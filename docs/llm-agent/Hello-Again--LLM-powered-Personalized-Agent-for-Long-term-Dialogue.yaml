- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:45:04'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:45:04
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Hello Again! LLM-powered Personalized Agent for Long-term Dialogue
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 再次你好！LLM驱动的个性化长期对话代理
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.05925](https://ar5iv.labs.arxiv.org/html/2406.05925)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.05925](https://ar5iv.labs.arxiv.org/html/2406.05925)
- en: Hao Li¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Hao Li¹
- en: 18th.leolee@gmail.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 18th.leolee@gmail.com
- en: '&Chenghao Yang^(2∗)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '&程昊杨^(2∗)'
- en: yangchenghao@mail.ustc.edu.cn
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: yangchenghao@mail.ustc.edu.cn
- en: '&An Zhang³'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '&安张³'
- en: anzhang@u.nus.edu
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: anzhang@u.nus.edu
- en: '&Yang Deng³'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '&杨邓³'
- en: ydeng@nus.edu.sg
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ydeng@nus.edu.sg
- en: '&Xiang Wang²'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '&向王²'
- en: xiangwang1223@gmail.com
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: xiangwang1223@gmail.com
- en: '&Tat-Seng Chua³'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '&卓胜楚³'
- en: dcscts@nus.edu.sg
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: dcscts@nus.edu.sg
- en: '&¹University of Electronic Science and Technology of China'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '&¹电子科技大学'
- en: ²University of Science and Technology of China
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ²中国科学技术大学
- en: ³National University of Singapore These authors contribute equally to this work.An
    Zhang is the corresponding author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ³新加坡国立大学 这些作者对本研究的贡献相同。安张为通讯作者。
- en: Abstract
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Open-domain dialogue systems have seen remarkable advancements with the development
    of large language models (LLMs). Nonetheless, most existing dialogue systems predominantly
    focus on brief single-session interactions, neglecting the real-world demands
    for long-term companionship and personalized interactions with chatbots. Crucial
    to addressing this real-world need are event summary and persona management, which
    enable reasoning for appropriate long-term dialogue responses. Recent progress
    in the human-like cognitive and reasoning capabilities of LLMs suggests that LLM-based
    agents could significantly enhance automated perception, decision-making, and
    problem-solving. In response to this potential, we introduce a model-agnostic
    framework, the Long-term Dialogue Agent (LD-Agent), which incorporates three independently
    tunable modules dedicated to event perception, persona extraction, and response
    generation. For the event memory module, long and short-term memory banks are
    employed to separately focus on historical and ongoing sessions, while a topic-based
    retrieval mechanism is introduced to enhance the accuracy of memory retrieval.
    Furthermore, the persona module conducts dynamic persona modeling for both users
    and agents. The integration of retrieved memories and extracted personas is subsequently
    fed into the generator to induce appropriate responses. The effectiveness, generality,
    and cross-domain capabilities of LD-Agent are empirically demonstrated across
    various illustrative benchmarks, models, and tasks. The code is released at [https://github.com/leolee99/LD-Agent](https://github.com/leolee99/LD-Agent).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 开放领域对话系统随着大语言模型（LLMs）的发展取得了显著进展。然而，大多数现有的对话系统主要集中在简短的单次互动上，忽视了与聊天机器人进行长期陪伴和个性化互动的现实需求。解决这一现实需求的关键是事件摘要和个性管理，这些都可以使对话响应更具长期适应性。近期在人类认知和推理能力方面的进展表明，基于LLM的代理可以显著提升自动感知、决策和问题解决能力。为了应对这一潜力，我们介绍了一种模型无关的框架，即长期对话代理（LD-Agent），该框架包含三个独立可调的模块，分别致力于事件感知、个性提取和响应生成。对于事件记忆模块，采用了长期和短期记忆库来分别关注历史和当前会话，同时引入了基于主题的检索机制以提高记忆检索的准确性。此外，个性模块对用户和代理进行动态个性建模。检索到的记忆和提取的个性随后被输入生成器，以产生适当的响应。LD-Agent的有效性、通用性和跨领域能力在各种示例基准、模型和任务中得到了实证验证。代码已发布在
    [https://github.com/leolee99/LD-Agent](https://github.com/leolee99/LD-Agent)。
- en: 1 Introduction
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Open-domain dialogue systems aim to establish long-term, personalized interactions
    with users via human-like chatbots [[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)].
    Unlike most existing studies [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)]
    that are limited to brief, single-session interactions spanning 2-15 turns, real-life
    scenarios often necessitate a chatbot’s capability for long-term companionship
    and familiarity [[1](#bib.bib1), [2](#bib.bib2), [7](#bib.bib7)]. Achieving this
    requires the chatbot not only to understand and remember extensive dialogue histories
    but also to faithfully reflect and consistently update both the user’s and its
    personalized characteristics [[1](#bib.bib1), [7](#bib.bib7), [8](#bib.bib8)].
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 开放领域对话系统旨在通过类人聊天机器人与用户建立长期个性化互动[[1](#bib.bib1), [2](#bib.bib2), [3](#bib.bib3)]。与大多数现有研究[[4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6)]仅限于2-15轮的简短单次互动不同，现实生活中的场景通常需要聊天机器人具备长期陪伴和熟悉感的能力[[1](#bib.bib1),
    [2](#bib.bib2), [7](#bib.bib7)]。实现这一点要求聊天机器人不仅能够理解和记住大量对话历史，还能够真实地反映和持续更新用户及其个性化特征[[1](#bib.bib1),
    [7](#bib.bib7), [8](#bib.bib8)]。
- en: Motivated by real-life demands, the core challenge of open-domain dialogue systems
    is to simultaneously maintain long-term event memory and preserve persona consistency [[9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11), [3](#bib.bib3)]. Existing research often addresses
    these aspects separately—focusing either on event memory or persona extraction—thereby
    hindering long-term consistency. Current strategies for event memory typically
    involve constructing a memory bank that stores historical event summaries, complemented
    by retrieval-augmented approaches to access relevant information for response
    generation [[12](#bib.bib12), [13](#bib.bib13)]. Studies on persona-based dialogue
    rang from unidirectional user modeling [[14](#bib.bib14)] to bidirectional agent-user
    modeling [[15](#bib.bib15), [16](#bib.bib16), [3](#bib.bib3)], enhancing personalized
    chat abilities by leveraging profile information. Worse still, the aforementioned
    methods are highly dependent on specific model architectures, making them challenging
    to adapt to other models. Additionally, These dialogue models largely lack zero-shot
    generalization capabilities, essential for effective deployment across various
    real-world domains [[2](#bib.bib2), [3](#bib.bib3)]. We conjecture that an optimal
    long-term dialogue framework should be model-agnostic, deployable in various real-world
    domains, and capable of autonomously integrating comprehensive data from both
    event memories and personas, as illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1
    Introduction ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue").
    However, developing such a model-agnostic, cross-domain, and autonomous framework
    remains unexplored and challenging.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 受现实需求驱动，开放领域对话系统的核心挑战是同时维持长期事件记忆和保持个性一致性[[9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11),
    [3](#bib.bib3)]。现有研究通常将这些方面分开处理——要么专注于事件记忆，要么专注于个性提取——从而阻碍了长期一致性。当前的事件记忆策略通常涉及构建存储历史事件摘要的记忆库，并辅以检索增强的方法来获取相关信息用于生成响应[[12](#bib.bib12),
    [13](#bib.bib13)]。关于个性化对话的研究从单向用户建模[[14](#bib.bib14)]到双向代理-用户建模[[15](#bib.bib15),
    [16](#bib.bib16), [3](#bib.bib3)]，通过利用个人资料信息增强个性化聊天能力。更糟糕的是，上述方法高度依赖于特定的模型架构，使其难以适应其他模型。此外，这些对话模型在跨领域的零样本泛化能力上普遍缺乏，这对在各种现实世界领域的有效部署至关重要[[2](#bib.bib2),
    [3](#bib.bib3)]。我们推测，一个理想的长期对话框架应该是与模型无关的，可部署于各种现实世界领域，并能够自主整合来自事件记忆和个性的全面数据，如图[1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue")所示。然而，开发这样一个模型无关、跨领域且自主的框架仍未探索，并且具有挑战性。
- en: '![Refer to caption](img/4bdea73a74730497c5d1cc106178b897.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4bdea73a74730497c5d1cc106178b897.png)'
- en: 'Figure 1: The illustration of how event memory and personas guide long-term
    dialogue. The event summary and personas are extracted from a conversation that
    occurred one week ago. In today’s interaction, the event memory prompts the girl
    to inquire about the swimming lesson they scheduled last week. The personas, indicating
    that she is careful and professional in swimming, guide her to offer detailed
    and professional advice.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：事件记忆和个性如何指导长期对话的示意图。事件摘要和个性来自一周前发生的对话。在今天的互动中，事件记忆促使女孩询问她们上周安排的游泳课程。个性表明她在游泳方面细心且专业，指导她提供详细和专业的建议。
- en: Benefiting from the excellent human-like cognitive and reasoning abilities of
    large language models (LLM), there is an increasing trend [[17](#bib.bib17), [18](#bib.bib18),
    [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)] to employ LLMs as the cores
    of agent-based simulation systems to automate the process of perception, decision-making,
    and problem-solving. While recent studies have developed LLM-powered agents in
    various fields, such as economics [[22](#bib.bib22)], politics [[23](#bib.bib23)],
    sociology [[24](#bib.bib24)], and recommendation [[21](#bib.bib21)], its application
    in open-domain dialogue remains unexplored. To effectively support long-term open-domain
    dialogue, an LLM-powered dialogue agent framework should exhibit broad generality,
    cross-domain adaptability, and the ability to dynamically refine information across
    dimensions like events, user personalities, and agent personalities.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大型语言模型（LLM）卓越的人类认知和推理能力，越来越多的趋势是[[17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19),
    [20](#bib.bib20), [21](#bib.bib21)]将LLM作为基于代理的模拟系统的核心，以自动化感知、决策和问题解决的过程。尽管近期研究已经在经济学[[22](#bib.bib22)]、政治学[[23](#bib.bib23)]、社会学[[24](#bib.bib24)]和推荐系统[[21](#bib.bib21)]等各个领域开发了LLM驱动的代理，但其在开放领域对话中的应用仍未被探索。为了有效支持长期开放领域对话，LLM驱动的对话代理框架应具有广泛的通用性、跨领域适应性，并能够在事件、用户个性和代理个性等维度上动态完善信息。
- en: 'In this paper, we propose LD-Agent—a model-agnostic Long-term Dialogue Agent
    framework consisting of three principal components: an event memory perception
    module, a persona extraction module, and response generation module (see the framework
    of LD-Agent in Figure [2](#S2.F2 "Figure 2 ‣ 2.2 Event Perception ‣ 2 Method ‣
    Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")). The event
    memory perception module is designed to enhance coherence across sessions by separately
    maintaining long-term and short-term memory banks. The long-term memory bank stores
    vector representations of high-level event summaries from previous sessions, refined
    through a tunable event summary module. The short-term memory bank maintains contextual
    information for ongoing conversations. The persona extraction module, designed
    to facilitate personalized interactions, incorporates a disentangled, tunable
    mechanism for accurate user-agent modeling. Extracted personas are continuously
    updated and stored in a long-term persona bank. These personas, along with relevant
    memories, are then integrated into the response generation module, guiding the
    generation of appropriate responses, as depicted in Figure [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue").'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了LD-Agent——一个模型无关的长期对话代理框架，由三个主要组件组成：事件记忆感知模块、个性提取模块和响应生成模块（见LD-Agent的框架，图[2](#S2.F2
    "图 2 ‣ 2.2 事件感知 ‣ 2 方法 ‣ 再见！LLM驱动的个性化长期对话代理")）。事件记忆感知模块旨在通过分别维护长期和短期记忆库来增强会话的连贯性。长期记忆库存储来自先前会话的高层次事件摘要的向量表示，并通过可调节的事件摘要模块进行优化。短期记忆库维护正在进行的对话的上下文信息。个性提取模块旨在促进个性化互动，包含一个解耦的、可调的机制，用于准确的用户-代理建模。提取的个性不断更新并存储在长期个性库中。这些个性以及相关的记忆随后被整合到响应生成模块中，指导生成适当的回应，如图[1](#S1.F1
    "图 1 ‣ 1 引言 ‣ 再见！LLM驱动的个性化长期对话代理")所示。
- en: 'We conduct comprehensive experiments on two illustrative long-term multi-session
    daily dialogue datasets, MSC [[1](#bib.bib1)] and Conversation Chronicles (CC) [[7](#bib.bib7)],
    to evaluate the effectiveness, generality, and cross-domain capabilities of the
    proposed framework. In terms of effectiveness, LD-Agent achieves state-of-the-art
    performance on both benchmarks, significantly outperforming existing methods [[2](#bib.bib2),
    [25](#bib.bib25), [26](#bib.bib26)]. To assess generality, we examine the framework
    from both model and task perspectives. From the model perspective, LD-Agent is
    evaluated across a range of both online and offline models, including LLMs [[25](#bib.bib25)]
    and non-LLMs [[26](#bib.bib26)]. From the task perspective, we extend our evaluation
    to multiparty dialogue tasks [[27](#bib.bib27)], where LD-Agent also demonstrates
    substantial improvements, showcasing its adaptability across different models
    and tasks. Regarding the method’s cross-domain capabilities, we design two cross-domain
    settings: tuning the model on the MSC dataset and testing it on the CC dataset,
    and vice versa. In both scenarios, LD-Agent shows competitive performance, nearly
    matching the results of in-domain training.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在两个示例性的长期多会话日常对话数据集 MSC [[1](#bib.bib1)] 和 Conversation Chronicles (CC) [[7](#bib.bib7)]
    上进行了全面的实验，以评估所提框架的有效性、普遍性和跨领域能力。在有效性方面，LD-Agent 在两个基准测试中都达到了最先进的性能，显著超越了现有方法 [[2](#bib.bib2),
    [25](#bib.bib25), [26](#bib.bib26)]。为了评估普遍性，我们从模型和任务两个角度审视框架。从模型角度，LD-Agent 在一系列在线和离线模型中进行评估，包括
    LLMs [[25](#bib.bib25)] 和非 LLMs [[26](#bib.bib26)]。从任务角度，我们将评估扩展到多方对话任务 [[27](#bib.bib27)]，其中
    LD-Agent 也表现出了显著的改进，展示了其在不同模型和任务中的适应性。关于方法的跨领域能力，我们设计了两个跨领域设置：在 MSC 数据集上调整模型，然后在
    CC 数据集上测试，反之亦然。在这两种情况下，LD-Agent 都显示出了竞争力的表现，几乎与领域内训练的结果相匹配。
- en: 'Our contributions can be summarized as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献可以总结如下：
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We develop LD-Agent, a general long-term dialogue agent framework, considering
    both historical events and personas. The event memory module ensures dialogue
    coherence across sessions, while the persona module ensures character consistency.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们开发了 LD-Agent，一个通用的长期对话代理框架，考虑了历史事件和角色。事件记忆模块确保了跨会话的对话连贯性，而角色模块确保了角色一致性。
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce a disentangled, tunable approach for long-term dialogue to ensure
    the accuracy of each module. The highly modular framework enables it to adapt
    to various dialogue tasks through module re-training.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们引入了一种解耦的、可调的长期对话方法，以确保每个模块的准确性。这个高度模块化的框架使其能够通过模块再训练适应各种对话任务。
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We confirm the superiority of our proposed framework through rigorous experiments
    across multiple challenging benchmarks, diverse illustrative models, and various
    tasks. Extensive insightful ablation studies further highlight its effectiveness
    and generalization.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过在多个具有挑战性的基准测试、各种示例模型和任务上进行严格的实验，确认了我们提出的框架的优越性。广泛的有意义的消融研究进一步突显了其有效性和泛化能力。
- en: 2 Method
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法
- en: In this section, we introduce the detailed description of LD-Agent with the
    framework shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.2 Event Perception ‣ 2 Method
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue"). We first
    introduce the task definition of long-term dialogue in Section. [2.1](#S2.SS1
    "2.1 Task Definition ‣ 2 Method ‣ Hello Again! LLM-powered Personalized Agent
    for Long-term Dialogue"). Consequently, we separately introduce the mechanism
    of event perception (Section. [2.2](#S2.SS2 "2.2 Event Perception ‣ 2 Method ‣
    Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")), dynamic
    personas extraction (Section. [2.3](#S2.SS3 "2.3 Dynamic Personas Extraction ‣
    2 Method ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")),
    and response generation (Section. [2.4](#S2.SS4 "2.4 Response Generation ‣ 2 Method
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了 LD-Agent 的详细描述，框架如图 [2](#S2.F2 "Figure 2 ‣ 2.2 Event Perception ‣
    2 Method ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")所示。我们首先在第 [2.1](#S2.SS1
    "2.1 Task Definition ‣ 2 Method ‣ Hello Again! LLM-powered Personalized Agent
    for Long-term Dialogue")节中介绍了长期对话的任务定义。随后，我们分别介绍了事件感知机制（第 [2.2](#S2.SS2 "2.2 Event
    Perception ‣ 2 Method ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue")节）、动态角色提取（第 [2.3](#S2.SS3 "2.3 Dynamic Personas Extraction ‣ 2 Method
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")节）和响应生成（第 [2.4](#S2.SS4
    "2.4 Response Generation ‣ 2 Method ‣ Hello Again! LLM-powered Personalized Agent
    for Long-term Dialogue")节）。
- en: 2.1 Task Definition
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 任务定义
- en: The goal of the long-term multi-session dialogue task is to generate an appropriate
    response $r$-th conversational session. Distinct from single-session dialogue
    models, a long-term multi-session dialogue system integrates both current and
    long-term historical conversational cues to generate contextually appropriate
    responses.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 长期多会话对话任务的目标是生成适当的响应 $r$-th 对话会话。与单会话对话模型不同，长期多会话对话系统结合了当前和长期的历史对话线索，以生成上下文适当的响应。
- en: 2.2 Event Perception
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 事件感知
- en: The event memory module is designed to perceive historical events to generate
    coherent responses across interval time. As shown in Figure [2](#S2.F2 "Figure
    2 ‣ 2.2 Event Perception ‣ 2 Method ‣ Hello Again! LLM-powered Personalized Agent
    for Long-term Dialogue"), this event memory module is segmented into two major
    sub-modules that focus separately on long-term and short-term memory.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 事件记忆模块旨在感知历史事件，以在时间间隔内生成连贯的响应。如图 [2](#S2.F2 "图 2 ‣ 2.2 事件感知 ‣ 2 方法 ‣ 再见！LLM驱动的个性化长期对话代理")
    所示，该事件记忆模块被分为两个主要子模块，分别关注长期和短期记忆。
- en: '![Refer to caption](img/960eaa600139fd6755ba55665bfc5f6e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/960eaa600139fd6755ba55665bfc5f6e.png)'
- en: 'Figure 2: The Framework of LD-Agent. The event module stores historical memories
    from past sessions in long-term memory and current context in short-term memory.
    The persona module dynamically extracts and updates personas for both users and
    agents from ongoing utterances, storing them in a persona bank for each character.
    The response module then synthesizes this data to generate informed and appropriate
    responses.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：LD-Agent 框架。事件模块将来自过去会话的历史记忆存储在长期记忆中，将当前上下文存储在短期记忆中。个性模块动态提取并更新来自正在进行的发言的用户和代理的个性，将其存储在每个角色的个性库中。响应模块随后综合这些数据以生成信息丰富且适当的响应。
- en: 2.2.1 Long-term Memory
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 长期记忆
- en: Memory Storage.
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 记忆存储。
- en: The long-term memory module aims to extract and encode events from past sessions.
    Specifically, this involves recording the occurrence times $t$ specifies the length
    of the memory bank. The encoded representations are then efficiently retrieved
    through an embedding-based mechanism, which enhances the accessibility of the
    stored memory.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 长期记忆模块旨在提取和编码来自过去会话的事件。具体来说，这涉及记录事件发生时间 $t$，以指定记忆库的长度。编码的表示通过基于嵌入的机制高效检索，这增强了存储记忆的可访问性。
- en: Event Summary.
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 事件总结。
- en: 'Different from previous agent approaches [[20](#bib.bib20), [21](#bib.bib21),
    [29](#bib.bib29)] that entirely rely on LLM’s zero-shot ability to excavate and
    summarize events, we apply instruction tuning [[30](#bib.bib30)] to the event
    summary module, which can directly improve the event summary quality. Specifically,
    we rebuild the DialogSum dataset [[31](#bib.bib31)], a large-scale dialogue summarization
    dataset, into the following format: (1) an introduction to the task background,
    (2) the related conversations that need to be understood, and (3) detailed summarization
    requests. These three parts serve as input prompts (see Appendix. [D.1](#A4.SS1
    "D.1 Prompt of Event Summary ‣ Appendix D Prompt ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue") for more details), combined with the original summaries
    from DialogSum as answers, and are jointly used to fine-tune the event summary
    module, thereby directly improving the quality of event summarization.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与完全依赖 LLM 的零-shot 能力挖掘和总结事件的先前代理方法 [[20](#bib.bib20), [21](#bib.bib21), [29](#bib.bib29)]
    不同，我们对事件总结模块应用了指令微调 [[30](#bib.bib30)]，这可以直接提高事件总结的质量。具体来说，我们将 DialogSum 数据集 [[31](#bib.bib31)]，一个大规模对话总结数据集，重建为以下格式：（1）任务背景介绍，（2）需要理解的相关对话，以及（3）详细的总结请求。这三个部分作为输入提示（见附录。[D.1](#A4.SS1
    "D.1 事件总结提示 ‣ 附录 D 提示 ‣ 再见！LLM驱动的个性化长期对话代理") 了解更多细节），与 DialogSum 的原始总结作为答案结合使用，并共同用于微调事件总结模块，从而直接提高事件总结的质量。
- en: Memory Retrieval.
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 记忆检索。
- en: 'To improve retrieval accuracy, we employ a retrieval mechanism that comprehensively
    considers semantic relevance, topic overlap, and time decay. Optimizing the retrieval
    accuracy of agent memory is challenging due to the difficulty in obtaining accurate
    memory retrieval data. Most existing methods [[20](#bib.bib20), [21](#bib.bib21)]
    use event summaries as keys and context as queries, calculating the query-key
    semantic relevance score $s_{\text{sem}}$ by:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高检索准确性，我们采用了一种综合考虑语义相关性、主题重叠和时间衰减的检索机制。由于准确的记忆检索数据难以获得，优化代理记忆的检索准确性是具有挑战性的。大多数现有方法
    [[20](#bib.bib20), [21](#bib.bib21)] 使用事件摘要作为键，背景作为查询，通过以下公式计算查询-键的语义相关性得分 $s_{\text{sem}}$：
- en: '|  | $s_{\text{top}}=\frac{1}{2}(\frac{\left&#124;V_{q}\cap V_{k}\right&#124;}{V_{q}}+\frac{\left&#124;V_{q}\cap
    V_{k}\right&#124;}{V_{k}}),$ |  | (1) |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | $s_{\text{top}}=\frac{1}{2}(\frac{\left&#124;V_{q}\cap V_{k}\right&#124;}{V_{q}}+\frac{\left&#124;V_{q}\cap
    V_{k}\right&#124;}{V_{k}}),$ |  | (1) |'
- en: 'where $V_{q}$, signified as:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $V_{q}$，表示为：
- en: '|  | $s_{\text{overall}}=\lambda_{t}(s_{\text{sem}}+s_{\text{top}}).$ |  |
    (2) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $s_{\text{overall}}=\lambda_{t}(s_{\text{sem}}+s_{\text{top}}).$ |  |
    (2) |'
- en: 'To avoid retrieving inappropriate memory due to no suitable memories existing,
    we implement a semantic threshold $\gamma$ can be denoted as:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为避免因没有合适的记忆而检索到不恰当的记忆，我们实现了一个语义阈值 $\gamma$，可以表示为：
- en: '|  | $m=\psi(M_{L},\gamma).$ |  | (3) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | $m=\psi(M_{L},\gamma).$ |  | (3) |'
- en: 2.2.2 Short-term Memory
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 短期记忆
- en: 'The short-term memory module actively manages a dynamic dialogue cache $M_{S}=\{(t_{i},u_{i})|i=\{1,2,3,\dots,r_{c}\}\}$
    is added to the cache. The mathematical expression of this process is given by:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 短期记忆模块积极管理一个动态对话缓存 $M_{S}=\{(t_{i},u_{i})|i=\{1,2,3,\dots,r_{c}\}\}$ 被添加到缓存中。这个过程的数学表达式为：
- en: '|  | $\displaystyle M^{\prime}_{L}$ |  | (4) |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle M^{\prime}_{L}$ |  | (4) |'
- en: '|  | $\displaystyle M_{S}$ |  |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle M_{S}$ |  |'
- en: where $M^{\prime}_{L}$.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $M^{\prime}_{L}$。
- en: 2.3 Dynamic Personas Extraction
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 动态角色提取
- en: The persona module is pivotal in maintaining long-term persona consistency for
    both participants in a dialogue system. Drawing inspiration from prior work [[3](#bib.bib3)],
    we adopt a bidirectional user-agent modeling approach, utilizing a tunable persona
    extractor to manage long-term persona bank $P_{u}$ for the user and agent, respectively.
    Specifically, we develop an open-domain, utterance-based persona extraction dataset
    derived from MSC [[1](#bib.bib1)]. We enhance the persona extractor with LoRA-based
    instruction tuning, which allows for the dynamic extraction of personality traits
    during conversations. These traits are subsequently stored in the corresponding
    character’s persona bank. For utterances devoid of personality traits, the module
    outputs “No Trait”. Additionally, we employ a tuning-free strategy that harnesses
    the zero-shot capabilities of LLM models to directly extract personas based on
    prompts. To further improve the agent’s ability to excavate user personas without
    training, we adjust our reasoning strategy from direct reasoning to a Chain-of-Thought
    reasoning [[32](#bib.bib32)] (see Appendix. [D.2](#A4.SS2 "D.2 Prompt of Persona
    Extraction ‣ Appendix D Prompt ‣ Hello Again! LLM-powered Personalized Agent for
    Long-term Dialogue")).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 角色模块在维护对话系统中参与者的长期角色一致性方面至关重要。受先前工作的启发 [[3](#bib.bib3)]，我们采用了双向用户-代理建模方法，利用可调的角色提取器分别管理用户和代理的长期角色库
    $P_{u}$。具体而言，我们开发了一个基于发言的开放域角色提取数据集，该数据集来源于 MSC [[1](#bib.bib1)]。我们通过 LoRA 基于指令调优增强了角色提取器，这使得在对话过程中可以动态提取个性特征。这些特征随后被存储在对应角色的角色库中。对于没有个性特征的发言，模块输出“No
    Trait”。此外，我们采用了一种无需调优的策略，利用 LLM 模型的零-shot 能力根据提示直接提取角色。为了进一步提高代理挖掘用户角色的能力而无需训练，我们将推理策略从直接推理调整为链式思维推理
    [[32](#bib.bib32)]（见附录 [D.2](#A4.SS2 "D.2 Prompt of Persona Extraction ‣ Appendix
    D Prompt ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")）。
- en: 2.4 Response Generation
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 响应生成
- en: Upon receiving a new user utterance $u^{\prime}$, as formulated in Eq. [5](#S2.E5
    "In 2.4 Response Generation ‣ 2 Method ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue").
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到新的用户发言 $u^{\prime}$ 时，如公式 [5](#S2.E5 "In 2.4 Response Generation ‣ 2 Method
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue") 所述。
- en: '|  | $r=G(u^{\prime},m,M_{S},P_{u},P_{a}).$ |  | (5) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | $r=G(u^{\prime},m,M_{S},P_{u},P_{a}).$ |  | (5) |'
- en: To enhance the agent’s ability for coherent and contextually appropriate responses,
    we develop a long-term, multi-session dialogue dataset, featuring dynamic retrieval
    memories, context, and personas sourced from the MSC and CC datasets for generator
    tuning. Specifically, for each sample, covering five sessions, we dynamically
    simulate the entire progression of the conversation. As each new utterance is
    introduced, the previously tuned modules for event summarization, persona extraction,
    and topic-aware memory retrieval are utilized to collect the necessary context,
    retrieved memories, and both user and agent personas related to the utterance.
    This comprehensive data is then integrated into a response generation prompt (see
    Appendix. [D.3](#A4.SS3 "D.3 Prompt of Response Generation ‣ Appendix D Prompt
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")). The original
    responses from the MSC and CC datasets are used as ground truth sentences.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强代理在连贯和上下文适当回应方面的能力，我们开发了一个长期的多会话对话数据集，包含来自MSC和CC数据集的动态检索记忆、上下文和角色用于生成器调优。具体而言，对于每个样本，涵盖五个会话，我们动态模拟对话的整个进程。每当引入新的发言时，之前调优的事件摘要、角色提取和话题感知记忆检索模块被用来收集所需的上下文、检索到的记忆以及与发言相关的用户和代理角色。这些综合数据随后被整合到回应生成提示中（见附录。[D.3](#A4.SS3
    "D.3 回应生成提示 ‣ 附录 D 提示 ‣ 再见！基于LLM的个性化长期对话代理")）。MSC和CC数据集中的原始回应被用作真实句子。
- en: 3 Experiments
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: 'We aim to answer the following research questions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们旨在回答以下研究问题：
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ1: How does LD-Agent perform in long-term dialogue tasks?'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ1: LD-Agent在长期对话任务中的表现如何？'
- en: •
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ2: How is the generality and practicality of LD-Agent?'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'RQ2: LD-Agent的通用性和实用性如何？'
- en: 3.1 Evaluation Settings
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 评估设置
- en: In this subsection, we briefly introduce the experimental dataset, evaluation
    metrics, and baseline models in our study. Detailed evaluation settings are elaborated
    in Appendix. [C](#A3 "Appendix C Detailed Evaluation Settings ‣ Hello Again! LLM-powered
    Personalized Agent for Long-term Dialogue").
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，我们简要介绍了实验数据集、评估指标和基线模型。详细的评估设置在附录中说明。[C](#A3 "附录 C 详细评估设置 ‣ 再见！基于LLM的个性化长期对话代理")。
- en: Datasets.
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据集。
- en: Extensive experiments are conducted on two illustrative multi-session datasets,
    MSC [[1](#bib.bib1)] and CC [[7](#bib.bib7)], each comprising 5 sessions with
    approximately 50 conversational turns per sample, to investigate the effectiveness
    of LD-Agent on long-term dialogue scenarios. The experiments cover model independence
    assessment, module ablation, persona extractor analysis, and cross-domain evaluation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个具有代表性的多会话数据集MSC [[1](#bib.bib1)]和CC [[7](#bib.bib7)]上进行了大量实验，每个数据集包含5个会话，每个样本约有50轮对话，以研究LD-Agent在长期对话场景中的有效性。实验涵盖了模型独立性评估、模块消融、角色提取器分析和跨领域评估。
- en: Additionally, to evaluate the transferability of the LD-Agent, we apply our
    method to the Ubuntu IRC benchmark [[27](#bib.bib27)], a dataset known for its
    multiparty interaction tasks.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了评估LD-Agent的可迁移性，我们将我们的方法应用于Ubuntu IRC基准数据集 [[27](#bib.bib27)]，该数据集以其多方交互任务而闻名。
- en: Metrics.
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 指标。
- en: 'Our evaluation combines both automatic and human assessments to thoroughly
    investigate the effectiveness of LD-Agent. For automatic evaluation, we use three
    widely used standard metrics: BLEU-N (BL-N) [[33](#bib.bib33)], ROUGE-L (R-L) [[34](#bib.bib34)],
    and METEOR (MET) [[35](#bib.bib35)] to measure the quality of response generation.
    Additionally, accuracy (ACC) is employed to evaluate the classification performance
    of the persona extractor. In human evaluation, we measure topic coherence across
    sessions, interaction fluency, and user engagement using the metrics of coherence,
    fluency, and engagingness, respectively.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评估结合了自动评估和人工评估，以全面调查LD-Agent的有效性。对于自动评估，我们使用三种广泛使用的标准指标：BLEU-N (BL-N) [[33](#bib.bib33)]、ROUGE-L
    (R-L) [[34](#bib.bib34)]和METEOR (MET) [[35](#bib.bib35)]来衡量回应生成的质量。此外，准确率（ACC）用于评估角色提取器的分类性能。在人工评估中，我们使用连贯性、流畅性和吸引力这三个指标来衡量话题连贯性、互动流畅性和用户参与度。
- en: Baselines.
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基线。
- en: 'To demonstrate the effectiveness and model independence of LD-Agent, we deploy
    LD-Agent on multiple platforms and models. Specifically, the LLM-based models
    (online model: ChatGPT; offline model: ChatGLM [[25](#bib.bib25)]) and traditional
    language models (BlenderBot [[26](#bib.bib26)], and BART [[36](#bib.bib36)]) are
    employed as our baselines. In our experiments, The notation “Model[LDA]” denotes
    models that incorporate the LD-Agent framework, while “Model” refers to the original
    baseline models without LD-Agent. Additionally, we also utilize HAHT [[2](#bib.bib2)],
    the previous state-of-the-art model in long-term dialogue task, as a contrast.
    See the above baselines stand and their role in rich literature in Appendix. [A](#A1
    "Appendix A Related Work ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue").'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示 LD-Agent 的有效性和模型独立性，我们在多个平台和模型上部署 LD-Agent。具体而言，使用了基于 LLM 的模型（在线模型：ChatGPT；离线模型：ChatGLM [[25](#bib.bib25)]）和传统语言模型（BlenderBot [[26](#bib.bib26)]，以及
    BART [[36](#bib.bib36)]）作为我们的基准。在我们的实验中，符号“Model[LDA]”表示结合 LD-Agent 框架的模型，而“Model”指的是没有
    LD-Agent 的原始基准模型。此外，我们还利用了 HAHT [[2](#bib.bib2)]，这是在长期对话任务中的前沿模型，用于对比。有关上述基准模型及其在丰富文献中的作用，请参见附录。[A](#A1
    "附录 A 相关工作 ‣ 再见！LLM 驱动的个性化长期对话代理")。
- en: 'Table 1: Experimental results of the automatic evaluation for response generation
    on MSC and CC.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：MSC 和 CC 上响应生成的自动评估实验结果。
- en: '|  |  | Session 2 | Session 3 | Session 4 | Session 5 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  |  | Session 2 | Session 3 | Session 4 | Session 5 |'
- en: '|  | Model | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2
    | BL-3 | R-L |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | Model | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2
    | BL-3 | R-L |'
- en: '| MSC |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| MSC |'
- en: '|  | ChatGLM | 5.44 | 1.49 | 16.76 | 5.18 | 1.55 | 15.51 | 5.63 | 1.33 | 16.35
    | 5.92 | 1.45 | 16.63 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  | ChatGLM | 5.44 | 1.49 | 16.76 | 5.18 | 1.55 | 15.51 | 5.63 | 1.33 | 16.35
    | 5.92 | 1.45 | 16.63 |'
- en: '|  | ChatGLM[LDA] | 5.74 | 1.73 | 17.21 | 6.05 | 1.73 | 16.97 | 6.09 | 1.59
    | 16.76 | 6.60 | 1.94 | 17.18 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | ChatGLM[LDA] | 5.74 | 1.73 | 17.21 | 6.05 | 1.73 | 16.97 | 6.09 | 1.59
    | 16.76 | 6.60 | 1.94 | 17.18 |'
- en: '|  | ChatGPT | 5.22 | 1.45 | 16.04 | 5.18 | 1.55 | 15.51 | 4.64 | 1.32 | 15.19
    | 5.38 | 1.58 | 15.48 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | ChatGPT | 5.22 | 1.45 | 16.04 | 5.18 | 1.55 | 15.51 | 4.64 | 1.32 | 15.19
    | 5.38 | 1.58 | 15.48 |'
- en: '| Zero-shot | ChatGPT[LDA] | 8.67 | 4.63 | 19.86 | 7.92 | 3.55 | 18.54 | 7.08
    | 2.97 | 17.90 | 7.37 | 3.03 | 17.86 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot | ChatGPT[LDA] | 8.67 | 4.63 | 19.86 | 7.92 | 3.55 | 18.54 | 7.08
    | 2.97 | 17.90 | 7.37 | 3.03 | 17.86 |'
- en: '|  | HAHT | 5.06 | 1.68 | 16.82 | 4.96 | 1.50 | 16.48 | 4.75 | 1.45 | 15.82
    | 4.99 | 1.51 | 16.24 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | HAHT | 5.06 | 1.68 | 16.82 | 4.96 | 1.50 | 16.48 | 4.75 | 1.45 | 15.82
    | 4.99 | 1.51 | 16.24 |'
- en: '|  | BlenderBot | 5.71 | 1.62 | 16.15 | 8.10 | 2.50 | 18.23 | 7.55 | 1.96 |
    17.45 | 8.02 | 2.36 | 17.65 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | BlenderBot | 5.71 | 1.62 | 16.15 | 8.10 | 2.50 | 18.23 | 7.55 | 1.96 |
    17.45 | 8.02 | 2.36 | 17.65 |'
- en: '|  | BlenderBot[LDA] | 8.45 | 3.27 | 19.07 | 8.68 | 3.06 | 18.87 | 8.16 | 2.77
    | 18.06 | 8.31 | 2.69 | 18.19 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | BlenderBot[LDA] | 8.45 | 3.27 | 19.07 | 8.68 | 3.06 | 18.87 | 8.16 | 2.77
    | 18.06 | 8.31 | 2.69 | 18.19 |'
- en: '|  | ChatGLM | 5.48 | 1.59 | 17.65 | 6.12 | 1.78 | 17.91 | 6.14 | 1.63 | 17.78
    | 6.16 | 1.69 | 17.65 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | ChatGLM | 5.48 | 1.59 | 17.65 | 6.12 | 1.78 | 17.91 | 6.14 | 1.63 | 17.78
    | 6.16 | 1.69 | 17.65 |'
- en: '| Tuning | ChatGLM[LDA] | 10.70 | 5.63 | 23.31 | 10.03 | 5.12 | 21.55 | 9.07
    | 4.06 | 20.19 | 8.96 | 4.01 | 19.94 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Tuning | ChatGLM[LDA] | 10.70 | 5.63 | 23.31 | 10.03 | 5.12 | 21.55 | 9.07
    | 4.06 | 20.19 | 8.96 | 4.01 | 19.94 |'
- en: '| CC |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| CC |'
- en: '| Zero-shot | ChatGLM | 8.94 | 4.44 | 21.54 | 8.34 | 4.03 | 21.00 | 8.28 |
    3.82 | 20.67 | 8.12 | 3.81 | 20.54 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot | ChatGLM | 8.94 | 4.44 | 21.54 | 8.34 | 4.03 | 21.00 | 8.28 |
    3.82 | 20.67 | 8.12 | 3.81 | 20.54 |'
- en: '| ChatGLM[LDA] | 9.53 | 4.82 | 22.76 | 9.22 | 4.43 | 22.18 | 9.15 | 4.48 |
    22.18 | 8.99 | 4.43 | 22.10 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM[LDA] | 9.53 | 4.82 | 22.76 | 9.22 | 4.43 | 22.18 | 9.15 | 4.48 |
    22.18 | 8.99 | 4.43 | 22.10 |'
- en: '| ChatGPT | 10.57 | 5.50 | 22.10 | 10.58 | 5.59 | 22.04 | 10.61 | 5.58 | 21.92
    | 10.17 | 5.22 | 21.45 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 10.57 | 5.50 | 22.10 | 10.58 | 5.59 | 22.04 | 10.61 | 5.58 | 21.92
    | 10.17 | 5.22 | 21.45 |'
- en: '| ChatGPT[LDA] | 15.89 | 11.01 | 26.96 | 12.92 | 8.27 | 24.31 | 12.20 | 7.35
    | 23.69 | 11.54 | 6.74 | 22.87 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT[LDA] | 15.89 | 11.01 | 26.96 | 12.92 | 8.27 | 24.31 | 12.20 | 7.35
    | 23.69 | 11.54 | 6.74 | 22.87 |'
- en: '| Tuning | BlenderBot | 8.99 | 4.86 | 21.58 | 9.44 | 5.19 | 22.13 | 9.46 |
    5.21 | 22.08 | 8.99 | 4.75 | 21.73 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Tuning | BlenderBot | 8.99 | 4.86 | 21.58 | 9.44 | 5.19 | 22.13 | 9.46 |
    5.21 | 22.08 | 8.99 | 4.75 | 21.73 |'
- en: '| BlenderBot[LDA] | 14.47 | 10.16 | 27.91 | 15.66 | 11.33 | 29.10 | 15.13 |
    10.80 | 28.38 | 14.08 | 9.72 | 27.37 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| BlenderBot[LDA] | 14.47 | 10.16 | 27.91 | 15.66 | 11.33 | 29.10 | 15.13 |
    10.80 | 28.38 | 14.08 | 9.72 | 27.37 |'
- en: '| ChatGLM | 15.89 | 9.90 | 30.59 | 15.97 | 10.06 | 30.27 | 16.10 | 10.31 |
    30.54 | 15.10 | 9.34 | 29.43 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM | 15.89 | 9.90 | 30.59 | 15.97 | 10.06 | 30.27 | 16.10 | 10.31 |
    30.54 | 15.10 | 9.34 | 29.43 |'
- en: '| ChatGLM[LDA] | 25.69 | 19.53 | 39.67 | 25.93 | 19.72 | 39.15 | 25.82 | 19.40
    | 39.05 | 24.26 | 18.16 | 37.61 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM[LDA] | 25.69 | 19.53 | 39.67 | 25.93 | 19.72 | 39.15 | 25.82 | 19.40
    | 39.05 | 24.26 | 18.16 | 37.61 |'
- en: 3.2 Results of Multi-Session Dialogue
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 多会话对话的结果
- en: We adopt two multi-session dialogue dataset to quantitatively evaluate our method
    in long-term dialogue scenarios. The first session is used to initialize conversation
    and the subsequent four sessions are used to evaluate the performance of long-term
    dialogue. In these experiments, our framework is applied to both zero-shot models,
    including ChatGLM and ChatGPT, and to tuned models such as BlenderBot and ChatGLM.
    The results are shown in Table [1](#S3.T1 "Table 1 ‣ Baselines. ‣ 3.1 Evaluation
    Settings ‣ 3 Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue").
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了两个多会话对话数据集来定量评估我们的方法在长期对话场景中的表现。第一次会话用于初始化对话，随后的四次会话用于评估长期对话的表现。在这些实验中，我们的框架应用于零样本模型，包括ChatGLM和ChatGPT，以及调优后的模型，如BlenderBot和ChatGLM。结果如表[1](#S3.T1
    "表 1 ‣ 基线 ‣ 3.1 评估设置 ‣ 3 实验 ‣ 再见！LLM驱动的长期对话个性化代理")所示。
- en: Impressive performance on long-term dialogue tasks.
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 在长期对话任务上表现令人印象深刻。
- en: On both datasets, all models employing LD-Agent consistently achieve significant
    improvements across all sessions and metrics, showcasing the powerful ability
    of LD-Agent on supporting long-term dialogue. Most notably, comparing with previous
    state-of-the-art model HAHT, BlenderBot employing LD-Agent, which has similar
    parameter scale to HAHT, outperforms it with a large performance gap of 3.39%,
    3.72%, 3.41%, and 3.32% on BLEU-2 ranging from session 2 to 5\. This further highlighting
    the effectiveness of LD-Agent on long-term dialogue tasks.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个数据集中，所有使用LD-Agent的模型在所有会话和指标中一致地实现了显著的改进，展示了LD-Agent在支持长期对话方面的强大能力。最值得注意的是，与之前的最先进模型HAHT相比，使用LD-Agent的BlenderBot在BLEU-2上相较于HAHT取得了3.39%、3.72%、3.41%和3.32%的显著性能提升，范围从第2到第5会话。这进一步突显了LD-Agent在长期对话任务中的有效性。
- en: Remarkable generality of LD-Agent.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: LD-Agent的显著通用性。
- en: 'The generality of LD-Agent are proved from two aspects: data transferability
    and model transferability. The consistently improvements brought by LD-Agent on
    both benchmarks demonstrate the generality of our framework on various long-term
    dialogue scenarios. In parallel, we observe that LD-Agent also plays positive
    roles in the zero-shot setting, employing to the online model of ChatGPT and the
    offline model of ChatGLM. In the tuning setting, LD-Agent achieves significant
    enhancements on both LLM of ChatGLM and traditional model of BlenderBot, fully
    proving the remarkable model transferability of LD-Agent. These results comprehensive
    demonstrate the generality of LD-Agent.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: LD-Agent的通用性从两个方面得到了证明：数据迁移性和模型迁移性。LD-Agent在两个基准测试中带来的持续改进展示了我们框架在各种长期对话场景中的通用性。同时，我们观察到LD-Agent在零样本设置中也发挥了积极作用，应用于ChatGPT的在线模型和ChatGLM的离线模型。在调优设置中，LD-Agent在ChatGLM和BlenderBot的传统模型中都实现了显著的提升，充分证明了LD-Agent卓越的模型迁移性。这些结果全面展示了LD-Agent的通用性。
- en: 3.3 Ablation Studies
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 消融研究
- en: To further analyze the effectiveness of each components, we conduct ablation
    studies for memory module and personas module. We adopt ChatGLM as our backbone,
    which is tuned solely using the context of the current session, referred to here
    as “Baseline”. Afterward, we separately add “Event Memory”, “Agent personas”,
    and “User personas” modules for additional tuning on top of the baseline. The
    results are presented in Table [2](#S3.T2 "Table 2 ‣ 3.3 Ablation Studies ‣ 3
    Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue").
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步分析各个组件的有效性，我们进行了内存模块和角色模块的消融研究。我们采用了ChatGLM作为我们的基础模型，仅使用当前会话的上下文进行调优，称之为“基线”。随后，我们分别添加了“事件记忆”、“代理角色”和“用户角色”模块，在基线模型基础上进行额外调优。结果如表[2](#S3.T2
    "表 2 ‣ 3.3 消融研究 ‣ 3 实验 ‣ 再见！LLM驱动的长期对话个性化代理")所示。
- en: The results clearly demonstrate that all modules positively influence long-term
    dialogue capabilities, with the event memory module contributing the most significant
    improvements. It is worth noting that although all modules experience a performance
    decline as the number of sessions increased, the addition of the event memory
    module results in more stable performance compared to the use of user or agent
    personas. This highlights the critical role of event memory in maintaining coherence
    across multiple sessions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 结果清楚地表明，所有模块都对长期对话能力产生了积极影响，其中事件记忆模块带来了最显著的改进。值得注意的是，尽管所有模块在会话次数增加时性能有所下降，但事件记忆模块的加入相比于用户或代理人角色的使用，带来了更稳定的性能。这突显了事件记忆在保持多次会话一致性中的关键作用。
- en: 'Table 2: Ablation study results of LD-Agent on MSC. The experiments are conducted
    on tuned ChatGLM. Baseline denotes the model tuned with context of current session.
    “+ module name” indicates the model tuned solely with context and corresponding
    module. “Full” indicates the model tuned with all modules.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：LD-Agent 在 MSC 上的消融研究结果。实验在调优后的 ChatGLM 上进行。基线表示使用当前会话的上下文调优的模型。 “+ 模块名”表示仅使用上下文和相应模块调优的模型。
    “完整”表示使用所有模块调优的模型。
- en: '|  |  | Session 2 | Session 3 | Session 4 | Session 5 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 会话 2 | 会话 3 | 会话 4 | 会话 5 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|  | Model | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2
    | BL-3 | R-L |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  | 模型 | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2
    | BL-3 | R-L |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- |'
- en: '|  | Baseline | 5.48 | 1.59 | 17.65 | 6.12 | 1.78 | 17.91 | 6.14 | 1.63 | 17.78
    | 6.16 | 1.69 | 17.65 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | 基线 | 5.48 | 1.59 | 17.65 | 6.12 | 1.78 | 17.91 | 6.14 | 1.63 | 17.78 |
    6.16 | 1.69 | 17.65 |'
- en: '|  | + Mem | 7.57 | 2.49 | 19.50 | 7.70 | 2.48 | 19.46 | 7.53 | 2.31 | 19.26
    | 7.56 | 2.33 | 19.03 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | + 记忆 | 7.57 | 2.49 | 19.50 | 7.70 | 2.48 | 19.46 | 7.53 | 2.31 | 19.26
    | 7.56 | 2.33 | 19.03 |'
- en: '|  | + Persona [user] | 7.54 | 2.57 | 19.68 | 7.51 | 2.38 | 19.39 | 7.30 |
    2.09 | 18.80 | 7.08 | 2.27 | 18.79 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  | + 角色 [用户] | 7.54 | 2.57 | 19.68 | 7.51 | 2.38 | 19.39 | 7.30 | 2.09 |
    18.80 | 7.08 | 2.27 | 18.79 |'
- en: '|  | + Persona [agent] | 7.00 | 2.27 | 18.70 | 7.23 | 2.33 | 18.75 | 7.32 |
    2.18 | 18.47 | 7.13 | 2.36 | 18.48 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | + 角色 [代理] | 7.00 | 2.27 | 18.70 | 7.23 | 2.33 | 18.75 | 7.32 | 2.18 |
    18.47 | 7.13 | 2.36 | 18.48 |'
- en: '|  | Full | 10.70 | 5.63 | 23.31 | 10.03 | 5.12 | 21.55 | 8.96 | 4.01 | 19.94
    | 9.07 | 4.06 | 20.19 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | 完整 | 10.70 | 5.63 | 23.31 | 10.03 | 5.12 | 21.55 | 8.96 | 4.01 | 19.94
    | 9.07 | 4.06 | 20.19 |'
- en: 'Table 3: The effect of different extractors on persona extraction and response
    generation on MSC.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：不同提取器对 MSC 上的角色提取和响应生成的影响。
- en: '|  |  | Extraction | Generation |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 提取 | 生成 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | Extractor | BL-2 | BL-3 | R-L | ACC | BL-2 | BL-3 | R-L |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|  | 提取器 | BL-2 | BL-3 | R-L | ACC | BL-2 | BL-3 | R-L |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '|  | CoT | 5.05 | 2.69 | 25.54 | 61.6 | 5.82 | 1.69 | 16.95 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '|  | CoT | 5.05 | 2.69 | 25.54 | 61.6 | 5.82 | 1.69 | 16.95 |'
- en: '|  | Tuning | 8.31 | 5.65 | 43.70 | 77.8 | 6.12 | 1.75 | 17.03 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|  | 调优 | 8.31 | 5.65 | 43.70 | 77.8 | 6.12 | 1.75 | 17.03 |'
- en: 3.4 Persona Extraction Analysis
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 角色提取分析
- en: 'To explore the effect of different persona extractor, including zero-shot ChatGLM
    with Chain-of-Thought [[32](#bib.bib32)] and ChatGLM tuned on the persona extraction
    dataset collected from MSC training set, we carry out comparison experiments on
    two perspectives: Persona Extraction Accuracy and Impact to Response Generation.
    The results are shown in Table [3](#S3.T3 "Table 3 ‣ 3.3 Ablation Studies ‣ 3
    Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue").'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探究不同角色提取器的效果，包括零样本 ChatGLM 与 Chain-of-Thought [[32](#bib.bib32)] 以及在从 MSC
    训练集收集的角色提取数据集上调优的 ChatGLM，我们从两个角度进行比较实验：角色提取准确率和对响应生成的影响。结果见表 [3](#S3.T3 "表 3
    ‣ 3.3 消融研究 ‣ 3 实验 ‣ 再见！基于 LLM 的长期对话个性化代理")。
- en: Extraction Accuracy.
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 提取准确率。
- en: We evaluate the extraction accuracy on the persona extraction dataset collected
    from MSC testing set, through BLEU-2/3, R-L, and ACC. ACC is to assess the classification
    accuracy of dividing utterance into “with personas” or “without personas”. The
    results of extraction in Table [3](#S3.T3 "Table 3 ‣ 3.3 Ablation Studies ‣ 3
    Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")
    show that the extractor after tuning performs better than CoT ChatGLM on all metrics.
    The higher BLEU and R-L indicates the tuned extractor performs better capability
    to extract personas from an utterance, while higher ACC indicates a stronger capability
    to distinguish whether personas are contained in an utterance.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过BLEU-2/3、R-L和ACC评估从MSC测试集收集的角色提取数据集上的提取准确性。ACC用于评估将发言分类为“包含角色”或“未包含角色”的准确性。表中[3](#S3.T3
    "Table 3 ‣ 3.3 Ablation Studies ‣ 3 Experiments ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue")的提取结果显示，调优后的提取器在所有指标上都优于CoT ChatGLM。更高的BLEU和R-L表示调优提取器在从发言中提取角色方面具有更好的能力，而更高的ACC表示在区分发言中是否包含角色方面更强的能力。
- en: Impact to Response Generation.
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对响应生成的影响。
- en: In addition, to explore the effect of different persona extractor to the final
    response generation, we conduct experiments on MSC by comparing the results of
    zero-shot ChatGLM[LDA] with personas extracted by CoT and tuned extractor, respectively.
    The Generation results in Table [3](#S3.T3 "Table 3 ‣ 3.3 Ablation Studies ‣ 3
    Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")
    indicate the tuned extractor performs better in most sessions. As the number of
    sessions increases, the gap is also constantly expanding, demonstrating tuned
    extractor is more suitable for long-term dialogue.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了探讨不同**角色提取器**对最终响应生成的影响，我们通过比较`零-shot ChatGLM[LDA]`与由CoT和调优提取器分别提取的角色，进行MSC实验。表中[3](#S3.T3
    "Table 3 ‣ 3.3 Ablation Studies ‣ 3 Experiments ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue")的生成结果表明，调优提取器在大多数会话中表现更好。随着会话数量的增加，差距也不断扩大，证明调优提取器更适合长期对话。
- en: 3.5 Human Evaluation
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 人工评估
- en: To further explore the performance of LD-Agent in real-life conversation, we
    adopt human evaluation to separately evaluate the ability of memory recall and
    response generation with the results on Figure [3](#S3.F3 "Figure 3 ‣ Retrieval
    Mechanism Analysis. ‣ 3.5 Human Evaluation ‣ 3 Experiments ‣ Hello Again! LLM-powered
    Personalized Agent for Long-term Dialogue").
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步探讨LD-Agent在真实对话中的表现，我们采用人工评估分别评估记忆回忆能力和响应生成能力，结果如图[3](#S3.F3 "Figure 3
    ‣ Retrieval Mechanism Analysis. ‣ 3.5 Human Evaluation ‣ 3 Experiments ‣ Hello
    Again! LLM-powered Personalized Agent for Long-term Dialogue")所示。
- en: Retrieval Mechanism Analysis.
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 检索机制分析。
- en: Retrieval mechanism plays a crucial role for event memory accurately utilized
    in long-term dialogue. To evaluate the superiority of topic-based retrieval approach
    than direct semantic retrieval commonly used in previous methods, we conduct an
    event memory human evaluation. In the beginning, we initialize a conversation
    using first four sessions and store event memories for each session into long-term
    memory bank. In the last session, we let evaluators select relevant memories from
    long-term memory bank for each utterance as the ground truths. Consequently, we
    separately utilize direct semantic retrieval and topic-based retrieval to search
    relevant memories for each utterance, and calculate the accuracy and recall based
    on human annotations. The results are shown in Figure [3a](#S3.F3.sf1 "In Figure
    3 ‣ Retrieval Mechanism Analysis. ‣ 3.5 Human Evaluation ‣ 3 Experiments ‣ Hello
    Again! LLM-powered Personalized Agent for Long-term Dialogue"). The topic-based
    retrieval outperforms direct semantic retrieval with significant gap on both ACC
    and Recall, proving that our retrieval method accurately retrieves relevant memories.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 检索机制在长期对话中准确利用事件记忆方面发挥了关键作用。为了评估基于主题的检索方法相较于以往方法中常用的直接语义检索的优越性，我们进行了一次事件记忆人工评估。首先，我们使用前四个会话初始化对话，并将每个会话的事件记忆存储到长期记忆库中。在最后一次会话中，我们让评估人员为每个发言从长期记忆库中选择相关记忆作为真实情况。随后，我们分别使用直接语义检索和基于主题的检索来搜索每个发言的相关记忆，并根据人工标注计算准确性和召回率。结果如图[3a](#S3.F3.sf1
    "In Figure 3 ‣ Retrieval Mechanism Analysis. ‣ 3.5 Human Evaluation ‣ 3 Experiments
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue")所示。基于主题的检索在ACC和召回率上都显著优于直接语义检索，证明了我们的检索方法准确地检索了相关记忆。
- en: '![Refer to caption](img/c7de0851b675533de1f357ce9172df0c.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c7de0851b675533de1f357ce9172df0c.png)'
- en: (a) Comparison of Different Retrieval Mechanism
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 不同检索机制的比较
- en: '![Refer to caption](img/1e3bb367dc989bdee3249b81e858ac66.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1e3bb367dc989bdee3249b81e858ac66.png)'
- en: (b) Comparison of Response Generation
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 回应生成的比较
- en: 'Figure 3: The results of human evaluation on retrieval mechanism and response
    generation.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：人类评价检索机制和回应生成的结果。
- en: Response Generation Analysis.
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 回应生成分析。
- en: 'To further validate the superiority of LD-Agent in long-term open-domain dialogue
    tasks, we organize multiple multi-session human-bot conversations on ChatGLM with
    LD-Agent and w/o LD-Agent. We first initialize a predefined dialogue as the first
    session for all chatbots. Subsequently, we employ some human evaluators to chat
    with each chatbot with a time interval from first session. The interactions are
    evaluated on three aspects: coherence, fluency and engagingness. The results in
    Figure [3b](#S3.F3.sf2 "In Figure 3 ‣ Retrieval Mechanism Analysis. ‣ 3.5 Human
    Evaluation ‣ 3 Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue") demonstrate the advantages of LD-Agent in long-term real-life dialogue
    scenarios.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步验证LD-Agent在长期开放领域对话任务中的优越性，我们在ChatGLM上组织了多轮人机对话，其中包括使用LD-Agent和不使用LD-Agent的对话。我们首先将预定义对话初始化为所有聊天机器人的第一轮对话。随后，我们让一些人类评估者与每个聊天机器人进行对话，时间间隔从第一轮对话开始。互动从三个方面进行评估：连贯性、流畅性和吸引力。图 [3b](#S3.F3.sf2
    "在图3中 ‣ 检索机制分析 ‣ 3.5 人类评估 ‣ 3 实验 ‣ 再见！LLM驱动的个性化长期对话代理")展示了LD-Agent在长期真实对话场景中的优势。
- en: 'Table 4: The results of cross-domain evaluation on MSC and CC. “Zero-shot”
    indicates the ChatGLM without tuning. “CC-tuning” indicates the ChatGLM tuned
    on CC dataset. “MSC-tuning” indicates the ChatGLM tuned on MSC dataset.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：对MSC和CC的跨领域评估结果。“Zero-shot”表示未调整的ChatGLM。“CC-tuning”表示在CC数据集上调整的ChatGLM。“MSC-tuning”表示在MSC数据集上调整的ChatGLM。
- en: '|  | Session 2 | Session 3 | Session 4 | Session 5 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | Session 2 | Session 3 | Session 4 | Session 5 |'
- en: '| Model | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2
    | BL-3 | R-L |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Model | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2 | BL-3 | R-L | BL-2
    | BL-3 | R-L |'
- en: '| MSC |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| MSC |'
- en: '| Zero-shot | 5.44 | 1.49 | 16.76 | 5.59 | 1.49 | 16.47 | 5.63 | 1.33 | 16.35
    | 5.92 | 1.45 | 16.63 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot | 5.44 | 1.49 | 16.76 | 5.59 | 1.49 | 16.47 | 5.63 | 1.33 | 16.35
    | 5.92 | 1.45 | 16.63 |'
- en: '| Zero-shot[LDA] | 5.74 | 1.73 | 17.21 | 6.05 | 1.73 | 16.97 | 6.09 | 1.59
    | 16.76 | 6.60 | 1.94 | 17.18 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot[LDA] | 5.74 | 1.73 | 17.21 | 6.05 | 1.73 | 16.97 | 6.09 | 1.59
    | 16.76 | 6.60 | 1.94 | 17.18 |'
- en: '| CC-tuning | 5.81 | 1.74 | 18.79 | 6.08 | 1.83 | 18.58 | 5.96 | 1.74 | 18.31
    | 5.95 | 1.68 | 18.23 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| CC-tuning | 5.81 | 1.74 | 18.79 | 6.08 | 1.83 | 18.58 | 5.96 | 1.74 | 18.31
    | 5.95 | 1.68 | 18.23 |'
- en: '| CC-tuning[LDA] | 7.86 | 3.63 | 21.00 | 7.46 | 3.16 | 20.00 | 7.15 | 2.87
    | 19.53 | 7.12 | 2.64 | 19.30 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| CC-tuning[LDA] | 7.86 | 3.63 | 21.00 | 7.46 | 3.16 | 20.00 | 7.15 | 2.87
    | 19.53 | 7.12 | 2.64 | 19.30 |'
- en: '| MSC-tuning | 5.48 | 1.59 | 17.65 | 6.12 | 1.78 | 17.91 | 6.14 | 1.63 | 17.78
    | 6.16 | 1.69 | 17.65 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| MSC-tuning | 5.48 | 1.59 | 17.65 | 6.12 | 1.78 | 17.91 | 6.14 | 1.63 | 17.78
    | 6.16 | 1.69 | 17.65 |'
- en: '| MSC-tuning[LDA] | 10.70 | 5.63 | 23.31 | 10.03 | 5.12 | 21.55 | 9.07 | 4.06
    | 20.19 | 8.96 | 4.01 | 19.94 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| MSC-tuning[LDA] | 10.70 | 5.63 | 23.31 | 10.03 | 5.12 | 21.55 | 9.07 | 4.06
    | 20.19 | 8.96 | 4.01 | 19.94 |'
- en: '| CC |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| CC |'
- en: '| Zero-shot | 9.53 | 4.82 | 22.76 | 9.22 | 4.43 | 22.18 | 9.15 | 4.48 | 22.18
    | 8.99 | 4.43 | 22.10 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot | 9.53 | 4.82 | 22.76 | 9.22 | 4.43 | 22.18 | 9.15 | 4.48 | 22.18
    | 8.99 | 4.43 | 22.10 |'
- en: '| Zero-shot[LDA] | 8.94 | 4.44 | 21.54 | 8.34 | 4.03 | 21.00 | 8.28 | 3.82
    | 20.67 | 8.12 | 3.81 | 20.54 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Zero-shot[LDA] | 8.94 | 4.44 | 21.54 | 8.34 | 4.03 | 21.00 | 8.28 | 3.82
    | 20.67 | 8.12 | 3.81 | 20.54 |'
- en: '| MSC-tuning | 8.37 | 3.88 | 22.93 | 8.49 | 3.99 | 22.96 | 7.97 | 3.75 | 22.15
    | 7.60 | 3.70 | 21.87 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| MSC-tuning | 8.37 | 3.88 | 22.93 | 8.49 | 3.99 | 22.96 | 7.97 | 3.75 | 22.15
    | 7.60 | 3.70 | 21.87 |'
- en: '| MSC-tuning[LDA] | 21.71 | 15.42 | 34.97 | 20.87 | 14.74 | 34.01 | 19.57 |
    13.51 | 32.72 | 18.59 | 12.80 | 31.68 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| MSC-tuning[LDA] | 21.71 | 15.42 | 34.97 | 20.87 | 14.74 | 34.01 | 19.57 |
    13.51 | 32.72 | 18.59 | 12.80 | 31.68 |'
- en: '| CC-tuning | 15.89 | 9.90 | 30.59 | 15.97 | 10.06 | 30.27 | 16.10 | 10.31
    | 30.54 | 15.10 | 9.34 | 29.43 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| CC-tuning | 15.89 | 9.90 | 30.59 | 15.97 | 10.06 | 30.27 | 16.10 | 10.31
    | 30.54 | 15.10 | 9.34 | 29.43 |'
- en: '| CC-tuning[LDA] | 25.69 | 19.53 | 39.67 | 25.93 | 19.72 | 39.15 | 25.82 |
    19.40 | 39.05 | 24.26 | 18.16 | 37.61 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| CC-tuning[LDA] | 25.69 | 19.53 | 39.67 | 25.93 | 19.72 | 39.15 | 25.82 |
    19.40 | 39.05 | 24.26 | 18.16 | 37.61 |'
- en: 3.6 Generality Analysis
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 普遍性分析
- en: 'We further explore the generality of LD-Agent from two perspectives: cross-domain
    and cross-task capability.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从两个方面进一步探讨了LD-Agent的普遍性：跨领域和跨任务能力。
- en: Cross-domain Results
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 跨领域结果
- en: The cross-domain capability is important for open-domain dialogue task. Poor
    cross-domain capability, easily occuring on models tuned with specific datasets,
    largely limits its practicality in real-world environments. To explore the practicality
    of our tuned model in real-world, we conducts two cross-evaluation experiments
    on MSC and CC, two long-term dialogue datasets with significant domain gap due
    to the difference of collecting approaches, including manually annotating and
    LLM generation. Specifically, we first tune ChatGLM on CC, and test it on MSC.
    Then we tune ChatGLM on MSC, and test it on CC. The results are reported in Table [4](#S3.T4
    "Table 4 ‣ Response Generation Analysis. ‣ 3.5 Human Evaluation ‣ 3 Experiments
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue"). We can
    observe that the models tuned on one dataset still performs well on the other
    dataset, only with a slight performance decrease than the models tuned on the
    same dataset. Besides, cross-domain tuned model always outperforms zero-shot model
    with a large performance gap. These experiments fully demonstrate the powerful
    cross-domain capability and strong practical potential of our method.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 跨领域能力对开放领域对话任务非常重要。跨领域能力差，通常发生在使用特定数据集调整的模型上，这在实际环境中大大限制了其实用性。为了探讨我们调整模型在现实世界中的实用性，我们在
    MSC 和 CC 两个长期对话数据集上进行了两项交叉评估实验，这两个数据集由于收集方法的不同（包括人工标注和 LLM 生成）存在显著的领域差距。具体来说，我们首先在
    CC 上调整 ChatGLM，然后在 MSC 上测试。接着我们在 MSC 上调整 ChatGLM，然后在 CC 上测试。结果见表 [4](#S3.T4 "Table
    4 ‣ Response Generation Analysis. ‣ 3.5 Human Evaluation ‣ 3 Experiments ‣ Hello
    Again! LLM-powered Personalized Agent for Long-term Dialogue")。我们可以观察到，在一个数据集上调整的模型在另一个数据集上的表现仍然很好，只是比在相同数据集上调整的模型略有下降。此外，跨领域调整的模型总是显著优于零样本模型。这些实验充分展示了我们方法强大的跨领域能力和强大的实际潜力。
- en: Cross-task Results
  id: totrans-170
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 跨任务结果
- en: The other capability worth exploring is the transferability of LD-Agent to different
    dialogue tasks. We explore the effectiveness of our method on multiparty dialogue,
    a task requires playing multiple roles simultaneously. We conduct our experiments
    on Ubuntu IRC dataset [[27](#bib.bib27)], a commonly used multiparty dialogue
    dataset. where our backbone adopts BART [[36](#bib.bib36)]. We compare our method
    with some previous multiparty dialogue methods, including GPT-2 [[37](#bib.bib37)],
    GSN [[27](#bib.bib27)], HeterMPC[BART] [[38](#bib.bib38)], and BART tuned without
    prompt. The results are reported at Table [5](#S3.T5 "Table 5 ‣ Cross-task Results
    ‣ 3.6 Generality Analysis ‣ 3 Experiments ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue"). It can be seen that BART tuned with LD-Agent obtained
    the state-of-the-art performance in most metrics, outperforming previous multiparty
    dialogue approach HeterMPC[BART], which also employs BART as backbone. This well
    proves the powerful task tranferability of LD-Agent.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得探索的能力是 LD-Agent 在不同对话任务中的迁移性。我们探索了我们方法在多方对话中的有效性，这是一项需要同时扮演多个角色的任务。我们在常用的多方对话数据集
    Ubuntu IRC 数据集 [[27](#bib.bib27)] 上进行了实验，我们的骨干采用 BART [[36](#bib.bib36)]。我们将我们的方法与一些以前的多方对话方法进行了比较，包括
    GPT-2 [[37](#bib.bib37)]、GSN [[27](#bib.bib27)]、HeterMPC[BART] [[38](#bib.bib38)]
    和没有提示的 BART 调整模型。结果见表 [5](#S3.T5 "Table 5 ‣ Cross-task Results ‣ 3.6 Generality
    Analysis ‣ 3 Experiments ‣ Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue")。可以看出，使用 LD-Agent 调整的 BART 在大多数指标中获得了最先进的性能，超越了以前的多方对话方法 HeterMPC[BART]，后者也使用
    BART 作为骨干。这很好地证明了 LD-Agent 强大的任务迁移能力。
- en: 'Table 5: Multi-party performance on the Ubuntu IRC benchmark'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：Ubuntu IRC 基准上的多方性能
- en: '| Model | BL-1 | BL-2 | BL-3 | BL-4 | MET | R-L |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | BL-1 | BL-2 | BL-3 | BL-4 | MET | R-L |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-2 [[37](#bib.bib37)] | 10.37 | 3.60 | 1.66 | 0.93 | 4.01 | 9.53 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| GPT-2 [[37](#bib.bib37)] | 10.37 | 3.60 | 1.66 | 0.93 | 4.01 | 9.53 |'
- en: '| GSN [[27](#bib.bib27)] | 10.23 | 3.57 | 1.70 | 0.97 | 4.10 | 9.91 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| GSN [[27](#bib.bib27)] | 10.23 | 3.57 | 1.70 | 0.97 | 4.10 | 9.91 |'
- en: '| HeterMPC[BART] [[38](#bib.bib38)] | 12.26 | 4.80 | 2.42 | 1.49 | 4.94 | 11.20
    |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| HeterMPC[BART] [[38](#bib.bib38)] | 12.26 | 4.80 | 2.42 | 1.49 | 4.94 | 11.20
    |'
- en: '| BART [[36](#bib.bib36)] | 11.25 | 4.02 | 1.78 | 0.95 | 4.46 | 9.90 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| BART [[36](#bib.bib36)] | 11.25 | 4.02 | 1.78 | 0.95 | 4.46 | 9.90 |'
- en: '| BART[LDA] | 14.40 | 4.92 | 2.07 | 1.00 | 5.30 | 12.28 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| BART[LDA] | 14.40 | 4.92 | 2.07 | 1.00 | 5.30 | 12.28 |'
- en: 4 Conclusion
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结论
- en: In this work, we delved into the long-term open-domain dialogue agent to satisfy
    real-life chatbot demands of long-term companionship and personalized interactions.
    We introduced a model-agnostic long-term dialogue agent framework, LD-Agent, which
    comprehensively considers both historical events and user-agent personas to support
    coherent and consistent conversation. Our framework was capably decomposed into
    three learnable modules, significantly improving the adaptability and transferability.
    We conducted extensive experiments, well demonstrated the strong capability of
    LD-Agent to handle long-term dialogue tasks. The practicality of LD-Agent was
    also demonstrated through extensive experiments across multiple benchmarks, diverse
    models, and various tasks. Limited by the length of existing long-term dialogue
    datasets, the capability of LD-Agent in longer conversation scenarios is valuable
    to be explored.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们深入探讨了长期开放领域对话代理，以满足实际聊天机器人对长期陪伴和个性化互动的需求。我们引入了一个与模型无关的长期对话代理框架LD-Agent，它全面考虑了历史事件和用户-代理角色，以支持连贯且一致的对话。我们的框架被有效地分解为三个可学习的模块，显著提升了适应性和可迁移性。我们进行了广泛的实验，充分展示了LD-Agent在处理长期对话任务中的强大能力。LD-Agent的实用性也通过在多个基准、不同模型和各种任务中的广泛实验得到了验证。由于现有长期对话数据集的长度限制，LD-Agent在更长对话场景中的能力仍有待探索。
- en: References
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Xu et al. [2022a] Jing Xu, Arthur Szlam, and Jason Weston. Beyond goldfish
    memory: Long-term open-domain conversation. In *ACL*, pages 5180–5197, 2022a.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. [2022a] Jing Xu, Arthur Szlam, and Jason Weston. 超越金鱼记忆：长期开放领域对话。在*ACL*，页5180–5197，2022年。
- en: Zhang et al. [2022] Tong Zhang, Yong Liu, Boyang Li, Zhiwei Zeng, Pengwei Wang,
    Yuan You, Chunyan Miao, and Lizhen Cui. History-aware hierarchical transformer
    for multi-session open-domain dialogue system. In *EMNLP Findings*, pages 3395–3407,
    2022.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2022] Tong Zhang, Yong Liu, Boyang Li, Zhiwei Zeng, Pengwei Wang,
    Yuan You, Chunyan Miao, and Lizhen Cui. 历史感知分层变换器用于多会话开放领域对话系统。在*EMNLP Findings*，页3395–3407，2022年。
- en: Xu et al. [2022b] Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu,
    Haifeng Wang, and Shihang Wang. Long time no see! open-domain conversation with
    long-term persona memory. In *ACL Findings*, pages 2639–2650, 2022b.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. [2022b] Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu,
    Haifeng Wang, and Shihang Wang. 好久不见！具有长期角色记忆的开放领域对话。在*ACL Findings*，页2639–2650，2022年。
- en: 'Li et al. [2017] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and
    Shuzi Niu. Dailydialog: A manually labelled multi-turn dialogue dataset. In *IJCNLP*,
    pages 986–995, 2017.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2017] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and
    Shuzi Niu. Dailydialog：一个手工标注的多轮对话数据集。在*IJCNLP*，页986–995，2017年。
- en: 'Zhang et al. [2018] Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam,
    Douwe Kiela, and Jason Weston. Personalizing dialogue agents: I have a dog, do
    you have pets too? In *ACL*, pages 2204–2213, 2018.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2018] Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam,
    Douwe Kiela, and Jason Weston. 个性化对话代理：我有一只狗，你也有宠物吗？在*ACL*，页2204–2213，2018年。
- en: 'Rashkin et al. [2019] Hannah Rashkin, Eric Michael Smith, Margaret Li, and
    Y-Lan Boureau. Towards empathetic open-domain conversation models: A new benchmark
    and dataset. In *ACL*, pages 5370–5381, 2019.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rashkin et al. [2019] Hannah Rashkin, Eric Michael Smith, Margaret Li, and Y-Lan
    Boureau. 朝着富有同情心的开放领域对话模型：新的基准和数据集。在*ACL*，页5370–5381，2019年。
- en: 'Jang et al. [2023] Jihyoung Jang, Minseong Boo, and Hyounghun Kim. Conversation
    chronicles: Towards diverse temporal and relational dynamics in multi-session
    conversations. In *EMNLP*, pages 13584–13606, 2023.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jang et al. [2023] Jihyoung Jang, Minseong Boo, and Hyounghun Kim. 对话纪事：朝着多会话中的多样时间和关系动态前进。在*EMNLP*，页13584–13606，2023年。
- en: Zhang et al. [2023a] Qiang Zhang, Jason Naradowsky, and Yusuke Miyao. Mind the
    gap between conversations for improved long-term dialogue generation. In *EMNLP
    Findings*, pages 10735–10762, 2023a.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2023a] Qiang Zhang, Jason Naradowsky, and Yusuke Miyao. 注意对话之间的差距，以改进长期对话生成。在*EMNLP
    Findings*，页10735–10762，2023年。
- en: Gu et al. [2019] Jia-Chen Gu, Zhen-Hua Ling, Xiaodan Zhu, and Quan Liu. Dually
    interactive matching network for personalized response selection in retrieval-based
    chatbots. In *EMNLP-IJCNLP*, pages 1845–1854, 2019.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu et al. [2019] Jia-Chen Gu, Zhen-Hua Ling, Xiaodan Zhu, and Quan Liu. 用于个性化响应选择的双重交互匹配网络。在*EMNLP-IJCNLP*，页1845–1854，2019年。
- en: Cao et al. [2022] Yu Cao, Wei Bi, Meng Fang, Shuming Shi, and Dacheng Tao. A
    model-agnostic data manipulation method for persona-based dialogue generation.
    In *ACL*, pages 7984–8002, 2022.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao et al. [2022] Yu Cao, Wei Bi, Meng Fang, Shuming Shi, and Dacheng Tao. 一种与模型无关的数据操作方法，用于基于角色的对话生成。在*ACL*，页7984–8002，2022年。
- en: 'Zhao et al. [2023] Kang Zhao, Wei Liu, Jian Luan, Minglei Gao, Li Qian, Hanlin
    Teng, and Bin Wang. Unimc: A unified framework for long-term memory conversation
    via relevance representation learning. *CoRR*, abs/2306.10543, 2023.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao et al. [2023] Kang Zhao, Wei Liu, Jian Luan, Minglei Gao, Li Qian, Hanlin
    Teng, 和 Bin Wang. Unimc: 通过相关性表示学习实现长期记忆对话的统一框架. *CoRR*，abs/2306.10543，2023年。'
- en: Chen et al. [2019] Xiuyi Chen, Jiaming Xu, and Bo Xu. A working memory model
    for task-oriented dialog response generation. In *ACL*, pages 2687–2693, 2019.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2019] Xiuyi Chen, Jiaming Xu, 和 Bo Xu. 用于任务导向对话回应生成的工作记忆模型. 发表在
    *ACL*，页码 2687–2693，2019年。
- en: Zhang et al. [2019] Zheng Zhang, Minlie Huang, Zhongzhou Zhao, Feng Ji, Haiqing
    Chen, and Xiaoyan Zhu. Memory-augmented dialogue management for task-oriented
    dialogue systems. *ACM Trans. Inf. Syst.*, 37(3):34:1–34:30, 2019.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2019] Zheng Zhang, Minlie Huang, Zhongzhou Zhao, Feng Ji, Haiqing
    Chen, 和 Xiaoyan Zhu. 任务导向对话系统的记忆增强对话管理. *ACM Trans. Inf. Syst.*，37(3):34:1–34:30，2019年。
- en: Chen et al. [2023a] Liang Chen, Hongru Wang, Yang Deng, Wai-Chung Kwan, Zezhong
    Wang, and Kam-Fai Wong. Towards robust personalized dialogue generation via order-insensitive
    representation regularization. In *ACL Findings*, pages 7337–7345, 2023a.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2023a] Liang Chen, Hongru Wang, Yang Deng, Wai-Chung Kwan, Zezhong
    Wang, 和 Kam-Fai Wong. 通过无序敏感表示正则化实现鲁棒的个性化对话生成. 发表在 *ACL Findings*，页码 7337–7345，2023a年。
- en: Wu et al. [2020] Bowen Wu, Mengyuan Li, Zongsheng Wang, Yifu Chen, Derek F.
    Wong, Qihang Feng, Junhong Huang, and Baoxun Wang. Guiding variational response
    generator to exploit persona. In *ACL*, pages 53–65, 2020.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. [2020] Bowen Wu, Mengyuan Li, Zongsheng Wang, Yifu Chen, Derek F.
    Wong, Qihang Feng, Junhong Huang, 和 Baoxun Wang. 引导变分回应生成器利用个性. 发表在 *ACL*，页码 53–65，2020年。
- en: 'Liu et al. [2020] Qian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou, Zixuan Chen,
    Bin Zhou, and Dongmei Zhang. You impress me: Dialogue generation via mutual persona
    perception. In *ACL*, pages 1417–1427, 2020.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2020] Qian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou, Zixuan Chen,
    Bin Zhou, 和 Dongmei Zhang. 你给我留下了深刻的印象：通过相互个性感知生成对话. 发表在 *ACL*，页码 1417–1427，2020年。
- en: 'Deng et al. [2023] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samual Stevens,
    Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the
    web. In *NeurIPS*, 2023.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng et al. [2023] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samual Stevens,
    Boshi Wang, Huan Sun, 和 Yu Su. Mind2web: 面向网络的通用代理. 发表在 *NeurIPS*，2023年。'
- en: 'Wang et al. [2023a] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied
    agent with large language models. *CoRR*, abs/2305.16291, 2023a.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. [2023a] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, 和 Anima Anandkumar. Voyager: 基于大语言模型的开放式具身代理. *CoRR*，abs/2305.16291，2023a年。'
- en: Qian et al. [2023] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. Communicative agents for software development.
    *CoRR*, abs/2307.07924, 2023.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian et al. [2023] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, 和 Maosong Sun. 软件开发中的沟通代理. *CoRR*，abs/2307.07924，2023年。
- en: 'Park et al. [2023] Joon Sung Park, Joseph C. O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive
    simulacra of human behavior. In *UIST*, pages 2:1–2:22, 2023.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park et al. [2023] Joon Sung Park, Joseph C. O’Brien, Carrie Jun Cai, Meredith
    Ringel Morris, Percy Liang, 和 Michael S. Bernstein. 生成代理：人类行为的互动仿真. 发表在 *UIST*，页码
    2:1–2:22，2023年。
- en: Zhang et al. [2023b] An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng,
    Xiang Wang, and Tat-Seng Chua. On generative agents in recommendation. *CoRR*,
    abs/2310.10108, 2023b.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. [2023b] An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng,
    Xiang Wang, 和 Tat-Seng Chua. 关于推荐系统中的生成代理. *CoRR*，abs/2310.10108，2023b年。
- en: 'Cheng and Chin [2024] Junyan Cheng and Peter Chin. Sociodojo: Building lifelong
    analytical agents with real-world text and time series. In *ICLR*, 2024.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cheng and Chin [2024] Junyan Cheng 和 Peter Chin. Sociodojo: 利用现实世界文本和时间序列构建终身分析代理.
    发表在 *ICLR*，2024年。'
- en: 'Hua et al. [2023] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji,
    Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. War and peace (waragent): Large
    language model-based multi-agent simulation of world wars. *CoRR*, 2023.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hua et al. [2023] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji,
    Yingqiang Ge, Libby Hemphill, 和 Yongfeng Zhang. 战争与和平（waragent）：基于大语言模型的世界大战多代理模拟.
    *CoRR*，2023年。
- en: 'Xu et al. [2024] Ruoxi Xu, Yingfei Sun, Mengjie Ren, Shiguang Guo, Ruotong
    Pan, Hongyu Lin, Le Sun, and Xianpei Han. AI for social science and social science
    of AI: A survey. *CoRR*, abs/2401.11839, 2024.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. [2024] Ruoxi Xu, Yingfei Sun, Mengjie Ren, Shiguang Guo, Ruotong Pan,
    Hongyu Lin, Le Sun, 和 Xianpei Han. 社会科学中的人工智能与人工智能的社会科学：一项调查. *CoRR*，abs/2401.11839，2024年。
- en: 'Zeng et al. [2023] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    and Jie Tang. GLM-130B: an open bilingual pre-trained model. In *ICLR*, 2023.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng et al. [2023] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong,
    and Jie Tang. GLM-130B: 一种开放的双语预训练模型。发表于*ICLR*，2023年。'
- en: Roller et al. [2021] Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson,
    Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston.
    Recipes for building an open-domain chatbot. In *EACL*, pages 300–325, 2021.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roller et al. [2021] Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson,
    Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston.
    构建开放领域聊天机器人的食谱。发表于*EACL*，第300–325页，2021年。
- en: 'Hu et al. [2019] Wenpeng Hu, Zhangming Chan, Bing Liu, Dongyan Zhao, Jinwen
    Ma, and Rui Yan. GSN: A graph-structured network for multi-party dialogues. In
    *IJCAI*, pages 5010–5016, 2019.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu et al. [2019] Wenpeng Hu, Zhangming Chan, Bing Liu, Dongyan Zhao, Jinwen
    Ma, and Rui Yan. GSN: 一种用于多方对话的图结构网络。发表于*IJCAI*，第5010–5016页，2019年。'
- en: 'Wang et al. [2020] Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and
    Ming Zhou. Minilm: Deep self-attention distillation for task-agnostic compression
    of pre-trained transformers. In *NeurIPS*, 2020.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. [2020] Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and
    Ming Zhou. Minilm: 任务无关的预训练变换器深度自注意力蒸馏压缩。发表于*NeurIPS*，2020年。'
- en: 'Zhong et al. [2024] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin
    Wang. Memorybank: Enhancing large language models with long-term memory. In *AAAI*,
    pages 19724–19731, 2024.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhong et al. [2024] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin
    Wang. Memorybank: 通过长期记忆增强大语言模型。发表于*AAAI*，第19724–19731页，2024年。'
- en: Wei et al. [2022a] Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. Finetuned language models
    are zero-shot learners. In *ICLR*, 2022a.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. [2022a] Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams
    Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 微调语言模型是零样本学习者。发表于*ICLR*，2022年。
- en: 'Chen et al. [2021] Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang. Dialogsum:
    A real-life scenario dialogue summarization dataset. In *ACL-IJCNLP Findings*,
    volume ACL/IJCNLP 2021, pages 5062–5074, 2021.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. [2021] Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang. Dialogsum:
    一种真实场景对话摘要数据集。发表于*ACL-IJCNLP Findings*，第5062–5074页，2021年。'
- en: Wei et al. [2022b] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. Chain-of-thought prompting
    elicits reasoning in large language models. In *NeurIPS*, 2022b.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. [2022b] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 链式思维提示引发大语言模型的推理能力。发表于*NeurIPS*，2022年。
- en: 'Papineni et al. [2002] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. Bleu: a method for automatic evaluation of machine translation. In *ACL*,
    pages 311–318, 2002.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Papineni et al. [2002] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. Bleu: 一种自动评估机器翻译的方法。发表于*ACL*，第311–318页，2002年。'
- en: 'Lin [2004] Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries.
    In *ACL*, 2004.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin [2004] Chin-Yew Lin. Rouge: 一种自动评估摘要的工具包。发表于*ACL*，2004年。'
- en: 'Banerjee and Lavie [2005] Satanjeev Banerjee and Alon Lavie. METEOR: an automatic
    metric for MT evaluation with improved correlation with human judgments. In *ACL
    Workshop*, pages 65–72, 2005.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Banerjee and Lavie [2005] Satanjeev Banerjee and Alon Lavie. METEOR: 一种改进与人工评判相关性的机器翻译评估自动指标。发表于*ACL
    Workshop*，第65–72页，2005年。'
- en: 'Lewis et al. [2020] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART:
    denoising sequence-to-sequence pre-training for natural language generation, translation,
    and comprehension. In *ACL*, pages 7871–7880, 2020.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lewis et al. [2020] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART:
    序列到序列去噪预训练，用于自然语言生成、翻译和理解。发表于*ACL*，第7871–7880页，2020年。'
- en: '[37] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving
    language understanding by generative pre-training.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 通过生成预训练提高语言理解能力。'
- en: 'Gu et al. [2022] Jia-Chen Gu, Chao-Hong Tan, Chongyang Tao, Zhen-Hua Ling,
    Huang Hu, Xiubo Geng, and Daxin Jiang. Hetermpc: A heterogeneous graph neural
    network for response generation in multi-party conversations. In *ACL*, pages
    5086–5097, 2022.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gu et al. [2022] Jia-Chen Gu, Chao-Hong Tan, Chongyang Tao, Zhen-Hua Ling,
    Huang Hu, Xiubo Geng, and Daxin Jiang. Hetermpc: 一种用于多方对话的异构图神经网络。发表于*ACL*，第5086–5097页，2022年。'
- en: Wang et al. [2023b] Lanrui Wang, Jiangnan Li, Chenxu Yang, Zheng Lin, and Weiping
    Wang. Enhancing empathetic and emotion support dialogue generation with prophetic
    commonsense inference. *CoRR*, abs/2311.15316, 2023b.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. [2023b] 王兰瑞、李江南、杨晨旭、林正、王伟平。通过预言性常识推理增强共情与情感支持对话生成。*CoRR*，abs/2311.15316，2023b年。
- en: 'Wang et al. [2024] Hongru Wang, Wenyu Huang, Yang Deng, Rui Wang, Zezhong Wang,
    Yufei Wang, Fei Mi, Jeff Z. Pan, and Kam-Fai Wong. Unims-rag: A unified multi-source
    retrieval-augmented generation for personalized dialogue systems. *CoRR*, abs/2401.13256,
    2024.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. [2024] 王洪如、黄文宇、邓杨、王瑞、王泽中、王宇飞、米飞、潘杰夫、黄锦辉。Unims-rag: 一种用于个性化对话系统的统一多源检索增强生成方法。*CoRR*，abs/2401.13256，2024年。'
- en: 'Chen et al. [2023b] Siyuan Chen, Mengyue Wu, Kenny Q. Zhu, Kunyao Lan, Zhiling
    Zhang, and Lyuchun Cui. Llm-empowered chatbots for psychiatrist and patient simulation:
    Application and evaluation. *CoRR*, abs/2305.13614, 2023b.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. [2023b] 陈思源、吴梦悦、朱肯尼·Q、兰昆耀、张志凌、崔柳春。LLM赋能的聊天机器人用于精神科医生和患者模拟: 应用与评估。*CoRR*，abs/2305.13614，2023b年。'
- en: 'Chen et al. [2023c] Yirong Chen, Xiaofen Xing, Jingkai Lin, Huimin Zheng, Zhenyu
    Wang, Qi Liu, and Xiangmin Xu. Soulchat: Improving llms’ empathy, listening, and
    comfort abilities through fine-tuning with multi-turn empathy conversations. In
    *EMNLP Findings*, pages 1170–1183, 2023c.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. [2023c] 陈依容、邢晓芬、林靖凯、郑惠敏、王振宇、刘琦、徐向敏。Soulchat: 通过多轮共情对话微调提升LLMs的共情、倾听和安慰能力。发表于*EMNLP
    Findings*，第1170–1183页，2023c年。'
- en: Deng et al. [2022] Yang Deng, Yaliang Li, Wenxuan Zhang, Bolin Ding, and Wai
    Lam. Toward personalized answer generation in e-commerce via multi-perspective
    preference modeling. *ACM Trans. Inf. Syst.*, 40(4):87:1–87:28, 2022.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. [2022] 邓杨、李亚亮、张文轩、丁博林、赖岚。通过多视角偏好建模实现个性化答案生成。*ACM Trans. Inf. Syst.*，40(4):87:1–87:28，2022年。
- en: Dillion et al. [2023] Danica Dillion, Niket Tandon, Yuling Gu, and Kurt Gray.
    Can ai language models replace human participants? *Trends in Cognitive Sciences*,
    2023.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dillion et al. [2023] 达尼卡·迪伦、尼凯特·坦登、顾宇凌、柯特·格雷。AI语言模型能替代人类参与者吗？*Trends in Cognitive
    Sciences*，2023年。
- en: 'Shaikh et al. [2023] Omar Shaikh, Valentino Chai, Michele J. Gelfand, Diyi
    Yang, and Michael S. Bernstein. Rehearsal: Simulating conflict to teach conflict
    resolution. *CoRR*, abs/2309.12309, 2023.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shaikh et al. [2023] 沙伊赫、蔡瓦伦蒂诺、米歇尔·J·戈尔法、杨笛仪、迈克尔·S·伯恩斯坦。Rehearsal: 模拟冲突以教授冲突解决。*CoRR*，abs/2309.12309，2023年。'
- en: 'Gao et al. [2023] Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua
    Piao, Huandong Wang, Depeng Jin, and Yong Li. S${}^{\mbox{3}}$: Social-network
    simulation system with large language model-empowered agents. *CoRR*, abs/2307.14984,
    2023.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao et al. [2023] 陈高、兰晓冲、陆志宏、毛金珠、焦静华、王环东、金德鹏、李勇。S${}^{\mbox{3}}$: 具有大型语言模型赋能代理的社交网络仿真系统。*CoRR*，abs/2307.14984，2023年。'
- en: 'Huang et al. [2023] Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian,
    and Xing Xie. Recommender AI agent: Integrating large language models for interactive
    recommendations. *CoRR*, abs/2308.16505, 2023.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang et al. [2023] 黄旭、连剑勋、雷雨轩、姚静、连德富、谢兴。推荐系统AI代理: 将大型语言模型集成用于互动推荐。*CoRR*，abs/2308.16505，2023年。'
- en: 'Shao et al. [2023] Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. Character-llm:
    A trainable agent for role-playing. In *EMNLP*, pages 13153–13187, 2023.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shao et al. [2023] 邵云凡、李林阳、戴俊琦、邱熙鹏。Character-llm: 一种可训练的角色扮演代理。发表于*EMNLP*，第13153–13187页，2023年。'
- en: 'Zhou et al. [2023] Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song,
    Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, Sahand Sabour,
    Xiaohan Zhang, Wenjing Hou, Yijia Zhang, Yuxiao Dong, Jie Tang, and Minlie Huang.
    Characterglm: Customizing chinese conversational AI characters with large language
    models. *CoRR*, abs/2311.16832, 2023.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou et al. [2023] 周金峰、陈壮、万大珍、温博思、宋怡、余吉凡、黄永康、彭丽彪、杨家铭、肖夕尧、萨汉德·萨布尔、张晓寒、侯文静、张怡佳、董宇霄、唐洁、黄敏礼。Characterglm:
    用大型语言模型定制中文对话AI角色。*CoRR*，abs/2311.16832，2023年。'
- en: 'Wang et al. [2023c] Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu,
    Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, Zhaoxiang
    Zhang, Wanli Ouyang, Ke Xu, Wenhu Chen, Jie Fu, and Junran Peng. Rolellm: Benchmarking,
    eliciting, and enhancing role-playing abilities of large language models. *CoRR*,
    abs/2310.00746, 2023c.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. [2023c] 王泽坤、彭中华、阙浩然、刘佳恒、周旺春、吴宇涵、郭洪成、甘瑞彤、倪泽豪、张曼、张兆祥、欧阳万里、徐克、陈文辉、傅杰、彭俊然。Rolellm:
    大型语言模型的角色扮演能力基准测试、激发与提升。*CoRR*，abs/2310.00746，2023c年。'
- en: 'Kingma and Ba [2015] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic
    optimization. In Yoshua Bengio and Yann LeCun, editors, *ICLR*, 2015.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Ba [2015] Diederik P. Kingma 和 Jimmy Ba. Adam：一种随机优化方法。在 Yoshua Bengio
    和 Yann LeCun 编者，*ICLR*，2015。
- en: Appendix
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: 'In this Appendix, we discuss the following topics: (1): We elaborate on some
    related work about long-term open-domain dialogue and LLM-based autonomous agent
    in Appendix. [A](#A1 "Appendix A Related Work ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue"). (2): We visualize responses of original ChatGLM
    and LD-Agent to further demonstrate the ability of LD-Agent in long-term dialogue
    (see Appendix. [B](#A2 "Appendix B Response Visualization ‣ Hello Again! LLM-powered
    Personalized Agent for Long-term Dialogue")). (3): More detailed experimental
    settings are introduced in Appendix. [C](#A3 "Appendix C Detailed Evaluation Settings
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue"). (4): In
    the Appendix. [D](#A4 "Appendix D Prompt ‣ Hello Again! LLM-powered Personalized
    Agent for Long-term Dialogue"), the prompts utilized in LD-Agent is illustrated.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在本附录中，我们讨论以下主题：（1）：我们详细阐述了附录中有关长期开放域对话和基于LLM的自主代理的一些相关工作。[A](#A1 "附录 A 相关工作
    ‣ 再见！基于LLM的个性化代理的长期对话")。（2）：我们可视化了原始 ChatGLM 和 LD-Agent 的响应，以进一步展示 LD-Agent 在长期对话中的能力（见附录。[B](#A2
    "附录 B 响应可视化 ‣ 再见！基于LLM的个性化代理的长期对话")）。 （3）：附录中介绍了更详细的实验设置。[C](#A3 "附录 C 详细评估设置
    ‣ 再见！基于LLM的个性化代理的长期对话")。（4）：在附录[D](#A4 "附录 D 提示 ‣ 再见！基于LLM的个性化代理的长期对话")中，展示了 LD-Agent
    中使用的提示。
- en: Appendix A Related Work
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 相关工作
- en: A.1 Long-term Open-domain Dialogue
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 长期开放域对话
- en: Open-domain dialogue aims to develop a human-like chatbot that can emulate human
    conversation, facilitating free-flowing dialogue on a wide range of topics. However,
    the dialogue’s extent in earlier studies is often limited by conversation length,
    focusing primarily on brief conversations of about 2-15 turns within a single
    session [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)]. To support more realistic
    and extended conversations, a series of studies have explored the role of both
    external [[39](#bib.bib39), [40](#bib.bib40)] and internal knowledge [[2](#bib.bib2),
    [3](#bib.bib3)] on maintaining the feasibility of long-term dialogue. Commonly
    referenced external knowledge, such as commonsense [[40](#bib.bib40)], medical [[41](#bib.bib41)],
    and psychological [[42](#bib.bib42)] knowledge, serves as supplementary guidance
    for the reasoning process, ensuring logical coherence in extended contexts. In
    parallel, internal knowledge captured dynamically during long conversations generally
    contains historical events [[1](#bib.bib1), [8](#bib.bib8), [2](#bib.bib2), [7](#bib.bib7)]
    and personas [[9](#bib.bib9), [3](#bib.bib3), [10](#bib.bib10), [43](#bib.bib43)].
    Historical events are typically summarized and stored into a memory bank to maintain
    dialogue coherence across sessions, while interlocutors’ personas are maintained
    via a dynamic persona memory bank, which ensures character consistency in long-term
    conversations. In this study, we focus on the internal knowledge to integrate
    dynamically updated historical events and personas to conduct long-term personalized
    conversations.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 开放域对话旨在开发一个类人聊天机器人，能够模拟人类对话，促进在广泛话题上的自由流动对话。然而，早期研究中的对话范围通常受到对话长度的限制，主要集中在单次会话中的简短对话，约
    2-15 回合 [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)]。为了支持更真实和扩展的对话，一系列研究探索了外部
    [[39](#bib.bib39), [40](#bib.bib40)] 和内部知识 [[2](#bib.bib2), [3](#bib.bib3)] 在维持长期对话的可行性中的作用。常引用的外部知识，如常识
    [[40](#bib.bib40)]、医学 [[41](#bib.bib41)] 和心理学 [[42](#bib.bib42)] 知识，作为推理过程的补充指导，确保在扩展的背景中逻辑一致性。与此同时，在长时间对话中动态捕获的内部知识通常包括历史事件
    [[1](#bib.bib1), [8](#bib.bib8), [2](#bib.bib2), [7](#bib.bib7)] 和人物角色 [[9](#bib.bib9),
    [3](#bib.bib3), [10](#bib.bib10), [43](#bib.bib43)]。历史事件通常被总结并存储到记忆库中，以维持跨会话的对话一致性，而对话者的人物角色则通过动态人物记忆库得以维持，从而确保长期对话中的角色一致性。在本研究中，我们专注于内部知识，以整合动态更新的历史事件和人物角色，以进行长期个性化对话。
- en: A.2 LLM-based Autonomous Agents
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 基于LLM的自主代理
- en: AI Agent conception is geared towards autonomous environmental perception, decision-making,
    and problem-solving capabilities. With the large language models (LLMs) underlining
    their impressive generalization potential, leading to their widespread adoption
    as substitutes for human operators in various research fields [[17](#bib.bib17),
    [19](#bib.bib19), [44](#bib.bib44), [21](#bib.bib21)]. Generally, these agents
    can be categorized into task-oriented agents [[17](#bib.bib17), [18](#bib.bib18),
    [19](#bib.bib19), [29](#bib.bib29)] and simulation-oriented agents [[44](#bib.bib44),
    [45](#bib.bib45), [46](#bib.bib46), [21](#bib.bib21), [47](#bib.bib47)]. Task-oriented
    agents are designed to accurately perform and achieve predefined tasks, as seen
    in applications for web assistance [[17](#bib.bib17)], game-playing [[18](#bib.bib18)],
    and software development [[19](#bib.bib19)]. On the other hand, simulation-oriented
    agents are devised to emulate human emotive and cognitive behaviors, having played
    roles in psychological studies [[44](#bib.bib44)], social networking platforms [[46](#bib.bib46)],
    conflict resolution scenarios [[45](#bib.bib45)], and recommendation systems [[21](#bib.bib21),
    [47](#bib.bib47)]. In addition, recent developments have seen the advent of individual-level
    agents that are utilized to simulate specific character behaviors, enhancing the
    realism and personalization of user-agent interactions [[48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)]. This paper falls into the simulation-oriented agent to build
    a human-like open-domain dialogue agent with memory retrieved and character analysis
    modules.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理概念旨在实现自主环境感知、决策和问题解决能力。随着大型语言模型（LLMs）展现出其卓越的泛化潜力，导致它们被广泛应用于各种研究领域，作为人类操作员的替代品[[17](#bib.bib17),
    [19](#bib.bib19), [44](#bib.bib44), [21](#bib.bib21)]。一般来说，这些代理可以分为任务导向型代理[[17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19), [29](#bib.bib29)]和模拟导向型代理[[44](#bib.bib44),
    [45](#bib.bib45), [46](#bib.bib46), [21](#bib.bib21), [47](#bib.bib47)]。任务导向型代理旨在准确执行和完成预定义任务，如在网络辅助[[17](#bib.bib17)]、游戏[[18](#bib.bib18)]和软件开发[[19](#bib.bib19)]中的应用。而模拟导向型代理则旨在模拟人类的情感和认知行为，已在心理学研究[[44](#bib.bib44)]、社交网络平台[[46](#bib.bib46)]、冲突解决场景[[45](#bib.bib45)]和推荐系统[[21](#bib.bib21),
    [47](#bib.bib47)]中发挥作用。此外，近期的发展见证了个体级代理的出现，用于模拟特定角色的行为，增强用户与代理互动的真实感和个性化[[48](#bib.bib48),
    [49](#bib.bib49), [50](#bib.bib50)]。本文属于模拟导向型代理的范畴，旨在构建一个具备记忆检索和角色分析模块的类人开放域对话代理。
- en: Appendix B Response Visualization
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 响应可视化
- en: To further analyze the ability of LD-Agent in long-term dialogue, we illustrate
    an example in Figure [4](#A2.F4 "Figure 4 ‣ Appendix B Response Visualization
    ‣ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue"). It can
    be seen that the response generated by LD-Agent successfully captures the information
    about “General Nathan Bedford Forrest” they talked about in the history session.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步分析LD-Agent在长期对话中的能力，我们在图[4](#A2.F4 "图 4 ‣ 附录 B 响应可视化 ‣ 你好，再见！基于LLM的个性化长期对话代理")中展示了一个示例。可以看出，LD-Agent生成的响应成功捕捉了他们在历史会话中讨论的“内森·贝德福德·福雷斯特”的信息。
- en: '![Refer to caption](img/57cb20cb8186bc932322a2c39e495d8f.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/57cb20cb8186bc932322a2c39e495d8f.png)'
- en: 'Figure 4: Example of separately chatting with original ChatGLM and ChatGLM
    with LD-Agent. A more relevant response to history conversation is generated.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：分别与原始ChatGLM和带有LD-Agent的ChatGLM聊天的示例。生成了与历史对话更相关的响应。
- en: Appendix C Detailed Evaluation Settings
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 详细评估设置
- en: In this section, we introduce the detailed experimental dataset, evaluation
    metrics, baseline models, and our implementation details.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了详细的实验数据集、评估指标、基线模型以及我们的实现细节。
- en: C.1 Datasets
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 数据集
- en: Multi-session Dataset.
  id: totrans-248
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 多会话数据集。
- en: 'Our experiments are conducted on two illustrative multi-session datasets: MSC [[1](#bib.bib1)]
    and CC [[7](#bib.bib7)]. Both datasets feature 5 sessions, with approximately
    50 conversational turns per sample. MSC extends the PersonaChat dataset [[5](#bib.bib5)],
    utilizing PersonaChat for the initial session and employing human-human crowd
    workers to simulate the dialogues in subsequent sessions. The time intervals between
    sessions can span several days, and the dataset includes records of the participants’
    personas. We follow the split of [[2](#bib.bib2)] with 4,000 conversations for
    training, 500 conversations for validation, and 501 conversations for testing.
    CC is complied by ChatGPT, which guides interactions according to a predefined
    event graph and participant relationships, with time intervals between sessions
    extending over several years. We employ the same data scale as MSC, with 4,000
    conversations for training, 500 conversations for validation, and 501 conversations
    for testing.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验在两个具有代表性的多会话数据集上进行：MSC [[1](#bib.bib1)]和CC [[7](#bib.bib7)]。这两个数据集均包含5个会话，每个样本大约有50轮对话。MSC扩展了PersonaChat数据集 [[5](#bib.bib5)]，利用PersonaChat进行初始会话，并使用人类众包工模拟后续会话中的对话。会话之间的时间间隔可以跨越几天，数据集包括参与者人设的记录。我们按照[[2](#bib.bib2)]的划分进行训练，训练集包含4,000个对话，验证集包含500个对话，测试集包含501个对话。CC由ChatGPT编制，根据预定义的事件图和参与者关系指导互动，会话之间的时间间隔跨度达到数年。我们采用与MSC相同的数据规模，训练集4,000个对话，验证集500个对话，测试集501个对话。
- en: Multi-party Dataset.
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 多方数据集。
- en: To explore the transferability of LD-Agent on other dialogue tasks. We apply
    our method to the Ubuntu IRC benchmark [[27](#bib.bib27)], a dataset of multiparty
    tasks. We follow the split of previous works [[27](#bib.bib27), [38](#bib.bib38)]
    with 311,725 dialogues for training, 5,000 dialogues for validation, and 5,000
    dialogues for testing.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索LD-Agent在其他对话任务上的可转移性，我们将我们的方法应用于Ubuntu IRC基准 [[27](#bib.bib27)]，这是一个多方任务数据集。我们按照之前工作的划分 [[27](#bib.bib27),
    [38](#bib.bib38)] 进行训练，训练集包含311,725个对话，验证集包含5,000个对话，测试集包含5,000个对话。
- en: C.2 Metrics
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 评估指标
- en: Automatic Evaluation Metrics.
  id: totrans-253
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 自动评估指标。
- en: BLEU-N [[33](#bib.bib33)] (BL-N) and ROUGE-L [[34](#bib.bib34)] (R-L) metrics
    are commonly used automatic evaluation metrics in dialogue generation tasks. BLEU-N
    measures N-gram overlaps between the generated text and the reference text, while
    ROUGE-L focuses on sequential coherence. We employ the METEOR (MET) [[35](#bib.bib35)]
    metric in multi-party tasks as a complement to the BLEU metric, enhancing it with
    synonym calculation capabilities. In addition, accuracy (ACC) is calculated to
    measure the classification accuracy of different persona extractors.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU-N [[33](#bib.bib33)]（BL-N）和ROUGE-L [[34](#bib.bib34)]（R-L）指标是对话生成任务中常用的自动评估指标。BLEU-N测量生成文本与参考文本之间的N-gram重叠，而ROUGE-L关注顺序连贯性。我们在多方任务中采用METEOR（MET） [[35](#bib.bib35)]指标作为对BLEU指标的补充，增强了同义词计算能力。此外，计算准确率（ACC）以衡量不同人设提取器的分类准确性。
- en: Human Evaluation Metrics.
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 人工评估指标。
- en: 'In human evaluation, we evaluate LD-Agent on three aspects: coherence, fluency,
    and engagingness. Coherence measures the chatbot’s capabilities to maintain the
    coherence of topic and logic across sessions. Fluency reflects the natural and
    fluent degree of interactions, making the interaction similar to human-human interactions.
    Engagingness measures a user’s interest in interacting with the target chatbot.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工评估中，我们从三个方面对LD-Agent进行评估：连贯性、流畅性和吸引力。连贯性衡量聊天机器人的话题和逻辑在会话中的保持能力。流畅性反映了互动的自然和流畅程度，使互动类似于人与人之间的交流。吸引力衡量用户与目标聊天机器人互动的兴趣。
- en: C.3 Baselines
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 基准
- en: To validate the effectiveness of our method on various baselines, we employ
    LD-Agent on both online and offline models, tuned and zero-shot models, LLMs,
    and non-LLMs.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们方法在各种基准上的有效性，我们将LD-Agent应用于在线和离线模型、调优和零样本模型、LLMs和非LLMs。
- en: •
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'HAHT [[2](#bib.bib2)]: This is the state-of-the-art model crafted for multi-session,
    open-domain dialogue. It encodes all historical information and utilizes an attention
    mechanism to capture the relevant information to an ongoing conversation.'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: HAHT [[2](#bib.bib2)]：这是为多会话开放领域对话设计的最先进模型。它编码所有历史信息，并利用注意力机制捕捉与正在进行的对话相关的信息。
- en: •
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'BlenderBot [[26](#bib.bib26)]: This is a commonly used large-scale open-domain
    dialogue model pre-trained on online social discussion data.'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BlenderBot [[26](#bib.bib26)]：这是一个常用的大规模开放领域对话模型，预训练于在线社交讨论数据上。
- en: •
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ChatGLM3 [[25](#bib.bib25)]: This is an offline large language model 6B parameters.
    The model is pre-trained on 1T corpus, performing remarkable zero-shot reasoning
    capabilities.'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChatGLM3 [[25](#bib.bib25)]：这是一个离线大型语言模型，具有6B参数。该模型在1T语料上进行了预训练，表现出显著的零样本推理能力。
- en: •
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ChatGPT: This is an online large language model based on the GPT architecture
    with excellent human-like cognitive and reasoning abilities. In this paper, we
    use the API service with the model of “gpt-3.5-turbo-1106”.'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChatGPT：这是一个基于GPT架构的在线大型语言模型，具有出色的人类认知和推理能力。在本文中，我们使用了“gpt-3.5-turbo-1106”模型的API服务。
- en: •
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'BART [[36](#bib.bib36)]: This is a denoising autoencoder with transformer architecture,
    trained to reconstruct original text from corrupting text.'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BART [[36](#bib.bib36)]：这是一个带有变换器架构的去噪自编码器，训练用于从损坏的文本中重建原始文本。
- en: C.4 Implementation Details.
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.4 实现细节。
- en: For the event summarizer, persona extractor, and response generator modules,
    we employ the LoRA mechanism across all configurations. All training and evaluation
    operated on a single NVIDIA A100 GPU. For the ChatGLM3-6B, it is optimized by
    an Adam [[51](#bib.bib51)] optimizer with the learning rate of 5e-5\. We configure
    this model with a batch size of 4 and train it over 3 epochs. For BlenderBot,
    the initial learning rate is set to 2e-5, with the batch size and the number of
    training epochs set at 4 and 5, respectively.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 对于事件总结器、人物提取器和响应生成模块，我们在所有配置中使用了LoRA机制。所有训练和评估都在单个NVIDIA A100 GPU上进行。对于ChatGLM3-6B，使用Adam [[51](#bib.bib51)]优化器进行优化，学习率为5e-5。我们将此模型的批量大小配置为4，并进行3轮训练。对于BlenderBot，初始学习率设置为2e-5，批量大小和训练轮数分别设置为4和5。
- en: Appendix D Prompt
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 提示
- en: In this section, we separately provide the illustrations of the prompts used
    in the Event Module, Persona Module, and Response Module.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们分别提供了事件模块、人物模块和响应模块中使用的提示的说明。
- en: D.1 Prompt of Event Summary
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.1 事件总结的提示
- en: Prompt 1: 
    Event Summary Prompt $\mathcal{SYS\ PROMPT}$. Based
    on the Conversation, please summarize the main points of the conversation with
    brief sentences in English, within 20 words. SUMMARY:
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt 1: 
    Event Summary Prompt $\mathcal{SYS\ PROMPT}$. Based
    on the Conversation, please summarize the main points of the conversation with
    brief sentences in English, within 20 words. SUMMARY:
- en: D.2 Prompt of Persona Extraction
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.2 人物提取的提示
- en: Prompt 2: 
    Persona Extraction Prompt $\mathcal{SYS\ PROMPT}$
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt 2: 
    Persona Extraction Prompt $\mathcal{SYS\ PROMPT}$
- en: D.3 Prompt of Response Generation
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3 响应生成的提示
- en: 'Prompt 3: 
    Base Response Generation Prompt $\mathcal{SYS\ PROMPT}$’s statement
    using the following format (maximum 30 words, must be in English): RESPONSE:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt 3: 
    Base Response Generation Prompt $\mathcal{SYS\ PROMPT}$’s statement
    using the following format (maximum 30 words, must be in English): RESPONSE:'
