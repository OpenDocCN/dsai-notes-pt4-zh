<!--yml

分类：未分类

日期：2025-01-11 13:04:26

-->

# 如何在 AI 时代教授编程？使用 LLMs 作为可教代理进行调试

> 来源：[https://arxiv.org/html/2310.05292/](https://arxiv.org/html/2310.05292/)

\addauthor

sworange

¹¹institutetext: 卡内基梅隆大学，宾夕法尼亚州匹兹堡，美国 ¹¹email: {qianoum,krk,sherryw}@cs.cmu.edu ²²institutetext: 密歇根大学，安阿伯，密歇根州，美国

²²email: huashen@umich.eduQianou Ma 11    Hua Shen 22    Kenneth Koedinger 11    Sherry Tongshuang Wu 11

###### 摘要

大型语言模型（LLMs）现在在 *生成* 技能方面表现出色，能够以无可挑剔的速度创造内容。然而，它们并不完美，仍然会犯各种错误。在计算机科学教育的背景下，随着这些模型被广泛认可为“AI 配对程序员”，培养学生 *评估* 和 *调试* LLM 生成的代码变得越来越重要。在这项工作中，我们介绍了 HypoCompass，这是一个新颖的系统，旨在促进调试的刻意练习，在其中，人类新手扮演教学助理的角色，帮助 LLM 驱动的可教代理调试代码。我们在这种通过教学学习的环境中实现了学生与 LLM 之间的有效任务分配：学生专注于 *假设代码错误的原因*，而像代码补全这样的相邻技能则交给 LLM 代理来处理。我们的评估表明，HypoCompass 生成的高质量训练材料（*例如*，错误和修复）在效率上是人类同行的四倍，且显著提高了学生在调试方面的表现，前后测试成绩提高了 12%。

###### 关键词：

LLM 可教代理调试 CS1。

## 1 引言

大型语言模型（LLMs）正成为软件开发中不可或缺的一部分——像 GitHub Copilot 这样的商业化工具现在被宣传为“你的 AI 配对程序员”，并生成多达 46% 用户的代码[[6](https://arxiv.org/html/2310.05292v5#bib.bib6)]。尽管 LLMs 已广泛应用，但它们仍然会产生不可预测的错误[[11](https://arxiv.org/html/2310.05292v5#bib.bib11)]，*例如*，GPT-4 在针对初学者和中级编程课程的编码任务中仍然有 17% 的错误率[[22](https://arxiv.org/html/2310.05292v5#bib.bib22)]。LLMs 令人印象深刻但并不完美的生成能力，加上过度依赖这些模型的相关风险，凸显了教授学生 *评估* 技能的重要性。在编程的背景下，学生必须提升他们的调试和测试技能[[2](https://arxiv.org/html/2310.05292v5#bib.bib2)]。

然而，调试往往在正式的教育课程中被忽视，尤其是在计算机科学入门课程（*即*，CS1）中[[21](https://arxiv.org/html/2310.05292v5#bib.bib21)]。以往的研究指出了缺乏调试教学的多种原因，例如教师在开发专门的调试材料和评估工具方面的时间有限[[19](https://arxiv.org/html/2310.05292v5#bib.bib19)]。因此，学生主要通过自行解决错误来学习调试，这可能相当令人沮丧——他们必须花费大量时间和精力来*假设*错误的原因，同时还要处理其他认知要求较高的任务，如理解和编写代码。这些挑战促使我们提出以下问题：

研究问题：我们能否通过提供*明确的*、*分阶段的*练习，*以最小的教师时间成本*，来训练学生提高调试技能？

![请参阅标题](img/8c8c3f68b19c405bf4f80b779669c665.png)

图1：在HypoCompass中，给定一个编程问题描述（A），学生用户（以教学助理的角色）需要编写一个测试套件（B），并通过聊天界面（E）帮助多个LLM模拟代理（*例如*，Bob、Chelsea、Dave）在办公时间队列中（C）进行调试。每个LLM代理都充当一个寻求帮助的初学者，并提供反馈给用户（F）。

在这项工作中，我们专注于培养学生的*假设构建*能力，这在调试中是一个关键步骤，之前的研究也有提出[[29](https://arxiv.org/html/2310.05292v5#bib.bib29), [30](https://arxiv.org/html/2310.05292v5#bib.bib30)]。我们介绍了HypoCompass（[图1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")，[第3节](https://arxiv.org/html/2310.05292v5#S3 "3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")），一个互动的、LLM增强的智能辅导系统，专门用于调试。借助LLM的*材料生成*能力，我们让这些模型模拟那些编写了有bug代码并需要助教（TA）帮助的CS1学生。人类新手学生扮演助教的角色，帮助调试这些bug。这使得学生可以有意识地练习*假设*LLM生成代码缺陷的技能，并将与假设构建不直接相关的任务（*例如，*代码补全）委派给LLM。因此，HypoCompass通过*可教代理*框架[[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]，为学生提供了LLM生成的bug的引导性曝光，从而促进了一个富有参与感的学习环境。我们还采用了如集中任务形成和先生成后选择的提示策略，以提高HypoCompass中LLM生成的质量（[第4节](https://arxiv.org/html/2310.05292v5#S4 "4 LLM Integration ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")）。 

我们进行了两项评估研究，发现HypoCompass*节省了教师在材料生成上的时间*，并且*有利于学生的学习*。在我们的LLM评估研究中（[第5节](https://arxiv.org/html/2310.05292v5#S5 "5 LLM Evaluation: Generation Efficiency and Quality ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")），对六个练习问题和145个有bug的程序进行专家检查，结果显示HypoCompass在生成和验证完整材料集时达到了90%的成功率，*比人工生成速度快了四倍*。我们与19名新手的学习评估研究（[第6节](https://arxiv.org/html/2310.05292v5#S6 "6 Learning Evaluation: Pre- / Post-Test Study ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")）表明，HypoCompass显著提高了学生的前后测试成绩，提升了12%，并将完成时间缩短了14%。

总结来说，我们的贡献如下：

+   •

    一种务实的解决方案，平衡了LLM在学习中的收益与风险。我们使用LLM来帮助学生适应不完美的LLM，并强调*角色扮演*在LLM实际应用中的重要性，以及*任务委派*以帮助学生专注于核心技能。

+   •

    一种理论基础的教学设计，用于增强调试技能。根据我们所知，我们是首个提供与假设构建学习目标对齐的教学和评估的研究，*即*，关于错误来源的假设构建，这是调试中的核心瓶颈[[25](https://arxiv.org/html/2310.05292v5#bib.bib25)]。

## 2 相关工作

调试过程。调试是一个复杂的过程，涉及多项认知负荷较大的任务，包括理解代码、查找错误和修复错误，其中前两项被认为是主要瓶颈[[19](https://arxiv.org/html/2310.05292v5#bib.bib19), [25](https://arxiv.org/html/2310.05292v5#bib.bib25)]。虽然许多研究尝试提高学生的代码理解能力[[12](https://arxiv.org/html/2310.05292v5#bib.bib12)]，但对查找错误的指导却很有限。研究者将错误查找的认知模型描述为*假设构建过程*，包括初始化、修改、选择和验证假设（[图2](https://arxiv.org/html/2310.05292v5#S3.F2 "在3节 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为调试的可教代理")B）[[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]。这个过程充满挑战：先前的研究表明，新手在系统地生成全面的假设并识别正确的假设方面存在困难，而专家则能够做到这一点[[8](https://arxiv.org/html/2310.05292v5#bib.bib8), [7](https://arxiv.org/html/2310.05292v5#bib.bib7)]。因此，我们强调教授学生*构建准确的错误假设*和*制定关于潜在错误的全面假设*。

调试训练的导师与工具。先前的研究[[19](https://arxiv.org/html/2310.05292v5#bib.bib19)]和在线讨论[[21](https://arxiv.org/html/2310.05292v5#bib.bib21)]表明，教学调试具有挑战性，并且由于如缺乏教学时间和资源等后勤问题，调试训练很少出现在CS1课程中[[5](https://arxiv.org/html/2310.05292v5#bib.bib5), [10](https://arxiv.org/html/2310.05292v5#bib.bib10)]。现有工具需要教师的投入，且通常侧重于整个调试过程，提高错误修复的准确性和效率[[1](https://arxiv.org/html/2310.05292v5#bib.bib1), [15](https://arxiv.org/html/2310.05292v5#bib.bib15)]。相反，少有研究强调准确或全面的假设构建（并且这些研究通常是语言特定的）[[13](https://arxiv.org/html/2310.05292v5#bib.bib13), [25](https://arxiv.org/html/2310.05292v5#bib.bib25)]。为了填补这一空白，我们设计了HypoCompass，旨在提供关于假设构建的*刻意练习*[[9](https://arxiv.org/html/2310.05292v5#bib.bib9)]，并利用*LLM生成能力提供易于适应且针对性的练习*，并提供即时反馈。

LLM 在计算机科学学习中的能力。LLMs 在 CS1 教室中表现良好[[22](https://arxiv.org/html/2310.05292v5#bib.bib22)]，但对滥用和 LLM 错误的担忧限制了它们在教育中的使用[[2](https://arxiv.org/html/2310.05292v5#bib.bib2)]。因此，目前的应用部署通常专注于生成教学材料（*例如*，问题[[24](https://arxiv.org/html/2310.05292v5#bib.bib24)]）。在我们的工作中，HypoCompass 使用 LLM 生成相互依赖的材料，并将 LLM 视为向学生寻求帮助的工具[[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]，这样人类新手就能接受 LLM 中的不完美。LLM 的两个独特能力使这一点成为可能：(1) LLM 可以模拟不同的人物角色和辅导互动[[18](https://arxiv.org/html/2310.05292v5#bib.bib18)]；(2) LLM 会犯常见的错误和类似人类的自然漏洞[[20](https://arxiv.org/html/2310.05292v5#bib.bib20)]，这些可以作为有错误代码的练习示例。我们调整并开发了各种提示方法[[27](https://arxiv.org/html/2310.05292v5#bib.bib27)]，以提高 LLM 生成内容的质量。

## 3 HypoCompass 的设计

基于认知过程[[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]和新手与专家在假设驱动调试中的差异（[第 2 节](https://arxiv.org/html/2310.05292v5#S2 "2 Related Works ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")），我们为 HypoCompass 指定了两个关键的学习组件：全面且准确的假设构建。先前的研究表明，假设构建与测试密切相关[[30](https://arxiv.org/html/2310.05292v5#bib.bib30)]：每个额外的测试用例，理想情况下，应该是关于程序出错的假设。因此，一个*全面的*测试套件（*即*，一组测试用例）应该使有效的调试者能够构建出*准确的*假设，解释程序出错的原因。我们因此设计了两个学习目标（[图 2](https://arxiv.org/html/2310.05292v5#S3.F2 "In 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")A,D）：

1.  LO1

    综合假设构建：构建一个全面的测试套件，充分覆盖给定问题可能出现的错误。

1.  LO2

    准确的假设构建：给定失败的测试用例，构建一个准确的解释，说明程序出错的原因。

![请参考标题说明](img/24a0584c27ed826b53fd9ac48738c841.png)

图 2：为了实现有目的的练习，我们在 (A) 学习目标、(B) 认知调试过程模型、(C) HypoCompass 交互流程和 (D) 学生在 HypoCompass 中执行的主要任务之间建立了紧密的映射关系。我们将各种材料生成任务交给 LLMs（C[2]）。

#### *界面和关键组件*。

我们通过一个包含 10 个试点的迭代开发过程设计了 HypoCompass，其中包括 CS1 学生、助教和讲师。在最终的界面中（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")），学生将扮演助教的角色，帮助一个 LLM 模拟的学生（LLM-代理）进行调试。他们需要编写并将测试用例按类别排序（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")B），这些类别代表了不同的假设，表明哪些输入可能会触发代码中的错误。

一旦学生对他们的测试套件感到满意，HypoCompass 会显示一个办公时间队列（OHQ）模拟器（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")C）。当学生与每个 LLM-代理互动时，该代理会展示一个有问题的代码片段（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")D）。学生通过对话界面（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")E）引导 LLM-代理进行代码调试，选择或创建能够反映他们假设的 bug 的测试用例，并从候选的自然语言解释池中选择一个 bug 解释。这些候选解释各自阐述了不同的 bug，代表了可能会让学生困惑的不同假设（*例如*，[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")[3]）。

然后，LLM-agent使用测试用例和解释来修正代码，向学生提供即时反馈（[第3节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）。如果解释正确，代理将进行最小的代码修复，并将颜色编码的编辑作为反馈呈现（[图1](https://arxiv.org/html/2310.05292v5#S1.F1 "在1简介 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")F，放大视图请见[第3节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）。否则，LLM-agent会要求学生通过回应一个困惑消息来反思他们的假设，该消息突出了学生解释与实际代码行为之间的差异（[第3节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）。

一旦学生正确确认所有错误已修复，他们可以转到帮助下一个LLM-agent（[图1](https://arxiv.org/html/2310.05292v5#S1.F1 "在1简介 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")C）。完成后，HypoCompass将提供下一轮练习，包含另一个编程问题。虽然数量是可配置的，但默认情况下，HypoCompass包括两个编程练习，每个练习包含三个LLM-agent（有缺陷的程序）。

![请参阅标题](img/b546a894bf2d8f7f6f08c6c071f27150.png)\phantomcaption

图3(()): HypoCompass提供（1）*测试类别提示*，帮助系统地编写全面的测试套件；（2）*测试用例提示*，帮助学生添加缺失的测试场景；（3）*候选解释池*，澄清替代解释的误解。

![请参阅标题](img/11f3c2c8c07b608e9087409643f6ab19.png)\phantomcaption

图3(()): HypoCompass提供即时反馈给（1）*不正确的测试用例*，确保学生理解代码行为；（2）*正确的解释*，作为正确的代码修复；（3）*不正确的解释*，作为来自LLM-agent的困惑消息。

我们强调互动的两个最重要的组成部分：

+   •

    通过角色扮演来框定不完美的 LLM。我们使用 LLM 模拟写有错误的学生，并让人类新手提供帮助。这种可教授的代理设置支持学习，帮助学生反思自己的知识，并通过多种错误进行推理[[23](https://arxiv.org/html/2310.05292v5#bib.bib23)]。让学生处理“他人的错误”还可以提升他们的动力，并保护他们的自我效能感[[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]。更重要的是，它积极地让新手参与到识别 LLM 生成代码中的错误中，*使他们能够有针对性地接触 LLM 的不完美性*。

+   •

    学生与 LLM 之间的任务分配。为了确保在全面且准确的假设构建方面进行刻意练习，学生主要从事两个任务，每个任务对应一个学习目标（[图 2](https://arxiv.org/html/2310.05292v5#S3.F2 "3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")D）：(1) 使测试套件更加完整（[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项目 LO1 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")）；和 (2) 正确地将解释与错误匹配（[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项目 LO2 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")）。我们将学生的互动流程（[图 2](https://arxiv.org/html/2310.05292v5#S3.F2 "3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")C[1]）与调试的认知模型对齐[[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]（[图 2](https://arxiv.org/html/2310.05292v5#S3.F2 "3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")B）。LLM 承担了与核心学习目标*间接相关*的其他任务，包括生成多样的错误和修复，从而解放学生于代码编写之外。我们还使用 LLM 来支持支架教学、生成提示（[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")），并在整个练习过程中提供即时反馈（[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")）。

![参考标题](img/2f720117d725fdbb90d25741ec333ca3.png)

图 4：LLM 材料生成管道的输入和输出示例。

## 4 LLM 集成

如[图2](https://arxiv.org/html/2310.05292v5#S3.F2 "在HypoCompass设计中 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")C[2]所示，我们使用LLM生成五种类型的材料：（1）测试用例类别提示，（2）测试用例提示，（3）有错误的程序，（4）错误说明，以及（5）已修复错误的程序。通过仅使用问题描述、参考解决方案和约10个输入的参考测试集来生成练习，我们减少了教师的工作量，并通过优化提示和自动化算法进一步最小化了人工验证开销。我们的生成过程详见[图4](https://arxiv.org/html/2310.05292v5#S3.F4 "在界面与关键组件中 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")，示例提示见[表1](https://arxiv.org/html/2310.05292v5#S4.T1 "在任务形成与分解中 ‣ 4 LLM集成 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")，完整提示见[补充材料](http://tinyurl.com/hypocompass-sup)¹¹1中的表3。所有材料均使用OpenAI的gpt-3.5-turbo，除了说明生成使用gpt-4，以增强推理能力。以下是生成成功的关键因素：

#### *任务形成与分解。*

我们根据任务的性质迭代我们的提示语。首先，由于当用户任务与LLM固有的训练目标冲突时，LLM的表现往往不一致[[28](https://arxiv.org/html/2310.05292v5#bib.bib28)]，我们会仔细制定任务，以避免引入相互竞争的任务。以*本地错误修复*（[表1](https://arxiv.org/html/2310.05292v5#S4.T1 "在任务形成与分解中 ‣ 4 LLM集成 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")）为例：当我们直接要求LLM根据说明修复一个错误时，我们观察到模型几乎总是会过度修复所有错误，而不管提供的指令是什么。这是因为LLM可能会倾向于生成完全正确的代码（LLM预训练的一部分），而不专注于本地错误修复（仅修改指令描述的错误代码片段，即期望任务）。因此，我们将其重新构造为*翻译任务*，将错误修复指令转换为其代码格式，从旧代码$\rightarrow$新代码片段。这种任务重构减轻了模型的固有偏差，减少了70%的过度修复错误。

其次，对于多步骤任务（*例如*，*本地错误修复*），我们采用LLM链[[27](https://arxiv.org/html/2310.05292v5#bib.bib27)]，将任务分解成子任务并由不同步骤处理，从而使每个步骤都能贡献于稳定的表现。第三，我们通过显式优先考虑基本要求来解决提示复杂性。对于像生成*错误解释和修复说明*（[表1](https://arxiv.org/html/2310.05292v5#S4.T1 "任务形成与分解。 ‣ 4 LLM集成 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）这样的任务，我们优先进行精确的错误提取，指示模型先列出所有独特的错误。次要要求（*例如*，字数限制）只在输出格式中指定。这种层次化解构显著提高了成功率，超过40%。  

表格 1：生成错误、解释和修复的提示和温度（Temp.）。温度设定越高，输出的多样性和随机性越强。

| 材料 | 生成目标 | 温度 |
| --- | --- | --- |
| 有缺陷的代码 | 生成多种不同质量的错误代码供进一步选择。 | 0.7 |
| [系统] | 你是计算机科学入门课程的初学者，你会犯错并写出有缺陷的代码。 |
| [用户] | 问题描述: {问题描述} 写出带有常见错误的不同有缺陷的解决方案，如初学者学生： |
| 错误解释与修复说明 | 描述每个独特的错误，并写出相应的修复说明。如果代码中有多个错误，分别生成它们的解释和修复。 | 0.3 |
| [系统] | 你是计算机编程入门课的一个有经验且乐于助人的助教。 |
| [用户] | 嗨，我是你班上的一名学生。我在编程作业中遇到困难：{问题描述} 这是我的有缺陷代码：{有缺陷的代码} 我的代码有什么问题？列出所有独特的错误，但不要编造错误。对于每一点，使用以下格式：{解释：简洁而准确地解释代码的作用以及错误的所在，适合初学者，修复：如何修复错误，30个字以内} 仅返回项目符号列表，不要写任何其他文本或代码。 |
| 错误修复 | 根据修复说明编辑有缺陷的代码，避免过度或不足的修复。 | 0.3 |
| [系统] | 你根据说明仔细修复Python代码中的错误。 |

| [用户] | 原始代码: {有缺陷的代码}; 代码修改: {解释} 将语句翻译为实际的最小代码更改，格式如下：

{原始代码片段: ""复制需要编辑的代码行""

-> 编辑后的代码片段: ""写出编辑后的代码片段""} |

| [LLM] | {旧到新片段的JSON格式，例如，numbers_list[i] <= key $\mathrel{\hbox{\rule[-0.2pt]{3.0pt}{0.4pt}}\mkern-4.0mu\hbox{\char 41\relax}}$ numbers_list[i] > key } |
| --- | --- |
| [用户] | 旧代码:{有缺陷的代码}; 指令:{旧片段到新片段}; 新代码: |

#### *过度生成然后选择。*

![参见说明](img/1da5c09ee8dfaa7e8d95618f11110b2b.png)

图 5：过度生成并自动选择具有教学价值的材料。

尽管大型语言模型（LLMs）可以轻松生成随机材料，但确保其生成内容具有教学价值并非易事。例如，行为上有明显差异的 bug 帮助学生练习不同的实例，但通过提示强制实现这一点很困难，因为这需要 LLMs “了解” bug 行为。然而，我们可以配置非确定性的 LLMs 使其过度生成多种具有不同质量的解决方案[[17](https://arxiv.org/html/2310.05292v5#bib.bib17)]，然后从中选择出我们所需的子集（[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")）。我们在多个地方应用了这一策略：

（1）为了让学生接触到行为上有明显差异的 bug，我们过度生成了有 bug 的代码（[表 1](https://arxiv.org/html/2310.05292v5#S4.T1 "在任务形成和分解中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")）。我们剔除了正确代码，并基于参考测试套件对有 bug 的代码行为进行向量化（[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")A，0代表测试失败）。然后，我们贪婪地选择了一组多样的有 bug 程序，这些程序在错误向量上的成对距离最大，使用的是欧几里得距离（[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")B）。

（2）为了帮助学生澄清误解（[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")C），我们希望有干扰性的解释，它们看起来与每个实践用的有 bug 代码的实际解释相似。我们从过度生成的有 bug 代码池中选择，找到与目标代码最小欧几里得距离的两个代码，并使用它们的相应解释作为干扰项。这个映射还帮助生成混淆信息（[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件。 ‣ 3 HypoCompass的设计 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试") [3]）——当学生选择干扰项解释时，我们使用其相应的有 bug 代码来寻找测试用例并呈现给学生。

(3) 为了捕捉我们测试类别提示中的关键测试方面（见[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在过度生成然后选择中。 ‣ 4 LLM 集成 ‣ 如何在 AI 时代教授编程？使用 LLM 作为可教授的调试代理")D），我们将参考测试用例聚集成语义上有意义的组。我们使用聚合层次聚类（Agglomerative Hierarchical Clustering）从测试用例向量中构建树状图[[14](https://arxiv.org/html/2310.05292v5#bib.bib14)]，这些树状图指导从过度生成池中选择测试类别提示。

#### *人类参与验证。*

如[图 4](https://arxiv.org/html/2310.05292v5#S3.F4 "在接口和关键组件中。 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为可教授的调试代理")所示，虽然测试用例和类别的提示是分别生成的，但与错误相关的材料是按顺序生成的。我们在每个步骤上执行人工验证，以减少后续步骤中级联错误的风险。我们在[第 5 节](https://arxiv.org/html/2310.05292v5#S5 "5 LLM 评估：生成效率和质量 ‣ 如何在 AI 时代教授编程？使用 LLM 作为可教授的调试代理")中提供了更多关于人工验证和编辑时间的详细信息。

## 5 LLM 评估：生成效率和质量

我们在六个不同问题上评估了生成内容，来自先前的工作[[4](https://arxiv.org/html/2310.05292v5#bib.bib4)]以及我们自己的问题（详见[附录](http://tinyurl.com/hypocompass-sup)中的表 4）。平均而言，对于每个问题，我们生成了 3 个测试类别提示、10 个测试用例提示、24 个错误程序、解释和修复指令，以及 33 个错误修复。总数和成功率总结在[表 2](https://arxiv.org/html/2310.05292v5#S5.T2 "在方法中。 ‣ 5 LLM 评估：生成效率和质量 ‣ 如何在 AI 时代教授编程？使用 LLM 作为可教授的调试代理")中。我们在[附录](http://tinyurl.com/hypocompass-sup)中的表 5 提供了所有类型材料的成功标准。

#### *方法。*

两位作者分别在每个步骤标注了10%的生成内容，并讨论解决分歧并更新了代码本。外部讲师使用更新后的代码本标注了同样10%的LLM生成材料。我们计算了外部讲师与两位作者解决后标注之间的评分一致性（IRR），使用百分比IRR和Cohen's Kappa。正如在[表2](https://arxiv.org/html/2310.05292v5#S5.T2 "在方法部分 ‣ 5 LLM评估：生成效率与质量 ‣ 如何在AI时代教授编程？使用LLMs作为可教学的调试代理")中所示，不同模型生成之间的一致性是令人满意的（IRR% $>$ 90% 和 $\kappa>0.75$）²²2 有缺陷的程序经过自动测试，因此无需人工验证（n/a）。如果两个评审者在某一类别中达成一致，则$kappa$未定义（-），因此$\kappa$仅在单一标签的IRR一致性不到100%时才进行标注。一个作者标注了剩余的材料以计算成功率。我们记录了验证和编辑的*时间*，作为讲师负担的代理。

为了比较LLM和人工生成，我们招募了两位经验丰富的计算机科学教学助理（CS TA），让他们分别为一个特定问题创建练习材料。每位TA收到与LLM相同的输入，要求他们生成一套与LLM生成内容相匹配的材料，并为他们的时间提供报酬。

表2：LLM评估：时间、成功率和评分一致性（*即*，IRR% = #一致项 / #总标签，$\kappa$是Cohen的Kappa系数）。${}^{\ref{footnote:kappa}}$

| 材料 | 原始LLM输出 | 人工验证 |
| --- | --- | --- |
| # 生成 | 平均生成时间 | 成功率% | 平均编辑时间 | IRR% | $\kappa$ |
| --- | --- | --- | --- | --- | --- |
| 测试用例描述提示 | 61 | 0:00:37 | 98.36% | 0:00:08 | 100% | - |
| 测试用例类别提示 | 18 | 0:00:10 | 94.44% | 0:00:10 | 100% | - |
| 有缺陷的代码 | 145 | 0:01:30 | 57.93% | 0:00:02 | n/a | n/a |
| 错误解释与修复 | 145 | 0:03:36 | 91.72% | 0:00:52 | 90% | 0.875 |
| Bug修复 | 195 | 0:02:45 | 86.15% | 0:00:37 | 92% | 0.752 |

#### *结果：高效且高质量的生成。*

我们实现了高质量的生成：一套完整的练习材料，包括9个有缺陷的程序（3个用于练习，另外6个作为干扰项）、9个错误解释、9个错误修复、10个测试用例提示和3个测试类别提示，成功率达到90%，且只需要15分钟来标注和编辑。由于我们*过度生成*并自动选择有缺陷的代码，成功率超过50%是实际应用中合理的。

使用 LLM 还可以显著提高效率。总的来说，一名助教花费了大约 60 分钟来生成一套 HypoCompass 的练习材料。一名助教提到，在持续 30 分钟后，保持创作独特且高质量的材料变得困难，并表示*“我创建的 bug 的重要性开始下降。”* 同一位作者使用注释代码本评估了助教的创作，结果显示 100% 成功率，并且用了 11 分钟。使用 LLM 生成和编辑 HypoCompass 教学材料所投入的时间比人工助教少了 4.67 倍。

## 6 学习评估：前测 / 后测研究

*在使用 HypoCompass 后，新手能更好地制定假设吗？* 我们对19名学生进行了学习评估，并比较了前测和后测之间的速度和表现差异。

#### *评估。*

为了最佳地捕捉学生在我们的学习目标上的学习成果，我们采用了逆向设计方法[[26](https://arxiv.org/html/2310.05292v5#bib.bib26)]，创建了一个与[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项 LO1 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")和[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项 LO2 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")的综合性与准确假设构建技能对齐的评估。我们进行了多轮试点测试，以优化我们的干预和前后测评估。

![请参见说明](img/d4a026a6130eb6e79490621d5411a34c.png)

图 6：前后测问题示例，针对[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项 LO1 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")的综合性（Q3.1 和 Q3.2）以及[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项 LO2 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")的准确假设构建（Q7）。

我们的最终测试基于两个难度相当的编程练习。为了控制问题顺序的影响，我们对前后测试的问题进行了平衡安排。每个测试包含七个问题，其中三个评估[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项目 LO1 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")，四个评估[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项目 LO2 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")。[图 6](https://arxiv.org/html/2310.05292v5#S6.F6 "评估中 ‣ 6 学习评估：前/后测试研究 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")提供了每个问题的示例。例如，问题3.1要求学生识别更适合添加到现有测试套件中的测试用例，评估他们构建全面假设的能力（[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项目 LO1 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")）。我们通过标准评分量表来衡量学生的表现，同时记录前后测试的完成时间，作为熟练度的代理。

#### *方法：学习程序和参与者。*

我们的为期一小时的用户研究包括前调查、前测试、与HypoCompass的互动、后测试和后调查。参与者首先进行前调查，问卷包括人口统计信息以及关于其调试经验的7级李克特量表问题。接着，参与者有最多20分钟时间进行前测试。系统互动包含两个问题，参与者需要为每个问题编写测试套件，并解释三个不同的有错误程序中的 bug。第一个问题与前测试相同，第二个问题与筛选问卷中的练习一致。通过重复使用学生已经见过的问题，我们将学习目标与程序理解技能分离开来。之后进行20分钟的后测试，参与者填写后调查，问卷包括李克特量表和开放性问题，旨在了解他们使用HypoCompass的体验和感知。参与者会因其时间获得15美元的礼品卡。

我们招募了来自四所美国公立或私立院校的不同背景的本科生和研究生。感兴趣的参与者填写了筛选问卷，其中包括一个编程练习，该练习也作为我们研究中的第二个练习。为了确保技能范围合适，我们排除了那些具有丰富编程经验或能够快速解决练习的参与者。筛选后，19名参与者（S1-19）被纳入研究——其中12名女性，6名男性，1名非二元性别，8名非母语英语者，平均年龄为20.7岁。

#### *定量结果：学习收获。*

一项双尾配对t检验表明，学生的前测到后测成绩显著提高了11.7%（$p=0.033<0.05$），完成时间显著减少了13.6%（$p=0.003$），这表明通过与HypoCompass的互动，学生在学习上取得了成功。请注意，前后测使用的错误是人为生成的，与HypoCompass中的错误不同。因此，这些显著的学习进展表明，学生能够学习到可以 *迁移* 到实际世界错误的调试技能。

学习进展来源于哪里？我们根据学习目标进行了分析。我们发现，在*综合假设构建*（[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项 LO1 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")）上，得分提高了6.1%，而时间减少了23.6%；在*准确假设构建*（[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项 LO2 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")）上，得分提高了15.8%，时间减少了9.0%。因此，学生在[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项 LO1 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")上的效率提升更多，而在[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项 LO2 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")上则获得了更多的学习进展。需要注意的是，这些改进可能与问题难度有关，因为[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项 LO1 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")（前测 $\mu=54\%$）对应的题目似乎比[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "项 LO2 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")（前测 $\mu=38\%$）对应的题目更容易。

#### *定性结果：学生的感知。*

我们通过分析调查反馈进一步揭示了HypoCompass对学习的贡献。学生们很看重能够将一些调试子任务转交给HypoCompass，比如编写代码和解释。例如，S1说 *“查看测试行为和解释选项确实有助于减轻负担。”* 学生们普遍觉得由LLM生成的错误和修复是可信的。大多数参与者无法判断他们练习的程序是由学生还是AI编写的，因为他们有过类似的错误经历，或者曾见过同学犯过类似的错误。

此外，学生们报告称HypoCompass具有吸引力、趣味性，不令人沮丧，并且帮助建立了调试信心。威尔科克森符号秩检验显示，学生自评的调试信心提高了15%（$p=0.007$）。学生们认为HypoCompass比他们传统的调试和测试学习方式更具吸引力（得分6.0/7）、趣味性（得分6.0），并且不那么令人沮丧（得分2.5）（每项$p<0.005$）。S8特别喜欢可教代理设置：“*角色扮演感觉更自然，因为它更像是对一个橡皮鸭进行解释，而不是对自己说话*”。

## 7 讨论

适用于不完美AI的可教代理。我们的研究展示了一个场景，其中*大语言模型（LLM）生成的错误并不被视为问题，而是作为一种特性*。HypoCompass的可教代理设置为学生提供了*有控制的暴露于不完美LLMs*的机会，并可能帮助他们认识到LLMs是有缺陷的，并据此调整信任。未来的迭代可能会去除材料验证，允许学生直接接触到实时互动中的未过滤LLM错误，从而充分利用可教代理框架。学生们自然会预期寻求帮助的LLM代理可能会犯错（*例如*，未能按照错误修复的解释执行）。然而，这种方法需要更复杂的设计来支持学生识别LLM错误。

任务委派以转变学习焦点。我们的探索为在生成性AI时代培养更高阶评估技能的范式转变奠定了基础。本质上，我们提出了一个问题：我们应该卸载哪些技能，应该学习哪些技能？我们研究中的大多数学生都赞赏将子任务委托给LLM（[第6节](https://arxiv.org/html/2310.05292v5#S6.SS0.SSS0.Px4 "定性结果：学生感知。‣ 6 学习评估：前测/后测研究 ‣ 如何在AI时代教授编程？利用LLMs作为调试的可教代理")）；然而，有些学生需要更多支持，而另一些学生则偏好较少。未来的研究可以探讨更加个性化的任务委派。例如，需要更多帮助的学生可以使用LLMs来促进代码追踪，而学生也可以根据自己的熟练程度编写关于错误的解释。决定教授的最低编程技能和人类-人工智能协作技能也需要进一步探索[[16](https://arxiv.org/html/2310.05292v5#bib.bib16)]。

模块化以适应不同需求。虽然大多数学生和教师发现HypoCompass具有吸引力，但也有些人对新工具的部署和维护成本表示担忧。为了最大化对不同用户的效用，我们可以将HypoCompass的不同组件模块化。那些希望将培训材料分发为讲义的教师可以完全依赖于材料生成模块。相比之下，想要实验TA培训的教师可以通过使用他们自己的训练问题生成的练习来使用HypoCompass。未来的研究可能会进行消融研究，以评估在更多课堂部署中HypoCompass的不同组件。

局限性。我们主要通过小规模实验评估了*HypoCompass是否能够带来学习和效率提升*。在此前提下，我们计划进行未来的课堂部署并进行控制性比较。此外，关于LLM辅助的教学材料开发的效率也存在局限性，因为教师需要一些时间来熟悉该工具和流程。

## 8 结论

为了回答大型语言模型（LLMs）如何重塑编程教育的重点，我们引入了一个新系统HypoCompass，并提出了新的假设构建技能的教学设计。我们的目标是通过使用经过理论驱动和经验验证的可教代理，并结合LLM，向初学者提供有趣且有目的的调试实践。我们的评估结果表明，HypoCompass可以有效帮助教师创建高质量的教学材料，帮助初学者有效地进行全面和准确的假设构建训练，并促进学生在调试中的信心和参与感。

### 8.0.1 致谢

感谢参与者、评审、Vicky Zhou、Kelly Rivers、Michael Taylor、Michael Hilton、Michael Xieyang Liu、Kexin Yang、Jionghao Lin、Erik Harpstead以及Ken实验室的其他成员提供的见解和帮助。感谢Adobe、Oracle和Google的捐赠基金；感谢国家科学基金会（奖项CNS-2213791）对本研究的部分资助。

## 参考文献

+   [1] Ardimento, P., Bernardi, M.L., Cimitile, M., Ruvo, G.D.: 重新使用有缺陷的源代码以支持初学者进行调试任务。ACM 计算机教育学报 20(1), 1–24 (2019). https://doi.org/10.1145/3355616

+   [2] Becker, B.A., Denny, P., Finnie-Ansley, J., Luxton-Reilly, A., Prather, J., Santos, E.A.: 编程很难——或者至少以前是：AI代码生成的教育机会与挑战。见：第54届ACM计算机科学教育技术研讨会论文集V. 1. 第500–506页（2023）

+   [3] Blair, K., Schwartz, D.L., Biswas, G., Leelawong, K.: 用于教学学习的教学代理：可教代理。教育技术研究与发展 47(1), 56–61 (2007)

+   [4] Dakhel, A.M., Majdinasab, V., Nikanjam, A., Khomh, F., Desmarais, M.C., Jiang, Z.M.J.: Github Copilot AI配对程序员：资产还是负担？《系统与软件期刊》203，111734（2023）。https://doi.org/10.48550/ARXIV.2206.15331

+   [5] Desai, C., Janzen, D.S., Clements, J.: 将测试驱动开发集成到CS1/CS2课程中的影响。SIGCSE公报，41(1)，148–152（2009年3月）

+   [6] Dohmke, T.: GitHub Copilot X：AI驱动的开发者体验。[https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/)（2023年3月），访问日期：2023年9月5日

+   [7] Edwards, S.H., Shams, Z.: 比较评估学生编写的测试的测试质量指标。载于：第36届国际软件工程会议论文集。第354–363页。ICSE Companion 2014，计算机协会，纽约，美国（2014年5月）

+   [8] Edwards, S.H., Shams, Z.: 学生程序员是否都倾向于编写相同的软件测试？载于：2014年创新与技术计算机科学教育会议论文集。第171–176页。ITiCSE ’14，计算机协会，纽约，美国（2014年6月）

+   [9] Ericsson, A., Pool, R.: 《峰值：新科学的专业性秘密》。兰登书屋（2016年）

+   [10] Fitzgerald, S., McCauley, R., Hanks, B., Murphy, L., Simon, B., Zander, C.: 从学生角度看调试。IEEE教育学报，53(3)，390–396（2010年）

+   [11] Ganguli, D., Hernandez, D., Lovitt, L., Askell, A., Bai, Y., Chen, A., Conerly, T., Dassarma, N., Drain, D., Elhage, N., 等：大规模生成模型中的可预测性与惊讶。载于：2022年ACM公平性、问责制与透明度会议论文集。第1747–1764页（2022年）

+   [12] Kallia, M.: 寻找意义：编程中的推理性战略阅读理解。载于：2023年ACM国际计算教育研究会议（ICER ’23）论文集。ACM（2023年5月）

+   [13] Ko, A.J., Myers, B.A.: 调试的重塑：问与答关于程序行为的“为什么”和“为什么不”。载于：第30届国际软件工程会议论文集。第301–310页。ICSE ’08，计算机协会，纽约，美国（2008年5月）

+   [14] Lukasová, A.: 层次聚类过程。模式识别，11(5-6)，365–381（1979年）

+   [15] Luxton-Reilly, A., McMillan, E., Stevenson, E., Tempero, E., Denny, P.: Ladebug：一款帮助初学程序员提高调试技能的在线工具。载于：第23届年度ACM创新与技术计算机科学教育会议论文集。第159–164页。ITiCSE 2018，计算机协会（2018年7月）

+   [16] Ma, Q., Wu, T., Koedinger, K.: AI是更好的编程伙伴吗？人类与人类配对编程与人类与AI配对编程。arXiv 预印本 arXiv:2306.05153 (2023)，[http://arxiv.org/abs/2306.05153](http://arxiv.org/abs/2306.05153)

+   [17] MacNeil, S., Tran, A., Mogil, D., Bernstein, S., Ross, E., Huang, Z.: 使用GPT-3大语言模型生成多样化的代码解释。在：2022年ACM国际计算教育研究会议论文集-第2卷。第37–39页 (2022)

+   [18] Markel, J.M., Opferman, S.G., Landay, J.A., Piech, C.: GPTeach：基于GPT的学生进行互动式助教培训。在：第十届ACM学习规模会议论文集。第226–236页。L@S '23，计算机协会，美国纽约 (2023年7月)。https://doi.org/10.1145/3573051.3593393

+   [19] McCauley, R., Fitzgerald, S., Lewandowski, G., Murphy, L., Simon, B., Thomas, L., Zander, C.: 调试：从教育角度的文献综述。计算机科学教育 18(2)，67–92 (2008年6月)

+   [20] Mozannar, H., Bansal, G., Fourney, A., Horvitz, E.: 细读背后：建模用户行为和人工智能辅助编程中的成本。arXiv 预印本 arXiv:2210.14306 (2022)

+   [21] News, Y.H.: 为什么学校不教调试？[https://news.ycombinator.com/item?id=7215870](https://news.ycombinator.com/item?id=7215870) (2014年2月)，访问日期：2023年9月8日

+   [22] Savelka, J., Agarwal, A., An, M., Bogart, C., Sakr, M.: 为你的进展而兴奋！大型语言模型（GPT-4）不再难以通过高等教育编程课程中的评估。arXiv 预印本 arXiv:2306.10073 (2023)

+   [23] Shahriar, T., Matsuda, N.: 你如何解释很重要：好奇心强的可教代理通过支架式学习促进导师学习的知识构建。在：国际人工智能教育大会。第126–138页。Springer (2023)

+   [24] Wang, Z., Valdez, J., Basu Mallick, D., Baraniuk, R.G.: 面向类人教育性问题生成的大型语言模型研究。在：人工智能教育。第153–166页。Springer国际出版 (2022)

+   [25] Whalley, J., Settle, A., Luxton-Reilly, A.: 介绍性调试过程分析。在：第23届澳大利亚计算机教育会议论文集。第11–20页。ACE '21，计算机协会 (2021年3月)

+   [26] Wiggins, G.P., McTighe, J.: 设计理解。ASCD (2005)

+   [27] Wu, T., Terry, M., Cai, C.J.: AI链：通过链接大型语言模型提示实现透明且可控的人工智能互动。在：2022年CHI计算机系统人因会议论文集。第1–22页。CHI '22，计算机协会，美国纽约 (2022)

+   [28] Xie, J., Zhang, K., Chen, J., Lou, R., Su, Y.: 自适应变色龙或顽固树懒：揭示大型语言模型在知识冲突中的行为 (2023)

+   [29] Xu, S., Rajlich, V.：《程序调试中的认知过程》。载《第三届IEEE国际认知信息学会议论文集》，2004年。第176–182页。IEEE（2004年8月）

+   [30] Zeller, A.：《为什么程序会失败：系统调试指南》。摩根·考夫曼出版社，英国牛津，第2版。（2009年6月）
