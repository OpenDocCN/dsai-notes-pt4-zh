- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-08 18:51:45'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:51:45'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Triad: 利用多角色大语言模型代理解决知识库问答的框架'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14320](https://ar5iv.labs.arxiv.org/html/2402.14320)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14320](https://ar5iv.labs.arxiv.org/html/2402.14320)
- en: Chang Zong
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Chang Zong
- en: Zhejiang University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 浙江大学
- en: zongchang@zju.edu.cn
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: zongchang@zju.edu.cn
- en: '&Yuchen Yan'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '&Yuchen Yan'
- en: Zhejiang University
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 浙江大学
- en: yanyuchen@zju.edu.cn
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: yanyuchen@zju.edu.cn
- en: '&Weiming Lu'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '&Weiming Lu'
- en: Zhejiang University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 浙江大学
- en: luwm@zju.edu.cn
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: luwm@zju.edu.cn
- en: \ANDEliot Huang
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \ANDEliot Huang
- en: Leibowitz AI
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Leibowitz AI
- en: EliotHuang@leibowitz.org.cn
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: EliotHuang@leibowitz.org.cn
- en: '&Jian Shao'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '&Jian Shao'
- en: Zhejiang University
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 浙江大学
- en: jshao@zju.edu.cn
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: jshao@zju.edu.cn
- en: '&Yueting Zhuang'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '&Yueting Zhuang'
- en: Zhejiang University
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 浙江大学
- en: yzhuang@zju.edu.cn
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: yzhuang@zju.edu.cn
- en: Abstract
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Recent progress with LLM-based agents has shown promising results across various
    tasks. However, their use in answering questions from knowledge bases remains
    largely unexplored. Implementing a KBQA system using traditional methods is challenging
    due to the shortage of task-specific training data and the complexity of creating
    task-focused model structures. In this paper, we present Triad, a unified framework
    that utilizes an LLM-based agent with three roles for KBQA tasks. The agent is
    assigned three roles to tackle different KBQA subtasks: agent as a generalist
    for mastering various subtasks, as a decision maker for the selection of candidates,
    and as an advisor for answering questions with knowledge. Our KBQA framework is
    executed in four phases, involving the collaboration of the agent’s multiple roles.
    We evaluated the performance of our framework using three benchmark datasets,
    and the results show that our framework outperforms state-of-the-art systems on
    the LC-QuAD and YAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLM）的代理最近在各种任务中取得了令人鼓舞的进展。然而，它们在回答知识库中的问题方面的应用仍然未被充分探索。由于任务特定训练数据的短缺和创建任务聚焦模型结构的复杂性，使用传统方法实现知识库问答（KBQA）系统具有挑战性。本文提出了Triad，一个统一的框架，利用一个具有三种角色的大语言模型代理来处理KBQA任务。该代理被分配三种角色来应对不同的KBQA子任务：作为通才掌握各种子任务，作为决策者选择候选项，以及作为顾问用知识回答问题。我们的KBQA框架分为四个阶段执行，涉及代理多个角色的协作。我们使用三个基准数据集评估了我们的框架性能，结果表明，我们的框架在LC-QuAD和YAGO-QA基准测试中优于最先进的系统，分别获得了11.8%和20.7%的F1得分。
- en: 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 'Triad: 利用多角色大语言模型代理解决知识库问答的框架'
- en: Chang Zong Zhejiang University zongchang@zju.edu.cn                        Yuchen
    Yan Zhejiang University yanyuchen@zju.edu.cn                        Weiming Lu
    Zhejiang University luwm@zju.edu.cn
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Chang Zong 浙江大学 zongchang@zju.edu.cn                        Yuchen Yan 浙江大学
    yanyuchen@zju.edu.cn                        Weiming Lu 浙江大学 luwm@zju.edu.cn
- en: Eliot Huang Leibowitz AI EliotHuang@leibowitz.org.cn                       
    Jian Shao Zhejiang University jshao@zju.edu.cn                        Yueting
    Zhuang Zhejiang University yzhuang@zju.edu.cn
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Eliot Huang Leibowitz AI EliotHuang@leibowitz.org.cn                       
    Jian Shao 浙江大学 jshao@zju.edu.cn                        Yueting Zhuang 浙江大学 yzhuang@zju.edu.cn
- en: 1 Introduction
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: A question-answering system is designed to extract information by converting
    a natural language question into a structured query that can retrieve precise
    information from an existing knowledge base Omar et al. ([2023a](#bib.bib13)).
    The resolution of Knowledge Base Question Answering (KBQA) typically involves
    phases including question understanding, URI linking, and query execution. Traditional
    KBQA systems require the use of specialized models trained with domain datasets
    for question parsing and entity linking Hu et al. ([2018](#bib.bib7)); Omar et al.
    ([2023a](#bib.bib13)); Hu et al. ([2021](#bib.bib8)). Large language models (LLMs),
    however, have shown promising competencies in in-context learning using task-specific
    demonstrations Dong et al. ([2022](#bib.bib4)). LLMs have recently been employed
    as agents in the execution of complex problems. A framework that employs LLM-augmented
    agents can generate actions or coordinate multiple agents, thus improving the
    capacity to handle complex situations Liu et al. ([2023](#bib.bib12)). Despite
    the remarkable performance of LLMs in various tasks as evidenced in previous studies,
    a comprehensive qualitative and quantitative evaluation of KBQA frameworks empowered
    with an LLM-based agent remains a challenge.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 问答系统旨在通过将自然语言问题转换为结构化查询，从现有知识库中提取信息 Omar et al. ([2023a](#bib.bib13))。知识库问答（KBQA）的解决通常包括问题理解、URI
    链接和查询执行等阶段。传统的 KBQA 系统需要使用在领域数据集上训练的专门模型来进行问题解析和实体链接 Hu et al. ([2018](#bib.bib7));
    Omar et al. ([2023a](#bib.bib13)); Hu et al. ([2021](#bib.bib8))。然而，大型语言模型（LLMs）在使用任务特定演示进行上下文学习方面显示了有前景的能力
    Dong et al. ([2022](#bib.bib4))。LLMs 最近被作为代理用于解决复杂问题。一个利用 LLM 增强代理的框架可以生成行动或协调多个代理，从而提高处理复杂情况的能力
    Liu et al. ([2023](#bib.bib12))。尽管 LLM 在各种任务中表现出色，如前期研究所示，但对基于 LLM 的代理赋能的 KBQA
    框架进行全面的定性和定量评估仍然是一项挑战。
- en: 'Recent research on KBQA with LLMs has focused primarily on highlighting the
    inability of LLMs to generate complete factoid results Hu et al. ([2023b](#bib.bib6));
    Tan et al. ([2023c](#bib.bib22)) or demonstrating their potential efficacy in
    future research Omar et al. ([2023b](#bib.bib14)); Tan et al. ([2023b](#bib.bib21)).
    Other studies on LLM-based KBQA concentrates on generating answers by prompt learning
    and incorporating external knowledge bases Baek et al. ([2023](#bib.bib2)); Tan
    et al. ([2023a](#bib.bib20)). Concurrently, LLMs can be deployed to address subtasks
    within a complex task. In the Text2SQL challenge, the work Li et al. ([2023a](#bib.bib10),
    [b](#bib.bib11)) attempts to utilize an LLM with graph-aware structural inductive
    bias or as a database interface to handle minor issues. In another recent studyDong
    et al. ([2023](#bib.bib3)), five distinct roles of mathematicians, enacted by
    an LLM, are introduced to collaboratively prove a theorem. Such research has spurred
    our exploration into the following question: Whether an LLM-based agent can solve
    KBQA tasks by serving as multiple roles.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最近关于 LLM 的 KBQA 研究主要集中在强调 LLM 生成完整事实结果的能力不足 Hu et al. ([2023b](#bib.bib6));
    Tan et al. ([2023c](#bib.bib22))，或展示其在未来研究中的潜在有效性 Omar et al. ([2023b](#bib.bib14));
    Tan et al. ([2023b](#bib.bib21))。其他关于 LLM 基于 KBQA 的研究则专注于通过提示学习生成答案并整合外部知识库 Baek
    et al. ([2023](#bib.bib2)); Tan et al. ([2023a](#bib.bib20))。与此同时，LLMs 可以被部署来处理复杂任务中的子任务。在
    Text2SQL 挑战中，Li et al. ([2023a](#bib.bib10), [b](#bib.bib11)) 的工作尝试利用带有图结构归纳偏置的
    LLM 或作为数据库接口来处理小问题。在另一项近期研究中，Dong et al. ([2023](#bib.bib3)) 引入了由 LLM 扮演的五种不同数学家角色来协作证明定理。这项研究激发了我们对以下问题的探索：基于
    LLM 的代理是否可以通过扮演多个角色来解决 KBQA 任务。
- en: 'In this study, we introduce Triad, a unified framework that leverages an LLM-based
    agent with three roles to address KBQA tasks. Specifically, we implement the agent
    consisting of an LLM as the core, supplemented by various task-specific modules
    such as memory and executing functions. The agent is assigned three distinct roles:
    a generalist (G-Agent) adept at mastering numerous small tasks by the given examples,
    a decision maker (D-Agent) proficient at identifying options and selecting candidates,
    and an advisor (A-Agent) skilled at providing answers using internal and external
    knowledge. The cooperation of these agent roles composes a KBQA process containing
    four phases: question parsing, URI linking, query construction, and answer generation.
    We evaluate our framework on three benchmark datasets in various difficulties.
    The results show that our framework outperforms state-of-the-art systems, demonstrated
    by 11.8% and 20.7% F1 scores on the LC-QuAD and YAGO-QA benchmarks, respectively.
    The contributions of this study can be summarized as follows.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们介绍了Triad，一个统一框架，利用基于LLM的代理通过三个角色来处理KBQA任务。具体来说，我们实现了以LLM为核心的代理，并辅以各种任务特定的模块，如记忆和执行功能。该代理被分配了三个不同的角色：通才（G-代理）擅长通过给定的示例掌握众多小任务，决策者（D-代理）擅长识别选项和选择候选者，以及顾问（A-代理）擅长利用内外部知识提供答案。这些代理角色的合作组成了一个包含四个阶段的KBQA过程：问题解析、URI链接、查询构建和回答生成。我们在三个具有不同难度的基准数据集上评估了我们的框架。结果表明，我们的框架超越了最先进的系统，在LC-QuAD和YAGO-QA基准测试中分别表现出11.8%和20.7%的F1分数。这项研究的贡献可以总结如下。
- en: •
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose Triad, the first framework that leverages an LLM-based agent to solve
    KBQA tasks in all its four phases, without specialized training models.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了Triad，这是第一个利用基于LLM的代理来解决KBQA任务的框架，涵盖所有四个阶段，无需专门的训练模型。
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We implement an LLM-based agent with various task-specific modules that can
    act as three roles, including a generalist, a decision maker, and an advisor,
    to collaboratively solve subtasks in KBQA.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们实现了一个基于LLM的代理，具备各种任务特定的模块，能够作为通才、决策者和顾问三种角色，共同解决KBQA中的子任务。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate the performance of our multi-role agent framework. The results show
    a competitive ability compared to both state-of-the-art KBQA systems and pure
    LLM methods¹¹1Code and datasets used to achieve the performance will be made public
    if the paper is accepted..
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们评估了我们的多角色代理框架的性能。结果显示，与最先进的KBQA系统和纯LLM方法相比，表现具有竞争力¹¹1代码和数据集将公开，如果论文被接受。.
- en: 2 Preliminaries
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 前提
- en: 2.1 Phases of KBQA
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 KBQA阶段
- en: 'A typical KBQA system has a process that encompasses four phases:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的KBQA系统包含四个阶段：
- en: Question parsing
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 问题解析
- en: involves converting natural language questions into a structured format that
    incorporates references to entities and relations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及将自然语言问题转换为包含实体和关系引用的结构化格式。
- en: URI linking
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: URI链接
- en: entails associating and replacing these entity and relation mentions with their
    corresponding URIs within a knowledge base.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 包括将这些实体和关系提及与知识库中的对应URI进行关联和替换。
- en: Query construction
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查询构建
- en: involves creating executable queries in a standard format to extract answers
    from knowledge bases.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及以标准格式创建可执行查询，以从知识库中提取答案。
- en: Answer generation
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回答生成
- en: seeks to obtain the ultimate answers either by performing queries within knowledge
    bases or by directly querying an agent.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在通过在知识库中执行查询或直接查询代理来获得*最终*答案。
- en: 2.2 Roles of LLM-based Agent
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于LLM的代理角色
- en: We employ an LLM-based agent to solve a series of subtasks by assuming three
    distinct roles, which collaboratively execute the four phases of KBQA.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用基于LLM的代理通过假设三种不同的角色来解决一系列子任务，这些角色协同执行KBQA的四个阶段。
- en: Agent as a generalist
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理作为通才
- en: (G-Agent) is capable of mastering various tasks, given a few examples.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: (G-代理)能够掌握各种任务，给定少量示例。
- en: Agent as a decision-maker
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理作为决策者
- en: (D-Agent) concentrates on the identification of options and the selection of
    candidates.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: (D-代理)专注于选项识别和候选者选择。
- en: Agent as an advisor
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理作为顾问
- en: (A-Agent) is skilled in answering questions with the aid of both external and
    internal knowledge.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: (A-代理)擅长在内外知识的帮助下回答问题。
- en: 2.3 Task Formulation
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 任务表述
- en: 'A KBQA task refers to the process of solving a set of subtasks $S$. The task
    can be formulated as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: KBQA任务指的是解决一组子任务$S$的过程。任务可以表述如下：
- en: '|  |  | $\displaystyle f(KBQA)=\mathop{\bigoplus}\limits_{t=1}^{T}f(S_{t})$
    |  | (1) |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle f(KBQA)=\mathop{\bigoplus}\limits_{t=1}^{T}f(S_{t})$
    |  | (1) |'
- en: '|  | $\displaystyle f(S_{t})=$ |  |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{t})=$ |  |'
- en: ', where $T$ is the way to coordinate subtasks to solve the whole.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $T$ 是协调子任务以解决整体的方式。
- en: 3 Triad Framework
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 三元组框架
- en: 'The overall architecture of Triad is shown in Figure [1](#S3.F1 "Figure 1 ‣
    3 Triad Framework ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent
    to Solve Knowledge Base Question Answering"). Each role of the LLM-based agent,
    along with its associated subtasks, is illustrated as follows.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 三元组的整体架构如图 [1](#S3.F1 "图 1 ‣ 3 三元组框架 ‣ 三元组：利用多角色 LLM 基于代理解决知识库问答") 所示。LLM 基于代理的每个角色及其相关的子任务如下所示。
- en: '![Refer to caption](img/bf1f84e415f603d660148dbe7785889e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bf1f84e415f603d660148dbe7785889e.png)'
- en: 'Figure 1: Our Triad framework leverages an LLM-based agent with three different
    roles including a generalist, a decision-maker, and an advisor to cooperatively
    handle a series of subtasks in the four phases of a KBQA process.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们的三元组框架利用基于 LLM 的代理，具备通才、决策者和顾问三种不同角色，以协同处理 KBQA 过程中的四个阶段的一系列子任务。
- en: 3.1 G-Agent as a Generalized Solver
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 G-Agent 作为一种通用解算器
- en: 'A generalized agent (G-Agent) proficiently manages numerous tasks by leveraging
    learning from limited examples through an LLM. In our framework, a G-Agent can
    perform question parsing, query template generation, or answer type classification
    as actions solely utilizing an LLM. These three subtasks are illustrated as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一种通用代理（G-Agent）通过利用有限示例的学习来高效管理众多任务。在我们的框架中，G-Agent 可以执行问题解析、查询模板生成或答案类型分类等操作，完全依赖
    LLM。这三种子任务如下所示：
- en: 'Triplet mention extraction:'
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 三元组提及提取：
- en: 'The process of extracting triplet mentions in question parsing involves the
    conversion of a naturally phrased question, denoted as $Q$, into formatted triplets
    of entities and relations. This subtask is executed employing an LLM, which is
    guided by a prompt with a set of prerequisites and a selection of examples. This
    subtask can be represented as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在问题解析中的三元组提取过程涉及将自然表述的问题 $Q$ 转换为格式化的实体和关系三元组。此子任务使用 LLM 执行，LLM 根据一组先决条件和示例的提示进行引导。该子任务可以表示为：
- en: '|  | $\displaystyle f(S_{tri})=$ |  | (2) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{tri})=$ |  | (2) |'
- en: '|  | $\displaystyle Pmt_{tri}=$ |  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Pmt_{tri}=$ |  |'
- en: ', where $Agent_{g}$ Kojima et al. ([2022](#bib.bib9)).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $Agent_{g}$ Kojima 等人 ([2022](#bib.bib9))。
- en: 'SPARQL template generation:'
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SPARQL 模板生成：
- en: 'The generation of SPARQL templates in query construction involves the use of
    an LLM to create a SPARQL template that articulates the question using standard
    SPARQL syntax, replacing URI identifiers with entity and relation variables. To
    derive precise and comprehensive answers from the knowledge base using SPARQL
    queries, there are two potential strategies. One approach involves the direct
    generation of an executable SPARQL using an LLM, though this method may significantly
    increase LLM call times and error rates when numerous candidate queries are in
    play. Alternatively, a SPARQL template can initially be generated with entity
    and relation variables, which are subsequently replaced with linked URIs. For
    the sake of stability and efficiency, we opt for the second strategy. This subtask
    can be denoted as:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询构建中生成 SPARQL 模板涉及使用 LLM 创建一个 SPARQL 模板，该模板使用标准 SPARQL 语法表达问题，将 URI 标识符替换为实体和关系变量。为了从知识库中通过
    SPARQL 查询得出准确且全面的答案，有两种潜在策略。一种方法是直接生成可执行的 SPARQL 查询，但当候选查询数量众多时，此方法可能会显著增加 LLM
    调用次数和错误率。另一种方法是首先生成带有实体和关系变量的 SPARQL 模板，然后用链接的 URI 进行替换。为了稳定性和效率，我们选择第二种策略。该子任务可以表示为：
- en: '|  | $\displaystyle f(S_{qt})=$ |  | (3) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{qt})=$ |  | (3) |'
- en: '|  | $\displaystyle Pmt_{qt}=$ |  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Pmt_{qt}=$ |  |'
- en: ', where $Agent_{g}$ to generate SPARQL template.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $Agent_{g}$ 用于生成 SPARQL 模板。
- en: 'Answer type classification:'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 答案类型分类：
- en: 'In the phase of answer generation, the answer type classification subtask refers
    to the process of assigning a specific category to a response according to the
    question. This process serves as a guiding mechanism for the framework to generate
    comprehensive and accurate answers. This classification subtask is denoted as:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在答案生成阶段，答案类型分类子任务指的是根据问题将响应分配到特定类别的过程。这个过程作为框架生成全面且准确答案的指导机制。这个分类子任务表示为：
- en: '|  | $\displaystyle f(S_{cls})=$ |  | (4) |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{cls})=$ |  | (4) |'
- en: '|  | $\displaystyle Pmt_{cls}=$ |  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Pmt_{cls}=$ |  |'
- en: ', where $Agent_{g}$.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ', 其中$Agent_{g}$。'
- en: 3.2 D-Agent as a Decision-Maker
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 D-Agent作为决策者
- en: 'An agent as a decision maker (D-Agent) is capable of making candidate selections
    step by step through filtering and choosing from given options, harnessing the
    capabilities of an LLM and KB as memory. The D-Agent can effectively handle three
    subtasks, which are delineated as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 作为决策者的代理（D-Agent）能够通过筛选和选择给定选项逐步做出候选选择，利用LLM和KB作为内存。D-Agent可以有效地处理三个子任务，具体如下：
- en: 'Candidate entity selection:'
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 候选实体选择：
- en: 'The selection of candidate entities in URI linking is pivotal to the ultimate
    efficacy of KBQA. Prior research has focused primarily on developing a semantic
    similarity model to address this linking challenge. However, the linking task
    requires numerous iterations of searching within the knowledge base, which poses
    a compatibility issue for LLM-oriented methods. In our framework, an agent as
    a decision maker is utilized initially to filter all potential entity URIs from
    the knowledge base, subsequently deploying an LLM to select candidate URIs from
    a pool of potential identifiers. For each entity, our aim is to find the $\mathcal{K}$
    most possible entity URIs which can be used to traverse over the KB to get the
    final answer. The entity selection subtask can be denoted as:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: URI链接中候选实体的选择对KBQA的**最终**效果至关重要。之前的研究主要集中在开发语义相似性模型以解决这一链接挑战。然而，链接任务需要在知识库中进行大量迭代搜索，这对面向LLM的方法提出了兼容性问题。在我们的框架中，首先利用作为决策者的代理从知识库中筛选所有潜在实体URI，然后使用LLM从潜在标识符池中选择候选URI。对于每个实体，我们的目标是找到最可能的$\mathcal{K}$个实体URI，用于在KB中遍历以获得最终答案。实体选择子任务可以表示为：
- en: '|  | $\displaystyle f(S_{es})=$ |  | (5) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{es})=$ |  | (5) |'
- en: '|  |  | $\displaystyle Pmt_{es},\theta_{es},\mathcal{K}),$ |  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{es},\theta_{es},\mathcal{K}),$ |  |'
- en: '|  | $\displaystyle Mem_{es}=$ |  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{es}=$ |  |'
- en: ', where $Agent_{d}$.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ', 其中$Agent_{d}$。'
- en: 'Candidate relation selection:'
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 候选关系选择：
- en: 'The task of candidate relation selection in URI linking presents considerable
    challenges due to the discrepancies between word forms and meanings. Nevertheless,
    the existence of reasoning paths in the knowledge base can be utilized to allow
    for a significant reduction of the search space in relation linking. In our framework,
    an agent as a decision maker endeavors to sieve through all potential relation
    URIs by navigating the knowledge base with candidate entity URIs generated from
    the previous subtask. Subsequently, an LLM is used to select the top $\mathcal{K}$
    most probable relation URIs for output. The relation selection subtask can be
    denoted as:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: URI链接中的候选关系选择任务面临重大挑战，因为单词形式和含义之间存在差异。然而，知识库中的推理路径可以用来显著减少关系链接中的搜索空间。在我们的框架中，作为决策者的代理通过使用从先前子任务生成的候选实体URI在知识库中筛选所有潜在的关系URI。随后，使用LLM选择最有可能的$\mathcal{K}$个关系URI作为输出。关系选择子任务可以表示为：
- en: '|  | $\displaystyle f(S_{rs})=$ |  | (6) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{rs})=$ |  | (6) |'
- en: '|  |  | $\displaystyle Pmt_{rs},\theta_{rs},\mathcal{K}),$ |  |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{rs},\theta_{rs},\mathcal{K}),$ |  |'
- en: '|  | $\displaystyle Mem_{rs}=$ |  |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{rs}=$ |  |'
- en: ', where memory $Mem_{rs}$ is the number of relation URIs selected by LLM.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ', 其中内存$Mem_{rs}$是LLM选择的关系URI数量。'
- en: 'Candidate SPARQL selection:'
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 候选SPARQL选择：
- en: 'The subtask of candidate SPARQL selection in query construction involves determining
    the appropriate SPARQL queries to obtain the final answers. Given a SPARQL template
    generated by the G-Agent, along with multiple candidate URIs selected from the
    D-Agent in previous subtasks, our D-Agent is targeted to identify the most plausible
    query. To further reduce the difficulty of selection, an executor function is
    applied to eliminate queries that cannot retrieve any results from the knowledge
    base. In conclusion, our aim in this subtask is to use D-Agent to construct executable
    SPARQLs and find the most possible one given a query candidate list with supported
    information. The SPARQL selection subtask can be denoted as:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询构造中，候选 SPARQL 选择的子任务涉及确定适当的 SPARQL 查询以获得最终答案。给定由 G-Agent 生成的 SPARQL 模板，以及从之前子任务中的
    D-Agent 选择的多个候选 URI，我们的 D-Agent 旨在识别最有可能的查询。为了进一步降低选择的难度，应用了执行函数以消除不能从知识库中检索任何结果的查询。总之，我们在该子任务中的目标是使用
    D-Agent 构建可执行的 SPARQL，并在给定的支持信息的查询候选列表中找到最可能的一个。SPARQL 选择子任务可以表示为：
- en: '|  | $\displaystyle f(S_{qs})=$ |  | (7) |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{qs})=$ |  | (7) |'
- en: '|  |  | $\displaystyle Pmt_{qs},\theta_{qs},\mathcal{K}),$ |  |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{qs},\theta_{qs},\mathcal{K}),$ |  |'
- en: '|  | $\displaystyle Mem_{qs}=$ |  |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{qs}=$ |  |'
- en: '|  | $\displaystyle\theta_{qs}=$ |  |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\theta_{qs}=$ |  |'
- en: ', where memory $Mem_{qs}$ is the number of queries selected by LLM.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中记忆 $Mem_{qs}$ 是 LLM 选择的查询数量。
- en: 3.3 A-Agent as a Comprehensive Advisor
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 A-Agent 作为综合顾问
- en: 'An advisory agent (A-Agent) is capable of processing a question and a corresponding
    type of answer as input. Its response is generated by either extracting information
    from an external knowledge base or by utilizing its internal knowledge to provide
    a direct answer. This comprehensive answering subtask can be described as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一个顾问代理（A-Agent）能够处理问题及相应类型的回答作为输入。其响应是通过从外部知识库中提取信息或利用其内部知识直接提供答案来生成的。这个综合回答子任务可以描述如下：
- en: 'Comprehensive answering:'
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 综合回答：
- en: 'The objective of comprehensive answering in the answer generation phase is
    to derive a definitive response based on an incoming question. Previous work Omar
    et al. ([2023b](#bib.bib14)) has demonstrated that LLMs are more proficient in
    delivering single-fact responses and making Boolean judgments. Given this understanding,
    we implement an advisory agent that incorporates a simple policy to facilitate
    a comprehensive answering approach. Specifically, if a question yields a final
    SPARQL generated from the preceding steps, A-Agent extracts elements from the
    knowledge base to give the answer. Conversely, if the agent does not receive a
    feasible SPARQL, A-Agent provides a direct response with LLM’s internal knowledge,
    following the prompt based on the type of the answer. Additionally, A-Agent will
    send a retry signal to previous phases if no result is generated. The subtask
    can be formulated as below:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 综合回答阶段的目标是在生成答案的过程中，根据输入的问题得出明确的回应。Omar 等人（[2023b](#bib.bib14)）的研究表明，LLMs 在提供单一事实的回答和进行布尔判断方面更为熟练。基于这一理解，我们实现了一个顾问代理，该代理结合了简单的策略来促进综合回答的方法。具体而言，如果一个问题产生了从前面的步骤生成的最终
    SPARQL，A-Agent 将从知识库中提取元素来给出答案。相反，如果代理未收到可行的 SPARQL，A-Agent 会根据答案类型使用 LLM 的内部知识提供直接回应。此外，如果没有生成结果，A-Agent
    会向之前的阶段发送重试信号。该子任务可以如下表示：
- en: '|  | $\displaystyle f(S_{ca})=$ |  | (8) |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{ca})=$ |  | (8) |'
- en: '|  |  | $\displaystyle Pmt_{ca},\theta_{ca},\mathcal{T}),$ |  |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{ca},\theta_{ca},\mathcal{T}),$ |  |'
- en: '|  | $\displaystyle Mem_{ca}=$ |  |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{ca}=$ |  |'
- en: ', where $Agent_{a}$.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $Agent_{a}$。
- en: 4 Experimental Evaluation
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验评估
- en: 4.1 Indexed Knowledge Bases
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 索引知识库
- en: The efficacy of our framework is assessed through the collection of two real
    knowledge bases, specifically DBpedia and YAGO. DBpedia Auer et al. ([2007](#bib.bib1))
    serves as an accessible knowledge base extracted from Wikipedia, while YAGO Pellissier Tanon
    et al. ([2020](#bib.bib16)) is a large knowledge base that includes individuals,
    cities, nations, and organizations. We index the triples and the mentions of entities
    and relations in a Virtuoso endpoint and an Elasticsearch server, respectively.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架通过收集两个实际知识库来评估其效果，具体为 DBpedia 和 YAGO。DBpedia Auer 等人（[2007](#bib.bib1)）作为一个从
    Wikipedia 提取的可访问知识库，而 YAGO Pellissier Tanon 等人（[2020](#bib.bib16)）是一个包含个人、城市、国家和组织的大型知识库。我们在
    Virtuoso 端点和 Elasticsearch 服务器中分别索引三元组和实体与关系的提及。
- en: 4.2 KBQA Benchmark Datasets
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 KBQA基准数据集
- en: 'We evaluate our framework on datasets including YAGO-QA, LC-QuAD 1.0, and QALD-9,
    which have various difficulties in interpreting the questions. These datasets
    contain questions in English, paired with their respective SPARQL queries, and
    accurate responses derived from a specific knowledge base. QALD-9 Usbeck et al.
    ([2018](#bib.bib24)) and LC-QuAD 1.0 Trivedi et al. ([2017](#bib.bib23)) are frequently
    used to evaluate QA systems in different versions of DBpedia. The recently published
    YAGO-QA in Omar et al. ([2023a](#bib.bib13)), features questions accompanied by
    annotated SPARQL queries and answers sourced from the YAGO. The statistics for
    three benchmarks, along with their associated knowledge bases, are depicted in
    Table [1](#S4.T1 "Table 1 ‣ 4.2 KBQA Benchmark Datasets ‣ 4 Experimental Evaluation
    ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering").'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在包括YAGO-QA、LC-QuAD 1.0和QALD-9的数据集上评估了我们的框架，这些数据集在解释问题时有不同的难度。这些数据集包含英语问题、相应的SPARQL查询以及从特定知识库中得出的准确回答。QALD-9
    Usbeck等([2018](#bib.bib24))和LC-QuAD 1.0 Trivedi等([2017](#bib.bib23))经常用于评估不同版本的DBpedia中的QA系统。最近发布的YAGO-QA
    Omar等([2023a](#bib.bib13))，特征为附带注释的SPARQL查询和来源于YAGO的答案。三个基准及其相关知识库的统计数据见表[1](#S4.T1
    "Table 1 ‣ 4.2 KBQA Benchmark Datasets ‣ 4 Experimental Evaluation ‣ Triad: A
    Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question
    Answering")。'
- en: 'Table 1: The statistics of KBQA benchmarks, including the number of questions
    number, the number of triples, the size of index in Virtuoso and Elasticsearch.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：KBQA基准的统计数据，包括问题数量、三元组数量、Virtuoso和Elasticsearch中的索引大小。
- en: '| Benchmarks | Benchmark Statistics |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 基准统计 |'
- en: '| #Questions | KB | #Triples | Virtuoso Size | ES size |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| #Questions | KB | #Triples | Virtuoso Size | ES size |'
- en: '| LC-QuAD 1.0 | 1000 | DBpedia-04 | 397M | 35.40G | 1.56G |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| LC-QuAD 1.0 | 1000 | DBpedia-04 | 397M | 35.40G | 1.56G |'
- en: '| QALD-9 | 150 | DBpedia-10 | 374M | 36.89G | 1.57G |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| QALD-9 | 150 | DBpedia-10 | 374M | 36.89G | 1.57G |'
- en: '| YAGO-QA | 100 | YAGO-4 | 207M | 24.85G | 0.54G |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| YAGO-QA | 100 | YAGO-4 | 207M | 24.85G | 0.54G |'
- en: 4.3 Baseline Methods
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基准方法
- en: We evaluate Triad against traditional KBQA systems such as KGQAN Omar et al.
    ([2023a](#bib.bib13)), EDGQA Hu et al. ([2021](#bib.bib8)) and gAnswer Hu et al.
    ([2018](#bib.bib7)). This comparison shows how our LLM-based agent framework can
    rival full-shot systems with just a few examples. Additionally, we contrast our
    framework with pure GPT models like GPT-3.5 Turbo and GPT-4 ²²2https://platform.openai.com/docs/models
    to exhibit Triad’s architectural performance. We treat these foundation models
    as few-shot methods to answer the questions referring to some examples.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将Triad与传统的KBQA系统进行比较，例如KGQAN Omar等([2023a](#bib.bib13))、EDGQA Hu等([2021](#bib.bib8))和gAnswer
    Hu等([2018](#bib.bib7))。这一比较展示了我们的LLM基础的代理框架如何仅用少量示例与全样本系统相抗衡。此外，我们将我们的框架与纯GPT模型如GPT-3.5
    Turbo和GPT-4²²2https://platform.openai.com/docs/models对比，以展示Triad的架构性能。我们将这些基础模型视为少量示例的方法来回答参考一些示例的问题。
- en: 4.4 Implementation Details
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 实现细节
- en: 'Triad is implemented with Python 3.9\. We incorporate LLM capabilities to our
    multi-role agent via OpenAI’s API services. The names of entities and relations
    from knowledge bases are indexed in an ElasticSearch 7.5.2 server for text matching.
    All triples are imported into an SPARQL endpoint of Virtuoso 07.20.3237 for traversal
    and retrieval. Triad requires four hyperparameters: the number of examples G-Agent
    uses for subtask learning, the number of candidates D-Agent selects for entity
    and relation linking, and the retry times for handling non-response SPARQLs. The
    optimal values for these parameters are 3, 2, 2, and 3, respectively. The framework
    and its variants are tested five times on each benchmark, with the average scores
    reported as the final results. For traditional systems, we report the results
    recorded in their papers. For pure LLM baselines, we write prompts to hire an
    LLM to answer questions directly referring to examples, and then link the mentions
    from the responses to the URIs in our indexed knowledge bases via built-in similarity
    search.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Triad 使用 Python 3.9 实现。我们通过 OpenAI 的 API 服务将 LLM 能力整合到我们的多角色代理中。来自知识库的实体和关系名称被索引在
    ElasticSearch 7.5.2 服务器上以进行文本匹配。所有三元组被导入到 Virtuoso 07.20.3237 的 SPARQL 端点以进行遍历和检索。Triad
    需要四个超参数：G-Agent 用于子任务学习的示例数量、D-Agent 选择的实体和关系链接候选数量，以及处理无响应 SPARQL 的重试次数。这些参数的最佳值分别是
    3、2、2 和 3。框架及其变体在每个基准上测试了五次，平均得分报告为最终结果。对于传统系统，我们报告其论文中记录的结果。对于纯 LLM 基线，我们编写提示来雇佣
    LLM 直接回答参考示例的问题，然后通过内置相似度搜索将响应中的提及链接到我们索引的知识库中的 URI。
- en: 4.5 Performance Comparison
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 性能比较
- en: 'The performance of Triad compared to traditional KBQA systems and pure LLM
    generation methods is shown in Table [2](#S4.T2 "Table 2 ‣ 4.5 Performance Comparison
    ‣ 4 Experimental Evaluation ‣ Triad: A Framework Leveraging a Multi-Role LLM-based
    Agent to Solve Knowledge Base Question Answering"). Evaluation metrics precision(P),
    recall(R), and F1-score(F1) are reported. We can observe from the experimental
    results that:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 'Triad 相对于传统的 KBQA 系统和纯 LLM 生成方法的性能如表 [2](#S4.T2 "Table 2 ‣ 4.5 Performance
    Comparison ‣ 4 Experimental Evaluation ‣ Triad: A Framework Leveraging a Multi-Role
    LLM-based Agent to Solve Knowledge Base Question Answering") 所示。评估指标包括精度（P）、召回率（R）和
    F1 分数（F1）。从实验结果中我们可以观察到：'
- en: 'Table 2: The performance of our Triad on three benchmarks, comparing with traditional
    KBQA systems (full-shot) and pure LLM (few-shot) baselines. The optimal and suboptimal
    scores are highlighted with bold and underlined text, respectively.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：我们 Triad 在三个基准上的表现，与传统 KBQA 系统（full-shot）和纯 LLM（few-shot）基线进行比较。最佳和次优得分分别用粗体和下划线文本突出显示。
- en: '| Type | Frameworks | LC-QuAD 1.0 | QALD-9 | YAGO-QA |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 框架 | LC-QuAD 1.0 | QALD-9 | YAGO-QA |'
- en: '| P | R | F1 | P | R | F1 | P | R | F1 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| P | R | F1 | P | R | F1 | P | R | F1 |'
- en: '| full-shot | gAnswer | - | - | - | 0.293 | 0.327 | 0.298 | 0.585 | 0.341 |
    0.430 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| full-shot | gAnswer | - | - | - | 0.293 | 0.327 | 0.298 | 0.585 | 0.341 |
    0.430 |'
- en: '|  | EDGQA | 0.505 | 0.560 | 0.531 | 0.313 | 0.403 | 0.320 | 0.419 | 0.408
    | 0.414 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|  | EDGQA | 0.505 | 0.560 | 0.531 | 0.313 | 0.403 | 0.320 | 0.419 | 0.408
    | 0.414 |'
- en: '|  | KGQAN | 0.587 | 0.461 | 0.516 | 0.511 | 0.387 | 0.441 | 0.485 | 0.652
    | 0.556 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  | KGQAN | 0.587 | 0.461 | 0.516 | 0.511 | 0.387 | 0.441 | 0.485 | 0.652
    | 0.556 |'
- en: '| few-shot | GPT-3.5 | 0.269 | 0.251 | 0.266 | 0.240 | 0.217 | 0.228 | 0.171
    | 0.142 | 0.155 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| few-shot | GPT-3.5 | 0.269 | 0.251 | 0.266 | 0.240 | 0.217 | 0.228 | 0.171
    | 0.142 | 0.155 |'
- en: '|  | GPT-4 | 0.336 | 0.344 | 0.340 | 0.250 | 0.249 | 0.249 | 0.193 | 0.190
    | 0.191 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT-4 | 0.336 | 0.344 | 0.340 | 0.250 | 0.249 | 0.249 | 0.193 | 0.190
    | 0.191 |'
- en: '|  | Triad-GPT3.5 | 0.490 | 0.519 | 0.504 | 0.293 | 0.302 | 0.297 | 0.660 |
    0.639 | 0.649 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '|  | Triad-GPT3.5 | 0.490 | 0.519 | 0.504 | 0.293 | 0.302 | 0.297 | 0.660 |
    0.639 | 0.649 |'
- en: '|  | Triad-GPT4 | 0.561 | 0.568 | 0.564 | 0.408 | 0.425 | 0.416 | 0.690 | 0.664
    | 0.677 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  | Triad-GPT4 | 0.561 | 0.568 | 0.564 | 0.408 | 0.425 | 0.416 | 0.690 | 0.664
    | 0.677 |'
- en: Few-shot can be competitive with full-shot.
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Few-shot 可以与 full-shot 竞争。
- en: Our multi-role LLM-based agent framework, though executing a few-shot prompt
    learning, exhibits competitive performance with cutting-edge full-shot KBQA systems.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的多角色 LLM 基于的代理框架执行了少量示例的提示学习，但其表现与最先进的 full-shot KBQA 系统具有竞争力。
- en: Underlying capability matters.
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础能力很重要。
- en: The use of GPT-4 as the core in an LLM-based agent significantly outperforms
    GPT-3.5 on all benchmarks, demonstrating the importance of the underlying capabilities
    of an agent.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 GPT-4 作为基于 LLM 的代理核心在所有基准上显著优于 GPT-3.5，证明了代理基础能力的重要性。
- en: Explicit knowledge is necessary.
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 显式知识是必要的。
- en: Pure LLM models with GPT-3.5 and GPT-4 display deficiencies in generating accurate
    responses without an auxiliary knowledge base as a memory for intermediary steps
    such as URI linking.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 纯 LLM 模型如 GPT-3.5 和 GPT-4 在生成准确响应时表现出缺陷，因为没有作为中介步骤（如 URI 链接）的辅助知识库。
- en: Performance varies with complexity.
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能随着复杂性而变化。
- en: Triad demonstrates superior results on the LC-QuAD and YAGO-QA benchmarks compared
    to QALD-9, due to an increasing failure in response to complex questions, which
    will be discussed later.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Triad 在 LC-QuAD 和 YAGO-QA 基准测试中的表现优于 QALD-9，原因是对复杂问题的响应失败增加，具体讨论将在后续进行。
- en: 4.6 Agent Role Ablation Study
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 代理角色消融研究
- en: 'We assess the efficacy of G-Agent with various other language models as the
    core. The framework without G-task uses the text-davinci-002, which is not as
    powerful as GPT-3.5 and GPT-4 in solving many tasks, and the one without G-chat
    uses text-davinci-003 to eliminate the chat and alignment abilities. We test the
    ability of D-Agent without D-uri and D-query by replacing the URI selection and
    query selection with URI matching and query generation, respectively. We evaluate
    the contribution of A-Agent eliminating A-llm and A-fact by responding to questions
    without using LLM’s assistance or use an LLM to answer Boolean questions for auxiliary
    rather than single-fact questions. The F1 results of the role ablation experiments
    are shown in Table [3](#S4.T3 "Table 3 ‣ 4.6 Agent Role Ablation Study ‣ 4 Experimental
    Evaluation ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve
    Knowledge Base Question Answering"). The results indicate that every component
    pertaining to each role contributes to the overall performance. More specifically,
    a G-Agent that employs a less powerful LLM as its core can drastically undermine
    performance. D-Agent assumes a more pivotal role during the linking phase compared
    to the query construction phase. A-Agent, on the other hand, proves to be an efficient
    solution for managing situations where SPARQL results are absent.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了以各种其他语言模型作为核心的 G-Agent 的效能。没有 G-task 的框架使用的是 text-davinci-002，其在解决许多任务时不如
    GPT-3.5 和 GPT-4 强大，而没有 G-chat 的框架使用 text-davinci-003，以消除聊天和对齐能力。我们通过将 URI 选择和查询选择分别替换为
    URI 匹配和查询生成，测试了没有 D-uri 和 D-query 的 D-Agent 的能力。我们通过在没有使用 LLM 的帮助下回答问题或使用 LLM
    来回答布尔问题而非单一事实问题，评估了消除 A-llm 和 A-fact 的 A-Agent 的贡献。角色消融实验的 F1 结果如表 [3](#S4.T3
    "表 3 ‣ 4.6 代理角色消融研究 ‣ 4 实验评估 ‣ 三合一：利用多角色 LLM 基于代理解决知识库问答") 所示。结果表明，每个角色相关的组件都对整体性能有贡献。更具体地说，采用能力较弱的
    LLM 作为核心的 G-Agent 会大幅削弱性能。D-Agent 在链接阶段比在查询构造阶段扮演更为关键的角色。另一方面，A-Agent 证明是管理 SPARQL
    结果缺失情况下的有效解决方案。
- en: 'Table 3: Ablation study on the roles of LLM-based agent by eliminating an element
    or downgrading the capability.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：通过消除一个元素或降低能力对基于LLM的代理角色进行的消融研究。
- en: '| G-task | G-chat | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| G-task | G-chat | LC-QuAD 1.0 | QALD-9 |'
- en: '| ✗ | ✗ | 0.343 | 0.159 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✗ | 0.343 | 0.159 |'
- en: '| ✓ | ✗ | 0.443 | 0.248 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.443 | 0.248 |'
- en: '| ✓ | ✓ | 0.564 | 0.416 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.564 | 0.416 |'
- en: '| D-uri | D-query | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| D-uri | D-query | LC-QuAD 1.0 | QALD-9 |'
- en: '| ✗ | ✓ | 0.274 | 0.210 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✓ | 0.274 | 0.210 |'
- en: '| ✓ | ✗ | 0.431 | 0.301 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.431 | 0.301 |'
- en: '| ✓ | ✓ | 0.564 | 0.416 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.564 | 0.416 |'
- en: '| A-llm | A-fact | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| A-llm | A-fact | LC-QuAD 1.0 | QALD-9 |'
- en: '| ✗ | ✗ | 0.459 | 0.382 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✗ | 0.459 | 0.382 |'
- en: '| ✓ | ✗ | 0.473 | 0.385 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.473 | 0.385 |'
- en: '| ✓ | ✓ | 0.564 | 0.416 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.564 | 0.416 |'
- en: 4.7 Role Hyperparameter Analysis
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 角色超参数分析
- en: 'We concentrate on three hyperparameters of roles, including the number of examples
    ($\mathcal{N}$) launched by A-Agent when there is no response. The space of hyperparameters
    is given as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们集中在角色的三个超参数上，包括在没有响应时 A-Agent 发起的示例数量 ($\mathcal{N}$)。超参数的空间如下：
- en: •
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Example numbers $\mathcal{N}$: {1,2,3}'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例数量 $\mathcal{N}$：{1,2,3}
- en: •
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'URI candidate numbers of entities and relations $\mathcal{K}$: {(1,1),(1,2),(2,2),(2,3)}'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实体和关系的 URI 候选数量 $\mathcal{K}$：{(1,1),(1,2),(2,2),(2,3)}
- en: •
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Retry times $\mathcal{T}$: {1,2,3}'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重试次数 $\mathcal{T}$：{1,2,3}
- en: 'Table [4](#S4.T4 "Table 4 ‣ 4.7 Role Hyperparameter Analysis ‣ 4 Experimental
    Evaluation ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve
    Knowledge Base Question Answering") presents the F1 results of Triad’s performance,
    employing three hyperparameters on two benchmarks. From the results, we discover
    that:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [4](#S4.T4 "表格 4 ‣ 4.7 角色超参数分析 ‣ 4 实验评估 ‣ Triad: 利用多角色 LLM 基于代理解决知识库问答")
    展示了 Triad 在两个基准测试中使用三种超参数的 F1 结果。从结果中我们发现：'
- en: 'Table 4: Performance evaluation on three hyperparameters that related to each
    role of an LLM-based agent.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 4：对与 LLM 基于代理的每个角色相关的三个超参数的性能评估。
- en: '| Triad Variants | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Triad 变体 | LC-QuAD 1.0 | QALD-9 |'
- en: '| Triad-1-Shot | 0.556 | 0.376 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Triad-1-Shot | 0.556 | 0.376 |'
- en: '| Triad-2-Shot | 0.511 | 0.402 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Triad-2-Shot | 0.511 | 0.402 |'
- en: '| Triad-3-Shot | 0.564 | 0.416 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| Triad-3-Shot | 0.564 | 0.416 |'
- en: '| Triad-Top1-1 | 0.528 | 0.281 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top1-1 | 0.528 | 0.281 |'
- en: '| Triad-Top1-2 | 0.562 | 0.375 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top1-2 | 0.562 | 0.375 |'
- en: '| Triad-Top2-2 | 0.564 | 0.416 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top2-2 | 0.564 | 0.416 |'
- en: '| Triad-Top2-3 | 0.558 | 0.384 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top2-3 | 0.558 | 0.384 |'
- en: '| Triad-1-Try | 0.529 | 0.375 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Triad-1-Try | 0.529 | 0.375 |'
- en: '| Triad-2-Tries | 0.561 | 0.407 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Triad-2-Tries | 0.561 | 0.407 |'
- en: '| Triad-3-Tries | 0.564 | 0.416 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Triad-3-Tries | 0.564 | 0.416 |'
- en: Quality is more important than quantity.
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 质量比数量更重要。
- en: More examples provided to G-Agent do not always improve the performance. The
    efficacy of G-Agent is significantly influenced by the quality of the provided
    examples.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 向 G-Agent 提供更多示例并不总能提高性能。G-Agent 的效能受到提供示例质量的显著影响。
- en: More options may harm the result.
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更多选项可能会影响结果。
- en: Choosing more candidate URIs for entities and relations could potentially disrupt
    subsequent query phases, thus affecting overall performance.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 选择更多候选 URI 可能会干扰后续查询阶段，从而影响整体性能。
- en: More chances benefits the framework.
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更多机会有利于框架。
- en: Persistently attempting to construct and execute SPARQL queries, despite the
    initial lack of results, is an effective strategy that improves the probability
    of obtaining accurate answers. Considering the efficiency of overall execution,
    we set the maximum retry times as 3 in practice.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管初始结果不佳，持续尝试构建和执行 SPARQL 查询是一种有效策略，可提高获取准确答案的概率。考虑到整体执行效率，我们在实践中将最大重试次数设置为
    3 次。
- en: 4.8 Linking Survival Analysis
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8 链接生存分析
- en: The process of linking is a relatively complex subtask in both the Text2SQL
    and the KBQA process Li et al. ([2023b](#bib.bib11)). Calculating the recall ratio
    of accurate URIs using D-Agent provides clarity on which step most adversely impacts
    performance. In the entity linking phase, considering all URIs of entities in
    the testing set as the ground truth of the linking results, 80\. 75% of the correct
    URIs are contained from the output of the entity matching filter in D-Agent and
    70\. 50% of the correct URIs are retained from the entity selection performed
    by the LLM in D-Agent. Whereas, in the relation linking phase, only 52\. 54% of
    the correct relation URIs survive from the selection of LLM, which indicates a
    greater difficulty in relation linking.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 链接过程在 Text2SQL 和 KBQA 过程中是一个相对复杂的子任务 Li 等（[2023b](#bib.bib11)）。通过 D-Agent 计算准确
    URI 的召回率可以明确哪个步骤对性能影响最大。在实体链接阶段，考虑测试集中的所有实体 URI 作为链接结果的真实值，D-Agent 中实体匹配过滤器的输出包含
    80.75% 的正确 URI，而 LLM 在 D-Agent 中执行的实体选择保留了 70.50% 的正确 URI。而在关系链接阶段，只有 52.54% 的正确关系
    URI 从 LLM 的选择中保留下来，这表明关系链接更具挑战性。
- en: 4.9 Complex Case Analysis
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.9 复杂案例分析
- en: 'Despite the impressive performance of Triad in certain benchmarks, notable
    deficiencies remain in its ability to understand questions and generate queries
    for complex questions. A critical analysis of unsuccessful cases in QALD-9, which
    has the lowest F1 score, has revealed three primary reasons for this failure,
    as detailed below:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Triad 在某些基准测试中表现出色，但其在理解问题和生成复杂问题查询方面仍存在显著缺陷。对 F1 分数最低的 QALD-9 中不成功案例的关键分析揭示了导致失败的三个主要原因，详见下文：
- en: 'Table 5: The major reasons of complexity that result in failures, with their
    corresponding ratios of occurrence in failed cases.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5：复杂性导致失败的主要原因及其在失败案例中的出现比例。
- en: '| Fail Reason | Ratio | Example |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 失败原因 | 比例 | 示例 |'
- en: '| Complex Syntax | 20% | Q42: Which countries have places with more than two
    caves? |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 复杂语法 | 20% | Q42: 哪些国家有超过两个洞穴的地方？ |'
- en: '| Unexploited Semantics | 17% | Q199: Give me all Argentine films. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 未开发的语义 | 17% | Q199: 给我所有阿根廷电影。 |'
- en: '| Implicit Reasoning | 5% | Q133: What are the names of the Teenage Mutant
    Ninja Turtles? |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 隐式推理 | 5% | Q133: 青少年忍者神龟的名字是什么？ |'
- en: Complex Syntax
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 复杂语法
- en: 'signifies that advanced SPARQL queries incorporate keywords such as GROUP BY
    and HAVING. These terms augment the error propensity in the generation of SPARQL
    templates such as the example: Which frequent flyer program has the most airlines?'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着高级SPARQL查询包含了如GROUP BY和HAVING等关键字。这些术语增加了生成SPARQL模板的错误倾向，例如：哪个常旅客计划拥有最多的航空公司？
- en: Unexploited Semantics
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 未开发的语义
- en: indicates that semantics of an implicit entity should be comprehended in order
    to exclude irrelevant URIs. In the example Give me all Argentine films, the meaning
    of films should be used to narrow down the scope of potential entities in order
    to eliminate unrelated answers.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 指出隐式实体的语义应被理解，以排除无关的URI。在示例中“给我所有的阿根廷电影”，电影的含义应被用于缩小潜在实体的范围，以排除无关的答案。
- en: Implicit Reasoning
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 隐式推理
- en: presents a challenge that requires a deeper level of traversal by the framework
    to deduce accurate results from the posed question. For example, another failure
    question, How many grand-children did Jacques Cousteau have?, the term grand-children
    must be interpreted to son of son to ensure an accurate response.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了一个挑战，要求框架进行更深层次的遍历以从提出的问题中推断出准确的结果。例如，对于另一个失败的问题，雅克·库斯托有多少个孙子？，术语孙子必须被解释为孙子的儿子以确保准确回答。
- en: 5 Related Work
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: 5.1 SPARQL-based and LLM-based KBQA
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 基于SPARQL和LLM的KBQA
- en: Traditional SPARQL-based KBQA methods transform natural language queries into
    SPARQL requests for data extraction. Various specific models are employed either
    for question understanding or URI linking, utilizing domain-based training datasets.
    Hu et al. ([2018](#bib.bib7)) introduces a semantic query graph to structurally
    represent the natural language query, thereby simplifying a SPARQL-based KBQA
    into a subgraph matching problem. Hu et al. ([2021](#bib.bib8)) proposes an entity
    description graph to represent natural language queries for question parsing and
    element linking. The most recent system Omar et al. ([2023a](#bib.bib13)) restructures
    the question parsing task as a text generation issue using a sequence-to-sequence
    model, as opposed to a rule-based transformation. With the advent of large language
    models (LLMs), certain phases of KBQA can be enhanced with LLM-integrated methods.
    Baek et al. ([2023](#bib.bib2)) aims to augment LLM-based QA tasks with pertinent
    facts extracted from knowledge bases, offering a fully zero-shot architecture.
    Tan et al. ([2023a](#bib.bib20)) leverages the general applicability of LLMs to
    filter linking candidates by making selections via few-shot in-context learning.
    Omar et al. ([2023b](#bib.bib14)) provides a thorough comparison between LLMs
    and QA systems in KBQA tasks, recommending further studies to improve the KBQA
    process with LLM capabilities. However, apart from the above studies, our investigation
    proposes a unified framework for KBQA tasks, which incorporates both an LLM and
    few-shot or zero-shot prompting from a systematic perspective.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的基于SPARQL的知识库问答（KBQA）方法将自然语言查询转换为SPARQL请求以提取数据。各种特定模型被用于问题理解或URI链接，利用领域特定的训练数据集。胡等人（[2018](#bib.bib7)）引入了一个语义查询图来结构性地表示自然语言查询，从而将基于SPARQL的KBQA简化为子图匹配问题。胡等人（[2021](#bib.bib8)）提出了一个实体描述图，用于表示自然语言查询以进行问题解析和元素链接。最新的系统奥马尔等人（[2023a](#bib.bib13)）将问题解析任务重构为一个文本生成问题，使用序列到序列模型，而不是基于规则的转换。随着大型语言模型（LLMs）的出现，KBQA的某些阶段可以通过集成LLM的方法得到增强。贝克等人（[2023](#bib.bib2)）旨在通过从知识库中提取相关事实来增强基于LLM的问答任务，提供了一个完全的零样本架构。谭等人（[2023a](#bib.bib20)）利用LLM的通用性，通过在上下文学习中进行少量样本选择来筛选链接候选项。奥马尔等人（[2023b](#bib.bib14)）对LLM和QA系统在KBQA任务中的表现进行了全面比较，并建议进一步研究以提升KBQA过程中的LLM能力。然而，除了上述研究，我们的调查提出了一个统一的KBQA任务框架，从系统的角度结合了LLM和少样本或零样本提示。
- en: 5.2 LLM-based Agents for Complex Tasks
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基于LLM的复杂任务代理
- en: LLMs have recently gained significant attention due to their ability to approximate
    human-level intelligence through the acquisition of vast amounts of web knowledge.
    This has led to numerous studies focusing on LLM-based agents. A recent surveyWang
    et al. ([2023](#bib.bib25)) proposes a unified architectural design for LLM-based
    agents, which consists of four modules that include profile, memory, plan, and
    action. CHATDBHu et al. ([2023a](#bib.bib5)) employs an LLM controller to generate
    SQL instructions, enabling it to manipulate databases, which allows for symbolic
    memory and complex multi-hop reasoning. ARTParanjape et al. ([2023](#bib.bib15))
    uses a frozen LLM to generate intermediate reasoning steps and further integrates
    tools for new tasks with minimal human intervention. ToolformerSchick et al. ([2023](#bib.bib17))
    takes a different approach by training an LLM to plan and execute tools for the
    next token prediction by learning API calls generation. ReActYao et al. ([2023](#bib.bib26))
    focuses on overcoming LLM hallucination by interacting with external knowledge
    bases, thus generating interpretable task-solving strategies. Divergent from the
    aforementioned research, our framework concentrates on the resolution of KBQA
    tasks by introducing a multi-role LLM-based agent that specializes in various
    types of subtask.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 近期，LLMs（大规模语言模型）因其通过获取大量网络知识来近似人类智能的能力而获得了显著关注。这导致了许多针对基于LLM的智能体的研究。最近的调研Wang
    et al. ([2023](#bib.bib25)) 提出了一个统一的LLM智能体架构设计，包含四个模块：配置、记忆、计划和行动。CHATDBHu et
    al. ([2023a](#bib.bib5)) 使用LLM控制器生成SQL指令，使其能够操作数据库，实现符号记忆和复杂的多跳推理。ARTParanjape
    et al. ([2023](#bib.bib15)) 使用冻结的LLM生成中间推理步骤，并进一步整合工具以处理新任务，且仅需最少的人为干预。ToolformerSchick
    et al. ([2023](#bib.bib17)) 采取了不同的方法，通过训练LLM来计划和执行工具以预测下一个标记，并学习API调用生成。ReActYao
    et al. ([2023](#bib.bib26)) 专注于通过与外部知识库互动来克服LLM的幻觉，从而生成可解释的任务解决策略。与上述研究不同，我们的框架专注于通过引入一个多角色LLM智能体来解决KBQA任务，该智能体专注于各种类型的子任务。
- en: 6 Conclusion
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this study, we aim to bridge the gap between KBQA tasks and the investigation
    of LLM-based agents. We introduce Triad, a unified framework to address the KBQA
    task through an LLM-based agent acting as three roles. This includes a generalist
    capable of mastering diverse tasks given minimal examples, a decision-maker concentrating
    on option identification and candidate selection, and an advisor skilled in answering
    questions with the aid of both external and internal knowledge. Triad achieves
    the best or competitive performance across three benchmark datasets compared to
    traditional KBQA systems trained on full-size QA data and pure LLM models. In
    future research, we plan to broaden our framework to handle more intricate scenarios,
    such as accommodating advanced queries and multi-hop implicit reasoning.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们旨在弥合KBQA任务与LLM智能体研究之间的差距。我们引入了Triad，一个统一的框架，通过一个扮演三种角色的LLM智能体来解决KBQA任务。这包括一个能够在最少示例下掌握各种任务的通才，一个专注于选项识别和候选选择的决策者，以及一个能够利用外部和内部知识回答问题的顾问。与传统的基于完整QA数据和纯LLM模型训练的KBQA系统相比，Triad在三个基准数据集上的表现最好或具有竞争力。在未来的研究中，我们计划拓展我们的框架，以处理更复杂的场景，例如适应高级查询和多跳隐性推理。
- en: Ethics Considerations
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理考虑
- en: All datasets utilized in this study are publicly available and we have adhered
    to ethical considerations by not introducing additional information as input during
    LLM training and LLM text generation.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中使用的所有数据集都是公开可用的，我们遵循了伦理考虑，没有在LLM训练和LLM文本生成过程中引入额外的信息作为输入。
- en: References
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Auer et al. (2007) Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann,
    Richard Cyganiak, and Zachary Ives. 2007. [Dbpedia: A nucleus for a web of open
    data](https://doi.org/https://doi.org/10.1007/978-3-540-76298-0_52). In *The Semantic
    Web*, pages 722–735, Berlin, Heidelberg. Springer Berlin Heidelberg.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Auer et al. (2007) Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann,
    Richard Cyganiak, 和 Zachary Ives. 2007. [Dbpedia: 开放数据网络的核心](https://doi.org/https://doi.org/10.1007/978-3-540-76298-0_52)。收录于
    *语义网*，第722–735页，柏林，海德堡。Springer Berlin Heidelberg。'
- en: Baek et al. (2023) Jinheon Baek, AlhamFikri Aji, and Amir Saffari. 2023. [Knowledge-augmented
    language model prompting for zero-shot knowledge graph question answering](https://doi.org/https://doi.org/10.48550/arXiv.2306.04136).
    *arXiv preprint arXiv:2306.04136*.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baek et al. (2023) Jinheon Baek, AlhamFikri Aji, 和 Amir Saffari. 2023. [知识增强语言模型提示用于零样本知识图谱问答](https://doi.org/https://doi.org/10.48550/arXiv.2306.04136)。*arXiv预印本
    arXiv:2306.04136*。
- en: 'Dong et al. (2023) Qingxiu Dong, Li Dong, Ke Xu, Guangyan Zhou, Yaru Hao, Zhifang
    Sui, and Furu Wei. 2023. Large language model for science: A study on p vs. np.
    *arXiv preprint arXiv:2309.05689*.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等人（2023）**董清修**、**董黎**、**徐可**、**周广彦**、**郝雅如**、**随志芳** 和 **魏福如**。2023年。大型语言模型在科学中的应用：对
    P 与 NP 的研究。*arXiv 预印本 arXiv:2309.05689*。
- en: Dong et al. (2022) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao
    Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. [A survey on in-context learning](https://doi.org/https://doi.org/10.48550/arXiv.2301.00234).
    *arXiv preprint arXiv:2301.00234*.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等人（2022）**董清修**、**李磊**、**戴达迈**、**郑策**、**吴智勇**、**常宝宝**、**孙旭**、**徐晶晶** 和
    **随志芳**。2022年。[关于上下文学习的调查](https://doi.org/https://doi.org/10.48550/arXiv.2301.00234)。*arXiv
    预印本 arXiv:2301.00234*。
- en: 'Hu et al. (2023a) Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao,
    and Hang Zhao. 2023a. [Chatdb: Augmenting llms with databases as their symbolic
    memory](https://doi.org/https://doi.org/10.48550/arXiv.2306.03901). *arXiv preprint
    arXiv:2306.03901*.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2023a）**胡晨旭**、**傅杰**、**杜辰庄**、**罗思敏**、**赵俊博** 和 **赵航**。2023a。[Chatdb：用数据库作为其符号记忆来增强
    LLM](https://doi.org/https://doi.org/10.48550/arXiv.2306.03901)。*arXiv 预印本 arXiv:2306.03901*。
- en: Hu et al. (2023b) Nan Hu, Yike Wu, Guilin Qi, Dehai Min, Jiaoyan Chen, Jeff Z
    Pan, and Zafar Ali. 2023b. [An empirical study of pre-trained language models
    in simple knowledge graph question answering](https://doi.org/https://doi.org/10.1007/s11280-023-01166-y).
    *World Wide Web*, pages 1–32.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2023b）**胡楠**、**吴宜克**、**祁桂林**、**闵德海**、**陈娇颜**、**Jeff Z Pan** 和 **扎法尔·阿里**。2023b。[预训练语言模型在简单知识图谱问答中的实证研究](https://doi.org/https://doi.org/10.1007/s11280-023-01166-y)。*世界广网*，第
    1–32 页。
- en: Hu et al. (2018) Sen Hu, Lei Zou, Jeffrey Xu Yu, Haixun Wang, and Dongyan Zhao.
    2018. [Answering natural language questions by subgraph matching over knowledge
    graphs](https://doi.org/10.1109/tkde.2017.2766634). *IEEE Transactions on Knowledge
    and Data Engineering*, page 824–837.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2018）**胡森**、**邹磊**、**许杰弗里·余**、**王海勋** 和 **赵冬燕**。2018年。[通过子图匹配知识图谱回答自然语言问题](https://doi.org/10.1109/tkde.2017.2766634)。*IEEE
    知识与数据工程汇刊*，第 824–837 页。
- en: 'Hu et al. (2021) Xixin Hu, Yiheng Shu, Xiang Huang, and Yuzhong Qu. 2021. [Edg-based
    question decomposition for complex question answering over knowledge bases](https://doi.org/10.1007/978-3-030-88361-4_8).
    In *The Semantic Web – ISWC 2021: 20th International Semantic Web Conference,
    ISWC 2021, Virtual Event, October 24–28, 2021, Proceedings*, page 128–145, Berlin,
    Heidelberg. Springer-Verlag.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2021）**胡锡鑫**、**舒艺恒**、**黄翔** 和 **屈宇忠**。2021年。[基于 EDG 的复杂问题回答中的问题分解](https://doi.org/10.1007/978-3-030-88361-4_8)。见于
    *语义网 – ISWC 2021：第 20 届国际语义网会议，ISWC 2021，虚拟会议，2021年10月24–28日，会议论文集*，第 128–145
    页，柏林，海德堡。Springer-Verlag。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://doi.org/https://doi.org/10.48550/arXiv.2205.1191).
    *Advances in neural information processing systems*, 35:22199–22213.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）**小岛武史**、**Shixiang Shane Gu**、**Machel Reid**、**Yutaka Matsuo**
    和 **Yusuke Iwasawa**。2022年。[大型语言模型是零-shot 推理器](https://doi.org/https://doi.org/10.48550/arXiv.2205.1191)。*神经信息处理系统的进展*，35:22199–22213。
- en: 'Li et al. (2023a) Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao
    Ma, Nan Huo, Fei Huang, Wenyu Du, Luo Si, and Yongbin Li. 2023a. [Graphix-t5:
    Mixing pre-trained transformers with graph-aware layers for text-to-sql parsing](https://doi.org/https://doi.org/10.48550/arXiv.2301.07507).
    *arXiv preprint arXiv:2301.07507*.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2023a）**李金阳**、**徐斌远**、**郑锐诺**、**秦博文**、**马晨浩**、**霍楠**、**黄飞**、**杜文宇**、**罗思**
    和 **李永彬**。2023a。[Graphix-t5：将预训练的变压器与图感知层结合用于文本到 SQL 解析](https://doi.org/https://doi.org/10.48550/arXiv.2301.07507)。*arXiv
    预印本 arXiv:2301.07507*。
- en: Li et al. (2023b) Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen
    Li, Bailin Wang, Bowen Qin, Rongyu Cao, Ruiying Geng, Nan Huo, Chenhao Ma, KevinC.C.
    Chang, Fei Huang, Reynold Cheng, and Yongbin Li. 2023b. [Can llm already serve
    as a database interface? a big bench for large-scale database grounded text-to-sqls](https://doi.org/https://doi.org/10.48550/arXiv.2305.03111).
    *arXiv preprint arXiv:2305.03111*.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2023b）**李金阳**、**徐斌远**、**郭戈**、**李彬华**、**杨佳熙**、**李博文**、**王百林**、**秦博文**、**曹荣宇**、**耿瑞英**、**霍楠**、**马晨浩**、**KevinC.C.
    Chang**、**黄飞**、**郑锐诺** 和 **李永彬**。2023b。[大型语言模型是否已经能作为数据库接口？大规模数据库基础文本到 SQL 的大基准](https://doi.org/https://doi.org/10.48550/arXiv.2305.03111)。*arXiv
    预印本 arXiv:2305.03111*。
- en: 'Liu et al. (2023) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al.
    2023. [Bolaa: Benchmarking and orchestrating llm-augmented autonomous agents](https://doi.org/https://doi.org/10.48550/arXiv.2308.05960).
    *arXiv preprint arXiv:2308.05960*.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2023) Zhiwei Liu、Weiran Yao、Jianguo Zhang、Le Xue、Shelby Heinecke、Rithesh
    Murthy、Yihao Feng、Zeyuan Chen、Juan Carlos Niebles、Devansh Arpit 等人。2023。 [Bolaa:
    基准测试和协调 llm 增强的自主代理](https://doi.org/https://doi.org/10.48550/arXiv.2308.05960)。
    *arXiv 预印本 arXiv:2308.05960*。'
- en: Omar et al. (2023a) Reham Omar, Ishika Dhall, Panos Kalnis, and Essam Mansour.
    2023a. [A universal question-answering platform for knowledge graphs](https://doi.org/10.1145/3588911).
    *Proceedings of the ACM on Management of Data*, 1(1):1–25.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Omar 等人 (2023a) Reham Omar、Ishika Dhall、Panos Kalnis 和 Essam Mansour。2023a。
    [一个通用的知识图谱问答平台](https://doi.org/10.1145/3588911)。 *ACM 数据管理会议论文集*，1(1):1–25。
- en: 'Omar et al. (2023b) Reham Omar, Omij Mangukiya, Panos Kalnis, and Essam Mansour.
    2023b. [Chatgpt versus traditional question answering for knowledge graphs: Current
    status and future directions towards knowledge graph chatbots](https://doi.org/https://doi.org/10.48550/arXiv.2302.06466).
    *arXiv preprint arXiv:2302.06466*.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Omar 等人 (2023b) Reham Omar、Omij Mangukiya、Panos Kalnis 和 Essam Mansour。2023b。
    [Chatgpt 与传统知识图谱问答的对比：知识图谱聊天机器人现状与未来方向](https://doi.org/https://doi.org/10.48550/arXiv.2302.06466)。
    *arXiv 预印本 arXiv:2302.06466*。
- en: 'Paranjape et al. (2023) Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh
    Hajishirzi, Luke Zettlemoyer, and MarcoTulio Ribeiro. 2023. [Art: Automatic multi-step
    reasoning and tool-use for large language models](https://doi.org/https://doi.org/10.48550/arXiv.2303.09014).
    *arXiv preprint arXiv:2303.09014*.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Paranjape 等人 (2023) Bhargavi Paranjape、Scott Lundberg、Sameer Singh、Hannaneh
    Hajishirzi、Luke Zettlemoyer 和 MarcoTulio Ribeiro。2023。 [Art: 自动化多步骤推理与工具使用的语言模型](https://doi.org/https://doi.org/10.48550/arXiv.2303.09014)。
    *arXiv 预印本 arXiv:2303.09014*。'
- en: 'Pellissier Tanon et al. (2020) Thomas Pellissier Tanon, Gerhard Weikum, and
    Fabian Suchanek. 2020. [Yago 4: A reason-able knowledge base](https://doi.org/https://doi.org/10.1007/978-3-030-49461-2_34).
    In *The Semantic Web*, pages 583–596, Cham. Springer International Publishing.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pellissier Tanon 等人 (2020) Thomas Pellissier Tanon、Gerhard Weikum 和 Fabian
    Suchanek。2020。 [Yago 4: 一个合理的知识库](https://doi.org/https://doi.org/10.1007/978-3-030-49461-2_34)。
    收录于 *语义网*，第583–596页，Cham。Springer 国际出版公司。'
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. [Toolformer:
    Language models can teach themselves to use tools](https://doi.org/https://doi.org/10.48550/arXiv.2302.04761).
    *arXiv preprint arXiv:2302.04761*.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick 等人 (2023) Timo Schick、Jane Dwivedi-Yu、Roberto Dessì、Roberta Raileanu、Maria
    Lomeli、Luke Zettlemoyer、Nicola Cancedda 和 Thomas Scialom。2023。 [Toolformer: 语言模型可以自我教授使用工具](https://doi.org/https://doi.org/10.48550/arXiv.2302.04761)。
    *arXiv 预印本 arXiv:2302.04761*。'
- en: 'Shen et al. (2023) Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. 2023. [Hugginggpt: Solving ai tasks with chatgpt and its
    friends in huggingface](https://doi.org/https://doi.org/10.48550/arXiv.2303.17580).
    *arXiv preprint arXiv:2303.17580*.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shen 等人 (2023) Yongliang Shen、Kaitao Song、Xu Tan、Dongsheng Li、Weiming Lu 和
    Yueting Zhuang。2023。 [Hugginggpt: 利用 chatgpt 和 Huggingface 的朋友们解决 ai 任务](https://doi.org/https://doi.org/10.48550/arXiv.2303.17580)。
    *arXiv 预印本 arXiv:2303.17580*。'
- en: 'Shinn et al. (2023) Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023. [Reflexion:
    an autonomous agent with dynamic memory and self-reflection](https://doi.org/https://doi.org/10.48550/arXiv.2303.11366).
    *arXiv preprint arXiv:2303.11366*.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn 等人 (2023) Noah Shinn、Beck Labash 和 Ashwin Gopinath。2023。 [Reflexion:
    一个具有动态记忆和自我反思的自主代理](https://doi.org/https://doi.org/10.48550/arXiv.2303.11366)。
    *arXiv 预印本 arXiv:2303.11366*。'
- en: Tan et al. (2023a) Chuanyuan Tan, Yuehe Chen, Wenbiao Shao, Wenliang Chen, Zhefeng
    Wang, Baoxing Huai, and Min Zhang. 2023a. [Make a choice! knowledge base question
    answering with in-context learning](https://doi.org/https://doi.org/10.48550/arXiv.2305.13972).
    *arXiv preprint arXiv:2305.13972*.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人 (2023a) Chuanyuan Tan、Yuehe Chen、Wenbiao Shao、Wenliang Chen、Zhefeng Wang、Baoxing
    Huai 和 Min Zhang。2023a。 [做出选择！基于上下文学习的知识库问答](https://doi.org/https://doi.org/10.48550/arXiv.2305.13972)。
    *arXiv 预印本 arXiv:2305.13972*。
- en: Tan et al. (2023b) Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen,
    and Guilin Qi. 2023b. [Can chatgpt replace traditional kbqa models? an in-depth
    analysis of the question answering performance of the gpt llm family](https://doi.org/https://doi.org/10.48550/arXiv.2303.07992).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人 (2023b) Yiming Tan、Dehai Min、Yu Li、Wenbo Li、Nan Hu、Yongrui Chen 和 Guilin
    Qi。2023b。 [Chatgpt 能否取代传统 kbqa 模型？对 gpt llm 系列问答性能的深入分析](https://doi.org/https://doi.org/10.48550/arXiv.2303.07992)。
- en: Tan et al. (2023c) Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen,
    and Guilin Qi. 2023c. [Evaluation of chatgpt as a question answering system for
    answering complex questions](https://doi.org/https://doi.org/10.48550/arXiv.2303.0799).
    *arXiv preprint arXiv:2303.07992*.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等 (2023c) Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen,
    和 Guilin Qi. 2023c. [评估 chatgpt 作为回答复杂问题的问答系统](https://doi.org/https://doi.org/10.48550/arXiv.2303.0799)。*arXiv
    预印本 arXiv:2303.07992*。
- en: 'Trivedi et al. (2017) Priyansh Trivedi, Gaurav Maheshwari, Mohnish Dubey, and
    Jens Lehmann. 2017. [Lc-quad: A corpus for complex question answering over knowledge
    graphs](https://doi.org/https://doi.org/10.1007/978-3-319-68204-4_22). In *The
    Semantic Web – ISWC 2017*, pages 210–218, Cham. Springer International Publishing.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Trivedi 等 (2017) Priyansh Trivedi, Gaurav Maheshwari, Mohnish Dubey, 和 Jens
    Lehmann. 2017. [Lc-quad: 一个用于知识图谱复杂问答的语料库](https://doi.org/https://doi.org/10.1007/978-3-319-68204-4_22)。在
    *The Semantic Web – ISWC 2017*，第 210–218 页，Cham。Springer International Publishing。'
- en: Usbeck et al. (2018) Ricardo Usbeck, Ria Hari Gusmita, Axel-Cyrille Ngonga Ngomo,
    and Muhammad Saleem. 2018. [9th challenge on question answering over linked data
    (qald-9) (invited paper)](https://doi.org/https://api.semanticscholar.org/CorpusID:53220210).
    In *Semdeep/NLIWoD@ISWC*.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Usbeck 等 (2018) Ricardo Usbeck, Ria Hari Gusmita, Axel-Cyrille Ngonga Ngomo,
    和 Muhammad Saleem. 2018. [第 9 届针对链接数据问答的挑战 (qald-9) (邀请论文)](https://doi.org/https://api.semanticscholar.org/CorpusID:53220210)。在
    *Semdeep/NLIWoD@ISWC*。
- en: Wang et al. (2023) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023. [A survey
    on large language model based autonomous agents](https://doi.org/https://doi.org/10.48550/arXiv.2308.11432).
    *arXiv preprint arXiv:2308.11432*.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等 (2023) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin 等. 2023. [基于大型语言模型的自主体综述](https://doi.org/https://doi.org/10.48550/arXiv.2308.11432)。*arXiv
    预印本 arXiv:2308.11432*。
- en: 'Yao et al. (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2023. [React: Synergizing reasoning and acting
    in language models](https://doi.org/https://doi.org/10.48550/arXiv.2210.03629).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等 (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik
    Narasimhan, 和 Yuan Cao. 2023. [React: 协同推理和语言模型中的行动](https://doi.org/https://doi.org/10.48550/arXiv.2210.03629)。'
- en: Appendix A Prompts Provided to LLMs of G-Agent for Solving Various Subtasks
    in KBQA
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 提供给 G-Agent 的 LLMs 用于解决 KBQA 中各种子任务的提示
- en: 'The prompt given to LLMs of $Agent_{g}$ is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 给 $Agent_{g}$ 的 LLMs 提供的提示如下：
- en: 'You are an assistant to identify triples within a provided sentence. Please
    adhere to the following guidelines: 1\. Triples should be structured in the format
    . 2\. The sentence must contain at least one triple,
    so you should provide at least one. 3\. Entities should represent the smallest
    semantic units and should not contain descriptive details. 4\. Entities can take
    the form of explicit or implicit references. Explicit entities refer to specific
    named resources, whereas implicit entities are less certain. 5\. When an entity
    is implicit, utilize a variable format such as ’?variable’ to denote it, for example,
    ’?location’ or ’?person’. Here are some examples: Which city’s founder is John
    Forbes? : <?city, foundeer, John Forbes> How many races have the horses bred by
    Jacques Van’t Hart participated in? : <?horse, participated in, ?race> <?horse,
    breeder, Jacques Van’t Hart> Is camel of the chordate phylum? :  Sentence:  Output:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '你是一个助手，负责识别句子中的三元组。请遵循以下指南：1. 三元组应按  格式结构化。2. 句子中必须包含至少一个三元组，因此你应提供至少一个。3.
    实体应表示最小的语义单位，不应包含描述性细节。4. 实体可以是显式或隐式引用。显式实体指特定命名的资源，而隐式实体则不那么确定。5. 当实体是隐式时，使用变量格式如
    ‘?variable’ 来表示，例如 ‘?location’ 或 ‘?person’。以下是一些示例：哪个城市的创始人是 John Forbes? : <?city,
    founder, John Forbes> 被 Jacques Van’t Hart 培育的马参加了多少场比赛？ : <?horse, participated
    in, ?race> <?horse, breeder, Jacques Van’t Hart> 骆驼属于脊索动物门吗？ :  句子： 输出：'
- en: 'The prompt given to LLMs of $Agent_{g}$ for SPARQL template generation is as
    follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 给 $Agent_{g}$ 的 LLMs 生成 SPARQL 模板的提示如下：
- en: 'You are an assistant to generate a SPARQL query to address a specific question.
    Here are the guidelines to follow: 1\. Ensure that the resulting SPARQL query
    is designed to answer the provided question. 2\. Adhere to the commonly accepted
    SPARQL standards when generating the query. 3\. Make an effort to leverage the
    information provided to assist in the creation of the SPARQL query. 4\. Strive
    to keep the generated SPARQL query as straightforward as possible. 5\. Avoid including
    ’PREFIX’ or ’:’ in the SPARQL query. 6\. Enclose condition entities and predicates
    within angle brackets, such as  or . 7\. Maintain the original
    order of the given triples without altering their sequence. Question:  Triplets:  Output:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责生成一个SPARQL查询以解决特定问题。请遵循以下指南：1\. 确保生成的SPARQL查询旨在回答提供的问题。2\. 在生成查询时遵守常见的SPARQL标准。3\.
    努力利用提供的信息来协助创建SPARQL查询。4\. 尽量保持生成的SPARQL查询简洁。5\. 避免在SPARQL查询中包含’PREFIX’或’：’。6\.
    将条件实体和谓词用尖括号括起来，如或。7\. 保持给定三元组的原始顺序，不改变其顺序。问题： 三元组：
    输出：
- en: 'The prompt given to LLMs of $Agent_{g}$ for question type classification is
    as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 给$Agent_{g}$的LLMs用于问题类型分类的提示如下：
- en: 'You are an assistant to determine the specific type of a given question according
    to the following guidelines: 1\. You must determine the most probable question
    type for the input question. 2\. The type of question should be enclosed within
    angle brackets, denoted as ’<’ and ’>’. 3\. Possible question types include: ,
    , and . Question:  Output:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，按照以下指南来确定给定问题的具体类型：1\. 你必须确定输入问题最可能的类型。2\. 问题的类型应当用尖括号括起来，表示为’<’和’>’。3\.
    可能的问题类型包括：，，和 。问题： 输出：
- en: Appendix B Prompts Provided to LLMs of D-Agent for Solving Selection Subtasks
    in KBQA
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 提供给D-Agent的LLMs用于解决KBQA选择子任务的提示
- en: 'The prompt given to LLMs of $Agent_{d}$ for candidate entities selection is
    as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 给$Agent_{d}$的LLMs用于候选实体选择的提示如下：
- en: 'You are an assistant to select  URIs from a provided list of possible URIs
    for a specified entity, following these guidelines: 1\. Identify the  most
    appropriate URIs from the given list that best represent the entity in question.
    2\. Seek to understand the semantic information associated with the specified
    entity by examining the provided question. 3\. The output should consist of 
    URIs chosen from the provided list of possible URIs. 4\. Simply output these 
    target URIs, each on a separate line, without providing any additional explanations.
    Sentence:  Entity:  Possible entity URIs:  Output:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，从提供的可能URI列表中选择个URI，以表示特定实体，遵循以下指南：1\. 从给定列表中识别出最适合表示该实体的个URI。2\.
    通过检查提供的问题来理解指定实体的语义信息。3\. 输出应包含从提供的可能URI列表中选择的个URI。4\. 只需输出这个目标URI，每个URI占一行，不提供任何额外说明。句子：
    实体： 可能的实体URI： 输出：
- en: 'The prompt given to LLMs of $Agent_{d}$ for candidate relation selection is
    as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 给$Agent_{d}$的LLMs用于候选关系选择的提示如下：
- en: 'You are an assistant tasked with selecting the  relation URIs between entities
    mentioned in a sentence. Here are the guidelines: 1\. The two entities are listed
    one after the other, without a specific order. 2\. Use the provided sentence to
    discern the semantic meaning of these entities. 3\. The potential relation URIs
    are listed one by one. 4\. Your output should consist of a maximum of  possible
    relation URIs, although you may also output fewer if appropriate. 5\. Ensure that
    your output is organized, prioritizing the most likely relationship first. 6\.
    Provide a list of no more than  relation URIs (each on a separate line if there
    are multiple) without any additional descriptions. Sentence: 
    Entities:  Possible relation URIs:  Output:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责选择句子中提到的实体之间的个关系URI。以下是指南：1\. 两个实体按顺序列出，没有特定顺序。2\. 使用提供的句子来辨别这些实体的语义意义。3\.
    可能的关系URI逐一列出。4\. 你的输出应包括最多个可能的关系URI，但如果适当，也可以输出更少。5\. 确保你的输出有序，优先考虑最可能的关系。6\.
    提供不超过个关系URI的列表（如果有多个，每行一个），不提供任何额外描述。句子： 实体： 可能的关系URI： 输出：
- en: 'The prompt given to LLMs of $Agent_{d}$ for the final SPARQL selection is as
    follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: $Agent_{d}$ 的提示词，用于最终的 SPARQL 选择，如下所示：
- en: 'You are an assistant to select an appropriate SPARQL query from the provided
    list in order to respond to a specific question. Please adhere to the following
    guidelines: 1\. Select the most suitable SPARQL query from the given query list
    to address the question. 2\. Select a SPARQL query solely from the provided list;
    avoid crafting your own SPARQL query. 3\. The selected SPARQL query must be applicable
    to answer the given question. Sentence:  SPARQL candidates:
     Output:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，从提供的列表中选择一个合适的 SPARQL 查询以回应特定问题。请遵守以下指南：1\. 从给定的查询列表中选择最合适的 SPARQL 查询以解决该问题。2\.
    仅从提供的列表中选择 SPARQL 查询；避免自己编写 SPARQL 查询。3\. 选择的 SPARQL 查询必须适用于回答给定的问题。句子： SPARQL 候选： 输出：
- en: Appendix C Prompt Provided to LLMs of A-Agent for Solving Answering Subtask
    in KBQA
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 提供给 A-Agent 的 LLMs 的提示，用于解决 KBQA 中的回答子任务
- en: 'The prompt given to LLMs of $Agent_{a}$ to generate a yes or no answer for
    the give question is as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: $Agent_{a}$ 的提示词，用于生成给定问题的“是”或“否”答案，如下所示：
- en: 'You are an assistant to answer a yes-or-no question. Please adhere to the following
    guidelines: 1\. If you believe that the answer is yes, provide an output of ’True’.
    If not, provide an output of ’False’. 2\. Please do not include additional information
    or explanations in your response. Sentence:  Output:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个回答“是”或“否”问题的助手。请遵守以下指南：1\. 如果你认为答案是“是”，请输出’True’。否则，请输出’False’。2\. 请不要在你的回答中包含额外的信息或解释。句子： 输出：
- en: 'The prompt given to LLMs of $Agent_{a}$ to generate a single-fact answer for
    the give question is as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: $Agent_{a}$ 的提示词，用于生成单一事实答案，如下所示：
- en: 'You are an assistant to answer a question. Please adhere to the following guidelines:
    1\. The answer to the question is a single entity. 2\. You should just output
    the full expression of the answer without any punctuation. 3\. Do not output any
    other description. Sentence:  Output:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手来回答问题。请遵守以下指南：1\. 问题的答案是一个单一实体。2\. 你应只输出答案的完整表达式，不带任何标点符号。3\. 不要输出任何其他描述。句子： 输出：
