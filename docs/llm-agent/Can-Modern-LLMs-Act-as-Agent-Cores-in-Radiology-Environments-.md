<!--yml

类别：未分类

日期：2025-01-11 11:48:45

-->

# 现代LLM能否作为放射学环境中的代理核心？

> 来源：[https://arxiv.org/html/2412.09529/](https://arxiv.org/html/2412.09529/)

Qiaoyu Zheng 上海交通大学 上海人工智能实验室 Chaoyi Wu 上海交通大学 上海人工智能实验室 Pengcheng Qiu 上海交通大学 上海人工智能实验室 Lisong Dai 武汉大学人民医院 放射科 Ya Zhang 上海交通大学 上海人工智能实验室 Yanfeng Wang 上海交通大学 上海人工智能实验室 Weidi Xie 上海交通大学 上海人工智能实验室

###### 摘要

大型语言模型（LLMs）的进展为基于LLM的代理系统铺平了道路，这些系统在多个领域提供了增强的准确性和可解释性。放射学由于其复杂的分析需求，是这些代理应用的理想领域。本文旨在探讨构建具体放射学代理所需的前提问题：“现代LLM能否作为放射学环境中的代理核心？”为了探讨这一问题，我们介绍了RadABench，并做出三项重要贡献：首先，我们提出了RadABench-Data，这是一个全面的综合评估数据集，专为LLM代理生成，涵盖了包括6种解剖学、5种影像学模式、10类工具和11个放射学任务的广泛分类体系。其次，我们提出了RadABench-EvalPlat，这是一个新颖的代理评估平台，具有基于提示的工作流程，并能够模拟多种放射学工具集。第三，我们从5个维度、通过多项指标评估了7个领先LLM在我们的基准测试上的表现。我们的研究发现，虽然当前LLM在许多领域展现出了强大的能力，但它们仍然不够成熟，无法作为完全运营的放射学代理系统中的核心代理。此外，我们还识别了影响LLM代理核心表现的关键因素，为临床医生提供了如何有效地在实际放射学实践中应用代理系统的见解。我们的所有代码和数据都已开源，网址：[https://github.com/MAGIC-AI4Med/RadABench](https://github.com/MAGIC-AI4Med/RadABench)。

## 1 引言

大型语言模型（LLMs）的最新进展在人工智能（AI）的多个领域引发了革命性变化，从自然语言处理[[1](https://arxiv.org/html/2412.09529v2#bib.bib1), [2](https://arxiv.org/html/2412.09529v2#bib.bib2), [3](https://arxiv.org/html/2412.09529v2#bib.bib3)]到计算机视觉[[4](https://arxiv.org/html/2412.09529v2#bib.bib4), [5](https://arxiv.org/html/2412.09529v2#bib.bib5), [6](https://arxiv.org/html/2412.09529v2#bib.bib6)]。像GPT-4、Gemini和LLaMA这样的模型拓展了机器理解和生成的边界[[3](https://arxiv.org/html/2412.09529v2#bib.bib3), [7](https://arxiv.org/html/2412.09529v2#bib.bib7), [8](https://arxiv.org/html/2412.09529v2#bib.bib8)]。在这些突破中，基于LLM的智能体系统的出现[[9](https://arxiv.org/html/2412.09529v2#bib.bib9), [10](https://arxiv.org/html/2412.09529v2#bib.bib10), [11](https://arxiv.org/html/2412.09529v2#bib.bib11), [12](https://arxiv.org/html/2412.09529v2#bib.bib12), [13](https://arxiv.org/html/2412.09529v2#bib.bib13), [14](https://arxiv.org/html/2412.09529v2#bib.bib14)]尤其值得注意。这些系统展示了一个中央智能体核心与外部工具交互的能力，使得执行复杂的多步骤任务成为可能，并在客户服务、商业自动化和创意内容生成等领域展现出了显著的潜力。这一成功归功于精准性、可解释性和可扩展性的结合，这些特点增强了LLM在现实世界应用中的效用。

尽管这些变革性的进展，LLM在临床环境中的应用——特别是在放射学中的应用——仍处于初期阶段[[15](https://arxiv.org/html/2412.09529v2#bib.bib15), [16](https://arxiv.org/html/2412.09529v2#bib.bib16)]。放射学是医学诊断的核心，要求对来自医学影像的详细文本报告和复杂视觉数据进行解读[[17](https://arxiv.org/html/2412.09529v2#bib.bib17), [18](https://arxiv.org/html/2412.09529v2#bib.bib18), [19](https://arxiv.org/html/2412.09529v2#bib.bib19), [20](https://arxiv.org/html/2412.09529v2#bib.bib20)]。最近，放射学通用模型[[4](https://arxiv.org/html/2412.09529v2#bib.bib4), [21](https://arxiv.org/html/2412.09529v2#bib.bib21), [22](https://arxiv.org/html/2412.09529v2#bib.bib22), [23](https://arxiv.org/html/2412.09529v2#bib.bib23), [24](https://arxiv.org/html/2412.09529v2#bib.bib24), [25](https://arxiv.org/html/2412.09529v2#bib.bib25), [26](https://arxiv.org/html/2412.09529v2#bib.bib26)]在处理多种放射学分析时显示出潜力，能够在一个框架中运行。然而，放射学的复杂性——涵盖了多种成像模式、多样的病理学和复杂的解读标准——可能超出了任何单一全能模型的能力。这种复杂性使得放射学成为基于代理的系统的理想领域，在这里，专门化的工具（或模型）可以协作工作，提供更强大和更精确的分析[[27](https://arxiv.org/html/2412.09529v2#bib.bib27)]。

本研究解决了开发基于代理的放射学分析系统的一个基本前提。具体来说，我们提出了以下问题：

> 现有的LLM是否能够有效地与放射学环境互动——理解专业的医学工具描述，准确地将多样的临床查询转化为可执行的步骤，并调用工具依次执行子任务？

为了探索这个问题，我们引入了RadABench（放射学代理基准），它作为评估基于LLM的放射学代理的综合资源。具体来说，它有三个主要贡献：（1）我们提出了一个专门为评估基于LLM的放射学代理而设计的新数据集，包含合成患者、工具和任务。（2）我们开发了一个新颖的评估平台，专门用于评估放射学特定的LLM代理。该平台建立了一个通用的基于提示的代理工作流程，并模拟了多种外部放射学工具集，具有可变和动态的条件。（3）我们提供了对7个最先进的LLM模型的全面性能分析，包括封闭源模型（GPT-4、GPT-4o、Gemini、Claude）和开源模型（LLaMA、Mixtral、Qwen）。我们系统设计的评估指标评估了五个关键能力：链式规划、最优工具编排、输入/输出组织、响应合成和不可解解析。

构建的数据集，称为 RadABench-Data，采用系统的方法确保广泛覆盖。我们首先开发了一个全面的分类法，将患者记录按 6 个解剖区域（如胸部、大脑、脊柱）和 5 种影像学方式（如 X 光、CT、MRI）组合的 22 种常见解剖学-影像学配对进行分类。对于每对解剖学-影像学组合，我们选择了 100 种常见疾病，结果得到了 2,200 条患者记录，每条记录代表一种独特的与放射学相关的病症。此外，我们定义了 10 个常用的放射学工具类别，并结合了 11 个放射学任务分解元链，系统地生成了 24,200 对问答。所有数据都经过放射科医生的临床验证，以确保其准确性和代表性。

RadABench-EvalPlat 是一个专门的评估平台，旨在模拟复杂的临床场景，反映实际放射科医生的决策过程。该平台采用基于提示的三阶段工作流程，系统地评估 LLM 作为代理核心的能力，重点评估其解读临床查询、选择合适工具以及在这些多样且具有挑战性的场景中管理任务执行的能力。此外，我们设计了一种动态工具集模拟策略，捕捉现实世界放射学条件下面临的各种挑战，涵盖了 10 个不同的工具类别，包括器官分割、疾病诊断、报告生成及其他放射学任务。

为了严格评估 7 个领先 LLM 作为代理核心的表现，我们采用了一个评估框架，强调五个关键方面：链式规划（比较预测的规划和真实的规划）、最优协调（评估适当工具的选择）、输入输出组织（确保正确的输入/输出格式）、响应合成（评估生成响应的质量）以及不可解解析（识别无法解决的任务）。针对每个方面，我们设计了专门的度量标准，确保进行全面且多维度的评估。

尽管像 GPT-4o 和 Claude 3.5-Sonnet 这样的最先进模型在某些简单任务中表现出色，但我们的分析揭示了在面对更复杂的临床场景时存在显著的差距。这些发现强调了当前大型语言模型（LLM）能力与现实世界放射学应用严格要求之间的巨大差距。它们还突出了开发基于代理的放射学系统的更广泛挑战。为了加速进展，我们已公开发布了我们的数据集和评估代码。

## 2 结果

本节中，我们将详细介绍RadABench框架和基准测试。首先，我们介绍RadABench-Data，全面概述其在各种放射学病例中的范围和覆盖情况。接下来，我们详细说明RadABench-EvalPlat，概述其核心工作流程和动态工具集模拟策略。这些内容共同确保对评估条件和标准有清晰的理解。最后，我们报告7种领先的大语言模型的定量结果，从多个角度审视它们的表现——决策规划、执行精度、拒绝意识、选择优化和响应合成，并突出展示我们的基准测试揭示的关键优点、局限性和趋势。

### 2.1 RadABench-Data介绍

RadABench-Data涵盖了一套全面的放射学分类法，包括病人记录、工具和任务。基于该分类法，我们模拟了2200条合成病人记录，并使用问答对来基准测试作为代理核心的大语言模型的能力。下面，我们将详细介绍每个数据组件。

病人记录分析

这里的“病人记录”指的是以放射学为中心的医学记录，包括病人基本信息、病史、标注的影像数据（包含解剖和病理细节）以及广泛的临床发现。我们根据解剖学、影像学方法和疾病对病人记录进行分类。此分类法涵盖了22种常见的解剖-影像组合，这些组合来源于6个解剖区域和5种影像学方法：

> 头颈部：{X光、CT、MRI、超声}; 胸部：{X光、CT、MRI、超声};
> 
> 四肢：{X光、CT、MRI、超声}; 腹部和盆腔：{X光、CT、MRI、超声};
> 
> 脊柱：{X光、CT、MRI}; 乳房：{乳腺X光、MRI、超声}。

对于每种组合，我们选择100种常见疾病，这些疾病可通过相应的影像学检查方法进行检测。使用GPT-4，我们为每个叶节点生成一条病人记录，最终得到2200条记录（22种解剖-影像组合 $\times$ 100种疾病）。每条记录由一位具有10年以上经验的放射科医生进行验证。关于生成和验证的详细信息，请参见“方法”部分。示例病人记录请参阅附加文件。

![请参见说明文字](img/9dfecd968f654945eccd5427feddd301.png)

图1：RadA-Bench中的统计数据。a. 不同解剖区域的病人性别分布。b-d. 不同年龄/身高/体重范围下的六个解剖区域的病人记录分布。e. BioLORD提取的异常/疾病/生物标志物/指标的特征分布。f. 11个任务分解链，包括工具类别覆盖、工具链长度和令牌/字符数量。g. 在8种模拟条件下可用工具的数量范围。h. 在8种模拟条件下，使用GPT-4o/Llama-3.1-405B作为代理核心的上下文令牌长度。i. 不同开源和闭源大语言模型的最大令牌长度。

图 [1](https://arxiv.org/html/2412.09529v2#S2.F1 "Figure 1 ‣ 2.1 Introduction to RadABench-Data ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")a-d 显示了这些合成患者记录在各个人口因素（包括性别、年龄、身高和体重）上的分布。值得注意的是，虽然数据集在性别上总体上是平衡的，但与乳腺相关的病例主要是女性，因为这些病例的临床发生率较高。年龄分布集中在中年群体（35-70岁），反映了典型的临床模式。身高和体重的分布呈现正态分布，进一步确认了数据集的现实性和多样性。

图 [1](https://arxiv.org/html/2412.09529v2#S2.F1 "Figure 1 ‣ 2.1 Introduction to RadABench-Data ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")e 可视化了患者记录中的异常、疾病、生物标志物和指标。在这里，“生物标志物”指的是影像特征（例如，维度、纹理），而“指标”则对应于临床分类（例如，癌症分期）或评分系统（例如，CURB-65）。我们使用BioLORD [[28](https://arxiv.org/html/2412.09529v2#bib.bib28)] 嵌入这些属性，并通过t-SNE绘制它们，揭示了均匀分布，并确认我们的数据集覆盖了广泛的临床场景。

总结来说，RadABench-Data中的合成患者记录展示了强大的临床多样性，并与现实世界的医疗背景紧密契合。这些记录为评估LLM代理核心在管理复杂放射学任务中的表现提供了坚实的基础。

放射学工具分析

与临床实践一致，我们将放射学工具分为10个高级类别（详细信息请参见附加文件）：解剖分类器（AC）、模态分类器（MC）、器官分割器（OS）、异常检测器（AD）、影像诊断器（ID）、合成诊断器（SD）、生物标志物量化器（BQ）、指标评估器（IE）、报告生成器（RG）和治疗推荐器（TR）。

每个工具都通过“工具卡”进行描述，工具卡概述了工具的类别、属性、能力、必选输入、可选输入和性能。每个组件的值是通过在临床合理范围内随机抽样得到的。例如，类别可能是“解剖分类器”，而性能值则可能是从0到100的数值评分。这种方法使我们理论上能够生成无限数量的工具，涵盖广泛的放射学场景，并确保评估保持具有挑战性。生成过程的详细信息请参见“方法”部分。

放射学任务分析

为了全面评估基于大语言模型（LLM）的代理系统，我们开发了一个放射学任务分类法，包含11个不同的任务（在补充文件中有详细说明）：(a) 器官遮罩标注，(b) 异常区域标注，(c) 器官级生物标志物计算，(d) 异常级生物标志物计算，(e) 器官与异常级图像解读，(f) 无视觉线索的疾病诊断，(g) 有视觉线索的疾病诊断，(h) 常见报告生成，(i) 专注于特定生物标志物的报告生成，(j) 专注于特定生物标志物和指标的报告生成，(k) 治疗计划制定。我们进一步将每个任务细分为一系列工具类别步骤（如图[1](https://arxiv.org/html/2412.09529v2#S2.F1 "Figure 1 ‣ 2.1 Introduction to RadABench-Data ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")f)所示）。每个任务涉及3到9个工具类别，反映了不同的复杂性水平。涉及更多工具类别的任务需要更复杂的推理和规划。

对于每一条2,200个患者记录，我们为11个任务中的每个任务创建一个仿真实例，共生成24,200个问答对（2,200条记录 $\times$ 11个任务）。例如，一条患者记录可能会提出问题“可以推断出什么疾病？”用于诊断任务，或“请为该图像撰写一份放射学报告。”用于报告生成任务。这些问答对在所有任务中均匀分布，确保了平衡的代表性和多样性。所有问答对都经过人工验证。生成和验证过程的详细信息在“方法”部分中提供。

### 2.2 RadABench-EvalPlat简介

本节介绍RadABench-EvalPlat，首先描述其主要工作流的构建，然后介绍我们的动态工具集仿真策略，用于全面评估。

![参见说明](img/e2361d5afd1c9c15dd94a18a420610f9.png)

图2：我们评估平台的概览。我们通过动态组合10个不同的工具类别及其相应的属性，构建了4个类别和8个具体的医疗条件。基于不同的工具集，我们开发了一个三阶段的代理核心工作流来评估LLMs。通过有针对性的分析，评估代理核心响应的质量，涵盖5个能力维度。

主要工作流构建

一般来说，典型的基于LLM的代理系统包含三个主要组件：基于LLM的代理核心（$\Phi$），一组外部专用工具（$\mathcal{T}={t_{1},t_{2},\ldots,t_{m}}$），以及一个记忆库（$\mathcal{B}$）。代理核心协调工作流，选择并执行一系列适当的工具，而记忆库存储中间输出和上下文信息。给定一个临床查询$\mathcal{Q}$和患者的历史信息，系统遵循一个三步过程来生成最终响应：

+   •

    任务分解。智能体核心（$\Phi$）首先将临床查询分解成一系列与工具集$\mathcal{T}$能力相匹配的可管理子任务。同时，内存库$\mathcal{B}$会初始化关键信息——如患者的基本信息、病史以及每个工具执行的输出——确保相关数据在整个过程中始终可用。

+   •

    工具选择与执行。在任务分解和内存库$\mathcal{B}$中存储的上下文的引导下，智能体核心为每个子任务选择最合适的工具，并准备其输入。一旦工具产生输出，结果会被存储在$\mathcal{B}$中。在每次迭代后，智能体核心会评估是否已充分解决整体查询。如果是，则终止过程；否则，继续选择和执行工具，直到任务完成。

+   •

    响应生成。最后，智能体核心综合所有存储在$\mathcal{B}$中的相关历史数据，组织信息以回应临床查询。通过整合各个工具的输出并将其置于原始查询的上下文中，智能体核心生成连贯且可操作的最终响应。

详细示例。考虑一个临床场景，其中智能体系统需要根据患者的基本信息（例如年龄、体重、主要症状）、放射学检查扫描以及自由文本诊断查询（如：“请基于患者的所有信息做出诊断”）提供诊断。

在任务分解阶段，智能体核心将该查询分为四个子步骤：识别解剖区域和成像方式，应用器官分割和异常检测工具，最终推断疾病类型。接下来，在工具选择与执行阶段，智能体系统地从工具集$\mathcal{T}$中选择最合适的工具。每个工具的输出都记录在内存库$\mathcal{B}$中，使得智能体能够迭代地优化解决方案，直到子任务完成。在最终的响应生成阶段，智能体将存储在$\mathcal{B}$中的患者详情、分割结果和诊断推断整合在一起，生成一个连贯且全面的响应。

我们本研究的目标是评估各种大型语言模型（LLMs）在此类工作流中作为核心智能体的有效性，控制多个工具并处理各种放射学任务。在接下来的部分中，我们将描述如何组装评估所需的工具集。

动态工具集模拟

我们在动态工具集模拟中的目标是确保，在评估过程中，我们所考虑的工具集能够反映各种真实世界的临床情境。例如，这些情境可能包括缺少必要工具的情况，或是多个工具可以用于类似任务但表现不同的情况。

具体来说，针对某个患者记录和特定查询，我们遵循以下原则来形成不同的评估条件：

+   •

    NS. （必要且充分）条件。相关工具集包括一个最小的工具集，其中每个工具类别都包含一个综合工具，确保用户查询可以通过工具解决。这测试了代理的基本工具链规划和执行能力。

+   •

    SNN. （充分但不必要）条件。相关工具集比查询所需的工具更多，包含冗余工具。此条件可以进一步分为三个冗余级别——常规、中等和大规模——随着冗余工具数量的增加。这评估了代理在嘈杂环境中选择相关工具的能力。

+   •

    NR. （必要但不充分）条件。相关工具集缺少完成查询所需的必要工具。它有三个难度级别：Denyl1，缺少工具类别；Denyl2，缺少模态/解剖学特定工具；Denyl3，缺少必需的详细疾病/异常工具。这评估了代理识别限制并在关键工具不可用时作出适当回应的能力。

+   •

    OPT. （最优）条件。相关工具集提供多个具有重叠能力但性能水平不同的工具，代理核心需要挑选出表现更好的工具进行执行。这评估了代理从相似替代工具中选择最佳性能工具的能力。

这种仿真方法确保动态生成的工具集全面反映了各种评估条件，有效评估了LLM代理核心的不同能力。在“方法部分”，我们将介绍每个条件的更多实施细节。

在图[1](https://arxiv.org/html/2412.09529v2#S2.F1 "Figure 1 ‣ 2.1 Introduction to RadABench-Data ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")g中，我们展示了在不同条件下模拟工具集的规模。对于NS条件，如图所示，无论患者记录和任务查询如何变化，工具集大小保持不变。具体而言，该条件下有一个固定的12工具集，涵盖所有10个工具类别，其中生物标志物定量器和指标评估器类别各有两个工具（一个用于器官，一个用于异常评估）。对于三个SNN条件，常规和中等级别的工具数量根据特定的患者记录和查询而有所不同——常规包括必要的工具，并且每个类别最多有一个额外的不可用工具（12-15个工具），而中等则在每个类别中添加2-3个额外的工具，超出任务特定的模态和解剖学要求（27-34个工具）。相比之下，大型条件通过包括所有可能的工具组合，跨越模态、解剖学和工具可选输入，保持一个固定（尽管很大）的工具集大小，无论特定的患者记录和任务如何。对于三个NR条件，我们根据不同的患者记录和QA任务类型构建无法解决的工具集。在Denyl1和Denyl2中，工具数量会有所变化（14-17个工具），这取决于缺少哪些关键组件——例如，在Denyl1中，去除器官分割工具会使得器官生物标志物定量任务无法完成。相比之下，Denyl3保持固定大小（18个工具），因为它专注于修改特定工具功能，而不是移除整个工具或类别。在OPT条件下，我们为特定类别创建了不同性能水平的多个工具，基于特定任务（*例如*，具有不同准确率的诊断工具）。这导致工具集更大（17-18个工具），相比NS条件，工具选择选项根据不同任务而有所变化。这些统计数据可以间接表示在不同条件下工具集理解的复杂性。

### 2.3 RadABench的定量分析

在本节中，我们展示了各种作为代理核心的LLM的主要定量结果。此分析着重于它们分解复杂放射影像任务的能力，以及有效利用多种医疗工具生成准确和最佳响应的能力。评估是基于以下几个关键维度进行的：

响应令牌长度分析

首先，我们分析了不同LLM的响应令牌长度，以评估现代模型的上下文窗口限制是否会影响它们在放射学环境中作为代理核心的使用。

如图[1](https://arxiv.org/html/2412.09529v2#S2.F1 "图 1 ‣ 2.1 RadABench-数据介绍 ‣ 2 结果 ‣ 现代LLM能否在放射学环境中充当智能体核心？")h所示，我们展示了由两种LLM（GPT-4o和Llama-3.1）生成的多轮响应令牌长度，分别代表封闭源和开源模型。在大多数情况下，这两种模型的总令牌长度相当，范围从3,000到30,000个令牌。然而，在NR. Deny条件下，GPT-4o的上下文长度明显长于Llama，主要是由于Llama经常未能执行正确的拒绝响应，导致过早终止。图[1](https://arxiv.org/html/2412.09529v2#S2.F1 "图 1 ‣ 2.1 RadABench-数据介绍 ‣ 2 结果 ‣ 现代LLM能否在放射学环境中充当智能体核心？")k进一步比较了不同LLM的最大支持令牌长度与我们条件下观察到的最高令牌需求。虽然GPT-3.5（上一代模型）难以处理完整的上下文长度，但所有其他最先进的模型都能有效应对。

这些发现表明，现代LLM的上下文窗口足够大，可以支持基于智能体的应用程序。这确保了我们后续的评估结果不受过长上下文的影响，并确认了我们分析的可靠性，符合当前LLM的能力。

![参见说明](img/913b99f01479653d57a4a30d1d37e0ac.png)

图3：在NS.条件和SNN.条件下的评估结果。 a. 在NS.条件下，7种LLM之间决策、执行和真实工具链的Levenshtein距离。b-c. 在SNN.常规条件下的Levenshtein距离、虚假发现率、工具匹配率、执行完成率、预失败成功百分比值。d-e. 在SNN.中等条件下的相同指标。f-g. 在SNN.大条件下的相同指标。

链规划能力分析

在此，为了分析智能体核心将复杂任务分解为适当的工具链并通过多次迭代保持规划一致性的能力，我们采用了Levenshtein距离（LD），该指标测量生成链与真实链之间的最小编辑步骤。虚假发现率（FDR）表示错误包含的工具比例，工具匹配精度（TMA）评估生成链与真实链在位置上的匹配比率。此评估是在NS.tool set条件和SNN.tool set条件下进行的。

如图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")所示，我们可以得出以下观察结论：1) 封闭源模型通常在NS.和SNN.条件下优于开源模型（Llama-3.1-405B除外），封闭源模型在NS.条件下实现的LD（规划与真实情况之间的差异小于1.5，平均需要1.5次编辑以匹配真实情况链条），如图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")a所示——考虑到平均链条长度为5步，这代表着相对较好的性能；2) 如图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")a所示，在多次迭代执行过程中，计划链与执行链之间出现差异，其中模型能够调整工具选择——Claude-3.5和LLama-3.1趋向于与真实情况链条一致，而其他模型则保持或增加偏差；3) 如图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")c、e和g所示，GPT-4o在SNN.常规、SNN.中等和SNN.大条件下的FDR（假阳性率）低于其他LLMs，表明其工具选择冗余较低；4) GPT-4o和Claude-3.5相比其他LLMs，在每个规划过程步骤中的位置对齐与真实情况工具链一致性较高，表现出更高的TMA；5) 当比较图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")b、d和f时，随着工具集条件复杂性的增加，所有LLMs表现出显著的性能下降，尤其是开源模型。

![参见图注](img/34e55ff6f5ec27560c65126e1b648c5e.png)

图4：在SNN.条件和OPT.条件下的评估结果。a. 在SNN.常规、SNN.中等和SNN.大条件下7个LLMs的目标命中率。b. 包括最优工具评分和里程碑命中率的工具链级结果，在OPT.条件下的7个LLMs。c. 在OPT.条件下，7个LLMs的自由文本最终响应级别结果，包括F1、BLEU和ROUGE评分。

最优协调能力分析

为了评估代理核心从多个候选工具中选择最优工具的能力，我们采用了最优工具评分（OTS），该评分通过比较所选工具的性能排名与可用替代工具的排名来进行评估。评估是在OPT.工具集条件下进行的。

从图[4](https://arxiv.org/html/2412.09529v2#S2.F4 "Figure 4 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")b中，我们可以观察到，大多数LLM在OPT条件下能够有效选择最优工具并成功执行核心任务步骤。特别是，Gemini-1.5-Pro在OTS上取得了最佳表现，得分为0.720，而开源的Qwen-2.5也取得了相当接近的成绩0.701，表明它们在多种工具可选时具备优越的能力，能够选择性能更高的工具。

输入输出组织能力分析

为了分析智能体核心在执行过程中管理顺序工具间数据流的能力，我们采用执行完成率（Execution Completion Rate，ECR）来衡量无I/O错误的链条完成情况，并采用预失败成功百分比（Pre-Failure Success Percentage，PFSP）来计算在失败案例中失败前的进度比例。此处的评估是在SNN工具集条件下进行的。

我们对数据流管理做出以下观察：1) 如图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")c和d所示，Claude-3.5-sonnet在所有三个SNN条件下的ECR表现优越（常规条件和中等条件分别为0.795和0.737），特别是它展示了相较于其他LLM显著更好的执行可靠性；2) 在SNN常规和SNN中等条件下，一半以上的LLM的PFSP得分超过0.5，表明即便它们未能完成整个任务，仍然能够成功执行工具链中的大部分步骤，然后才会遇到失败；3) 如图[3](https://arxiv.org/html/2412.09529v2#S2.F3 "Figure 3 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")e所示，随着工具集上下文的增加，所有LLM在ECR和PFSP指标上的表现都出现急剧下降，特别是在大型条件下，表明在复杂工具集条件下管理数据流存在显著挑战；4) Mixtral在所有三种条件下的表现始终较差，表明其在精准组织和管理工具之间的输入输出关系方面能力有限。

响应合成分析

为了分析智能体核心跟随推荐解决方案路径并生成适当响应的能力，我们采用目标命中率（Target Hit Rate，THR）来衡量最终工具是否与所需答案格式一致，里程碑命中率（Milestone Hit Rate，MHR）来评估有价值的中间输出，并采用包括BLEU、ROUGE和F1在内的多种文本相似性指标，从不同方面评估生成输出与参考输出之间的质量匹配。此评估在SNN工具集条件和OPT工具集条件下进行。

根据我们的分析，我们可以得出以下观察结果：1）从图[4](https://arxiv.org/html/2412.09529v2#S2.F4 "图4 ‣ 2.3 RadABench定量分析 ‣ 2 结果 ‣ 现代LLM能否在放射学环境中作为代理核心？")a中，我们发现Claude-3.5-sonnet在三个SNN条件下的THR表现明显优于其他开源模型，得分分别为0.519、0.450和0.231，展示了其在维持目标一致性方面优于其他LLM的能力；2）即使是表现最好的Claude-3.5，在简单的SNN常规条件下，只有51.9%的任务成功率。这个低的目标命中率可能来源于两个问题：代理通常会偏离实际的工具序列，未能选择正确的最终工具，即便规划正确，在工具执行过程中的输入/输出错误也可能导致任务无法完成；3）如图[4](https://arxiv.org/html/2412.09529v2#S2.F4 "图4 ‣ 2.3 RadABench定量分析 ‣ 2 结果 ‣ 现代LLM能否在放射学环境中作为代理核心？")b所示，Claude-3.5、GPT-4o和Qwen-2.5在OPT条件下的MHR指标与其他LLM相比表现相似且优越，达到了接近0.8的值，展示了它们在识别和执行任务过程中关键步骤方面的强大能力；4）如图[4](https://arxiv.org/html/2412.09529v2#S2.F4 "图4 ‣ 2.3 RadABench定量分析 ‣ 2 结果 ‣ 现代LLM能否在放射学环境中作为代理核心？")c所示，所有LLM在最终生成的响应中都表现出相对较低的BLEU、F1和ROUGE成绩（得分很少超过0.35），这归因于工具规划和执行链中缺失或冗余的步骤（这可以通过较低的THR和MHR得分看出），同时也表明在将中间输出合成成连贯且准确的结论方面仍有改进空间。

![参见标题](img/d16d281a1b1369cc25f9e663a0bedbdf.png)

图5：在NR条件下的评估结果。a. 在NR.Denyl1、NR.Denyl2和NR.Denyl3条件下，7个LLM的无解意识率。b. 在NR.Denyl1、NR.Denyl2和NR.Denyl3条件下，7个LLM的无解基础率。

无解解析分析

为了分析智能体核心识别和应对无法解决情况的能力，我们采用了不可解意识率（UAR）来衡量识别无法完成任务的能力，采用不可解归属率（UGR）来评估识别缺失工具或能力的能力。该评估是在NR条件下进行的。测试条件设计了逐渐增加难度的任务：“Denyl1”涉及缺失整个工具类别，“Denyl2”表示缺失针对特定解剖学模态的工具，而“Denyl3”则涉及工具能力不足，而非完全缺失工具。这一逐步增加的难度也体现在这些LLM的表现上。如图[5](https://arxiv.org/html/2412.09529v2#S2.F5 "Figure 5 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")a所示，Claude-3.5-Sonnet和GPT-4o在UAR方面的表现最佳，尤其是在三种NR条件下，其值约为0.6，这一表现令人印象深刻，表明它们具备识别不可解任务的能力。

在这些条件下，成功的标准不仅是能够识别无法解决的任务，还包括能够提出补充工具或策略以继续进行。例如，模型需要能够识别“Denyl1”中缺失的工具类别，指定“Denyl2”中所需的模态和解剖区域，并定义“Denyl3”中最低的工具能力要求。在这些严格的标准下，如图[5](https://arxiv.org/html/2412.09529v2#S2.F5 "Figure 5 ‣ 2.3 Quantitative Analysis on RadABench ‣ 2 RESULTS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")b所示，一些模型，如Gemini-1.5-Pro，UGR表现明显下降，而像Claude-3.5-Sonnet和GPT-4o等模型则表现相对较强，反映出它们更强的理解能力。相反，GPT-4-Turbo、Llama-3.1-405B、Mixtral和Qwen-2.5则一再尝试用不合适的工具来解决任务，突显了它们在判断给定工具是否适合解决特定任务时的困难。

## 3 讨论

近期的研究[[29](https://arxiv.org/html/2412.09529v2#bib.bib29)、[12](https://arxiv.org/html/2412.09529v2#bib.bib12)、[30](https://arxiv.org/html/2412.09529v2#bib.bib30)、[11](https://arxiv.org/html/2412.09529v2#bib.bib11)、[31](https://arxiv.org/html/2412.09529v2#bib.bib31)、[20](https://arxiv.org/html/2412.09529v2#bib.bib20)]突出显示了LLMs在构建代理系统方面的潜力，能够通过有效的工具利用来解决一般性问题。在医学界，研究[[32](https://arxiv.org/html/2412.09529v2#bib.bib32)、[33](https://arxiv.org/html/2412.09529v2#bib.bib33)]强调了LLMs在临床环境中的潜力，展示了它们支持决策、促进互动并调用工具的能力，应用范围从临床工作流程自动化到多代理辅助诊断。然而，在放射学特定任务方面，先前的研究[[34](https://arxiv.org/html/2412.09529v2#bib.bib34)、[35](https://arxiv.org/html/2412.09529v2#bib.bib35)]揭示了显著的挑战，甚至是最先进的视觉-语言模型（VLMs），如GPT-4V[[36](https://arxiv.org/html/2412.09529v2#bib.bib36)]，在进行可靠的医学影像分析时也存在困难。

目前在医学领域的现有大语言模型（LLMs）代理主要局限于特定的临床任务，例如诊断[[37](https://arxiv.org/html/2412.09529v2#bib.bib37)]、风险预测[[11](https://arxiv.org/html/2412.09529v2#bib.bib11)]，或特定的影像学模式和解剖区域，例如专注于大脑的研究[[31](https://arxiv.org/html/2412.09529v2#bib.bib31)、[20](https://arxiv.org/html/2412.09529v2#bib.bib20)]。这些限制性因素妨碍了它们在放射学更广泛和复杂领域的应用。本文旨在通过全面评估现有大型语言模型（LLMs）在处理复杂放射学任务中的能力，弥补这一空白。我们将利用和整合专门的放射学影像解读和分析工具，模拟真实临床医生的工作流程，处理各种复杂的临床问题。

### 3.1 研究影响

我们的研究贡献可以从三个方面总结：

首先，我们介绍了RadABench-Data，这是一个全面的放射学分析评估数据集。它包括2200个不同解剖学、影像模式和疾病组合的患者记录，涵盖11个临床任务和10个高级工具类别，捕捉了广泛的放射学场景。该数据集为测试代理系统在各种放射学任务中的表现提供了一个强有力的基准。

其次，我们开发了RadABench-EvalPlat，这是一个自动化评估平台，旨在模拟真实世界的临床环境，包含一个交互式提示系统，以便促进迭代任务的执行。该平台根据特定的评估需求动态生成量身定制的放射学工具集。它支持各种临床条件，从简单、明确的任务到复杂、资源受限的任务都有涵盖。它为测试基于LLM的代理核心的适应性和稳健性提供了一个灵活且逼真的环境。

第三，在最终的RadABench测试中，我们评估了七种最先进的LLM（大语言模型）作为放射学领域代理核心的表现。我们从三个关键维度评估它们的能力：任务分解与工具选择、工具执行与输入输出协调、响应合成与整合。为了解决评估自由文本输出的挑战，我们提出了一套全面的指标，评估任务特定的性能和整体系统的表现。我们的研究结果揭示了现有LLM的优缺点，为其在临床工作流中的部署提供了宝贵的见解。

本研究中的所有数据和代码均已公开，供研究人员基准测试新模型并推动该领域发展。通过解决工具整合、任务分解和真实场景模拟的挑战，本研究为改进放射学及其他领域的基于LLM的系统奠定了基础。

### 3.2 临床影响

我们的实验结果揭示了一个关键见解：现有的LLM仍然远未成为放射学应用中的可靠核心代理。虽然这些模型在相对简单的任务中表现良好，特别是在工具可用且任务复杂度有限的情况下，但在更复杂的场景中，它们显著表现不佳，例如那些涉及不完整或不一致工具集的场景。这一不足凸显了一个紧迫的问题：尽管先前的研究声称[[38](https://arxiv.org/html/2412.09529v2#bib.bib38)、[9](https://arxiv.org/html/2412.09529v2#bib.bib9)、[10](https://arxiv.org/html/2412.09529v2#bib.bib10)、[11](https://arxiv.org/html/2412.09529v2#bib.bib11)、[12](https://arxiv.org/html/2412.09529v2#bib.bib12)、[13](https://arxiv.org/html/2412.09529v2#bib.bib13)]，代理系统可以增强LLM输出的稳健性和可靠性，但它们在医学，特别是放射学中的可信度仍然值得怀疑，需要临床医生的仔细监督。

我们识别出几个限制LLM基础代理系统在放射学中表现和实际应用的关键因素：

理解复杂外部工具的挑战：LLM在解释和应用涉及长篇详细上下文描述的指令时表现较差。这个局限性在放射学中尤其成问题，因为工具指令和诊断标准往往需要持续的连贯性和细致的理解。

合成多轮信息时的低效性：随着响应轮次的增加，性能明显下降。这限制了模型在迭代诊断过程和长期患者监测中的能力，而这两者都需要持续跟踪和整合信息。

LLM容易出现显著的“工具不完整幻觉”：在使用外部工具时，LLM常常生成错误或不完整的输出——即“幻觉”——尤其是在这些工具未完全集成或不可访问时。这些幻觉可能误导临床医生或削弱AI系统在临床决策中的可信度，这是高风险医疗环境中的一个关键问题。

LLM在组织严格的IO格式以适应连续工具时表现困难：LLM常常未能精确遵循复杂的指令，尤其是那些需要系统化组织IO以连接不同工具的指令。在放射学中，诊断工作流程可能涉及多个阶段，例如影像分析、报告生成和治疗建议，LLM无法严格组织任务并以连贯的方式连接工具。

LLM经常未能根据其表现选择最合适的工具：在放射学中，有效代理系统的一个关键方面是能够根据客观性能指标评估和选择最佳工具。现有的LLM常常做出次优选择，这可能会影响诊断准确性和整体系统性能。

闭源LLM仍然优于开源替代品：在我们的评估中，闭源LLM在性能上始终优于开源对手。这可能是由于专有优化、对更高质量训练数据的访问或更先进的模型架构，这些因素共同促进了更高的可靠性和临床效用。

我们的研究结果旨在为寻求将基于LLM的代理系统应用于实践的临床医生和放射科医师提供洞察。它们突出了人类监督至关重要的情境、需要额外系统支持的领域以及可能对患者安全构成的风险。通过解决这些局限性，基于LLM的系统可以朝着更高的可靠性和临床效用发展，最终减少诊断错误的风险。

### 3.3 局限性与未来方向

本研究推动了LLM作为放射学应用代理管理器的评估，但也存在一些局限性，指出了未来值得关注的方向。

首先，虽然我们评估了七种最先进的（SOTA）LLM，这些模型是通用的，并非专门为医学领域设计。现有的医学专用 LLM[[39](https://arxiv.org/html/2412.09529v2#bib.bib39), [40](https://arxiv.org/html/2412.09529v2#bib.bib40), [41](https://arxiv.org/html/2412.09529v2#bib.bib41), [42](https://arxiv.org/html/2412.09529v2#bib.bib42), [43](https://arxiv.org/html/2412.09529v2#bib.bib43)]是为整合基础医学知识并直接回答医学问题而定制的。然而，它们在基于工具的任务分解方面缺乏熟练度，这限制了它们在我们工作流中的有效性。这为通过开发专门的训练方法和数据集，增强 LLM 代理在医学情境中工具互动和任务解决能力提供了机会。

其次，将大语言模型（LLM）替换为视觉语言模型（VLM）作为代理核心，可能显著提升能力。目前，基于 LLM 的系统依赖外部图像处理工具将视觉信息转化为文本信号。在这些工具不可用的情况下，系统无法有效运作。基于 VLM 的核心能够直接处理原始图像输入，从而缓解这一限制，提供更详细的分析，并能够精确回答与图像相关的查询。

第三，我们的基准评估通过将工具输出视为 oracle 结果，而不是实际实现，来评估基于 LLM 的代理的性能。虽然这种方法允许对 LLM 的决策和协调进行受控测试，但它仅表示代理系统的上限性能，并未考虑在实际工作流中工具错误的传播。未来的工作将涉及实现这些工具，使用其真实输出进行评估，并研究累积错误如何影响整体系统性能。

最后，针对可扩展评估，我们的研究依赖于合成数据和自动化度量。然而，涉及真实数据和人工评估将提供对代理系统性能的更为细致的理解。在有更多资源的情况下，仍然需要更多人工参与到评估中。

## 4 方法

在本节中，我们首先介绍构建 RadABench-Data 的过程，包括患者记录、工具和任务。然后，我们展示 RadABench-EvalPlat 的实施细节。最后，我们描述用于评估的不同 LLM，并提供一系列用于监测其性能的度量标准。

### 4.1 构建 RadABench-Data

我们创建了 RadABench-Data，一个针对放射学定制的 LLM-代理评估数据集，包含 2,200 条合成患者记录、24,200 对相关的 QA 问题及答案，以及基于我们提出的放射学分类系统的无限数量的放射学常用工具。在这一部分，我们将介绍数据生成和人工验证的实施细节。

![参考说明文字](img/2d8f88305f78ecc76480404d55b11d59.png)

图6：RadABench-数据生成。与GPT-4相关的患者记录和QA对数据集构建流程。患者记录基于相关分类法生成，其中GPT-4通过解剖学-影像学-疾病三元组进行提示。QA对基于任务分类法从相应的患者记录信息中推导而来，GPT-4为每个患者记录生成11个QA任务，涵盖所有列出的任务，并通过任务特定的提示进行生成。

#### 4.1.1 数据生成。

我们基于我们的影像学分类系统生成三种类型的数据，*即*，患者记录生成、工具卡生成和任务模拟。接下来，我们将描述生成的详细信息。

患者记录生成。患者记录表示患者的个人档案，包含以下信息：

+   •

    患者信息：人口统计学信息（年龄、性别、身高、体重）、病史和主诉。

+   •

    影像学信息：解剖位置、影像学设备规格、器官和异常标记以及相应的分类。

+   •

    与影像学相关的临床信息：诊断情况、器官和异常生物标志物的指标及其相应值、特定患者指标、整合的患者和影像学报告，以及治疗建议。

如图[6](https://arxiv.org/html/2412.09529v2#S4.F6 "Figure 6 ‣ 4.1 Building RadABench-Data ‣ 4 METHODS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")所示，对于每个患者记录的构建，首先我们指定一个与特定解剖部位和影像学方式相关联的<Disease>（疾病）。其次，我们定义一个患者记录模板来指导生成过程。该模板的组成包括三个方面：1）患者信息的六个方面，包括<Age>（年龄）、<Sex>（性别）、<Height>（身高）、<Weight>（体重）、<History>（病史）、<Complaint>（主诉）。2）影像学信息，包括<Anatomy>（解剖部位）、影像学<Modality>（方式）以及器官和异常的分割掩膜（用特殊符号标注）。3）与影像学相关的临床信息的六个方面，包括<Anomaly>（异常）描述、<Disease>（疾病）、<Biomarker>（生物标志物）测量（包括影像中观察到的物体的尺寸、数量、强度、纹理等特征）、<Indicator>（指标）值（如评分或分级系统，例如CURB-65、肿瘤分级）、影像学<Report>（报告，结合MIMIC-CXR和PadChest格式的发现和印象）以及<Treatment>（治疗）计划（涵盖诊断程序、药物指南和随访方案）。第三，我们通过将疾病-解剖部位-影像学方式组合与模板结合来创建提示词。每个提示词指示GPT-4根据给定的组合填充适当的值到模板中的实体（<>）。例如，当选择胸部X光-肺炎组合时，GPT-4应为患者信息（如年龄和典型肺炎症状）、影像学信息（聚焦于X光胸部区域）以及临床信息（肺炎相关的发现和治疗）生成适当的值，从而创建完整的患者记录。我们通过使用此模板结构选择不同的组合生成多个患者记录。有关详细的提示词和生成的患者记录示例，请参见补充文件。

工具卡生成。我们通过填写8个组成部分来生成一个“工具卡”以代表一个工具：名称、类别、属性、能力、必填输入、可选输入、输出、性能。每个组成部分有其具体定义，具体如下：

+   •

    名称指的是工具的索引，没有特定意义，例如，Tool1、Tool2、*等*；

+   •

    类别表示我们预定义的10个工具类别中的一个实例，属于放射学工具分类系统；

+   •

    属性描述工具是通用的，还是针对特定的解剖部位-影像学方式组合（例如，通用的“异常检测器”或仅适用于“头颈部X光”影像的“影像诊断器”）；

+   •

    能力定义了工具的应用场景，包括相关的影像学方式、解剖部位，以及在必要时，相关的疾病；

+   •

    必填输入给出了工具运行所需的最小输入；

+   •

    可选输入描述了可能提高性能的额外输入；

+   •

    输出指定输出格式；

+   •

    性能显示一个介于 0 到 1 之间的分数，表示该工具在某些任务上的平均表现，例如，分割特定解剖结构的骰子分数。

在生成过程中，我们首先选择类别组件。接下来，我们获取该工具类别内其他组件的预定义候选值集。然后通过随机抽样生成概念工具。

任务模拟. 为了模拟我们放射学分类系统中的 11 项任务，我们生成专注于特定放射学任务的自由文本 QA 对。通常，它们的格式如下：

+   •

    问题.. 问题必须专门针对医学影像方面，涉及案件中明确的信息或可以从已知案件信息中综合得出的内容，例如“肿瘤的大小是多少？”。

+   •

    答案. 答案必须来源于相关病历中的关键信息，以支持问题的解答。当答案涉及视觉信息，如掩模时，需以自由文本形式呈现，并使用特殊符号（例如，“器官分割结果显示为[器官掩模]”）。

如图[6](https://arxiv.org/html/2412.09529v2#S4.F6 "Figure 6 ‣ 4.1 Building RadABench-Data ‣ 4 METHODS ‣ Can Modern LLMs Act as Agent Cores in Radiology Environments?")所示，为了生成全面覆盖我们放射学分类系统中描述的 11 项任务的 QA 对，我们开发了详细的提示描述，涵盖目标场景、步骤和具体要求。具体而言，我们将每项任务的定义以及在分类系统中列出的相应计划链提供给 GPT-4，并附上特定的病案，要求它同时生成问题和答案。问题必须与相应的任务主题一致，其解决方案的分解必须遵循预定义的链条。答案应基于可用的案件信息直接回应问题。为了确保临床相关性和一致性，我们在生成提示中设置了其他要求。1）为一个病历生成的所有任务模拟任务必须是独立的，互不影响，2）响应应简洁，3）视觉元素占位符必须遵循标准符号格式，例如，[器官掩模]和[异常掩模]，4）每个响应必须遵循结构化格式，并使用特殊的问答符号（例如，<Q>…</Q>，<A>…</A>）。最后，对于每个病历，我们生成对应于不同任务的 11 个模拟实例。

#### 4.1.2 手动验证

为确保合成数据集的质量和可靠性，每个病历都会由一位拥有超过 10 年临床经验的放射科医师严格审查。评估重点关注四个关键方面：

+   •

    患者多样性。大多数解剖部位在临床场景中展示了足够的多样性，唯一的例外是乳腺相关患者，99%为女性，且年龄集中在45-65岁之间。相比之下，其他解剖部位的患者人口特征和记录复杂度表现出足够的变化。

+   •

    疾病代表性。所选疾病被确认在临床上常见，并且具有明显的放射学特征。这确保了任务既具有临床相关性，又可以通过放射学分析解决。

+   •

    信息有效性。包括器官、异常、标志物、指标、报告和治疗在内的医学实体已验证其客观存在性。约97.32%的记录被认为有效，其余记录经过手动修正以确保准确性。

+   •

    逻辑一致性。强调患者信息、病史、主诉和放射学发现之间的一致性。观察到96.37%的一致性率，所有不一致之处已通过人工解决，以维持记录的逻辑完整性。

对于合成工具，所有相关的预定义值集均由一位具有10年经验的放射科医师设计，确保我们生成的工具卡具有临床意义且高度相关。

对于QA对，考虑到通过阅读患者记录可以直接检查答案的正确性，验证难度较低。因此，相关的质量控制由两名医学博士研究生负责，关注两个方面：

+   •

    查询-回答合理性。每个问题都会被审查，以确定它是否代表了放射科医师常见的临床任务或关注点，以及相应的回答是否客观地解决了问题并与记录信息一致。审查结果显示，94.23%的问题反映了典型的影像学相关任务，只有少部分问题关注无关的细节。同样，98.36%的回答显示了足够的质量，只有少数子集中的记录信息存在轻微偏差。

+   •

    任务链分解准确性。每个QA任务的指定步骤链通过人工评估，确保其必要、充分、正确且逻辑结构清晰。结果表明，90.64%的任务链标签是合适的，其余的链虽然能够部分解决查询，但并不是最合适的。

最后，识别出的意外患者记录或QA对由临床医生直接修订。因此，RadABench-Data中的最终数据规模保持高质量。

### 4.2 建立RadABench-EvalPlat

RadA-EvalPlat的目标是创建一个自由文本智能体系统，使得LLM核心能够与多样化的外部工具集进行交互。它包含两种主要方法：首先，通过基于提示的智能体工作流评估任何LLM；其次，通过动态工具集模拟策略，涵盖可能的放射学分析工具并模拟不同的评估条件。

基于提示的智能体工作流

一个典型的智能体工作流由三个主要组件组成：基于LLM的中央核心、外部专家工具集以及用于保持中间结果的内存库。在给定包含患者信息的临床查询时，系统会按照三个高层步骤来获得最终答案：任务分解、工具选择与执行、以及响应生成。值得注意的是，在补充文件中，我们提供了这三个阶段的详细提示示例。

![参见说明文字](img/cf11172f8e1435d814be8a58a030ff8f.png)

图7：智能体核心工作流。它由三阶段架构组成。第一阶段是初始化阶段，通过考虑工具包描述、患者信息和初始提示，生成工具链并组织已知参数。第二阶段是循环阶段，涉及通过选择-调用-更新机制的多轮交互执行，以逐步完成任务。每轮迭代产生三种可能的输出标志之一：Call（继续调用）、EndCall（终止调用）或NoCall（检测到工具缺失）。在第三阶段，智能体核心执行结论处理：当标志为NoCall时，输出拒绝消息；当标志为EndCall时，综合所有从前几个阶段获得的中间知识和问题，生成最终答案。

任务分解。在这一阶段，智能体核心接收到一个初始提示，描述了完整的智能体工作流指南，以初始化其“放射学智能体核心”的角色，同时提供患者记录和查询的“患者信息”。首先，LLM需要通过存储所有可用的初始信息来初始化内存库，包括患者的放射学影像、人口统计学信息、病史和主要症状。其次，LLM会通过将临床查询分解为一系列可以通过各种专业工具解决的子步骤来执行任务分解。这个提示确立了智能体核心在解决医学影像任务中的角色，并提供了临床背景，同时提供了具体的查询描述和响应格式示例。智能体必须遵循严格的响应规则，例如使用特殊标记“$$”来突出关键信息，并遵守预定义的信息类型和工具类别范围。尽管智能体已经意识到工作流中的后续阶段，这些内容将在过程中的后续提示中单独处理。

工具选择与执行。在此阶段，代理核心通过迭代调用不同的外部工具进行医学影像分析。根据第一阶段确定的工具链，代理核心首先选择并调用第一个工具，提供必要的输入，并获取结果，随后将结果推送到记忆库中。该过程会持续进行，代理根据整体计划步骤、前期执行结果和所有存储的信息来优化后续决策。

执行过程遵循三种不同的XML风格模板格式：<Call>、<EndCall> 和 <NoCall>。<Call>模板表示执行计划中的中间步骤，在这些步骤中需要特定的工具，但最终目标尚未实现。<EndCall>模板表示终端步骤，在此步骤中工具的执行将产生所需的最终结果。当代理遇到某些任务没有合适工具时，它会使用<NoCall>模板记录能力差距，具体说明目的、相关工具类别、解剖学背景、影像学模式以及当前不足的必要能力。每次迭代都遵循这些严格的XML风格模板和全面的指导方针，涵盖任务描述、输入要求和执行规则。在每个工具执行后，记忆库会更新以记录工具的输出。然后，代理核心评估是否已达到预期结果。如果已经达成，它将退出该步骤；否则，它将回到该步骤并重复执行。

响应生成。在最后阶段，一旦代理核心确认记忆库中已收集足够的信息，它将开始生成全面的响应。在结论提示的指导下，代理将之前阶段的所有发现整合成一个结论性答案。这个过程整合了多个元素：最初的分析计划、工具执行的顺序及其结果，以及记忆库中存储的所有相关信息。提示指引代理构建一个简明的答案，确保结果中的关键信据支持结论，同时与原定的分析策略保持一致。直接且简短的提示会产生一个集中的高效响应，能够有效整合诊断过程中的所有相关发现。

在这样的代理工作流中，LLMs作为代理核心，要求具备五项关键能力。这些能力包括分析（全面评估临床医学场景、临床信息以及任务/问题描述）、决策（根据任务的类型和内容战略性地分解任务）、工具调用（理解可用工具并为特定任务选择合适的工具）、集成（协调并协调工具调用的输入输出关系）以及综合（整合所有互动中的中间结果，形成全面的结论）。通过这些相互关联的能力，代理核心能够建立一个有条理的医学任务工作流，并拥有明确的提示策略。

动态工具集模拟

为了实现上述代理工作流，必须模拟外部工具集。因此，我们提出了一种动态工具集模拟策略，可以生成不同的概念工具集，模拟不同的评估条件。具体来说，我们根据启发式算法结合不同的工具，形成工具集，以满足不同的评估条件，如下所示：

NS（必要且充分）条件。在这个基础的测试环境中，我们为每个十个工具类别配置一到三个工具，每个工具都配备了在其指定的输入输出限制内的最大能力。例如，我们实现了一个综合性疾病诊断工具，能够分析不同方式和解剖位置下的所有疾病类型。这个简化的设置专门用于评估代理核心在任务分解、高级工具链规划和基本工具执行方面的基础能力，重点是它理解工具功能和构建适当的序列的能力，而不是处理类别内复杂的工具选择。

SNN（充分但不必要）条件。在这个扩展的测试环境中，我们在NS工具场景的基础上，加入了更多的“不可用”工具，这些工具不符合当前案例的方式和解剖要求。这种故意扩展不兼容工具的做法更好地模拟了现实世界的场景，其中只有少数可用工具适用于任何给定的案例，而大多数工具则不适用。我们建立了三个不同的场景，具有不同数量的不可用工具：

+   •

    常规条件。一个基本场景，其中每个工具类别包含必要的工具，以及最多一个额外的不可用工具。

+   •

    中等条件。一个适度复杂的场景，其中每个工具类别包含2-3个额外工具，超出了与QA任务方式和解剖相关的工具。

+   •

    大规模条件。一个高度复杂的场景，其中每个工具类别包含所有常见的解剖-方式组合工具，导致大量不可用工具的冗余。

该设置专门用于评估代理核心理解和筛选大量工具描述的能力，测试其在处理较长工具卡片文本描述的认知负荷增加的情况下，仍能有效识别并选择相关工具，从而保持任务执行的准确性。

NR.（必要但不足够）条件。在此测试环境中，我们故意通过基于案例信息和QA任务遗漏关键工具，创建不可解决的任务场景。该场景涵盖了三种不同类型的工具遗漏场景。

+   •

    Denyl1 条件。此场景考虑完全缺少某一工具类别的情况，例如找不到任何器官分割工具，这使得器官分割任务无法获得器官掩膜和标签。理想情况下，这代表了代理核心识别并拒绝响应的最简单场景。

+   •

    Denyl2 条件。此场景检查特定成像方式和解剖结构工具的缺失。虽然可能存在一般性的疾病诊断工具，但该场景缺乏专门与当前案例的成像方式和解剖结构匹配的工具。例如，在胸部X光分析任务中，可能存在脑部MRI或腹部CT的疾病诊断工具，但没有适用于胸部X光的工具，从而无法完成所需的分析。

+   •

    Denyl3 条件。此场景处理特定工具能力不足的情况。即使存在适当类别、解剖区域和成像方式的工具，它们的能力也可能无法满足当前任务的需求。例如，如果一种疾病诊断工具只能检测气胸和肺不张，但查询要求进行肺癌评估，那么该工具的能力不足以回答问题，需要拒绝响应。

此设置专门设计用于评估代理核心在应该拒绝提供答案时的表现，因为所有三种遗漏情况严格确保无法达到事实真相，测试其识别并适当回应无法解决的场景的能力。

OPT.（最佳）条件。在这个测试环境中，每个类别内配置了多个工具，并采用不同的性能指标，反映了现实世界中更多专业化模型通常能获得更高性能的情况。例如，在异常检测类别中，一个通用工具的得分可能为$0.5$，而一个针对当前案例的模态和解剖位置的专业工具得分为$0.6$，甚至更专业的工具，专注于同一模态和位置下特定异常类型的工具，得分为$0.7$。这个设置模拟了一个常见的模式：增加专业化通常与性能提升相关，并旨在评估代理核心在构建解决方案链时，在工具通用性和性能指标之间平衡选择最优工具的决策能力。

总体而言，每个工具组合条件旨在提供对代理核心性能特定方面的全面洞察，同时保持测试环境中的实际可行性。它们共同支持系统化评估代理核心在各种操作维度上的能力，从基本的工具操作到复杂的链规划与优化。

### 4.3 评估

在这一部分，我们将介绍作为我们提议的RadABench代理核心的LLM，并量化其性能的评估指标。

代理核心选择

代理核心的选择显著影响代理系统的整体性能。作为代理核心的大型语言模型必须具备几个关键能力才能有效工作。首先，它们必须展现出强大的多轮交互对话能力，以支持实时决策集成和优化。其次，它们需要拥有大量的领域特定知识，这要求模型具备足够的参数规模，以涵盖全面的医学领域理解，从而做出明智的决策。第三，模型必须支持至少40,000个token的上下文窗口，以容纳我们工具包中的广泛工具描述，因为具有有限上下文窗口的模型（例如GPT-3.5 [[44](https://arxiv.org/html/2412.09529v2#bib.bib44)]的16,000个token）无法满足这一需求。

基于这些要求，我们已选择了特定的模型进行评估，作为潜在的代理核心，特别关注它们处理广泛上下文、维持连贯的多轮交互以及展示强大的医学领域知识的能力。这些选择标准确保所选模型能够有效地协调医学影像解读任务中所需的复杂交互。在接下来的部分，我们将介绍我们在工作中考虑的LLM，以进行比较：

+   •

    GPT-4 [[3](https://arxiv.org/html/2412.09529v2#bib.bib3)]是由OpenAI开发的开创性大型语言模型。它在不同领域，包括医疗领域，展现了卓越的能力，并被视为最具代表性的闭源LLM。由于数据和模型细节的保密性，详细的模型规模尚不明确。在本研究中，我们通过官方API进行零-shot评估，API版本为“gpt-4-turbo-2024-04-09”。

+   •

    GPT-4o [[45](https://arxiv.org/html/2412.09529v2#bib.bib45)]是最先进的GPT模型。它是多模态的（接受文本或图像输入并输出文本），并且与GPT-4 Turbo具有相同的高智力，但效率更高。与GPT-4相比，它进一步增强了LLM的推理能力，专注于通过更深思熟虑的推理解决复杂的推理任务，这与RadA-Bench评估的技能紧密契合。与GPT-4类似，它的数据和模型细节未公开，我们通过官方API对其进行评估，API版本为“gpt-4o-2024-08-06”。

+   •

    Gemini [[7](https://arxiv.org/html/2412.09529v2#bib.bib7)]，前身为Bard，是由Google开发的一种通用多模态基础模型。尽管它面向多模态应用，但它也被广泛认为是Google最具代表性的闭源语言模型，其语言能力甚至超越了Google的其他LLM，如PaLM 2 [[46](https://arxiv.org/html/2412.09529v2#bib.bib46)]。它的详细规模和训练细节未发布。我们通过官方API评估它，使用的版本是“gemini-1.5-pro-latest”，并已于2024年9月更新。 

+   •

    Claude [[47](https://arxiv.org/html/2412.09529v2#bib.bib47)]是由Anthropic开发的一系列大型语言模型。在模型规模上，它包含三种类型的规模，*即*，“Haiku”，“Sonnet”和“Opus”，从小到大。另一方面，它还具有两个主要使用的版本，*即*，Claude-3和Claude-3.5。根据官方介绍，我们选择“Claude-3.5-Sonnet”来代表该系列，考虑到它在广泛使用的基准测试中已被证明是最强大的。与以前的闭源LLM类似，它的细节是机密的，我们通过官方API“claude-3-5-sonnet-20241022”访问它。

+   •

    Llama [[8](https://arxiv.org/html/2412.09529v2#bib.bib8)]系列是由Meta开发的最著名开源LLM。最新版本是Llama-3.1，其中最大版本（Llama-3.1-405B）在大多数基准测试中表现与GPT-4相当。我们在评估过程中使用了2024年9月26日更新的“Llama-3.1-405B”版本。

+   •

    Mixtral [[48](https://arxiv.org/html/2412.09529v2#bib.bib48)] 于2023年10月首次发布，并持续更新。在架构设计中，Mixtral采用了专家混合模型[[49](https://arxiv.org/html/2412.09529v2#bib.bib49)]，以降低计算成本并增强性能。本文默认评估了2023年12月11日提出的“Mixtral-8x7B”。

+   •

    Qwen [[50](https://arxiv.org/html/2412.09529v2#bib.bib50)] 是由Qwen团队开发的双语LLM系列。尽管它包含了中文和英文，但根据评估，其仅在英文方面的能力相比其他以英文为主的LLM仍然令人印象深刻。我们选择它作为双语LLM的代表。我们在RadABench上评估了它在2024年9月19日发布的最新模型版本“Qwen-2.5-72B”。

评估指标

受到之前基于代理的评估工作启发[[13](https://arxiv.org/html/2412.09529v2#bib.bib13), [12](https://arxiv.org/html/2412.09529v2#bib.bib12)]，我们的评估指标全面评估了代理的核心性能，包括5项关键能力：首先，链规划，评估规划质量以及计划与实际执行链之间的一致性；其次，最佳协调，评估代理在执行阶段优化工具使用的能力；第三，输入输出组织，衡量代理在多个工具之间组织输入输出的能力；第四，响应合成，检查基于工具输出生成的响应质量；第五，无法解决解析，评估识别和处理无法解决的情况的能力。

链规划指标。链规划评估主要集中于衡量LLM生成的工具类别链与真实分解之间的差异。采用以下指标：

+   •

    Levenshtein距离[[51](https://arxiv.org/html/2412.09529v2#bib.bib51)]。该指标计算将生成的工具链转化为真实工具链所需的最小编辑操作步骤数（插入、删除、替换）。较低的分数表示两个序列之间的相似度较高，0表示序列完全相同。

+   •

    假阳性发现率[[52](https://arxiv.org/html/2412.09529v2#bib.bib52)]。该指标计算生成链中错误包含的工具（在生成链中出现但在真实链中缺失的工具）占生成链中所有工具的比例。它反映了代理在规划中的精度，避免了不必要的工具使用。

+   •

    工具匹配准确率[[53](https://arxiv.org/html/2412.09529v2#bib.bib53)]。该指标直接检查预测链能够在多大程度上命中真实工具序列中的位置（相同工具出现在相同位置），然后计算匹配工具与真实工具序列总长度的比例。它反映了代理在规划中的召回能力。

最优编排度量。最优编排评估智能体是否能够通过比较工具的性能评分来执行一个计划的、按工具类别排序的链条。采用以下度量标准：

+   •

    最优工具得分 [[54](https://arxiv.org/html/2412.09529v2#bib.bib54)]。该度量评估智能体在需要选择工具以完成特定工具类别需求时的决策质量。得分定义为$(N-R+1)/N$，其中N是提供的工具集中适合该工具类别的工具总数，R是所选工具的性能排名（1为最好）。例如，如果有4个适合的工具，而智能体选择了第二好的工具，则得分为$(4-2+1)/4=0.75$。最终得分是通过对所有相关工具选择步骤的平均值来确定的。例如，一个QA对可能在执行过程中涉及多个工具选择步骤，每个步骤都会生成自己的最优工具得分。

输入输出组织度量。输入输出组织评估智能体在执行过程中如何组织和管理各个工具间的输入输出流。采用以下度量标准：

+   •

    执行完成率。该度量衡量智能体是否能够在没有任何输入/输出错误的情况下完成整个计划的链条。若所有工具均成功执行，不管最终输出的正确性如何，都会判定为通过，表示智能体具有基本的处理工具输入输出要求的能力。

+   •

    失败前成功百分比。该度量进一步明确在发生失败之前，成功执行的步骤所占的百分比。该计算仅对失败案例进行，通过比较失败发生前成功执行的工具数量，再除以真实链条的总长度。这有助于进一步比较不同LLM在失败案例中的输入输出组织能力。

回应综合度量。回应综合评估智能体生成最终输出的质量，以及这些输出与专家提供的参考内容的匹配度。采用以下度量标准：

+   •

    目标命中率 [[54](https://arxiv.org/html/2412.09529v2#bib.bib54)]。该度量检查执行链是否以提供所需响应格式的适当工具结束。通过意味着最终输出符合给定任务的预期响应类型和格式。 

+   •

    里程碑达成率 [[54](https://arxiv.org/html/2412.09529v2#bib.bib54)]。此指标衡量代理在最终任务未完全成功解决时，完成有价值中间步骤的能力。在医学影像任务中，它评估代理是否能够在遇到失败之前生成有用的中间输出（如器官分割或初步诊断）。这有助于评估代理在提供部分但具有临床价值的结果方面的有效性。具体而言，我们为每个放射学任务手动设置了一个里程碑，计算所有QA对的达成率。

+   •

    BLEU [[55](https://arxiv.org/html/2412.09529v2#bib.bib55)]。此指标通过衡量生成文本与参考文本之间的词汇重叠，重点关注精准度。在医学影像任务中，它通过比较词序列的重叠度，评估生成的诊断报告与参考报告的匹配度。

+   •

    ROUGE [[56](https://arxiv.org/html/2412.09529v2#bib.bib56)]。此指标通过衡量生成文本与参考文本之间的词汇重叠，重点关注召回率，从而评估文本质量。它有助于评估生成的医学报告是否包含参考报告中的所有关键信息。

+   •

    F1 [[57](https://arxiv.org/html/2412.09529v2#bib.bib57)]。此指标结合了基于生成文本与参考文本之间词汇重叠的精准度和召回率，提供了一个平衡的评估，衡量生成的医学报告是否既准确又完整。

+   •

    RaTEScore [[58](https://arxiv.org/html/2412.09529v2#bib.bib58)]。此医学特定指标通过关注关键医学术语和实体，评估文本相似性。它通过衡量生成的报告与参考报告相比，捕获医学关键信息的效果，提供了更具临床相关性的评估。

不可解性解析指标。上述所有指标评估LLM在可解情境下的表现，而不可解性解析指标旨在衡量当某个查询无法通过外部工具集解决时，代理核心是否能够识别其不可解性。我们设计了两个指标，从两个层面监测解析能力：

+   •

    不可解性意识率。衡量代理是否能够识别当前工具无法解决的任务。当代理正确拒绝提供无效答案时为通过，而尝试解决不可能完成的任务则为不通过。

+   •

    不可解性基础率。评估代理是否能够识别出特定的缺陷，无论是缺少工具还是能力不足。通过要求代理正确指出缺少的内容——无论是完成任务所需的特定工具还是能力，来判定是否通过。

## 参考文献

+   [1] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl 等人。《大型语言模型编码临床知识》。自然，620(7972):172–180, 2023年。

+   [2] 胡姆扎·纳维德、阿萨德·乌拉·汗、邱诗、穆罕默德·萨基布、赛义德·安瓦尔、穆罕默德·乌斯曼、纳维德·阿赫塔尔、尼克·巴恩斯和阿吉马尔·米安。大型语言模型的全面概述。arXiv 预印本 arXiv:2307.06435，2023年。

+   [3] 乔什·阿奇亚姆、史蒂文·阿德勒、桑迪尼·阿卡瓦尔、拉马·艾哈迈德、伊尔格·阿卡亚、佛罗伦西亚·莱奥尼·阿尔曼、迪奥戈·阿尔梅达、扬科·阿尔滕施密特、萨姆·奥特曼、沙亚马尔·阿纳德卡特等人。GPT-4 技术报告。arXiv 预印本 arXiv:2303.08774，2023年。

+   [4] 吴超毅、张小曼、张亚、王艳峰和谢伟迪。朝着通用放射学基础模型迈进。arXiv 预印本 arXiv:2308.02463，2023年。

+   [5] 崔赫杰、毛凌军、梁鑫、张杰宇、任辉、李全正、李翔和杨凯尔。生物医学视觉指令调优与临床医生偏好对齐。arXiv 预印本 arXiv:2406.13173，2024年。

+   [6] 刘昊天、李春元、吴青阳和李永载。视觉指令调优。《神经信息处理系统进展》，第36卷，2024年。

+   [7] Gemini团队、罗汉·阿尼尔、塞巴斯蒂安·博尔格奥、吴永辉、让-巴蒂斯特·阿莱拉克、余嘉辉、拉杜·索里库特、约翰·沙尔克维克、安德鲁·M·戴、安佳·霍斯等人。Gemini：一系列高能力多模态模型。arXiv 预印本 arXiv:2312.11805，2023年。

+   [8] 雨果·图弗龙、蒂博·拉夫里尔、戈蒂埃·伊萨卡尔、泽维尔·马尔蒂内、玛丽-安娜·拉肖、蒂莫忒·拉克罗瓦、巴蒂斯特·罗齐耶、纳曼·戈亚尔、埃里克·汉布罗、费萨尔·阿扎尔等人。Llama：开放且高效的基础语言模型。arXiv 预印本 arXiv:2302.13971，2023年。

+   [9] 蒂莫·希克、简·德维韦迪-余、罗伯托·德西、罗伯塔·赖莱阿努、玛丽亚·洛梅里、埃里克·汉布罗、卢克·泽特尔莫耶、尼古拉·坎切达、托马斯·西亚隆。Toolformer：语言模型能够自学使用工具。《神经信息处理系统进展》，第36卷，2024年。

+   [10] 唐向如、邹安妮、张卓生、李子铭、赵艺伦、张星耀、阿尔曼·科汉和马克·格尔斯坦。Medagents：作为零-shot医学推理合作伙伴的大型语言模型。ICLR 2024 大型语言模型（LLM）代理工作坊。

+   [11] 乔金、王志正、杨一凡、朱青青、唐纳德·赖特、托马斯·黄、约翰·威尔伯、何哲、安德鲁·泰勒、陈青宇等人。Agentmd：通过大规模临床工具学习赋能语言代理进行风险预测。arXiv 预印本 arXiv:2402.13225，2024年。

+   [12] 秦宇佳、梁诗豪、叶奕宁、朱坤伦、严蓝、陆雅希、林彦凯、丛欣、唐向如、钱璧等人。Toolllm：帮助大型语言模型掌握16000+真实世界 API。arXiv 预印本 arXiv:2307.16789，2023年。

+   [13] 邢亮·沈、凯涛·宋、许坦、董胜·李、伟明·卢和悦庭·庄。Hugginggpt：通过 ChatGPT 和 Hugging Face 解决人工智能任务。《神经信息处理系统进展》，第36卷，2024年。

+   [14] Hejie Cui, Zhuocheng Shen, Jieyu Zhang, Hui Shao, Lianhui Qin, Joyce C Ho 和 Carl Yang。基于LLMs的少样本疾病预测使用EHR：结合预测代理推理与关键代理指令的新方法。arXiv 预印本 arXiv:2403.15464，2024年。

+   [15] Michael Moor, Oishi Banerjee, Zahra Shakeri Hossein Abad, Harlan M Krumholz, Jure Leskovec, Eric J Topol 和 Pranav Rajpurkar。通用医学人工智能的基础模型。自然，616(7956):259–265，2023年。

+   [16] Peilun Shi, Jianing Qiu, Sai Mu Dalike Abaxi, Hao Wei, Frank P-W Lo 和 Wu Yuan。通用视觉基础模型在医学影像中的应用：以零样本医学分割中的“Segment Anything”模型为例。诊断学，13(11):1947，2023年。

+   [17] Qiaoyu Zheng, Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Lisong Dai, Hengyu Guan, Yuehua Li, Ya Zhang, Yanfeng Wang 和 Weidi Xie。大规模长尾疾病诊断在放射影像中的应用。自然通讯，15(1):10147，2024年。

+   [18] Ziheng Zhao, Yao Zhang, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang 和 Weidi Xie。一个模型统领所有：迈向利用文本提示的医学图像通用分割。arXiv 预印本 arXiv:2312.17183，2023年。

+   [19] Xiao Zhou, Xiaoman Zhang, Chaoyi Wu, Ya Zhang, Weidi Xie 和 Yanfeng Wang。知识增强的视觉-语言预训练用于计算病理学。在 Aleš Leonardis, Elisa Ricci, Stefan Roth, Olga Russakovsky, Torsten Sattler 和 Gül Varol 编辑的《计算机视觉 – ECCV 2024》一书中，页面345-362，2025年，Springer Nature Switzerland出版。

+   [20] Jiayu Lei, Xiaoman Zhang, Chaoyi Wu, Lisong Dai, Ya Zhang, Yanyong Zhang, Yanfeng Wang, Weidi Xie 和 Yuehua Li。Autorg-brain: 用于脑部MRI的基于文本的报告生成。arXiv 预印本 arXiv:2407.16684，2024年。

+   [21] Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed Amin, Pi-Chuan Chang, Andrew Carroll, Charles Lau, Ryutaro Tanno, Ira Ktena 等人。迈向通用生物医学AI。NEJM AI，1(3):AIoa2300138，2024年。

+   [22] Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon 和 Jianfeng Gao。Llava-med：在一天内训练一个用于生物医学的大型语言-视觉助手。arXiv 预印本 arXiv:2306.00890，2023年。

+   [23] Zhengliang Liu, Yiwei Li, Peng Shu, Aoxiao Zhong, Longtao Yang, Chao Ju, Zihao Wu, Chong Ma, Jie Luo, Cheng Chen 等人。Radiology-llama2: 放射学领域最佳的大型语言模型。arXiv 电子预印本，页面 arXiv–2309，2023年。

+   [24] Zhihong Chen, Maya Varma, Jean-Benoit Delbrouck, Magdalini Paschali, Louis Blankemeier, Dave Van Veen, Jeya Maria Jose Valanarasu, Alaa Youssef, Joseph Paul Cohen, Eduardo Pontes Reis 等人。Chexagent: 致力于胸部X光解读的基础模型。arXiv 预印本 arXiv:2401.12208，2024年。

+   [25] Kai Zhang, Rong Zhou, Eashan Adhikarla, Zhiling Yan, Yixin Liu, Jun Yu, Zhengliang Liu, Xun Chen, Brian D Davison, Hui Ren, 等. 一种用于多样生物医学任务的通用视觉-语言基础模型. 《自然·医学》，页码 1–13, 2024.

+   [26] Xiaoman Zhang, Chaoyi Wu, Ziheng Zhao, Weixiong Lin, Ya Zhang, Yanfeng Wang, 和 Weidi Xie. Pmc-vqa: 用于医学视觉问答的视觉指令微调. arXiv预印本 arXiv:2305.10415, 2023.

+   [27] Nikita Mehandru, Brenda Y Miao, Eduardo Rodriguez Almaraz, Madhumita Sushil, Atul J Butte, 和 Ahmed Alaa. 评估大型语言模型作为临床代理的表现. NPJ数字医学, 7(1):84, 2024.

+   [28] François Remy, Kris Demuynck, 和 Thomas Demeester. Biolord: 从定义中学习本体表示（用于生物医学概念及其文本描述）. arXiv预印本 arXiv:2210.11892, 2022.

+   [29] Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, 等. Taskmatrix.ai: 通过连接基础模型与数百万个API完成任务. 《智能计算》，3:0063, 2024.

+   [30] Chenyu Wang, Weixin Luo, Qianyu Chen, Haonan Mai, Jindi Guo, Sixun Dong, Zhengxin Li, Lin Ma, Shenghua Gao, 等. Tool-lmm: 一种用于工具代理学习的大型多模态模型. arXiv预印本 arXiv:2401.10727, 2024.

+   [31] Andrew Hoopes, Victor Ion Butoi, John V Guttag, 和 Adrian V Dalca. Voxelprompt: 一种用于医学图像分析的视觉-语言代理. arXiv预印本 arXiv:2410.08397, 2024.

+   [32] Jianing Qiu, Kyle Lam, Guohao Li, Amish Acharya, Tien Yin Wong, Ara Darzi, Wu Yuan, 和 Eric J Topol. 基于LLM的医疗和健康领域代理系统. 《自然·机器智能》，12, 2024.

+   [33] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang, Weizhi Ma, 和 Yang Liu. Agent hospital: 一种具有可进化医学代理的医院模拟系统. arXiv预印本 arXiv:2405.02957, 2024.

+   [34] Chaoyi Wu, Jiayu Lei, Qiaoyu Zheng, Weike Zhao, Weixiong Lin, Xiaoman Zhang, Xiao Zhou, Ziheng Zhao, Ya Zhang, Yanfeng Wang, 等. GPT-4v (ision) 能为医学应用服务吗？关于GPT-4v在多模态医学诊断中的案例研究. arXiv预印本 arXiv:2310.09909, 2023.

+   [35] Dana Brin, Vera Sorin, Yiftach Barash, Eli Konen, Benjamin S Glicksberg, Girish N Nadkarni, 和 Eyal Klang. 评估GPT-4在放射影像分析中的多模态表现. 《欧洲放射学》，页码 1–7, 2024.

+   [36] GPT-4v(ision) 系统卡片. 2023.

+   [37] Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, 和 Michael Moor. Agentclinic: 一个用于评估人工智能在模拟临床环境中的表现的多模态代理基准. arXiv预印本 arXiv:2405.07960, 2024.

+   [38] Vasilios Mavroudis. Langchain. 2024.

+   [39] Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Weidi Xie, 和 Yanfeng Wang. Pmc-llama: 面向构建开放源代码医学语言模型的研究. 美国医学信息学会杂志, 页码 ocae045, 2024.

+   [40] Pengcheng Qiu, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, 和 Weidi Xie. 构建医学领域多语言模型的探索. 自然通讯, 15(1):8384, 2024。

+   [41] Zeming Chen, Alejandro Hernández Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, 等人. Meditron-70b: 扩展大型语言模型的医学预训练. arXiv 预印本 arXiv:2311.16079, 2023。

+   [42] Chaoyi Wu, Pengcheng Qiu, Jinxin Liu, Hongfei Gu, Na Li, Ya Zhang, Yanfeng Wang, 和 Weidi Xie. 评估和构建多功能医学大语言模型的探索. arXiv 预印本 arXiv:2408.12547, 2024。

+   [43] Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, 和 Daniel Shu Wei Ting. 医学中的大型语言模型. 自然医学, 29(8):1930–1940, 2023。

+   [44] Openai 平台, 2024。

+   [45] OpenAI, 访问时间：2024年10月12日。

+   [46] Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, 等人. Palm 2 技术报告. arXiv 预印本 arXiv:2305.10403, 2023。

+   [47] Anthropic, 访问时间：2024年10月12日。

+   [48] Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, 等人. Mixtral of experts. arXiv 预印本 arXiv:2401.04088, 2024。

+   [49] Saeed Masoudnia 和 Reza Ebrahimpour. 专家混合模型: 文献综述. 人工智能评论, 42:275–293, 2014。

+   [50] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, 等人. Qwen 技术报告. arXiv 预印本 arXiv:2309.16609, 2023。

+   [51] Li Yujian 和 Liu Bo. 一种标准化的 Levenshtein 距离度量. IEEE 模式分析与机器智能学报, 29(6):1091–1095, 2007。

+   [52] John D Storey. 假发现率. 国际统计科学百科全书, 1:504–508, 2011。

+   [53] Awatif Alqahtani, Hosam Alhakami, Tahani Alsubait, 和 Abdullah Baz. 文本匹配技术的综述. 工程技术与应用科学研究, 11(1):6656–6661, 2021。

+   [54] Aryan Jadon 和 Avinash Patil. 推荐系统评估技术的综合综述. 在国际人工智能与机器学习计算大会上，页面281–304. Springer, 2024。

+   [55] Kishore Papineni, Salim Roukos, Todd Ward, 和 Wei-Jing Zhu. Bleu: 一种自动评估机器翻译的方法. 在第40届计算语言学协会年会上，页面311–318, 2002。

+   [56] Chin-Yew Lin. Rouge: 自动评估摘要的工具包. 在《文本摘要分支》中，页面74–81, 2004。

+   [57] David MW Powers. 评估：从精确度、召回率和F-measure到roc、知情度、显著性和相关性。arXiv预印本 arXiv:2010.16061，2020。

+   [58] Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, 和 Weidi Xie. Ratescore: 一种用于放射学报告生成的度量。arXiv预印本 arXiv:2406.16845，2024。

## 附加文件

### 患者记录中的疾病/异常名称

我们在合成患者记录中考虑了每种解剖模态组合的100种常见病症。所考虑的疾病/异常名称可以在[CSV文件](https://github.com/MAGIC-AI4Med/RadABench/Patient_Record_Disease_Abnormality_Names.csv)中找到。

### 工具类别的详细解释

我们在这里解释了10个工具类别：

+   •

    解剖分类器（AC）是一种分类器，用于预测输入图像所拍摄的解剖区域。

+   •

    模态分类器（MC）是一种分类器，用于预测输入图像基于的成像模态。

+   •

    器官分割工具（OS）是一种用于预测输入图像中某个器官的密集分割掩膜的工具。

+   •

    异常检测器（AD）是一种检测工具，用于基于输入图像预测某种异常类型的异常区域掩膜或框坐标。

+   •

    成像诊断工具（ID）是一种仅基于输入图像预测相关疾病的诊断工具。

+   •

    合成诊断工具（SD）是一种基于输入图像和文本信息综合预测相关疾病的诊断工具。

+   •

    生物标志物定量工具（BQ）是一种生物标志物计算工具，基于输入图像和器官或异常区域的密集掩膜精确计算放射学生物标志物。

+   •

    指标评估工具（IE）是一种指标（如肿瘤分级）计算工具，基于输入图像和器官或异常区域的密集掩膜精确计算或预测某些医学指标。

+   •

    报告生成器（RG）是一种文本生成工具，用于预测放射学报告。

+   •

    治疗推荐工具（TR）是一种治疗推荐工具（或系统），根据当前临床发现提供治疗推荐。

### 工具类别的详细解释

我们在这里解释了11个放射学任务及其详细的工具类别链：

+   •

    器官掩膜标注是一个任务，目标是预测某个器官的密集掩膜。链条：解剖分类 → 模态分类 → 器官分割

+   •

    异常区域标注是一个任务，目标是预测某一异常类型的区域掩膜。链条：解剖分类 → 模态分类 → 异常检测

+   •

    器官相关生物标志物计算是一个任务，用于计算或测量某些器官相关的生物标志物。链条：解剖分类 → 模态分类 → 器官分割 → 生物标志物定量

+   •

    异常相关生物标志物计算是一个任务，用于计算或测量某些与异常相关的生物标志物。链条：解剖分类 → 模态分类 → 异常检测 → 异常定量

+   •

    器官和异常区域图像解释是对图像进行解释并回答用户关于器官或异常区域或两者的查询的任务。链路：解剖学分类 → 模态分类 → [器官分割, 异常检测]

+   •

    没有视觉线索的疾病诊断是一个基于放射学中心病历进行端到端诊断的任务。链路：解剖学分类 → 模态分类 → 疾病诊断

+   •

    有视觉线索的疾病诊断是一个任务，基于不仅仅是原始图像，还包括相关的分割注释（器官或异常）进行诊断。链路：解剖学分类 → 模态分类 → [器官分割, 异常检测] → 疾病推断

+   •

    常规报告生成是一个基本的放射学常规任务，将某个放射学图像解释为自由文本描述。链路：解剖学分类 → 模态分类 → 异常检测 → 疾病诊断 → 报告生成

+   •

    聚焦于特定生物标志物的报告生成是一个报告生成任务变体，强调在最终报告中反映某些生物标志物的情况。链路：解剖学分类 → 模态分类 → [器官分割, 异常检测] → [器官生物标志物量化, 异常生物标志物量化] → 报告生成

+   •

    聚焦于特定生物标志物和指标的报告生成是一个报告生成任务变体，强调在最终报告中反映某些生物标志物和指标的情况。链路：解剖学分类 → 模态分类 → [器官分割, 异常检测] → 疾病诊断 → [器官生物标志物量化, 异常量化] → 指标评估 → 报告生成

+   •

    治疗计划制定是一个为患者提供治疗计划的任务。链路：解剖学分类 → 模态分类 → [器官分割, 异常检测] → 疾病诊断 → [器官生物标志物量化, 异常量化] → 指标评估 → 报告生成 → 治疗推荐

### 病人记录示例

在此，我们展示了在我们的RadABench-Data中创建的一个具体的合成病人记录：{mdframed}[backgroundcolor=lightgray!20] 病人记录示例

```
"Information": {
    "Age": "42",
    "Sex": "Female",
    "Height": "165",
    "Weight": "68",
    "History": "Patient has a history of seasonal allergies and recurrent upper
    respiratory infections",
    "Complaint": "Persistent facial pain, nasal congestion, and headache for the
    past 2 weeks"
},
"Anatomy": "Head and Neck",
"Modality": "X-ray",
"Anomaly": {
    "Part": "Maxillary sinuses",
    "Symptom": "Opacification"
},
"Disease": "Sinusitis",
"OrganBiomarker": {
    "OrganObject": "Maxillary sinus",
    "OrganDim": "density",
    "OrganQuant": "+40 Hounsfield Units"
},
"AnomalyBiomarker": {
    "AnomalyObject": "Opacification",
    "AnomalyDim": "intensity",
    "AnomalyQuant": "80% increase compared to normal airspace"
},
"Indicator": {
    "Name": "Lund-Mackay Score",
    "Value": "8 (Moderate sinusitis)"
},
"Report": {
    "Finding": "X-ray of the paranasal sinuses demonstrates bilateral maxillary
    sinus opacification. The right maxillary sinus shows complete opacification,
    while the left maxillary sinus demonstrates air-fluid levels. Frontal and ethmoid
    sinuses appear clear. No evidence of bone erosion or destruction. Nasal septum
    appears midline. Soft tissues of the face and neck are unremarkable.",
    "Impression": "Findings consistent with bilateral maxillary sinusitis, more
    pronounced on the right side. No evidence of complications such as orbital or
    intracranial involvement."
},
"Treatment": "Given the patient’s symptoms and radiographic findings, a diagnosis
of acute bacterial sinusitis is likely. Initial treatment should include a 10-14 day
course of broad-spectrum antibiotics such as amoxicillin-clavulanate or, in case of
penicillin allergy, a respiratory fluoroquinolone. Adjunctive treatments include nasal
saline irrigation, intranasal corticosteroids, and oral decongestants for symptom
relief. The patient should be advised to stay well-hydrated and use over-the-counter
pain relievers as needed. If symptoms persist or worsen after 72 hours of antibiotic
therapy, reassessment is warranted. A follow-up appointment should be scheduled in 2-3
weeks to ensure resolution of symptoms. If recurrent episodes occur, further evaluation
with CT imaging and potential referral to an ENT specialist for consideration of
endoscopic sinus surgery may be necessary."

```

这是通过以下提示生成的，利用GPT-4：{mdframed}[backgroundcolor=lightgray!20] 病人记录生成提示

```

You are an experienced clinical radiologist. Your task is to generate a detailed
medical case based on a hypothetical 256x256 medical image. I will provide you with
the Anatomy and Modality of the image, as well as an overall Disease. Using this
information, you should create a comprehensive case report including patient
information, specific anomalies, biomarkers, indicators, a radiology report, and
treatment recommendations.

Please structure your response using the following template:

<Case>
    <Information>
        <Age> [Number without units] </Age>
        <Sex> [Male / Female] </Sex>
        <Height> [Number in cm] </Height>
        <Weight> [Number in kg] </Weight>
        <History> [Brief descriptive text] </History>
        <Complaint> [Brief descriptive text] </Complaint>
    </Information>
    <Anatomy> [Head and Neck / Chest / Breast / Abdomen and Pelvis / Limb / Spine]
    </Anatomy>
    <Modality> [CT / MRI / X-ray / Ultrasound / Mammography] </Modality>
    <Anomaly>
        <Part> [Specific location of anomaly (e.g., right upper lobe of lung)] </Part>
        <Symptom> [Type of anomaly (e.g., nodule)] </Symptom>
    </Anomaly>
    <Disease> [Corresponding disease name] </Disease>
    <OrganBiomarker>
        <OrganObject> [A specific organ serving as biomarker] </OrganObject>
        <OrganDim> [number / length / size / volume / angle / density / intensity /
        texture] </OrganDim>
        <OrganQuant> [Specific quantitative value] </OrganQuant>
    </OrganBiomarker>
    <AnomalyBiomarker>
        <AnomalyObject> [The same Anomaly described in the Anomaly Symptom serving
        as biomarker] </AnomalyObject>
        <AnomalyDim> [number / length / size / volume / angle / density / intensity /
        texture] </AnomalyDim>
        <AnomalyQuant> [Specific quantitative value] </AnomalyQuant>
    </AnomalyBiomarker>
    <Indicator>
        <Name> [Name of the indicator (e.g., Lung Cancer TNM Staging Score)] </Name>
        <Value> [Specific value or grade (e.g., cT2aN0M0 (Stage IB))] </Value>
    </Indicator>
    <Report>
        <Finding> [Findings section in the style of a MIMIC-CXR report] </Finding>
        <Impression> [Impression section in the style of a MIMIC-CXR report]
        </Impression>
    </Report>
    <Treatment> [A paragraph including diagnostic procedures, medication
    recommendations, and follow-up suggestions] </Treatment>
</Case>

Guidelines for generating the case report:

Information: Provide realistic patient demographics, medical history, and chief
complaint.
Anomaly: Describe a specific anomaly consistent with the given anatomy, modality,
and disease.
Biomarkers: Choose a relevant organ biomarker and the anomaly biomarker mentioned
before that can be observed in the image and provide plausible quantitative value.
Indicator: Calculate an appropriate indicator based on the patient information and
biomarker value. Provide a specific, medically accurate score or grade.
Report: Generate a concise radiological report in the style of MIMIC-CXR, with
separate Findings and Impression sections.
Treatment: Offer a comprehensive treatment plan including diagnostic procedures,
medication recommendations, and follow-up care.
Ensure that all parts of the case are medically accurate and consistent with each
other. Use your expertise as a radiologist to provide realistic and detailed
information throughout the case.

Given the following parameters:
- Anatomy: {ANATOMY}
- Imaging Modality: {MODALITY}
- Disease: {DISEASE}
Please generate this patient record.

```

### 工具卡示例

这里是一个聚焦于头颈部X光图像的报告生成工具的工具卡示例：

{mdframed}

[backgroundcolor=lightgray!20] 工具卡示例

```
=== Tool Description for TOOL17 ===
Name: TOOL17
Category: Report Generator
Ability: Given the Head and Neck X-ray Image, any other text information and
organ/anomaly masks and labels, generate a radiology report.
Property: Report Generator only suitable for Head and Neck X-ray image with
Text and Mask
Compulsory Input: [‘$Image$’]
Optional Input: [‘$Information$’, ‘$OrganObject$’, ‘$AnomalyObject$’, ‘$Disease$’,
‘$OrganDim$’, ‘$OrganQuant$’, ‘$AnomalyDim$’, ‘$AnomalyQuant$’, ‘$IndicatorName$’,
‘$ValueName$’, ‘$OrganMask$’, ‘$AnomalyMask$’]
Output: [‘$Report$’]
Performance: Score from 0.4 to 0.88, increases with optional inputs

```

### 任务模拟示例

这是一个从肺炎患者的胸部X光记录生成QA对的示例：

{mdframed}

[backgroundcolor=lightgray!20] QA对示例

```
    <Q1> Identify and segment the lung fields in this chest X-ray. </Q1>
    <A1> The lung fields are segmented [{\em organ mask}: left lung, right lung].
    Both lungs show clear boundaries. </A1>

    ...

    <Q11> Based on the imaging findings and clinical indicators, what treatment plan
    would you recommend? </Q11>
    <A11> Given the moderate pneumonia severity (CURB-65 score: 2) and [anomaly mask],
    recommend oral antibiotics and follow-up chest X-ray in 2 weeks. </A11>

```

这是通过以下提示生成的，利用了GPT-4：

{mdframed}

[backgroundcolor=lightgray!20] QA对生成提示

```
Assume a clinical medical imaging scenario where you, as the Agent core, play the role
of a doctor. Given a patient’s radiological image, you want to complete different tasks
by calling various tools. There are ten tools in total (numbered 0 to 9):

TOOLKIT
0\. |Modality Classifier|
    Property: A classification model
    Ability: Determine the modality of the Image.
    Input: [Image]
    Output: [Modality]

1\. |Anatomy Classifier|
    Property: A classification model,
    Ability: Determine the anatomy of the Image.
    Input: [Image]
    Output: [Anatomy]

2\. |Organ Segmentation Model|
    Property: A segmentation model
    Ability: Given the modality and anatomy, segment all organs in the Image
    (can not segment any lesion or abnormality).
    Input: [Image] & [Modality] & [Anatomy]
    Output: [Organ Mask] & [Organ Label]

3\. |Anomaly Detection Model|
    Property: A detection model
    Ability: Given the modality and anatomy, determine the location and type of
    abnormality.
    Input: [Image] & [Modality] & [Anatomy]
    Output: [Anomaly Mask] & [Anomaly Label]

4\. |Disease Diagnosis Model|
    Property: A classification model
    Ability: Given the modality and anatomy, diagnose diseases directly from the input
    image.
    Input: [Image] & [Modality] & [Anatomy]
    Output: [Diseases]

5\. |Disease Inference Model|
    Property: A Inference model
    Ability: Infer disease based on organ segmentation and anomaly detection results.
    Input: [Image] & [Organ Mask] & [Organ Label] & [Anomaly Mask] & [Anomaly Label]
    Output: [Diseases]

6\. |Biomarker Quantification Model|
    Property: A quantification model
    Ability: Given the organ region or anomaly region and the biomarker of interest,
    estimate its property. The biomarker can be either organ or anomaly. The dimension
    can be one of the number, length, size, volume, angle, density, intensity or
    texture of the organ or anomaly.
    Input: [Image] & [Object] & [Dim] & [Biomarker Mask] & [Biomarker Label]
    Output: [Quant]

7\. |Indicator Evaluation Model|
    Property: A calculation model
    Ability: Use prior patient information and several biomarkers values to calculate
    the indicator, the indicator can be a score or a grading.
    Input: [Priors] & [Indicator] & [Biomarkers] & [Quants]
    Output: [Value]

8\. |Report Generation Model|
    Property: A multimodal model
    Ability: Generate a medical report by integrating results processed by former tools.
    Input: [Image] & [Modality] & [Anatomy]
    Optional Input: ([Organ Mask] & [Organ Label]), ([Anomaly Mask] & [Anomaly Label]),
    [Diseases], ([Object] & [Dim] & [Quant]), ([Indicators] & [Values])
    Output: [Report]

9\. |Treatment Recommendation Model|
    Property: a language model
    Ability: Recommend personalized treatment plans based on all results processed by
    former tools and the patient’s information.
    Input: [Image] & [Priors] & [Modality] & [Anatomy] & [Diseases]
    Optional Input: ([Organ Mask] & [Organ Label]),([Anomaly Mask] & [Anomaly Label]),
    ([Object] & [Dim] & [Quant]), ([Indicators] & [Values])
    Output: [Treatment]

There are 11 different tasks and the chain of tools each task hopes to break down into:

(1) Basic Image Analysis and Organ Segmentation
    ToolUse: 012
    Description: Perform basic image analysis and segment organs within the medical
    image.

(2) Basic Image Analysis and Anomaly Detection
    ToolUse: 013
    Description: Perform basic image analysis and detect anomalies within the medical
    image.

(3) Image-based Direct Disease Diagnosis
    ToolUse: 014
    Description: Diagnose disease directly from the medical image without intermediate
    steps.

(4) Organ segmentation and anomaly localization
    ToolUse: 0123
    Description: Segment organs and locate anomalies within the medical image.

(5) Anomaly-based Disease Diagnosis
    ToolUse: 01235
    Description: Diagnose disease based on disease inference by finding abnormalities
    and the organ in which they occur.

(6) Organ Biomarker Quantification
    ToolUse: 0126
    Description: Quantify specific biomarkers related to organs in the medical image.

(7) Anomaly Biomarker Quantification
    ToolUse: 0136
    Description: Quantify specific biomarkers related to anomalies in the medical image.

(8) Disease and Anomaly Based Report Generation
    ToolUse: 01348
    Description: Generate a medical report based on detected diseases and anomalies.

(9) Disease and Biomarker Based Report Generation
    ToolUse: 0123568
    Description: Generate a comprehensive report incorporating anomaly detection,
    disease diagnosis and biomarker quantification.

(10) Comprehensive Evaluation Report Generation
    ToolUse: 01235678
    Description: Generate a detailed evaluation report including all aspects of the
    medical image analysis.

(11) Comprehensive Report Generation and Treatment Recommendations
    ToolUse: 012356789
    Description: Generate a comprehensive report including all analysis results and
    treatment recommendations.

Please generate 11 mutually independent question-answer pairs corresponding to tasks
above, based on the different task natures and the content of the case. Specifically,
strictly avoid including information
in the questions that should be determined by the tools (such as imaging modality,
specific anatomy, or precise abnormality types).
Pay attention: create task-specific question-answer pairs that highlight the unique
tool usage patterns for different tasks. The questions should be:

1\. Naturally aligned with the task description
2\. Representative of real-world scenarios for that task type
3\. Questions must not reveal information about modality or anatomy that should be
determined by Tools 0 and 1 or other tools. The questions should be phrased in a way
that necessitates the use of these basic identification tools.

Provide answers in the most concise free-text form possible. If visual results such as
masks are involved, please embed them in the text in the form of [Organ Mask] or
[Anomaly Mask]. (eg. The organ segmentation result is shown as [Organ Mask].) The 11
generated question-answer pairs should follow this template:

<Q1> ... </Q1>
<A1> ... </A1>
<Q2> ... </Q2>
<A2> ... </A2>
...
<Q11> ... </Q11>
<A11> ... </A11>

The answer only needs to provide a simple final result based on the information already
available in the Case, without showing the thought process. I will now provide you with
a Case containing all the information.

The patient record is {Patient Record}, please generate the corresponding QA pairs.

```

### RadABench-EvalPlat中的详细工作流程提示

在这一部分，我们详细介绍了我们RadABench-EvalPlat主工作流程中使用的提示模板。

任务分解。

{mdframed}

[backgroundcolor=lightgray!20] 任务分解提示

```
# Medical Image Analysis Assistant

## Task Overview
You are a radiological agent analyzing medical images.
For each query, you will receive:
    1\. A medical imaging examination (Image) of a patient (assume already provided)
    2\. Known patient Information including demographics, medical history,
    and main complaints.

Your task involves three sequential parts:

1\. Problem Decomposition (Part 1)
- Identify available information
- Break down the question into sequential steps

2\. Sequential Tool Application (Part 2)
- Execute one tool at a time
- Record each tool’s output
- Continue until sufficient information is gathered

3\. Solution Synthesis (Part 3)
- Integrate all results
- Generate final answer

## Available Information Categories
The following categories must be used exactly as written:

[’$Information$’, ’$Anatomy$’, ’$Modality$’, ’$Disease$’, ’$OrganObject$’,
’$OrganDim$’, ’$OrganQuant$’, ’$AnomalyObject$’, ’$AnomalyDim$’,
’$AnomalyQuant$’, ’$IndicatorName$’, ’$IndicatorValue$’, ’$Report$’, ’$Treatment$’]

Where:
- $Information$: Patient demographics
(e.g., "45-year-old male", "BMI: 24", "history of diabetes")
- $Anatomy$: Body part (e.g., "chest", "abdomen", "brain")
- $Modality$: Imaging technique (e.g., "X-ray", "CT", "MRI")
- $Disease$: Medical condition (e.g., "pneumonia", "cancer", "fracture")
- $OrganObject$: Organ to measure (e.g., "liver", "heart")
- $OrganDim$: Organ measurement type (e.g., "number", "length", "size",
  "volume", "angle", "density", "intensity", "texture")
- $OrganQuant$: Organ measurement value (e.g., "5cm", "120ml")
- $AnomalyObject$: Abnormality to measure (e.g., "tumor", "fracture")
- $AnomalyDim$: Abnormality measurement type (e.g., "number", "length", "size",
  "volume", "angle", "density", "intensity", "texture")
- $AnomalyQuant$: Abnormality measurement value (e.g., "2cm", "5ml")
- $IndicatorName$: Clinical indicator name
- $IndicatorValue$: Clinical indicator value
- $Report$: Medical report content
- $Treatment$: Treatment recommendations

## Available Tool Categories
Tool categories must be used exactly as written:

[*Anatomy Classification Tool*, *Modality Classification Tool*,
*Organ Segmentation Tool*, *Anomaly Detection Tool*,
*Disease Diagnosis Tool*, *Disease Inference Tool*,
*Organ Biomarker Quantification Tool*,
*Anomaly Biomarker Quantification Tool*, *Indicator Evaluation Tool*,
*Report Generation Tool*, *Treatment Recommendation Tool*]

## Response Format for Part 1
For each query, respond ONLY with:

Known Info: [list any categories explicitly mentioned in the query]
Tool Chain: [list required tools connected by ->]

## Examples

Query 1: "For a straightforward approach to diagnosing the patient’s condition
based on her symptoms and the image, what diseases can be directly identified?"
Response:
Known Info: []
Tool Chain: [*Anatomy Classification Tool* -> *Modality Classification Tool*
             -> *Disease Diagnosis Tool*]

Query 2: "This 45-year-old male’s chest CT shows a 2cm nodule in the right lung.
Can you give a report?"
Response:
Known Info: [’$Information$’, ’$Anatomy$’, ’$Modality$’, ’$AnomalyObject$’,
            ’$AnomalyDim$’, ’$AnomalyQuant$’]
Tool Chain: [*Organ Segmentation Tool* -> *Anomaly Detection Tool*
             -> *Disease Inference Tool* -> *Report Generation Tool*]
             (because some information is provided, so
             *Anatomy Classification Tool*, *Modality Classification Tool*,
             *Anomaly Biomarker Quantification Tool* are optimized.)

## Important Rules
1\. Assume the medical image is already provided
2\. Use exact item category names with $$ as listed (e.g., ’$Anatomy$’)
3\. Use exact tool category names with ** as listed
   (e.g., ’*Anatomy Classification Tool*’)
4\. Only respond with Part 1 analysis - Parts 2 & 3 will be addressed
   in subsequent interactions
5\. Include only the categories explicitly mentioned in the query
6\. Connect tools using -> symbol

Please wait for my query.
When provided, analyze it following the format shown in the examples above.

{Patient Record}

{Query}

```

工具选择与执行。

{mdframed}

[backgroundcolor=lightgray!20] 工具选择与执行提示

```
# Next Step Planning

## Current Status
Current results dictionary: {value_dict}

## Planning Guidelines
1\. Reference your high-level tool chain from Part 1 decomposition
2\. Consider current results to refine specific tool selection
3\. Maintain sequential progression according to planned workflow
4\. Adjust tool selection if needed based on intermediate results
5\. Check if the tool category is missing when this category of tools is required
6\. Check if the tool is suitable for the detected Anatomy and Modality in reserved
value dictionary based on the Tool description Ability and Property
7\. Check if the result in reserved value dictionary can be derived from each tool used
in former steps based on the limited label list described in Tool Ability
8\. If no suitable tool exists, identify which type of denial applies:
   - Missing tool category
   - Missing specific modality-anatomy tool
   - Insufficient tool capability

## Input Requirements
1\. Required inputs: Must include all mandatory inputs specified in tool description
2\. Optional inputs: Include if available and beneficial to tool performance
3\. Do not include variables that are not relevant to the tool’s function
4\. All variables must exist in the current results dictionary
5\. Use proper $$ notation for all variables

## Response Format
For ongoing analysis (if not final step):
<Call>
    <Purpose>Brief, clear statement of this step’s goal in context of overall
    analysis</Purpose>
    <Tool>TOOL[number] - must match available specific tools</Tool>
    <Input>[’$variable1$’, ’$variable2$’, ...] - use only existing variables from
    results</Input>
</Call>

For final step only:
<EndCall>
    <Purpose>Brief, clear statement of this final step’s goal</Purpose>
    <Tool>TOOL[number] - must match available specific tools</Tool>
    <Input>[’$variable1$’, ’$variable2$’, ...] - use only existing variables from
    results</Input>
</EndCall>

When a tool category is completely missing:
<NoCall>
    <Purpose>The purpose requiring a missing tool category</Purpose>
    <Category>The missing category from [’Anatomy Classifier’, ’Modality Classifier’,
    ’Organ Segmentor’, ’Anomaly Detector’, ’Disease Diagnoser’, ’Disease Inferencer’,
    ’Biomarker Quantifier’, ’Indicator Evaluator’, ’Report Generator’, ’Treatment
    Recommender’]</Category>
    <Anatomy>Universal</Anatomy>
    <Modality>Universal</Modality>
    <Ability>CategoryMissing</Ability>
</NoCall>

When specific tools for a modality-anatomy combination are missing:
<NoCall>
    <Purpose>The purpose requiring a specific modality-anatomy tool</Purpose>
    <Category>The required tool category</Category>
    <Anatomy>The specific anatomy from [’Universal’, ’Head and Neck’, ’Chest’,
    ’Breast’, ’Abdomen and Pelvis’, ’Limb’, ’Spine’]</Anatomy>
    <Modality>The specific modality from [’Universal’, ’X-ray’, ’CT’, ’MRI’,
    ’Ultrasound’]</Modality>
    <Ability>SpecificToolMissing</Ability>
</NoCall>

When existing tools lack required capabilities:
<NoCall>
    <Purpose>The purpose requiring advanced capabilities</Purpose>
    <Category>The category of existing but insufficient tools</Category>
    <Anatomy>The relevant anatomy</Anatomy>
    <Modality>The relevant modality</Modality>
    <Ability>InsufficientCapability</Ability>
</NoCall>

## Format Requirements
1\. Maintain proper XML structure
2\. Use exact tool numbers as specified in tool descriptions
3\. Mark all variables with $$ notation
4\. Include only existing variables from results dictionary
5\. Keep purpose statements clear and concise
6\. Brief response only includes one Call, EndCall, or NoCall XML part without
additional explanations
7\. For NoCall responses, use the appropriate format based on denial type

## Decision Making Process
1\. Review planned tool chain from Part 1
2\. Check current results in value dictionary
3\. Check if tool category is missing when this category of tools is required
4\. Check tool Ability and Property in detail to judge its suitability for detected
Anatomy and Modality in the value dictionary
5\. Check if the result in reserved value dictionary can be derived from each tool used
in former steps based on the limited label list described in Tool Ability
6\. Evaluate tool availability and capability:
   - Is the required tool category available?
   - Are specific tools available for the needed modality-anatomy combination?
   - Do available tools have sufficient capabilities?
7\. If tools are insufficient, use appropriate NoCall format
8\. If tools are available, select and format appropriate Call/EndCall
9\. Use <EndCall> only if this will be the final step

Please provide your next step based on:
- Original tool chain plan
- Current results
- Available specific tools
- Remaining analysis needs
- Tool availability and capability assessment

```

响应生成。 {mdframed}[backgroundcolor=lightgray!20] 响应生成提示

```
Based on your Part 1 analysis plan, Part 2 tool execution sequence, and the final
results dictionary {value_dict}, provide:

    1\. A concise answer to the initial question
    2\. Key supporting evidence from your results
    3\. How your findings align with the planned analysis

Keep your response brief and focused on directly answer the initial question.

```

### 深入案例研究

在这里，我们从智能体核心评估工作流中选择一个典型案例来演示该过程，在该过程中，我们使用基于任务类型“异常生物标志物计算”的问答对和患者记录（62岁女性，患有高血压、膝关节骨关节炎和慢性颈痛，且颈部僵硬辐射至右肩）在NR. Denyl2工具集条件下，使用Claude-3.5-Sonnet作为智能体核心，记录其所做的每个决策。我们可以观察到该示例所反映的优点和局限性。

初始输入。智能体核心接收患者信息及虚拟影像。在我们的评估任务“异常生物标志物计算”中，我们基于患者的完整病历生成相应的问答对。初始输入如下：

{mdframed}

[backgroundcolor=lightgray!20] 初始输入

```
$Information$: {
    "Age": "62",
    "Sex": "Female",
    "Height": "165",
    "Weight": "72",
    "History": "Hypertension, osteoarthritis of the knees",
    "Complaint": "Chronic neck pain and stiffness, radiating pain to right shoulder"
},

$Query$: From an anomaly perspective in a specific medical image, after identifying
the type and area, could you quantify specific biomarker characteristics?

$Image$: ‘PLACEHOLDER_IMAGE’

```

任务分解。智能体核心通过分析患者信息并识别关键数据进行处理，以便提取相关数据。它确定完成任务所需的高层次工具链。智能体核心随后将所有相关信息存储在内存库中，并建立一个工具类别链以指导后续的执行。该过程如下所示：

{mdframed}

[backgroundcolor=lightgray!20] 阶段 1：任务分解

```
Initial Output: Known Info: []
Tool Chain: [*Anatomy Classification Tool* -> *Modality Classification Tool* ->
*Anomaly Detection Tool* -> *Anomaly Biomarker Quantification Tool*]
Initial Value Dict: {’$Image$’: ’PLACEHOLDER_IMAGE’, ’$Information$’: ’PLACEHOLDER_
INFORMATION’}
Initial Score Dict: {’$Image$’: 1.0, ’$Information$’: 1.0}
Initial Fixed Dict: frozendict.frozendict({’$Image$’: 1.0, ’$Information$’: 1.0})
High-level Tool chain: Anatomy Classification Tool -> Modality Classification Tool ->
Anomaly Detection Tool -> Anomaly Biomarker Quantification Tool

Memory bank: {’$Image$’: ’PLACEHOLDER_IMAGE’, ’$Information$’: ’PLACEHOLDER_
INFORMATION’}
Score bank: {’$Image$’: 1.0, ’$Information$’: 1.0}
Fixed bank: frozendict.frozendict({’$Image$’: 1.0, ’$Information$’: 1.0})

```

工具选择与执行：工具选择与执行的第一阶段开始。在每一步中，智能体核心将规划的高层次工具链与内存库中存储的信息结合，生成工具API调用，指定目的、工具名称和输入参数。平台随后通过激活所选工具并处理输入来执行API调用。在成功执行后，工具的输出被存储在内存库中。我们根据NR. Denyl2条件配置工具集，在该条件下，异常检测工具与所提供的$Image$特征（头部和颈部X光）的解剖学和模态存在不匹配。建立的工具集如下：

{mdframed}

[backgroundcolor=lightgray!20] 工具集描述

```

"TOOL1": {
    "Name": "TOOL1",
    "Category": "Anatomy Classifier",
    "Ability": "Determine the anatomy of the Image.",
    "Property": "Universal Anatomy Classifier",
    "Compulsory Input": [
        "$Image$"
    ],
    "Optional Input": [],
    "Output": [
        "$Anatomy$"
    ],
    "Performance": "Score from 0.95 to 0.95, increases with optional inputs"
},
"TOOL2": {
    "Name": "TOOL2",
    "Category": "Modality Classifier",
    "Ability": "Determine the modality of the Image.",
    "Property": "Universal Modality Classifier",
    "Compulsory Input": [
        "$Image$"
    ],
    "Optional Input": [],
    "Output": [
        "$Modality$"
    ],
    "Performance": "Score from 0.95 to 0.95, increases with optional inputs"
},

...

"TOOL5": {
    "Name": "TOOL5",
    "Category": "Anomaly Detector",
    "Ability": "Given the Limb Ultrasound Image, determine the location and
    type of abnormality.",
    "Property": "Anomaly Detector only suitable for Limb Ultrasound image",
    "Compulsory Input": [
        "$Image$"
    ],
    "Optional Input": [],
    "Output": [
        "$AnomalyMask$",
        "$AnomalyObject$"
    ],
    "Performance": "Score from 0.8 to 0.8, increases with optional inputs"
},
"TOOL6": {
    "Name": "TOOL6",
    "Category": "Anomaly Detector",
    "Ability": "Given the Breast MRI Image, determine the location and type
    of abnormality.",
    "Property": "Anomaly Detector only suitable for Breast MRI image",
    "Compulsory Input": [
        "$Image$"
    ],
    "Optional Input": [],
    "Output": [
        "$AnomalyMask$",
        "$AnomalyObject$"
    ],
    "Performance": "Score from 0.8 to 0.8, increases with optional inputs"
},

...

"TOOL8": {
    "Name": "TOOL8",
    "Category": "Disease Diagnoser",
    "Ability": "Given the Head and Neck X-ray Image, diagnose the disease.",
    "Property": "Disease Diagnoser only suitable for Head and Neck X-ray image",
    "Compulsory Input": [
        "$Image$"
    ],
    "Optional Input": [],
    "Output": [
        "$Disease$"
    ],
    "Performance": "Score from 0.75 to 0.75, increases with optional inputs"
},

...

"TOOL10": {
    "Name": "TOOL10",
    "Category": "Biomarker Quantifier",
    "Ability": "Measure the anomaly biomarker of the Image.",
    "Property": "Universal Anomaly Biomarker Quantifier",
    "Compulsory Input": [
        "$Image$",
        "$AnomalyObject$",
        "$AnomalyMask$"
    ],
    "Optional Input": [
        "$AnomalyDim$"
    ],
    "Output": [
        "$AnomalyDim$",
        "$AnomalyQuant$"
    ],
    "Performance": "Score from 0.75 to 0.8, increases with optional inputs"
},

...

```

在第一步中，智能体核心选择了解剖学分类工具。我们观察到，在工具执行后，解剖学信息已成功存储在内存库中：

{mdframed}

[backgroundcolor=lightgray!20] 工具选择与执行 第1步

```
Step 1 starts!
Stepoutput: Based on the tool chain from Part 1 (Anatomy Classification Tool ->
Modality Classification Tool -> Anomaly Detection Tool -> Anomaly Biomarker
Quantification Tool) and current results dictionary, I’ll proceed with the first step:

<Call>
    <Purpose>Determine the anatomy region of the medical image</Purpose>
    <Tool>TOOL1</Tool>
    <Input>[’$Image$’]</Input>
</Call>
Call Dict: {’Purpose’: ’Determine the anatomy region of the medical image’, ’Tool’:
’TOOL1’, ’Input’: [’$Image$’]}
Memory bank: {’$Image$’: ’PLACEHOLDER_IMAGE’, ’$Information$’: ’PLACEHOLDER_
INFORMATION’, ’$Anatomy$’: ’Head and Neck’}
Score bank: {’$Image$’: 1.0, ’$Information$’: 1.0, ’$Anatomy$’: 0.95}
Fixed bank: frozendict.frozendict({’$Image$’: 1.0, ’$Information$’: 1.0})
Step 1 completes!

```

第二步中，选择并执行了模态分类工具。成功执行的过程如下所示。我们可以观察到，模态信息在工具执行后被添加到内存库中。

{mdframed}

[backgroundcolor=lightgray!20] 工具选择与执行步骤 2

```
Step 2 starts!
Stepoutput: Based on the tool chain and current results showing Head and Neck anatomy,
the next step is to determine the image modality:

<Call>
    <Purpose>Determine the imaging modality of the medical image</Purpose>
    <Tool>TOOL2</Tool>
    <Input>[’$Image$’]</Input>
</Call>
Call Dict: {’Purpose’: ’Determine the imaging modality of the medical image’, ’Tool’:
’TOOL2’, ’Input’: [’$Image$’]}
Memory bank: {’$Image$’: ’PLACEHOLDER_IMAGE’, ’$Information$’: ’PLACEHOLDER_
INFORMATION’, ’$Anatomy$’: ’Head and Neck’, ’$Modality$’: ’X-ray’}
Score bank: {’$Image$’: 1.0, ’$Information$’: 1.0, ’$Anatomy$’: 0.95, ’$Modality$’:
0.95}
Fixed bank: frozendict.frozendict({’$Image$’: 1.0, ’$Information$’: 1.0})
Step 2 completes!

```

在第三步，与预期的器官分割工具的使用相反，反而调用了疾病诊断工具。虽然这个工具选择与当前任务无关，但执行没有出错。工具调用的详细情况如下：

{mdframed}

[backgroundcolor=lightgray!20] 工具选择与执行步骤 3

```
Step 3 starts!
Stepoutput: Given the current results showing Head and Neck anatomy and X-ray modality,
the next step is to detect any anomalies in the medical image:

<Call>
    <Purpose>Detect abnormalities in the Head and Neck X-ray image</Purpose>
    <Tool>TOOL8</Tool>
    <Input>[’$Image$’]</Input>
</Call>
Call Dict: {’Purpose’: ’Detect abnormalities in the Head and Neck X-ray image’, ’Tool’:
’TOOL8’, ’Input’: [’$Image$’]}
Memory bank: {’$Image$’: ’PLACEHOLDER_IMAGE’, ’$Information$’: ’PLACEHOLDER_
INFORMATION’, ’$Anatomy$’: ’Head and Neck’, ’$Modality$’: ’X-ray’, ’$Disease$’:
’Cervical spine degenerative changes’}
Score bank: {’$Image$’: 1.0, ’$Information$’: 1.0, ’$Anatomy$’: 0.95, ’$Modality$’:
0.95, ’$Disease$’: 0.75}
Fixed bank: frozendict.frozendict({’$Image$’: 1.0, ’$Information$’: 1.0})
Step 3 completes!

```

在第四步，当选择异常检测工具时，代理核心正确识别出工具集中的可用工具缺乏检测和定位头颈部 X 光图像中异常的能力。如下面所示，代理核心适当地拒绝了这个无效操作，并成功识别了工具的能力差距。

{mdframed}

[backgroundcolor=lightgray!20] 工具选择与执行步骤 4

```
Step 4 starts!
Stepoutput: Before we can quantify biomarkers (per the original tool chain), we need
the anomaly detection results first. Looking at the available tools for Head and Neck
X-ray anomaly detection:

<NoCall>
    <Purpose>Detect specific anomalies in Head and Neck X-ray for biomarker
    quantification</Purpose>
    <Category>Anomaly Detector</Category>
    <Anatomy>Head and Neck</Anatomy>
    <Modality>X-ray</Modality>
    <Ability>SpecificToolMissing</Ability>
</NoCall>
Deny Call Dict: {’Purpose’: ’Detect specific anomalies in Head and Neck X-ray for
biomarker quantification’, ’Category’: ’Anomaly Detector’, ’Anatomy’: ’Head and Neck’,
’Modality’: ’X-ray’, ’Ability’: ’SpecificToolMissing’}Agent denies the call because no
suitable tool is found.

```

总体而言，尽管代理核心展示了正确的初始化和工具链规划，但在工具选择与执行阶段出现了偏差。尽管每一轮都可以访问工具链指导，代理核心未能遵循这些指示，导致不必要的疾病诊断工具调用。然而，执行过程中没有发生任何输入输出错误，代理核心成功识别了工具的能力限制，并因缺失的功能适当地终止了任务执行。
