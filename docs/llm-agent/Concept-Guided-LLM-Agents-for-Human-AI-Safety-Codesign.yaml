- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:48:09'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:48:09
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Concept-Guided LLM Agents for Human-AI Safety Codesign
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念引导的 LLM 代理用于人类-AI 安全共同设计
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.15317](https://ar5iv.labs.arxiv.org/html/2404.15317)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.15317](https://ar5iv.labs.arxiv.org/html/2404.15317)
- en: Florian Geissler¹, Karsten Roscher¹, and Mario Trapp^(1, 2)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Florian Geissler¹, Karsten Roscher¹, 和 Mario Trapp^(1, 2)
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative AI is increasingly important in software engineering, including safety
    engineering, where its use ensures that software does not cause harm to people.
    This also leads to high quality requirements for generative AI. Therefore, the
    simplistic use of Large Language Models (LLMs) alone will not meet these quality
    demands. It is crucial to develop more advanced and sophisticated approaches that
    can effectively address the complexities and safety concerns of software systems.
    Ultimately, humans must understand and take responsibility for the suggestions
    provided by generative AI to ensure system safety. To this end, we present an
    efficient, hybrid strategy to leverage LLMs for safety analysis and Human-AI codesign.
    In particular, we develop a customized LLM agent that uses elements of prompt
    engineering, heuristic reasoning, and retrieval-augmented generation to solve
    tasks associated with predefined safety concepts, in interaction with a system
    model graph. The reasoning is guided by a cascade of micro-decisions that help
    preserve structured information. We further suggest a graph verbalization which
    acts as an intermediate representation of the system model to facilitate LLM-graph
    interactions. Selected pairs of prompts and responses relevant for safety analytics
    illustrate our method for the use case of a simplified automated driving system.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 在软件工程中变得越来越重要，包括安全工程，在这些领域，它的使用确保软件不会对人造成伤害。这也导致了对生成式 AI 高质量的要求。因此，仅仅使用大型语言模型（LLMs）是不足以满足这些质量需求的。至关重要的是开发更先进、更复杂的方法，以有效解决软件系统的复杂性和安全问题。*最终*，人类必须理解并对生成式
    AI 提供的建议负责，以确保系统安全。为此，我们提出了一种高效的混合策略，以利用 LLMs 进行安全分析和人类-AI 共同设计。特别地，我们开发了一个定制的
    LLM 代理，该代理使用提示工程、启发式推理和增强生成的元素来解决与预定义安全概念相关的任务，并与系统模型图进行互动。推理由一系列微决策引导，这些决策有助于保持结构化信息。我们进一步建议了一种图形语言化，它作为系统模型的中间表示，以促进
    LLM-图形互动。选择的与安全分析相关的提示和响应对展示了我们的方法，适用于简化自动驾驶系统的用例。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: The advent of transformer-based (Vaswani et al. [2017](#bib.bib17)) large language
    models (LLMs) has sparked enormous popularity of generative artificial intelligence
    (AI) for creative, text-based tasks. Representative of this trend is the reported
    record of OpenAI’s ChatPGT for the fastest growing user base of all times in February
    2023 (Reuters [2023](#bib.bib13)). The high quality of auto-generated text has
    inspired the exploration of LLMs for tasks that involve structured data, such
    as knowledge graphs. In particular, a widely desired use case is the application
    of LLMs to safety-analytical tasks (Jin et al. [2023](#bib.bib10); Pan et al.
    [2023](#bib.bib12); Wang et al. [2023](#bib.bib18)), for example, reasoning about
    fault propagation in model graphs and associated risks. Attempts to make use of
    LLMs for a formal hazard analysis have been made with moderate success (Diemert
    and Weber [2023](#bib.bib5)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 基于变换器的（Vaswani et al. [2017](#bib.bib17)）大型语言模型（LLMs）的出现引发了生成式人工智能（AI）在创意文本任务中的巨大受欢迎程度。代表这一趋势的是
    OpenAI 的 ChatGPT 在 2023 年 2 月创下的所有时代用户基础增长最快的记录（Reuters [2023](#bib.bib13)）。自动生成文本的高质量激发了对
    LLMs 在涉及结构化数据的任务中的探索，例如知识图谱。特别地，一个广泛期望的用例是将 LLMs 应用于安全分析任务（Jin et al. [2023](#bib.bib10);
    Pan et al. [2023](#bib.bib12); Wang et al. [2023](#bib.bib18)），例如对模型图中的故障传播及相关风险进行推理。对
    LLMs 进行正式危险分析的尝试取得了适度的成功（Diemert and Weber [2023](#bib.bib5)）。
- en: 'A particular challenge lies in the transformation of verbalized content to
    a structured graph information, and vice versa. Since the text generation process
    is of statistical nature, thus not bound by logical constraints, LLM responses
    will not necessarily preserve information structures of a given input. Existing
    strategies to tackle this problem can be broadly categorized as follows (Jin et al.
    [2023](#bib.bib10)): 1) Prompt-engineering to encourage specific output formats
    or structural rules; 2) Heuristic or algorithmic reasoning: Encouraging the LLM
    to perform chain-of-thought (CoT) reasoning, for example, to solve the problem
    step by step following self-generated or predetermined instructions; 3) Making
    use of external knowledge using retrieval-augmented generation (RAG), for example
    via non-AI tools; 4) Fine-tuning or retraining models to empirically minimize
    the loss of structured information, see e.g., GraphGPT (Tang et al. [2023](#bib.bib14)).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别的挑战在于将口头表达的内容转换为结构化的图形信息，反之亦然。由于文本生成过程具有统计性质，因此不受逻辑约束，LLM的回应不一定会保留给定输入的信息结构。解决这一问题的现有策略可以大致分类如下（Jin
    et al. [2023](#bib.bib10)）：1) 提示工程，以鼓励特定输出格式或结构规则；2) 启发式或算法推理：鼓励LLM进行链式思维（CoT）推理，例如，逐步解决问题，遵循自生成或预定的指令；3)
    利用检索增强生成（RAG）使用外部知识，例如通过非AI工具；4) 微调或重新训练模型，以实证方式最小化结构化信息的丢失，例如见GraphGPT（Tang et
    al. [2023](#bib.bib14)）。
- en: '![Refer to caption](img/f96a1618b572d50cb4e5a966d35a9f9d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/f96a1618b572d50cb4e5a966d35a9f9d.png)'
- en: 'Figure 1: Layout of the Human-AI safety codesign framework: A user interacts
    with the LLM agent through a chat prompt and receives a text response. The LLM
    agent interfaces to a database containing a graph description of the system model
    in IR, as well as safety concepts, and analysis tools. System manipulations can
    update the database and alter the system model. The system model and its changes
    are displayed to the user.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：人类与人工智能安全共设计框架的布局：用户通过聊天提示与LLM代理进行交互，并接收文本回应。LLM代理连接到一个数据库，该数据库包含系统模型的图形描述（以IR形式呈现）、安全概念和分析工具。系统操作可以更新数据库并改变系统模型。系统模型及其更改会显示给用户。
- en: '![Refer to caption](img/1af2cc541893a29e74ece2b2f4336546.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1af2cc541893a29e74ece2b2f4336546.png)'
- en: 'Figure 2: Outline of the workflow of LLM agent decisions and database interactions.
    The custom agent runs a cascading decision layer to identify the task type, and
    a subsequent layer to formulate the task for information retrieval. The latter
    looks up knowledge from a vectorstore database, or uses functional tools to calculate
    for example the critical path.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：LLM代理决策和数据库交互的工作流程概述。定制代理运行一个级联决策层来识别任务类型，并通过随后的层来制定信息检索任务。后者从向量存储数据库中查找知识，或使用功能工具计算例如关键路径。
- en: 'This article presents a concept-guided approach aimed at enhancing the capabilities
    of LLMs for graph analysis and manipulation, particularly in the context of safety-relevant
    developments. To achieve this goal, we have integrated the strengths of LLMs with
    the rigorous standards of safety engineering models and analysis. Starting from
    a structured system model graph, we first establish a verbalized intermediate
    representation (IR) of the system to facilitate the comprehension of its components
    and relationships by the LLM. A custom LLM agent is designed who deploys a hybrid
    strategy featuring the techniques 1) to 3) above: The agent performs a series
    of LLM calls to categorize and formalize the task at hand according to predefined
    concepts. Subsequently, RAG techniques are leveraged to offload structural computations
    to external functions. We test our method for the example of a simplified automated
    driving architecture, and present selected experimental results for the tasks
    of fault propagation, critical path finding, single-points-of-failure detection,
    and node replication. Our work provides the basis for an interactive, LLM-based
    Human-AI safety codesign framework.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种概念引导的方法，旨在增强大语言模型（LLMs）在图分析和操作中的能力，特别是在安全相关开发的背景下。为了实现这一目标，我们将LLMs的优势与安全工程模型和分析的严格标准相结合。从一个结构化的系统模型图开始，我们首先建立系统的口头中间表示（IR），以便LLM能够理解其组件及关系。我们设计了一个自定义LLM代理，采用了上述1)到3)的混合策略：代理通过一系列LLM调用，根据预定义的概念对任务进行分类和形式化。随后，利用RAG技术将结构计算卸载到外部函数。我们在简化的自动驾驶架构示例上测试了我们的方法，并展示了在故障传播、关键路径寻找、单点故障检测和节点复制等任务上的部分实验结果。我们的工作为一个互动的、基于LLM的人工智能安全共同设计框架奠定了基础。
- en: Model
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: The overall system layout is shown in Fig. [1](#Sx1.F1 "Figure 1 ‣ Introduction
    ‣ Concept-Guided LLM Agents for Human-AI Safety Codesign"). Key components of
    our architecture are explained in the following.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的整体布局如图 [1](#Sx1.F1 "Figure 1 ‣ Introduction ‣ Concept-Guided LLM Agents for
    Human-AI Safety Codesign")所示。我们架构的关键组件将在下文中解释。
- en: 'System model and intermediate representation: The system model contains the
    system architecture, including the system components and their interactions, as
    well as additional safety-related information required to model fault propagation
    within the system. To ensure interoperability with established industrial meta
    model formats, we create the system model with the Eclipse-based OSATE tool (Carnegie
    Mellon University [2023](#bib.bib3)) and export the resulting ECore file as xml.
    The elements of the xml model (EClass, EReference, EAttribute) can be directly
    mapped onto the elements of a generic graph (nodes, edges, attributes). Even though
    LLMs are capable of reading and interpreting xml structures directly, we find
    that inaccuracies can be reduced when operating with a system description that
    has a closer resemblance with natural language. Therefore, we further verbalize
    the xml system model to an IR which takes an intuitive list structure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 系统模型和中间表示：系统模型包含系统架构，包括系统组件及其交互，以及建模系统内故障传播所需的额外安全相关信息。为了确保与已建立的工业元模型格式的互操作性，我们使用基于Eclipse的OSATE工具（卡内基梅隆大学
    [2023](#bib.bib3)）创建系统模型，并将生成的ECore文件导出为xml。xml模型的元素（EClass、EReference、EAttribute）可以直接映射到通用图的元素（节点、边、属性）。尽管LLMs能够直接读取和解释xml结构，但我们发现，当使用与自然语言更接近的系统描述时，可以减少不准确性。因此，我们进一步将xml系统模型口头化为具有直观列表结构的IR。
- en: 'Nodes:-  Node  1-  Node  2-  ...Edges:-  Node  1  -->  Node  2-  ...Attributes:-  Node  1:  Attribute  1-  ...'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '节点：-  节点 1-  节点 2-  ...边：-  节点 1  -->  节点 2-  ...属性：-  节点 1:  属性 1-  ...'
- en: This IR represents the basis of system-relevant information for the LLM agent.
    For safety analysis, we assume that each node is subject to possible failure.
    In order to model the propagation of system faults, we populate graph node attributes
    with verbalized logic of fault gates (e.g., AND, OR, N-out-of-M) to represent
    fault trees (Avižienis et al. [2004](#bib.bib1); Trapp [2016](#bib.bib16)). Further,
    start and end nodes of the system graph are specified with corresponding attributes.
    For the current proof-of-concept, we used an integrated system-safety model. However,
    in model-based safety engineering, long-lasting work has been conducted on integrating
    system and safety models (Domis and Trapp [2008](#bib.bib7)), which can be used
    as a scalable basis for further development.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 IR 代表了 LLM 代理的系统相关信息基础。对于安全分析，我们假设每个节点可能会发生故障。为了建模系统故障的传播，我们将图节点属性填充为故障门的语言逻辑（例如，AND，OR，N-out-of-M）以表示故障树（Avižienis
    等 [2004](#bib.bib1)；Trapp [2016](#bib.bib16)）。此外，系统图的开始和结束节点用相应的属性进行了指定。对于当前的概念验证，我们使用了集成的系统安全模型。然而，在基于模型的安全工程中，已经进行了长期的工作来整合系统和安全模型（Domis
    和 Trapp [2008](#bib.bib7)），这些模型可以作为进一步开发的可扩展基础。
- en: 'LLM: At the core, we use OpenAI’s $GPT3.5-turbo$ (OpenAI [2023](#bib.bib11))
    model for LLM inferences. As our concept-guided approach requires the LLM to solve
    a series of rather simple micro-decisions, we expect to see in further work, that
    also much smaller and simpler models such as LLama2 (Touvron et al. [2023](#bib.bib15))
    or Mistral-7B (Jiang et al. [2023](#bib.bib9)) suffice for this purpose.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: LLM：核心部分，我们使用 OpenAI 的 $GPT3.5-turbo$（OpenAI [2023](#bib.bib11)）模型进行 LLM 推理。由于我们的概念引导方法要求
    LLM 解决一系列相当简单的微决策，我们预计在进一步的工作中，像 LLama2（Touvron 等 [2023](#bib.bib15)）或 Mistral-7B（Jiang
    等 [2023](#bib.bib9)）这样的更小、更简单的模型也足以完成这个目的。
- en: '![Refer to caption](img/df29db194468644323abbf8c3bd36676.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/df29db194468644323abbf8c3bd36676.png)'
- en: 'Figure 3: Example use case of a simplified automated driving system. The node
    labels denote the component name (top row) and the fault gate attribute below
    (if none is given, an AND fault gate of all inputs is assumed). $2OO3$ means that
    two out of three of the listed inputs are required. Start and end nodes are further
    labeled explicitly. The figure is a pydot visualization of the ECore file.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：简化自动驾驶系统的示例用例。节点标签表示组件名称（顶行）和下面的故障门属性（如果未给出，则假设为所有输入的 AND 故障门）。 $2OO3$ 意味着需要列出输入中的两个。开始和结束节点进一步明确标记。该图是
    ECore 文件的 pydot 可视化。
- en: 'LLM agent: LLMs are conveniently orchestrated by functional wrappers called
    agents, which can be configured to self-induce an iterative chain of thoughts,
    or to interface automatically to external tools and sources of information. We
    here use the LangChain library (Harrison Chase [2022](#bib.bib8)) to design a
    customized agent. Importantly, we find that equipping an agent with multiple tools
    can quickly lead to inaccurate tool usage, unless the verbalized trigger conditions
    are well-separated in linguistic space. At the same time, for self-induced CoT
    flows, it is challenging to incorporate and assert procedural safety guardrails.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理：LLM 通过称为代理的功能包装器方便地进行编排，这些代理可以配置为自我引发一个迭代思维链，或者自动与外部工具和信息源接口。我们在这里使用
    LangChain 库（Harrison Chase [2022](#bib.bib8)）来设计一个定制的代理。重要的是，我们发现，除非语言触发条件在语言空间中分隔良好，否则为代理配备多个工具很快会导致工具使用不准确。同时，对于自我引发的
    CoT 流程，整合和断言程序安全保护措施是具有挑战性的。
- en: 'We therefore implement a different workflow, as illustrated in Fig. [2](#Sx1.F2
    "Figure 2 ‣ Introduction ‣ Concept-Guided LLM Agents for Human-AI Safety Codesign"):
    The agent cascades the input prompt through a network of micro-decisions, where
    a single LLM call associates the input with the best match among only $2$ predefined
    concepts in each decision. For example, as shown in Fig. [2](#Sx1.F2 "Figure 2
    ‣ Introduction ‣ Concept-Guided LLM Agents for Human-AI Safety Codesign"), in
    the first decision node the agent associates the input with one of four possible
    task concepts of Safety question answering, System safety analysis, Suggestions
    for fault-tolerance, and Other. To improve the quality of the micro-decision,
    we use few-shot learning (Brown et al. [2020](#bib.bib2)) by augmenting the prompts
    with around ten hand-crafted example triggers for each concept. The last layer
    of our decision network is a Task formulation layer, where the fully identified
    task concept is used together with the given prompt to refine a specific task
    prompt. Finally, the external tools or information lookup mechanisms that are
    provided for this specific task are called and the result is rephrased as a user
    response. We find that this method overcomes some of the challenges mentioned
    above: The CoT flow is tightly guided by predefined concepts, yet allows sufficient
    flexibility in the prompt formulation, and tool triggers cannot overlap since
    they are strictly associated with specific task concepts.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们因此实施了不同的工作流程，如图 [2](#Sx1.F2 "Figure 2 ‣ Introduction ‣ Concept-Guided LLM
    Agents for Human-AI Safety Codesign")所示：代理将输入提示通过一个微决策网络，其中单个LLM调用将输入与每个决策中的两个预定义概念中的最佳匹配相关联。例如，如图 [2](#Sx1.F2
    "Figure 2 ‣ Introduction ‣ Concept-Guided LLM Agents for Human-AI Safety Codesign")所示，在第一个决策节点中，代理将输入与安全问题回答、系统安全分析、容错建议和其他四种可能的任务概念之一相关联。为了提高微决策的质量，我们通过使用少量示例学习（Brown
    et al. [2020](#bib.bib2)）来增强提示，每个概念大约有十个手工制作的示例触发器。我们决策网络的最后一层是任务制定层，在这里，完全确定的任务概念与给定的提示一起用于细化特定任务提示。最后，为此特定任务提供的外部工具或信息查找机制被调用，结果被重新表述为用户响应。我们发现，这种方法克服了一些上述提到的挑战：CoT流程严格按照预定义概念指导，但在提示制定上仍然保留足够的灵活性，且工具触发器不会重叠，因为它们严格与特定任务概念相关联。
- en: 'Database/toolset: We provide a collection of information that is retrieved
    from a knowledge base, or generated on demand with deterministic functions. This
    includes, but is not limited to the following: The IR of the system, documentation
    about safety practices, a function to calculate fault propagation using the fault
    gates retrieved from the system IR, a function to calculate the critical path
    using Dijkstra’s algorithm (Dijkstra [1959](#bib.bib6)) for the shortest path
    and start and end nodes from the IR, a function to find the single points of failure,
    a function to replicate a given node or edge in the model IR. The usage of these
    tools is triggered in a predefined way depending on the identified task category.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库/工具集：我们提供的信息集合来自知识库检索，或通过确定性函数按需生成。这包括但不限于以下内容：系统的IR、安全实践的文档、一个用于计算故障传播的函数，利用从系统IR中检索的故障门，一个使用Dijkstra算法（Dijkstra
    [1959](#bib.bib6)）计算最短路径和从IR中获取的起始和结束节点的函数、一个用于查找单点故障的函数、一个用于复制模型IR中给定节点或边的函数。根据识别出的任务类别，这些工具的使用以预定义的方式触发。
- en: '| Prompt | Response |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 响应 |'
- en: '| --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| What happens if Radar1, Radar2 and IMU have a fault? | In this scenario,
    the faulty components are IMU, Radar1, Radar2, and SignalProcessor. When these
    components have a fault, it can have several consequences for the system. The
    IMU (Inertial Measurement Unit) is responsible for measuring the orientation,
    velocity, and acceleration of the vehicle. If the IMU has a fault, it can lead
    to inaccurate measurements, which can affect the overall navigation and control
    of the vehicle. The radars (Radar1 and Radar2) are used for detecting and tracking
    objects in the environment. If these radars have a fault, it can result in missed
    or incorrect detections, which can impact the perception and decision-making capabilities
    of the system. The SignalProcessor is responsible for processing the sensor data
    and extracting relevant information. If the SignalProcessor has a fault, it can
    lead to incorrect or incomplete data processing, which can affect the overall
    performance and reliability of the system. Overall, when these components have
    a fault, it can lead to degraded performance, reduced safety, and potentially
    compromised functionality of the system. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 如果Radar1、Radar2和IMU出现故障会发生什么？ | 在这种情况下，故障组件是IMU、Radar1、Radar2和SignalProcessor。当这些组件出现故障时，会对系统产生若干后果。IMU（惯性测量单元）负责测量车辆的方向、速度和加速度。如果IMU出现故障，可能导致测量不准确，从而影响车辆的整体导航和控制。雷达（Radar1和Radar2）用于检测和跟踪环境中的物体。如果这些雷达出现故障，可能导致漏检或错误检测，从而影响系统的感知和决策能力。SignalProcessor负责处理传感器数据并提取相关信息。如果SignalProcessor出现故障，可能导致数据处理不正确或不完整，从而影响系统的整体性能和可靠性。总体而言，当这些组件出现故障时，可能导致性能下降、安全性降低，甚至可能影响系统的功能。'
- en: '| Show me the critical path. | The critical path in the given scenario includes
    the following components: Camera1, Camera2, CollisionAvoidance, GPS, IMU, ImageProcessor,
    Lidar1, Map, PathPlanner, PointCloudProcessor, SensorFusion, and VehicleController.
    The critical path represents the sequence of components that are essential for
    the system’s operation and have the longest duration in terms of time. These components
    are crucial for tasks such as perception, sensor fusion, planning, and control,
    and any faults or failures in these components can significantly impact the overall
    performance and safety of the system. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 展示关键路径。 | 在给定的场景中，关键路径包括以下组件：Camera1、Camera2、CollisionAvoidance、GPS、IMU、ImageProcessor、Lidar1、Map、PathPlanner、PointCloudProcessor、SensorFusion
    和 VehicleController。关键路径表示对系统操作至关重要且时间上最长的组件序列。这些组件对于感知、传感器融合、规划和控制等任务至关重要，任何这些组件的故障或失效都可能显著影响系统的整体性能和安全性。'
- en: '| Explain the critical path, given the last fault. | The critical path in this
    scenario, considering the last reported faulty system components, consists of
    the following components: Camera1, Camera3, CollisionAvoidance, GPS, ImageProcessor,
    Lidar1, Map, PathPlanner, PointCloudProcessor, SensorFusion, VehicleController,
    and VelocitySensor. The critical path represents the sequence of components and
    processes that are essential for the system’s operation and performance. Any delay
    or failure in these components can significantly impact the overall functionality
    and reliability of the system. It is important to note that the previously reported
    system faults, including IMU, Radar1, Radar2, and SignalProcessor, can also affect
    the critical path and further exacerbate the potential consequences to the system.
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 解释给定的最后一个故障下的关键路径。 | 在这种情况下，考虑到最后报告的故障系统组件，关键路径包括以下组件：Camera1、Camera3、CollisionAvoidance、GPS、ImageProcessor、Lidar1、Map、PathPlanner、PointCloudProcessor、SensorFusion、VehicleController
    和 VelocitySensor。关键路径表示对系统操作和性能至关重要的组件和过程的顺序。任何这些组件的延迟或故障都可能显著影响系统的整体功能和可靠性。需要注意的是，先前报告的系统故障，包括IMU、Radar1、Radar2和SignalProcessor，也可能影响关键路径，并进一步加剧对系统的潜在影响。'
- en: '| What are the single points of failure? | The single point of failure components
    in the given scenario are PathPlanner, VehicleController, Map, SensorFusion, CollisionAvoidance,
    and GPS. These components are considered single points of failure because if any
    of them were to fail, it could result in a complete system failure or significant
    degradation in the system’s performance. For example, if the PathPlanner fails,
    the system may not be able to generate safe and efficient trajectories for the
    vehicle. Similarly, if the VehicleController fails, the system may lose control
    over the vehicle’s movements. The Map, SensorFusion, CollisionAvoidance, and GPS
    components are also critical for accurate perception, situational awareness, and
    navigation, and their failure can have serious consequences for the overall system
    functionality. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 单点故障是什么？ | 在给定场景中，单点故障的组件包括 PathPlanner、VehicleController、Map、SensorFusion、CollisionAvoidance
    和 GPS。这些组件被认为是单点故障，因为如果其中任何一个组件出现故障，可能会导致系统的完全失败或系统性能的显著下降。例如，如果 PathPlanner 发生故障，系统可能无法为车辆生成安全和高效的轨迹。类似地，如果
    VehicleController 发生故障，系统可能会失去对车辆运动的控制。Map、SensorFusion、CollisionAvoidance 和 GPS
    组件对于准确的感知、态势意识和导航也至关重要，它们的故障可能对整体系统功能产生严重影响。'
- en: '| How would you make my system safer? | To make your system safer, I would
    suggest performing replication on the component SensorFusion. SensorFusion should
    be replicated because it is a critical component that relies on multiple inputs
    from ImageProcessor, SignalProcessor, and PointCloudProcessor. If SensorFusion
    fails, it can lead to incorrect data being sent to PathPlanner and CollisionAvoidance,
    compromising the overall safety of the system. By replicating SensorFusion, the
    system can continue to function even if one instance of SensorFusion fails, ensuring
    that accurate and reliable data is provided to the other components. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 你会如何使我的系统更安全？ | 为了使您的系统更安全，我建议对 SensorFusion 组件进行复制。SensorFusion 应该进行复制，因为它是一个依赖于来自
    ImageProcessor、SignalProcessor 和 PointCloudProcessor 多个输入的关键组件。如果 SensorFusion
    发生故障，可能会导致错误的数据传送到 PathPlanner 和 CollisionAvoidance，从而危及系统的整体安全。通过复制 SensorFusion，即使其中一个
    SensorFusion 实例发生故障，系统仍能继续运行，确保向其他组件提供准确和可靠的数据。'
- en: 'Table 1: Selected example prompts and responses. Refer to Fig. [3](#Sx2.F3
    "Figure 3 ‣ Model ‣ Concept-Guided LLM Agents for Human-AI Safety Codesign") for
    the system description. The example in row three references the agent’s memory,
    as last fault refers to the last mentioned system fault in the chat history.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：所选示例提示和响应。有关系统描述，请参阅图[3](#Sx2.F3 "Figure 3 ‣ Model ‣ Concept-Guided LLM
    Agents for Human-AI Safety Codesign")。第三行的示例引用了代理的记忆，因为“last fault”指的是聊天记录中最后提到的系统故障。
- en: Experiments
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验
- en: We test our model with the use case of a simplified automated driving system
    modeled in OSATE, see Fig. [3](#Sx2.F3 "Figure 3 ‣ Model ‣ Concept-Guided LLM
    Agents for Human-AI Safety Codesign"), here visualized with pydot (Carrera [2021](#bib.bib4)).
    Fault gates are implemented as respective node attributes and given in the figure
    below the node label, for example, the ImageProcessor node will turn faulty if
    at least two out of three ($2OO3$) camera input nodes are faulty. To verify the
    effectiveness of our concept-guided agent, we test our approach with sample questions
    in the domain of system safety design. Representative examples and results are
    given in Tab. [1](#Sx2.T1 "Table 1 ‣ Model ‣ Concept-Guided LLM Agents for Human-AI
    Safety Codesign"). In all examples, we find that the tasks have been accurately
    identified and formulated, and the correct information was retrieved with the
    appropriate tools. For example, the agent can make suggestions about modifying
    the graph to improve fault tolerance. In our implementation, this is based on
    the predefined concept of redundancy and the usage of the tool which finds single
    points of failures to select the best replication candidate. To modify the system
    graph, the agent uses the graph replication tool and updates the xml model accordingly.
    We further note that, in the response, the agent leverages general knowledge to
    relate the functionality of the relevant components with its impact on safety.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 OSATE 中建模的简化自动驾驶系统作为用例来测试我们的模型，见图[3](#Sx2.F3 "图 3 ‣ 模型 ‣ 面向概念的 LLM 代理用于人机安全协同设计")，这里通过
    pydot 进行可视化（Carrera [2021](#bib.bib4)）。故障门被实现为各自的节点属性，并在下方节点标签的图中给出，例如，如果至少两个（$2OO3$）摄像头输入节点发生故障，则
    ImageProcessor 节点会发生故障。为了验证我们面向概念的代理的有效性，我们通过系统安全设计领域的样本问题来测试我们的方法。代表性的示例和结果见表[1](#Sx2.T1
    "表 1 ‣ 模型 ‣ 面向概念的 LLM 代理用于人机安全协同设计")。在所有示例中，我们发现任务被准确识别和制定，且通过适当的工具检索到了正确的信息。例如，代理可以建议修改图表以提高故障容忍度。在我们的实现中，这基于冗余的预定义概念以及寻找单点故障的工具来选择最佳的复制候选者。为了修改系统图，代理使用图形复制工具并相应地更新
    xml 模型。我们进一步注意到，在响应中，代理利用一般知识将相关组件的功能与其对安全性的影响联系起来。
- en: Conclusion and Outlook
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论与展望
- en: 'Our approach of a concept-guided LLM agent overcomes two challenges typically
    encountered when solving generative text tasks on structured data: 1) Chain-of-thought
    processes derail and no longer comply with a set of required rules, or miss their
    goals, 2) Trigger conditions to retrieve external information via tools become
    inaccurate when the number of possible options increases. Instead, we here guide
    the thought process with a series of micro-decisions to ensure that the right
    tool triggers are met. We envision to extend our setup to more concepts and larger
    decision cascades, such that more complex tasks can be tackled. Our work provides
    the basis for an interactive framework where LLMs assist in Human-AI safety codesign.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的面向概念的 LLM 代理方法克服了在处理结构化数据上的生成文本任务时通常遇到的两个挑战：1）思维链过程脱轨，不再遵循一套所需的规则，或未能实现目标，2）当可选项数量增加时，触发条件变得不准确。相反，我们在这里通过一系列微决策来引导思维过程，以确保满足正确的工具触发条件。我们计划将我们的设置扩展到更多的概念和更大的决策级联，以便处理更复杂的任务。我们的工作为一个互动框架提供了基础，其中
    LLM 在人机安全协同设计中提供帮助。
- en: Acknowledgments
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was funded by the Bavarian Ministry for Economic Affairs, Regional
    Development and Energy as part of a project to support the thematic development
    of the Institute for Cognitive Systems.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了巴伐利亚经济事务、区域发展和能源部的资助，作为支持认知系统研究所主题发展的项目的一部分。
- en: References
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Avižienis et al. (2004) Avižienis, A.; Laprie, J. C.; Randell, B.; and Landwehr,
    C. 2004. Basic concepts and taxonomy of dependable and secure computing. *IEEE
    Transactions on Dependable and Secure Computing*, 1(1): 11–33.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Avižienis 等（2004）Avižienis, A.; Laprie, J. C.; Randell, B.; 和 Landwehr, C.
    2004. 可靠和安全计算的基本概念和分类。*IEEE 可靠和安全计算期刊*，1(1): 11–33。'
- en: Brown et al. (2020) Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan,
    J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal,
    S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler,
    D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray,
    S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever,
    I.; and Amodei, D. 2020. Language models are few-shot learners. *Advances in Neural
    Information Processing Systems*, 2020-Decem.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown et al. (2020) Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan,
    J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal,
    S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler,
    D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray,
    S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever,
    I.; and Amodei, D. 2020. 语言模型是少样本学习者。*神经信息处理系统进展*，2020-12月。
- en: 'Carnegie Mellon University (2023) Carnegie Mellon University. 2023. OSATE 2.13.
    https://osate.org/. Accessed: 2023-12-01.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carnegie Mellon University (2023) Carnegie Mellon University. 2023. OSATE 2.13.
    https://osate.org/. 访问日期：2023-12-01。
- en: 'Carrera (2021) Carrera, E. 2021. pydot. https://pypi.org/project/pydot/. Accessed:
    2023-12-01.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carrera (2021) Carrera, E. 2021. pydot. https://pypi.org/project/pydot/. 访问日期：2023-12-01。
- en: Diemert and Weber (2023) Diemert, S.; and Weber, J. H. 2023. Can Large Language
    Models Assist in Hazard Analysis? In *Lecture Notes in Computer Science (including
    subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)*,
    volume 14182 LNCS, 410–422. ISBN 9783031409523.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Diemert and Weber (2023) Diemert, S.; and Weber, J. H. 2023. 大型语言模型能否协助危害分析？见*计算机科学讲义（包括子系列人工智能讲义和生物信息学讲义）*，第14182卷
    LNCS，410–422。ISBN 9783031409523。
- en: 'Dijkstra (1959) Dijkstra, E. W. 1959. A note on two problems in connexion with
    graphs. *Numer. Math.*, 271: 269–271.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dijkstra (1959) Dijkstra, E. W. 1959. 关于图的两个问题的注记。*数值数学*，271: 269–271。'
- en: 'Domis and Trapp (2008) Domis, D.; and Trapp, M. 2008. Integrating Safety Analyses
    and Component-Based Design. In Harrison, M. D.; and Sujan, M.-A., eds., *Computer
    Safety, Reliability, and Security*, 58–71\. Berlin, Heidelberg: Springer Berlin
    Heidelberg. ISBN 978-3-540-87698-4.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Domis and Trapp (2008) Domis, D.; and Trapp, M. 2008. 整合安全分析与基于组件的设计。见Harrison,
    M. D.; 和Sujan, M.-A., 编，《*计算机安全、可靠性与安全性*》，58–71。柏林，海德堡：Springer Berlin Heidelberg。ISBN
    978-3-540-87698-4。
- en: 'Harrison Chase (2022) Harrison Chase. 2022. LangChain. https://github.com/langchain-ai/langchain.
    Accessed: 2023-12-01.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harrison Chase (2022) Harrison Chase. 2022. LangChain. https://github.com/langchain-ai/langchain.
    访问日期：2023-12-01。
- en: Jiang et al. (2023) Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;
    Chaplot, D. S.; de las Casas, D.; Bressand, F.; Lengyel, G.; Lample, G.; Saulnier,
    L.; Lavaud, L. R.; Lachaux, M.-A.; Stock, P.; Scao, T. L.; Lavril, T.; Wang, T.;
    Lacroix, T.; and Sayed, W. E. 2023. Mistral 7B. arXiv:2310.06825.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2023) Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;
    Chaplot, D. S.; de las Casas, D.; Bressand, F.; Lengyel, G.; Lample, G.; Saulnier,
    L.; Lavaud, L. R.; Lachaux, M.-A.; Stock, P.; Scao, T. L.; Lavril, T.; Wang, T.;
    Lacroix, T.; and Sayed, W. E. 2023. Mistral 7B. arXiv:2310.06825。
- en: 'Jin et al. (2023) Jin, B.; Liu, G.; Han, C.; Jiang, M.; Ji, H.; and Han, J.
    2023. Large Language Models on Graphs: A Comprehensive Survey. arXiv:2312.02783.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin et al. (2023) Jin, B.; Liu, G.; Han, C.; Jiang, M.; Ji, H.; and Han, J.
    2023. 图上的大型语言模型：一项综合调查。arXiv:2312.02783。
- en: 'OpenAI (2023) OpenAI. 2023. ChatGPT 3.5-turbo. https://openai.com/. Accessed:
    2023-12-01.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. ChatGPT 3.5-turbo. https://openai.com/. 访问日期：2023-12-01。
- en: 'Pan et al. (2023) Pan, S.; Luo, L.; Wang, Y.; Chen, C.; Wang, J.; and Wu, X.
    2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. arXiv:2306.08302.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan et al. (2023) Pan, S.; Luo, L.; Wang, Y.; Chen, C.; Wang, J.; and Wu, X.
    2023. 统一大型语言模型和知识图谱：一条路线图。arXiv:2306.08302。
- en: 'Reuters (2023) Reuters. 2023. ChatGPT sets record for fastest-growing user
    base - analyst note. https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/.
    Accessed: 2023-12-01.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reuters (2023) Reuters. 2023. ChatGPT 创下用户增长最快的记录 - 分析师报告。https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/.
    访问日期：2023-12-01。
- en: 'Tang et al. (2023) Tang, J.; Yang, Y.; Wei, W.; Shi, L.; Su, L.; Cheng, S.;
    Yin, D.; and Huang, C. 2023. GraphGPT: Graph Instruction Tuning for Large Language
    Models. arXiv:2310.13023.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tang et al. (2023) Tang, J.; Yang, Y.; Wei, W.; Shi, L.; Su, L.; Cheng, S.;
    Yin, D.; and Huang, C. 2023. GraphGPT: 图形指令调优的大型语言模型。arXiv:2310.13023。'
- en: 'Touvron et al. (2023) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.;
    Blecher, L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.;
    Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
    S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev,
    A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.;
    Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton,
    A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E. M.;
    Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J. X.;
    Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.; Rodriguez,
    A.; Stojnic, R.; Edunov, S.; and Scialom, T. 2023. Llama 2: Open Foundation and
    Fine-Tuned Chat Models. arXiv:2307.09288.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等（2023）Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi, A.;
    Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.; Blecher,
    L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.; Fu, J.;
    Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
    S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev,
    A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.;
    Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton,
    A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E.
    M.; Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J.
    X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.;
    Rodriguez, A.; Stojnic, R.; Edunov, S.; 和 Scialom, T. 2023. Llama 2：开放基础和微调聊天模型。arXiv:2307.09288。
- en: Trapp (2016) Trapp, M. 2016. Assuring Functional Safety in Open Systems of Systems.
    https://nbn-resolving.de/urn:nbn:de:hbz:386-kluedo-44221.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trapp（2016）Trapp, M. 2016. 确保开放系统中的功能安全。https://nbn-resolving.de/urn:nbn:de:hbz:386-kluedo-44221。
- en: 'Vaswani et al. (2017) Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.;
    Jones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention is all
    you need. *Advances in Neural Information Processing Systems*, 2017-Decem: 5999–6009.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等（2017）Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.;
    Gomez, A. N.; Kaiser, Ł.; 和 Polosukhin, I. 2017. 注意力机制即一切。*神经信息处理系统进展*，2017年12月：5999–6009。
- en: Wang et al. (2023) Wang, H.; Feng, S.; He, T.; Tan, Z.; Han, X.; and Tsvetkov,
    Y. 2023. Can Language Models Solve Graph Problems in Natural Language? arXiv:2305.10037.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2023）Wang, H.; Feng, S.; He, T.; Tan, Z.; Han, X.; 和 Tsvetkov, Y. 2023.
    语言模型能否解决自然语言中的图问题？arXiv:2305.10037。
