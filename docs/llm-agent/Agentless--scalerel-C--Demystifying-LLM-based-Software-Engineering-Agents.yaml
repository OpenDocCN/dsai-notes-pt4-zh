- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:42:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:42:30
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Agentless \scalerel*C: Demystifying LLM-based Software Engineering Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Agentless \scalerel*C: 揭示基于LLM的软件工程代理'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.01489](https://ar5iv.labs.arxiv.org/html/2407.01489)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.01489](https://ar5iv.labs.arxiv.org/html/2407.01489)
- en: Chunqiu Steven Xia^($*$)   Yinlin Deng      Soren Dunn                              Lingming
    Zhang
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Chunqiu Steven Xia^($*$)   Yinlin Deng      Soren Dunn                              Lingming
    Zhang
- en: University of Illinois Urbana-Champaign \scalerel *![[Uncaptioned image]](img/32dc28cbed3f8046e3707ce735d4d725.png)C
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 伊利诺伊大学厄本那-香槟分校 \scalerel *![[无标题图片]](img/32dc28cbed3f8046e3707ce735d4d725.png)C
- en: '{chunqiu2, yinlind2, sorend2, lingming}@illinois.edu Contributed equally with
    author ordering decided by [Nigiri](https://senseis.xmp.net/?Nigiri).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '{chunqiu2, yinlind2, sorend2, lingming}@illinois.edu 与作者按[Nigiri](https://senseis.xmp.net/?Nigiri)的决定顺序平等贡献。'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Recent advancements in large language models (LLMs) have significantly advanced
    the automation of software development tasks, including code synthesis, program
    repair, and test generation. More recently, researchers and industry practitioners
    have developed various autonomous *LLM agents* to perform end-to-end software
    development tasks. These agents are equipped with the ability to use tools, run
    commands, observe feedback from the environment, and plan for future actions.
    However, the complexity of these agent-based approaches, together with the limited
    abilities of current LLMs, raises the following question: *Do we really have to
    employ complex autonomous software agents?* To attempt to answer this question,
    we build Agentless – an *agentless* approach to automatically solve software development
    problems. Compared to the verbose and complex setup of agent-based approaches,
    Agentless employs a simplistic two-phase process of localization followed by repair,
    without letting the LLM decide future actions or operate with complex tools. Our
    results on the popular SWE-bench Lite benchmark show that surprisingly the simplistic
    Agentless is able to achieve both the highest performance (27.33%) and lowest
    cost ($0.34) compared with all existing open-source software agents! Furthermore,
    we manually classified the problems in SWE-bench Lite and found problems with
    exact ground truth patch or insufficient/misleading issue descriptions. As such,
    we construct SWE-bench Lite-$S$ by excluding such problematic issues to perform
    more rigorous evaluation and comparison. Our work highlights the current overlooked
    potential of a simple, interpretable technique in autonomous software development.
    We hope Agentless will help reset the baseline, starting point, and horizon for
    autonomous software agents, and inspire future work along this crucial direction.
    We have open-sourced Agentless at: [https://github.com/OpenAutoCoder/Agentless](https://github.com/OpenAutoCoder/Agentless)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）的进展显著推动了软件开发任务的自动化，包括代码合成、程序修复和测试生成。最近，研究人员和行业从业者开发了各种自主的*LLM代理*来执行端到端的软件开发任务。这些代理具备使用工具、运行命令、观察环境反馈和规划未来行动的能力。然而，这些基于代理的方法的复杂性，加上当前LLMs的能力有限，提出了以下问题：*我们真的需要使用复杂的自主软件代理吗？*
    为了尝试回答这个问题，我们构建了Agentless——一种*无代理*的方法来自动解决软件开发问题。与基于代理的方法的冗长和复杂设置相比，Agentless采用了简单的两阶段过程：定位后修复，而不让LLM决定未来行动或操作复杂工具。我们在流行的SWE-bench
    Lite基准上的结果表明，令人惊讶的是，简单的Agentless在所有现有的开源软件代理中实现了最高的性能（27.33%）和最低的成本（$0.34）！此外，我们手动分类了SWE-bench
    Lite中的问题，并发现了一些具有准确地面真值补丁或不充分/误导性问题描述的问题。因此，我们通过排除这些有问题的问题来构建SWE-bench Lite-$S$，以进行更严格的评估和比较。我们的工作突显了当前在自主软件开发中被忽视的简单、可解释技术的潜力。我们希望Agentless能帮助重设自主软件代理的基准、起点和视野，并激发未来在这一关键方向上的工作。我们已经开源了Agentless，地址为：[https://github.com/OpenAutoCoder/Agentless](https://github.com/OpenAutoCoder/Agentless)
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) have become the go-to default choice for code generation [[18](#bib.bib18);
    [14](#bib.bib14); [34](#bib.bib34); [54](#bib.bib54)]. State-of-the-art LLMs like
    GPT-4 [[44](#bib.bib44)] and Claude-3.5 [[13](#bib.bib13)] have demonstrated their
    prowess in being able to synthesize code snippets based on given user description.
    However, compared to the main evaluation setting of simple, self-contained problems,
    applying LLMs on repository-level software engineering tasks has been understudied.
    Software engineering tasks like feature addition, program repair, and test generation
    require an in-depth understanding of not only information within files, which
    can contain thousands of lines of code, but also repository-level dependencies
    across files.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已成为代码生成的首选方法[[18](#bib.bib18); [14](#bib.bib14); [34](#bib.bib34);
    [54](#bib.bib54)]。先进的LLMs，如GPT-4[[44](#bib.bib44)]和Claude-3.5[[13](#bib.bib13)]，已展示了根据给定用户描述合成代码片段的能力。然而，与主要评估环境中的简单、自包含问题相比，将LLMs应用于仓库级的软件工程任务仍然研究不足。软件工程任务如功能添加、程序修复和测试生成需要深入理解文件中的信息，这些文件可能包含数千行代码，还需要了解跨文件的仓库级依赖。
- en: Recently, to address the gap and evaluate the ability of tools to automatically
    solve real-world software engineering problems, the popular SWE-bench [[28](#bib.bib28)]
    benchmark has been developed. In SWE-bench, each problem consists of a real-world
    GitHub issue description and the corresponding Python repository. The task is
    to modify the repository to resolve the issue, either fixing a bug or introducing
    a new feature. Recently, the authors have published a subset of the benchmark
    – SWE-bench Lite [[11](#bib.bib11)] (300 problems) that performs further filtering
    and focuses on bug fixing issues.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，为了填补这一空白并评估工具自动解决现实世界软件工程问题的能力，开发了流行的SWE-bench[[28](#bib.bib28)]基准。在SWE-bench中，每个问题由一个真实的GitHub问题描述和相应的Python仓库组成。任务是修改仓库以解决问题，无论是修复错误还是引入新功能。最近，作者发布了基准的一个子集——SWE-bench
    Lite[[11](#bib.bib11)]（300个问题），该子集进行了进一步筛选，并专注于错误修复问题。
- en: To solve the challenging real-world software development problems from SWE-bench,
    inspired by the Devin AI Software Engineer [[4](#bib.bib4)], there has been a
    significant body of work from both academia and industry focusing on developing
    *agent-based* approaches [[65](#bib.bib65); [21](#bib.bib21); [61](#bib.bib61);
    [17](#bib.bib17); [41](#bib.bib41); [15](#bib.bib15)]. While there is not a fixed
    definition for agent-based approaches, they generally equip LLMs with a set of
    tools and allow agents to iteratively and autonomously perform actions, observe
    feedback, and plan future steps. Example tools can include the ability to open/write/create
    files, search for code lines, run tests, and execute shell commands. In each attempt
    to solve a problem, agent-based approaches will have multiple turns, where each
    turn consists of performing an action. Subsequent turns depend on previous actions
    and the feedback information the agent receives from the environment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决SWE-bench中的现实世界软件开发问题，受到Devin AI Software Engineer[[4](#bib.bib4)]的启发，学术界和工业界已经进行了大量工作，重点开发了*基于代理*的方法[[65](#bib.bib65);
    [21](#bib.bib21); [61](#bib.bib61); [17](#bib.bib17); [41](#bib.bib41); [15](#bib.bib15)]。虽然对基于代理的方法没有固定的定义，但它们通常为LLMs配备了一套工具，允许代理迭代地和自主地执行操作、观察反馈并规划未来的步骤。示例工具可以包括打开/写入/创建文件、搜索代码行、运行测试和执行shell命令的能力。在每次尝试解决问题时，基于代理的方法会有多个回合，每个回合包括执行一个操作。后续回合依赖于之前的操作和代理从环境中收到的反馈信息。
- en: 'At first glance, agent-based approaches appear to be a natural and straightforward
    way to tackle software development tasks. After all, human developers also perform
    similar actions and use feedback to plan future steps. However, the disparity
    between human and current LLM abilities leads to the following limitations of
    agent-based approaches:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，基于代理的方法似乎是处理软件开发任务的自然且直接的方式。毕竟，人类开发人员也执行类似的操作，并使用反馈来规划未来的步骤。然而，人类和当前LLM能力之间的差异导致了基于代理的方法存在以下限制：
- en: •
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Complex tool usage/design. To utilize tools, current agent-based approaches
    apply an abstraction layer between the agent and the environment. Examples are
    mapping real actions to API calls so that agents can use tools by outputting an
    API call instruction. However, such abstractions and API call specifications require
    careful design of input/output formats and can easily lead to incorrect or imprecise
    tool design/usage, especially for more complex action spaces. Given the iterative
    nature of agent-based approaches, where current action/plan depends on previous
    turns, incorrectly or imprecisely defining/using a tool can both reduce performance
    and incur additional cost in wasted LLM queries.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具使用/设计复杂。为了利用工具，目前的代理程序方法在代理程序和环境之间应用了一个抽象层。例如，将实际操作映射到API调用，使代理程序可以通过输出API调用指令来使用工具。然而，这种抽象和API调用规范需要仔细设计输入/输出格式，并且容易导致工具设计/使用的不正确或不精确，特别是在更复杂的行动空间中。考虑到代理程序方法的迭代特性，当前的行动/计划依赖于之前的轮次，不正确或不精确地定义/使用工具可能会降低性能并增加额外的LLM查询浪费成本。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Lack of control in decision planning. In addition to using tools, current agent-based
    approaches also delegates the decision making process to the agents – deciding
    when and what action to perform. The agents decide the current action to take
    based on previous actions taken and the feedback provided by the environment,
    often with minimal checks to ensure the action taken make sense. Due to the large
    possible action space and feedback response, it can be extremely easy for autonomous
    agents to become confused and perform sub-optimal explorations. Furthermore, to
    solve an issue, an agent can take upwards of 30 or 40 turns which makes it extremely
    difficult to both understand the decisions made by the agents and also debug the
    exact turns where the incorrect decision is made.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 决策规划控制缺乏。除了使用工具外，目前的代理程序方法还将决策过程委托给代理程序——决定何时以及采取何种行动。代理程序根据之前采取的行动和环境提供的反馈来决定当前的行动，通常几乎没有检查以确保所采取的行动合理。由于可能的行动空间和反馈响应非常庞大，自动代理程序很容易变得混乱，执行次优的探索。此外，为了解决一个问题，代理程序可能需要进行30到40轮，这使得理解代理程序所做的决策和调试具体的错误决策变得极其困难。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Limited ability to self-reflect. Existing agents struggle with the capability
    to perform self-reflection [[43](#bib.bib43); [24](#bib.bib24)]. That is to say
    they tend to take all information/feedback and do not know how to filter out or
    correct irrelevant, incorrect, or misleading information [[53](#bib.bib53); [64](#bib.bib64)].
    For example, a common step in the agent-based approach is to reproduce an issue
    with a minimal test case. However, the reproduced test case may not be always
    correct or precise. The limited ability to self-reflect means that an incorrect
    step can be easily amplified and negatively affect all future decisions taken
    by the agent.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自我反思能力有限。现有的代理程序在执行自我反思方面存在困难[[43](#bib.bib43); [24](#bib.bib24)]。也就是说，它们往往接受所有信息/反馈，却不知道如何筛选或纠正不相关、不正确或误导性的信息[[53](#bib.bib53);
    [64](#bib.bib64)]。例如，代理程序方法中的一个常见步骤是通过最小化测试用例来重现问题。然而，重现的测试用例可能并不总是正确或准确。自我反思能力有限意味着一个错误的步骤可能会被放大，并对代理程序未来的所有决策产生负面影响。
- en: 'In this paper, we advocate that instead of rushing to develop increasingly
    complex LLM agent-based approaches and tools for software development (which can
    also be non-trivial to use or replicate due to the fully autonomous setup), we
    should first take a step back and ask the following introspective question: *Do
    we really have to employ complex autonomous software agents?*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提倡与其急于开发越来越复杂的LLM代理程序方法和用于软件开发的工具（由于完全自主的设置，这些工具可能也不容易使用或复制），不如先退一步，问以下内省性问题：*我们真的需要使用复杂的自主软件代理程序吗？*
- en: 'Our work. We set out to answer this important question by building Agentless
    – an *agentless* approach to automatically solve software development problems.
    To solve each issue, Agentless follows a simple two phase process: localization
    and repair. In the localization process, Agentless employs a hierarchical process
    to first localize the fault to specific files, then to relevant classes or functions,
    and finally to fine-grained edit locations. To perform repair, Agentless takes
    the edit locations and generates multiple candidate patches in a simple diff format.
    Agentless then performs simple filtering to remove any patches that have syntax
    errors or cannot pass the previous tests in the repository. Finally, Agentless
    re-ranks all remaining patches and selects one to submit in order to fix the issue.
    While Agentless leverages LLMs to perform each detailed task, unlike prior complex
    agent-based tools, Agentless does not allow LLMs to *autonomously* decide future
    actions or operate with any complex tools. Our deliberate choice of not using
    agents not only allows Agentless to have a simplistic and straightforward design
    that can be easily understood, but also helps avoid the above mentioned limitations
    of LLM agents in software development. We evaluate Agentless on the popular SWE-bench
    Lite [[11](#bib.bib11)] benchmark and demonstrate that Agentless not only achieves
    the highest performance (27.33%) among all open-source approaches, but it does
    so at a fraction of the cost!'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作。我们旨在通过构建Agentless——一种*无代理*的方法来自动解决软件开发问题，来回答这个重要问题。为了解决每个问题，Agentless遵循一个简单的两个阶段过程：定位和修复。在定位过程中，Agentless使用分层过程首先将故障定位到特定文件，然后到相关的类或函数，最后到细粒度的编辑位置。为了进行修复，Agentless获取编辑位置并生成多个候选补丁，以简单的diff格式表示。然后，Agentless进行简单过滤，去除任何有语法错误或无法通过仓库中先前测试的补丁。最后，Agentless重新排序所有剩余的补丁，并选择一个提交以解决问题。虽然Agentless利用LLMs执行每一个详细任务，但与以往复杂的基于代理的工具不同，Agentless不允许LLMs*自主*决定未来的行动或操作任何复杂工具。我们故意不使用代理的选择不仅使Agentless具有一个简洁明了的设计，易于理解，还帮助避免了上述LLM代理在软件开发中的局限性。我们在流行的SWE-bench
    Lite [[11](#bib.bib11)]基准上评估Agentless，并展示了Agentless不仅在所有开源方法中取得了最高性能（27.33%），而且成本仅为其一小部分！
- en: Furthermore, we performed fine-grained manual analysis on the SWE-bench Lite
    dataset and classified all its problems into different categories across dimensions
    like problem description, ground truth patch, and location information. Surprisingly,
    we observed that SWE-bench Lite contains problems (4.3%) with exact ground truth
    patch in the description, problems (9.3%) with missing critical information needed
    to solve the issue, and problems (4.3%) that include misleading solutions in the
    issue description. Recognizing these issues, we built SWE-bench Lite-$S$, which
    removes such problematic problems, and serves as a more rigorous benchmark to
    evaluate the ability to solve real-world software development problems. Overall,
    in an era focused on achieving top placements on leaderboards, our work highlights
    the overlooked potential of a simplistic, interpretable technique in autonomous
    software development. We hope Agentless will help reset the baseline, starting
    point, and horizon for autonomous software agents, and inspire future work along
    this crucial direction.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们对SWE-bench Lite数据集进行了细粒度的人工分析，并将所有问题根据问题描述、实际补丁和位置信息等维度分类。令人惊讶的是，我们发现SWE-bench
    Lite包含了4.3%的问题，其描述中具有准确的实际补丁，9.3%的问题缺少解决问题所需的关键信息，以及4.3%的问题描述中包含误导性的解决方案。认识到这些问题后，我们构建了SWE-bench
    Lite-$S$，该版本删除了这些有问题的样本，并作为一个更严格的基准来评估解决现实软件开发问题的能力。总体来说，在一个关注在排行榜上取得顶尖名次的时代，我们的工作突出了简洁、可解释的技术在自主软件开发中的被忽视的潜力。我们希望Agentless能帮助重置自主软件代理的基准、起点和视野，并激发未来在这一关键方向上的工作。
- en: 2 Agentless \scalerel*![[Uncaptioned image]](img/0620a2f4f39f95766dc037e6b7f67162.png)C
    Approach
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 Agentless \scalerel*![[未标注的图像]](img/0620a2f4f39f95766dc037e6b7f67162.png)C
    方法
- en: '![Refer to caption](img/0ed54bfbd169c4aba3e3dec47f7d8563.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0ed54bfbd169c4aba3e3dec47f7d8563.png)'
- en: 'Figure 1: Overview of Agentless.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：Agentless概览。
- en: 'Figure [1](#S2.F1 "Figure 1 ‣ 2 Agentless \scalerel*C Approach ‣ Agentless
    \scalerel*C: Demystifying LLM-based Software Engineering Agents") shows the overview
    of Agentless, consisting of two phases: localization and repair. We first take
    in the issue description and the existing project codebase as input. Then, we
    begin our hierarchical localization process by 1 turning the
    project codebase into a tree-like structure format that demonstrates the relative
    location of each file in the project. Next, 2 using this
    repository structure format along with the original issue description, we ask
    the LLM to localize and rank the top N most suspicious files that need editing
    to solve the issue. However, not all contents in each file need to be modified.
    As such, 3
    we provide a skeleton for each file (i.e., a list of declaration headers of the
    classes and functions) and ask the LLM to output a specific list of classes and
    functions that we should examine more closely to fix the bug. We then provide
    the complete code content of the previous locations and 4
    ask the LLM to finalize a smaller set of edit locations (i.e., classes, functions,
    or even specific lines). For the repair phase, we provide the code snippets at
    these edit locations together with the issue description and 5
    ask the LLM to sample multiple patches to solve the issue. Next, 6
    we perform a simple filtering to remove any patches with syntax errors and regression
    test failures, and use majority voting to rank the remaining patches. Finally,
    7
    Agentless selects the top-ranked patch as the final patch for submission. We now
    describe the steps in each of Agentless''s two phases in more detail.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '图[1](#S2.F1 "图 1 ‣ 2 无代理 \scalerel*C 方法 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理")展示了
    Agentless 的概述，包括两个阶段：定位和修复。我们首先将问题描述和现有的项目代码库作为输入。接着，我们开始我们的分层定位过程，通过1
    将项目代码库转化为树状结构格式，展示项目中每个文件的相对位置。接下来，2 利用这个仓库结构格式以及原始问题描述，我们要求
    LLM 本地化并排序需要编辑的前 N 个最可疑文件。然而，并非每个文件中的所有内容都需要修改。因此，3 我们为每个文件提供一个骨架（即类和函数的声明头列表），并要求
    LLM 输出我们应更详细检查的特定类和函数列表，以修复错误。然后，我们提供先前位置的完整代码内容，并且4 要求 LLM 确定较小的编辑位置集合（即类、函数，甚至特定行）。在修复阶段，我们提供这些编辑位置的代码片段以及问题描述，并且5
    要求 LLM 生成多个修补程序以解决问题。接下来，6 我们执行简单的过滤，去除任何具有语法错误和回归测试失败的修补程序，并使用多数投票对剩余修补程序进行排名。最后，7
    Agentless 选择排名最高的修补程序作为最终提交的修补程序。我们现在更详细地描述 Agentless 两个阶段中的每个步骤。'
- en: 2.1 Localization \scalerel*![[Uncaptioned image]](img/85357b8d562a6601d9929e5e24058820.png)C
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 本地化 \scalerel*![[未标注的图像]](img/85357b8d562a6601d9929e5e24058820.png)C
- en: 'To fix or implement a new feature, the first step is to obtain the locations
    in the source code, as without the correct locations, it can be impossible to
    provide the right edits. The difficulty lies in the fact that there could be hundreds
    of files with thousands of lines of code each in a repository, whereas the correct
    locations to edit are only a few selected lines or functions. Agentless addresses
    this by using a simple three-step hierarchical localization process: 1) localize
    to selected files; 2) localize each selected files into relevant classes, functions,
    and variables; 3) localize to code edit locations.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要修复或实现新功能，第一步是获取源代码中的位置，因为没有正确的位置，就无法提供正确的编辑。困难在于，代码库中可能有数百个文件，每个文件都有成千上万行代码，而正确的编辑位置只有少数几行或函数。Agentless
    通过使用简单的三步层次本地化过程来解决这个问题：1) 本地化到选定的文件；2) 将每个选定的文件本地化到相关的类、函数和变量；3) 本地化到代码编辑位置。
- en: Localize to suspicious files. First, Agentless localizes the possible locations
    to specific suspicious files. Instead of providing the complete code snippet for
    each file in the repository, Agentless constructs a succinct representation of
    the repository's file and directory structure. We refer to this as the repository
    structure format, which begins with the root folder of the repository and organizes
    code files or folder names. Files and folders at the same directory level are
    aligned vertically, and files/folders in sub-directories are indented. We recursively
    traverse the entire repository to obtain the repository structure format, which
    will be used as input for the LLM. The repository structure format provides the
    necessary file paths alongside the neighboring file names to maintain organizational
    information in the original codebase. Agentless then inputs the processed repository
    structure format along with the original issue description to an LLM and requests
    it to identify a list of the top N suspicious files in the repository that need
    further inspection or modification to resolve the issue.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本地化到可疑文件。首先，Agentless 将可能的位置本地化到具体的可疑文件中。Agentless 不是为代码库中的每个文件提供完整的代码片段，而是构建一个简明的代码库文件和目录结构表示。我们称之为代码库结构格式，它以代码库的根文件夹开始，并组织代码文件或文件夹名称。相同目录级别的文件和文件夹垂直对齐，子目录中的文件/文件夹缩进。我们递归遍历整个代码库以获取代码库结构格式，这将作为
    LLM 的输入。代码库结构格式提供了必要的文件路径及其邻近文件名，以保持原始代码库中的组织信息。然后，Agentless 将处理过的代码库结构格式以及原始问题描述输入到
    LLM 中，并请求其识别出需要进一步检查或修改以解决问题的前 N 个可疑文件列表。
- en: '![Refer to caption](img/26c08f2fd7edfb79c1f1dab41a986115.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/26c08f2fd7edfb79c1f1dab41a986115.png)'
- en: 'Figure 2: Skeleton format'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：骨架格式
- en: 'Localize to related elements. After obtaining the list of suspicious files
    to edit to solve the issue, Agentless then moves on to the second part of the
    localization process: localize to related elements within the suspicious files.
    Directly providing the complete context of all files can be large. As such, Agentless
    builds a compressed format of each file that contains the list of class, function,
    or variable declarations. We refer to this format as skeleton format, with an
    example shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Localization \scalerel*C ‣
    2 Agentless \scalerel*C Approach ‣ Agentless \scalerel*C: Demystifying LLM-based
    Software Engineering Agents"). In the skeleton format, we provide only the headers
    of the classes and functions in the file. For classes, we further include any
    class fields and methods (signatures only). Additionally, we also keep comments
    in the class and module level to provide further information. Compared to providing
    the entire file context to the model, the skeleton format is a much more concise
    representation, especially when the file contains thousands of lines, making it
    impractical/costly to process all at once with existing LLMs. We provide the skeleton
    of all suspicious files to the LLM at one time in a single prompt, enabling the
    model to comprehensively analyze the pertinent information and decide the most
    relevant elements. Using this input, we ask the LLM to provide a list of related
    classes and functions that one should examine to fix the provided issue.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '本地化到相关元素。获得了需要编辑的可疑文件列表以解决问题后，Agentless接着进入本地化过程的第二部分：本地化到可疑文件中的相关元素。直接提供所有文件的完整上下文可能很庞大。因此，Agentless构建了每个文件的压缩格式，其中包含类、函数或变量声明的列表。我们将这种格式称为骨架格式，如图 [2](#S2.F2
    "图 2 ‣ 2.1 本地化 \scalerel*C ‣ 2 Agentless \scalerel*C 方法 ‣ Agentless \scalerel*C:
    揭开基于LLM的软件工程代理的面纱")所示。在骨架格式中，我们只提供文件中类和函数的头部。对于类，我们进一步包括任何类字段和方法（仅签名）。此外，我们还保留类和模块级别的注释，以提供进一步的信息。与将整个文件上下文提供给模型相比，骨架格式是一种更为简洁的表示方式，特别是当文件包含成千上万行时，这使得使用现有LLMs一次性处理所有内容变得不切实际/成本高昂。我们将所有可疑文件的骨架一次性提供给LLM，使模型能够全面分析相关信息并决定最相关的元素。利用这些输入，我们要求LLM提供应检查的相关类和函数的列表，以修复所提供的问题。'
- en: Localize to edit locations. The previous localization step provided us with
    a list of related code elements. We then directly provide the code content from
    these elements to the model and ask it to localize to specific edit locations.
    Compared to using the entire file content, the input context we provide here is
    much smaller. With this input, we then ask the LLM to identify the final set of
    edit locations, specified by line numbers, functions, or classes. Our simple hierarchical
    localization process allows Agentless to select a set of relevant code snippets
    as edit locations to perform repair.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本地化以编辑位置。之前的本地化步骤为我们提供了一份相关代码元素的列表。然后，我们直接将这些元素的代码内容提供给模型，并要求它本地化到特定的编辑位置。与使用整个文件内容相比，我们在这里提供的输入上下文要小得多。利用这些输入，我们随后要求LLM确定最终的编辑位置，这些位置由行号、函数或类指定。我们简单的分层本地化过程使得Agentless可以选择一组相关的代码片段作为编辑位置进行修复。
- en: '![Refer to caption](img/5bfcf8ab7d355c3529c929c9837d1307.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5bfcf8ab7d355c3529c929c9837d1307.png)'
- en: 'Figure 3: Search/Replace edit format'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 搜索/替换编辑格式'
- en: 2.2 Repair \scalerel*![[Uncaptioned image]](img/a0871097533a47345cc3b10ac445da92.png)C
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 修复 \scalerel*![[未标注的图像]](img/a0871097533a47345cc3b10ac445da92.png)C
- en: In the repair stage, the goal is to produce the correct patch to solve the issue.
    Following existing work on LLM-based program repair [[31](#bib.bib31); [48](#bib.bib48);
    [27](#bib.bib27)], we first utilize the identified edit locations and construct
    a context window of code snippets to provide to the LLM for repair. For example,
    if the identified location was a class from line 40 to 78, we would produce a
    context window of [40 - x, 78 + x] where x denotes the context window size. The
    intuition behind adding the additional code before and after the identified location
    is to provide the LLM with relevant contextual information for better program
    repair [[57](#bib.bib57)]. If multiple edit locations are identified, we would
    concatenate these context windows together separated with ``...'' to indicate
    missing context in the middle.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在修复阶段，目标是生成正确的补丁来解决问题。参考现有关于基于 LLM 的程序修复的工作[[31](#bib.bib31); [48](#bib.bib48);
    [27](#bib.bib27)]，我们首先利用识别出的编辑位置，并构建一个包含代码片段的上下文窗口以提供给 LLM 进行修复。例如，如果识别的位置是从第
    40 行到第 78 行的类，我们会生成一个 [40 - x, 78 + x] 的上下文窗口，其中 x 表示上下文窗口的大小。添加识别位置之前和之后的附加代码的直觉是为
    LLM 提供相关的上下文信息以便更好地进行程序修复[[57](#bib.bib57)]。如果识别出多个编辑位置，我们会将这些上下文窗口连接在一起，中间用 ``...''
    分隔，以指示中间缺失的上下文。
- en: 'Patch format. Using the code snippets, we then ask the LLM to generate patches
    to solve the issue. However, instead of directly producing the entire code snippet
    to replace the entire given context, Agentless asks the LLM to generate a Search/Replace
    edit [[21](#bib.bib21)]: a simple diff format to efficiently create each patch.
    Figure [3](#S2.F3 "Figure 3 ‣ 2.1 Localization \scalerel*C ‣ 2 Agentless \scalerel*C
    Approach ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering
    Agents") shows an example of the Search/Replace format containing two main parts:
    1) search: the original code snippet we want to replace and 2) replace: the replacement
    code snippet we want to replace with. To apply the generated Search/Replace diff
    to the original file, we can simply match the search code snippet and replace
    it with the replacement. This simple diff format avoids generating the complete
    code and instead focuses on producing small edits, which are not only more cost-efficient,
    but also more reliable and accurate (less chances for hallucination).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '补丁格式。使用这些代码片段后，我们会要求 LLM 生成修复补丁来解决问题。然而，Agentless 并不是直接生成替换整个给定上下文的完整代码片段，而是要求
    LLM 生成一个搜索/替换编辑[[21](#bib.bib21)]：一种简单的 diff 格式来高效地创建每个补丁。图[3](#S2.F3 "Figure
    3 ‣ 2.1 Localization \scalerel*C ‣ 2 Agentless \scalerel*C Approach ‣ Agentless
    \scalerel*C: Demystifying LLM-based Software Engineering Agents") 显示了包含两个主要部分的搜索/替换格式的示例：1)
    search：我们想要替换的原始代码片段；2) replace：我们想要用来替换的代码片段。为了将生成的搜索/替换 diff 应用到原始文件中，我们可以简单地匹配搜索代码片段并用替换代码片段进行替换。这种简单的
    diff 格式避免了生成完整代码，专注于生成小的编辑，这不仅更具成本效益，而且更可靠和准确（减少了幻觉的可能性）。'
- en: 'Filtering and patch selection. For each issue, Agentless uses the LLM to generate
    multiple potential patches (starting with greedy and then sample multiple patches
    with higher temperature). We also apply traditional software engineering technique
    of regression testing [[55](#bib.bib55)] to run the existing tests in the repository
    on all the generated patches. Any patches which failed the existing tests can
    be filtered out as they incorrectly change the correct behavior of previous code.
    Note, our implementation of this regression test filtering step follows prior
    work also evaluated on the same benchmark [[21](#bib.bib21); [17](#bib.bib17)].
    For the remaining patches, Agentless applies a re-ranking approach using majority
    voting: We first normalize each patch to ignore surface-level differences (e.g.,
    extra spaces, newlines, and comments), and then select the patch with the highest
    number of occurrences as the final patch for submission. More specifically, to
    standardize the patch, we begin by parsing both the old and new code (after applying
    the patch) into abstract syntax trees. Next, we unparse the trees into a canonical
    source code format with docstrings removed. Finally, we compute the textual diff
    between the standardized old and new code to get the normalized patch.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤和补丁选择。对于每个问题，Agentless 使用 LLM 生成多个潜在补丁（首先使用贪婪算法，然后用更高的温度采样多个补丁）。我们还应用了传统的软件工程技术回归测试
    [[55](#bib.bib55)]，在所有生成的补丁上运行现有的测试。任何未通过现有测试的补丁都可以被过滤掉，因为它们错误地改变了先前代码的正确行为。请注意，我们的回归测试过滤步骤的实现遵循了先前在相同基准上评估的工作
    [[21](#bib.bib21); [17](#bib.bib17)]。对于剩下的补丁，Agentless 使用多数投票的重新排序方法：我们首先标准化每个补丁以忽略表面级差异（例如，额外的空格、换行符和注释），然后选择出现次数最多的补丁作为最终提交补丁。更具体地说，为了标准化补丁，我们首先将旧代码和新代码（应用补丁后）解析为抽象语法树。接着，我们将这些树解析为去除文档字符串的标准源代码格式。最后，我们计算标准化后的旧代码和新代码之间的文本差异，以获得标准化的补丁。
- en: Agentless solves repository-level issues using a simple step-by-step procedure.
    We note here that none of the techniques used by Agentless in isolation are revolutionary,
    but instead Agentless smartly combines existing techniques to construct an easy-to-understand
    approach. Different from prior autonomous agent-based tools that involve complex
    interactions with the environment, Agentless uses a simple two phase approach
    to first localize and then repair the bug without relying on any agents for decision-making.
    By conducting localization in a hierarchical manner, Agentless can efficiently
    and effectively compute the fine-grained locations for editing. Agentless then
    performs repair by sampling multiple patches using a simple diff format. We filter
    out any patches with syntax and regression tests errors, and finally select the
    patch for submission using classic majority voting.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Agentless 使用简单的逐步程序解决库级问题。我们在此指出，Agentless 单独使用的任何技术都不是革命性的，但 Agentless 智巧地结合了现有技术，构建了易于理解的方法。与先前涉及复杂环境交互的自主代理工具不同，Agentless
    采用简单的两阶段方法，首先进行定位，然后修复错误，而不依赖任何代理进行决策。通过分层方式进行定位，Agentless 可以高效且有效地计算细粒度的编辑位置。然后，Agentless
    通过采样多个补丁使用简单的差异格式进行修复。我们过滤掉任何有语法和回归测试错误的补丁，并最终使用经典的多数投票选择提交补丁。
- en: 3 Experimental Setup
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验设置
- en: 'Datasets. We evaluate Agentless and baselines using the popular SWE-bench dataset
    to test the ability to solve real-world software engineering issues. Each problem
    in SWE-bench requires submitting a patch to solve the underlying issue described
    in the input issue description. In particular, we focus on the filtered subset
    SWE-bench Lite, containing 300 problems with tests to evaluate the functional
    correctness of submitted patch. Furthermore, we also conduct a detailed study
    (Section [5.1](#S5.SS1 "5.1 Problem Classification ‣ 5 Additional Analysis on
    SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering
    Agents")) on the SWE-bench Lite benchmark to not only demonstrate potential issues
    and biases but also produce a more rigorous filtered set of problems for better
    evaluation.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '数据集。我们使用流行的SWE-bench数据集来评估Agentless和基准，以测试解决实际软件工程问题的能力。SWE-bench中的每个问题都要求提交一个补丁以解决输入问题描述中描述的潜在问题。特别地，我们关注于筛选后的子集SWE-bench
    Lite，其中包含300个问题，并通过测试评估提交补丁的功能正确性。此外，我们还对SWE-bench Lite基准进行了详细研究（第[5.1节](#S5.SS1
    "5.1 问题分类 ‣ 5 关于SWE-bench Lite的附加分析 ‣ Agentless \scalerel*C: 揭示LLM驱动的软件工程代理")），以展示潜在问题和偏差，并生成更严格的筛选问题集以进行更好的评估。'
- en: Implementation. We implement Agentless using GPT-4o (gpt-4o-2024-05-13) [[45](#bib.bib45)].
    By default, we query the LLM with greedy decoding. During sampling, we use a sampling
    temperature of $0.8$ 10 lines around each edit location, and generate 21 patches
    (1 greedy and 20 samples). This results in a total of 42¹¹1the answer to the ultimate
    question of life, the universe, and everything [[12](#bib.bib12)] patches per
    bug. We adopt the same Search/Replace edit format from prior work [[21](#bib.bib21)],
    and use the built-in Python ast library [[2](#bib.bib2)] to perform parsing in
    our patch normalization step. Due to issues with the original SWE-bench evaluation
    script at the time of writing, we adopt the SWE-bench-docker [[68](#bib.bib68)]
    evaluation setup used by prior tools [[21](#bib.bib21)].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 实现。我们使用GPT-4o (gpt-4o-2024-05-13) [[45](#bib.bib45)] 实现了Agentless。默认情况下，我们使用贪婪解码查询LLM。在采样过程中，我们在每个编辑位置周围使用$0.8$的采样温度，并生成21个补丁（1个贪婪和20个样本）。这导致每个错误总共生成42¹¹1the
    answer to the ultimate question of life, the universe, and everything [[12](#bib.bib12)]个补丁。我们采用了先前工作中的相同Search/Replace编辑格式[[21](#bib.bib21)]，并使用内置的Python
    ast库[[2](#bib.bib2)]在补丁标准化步骤中执行解析。由于撰写时原始SWE-bench评估脚本的问题，我们采用了先前工具[[21](#bib.bib21)]使用的SWE-bench-docker
    [[68](#bib.bib68)]评估设置。
- en: Baselines. We compare Agentless against 13 agent-based approaches. These baseline
    tools represent the state-of-the-art performance on SWE-bench. We include state-of-the-art
    open-source as well as commercial or closed-source baselines (indicated via a
    \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C).
    We note here that the majority of the closed-source baselines do not provide any
    trajectories, just the submission patches. Therefore, we cannot verify the steps
    taken to arrive at the final patches. Moreover, we also include a simple agentless
    baseline using retrieval-augmented generation (RAG) proposed as part of SWE-bench [[28](#bib.bib28)]
    for comparison. In this case, the agentless baseline uses the LLM to directly
    generate a patch file by providing it with the file content of the most relevant
    files, retrieved using BM25 [[49](#bib.bib49)]. Additionally, we also list the
    underlying LLM used by each tool whenever possible.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 基准线。我们将Agentless与13种基于代理的方法进行比较。这些基准工具代表了SWE-bench的最先进性能。我们包括了最先进的开源工具以及商业或闭源基准（通过\scalerel*![[Uncaptioned
    image]](img/f1313f50693714130653fb391f45f297.png)C标记）。我们注意到，大多数闭源基准并未提供任何轨迹，仅提供提交的补丁。因此，我们无法验证达到最终补丁所采取的步骤。此外，我们还包括了一种简单的无代理基准，使用在SWE-bench中提出的检索增强生成（RAG）[[28](#bib.bib28)]进行比较。在这种情况下，无代理基准使用LLM直接生成补丁文件，提供最相关文件的内容，这些文件通过BM25[[49](#bib.bib49)]检索得到。此外，我们还尽可能列出了每个工具使用的底层LLM。
- en: 'Metrics. Following prior work [[65](#bib.bib65)], we report 1) % Resolved:
    the percentage of resolved problems in the benchmark, 2) Avg. $ Cost: average
    inference cost of running the tool, and 3) Avg. # Tokens: average number of input
    and output tokens used to query to LLM. Additionally, we also report the % Correct
    Location: the percent of problems where the patch produced by the tool matches
    with the edit location of the ground truth developer patch. We compute this metric
    over three granularities: file, function, and line. We report that a patch contains
    the correct location if it edits a superset of all locations in the ground truth
    patch. For baseline tools, we directly use the reported results either from the
    official leaderboard [[29](#bib.bib29)] or from the tool''s official paper/repository.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '指标。参照之前的研究 [[65](#bib.bib65)]，我们报告 1) % 已解决：基准测试中已解决问题的百分比，2) 平均 $ 成本：运行工具的平均推理成本，以及
    3) 平均 # 令牌：用于查询LLM的输入和输出令牌的平均数量。此外，我们还报告 % 正确位置：工具生成的补丁与真实开发者补丁的编辑位置匹配的问题百分比。我们在三个粒度上计算此指标：文件、函数和行。如果补丁编辑了真实补丁中的所有位置的超集，我们认为它包含正确的位置。对于基准工具，我们直接使用官方排行榜 [[29](#bib.bib29)]
    或工具的官方论文/库中报告的结果。'
- en: 4 Evaluation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 评估
- en: 'Table 1: Results on SWE-bench Lite. Note: \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    indicates approaches that are closed-source (i.e., source code is not released).
    ''-'' indicates that the relevant information to compute this has not been released.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：SWE-bench Lite上的结果。注：\scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    表示封闭源代码的方法（即源代码未发布）。'-' 表示相关信息尚未发布。
- en: '| Tool | LLM | % Resolved | Avg. $ Cost | Avg. # Tokens | % Correct Location
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | LLM | % 已解决 | 平均 $ 成本 | 平均 # 令牌 | % 正确位置 |'
- en: '| Line | Function | File |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 行 | 函数 | 文件 |'
- en: '| Alibaba Lingma Agent [[7](#bib.bib7)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o+   \scalerel *![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C  Claude-3.5  |
    99 (33.00%) | - | - | 40.0% | 58.7% | 75.0% |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Alibaba Lingma Agent [[7](#bib.bib7)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o+   \scalerel
    *![[无标题图像]](img/578665f7ee65c9339d9280f0414de219.png)C  Claude-3.5  | 99 (33.00%)
    | - | - | 40.0% | 58.7% | 75.0% |'
- en: '| Factory Code Droid [[5](#bib.bib5)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 94 (31.33%) | - | - | 36.7% | 55.7% | 72.7% |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Factory Code Droid [[5](#bib.bib5)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 94 (31.33%) | - | - | 36.7% | 55.7% | 72.7% |'
- en: '| AutoCodeRover-v2 [[3](#bib.bib3)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 92 (30.67%) | - | - | 35.0% | 52.3% | 69.3% |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| AutoCodeRover-v2 [[3](#bib.bib3)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o | 92
    (30.67%) | - | - | 35.0% | 52.3% | 69.3% |'
- en: '| CodeR [[17](#bib.bib17)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 85 (28.33%) | $3.34 | 323,802 | 35.7% | 52.3% | 67.0% |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| CodeR [[17](#bib.bib17)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4 | 85 (28.33%)
    | $3.34 | 323,802 | 35.7% | 52.3% | 67.0% |'
- en: '| IBM Research Agent-101 [[6](#bib.bib6)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 80 (26.67%) | - | - | 39.7% | 56.7% | 73.3% |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| IBM Research Agent-101 [[6](#bib.bib6)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 80 (26.67%) | - | - | 39.7% | 56.7% | 73.3% |'
- en: '| OpenCSG StarShip [[9](#bib.bib9)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 71 (23.67%) | - | - | 39.0% | 61.7% | 90.7% |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| OpenCSG StarShip [[9](#bib.bib9)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4 | 71 (23.67%)
    | - | - | 39.0% | 61.7% | 90.7% |'
- en: '| Bytedance MarsCode [[8](#bib.bib8)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 76 (25.33%) | - | - | 37.3% | 52.7% | 73.7% |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Bytedance MarsCode [[8](#bib.bib8)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o | 76
    (25.33%) | - | - | 37.3% | 52.7% | 73.7% |'
- en: '| Amazon Q Developer [[1](#bib.bib1)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 61 (20.33%) | - | - | 34.0% | 43.7% | 71.7% |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Q Developer [[1](#bib.bib1)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 61 (20.33%) | - | - | 34.0% | 43.7% | 71.7% |'
- en: '| RepoUnderstander [[41](#bib.bib41)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 64 (21.33%) | - | - | - | - | - |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| RepoUnderstander [[41](#bib.bib41)] \scalerel*![[无标题图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4 | 64 (21.33%)
    | - | - | - | - | - |'
- en: '| Aider [[21](#bib.bib21)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o+   \scalerel *![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C  Claude-3
    | 79 (26.33%) | - | - | 35.3% | 50.0% | 69.7% |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Aider [[21](#bib.bib21)] | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o+ \scalerel *![[无标题图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3
    | 79 (26.33%) | - | - | 35.3% | 50.0% | 69.7% |'
- en: '| AutoCodeRover [[65](#bib.bib65)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 57 (19.00%) | $0.45 | 38,663 | 29.0% | 42.3% | 62.3% |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| AutoCodeRover [[65](#bib.bib65)] | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 57 (19.00%) | $0.45 | 38,663 | 29.0% | 42.3% | 62.3% |'
- en: '|  | \scalerel'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | \scalerel'
- en: '*![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3
    | 35 (11.67%) | $3.42 | 221,258 | 26.3% | 36.0% | 48.0% |'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*![[无标题图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3 | 35 (11.67%)
    | $3.42 | 221,258 | 26.3% | 36.0% | 48.0% |'
- en: '|  | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 54 (18.00%) | $2.51 | 245,008 | 30.7% | 45.3% | 61.0% |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4
    | 54 (18.00%) | $2.51 | 245,008 | 30.7% | 45.3% | 61.0% |'
- en: '| SWE-agent [[61](#bib.bib61)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 54 (17.00%) | - | - | - | - | - |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| SWE-agent [[61](#bib.bib61)] | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 54 (17.00%) | - | - | - | - | - |'
- en: '|  | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 50 (16.67%) | - | - | 29.0% | 39.0% | 55.3% |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4
    | 50 (16.67%) | - | - | 29.0% | 39.0% | 55.3% |'
- en: '| OpenDevin [[10](#bib.bib10)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 52 (17.33%) | - | - | 27.3% | 39.3% | 56.7% |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| OpenDevin [[10](#bib.bib10)] | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 52 (17.33%) | - | - | 27.3% | 39.3% | 56.7% |'
- en: '|  | \scalerel'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | \scalerel'
- en: '*![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3
    | 13 (4.33%) | $0.25 | - | 22.0% | 30.0% | 57.0% |'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*![[无标题图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3 | 13 (4.33%)
    | $0.25 | - | 22.0% | 30.0% | 57.0% |'
- en: '|  | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 8 (2.67%) | $0.13 | - | 12.7% | 23.3% | 47.3% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4
    | 8 (2.67%) | $0.13 | - | 12.7% | 23.3% | 47.3% |'
- en: '|  | \scalerel'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | \scalerel'
- en: '*![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-2
    | 9 (3.00%) | - | - | 16.7% | 24.3% | 46.7% |'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*![[无标题图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-2 | 9 (3.00%)
    | - | - | 16.7% | 24.3% | 46.7% |'
- en: '| RAG [[28](#bib.bib28)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    ChatGPT | 1 (0.33%) | - | - | 6.3% | 11.3% | 27.3% |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| RAG [[28](#bib.bib28)] | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    ChatGPT | 1 (0.33%) | - | - | 6.3% | 11.3% | 27.3% |'
- en: '| Agentless \scalerel*![[Uncaptioned image]](img/0620a2f4f39f95766dc037e6b7f67162.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 82 (27.33%) | $0.34 | 42,376 | 34.3% | 51.0% | 68.7% |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Agentless \scalerel*![[无标题图像]](img/0620a2f4f39f95766dc037e6b7f67162.png)C
    | \scalerel*![[无标题图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o | 82
    (27.33%) | $0.34 | 42,376 | 34.3% | 51.0% | 68.7% |'
- en: 'Repair performance. Table [1](#S4.T1 "Table 1 ‣ 4 Evaluation ‣ Agentless \scalerel*C:
    Demystifying LLM-based Software Engineering Agents") shows the main evaluation
    result of Agentless and prior agent-based approaches on SWE-bench Lite. We observe
    that Agentless is able to solve 82 out of 300 problems (27.33%). While this is
    not the highest percentage of problems solved on SWE-bench Lite, Agentless is
    extremely competitive compared with prior agent-based approaches while using a
    much simpler design and overall technique. It is important to note here that many
    of the top techniques are closed-source/commercial and did not release any source
    code to reproduce experiments or even trajectories for further verification. Compared
    with open-source approaches, Agentless is able to achieve the highest performance
    of 27.33% (82 / 300) on SWE-bench Lite. Additionally, Agentless only costs on
    average $0.34, which is drastically less than prior agent-based approaches. Comparing
    against the RAG agentless baselines, we see that while Agentless costs slightly
    more, Agentless is also able to fix way more issues.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '修复性能。表[1](#S4.T1 "表 1 ‣ 4 评估 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理")展示了 Agentless
    和以前的代理方法在 SWE-bench Lite 上的主要评估结果。我们观察到 Agentless 能够解决 300 个问题中的 82 个（27.33%）。虽然这不是在
    SWE-bench Lite 上解决问题的最高百分比，但 Agentless 相比于以前的代理方法在使用更简单的设计和整体技术下极具竞争力。值得注意的是，许多顶级技术是闭源/商业的，并未发布任何源代码以重现实验或进一步验证。与开源方法相比，Agentless
    在 SWE-bench Lite 上达到了最高的 27.33%（82 / 300）性能。此外，Agentless 平均成本仅为 $0.34，远低于以前的代理方法。与
    RAG 无代理基准相比，我们看到虽然 Agentless 成本稍高，但能够修复的问题却远远更多。'
- en: '![Refer to caption](img/df526cb0d2763079bf67884daf9245e2.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/df526cb0d2763079bf67884daf9245e2.png)'
- en: 'Figure 4: Venn diagram for issue fixes'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：问题修复的维恩图
- en: 'Unique issues fixed. Figure [4](#S4.F4 "Figure 4 ‣ 4 Evaluation ‣ Agentless
    \scalerel*C: Demystifying LLM-based Software Engineering Agents") shows the unique
    issues solved by Agentless compared with the top-performing closed-source/commercial
    and open-source approaches (``Others'''' in Figure [4](#S4.F4 "Figure 4 ‣ 4 Evaluation
    ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering Agents")
    indicates all other approaches within each category). First, we see that compared
    to the open-source agent-based techniques, Agentless is able to fix 15 issues
    that no other existing open-source agent can resolve, showing the success of using
    a simple agentless approach in solving difficult issues. Furthermore, even when
    compared with high-performing commercial approaches, Agentless is still able to
    offer unique fixes, with even more unique patches than Alibaba Lingma Agent –
    the top commercial solution! This demonstrates that Agentless can be complementary
    to existing commercial agent-based setups.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '解决的独特问题。图[4](#S4.F4 "图 4 ‣ 4 评估 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理")展示了与表现最佳的闭源/商业和开源方法相比，Agentless
    解决的独特问题（图[4](#S4.F4 "图 4 ‣ 4 评估 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理")中的“其他”表示每个类别中的所有其他方法）。首先，我们看到与开源代理技术相比，Agentless
    能够解决15个其他现有开源代理无法解决的问题，展示了使用简单的无代理方法解决困难问题的成功。此外，即使与高性能的商业方法相比，Agentless 仍然能够提供独特的修复，甚至比顶级商业解决方案——阿里巴巴
    Lingma Agent 还要更多独特的补丁！这表明 Agentless 可以与现有的商业代理设置互补。'
- en: 'Localization performance. In real-world software development, apart from directly
    fixing the issue, providing the correct edit location to human developers is extremely
    helpful for debugging. As such, we examine the locations of the patches generated
    by each technique compared with the ground truth patch. We note here that it is
    possible to fix a bug in a different location than the ground truth, however comparing
    against the ground truth patch can still serve as an approximate measure. Table [1](#S4.T1
    "Table 1 ‣ 4 Evaluation ‣ Agentless \scalerel*C: Demystifying LLM-based Software
    Engineering Agents") additionally shows the percentage of submitted patches with
    correct locations for each tool, across line, function, and file levels. We first
    observe that the percentage of patches with correct locations correlates heavily
    with the solve rate. Interestingly, the highest result in terms of file-level
    location is OpenCSG StarShip at 90.0%, significantly higher than even the best-performing
    approaches while at the same time having a relatively low solve rate (23.67%).
    As OpenCSG StarShip is a commercial product that does not provide source code
    or detailed trajectories, it is difficult to explain this huge difference between
    localization and repair performance. In terms of localization performance, by
    using our simple hierarchical approach, Agentless remains very competitive compared
    with previous agent-based approaches (best function-level, and second-best file-
    and line-level localization among all open-source approaches).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '本地化性能。在实际的软件开发中，除了直接修复问题，向人工开发者提供正确的编辑位置对调试极为有帮助。因此，我们比较了每种技术生成的补丁位置与真实补丁的位置。需要注意的是，修复一个错误的位置可能与真实补丁不同，但与真实补丁比较仍然可以作为一个近似的衡量标准。表 [1](#S4.T1
    "表 1 ‣ 4 评估 ‣ Agentless \scalerel*C: 揭示基于 LLM 的软件工程代理") 另外显示了每种工具在行、函数和文件级别的正确位置补丁的百分比。我们首先观察到，具有正确位置的补丁百分比与解决率高度相关。有趣的是，在文件级位置方面，OpenCSG
    StarShip 的结果最高，达到 90.0%，显著高于即使是最好的方法，同时其解决率（23.67%）相对较低。由于 OpenCSG StarShip 是一个不提供源代码或详细轨迹的商业产品，因此很难解释其本地化和修复性能之间的巨大差异。在本地化性能方面，通过使用我们简单的分层方法，Agentless
    与之前的基于代理的方法相比仍然非常具有竞争力（在所有开源方法中，函数级别最佳，文件和行级别第二佳）。'
- en: 'Table 2: Performance of different localization steps of Agentless.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：Agentless 的不同本地化步骤的性能。
- en: '| Step | Contains GT | LoC | Avg. $ |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 步骤 | 包含 GT | 代码行数 | 平均 $ |'
- en: '| 1\. file level | 77.7% | 3,305 | $0.02 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 1\. 文件级别 | 77.7% | 3,305 | $0.02 |'
- en: '| 2\. related classes + functions | 55.3% | 813 | $0.02 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 2\. 相关类 + 函数 | 55.3% | 813 | $0.02 |'
- en: '| 3\. edit locations | 50.8% | 246 | $0.05 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 3\. 编辑位置 | 50.8% | 246 | $0.05 |'
- en: 'Ablation study on components of Agentless. Next, we look at how each component
    in both localization and repair phases contributed to the final Agentless performance.
    Table [2](#S4.T2 "Table 2 ‣ 4 Evaluation ‣ Agentless \scalerel*C: Demystifying
    LLM-based Software Engineering Agents") shows the performance of each of the 3
    step in Agentless''s localization phase (for step-3, the metrics are averaged
    across two sets of locations, with the cost being the total cost). We show after
    each localization step the percentage of ground truth edit locations that still
    remains, the lines of code in each localization, and the average dollar cost of
    each step. We observe that Agentless is able to localize the ground truth file
    in 77.7% of cases; however, using all of the localized files leads to a huge number
    of code lines as part of the context. As such, in our second localization step,
    we localize to relevant classes and functions, and are able to drastically reduce
    the context window. Finally, Agentless localizes to the exact edit locations needed
    to achieve even more context reduction without losing much of the localization
    accuracy. Furthermore, we observe that by using hierarchical localization steps,
    Agentless can successfully minimize the cost while performing effective localization.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '关于 Agentless 组件的消融研究。接下来，我们来看每个组件在本地化和修复阶段如何对最终的 Agentless 性能做出贡献。表格 [2](#S4.T2
    "表 2 ‣ 4 评估 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理") 显示了 Agentless 本地化阶段中每个步骤的性能（对于第
    3 步，指标是两个位置集的平均值，成本为总成本）。我们展示了每个本地化步骤后仍然保留的真实编辑位置的百分比、每个本地化的代码行数以及每个步骤的平均美元成本。我们观察到，Agentless
    能够在 77.7% 的情况下定位真实文件；然而，使用所有本地化文件会导致大量的代码行作为上下文。因此，在我们的第二个本地化步骤中，我们定位到相关的类和函数，并能够大幅度减少上下文窗口。最后，Agentless
    定位到实现更多上下文减少所需的确切编辑位置，而不失去太多的本地化准确性。此外，我们观察到，通过使用分层本地化步骤，Agentless 可以在进行有效本地化的同时成功地降低成本。'
- en: 'Table 3: Performance of different repair setups of Agentless.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：Agentless 的不同修复设置的性能。
- en: '| Setup | Performance | Avg. $ |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 设置 | 性能 | 平均 $ |'
- en: '| single sample | 70 (23.33%) | $0.11 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 单个样本 | 70 (23.33%) | $0.11 |'
- en: '| + multiple samples & maj. voting | 78 (26.00%) | $0.34 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| + 多个样本 & 多数投票 | 78 (26.00%) | $0.34 |'
- en: '| + test filtering (full Agentless) | 82 (27.33%) | $0.34 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| + 测试过滤（完整的 Agentless） | 82 (27.33%) | $0.34 |'
- en: 'We now look at the impact of our different repair setups on the final performance.
    Table [3](#S4.T3 "Table 3 ‣ 4 Evaluation ‣ Agentless \scalerel*C: Demystifying
    LLM-based Software Engineering Agents") shows the different ways we can generate
    or select the final patch for submission. Starting with just generating a single
    sample (i.e., using greedy decoding), Agentless can achieve 70 correct fixes while
    costing an average of $0.11 dollars per bug (total cost, including localization).
    We note that even with this simple patch generation step, Agentless can already
    beat the majority of the prior open-source agent-based approaches (with more than
    4X in cost reduction). We can further improve performance to 78 fixes by sampling
    the LLM multiple times and selecting a patch using majority voting. Finally, the
    full Agentless performance is achieved by further applying filtering to select
    only the patches which can successfully pass the existing regressions tests. Since
    we sample multiple patches per each issue, we also observe that the total number
    of possible issues that Agentless can solve when using all samples is 123 (41.0%).
    This shows a high upper bound for the repair potential of Agentless with future
    work being better re-ranking and selection techniques to further improve the overall
    performance.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们来看看不同修复设置对最终性能的影响。表格 [3](#S4.T3 "表 3 ‣ 4 评估 ‣ 无代理 \scalerel*C: 揭示基于 LLM
    的软件工程代理") 显示了我们可以生成或选择最终提交补丁的不同方式。从仅生成一个样本（即，使用贪婪解码）开始，Agentless 能够实现 70 个正确的修复，同时每个错误的平均成本为
    $0.11（总成本，包括本地化）。我们注意到，即使在这个简单的补丁生成步骤中，Agentless 已经可以超越大多数之前的开源基于代理的方法（成本减少超过
    4 倍）。我们通过多次采样 LLM 并使用多数投票选择补丁，可以将性能进一步提高到 78 个修复。最后，通过进一步应用过滤来选择只有成功通过现有回归测试的补丁，达到了完整的
    Agentless 性能。由于我们对每个问题进行多个补丁采样，我们还观察到，当使用所有样本时，Agentless 可以解决的总问题数为 123 (41.0%)。这显示了
    Agentless 在修复潜力方面的高上限，未来的工作可以通过更好的重新排序和选择技术进一步提高整体性能。'
- en: 5 Additional Analysis on SWE-bench Lite
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 关于 SWE-bench Lite 的额外分析
- en: 5.1 Problem Classification
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 问题分类
- en: '![Refer to caption](img/c492198287de4baca6ee3eb8a73201a1.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c492198287de4baca6ee3eb8a73201a1.png)'
- en: (a) Description quality
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 描述质量
- en: '![Refer to caption](img/d8dc8a1d69ba9de9c544447bed4bdbc5.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/d8dc8a1d69ba9de9c544447bed4bdbc5.png)'
- en: (b) Solution in description
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 描述中的解决方案
- en: '![Refer to caption](img/42c6bd9023c8476a2a78b7693348b024.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/42c6bd9023c8476a2a78b7693348b024.png)'
- en: (c) Location information
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 位置信息
- en: 'Figure 5: Categorization and corresponding breakdown of the SWE-bench Lite
    problems.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：SWE-bench Lite 问题的分类及相应细分。
- en: 'We now take a closer look at the problems in SWE-bench Lite. We first classify
    the existing problems to gain better understanding and additional insights on
    exactly what *types* of problems Agentless and prior approaches can solve. Specifically,
    we perform manual classification based on the issue description and ground truth
    developer patch of each problem. Below describes each of classification dimensions
    and their categories in more detail:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在更详细地查看SWE-bench Lite中的问题。我们首先对现有问题进行分类，以更好地理解和获得关于无代理和先前方法能够解决的*问题类型*的额外见解。具体而言，我们基于每个问题的描述和真实情况开发人员补丁进行手动分类。以下详细描述了每个分类维度及其类别：
- en: '1) Description quality. We first inspect whether each issue description contains
    sufficient information to perform the desired task. Figure [5(a)](#S5.F5.sf1 "In
    Figure 5 ‣ 5.1 Problem Classification ‣ 5 Additional Analysis on SWE-bench Lite
    ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering Agents")
    shows the distribution of each category: *(i)* contains enough information in
    natural language, *(ii)* contains reproducible failure example, *(iii)* contains
    partially reproducible example, and *(iv)* does not contain enough information.We
    observe that while a majority of the tasks in SWE-bench Lite contains sufficient
    information, with many having some small failure examples to showcase the bug,
    there is a non-trivial percentage (9.3%) of problems which do not contain enough
    information. Such problems include those that require implementing a new function
    with a specific name or adding an error message with a specific string that was
    not provided in the problem description.²²2These types of problems still exist
    in the benchmark despite claims that they have been completely removed by the
    filtering process according to [SWE-bench Lite](www.swebench.com/lite.html). This
    means the test will fail if the function name or error message string does not
    match exactly, even if the underlying functionality is correctly implemented.
    Another example of insufficient information are problems that have multiple different
    interpretations on how to solve the issue, and only a subset of them can pass
    the ground truth test. For instance, the issue description will outline two possible
    solutions suggestions with only one of them aligned well with developer intention.
    Implementing the other proposed solution suggestion will lead to test failure.
    This highlights the necessity to further sanitize/improve SWE-bench Lite where
    these problems with uninformative descriptions shall be further excluded.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '1) 描述质量。我们首先检查每个问题描述是否包含足够的信息来执行期望的任务。图[5(a)](#S5.F5.sf1 "在图 5 ‣ 5.1 问题分类 ‣
    5 对 SWE-bench Lite 的额外分析 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理")展示了每个类别的分布：*(i)*
    包含足够的信息以自然语言呈现，*(ii)* 包含可重复的失败示例，*(iii)* 包含部分可重复的示例，*(iv)* 不包含足够的信息。我们观察到，尽管SWE-bench
    Lite中的大多数任务包含足够的信息，许多任务还包含一些小的失败示例来展示缺陷，但有一个非微不足道的百分比（9.3%）的问题没有包含足够的信息。这些问题包括那些要求实现一个具有特定名称的新函数或添加一个带有特定字符串的错误消息，而这些在问题描述中没有提供。²²2这些类型的问题仍然存在于基准测试中，尽管有声称这些问题已通过[SWE-bench
    Lite](www.swebench.com/lite.html)的筛选过程完全移除。这意味着，如果函数名称或错误消息字符串不完全匹配，即使底层功能正确实现，测试也会失败。另一个信息不足的例子是问题存在多种不同的解决方案解释，而只有一部分能够通过真实情况测试。例如，问题描述将概述两个可能的解决方案建议，只有其中一个与开发人员意图很好地对齐。实现其他提出的解决方案建议将导致测试失败。这突显了进一步清理/改进SWE-bench
    Lite的必要性，其中这些描述信息不足的问题应进一步排除。'
- en: '2) Solution in description. We also examine whether the solution or steps to
    solve the problem are already provided in the issue description. Figure [5(b)](#S5.F5.sf2
    "In Figure 5 ‣ 5.1 Problem Classification ‣ 5 Additional Analysis on SWE-bench
    Lite ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering Agents")
    shows the breakdown of our categories: *(i)* no solution or steps provided, *(ii)*
    partial solution provided (e.g., some steps in natural language), *(iii)* complete
    solution provided (e.g., complete steps in natural language), *(iv)* exact patch
    provided, and *(v)* misleading solution or steps. Interestingly, we observe that
    4.3% of issues contain the exact ground truth patch in the issue description,
    while an additional 10.0% of issues describe the exact steps required to come
    up with the correct solution. This shows that certain problems in SWE-bench Lite
    can be much easier to solve since they provide the solution either in exact code
    snippets or natural language. Furthermore, we also observe 4.3% of issues contain
    proposed solution or steps in the issue description that do not reflect the ground
    truth patch introduced by the developers. This further highlights potential issues
    with the benchmark, as these discrepancies can mislead tools to generate incorrect
    solutions simply by following the issue description.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '2) 描述中的解决方案。我们还检查了问题描述中是否已经提供了解决方案或步骤。图[5(b)](#S5.F5.sf2 "在图 5 ‣ 5.1 问题分类 ‣
    5 SWE-bench Lite 的额外分析 ‣ 无代理 \scalerel*C: 揭示基于 LLM 的软件工程代理")展示了我们分类的详细信息：*(i)*
    没有提供解决方案或步骤，*(ii)* 提供了部分解决方案（例如，一些自然语言步骤），*(iii)* 提供了完整的解决方案（例如，完整的自然语言步骤），*(iv)*
    提供了准确的补丁，以及*(v)* 误导性的解决方案或步骤。有趣的是，我们观察到 4.3% 的问题描述中包含了准确的实际补丁，而额外 10.0% 的问题描述了得出正确解决方案所需的准确步骤。这表明，SWE-bench
    Lite 中某些问题的解决可能更容易，因为它们提供了确切的代码片段或自然语言解决方案。此外，我们还观察到 4.3% 的问题描述中包含了提出的解决方案或步骤，这些方案或步骤并未反映开发者提供的实际补丁。这进一步突出显示了基准测试可能存在的问题，因为这些差异可能会误导工具生成错误的解决方案，仅仅通过遵循问题描述。'
- en: '3) Location information. We further check if the issues description contains
    the correct location information. We divide the granularity into line, function,
    and file level locations. Our categories are: *(i)* exact locations in natural
    language, *(ii)* exact locations provided in failure stack traces, *iii)* related
    keywords in the issue description that can be used to search for the location,
    and *(iv)* not provided. We first observe that only in very few cases ($<$10%),
    the issue provides the exact lines needed to fix the bug. However, this number
    increases as we increase the granularity to functions and files where we found
    that around half of the issues already provide the location of the file needed
    to be edited in the description. To repair a bug or introduce a new feature, finding
    the location to make the edit is extremely important. As such, we leverage this
    classification and focus our later analysis on the effect the provided location
    has on the repair performance of Agentless and baseline approaches.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 位置信息。我们进一步检查问题描述中是否包含正确的位置信息。我们将粒度划分为行、函数和文件级别的位置。我们的分类包括：*(i)* 自然语言中的准确位置，*(ii)*
    在失败堆栈跟踪中提供的准确位置，*iii)* 问题描述中与位置相关的关键词，可用于搜索位置，以及*(iv)* 未提供。我们首先观察到，仅在很少的情况下（$<$10%），问题提供了修复错误所需的准确行。然而，随着我们将粒度提高到函数和文件，这个数字增加了，我们发现大约一半的问题已经在描述中提供了需要编辑的文件位置。修复错误或引入新功能时，找到进行编辑的位置极为重要。因此，我们利用这一分类，并在后续分析中重点关注提供的位置对无代理和基线方法修复性能的影响。
- en: These classification dimensions and categories raise potential issues with the
    SWE-bench Lite problems such as unsolvable questions, misleading potential solutions,
    and significant differences in problem difficulties. These issues have not been
    properly considered by either the benchmark creation process or prior approaches.
    Furthermore, we hope our classification can provide additional insights on the
    type of problems that can be solved by existing and future approaches.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分类维度和类别提出了 SWE-bench Lite 问题的潜在问题，如无法解决的问题、误导性的潜在解决方案以及问题难度的显著差异。这些问题在基准创建过程或之前的方法中没有得到妥善考虑。此外，我们希望我们的分类能够提供关于现有和未来方法能够解决的问题类型的额外见解。
- en: 5.2 SWE-bench Lite-$S$
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 SWE-bench Lite-$S$
- en: 'Table 4: Performance and ranking on SWE-bench Lite-$S$. * indicates a tie in
    ranking.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: SWE-bench Lite-$S$ 的性能和排名。* 表示排名的并列。'
- en: '| Tool | LLM | SWE-bench Lite | SWE-bench Lite-$S$ |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | LLM | SWE-bench Lite | SWE-bench Lite-$S$ |'
- en: '| % Resolved | Rank | % Resolved | Rank |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| % 解决 | 排名 | % 解决 | 排名 |'
- en: '| Alibaba Lingma Agent [[7](#bib.bib7)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o+   \scalerel *![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C  Claude-3.5  |
    99 (33.00%) | 1 | 87 (34.52%) | 1 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| Alibaba Lingma Agent [[7](#bib.bib7)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o+ \scalerel
    *![[未标注的图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3.5 | 99 (33.00%)
    | 1 | 87 (34.52%) | 1 |'
- en: '| Factory Code Droid [[5](#bib.bib5)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 94 (31.33%) | 2 | 82 (32.54%) | 2 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| Factory Code Droid [[5](#bib.bib5)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 94 (31.33%) | 2 | 82 (32.54%) | 2 |'
- en: '| AutoCodeRover-v2 [[3](#bib.bib3)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 92 (30.67%) | 3 | 79 (31.35%) | 3 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| AutoCodeRover-v2 [[3](#bib.bib3)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o | 92
    (30.67%) | 3 | 79 (31.35%) | 3 |'
- en: '| CodeR [[17](#bib.bib17)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 85 (28.33%) | 4 | 72 (28.57%) | 4 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| CodeR [[17](#bib.bib17)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4 | 85
    (28.33%) | 4 | 72 (28.57%) | 4 |'
- en: '| IBM Research Agent-101 [[6](#bib.bib6)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 80 (26.67%) | 6 | 66 (26.19%) | 7 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| IBM Research Agent-101 [[6](#bib.bib6)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 80 (26.67%) | 6 | 66 (26.19%) | 7 |'
- en: '| OpenCSG StarShip [[9](#bib.bib9)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 71 (23.67%) | 9 | 57 (22.62%) | 9 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| OpenCSG StarShip [[9](#bib.bib9)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4 | 71
    (23.67%) | 9 | 57 (22.62%) | 9 |'
- en: '| Bytedance MarsCode [[8](#bib.bib8)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 76 (25.33%) | 8 | 63 (25.00%) | 8 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Bytedance MarsCode [[8](#bib.bib8)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4o | 76
    (25.33%) | 8 | 63 (25.00%) | 8 |'
- en: '| Amazon Q Developer [[1](#bib.bib1)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 61 (20.33%) | 11 | 52 (20.63%) | 10* |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Amazon Q Developer [[1](#bib.bib1)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | NA | 61 (20.33%) | 11 | 52 (20.63%) | 10* |'
- en: '| RepoUnderstander [[41](#bib.bib41)] \scalerel*![[Uncaptioned image]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 64 (21.33%) | 10 | 52 (20.63%) | 10* |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| RepoUnderstander [[41](#bib.bib41)] \scalerel*![[未标注的图像]](img/f1313f50693714130653fb391f45f297.png)C
    | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4 | 64
    (21.33%) | 10 | 52 (20.63%) | 10* |'
- en: '| Aider [[21](#bib.bib21)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o+   \scalerel *![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C  Claude-3
    | 79 (26.33%) | 7 | 67 (26.59%) | 6 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Aider [[21](#bib.bib21)] | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o+ \scalerel *![[未标注的图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3
    | 79 (26.33%) | 7 | 67 (26.59%) | 6 |'
- en: '| AutoCodeRover [[65](#bib.bib65)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 57 (19.00%) | 12 | 46 (18.25%) | 12 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| AutoCodeRover [[65](#bib.bib65)] | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 57 (19.00%) | 12 | 46 (18.25%) | 12 |'
- en: '|  | \scalerel'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '| | \scalerel'
- en: '*![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3
    | 35 (11.67%) | 16 | 27 (10.71%) | 16 |'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*![[未标注的图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3 | 35 (11.67%)
    | 16 | 27 (10.71%) | 16 |'
- en: '| SWE-agent [[61](#bib.bib61)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 54 (18.00%) | 13 | 42 (16.67%) | 14 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| SWE-agent [[61](#bib.bib61)] | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 54 (18.00%) | 13 | 42 (16.67%) | 14 |'
- en: '|  | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 50 (16.67%) | 15 | 41 (16.27%) | 15 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4
    | 50 (16.67%) | 15 | 41 (16.27%) | 15 |'
- en: '| OpenDevin [[10](#bib.bib10)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 52 (17.33%) | 14 | 45 (17.86%) | 13 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| OpenDevin [[10](#bib.bib10)] | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 52 (17.33%) | 14 | 45 (17.86%) | 13 |'
- en: '|  | \scalerel'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | \scalerel'
- en: '*![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3
    | 13 (4.33%) | 17 | 10 (3.97%) | 17 |'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*![[未标注的图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-3 | 13 (4.33%)
    | 17 | 10 (3.97%) | 17 |'
- en: '|  | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4 | 8 (2.67%) | 19 | 5 (1.98%) | 19 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C GPT-4
    | 8 (2.67%) | 19 | 5 (1.98%) | 19 |'
- en: '|  | \scalerel'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | \scalerel'
- en: '*![[Uncaptioned image]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-2
    | 9 (3.00%) | 18 | 6 (2.38%) | 18 |'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*![[未标注的图像]](img/578665f7ee65c9339d9280f0414de219.png)C Claude-2 | 9 (3.00%)
    | 18 | 6 (2.38%) | 18 |'
- en: '| RAG [[28](#bib.bib28)] | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    ChatGPT | 1 (0.33%) | 20 | 0 (0.00%) | 20 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| RAG [[28](#bib.bib28)] | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    ChatGPT | 1 (0.33%) | 20 | 0 (0.00%) | 20 |'
- en: '| Agentless \scalerel*![[Uncaptioned image]](img/0620a2f4f39f95766dc037e6b7f67162.png)C
    | \scalerel*![[Uncaptioned image]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 82 (27.33%) | 5 | 71 (28.17%) | 5 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 无代理 \scalerel*![[未标注的图像]](img/0620a2f4f39f95766dc037e6b7f67162.png)C | \scalerel*![[未标注的图像]](img/4d252a238606b0213280842a3fb0bbe8.png)C
    GPT-4o | 82 (27.33%) | 5 | 71 (28.17%) | 5 |'
- en: Building on the above problem classifications, in the following evaluation section,
    we will more rigorously compare and contrast Agentless and existing work. Specifically,
    we focus on a subset of the problems in SWE-bench Lite after removing the problems
    that contain the exact patch in the problem description, misleading solutions,
    or do not provide enough information in the original issue description. This eliminates
    the less reasonable problems and normalizes the difficulty level of the benchmark.
    For future work, we hope to work with the maintainers and contribute to the SWE-bench
    Lite benchmark by fixing these unreasonable problems to add additional information
    as well as removing exact ground truth patches in the problem descriptions. However,
    as we are not able to run commercial tools ourselves on the modified problems,
    we simply exclude the problematic problems in the below evaluation. We refer to
    our subset of 252 problems as SWE-bench Lite-$S$.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述问题分类，在接下来的评估部分，我们将更加严格地比较和对比无代理和现有工作。具体来说，我们重点关注SWE-bench Lite中的一个子集，去除那些问题描述中包含确切修补、误导性解决方案或原始问题描述中信息不足的问题。这消除了不合理的问题，并标准化了基准测试的难度级别。对于未来的工作，我们希望与维护者合作，通过修复这些不合理的问题以添加额外的信息，并移除问题描述中的确切真实修补，从而为SWE-bench
    Lite基准做出贡献。然而，由于我们无法在修改后的问题上运行商业工具，我们在下面的评估中简单地排除了有问题的问题。我们将我们选择的252个问题称为SWE-bench
    Lite-$S$。
- en: 'Table [4](#S5.T4 "Table 4 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 Additional Analysis on
    SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering
    Agents") shows the results on the SWE-bench Lite-$S$ provides a more accurate
    reflection of the true capability of autonomous software development tools.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [4](#S5.T4 "表 4 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 对SWE-bench Lite的额外分析 ‣ 无代理 \scalerel*C:
    揭示基于LLM的软件工程代理") 显示了SWE-bench Lite-$S$的结果，它更准确地反映了自主软件开发工具的实际能力。'
- en: '![Refer to caption](img/a48daa4cc29a0282d3618e952e21ec02.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a48daa4cc29a0282d3618e952e21ec02.png)'
- en: (a) Description quality
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 描述质量
- en: '![Refer to caption](img/e927dab417680dd9d1149bf965860ac5.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e927dab417680dd9d1149bf965860ac5.png)'
- en: (b) Solution in description
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 描述中的解决方案
- en: '![Refer to caption](img/d98dd19f9ad07105609eacd1658cb6f2.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d98dd19f9ad07105609eacd1658cb6f2.png)'
- en: (c) Location information
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 位置信息
- en: 'Figure 6: Solve rate of selected approaches (orange means open-source while
    indigo means closed-source) on different problem categories in SWE-bench Lite-$S$
    for each approach.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 各种方法在SWE-bench Lite-$S$中不同问题类别的解决率（橙色表示开源，靛蓝色表示闭源）。'
- en: 'Using the classification results, we further examine the types of problems
    that are solved by Agentless and prior approaches on SWE-bench Lite-$S$. Figure [6](#S5.F6
    "Figure 6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 Additional Analysis on SWE-bench Lite ‣ Agentless
    \scalerel*C: Demystifying LLM-based Software Engineering Agents") shows the solve
    rate of various top-performing open-source and closed-source approaches across
    the different categories of problems. We first examine if having code examples
    to reproduce the error in the issue description can help the LLM better solve
    the issue in Figure [6(a)](#S5.F6.sf1 "In Figure 6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5
    Additional Analysis on SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying LLM-based
    Software Engineering Agents"). Surprisingly, we found that the solve rate of all
    prior approaches drop when evaluated on the problems with reproducible code examples.
    Many agent-based approaches [[61](#bib.bib61); [10](#bib.bib10); [17](#bib.bib17)]
    attempt to first reproduce the error, however, this may not improve performance
    even on problems with already provided reproducible examples. This shows that
    there are still room for further improvement specifically on reproducing error-triggering
    tests. Next, we look at the effect of ground truth patch/solution in the issue
    description. Figure [6(b)](#S5.F6.sf2 "In Figure 6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5
    Additional Analysis on SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying LLM-based
    Software Engineering Agents") shows the expected result where all selected techniques
    perform better on issues that already provide solution steps in natural language.
    Furthermore, in Figure [6(c)](#S5.F6.sf3 "In Figure 6 ‣ 5.2 SWE-bench Lite-𝑆 ‣
    5 Additional Analysis on SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying
    LLM-based Software Engineering Agents"), we examine the solve rate with respect
    to the location information provided in the issues description. Unsurprisingly,
    we found that the highest solve rates are on problems where the location is provided
    in natural language followed by stack traces. The most difficult problems are
    those that do not contain any clues about the location of the issue in the description.
    We observe that compared with closed-source approaches, Agentless performs comparably
    when the location is provided in either natural language, stack trace, or keywords.
    However, the closed-source agent tools perform better compared to Agentless in
    the case where no location clue is provided. This highlights an advantage of agent-based
    tools in solving these more complex problems where they are able to use complex
    code search tools. This represents potential future work for Agentless to target
    and further improve these types of problems.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '利用分类结果，我们进一步检查了 Agentless 和以往方法在 SWE-bench Lite-$S$ 上解决问题的类型。图 [6](#S5.F6 "Figure
    6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 Additional Analysis on SWE-bench Lite ‣ Agentless
    \scalerel*C: Demystifying LLM-based Software Engineering Agents") 显示了不同类别问题上各种顶级开源和闭源方法的解决率。我们首先检查了在问题描述中是否提供代码示例以重现错误是否能帮助
    LLM 更好地解决问题，如图 [6(a)](#S5.F6.sf1 "In Figure 6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 Additional
    Analysis on SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying LLM-based Software
    Engineering Agents") 所示。令人惊讶的是，我们发现当在具有可重现代码示例的问题上进行评估时，所有先前的方法的解决率都下降了。许多基于代理的方法
    [[61](#bib.bib61); [10](#bib.bib10); [17](#bib.bib17)] 试图首先重现错误，但即使在已经提供了可重现示例的问题上，这也可能不会改善性能。这表明在重现错误触发测试方面仍有改进的空间。接下来，我们查看了问题描述中地面真实补丁/解决方案的效果。图
    [6(b)](#S5.F6.sf2 "In Figure 6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 Additional Analysis
    on SWE-bench Lite ‣ Agentless \scalerel*C: Demystifying LLM-based Software Engineering
    Agents") 显示了期望的结果，其中所有选择的技术在已经提供自然语言解决步骤的问题上表现更好。此外，在图 [6(c)](#S5.F6.sf3 "In Figure
    6 ‣ 5.2 SWE-bench Lite-𝑆 ‣ 5 Additional Analysis on SWE-bench Lite ‣ Agentless
    \scalerel*C: Demystifying LLM-based Software Engineering Agents") 中，我们检查了问题描述中提供的位置信息与解决率的关系。不出所料，我们发现解决率最高的是那些在自然语言中提供位置的信息的问题，其次是堆栈跟踪。最困难的问题是那些在描述中没有任何关于位置的线索的问题。我们观察到，与闭源方法相比，当位置以自然语言、堆栈跟踪或关键字提供时，Agentless
    的表现相当。然而，在没有提供位置线索的情况下，闭源代理工具的表现优于 Agentless。这突出了基于代理的工具在解决这些更复杂的问题时的优势，因为它们能够使用复杂的代码搜索工具。这代表了
    Agentless 未来可能的工作方向，旨在针对并进一步改进这些类型的问题。'
- en: 6 Related Work
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: LLMs for code. LLMs have become the default choice for various coding tasks,
    due to the impressive results achieved by LLMs in both code generation and understanding [[18](#bib.bib18)].
    Developers and researchers have applied on software engineering tasks, such as
    program synthesis [[47](#bib.bib47); [18](#bib.bib18); [35](#bib.bib35); [25](#bib.bib25)],
    code translation [[46](#bib.bib46); [50](#bib.bib50); [51](#bib.bib51)], program
    repair [[59](#bib.bib59); [58](#bib.bib58); [42](#bib.bib42); [31](#bib.bib31);
    [15](#bib.bib15)], and test generation [[19](#bib.bib19); [60](#bib.bib60); [20](#bib.bib20);
    [33](#bib.bib33); [30](#bib.bib30)]. Apart from using general-purpose LLMs, code-specific
    LLMs have been built by further training LLMs using large amounts of open-source
    code snippets. Examples of code LLMs include Codex [[18](#bib.bib18)], CodeLlama [[52](#bib.bib52)],
    StarCoder [[34](#bib.bib34); [39](#bib.bib39)], DeepSeek-Coder [[22](#bib.bib22)],
    etc. Furthermore, researchers have also developed instruction-following code-specific
    LLMs using instruction-tuning methods. Examples of such LLMs include CodeLlama-Inst [[52](#bib.bib52)],
    DeepSeek-Coder-Inst [[22](#bib.bib22)], WizardCoder [[40](#bib.bib40)], Magicoder [[54](#bib.bib54)],
    and OpenCodeInterpreter [[67](#bib.bib67)].
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs用于代码。由于LLMs在代码生成和理解方面取得的令人印象深刻的成果，LLMs已成为各种编码任务的默认选择[[18](#bib.bib18)]。开发人员和研究人员已经将其应用于软件工程任务，如程序合成[[47](#bib.bib47);
    [18](#bib.bib18); [35](#bib.bib35); [25](#bib.bib25)]、代码翻译[[46](#bib.bib46); [50](#bib.bib50);
    [51](#bib.bib51)]、程序修复[[59](#bib.bib59); [58](#bib.bib58); [42](#bib.bib42); [31](#bib.bib31);
    [15](#bib.bib15)]和测试生成[[19](#bib.bib19); [60](#bib.bib60); [20](#bib.bib20); [33](#bib.bib33);
    [30](#bib.bib30)]。除了使用通用LLMs外，还通过使用大量开源代码片段进一步训练LLMs，构建了特定于代码的LLMs。代码LLMs的例子包括Codex[[18](#bib.bib18)]、CodeLlama[[52](#bib.bib52)]、StarCoder[[34](#bib.bib34);
    [39](#bib.bib39)]、DeepSeek-Coder[[22](#bib.bib22)]等。此外，研究人员还使用指令调优方法开发了遵循指令的代码特定LLMs。这些LLMs的例子包括CodeLlama-Inst[[52](#bib.bib52)]、DeepSeek-Coder-Inst[[22](#bib.bib22)]、WizardCoder[[40](#bib.bib40)]、Magicoder[[54](#bib.bib54)]和OpenCodeInterpreter[[67](#bib.bib67)]。
- en: Benchmarking for LLM-based coding tasks. To evaluate the capability of LLMs
    on code, various benchmark has been proposed. HumanEval [[18](#bib.bib18)] and
    MBPP [[14](#bib.bib14)] are two of the most widely-used handcrafted code generation
    benchmarks complete with test cases to check for the correctness of LLM outputs.
    Furthermore, other benchmarks have been proposed with more robust test [[37](#bib.bib37)],
    additional programming languages [[66](#bib.bib66); [16](#bib.bib16)], and other
    programming domains [[26](#bib.bib26); [23](#bib.bib23); [36](#bib.bib36); [32](#bib.bib32);
    [62](#bib.bib62)].
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试LLM基础编码任务。为了评估LLMs在代码上的能力，提出了各种基准测试。HumanEval[[18](#bib.bib18)]和MBPP[[14](#bib.bib14)]是两个最广泛使用的手工编写的代码生成基准，配有测试用例以检查LLM输出的正确性。此外，还提出了其他基准，具有更强的测试[[37](#bib.bib37)]、附加的编程语言[[66](#bib.bib66);
    [16](#bib.bib16)]和其他编程领域[[26](#bib.bib26); [23](#bib.bib23); [36](#bib.bib36);
    [32](#bib.bib32); [62](#bib.bib62)]。
- en: More recently, instead of evaluating on self-contained coding problems, researchers
    have developed benchmarks focus on solving real-world software engineering issues
    by operating on an entire coding repository [[28](#bib.bib28); [63](#bib.bib63);
    [38](#bib.bib38)]. One such popular benchmark is SWE-bench [[28](#bib.bib28)],
    containing problems where the goal is to modify the repository and resolve a real-world
    GitHub issue. The authors of SWE-bench have since published a smaller filtered
    subset of SWE-bench Lite [[11](#bib.bib11)], containing 300 total problems, focused
    on bug fixing issues that only modify a single file in the ground truth patch.
    In this work, we conduct a detailed classification and analysis of the problems
    in SWE-bench Lite. We found that some problems lack sufficient information in
    the problem description to correctly solve the problem. Furthermore, there are
    also problems containing misleading patches, which can confuse the model. Recognizing
    these limitations, we further filter SWE-bench Lite to remove such problems and
    construct SWE-bench Lite-$S$ that can serve as a more rigorous set of problems
    to evaluate different tools.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究人员不再仅仅评估自包含的编程问题，而是开发了专注于解决实际软件工程问题的基准，通过操作整个编码库[[28](#bib.bib28); [63](#bib.bib63);
    [38](#bib.bib38)]。其中一个流行的基准是SWE-bench [[28](#bib.bib28)]，包含了旨在修改代码库并解决实际GitHub问题的任务。SWE-bench的作者随后发布了一个较小的筛选子集SWE-bench
    Lite [[11](#bib.bib11)]，包含300个问题，专注于修复仅修改单个文件的漏洞。在这项工作中，我们对SWE-bench Lite中的问题进行了详细的分类和分析。我们发现某些问题在问题描述中缺乏足够的信息来正确解决问题。此外，还有一些问题包含误导性的修复，这可能会混淆模型。鉴于这些限制，我们进一步筛选了SWE-bench
    Lite，以去除此类问题，并构建了SWE-bench Lite-$S$，作为评估不同工具的更严格的问题集。
- en: Agent-based software development. With the emergence and popularity of agent-based
    frameworks [[56](#bib.bib56)], recently researchers and industry practitioners
    have begun developing agent-based approaches to solve software engineering tasks.
    Devin [[4](#bib.bib4)] (and OpenDevin [[10](#bib.bib10)], open-source alternative),
    is one of the first end-to-end LLM agent-based framework. Devin uses agents to
    first perform planning based on user requirement, then allows the agent to use
    file editor, terminal, and web search engine tools to iteratively perform the
    task. SWE-agent [[61](#bib.bib61)] designs a custom agent-computer interface (ACI)
    that allows the LLM agent to interact with the repository environment with actions
    such as reading, editing file, and running bash commands. AutoCodeRover [[65](#bib.bib65)]
    is another agent-based approach that provide the LLM agent with specific APIs
    (e.g., searching methods in certain class) to effectively find the locations that
    need to be modified to solve the issue. In addition to these highlighted examples,
    there has been a plethora of other agent-based approaches developed in both open-source [[21](#bib.bib21)]
    and close-source/commercial products [[15](#bib.bib15); [17](#bib.bib17); [41](#bib.bib41);
    [7](#bib.bib7); [5](#bib.bib5); [6](#bib.bib6); [9](#bib.bib9); [8](#bib.bib8);
    [1](#bib.bib1)]. Compared to these agent-based techniques, Agentless offers a
    simple and cost-effective solution to tackle real-world software engineering issues.
    Agentless demonstrates for the first time that an *agentless* approach can achieve
    similar performance, without the additional baggage of having to providing excessive
    tools or modeling complex environment behavior/feedback.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的软件开发。随着基于代理的框架的出现和流行[[56](#bib.bib56)]，近期研究人员和行业从业者开始开发基于代理的方法来解决软件工程任务。Devin
    [[4](#bib.bib4)]（以及OpenDevin [[10](#bib.bib10)]，开源替代方案）是第一个端到端LLM基于代理的框架之一。Devin使用代理首先根据用户需求进行规划，然后允许代理使用文件编辑器、终端和网页搜索引擎工具来迭代执行任务。SWE-agent
    [[61](#bib.bib61)]设计了一个自定义的代理-计算机接口（ACI），允许LLM代理通过读取、编辑文件和运行bash命令等操作与代码库环境进行交互。AutoCodeRover
    [[65](#bib.bib65)]是另一种基于代理的方法，它为LLM代理提供特定的API（例如，在某个类中搜索方法），以有效地找到需要修改的位置以解决问题。除了这些突出的例子，还有大量其他基于代理的方法在开源[[21](#bib.bib21)]和闭源/商业产品[[15](#bib.bib15);
    [17](#bib.bib17); [41](#bib.bib41); [7](#bib.bib7); [5](#bib.bib5); [6](#bib.bib6);
    [9](#bib.bib9); [8](#bib.bib8); [1](#bib.bib1)]中开发。与这些基于代理的技术相比，Agentless提供了一种简单且具有成本效益的解决方案来应对现实世界的软件工程问题。Agentless首次展示了*无代理*方法可以在不需要额外工具或复杂环境行为/反馈建模的情况下实现类似的性能。
- en: 7 Conclusion
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: We propose Agentless– an *agentless* approach to automatically tackle software
    development problems. Agentless uses a simple two phase approach of localization
    followed by repair. Compared to prior agent-based approaches, Agentless deliberately
    disallows the LLM for autonomous tool usage or planning. Our evaluation on the
    popular SWE-bench Lite benchmark demonstrates that Agentless can achieve the highest
    performance compared with other open-source techniques while at the same time
    minimizing the cost. Furthermore, we perform a detailed classification of problems
    in SWE-bench Lite to not only offer new insights but to construct a more rigorous
    benchmark of SWE-bench Lite-$S$ after removing problematic problems.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了 Agentless——一种*无代理*的方法来自动处理软件开发问题。Agentless 使用简单的两阶段方法：首先是本地化，然后是修复。与以往的基于代理的方法相比，Agentless
    刻意不允许 LLM 自主使用工具或进行规划。我们在流行的 SWE-bench Lite 基准上进行的评估表明，Agentless 相比其他开源技术能够实现最高的性能，同时最小化成本。此外，我们对
    SWE-bench Lite 中的问题进行了详细分类，不仅提供了新的见解，还在去除有问题的问题后构建了一个更严格的 SWE-bench Lite-$S$ 基准。
- en: Acknowledgments
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We thank Jiawei Liu for providing some of the resources used to run the experiments.
    One of the authors would like to thank Jun Yang for generously gifting his old
    bike³³3Sadly the bike is currently broken. which allowed the author to travel
    faster and thus increasing research speed.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢 Jiawei Liu 提供了用于运行实验的一些资源。作者之一还要感谢 Jun Yang 慷慨赠送的旧自行车³³3遗憾的是，这辆自行车目前坏了，这使得作者能够更快地出行，从而提高了研究速度。
- en: References
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: ama [2024] Amazon q developer the most capable generative ai–powered assistant
    for software development. [https://aws.amazon.com/q/developer//](https://aws.amazon.com/q/developer//),
    2024.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ama [2024] 亚马逊 q 开发者：最强大的生成式 AI 助手，用于软件开发。[https://aws.amazon.com/q/developer//](https://aws.amazon.com/q/developer//)，2024。
- en: ast [2024] Python ast — abstract syntax trees. [https://docs.python.org/3/library/ast.html/](https://docs.python.org/3/library/ast.html/),
    2024.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ast [2024] Python ast —— 抽象语法树。[https://docs.python.org/3/library/ast.html/](https://docs.python.org/3/library/ast.html/)，2024。
- en: aut [2024] Autocoderover autonomous software engineering. [https://autocoderover.dev/](https://autocoderover.dev/),
    2024.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: aut [2024] Autocoderover 自主软件工程。[https://autocoderover.dev/](https://autocoderover.dev/)，2024。
- en: dev [2024] Devin, ai software engineer. [https://www.cognition.ai/introducing-devin](https://www.cognition.ai/introducing-devin),
    2024.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dev [2024] Devin，AI 软件工程师。[https://www.cognition.ai/introducing-devin](https://www.cognition.ai/introducing-devin)，2024。
- en: fac [2024] Factory bringing autonomy to software engineering. [https://www.factory.ai/](https://www.factory.ai/),
    2024.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fac [2024] 工厂将自主性引入软件工程。[https://www.factory.ai/](https://www.factory.ai/)，2024。
- en: 'ibm [2024] Agent-101: A software engineering agent for code assistance developed
    by ibm research. [https://github.com/swe-bench/experiments/blob/main/evaluation/lite/20240612_IBM_Research_Agent101/README.md/](https://github.com/swe-bench/experiments/blob/main/evaluation/lite/20240612_IBM_Research_Agent101/README.md/),
    2024.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ibm [2024] Agent-101：由 ibm 研究开发的代码辅助软件工程代理。[https://github.com/swe-bench/experiments/blob/main/evaluation/lite/20240612_IBM_Research_Agent101/README.md/](https://github.com/swe-bench/experiments/blob/main/evaluation/lite/20240612_IBM_Research_Agent101/README.md/)，2024。
- en: lin [2024] Lingma agent. [https://github.com/swe-bench/experiments/tree/main/evaluation/lite/20240622_Lingma_Agent](https://github.com/swe-bench/experiments/tree/main/evaluation/lite/20240622_Lingma_Agent),
    2024.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: lin [2024] Lingma 代理。[https://github.com/swe-bench/experiments/tree/main/evaluation/lite/20240622_Lingma_Agent](https://github.com/swe-bench/experiments/tree/main/evaluation/lite/20240622_Lingma_Agent)，2024。
- en: mar [2024] Marscode code and innovate faster with ai. [https://www.marscode.com/](https://www.marscode.com/),
    2024.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: mar [2024] Marscode 通过 AI 更快地编写和创新代码。[https://www.marscode.com/](https://www.marscode.com/)，2024。
- en: ope [2024a] Opencsg starship. [https://opencsg.com/product?class=StarShip/](https://opencsg.com/product?class=StarShip/),
    2024a.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ope [2024a] Opencsg Starship。[https://opencsg.com/product?class=StarShip/](https://opencsg.com/product?class=StarShip/)，2024a。
- en: 'ope [2024b] Opendevin: Code less, make more. [https://github.com/OpenDevin/OpenDevin/](https://github.com/OpenDevin/OpenDevin/),
    2024b.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ope [2024b] Opendevin：少写代码，做更多。[https://github.com/OpenDevin/OpenDevin/](https://github.com/OpenDevin/OpenDevin/)，2024b。
- en: swe [2024] Swe-bench lite. [https://www.swebench.com/lite.html](https://www.swebench.com/lite.html),
    2024.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: swe [2024] Swe-bench lite。[https://www.swebench.com/lite.html](https://www.swebench.com/lite.html)，2024。
- en: Adams [1995] Douglas Adams. *The Hitch Hiker's Guide to the Galaxy Omnibus*.
    Random House, 1995.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adams [1995] 道格拉斯·亚当斯。*银河系漫游指南全集*。随机之家，1995。
- en: Anthropic [2024] Anthropic. Introducing claude 3.5 sonnet. [https://www.anthropic.com/news/claude-3-5-sonnet/](https://www.anthropic.com/news/claude-3-5-sonnet/),
    2024.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthropic [2024] Anthropic。介绍 Claude 3.5 Sonnet。 [https://www.anthropic.com/news/claude-3-5-sonnet/](https://www.anthropic.com/news/claude-3-5-sonnet/)，2024年。
- en: Austin et al. [2021] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma,
    Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc
    Le, and Charles Sutton. Program synthesis with large language models, 2021.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Austin et al. [2021] 雅各布·奥斯丁、奥古斯都·奥登纳、麦克斯韦·奈、马尔滕·博斯马、亨利克·米哈维尔斯基、戴维·多汉、艾伦·姜、凯莉·蔡、迈克尔·特里、阮克·乐和查尔斯·萨顿。使用大型语言模型进行程序合成，2021年。
- en: 'Bouzenia et al. [2024] Islem Bouzenia, Premkumar Devanbu, and Michael Pradel.
    Repairagent: An autonomous, llm-based agent for program repair. *arXiv preprint
    arXiv:2403.17134*, 2024.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bouzenia et al. [2024] 伊斯勒姆·布泽尼亚、普雷姆库马尔·德万布和迈克尔·普拉德尔。修复代理：一种基于 LLM 的自主程序修复代理。*arXiv
    预印本 arXiv:2403.17134*，2024年。
- en: 'Cassano et al. [2023] Federico Cassano, John Gouwar, Daniel Nguyen, Sydney
    Nguyen, Luna Phipps-Costin, Donald Pinckney, Ming-Ho Yee, Yangtian Zi, Carolyn Jane
    Anderson, Molly Q Feldman, et al. Multipl-e: A scalable and polyglot approach
    to benchmarking neural code generation. *IEEE Transactions on Software Engineering*,
    2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cassano et al. [2023] 费德里科·卡萨诺、约翰·古瓦尔、丹尼尔·阮、悉尼·阮、露娜·菲普斯-科斯廷、唐纳德·平克尼、明昊·易、杨天·紫、卡罗琳·简·安德森、莫莉·Q·费尔德曼等。Multipl-e：一种可扩展的多语言神经代码生成基准方法。*IEEE
    软件工程学报*，2023年。
- en: 'Chen et al. [2024] Dong Chen, Shaoxin Lin, Muhan Zeng, Daoguang Zan, Jian-Gang
    Wang, Anton Cheshkov, Jun Sun, Hao Yu, Guoliang Dong, Artem Aliev, et al. Coder:
    Issue resolving with multi-agent and task graphs. *arXiv preprint arXiv:2406.01304*,
    2024.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2024] 董晨、邵新·林、穆汉·曾、道光·赞、简刚·王、安东·切什科夫、俊·孙、浩宇、郭良·董、阿尔忒弥斯·阿列夫等。编码器：使用多代理和任务图解决问题。*arXiv
    预印本 arXiv:2406.01304*，2024年。
- en: Chen et al. [2021] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. Evaluating large language models trained on code. *arXiv
    preprint arXiv:2107.03374*, 2021.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. [2021] 马克·陈、杰瑞·特沃雷克、希伍·郑、齐明·袁、亨里克·庞德·德·奥利维拉·皮尼托、贾瑞德·卡普兰、哈里·爱德华兹、尤里·布尔达、尼古拉斯·约瑟夫、格雷格·布罗克曼等。评估训练有素的大型语言模型。*arXiv
    预印本 arXiv:2107.03374*，2021年。
- en: 'Deng et al. [2023] Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang,
    and Lingming Zhang. Large language models are zero-shot fuzzers: Fuzzing deep-learning
    libraries via large language models. In *32nd International Symposium on Software
    Testing and Analysis (ISSTA)*, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. [2023] 阴霖·邓、春秋·史蒂文·夏、浩然·彭、陈远·杨和凌铭·张。大型语言模型是零-shot 模糊测试器：通过大型语言模型对深度学习库进行模糊测试。发表于
    *第32届国际软件测试与分析研讨会（ISSTA）*，2023年。
- en: 'Deng et al. [2024] Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan
    Zhang, Shujing Yang, and Lingming Zhang. Large language models are edge-case fuzzers:
    Testing deep learning libraries via fuzzgpt. In *46th International Conference
    on Software Engineering (ICSE)*, 2024.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. [2024] 阴霖·邓、春秋·史蒂文·夏、陈远·杨、石卓·迪伦·张、舒靖·杨和凌铭·张。大型语言模型是边缘情况模糊测试器：通过
    fuzzgpt 测试深度学习库。发表于 *第46届国际软件工程大会（ICSE）*，2024年。
- en: Gauthier [2024] Paul Gauthier. Aider is ai pair programming in your terminal.
    [https://aider.chat/](https://aider.chat/), 2024.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gauthier [2024] 保罗·高提耶。Aider 是终端中的 AI 配对编程。 [https://aider.chat/](https://aider.chat/)，2024年。
- en: 'Guo et al. [2024] Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao
    Zhang, Guanting Chen, Xiao Bi, Y Wu, YK Li, et al. Deepseek-coder: When the large
    language model meets programming–the rise of code intelligence. *arXiv preprint
    arXiv:2401.14196*, 2024.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. [2024] 大雅·郭、齐浩·朱、德健·杨、振达·谢、凯·董、文涛·张、关婷·陈、小毕、Y·吴、YK·李等。Deepseek-coder：当大型语言模型遇到编程——代码智能的崛起。*arXiv
    预印本 arXiv:2401.14196*，2024年。
- en: Hendrycks et al. [2021] Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas
    Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song,
    and Jacob Steinhardt. Measuring coding challenge competence with apps. *NeurIPS*,
    2021.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks et al. [2021] 丹·亨德里克斯、史蒂文·巴萨特、索拉夫·卡达瓦斯、曼塔斯·马泽伊卡、阿库尔·阿罗拉、伊桑·郭、科林·伯恩斯、萨米尔·普拉尼克、霍勒斯·赫、道恩·宋和雅各布·斯坦哈特。通过应用程序测量编码挑战能力。*NeurIPS*，2021年。
- en: Huang et al. [2024] Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng,
    Adams Wei Yu, Xinying Song, and Denny Zhou. Large language models cannot self-correct
    reasoning yet. In *The Twelfth International Conference on Learning Representations*,
    2024. URL [https://openreview.net/forum?id=IkmD3fKBPQ](https://openreview.net/forum?id=IkmD3fKBPQ).
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2024] Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng,
    Adams Wei Yu, Xinying Song, 和 Denny Zhou. 大型语言模型尚无法自我修正推理。在*第十二届国际学习表征大会*上，2024年。网址
    [https://openreview.net/forum?id=IkmD3fKBPQ](https://openreview.net/forum?id=IkmD3fKBPQ)。
- en: Iyer et al. [2018] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke
    Zettlemoyer. Mapping language to code in programmatic context. In *Proceedings
    of the 2018 Conference on Empirical Methods in Natural Language Processing*, pp. 
    1643–1652, 2018.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iyer et al. [2018] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, 和 Luke Zettlemoyer.
    在程序化上下文中将语言映射到代码。在*2018年自然语言处理实证方法会议论文集*上，页码 1643–1652，2018年。
- en: 'Jain et al. [2024] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan,
    Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. Livecodebench:
    Holistic and contamination free evaluation of large language models for code.
    *arXiv preprint*, 2024.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jain et al. [2024] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan,
    Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, 和 Ion Stoica. Livecodebench:
    大型语言模型代码的整体与无污染评估。*arXiv 预印本*，2024年。'
- en: 'Jiang et al. [2023] Nan Jiang, Kevin Liu, Thibaud Lutellier, and Lin Tan. Impact
    of code language models on automated program repair. In *2023 IEEE/ACM 45th International
    Conference on Software Engineering (ICSE)*, pp.  1430–1442, 2023. doi: 10.1109/ICSE48619.2023.00125.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiang et al. [2023] Nan Jiang, Kevin Liu, Thibaud Lutellier, 和 Lin Tan. 代码语言模型对自动程序修复的影响。在*2023
    IEEE/ACM 第45届国际软件工程大会 (ICSE)*上，页码 1430–1442，2023年。doi: 10.1109/ICSE48619.2023.00125。'
- en: 'Jimenez et al. [2024a] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, and Karthik R Narasimhan. SWE-bench: Can language
    models resolve real-world github issues? In *The Twelfth International Conference
    on Learning Representations*, 2024a. URL [https://openreview.net/forum?id=VTF8yNQM66](https://openreview.net/forum?id=VTF8yNQM66).'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jimenez et al. [2024a] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, 和 Karthik R Narasimhan. SWE-bench: 语言模型能否解决现实世界的 GitHub
    问题？在*第十二届国际学习表征大会*上，2024a。网址 [https://openreview.net/forum?id=VTF8yNQM66](https://openreview.net/forum?id=VTF8yNQM66)。'
- en: Jimenez et al. [2024b] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, and Karthik R Narasimhan. Swe-bench leaderboard. [https://www.swebench.com/](https://www.swebench.com/),
    2024b.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jimenez et al. [2024b] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, 和 Karthik R Narasimhan. Swe-bench 排行榜。 [https://www.swebench.com/](https://www.swebench.com/)，2024b。
- en: 'Kang et al. [2023] Sungmin Kang, Juyeon Yoon, and Shin Yoo. Large language
    models are few-shot testers: Exploring llm-based general bug reproduction. In
    *2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)*,
    pp.  2312–2323\. IEEE, 2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang et al. [2023] Sungmin Kang, Juyeon Yoon, 和 Shin Yoo. 大型语言模型是少量测试者：探索基于
    LLM 的通用 bug 复现。在*2023 IEEE/ACM 第45届国际软件工程大会 (ICSE)*上，页码 2312–2323。IEEE，2023年。
- en: 'Kolak et al. [2022] Sophia D Kolak, Ruben Martins, Claire Le Goues, and Vincent Josua
    Hellendoorn. Patch generation with language models: Feasibility and scaling behavior.
    In *Deep Learning for Code Workshop*, 2022.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kolak et al. [2022] Sophia D Kolak, Ruben Martins, Claire Le Goues, 和 Vincent
    Josua Hellendoorn. 使用语言模型生成补丁：可行性与扩展行为。在*代码深度学习研讨会*上，2022年。
- en: 'Lai et al. [2023] Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi
    Zhong, Luke Zettlemoyer, Wen-tau Yih, Daniel Fried, Sida Wang, and Tao Yu. Ds-1000:
    A natural and reliable benchmark for data science code generation. In *International
    Conference on Machine Learning*, pp.  18319–18345\. PMLR, 2023.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lai et al. [2023] Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi
    Zhong, Luke Zettlemoyer, Wen-tau Yih, Daniel Fried, Sida Wang, 和 Tao Yu. DS-1000:
    一个自然且可靠的数据科学代码生成基准。在*国际机器学习大会*上，页码 18319–18345。PMLR，2023年。'
- en: 'Lemieux et al. [2023] Caroline Lemieux, Jeevana Priya Inala, Shuvendu K Lahiri,
    and Siddhartha Sen. Codamosa: Escaping coverage plateaus in test generation with
    pre-trained large language models. In *45th International Conference on Software
    Engineering (ICSE)*, 2023.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lemieux et al. [2023] Caroline Lemieux, Jeevana Priya Inala, Shuvendu K Lahiri,
    和 Siddhartha Sen. Codamosa: 利用预训练的大型语言模型打破测试生成中的覆盖面瓶颈。在*第45届国际软件工程大会 (ICSE)*上，2023年。'
- en: 'Li et al. [2023] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff,
    Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim,
    et al. Starcoder: may the source be with you!, 2023.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. [2023] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff,
    Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim,
    等。Starcoder: 愿源代码与你同在！，2023年。'
- en: Li et al. [2022a] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian
    Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin
    Dal Lago, et al. Competition-level code generation with alphacode. *Science*,
    378(6624):1092–1097, 2022a.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2022a] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,
    Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago 等人。竞赛级代码生成与
    alphacode。*Science*, 378(6624):1092–1097, 2022a。
- en: Li et al. [2022b] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian
    Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal
    Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d’Autume, Igor Babuschkin,
    Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James
    Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas,
    Koray Kavukcuoglu, and Oriol Vinyals. Competition-level code generation with alphacode.
    *Science*, 2022b. URL [https://www.science.org/doi/abs/10.1126/science.abq1158](https://www.science.org/doi/abs/10.1126/science.abq1158).
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2022b] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,
    Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas
    Hubert, Peter Choy, Cyprien de Masson d’Autume, Igor Babuschkin, Xinyun Chen,
    Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel
    J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray
    Kavukcuoglu, 和 Oriol Vinyals. 竞赛级代码生成与 alphacode。*Science*, 2022b。网址 [https://www.science.org/doi/abs/10.1126/science.abq1158](https://www.science.org/doi/abs/10.1126/science.abq1158)。
- en: Liu et al. [2023a] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming
    Zhang. Is your code generated by chatGPT really correct? rigorous evaluation of
    large language models for code generation. In *Thirty-seventh Conference on Neural
    Information Processing Systems*, 2023a. URL [https://openreview.net/forum?id=1qvx610Cu7](https://openreview.net/forum?id=1qvx610Cu7).
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2023a] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, 和 Lingming Zhang.
    你的代码由 chatGPT 生成真的正确吗？对大型语言模型进行的严格评估。载于 *第37届神经信息处理系统会议*，2023a。网址 [https://openreview.net/forum?id=1qvx610Cu7](https://openreview.net/forum?id=1qvx610Cu7)。
- en: 'Liu et al. [2023b] Tianyang Liu, Canwen Xu, and Julian McAuley. Repobench:
    Benchmarking repository-level code auto-completion systems. *arXiv preprint arXiv:2306.03091*,
    2023b.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 [2023b] Tianyang Liu, Canwen Xu, 和 Julian McAuley. Repobench: 基于仓库级代码自动补全系统的基准测试。*arXiv
    预印本 arXiv:2306.03091*, 2023b。'
- en: 'Lozhkov et al. [2024] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico
    Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu,
    Yuxiang Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada,
    Zijian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding
    Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii
    Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He, Manan
    Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov,
    Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan
    Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian
    McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane
    Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz
    Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra,
    and Harm de Vries. Starcoder 2 and the stack v2: The next generation, 2024.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lozhkov 等人 [2024] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano,
    Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang
    Wei, Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian
    Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan
    Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii Osae Osae
    Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He, Manan Dey, Edoardo
    Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muhtasham Oblokulov, Christopher
    Akiki, Marc Marone, Chenghao Mou, Mayank Mishra, Alex Gu, Binyuan Hui, Tri Dao,
    Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu, Julian McAuley, Han Hu,
    Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane Anderson, Nicolas
    Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz Ferrandis,
    Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, 和 Harm
    de Vries. Starcoder 2 和 stack v2：下一代，2024。
- en: 'Luo et al. [2023] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang
    Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering
    code large language models with evol-instruct. *arXiv preprint arXiv:2306.08568*,
    2023.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Luo 等人 [2023] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang
    Hu, Chongyang Tao, Jing Ma, Qingwei Lin, 和 Daxin Jiang. Wizardcoder: 用 evol-instruct
    强化代码大型语言模型。*arXiv 预印本 arXiv:2306.08568*, 2023。'
- en: Ma et al. [2024] Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang,
    and Yongbin Li. How to understand whole software repository? *arXiv preprint arXiv:2406.01422*,
    2024.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等人 [2024] Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang, 和
    Yongbin Li. 如何理解整个软件库？*arXiv 预印本 arXiv:2406.01422*, 2024。
- en: Monperrus [2018] Martin Monperrus. *The living review on automated program repair*.
    PhD thesis, HAL Archives Ouvertes, 2018.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Monperrus [2018] 马丁·蒙佩鲁斯。 *自动程序修复的生动评述*。博士论文，HAL Archives Ouvertes，2018年。
- en: Olausson et al. [2023] Theo X Olausson, Jeevana Priya Inala, Chenglong Wang,
    Jianfeng Gao, and Armando Solar-Lezama. Is self-repair a silver bullet for code
    generation? In *The Twelfth International Conference on Learning Representations*,
    2023.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olausson et al. [2023] 西奥·X·奥劳森，吉瓦娜·普里亚·伊纳拉，程龙·王，简锋·高，和阿曼多·索拉尔-莱扎玛。自我修复是否是代码生成的灵丹妙药？在
    *第十二届国际学习表征会议*，2023年。
- en: OpenAI [2023] OpenAI. Gpt-4 technical report. *ArXiv*, abs/2303.08774, 2023.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2023] OpenAI。Gpt-4 技术报告。 *ArXiv*，abs/2303.08774，2023年。
- en: OpenAI [2024] OpenAI. Hello gpt-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/),
    2024.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI [2024] OpenAI. 你好 gpt-4o。 [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)，2024年。
- en: 'Pan et al. [2024] Rangeet Pan, Ali Reza Ibrahimzada, Rahul Krishna, Divya Sankar,
    Lambert Pouguem Wassi, Michele Merler, Boris Sobolev, Raju Pavuluri, Saurabh Sinha,
    and Reyhaneh Jabbarvand. Lost in translation: A study of bugs introduced by large
    language models while translating code. In *Proceedings of the IEEE/ACM 46th International
    Conference on Software Engineering*, pp.  1–13, 2024.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan et al. [2024] 兰吉特·潘，阿里·雷扎·易卜拉欣扎达，拉胡尔·克里希纳，迪维亚·桑卡尔，兰伯特·普古姆·瓦西，米歇尔·梅勒，鲍里斯·索博列夫，拉朱·帕武鲁里，索拉布·辛哈，和雷哈内·贾巴尔万德。在翻译代码时，大型语言模型引入的错误。见
    *IEEE/ACM 第46届国际软件工程会议论文集*，第1–13页，2024年。
- en: Patton et al. [2024] Noah Patton, Kia Rahmani, Meghana Missula, Joydeep Biswas,
    and Işıl Dillig. Programming-by-demonstration for long-horizon robot tasks. *Proceedings
    of the ACM on Programming Languages*, 8(POPL):512–545, 2024.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Patton et al. [2024] 诺亚·帕顿，基亚·拉赫马尼，梅赫娜·米苏拉，乔伊迪普·比斯瓦斯，和伊什尔·迪利格。用于长时间机器人任务的编程演示。
    *ACM 编程语言会议论文集*，8(POPL):512–545，2024年。
- en: 'Prenner et al. [2022] Julian Aron Prenner, Hlib Babii, and Romain Robbes. Can
    openai''s codex fix bugs?: An evaluation on quixbugs. In *2022 IEEE/ACM International
    Workshop on Automated Program Repair (APR)*, pp.  69–75, 2022.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prenner et al. [2022] 朱利安·阿龙·普伦纳，赫利布·巴比，和罗曼·罗布斯。OpenAI 的 Codex 能修复错误吗？：对 Quixbugs
    的评估。在 *2022 IEEE/ACM 国际自动化程序修复研讨会 (APR)*，第69–75页，2022年。
- en: 'Robertson et al. [2009] Stephen Robertson, Hugo Zaragoza, et al. The probabilistic
    relevance framework: Bm25 and beyond. *Foundations and Trends® in Information
    Retrieval*, 3(4):333–389, 2009.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robertson et al. [2009] 斯蒂芬·罗伯逊，雨果·萨拉戈萨，等人。概率相关框架：BM25 及其拓展。 *信息检索基础与趋势®*，3(4):333–389，2009年。
- en: Roziere et al. [2020] Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot,
    and Guillaume Lample. Unsupervised translation of programming languages. *Advances
    in neural information processing systems*, 33:20601–20611, 2020.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roziere et al. [2020] 巴普蒂斯特·罗齐耶，玛丽-安·拉肖，洛维克·查努索，和纪尧姆·兰普勒。编程语言的无监督翻译。 *神经信息处理系统进展*，33:20601–20611，2020年。
- en: Roziere et al. [2021] Baptiste Roziere, Jie M Zhang, Francois Charton, Mark
    Harman, Gabriel Synnaeve, and Guillaume Lample. Leveraging automated unit tests
    for unsupervised code translation. *arXiv preprint arXiv:2110.06773*, 2021.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roziere et al. [2021] 巴普蒂斯特·罗齐耶，张杰，弗朗索瓦·夏尔顿，马克·哈曼，加布里埃尔·辛奈夫，纪尧姆·兰普勒。利用自动化单元测试进行无监督代码翻译。
    *arXiv 预印本 arXiv:2110.06773*，2021年。
- en: 'Rozière et al. [2023] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy
    Rapin, et al. Code llama: Open foundation models for code. *arXiv preprint arXiv:2308.12950*,
    2023.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rozière et al. [2023] 巴普蒂斯特·罗齐耶，乔纳斯·格赫林，法比安·格洛克尔，斯滕·苏特拉，伊泰·加特，肖青青·坦，约西·阿迪，刘晶瑜，塔尔·瑞梅兹，杰雷米·拉潘，等人。Code
    llama: 开放的代码基础模型。 *arXiv 预印本 arXiv:2308.12950*，2023年。'
- en: Shi et al. [2023] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David
    Dohan, Ed H Chi, Nathanael Schärli, and Denny Zhou. Large language models can
    be easily distracted by irrelevant context. In *International Conference on Machine
    Learning*, pp.  31210–31227\. PMLR, 2023.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. [2023] 弗雷达·史，陈新云，卡尼什卡·米斯拉，内森·斯凯尔斯，大卫·多汉，埃德·H·池，纳塔纳埃尔·施亚尔利，和丹尼·周。大型语言模型容易被无关的上下文分心。在
    *国际机器学习会议*，第31210–31227页。PMLR，2023年。
- en: 'Wei et al. [2023] Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming
    Zhang. Magicoder: Source code is all you need. *arXiv preprint arXiv:2312.02120*,
    2023.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wei et al. [2023] 余翔伟，王哲，刘佳伟，丁逸峰，张玲铭。Magicoder: 只需源代码。 *arXiv 预印本 arXiv:2312.02120*，2023年。'
- en: Wong et al. [1997] W Eric Wong, Joseph R Horgan, Saul London, and Hiralal Agrawal.
    A study of effective regression testing in practice. In *PROCEEDINGS The Eighth
    International Symposium On Software Reliability Engineering*, pp.  264–274\. IEEE,
    1997.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wong 等人 [1997] W Eric Wong, Joseph R Horgan, Saul London 和 Hiralal Agrawal.
    实践中的有效回归测试研究。发表于 *第八届国际软件可靠性工程研讨会论文集*，第264–274页。IEEE，1997年。
- en: 'Xi et al. [2023] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential
    of large language model based agents: A survey. *arXiv preprint arXiv:2309.07864*,
    2023.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xi 等人 [2023] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou 等人. 基于大型语言模型的代理的崛起与潜力：一项调查。*arXiv
    预印本 arXiv:2309.07864*，2023年。
- en: 'Xia & Zhang [2022] Chunqiu Steven Xia and Lingming Zhang. Less training, more
    repairing please: revisiting automated program repair via zero-shot learning.
    In *Proceedings of the 30th ACM Joint European Software Engineering Conference
    and Symposium on the Foundations of Software Engineering*, pp.  959–971, 2022.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia 和 Zhang [2022] Chunqiu Steven Xia 和 Lingming Zhang. 少训练，多修复：通过零样本学习重新审视自动程序修复。发表于
    *第30届ACM联合欧洲软件工程会议暨软件工程基础研讨会论文集*，第959–971页，2022年。
- en: 'Xia & Zhang [2023] Chunqiu Steven Xia and Lingming Zhang. Keep the conversation
    going: Fixing 162 out of 337 bugs for $0.42 each using chatgpt. *arXiv preprint
    arXiv:2304.00385*, 2023.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia 和 Zhang [2023] Chunqiu Steven Xia 和 Lingming Zhang. 保持对话：利用 ChatGPT 修复337个漏洞中的162个，每个修复费用
    $0.42。*arXiv 预印本 arXiv:2304.00385*，2023年。
- en: Xia et al. [2023] Chunqiu Steven Xia, Yuxiang Wei, and Lingming Zhang. Automated
    program repair in the era of large pre-trained language models. In *Proceedings
    of the ACM/IEEE 45th International Conference on Software Engineering*, ICSE '23,
    2023.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia 等人 [2023] Chunqiu Steven Xia, Yuxiang Wei 和 Lingming Zhang. 大型预训练语言模型时代的自动程序修复。发表于
    *ACM/IEEE 第45届国际软件工程会议论文集*，ICSE '23，2023年。
- en: Xia et al. [2024] Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael
    Pradel, and Lingming Zhang. Universal fuzzing via large language models. In *46th
    International Conference on Software Engineering (ICSE)*, 2024.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia 等人 [2024] Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel
    和 Lingming Zhang. 通过大型语言模型实现通用模糊测试。发表于 *第46届国际软件工程会议 (ICSE)*，2024年。
- en: 'Yang et al. [2024] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret,
    Shunyu Yao, Karthik Narasimhan, and Ofir Press. Swe-agent: Agent-computer interfaces
    enable automated software engineering. *arXiv preprint arXiv:2405.15793*, 2024.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等人 [2024] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret,
    Shunyu Yao, Karthik Narasimhan 和 Ofir Press. Swe-agent: 代理-计算机接口实现自动化软件工程。*arXiv
    预印本 arXiv:2405.15793*，2024年。'
- en: Yin et al. [2022] Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming
    Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski,
    Alex Polozov, and Charles Sutton. Natural language to code generation in interactive
    data science notebooks. 2022.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin 等人 [2022] Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming Wen,
    Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski,
    Alex Polozov 和 Charles Sutton. 交互式数据科学笔记本中的自然语言到代码生成。2022。
- en: 'Zhang et al. [2023a] Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu,
    Daoguang Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen. Repocoder: Repository-level
    code completion through iterative retrieval and generation. *arXiv preprint arXiv:2303.12570*,
    2023a.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等人 [2023a] Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu, Daoguang
    Zan, Yi Mao, Jian-Guang Lou 和 Weizhu Chen. Repocoder: 通过迭代检索和生成实现的库级代码补全。*arXiv
    预印本 arXiv:2303.12570*，2023a。'
- en: 'Zhang et al. [2023b] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. Siren''s song in the
    ai ocean: a survey on hallucination in large language models. *arXiv preprint
    arXiv:2309.01219*, 2023b.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 [2023b] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen 等人. AI 海洋中的塞壬之歌：对大型语言模型中的幻觉的调查。*arXiv
    预印本 arXiv:2309.01219*，2023b。
- en: 'Zhang et al. [2024] Yuntong Zhang, Haifeng Ruan, Zhiyu Fan, and Abhik Roychoudhury.
    Autocoderover: Autonomous program improvement, 2024.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等人 [2024] Yuntong Zhang, Haifeng Ruan, Zhiyu Fan 和 Abhik Roychoudhury.
    Autocoderover: 自主程序改进，2024年。'
- en: 'Zheng et al. [2023] Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang,
    Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, et al. Codegeex: A pre-trained
    model for code generation with multilingual evaluations on humaneval-x. *arXiv
    preprint arXiv:2303.17568*, 2023.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng 等人 [2023] Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei
    Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li 等人. Codegeex: 一种用于代码生成的预训练模型，在humaneval-x上进行了多语言评估。*arXiv
    预印本 arXiv:2303.17568*，2023年。'
- en: 'Zheng et al. [2024] Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill Yuchen
    Lin, Jie Fu, Wenhu Chen, and Xiang Yue. Opencodeinterpreter: Integrating code
    generation with execution and refinement. *arXiv preprint arXiv:2402.14658*, 2024.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zheng et al. [2024] Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill
    Yuchen Lin, Jie Fu, Wenhu Chen, 和 Xiang Yue. Opencodeinterpreter: 将代码生成与执行和优化集成。
    *arXiv 预印本 arXiv:2402.14658*，2024年。'
- en: Örwall [2024] Albert Örwall. A docker based solution of the swe-bench evaluation
    framework. [https://github.com/aorwall/SWE-bench-docker](https://github.com/aorwall/SWE-bench-docker),
    2024.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Örwall [2024] Albert Örwall. 基于 Docker 的 swe-bench 评估框架解决方案。 [https://github.com/aorwall/SWE-bench-docker](https://github.com/aorwall/SWE-bench-docker)，2024年。
