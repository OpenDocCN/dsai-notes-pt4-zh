<!--yml

category: 未分类

日期：2025-01-11 11:49:17

-->

# 隐私保护联邦上下文LLM代理学习

> 来源：[https://arxiv.org/html/2412.08054/](https://arxiv.org/html/2412.08054/)

Panlong Wu¹, Kangshuo Li¹, Junbao Nan¹, Fangxin Wang¹

###### 摘要

大型语言模型（LLMs）通过使逻辑推理、工具使用和与外部系统的互动成为可能，彻底改变了智能服务。LLMs的进展常常受到高质量数据稀缺的阻碍，其中很多数据本质上是敏感的。联邦学习（FL）提供了一种潜在解决方案，通过促进分布式LLM的协作训练，同时保护私密数据。然而，FL框架面临着显著的带宽和计算需求，以及来自异构数据分布的挑战。LLMs新兴的上下文学习能力提供了一种有前景的方法，它通过汇总自然语言而不是庞大的模型参数来进行训练。然而，这种方法也存在隐私泄露的风险，因为它需要在聚合过程中收集和呈现来自不同客户端的数据样本。在本文中，我们提出了一种新颖的隐私保护联邦上下文LLM代理学习（FICAL）算法，据我们所知，这是首个通过FL释放上下文学习的力量来训练多样化LLM代理的工作。在我们的设计中，由新型LLM增强的知识编纂生成（KCG）模块生成的知识编纂将在客户端和服务器之间传输，而不是以前FL方法中的模型参数。除此之外，我们设计了一个基于检索增强生成（RAG）的工具学习与使用（TLU）模块，并将聚合的全球知识编纂作为教师，用以教导LLM代理如何使用工具。我们进行了广泛的实验，结果表明，FICAL相较于其他最先进的基准方法具有竞争力，并且通信成本显著降低，达到了$\mathbf{3.33\times 10^{5}}$倍。

## 介绍

大型语言模型（LLMs）的出现为应对日益增长的高级智能服务需求提供了一种革命性的方法。与传统的小型神经网络不同，LLMs是在包含数十亿参数的海量多样化数据上进行训练，从而使它们具备传统神经网络所不具备的突现能力（Wei et al. [2022](https://arxiv.org/html/2412.08054v1#bib.bib25)）。这些突现能力使LLMs能够进行逻辑推理和思考，并与外部工具进行互动，因此可以作为代理帮助处理更为多样化和复杂的任务。

尽管LLM的快速发展及其卓越的能力，但LLM代理在下游任务中的能力往往受到高质量数据量的限制。然而，大多数数据都存储在本地且是私有的，这使得LLM无法吸收更多数据以提高其性能。联邦学习（FL）作为一种有前景的方法应运而生，使得多个客户端可以在不直接交换私有数据的情况下协同改进模型。在FL中，通过聚合模型权重促进了不同客户端之间的知识共享，从而保护了隐私。

然而，在联邦学习（FL）中训练大语言模型（LLM）代理会带来许多实际部署中的重大挑战。第一个挑战是高带宽消耗与现代通信系统之间的不匹配。像LLaMA3.1-405B（Dubey等人 [2024](https://arxiv.org/html/2412.08054v1#bib.bib6)）这样的流行LLM在典型的100 Mbps通信网络下需要超过十个小时才能在两个分布式节点之间传输数据。LLM在FL中每轮通信中客户端与中央服务器之间的参数共享对现代通信系统来说是一个巨大的负担。第二个挑战是高计算消耗与现代计算硬件之间的不匹配。流行的现代LLM通常具有数十亿个参数，比传统模型大数千倍，但硬件的发展无法跟上这一进展。训练LLM计算密集，导致训练时间延长，并且由于需要购买具有高处理能力和大内存容量的GPU，成本也非常高。第三个挑战是不同客户端之间的数据分布异质性。由于用户的地理位置或行业的不同，不同客户端可能具有非独立同分布（non-IID）数据。这会损害模型参数的聚合（Zhao等人 [2018](https://arxiv.org/html/2412.08054v1#bib.bib28)），并进一步复杂化FL过程。

大模型的上下文学习能力为大模型代理的联邦训练提供了启示。随着语言模型参数规模的大幅增加，大模型展现出卓越的理解能力，能够更好地理解提供的上下文，并在上下文中包含更多知识时提升性能。这表明，通过提供包含指令、相应工具以及使用这些工具所需输入参数的多种示例，能够直接增强大模型代理的工具使用能力，从而使其从这些实例中学习。大模型的上下文学习能力使其能够广泛地从提供的自然语言上下文中获取知识。通过将这一能力与联邦学习结合，我们可以传输自然语言上下文，而不是大模型繁琐的参数，从而显著降低通信成本。然而，在联邦学习中应用上下文学习可能会导致用户隐私泄露，因为它通常需要在聚合过程中收集来自不同客户端的数据样本并呈现在上下文中。如何在保证联邦学习隐私的同时，使得不同的大模型代理能够通过上下文学习访问知识，仍然是先前研究中未解决的挑战。

在本文中，我们提出了一种新颖的隐私保护联邦上下文大模型（FICAL）算法，以填补这一空白。根据我们的最佳知识，这是首次在联邦学习（FL）中释放上下文学习的潜力，以应对这些挑战。与所有之前的传统联邦学习算法不同，这些算法每次通信轮次都会传输模型参数，而在FICAL中，我们创新性地设计了一个知识汇编生成（KCG）模块，用于生成包含工具使用知识的知识汇编，并进行传输和聚合。这一创新设计使得FICAL的通信消耗为$O(1)$，而传统的参数共享联邦学习算法的通信消耗则相对于模型大小为$O(N)$。这一卓越的通信性能保证还表明，随着模型参数规模的不断增大，FICAL在可扩展性方面具有显著优势。此外，我们设计了一个基于检索增强生成（RAG）的工具学习与使用（TLU）模块，使得大模型代理能够通过长上下文聚合的知识汇编学习如何使用工具。该TLU模块解决了当FICAL支持大量客户端时遇到的可扩展性挑战。此类情况可能导致聚合的知识汇编中的上下文过长，从而不利于大模型代理的性能，甚至可能超过其最大上下文长度。

我们考虑了多个客户端拥有本地LLM代理和不同工具使用实例的私有数据，并共同训练一个全局LLM代理的联邦学习场景。我们的设计包含以下步骤：（1）每个客户端基于其本地数据集，通过新设计的LLM增强型知识汇编生成（KCG）模块生成本地知识汇编，并将其传输到中央服务器。该本地知识汇编包含工具使用场景、工具使用注意事项、不同工具之间的协调等信息。（2）中央服务器接收来自不同客户端的知识汇编，将其聚合形成全局知识汇编，并将其返回给客户端。该全局知识汇编包含教导LLM代理使用工具的知识，并且具有隐私保护性，因为它是生成用于描述工具信息的，而非通过生成合成数据的传统方法。这些传统方法往往会泄露私有数据分布信息，并容易遭受攻击（Slokom, de Wolf, 和 Larson [2022](https://arxiv.org/html/2412.08054v1#bib.bib19)）。 （3）客户端接收全局知识汇编，将其作为教师，学习如何在不同查询下使用相应的工具，并通过新型的基于RAG的工具学习与利用（TLU）模块调用工具。

总结来说，本文的主要贡献可以概括如下：

+   •

    我们提出了一种新颖的一轮通信高效、计算高效和隐私保护的联邦学习（FL）算法，称为联邦上下文LLM代理学习（FICAL），据我们所知，这是首个在LLM代理的联邦学习中释放上下文学习能力的工作。

+   •

    在我们的设计中，隐私保护的本地知识汇编是通过新设计的LLM增强型KCG模块生成的，取代了传统联邦学习中的模型参数。FICAL实现了$O(1)$复杂度的通信效率，无论模型大小如何，而传统的联邦学习则会带来线性$O(N)$的开销，且随着模型大小的增加而扩展。

+   •

    我们设计了基于检索增强生成（RAG）的工具学习与利用（TLU）模块，以克服知识汇编学习中的长上下文问题，并提高了$7.6\%$的准确度。

+   •

    我们在不同场景下进行了广泛的实验，结果表明，FICAL相比其他SOTA基准方法，能够实现具有竞争力的结果，并将通信成本降低了$\mathbf{3.33\times 10^{5}}$倍。

## 相关工作

### 单一LLM代理学习

与 LLM 代理学习相关的几项研究已经完成。Chen、Koenig 和 Dilkina [2024](https://arxiv.org/html/2412.08054v1#bib.bib4) 引入了一种新方法，以增强 LLM 在特定领域内的规划能力，该方法使用“梯度下降”来优化 LLM 代理提示中的逐步指令，利用与这些代理交互的聊天历史。Biderman 等人 [2024](https://arxiv.org/html/2412.08054v1#bib.bib2) 旨在通过从低计算试运行中外推记忆行为，预测哪些序列将在大型模型完全训练之前被记住，从而为我们提供等计算推荐，以最大限度地提高这些预测的可靠性。Madaan 等人 [2024](https://arxiv.org/html/2412.08054v1#bib.bib15) 引入了一种通过迭代反馈和改进增强 LLM 初步输出的方法，利用单一 LLM 作为生成器、改进者和反馈提供者。

### 资源高效的 LLM 学习

随着 LLM 能力的不断提升，情境学习已成为自然语言处理中的一种新范式。Wei 等人 [2023](https://arxiv.org/html/2412.08054v1#bib.bib24) 提出了一种在情境输入-标签对上微调语言模型的方法，其中自然语言标签（例如，“正面/负面情感”）被任意符号（例如，“foo/bar”）所替代。这种方法提升了在未见过的情境学习任务中的表现，并且对未指定的提示提供了更强的鲁棒性。Liu 等人 [2022](https://arxiv.org/html/2412.08054v1#bib.bib14) 提出了一个选择情境学习示例的策略，基于查询和示例之间的相似性来制定相应的提示，其中选择的示例可以直观地作为更具信息量的输入。

检索增强生成（RAG）（Lewis 等人 [2020](https://arxiv.org/html/2412.08054v1#bib.bib11)）使得大语言模型（LLMs）能够与外部大型数据集交互，通过检索相关知识来增强其性能。Asai 等人 [2024](https://arxiv.org/html/2412.08054v1#bib.bib1) 提出了一个自我 RAG 算法，该算法利用 LLM 的自我反思帮助其提高性能，从而避免 RAG 过程中不必要的信息。Kim 等人 [2023](https://arxiv.org/html/2412.08054v1#bib.bib10) 提出了一个澄清树（TOC）算法，通过递归构建歧义解析树和自我验证剪枝方法，能够有效处理开放领域中的歧义问题。

### 基于 LLM 的联邦学习（FL）

有许多与大规模语言模型（LLM）联邦学习（FL）相关的研究工作。（Zhang 等人 [2023](https://arxiv.org/html/2412.08054v1#bib.bib27)）探讨了流行的参数高效调优方法（如 LoRA（Hu 等人 [2022](https://arxiv.org/html/2412.08054v1#bib.bib8)）、适配器（Houlsby 等人 [2019](https://arxiv.org/html/2412.08054v1#bib.bib7)）和前缀调优（Li 和 Liang [2021](https://arxiv.org/html/2412.08054v1#bib.bib13)）在不同联邦学习设置下的表现和资源消耗。（Sun 等人 [2024b](https://arxiv.org/html/2412.08054v1#bib.bib22)）通过在FL中添加差分隐私（DP）来保护用户隐私，并通过固定随机初始化的非零矩阵来改进 LoRA（Hu 等人 [2022](https://arxiv.org/html/2412.08054v1#bib.bib8)）方法。（Sun 等人 [2024a](https://arxiv.org/html/2412.08054v1#bib.bib21)）通过训练最优提示并利用无梯度优化方法来减少通信成本。（Peng 等人 [2024](https://arxiv.org/html/2412.08054v1#bib.bib16)）提出了子FM构建模块和子FM对齐模块，以提高FL的性能。

## 动机

![参见说明](img/e9f442ae447ba631dff96d75812cff43.png)

图 1：LLM、通信和计算技术的发展

| 模型 | LLaMA3.1 | GPT3 | Qwen2 | Mistral-L-2 |
| --- | --- | --- | --- | --- |
| 参数 | 405 B | 175 B | 72 B | 123 B |

|

&#124; 转换 &#124;

&#124; 时间（小时） &#124;

| 36 | 15.56 | 6.4 | 10.93 |
| --- | --- | --- | --- |

表格 1：现代通信系统下流行LLM的参数大小和传输时间

现有的LLM通常非常庞大，参数大小超过十亿，并呈现出快速增长的趋势。在图 [1](https://arxiv.org/html/2412.08054v1#Sx3.F1 "Figure 1 ‣ Motivation ‣ Federated In-Context LLM Agent Learning") 中，灰色线条显示了历史上具有重要意义的LLM的参数大小，蓝色线条表示不同代通信技术的发展，橙色线条则代表了计算设备的发展。从图中可以得出结论，尽管这三者的增长速度都有所加快，但参数数量的增长速度已经超过了通信带宽和计算能力的提升。这个发现表明，通信速度和计算能力的进步无法跟上训练LLM日益增长的需求。

表格 [1](https://arxiv.org/html/2412.08054v1#Sx3.T1 "Table 1 ‣ Motivation ‣ Federated In-Context LLM Agent Learning") 显示了在现代通信网络下，一些流行的LLM模型的参数大小和传输时间。我们选择了四个流行的LLM模型，并假设典型的传输速率为100 Mbps来计算传输时间。从表格中可以观察到，传输这些LLM的参数在不同设备之间需要6.4小时到36小时不等。此外，LLM的训练还需要大量的计算能力。

分布式客户端之间高效的模型更新和同步在很大程度上依赖于强大的计算能力和快速的通信。然而，即使是最先进的硬件也面临这些要求的挑战，因为它们可能难以应对支持联邦学习（FL）过程所需的高计算负载和大量数据传输。因此，在联邦设置中部署和高效训练此类大型语言模型（LLM）仍然是一个艰巨的任务。

为了解决这个难题，我们提出了FICAL，其灵感来自于著名的中国书籍《道德经》¹¹1这个格言的来源有很多版本，这里我们采用了由老子（中国历史上著名的哲学家，被认为是道家思想的创始人）所写的一个版本。在这本书中有这样一句话：“授人以鱼，食一日；授人以渔，终身受益。” 这句话强调了一个原则：传授知识和技能比提供物质援助更为重要和持久。通过教育，人们可以学会如何解决问题。这种哲学思想启发我们重新思考多样化LLM代理的联邦上下文学习。在FL中，最常用的数据样本放置方式可能会泄露客户的数据隐私，因为如果他们共享数据样本，可能会暴露敏感信息。

在我们的设计中，客户端不是传输私人数据样本，而是传输一个知识汇编，该汇编包含使用工具的说明。这些汇编通过从本地数据集中提取掌握工具所需的关键信息来生成。所有本地知识汇编的集合形成了一个全球汇编，包含了全面的工具使用知识。这个全球汇编可以作为教师，指导LLM代理如何使用工具，这类似于那句教人如何捕鱼的格言。

## 方法论

### 问题陈述

在本文中，我们考虑一个FL场景，其中总共有$N$个客户端和$M$种工具集，每个工具集包含若干属于相似领域的工具。每个客户端$i$拥有自己的数据集$D_{i}$，该数据集包含工具使用实例。不同客户端的数据集可能包含不同工具的实例，因为在实践中，FL中的不同参与者由于各自行业的限制（如医疗、教育、体育等），可能只能访问某些特定领域的数据。

### 上下文学习的基础

与以前的神经网络不同，LLMs（大型语言模型）可以从给定的自然语言提示上下文中学习知识，而无需更改其参数的权重（Brown 等人 [2020](https://arxiv.org/html/2412.08054v1#bib.bib3)）。这种被称为“上下文学习”的新型学习方法，因其作为LLMs的涌现能力之一而获得了广泛关注（Wei 等人 [2022](https://arxiv.org/html/2412.08054v1#bib.bib25)），使其与传统神经网络架构区分开来。因此，上下文学习方法显著减少了计算能力和GPU内存的使用，提升了这些模型在实际部署中的可访问性和效率。

### 检索增强生成的前提

尽管LLMs具有令人印象深刻的上下文学习能力，但在处理长上下文时仍面临重大挑战。随着上下文长度的增加，这些模型可能难以有效分配注意力。自注意力机制依赖于关注相关的上下文信息，但在长序列中，重要信息可能被不相关的数据稀释或遮蔽，从而导致LLM的注意力分散（Song、Zheng 和 Luo [2024](https://arxiv.org/html/2412.08054v1#bib.bib20)）。RAG（检索增强生成）过程如下：接收到查询后，首先使用检索模型从包含大量数据的向量数据库中提取相关信息，并将其传递给LLMs。最后，LLM根据从向量数据库中提取的知识回答查询。这种方法使得LLMs能够利用大量数据的洞察力，而无需处理与长上下文处理相关的复杂性。

### 传统联邦学习

在传统的联邦学习中，客户端在每轮通信中都将其模型参数传输到中央服务器。在接收到所有参数后，服务器将它们聚合成全局模型，并将其返回给客户端。经过几轮通信后，最终的全局模型训练完成。传统联邦学习的学习目标可以表示为

|  | $\min_{\mathbf{w}_{i}}\mathcal{L}=\frac{1}{N}\sum_{i=1}^{N}\mathbb{E}_{(% \boldsymbol{x}_{i},y_{i})\sim{d}_{i}}\mathcal{L}_{i}(\boldsymbol{x}_{i},y_{i};% \mathbf{w}_{i})$ |  | (1) |
| --- | --- | --- | --- |

其中，$\mathcal{L}_{i}$表示客户端 $i$ 的损失函数，$(\boldsymbol{x}_{i}$ 和 $y_{i}$ 表示客户端 $i$ 的私有数据及其对应答案，$\mathbf{w}_{i}$ 表示客户端 $i$ 的LLM参数，${d}_{i}$ 表示客户端 $i$ 私有数据的分布。

![参考说明](img/82b2b978559fdb85620b136f5de98a77.png)

图 2：FICAL的工作流程

### FICAL

我们方法的详细过程如图[2](https://arxiv.org/html/2412.08054v1#Sx4.F2 "图 2 ‣ 传统FL ‣ 方法论 ‣ 联邦上下文LLM代理学习")所示。FICAL的整个过程可以分为三个部分。

第一部分是知识汇编的生成和上传。在这一部分，每个客户端根据其独特的本地数据集生成自己的本地知识汇编，记作$\zeta_{i}$，用于提取如何使用工具的知识。这个知识提取过程由一个新设计的（知识汇编生成）KCG模块进行，其核心是一个LLM（在本工作中，我们使用DeepSeek-v2（DeepSeek-AI等，[2024](https://arxiv.org/html/2412.08054v1#bib.bib5)）作为生成器），我们称之为“老子”，因为它生成知识汇编，以帮助LLM代理根据老子提出的思想不断改进。

我们精心设计了一个知识生成提示，并将其输入到老子中以帮助其生成。更具体地，图[3](https://arxiv.org/html/2412.08054v1#Sx4.F3 "图 3 ‣ FICAL ‣ 方法论 ‣ 联邦上下文LLM代理学习")展示了知识汇编模板的设计。在我们的模板中，我们放入了由用户指令组成的本地数据集，以及相应的答案，这些答案包括了工具名称和输入参数，用于正确使用该工具的示例。给定这些示例，老子将生成工具的使用方法。这一步涉及精炼知识，从观察到的示例信息中提取与工具特性相关的有用数据。工具相关的知识提取具有重要意义，因为生成的信息不包含用户的私人信息（例如个人隐私数据），但却有助于LLM代理学习如何使用这些工具。生成的使用方法的第一部分是工具的详细描述，表示为$des_{i}$，它可以帮助用户清楚地了解工具的主要功能和用途，从而判断是否满足他们的需求。第二部分表示为$app_{i}$，是工具应使用的应用场景。此部分可以帮助用户理解在特定情况下工具的有效性，确保选择合适的工具来解决具体问题。通过了解最佳使用时机和场合，用户可以更高效地使用工具，避免不必要的尝试。第三部分表示为$pre_{i}$，是使用工具时应注意的预防措施。该部分指导如何高效地使用API，以避免错误请求，从而提高应用性能。同时，它还可以提供常见的错误和处理方法，减少使用工具时出现的问题。第四部分表示为$coo_{i}$，是不同工具的协调。此部分可以帮助工具用户了解如何通过链式调用工具来解决问题。最终的知识汇编可以表示为

|  | $\zeta_{i}=\{des_{i},app_{i},pre_{i},coo_{i}\}$ |  | (2) |
| --- | --- | --- | --- |

![请参阅说明](img/de2c419da2d89cebe5bd7676f547c75f.png)

图 3：知识汇编生成模板

![请参阅说明](img/32c58a58df687191955de6a1c8264675.png)![请参阅说明](img/fd7bdbda55d2ee45d2f4d98b03ba69c9.png)

图 4：不同客户端数量下的结果比较

第二部分是全球知识汇编的生成和卸载。在生成本地知识汇编后，客户端随后将其传输到中央服务器。在接收到不同客户端的知识汇编后，中央服务器将其拼接形成一个全球知识汇编$\zeta_{g}$，可以表示为

|  | $\zeta_{g}=\{\zeta_{1},\zeta_{2},...,\zeta_{n}\}$ |  | (3) |
| --- | --- | --- | --- |

然后将其发送回客户端。这个全球知识集包含了如何使用从不同客户端收集的多种工具的信息。  

第三部分是工具的学习与使用。当客户端收集全球知识集时，它们首先使用嵌入模型将其转换为向量形式，然后存储在向量数据库中。在本工作中，我们使用bge-large-en-v1.5（Xiao et al. [2023](https://arxiv.org/html/2412.08054v1#bib.bib26)）作为嵌入模型。这个处理过的知识集将作为外部教师，帮助LLM代理学习如何使用工具。全球知识集的内容通常非常庞大，包含了所有客户端收集的信息，这给LLM代理在将其直接纳入提示时带来了巨大挑战。因此，提取全球知识集中的必要信息来回答查询至关重要。通过提取相关信息，我们可以避免冗余信息干扰注意力机制的注意力分配，确保回答查询所需的有用信息获得足够的关注。  

我们设计了一种基于RAG的工具学习与利用（TLU）模块，以提升工具学习的性能。当LLM代理收到查询时，首先将查询转换为查询向量，然后使用生成的查询向量在向量数据库中检索最相关的信息，该数据库包含了可能有助于回答查询的工具使用信息，通过计算相似度来实现。提取出的相关信息包括了可以指导LLM代理如何应用与查询相关工具的知识，从而增强其工具学习与利用的能力。  

|  | FICAL | FedLoRA | FedACG | FedAdam | FedProx | FedDecorr | FedYogi |   |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 准确率 | 52.34% | 39.25% | 38.32% | 35.52% | 42.99% | 38.32% | 39.25% |   |

表格 2: 各客户端拥有多个工具集数据时工具使用准确率的比较  

|  | FICAL | FedLoRA | FedACG | FedAdam | FedProx | FedDecorr | FedYogi |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 通信开销（MB） | 0.078 | 26000 | 26000 | 26000 | 26000 | 26000 | 26000 |   |

表格 3: 不同算法的通信开销比较  

## 实验与分析  

在本节中，我们将FICAL与其他最先进的基准算法在不同设置下的性能进行比较，以证明我们算法的有效性。  

### 实验设置  

#### 数据集  

我们使用（Tang 等 [2023](https://arxiv.org/html/2412.08054v1#bib.bib23)）中的数据集生成方法生成数据集。我们从公共 API 中选择了 $M$ 个工具集²²2https://github.com/public-apis/public-apis，每个工具集由一组相似领域的工具组成（例如，关于狗的工具集包含返回狗种类信息、如何喂养狗等的工具）。工具和大语言模型（LLM）代理的交互是在一个模拟环境中进行的，其中一个外部 LLM 作为模拟器来模拟工具返回的结果。模拟器可以获取工具的信息，并将其作为生成响应的依据。LLM 代理与工具的交互产生的痕迹将输入到一个判断 LLM（我们在实验中使用 DeepSeek-v2（DeepSeek-AI 等 [2024](https://arxiv.org/html/2412.08054v1#bib.bib5)））中，以评估 LLM 代理是否正确使用了工具。默认客户端数为 5，默认工具集数为 5。我们使用 4 位 NF4 量化作为默认量化设置，并将 LoRA 参数应用于 LLM，仅在基线中微调 LoRA 参数，以更好地适应资源有限的场景。在 FICAL 上进行额外的无关数据集训练，以提高 LLM 代理遵循输出格式的能力。所有基线都训练 50 个通信轮次，每个客户端在每个通信轮次中进行 5 次本地训练。所有实验均在 LLaMA3-8B 上完成。

#### 基线

为了验证 FICAL 算法的有效性，我们将工具使用的成功率与以下最先进（SOTA）的联邦学习基线进行了比较。

+   •

    FedACG（Kim, Kim, and Han [2024](https://arxiv.org/html/2412.08054v1#bib.bib9)）：FedACG 是一种联邦学习（FL）算法，通过广播带有前瞻梯度的全局模型，增强了收敛性和稳定性。（CVPR 2024）

+   •

    FedDecorr（Shi 等 [2023](https://arxiv.org/html/2412.08054v1#bib.bib18)）：FedDecorr 在本地训练中引入了一项正则化项，促进表示中的无关维度。（ICLR 2023）

+   •

    FedLoRA（Peng 等 [2024](https://arxiv.org/html/2412.08054v1#bib.bib16)）：FedLoRA 是一种联邦学习方法，提供了针对预训练语言模型在联邦环境中调优方法的全面实证研究。（ACL 2023 Findings）

+   •

    FedAdam（Reddi 等 [2021](https://arxiv.org/html/2412.08054v1#bib.bib17)）：FedAdam 是一种联邦学习优化算法，将 Adam 优化器适应于分布式训练。（ICLR 2021）

+   •

    FedYogi（Reddi 等 [2021](https://arxiv.org/html/2412.08054v1#bib.bib17)）：FedYogi 是一种联邦学习优化算法，它将 Yogi 优化器扩展到联邦设置中。它平衡了自适应梯度方法的稳定性与非独立同分布（non-iid）数据分布和不同客户端能力的鲁棒性。（ICLR 2021）

+   •

    FedProx (Li et al. [2020](https://arxiv.org/html/2412.08054v1#bib.bib12))：FedProx 在优化目标中引入了一个邻近项，以稳定训练并提高收敛性。（MLSys 2020）

### 性能评估

#### 通信资源消耗比较

表[3](https://arxiv.org/html/2412.08054v1#Sx4.T3 "Table 3 ‣ FICAL ‣ Methodology ‣ Federated In-Context LLM Agent Learning")展示了各种算法在通信资源消耗方面的比较。从结果来看，我们可以得出结论，FICAL在通信资源消耗方面表现最低。与其他基准相比，它可以节省$\mathbf{3.33\times 10^{5}}$倍的通信资源。这是因为FICAL采用了新颖的知识编纂传输，而不是传统FL中的模型参数共享，后者对像LLM这样拥有大量参数的模型来说是致命的。此外，FICAL仅需要一次通信，而其他基准算法通常需要多轮才能收敛。更重要的是，在传统FL方法中，随着模型参数的增长，通信开销会线性增加，使这些方法在未来对上升的通信成本变得越来越敏感。相比之下，我们的算法表明，通信开销随着模型参数的扩展保持不变，突显了FICAL算法在未来的巨大潜力。

#### 每个客户端拥有一个工具集的数据时的结果

我们考虑了每个客户端拥有一个独特工具集的情况，并测试了LLM代理调用工具的准确性。从图[4](https://arxiv.org/html/2412.08054v1#Sx4.F4 "Figure 4 ‣ FICAL ‣ Methodology ‣ Federated In-Context LLM Agent Learning")中我们可以观察到，在默认设置下，FICAL达到了$57.61\%$的最高准确率，而其他基准的准确率在$26.09\%$到$43.48\%$之间，比我们的算法低$14.13\%$到$31.52\%$。

#### 每个客户端拥有多个工具集的数据时的结果

我们进一步考虑了每个客户端拥有多个工具集数据的情况。更具体地说，我们考虑了每个客户端拥有两个工具集的情况。表[2](https://arxiv.org/html/2412.08054v1#Sx4.T2 "Table 2 ‣ FICAL ‣ Methodology ‣ Federated In-Context LLM Agent Learning")中的结果显示，与其他基准相比，FICAL的准确率提高了$13.09\%,14.02\%,16.82\%,9.35\%,14.02\%,13.09\%$。从这些结果可以得出结论，FICAL能够在不同的异质工具数据拥有情况下表现良好，这证明了我们算法的鲁棒性。

#### 在不同量化水平下的结果

我们在不同量化级别的LLM上进行实验，以验证FICAL的有效性。更具体地说，我们使用数据格式NF4和NF8对不同算法在4位和8位量化下的性能进行测试。从图[4](https://arxiv.org/html/2412.08054v1#Sx4.F4 "Figure 4 ‣ FICAL ‣ Methodology ‣ Federated In-Context LLM Agent Learning")中可以得出结论，当使用4位量化时，FICAL的准确率为$57.61\%$，当客户端数量为5和8时，其准确率分别为$44.60\%$。其他基准的准确率从$25\%$到$43.47\%$不等，以及从$24.49\%$到$44.60\%$。当使用8位量化时，FICAL的准确率为$71.74\%$和$53.24\%$，而其他基准的平均准确率为$60.32\%$和$48.80\%$。我们发现，8位量化下的整体表现优于4位量化，这表明尽管量化可以节省内存，但它可能由于精度丧失导致性能下降，进而可能导致前向传播中的不准确性，甚至是梯度消失/爆炸。

#### 客户端数量的影响

为了评估不同算法在不同规模下的性能，我们在参与FL的不同数量客户端下进行测试。我们分别在5个客户端和8个客户端的情况下进行实验。结果表明，FICAL在不同规模下都能实现具有竞争力的准确率。

|  | FICAL（无RAG） | FICAL（有RAG） |
| --- | --- | --- |
| 准确率 | 50% | 57.6% |

表格4：有无RAG时准确率的比较

#### 有无RAG的性能比较

表格[4](https://arxiv.org/html/2412.08054v1#Sx5.T4 "Table 4 ‣ Impact of Number of clients ‣ Performance Evaluation ‣ Experiments and Analyses ‣ Federated In-Context LLM Agent Learning")展示了FICAL在使用RAG增强工具学习模块时的准确率，以及在没有RAG处理时的表现，后者通过直接将全球知识库的内容融入提示中，指导LLM代理使用工具。从结果中可以看出，使用RAG的FICAL准确率提高了$7.6\%$，这证明了TLU模块设计的有效性。

## 结论

在本文中，我们提出了一种新颖的隐私保护联邦上下文LLM代理学习（FICAL），这是我们所知的首个在LLM代理的联邦学习中释放上下文学习能力的研究工作。我们设计了一个LLM增强的KCG模块，用于在客户端生成隐私保护的知识汇编并将其发送到中央服务器，进而聚合成全球知识汇编。此外，我们还设计了一个基于RAG的TLU模块，使得LLM代理在接收到查询时能够学习并使用相应的工具。FICAL将先前联邦学习方法中相对于模型规模的通信消耗从$O(N)$减少到了$O(1)$，展示了其在未来LLM联邦学习研究中的巨大潜力。我们进行了广泛的实验，结果表明，FICAL具有竞争力的性能，通信成本减少了$\mathbf{3.33\times 10^{5}}$倍。

## 参考文献

+   Asai等人（2024）Asai, A.; Wu, Z.; Wang, Y.; Sil, A.; 和 Hajishirzi, H. 2024. Self-RAG: 通过自我反思学习检索、生成和批评. 在 *第十二届国际学习表示会议*.

+   Biderman等人（2024）Biderman, S.; Prashanth, U.; Sutawika, L.; Schoelkopf, H.; Anthony, Q.; Purohit, S.; 和 Raff, E. 2024. 大型语言模型中的突现和可预测记忆化. *神经信息处理系统进展*, 36.

+   Brown等人（2020）Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; 等人. 2020. 语言模型是少样本学习者. *神经信息处理系统进展*, 33: 1877–1901.

+   Chen, Koenig, 和 Dilkina（2024）Chen, W.; Koenig, S.; 和 Dilkina, B. 2024. RePrompt: 通过自动提示工程进行大型语言模型代理的规划. *arXiv预印本 arXiv:2406.11132*.

+   DeepSeek-AI等人（2024）DeepSeek-AI; Liu, A.; Feng, B.; Wang, B.; Wang, B.; Liu, B.; Zhao, C.; Dengr, C.; 和等人, C. R. 2024. DeepSeek-V2: 一个强大、经济且高效的专家混合语言模型. arXiv:2405.04434.

+   Dubey等人（2024）Dubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.; Letman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.; 等人. 2024. Llama 3 模型群体. *arXiv预印本 arXiv:2407.21783*.

+   Houlsby等人（2019）Houlsby, N.; Giurgiu, A.; Jastrzebski, S.; Morrone, B.; De Laroussilhe, Q.; Gesmundo, A.; Attariyan, M.; 和 Gelly, S. 2019. 用于自然语言处理的参数高效迁移学习. 在 *国际机器学习会议*, 2790–2799. PMLR.

+   Hu等人（2022）Hu, E. J.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; Chen, W.; 等人. 2022. LoRA: 大型语言模型的低秩适应. 在 *国际学习表示会议*.

+   Kim, Kim, 和 Han（2024）Kim, G.; Kim, J.; 和 Han, B. 2024. 具有加速客户端梯度的通信高效联邦学习. 在 *IEEE/CVF计算机视觉与模式识别会议论文集*, 12385–12394.

+   Kim 等人（2023）Kim, G.; Kim, S.; Jeon, B.; Park, J.; 和 Kang, J. 2023. 澄清树：用检索增强的大型语言模型回答模糊问题。*arXiv 预印本 arXiv:2310.14696*。

+   Lewis 等人（2020）Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; Küttler, H.; Lewis, M.; Yih, W.-t.; Rocktäschel, T.; 等人. 2020. 用于知识密集型NLP任务的检索增强生成。*神经信息处理系统进展*，33：9459–9474。

+   Li 等人（2020）Li, T.; Sahu, A. K.; Zaheer, M.; Sanjabi, M.; Talwalkar, A.; 和 Smith, V. 2020. 异质网络中的联邦优化。*机器学习与系统会议论文集*，2：429–450。

+   Li 和 Liang（2021）Li, X. L.; 和 Liang, P. 2021. Prefix-Tuning：为生成优化连续提示。在 *第59届计算语言学协会年会和第11届国际自然语言处理联合会议（第1卷：长篇论文）*，4582–4597。

+   Liu 等人（2022）Liu, J.; Shen, D.; Zhang, Y.; Dolan, B.; Carin, L.; 和 Chen, W. 2022. 什么样的上下文示例适合 GPT-3？在 Agirre, E.; Apidianaki, M.; 和 Vulić, I.（编），*深度学习内外（DeeLIO 2022）：深度学习架构的知识提取与集成第3次研讨会*，100–114。爱尔兰都柏林和在线：计算语言学协会。

+   Madaan 等人（2024）Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao, L.; Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.; Yang, Y.; 等人. 2024. 自我精炼：带有自反馈的迭代精炼。*神经信息处理系统进展*，36。

+   Peng 等人（2024）Peng, Z.; Fan, X.; Chen, Y.; Wang, Z.; Pan, S.; Wen, C.; Zhang, R.; 和 Wang, C. 2024. FedPFT：基础模型的联邦代理微调。*arXiv 预印本 arXiv:2404.11536*。

+   Reddi 等人（2021）Reddi, S. J.; Charles, Z.; Zaheer, M.; Garrett, Z.; Rush, K.; Konečnỳ, J.; Kumar, S.; 和 McMahan, H. B. 2021. 自适应联邦优化。在 *国际学习表示会议*。

+   Shi 等人（2023）Shi, Y.; Liang, J.; Zhang, W.; Tan, V.; 和 Bai, S. 2023. 朝着理解和缓解异质联邦学习中的维度崩溃迈进。在 *第十一届国际学习表示会议*。

+   Slokom, de Wolf, 和 Larson（2022）Slokom, M.; de Wolf, P.-P.; 和 Larson, M. 2022. 当机器学习模型泄漏时：对合成训练数据的探索。在 *国际统计数据库隐私会议*，283–296。Springer。

+   Song, Zheng, 和 Luo（2024）Song, M.; Zheng, M.; 和 Luo, X. 2024. Counting-stars：一种简单、高效且合理的策略，用于评估长上下文的大型语言模型。*arXiv 预印本 arXiv:2403.11802*。

+   Sun 等人（2024a）Sun, J.; Xu, Z.; Yin, H.; Yang, D.; Xu, D.; Liu, Y.; Du, Z.; Chen, Y.; 和 Roth, H. R. 2024a. 《FedBPT：大语言模型的高效联邦黑盒提示调优》。在 *第41届国际机器学习会议*。

+   Sun 等人（2024b）Sun, Y.; Li, Z.; Li, Y.; 和 Ding, B. 2024b. 《在隐私保护联邦学习中改进 LoRA》。*arXiv 预印本 arXiv:2403.12313*。

+   Tang 等人（2023）Tang, Q.; Deng, Z.; Lin, H.; Han, X.; Liang, Q.; Cao, B.; 和 Sun, L. 2023. 《Toolalpaca：用于语言模型的通用工具学习，基于3000个模拟案例》. *arXiv 预印本 arXiv:2306.05301*。

+   Wei 等人（2023）Wei, J.; Hou, L.; Lampinen, A.; Chen, X.; Huang, D.; Tay, Y.; Chen, X.; Lu, Y.; Zhou, D.; Ma, T.; 和 Le, Q. 2023. 《符号调优提升语言模型的上下文学习》。在 Bouamor, H.; Pino, J.; 和 Bali, K. 编，*2023年自然语言处理经验方法会议论文集*，968–979\. 新加坡：计算语言学协会。

+   Wei 等人（2022）Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud, S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; 等人 2022. 《大语言模型的涌现能力》. *机器学习研究学报*。

+   Xiao 等人（2023）Xiao, S.; Liu, Z.; Zhang, P.; 和 Muennighoff, N. 2023. 《C-Pack：推进通用中文嵌入的打包资源》。arXiv:2309.07597。

+   Zhang 等人（2023）Zhang, Z.; Yang, Y.; Dai, Y.; Wang, Q.; Yu, Y.; Qu, L.; 和 Xu, Z. 2023. 《Fedpetuning：当联邦学习遇上预训练语言模型的参数高效调优方法》。在 *2023 年计算语言学协会年会*，9963–9977\. 计算语言学协会（ACL）。

+   Zhao 等人（2018）Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; 和 Chandra, V. 2018. 《具有非独立同分布数据的联邦学习》. *arXiv 预印本 arXiv:1806.00582*。

## AAAI 可重复性检查清单

除非另有说明，请在每个问题的答案中选择“是”，如果相关信息在论文本身或技术附录中有明确的参考。如果您希望进一步解释某个答案，请在技术附录末尾的“可重复性检查清单”部分中进行说明。

这篇论文：

+   •

    包含了引入的人工智能方法的概念大纲和/或伪代码描述。（是）

+   •

    清楚地区分了意见、假设和猜测与客观事实和结果。（是）

+   •

    为不太熟悉的读者提供了标注清晰的教学参考，以帮助其获取复制论文所需的背景知识。（是）

这篇论文是否有理论贡献？（是）

如果是，请完成以下列表。

+   •

    所有假设和限制条件都明确且正式地表述。（是）

+   •

    所有新颖的主张都正式表述（例如，在定理陈述中）。（是）

+   •

    所有新颖的主张都包含了证明。（是）

+   •

    对于复杂和/或新颖的结果，给出了证明草图或直觉推理。（是）

+   •

    对使用的理论工具给出了适当的引用。（是）

+   •

    所有理论声明都通过实验证明其有效性。（是）

+   •

    所有用于消除或反驳声明的实验代码均已包含。（是）

本文是否依赖于一个或多个数据集？（是）

如果是，请完成下面的列表。

+   •

    给出了为什么在选定数据集上进行实验的动机。（是）

+   •

    本文介绍的所有新颖数据集都包括在数据附录中。（否）

+   •

    本文介绍的所有新颖数据集将在论文发表时公开，并附有允许免费用于研究的许可证。（是）

+   •

    所有从现有文献中获取的数据集（可能包括作者自己先前发表的工作）都附有适当的引用。（是）

+   •

    所有从现有文献中获取的数据集（可能包括作者自己先前发表的工作）都是公开可用的。（是）

+   •

    所有非公开的数据集都有详细描述，并解释为什么公开的替代数据集在科学上不具备充分的满足性。（无）

本文是否包含计算实验？（是）

如果是，请完成下面的列表。

+   •

    所有预处理数据所需的代码都包括在附录中。（否）

+   •

    所有进行实验和分析所需的源代码都包括在代码附录中。（否）

+   •

    所有进行实验和分析所需的源代码将在论文发表时公开，并附有允许免费用于研究的许可证。（是）

+   •

    所有实现新方法的源代码都包含详细的实现注释，并引用了每个步骤来源的论文。（是）

+   •

    如果算法依赖于随机性，则会描述设置种子的方法，确保结果可以复现。（是）

+   •

    本文明确指出了用于运行实验的计算基础设施（硬件和软件），包括GPU/CPU型号、内存大小、操作系统、相关软件库和框架的名称和版本。（是）

+   •

    本文正式描述了所使用的评估指标，并解释了选择这些指标的动机。（是）

+   •

    本文说明了用于计算每个报告结果的算法运行次数。（是）

+   •

    实验分析超越了对性能的单维度总结（例如，平均值；中位数），包括变异性、置信度或其他分布性信息的度量。（是）

+   •

    对任何性能改进或下降的意义使用适当的统计检验（例如，Wilcoxon符号秩检验）进行评判。（是）

+   •

    本文列出了实验中每个模型/算法所使用的最终（超）参数。（是）

+   •

    本文阐述了在论文开发过程中每个（超）参数尝试的值的数量和范围，以及用于选择最终参数设置的标准。（是的）
