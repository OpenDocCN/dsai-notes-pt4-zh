- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:47:52'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:47:52
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.17833](https://ar5iv.labs.arxiv.org/html/2404.17833)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.17833](https://ar5iv.labs.arxiv.org/html/2404.17833)
- en: 'Zhenlan Ji, Daoyuan Wu, Pingchuan Ma, Zongjie Li, Shuai Wang¹¹footnotemark:
    1'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 'Zhenlan Ji, Daoyuan Wu, Pingchuan Ma, Zongjie Li, Shuai Wang¹¹footnotemark:
    1'
- en: The Hong Kong University of Science and Technology
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: The Hong Kong University of Science and Technology
- en: Hong Kong SAR, China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Hong Kong SAR, China
- en: '{zjiae, daoyuan, pmaab, zligo, shuaiw}@cse.ust.hk Corresponding authors.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{zjiae, daoyuan, pmaab, zligo, shuaiw}@cse.ust.hk 对应作者。'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Agents based on large language models (LLMs) have demonstrated effectiveness
    in solving a wide range of tasks by integrating LLMs with key modules such as
    planning, memory, and tool usage. Increasingly, customers are adopting LLM agents
    across a variety of commercial applications critical to reliability, including
    support for mental well-being, chemical synthesis, and software development. Nevertheless,
    our observations and daily use of LLM agents indicate that they are prone to making
    erroneous plans, especially when the tasks are complex and require long-term planning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大型语言模型（LLMs）的代理已证明在通过将LLM与规划、记忆和工具使用等关键模块集成来解决各种任务方面的有效性。越来越多的客户在各种关键可靠性的商业应用中采用LLM代理，包括心理健康支持、化学合成和软件开发。然而，我们的观察和对LLM代理的日常使用表明，它们容易制定错误的计划，尤其是在任务复杂且需要长期规划时。
- en: 'In this paper, we propose PDoctor, a novel and automated approach to testing
    LLM agents and understanding their erroneous planning. As the first work in this
    direction, we formulate the detection of erroneous planning as a constraint satisfiability
    problem: an LLM agent’s plan is considered erroneous if its execution violates
    the constraints derived from the user inputs. To this end, PDoctor first defines
    a domain-specific language (DSL) for user queries and synthesizes varying inputs
    with the assistance of the Z3 constraint solver. These synthesized inputs are
    natural language paragraphs that specify the requirements for completing a series
    of tasks. Then, PDoctor derives constraints from these requirements to form a
    testing oracle. PDoctor features several design considerations, such as mock tool
    and input mutation, to enhance testing effectiveness. Its synthesized inputs can
    also incorporate advanced features like dynamic constraint update to better test
    the LLM agent’s planning ability. We evaluate PDoctor with three mainstream agent
    frameworks and two powerful LLMs (GPT-3.5 and GPT-4). The results show that PDoctor can
    effectively detect diverse errors in agent planning, and provide insights and
    error characteristics that are valuable to both agent developers (for improving
    LLM agents) and users (for using contemporary agents). We conclude by discussing
    potential alternative designs and directions to extend PDoctor.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了PDoctor，一种新颖且自动化的LLM代理测试方法，用于理解其错误的规划。作为该方向的首个工作，我们将错误规划的检测形式化为一个约束满足问题：如果LLM代理的执行违反了从用户输入中得出的约束，则该计划被视为错误。为此，PDoctor首先定义了一种用于用户查询的领域特定语言（DSL），并借助Z3约束求解器合成不同的输入。这些合成的输入是自然语言段落，指定了完成一系列任务的要求。然后，PDoctor从这些要求中推导出约束，以形成测试oracle。PDoctor具有多个设计考虑因素，如模拟工具和输入突变，以提高测试效果。其合成的输入还可以包含动态约束更新等高级特性，以更好地测试LLM代理的规划能力。我们在三个主流代理框架和两个强大的LLM（GPT-3.5和GPT-4）上评估了PDoctor。结果表明，PDoctor可以有效检测代理规划中的各种错误，并提供对代理开发者（用于改进LLM代理）和用户（用于使用当代代理）都很有价值的见解和错误特征。我们通过讨论潜在的替代设计和扩展PDoctor的方向来总结。
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 Introduction
- en: Large language models (LLMs) have become extremely popular due to their remarkable
    performance across a wide range of tasks [[22](#bib.bib22), [12](#bib.bib12),
    [26](#bib.bib26), [44](#bib.bib44), [21](#bib.bib21), [55](#bib.bib55), [47](#bib.bib47)],
    demonstrating an ability to understand, reason, and act in ways akin to human
    cognition and reasoning. With their extensive parameters and training data, these
    models have shown proficiency in complex pattern recognition in natural language,
    leading to advancements in logical reasoning [[16](#bib.bib16), [56](#bib.bib56)],
    vulnerability detection [[47](#bib.bib47), [46](#bib.bib46)], robot planning [[11](#bib.bib11),
    [29](#bib.bib29)], and causal inference [[31](#bib.bib31), [24](#bib.bib24)].
    This has fueled the development of LLM agents [[59](#bib.bib59), [43](#bib.bib43),
    [14](#bib.bib14), [40](#bib.bib40)], which are designed to interact with the external
    world and make decisions to achieve complex objectives, leveraging LLMs’ cognitive
    capabilities for tasks that require planning, memory, and execution of a sequence
    of actions. These agents, integrating key modules alongside LLMs, excel in processing
    complex user queries, learning from past interactions, and adapting to new tasks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）由于其在广泛任务中的卓越表现而变得极为流行[[22](#bib.bib22), [12](#bib.bib12), [26](#bib.bib26),
    [44](#bib.bib44), [21](#bib.bib21), [55](#bib.bib55), [47](#bib.bib47)]，展示了类似于人类认知和推理的理解、推理和行动能力。凭借其广泛的参数和训练数据，这些模型在自然语言中的复杂模式识别方面表现出色，推动了逻辑推理[[16](#bib.bib16),
    [56](#bib.bib56)]、漏洞检测[[47](#bib.bib47), [46](#bib.bib46)]、机器人规划[[11](#bib.bib11),
    [29](#bib.bib29)]和因果推断[[31](#bib.bib31), [24](#bib.bib24)]的进展。这促进了LLM代理的发展[[59](#bib.bib59),
    [43](#bib.bib43), [14](#bib.bib14), [40](#bib.bib40)]，这些代理旨在与外部世界互动，并做出决策以实现复杂目标，利用LLM的认知能力来执行需要规划、记忆和行动序列的任务。这些代理通过整合关键模块与LLM，擅长处理复杂的用户查询、从过去的互动中学习以及适应新任务。
- en: To date, the industry has been increasingly commercializing LLM agents in various
    highly profitable and even mission-critical applications [[59](#bib.bib59), [5](#bib.bib5),
    [7](#bib.bib7), [9](#bib.bib9), [8](#bib.bib8), [2](#bib.bib2), [33](#bib.bib33)],
    such as healthcare, personal assistance, and financial services. However, despite
    their great potential and overall enthusiasm, LLM agents often struggle with erroneous
    planning, leading to significant consequences. For example, an LLM agent used
    to manage a chemical synthesis process may fail to produce the desired chemical
    compound if it makes an erroneous plan, and the involved, possibly expensive,
    chemical reagents are already consumed during the process. This challenge, highlighted
    by our observations and experiences, underscores the need for improvements in
    their design and operation. Errors in planning, particularly in complex, long-term
    tasks, can result in the misuse of resources or failure to achieve intended outcomes,
    underscoring the importance of developing more reliable and effective LLM agents.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，行业在各种高盈利甚至任务关键型应用[[59](#bib.bib59), [5](#bib.bib5), [7](#bib.bib7), [9](#bib.bib9),
    [8](#bib.bib8), [2](#bib.bib2), [33](#bib.bib33)]中逐渐商业化LLM代理，例如医疗保健、个人助理和金融服务。然而，尽管它们具有巨大的潜力和整体热情，LLM代理在规划错误时往往会面临重大后果。例如，一个用于管理化学合成过程的LLM代理如果制定了错误的计划，可能会无法生产所需的化学化合物，而在过程中可能已经消耗了昂贵的化学试剂。我们的观察和经验突显了这一挑战，强调了改进其设计和操作的必要性。特别是在复杂的长期任务中，规划错误可能导致资源的误用或未能实现预期结果，凸显了开发更可靠、更有效的LLM代理的重要性。
- en: 'In this paper, we propose PDoctor, a novel framework for testing and understanding
    erroneous planning in LLM agents. Our approach is fully automated and can be used
    to detect erroneous planning in LLM agents using different core LLMs and following
    different paradigms (see introduction in Sec. [2](#S2 "2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")).
    As the first work in this direction, PDoctor  formulates the occurrence of “erroneous
    planning” as a constraint satisfiability problem: an LLM agent’s plan is erroneous
    if its execution violates the constraints derived from the user inputs. The constraints
    can be rigorously checked with moderate cost, thus providing a reliable way to
    detect erroneous planning.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了 PDoctor，一个用于测试和理解 LLM 代理中错误规划的全新框架。我们的方法是完全自动化的，可以用于检测使用不同核心 LLM 和遵循不同范式的
    LLM 代理中的错误规划（见第 [2](#S2 "2 Preliminary ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs") 节介绍）。作为该方向的首项工作，PDoctor 将“错误规划”的发生形式化为一个约束满足性问题：如果
    LLM 代理的计划执行违反了从用户输入中推导出的约束，则该计划是错误的。这些约束可以以适中的成本进行严格检查，从而提供了一种可靠的检测错误规划的方法。
- en: PDoctor defines a domain specific language (DSL) that captures the semantics
    of user queries and features a synthesis procedure (with the assistance of Z3)
    that can generate diverse user requests as the test inputs to the LLM agent. We
    provide configurable parameters to control the diversity and complexity of the
    user queries and offer a mutation procedure to further transform each generated
    user query. Each user query denotes a paragraph that outlines the requirements
    for conducting a series of tasks. PDoctor accordingly derives constraints from
    these requirements and checks if the LLM agent’s plan aligns with the satisfiability
    of these constraints; misalignment flags erroneous planning. We provide a set
    of design considerations and optimizations (e.g., mock tools employed by the agent)
    to deliver effective testing, and also augment the synthesized inputs with advanced
    features like dynamic constraint update to test the LLM agent’s planning capability.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: PDoctor 定义了一种领域特定语言（DSL），它捕捉了用户查询的语义，并具有一个合成过程（在 Z3 的协助下），可以生成多样化的用户请求作为 LLM
    代理的测试输入。我们提供了可配置的参数来控制用户查询的多样性和复杂性，并提供了一个变异过程以进一步转换每个生成的用户查询。每个用户查询表示一个段落，概述了进行一系列任务的要求。PDoctor
    相应地从这些要求中推导约束，并检查 LLM 代理的计划是否与这些约束的可满足性一致；不一致则标志着计划错误。我们提供了一组设计考虑和优化（例如，代理使用的模拟工具），以提供有效的测试，并通过动态约束更新等高级功能增强合成的输入，以测试
    LLM 代理的规划能力。
- en: 'We evaluate PDoctor on three mainstream LLM agent frameworks, ReAct [[59](#bib.bib59)],
    OpenAI Tools (OT) [[5](#bib.bib5)], and OpenAI Assistant (OA) [[7](#bib.bib7)].
    These LLM agents represent different paradigms and are widely used in various
    applications. We incorporate these frameworks with two widely-used LLM models,
    GPT-3.5 and GPT-4 [[10](#bib.bib10)]. PDoctor can effectively detect thousands
    of erroneous plans across all these settings. We configure PDoctor to depict the
    planning capability “upper bound” of different LLM agents and also summarize the
    detected erroneous plans. These results can provide insights into the common pitfalls
    of LLM agents and offer guidance for developers and users in daily practice. We
    also discuss the extension of PDoctor and the potential future work to repair
    the detected erroneous plans. In summary, the contributions of this paper are
    as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在三个主流的 LLM 代理框架上评估了 PDoctor，分别是 ReAct [[59](#bib.bib59)]、OpenAI 工具（OT）[[5](#bib.bib5)]
    和 OpenAI 助手（OA）[[7](#bib.bib7)]。这些 LLM 代理代表了不同的范式，并广泛应用于各种场景。我们将这些框架与两个广泛使用的 LLM
    模型，GPT-3.5 和 GPT-4 [[10](#bib.bib10)] 结合使用。PDoctor 可以有效地检测所有这些设置中的数千个错误计划。我们配置
    PDoctor 以描绘不同 LLM 代理的规划能力“上限”，并总结检测到的错误计划。这些结果可以提供对 LLM 代理常见陷阱的见解，并为开发者和用户在日常实践中提供指导。我们还讨论了
    PDoctor 的扩展以及未来修复检测到的错误计划的潜在工作。总之，本文的贡献如下：
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We pioneer the effort to test and understand erroneous planning in LLM agents,
    given their increasing commercialization in reliability-sensitive fields and the
    potential severe consequences of erroneous planning.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 鉴于 LLM 代理在对可靠性敏感的领域中的日益商业化以及错误规划可能带来的严重后果，我们首创了测试和理解 LLM 代理中错误规划的努力。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We formulate the problem of detecting erroneous planning as a constraint satisfiability
    problem and present a fully automated framework, PDoctor, that employs input synthesis
    and constraint checking to detect erroneous planning.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将检测错误规划的问题形式化为约束满足问题，并提出了一个完全自动化的框架 PDoctor，该框架利用输入合成和约束检查来检测错误规划。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate PDoctor on mainstream LLM agents using different paradigms and show
    that our approach can effectively detect thousands of erroneous planning with
    moderate cost. We also summarize insights from different aspects to benefit developers
    and users.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在不同范式的主流 LLM 代理上评估了 PDoctor，并展示了我们的方法可以以适中的成本有效地检测到数千个错误规划。我们还总结了来自不同方面的见解，以便于开发人员和用户。
- en: Tool Availability. We have made PDoctor available at [https://anonymous.4open.science/r/PDoctor-E872](https://anonymous.4open.science/r/PDoctor-E872)
    for review purposes. We will continue to maintain the tool and add more documentation
    to assist users in utilizing it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 工具可用性。我们已将 PDoctor 提供于 [https://anonymous.4open.science/r/PDoctor-E872](https://anonymous.4open.science/r/PDoctor-E872)
    供审阅使用。我们将继续维护该工具，并添加更多文档以帮助用户使用它。
- en: 2 Preliminary
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 初步情况
- en: 2.1 Planning Problem
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 规划问题
- en: 'Planning is a fundamental problem-solving task that involves generating a sequence
    of actions to achieve a goal [[34](#bib.bib34), [18](#bib.bib18)]. Extensive efforts
    have been devoted to this area, achieving significant progress in various domains,
    such as robotics [[36](#bib.bib36), [13](#bib.bib13), [23](#bib.bib23)] and autonomous
    vehicles [[15](#bib.bib15), [32](#bib.bib32)]. Formally, the planning problem
    can be defined as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 规划是一个基础的问题解决任务，它涉及生成一系列动作以实现目标 [[34](#bib.bib34), [18](#bib.bib18)]。在这个领域已付出了大量努力，并在各个领域取得了显著进展，如机器人技术
    [[36](#bib.bib36), [13](#bib.bib13), [23](#bib.bib23)] 和自动驾驶车辆 [[15](#bib.bib15),
    [32](#bib.bib32)]。形式上，规划问题可以定义如下：
- en: Definition 1  (Planning Problem).
  id: totrans-29
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义 1（规划问题）。
- en: Given a set of states $\bm{S}$.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组状态 $\bm{S}$。
- en: In the context of LLM agents, the user query can be viewed as a planning problem
    $\mathcal{P}=\langle\bm{S},\bm{A},f,s_{0},s_{g}\rangle$ are satisfied.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 代理的背景下，用户查询可以被视为一个规划问题 $\mathcal{P}=\langle\bm{S},\bm{A},f,s_{0},s_{g}\rangle$
    是否满足。
- en: 2.2 An Example of LLM Agents
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 LLM 代理的示例
- en: '![Refer to caption](img/2338b3108bb56f699662c3e3b705de58.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/2338b3108bb56f699662c3e3b705de58.png)'
- en: 'Figure 1: An example illustrating an LLM agent working on a complex user query.
    Green and blue represent the agent’s actions and the execution results of invoked
    tools, respectively.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：一个示例，展示了一个 LLM 代理处理复杂用户查询的过程。绿色和蓝色分别表示代理的动作和调用工具的执行结果。
- en: Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")
    presents a typical example of an LLM agent working on a sample user query (Fig. [1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(a)). The agent
    first understands the requirements implied by the user query, then plans (reasons)
    to select the appropriate tools (Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 An Example of
    LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM
    Agents through Synthesized User Inputs")(b)) to invoke, and finally acts to execute
    each selected tool and collect its response (Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 An
    Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")(c)). In particular, after receiving
    the output from each invoked tool, the agent repeats the above process until the
    user query is fully answered. This series of interactions between the agent and
    the environment, as listed in Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 An Example of LLM
    Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs")(c), collectively constitutes a problem-solving
    procedure and then determines the final response (omitted here) to the user query.
    LLM agents benefit from powerful LLMs that can behave in a human-like manner to
    understand, reason, and act simultaneously, and the synergy of these three capabilities.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](#S2.F1 "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")展示了一个LLM代理处理示例用户查询的典型例子（图[1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(a)）。代理首先理解用户查询中隐含的需求，然后规划（推理）以选择适当的工具（图[1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(b)），最后执行每个选择的工具并收集其响应（图[1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(c)）。特别是，在接收到每个调用工具的输出后，代理重复上述过程，直到用户查询得到完全回答。这一系列代理与环境之间的互动，如图[1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(c)所示，共同构成了一个问题解决过程，然后确定最终回应（此处省略）用户查询。LLM代理得益于强大的LLM，这些LLM能够以类似人类的方式同时理解、推理和行动，以及这三种能力的协同作用。
- en: Nevertheless, given the susceptibility of LLMs that has been exposed in prior
    research [[38](#bib.bib38), [53](#bib.bib53), [58](#bib.bib58), [27](#bib.bib27)],
    it is not surprising that LLM agents are substantially prone to errors and failures.
    Intuitively, the agent’s action chain can be viewed as an “error amplifier,” where
    a small mistake in the early stage of the action chain could be continuously amplified
    and propagated in each subsequent step, leading to catastrophic failures in the
    end. This character further exacerbates the difficulty of providing a correct
    and stable response to the user query. Moreover, the interaction between the LLM
    agent and the environment is often complex and dynamic, distinct from the static
    and isolated settings in which LLMs’s abilities have been tested [[49](#bib.bib49),
    [26](#bib.bib26), [22](#bib.bib22), [46](#bib.bib46)].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，鉴于之前研究中暴露出的LLM的易感性[[38](#bib.bib38), [53](#bib.bib53), [58](#bib.bib58),
    [27](#bib.bib27)]，LLM代理容易出错和失败并不令人惊讶。直观地说，代理的行动链可以被视为“错误放大器”，早期阶段的小错误可能会在后续步骤中不断放大和传播，最终导致灾难性的失败。这一特点进一步加剧了提供正确和稳定回应的难度。此外，LLM代理与环境之间的互动通常复杂且动态，与LLM能力测试中的静态和孤立环境不同[[49](#bib.bib49),
    [26](#bib.bib26), [22](#bib.bib22), [46](#bib.bib46)]。
- en: In general, previous studies that endeavor to evaluate LLMs are often limited
    to a straightforward linear flow following a “text in and text out” paradigm.
    In this paradigm, problems are presented in their entirety, and LLMs are expected
    to generate a textual response based on the given problem. In contrast, LLM agent
    testing necessitates a focus on the interaction and interplay between the LLM
    and the environment, where the problems are dynamic and the LLM agent is required
    to adjust its plan in response to the environment’s feedback. Here, the feedback
    refers to the results of the invoked tools, as shown in the blue text of Fig. [1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(c). In line
    with these dynamic and complex settings, we design PDoctor to dynamically update
    the constraint sets (see details in Sec. [4.4](#S4.SS4 "4.4 Extended Testing Framework
    ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs")). This underscores the importance of tool design, in
    addition to the textual problems, during test case generation. Consequently, it
    is crucial to develop a systematic approach tailored to the unique characteristics
    of LLM agents to test and assess their performance in a thorough manner.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，以前的研究在评估大型语言模型（LLMs）时，往往局限于简单的线性流程，即“输入文本和输出文本”范式。在这一范式中，问题被完整地呈现，LLMs
    需要根据给定的问题生成文本响应。与此不同，LLM 代理的测试需要关注 LLM 与环境之间的互动与相互作用，其中问题是动态的，LLM 代理需要根据环境的反馈调整其计划。这里的反馈指的是调用工具的结果，如图
    [1](#S2.F1 "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")(c)
    中的蓝色文本所示。根据这些动态和复杂的设置，我们设计了 PDoctor，以动态更新约束集（详见第 [4.4](#S4.SS4 "4.4 Extended Testing
    Framework ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs")节）。这强调了在测试用例生成过程中，除了文本问题之外，工具设计的重要性。因此，开发一种适应
    LLM 代理独特特性的系统化方法，以全面测试和评估其性能是至关重要的。
- en: 2.3 Architecture of LLM Agents
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 LLM 代理的架构
- en: With a typical example of LLM agents illustrated in Sec.[2.2](#S2.SS2 "2.2 An
    Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs"), we now delve into the architecture
    of an LLM agent to better understand the mechanisms behind the agent’s operation,
    which is valuable for designing the testing framework.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 [2.2](#S2.SS2 "2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and
    Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")节中，我们通过一个典型的
    LLM 代理示例，现在深入探讨 LLM 代理的架构，以更好地理解代理操作背后的机制，这对于设计测试框架是非常有价值的。
- en: '![Refer to caption](img/e38da86ae58301eabbcb2300556dffe9.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e38da86ae58301eabbcb2300556dffe9.png)'
- en: 'Figure 2: A typical architecture of LLM agents, according to [[54](#bib.bib54)].'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：根据 [[54](#bib.bib54)] 的典型 LLM 代理架构。
- en: 'Modules. Fig. [2](#S2.F2 "Figure 2 ‣ 2.3 Architecture of LLM Agents ‣ 2 Preliminary
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs") presents a typical architecture of an LLM agent. This agent consists
    of three main components: (1) an understand module, (2) a plan module, and (3)
    an act (tool usage) module. The understand module is tasked with comprehending
    the user query and some historical records of previous actions (i.e., in the “memory”
    component) to extract a concrete task to be accomplished. The plan module is responsible
    for: (1) decomposing the extracted task into a sequence of sub-tasks that can
    be accomplished by invoking various tools, (2) managing the state and resources
    to support an appropriate plan (e.g., retaining the error code until requested
    by network_diagnose, as shown in Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 An Example of
    LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM
    Agents through Synthesized User Inputs")), and (3) determining the execution order
    of the sub-tasks. The act module then invokes the tools according to the generated
    plan and collects the results of the tool invocations.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 模块。图[2](#S2.F2 "Figure 2 ‣ 2.3 Architecture of LLM Agents ‣ 2 Preliminary ‣
    Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs")展示了LLM代理的典型架构。该代理由三个主要组件组成：（1）理解模块，（2）计划模块，以及（3）行动（工具使用）模块。理解模块负责理解用户查询及一些历史记录（即“内存”组件），以提取要完成的具体任务。计划模块的职责包括：（1）将提取的任务分解为可以通过调用各种工具完成的子任务序列，（2）管理状态和资源以支持适当的计划（例如，保留错误代码直到网络诊断请求，如图[1](#S2.F1
    "Figure 1 ‣ 2.2 An Example of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")所示），以及（3）确定子任务的执行顺序。然后，行动模块根据生成的计划调用工具并收集工具调用的结果。
- en: 'LLM and Prompts. All the components mentioned above are implemented by an LLM,
    which serves as the “brain” of the agent. The agent offers prompt templates composing
    the query context, how the agent should respond, and the accessible tools, whereas
    the users provide the query content. The formed prompt will be used to guide the
    LLM to generate the response. For example, ReAct [[59](#bib.bib59)] categorizes
    the core LLM’s response into three types: observation, thought, and action, which
    correspond to the understand, plan, and act modules in Fig. [2](#S2.F2 "Figure
    2 ‣ 2.3 Architecture of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs"), respectively.
    Additionally, prompt engineering strategies like role-play are often employed
    to enhance the agent’s performance under specific scenarios, such as through the
    instruction parameter in OpenAI’s Assistant API [[7](#bib.bib7)].'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 和提示。上述所有组件均由LLM实现，LLM作为代理的“脑部”。该代理提供了组成查询上下文、代理应如何响应以及可用工具的提示模板，而用户提供查询内容。形成的提示将用于指导LLM生成响应。例如，ReAct
    [[59](#bib.bib59)] 将LLM的核心响应分为三类：观察、思考和行动，分别对应图[2](#S2.F2 "Figure 2 ‣ 2.3 Architecture
    of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in
    LLM Agents through Synthesized User Inputs")中的理解、计划和行动模块。此外，像角色扮演这样的提示工程策略通常用于提升代理在特定场景下的表现，例如通过OpenAI的助手API
    [[7](#bib.bib7)] 中的指令参数。
- en: 2.4 Our Testing Focus
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 我们的测试重点
- en: 'As shown in Fig. [2](#S2.F2 "Figure 2 ‣ 2.3 Architecture of LLM Agents ‣ 2
    Preliminary ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs"), different components jointly contribute to the agent’s
    overall performance. Nevertheless, this paper considers testing the plan module
    a top priority. This is because extensive efforts [[25](#bib.bib25), [19](#bib.bib19),
    [62](#bib.bib62), [46](#bib.bib46), [51](#bib.bib51), [28](#bib.bib28)] have been
    devoted to evaluating the understand module, which rely on LLMs’ basic natural
    language understanding capability. Similarly, the act module has also made promising
    progress, as evidenced by OpenAI’s recent work in incorporating function calling
    functionality into GPT models [[6](#bib.bib6)]. Moreover, Yue et al. [[20](#bib.bib20)]
    have conducted a thorough investigation into LLM agents’ tool usage performance
    and proposed a benchmark, MetaTool, to evaluate the act module. In contrast, the
    plan module, which determines how to concretize the agent’s thought into a sequence
    of actions that can be executed by the agent, has not been systematically studied
    or tested in existing research. To sum up, we have the following focuses:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [2](#S2.F2 "Figure 2 ‣ 2.3 Architecture of LLM Agents ‣ 2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")
    所示，不同的组件共同影响代理的整体表现。然而，本文认为测试计划模块是重中之重。这是因为大量的努力 [[25](#bib.bib25), [19](#bib.bib19),
    [62](#bib.bib62), [46](#bib.bib46), [51](#bib.bib51), [28](#bib.bib28)] 已经投入到评估理解模块，该模块依赖LLMs的基本自然语言理解能力。同样，行动模块也取得了有希望的进展，OpenAI最近在GPT模型中加入了函数调用功能 [[6](#bib.bib6)]。此外，Yue等人 [[20](#bib.bib20)]
    进行了对LLM代理工具使用性能的深入研究，并提出了一个基准MetaTool来评估行动模块。相比之下，计划模块，决定如何将代理的思维具体化为可以由代理执行的动作序列，尚未在现有研究中系统地研究或测试。总之，我们有以下重点：
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: (Isolating the test of the planning module only) While maintaining the complexity
    of the planning problem, we strive to simplify the user queries handled by the
    understand and act modules (see Fig. [2](#S2.F2 "Figure 2 ‣ 2.3 Architecture of
    LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM
    Agents through Synthesized User Inputs")). By doing this, we can guarantee that
    any detected agent failure can be solely attributed to an error in the planning
    module, thereby achieving a simulated “isolation” of the planning module. This
    approach facilitates more precise testing of LLM agents’ planning ability.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: （仅隔离规划模块的测试）在保持规划问题复杂性的同时，我们力求简化由理解和行动模块处理的用户查询（见图 [2](#S2.F2 "Figure 2 ‣ 2.3
    Architecture of LLM Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous
    Planning in LLM Agents through Synthesized User Inputs")）。通过这样做，我们可以确保任何检测到的代理失败都可以归因于规划模块中的错误，从而实现规划模块的模拟“隔离”。这种方法有助于更精确地测试LLM代理的规划能力。
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: (Covering both textual queries and underlying tools) Unlike previous works [[50](#bib.bib50),
    [49](#bib.bib49)] that tested the planning ability of LLMs by generating and evaluating
    textual plans, the planning module in LLM agents is required to decide the order
    of tool invocation, making the testing of the planning module more complex. We
    aim to generate specialized test cases that comprise both textual queries and
    corresponding tools.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: （涵盖文本查询和相关工具）与以前的工作 [[50](#bib.bib50), [49](#bib.bib49)] 通过生成和评估文本计划来测试LLMs的规划能力不同，LLM代理中的规划模块需要决定工具调用的顺序，使得规划模块的测试更加复杂。我们旨在生成包括文本查询和相应工具的专门测试用例。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: (Using only valid user queries for testing) For individual queries, we focus
    on generating valid user queries to test LLM agents. That said, we are not using
    extreme user queries to stress LLM agents. Based on our observation, extreme queries,
    such as overly long or complex ones, as well as those with broken or confusing
    contents, may hinder the LLM agent from generating meaningful outputs. This is
    not surprising since LLM agents rely on LLMs to generate outputs and are, therefore,
    sensitive to the quality of the input prompts. Sticking to valid user queries
    can help us better understand the planning module’s performance in a real-world
    setting.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: （仅使用有效的用户查询进行测试）对于单个查询，我们专注于生成有效的用户查询来测试LLM代理。也就是说，我们不会使用极端的用户查询来施压LLM代理。根据我们的观察，极端查询，如过长或复杂的查询，或内容破碎或混乱的查询，可能会阻碍LLM代理生成有意义的输出。这并不奇怪，因为LLM代理依赖LLMs生成输出，因此对输入提示的质量非常敏感。坚持使用有效的用户查询可以帮助我们更好地了解规划模块在实际环境中的表现。
- en: 3 Overview
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 概述
- en: '![Refer to caption](img/d72a19154f1e13ed6d7754dd4b11bb0b.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d72a19154f1e13ed6d7754dd4b11bb0b.png)'
- en: 'Figure 3: An overall workflow of PDoctor, which synthesizes textual user queries
    with a list of tools and derives the constraints as the oracle to test the LLM
    agent.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：PDoctor的总体工作流程，它将文本用户查询与工具列表进行综合，并将约束作为测试LLM代理的神谕。
- en: 'With the testing focus described in Sec. [2.4](#S2.SS4 "2.4 Our Testing Focus
    ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs"), we now introduce PDoctor, a novel system for testing
    and understanding erroneous planning in LLM agents. The basic idea of PDoctor
    is to synthesize textual user queries, and based on the simultaneously derived
    formal constraints, we can identify the erroneous planning. Based on this idea,
    we present the overall design of PDoctor as shown in Fig. [3](#S3.F3 "Figure 3
    ‣ 3 Overview ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs"). At a high level, PDoctor generates test cases comprising
    textual user queries that represent planning problems, along with a series of
    tools for invocation by the LLM agent. The testing oracle, automatically derived
    from the synthesized queries, is used to check the correctness of the LLM agent’s
    planning. This oracle also facilitates the dissection and characterization of
    erroneous planning when it occurs. Specifically, PDoctor has the following key
    components:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 根据第[2.4](#S2.SS4 "2.4 Our Testing Focus ‣ 2 Preliminary ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")节中描述的测试重点，我们现在介绍PDoctor，一个用于测试和理解LLM代理中的错误规划的新系统。PDoctor的基本思想是综合文本用户查询，并基于同时导出的正式约束，我们可以识别错误的规划。基于这一思想，我们展示了PDoctor的整体设计，如图[3](#S3.F3
    "Figure 3 ‣ 3 Overview ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs")所示。总体而言，PDoctor生成包含代表规划问题的文本用户查询的测试用例，以及一系列由LLM代理调用的工具。自动从综合查询中导出的测试神谕用于检查LLM代理规划的正确性。当发生错误规划时，这个神谕还促进了错误规划的剖析和表征。具体而言，PDoctor具有以下关键组件：
- en: '① User Query Generation. PDoctor performs a natural language synthesis process
    to generate textual user queries, which are considered as a planning problem $\mathcal{P}$,
    as formulated in Sec. [2.1](#S2.SS1 "2.1 Planning Problem ‣ 2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs"),
    for the LLM agent. This process comprises two steps: skeleton synthesis and text
    filling. The former step generates a skeleton of the user query, which is a high-level,
    abstract representation of the planning problem. This enables PDoctor directly
    to derive the constraints for subsequent testing. The latter step fills in this
    skeleton with text to form a complete user query that describes the requirements
    for problem-solving. The design of this synthesis process is motivated by two
    key considerations: (1) the derived constraints should be equivalent to the semantics
    of the generated queries, since these constraints are used as the oracle to test
    the LLM agent; (2) the synthesis process should be flexible and extensible, allowing
    users to specify the complexity and scenarios of the generated queries. For the
    first consideration, alternative methods for generating user queries, such as
    text mutation and LLM-based text generation, are further discussed in Sec. [7](#S7
    "7 Discussion ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs").'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ① 用户查询生成。PDoctor执行自然语言综合过程生成文本用户查询，这些查询被视为规划问题$\mathcal{P}$，如第[2.1](#S2.SS1
    "2.1 Planning Problem ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")节中所述，用于LLM代理。此过程包括两个步骤：骨架综合和文本填充。前者生成用户查询的骨架，这是规划问题的高层次、抽象表示。这使得PDoctor能够直接导出用于后续测试的约束。后者步骤将文本填充到这个骨架中，形成一个完整的用户查询，描述问题解决的要求。这个综合过程的设计受到两个关键考虑的驱动：（1）导出的约束应等同于生成查询的语义，因为这些约束用作测试LLM代理的神谕；（2）综合过程应具有灵活性和可扩展性，允许用户指定生成查询的复杂性和场景。对于第一个考虑，第[7](#S7
    "7 Discussion ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs")节进一步讨论了生成用户查询的替代方法，如文本变异和基于LLM的文本生成。
- en: ② Test Results Check. After deriving formal constraints from the synthesis process,
    PDoctor utilizes these constraints to detect erroneous planning of the LLM agent.
    Specifically, PDoctor maps each action, which corresponds to subtasks specified
    by the user query in a one-to-one manner, to a specific tool invocation and collects
    the action chain (i.e., the planning made by the LLM agent) by recording the history
    of tool invocations. The collected planning is then compared against the constraints
    to determine whether the planning is correct.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ② 测试结果检查。在从合成过程中推导出正式约束后，PDoctor利用这些约束来检测LLM代理的错误规划。具体来说，PDoctor将每个动作（即与用户查询中指定的子任务一一对应的动作）映射到特定的工具调用，并通过记录工具调用的历史来收集动作链（即LLM代理的规划）。然后，将收集到的规划与约束进行比较，以确定规划是否正确。
- en: ③ Error Dissection. In contrast to prior studies that modified inputs based
    on superficial natural language properties (e.g., word-level replacement) [[48](#bib.bib48),
    [30](#bib.bib30)], PDoctor synthesize complete textual user queries from scratch,
    gaining full control over both the semantics (i.e., the derived constraints) and
    the structure (i.e., the skeleton) of the user query. This design allows PDoctor to
    conduct comprehensive mutations and transformations on the generated query. By
    maintaining the overall semantic meaning, PDoctor is capable of altering words,
    sub-tasks, the context of the prompt, multiple sentences, and even the entire
    structure of the prompt. This capability is crucial for dissecting erroneous planning
    in LLM agents, as it enables PDoctor to pinpoint the root cause of failures by
    comparing the planning results of the original and mutated prompts.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 错误解剖。与先前基于表面自然语言属性（如单词级替换）修改输入的研究[[48](#bib.bib48), [30](#bib.bib30)]不同，PDoctor从头合成完整的文本用户查询，完全控制用户查询的语义（即推导出的约束）和结构（即骨架）。这种设计使PDoctor能够对生成的查询进行全面的变异和转换。在保持整体语义的情况下，PDoctor能够改变单词、子任务、提示的上下文、多个句子，甚至提示的整体结构。这一能力对于解剖LLM代理的错误规划至关重要，因为它使PDoctor能够通过比较原始和变异提示的规划结果来精准找出失败的根本原因。
- en: 'Challenges and Key Solutions. To achieve the design above, however, we need
    to address some unique challenges:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战与关键解决方案。然而，为实现上述设计，我们需要解决一些独特的挑战：
- en: 'C1:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 'C1:'
- en: Designing a mechanism or specification to support user query synthesis. Without
    a mechanism or specification to guide their formulation, the synthesized user
    queries could become highly varied and uncontrollable. Moreover, to easily derive
    the corresponding constraints from the synthesized queries, we also need the support
    of a formal specification. To address this problem, we propose a specialized DSL
    in Sec. [4.1](#S4.SS1 "4.1 Domain-Specific Language ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs"). With this
    DSL, PDoctor is able to cover a diverse set of user queries with configurable
    complexity and diversity. Moreover, DSL-based skeleton synthesis ensures the full
    control over the structure and semantics of the user queries, enabling PDoctor to
    exhaustively conduct mutation and transformation on a given prompt, thereby allowing
    the dissection of erroneous planning in Sec. [4.5](#S4.SS5 "4.5 Error Dissection
    ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs").
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 设计一个机制或规范以支持用户查询的合成。如果没有机制或规范来指导查询的制定，合成的用户查询可能会变得非常多样化且不可控。此外，为了轻松地从合成的查询中推导出相应的约束，我们还需要正式规范的支持。为了解决这个问题，我们在第[4.1节](#S4.SS1
    "4.1 Domain-Specific Language ‣ 4 Design ‣ Testing and Understanding Erroneous
    Planning in LLM Agents through Synthesized User Inputs")中提出了一种专门的领域特定语言（DSL）。通过这种DSL，PDoctor能够涵盖具有可配置复杂性和多样性的各种用户查询。此外，基于DSL的骨架合成确保了对用户查询的结构和语义的完全控制，使PDoctor能够对给定提示进行全面的变异和转换，从而允许在第[4.5节](#S4.SS5
    "4.5 Error Dissection ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")中解剖错误的规划。
- en: 'C2:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 'C2:'
- en: Generating syntactically valid and semantically meaningful user queries. As
    mentioned in Sec. [2.4](#S2.SS4 "2.4 Our Testing Focus ‣ 2 Preliminary ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs"),
    we aim to generate valid user queries to test LLM agents. That said, PDoctor  should
    focus on generating syntactically valid and semantically meaningful user queries
    as testing inputs. To address this challenge, the user query skeletons are specified
    using the aforementioned DSL, which prevents the generation of broken content;
    see details in Sec. [4.2](#S4.SS2 "4.2 User Query Synthesis ‣ 4 Design ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs").
    Moreover, a constraint solver (Z3 [[17](#bib.bib17)] in our case) is used to ensure
    that the semantics underlying the user queries are meaningful, i.e., the constraints
    derived from the generated prompt are always satisfiable, as to be illustrated
    in Sec. [4.3](#S4.SS3 "4.3 Test Results Check ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs").
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 生成语法上有效且语义上有意义的用户查询。如第[2.4节](#S2.SS4 "2.4 Our Testing Focus ‣ 2 Preliminary
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs")中提到的，我们的目标是生成有效的用户查询来测试LLM代理。也就是说，PDoctor 应该专注于生成语法上有效且语义上有意义的用户查询作为测试输入。为了解决这个挑战，用户查询的框架使用前述DSL进行指定，这可以防止生成损坏的内容；具体细节见第[4.2节](#S4.SS2
    "4.2 User Query Synthesis ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")。此外，使用约束求解器（在我们的案例中为Z3 [[17](#bib.bib17)]）来确保用户查询的语义是有意义的，即从生成的提示中导出的约束始终是可满足的，这将在第[4.3节](#S4.SS3
    "4.3 Test Results Check ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")中说明。
- en: 'C3:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 'C3:'
- en: Covering complex planning problems with state management and dynamic problem-solving.
    While the original design of PDoctor above already covers planning tests for both
    textual queries and corresponding tools, it has not yet considered complex planning
    problems involving state management and dynamic problem-solving. We address this
    challenge by introducing time and duration constraints, thereby obtaining an extended
    testing framework for PDoctor, which will be presented in Sec. [4.4](#S4.SS4 "4.4
    Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs").
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 涵盖具有状态管理和动态问题解决的复杂规划问题。虽然上述PDoctor的原始设计已经涵盖了对文本查询和相应工具的规划测试，但尚未考虑涉及状态管理和动态问题解决的复杂规划问题。我们通过引入时间和持续时间约束来解决这个挑战，从而获得了扩展的PDoctor测试框架，这将在第[4.4节](#S4.SS4
    "4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding Erroneous
    Planning in LLM Agents through Synthesized User Inputs")中展示。
- en: 4 Design
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 设计
- en: 4.1 Domain-Specific Language
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 领域特定语言
- en: To support user query synthesis, we have designed a specialized DSL tailored
    for LLM agent planning problems. This DSL is not intended to cover the infinitely
    vast semantic space of natural language for describing anything conceivable concept.
    Instead, it narrows its focus exclusively to the semantic space required for the
    planning problems defined in Sec. [2.1](#S2.SS1 "2.1 Planning Problem ‣ 2 Preliminary
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs"). Therefore, before delving into the specifics of the DSL, we first
    present how we simplify the semantic space to be explored, which could also avoid
    ambiguity due to English not being context-free.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持用户查询合成，我们设计了一种专门针对LLM代理规划问题的DSL。这种DSL并不打算涵盖自然语言描述任何可想象概念的无限广阔语义空间。相反，它将重点聚焦于第[2.1节](#S2.SS1
    "2.1 Planning Problem ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")中定义的规划问题所需的语义空间。因此，在深入探讨DSL的具体细节之前，我们首先介绍了如何简化要探索的语义空间，这也可以避免由于英语不是上下文无关的而产生的歧义。
- en: Semantic Simplification. For two given tasks that cannot be executed in parallel,
    denoted as task $A$” is a simplified constraint in this context. Moreover, it
    is straightforward to generalize this simplification to multiple tasks. Thus,
    PDoctor simplifies prompt synthesis into generating several sentences, each of
    which is composed of this kind of simplified constraints.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 语义简化。对于两个不能并行执行的任务，这里的“任务$A$”是一个简化的约束。此外，这种简化很容易推广到多个任务。因此，PDoctor将提示合成简化为生成几句每句由这种简化约束组成的句子。
- en: In addition, each “task” in the user query is simplified to take an action $a$
    is the set of actions that the LLM agent can perform (see Sec. [2.1](#S2.SS1 "2.1
    Planning Problem ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")). Take Fig. [3](#S3.F3 "Figure
    3 ‣ 3 Overview ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs") as an example, conducting network status check is a
    task and invoking network_status_check() is the action. Without necessitating
    additional decomposition, every task can be completed directly through one single
    action. This simplification is based on the observation that task decomposition
    is mainly determined by the context of the task, rather than the performance of
    the LLM agent itself. For example, LLM agents that are familiar with the network
    would be able to correctly decompose the task of “fix disconnected network” into
    a series of sub-tasks like “check network status” and “network diagnosis”, while
    others that are designed for addressing book management would not. Nonetheless,
    this task decomposition failure can be easily mitigated by providing the LLM agent
    with instructive knowledge of network repair. Due to the potential unanticipated
    impact that task decomposition could have on the performance of the LLM agent,
    PDoctor avoids generating complex tasks that require decomposition.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，用户查询中的每个“任务”都简化为采取一个动作 $a$，这是LLM代理可以执行的动作集合（见第[2.1节](#S2.SS1 "2.1 规划问题 ‣
    2 初步 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")）。以图[3](#S3.F3 "图 3 ‣ 3 概览 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")为例，进行网络状态检查是一个任务，而调用network_status_check()是这个动作。无需额外的分解，每个任务可以通过一个单一的动作直接完成。这种简化基于这样一个观察：任务分解主要由任务的上下文决定，而不是LLM代理本身的表现。例如，熟悉网络的LLM代理能够将“修复断开网络”的任务正确分解为一系列子任务，如“检查网络状态”和“网络诊断”，而那些设计用于处理书籍管理的代理则不能。然而，通过提供网络修复的指导性知识，这种任务分解失败可以很容易地得到缓解。由于任务分解可能对LLM代理的性能产生意想不到的影响，PDoctor
    避免生成需要分解的复杂任务。
- en: Syntax $\displaystyle\langle\mathcal{P}\in\text{Planning Problem}\rangle\Coloneqq{}$
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 语法 $\displaystyle\langle\mathcal{P}\in\text{规划问题}\rangle\Coloneqq{}$
- en: 'Figure 4: The syntax of our DSL, specifically designed for synthesizing user
    queries and deriving their constraints.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：我们的DSL的语法，专门用于合成用户查询并推导其约束。
- en: DSL Specifics. Fig. [4](#S4.F4 "Figure 4 ‣ 4.1 Domain-Specific Language ‣ 4
    Design ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs") presents the syntax of this domain-specific language. Overall, each
    user query is represented as a paragraph $\mathcal{P}$ is an exceptional case,
    as it is merely used to decorate the verb phrase VP, indicating that the verb
    phrase is not associated with any temporal relationship, like “happen” or “occur”.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: DSL 细节。图[4](#S4.F4 "图 4 ‣ 4.1 领域特定语言 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")展示了这个领域特定语言的语法。总体而言，每个用户查询都表示为一个段落
    $\mathcal{P}$ 是一个特殊情况，因为它仅用于装饰动词短语 VP，表示动词短语与任何时间关系无关，如“发生”或“出现”。
- en: 4.2 User Query Synthesis
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 用户查询合成
- en: The DSL designed in Sec. [4.1](#S4.SS1 "4.1 Domain-Specific Language ‣ 4 Design
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs") moderates natural language complexity while preserving the expressiveness
    and variety of the user queries it generates. In general, synthesizing a user
    query is to gradually expand an abstract syntax tree (AST) where each node in
    the AST is randomly selected from a set of valid nodes according to the grammar
    of the DSL. That said, the synthesis process is conducted in a top-down manner,
    with the root node being the paragraph $P$, the DSL offers a total of 340 possible
    expanding options, ensuring the diversity of the synthesized user queries.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第[4.1节](#S4.SS1 "4.1 领域特定语言 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")设计的DSL调节自然语言复杂性，同时保留了生成的用户查询的表达力和多样性。一般来说，合成用户查询是逐步扩展一个抽象语法树（AST），其中AST中的每个节点都根据DSL的语法从一组有效节点中随机选择。也就是说，合成过程是自顶向下进行的，根节点是段落
    $P$，DSL提供了总共340个可能的扩展选项，确保了合成用户查询的多样性。
- en: 'Based on this carefully designed DSL, the synthesis of user queries mainly
    comprises three steps: synthesizing the skeleton, translating the skeleton into
    NL (natural language) prompts, and simultaneously deriving the constraints from
    the synthesized skeleton, as illustrated in Fig. [3](#S3.F3 "Figure 3 ‣ 3 Overview
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs").'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一精心设计的DSL，用户查询的合成主要包括三个步骤：合成骨架，将骨架翻译成自然语言（NL）提示，以及从合成的骨架中同时推导约束，如图[3](#S3.F3
    "图3 ‣ 3 概述 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")所示。
- en: 'Input: Action Set $\bm{A}=\{a_{1},a_{2},...,a_{n}\}$*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：动作集$\bm{A}=\{a_{1},a_{2},...,a_{n}\}$*
- en: Algorithm 1 Skeleton Synthesis.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 算法1 骨架合成。
- en: Skeleton Synthesis. Alg. [1](#alg1 "In 4.2 User Query Synthesis ‣ 4 Design ‣
    Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs") presents the algorithmic procedure for prompt skeleton synthesis.
    The algorithm takes the action set $\bm{A}$ is reached, at which point the generation
    process will be terminated since it indicates that finding a satisfiable sentence
    is infeasible (lines 12–17). It is worth noting that this algorithm ensures the
    generated user query must be satisfiable, as the constraints are checked after
    each sentence generation. This way, the synthesized user query can effectively
    be used for testing the LLM agent’s planning ability.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 骨架合成。算法[1](#alg1 "在4.2 用户查询合成 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")展示了提示骨架合成的算法过程。该算法取动作集$\bm{A}$，在此点生成过程将被终止，因为这表示找到一个可满足的句子是不可行的（第12–17行）。值得注意的是，这个算法确保生成的用户查询必须是可满足的，因为在每次句子生成后都会检查约束。通过这种方式，合成的用户查询可以有效地用于测试LLM代理的规划能力。
- en: Text Filling. To “translate” the skeleton into natural language user queries,
    PDoctor fills text into the slots marked by the terminal symbols (e.g., various
    keywords and actions) in the skeleton. Except for action symbols, there are seven
    alternative natural language words on average for each terminal symbol. For example,
    “happen”, “occur”, “be executed”, etc., for the verb phrase ${\color[rgb]{.5,0,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,0,.5}\texttt{VP}}_{\emptyset}$.
    For the action symbols, we substitute them with the daily activities of various
    jobs. More specifically, we first instruct the LLM to provide a list of common
    jobs (e.g., “teacher”, “software developer”, etc.) by querying the LLM with the
    prompt “Please provide a list of 50 typical jobs. Ensure that these 50 positions
    span a variety of industries.”. For each provided job, we further query the LLM
    with the prompt “Please list 20 activities in noun phrase format that a [role]
    may need to do in a day.”, where “[role]” is replaced with the job name. Action
    symbols in the same paragraph are substituted with daily activities from the same
    job, and the job becomes the Topic of the user query. By changing the topic, PDoctor is
    capable of smoothly altering the context of the user queries, which is beneficial
    for the error dissection in Sec. [4.5](#S4.SS5 "4.5 Error Dissection ‣ 4 Design
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs"). The design of text filling facilitates the diversity and realism
    of the synthesized user queries, in contrast to the previous works that are limited
    to a few fixed, artificial scenarios or templates [[49](#bib.bib49), [42](#bib.bib42)].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 文本填充。为了将骨架“翻译”成自然语言用户查询，PDoctor将文本填充到骨架中由终端符号（例如，各种关键词和动作）标记的插槽中。除了动作符号之外，每个终端符号平均有七个备用的自然语言词汇。例如，动词短语${\color[rgb]{.5,0,.5}\definecolor[named]{pgfstrokecolor}{rgb}{.5,0,.5}\texttt{VP}}_{\emptyset}$可以使用“发生”、“出现”、“被执行”等词汇。对于动作符号，我们用各种工作的日常活动进行替代。更具体地说，我们首先指示LLM提供一个常见工作的列表（例如，“教师”、“软件开发人员”等），通过使用提示“请提供50个典型工作的列表。确保这50个职位涵盖各种行业。”进行查询。对于每个提供的工作，我们进一步通过提示“请列出一个[角色]一天可能需要做的20项活动，格式为名词短语。”进行查询，其中“[角色]”替换为职位名称。同一段落中的动作符号被替代为相同工作的日常活动，工作成为用户查询的主题。通过更改主题，PDoctor能够顺畅地改变用户查询的上下文，这有助于第[4.5](#S4.SS5
    "4.5 错误剖析 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")节中的错误剖析。文本填充的设计促进了合成用户查询的多样性和真实性，相比于仅限于少数固定的、人工的场景或模板的先前工作[[49](#bib.bib49),
    [42](#bib.bib42)]。
- en: Deriving Constraints. Simultaneously, PDoctor derives the constraints from each
    synthesized user query. Specifically, each action $a$.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 推导约束条件。同时，PDoctor 从每个合成的用户查询中推导约束条件。具体来说，是每个行动 $a$。
- en: 4.3 Test Results Check
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 测试结果检查
- en: Once we feed the synthesized user query to the LLM agent, it will generate a
    textual response that describes the planning of the tasks. We can check the correctness
    of the planning by comparing the action sequence extracted from the response to
    the constraints derived from the user query. It is worth noting that some may
    argue for employing metrics like the BLEU score [[37](#bib.bib37)] and BertScore [[64](#bib.bib64)]
    to assess the similarity between the generated response and the ground truth.
    However, this is less feasible in our context because (i) these metrics may be
    biased or expensive to compute, and (ii) the effectiveness of planning testing
    should be assessed based on whether the action sequence satisfies the constraints,
    rather than on the similarity between the generated response and the ground truth.
    Our approach of comparing the action sequence to the constraints, instead, is
    a more direct and effective way to validate the LLM agent’s planning.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将合成的用户查询输入到 LLM 代理中，它将生成一个描述任务规划的文本响应。我们可以通过将从响应中提取的行动序列与从用户查询中推导的约束条件进行比较来检查规划的正确性。值得注意的是，有些人可能主张使用
    BLEU 评分[[37](#bib.bib37)]和 BertScore[[64](#bib.bib64)]等指标来评估生成的响应与真实情况之间的相似性。然而，在我们的背景下，这种方法的可行性较低，因为（i）这些指标可能存在偏差或计算成本较高，以及（ii）规划测试的有效性应该基于行动序列是否满足约束条件，而不是基于生成响应与真实情况之间的相似性。相比之下，我们将行动序列与约束条件进行比较的方法，更直接有效地验证了
    LLM 代理的规划。
- en: A new challenge arises, however, as extracting the action sequence from the
    LLM agent’s textual response is non-trivial, requiring a precise understanding
    of the LLM response meaning. Existing work typically instructs the LLM to respond
    in a structural format through the adoption of few-shot prompts [[29](#bib.bib29),
    [49](#bib.bib49)]. We argue, nevertheless, that this practice is still not ideal,
    as LLMs may fail to comply with the format requirements. For example, the LLM
    may generate a response that is not structured as expected, or the response may
    contain irrelevant information that complicates the extraction process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，提取 LLM 代理的文本响应中的行动序列带来了新的挑战，这并非易事，需要对 LLM 响应的意义有精确的理解。现有的工作通常通过采用少量示例提示来指示
    LLM 以结构化格式响应[[29](#bib.bib29), [49](#bib.bib49)]。然而，我们认为这种做法仍然不理想，因为 LLM 可能未能遵守格式要求。例如，LLM
    可能生成一个结构与预期不符的响应，或者响应中可能包含无关信息，从而使提取过程复杂化。
- en: '![Refer to caption](img/5c39d0607052f7e7aadbf7a47c56fdde.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/5c39d0607052f7e7aadbf7a47c56fdde.png)'
- en: 'Figure 5: An example illustrating our “mock test” approach to extract the action
    sequence of LLM agents. Green italic denotes the synthesized part, which describes
    the constraints for conducting a series of tasks.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 一个示例，展示了我们“模拟测试”方法以提取 LLM 代理的行动序列。绿色斜体表示合成部分，描述了进行一系列任务的约束条件。'
- en: Mock Tool Design. PDoctor conducts a “mock test” approach to extracting the
    action sequence of LLM agents. Specifically, for each action $a$ is not conducted
    in the environment, and the tool merely returns a string that deceives the LLM
    agent into believing that the action has been completed. Fig. [5](#S4.F5 "Figure
    5 ‣ 4.3 Test Results Check ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs") illustrates an example of this
    design. For the synthesized user query presented in Fig. [5](#S4.F5 "Figure 5
    ‣ 4.3 Test Results Check ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")(a), PDoctor  creates a set of
    tools corresponding to the actions in the user query, where Fig. [5](#S4.F5 "Figure
    5 ‣ 4.3 Test Results Check ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")(b) depicts one of the tools. The
    network_diagnosis does not perform an actual network diagnosis in the environment.
    Instead, it merely writes the tool’s ID, “a1”, into the log file and deceives
    the LLM agent into believing that the network has been diagnosed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟工具设计。PDoctor 采用“模拟测试”方法来提取 LLM 代理的动作序列。具体而言，对于环境中未实际执行的每个动作 $a$，工具仅返回一个字符串，欺骗
    LLM 代理，使其相信该动作已经完成。图 [5](#S4.F5 "图 5 ‣ 4.3 测试结果检查 ‣ 4 设计 ‣ 通过合成用户输入测试和理解 LLM 代理的错误规划")
    说明了这种设计的一个示例。对于图 [5](#S4.F5 "图 5 ‣ 4.3 测试结果检查 ‣ 4 设计 ‣ 通过合成用户输入测试和理解 LLM 代理的错误规划")
    (a) 中展示的合成用户查询，PDoctor 创建了一组与用户查询中动作对应的工具，其中图 [5](#S4.F5 "图 5 ‣ 4.3 测试结果检查 ‣ 4
    设计 ‣ 通过合成用户输入测试和理解 LLM 代理的错误规划") (b) 描绘了其中一个工具。network_diagnosis 不在环境中实际执行网络诊断。相反，它仅将工具的
    ID，“a1”，写入日志文件，并欺骗 LLM 代理，使其相信网络已经被诊断。
- en: Result Checking. After the agent finishes processing the synthesized user query,
    the log file is read to collect the action sequence. Take the case in Fig. [3](#S3.F3
    "Figure 3 ‣ 3 Overview ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs") as an example, the action sequence is “[$a_{1}$)
    is unsatisfied, this planning is identified as correct. Overall, we view the integration
    of this check design with the mock tools as a novel approach to rigorously examine
    the planning of LLM agents while avoiding the complexity of understanding LLMs’
    textual response.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 结果检查。在代理处理完合成的用户查询后，读取日志文件以收集动作序列。以图 [3](#S3.F3 "图 3 ‣ 3 概述 ‣ 通过合成用户输入测试和理解
    LLM 代理的错误规划") 中的案例为例，动作序列是“[$a_{1}$）未满足，该规划被确定为正确。总体来看，我们将这种检查设计与模拟工具的集成视为一种新颖的方法，以严格检查
    LLM 代理的规划，同时避免理解 LLM 文本响应的复杂性。
- en: 4.4 Extended Testing Framework
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 扩展测试框架
- en: Syntax
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 语法
- en: '|  | $\displaystyle\langle o\in\text{Object}\rangle\Coloneqq{}$ |  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\langle o\in\text{Object}\rangle\Coloneqq{}$ |  |'
- en: '|  | $\displaystyle\langle t\in\text{Time}\rangle\Coloneqq{}$ |  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\langle t\in\text{Time}\rangle\Coloneqq{}$ |  |'
- en: 'Figure 6: DSL extension for covering time and duration constraints.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：用于覆盖时间和持续时间约束的 DSL 扩展。
- en: '![Refer to caption](img/39bde12048e3fad71dc533c0d801c7a8.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/39bde12048e3fad71dc533c0d801c7a8.png)'
- en: 'Figure 7: An example illustrating the extended version of the generated test
    case, including the user query and corresponding tools. Similar to Fig. [5](#S4.F5
    "Figure 5 ‣ 4.3 Test Results Check ‣ 4 Design ‣ Testing and Understanding Erroneous
    Planning in LLM Agents through Synthesized User Inputs"), green italic denotes
    the synthesized part. Newly added instructions are highlighted in brown. Sub-figure
    (c) shows the mapping between the action ID and the action name. (d) and (e) present
    the basic constraints and the additional constraints derived from the user query,
    respectively.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：一个示例，展示了生成的测试用例的扩展版本，包括用户查询和相应工具。类似于图 [5](#S4.F5 "图 5 ‣ 4.3 测试结果检查 ‣ 4 设计
    ‣ 通过合成用户输入测试和理解 LLM 代理的错误规划")，绿色斜体表示合成部分。新添加的指令以棕色突出显示。子图 (c) 显示了动作 ID 和动作名称之间的映射。(d)
    和 (e) 分别展示了基本约束和从用户查询中衍生的附加约束。
- en: Although the aforementioned test framework is effective in evaluating the planning
    ability of LLM agents, real-world scenarios would be more complex and challenging.
    Referring to the example in Fig. [1](#S2.F1 "Figure 1 ‣ 2.2 An Example of LLM
    Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs"), the agent is expected to dynamically adjust
    its planning based on the execution results of the tools. Moreover, some tools
    may require several specific inputs, like error_code in this example, which requires
    the LLM agent to retain the state information across different tasks. Motivated
    by these observations, we extend the test framework by introducing time and tool
    duration concepts into the agent planning. For one thing, time constraints are
    widely used in real-world planning, such as daily schedules. For another, the
    introduction of time allows PDoctor to simulate the dynamic planning over global
    resources, which is a representative complex planning problem in real-world scenarios.
    In particular, the synthesized user query is extended to include new constraints
    that regulate the start or end time of given tasks as illustrated in Fig. [6](#S4.F6
    "Figure 6 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs"). Accordingly,
    the mock tools are modified to require the start time point as the input parameter
    and return the duration of their execution. Fig. [7](#S4.F7 "Figure 7 ‣ 4.4 Extended
    Testing Framework ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in
    LLM Agents through Synthesized User Inputs") illustrates an example of the extended
    version of the generated test case.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述测试框架在评估LLM代理的规划能力方面有效，但实际场景会更加复杂和具有挑战性。参考图示中的示例[1](#S2.F1 "图 1 ‣ 2.2 LLM代理的示例
    ‣ 2 初步 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")，预计代理会根据工具的执行结果动态调整其规划。此外，一些工具可能需要几个特定输入，比如这个示例中的error_code，这要求LLM代理在不同任务之间保留状态信息。基于这些观察，我们通过将时间和工具持续时间的概念引入代理规划来扩展测试框架。一方面，时间约束在实际规划中被广泛使用，比如日常日程安排。另一方面，引入时间使得PDoctor能够模拟全球资源的动态规划，这在实际场景中是一个具有代表性的复杂规划问题。特别是，合成的用户查询被扩展为包含新的约束，这些约束规范了给定任务的开始或结束时间，如图示中的[6](#S4.F6
    "图 6 ‣ 4.4 扩展测试框架 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")所示。因此，模拟工具被修改为需要开始时间点作为输入参数，并返回其执行的持续时间。图示中的[7](#S4.F7
    "图 7 ‣ 4.4 扩展测试框架 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")展示了扩展版本的生成测试用例示例。
- en: From this figure, an obvious change is the template of the user query. Several
    new instructions are added, to require the LLM agent to consider the time constraints.
    Besides, the change in the return value of the mock tool, which is presented in
    Fig. [7](#S4.F7 "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")(b),
    requires the agent to dynamically adjust its planning. Due to the absence of knowledge
    about the tool execution time, the agent may encounter a situation where the planning
    is negated by the execution result of tools. Taking the case in Fig. [7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs") as an example,
    if the agent starts the execution of the network_diagnosis tool at 14:00, this
    planning would be negated because network_diagnosis takes 2 hours and finishes
    at 16:00, while the subsequent action network_speed_test is required to be executed
    before 15:00\. In this case, the agent is instructed to conduct an early halt
    and re-plan as shown in Fig. [7](#S4.F7 "Figure 7 ‣ 4.4 Extended Testing Framework
    ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs")(a).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以明显看出用户查询的模板发生了变化。新增了几条指令，要求LLM代理考虑时间约束。此外，模拟工具的返回值发生了变化，如图[7](#S4.F7 "Figure
    7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding Erroneous
    Planning in LLM Agents through Synthesized User Inputs")(b)所示，要求代理动态调整其规划。由于缺乏工具执行时间的知识，代理可能遇到规划被工具执行结果否定的情况。以图[7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")中的情况为例，如果代理在14:00开始执行network_diagnosis工具，那么这个规划将被否定，因为network_diagnosis需要2小时，直到16:00完成，而后续的network_speed_test要求在15:00之前执行。在这种情况下，代理被指示提前终止并重新规划，如图[7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(a)所示。
- en: Besides, the constraints derivation also changes. Now each action $a$, denoting
    the start and end time of the action, respectively. A new kind of constraint,
    duration constraint, is derived from the mock tools’ return value, regulating
    the duration of the associated action. Fig. [7](#S4.F7 "Figure 7 ‣ 4.4 Extended
    Testing Framework ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in
    LLM Agents through Synthesized User Inputs")(d) shows the basic constraints that
    are implied by the test environment and the instructions in the user query. Fig. [7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(e) presents
    the additional constraints derived from the synthesized part that is highlighted
    in green italic.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，约束推导也发生了变化。现在每个动作 $a$ 分别表示动作的开始和结束时间。新的约束类型，即持续时间约束，是从模拟工具的返回值中推导出的，用于调节相关动作的持续时间。图[7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(d)展示了测试环境和用户查询中的指令所隐含的基本约束。图[7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")(e)展示了从合成部分推导出的附加约束，突出显示为绿色斜体。
- en: 'Input: User Query $Q$* then30             return *“Structure”*31       end
    if32      else33             return *“Constraint”*34       end if35      36 end
    for37'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：用户查询 $Q$* 然后30 返回 *“结构”*31 结束 if32 否则33 返回 *“约束”*34 结束 if35 36 结束 for37
- en: Algorithm 2 Error Dissection.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 算法2 错误剖析。
- en: 4.5 Error Dissection
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 错误剖析
- en: PDoctor also features an error dissection component designed to investigate
    the causes of erroneous planning in LLM agents. Recall that our proposed query
    synthesis technique facilitates a thorough understanding of query semantics and
    the constraints that the LLM agent should satisfy. Given an error-triggering query,
    PDoctor can deliberately mutate components in this query to dissect the triggered
    error.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: PDoctor还具有一个错误剖析组件，旨在调查LLM代理中错误规划的原因。回顾一下，我们提出的查询合成技术有助于全面理解查询语义以及LLM代理应满足的约束。针对触发错误的查询，PDoctor可以故意变更查询中的组件以剖析触发的错误。
- en: 'Alg. [2](#alg2 "In 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and
    Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")
    presents the error dissection algorithm. In general, this algorithm first checks
    whether the error emerges probabilistically by running the LLM agent multiple
    times with the same user query. It then proceeds to mutate the user query from
    a low-level word substitution to high-level modification to identify the causes
    of the error. Specifically, the algorithm employs three mutation strategies: TerminalSubstitute,
    TopicChange, and QuerySynthesize. Correspondingly, there are five possible error
    causes: Probability, Terminal, Topic, Structure, and Constraint. If the error
    happens probabilistically, the error cause is Probability (lines 1–6). If the
    error is caused by specific words and can be fixed by substituting these words,
    the error cause is Terminal (lines 7–13). If the error can only be rectified by
    changing the topic of the user query, the error cause is Topic (lines 14–20).
    Furthermore, PDoctor will try to synthesize a new user query whose constraints
    are equivalent to the original one. If the error does not occur with the new query,
    the cause is Structure; otherwise, it is Constraint (lines 21–30). Constraint
    means that PDoctor  reveals a special set of constraints that the LLM agent is
    more prone to make mistakes with. Note that we do not consider dissecting multiple
    errors over a query, as this may complicate the whole process and make it hard
    to pinpoint the genuine cause of the error. For instance, if the error behaves
    probabilistically, it becomes less meaningful to dissect the error further. Similarly,
    if we have already identified specific words that cause the error (i.e., Terminal),
    then it should not belong to more holistic causes like Topic or Structure.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 [2](#alg2 "在 4.4 扩展测试框架 ‣ 4 设计 ‣ 通过合成用户输入测试和理解 LLM 代理中的错误规划") 介绍了错误剖析算法。一般来说，该算法首先通过多次运行
    LLM 代理并使用相同的用户查询来检查错误是否以概率形式出现。然后，它会对用户查询进行从低级词汇替换到高级修改的变异，以识别错误的原因。具体而言，该算法采用了三种变异策略：TerminalSubstitute、TopicChange
    和 QuerySynthesize。相应地，有五种可能的错误原因：Probability、Terminal、Topic、Structure 和 Constraint。如果错误是概率性出现的，则错误原因是
    Probability（第 1–6 行）。如果错误是由特定词汇造成的，并且可以通过替换这些词汇来修复，则错误原因是 Terminal（第 7–13 行）。如果错误只能通过更改用户查询的主题来纠正，则错误原因是
    Topic（第 14–20 行）。此外，PDoctor 将尝试合成一个新用户查询，其约束条件与原始查询等效。如果新查询中没有出现错误，则原因是 Structure；否则，就是
    Constraint（第 21–30 行）。Constraint 意味着 PDoctor 揭示了一组特殊的约束条件，LLM 代理更容易出错。请注意，我们不考虑对一个查询进行多个错误的剖析，因为这可能会使整个过程变得复杂，并且难以确定错误的真正原因。例如，如果错误是以概率性形式表现的，则进一步剖析错误的意义减少。类似地，如果我们已经识别了导致错误的特定词汇（即
    Terminal），那么它就不应归属于更全面的原因，如 Topic 或 Structure。
- en: 5 Implementation and Experiment Setup
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实现和实验设置
- en: PDoctor is implemented in Python3 with about 2,600 lines of code. We integrate
    PDoctor with Z3 [[17](#bib.bib17)], a popular constraint solver, for user query
    synthesis and mutation. In addition, all LLM agents are implemented using LangChain [[14](#bib.bib14)],
    a prevalent Python-based framework for developing LLM agents.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: PDoctor 是用 Python3 实现的，代码大约有 2,600 行。我们将 PDoctor 与 Z3 [[17](#bib.bib17)]，一个流行的约束求解器，集成，用于用户查询的合成和变异。此外，所有的
    LLM 代理都是使用 LangChain [[14](#bib.bib14)] 实现的，这是一个流行的基于 Python 的 LLM 代理开发框架。
- en: Models. Two widely-used LLM models, GPT-3.5 and GPT-4, are employed in our evaluation
    for two main reasons. First, acting as the agent core to conduct correct planning
    is challenging, thereby necessitating the need for powerful LLMs like the ones
    from OpenAI. Second, OpenAI’s models are the mainstream choices among the LLM
    application community, with the majority of popular libraries (e.g., LangChain)
    using them as the default. In this paper, all parameters of the LLM models are
    set to their default values except for temperature, which is set to $0$ to mitigate
    the non-determinism of LLM responses (OpenAI Assistant excludes this parameter
    because it does not support it). The versions of both models employed in this
    study are set to 1106, namely gpt-3.5-turbo-1106 and gpt-4-1106-preview.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 模型。我们在评估中使用了两个广泛使用的 LLM 模型，GPT-3.5 和 GPT-4，主要有两个原因。首先，作为代理核心进行正确规划是具有挑战性的，因此需要像
    OpenAI 的强大 LLM。其次，OpenAI 的模型是 LLM 应用社区中的主流选择，大多数流行的库（例如 LangChain）将其作为默认值。在本文中，LLM
    模型的所有参数均设置为默认值，除了温度参数设置为 $0$，以减轻 LLM 响应的非确定性（OpenAI Assistant 不包括此参数，因为它不支持）。本研究中使用的两个模型的版本设置为
    1106，即 gpt-3.5-turbo-1106 和 gpt-4-1106-preview。
- en: LLM Agent Frameworks. We evaluate PDoctor on three mainstream LLM agent frameworks,
    including ReAct [[59](#bib.bib59)], OpenAI Tools (OT) [[5](#bib.bib5)], and OpenAI
    Assistant (OA) [[7](#bib.bib7)]. These LLM agents are selected to cover different
    design choices and paradigms, including different interaction modes (how the LLM
    agent interacts with the core LLM or the integrated tools), prompt template designs,
    and in-depth customizations (e.g., LLM sampling parameter tuning, memory management,
    etc.).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理框架。我们在三个主流 LLM 代理框架上评估了 PDoctor，包括 ReAct [[59](#bib.bib59)]、OpenAI 工具
    (OT) [[5](#bib.bib5)] 和 OpenAI 助手 (OA) [[7](#bib.bib7)]。选择这些 LLM 代理是为了涵盖不同的设计选择和范式，包括不同的交互模式（LLM
    代理如何与核心 LLM 或集成工具互动）、提示模板设计和深入定制（例如，LLM 采样参数调整、内存管理等）。
- en: Table [1](#S5.T1 "Table 1 ‣ 5 Implementation and Experiment Setup ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")
    lists the details of the evaluated LLM agent frameworks. ReAct is the most compatible
    agent framework, as it supports any LLM that can be invoked via a completion.
    In contrast, OT and OA require the core LLM to support chat-based interaction
    and be tuned with function calling capabilities [[6](#bib.bib6)]. Both ReAct and
    OT are built with an emphasis on flexibility, allowing users to customize the
    LLM agent in-depth and use prompt templates to guide the user queries. In contrast,
    OA is designed to be more “fool-proof”, with limited customization options. This
    simple design choice has garnered considerable attention for OA among the general
    public and may signify a new trend in the LLM agent sector. To the best of our
    knowledge, the aforementioned LLM agents are the most representative ones in the
    current LLM agent landscape. It is noteworthy, nevertheless, that PDoctor is not
    limited to these LLM agent frameworks and can be applied to other LLM agents as
    well.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [1](#S5.T1 "表 1 ‣ 5 实施和实验设置 ‣ 通过合成用户输入测试和理解 LLM 代理中的错误规划") 列出了评估的 LLM 代理框架的详细信息。ReAct
    是最兼容的代理框架，因为它支持任何可以通过完成调用的 LLM。相比之下，OT 和 OA 需要核心 LLM 支持基于聊天的交互，并且具备功能调用能力 [[6](#bib.bib6)]。ReAct
    和 OT 都强调灵活性，允许用户深入定制 LLM 代理并使用提示模板来指导用户查询。相比之下，OA 设计上更为“防呆”，定制选项有限。这种简单的设计选择使
    OA 在公众中引起了相当大的关注，并可能标志着 LLM 代理领域的新趋势。根据我们的了解，上述 LLM 代理是当前 LLM 代理领域中最具代表性的。值得注意的是，PDoctor
    并不限于这些 LLM 代理框架，也可以应用于其他 LLM 代理。
- en: 'Table 1: Details of the evaluated LLM agents.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：评估的 LLM 代理的详细信息。
- en: '| Tool | LLM Interaction | Tool Interaction | Prompt Template? | In-depth Customization?
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | LLM 交互 | 工具交互 | 提示模板？ | 深入定制？ |'
- en: '| ReAct [[59](#bib.bib59)] | Completion | Few-Shot Prompting | ✓ | ✓ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| ReAct [[59](#bib.bib59)] | 完成 | 少样本提示 | ✓ | ✓ |'
- en: '| OT [[5](#bib.bib5)] | Chat | Function Calling | ✓ | ✓ |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| OT [[5](#bib.bib5)] | 聊天 | 功能调用 | ✓ | ✓ |'
- en: '| OA [[7](#bib.bib7)] | Chat | Function Calling | ✗ | ✗ |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| OA [[7](#bib.bib7)] | 聊天 | 功能调用 | ✗ | ✗ |'
- en: 6 Evaluation
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 评估
- en: 'In this section, We aim to answer the following research questions (RQs):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们旨在回答以下研究问题（RQs）：
- en: 'RQ1:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: RQ1：
- en: How effective is PDoctor in detecting erroneous planning in LLM agents?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: PDoctor 在检测 LLM 代理中的错误规划方面有多有效？
- en: 'RQ2:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: RQ2：
- en: How well do LLM agents perform planning and what kinds of planning errors do
    they make?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理在规划中的表现如何，它们会犯哪些类型的规划错误？
- en: 'RQ3:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: RQ3：
- en: How do LLM agents perform when encountering complex planning problems?
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当遇到复杂的规划问题时，LLM代理的表现如何？
- en: '6.1 RQ1: Assessing PDoctor’s Effectiveness in Detecting Erroneous Planning'
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 RQ1：评估PDoctor在检测错误规划中的有效性
- en: We first assess the effectiveness of PDoctor in detecting erroneous planning
    in LLM agents. For each type of LLM agent (six in total, two models for three
    types of LLM agent frameworks as described in Sec. [5](#S5 "5 Implementation and
    Experiment Setup ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs")), we employ PDoctor to randomly generate test
    cases and test the agent’s planning performance within a specified time constraint.
    Since token usage increases exponentially with agent iteration, rendering the
    test of LLM agents costly, we set the time limit to 60 minutes for each type of
    LLM agent. For each generated test case, we create a new LLM agent instance and
    instruct it to process the synthesized user query with the provided tools, with
    the timeout configured to 180 seconds. The maximum iteration limit is set to 50,
    consistent with that in Yao et al.’s work [[59](#bib.bib59)].
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先评估PDoctor在检测LLM代理中的错误规划的有效性。对于每种类型的LLM代理（共六种，每种类型有两个模型，如第[5](#S5 "5 Implementation
    and Experiment Setup ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs")节所述的LLM代理框架），我们使用PDoctor随机生成测试用例，并在指定的时间限制内测试代理的规划性能。由于代币使用量随着代理迭代呈指数增长，使得测试LLM代理变得成本高昂，我们将每种LLM代理的时间限制设置为60分钟。对于每个生成的测试用例，我们创建一个新的LLM代理实例，并指示其使用提供的工具处理合成的用户查询，超时设置为180秒。最大迭代次数设置为50，与Yao等人的工作[[59](#bib.bib59)]中的设置一致。
- en: Moreover, the difficulty level of the planning problem is a key factor that
    affects the planning performance of LLM agents. In particular, the LLM agent is
    a difficulty-sensitive system expected to perform better on easier problems and
    worse on harder problems. The rationale behind this is that the ultimate goal
    of LLM agents is to generate human-like text by imitating the logic underlying
    human behaviors, and human beings are known to be difficulty-sensitive when solving
    problems. PDoctor takes the action number, $|\mathcal{A}|$ if the tested agent
    strictly follows the user query and invokes every tool only once. Furthermore,
    the number of actions also affects the constraint set size and the generated user
    query length, as more actions require more sentences to mention them, which in
    turn increases the number of constraints. Both the user query length and the constraint
    set size contribute to the difficulty of the problem.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，规划问题的难度水平是影响LLM代理规划性能的关键因素。特别是，LLM代理是一个对难度敏感的系统，预计在较简单的问题上表现更好，而在较复杂的问题上表现较差。其背后的理由是，LLM代理的最终目标是通过模仿人类行为背后的逻辑来生成类似人类的文本，而人类在解决问题时被认为是对难度敏感的。PDoctor考虑动作数量$|\mathcal{A}|$，如果被测试的代理严格遵循用户查询并且每个工具仅调用一次。此外，动作的数量还影响约束集大小和生成的用户查询长度，因为更多的动作需要更多的句子来提及它们，这反过来增加了约束的数量。用户查询长度和约束集大小都对问题的难度产生影响。
- en: In this RQ, we randomly sample the value of $|\mathcal{A}|$ is appropriate for
    this experiment. Under this setting, the sub-sentence number of the synthesized
    user query varies from one to seven, with the constraint set size ranging from
    two to ten, consistent with the common scenario in real-world applications.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个RQ中，我们随机抽取$|\mathcal{A}|$的值作为实验的适当设置。在此设置下，合成用户查询的子句数从一到七不等，约束集大小从二到十，符合现实世界应用中的常见情况。
- en: 'Table 2: Evaluation results of PDoctor in detecting erroneous planning in LLM
    agents. Z3-Count denotes the number of calls to the Z3 solver. Time denotes the
    total time spent on Z3/synthesis/agent.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：PDoctor在检测LLM代理中的错误规划的评估结果。Z3-Count表示对Z3求解器的调用次数。Time表示在Z3/合成/代理上的总花费时间。
- en: '|  | Agent | Generated | Errors (% of total) | Z3-Count | Z3-Time | Synthesis-Time
    | Agent-Time |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  | 代理 | 生成的 | 错误（占总数的百分比） | Z3-Count | Z3时间 | 合成时间 | 代理时间 |'
- en: '| GPT-3.5 | ReAct | 843 | 519 (61.57%) | 99,972 | 00:24.96 | 00:59.13 | 58:00.86
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | ReAct | 843 | 519 (61.57%) | 99,972 | 00:24.96 | 00:59.13 | 58:00.86
    |'
- en: '| OT | 1,168 | 635 (54.37%) | 133,008 | 00:34.30 | 01:20.49 | 57:11.94 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| OT | 1,168 | 635 (54.37%) | 133,008 | 00:34.30 | 01:20.49 | 57:11.94 |'
- en: '| OA | 327 | 179 (54.74%) | 36,694 | 00:09.67 | 00:22.52 | 59:22.24 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| OA | 327 | 179 (54.74%) | 36,694 | 00:09.67 | 00:22.52 | 59:22.24 |'
- en: '| GPT-4 | ReAct | 160 | 47 (29.38%) | 19,726 | 00:05.03 | 00:11.73 | 59:54.44
    |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | ReAct | 160 | 47 (29.38%) | 19,726 | 00:05.03 | 00:11.73 | 59:54.44
    |'
- en: '| OT | 144 | 32 (22.22%) | 16,253 | 00:04.13 | 00:09.66 | 59:40.41 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| OT | 144 | 32 (22.22%) | 16,253 | 00:04.13 | 00:09.66 | 59:40.41 |'
- en: '| OA | 111 | 40 (36.04%) | 12,775 | 00:03.38 | 00:07.75 | 59:54.25 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| OA | 111 | 40 (36.04%) | 12,775 | 00:03.38 | 00:07.75 | 59:54.25 |'
- en: 'Table [2](#S6.T2 "Table 2 ‣ 6.1 RQ1: Assessing PDoctor’s Effectiveness in Detecting
    Erroneous Planning ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs") shows the result of the evaluation.
    The call count and total time consumed by Z3 are presented in this table to offer
    a comprehensive understanding of the overhead associated with constraint-solving
    during the synthesis procedure. Moreover, the time consumption of both the synthesis
    and agent execution process is presented. An obvious observation from the table
    is that PDoctor is highly effective in synthesizing test cases. The average time
    consumed to synthesize a test case is only around 0.07 seconds. Despite the high
    call count of Z3, the time spent on Z3 is relatively low, with the average time
    spent on Z3 falling below 0.03 seconds per test case. Additionally, less than
    half of the total time required for the synthesis process is devoted to Z3\. In
    contrast, the execution of the agent is the most time-consuming part, as each
    agent type takes over 57 minutes.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [2](#S6.T2 "Table 2 ‣ 6.1 RQ1: Assessing PDoctor’s Effectiveness in Detecting
    Erroneous Planning ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs") 显示了评估结果。该表格中展示了Z3的调用次数和总耗时，以提供对合成过程中约束求解开销的全面理解。此外，还展示了合成和代理执行过程的时间消耗。从表格中明显可以看出，PDoctor在合成测试用例方面非常有效。合成一个测试用例的平均时间仅约为0.07秒。尽管Z3的调用次数很高，但在Z3上花费的时间相对较低，每个测试用例在Z3上花费的平均时间不到0.03秒。此外，合成过程所需的总时间中不到一半用于Z3。相比之下，代理的执行是最耗时的部分，每种代理类型的执行时间均超过57分钟。'
- en: In general, the speed bottleneck of the entire testing process lies in the agent’s
    throughput. Both model and framework have a significant impact on the performance
    of an LLM agent. Among all agents based on the GPT-3.5 model, ReAct and OT exhibit
    a substantial speed advantage over OA, with the number of processed queries being
    843 and 1,168, respectively, compared to OA’s 327\. For agents based on the GPT-4
    model, the number of processed queries substantially decreases across all three
    frameworks. Meanwhile, the gap between different frameworks narrows, indicating
    that the token process rate of GPT-4 constitutes a more severe bottleneck. However,
    it is important to note that the time overhead of the agent execution process
    is negligible in a real-world scenario, especially for ordinary users. Even in
    the worst case (OA based on GPT-4), the agent achieves an average speed of 32.4
    seconds per test case. This time would be negligible given the considerably longer
    execution times that real-world tools may require.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，整个测试过程的速度瓶颈在于代理的吞吐量。模型和框架对LLM代理的性能有着显著影响。在所有基于GPT-3.5模型的代理中，ReAct和OT相较于OA表现出显著的速度优势，处理的查询数量分别为843和1,168，而OA为327。对于基于GPT-4模型的代理，所有三个框架处理的查询数量都显著减少。同时，不同框架之间的差距缩小，这表明GPT-4的令牌处理速率构成了更严重的瓶颈。然而，需要注意的是，在实际应用场景中，代理执行过程的时间开销是微不足道的，尤其是对于普通用户而言。即使在最坏的情况下（基于GPT-4的OA），代理每个测试用例的平均速度为32.4秒。考虑到实际工具可能需要的执行时间更长，这个时间几乎可以忽略不计。
- en: In terms of error detection, PDoctor uncovers a considerable number of errors
    across all agent settings. Further characterization of the errors will be discussed
    in RQ2. From this table, it is evident that GPT-4 significantly improves the agent’s
    performance, with the error rate of all agents based on GPT-4 decreasing by 48.53%
    on average compared to those based on GPT-3.5. For GPT-3.5, we attribute the comparatively
    high error rate to its incapacity to manage the intricate nature of the planning
    problem, which will be further investigated in RQ2 and RQ3\. Regarding the agent
    framework, OT is the most recommended one, outperforming the other two frameworks
    in both models.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 就错误检测而言，PDoctor在所有代理设置中发现了相当数量的错误。错误的进一步特征化将在RQ2中讨论。从这张表格中可以明显看出，GPT-4显著提高了代理的性能，基于GPT-4的所有代理的错误率平均下降了48.53%，相比于基于GPT-3.5的代理。对于GPT-3.5，我们将相对较高的错误率归因于其无法处理复杂的规划问题，这将在RQ2和RQ3中进一步调查。关于代理框架，OT是最推荐的框架，在两种模型中均优于其他两个框架。
- en: 'Overall, given that the result check process is carried out in accordance with
    the constraint check (see Sec. [4.3](#S4.SS3 "4.3 Test Results Check ‣ 4 Design
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs")), it is guaranteed that any planning error made by the agent will
    be detected. Other kinds of errors, such as invoking a non-existing tool or forgetting
    to accomplish a task specified in the query, can also be easily detected by inspecting
    the execution chain of the agent. Given the high comprehensiveness of our testing
    approach, it is reasonable to conclude that the error rate reported in Table [2](#S6.T2
    "Table 2 ‣ 6.1 RQ1: Assessing PDoctor’s Effectiveness in Detecting Erroneous Planning
    ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs") faithfully reflects LLM agents’ performance. Indeed,
    the performance of each LLM agent is consistent with that of previous studies [[59](#bib.bib59),
    [41](#bib.bib41)].'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '总体而言，由于结果检查过程是根据约束检查进行的（见第[4.3节](#S4.SS3 "4.3 Test Results Check ‣ 4 Design
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs")），因此可以保证代理所犯的任何规划错误都会被检测到。其他类型的错误，例如调用不存在的工具或忘记完成查询中指定的任务，也可以通过检查代理的执行链轻松检测到。鉴于我们测试方法的高综合性，可以合理地得出结论，表[2](#S6.T2
    "Table 2 ‣ 6.1 RQ1: Assessing PDoctor’s Effectiveness in Detecting Erroneous Planning
    ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs")中报告的错误率忠实地反映了LLM代理的性能。确实，每个LLM代理的性能与先前的研究[[59](#bib.bib59),
    [41](#bib.bib41)]一致。'
- en: '6.2 RQ2: Understanding LLM Agents’ Planning Performance and Their Errors'
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 RQ2：理解LLM代理的规划性能及其错误
- en: This RQ delves into the planning and errors made by LLM agents. Recall in RQ1,
    we explain that LLM agents are generally difficulty-sensitive systems, and their
    planning performance would therefore depend on the difficulty of the encountered
    problem. Therefore, we presume that only the errors that fall within the planning
    capability of the LLM agent are valuable for further investigation. Hence, a comprehensive
    test with varying difficulties (up to the upper-level planning capability) is
    required to exhaustively explore the planning capability of LLM agents.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 本RQ深入探讨了LLM代理的规划及其错误。回顾RQ1，我们解释了LLM代理通常是难度敏感的系统，因此它们的规划性能将取决于遇到的问题的难度。因此，我们推测，只有在LLM代理规划能力范围内的错误才具有进一步调查的价值。因此，需要进行全面的测试，涵盖不同的难度（直到最高规划能力），以全面探索LLM代理的规划能力。
- en: Planning Capability Measurement. Specifically, we employ PDoctor to synthesize
    extensive test cases, with the difficulty level (i.e., the action number) gradually
    increasing. For each difficulty level, we record the success rate of the planning.
    We consider the agent to have reached its “upper-level planning capability” when
    the success rate drops too low (less than 20% in our experiments). Since the sampling
    space of the query generation is determined by the action number, we dynamically
    adjust the sampling number to fit it. That said, for a given action number $|\mathcal{A}|=n$
    represents the number of sentences in the extreme case where the synthesized user
    query contains sentences that solely mention two actions in a single sub-sentence
    (i.e., the possible minimum number of actions in a sentence). This represents
    the maximum number of sentences that can be generated for a given action number,
    depicting the sampling space of the query generation.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 规划能力测量。具体来说，我们使用 PDoctor 来合成大量测试用例，难度等级（即动作数量）逐渐增加。对于每个难度等级，我们记录规划的成功率。当成功率过低（在我们的实验中低于
    20%）时，我们认为代理已达到其“高级规划能力”。由于查询生成的采样空间由动作数量决定，我们动态调整采样数量以适应它。也就是说，对于给定的动作数量 $|\mathcal{A}|=n$，表示在极端情况下合成的用户查询包含仅提及两个动作的句子的数量（即句子中的动作可能的最小数量）。这表示在给定的动作数量下可以生成的最大句子数，描绘了查询生成的采样空间。
- en: In our experiments, $n$ starts from 2 and increases by 1 until the success rate
    threshold is reached. Likewise, we limit the maximum sampling number for each
    action setting to 300, considering the high cost of using OpenAI’s API. In this
    RQ, we test and present the planning performance of all agents under action numbers
    ranging from 2 to 9 to facilitate a comprehensive comparison. Hence, we conduct
    the above process for each of the six LLM agents (two models for each of the three
    agent frameworks), with 1,600 test cases generated for each agent type.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，$n$ 从 2 开始，并增加 1 直到达到成功率阈值。同样，我们限制每个动作设置的最大采样数为 300，考虑到使用 OpenAI 的 API
    成本。在此 RQ 中，我们测试并展示了所有代理在动作数量从 2 到 9 范围内的规划性能，以便进行全面比较。因此，我们对每个六个 LLM 代理（每个三种代理框架中的两个模型）进行上述过程，每种代理类型生成
    1,600 个测试用例。
- en: '![Refer to caption](img/1b0bd0c57087ac793e3fd30030975738.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1b0bd0c57087ac793e3fd30030975738.png)'
- en: 'Figure 8: Planning performance of different LLM agents.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: 不同 LLM 代理的规划性能。'
- en: 'Fig. [8](#S6.F8 "Figure 8 ‣ 6.2 RQ2: Understanding LLM Agents’ Planning Performance
    and Their Errors ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")(a) and Fig. [8](#S6.F8 "Figure
    8 ‣ 6.2 RQ2: Understanding LLM Agents’ Planning Performance and Their Errors ‣
    6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs")(b) present the planning success rate of LLM agents based
    on the GPT-3.5 and GPT-4 models, respectively. At the 20% success rate, a dashed
    line is drawn to signify the planning capability limit for each agent. Aligning
    with the findings of RQ1, agents based on GPT-4 generally exhibit superior planning
    abilities compared to those based on GPT-3.5 across all agent frameworks. The
    upper bound of agents adopting GPT-4 is achieved when $|\mathcal{A}=8|$. Moreover,
    the success rate of planning for agents based on GPT-3.5 drops sharply when the
    action number exceeds three, whereas it continues to decline gradually for agents
    based on GPT-4\. This suggests that GPT-4 is more robust in handling complex planning
    problems. In terms of the agent framework, it is hard to identify the optimal
    frameworks in this setting, as each one has its own strengths. Roughly speaking,
    users are recommended to choose OT plus GPT-3.5 for simple tasks and ReAct plus
    GPT-4 for complex tasks, considering the time overhead revealed in RQ1.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [8](#S6.F8 "Figure 8 ‣ 6.2 RQ2: Understanding LLM Agents’ Planning Performance
    and Their Errors ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs")(a) 和图 [8](#S6.F8 "Figure 8 ‣ 6.2
    RQ2: Understanding LLM Agents’ Planning Performance and Their Errors ‣ 6 Evaluation
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs")(b) 展示了基于 GPT-3.5 和 GPT-4 模型的 LLM 代理的规划成功率。在 20% 成功率处，画出了一条虚线，以标志每个代理的规划能力限制。与
    RQ1 的发现一致，基于 GPT-4 的代理在所有代理框架中通常表现出比基于 GPT-3.5 的代理更优越的规划能力。当 $|\mathcal{A}=8|$
    时，采用 GPT-4 的代理达到上限。此外，当动作数量超过三时，基于 GPT-3.5 的代理的规划成功率急剧下降，而基于 GPT-4 的代理则持续缓慢下降。这表明
    GPT-4 在处理复杂规划问题时更具鲁棒性。在代理框架方面，很难在这种设置中识别出最佳框架，因为每种框架都有其自身的优势。粗略来说，建议用户在简单任务中选择
    OT 加 GPT-3.5，而在复杂任务中选择 ReAct 加 GPT-4，考虑到 RQ1 中揭示的时间开销。'
- en: 'Table 3: The distribution of different types of planning errors in LLM agents.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: LLM 代理中不同类型规划错误的分布。'
- en: '|  | Agent | Timeout | Act Error | Action Lost | Order Error |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | 代理 | 超时 | 动作错误 | 动作丢失 | 顺序错误 |'
- en: '| GPT-3.5 | ReAct | 0.00% | 1.03% | 8.25% | 90.72% |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | ReAct | 0.00% | 1.03% | 8.25% | 90.72% |'
- en: '| OT | 0.00% | 0.00% | 0.46% | 99.54% |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| OT | 0.00% | 0.00% | 0.46% | 99.54% |'
- en: '| OA | 0.00% | 0.80% | 0.40% | 98.80% |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| OA | 0.00% | 0.80% | 0.40% | 98.80% |'
- en: '| GPT-4 | ReAct | 0.00% | 1.27% | 0.00% | 98.73% |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | ReAct | 0.00% | 1.27% | 0.00% | 98.73% |'
- en: '| OT | 0.00% | 1.12% | 0.00% | 98.88% |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| OT | 0.00% | 1.12% | 0.00% | 98.88% |'
- en: '| OA | 0.00% | 1.61% | 0.13% | 98.26% |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| OA | 0.00% | 1.61% | 0.13% | 98.26% |'
- en: 'Error Characteristics. We categorize the errors that fall within the planning
    capability limit of LLM agents into four types: (1) Timeout, where the agent spends
    too much time (over 180 seconds) or exceeds the maximal iteration limit (50) without
    reaching a solution; (2) Act Error, where the agent fails to correctly invoke
    tools; (3) Action Lost, where the agent fails to accomplish all tasks specified
    in the query, i.e., some actions are lost; (4) Order Error, where the agent fails
    to follow the constraints derived from the query. Table [3](#S6.T3 "Table 3 ‣
    6.2 RQ2: Understanding LLM Agents’ Planning Performance and Their Errors ‣ 6 Evaluation
    ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs") presents the error type distribution for each agent. Order Error
    is the most common error type across all agents, indicating that LLM agents may
    encounter difficulties in untangling the complex constraints of the planning problems.
    This observation further confirms the difficulty-sensitive nature of LLM agents.
    In addition, ReAct based on GPT-3.5 is substantially more prone to Action Lost
    than other agents. We attribute this to the lengthy prompt template of ReAct,
    which could potentially cause the LLM model to forget some actions specified in
    the query. On GPT-4, in contrast, the Action Lost error is significantly reduced,
    benefiting from the substantial improvement in GPT-4’s long-term memory. We believe
    these findings are valuable for the design and optimization of LLM agents (e.g.,
    their accompanying prompt templates), as well as for users who are interested
    in adopting LLM agents in their applications.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '错误特征。我们将落在 LLM 代理规划能力限制范围内的错误分类为四种类型：（1）超时，即代理花费过多时间（超过 180 秒）或超过最大迭代限制（50
    次）而未能找到解决方案；（2）动作错误，即代理未能正确调用工具；（3）动作丢失，即代理未能完成查询中指定的所有任务，即一些动作丢失；（4）顺序错误，即代理未能遵循查询中得出的约束。表
    [3](#S6.T3 "表 3 ‣ 6.2 RQ2: 了解 LLM 代理的规划表现及其错误 ‣ 6 评估 ‣ 通过合成用户输入测试和理解 LLM 代理中的错误规划")
    显示了每个代理的错误类型分布。顺序错误是所有代理中最常见的错误类型，这表明 LLM 代理在理清规划问题的复杂约束时可能会遇到困难。这一观察进一步确认了 LLM
    代理对困难的敏感性。此外，基于 GPT-3.5 的 ReAct 在动作丢失方面明显比其他代理更容易出现这种情况。我们将其归因于 ReAct 的较长提示模板，这可能导致
    LLM 模型忘记查询中指定的一些动作。相比之下，GPT-4 上的动作丢失错误显著减少，这得益于 GPT-4 在长期记忆方面的显著改进。我们认为这些发现对 LLM
    代理的设计和优化（例如其附带的提示模板）以及对有兴趣在其应用中采用 LLM 代理的用户都具有重要价值。'
- en: 'Table 4: The distribution of different root causes in erroneous planning.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 错误规划中不同根本原因的分布。'
- en: '|  | Agent | Probability | Terminal | Topic | Structure | Constraint |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | 代理 | 概率 | 终端 | 主题 | 结构 | 约束 |'
- en: '| GPT-3.5 | ReAct | 19.0% | 50.0% | 18.0% | 9.0% | 4.0% |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | ReAct | 19.0% | 50.0% | 18.0% | 9.0% | 4.0% |'
- en: '| OT | 8.0% | 42.0% | 22.0% | 15.0% | 13.0% |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| OT | 8.0% | 42.0% | 22.0% | 15.0% | 13.0% |'
- en: '| OA | 27.0% | 28.0% | 15.0% | 18.0% | 12.0% |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| OA | 27.0% | 28.0% | 15.0% | 18.0% | 12.0% |'
- en: '| GPT-4 | ReAct | 19.0% | 44.0% | 14.0% | 18.0% | 5.0% |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | ReAct | 19.0% | 44.0% | 14.0% | 18.0% | 5.0% |'
- en: '| OT | 15.0% | 37.0% | 23.0% | 17.0% | 8.0% |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| OT | 15.0% | 37.0% | 23.0% | 17.0% | 8.0% |'
- en: '| OA | 28.0% | 30.0% | 14.0% | 17.0% | 11.0% |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| OA | 28.0% | 30.0% | 14.0% | 17.0% | 11.0% |'
- en: 'Root Cause Analysis. After identifying the planning capability limit, further
    investigation into the cause of the triggered failures is conducted. A systematic
    error dissection is performed using the algorithm proposed in Sec. [4.5](#S4.SS5
    "4.5 Error Dissection ‣ 4 Design ‣ Testing and Understanding Erroneous Planning
    in LLM Agents through Synthesized User Inputs"). Specifically, we randomly sample
    100 errors that fall within the planning capability limit and dissect them to
    identify the root cause. The error dissection results are presented in Table [4](#S6.T4
    "Table 4 ‣ 6.2 RQ2: Understanding LLM Agents’ Planning Performance and Their Errors
    ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs"). Although the root cause distribution varies across
    different agent frameworks, it remains notably consistent across models. The high
    similarity in error patterns observed among agents based on different models indicates
    that agent frameworks play a more significant role in determining the error cause
    than the model itself. Another finding is that Probability results in notably
    more errors in OA than in other frameworks. We attribute this to the fact that
    OA cannot set the temperature of the core LLM, incurring more instability in the
    agent’s behaviors. Other frameworks, however, still fail to suppress Probability
    errors to a satisfactory level, even though the sampling parameters of the core
    LLM have been tuned before using PDoctor to mitigate non-determinism. This observation
    supports our hypothesis discussed in Sec. [2.2](#S2.SS2 "2.2 An Example of LLM
    Agents ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs") that the multi-turn interaction mode of LLM
    agents may further exacerbate the non-determinism issue of LLMs. Besides, it is
    worth noting that Terminal is the most common root cause across all agents, while
    Constraint typically causes only a small portion of errors. In other words, altering
    the prompt through text mutation not only works well in tweaking LLM’s behavior [[22](#bib.bib22)]
    but can also be applied to improve or worsen LLM agents’ performance.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '根本原因分析。在识别出规划能力限制后，进一步调查触发失败的原因。使用第[4.5](#S4.SS5 "4.5 错误解剖 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理的错误规划")节中提出的算法进行系统性的错误解剖。具体来说，我们随机抽取100个在规划能力限制内的错误进行解剖，以识别根本原因。错误解剖结果见表[4](#S6.T4
    "表4 ‣ 6.2 RQ2: 理解LLM代理的规划性能及其错误 ‣ 6 评估 ‣ 通过合成用户输入测试和理解LLM代理的错误规划")。尽管根本原因的分布在不同的代理框架中有所不同，但在模型间保持了显著的一致性。不同模型下观察到的代理之间错误模式的高度相似性表明，代理框架在决定错误原因方面比模型本身更为重要。另一个发现是，Probability在OA中的错误显著多于其他框架。我们将此归因于OA无法设置核心LLM的温度，导致代理行为更不稳定。然而，其他框架即使在使用PDoctor调整了核心LLM的采样参数以减轻非确定性后，仍未能将Probability错误抑制到令人满意的水平。这一观察支持了我们在第[2.2](#S2.SS2
    "2.2 LLM代理的一个例子 ‣ 2 初步 ‣ 通过合成用户输入测试和理解LLM代理的错误规划")节中讨论的假设，即LLM代理的多轮交互模式可能进一步加剧LLM的非确定性问题。此外，值得注意的是，Terminal是所有代理中最常见的根本原因，而Constraint通常只会导致一小部分错误。换句话说，通过文本变异改变提示不仅在调整LLM的行为[[22](#bib.bib22)]方面效果显著，也可以用于改善或恶化LLM代理的性能。'
- en: 'Table 5: Top-5 topics that cause the most errors.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：导致最多错误的前五个话题。
- en: '| GPT-3.5 | GPT-4 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | GPT-4 |'
- en: '| Topic | count | Topic | count |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 话题 | 数量 | 话题 | 数量 |'
- en: '| Waiter/Waitress | 6 | Graphic Designer | 5 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 服务员 | 6 | 平面设计师 | 5 |'
- en: '| Computer Programmer | 5 | Electrician | 4 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 计算机程序员 | 5 | 电工 | 4 |'
- en: '| Physical Therapist | 4 | Human Resources Manager | 4 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 物理治疗师 | 4 | 人力资源经理 | 4 |'
- en: '| Marketing Manager | 4 | Journalist | 4 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 市场营销经理 | 4 | 记者 | 4 |'
- en: '| Stock Broker | 4 | Video Game Designer | 4 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 股票经纪人 | 4 | 视频游戏设计师 | 4 |'
- en: 'As a further step, since the Topic causes a notable number of errors, we also
    count the top-5 topics that cause the most errors and present them in Table [5](#S6.T5
    "Table 5 ‣ 6.2 RQ2: Understanding LLM Agents’ Planning Performance and Their Errors
    ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs"). Here, we merge the results of agents based on the same
    model, as the topic of user queries may solely affect the language comprehension
    of the core LLM model. As stated in Sec. [4.2](#S4.SS2 "4.2 User Query Synthesis
    ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs"), PDoctor randomly picks one of 50 topics, which are
    about the daily tasks of different professions, to fill the action slots in the
    synthesized user query skeleton. It is observed that the most challenging topic
    for GPT3.5 is Waiter/Waitress, which causes 6 errors, while the remaining 19 topics
    never cause any errors. Similarly, for GPT-4, Graphic Designer’s daily life seems
    to be most challenging for the agent (causing 5 errors), while there are 16 error-free
    topics. We interpret that the topic of the user query may be likely unfamiliar
    to the agent, thereby notably affecting the agent’s performance. Yet, from the
    perspective of agent users, the role-playing instruction (currently employed by
    these agents; introduced in Sec. [2.3](#S2.SS3 "2.3 Architecture of LLM Agents
    ‣ 2 Preliminary ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs")) seems insufficient to improve their performance.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '作为进一步步骤，由于主题导致了显著数量的错误，我们还统计了导致最多错误的前五个主题，并在表[5](#S6.T5 "表5 ‣ 6.2 RQ2: 了解LLM代理的规划表现及其错误
    ‣ 6 评估 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")中呈现。在此，我们基于相同模型合并了代理的结果，因为用户查询的主题可能仅影响核心LLM模型的语言理解。如Sec. [4.2](#S4.SS2
    "4.2 用户查询合成 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")所述，PDoctor从50个主题中随机选择一个，这些主题涉及不同职业的日常任务，以填充合成用户查询框架中的行动槽。观察到GPT3.5最具挑战性的主题是服务员/服务员，这会导致6个错误，而剩余的19个主题则从未导致任何错误。同样，对于GPT-4，图形设计师的日常生活似乎是对代理最具挑战性的（导致5个错误），而有16个没有错误的主题。我们解释说，用户查询的主题可能对代理来说较为陌生，从而显著影响代理的表现。然而，从代理用户的角度来看，角色扮演指令（目前由这些代理采用；在Sec. [2.3](#S2.SS3
    "2.3 LLM代理的架构 ‣ 2 初步 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")中介绍）似乎不足以改善它们的表现。'
- en: '6.3 RQ3: Further Examining LLM Agents’ Performance on Complex Planning Problems'
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.3 RQ3: 进一步考察LLM代理在复杂规划问题上的表现'
- en: '![Refer to caption](img/33110567f0381925d63ebea35271f6c8.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/33110567f0381925d63ebea35271f6c8.png)'
- en: 'Figure 9: Planning performance of different LLM agents on complex planning
    problems.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '图9: 不同LLM代理在复杂规划问题上的规划表现。'
- en: In this RQ, we repeat the evaluation process described in RQ2 using the extended
    version of PDoctor to further examine the planning ability of LLM agents. As stated
    in Sec. [4.4](#S4.SS4 "4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and
    Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs"),
    the extended version introduces a more complex planning paradigm by adding time
    constraints, task duration, and tool parameters, thereby stressing the tested
    agents’ planning capabilities.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一RQ中，我们重复了RQ2中描述的评估过程，使用扩展版本的PDoctor来进一步考察LLM代理的规划能力。如Sec. [4.4](#S4.SS4 "4.4
    扩展测试框架 ‣ 4 设计 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")所述，扩展版本通过增加时间限制、任务持续时间和工具参数，引入了更复杂的规划范式，从而增强了被测试代理的规划能力。
- en: 'Planning Capability Measurement. We follow the same procedure as described
    in RQ2 to measure the upper bound of the LLM agents’ planning capability. Fig. [9](#S6.F9
    "Figure 9 ‣ 6.3 RQ3: Further Examining LLM Agents’ Performance on Complex Planning
    Problems ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM
    Agents through Synthesized User Inputs") presents the planning success rate of
    LLM agents based on the GPT-3.5 and GPT-4 models in this experiment. Since the
    maximal planning capability limit of all agents is reached when $|\mathcal{A}=5|$,
    only the planning success rates for action numbers ranging from 2 to 5 are presented
    in this figure. Clearly, the success rate of all agents drops significantly in
    comparison to the previous experiment, indicating that the extended version of
    PDoctor indeed introduces a more challenging (yet still realistic) planning problem.
    All agents based on GPT-3.5 drops below the 20% success rate when the action number
    reaches three, suggesting GPT-3.5 may not be suitable for handling such an intricate
    planning problem. For agents based on GPT-4, they maintain a relatively high success
    rate, though the success rate suffers a sharp decline when the action number exceeds
    four. Regarding the agent framework, ReAct performs the poorest in this setting,
    failing to address even the simplest planning problem when it takes GPT-3.5 as
    the core. Such failure extends when GPT-4 is adopted, with the success rate remaining
    below 50% across all action numbers. In contrast, OT and OA exhibit a relatively,
    albeit limited, higher success rate. We attribute this to the fact that ReAct
    relies on few-shot prompting to instruct the model to invoke tools, and the unstable
    nature of the LLM model becomes more apparent when the task becomes more complex.
    Conversely, OT and OA adopt function calling, which is implemented by fine-tuning
    the model with a large number of function calling data, making them more robust.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 计划能力测量。我们遵循RQ2中描述的相同程序来测量LLM代理的计划能力上限。图[9](#S6.F9 "图9 ‣ 6.3 RQ3：进一步检验LLM代理在复杂规划问题上的表现
    ‣ 6 评估 ‣ 通过合成用户输入测试和理解LLM代理中的错误规划")展示了基于GPT-3.5和GPT-4模型的LLM代理的规划成功率。在所有代理的最大规划能力限制在$|\mathcal{A}=5|$时，该图中仅展示了动作数量在2到5之间的规划成功率。显然，与之前的实验相比，所有代理的成功率显著下降，这表明扩展版PDoctor确实引入了更具挑战性（但仍然现实）的规划问题。基于GPT-3.5的所有代理在动作数量达到三时成功率下降到20%以下，表明GPT-3.5可能不适合处理如此复杂的规划问题。基于GPT-4的代理保持了相对较高的成功率，但当动作数量超过四时，成功率急剧下降。关于代理框架，ReAct在这种设置下表现最差，甚至在以GPT-3.5为核心时也未能解决最简单的规划问题。当采用GPT-4时，这种失败更为明显，所有动作数量下的成功率均低于50%。相比之下，OT和OA表现出相对（尽管有限）较高的成功率。我们将此归因于ReAct依赖少量示例提示来指示模型调用工具，当任务变得更加复杂时，LLM模型的不稳定性变得更加明显。相反，OT和OA采用功能调用，通过用大量功能调用数据微调模型，使其更具鲁棒性。
- en: 'Table 6: The distribution of different types of planning errors detected by
    the extended version of PDoctor.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：扩展版PDoctor检测到的不同类型的规划错误的分布。
- en: '|  | Agent | Timeout | Act Error | Action Lost | Order Error | Parameter Error
    |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | 代理 | 超时 | 行为错误 | 行动丢失 | 订单错误 | 参数错误 |'
- en: '| GPT-3.5 | ReAct | NaN | NaN | NaN | NaN | NaN |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | ReAct | NaN | NaN | NaN | NaN | NaN |'
- en: '| OT | 0.0% | 7.14% | 0.0% | 28.57% | 64.29% |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| OT | 0.0% | 7.14% | 0.0% | 28.57% | 64.29% |'
- en: '| OA | 0.0% | 0.0% | 0.0% | 50.0% | 50.0% |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| OA | 0.0% | 0.0% | 0.0% | 50.0% | 50.0% |'
- en: '| GPT-4 | ReAct | 0.0% | 64.44% | 0.0% | 33.33% | 2.22% |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | ReAct | 0.0% | 64.44% | 0.0% | 33.33% | 2.22% |'
- en: '| OT | 0.0% | 3.77% | 2.83% | 66.04% | 27.36% |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| OT | 0.0% | 3.77% | 2.83% | 66.04% | 27.36% |'
- en: '| OA | 0.0% | 0.74% | 1.12% | 64.31% | 33.83% |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| OA | 0.0% | 0.74% | 1.12% | 64.31% | 33.83% |'
- en: 'Error Type Analysis. Table [6](#S6.T6 "Table 6 ‣ 6.3 RQ3: Further Examining
    LLM Agents’ Performance on Complex Planning Problems ‣ 6 Evaluation ‣ Testing
    and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs")
    presents the error type distribution for each agent on the extended version of
    PDoctor. The extended version requires the agent to pass the start time point
    of actions to the corresponding tools and understand the tools’ return values,
    which reveal their execution time. Therefore, we introduce a new error type, Parameter
    Error, to denote the errors caused by the agent incorrectly setting the parameters
    of the tools. In particular, the start time of one tool should be later than the
    end time of the previous tool; otherwise, the agent would be considered to be
    mismanaging the global resource — time — of the planning problem. From the table¹¹1ReAct
    based on GPT-3.5 fails to address the simplest planning problem in this setting,
    leading to a NaN error rate in this table., we observe that ReAct encounters a
    substantial number of Act Error, confirming our earlier interpretation that ReAct’s
    tool invocation mechanism is not suitable for handling complex planning problems.
    For OT and OA, the main error type is Parameter Error when they adopt GPT-3.5,
    partially explaining their poor performance in this setting. In contrast, when
    GPT-4 is adopted, the main error type for all agents remains Order Error, aligning
    with the findings in RQ2\. In sum, we show that the extended version of PDoctor indeed
    introduces a more challenging planning problem, and the agent’s performance is
    significantly affected by the model and framework. In practice, we recommend users
    to employ OT or OA plus GPT-4 to handle such complex planning problems.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '错误类型分析。表格 [6](#S6.T6 "表 6 ‣ 6.3 RQ3: 进一步审查 LLM 代理人在复杂规划问题上的表现 ‣ 6 评估 ‣ 通过综合用户输入测试和理解
    LLM 代理人的错误规划")展示了每个代理人在 PDoctor 扩展版上的错误类型分布。扩展版要求代理人将动作的开始时间点传递给相应的工具，并理解工具的返回值，这些返回值揭示了它们的执行时间。因此，我们引入了一种新的错误类型，参数错误，来表示代理人错误设置工具参数所导致的错误。特别是，一个工具的开始时间应该晚于前一个工具的结束时间；否则，代理人会被认为在规划问题中错误地管理了全局资源——时间。从表中¹¹1ReAct
    基于 GPT-3.5 未能解决此设置下最简单的规划问题，导致此表中的 NaN 错误率。我们观察到 ReAct 遇到大量 Act Error，确认了我们之前的解释，即
    ReAct 的工具调用机制不适合处理复杂的规划问题。对于 OT 和 OA，当它们采用 GPT-3.5 时，主要错误类型是参数错误，部分解释了它们在此设置中的表现较差。相比之下，当采用
    GPT-4 时，所有代理人的主要错误类型仍然是 Order Error，与 RQ2 的发现一致。总之，我们展示了 PDoctor 扩展版确实引入了更具挑战性的规划问题，代理人的表现受到了模型和框架的显著影响。在实际应用中，我们建议用户使用
    OT 或 OA 加 GPT-4 来处理此类复杂规划问题。'
- en: 'Table 7: The distribution of different root causes identified by the extended
    version of PDoctor.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：PDoctor 扩展版识别出的不同根本原因的分布情况。
- en: '|  | Probability | Terminal | Topic | Structure | Constraint |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | 概率 | 终端 | 主题 | 结构 | 约束 |'
- en: '| ReAct | 8.0% | 22.0% | 11.0% | 14.0% | 45.0% |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| ReAct | 8.0% | 22.0% | 11.0% | 14.0% | 45.0% |'
- en: '| OT | 25.0% | 32.0% | 12.0% | 8.0% | 23.0% |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| OT | 25.0% | 32.0% | 12.0% | 8.0% | 23.0% |'
- en: '| OA | 23.0% | 22.0% | 11.0% | 5.0% | 39.0% | ![Refer to caption](img/72edfd35e6bed4426d7eef655b94c234.png)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '| OA | 23.0% | 22.0% | 11.0% | 5.0% | 39.0% | ![参见说明](img/72edfd35e6bed4426d7eef655b94c234.png)'
- en: 'Figure 10: An example of the erroneous planning made by an LLM agent. Actions
    are highlighted in different colors. To facilitate the understanding, we also
    present the derived constraints and the mapping between the actions and the variables
    in the constraints.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：LLM 代理人所做的错误规划示例。动作以不同颜色突出显示。为了便于理解，我们还展示了衍生的约束条件以及动作与约束条件中变量之间的映射关系。
- en: 'Root Cause Analysis. Similar to RQ2, we dissect the errors made by LLM agents.
    Due to the failure of GPT-3.5-based agents on the extended version of PDoctor,
    we primarily inspect the root cause for GPT-4-based agents to provide a more insightful
    analysis. Table [7](#S6.T7 "Table 7 ‣ 6.3 RQ3: Further Examining LLM Agents’ Performance
    on Complex Planning Problems ‣ 6 Evaluation ‣ Testing and Understanding Erroneous
    Planning in LLM Agents through Synthesized User Inputs") presents the root cause
    distribution for each agent. A notable difference from the results in RQ2 is that
    Constraint causes a larger portion of errors in this experiment, taking the dominant
    position in ReAct and OA, and ranking second in OT. We believe this is due to
    several reasons as follows.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '根本原因分析。类似于RQ2，我们分析了LLM代理的错误。由于基于GPT-3.5的代理在PDoctor的扩展版本上失败，我们主要检查了基于GPT-4的代理的根本原因，以提供更深入的分析。表格[7](#S6.T7
    "Table 7 ‣ 6.3 RQ3: Further Examining LLM Agents’ Performance on Complex Planning
    Problems ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM
    Agents through Synthesized User Inputs")展示了每个代理的根本原因分布。与RQ2中的结果显著不同的是，在本实验中，Constraint（约束）造成了更大比例的错误，在ReAct和OA中占据主导地位，在OT中排名第二。我们认为这主要有以下几个原因。'
- en: 'First, the agent is required to adjust its plan dynamically according to the
    tool return values, which substantially increases the complexity of the planning
    problem as discussed in Sec. [4.4](#S4.SS4 "4.4 Extended Testing Framework ‣ 4
    Design ‣ Testing and Understanding Erroneous Planning in LLM Agents through Synthesized
    User Inputs"). Second, the experiment results reveal that LLMs tend to make more
    errors when handling multiple different kinds of requirements simultaneously,
    which is a common scenario in real-world applications. Fig. [10](#S6.F10 "Figure
    10 ‣ 6.3 RQ3: Further Examining LLM Agents’ Performance on Complex Planning Problems
    ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM Agents through
    Synthesized User Inputs") provides an example of the erroneous planning made by
    an LLM agent. In this example, the agent fails to pass the correct start time
    to applying_hair_color, leading to a Parameter Error. Since the previous tool
    started at 10:00 and took two hours, applying_hair_color should start after 12:00
    (i.e., $start\_time\geq 12$), but the agent mistakenly sets the start time to
    8\. Although the action chain would be correct if the agent could reorder the
    actions according to the current start time of the tools, it already violates
    the requirement that “You need to execute all tasks one by one in the correct
    order and within the time range set by the requirement” in the query (see Fig. [7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")). Furthermore,
    the introduction of time and duration undoubtedly adds more constraints to the
    planning problem, which may also exacerbate agents’ planning difficulties.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，代理需要根据工具的返回值动态调整计划，这显著增加了规划问题的复杂性，如第[4.4](#S4.SS4 "4.4 Extended Testing
    Framework ‣ 4 Design ‣ Testing and Understanding Erroneous Planning in LLM Agents
    through Synthesized User Inputs")节讨论的那样。其次，实验结果显示，LLM在同时处理多种不同要求时容易出现更多错误，这在实际应用中是一种常见情况。图[10](#S6.F10
    "Figure 10 ‣ 6.3 RQ3: Further Examining LLM Agents’ Performance on Complex Planning
    Problems ‣ 6 Evaluation ‣ Testing and Understanding Erroneous Planning in LLM
    Agents through Synthesized User Inputs")提供了LLM代理错误规划的一个例子。在这个例子中，代理未能将正确的开始时间传递给applying_hair_color，导致了一个参数错误。由于之前的工具在10:00开始并持续了两个小时，applying_hair_color应在12:00之后开始（即，$start\_time\geq
    12$），但代理错误地将开始时间设置为8\. 尽管如果代理能够根据当前工具的开始时间重新排序动作，动作链是正确的，但它已经违反了查询中的要求：“你需要按正确的顺序和在要求设定的时间范围内逐一执行所有任务”（参见图[7](#S4.F7
    "Figure 7 ‣ 4.4 Extended Testing Framework ‣ 4 Design ‣ Testing and Understanding
    Erroneous Planning in LLM Agents through Synthesized User Inputs")）。此外，引入时间和持续时间无疑为规划问题增加了更多约束，这也可能加剧代理的规划困难。'
- en: 7 Discussion
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论
- en: Alternative Approaches for Test Case Generation. Several other approaches can
    be employed to generate test cases for LLM agents, including text mutation and
    text generation based on LLM. Based on preliminary study and experiments, we find
    that these methods are much less effective than our approach. In short, while
    these methods may seem simpler to implement and lighter in weight, they are incapable
    of generating high-diversity test cases and guaranteeing the correctness of result
    verification in the meantime.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 测试用例生成的替代方法。可以采用几种其他方法来生成 LLM 代理的测试用例，包括文本变异和基于 LLM 的文本生成。根据初步研究和实验，我们发现这些方法的效果远不如我们的方法。简而言之，尽管这些方法可能看起来更容易实现且更轻量，但它们无法生成高多样性的测试用例，也无法同时保证结果验证的正确性。
- en: Text mutation is limited to superficial changes in the input text, which is
    hardly feasible to cover the diverse scenarios that LLM agents may encounter.
    As for text generation, a possible approach is feeding a constraint set into an
    LLM, and ask the LLM to generate a user query in natural language. This method,
    nevertheless, is problematic because of the unstable nature of LLMs. To illustrate,
    we carry out an experiment in which we feed a constraint set and the variable-action
    mapping (e.g., $\mathbf{a_{1}}$. Considering that the test effectiveness is determined
    by the consistency of the generated text with the constraints, the results suggest
    that the text generation approach is unsuitable for this task.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 文本变异仅限于对输入文本的表面性修改，这很难覆盖 LLM 代理可能遇到的各种场景。至于文本生成，一种可能的方法是将约束集输入 LLM，并要求 LLM 生成自然语言的用户查询。然而，这种方法存在问题，因为
    LLM 的不稳定性。例如，我们进行了一项实验，其中我们输入了约束集和变量-动作映射（例如，$\mathbf{a_{1}}$）。考虑到测试效果取决于生成文本与约束的一致性，结果表明文本生成方法不适合此任务。
- en: Threat to Validity. Our approach is based on the assumption that no inherent
    sequential dependencies exist among the actions in the planning tasks, i.e., the
    derived constraints wholly reflect the constraints among the actions. This assumption
    shall hold for most cases, but there exist scenarios where the inherent sequential
    dependencies contained by the actions are common sense and do not need to be explicitly
    specified. In such cases, our approach may fail if there is a conflict between
    the inherent dependencies and the constraints derived from the synthesized plans.
    We leave it as future work to investigate how to handle such corner cases.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 有效性威胁。我们的方法基于一个假设，即在规划任务中的动作之间不存在固有的顺序依赖关系，即派生的约束完全反映了动作之间的约束。这个假设在大多数情况下是成立的，但也存在动作之间固有的顺序依赖关系是常识性并且不需要明确说明的场景。在这种情况下，如果固有依赖关系与从合成计划中得出的约束存在冲突，我们的方法可能会失败。我们将其作为未来的工作来研究如何处理这些极端情况。
- en: Extensions. Our approach can be extended in several directions. First, we can
    explore the use of other LLMs like Claude-3 [[4](#bib.bib4)] and other agent frameworks.
    Given the rather limited performance of current state-of-the-art LLMs when being
    tested by the extended version of PDoctor, we presume it is necessary to further
    gauge the planning capabilities of further advanced LLMs. Integrating PDoctor with
    other mainstream agent frameworks and LLMs is straightforward, as PDoctor does
    not rely on specific LLM or agent framework features.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展。我们的方法可以在多个方向上进行扩展。首先，我们可以探索使用其他 LLM，如 Claude-3 [[4](#bib.bib4)] 和其他代理框架。考虑到当前最先进的
    LLM 在经过 PDoctor 扩展版本测试时表现相当有限，我们认为有必要进一步评估更先进 LLM 的规划能力。将 PDoctor 与其他主流代理框架和 LLM
    进行集成是直接的，因为 PDoctor 不依赖于特定的 LLM 或代理框架特性。
- en: Another straightforward extension is to apply our approach to fine-tune the
    LLMs for planning tasks. The intuition is that PDoctor can generate numerous diverse
    and high-quality test cases with different complexities. More importantly, PDoctor can
    automatically identify which constraints are violated by the LLMs, and therefore,
    it provides valuable feedback to the LLMs to improve their planning capabilities.
    Such an “error-driven” fine-tuning process can be repeated iteratively to enhance
    the LLMs’ planning capabilities. knowledgeable audience may be aware that localizing
    which constraints are violated by the LLMs can be smoothly implemented by using
    the unsat_core function in the Z3 solver.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个直接的扩展是将我们的方法应用于对LLMs进行规划任务的微调。直觉是PDoctor可以生成大量不同复杂度的多样化高质量测试用例。更重要的是，PDoctor可以自动识别LLMs违反了哪些约束，因此，它为LLMs提供了宝贵的反馈，以改进其规划能力。这种“错误驱动”的微调过程可以反复进行，以提高LLMs的规划能力。了解的读者可能知道，通过使用Z3求解器中的unsat_core函数，可以顺利实现定位LLMs违反的约束。
- en: One may also question the feasibility of repairing the detected erroneous plans
    in an “on-the-fly” manner, where we use constraint solvers to generate a new plan
    that satisfies the requirements. This can be achieved by first extracting the
    constraints from an error-triggering user query encountered during daily agent
    usage (not those test query inputs synthesized by PDoctor), then using Z3 to find
    a plan that satisfies the constraints. We clarify, however, that extracting the
    constraints from arbitrary natural language queries in the wild is still in its
    infancy, despite several encouraging progresses [[29](#bib.bib29), [60](#bib.bib60)]
    have been made. An initial consideration is that the extracted constraints might
    be inconsistent or insufficient due to the unstable nature of LLMs. Furthermore,
    the intricate interaction mode — the user query, the tool’s name and description,
    and the return message, all of which may contain the constraints — may complicate
    the constraint extraction process. In contrast, previous work [[29](#bib.bib29),
    [60](#bib.bib60)] mainly focuses on testing the LLM, rather than the agent, on
    well-formed planning questions, neglecting the real-world scenario where the LLM
    agent is required to interact with the user.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 人们还可能质疑在“即时”修复检测到的错误计划的可行性，我们可以使用约束求解器生成一个满足要求的新计划。这可以通过首先从日常代理使用中遇到的错误触发用户查询（而非PDoctor合成的测试查询输入）中提取约束来实现，然后使用Z3找到一个满足这些约束的计划。然而，我们澄清，尽管已有一些鼓舞人心的进展[[29](#bib.bib29),
    [60](#bib.bib60)]，从自然语言查询中提取约束仍处于初期阶段。初步考虑是，由于LLMs的不稳定性，提取的约束可能是不一致或不足的。此外，复杂的交互模式——用户查询、工具的名称和描述，以及返回的消息，都可能包含约束——可能会使约束提取过程复杂化。相比之下，先前的工作[[29](#bib.bib29),
    [60](#bib.bib60)]主要关注在结构良好的规划问题上测试LLM，而忽视了LLM代理与用户互动的实际场景。
- en: 8 Related Work
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 相关工作
- en: Benchmarking LLM Agents. There has been a growing interest in benchmarking LLM
    agents, and several benchmarking suites have been proposed. Wu et al. [[57](#bib.bib57)]
    proposed SmartPlay, a benchmarking suite that contains multiple specialized games,
    aiming to evaluate the understanding, knowledge, and reasoning capabilities of
    LLM agents in a comprehensive manner. Trulens [[1](#bib.bib1)] is another benchmarking
    suite that is designed to evaluate the performance of LLM agents on tasks that
    require complex reasoning and planning. Besides, a series of studies have been
    conducted to gauge the LLM agent from different perspectives, including tool interaction [[20](#bib.bib20)],
    robustness against jailbreak [[63](#bib.bib63)], and safety risk awareness [[35](#bib.bib35),
    [61](#bib.bib61)].
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试LLM代理。对基准测试LLM代理的兴趣日益增加，已经提出了几种基准测试套件。吴等人[[57](#bib.bib57)] 提出了SmartPlay，这是一种包含多个专业游戏的基准测试套件，旨在全面评估LLM代理的理解、知识和推理能力。Trulens[[1](#bib.bib1)]是另一种基准测试套件，旨在评估LLM代理在需要复杂推理和规划的任务上的表现。此外，还进行了一系列研究，从不同角度评估LLM代理，包括工具互动[[20](#bib.bib20)]、对越狱的鲁棒性[[63](#bib.bib63)]以及安全风险意识[[35](#bib.bib35),
    [61](#bib.bib61)]。
- en: Testing LLMs. In line with their remarkable success in various applications,
    LLMs have been emergingly tested to ensure their reliability and robustness across
    different scenarios. A recent trend in testing LLMs is to gauge their logical
    reasoning capabilities, including mathematical reasoning [[45](#bib.bib45)], causal
    inference [[24](#bib.bib24), [31](#bib.bib31)], and planning [[49](#bib.bib49),
    [50](#bib.bib50)]. Among these, the planning capability is particularly crucial
    for LLM as it constitutes the foundation for many applications, such as autonomous
    vehicles [[54](#bib.bib54), [15](#bib.bib15)], robotics [[23](#bib.bib23)], and
    any agent-based systems [[59](#bib.bib59), [39](#bib.bib39), [52](#bib.bib52)].
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 测试LLM。 根据其在各种应用中的显著成功，LLM的测试正在不断进行，以确保其在不同场景中的可靠性和稳健性。最近的测试趋势是评估其逻辑推理能力，包括数学推理 [[45](#bib.bib45)]、因果推断 [[24](#bib.bib24)，[31](#bib.bib31)]，以及规划 [[49](#bib.bib49)，[50](#bib.bib50)]。其中，规划能力对LLM尤为重要，因为它构成了许多应用的基础，如自动驾驶汽车 [[54](#bib.bib54)，[15](#bib.bib15)]、机器人技术 [[23](#bib.bib23)]，以及任何基于代理的系统 [[59](#bib.bib59)，[39](#bib.bib39)，[52](#bib.bib52)]。
- en: 9 Conclusion
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: We have proposed PDoctor, a novel and automated approach to testing and understanding
    the planning ability of LLM agents. We formulate the detection of erroneous planning
    as a constraint satisfiability problem and propose a fully automated framework
    to synthesize diverse and high-quality user inputs for testing. We evaluate PDoctor’s
    effectiveness using three mainstream agent frameworks and two powerful LLMs (GPT-3.5
    and GPT-4). The results show that PDoctor can effectively detect LLM agents’ erroneous
    planning and provide valuable insights into the mechanisms underlying the errors.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了PDoctor，这是一种新颖且自动化的方法，用于测试和理解LLM代理的规划能力。我们将错误规划的检测形式化为约束满足问题，并提出了一个完全自动化的框架，用于合成多样且高质量的用户输入以进行测试。我们通过三种主流代理框架和两种强大的LLM（GPT-3.5和GPT-4）来评估PDoctor的有效性。结果显示，PDoctor可以有效检测LLM代理的错误规划，并提供有关错误机制的有价值的见解。
- en: References
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Trulens, evaluating and testing llm apps. [https://medium.com/trulens](https://medium.com/trulens).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Trulens，评估和测试llm应用。 [https://medium.com/trulens](https://medium.com/trulens)。'
- en: '[2] Designing llm agent tools for due diligence in financial instruments. [https://developers.lseg.com/en/article-catalog/article/designing-llm-agent-tools-for-due-diligence-in-financial-instruments](https://developers.lseg.com/en/article-catalog/article/designing-llm-agent-tools-for-due-diligence-in-financial-instruments),
    2024.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] 设计用于金融工具尽职调查的llm代理工具。 [https://developers.lseg.com/en/article-catalog/article/designing-llm-agent-tools-for-due-diligence-in-financial-instruments](https://developers.lseg.com/en/article-catalog/article/designing-llm-agent-tools-for-due-diligence-in-financial-instruments)，2024。'
- en: '[3] International planning competition. [https://www.icaps-conference.org/competitions/](https://www.icaps-conference.org/competitions/),
    2024.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] 国际规划竞赛。 [https://www.icaps-conference.org/competitions/](https://www.icaps-conference.org/competitions/)，2024。'
- en: '[4] Introducing the next generation of claude. [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family),
    2024.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] 介绍下一代Claude。 [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family)，2024。'
- en: '[5] Openai tools. [https://python.langchain.com/docs/modules/agents/agent_types/openai_tools](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools),
    2024.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Openai工具。 [https://python.langchain.com/docs/modules/agents/agent_types/openai_tools](https://python.langchain.com/docs/modules/agents/agent_types/openai_tools)，2024。'
- en: '[6] Openai’s function callling. [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling),
    2024.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Openai的功能调用。 [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)，2024。'
- en: '[7] Overview of openai’s assistant. [https://platform.openai.com/docs/assistants/overview?context=with-streaming](https://platform.openai.com/docs/assistants/overview?context=with-streaming),
    2024.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Openai助手概述。 [https://platform.openai.com/docs/assistants/overview?context=with-streaming](https://platform.openai.com/docs/assistants/overview?context=with-streaming)，2024。'
- en: '[8] This ai research introduces ‘rafa’: A principled artificial intelligence
    framework for autonomous llm agents with provable sample efficiency. [https://www.marktechpost.com/2023/10/24/this-ai-research-introduces-rafa-a-principled-artificial-intelligence-framework-for-autonomous-llm-agents-with-provable-sample-efficiency/](https://www.marktechpost.com/2023/10/24/this-ai-research-introduces-rafa-a-principled-artificial-intelligence-framework-for-autonomous-llm-agents-with-provable-sample-efficiency/),
    2024.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] 这项AI研究介绍了‘rafa’：一个原则性的人工智能框架，旨在实现自主LLM代理的可证明样本效率。[https://www.marktechpost.com/2023/10/24/this-ai-research-introduces-rafa-a-principled-artificial-intelligence-framework-for-autonomous-llm-agents-with-provable-sample-efficiency/](https://www.marktechpost.com/2023/10/24/this-ai-research-introduces-rafa-a-principled-artificial-intelligence-framework-for-autonomous-llm-agents-with-provable-sample-efficiency/)，2024年。'
- en: '[9] unskript launches ai-powered infrastructure health intelligence platform
    for software teams. [https://markets.businessinsider.com/news/stocks/unskript-launches-ai-powered-infrastructure-health-intelligence-platform-for-software-teams-1032992108](https://markets.businessinsider.com/news/stocks/unskript-launches-ai-powered-infrastructure-health-intelligence-platform-for-software-teams-1032992108),
    2024.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] unskript推出了为软件团队提供AI驱动的基础设施健康智能平台。[https://markets.businessinsider.com/news/stocks/unskript-launches-ai-powered-infrastructure-health-intelligence-platform-for-software-teams-1032992108](https://markets.businessinsider.com/news/stocks/unskript-launches-ai-powered-infrastructure-health-intelligence-platform-for-software-teams-1032992108)，2024年。'
- en: '[10] Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L.,
    Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. Gpt-4 technical
    report. arXiv preprint arXiv:2303.08774 (2023).'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.
    L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., 等。GPT-4技术报告。arXiv预印本arXiv:2303.08774（2023年）。'
- en: '[11] Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., Finn,
    C., Fu, C., Gopalakrishnan, K., Hausman, K., et al. Do as i can, not as i say:
    Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691 (2022).'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., Finn,
    C., Fu, C., Gopalakrishnan, K., Hausman, K., 等。按我所能做的，而非我所说的：将语言与机器人功能相结合。arXiv预印本arXiv:2204.01691（2022年）。'
- en: '[12] Bills, S., Cammarata, N., Mossing, D., Tillman, H., Gao, L., Goh, G.,
    Sutskever, I., Leike, J., Wu, J., and Saunders, W. Language models can explain
    neurons in language models. [https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html)
    (2023).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Bills, S., Cammarata, N., Mossing, D., Tillman, H., Gao, L., Goh, G.,
    Sutskever, I., Leike, J., Wu, J., 和 Saunders, W. 语言模型可以解释语言模型中的神经元。[https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html)（2023年）。'
- en: '[13] Carbonell, J., Etzioni, O., Gil, Y., Joseph, R., Knoblock, C., Minton,
    S., and Veloso, M. Prodigy: An integrated architecture for planning and learning.
    ACM SIGART Bulletin 2, 4 (1991), 51–55.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Carbonell, J., Etzioni, O., Gil, Y., Joseph, R., Knoblock, C., Minton,
    S., 和 Veloso, M. Prodigy：一个集成的规划与学习架构。ACM SIGART公告2, 4（1991年），51-55页。'
- en: '[14] Chase, H. LangChain, Oct. 2022.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Chase, H. LangChain, 2022年10月。'
- en: '[15] Chen, Y., Veer, S., Karkus, P., and Pavone, M. Interactive joint planning
    for autonomous vehicles. IEEE Robotics and Automation Letters (2023).'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Chen, Y., Veer, S., Karkus, P., 和 Pavone, M. 自主车辆的互动联合规划。IEEE机器人与自动化快报（2023年）。'
- en: '[16] Creswell, A., Shanahan, M., and Higgins, I. Selection-inference: Exploiting
    large language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712
    (2022).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Creswell, A., Shanahan, M., 和 Higgins, I. Selection-inference：利用大型语言模型进行可解释的逻辑推理。arXiv预印本arXiv:2205.09712（2022年）。'
- en: '[17] De Moura, L., and Bjørner, N. Z3: An efficient smt solver. In International
    conference on Tools and Algorithms for the Construction and Analysis of Systems
    (2008), Springer, pp. 337–340.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] De Moura, L., 和 Bjørner, N. Z3：一种高效的SMT求解器。国际工具与算法建设与分析系统会议（2008年），Springer，第337-340页。'
- en: '[18] Ghallab, M., Nau, D., and Traverso, P. Automated Planning: theory and
    practice. Elsevier, 2004.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Ghallab, M., Nau, D., 和 Traverso, P. 自动规划：理论与实践。Elsevier，2004年。'
- en: '[19] Huang, J., Chen, X., Mishra, S., Zheng, H. S., Yu, A. W., Song, X., and
    Zhou, D. Large language models cannot self-correct reasoning yet. In Proc. ICLR
    (2024).'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Huang, J., Chen, X., Mishra, S., Zheng, H. S., Yu, A. W., Song, X., 和
    Zhou, D. 大型语言模型尚未能自我修正推理。会议录 ICLR（2024年）。'
- en: '[20] Huang, Y., Shi, J., Li, Y., Fan, C., Wu, S., Zhang, Q., Liu, Y., Zhou,
    P., Wan, Y., Gong, N. Z., et al. Metatool benchmark for large language models:
    Deciding whether to use tools and which to use. arXiv preprint arXiv:2310.03128
    (2023).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Huang, Y., Shi, J., Li, Y., Fan, C., Wu, S., Zhang, Q., Liu, Y., Zhou,
    P., Wan, Y., Gong, N. Z., 等。大型语言模型的MetaTool基准：决定是否使用工具及使用哪些工具。arXiv预印本arXiv:2310.03128（2023年）。'
- en: '[21] Ji, Z., Ma, P., Li, Z., and Wang, S. Benchmarking and explaining large
    language model-based code generation: A causality-centric approach. arXiv preprint
    arXiv:2310.06680 (2023).'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Ji, Z., Ma, P., Li, Z., 和 Wang, S. 基于大型语言模型的代码生成的基准测试与解释：一种以因果关系为中心的方法。arXiv
    预印本 arXiv:2310.06680 (2023)。'
- en: '[22] Jiao, W., Wang, W., Huang, J.-t., Wang, X., Shi, S., and Tu, Z. Is ChatGPT
    A Good Translator? Yes With GPT-4 As The Engine. arXiv preprint arXiv:2301.08745
    (2023).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Jiao, W., Wang, W., Huang, J.-t., Wang, X., Shi, S., 和 Tu, Z. ChatGPT
    是一个好的翻译器吗？是的，使用 GPT-4 作为引擎。arXiv 预印本 arXiv:2301.08745 (2023)。'
- en: '[23] Joshi, S. S., Hutchinson, S., and Tsiotras, P. Les: Locally exploitative
    sampling for robot path planning. In 2023 IEEE International Conference on Robotics
    and Automation (ICRA) (2023), IEEE, pp. 1551–1557.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Joshi, S. S., Hutchinson, S., 和 Tsiotras, P. Les: 用于机器人路径规划的局部开发采样。在 2023
    IEEE 国际机器人与自动化会议 (ICRA) (2023)，IEEE，第 1551–1557 页。'
- en: '[24] Kıcıman, E., Ness, R., Sharma, A., and Tan, C. Causal reasoning and large
    language models: Opening a new frontier for causality. arXiv preprint arXiv:2305.00050
    (2023).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Kıcıman, E., Ness, R., Sharma, A., 和 Tan, C. 因果推理与大型语言模型：开辟因果关系的新前沿。arXiv
    预印本 arXiv:2305.00050 (2023)。'
- en: '[25] Lanham, T., Chen, A., Radhakrishnan, A., Steiner, B., Denison, C., Hernandez,
    D., Li, D., Durmus, E., Hubinger, E., Kernion, J., Lukosiute, K., Nguyen, K.,
    Cheng, N., Joseph, N., Schiefer, N., Rausch, O., Larson, R., McCandlish, S., Kundu,
    S., Kadavath, S., Yang, S., Henighan, T., Maxwell, T., Telleen-Lawton, T., Hume,
    T., Hatfield-Dodds, Z., Kaplan, J., Brauner, J., Bowman, S. R., and Perez, E.
    Measuring faithfulness in chain-of-thought reasoning. arXiv preprint arXiv:2307.13702
    (2023).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Lanham, T., Chen, A., Radhakrishnan, A., Steiner, B., Denison, C., Hernandez,
    D., Li, D., Durmus, E., Hubinger, E., Kernion, J., Lukosiute, K., Nguyen, K.,
    Cheng, N., Joseph, N., Schiefer, N., Rausch, O., Larson, R., McCandlish, S., Kundu,
    S., Kadavath, S., Yang, S., Henighan, T., Maxwell, T., Telleen-Lawton, T., Hume,
    T., Hatfield-Dodds, Z., Kaplan, J., Brauner, J., Bowman, S. R., 和 Perez, E. 测量链式推理中的忠实度。arXiv
    预印本 arXiv:2307.13702 (2023)。'
- en: '[26] Li, Z., Wang, C., Liu, Z., Wang, H., Wang, S., and Gao, C. CCTEST: Testing
    and repairing code completion systems. In Proc. ACM ICSE (2023).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Li, Z., Wang, C., Liu, Z., Wang, H., Wang, S., 和 Gao, C. CCTEST：测试和修复代码补全系统。在
    Proc. ACM ICSE (2023)。'
- en: '[27] Li, Z., Wang, C., Ma, P., Wu, D., Li, T., Wang, S., Gao, C., and Liu,
    Y. Split and merge: Aligning position biases in large language model based evaluators.
    arXiv preprint arXiv:2310.01432 (2023).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Li, Z., Wang, C., Ma, P., Wu, D., Li, T., Wang, S., Gao, C., 和 Liu, Y.
    拆分与合并：在大型语言模型评估器中对齐位置偏差。arXiv 预印本 arXiv:2310.01432 (2023)。'
- en: '[28] Lin, Z., Gou, Z., Liang, T., Luo, R., Liu, H., and Yang, Y. CriticBench:
    Benchmarking LLMs for Critique-Correct Reasoning. arXiv preprint arXiv:2402.14809
    (2024).'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Lin, Z., Gou, Z., Liang, T., Luo, R., Liu, H., 和 Yang, Y. CriticBench:
    基准测试 LLM 的批判性推理。arXiv 预印本 arXiv:2402.14809 (2024)。'
- en: '[29] Liu, B., Jiang, Y., Zhang, X., Liu, Q., Zhang, S., Biswas, J., and Stone,
    P. Llm+ p: Empowering large language models with optimal planning proficiency.
    arXiv preprint arXiv:2304.11477 (2023).'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Liu, B., Jiang, Y., Zhang, X., Liu, Q., Zhang, S., Biswas, J., 和 Stone,
    P. Llm+ p: 赋能大型语言模型以获得最佳规划能力。arXiv 预印本 arXiv:2304.11477 (2023)。'
- en: '[30] Liu, S., Lu, N., Chen, C., and Tang, K. Efficient combinatorial optimization
    for word-level adversarial textual attack. IEEE/ACM Transactions on Audio, Speech,
    and Language Processing 30 (2021), 98–111.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Liu, S., Lu, N., Chen, C., 和 Tang, K. 高效的组合优化用于单词级对抗文本攻击。IEEE/ACM 音频、语音与语言处理交易
    30 (2021)，98–111。'
- en: '[31] Long, S., Schuster, T., Piché, A., de Montreal, U., Research, S., et al.
    Can large language models build causal graphs? arXiv preprint arXiv:2303.05279
    (2023).'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Long, S., Schuster, T., Piché, A., de Montreal, U., Research, S., 等. 大型语言模型能构建因果图吗？arXiv
    预印本 arXiv:2303.05279 (2023)。'
- en: '[32] Lu, Y., Zhang, X., Xu, X., and Yao, W. Learning-based near-optimal motion
    planning for intelligent vehicles with uncertain dynamics. IEEE Robotics and Automation
    Letters (2023).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Lu, Y., Zhang, X., Xu, X., 和 Yao, W. 基于学习的智能车辆近似最优运动规划，具有不确定的动力学。IEEE
    机器人与自动化信函 (2023)。'
- en: '[33] Ma, W., Wu, D., Sun, Y., Wang, T., Liu, S., Zhang, J., Xue, Y., and Liu,
    Y. Combining fine-tuning and LLM-based agents for intuitive smart contract auditing
    with justifications. arXiv preprint arXiv:2403.16073 (2024).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Ma, W., Wu, D., Sun, Y., Wang, T., Liu, S., Zhang, J., Xue, Y., 和 Liu,
    Y. 结合微调和基于 LLM 的代理进行直观智能合约审计及其理由。arXiv 预印本 arXiv:2403.16073 (2024)。'
- en: '[34] McCarthy, J., et al. Situations, actions, and causal laws. Comtex Scientific,
    1963.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] McCarthy, J., 等. 情境、行动和因果法则。Comtex Scientific，1963。'
- en: '[35] Naihin, S., Atkinson, D., Green, M., Hamadi, M., Swift, C., Schonholtz,
    D., Kalai, A. T., and Bau, D. Testing language model agents safely in the wild.
    arXiv preprint arXiv:2311.10538 (2023).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Naihin, S., Atkinson, D., Green, M., Hamadi, M., Swift, C., Schonholtz,
    D., Kalai, A. T., and Bau, D. 安全地在实际环境中测试语言模型代理。arXiv 预印本 arXiv:2311.10538 (2023)。'
- en: '[36] Nilsson, N. J., et al. Shakey the robot, vol. 323. Sri International Menlo
    Park, California, 1984.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Nilsson, N. J., 等。Shakey the robot，第323卷。Sri International Menlo Park,
    California, 1984。'
- en: '[37] Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. Bleu: a method for
    automatic evaluation of machine translation. In Proceedings of the 40th annual
    meeting of the Association for Computational Linguistics (2002), pp. 311–318.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. Bleu: 一种自动评估机器翻译的方法。在第40届计算语言学协会年会上
    (2002)，第311–318页。'
- en: '[38] Payandeh, A., Pluth, D., Hosier, J., Xiao, X., and Gurbani, V. K. How
    susceptible are LLMs to logical fallacies? arXiv preprint arXiv:2308.09853 (2023).'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Payandeh, A., Pluth, D., Hosier, J., Xiao, X., and Gurbani, V. K. 大型语言模型对逻辑谬误的敏感性如何？arXiv
    预印本 arXiv:2308.09853 (2023)。'
- en: '[39] Shao, Y., Li, L., Dai, J., and Qiu, X. Character-llm: A trainable agent
    for role-playing. arXiv preprint arXiv:2310.10158 (2023).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Shao, Y., Li, L., Dai, J., and Qiu, X. Character-llm: 一个可训练的角色扮演代理。arXiv
    预印本 arXiv:2310.10158 (2023)。'
- en: '[40] Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y. Hugginggpt:
    Solving ai tasks with chatgpt and its friends in hugging face. Advances in Neural
    Information Processing Systems 36 (2024).'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y. Hugginggpt:
    使用 ChatGPT 和它的朋友们在 Hugging Face 上解决 AI 任务。Neural Information Processing Systems
    36 (2024)。'
- en: '[41] Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and Yao, S. Reflexion:
    Language agents with verbal reinforcement learning. Advances in Neural Information
    Processing Systems 36 (2024).'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and Yao, S. Reflexion:
    具有语言强化学习的语言代理。Neural Information Processing Systems 36 (2024)。'
- en: '[42] Shridhar, M., Yuan, X., Côté, M.-A., Bisk, Y., Trischler, A., and Hausknecht,
    M. Alfworld: Aligning text and embodied environments for interactive learning.
    arXiv preprint arXiv:2010.03768 (2020).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Shridhar, M., Yuan, X., Côté, M.-A., Bisk, Y., Trischler, A., and Hausknecht,
    M. Alfworld: 对齐文本和具身环境以进行互动学习。arXiv 预印本 arXiv:2010.03768 (2020)。'
- en: '[43] Significant Gravitas. AutoGPT.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Significant Gravitas. AutoGPT。'
- en: '[44] Singhal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W.,
    Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S., et al. Large language models
    encode clinical knowledge. Nature (2023), 1–9.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Singhal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W.,
    Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S., 等。大型语言模型编码临床知识。Nature (2023),
    1–9。'
- en: '[45] Stolfo, A., Jin, Z., Shridhar, K., Schölkopf, B., and Sachan, M. A causal
    framework to quantify the robustness of mathematical reasoning with language models.
    arXiv preprint arXiv:2210.12023 (2022).'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Stolfo, A., Jin, Z., Shridhar, K., Schölkopf, B., and Sachan, M. 量化数学推理的鲁棒性的因果框架。arXiv
    预印本 arXiv:2210.12023 (2022)。'
- en: '[46] Sun, Y., Wu, D., Xue, Y., Liu, H., Ma, W., Zhang, L., Shi, M., and Liu,
    Y. LLM4Vuln: A unified evaluation framework for decoupling and enhancing llms’
    vulnerability reasoning. arXiv preprint arXiv:2401.16185 (2024).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Sun, Y., Wu, D., Xue, Y., Liu, H., Ma, W., Zhang, L., Shi, M., and Liu,
    Y. LLM4Vuln: 一种统一的评估框架，用于解耦和增强大型语言模型的漏洞推理。arXiv 预印本 arXiv:2401.16185 (2024)。'
- en: '[47] Sun, Y., Wu, D., Xue, Y., Liu, H., Wang, H., Xu, Z., Xie, X., and Liu,
    Y. GPTScan: Detecting logic vulnerabilities in smart contracts by combining GPT
    with program analysis. In Proc. ACM ICSE (2024).'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Sun, Y., Wu, D., Xue, Y., Liu, H., Wang, H., Xu, Z., Xie, X., and Liu,
    Y. GPTScan: 通过结合 GPT 和程序分析来检测智能合约中的逻辑漏洞。在 ACM ICSE 会议上 (2024)。'
- en: '[48] Sun, Z., Zhang, J. M., Harman, M., Papadakis, M., and Zhang, L. Automatic
    testing and improvement of machine translation. In Proceedings of the ACM/IEEE
    42nd International Conference on Software Engineering (2020), pp. 974–985.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Sun, Z., Zhang, J. M., Harman, M., Papadakis, M., and Zhang, L. 机器翻译的自动测试与改进。在
    ACM/IEEE 第42届国际软件工程会议上 (2020)，第974–985页。'
- en: '[49] Valmeekam, K., Marquez, M., Olmo, A., Sreedharan, S., and Kambhampati,
    S. PlanBench: An extensible benchmark for evaluating large language models on
    planning and reasoning about change. Advances in Neural Information Processing
    Systems 36 (2024).'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Valmeekam, K., Marquez, M., Olmo, A., Sreedharan, S., and Kambhampati,
    S. PlanBench: 一个可扩展的基准，用于评估大型语言模型在规划和处理变化方面的表现。Neural Information Processing Systems
    36 (2024)。'
- en: '[50] Valmeekam, K., Marquez, M., Sreedharan, S., and Kambhampati, S. On the
    planning abilities of large language models-a critical investigation. Advances
    in Neural Information Processing Systems 36 (2024).'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Valmeekam, K., Marquez, M., Sreedharan, S., and Kambhampati, S. 关于大型语言模型的规划能力——一次关键调查。Neural
    Information Processing Systems 36 (2024)。'
- en: '[51] Wang, S., Wei, Z., Choi, Y., and Ren, X. Can LLMs Reason with Rules? Logic
    Scaffolding for Stress-Testing and Improving LLMs. arXiv preprint arXiv:2402.11442
    (2024).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Wang, S., Wei, Z., Choi, Y., 和 Ren, X. 大语言模型能否进行规则推理？用于压力测试和改进 LLM 的逻辑支架。arXiv
    预印本 arXiv:2402.11442 (2024)。'
- en: '[52] Wang, Z., Cai, S., Chen, G., Liu, A., Ma, X. S., and Liang, Y. Describe,
    explain, plan and select: interactive planning with llms enables open-world multi-task
    agents. Advances in Neural Information Processing Systems 36 (2024).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Wang, Z., Cai, S., Chen, G., Liu, A., Ma, X. S., 和 Liang, Y. 描述、解释、计划和选择：通过
    LLM 进行互动规划以实现开放世界多任务代理。Neural Information Processing Systems 36 (2024)。'
- en: '[53] Wei, A., Haghtalab, N., and Steinhardt, J. Jailbroken: How does LLM safety
    training fail? In Proc. NeurIPS (2023).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Wei, A., Haghtalab, N., 和 Steinhardt, J. Jailbroken：LLM 安全训练如何失败？在 Proc.
    NeurIPS (2023)。'
- en: '[54] Weng, L. LLM Powered Autonomous Agents. [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/),
    2023.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Weng, L. **LLM 驱动的自主代理**。 [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/),
    2023。'
- en: '[55] Wong, W. K., Wang, H., Li, Z., Liu, Z., Wang, S., Tang, Q., Nie, S., and
    Wu, S. Refining decompiled c code with large language models. arXiv preprint arXiv:2310.06530
    (2023).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Wong, W. K., Wang, H., Li, Z., Liu, Z., Wang, S., Tang, Q., Nie, S., 和
    Wu, S. 使用大语言模型精炼反编译的 C 代码。arXiv 预印本 arXiv:2310.06530 (2023)。'
- en: '[56] Wu, X., Li, Y.-L., Sun, J., and Lu, C. Symbol-llm: Leverage language models
    for symbolic system in visual human activity reasoning. Advances in Neural Information
    Processing Systems 36 (2024).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Wu, X., Li, Y.-L., Sun, J., 和 Lu, C. Symbol-llm：利用语言模型进行视觉人类活动推理中的符号系统。Neural
    Information Processing Systems 36 (2024)。'
- en: '[57] Wu, Y., Tang, X., Mitchell, T. M., and Li, Y. Smartplay: A benchmark for
    llms as intelligent agents. arXiv preprint arXiv:2310.01557 (2023).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Wu, Y., Tang, X., Mitchell, T. M., 和 Li, Y. Smartplay：作为智能代理的 LLM 基准测试。arXiv
    预印本 arXiv:2310.01557 (2023)。'
- en: '[58] Xu, Z., Jain, S., and Kankanhalli, M. Hallucination is inevitable: An
    innate limitation of large language models. arXiv preprint arXiv:2401.11817 (2023).'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Xu, Z., Jain, S., 和 Kankanhalli, M. 幻觉是不可避免的：大语言模型的固有局限性。arXiv 预印本 arXiv:2401.11817
    (2023)。'
- en: '[59] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao,
    Y. React: Synergizing reasoning and acting in language models. arXiv preprint
    arXiv:2210.03629 (2022).'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., 和 Cao,
    Y. React：在语言模型中协同推理和行动。arXiv 预印本 arXiv:2210.03629 (2022)。'
- en: '[60] Ye, X., Chen, Q., Dillig, I., and Durrett, G. Satlm: Satisfiability-aided
    language models using declarative prompting. Advances in Neural Information Processing
    Systems 36 (2024).'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Ye, X., Chen, Q., Dillig, I., 和 Durrett, G. Satlm：利用声明式提示的可满足性辅助语言模型。Neural
    Information Processing Systems 36 (2024)。'
- en: '[61] Yuan, T., He, Z., Dong, L., Wang, Y., Zhao, R., Xia, T., Xu, L., Zhou,
    B., Li, F., Zhang, Z., et al. R-judge: Benchmarking safety risk awareness for
    llm agents. arXiv preprint arXiv:2401.10019 (2024).'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Yuan, T., He, Z., Dong, L., Wang, Y., Zhao, R., Xia, T., Xu, L., Zhou,
    B., Li, F., Zhang, Z., 等。R-judge：对 LLM 代理的安全风险意识进行基准测试。arXiv 预印本 arXiv:2401.10019
    (2024)。'
- en: '[62] Zeng, Z., Yu, J., Gao, T., Meng, Y., Goyal, T., and Chen, D. Evaluating
    large language models at evaluating instruction following. arXiv preprint arXiv:2310.07641
    (2023).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Zeng, Z., Yu, J., Gao, T., Meng, Y., Goyal, T., 和 Chen, D. 评估大语言模型在指令遵循评估中的表现。arXiv
    预印本 arXiv:2310.07641 (2023)。'
- en: '[63] Zhan, Q., Liang, Z., Ying, Z., and Kang, D. Injecagent: Benchmarking indirect
    prompt injections in tool-integrated large language model agents. arXiv preprint
    arXiv:2403.02691 (2024).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Zhan, Q., Liang, Z., Ying, Z., 和 Kang, D. Injecagent：在工具集成的大语言模型代理中基准测试间接提示注入。arXiv
    预印本 arXiv:2403.02691 (2024)。'
- en: '[64] Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., and Artzi, Y. Bertscore:
    Evaluating text generation with bert. arXiv preprint arXiv:1904.09675 (2019).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., 和 Artzi, Y. Bertscore：使用
    BERT 评估文本生成。arXiv 预印本 arXiv:1904.09675 (2019)。'
