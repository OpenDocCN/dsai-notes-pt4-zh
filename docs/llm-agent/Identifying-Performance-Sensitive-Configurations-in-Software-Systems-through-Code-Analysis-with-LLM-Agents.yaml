- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:44:00'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:44:00
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Identifying Performance-Sensitive Configurations in Software Systems through
    Code Analysis with LLM Agents
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过LLM代理进行代码分析以识别软件系统中的性能敏感配置
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.12806](https://ar5iv.labs.arxiv.org/html/2406.12806)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.12806](https://ar5iv.labs.arxiv.org/html/2406.12806)
- en: Zehao Wang, Dong Jae Kim, Tse-Husn (Peter) Chen
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Zehao Wang, Dong Jae Kim, Tse-Husn (Peter) Chen
- en: Software PErformance, Analysis and Reliability (SPEAR) Lab
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 软件性能、分析与可靠性（SPEAR）实验室
- en: Concordia University, Montreal, Canada
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 康考迪亚大学，加拿大蒙特利尔
- en: w_zeha@encs.concordia.ca, k_dongja@encs.concordia.ca, peterc@encs.concordia.ca
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: w_zeha@encs.concordia.ca, k_dongja@encs.concordia.ca, peterc@encs.concordia.ca
- en: Abstract.
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Configuration settings are essential for tailoring software behavior to meet
    specific performance requirements. However, incorrect configurations are widespread,
    and identifying those that impact system performance is challenging due to the
    vast number and complexity of possible settings. In this work, we present PerfSense,
    a lightweight framework that leverages Large Language Models (LLMs) to efficiently
    identify performance-sensitive configurations with minimal overhead. PerfSense
    employs LLM agents to simulate interactions between developers and performance
    engineers using advanced prompting techniques such as prompt chaining and retrieval-augmented
    generation (RAG). Our evaluation of seven open-source Java systems demonstrates
    that PerfSense achieves an average accuracy of 64.77% in classifying performance-sensitive
    configurations, outperforming both our LLM baseline (50.36%) and the previous
    state-of-the-art method (61.75%). Notably, our prompt chaining technique improves
    recall by 10% to 30% while maintaining similar precision levels. Additionally,
    a manual analysis of 362 misclassifications reveals common issues, including LLMs’
    misunderstandings of requirements (26.8%). In summary, PerfSense significantly
    reduces manual effort in classifying performance-sensitive configurations and
    offers valuable insights for future LLM-based code analysis research.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 配置设置对于调整软件行为以满足特定性能要求至关重要。然而，不正确的配置普遍存在，由于可能的设置数量庞大且复杂，识别那些影响系统性能的配置非常具有挑战性。在这项工作中，我们提出了PerfSense，一个轻量级框架，利用大型语言模型（LLMs）以最小的开销高效识别性能敏感的配置。PerfSense使用LLM代理模拟开发人员与性能工程师之间的交互，采用高级提示技术，如提示链和检索增强生成（RAG）。我们对七个开源Java系统的评估表明，PerfSense在分类性能敏感配置方面的平均准确率达到64.77%，超越了我们的LLM基准（50.36%）和之前的最先进方法（61.75%）。值得注意的是，我们的提示链技术提高了10%到30%的召回率，同时保持了类似的精准度。此外，对362个误分类的手动分析揭示了常见问题，包括LLM对需求的误解（26.8%）。总之，PerfSense显著减少了分类性能敏感配置的人工工作，并为未来基于LLM的代码分析研究提供了有价值的见解。
- en: Large language model, Configuration, Performance, Multi-Agent
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型、配置、性能、多代理
- en: 1\. Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Modern software systems feature numerous configuration options, enabling customization
    for diverse workloads and hardware platforms (Singh et al., [2016](#bib.bib44);
    Bao et al., [2018](#bib.bib3)). While these configurations provide flexibility,
    some configurations, known as performance-sensitive configurations, can impact
    system performance when their values change. Developers need to identify and understand
    the impact of such configurations to ensure they are set correctly, maintaining
    system performance and behavior. However, due to the large volume of configurations,
    pinpointing performance-sensitive configurations is time-consuming (Jin et al.,
    [2012](#bib.bib21); Han and Yu, [2016a](#bib.bib17)) and incorrect settings are
    a common source of system misbehavior and performance degradation (Ganapathi et al.,
    [2004](#bib.bib14); community, [[n.d.]](#bib.bib10)). Hence, automated approaches
    to quickly find performance-sensitive configurations that require special attention
    or further investigation are important to alleviate developers burden (Yonkovit,
    [[n.d.]](#bib.bib57); Tian et al., [2015](#bib.bib45)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现代软件系统具有众多配置选项，支持针对不同的工作负载和硬件平台进行定制（Singh et al., [2016](#bib.bib44); Bao et
    al., [2018](#bib.bib3)）。虽然这些配置提供了灵活性，但某些配置，即性能敏感配置，当其值发生变化时，可能会影响系统性能。开发人员需要识别和理解这些配置的影响，以确保它们被正确设置，从而保持系统性能和行为。然而，由于配置数量庞大，确定性能敏感配置是耗时的（Jin
    et al., [2012](#bib.bib21); Han and Yu, [2016a](#bib.bib17)），且不正确的设置是系统异常行为和性能下降的常见原因（Ganapathi
    et al., [2004](#bib.bib14); community, [[n.d.]](#bib.bib10)）。因此，自动化的方法用于快速发现需要特别关注或进一步调查的性能敏感配置，对减轻开发人员的负担非常重要（Yonkovit,
    [[n.d.]](#bib.bib57); Tian et al., [2015](#bib.bib45)）。
- en: Performance experts have various tools at their disposal to assess performance-sensitive
    configurations. Alongside performance profiling tools (ej technologies, [[n.d.]](#bib.bib13);
    visualvm, [[n.d.]](#bib.bib50); Bornholt and Torlak, [2018](#bib.bib4)), they
    can identify inefficient code patterns (Chen et al., [2014](#bib.bib7); Liu et al.,
    [2014](#bib.bib30); Nistor et al., [2015](#bib.bib35)), and utilize data-flow
    and dynamic analysis to find performance-sensitive configurations (Li et al.,
    [2020](#bib.bib23); Lillack et al., [2014](#bib.bib27)). However, as highlighted
    by  Velez et al. ([2022a](#bib.bib48)), the adoption of these tools faces usability
    challenges for performance experts when analyzing the performance impact of configurations.
    These challenges arise from (1) a lack of comprehensive understanding of the codebase
    and its intricate interactions across multiple components, (2) difficulties in
    identifying the code affected by performance-sensitive configurations, and (3)
    the intricate cause-and-effect relationship between performance-sensitive configurations
    and the corresponding source code. Consequently, performance engineers may face
    challenges in accurately identifying the performance sensitivity of configurations.
    Effective collaboration between developers and performance engineers is crucial
    for overcoming these challenges and effectively identifying performance-sensitive
    configurations. Developers possess in-depth knowledge about the codebase and its
    functionality, while performance engineers specialize in analyzing performance-related
    issues. Leveraging their complementary expertise enables more thorough code analysis
    and more accurate classification of performance-sensitive configurations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 性能专家拥有多种工具来评估性能敏感配置。除了性能分析工具（ej technologies, [[n.d.]](#bib.bib13); visualvm,
    [[n.d.]](#bib.bib50); Bornholt and Torlak, [2018](#bib.bib4)），他们还可以识别低效的代码模式（Chen
    et al., [2014](#bib.bib7); Liu et al., [2014](#bib.bib30); Nistor et al., [2015](#bib.bib35)），并利用数据流和动态分析来查找性能敏感配置（Li
    et al., [2020](#bib.bib23); Lillack et al., [2014](#bib.bib27)）。然而，正如Velez et
    al. ([2022a](#bib.bib48)) 强调的那样，这些工具在分析配置的性能影响时面临可用性挑战。这些挑战来源于：（1）对代码库及其多个组件之间复杂交互的缺乏全面理解，（2）识别受性能敏感配置影响的代码的困难，以及（3）性能敏感配置与相应源代码之间复杂的因果关系。因此，性能工程师可能在准确识别配置的性能敏感性方面面临挑战。开发人员和性能工程师之间的有效协作对于克服这些挑战并有效识别性能敏感配置至关重要。开发人员对代码库及其功能有深入了解，而性能工程师专注于分析性能相关问题。利用他们互补的专业知识可以实现更全面的代码分析和更准确的性能敏感配置分类。
- en: The rise of Large Language Models (LLMs) is revolutionizing programming and
    software engineering. Trained on vast code datasets, LLMs understand code deeply
    and excel in various code-related tasks. With tools like ChatGPT (OpenAI, [2023](#bib.bib36))
    and LLaMA (Touvron et al., [2023](#bib.bib46)), researchers showcase LLMs’ potential
    in tasks like generating commit messages (Zhang et al., [2024](#bib.bib60)), resolving
    merge conflicts (Shen et al., [2023](#bib.bib43)), creating tests (Xie et al.,
    [2023](#bib.bib53); Yuan et al., [2023](#bib.bib58); Schäfer et al., [2023](#bib.bib40)),
    renaming methods (AlOmar et al., [2024](#bib.bib2)), and aiding in log analytics (Ma
    et al., [2024b](#bib.bib32), [a](#bib.bib33)). Given the complexity of collaboration
    during software engineering tasks, using LLM agents stands out as a promising
    direction to replicate human workflows. Specifically, multi-agent systems have
    achieved significant progress in solving complex tasks by assigning agents to
    specific roles and emulating collaborative activities in software engineering
    practice (Hong et al., [2023](#bib.bib19); Dong et al., [2023](#bib.bib12); Qian
    et al., [2023](#bib.bib38)). For example, Dong et al. ([2023](#bib.bib12)) developed
    a self-collaboration framework, assigning LLM agents to work as distinct experts
    for sub-tasks in software development. Qian et al. ([2023](#bib.bib38)) proposed
    an end-to-end framework for software development through self-communication among
    the agents.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的崛起正在革新编程和软件工程。经过大量代码数据集的训练，LLMs 对代码有深刻的理解，并在各种与代码相关的任务中表现出色。借助像
    ChatGPT（OpenAI，[2023](#bib.bib36)）和 LLaMA（Touvron et al.，[2023](#bib.bib46)）这样的工具，研究人员展示了
    LLMs 在生成提交信息（Zhang et al.，[2024](#bib.bib60)）、解决合并冲突（Shen et al.，[2023](#bib.bib43)）、创建测试（Xie
    et al.，[2023](#bib.bib53)；Yuan et al.，[2023](#bib.bib58)；Schäfer et al.，[2023](#bib.bib40)）、重命名方法（AlOmar
    et al.，[2024](#bib.bib2)）和帮助日志分析（Ma et al.，[2024b](#bib.bib32)，[a](#bib.bib33)）中的潜力。考虑到软件工程任务中的协作复杂性，使用
    LLM 代理作为复制人类工作流的有希望的方向尤为突出。具体而言，多代理系统通过将代理分配到特定角色并模拟软件工程实践中的协作活动，已在解决复杂任务方面取得了显著进展（Hong
    et al.，[2023](#bib.bib19)；Dong et al.，[2023](#bib.bib12)；Qian et al.，[2023](#bib.bib38)）。例如，Dong
    et al.（[2023](#bib.bib12)）开发了一个自我协作框架，将 LLM 代理分配为软件开发中不同子任务的专家。Qian et al.（[2023](#bib.bib38)）提出了一个通过代理之间自我沟通的端到端软件开发框架。
- en: 'Inspired by multi-agent, we introduce PerfSense, a lightweight framework designed
    to effectively classify performance-sensitive configurations using Large Language
    Models (LLMs) as multi-agent systems. PerfSense leverages the collaborative capabilities
    of LLMs to mimic the interactions between developers and performance engineers,
    enabling a thorough analysis of the performance sensitivity of configurations.
    PerfSense employs two primary agents: DevAgent and PerfAgent. DevAgent focuses
    on retrieving relevant source code and documentation related to the configurations
    and conducting performance-aware code reviews. PerfAgent, on the other hand, utilizes
    the insights from DevAgent to classify configurations based on their performance
    sensitivity. This collaboration is facilitated through advanced prompting techniques
    such as prompt chaining and retrieval-augmented generation (RAG), which enhance
    the agents’ understanding and analytical capabilities.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 受到多代理系统的启发，我们引入了 PerfSense，这是一个轻量级框架，旨在利用大型语言模型（LLMs）作为多代理系统来有效地分类性能敏感配置。PerfSense
    利用 LLM 的协作能力，模拟开发人员和性能工程师之间的互动，从而全面分析配置的性能敏感性。PerfSense 采用了两个主要代理：DevAgent 和 PerfAgent。DevAgent
    专注于检索与配置相关的源代码和文档，并进行性能感知的代码审查。PerfAgent 则利用 DevAgent 的洞察力，根据性能敏感性对配置进行分类。这种协作通过先进的提示技术如提示链和增强检索生成（RAG）得以实现，增强了代理的理解和分析能力。
- en: To address the challenge of navigating a large codebase with limited LLM context
    size, PerfSense iteratively breaks down complex tasks into manageable subtasks.
    Specifically, PerfAgent iteratively communicates with DevAgent to gather and analyze
    relevant source code associated with the configurations under scrutiny. Through
    a series of prompt chains, PerfAgent refines its understanding by requesting specific
    details, clarifications, and performance-related insights from DevAgent. This
    iterative communication ensures that PerfAgent accumulates a comprehensive knowledge
    base without exceeding the context size limitations, enabling accurate classification
    of performance-sensitive configurations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决在有限LLM上下文大小下导航大型代码库的挑战，PerfSense 迭代地将复杂任务拆分为可管理的子任务。具体来说，PerfAgent 通过与 DevAgent
    迭代沟通来收集和分析与被审查配置相关的源代码。通过一系列提示链，PerfAgent 通过请求具体细节、澄清和与性能相关的见解来完善其理解。这种迭代沟通确保
    PerfAgent 在不超过上下文大小限制的情况下积累全面的知识库，从而实现对性能敏感配置的准确分类。
- en: Our evaluation of seven open-source systems demonstrates that PerfSense achieves
    64.77% accuracy in classifying performance-sensitive configurations, outperforming
    state-of-the-art technique (Chen et al., [2023a](#bib.bib9)) and our LLM baseline
    with an average accuracy of 61.75% and 50.36%, respectively. Compared to prior
    technique (Chen et al., [2023a](#bib.bib9)) that requires tens or hundreds of
    hours to collect performance data manually, PerfSense is lightweight and requires
    minimal human effort.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对七个开源系统的评估表明，PerfSense 在分类性能敏感配置方面达到了64.77%的准确率，优于具有61.75%和50.36%平均准确率的最先进技术（Chen
    等，[2023a](#bib.bib9)）和我们的LLM基准。与需要数十或数百小时手动收集性能数据的先前技术（Chen 等，[2023a](#bib.bib9)）相比，PerfSense
    轻量且需要最少的人力。
- en: 'In summary, we make the following contributions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们做出了以下贡献：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Our evaluation of seven open-source systems demonstrates that PerfSense achieves
    an average accuracy of 64.77%, surpassing the state-of-the-art approaches with
    an average accuracy of 61.75%.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对七个开源系统的评估表明，PerfSense 在分类性能敏感配置方面达到了64.77%的平均准确率，超越了具有61.75%平均准确率的最先进方法。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We proposed a new LLM-based code analysis technique that employs two primary
    agents, DevAgent and PerfAgent, to navigate large codebases with limited LLM context
    sizes through advanced prompting techniques such as prompt chaining and retrieval-augmented
    generation (RAG).
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新的基于LLM的代码分析技术，采用两个主要代理：DevAgent 和 PerfAgent，通过先进的提示技术如提示链和检索增强生成（RAG），在有限的LLM上下文大小下导航大型代码库。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We analyzed the effect of different prompting components that we implemented
    in PerfSense. We found that our prompt chaining technique significantly improves
    the recall (10% to 30% improvement) while maintaining a similar level of precision.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们分析了在 PerfSense 中实施的不同提示组件的效果。我们发现我们的提示链技术显著提高了召回率（提高了10%到30%），同时保持了相似的精确度水平。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conducted a manual study of the 362 misclassified configurations, identifying
    key reasons for misclassification, including LLM’s misunderstanding of requirements
    (26.8%) and incorrect interpretation of performance impact (10.0%).
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对362个错误分类的配置进行了手动研究，识别出错误分类的主要原因，包括LLM对需求的误解（26.8%）和对性能影响的错误解释（10.0%）。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We provided a discussion on the implications of our findings and highlight future
    direction on LLM-based code analysis.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们讨论了研究结果的影响，并强调了基于LLM的代码分析的未来方向。
- en: In conclusion, by leveraging multi-agent collaboration and advanced prompting
    techniques, PerfSense provides an efficient technique for classifying performance-sensitive
    configuration, one of the most important first steps in understanding system performance.
    PerfSense also presents a novel code navigation approach that may inspire future
    LLM-based research on code analysis.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，通过利用多代理协作和先进的提示技术，PerfSense 提供了一种高效的性能敏感配置分类技术，这是理解系统性能的重要第一步之一。PerfSense
    还提出了一种新颖的代码导航方法，可能会激发未来基于LLM的代码分析研究。
- en: Paper Organization. Section [2](#S2 "2\. Background ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents") provides
    the background of the problem and technique. Section [3](#S3 "3\. Related Work
    ‣ Identifying Performance-Sensitive Configurations in Software Systems through
    Code Analysis with LLM Agents") discusses related work. Section [4](#S4 "4\. Design
    of PerfSense ‣ Identifying Performance-Sensitive Configurations in Software Systems
    through Code Analysis with LLM Agents") presents the details of PerfSense. Section [5](#S5
    "5\. Evaluation ‣ Identifying Performance-Sensitive Configurations in Software
    Systems through Code Analysis with LLM Agents") shows the evaluation results.
    Section [6](#S6 "6\. Discussion ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") discusses the findings.
    Section [7](#S7 "7\. Threats to Validity ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") discusses the threats
    to validity. Section [8](#S8 "8\. Conclusion ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents") concludes
    the paper.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 论文组织。第[2](#S2 "2\. Background ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents")节提供了问题和技术的背景。第[3](#S3
    "3\. Related Work ‣ Identifying Performance-Sensitive Configurations in Software
    Systems through Code Analysis with LLM Agents")节讨论了相关工作。第[4](#S4 "4\. Design of
    PerfSense ‣ Identifying Performance-Sensitive Configurations in Software Systems
    through Code Analysis with LLM Agents")节介绍了PerfSense的细节。第[5](#S5 "5\. Evaluation
    ‣ Identifying Performance-Sensitive Configurations in Software Systems through
    Code Analysis with LLM Agents")节展示了评估结果。第[6](#S6 "6\. Discussion ‣ Identifying
    Performance-Sensitive Configurations in Software Systems through Code Analysis
    with LLM Agents")节讨论了发现。第[7](#S7 "7\. Threats to Validity ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents")节讨论了有效性威胁。第[8](#S8
    "8\. Conclusion ‣ Identifying Performance-Sensitive Configurations in Software
    Systems through Code Analysis with LLM Agents")节总结了论文。
- en: 2\. Background
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 背景
- en: In this section, we first discuss the definition and importance of performance-sensitive
    configuration. Then, we provide background on large language models (LLM) agents
    and retrieval-augmented generation (RAG).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先讨论性能敏感配置的定义和重要性。然后，我们提供有关大语言模型（LLM）代理和检索增强生成（RAG）的背景信息。
- en: 2.1\. Performance-Sensitive Configurations
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 性能敏感配置
- en: Software systems often contain various configuration parameters to provide flexibility
    in deployment and execution (Singh et al., [2016](#bib.bib44); Bao et al., [2018](#bib.bib3)).
    Some configurations, known as performance-sensitive configurations, affect performance
    when their values change. For example, an application’s name is generally not
    performance-sensitive, whereas memory allocation settings can significantly impact
    performance (Yin et al., [2011](#bib.bib56); Chen et al., [2016](#bib.bib6)).
    Identifying these configurations is crucial, as their usage directly impacts system
    efficiency and stability. However, developers may not always be aware of the performance
    implications of configuration changes, leading to common misconfigurations, impacting
    overall system performance (Yin et al., [2011](#bib.bib56); Xu et al., [2013](#bib.bib54);
    Chen et al., [2016](#bib.bib6); Han and Yu, [2016b](#bib.bib18); Velez et al.,
    [2022b](#bib.bib49)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 软件系统通常包含各种配置参数，以提供在部署和执行时的灵活性（Singh 等，[2016](#bib.bib44); Bao 等，[2018](#bib.bib3)）。一些配置，称为性能敏感配置，会在其值改变时影响性能。例如，应用程序的名称通常不是性能敏感的，而内存分配设置则可以显著影响性能（Yin
    等，[2011](#bib.bib56); Chen 等，[2016](#bib.bib6)）。识别这些配置至关重要，因为它们的使用直接影响系统效率和稳定性。然而，开发人员可能并不总是意识到配置变化的性能影响，从而导致常见的配置错误，影响整体系统性能（Yin
    等，[2011](#bib.bib56); Xu 等，[2013](#bib.bib54); Chen 等，[2016](#bib.bib6); Han 和
    Yu，[2016b](#bib.bib18); Velez 等，[2022b](#bib.bib49)）。
- en: Determining which configurations are performance-sensitive is challenging, given
    the high number of configurations and complex interactions among various system
    components (Zhang et al., [2015](#bib.bib59)), the absence of transparent documentation
    or feedback concerning the performance implications of each setting (Yin et al.,
    [2011](#bib.bib56)), and the complexity and time-intensive nature of performance
    testing (Yonkovit, [[n.d.]](#bib.bib57)). Performance engineers need to conduct
    load tests to evaluate the performance sensitivity and impacts of various configurations.
    These tests involve altering the values of configuration parameters and assessing
    their impacts on system performance (Zhang et al., [2015](#bib.bib59); Singh et al.,
    [2016](#bib.bib44); Wang et al., [2021](#bib.bib52); Vitui and Chen, [2021](#bib.bib51)).
    Therefore, an important step that can reduce the testing cost is to only conduct
    such tests on performance-sensitive configurations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 确定哪些配置是性能敏感的具有挑战性，原因包括配置数量多和各种系统组件之间的复杂交互（Zhang et al., [2015](#bib.bib59)）、缺乏关于每个设置性能影响的透明文档或反馈（Yin
    et al., [2011](#bib.bib56)）、以及性能测试的复杂性和耗时性（Yonkovit, [[n.d.]](#bib.bib57)）。性能工程师需要进行负载测试，以评估各种配置的性能敏感性和影响。这些测试包括改变配置参数的值并评估其对系统性能的影响（Zhang
    et al., [2015](#bib.bib59); Singh et al., [2016](#bib.bib44); Wang et al., [2021](#bib.bib52);
    Vitui and Chen, [2021](#bib.bib51)）。因此，减少测试成本的一个重要步骤是仅对性能敏感的配置进行测试。
- en: While developers implement code functionality with the best coding standards
    in mind, they may not always adhere to best-performance engineering practices.
    In collaborative efforts, developers and performance engineers work together to
    identify performance-sensitive configurations. Performance engineers leverage
    domain-specific knowledge to design and implement performance tests that uncover
    configuration sensitivities. However, performance engineers need the assistance
    of developers who have an in-depth understanding of the codebase to navigate across
    multiple source code components. Hence, to narrow down performance-sensitive configurations
    that impact overall system performance, there must be synergy in sharing knowledge
    between developers and performance engineers.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管开发人员在实施代码功能时会考虑最佳编码标准，但他们可能并不总是遵循最佳性能工程实践。在协作过程中，开发人员和性能工程师需要共同努力以识别性能敏感的配置。性能工程师利用领域特定的知识来设计和实施性能测试，以揭示配置的敏感性。然而，性能工程师需要具有深入代码库理解的开发人员的协助，以便在多个源代码组件之间导航。因此，为了缩小影响整体系统性能的性能敏感配置，开发人员和性能工程师之间必须在知识共享方面形成协同作用。
- en: 2.2\. LLM-based Multi-agent Framework
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. 基于LLM的多代理框架
- en: Large language models (LLMs) are pre-trained using vast datasets comprising
    a wide range of texts, such as documentation and source code. The core of LLM
    agents consists of large language models (LLMs) designed to understand questions
    and generate human-like responses. These agents refine their responses based on
    feedback (Madaan et al., [2024](#bib.bib34)), use memory mechanisms to learn from
    historical experiences (Li et al., [2024b](#bib.bib25)), retrieve informative
    knowledge to improve prompting and generate better responses (Zhao et al., [2023](#bib.bib61)),
    and collaborate with other LLM agents to solve complex tasks in a multi-agent
    process (Guo et al., [2024](#bib.bib16)). By using prompting, agents can assume
    specific roles (e.g., developer or tester) and provide domain-specific responses (Deshpande
    et al., [2023](#bib.bib11)). In particular, a multi-agent system has been shown
    to improve the capabilities of individual LLM agents by enabling collaboration
    among agents, each with specialized abilities (Hong et al., [2023](#bib.bib19);
    Chan et al., [2023](#bib.bib5)). Multiple LLM agents can share domain expertise
    and make collective decisions. Effective communication patterns are crucial for
    optimizing the overall performance of a multi-agent framework, allowing them to
    tackle complex projects using a divide-and-conquer approach (Chen et al., [2023b](#bib.bib8)).
    Finally, with modern frameworks like LangChain (langchain, [2023](#bib.bib22)),
    one key characteristic of LLM agents is their ability to interact with external
    tools to perform tasks similarly to humans. For example, an LLM agent acting as
    a test engineer can generate test cases, use test automation tools to collect
    code coverage, and answer further queries based on the gathered information.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是使用包括文档和源代码在内的大量数据集进行预训练的。LLM代理的核心包括旨在理解问题并生成类似人类回答的大型语言模型（LLMs）。这些代理根据反馈（Madaan
    et al., [2024](#bib.bib34)）来优化其回答，使用记忆机制从历史经验中学习（Li et al., [2024b](#bib.bib25)），检索信息以改善提示并生成更好的回答（Zhao
    et al., [2023](#bib.bib61)），并与其他LLM代理协作以在多代理过程中解决复杂任务（Guo et al., [2024](#bib.bib16)）。通过使用提示，代理可以承担特定角色（例如，开发人员或测试人员）并提供领域特定的回答（Deshpande
    et al., [2023](#bib.bib11)）。特别地，已显示多代理系统通过使每个代理能够协作并具有专门能力来提高个体LLM代理的能力（Hong et
    al., [2023](#bib.bib19); Chan et al., [2023](#bib.bib5)）。多个LLM代理可以共享领域专长并做出集体决策。有效的沟通模式对于优化多代理框架的整体性能至关重要，使它们能够通过分而治之的方法处理复杂项目（Chen
    et al., [2023b](#bib.bib8)）。最后，使用现代框架如LangChain（langchain, [2023](#bib.bib22)），LLM代理的一个关键特性是它们能够与外部工具互动，执行类似于人类的任务。例如，一个作为测试工程师的LLM代理可以生成测试用例，使用测试自动化工具收集代码覆盖率，并根据收集到的信息回答进一步的问题。
- en: In this paper, we propose PerfSense, which leverages LLM agents to emulate the
    collaboration between developers and performance engineers. PerfSense analyzes
    the source code and classifies whether a configuration is performance-sensitive.
    PerfSense is zero-shot and unsupervised. It requires minimal input from developers
    and achieves better results than the state-of-the-art technique on classifying
    performance-sensitive configuration (Chen et al., [2023a](#bib.bib9)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了PerfSense，它利用LLM代理模拟开发人员和性能工程师之间的协作。PerfSense分析源代码并分类配置是否对性能敏感。PerfSense是零样本和无监督的。它只需开发人员的最小输入，并在分类性能敏感配置方面优于最先进的技术
    (Chen et al., [2023a](#bib.bib9))。
- en: 3\. Related Work
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 相关工作
- en: 'In this section, we discuss existing research and literature on three topics:
    1) Performance Analysis of Configuration; 2) Using LLMs to Analyze Configuration;
    and 3) Multi-Agent-Based Code Analysis.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了关于三个主题的现有研究和文献：1) 配置的性能分析；2) 使用LLMs分析配置；和3) 基于多代理的代码分析。
- en: 3.1\. Performance Analysis of Configuration
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 配置的性能分析
- en: Some previous research aims to analyze the performance of configuration to help
    developers understand the performance issue during the software configuration
    tuning. ConfigCrusher (Velez et al., [2020](#bib.bib47)) relies on static taint
    analysis to reveal the relationship between an option and the affected code regions,
    dynamically analyze the influence of configuration options on the regions’ performance,
    and build the performance-influence model through white-box performance analysis.
    DiagConfig (Chen et al., [2023a](#bib.bib9)) leverages static taint analysis to
    identify the dependencies between performance-related operations and options.
    Through manual performance experiments and labeling on training systems, they
    build a random forest model to classify the performance-sensitive configurations.
    Different from the above work, in our work, we employ the LLM agent alongside
    static code analysis, specifically the call graph analysis, to study the performance
    of configurations. Given LLMs’ promising performance in understanding code, call
    graph analysis for LLMs can provide more information and incur lower overhead
    compared to taint analysis. More importantly, our approach is zero-shot and reduces
    minimal human effort, which can help developers efficiently identical potential
    performance-sensitive configurations for further analysis.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一些早期研究旨在分析配置性能，以帮助开发人员理解软件配置调整过程中的性能问题。ConfigCrusher（Velez 等，[2020](#bib.bib47)）依赖静态污点分析来揭示选项与受影响代码区域之间的关系，动态分析配置选项对区域性能的影响，并通过白盒性能分析构建性能影响模型。DiagConfig（Chen
    等，[2023a](#bib.bib9)）利用静态污点分析来识别与性能相关的操作和选项之间的依赖关系。通过在训练系统上进行手动性能实验和标注，他们建立了一个随机森林模型来分类性能敏感的配置。与上述工作不同的是，我们的工作结合了LLM代理和静态代码分析，特别是调用图分析，来研究配置的性能。考虑到LLM在理解代码方面的良好表现，LLM的调用图分析能够提供更多的信息，并且相比于污点分析，开销更低。更重要的是，我们的方法是零样本的，减少了最小的人力投入，这可以帮助开发人员高效地识别潜在的性能敏感配置，以便进一步分析。
- en: 3.2\. Using LLMs to Analyze Configuration
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 使用LLM分析配置
- en: Recently, large language models have shown promising performance on various
    software engineer tasks, such as code generation and summarization. Much research
    leveraged LLMs for tasks related to software configuration.  Lian et al. ([2024](#bib.bib26))
    proposed an LLM-based framework, Ciri, using few-shot learning and prompt engineering
    to validate the correctness of configuration files from the file level and parameter
    level. From the evaluation of real-world misconfigurations, comprising 64 configurations,
    and synthesized misconfigurations involving 1,582 parameters, Ciri achieves F1
    scores of 0.79 and 0.65 at the file level and parameter level, respectively. Liu
    et al. ([2024b](#bib.bib31)) introduced the LLM-CompDroid framework, which employs
    LLMs alongside the bug resolution tool to address configuration compatibility
    issues in Android applications. Their framework surpasses the state-of-the-art
    (SOTA) methods by at least 9.8% and 10.4% in the Correct and Correct@k metrics,
    respectively, respectively. Shan et al. ([2024](#bib.bib42)) came up with the
    framework, LogConfigLocalizer, which leverages Large Language Models and logs
    to localize root-cause configuration properties, achieving a high average accuracy
    of 99.91%. Different from these works, our work explores the potential of LLMs
    to analyze the performance sensitivity of configurations, which can assist developers
    in reducing performance testing costs.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型在各种软件工程任务中显示出了有希望的性能，例如代码生成和摘要。许多研究利用LLM处理与软件配置相关的任务。Lian 等（[2024](#bib.bib26)）提出了一个基于LLM的框架Ciri，使用少量学习和提示工程来验证配置文件的正确性，从文件级别和参数级别进行评估。从实际配置错误的评估中，包括64种配置，以及涉及1582个参数的合成配置错误，Ciri在文件级别和参数级别分别取得了0.79和0.65的F1分数。Liu
    等（[2024b](#bib.bib31)）介绍了LLM-CompDroid框架，该框架结合LLM和错误解决工具来处理Android应用程序中的配置兼容性问题。他们的框架在Correct和Correct@k指标中分别超越了当前最先进的方法（SOTA）至少9.8%和10.4%。Shan
    等（[2024](#bib.bib42)）提出了框架LogConfigLocalizer，该框架利用大型语言模型和日志来定位根本原因配置属性，取得了99.91%的高平均准确率。与这些工作不同，我们的工作探索了LLM在分析配置性能敏感性方面的潜力，这可以帮助开发人员降低性能测试成本。
- en: 3.3\. Multi-Agent Based Code Analysis
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 基于多代理的代码分析
- en: Agent-based code analysis emphasizes the importance of defining roles and facilitating
    communication among multiple LLM agents. Some approaches incorporate external
    tools as agents. For example, Huang et al. ([2023](#bib.bib20)) introduced a test
    executor agent that employs a Python interpreter to provide test logs for LLMs.
    Similarly, Zhong et al. ([2024](#bib.bib62)) presented a debugger agent that uses
    a static analysis tool to construct control flow graphs, aiding LLMs in locating
    bugs. Other studies (Hong et al., [2023](#bib.bib19); Qian et al., [2023](#bib.bib38);
    Dong et al., [2023](#bib.bib12); Lin et al., [2024](#bib.bib28)) assigned LLMs
    to emulate diverse human roles, such as analysts, engineers, testers, project
    managers, and chief technology officers (CTOs). These approaches use software
    process models (e.g., Waterfall) for inter-role communication, varying the prompts
    and roles to enhance code generation. Our technique leverages similar multi-agent
    systems to classify performance-sensitive configurations. By integrating prompt
    chaining and retrieval-augmented generation (RAG), PerfSense enhances the collaborative
    capabilities of LLM agents, leading to a lightweight technique that addresses
    the challenge of limited LLM context size when analyzing a large codebase.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的代码分析强调了定义角色和促进多个 LLM 代理之间通信的重要性。一些方法将外部工具作为代理。例如，Huang 等人 ([2023](#bib.bib20))
    引入了一个测试执行代理，该代理利用 Python 解释器为 LLM 提供测试日志。类似地，Zhong 等人 ([2024](#bib.bib62)) 提出了一个调试器代理，使用静态分析工具构建控制流图，帮助
    LLM 定位错误。其他研究（Hong 等人，[2023](#bib.bib19)；Qian 等人，[2023](#bib.bib38)；Dong 等人，[2023](#bib.bib12)；Lin
    等人，[2024](#bib.bib28)）将 LLM 指派为模拟各种人类角色，如分析师、工程师、测试人员、项目经理和首席技术官（CTO）。这些方法使用软件过程模型（例如，瀑布模型）进行角色间通信，通过变化提示和角色来增强代码生成。我们的方法利用类似的多代理系统来分类性能敏感配置。通过集成提示链和检索增强生成（RAG），PerfSense
    提升了 LLM 代理的协作能力，形成了一种轻量级技术，解决了在分析大型代码库时 LLM 上下文大小有限的问题。
- en: '![Refer to caption](img/4372bf77c7443de229d26254bbe72532.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4372bf77c7443de229d26254bbe72532.png)'
- en: Figure 1. Overview of PerfSense
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. PerfSense 的概述
- en: 4\. Design of PerfSense
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. PerfSense 的设计
- en: In this section, we introduce PerfSense, a lightweight framework designed for
    identifying performance-sensitive configurations. We begin by discussing various
    LLM agents and their communication and conclude with a detailed running example.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍 PerfSense，这是一种轻量级框架，旨在识别性能敏感配置。我们首先讨论各种 LLM 代理及其通信，然后以详细的运行示例结束。
- en: 'Figure [1](#S3.F1 "Figure 1 ‣ 3.3\. Multi-Agent Based Code Analysis ‣ 3\. Related
    Work ‣ Identifying Performance-Sensitive Configurations in Software Systems through
    Code Analysis with LLM Agents") illustrates the overview of PerfSense. To analyze
    the performance sensitivity of configurations, PerfSense comprises two different
    agents: the developer (DevAgent) and the performance expert (PerfAgent). At a
    high level, given a potential performance-sensitive configuration, PerfAgent utilizes
    iterative self-refinement and retrieval-augmented prompting techniques in a zero-shot
    setting, with the assistance of DevAgent, to iteratively build a knowledge base
    of the codebase and classify whether the configuration is performance-sensitive.
    In the following section, we elaborate on the roles of PerfAgent and DevAgent,
    and their communication pattern for determining performance-sensitive configurations.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S3.F1 "图 1 ‣ 3.3\. 基于多代理的代码分析 ‣ 3\. 相关工作 ‣ 通过 LLM 代理的代码分析识别软件系统中的性能敏感配置")
    说明了 PerfSense 的概述。为了分析配置的性能敏感性，PerfSense 包含两个不同的代理：开发人员（DevAgent）和性能专家（PerfAgent）。从高层次看，针对潜在的性能敏感配置，PerfAgent
    在零样本设置中利用迭代自我优化和检索增强提示技术，并在 DevAgent 的协助下，迭代构建代码库的知识库，并分类配置是否性能敏感。在接下来的章节中，我们详细阐述
    PerfAgent 和 DevAgent 的角色，以及他们在确定性能敏感配置中的通信模式。
- en: 4.1\. Agent Roles and Definition
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 代理角色和定义
- en: '![Refer to caption](img/755a9b73546c63f2b64cf57096420fc1.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/755a9b73546c63f2b64cf57096420fc1.png)'
- en: Figure 2. An example of performance-sensitive configuration.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. 一个性能敏感配置的示例。
- en: '4.1.1\. Developer Agent: Retrieving Configuration-Related Code'
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1\. 开发人员代理：检索与配置相关的代码
- en: 'The main role of a DevAgent is to retrieve source code and conduct performance-aware
    code review, upon PerfAgent’s request, and respond with the result so that PerfAgent
    has the necessary information to make the classification decision. Initially,
    PerfAgent receives the potential performance-sensitive configuration to analyze.
    However, multiple methods across various classes may have some dependencies with
    the configuration parameter, making it difficult for PerfAgent to assess the configuration’s
    performance sensitivity accurately. Providing additional summaries of the configuration-related
    code, such as related source code and documentation, can help improve PerfAgent’s
    output (Ye et al., [2020](#bib.bib55)). Hence, PerfAgent relies on DevAgent, which
    utilizes two tools: (1) traditional program analysis to extract source code that
    may be associated with the configuration through inter-procedural call graphs,
    and (2) document retrieval to extract official documentation associated with the
    configuration. In addition to retrieving the code, PerfAgent may also rely on
    DevAgent to provide feedback on the specific source code, since our intuition
    is that the developer should have a better understanding of the functionality
    of the code. Thus, DevAgent conducts performance-aware code reviews on the source
    code methods requested by PerfAgent, as indicated in Figure [3](#S4.F3 "Figure
    3 ‣ 4.1.1\. Developer Agent: Retrieving Configuration-Related Code ‣ 4.1\. Agent
    Roles and Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents"). Below,
    we further discuss how we extract code context, official documentation, and the
    prompt design for DevAgent’s performance-aware code review.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 'DevAgent的主要角色是根据PerfAgent的请求检索源代码并进行性能感知代码审查，并回应结果，以便PerfAgent拥有做出分类决策所需的信息。最初，PerfAgent接收需要分析的潜在性能敏感配置。然而，多个类中的方法可能与配置参数存在一些依赖关系，这使得PerfAgent难以准确评估配置的性能敏感性。提供配置相关代码的额外摘要，例如相关源代码和文档，可以帮助提高PerfAgent的输出（Ye
    et al., [2020](#bib.bib55)）。因此，PerfAgent依赖DevAgent，后者利用两个工具：（1）传统程序分析来通过跨过程调用图提取可能与配置相关的源代码，以及（2）文档检索来提取与配置相关的官方文档。除了检索代码外，PerfAgent还可能依赖DevAgent对特定源代码提供反馈，因为我们的直觉是开发者对代码的功能有更好的理解。因此，DevAgent对PerfAgent请求的源代码方法进行性能感知代码审查，如图[3](#S4.F3
    "Figure 3 ‣ 4.1.1\. Developer Agent: Retrieving Configuration-Related Code ‣ 4.1\.
    Agent Roles and Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents")所示。下面，我们进一步讨论如何提取代码上下文、官方文档以及DevAgent性能感知代码审查的提示设计。'
- en: Extracting Configuration-Related Code. We define configuration-related code
    as the caller source code that invokes a method that directly accesses the configuration.
    For example, as indicated in Figure [2](#S4.F2 "Figure 2 ‣ 4.1\. Agent Roles and
    Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents"), the configuration
    under analysis is key_cache_size_in_mb, and its related source code is initKeyCache,
    which is the caller source code that accesses the configuration. To extract configuration-related
    source code, we first utilize static code analysis to extract the inter-procedural
    call graph (Gousios, [[n.d.]](#bib.bib15)). We first identify the method that
    directly accesses the configuration, then we traverse the graph to retrieve all
    the methods that have either a direct or indirect caller-callee relationship.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 提取配置相关代码。我们将配置相关代码定义为调用直接访问配置的方法的调用者源代码。例如，如图[2](#S4.F2 "Figure 2 ‣ 4.1\. Agent
    Roles and Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents")所示，正在分析的配置是key_cache_size_in_mb，而相关的源代码是initKeyCache，它是访问该配置的调用者源代码。为了提取配置相关的源代码，我们首先利用静态代码分析来提取跨过程调用图（Gousios,
    [[n.d.]](#bib.bib15)）。我们首先识别直接访问配置的方法，然后遍历图以检索所有具有直接或间接调用者-被调用者关系的方法。
- en: Extracting Configuration Documentation. The description of a configuration on
    the document may provide additional information that can help classify configurations.
    For example, in the studied system Batik, the documentation for the configuration
    called Width provides additional information that it is the “Output Image Width”,
    which may help the agents with the analysis. Therefore, we extract the configuration
    descriptions, if they are available, from the official project website. The description
    is passed to both DevAgent and PerfAgent as part of the prompts when analyzing
    the configuration.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 提取配置文档。文档中对配置的描述可能提供额外的信息，有助于分类配置。例如，在研究系统 Batik 中，名为 Width 的配置的文档提供了额外的信息，指出它是“输出图像宽度”，这可能帮助代理进行分析。因此，我们从官方项目网站提取配置描述（如果有的话）。这些描述作为分析配置时的提示的一部分，传递给
    DevAgent 和 PerfAgent。
- en: 'DevAgent’s Performance Aware Code Review. Figure [3](#S4.F3 "Figure 3 ‣ 4.1.1\.
    Developer Agent: Retrieving Configuration-Related Code ‣ 4.1\. Agent Roles and
    Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") shows our prompt design
    for performance-aware code review that DevAgent carries out. Firstly, we give
    personification to the DevAgent, describing its role and goals, such as “You are
    a developer. Your job is to conduct performance-aware code review.”. Consequently,
    we provide context about the (1) source code and (2) configuration description
    to the DevAgent. Finally, we ask DevAgent to output the following requirements:
    (i) summarize the functionality of the code, (ii) how many times such source code
    may be triggered (estimation based on the provided textual information), and (iii)
    whether the code may have an impact on memory or execution time. It is important
    to note that performance-aware code review does not determine whether a configuration
    is performance-sensitive; this task falls to PerfAgent. However, DevAgent should
    be aware of common performance issues within the code they write, such as excessive
    memory usage and frequency of invocation, which may help PerfAgent with the analysis.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 'DevAgent 的性能感知代码审查。图 [3](#S4.F3 "Figure 3 ‣ 4.1.1\. Developer Agent: Retrieving
    Configuration-Related Code ‣ 4.1\. Agent Roles and Definition ‣ 4\. Design of
    PerfSense ‣ Identifying Performance-Sensitive Configurations in Software Systems
    through Code Analysis with LLM Agents") 展示了 DevAgent 进行性能感知代码审查的提示设计。首先，我们赋予 DevAgent
    拟人化，描述其角色和目标，例如“你是一个开发者。你的工作是进行性能感知代码审查。”。因此，我们向 DevAgent 提供有关（1）源代码和（2）配置描述的上下文。最后，我们要求
    DevAgent 输出以下要求：（i）总结代码的功能，（ii）此类源代码可能被触发的次数（基于提供的文本信息进行估算），以及（iii）代码是否可能对内存或执行时间产生影响。需要注意的是，性能感知代码审查并不决定配置是否对性能敏感；这项任务由
    PerfAgent 完成。然而，DevAgent 应该了解他们编写的代码中常见的性能问题，如过度的内存使用和调用频率，这可能有助于 PerfAgent 的分析。'
- en: 'Prompt
    Template for Performance-Aware Code Review Role: You
    are a developer. Your job is to conduct performance-aware code reviews on the
    given configuration-related code and official documentation for configuration
    to output the performance impact code that you wrote. Configuration-related code:1private  static  AutoSavingCache  initKeyCache()){
    2  ... 3  long  keyCacheInMemoryCapacity  =  DatabaseDescriptor.getKeyCacheSizeInMB()  *  1024  *  1024;
    4  kc  =  CaffeineCache.create(keyCacheInMemoryCapacity); 5  ... 6} Configuration
    description: Configuration Documentation after summarization. AutoSavingCache:
    “Specify the way Cassandra allocates and manages memtable memory.” Requirement:
    You must output three things below: 1\. Understand the functionality of the configuration
    in the code. 2\. Investigate triggering frequency of configuration-related operations.
    3\. Check the potential impact of configuration on the system.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt
    Template for Performance-Aware Code Review Role: You
    are a developer. Your job is to conduct performance-aware code reviews on the
    given configuration-related code and official documentation for configuration
    to output the performance impact code that you wrote. Configuration-related code:1private  static  AutoSavingCache  initKeyCache()){
    2  ... 3  long  keyCacheInMemoryCapacity  =  DatabaseDescriptor.getKeyCacheSizeInMB()  *  1024  *  1024;
    4  kc  =  CaffeineCache.create(keyCacheInMemoryCapacity); 5  ... 6} Configuration
    description: Configuration Documentation after summarization. AutoSavingCache:
    “Specify the way Cassandra allocates and manages memtable memory.” Requirement:
    You must output three things below: 1\. Understand the functionality of the configuration
    in the code. 2\. Investigate triggering frequency of configuration-related operations.
    3\. Check the potential impact of configuration on the system.'
- en: Figure 3. DevAgent’s Performance-Aware Code Review.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3. DevAgent 的性能感知代码审查。
- en: '4.1.2\. Performance Expert Agent: Analyzing the Performance Sensitivity of
    Configuration'
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2. 性能专家代理：分析配置的性能敏感性
- en: 'Given DevAgent’s feedback on a specific configuration-related operation, PerfAgent
    utilizes this feedback to classify performance-sensitive configurations. However,
    PerfAgent may require further clarification on the retrieved code. For example,
    as indicated in Figure [4](#S4.F4 "Figure 4 ‣ 4.1.2\. Performance Expert Agent:
    Analyzing the Performance Sensitivity of Configuration ‣ 4.1\. Agent Roles and
    Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents"), it may reference
    other methods (e.g., create) about which PerfAgent may lack performance knowledge.
    Hence, PerfAgent may request additional information about these operations. In
    particular, we use the prompt template in Figure [4](#S4.F4 "Figure 4 ‣ 4.1.2\.
    Performance Expert Agent: Analyzing the Performance Sensitivity of Configuration
    ‣ 4.1\. Agent Roles and Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents"), which
    starts by personifying PerfAgent with the introduction, “You are a performance
    expert… Check whether the provided configuration-related code is sufficient for
    performance analysis.” In the prompt, PerfAgent receives the source code, as well
    as feedback from DevAgent as indicated in the template from Figure [3](#S4.F3
    "Figure 3 ‣ 4.1.1\. Developer Agent: Retrieving Configuration-Related Code ‣ 4.1\.
    Agent Roles and Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive
    Configurations in Software Systems through Code Analysis with LLM Agents"). Based
    on this context, PerfSense instructs PerfAgent to pinpoint unclear or ambiguous
    methods crucial for accurate performance analysis. Upon identifying the code that
    needs further analysis, PerfAgent requests DevAgent to retrieve and analyze it.
    By retrieving and clarifying the code when needed, PerfAgent can explore configuration-related
    code information, ensuring that all necessary code information is retrieved while
    minimizing the tokens and not exceeding the size limitation.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '在 DevAgent 对特定配置相关操作的反馈下，PerfAgent 利用这些反馈来分类性能敏感的配置。然而，PerfAgent 可能需要进一步澄清所获取的代码。例如，如图
    [4](#S4.F4 "Figure 4 ‣ 4.1.2\. Performance Expert Agent: Analyzing the Performance
    Sensitivity of Configuration ‣ 4.1\. Agent Roles and Definition ‣ 4\. Design of
    PerfSense ‣ Identifying Performance-Sensitive Configurations in Software Systems
    through Code Analysis with LLM Agents") 所示，它可能参考其他方法（例如 create），而 PerfAgent 可能缺乏这些方法的性能知识。因此，PerfAgent
    可能会请求关于这些操作的额外信息。特别地，我们使用图 [4](#S4.F4 "Figure 4 ‣ 4.1.2\. Performance Expert Agent:
    Analyzing the Performance Sensitivity of Configuration ‣ 4.1\. Agent Roles and
    Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") 中的提示模板，该模板通过介绍“你是一个性能专家……检查提供的配置相关代码是否足够进行性能分析”来拟人化
    PerfAgent。在提示中，PerfAgent 收到源代码以及 DevAgent 的反馈，如图 [3](#S4.F3 "Figure 3 ‣ 4.1.1\.
    Developer Agent: Retrieving Configuration-Related Code ‣ 4.1\. Agent Roles and
    Definition ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") 中的模板所示。根据这一背景，PerfSense
    指示 PerfAgent 确定对准确性能分析至关重要的不清楚或模糊的方法。在识别出需要进一步分析的代码后，PerfAgent 请求 DevAgent 检索和分析这些代码。通过在需要时检索和澄清代码，PerfAgent
    可以深入了解配置相关的代码信息，确保检索所有必要的代码信息，同时尽量减少 tokens 并不超过大小限制。'
- en: 'Prompt
    Template for Code Understanding Role: You are a performance
    expert. Your job is to analyze the performance of the configuration. Check whether
    the provided configuration-related code is sufficient for performance analysis.
    Configuration-related code: 1private  static  AutoSavingCache  initKeyCache()){
    2  ... 3  long  keyCacheInMemoryCapacity  =  DatabaseDescriptor.getKeyCacheSizeInMB()  *  1024  *  1024;
    4  kc  =  CaffeineCache.create(keyCacheInMemoryCapacity); 5  ... 6} Code Context:
    Responses received from DevAgent. Requirement: If you need further code context
    to help understand the code, return the name of method name.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt
    Template for Code Understanding Role: You are a performance
    expert. Your job is to analyze the performance of the configuration. Check whether
    the provided configuration-related code is sufficient for performance analysis.
    Configuration-related code: 1private  static  AutoSavingCache  initKeyCache()){
    2  ... 3  long  keyCacheInMemoryCapacity  =  DatabaseDescriptor.getKeyCacheSizeInMB()  *  1024  *  1024;
    4  kc  =  CaffeineCache.create(keyCacheInMemoryCapacity); 5  ... 6} Code Context:
    Responses received from DevAgent. Requirement: If you need further code context
    to help understand the code, return the name of method name.'
- en: Figure 4. PerfAgent’s Prompt for Code Understanding.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4. PerfAgent 的代码理解提示。
- en: 4.2\. Multi-Agent Communications
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 多代理通信
- en: Based on our definition of DevAgent and PerfAgent, below we discuss how the
    agents collaborate together to classify performance-sensitive configurations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们对 DevAgent 和 PerfAgent 的定义，下面我们讨论了这些代理如何协作以分类性能敏感的配置。
- en: 4.2.1\. Prompt Chaining to Iteratively Build Code Understanding
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1\. 通过提示链迭代构建代码理解
- en: One effective technique for enhancing the reliability and performance of LLMs
    is to use a prompting paradigm called prompt chaining. Prompt chaining refers
    to breaking a complex task into simpler subtasks, prompting the LLM with each
    subtask sequentially, and using its responses as inputs for subsequent prompts (promptingguide,
    [[n.d.]](#bib.bib37)). In our performance chaining analysis, our goal is to retrieve
    all the necessary code for PerfAgent to assess the configuration’s sensitivity
    to performance. To achieve this, PerfAgent iteratively instructs DevAgent to retrieve
    source code methods sequentially. The DevAgent fetches a single method based on
    PerfAgent’s requests (include the source code, DevAgent’s description of the code,
    and DevAgent’s performance-aware code review result) until a termination condition
    is met, indicating that PerfAgent has gathered sufficient code and no longer requires
    assistance from DevAgent. PerfSense includes a memory mechanism that saves the
    DevAgent feedback at the end of each iteration of source code retrieval. This
    saved feedback can then be used as a code example in the next iteration of prompt
    chaining, allowing PerfAgent to clarify unclear contexts and request additional
    source code methods if needed.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 提高 LLM 可靠性和性能的一个有效技术是使用称为提示链的提示范式。提示链指的是将复杂任务分解为更简单的子任务，依次提示 LLM 每个子任务，并使用其响应作为后续提示的输入（promptingguide,
    [[n.d.]](#bib.bib37)）。在我们的性能链分析中，我们的目标是检索所有必要的代码，以便 PerfAgent 评估配置对性能的敏感性。为此，PerfAgent
    迭代地指示 DevAgent 依次检索源代码方法。DevAgent 根据 PerfAgent 的请求提取单个方法（包括源代码、DevAgent 对代码的描述和
    DevAgent 的性能感知代码审查结果），直到满足终止条件，表明 PerfAgent 已经收集了足够的代码，不再需要 DevAgent 的协助。PerfSense
    包括一个内存机制，在每次源代码检索迭代结束时保存 DevAgent 的反馈。这些保存的反馈可以作为下一次提示链迭代中的代码示例，从而允许 PerfAgent
    澄清不明确的上下文，并在需要时请求额外的源代码方法。
- en: 4.2.2\. Retrieval Augmented Generation for Performance Classifier
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. 用于性能分类器的检索增强生成
- en: 'Based on the result of prompt chaining in prior steps, PerfAgent sequentially
    builds a memory of the knowledge base, which allows PerfAgent to classify performance-sensitive
    configurations more accurately. More precisely, we use the prompt template in
    Figure [5](#S4.F5 "Figure 5 ‣ 4.2.2\. Retrieval Augmented Generation for Performance
    Classifier ‣ 4.2\. Multi-Agent Communications ‣ 4\. Design of PerfSense ‣ Identifying
    Performance-Sensitive Configurations in Software Systems through Code Analysis
    with LLM Agents"). Like prior templates, our RAG starts by personifying PerfAgent
    with the introduction, “You are a performance expert. Given feedback from DevAgent,
    your job is to perform performance analysis of configurations.” We then provide
    the retrieved context from DevAgent: (1) configuration-related code, (2) performance-aware
    code reviews, and (3) other code contexts to resolve clarity issues related to
    the configuration. Finally, we require PerfAgent to classify whether or not the
    configuration is performance-sensitive.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 基于前面步骤中提示链的结果，PerfAgent 顺序构建了一个知识库记忆，这使得 PerfAgent 能够更准确地对性能敏感的配置进行分类。更准确地说，我们使用图
    [5](#S4.F5 "图 5 ‣ 4.2.2\. 用于性能分类器的检索增强生成 ‣ 4.2\. 多智能体通信 ‣ 4\. PerfSense 的设计 ‣
    通过代码分析和 LLM 智能体识别软件系统中的性能敏感配置") 中的提示模板。与之前的模板一样，我们的 RAG 开始时通过介绍“你是一个性能专家。根据 DevAgent
    的反馈，你的工作是对配置进行性能分析”来拟人化 PerfAgent。然后，我们提供来自 DevAgent 的检索上下文：(1) 配置相关代码，(2) 性能感知代码审查，以及
    (3) 其他代码上下文以解决与配置相关的明确性问题。最后，我们要求 PerfAgent 对配置是否性能敏感进行分类。
- en: 'Prompt
    Template for Retrieval Augmented Generation for Performance-Sensitive Configuration
    Classifier Role: You are a performance
    expert. Your job is to analyze the performance of the configuration. You can check
    the provided code if code is clear and enough for performance analysis of configuration.
    Background knowledge about performance: Background information about performance-sensitive
    configuration and performance operations. RAG information: Access the memory,
    which includes the following retrieved configuration information: 1\. Configuration-related
    code 2\. Code understanding 3\. Analysis result of unclear context Requirement:
    Classify the configuration as performance sensitive or insensitive.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt
    Template for Retrieval Augmented Generation for Performance-Sensitive Configuration
    Classifier Role: You are a performance
    expert. Your job is to analyze the performance of the configuration. You can check
    the provided code if code is clear and enough for performance analysis of configuration.
    Background knowledge about performance: Background information about performance-sensitive
    configuration and performance operations. RAG information: Access the memory,
    which includes the following retrieved configuration information: 1\. Configuration-related
    code 2\. Code understanding 3\. Analysis result of unclear context Requirement:
    Classify the configuration as performance sensitive or insensitive.'
- en: 'Figure 5. Prompt Template 3: Retrieval Augmented Generation for Performance
    Classifier'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. 提示模板 3：用于性能分类器的检索增强生成
- en: 4.3\. Implementation and Experiment Settings
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 实现和实验设置
- en: Environment. We use GPT 3.5 (version gpt-3.5-turbo-0125) as our underlying LLM
    due to its popularity and wide usage. We leverage the OpenAI APIs and the LangGraph
    library (langchain, [2023](#bib.bib22)) to implement the LLM agents for recursive
    code analysis and performance configuration classification. Temperature is a parameter
    in LLMs that ranges from 0 to 1\. A low temperature makes the results more deterministic,
    and a higher value makes the results more diverse. To ensure the generated outputs
    are more stable across runs, We set the temperature to 0.3, which is a relatively
    low value but it still allows some diversity in the output. We also repeat our
    experiments five times and report the average. Note that although we use GPT 3.5
    as the underlying LLM, our approach is general and can be replaced with other
    LLMs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 环境。我们使用GPT 3.5（版本 gpt-3.5-turbo-0125）作为我们的基础LLM，因为它的流行和广泛使用。我们利用OpenAI APIs和LangGraph库（langchain，[2023](#bib.bib22)）来实现用于递归代码分析和性能配置分类的LLM代理。温度是LLM中的一个参数，范围从0到1。较低的温度使结果更加确定，较高的温度使结果更加多样化。为了确保生成的输出在不同运行间更稳定，我们将温度设置为0.3，这是一个相对较低的值，但仍允许输出有一定的多样性。我们还将实验重复进行五次，并报告平均值。请注意，尽管我们使用GPT
    3.5作为基础LLM，但我们的方法是通用的，可以替换为其他LLM。
- en: Benchmark Datasets. Table [1](#S4.T1 "Table 1 ‣ 4.3\. Implementation and Experiment
    Settings ‣ 4\. Design of PerfSense ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") presents the studied
    systems in our experiment. These seven systems are real-world open-source Java
    applications that cover various domains, ranging from databases to rendering engines.
    The systems have various configurations, some of which are related to performance.
    Previous work (Chen et al., [2023a](#bib.bib9)) conducted manual performance testing
    and provided the ground truth about the performance-sensitive configurations for
    these seven systems. We leverage the ground truth provided by Chen et al. (Chen
    et al., [2023a](#bib.bib9)) with some adjustments based on manually examining
    the source code and official documents. The replication package is available online (SensitiveTeeth,
    [2024](#bib.bib41)).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基准数据集。表 [1](#S4.T1 "表 1 ‣ 4.3\. 实施与实验设置 ‣ 4\. PerfSense的设计 ‣ 通过LLM代理进行代码分析以识别软件系统中的性能敏感配置")
    展示了我们实验中研究的系统。这七个系统是实际的开源Java应用程序，涵盖了从数据库到渲染引擎的各种领域。这些系统有各种配置，其中一些与性能相关。先前的工作（Chen等，[2023a](#bib.bib9)）进行了手动性能测试，并提供了这些七个系统性能敏感配置的真实数据。我们利用了Chen等人（Chen等，[2023a](#bib.bib9)）提供的真实数据，并根据手动检查源代码和官方文档进行了调整。复制包可在线获取（SensitiveTeeth，[2024](#bib.bib41)）。
- en: Table 1. An overview of the systems, versions, the number of configurations,
    and the number of performance-sensitive configurations that we studied.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表1. 我们研究的系统、版本、配置数量以及性能敏感配置数量的概述。
- en: '| System | Domain | Version | Config. | Perf. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 系统 | 领域 | 版本 | 配置 | 性能 |'
- en: '|  |  |  |  | Config. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 配置 |'
- en: '| Cassandra | NoSQL Database | 4.0.5 | 133 | 76 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Cassandra | NoSQL数据库 | 4.0.5 | 133 | 76 |'
- en: '| DConverter | image Density Converter | bdf1535 | 23 | 5 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| DConverter | 图像密度转换器 | bdf1535 | 23 | 5 |'
- en: '| Prevayler | Database | 2.6 | 12 | 8 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Prevayler | 数据库 | 2.6 | 12 | 8 |'
- en: '| BATIK | SVG rasterizer | 1.14 | 21 | 8 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| BATIK | SVG光栅化器 | 1.14 | 21 | 8 |'
- en: '| Catena | Password hashing | 1281e4b | 12 | 6 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| Catena | 密码哈希 | 1281e4b | 12 | 6 |'
- en: '| Sunflow | Rendering engine | 0.07.2 | 6 | 4 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| Sunflow | 渲染引擎 | 0.07.2 | 6 | 4 |'
- en: '| H2 | Database | 2.1.210 | 20 | 11 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| H2 | 数据库 | 2.1.210 | 20 | 11 |'
- en: 5\. Evaluation
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 评估
- en: In this section, we evaluate PerfSense by answering three research questions
    (RQs).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过回答三个研究问题（RQs）来评估PerfSense。
- en: 'RQ1: How effective is PerfSense in identifying performance-sensitive configurations?'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'RQ1: PerfSense在识别性能敏感配置方面的有效性如何？'
- en: 'In this RQ, we evaluate the classification result of PerfSense in identifying
    the performance-sensitive configuration. We compare PerfSense with two baselines:
    DiagConfig and ChatGPT. DiagConfig (Chen et al., [2023a](#bib.bib9)) utilized
    the taint static analysis on several systems to extract the performance-related
    operations related to configurations. Through manual performance tests by altering
    the configuration values and evaluating the variation of throughput, the performance-sensitive
    configurations would be identified and labeled. Utilizing the labeled configurations
    and taint static analysis of configuration, DiagConfig is trained using a random
    forest model to classify performance-sensitive configurations. ChatGPT directly
    calls ChatGPT APIs to classify if a configuration is performance-sensitive. We
    provide the system name, the configuration name, and the definition of a performance-sensitive
    configuration to ChatGPT (the same version as PerfSense) for classification. It
    is important to note that for PerfSense, the system name is not provided to reduce
    potential data leakage issues (Sallou et al., [2024](#bib.bib39)).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个研究问题中，我们评估PerfSense在识别性能敏感配置方面的分类结果。我们将PerfSense与两个基准进行比较：DiagConfig和ChatGPT。DiagConfig（Chen等，[2023a](#bib.bib9)）利用污点静态分析在多个系统上提取与配置相关的性能操作。通过手动性能测试，改变配置值并评估吞吐量的变化，可以识别和标记性能敏感配置。利用标记的配置和配置的污点静态分析，DiagConfig使用随机森林模型进行训练，以分类性能敏感配置。ChatGPT直接调用ChatGPT
    API来分类配置是否性能敏感。我们向ChatGPT（与PerfSense相同版本）提供系统名称、配置名称和性能敏感配置的定义进行分类。需要注意的是，对于PerfSense，为了减少潜在的数据泄漏问题，不提供系统名称（Sallou等，[2024](#bib.bib39)）。
- en: 'The classification result of PerfSense is assessed using three accuracy metrics:
    accuracy, precision, and recall. Specifically, we focus on the precision and recall
    of classifying the performance-sensitive configurations. True Positives (TP) happen
    when a performance-sensitive configuration is correctly classified. True Negatives
    (TN) happens when a non-performance-sensitive configuration is correctly classified
    as not performance-sensitive. False Positives (FP) happen when PerfSense incorrectly
    classifies a non-performance-sensitive configuration as performance-sensitive.
    False negatives (FN) happen when PerfSense misclassifies a performance-sensitive
    configuration as non-performance-sensitive. Given the TP, FP, and FN, we calculate
    precision as $\frac{TP}{TP+FP}$.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: PerfSense的分类结果使用三种准确性指标进行评估：准确率、精确度和召回率。具体来说，我们关注分类性能敏感配置的精确度和召回率。真正例（TP）发生在性能敏感配置被正确分类时。真正负例（TN）发生在非性能敏感配置被正确分类为非性能敏感时。假正例（FP）发生在PerfSense错误地将非性能敏感配置分类为性能敏感时。假负例（FN）发生在PerfSense错误地将性能敏感配置分类为非性能敏感时。给定TP、FP和FN，我们计算精确度为
    $\frac{TP}{TP+FP}$。
- en: Because of the generative nature of LLMs, the output may vary in each execution.
    Hence, we repeat each experiment five times and report the average precision,
    recall, and accuracy.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大型语言模型（LLMs）的生成特性，每次执行的输出可能有所不同。因此，我们重复每个实验五次，并报告平均的精确度、召回率和准确率。
- en: Table 2. The accuracy, precision, and recall of PerfSense and the baselines
    in classifying performance-sensitive configurations. Note that DiagConfig’s results
    are unavailable for all the systems, except Cassandra, because DiagConfig trained
    a classifier using other systems and applied it on Cassandra.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 表2。PerfSense及其基准在分类性能敏感配置方面的准确率、精确度和召回率。请注意，DiagConfig的结果在所有系统中都不可用，除了Cassandra，因为DiagConfig使用其他系统训练了分类器，并将其应用于Cassandra。
- en: '|  | PerfSense | ChatGPT | DiaConfig |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | PerfSense | ChatGPT | DiaConfig |'
- en: '|  | Accuracy | Precision | Recall | Accuracy | precision | recall | Accuracy
    | precision | recall |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | 准确率 | 精确度 | 召回率 | 准确率 | 精确度 | 召回率 | 准确率 | 精确度 | 召回率 |'
- en: '| Cassandra | 64.01% | 64.46% | 82.32% | 56.99% | 57.08% | 99.74% | 61.75%
    | 87.88% | 38.26% |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Cassandra | 64.01% | 64.46% | 82.32% | 56.99% | 57.08% | 99.74% | 61.75%
    | 87.88% | 38.26% |'
- en: '| DConverter | 66.09% | 39.06% | 100.00% | 26.96% | 20.79% | 84.00% | – | –
    | – |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| DConverter | 66.09% | 39.06% | 100.00% | 26.96% | 20.79% | 84.00% | – | –
    | – |'
- en: '| Prevayler | 75.00% | 75.51% | 95.50% | 66.70% | 66.70% | 100.00% | – | –
    | – |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Prevayler | 75.00% | 75.51% | 95.50% | 66.70% | 66.70% | 100.00% | – | –
    | – |'
- en: '| BATIK | 72.38% | 63.41% | 65.00% | 34.29% | 35.35% | 87.50% | – | – | – |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| BATIK | 72.38% | 63.41% | 65.00% | 34.29% | 35.35% | 87.50% | – | – | – |'
- en: '| Catena | 46.67% | 48.15% | 86.67% | 50.00% | 50.00% | 83.00% | – | – | –
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Catena | 46.67% | 48.15% | 86.67% | 50.00% | 50.00% | 83.00% | – | – | –
    |'
- en: '| Sunflow | 53.30% | 61.54% | 80.00% | 66.70% | 66.70% | 100.00% | – | – |
    – |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Sunflow | 53.30% | 61.54% | 80.00% | 66.70% | 66.70% | 100.00% | – | – |
    – |'
- en: '| H2 | 76% | 78.18% | 78.18% | 50.91% | 50.46% | 100.00% | – | – | – |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| H2 | 76% | 78.18% | 78.18% | 50.91% | 50.46% | 100.00% | – | – | – |'
- en: '| Average | 64.77% | 61.47% | 83.95% | 50.36% | 49.58% | 93.46% | – | – | –
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 64.77% | 61.47% | 83.95% | 50.36% | 49.58% | 93.46% | – | – | – |'
- en: 'Results. PerfSense achieves a better accuracy (64.77% on average) compared
    to ChatGPT and DiagConfig (50.36% and 61.75%, respectively). Table [2](#S5.T2
    "Table 2 ‣ RQ1: How effective is PerfSense in identifying performance-sensitive
    configurations? ‣ 5\. Evaluation ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") shows the classification
    result of PerfSense and the baselines. We find that the PerfSense provides a better
    balance of precision and recall, achieving better accuracy than the two baselines.
    ChatGPT achieves a higher recall (93.46%) than both PerfSense (83.95%) and DiagConfig
    (38.26%) but with a much lower precision (49.58% v.s. 61.47% and 87.88%). We find
    that the reason for a high recall and low precision is that ChatGPT misclassifies
    most configurations as performance-sensitive. In systems with less performance-sensitive
    configurations, ChatGPT achieves much worse results. For example, in DConverter,
    since 80% of the configurations are not performance-sensitive, ChatGPT achieves
    only a 27% accuracy rate. In contrast, the agents and prompting techniques implemented
    in PerfSense help improve the balance between precision and recall, resulting
    in much higher accuracy. We find that DiagConfig achieves a relatively high precision
    of 87.88% in Cassandra (it uses a classification model trained using data from
    all other systems, so the results are only available for Cassandra). However,
    DiagConfig has a very low recall (38.26% compared to PerfSense’s 82.32%) because
    DiagConfig misses many configurations where there were issues with obtaining the
    taint analysis result.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '结果。PerfSense的准确率（平均64.77%）比ChatGPT和DiagConfig（分别为50.36%和61.75%）更高。表格 [2](#S5.T2
    "表2 ‣ RQ1: PerfSense在识别性能敏感配置方面的效果如何？ ‣ 5\. 评估 ‣ 通过LLM代理进行代码分析来识别软件系统中的性能敏感配置")
    显示了PerfSense和基准的分类结果。我们发现，PerfSense在精确度和召回率之间提供了更好的平衡，比两个基准的准确率更高。ChatGPT的召回率（93.46%）高于PerfSense（83.95%）和DiagConfig（38.26%），但精确度远低于PerfSense（49.58%对比61.47%和87.88%）。我们发现，高召回率和低精确度的原因是ChatGPT将大多数配置错误分类为性能敏感。在性能敏感配置较少的系统中，ChatGPT的结果要差得多。例如，在DConverter中，由于80%的配置不是性能敏感的，ChatGPT的准确率仅为27%。相比之下，PerfSense中实现的代理和提示技术有助于提高精确度和召回率之间的平衡，从而得到更高的准确率。我们发现，DiagConfig在Cassandra中达到了相对较高的精确度87.88%（它使用了从其他系统数据训练的分类模型，因此结果仅适用于Cassandra）。然而，DiagConfig的召回率非常低（38.26%，相比PerfSense的82.32%），因为DiagConfig遗漏了许多无法获取污点分析结果的配置。'
- en: Note that, in theory, we can adjust PerfSense’s precision/recall by asking LLMs
    to estimate the performance impact (e.g., severe, medium, or low) and only classify
    the ones with a severe impact as performance sensitive to improve precision. In
    our pilot study, we achieve a much higher precision of 72.41% but a lower recall
    of 27.63%. PerfSense only classifies the configurations with severe performance
    impact as the performance-sensitive configurations. However, in this work, we
    aim to achieve higher recall and maintain good precision because the goal of PerfSense
    is to provide an initial list of configurations for performance engineers efficiently
    for further investigation.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，理论上，我们可以通过让LLMs估计性能影响（例如，严重、中等或低）来调整PerfSense的精确度/召回率，只将严重影响的配置分类为性能敏感配置，以提高精确度。在我们的试点研究中，我们达到了72.41%的更高精确度，但召回率降低到27.63%。PerfSense只将严重性能影响的配置分类为性能敏感配置。然而，在这项工作中，我们旨在实现更高的召回率并保持良好的精确度，因为PerfSense的最终目标是为性能工程师提供一个初步的配置列表，以便高效进行进一步的调查。
- en: Compared to DiagConfig, PerfSense requires less running time and no manual effort.
    DiagConfig requires a taint analysis to identify all the code that is reachable
    from the configuration, which may require tens of hours of computation time for
    large systems like Cassandra. Moreover, DiagConfig built a random forest classification
    model by manually collecting test results from other systems. This manual-intensive
    process may need to be repeated if we want to apply the model to systems in other
    domains or if they are developed by a different development practice. In contrast,
    PerfSense’s running time is less than 50 minutes for Cassandra (the largest studied
    system with over 130 configuration parameters) and can be easily extended to any
    system because of its zero-shot and unsupervised nature.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 与 DiagConfig 相比，PerfSense 需要更少的运行时间且无需手动操作。DiagConfig 需要进行污点分析以识别从配置中可达的所有代码，这可能需要对大型系统如
    Cassandra 进行数十小时的计算。此外，DiagConfig 通过手动收集其他系统的测试结果来构建随机森林分类模型。如果我们想将模型应用于其他领域的系统或由不同开发实践开发的系统，这一手动密集过程可能需要重复。相比之下，PerfSense
    在 Cassandra（研究过的最大系统，有超过 130 个配置参数）上的运行时间少于 50 分钟，且由于其零样本和无监督的特性，可以轻松扩展到任何系统。
- en: Answers to RQ1. PerfSense provides
    a better balance of precision and recall, achieving the highest accuracy compared
    to the baselines. PerfSense is also lightweight and requires less than one hour
    to run for the largest studied system.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Answers to RQ1. PerfSense provides
    a better balance of precision and recall, achieving the highest accuracy compared
    to the baselines. PerfSense is also lightweight and requires less than one hour
    to run for the largest studied system.
- en: 'RQ2: How do different components in PerfSense affect the classification result?'
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'RQ2: PerfSense 中不同组件如何影响分类结果？'
- en: 'PerfSense contains various components, including the retrieval augmented generation
    (e.g., retrieving related code to help make classification decisions) and chain-of-thought
    (e.g., asking agents to generate a code summary and combine the generated summary
    with subsequent tasks). In this RQ, we aim to study the impact of each component.
    We remove each component separately, re-execute PerfSense, and re-evaluate the
    classification accuracy. In particular, we consider five combinations: 1) code:
    retrieve only the source code method that directly uses the configuration value;
    2) code + analysis: expands code by enabling the DevAgent to iteratively traverse
    the code to analyze the methods that the agent believes is relevant (i.e., through
    prompt chaining); 3) dev: the DevAgent generates a summary and description of
    the retrieved code; 4) code + dev: expands code by asking the DevAgent to provide
    a summary and description of the retrieved code for subsequent prompts (i.e.,
    chain-of-thought); and 5) code + dev + analysis: the full version of PerfSense.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 'PerfSense 包含多种组件，包括增强检索生成（例如，检索相关代码以帮助做出分类决策）和思路链（例如，要求代理生成代码摘要，并将生成的摘要与后续任务结合）。在这一
    RQ 中，我们旨在研究每个组件的影响。我们分别移除每个组件，重新执行 PerfSense，并重新评估分类准确率。特别是，我们考虑了五种组合：1) code:
    仅检索直接使用配置值的源代码方法；2) code + analysis: 通过启用 DevAgent 迭代遍历代码以分析代理认为相关的方法（即，通过提示链）来扩展代码；3)
    dev: DevAgent 生成检索代码的摘要和描述；4) code + dev: 通过要求 DevAgent 提供检索代码的摘要和描述以供后续提示（即，思路链）来扩展代码；5)
    code + dev + analysis: PerfSense 的完整版本。'
- en: Table 3. Classification results of PerfSense with different components. The
    best precision and recall values in each system are marked in bold. The numbers
    in the parentheses show the percentage difference compared to the full version
    of PerfSense (code+dev+analysis).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. PerfSense 在不同组件下的分类结果。每个系统中的最佳精确度和召回率值用粗体标记。括号中的数字显示与 PerfSense（code+dev+analysis）完整版本的百分比差异。
- en: '| System | Approach | Precision | Recall |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 系统 | 方法 | 精确度 | 召回率 |'
- en: '| Cassandra | PerfSense${}_{\text{code+dev+analysis}}$ | 64.46% | 82.32% |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Cassandra | PerfSense${}_{\text{code+dev+analysis}}$ | 64.46% | 82.32% |'
- en: '| PerfSense${}_{\text{code}}$ | 67.55% (+4.79%) | 73.42% (-10.81%) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 67.55% (+4.79%) | 73.42% (-10.81%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 61.81% (-4.11%) | 77.11% (-6.32%)
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 61.81% (-4.11%) | 77.11% (-6.32%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 62.32% (-3.31%) | 74.47% (-9.53%)% |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 62.32% (-3.31%) | 74.47% (-9.53%)% |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 64.12% (-0.53%) % | 73.09% (-11.23%) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 64.12% (-0.53%) % | 73.09% (-11.23%) |'
- en: '| Dconverter | PerfSense${}_{\text{code+dev+analysis}}$ | 39.06% | 100.00%
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Dconverter | PerfSense${}_{\text{code+dev+analysis}}$ | 39.06% | 100.00%
    |'
- en: '| PerfSense${}_{\text{code}}$ | 30.49% (-21.94%) | 100.00% (-0.00%) |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 30.49% (-21.94%) | 100.00% (-0.00%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 29.76% (-23.81%) | 100.00% (-0.00%)
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 29.76% (-23.81%) | 100.00% (-0.00%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 32.20% (-17.56%) | 100.00% (-0.00%) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 32.20% (-17.56%) | 100.00% (-0.00%) |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 36.76% (-5.89%) | 100.00% (-0.00%) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 36.76% (-5.89%) | 100.00% (-0.00%) |'
- en: '| Prevayler | PerfSense${}_{\text{code+dev+analysis}}$ | 75.51% | 92.50% |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Prevayler | PerfSense${}_{\text{code+dev+analysis}}$ | 75.51% | 92.50% |'
- en: '| PerfSense${}_{\text{code}}$ | 80.56% (+6.70%) | 72.50% (-21.62%) |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 80.56% (+6.70%) | 72.50% (-21.62%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 74.47% (-1.38%) | 87.50% (-5.41%)
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 74.47% (-1.38%) | 87.50% (-5.41%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 70.83% (-6.20%) | 85.00% (-8.11%) |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 70.83% (-6.20%) | 85.00% (-8.11%) |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 70.45% (-6.70%) | 79.49% (-14.06%) |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 70.45% (-6.70%) | 79.49% (-14.06%) |'
- en: '| BATIK | PerfSense${}_{\text{code+dev+analysis}}$ | 63.41% | 65.00% |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| BATIK | PerfSense${}_{\text{code+dev+analysis}}$ | 63.41% | 65.00% |'
- en: '| PerfSense${}_{\text{code}}$ | 42.86% (-32.40%) | 45.00% (-30.76%) |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 42.86% (-32.40%) | 45.00% (-30.76%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 47.92% (-24.42%) | 57.50% (-11.53%)
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 47.92% (-24.42%) | 57.50% (-11.53%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 59.09% (-6.86%) | 32.50% (-50.00%) |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 59.09% (-6.86%) | 32.50% (-50.00%) |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 51.28 (-19.12%) | 50.00% (-23.07%) |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 51.28 (-19.12%) | 50.00% (-23.07%) |'
- en: '| Catena | PerfSense${}_{\text{code+dev+analysis}}$ | 48.15% | 86.67% |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| Catena | PerfSense${}_{\text{code+dev+analysis}}$ | 48.15% | 86.67% |'
- en: '| PerfSense${}_{\text{code}}$ | 51.43% (+6.81%) | 60.0% (-30.77%) |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 51.43% (+6.81%) | 60.0% (-30.77%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 48.89% (+1.53%) | 73.33% (-15.39%)
    |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 48.89% (+1.53%) | 73.33% (-15.39%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 48.15% (-0.00%) | 86.67% (-0.00%) |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 48.15% (-0.00%) | 86.67% (-0.00%) |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 50.00% (+3.84%) | 76.67% (-11.53%) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 50.00% (+3.84%) | 76.67% (-11.53%) |'
- en: '| Sunflow | PerfSense${}_{\text{code+dev+analysis}}$ | 61.54% | 80.00 % |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Sunflow | PerfSense${}_{\text{code+dev+analysis}}$ | 61.54% | 80.00% |'
- en: '| PerfSense${}_{\text{code}}$ | 83.00% (+34.87%) | 50.00% (-37.50%) |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 83.00% (+34.87%) | 50.00% (-37.50%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 65.22% (+6.00%) | 75.00% (-6.25%)
    |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 65.22% (+6.00%) | 75.00% (-6.25%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 68.00% (+10.49%) | 100% (+25.00%) |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 68.00% (+10.49%) | 100% (+25.00%) |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 65.38% (+6.23%) | 89.47% (+11.83%) |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 65.38% (+6.23%) | 89.47% (+11.83%) |'
- en: '| H2 | PerfSense${}_{\text{code+dev+analysis}}$ | 78.18% | 78.18% |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| H2 | PerfSense${}_{\text{code+dev+analysis}}$ | 78.18% | 78.18% |'
- en: '| PerfSense${}_{\text{code}}$ | 58.70% (-24.91%) | 50.00% (-36.04%) |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code}}$ | 58.70% (-24.91%) | 50.00% (-36.04%) |'
- en: '| PerfSense${}_{\text{code+analysis}}$ | 66.04% (-15.52%) | 63.64% (-18.59%)
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+analysis}}$ | 66.04% (-15.52%) | 63.64% (-18.59%)
    |'
- en: '| PerfSense${}_{\text{dev}}$ | 66.07% (-15.48%) | 67.27% (-13.95%) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{dev}}$ | 66.07% (-15.48%) | 67.27% (-13.95%) |'
- en: '| PerfSense${}_{\text{code+dev}}$ | 80.00% (+2.33%) | 72.73% (-6.97%) |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| PerfSense${}_{\text{code+dev}}$ | 80.00% (+2.33%) | 72.73% (-6.97%) |'
- en: 'Results. Integrating code results in the highest precision in 4/7 studied systems,
    with the sacrifice of recall. Further adding dev improves recall significantly
    across most systems, achieving a more balanced trade-off between precision and
    recall while maintaining reasonably high precision. Table [3](#S5.T3 "Table 3
    ‣ RQ2: How do different components in PerfSense affect the classification result?
    ‣ 5\. Evaluation ‣ Identifying Performance-Sensitive Configurations in Software
    Systems through Code Analysis with LLM Agents") shows the precision and recall
    of the combinations of the components in PerfSense. We find that a simple RAG
    approach by retrieving only the method that directly uses the configuration parameter
    (PerfSense ${}_{\text{code}}$ achieves a precision of 67.55%, which is 4.79% higher
    than the full version, but the recall drops significantly by 10.81% to 73.42%.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '结果。整合代码在7个研究系统中的4个系统中实现了最高的精度，但牺牲了召回率。进一步添加开发组件显著提高了大多数系统的召回率，实现了精度和召回率之间更平衡的折衷，同时保持了相对较高的精度。表[3](#S5.T3
    "表 3 ‣ RQ2: PerfSense中的不同组件如何影响分类结果？ ‣ 5\. 评估 ‣ 通过代码分析与LLM代理识别软件系统中的性能敏感配置")显示了PerfSense组件组合的精度和召回率。我们发现，通过仅检索直接使用配置参数的方法（PerfSense
    ${}_{\text{code}}$）的简单RAG方法达到了67.55%的精度，比完整版本高4.79%，但召回率显著下降10.81%至73.42%。'
- en: While code alone can achieve high precision, it often sacrifices recall significantly.
    On the other hand, code+dev tends to provide a better balance between precision
    and recall, with generally higher recall rates and more stable precision. This
    suggests that incorporating LLM-generated summaries and descriptions helps to
    enhance the overall performance of the tool by maintaining a more comprehensive
    approach. In comparison, integrating the LLM-generated summary/description of
    a given piece of code in the prompt (code v.s. code+dev) tends to provide a better
    balance between precision and recall, with generally higher recall rates and more
    stable precision. This suggests that incorporating LLM-generated summaries/descriptions
    helps to enhance the overall performance of PerfSense by maintaining a more comprehensive
    approach.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然单独使用代码可以实现高精度，但通常会显著牺牲召回率。另一方面，代码+开发通常提供了精确度和召回率之间更好的平衡，通常具有更高的召回率和更稳定的精确度。这表明，结合
    LLM 生成的摘要和描述有助于通过保持更全面的方法来提升工具的整体性能。相比之下，将 LLM 生成的摘要/描述整合到给定代码的提示中（代码与代码+开发）通常在精确度和召回率之间提供了更好的平衡，通常具有更高的召回率和更稳定的精确度。这表明，结合
    LLM 生成的摘要/描述有助于通过保持更全面的方法来提升 PerfSense 的整体性能。
- en: Adding analysis to code further improves recall significantly across most systems
    while maintaining similar precision. For example, in Prevayler, the precision
    of code+analysis (74.47%) is slightly lower than code (80.56%), but the recall
    increases from 72.56% to 87.50%. Similarly, in BATIK, while code+analysis achieves
    a precision of 47.92% compared to 42.86% for code, the recall improves significantly
    from 45.00% to 57.50%. This finding suggests that the additional context and understanding
    provided by the analysis help PerfSense identify more relevant methods, thereby
    improving recall and maintaining precision.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 将分析添加到代码中可以显著提高大多数系统的召回率，同时保持类似的精度。例如，在 Prevayler 中，代码+分析的精度（74.47%）略低于代码（80.56%），但召回率从
    72.56% 增加到 87.50%。类似地，在 BATIK 中，虽然代码+分析的精度为 47.92%，而代码为 42.86%，但召回率从 45.00% 显著提高到
    57.50%。这一发现表明，分析提供的额外背景和理解帮助 PerfSense 识别更多相关方法，从而提高召回率并保持精度。
- en: Integrating code+dev+analysis offers a holistic approach that leverages the
    strengths of individual components—code, developer insights, and analytical context—to
    achieve the best balanced performance. For instance, in the case of Cassandra,
    code+dev+analysis achieves a precision of 64.46% and a recall of 82.32%. The full
    version of PerfSense surpasses the recall of both code (73.42%) and code+dev (73.09%),
    while maintaining a competitive precision. Our findings show that each component
    has its own benefits to the result, and the integrated components enhance the
    overall effectiveness and reliability of PerfSense, providing a robust solution
    for identifying relevant methods and classifying performance-sensitive configurations
    within codebases.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码+开发+分析整合在一起提供了一种整体方法，利用了各个组件的优势——代码、开发者见解和分析背景——以实现最佳的平衡性能。例如，在 Cassandra
    的案例中，代码+开发+分析达到了 64.46% 的精确度和 82.32% 的召回率。PerfSense 的完整版超越了代码（73.42%）和代码+开发（73.09%）的召回率，同时保持了具有竞争力的精确度。我们的研究结果表明，每个组件对结果都有自己的好处，整合后的组件提升了
    PerfSense 的整体有效性和可靠性，为识别相关方法和在代码库中分类性能敏感配置提供了强有力的解决方案。
- en: Answers to RQ2. Adding dev
    improves recall with a balanced trade-off in precision, and incorporating analysis
    further enhances recall while maintaining competitive precision. The combined
    code+dev+analysis approach effectively leverages each component’s strengths for
    comprehensive method identification.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Answers to RQ2. Adding dev
    improves recall with a balanced trade-off in precision, and incorporating analysis
    further enhances recall while maintaining competitive precision. The combined
    code+dev+analysis approach effectively leverages each component’s strengths for
    comprehensive method identification.
- en: 'RQ3: What are the reasons for PerfSense’s misclassification?'
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RQ3：PerfSense 误分类的原因是什么？
- en: Despite PerfSense achieving the highest accuracy and maintaining a balance between
    precision and recall, there remain instances of misclassification. Understanding
    the underlying causes of these misclassifications is crucial for understanding
    the limitations of PerfSense and providing insights for future performance analysis
    utilizing LLMs. Hence, in this RQ, we conduct a detailed manual study on the reasons
    for misclassification.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 PerfSense 实现了最高的准确率并在精确度和召回率之间保持了平衡，但仍然存在误分类的情况。了解这些误分类的根本原因对于理解 PerfSense
    的局限性以及为未来利用 LLM 进行的性能分析提供见解至关重要。因此，在这一研究问题中，我们对误分类的原因进行了详细的手动研究。
- en: We collected and examined 362 configurations incorrectly classified by PerfSense.
    To systematically analyze the reasons for misclassifications by PerfSense, we
    began by selecting a 20% random sample from our dataset of 362 misclassified configurations.
    This subset was thoroughly reviewed to identify and categorize the various reasons
    for misclassification. In particular, we studied the communication history among
    the agents, the source code, and all related documents that we could find. With
    these categories established, we then manually examined the remaining 80% of the
    dataset, applying the derived categories to each configuration to understand the
    distribution of the different reasons for misclassification. We did not find any
    new categories during the process.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集并检查了362个被PerfSense错误分类的配置。为了系统地分析PerfSense误分类的原因，我们首先从362个误分类配置的数据集中随机选择了20%的样本。对这个子集进行了彻底审查，以识别和分类误分类的各种原因。特别是，我们研究了代理之间的通信记录、源代码以及我们能找到的所有相关文档。在确定这些类别后，我们手动检查了剩余80%的数据集，将得出的类别应用于每个配置，以了解误分类不同原因的分布。在此过程中，我们没有发现任何新的类别。
- en: Table 4. Reasons and prevalence for the misclassification of performance sensitivity
    by PerfSense.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 表4. PerfSense误分类性能敏感性的原因及其发生频率。
- en: '| Reason | Description | Percentage |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 原因 | 描述 | 百分比 |'
- en: '| No clear evidence of performance sensitivity | Through an examination of
    the related code and a careful review of available information (e.g., code and
    documentation), there is no clear evidence to indicate the performance sensitivity
    of the configuration. | 54.1% |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 没有明确的性能敏感性证据 | 通过检查相关代码和仔细审查可用信息（例如，代码和文档），没有明确的证据表明配置的性能敏感性。 | 54.1% |'
- en: '| Misunderstood requirements | LLMs misunderstand the requirements for classification
    of performance-sensitive. | 26.8% |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 误解要求 | LLM误解了性能敏感分类的要求。 | 26.8% |'
- en: '| Incorrect interpretation on the impact of performance-related operation |
    LLMs incorrectly interpreted the impact of performance-related operations. This
    misinterpretation led to the misclassification of the performance sensitivity
    of the configurations. | 10.0% |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 对性能相关操作影响的错误解释 | LLM错误解释了性能相关操作的影响。这种误解导致了配置性能敏感性的误分类。 | 10.0% |'
- en: '| Influenced by performance-related keywords | When LLMs classifies performance-sensitive
    configurations, keywords like “memory” and “scalability” can lead to misclassifications.
    These keywords are inherently associated with performance-related aspects, which
    may cause performance-insensitive configurations to be incorrectly identified
    as performance-sensitive. | 8.0% |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 受性能相关关键词的影响 | 当LLM对性能敏感的配置进行分类时，像“内存”和“可扩展性”这样的关键词可能导致误分类。这些关键词本质上与性能相关的方面有关，可能导致性能不敏感的配置被错误地识别为性能敏感。
    | 8.0% |'
- en: '| Hallucination | LLMs generate information that is not based on actual facts
    or truths. | 1.1% |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 错觉 | LLM生成的信息并不是基于实际事实或真相。 | 1.1% |'
- en: 'Results Table [4](#S5.T4 "Table 4 ‣ RQ3: What are the reasons for PerfSense’s
    misclassification? ‣ 5\. Evaluation ‣ Identifying Performance-Sensitive Configurations
    in Software Systems through Code Analysis with LLM Agents") shows the reasons
    for the misclassification of performance-sensitivity by PerfSense and their percentage.
    In total, we uncovered five reasons that cause the misclassification.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '结果表[4](#S5.T4 "表4 ‣ RQ3: PerfSense误分类的原因是什么？ ‣ 5. 评估 ‣ 通过LLM代理的代码分析识别软件系统中的性能敏感配置")
    显示了PerfSense对性能敏感性误分类的原因及其百分比。总的来说，我们揭示了五个导致误分类的原因。'
- en: Most misclassifications (54.1%) occur in configurations without clear evidence
    to support the performance sensitivity. For the configuration where the classification
    results by PerfSense differ from the ground truth (Chen et al., [2023a](#bib.bib9)),
    although we conducted a thorough examination of the related code and a careful
    review of available information (e.g., documentation and source code), there is
    no substantive evidence supporting the performance sensitivity of this configuration.
    For example, in Cassandra, the configuration column_index_cache_size_in_kb is
    not performance-sensitive (Chen et al., [2023a](#bib.bib9)). However, the LLM
    agents responded that this configuration can impact the amount of memory used
    for holding index entries in memory, which can cause performance variations. Setting
    a higher value may improve performance by reducing disk reads for index entries
    while setting a lower value may result in more disk reads and potentially slower
    performance. Based on reading the source code, we believe the explanation of PerfSense’s
    decision is valid, but there is no available evidence to support the performance
    sensitivity of the configuration. This misinterpretation can lead to inaccurate
    classification of performance sensitivity, highlighting the need for providing
    better requirements to LLMs for code understanding.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数错误分类（54.1%）发生在没有明确证据支持性能敏感性的配置中。对于PerfSense的分类结果与真实情况不同的配置（Chen et al., [2023a](#bib.bib9)），尽管我们对相关代码进行了彻底检查并仔细审查了可用信息（例如文档和源代码），但没有实质性证据支持该配置的性能敏感性。例如，在Cassandra中，配置column_index_cache_size_in_kb不具备性能敏感性（Chen
    et al., [2023a](#bib.bib9)）。然而，LLM代理回应称，该配置可能影响内存中存储索引条目的内存使用量，从而导致性能波动。设置较高的值可能通过减少索引条目的磁盘读取来提高性能，而设置较低的值则可能导致更多的磁盘读取和潜在的较慢性能。根据阅读源代码，我们认为PerfSense的决定解释是有效的，但没有可用证据支持该配置的性能敏感性。这种误解可能导致对性能敏感性的错误分类，突显了为LLM提供更好需求以理解代码的必要性。
- en: PerfSense may misunderstand requirements on performance sensitivities and classify
    other aspects as performance sensitive (26.8%). PerfSense may do some interpolation
    and infer that some non-performance-sensitive operations as performance sensitive.
    For example, the configuration _prevalenceDirectory in Prevayler specifies the
    directory used for reading and writing files. The configuration is related to
    file storage and is not performance-sensitive. However, PerfSense incorrectly
    assumes that the location of these read-write operations impacts system performance,
    whereas the configuration primarily pertains to system storage rather than performance.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: PerfSense可能误解了性能敏感性的要求，并将其他方面分类为性能敏感（26.8%）。PerfSense可能进行了一些插值，推断出一些非性能敏感的操作为性能敏感。例如，配置_prevalenceDirectory在Prevayler中指定了用于读取和写入文件的目录。该配置与文件存储相关，不具备性能敏感性。然而，PerfSense错误地假设这些读写操作的位置会影响系统性能，而该配置主要涉及系统存储而非性能。
- en: 10.0% of the misclassifications are due to incorrect interpretations of performance
    impact. In some instances, PerfSense inaccurately assesses the performance impact
    of specific configurations that do not inherently influence system efficiency.
    For example, the configuration BACKGROUND_COLOR in Batik, which sets the background
    color, is performance-sensitive. The reason is different color settings can have
    an impact on the performance of graph rendering. However, PerfSense incorrectly
    classifies the code related to the configuration of the color as performance-insensitive.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 10.0%的错误分类是由于对性能影响的错误解释。在某些情况下，PerfSense错误地评估了特定配置的性能影响，而这些配置本质上不会影响系统效率。例如，在Batik中，配置BACKGROUND_COLOR用于设置背景颜色，该配置是性能敏感的。原因是不同的颜色设置会对图形渲染的性能产生影响。然而，PerfSense错误地将与颜色配置相关的代码分类为性能非敏感。
- en: 8.0% misclassification is related to having performance-related keywords for
    a performance non-sensitive configuration. LLMs are trained using natural language
    texts so they are sensitive to keywords in the prompts. If there are performance-related
    keywords in the prompt, PerfSense is more likely to classify a configuration as
    performance-sensitive. For example, the configuration gc_log_threshold_in_ms’
    is not performance-sensitive in the Cassandra project based on the ground truth (Chen
    et al., [2023a](#bib.bib9)). Enabling or disabling the configuration does not
    affect the system execution time. However, the keyword “gc” (garbage collection)
    is often considered to be performance-related in many situations, PerfSense incorrectly
    classified the configuration as performance-sensitive. However, the configuration
    is related to logging during gc, and setting a lower/higher threshold does not
    have a noticeable impact on the performance.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 8.0%的误分类与性能无关配置中包含性能相关的关键词有关。LLMs使用自然语言文本进行训练，因此它们对提示中的关键词很敏感。如果提示中包含性能相关的关键词，PerfSense更有可能将配置分类为性能敏感。例如，`gc_log_threshold_in_ms`配置在Cassandra项目中根据实际情况被认为是非性能敏感的（Chen
    et al., [2023a](#bib.bib9)）。启用或禁用该配置不会影响系统执行时间。然而，“gc”（垃圾回收）这个关键词在许多情况下被认为是性能相关的，PerfSense错误地将该配置分类为性能敏感。然而，该配置与gc期间的日志记录相关，设置更低/更高的阈值对性能没有显著影响。
- en: Hallucination is rare but can still cause misclassification (1.1%). Hallucination
    in LLMs can lead to incorrect or misleading results (Liu et al., [2024a](#bib.bib29);
    Li et al., [2024a](#bib.bib24)). For example, the configuration hinted_handoff_enabled
    in Cassandra is considered performance-sensitive (Chen et al., [2023a](#bib.bib9)).
    This configuration is to allow Cassandra to “continue performing the same number
    of writes even when the cluster is operating at reduced capacity”. However, due
    to hallucination, PerfSense erroneously states that this configuration is related
    to the name of applications, causing misclassification of the configuration.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉现象虽然罕见，但仍然可能导致误分类（1.1%）。LLMs中的幻觉可能导致不正确或误导性的结果（Liu et al., [2024a](#bib.bib29);
    Li et al., [2024a](#bib.bib24)）。例如，Cassandra中的配置项`hinted_handoff_enabled`被认为是性能敏感的（Chen
    et al., [2023a](#bib.bib9)）。该配置旨在允许Cassandra“即使在集群以减少的容量运行时也继续执行相同数量的写操作”。然而，由于幻觉，PerfSense错误地指出该配置与应用程序的名称相关，导致对配置的误分类。
- en: Answers to RQ3. PerfSense’s
    misclassifications of performance-sensitive configurations are primarily due to
    a lack of clear evidence supporting performance sensitivity (54.1%) and misunderstanding
    of requirements leading to incorrect classifications (26.8%). Addressing these
    issues may require better requirements specification and enhanced understanding
    by LLMs to improve classification accuracy.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Answers to RQ3. PerfSense’s
    misclassifications of performance-sensitive configurations are primarily due to
    a lack of clear evidence supporting performance sensitivity (54.1%) and misunderstanding
    of requirements leading to incorrect classifications (26.8%). Addressing these
    issues may require better requirements specification and enhanced understanding
    by LLMs to improve classification accuracy.
- en: 6\. Discussion
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6. 讨论
- en: Better requirements for analyzing the performance sensitivity of configuration
    are needed. During the reason analysis of the misclassification of configurations,
    we find that misunderstanding the requirement on performance sensitivities affects
    the precision in identifying the performance-sensitive configurations by PerfSense.
    The specificity and clarity of prompts used to interact with these agents can
    influence their ability to accurately identify performance-sensitive configurations.
    Incorporating more explicit performance-related criteria into the prompts can
    help reduce misclassifications by aligning the LLM’s analysis more closely with
    the actual performance impacts of the configurations. This adjustment could guide
    the LLM agents to distinguish between configurations that truly affect performance
    and those that do not, despite potentially misleading indicators such as performance-related
    keywords.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 需要更好的要求来分析配置的性能敏感性。在对配置误分类的原因分析过程中，我们发现，对性能敏感性的误解会影响PerfSense准确识别性能敏感配置的精度。用于与这些代理互动的提示的特异性和清晰度可以影响它们准确识别性能敏感配置的能力。将更多明确的性能相关标准纳入提示中，可以帮助减少误分类，使LLM的分析更
    closely align with 实际的性能影响。这种调整可以指导LLM代理区分真正影响性能的配置和不影响性能的配置，尽管有时可能会出现误导性指示器，如性能相关的关键词。
- en: PerfSense efficiently narrows down the scope of investigation performance sensitivity
    of configurations. One of the strengths of PerfSense is its ability to efficiently
    narrow down the list of configurations that need deeper investigation. Performance
    sensitivity in software configurations is a complex domain where manual identification
    processes are time-consuming and prone to errors. By automating the identification
    process, PerfSense allows performance engineers and developers to focus their
    efforts and expertise on a refined subset of configurations, enhancing productivity
    and optimizing resource allocation.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: PerfSense有效缩小了配置性能敏感性的调查范围。PerfSense的一个优点是能够高效地缩小需要深入调查的配置列表。软件配置中的性能敏感性是一个复杂领域，人工识别过程既耗时又容易出错。通过自动化识别过程，PerfSense使性能工程师和开发人员能够将精力和专业知识集中在一个经过精炼的配置子集上，从而提高生产力并优化资源分配。
- en: Prompt chaining and RAG technique enhance PerfSense understanding and analytical
    capabilities of the LLM on performance analysis. tool leverages advanced prompting
    techniques, such as prompt chaining and retrieval-augmented generation, to improve
    the interaction dynamics between the developer and performance expert agents.
    Prompt chaining breaks down complex tasks into simpler, sequential queries that
    build upon each other, which helps in constructing a comprehensive performance
    analysis for each performance-sensitive decision. RAG integrates the configuration-related
    information from external sources and reduces the context size, ensuring that
    the analysis from LLMs is both relevant and deeply informed for the performance
    assessment of configurations. The integration of various prompting techniques
    enhances PerfSense’s ability to accurately identify performance-sensitive configurations
    with balanced precision and recall, minimizing the risk of overlooking critical
    performance nuances in software behavior.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 提示链和RAG技术增强了PerfSense对性能分析的理解和LLM的分析能力。该工具利用了先进的提示技术，如提示链和检索增强生成，以改善开发者与性能专家代理之间的互动动态。提示链将复杂任务分解为更简单的、依次构建的查询，这有助于为每个对性能敏感的决策构建全面的性能分析。RAG从外部来源集成与配置相关的信息，并减少上下文大小，确保LLM的分析在配置性能评估中既相关又深入。各种提示技术的集成增强了PerfSense准确识别性能敏感配置的能力，在精确度和召回率之间取得平衡，最大限度地减少了忽视软件行为中关键性能细微差别的风险。
- en: 7\. Threats to Validity
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 影响效度的威胁
- en: 7.1\. Internal Validity
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 内部效度
- en: Due to the generative nature of LLM, the responses may change across runs. To
    mitigate the threat, we try to execute the LLMs five times and report the average
    for our evaluation. We set the temperature value to 0.3, which makes the result
    more consistent but still allows some diversity. We find that the results are
    similar across runs, which means the outputs are stable. However, future studies
    are needed to understand the impact of temperature on the results. Since LLMs
    are trained using open-source systems, there is the possibility of data leakage
    problems. To minimize the impact, we excluded system-specific information (e.g.,
    system and package names) when classifying configuration performance sensitivity
    to mitigate data(Sallou et al., [2024](#bib.bib39)).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM的生成特性，响应可能会在不同的运行中有所变化。为了减轻这种威胁，我们尝试执行LLM五次，并报告平均值作为评估依据。我们将温度值设置为0.3，这使得结果更为一致，但仍允许一定的多样性。我们发现结果在不同运行间相似，这意味着输出是稳定的。然而，未来的研究仍需要了解温度对结果的影响。由于LLM是使用开源系统进行训练的，因此存在数据泄漏问题的可能性。为了最小化影响，我们在分类配置性能敏感性时排除了系统特定的信息（例如，系统和软件包名称），以减轻数据泄漏（Sallou等，[2024](#bib.bib39)）。
- en: 7.2\. External Validity
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 外部效度
- en: We conducted the study on open-source Java systems. Although we tried to choose
    matured and popular systems that are also used in prior studies, the results may
    not apply to systems implemented in other programming languages. Future research
    is needed to examine the results of other types of systems.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在开源Java系统上进行了研究。尽管我们尝试选择成熟且流行的系统，这些系统也在以前的研究中使用，但结果可能不适用于其他编程语言实现的系统。未来的研究需要检查其他类型系统的结果。
- en: 7.3\. Construct Validity
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3\. 构造效度
- en: Classifying the performance sensitivity of a configuration parameter is a challenging
    task due to varying workloads (Vitui and Chen, [2021](#bib.bib51)). Hence, in
    this paper, we rely on the prior benchmark (Chen et al., [2023a](#bib.bib9)) and
    validate the result by an in-depth analysis and all the documents that we could
    find. To encourage replication and validation of our study, we made the dataset
    publicly online (SensitiveTeeth, [2024](#bib.bib41)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 由于工作负载的变化，分类配置参数的性能敏感性是一项具有挑战性的任务（Vitui 和 Chen，[2021](#bib.bib51)）。因此，在本文中，我们依赖于先前的基准（Chen
    et al., [2023a](#bib.bib9)）并通过深入分析和我们能找到的所有文档来验证结果。为了鼓励复制和验证我们的研究，我们将数据集公开在线（SensitiveTeeth，[2024](#bib.bib41)）。
- en: 8\. Conclusion
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: Configuration parameters are crucial for customizing software behavior, and
    some configurations can have a performance impact on systems. However, misconfigurations
    are common and can lead to significant performance degradation, making it essential
    to identify performance-sensitive configurations. In this paper, we introduced
    PerfSense, a novel framework leveraging LLM-based multi-agent systems to identify
    performance-sensitive configurations in software systems. By combining static
    code analysis and retrieval-augmented prompting techniques, PerfSense can identify
    performance-sensitive configurations with minimal manual work. Our evaluation
    of seven open-source systems demonstrated that PerfSense achieves a higher accuracy
    of 64.77% compared to existing the state-of-the-art method (61.75%). Furthermore,
    our evaluation of studying the effect of different prompting components revealed
    that the implementation of prompt chaining in PerfSense substantially enhances
    recall, with improvements ranging from 10% to 30%. To understand the limitations
    of PerfSense, we conduct a manual analysis of 362 misclassification configurations
    to analyze and summarize the reasons for the misclassification of performance
    sensitivity by PerfSense. LLM’s misunderstanding of requirements (26.8%) is the
    key reason for misclassification. Additionally, we provide a detailed discussion
    to offer insights for future research to enhance the robustness and accuracy of
    LLM-based configuration performance analysis.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 配置参数对于定制软件行为至关重要，有些配置可能会对系统的性能产生影响。然而，配置错误是常见的，可能导致性能显著下降，因此识别性能敏感的配置非常重要。在本文中，我们介绍了
    PerfSense，一个利用基于 LLM 的多智能体系统来识别软件系统中性能敏感配置的创新框架。通过结合静态代码分析和增强检索提示技术，PerfSense
    可以以最少的手动工作识别性能敏感的配置。我们对七个开源系统的评估表明，PerfSense 达到了比现有最先进方法（61.75%）更高的准确率 64.77%。此外，我们对不同提示组件的影响进行的评估显示，PerfSense
    中提示链的实施显著提升了召回率，提升幅度在 10% 到 30% 之间。为了理解 PerfSense 的局限性，我们对 362 个错误分类的配置进行了手动分析，以分析和总结
    PerfSense 在性能敏感性分类中的误分类原因。LLM 对需求的误解（26.8%）是误分类的主要原因。此外，我们提供了详细讨论，以为未来的研究提供见解，提升基于
    LLM 的配置性能分析的稳健性和准确性。
- en: References
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: AlOmar et al. (2024) Eman Abdullah AlOmar, Anushkrishna Venkatakrishnan, Mohamed Wiem
    Mkaouer, Christian D Newman, and Ali Ouni. 2024. How to Refactor this Code? An
    Exploratory Study on Developer-ChatGPT Refactoring Conversations. *arXiv preprint
    arXiv:2402.06013* (2024).
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlOmar et al. (2024) Eman Abdullah AlOmar, Anushkrishna Venkatakrishnan, Mohamed
    Wiem Mkaouer, Christian D Newman, 和 Ali Ouni. 2024. 如何重构这段代码？开发者与 ChatGPT 的重构对话探索性研究。*arXiv
    预印本 arXiv:2402.06013* (2024)。
- en: 'Bao et al. (2018) Liang Bao, Xin Liu, Ziheng Xu, and Baoyin Fang. 2018. Autoconfig:
    Automatic configuration tuning for distributed message systems. In *Proceedings
    of the 33rd ACM/IEEE International Conference on Automated Software Engineering*.
    29–40.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bao et al. (2018) Liang Bao, Xin Liu, Ziheng Xu, 和 Baoyin Fang. 2018. Autoconfig:
    分布式消息系统的自动配置调优。载于*第33届 ACM/IEEE 自动化软件工程国际会议论文集*。29–40。'
- en: Bornholt and Torlak (2018) James Bornholt and Emina Torlak. 2018. Finding code
    that explodes under symbolic evaluation. *Proceedings of the ACM on Programming
    Languages* 2, OOPSLA (2018), 1–26.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bornholt 和 Torlak (2018) James Bornholt 和 Emina Torlak. 2018. 寻找在符号评估下爆炸的代码。*ACM
    编程语言会议论文集* 2, OOPSLA (2018), 1–26。
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based
    evaluators through multi-agent debate. *arXiv preprint arXiv:2308.07201* (2023).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, 和 Zhiyuan Liu. 2023. Chateval: 通过多智能体辩论改进基于 llm 的评估器。*arXiv
    预印本 arXiv:2308.07201* (2023)。'
- en: 'Chen et al. (2016) Tse-Hsun Chen, Weiyi Shang, Ahmed E. Hassan, Mohamed Nasser,
    and Parminder Flora. 2016. CacheOptimizer: helping developers configure caching
    frameworks for hibernate-based database-centric web applications. In *Proceedings
    of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software
    Engineering* (Seattle, WA, USA) *(FSE 2016)*. 666–677.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2016) Tse-Hsun Chen, Weiyi Shang, Ahmed E. Hassan, Mohamed Nasser,
    和 Parminder Flora. 2016. CacheOptimizer：帮助开发者配置基于 Hibernate 的数据库中心网络应用程序的缓存框架。见
    *2016年第24届ACM SIGSOFT国际软件工程基础研讨会论文集* (Seattle, WA, USA) *(FSE 2016)*。666–677。
- en: Chen et al. (2014) Tse-Hsun Chen, Weiyi Shang, Zhen Ming Jiang, Ahmed E Hassan,
    Mohamed Nasser, and Parminder Flora. 2014. Detecting performance anti-patterns
    for applications developed using object-relational mapping. In *Proceedings of
    the 36th international conference on software engineering*. 1001–1012.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2014) Tse-Hsun Chen, Weiyi Shang, Zhen Ming Jiang, Ahmed E Hassan,
    Mohamed Nasser, 和 Parminder Flora. 2014. 检测基于对象关系映射开发的应用程序的性能反模式。见 *第36届国际软件工程大会论文集*。1001–1012。
- en: 'Chen et al. (2023b) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2023b.
    Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors
    in agents. *arXiv preprint arXiv:2308.10848* (2023).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023b) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, 等. 2023b. Agentverse：促进多智能体协作并探索智能体中的突现行为。*arXiv
    预印本 arXiv:2308.10848* (2023)。
- en: 'Chen et al. (2023a) Zhiming Chen, Pengfei Chen, Peipei Wang, Guangba Yu, Zilong
    He, and Genting Mai. 2023a. DiagConfig: Configuration Diagnosis of Performance
    Violations in Configurable Software Systems. In *Proceedings of the 31st ACM Joint
    European Software Engineering Conference and Symposium on the Foundations of Software
    Engineering* *(ESEC/FSE 2023)*. 566–578.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023a) Zhiming Chen, Pengfei Chen, Peipei Wang, Guangba Yu, Zilong
    He, 和 Genting Mai. 2023a. DiagConfig：配置软件系统中性能违规的配置诊断。见 *第31届ACM联合欧洲软件工程大会和软件工程基础研讨会*
    *(ESEC/FSE 2023)*。566–578。
- en: community ([n.d.]) LinkedIn community. [n.d.]. *What are the most common factors
    that slow down web application performance?* [https://www.linkedin.com/advice/0/what-most-common-factors-slow-down-web-application-lcsme](https://www.linkedin.com/advice/0/what-most-common-factors-slow-down-web-application-lcsme)
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: community ([n.d.]) LinkedIn community. [n.d.]. *是什么最常见的因素会拖慢网页应用程序的性能？* [https://www.linkedin.com/advice/0/what-most-common-factors-slow-down-web-application-lcsme](https://www.linkedin.com/advice/0/what-most-common-factors-slow-down-web-application-lcsme)
- en: 'Deshpande et al. (2023) Ameet Deshpande, Tanmay Rajpurohit, Karthik Narasimhan,
    and Ashwin Kalyan. 2023. Anthropomorphization of AI: opportunities and risks.
    *arXiv preprint arXiv:2305.14784* (2023).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deshpande et al. (2023) Ameet Deshpande, Tanmay Rajpurohit, Karthik Narasimhan,
    和 Ashwin Kalyan. 2023. 人工智能的拟人化：机遇与风险。*arXiv 预印本 arXiv:2305.14784* (2023)。
- en: Dong et al. (2023) Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023. Self-collaboration
    code generation via chatgpt. *arXiv preprint arXiv:2304.07590* (2023).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong et al. (2023) Yihong Dong, Xue Jiang, Zhi Jin, 和 Ge Li. 2023. 通过 chatgpt
    进行自协作代码生成。*arXiv 预印本 arXiv:2304.07590* (2023)。
- en: ej technologies ([n.d.]) ej technologies. [n.d.]. *Jprofiler*. [https://www.ej-technologies.com/products/jprofiler/overview.html](https://www.ej-technologies.com/products/jprofiler/overview.html)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ej technologies ([n.d.]) ej technologies. [n.d.]. *Jprofiler*。 [https://www.ej-technologies.com/products/jprofiler/overview.html](https://www.ej-technologies.com/products/jprofiler/overview.html)
- en: 'Ganapathi et al. (2004) Archana Ganapathi, Yi-Min Wang, Ni Lao, and Ji-Rong
    Wen. 2004. Why pcs are fragile and what we can do about it: A study of windows
    registry problems. In *International Conference on Dependable Systems and Networks,
    2004*. IEEE, 561–566.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ganapathi et al. (2004) Archana Ganapathi, Yi-Min Wang, Ni Lao, 和 Ji-Rong Wen.
    2004. 为什么个人计算机脆弱以及我们可以做些什么：Windows 注册表问题的研究。见 *2004年国际可靠系统与网络会议*。IEEE, 561–566。
- en: 'Gousios ([n.d.]) Georgios Gousios. [n.d.]. *java-callgraph: Java Call Graph
    Utilities*. [https://github.com/gousiosg/java-callgraph](https://github.com/gousiosg/java-callgraph)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gousios ([n.d.]) Georgios Gousios. [n.d.]. *java-callgraph: Java调用图实用工具*。 [https://github.com/gousiosg/java-callgraph](https://github.com/gousiosg/java-callgraph)'
- en: 'Guo et al. (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao
    Pei, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large language model
    based multi-agents: A survey of progress and challenges. *arXiv preprint arXiv:2402.01680*
    (2024).'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao
    Pei, Nitesh V Chawla, Olaf Wiest, 和 Xiangliang Zhang. 2024. 基于大型语言模型的多智能体：进展与挑战的综述。*arXiv
    预印本 arXiv:2402.01680* (2024)。
- en: Han and Yu (2016a) Xue Han and Tingting Yu. 2016a. An empirical study on performance
    bugs for highly configurable software systems. In *Proceedings of the 10th ACM/IEEE
    International Symposium on Empirical Software Engineering and Measurement*. 1–10.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 和 Yu (2016a) Xue Han 和 Tingting Yu. 2016a. 对高度可配置软件系统性能缺陷的实证研究。载于 *第10届ACM/IEEE国际软件工程与测量实证研讨会论文集*。1–10页。
- en: Han and Yu (2016b) Xue Han and Tingting Yu. 2016b. An Empirical Study on Performance
    Bugs for Highly Configurable Software Systems. In *Proceedings of the 10th ACM/IEEE
    International Symposium on Empirical Software Engineering and Measurement* (Ciudad
    Real, Spain) *(ESEM ’16)*. Article 23, 10 pages.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 和 Yu (2016b) Xue Han 和 Tingting Yu. 2016b. 对高度可配置软件系统性能缺陷的实证研究。载于 *第10届ACM/IEEE国际软件工程与测量实证研讨会论文集*（西班牙
    Ciudad Real）*(ESEM ’16)*。第23篇，10页。
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al.
    2023. Metagpt: Meta programming for multi-agent collaborative framework. *arXiv
    preprint arXiv:2308.00352* (2023).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hong 等 (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin
    Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou 等.
    2023. Metagpt: 多智能体协作框架的元编程。*arXiv 预印本 arXiv:2308.00352* (2023)。'
- en: 'Huang et al. (2023) Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck, and
    Heming Cui. 2023. AgentCoder: Multi-Agent-based Code Generation with Iterative
    Testing and Optimisation. *arXiv preprint arXiv:2312.13010* (2023).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2023) Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck 和 Heming Cui.
    2023. AgentCoder: 基于多智能体的代码生成与迭代测试和优化。*arXiv 预印本 arXiv:2312.13010* (2023)。'
- en: Jin et al. (2012) Guoliang Jin, Linhai Song, Xiaoming Shi, Joel Scherpelz, and
    Shan Lu. 2012. Understanding and detecting real-world performance bugs. *ACM SIGPLAN
    Notices* 47, 6 (2012), 77–88.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 等 (2012) Guoliang Jin, Linhai Song, Xiaoming Shi, Joel Scherpelz 和 Shan
    Lu. 2012. 理解和检测现实世界中的性能缺陷。*ACM SIGPLAN 通讯* 47, 6 (2012), 77–88。
- en: langchain (2023) langchain. 2023. LangGraph. [https://python.langchain.com/v0.1/docs/langgraph/](https://python.langchain.com/v0.1/docs/langgraph/).
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: langchain (2023) langchain. 2023. LangGraph. [https://python.langchain.com/v0.1/docs/langgraph/](https://python.langchain.com/v0.1/docs/langgraph/)。
- en: Li et al. (2020) Chi Li, Shu Wang, Henry Hoffmann, and Shan Lu. 2020. Statically
    inferring performance properties of software configurations. In *Proceedings of
    the Fifteenth European Conference on Computer Systems*. 1–16.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2020) Chi Li, Shu Wang, Henry Hoffmann 和 Shan Lu. 2020. 静态推断软件配置的性能属性。载于
    *第十五届欧洲计算机系统会议论文集*。1–16页。
- en: 'Li et al. (2024a) Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Wayne Xin
    Zhao, Jian-Yun Nie, and Ji-Rong Wen. 2024a. The Dawn After the Dark: An Empirical
    Study on Factuality Hallucination in Large Language Models. arXiv:cs.CL/2401.03205'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2024a) Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Wayne Xin Zhao,
    Jian-Yun Nie 和 Ji-Rong Wen. 2024a. 黑暗之后的曙光：关于大型语言模型事实性幻觉的实证研究。arXiv:cs.CL/2401.03205
- en: 'Li et al. (2024b) Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan,
    Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, et al. 2024b. Personal
    llm agents: Insights and survey about the capability, efficiency and security.
    *arXiv preprint arXiv:2401.05459* (2024).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2024b) Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong
    Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun 等. 2024b. 个人 LLM 代理：关于能力、效率和安全性的见解与调研。*arXiv
    预印本 arXiv:2401.05459* (2024)。
- en: Lian et al. (2024) Xinyu Lian, Yinfang Chen, Runxiang Cheng, Jie Huang, Parth
    Thakkar, Minjia Zhang, and Tianyin Xu. 2024. Configuration Validation with Large
    Language Models. arXiv:cs.SE/2310.09690
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lian 等 (2024) Xinyu Lian, Yinfang Chen, Runxiang Cheng, Jie Huang, Parth Thakkar,
    Minjia Zhang 和 Tianyin Xu. 2024. 大型语言模型配置验证。arXiv:cs.SE/2310.09690
- en: Lillack et al. (2014) Max Lillack, Christian Kästner, and Eric Bodden. 2014.
    Tracking load-time configuration options. In *Proceedings of the 29th ACM/IEEE
    international conference on Automated software engineering*. 445–456.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lillack 等 (2014) Max Lillack, Christian Kästner 和 Eric Bodden. 2014. 跟踪加载时的配置选项。载于
    *第29届ACM/IEEE自动化软件工程国际会议论文集*。445–456页。
- en: Lin et al. (2024) Feng Lin, Dong Jae Kim, et al. 2024. When llm-based code generation
    meets the software development process. *arXiv preprint arXiv:2403.15852* (2024).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等 (2024) Feng Lin, Dong Jae Kim 等. 2024. 当 LLM 基础的代码生成遇上软件开发过程。*arXiv 预印本
    arXiv:2403.15852* (2024)。
- en: Liu et al. (2024a) Fang Liu, Yang Liu, Lin Shi, Houkun Huang, Ruifeng Wang,
    Zhen Yang, Li Zhang, Zhongqi Li, and Yuchi Ma. 2024a. Exploring and Evaluating
    Hallucinations in LLM-Powered Code Generation. arXiv:cs.SE/2404.00971
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2024a) Fang Liu, Yang Liu, Lin Shi, Houkun Huang, Ruifeng Wang, Zhen
    Yang, Li Zhang, Zhongqi Li 和 Yuchi Ma. 2024a. 探索和评估 LLM 驱动的代码生成中的幻觉。arXiv:cs.SE/2404.00971
- en: Liu et al. (2014) Yepang Liu, Chang Xu, and Shing-Chi Cheung. 2014. Characterizing
    and detecting performance bugs for smartphone applications. In *Proceedings of
    the 36th international conference on software engineering*. 1013–1024.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等（2014）Yepang Liu, Chang Xu, 和 Shing-Chi Cheung。2014。针对智能手机应用程序的性能错误特征及检测。在*第36届国际软件工程会议论文集*。1013–1024。
- en: 'Liu et al. (2024b) Zhijie Liu, Yutian Tang, Meiyun Li, Xin Jin, Yunfei Long,
    Liang Feng Zhang, and Xiapu Luo. 2024b. LLM-CompDroid: Repairing Configuration
    Compatibility Bugs in Android Apps with Pre-trained Large Language Models. arXiv:cs.SE/2402.15078'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等（2024b）Zhijie Liu, Yutian Tang, Meiyun Li, Xin Jin, Yunfei Long, Liang
    Feng Zhang, 和 Xiapu Luo。2024b。LLM-CompDroid: 使用预训练的大语言模型修复Android应用中的配置兼容性错误。arXiv:cs.SE/2402.15078'
- en: 'Ma et al. (2024b) Lipeng Ma, Weidong Yang, Bo Xu, Sihang Jiang, Ben Fei, Jiaqing
    Liang, Mingjie Zhou, and Yanghua Xiao. 2024b. KnowLog: Knowledge Enhanced Pre-trained
    Language Model for Log Understanding. In *Proceedings of the 46th IEEE/ACM International
    Conference on Software Engineering*. 1–13.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ma等（2024b）Lipeng Ma, Weidong Yang, Bo Xu, Sihang Jiang, Ben Fei, Jiaqing Liang,
    Mingjie Zhou, 和 Yanghua Xiao。2024b。KnowLog: 知识增强的预训练语言模型用于日志理解。在*第46届IEEE/ACM国际软件工程大会论文集*。1–13。'
- en: 'Ma et al. (2024a) Zeyang Ma, An Ran Chen, Dong Jae Kim, Tse-Hsun Chen, and
    Shaowei Wang. 2024a. LLMParser: An Exploratory Study on Using Large Language Models
    for Log Parsing. In *2024 IEEE/ACM 46th International Conference on Software Engineering
    (ICSE)*. IEEE Computer Society, 883–883.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ma等（2024a）Zeyang Ma, An Ran Chen, Dong Jae Kim, Tse-Hsun Chen, 和 Shaowei Wang。2024a。LLMParser:
    使用大语言模型进行日志解析的探索性研究。在*2024 IEEE/ACM 第46届国际软件工程大会（ICSE）*。IEEE计算机学会，883–883。'
- en: 'Madaan et al. (2024) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    et al. 2024. Self-refine: Iterative refinement with self-feedback. *Advances in
    Neural Information Processing Systems* 36 (2024).'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Madaan等（2024）Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu
    Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang等。2024。Self-refine:
    通过自我反馈进行迭代优化。*神经信息处理系统进展* 36（2024）。'
- en: 'Nistor et al. (2015) Adrian Nistor, Po-Chun Chang, Cosmin Radoi, and Shan Lu.
    2015. Caramel: Detecting and fixing performance problems that have non-intrusive
    fixes. In 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering.
    *IEEE, 902ś912* (2015).'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nistor等（2015）Adrian Nistor, Po-Chun Chang, Cosmin Radoi, 和 Shan Lu。2015。Caramel:
    检测和修复具有非侵入性修复的性能问题。在2015 IEEE/ACM第37届IEEE国际软件工程会议。*IEEE, 902ś912*（2015）。'
- en: OpenAI (2023) OpenAI. 2023. ChatGPT. [https://chat.openai.com/](https://chat.openai.com/).
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI。2023。ChatGPT。[https://chat.openai.com/](https://chat.openai.com/)。
- en: promptingguide ([n.d.]) promptingguide. [n.d.]. *Prompt Chaining*. [https://www.promptingguide.ai/techniques/prompt_chaining](https://www.promptingguide.ai/techniques/prompt_chaining)
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: promptingguide ([n.d.]) promptingguide。[n.d.]。*提示链*。[https://www.promptingguide.ai/techniques/prompt_chaining](https://www.promptingguide.ai/techniques/prompt_chaining)
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924* (2023).
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian等（2023）Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu,
    Zhiyuan Liu, 和 Maosong Sun。2023。用于软件开发的交流代理。*arXiv预印本arXiv:2307.07924*（2023）。
- en: 'Sallou et al. (2024) June Sallou, Thomas Durieux, and Annibale Panichella.
    2024. Breaking the Silence: the Threats of Using LLMs in Software Engineering.
    In *Proceedings of the 2024 ACM/IEEE 44th International Conference on Software
    Engineering: New Ideas and Emerging Results* (, Lisbon, Portugal,) *(ICSE-NIER’24)*.
    Association for Computing Machinery, New York, NY, USA, 102–106. [https://doi.org/10.1145/3639476.3639764](https://doi.org/10.1145/3639476.3639764)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sallou等（2024）June Sallou, Thomas Durieux, 和 Annibale Panichella。2024。打破沉默:
    使用LLM在软件工程中的威胁。在*2024 ACM/IEEE第44届国际软件工程会议: 新思想与新兴成果*（，里斯本，葡萄牙，）*(ICSE-NIER’24)*。计算机协会，纽约，NY，美国，102–106。[https://doi.org/10.1145/3639476.3639764](https://doi.org/10.1145/3639476.3639764)'
- en: Schäfer et al. (2023) Max Schäfer, Sarah Nadi, Aryaz Eghbali, and Frank Tip.
    2023. An empirical evaluation of using large language models for automated unit
    test generation. *IEEE Transactions on Software Engineering* (2023).
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schäfer等（2023）Max Schäfer, Sarah Nadi, Aryaz Eghbali, 和 Frank Tip。2023。使用大语言模型进行自动化单元测试生成的实证评估。*IEEE软件工程汇刊*（2023）。
- en: SensitiveTeeth (2024) SensitiveTeeth 2024. Replication Package for SensitiveTeeth.
    [https://github.com/anonymous334455/SensitiveTeeth](https://github.com/anonymous334455/SensitiveTeeth).
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SensitiveTeeth (2024) SensitiveTeeth 2024。SensitiveTeeth的复制包。[https://github.com/anonymous334455/SensitiveTeeth](https://github.com/anonymous334455/SensitiveTeeth)。
- en: 'Shan et al. (2024) Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, and
    Zibin Zheng. 2024. Face It Yourselves: An LLM-Based Two-Stage Strategy to Localize
    Configuration Errors via Logs. arXiv:cs.SE/2404.00640'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shan et al. (2024) Shiwen Shan, Yintong Huo, Yuxin Su, Yichen Li, Dan Li, 和
    Zibin Zheng. 2024. 面对现实：基于LLM的双阶段策略通过日志定位配置错误。arXiv:cs.SE/2404.00640
- en: Shen et al. (2023) Chaochao Shen, Wenhua Yang, Minxue Pan, and Yu Zhou. 2023.
    Git Merge Conflict Resolution Leveraging Strategy Classification and LLM. In *2023
    IEEE 23rd International Conference on Software Quality, Reliability, and Security
    (QRS)*. IEEE, 228–239.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen et al. (2023) Chaochao Shen, Wenhua Yang, Minxue Pan, 和 Yu Zhou. 2023.
    利用策略分类和LLM进行Git合并冲突解决。见于 *2023 IEEE第23届国际软件质量、可靠性与安全会议（QRS）*。IEEE, 228–239。
- en: Singh et al. (2016) Ravjot Singh, Cor-Paul Bezemer, Weiyi Shang, and Ahmed E
    Hassan. 2016. Optimizing the performance-related configurations of object-relational
    mapping frameworks using a multi-objective genetic algorithm. In *Proceedings
    of the 7th ACM/SPEC on International Conference on Performance Engineering*. 309–320.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh et al. (2016) Ravjot Singh, Cor-Paul Bezemer, Weiyi Shang, 和 Ahmed E Hassan.
    2016. 使用多目标遗传算法优化对象-关系映射框架的性能相关配置。见于 *第7届ACM/SPEC国际性能工程会议论文集*。309–320。
- en: Tian et al. (2015) Xinhui Tian, Rui Han, Lei Wang, Gang Lu, and Jianfeng Zhan.
    2015. Latency critical big data computing in finance. *The Journal of Finance
    and Data Science* 1, 1 (2015), 33–41.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian et al. (2015) Xinhui Tian, Rui Han, Lei Wang, Gang Lu, 和 Jianfeng Zhan.
    2015. 在金融领域的延迟关键大数据计算。*金融与数据科学杂志* 1, 1 (2015), 33–41。
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language
    models. *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, 等. 2023. Llama: 开放且高效的基础语言模型。*arXiv 预印本 arXiv:2302.13971*
    (2023)。'
- en: 'Velez et al. (2020) Miguel Velez, Pooyan Jamshidi, Florian Sattler, Norbert
    Siegmund, Sven Apel, and Christian Kästner. 2020. ConfigCrusher: towards white-box
    performance analysis for configurable systems. *Automated Software Engg.* 27,
    3–4 (dec 2020), 265–300. [https://doi.org/10.1007/s10515-020-00273-8](https://doi.org/10.1007/s10515-020-00273-8)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Velez et al. (2020) Miguel Velez, Pooyan Jamshidi, Florian Sattler, Norbert
    Siegmund, Sven Apel, 和 Christian Kästner. 2020. ConfigCrusher: 朝着白盒性能分析的方向前进。*自动化软件工程*
    27, 3–4 (2020年12月), 265–300。 [https://doi.org/10.1007/s10515-020-00273-8](https://doi.org/10.1007/s10515-020-00273-8)'
- en: 'Velez et al. (2022a) Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven
    Apel, and Christian Kästner. 2022a. On debugging the performance of configurable
    software systems: Developer needs and tailored tool support. In *Proceedings of
    the 44th International Conference on Software Engineering*. 1571–1583.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Velez et al. (2022a) Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel,
    和 Christian Kästner. 2022a. 调试可配置软件系统性能：开发者需求与量身定制的工具支持。见于 *第44届国际软件工程会议论文集*。1571–1583。
- en: 'Velez et al. (2022b) Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven
    Apel, and Christian Kästner. 2022b. On debugging the performance of configurable
    software systems: developer needs and tailored tool support. In *Proceedings of
    the 44th International Conference on Software Engineering* (Pittsburgh, Pennsylvania)
    *(ICSE ’22)*. 1571–1583.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Velez et al. (2022b) Miguel Velez, Pooyan Jamshidi, Norbert Siegmund, Sven Apel,
    和 Christian Kästner. 2022b. 调试可配置软件系统性能：开发者需求与量身定制的工具支持。见于 *第44届国际软件工程会议论文集*（宾夕法尼亚州匹兹堡）
    *(ICSE ’22)*。1571–1583。
- en: visualvm ([n.d.]) visualvm. [n.d.]. *VisualVM*. [https://visualvm.github.io/](https://visualvm.github.io/)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: visualvm ([n.d.]) visualvm. [n.d.]. *VisualVM*。 [https://visualvm.github.io/](https://visualvm.github.io/)
- en: 'Vitui and Chen (2021) Arthur Vitui and Tse-Hsun Chen. 2021. MLASP: Machine
    learning assisted capacity planning: An industrial experience report. *Empirical
    Software Engineering* 26, 5 (2021), 87.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vitui 和 Chen (2021) Arthur Vitui 和 Tse-Hsun Chen. 2021. MLASP: 机器学习辅助容量规划：一份工业经验报告。*实证软件工程*
    26, 5 (2021), 87。'
- en: Wang et al. (2021) Zehao Wang, Haoxiang Zhang, Tse-Hsun Chen, and Shaowei Wang.
    2021. Would you like a quick peek? providing logging support to monitor data processing
    in big data applications. In *Proceedings of the 29th ACM Joint Meeting on European
    Software Engineering Conference and Symposium on the Foundations of Software Engineering*.
    516–526.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2021) Zehao Wang, Haoxiang Zhang, Tse-Hsun Chen, 和 Shaowei Wang.
    2021. 你想快速了解一下吗？为大数据应用提供日志支持以监控数据处理。见于 *第29届ACM欧洲软件工程会议和软件工程基础研讨会联合会议论文集*。516–526。
- en: 'Xie et al. (2023) Zhuokui Xie, Yinghao Chen, Chen Zhi, Shuiguang Deng, and
    Jianwei Yin. 2023. ChatUniTest: a ChatGPT-based automated unit test generation
    tool. *arXiv preprint arXiv:2305.04764* (2023).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谢等人 (2023) 谢卓奎、陈颖浩、陈志、邓水光和尹建伟。2023年。《ChatUniTest：基于ChatGPT的自动化单元测试生成工具》。*arXiv预印本
    arXiv:2305.04764* (2023)。
- en: Xu et al. (2013) Tianyin Xu, Jiaqi Zhang, Peng Huang, Jing Zheng, Tianwei Sheng,
    Ding Yuan, Yuanyuan Zhou, and Shankar Pasupathy. 2013. Do not blame users for
    misconfigurations. In *Proceedings of the Twenty-Fourth ACM Symposium on Operating
    Systems Principles* (Farminton, Pennsylvania) *(SOSP ’13)*. New York, NY, USA,
    244–259.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 徐等人 (2013) 徐天寅、张佳琪、黄鹏、郑静、盛天伟、袁鼎、周媛媛和尚卡尔·帕苏帕提。2013年。《不要责怪用户配置错误》。在*第二十四届ACM操作系统原理研讨会论文集*
    (宾夕法尼亚州法明顿) *(SOSP ’13)*。美国纽约，244–259。
- en: Ye et al. (2020) Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang,
    and Shikun Zhang. 2020. Leveraging code generation to improve code retrieval and
    summarization via dual learning. In *Proceedings of The Web Conference 2020*.
    2309–2319.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 叶等人 (2020) 叶伟、谢瑞、张晶雷、胡天翔、王晓音和张世坤。2020年。《利用代码生成来改进代码检索和总结，通过双重学习》。在*2020年网络大会论文集*。2309–2319。
- en: Yin et al. (2011) Zuoning Yin, Xiao Ma, Jing Zheng, Yuanyuan Zhou, Lakshmi N
    Bairavasundaram, and Shankar Pasupathy. 2011. An empirical study on configuration
    errors in commercial and open source systems. In *Proceedings of the Twenty-Third
    ACM Symposium on Operating Systems Principles*. 159–172.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尹等人 (2011) 尹作宁、马晓、郑静、周媛媛、拉克希米·N·巴拉瓦苏达拉姆和尚卡尔·帕苏帕提。2011年。《对商业和开源系统中的配置错误的实证研究》。在*第二十三届ACM操作系统原理研讨会论文集*。159–172。
- en: Yonkovit ([n.d.]) Matt Yonkovit. [n.d.]. *Netherlands ’will pay the price’ for
    blocking Turkish visit – Erdoğan*. [https://www.percona.com/blog/cost-not-properly-managing-databases/](https://www.percona.com/blog/cost-not-properly-managing-databases/)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约科维特 ([n.d.]) 马特·约科维特。*[荷兰将为阻止土耳其访问付出代价 – 埃尔多安]*。 [https://www.percona.com/blog/cost-not-properly-managing-databases/](https://www.percona.com/blog/cost-not-properly-managing-databases/)
- en: Yuan et al. (2023) Zhiqiang Yuan, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin
    Wang, Yixuan Chen, and Xin Peng. 2023. No more manual tests? evaluating and improving
    ChatGPT for unit test generation. *arXiv preprint arXiv:2305.04207* (2023).
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 袁等人 (2023) 袁志强、楼怡凌、刘铭伟、丁世基、王凯欣、陈奕轩和彭鑫。2023年。《不再需要手动测试？评估和改进ChatGPT用于单元测试生成》。*arXiv预印本
    arXiv:2305.04207* (2023)。
- en: Zhang et al. (2015) Yi Zhang, Jianmei Guo, Eric Blais, and Krzysztof Czarnecki.
    2015. Performance prediction of configurable software systems by fourier learning
    (t). In *2015 30th IEEE/ACM International Conference on Automated Software Engineering
    (ASE)*. IEEE, 365–373.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人 (2015) 张毅、郭建梅、埃里克·布莱斯和克日斯托夫·查尔涅茨基。2015年。《通过傅里叶学习 (t) 预测可配置软件系统的性能》。在*2015年第30届IEEE/ACM国际自动化软件工程大会
    (ASE)*。IEEE，365–373。
- en: 'Zhang et al. (2024) Yuxia Zhang, Zhiqing Qiu, Klaas-Jan Stol, Wenhui Zhu, Jiaxin
    Zhu, Yingchen Tian, and Hui Liu. 2024. Automatic Commit Message Generation: A
    Critical Review and Directions for Future Work. *IEEE Transactions on Software
    Engineering* (2024).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人 (2024) 张玉霞、邱智青、克拉斯-简·斯托尔、朱文辉、朱佳欣、田英辰和刘辉。2024年。《自动提交信息生成：关键评估与未来工作的方向》。*IEEE软件工程汇刊*
    (2024)。
- en: 'Zhao et al. (2023) Ruochen Zhao, Hailin Chen, Weishi Wang, Fangkai Jiao, Xuan Long
    Do, Chengwei Qin, Bosheng Ding, Xiaobao Guo, Minzhi Li, Xingxuan Li, et al. 2023.
    Retrieving multimodal information for augmented generation: A survey. *arXiv preprint
    arXiv:2303.10868* (2023).'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 赵等人 (2023) 赵若辰、陈海林、王伟世、焦芳凯、龙轩、秦成伟、丁博生、郭晓宝、李敏智、李兴轩等。2023年。《用于增强生成的多模态信息检索：综述》。*arXiv预印本
    arXiv:2303.10868* (2023)。
- en: 'Zhong et al. (2024) Li Zhong, Zilong Wang, and Jingbo Shang. 2024. LDB: A Large
    Language Model Debugger via Verifying Runtime Execution Step-by-step. *arXiv preprint
    arXiv:2402.16906* (2024).'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 钟等人 (2024) 钟立、王子龙和尚靖波。2024年。《LDB：一种通过逐步验证运行时执行的大型语言模型调试器》。*arXiv预印本 arXiv:2402.16906*
    (2024)。
