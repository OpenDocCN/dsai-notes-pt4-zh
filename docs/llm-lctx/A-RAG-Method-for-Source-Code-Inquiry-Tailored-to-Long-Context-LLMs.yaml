- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 19:03:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 19:03:54'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 针对长上下文 LLM 的源代码查询 RAG 方法
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.06082](https://ar5iv.labs.arxiv.org/html/2404.06082)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2404.06082](https://ar5iv.labs.arxiv.org/html/2404.06082)
- en: Toshihiro Kamiya
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Toshihiro Kamiya
- en: Institute of Science and Engineering, Shimane University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 島根大学科学与工程学院
- en: 1 Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: The development of text generation AI (large language models; LLMs) has been
    remarkable. LLMs have started to be used in software development as well, and
    AI assistant tools such as GitHub Copilot have emerged. However, there are still
    challenges with LLMs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成 AI（大型语言模型；LLMs）的发展非常显著。LLMs 已经开始在软件开发中使用，像 GitHub Copilot 这样的 AI 助手工具也应运而生。然而，LLMs
    仍然面临挑战。
- en: One of the issues frequently pointed out with LLMs is the context length limitation.
    The context length limitation refers to the upper bound on the length of context
    that an LLM can consider when generating text. For example, the LLM called `gpt-4-32k`
    from OpenAI has a context length limitation of 32k tokens (approximately 60k characters
    in English). In user interfaces like ChatGPT’s chat interface, it is common to
    implement an error when the input text exceeds this limit.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 常被指出的一个问题是上下文长度限制。上下文长度限制指的是 LLM 在生成文本时可以考虑的上下文长度的上限。例如，OpenAI 的 `gpt-4-32k`
    语言模型的上下文长度限制为 32k tokens（大约 60k 英文字符）。在像 ChatGPT 的聊天界面这样的用户界面中，当输入文本超过此限制时，通常会实现错误。
- en: While LLMs that support long context input have emerged, even with such LLMs,
    according to research by Levy et al. [[2](#bib.bib2)], the inference performance
    of LLMs decreases as the input text becomes longer, leading to the so-called needle
    in a haystack problem.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已经出现了支持长上下文输入的 LLMs，但即使是这样的 LLMs，根据 Levy 等人的研究[[2](#bib.bib2)]，随着输入文本变长，LLMs
    的推理性能会下降，导致所谓的“大海捞针”问题。
- en: Source code for software can easily exceed tens of thousands of lines, so inquiries
    that include source code may exceed the context length limitation, making it difficult
    to obtain high-quality answers. In current software development, extensive reuse
    is practiced. Even if the product being developed has a small or compact source
    code, it is common for the code to expand by dozens of times when including the
    source code of the reused libraries, including frameworks. Therefore, the context
    length limitation of LLMs becomes an issue when making inquiries such as identifying
    the cause of a bug or investigating the implementation of a specific feature.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 软件的源代码容易超过数万行，因此包含源代码的查询可能会超过上下文长度限制，使得获得高质量的答案变得困难。在当前的软件开发中，广泛重用是普遍做法。即使正在开发的产品源代码较小或紧凑，包含重用库（包括框架）的源代码时，代码量通常会膨胀数十倍。因此，在进行例如识别错误原因或调查特定功能实现等查询时，LLMs
    的上下文长度限制成为一个问题。
- en: One method to mitigate the context length limitation of LLMs is RAG (Retrieval-Augmented
    Generation) [[3](#bib.bib3)]. In RAG, documents relevant to the inquiry in the
    prompt are retrieved and filtered from a database, web search, or some other method,
    and these documents are added to the original prompt as input to the LLM, allowing
    for answers based on the content of the documents. For example, if the prompt
    is ”Tell me about the habits of cats,” the Wikipedia article ”Cat” can be searched
    and its text added to the prompt to obtain a more detailed answer. For inquiries
    about a software product, the source code of the product itself or the products
    being reused can be used as the documents to be added to the original prompt in
    RAG.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解大语言模型（LLMs）上下文长度限制的一种方法是 RAG（检索增强生成）[[3](#bib.bib3)]。在 RAG 中，与提示中的查询相关的文档会从数据库、网页搜索或其他方法中检索并筛选出来，这些文档会作为输入添加到原始提示中，使得
    LLM 可以根据文档的内容生成回答。例如，如果提示是“告诉我关于猫的习性”，可以搜索维基百科文章“猫”，并将其文本添加到提示中，以获得更详细的回答。对于关于软件产品的查询，可以使用产品本身的源代码或被重用的产品作为要添加到
    RAG 原始提示中的文档。
- en: Another method to mitigate the context length limitation of LLMs is to use LLMs
    with larger contexts from the beginning. However, for the Transformer-based LLMs
    that are widely used today, the computational cost is proportional to the square
    of the context length, so increasing the context length directly leads to an increase
    in computational cost.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解LLMs上下文长度限制的另一种方法是从一开始就使用具有更大上下文的LLMs。然而，对于当前广泛使用的基于Transformer的LLMs，计算成本与上下文长度的平方成正比，因此增加上下文长度直接导致计算成本增加。
- en: In this research, we propose a RAG method for inquiries about the source code
    of software products. The proposed method aims to mitigate and solve the needle
    in a haystack problem by obtaining accurate answers without referring to the entire
    source code, by executing the product to obtain an execution trace (log of called
    functions), extracting the call tree and source code of the called functions from
    the execution trace, and inputting them to the LLM as documents for RAG.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们提出了一种用于软件产品源代码查询的RAG方法。该方法旨在通过执行产品以获取执行跟踪（调用函数的日志）、从执行跟踪中提取调用树和调用函数的源代码，并将其输入到LLM作为RAG文档，来缓解和解决大海捞针的问题，准确获得答案而无需参考整个源代码。
- en: 2 Related Research
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关研究
- en: As research on applying LLMs to software development, a study [[1](#bib.bib1)]
    on using LLMs for bug localization proposes a method where error messages from
    failed test cases are input to the LLM to identify the cause, and further, to
    identify the location of the bug.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在将LLMs应用于软件开发的研究中，一项关于使用LLMs进行错误定位的研究 [[1](#bib.bib1)] 提出了一种方法，将失败的测试用例中的错误信息输入LLM，以确定原因，并进一步确定错误的位置。
- en: Tools have been proposed that incorporate LLMs into IDEs to assist developers
    in understanding source code and APIs [[4](#bib.bib4)]. The goal is to improve
    the efficiency of developers’ work by answering their questions and automatically
    displaying summaries of the code, without interrupting their concentration.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 已提出一些工具，将LLMs集成到IDE中，以帮助开发者理解源代码和API [[4](#bib.bib4)]。其目标是通过回答开发者的问题并自动显示代码摘要来提高开发者的工作效率，而不干扰他们的专注力。
- en: The literature [[6](#bib.bib6)] points out that existing benchmarks may not
    be able to accurately evaluate the performance of LLMs because the training data
    includes answer examples. This issue is also partially encountered in the experiment
    described in Section [4.4](#S4.SS4 "4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method
    for Source Code Inquiry Tailored to Long-Context LLMs").
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 文献 [[6](#bib.bib6)] 指出，现有基准可能无法准确评估LLMs的性能，因为训练数据包含答案示例。这个问题在第[4.4](#S4.SS4
    "4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs")节描述的实验中也部分存在。
- en: 'A blog post¹¹1Using GitHub Copilot in your IDE: Tips, tricks, and best practices,
    https://github.blog/2024-03-25-how-to-use-github-copilot-in-your-ide-tips-tricks-and-best-practices/
    for the GitHub Copilot software development AI assistant tool states that to obtain
    appropriate responses from the AI, you should open files related to the task you
    are currently working on, in order to provide the LLM with the appropriate context.
    The method proposed in this research automatically identifies the source code
    that should be shown to the LLM by dynamically analyzing the target product.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇博文¹¹1使用GitHub Copilot的IDE中的提示、技巧和最佳实践，https://github.blog/2024-03-25-how-to-use-github-copilot-in-your-ide-tips-tricks-and-best-practices/
    提到，为了从AI中获得适当的响应，您应打开与当前任务相关的文件，以为LLM提供适当的上下文。本研究中提出的方法通过动态分析目标产品自动识别应向LLM显示的源代码。
- en: 3 Approach
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: The proposed method takes a user inquiry and the execution trace of the software
    as input, and identifies the corresponding source code through the following steps,
    which is then input to the LLM.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所提出的方法以用户查询和软件的执行跟踪作为输入，通过以下步骤识别相应的源代码，然后将其输入LLM。
- en: Step 1. The user inputs an inquiry about a software product and the trace (log
    of called functions) collected when executing the feature related to that inquiry.
    The execution trace is obtained using the trace collection tool `rapt` developed
    by the author. This tool executes the target Python script and collects a log
    of the called functions. The location information (source file and line number)
    of the functions in the source code is also collected. For example, in the experiment
    described in Section [4.4](#S4.SS4 "4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method
    for Source Code Inquiry Tailored to Long-Context LLMs"), an inquiry is made about
    the feature of formatting and displaying CSV files in the `rich-cli` command-line
    interface (CLI) tool, and the execution trace is collected by displaying a CSV
    file.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第1步。用户输入有关软件产品的查询以及执行与该查询相关功能时收集的跟踪（被调用函数的日志）。执行跟踪使用作者开发的跟踪收集工具`rapt`获得。该工具执行目标Python脚本并收集被调用函数的日志。还收集源代码中函数的位置（源文件和行号）信息。例如，在第[4.4](#S4.SS4
    "4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs")节中描述的实验中，查询有关`rich-cli`命令行工具中格式化和显示CSV文件的功能，并通过显示CSV文件收集执行跟踪。
- en: Step 2. Analyze the execution trace and identify the executed functions and
    methods, as well as their call relationships.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 第2步。分析执行跟踪，识别执行的函数和方法及其调用关系。
- en: Step 3. Identify the corresponding source code file and the location of the
    function within it from the names of the called functions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步。根据被调用函数的名称，识别相应的源代码文件及其中函数的位置。
- en: Step 4. Create a call graph (a graph representing the call relationships between
    functions) from the call relationships, and further generate a call tree (tree
    structure) by removing loops and other constructs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步。从调用关系中创建调用图（表示函数之间调用关系的图），并进一步通过去除循环和其他构造生成调用树（树结构）。
- en: Step 5. Input the prompt, which is the inquiry text appended with the call tree
    and the source code of the functions within the call tree, to the LLM and output
    the response.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第5步。将包含调用树和调用树中函数的源代码的查询文本输入到LLM中，并输出响应。
- en: In this case, the source code of the functions is arranged in the order they
    appear in the call tree. In other words, if a function `f` calls another function
    `g`, the source code of `g` is placed after the source code of `f`. This ordering
    is intended to make it easier for the LLM to follow the execution flow by showing
    the lines of source code in the order they are executed. The experiment described
    in Section [4.4](#S4.SS4 "4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for
    Source Code Inquiry Tailored to Long-Context LLMs") evaluates the effect of this
    ordering.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，函数的源代码按它们在调用树中出现的顺序排列。换句话说，如果函数`f`调用了另一个函数`g`，则`g`的源代码放在`f`的源代码之后。这种排序旨在通过按执行顺序展示源代码行来使LLM更容易跟随执行流程。第[4.4](#S4.SS4
    "4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs")节中描述的实验评估了这种排序的效果。
- en: 3.1 Practical Considerations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 实际考虑
- en: 'In the implementation of the proposed method, the following processing is performed
    to represent the call tree in a compact form:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在所提方法的实现中，为了将调用树以紧凑的形式表示，执行以下处理：
- en: (1) When a function calls the same function multiple times, the called function
    is represented as a single node. Also, when a function is called from different
    functions, the called function nodes are represented separately (not merged).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: （1）当一个函数多次调用相同函数时，被调用的函数表示为一个单独的节点。此外，当一个函数被不同函数调用时，被调用函数的节点分别表示（不进行合并）。
- en: As a result, such a call tree becomes a tree obtained by removing recursion
    (i.e., cycles in the graph) and merging (i.e., parts of the graph where nodes
    have multiple incoming edges) from the call graph represented as a directed graph.
    By representing it as a tree structure, it is expected to become easier to determine
    the order in which to append the source code to the prompt.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这种调用树是通过从表示为有向图的调用图中去除递归（即图中的环路）和合并（即节点有多个入边的图的部分）得到的树。通过将其表示为树结构，预计将更容易确定将源代码附加到提示中的顺序。
- en: (2) When there is a recursive call, the hierarchy up to the node where the first
    recursive call occurs is represented, and nodes for deeper recursive calls are
    omitted. Recursive calls are sometimes used for iteration, and this avoids generating
    an excessively large call tree in such cases.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 当发生递归调用时，只表示到第一次递归调用发生的节点的层次，省略了更深递归调用的节点。递归调用有时用于迭代，这样可以避免在这种情况下生成过大的调用树。
- en: (3) Other considerations and limitations
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 其他考虑因素和限制
- en: The execution trace collection tool `rapt` only records the calls of functions
    within the modules specified by the user. Calls to built-in functions (e.g., `print`)
    or functions in the standard library are not recorded.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 执行跟踪收集工具 `rapt` 仅记录用户指定模块内函数的调用。对内置函数（例如，`print`）或标准库中的函数调用不会被记录。
- en: '`rapt` adopts a method of wrapping functions and logging their calls during
    the execution of the target product. However, due to the limitations of this implementation
    method, it is not possible to record calls to functions of dynamically (lazily)
    loaded modules or functions that are not in the global scope (such as lambdas).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`rapt` 采用了一种在目标产品执行期间包装函数并记录其调用的方法。然而，由于这种实现方法的限制，无法记录对动态（延迟）加载模块的函数调用或不在全局作用域中的函数（如匿名函数）的调用。'
- en: In general, programs perform module imports and initialization during startup.
    Since there may be cases where such processing needs to be excluded from the analysis,
    a branch pruning function for the call tree was implemented. To perform branch
    pruning, first, an execution trace is obtained by executing the program without
    running its functionality (by immediately exiting after program start). The functions
    included in such a call tree are considered to be related to startup, and if the
    same node (same function call) is present in the leaves of the call tree being
    analyzed, it is removed.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，程序在启动期间会执行模块导入和初始化。由于可能存在需要将此类处理排除在分析之外的情况，实施了调用树的分支修剪功能。要执行分支修剪，首先，通过在不运行其功能的情况下执行程序（程序启动后立即退出）来获取执行跟踪。此类调用树中包含的函数被认为与启动相关，如果分析的调用树的叶子中存在相同的节点（相同的函数调用），则将其移除。
- en: 4 Experiments
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: In this section, we evaluate the proposed method by applying it to an open-source
    product. We prepared specific inquiries that could occur during software development
    and criteria for evaluating the quality of responses to those inquiries (described
    later). We create variants by changing the content of the prompt (presence or
    order of the call tree and function source code) and analyze whether the proposed
    method contributes to the quality of the response by making inquiries with these
    variants and evaluating the quality of the responses (evaluation criteria described
    later).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过将提出的方法应用于开源产品来评估它。我们准备了在软件开发过程中可能出现的具体查询和评估这些查询的响应质量的标准（后文描述）。我们通过更改提示的内容（调用树的存在或顺序以及函数源代码）来创建变体，并通过这些变体进行查询，分析提出的方法是否有助于响应质量，然后评估响应的质量（评估标准后文描述）。
- en: 4.1 Target Product
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 目标产品
- en: For the experiment, we selected the OSS command-line tool `rich-cli`²²2rich-cli
    https://github.com/Textualize/rich-cli as the target. The reasons for choosing
    this tool are that it is feature-rich and has an appropriate scale (approximately
    220k lines) for the experiment, and because it is a CLI tool, it is easy to maintain
    consistent conditions when running repeatedly (high reproducibility). The `rich-cli`
    tool has the ability to take files in formats such as CSV, Markdown, and ReStructuredText
    as input, and format and display them in the terminal with syntax highlighting,
    among other features.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验中，我们选择了 OSS 命令行工具 `rich-cli`²²2rich-cli https://github.com/Textualize/rich-cli
    作为目标。选择这个工具的原因是它功能丰富，且规模适中（大约 220k 行），并且由于它是 CLI 工具，重复运行时容易保持一致的条件（高可重复性）。`rich-cli`
    工具能够接收 CSV、Markdown 和 ReStructuredText 等格式的文件作为输入，并在终端中格式化并显示它们，包括语法高亮等功能。
- en: Table [1](#S4.T1 "Table 1 ‣ 4.1 Target Product ‣ 4 Experiments ‣ A RAG Method
    for Source Code Inquiry Tailored to Long-Context LLMs") shows the line counts
    (measured using the `cloc`³³3Cloc https://github.com/AlDanial/cloc tool) of Python
    source files for the target product and the libraries (packages) it directly and
    indirectly depends on. The target product `rich-cli` itself is only 900 lines,
    as it is a tool that allows the functionality of libraries such as `rich` and
    `rich-rst` to be accessed from the command line. However, including the dependent
    libraries, the total is approximately 220k lines.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [1](#S4.T1 "表 1 ‣ 4.1 目标产品 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询 RAG 方法") 显示了目标产品及其直接和间接依赖的库（包）的
    Python 源文件的行数（使用 `cloc` 工具测量）。目标产品 `rich-cli` 本身只有 900 行，因为它是一个允许从命令行访问如 `rich`
    和 `rich-rst` 等库功能的工具。然而，包括所有依赖库，总行数约为 220k 行。
- en: 'Table 1: Packages that make up the target product'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 组成目标产品的包'
- en: '| Package | Version | Python Lines |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 包 | 版本 | Python 行数 |'
- en: '| --- | --- | --- |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| certifi | 2024.2.2 | 63 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| certifi | 2024.2.2 | 63 |'
- en: '| charset-normalizer | 3.3.2 | 4,022 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| charset-normalizer | 3.3.2 | 4,022 |'
- en: '| click | 8.1.7 | 5,659 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| click | 8.1.7 | 5,659 |'
- en: '| docutils | 0.20.1 | 28,303 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| docutils | 0.20.1 | 28,303 |'
- en: '| idna | 3.6 | 11,142 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| idna | 3.6 | 11,142 |'
- en: '| linkify-it-py | 2.0.3 | 2,032 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| linkify-it-py | 2.0.3 | 2,032 |'
- en: '| markdown-it-py | 3.0.0 | 4,226 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| markdown-it-py | 3.0.0 | 4,226 |'
- en: '| mdit-py-plugins | 0.4.0 | 2,440 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| mdit-py-plugins | 0.4.0 | 2,440 |'
- en: '| mdurl | 0.1.2 | 342 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| mdurl | 0.1.2 | 342 |'
- en: '| Pygments | 2.17.2 | 94,240 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| Pygments | 2.17.2 | 94,240 |'
- en: '| requests | 2.31.0 | 2,904 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| requests | 2.31.0 | 2,904 |'
- en: '| rich | 13.7.1 | 19,638 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| rich | 13.7.1 | 19,638 |'
- en: '| rich-cli | 1.8.0 | 900 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| rich-cli | 1.8.0 | 900 |'
- en: '| rich-rst | 1.2.0 | 569 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| rich-rst | 1.2.0 | 569 |'
- en: '| textual | 0.54.0 | 33,438 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| textual | 0.54.0 | 33,438 |'
- en: '| typing_extensions | 4.10.0 | 1,633 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| typing_extensions | 4.10.0 | 1,633 |'
- en: '| uc-micro-py | 1.0.3 | 14 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| uc-micro-py | 1.0.3 | 14 |'
- en: '| urllib3 | 2.2.1 | 6,419 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| urllib3 | 2.2.1 | 6,419 |'
- en: '| (Total) |  | 217,984 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| (总计) |  | 217,984 |'
- en: 4.2 LLMs Used in the Experiment
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 实验中使用的 LLM
- en: Table [2](#S4.T2 "Table 2 ‣ 4.2 LLMs Used in the Experiment ‣ 4 Experiments
    ‣ A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs") shows the
    context length limits (in tokens) of the LLMs Gemini 1.5 Pro [[5](#bib.bib5)],
    Claude 3 Sonnet, and ChatGPT-4 used in the experiment. As described in Section
    [4.5](#S4.SS5 "4.5 Experiment 2 ‣ 4 Experiments ‣ A RAG Method for Source Code
    Inquiry Tailored to Long-Context LLMs") below, the length of the generated prompts
    can reach up to around 87k tokens, so LLMs capable of handling relatively large
    contexts were selected. In all cases, the responses were generated by pasting
    the prompts into a chat-style UI, without using an API. Each LLM uses a different
    tokenizer (a function that splits text into tokens), so the token count for the
    same text will differ, making the context length limit only a rough guideline.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [2](#S4.T2 "表 2 ‣ 4.2 实验中使用的 LLM ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询 RAG 方法") 显示了实验中使用的
    LLM Gemini 1.5 Pro [[5](#bib.bib5)]、Claude 3 Sonnet 和 ChatGPT-4 的上下文长度限制（以 token
    为单位）。如第 [4.5](#S4.SS5 "4.5 实验 2 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询 RAG 方法") 节所述，生成的提示长度可以达到约
    87k tokens，因此选择了能够处理相对较大上下文的 LLM。在所有情况下，响应都是通过将提示粘贴到聊天式 UI 中生成的，没有使用 API。每个 LLM
    使用不同的分词器（将文本拆分成 token 的函数），因此相同文本的 token 数量会有所不同，使得上下文长度限制仅为粗略指导。
- en: 'Table 2: LLMs used in the experiment'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 实验中使用的 LLM'
- en: '| LLM | c. | Service Used |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| LLM | c. | 使用的服务 |'
- en: '| --- | --- | --- |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Gemini 1.5 Pro | 1M | Accessed from Google AI Studio |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| Gemini 1.5 Pro | 1M | 来源于 Google AI Studio |'
- en: '| Claude 3 Sonnet | 200K | Accessed from poe.com |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| Claude 3 Sonnet | 200K | 来源于 poe.com |'
- en: '| ChatGPT-4 | 128K | Accessed from poe.com |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT-4 | 128K | 来源于 poe.com |'
- en: The c. column shows the context length limit (in tokens).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: c. 列显示了上下文长度限制（以 token 为单位）。
- en: 4.3 Prompt Variants
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 提示变体
- en: The proposed method includes the call tree and source code in the prompt. To
    experimentally evaluate the effect of including these in the prompt, we create
    variants by removing or reordering them from the prompt generated by the proposed
    method and evaluate the quality of the responses. Table [3](#S4.T3 "Table 3 ‣
    4.3 Prompt Variants ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs") shows the variants of the prompt used in the experiment.
    Figure [1](#S4.F1 "Figure 1 ‣ 4.3 Prompt Variants ‣ 4 Experiments ‣ A RAG Method
    for Source Code Inquiry Tailored to Long-Context LLMs") shows an example of the
    prompt used in the following Section [4.4](#S4.SS4 "4.4 Experiment 1 ‣ 4 Experiments
    ‣ A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs").
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的方法包括了调用树和源代码在提示中。为了实验性地评估将这些包含在提示中的效果，我们通过从提议的方法生成的提示中移除或重新排序它们来创建变体，并评估响应的质量。表格
    [3](#S4.T3 "表 3 ‣ 4.3 提示变体 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询的 RAG 方法") 显示了实验中使用的提示变体。图
    [1](#S4.F1 "图 1 ‣ 4.3 提示变体 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询的 RAG 方法") 显示了在后续的第 [4.4](#S4.SS4
    "4.4 实验 1 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询的 RAG 方法") 节中使用的提示示例。
- en: 'Table 3: Prompt Variants'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：提示变体
- en: '| Variant | Description |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 变体 | 描述 |'
- en: '| --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| full | The prompt generated by the proposed method itself, including the
    inquiry text, call tree, and source code of the functions within the call tree
    in the order they appear in the call tree. If the same function appears multiple
    times in the call tree, its source code is included multiple times in the prompt.
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| full | 由提议的方法生成的提示本身，包括询问文本、调用树，以及调用树中出现的函数的源代码，按调用树中出现的顺序排列。如果同一个函数在调用树中出现多次，则其源代码在提示中也会多次包含。
    |'
- en: '| A | Same as full, but the source code within the call tree is sorted by function
    name (including module name). If the same function appears multiple times in the
    call tree, its source code is included only once in the prompt without duplication.
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| A | 与完整提示相同，但调用树中的源代码按函数名称（包括模块名称）排序。如果同一个函数在调用树中出现多次，则其源代码仅在提示中包含一次，不重复。
    |'
- en: '| C | Excludes the call tree from full. The source code of the functions is
    included in the order they appear in the call tree. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| C | 从完整的提示中排除了调用树。函数的源代码按调用树中出现的顺序包括在内。 |'
- en: '| CA | Excludes the call tree from full. The source code of the functions is
    sorted and duplicates are removed. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| CA | 从完整提示中排除了调用树。函数的源代码经过排序，并删除了重复项。 |'
- en: '| T | Excludes the source code from full. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| T | 从完整提示中排除了源代码。 |'
- en: '![Refer to caption](img/0331e5e026b434e60ba61d7ec10b9418.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0331e5e026b434e60ba61d7ec10b9418.png)'
- en: 'Figure 1: Example prompt'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：示例提示
- en: 4.4 Experiment 1
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 实验 1
- en: We create prompts following the proposed method for specific inquiries that
    could arise during software development, input them to LLMs, and evaluate their
    responses according to the evaluation criteria. In this experiment, the response
    generation is performed only once for each prompt variant and each LLM. With the
    chat-style UI of the LLM services, a random number is used, so the content of
    the response differs each time it is generated. In that sense as well, the evaluation
    of the responses is not absolute, but should be noted as an assessment of the
    overall trend.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据提议的方法为在软件开发过程中可能出现的具体查询创建提示，将其输入到 LLM 中，并根据评估标准评估其响应。在本实验中，每个提示变体和每个 LLM
    仅执行一次响应生成。由于 LLM 服务的聊天式 UI 使用了随机数，因此每次生成的响应内容有所不同。从这个角度来看，响应的评估也不是绝对的，但应作为整体趋势的评估进行记录。
- en: 4.4.1 Prompt 1
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1 提示 1
- en: The tool has a feature to format and display CSV files in the terminal. This
    feature uses line characters to create the appearance of a table. The inquiry
    asks what function determines this appearance (such as the type of line or right
    alignment) and how to change the appearance. The command line of the tool does
    not provide a way to change the format, so the source code needs to be modified.
    The correct answer for the location to be modified was determined by considering
    the ability to confirm that the change would modify the functionality of the product,
    that no modifications other than the indicated location are necessary, and that
    the impact on other features of the product should be minimized as much as possible.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具具有在终端中格式化和显示 CSV 文件的功能。此功能使用行字符创建表格的外观。查询询问确定这种外观的函数（例如行的类型或右对齐）以及如何更改外观。工具的命令行不提供更改格式的方法，因此需要修改源代码。正确的修改位置是通过考虑能够确认更改会修改产品功能、除了指示的位置外不需要其他修改，并尽可能减少对产品其他功能的影响来确定的。
- en: The author visually inspected each response and evaluated it on a 4-point scale
    according to the following criteria. Items in the response that were deemed to
    be incorrect explanations or hallucinations were deducted points.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作者对每个响应进行了目视检查，并根据以下标准用 4 分制进行评估。对被认为是错误解释或幻觉的响应内容扣分。
- en: \Circled
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 1 The name of the class or function that implements the feature can be output
    (1 point). If multiple instances are mentioned and the correct one is included,
    0.5 points.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 1 实现该功能的类或函数的名称可以输出（1 分）。如果提到多个实例且包含正确的实例，则得 0.5 分。
- en: \Circled
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 2 In addition to lines, elements such as color and padding that affect the appearance
    of the table are explained (1 point).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 2 除了行之外，还解释了影响表格外观的元素，如颜色和填充（1 分）。
- en: \Circled
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 3 The content of the change (the modified code or how to modify it) can be output
    (1 point). If multiple instances are mentioned and the correct one is included,
    0.5 points.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 3 变更的内容（修改的代码或如何修改）可以输出（1 分）。如果提到多个实例且包含正确的实例，则得 0.5 分。
- en: \Circled
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 4 The location to be modified can be output by function name (1 point). If multiple
    instances are mentioned and the correct one is included, 0.5 points.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 4 可以通过函数名称输出修改的位置（1 分）。如果提到多个实例且包含正确的实例，则得 0.5 分。
- en: The results for Prompt 1 are shown in Table [4](#S4.T4 "Table 4 ‣ 4.4.1 Prompt
    1 ‣ 4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs"). The evaluation scores for the responses obtained from
    all LLMs and all variants were high. However, for the T variant, which included
    only the inquiry text and the call tree where function names are nodes, some responses
    included the name of a global variable. This could be due to hallucination or
    the possibility that the LLM’s training data included information about the `rich`
    package, causing the response to be generated based on the learned information
    rather than the content of the prompt (suspected data leakage).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 1 的结果显示在表 [4](#S4.T4 "Table 4 ‣ 4.4.1 Prompt 1 ‣ 4.4 Experiment 1 ‣ 4 Experiments
    ‣ A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs") 中。所有 LLM
    和所有变体的响应评估得分都很高。然而，对于仅包含查询文本和函数名称为节点的调用树的 T 变体，有些响应中包含了全局变量的名称。这可能是由于幻觉或 LLM 的训练数据中包含了有关
    `rich` 包的信息，导致响应基于学习到的信息生成，而不是基于提示的内容（怀疑数据泄漏）。
- en: 'Table 4: Evaluation scores for Prompt 1 responses'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：提示 1 响应的评估得分
- en: '| LLM | full | A | C | CA | T |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| LLM | full | A | C | CA | T |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Gemini 1.5 Pro | 4.0 | 4.0 | 4.0 | 3.0 | 4.0* |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Gemini 1.5 Pro | 4.0 | 4.0 | 4.0 | 3.0 | 4.0* |'
- en: '| Claude 3 Sonnet | 4.0 | 4.0 | 4.0 | 4.0 | 4.0 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Claude 3 Sonnet | 4.0 | 4.0 | 4.0 | 4.0 | 4.0 |'
- en: '| ChatGPT-4 | 3.0 | 4.0 | 4.0 | 3.0 | 4.0* |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT-4 | 3.0 | 4.0 | 4.0 | 3.0 | 4.0* |'
- en: The numbers marked with * indicate that the name of a global variable not included
    in the call tree was included in the response.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 标记为 * 的数字表示响应中包含了调用树中未包含的全局变量名称。
- en: 4.4.2 Prompt 2
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2 提示 2
- en: The tool has a feature to format and display Markdown files containing tables
    in the terminal. Similar to Prompt 1, we inquired about how to change the appearance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具具有在终端中格式化和显示包含表格的 Markdown 文件的功能。与提示 1 类似，我们询问了如何更改外观。
- en: Since Markdown has many formatting options besides tables, such as lists and
    quotes, the parsing performed is more complex compared to processing CSV files.
    As a result, there are more classes and methods involved in the processing, making
    it more difficult than Prompt 1. The same evaluation criteria as Prompt 1 were
    used.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Markdown 除了表格还有许多格式化选项，如列表和引用，因此与处理 CSV 文件相比，解析过程更为复杂。因此，处理时涉及的类和方法更多，比 Prompt
    1 更加困难。使用了与 Prompt 1 相同的评价标准。
- en: The results for Prompt 2 are shown in Table [5](#S4.T5 "Table 5 ‣ 4.4.2 Prompt
    2 ‣ 4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs"). For all LLMs, the maximum evaluation score was obtained
    from the responses generated by the full or A variants. Additionally, as with
    Prompt 1, the responses for the T variant included suspected data leakage.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt 2 的结果见表[5](#S4.T5 "Table 5 ‣ 4.4.2 Prompt 2 ‣ 4.4 Experiment 1 ‣ 4 Experiments
    ‣ A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs")。对于所有LLM，从完整或A变体生成的响应中获得了最高评价分数。此外，与
    Prompt 1 一样，T 变体的响应中包括了疑似数据泄露的内容。
- en: 'Table 5: Evaluation scores for Prompt 2 responses'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：Prompt 2 响应的评价分数
- en: '| LLM | full | A | C | CA | T |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| LLM | full | A | C | CA | T |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Gemini 1.5 Pro | 4.0 | 4.0 | 4.0 | 2.0 | 3.0* |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Gemini 1.5 Pro | 4.0 | 4.0 | 4.0 | 2.0 | 3.0* |'
- en: '| Claude 3 Sonnet | 2.0 | 3.5 | 1.5 | 2.5 | 2.5 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Claude 3 Sonnet | 2.0 | 3.5 | 1.5 | 2.5 | 2.5 |'
- en: '| ChatGPT-4 | 4.0 | 3.0 | 3.0 | 3.0 | 3.5* |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT-4 | 4.0 | 3.0 | 3.0 | 3.0 | 3.5* |'
- en: The numbers marked with * indicate that the name of a global variable not included
    in the call tree was included in the response.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 带有 * 的数字表示响应中包含了一个未包含在调用树中的全局变量的名称。
- en: 4.4.3 Prompt 3
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.3 Prompt 3
- en: 'We compared the feature used in Prompt 1 to format and display CSV files in
    the terminal and the feature used in Prompt 2 to format and display Markdown files
    containing tables in the terminal. Specifically, we inquired about the differences
    and similarities in implementation, differences in control flow and data structures,
    and differences in table-related functionality. Prompt 3 was the longest in the
    experiment and serves as a benchmark for testing the scalability of the proposed
    method. The following evaluation criteria were used:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了 Prompt 1 中用于格式化和显示终端中的 CSV 文件的功能与 Prompt 2 中用于格式化和显示包含表格的 Markdown 文件的功能。具体而言，我们询问了实现中的差异和相似之处、控制流和数据结构的差异，以及表格相关功能的差异。Prompt
    3 是实验中最长的一个，作为测试所提方法可扩展性的基准。使用了以下评价标准：
- en: \Circled
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 1 Differences and similarities in implementation are explained (1 point).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 实现的差异和相似之处被解释（1分）。
- en: \Circled
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 2 Names of important functions or methods that illustrate differences in control
    flow are provided. 1 point if both are correct. 0.5 points if one is correct.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 2 个显示控制流差异的重要函数或方法的名称被提供。如果两个都正确则得1分。如果其中一个正确则得0.5分。
- en: \Circled
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 3 Differences in the data structures used are explained by class names. 1 point
    if both are correct. 0.5 points if one is correct.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 3 个数据结构的差异通过类名解释。如果两个都正确则得1分。如果其中一个正确则得0.5分。
- en: \Circled
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 4 Differences in table-related functionality between the two (e.g., right alignment)
    are explained (1 point). General Markdown features (such as links) are excluded.
    If specific examples like right alignment are not provided and only terms like
    ”styles” are used, 0.5 points.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 两者之间的表格相关功能的差异（例如，右对齐）被解释（1分）。一般的Markdown特性（如链接）被排除。如果没有提供具体示例如右对齐，而仅使用“样式”等术语，则得0.5分。
- en: 'Since Prompt 3 requires comparing two executions, the content of the prompt
    was arranged in the following order: the inquiry text, the call tree of the first
    execution, the sequence of source code of functions included in the call tree
    of the first execution, the call tree of the second execution, and the sequence
    of source code of functions included in the call tree of the second execution.
    However, for the CA variant prompt, the content was the inquiry text and the source
    code of functions included in either execution call tree, sorted by function name.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Prompt 3 需要比较两个执行结果，提示内容被安排如下顺序：查询文本、第一个执行的调用树、第一个执行中包含的函数的源代码顺序、第二个执行的调用树，以及第二个执行中包含的函数的源代码顺序。然而，对于
    CA 变体提示，内容包括查询文本和任一执行调用树中包含的函数源代码，按函数名排序。
- en: The results for Prompt 3 are shown in Table [6](#S4.T6 "Table 6 ‣ 4.4.3 Prompt
    3 ‣ 4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs"). The low evaluation score for the full variant of ChatGPT-4
    is notable. This is mere speculation, but since the full variant of Prompt 3 is
    also the longest prompt in this experiment (as described in Section [4.5](#S4.SS5
    "4.5 Experiment 2 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs")), it may have approached the LLM’s context length limit,
    resulting in a degradation of response quality (suspected context length limit
    issue).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 3 的结果见表 [6](#S4.T6 "表 6 ‣ 4.4.3 提示 3 ‣ 4.4 实验 1 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询的
    RAG 方法")。ChatGPT-4 全部变体的低评估分数值得注意。这只是推测，但由于提示 3 的完整变体也是该实验中最长的提示（如第 [4.5](#S4.SS5
    "4.5 实验 2 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询的 RAG 方法")节所述），它可能接近 LLM 的上下文长度限制，导致响应质量下降（怀疑的上下文长度限制问题）。
- en: 'Table 6: Evaluation scores for Prompt 3 responses'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：提示 3 响应的评估分数
- en: '| LLM | full | A | C | CA | T |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| LLM | full | A | C | CA | T |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Gemini 1.5 Pro | 3.5 | 4.0 | 2.0 | 3.0 | 1.5 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| Gemini 1.5 Pro | 3.5 | 4.0 | 2.0 | 3.0 | 1.5 |'
- en: '| Claude 3 Sonnet | 2.0 | 2.0 | 1.5 | 2.0 | 3.0 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Claude 3 Sonnet | 2.0 | 2.0 | 1.5 | 2.0 | 3.0 |'
- en: '| ChatGPT-4 | 1.0 | 3.5 | 2.5 | 1.0 | 3.0 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT-4 | 1.0 | 3.5 | 2.5 | 1.0 | 3.0 |'
- en: 4.4.4 Prompt 4
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.4 提示 4
- en: The tool has a command line option `--emoji` that converts emoji codes (`:sparkle:`,
    etc.) to actual emoji when outputting text. This option works when the text is
    provided as a command line argument, but not when it is provided from a file.
    We inquired about the cause and how to fix it.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具有一个命令行选项 `--emoji`，可以将 emoji 代码（`:sparkle:` 等）转换为实际 emoji，当输出文本时使用。此选项在文本作为命令行参数提供时有效，但在从文件提供时无效。我们查询了原因和解决方法。
- en: Since the implementation differs between text provided as a command line argument
    and text provided from a file, the emoji processing needs to be added to the file
    processing part. Branching based on the presence of the option is also necessary.
    Additionally, to maintain consistency in the tool’s functionality, modifications
    that reuse existing processing are preferable, so reuse was added as an evaluation
    item. Prompt 4 requires making a design decision on where to add the necessary
    processing within the product, making it more difficult compared to the previous
    prompts.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 由于命令行参数和文件提供的文本处理方式不同，因此需要将 emoji 处理添加到文件处理部分。还需要基于选项的存在进行分支。此外，为了保持工具功能的一致性，最好修改已有处理逻辑，因此将重用添加为评估项。提示
    4 需要对产品内添加必要处理的位置做出设计决策，这使其比之前的提示更具挑战性。
- en: 'The evaluation criteria were as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 评估标准如下：
- en: \Circled
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 1 The cause can be output (1 point). If multiple causes are mentioned and the
    correct one is included, 0.5 points.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 1 可以输出原因（1 分）。如果提到了多个原因且包括了正确的一个，则得 0.5 分。
- en: \Circled
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 2 The content of the change (the modified code or how to modify it) can be output
    (1 point). If multiple instances are mentioned and the correct one is included,
    0.5 points.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 2 可以输出更改内容（修改的代码或修改方式）（1 分）。如果提到了多个实例且包括了正确的一个，则得 0.5 分。
- en: \Circled
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 3 The location to be modified can be output by function name (1 point). If multiple
    instances are mentioned and the correct one is included, 0.5 points.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 3 通过函数名称可以输出要修改的位置（1 分）。如果提到了多个实例且包括了正确的一个，则得 0.5 分。
- en: \Circled
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: \Circled
- en: 4 A modification plan that reuses existing functionality can be output (1 point).
    If the plan is to create new functionality, 0.5 points.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 4 一个重用现有功能的修改计划可以得分（1 分）。如果计划是创建新功能，则得 0.5 分。
- en: The results for Prompt 4 are shown in Table [7](#S4.T7 "Table 7 ‣ 4.4.4 Prompt
    4 ‣ 4.4 Experiment 1 ‣ 4 Experiments ‣ A RAG Method for Source Code Inquiry Tailored
    to Long-Context LLMs"). For all LLMs, the maximum evaluation score was obtained
    from the full variant (however, for ChatGPT-4, the evaluation score was 2.5 for
    all variants).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 4 的结果见表 [7](#S4.T7 "表 7 ‣ 4.4.4 提示 4 ‣ 4.4 实验 1 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询的
    RAG 方法")。所有 LLM 中，最大评估分数来自完整变体（但对于 ChatGPT-4，所有变体的评估分数均为 2.5）。
- en: 'Table 7: Evaluation scores for Prompt 4 responses'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：提示 4 响应的评估分数
- en: '| LLM | full | A | C | CA | T |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| LLM | full | A | C | CA | T |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Gemini 1.5 Pro | 4.0 | 2.5 | 2.0 | 3.0 | 1.0 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Gemini 1.5 Pro | 4.0 | 2.5 | 2.0 | 3.0 | 1.0 |'
- en: '| Claude 3 Sonnet | 4.0 | 3.0 | 2.0 | 2.0 | 3.0 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Claude 3 Sonnet | 4.0 | 3.0 | 2.0 | 2.0 | 3.0 |'
- en: '| ChatGPT-4 | 2.5 | 2.5 | 2.5 | 2.5 | 2.5 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT-4 | 2.5 | 2.5 | 2.5 | 2.5 | 2.5 |'
- en: 4.4.5 Analysis
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.5 分析
- en: Figure [2](#S4.F2 "Figure 2 ‣ 4.4.5 Analysis ‣ 4.4 Experiment 1 ‣ 4 Experiments
    ‣ A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs") shows a
    line graph representing the average of Prompts 1 to 4 for each variant (full,
    A, C, CA, T), with the horizontal axis representing the prompt variants and the
    vertical axis representing the aggregated evaluation scores. The solid black line
    (AVE1) uses the raw experimental results, while the black dotted line (AVE2) excludes
    the suspected data leakage observed in Prompts 1 and 2. For example, the black
    circle on the far left indicates that the average evaluation score for the full
    variant across all LLMs and all prompts (1 to 4) is 3.17.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](#S4.F2 "Figure 2 ‣ 4.4.5 Analysis ‣ 4.4 Experiment 1 ‣ 4 Experiments ‣
    A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs")显示了一个折线图，表示每个变体（全量、A、C、CA、T）对于提示1到4的平均值，横轴表示提示变体，纵轴表示汇总评估分数。实线黑线（AVE1）使用了原始实验结果，而黑色虚线（AVE2）排除了在提示1和2中观察到的可能数据泄漏。例如，最左侧的黑圈表示全量变体在所有LLM和所有提示（1到4）中的平均评估分数为3.17。
- en: '![Refer to caption](img/ec9569bb1b199102d4831a83b3fa55ae.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ec9569bb1b199102d4831a83b3fa55ae.png)'
- en: 'Figure 2: Trend of evaluation scores'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：评估分数趋势
- en: The lines other than the solid black line show the scores aggregated and classified
    by LLM. The drop in evaluation scores at full could be due to the influence of
    the context length limit, as observed in Prompt 3 of Experiment 1.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 除实线黑线外的其他线条显示了由LLM汇总和分类的得分。全量中的评估分数下降可能是由于上下文长度限制的影响，正如在实验1的Prompt 3中观察到的。
- en: Since this experiment has a small sample size, statistical judgments cannot
    be made, but overall trends can be discussed.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此实验的样本量较小，不能做出统计判断，但可以讨论总体趋势。
- en: First, looking at Gemini 1.5 Pro, which has the largest context, the evaluation
    score for the full variant is the highest, followed by A, C, CA, and T in that
    order.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，查看具有最大上下文的Gemini 1.5 Pro，全量变体的评估分数最高，其次是A、C、CA和T。
- en: Focusing on the presence or absence of source code, the evaluation score for
    the T variant, which does not include source code, does not reach the scores of
    the full or A variants, which include both source code and the call tree. This
    suggests a trend that including the call tree and source code in the prompt contributes
    to the quality of the response.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 关注源代码的有无时，不包含源代码的T变体的评估分数没有达到包含源代码和调用树的全量或A变体的分数。这表明，将调用树和源代码包含在提示中有助于提高响应质量。
- en: Looking at the variants that include source code, i.e., full, A, C, and CA,
    the only variant that does not include the order in which functions are called
    is CA. The other variants, full, A, and C, include information about the order
    in which functions are called, either through the call tree or the ordering of
    the function source code. The lower evaluation score for the CA variant suggests
    a trend that the order in which functions are called contributes to the quality
    of the response.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 查看包含源代码的变体，即全量、A、C和CA，唯一一个不包含函数调用顺序的变体是CA。其他变体，全量、A和C，包含了函数调用的顺序信息，无论是通过调用树还是函数源代码的排序。CA变体较低的评估分数表明，函数调用的顺序有助于响应质量。
- en: Further examining the full, A, and C variants, the C variant presents the order
    in which functions are called through the ordering of the source code, while full
    and A present the order in which functions are called through the call tree. Excluding
    the suspected context length limit issue described in Prompt 3 of Experiment 1,
    there appears to be a trend that presenting the order through the call tree contributes
    to the quality of the response.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步检查全量、A和C变体时，C变体通过源代码的排序呈现函数调用的顺序，而全量和A则通过调用树呈现函数调用的顺序。除去在实验1的Prompt 3中描述的可能的上下文长度限制问题，似乎有一种趋势，即通过调用树呈现顺序有助于响应质量。
- en: 4.5 Experiment 2
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 实验2
- en: We evaluate the size of the prompts generated by the proposed method.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了所提方法生成的提示的大小。
- en: (1) Examine how the prompt size compares to the LLM’s context length limit.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 检查提示大小与LLM的上下文长度限制的比较。
- en: Table [8](#S4.T8 "Table 8 ‣ 4.5 Experiment 2 ‣ 4 Experiments ‣ A RAG Method
    for Source Code Inquiry Tailored to Long-Context LLMs") shows the prompt lengths
    of Prompts 1 to 4 measured using the ChatGPT-4 tokenizer⁴⁴4The Tokenizer Playground
    https://huggingface.co/spaces/Xenova/the-tokenizer-playground was used.. The maximum
    is the full variant of Prompt 3 with 87,950 tokens. Theoretically, this reaches
    nearly 70% of the context length limit of the ChatGPT-4 used in this experiment.
    Additionally, when measured with the Gemini (Gemma) tokenizer, this prompt becomes
    106,875 tokens, revealing a difference of around 20% in token counts between LLMs.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [8](#S4.T8 "表 8 ‣ 4.5 实验 2 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询 RAG 方法") 显示了使用 ChatGPT-4
    分词器测量的提示 1 到 4 的长度。最大的是提示 3 的完整变体，有 87,950 个令牌。理论上，这接近于 ChatGPT-4 的上下文长度限制的 70%。此外，当使用
    Gemini (Gemma) 分词器测量时，此提示变为 106,875 个令牌，显示 LLM 之间令牌数量的差异约为 20%。
- en: 'Table 8: Prompt sizes (in ChatGPT-4 tokens)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：提示大小（以 ChatGPT-4 令牌为单位）
- en: '| Prompt | full | A | C | CA | T |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 完整 | A | C | CA | T |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Prompt 1 | 32,250 | 19,949 | 22,079 | 18,768 | 1,279 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 提示 1 | 32,250 | 19,949 | 22,079 | 18,768 | 1,279 |'
- en: '| Prompt 2 | 64,838 | 53,537 | 61,238 | 49,943 | 3,711 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 提示 2 | 64,838 | 53,537 | 61,238 | 49,943 | 3,711 |'
- en: '| Prompt 3 | 87,950 | 73,338 | 83,198 | 50,528 | 4,876 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 提示 3 | 87,950 | 73,338 | 83,198 | 50,528 | 4,876 |'
- en: '| Prompt 4 | 26,104 | 23,984 | 24,489 | 18,792 | 1,751 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 提示 4 | 26,104 | 23,984 | 24,489 | 18,792 | 1,751 |'
- en: In terms of prompt size, the full variant is the largest for all prompts from
    1 to 4\. The C variant is smaller because it does not include the call graph.
    The A variant is smaller because it does not include duplicate function source
    code. The T variant is smaller because it does not include source files.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 就提示大小而言，所有提示 1 到 4 的完整变体是最大的。C 变体较小，因为它不包含调用图。A 变体较小，因为它不包含重复的函数源代码。T 变体较小，因为它不包含源文件。
- en: (2) Examine how the prompt size compares to the source files of the target product.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 检查提示大小与目标产品源文件的比较情况。
- en: Table [9](#S4.T9 "Table 9 ‣ 4.5 Experiment 2 ‣ 4 Experiments ‣ A RAG Method
    for Source Code Inquiry Tailored to Long-Context LLMs") shows the number of Python
    source files included in Prompts 1 to 4 and the total number of lines in those
    source files. For comparison, the number of lines in the full variant prompt is
    also included. Table [1](#S4.T1 "Table 1 ‣ 4.1 Target Product ‣ 4 Experiments
    ‣ A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs") showed
    that the total line count for the target product was approximately 220k lines,
    so in comparison to inputting the entire source code of the target product into
    the LLM, the number of lines in the prompts is less than 1/20.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [9](#S4.T9 "表 9 ‣ 4.5 实验 2 ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询 RAG 方法") 显示了提示 1 到 4
    中包含的 Python 源文件数量以及这些源文件的总行数。为了比较，也包括了完整变体提示中的行数。表 [1](#S4.T1 "表 1 ‣ 4.1 目标产品
    ‣ 4 实验 ‣ 针对长上下文 LLM 的源代码查询 RAG 方法") 显示目标产品的总行数约为 220k 行，因此与将目标产品的整个源代码输入 LLM 相比，提示中的行数不到
    1/20。
- en: 'Table 9: Python source code referenced by the prompts'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：由提示引用的 Python 源代码
- en: '| Prompt | File Count | File Lines | Full Variant Lines |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | 文件数量 | 文件行数 | 完整变体行数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Prompt 1 | 14 | 11,552 | 2,549 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 提示 1 | 14 | 11,552 | 2,549 |'
- en: '| Prompt 2 | 53 | 18,799 | 7,079 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 提示 2 | 53 | 18,799 | 7,079 |'
- en: '| Prompt 3 | 53 | 18,799 | 9,626 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 提示 3 | 53 | 18,799 | 9,626 |'
- en: '| Prompt 4 | 18 | 13,757 | 2,737 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 提示 4 | 18 | 13,757 | 2,737 |'
- en: Prompts 2 and 3 reference the same set of source files,
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 2 和 3 引用的是相同的一组源文件，
- en: hence the file count and file lines are the same.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，文件数量和文件行数是相同的。
- en: With the proposed method, the necessary source files are identified by executing
    the target product, eliminating the need for the user (developer) to manually
    select source files. Even if developers could select source files, the proposed
    method extracts the source code at the function level and appends it to the prompt,
    allowing for smaller prompts. For example, the full variant of Prompt 1 is 22%
    (=2549/11552) in terms of line count.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 通过所提出的方法，通过执行目标产品来识别必要的源文件，消除了用户（开发者）手动选择源文件的需求。即使开发者能够选择源文件，所提出的方法也会在函数级别提取源代码并将其附加到提示中，从而允许更小的提示。例如，提示
    1 的完整变体在行数上是 22%（=2549/11552）。
- en: 5 Summary and Future Prospects
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 总结与未来展望
- en: In this research, we proposed a RAG method for inquiries about source code.
    The proposed method extracts the call tree and the source code of the called functions
    from the execution trace of a software product and appends them to the prompt.
    This enables inquiries that require considering the product’s design, such as
    investigating differences in functionality or determining where functionality
    should be implemented.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们提出了一种针对源代码查询的RAG方法。该方法从软件产品的执行跟踪中提取调用树和被调用函数的源代码，并将其附加到提示中。这使得需要考虑产品设计的查询成为可能，例如调查功能差异或确定功能应实现的位置。
- en: In the experiment, we used an open-source product of approximately 220k lines,
    including dependencies, as the target and evaluated the responses by inputting
    the created prompts into LLMs for specific inquiries that could arise during software
    development. The experimental results showed a trend of improved response quality
    when including the call tree and source code in the prompt. In particular, it
    was found that including the order in which functions are called in the prompt
    is important. On the other hand, there were cases where the quality of the response
    degraded when the prompt size became large, depending on the LLM.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验中，我们使用了一个大约有220k行的开源产品（包括依赖项）作为目标，并通过将创建的提示输入LLMs来评估响应，这些提示涵盖了在软件开发过程中可能出现的具体询问。实验结果显示，当提示中包含调用树和源代码时，响应质量有改善的趋势。特别是，发现提示中包含函数调用顺序是很重要的。另一方面，根据LLM的不同，当提示大小变大时，响应质量会下降。
- en: Future tasks include automating prompt generation to reduce manual effort by
    the user and establishing a method for creating prompts that can handle various
    software tasks. It will also be necessary to investigate more effective methods
    for addressing the context length limit of LLMs.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的任务包括自动生成提示，以减少用户的手动工作量，并建立一种能够处理各种软件任务的提示创建方法。还需要研究更有效的方法来解决LLMs的上下文长度限制。
- en: References
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M. Jin, S. Shahriar, M. Tufano, X. Shi, S. Lu, N. Sundaresan, A. Svyatkovski,
    InferFix: End-to-End Program Repair with LLMs, ESEC/FSE 2023, pp. 1646–1656, 2023.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] M. Jin, S. Shahriar, M. Tufano, X. Shi, S. Lu, N. Sundaresan, A. Svyatkovski,
    InferFix: End-to-End Program Repair with LLMs, ESEC/FSE 2023, pp. 1646–1656, 2023.'
- en: '[2] M. Levy, A. Jacoby, Y. Goldberg, Same Task, More Tokens: the Impact of
    Input Length on the Reasoning Performance of Large Language Models, arXiv:2402.14848v1,
    2024.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] M. Levy, A. Jacoby, Y. Goldberg, Same Task, More Tokens: the Impact of
    Input Length on the Reasoning Performance of Large Language Models, arXiv:2402.14848v1,
    2024.'
- en: '[3] P. Lewis, E. Perez, A. Piktus, et al., Retrieval-Augmented Generation for
    Knowledge-Intensive NLP Tasks, arXiv:2005.11401v4, 2021.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] P. Lewis, E. Perez, A. Piktus, et al., Retrieval-Augmented Generation for
    Knowledge-Intensive NLP Tasks, arXiv:2005.11401v4, 2021.'
- en: '[4] D. Nam, A. Macvean, V. Hellendoorn, B. Vasilescu, B. Myers, Using an LLM
    to Help With Code Understanding, ICSE 2024, p. 881, 2024.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] D. Nam, A. Macvean, V. Hellendoorn, B. Vasilescu, B. Myers, Using an LLM
    to Help With Code Understanding, ICSE 2024, p. 881, 2024.'
- en: '[5] M. Reid, N. Savinov, D. Teplyashin, et al., Gemini 1.5: Unlocking multimodal
    understanding across millions of tokens of context, arXiv:2403.05530v1, 2024.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] M. Reid, N. Savinov, D. Teplyashin, et al., Gemini 1.5: Unlocking multimodal
    understanding across millions of tokens of context, arXiv:2403.05530v1, 2024.'
- en: '[6] C. S. Xia, Y. Deng, L. Zhang, Top Leaderboard Ranking = Top Coding Proficiency,
    Always? EvoEval: Evolving Coding Benchmarks via LLM, arXiv:2403.19114v1, 2024.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] C. S. Xia, Y. Deng, L. Zhang, Top Leaderboard Ranking = Top Coding Proficiency,
    Always? EvoEval: Evolving Coding Benchmarks via LLM, arXiv:2403.19114v1, 2024.'
- en: '[7] J. Xu, Z. Cui, Y. Zhao, et al., UniLog: Automatic Logging via LLM and In-Context
    Learning, ICSE 2024, pp. 1–12, 2024.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] J. Xu, Z. Cui, Y. Zhao, et al., UniLog: Automatic Logging via LLM and In-Context
    Learning, ICSE 2024, pp. 1–12, 2024.'
