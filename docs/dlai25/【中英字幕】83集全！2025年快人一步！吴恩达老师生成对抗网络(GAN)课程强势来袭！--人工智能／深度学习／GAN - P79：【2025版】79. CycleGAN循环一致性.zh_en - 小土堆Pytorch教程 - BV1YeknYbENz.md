# P79：【2025版】79. CycleGAN循环一致性.zh_en - 小土堆Pytorch教程 - BV1YeknYbENz

在这个视频中你将学习到循环一致性，这是添加到循环甘的最后一个术语，它使循环甘的循环得以实现。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_1.png)

所以循环一致性是损失函数的额外损失项，这是对两个甘都适用的，我将解释循环一致性是如何具体帮助的，当我们在循环甘中不包括它时会发生什么。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_3.png)

所以首先我们检查斑马到马再到斑马的方向，所以首先斑马到马的生成器会将真实的斑马图像映射，到一个假的马。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_5.png)

然后另一个生成器会将那个马映射回斑马，因此，循环一致性期望的是，生成的假斑马看起来与真实的斑马完全一致，因为只有样式应该发生变化，因此你可以在这里做的。

你可以计算这两张图片之间的像素差异并将其添加到你的损失函数中，你想要鼓励这两张图片尽可能接近。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_7.png)

这也适用于相反的方向，从马到斑马再到马。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_9.png)

你想要再次计算这两者之间的像素差异，因此你可以构建整个循环一致性损失，通过相加来自两个方向的像素差异，所以，一个是从斑马到马再到斑马的方向，这里你观察的是真斑马和假斑马之间的差异，经过循环后，同样的。

马到斑马再到马的方向也适用，所以你可以简单地对每个方向的i个样本进行求和，因此这构成了你对生成器整个循环一致性损失项。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_11.png)

所以你是如何添加这一项的，你将其添加到你的对抗损失中，由于每个方向都使用了你看到的这两个生成器，你实际上只用一个优化器来控制两个生成器，所以两个生成器只使用一个损失项。

从这个损失项中计算出循环一致性损失，两个生成器共享这个损失，再次，对抗性损失就是那个主要的GAN损失函数，你将会学到关于循环GAN中的对抗性损失函数具体是什么，因为它和你之前见过的有点不同，更具体地说。

你可以在训练数据集中的斑马和马上计算循环一致性损失，并且用一些lambda项来加权，这样你就可以得到你的全局循环一致性损失项，然后将其加到你的生成器的损失中，然后你就可以得到你的生成器的最终损失。

所以有趣的一点是，循环一致性的概念在循环GAN中的应用比想象中要广泛，它在深度学习中被广泛应用，它帮助了数据增强，例如，它也被用于文本翻译，从法语翻译成英语再翻译回法语，你期望得到相同的短语。

或者用于增强你的数据集，因为可能你不会得到相同的短语，但这会增加你数据集中的额外噪声。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_13.png)

所以，循环一致性可以做到一些很酷的事情，好的，这就是循环一致性损失的前提。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_15.png)

《自行车纸》也展示了一些酷炫的标记研究，并且什么是消融研究。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_17.png)

消融这个词，这意味着你在循环中引入的各种组件正在被切除。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_19.png)

并且观察模型在没有那些各种组件的情况下如何运作。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_21.png)

所以首先它采用了循环生成，但是拿走了所有的gan组件，如果只有循环一致性损失会怎样。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_23.png)

你可以看到这种模型会怎样，只有循环一致性损失效果不佳。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_25.png)

这些图像效果不佳，所以这里发生了什么。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_27.png)

你实际上在看一个配对数据集，但请记住，Seth可以处理未配对数据。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_29.png)

所以它实际上只考虑两堆数据，它完全没有考虑配对。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_31.png)

但使用配对数据集的原因是为了了解差距，输出来自真实数据，这是很酷的评价方式。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_33.png)

看看模型去处，即使你正在查看未配对的翻译，也要使用配对的翻译数据集。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_35.png)

这里发生的事情是，真实数据正在输入这个现实图像。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_37.png)

并产生这个分割输出。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_39.png)

或者相反方向，取得分割输出并产生这个现实图像，所以这些是同一对在这里不同的方向，第二组也是同一对，只是方向不同，因此仅仅依靠循环一致性。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_41.png)

你可以看到这些输出完全不现实，你得到这些完全黑色的方块。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_43.png)

可能正在发生模式崩溃，而且几乎没有现实感。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_45.png)

来自生成对抗网络的对抗损失确实让事物看起来逼真，因此如预期，没有它仅仅依靠循环一致性，你不会得到那些你想要的现实输出。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_47.png)

但是如果你只有生成对抗网络会怎样，没有循环一致性，嗯，输出看起来相当逼真，看起来相当不错。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_49.png)

除非你注意到有一些模式的崩溃，这两张图片输入完全不同。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_51.png)

但它们的分割面具非常相似。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_53.png)

有一些模式的崩溃，这显然不理想，这些逼真的图片虽然看起来有些逼真，比那些黑色方块好多了，看起来还是有点模式崩溃，它们具有相同的所有特征，它不像真实图像那样多样化，有趣的是，你可以使用一半的循环一致性。

但这也不足以使GAN学习多样化的质量映射。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_55.png)

没有心理一致性损失，你可以看到这一点，没有伪损失，马到斑马的转换，马和斑马，马和斑马，然后输出仍然看到一些模式崩溃。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_57.png)

这不好，但肖恩想说的是，有了这两个损失项，有了你的对抗损失项和你的循环一致性损失项，双向的，然后它对这些输出真的有很大的帮助，这里，你看到的模式崩溃减少了，你看到输出多样性，看起来相当逼真。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_59.png)

我们到这里能做到的最逼真，所以循环一致性真的使用了最好的两个世界。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_61.png)

通过这些消融研究显示，如果你去掉其中一个，它不会做得那么好，这就是GAN试图说，你知道我们需要这个，这是一个重要的贡献，所以你会在研究论文中经常看到消融研究。



![](img/1758b777e02d4b3dbe4931b7a4b63d23_63.png)

总结，循环一致性在传输不常见的风格元素时，保持这些图像中的常见内容很重要，这是一个非常重要的损失项，可以通过添加像素距离损失到你的对抗损失来实现，以鼓励循环一致性，双向的，看假斑马到真斑马和假马到真马。

消融研究显示，双向的循环一致性损失项有助于防止模式崩溃。

![](img/1758b777e02d4b3dbe4931b7a4b63d23_65.png)