# P47：【2025版】47. GAN的替代方案.zh_en - 小土堆Pytorch教程 - BV1YeknYbENz

![](img/88bc0d3c236695967281dfc0592938bf_0.png)

在这个视频中你将了解一些生成对抗网络的替代方案，在上个视频中你看到了使用生成对抗网络（GANs）的缺点。



![](img/88bc0d3c236695967281dfc0592938bf_2.png)

在这个视频中你将看到其他生成模型如何解决这些缺点。

![](img/88bc0d3c236695967281dfc0592938bf_4.png)

但它们也有自己的不同权衡，具体来说，我将讨论另一种流行的模型称为VAE（变分自编码器）。

![](img/88bc0d3c236695967281dfc0592938bf_6.png)

你可能已经在之前的周次中稍微熟悉过它，然后其他不那么流行的。

![](img/88bc0d3c236695967281dfc0592938bf_8.png)

但仍然非常酷的替代方案，生成模型可以是任何试图建模p(x|y)的机器学习模型。

![](img/88bc0d3c236695967281dfc0592938bf_10.png)

![](img/88bc0d3c236695967281dfc0592938bf_11.png)

或者如果它只是建模那一类，这可能是数据中x的概率，通常它会引入某种噪音或随机性，这样每次生成的结果都不同，这意味着输出结果的多样性，然后输出代表该类的特征或对象，生成器模型包括更多内容，远不止GAN。



![](img/88bc0d3c236695967281dfc0592938bf_13.png)

让我们深入探讨变分自编码器。

![](img/88bc0d3c236695967281dfc0592938bf_15.png)

变分自编码器（Vae）是另一种大型生成模型家族，提醒一下，上周我们学过。

![](img/88bc0d3c236695967281dfc0592938bf_17.png)

Vae使用两种不同的模型工作，一个编码器和解码器。

![](img/88bc0d3c236695967281dfc0592938bf_19.png)

通过将真实图像喂入编码器来学习，找到一种良好的方式来表示这张图像在这个潜在空间中。

![](img/88bc0d3c236695967281dfc0592938bf_21.png)

也许在这里，然后取这个表示或接近它的表示。

![](img/88bc0d3c236695967281dfc0592938bf_23.png)

然后用这个解码器重构编码器之前看到的真实图像。

![](img/88bc0d3c236695967281dfc0592938bf_25.png)

我刚才描述的大致就是自编码器，是VAE的一部分。

![](img/88bc0d3c236695967281dfc0592938bf_27.png)

而变分部分稍微复杂一些，但它使得模型能够以一种方式进行训练，以最大化生成真实数据或图像的概率。

![](img/88bc0d3c236695967281dfc0592938bf_29.png)

就像实际数据输入到编码器中一样。

![](img/88bc0d3c236695967281dfc0592938bf_31.png)

所以从宏观角度来看，Vae，试图最小化生成和真实分布之间的差异。

![](img/88bc0d3c236695967281dfc0592938bf_33.png)

这通常被认为是一个稍微容易的优化问题。

![](img/88bc0d3c236695967281dfc0592938bf_35.png)

导致更稳定的训练，这也被认为是结果模糊或低保真。

![](img/88bc0d3c236695967281dfc0592938bf_37.png)

在训练完VAE之后，实际上去掉编码器。

![](img/88bc0d3c236695967281dfc0592938bf_39.png)

就像你不需要判别器一样，然后你用解码器类似于生成器。

![](img/88bc0d3c236695967281dfc0592938bf_41.png)

你从你的潜在空间中采样点，你能够生成一个输出图像，所以如果你记得GAN的优缺点。

![](img/88bc0d3c236695967281dfc0592938bf_43.png)

Vae在大多数方面是相反的，通常认为Vae生成的结果质量低于GAN。

![](img/88bc0d3c236695967281dfc0592938bf_45.png)

或者至少不是第一个产生逼真结果的。

![](img/88bc0d3c236695967281dfc0592938bf_47.png)

他们确实落后于GAN，他们需要更多的工程和调整。

![](img/88bc0d3c236695967281dfc0592938bf_49.png)

但他们有密度估计，他们可以很容易地反向处理。

![](img/88bc0d3c236695967281dfc0592938bf_51.png)

因为他们有一个编码器来尝试找到那个潜在空间表示。

![](img/88bc0d3c236695967281dfc0592938bf_53.png)

这可能不是一个完美的逆向，这意味着它不是正好一对一，但它是什么东西会让你得到一个不错的噪声因素，并且旋转也更加稳定和可靠，尽管可以说它相当慢。



![](img/88bc0d3c236695967281dfc0592938bf_55.png)

但是GANs的阵营会说，所有这些都很好，但是如果你不能生成好的样本。

![](img/88bc0d3c236695967281dfc0592938bf_57.png)

那就没用，而这里是 dun dun dun，因此，为了改善他们的结果，已经投入了大量的工作，所以这里是一个很近的VAE的例子，叫做VQ，左边是VQ-VAE2，右边是GAN。

你可以看到GAN的质量稍微高一些，但是VAE也开始有更好的结果，特别是在多样性这里，就像你看到的生成的鱼一样，还有这个VAE式的模型，V，QV，VQ-VAE2借鉴了很多VAE的概念。

但是它实际上不被认为是一个纯粹的VAE解决方案，事实上它也依赖于自回归网络组件，那么自回归模型是什么，它是一种模型，通过看之前的像素来确定下一个像素。



![](img/88bc0d3c236695967281dfc0592938bf_59.png)

也许它看到了这里的几个像素，然后它能够确定那个图像的其余像素。

![](img/88bc0d3c236695967281dfc0592938bf_61.png)

这也是另一种生成模型，它根据之前的像素逐个像素生成。

![](img/88bc0d3c236695967281dfc0592938bf_63.png)

所以你可以认为这是它在之前的像素上的条件。

![](img/88bc0d3c236695967281dfc0592938bf_65.png)

来确定下一个像素，它看不到未来的像素。

![](img/88bc0d3c236695967281dfc0592938bf_67.png)

我不能看到未来的像素，它只能看到过去的像素，如果你熟悉RNNs或语言和语音模型。

![](img/88bc0d3c236695967281dfc0592938bf_69.png)

这个概念也很相似，你不能看到未来，正如你所能猜到的。

![](img/88bc0d3c236695967281dfc0592938bf_71.png)

这个模型并不是完全无监督的，因为它依赖于那些之前的像素。

![](img/88bc0d3c236695967281dfc0592938bf_73.png)

所以它是一种有监督的技术，这意味着它需要锚定像素来开始生成，不能直接从噪声中生成。

![](img/88bc0d3c236695967281dfc0592938bf_75.png)

另一种生成模型是流模型。

![](img/88bc0d3c236695967281dfc0592938bf_77.png)

这些训练起来很难也很耗时，但是它是一个很酷的新想法。

![](img/88bc0d3c236695967281dfc0592938bf_79.png)

基于似然来找到一个可逆映射，从噪声到生成的图像，这是一个基于似然的新想法。

![](img/88bc0d3c236695967281dfc0592938bf_81.png)

因此很明显，它将是可逆的，在高层次上。

![](img/88bc0d3c236695967281dfc0592938bf_83.png)

它正在做的是从一个初始的简单分布开始，它找到一系列可逆变换来创建更复杂的分布。

![](img/88bc0d3c236695967281dfc0592938bf_85.png)

![](img/88bc0d3c236695967281dfc0592938bf_86.png)

假设它从非常简单的东西开始，它有这些可逆映射，这些映射由这些箭头表示。

![](img/88bc0d3c236695967281dfc0592938bf_88.png)

它得到更复杂的分布。

![](img/88bc0d3c236695967281dfc0592938bf_90.png)

最终它能够建模人脸，这是一个名为Glow的流模型示例。

![](img/88bc0d3c236695967281dfc0592938bf_92.png)

最后，你也可以将这些模型或想法结合起来形成混合架构。

![](img/88bc0d3c236695967281dfc0592938bf_94.png)

试图从两个或多个世界中获益，这就是你之前看到的VAE自回归模型，称为V。

![](img/88bc0d3c236695967281dfc0592938bf_96.png)

QV，E，2，还有许多GAN-VAE模型将两者的概念结合起来。

![](img/88bc0d3c236695967281dfc0592938bf_98.png)

你也将在课程三中看到一些先进的模型。

![](img/88bc0d3c236695967281dfc0592938bf_100.png)

总之。

![](img/88bc0d3c236695967281dfc0592938bf_102.png)

VAEs在很大程度上与GANs的优缺点列表相反，值得注意的是，结果通常更模糊。

![](img/88bc0d3c236695967281dfc0592938bf_104.png)

尽管这是有争议的，但它可以估计密度，易于逆向，训练稳定。

![](img/88bc0d3c236695967281dfc0592938bf_106.png)

然而，GANs在许多方面已经改进了这些缺点。

![](img/88bc0d3c236695967281dfc0592938bf_108.png)

因为训练已经大大稳定下来，并且近似反演，这是你需要编辑图像的。

![](img/88bc0d3c236695967281dfc0592938bf_110.png)

已经减少到一个工程问题，即通过另一个模型找到你的z向量。

![](img/88bc0d3c236695967281dfc0592938bf_112.png)

这些在结果上也取得了长足的进步。

![](img/88bc0d3c236695967281dfc0592938bf_114.png)

总的来说，当我们谈到应用时，我认为GANs在生成真实图像是主要目标时仍然更有用。

![](img/88bc0d3c236695967281dfc0592938bf_116.png)

正如你在这个视频中所看到的，其他替代性的生成模型包括自回归模型、流模型，以及其他所有这些模型的混合模型。



![](img/88bc0d3c236695967281dfc0592938bf_118.png)

现在，你已经学习了其他生成模型。

![](img/88bc0d3c236695967281dfc0592938bf_120.png)

你将探索机器学习中普遍存在的问题，GANs，以及这些其他模型当然不会对这些问题免疫。

![](img/88bc0d3c236695967281dfc0592938bf_122.png)

![](img/88bc0d3c236695967281dfc0592938bf_123.png)