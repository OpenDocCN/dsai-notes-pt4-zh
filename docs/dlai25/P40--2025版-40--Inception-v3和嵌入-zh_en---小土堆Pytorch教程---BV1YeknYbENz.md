# P40：【2025版】40. Inception v3和嵌入.zh_en - 小土堆Pytorch教程 - BV1YeknYbENz

![](img/849ce3f812259964cf0356c06159316c_0.png)

在这个视频中你将了解Inception V3网络，这是一个复杂的卷积神经网络分类器，可以在ImageNet上进行训练。



![](img/849ce3f812259964cf0356c06159316c_2.png)

本节是关于Inception V3网络。

![](img/849ce3f812259964cf0356c06159316c_4.png)

如何从中提取特征嵌入，然后比较那些嵌入，这种比较可以用于评估GAN。

![](img/849ce3f812259964cf0356c06159316c_6.png)

在上一个视频中你学会了，可以使用分类器作为特征提取器。

![](img/849ce3f812259964cf0356c06159316c_8.png)

特别是那些在庞大的ImageNet数据集上训练过的。

![](img/849ce3f812259964cf0356c06159316c_10.png)

你使用的确切网络可能会有所不同，但最常用的一个是Inception V3或简称Inception。

![](img/849ce3f812259964cf0356c06159316c_12.png)

Inception有四层，有两层深度，但令人惊讶的是，成本和计算效率都很高。

![](img/849ce3f812259964cf0356c06159316c_14.png)

并且在分类任务中表现良好，同时也特别有助于作为特征提取器。

![](img/849ce3f812259964cf0356c06159316c_16.png)

既然你将使用这个作为特征提取器。

![](img/849ce3f812259964cf0356c06159316c_18.png)

用于比较真实与生成的图像，我将专注于那里，所以这是Inception V3网络的表示。

![](img/849ce3f812259964cf0356c06159316c_20.png)

你可以从这里开始，取这个分类网络，切除最后的全连接层用于分类。

![](img/849ce3f812259964cf0356c06159316c_22.png)

然后使用最后的池化层。

![](img/849ce3f812259964cf0356c06159316c_24.png)

分类发生在屏幕外的那里，已经被切除了，在这里你看到输出。

![](img/849ce3f812259964cf0356c06159316c_26.png)

你得到了这个8x8x2048，这实际上并不是输出。

![](img/849ce3f812259964cf0356c06159316c_28.png)

这是你从最后一个卷积层得到的，然后你将这个放入你的最后一个池化层，使用1个滤波器。

![](img/849ce3f812259964cf0356c06159316c_30.png)

你得到一个2048维的嵌入向量。

![](img/849ce3f812259964cf0356c06159316c_32.png)

令人惊讶的是，你只能得到这2048个值作为输出。

![](img/849ce3f812259964cf0356c06159316c_34.png)

这意味着给定一张图片，它可以将图片的像素压缩到只有2048个值。

![](img/849ce3f812259964cf0356c06159316c_36.png)

来表示图片的关键特征。

![](img/849ce3f812259964cf0356c06159316c_38.png)

我反复说2048，因为实际上并不是很多值，与许多图片相比。

![](img/849ce3f812259964cf0356c06159316c_40.png)

许多网上的图片是，让我们说，1024x1024像素，带有3个通道的RGB颜色。

![](img/849ce3f812259964cf0356c06159316c_42.png)

这超过300万像素值，所以2048维的嵌入大小是超过1000倍的更小。

![](img/849ce3f812259964cf0356c06159316c_44.png)

这表示你需要的描述图片的值是1000倍更少，所以做特征距离看起来比像素距离要好得多。

![](img/849ce3f812259964cf0356c06159316c_46.png)

![](img/849ce3f812259964cf0356c06159316c_47.png)

也有用处，你的特征提取器压缩了图片的信息，因为这允许你在更少的维度上操作每张图片。

![](img/849ce3f812259964cf0356c06159316c_49.png)

并且会大大减少比较大量图片的时间。

![](img/849ce3f812259964cf0356c06159316c_51.png)

这在以后的工作中你会经常做。

![](img/849ce3f812259964cf0356c06159316c_53.png)

使用已经在ImageNet上训练过的Inception V3网络。

![](img/849ce3f812259964cf0356c06159316c_55.png)

你现在可以从你的照片中提取特征，来评估你的GAN，再次，这可能提取特征如两只眼睛。

![](img/849ce3f812259964cf0356c06159316c_57.png)

两只耷拉的耳朵和一只鼻子来自这只可爱的狗，当然，这些特征的描述比实际的特征要抽象一些。

![](img/849ce3f812259964cf0356c06159316c_59.png)

从符号学的角度，特征提取模型应用一个函数或映射函数。

![](img/849ce3f812259964cf0356c06159316c_61.png)

称为fee的函数对一个图像x进行特征提取。

![](img/849ce3f812259964cf0356c06159316c_63.png)

这里的x可以是真图像也可以是假图像。

![](img/849ce3f812259964cf0356c06159316c_65.png)

这里的fee实际上是那个 inception 网络，去掉全连接层以获取这些特征，以构建那个嵌入，这是一个包含248个值的向量。



![](img/849ce3f812259964cf0356c06159316c_67.png)

你又学到了，这些提取的特征通常被称为图像的嵌入。

![](img/849ce3f812259964cf0356c06159316c_69.png)

因为它们被压缩到了更低维度的空间，它们在更低维度空间中的位置意味着它们彼此之间有某种关系。

![](img/849ce3f812259964cf0356c06159316c_71.png)

实际上，具有相似特征的嵌入会更接近。

![](img/849ce3f812259964cf0356c06159316c_73.png)

也就是说，它们会取相似的值，例如，如果你有另一只狗进来。

![](img/849ce3f812259964cf0356c06159316c_75.png)

它与这只狗非常相似，也许是另一只金毛寻回犬，但它的位置不同或者其他什么。

![](img/849ce3f812259964cf0356c06159316c_77.png)

但它的位置不同或者其他什么，而你仍然提取这些相似的特征。

![](img/849ce3f812259964cf0356c06159316c_79.png)

那么也许它的特征向量将更接近那个原始的。

![](img/849ce3f812259964cf0356c06159316c_81.png)

所以它将有负五四并且让我们想象另一个有六和四。

![](img/849ce3f812259964cf0356c06159316c_83.png)

因此这两个现在相当相似的向量。

![](img/849ce3f812259964cf0356c06159316c_85.png)

如果你有一个进来的椅子图像看起来非常不同没有这些特征。

![](img/849ce3f812259964cf0356c06159316c_87.png)

那么你将有一个第三特征向量将非常远离这两个。

![](img/849ce3f812259964cf0356c06159316c_89.png)

例如一千在这里和点零零一。

![](img/849ce3f812259964cf0356c06159316c_91.png)

我在这里只显示这两个维度的嵌入，但请记住它们有2048。

![](img/849ce3f812259964cf0356c06159316c_93.png)

所以为了评估一个，下一步是比对这些嵌入。

![](img/849ce3f812259964cf0356c06159316c_95.png)

这些真实和虚假提取的特征，这通常涉及几则真实和几则虚假，所以你能得到足够的图像表示，假设你有几则虚假的狗例子。



![](img/849ce3f812259964cf0356c06159316c_97.png)

当你将它们的特征提取到一个嵌入中，你会发现这些嵌入，这些都是向量值的图像表示。

![](img/849ce3f812259964cf0356c06159316c_99.png)

表示浅色鼻子的狗。

![](img/849ce3f812259964cf0356c06159316c_101.png)

同时，真实图像的特征嵌入也有浅色狗。

![](img/849ce3f812259964cf0356c06159316c_103.png)

但是更多的黑鼻子。

![](img/849ce3f812259964cf0356c06159316c_105.png)

所以将这些图像作为特征进行比较，会比将它们作为像素进行比较更有意义。

![](img/849ce3f812259964cf0356c06159316c_107.png)

记住，仅凭简单的像素距离，轻微的像素偏移实际上会使两个看似相同的图像。

![](img/849ce3f812259964cf0356c06159316c_109.png)

看起来完全不同，所以这两个相当相似的图像。

![](img/849ce3f812259964cf0356c06159316c_111.png)

根据它们的特征距离实际上非常接近，因为它们都是浅色犬。

![](img/849ce3f812259964cf0356c06159316c_113.png)

它们都有粉红色的鼻子，但在像素距离上，它们会相距甚远。

![](img/849ce3f812259964cf0356c06159316c_115.png)

因为你知道一个像素与另一个像素非常不同，所以在像素距离上它们会相距甚远。

![](img/849ce3f812259964cf0356c06159316c_117.png)

所以为了得到特征距离，你可以通过减去它们来直接比较特征。

![](img/849ce3f812259964cf0356c06159316c_119.png)

假设你有所有这些特征的向量。

![](img/849ce3f812259964cf0356c06159316c_121.png)

你可以或许计算所有假向量的平均值，以及所有可能向量的平均值，并相减，这是一种方法。

![](img/849ce3f812259964cf0356c06159316c_123.png)

这与你计算像素距离的方法类似，或者你可以计算欧几里得或余弦距离。

![](img/849ce3f812259964cf0356c06159316c_125.png)

你也可以考虑真实的集合，和假的集合是某种分布。

![](img/849ce3f812259964cf0356c06159316c_127.png)

并看看这些分布有多远。

![](img/849ce3f812259964cf0356c06159316c_129.png)

在下一个视频中，你将学习如何计算真实和假之间的特征距离，这是评估的常见方法。

![](img/849ce3f812259964cf0356c06159316c_131.png)

所以请关注，现在你对Inception作为分类器有了相当多的了解，它预先在ImageNet上训练。

![](img/849ce3f812259964cf0356c06159316c_133.png)

它也可以作为特征提取器，通过去掉最后的全连接层，以及那个最后一层池化层的中间输出。

![](img/849ce3f812259964cf0356c06159316c_135.png)

可以为输入图像构建一个特征嵌入，然后可以用来比较不同图像。

![](img/849ce3f812259964cf0356c06159316c_137.png)

即真实图像和假图像之间。

![](img/849ce3f812259964cf0356c06159316c_139.png)