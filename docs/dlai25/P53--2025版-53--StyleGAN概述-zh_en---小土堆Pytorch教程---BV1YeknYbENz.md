# P53：【2025版】53. StyleGAN概述.zh_en - 小土堆Pytorch教程 - BV1YeknYbENz

![](img/0ce5e0432b36bdda7e29649bf0a47549_0.png)

在前一个视频中，你听到了关于这些年来GANs如何提高的事情。在这个视频中你将了解风格生成器（Style GAN）。



![](img/0ce5e0432b36bdda7e29649bf0a47549_2.png)

一种相对较新的建筑风格，被认为是不仅现在代表了建筑界的最前沿。

![](img/0ce5e0432b36bdda7e29649bf0a47549_4.png)

但在改进中的一个转折点，特别是在生成极其逼真的人脸方面。

![](img/0ce5e0432b36bdda7e29649bf0a47549_6.png)

我将从风格生成器的主要目标开始。

![](img/0ce5e0432b36bdda7e29649bf0a47549_8.png)

并展示它是如何成为改进的化身，而且你们刚刚听说的，然后，我会谈论风格和风格gan的含义，最后，你将会了解其架构的各个组成部分的介绍。



![](img/0ce5e0432b36bdda7e29649bf0a47549_10.png)

所以风格迁移的第一个目标之一是产生高质量，高分辨率的图像，这些图像能够愚弄一个随意的旁观者。

![](img/0ce5e0432b36bdda7e29649bf0a47549_12.png)

所以你和我，也许第二个目标是输出图片的多样性更大。

![](img/0ce5e0432b36bdda7e29649bf0a47549_14.png)

所以如果你还在思考早期的视频中可爱的小狗的例子。

![](img/0ce5e0432b36bdda7e29649bf0a47549_16.png)

那些例子，输出可能会从金毛寻回犬到金毛寻回犬的混血犬。

![](img/0ce5e0432b36bdda7e29649bf0a47549_18.png)

再到法国斗牛犬，而不是只给你一系列背景相同的略有不同的金毛寻回犬。

![](img/0ce5e0432b36bdda7e29649bf0a47549_20.png)

风格迁移的另一个酷点也是对图像特征的控制增加。

![](img/0ce5e0432b36bdda7e29649bf0a47549_22.png)

而且这可以添加特征比如帽子或太阳镜。

![](img/0ce5e0432b36bdda7e29649bf0a47549_24.png)

或者混合两种不同生成图像的风格，所以从某种意义上说，你真的可以看到布拉德·皮特和安吉丽娜·朱莉会创造出什么，安吉丽娜在高分辨率的精确度上达到了欺骗未受过训练的眼睛，这是一项巨大的成就。

直到最近才更容易实现，朱莉在高分辨率的精确度上达到了欺骗未受过训练的眼睛，这是一项巨大的成就，直到最近才更容易实现。



![](img/0ce5e0432b36bdda7e29649bf0a47549_26.png)

而这主要是由于较小的模型容量，较低的分辨率数据集，以及高分辨率的挑战，直到GAN的出现才得以解决。

![](img/0ce5e0432b36bdda7e29649bf0a47549_28.png)

直到GAN的出现才得以解决。

![](img/0ce5e0432b36bdda7e29649bf0a47549_30.png)

直到GAN的出现才得以解决，直到GAN的出现才得以解决。

![](img/0ce5e0432b36bdda7e29649bf0a47549_32.png)

直到GAN的出现才得以解决。

![](img/0ce5e0432b36bdda7e29649bf0a47549_34.png)

在这里你看到这些生成的面孔来自2014年，大部分看起来都很不错。

![](img/0ce5e0432b36bdda7e29649bf0a47549_36.png)

就像糟糕的素描，它们模糊且不太可能说服任何人相信它们的真实性。

![](img/0ce5e0432b36bdda7e29649bf0a47549_38.png)

现在再看一下这个更近的高分辨率风格生成的面孔。

![](img/0ce5e0432b36bdda7e29649bf0a47549_40.png)

如果你在没有任何上下文的情况下看到这张图片，你会不会猜到她不是一个真实的人。

![](img/0ce5e0432b36bdda7e29649bf0a47549_42.png)

看起来很明显斯大林已经实现了更高的真实性。

![](img/0ce5e0432b36bdda7e29649bf0a47549_44.png)

但一个有趣的方面，注意风格再次尝试了w和gp损失，这些都是你在第三周学到的，以及第一周你学到的原始gan损失，并发现它们在不同的数据集上各有优势，这两组数据都是高分辨率的面部图像，所以陪审团还在讨论中。

但实际上两者可能都有效，因此，关键在于尝试。

![](img/0ce5e0432b36bdda7e29649bf0a47549_46.png)

最后，风格还想要增加你对图像特征的控制。

![](img/0ce5e0432b36bdda7e29649bf0a47549_48.png)

这可以是将一个图像的风格混合到另一个图像中。

![](img/0ce5e0432b36bdda7e29649bf0a47549_50.png)

就像这里你看到的那样，这里这张脸是从下面的和右边的混合而来。

![](img/0ce5e0432b36bdda7e29649bf0a47549_52.png)

你可以看到发色和风格来自右边的图片。

![](img/0ce5e0432b36bdda7e29649bf0a47549_54.png)

各种面部特征来自下面的脸。

![](img/0ce5e0432b36bdda7e29649bf0a47549_56.png)

然后你在这里看到右下角，这个女人是上面女人和左边男孩风格的混合。

![](img/0ce5e0432b36bdda7e29649bf0a47549_58.png)

同样也是风格的混合。

![](img/0ce5e0432b36bdda7e29649bf0a47549_60.png)

控制也可以意味着添加配饰，如眼镜和斯大林。

![](img/0ce5e0432b36bdda7e29649bf0a47549_62.png)

通过解纠缠潜空间来实现这一点，你将会在这里不久的将来了解更多细节。

![](img/0ce5e0432b36bdda7e29649bf0a47549_64.png)

正如你所看到的，所有这些家伙都有太阳镜。

![](img/0ce5e0432b36bdda7e29649bf0a47549_66.png)

在图像生成上下文中，风格几乎意味着图像的任何变化。

![](img/0ce5e0432b36bdda7e29649bf0a47549_68.png)

你可以把这些变化看作是一般代表图像不同层次的外观和感觉。

![](img/0ce5e0432b36bdda7e29649bf0a47549_70.png)

这些不同层次可能意味着更大，更粗犷的风格，如面部形状或面部结构。

![](img/0ce5e0432b36bdda7e29649bf0a47549_72.png)

到更精细，更详细的风格，如颜色。

![](img/0ce5e0432b36bdda7e29649bf0a47549_74.png)

头发或某些头发的放置位置，风格生成器。

![](img/0ce5e0432b36bdda7e29649bf0a47549_76.png)

有趣的是，由块组成，早期的块大致与更粗的特征相匹配，如面部结构或姿势。

![](img/0ce5e0432b36bdda7e29649bf0a47549_78.png)

所以这里的早期层和接近输出。

![](img/0ce5e0432b36bdda7e29649bf0a47549_80.png)

更精细，更详细的风格，如发色或眉毛形状由控制。

![](img/0ce5e0432b36bdda7e29649bf0a47549_82.png)

你可以想象这个女人在这里可以以某种方式组合或改变。

![](img/0ce5e0432b36bdda7e29649bf0a47549_84.png)

基于上面女人的粗犷风格，中等风格来自中间的女人。

![](img/0ce5e0432b36bdda7e29649bf0a47549_86.png)

和更精细的颗粒风格来自下面的女人，现在，你对风格的概念更熟悉了，让我们看看风格对抗生成器和你可能更熟悉的传统GAN生成器之间的差异。



![](img/0ce5e0432b36bdda7e29649bf0a47549_88.png)

传统的GAN生成器，你可能更熟悉。

![](img/0ce5e0432b36bdda7e29649bf0a47549_90.png)

你将噪声向量输入到生成器中，生成器然后输出一个图像现在风格中。

![](img/0ce5e0432b36bdda7e29649bf0a47549_92.png)

噪声向量处理方式有点不同。

![](img/0ce5e0432b36bdda7e29649bf0a47549_94.png)

而不是直接将噪声向量输入到生成器中，它通过一个映射网络得到一个中间噪声向量。

![](img/0ce5e0432b36bdda7e29649bf0a47549_96.png)

我们称之为然后注入到风格生成器中实际上多次产生这个图像。

![](img/0ce5e0432b36bdda7e29649bf0a47549_98.png)

![](img/0ce5e0432b36bdda7e29649bf0a47549_99.png)

还有额外的随机噪声传递进来，以添加这种图像上的随机变异。

![](img/0ce5e0432b36bdda7e29649bf0a47549_101.png)

这可能是移动这缕头发以不同方式。

![](img/0ce5e0432b36bdda7e29649bf0a47549_103.png)

所以较小的变异，这种随机噪声可以帮助产生。

![](img/0ce5e0432b36bdda7e29649bf0a47549_105.png)

至于这种随机噪声，没有学习方面，它主要是不相关的随机高斯噪声，你可以扰动值。

![](img/0ce5e0432b36bdda7e29649bf0a47549_107.png)

来自卷积，各种层的值一点。

![](img/0ce5e0432b36bdda7e29649bf0a47549_109.png)

然而，这个映射网络，你将会不久看到它是非常重要的，并且也包含可学习的参数。

![](img/0ce5e0432b36bdda7e29649bf0a47549_111.png)

所以反向传播将从判别器回来。

![](img/0ce5e0432b36bdda7e29649bf0a47549_113.png)

通过后到生成器，并通过这个映射网络，值得注意的是W不是轻易地输入到细胞中。

![](img/0ce5e0432b36bdda7e29649bf0a47549_115.png)

再次提取样式，而不是样式生成器中的w值，然后将此中间噪声值添加到样式gan生成器中的多个点。

![](img/0ce5e0432b36bdda7e29649bf0a47549_117.png)

以及在样式生成器的早期阶段。

![](img/0ce5e0432b36bdda7e29649bf0a47549_119.png)

w将告知更粗略的样式，就像您之前看到的那样。

![](img/0ce5e0432b36bdda7e29649bf0a47549_121.png)

例如，一般的面部形状，并在图层中注入w，将控制更精细的样式，如发色。

![](img/0ce5e0432b36bdda7e29649bf0a47549_123.png)

将这种中间噪声注入所有样式层。

![](img/0ce5e0432b36bdda7e29649bf0a47549_125.png)

是通过一种称为AdaIn或自适应实例归一化的操作来实现的。

![](img/0ce5e0432b36bdda7e29649bf0a47549_127.png)

这是一种类似于批归一化的归一化。

![](img/0ce5e0432b36bdda7e29649bf0a47549_129.png)

但在归一化后，它会尝试应用某种样式。

![](img/0ce5e0432b36bdda7e29649bf0a47549_131.png)

这仅仅是基于传入的w的图像统计，风格gan的第三个也是最后一个重要组成部分是渐进生长。

![](img/0ce5e0432b36bdda7e29649bf0a47549_133.png)

![](img/0ce5e0432b36bdda7e29649bf0a47549_134.png)

这是指逐步生成和评估生成器生成的图像分辨率，在整个训练过程中，渐进生长。

![](img/0ce5e0432b36bdda7e29649bf0a47549_136.png)

起源于渐进生长的gan。

![](img/0ce5e0432b36bdda7e29649bf0a47549_138.png)

它不是独有的风格gan。

![](img/0ce5e0432b36bdda7e29649bf0a47549_140.png)

但它是它的前身，作者们注意到它对高分辨率图像的训练有帮助。

![](img/0ce5e0432b36bdda7e29649bf0a47549_142.png)

在训练过程中，生成器和判别器从低分辨率的小图像开始，目标是训练生成器能够生成高分辨率的面部图像，例如，一个小而模糊的图像，但它在大致正确的方向上，你知道，有一些面部像素，当模型稳定时。

它们可以扩展到高度的两倍。

![](img/0ce5e0432b36bdda7e29649bf0a47549_144.png)

所以现在是一个稍微更难的任务，需要更少模糊，看起来更像面部。

![](img/0ce5e0432b36bdda7e29649bf0a47549_146.png)

但仍然比超高分辨率的面部更容易。

![](img/0ce5e0432b36bdda7e29649bf0a47549_148.png)

并且这个过程会一直持续到达到所需的图像分辨率，并且这种加倍会在训练过程中的预定时间发生。

![](img/0ce5e0432b36bdda7e29649bf0a47549_150.png)

但加倍不能太突然，必须更加渐进，以便让生成器更容易生成更大的图像。

![](img/0ce5e0432b36bdda7e29649bf0a47549_152.png)

如果你感到困惑，完全不用担心，稍后会在课程中详细解释。

![](img/0ce5e0432b36bdda7e29649bf0a47549_154.png)

主要的要点是如果你想要增长，你必须慢慢来，现在你已经熟悉了风格gan及其一些惊人的成就。

![](img/0ce5e0432b36bdda7e29649bf0a47549_156.png)

包括在高分辨率图像上更高的保真度，增加了生成结果的多样性。

![](img/0ce5e0432b36bdda7e29649bf0a47549_158.png)

并且对图像特征，如发色和配饰，有更多的控制，你稍微了解了在图像生成中的样式是什么意思。

![](img/0ce5e0432b36bdda7e29649bf0a47549_160.png)

也就是说，图像的一般纹理或外观和感觉。

![](img/0ce5e0432b36bdda7e29649bf0a47549_162.png)

这取决于它在生成器中的位置，从大的核心样式，如面部形状到更精细的样式，如发色。

![](img/0ce5e0432b36bdda7e29649bf0a47549_164.png)

最后，你被介绍了风格gan的架构。

![](img/0ce5e0432b36bdda7e29649bf0a47549_166.png)

并且你已经看到了它的主要组成部分，噪声映射网络。

![](img/0ce5e0432b36bdda7e29649bf0a47549_168.png)

以及自适应实例归一化，最后，你被介绍了风格gan的架构。

![](img/0ce5e0432b36bdda7e29649bf0a47549_170.png)

并且你已经看到了它的主要组成部分，噪声映射网络，自适应实例归一化，让它与更传统的GAN区分开来，渐进生长并不局限于风格再现。



![](img/0ce5e0432b36bdda7e29649bf0a47549_172.png)

但它有助于更高分辨率图像的更稳定训练。

![](img/0ce5e0432b36bdda7e29649bf0a47549_174.png)

这只是一个高层次的介绍。

![](img/0ce5e0432b36bdda7e29649bf0a47549_176.png)

你将深入探讨这些组件。

![](img/0ce5e0432b36bdda7e29649bf0a47549_178.png)