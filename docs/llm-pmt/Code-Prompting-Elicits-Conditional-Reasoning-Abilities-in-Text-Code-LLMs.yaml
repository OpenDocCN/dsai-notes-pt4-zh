- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:47:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:47:05'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码提示在文本+代码LLM中引发条件推理能力
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2401.10065](https://ar5iv.labs.arxiv.org/html/2401.10065)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2401.10065](https://ar5iv.labs.arxiv.org/html/2401.10065)
- en: Haritz Puerto¹, Martin Tutek¹, Somak Aditya², Xiaodan Zhu^(1,3), Iryna Gurevych¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Haritz Puerto¹，Martin Tutek¹，Somak Aditya²，Xiaodan Zhu^(1,3)，Iryna Gurevych¹
- en: ¹Ubiquitous Knowledge Processing Lab (UKP Lab),
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹无处不在的知识处理实验室（UKP Lab），
- en: TU Darmstadt and Hessian Center for AI (hessian.AI)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 达姆施塔特工业大学和黑森人工智能中心（hessian.AI）
- en: ²IIT Kharagpur, ³Queen’s University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²IIT Kharagpur，³女王大学
- en: '[https://www.ukp.tu-darmstadt.de](https://www.ukp.tu-darmstadt.de)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.ukp.tu-darmstadt.de](https://www.ukp.tu-darmstadt.de)'
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Reasoning is a fundamental component for achieving language understanding. Among
    the multiple types of reasoning, conditional reasoning, the ability to draw different
    conclusions depending on some condition, has been understudied in large language
    models (LLMs). Recent prompting methods, such as chain of thought, have significantly
    improved LLMs on reasoning tasks. Nevertheless, there is still little understanding
    of what triggers reasoning abilities in LLMs. We hypothesize that code prompts
    can trigger conditional reasoning in LLMs trained on text and code. We propose
    a chain of prompts that transforms a natural language problem into code and prompts
    the LLM with the generated code. Our experiments find that code prompts exhibit
    a performance boost between $2.6$ points on GPT 3.5 across multiple datasets requiring
    conditional reasoning. We then conduct experiments to discover how code prompts
    elicit conditional reasoning abilities and through which features. We observe
    that prompts need to contain natural language text accompanied by high-quality
    code that closely represents the semantics of the instance text. Furthermore,
    we show that code prompts are more efficient, requiring fewer demonstrations,
    and that they trigger superior state tracking of variables or key entities.¹¹1Code,
    prompt templates, prompts, and outputs are publicly available at [https://github.com/UKPLab/arxiv2024-conditional-reasoning-llms](https://github.com/UKPLab/arxiv2024-conditional-reasoning-llms).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是实现语言理解的基本组成部分。在多种推理类型中，条件推理——根据某些条件得出不同结论的能力——在大型语言模型（LLMs）中尚未得到充分研究。近期的提示方法，如思维链，显著提升了LLMs在推理任务中的表现。然而，对LLMs中什么触发推理能力仍知之甚少。我们假设代码提示可以触发在文本和代码上训练的LLMs中的条件推理。我们提出了一种提示链，将自然语言问题转换为代码，并用生成的代码提示LLM。我们的实验发现，代码提示在多个需要条件推理的数据集上，GPT
    3.5的性能提升了$2.6$分。我们随后进行了实验，探索代码提示如何引发条件推理能力及其特征。我们观察到，提示需要包含自然语言文本，并附有高质量代码，这些代码能紧密地表示实例文本的语义。此外，我们展示了代码提示更为高效，要求的示例更少，并且触发了更优的变量或关键实体状态跟踪。¹¹1代码、提示模板、提示和输出可在
    [https://github.com/UKPLab/arxiv2024-conditional-reasoning-llms](https://github.com/UKPLab/arxiv2024-conditional-reasoning-llms)
    上公开获取。
- en: Code Prompting Elicits Conditional Reasoning Abilities
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 代码提示引发条件推理能力
- en: in Text+Code LLMs
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本+代码LLM中
- en: Haritz Puerto¹, Martin Tutek¹, Somak Aditya², Xiaodan Zhu^(1,3), Iryna Gurevych¹
    ¹Ubiquitous Knowledge Processing Lab (UKP Lab), TU Darmstadt and Hessian Center
    for AI (hessian.AI) ²IIT Kharagpur, ³Queen’s University [https://www.ukp.tu-darmstadt.de](https://www.ukp.tu-darmstadt.de)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Haritz Puerto¹，Martin Tutek¹，Somak Aditya²，Xiaodan Zhu^(1,3)，Iryna Gurevych¹
    ¹无处不在的知识处理实验室（UKP Lab），达姆施塔特工业大学和黑森人工智能中心（hessian.AI） ²IIT Kharagpur，³女王大学 [https://www.ukp.tu-darmstadt.de](https://www.ukp.tu-darmstadt.de)
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 介绍
- en: Reasoning is a fundamental component of both human and artificial intelligence
    (AI). Some reasoning types have received much attention in the form of new benchmarks
    and models from the AI community in the last few years, such as mathematical (Patel
    et al., [2021](#bib.bib22); Chen et al., [2021](#bib.bib2); Cobbe et al., [2021](#bib.bib4)),
    logical (Liu et al., [2020](#bib.bib15), [2023a](#bib.bib12); Sinha et al., [2019](#bib.bib24)),
    and commonsense reasoning (Madaan et al., [2022](#bib.bib18); Liu et al., [2022a](#bib.bib13),
    [b](#bib.bib14); Wang et al., [2023](#bib.bib27)). However, other important reasoning
    types, such as conditional reasoning, remain understudied. Conditional reasoning
    draws alternative conclusions depending on the fulfillment of certain conditions.
    It is also a fundamental form of logical reasoning useful in many scenarios, such
    as in chatbots (e.g., ChatGPT), to answer real-world questions like eligibility
    for a visa or a loan. Despite the recent introduction of some benchmarks (Saeidi
    et al., [2018](#bib.bib23); Sun et al., [2022](#bib.bib25); Kazemi et al., [2023](#bib.bib8)),
    conditional reasoning abilities of LLMs remain unknown.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是人类和人工智能（AI）的一个基本组成部分。在过去几年中，AI社区对一些推理类型给予了很多关注，例如数学推理（Patel et al., [2021](#bib.bib22);
    Chen et al., [2021](#bib.bib2); Cobbe et al., [2021](#bib.bib4)）、逻辑推理（Liu et al.,
    [2020](#bib.bib15), [2023a](#bib.bib12); Sinha et al., [2019](#bib.bib24)）和常识推理（Madaan
    et al., [2022](#bib.bib18); Liu et al., [2022a](#bib.bib13), [b](#bib.bib14);
    Wang et al., [2023](#bib.bib27)）。然而，其他重要的推理类型，如条件推理，仍然研究不足。条件推理根据某些条件的满足来得出不同的结论。它也是一种基本的逻辑推理形式，在许多场景中很有用，例如在聊天机器人（如ChatGPT）中，用于回答现实世界中的问题，例如签证或贷款资格。尽管最近引入了一些基准测试（Saeidi
    et al., [2018](#bib.bib23); Sun et al., [2022](#bib.bib25); Kazemi et al., [2023](#bib.bib8)），LLMs的条件推理能力仍然未知。
- en: '![Refer to caption](img/bd49ba7c37a99591e1cde3311e697099.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bd49ba7c37a99591e1cde3311e697099.png)'
- en: 'Figure 1: Code prompting converts a natural language problem into a code prompt
    and prompts a large language model with such code to generate a natural language
    answer.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：代码提示将自然语言问题转换为代码提示，并用这种代码提示大型语言模型以生成自然语言答案。
- en: Recently, researchers have improved performance on reasoning tasks by combining
    LLMs with symbolic interpreters such as the Python runtime  (Gao et al., [2023](#bib.bib5);
    Chen et al., [2023](#bib.bib1); Lyu et al., [2023](#bib.bib17)) or SATisfiability
    solvers  (Ye et al., [2023](#bib.bib29)). Here, LLMs pretrained on code or a combination
    of text and code (henceforth text+code LLM) are used to convert the input task
    into a symbolic language (e.g., Python or SAT problems), which is then fed into
    an external interpreter to make use of its symbolic execution. However, offloading
    the final reasoning task to an external execution module does not help with, or
    sometimes confounds, our understanding of the reasoning abilities of the model
    because part of the performance gain may come from the correct execution of the
    external interpreter. In particular, the fundamental questions of what contributes
    to the reasoning abilities and how reasoning abilities are triggered are still
    open questions needing further understanding. Nevertheless, pretraining on code
    is considered an important component that contributes to and explains the improved
    reasoning ability of LLMs. State-of-the-art LLMs such as GPT 3.5 (Kojima et al.,
    [2022](#bib.bib10)), GPT 4 (OpenAI, [2023](#bib.bib20)), PaLM (Chowdhery et al.,
    [2023](#bib.bib3)), and Mistral 7B (Jiang et al., [2023](#bib.bib7)) have been
    pretrained on both text and code and have demonstrated considerable boosts in
    many reasoning benchmarks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究人员通过将LLMs与符号解释器（例如Python运行时（Gao et al., [2023](#bib.bib5); Chen et al.,
    [2023](#bib.bib1); Lyu et al., [2023](#bib.bib17))或SATisfiability求解器（Ye et al.,
    [2023](#bib.bib29))结合，提升了推理任务的性能。在这里，预训练的LLMs（包括代码或文本与代码的组合（以下简称text+code LLM））用于将输入任务转换为符号语言（例如Python或SAT问题），然后将其输入外部解释器以利用其符号执行。然而，将最终推理任务委托给外部执行模块并不能帮助或有时会混淆我们对模型推理能力的理解，因为性能的部分提升可能来自外部解释器的正确执行。特别是，什么因素有助于推理能力以及如何触发推理能力这些基本问题仍然是需要进一步理解的未解之谜。尽管如此，代码预训练被认为是提升LLMs推理能力的一个重要因素。最先进的LLMs，如GPT
    3.5（Kojima et al., [2022](#bib.bib10)）、GPT 4（OpenAI, [2023](#bib.bib20)）、PaLM（Chowdhery
    et al., [2023](#bib.bib3)）和Mistral 7B（Jiang et al., [2023](#bib.bib7)），已经在文本和代码上进行过预训练，并在许多推理基准测试中表现出显著的提升。
- en: 'In this work, we investigate which aspects of code prompts, and in which way,
    elicit conditional reasoning abilities of GPT 3.5, a text+code LLM, across two
    datasets: (1) ConditionalQA (Sun et al., [2022](#bib.bib25)), a scenario-based
    question answering (QA) dataset and (2) BoardgameQA (Kazemi et al., [2023](#bib.bib8)),
    a boardgame-based QA dataset with conflicting rules. To understand the true benefit
    of code as an intermediate representation, we devise a chain of prompts, code
    prompting, that transform a natural language (NL) task into code and prompt the
    LLM with the generated code to elicit reasoning abilities. An illustration is
    provided in [Figure 1](#S1.F1 "In 1 Introduction ‣ Code Prompting Elicits Conditional
    Reasoning Abilities in Text+Code LLMs"). This setup has multiple benefits. Firstly,
    we fully utilize LLM’s reasoning ability without offloading any subtask to an
    external interpreter. In this way, we can make a fair comparison between text
    and code prompts without external variables such as interpreters. Secondly, enforcing
    compilability and executability of the generated code is not required, resulting
    in fewer interpreter-driven errors.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们调查了哪些代码提示的方面以及以何种方式，激发了GPT 3.5（一个文本+代码的LLM）的条件推理能力，涉及两个数据集：（1）ConditionalQA（Sun等，[2022](#bib.bib25)），一个基于情景的问题回答（QA）数据集，以及（2）BoardgameQA（Kazemi等，[2023](#bib.bib8)），一个具有冲突规则的棋盘游戏基础QA数据集。为了理解代码作为中间表示的真正好处，我们设计了一系列提示，即代码提示，将自然语言（NL）任务转换为代码，并用生成的代码提示LLM以引发推理能力。[图1](#S1.F1
    "在1 引言 ‣ 代码提示引发文本+代码LLM中的条件推理能力")提供了一个示例。这种设置具有多个好处。首先，我们充分利用LLM的推理能力，而不将任何子任务外包给外部解释器。通过这种方式，我们可以在没有外部变量（如解释器）的情况下公平地比较文本和代码提示。其次，不需要强制生成代码的可编译性和可执行性，从而减少了解释器驱动的错误。
- en: 'Our contributions are summarized as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献总结如下：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We devise a chain of prompts that transforms a NL task into code to trigger
    conditional reasoning abilities in text+code LLMs.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们设计了一系列提示，将NL任务转换为代码，以触发文本+代码LLM中的条件推理能力。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct a comprehensive study to compare code prompts with text prompts,
    showing i) large performance gains between $2.6$ points while ii) being more efficient
    w.r.t. the number of demonstrations.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们进行了一项全面的研究，比较代码提示和文本提示，显示出i）性能提高了$2.6$分，而ii）在演示数量上更高效。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct an extensive analysis of why code prompts efficiently elicit conditional
    reasoning abilities in text+code LLMs, showing that prompting with code results
    in largely improved variable state tracking.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们进行了一项广泛的分析，研究为什么代码提示能够有效地引发文本+代码LLM中的条件推理能力，结果表明，使用代码提示显著改善了变量状态跟踪。
- en: '![Refer to caption](img/a2ecec96e4d34b113cb5e556691893d8.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a2ecec96e4d34b113cb5e556691893d8.png)'
- en: 'Figure 2: Code Prompts converts a natural language problem instance into code
    before solving it with a large language model.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：代码提示将自然语言问题实例转换为代码，然后用大型语言模型解决它。
- en: 2 Related Work
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Most works generating code to solve natural language tasks use an external symbolic
    interpreter to run such code. Chen et al. ([2023](#bib.bib1)) and Gao et al. ([2023](#bib.bib5))
    showed consistent gains on mathematical problems, symbolic reasoning, and algorithmic
    problems by using LLMs aided by external code interpreters. Lyu et al. ([2023](#bib.bib17))
    show further gains in multi-hop QA, planning, and relational inference. Instead
    of leveraging a code interpreter, Ye et al. ([2023](#bib.bib29)) used an automated
    theorem prover with declarative code and showed consistent gains w.r.t. imperative
    code-interpreter-aided LLMs on arithmetic reasoning, logical reasoning, symbolic
    reasoning, and regex synthesis tasks. Lastly, Pan et al. ([2023](#bib.bib21))
    did not use any interpreter and instead created programs composed of multiple
    subroutines and used smaller specialized models to run them. In this way, they
    outperform text prompts on text LLMs for fact-checking tasks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数生成代码以解决自然语言任务的工作使用外部符号解释器来运行这些代码。Chen等人（[2023](#bib.bib1)）和Gao等人（[2023](#bib.bib5)）通过使用由外部代码解释器辅助的LLM，在数学问题、符号推理和算法问题上显示了一致的改进。Lyu等人（[2023](#bib.bib17)）在多跳QA、规划和关系推理方面显示了进一步的改进。Ye等人（[2023](#bib.bib29)）则使用了具有声明性代码的自动定理证明器，并显示了与使用命令式代码解释器辅助的LLM相比，在算术推理、逻辑推理、符号推理和正则表达式合成任务上的一致改进。最后，Pan等人（[2023](#bib.bib21)）没有使用任何解释器，而是创建了由多个子程序组成的程序，并使用较小的专门模型来运行它们。通过这种方式，他们在事实核查任务中超越了文本LLM上的文本提示。
- en: All these works employ an external solver system to run the code; therefore,
    the LLM is not conducting part of the reasoning. However, some works (Madaan et al.,
    [2022](#bib.bib18); Liu et al., [2023b](#bib.bib16)) suggest that LLMs of code
    may possess superior reasoning abilities than LLMs of text (i.e., pretrained only
    on natural language text). Madaan et al. ([2022](#bib.bib18)) observed improved
    commonsense reasoning, while Liu et al. ([2023b](#bib.bib16)) showed superior
    causal reasoning. This last work is based on the intuition that the large amount
    of if statements in the pretraining corpus enhances the causal reasoning abilities
    because they represent explicit causal relations. They conducted experiments on
    abductive and counterfactual reasoning tasks and showed that translating NL problems
    into code and then generating functions that return the answer to the problem
    with a code LLM outperforms prompting the same NL task in a text LLM. However,
    most popular LLMs are trained on text and code (e.g., GPT 3.5; Kojima et al. [2022](#bib.bib10),
    GPT 4; OpenAI [2023](#bib.bib20)) and it remains unknown whether the reported
    performance gains come from the prompt format, the abilities of the LLM, or a
    combination of both. Therefore, it remains unclear whether code prompts also outperform
    text prompts in text+code models and, if so, why code prompts elicit reasoning
    abilities. In our work, we aim to answer all these questions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些工作都使用外部求解系统来运行代码，因此 LLM 并未进行部分推理。然而，一些工作（Madaan 等人，[2022](#bib.bib18)；Liu
    等人，[2023b](#bib.bib16)）表明，代码 LLM 的推理能力可能优于仅在自然语言文本上进行预训练的文本 LLM。Madaan 等人（[2022](#bib.bib18)）观察到改进的常识推理，而
    Liu 等人（[2023b](#bib.bib16)）展示了优越的因果推理。最后一项工作基于这样一个直觉：预训练语料库中的大量 if 语句增强了因果推理能力，因为它们表示显式的因果关系。他们在归纳和反事实推理任务中进行了实验，结果显示，将自然语言问题翻译为代码，然后生成返回问题答案的函数，使用代码
    LLM 优于在文本 LLM 中提示相同的自然语言任务。然而，大多数流行的 LLM 都是在文本和代码上进行训练的（例如，GPT 3.5；Kojima 等人，[2022](#bib.bib10)，GPT
    4；OpenAI [2023](#bib.bib20)），目前尚不清楚报告的性能提升是来自提示格式、LLM 的能力，还是两者的结合。因此，尚不清楚代码提示是否在文本+代码模型中也优于文本提示，如果是的话，为什么代码提示能引发推理能力。在我们的工作中，我们旨在回答所有这些问题。
- en: As far as we know, only the concurrent work of (Hussain et al., [2023](#bib.bib6))
    investigates the conditional reasoning abilities of LLMs. However, they only analyze
    the abilities of text-only LLMs after training them on ConditionalQA (Sun et al.,
    [2022](#bib.bib25)). Instead, we investigate how to use prompts to elicit conditional
    reasoning in text+code LLMs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，只有（Hussain 等人，[2023](#bib.bib6)）的并行工作研究了 LLM 的条件推理能力。然而，他们仅分析了在 ConditionalQA（Sun
    等人，[2022](#bib.bib25)）上训练后的仅文本 LLM 的能力。相反，我们探讨了如何利用提示来引发文本+代码 LLM 的条件推理。
- en: 3 Code Prompting
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 代码提示
- en: 3.1 Definition
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 定义
- en: 'We hypothesize that querying text+code LLMs with instances translated to (pseudo)-code
    will result in improved conditional reasoning capabilities. Our hypothesis is
    motivated by previous results showing that program-aided LMs exhibit superior
    results on reasoning tasks than regular text prompts (Gao et al., [2023](#bib.bib5);
    Chen et al., [2023](#bib.bib1); Lyu et al., [2023](#bib.bib17); Ye et al., [2023](#bib.bib29)).
    Thus, it comes naturally that prompting text+code models with instances translated
    to code could cause the underlying model to exhibit superior reasoning abilities
    when compared to text prompts. We formally define our hypothesis as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设，通过将实例翻译为（伪）代码来查询文本+代码 LLM，将提高条件推理能力。我们的假设得到了以往结果的支持，这些结果显示，程序辅助的语言模型在推理任务中比普通文本提示表现更佳（Gao
    等人，[2023](#bib.bib5)；Chen 等人，[2023](#bib.bib1)；Lyu 等人，[2023](#bib.bib17)；Ye 等人，[2023](#bib.bib29)）。因此，自然地，使用翻译为代码的实例来提示文本+代码模型可能使底层模型在与文本提示相比时表现出更好的推理能力。我们将我们的假设正式定义如下：
- en: '|  | $\sum_{p\in P}\sigma(LLM(T(p)),p)\leq\sum_{p\in P}\sigma(LLM(C(p)),p)$
    |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sum_{p\in P}\sigma(LLM(T(p)),p)\leq\sum_{p\in P}\sigma(LLM(C(p)),p)$
    |  |'
- en: where $p$ are functions that create a natural language (Text) prompt and Code
    prompt, respectively, for the same given problem.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p$ 是分别为同一问题创建自然语言（文本）提示和代码提示的函数。
- en: We define code prompts as prompts that model a natural language (NL) problem
    with code. The code contains the logical structure needed to solve the problem,
    along with the original natural language text as code comments. To solve an NL
    task with code prompts, we define a chain of prompts that i) transforms the NL
    text into code and ii) prompts using this code to generate the answer in natural
    language. [Figure 1](#S1.F1 "In 1 Introduction ‣ Code Prompting Elicits Conditional
    Reasoning Abilities in Text+Code LLMs") illustrates this pipeline.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义代码提示为将自然语言（NL）问题建模为代码的提示。代码包含解决问题所需的逻辑结构，以及作为代码注释的原始自然语言文本。为了解决具有代码提示的NL任务，我们定义了一个提示链，即
    i) 将NL文本转换为代码，并 ii) 使用这段代码生成自然语言答案。[图 1](#S1.F1 "在 1 引言 ‣ 代码提示引发文本+代码 LLMs 中的条件推理能力")
    展示了这一流程。
- en: The prompt that transforms the NL problem to code is comprised of code that
    closely follows the original NL text. In particular, it creates variables for
    the key entities in the question and documents and if blocks for the documents,
    representing their conditional statements. [Figure 2](#S1.F2 "In 1 Introduction
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs") illustrates
    this transformation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将NL问题转换为代码的提示包含紧密跟随原始NL文本的代码。特别地，它为问题中的关键实体创建变量，并为文档创建if块，表示它们的条件语句。[图 2](#S1.F2
    "在 1 引言 ‣ 代码提示引发文本+代码 LLMs 中的条件推理能力") 展示了这种转换。
- en: 3.2 Coding Features
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 编码特征
- en: To generate code as close as possible to the NL text, we use a programming language
    based on a simplification of Python. We only use boolean variables or variables
    that contain lists of strings. Variables follow the snake case naming convention.
    We also employ if statements to model conditional reasoning, but we do not use
    loops, functions, or classes. We create a code comment with the original NL text
    for each input sentence, and right after the code comment, we generate the code
    that represents the semantics of that sentence. However, we do not enforce that
    the generated code should be a runnable Python script.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成尽可能接近NL文本的代码，我们使用基于Python简化版的编程语言。我们仅使用布尔变量或包含字符串列表的变量。变量遵循蛇形命名约定。我们还使用if语句来建模条件推理，但不使用循环、函数或类。我们为每个输入句子创建一个包含原始NL文本的代码注释，并在代码注释后立即生成表示该句子语义的代码。然而，我们不要求生成的代码必须是可运行的Python脚本。
- en: 4 Experimental Setup
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验设置
- en: 4.1 Datasets
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集
- en: 'Throughout our experiments, we focus on two conditional question-answering
    QA datasets: ConditionalQA (CondQA; Sun et al., [2022](#bib.bib25)) and BoardgameQA
    (BGQA; Kazemi et al., [2023](#bib.bib8)). Solving these datasets requires advanced
    conditional and compositional reasoning capabilities.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们重点关注两个条件问答数据集：ConditionalQA（CondQA；Sun 等，[2022](#bib.bib25)）和 BoardgameQA（BGQA；Kazemi
    等，[2023](#bib.bib8)）。解决这些数据集需要高级的条件和组合推理能力。
- en: ConditionalQA is a QA dataset where the answers are applicable under specific
    scenarios (i.e., conditional answers). Therefore, along with each question, the
    dataset provides a scenario that describes the background of the person posing
    such a question. Questions require multi-hop, compositional, and conditional logic
    over documents about public policies (e.g., the eligibility for a subsidy). Answers
    can be a span of the document, yes, and no. We use an oracle retriever to select
    the relevant passages to the question so that we can isolate the analysis of conditional
    reasoning abilities in LLMs from the retrieval component. The expected output
    is a chain of thought (CoT; Wei et al. [2022](#bib.bib28)) followed by the final
    answer. To create the CoT, we use the annotated evidence sentences.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ConditionalQA 是一个问答数据集，其中答案适用于特定场景（即条件答案）。因此，数据集在每个问题的同时提供一个场景，描述提出该问题的人的背景。问题需要对公共政策文档进行多跳、组合和条件逻辑推理（例如，补贴资格）。答案可以是文档的一个片段、是或否。我们使用oracle检索器来选择与问题相关的段落，从而将对LLMs条件推理能力的分析与检索组件隔离。预期输出是一个思考链（CoT；Wei
    等，[2022](#bib.bib28)）以及最终答案。为了创建CoT，我们使用注释的证据句子。
- en: BoardgameQA is a dataset that evaluates the ability to reason with contradictory
    information guided by preferences. For example, given a question about traveling
    abroad, information found online about regulations can be contradictory because
    rules may change over time. Answering questions in this dataset requires complex
    multi-hop reasoning with conditional, deductive, and compositional abilities.
    The domain of the problems is board games, which allows us to analyze the conditional
    reasoning abilities in a completely different domain from CondQA. BGQA is divided
    into multiple partitions focusing on different characteristics, such as the depth
    of the reasoning tree, the need for external information, etc. We focus on the
    main partition and its subpartitions (i.e., BGQA-1, BGQA-2, BGQA-3), where the
    number refers to the number of reasoning hops required to answer the question.
    This dataset also includes annotated chain-of-thoughts (CoT); therefore, we use
    their annotated input (“example”) as the input prompt and their annotated CoT
    (“proof”) as the expected output.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: BoardgameQA 是一个数据集，用于评估在偏好指导下处理矛盾信息的推理能力。例如，针对出国旅行的问题，网上找到的关于规定的信息可能会有矛盾，因为规则可能会随着时间而改变。回答这个数据集中的问题需要复杂的多跳推理能力，包括条件推理、演绎推理和组合推理。问题领域是棋盘游戏，这使我们能够在与
    CondQA 完全不同的领域中分析条件推理能力。BGQA 被划分为多个分区，重点关注不同的特征，如推理树的深度、对外部信息的需求等。我们关注主要分区及其子分区（即
    BGQA-1、BGQA-2、BGQA-3），其中的数字表示回答问题所需的推理跳数。该数据集还包括注释的思维链（CoT）；因此，我们使用它们注释的输入（“example”）作为输入提示，并将其注释的
    CoT（“proof”）作为期望输出。
- en: We include more details about the datasets in Appendix [A](#A1 "Appendix A Datasets
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"),
    a formal definition of the prompts in [Appendix B](#A2 "Appendix B Prompt Formulation
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"),
    and examples in [Appendix G](#A7 "Appendix G Prompt Examples ‣ Code Prompting
    Elicits Conditional Reasoning Abilities in Text+Code LLMs").
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 附录 [A](#A1 "Appendix A Datasets ‣ Code Prompting Elicits Conditional Reasoning
    Abilities in Text+Code LLMs") 中包含有关数据集的更多细节，[附录 B](#A2 "Appendix B Prompt Formulation
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs") 中提供了提示的正式定义，以及[附录
    G](#A7 "Appendix G Prompt Examples ‣ Code Prompting Elicits Conditional Reasoning
    Abilities in Text+Code LLMs") 中的示例。
- en: 4.2 LLM Setup.
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 LLM 设置。
- en: We perform our study using gpt-35-turbo-0613-16k through the Azure OpenAI service.
    All of our prompting methods are implemented using the Langchain library.²²2[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)
    We set the decoding temperature to zero and use greedy sampling to make the outputs
    deterministic. We execute our prompts with in-context learning. However, the amount
    of demonstrations is constrained by their long length and the context window of
    the model, especially in code prompts, which are longer than text prompts because
    they include the original natural language text and the corresponding code. Specifically,
    we used between three and nine demonstrations except for code prompts in BGQA-2
    and BGQA-3 where the maximum possible is 6. In other words, we provided from one
    to three demonstrations per class. For each experiment, we use a random sample
    from the training set as demonstrations. A detailed analysis of the impact of
    the number of demonstrations in the performance of the prompts is provided in
    [Section 5.4](#S5.SS4 "5.4 Code Prompts are More Sample-Efficient at Eliciting
    Reasoning Abilities ‣ 5 Experiments ‣ Code Prompting Elicits Conditional Reasoning
    Abilities in Text+Code LLMs"). We also report the costs of our prompts in [Appendix C](#A3
    "Appendix C Costs ‣ Code Prompting Elicits Conditional Reasoning Abilities in
    Text+Code LLMs").
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过 Azure OpenAI 服务使用 gpt-35-turbo-0613-16k 进行研究。我们所有的提示方法都是使用 Langchain 库实现的。²²2[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)
    我们将解码温度设置为零，并使用贪婪采样来使输出具有确定性。我们使用上下文学习执行我们的提示。然而，由于其较长的长度和模型的上下文窗口，演示的数量受到限制，特别是在代码提示中，因为它们比文本提示更长，因为它们包括原始自然语言文本和相应的代码。具体来说，我们使用了三到九个演示，BGQA-2
    和 BGQA-3 中的代码提示的最大可能值为 6。换句话说，我们每个类别提供了一到三个演示。对于每个实验，我们从训练集中随机抽取一个样本作为演示。在[第 5.4
    节](#S5.SS4 "5.4 Code Prompts are More Sample-Efficient at Eliciting Reasoning
    Abilities ‣ 5 Experiments ‣ Code Prompting Elicits Conditional Reasoning Abilities
    in Text+Code LLMs")中提供了演示数量对提示性能影响的详细分析。我们还在[附录 C](#A3 "Appendix C Costs ‣ Code
    Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs")中报告了我们提示的成本。
- en: 4.3 Evaluation.
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 评估。
- en: 'We follow the evaluation metrics used in the original datasets. For CondQA,
    we report the F1 token overlap between the predicted answer and the label, while
    for BGQA, we report accuracy. We run the main experiments multiple times with
    different random seeds: two times on BGQA and three times on CondQA. We report
    the average and standard deviation performance across these runs. For the subsequent
    analyses of code prompts, we run each experiment once due to the inference costs.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循原始数据集中使用的评估指标。对于 CondQA，我们报告预测答案与标签之间的 F1 词重叠，而对于 BGQA，我们报告准确率。我们使用不同的随机种子多次运行主要实验：BGQA
    运行两次，CondQA 运行三次。我们报告这些运行的平均值和标准差。由于推断成本，对于后续的代码提示分析，我们每次实验仅运行一次。
- en: '| Prompt Method | CondQA | BGQA-1 | BGQA-2 | BGQA-3 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 提示方法 | CondQA | BGQA-1 | BGQA-2 | BGQA-3 |'
- en: '| Text Prompt | $56.32\pm 1.06$ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 文本提示 | $56.32\pm 1.06$ |'
- en: '| Code Prompt | 59.17 $\pm$ 0.42 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 代码提示 | 59.17 $\pm$ 0.42 |'
- en: '| Atomic Statements | 55.94 | 57.80 | 47.80 | 35.60 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 原子陈述 | 55.94 | 57.80 | 47.80 | 35.60 |'
- en: '| Code $\rightarrow$ NL | 55.42 | 63.00 | 55.60 | 48.00 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 代码 $\rightarrow$ NL | 55.42 | 63.00 | 55.60 | 48.00 |'
- en: 'Table 1: Comparison of text prompt and code prompts on the validation set of
    each dataset. Last two rows analyse the impact of the input format on text prompts.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：在每个数据集的验证集上，文本提示和代码提示的比较。最后两行分析了输入格式对文本提示的影响。
- en: 5 Experiments
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: We first compare the performance of the two prompting methods — text prompts
    and code prompts. We then conduct extensive ablation experiments to determine
    whether it is the code-translated instances what improve performance or if the
    improvement is caused by implicit text simplification ([Section 5.2](#S5.SS2 "5.2
    Code Format Elicits Reasoning Abilities ‣ 5 Experiments ‣ Code Prompting Elicits
    Conditional Reasoning Abilities in Text+Code LLMs")) or by models merely being
    exposed to code within prompts and not necessarily the instances translated to
    code ([Section 5.3](#S5.SS3 "5.3 Code Semantic is Important ‣ 5 Experiments ‣
    Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs")). Finally,
    we show that code prompting is more sample efficient ([Section 5.4](#S5.SS4 "5.4
    Code Prompts are More Sample-Efficient at Eliciting Reasoning Abilities ‣ 5 Experiments
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"))
    when compared to text prompting and that models prompted with code exhibit superior
    state tracking capabilities ([Section 5.5](#S5.SS5 "5.5 Code Prompts Improve Variable
    Tracking in LLMs ‣ 5 Experiments ‣ Code Prompting Elicits Conditional Reasoning
    Abilities in Text+Code LLMs")).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先比较了两种提示方法的性能——文本提示和代码提示。然后我们进行广泛的消融实验，以确定是代码转换实例提高了性能，还是改进是由隐式文本简化 ([第 5.2
    节](#S5.SS2 "5.2 代码格式引发推理能力 ‣ 5 实验 ‣ 代码提示引发文本+代码 LLMs 的条件推理能力")) 还是模型仅仅暴露于提示中的代码，而不是必然翻译成代码的实例
    ([第 5.3 节](#S5.SS3 "5.3 代码语义很重要 ‣ 5 实验 ‣ 代码提示引发文本+代码 LLMs 的条件推理能力"))。最后，我们展示了代码提示在样本效率上优于文本提示
    ([第 5.4 节](#S5.SS4 "5.4 代码提示在引发推理能力方面更具样本效率 ‣ 5 实验 ‣ 代码提示引发文本+代码 LLMs 的条件推理能力"))，并且模型在代码提示下表现出更优的状态跟踪能力
    ([第 5.5 节](#S5.SS5 "5.5 代码提示改善 LLMs 的变量跟踪 ‣ 5 实验 ‣ 代码提示引发文本+代码 LLMs 的条件推理能力"))。
- en: 5.1 Code Prompting Improves over Text Prompting
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 代码提示优于文本提示
- en: Overall, as shown in [Table 1](#S4.T1 "In 4.3 Evaluation. ‣ 4 Experimental Setup
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"),
    code prompts consistently outperform text prompts. In particular, we can observe
    a significant performance boost of $7.71$ points on CondQA. Furthermore, we can
    also observe how the gap between both prompting methods increases in BGQA as the
    difficulty of the task increases. This clearly indicates the potential benefits
    of using code to elicit reasoning abilities, especially on the multi-hop subsets.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，如 [表 1](#S4.T1 "在 4.3 评估中。 ‣ 4 实验设置 ‣ 代码提示引发文本+代码 LLMs 的条件推理能力") 所示，代码提示始终优于文本提示。特别是，我们可以观察到
    CondQA 上的显著性能提升 $7.71$ 分。此外，我们还可以观察到，随着任务难度的增加，BGQA 中两种提示方法之间的差距也在扩大。这清楚地表明了使用代码来引发推理能力的潜在好处，尤其是在多跳子集上。
- en: We note that these consistent and substantial gains using code prompts are obtained
    despite the straightforward transformation of the text prompt, which does not
    incorporate new information as shown in [Figure 2](#S1.F2 "In 1 Introduction ‣
    Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"). This
    suggests that the code format exhibits characteristics that trigger the conditional
    reasoning abilities of text+code LLMs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，尽管文本提示的转换非常直接，并且没有引入新信息，如[图 2](#S1.F2 "在 1 引言 ‣ 代码提示激发文本+代码 LLM 的条件推理能力")所示，但使用代码提示仍然获得了一致且显著的提升。这表明代码格式具有触发文本+代码
    LLM 条件推理能力的特征。
- en: In the following experiments, we perform detailed ablation studies confirming
    that the performance improvements indeed originate from the code format and render
    additional insights into the potential reasons behind this phenomenon.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的实验中，我们进行详细的消融研究，确认性能改进确实源于代码格式，并提供了对这一现象潜在原因的额外见解。
- en: '| Prompt | CondQA | CondQA-YN | BGQA-1 | BGQA-2 | BGQA-3 |  |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 提示 | CondQA | CondQA-YN | BGQA-1 | BGQA-2 | BGQA-3 |  |'
- en: '| Code Prompt | $\mathbf{60.04}$ |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 代码提示 | $\mathbf{60.04}$ |  |'
- en: '| Anonymous code | $58.42$ |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 匿名代码 | $58.42$ |  |'
- en: '| Random code | $56.64$ |  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | $56.64$ |  |'
- en: '| - Comments | N.A. | $64.92$ |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| - 评论 | 不适用 | $64.92$ |  |'
- en: 'Table 2: Ablation study on the relevance of code semantics within Code Prompts.
    CondQA-YN represents the partition of ConditionalQA with yes-no answers.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：关于代码语义在代码提示中的相关性的消融研究。CondQA-YN 代表带有是/否答案的 ConditionalQA 部分。
- en: 5.2 Code Format Elicits Reasoning Abilities
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 代码格式激发推理能力
- en: We are now interested in whether the observed improvements in code prompting
    originate from the input instances being formatted as code or if they are caused
    by the implicit simplification of text that occurs when the instances are translated
    into code. To investigate this, we devise experiments with prompts that represent
    the intermediate states between natural language and code.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在感兴趣的是，观察到的代码提示改进是否来源于输入实例被格式化为代码，还是由于实例被翻译成代码时发生的隐含文本简化。为此，我们设计了表示自然语言和代码之间中间状态的实验。
- en: 'Inspired by Min et al. ([2023](#bib.bib19)), in our first study, we transform
    each NL sentence³³3We only transform the facts in BGQA since transforming the
    rules into atomic statements as well yields worse results. into a sequence of
    atomic statements, which we then append to the original sentence. In this way,
    the atomic statements can be seen as defining variables for each key entity in
    the text. Therefore, this new type of prompt would resemble code but without control
    flow and in natural language form. For instance, for the sentence Applying for
    the legal right to deal with someone’s property, money and possessions (their
    estate) when they die is called applying for probate, some atomic statements would
    be: i) Applying for the legal right is a process and ii) The process is called
    ‘applying for probate’. A complete example is provided in [Appendix D](#A4 "Appendix
    D Atomic Statements ‣ Code Prompting Elicits Conditional Reasoning Abilities in
    Text+Code LLMs").'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 受到 Min 等人（[2023](#bib.bib19)）的启发，在我们的第一次研究中，我们将每个 NL 句子³³3我们只转换 BGQA 中的事实，因为将规则转换为原子语句会产生更差的结果。
    转换为一系列原子语句，然后将其附加到原始句子中。通过这种方式，原子语句可以视为定义文本中每个关键实体的变量。因此，这种新类型的提示会类似于代码，但没有控制流，并且以自然语言形式呈现。例如，对于句子“申请处理某人财产、金钱和财物（遗产）的法律权利称为申请遗嘱认证”，一些原子语句可能是：i）申请法律权利是一个过程，ii）该过程称为“申请遗嘱认证”。完整的示例见[附录
    D](#A4 "附录 D 原子语句 ‣ 代码提示激发文本+代码 LLM 的条件推理能力")。
- en: The prompt retains access to the original instance text (i.e., no loss of information)
    but is also augmented by simplified sentences in the form of atomic statements.
    This setup allows us to investigate whether the simplicity of the input prompt
    is the cause of improved reasoning abilities, regardless of the text and code
    formats.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 提示保留对原始实例文本的访问（即信息没有丢失），但也通过以原子语句形式呈现的简化句子进行了增强。该设置使我们能够调查输入提示的简化是否是提高推理能力的原因，而不考虑文本和代码格式。
- en: 'In our second experiment, we investigate whether the semantics of the code
    statements and not the form of the code are the reason behind the performance
    boost. For this purpose, we back-transform the code prompts into NL such that
    the reasoning statements (i.e., the if conditions) are clearly and concisely stated
    in natural language. Specifically, we map every variable into the format Key entity:
    variable without snake case. For instance, the variable husband_pass_away from
    [Figure 2](#S1.F2 "In 1 Introduction ‣ Code Prompting Elicits Conditional Reasoning
    Abilities in Text+Code LLMs") would be back-transformed as Key entity: husband
    pass away. To transform the if statements, we create a translation prompt by providing
    four demonstrations. These demonstrations simply translate the conditional statements
    within the  code-formatted instance back into natural language in the same manner
    as the variables. This makes the back-translated text as close as possible to
    the code text. We provide examples of this in [Table 6](#A6.T6 "In Prompt Probes.
    ‣ Appendix F Variable Tracking Setup ‣ Code Prompting Elicits Conditional Reasoning
    Abilities in Text+Code LLMs") from [Appendix E](#A5 "Appendix E Examples of Code
    Ablations ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code
    LLMs").'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们的第二个实验中，我们研究了代码语句的语义而非代码的形式是否是性能提升的原因。为此，我们将代码提示回转化为自然语言，使得推理语句（即if条件）在自然语言中清晰且简明地表达。具体来说，我们将每个变量映射为格式为“Key
    entity: variable”的形式，不使用蛇形命名法。例如，[图2](#S1.F2 "在1介绍‣ 代码提示引发文本+代码LLM中的条件推理能力")中的变量husband_pass_away将被回转化为“Key
    entity: husband pass away”。为了转换if语句，我们创建了一个翻译提示，通过提供四个示例来实现。这些示例简单地将代码格式实例中的条件语句翻译回自然语言，与变量的方式相同。这使得回翻译的文本尽可能接近代码文本。我们在[表6](#A6.T6
    "在提示探测器。‣ 附录F变量跟踪设置‣ 代码提示引发文本+代码LLM中的条件推理能力")中提供了这一点的示例，来自[附录E](#A5 "附录E代码消融示例‣
    代码提示引发文本+代码LLM中的条件推理能力")。'
- en: From the results in [Table 1](#S4.T1 "In 4.3 Evaluation. ‣ 4 Experimental Setup
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"),
    we see that (1) prompting with atomic statements does not yield performance improvements
    w.r.t. text prompts, and (2) mapping back from code to NL provokes performance
    drop w.r.t. code prompts, yielding similar results to the original text prompt.
    In the first case, we observe that the performance drop w.r.t. the original text
    prompt can be due to the sampling variance since the results are within the standard
    deviation of text prompts. However, we obtain a more acute drop for BGQA. This
    can be attributed to the format of this dataset. The atomic statements method
    we use (Min et al., [2023](#bib.bib19)) was devised for general texts such as
    Wikipedia pages. However, BGQA is a logic-based dataset, where the input facts
    are statements that are already minimal units of information and do not follow
    the style of general documents. Thus, creating atomic statements from these sentences
    can break the sentence structure needed to track the attributes of the subjects
    and objects of the sentences.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从[表1](#S4.T1 "在4.3评估。‣ 4实验设置‣ 代码提示引发文本+代码LLM中的条件推理能力")的结果中，我们看到（1）使用原子语句提示并未带来相对于文本提示的性能提升，（2）从代码映射回自然语言会导致相对于代码提示的性能下降，结果与原始文本提示类似。在第一种情况下，我们观察到相对于原始文本提示的性能下降可能是由于采样方差，因为结果在文本提示的标准差范围内。然而，对于BGQA，我们获得了更明显的下降。这可以归因于数据集的格式。我们使用的原子语句方法（Min等，[2023](#bib.bib19)）是为像维基百科页面这样的通用文本设计的。然而，BGQA是一个基于逻辑的数据集，其中输入事实是已经是最小信息单位的语句，并不遵循通用文档的风格。因此，从这些句子创建原子语句可能会破坏追踪句子中主语和宾语属性所需的句子结构。
- en: These results indicate that the enhanced complex reasoning abilities do not
    originate from input text simplification nor the conditional statements being
    extracted from the instance sentences, but rather the code format of the input
    instances.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，增强的复杂推理能力并非源于输入文本简化或从实例句子中提取的条件语句，而是源于输入实例的代码格式。
- en: 5.3 Code Semantic is Important
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 代码语义很重要
- en: Previously, we have shown that the code format is necessary to elicit the reasoning
    abilities of text+code LLMs. Now, we aim to investigate which aspects of code
    are needed for this. In particular, we evaluate the impact of retaining the natural
    language text of the original instance within the code comments and the importance
    of the semantics of the code. To analyze the former, we have removed the code
    comments that include the original natural language text from the input and evaluated
    the performance of the new prompts. To analyze the latter, we perturbed the code
    to anonymize the variables and functions, as well as added random code whose semantics
    are completely irrelevant to the original natural language text. In the latter
    two cases, the code comments remain unmodified (examples illustrating them are
    provided in [Table 7](#A6.T7 "In Prompt Probes. ‣ Appendix F Variable Tracking
    Setup ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs")
    from [Appendix E](#A5 "Appendix E Examples of Code Ablations ‣ Code Prompting
    Elicits Conditional Reasoning Abilities in Text+Code LLMs")). Since CondQA includes
    span answers and removing the NL text would make it impossible for the model to
    generate the span, we only report performance on the yes-no answers partition
    (i.e., CondQA-YN).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们已经展示了代码格式对激发文本+代码LLMs的推理能力是必要的。现在，我们旨在探究哪些代码方面对此是必要的。特别是，我们评估了保留原始实例中的自然语言文本在代码注释中的影响及代码语义的重要性。为了分析前者，我们移除了包含原始自然语言文本的代码注释，并评估了新提示的表现。为了分析后者，我们扰动了代码以匿名化变量和函数，并添加了与原始自然语言文本完全不相关的随机代码。在后两种情况下，代码注释保持不变（相关示例见[表7](#A6.T7
    "In Prompt Probes. ‣ Appendix F Variable Tracking Setup ‣ Code Prompting Elicits
    Conditional Reasoning Abilities in Text+Code LLMs")，来自[附录E](#A5 "Appendix E Examples
    of Code Ablations ‣ Code Prompting Elicits Conditional Reasoning Abilities in
    Text+Code LLMs")）。由于CondQA包括跨度答案，移除NL文本会使模型无法生成跨度，因此我们仅报告yes-no答案部分（即CondQA-YN）的表现。
- en: Table [2](#S5.T2 "Table 2 ‣ 5.1 Code Prompting Improves over Text Prompting
    ‣ 5 Experiments ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code
    LLMs") shows that removing the NL text in the code comments yields a performance
    drop of $14.02$ on BGQA. This significant and consistent decrease in all datasets
    confirms that retaining NL text in comments is vital for the LLM to understand
    the input problem.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表[2](#S5.T2 "Table 2 ‣ 5.1 Code Prompting Improves over Text Prompting ‣ 5 Experiments
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs")显示，移除代码注释中的NL文本导致BGQA性能下降了$14.02$。这种显著且一致的下降在所有数据集中确认了保留NL文本在注释中对LLM理解输入问题的重要性。
- en: Code perturbations (anonymous code and random code) also confirm the importance
    of code semantics to elicit reasoning abilities. When we use anonymized code,
    we observe a performance reduction of almost $2$ on BGQA. This more pronounced
    drop is expected since the semantics and logic of the code mismatch the NL text,
    whereas anonymous code maintains the same logic on both NL and code.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 代码扰动（匿名代码和随机代码）也确认了代码语义在激发推理能力中的重要性。当我们使用匿名代码时，我们观察到BGQA的性能下降了近$2$。这种更明显的下降是预期中的，因为代码的语义和逻辑与NL文本不匹配，而匿名代码在NL和代码上保持相同的逻辑。
- en: Furthermore, we also observe that the performance of random code prompts is
    similar to that of text prompts (Table [1](#S4.T1 "Table 1 ‣ 4.3 Evaluation. ‣
    4 Experimental Setup ‣ Code Prompting Elicits Conditional Reasoning Abilities
    in Text+Code LLMs")) in all datasets. This can be interpreted as the model being
    able to identify the irrelevance of the code to the text. Hence, the model disregards
    the code to solely focus on the code comments (i.e., the natural language text).
    This could be possible thanks to the provided demonstrations, which show answers
    that only refer to the natural language text.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还观察到，随机代码提示的表现与文本提示在所有数据集中的表现相似（表[1](#S4.T1 "Table 1 ‣ 4.3 Evaluation.
    ‣ 4 Experimental Setup ‣ Code Prompting Elicits Conditional Reasoning Abilities
    in Text+Code LLMs")）。这可以解释为模型能够识别代码与文本的不相关性。因此，模型忽略代码，专注于代码注释（即自然语言文本）。这可能得益于提供的演示，展示了仅引用自然语言文本的答案。
- en: These results confirm that code alone does not trigger reasoning abilities,
    and instead, the combination of code that represents the original natural language
    instance and the NL text exploits the potential of LLMs.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果确认了仅有代码并不会激发推理能力，相反，代表原始自然语言实例的代码与NL文本的结合利用了LLMs的潜力。
- en: 5.4 Code Prompts are More Sample-Efficient at Eliciting Reasoning Abilities
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 代码提示在引发推理能力方面更具样本效率
- en: 'Given our observations that code prompts trigger conditional reasoning abilities
    better than text prompts, it is natural to ask the follow-up question: are code
    prompts also more sample-efficient at triggering conditional reasoning abilities
    when compared to text prompts? To answer this, we evaluate how the overall performance
    of the model changes with respect to the number of demonstrations.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们的观察表明，代码提示比文本提示更能引发条件推理能力，自然会提出一个后续问题：与文本提示相比，代码提示在引发条件推理能力方面是否也更具样本效率？为了回答这个问题，我们评估了模型的整体性能如何随着示例数量的变化而变化。
- en: In the following experiments, we compare the performance gap of the two prompting
    methods under different numbers of demonstrations. [Figure 3](#S5.F3 "In 5.4 Code
    Prompts are More Sample-Efficient at Eliciting Reasoning Abilities ‣ 5 Experiments
    ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs") shows
    that when we only provide one demonstration per class (i.e., answer type in our
    datasets), the performance gap is the largest across all datasets. As expected,
    this gap decreases when we provide more demonstrations. These results indicate
    that code prompts trigger conditional reasoning more efficiently than text prompts,
    and this is one of the reasons for its superior performance. This phenomenon has
    further applicability in long-document and very low resource settings, where only
    one demonstration is available or fits within the input window, and therefore,
    it would be advisable to convert that demonstration into code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下实验中，我们比较了在不同示例数量下，两种提示方法的性能差距。[图 3](#S5.F3 "在 5.4 节中，代码提示在引发推理能力方面更具样本效率
    ‣ 5 实验 ‣ 代码提示在文本+代码 LLM 中引发条件推理能力") 显示，当我们每类仅提供一个示例（即我们数据集中的答案类型）时，性能差距在所有数据集中最大。正如预期的那样，当我们提供更多示例时，这个差距会减少。这些结果表明，代码提示比文本提示更有效地引发条件推理能力，这也是其优越性能的原因之一。这一现象在长文档和极低资源环境中具有进一步的适用性，在这些环境中仅有一个示例可用或适合于输入窗口，因此，建议将该示例转换为代码。
- en: '![Refer to caption](img/446f092ace79a6b0b9dd1da53762025b.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/446f092ace79a6b0b9dd1da53762025b.png)'
- en: 'Figure 3: Performance comparison between text prompts (blue) and code prompts
    (green) using 1, 2, and 3 demonstrations per class.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：使用每类 1、2 和 3 个示例的文本提示（蓝色）与代码提示（绿色）的性能比较。
- en: 5.5 Code Prompts Improve Variable Tracking in LLMs
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 代码提示改善 LLM 中的变量跟踪
- en: '|  | Correct Instances | Incorrect Instances |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | 正确实例 | 错误实例 |'
- en: '| --- | --- | --- |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Dataset | Text Prompts | Code Prompts | Text Prompts | Code Prompts |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 文本提示 | 代码提示 | 文本提示 | 代码提示 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CondQA | 71.08 | 4.39 | 60.79 | 11.39 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| CondQA | 71.08 | 4.39 | 60.79 | 11.39 |'
- en: '| BGQA-1 | 39.33 | 8.84 | 51.65 | 22.12 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| BGQA-1 | 39.33 | 8.84 | 51.65 | 22.12 |'
- en: '| BGQA-2 | 44.79 | 15.04 | 52.54 | 24.75 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| BGQA-2 | 44.79 | 15.04 | 52.54 | 24.75 |'
- en: '| BGQA-3 | 54.01 | 14.21 | 52.13 | 16.98 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| BGQA-3 | 54.01 | 14.21 | 52.13 | 16.98 |'
- en: 'Table 3: Comparison of the percentage of memory errors made by GPT 3.5\. For
    each dataset, we separately compute memory errors for the instances where the
    model gives the correct and incorrect answers. Lower is better.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：GPT 3.5 的记忆错误百分比比较。对于每个数据集，我们分别计算模型给出正确答案和错误答案的记忆错误。错误率越低越好。
- en: We hypothesize that one of the reasons for the superior performance of code
    prompting is an improved ability to track the states of variables or key concepts.
    This hypothesis is based on the intuition that, for natural language in general,
    local context is the most important part of generating the next token Khandelwal
    et al. ([2018](#bib.bib9)); Sun et al. ([2021](#bib.bib26)). However, generating
    code is often more challenging because code frequently refers to previously defined
    functions, which can be dozens or even hundreds of lines apart. This resembles
    multi-hop reasoning, where the model may need to reference a key entity dozens
    of lines before. Therefore, an improved ability to look for distant co-references
    can be beneficial to multi-hop reasoning, which is also needed to solve our datasets.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设代码提示性能优越的原因之一是改进了跟踪变量或关键概念状态的能力。这个假设基于这样的直觉，即对于自然语言来说，局部上下文是生成下一个标记的最重要部分
    Khandelwal 等人 ([2018](#bib.bib9)); Sun 等人 ([2021](#bib.bib26))。然而，生成代码通常更具挑战性，因为代码经常引用之前定义的函数，这些函数可能相隔几十行甚至几百行。这类似于多跳推理，其中模型可能需要参考几十行之前的关键实体。因此，改进查找远程共同引用的能力对多跳推理可能是有益的，而这也是解决我们数据集所需的能力。
- en: To test our hypothesis, we devise the following experiment. Firstly, we define
    reasoning step as each output sentence split by “\n.” After generating each reasoning
    step, we stop the model generation and query about all key entities defined in
    the input prompt. In the case of text prompts, we query the model whether the
    given facts are true or not, and for code prompts, we query for the value of the
    (boolean) variables. In all cases, the model only has to generate True, False,
    a string, or unknown. Then, we compare the percentage of errors in text and code
    prompts. This number represents the memory errors committed by the model. The
    more memory errors, the more difficult is for the model to track and remember
    entities/variables. We provide further details on how we extracted the key entities
    to ask for, how we identified the reasoning steps in the chain of thought used
    to stop the model from conducting the probes, and examples of the prompt probes
    in [Appendix F](#A6 "Appendix F Variable Tracking Setup ‣ Code Prompting Elicits
    Conditional Reasoning Abilities in Text+Code LLMs") and its [Table 8](#A6.T8 "In
    Prompt Probes. ‣ Appendix F Variable Tracking Setup ‣ Code Prompting Elicits Conditional
    Reasoning Abilities in Text+Code LLMs").
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们的假设，我们设计了以下实验。首先，我们将推理步骤定义为每个输出句子按“\n”分隔。在生成每个推理步骤后，我们停止模型生成并查询输入提示中定义的所有关键实体。在文本提示的情况下，我们查询模型所给的事实是否为真，而在代码提示的情况下，我们查询（布尔型）变量的值。在所有情况下，模型只需生成
    True、False、一个字符串或 unknown。然后，我们比较文本和代码提示中的错误百分比。这个数字代表了模型犯的记忆错误。记忆错误越多，模型跟踪和记住实体/变量的难度就越大。我们提供了有关如何提取关键实体以进行查询、如何识别推理步骤以停止模型进行探针，以及[附录
    F](#A6 "附录 F 变量跟踪设置 ‣ 代码提示引发文本+代码 LLM 的条件推理能力")和其[表 8](#A6.T8 "在提示探针中。 ‣ 附录 F
    变量跟踪设置 ‣ 代码提示引发文本+代码 LLM 的条件推理能力")中的提示探针示例的进一步细节。
- en: We acknowledge that the output text may not be completely faithful to the internal
    beliefs of the model (Lyu et al., [2023](#bib.bib17)). Therefore, we first test
    whether this experiment can be a proxy metric of the internal belief of the model.
    To do this, we compare the memory error percentage of the prompting methods in
    instances where the model solves (i.e., correct instances) and does not solve
    (i.e., incorrect instances) the question. If incorrect instances yield a higher
    memory error, this would indicate that the model struggles more to remember the
    state of those variables, and this would make it fail to conduct the reasoning
    process. Therefore, our probes would be a proxy metric of the internal belief
    of the model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们承认输出文本可能无法完全忠实于模型的内部信念（Lyu 等人，[2023](#bib.bib17)）。因此，我们首先测试此实验是否可以作为模型内部信念的代理指标。为此，我们比较模型在解决问题（即正确实例）和未解决问题（即错误实例）时，提示方法的记忆错误百分比。如果错误实例产生更高的记忆错误，这将表明模型在记住这些变量的状态时遇到更多困难，从而使其无法进行推理过程。因此，我们的探针将成为模型内部信念的代理指标。
- en: '[Table 3](#S5.T3 "In 5.5 Code Prompts Improve Variable Tracking in LLMs ‣ 5
    Experiments ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code
    LLMs") shows the results of this comparison. We observe that all prompting methods
    in all datasets consistently make more memory mistakes on incorrect instances
    than on correct instances, with the exception of text prompts on CondQA. However,
    the memory error in this case is significantly high, which may suggest that the
    model is not able to track entities correctly in any case. Therefore, we can use
    this experiment as a proxy measure of the memory of the model.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3](#S5.T3 "在5.5代码提示提高LLMs中的变量跟踪 ‣ 5个实验 ‣ 代码提示引发文本+代码LLMs中的条件推理能力")展示了这种比较的结果。我们观察到，除了在CondQA上的文本提示外，所有数据集中的所有提示方法在错误实例上的记忆错误始终比正确实例多。然而，这种情况下的记忆错误显著较高，这可能表明模型在任何情况下都无法正确跟踪实体。因此，我们可以将这个实验作为模型记忆的代理指标。'
- en: From the same table, we can observe that Text Prompts make significantly more
    memory errors than code prompts on all datasets. Specifically, the gap is consistently
    more than 30% with peaks on CondQA (66.69%) and BGQA-3 (39.8%). Therefore, this
    experiment empirically confirms our hypothesis that code prompts can track the
    state of the variables/key entities better than text prompts.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从同一表中，我们可以观察到，文本提示在所有数据集上比代码提示产生了显著更多的记忆错误。具体而言，这个差距始终超过30%，在CondQA（66.69%）和BGQA-3（39.8%）上达到了峰值。因此，这个实验从经验上证实了我们的假设，即代码提示可以比文本提示更好地跟踪变量/关键实体的状态。
- en: 5.6 Qualitative Analysis
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 质性分析
- en: 'All our previous experiments have focused on the accuracy of the answers. Obtaining
    a correct answer is correlated to a correct reasoning process. However, it is
    possible to obtain a correct answer despite an incorrect reasoning chain. Due
    to the difficulty of automatically evaluating the chain of thoughts, we perform
    a limited human evaluation. We sample ten instances from BGQA-3 (i.e., the dataset
    with the most complex reasoning chains) where both text and code prompts return
    the correct answer and manually inspect the quality of the reasoning chains. Based
    on this limited sample, we observe that text prompts conduct a 100% correct reasoning
    chain in only two cases, while code prompts do so in three cases. We identify
    two main types of errors: (1) wrong conditional reasoning and (2) commonsense
    errors. We provide examples of those in [Table 4](#S5.T4 "In 5.6 Qualitative Analysis
    ‣ 5 Experiments ‣ Code Prompting Elicits Conditional Reasoning Abilities in Text+Code
    LLMs"). This observation raises the question of whether the generated chain of
    thought is not faithful to the internal reasoning of the model, as suggested by
    (Lyu et al., [2023](#bib.bib17)) or whether the model generated the right answer
    from a greedy attempt to reach the closest plausible conclusion (code prompts
    shows a reasoning error in the last step of the CoT in three out of seven cases).
    We leave the analysis of faithfulness of chains of thoughts as future work.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的实验都集中在答案的准确性上。获得正确答案与正确的推理过程相关。然而，尽管推理链不正确，也有可能获得正确答案。由于自动评估思维链的困难，我们进行了有限的人为评估。我们从BGQA-3（即推理链最复杂的数据集）中抽取了十个实例，其中文本和代码提示都返回了正确的答案，并手动检查推理链的质量。根据这个有限的样本，我们观察到文本提示在只有两个案例中进行了100%正确的推理链，而代码提示在三个案例中做到了这一点。我们识别出两种主要的错误类型：（1）错误的条件推理和（2）常识错误。我们在[表4](#S5.T4
    "在5.6质性分析 ‣ 5个实验 ‣ 代码提示引发文本+代码LLMs中的条件推理能力")中提供了这些例子的说明。这个观察结果引发了一个问题，即生成的思维链是否忠实于模型的内部推理，正如(Lyu
    et al., [2023](#bib.bib17))所建议的，或者模型是否通过贪婪尝试生成了正确的答案，以接近最可信的结论（在七个案例中的三个中，代码提示在CoT的最后一步显示了推理错误）。我们将思维链忠实性的分析留作未来工作。
- en: '| Error Type | Example | Explanation |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 错误类型 | 示例 | 解释 |'
- en: '| --- | --- | --- |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Commonsense | We know the catfish has a harmonica, and according to Rule3
    "if the catfish has something to sit on, … | The model believes a harmonica is
    something to sit on. |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 常识 | 我们知道鲶鱼有一个口琴，根据规则3 “如果鲶鱼有东西可以坐... | 模型认为口琴是可以坐的东西。 |'
- en: '| Conditional Reasoning | # We know the lion does not remove from the board
    one of the pieces of the dog, and according to Rule5 "if something becomes an
    enemy of the squid but does not remove from the board one of the pieces of the
    dog, then it steals five points from the mosquito." become_enemy(lion, squid)==True
    not remove_piece(lion, dog)==True steal_points(lion,mosquito,5)=rule5(lion) steal_points(lion,
    mosquito, 5)==True | We do not know  become_enemy(lion, squid) == True, but if
    we assume this, we reach the question variable, so we get an answer to the question.
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 条件推理 | # 我们知道狮子不会从棋盘上移除狗的一块棋子，根据规则5“如果某物成为鱿鱼的敌人但没有从棋盘上移除狗的一块棋子，则它从蚊子那里偷取五分。”
    become_enemy(lion, squid)==True not remove_piece(lion, dog)==True steal_points(lion,mosquito,5)=rule5(lion)
    steal_points(lion, mosquito, 5)==True | 我们不知道 become_enemy(lion, squid) == True，但如果我们假设这一点，我们就能得出问题变量，从而获得问题的答案。
    |'
- en: 'Table 4: Examples of reasoning errors on correct instances by text and code
    prompts. Underline text is the cause of the error.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：文本和代码提示在正确实例上的推理错误示例。下划线文本是错误的原因。
- en: 6 Conclusions and Future Work
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与未来工作
- en: This work demonstrates that conditional reasoning abilities can be triggered
    by using code prompts in large language models (LLMs) of text and code. These
    code prompts contain the original natural language (NL) formulation as a code
    comment and code that formulates the logic of the text (e.g., documents and questions).
    To create these code prompts, we use in-context learning to teach an LLM how to
    automatically conduct such a transformation. Through multiple experiments, we
    show that code prompts trigger conditional reasoning abilities. They consistently
    and substantially outperform text prompts across two conditional reasoning datasets
    by between $2.6$ points. Our experiments show that even simple code can be beneficial
    as long as it closely follows the semantics of the NL text and is accompanied
    by the original NL text. In addition, code prompts require fewer demonstrations,
    making them more efficient than vanilla text prompts. Our experiments also suggest
    that code prompts achieve the performance boost due to their superior ability
    to track the state of variables or key entities.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作展示了条件推理能力可以通过在大型语言模型（LLMs）中使用代码提示来触发。这些代码提示包含了原始自然语言（NL）表述作为代码注释和制定文本逻辑的代码（例如，文档和问题）。为了创建这些代码提示，我们使用了上下文学习来教导
    LLM 如何自动进行这种转换。通过多次实验，我们展示了代码提示触发了条件推理能力。它们在两个条件推理数据集上的表现一致且显著优于文本提示，提升幅度达 $2.6$
    分。我们的实验表明，即使是简单的代码，只要紧密遵循 NL 文本的语义并伴有原始 NL 文本，也能发挥作用。此外，代码提示需要较少的演示，使其比普通文本提示更高效。我们的实验还表明，代码提示之所以能实现性能提升，是因为其跟踪变量或关键实体状态的能力更强。
- en: In our future work, we plan to extend our experiments to other text+code LLMs.
    We also plan to conduct experiments investigating how pretraining on text, code,
    and text+code affects the triggering of reasoning abilities. Lastly, we would
    like to extend our experiments to a wider range of reasoning abilities to verify
    the generalization of our findings.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来的工作中，我们计划将实验扩展到其他文本+代码的 LLMs。我们还计划进行实验，调查对文本、代码和文本+代码的预训练如何影响推理能力的触发。最后，我们希望将实验扩展到更广泛的推理能力，以验证我们发现的普遍性。
- en: Limitations
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: Transforming a natural language problem into code requires an intermediate step
    that raises the cost of the whole pipeline. However, this mapping is not a complicated
    task. Therefore, we believe it would be possible to train a small generative model
    to do it instead of using a large language model. In this way, we could minimize
    the cost of using code prompts without affecting its performance.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 将自然语言问题转换成代码需要一个中间步骤，这增加了整个流程的成本。然而，这种映射并不是一个复杂的任务。因此，我们认为可以训练一个小型生成模型来代替使用大型语言模型。通过这种方式，我们可以在不影响性能的情况下，最小化使用代码提示的成本。
- en: Due to the costs of very large language models and the large size of BoardgameQA,
    we only ran the experiments two times with different random seeds. However, the
    variance is small enough to ensure the representativeness of the results.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于非常大型语言模型的成本和 BoardgameQA 的大规模，我们只进行了两次实验，每次使用不同的随机种子。然而，方差足够小，以确保结果的代表性。
- en: Acknowledgements
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work has been funded by the German Research Foundation (DFG) as part of
    the UKP-SQuARE project (grant GU 798/29-1), by the German Federal Ministry of
    Education and Research and the Hessian Ministry of Higher Education, Research,
    Science and the Arts within their joint support of the National Research Center
    for Applied Cybersecurity ATHENE, and by the European Union (ERC, InterText, 101054961).
    Views and opinions expressed are, however, those of the author(s) only and do
    not necessarily reflect those of the European Union or the European Research Council.
    Neither the European Union nor the granting authority can be held responsible
    for them.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究由德国研究基金会（DFG）资助，作为UKP-SQuARE项目（资助编号GU 798/29-1）的一部分，此外还由德国联邦教育和研究部以及黑森州高等教育、研究、科学与艺术部共同资助支持国家应用网络安全研究中心ATHENE，以及由欧盟（ERC,
    InterText, 101054961）资助。然而，所表达的观点和意见仅代表作者（们）个人，不一定反映欧盟或欧洲研究委员会的观点。欧盟和资助机构对此不承担责任。
- en: We gratefully acknowledge the support of Microsoft with a grant for access to
    OpenAI GPT models via the Azure cloud (Accelerate Foundation Model Academic Research).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们由衷感谢微软提供的资助，使我们能够通过Azure云访问OpenAI GPT模型（Accelerate Foundation Model Academic
    Research）。
- en: Lastly, we thank Max Glockner, Jonathan Tonglet, and Sheng Lu for their insightful
    comments and suggestions on a draft of this paper.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们感谢Max Glockner、Jonathan Tonglet和Sheng Lu对本文草稿提出的有见地的评论和建议。
- en: References
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Chen et al. (2023) Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen.
    2023. [Program of thoughts prompting: Disentangling computation from reasoning
    for numerical reasoning tasks](https://openreview.net/forum?id=YfZ4ZPt8zd). *Transactions
    on Machine Learning Research*.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2023年）Wenhu Chen、Xueguang Ma、Xinyi Wang和William W. Cohen。2023年。[思维提示程序：为数值推理任务分离计算与推理](https://openreview.net/forum?id=YfZ4ZPt8zd)。*机器学习研究事务*。
- en: 'Chen et al. (2021) Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana
    Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge,
    and William Yang Wang. 2021. [FinQA: A dataset of numerical reasoning over financial
    data](https://doi.org/10.18653/v1/2021.emnlp-main.300). In *Proceedings of the
    2021 Conference on Empirical Methods in Natural Language Processing*, pages 3697–3711,
    Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen等人（2021年）Zhiyu Chen、Wenhu Chen、Charese Smiley、Sameena Shah、Iana Borova、Dylan
    Langdon、Reema Moussa、Matt Beane、Ting-Hao Huang、Bryan Routledge和William Yang Wang。2021年。[FinQA:
    一个财务数据的数值推理数据集](https://doi.org/10.18653/v1/2021.emnlp-main.300)。在*2021年自然语言处理实证方法会议论文集*，第3697–3711页，在线和多米尼加共和国蓬塔卡纳。计算语言学协会。'
- en: 'Chowdhery et al. (2023) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
    Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily
    Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael
    Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
    Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam
    Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander
    Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M.
    Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
    Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,
    Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern,
    Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2023. [Palm: Scaling language
    modeling with pathways](http://jmlr.org/papers/v24/22-1144.html). *Journal of
    Machine Learning Research*, 24(240):1–113.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chowdhery等人（2023年）Aakanksha Chowdhery、Sharan Narang、Jacob Devlin、Maarten Bosma、Gaurav
    Mishra、Adam Roberts、Paul Barham、Hyung Won Chung、Charles Sutton、Sebastian Gehrmann、Parker
    Schuh、Kensen Shi、Sasha Tsvyashchenko、Joshua Maynez、Abhishek Rao、Parker Barnes、Yi
    Tay、Noam Shazeer、Vinodkumar Prabhakaran、Emily Reif、Nan Du、Ben Hutchinson、Reiner
    Pope、James Bradbury、Jacob Austin、Michael Isard、Guy Gur-Ari、Pengcheng Yin、Toju
    Duke、Anselm Levskaya、Sanjay Ghemawat、Sunipa Dev、Henryk Michalewski、Xavier Garcia、Vedant
    Misra、Kevin Robinson、Liam Fedus、Denny Zhou、Daphne Ippolito、David Luan、Hyeontaek
    Lim、Barret Zoph、Alexander Spiridonov、Ryan Sepassi、David Dohan、Shivani Agrawal、Mark
    Omernick、Andrew M. Dai、Thanumalayan Sankaranarayana Pillai、Marie Pellat、Aitor
    Lewkowycz、Erica Moreira、Rewon Child、Oleksandr Polozov、Katherine Lee、Zongwei Zhou、Xuezhi
    Wang、Brennan Saeta、Mark Diaz、Orhan Firat、Michele Catasta、Jason Wei、Kathy Meier-Hellstern、Douglas
    Eck、Jeff Dean、Slav Petrov和Noah Fiedel。2023年。[Palm: 扩展语言建模与路径](http://jmlr.org/papers/v24/22-1144.html)。*机器学习研究期刊*，24(240):1–113。'
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, et al. 2021. [Training verifiers to solve math word problems](https://arxiv.org/abs/2110.14168).
    *arXiv preprint arXiv:2110.14168*.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe 等人（2021）Karl Cobbe、Vineet Kosaraju、Mohammad Bavarian、Mark Chen、Heewoo
    Jun、Lukasz Kaiser、Matthias Plappert、Jerry Tworek、Jacob Hilton、Reiichiro Nakano
    等。2021年。[训练验证器解决数学文字题](https://arxiv.org/abs/2110.14168)。*arXiv 预印本 arXiv:2110.14168*。
- en: 'Gao et al. (2023) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu,
    Yiming Yang, Jamie Callan, and Graham Neubig. 2023. [Pal: program-aided language
    models](https://dl.acm.org/doi/10.5555/3618408.3618843). In *Proceedings of the
    40th International Conference on Machine Learning*, ICML’23\. JMLR.org.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao 等人（2023）Luyu Gao、Aman Madaan、Shuyan Zhou、Uri Alon、Pengfei Liu、Yiming Yang、Jamie
    Callan 和 Graham Neubig。2023年。[Pal: 程序辅助语言模型](https://dl.acm.org/doi/10.5555/3618408.3618843)。在
    *第40届国际机器学习大会论文集*，ICML’23。JMLR.org。'
- en: Hussain et al. (2023) Syed-Amad Hussain, Parag Pravin Dakle, SaiKrishna Rallabandi,
    and Preethi Raghavan. 2023. [Towards leveraging llms for conditional qa](https://arxiv.org/abs/2312.01143).
    *arXiv preprint arXiv:2312.01143*.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hussain 等人（2023）Syed-Amad Hussain、Parag Pravin Dakle、SaiKrishna Rallabandi 和
    Preethi Raghavan。2023年。[朝着利用大型语言模型进行条件问答](https://arxiv.org/abs/2312.01143)。*arXiv
    预印本 arXiv:2312.01143*。
- en: Jiang et al. (2023) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. 2023. [Mistral 7b](https://arxiv.org/abs/2310.06825). *arXiv
    preprint arXiv:2310.06825*.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人（2023）Albert Q. Jiang、Alexandre Sablayrolles、Arthur Mensch、Chris Bamford、Devendra
    Singh Chaplot、Diego de las Casas、Florian Bressand、Gianna Lengyel、Guillaume Lample、Lucile
    Saulnier、Lélio Renard Lavaud、Marie-Anne Lachaux、Pierre Stock、Teven Le Scao、Thibaut
    Lavril、Thomas Wang、Timothée Lacroix 和 William El Sayed。2023年。[Mistral 7b](https://arxiv.org/abs/2310.06825)。*arXiv
    预印本 arXiv:2310.06825*。
- en: 'Kazemi et al. (2023) Mehran Kazemi, Quan Yuan, Deepti Bhatia, Najoung Kim,
    Xin Xu, Vaiva Imbrasaite, and Deepak Ramachandran. 2023. [BoardgameQA: A dataset
    for natural language reasoning with contradictory information](https://openreview.net/forum?id=BR1m3JIoKm).
    In *Thirty-seventh Conference on Neural Information Processing Systems Datasets
    and Benchmarks Track*, pages 1–23.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kazemi 等人（2023）Mehran Kazemi、Quan Yuan、Deepti Bhatia、Najoung Kim、Xin Xu、Vaiva
    Imbrasaite 和 Deepak Ramachandran。2023年。[BoardgameQA: 一个包含矛盾信息的自然语言推理数据集](https://openreview.net/forum?id=BR1m3JIoKm)。在
    *第37届神经信息处理系统大会数据集和基准跟踪*，第1–23页。'
- en: 'Khandelwal et al. (2018) Urvashi Khandelwal, He He, Peng Qi, and Dan Jurafsky.
    2018. [Sharp nearby, fuzzy far away: How neural language models use context](https://doi.org/10.18653/v1/P18-1027).
    In *Proceedings of the 56th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 284–294, Melbourne, Australia. Association
    for Computational Linguistics.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khandelwal 等人（2018）Urvashi Khandelwal、He He、Peng Qi 和 Dan Jurafsky。2018年。[近处锐利，远处模糊：神经语言模型如何使用上下文](https://doi.org/10.18653/v1/P18-1027)。在
    *第56届计算语言学协会年会论文集（第1卷：长篇论文）*，第284–294页，澳大利亚墨尔本。计算语言学协会。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 35, pages 22199–22213\.
    Curran Associates, Inc.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）Takeshi Kojima、Shixiang（Shane）Gu、Machel Reid、Yutaka Matsuo 和
    Yusuke Iwasawa。2022年。[大型语言模型是零-shot 推理者](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)。在
    *《神经信息处理系统进展》*，第35卷，第22199–22213页。Curran Associates, Inc.
- en: Lanham et al. (2023) Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner,
    Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson
    Kernion, et al. 2023. [Measuring faithfulness in chain-of-thought reasoning](https://arxiv.org/abs/2307.13702).
    *arXiv preprint arXiv:2307.13702*.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lanham 等人（2023）Tamera Lanham、Anna Chen、Ansh Radhakrishnan、Benoit Steiner、Carson
    Denison、Danny Hernandez、Dustin Li、Esin Durmus、Evan Hubinger、Jackson Kernion 等。2023年。[测量链式思维推理中的忠诚度](https://arxiv.org/abs/2307.13702)。*arXiv
    预印本 arXiv:2307.13702*。
- en: Liu et al. (2023a) Hanmeng Liu, Jian Liu, Leyang Cui, Zhiyang Teng, Nan Duan,
    Ming Zhou, and Yue Zhang. 2023a. [Logiqa 2.0—an improved dataset for logical reasoning
    in natural language understanding](https://doi.org/10.1109/TASLP.2023.3293046).
    *IEEE/ACM Transactions on Audio, Speech, and Language Processing*, 31:2947–2962.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023a）韩梦 Liu、Jian Liu、Leyang Cui、Zhiyang Teng、Nan Duan、Ming Zhou 和 Yue
    Zhang。2023a。[Logiqa 2.0——改进的自然语言理解逻辑推理数据集](https://doi.org/10.1109/TASLP.2023.3293046)。*IEEE/ACM
    音频、语音与语言处理学报*，31:2947–2962。
- en: 'Liu et al. (2022a) Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean
    Welleck, Hannaneh Hajishirzi, and Yejin Choi. 2022a. [Rainier: Reinforced knowledge
    introspector for commonsense question answering](https://doi.org/10.18653/v1/2022.emnlp-main.611).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing*, pages 8938–8958, Abu Dhabi, United Arab Emirates. Association for
    Computational Linguistics.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2022a）贾成 Liu、Skyler Hallinan、Ximing Lu、Pengfei He、Sean Welleck、Hannaneh
    Hajishirzi 和 Yejin Choi。2022a。[Rainier：用于常识问答的强化知识内省器](https://doi.org/10.18653/v1/2022.emnlp-main.611)。在
    *2022 年自然语言处理实证方法会议论文集*，第 8938–8958 页，阿布扎比，阿联酋。计算语言学协会。
- en: 'Liu et al. (2022b) Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter
    West, Ronan Le Bras, Yejin Choi, and Hannaneh Hajishirzi. 2022b. [Generated knowledge
    prompting for commonsense reasoning](https://doi.org/10.18653/v1/2022.acl-long.225).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 3154–3169, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2022b）贾成 Liu、Alisa Liu、Ximing Lu、Sean Welleck、Peter West、Ronan Le Bras、Yejin
    Choi 和 Hannaneh Hajishirzi。2022b。[生成的知识提示用于常识推理](https://doi.org/10.18653/v1/2022.acl-long.225)。在
    *第 60 届计算语言学协会年会（卷 1：长篇论文）*，第 3154–3169 页，爱尔兰都柏林。计算语言学协会。
- en: 'Liu et al. (2020) Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang,
    and Yue Zhang. 2020. [Logiqa: A challenge dataset for machine reading comprehension
    with logical reasoning](https://doi.org/10.24963/ijcai.2020/501). In *Proceedings
    of the Twenty-Ninth International Joint Conference on Artificial Intelligence,
    IJCAI-20*, pages 3622–3628\. International Joint Conferences on Artificial Intelligence
    Organization. Main track.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2020）简 Liu、Leyang Cui、韩梦 Liu、Dandan Huang、Yile Wang 和 Yue Zhang。2020。[Logiqa：一个针对逻辑推理的机器阅读理解挑战数据集](https://doi.org/10.24963/ijcai.2020/501)。在
    *第二十九届国际人工智能联合会议 IJCAI-20 论文集*，第 3622–3628 页。国际人工智能联合会议组织。主要轨道。
- en: 'Liu et al. (2023b) Xiao Liu, Da Yin, Chen Zhang, Yansong Feng, and Dongyan
    Zhao. 2023b. [The magic of IF: Investigating causal reasoning abilities in large
    language models of code](https://doi.org/10.18653/v1/2023.findings-acl.574). In
    *Findings of the Association for Computational Linguistics: ACL 2023*, pages 9009–9022,
    Toronto, Canada. Association for Computational Linguistics.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023b）肖 Liu、Da Yin、Chen Zhang、Yansong Feng 和 Dongyan Zhao。2023b。[IF 的魔力：探究大型语言模型在代码中的因果推理能力](https://doi.org/10.18653/v1/2023.findings-acl.574)。在
    *计算语言学协会年会论文集：ACL 2023*，第 9009–9022 页，加拿大多伦多。计算语言学协会。
- en: Lyu et al. (2023) Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao,
    Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023. [Faithful chain-of-thought
    reasoning](https://arxiv.org/abs/2301.13379). *arXiv preprint arXiv:2301.13379*.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lyu 等人（2023）青吕、Shreya Havaldar、Adam Stein、李张、Delip Rao、Eric Wong、Marianna Apidianaki
    和 Chris Callison-Burch。2023。[忠实的思维链推理](https://arxiv.org/abs/2301.13379)。*arXiv
    预印本 arXiv:2301.13379*。
- en: Madaan et al. (2022) Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, and Graham
    Neubig. 2022. [Language models of code are few-shot commonsense learners](https://doi.org/10.18653/v1/2022.emnlp-main.90).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing*, pages 1384–1403, Abu Dhabi, United Arab Emirates. Association for
    Computational Linguistics.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madaan 等人（2022）Aman Madaan、Shuyan Zhou、Uri Alon、Yiming Yang 和 Graham Neubig。2022。[代码语言模型是少量样本常识学习者](https://doi.org/10.18653/v1/2022.emnlp-main.90)。在
    *2022 年自然语言处理实证方法会议论文集*，第 1384–1403 页，阿布扎比，阿联酋。计算语言学协会。
- en: 'Min et al. (2023) Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau
    Yih, Pang Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023. [FActScore:
    Fine-grained atomic evaluation of factual precision in long form text generation](https://doi.org/10.18653/v1/2023.emnlp-main.741).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 12076–12100, Singapore. Association for Computational Linguistics.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Min 等（2023）Sewon Min、Kalpesh Krishna、Xinxi Lyu、Mike Lewis、Wen-tau Yih、Pang
    Koh、Mohit Iyyer、Luke Zettlemoyer 和 Hannaneh Hajishirzi. 2023. [FActScore: 长文本生成中的事实精确度细粒度原子评估](https://doi.org/10.18653/v1/2023.emnlp-main.741)。在
    *2023年自然语言处理实证方法会议论文集*，第12076–12100页，新加坡。计算语言学协会。'
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](https://arxiv.org/pdf/2303.08774.pdf).
    *arXiv preprint arXiv:2303.08774*.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023）OpenAI. 2023. [GPT-4技术报告](https://arxiv.org/pdf/2303.08774.pdf)。*arXiv预印本
    arXiv:2303.08774*。
- en: 'Pan et al. (2023) Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan Luu, William Yang
    Wang, Min-Yen Kan, and Preslav Nakov. 2023. [Fact-checking complex claims with
    program-guided reasoning](https://doi.org/10.18653/v1/2023.acl-long.386). In *Proceedings
    of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 6981–7004, Toronto, Canada. Association for Computational
    Linguistics.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 等（2023）Liangming Pan、Xiaobao Wu、Xinyuan Lu、Anh Tuan Luu、William Yang Wang、Min-Yen
    Kan 和 Preslav Nakov. 2023. [使用程序引导推理对复杂主张进行事实检查](https://doi.org/10.18653/v1/2023.acl-long.386)。在
    *第61届计算语言学协会年会（第1卷：长篇论文）论文集*，第6981–7004页，多伦多，加拿大。计算语言学协会。
- en: 'Patel et al. (2021) Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021.
    [Are NLP models really able to solve simple math word problems?](https://doi.org/10.18653/v1/2021.naacl-main.168)
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 2080–2094,
    Online. Association for Computational Linguistics.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Patel 等（2021）Arkil Patel、Satwik Bhattamishra 和 Navin Goyal. 2021. [NLP模型真的能解决简单的数学题吗？](https://doi.org/10.18653/v1/2021.naacl-main.168)。在
    *2021年北美计算语言学协会会议：人类语言技术论文集*，第2080–2094页，在线。计算语言学协会。
- en: Saeidi et al. (2018) Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh,
    Tim Rocktäschel, Mike Sheldon, Guillaume Bouchard, and Sebastian Riedel. 2018.
    [Interpretation of natural language rules in conversational machine reading](https://doi.org/10.18653/v1/D18-1233).
    In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language
    Processing*, pages 2087–2097, Brussels, Belgium. Association for Computational
    Linguistics.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saeidi 等（2018）Marzieh Saeidi、Max Bartolo、Patrick Lewis、Sameer Singh、Tim Rocktäschel、Mike
    Sheldon、Guillaume Bouchard 和 Sebastian Riedel. 2018. [会话机器阅读中的自然语言规则解释](https://doi.org/10.18653/v1/D18-1233)。在
    *2018年自然语言处理实证方法会议论文集*，第2087–2097页，布鲁塞尔，比利时。计算语言学协会。
- en: 'Sinha et al. (2019) Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau,
    and William L. Hamilton. 2019. [CLUTRR: A diagnostic benchmark for inductive reasoning
    from text](https://doi.org/10.18653/v1/D19-1458). In *Proceedings of the 2019
    Conference on Empirical Methods in Natural Language Processing and the 9th International
    Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*, pages 4506–4515,
    Hong Kong, China. Association for Computational Linguistics.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sinha 等（2019）Koustuv Sinha、Shagun Sodhani、Jin Dong、Joelle Pineau 和 William
    L. Hamilton. 2019. [CLUTRR: 从文本中进行归纳推理的诊断基准](https://doi.org/10.18653/v1/D19-1458)。在
    *2019年自然语言处理实证方法会议暨第九届国际自然语言处理联合会议（EMNLP-IJCNLP）论文集*，第4506–4515页，香港，中国。计算语言学协会。'
- en: 'Sun et al. (2022) Haitian Sun, William Cohen, and Ruslan Salakhutdinov. 2022.
    [ConditionalQA: A complex reading comprehension dataset with conditional answers](https://doi.org/10.18653/v1/2022.acl-long.253).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 3627–3637, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sun 等（2022）Haitian Sun、William Cohen 和 Ruslan Salakhutdinov. 2022. [ConditionalQA:
    具有条件答案的复杂阅读理解数据集](https://doi.org/10.18653/v1/2022.acl-long.253)。在 *第60届计算语言学协会年会（第1卷：长篇论文）论文集*，第3627–3637页，都柏林，爱尔兰。计算语言学协会。'
- en: Sun et al. (2021) Simeng Sun, Kalpesh Krishna, Andrew Mattarella-Micke, and
    Mohit Iyyer. 2021. [Do long-range language models actually use long-range context?](https://doi.org/10.18653/v1/2021.emnlp-main.62)
    In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing*, pages 807–822, Online and Punta Cana, Dominican Republic. Association
    for Computational Linguistics.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等（2021）Simeng Sun, Kalpesh Krishna, Andrew Mattarella-Micke, 和 Mohit Iyyer.
    2021. [Do long-range language models actually use long-range context?](https://doi.org/10.18653/v1/2021.emnlp-main.62)
    在 *Proceedings of the 2021 Conference on Empirical Methods in Natural Language
    Processing*，第 807–822 页，在线和多米尼加共和国蓬塔卡纳。计算语言学协会。
- en: 'Wang et al. (2023) Wenya Wang, Vivek Srikumar, Hannaneh Hajishirzi, and Noah A.
    Smith. 2023. [Elaboration-generating commonsense question answering at scale](https://doi.org/10.18653/v1/2023.acl-long.90).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 1619–1635, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等（2023）Wenya Wang, Vivek Srikumar, Hannaneh Hajishirzi, 和 Noah A. Smith.
    2023. [Elaboration-generating commonsense question answering at scale](https://doi.org/10.18653/v1/2023.acl-long.90)。在
    *Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics
    (Volume 1: Long Papers)*，第 1619–1635 页，加拿大多伦多。计算语言学协会。'
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian
    ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. [Chain-of-thought prompting
    elicits reasoning in large language models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 35, pages 24824–24837\.
    Curran Associates, Inc.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022）Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter,
    Fei Xia, Ed Chi, Quoc V Le, 和 Denny Zhou. 2022. [Chain-of-thought prompting elicits
    reasoning in large language models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)。在
    *Advances in Neural Information Processing Systems*，第 35 卷，第 24824–24837 页。Curran
    Associates, Inc.
- en: 'Ye et al. (2023) Xi Ye, Qiaochu Chen, Isil Dillig, and Greg Durrett. 2023.
    [Satlm: Satisfiability-aided language models using declarative prompting](https://openreview.net/pdf?id=TqW5PL1Poi).
    In *Proceedings of NeurIPS*, pages 1–33.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ye 等（2023）Xi Ye, Qiaochu Chen, Isil Dillig, 和 Greg Durrett. 2023. [Satlm: Satisfiability-aided
    language models using declarative prompting](https://openreview.net/pdf?id=TqW5PL1Poi)。在
    *Proceedings of NeurIPS*，第 1–33 页。'
- en: Appendix A Datasets
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 数据集
- en: In ConditionalQA, we use an oracle retriever to retrieve the relevant passages
    to the question. This retriever is based on the sentences annotated as evidence
    for the answer (i.e., rationales). We concatenate all sections that include one
    rationale and use the resulting passage as input document.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ConditionalQA 中，我们使用一个 oracle 检索器来检索与问题相关的段落。这个检索器基于标注为答案证据的句子（即，推理依据）。我们将包含一个推理依据的所有部分串联起来，并将生成的段落用作输入文档。
- en: The sizes of all the datasets used in this work are provided in [Table 5](#A1.T5
    "In Appendix A Datasets ‣ Code Prompting Elicits Conditional Reasoning Abilities
    in Text+Code LLMs").
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作中使用的所有数据集的大小见 [表 5](#A1.T5 "在附录 A 数据集 ‣ 代码提示引发条件推理能力的文本+代码 LLMs")。
- en: '| Dataset | Training Size | Dev Size |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 训练大小 | 开发大小 |'
- en: '| --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| CondQA | 2338 | 285 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| CondQA | 2338 | 285 |'
- en: '| BGQA-1 | 1000 | 500 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| BGQA-1 | 1000 | 500 |'
- en: '| BGQA-2 | 1000 | 500 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| BGQA-2 | 1000 | 500 |'
- en: '| BGQA-3 | 1000 | 500 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| BGQA-3 | 1000 | 500 |'
- en: 'Table 5: Sizes of the datasets.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：数据集的大小。
- en: Appendix B Prompt Formulation
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 提示制定
- en: CONDQA.
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: CONDQA。
- en: 'Firstly, we define the different components of a data point: scenario ($S$
    is defined as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义数据点的不同组件：场景（$S$ 定义如下：
- en: '|  | $\begin{split}tp=\text{&quot;Question:&quot;}+S+Q+\text{&quot;Document:&quot;}+D\\
    +\text{&quot;Let''s think step by step&quot;}\end{split}$ |  | (1) |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}tp=\text{&quot;Question:&quot;}+S+Q+\text{&quot;Document:&quot;}+D\\
    +\text{&quot;Let''s think step by step&quot;}\end{split}$ |  | (1) |'
- en: 'where $+$ is:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $+$ 是：
- en: '|  | $to=R+\text{&quot;Answer:&quot;}+A$ |  | (2) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  | $to=R+\text{&quot;Answer:&quot;}+A$ |  | (2) |'
- en: 'For code prompts, we first define a function ${C:\mathbb{NL}\rightarrow\mathbb{C}}$
    as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码提示，我们首先定义一个函数 ${C:\mathbb{NL}\rightarrow\mathbb{C}}$ 如下：
- en: '|  | $$\begin{split}cp=\text{&quot;\#Question:&quot;}+C(S)+C(Q)+\\ \text{&quot;\#Document:&quot;}+C(D)\\'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\begin{split}cp=\text{&quot;\#Question:&quot;}+C(S)+C(Q)+\\ \text{&quot;\#Document:&quot;}+C(D)\\'
- en: +\text{&quot;\#Let's think step by step&quot;}\end{split}$$ |  | (3) |
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: +\text{&quot;\#我们一步步思考&quot;}\end{split}$$ |  | (3) |
- en: 'Similarly, we define the output format, $co$, as:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将输出格式 $co$ 定义为：
- en: '|  | $co=R+\text{&quot;\#Answer:&quot;}+A$ |  | (4) |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|  | $co=R+\text{&quot;\#Answer:&quot;}+A$ |  | (4) |'
- en: BGQA.
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: BGQA。
- en: 'Firstly, we define the components of a data point in this dataset: facts ($F$).
    Therefore, our text prompt is defined as follows⁴⁴4BGQA provides a field example
    with all the variables of the dataset concatenated with descriptions. We use this
    field as text prompt.:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义此数据集中的数据点组件：事实（$F$）。因此，我们的文本提示定义如下⁴⁴4BGQA提供了一个现场示例，其中包含数据集的所有变量和描述。我们使用该字段作为文本提示。：
- en: '|  | $\begin{split}tp=F+R+Q\end{split}$ |  | (5) |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}tp=F+R+Q\end{split}$ |  | (5) |'
- en: This dataset also provides the CoT that leads to the answer. Therefore, we use
    that CoT as the expected output.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集还提供了导致答案的CoT。因此，我们将该CoT用作期望输出。
- en: 'For code prompts, we follow the same approach as with the previous dataset.
    We define code prompts, $cp$, as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码提示，我们遵循与之前数据集相同的方法。我们将代码提示（$cp$）定义如下：
- en: '|  | $tp=C(F)+C(R)+C(Q)$ |  | (6) |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | $tp=C(F)+C(R)+C(Q)$ |  | (6) |'
- en: 'with the output format ($co$) being:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 输出格式（$co$）为：
- en: '|  | $co=C(cot)$ |  | (7) |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | $co=C(cot)$ |  | (7) |'
- en: Appendix C Costs
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 成本
- en: Running a data instance from ConditionalQA with code prompts costs $0.04 while
    with text prompts $0.01\. On BoardgameQA-depth 3 (i.e., the partition with the
    most expensive prompts), the costs per question are $0.02 and $0.03 for text and
    code prompts, respectively.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 从ConditionalQA中运行一个数据实例，使用代码提示的费用为$0.04，而使用文本提示的费用为$0.01。在BoardgameQA-depth
    3（即最昂贵的提示分区）中，每个问题的费用分别为文本提示$0.02和代码提示$0.03。
- en: Appendix D Atomic Statements
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 原子陈述
- en: 'Original sentence: Applying for the legal right to deal with someone’s property,
    money and possessions (their estate) when they die is called applying for probate.
    Atomic statements: Applying for the legal right is a process. The process is called
    ’applying for probate’. The legal right is to deal with someone’s property, money,
    and possessions. The someone is a person who has died. The property, money, and
    possessions are collectively called the ’estate’.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 原句：申请处理某人的财产、金钱和财物（他们的遗产）的法定权利被称为申请遗嘱认证。 原子陈述：申请法定权利是一个过程。该过程称为‘申请遗嘱认证’。法定权利是处理某人的财产、金钱和财物。某人是一个已经去世的人。财产、金钱和财物统称为‘遗产’。
- en: Appendix E Examples of Code Ablations
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 代码切除示例
- en: An example of a back-translated code into natural language is provided in [Table 6](#A6.T6
    "In Prompt Probes. ‣ Appendix F Variable Tracking Setup ‣ Code Prompting Elicits
    Conditional Reasoning Abilities in Text+Code LLMs"). We can observe in both examples
    that the resulting natural language (NL) text is extremely similar to the original
    code. In addition, in the second example (BGQA), Rule2 is much simpler after the
    back-translation than its original description in NL.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[表6](#A6.T6 "在提示探测中。 ‣ 附录F 变量跟踪设置 ‣ 代码提示引发文本+代码LLMs中的条件推理能力")中提供了一个反向翻译的代码示例。我们可以在两个示例中观察到，得到的自然语言（NL）文本与原始代码非常相似。此外，在第二个示例（BGQA）中，Rule2在反向翻译后比其原始NL描述要简单得多。'
- en: '[Table 7](#A6.T7 "In Prompt Probes. ‣ Appendix F Variable Tracking Setup ‣
    Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs") shows
    examples of the multiple code ablations we conducted in [Section 5.3](#S5.SS3
    "5.3 Code Semantic is Important ‣ 5 Experiments ‣ Code Prompting Elicits Conditional
    Reasoning Abilities in Text+Code LLMs"). Random code replaces the code with a
    piece of code from another data point. In this way, the semantics of the text
    and code mismatch while we keep the code syntactically correct.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[表7](#A6.T7 "在提示探测中。 ‣ 附录F 变量跟踪设置 ‣ 代码提示引发文本+代码LLMs中的条件推理能力")显示了我们在[第5.3节](#S5.SS3
    "5.3 代码语义很重要 ‣ 5 实验 ‣ 代码提示引发文本+代码LLMs中的条件推理能力")进行的多次代码切除示例。随机代码将代码替换为来自另一个数据点的一段代码。通过这种方式，文本和代码的语义不匹配，同时我们保持代码语法正确。'
- en: Appendix F Variable Tracking Setup
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录F 变量跟踪设置
- en: Extracting key entities in BoardgameQA.
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在BoardgameQA中提取关键实体。
- en: This dataset provides a list of “facts,” which are short and concise sentences
    describing the state of a key entity. Therefore, we use them without alterations
    as the key entities to ask for.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集提供了一系列“事实”，这些事实是描述关键实体状态的简短而简洁的句子。因此，我们不做修改地使用它们作为要询问的关键实体。
- en: Extracting key entities in ConditionalQA.
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在ConditionalQA中提取关键实体。
- en: This dataset provides a scenario describing the background information of the
    person posing the answer. Since this scenario is a free-form text, we follow (Min
    et al., [2023](#bib.bib19)) to extract atomic statements and use them as the key
    entities to ask for.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集提供了一个场景，描述了回答者的背景信息。由于这个场景是自由格式文本，我们遵循 (Min et al., [2023](#bib.bib19))
    提取原子陈述，并将其作为询问的关键实体。
- en: Code Prompting variables
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码提示变量
- en: . To probe the variable tracking abilities of code prompts, we use the variables
    defined in the “facts” and “scenario” of BoardgameQA and ConditionalQA, respectively.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探测代码提示的变量跟踪能力，我们使用 BoardgameQA 和 ConditionalQA 中分别定义的“facts”和“scenario”中的变量。
- en: Probing memory at different steps in the Chain-of-Thought.
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在链式思维的不同步骤中探测记忆。
- en: Inspired by Lanham et al. ([2023](#bib.bib11)), we truncate the Chain-of-Thought
    (CoT) at different completion states and probe the memory of the model. To break
    down the CoT, we split it by the character “\n”, which usually represents the
    end of a reasoning step. This is possible because our in-context learning demonstrations
    follow this format.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 受 Lanham et al. ([2023](#bib.bib11)) 的启发，我们在不同的完成状态下截断链式思维（CoT），并探测模型的记忆。为了分解
    CoT，我们通过字符“\n”进行分割，这通常表示推理步骤的结束。这是可能的，因为我们的上下文学习演示遵循这种格式。
- en: Number of probes.
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 探测次数。
- en: For each dataset instance, we run $num\_facts\times num_{s}teps_{c}ot$ probes)
    because of the cost of the experiment. Due to the length of the demonstrations
    of ConditionalQA and its impact on the costs, we sample five facts and three partial
    CoTs for each instance, yielding an upper-bound of 15 probes per instance, and
    run the probes for 30 instances for each dataset partition (i.e., correct and
    incorrect instances).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数据集实例，我们运行 $num\_facts\times num_{s}teps_{c}ot$ 次探测，这是因为实验的成本。由于 ConditionalQA
    演示的长度及其对成本的影响，我们为每个实例抽取五个事实和三个部分 CoT，得出每个实例的最大探测次数为 15 次，并对每个数据集分区（即正确和错误实例）运行
    30 个实例的探测。
- en: Prompt Probes.
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示探测。
- en: 'In all cases, we follow the following format: Sys. Prompt; ICL Demonstrations;
    Input Instance; Partial CoT; Probe.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，我们遵循以下格式：系统提示；ICL 演示；输入实例；部分 CoT；探测。
- en: 'The probe for text and code prompts in BoardgameQA is: “Now, I want to ask
    you about the value of some key entities you used. Your answers must be ‘yes‘,
    ‘no‘, or ‘unknown‘. It is very important that you only write one word. Is it true
    that {fact}?”'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: BoardgameQA 中文本和代码提示的探测是：“现在，我想询问你所使用的一些关键实体的值。你的回答必须是‘yes’，‘no’，或‘unknown’。非常重要的是，你只写一个词。{fact}
    是否为真？”
- en: 'The probe for text prompts in ConditionalQA is: “Now, I want to ask you about
    the value of some key entities you used. Your answers must be “True”, “False”,
    “unknown”, or a string. It is very important that you only write the exact value.
    From the speaker perspective, is it true that {fact}?”'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ConditionalQA 中文本提示的探测是：“现在，我想询问你所使用的一些关键实体的值。你的回答必须是‘True’，‘False’，‘unknown’
    或一个字符串。非常重要的是，你只写出准确的值。从说话者的角度来看，{fact} 是否为真？”
- en: 'The probe for code prompts in ConditionalQA is: “Now, I want to ask you about
    the value of some key entities you used. Your answers must be “True”, “False”,
    “unknown”, or a string. It is very important that you only write the exact value.
    What is the value of the variable {var}?” A real example is provided in [Table 8](#A6.T8
    "In Prompt Probes. ‣ Appendix F Variable Tracking Setup ‣ Code Prompting Elicits
    Conditional Reasoning Abilities in Text+Code LLMs").'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ConditionalQA 中代码提示的探测是：“现在，我想询问你所使用的一些关键实体的值。你的回答必须是‘True’，‘False’，‘unknown’
    或一个字符串。非常重要的是，你只写出准确的值。变量 {var} 的值是多少？” 一个实际的例子见 [表 8](#A6.T8 "在提示探测中。 ‣ 附录 F
    变量跟踪设置 ‣ 代码提示引发文本+代码 LLM 的条件推理能力")。
- en: '| Type | Text |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 文本 |'
- en: '| --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Code | # You can apply to become the estate’s administrator if you are
    18 or over and you are the most ‘entitled’ inheritor of the deceased’s estate.
    This is usually the deceased’s closest living relative. if applicant_age >=
    18 and entitled_inheritor and closest_relative: can_apply_estate_administrator
    = True |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | # 如果你年满 18 岁或以上，并且你是死者遗产的最“有权”继承人，你可以申请成为遗产管理人。通常这是死者的最近亲属。 如果
    applicant_age >= 18 且 entitled_inheritor 和 closest_relative: can_apply_estate_administrator
    = True |'
- en: '| Code $\rightarrow$ NL | You can apply to become the estate’s administrator
    if you are 18 or over and you are the most ‘entitled’ inheritor of the deceased’s
    estate. This is usually the deceased’s closest living relative. if you are
    18 or over and you are the most entitled inheritor of the deceased’s estate and
    you are the closest living relative, you can apply to become the estate’s administrator
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 代码 $\rightarrow$ NL | 如果您年满18岁或以上，并且是已故遗产的最有权利的继承人，您可以申请成为遗产的管理员。这通常是已故的最近亲属。
    如果您年满18岁或以上，并且是已故遗产的最有权利的继承人，且您是最近的亲属，您可以申请成为遗产的管理员 |'
- en: '| Code | # Rule2: Be careful when something removes from the board one of the
    pieces of the dog and also becomes an enemy of the catfish because in this case
    it will surely not burn the warehouse of the mosquito (this may or may not be
    problematic) rule2(something) = remove(something, piece_of(dog)) & enemy(something,
    catfish) => not burn(something, warehouse_of(mosquito)) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 代码 | # 规则2：当某物从棋盘上移除一只狗的棋子并且同时成为鲶鱼的敌人时要小心，因为在这种情况下，它肯定不会烧毁蚊子的仓库（这可能会或可能不会有问题）
    rule2(something) = remove(something, piece_of(dog)) & enemy(something, catfish)
    => not burn(something, warehouse_of(mosquito)) |'
- en: '| Code $\rightarrow$ NL | Rule2: If something removes from the board one of
    the pieces of the dog and also becomes an enemy of the catfish, then it does not
    burn the warehouse of the mosquito |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 代码 $\rightarrow$ NL | 规则2：如果某物从棋盘上移除一只狗的棋子，并且同时成为了鲶鱼的敌人，那么它不会烧毁蚊子的仓库 |'
- en: 'Table 6: Example of a back-translation ${\mathbb{NL}\rightarrow\mathbb{C}}$
    in ConditionalQA and BGQA-3\. Text in bold represents the main modification.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：ConditionalQA和BGQA-3中回译的示例 ${\mathbb{NL}\rightarrow\mathbb{C}}$。粗体文本代表主要修改。
- en: '| Type | Text |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 文本 |'
- en: '| --- | --- |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Original Code | # To be eligible you must have left your country and be
    unable to go back because you fear persecution. if left_country_and_fear_persecution:
    eligible_for_asylum = True |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 原始代码 | # 要符合资格，您必须离开您的国家，并且因为害怕迫害而无法返回。 如果 left_country_and_fear_persecution:
    eligible_for_asylum = True |'
- en: '| Anonymous Code | # To be eligible you must have left your country and
    be unable to go back because you fear persecution. if var_1 var_2 = True |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 匿名代码 | # 要符合资格，您必须离开您的国家，并且因为害怕迫害而无法返回。 如果 var_1 var_2 = True |'
- en: '| Random Code | # To be eligible you must have left your country and be
    unable to go back because you fear persecution. if value_of_property_gone_down_by_more_than_50:
    eligible_to_claim = True getting_housing_benefit = True |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 随机代码 | # 要符合资格，您必须离开您的国家，并且因为害怕迫害而无法返回。 如果 value_of_property_gone_down_by_more_than_50:
    eligible_to_claim = True getting_housing_benefit = True |'
- en: 'Table 7: Examples code ablations.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：代码消融示例。
- en: '| Section | Role | Message |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 部门 | 角色 | 信息 |'
- en: '| --- | --- | --- |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Problem instance | Human | Question: My brother and his wife are in prison
    for carrying out a large fraud scheme. Their 7 and 8 year old children have been
    living with me for the last 4 years. I want to become their Special Guardian to
    look after them permanently. How long will it be before I hear back from the court?
    Document: What is a special guardian You can apply to be a child’s
    special guardian when they cannot live with their birth parents and adoption is
    not right for them. … Answers can be "yes" or "no". Let’s think step by step:
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 问题实例 | 人类 | 问题：我的兄弟和他的妻子因实施大规模欺诈计划而入狱。他们7岁和8岁的孩子在过去4年里一直与我同住。我想成为他们的特别监护人，永久照顾他们。我何时能收到法院的回复？文件：什么是特别监护人
    当孩子不能与亲生父母生活，并且收养对他们不合适时，您可以申请成为孩子的特别监护人。 … 答案可以是“是”或“否”。我们一步一步来思考： |'
- en: '| Partial CoT | AI | Within 10 days of receiving your application the court
    will send you a case number and a date for a meeting to set out:\n |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 部分 CoT | AI | 在收到您的申请后的10天内，法院会向您发送案件编号和一个日期，以便安排：\n |'
- en: '| Probe | Human | Now, I want to ask you about the value of some key entities
    you used. Your answers must be ‘True‘, ‘False‘, ‘unknown‘, or a string. It is
    very important that you only write the exact value. From the speaker perspective,
    is it true that the children have been living with me for the last 4 years? |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 探测 | 人类 | 现在，我想问你一些关键实体的值。你的回答必须是‘正确‘、‘错误‘、‘未知‘或一个字符串。非常重要的是，您只写准确的值。从发言人的角度来看，孩子们在过去4年里一直与我同住，这是真的吗？
    |'
- en: '| Probe | AI | True |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 探测 | AI | 正确 |'
- en: 'Table 8: Variable Tracking Example. Underlined text represents the variable
    to probe. Partial CoT is not the complete answer. The generation was stopped,
    and only the first step was used in this probe.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：变量跟踪示例。下划线文本表示需要探测的变量。部分 CoT 不是完整的答案。生成被停止了，只使用了这次探测中的第一步。
- en: Appendix G Prompt Examples
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G 提示示例
- en: '| System: You are a helpful assistant that answers questions given a document.
    Answers must be a short span of the document. You have to extract the span from
    the document. Do not write anything else. I will give you some examples first.
    ICL Demonstrations… Human: Question: My brother and his wife are in prison for
    carrying out a large fraud scheme. Their 7 and 8 year old children have been living
    with me for the last 4 years. I want to become their Special Guardian to look
    after them permanently. How long will it be before I hear back from the court?
    Document: What is a special guardian You can apply to be a child’s
    special guardian when they cannot live with their birth parents and adoption is
    not right for them. You’ll be responsible for looking after the child until
    they’re 18 (unless the court takes your responsibility away earlier). You’ll
    make all day to day decisions about the child, for example schooling and medical
    treatment. You do not have to discuss these decisions with the birth parents.
    You’ll need to get the consent of everyone who has parental responsibility
    for the child before you make some important decisions, for example: changing
    the child’s surname putting the child up for adoption taking
    the child abroad for more than 3 months the child having surgery for
    reasons other than improving health, such as circumcision, sterilisation or cosmetic
    surgery If you cannot get consent, you can ask the court to decide. Use
    the form ‘Make an application in existing court proceedings related to children’
    (form C2). After you apply Within 10 days of receiving your application
    the court will send you a case number and a date for a meeting to set out:
    a timetable for your case how it will be dealt with This
    meeting is called a ‘first directions hearing’. You must go to all hearings
    you’re told to unless the court excuses you. If you’re not able to go, contact
    the court office. Answers must be a short span of the document. You have to
    extract the span from the document. Do not write anything else. Let’s think step
    by step: |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 系统：你是一个有帮助的助手，根据文档回答问题。答案必须是文档的简短片段。你需要从文档中提取这段文字。不要写任何其他内容。我将首先给你一些示例。ICL
    演示…… 人类：问题：我的兄弟和他的妻子因为实施大规模诈骗计划而入狱。他们 7 岁和 8 岁的孩子在过去 4 年里一直和我生活。我想成为他们的特别监护人，永久照顾他们。我会在多久之后从法院那里得到回复？
    文档：什么是特别监护人 当孩子不能和亲生父母生活，并且收养不适合他们时，你可以申请成为孩子的特别监护人。 你将负责照顾孩子直到他们
    18 岁（除非法院提前取消你的责任）。 你将做出所有日常决策，例如学校和医疗治疗。你不需要与亲生父母讨论这些决策。 在做一些重要决策之前，你需要获得所有对孩子有父母责任的人的同意，例如：
    更改孩子的姓氏 让孩子接受收养 将孩子带出国超过 3 个月 孩子接受健康以外的手术，例如割礼、绝育或整形手术
    如果你不能获得同意，你可以请求法院作出决定。使用“在现有儿童案件中申请”表格（表格 C2）。 申请后 法院在收到你的申请后
    10 天内会向你发送案件编号和会议日期，以设定： 案件的时间表 如何处理 这次会议称为“第一次指示听证会”。
    除非法院免除你，否则你必须参加所有通知你的听证会。如果你不能去，联系法院办公室。 答案必须是文档的简短片段。你需要从文档中提取这段文字。不要写任何其他内容。让我们一步步来考虑：'
- en: 'Table 9: Text prompt Example for ConditionalQA'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：条件问答的文本提示示例
- en: '| System: You are a helpful assistant. Your task is to process a pseudo-code
    that describes a question and a document. You need to reason using that document
    and the comments to return the answers. Answers must be a short span of the document.
    You have to extract the span from the code comments. Do not write anything else.
    I will give you some examples first. ICL Demonstrations… Human: # Question: My
    brother and his wife are in prison for carrying out a large fraud scheme. Their
    7 and 8 year old children have been living with me for the last 4 years. I want
    to become their Special Guardian to look after them permanently. How long will
    it be before I hear back from the court? maximum_redundancy_pay = 16320 housing_standards_and_procedures_in_Northern_Ireland
    = True ensure_vehicle_taxed_in_UK = True immigration_advisers_can_help_with_representation_at_tribunal
    = True supply_protective_clothing_and_equipment = True CBT_required_for_moped_and_motorcycle
    = True court_response_time = None # This is the variable that answers the question
    # What is a special guardian # You can apply to be a child’s special
    guardian when they cannot live with their birth parents and adoption is not right
    for them. if attorneys_appointed_jointly: all_attorneys_must_agree_to_make_decision
    = True disability_or_severe_disability_element_of_working_tax_credit = True mugging_without_physical_harm_emergency
    = True # You’ll be responsible for looking after the child until they’re 18
    (unless the court takes your responsibility away earlier). work_temporarily_for_hirer
    = True # You’ll make all day to day decisions about the child, for example
    schooling and medical treatment. You do not have to discuss these decisions with
    the birth parents. accounts_and_tax_returns_cover_financial_year = "1 June
    to 31 May" employer_operating_PAYE = True # You’ll need to get the consent
    of everyone who has parental responsibility for the child before you make some
    important decisions, for example: # changing the child’s surname
    # putting the child up for adoption # taking the child abroad for
    more than 3 months # the child having surgery for reasons other than
    improving health, such as circumcision, sterilisation or cosmetic surgery
    managed_by_fit_and_proper_persons = True check_court_order_for_authorization =
    True considering_fostering = True if not_connected_to_mains_sewer: septic_tank_used
    = True can_claim_tax_relief_if_taxed_twice = True extra_support_for_disability
    = True if operator_of_septic_tank_or_treatment_plant: follow_general_binding_rules
    = True # If you cannot get consent, you can ask the court to decide. Use the
    form ‘Make an application in existing court proceedings related to children’ (form
    C2). appeals_decision_time = "several months" if worker and informal_resolution_not_satisfactory:
    formal_grievance_complaint_possible = True time_limit_for_backdating_claims_services
    = 6 # After you apply # Within 10 days of receiving your application
    the court will send you a case number and a date for a meeting to set out:
    # a timetable for your case # how it will be dealt with # This
    meeting is called a ‘first directions hearing’. committee_recommendations_go_to_Prime_Minister
    = True check_adviser_registration = True meet_manning_levels = True recognised_as_charity_or_CASC
    = True apply_for_visa_for_other_reasons = True debt_paid_off = True if special_educational_needs_and_disabilities:
    affects_behaviour_or_socialisation = True # You must go to all hearings you’re
    told to unless the court excuses you. If you’re not able to go, contact the court
    office. payslip_can_include_tax_code = True VAT_zero_rate = 0 gas_equipment_installed_and_maintained_by_Gas_Safe_registered_engineer
    = True # Question: My brother and his wife are in prison for carrying out a large
    fraud scheme. Their 7 and 8 year old children have been living with me for the
    last 4 years. I want to become their Special Guardian to look after them permanently.
    How long will it be before I hear back from the court? # Answers must be a short
    span of the document. You have to extract the span from the code comments. Do
    not write anything else. # Let’s think step by step: |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 系统：你是一个有帮助的助手。你的任务是处理描述问题和文档的伪代码。你需要根据文档和注释进行推理以返回答案。答案必须是文档的简短片段。你必须从代码注释中提取该片段。不要写其他内容。我将先给你一些示例。ICL
    演示…… 人类：# 问题：我的兄弟和他的妻子因为进行了一项大规模的欺诈计划而入狱。他们 7 岁和 8 岁的孩子在过去的 4 年里一直和我住在一起。我想成为他们的特别监护人，永久照顾他们。我什么时候能从法院那里得到回复？
    maximum_redundancy_pay = 16320 housing_standards_and_procedures_in_Northern_Ireland
    = True ensure_vehicle_taxed_in_UK = True immigration_advisers_can_help_with_representation_at_tribunal
    = True supply_protective_clothing_and_equipment = True CBT_required_for_moped_and_motorcycle
    = True court_response_time = None # 这是回答问题的变量 # 什么是特别监护人 # 当孩子不能与生父母生活，且收养不适合他们时，你可以申请成为特别监护人。
    if attorneys_appointed_jointly: all_attorneys_must_agree_to_make_decision = True
    disability_or_severe_disability_element_of_working_tax_credit = True mugging_without_physical_harm_emergency
    = True # 你将负责照顾孩子，直到他们 18 岁（除非法院提前撤销你的责任）。 work_temporarily_for_hirer =
    True # 你将做出所有关于孩子的日常决定，例如学校和医疗处理。你不需要与生父母讨论这些决定。 accounts_and_tax_returns_cover_financial_year
    = "6 月 1 日至 5 月 31 日" employer_operating_PAYE = True # 在做出一些重要决定之前，你需要获得所有有父母责任的人的同意，例如：
    # 更改孩子的姓氏 # 将孩子送去收养 # 将孩子带到国外超过 3 个月 # 孩子接受除改善健康外的手术，例如包皮环切术、绝育或整形手术
    managed_by_fit_and_proper_persons = True check_court_order_for_authorization =
    True considering_fostering = True if not_connected_to_mains_sewer: septic_tank_used
    = True can_claim_tax_relief_if_taxed_twice = True extra_support_for_disability
    = True if operator_of_septic_tank_or_treatment_plant: follow_general_binding_rules
    = True # 如果你无法获得同意，可以要求法院决定。使用表格“在现有儿童相关法院程序中申请”（表格 C2）。 appeals_decision_time
    = "几个月" if worker and informal_resolution_not_satisfactory: formal_grievance_complaint_possible
    = True time_limit_for_backdating_claims_services = 6 # 申请之后 # 在收到你的申请后的
    10 天内，法院将向你发送一个案件编号和一个会议日期，以确定： # 你的案件时间表 # 案件的处理方式 # 这个会议叫做“首次指示听证会”。
    committee_recommendations_go_to_Prime_Minister = True check_adviser_registration
    = True meet_manning_levels = True recognised_as_charity_or_CASC = True apply_for_visa_for_other_reasons
    = True debt_paid_off = True if special_educational_needs_and_disabilities: affects_behaviour_or_socialisation
    = True # 你必须参加所有法院要求你参加的听证会，除非法院允许你缺席。如果你无法参加，请联系法院办公室。 payslip_can_include_tax_code
    = True VAT_zero_rate = 0 gas_equipment_installed_and_maintained_by_Gas_Safe_registered_engineer
    = True # 问题：我的兄弟和他的妻子因为进行了一项大规模的欺诈计划而入狱。他们 7 岁和 8 岁的孩子在过去的 4 年里一直和我住在一起。我想成为他们的特别监护人，永久照顾他们。我什么时候能从法院那里得到回复？
    # 答案必须是文档的简短片段。你必须从代码注释中提取该片段。不要写其他内容。# 让我们一步步考虑： |'
- en: 'Table 10: Code Prompt Example for ConditionalQA'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：条件 QA 的代码提示示例
- en: '| System: You are a question-answering system that solves the problem of reasoning
    with contradictory information guided by preferences over sources of information.
    You must explain your answers step by step. ICL Demonstrations … Human: A few
    players are playing a boardgame The current state of the game is as follows The
    amberjack struggles to find food And the rules of the game are as follows Rule1:
    If the amberjack has difficulty to find food, then the amberjack removes from
    the board one of the pieces of the carp Based on the game state and the rules
    and preferences, does the amberjack remove from the board one of the pieces of
    the carp? AI: |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 系统：你是一个回答问题的系统，解决了根据信息来源的偏好推理矛盾信息的问题。你必须一步一步解释你的答案。ICL 演示 …… 人类：几个玩家正在玩棋盘游戏。游戏的当前状态如下：琵琶鱼在寻找食物方面遇到困难。游戏规则如下：规则1：如果琵琶鱼在寻找食物时遇到困难，那么琵琶鱼会从棋盘上移除一块鲤鱼的棋子。根据游戏状态、规则和偏好，琵琶鱼会从棋盘上移除一块鲤鱼的棋子吗？AI：
    |'
- en: 'Table 11: Text prompt Example for BGQA-1'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：BGQA-1 的文本提示示例
- en: '| System: You are a large language model of code that can interpret code. You
    are given a pseudo-code that resembles to first-order logic that models some scenario.
    You will be given a question and you have to answer it step by step. You can use
    a rule if and only if you know the antecedent of the rule. ICL Demonstrations
    Human: # A few players are playing a boardgame # The rules of the game are as
    follows # Rule1: If the amberjack has difficulty to find food, then the amberjack
    removes from the board one of the pieces of the carp. rule1() = difficulty_finding_food(amberjack)
    => remove_piece(amberjack, carp) # The current state of the game is as follows
    # The amberjack struggles to find food. difficulty_finding_food(amberjack) = True
    # Based on the game state and the rules and preferences, does the amberjack remove
    from the board one of the pieces of the carp? question = remove_piece(amberjack,
    carp) AI: |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 系统：你是一个可以解释代码的大型语言模型。你会得到一个类似于一阶逻辑的伪代码，这些伪代码模拟了某种场景。你将会得到一个问题，你必须一步一步回答。只有在你知道规则的前提时，你才可以使用规则。ICL
    演示 人类： # 几个玩家正在玩棋盘游戏 # 游戏规则如下 # 规则1：如果琵琶鱼在寻找食物时遇到困难，那么琵琶鱼会从棋盘上移除一块鲤鱼的棋子。 rule1()
    = difficulty_finding_food(琵琶鱼) => remove_piece(琵琶鱼, 鲤鱼) # 游戏的当前状态如下 # 琵琶鱼在寻找食物方面遇到困难。
    difficulty_finding_food(琵琶鱼) = True # 根据游戏状态、规则和偏好，琵琶鱼会从棋盘上移除一块鲤鱼的棋子吗？ question
    = remove_piece(琵琶鱼, 鲤鱼) AI： |'
- en: 'Table 12: Code prompt Example for BGQA-1'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 表 12：BGQA-1 的代码提示示例
