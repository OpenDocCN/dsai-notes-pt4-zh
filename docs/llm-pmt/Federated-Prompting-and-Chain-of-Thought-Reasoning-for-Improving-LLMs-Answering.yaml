- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:51:38'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:51:38'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦提示和思维链推理以提高LLMs回答的准确性
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2304.13911](https://ar5iv.labs.arxiv.org/html/2304.13911)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2304.13911](https://ar5iv.labs.arxiv.org/html/2304.13911)
- en: '¹¹institutetext: South China Normal University, Guangdong, China'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹institutetext: 南方科技大学，中国广东'
- en: '¹¹email: {2022024952,2022024954}@m.scnu.edu.cn, fanchenyou@scnu.edu.cnXiangyang
    Liu    Tianqi Pang    Chenyou Fan'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹email: {2022024952,2022024954}@m.scnu.edu.cn, fanchenyou@scnu.edu.cn    蔡翔阳
       庞天琪    范晨友'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: We investigate how to enhance answer precision in frequently asked questions
    posed by distributed users using cloud-based Large Language Models (LLMs). Our
    study focuses on a typical situations where users ask similar queries that involve
    identical mathematical reasoning steps and problem-solving procedures. Due to
    the unsatisfactory accuracy of LLMs’ zero-shot prompting with standalone questions,
    we propose to improve the distributed synonymous questions using Self-Consistency
    (SC) and Chain-of-Thought (CoT) techniques. Specifically, we first retrieve synonymous questions
    from a crowd-sourced database and create a federated question pool. We call these
    federated synonymous questions with the same or different parameters SP-questions
    or DP-questions, respectively. We refer to our methods as Fed-SP-SC and Fed-DP-CoT,
    which can generate significantly more accurate answers for all user queries without
    requiring sophisticated model-tuning. Through extensive experiments, we demonstrate
    that our proposed methods can significantly enhance question accuracy by fully
    exploring the synonymous nature of the questions and the consistency of the answers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了如何通过基于云的大型语言模型（LLMs）提升分布式用户提出的常见问题的回答准确性。我们的研究聚焦于用户提出的相似查询，这些查询涉及相同的数学推理步骤和问题解决程序。由于LLMs在独立问题上的零-shot
    提示准确性不尽如人意，我们提出使用自我一致性（SC）和思维链（CoT）技术来改进分布式同义问题。具体来说，我们首先从众包数据库中检索同义问题，并创建一个联邦问题池。我们将这些具有相同或不同参数的联邦同义问题分别称为SP-问题或DP-问题。我们将我们的方法称为Fed-SP-SC和Fed-DP-CoT，这些方法可以在不需要复杂模型调整的情况下，为所有用户查询生成显著更准确的答案。通过大量实验，我们展示了我们提出的方法通过充分探索问题的同义性质和答案的一致性，可以显著提高问题的准确性。
- en: 'Keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Synonymous Question-answering Federated Learning Large Language Model Prompt
    Learning Chain-of-Thought.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 同义问题回答 联邦学习 大型语言模型 提示学习 思维链。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/3ac7d5a88869d1abe904a699830c7fff.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3ac7d5a88869d1abe904a699830c7fff.png)'
- en: 'Figure 1: A general overview of our approach to dealing with federated synonymous
    question-answering. Our approach is categorized into two user scenarios: synonymous
    questions that share the same parameters, and those that have different parameters.
    When the parameters are the same, we utilize self-consistency to select the most
    commonly voted answer as the consistent response. However, for cases where the
    parameters are different, we amalgamate each question’s consistent answer to create
    a Chain-of-Thought, which makes it easier for the LLM to respond to new queries.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们处理联邦同义问题回答的总体概述。我们的方法分为两种用户场景：参数相同的同义问题和参数不同的同义问题。当参数相同时，我们利用自我一致性选择最常被投票的答案作为一致的响应。然而，对于参数不同的情况，我们将每个问题的一致答案合并以创建思维链，这使得LLM更容易回答新的查询。
- en: Recently, Large Language Models (LLMs) such as PaLM [[2](#bib.bib2)] and GPT
    family [[1](#bib.bib1), [13](#bib.bib13)] have revolutionized the methodology
    of tackling natural language processing (NLP) tasks such as sentiment analysis [[20](#bib.bib20)],
    question answering [[24](#bib.bib24)], text summarization [[23](#bib.bib23)],
    and reasoning on arithmetic and common sense questions [[25](#bib.bib25)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，像PaLM [[2](#bib.bib2)] 和GPT系列 [[1](#bib.bib1), [13](#bib.bib13)] 等大型语言模型（LLMs）彻底改变了处理自然语言处理（NLP）任务的方法，如情感分析
    [[20](#bib.bib20)]、问题回答 [[24](#bib.bib24)]、文本摘要 [[23](#bib.bib23)] 和对算术和常识问题的推理
    [[25](#bib.bib25)]。
- en: Large Language Models (LLMs) are highly over-parameterized with millions or
    billions of parameters, e.g., the GPT-3 model has about 175 Billion parameters.
    Due to this redundancy in model design, LLMs can represent language in a highly
    flexible and expressive manner by capturing the complex and structured patterns
    in human languages. In addition, LLMs can generate remarkably natural dialogues
    and accurate answers with contextual understanding, sometimes even surpassing
    human experts in certain tasks. For example, in arithmetic reasoning, GPT-4 achieved
    an accuracy rate of 92% on the GSM8K dataset [[12](#bib.bib12)]; in common sense
    reasoning, KEAR achieved an accuracy rate of 89.4% on the CSQA dataset [[22](#bib.bib22)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLM）参数过多，通常有数百万或数十亿个参数，例如，GPT-3模型大约有1750亿个参数。由于模型设计中的这种冗余，LLM能够以高度灵活和表达力强的方式表示语言，通过捕捉人类语言中的复杂和结构化模式。此外，LLM能够生成极为自然的对话和准确的回答，并具有上下文理解，有时在某些任务上甚至超越了人类专家。例如，在算术推理中，GPT-4在GSM8K数据集上的准确率达到了92%[[12](#bib.bib12)]；在常识推理中，KEAR在CSQA数据集上的准确率达到了89.4%[[22](#bib.bib22)]。
- en: We consider a practical user scenario in which a large number of users can access
    a cloud-deployed LLM for solving personal tasks from all places over the world.
    For example, more and more primary school students and their parents rely on the
    capability of LLMs for solving mathematical problems. The users often access a
    LLM and ask common realistic questions. For example, primary school children might
    ask “Chickens and rabbits are in the same cage, a total of 35 heads, 94 feet,
    how many chickens and rabbits are there?”, while computer science students often
    ask “How to write a QuickSort in Python?”.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑一个实际的用户场景，其中大量用户可以访问部署在云端的LLM，以解决来自全球各地的个人任务。例如，越来越多的小学生及其家长依赖LLM的能力来解决数学问题。用户通常会访问LLM并提出常见的现实问题。例如，小学生可能会问“鸡和兔子在同一个笼子里，总共有35个头，94只脚，鸡和兔子各有多少只？”，而计算机科学学生则常问“如何用Python编写QuickSort？”。
- en: Due to the complexity in task understanding and reasoning, the LLMs often return
    the wrong answers even given seemingly simple questions. For example, on the GSM8K
    dataset, the fine-tuned GPT-3 (175B) with verifier only achieves an accuracy of
    55.0%. Meanwhile, the PaLM-540B (Few-shot-CoT) only achieves an accuracy of 58.1%. [[8](#bib.bib8)]
    *How to improve the question answering accuracy has become a serious challenge
    which decides whether LLMs can be accepted as a robust and reliable part in realistic
    applications.*
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任务理解和推理的复杂性，即使面对看似简单的问题，LLM（大语言模型）也常常返回错误答案。例如，在GSM8K数据集上，经过微调的GPT-3（175B）仅能达到55.0%的准确率。同时，PaLM-540B（Few-shot-CoT）的准确率也仅为58.1%[[8](#bib.bib8)]。*如何提高问题回答的准确性已成为一个严重的挑战，这决定了LLM是否能被接受为现实应用中的一个可靠和稳健的部分。*
- en: One commonsense is that can we crowd-source many questions and aggregate those
    questions to better understand some common questions. A common question might
    be asked frequently as its variants in the concrete parameters or rephrased formulations.
    For example, the Chickens-and-rabbits questions can be asked with different number
    of heads and feet. Now we want to ask *Can we fully utilize those similar questions
    to improve the question answering of the LLMs without tuning the model parameters
    or infringing user privacy?*
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常识性的问题是，我们是否可以众包许多问题，并将这些问题聚合以更好地理解一些常见问题。一个常见的问题可能会以具体参数的不同变体或重新措辞的形式频繁出现。例如，鸡兔同笼的问题可以通过不同的头数和脚数来提问。现在我们想问*我们是否可以充分利用这些相似的问题来改善LLM的问题回答，而不需要调整模型参数或侵犯用户隐私？*
- en: Recent progressives in federated learning (FL) [[10](#bib.bib10)] have proved
    that utilizing distributed data sources can both preserve data privacy and enhance
    model training. In the FL paradigm, each client trains a local learning model
    with *own data*, while a central server regularly communicates with all agents
    to generate a better global model through the aggregation of the local models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，联邦学习（FL）的进展[[10](#bib.bib10)] 已证明，利用分布式数据源既能保护数据隐私，又能增强模型训练。在FL范式中，每个客户端使用*自己的数据*训练本地学习模型，而中央服务器则定期与所有代理进行通信，通过汇总本地模型来生成更好的全局模型。
- en: In this study, we consider improving the reasoning capacity of LLMs by better
    understanding crowd-sourced similar questions, from which we can explore the contextual
    information and improve the LLM answers substantially. Inspired by FL, we propose
    two typical scenarios when a user sends a QA request to the LLM and the LLM tries
    to answer with a collected question database.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们考虑通过更好地理解众包的类似问题来提高LLMs的推理能力，从中可以探索上下文信息，并显著改善LLM的回答。受到FL的启发，我们提出了两种典型场景：当用户向LLM发送QA请求时，LLM尝试使用收集的问题数据库来回答。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Synonymous Questions with Same Parameters (SP-questions). The cloud-deployed
    system retrieves from the database and finds several synonymous but rephrased
    questions with exactly the same parameters. For example,
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参数相同的同义问题（SP问题）。云部署系统从数据库中检索，并找到几个同义但措辞不同的问题，其参数完全相同。例如，
- en: '*Q1:“If a farmer has a certain number of chickens and rabbits in a barn, and
    there are a total of 32 heads and 100 feet, how many chickens and how many rabbits
    does the farmer have?”'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Q1：“如果一个农场主的谷仓里有一定数量的鸡和兔子，总共有32个头和100只脚，那么这个农场主有多少只鸡和兔子？”*'
- en: Q2:“In a barn, there are a certain number of chickens and rabbits that have
    a total of 32 heads and 100 feet. how many of each animal are in the barn?”*
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Q2：“在一个谷仓里，有一定数量的鸡和兔子，总共有32个头和100只脚。谷仓里各有多少只鸡和兔子？”*'
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Synonymous Questions with Different Parameters (DP-questions). This situation
    is harder as the question parameters mined in the database are different from
    each other. For example,
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参数不同的同义问题（DP问题）。这种情况更难，因为数据库中挖掘的问题参数彼此不同。例如，
- en: '*Q1:“If a farmer has a certain number of chickens and rabbits in a barn, and
    there are a total of 32 heads and 100 feet, how many chickens and how many rabbits
    does the farmer have?”'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Q1：“如果一个农场主的谷仓里有一定数量的鸡和兔子，总共有32个头和100只脚，那么这个农场主有多少只鸡和兔子？”*'
- en: Q2:“A farmer has a total of 20 chickens and rabbits in his barn. If the total
    number of legs in the barn is 56, how many chickens and how many rabbits are in
    the barn?”*
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Q2：“一个农场主的谷仓里总共有20只鸡和兔子。如果谷仓里总共有56只脚，那么谷仓里有多少只鸡和兔子？”*'
- en: For SP-questions, we propose to leverage LLMs to directly generate answers first.
    Then we federate the answers and apply the self-consistency [[19](#bib.bib19)]
    technique to obtain the most voted answer for all synonymous questions in the
    federation. We call this method Fed-SP-SC (Fed-SP with Self-Consistency).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SP问题，我们建议首先直接生成答案。然后我们联合这些答案，并应用自一致性[[19](#bib.bib19)]技术，以获得所有同义问题中票数最多的答案。我们称这种方法为Fed-SP-SC（Fed-SP与自一致性）。
- en: For DP-questions, we propose to leverage LLMs to generate consistent answers
    for each DP-questions first. Different from procedures of dealing SP-questions,
    we cannot directly agglomerate the answers since they are for different parameters.
    Instead, we federate them by forming the Chain-of-Thought (CoT) to provide hints
    to the LLMs. We append the original query to the CoT as the full prompt to obtain
    improved final answer. We call this technique Fed-DP-CoT.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于DP问题，我们建议首先利用LLMs生成每个DP问题的一致答案。与处理SP问题的程序不同，由于这些问题涉及不同的参数，我们不能直接聚合答案。相反，我们通过形成思维链（CoT）来联合它们，为LLMs提供提示。我们将原始查询附加到CoT中，作为完整的提示，以获得改进后的最终答案。我们称这种技术为Fed-DP-CoT。
- en: Once the LLM has finished generating the answer using either Fed-SP-SC or Fed-DP-CoT,
    the system will store both the questions and answers into the database. This enables
    the system to collect all records and leverage past records to produce re-fined
    answers to new queries. For questions that have been asked before with wrong answers,
    the system can evolve itself by correcting the answers with self-consistency mechanism
    or with more comprehensive CoT prompts.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦LLM使用Fed-SP-SC或Fed-DP-CoT生成了答案，系统将把问题和答案都存储到数据库中。这使得系统可以收集所有记录，并利用过去的记录为新查询生成更精确的答案。对于以前提问过但答案错误的问题，系统可以通过自一致性机制或更全面的CoT提示来纠正答案，从而使系统自我改进。
- en: We extensively evaluate our methods on the GSM8K and SVAMP datasets and demonstrate
    that the Fed-SP-SC method achieves a notable improvement in accuracy of 14-18%
    over the standalone LLMs with Zero-Shot-CoT (“Let’s think step by step”). Additionally,
    our Fed-DP-CoT method delivers an impressive increase of 10-15% over the standalone
    LLMs with Zero-Shot-CoT.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 GSM8K 和 SVAMP 数据集上广泛评估了我们的方法，结果表明 Fed-SP-SC 方法在准确性上比独立的 LLM 提高了 14-18%。此外，我们的
    Fed-DP-CoT 方法在准确性上比独立的 LLM 提高了 10-15%。
- en: We summarize our contributions in this study as follows.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本研究中总结了我们的贡献如下。
- en: '1.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: We consider a practical but under-studied scenario, which is the cloud-based
    LLMs are frequently asked similar and even synonymous common questions from large
    number distributed users.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们考虑了一个实际但研究不足的场景，即基于云的 LLM 经常接收到来自大量分布式用户的相似甚至同义的常见问题。
- en: '2.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'We abstract two main user scenarios: distributed users are querying synonymous
    questions that share the same parameters (SP-questions), and those that have different
    parameters (DP-questions).'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们抽象出两个主要用户场景：分布式用户查询具有相同参数的同义问题（SP- 问题）和具有不同参数的问题（DP- 问题）。
- en: '3.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: We design the system to firstly federate those SP- and DP-questions first by
    retrieving the database. Then we propose to utilize self-consistency methodology
    to select the most commonly voted answer to improve SP-question answering. All
    consistent answers and CoTs will be stored back into database for further reuse.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们设计系统首先通过检索数据库来联邦化这些 SP- 和 DP- 问题。然后我们提出利用自一致性方法来选择最常被投票的答案，以改进 SP- 问题的回答。所有一致的答案和
    CoTs 将被存储回数据库以备进一步使用。
- en: '4.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: We also amalgamate consistent answers to create a chain-of-thought prompt that
    significantly improves DP-questions answering quality. We also design a simple
    disclaimer to handle noisy CoT generated from LLM answers better.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还将一致的答案合并以创建一个链式思维提示，这显著提高了 DP- 问题的回答质量。我们还设计了一个简单的免责声明，以更好地处理来自 LLM 答案的噪声
    CoT。
- en: '5.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Inherited from Federated Learning, our Fed-SP-SC and Fed-DP-COT methods can
    collaboratively enhance the question-answering process of the LLM while preserving
    their anonymity. There would be no data exchange or leakage among distributed
    users.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 继承自联邦学习，我们的 Fed-SP-SC 和 Fed-DP-COT 方法可以协同提升 LLM 的问答过程，同时保持其匿名性。分布式用户之间不会有数据交换或泄漏。
- en: 2 Related Work
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Pre-trained Language Models (PLMs). Recent studies in Transformer-based language
    models such as ELMo [[15](#bib.bib15)] and BERT [[4](#bib.bib4)] have shown their
    capabilities in scaling up model sizes with pre-training methodology such as Masked
    Language Modeling [[4](#bib.bib4)]. Shortly after, several Large Language Models (LLMs),
    e.g., the GPT family [[1](#bib.bib1), [13](#bib.bib13)], PaLM [[2](#bib.bib2)],
    Jurassic-X [[9](#bib.bib9)], Megatron-Turing [[16](#bib.bib16)] , LaMDA [[17](#bib.bib17)],LLaMA [[18](#bib.bib18)],
    have been emerging with huge amount of parameters of up to 100B-5000B parameters.
    They have shown great advantages in language modeling tasks, such as arithmetic
    reasoning, commonsense reasoning, symbolic reasoning and natural language inference.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练语言模型（PLMs）。最近在基于 Transformer 的语言模型（如 ELMo [[15](#bib.bib15)] 和 BERT [[4](#bib.bib4)]）中的研究表明，其在通过
    Masked Language Modeling [[4](#bib.bib4)] 等预训练方法扩展模型规模方面具有能力。不久之后，出现了多个大型语言模型（LLMs），如
    GPT 系列 [[1](#bib.bib1), [13](#bib.bib13)]，PaLM [[2](#bib.bib2)]，Jurassic-X [[9](#bib.bib9)]，Megatron-Turing
    [[16](#bib.bib16)]，LaMDA [[17](#bib.bib17)]，LLaMA [[18](#bib.bib18)]，这些模型的参数量高达
    100B-5000B。它们在语言建模任务中展现了巨大的优势，如算术推理、常识推理、符号推理和自然语言推理。
- en: However, PLMs are still like black boxes which lack of explanation. Some recent
    studies made efforts towards unveiling the power of those LLMs. The proposal of
    the concept of the *Chain-of-Thought* (CoT) [[21](#bib.bib21)] indicates that
    incorporating intermediate reasoning steps can lead to a significant improvement
    in the performance of large language models on reasoning tasks. The proposal of
    the *Self-consistency* [[19](#bib.bib19)] suggest that aggregating multiple reasoning
    paths, rather than relying on greedy decoding, can lead to further improvements
    in the accuracy of models on reasoning tasks. LMSI [[7](#bib.bib7)] provides a
    demonstration of how large language models can achieve self-improvement by utilizing
    only unlabelled datasets.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，PLMs仍然像黑匣子一样缺乏解释。一些近期的研究努力揭示了这些LLMs的能力。*思维链*（CoT）[[21](#bib.bib21)]概念的提出表明，结合中间推理步骤可以显著改善大语言模型在推理任务上的表现。*自洽*（Self-consistency）[[19](#bib.bib19)]的提出表明，汇总多条推理路径，而不是依赖贪婪解码，可以进一步提高模型在推理任务中的准确性。LMSI [[7](#bib.bib7)]演示了大语言模型如何仅利用未标记的数据集实现自我改进。
- en: However, it is unknown how to apply proper pre-training to distributed learning
    scenarios, due to substantial differences between centralized large model deployment
    and distributed query demands. In this study, we adopt the recent popular distributed
    machine learning methodology called *Federated Learning* [[10](#bib.bib10), [26](#bib.bib26),
    [6](#bib.bib6), [5](#bib.bib5)] (FL) to fully explore the potentiality of Large
    Language Models to tackle frequently asked questions while preserving data privacy
    for the users. The FL provides a way of learning models over a collection of distributed
    devices while keeping data locality. However, classical FL studies assumed the
    agents in FL can own copies of local models while receiving updates from centralized
    model. In contrast, we focus on a practical scenario that the clients can only
    query answers from centralized Large Language Models without owning any local
    model, due to the practical situations that Large Language Models are simply too
    large and computational extensive to be deployed locally.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于集中式大模型部署和分布式查询需求之间存在显著差异，目前尚不清楚如何将适当的预训练应用于分布式学习场景。在这项研究中，我们采用了最近流行的分布式机器学习方法——*联邦学习* [[10](#bib.bib10),
    [26](#bib.bib26), [6](#bib.bib6), [5](#bib.bib5)] (FL)，以充分探索大语言模型的潜力，处理常见问题，同时保护用户的数据隐私。FL提供了一种在分布式设备集合上学习模型的方法，同时保持数据的本地性。然而，传统的FL研究假设FL中的代理可以拥有本地模型的副本，并从集中式模型接收更新。相比之下，我们关注的是一种实际场景，即客户端只能从集中式大语言模型中查询答案，而无法拥有任何本地模型，这主要是因为大语言模型过于庞大且计算量巨大，无法在本地部署。
- en: 3 Scenarios and Approaches
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 场景和方法
- en: In this section, we describe the federated scenarios that distributed users
    query the LLMs with similar (but not exact the same) questions. We identify two
    types of questions and discuss them in details.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了分布式用户用类似（但不完全相同）的问题查询LLMs的联邦场景。我们识别出两种类型的问题，并对此进行详细讨论。
- en: 3.1 Basic Concepts
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基本概念
- en: Chain-of-Thought (CoT) [[21](#bib.bib21)] is a series of generated intermediate
    reasoning texts that can be added to the original prompts. CoT is proposed for
    enhancing the capability of language models to perform various reasoning tasks
    by allowing LLMs to decompose complex problems into intermediate steps that could
    be solved well step-by-step. Chain-of-thought prompting, i.e. prompting LLMs with
    CoT, is a simple and practical method for improving the reasoning tasks readily
    with no additional efforts of tuning the original LLMs. CoT prompting has shown
    improved reasoning results on arithmetic, commonsense, and symbolic reasoning
    tasks.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*思维链*（CoT）[[21](#bib.bib21)]是一系列生成的中间推理文本，可以添加到原始提示中。CoT旨在通过允许LLMs将复杂问题分解为可以逐步解决的中间步骤，从而增强语言模型执行各种推理任务的能力。思维链提示，即用CoT提示LLMs，是一种简单且实用的方法，可以在无需额外调整原始LLMs的情况下，直接改善推理任务。CoT提示在算术、常识和符号推理任务中显示出了改进的推理结果。'
- en: Self-Consistency (SC) [[19](#bib.bib19)] is a decoding strategy that enhances
    language model reasoning with voting ensemble. SC first samples a diverse set
    of answers as reasoning paths of a question, rather than only the greedy path.
    By exploring multiple paths, SC is capable of identifying the most consist answer
    as the final answer by majority voting, i.e., the most voted answer of the LLM
    is taken as the final answer. Compared with a single-path reasoning, SC ensembles
    answers to improve accuracy and filters out noises or outliers. SC has also been
    widely explored in reasoning and QA tasks [[19](#bib.bib19)].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 自一致性（SC）[[19](#bib.bib19)]是一种解码策略，通过投票集成来增强语言模型推理。SC首先作为问题的推理路径抽样一组多样的答案，而不仅仅是贪婪路径。通过探索多个路径，SC能够通过多数投票来识别最一致的答案作为最终答案，即LLM投票最多的答案被作为最终答案。与单路径推理相比，SC集成答案以提高准确性，并过滤噪声或异常值。SC在推理和QA任务中也得到了广泛探索[[19](#bib.bib19)]。
- en: Majority voting(MV)[[11](#bib.bib11)] is a commonly used method in statistical
    decision theory that involves aggregating the opinions or decisions of multiple
    individuals or models, typically by selecting the option with the highest frequency
    of agreement among the voters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 多数投票（MV）[[11](#bib.bib11)]是统计决策理论中常用的一种方法，它涉及聚合多个个体或模型的意见或决定，通常通过选择选项中最高频率的同意来进行。
- en: 3.2 Synonymous Questions with Same Parameters (SP-questions)
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 同义问题与相同参数（SP-问题）
- en: We consider a cloud-based LLM system which accepts queries from distributed
    users. The first practical user scenario that we consider is as follows. Given
    a user query, we can retrieve from the cloud database several synonymous questions
    with same parameters (SP-questions).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑一个基于云的LLM系统，该系统接受来自分布式用户的查询。我们考虑的第一个实际用户场景如下。给定用户查询，我们可以从云数据库中检索出几个具有相同参数的同义问题（SP-问题）。
- en: 'Table 1: Examples of synonymous SP-questions and answers.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：同义SP-问题及其答案示例。
- en: '| *Example1:* |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| *示例1:* |'
- en: '| *Q1: “If a farmer has a certain number of chickens and rabbits in a barn,
    and* |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| *问题1：“如果一个农场主在一个谷仓里有一定数量的鸡和兔子，并且* |'
- en: '| *there are a total of $32$ heads and 100 feet, how many chickens and how
    many* |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| *总共有$32$个头和$100$只脚，有多少只鸡和多少只* |'
- en: '| *rabbits does the farmer have?”* |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| *兔子，农场主有多少只兔子？”* |'
- en: '| *A1: “The farmer has $24$ chickens and 8 rabbits.”* (wrong) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| *答案1：“农场主有$24$只鸡和8只兔子。”*（错误）|'
- en: '| *Q2: “In a barn, there are a certain number of chickens and rabbits that
    have* |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| *问题2：“在一个谷仓里，有一定数量的鸡和兔子，它们的* |'
- en: '| *a total of $32$ feet. how many of each animal are in the barn?”* |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| *总共有$32$只脚。谷仓里有多少每种动物？”* |'
- en: '| *A2: “Let $x=$ the number of rabbits. We can* |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| *答案2：“设$x=$兔子的数量。我们可以* |'
- en: '| *set up the following system of equations:$x+y=32(heads)$* |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| *建立如下方程组：$x+y=32（头）$* |'
- en: '| *(feet), Solving this system of equations, we get $x=20$.Therefore,* |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| *(只脚)，解这个方程组，我们得到$x=20$。因此，* |'
- en: '| *there are $20$ rabbits in the barn.”* (wrong) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| *谷仓里有$20$只兔子。”*（错误）|'
- en: '| *Example2:* |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| *示例2:* |'
- en: '| *Q1: “James writes a $3$ different friends twice a week.How many* |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| *问题1：“詹姆斯每周给$3$个不同的朋友写两封信。他写了多少* |'
- en: '| *pages does he write a year?”* |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| *他每年写多少页？”* |'
- en: '| *A1: “James writes $3$ pages* |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| *答案1：“詹姆斯写$3$页* |'
- en: '| *a month and $288$ pages a year.”* (wrong) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| *一个月和每年$288$页。”*（错误）|'
- en: '| *Q2: “If James writes a $3$-page letter to two different friends twice per
    week,what* |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| *问题2：“如果詹姆斯每周给两个不同的朋友写$3$页的信，他写了多少* |'
- en: '| *is the total number of pages he produces every year?”* |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| *他每年总共生产多少页？”* |'
- en: '| *A2: “James writes two $3$ weeks in a* |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| *答案2：“詹姆斯每周写$3$页信两次，* |'
- en: '| *year. Therefore, James produces a total of $312$).”* |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| *每年。因此，詹姆斯每年生产总共$312$页。）”* |'
- en: '| (wrong) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|（错误）|'
- en: 'For complex reasoning tasks, the LLMs may provide unreliable answers to the
    questions. We provide two failure cases in Table. [1](#S3.T1 "Table 1 ‣ 3.2 Synonymous
    Questions with Same Parameters (SP-questions) ‣ 3 Scenarios and Approaches ‣ Federated
    Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering"). We found
    that in both examples, Q1 and Q2 are synonymous while each of them gets a wrong
    answer from LLM. We summarize the difficulties of tackling the SP-questions as
    follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于复杂的推理任务，LLMs可能会提供不可靠的答案。我们在表格[1](#S3.T1 "Table 1 ‣ 3.2 Synonymous Questions
    with Same Parameters (SP-questions) ‣ 3 Scenarios and Approaches ‣ Federated Prompting
    and Chain-of-Thought Reasoning for Improving LLMs Answering")中提供了两个失败案例。我们发现，在这两个示例中，Q1和Q2是同义的，而每个问题都从LLM得到了错误的答案。我们总结了处理SP-问题的困难如下：
- en: '1.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Most LLMs have unsatisfying accuracy in solving reasoning problems in zero-shot
    way, i.e., prompting the LLMs with questions directly without giving other information.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数LLM在以零样本方式解决推理问题时准确性不尽如人意，即直接用问题提示LLM而不给予其他信息。
- en: '2.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: LLMs tend to under-perform when understanding complex problems involving multiple
    reasoning steps, such as the arithmetic problems given above.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM在理解涉及多个推理步骤的复杂问题时往往表现不佳，例如上述算术问题。
- en: Thus, our task is to *fully explore the SP-questions as a federation which can
    enhance the answer quality together*, instead of dealing them separately. To this
    end, we propose a technique named Fed-SP-SC (Federated SP-questions with Self-Consistency)
    for answering the questions with the self-consistency technique mentioned above.
    Fed-SP-SC can improve the zero-shot accuracy of the answers by eliciting answers
    from multiple synonymous questions and make a majority vote to disclose the most
    likely answer.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的任务是*充分探索作为联合体的SP问题，以共同提高答案质量*，而不是单独处理这些问题。为此，我们提出了一种名为Fed-SP-SC（自一致性联邦SP问题）的技术，用于回答上述自一致性技术提到的问题。Fed-SP-SC可以通过从多个同义问题中引出答案并进行多数投票来提高零样本答案的准确性，从而揭示最可能的答案。
- en: Concretely, we query the database using the user’s prompt to match SP-questions
    in the database. Note that here we assume we can retrieve the SP-questions which
    are just rephrased with synonymous and same parameters.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 具体地，我们使用用户的提示查询数据库，以匹配数据库中的SP问题。请注意，在这里我们假设我们可以检索到仅用同义词和相同参数重新表述的SP问题。
- en: Next, we generate the answers with LLMs by zero-shot prompting. For SP-questions,
    these answers are presumably same. Assuming that we have generated a total of
    *n* answers of synonymous questions during the Fed-SP-SC process, we can ensure
    the consistency with SC procedure, i.e., we make a majority vote and select the
    most voted answer $A^{SC}$ as the final answer of all SP-questions, as below.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过零样本提示生成LLM的答案。对于SP问题，这些答案被认为是相同的。假设我们在Fed-SP-SC过程中生成了总共*n*个同义问题的答案，我们可以通过SC程序确保一致性，即我们进行多数投票，并选择最多票数的答案
    $A^{SC}$ 作为所有SP问题的最终答案，如下所示。
- en: '|  | $A^{SC}\leftarrow\operatorname*{arg\,max}_{A\in\mathcal{A}}\sum\mathbf{1}[A==A_{i}],\
    \ \forall i=1,...,n\ .$ |  | (1) |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | $A^{SC}\leftarrow\operatorname*{arg\,max}_{A\in\mathcal{A}}\sum\mathbf{1}[A==A_{i}],\
    \ \forall i=1,...,n\ .$ |  | (1) |'
- en: Intuitively, the majority voting filters out outliers and noisy rephrased questions.
    In addition, the most voted answer is the agreement of multiple reasoning paths
    from multiple rephrased SP-questions, thus is more likely to be better than a
    single prompted answer decoded from a single reasoning path.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，多数投票可以过滤掉异常值和噪声重述的问题。此外，最多票数的答案是来自多个重述SP问题的多个推理路径的共识，因此比从单一推理路径解码出的单一提示答案更有可能更好。
- en: In our experiments, we demonstrate that Fed-SP-SC achieves a 17.5% improvement
    in accuracy on the GSM8K dataset and a 14% improvement on the SVAMP dataset in
    Table [3](#S4.T3 "Table 3 ‣ 4.2 Results of Fed-SP-SC ‣ 4 Experiment ‣ Federated
    Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering"). In a
    practical system, we can further store these user prompts and the SC-selected
    answer back into the database.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们证明了Fed-SP-SC在GSM8K数据集上提高了17.5%的准确性，在SVAMP数据集上提高了14%的准确性，见表 [3](#S4.T3
    "表3 ‣ 4.2 Fed-SP-SC结果 ‣ 4 实验 ‣ 联邦提示和链式推理以提高LLM回答能力")。在实际系统中，我们还可以将这些用户提示和SC选择的答案进一步存储回数据库。
- en: '![Refer to caption](img/e9d8d8903d45611f6750eb55fb429ab7.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e9d8d8903d45611f6750eb55fb429ab7.png)'
- en: 'Figure 2: The illustration of performing Fed-SP-SC for answering synonymous SP-questions.
    $(A\rightarrow B)$: The most voted answer is returned to the user as the best
    answer. The database could store the query and answer pair back to the database,
    caching for later retrieval. This procedure can grow the database quickly by gathering
    distributed user queries.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：执行Fed-SP-SC以回答同义SP问题的示意图。 $(A\rightarrow B)$：最多票数的答案作为最佳答案返回给用户。数据库可以将查询和答案对存储回数据库中，为后续检索进行缓存。这个过程可以通过收集分布式用户查询快速增长数据库。
- en: 3.3 Synonymous questions with Different Parameters (DP-questions)
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 参数不同的同义问题（DP问题）
- en: We now describe the second scenario which is named synonymous questions with
    different parameters (DP-questions), which is broader and more practical. Based
    on the user query question, the cloud-deployed system searches and retrieves from
    the database for questions with same meanings but may have different parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在描述第二种情况，称为具有不同参数的同义问题（DP-问题），它更广泛且更实用。根据用户的查询问题，云部署的系统会从数据库中搜索并检索具有相同含义但参数可能不同的问题。
- en: DP-questions are more practical yet harder than SP-questions as the question
    parameters retrieved from the database are different. We show two exemplary questions
    Q1 and Q2 below which have the same meaning yet with different parameters *heads*
    and *feet* in Table [2](#S3.T2 "Table 2 ‣ 3.3 Synonymous questions with Different
    Parameters (DP-questions) ‣ 3 Scenarios and Approaches ‣ Federated Prompting and
    Chain-of-Thought Reasoning for Improving LLMs Answering").
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: DP-问题比SP-问题更实际，但更难，因为从数据库检索到的问题参数不同。我们在下面展示了两个示例问题Q1和Q2，它们具有相同的含义，但参数*头*和*脚*不同，见表[2](#S3.T2
    "表2 ‣ 3.3 具有不同参数的同义问题（DP-问题） ‣ 3 情境与方法 ‣ 联邦提示和思维链推理以改善LLMs回答")。
- en: 'Table 2: Two examples of DP-questions. *Q1* and *Q2* are synonymous but with
    different question parameters.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：DP-问题的两个示例。*Q1* 和 *Q2* 是同义的，但问题参数不同。
- en: '| The specific description of *Q1* and *Q2:* |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| *Q1* 和 *Q2* 的具体描述：|'
- en: '| *Q1: “If a farmer has a certain number of chickens and rabbits in a barn
    and*, |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| *Q1: “如果一个农场主在谷仓里有一定数量的鸡和兔子，* |'
- en: '| *there are a total of 32 heads and 100 feet, how many chickens and how many*
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| *总共有32个头和100只脚，有多少只鸡和多少只* |'
- en: '| *rabbits does the farmer have?”* |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| *兔子？”* |'
- en: '| *Q2: “A farmer has a total of 20 chickens and rabbits in his barn. If the
    total* |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| *Q2: “一个农场主的谷仓里总共有20只鸡和兔子。如果总* |'
- en: '| *number of legs in the barn is 56, how many chickens and how many rabbits*
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| *而谷仓里的腿总数是56，那么有多少只鸡和多少只兔子* |'
- en: '| *are in the barn?”* |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| *在谷仓里？”* |'
- en: 'Note that tackling DP-questions would face all the difficulties of SP-questions,
    and would have additional obstacles as summarized below:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，处理DP-问题将面临所有SP-问题的困难，并且会有如下总结的额外障碍：
- en: '1.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: There is no uniform ground-truth for DP-questions in the database, since each
    one has different parameters.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据库中对于DP-问题没有统一的真实答案，因为每个问题都有不同的参数。
- en: '2.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Similarly, we cannot apply self-consistency (SC) directly to improve accuracy
    due to different parameters.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同样，由于参数不同，我们无法直接应用自洽性（SC）来提高准确性。
- en: '3.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: If we apply Chain-of-Thought (CoT) together to the original questions as enhanced
    prompts, we cannot guarantee the correctness of the CoT. Incorrect CoT may even
    harm the answering accuracy.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们将思维链（CoT）与原始问题一起应用作为增强提示，我们无法保证CoT的正确性。错误的CoT甚至可能会损害回答的准确性。
- en: To tackle the above challenges, we propose the Federated questions of Different
    Parameters with Chain-of-Thought (Fed-DP-CoT) technique to leverage existing answers
    of DP-questions in CoT forms to improve new query answering.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对上述挑战，我们提出了不同参数的联合问题与思维链（Fed-DP-CoT）技术，以利用DP-问题的现有答案（以CoT形式）来改善新的查询回答。
- en: '![Refer to caption](img/cc7b5c7cd186a7fbd826092438b6cea2.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cc7b5c7cd186a7fbd826092438b6cea2.png)'
- en: 'Figure 3: The illustration of performing Fed-DP-CoT. $(A\rightarrow B)$: The
    system concatenates questions and pseudo-labels, adds a pseudo-label disclaimer
    such as “The examples may have errors.” after, and finally appends the original
    user query and Zero-Shot-CoT to form the complete CoT prompt.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '图3：执行Fed-DP-CoT的示意图。 $(A\rightarrow B)$: 系统将问题和伪标签连接起来，在其后添加诸如“示例可能存在错误”的伪标签免责声明，最后附上原始用户查询和零-shot-CoT，以形成完整的CoT提示。'
- en: When a user starts querying the cloud-based LLM service, the cloud system performs
    query-question retrieval first. The system matches several questions with the
    highest similarity in the database. Generally, these the retrieved questions are
    of different parameters (DP-questions). We design the system to perform Fed-DP-CoT
    for understanding DP-questions.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户开始查询基于云的LLM服务时，云系统首先执行查询问题检索。系统会匹配数据库中相似度最高的几个问题。通常，这些检索到的问题具有不同的参数（DP-问题）。我们设计系统来执行Fed-DP-CoT以理解DP-问题。
- en: We consider a practical case that these DP-questions have *pseudo-labels* generated
    by self-consistency majority voting in the Fed-SP-SC processes. We call these
    labels “pseudo-labels” as they are not actual ground-truth labels.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了一个实际案例，这些DP问题具有*伪标签*，由Fed-SP-SC过程中的自一致性多数投票生成。我们称这些标签为“伪标签”，因为它们不是实际的真实标签。
- en: Then we utilize these DP-questions with pseudo-labels together as CoT for the
    original query-question. To be specific, we concatenate DP-questions with their
    answers as a single prompt, followed by the error disclaimer “The examples given
    above may contain errors , please think more carefully. ” at the end of this prompt
    as the complete prompt. The error disclaimer reminds the LLMs that the answers
    in CoT are pseudo-labels and could be incorrect. We found this simple practice
    can boost performance by approximately 2%. Finally, we use the entire disclaimed
    CoT as a prefix to the user’s query prompt for the LLMs to provide the final answer.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将这些带有伪标签的DP问题作为CoT一起使用，作为原始查询问题。具体来说，我们将DP问题及其答案连接成一个单一的提示，并在提示的末尾加上错误免责声明“上述示例可能包含错误，请仔细思考。”作为完整的提示。错误免责声明提醒LLMs，CoT中的答案是伪标签，可能不正确。我们发现这种简单的做法可以提高约2%的性能。最后，我们将整个声明的CoT作为前缀添加到用户的查询提示中，以便LLMs提供最终答案。
- en: 4 Experiment
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: We evaluate our proposed Fed-SP-SC and Fed-DP-CoT methods on benchmark datasets
    with simulated user scenarios such that SP- and DP-questions are retrieved to
    improve over standalone question answering.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在基准数据集上评估我们提出的Fed-SP-SC和Fed-DP-CoT方法，模拟用户场景，以便SP和DP问题被检索以改进独立的问题回答。
- en: We compare our methods with *Zero-Shot-CoT* [[1](#bib.bib1)], which refers to
    adding *“Let’s think step by step.”* to prompt as a composite prompt, such as
    “[Question] A:Let’s think step by step.”
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将我们的方法与*零样本-CoT* [[1](#bib.bib1)]进行比较，零样本-CoT是指将*“让我们一步步思考。”* 添加到提示中作为复合提示，例如“[问题]
    A: 让我们一步步思考。”'
- en: 4.1 Datasets
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集
- en: Grade School Math (GSM8K) is a math dataset with 7,473 training and 1,319 testing
    examples of grade-school-level word problems[[3](#bib.bib3)]. These math problems
    typically require two to eight calculation steps to arrive at a final answer,
    as shown in Fig.[2](#S3.F2 "Figure 2 ‣ 3.2 Synonymous Questions with Same Parameters
    (SP-questions) ‣ 3 Scenarios and Approaches ‣ Federated Prompting and Chain-of-Thought
    Reasoning for Improving LLMs Answering"). GSM8K is widely used as a benchmark
    dataset for testing the arithmetic and commonsense reasoning capacities of LLMs [[7](#bib.bib7),
    [8](#bib.bib8)].
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 小学数学（GSM8K）是一个数学数据集，包含7,473个训练样本和1,319个测试样本的小学水平的文字问题[[3](#bib.bib3)]。这些数学问题通常需要两到八步计算才能得出最终答案，如图[2](#S3.F2
    "图 2 ‣ 3.2 同义问题与相同参数 (SP-问题) ‣ 3 场景和方法 ‣ 联邦提示和思路链推理以提高LLMs回答能力")所示。GSM8K被广泛用作测试LLMs算术和常识推理能力的基准数据集[[7](#bib.bib7),
    [8](#bib.bib8)]。
- en: Simple Variations on Arithmetic Math word Problems (SVAMP) is a dataset of simple
    arithmetic math word problems [[14](#bib.bib14)] with around 6,000 samples. Each
    data instance has a short story and a question about unknown quantities. SVAMP
    provides a benchmark test set for comparing the textual understanding and reasoning
    abilities of LLMs, which is widely compared in recent studies [[14](#bib.bib14),
    [21](#bib.bib21), [19](#bib.bib19)].
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 简单算术数学问题集（SVAMP）是一个包含约6,000个样本的简单算术数学问题数据集[[14](#bib.bib14)]。每个数据实例都有一个简短的故事和一个关于未知量的问题。SVAMP提供了一个基准测试集，用于比较LLMs的文本理解和推理能力，这在最近的研究中被广泛比较[[14](#bib.bib14),
    [21](#bib.bib21), [19](#bib.bib19)]。
- en: In practice, we utilized the OpenAI’s API ¹¹1https://platform.openai.com/docs/models
    text-davinci-002 and text-davinci-003\. We selected text-davinci-003 for the GSM8K
    dataset as text-davinci-002 performed very poorly. Similarly, we used text-davinci-002
    for the SVAMP dataset as text-davinci-003 had an overly high accuracy rate on
    this dataset.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 实际操作中，我们利用了OpenAI的API ¹¹1https://platform.openai.com/docs/models text-davinci-002
    和 text-davinci-003。我们为GSM8K数据集选择了text-davinci-003，因为text-davinci-002表现非常糟糕。类似地，我们对SVAMP数据集使用了text-davinci-002，因为text-davinci-003在该数据集上的准确率过高。
- en: 4.2 Results of Fed-SP-SC
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 Fed-SP-SC的结果
- en: As a kind reminder, in the following discussions, SP-questions stand for *a
    set of rephrased synonymous questions with same parameters.* Differently, DP-questions
    stand for *a set of rephrased synonymous questions with different parameters.*
    We now describe the experiment procedures shown in Fig. [4](#S4.F4 "Figure 4 ‣
    4.2 Results of Fed-SP-SC ‣ 4 Experiment ‣ Federated Prompting and Chain-of-Thought
    Reasoning for Improving LLMs Answering").
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，在接下来的讨论中，SP问题指的是*一组参数相同的同义重新表述的问题。* 不同的是，DP问题指的是*一组参数不同的同义重新表述的问题。* 现在我们描述图[4](#S4.F4
    "图 4 ‣ 4.2 Fed-SP-SC结果 ‣ 4 实验 ‣ 提升LLMs回答的联邦提示和思维链推理")中显示的实验程序。
- en: '[SP-questions generation]. We first generate four SP-questions for each of
    the original question with both OpenAI GPT-3 [[1](#bib.bib1)] and GPT-3.5 [[13](#bib.bib13)],
    respectively. Concretely, we add each original question a same prompt prefix “Rephrase
    in 4 ways: [ORIGINAL QUESTION]”, then we collect the generated answers.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[SP问题生成]。我们首先分别使用OpenAI GPT-3 [[1](#bib.bib1)]和GPT-3.5 [[13](#bib.bib13)]为每个原始问题生成四个SP问题。具体来说，我们为每个原始问题添加相同的提示前缀“以4种方式重新表述：[ORIGINAL
    QUESTION]”，然后收集生成的答案。'
- en: '[SP-questions answering]. We query the cloud-deployed LLM for answering rephrased
    questions generated as above. Specifically, we obtain the improved Zero-Shot-CoT
    answering with the magic sentence “Let’s think step by step” as the prompt.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[SP问题回答]。我们查询云端部署的LLM以回答上述生成的重新表述问题。具体来说，我们使用魔法句子“让我们一步一步思考”作为提示来获得改进的Zero-Shot-CoT回答。'
- en: We first examine the performance of our proposed Fed-SP-SC which deals with
    SP-questions with the Self-consistency technique. We conducted experiments on
    GSM8K and SVAMP and report the results below.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先检查了我们提出的Fed-SP-SC的性能，它使用自一致性技术处理SP问题。我们在GSM8K和SVAMP上进行了实验，并报告了以下结果。
- en: '![Refer to caption](img/c0d7a176c58306cd3a2da95bcf44e2a5.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c0d7a176c58306cd3a2da95bcf44e2a5.png)'
- en: 'Figure 4: The experiment of Fed-SP-SC contains five steps: (1) Load the GSM8K
    and SVAMP datasets as our benchmark and extract the questions and answers in the
    dataset; (2) Add each original question a same prompt prefix “Rephrase in 4 ways:
    [QUESTION]” to generate SP-questions; (3) Prompt both the original and rewritten
    questions to the LLMs to obtain their respective answers; (4) Use the majority
    vote for self-consistency; (5) Get the answer generated by Fed-SP-SC and compare
    it with the answer in the dataset to determine the accuracy rate.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：Fed-SP-SC实验包括五个步骤：（1）加载GSM8K和SVAMP数据集作为我们的基准，提取数据集中的问题和答案；（2）为每个原始问题添加相同的提示前缀“以4种方式重新表述：[QUESTION]”以生成SP问题；（3）将原始和重写的问题提示给LLMs以获取各自的答案；（4）使用多数投票进行自一致性；（5）获取Fed-SP-SC生成的答案，并与数据集中的答案进行比较以确定准确率。
- en: 'Table 3: Fed-SP-SC results'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：Fed-SP-SC结果
- en: '| Data\Method | Zero-Shot-CoT |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 数据\方法 | Zero-Shot-CoT |'
- en: '&#124; Fed-SP-SC &#124;'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fed-SP-SC &#124;'
- en: '&#124; (GPT-3 Gen.) &#124;'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (GPT-3 Gen.) &#124;'
- en: '|'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Fed-SP-SC &#124;'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fed-SP-SC &#124;'
- en: '&#124; (GPT-3.5 Gen.) &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (GPT-3.5 Gen.) &#124;'
- en: '|'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| GSM8K | 52.5% | 62.7% | 70.6% |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K | 52.5% | 62.7% | 70.6% |'
- en: '| SVAMP | 77.2% | 86.3% | 91.1% |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| SVAMP | 77.2% | 86.3% | 91.1% |'
- en: We show accuracy of self-consistency after obtaining results from different
    phrasings of the synonymous question on GSM8K and SVAMP in Table [3](#S4.T3 "Table
    3 ‣ 4.2 Results of Fed-SP-SC ‣ 4 Experiment ‣ Federated Prompting and Chain-of-Thought
    Reasoning for Improving LLMs Answering"). We have the following observations.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了在GSM8K和SVAMP上通过不同同义问题的表述获得的自一致性准确率，见表[3](#S4.T3 "表 3 ‣ 4.2 Fed-SP-SC结果
    ‣ 4 实验 ‣ 提升LLMs回答的联邦提示和思维链推理")。我们有以下观察。
- en: •
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Fed-SP-SC can improve answering accuracy* of LLMs by federating multiple SP-questions
    through self-consistency.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Fed-SP-SC可以通过自一致性提高LLMs的回答准确性*。'
- en: •
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Fed-SP-SC(GPT-3.5 Gen.) performs best on the GSM8K and SVAMP datasets,* improved
    the performance by $17.5\%$ on the GSM8K and SVAMP datasets, respectively.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Fed-SP-SC(GPT-3.5 Gen.)在GSM8K和SVAMP数据集上表现最佳，* 分别提高了GSM8K和SVAMP数据集的性能$17.5\%$。'
- en: •
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*The quality of the synonymous questions can affect the accuracy significantly*,
    as seen in the larger improvement from the synonymous questions generated by GPT-3.5
    compared to GPT-3.'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*同义问题的质量可以显著影响准确率，* 从GPT-3.5生成的同义问题相比GPT-3的显著改善可以看出。'
- en: 4.3 Results of Fed-DP-CoT
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 Fed-DP-CoT的结果
- en: '![Refer to caption](img/59236f8ee011c3a74d46d8c9fc49d557.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/59236f8ee011c3a74d46d8c9fc49d557.png)'
- en: 'Figure 5: The experiment of Fed-DP-CoT contains five steps:(1) Form a new test
    set by rephrasing the questions using different parameters in the benchmark manually
    and providing answers; (2) Extract consistent questions and answers in Fed-SP-SC
    experiment; (3) Add a disclaimer to form the CoT prompt; (4) Add the rephrased
    questions after the CoT prompt; (5) Prompt LLMs with entire CoT prompt and compared
    the answers with the rephrased answers for evaluation.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：Fed-DP-CoT 实验包含五个步骤：(1) 通过手动使用基准中的不同参数重新措辞问题并提供答案，形成新的测试集；(2) 在 Fed-SP-SC
    实验中提取一致的问题和答案；(3) 添加免责声明以形成 CoT 提示；(4) 在 CoT 提示后添加重新措辞的问题；(5) 使用整个 CoT 提示对 LLMs
    进行提示，并将答案与重新措辞的答案进行比较以进行评估。
- en: 'Table 4: Fed-DP-CoT results.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：Fed-DP-CoT 结果。
- en: '| Setting\Method | Zero-Shot-CoT |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 设置\方法 | Zero-Shot-CoT |'
- en: '&#124; Fed-DP-CoT &#124;'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fed-DP-CoT &#124;'
- en: '&#124; (GPT-3 Gen.) &#124;'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (GPT-3 生成版) &#124;'
- en: '|'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Fed-DP-CoT &#124;'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fed-DP-CoT &#124;'
- en: '&#124; (GPT-3.5 Gen.) &#124;'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (GPT-3.5 生成版) &#124;'
- en: '|'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| GSM8K | 48.3% | 59.2% | 62.5% |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K | 48.3% | 59.2% | 62.5% |'
- en: '| SVAMP | 76.5% | 82.4% | 85.7% |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| SVAMP | 76.5% | 82.4% | 85.7% |'
- en: We report results of Fed-DP-CoT on GSM8K and SVAMP in Table [4](#S4.T4 "Table
    4 ‣ 4.3 Results of Fed-DP-CoT ‣ 4 Experiment ‣ Federated Prompting and Chain-of-Thought
    Reasoning for Improving LLMs Answering"), and compare with the baseline Zero-Shot-CoT.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表 [4](#S4.T4 "表 4 ‣ 4.3 Fed-DP-CoT 的结果 ‣ 4 实验 ‣ 提高 LLMs 回答质量的联邦提示和思维链推理")
    中报告了 Fed-DP-CoT 在 GSM8K 和 SVAMP 上的结果，并与基准 Zero-Shot-CoT 进行了比较。
- en: •
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Fed-DP-CoT can improve the performance.* Compared to Zero-Shot-CoT, CoT Prompt(GPT-3
    Gen.) and CoT Prompt(GPT-3.5 Gen.) improve by approximately 10.9%-14.2% and 6.6%-10%
    respectively on the datasets GSM8K and SVAMP.'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Fed-DP-CoT 可以提高性能。* 与 Zero-Shot-CoT 相比，CoT 提示 (GPT-3 生成版) 和 CoT 提示 (GPT-3.5
    生成版) 在数据集 GSM8K 和 SVAMP 上分别提高了大约 10.9%-14.2% 和 6.6%-10%。'
- en: •
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Fed-SP-SC performs better than Fed-DP-CoT.* The results of Fed-SP-SC (GPT-3
    Gen.) and Fed-SP-SC (GPT-3.5 Gen.) on the GSM8K and SVAMP datasets are both higher
    than Fed-DP-CoT (GPT-3 Gen.) and CoT Prompt (GPT-3.5 Gen.), with an approximate
    improvement of 5%.'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*Fed-SP-SC 的表现优于 Fed-DP-CoT。* Fed-SP-SC (GPT-3 生成版) 和 Fed-SP-SC (GPT-3.5 生成版)
    在 GSM8K 和 SVAMP 数据集上的结果均高于 Fed-DP-CoT (GPT-3 生成版) 和 CoT 提示 (GPT-3.5 生成版)，大约提高了
    5%。'
- en: •
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*Less significant performance difference between GPT-3 Gen. and GPT-3.5 Gen.
    compared to Fed-SP-SC experiment.* The reason for this is the disparity in parameters
    employed, coupled with the lack of emphasis on synonym usage in the CoT prompt.'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*与 Fed-SP-SC 实验相比，GPT-3 生成版和 GPT-3.5 生成版之间的性能差异不显著。* 这主要是由于所使用参数的差异，加上 CoT
    提示中对同义词使用的重视程度不足。'
- en: 4.4 Ablation studies
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 消融研究
- en: '![Refer to caption](img/433ce48505dbe7f25b41f3d15dca258a.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/433ce48505dbe7f25b41f3d15dca258a.png)'
- en: (a) GSM8K
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: (a) GSM8K
- en: '![Refer to caption](img/5472ab346020a52db7685a6507791ec8.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/5472ab346020a52db7685a6507791ec8.png)'
- en: (b) SVAMP
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: (b) SVAMP
- en: 'Figure 6: Ablation study of choice of sampled reasoning paths.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：采样推理路径选择的消融研究。
- en: The number of reasoning paths for self-consistency. We study the effect of using
    different number of sampled reasoning paths for Fed-SP-SC (Sec. [4.2](#S4.SS2
    "4.2 Results of Fed-SP-SC ‣ 4 Experiment ‣ Federated Prompting and Chain-of-Thought
    Reasoning for Improving LLMs Answering")) to apply self-consistency. We conduct
    hyper-parameter search with a subset of the data for this ablation study due to
    the limits of accesses of the OpenAI API.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 自一致性的推理路径数量。我们研究了使用不同数量的采样推理路径对 Fed-SP-SC (第 [4.2 节](#S4.SS2 "4.2 Fed-SP-SC
    的结果 ‣ 4 实验 ‣ 提高 LLMs 回答质量的联邦提示和思维链推理")) 应用自一致性的效果。由于 OpenAI API 的访问限制，我们在数据子集上进行超参数搜索以进行这一消融研究。
- en: We vary the number of sampled reasoning paths of synonymous questions from one
    to nine. Figure [6](#S4.F6 "Figure 6 ‣ 4.4 Ablation studies ‣ 4 Experiment ‣ Federated
    Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering") shows
    that increasing the number of sampled reasoning paths of the synonymous questions
    does not always improve the accuracy of the model.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将同义问题的采样推理路径数量从一增加到九。图 [6](#S4.F6 "图 6 ‣ 4.4 消融研究 ‣ 4 实验 ‣ 提高 LLMs 回答质量的联邦提示和思维链推理")
    显示，增加同义问题的采样推理路径数量并不总是能提高模型的准确性。
- en: In the line chart, as the number of sampled reasoning paths increases from one
    to five, the accuracy rate gradually increases. However, when the number of synonymous questions
    exceeds five, the accuracy of the model starts to decrease.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在折线图中，随着采样推理路径数量从一增加到五，准确率逐渐提高。然而，当同义问题的数量超过五个时，模型的准确性开始下降。
- en: We speculate that this is because introducing synonymous questions also introduces
    noisy phrases, causing a deviation in the semantic meaning of the original questions.
    This deviation is particularly evident in synonymous questions generated by GPT-3
    (blue lines), while the generation results of GPT-3.5 (orange lines) exhibit stronger
    robustness.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推测这是因为引入同义问题也引入了噪声短语，导致了原始问题语义上的偏差。这种偏差在GPT-3生成的同义问题中尤为明显（蓝线），而GPT-3.5生成的结果（橙线）表现出更强的鲁棒性。
- en: 'Table 5: GSM8K disclaimer ablation.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：GSM8K免责声明消融实验。
- en: '| Method\Setting |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 方法\设置 |'
- en: '&#124; Zero-shot &#124;'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 零样本 &#124;'
- en: '&#124; -CoT &#124;'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; -CoT &#124;'
- en: '|'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Fed-DP-CoT &#124;'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fed-DP-CoT &#124;'
- en: '&#124; (GPT-3 Gen.) &#124;'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (GPT-3 Gen.) &#124;'
- en: '|'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Fed-DP-CoT &#124;'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fed-DP-CoT &#124;'
- en: '&#124; (GPT-3.5 Gen.) &#124;'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (GPT-3.5 Gen.) &#124;'
- en: '|'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| w/o disclaimer | 48.3% | 57.7% | 60% |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| w/o 免责声明 | 48.3% | 57.7% | 60% |'
- en: '| w/ disclaimer | NA | 59.2% | 62.5% |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| w/ 免责声明 | NA | 59.2% | 62.5% |'
- en: Disclaimer We investigate whether the disclaimer is effective of correcting
    noisy CoTs in this ablation experiment. As Zero-Shot-CoT does not employ pseudo-labels,
    we do not conduct disclaimer ablation on it. Table [5](#S4.T5 "Table 5 ‣ 4.4 Ablation
    studies ‣ 4 Experiment ‣ Federated Prompting and Chain-of-Thought Reasoning for
    Improving LLMs Answering") compares the DP-questions answering accuracy with disclaimer
    or without disclaimer. We observe that the addition of a disclaimer in the questions
    and answers generated by GPT-3 resulted in an increase in accuracy from 57.7%
    to 59.2% for the Fed-DP-CoT task. Similarly, in the case of questions and answers
    generated by GPT-3.5, the accuracy increase from 60% to 62.5%. These results indicate
    that the use of a simple disclaimer can potentially improve the accuracy of LLMs
    by approximately 2% for the Fed-DP-CoT task. We postulate that the improvement
    in accuracy may be attributed to the fact that the disclaimer prompts LLMs to
    be careful of the pseudo-labels and self-examine the reasoning steps.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 免责声明 我们研究了免责声明在这个消融实验中是否有效地纠正了噪声链式推理。由于零样本链式推理（Zero-Shot-CoT）不使用伪标签，我们没有对其进行免责声明消融。表
    [5](#S4.T5 "表 5 ‣ 4.4 消融研究 ‣ 4 实验 ‣ 联邦提示和链式推理以改进LLMs回答") 比较了有无免责声明的DP-问题回答准确性。我们观察到，在GPT-3生成的问题和答案中加入免责声明，使得Fed-DP-CoT任务的准确性从57.7%提高到了59.2%。类似地，在GPT-3.5生成的问题和答案中，准确性从60%提高到62.5%。这些结果表明，使用简单的免责声明可能会将LLMs的准确性提高约2%用于Fed-DP-CoT任务。我们推测，准确性的提升可能归因于免责声明促使LLMs注意伪标签并自我检查推理步骤。
- en: 5 Conclusion
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: We investigate the potential benefits of employing synonymous queries from distributed
    users to enhance question-answering beyond what is achievable by a single user.
    Specifically, we explore the use of such queries in a federated manner by extracting
    two common user scenarios whereby the cloud database retrieves either SP- or DP-questions.
    To address these scenarios, we propose the application of self-consistency to
    identify the most consistent answers for SP-questions and utilize them as CoT
    to improve the answers provided for DP-questions. Our experimental results demonstrate
    that this approach yields a significant boost in performance compared to standalone
    zero-shot QA.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了利用来自分布式用户的同义查询来提升问答系统性能的潜在好处，超越单一用户所能实现的效果。具体而言，我们探讨了以联邦方式使用这些查询，通过提取两个常见的用户场景，其中云数据库检索的是SP-问题或DP-问题。为了解决这些场景，我们提出了应用自一致性来识别SP-问题中最一致的答案，并利用这些答案作为链式推理（CoT）来改善对DP-问题提供的答案。我们的实验结果表明，这种方法相比于独立的零样本问答（zero-shot
    QA）显著提升了性能。
- en: Moving forward, future research may investigate the implementation of more realistic
    systems that can efficiently retrieve federated questions while also improving
    CoT correctness to further advance reasoning capabilities. In this study, we assumed
    the DP-questions have already been stored with their answers generated by LLMs,
    and the consistent answers have been generated. Future work can further extend
    to scenarios that part of the DP-questions have no answers or pseudo-answers.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，进一步的研究可以探讨实现更现实的系统，这些系统能够高效地检索联邦问题，同时改善链式推理的准确性，以进一步提升推理能力。在本研究中，我们假设DP-问题已经存储并由LLMs生成了答案，并且生成了一致的答案。未来的工作可以进一步扩展到DP-问题中部分没有答案或伪答案的场景。
- en: References
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are
    few-shot learners. Advances in neural information processing systems 33, 1877–1901
    (2020)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., 等：语言模型是少样本学习者。神经信息处理系统进展 33,
    1877–1901 (2020)'
- en: '[2] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts,
    A., Barham, P., Chung, H.W., Sutton, C., Gehrmann, S., et al.: Palm: Scaling language
    modeling with pathways. arXiv preprint arXiv:2204.02311 (2022)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts,
    A., Barham, P., Chung, H.W., Sutton, C., Gehrmann, S., 等：Palm：通过路径扩展语言建模。arXiv
    预印本 arXiv:2204.02311 (2022)'
- en: '[3] Cobbe, K., Kosaraju, V., et al.: Training verifiers to solve math word
    problems. arXiv preprint arXiv:2110.14168 (2021)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Cobbe, K., Kosaraju, V., 等：训练验证器解决数学文字问题。arXiv 预印本 arXiv:2110.14168 (2021)'
- en: '[4] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of
    deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805
    (2018)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert：双向深度变换器的语言理解预训练。arXiv
    预印本 arXiv:1810.04805 (2018)'
- en: '[5] Fan, C., Hu, J., Huang, J.: Private semi-supervised federated learning.
    In: IJCAI. pp. 2009–2015 (2022)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Fan, C., Hu, J., Huang, J.: 私有半监督联邦学习。收录于：IJCAI。第2009–2015页 (2022)'
- en: '[6] Fan, C., Huang, J.: Federated few-shot learning with adversarial learning.
    In: 2021 19th International Symposium on Modeling and Optimization in Mobile,
    Ad hoc, and Wireless Networks (WiOpt). pp. 1–8\. IEEE (2021)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Fan, C., Huang, J.: 结合对抗学习的联邦少样本学习。收录于：2021年第19届移动、Ad hoc 和无线网络建模与优化国际研讨会（WiOpt）。第1–8页。IEEE
    (2021)'
- en: '[7] Huang, J., Gu, S.S., Hou, L., Wu, Y., Wang, X., Yu, H., Han, J.: Large
    language models can self-improve. arXiv preprint arXiv:2210.11610 (2022)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Huang, J., Gu, S.S., Hou, L., Wu, Y., Wang, X., Yu, H., Han, J.: 大型语言模型可以自我改进。arXiv
    预印本 arXiv:2210.11610 (2022)'
- en: '[8] Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.: Large language
    models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 (2023)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.: 大型语言模型是零样本推理器。arXiv
    预印本 arXiv:2205.11916 (2023)'
- en: '[9] Levine, Y., Dalmedigos, I., Ram, O., Zeldes, Y., Jannai, D., Muhlgay, D.,
    Osin, Y., Lieber, O., Lenz, B., Shalev-Shwartz, S., et al.: Standing on the shoulders
    of giant frozen language models. arXiv preprint arXiv:2204.10019 (2022)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Levine, Y., Dalmedigos, I., Ram, O., Zeldes, Y., Jannai, D., Muhlgay, D.,
    Osin, Y., Lieber, O., Lenz, B., Shalev-Shwartz, S., 等：立足于巨型冻结语言模型的肩膀。arXiv 预印本
    arXiv:2204.10019 (2022)'
- en: '[10] McMahan, H.B., Moore, E., Ramage, D., Hampson, S., y Arcas, B.A.: Communication-efficient
    learning of deep networks from decentralized data. In: AISTATS (2017)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] McMahan, H.B., Moore, E., Ramage, D., Hampson, S., y Arcas, B.A.: 从分散数据中进行通信高效的深度网络学习。收录于：AISTATS
    (2017)'
- en: '[11] Ongaro, D., Ousterhout, J.: In search of an understandable consensus algorithm.
    In: Proceedings of the 2014 USENIX Conference on USENIX Annual Technical Conference.
    p. 305–320 (2014)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Ongaro, D., Ousterhout, J.: 寻找可理解的共识算法。收录于：2014年 USENIX 年会技术会议论文集。第305–320页
    (2014)'
- en: '[12] OpenAI: Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] OpenAI: Gpt-4 技术报告。arXiv 预印本 arXiv:2303.08774 (2023)'
- en: '[13] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin,
    P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al.: Training language models
    to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 (2022)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin,
    P., Zhang, C., Agarwal, S., Slama, K., Ray, A., 等：训练语言模型以遵循带有人类反馈的指令。arXiv 预印本
    arXiv:2203.02155 (2022)'
- en: '[14] Patel, A., Bhattamishra, S., Goyal, N.: Are NLP models really able to
    solve simple math word problems? In: Proceedings of the 2021 Conference of the
    North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies. pp. 2080–2094 (2021)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Patel, A., Bhattamishra, S., Goyal, N.: 自然语言处理模型真的能解决简单的数学文字问题吗？收录于：2021年北美计算语言学协会年会：人类语言技术会议论文集。第2080–2094页
    (2021)'
- en: '[15] Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K.,
    Zettlemoyer, L.: Deep contextualized word representations. In: ACL. pp. 2227–2237
    (2018). https://doi.org/10.18653/v1/N18-1202'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K.,
    Zettlemoyer, L.: 深度上下文化词表示。收录于：ACL。第2227–2237页 (2018). https://doi.org/10.18653/v1/N18-1202'
- en: '[16] Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., Catanzaro,
    B.: Megatron-lm: Training multi-billion parameter language models using model
    parallelism. arXiv preprint arXiv:1909.08053 (2019)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., Catanzaro,
    B.: Megatron-lm：使用模型并行训练多十亿参数语言模型。arXiv 预印本 arXiv:1909.08053 (2019)'
- en: '[17] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A.,
    Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al.: Lamda: Language models
    for dialog applications. arXiv preprint arXiv:2201.08239 (2022)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A.,
    Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., 等：Lamda: 对话应用的语言模型。arXiv 预印本
    arXiv:2201.08239 (2022)'
- en: '[18] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al.: Llama: Open and efficient
    foundation language models. arXiv preprint arXiv:2302.13971 (2023)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix,
    T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., 等：Llama: 开放且高效的基础语言模型。arXiv
    预印本 arXiv:2302.13971 (2023)'
- en: '[19] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., Zhou, D.: Self-consistency improves chain of thought reasoning in language
    models (2023)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., Zhou, D.: 自我一致性改善语言模型中的思维链推理 (2023)'
- en: '[20] Wankhade, M., Rao, A.C.S., Kulkarni, C.: A survey on sentiment analysis
    methods, applications, and challenges. Artificial Intelligence Review 55(7), 5731–5780
    (2022)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Wankhade, M., Rao, A.C.S., Kulkarni, C.: 关于情感分析方法、应用和挑战的调查。人工智能评论 55(7),
    5731–5780 (2022)'
- en: '[21] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., Zhou, D.:
    Chain of thought prompting elicits reasoning in large language models. arXiv preprint
    arXiv:2201.11903 (2022)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., Zhou, D.:
    思维链提示在大型语言模型中引发推理。arXiv 预印本 arXiv:2201.11903 (2022)'
- en: '[22] Xu, Y., Zhu, C., et al.: Human parity on commonsenseQA: Augmenting self-attention
    with external attention. arXiv preprint arXiv:2112.03254 (2022)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Xu, Y., Zhu, C., 等：在 commonsenseQA 上达到人类水平：通过外部注意力增强自注意力。arXiv 预印本 arXiv:2112.03254
    (2022)'
- en: '[23] Yadav, D., Desai, J., Yadav, A.K.: Automatic text summarization methods:
    A comprehensive review. arXiv preprint arXiv:2204.01849 (2022)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Yadav, D., Desai, J., Yadav, A.K.: 自动文本摘要方法：全面综述。arXiv 预印本 arXiv:2204.01849
    (2022)'
- en: '[24] Zaib, M., Zhang, W.E., Sheng, Q.Z., Mahmood, A., Zhang, Y.: Conversational
    question answering: A survey. Knowledge and Information Systems 64(12), 3151–3195
    (2022)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Zaib, M., Zhang, W.E., Sheng, Q.Z., Mahmood, A., Zhang, Y.: 对话式问答：调查。知识与信息系统
    64(12), 3151–3195 (2022)'
- en: '[25] Zhao, W.X., Zhou, K., et al.: A survey of large language models. arXiv
    preprint arXiv:2303.18223 (2023)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Zhao, W.X., Zhou, K., 等：大型语言模型的调查。arXiv 预印本 arXiv:2303.18223 (2023)'
- en: '[26] Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: Federated
    learning with non-iid data. arXiv preprint arXiv:1806.00582 (2018)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: 非独立同分布数据下的联邦学习。arXiv
    预印本 arXiv:1806.00582 (2018)'
