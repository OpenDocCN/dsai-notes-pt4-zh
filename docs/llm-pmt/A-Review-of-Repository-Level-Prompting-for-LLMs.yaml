- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:47:34'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:47:34
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Review of Repository Level Prompting for LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对于大语言模型（LLMs）的代码库级提示的综述
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10101](https://ar5iv.labs.arxiv.org/html/2312.10101)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10101](https://ar5iv.labs.arxiv.org/html/2312.10101)
- en: Douglas Schonholtz
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 道格拉斯·肖恩霍尔茨
- en: Northeastern University, Boston, Masssachusetts, 02115
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Northeastern University, Boston, Masssachusetts, 02115
- en: schonholtz.d@northeastern.edu
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: schonholtz.d@northeastern.edu
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: As coding challenges become more complex, recent advancements in Large Language
    Models (LLMs) have led to notable successes, such as achieving a 94.6% solve rate
    on the HumanEval benchmark. Concurrently, there is an increasing commercial push
    for repository-level inline code completion tools, such as GitHub Copilot and
    Tab Nine, aimed at enhancing developer productivity. This paper delves into the
    transition from individual coding problems to repository-scale solutions, presenting
    a thorough review of the current literature on effective LLM prompting for code
    generation at the repository level. We examine approaches that will work with
    black-box LLMs such that they will be useful and applicable to commercial use
    cases, and their applicability in interpreting code at a repository scale. We
    juxtapose the Repository-Level Prompt Generation technique with RepoCoder, an
    iterative retrieval and generation method, to highlight the trade-offs inherent
    in each approach and to establish best practices for their application in cutting-edge
    coding benchmarks. The interplay between iterative refinement of prompts and the
    development of advanced retrieval systems forms the core of our discussion, offering
    a pathway to significantly improve LLM performance in code generation tasks. Insights
    from this study not only guide the application of these methods but also chart
    a course for future research to integrate such techniques into broader software
    engineering contexts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着编码挑战变得越来越复杂，大语言模型（LLMs）的最新进展取得了显著的成功，例如在 HumanEval 基准上达到 94.6% 的解决率。同时，市场上对代码库级内联代码补全工具的需求也在增加，例如
    GitHub Copilot 和 Tab Nine，这些工具旨在提升开发者的生产力。本文探讨了从个别编码问题到代码库规模解决方案的过渡，全面回顾了当前关于有效
    LLM 提示的文献，以用于代码生成的代码库级应用。我们考察了适用于黑箱 LLM 的方法，使其能够在商业用例中有效应用，并在代码库规模下进行解释。我们将代码库级提示生成技术与
    RepoCoder 迭代检索和生成方法进行对比，以突出每种方法的权衡，并建立其在前沿编码基准中的应用最佳实践。提示的迭代优化与高级检索系统的发展之间的互动构成了我们讨论的核心，为显著提高
    LLM 在代码生成任务中的表现提供了一条路径。本研究的见解不仅指导这些方法的应用，还为未来的研究在更广泛的软件工程背景中整合这些技术绘制了路线图。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The advent of Large Language Models (LLMs) has revolutionized the field of automated
    code generation, offering solutions that range from simple code snippets to complex
    blocks that fit into larger systems. The HumanEval benchmark, which emerged as
    a standard for evaluating the capabilities of these models, has shown that LLMs
    can achieve high success rates, often outperforming traditional programming approaches
    (?). However, as we shift from isolated challenges to the nuanced realm of repository-level
    development, new complexities arise. Developers don’t just need code that works;
    they need code that integrates seamlessly with existing codebases—a challenge
    that requires a deep understanding of context, dependencies, and the idiosyncrasies
    of each repository.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）的出现彻底改变了自动代码生成领域，提供了从简单代码片段到适用于更大系统的复杂代码块的解决方案。HumanEval 基准，作为评估这些模型能力的标准，显示出
    LLMs 能够实现较高的成功率，通常优于传统编程方法（？）。然而，当我们从孤立的挑战转向代码库级的复杂领域时，新的复杂性随之而来。开发者不仅需要能正常工作的代码，还需要能够与现有代码库无缝集成的代码——这需要对上下文、依赖关系以及每个代码库的特殊性有深入的理解。
- en: The concept of Retrieval Augmented Generation (RAG) presents a paradigm shift
    in this landscape. By leveraging existing code in a repository as a knowledge
    base, RAG enables LLMs to generate more accurate and contextually relevant code
    completions. This process is akin to a seasoned developer recalling similar problems
    and solutions from past experiences to tackle current coding challenges.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）的概念在这一领域中带来了范式转变。通过利用代码库中现有的代码作为知识库，RAG 使 LLMs 能够生成更准确、更具上下文相关性的代码补全。这一过程类似于经验丰富的开发者回忆过去经历中的类似问题和解决方案，以应对当前的编码挑战。
- en: Furthering this idea, the integration of another LLM for the purpose of prompt
    generation opens up new avenues for contextual understanding. It allows for a
    more dynamic interaction with the codebase, where the LLM not only generates code
    but also assists in identifying the most relevant pieces of information to guide
    its generation process. This meta-level operation stands to significantly enhance
    the model’s performance by refining its focus and adapting its output to the specific
    context of the repository in question.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在此基础上，集成另一LLM以生成提示为目的，开辟了新的上下文理解途径。它允许与代码库进行更动态的交互，其中LLM不仅生成代码，还协助识别指导其生成过程的最相关信息。这种元级操作有望通过精炼焦点并将输出调整到特定存储库的上下文中，显著提升模型的性能。
- en: 'This paper provides an in-depth analysis of these innovative approaches, particularly
    focusing on their effectiveness at the repository level—a scale that presents
    a more realistic and challenging scenario for LLMs. We explore two pioneering
    methods: the Repository-Level Prompt Generation technique and RepoCoder, an iterative
    retrieval and generation method. By juxtaposing these methodologies, we aim to
    uncover the trade-offs they present and establish a set of best practices for
    leveraging LLMs in repository-level code generation. Our review does not merely
    highlight their potential but also underscores the necessity for sophisticated
    retrieval systems that can keep pace with the evolving complexity of software
    development tasks.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提供了对这些创新方法的深入分析，特别关注它们在存储库级别的有效性——这是一个对LLM提出更实际和挑战性的场景的尺度。我们探讨了两种开创性方法：存储库级提示生成技术和RepoCoder，一种迭代检索和生成方法。通过对比这些方法，我们旨在揭示它们的权衡，并建立一套最佳实践，以利用LLM进行存储库级代码生成。我们的回顾不仅强调了它们的潜力，还突出了对复杂检索系统的需求，以跟上软件开发任务日益复杂的步伐。
- en: As we navigate through these methodologies, our narrative will unravel the intricate
    tapestry of LLM capabilities, their limitations, and the prospects of combining
    various strategies to create a more potent tool for developers. The synthesis
    of iterative refinement of prompts with advanced retrieval systems promises a
    future where LLMs could become indispensable assistants to programmers, offering
    intelligent suggestions that streamline the development process and elevate the
    quality of software engineering.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入这些方法论的过程中，我们的叙述将揭示LLM能力的复杂图景、它们的局限性以及将各种策略结合起来创造更强大工具的前景。迭代优化提示与高级检索系统的合成预示着LLM未来可能成为程序员不可或缺的助手，提供智能建议，以简化开发过程并提升软件工程的质量。
- en: (?), (?), (?)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (?), (?), (?)
- en: 2 Repository Level Retrieval Techniques
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 存储库级检索技术
- en: In order to be able to make good code completions at the repository level, an
    LLM must be prompted with relevant context so that it can infer what code it should
    generate.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在存储库级别进行良好的代码补全，LLM必须提供相关的上下文提示，以便推断应生成什么代码。
- en: RepoCoder(?) uses BM25(?), a sparse retrieval technique, across sliding windows
    of code to retrieve code relevant to the the generated code, and the code around
    the hole the generated code fills. Then that generation is used as a query to
    find other relevant code with the same BM25/bag of words retrieval system. This
    can then be done iteratively potentially improving every time this process is
    run. This process is illustrated in figure [1](#S2.F1 "Figure 1 ‣ 2 Repository
    Level Retrieval Techniques ‣ A Review of Repository Level Prompting for LLMs")
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: RepoCoder(?) 使用 BM25(?)，一种稀疏检索技术，通过滑动窗口检索与生成代码相关的代码，以及生成代码填补的空洞周围的代码。然后，这一生成结果作为查询，用相同的BM25/词袋检索系统找到其他相关代码。这一过程可以迭代进行，每次运行可能都会改善。此过程如图
    [1](#S2.F1 "图 1 ‣ 2 存储库级检索技术 ‣ 对LLM存储库级提示的回顾") 所示。
- en: '![Refer to caption](img/1a4581c2e77fe7755833f3d6f3652b8e.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1a4581c2e77fe7755833f3d6f3652b8e.png)'
- en: 'Figure 1: The iterative process of the RepoCoder framework. As seen in RepoCoder
    (?)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：RepoCoder框架的迭代过程。如RepoCoder (?) 所示。
- en: 'The generated code can be modeled with this equation: $\hat{Y}^{i}=M(C_{\text{ret}}^{i},X).$
    is the repository context which is initially empty.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的代码可以通过以下方程建模：$\hat{Y}^{i}=M(C_{\text{ret}}^{i},X).$ 其中 $C_{\text{ret}}^{i}$
    是最初为空的存储库上下文。
- en: The context retrieval process can be modeled with this equation. $C_{\text{ret}}^{i}=R(C_{\text{repo}},X,\hat{Y}^{i-1}).$
    is iteration i of context retrieval.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文检索过程可以用这个方程建模。 $C_{\text{ret}}^{i}=R(C_{\text{repo}},X,\hat{Y}^{i-1}).$ 是上下文检索的第
    i 次迭代。
- en: In contrast, Repo Level Prompting presents a significantly more complicated
    approach as it’s paper focuses on optimizing retrieval instead of optimizing the
    iteration process with an existing retrieval method.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，Repo Level Prompting 提出了一个显著更复杂的方法，因为它的论文专注于优化检索，而不是使用现有的检索方法优化迭代过程。
- en: The repository-level Prompt Generation paper compiles code prompts from various
    relevant code segments, which are then processed by the OpenAI Codex model. The
    effectiveness of each prompt is assessed based on whether it successfully completes
    the code gaps, marked by a binary score indicating success or failure. All of
    the prompting options are indexed into a vector, for a given repository completion
    the ground truth vector is defined as a one in each index of that vector where
    the associated prompt resulted in a successful generation. (?).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 存储库级提示生成论文编译了来自各种相关代码段的代码提示，然后由 OpenAI Codex 模型处理。每个提示的有效性是基于它是否成功完成了代码空白，由一个二元分数表示成功或失败。所有提示选项都被索引到一个向量中，对于给定的存储库完成，真实向量在该向量的每个索引中定义为一，其中相关提示导致成功生成。（？）。
- en: This can then be used to build a loss function which will allow classification
    of these prompts as useful or not in arbitrary code contexts. The loss function
    for the model is an average of the individual losses across code holes, formalized
    in equation [1](#S2.E1 "In 2 Repository Level Retrieval Techniques ‣ A Review
    of Repository Level Prompting for LLMs").
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以用来构建一个损失函数，从而在任意代码上下文中对这些提示进行有用性分类。模型的损失函数是跨代码空白的个体损失的平均值，形式化在方程 [1](#S2.E1
    "在 2 存储库级检索技术 ‣ 对存储库级提示的回顾") 中。
- en: '|  | $1$2 |  | (1) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (1) |'
- en: where $M^{h}=\sum_{p}r_{p}^{h}$ signifies the binary cross-entropy loss (?).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $M^{h}=\sum_{p}r_{p}^{h}$ 表示二元交叉熵损失（？）。
- en: 'To predict optimal prompts for code generation by LLMs, two models are constructed:
    RLPG-H, a two-layer dense network featuring a ReLU non-linearity, and RLPG-R,
    which utilizes a single multi-head attention layer. Both of these models are placed
    on top of frozen embedding models and then trained to attempt to classify the
    optimal prompts to choose given the missing code context. Despite RLPG-R using
    multi-head attention, it is less performant than the dense model and it underperforms
    compared to RLPG-H.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测 LLMs 生成代码的最佳提示，构建了两个模型：RLPG-H，一个具有 ReLU 非线性的两层密集网络，以及 RLPG-R，它使用了一个多头注意力层。这两个模型都置于冻结的嵌入模型之上，然后进行训练，试图对给定缺失代码上下文的最佳提示进行分类。尽管
    RLPG-R 使用了多头注意力，但其性能不如密集模型，并且相较于 RLPG-H 表现更差。
- en: The prompts generated are based off of the current, parent, children, imported,
    fuzzy matched, and sibling classes, methods, and files. Then these chunks of context
    are added above the default completion in no particular order. They also are truncated
    as necessary from the front or back to fit into the context window.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的提示基于当前、父类、子类、导入、模糊匹配和兄弟类、方法和文件。然后，这些上下文片段被添加到默认完成上方，顺序不特定。它们还根据需要从前面或后面截断，以适应上下文窗口。
- en: 3 Datasets
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 个数据集
- en: The datasets used were different. RepoCoder uses a collection of repositories
    they extracted via the GitHub API as seen in Table [1](#S3.T1 "Table 1 ‣ 3 Datasets
    ‣ A Review of Repository Level Prompting for LLMs").
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的数据集是不同的。RepoCoder 使用了一组通过 GitHub API 提取的存储库，如表 [1](#S3.T1 "表 1 ‣ 3 个数据集 ‣
    对存储库级提示的回顾") 所示。
- en: 'Table 1: Function Body Completion Dataset and Line and API Invocation Completion
    Datasets. F is the total number of python files, while N is the number of extracted
    Samples.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 函数体完成数据集和行及 API 调用完成数据集。F 是 Python 文件的总数，而 N 是提取的样本数。'
- en: '| Name | License | Created | F. | N. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 许可证 | 创建日期 | F. | N. |'
- en: '| imagen | MIT License | 2022-05-23 | 14 | 67 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| imagen | MIT License | 2022-05-23 | 14 | 67 |'
- en: '| tracr | Apache V2.0 | 2022-12-01 | 56 | 146 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| tracr | Apache V2.0 | 2022-12-01 | 56 | 146 |'
- en: '| lightmmmm | Apache V2.0 | 2022-10-10 | 36 | 64 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| lightmmmm | Apache V2.0 | 2022-10-10 | 36 | 64 |'
- en: '| inspection | Apache V2.0 | 2022-05-05 | 16 | 32 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| inspection | Apache V2.0 | 2022-05-05 | 16 | 32 |'
- en: '| omnivore | CC BY-NC 4.0 | 2022-01-20 | 66 | 22 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| omnivore | CC BY-NC 4.0 | 2022-01-20 | 66 | 22 |'
- en: '| redframes | BSD-2-Clause | 2022-08-21 | 49 | 42 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| redframes | BSD-2-Clause | 2022-08-21 | 49 | 42 |'
- en: '| Line and API Invocation Completion Datasets |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 行和 API 调用完成数据集 |'
- en: '| rl | MIT License | 2022-02-01 | 165 | 400 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| rl | MIT License | 2022-02-01 | 165 | 400 |'
- en: '| ACE | Apache V2.0 | 2022-11-23 | 425 | 400 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| ACE | Apache V2.0 | 2022-11-23 | 425 | 400 |'
- en: '| vizier | Apache V2.0 | 2022-02-16 | 188 | 400 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| vizier | Apache V2.0 | 2022-02-16 | 188 | 400 |'
- en: '| fortuna | Apache V2.0 | 2022-11-17 | 168 | 400 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| fortuna | Apache V2.0 | 2022-11-17 | 168 | 400 |'
- en: '| evaluate | Apache V2.0 | 2022-03-30 | 180 | 400 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| evaluate | Apache V2.0 | 2022-03-30 | 180 | 400 |'
- en: '| diffusers | Apache V2.0 | 2022-05-30 | 305 | 400 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| diffusers | Apache V2.0 | 2022-05-30 | 305 | 400 |'
- en: '| nerfstudio | Apache V2.0 | 2022-05-31 | 357 | 400 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| nerfstudio | Apache V2.0 | 2022-05-31 | 357 | 400 |'
- en: '| FedScope | Apache V2.0 | 2022-03-24 | 443 | 400 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| FedScope | Apache V2.0 | 2022-03-24 | 443 | 400 |'
- en: Meanwhile, Repo Level Prompting used repositories from Google as they feared
    that GitHub’s data was used for training OpenAI’s Codex model that they were testing.
    These repositories can be found in Figure [2](#S3.F2 "Figure 2 ‣ 3 Datasets ‣
    A Review of Repository Level Prompting for LLMs"). This is a collection of Java
    repositories. It is worth noting, that the dataset for repo level prompting is
    far larger and more comprehensive, as the number of total holes there is much
    larger than the number of samples found in the number of samples extracted from
    RepoCoder.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，Repo Level Prompting 使用了来自 Google 的代码库，因为他们担心 GitHub 的数据被用来训练他们正在测试的 OpenAI
    Codex 模型。这些代码库可以在图 [2](#S3.F2 "图 2 ‣ 3 个数据集 ‣ 对 LLM 的 Repository Level Prompting
    的回顾") 中找到。这是一个 Java 代码库的集合。值得注意的是，repo level prompting 的数据集要大得多且更全面，因为那里的总漏洞数远远大于从
    RepoCoder 提取的样本数量。
- en: '![Refer to caption](img/619a6db8b2aa2cd6ae0c6cc691823aed.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/619a6db8b2aa2cd6ae0c6cc691823aed.png)'
- en: 'Figure 2: Repositories used in RepoLevel Prompting'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: RepoLevel Prompting 使用的代码库'
- en: 'Table 2: Repo Level Prompting Dataset'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: Repo Level Prompting 数据集'
- en: '| Feature | Train | Val | Test | Total |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 训练 | 验证 | 测试 | 总计 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| # Repositories | 19 | 14 | 14 | 47 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| # 代码库 | 19 | 14 | 14 | 47 |'
- en: '| # Files | 2655 | 1060 | 1308 | 4757 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| # 文件 | 2655 | 1060 | 1308 | 4757 |'
- en: '| # Holes | 92721 | 48548 | 48288 | 189557 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| # 漏洞 | 92721 | 48548 | 48288 | 189557 |'
- en: For Repo Level Prompting you can also see the total number of holes and breakdown
    by train, validation and test splits for all repositories in Table [2](#S3.T2
    "Table 2 ‣ 3 Datasets ‣ A Review of Repository Level Prompting for LLMs")
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Repo Level Prompting，您还可以在表 [2](#S3.T2 "表 2 ‣ 3 个数据集 ‣ 对 LLM 的 Repository
    Level Prompting 的回顾") 中查看所有代码库的总漏洞数以及按训练、验证和测试划分的情况。
- en: 4 Comparing Oracle Retrieval Systems
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 比较 Oracle 检索系统
- en: Both RepoCoder, and RepoLevel Prompting compare themselves to optimal oracle
    retrieval systems. In RepoCoder, this means doing the retrieval based on the ground
    truth code to fill the hole that the LLM normally would first attempt to hallucinate
    before doing it’s first round of retrieval. In RepoLevel prompting, this means
    for their vector Y of possible successful prompts, using that set of optimal working
    prompts to search for code. In both cases, this creates an upper bound showing
    the limit of capability of these methods.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: RepoCoder 和 RepoLevel Prompting 都将自己与最佳的 oracle 检索系统进行比较。在 RepoCoder 中，这意味着根据真实的代码进行检索，以填补
    LLM 通常会首先尝试生成的漏洞，然后再进行第一次检索。在 RepoLevel Prompting 中，这意味着对于他们可能成功的提示向量 Y，使用那组最佳的有效提示来搜索代码。在这两种情况下，这都创建了一个上限，展示了这些方法的能力极限。
- en: 'Table 3: Performance of the oracle relative to Codex for repo level prompting.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: Oracle 相对于 Codex 的 repo level prompting 性能。'
- en: '| Split | SR Codex(%) | SR Oracle(%) | Rel. ↑Codex(%) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 划分 | SR Codex(%) | SR Oracle(%) | 相对 ↑Codex(%) |'
- en: '| --- | --- | --- | --- |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Train | 59.78 | 80.29 | 34.31 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 训练 | 59.78 | 80.29 | 34.31 |'
- en: '| Val | 62.10 | 79.05 | 27.28 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 验证 | 62.10 | 79.05 | 27.28 |'
- en: '| Test | 58.73 | 79.63 | 35.58 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 测试 | 58.73 | 79.63 | 35.58 |'
- en: You can see the effectiveness of the oracle and the relative improvement for
    it in Repo Level Prompting in Table [3](#S4.T3 "Table 3 ‣ 4 Comparing Oracle Retrieval
    Systems ‣ A Review of Repository Level Prompting for LLMs"). You can find a breakdown
    of how the oracle does for RepoCoder in a later set of results tables. The most
    important take away from these though is that the oracle shows a potential upper
    bound with the codex model for Repo Level Prompting of 35.48% on the test set.
    While RepoCoder shows up to a 90% relative performance improvement on some function
    completion tests and a 45% improvement on the exact match benchmark with GPT-3.5
    when compared to in-file prompting. These methods will be expanded on more in
    the Validation of Code Generation section where we cover results.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在表[3](#S4.T3 "表3 ‣ 4 比较Oracle检索系统 ‣ LLMs的仓库级提示审查")中看到oracle的有效性及其在Repo Level
    Prompting中的相对改进。你可以在后续的结果表中找到oracle在RepoCoder中的表现细分。最重要的结论是，oracle在测试集上显示了Codex模型在Repo
    Level Prompting中的潜在上限为35.48%。而RepoCoder在某些函数完成测试中显示了高达90%的相对性能提升，以及在与GPT-3.5进行精确匹配基准测试时的45%改进，相较于文件内提示。这些方法将在代码生成验证部分进行更详细的扩展。
- en: 5 Locations of Text in Repositories for Optimal Retrieval
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仓库中文本的5个位置以实现最佳检索
- en: One of the crucial findings of both RepoCoder and Repo Level Prompting is where
    the critical code is stored. This information can be used to build future potentially
    more effective retrieval systems to power these code generating LLMs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: RepoCoder和Repo Level Prompting的一个关键发现是关键代码的存储位置。这些信息可以用来构建未来潜在的更有效的检索系统，以支持这些代码生成LLMs。
- en: RepoCoder’s breakdown in Figure [4](#S5.F4 "Figure 4 ‣ 5 Locations of Text in
    Repositories for Optimal Retrieval ‣ A Review of Repository Level Prompting for
    LLMs") shows that fuzzy import and names are extremely valuable with usage marking
    in the 50 and 80 percentiles for cases where the repocoder method beat the naive
    in file completion method.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](#S5.F4 "图4 ‣ 仓库中文本的5个位置以实现最佳检索 ‣ LLMs的仓库级提示审查")中的RepoCoder的细分显示，模糊导入和名称在用法标记中的50和80百分位非常有价值，对于repoCoder方法在文件完成方法中胜过naive的情况。
- en: '![Refer to caption](img/eaa7c53f6f3732efb58c63812fa1be67.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eaa7c53f6f3732efb58c63812fa1be67.png)'
- en: 'Figure 3: Locations of retrieved code snippets when the Oracle/RepoCoder method
    outperforms the In-File completion method using GPT-3.5-Turbo on the line and
    API completion datasets'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：当Oracle/RepoCoder方法在行和API完成数据集上使用GPT-3.5-Turbo优于文件完成方法时检索的代码片段位置
- en: We can contrast the findings of RepoCoder with those of Repo Level Prompting
    in Figure [4](#S5.F4 "Figure 4 ‣ 5 Locations of Text in Repositories for Optimal
    Retrieval ‣ A Review of Repository Level Prompting for LLMs") and in Figure [5](#S5.F5
    "Figure 5 ‣ 5 Locations of Text in Repositories for Optimal Retrieval ‣ A Review
    of Repository Level Prompting for LLMs").
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将RepoCoder的发现与图[4](#S5.F4 "图4 ‣ 仓库中文本的5个位置以实现最佳检索 ‣ LLMs的仓库级提示审查")和图[5](#S5.F5
    "图5 ‣ 仓库中文本的5个位置以实现最佳检索 ‣ LLMs的仓库级提示审查")中Repo Level Prompting的发现进行对比。
- en: '![Refer to caption](img/130d8c8e907da83f29ffd12fbc1a0864.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/130d8c8e907da83f29ffd12fbc1a0864.png)'
- en: 'Figure 4: Mean success rates of different prompt sources when they are applicable.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：不同提示源适用时的平均成功率。
- en: '![Refer to caption](img/84e9ac16f8d02308b58059e8695050d8.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/84e9ac16f8d02308b58059e8695050d8.png)'
- en: 'Figure 5: (Left) Normalized success rate of prompt sources when applicable,
    (Right) Normalized success rate of prompt context types when applicable'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：（左）适用时提示源的标准化成功率，（右）适用时提示上下文类型的标准化成功率
- en: 5.1 Short Hand File Source References
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 简写文件源参考
- en: To understand these references we also have to understand these short hand labels.
    They are broken out for convenience below.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些参考，我们还必须理解这些简写标签。它们为方便起见在下方进行了详细说明。
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Current: take code from the current file excluding the contents of the target
    hole. The current file is the file that contains the target hole. The code in
    the current file (e.g. the lines after the hole position) can be very useful in
    predicting the target hole.'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当前：从当前文件中提取代码，但不包括目标孔的内容。当前文件是包含目标孔的文件。当前文件中的代码（例如，孔位置之后的行）在预测目标孔时非常有用。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Parent Class: take code from the file that contains the parent of the class
    to which the target hole belongs. The intuition behind this is to account for
    cases where a method present in the parent class is invoked in the current file
    (i.e. the child class).'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 父类：从包含目标空洞所属类的父类的文件中获取代码。这样做的直觉是考虑到在当前文件（即子类）中调用父类中的方法的情况。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Import: take code from the import files used in the current file. The dependencies
    specified via imports can provide useful cues to predict the target hole.'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导入：从当前文件中使用的导入文件中获取代码。通过导入指定的依赖项可以提供有用的线索来预测目标空洞。
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sibling: take code from the files that are in the same directory as the current
    file. Files in the same directory tend to share code variables (e.g. identifiers).'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 兄弟文件：从与当前文件在同一目录中的文件中获取代码。同一目录中的文件往往共享代码变量（例如标识符）。
- en: •
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Similar Name: take code from files that have a similar name as the current
    file. Similar names are determined by splitting the file name based on underscore
    or camel-case formatting and then matching parts of the filename. If one or more
    parts matches, two files are considered to have similar names. The intuition behind
    this is that software developers tend to name files based on the functionality
    of the code written in that file. Therefore, a similar name file might contain
    some portion of the code that is common with the current file and hence might
    be useful for predicting the target hole.'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相似名称：从具有与当前文件相似名称的文件中获取代码。相似名称是通过基于下划线或驼峰命名格式拆分文件名，然后匹配文件名的部分来确定的。如果一个或多个部分匹配，则两个文件被认为具有相似名称。这种做法的直觉是软件开发人员倾向于根据文件中编写的代码的功能来命名文件。因此，具有相似名称的文件可能包含与当前文件共享的某些代码片段，因此可能对预测目标空洞有用。
- en: •
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Child Class: take code from files that have the current file as their parent
    class file.'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 子类：从将当前文件作为其父类文件的文件中获取代码。
- en: •
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Import of Parent Class: take code from the import files used in the parent
    class files.'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 父类导入：从父类文件中使用的导入文件中获取代码。
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Import of Sibling: take code from the import files used in the sibling files.'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 兄弟文件导入：从兄弟文件中使用的导入文件中获取代码。
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Import of Similar Name: take code from the import files used in the similar
    name files.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相似名称导入：从具有相似名称的文件中的导入文件中获取代码。
- en: •
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Import of Child Class: take code from the import files used in the child class
    files.'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 子类导入：从子类文件中使用的导入文件中获取代码。
- en: 5.2 Short Hand Data to be Extracted from Files
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 从文件中提取的简写数据
- en: To understand, the figure to the right in Figure 5, we have to understand this
    corresponding list as well.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解右侧的图5，我们必须理解这个相应的列表。
- en: •
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Post Lines (PL): Take all the lines after the target hole line till the end
    of the current file.'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 后续行（PL）：获取目标空洞行之后的所有行直到当前文件的末尾。
- en: •
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Identifiers (I): Take all the identifiers used in the prompt source.'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标识符（I）：获取提示源中使用的所有标识符。
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Type Identifiers (TI): Take all the type identifiers used in the prompt source.'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类型标识符（TI）：获取提示源中使用的所有类型标识符。
- en: •
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Field Declarations (FD): Take all the field declarations used in the prompt
    source.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 字段声明（FD）：获取提示源中使用的所有字段声明。
- en: •
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'String Literals (SL): Take all the string literals used in the prompt source.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 字符串文字（SL）：获取提示源中使用的所有字符串文字。
- en: •
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Method Names (MN): Take all the method names along with their signatures used
    in the prompt source.'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法名称（MN）：获取提示源中使用的所有方法名称及其签名。
- en: •
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Method Names and Bodies (MNB): Take all the method names along with their signatures
    and corresponding bodies used in the prompt source.'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法名称和主体（MNB）：获取提示源中使用的所有方法名称及其签名和对应的主体。
- en: 6 Validation of Code Generation
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 代码生成的验证
- en: RepoCoder evaluates their system on three separate benchmarks they build. The
    first benchmark was line completion, completing a single line in a repository.
    The second benchmark was function completion, where the model has to complete
    a function which has had some subset of its lines removed. The results for this
    benchmark can be seen in Table [4](#S6.T4 "Table 4 ‣ 6 Validation of Code Generation
    ‣ A Review of Repository Level Prompting for LLMs").
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: RepoCoder 在他们构建的三个独立基准上评估他们的系统。第一个基准是行补全，即在代码库中完成单行。第二个基准是函数补全，其中模型必须完成一个函数，该函数的一些行已被删除。该基准的结果可以在表[4](#S6.T4
    "表 4 ‣ 6 代码生成的验证 ‣ 对 LLM 代码库级提示的回顾")中查看。
- en: 'Table 4: Line Completion performance evaluation using RepoCoder for exact match
    (EM) and Normalized Edit Distance (NED)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：使用 RepoCoder 对准确匹配（EM）和标准化编辑距离（NED）进行的行完成性能评估
- en: '| Metric | Oracle | In-File | RepoCoder Iterations |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| Metric | Oracle | In-File | RepoCoder Iterations |'
- en: '| --- | --- | --- | --- |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  |  |  | 1 | 2 | 3 | 4 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 1 | 2 | 3 | 4 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-3.5-Turbo |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-Turbo |'
- en: '| --- |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| EM | 57.75 | 40.56 | 55.31 | 56.81 | 57.00 | 56.63 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| EM | 57.75 | 40.56 | 55.31 | 56.81 | 57.00 | 56.63 |'
- en: '| NED | 75.43 | 65.06 | 74.38 | 75.11 | 75.30 | 75.10 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| NED | 75.43 | 65.06 | 74.38 | 75.11 | 75.30 | 75.10 |'
- en: '| CodeGen-Mono-6B |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-Mono-6B |'
- en: '| EM | 48.81 | 34.56 | 45.81 | 47.06 | 47.75 | 47.44 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| EM | 48.81 | 34.56 | 45.81 | 47.06 | 47.75 | 47.44 |'
- en: '| NED | 71.02 | 60.67 | 69.21 | 70.10 | 70.73 | 70.19 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| NED | 71.02 | 60.67 | 69.21 | 70.10 | 70.73 | 70.19 |'
- en: '| CodeGen-Mono-2B |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-Mono-2B |'
- en: '| EM | 47.31 | 33.63 | 44.56 | 46.94 | 46.69 | 47.13 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| EM | 47.31 | 33.63 | 44.56 | 46.94 | 46.69 | 47.13 |'
- en: '| NED | 69.80 | 58.99 | 67.68 | 68.82 | 68.62 | 68.92 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| NED | 69.80 | 58.99 | 67.68 | 68.82 | 68.62 | 68.92 |'
- en: '| CodeGen-Mono-350M |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-Mono-350M |'
- en: '| EM | 45.19 | 29.56 | 41.88 | 43.06 | 43.94 | 43.06 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| EM | 45.19 | 29.56 | 41.88 | 43.06 | 43.94 | 43.06 |'
- en: '| NED | 67.20 | 55.39 | 65.05 | 65.66 | 65.97 | 65.62 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| NED | 67.20 | 55.39 | 65.05 | 65.66 | 65.97 | 65.62 |'
- en: The third benchmark was API invocation completion. This included 1046 and 1086
    samples that were run on GPT-3.5 Turbo and other smaller CodeGen models respectively.
    Where an api invocation was just an api that was invoked somewhere in the codebase
    and that was the code that had to be completed. All of these methods are then
    evaluated against an exact match metric, a metric to determine if the generated
    code matches character for character with the true expected code. They are then
    also tested with a normalized edit distance metric (NED), which is the Levenshtein
    distance(?) divided by the maximum character count between the generated code
    and the ground truth. You can see the results for this measurement in Table [5](#S6.T5
    "Table 5 ‣ 6 Validation of Code Generation ‣ A Review of Repository Level Prompting
    for LLMs").
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 第三项基准是 API 调用完成。这包括在 GPT-3.5 Turbo 和其他较小的 CodeGen 模型上运行的 1046 和 1086 个样本。API
    调用只是代码库中的一个 API 调用，代码必须完成。所有这些方法都通过精确匹配度量进行评估，该度量用于确定生成的代码是否与真实期望的代码逐字匹配。它们还通过标准化编辑距离度量（NED）进行测试，NED
    是生成代码和真实代码之间的 Levenshtein 距离除以最大字符数。您可以在表格 [5](#S6.T5 "Table 5 ‣ 6 Validation
    of Code Generation ‣ A Review of Repository Level Prompting for LLMs") 中查看此测量的结果。
- en: 'Table 5: API Invocation Completion performance evaluation using RepoCoder.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：使用 RepoCoder 对 API 调用完成进行的性能评估。
- en: '| Metric | Oracle | In-File | RepoCoder Iterations |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Metric | Oracle | In-File | RepoCoder Iterations |'
- en: '| --- | --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  |  |  | 1 | 2 | 3 | 4 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 1 | 2 | 3 | 4 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-3.5-Turbo |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-Turbo |'
- en: '| --- |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| EM | 50.13 | 34.06 | 47.69 | 49.19 | 49.44 | 49.56 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| EM | 50.13 | 34.06 | 47.69 | 49.19 | 49.44 | 49.56 |'
- en: '| NED | 74.50 | 63.22 | 73.63 | 74.43 | 74.59 | 74.48 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| NED | 74.50 | 63.22 | 73.63 | 74.43 | 74.59 | 74.48 |'
- en: '| CodeGen-Mono-6B |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-Mono-6B |'
- en: '| EM | 40.25 | 26.19 | 36.69 | 38.88 | 39.13 | 39.31 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| EM | 40.25 | 26.19 | 36.69 | 38.88 | 39.13 | 39.31 |'
- en: '| NED | 67.94 | 56.45 | 64.20 | 65.52 | 65.53 | 65.90 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| NED | 67.94 | 56.45 | 64.20 | 65.52 | 65.53 | 65.90 |'
- en: '| CodeGen-Mono-2B |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-Mono-2B |'
- en: '| EM | 39.44 | 25.44 | 35.44 | 37.56 | 38.44 | 38.25 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| EM | 39.44 | 25.44 | 35.44 | 37.56 | 38.44 | 38.25 |'
- en: '| NED | 66.78 | 56.88 | 63.47 | 64.15 | 64.53 | 64.60 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| NED | 66.78 | 56.88 | 63.47 | 64.15 | 64.53 | 64.60 |'
- en: '| CodeGen-Mono-350M |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-Mono-350M |'
- en: '| EM | 34.88 | 22.19 | 31.75 | 33.88 | 33.75 | 33.81 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| EM | 34.88 | 22.19 | 31.75 | 33.88 | 33.75 | 33.81 |'
- en: '| NED | 63.06 | 52.24 | 59.82 | 61.03 | 60.96 | 61.06 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| NED | 63.06 | 52.24 | 59.82 | 61.03 | 60.96 | 61.06 |'
- en: Both of these results rely heavily on the exact match and NED metric. Such evaluations,
    however, are limited by their syntactic focus, neglecting the semantic similarity
    vital for grasping the intended code functionality. Moreover, the approach does
    not consider anonymized variables common in arbitrary solutions, nor does it acknowledge
    various valid problem-solving methods.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个结果都严重依赖精确匹配和 NED 度量。然而，这种评估受限于其语法焦点，忽视了理解预期代码功能所必需的语义相似性。此外，该方法没有考虑在任意解决方案中常见的匿名变量，也没有承认各种有效的解决问题的方法。
- en: To mitigate these limitations, test case validation is also employed, though
    the methodology lacks a pre-and post-modification test state analysis, raising
    concerns about the integrity of the test cases and their coverage of the modified
    code. Meaning that verification that the tests pass before and after the code
    is implemented in the ground truth state, and that the unchanged code causes the
    modified tests to fail, as is described in other papers.(?). Despite these concerns,
    the pass rate of 44.6% in repository test cases reported by RepoCoder is promising,
    especially when juxtaposed with a mere 23.32% achievement through in-file retrieval.
    The improvements of 8% and 10% in exact and Levenshtein match scores over the
    baseline model further underscore the potential of the repo coder methodology.
    These results are shown in Table [6](#S6.T6 "Table 6 ‣ 6 Validation of Code Generation
    ‣ A Review of Repository Level Prompting for LLMs")
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解这些限制，还采用了测试用例验证，尽管该方法论缺乏修改前后的测试状态分析，这引发了对测试用例完整性及其对修改代码的覆盖范围的担忧。这意味着需要验证代码实施前后的测试是否通过，以及未修改的代码是否导致修改后的测试失败，这在其他文献中有所描述。尽管存在这些担忧，RepoCoder报告的44.6%的库测试用例通过率仍然是一个积极的信号，特别是与仅有23.32%的文件内检索成果相比。相较于基线模型，在精确匹配和Levenshtein匹配分数上分别提高了8%和10%进一步突显了repo
    coder方法的潜力。这些结果见于表[6](#S6.T6 "Table 6 ‣ 6 Validation of Code Generation ‣ A Review
    of Repository Level Prompting for LLMs")。
- en: 'Table 6: RepoCoder Pass Rate against unit tests.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：RepoCoder在单元测试中的通过率。
- en: '| N. | Oracle | In-File | RepoCoder Iterations |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| N. | Oracle | 文件内 | RepoCoder迭代 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  |  |  | 1 | 2 | 3 | 4 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 1 | 2 | 3 | 4 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 67 | 56.72 | 29.85 | 53.73 | 55.22 | 55.22 | 55.22 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 67 | 56.72 | 29.85 | 53.73 | 55.22 | 55.22 | 55.22 |'
- en: '| 146 | 43.84 | 27.40 | 41.78 | 43.84 | 44.52 | 44.52 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 146 | 43.84 | 27.40 | 41.78 | 43.84 | 44.52 | 44.52 |'
- en: '| 64 | 32.81 | 10.94 | 25.00 | 34.38 | 31.25 | 32.81 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 64 | 32.81 | 10.94 | 25.00 | 34.38 | 31.25 | 32.81 |'
- en: '| 32 | 34.38 | 28.13 | 34.38 | 37.50 | 34.38 | 34.38 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 32 | 34.38 | 28.13 | 34.38 | 37.50 | 34.38 | 34.38 |'
- en: '| 22 | 40.91 | 31.82 | 31.82 | 36.36 | 31.82 | 36.36 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 22 | 40.91 | 31.82 | 31.82 | 36.36 | 31.82 | 36.36 |'
- en: '| 42 | 38.10 | 9.52 | 28.57 | 38.10 | 38.10 | 38.10 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 42 | 38.10 | 9.52 | 28.57 | 38.10 | 38.10 | 38.10 |'
- en: '| 373 | 42.63 | 23.32 | 38.34 | 42.63 | 41.82 | 42.36 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 373 | 42.63 | 23.32 | 38.34 | 42.63 | 41.82 | 42.36 |'
- en: When we compare this to Repo Level Prompting, we can see that the NED relative
    comparison is comprable with a large 25% relative improvement to the baseline.
    You can see this in Table [7](#S6.T7 "Table 7 ‣ 6 Validation of Code Generation
    ‣ A Review of Repository Level Prompting for LLMs").
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将其与库级提示进行比较时，可以看到NED相对比较具有显著的25%相对改进。您可以在表[7](#S6.T7 "Table 7 ‣ 6 Validation
    of Code Generation ‣ A Review of Repository Level Prompting for LLMs")中看到这一点。
- en: 'Table 7: Normalized Edit Distance (NED) based performance evaluation for repo
    level prompting.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：基于NED的库级提示性能评估。
- en: '| Method | NED(%) | Rel. ↑(%) |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | NED（%） | 相对 ↑（%） |'
- en: '| --- | --- | --- |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Codex | 30.73 | - |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Codex | 30.73 | - |'
- en: '| RLPG-H | 22.55 | 26.62 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| RLPG-H | 22.55 | 26.62 |'
- en: '| RLPG-R | 23.00 | 25.14 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| RLPG-R | 23.00 | 25.14 |'
- en: You can also see the impact of each of their different retrieval models. It
    is worth noting that the file level BM25 is fairly good, but their RLPG-H is the
    highest performing strategy. Considering how performant the RLPG-BM25 model is,
    it is possible that taking the prompt generation strategy and doing a BM25 classification
    may be the optimal option in terms of latency, compute and developer time for
    many developers who rapidly want something that is highly performant. These results
    can be seen in [8](#S6.T8 "Table 8 ‣ 6 Validation of Code Generation ‣ A Review
    of Repository Level Prompting for LLMs").
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以看到它们不同检索模型的影响。值得注意的是，文件级BM25相当不错，但其RLPG-H是表现最好的策略。考虑到RLPG-BM25模型的性能，采用提示生成策略并进行BM25分类可能是许多开发者在延迟、计算和开发者时间方面的最佳选择，这些开发者急需高性能的解决方案。这些结果可以在[8](#S6.T8
    "Table 8 ‣ 6 Validation of Code Generation ‣ A Review of Repository Level Prompting
    for LLMs")中查看。
- en: 'Table 8: Comparison of methods for repo level prompting.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：库级提示方法比较。
- en: '| Method | Success Rate(%) | Rel. ↑(%) |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 成功率（%） | 相对 ↑（%） |'
- en: '| --- | --- | --- |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Codex (Chen et al., 2021) | 58.73 | - |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Codex (Chen et al., 2021) | 58.73 | - |'
- en: '| Oracle | 79.63 | 35.58 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Oracle | 79.63 | 35.58 |'
- en: '| Random | 58.13 | -1.02 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 随机 | 58.13 | -1.02 |'
- en: '| Random NN | 58.98 | 0.43 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 随机NN | 58.98 | 0.43 |'
- en: '| File-level BM25 | 63.14 | 7.51 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 文件级BM25 | 63.14 | 7.51 |'
- en: '| Identifier Usage (Random) | 64.93 | 10.55 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 标识符使用（随机） | 64.93 | 10.55 |'
- en: '| Identifier Usage (NN) | 64.91 | 10.52 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 标识符使用（NN） | 64.91 | 10.52 |'
- en: '| Fixed Prompt Proposal | 65.78 | 12.00 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 固定提示方案 | 65.78 | 12.00 |'
- en: '| RLPG-BM25 | 66.41 | 13.07 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| RLPG-BM25 | 66.41 | 13.07 |'
- en: '| RLPG-H | 68.51 | 16.65 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| RLPG-H | 68.51 | 16.65 |'
- en: '| RLPG-R | 67.80 | 15.44 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| RLPG-R | 67.80 | 15.44 |'
- en: '![Refer to caption](img/d6b9b6bd44c59f87a535bd91620080ea.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d6b9b6bd44c59f87a535bd91620080ea.png)'
- en: 'Figure 6: Variation of RLPG and Fixed Prompt Proposal with Num. attempts (k),
    when averaged over individual repositories (repo-wise) and all holes (hole-wise)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：RLPG 和固定提示方案与尝试次数（k）的变化，当在各个仓库（repo-wise）和所有洞（hole-wise）上取平均时
- en: Another experiment the authors of repo level prompting can be seen in Figure
    [6](#S6.F6 "Figure 6 ‣ 6 Validation of Code Generation ‣ A Review of Repository
    Level Prompting for LLMs"). There you can see the impact of choosing the top k
    prompt proposals the classifiers chose. This shows the steadily increasing performance
    with further prompts. This is somewhat surprising as you would expect truncation
    to fit everything into the context window or filling the context window to rapidly
    be a problem, but performance seems to only rise.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个实验可以在图 [6](#S6.F6 "图 6 ‣ 6 代码生成验证 ‣ 对 LLM 的 Repository Level Prompting 进行审查")中看到。可以看到分类器选择的前
    k 个提示建议的影响。这显示了随着进一步提示性能的稳步提高。这有些令人惊讶，因为你可能会期望截断将所有内容适配到上下文窗口中或填充上下文窗口会迅速成为问题，但性能似乎只在上升。
- en: 7 How to build an optimal prompting system
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 如何构建一个最佳提示系统
- en: Considering both of these papers, RepoCoder and Repository Level Prompt Generation
    can dramatically improve LLM performance when filling gaps in missing chunks of
    code. On top of that, while one method focuses on iteratively improving generation
    with retrieval results that are progressively more relevant with an off the shelf
    retriever, the other focused on building a better retrieval system by using a
    neural network to figure out exactly what code should be retrieved. It therefore,
    would make sense to attempt to combine these methods, especially since the sparse
    retrieval method performed so poorly in Repo Level Prompting. To accomplish this,
    one would have to train the neural network described in (?) but with the hole
    filled in and the generated code present. Then to iteratively rerun the generation
    with the context found.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这两篇论文，RepoCoder 和 Repository Level Prompt Generation 可以显著提高 LLM 在填补缺失代码片段时的表现。此外，虽然一种方法侧重于利用逐步相关的检索结果迭代改进生成，另一种方法则通过使用神经网络精确确定应该检索哪些代码来构建更好的检索系统。因此，尝试将这些方法结合起来是有意义的，尤其是考虑到稀疏检索方法在
    Repo Level Prompting 中表现不佳。为此，需要训练文献中描述的神经网络，但要填补空洞并提供生成的代码。然后，迭代地重新运行生成，并使用找到的上下文。
- en: 8 Future Work
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 未来工作
- en: On top of naively combining these two methods, another next step would be to
    integrate them into more complex use cases then doing auto-complete for a single
    line, function or API request in a repository. One such example of this is described
    in Software Engineering Bench(?). There they build an extremely robust benchmark
    where they collect 2,294 github issues that have associated pull requests and
    test cases. They verify that all of the test cases succeed after the pull request,
    and if you run the code before the pull request against the test, after the ground
    truth code is applied to the tests, that some of them fail. This handles several
    of the edge cases and problems seen in the RepoCoder Test Benchmark.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单地将这两种方法结合的基础上，另一个下一步是将它们整合到更复杂的使用案例中，然后对单行、函数或 API 请求进行自动补全。例如，软件工程基准中描述了一个这样的例子。在那里，他们构建了一个极其稳健的基准，收集了2,294个包含关联拉取请求和测试用例的
    GitHub 问题。他们验证所有测试用例在拉取请求之后是否成功，如果你在拉取请求之前运行代码并与测试进行对比，则在应用真实代码到测试之后，有些测试会失败。这处理了
    RepoCoder 测试基准中看到的多个边缘情况和问题。
- en: In SWE-Bench they provide several additional retrieval systems and tools, but
    their retrieval system only retrieves entire files which will mostly contain noise
    and not be useful. Also, many of the issues are very large and must be condensed
    in some meaningful way. Even their oracle retrieval system pulls in all of the
    full files that were modified instead of just subsets of them. Because of this
    the performance of the language models tested is extremely poor, Claude-2 solves
    4.8% and GPT-4 solves 1.7%. Considering Claude is significantly worse in other
    benchmarks like HumanEval, 71.2 compared to GPT-4’s 86%(?) (?). This is likely
    because of Claude’s long context length and the fact that their retrieval systems
    only support searching for entire files. Therefore, it likely would be possible
    to top their online leaderboard at SWE-Bench.com by combining these techniques
    of iterative generation and custom retrieval proposed in RepoCoder (?) and Repo
    Level Prompting (?) with their benchmark.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在SWE-Bench中，他们提供了若干额外的检索系统和工具，但他们的检索系统仅检索整个文件，这些文件大多包含噪音，并且没有用处。此外，许多问题非常庞大，必须以某种有意义的方式进行浓缩。即使是他们的oracle检索系统也会拉取所有被修改的完整文件，而不仅仅是其中的子集。因此，测试的语言模型的性能非常差，Claude-2解决了4.8%，GPT-4解决了1.7%。考虑到Claude在其他基准测试中的表现显著较差，比如HumanEval，71.2对比GPT-4的86%(?)
    (?). 这可能是因为Claude的长上下文长度和他们的检索系统仅支持搜索整个文件。因此，通过将RepoCoder (?) 和仓库级提示 (?) 中提出的迭代生成和自定义检索技术与他们的基准相结合，可能会有可能在SWE-Bench.com的在线排行榜上名列前茅。
- en: The next place to look after all of this may be to agent based LLM usage.(?)(?)(?)
    Building on Reflexion(?), or Language Agent Tree Search (?), the two top performing
    HumanEval papers which use a mix of reinforcement learning where the LLM is performing
    the actor and critic work and other methods like monte-carlo tree search to build
    optimal paths in traversing the problem space. Although these methods are currently
    computationally expensive and induce high latency, it is likely that as LLM inference
    time continues to fall that some combination of these methods will create the
    best performance and will still not force the user to wait for intractably long
    periods of time.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些之后，下一步可能是基于代理的LLM使用。(?)(?)(?) 以Reflexion(?) 或语言代理树搜索 (?) 为基础，这两篇表现最佳的HumanEval论文使用了一种结合了强化学习的混合方法，其中LLM执行演员和评论员工作，以及其他方法如蒙特卡罗树搜索，以建立遍历问题空间的最佳路径。尽管这些方法目前计算成本高且会引发高延迟，但随着LLM推理时间的不断下降，某种组合的这些方法可能会创造出最佳性能，同时仍然不会迫使用户等待过长时间。
- en: 9 Conclusion
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 结论
- en: 'This paper has provided a comprehensive review of two innovative approaches
    for repository-level prompting in Large Language Models: Repository-Level Prompt
    Generation and RepoCoder. Our analysis revealed that each method has its strengths
    and trade-offs. RepoCoder’s iterative retrieval and generation method excels in
    refining the prompt process, while Repository-Level Prompt Generation offers a
    robust framework for evaluating the effectiveness of various prompts against code
    completion tasks.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 本文全面回顾了两种针对大型语言模型的仓库级提示创新方法：仓库级提示生成和RepoCoder。我们的分析揭示了每种方法的优点和权衡。RepoCoder的迭代检索和生成方法在优化提示过程方面表现出色，而仓库级提示生成则提供了一个强大的框架，用于评估各种提示在代码完成任务中的有效性。
- en: We have demonstrated that by leveraging these methods, LLMs can be prompted
    to produce contextually relevant and syntactically coherent code completions that
    align with the complex requirements of real-world software repositories. The iterative
    nature of RepoCoder aligns well with the dynamic development environments, offering
    incremental improvements in code generation. Conversely, the classification-based
    approach of Repository-Level Prompt Generation provides a more direct path to
    identifying effective prompts, although it may require more extensive training
    data.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经证明，通过利用这些方法，LLM可以被提示生成符合现实世界软件仓库复杂要求的上下文相关和语法一致的代码补全。RepoCoder的迭代特性与动态开发环境非常契合，提供了代码生成的逐步改进。相反，仓库级提示生成的分类方法提供了一条更直接的路径来识别有效的提示，尽管它可能需要更多的训练数据。
- en: Our comparative analysis underscores the potential for integrating these strategies
    to harness their combined strengths. By doing so, we can address the current limitations
    of sparse retrieval methods and pave the way for more sophisticated code generation
    models. The promising results from applying these methods suggest that we are
    on the cusp of a new era in automated coding, where LLMs can not only assist in
    code generation but also evolve with the changing landscapes of software development.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的比较分析突显了整合这些策略以发挥其综合优势的潜力。通过这样做，我们可以解决稀疏检索方法的当前局限，并为更复杂的代码生成模型铺平道路。应用这些方法的有希望的结果表明，我们正处于自动编码的新纪元的边缘，其中大语言模型不仅可以协助代码生成，还能随着软件开发环境的变化而发展。
- en: As we look to the future, the integration of these methods into more complex
    systems, such as those described in Software Engineering Bench, represents the
    next frontier for LLMs. The potential for topping performance leaderboards by
    combining iterative generation with custom retrieval systems is substantial and
    warrants further exploration.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，将这些方法融入更复杂的系统，如《软件工程基准》中描述的系统，代表了大语言模型的下一个前沿。通过将迭代生成与定制检索系统相结合，有可能在性能排行榜上占据领先位置，这一潜力巨大，值得进一步探索。
- en: Ultimately, the journey towards fully autonomous and intelligent coding assistants
    is just beginning. We anticipate that as LLM inference times decrease, the amalgamation
    of agent-based LLM usage, reinforcement learning, and other advanced techniques
    will set new benchmarks in the field. The research community is encouraged to
    build upon the insights presented in this study to create LLMs that not only augment
    the coding process but also contribute to the art of programming itself.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '*最终*，完全自主和智能的编码助手的旅程才刚刚开始。我们预期随着大语言模型推理时间的减少，基于代理的大语言模型使用、强化学习和其他先进技术的结合将为该领域设定新的基准。研究界被鼓励基于本研究中提出的见解，创建不仅增强编码过程，还对编程艺术本身有所贡献的大语言模型。'
- en: References
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Amati 2009] Amati, G. 2009. BM25. Boston, MA: Springer US. 257–260.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Amati 2009] Amati, G. 2009. BM25. 波士顿, MA: Springer US. 257–260。'
- en: '[Anthropic 2023] Anthropic. 2023. Claude-2 technical report.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Anthropic 2023] Anthropic. 2023. Claude-2 技术报告。'
- en: '[Chen et al. 2021] Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; de Oliveira Pinto,
    H. P.; Kaplan, J.; Edwards, H.; Burda, Y.; Joseph, N.; Brockman, G.; Ray, A.;
    Puri, R.; Krueger, G.; Petrov, M.; Khlaaf, H.; Sastry, G.; Mishkin, P.; Chan,
    B.; Gray, S.; Ryder, N.; Pavlov, M.; Power, A.; Kaiser, L.; Bavarian, M.; Winter,
    C.; Tillet, P.; Such, F. P.; Cummings, D.; Plappert, M.; Chantzis, F.; Barnes,
    E.; Herbert-Voss, A.; Guss, W. H.; Nichol, A.; Paino, A.; Tezak, N.; Tang, J.;
    Babuschkin, I.; Balaji, S.; Jain, S.; Saunders, W.; Hesse, C.; Carr, A. N.; Leike,
    J.; Achiam, J.; Misra, V.; Morikawa, E.; Radford, A.; Knight, M.; Brundage, M.;
    Murati, M.; Mayer, K.; Welinder, P.; McGrew, B.; Amodei, D.; McCandlish, S.; Sutskever,
    I.; and Zaremba, W. 2021. Evaluating large language models trained on code.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chen 等 2021] Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; de Oliveira Pinto, H. P.;
    Kaplan, J.; Edwards, H.; Burda, Y.; Joseph, N.; Brockman, G.; Ray, A.; Puri, R.;
    Krueger, G.; Petrov, M.; Khlaaf, H.; Sastry, G.; Mishkin, P.; Chan, B.; Gray,
    S.; Ryder, N.; Pavlov, M.; Power, A.; Kaiser, L.; Bavarian, M.; Winter, C.; Tillet,
    P.; Such, F. P.; Cummings, D.; Plappert, M.; Chantzis, F.; Barnes, E.; Herbert-Voss,
    A.; Guss, W. H.; Nichol, A.; Paino, A.; Tezak, N.; Tang, J.; Babuschkin, I.; Balaji,
    S.; Jain, S.; Saunders, W.; Hesse, C.; Carr, A. N.; Leike, J.; Achiam, J.; Misra,
    V.; Morikawa, E.; Radford, A.; Knight, M.; Brundage, M.; Murati, M.; Mayer, K.;
    Welinder, P.; McGrew, B.; Amodei, D.; McCandlish, S.; Sutskever, I.; 和 Zaremba,
    W. 2021. 评估训练于代码的大语言模型。'
- en: '[Jimenez et al. 2023] Jimenez, C. E.; Yang, J.; Wettig, A.; Yao, S.; Pei, K.;
    Press, O.; and Narasimhan, K. 2023. Swe-bench: Can language models resolve real-world
    github issues?'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jimenez 等 2023] Jimenez, C. E.; Yang, J.; Wettig, A.; Yao, S.; Pei, K.; Press,
    O.; 和 Narasimhan, K. 2023. Swe-bench: 语言模型能否解决现实世界的 GitHub 问题？'
- en: '[Levenshtein 1965] Levenshtein, V. I. 1965. Binary codes capable of correcting
    deletions, insertions, and reversals. Soviet physics. Doklady 10:707–710.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Levenshtein 1965] Levenshtein, V. I. 1965. 能够纠正删除、插入和反转的二进制代码。苏联物理学. 《公报》
    10:707–710。'
- en: '[OpenAI 2023] OpenAI. 2023. Gpt-4 technical report.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenAI 2023] OpenAI. 2023. Gpt-4 技术报告。'
- en: '[Shinn et al. 2023] Shinn, N.; Cassano, F.; Berman, E.; Gopinath, A.; Narasimhan,
    K.; and Yao, S. 2023. Reflexion: Language agents with verbal reinforcement learning.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Shinn 等 2023] Shinn, N.; Cassano, F.; Berman, E.; Gopinath, A.; Narasimhan,
    K.; 和 Yao, S. 2023. Reflexion: 具有言语强化学习的语言代理。'
- en: '[Shrivastava, Larochelle, and Tarlow 2023] Shrivastava, D.; Larochelle, H.;
    and Tarlow, D. 2023. Repository-level prompt generation for large language models
    of code.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Shrivastava, Larochelle 和 Tarlow 2023] Shrivastava, D.; Larochelle, H.; 和
    Tarlow, D. 2023. 代码的大语言模型的库级提示生成。'
- en: '[Yao et al. 2023] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan,
    K.; and Cao, Y. 2023. React: Synergizing reasoning and acting in language models.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[姚等人 2023] 姚思远；赵静；余丹；杜娜；沙夫兰；纳拉辛汉；和曹阳。2023年。《React：在语言模型中协同推理与行动》。'
- en: '[Zhang et al. 2023] Zhang, F.; Chen, B.; Zhang, Y.; Keung, J.; Liu, J.; Zan,
    D.; Mao, Y.; Lou, J.-G.; and Chen, W. 2023. Repocoder: Repository-level code completion
    through iterative retrieval and generation.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[张等人 2023] 张峰；陈斌；张颖；邱洁；刘杰；赞达；毛阳；楼江光；和陈伟。2023年。《Repocoder：通过迭代检索和生成实现库级代码补全》。'
- en: '[Zhou et al. 2023] Zhou, A.; Yan, K.; Shlapentokh-Rothman, M.; Wang, H.; and
    Wang, Y.-X. 2023. Language agent tree search unifies reasoning acting and planning
    in language models.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[周等人 2023] 周安；严凯；沙兰托赫-罗斯曼；王辉；和王云熙。2023年。《语言代理树搜索统一了语言模型中的推理、行动和规划》。'
