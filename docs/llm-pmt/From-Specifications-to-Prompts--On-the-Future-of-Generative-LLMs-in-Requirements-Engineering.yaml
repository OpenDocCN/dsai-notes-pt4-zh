- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:40:55'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:40:55
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'From Specifications to Prompts: On the Future of Generative LLMs in Requirements
    Engineering'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从规范到提示：生成型 LLMs 在需求工程中的未来
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.09127](https://ar5iv.labs.arxiv.org/html/2408.09127)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.09127](https://ar5iv.labs.arxiv.org/html/2408.09127)
- en: \jvol
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \jvol
- en: XX \jnumXX
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: XX \jnumXX
- en: Andreas Vogelsang University of Cologne, Germany(2024)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 安德烈亚斯·沃格尔桑，科隆大学，德国（2024）
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative LLMs, such as GPT, have the potential to revolutionize Requirements
    Engineering (RE) by automating tasks in new ways. This column explores the novelties
    and introduces the importance of precise prompts for effective interactions. Human
    evaluation and prompt engineering are essential in leveraging LLM capabilities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型 LLMs，例如 GPT，有可能通过以新方式自动化任务来彻底改变需求工程（RE）。本文探讨了这些新颖之处，并介绍了精准提示在有效互动中的重要性。人类评估和提示工程在利用
    LLM 能力方面至关重要。
- en: FROM THE EDITOR
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从编辑部
- en: The theme of this issue is Generative AI for Software Engineering, a versatile
    approach that will impact the entire development lifecycle. Frequent readers will
    recall the summary of a panel discussion at the RE 2023 Conference from three
    issues ago. In this guest column, Andreas Vogelsang, drawing from his keynote
    at the 7th Workshop on Natural Language Processing for RE, continues this discussion.
    He explores the potential of generative AI to automate tasks, from capturing requirements
    to verifying consistency and completeness. Additionally, he discusses how RE can
    enhance prompt engineering. I’m sure generative AI will quickly evolve from a
    novel tool to an integral part of the software engineering context. Here are some
    insights from an expert at the forefront of this shift!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本期的主题是“用于软件工程的生成型人工智能”，这一多功能的方法将影响整个开发生命周期。常读者会记得三期前 RE 2023 会议上的小组讨论总结。在这篇特约专栏中，安德烈亚斯·沃格尔桑（Andreas
    Vogelsang）基于他在第七届自然语言处理需求工程研讨会上的主题演讲，继续探讨这个话题。他探讨了生成型人工智能在自动化任务方面的潜力，包括从捕捉需求到验证一致性和完整性。此外，他还讨论了需求工程如何提升提示工程。我相信生成型人工智能将迅速从一种新颖的工具演变为软件工程背景中的重要组成部分。以下是来自这一变革前沿专家的一些见解！
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: 'Generative LLMs, such as GPT, have revolutionized our interaction with artificial
    intelligence. Their ability to understand, generate, and manipulate language presents
    unprecedented opportunities and challenges across various disciplines, including
    RE. Generative LLMs have the potential to redefine the landscape of requirements
    elicitation, specification, and validation. The main messages conveyed in this
    column are:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型大型语言模型（LLMs），例如 GPT，已经彻底改变了我们与人工智能的互动方式。它们理解、生成和操控语言的能力为各个学科，包括需求工程（RE），带来了前所未有的机会和挑战。生成型
    LLMs 具有重新定义需求获取、规范制定和验证领域的潜力。本文传达的主要信息是：
- en: '1.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Generative LLMs provide novel features to support RE tasks. However, the human
    in the loop becomes even more important for evaluating generative LLMs.
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成型 LLMs 提供了支持需求工程任务的新功能。然而，人类在评估生成型 LLMs 时变得更加重要。
- en: '2.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Prompts are expressions of requirements. RE can help improve prompt engineering
    and position prompts as artifacts in the software development lifecycle.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示是需求的表达方式。需求工程可以帮助改进提示工程，并将提示定位为软件开发生命周期中的工件。
- en: 'Preliminaries: Decoder-only (Generative) LLMs'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言：仅解码器（生成型）LLMs
- en: Generative LLMs build upon a decoder-only architecture. Decoder-only architectures
    are derived from the well-known transformer architecture [[1](#bib.bib1)]. The
    original transformer architecture addressed translation tasks by combining an
    encoder, which encodes the input, and a decoder, which generates the output. However,
    it turned out that the encoder and the decoder parts alone can be adapted to create
    helpful models. For example, the successful BERT model [[2](#bib.bib2)] is an
    encoder-only model. Encoder-only models are primarily used for predictive tasks
    where patterns in data are used to make forecasts and predictions (e.g., classification,
    clustering, similarity estimation).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型 LLMs 建立在仅解码器的架构之上。仅解码器架构源自广为人知的变换器架构 [[1](#bib.bib1)]。原始变换器架构通过结合编码器（对输入进行编码）和解码器（生成输出）来解决翻译任务。然而，事实证明，仅编码器和解码器部分可以被调整以创建有用的模型。例如，成功的
    BERT 模型 [[2](#bib.bib2)] 是一个仅编码器模型。仅编码器模型主要用于预测任务，其中数据中的模式用于进行预测和预报（例如分类、聚类、相似性估计）。
- en: Decoder-only LLMs have been designed to generate text. To support the generative
    capabilities of decoder-only LLMs, they are primarily pre-trained with a next-word
    prediction (NWP) objective, where the models predict the next word or words in
    a given sequence of words. After pre-training, decoder-only LLMs are triggered
    by a so-called prompt. A prompt is a textual input instructing the generative
    LLM to generate the desired response.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 仅解码器LLMs被设计用于生成文本。为了支持仅解码器LLMs的生成能力，它们主要通过下一个词预测（NWP）目标进行预训练，其中模型预测给定词序列中的下一个词或词汇。预训练后，仅解码器LLMs由所谓的提示触发。提示是指令性文本，指导生成型LLM生成所需的回应。
- en: 'Feeding decoder-only LLMs with prompts offers a new paradigm for interaction.
    In encoder-only or full transformer models, information about the task had to
    be reflected in the training data. The input had to be preprocessed before the
    model could make a prediction. In decoder-only models, the task and the input
    can be expressed in natural language and passed directly to the model. The model’s
    output is also richer than for non-generative LLMs since it produces (customizable)
    text instead of confidence values for predefined outcomes. A prompt contains any
    of the following elements:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 向仅解码器LLMs提供提示提供了一种新的交互范式。在仅编码器或完整变换器模型中，任务的信息必须体现在训练数据中。输入必须在模型进行预测之前进行预处理。在仅解码器模型中，任务和输入可以用自然语言表达，并直接传递给模型。模型的输出也比非生成型LLMs更丰富，因为它生成的是（可定制的）文本，而不是预定义结果的置信值。一个提示包含以下任一元素：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Instruction: a specific task or instruction you want the model to perform'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指令：你希望模型执行的特定任务或指令。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Context: external information or additional context that can steer the model
    to better responses'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上下文：外部信息或附加背景，可以引导模型生成更好的回应。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Input Data: the input or question that we are interested in finding a response
    for'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入数据：我们希望寻找回应的输入或问题。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Output Indicator: the type or format of the output.'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出指示符：输出的类型或格式。
- en: You do not need all four elements for a prompt, and the ideal format depends
    on the task. Although prompting an LLM sounds relatively straightforward, the
    creation and exact phrasing of a prompt is crucial for the quality of the LLM
    output. For most tasks, it is necessary to experiment with different prompts and
    iteratively refine them to yield the best results. This so-called prompt engineering
    step is similar to feature engineering in more traditional machine learning (ML)
    approaches. Prompt engineering is a relatively new field where only heuristics
    and simple rules exist that help create effective prompts.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要所有四个元素来创建提示，理想的格式取决于任务。尽管提示LLM听起来相对简单，但提示的创建和准确措辞对LLM输出的质量至关重要。对于大多数任务，有必要实验不同的提示并迭代改进，以获得最佳结果。这个所谓的提示工程步骤类似于传统机器学习（ML）方法中的特征工程。提示工程是一个相对较新的领域，目前仅有启发式方法和简单规则存在，帮助创建有效的提示。
- en: Using Generative LLMs for RE tasks
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用生成型LLMs进行RE任务
- en: Generative LLMs provide a new way to solve RE tasks. Traditional predictive
    LLMs (i.e., encoder-only LLMs) are trained or fine-tuned to predict the most likely
    output for a given input. Usually, the set of possible outputs is constrained.
    It is either a set of classes [[3](#bib.bib3), [4](#bib.bib4)], a subset of the
    input (i.e., information retrieval [[5](#bib.bib5)]), or a numeric value in a
    defined range (e.g., similarity estimation).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型LLMs提供了一种新的解决RE任务的方法。传统的预测型LLMs（即仅编码器LLMs）经过训练或微调，以预测给定输入的最可能输出。通常，可能的输出集是受限的。它可以是一个类别集合[[3](#bib.bib3),
    [4](#bib.bib4)]、输入的子集（即信息检索[[5](#bib.bib5)]）或在定义范围内的数值（例如，相似性估计）。
- en: With generative LLMs, a specific RE task is written as a prompt, which serves
    as input. The prompt usually contains the task and the input data to be processed.
    The model’s output provides the answer to the specific task.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成型LLMs时，特定的RE任务作为提示编写，作为输入。提示通常包含任务和要处理的输入数据。模型的输出提供了特定任务的答案。
- en: 'Here is an example of how a trace link recovery task can be formulated as prompt [[6](#bib.bib6)]:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个如何将追踪链接恢复任务表述为提示的示例[[6](#bib.bib6)]：
- en: User
    Prompt: Below are artifacts from the
    same software system. Is there a traceability link between (1) and (2)? (1) The
    DPU-TMALI shall utilize SCM_DCI_SR, along with ERRNO provided by DPU-DCI to decode
    errors and place them on an error queue for DPU-CCM. (2) Error Collection and
    Reporting The ccmErrEnq() function tracks the last error reported and its frequency
    of occurrence. Once an error code has been reported it becomes the previously
    reported error code maintained by ccmErrEnq(). A repetition count is then incremented
    for each subsequent, consecutively reported, identical instance of this previously
    reported error. If this error code is reported more than once in one high-rate
    housekeeping reporting period, then a special error, S_ccm_ERR_REPEAT is enqueued
    with the repetition count for the error encoded in the least significant byte.
    This mechanism effectively reduces the potential for housekeeping telemetry to
    become flooded with a single repeated error.LLM Assistant:
    Yes, there is a traceability link between (1) and (2). (1) mentions
    that the DPU-TMALI places errors on an error queue for the DPU-CCM. (2) describes
    the error collection and reporting mechanism of the DPU-CCM, specifically referring
    to enqueuing errors. So (2) provides an implementation detail for the error queuing
    functionality briefly mentioned in (1). Therefore, there is a traceability link
    between these two artifacts in the software system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是来自同一软件系统的文档。是否存在(1)和(2)之间的可追溯链接？(1) DPU-TMALI应利用SCM_DCI_SR以及DPU-DCI提供的ERRNO来解码错误，并将错误放入DPU-CCM的错误队列中。(2)
    错误收集与报告 ccmErrEnq()函数跟踪最后报告的错误及其发生频率。一旦错误代码被报告，它就成为由ccmErrEnq()维护的之前报告的错误代码。对于每个后续的、连续报告的相同错误实例，重复计数会增加。如果在一个高频率的维护报告周期内，该错误代码被报告多于一次，则会将一个特殊错误S_ccm_ERR_REPEAT加入队列，其中错误的重复计数编码在最低有效字节中。该机制有效地减少了维护遥测因单个重复错误而被淹没的可能性。
- en: The quality of the provided output depends on the specific prompt. Prompts can
    be refined by refining any component (i.e., instructions, context, input question).
    Providing more context and instructions is an effective strategy to increase the
    semantic quality of the output. In a recent publication, we describe few-shot
    prompting, instruction fine-tuning, and retrieval augmented generation, which
    can be used to refine the prompt and increase the model’s performance [[7](#bib.bib7)].
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的输出质量依赖于具体的提示。通过完善任何组件（即，指令、背景、输入问题）可以改进提示。提供更多的背景信息和指令是一种有效的策略，可以提高输出的语义质量。在最近的一项出版物中，我们描述了少量示例提示、指令微调和检索增强生成，这些方法可以用来优化提示并提高模型的性能[[7](#bib.bib7)]。
- en: Besides the novel input paradigm, LLMs also offer two novel ways to work with
    the output.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 除了新颖的输入范式，LLMs 还提供了两种新颖的输出处理方式。
- en: We can ask generative LLMs to augment the response with rationales and explanations.
    In contrast to predictive LLMs, which only provide the prediction as output, generative
    LLMs can be instructed to provide explanations along the result. As also shown
    in the example above, the LLM assistant provides the answer (“yes, there is a
    trace link”) followed by an explanation. This additional information impacts the
    perception of the human analyst using the tool. It may also increase the chances
    that humans can uncover mispredictions by the model and also help humans to improve
    quality flaws.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以要求生成型 LLM 用理由和解释来扩展回答。与仅提供预测作为输出的预测型 LLM 相比，生成型 LLM 可以被指示在结果中提供解释。如上例所示，LLM
    助手提供了答案（“是的，有一个追踪链接”），然后是解释。这些额外的信息影响了使用工具的人类分析师的感知。它也可能增加人类发现模型误预测的机会，并帮助人类改进质量缺陷。
- en: 'We can enter into a dialog with a generative LLM. The second novel advantage
    is that generative LLMs can incorporate prior answers as context into new prompts.
    This gives the user the possibility to ask for additional information or even
    correct certain details of an answer. The generative LLM can respond to this additional
    human input to refine, clarify, or even correct its answer. If, for example, we
    have spotted a mistake in the answer, we may correct the model and get a refined
    answer:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以与生成型 LLM 进行对话。第二个新颖的优势是，生成型 LLM 可以将先前的回答作为背景纳入新的提示中。这使得用户可以要求提供额外的信息或纠正回答中的某些细节。生成型
    LLM 可以对这些额外的人类输入做出回应，以完善、澄清或纠正其回答。例如，如果我们发现回答中有错误，我们可以纠正模型，并得到一个更精确的回答：
- en: User Prompt:
    The explanation is incorrect. (2) does not describe the DPU-CCM
    but another component.LLM Assistant: I apologize for the confusion
    in my previous response. Based on the information provided, there is no direct
    traceability link between (1) and (2) in terms of specific components or functionalities.
    (1) describes the error handling process in the DPU-TMALI component, while (2)
    describes the error collection and reporting mechanism in a different component
    that is not explicitly mentioned. Without further context or explicit connections
    between the components mentioned in (1) and (2), it is not possible to establish
    a direct traceability link between the two artifacts.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 用户提示： 解释不正确。 (2) 并没有描述 DPU-CCM，而是描述了另一个组件。LLM 助手：
    对于我之前回答中的混淆，我深表歉意。根据提供的信息，在（1）和（2）之间没有直接的可追溯链接，涉及到具体的组件或功能。（1）描述了
    DPU-TMALI 组件中的错误处理过程，而（2）描述了不同组件中的错误收集和报告机制，但该组件未明确提及。在没有进一步的背景或（1）和（2）中提到的组件之间的明确连接的情况下，无法在这两个文档之间建立直接的可追溯链接。
- en: We can combine different modalities. Although LLMs were originally designed
    to process and produce text, recent LLMs can also process and generate image,
    audio, and even video data. Much requirements-related information is in non-text
    format (e.g., visual models, interview recordings, vision videos). The recent
    LLM advancements allow the integration of these representations into the automation
    pipeline.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以结合不同的模式。尽管大型语言模型（LLMs）最初设计用于处理和生成文本，但最近的LLMs也可以处理和生成图像、音频，甚至视频数据。许多需求相关的信息是以非文本格式存在的（例如，视觉模型、面试录音、视觉视频）。最近的LLM进展允许将这些表示形式整合到自动化流程中。
- en: Evaluation becomes a challenge. Augment a response with explanations, entering
    into a dialog, and combining modalities are features of generative LLMs that distinguish
    them from predictive LLMs we used in the past to automate RE tasks. These features,
    however, make the evaluation of LLMs more challenging. When generative LLMs are
    used like predictive models, the evaluation is straightforward and should adhere
    to existing best practices (e.g., as suggested by Dell’Anna et al. [[8](#bib.bib8)]).
    However, when using the generative, conversational, and multimodal capabilities,
    the human-in-the-loop becomes much more important for evaluating generative LLMs.
    This starts with different metrics that are used to compare generated text (e.g.,
    BLEU and ROUGE instead of precision and recall). Even more importantly, the performance
    of an LLM assistant will strongly depend on the conversational flow, the perceived
    quality of answers, the trust of humans in the answers, and the way the assistant
    handles human feedback.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 评估变得具有挑战性。将响应与解释结合、进入对话以及结合多种模式是生成型 LLM 的特点，这些特点使它们与我们过去用于自动化 RE 任务的预测型 LLM
    区分开来。然而，这些特点也使得 LLM 的评估变得更加复杂。当生成型 LLM 被像预测模型一样使用时，评估是直接的，并且应遵循现有的最佳实践（例如，Dell’Anna
    等人 [[8](#bib.bib8)] 提出的）。然而，当使用生成型、对话型和多模态能力时，人类在环的重要性大大增加。评估生成型 LLM 开始需要使用不同的指标来比较生成的文本（例如，使用
    BLEU 和 ROUGE 而不是精确度和召回率）。更重要的是，LLM 助手的表现将很大程度上取决于对话流、回答的感知质量、人类对回答的信任以及助手处理人类反馈的方式。
- en: Using RE for Effective Prompting
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 RE 进行有效提示
- en: In the rapidly advancing landscape of AI, prompt engineering emerged as a new
    discipline concerning the development and optimization of prompts for LLMs. Various
    prompting techniques have been introduced by different sources, ranging from blog
    articles to peer-reviewed academic publications. However, the vast majority seem
    to lack a scientific foundation and are more based on trial and error. Some of
    these rules address the style of how prompts should be phrased, e.g.,
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速发展的人工智能领域，提示工程作为一种新学科出现，涉及对大型语言模型（LLMs）提示的开发和优化。各种提示技术已由不同来源提出，从博客文章到同行评审的学术出版物都有涉及。然而，绝大多数似乎缺乏科学基础，更多地依赖于反复试验。这些规则中的一些涉及提示的表达风格，例如，
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Start simple: start with a simple prompt and build on it'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从简单开始：从一个简单的提示开始，并逐步完善
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Call to action: start the prompt with an action word like “Write”, “Create”,
    or “Summarize” instead of “Can you”'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行动呼吁：用动作词如“写作”、“创建”或“总结”开始提示，而不是“你能否”
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Add context: add specific and relevant context to the task you want to perform'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 添加上下文：为你想执行的任务添加具体且相关的上下文
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Add expectations: add clear and direct expectations for the content, like how
    long it should be and what to include'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 添加期望：为内容添加明确和直接的期望，比如长度和包含的内容
- en: 'Prompt templates such as the CRISPE framework¹¹1[https://sourcingdenis.medium.com/crispe-prompt-engineering-framework-e47eaaf83611](https://sourcingdenis.medium.com/crispe-prompt-engineering-framework-e47eaaf83611)
    (Capacity and Role, Insight, Statement, Personality, Experiment) or the RICE framework²²2[https://www.geeky-gadgets.com/harnessing-the-power-of-the-rice-framework-for-perfect-chatgpt-prompts/](https://www.geeky-gadgets.com/harnessing-the-power-of-the-rice-framework-for-perfect-chatgpt-prompts/)
    (Role, Instructions, Context, Constraints, and Examples) provide guidelines and
    best practices for structuring the content of a prompt. A prompt for a trace link
    recovery task following the CRISPE framework could look like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 像 CRISPE 框架¹¹1[https://sourcingdenis.medium.com/crispe-prompt-engineering-framework-e47eaaf83611](https://sourcingdenis.medium.com/crispe-prompt-engineering-framework-e47eaaf83611)（容量和角色、洞察、声明、个性、实验）或
    RICE 框架²²2[https://www.geeky-gadgets.com/harnessing-the-power-of-the-rice-framework-for-perfect-chatgpt-prompts/](https://www.geeky-gadgets.com/harnessing-the-power-of-the-rice-framework-for-perfect-chatgpt-prompts/)（角色、指令、上下文、限制条件和示例）的提示模板提供了结构化提示内容的指导原则和最佳实践。按照
    CRISPE 框架的跟踪链接恢复任务的提示可能如下所示：
- en: 'User
    Prompt: Capacity and Role: Requirement
    Analyst Insight: We’re looking for traceability links between high-level and low-level
    requirements. A traceability link indicates that a low-level requirement is related
    to a high-level requirement (e.g. because it refines it). Statement: Find all
    traceability links between the following low-level and high-level requirements.
    Personality: Accurate and precise. Experiment: Provide just one answer. [Low-level
    Requirements]: … [High-level Requirements]: …'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 'User
    Prompt: Capacity and Role: Requirement
    Analyst Insight: We’re looking for traceability links between high-level and low-level
    requirements. A traceability link indicates that a low-level requirement is related
    to a high-level requirement (e.g. because it refines it). Statement: Find all
    traceability links between the following low-level and high-level requirements.
    Personality: Accurate and precise. Experiment: Provide just one answer. [Low-level
    Requirements]: … [High-level Requirements]: …'
- en: Other prompting strategies suggest adding examples (few-shot prompting) or breaking
    down the problem into smaller tasks (chain-of-thought prompting).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其他提示策略建议添加示例（少量示例提示）或将问题拆解成更小的任务（思维链提示）。
- en: 'From an RE perspective, prompts express the user’s needs and expectations to
    an LLM. Therefore, prompts are expressions of requirements. RE research has a
    long tradition of thinking about and coming up with methods to describe stakeholder
    needs in a precise manner. This also includes thinking about the role and importance
    of prompts in a broader development context and not just aiming at the quality
    of the resulting outputs. Generally, the goals of RE are (1) knowing all relevant
    requirements, (2) achieving a consensus among the stakeholders about these requirements,
    (3) documenting requirements appropriately, and (4) managing requirements systematically.
    Adapting these goals to requirements expressed as prompts leads to interesting
    questions:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从需求工程（RE）的角度来看，提示表达了用户对大型语言模型（LLM）的需求和期望。因此，提示是需求的表达。需求工程的研究传统上致力于思考和提出描述利益相关者需求的精确方法。这还包括在更广泛的发展背景下思考提示的角色和重要性，而不仅仅是关注最终输出的质量。一般来说，需求工程的目标是（1）了解所有相关需求，（2）在利益相关者之间达成对这些需求的共识，（3）适当地记录需求，以及（4）系统地管理需求。将这些目标适应于作为提示表达的需求，会引发有趣的问题：
- en: Knowing all prompts
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 了解所有提示
- en: •
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Have we included all relevant content in a prompt?
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们是否在提示中包含了所有相关内容？
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Do we need additional prompts to improve the results?
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们是否需要额外的提示来改善结果？
- en: 'Achieving a consensus among the stakeholders about these prompts:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些提示中达成利益相关者之间的共识：
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Do all stakeholders agree with the prompt?
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有利益相关者是否同意该提示？
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Are the perspectives of all stakeholders reflected in a (set of) prompts?
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是否所有利益相关者的观点都反映在（一组）提示中？
- en: Documenting prompts appropriately
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 适当地记录提示
- en: •
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Is there a need to document and store the prompts?
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是否需要记录和存储提示？
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Who may need to read, change, or reuse the prompts?
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 谁可能需要阅读、更改或重用提示？
- en: Managing prompts systematically
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 系统地管理提示
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Which (version of a) prompt generated which artifact?
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 哪个（版本的）提示生成了哪个工件？
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Which LLM (version) has been used?
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用了哪个 LLM（版本）？
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Which prompts have been derived from which requirements?
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 哪些提示是从哪些需求派生的？
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Is all prompt content backed up by requirements?
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有提示内容是否都有需求支持？
- en: 'Recently, we investigated reproducible indicators within prompts that may predict
    a loss of quality or flaw. We base these flaw indicators on established requirements
    smells, which are reliable indicators for requirements quality [[9](#bib.bib9),
    [10](#bib.bib10)]. Our initial experiments showed interesting results. For example,
    in a code generation task, ChatGPT interpreted the vague requirement “If the points
    of one player are too low, the game ends and the player loses the game.” by setting
    the boundary to 0 points without asking for clarification or hinting at the ambiguity:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我们调查了提示中的可复现指标，这些指标可能预测质量下降或缺陷。我们将这些缺陷指标基于已建立的需求嗅探器，这些是需求质量的可靠指标[[9](#bib.bib9),
    [10](#bib.bib10)]。我们的初步实验显示了有趣的结果。例如，在代码生成任务中，ChatGPT 解释了模糊的需求“如果一个玩家的得分过低，游戏结束，玩家输掉游戏。”，通过将边界设置为
    0 分，而没有请求澄清或提示模糊性：
- en: 'User
    Prompt: We want to develop a game for
    mobile devices. The game has two players who throw a dice in each turn. Both players
    start with 10 points. If the dice shows an even number, the number is added to
    the points of the player, if it shows an uneven number, the points are subtracted.
    If the points of one player are too low, the game ends and the player loses the
    game. Create Python code that implements this game.LLM Assistant:
    Certainly! Below is a Python implementation of the game: […] if
    player1_points <= 0: print(“Player 1 has lost the game!”) break […]'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '用户提示：
    我们想开发一个适用于移动设备的游戏。游戏中有两个玩家，每回合掷一次骰子。两个玩家都从10分开始。如果骰子显示偶数，该数值将加到玩家的分数上，如果显示奇数，则减去分数。如果一个玩家的分数过低，游戏结束，该玩家输掉游戏。创建一个实现该游戏的Python代码。LLM助手：
    当然！以下是该游戏的Python实现代码：[…] if player1_points <= 0: print(“玩家1已经输掉了游戏！”)
    break […]'
- en: Considering prompts as a new manifestation of requirements is a novel and relevant
    research direction. This line of research should start with characterizing the
    role of prompts in the development process. Should prompts be considered similarly
    to requirements expressed in requirements documents? Are they more like intermediate
    and transitory artifacts? Or should they be treated as very high-level code?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示视为需求的新表现形式是一个新颖且相关的研究方向。这一研究方向应从描述提示在开发过程中的角色开始。提示应被视为与需求文档中表达的需求类似吗？它们更像是中间和过渡性工件？还是应将其视为非常高级的代码？
- en: Conclusions
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Generative large language models (LLMs) are opening up new opportunities for
    requirements analysts, providing innovative tools to enhance their work. Unlike
    traditional predictive models, generative LLMs offer detailed explanations and
    allow users to engage in a dialogue to refine or correct responses. This brings
    exciting possibilities but also introduces challenges. We need to rethink how
    we evaluate these models’ capabilities and develop new ways to assess their effectiveness,
    especially when humans are involved.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式大型语言模型（LLMs）为需求分析师提供了新机会，提供了创新工具来增强他们的工作。与传统的预测模型不同，生成式LLMs提供了详细的解释，并允许用户进行对话以细化或纠正回答。这带来了令人兴奋的可能性，但也引入了挑战。我们需要重新思考如何评估这些模型的能力，并开发新的方法来评估它们的有效性，特别是当涉及到人类时。
- en: Additionally, there is a growing interest in the intersection of RE and prompt
    engineering. How can we create precise prompts or break down complex goals into
    actionable steps? Is there a need for systematic prompt documentation and management?
    This is an intriguing area for RE researchers and enthusiasts to explore.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，需求工程与提示工程的交集引起了越来越多的关注。我们如何创建精确的提示或将复杂目标分解为可操作的步骤？是否需要系统化的提示文档和管理？这是需求工程研究人员和爱好者可以探索的一个有趣领域。
- en: References
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. u. Kaiser, and I. Polosukhin, “Attention is all you need,” in *Advances in
    Neural Information Processing Systems*, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
    R. Fergus, S. Vishwanathan, and R. Garnett, Eds., vol. 30.   Curran Associates,
    Inc., 2017.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. u. Kaiser 和 I. Polosukhin, “注意力即你所需”，收录于*神经信息处理系统进展*，由 I. Guyon, U. V. Luxburg,
    S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan 和 R. Garnett 主编，第30卷。Curran
    Associates, Inc., 2017年。'
- en: '[2] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of
    deep bidirectional transformers for language understanding,” 2018.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J. Devlin, M.-W. Chang, K. Lee 和 K. Toutanova, “BERT: 深度双向变换器的预训练用于语言理解”，2018年。'
- en: '[3] J. Winkler and A. Vogelsang, “Automatic classification of requirements
    based on convolutional neural networks,” in *2016 IEEE 24th International Requirements
    Engineering Conference Workshops (REW)*.   IEEE, 2016, pp. 39–45.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] J. Winkler 和 A. Vogelsang, “基于卷积神经网络的需求自动分类”，收录于*2016 IEEE 第24届国际需求工程会议工作坊
    (REW)*。IEEE, 2016年，第39–45页。'
- en: '[4] M. Binder, A. Vogt, A. Bajraktari, and A. Vogelsang, “Automatically Classifying
    Kano Model Factors in App Reviews,” in *International Working Conference on Requirements
    Engineering: Foundation for Software Quality*.   Springer Nature Switzerland Cham,
    2023, pp. 245–261.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] M. Binder, A. Vogt, A. Bajraktari 和 A. Vogelsang, “自动分类应用评论中的 Kano 模型因素”，收录于*国际需求工程工作会议：软件质量基础*。Springer
    Nature Switzerland Cham, 2023, 第245–261页。'
- en: '[5] J. Fischbach, B. Hauptmann, L. Konwitschny, D. Spies, and A. Vogelsang,
    “Towards causality extraction from requirements,” in *IEEE 28th International
    Requirements Engineering Conference (RE)*.   IEEE, 2020, pp. 388–393.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] J. Fischbach, B. Hauptmann, L. Konwitschny, D. Spies 和 A. Vogelsang, “朝着从需求中提取因果关系的方向前进”，收录于*IEEE
    第28届国际需求工程会议 (RE)*。IEEE, 2020年，第388–393页。'
- en: '[6] A. D. Rodriguez, K. R. Dearstyne, and J. Cleland-Huang, “Prompts matter:
    Insights and strategies for prompt engineering in automated software traceability,”
    in *IEEE 31st International Requirements Engineering Conference Workshops (REW)*,
    2023, pp. 455–464.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] A. D. Rodriguez, K. R. Dearstyne 和 J. Cleland-Huang, “提示很重要：自动化软件可追溯性中的提示工程洞察与策略”，收录于*IEEE
    第31届国际需求工程会议工作坊 (REW)*, 2023, 第455–464页。'
- en: '[7] A. Vogelsang and J. Fischbach, “Using Large Language Models for Natural
    Language Processing Tasks in Requirements Engineering: A Systematic Guideline,”
    in *Handbook of Natural Language Processing for Requirements Engineering*, A. Ferrari
    and G. G. Deshpande, Eds.   Cham: Springer International Publishing, 2024.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] A. Vogelsang 和 J. Fischbach, “在需求工程中使用大型语言模型进行自然语言处理任务：系统指南”，收录于*需求工程自然语言处理手册*，由
    A. Ferrari 和 G. G. Deshpande 主编。Cham: Springer International Publishing, 2024。'
- en: '[8] D. Dell’Anna, F. B. Aydemir, and F. Dalpiaz, “Evaluating classifiers in
    SE research: the ECSER pipeline and two replication studies,” *Empirical Software
    Engineering*, vol. 28, no. 1, Nov. 2022.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] D. Dell’Anna, F. B. Aydemir 和 F. Dalpiaz, “在软件工程研究中评估分类器：ECSER 流程和两个复制研究”，*实证软件工程*，第28卷，第1期，2022年11月。'
- en: '[9] H. Femmer, D. Méndez Fernández, S. Wagner, and S. Eder, “Rapid quality
    assurance with requirements smells,” *Journal of Systems and Software*, vol. 123,
    pp. 190–213, 2017.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] H. Femmer, D. Méndez Fernández, S. Wagner 和 S. Eder, “使用需求气味进行快速质量保证”，*系统与软件期刊*，第123卷，第190–213页，2017年。'
- en: '[10] J. Frattini, L. Montgomery, J. Fischbach, M. Unterkalmsteiner, D. Mendez,
    and D. Fucci, “A live extensible ontology of quality factors for textual requirements,”
    in *IEEE 30th International Requirements Engineering Conference (RE)*.   IEEE,
    2022.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] J. Frattini, L. Montgomery, J. Fischbach, M. Unterkalmsteiner, D. Mendez
    和 D. Fucci, “文本需求的可扩展质量因素实时本体”，收录于*IEEE 第30届国际需求工程会议 (RE)*。IEEE, 2022年。'
- en: '{IEEEbiography}'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '{IEEEbiography}'
- en: Andreas Vogelsang  is a full professor of Software Engineering at the University
    of Cologne, 50923 Cologne, Germany. Contact him at vogelsang@cs.uni-koeln.de.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Andreas Vogelsang  是科隆大学的软件工程全职教授，地址为德国科隆50923。联系他可以通过电子邮件 vogelsang@cs.uni-koeln.de。
