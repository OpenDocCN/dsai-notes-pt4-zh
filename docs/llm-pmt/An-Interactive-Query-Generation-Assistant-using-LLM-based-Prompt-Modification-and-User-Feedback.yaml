- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:48:01'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:48:01'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: An Interactive Query Generation Assistant using LLM-based Prompt Modification
    and User Feedback
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基于LLM的提示修改和用户反馈的互动查询生成助手
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.11226](https://ar5iv.labs.arxiv.org/html/2311.11226)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2311.11226](https://ar5iv.labs.arxiv.org/html/2311.11226)
- en: Kaustubh D. Dhole [kdhole@emory.edu](mailto:kdhole@emory.edu) Department of
    Computer ScienceEmory UniversityAtlantaUSA ,  Ramraj Chandradevan [rchan31@emory.edu](mailto:rchan31@emory.edu)
    Department of Computer ScienceEmory UniversityAtlantaUSA  and  Eugene Agichtein
    [yagicht@emory.edu](mailto:yagicht@emory.edu) Department of Computer ScienceEmory
    UniversityAtlantaUSA
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Kaustubh D. Dhole [kdhole@emory.edu](mailto:kdhole@emory.edu) 计算机科学系，艾默里大学，亚特兰大，美国
    ， Ramraj Chandradevan [rchan31@emory.edu](mailto:rchan31@emory.edu) 计算机科学系，艾默里大学，亚特兰大，美国
    和 Eugene Agichtein [yagicht@emory.edu](mailto:yagicht@emory.edu) 计算机科学系，艾默里大学，亚特兰大，美国
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: While search is the predominant method of accessing information, formulating
    effective queries remains a challenging task, especially for situations where
    the users are not familiar with a domain, or searching for documents in other
    languages, or looking for complex information such as events, which are not easily
    expressible as queries. Providing example documents or passages of interest, might
    be easier for a user, however, such query-by-example scenarios are prone to concept
    drift, and are highly sensitive to the query generation method. This demo illustrates
    complementary approaches of using LLMs interactively, assisting and enabling the
    user to provide edits and feedback at all stages of the query formulation process.
    The proposed Query Generation Assistant is a novel search interface which supports
    automatic and interactive query generation over a mono-linguial or multi-lingual
    document collection. Specifically, the proposed assistive interface enables the
    users to refine the queries generated by different LLMs, to provide feedback on
    the retrieved documents or passages, and is able to incorporate the users’ feedback
    as prompts to generate more effective queries. The proposed interface is a valuable
    experimental tool for exploring fine-tuning and prompting of LLMs for query generation
    to qualitatively evaluate the effectiveness of retrieval and ranking models, and
    for conducting Human-in-the-Loop (HITL) experiments for complex search tasks where
    users struggle to formulate queries without such assistance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管搜索是访问信息的主要方法，但制定有效的查询仍然是一个具有挑战性的任务，尤其是在用户不熟悉领域、或搜索其他语言的文档，或寻找如事件等复杂信息时，这些信息不容易用查询表达。提供示例文档或感兴趣的段落可能对用户更容易，但这种基于示例的查询场景容易出现概念漂移，并且对查询生成方法高度敏感。这个演示展示了使用LLMs的互补方法，辅助并使用户能够在查询制定过程的所有阶段进行编辑和反馈。提出的查询生成助手是一种新颖的搜索界面，支持对单语或多语文档集合进行自动和互动的查询生成。具体来说，提出的辅助界面使用户能够优化不同LLMs生成的查询，提供对检索文档或段落的反馈，并能够将用户的反馈作为提示，以生成更有效的查询。提出的界面是探索LLMs在查询生成中的微调和提示的宝贵实验工具，以定性评估检索和排序模型的有效性，并进行复杂搜索任务的Human-in-the-Loop
    (HITL)实验，在这些任务中，用户在没有这种帮助的情况下难以制定查询。
- en: 'query reformulation, prompting, large language models, interaction^†^†conference:
    Intelligence Advanced Research Projects Activity – Better Extraction from Text
    Towards Enhanced Retrieval; March 23, 2023; University of Maryland, College Park^†^†ccs:
    Information systems Search interfaces^†^†ccs: Information systems Query reformulation^†^†ccs:
    Information systems Presentation of retrieval results'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '查询重新表述、提示、大型语言模型、互动^†^†会议：智能高级研究项目活动 – 从文本中更好地提取以增强检索；2023年3月23日；马里兰大学，公园学院^†^†ccs:
    信息系统 搜索界面^†^†ccs: 信息系统 查询重新表述^†^†ccs: 信息系统 检索结果展示'
- en: 1\. Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Retrieving information is critically important from documents in multiple languages
    as the Internet increasingly provides access to documents across thousands of
    languages and domains. Creating effective search queries can be a daunting task
    for users. First, users may be unfamiliar with the language of the information
    they need to obtain or may be completely unaware of it, making it hard to craft
    specific queries. Second, most people are not familiar with the vocabulary and
    jargon used in other areas or fields, which can further impair their ability to
    formulate good search queries. Furthermore, users may be unfamiliar with the corpus,
    or collection of documents being searched, making it challenging to know what
    information to look for and how to phrase the information need. We propose a solution
    to this challenge by employing “query-by-example” - allowing users to explore
    document collections better by letting them specify an example document (rather
    than an explicit query) of what they are searching for. Although considerable
    advancements have been made in the domain of query-by-example (Sarwar and Allan,
    [2020](#bib.bib17); Zloof, [1975](#bib.bib24)), especially neural and transformer
    based, there is a clear lack of interfacing tools for performing qualitative analysis
    making it an area ripe for exploration.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从多语言文档中检索信息至关重要，因为互联网越来越多地提供对数千种语言和领域文档的访问。创建有效的搜索查询对用户来说可能是一项艰巨的任务。首先，用户可能对他们需要获取的信息的语言不熟悉，甚至可能完全不了解，这使得制定具体的查询变得困难。其次，大多数人对其他领域或领域中使用的词汇和术语不熟悉，这进一步影响了他们制定良好搜索查询的能力。此外，用户可能对被搜索的文档集合（语料库）不熟悉，这使得知道需要寻找什么信息以及如何表述信息需求变得具有挑战性。我们通过采用“示例查询”提出了解决方案——允许用户通过指定一个示例文档（而不是明确的查询）来更好地探索文档集合。尽管在示例查询领域（Sarwar
    和 Allan, [2020](#bib.bib17); Zloof, [1975](#bib.bib24)）已经取得了相当大的进展，特别是在神经网络和基于变压器的技术方面，但明显缺乏进行定性分析的接口工具，这使得这一领域充满探索的潜力。
- en: As query-by-example (QBE) and multilingual information retrieval (MLIR) introduce
    new tasks to the traditional information retrieval community, new research questions
    and challenges arise, such as how to provide effective search results in different
    languages and how to assist users in generating effective queries. Traditional
    methods of qualitative analysis can be time-consuming, as researchers need to
    manually generate queries and analyze search results, making it even harder to
    iterate. Hence, having an interfacing tool that can automatically generate queries
    and display the search results together can be invaluable for researchers and
    practitioners alike.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于示例查询（QBE）和多语言信息检索（MLIR）向传统信息检索社区引入了新任务，新的研究问题和挑战随之出现，例如如何在不同语言中提供有效的搜索结果，以及如何帮助用户生成有效的查询。传统的定性分析方法可能耗时较长，因为研究人员需要手动生成查询并分析搜索结果，从而使得迭代变得更加困难。因此，拥有一个能够自动生成查询并将搜索结果一同显示的接口工具，对研究人员和从业者来说都具有极大的价值。
- en: On the other hand, success in few-shot prompting (Srivastava et al., [2023](#bib.bib19);
    Brown et al., [2020](#bib.bib4); Liu et al., [2023](#bib.bib10)) has led large
    language models to play a key role in reducing the information burden on users
    by especially assisting them for writing tasks namely essay writing, summarisation,
    transcript and dialog generation, etc. This success has also been transferred
    to tasks related to query generation (Jeong et al., [2021](#bib.bib7); Nogueira
    et al., [2019](#bib.bib15)). While large language model applications are prevalent
    and numerous studies have been conducted for search interfaces (Liu et al., [2022](#bib.bib11),
    [2021a](#bib.bib8), [2021b](#bib.bib9); Xu et al., [2009](#bib.bib22)), there
    has been little impetus to combine search interfaces with large language model
    based query generation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，少量示例提示的成功（Srivastava 等, [2023](#bib.bib19); Brown 等, [2020](#bib.bib4);
    Liu 等, [2023](#bib.bib10)）使得大型语言模型在减少用户信息负担方面发挥了关键作用，特别是在写作任务（如论文写作、摘要生成、转录和对话生成等）中提供帮助。这种成功也转移到了与查询生成相关的任务中（Jeong
    等, [2021](#bib.bib7); Nogueira 等, [2019](#bib.bib15)）。尽管大型语言模型应用广泛且有大量关于搜索接口的研究（Liu
    等, [2022](#bib.bib11), [2021a](#bib.bib8), [2021b](#bib.bib9); Xu 等, [2009](#bib.bib22)），但将搜索接口与基于大型语言模型的查询生成相结合的动机仍然较少。
- en: 'In this paper, we demonstrate Query Generation Assistant, a search interface
    that supports automatic and interactive query generation for monolingual or multi-lingual
    interactive search. The novel contributions of the proposed interface include:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了Query Generation Assistant，这是一个支持单语或多语种互动搜索的自动和交互式查询生成的搜索界面。所提议界面的新颖贡献包括：
- en: (1)
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1）
- en: The interface provides a simple document search interface that displays documents
    in their original language along with their translations, making it simple for
    researchers to navigate and analyse search results.
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该界面提供了一个简单的文档搜索界面，显示原文及其翻译，使研究人员能够轻松浏览和分析搜索结果。
- en: (2)
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （2）
- en: The tool also supports diverse query generation, allowing users to explore search
    results more comprehensively.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该工具还支持多样化的查询生成，使用户能够更全面地探索搜索结果。
- en: (3)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （3）
- en: More importantly, it combines search with a prompting-based query generation
    interface which permits users to refine their queries and prompts with retrieval
    information.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更重要的是，它结合了搜索与基于提示的查询生成界面，允许用户根据检索信息细化他们的查询和提示。
- en: We believe our interface could work as an effective starting template for performing
    qualitative analysis over other search related experiments and datasets as well
    as serve as a tool to incorporate retrieval feedback and Human-In-The-Loop (HITL)
    studies. Even though our system was built initially for the BETTER search tasks
    (described in the next subsection,) our interface is generic in nature and would
    be transferable to other datasets and indices. We share the python code for the
    below described interface as well as the video demonstration here¹¹1[https://github.com/emory-irlab/better-search](https://github.com/emory-irlab/better-search).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信，我们的界面可以作为执行其他搜索相关实验和数据集的定性分析的有效起始模板，并作为纳入检索反馈和人机协作（HITL）研究的工具。尽管我们的系统最初是为BETTER搜索任务构建的（如下一小节所述），但我们的界面本质上是通用的，并且可以转移到其他数据集和索引中。我们在这里共享以下描述的界面的python代码以及视频演示¹¹1[https://github.com/emory-irlab/better-search](https://github.com/emory-irlab/better-search)。
- en: We first briefly describe the BETTER task and dataset in Section 1\. We then
    explicate the three main features of Query Generation Assistant in section 3.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在第1节中简要描述BETTER任务和数据集。然后在第3节中阐述Query Generation Assistant的三个主要特性。
- en: 2\. Dataset
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 数据集
- en: Our system and interface was designed to investigate interactive query generation
    especially for Query-By-Example (QBE) settings. The BETTER search datasets²²2[https://ir.nist.gov/better/](https://ir.nist.gov/better/) (Mckinnon
    and Rubino, [2022](#bib.bib12); Soboroff, [2023](#bib.bib18)) were used for demonstration.
    The BETTER dataset is a collection of natural language processing resources developed
    by IARPA’s BETTER program³³3[https://www.iarpa.gov/research-programs/better](https://www.iarpa.gov/research-programs/better)
    to assist their intelligence analysts to process and analyze huge amounts of unstructured,
    multilingual information efficiently and effectively and serves as an example
    application for multi-lingual QBE and document retrieval for event monitoring
    (event retrieval). This collection also contains ancillary information like event
    span annotations from text across many languages and topics. Particularly, the
    BETTER program seeks search systems to perform accurate retrieval of Arabic, Persian,
    Chinese, Korean, and Russian documents on being queried with example English documents.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统和界面旨在研究交互式查询生成，特别是针对示例查询（QBE）设置。BETTER搜索数据集²²2[https://ir.nist.gov/better/](https://ir.nist.gov/better/)（Mckinnon
    和 Rubino，[2022](#bib.bib12)；Soboroff，[2023](#bib.bib18)）被用于演示。BETTER数据集是由IARPA的BETTER计划³³3[https://www.iarpa.gov/research-programs/better](https://www.iarpa.gov/research-programs/better)开发的自然语言处理资源集合，旨在帮助情报分析师高效、有效地处理和分析大量非结构化、多语言信息，并作为多语言QBE和事件监控（事件检索）的文档检索应用示例。该集合还包含诸如跨多种语言和主题的事件跨度注释等附加信息。特别是，BETTER计划旨在开发能够准确检索阿拉伯语、波斯语、中文、韩语和俄语文档的搜索系统，这些系统以示例英语文档进行查询。
- en: 3\. Query Generation Assistant
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 查询生成助手
- en: The Query Generation Assistant User Interface is made up of 3 subsystems. Each
    of them are described below. The interface is built using HuggingFace’s Gradio
    platform. Gradio (Wolf et al., [2020](#bib.bib20); Abid et al., [2019](#bib.bib2))
    is an open-source Python package to quickly create easy-to-use, customizable UI
    components for machine learning models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 查询生成助手用户界面由 3 个子系统组成。每个子系统的描述如下。该界面使用 HuggingFace 的 Gradio 平台构建。Gradio（Wolf
    等，[2020](#bib.bib20)；Abid 等，[2019](#bib.bib2)）是一个开源 Python 包，用于快速创建易于使用的、可定制的机器学习模型
    UI 组件。
- en: 3.1\. Manual Search
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 手动搜索
- en: '![Refer to caption](img/62f02ff0e65d291f907c11a7b87d4ff9.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/62f02ff0e65d291f907c11a7b87d4ff9.png)'
- en: 'Figure 1\. Manual Search: The list of returned documents displayed alongwith
    their translations and event annotations.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 手动搜索：返回文档的列表，展示其翻译和事件注释。
- en: This tab (shown in Figure [1](#S3.F1 "Figure 1 ‣ 3.1\. Manual Search ‣ 3\. Query
    Generation Assistant ‣ An Interactive Query Generation Assistant using LLM-based
    Prompt Modification and User Feedback")) is the simplest interface which permits
    users to write search queries by themselves and returns the top-k relevant documents,
    their English translations, and the highlighted events for each document. The
    search is conducted on each index built using their corresponding language’s documents,
    using SOTA cross-lingual dense retrieval model, ColBERT-x (Nair et al., [2022](#bib.bib13)).
    A document rank list is returned for each language. These rank lists are eventually
    combined and reranked using reciprocal rank fusion. All the documents are translated
    offline using Google Translate⁴⁴4[https://translate.google.com/](https://translate.google.com/)
    for faster look-up during query time. To highlight the event annotations, such
    as event triggers and argument entities, on the displayed documents, the collection
    is parsed to a SOTA event annotator (span-finder (Xia et al., [2021](#bib.bib21)))
    offline and then looked-up during the query time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该选项卡（如图 [1](#S3.F1 "图 1 ‣ 3.1\. 手动搜索 ‣ 3\. 查询生成助手 ‣ 基于 LLM 的提示修改和用户反馈的交互式查询生成助手")
    所示）是最简单的界面，允许用户自行编写搜索查询，并返回前 k 个相关文档、它们的英文翻译以及每个文档中突出显示的事件。搜索在使用 SOTA 跨语言密集检索模型
    ColBERT-x（Nair 等，[2022](#bib.bib13)）构建的每个索引上进行。为每种语言返回一个文档排名列表。这些排名列表最终会合并并使用倒数排名融合进行重新排名。所有文档都通过
    Google 翻译⁴⁴[https://translate.google.com/](https://translate.google.com/) 离线翻译，以加快查询时的查找速度。为了突出显示显示文档中的事件注释，如事件触发器和论元实体，集合被解析到
    SOTA 事件标注器（span-finder（Xia 等，[2021](#bib.bib21)））离线，然后在查询时查找。
- en: 3.2\. Auto Query Generator
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 自动查询生成器
- en: The BETTER task seeks to benchmark systems to be able to look for documents
    in specified target languages which are similar to a user’s example document.
    We attempt to do this via generating an intermediate query from the example document
    and performing retrieval over the same. However, the effectiveness of the generated
    queries is crucial to retrieve relevant documents, while also ensuring query interpretability.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: BETTER 任务旨在基准测试系统，能够查找与用户示例文档相似的指定目标语言中的文档。我们尝试通过从示例文档生成中间查询并在其上执行检索来实现这一点。然而，生成查询的有效性对于检索相关文档至关重要，同时也要确保查询的可解释性。
- en: Inspired by the recent success of pre-trained generation models, we fine-tune
    a T5 (Raffel et al., [2020](#bib.bib16)) model on (document, query) pairs. To
    evaluate the performance of our approach, we compare the original T5 model with
    a docT5query (Nogueira et al., [2019](#bib.bib15)) model, which has already been
    fine-tuned on the MSMarco (Nguyen et al., [2016](#bib.bib14)) dataset. Our results
    indicate that the docT5query model outperforms the original T5 model, and thus
    we utilize it for our demonstration.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 受到预训练生成模型最近成功的启发，我们对 T5（Raffel 等，[2020](#bib.bib16)）模型进行了针对（文档，查询）对的微调。为了评估我们方法的性能，我们将原始
    T5 模型与已在 MSMarco（Nguyen 等，[2016](#bib.bib14)）数据集上进行过微调的 docT5query（Nogueira 等，[2019](#bib.bib15)）模型进行了比较。我们的结果表明，docT5query
    模型优于原始 T5 模型，因此我们在演示中使用它。
- en: The complete interface is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.2\. Auto
    Query Generator ‣ 3\. Query Generation Assistant ‣ An Interactive Query Generation
    Assistant using LLM-based Prompt Modification and User Feedback").
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的界面如图 [2](#S3.F2 "图 2 ‣ 3.2\. 自动查询生成器 ‣ 3\. 查询生成助手 ‣ 基于 LLM 的提示修改和用户反馈的交互式查询生成助手")
    所示。
- en: '![Refer to caption](img/4c58a7393dae73cf13a3ceab09d97aa7.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4c58a7393dae73cf13a3ceab09d97aa7.png)'
- en: 'Figure 2\. Auto Query Generator: Given an example document, queries are generated.
    Queries can be further refined by the user and searched across the documents.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 自动查询生成器：给定一个示例文档，将生成查询。用户可以进一步调整查询，并在文档中进行搜索。
- en: 3.3\. Interactive Query Generation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 交互式查询生成
- en: Large language models in recent years have shown excellent strides in multi-task
    learning and few-shot learning. With just a handful of examples, large language
    models have shown impressive generative capabilities, albeit with risks of hallucinations.
    Prompting has been an effective and seemingly natural way to interact with such
    models.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型在多任务学习和少量示例学习方面取得了显著进展。仅凭少量示例，大型语言模型已展示出令人印象深刻的生成能力，尽管存在幻觉的风险。提示法已成为与这些模型交互的一种有效且看似自然的方法。
- en: While few-shot prompting has been a powerful approach to teach models new tasks,
    such models have generally shown different outputs on varying various prompting
    parameters. For example, varying the types of examples in the prompt, changing
    the order of the examples and number of examples vastly influence the generations.
    We use this feature to our advantage for query generation by letting people edit
    their prompts either directly or through user relevance feedback so as to improve
    subsequent query generations and corresponding retrieval.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管少量示例提示法已成为教导模型新任务的强大方法，但这些模型通常在不同的提示参数下会显示出不同的输出。例如，提示中示例的类型、示例的顺序和示例的数量都会显著影响生成结果。我们利用这一特性，通过让用户直接编辑提示或通过用户相关反馈来改进后续的查询生成及相应的检索。
- en: We choose FlanT5 (Chung et al., [2022](#bib.bib5)) as it has been fine-tuned
    already on a large amount of tasks making it arguably convenient (Aribandi et al.,
    [2022](#bib.bib3)) for learning on new tasks. The interface permits prompting
    FlanT5 by default with two editable (document, query) pairs alongwith an instruction.
    We present users with options of multiple instructions and their choice of document
    to generate query from. The interface is shown in Figure [3](#S3.F3 "Figure 3
    ‣ 3.3\. Interactive Query Generation ‣ 3\. Query Generation Assistant ‣ An Interactive
    Query Generation Assistant using LLM-based Prompt Modification and User Feedback").
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择 FlanT5（Chung et al., [2022](#bib.bib5)），因为它已经在大量任务上进行了微调，使其在学习新任务时显得相对方便（Aribandi
    et al., [2022](#bib.bib3)）。界面允许默认使用两个可编辑的（文档，查询）对以及一个指令来提示 FlanT5。我们为用户提供多个指令选项及其选择的文档以生成查询。界面如图[3](#S3.F3
    "图 3 ‣ 3.3\. 交互式查询生成 ‣ 3\. 查询生成助手 ‣ 基于 LLM 的提示修改和用户反馈的交互式查询生成助手")所示。
- en: '![Refer to caption](img/c2f0f2f46ea42ba647f70df48e5ef7a3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c2f0f2f46ea42ba647f70df48e5ef7a3.png)'
- en: Figure 3\. Prompt Based Interactive Query Generator
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. 基于提示的交互式查询生成器
- en: Each of the generated queries can at once or together be used to retrieve documents.
    On retrieval, each of the retrieved document is provided with a checkbox to permit
    it to be directly added to the prompt alongwith its original query. This is intended
    to incorporate user search feedback directly into the prompt to make the prompt
    more consistent with the users’ requests. In terms of few-shot prompting, when
    models are prompted to generate responses based on a limited set of examples,
    the quality of the generations depends on the quality and relevance of the examples
    provided as models are known to be also less robust towards prompt perturbations(Zhao
    et al., [2021](#bib.bib23); Dhole et al., [2023](#bib.bib6)).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个生成的查询可以一次性或同时用于检索文档。在检索时，每个检索到的文档都会提供一个复选框，以便将其与原始查询一起直接添加到提示中。这旨在将用户的搜索反馈直接纳入提示，使提示与用户的请求更加一致。在少量示例提示法方面，当模型被提示基于有限的示例集生成响应时，生成的质量依赖于提供的示例的质量和相关性，因为模型对于提示扰动的鲁棒性也较差（Zhao
    et al., [2021](#bib.bib23); Dhole et al., [2023](#bib.bib6)）。
- en: 4\. Conclusion
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 结论
- en: The primary objective of Query Generation Assistant is to assist researchers
    with an ability to qualitatively monitor cross-lingual retrieval and provide assistance
    to generate and refine queries. Researchers and practitioners can quickly and
    easily perform qualitative analysis with the tool’s search interface and query
    generation features, allowing them to evaluate search systems more thoroughly.
    The prompting-based search interface also provides an avenue to perform human-in-the-loop
    (HITL) studies. Apart from qualitative studies, we believe Query Generation Assistant
    could be used as an effective starting template to perform more sophisticated
    information retrieval experiments as well as serve as a tool to incorporate retrieval
    feedback and conduct Human-In-The-Loop studies.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Query Generation Assistant 的主要目标是帮助研究人员定性监测跨语言检索，并提供生成和完善查询的支持。研究人员和从业者可以通过该工具的搜索界面和查询生成特性快速、轻松地进行定性分析，使他们能够更全面地评估搜索系统。基于提示的搜索界面还提供了进行人机交互
    (HITL) 研究的途径。除了定性研究，我们相信 Query Generation Assistant 还可以作为有效的起始模板，用于执行更复杂的信息检索实验，以及作为工具来整合检索反馈并进行人机交互研究。
- en: 5\. Acknowledgements
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 致谢
- en: This work was supported in part by IARPA BETTER (#2019-19051600005). The views
    and conclusions contained in this work are those of the authors and should not
    be interpreted as necessarily representing the official policies, either expressed
    or implied, or endorsements of ODNI, IARPA, or the U.S. Government. The U.S. Government
    is authorized to reproduce and distribute reprints for governmental purposes notwithstanding
    any copyright annotation therein.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作部分由 IARPA BETTER (#2019-19051600005) 支持。本文中的观点和结论仅代表作者个人，不能被解读为 ODNI、IARPA
    或美国政府的官方政策或认可。美国政府有权复制和分发再版以供政府用途，不受任何版权标注的限制。
- en: References
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Abid et al. (2019) Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman
    Alfozan, and James Zou. 2019. Gradio: Hassle-free sharing and testing of ml models
    in the wild. *arXiv preprint arXiv:1906.02569* (2019).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abid 等人 (2019) Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman
    Alfozan, 和 James Zou. 2019. Gradio: 轻松分享和测试野外的机器学习模型。*arXiv 预印本 arXiv:1906.02569*
    (2019).'
- en: 'Aribandi et al. (2022) Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven
    Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo
    Ni, Jai Gupta, Kai Hui, Sebastian Ruder, and Donald Metzler. 2022. ExT5: Towards
    Extreme Multi-Task Scaling for Transfer Learning. In *International Conference
    on Learning Representations*. [https://openreview.net/forum?id=Vzh1BFUCiIX](https://openreview.net/forum?id=Vzh1BFUCiIX)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Aribandi 等人 (2022) Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu
    Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q. Tran, Dara Bahri,
    Jianmo Ni, Jai Gupta, Kai Hui, Sebastian Ruder, 和 Donald Metzler. 2022. ExT5:
    面向极端多任务扩展的迁移学习。发表于*国际学习表征会议*。[https://openreview.net/forum?id=Vzh1BFUCiIX](https://openreview.net/forum?id=Vzh1BFUCiIX)'
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems* 33 (2020), 1877–1901.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人 (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell 等. 2020. 语言模型是少样本学习者。*神经信息处理系统进展* 33 (2020), 1877–1901.
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi
    Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma,
    et al. 2022. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*
    (2022).
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等人 (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma 等. 2022.
    扩展指令微调语言模型。*arXiv 预印本 arXiv:2210.11416* (2022).
- en: 'Dhole et al. (2023) Kaustubh Dhole, Varun Gangal, Sebastian Gehrmann, Aadesh
    Gupta, Zhenhao Li, Saad Mahamood, Abinaya Mahadiran, Simon Mille, Ashish Shrivastava,
    Samson Tan, et al. 2023. NL-Augmenter: A Framework for Task-Sensitive Natural
    Language Augmentation. *Northern European Journal of Language Technology* 9, 1
    (2023). [https://nejlt.ep.liu.se/article/view/4725/3874](https://nejlt.ep.liu.se/article/view/4725/3874)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dhole 等人 (2023) Kaustubh Dhole, Varun Gangal, Sebastian Gehrmann, Aadesh Gupta,
    Zhenhao Li, Saad Mahamood, Abinaya Mahadiran, Simon Mille, Ashish Shrivastava,
    Samson Tan 等. 2023. NL-Augmenter: 任务敏感的自然语言增强框架。*北欧语言技术期刊* 9, 1 (2023)。 [https://nejlt.ep.liu.se/article/view/4725/3874](https://nejlt.ep.liu.se/article/view/4725/3874)'
- en: Jeong et al. (2021) Soyeong Jeong, Jinheon Baek, ChaeHun Park, and Jong Park.
    2021. Unsupervised Document Expansion for Information Retrieval with Stochastic
    Text Generation. In *Proceedings of the Second Workshop on Scholarly Document
    Processing*. Association for Computational Linguistics, Online, 7–17. [https://doi.org/10.18653/v1/2021.sdp-1.2](https://doi.org/10.18653/v1/2021.sdp-1.2)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeong et al. (2021) Soyeong Jeong, Jinheon Baek, ChaeHun Park, 和 Jong Park.
    2021. 用于信息检索的无监督文档扩展与随机文本生成。发表于 *第二届学术文档处理研讨会论文集*。计算语言学协会，在线，7–17. [https://doi.org/10.18653/v1/2021.sdp-1.2](https://doi.org/10.18653/v1/2021.sdp-1.2)
- en: Liu et al. (2021a) Chang Liu, Ying-Hsang Liu, Jingjing Liu, and Ralf Bierig.
    2021a. Search Interface Design and Evaluation. *Found. Trends Inf. Retr.* 15,
    3–4 (dec 2021), 243–416. [https://doi.org/10.1561/1500000073](https://doi.org/10.1561/1500000073)
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2021a) Chang Liu, Ying-Hsang Liu, Jingjing Liu, 和 Ralf Bierig. 2021a.
    搜索界面设计与评估。*Found. Trends Inf. Retr.* 15, 3–4 (2021年12月), 243–416. [https://doi.org/10.1561/1500000073](https://doi.org/10.1561/1500000073)
- en: Liu et al. (2021b) Chang Liu, Ying-Hsang Liu, Jingjing Liu, and Ralf Bierig.
    2021b. Search Interface Design and Evaluation. 15, 3–4 (dec 2021), 243–416. [https://doi.org/10.1561/1500000073](https://doi.org/10.1561/1500000073)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2021b) Chang Liu, Ying-Hsang Liu, Jingjing Liu, 和 Ralf Bierig. 2021b.
    搜索界面设计与评估。15, 3–4 (2021年12月), 243–416. [https://doi.org/10.1561/1500000073](https://doi.org/10.1561/1500000073)
- en: 'Liu et al. (2023) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. 2023. Pre-Train, Prompt, and Predict: A Systematic
    Survey of Prompting Methods in Natural Language Processing. *ACM Comput. Surv.*
    55, 9, Article 195 (jan 2023), 35 pages. [https://doi.org/10.1145/3560815](https://doi.org/10.1145/3560815)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, 和 Graham Neubig. 2023. 预训练、提示和预测：自然语言处理中的提示方法系统综述。*ACM Comput. Surv.*
    55, 9, 第195篇 (2023年1月), 35页. [https://doi.org/10.1145/3560815](https://doi.org/10.1145/3560815)
- en: 'Liu et al. (2022) Ying-Hsang Liu, Paul Thomas, Tom Gedeon, and Nicolay Rusnachenko.
    2022. Search Interfaces for Biomedical Searching: How Do Gaze, User Perception,
    Search Behaviour and Search Performance Relate?. In *Proceedings of the 2022 Conference
    on Human Information Interaction and Retrieval* (Regensburg, Germany) *(CHIIR
    ’22)*. Association for Computing Machinery, New York, NY, USA, 78–89. [https://doi.org/10.1145/3498366.3505769](https://doi.org/10.1145/3498366.3505769)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2022) Ying-Hsang Liu, Paul Thomas, Tom Gedeon, 和 Nicolay Rusnachenko.
    2022. 生物医学搜索的搜索界面：注视、用户感知、搜索行为和搜索表现之间的关系？发表于 *2022年人机信息交互与检索会议论文集*（德国雷根斯堡） *(CHIIR
    ’22)*. 计算机协会，美国纽约，78–89. [https://doi.org/10.1145/3498366.3505769](https://doi.org/10.1145/3498366.3505769)
- en: Mckinnon and Rubino (2022) Timothy Mckinnon and Carl Rubino. 2022. The IARPA
    BETTER Program Abstract Task Four New Semantically Annotated Corpora from IARPA’s
    BETTER Program. In *Proceedings of the Thirteenth Language Resources and Evaluation
    Conference*, Nicoletta Calzolari, Frédéric Béchet, Philippe Blache, Khalid Choukri,
    Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard,
    Joseph Mariani, Hélène Mazo, Jan Odijk, and Stelios Piperidis (Eds.). European
    Language Resources Association, Marseille, France, 3595–3600. [https://aclanthology.org/2022.lrec-1.384](https://aclanthology.org/2022.lrec-1.384)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mckinnon and Rubino (2022) Timothy Mckinnon 和 Carl Rubino. 2022. IARPA BETTER
    项目摘要任务四：IARPA BETTER 项目中的四个新的语义标注语料库。发表于 *第十三届语言资源与评估会议论文集*，Nicoletta Calzolari,
    Frédéric Béchet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck,
    Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, Hélène Mazo, Jan
    Odijk, 和 Stelios Piperidis (编辑)。欧洲语言资源协会，法国马赛，3595–3600. [https://aclanthology.org/2022.lrec-1.384](https://aclanthology.org/2022.lrec-1.384)
- en: 'Nair et al. (2022) Suraj Nair, Eugene Yang, Dawn Lawrie, Kevin Duh, Paul McNamee,
    Kenton Murray, James Mayfield, and Douglas W. Oard. 2022. Transfer Learning Approaches
    for Building Cross-Language Dense Retrieval Models. In *Advances in Information
    Retrieval: 44th European Conference on IR Research, ECIR 2022, Stavanger, Norway,
    April 10–14, 2022, Proceedings, Part I* (Stavanger, Norway). Springer-Verlag,
    Berlin, Heidelberg, 382–396. [https://doi.org/10.1007/978-3-030-99736-6_26](https://doi.org/10.1007/978-3-030-99736-6_26)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nair et al. (2022) Suraj Nair, Eugene Yang, Dawn Lawrie, Kevin Duh, Paul McNamee,
    Kenton Murray, James Mayfield, 和 Douglas W. Oard. 2022. 用于构建跨语言密集检索模型的迁移学习方法。发表于
    *信息检索的进展：第44届欧洲信息检索研究会议，ECIR 2022，挪威斯塔万格，2022年4月10–14日，会议论文集，第I部分*（挪威斯塔万格）。Springer-Verlag，德国柏林，海德堡，382–396.
    [https://doi.org/10.1007/978-3-030-99736-6_26](https://doi.org/10.1007/978-3-030-99736-6_26)
- en: 'Nguyen et al. (2016) Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh
    Tiwary, Rangan Majumder, and Li Deng. 2016. MS MARCO: A human generated machine
    reading comprehension dataset. *choice* 2640 (2016), 660.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen 等（2016）Tri Nguyen、Mir Rosenberg、Xia Song、Jianfeng Gao、Saurabh Tiwary、Rangan
    Majumder 和 Li Deng。2016。MS MARCO：一个由人生成的机器阅读理解数据集。*choice* 2640（2016），660。
- en: Nogueira et al. (2019) Rodrigo Nogueira, Wei Yang, Jimmy Lin, and Kyunghyun
    Cho. 2019. Document Expansion by Query Prediction. arXiv:1904.08375 [cs.IR]
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nogueira 等（2019）Rodrigo Nogueira、Wei Yang、Jimmy Lin 和 Kyunghyun Cho。2019。通过查询预测进行文档扩展。arXiv:1904.08375
    [cs.IR]
- en: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring
    the limits of transfer learning with a unified text-to-text transformer. *The
    Journal of Machine Learning Research* 21, 1 (2020), 5485–5551.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel 等（2020）Colin Raffel、Noam Shazeer、Adam Roberts、Katherine Lee、Sharan Narang、Michael
    Matena、Yanqi Zhou、Wei Li 和 Peter J Liu。2020。通过统一的文本到文本变换器探索迁移学习的极限。*机器学习研究期刊*
    21, 1（2020），5485–5551。
- en: Sarwar and Allan (2020) Sheikh Muhammad Sarwar and James Allan. 2020. Query
    by Example for Cross-Lingual Event Retrieval *(SIGIR ’20)*. Association for Computing
    Machinery, New York, NY, USA, 1601–1604. [https://doi.org/10.1145/3397271.3401283](https://doi.org/10.1145/3397271.3401283)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarwar 和 Allan（2020）Sheikh Muhammad Sarwar 和 James Allan。2020。通过示例进行跨语言事件检索
    *(SIGIR ’20)*。计算机协会，纽约，NY，USA，1601–1604。 [https://doi.org/10.1145/3397271.3401283](https://doi.org/10.1145/3397271.3401283)
- en: Soboroff (2023) Ian Soboroff. 2023. The BETTER Cross-Language Datasets. In *Proceedings
    of the 46th International ACM SIGIR Conference on Research and Development in
    Information Retrieval* (Taipei, Taiwan) *(SIGIR ’23)*. Association for Computing
    Machinery, New York, NY, USA, 3047–3053. [https://doi.org/10.1145/3539618.3591910](https://doi.org/10.1145/3539618.3591910)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Soboroff（2023）Ian Soboroff。2023。BETTER 跨语言数据集。在 *第46届国际 ACM SIGIR 信息检索研究与发展会议论文集*（台北，台湾）*(SIGIR
    ’23)*。计算机协会，纽约，NY，USA，3047–3053。 [https://doi.org/10.1145/3539618.3591910](https://doi.org/10.1145/3539618.3591910)
- en: 'Srivastava et al. (2023) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
    Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya
    Gupta, Adrià Garriga-Alonso, et al. 2023. Beyond the Imitation Game: Quantifying
    and extrapolating the capabilities of language models. *Transactions on Machine
    Learning Research* (2023).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava 等（2023）Aarohi Srivastava、Abhinav Rastogi、Abhishek Rao、Abu Awal Md
    Shoeb、Abubakar Abid、Adam Fisch、Adam R Brown、Adam Santoro、Aditya Gupta、Adrià Garriga-Alonso
    等。2023。超越模仿游戏：量化和推测语言模型的能力。*机器学习研究交易*（2023）。
- en: 'Wolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    and Alexander Rush. 2020. Transformers: State-of-the-Art Natural Language Processing.
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations*. Association for Computational Linguistics,
    Online, 38–45. [https://doi.org/10.18653/v1/2020.emnlp-demos.6](https://doi.org/10.18653/v1/2020.emnlp-demos.6)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf 等（2020）Thomas Wolf、Lysandre Debut、Victor Sanh、Julien Chaumond、Clement Delangue、Anthony
    Moi、Pierric Cistac、Tim Rault、Remi Louf、Morgan Funtowicz、Joe Davison、Sam Shleifer、Patrick
    von Platen、Clara Ma、Yacine Jernite、Julien Plu、Canwen Xu、Teven Le Scao、Sylvain
    Gugger、Mariama Drame、Quentin Lhoest 和 Alexander Rush。2020。变换器：前沿自然语言处理。在 *2020年自然语言处理经验方法会议：系统演示论文集*。计算语言学协会，在线，38–45。
    [https://doi.org/10.18653/v1/2020.emnlp-demos.6](https://doi.org/10.18653/v1/2020.emnlp-demos.6)
- en: 'Xia et al. (2021) Patrick Xia, Guanghui Qin, Siddharth Vashishtha, Yunmo Chen,
    Tongfei Chen, Chandler May, Craig Harman, Kyle Rawlins, Aaron Steven White, and
    Benjamin Van Durme. 2021. LOME: Large Ontology Multilingual Extraction. In *Proceedings
    of the 16th Conference of the European Chapter of the Association for Computational
    Linguistics: System Demonstrations*. 149–159. [https://www.aclweb.org/anthology/2021.eacl-demos.19](https://www.aclweb.org/anthology/2021.eacl-demos.19)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia 等（2021）Patrick Xia、Guanghui Qin、Siddharth Vashishtha、Yunmo Chen、Tongfei
    Chen、Chandler May、Craig Harman、Kyle Rawlins、Aaron Steven White 和 Benjamin Van
    Durme。2021。LOME：大型本体多语言提取。在 *第16届欧洲计算语言学协会会议：系统演示论文集*。149–159。 [https://www.aclweb.org/anthology/2021.eacl-demos.19](https://www.aclweb.org/anthology/2021.eacl-demos.19)
- en: Xu et al. (2009) Songhua Xu, Tao Jin, and Francis C. M. Lau. 2009. A New Visual
    Search Interface for Web Browsing *(WSDM ’09)*. Association for Computing Machinery,
    New York, NY, USA, 152–161. [https://doi.org/10.1145/1498759.1498821](https://doi.org/10.1145/1498759.1498821)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2009）Songhua Xu、Tao Jin 和 Francis C. M. Lau。2009年。《一种新的网页浏览视觉搜索界面*（WSDM
    ’09）*》。计算机协会，纽约，NY，美国，152–161。 [https://doi.org/10.1145/1498759.1498821](https://doi.org/10.1145/1498759.1498821)
- en: 'Zhao et al. (2021) Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer
    Singh. 2021. Calibrate before use: Improving few-shot performance of language
    models. In *International Conference on Machine Learning*. PMLR, 12697–12706.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人（2021）Zihao Zhao、Eric Wallace、Shi Feng、Dan Klein 和 Sameer Singh。2021年。《使用前校准：提升语言模型的少样本性能》。在*国际机器学习会议*上。PMLR，12697–12706。
- en: Zloof (1975) Moshé M. Zloof. 1975. Query by Example *(AFIPS ’75)*. Association
    for Computing Machinery, New York, NY, USA, 431–438. [https://doi.org/10.1145/1499949.1500034](https://doi.org/10.1145/1499949.1500034)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zloof（1975）Moshé M. Zloof。1975年。《示例查询*（AFIPS ’75）*》。计算机协会，纽约，NY，美国，431–438。
    [https://doi.org/10.1145/1499949.1500034](https://doi.org/10.1145/1499949.1500034)
