- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:42:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:42:17
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Can LLMs Generate Visualizations with Dataless Prompts?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM能否生成没有数据的提示可视化？
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.17805](https://ar5iv.labs.arxiv.org/html/2406.17805)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.17805](https://ar5iv.labs.arxiv.org/html/2406.17805)
- en: \onlineid
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \onlineid
- en: '0 \vgtccategoryResearch \vgtcpapertypeRepresentation and Interaction \authorfooter
    Darius Coelho, Harshit Barot, Naitik Rathod, and Klaus Mueller are with Stony
    Brook University. E-mail: {dcoelho | hbarot | nrathod | mueller}@cs.stonybrook.edu'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 0 \vgtccategoryResearch \vgtcpapertypeRepresentation and Interaction \authorfooter
    **达留斯·科埃略**、**哈希特·巴罗特**、**奈提克·拉索德** 和 **克劳斯·穆勒** 来自斯托尼布鲁克大学。电子邮件：{dcoelho | hbarot
    | nrathod | mueller}@cs.stonybrook.edu
- en: Darius Coelho    Harshit Barot    Naitik Rathod    Klaus Mueller
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**达留斯·科埃略**    **哈希特·巴罗特**    **奈提克·拉索德**    **克劳斯·穆勒**'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent advancements in large language models have revolutionized information
    access, as these models harness data available on the web to address complex queries,
    becoming the preferred information source for many users. In certain cases, queries
    are about publicly available data, which can be effectively answered with data
    visualizations. In this paper, we investigate the ability of large language models
    to provide accurate data and relevant visualizations in response to such queries.
    Specifically, we investigate the ability of GPT-3 and GPT-4 to generate visualizations
    with dataless prompts, where no data accompanies the query. We evaluate the results
    of the models by comparing them to visualization cheat sheets created by visualization
    experts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的近期进展革新了信息获取方式，因为这些模型利用网络上的数据来解决复杂查询，成为许多用户的首选信息来源。在某些情况下，查询涉及公开的数据，这些数据可以通过数据可视化有效回答。在这篇论文中，我们调查了大型语言模型在回应此类查询时提供准确数据和相关可视化的能力。具体来说，我们调查了GPT-3和GPT-4在没有数据的提示下生成可视化的能力，其中查询没有附带数据。我们通过将模型结果与可视化专家创建的图表备忘单进行比较来评估结果。
- en: 'keywords:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Large Language Models, Data Visualization, Captions, Prompt Engineering\teaser![A
    visualization chart sheet to show which chart can be generated using the type
    of data in consideration](img/4312e30f769bf806e0bcf88a99099bef.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型、数据可视化、图注、提示工程\teaser![一个可视化图表，以展示使用考虑中的数据类型可以生成哪些图表](img/4312e30f769bf806e0bcf88a99099bef.png)
- en: 'Chart Cheat Sheet: A visualization cheat sheet to decide which chart is best
    for a specific type of data and task. All of the charts were created by prompting
    GPT4 with real-world queries. Notably, and this one of the major findings of our
    paper, all returned charts matched what is commonly recommended for the query’s
    task and scenario.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图表备忘单：一个可视化备忘单，以决定哪种图表最适合特定的数据和任务类型。所有图表均由GPT4使用真实世界查询生成。值得注意的是，这是我们论文的一个主要发现，所有返回的图表与通常推荐的查询任务和场景相符。
- en: Introduction
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍
- en: Rapid advances in AI, specifically computer vision and natural language, have
    led to the development of large language models (LLMs) such as GPT that can generate
    contextually relevant and high-quality responses in the form of images or text
    to natural language queries. LLM models are trained on large amounts of text and
    image data sourced from a significant portion of the internet which gives them
    seemingly all-encompassing knowledge. As a result, LLMs have emerged as the de
    facto source of information for many users on the web.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: AI，特别是计算机视觉和自然语言的快速进展，导致了像GPT这样的高级语言模型的开发，这些模型能够生成与上下文相关且高质量的图像或文本响应。LLM模型在大量的文本和图像数据上进行训练，这些数据来自互联网的大部分，从而赋予它们似乎包罗万象的知识。因此，LLM已经成为许多网络用户的事实上的信息来源。
- en: '![Refer to caption](img/22ea6eff315c8b170052de8e999feff6.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/22ea6eff315c8b170052de8e999feff6.png)'
- en: (a)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/c71767b3e6c708a9533c5e9b42e053a4.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c71767b3e6c708a9533c5e9b42e053a4.png)'
- en: (b)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/1e36401d5daf5e8042d3898e0521a469.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1e36401d5daf5e8042d3898e0521a469.png)'
- en: (c)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: '![Refer to caption](img/883b2c2224042ccd293f4ff2a4423e1e.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/883b2c2224042ccd293f4ff2a4423e1e.png)'
- en: (d)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: (d)
- en: 'Figure 1: Visualizations showing the U.S. debt over the last two decades. (a)
    is the ground truth visualization retrieved from Statista while the remaining
    visualizations are generated with the prompt "Generate a chart showing the national
    debt of the U.S. over the last 2 decades" with (b) DALL-E, (c) GPT-3.5, and (d)
    GPT-4.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：显示过去二十年美国债务的可视化。 (a) 是从Statista检索到的真实可视化，而其余的可视化是通过提示“生成一张显示过去20年美国国债的图表”生成的，其中
    (b) 为DALL-E，(c) 为GPT-3.5，(d) 为GPT-4。
- en: People often have queries about publicly available data on the web, even though
    they do not possess the data themselves. For example, they might ask "What is
    the US debt over the last two decades?" As LLMs are trained on data available
    on the web, we hypothesize that they have captured publicly available data and
    can respond to these queries accurately. Additionally, given that visual representations
    can significantly enhance comprehension [[2](#bib.bib2)], we believe that responses
    accompanied by data visualizations are ideally suited to such queries.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 人们常常对网上公开的数据有疑问，即使他们自己并不拥有这些数据。例如，他们可能会问“过去二十年美国的债务是多少？”由于LLM是基于网络上可用的数据进行训练的，我们假设它们已经捕捉到了公开的数据，并能够准确回答这些问题。此外，考虑到视觉表示可以显著增强理解[[2](#bib.bib2)]，我们认为附带数据可视化的回答最适合这样的查询。
- en: We expect that when queried for a visual of the data, an LLM would provide us
    with an appropriate visual of the data as these models have also captured visualization
    rules [[5](#bib.bib5)]. For example, if we prompted an LLM "Generate a chart showing
    the US debt over the last two decades", we would expect to receive a line chart
    showing the US debt at each year over the past 20 years.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望当被询问数据的可视化时，LLM会提供适当的数据可视化，因为这些模型也捕捉到了可视化规则[[5](#bib.bib5)]。例如，如果我们提示LLM“生成一张显示过去二十年美国债务的图表”，我们期望收到一张展示过去20年每年美国债务的折线图。
- en: In this work, we investigate the ability of generative AI models to respond
    appropriately to dataless queries. We define dataless queries as text-based queries
    that can be answered with publicly available data but do not contain the data
    themselves. We expect the model to provide the data, or an approximation of the
    data, as part of its response. Our initial investigation tested the ability of
    DALL-E 2, GPT-3.5, and GPT-4, to respond to dataless queries. We found that GPT-4
    appeared to be more adept at answering such queries while responses from DALL-E
    2 and GPT-3.5 were inadequate. This motivated us to conduct a more in-depth investigation
    of GPT-4s abilities. We generated 15 prompts based on popular data visuals on
    the web, aided by a crowd-sourced survey to gather queries of popular interest.
    We then queried GPT-4 using these prompts and evaluated the responses by comparing
    them to visualization cheat sheets created by visualization experts and human-generated
    charts on the web.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们调查了生成型AI模型对无数据查询的适当响应能力。我们将无数据查询定义为可以用公开数据回答的基于文本的查询，但查询本身不包含数据。我们期望模型在其回答中提供数据或数据的近似值。我们的初步调查测试了DALL-E
    2、GPT-3.5和GPT-4对无数据查询的响应能力。我们发现GPT-4在回答这些查询方面表现得更为娴熟，而DALL-E 2和GPT-3.5的回答则不够充分。这促使我们对GPT-4的能力进行了更深入的调查。我们生成了15个基于网络上流行数据可视化的提示，辅以众包调查以收集流行的查询。然后，我们使用这些提示查询GPT-4，并通过将其回答与由可视化专家创建的可视化速查表和网络上的人工生成图表进行比较来评估这些回答。
- en: In the following. Section 2 provides relevant background. Section 3 details
    the study we conducted. Section 4 presents a discussion and concludes our paper.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，第二部分提供了相关背景。第三部分详细描述了我们进行的研究。第四部分提出了讨论，并总结了我们的论文。
- en: 1 Background
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 背景
- en: Generating data-visualizations based on user generated natural language (NL)
    queries has been a longstanding research topic. Early approaches used traditional
    natural language processing (NLP) techniques such as rule-based and probabilistic
    grammar-based approaches to decompose NL queries into a set of machine instructions.
    Cox et al. [[3](#bib.bib3)] created one of the first NL interfaces for visualization
    using a grammar-based approach to convert NL questions into database queries and
    visualize the results. Eviza [[12](#bib.bib12)] employed a probabilistic grammar-based
    approach and a finite state machine to allow users to interact with a given visualization
    using NL commands. NL4DV [[10](#bib.bib10)] is a python library that translates
    NL queries into visualizations. It combines NLP approaches to break down an NL
    input into the machine instructions required to query a dataset and generate a
    chart.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 基于用户生成的自然语言（NL）查询生成数据可视化一直是一个长期研究的话题。早期的方法使用了传统的自然语言处理（NLP）技术，如基于规则和概率语法的方法，将NL查询分解为一组机器指令。Cox等人[[3](#bib.bib3)]
    创建了第一个使用语法方法将NL问题转换为数据库查询并可视化结果的NL界面之一。Eviza [[12](#bib.bib12)] 采用了基于概率语法的方法和有限状态机，允许用户使用NL命令与给定的可视化进行交互。NL4DV
    [[10](#bib.bib10)] 是一个将NL查询翻译成可视化的Python库。它结合了NLP方法，将NL输入分解为查询数据集所需的机器指令，并生成图表。
- en: More recently researchers have explored deep-learning based approaches to convert
    NL queries to visualizations. Lui et al [[6](#bib.bib6)] proposed ADVISor, a deep-learning
    based system that uses multiple models to process and transform data and then
    generate annotated visualizations. Luo et al [[8](#bib.bib8)] devised a novel
    approach using a transformer-based model with several novel visualization-aware
    optimizations to take in a NL query along with an optional chart (e.g., a pie
    chart or a scatter plot) that serves as a template and generates a visualization.
    RGVisNet [[13](#bib.bib13)] is a hybrid system that first looks up a large data
    visualization query codebase for a query most relevant to the user’s data visualization
    query. The retrieved query is then refined by a GNN-based deep-learning model
    to create a visualization specification.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究人员探索了基于深度学习的方法将NL查询转换为可视化。Lui等人[[6](#bib.bib6)] 提出了ADVISor，一个基于深度学习的系统，使用多个模型来处理和转换数据，然后生成带注释的可视化。Luo等人[[8](#bib.bib8)]
    设计了一种新颖的方法，使用基于变压器的模型和几种新颖的可视化感知优化，以接受NL查询及一个可选的图表（例如，饼图或散点图）作为模板，并生成可视化。RGVisNet
    [[13](#bib.bib13)] 是一个混合系统，首先查找一个大型数据可视化查询代码库，以找到与用户的数据可视化查询最相关的查询。检索到的查询然后由基于GNN的深度学习模型进行细化，以创建可视化规范。
- en: Recent advances in generative AI, especially LLMs such as OpenAI’s GPT [[1](#bib.bib1)][[11](#bib.bib11)],
    have prompted researchers to investigate their application to the field of data
    visualization. Maddigan and Susnjak [[9](#bib.bib9)] showed how ChatGPT and GPT-3
    can be leveraged to build an end-to-end solution for converting NL queries to
    visualizations. Their system, Chat2Vis, takes in a NL query and a dataset from
    the user and behind the scenes engineers prompts to precisely query GPT-3\. The
    queries are constructed such that GPT-3 responds with a python script to visualize
    the data provided by the user. Dibia et al. [[4](#bib.bib4)] proposed a four-stage
    approach with LIDA that combines LLMs with image generation to turn datasets and
    analysis goals into charts and infographics. Finally Li et al [[5](#bib.bib5)]
    evaluated GPT-3.5 for vega-lite specification generation using multiple prompting
    strategies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，生成式AI的进展，尤其是像OpenAI的GPT [[1](#bib.bib1)][[11](#bib.bib11)] 这样的LLM，促使研究人员调查其在数据可视化领域的应用。Maddigan和Susnjak
    [[9](#bib.bib9)] 展示了如何利用ChatGPT和GPT-3构建一个将NL查询转换为可视化的端到端解决方案。他们的系统Chat2Vis接收用户的NL查询和数据集，并在后台生成精确查询GPT-3的提示。查询被构造得使得GPT-3用Python脚本响应，从而可视化用户提供的数据。Dibia等人[[4](#bib.bib4)]
    提出了一个四阶段的方法，使用LIDA将LLM与图像生成相结合，将数据集和分析目标转化为图表和信息图表。最后，Li等人[[5](#bib.bib5)] 评估了GPT-3.5在使用多种提示策略生成vega-lite规范方面的表现。
- en: All of these previous approaches required a dataset as input, along with the
    query to produce a visualization. Conversely, we have studied to what extent LLMs
    can deliver a visualization with just the query, or prompt, alone. Furthermore,
    we studied whether the visualizations so produced follow commonly available visualization
    expert guidelines. In other words, have LLMS learnt both data and visualization
    knowledge?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些先前的方法都需要数据集作为输入，以及查询来生成可视化。相反，我们研究了 LLM 仅凭查询或提示能在多大程度上提供可视化。此外，我们还研究了这些生成的可视化是否遵循常见的可视化专家指南。换句话说，LLM
    是否学习了数据和可视化知识？
- en: '![Refer to caption](img/05497e14c298bfbb4e78e7da52d46c0e.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/05497e14c298bfbb4e78e7da52d46c0e.png)'
- en: 'Figure 2: The visualization cheatsheet created by Patrik Lundblad at Qlik to
    assist visualization designers pick appropriate charts for their data'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: Patrik Lundblad 在 Qlik 创建的可视化备忘单，帮助可视化设计师为他们的数据选择合适的图表'
- en: 2 Study
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 研究
- en: Our study aims to investigate the ability of generative AI to produce visualizations
    when prompted with queries without data. This is much like the way a user queries
    an image search engine for data visualizations e.g. "Generate a plot of the most
    spoken languages". In this section, we discuss how we chose to construct dataless
    prompts, how multiple models responded to a small set of dataless prompts, and
    provide a detailed investigation into how GPT-4 performs on dataless prompts.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究旨在调查生成性 AI 在没有数据的情况下响应查询时生成可视化的能力。这很像用户在图像搜索引擎中查询数据可视化，例如“生成一张显示最常用语言的图表”。在这一部分，我们讨论了如何选择构建无数据提示的方式，多种模型如何响应一小组无数据提示，并详细调查了
    GPT-4 在无数据提示下的表现。
- en: 2.1 Dataless Prompts
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 无数据提示
- en: We define dataless prompts as text-based queries provided to LLMs that can be
    answered with publicly available data but do not contain the data themselves.
    An example of a dataless prompt is "What was the US GDP over the past 20 years."
    For this prompt, LLMs often provide a text-based response explaining the GDP trends
    with values for some of the 20 years. However, providing this prompt to a traditional
    search engine (e.g. Google or Yahoo) will provide the user with links to articles
    or images showing the values. In our work we are interested in the images, specifically
    the data visualizations. To have an LLM produce a visualization, we need to explicitly
    tell it to provide a chart, for example, "Generate a chart showing the US GDP
    over the past 20 years." Given such a prompt, LLMs will respond with an image
    of a chart or code to generate a chart. Thus for all dataless prompts in our study,
    we explicitly ask the models to provide a chart.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将无数据提示定义为提供给 LLM 的基于文本的查询，这些查询可以用公开的数据回答，但不包含数据本身。无数据提示的一个例子是“美国过去 20 年的 GDP
    是多少。”对于这个提示，LLM 通常会提供一个基于文本的响应，解释 GDP 趋势并给出一些 20 年中的数值。然而，将此提示提供给传统搜索引擎（如 Google
    或 Yahoo）会提供带有值的文章或图像链接。在我们的工作中，我们对图像特别感兴趣，特别是数据可视化。为了让 LLM 生成可视化，我们需要明确告诉它提供一个图表，例如“生成一张显示美国过去
    20 年 GDP 的图表。”给定这样的提示，LLM 会回应一个图表的图像或生成图表的代码。因此，对于我们研究中的所有无数据提示，我们明确要求模型提供一个图表。
- en: 2.2 Initial Investigation
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 初步调查
- en: We began with an initial investigation to test if generative AI modes could
    produce appropriate responses to dataless prompts. We tested GPT-3.5, GPT-4 and
    DALL-E. We chose to add DALL-E to the investigation as using it is very similar
    to how a user would use an image search engine. We queried all three models with
    three prompts and visually inspected the results. Each model’s response to the
    query "Generate a chart showing the national debt of the U.S. over last 2 decades"
    along with a reference ground truth image sourced from Google images is shown
    in figure [1](#S0.F1 "Figure 1 ‣ Can LLMs Generate Visualizations with Dataless
    Prompts?") . Note that the GPT-3.5 responded with code which we ran on our local
    machine to generate the chart in figure [1](#S0.F1 "Figure 1 ‣ Can LLMs Generate
    Visualizations with Dataless Prompts?")c.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始进行初步调查，以测试生成性 AI 模式是否能对无数据提示做出适当响应。我们测试了 GPT-3.5、GPT-4 和 DALL-E。我们选择将 DALL-E
    加入调查，因为使用它与用户使用图像搜索引擎的方式非常相似。我们用三个提示查询了这三种模型，并对结果进行了视觉检查。每种模型对查询“生成一张显示美国过去 20
    年国债的图表”的响应，以及来自 Google 图片的参考真实图像如图 [1](#S0.F1 "图 1 ‣ LLM 能否生成无数据提示的可视化？")所示。请注意，GPT-3.5
    的响应是代码，我们在本地机器上运行了这些代码，生成了图 [1](#S0.F1 "图 1 ‣ LLM 能否生成无数据提示的可视化？")c 中的图表。
- en: In our tests, all three models were able to generate coherent responses. GPT-3.5
    did not have the capability to respond with an image however responses contained
    mock data values or pointers to publicly available data and a python code to generate
    a chart. GPT-4 could generate charts but it stated that it used mock data. However,
    in both cases, the overall trend of the data was similar to the original data.
    DALL-E on the other hand could only generate a chart (shown in figure [1](#S0.F1
    "Figure 1 ‣ Can LLMs Generate Visualizations with Dataless Prompts?")b) for one
    prompt while it generated graphics related to the prompt topic for the others.
    In the case that it did generate the chart, the overall trend did match that of
    the original data. Based on the responses of each model, we concluded that GPT-4
    was the only model that could respond with an appropriate image or chart. GPT-3
    was unable to provide a visual result while DALL-E could not provide appropriate
    visuals.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试中，所有三种模型都能够生成连贯的响应。然而，GPT-3.5 无法生成图像，响应中包含了虚拟数据值或指向公开数据的指针以及生成图表的 Python
    代码。GPT-4 可以生成图表，但它声明使用了虚拟数据。然而，在这两种情况下，数据的整体趋势与原始数据相似。另一方面，DALL-E 仅能为一个提示生成图表（如图
    [1](#S0.F1 "图 1 ‣ 大型语言模型能否生成无数据提示的可视化？")b 所示），而为其他提示生成了与提示主题相关的图形。在生成图表的情况下，整体趋势确实与原始数据匹配。根据每个模型的响应，我们得出结论：GPT-4
    是唯一能够生成适当图像或图表的模型。GPT-3 无法提供可视化结果，而 DALL-E 无法提供合适的视觉效果。
- en: 2.3 Dataless Prompts with GPT-4
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 无数据提示与 GPT-4
- en: Having identified GPT-4 as a promising model to respond to dataless prompts,
    we decided to test it on a wider range of prompts.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在识别 GPT-4 为响应无数据提示的有前途模型后，我们决定在更广泛的提示范围内对其进行测试。
- en: 2.3.1 Procedure
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 过程
- en: To test GPT-4’s ability to respond to dataless prompts we first generated 15
    prompts. We generated 7 prompts by asking Google Images for various chart types.
    We then selected 7 random charts and constructed a prompt based on the data used
    to generate it. For example, we selected a pie chart showing Amazon’s 2022 revenue
    breakdown, and subsequently created the prompt "Create a chart to display the
    revenue breakdown of Amazon in 2022."
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试 GPT-4 对无数据提示的响应能力，我们首先生成了 15 个提示。我们通过询问 Google 图片各种图表类型生成了 7 个提示。然后，我们选择了
    7 个随机图表，并基于用于生成它们的数据构建了一个提示。例如，我们选择了一个显示亚马逊 2022 年收入分布的饼图，随后创建了提示“创建一个图表以显示亚马逊
    2022 年的收入分布。”
- en: To add more variety, we crowd-sourced the remaining 8 prompts. To crowd-source
    the prompts we sent a Google form to graduate students in our university’s computer
    science department asking "If you could ask ChatGPT to visualize public data,
    what would you ask it to visualize for you? List as many queries as you’d like".
    Seven students responded with a total of 22 responses. Next, we tested if each
    response returned a relevant chart on Google images. We discarded irrelevant responses
    such as "Make unique recipes using GPT". This process resulted in us collecting
    8 prompts with relevant charts on Google images.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加更多的多样性，我们通过众包的方式获取了剩余的 8 个提示。为了进行众包，我们向我们大学计算机科学系的研究生发送了一份 Google 表单，询问“如果你可以让
    ChatGPT 可视化公共数据，你会要求它为你可视化什么？列出你想要的尽可能多的查询。”七名学生回应了，共提供了 22 个响应。接下来，我们测试了每个响应是否在
    Google 图片中返回了相关的图表。我们丢弃了不相关的响应，例如“使用 GPT 制作独特的食谱”。这个过程使我们收集了 8 个在 Google 图片中有相关图表的提示。
- en: Once we finalized our set of 15 prompts we fed each prompt to GPT-4 and compared
    the result to the Google image we collected. The result returned by GPT-4 and
    the Google image result for each of the 15 prompts are shown in the supplementary
    material. For each response, we evaluated if (a) GPT-4 returned a chart with the
    data we requested, (b) it used an appropriate chart type, and (c) the data matched
    the data in the chart retrieved with Google Images.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了 15 个提示，我们将每个提示输入 GPT-4，并将结果与我们收集的 Google 图片进行比较。GPT-4 返回的结果和 Google
    图片的结果在补充材料中显示。对于每个响应，我们评估了 (a) GPT-4 是否返回了我们请求的数据图表，(b) 是否使用了合适的图表类型，以及 (c) 数据是否与从
    Google 图片中检索的图表数据匹配。
- en: '![Refer to caption](img/ae3a9ff0954f4db3127563499895947a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ae3a9ff0954f4db3127563499895947a.png)'
- en: (a)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/314256958f9cf73fe858bfe02440ea08.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/314256958f9cf73fe858bfe02440ea08.png)'
- en: (b)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 3: Visualizations retrieved from (a) Google images and (b) GPT-4 showing
    the U.S. cities with the highest average rent. When compared to the visualization
    from Google images, we see that GPT-4 was able to generate a similar ordering
    of cities however it provided different values for mean rents, perhaps it retrieved
    data from a different year.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：从 (a) Google 图片和 (b) GPT-4 中检索到的可视化图，展示了美国城市的平均租金最高情况。与 Google 图片中的可视化图相比，我们看到
    GPT-4 能够生成类似的城市排序，但提供了不同的平均租金值，可能是因为它检索的数据来自不同的年份。
- en: 2.3.2 Results
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 结果
- en: Overall GPT-4 performed very well, producing coherent responses to all prompts.
    For every prompt, it provided data requested in the prompt. We then evaluated
    whether each returned chart followed commonly accepted visualization design rules,
    given the specific data and query scenario. For this we used the widely accepted
    visualization cheat sheet developed by Patrik Lundblad at Qlik [[7](#bib.bib7)]
    shown in figure [2](#S1.F2 "Figure 2 ‣ 1 Background ‣ Can LLMs Generate Visualizations
    with Dataless Prompts?"). We found that every chart generated was appropriate!
    This can be gleaned from figure Can LLMs Generate Visualizations with Dataless
    Prompts? which shows the placement of each GPT-4 generated chart into the appropriate
    slot in Lundblad’s cheat sheet.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，GPT-4 的表现非常好，对所有提示都生成了连贯的响应。对于每个提示，它都提供了提示中请求的数据。然后我们评估了每个返回的图表是否遵循了通用的可视化设计规则，考虑了特定的数据和查询场景。为此，我们使用了
    Patrik Lundblad 在 Qlik 开发的广泛接受的可视化备忘单 [[7](#bib.bib7)]，如图 [2](#S1.F2 "Figure 2
    ‣ 1 Background ‣ Can LLMs Generate Visualizations with Dataless Prompts?") 所示。我们发现每个生成的图表都是合适的！这一点可以从图
    Can LLMs Generate Visualizations with Dataless Prompts? 中看出，其中展示了每个 GPT-4 生成的图表被放置在
    Lundblad 备忘单中的适当位置。
- en: GPT-4 faltered, however, when it came to reproducing the exact same data shown
    in the charts retrieved from Google Images. When generating line charts GPT-4
    could procudce charts with the same general trend, however the values were not
    identical and the trends were only correct at a larger scale. For example, in
    figure [1](#S0.F1 "Figure 1 ‣ Can LLMs Generate Visualizations with Dataless Prompts?")d,
    GPT-4 introduced a dip in the U.S. debt between the years 2013 to 2016 however
    the original data shown in figure [1](#S0.F1 "Figure 1 ‣ Can LLMs Generate Visualizations
    with Dataless Prompts?")a shows that the debt was monotonically increasing. When
    it came to generating rankings with bar charts (e.g., top UEFA football clubs,
    most expensive cities to rent in etc) GPT-4 appeared to be more accurate. It was
    able to generate the same overall ranking of items but the values represented
    by bars were inconsistent. See for example figure [3](#S2.F3 "Figure 3 ‣ 2.3.1
    Procedure ‣ 2.3 Dataless Prompts with GPT-4 ‣ 2 Study ‣ Can LLMs Generate Visualizations
    with Dataless Prompts?"), where a chart from Google images (a) reported the mean
    rent in New York to be $3260 while GPT-4 (b) reported it as $4100.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GPT-4 在再现 Google 图片中显示的确切数据时表现不佳。在生成折线图时，GPT-4 能够生成具有相同总体趋势的图表，但值并不完全相同，趋势仅在较大尺度上是正确的。例如，在图
    [1](#S0.F1 "Figure 1 ‣ Can LLMs Generate Visualizations with Dataless Prompts?")d
    中，GPT-4 引入了 2013 到 2016 年间美国债务的下降，而图 [1](#S0.F1 "Figure 1 ‣ Can LLMs Generate
    Visualizations with Dataless Prompts?")a 中显示的原始数据则表明债务是单调递增的。当涉及到生成排名的条形图时（例如，顶级
    UEFA 足球俱乐部、最昂贵的租房城市等），GPT-4 显得更为准确。它能够生成相同的整体排名，但条形图所表示的值不一致。例如，在图 [3](#S2.F3
    "Figure 3 ‣ 2.3.1 Procedure ‣ 2.3 Dataless Prompts with GPT-4 ‣ 2 Study ‣ Can
    LLMs Generate Visualizations with Dataless Prompts?") 中，来自 Google 图片 (a) 的图表报告纽约的平均租金为
    $3260，而 GPT-4 (b) 报告为 $4100。
- en: 3 Discussion and Conclusions
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 讨论与结论
- en: Our paper makes two contributions. First, we show that GPT-4 can return useful
    visualizations from dataless queries – queries that are not accompanied by associated
    data files, as has been common practice so far. It so absolves mainstream users
    from having to look for data files first before generating visualizations with
    GPT-4\. While the visualizations so produced are not perfect in every detail,
    they nevertheless indicate that GPT-4 has obtained a sufficient amount of data
    knowledge plus the skill to produce a visual rendition of it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的论文有两个贡献。首先，我们展示了 GPT-4 可以从没有数据文件的查询中返回有用的可视化图——这些查询没有附带相关的数据文件，这种情况在以前一直很常见。这使得主流用户无需在使用
    GPT-4 生成可视化图之前先寻找数据文件。虽然生成的可视化图在每一个细节上都不完美，但它们表明 GPT-4 已经获得了足够的数据知识和生成可视化图的技能。
- en: Second, we find that GPT-4 has been an excellent ’student’ of the art and science
    of data visualization, having learned an impressive amount of visualization knowledge
    from its ’teachers’, the many visualizations found on the web. We put GPT-4 to
    the test by asking it to fill in a commonly used visualization cheat sheet [[7](#bib.bib7)]
    where it reached a perfect score (compare figure Can LLMs Generate Visualizations
    with Dataless Prompts? with the cheat sheet published in [[7](#bib.bib7)]).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们发现 GPT-4 是数据可视化艺术和科学的优秀‘学生’，从其‘老师’——网络上的大量可视化中学到了令人印象深刻的可视化知识。我们通过让 GPT-4
    填写一个常用的可视化备忘单[[7](#bib.bib7)]来对其进行测试，它取得了满分（比较图 Can LLMs Generate Visualizations
    with Dataless Prompts? 与 [[7](#bib.bib7)] 中发布的备忘单）。
- en: During our experimentation, we noticed that GPT-4 seemed to insist on using
    specific visualizations for specific data queries, namely those shown in the cheat
    sheet, even when the prompt was moderately altered to create confusion. We value
    this as an indication that GPT-4’s visualization knowledge is fairly well expressed.
    solid, and ingrained.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验过程中，我们注意到 GPT-4 似乎坚持在特定的数据查询中使用特定的可视化，即备忘单中所示的那些，即使当提示稍微改变以造成混淆时也是如此。我们将此视为
    GPT-4 的可视化知识相当扎实且根深蒂固的迹象。
- en: Further, we also found that while GPT3.5 was not as reliable in creating the
    right type of visualization, it was still good at identifying the sources of data.
    To that end, a current line of our work is to identify effective mechanisms for
    LLMs to pull CSV files on its own from the respective online repositories, followed
    by running the code that generates the appropriate visualizations to provide users
    with results. Finally, we also believe that there is high promise in Dall-E to
    eventually be able to produce high quality infographics. We see this as another
    line of possible important future work.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还发现，虽然 GPT3.5 在创建正确类型的可视化方面不如 GPT-4 可靠，但在识别数据来源方面仍然表现良好。为此，我们当前的工作方向之一是识别有效的机制，使
    LLM 能够从各自的在线仓库中自动提取 CSV 文件，并运行生成适当可视化的代码，以向用户提供结果。最后，我们还认为 Dall-E 有很高的前景，最终能够生成高质量的信息图。我们视此为未来可能的重要工作方向之一。
- en: References
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] T. Brown, B. Mann, et al. Language models are few-shot learners. In H. Larochelle,
    M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, eds., Advances in Neural Information
    Processing Systems, vol. 33, pp. 1877–1901\. Curran Associates, Inc., 2020.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] T. Brown, B. Mann 等。语言模型是少量样本学习者。在 H. Larochelle, M. Ranzato, R. Hadsell,
    M. Balcan, 和 H. Lin 编，神经信息处理系统进展，第33卷，第1877–1901页。Curran Associates, Inc., 2020年。'
- en: '[2] W. Cleveland and R. McGill. Graphical perception: Theory, experimentation,
    and application to the development of graphical methods. Journal American Statistical
    Association, 79(387):531–554, 1984.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] W. Cleveland 和 R. McGill. 图形感知：理论、实验以及在图形方法开发中的应用。《美国统计协会杂志》，79(387)：531–554，1984年。'
- en: '[3] K. Cox, R. Grinter, S. Hibino, L. Jagadeesan, and D. Mantilla. A multi-modal
    natural language interface to an information visualization environment. Intern.
    Journal of Speech Technology, 4(3):297–314, 2001.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] K. Cox, R. Grinter, S. Hibino, L. Jagadeesan, 和 D. Mantilla. 多模态自然语言接口到信息可视化环境。国际语音技术杂志，4(3)：297–314，2001年。'
- en: '[4] V. Dibia. LIDA: A tool for automatic generation of grammar-agnostic visualizations
    and infographics using large language models. In D. Bollegala, R. Huang, and A. Ritter,
    eds., Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 3: System Demonstrations), pp. 113–126\. Toronto, Canada,
    July 2023.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] V. Dibia. LIDA：使用大型语言模型自动生成语法无关的可视化和信息图的工具。在 D. Bollegala, R. Huang, 和
    A. Ritter 编，计算语言学协会第61届年会论文集（卷3：系统演示），第113–126页。加拿大多伦多，2023年7月。'
- en: '[5] G. Li, X. Wang, G. Aodeng, S. Zheng, Y. Zhang, C. Ou, S. Wang, and C. H.
    Liu. Visualization generation with large language models: An evaluation, 2024\.
    [doi: 10 . 48550/arXiv . 2401 . 11255](https://doi.org/10.48550/arXiv.2401.11255)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] G. Li, X. Wang, G. Aodeng, S. Zheng, Y. Zhang, C. Ou, S. Wang, 和 C. H.
    Liu. 使用大型语言模型生成可视化：评估，2024年。[doi: 10 . 48550/arXiv . 2401 . 11255](https://doi.org/10.48550/arXiv.2401.11255)'
- en: '[6] C. Liu, Y. Han, R. Jiang, and X. Yuan. Advisor: Automatic visualization
    answer for natural-language question on tabular data. In 2021 IEEE 14th Pacific
    Visualization Symposium (PacificVis), pp. 11–20\. IEEE, 2021.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] C. Liu, Y. Han, R. Jiang, 和 X. Yuan. Advisor：对表格数据自然语言问题的自动可视化回答。在2021
    IEEE第14届太平洋可视化研讨会（PacificVis），第11–20页。IEEE，2021年。'
- en: '[7] P. Lundblad. Qlik: How to choose the right chart for your data. https://community.qlik.com/t5/Official-Support-Articles/How-to-Choose-the-Right-Chart/ta-p/1717241.
    Accessed: 2024-04-29.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] P. Lundblad. Qlik：如何为你的数据选择正确的图表。https://community.qlik.com/t5/Official-Support-Articles/How-to-Choose-the-Right-Chart/ta-p/1717241.
    访问日期：2024年4月29日。'
- en: '[8] Y. Luo, N. Tang, G. Li, J. Tang, C. Chai, and X. Qin. Natural language
    to visualization by neural machine translation. IEEE Transactions on Visualization
    and Computer Graphics, 28(1):217–226, 2022\. [doi: 10 . 1109/TVCG . 2021 . 3114848](https://doi.org/10.1109/TVCG.2021.3114848)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Y. Luo, N. Tang, G. Li, J. Tang, C. Chai 和 X. Qin. 通过神经机器翻译实现自然语言到可视化的转换。IEEE《可视化与计算机图形学汇刊》，28(1):217–226,
    2022年。[doi: 10.1109/TVCG.2021.3114848](https://doi.org/10.1109/TVCG.2021.3114848)'
- en: '[9] P. Maddigan and T. Susnjak. Chat2vis: Generating data visualizations via
    natural language using chatgpt, codex and gpt-3 large language models. IEEE Access,
    11:45181–45193, 2023\. [doi: 10 . 1109/ACCESS . 2023 . 3274199](https://doi.org/10.1109/ACCESS.2023.3274199)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] P. Maddigan 和 T. Susnjak. Chat2vis：通过自然语言生成数据可视化，使用ChatGPT、Codex和GPT-3大型语言模型。IEEE
    Access, 11:45181–45193, 2023年。[doi: 10.1109/ACCESS.2023.3274199](https://doi.org/10.1109/ACCESS.2023.3274199)'
- en: '[10] A. Narechania, A. Srinivasan, and J. Stasko. Nl4dv: A toolkit for generating
    analytic specifications for data visualization from natural language queries.
    IEEE Transactions on Visualization and Computer Graphics, 27(2):369–379, 2021\.
    [doi: 10 . 1109/TVCG . 2020 . 3030378](https://doi.org/10.1109/TVCG.2020.3030378)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] A. Narechania, A. Srinivasan 和 J. Stasko. NL4DV：一个从自然语言查询生成分析规范的工具包。IEEE《可视化与计算机图形学汇刊》，27(2):369–379,
    2021年。[doi: 10.1109/TVCG.2020.3030378](https://doi.org/10.1109/TVCG.2020.3030378)'
- en: '[11] OpenAI, J. Achiam, et al. Gpt-4 technical report, 2024\. [doi: 10 . 48550/arXiv . 2303 . 08774](https://doi.org/10.48550/arXiv.2303.08774)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] OpenAI, J. Achiam 等. GPT-4技术报告，2024年。[doi: 10.48550/arXiv.2303.08774](https://doi.org/10.48550/arXiv.2303.08774)'
- en: '[12] V. Setlur, S. E. Battersby, M. Tory, R. Gossweiler, and A. X. Chang. Eviza:
    A natural language interface for visual analysis. In Proc. UIST, 13 pages, p.
    365–377, 2016.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] V. Setlur, S. E. Battersby, M. Tory, R. Gossweiler 和 A. X. Chang. Eviza：一种用于视觉分析的自然语言接口。发表于UIST会议论文集，13页，第365–377页，2016年。'
- en: '[13] Y. Song, X. Zhao, R. C.-W. Wong, and D. Jiang. Rgvisnet: A hybrid retrieval-generation
    neural framework towards automatic data visualization generation. In Proceedings
    of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, p. 1646–1655,
    2022.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Song, X. Zhao, R. C.-W. Wong 和 D. Jiang. Rgvisnet：一种混合检索-生成神经框架，用于自动数据可视化生成。发表于第28届ACM
    SIGKDD知识发现与数据挖掘会议论文集，第1646–1655页，2022年。'
