- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:45:45'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:45:45
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical
    question answering
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 几-shot 思维链驱动的推理以提示 LLMs 进行开放式医学问题回答
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.04890](https://ar5iv.labs.arxiv.org/html/2403.04890)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.04890](https://ar5iv.labs.arxiv.org/html/2403.04890)
- en: Ojas Gramopadhye {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
    Saeel Sandeep Nachane {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Prateek Chanda {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Ganesh Ramakrishnan {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Kshitij Sharad Jadhav {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Yatin Nandwani {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
    Dinesh Raghu {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
    Sachindra Joshi {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Ojas Gramopadhye {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
    Saeel Sandeep Nachane {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Prateek Chanda {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Ganesh Ramakrishnan {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Kshitij Sharad Jadhav {20d180028@, prateekch@cse ,ganesh@cse, kshitij.jadhav@}.iitb.ac.in
    Yatin Nandwani {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
    Dinesh Raghu {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
    Sachindra Joshi {ojas.gramopadhye@, yatin.nandwani@, diraghu1@in, jsachind@in}.ibm.com
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language models (LLMs) have demonstrated significant potential in transforming
    healthcare by automating tasks such as clinical documentation, information retrieval,
    and decision support. In this aspect, carefully engineered prompts have emerged
    as a powerful tool to use LLMs for medical scenarios, e.g., patient clinical scenarios.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在通过自动化任务如临床文档、信息检索和决策支持来改变医疗保健方面展示了显著的潜力。在这一方面，精心设计的提示已成为利用 LLMs
    处理医疗场景（例如患者临床场景）的强大工具。
- en: In this paper, we propose a modified version of the MedQA-USMLE dataset, which
    is subjective, to mimic real-life clinical scenarios. We explore the Chain of
    Thought (CoT) reasoning based on subjective response generation for the modified
    MedQA-USMLE dataset with appropriate LM driven forward-reasoning for correct responses
    to the medical questions. Keeping in mind the importance of response verification
    in the medical setting, we utilize a reward training mechanism whereby the language
    model also provides an appropriate verified response for a particular response
    to a clinical question. In this regard, we also include human-in-the-loop for
    different evaluation aspects. We develop better in-contrast learning strategies
    by modifying the 5-shot-codex-CoT-prompt from (Liévin et al., [2022](#bib.bib12))
    for the subjective MedQA dataset and developing our incremental-reasoning prompt.
    Our evaluations show that the incremental reasoning prompt performs better than
    the modified codex prompt in certain scenarios. We also show that greedy decoding
    with the incremental reasoning method performs better than other strategies, such
    as prompt chaining and eliminative reasoning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一个经过修改的 MedQA-USMLE 数据集版本，该数据集是主观的，旨在模拟真实的临床场景。我们探索了基于主观响应生成的思维链（CoT）推理，结合适当的语言模型驱动的前向推理，以获取对医学问题的正确响应。考虑到医学环境中响应验证的重要性，我们采用了一种奖励训练机制，使语言模型能够为临床问题的特定响应提供适当的经过验证的回答。在这方面，我们还包括了人工干预以评估不同的方面。我们通过修改
    (Liévin et al., [2022](#bib.bib12)) 的 5-shot-codex-CoT-prompt 针对主观 MedQA 数据集，并开发了我们的增量推理提示，来开发更好的对比学习策略。我们的评估显示，在某些场景下，增量推理提示的表现优于修改后的
    codex 提示。我们还展示了，使用增量推理方法的贪婪解码在性能上优于其他策略，如提示链和消除性推理。
- en: Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical
    question answering
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几-shot 思维链驱动的推理以提示 LLMs 进行开放式医学问题回答
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large Language models (LLMs) are increasingly utilized in the healthcare sector,
    particularly for patient query-related tasks. These LLM-driven tools could potentially
    interpret and respond to patient inquiries, provide information on symptoms, diseases,
    treatments, and healthcare guidelines Thirunavukarasu et al. ([2023](#bib.bib17)).
    By analyzing vast amounts of medical literature and data, LLMs could also offer
    precise, up-to-date responses, improving patient education and engagement Singhal
    et al. ([2022](#bib.bib16)). The ability of LLMs to understand and process natural
    language queries makes them accessible and user-friendly, thus enhancing the patient
    experience and satisfaction Clusmann et al. ([2023](#bib.bib5)). As technology
    evolves, LLMs are expected to play a pivotal role in delivering personalized healthcare
    information, contributing to informed decision-making and better health outcomes
    Clusmann et al. ([2023](#bib.bib5)). However, with the recent advances in prompt
    engineering techniques in the Large Language Models space, there is an underlying
    requirement for accuracy and verifiability. In recent years, several methods in
    the space of verifiable LLMs have been proposed, such as Fact verification LLMs
    and COT-based LLMs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在医疗保健领域的应用越来越广泛，尤其是在处理患者查询相关任务方面。这些基于LLM的工具可能会解读并回应患者的询问，提供关于症状、疾病、治疗以及医疗指南的信息（Thirunavukarasu
    et al., [2023](#bib.bib17)）。通过分析大量的医学文献和数据，LLM还可以提供精准、最新的回答，从而提高患者的教育和参与度（Singhal
    et al., [2022](#bib.bib16)）。LLM理解和处理自然语言查询的能力使其更加易于使用，从而提升了患者的体验和满意度（Clusmann
    et al., [2023](#bib.bib5)）。随着技术的发展，LLM预计将在提供个性化医疗信息方面发挥关键作用，有助于做出知情决策并改善健康结果（Clusmann
    et al., [2023](#bib.bib5)）。然而，随着大型语言模型领域中提示工程技术的最新进展，对准确性和可验证性的要求也在不断增加。近年来，提出了几种可验证LLM的方法，如事实验证LLM和基于COT的LLM。
- en: '![Refer to caption](img/a1db88cec0425911aa9c21b54e1187d0.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a1db88cec0425911aa9c21b54e1187d0.png)'
- en: 'Figure 1: Forward and Eliminative prompting strategies overview'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：前向和消除提示策略概述
- en: 'Fact verification LLMs: Fact verification in large language models (LLMs) is
    an evolving field that spans multiple disciplines, including computational linguistics,
    artificial intelligence, and digital media. (Guo et al., [2022](#bib.bib7)) provides
    a comprehensive overview of automated fact-checking, defining it through stages
    such as claim detection, evidence retrieval, and claim verification. This framework
    emphasizes the multifaceted nature of fact-checking, which involves not only the
    assessment of a claim’s veracity but also the identification of relevant evidence
    and the generation of explanations for the verdicts given.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 事实验证LLM：大型语言模型（LLMs）中的事实验证是一个不断发展的领域，涉及多个学科，包括计算语言学、人工智能和数字媒体。（Guo et al., [2022](#bib.bib7)）提供了自动化事实检查的全面概述，通过声称检测、证据检索和声称验证等阶段定义了这一过程。这个框架强调了事实检查的多面性，这不仅涉及对声称真实性的评估，还包括识别相关证据和生成解释。
- en: 'Chain-of-Thought Prompting: Initially, scaling language models up appeared
    to benefit more knowledge-intensive tasks than reasoning-heavy ones (Rae et al.,
    2021). Nevertheless, Wei et al. ([2022](#bib.bib21)) demonstrated that LLMs could
    be applied to System 2 problems by prompting the model to generate step-by-step
    solutions, coined “Chain-of-Thought” (CoT). CoT prompting led to substantial improvements
    in many reasoning-intensive tasks Wei et al. ([2022](#bib.bib21)), Zhou et al.
    ([2022](#bib.bib23)),'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链提示：最初，扩大语言模型的规模似乎对知识密集型任务比推理密集型任务更有利（Rae et al., 2021）。然而，Wei et al.（[2022](#bib.bib21)）展示了通过提示模型生成逐步解决方案，将其称为“思维链”（CoT），LLM可以应用于系统2问题。CoT提示在许多推理密集型任务中带来了显著的改进（Wei
    et al., [2022](#bib.bib21)），（Zhou et al., [2022](#bib.bib23)），
- en: 'Drozdov et al. ([2022](#bib.bib6)); Nye et al. ([2021](#bib.bib14))), allowing
    to bridge the gap with human-level performances for most of the difficult BIG-bench
    tasks Chung et al. ([2022](#bib.bib4)). As an alternative to writing reference
    step-by-step solutions, zero-shot CoT (Kojima et al. ([2022](#bib.bib11))) allows
    for generating CoTs using single and domain-agnostic cues: “Let’s think step by
    step” (see example in Figure 1). The CoTs that result from that prompt not only
    appear to expose valid reasoning but also translate into superior zero-shot performances'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Drozdov 等人 ([2022](#bib.bib6)); Nye 等人 ([2021](#bib.bib14)))，使得在大多数困难的 BIG-bench
    任务中缩小了与人类水平表现的差距 Chung 等人 ([2022](#bib.bib4))。作为书写参考逐步解决方案的替代方法，零-shot CoT (Kojima
    等人 ([2022](#bib.bib11))) 允许使用单一和领域无关的提示生成 CoTs：“让我们一步步思考”（参见图 1 中的示例）。这种提示生成的
    CoTs 不仅似乎揭示了有效的推理，而且还转化为更优的零-shot 表现
- en: 1.1 Key Contributions
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 主要贡献
- en: 'We primarily focus on the USMLE-MedQA dataset (Jin et al., [2021](#bib.bib9)),
    an objective medical exam dataset. The dataset consists of questions sourced from
    professional medical board exams in the USA and is available in three languages:
    English, simplified Chinese, and traditional Chinese. The English subset utilized
    for this study consists of 12,723 questions, forming a comprehensive resource
    for investigating medical question answering in a standardized examination context.
    The current version of the dataset is not practically useful to be deployed in
    a patient query-based healthcare system since the responses to each such query
    are objective responses (either correct response or wrong response).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要关注 USMLE-MedQA 数据集（Jin 等人，[2021](#bib.bib9)），这是一个客观医学考试数据集。该数据集包含来自美国专业医学委员会考试的问题，并提供三种语言版本：英语、简体中文和繁体中文。用于本研究的英语子集包括
    12,723 个问题，形成了一个全面的资源，用于在标准化考试环境中研究医学问答。数据集的当前版本不适用于在基于患者查询的医疗系统中实际部署，因为对每个查询的响应都是客观响应（要么是正确响应，要么是错误响应）。
- en: Our contributions here are manifold
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献有很多
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a healthcare-specific language model response generation task that
    utilizes the best prompting methods.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种针对医疗保健的语言模型响应生成任务，该任务利用了最佳提示方法。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate that prospective incremental reasoning-driven prompting mimicking
    real-life clinical scenarios performs significantly better at answering open-ended
    medical questions.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了前瞻性的增量推理驱动的提示，模拟现实临床场景，在回答开放式医学问题方面表现显著更好。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We present efforts towards building a novel medical corpus that includes human-evaluated/verified
    subjective responses generated from a language model on the MedQA dataset.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了在 MedQA 数据集上构建新型医学语料库的努力，该语料库包括从语言模型生成的经人类评估/验证的主观回应。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We also contribute a modified MedQA dataset conducive to testing medical question-answering
    ability without options.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还贡献了一个修改后的 MedQA 数据集，适用于在没有选项的情况下测试医学问答能力。
- en: 2 Background & Related Work
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景与相关工作
- en: Recent advancements in the application of Large Language Models (LLMs) for medical
    question answering have highlighted the potential of these models to demonstrate
    applicability in medical diagnostics, education, and research. Venigalla et. al.,
    introduced BioMedLM, demonstrating its performance on several medical datasets,
    including MedQA, underscoring the capabilities of LLMs in handling complex medical
    queries (Venigalla et al., [2022](#bib.bib19); Jin et al., [2021](#bib.bib9)).
    Furthermore, Singhal et al.’s extensive experiments across a broad spectrum of
    medical question tasks within the MultiMedQA suite—encompassing datasets such
    as MedQA, MedMCQA, PubMedQA, and MMLU—have demonstrated the versatility and depth
    of knowledge encoded in these models (Singhal et al., [2022](#bib.bib16); Pal
    et al., [2022](#bib.bib15); Jin et al., [2019](#bib.bib10); Hendrycks et al.,
    [2020](#bib.bib8)).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在大规模语言模型（LLMs）应用于医学问答中的进展突显了这些模型在医学诊断、教育和研究中的潜力。Venigalla 等人介绍了 BioMedLM，展示了其在多个医学数据集上的表现，包括
    MedQA，强调了 LLMs 处理复杂医学查询的能力（Venigalla 等人，[2022](#bib.bib19); Jin 等人，[2021](#bib.bib9)）。此外，Singhal
    等人在 MultiMedQA 套件中对广泛医学问答任务的广泛实验——涵盖了如 MedQA、MedMCQA、PubMedQA 和 MMLU 等数据集——展示了这些模型中编码的知识的多样性和深度（Singhal
    等人，[2022](#bib.bib16); Pal 等人，[2022](#bib.bib15); Jin 等人，[2019](#bib.bib10); Hendrycks
    等人，[2020](#bib.bib8)）。
- en: The exploration of LLMs in generating not only accurate but also reasoning-based
    responses to medical questions marks a significant step forward. Models like PubMedGPT
    Bolton et al. ([2022](#bib.bib2)) and Codex (Liévin et al., [2022](#bib.bib12))
    have established benchmarks on datasets like MedQA through innovative approaches,
    including Classification head, Chain-of-Thought, and Knowledge Grounding, highlighting
    the importance of not just what is answered, but how the answer is derived. Advanced
    LLMs, such as Med-Palm2 Singhal et al. ([2022](#bib.bib16)), and Flan-Palm Chung
    et al. ([2022](#bib.bib4)), have further raised the bar for performance, although
    their limited availability poses challenges for widespread research and application
    in the medical field.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在生成不仅准确而且基于推理的医学问题回答方面的探索标志着一个重要的进步。像PubMedGPT Bolton et al. ([2022](#bib.bib2))和Codex
    (Liévin et al., [2022](#bib.bib12))这样的模型，通过创新的方法，包括分类头、链式思维和知识基础，在像MedQA这样的数据集上建立了基准，突出了不仅仅是回答了什么，更重要的是答案是如何得出的。先进的LLMs，如Med-Palm2
    Singhal et al. ([2022](#bib.bib16))和Flan-Palm Chung et al. ([2022](#bib.bib4))，进一步提高了性能的标准，尽管它们的有限可用性对医学领域的广泛研究和应用带来了挑战。
- en: In addition to these contributions, the work by authors such as Hendrycks et.
    al., on the Measuring Massive Multitask Language Understanding (MMLU) dataset
    presents a comprehensive evaluation of LLMs across a range of subjects, including
    medicine, pointing to the broad applicability and potential of LLMs beyond single-domain
    tasks (Hendrycks et al., [2020](#bib.bib8)). Another notable direction is the
    investigation into the interpretability and explainability of model predictions,
    as highlighted by Mesinovic et. al.,, which is critical for trust and reliability
    in medical applications (Mesinovic et al., [2023](#bib.bib13)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些贡献，Hendrycks等人关于测量大规模多任务语言理解（MMLU）数据集的工作，对LLMs在多个领域的综合评估，包括医学，显示了LLMs在单一领域任务之外的广泛适用性和潜力（Hendrycks
    et al., [2020](#bib.bib8)）。另一个显著的方向是对模型预测的可解释性和解释性的研究，如Mesinovic等人所强调的，这对于医学应用中的信任和可靠性至关重要（Mesinovic
    et al., [2023](#bib.bib13)）。
- en: '| MedQA-Original (MCQ Type) | MedQA-No-Opt (Descriptive Type) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| MedQA-Original（MCQ类型） | MedQA-No-Opt（描述性类型） |'
- en: '| Question: Four weeks after starting hydrochlorothiazide, a 49-year-old man
    with hypertension comes to the physician because of muscle cramps and weakness.
    His home medications also include amlodipine. His blood pressure today is 176/87
    mm Hg. Physical examination shows no abnormalities. The precordial leads of a
    12-lead ECG are shown. The addition of which of the following is most likely to
    have prevented this patient’s condition? (A) Torsemide (B) Nifedipine (C) Eplerenone
    (D) Hydralazine | Question: Four weeks after starting hydrochlorothiazide, a 49-year-old
    man with hypertension comes to the physician because of muscle cramps and weakness.
    His home medications also include amlodipine. His blood pressure today is 176/87
    mm Hg. Physical examination shows no abnormalities. The precordial leads of a
    12-lead ECG are shown. The addition of what is most likely to have prevented this
    patient’s condition? |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 问题：在开始使用氢氯噻吨四周后，一名49岁的高血压患者因肌肉痉挛和虚弱就医。他的家庭药物还包括氨氯地平。他今天的血压为176/87 mm Hg。体检未见异常。12导联心电图的前导联显示如下。以下哪项的添加最有可能防止了该患者的病情？
    (A) 托拉塞米 (B) 尼非地平 (C) 依普利酮 (D) 硝普钠 | 问题：在开始使用氢氯噻吨四周后，一名49岁的高血压患者因肌肉痉挛和虚弱就医。他的家庭药物还包括氨氯地平。他今天的血压为176/87
    mm Hg。体检未见异常。12导联心电图的前导联显示如下。以下哪项最有可能防止了该患者的病情？ |'
- en: 'Table 1: Sample Question from the USMLE-MedQA dataset along with its modified
    form. For more details, check Appendix A'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：USMLE-MedQA数据集中的示例问题及其修改形式。更多细节，请参阅附录A
- en: '![Refer to caption](img/13aae22efdc2faabec77da69cfd8dd0b.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/13aae22efdc2faabec77da69cfd8dd0b.png)'
- en: 'Figure 2: Codex COT looks at generating options in a more eliminative approach,
    often not catering to the context of clinical investigation, unlike differential
    diagnostics as per MedCodex'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：Codex COT在生成选项时采取更具排除性的方法，往往不考虑临床调查的背景，这与MedCodex的差异诊断不同
- en: '![Refer to caption](img/169ef6a36aa47e4947fe2df7c7ecb275.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/169ef6a36aa47e4947fe2df7c7ecb275.png)'
- en: ((a)) MedQA-Original Codex vs MedCodex
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ((a)) MedQA-Original Codex 与 MedCodex
- en: '![Refer to caption](img/34ed3fee6a7421731719057d0b53ebc5.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/34ed3fee6a7421731719057d0b53ebc5.png)'
- en: ((b)) MedQA-No-Opt Codex vs MedCodex
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ((b)) MedQA-No-Opt Codex 与 MedCodex
- en: 'Figure 3: Illustrative Example: Showcasing different Prompting Strategies across
    two dataset variants. context of the answer and corresponding reasoning and Future
    actions are highlighted.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：示例：展示了在两个数据集变体中不同的提示策略。答案的背景和相应的推理及未来行动被突出显示。
- en: 3 Problem Setting and Preliminary Notations
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 问题设置和初步符号
- en: Let us consider a language model at inference time $\mathcal{L}\mathcal{M}_{\boldsymbol{\theta}}:\mathcal{X}\rightarrow\mathcal{Y}$.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个推理时的语言模型$\mathcal{L}\mathcal{M}_{\boldsymbol{\theta}}:\mathcal{X}\rightarrow\mathcal{Y}$。
- en: Let the prompt $\boldsymbol{\mathcal{P}}=\langle q_{i},\boldsymbol{\mathcal{O}_{i}},\mathcal{R}^{i}\rangle$
    includes the corresponding reasoning quality as well as the correctness of the
    response based on ground truth.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让提示$\boldsymbol{\mathcal{P}}=\langle q_{i},\boldsymbol{\mathcal{O}_{i}},\mathcal{R}^{i}\rangle$包括相应的推理质量以及基于真实情况的响应正确性。
- en: 4 Experiments, Evaluation Methods and Results
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验、评估方法和结果
- en: 4.1 Datasets & Models
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集与模型
- en: Datasets The MedQA (Zhang et al., [2018](#bib.bib22)) dataset consists of multiple-choice
    questions based on United States Medical License Exams (USMLE). We modify the
    questions to seek descriptive responses and not remain objective multiple choice
    questions. We consider two variations of the MedQA dataset for our further experimentation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 MedQA（Zhang等，[2018](#bib.bib22)）数据集包含基于美国医学执照考试（USMLE）的多项选择题。我们修改这些问题以寻求描述性回应，而不是保持客观的多项选择问题。我们考虑MedQA数据集的两种变体用于进一步实验。
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MedQA-Original : We utilize the original MCQ type options format of the MedQA
    dataset, where we have the following $\langle\textit{Question, Option List}\rangle$.
    A sample is shown in Table [1](#S2.T1 "Table 1 ‣ 2 Background & Related Work ‣
    Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical
    question answering").'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MedQA-Original：我们使用MedQA数据集的原始MCQ类型选项格式，其中包含以下$\langle\textit{问题，选项列表}\rangle$。示例见表[1](#S2.T1
    "Table 1 ‣ 2 Background & Related Work ‣ Few shot chain-of-thought driven reasoning
    to prompt LLMs for open ended medical question answering")。
- en: •
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MedQA-No-Opt : Here, we consider the following format where the option list
    for a particular question $q_{i}$.'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MedQA-No-Opt：在这里，我们考虑以下格式，其中包含特定问题$q_{i}$的选项列表。
- en: 4.1.1 Conversion of MCQ type questions to descriptive type
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 MCQ类型问题转换为描述性类型
- en: The conversion of MCQ-type questions (MedQA-Original) to descriptive questions
    (MedQA-No-Opt) is aimed to emulate real-world medical scenarios where open-ended
    inquiries are prevalent. This modification required our model to respond without
    predefined choices, fostering holistic reasoning and integration of diverse knowledge
    sources. By eliminating answer options, we assessed the model’s depth and quality
    of reasoning skills, ensuring a more realistic evaluation of its performance in
    complex medical scenarios. To cater to a descriptive scenario, we slightly modify
    the question $q_{i}$ is done under clinical supervision with the help of medical
    experts.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 将MCQ类型问题（MedQA-Original）转换为描述性问题（MedQA-No-Opt）旨在模拟现实世界的医疗场景，在这些场景中开放式提问更为普遍。这一修改要求我们的模型在没有预定义选项的情况下作出回应，促进了整体推理和多样知识来源的整合。通过消除答案选项，我们评估了模型的推理深度和质量，确保在复杂医疗场景下更真实地评估其表现。为了适应描述性场景，我们在临床监督下略微修改了问题$q_{i}$，并借助医学专家的帮助完成这一过程。
- en: Models We use Llama2-7B chat and Llama2-70B chat model (Touvron et al., [2023](#bib.bib18))
    for our entire experimental evaluations.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 模型 我们使用Llama2-7B chat和Llama2-70B chat模型（Touvron等，[2023](#bib.bib18)）进行所有实验评估。
- en: 4.2 Prompting strategies
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 提示策略
- en: It is evident to see how we can utilize different prompting strategies for $\boldsymbol{\mathcal{P}}$
    i.e., how we would like the model to reason about reaching to a particular correct
    response.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见的是，我们可以如何利用不同的提示策略来处理$\boldsymbol{\mathcal{P}}$，即我们希望模型如何推理以达到特定的正确响应。
- en: 'Codex FewShot Prompts: Such prompting strategies first introduced in (Chen
    et al., [2021](#bib.bib3)) and subsequently in medical literature (Liévin et al.,
    [2022](#bib.bib12)) have shown to perform well on MCQ type questionnaire. For
    an MCQ-type question, the reasoning structure seems to follow the pattern:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Codex FewShot提示：这种提示策略首次在（Chen等，[2021](#bib.bib3)）中提出，随后在医学文献（Liévin等，[2022](#bib.bib12)）中也有所涉及，表现出在MCQ类型问卷上的良好效果。对于MCQ类型的问题，推理结构似乎遵循以下模式：
- en: '|  | $\mathcal{R}_{i}=\{o_{j}^{i}\in\boldsymbol{\mathcal{O}_{i}},r_{ij}\}_{j=1}^{m}$
    |  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{R}_{i}=\{o_{j}^{i}\in\boldsymbol{\mathcal{O}_{i}},r_{ij}\}_{j=1}^{m}$
    |  |'
- en: However, such kind of prompting strategies tends to be eliminative in nature,
    as shown in Fig. [2](#S2.F2 "Figure 2 ‣ 2 Background & Related Work ‣ Few shot
    chain-of-thought driven reasoning to prompt LLMs for open ended medical question
    answering") and often contradicts real-life clinical scenarios where prospective
    additive reasoning is needed for reaching a differential diagnosis. Further, the
    Codex prompt builds the entire context in one shot to reach the final answer.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种提示策略往往具有排除性质，如图 [2](#S2.F2 "图 2 ‣ 2 背景与相关工作 ‣ 几次推理链思维驱动提示 LLMs 进行开放性医疗问题回答")
    所示，并且往往与实际临床场景相矛盾，在这些场景中，需要前瞻性增量推理来达成差异诊断。此外，Codex 提示一次性建立整个背景以达成最终答案。
- en: 'MedCodex FewShot Prompts: Here, we utilize the intermittent reasoning structure
    given a unique medical context which builds upon every additive context in answering
    clinical questions that mimics the usual way of reaching a final diagnosis. In
    real clinical scenarios, there are no four options to choose from; the clinician
    takes a medical history, forms the mental structure for differential diagnosis,
    performs examinations, adds or deletes the potential diagnosis based on contextual
    information, and then ultimately takes into consideration the laboratory investigations
    to finally reach the diagnosis. The MedCodex FewShot Prompts mimics this strategy
    to reach a final answer.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: MedCodex FewShot 提示：在这里，我们利用了间歇性推理结构，结合独特的医疗背景，这种结构在回答临床问题时，依赖于每一个附加的上下文，模拟了通常达成最终诊断的方法。在实际的临床情境中，并没有四个选项供选择；临床医生会进行病史采集，形成差异诊断的思维结构，进行检查，根据上下文信息增减潜在诊断，最终结合实验室检查来得出诊断。MedCodex
    FewShot 提示模拟了这一策略，以达成最终答案。
- en: Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Few shot chain-of-thought driven
    reasoning to prompt LLMs for open ended medical question answering") refers to
    different classifications of prompting strategies based on their reasoning structure
    as well as their basis on the corresponding dataset (MCQ/ Descriptive Questions).
    In both prompt strategies, we use few shots $K=5$.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S1.F1 "图 1 ‣ 1 介绍 ‣ 几次推理链思维驱动提示 LLMs 进行开放性医疗问题回答") 指不同提示策略的分类，基于其推理结构以及对应的数据集（选择题/描述性问题）。在这两种提示策略中，我们使用了少量样本
    $K=5$。
- en: 4.3 Codex FewShot Prompts vs MedCodex FewShot Prompts on Original MedQA
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 Codex FewShot 提示 vs MedCodex FewShot 提示在原始 MedQA 上的对比
- en: 'Experimental Setup: We first utilize MedCodex FewShot Prompts due to its underlying
    prospective incremental reasoning structure, which typically follows the line
    of reasoning employed by medical professionals. Along with this, we compare responses
    collected using Codex FewShot Prompts where the reasoning is more eliminative
    in nature based on seeing the options and less attention is provided towards the
    clinical flow of argument (which also involves forming the entire clinical context
    in one go). The Llama2 70B Base and 70B Chat model were prompted using both strategies.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置：我们首先利用 MedCodex FewShot 提示，因为其潜在的前瞻性增量推理结构通常遵循医疗专业人员采用的推理思路。同时，我们将其与 Codex
    FewShot 提示收集的响应进行比较，后者的推理更具排除性质，基于查看选项，较少关注临床论证流程（这也涉及一次性形成整个临床背景）。Llama2 70B
    Base 和 70B Chat 模型都使用这两种策略进行了提示。
- en: 'Evaluation Strategy: The results of this experiment on the MedQA-Original’s
    1273 questions from the Test set are described in Table [2](#S4.T2 "Table 2 ‣
    4.3 Codex FewShot Prompts vs MedCodex FewShot Prompts on Original MedQA ‣ 4 Experiments,
    Evaluation Methods and Results ‣ Few shot chain-of-thought driven reasoning to
    prompt LLMs for open ended medical question answering")'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 评估策略：在 MedQA-Original 测试集的 1273 个问题上的实验结果在表格 [2](#S4.T2 "表格 2 ‣ 4.3 Codex FewShot
    提示 vs MedCodex FewShot 提示在原始 MedQA ‣ 4 实验、评估方法与结果 ‣ 几次推理链思维驱动提示 LLMs 进行开放性医疗问题回答")
    中描述。
- en: 'Observations:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：
- en: '| Methods | Accuracy Scores |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 |'
- en: '| --- | --- |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Llama2-70B-Base (Codex) | 54% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-70B-Base (Codex) | 54% |'
- en: '| Llama2-70B-Base (MedCodex) | 23% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-70B-Base (MedCodex) | 23% |'
- en: '| Llama2-70B-Chat (Codex) | 52% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-70B-Chat (Codex) | 52% |'
- en: '| Llama2-70B-Chat (MedCodex) | 50% |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| Llama2-70B-Chat (MedCodex) | 50% |'
- en: 'Table 2: CODEX FEWSHOT PROMPTS vs MEDCODEX FEWSHOT PROMPTS on Llama2-7B and
    Llama2-70B base and chat models'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 2：CODEX FEWSHOT 提示 vs MEDCODEX FEWSHOT 提示在 Llama2-7B 和 Llama2-70B 基础模型及聊天模型上的对比
- en: 'Interpretation: On the MedQA-Original, dataset, the MedCodex FewShot Prompts
    performed poorly as compared to Codex FewShot Prompts both on Llama2-70B base
    and 70B Chat model. Due to its inherent eliminative approach, the Codex FewShot
    Prompts has a smaller search space and results in higher accuracy.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 解释：在 MedQA-Original 数据集中，相较于 Codex FewShot Prompts，MedCodex FewShot Prompts
    在 Llama2-70B 基础版和 70B 聊天模型中的表现较差。由于其固有的消除方法，Codex FewShot Prompts 的搜索空间较小，结果精度更高。
- en: 4.4 Codex FewShot Prompts vs. MedCodex FewShot Prompts on Descriptive MedQA
    questions
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 Codex FewShot Prompts 与 MedCodex FewShot Prompts 在描述性 MedQA 问题上的比较
- en: 'Experimental Setup: We perform the experiment of comparing a modified version
    of the Codex FewShot Prompts and MedCodex FewShot Prompts on MedQA-No-Opt dataset.
    The Codex prompt is modified to remove options and their labels, to make it suited
    for a no options setting (Section: [4.2](#S4.SS2 "4.2 Prompting strategies ‣ 4
    Experiments, Evaluation Methods and Results ‣ Few shot chain-of-thought driven
    reasoning to prompt LLMs for open ended medical question answering")).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置：我们在 MedQA-No-Opt 数据集上比较了修改版的 Codex FewShot Prompts 和 MedCodex FewShot Prompts。Codex
    提示被修改以去除选项及其标签，以适应无选项的设置（章节：[4.2](#S4.SS2 "4.2 提示策略 ‣ 4 实验、评估方法和结果 ‣ 几次链式思维驱动的推理来提示
    LLMs 进行开放式医学问答")）。
- en: 'Evaluation Strategy: We select 100 questions from MedQA-No-Opt and evaluate
    via medical experts the final reasoning quality and final answer on a 3 point
    Likert scale (Batterton and Hale, [2017](#bib.bib1)) Agree, Neutral, Disagree.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 评估策略：我们从 MedQA-No-Opt 中选择了100个问题，并通过医学专家在3分制李克特量表上评估最终推理质量和最终答案（Batterton 和
    Hale，[2017](#bib.bib1)）同意、中立、不同意。
- en: 'Observations: As indicated in Figures [6](#S4.F6 "Figure 6 ‣ 4.6.1 Differential
    diagnosis generation with Trained Verifier on MedQA-on-opt Dataset ‣ 4.6 Experiments
    with Verifier ‣ 4 Experiments, Evaluation Methods and Results ‣ Few shot chain-of-thought
    driven reasoning to prompt LLMs for open ended medical question answering") and
    [7](#S4.F7 "Figure 7 ‣ 4.6.1 Differential diagnosis generation with Trained Verifier
    on MedQA-on-opt Dataset ‣ 4.6 Experiments with Verifier ‣ 4 Experiments, Evaluation
    Methods and Results ‣ Few shot chain-of-thought driven reasoning to prompt LLMs
    for open ended medical question answering"), for 82% and 77.85% of the questions,
    the expert medical personnel agreed with the reasoning and the evaluation provided
    by the MedCodex FewShot Prompts after prompting Llama2-7B-chat and Llama2-70B-chat
    models respectively. However, this was 72% and 82.5% subsequent to prompting Llama2-7B
    and Llama2-70B models, respectively, in the case of Codex FewShot Prompts.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 观察结果：如图[6](#S4.F6 "图 6 ‣ 4.6.1 使用训练的验证器生成差异诊断，在 MedQA-on-opt 数据集上 ‣ 4.6 验证器实验
    ‣ 4 实验、评估方法和结果 ‣ 几次链式思维驱动的推理来提示 LLMs 进行开放式医学问答")和[7](#S4.F7 "图 7 ‣ 4.6.1 使用训练的验证器生成差异诊断，在
    MedQA-on-opt 数据集上 ‣ 4.6 验证器实验 ‣ 4 实验、评估方法和结果 ‣ 几次链式思维驱动的推理来提示 LLMs 进行开放式医学问答")中所示，对于82%和77.85%的问题，专家医疗人员同意使用
    MedCodex FewShot Prompts 在分别提示 Llama2-7B-chat 和 Llama2-70B-chat 模型后提供的推理和评估。然而，在使用
    Codex FewShot Prompts 提示 Llama2-7B 和 Llama2-70B 模型的情况下，这一比例分别为72%和82.5%。
- en: 'Interpretations: Given the open-ended nature of MedQA-No-Opt dataset, the incremental
    generative approach of reasoning to reach the final answer by the MedCodex FewShot
    Prompts is qualitatively superior compared to Codex FewShot Prompts for Llama2-7B-chat
    model. This could be because the Codex FewShot Prompts is designed to work best
    on a restricted universe of options for MCQ-based questions. This also indicates
    that mimicking the human process of reaching the final answer in diverse medical
    scenarios (as performed by MedCodex FewShot Prompts) is better in scenarios of
    open-ended questions while prompting smaller parameter models. However, Codex
    FewShot Prompts is better able to leverage a larger model (Llama2-70B-chat).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 解释：鉴于 MedQA-No-Opt 数据集的开放性特点，相较于 Codex FewShot Prompts，MedCodex FewShot Prompts
    采用的逐步生成推理方法在 Llama2-7B-chat 模型中在定性上更为优越。这可能是因为 Codex FewShot Prompts 设计上更适合于多项选择题的有限选项宇宙。这也表明，在开放式问题的场景下，模仿人类在各种医学情境下得出最终答案的过程（如
    MedCodex FewShot Prompts 所执行的）在提示较小参数模型时表现更佳。然而，Codex FewShot Prompts 在利用更大模型（Llama2-70B-chat）时表现更佳。
- en: 4.5 Differential diagnosis generation with Codex for Selection on MedQA-no-opt
    Dataset
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 使用 Codex 进行差异诊断生成以选择 MedQA-no-opt 数据集
- en: 'Experimental Setup: Each question $\boldsymbol{q_{i}}$ with the Codex FewShot
    Prompts to select the most appropriate option. To create a set of 4 options through
    sampling, 10 unique options are sampled by filtering on a word-level match basis
    (to avoid selecting options that are repetitive). Out of these, the top 4 are
    selected through the perplexity of model outputs.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置：每个问题 $\boldsymbol{q_{i}}$ 使用 Codex FewShot Prompts 选择最合适的选项。通过抽样生成 4 个选项，从中筛选
    10 个独特的选项（以避免选择重复的选项），这些选项是基于词级匹配进行过滤的。在这些选项中，前 4 个通过模型输出的困惑度进行选择。
- en: 'Evaluation Methods: We evaluate via medical expert the final reasoning quality
    and final answer on a 3-point Likert scale (Batterton and Hale, [2017](#bib.bib1))
    Agree, Neutral, Disagree.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 评价方法：我们通过医疗专家对最终推理质量和最终答案进行评估，使用 3 分制李克特量表（Batterton 和 Hale, [2017](#bib.bib1)）进行评估，包括同意、中立和不同意。
- en: 'Observations: As indicated in Figures [6](#S4.F6 "Figure 6 ‣ 4.6.1 Differential
    diagnosis generation with Trained Verifier on MedQA-on-opt Dataset ‣ 4.6 Experiments
    with Verifier ‣ 4 Experiments, Evaluation Methods and Results ‣ Few shot chain-of-thought
    driven reasoning to prompt LLMs for open ended medical question answering") and
    [7](#S4.F7 "Figure 7 ‣ 4.6.1 Differential diagnosis generation with Trained Verifier
    on MedQA-on-opt Dataset ‣ 4.6 Experiments with Verifier ‣ 4 Experiments, Evaluation
    Methods and Results ‣ Few shot chain-of-thought driven reasoning to prompt LLMs
    for open ended medical question answering"), for 80% and 89.5% of the questions,
    the expert medical personnel agreed with the reasoning and the evaluation provided
    by the Differential diagnosis generation (using MedCodex FewShot Prompts) followed
    by Codex FewShot Prompts for Selection on MedQA-No-Opt Dataset after prompting
    Llama2-7B-chat and Llama2-70B-chat parameter models respectively.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：如图 [6](#S4.F6 "Figure 6 ‣ 4.6.1 Differential diagnosis generation with Trained
    Verifier on MedQA-on-opt Dataset ‣ 4.6 Experiments with Verifier ‣ 4 Experiments,
    Evaluation Methods and Results ‣ Few shot chain-of-thought driven reasoning to
    prompt LLMs for open ended medical question answering") 和 [7](#S4.F7 "Figure 7
    ‣ 4.6.1 Differential diagnosis generation with Trained Verifier on MedQA-on-opt
    Dataset ‣ 4.6 Experiments with Verifier ‣ 4 Experiments, Evaluation Methods and
    Results ‣ Few shot chain-of-thought driven reasoning to prompt LLMs for open ended
    medical question answering") 所示，对于 80% 和 89.5% 的问题，专家医疗人员同意通过 MedCodex FewShot
    Prompts 生成的差异诊断以及随后由 Codex FewShot Prompts 进行选择的评估结果，这些问题是在分别提示 Llama2-7B-chat
    和 Llama2-70B-chat 参数模型后对 MedQA-No-Opt 数据集进行的。
- en: 'Interpretation: Since the MedQA-No-Opt dataset questions are open-ended, we
    tried to restrict the pool from which the correct answers could be selected by
    generating four top answers. This was inspired by the Self-consistency approach
    of Codex Few Shot paper Wei et al. ([2022](#bib.bib21)). As expected, the larger
    Llama2-70B model prompting worked better than the Llama2-7B model. Importantly,
    this process was significantly better than all prompting strategies indicating
    the utility of leveraging the option creation process using MedCodex FewShot Prompts
    and subsequent selection by Codex FewShot Prompts.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 解释：由于 MedQA-No-Opt 数据集的问题是开放性的，我们尝试通过生成四个最佳答案来限制可以选择的正确答案池。这一做法受到 Codex Few
    Shot 论文 Wei 等人 ([2022](#bib.bib21)) 中自一致性方法的启发。正如预期的那样，较大的 Llama2-70B 模型提示效果优于
    Llama2-7B 模型。重要的是，这一过程明显优于所有提示策略，显示了利用 MedCodex FewShot Prompts 进行选项创建和随后由 Codex
    FewShot Prompts 进行选择的有效性。
- en: 4.6 Experiments with Verifier
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 验证器实验
- en: Motivation for Verifier and its training So far, we have approached the problem
    with an in-context learning perspective without changing the model parameters.
    We believe building on top of powerful models like the Llama2 chat series could
    give us a significant advantage in this scenario. We endeavored to improve performance
    by substituting the Codex FewShot Prompts prompt with a verifier Reward learning
    model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 验证器的动机及其训练：迄今为止，我们采用了上下文学习的视角来解决问题，而没有更改模型参数。我们相信，基于像 Llama2 聊天系列这样强大的模型进行构建，能够在这种情况下带来显著优势。我们尝试通过将
    Codex FewShot Prompts 提示替换为验证器奖励学习模型来提高性能。
- en: Verifier Dataset Contribution The training dataset for the verifier $\boldsymbol{\mathcal{D}_{ver}}$
    was constructed by gathering medical expert evaluations towards the correctness
    of model-generated responses. A representative sample of 100 questions was selected
    from the MedQA-No-Opt and divided into two subsets for inter-annotator agreement
    evaluation. Multiple medical experts independently assessed the correctness of
    responses generated by the Llama2-70B chat model, utilizing a newly designed verification
    prompt on the 3-point scale. The response sets encompassed both positive (correct
    answer) and negative (incorrect answer) pairs to evaluate the verifier’s ability
    to distinguish between them. Anonymity was maintained by not disclosing the actual
    correctness of the responses to the medical experts. The medical experts exhibited
    a commendable ability to discern the reasoning behind incorrect answers, emphasizing
    the value of their annotations for training the verifier. This annotated data
    was employed to train our reward model, with positive pairs acting as chosen pairs
    and negative pairs as rejected pairs.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 验证者数据集贡献 验证者的训练数据集$\boldsymbol{\mathcal{D}_{ver}}$是通过收集医学专家对模型生成回答的正确性评估而构建的。我们从MedQA-No-Opt中选取了100个具有代表性的问题，并将其分为两个子集以进行标注者一致性评估。多个医学专家独立评估Llama2-70B聊天模型生成的回答的正确性，使用了在3点评分尺度上新设计的验证提示。回答集合包括正向（正确答案）和负向（错误答案）对，以评估验证者区分它们的能力。通过不向医学专家披露回答的实际正确性来保持匿名性。医学专家展现出了出色的辨别错误答案推理的能力，这突显了他们的注释在训练验证者中的价值。这个注释数据被用于训练我们的奖励模型，正向对作为选择对，负向对作为拒绝对。
- en: We use pairwise “chosen-rejected” pairs of strings consisting of $\langle\boldsymbol{q}_{i};\boldsymbol{\mathcal{R}}_{i};\boldsymbol{\mathcal{A}}_{i}\rangle$.
    We use the MedQA-Original dataset with 4 options to create these pairs. Here,
    we take the known correct option for the ‘chosen’ part and switch the incorrect
    options for the ‘rejected’ part to create three pairs with one question sample.
    We borrow the Question and Answer parts of the triplet from the MedQA dataset
    and generate the Reasoning artificially by prompting the Llama2-7b-chat model.
    These results have been verified by medical experts. The prompt and input format
    for this are given below in Fig [4](#S4.F4 "Figure 4 ‣ 4.6 Experiments with Verifier
    ‣ 4 Experiments, Evaluation Methods and Results ‣ Few shot chain-of-thought driven
    reasoning to prompt LLMs for open ended medical question answering").
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了由$\langle\boldsymbol{q}_{i};\boldsymbol{\mathcal{R}}_{i};\boldsymbol{\mathcal{A}}_{i}\rangle$组成的逐对“选择-拒绝”字符串对。我们使用包含4个选项的MedQA-Original数据集来创建这些对。在这里，我们将已知的正确选项作为‘选择’部分，并将不正确的选项作为‘拒绝’部分，创建三个对，每个对都包含一个问题样本。我们从MedQA数据集中借用问题和回答部分，并通过提示Llama2-7b-chat模型人工生成推理。这些结果已经经过医学专家验证。有关此操作的提示和输入格式见下图[4](#S4.F4
    "图 4 ‣ 4.6 验证者实验 ‣ 4 实验、评估方法与结果 ‣ 少量样本链式思维驱动推理以提示LLMs进行开放式医学问题回答")。
- en: '![Refer to caption](img/fd06c07e3a6a2cd8e659480d16dbc418.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fd06c07e3a6a2cd8e659480d16dbc418.png)'
- en: 'Figure 4: Verifier Reasoning Generation'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: 验证者推理生成'
- en: Training We have fine-tuned the Llama2 7B-chat model for the reward model training
    followed by a linear head. We are applying LoRA for fine-tuning using the trl
    library from Hugging Face for this purpose. The model is trained on a reward modeling
    loss from Wang et al. ([2024](#bib.bib20)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 我们对Llama2 7B-chat模型进行了奖励模型训练的微调，然后是线性头。我们应用LoRA进行微调，使用Hugging Face的trl库来完成此任务。该模型在Wang等人提出的奖励建模损失上进行训练（[2024](#bib.bib20)）。
- en: '|  | $1$2 |  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: Where $\boldsymbol{q_{i}}$ denotes the reward margin. In our case, we utilize
    the reward margin = 0.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\boldsymbol{q_{i}}$表示奖励边际。在我们的情况下，我们使用奖励边际= 0。
- en: 4.6.1 Differential diagnosis generation with Trained Verifier on MedQA-on-opt
    Dataset
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.6.1 使用训练的验证者在MedQA-on-opt数据集上生成鉴别诊断
- en: 'Experimental Setup: We sample forward options as in the previous experiment
    [4.5](#S4.SS5 "4.5 Differential diagnosis generation with Codex for Selection
    on MedQA-no-opt Dataset ‣ 4 Experiments, Evaluation Methods and Results ‣ Few
    shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question
    answering"), then pass the generated options with their reasoning, as shown in
    Figure [5](#S4.F5 "Figure 5 ‣ 4.6.1 Differential diagnosis generation with Trained
    Verifier on MedQA-on-opt Dataset ‣ 4.6 Experiments with Verifier ‣ 4 Experiments,
    Evaluation Methods and Results ‣ Few shot chain-of-thought driven reasoning to
    prompt LLMs for open ended medical question answering") figure, to the verifier.
    We choose the option that produces the highest scalar reward. This experiment
    was performed only for the Llama2 7B parameter model due to resource constraints.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置：我们如前一个实验中所示，采样前向选项[4.5](#S4.SS5 "4.5 使用Codex进行MedQA-no-opt数据集选择的差异诊断生成
    ‣ 4 实验、评估方法和结果 ‣ 基于Few shot链式思维的推理提示LLMs以回答开放性医学问题")，然后将生成的选项及其推理，如图[5](#S4.F5
    "图5 ‣ 4.6.1 使用训练过的验证器在MedQA-on-opt数据集上的差异诊断生成 ‣ 4.6 使用验证器的实验 ‣ 4 实验、评估方法和结果 ‣
    基于Few shot链式思维的推理提示LLMs以回答开放性医学问题")所示，传递给验证器。我们选择产生最高标量奖励的选项。由于资源限制，这个实验只针对Llama2
    7B参数模型进行。
- en: 'Evaluation Methods: We select 100 questions from MedQA-No-Opt and evaluate
    via medical experts the final reasoning quality and final answer on a 3 point
    Likert scale (Batterton and Hale, [2017](#bib.bib1)) Agree, Neutral, Disagree.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 评估方法：我们从MedQA-No-Opt中选择100个问题，通过医学专家评估最终的推理质量和最终答案，采用3点评级量表（Batterton和Hale，[2017](#bib.bib1)）同意、中立、不同意。
- en: 'Observations: As indicated in Figure [6](#S4.F6 "Figure 6 ‣ 4.6.1 Differential
    diagnosis generation with Trained Verifier on MedQA-on-opt Dataset ‣ 4.6 Experiments
    with Verifier ‣ 4 Experiments, Evaluation Methods and Results ‣ Few shot chain-of-thought
    driven reasoning to prompt LLMs for open ended medical question answering"), for
    86% of the questions, the expert medical personnel agreed with the reasoning and
    the evaluation provided by the Differential diagnosis generation (using MedCodex
    FewShot Prompts) followed by Verifier for Selection on MedQA-No-Opt Dataset after
    prompting Llama2 7B-chat model.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：如图[6](#S4.F6 "图6 ‣ 4.6.1 使用训练过的验证器在MedQA-on-opt数据集上的差异诊断生成 ‣ 4.6 使用验证器的实验
    ‣ 4 实验、评估方法和结果 ‣ 基于Few shot链式思维的推理提示LLMs以回答开放性医学问题")所示，对于86%的问题，专家医学人员同意由差异诊断生成（使用MedCodex
    FewShot Prompts）后由验证器进行选择的推理和评估，针对Llama2 7B-chat模型的MedQA-No-Opt数据集。
- en: 'Interpretation: The development of the Verifier substantially improves the
    ability of Llama2 7B parameter model to select the response with high quality
    of explainability as well as high accuracy, indicating the viability of such an
    approach to beat larger parameter models by alternative prompting strategies.
    We hypothesize that the Verifier being trained to identify good quality reasoning
    can result in better abilities to select the most probable answer subsequent to
    the 4 option generation driven by MedCodex FewShot Prompts. We suspect that testing
    this strategy on the Llama70B model would provide significantly better results.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 解释：验证器的开发显著提高了Llama2 7B参数模型选择具有高解释质量和高准确度的响应的能力，这表明这种方法通过替代的提示策略有可能超越更大参数模型。我们假设，通过训练验证器识别优质推理，可以更好地选择在MedCodex
    FewShot Prompts驱动的4选项生成后的最可能答案。我们怀疑在Llama70B模型上测试这种策略将会提供显著更好的结果。
- en: '![Refer to caption](img/94b314398a42f52d3055709ff442238c.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/94b314398a42f52d3055709ff442238c.png)'
- en: 'Figure 5: Verifier Input'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：验证器输入
- en: '![Refer to caption](img/36396fb00ded260bc0e2bc8fcad0edb9.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/36396fb00ded260bc0e2bc8fcad0edb9.png)'
- en: 'Figure 6: Results for experiments on MedQA-no-opt dataset with Llama-2-7B-chat'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：Llama-2-7B-chat在MedQA-no-opt数据集上的实验结果
- en: '![Refer to caption](img/b267c728041ac76740e8831f70d57ea3.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b267c728041ac76740e8831f70d57ea3.png)'
- en: 'Figure 7: Results for experiments on MedQA-no-opt dataset with Llama-2-70B-chat'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：Llama-2-70B-chat在MedQA-no-opt数据集上的实验结果
- en: Conclusion and Future work
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论与未来工作
- en: The incremental reasoning chain of thought prompting is a novel prompting methodology
    developed by us that follows the usual clinical approach of reaching a decision
    in real-life clinical settings. We demonstrate that this strategy gives significantly
    better results than the CODEX prompting strategy, which is designed for MCQ-type
    questions. Further, we demonstrate that the verifier developed using reasoning
    performs much better at selecting agreeable responses from the Llama-2 models.
    Further research will focus on testing the Verifier-driven answer selection using
    the Llama2-70B-chat model, and we would explore the generalizability of this approach
    by testing on other open-source LLMs.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 增量推理链思维提示是一种由我们开发的新颖提示方法，遵循在实际临床环境中达成决策的常规临床方法。我们展示了这一策略比为MCQ类型问题设计的CODEX提示策略效果显著更好。此外，我们展示了使用推理开发的验证器在从Llama-2模型中选择一致回应方面表现更佳。进一步的研究将重点测试使用Llama2-70B-chat模型的验证器驱动的回答选择，并探索通过在其他开源LLM上进行测试来验证这一方法的普适性。
- en: '5 Limitations:'
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 限制：
- en: This paper does not train an LLM from scratch and only leverages pre-trained
    models. The quality of the model response depends on the quality of the forward-looking
    prompt. The current process has been only demonstrated on Llama-2 models and needs
    to be tested on other models to demonstrate generalizability.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本文不从头训练LLM，只利用预训练模型。模型响应的质量依赖于前瞻性提示的质量。当前过程仅在Llama-2模型上进行了演示，需要在其他模型上进行测试以证明其普适性。
- en: Acknowledgements
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: References
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Batterton and Hale (2017) Katherine A Batterton and Kimberly N Hale. 2017. The
    likert scale what it is and how to use it. *Phalanx*, 50(2):32–39.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Batterton 和 Hale（2017）Katherine A Batterton 和 Kimberly N Hale。2017年。利克特量表：它是什么以及如何使用它。*Phalanx*,
    50(2):32–39。
- en: Bolton et al. (2022) E Bolton et al. 2022. Pubmedgpt 2.7 b. Technical report,
    Technical report. Stanford University Center for Research on Foundation ….
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolton等（2022）E Bolton等。2022年。Pubmedgpt 2.7 b。技术报告，技术报告。斯坦福大学基础研究中心……
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021. Evaluating large language models trained on code.
    *arXiv preprint arXiv:2107.03374*.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等（2021）Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde
    de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
    Brockman, 等。2021年。评估训练在代码上的大语言模型。*arXiv预印本 arXiv:2107.03374*。
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    2022. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung等（2022）Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William
    Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, 等。2022年。扩展指令微调语言模型。*arXiv预印本
    arXiv:2210.11416*。
- en: Clusmann et al. (2023) Jan Clusmann, Fiona R Kolbinger, Hannah Sophie Muti,
    Zunamys I Carrero, Jan-Niklas Eckardt, Narmin Ghaffari Laleh, Chiara Maria Lavinia
    Löffler, Sophie-Caroline Schwarzkopf, Michaela Unger, Gregory P Veldhuizen, et al.
    2023. The future landscape of large language models in medicine. *Communications
    Medicine*, 3(1):141.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clusmann等（2023）Jan Clusmann, Fiona R Kolbinger, Hannah Sophie Muti, Zunamys
    I Carrero, Jan-Niklas Eckardt, Narmin Ghaffari Laleh, Chiara Maria Lavinia Löffler,
    Sophie-Caroline Schwarzkopf, Michaela Unger, Gregory P Veldhuizen, 等。2023年。医学中大语言模型的未来格局。*通讯医学*,
    3(1):141。
- en: Drozdov et al. (2022) Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan
    Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou. 2022. Compositional
    semantic parsing with large language models. *arXiv preprint arXiv:2209.15003*.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Drozdov等（2022）Andrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales,
    Xinying Song, Xinyun Chen, Olivier Bousquet, 和 Denny Zhou。2022年。利用大语言模型进行组合语义解析。*arXiv预印本
    arXiv:2209.15003*。
- en: Guo et al. (2022) Zhijiang Guo, Michael Schlichtkrull, and Andreas Vlachos.
    2022. A survey on automated fact-checking. *Transactions of the Association for
    Computational Linguistics*, 10:178–206.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo等（2022）Zhijiang Guo, Michael Schlichtkrull, 和 Andreas Vlachos。2022年。自动化事实核查调查。*计算语言学会会刊*,
    10:178–206。
- en: Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring massive multitask
    language understanding. *arXiv preprint arXiv:2009.03300*.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks等（2020）Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas
    Mazeika, Dawn Song, 和 Jacob Steinhardt。2020年。测量大规模多任务语言理解。*arXiv预印本 arXiv:2009.03300*。
- en: Jin et al. (2021) Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi
    Fang, and Peter Szolovits. 2021. What disease does this patient have? a large-scale
    open domain question answering dataset from medical exams. *Applied Sciences*,
    11(14):6421.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin et al. (2021) Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi
    Fang, and Peter Szolovits. 2021. 这个病人得了什么病？来自医学考试的大规模开放领域问答数据集。*应用科学*，11(14):6421。
- en: 'Jin et al. (2019) Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W Cohen,
    and Xinghua Lu. 2019. Pubmedqa: A dataset for biomedical research question answering.
    *arXiv preprint arXiv:1909.06146*.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin et al. (2019) Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W Cohen,
    and Xinghua Lu. 2019. Pubmedqa：一个用于生物医学研究问答的数据集。*arXiv 预印本 arXiv:1909.06146*。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners.
    *Advances in neural information processing systems*, 35:22199–22213.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. 大型语言模型是零-shot推理器。*神经信息处理系统进展*，35:22199–22213。
- en: Liévin et al. (2022) Valentin Liévin, Christoffer Egeberg Hother, and Ole Winther.
    2022. Can large language models reason about medical questions? *arXiv preprint
    arXiv:2207.08143*.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liévin et al. (2022) Valentin Liévin, Christoffer Egeberg Hother, and Ole Winther.
    2022. 大型语言模型能否推理医学问题？*arXiv 预印本 arXiv:2207.08143*。
- en: 'Mesinovic et al. (2023) Munib Mesinovic, Peter Watkinson, and Tingting Zhu.
    2023. Explainable ai for clinical risk prediction: a survey of concepts, methods,
    and modalities. *arXiv preprint arXiv:2308.08407*.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesinovic et al. (2023) Munib Mesinovic, Peter Watkinson, and Tingting Zhu.
    2023. 临床风险预测的可解释人工智能：概念、方法和模式的综述。*arXiv 预印本 arXiv:2308.08407*。
- en: 'Nye et al. (2021) Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk
    Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten
    Bosma, David Luan, et al. 2021. Show your work: Scratchpads for intermediate computation
    with language models. *arXiv preprint arXiv:2112.00114*.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nye et al. (2021) Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk
    Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten
    Bosma, David Luan, et al. 2021. 展示你的工作：与语言模型进行中间计算的草稿本。*arXiv 预印本 arXiv:2112.00114*。
- en: 'Pal et al. (2022) Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu.
    2022. Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain
    question answering. In *Conference on Health, Inference, and Learning*, pages
    248–260\. PMLR.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pal et al. (2022) Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu.
    2022. Medmcqa：用于医学领域问答的大规模多学科多选数据集。在*健康、推理和学习会议*上，第248–260页。PMLR。
- en: Singhal et al. (2022) Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi,
    Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen
    Pfohl, et al. 2022. Large language models encode clinical knowledge. *arXiv preprint
    arXiv:2212.13138*.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal et al. (2022) Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi,
    Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen
    Pfohl, et al. 2022. 大型语言模型编码临床知识。*arXiv 预印本 arXiv:2212.13138*。
- en: Thirunavukarasu et al. (2023) Arun James Thirunavukarasu, Darren Shu Jeng Ting,
    Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. 2023.
    Large language models in medicine. *Nature medicine*, 29(8):1930–1940.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thirunavukarasu et al. (2023) Arun James Thirunavukarasu, Darren Shu Jeng Ting,
    Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. 2023.
    医学中的大型语言模型。*自然医学*，29(8):1930–1940。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2：开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*。
- en: 'Venigalla et al. (2022) A Venigalla, J Frankle, and M Carbin. 2022. Biomedlm:
    a domain-specific large language model for biomedical text. *MosaicML. Accessed:
    Dec*, 23(3):2.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Venigalla et al. (2022) A Venigalla, J Frankle, and M Carbin. 2022. Biomedlm：一种用于生物医学文本的领域特定大型语言模型。*MosaicML。访问时间：Dec*，23(3):2。
- en: 'Wang et al. (2024) Binghai Wang, Rui Zheng, Lu Chen, Yan Liu, Shihan Dou, Caishuang
    Huang, Wei Shen, Senjie Jin, Enyu Zhou, Chenyu Shi, Songyang Gao, Nuo Xu, Yuhao
    Zhou, Xiaoran Fan, Zhiheng Xi, Jun Zhao, Xiao Wang, Tao Ji, Hang Yan, Lixing Shen,
    Zhan Chen, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, and Yu-Gang
    Jiang. 2024. [Secrets of rlhf in large language models part ii: Reward modeling](http://arxiv.org/abs/2401.06080).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等（2024）冰海王、瑞郑、陆辰、燕刘、士翰杜、彩霜黄、魏申、森杰金、恩宇周、晨雨石、宋阳高、诺徐、宇昊周、肖然范、志恒席、君赵、肖王、涛季、杭燕、立兴申、詹陈、涛桂、齐张、西鹏裘、轩靖黄、祖轩吴和于刚江。2024年。[大型语言模型中的强化学习奖励建模秘密第二部分](http://arxiv.org/abs/2401.06080)。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韦等（2022）贾森韦、薛志旺、戴尔舒尔曼斯、马滕博斯马、费霞、艾德·池、阮氏维·乐、丹尼周等。2022年。链式思维提示在大型语言模型中的推理激发。*神经信息处理系统进展*，35：24824–24837。
- en: Zhang et al. (2018) Xiao Zhang, Ji Wu, Zhiyang He, Xien Liu, and Ying Su. 2018.
    Medical exam question answering with large-scale reading comprehension. In *Proceedings
    of the AAAI conference on artificial intelligence*, volume 32.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等（2018）肖张、季武、智阳赫、谢刘和颖苏。2018年。大型阅读理解中的医学考试问题回答。在*AAAI人工智能会议论文集*，第32卷。
- en: Zhou et al. (2022) Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu.
    2022. Learning to prompt for vision-language models. *International Journal of
    Computer Vision*, 130(9):2337–2348.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周等（2022）凯扬周、景康杨、陈昌乐和子伟刘。2022年。为视觉-语言模型学习提示。*国际计算机视觉杂志*，130（9）：2337–2348。
- en: 'Appendix:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 附录：
- en: 6 Results of Human Evaluations of Llama-2-7B chat responses
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 Llama-2-7B 聊天回应的人工评估结果
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 88 | 10 | 2 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 88 | 10 | 2 |'
- en: '| Medical Expert 2 | 86 | 12 | 2 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 86 | 12 | 2 |'
- en: 'Table 3: Human evaluated results of reasoning of MedCodex-Greedy based approach
    for Set 1 (50 questions)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：MedCodex-Greedy 基础方法对第1组（50个问题）的推理结果的人工评估
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 82 | 2 | 16 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 82 | 2 | 16 |'
- en: '| Medical Expert 2 | 72 | 14 | 14 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 72 | 14 | 14 |'
- en: 'Table 4: Human evaluated results of reasoning of MedCodex-Greedy based approach
    for Set 2 (50 questions)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：MedCodex-Greedy 基础方法对第2组（50个问题）的推理结果的人工评估
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 76 | 18 | 6 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 76 | 18 | 6 |'
- en: '| Medical Expert 2 | 28 | 24 | 48 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 28 | 24 | 48 |'
- en: 'Table 5: Human evaluated results of reasoning of MedCodex-Codex based approach
    for Set 1 (50 questions)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：MedCodex-Codex 基础方法对第1组（50个问题）的推理结果的人工评估
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 72 | 14 | 14 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 72 | 14 | 14 |'
- en: '| Medical Expert 2 | 68 | 20 | 12 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 68 | 20 | 12 |'
- en: 'Table 6: Human evaluated results of reasoning of MedCodex-Codex based approach
    for Set 2 (50 questions)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：MedCodex-Codex 基础方法对第2组（50个问题）的推理结果的人工评估
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 84 | 0 | 16 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 84 | 0 | 16 |'
- en: '| Medical Expert 2 | 86 | 4 | 8 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 86 | 4 | 8 |'
- en: 'Table 7: Human evaluated results of reasoning of MedCodex-Reward Model-based
    approach for Set 1 (50 questions)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：MedCodex-Reward 模型基础方法对第1组（50个问题）的推理结果的人工评估
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 84 | 10 | 6 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 84 | 10 | 6 |'
- en: '| Medical Expert 2 | 88 | 6 | 6 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 88 | 6 | 6 |'
- en: 'Table 8: Human evaluated results of reasoning of MedCodex-Reward Model-based
    approach for Set 2 (50 questions)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：MedCodex-Reward 模型基础方法对第2组（50个问题）的推理结果的人工评估
- en: 7 Results of Human Evaluations of Llama-2-70B chat responses
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 Llama-2-70B 聊天回应的人工评估结果
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 89 | 0 | 11 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家1 | 89 | 0 | 11 |'
- en: '| Medical Expert 2 | 92.3 | 7.7 | 0 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家2 | 92.3 | 7.7 | 0 |'
- en: '| Medical Expert 3 | 87 | 2 | 11 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家3 | 87 | 2 | 11 |'
- en: 'Table 9: Human evaluated results of reasoning of MedCodex-Greedy approach'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：MedCodex-Greedy 方法对推理结果的人工评估
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 92 | 0 | 8 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家 1 | 92 | 0 | 8 |'
- en: '| Medical Expert 2 | 72 | 18 | 10 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家 2 | 72 | 18 | 10 |'
- en: '| Medical Expert 3 | 76 | 14 | 10 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家 3 | 76 | 14 | 10 |'
- en: 'Table 10: Human evaluated results of reasoning of Codex approach'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 10：Codex 方法的人工评估推理结果
- en: '|  | Agree | Neutral | Disagree |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  | 同意 | 中立 | 不同意 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Medical Expert 1 | 87 | 6 | 7 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家 1 | 87 | 6 | 7 |'
- en: '| Medical Expert 2 | 92 | 0 | 8 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家 2 | 92 | 0 | 8 |'
- en: '| Medical Expert 3 | 89 | 1 | 7 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 医疗专家 3 | 89 | 1 | 7 |'
- en: 'Table 11: Human evaluated results of reasoning of MedCodex-Codex approach'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 11：MedCodex-Codex 方法的人工评估推理结果
