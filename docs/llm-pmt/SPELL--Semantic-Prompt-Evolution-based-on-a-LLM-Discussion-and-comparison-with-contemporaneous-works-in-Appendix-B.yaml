- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:49:18'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'SPELL: Semantic Prompt Evolution based on a LLM Discussion and comparison with
    contemporaneous works in Appendix B'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2310.01260](https://ar5iv.labs.arxiv.org/html/2310.01260)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yujian Betterest Li^(†♢)  Kai Wu^†
  prefs: []
  type: TYPE_NORMAL
- en: ^†School of Artificial Intelligence, Xidian University
  prefs: []
  type: TYPE_NORMAL
- en: '^♢Institute of Freedom and Happiness, Dream Place  Correspondence: [bebetterest@outlook.com](bebetterest@outlook.com)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Prompt engineering is a new paradigm for enhancing the performance of trained
    neural network models. For optimizing text-style prompts, existing methods usually
    individually operate small portions of a text step by step, which either breaks
    the fluency or could not globally adjust a prompt. Since large language models
    (LLMs) have powerful ability of generating coherent texts token by token, can
    we utilize LLMs for improving prompts? Based on this motivation, in this paper,
    considering a trained LLM as a text generator, we attempt to design a black-box
    evolution algorithm for automatically optimizing texts, namely SPELL (Semantic
    Prompt Evolution based on a LLM). The proposed method is evaluated with different
    LLMs and evolution parameters in different text tasks. Experimental results show
    that SPELL could rapidly improve the prompts indeed. We further explore the evolution
    process and discuss on the limitations, potential possibilities and future work.
  prefs: []
  type: TYPE_NORMAL
- en: 'SPELL: Semantic Prompt Evolution based on a LLM'
  prefs: []
  type: TYPE_NORMAL
- en: 'Discussion and comparison with contemporaneous works in Appendix [B](#A2 "Appendix
    B On the Contemporaneous Works ‣ SPELL: Semantic Prompt Evolution based on a LLM
    Discussion and comparison with contemporaneous works in Appendix B")'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yujian Betterest Li^(†♢)^†^†thanks:  Correspondence: [bebetterest@outlook.com](bebetterest@outlook.com)
     Kai Wu^† ^†School of Artificial Intelligence, Xidian University ^♢Institute of
    Freedom and Happiness, Dream Place'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d1232d77406dc2befc72798d371f6d0b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Overview of SPELL (Semantic Prompt Evolution based on a LLM).'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Prompts (Liu et al., [2023](#bib.bib11)) are additional contents which would
    be integrated with the original input data to enhance the performance of a trained
    target model. For example, in a text classification task, a prompt, "[input text]\nDivide
    the above text into 2 classes: positive and negative.\nClass:[MASK]", may strengthen
    the performance of a language model because the prompt reduces the probabilities
    of many unrelated tokens and hints what the model should focus on. Good prompt
    engineering methods are able to enhance the ability of a target model with limited
    and efficient optimization. Besides, prompts are flexible. They could be continuous
    (Li and Liang, [2021](#bib.bib10); Qin and Eisner, [2021](#bib.bib16)), possibly
    work in hidden layers (Sun et al., [2022b](#bib.bib20)), and have already been
    applied to many modalities, such as text (Lester et al., [2021](#bib.bib8); Liu
    et al., [2022](#bib.bib12)), vision (Jia et al., [2022](#bib.bib7); Sohn et al.,
    [2023](#bib.bib18)), and graph (Sun et al., [2022a](#bib.bib19); Yi et al., [2023](#bib.bib27)).
    In this paper, we only focus on discrete text-style prompts applied at the input
    of a language model for text tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2c98ab3110e4588fa8e828a5b6979252.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: A reproduction example including $MP_{r}$ and the response from the
    LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many methods to optimize text-style prompts. Gradient-based methods
    (Wallace et al., [2019](#bib.bib24); Shin et al., [2020](#bib.bib17)) are the
    most intuitive one. They usually relax the discrete embeddings for optimization
    and need large computation because of the process of backward through the trained
    model. Nowadays, many target models are considered as black boxes since only inference
    APIs are provided for the users. Hence, many black-box methods, based on evolution
    (Sun et al., [2022c](#bib.bib21); Sun et al., [2022b](#bib.bib20)), reinforcement
    learning (Deng et al., [2022](#bib.bib2); Zhang et al., [2023](#bib.bib29); Diao
    et al., [2023](#bib.bib3)) or search strategies (Prasad et al., [2023](#bib.bib15)),
    improve the prompts without the information of gradients and parameters inside
    the target model. In particular, evolution-based methods maintain a population
    consists of several prompts as individuals and optimize the population by biological
    mechanisms such as reproduction and selection. However, these methods individually
    operate small portions of text step by step, leading to lack of global adjustment
    and serious damage on the fluency. The prompts optimized by these methods usually
    consist of various *strange* characters, such as "an-lione_-lo-:)eak".
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, large language models (LLMs) (Li et al., [2021](#bib.bib9);
    Zhao et al., [2023](#bib.bib30)) are the most popular star among various new AI
    applications. Optimized on language modeling, they could get universal generalization
    ability. With appropriate instructions, they could acquire amazing performance
    on language understanding, reasoning and text generation. Especially, the generated
    texts are coherent enough.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we attempt to propose SPELL (Semantic Prompt Evolution based on a
    LLM), an evolution algorithm to optimize prompts. Since the proposed method considers
    a LLM as a generator, SPELL would utilize the global feature of a prompt and the
    improved prompts are coherent. Through experiments, we evaluate that SPELL could
    rapidly improve performance keeping prompts fluent. Besides, we discover the evolution
    process and the impacts of different LLMs or evolution strategies. The limitations,
    challenges and possible directions are discussed on in the end.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As shown in Figure [1](#S0.F1 "Figure 1 ‣ SPELL: Semantic Prompt Evolution
    based on a LLM Discussion and comparison with contemporaneous works in Appendix
    B"), SPELL maintains a population $POP_{t}$. By two biological mechanisms, reproduction
    and selection, the population evolves as'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle OFFS_{t}=reproduction(POP_{t})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle POP_{t+1}=selection(OFFS_{t}\cup POP_{t})$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $reproduction$ times, the population is gradually optimized by generating
    better individuals and selecting the potential ones. In the evolution process,
    how to inherit outstanding feature and make effective explorations are the keys.
    In the following subsections, we introduce different components of SPELL and explain
    how they work in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Problem Formulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this paper, we focus on the text tasks translated to classification. For
    example, sentiment analysis is to classify the emotion contained in a given text.
    The text $X$ is constructed as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $X=concat([input],\backslash n,[prompt],\backslash n,[head])$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $concat$ makes the prediction as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $y=\mathop{\arg\min}\limits_{l_{i}\in L}P_{M}(l_{i}&#124;x_{1},x_{2}...x_{N_{X}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where L is the label space. To simplify the prediction process, we choose one
    word standing for each label, such as "positive" and "negative" in sentiment analysis.
    It is worth mentioning that we pay attention to optimizing $[prompt]$ fixed.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Reproduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Reproduction is the process of generating newborns. To keep useful feature from
    the previous generation, we select $N_{P}$ as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $MP_{r}=concat([pre],\backslash n,[exs],\backslash n,[post])$ |  |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $$\displaystyle\begin{cases}[pre]=concat([i_{tsk}],[i_{prompt}],[i_{rep}])\\
    [exs]=concat([pro_{1}],\backslash n,[pro_{2}]...[pro_{N_{P}}])\\'
  prefs: []
  type: TYPE_NORMAL
- en: '[post]=concat([i_{final}],[i_{additional}])\\'
  prefs: []
  type: TYPE_NORMAL
- en: '[pro_{i}]=concat([I_{P,t,i}],[fit_{i}]),i\in[1,N_{P}]\end{cases}$$ |  |'
  prefs: []
  type: TYPE_NORMAL
- en: '$[pre]$ is listed in Table [4](#A1.T4 "Table 4 ‣ Appendix A Other Settings
    ‣ SPELL: Semantic Prompt Evolution based on a LLM Discussion and comparison with
    contemporaneous works in Appendix B"). Given a meta prompt $MP_{r}$ is obtained
    by'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $I_{N,t,i}=EXT(G(MP_{r}))$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $EXT$.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Selection is to choose some individuals being parents or structuring the new
    population. Selection strategies usually pay attention to balance survival of
    the fittest and the luckiest. In SPELL, the selection is based on roulette. First,
    we calculate the selection probability $P_{S,i}$ as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P_{S,i}=\frac{e^{fitness(I_{i})}}{\sum_{j\in CAN}(e^{fitness(I_{j})})}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $fitness$ as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $I_{S}=sample(CAN,N_{S},P_{S})$ |  |'
  prefs: []
  type: TYPE_TB
- en: In this way, poor individual would have a chance to be selected, which enriches
    the diversity.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setups
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We experiment on three text tasks from GLUE (Wang et al., [2018](#bib.bib25)):
    SST-2 for sentiment prediction, RTE for textual entailment recognition, and AG’s
    News for news classification. Following Sun et al., [2022d](#bib.bib22), our experiments
    are in the few-shot setting. Only $k$ of individuals in a population is considered
    as the performance of the population.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | SST-2(%) | RTE(%) | AG’s News(%) |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot | 70.6 | 45.5 | 54.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Fine-tuning | 81.4 | 54.4 | 86.2 |'
  prefs: []
  type: TYPE_TB
- en: '| LM-BFF | 92.3 | 66.6 | 87.1 |'
  prefs: []
  type: TYPE_TB
- en: '| DART | 93.5 | 59.0 | 86.8 |'
  prefs: []
  type: TYPE_TB
- en: '| BBT | 88.2 | 49.1 | 81.2 |'
  prefs: []
  type: TYPE_TB
- en: '| RLPrompt | 90.5 | 52.2 | 76.2 |'
  prefs: []
  type: TYPE_TB
- en: '| PROMPTBOOSTING | 87.6 | 60.0 | 85.2 |'
  prefs: []
  type: TYPE_TB
- en: '| TEMPERA | 91.9 | 60.3 | 85.5 |'
  prefs: []
  type: TYPE_TB
- en: '| SPELL | 89.2 | 50.9 | 70.0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Performance of different methods in $D_{test}$. Zero-shot utilizes
    the initial prompt for prediction. Fine-tuning, LM-BFF (Gao et al., [2021](#bib.bib4))
    and DART (Zhang et al., [2022](#bib.bib28)) are white-box methods while BBT (Sun
    et al., [2022c](#bib.bib21)), RLPrompt (Deng et al., [2022](#bib.bib2)), PROMPTBOOSTING
    (Hou et al., [2023](#bib.bib6)), TEMPERA (Zhang et al., [2023](#bib.bib29)), and
    SPELL (ours) are black-box methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall View
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We compare SPELL with state-of-the-art methods and feasible black-box works.
    As shown in Table [1](#S3.T1 "Table 1 ‣ Setups ‣ 3 Experiments ‣ SPELL: Semantic
    Prompt Evolution based on a LLM Discussion and comparison with contemporaneous
    works in Appendix B"), as a black-box method, SPELL could improve the accuracy
    and shows the potential of prompt optimization problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b9b3d7023f5b12e1b8a50821eb841963.png)![Refer to caption](img/5e5c14e3697e84d75becb6a3546e30ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Accuracy vs. round with different seeds. Three seeds (41, 42 and
    43) are considered. The top one is evaluated in $D_{train}$.'
  prefs: []
  type: TYPE_NORMAL
- en: Optimization Process
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The optimization process is described in Figure [3](#S3.F3 "Figure 3 ‣ Overall
    View ‣ 3 Experiments ‣ SPELL: Semantic Prompt Evolution based on a LLM Discussion
    and comparison with contemporaneous works in Appendix B"). Due to the few-shot
    setting, there exists a performance gap between $D_{train}$. SPELL optimizes with
    fewer rounds than many black-box methods, such as BBT and RLPROMPT (more than
    3k rounds for prompts of only 5 tokens). In addition, it is worth noting that,
    due to the randomness of evolution process and text generation, SPELL is unstable
    with obvious fluctuations. In addition, the individual generation process is semantically
    causal and newborn prompts are coherent since it is spelled by the LLM token by
    token according to language modeling. For example, in SST-2, given the initial
    prompt "Classify the following sentence.", LLM would globally improve it to a
    new fluent one "Can you determine the sentiment of this sentence for me?" with
    clear reasons "…more concise and direct…emphasizes the task…more polite and conversational".
    A reproduction example is shown in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction
    ‣ SPELL: Semantic Prompt Evolution based on a LLM Discussion and comparison with
    contemporaneous works in Appendix B").'
  prefs: []
  type: TYPE_NORMAL
- en: '| LLM | Size(B) | Train(%) | Test(%) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-Chat | 7 | 100.0 | 89.2 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-Chat | 13 | 96.9 | 90.0 |'
  prefs: []
  type: TYPE_TB
- en: '| BLOOMZ | 7 | n/a | n/a |'
  prefs: []
  type: TYPE_TB
- en: '| ERNIE-Bot | n/a | 100.0 | 90.7 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Performance on various LLMs in SST-2\. Two Llama2 (Touvron et al.,
    [2023](#bib.bib23)) models with different size are evaluated. BLOOMZ (Muennighoff
    et al., [2022](#bib.bib14)) fails to generate individuals following instructions.
    The size of ERNIE-Bot (Baidu, [2023](#bib.bib1)) is not available.'
  prefs: []
  type: TYPE_NORMAL
- en: Influence of Different LLMs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As shown in Table [2](#S3.T2 "Table 2 ‣ Optimization Process ‣ 3 Experiments
    ‣ SPELL: Semantic Prompt Evolution based on a LLM Discussion and comparison with
    contemporaneous works in Appendix B"), we evaluate SPELL with different LLMs.
    Without any especial adaptation, not every LLM could be utilized in SPELL. For
    example, BLOOMZ is not available because it can not reply following the hinted
    format. In addition, ERBIE-Bot performs the best while the test accuracy of Llama2-Chat-13B
    is higher than that of Llama2-Chat-7B. It seems that larger and better LLMs would
    have better performance. Thus, the LLM for generation is essential for SPELL.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Configuration | Train(%) | Test(%) |'
  prefs: []
  type: TYPE_TB
- en: '| *Base* | 100.0 | 89.2 |'
  prefs: []
  type: TYPE_TB
- en: '| $fitness$=*loss* | 71.9 | 69.4 |'
  prefs: []
  type: TYPE_TB
- en: '| $N_{POP}$=2 | 100.0 | 88.9 |'
  prefs: []
  type: TYPE_TB
- en: '| $N_{POP}$=50 | 100.0 | 87.0 |'
  prefs: []
  type: TYPE_TB
- en: '| $k$=32 | 95.3 | 86.2 |'
  prefs: []
  type: TYPE_TB
- en: '| $k$=64 | 92.2 | 90.7 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Results of ablation studies in SST-2\. *Base* means the default settings
    ($fitness$=16). *loss* refers to the cross-entropy loss.'
  prefs: []
  type: TYPE_NORMAL
- en: Ablation Studies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As shown in Table [3](#S3.T3 "Table 3 ‣ Influence of Different LLMs ‣ 3 Experiments
    ‣ SPELL: Semantic Prompt Evolution based on a LLM Discussion and comparison with
    contemporaneous works in Appendix B"), we attempt to find out the impact of some
    meaningful factors. Even though previous methods usually utilize $loss$ trends
    to obtain higher accuracy for better estimation.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Conclusion and Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we propose SPELL, a semantic prompt evolution method considering
    a LLM as a prompt generator. We demonstrate that the proposed method could globally
    optimize prompts quickly, the reproduction process is reasonable and new spelled
    prompts are coherent. Besides, we do some ablation studies for further investigation.
    Even if our method seems unstable, it shows huge latent capacity. Future work
    may focus on adjusting a LLM to be more adaptive for semantic prompt optimization,
    such as meta prompt optimization and parameter effective parameter-efficient alignment,
    stabilizing the optimization, and expanding semantic evolution beyond text optimization.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Baidu (2023) Baidu. 2023. Ernie bot: Baidu’s knowledge-enhanced large language
    model built on full ai stack technology. [http://research.baidu.com/Blog/index-view?id=183](http://research.baidu.com/Blog/index-view?id=183).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2022) Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang,
    Han Guo, Tianmin Shu, Meng Song, Eric Xing, and Zhiting Hu. 2022. RLPrompt: Optimizing
    discrete text prompts with reinforcement learning. In *Proceedings of the 2022
    Conference on Empirical Methods in Natural Language Processing*, pages 3369–3391,
    Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diao et al. (2023) Shizhe Diao, Zhichao Huang, Ruijia Xu, Xuechun Li, LIN Yong,
    Xiao Zhou, and Tong Zhang. 2023. Black-box prompt learning for pre-trained language
    models. *Transactions on Machine Learning Research*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2021) Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making pre-trained
    language models better few-shot learners. In *Proceedings of the 59th Annual Meeting
    of the Association for Computational Linguistics and the 11th International Joint
    Conference on Natural Language Processing (Volume 1: Long Papers)*, pages 3816–3830,
    Online. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2023) Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song,
    Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang. 2023. Connecting large language
    models with evolutionary algorithms yields powerful prompt optimizers. *arXiv
    preprint arXiv:2309.08532*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hou et al. (2023) Bairu Hou, Joe O’Connor, Jacob Andreas, Shiyu Chang, and
    Yang Zhang. 2023. PromptBoosting: Black-box text classification with ten forward
    passes. In *Proceedings of the 40th International Conference on Machine Learning*,
    volume 202 of *Proceedings of Machine Learning Research*, pages 13309–13324\.
    PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jia et al. (2022) Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge
    Belongie, Bharath Hariharan, and Ser-Nam Lim. 2022. Visual prompt tuning. In *European
    Conference on Computer Vision*, pages 709–727\. Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lester et al. (2021) Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The
    power of scale for parameter-efficient prompt tuning. In *Proceedings of the 2021
    Conference on Empirical Methods in Natural Language Processing*, pages 3045–3059,
    Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2021) Junyi Li, Tianyi Tang, Wayne Xin Zhao, and Ji-Rong Wen. 2021.
    Pretrained language model for text generation: A survey. In *Proceedings of the
    Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21*,
    pages 4492–4499\. International Joint Conferences on Artificial Intelligence Organization.
    Survey Track.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li and Liang (2021) Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing
    continuous prompts for generation. In *Proceedings of the 59th Annual Meeting
    of the Association for Computational Linguistics and the 11th International Joint
    Conference on Natural Language Processing (Volume 1: Long Papers)*, pages 4582–4597,
    Online. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict: A systematic
    survey of prompting methods in natural language processing. *ACM Computing Surveys*,
    55(9):1–35.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2022) Xiao Liu, Kaixuan Ji, Yicheng Fu, Weng Tam, Zhengxiao Du,
    Zhilin Yang, and Jie Tang. 2022. P-tuning: Prompt tuning can be comparable to
    fine-tuning across scales and tasks. In *Proceedings of the 60th Annual Meeting
    of the Association for Computational Linguistics (Volume 2: Short Papers)*, pages
    61–68, Dublin, Ireland. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
    Roberta: A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Muennighoff et al. (2022) Niklas Muennighoff, Thomas Wang, Lintang Sutawika,
    Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin
    Yong, Hailey Schoelkopf, et al. 2022. Crosslingual generalization through multitask
    finetuning. *arXiv preprint arXiv:2211.01786*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prasad et al. (2023) Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal.
    2023. GrIPS: Gradient-free, edit-based instruction search for prompting large
    language models. In *Proceedings of the 17th Conference of the European Chapter
    of the Association for Computational Linguistics*, pages 3845–3864, Dubrovnik,
    Croatia. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qin and Eisner (2021) Guanghui Qin and Jason Eisner. 2021. Learning how to
    ask: Querying LMs with mixtures of soft prompts. In *Proceedings of the 2021 Conference
    of the North American Chapter of the Association for Computational Linguistics:
    Human Language Technologies*, pages 5203–5212, Online. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace,
    and Sameer Singh. 2020. AutoPrompt: Eliciting Knowledge from Language Models with
    Automatically Generated Prompts. In *Proceedings of the 2020 Conference on Empirical
    Methods in Natural Language Processing (EMNLP)*, pages 4222–4235, Online. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sohn et al. (2023) Kihyuk Sohn, Huiwen Chang, José Lezama, Luisa Polania, Han
    Zhang, Yuan Hao, Irfan Essa, and Lu Jiang. 2023. Visual prompt tuning for generative
    transfer learning. In *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition (CVPR)*, pages 19840–19851.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2022a) Mingchen Sun, Kaixiong Zhou, Xin He, Ying Wang, and Xin
    Wang. 2022a. Gppt: Graph pre-training and prompt tuning to generalize graph neural
    networks. In *Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery
    and Data Mining*, KDD ’22, page 1717–1727, New York, NY, USA. Association for
    Computing Machinery.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2022b) Tianxiang Sun, Zhengfu He, Hong Qian, Yunhua Zhou, Xuanjing
    Huang, and Xipeng Qiu. 2022b. BBTv2: Towards a gradient-free future with large
    language models. In *Proceedings of the 2022 Conference on Empirical Methods in
    Natural Language Processing*, pages 3916–3930, Abu Dhabi, United Arab Emirates.
    Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2022c) Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and
    Xipeng Qiu. 2022c. Black-box tuning for language-model-as-a-service. In *Proceedings
    of the 39th International Conference on Machine Learning*, volume 162 of *Proceedings
    of Machine Learning Research*, pages 20841–20855\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2022d) Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and
    Xipeng Qiu. 2022d. Black-box tuning for language-model-as-a-service. In *International
    Conference on Machine Learning*, pages 20841–20855\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wallace et al. (2019) Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner,
    and Sameer Singh. 2019. Universal adversarial triggers for attacking and analyzing
    NLP. In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language
    Processing and the 9th International Joint Conference on Natural Language Processing
    (EMNLP-IJCNLP)*, pages 2153–2162, Hong Kong, China. Association for Computational
    Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2018) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R Bowman. 2018. Glue: A multi-task benchmark and analysis
    platform for natural language understanding. *arXiv preprint arXiv:1804.07461*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2023) Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V
    Le, Denny Zhou, and Xinyun Chen. 2023. Large language models as optimizers. *arXiv
    preprint arXiv:2309.03409*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yi et al. (2023) Zixuan Yi, Iadh Ounis, and Craig Macdonald. 2023. Contrastive
    graph prompt-tuning for cross-domain recommendation. *ACM Transactions on Information
    Systems*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022) Ningyu Zhang, Luoqiu Li, Xiang Chen, Shumin Deng, Zhen Bi,
    Chuanqi Tan, Fei Huang, and Huajun Chen. 2022. Differentiable prompt makes pre-trained
    language models better few-shot learners. In *International Conference on Learning
    Representations*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023) Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans,
    and Joseph E. Gonzalez. 2023. TEMPERA: Test-time prompt editing via reinforcement
    learning. In *The Eleventh International Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al.
    2023. A survey of large language models. *arXiv preprint arXiv:2303.18223*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Other Settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Task | $i_{task}$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| SST-2 | "The task is to classify the sentiment of a sentence from movie reviews.
    Here are 2 classes ({negative}/{positive})." |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | "The task is to classify the relationship between sentence1 and sentence2\.
    Here are 2 classes ({yes}/{no}). {yes} means the relationship is entailment, the
    meaning of one sentence is entailed (can be inferred) from the other sentence,
    otherwise {no}." |'
  prefs: []
  type: TYPE_TB
- en: '| Task | $I_{ini}$ |'
  prefs: []
  type: TYPE_TB
- en: '| SST-2 | "Classify the following sentence." |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | "Classify whether the relationship between the following sentence1
    and sentence2 is entailment." |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: A list of $i_{task}$ in the experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B On the Contemporaneous Works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We discuss on two recent and similar contemporaneous works which utilize a
    LLM as a prompt generator/optimizer as well. It is worth noticing that OPRO and
    EVOPROMPT perform rather well while SPELL (ours) does not. Moreover, there’s overlap
    between the datasets on which EVOPROMPT is evaluated and those of ours. Considering
    the difference of the target model, we think the reason may be that the accuracy
    is originally higer when the target model is a LLM, and that the improved prompts
    generated by a LLM could not be well "understood" by a relatively small language
    model. In addition, the comparisons of OPRO and EVOPROMPT with SPELL (ours) are
    illustrated in detail as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: OPRO (Yang et al., [2023](#bib.bib26))
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The target model of OPRO is a LLM while that of SPELL is a much smaller language
    model. Besides, we think the key difference is that OPRO constructs a prompt-score
    trajectory of prompts to update the prompts while SPELL (ours) introduces selection
    and reproduction with randomness from evolution algorithm for prompt improvement.
  prefs: []
  type: TYPE_NORMAL
- en: EVOPROMPT (Guo et al., [2023](#bib.bib5))
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: EVOPROMPT and SPELL are really similar. EVOPROMPT includes evolution algorithm
    as well and further apply differential evolution with a LLM. EVOPROMPT separately
    designs the crossover and mutation operators while SPELL (ours) consists of one
    general operator for reproduction. Besides, the target model of EVOPROMPT is a
    LLM.
  prefs: []
  type: TYPE_NORMAL
