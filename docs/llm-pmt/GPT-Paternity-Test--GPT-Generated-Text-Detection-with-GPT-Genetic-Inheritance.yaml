- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:50:58'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:50:58
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT 亲子鉴定测试：利用 GPT 遗传继承检测 GPT 生成文本
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.12519](https://ar5iv.labs.arxiv.org/html/2305.12519)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2305.12519](https://ar5iv.labs.arxiv.org/html/2305.12519)
- en: Xiao Yu^(1†), Yuang Qi^(1†), Kejiang Chen¹  , Guoqiang Chen¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xiao Yu^(1†), Yuang Qi^(1†), Kejiang Chen¹  , Guoqiang Chen¹
- en: Xi Yang¹, Pengyuan Zhu², Weiming Zhang¹, Nenghai Yu¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Xi Yang¹, Pengyuan Zhu², Weiming Zhang¹, Nenghai Yu¹
- en: ^†equal contribution
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^†等贡献
- en: ¹University of Science and Technology of China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹中国科学技术大学
- en: ²Hefei High-dimensional Data Technology
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ²合肥高维数据技术
- en: qya7ya@mail.ustc.edu.cn, {chenkj, zhangwm, ynh}@ustc.edu.cn
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: qya7ya@mail.ustc.edu.cn, {chenkj, zhangwm, ynh}@ustc.edu.cn
- en: zhupengyuan@hddata.cn Corresponding author.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: zhupengyuan@hddata.cn 通讯作者。
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) can generate texts that carry the risk of various
    misuses, including plagiarism, planting fake reviews on e-commerce platforms,
    or creating fake social media postings that can sway election results. Detecting
    whether a text is machine-generated has thus become increasingly important. While
    machine-learning-based detection strategies exhibit superior performance, they
    often lack generalizability, limiting their practicality. In this work, we introduce
    GPT Paternity Test (GPT-Pat), which reliably detects machine-generated text across
    varied datasets. Given a text under scrutiny, we leverage ChatGPT to generate
    a corresponding question and provide a re-answer to the question. By comparing
    the similarity between the original text and the generated re-answered text, it
    can be determined whether the text is machine-generated. GPT-Pat consists of a
    Siamese network to compute the similarity between the original text and the generated
    re-answered text and a binary classifier. Our method achieved an average accuracy
    of 94.57% on four generalization test sets, surpassing the state-of-the-art RoBERTa-based
    method by 12.34%. The accuracy drop of our method is only about half of that of
    the RoBERTa-based method when it is attacked by re-translation and polishing.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）生成的文本存在各种滥用风险，包括剽窃、在电子商务平台上植入虚假评论，或创建虚假的社交媒体帖子，这些帖子可能影响选举结果。因此，检测文本是否由机器生成变得越来越重要。虽然基于机器学习的检测策略表现优异，但它们往往缺乏通用性，限制了其实际应用。在这项工作中，我们介绍了
    GPT 亲子鉴定测试（GPT-Pat），该测试可以在不同的数据集上可靠地检测机器生成的文本。给定一个待检文本，我们利用 ChatGPT 生成一个对应的问题并提供问题的重新回答。通过比较原始文本与生成的重新回答文本之间的相似度，可以确定文本是否为机器生成。GPT-Pat
    由一个用于计算原始文本与生成的重新回答文本之间相似度的孪生网络和一个二分类器组成。我们的方法在四个泛化测试集上取得了平均 94.57% 的准确率，超过了基于
    RoBERTa 的最新方法 12.34%。当面对重新翻译和润色的攻击时，我们的方法准确率下降仅为 RoBERTa 方法的一半左右。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) are neural networks that consist of hundreds of
    billions (or even more) of parameters. Prominent examples of LLMs include GPT-3
    [[4](#bib.bib4)], PaLM [[6](#bib.bib6)], ChatGPT ¹¹1Launched by OpenAI in November
    2022\. [https://chat.openai.com/chat](https://chat.openai.com/chat), and LLaMA
    [[31](#bib.bib31)]. These models are trained using extensive text data, allowing
    them to generate human-like responses and exhibit advanced language capabilities
    to understand natural language and solve complex tasks via text generation. LLMs
    such as ChatGPT can convincingly answer complex questions about science, mathematics,
    historical and current events, and social trends. ChatGPT has attracted the attention
    of millions of people, making it the fastest-growing app of all time [[15](#bib.bib15)].
    It has made significant advances in the field of natural language processing and
    can proficiently generate text for tasks such as writing emails, news reports,
    and academic papers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是由数百亿（甚至更多）参数组成的神经网络。著名的大型语言模型包括 GPT-3 [[4](#bib.bib4)]、PaLM [[6](#bib.bib6)]、ChatGPT
    ¹¹由 OpenAI 于 2022 年 11 月推出。[https://chat.openai.com/chat](https://chat.openai.com/chat)
    和 LLaMA [[31](#bib.bib31)]。这些模型通过大量文本数据进行训练，使它们能够生成类似人类的响应，展现出理解自然语言和通过文本生成解决复杂任务的先进语言能力。像
    ChatGPT 这样的 LLM 能够令人信服地回答有关科学、数学、历史和当前事件以及社会趋势的复杂问题。ChatGPT 吸引了数百万人的关注，成为有史以来增长最快的应用程序
    [[15](#bib.bib15)]。它在自然语言处理领域取得了重大进展，并能熟练生成诸如撰写电子邮件、新闻报道和学术论文等任务的文本。
- en: However, if placed in wrong hands, ChatGPT can undoubtedly serve as a "weapon
    of mass deception" [[29](#bib.bib29)]. It is undeniable that this tool has the
    potential to become the most powerful means of spreading misinformation ever witnessed
    on the Internet. With ChatGPT, fabricating false narratives can be accomplished
    on a massive scale and with alarming frequency, akin to AI agents actively contributing
    to disinformation [[11](#bib.bib11)]. Extensive research in the field indicates
    that ChatGPT demonstrates a bias toward certain values [[18](#bib.bib18)], which
    must be taken into consideration. Additionally, the formidable writing capabilities
    of ChatGPT pose a significant threat to democracy, as they enable the creation
    of automated bots on online social networks that can manipulate people’s political
    choices during election campaigns [[30](#bib.bib30), [11](#bib.bib11)]. Furthermore,
    the adoption of ChatGPT by students in educational institutions has led to instances
    of academic dishonesty, with essays and assignments being generated through its
    use, as reported by various news sources [[19](#bib.bib19), [26](#bib.bib26)].
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果被错误使用，ChatGPT无疑可以成为“大规模欺骗的武器”[[29](#bib.bib29)]。不可否认的是，这一工具有可能成为互联网历史上传播虚假信息的最强大手段。借助ChatGPT，可以大规模且频繁地制造虚假叙事，类似于AI代理积极参与虚假信息传播[[11](#bib.bib11)]。该领域的广泛研究表明，ChatGPT对某些价值观存在偏见[[18](#bib.bib18)]，这必须加以考虑。此外，ChatGPT强大的写作能力对民主构成了重大威胁，因为它能够在在线社交网络上创建自动化的机器人，操控人们在选举期间的政治选择[[30](#bib.bib30),
    [11](#bib.bib11)]。此外，ChatGPT在教育机构中被学生使用，导致了学术不诚实的情况，许多新闻来源报告了通过其生成的论文和作业[[19](#bib.bib19),
    [26](#bib.bib26)]。
- en: 'Text produced by LLMs such as ChatGPT often bears a striking resemblance to
    text written by humans, exhibiting similarities in style, grammar, and coherence.
    As a result, humans only marginally outperform chance when attempting to classify
    machine-generated text versus human-written text. Consequently, researchers have
    developed more precise automated detection methods to address this challenge.
    Specifically, two categories of methods have been considered: metric-based methods
    [[10](#bib.bib10), [20](#bib.bib20), [30](#bib.bib30), [12](#bib.bib12)] and model-based
    methods [[30](#bib.bib30), [12](#bib.bib12)]. Metric-based methods rely on metrics
    such as perplexity and log probability, while model-based methods involve training
    a classification model using corpora consisting of both machine-generated and
    human-written text. In general, the latter category of methods demonstrates superior
    detection capabilities [[14](#bib.bib14)].'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由像ChatGPT这样的LLM生成的文本往往与人类编写的文本有惊人的相似之处，表现出风格、语法和连贯性上的相似性。因此，人类在试图分类机器生成的文本与人类编写的文本时，仅略微超越随机猜测。因此，研究人员开发了更精确的自动检测方法来应对这一挑战。具体来说，考虑了两类方法：基于指标的方法[[10](#bib.bib10),
    [20](#bib.bib20), [30](#bib.bib30), [12](#bib.bib12)]和基于模型的方法[[30](#bib.bib30),
    [12](#bib.bib12)]。基于指标的方法依赖于困惑度和对数概率等指标，而基于模型的方法则涉及使用包括机器生成文本和人类编写文本在内的语料库来训练分类模型。一般来说，后一类方法展示了更优越的检测能力[[14](#bib.bib14)]。
- en: '![Refer to caption](img/ff62ce46c5996288b0255ed73fefee58.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ff62ce46c5996288b0255ed73fefee58.png)'
- en: 'Figure 1: An illustration of GPT-Pat. We send the text to be detected to a
    large language model of ChatGPT, generate a question and feed it into the model
    to generate a corresponding re-answered text. Compare the similarity between the
    original text and the re-answered text for machine-generated text detection. If
    the similarity is high, the text to be detected is likely to be machine-generated
    text.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GPT-Pat的示意图。我们将待检测的文本发送给ChatGPT的大型语言模型，生成一个问题并将其输入模型，以生成相应的重新回答文本。比较原文本与重新回答文本之间的相似性来检测机器生成的文本。如果相似性较高，待检测的文本很可能是机器生成的。
- en: Despite the achievements made by existing methods, detecting machine-generated
    text in more intricate scenarios remains a significant challenge. One such challenge
    arises from the complexity of text content in real-world detection scenarios.
    Existing methods necessitate the collection of extensive machine-generated and
    human-written text corpora for training purposes. However, machine-learning-based
    classifiers are susceptible to overfitting, thereby impacting their actual detection
    performance.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现有方法取得了一定的成果，但在更复杂的场景中检测机器生成的文本仍然是一个重大挑战。其中一个挑战来自于现实世界检测场景中文本内容的复杂性。现有方法需要收集大量机器生成和人类撰写的文本语料库进行训练。然而，基于机器学习的分类器容易发生过拟合，从而影响其实际检测性能。
- en: Another challenge lies in effectively addressing user perturbations. To evade
    detection, users are prone to employing various techniques, including multiple
    translations and artificial modifications on machine-generated text. It has been
    observed that existing detection methods struggle to perform well in the face
    of such attacks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个挑战在于有效应对用户的干扰。为了避免检测，用户倾向于使用各种技术，包括多次翻译和对机器生成文本进行人工修改。已有研究表明，现有的检测方法在面对这些攻击时表现不佳。
- en: 'To address these challenges, this paper aims to propose a more comprehensive
    detection method. Due to LLMs lack the lived experiences and contextual knowledge
    that humans possess, and are limited to generating content based on the patterns
    found in their training data, we put forward a simple hypothesis: when similar
    questions are posed to a large language model, the model’s output will also be
    similar. We define this characteristic as the *genetic inheritance* of LLMs, signifying
    that everything the model generates is derived from its training data. We utilize
    the genetic inheritance of LLMs to develop a novel detection method, which we
    have aptly named the GPT Paternity Test (GPT-Pat). In this method, we employ ChatGPT
    itself to summarize the text under scrutiny, presenting it as an answer to a specific
    question. Subsequently, we instruct ChatGPT to generate an answer to this question.
    By comparing the similarity between the original text and the re-answered text,
    we can determine whether the text is machine-generated. We hypothesize that if
    the text to be detected is generated by ChatGPT, the re-answered text will exhibit
    higher similarity to the original text. Conversely, if the text under examination
    is human-written, the similarity score will be lower. Our proposed method involves
    leveraging a Siamese network model to assess the similarity between the original
    and generated text, facilitating the detection of machine-generated content. See
    Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ GPT Paternity Test: GPT Generated
    Text Detection with GPT Genetic Inheritance") for an overview of GPT-Pat.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，本文旨在提出一种更全面的检测方法。由于大型语言模型（LLMs）缺乏人类所拥有的生活经历和背景知识，并且仅限于根据训练数据中发现的模式生成内容，我们提出了一个简单的假设：当对大型语言模型提出类似的问题时，模型的输出也将是类似的。我们将这一特征定义为LLMs的*遗传传承*，意味着模型生成的一切内容都源于其训练数据。我们利用LLMs的遗传传承开发了一种新颖的检测方法，我们称之为GPT亲子鉴定（GPT-Pat）。在此方法中，我们利用ChatGPT本身对待检文本进行总结，并将其作为对特定问题的回答。随后，我们指示ChatGPT生成对该问题的回答。通过比较原始文本和重新回答文本之间的相似度，我们可以判断文本是否由机器生成。我们假设，如果待检测的文本是由ChatGPT生成的，重新回答的文本将与原始文本表现出更高的相似度。相反，如果被检文本是人类撰写的，相似度得分将较低。我们提出的方法涉及利用孪生网络模型来评估原始文本和生成文本之间的相似度，从而有助于检测机器生成的内容。有关GPT-Pat的概述，请参见图
    [1](#S1.F1 "图 1 ‣ 1 引言 ‣ GPT亲子鉴定：利用GPT遗传传承检测GPT生成文本")。
- en: 'Our main contributions are: (1) We present a novel method to detect machine-generated
    text by introducing the concept of genetic inheritance. This concept leverages
    ChatGPT’s ability to detect itself in part by generating questions and re-answering;
    (2) We experiment in more realistic and complex environments. Our method achieves
    the state-of-the-art performance to date and improves the average accuracy by
    at least 12.34% over existing methods in detecting out-of-domain data; (3) We
    consider human-machine collaboration in real-world scenarios where users usually
    make secondary adjustments, our method also exhibits good robustness against attacks.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要贡献是：（1）我们提出了一种通过引入遗传继承概念来检测机器生成文本的新方法。该概念利用ChatGPT自身通过生成问题和重新回答的能力来进行部分自我检测；（2）我们在更现实和复杂的环境中进行实验。我们的方法在检测领域外数据方面达到了迄今为止的最先进性能，平均准确率比现有方法提高了至少12.34%；（3）我们考虑了现实场景中的人机协作，用户通常进行二次调整，我们的方法在抵御攻击方面也表现出良好的鲁棒性。
- en: 2 Related Work
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Several methods have been developed for detecting machine-generated text in
    the context of large language models (LLMs). In this paper, we focus on two metric-based
    detection methods, including Perplexity and DetectGPT, and a model-based detection
    methods that employ a fine-tuned RoBERTa model as a classifier.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 针对大型语言模型（LLMs）检测机器生成文本的方法已有若干种。在本文中，我们关注两种基于度量的检测方法，包括困惑度和DetectGPT，以及一种基于模型的检测方法，使用微调的RoBERTa模型作为分类器。
- en: Metric-based Detection.
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于度量的检测。
- en: Perplexity (PPL) is a widely used metric for assessing the performance of large
    language models (LLMs) [[5](#bib.bib5)]. It is calculated as the exponential of
    the negative average log-likelihood of the text given the LLM. In general, machine-generated
    text produced by LLMs tends to have lower perplexity values than human-written
    text [[12](#bib.bib12)].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 困惑度（PPL）是评估大型语言模型（LLMs）性能的广泛使用的度量[[5](#bib.bib5)]。它被计算为LLM给定文本的负平均对数似然的指数。通常，LLMs生成的文本的困惑度值往往低于人类编写的文本[[12](#bib.bib12)]。
- en: Mitchell et al. [[20](#bib.bib20)] introduced DetectGPT, a method that examines
    the fluctuations in the log probability function of a language model when minor
    perturbations are introduced to the original text. The fundamental idea behind
    this method posits that machine-generated text generated by LLMs often resides
    within a local optimum of the model’s log probability function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Mitchell等人[[20](#bib.bib20)] 引入了DetectGPT，这是一种在对原始文本引入轻微扰动时检查语言模型的对数概率函数波动的方法。这种方法的基本思想是，LLMs生成的机器生成文本通常位于模型对数概率函数的局部最优点。
- en: Model-based Detection.
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于模型的检测。
- en: Model-based methods leverage statistical models to extract patterns and features
    from annotated data. A commonly employed approach involves training a binary classifier
    capable of distinguishing between generated and human-written text. Guo et al.
    [[12](#bib.bib12)] collected paired human-written text and ChatGPT-generated text,
    creating the HC3 dataset. They then fine-tuned a RoBERTa model using this dataset
    to construct a text detector. Additionally, they proposed a novel training strategy
    that incorporates question-answer text pairs to jointly fine-tune the RoBERTa
    model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的方法利用统计模型从标注数据中提取模式和特征。一种常用的方法是训练一个二分类器，能够区分生成的文本和人类编写的文本。郭等人[[12](#bib.bib12)]
    收集了配对的人类编写文本和ChatGPT生成的文本，创建了HC3数据集。然后，他们利用该数据集微调了RoBERTa模型以构建文本检测器。此外，他们还提出了一种新颖的训练策略，结合了问答文本对以共同微调RoBERTa模型。
- en: 3 Method
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 3.1 Motivation
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 动机
- en: Traditional machine-generated text detection methods have primarily relied on
    data-driven binary classification, which involves training detectors using available
    data. However, this approach is susceptible to overfitting and relies heavily
    on the quality and availability of training data. Alternatively, optimization-based
    exploration methods require knowledge of intermediate model outputs or the use
    of fully controllable generative models, which are often impractical in real-world
    applications.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的机器生成文本检测方法主要依赖数据驱动的二分类，这涉及到利用可用数据训练检测器。然而，这种方法容易过拟合，并且严重依赖于训练数据的质量和可用性。另一种方法是基于优化的探索方法，需要对中间模型输出有了解或使用完全可控的生成模型，这在实际应用中往往不切实际。
- en: To address these limitations, our research aims to investigate and analyze the
    underlying principles of machine-generated text generation. By uncovering the
    distinctions between machine-generated and human-written texts, we seek to uncover
    novel detection ideas that can enhance the effectiveness of detection methods.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些限制，我们的研究旨在调查和分析机器生成文本生成的基本原理。通过揭示机器生成文本和人类撰写文本之间的区别，我们希望发现新的检测思路，以提高检测方法的有效性。
- en: 3.2 GPT Genetic Inheritance
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 GPT遗传继承
- en: After conducting a thorough examination of popular language models, we have
    observed remarkable advantages in fine-tuned large language models that employ
    carefully engineered text prompts. These models operate in accordance with the
    instruction fine-tuning approach, similar to InstructGPT[[24](#bib.bib24)], where
    they respond to user-provided instructions or prompts. In most cases, the user’s
    instruction can be seen as a question posed to the large language model (e.g.,
    ChatGPT), and the text generated by ChatGPT can be considered the model’s response
    or answer to that question. In the rest of this paper, we use GPT or ChatGPT to
    refer to all large language models with similar capabilities and no longer distinguish
    between the concepts of GPT-generated text, LLM-generated text, and machine-generated
    text.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在对流行语言模型进行彻底检查后，我们观察到在精细调优的大型语言模型中，采用精心设计的文本提示具有显著优势。这些模型遵循指令微调的方法，类似于InstructGPT[[24](#bib.bib24)]，它们根据用户提供的指令或提示作出响应。在大多数情况下，用户的指令可以视为对大型语言模型（如ChatGPT）提出的问题，而ChatGPT生成的文本可以看作是模型对该问题的回应或答案。在本文的其余部分，我们使用GPT或ChatGPT来指代所有具有类似能力的大型语言模型，不再区分GPT生成的文本、LLM生成的文本和机器生成的文本的概念。
- en: 'Based on our analysis of ChatGPT’s training process and user interactions,
    we propose a hypothesis: when ChatGPT consistently produces answers to similar
    questions, generated texts (i.e., ChatGPT’s responses to these questions) exhibit
    high similarity. In simpler terms, the language model’s output is a rearrangement
    of the content found in its training corpus. Therefore, when repeatedly answering
    a question, the language model’s response will be constrained by the information
    within its training corpus, resulting in limited deviations. We refer to this
    characteristic as the "genetic inheritance" of GPT-generated text. We present
    a more formal statement of our hypothesis in Hypothesis [3.1](#S3.Thmtheorem1
    "Hypothesis 3.1 (GPT Genetic Inheritance.) ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method
    ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance").'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '基于我们对ChatGPT训练过程和用户互动的分析，我们提出了一个假设：当ChatGPT对类似问题持续产生答案时，生成的文本（即ChatGPT对这些问题的回答）表现出高度的相似性。简单来说，语言模型的输出是对其训练语料库中内容的重新排列。因此，当重复回答一个问题时，语言模型的响应将受到其训练语料库中信息的限制，从而导致有限的偏差。我们将这一特性称为GPT生成文本的“遗传继承”。我们在假设
    [3.1](#S3.Thmtheorem1 "Hypothesis 3.1 (GPT Genetic Inheritance.) ‣ 3.2 GPT Genetic
    Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with
    GPT Genetic Inheritance") 中提出了我们假设的更正式陈述。'
- en: Hypothesis 3.1 (GPT Genetic Inheritance.)
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 假设 3.1（GPT遗传继承。）
- en: Let $\mathcal{T}=\{T_{1},T_{2},...\}$.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 令 $\mathcal{T}=\{T_{1},T_{2},...\}$。
- en: $A\to B$ in content and meaning. This hypothesis posits that the output of ChatGPT
    is predictable, implying that for questions that are highly similar, ChatGPT will
    produce correspondingly similar responses. Next, we aim to verify the presence
    of genetic inheritance in GPT-generated text.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: $A\to B$ 在内容和意义上。这一假设认为ChatGPT的输出是可预测的，意味着对于高度相似的问题，ChatGPT将产生相应相似的回答。接下来，我们旨在验证GPT生成文本中是否存在遗传继承。
- en: 'Given a piece of text $\mathcal{T}$, such that:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一段文本 $\mathcal{T}$，使得：
- en: '|  | $\bar{\mathbf{q}}=\arg\max_{\mathbf{q}}{P(\mathbf{q}&#124;\mathbf{t})},$
    |  | (1) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $\bar{\mathbf{q}}=\arg\max_{\mathbf{q}}{P(\mathbf{q}&#124;\mathbf{t})},$
    |  | (1) |'
- en: where $P(\mathbf{q}|\mathbf{t})$.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $P(\mathbf{q}|\mathbf{t})$。
- en: We notice that ChatGPT performs exceptionally well in the QG task. Specifically,
    we obtain human-written or ChatGPT-generated answers $\mathcal{T}^{H/C}$ in the
    dataset, we observed a significant level of similarity.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到ChatGPT在QG任务中表现非常出色。具体来说，我们在数据集中获得了人类撰写的或ChatGPT生成的答案 $\mathcal{T}^{H/C}$，我们观察到显著的相似性水平。
- en: 'Table 1: We use prompts to obtain questions and answers from ChatGPT. 
    represents the text to be detected, and  is the summary of the text
    to be detected by ChatGPT, that is, the output of calling ChatGPT in the first
    step. $len$ is the length of the text to be detected. The prompts are adopted
    from [[1](#bib.bib1)]'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：我们使用提示来从 ChatGPT 获取问题和答案。 代表待检测的文本， 是 ChatGPT 要检测的文本的总结，即第一步中调用
    ChatGPT 的输出。$len$ 是待检测文本的长度。这些提示采用了[[1](#bib.bib1)]
- en: '| Task | Prompt |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 提示 |'
- en: '| --- | --- |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| QG | I want you to play the role of the questioner. I will type an answer
    in English, and you will ask me a question based on the answer in the same language.
    Don’t write any explanations or other text, just give me the question. 
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| QG | 我希望你扮演提问者的角色。我将用英语输入一个答案，你需要基于这个答案用相同的语言问我一个问题。不要写任何解释或其他文字，只需给我问题。
    |'
- en: '| Response |  Answer in $len$ words or less. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 回复 |  在$len$字以内回答。 |'
- en: 'Table 2: Examples that illustrate the similarity between the original text
    and the re-answered text. H stands for human and C stands for ChatGPT. It is evident
    that the machine text and its re-answer text share a greater degree of similarity.
    We have shaded identical portions of the text in a faint shade of red or green.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：说明原始文本和重新回答文本之间相似性的示例。H 代表人类，C 代表 ChatGPT。显然，机器文本及其重新回答文本之间具有更高的相似度。我们已将相同部分的文本用淡红色或绿色标记。
- en: '| Question | Please explain what is "Spatial index"? |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 请解释什么是“空间索引”？ |'
- en: '| --- | --- |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Original text (H) | A \markoverwith \ULonspatial index is a general-purpose
    \markoverwith \ULondatabase (usually a relational database) that has been enhanced
    to include \markoverwith \ULonspatial data that represents objects defined in
    a geometric space, along with tools for querying … | Original text (C) | A \markoverwith \ULonspatial
    index is a \markoverwith \ULondata structure that is used to \markoverwith \ULonefficiently
    \markoverwith \ULonstore and \markoverwith \ULonquery data that \markoverwith \ULonrepresents
    \markoverwith \ULonobjects defined in a \markoverwith \ULongeometric \markoverwith \ULonspace.
    It is \markoverwith \ULondesigned to support \markoverwith \ULonspatial queries,
    which are queries … |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 原文 (H) | 一个\markoverwith \ULon空间索引是一个通用的\markoverwith \ULon数据库（通常是关系型数据库），它已被增强以包含\markoverwith \ULon空间数据，这些数据表示定义在几何空间中的对象，以及查询工具…
    | 原文 (C) | 一个\markoverwith \ULon空间索引是一个\markoverwith \ULon数据结构，用于\markoverwith \ULon高效\markoverwith \ULon存储和\markoverwith \ULon查询表示\markoverwith \ULon定义在\markoverwith \ULon几何\markoverwith \ULon空间中的对象的数据。它是\markoverwith \ULon设计用来支持\markoverwith \ULon空间查询的，这些查询…
    |'
- en: '| Generated question (H) | What is a spatial database and what types of objects
    can it represent? | Generated question (C) | What is a spatial index and how is
    it used to efficiently store and query data that represents objects defined in
    a geometric space? |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 生成的问题 (H) | 什么是空间数据库，它可以表示哪些类型的对象？ | 生成的问题 (C) | 什么是空间索引，它如何用于高效存储和查询表示定义在几何空间中的对象的数据？
    |'
- en: '| Re-answered text (H) | A \markoverwith \ULonspatial database is a \markoverwith \ULondatabase
    that is optimized to store and manage \markoverwith \ULonspatial data, which is
    data that has a geographic or spatial component. It is designed to handle \markoverwith \ULondata
    that is related to physical locations on the earth’s surface … | Re-answered text
    (C) | A \markoverwith \ULonspatial index is a \markoverwith \ULondata structure
    that is used to \markoverwith \ULonefficiently \markoverwith \ULonstore and \markoverwith \ULonquery
    data that \markoverwith \ULonrepresents \markoverwith \ULonobjects defined in
    a \markoverwith \ULongeometric \markoverwith \ULonspace. It is a type of index
    that is \markoverwith \ULondesigned to handle \markoverwith \ULonspatial data,
    … |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 重新回答的文本 (H) | 一个\markoverwith \ULon空间数据库是一个\markoverwith \ULon优化存储和管理\markoverwith \ULon空间数据的\markoverwith \ULon数据库，空间数据是具有地理或空间成分的数据。它设计用于处理\markoverwith \ULon与地球表面上的实际位置相关的数据…
    | 重新回答的文本 (C) | 一个\markoverwith \ULon空间索引是一个\markoverwith \ULon数据结构，用于\markoverwith \ULon高效\markoverwith \ULon存储和\markoverwith \ULon查询表示\markoverwith \ULon定义在\markoverwith \ULon几何\markoverwith \ULon空间中的对象的数据。它是一种\markoverwith \ULon设计用来处理\markoverwith \ULon空间数据的索引，…
    |'
- en: 'Next, we re-enter ChatGPT-generated questions $\mathcal{Q}^{\prime H/C}$ in
    Table [3.2](#S3.SS2 "3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance").'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将 ChatGPT 生成的问题 $\mathcal{Q}^{\prime H/C}$ 重新输入到表 [3.2](#S3.SS2 "3.2 GPT
    遗传继承 ‣ 3 方法 ‣ GPT 亲子鉴定：GPT 生成文本检测与 GPT 遗传继承") 中。
- en: Upon analysis, we observed that the re-answered text corresponding to machine-generated
    text exhibits a higher level of similarity to the original machine text in terms
    of structure and vocabulary, with more identical paragraphs. In contrast, the
    similarity between the re-answered text and the original human text is lower.
    This intuitive observation suggests that the re-answered text derived from the
    question generation-answering process demonstrates a relatively high similarity
    to the original machine-generated text, while the similarity to the original human
    text is comparatively low.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 经过分析，我们观察到，与机器生成文本对应的重新回答的文本在结构和词汇上与原始机器文本的相似度更高，段落也更相似。相比之下，重新回答的文本与原始人类文本的相似度较低。这一直观观察表明，从问题生成-回答过程中得出的重新回答文本与原始机器生成文本的相似度相对较高，而与原始人类文本的相似度则较低。
- en: 'Therefore, Hypothesis [3.1](#S3.Thmtheorem1 "Hypothesis 3.1 (GPT Genetic Inheritance.)
    ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text
    Detection with GPT Genetic Inheritance") can be further expressed as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，假设 [3.1](#S3.Thmtheorem1 "假设 3.1 (GPT 遗传继承) ‣ 3.2 GPT 遗传继承 ‣ 3 方法 ‣ GPT 亲子鉴定：GPT
    生成文本检测与 GPT 遗传继承") 可以进一步表示为：
- en: Hypothesis 3.2 (GPT Paternity Test)
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 假设 3.2 (GPT 亲子鉴定)
- en: Let $\mathcal{T}=\{T_{1},T_{2},...\}$ tends to result in a lower similarity
    value.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让 $\mathcal{T}=\{T_{1},T_{2},...\}$ 趋向于较低的相似度值。
- en: 3.3 GPT Paternity Test
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 GPT 亲子鉴定
- en: 'Paternity testing involves utilizing DNA profiles to determine whether an individual
    is the biological parent of another individual. This process becomes particularly
    crucial when the rights and responsibilities of a parent are in question and there
    is uncertainty regarding the paternity of a child. In this paper, we propose the
    GPT Paternity Test (GPT-Pat), aiming to leverage the genetic inheritance of GPT
    as previously discussed to address the fundamental question: "Who is the author
    of a specific piece of text? Is it a human or a machine?" The GPT-Pat framework,
    outlined in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"), can be divided into
    three main components based on the learning pipeline: (1) data creation, (2) similarity
    measurement, and (3) classification.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 亲子鉴定涉及利用 DNA 资料来确定一个人是否是另一个人的生物学父母。当父母的权利和责任受到质疑且对孩子的亲子关系存在不确定性时，这一过程尤为重要。在本文中，我们提出了
    GPT 亲子鉴定 (GPT-Pat)，旨在利用 GPT 的遗传继承，正如前面讨论的那样，来解决根本问题：“特定文本的作者是谁？是人类还是机器？”GPT-Pat
    框架，如图 [1](#S1.F1 "图 1 ‣ 1 引言 ‣ GPT 亲子鉴定：GPT 生成文本检测与 GPT 遗传继承") 所示，可以基于学习流程分为三个主要组件：(1)
    数据创建，(2) 相似度测量，以及 (3) 分类。
- en: Data Creation.
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据创建。
- en: 'Data creation aims to obtain the re-answered text corresponding to the text
    to be tested according to the process of summarizing and re-answering in Algorithm
    [1](#alg1 "Algorithm 1 ‣ Data Creation. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic
    Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with
    GPT Genetic Inheritance").'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据创建的目的是根据算法 [1](#alg1 "算法 1 ‣ 数据创建 ‣ 3.3 GPT 亲子鉴定 ‣ 3.2 GPT 遗传继承 ‣ 3 方法 ‣ GPT
    亲子鉴定：GPT 生成文本检测与 GPT 遗传继承") 中总结和重新回答的过程，获得与待测试文本对应的重新回答文本。
- en: Algorithm 1 Data Creation
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 数据创建
- en: 0:  $text\ \mathcal{T}$
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 0:  $text\ \mathcal{T}$
- en: Similarity Measurement.
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 相似度测量。
- en: In our preliminary experiments, we observed that the re-answered text generated
    by ChatGPT was more similar to the original answer of the same question compared
    to the human-written answer. Here, we consider calculating the similarity at the
    high-dimensional feature level to better capture the similarity of sentences.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的初步实验中，我们观察到 ChatGPT 生成的重新回答的文本与同一问题的原始回答相比，更类似于原始回答。这里，我们考虑在高维特征层面计算相似度，以更好地捕捉句子的相似性。
- en: To address this, we employed a Siamese network structure to measure the similarity
    between texts. We selected a pre-trained language model as the backbone network
    to convert texts into semantic embeddings. A Siamese network is an artificial
    neural network that simultaneously processes two different input tensors using
    the same weights, producing comparable output tensors.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们采用了Siamese网络结构来测量文本之间的相似度。我们选择了一个预训练的语言模型作为主干网络，将文本转换为语义嵌入。Siamese网络是一种人工神经网络，利用相同的权重同时处理两个不同的输入张量，产生可比的输出张量。
- en: 'In our Siamese network, the original text and the re-answered text are used
    as inputs for the two branches of the network. The output consists of two corresponding
    semantic embeddings. Based on these embeddings, we calculate the cosine similarity
    value, which can be expressed as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的Siamese网络中，原始文本和重新回答的文本作为网络两个分支的输入。输出包括两个相应的语义嵌入。基于这些嵌入，我们计算余弦相似度值，公式如下：
- en: '|  | $1$2 |  | (2) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (2) |'
- en: where $\mathbf{e}(\mathcal{T})$ obtained through the Siamese network.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{e}(\mathcal{T})$是通过Siamese网络获得的。
- en: Classification.
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类。
- en: 'Both the embeddings and the cosine similarity value are fed into a classifier
    denoted as $\phi$ being machine-generated text can be computed as:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入和余弦相似度值都输入到一个表示为$\phi$的分类器中，机器生成文本的计算公式为：
- en: '|  | $pre(\mathcal{T})=\phi(\mathbf{e}(\mathcal{T}),\mathbf{e}(\mathcal{T}^{\prime}),\sigma(\mathcal{T},\mathcal{T^{\prime}})).$
    |  | (3) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '|  | $pre(\mathcal{T})=\phi(\mathbf{e}(\mathcal{T}),\mathbf{e}(\mathcal{T}^{\prime}),\sigma(\mathcal{T},\mathcal{T^{\prime}})).$
    |  | (3) |'
- en: Please note that in addition to feeding the calculated similarity into the classifier,
    we have also included the semantic embeddings. This decision is based on the implication
    that the absolute value of similarity between a text and its corresponding re-answered
    text may vary across topics. By incorporating high-dimensional features represented
    by semantic embeddings, we can enhance the adaptability of the classifiers to
    handle a wide range of topics effectively.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了将计算出的相似度输入到分类器中外，我们还包含了语义嵌入。这一决定基于这样一个含义，即文本与其对应的重新回答文本之间的绝对相似度可能在不同主题间有所变化。通过引入由语义嵌入表示的高维特征，我们可以增强分类器处理广泛主题的适应性。
- en: 'Our loss function denoted as $\mathcal{L}$:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的损失函数表示为$\mathcal{L}$：
- en: '|  | $\mathcal{L}=-y\log(pre)+(1-y)\log(1-pre).$ |  | (4) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=-y\log(pre)+(1-y)\log(1-pre).$ |  | (4) |'
- en: With the well-trained Siamese network and the classifier, users can perform
    the paternity test on any piece of text to identify whether it is a machine-generated
    text.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用经过良好训练的Siamese网络和分类器，用户可以对任何文本进行父子鉴定，以识别是否为机器生成文本。
- en: 4 Experiment
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 'In this section, we first introduce the datasets and evaluation metrics that
    we use in Sec. [4.1](#S4.SS1 "4.1 Datasets and Evaluation ‣ 4 Experiment ‣ Classification.
    ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity
    Test: GPT Generated Text Detection with GPT Genetic Inheritance") and details
    of our experiments in Sec. [4.2](#S4.SS2 "4.2 Implementation Details. ‣ 4 Experiment
    ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method
    ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance").
    Then we validate the effectiveness of our proposed GPT-Pat in Sec. [4.3](#S4.SS3
    "4.3 Performance ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2
    GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection
    with GPT Genetic Inheritance"), which is followed by an ablation study in Sec.
    [4.4](#S4.SS4 "4.4 Ablation Studies ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT
    Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"). Finally, in Sec.
    [4.5](#S4.SS5 "4.5 Adaptive Attacks ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT
    Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"), some attacks are
    conducted to evaluate the robustness of GPT-Pat.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们首先介绍在 Sec. [4.1](#S4.SS1 "4.1 Datasets and Evaluation ‣ 4 Experiment
    ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method
    ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance")
    使用的数据集和评估指标，以及在 Sec. [4.2](#S4.SS2 "4.2 Implementation Details. ‣ 4 Experiment
    ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method
    ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic Inheritance")
    中实验的详细信息。接着，我们在 Sec. [4.3](#S4.SS3 "4.3 Performance ‣ 4 Experiment ‣ Classification.
    ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity
    Test: GPT Generated Text Detection with GPT Genetic Inheritance") 中验证我们提出的 GPT-Pat
    的有效性，然后在 Sec. [4.4](#S4.SS4 "4.4 Ablation Studies ‣ 4 Experiment ‣ Classification.
    ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity
    Test: GPT Generated Text Detection with GPT Genetic Inheritance") 进行消融研究。最后，在
    Sec. [4.5](#S4.SS5 "4.5 Adaptive Attacks ‣ 4 Experiment ‣ Classification. ‣ 3.3
    GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance") 中进行一些攻击实验，以评估 GPT-Pat
    的鲁棒性。'
- en: 4.1 Datasets and Evaluation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集和评估
- en: In this paper, we leverage 5 datasets, one for training and testing, and the
    other four for evaluating the generalization ability of various methods.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们利用了 5 个数据集，其中一个用于训练和测试，其余四个用于评估各种方法的泛化能力。
- en: •
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: HC3 [[12](#bib.bib12)]. The HC3 dataset consists of questions and their corresponding
    human/ChatGPT answers. Most of the human-written data come from the publicly available
    Question-Answering (QA) datasets, others are collected from Wikipedia²²2[https://www.wikipedia.org/](https://www.wikipedia.org/)
    as the human experts’ answers to questions such as "Please explain what is ?"
    ChatGPT answers are collected by inputting the questions into ChatGPT.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: HC3 [[12](#bib.bib12)]。HC3 数据集包含问题及其对应的人类/ChatGPT 答案。大部分人类编写的数据来自公开的问答（QA）数据集，其余数据则从维基百科²²2[https://www.wikipedia.org/](https://www.wikipedia.org/)
    收集，作为人类专家对诸如“请解释  是什么？”的问题的回答。ChatGPT 答案是通过将问题输入到 ChatGPT 中获得的。
- en: •
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Wiki. We selected some entries from Wikipedia that do not overlap with the data
    in HC3 to evaluate the performance of different detection methods on data similar
    to the training dataset.
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Wiki。我们从维基百科中选择了一些与 HC3 数据集中的数据不重叠的条目，以评估不同检测方法在类似训练数据集的数据上的表现。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: CCNews [[13](#bib.bib13)]. We selected some data from CCNews dataset to construct
    human/ChatGPT news pairs. ChatGPT news is generated according to the prompt "Heading
     and beginning with , follow up a press release", where  comes
    from the original dataset, and  is intercepted from the first 20% of human
    text.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CCNews [[13](#bib.bib13)]。我们从 CCNews 数据集中选择了一些数据以构建人类/ChatGPT 新闻对。ChatGPT 新闻是根据提示“标题
     并以  开头，跟随新闻稿”生成的，其中  来自原始数据集， 则从人类文本的前 20% 截取。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: CovidCM [[21](#bib.bib21)]. We picked the community split from CovidQA dataset,
    which is a collection of COVID-19 Q&A pairs from 15 English news websites across
    4 continents. ChatGPT answers are obtained by inputting the questions into ChatGPT.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CovidCM [[21](#bib.bib21)]。我们选择了 CovidQA 数据集中的社区划分，该数据集收集了来自 4 个大洲的 15 个英文新闻网站的
    COVID-19 问答对。ChatGPT 答案是通过将问题输入到 ChatGPT 中获得的。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ACLAbs. We selected some Association for Computational Linguistics (ACL) scientific
    paper data from SUMMAC³³3[https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html](https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html).
    For the human-written data, we use the original ABSTRACT data. To generate ChatGPT
    responses, we use the following prompt: "Please write an abstract with the title
     for the research paper," where  is obtained from the original dataset.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ACLAbs。我们从SUMMAC³³3[https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html](https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html)中选择了一些计算语言学协会（ACL）的科学论文数据。对于人类编写的数据，我们使用原始的ABSTRACT数据。为了生成ChatGPT的回答，我们使用以下提示：“请为研究论文写一篇标题为的摘要”，其中来自原始数据集。
- en: Both human answers and ChatGPT answers may contain some obvious indicating words
    that may influence the effectiveness of models [[12](#bib.bib12)]. Therefore,
    we conduct data cleaning on all data in the aforementioned datasets, removing
    indicating words corresponding to human-written and machine-generated text. Our
    evaluation metrics include accuracy, precision and F1-score. The machine-generated
    texts are used as positive samples, and the human-written texts are used as negative
    samples.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 人类回答和ChatGPT回答可能包含一些明显的指示性词汇，这可能会影响模型的有效性[[12](#bib.bib12)]。因此，我们对上述数据集中的所有数据进行了数据清理，去除了与人类编写和机器生成文本对应的指示性词汇。我们的评估指标包括准确率、精确度和F1分数。机器生成的文本作为正样本，人类编写的文本作为负样本。
- en: 4.2 Implementation Details.
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 实现细节。
- en: 'To be fairly comparable with other methods, we conduct the following training
    and testing settings. Unless otherwise noted, the settings are the same for all
    experiments. We implemented our proposed GPT-Pat using PyTorch [[25](#bib.bib25)].
    To access ChatGPT, we utilize the OpenAI API and specifically employed the gpt-3.5-turbo  [[23](#bib.bib23)]
    model for making requests, utilizing the prompts listed in Table [1](#S3.T1 "Table
    1 ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated
    Text Detection with GPT Genetic Inheritance") to generate questions and re-answered
    texts. We set the sampling temperature to 0.2, for lower temperature results in
    more focused and deterministic output, as suggested in the official documentation
    [[22](#bib.bib22)]. We create a new conversation with ChatGPT for each query to
    avoid being affected by the chat history. For measuring similarity, we use xlm-roberta-base  [[7](#bib.bib7)]
    as the initial weights for our Siamese network. We set batch size to 32 and employ
    the Adam [[16](#bib.bib16)] optimizer with an initial learning rate of 5e-5\.
    We trian the GPT-Pat model on HC3\. The ratio for splitting the training, validation,
    and test sets is 7:1.5:1.5\. The model was trained for 5000 steps on the training
    set, and the best model was selected based on its performance on the validation
    set.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '为了公平地与其他方法进行比较，我们进行了以下训练和测试设置。除非另有说明，这些设置对所有实验都是相同的。我们使用PyTorch[[25](#bib.bib25)]实现了我们提出的GPT-Pat。为了访问ChatGPT，我们利用了OpenAI
    API，并专门使用了gpt-3.5-turbo[[23](#bib.bib23)]模型进行请求，利用表格[1](#S3.T1 "Table 1 ‣ 3.2
    GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection
    with GPT Genetic Inheritance")中列出的提示生成问题和重新回答的文本。我们将采样温度设置为0.2，因为较低的温度可以产生更集中的确定性输出，如官方文档[[22](#bib.bib22)]所建议的。我们为每个查询创建一个新的ChatGPT对话，以避免受到聊天历史的影响。为了测量相似度，我们使用xlm-roberta-base[[7](#bib.bib7)]作为我们Siamese网络的初始权重。我们将批量大小设置为32，并使用Adam[[16](#bib.bib16)]优化器，初始学习率为5e-5。我们在HC3上训练了GPT-Pat模型。训练、验证和测试集的分割比例为7:1.5:1.5。该模型在训练集上训练了5000步，最佳模型是根据其在验证集上的表现选择的。'
- en: For PPL-based method [[12](#bib.bib12)], we use gpt2-medium  [[27](#bib.bib27)]
    model to compute the perplexity and burstiness of texts. We retrain a classification
    threshold for it on the training split of HC3\. DetectGPT is a zero-shot machine-generated
    text detection method based on the white-box assumption, which does not require
    training. To compare its performance, we follow the setting of MGTBench [[14](#bib.bib14)],
    utilizing gpt2-medium and t5-large  [[28](#bib.bib28)] as its base model and mask-filling
    model, respectively. For RoBERTa-based classifier, we use a pre-existing Hello-SimpleAI/chatgpt-detector-roberta  [[12](#bib.bib12)]
    weights that were well trained on the HC3 dataset.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于PPL的方法 [[12](#bib.bib12)]，我们使用gpt2-medium [[27](#bib.bib27)]模型来计算文本的困惑度和突发性。我们在HC3的训练集上重新训练了分类阈值。DetectGPT是一种基于白盒假设的零样本机器生成文本检测方法，无需训练。为了比较其性能，我们遵循MGTBench
    [[14](#bib.bib14)]的设置，分别使用gpt2-medium和t5-large [[28](#bib.bib28)]作为其基础模型和掩码填充模型。对于基于RoBERTa的分类器，我们使用预先存在的Hello-SimpleAI/chatgpt-detector-roberta
    [[12](#bib.bib12)]权重，该权重在HC3数据集上经过良好的训练。
- en: All experiments are conducted on a workstation equipped with 4 NVIDIA A6000
    GPU cards.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实验均在配备4张NVIDIA A6000 GPU卡的工作站上进行。
- en: 4.3 Performance
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 性能
- en: 'Table 3: The accuracy, precision and F1-score performance of our detection
    method and others on various datasets. P, D, R, and G stand for PPL[[5](#bib.bib5)]
    classifier, DetectGPT [[20](#bib.bib20)], RoBERTa-based classifer [[12](#bib.bib12)],
    and GPT-Pat, respectively. The length of these five datasets are 8838, 5166, 650
    and 295, respectively.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：我们的方法与其他方法在各种数据集上的准确率、精确度和F1-score表现。P、D、R和G分别代表PPL[[5](#bib.bib5)]分类器、DetectGPT
    [[20](#bib.bib20)]、基于RoBERTa的分类器 [[12](#bib.bib12)]和GPT-Pat。这五个数据集的长度分别为8838、5166、650和295。
- en: Dataset Accuracy Precision F1-score P D R G P D R G P D R G HC3 0.9344 0.8140
    0.9943 0.9989 0.9519 0.8036 0.9936 0.9984 0.9341 0.8171 0.9944 0.9989 Wiki 0.8547
    0.7155 0.8843 0.9532 0.8721 0.7181 0.8152 0.9348 0.8512 0.7138 0.8958 0.9541 CCNews
    0.7156 0.7650 0.7011 0.9337 0.6825 0.7477 0.6304 0.9670 0.7393 0.7729 0.7648 0.9313
    CovidCM 0.8353 0.7192 0.9676 0.9676 0.8758 0.7286 0.9634 0.9903 0.8260 0.7133
    0.9678 0.9669 ACLAbs 0.7050 0.8859 0.8745 0.8983 0.9692 0.9000 1.0000 1.0000 0.5915
    0.8839 0.8571 0.8872
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 准确率 精确度 F1-score P D R G P D R G P D R G HC3 0.9344 0.8140 0.9943 0.9989
    0.9519 0.8036 0.9936 0.9984 0.9341 0.8171 0.9944 0.9989 Wiki 0.8547 0.7155 0.8843
    0.9532 0.8721 0.7181 0.8152 0.9348 0.8512 0.7138 0.8958 0.9541 CCNews 0.7156 0.7650
    0.7011 0.9337 0.6825 0.7477 0.6304 0.9670 0.7393 0.7729 0.7648 0.9313 CovidCM
    0.8353 0.7192 0.9676 0.9676 0.8758 0.7286 0.9634 0.9903 0.8260 0.7133 0.9678 0.9669
    ACLAbs 0.7050 0.8859 0.8745 0.8983 0.9692 0.9000 1.0000 1.0000 0.5915 0.8839 0.8571
    0.8872
- en: Comparisons on HC3.
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: HC3上的比较。
- en: 'We compare GPT-Pat with other methods on the test split of HC3 dataset and
    show the accuracy, precision and F1-score in Table [3](#S4.T3 "Table 3 ‣ 4.3 Performance
    ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance"). All methods except DetectGPT are trained on HC3, so these results
    can well reflect the detection performance of various detection methods on the
    same type of text. The best performer among the compared methods is the RoBERTa
    classifier, achieving a capability very close to that of our method. As the model-based
    method is trained on a corpus containing pairings of human-written and ChatGPT-generated
    texts, it should learn the subtle differences between human texts and ChatGPT
    texts, resulting in improved performance. It can be observed that our GPT-Pat
    outperforms the RoBERTa classifier in terms of detection performance across all
    three metrics.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在HC3数据集的测试集上将GPT-Pat与其他方法进行了比较，并在表[3](#S4.T3 "Table 3 ‣ 4.3 Performance ‣
    4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance")中展示了准确率、精确度和F1-score。除DetectGPT外的所有方法均在HC3上进行训练，因此这些结果可以很好地反映各种检测方法在相同类型文本上的检测性能。比较方法中表现最好的的是RoBERTa分类器，其能力与我们的方法非常接近。由于基于模型的方法在包含人类编写文本和ChatGPT生成文本的语料库上进行训练，它应该能够学习人类文本和ChatGPT文本之间的微妙差异，从而提高性能。可以观察到，我们的GPT-Pat在三个指标上的检测性能都优于RoBERTa分类器。'
- en: Comparisons on other datasets.
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 其他数据集上的比较。
- en: 'We present the accuracy, precision, and F1-score of the compared methods on
    additional generalization test datasets in Table [3](#S4.T3 "Table 3 ‣ 4.3 Performance
    ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance"). Our method demonstrates significantly superior performance compared
    to other methods in these experiments. For instance, GPT-Pat achieves F1-scores
    of 0.9541 and 0.9313 on the Wiki and CCNews datasets, respectively, whereas RoBERTa
    only achieves F1-scores of 0.8958 and 0.7648\. On all the data of these four general
    test data sets, the average accuracy of GPT-Pat is as high as 0.9457, which is
    12.34% higher than the average accuracy of 0.8223 of the second-ranked RoBERTa.
    These results indicate that GPT-Pat is more suitable for practical applications
    where the source of the text to be detected is unknown and the topics are diverse.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在表格[3](#S4.T3 "Table 3 ‣ 4.3 Performance ‣ 4 Experiment ‣ Classification.
    ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity
    Test: GPT Generated Text Detection with GPT Genetic Inheritance")中展示了比较方法在附加泛化测试数据集上的准确率、精度和F1分数。我们的办法在这些实验中表现出明显优于其他方法的性能。例如，GPT-Pat在Wiki和CCNews数据集上分别取得了0.9541和0.9313的F1分数，而RoBERTa仅取得了0.8958和0.7648的F1分数。在这四个常规测试数据集的所有数据中，GPT-Pat的平均准确率高达0.9457，比排名第二的RoBERTa的0.8223高出12.34%。这些结果表明，GPT-Pat更适合于实际应用中，当待检测文本的来源未知且主题多样时。'
- en: On the other hand, we observe that our method exhibits a more pronounced advantage
    when using precision as the evaluation metric. For example, GPT-Pat achieves precise
    detection with a precision rate of 0.9670 on the CCNews dataset, whereas other
    methods can only achieve precision rates of no more than 0.7477\. In other words,
    our method is less prone to misclassify human-written text as machine-generated
    text, a common issue in other methods. This is a significant advantage as misclassification
    can severely undermine the credibility of the detector in practical scenarios.
    If too many human-written texts are flagged as machine-generated texts, it can
    result in a decline in user trust towards machine-generated text detectors. Users
    may begin disregarding alerts, even if some of them are genuine, due to becoming
    accustomed to receiving false alerts.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们观察到当使用精度作为评估指标时，我们的方法表现出更为明显的优势。例如，GPT-Pat在CCNews数据集上以0.9670的精度率实现了精准检测，而其他方法的精度率最高只能达到0.7477。换句话说，我们的方法较少将人类撰写的文本误分类为机器生成的文本，这是其他方法中的一个常见问题。这是一个显著的优势，因为误分类会严重影响检测器在实际场景中的可信度。如果过多的人类撰写的文本被标记为机器生成文本，可能会导致用户对机器生成文本检测器的信任下降。用户可能会开始忽视警报，即使其中一些是有效的，因为他们已经习惯了收到虚假的警报。
- en: This advantage can be attributed to the significant variations in writing styles
    among different human authors. It becomes challenging for human-written texts
    in other datasets to fully align with the features learned by the detector during
    training. GPT-Pat, on the other hand, learns the similarity between the text to
    be detected and its corresponding re-answered text. As long as the text does not
    exhibit the heritability of machine-generated text, it can be correctly classified
    as human-written text.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这种优势可以归因于不同人类作者之间写作风格的显著差异。其他数据集中人类撰写的文本与检测器在训练期间学到的特征完全对齐变得具有挑战性。另一方面，GPT-Pat学习了待检测文本与其相应的重新回答文本之间的相似性。只要文本没有显示出机器生成文本的遗传特征，就可以被正确地分类为人类撰写的文本。
- en: '![Refer to caption](img/efb0157556838e736d1fe439a47eb763.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/efb0157556838e736d1fe439a47eb763.png)'
- en: (a) Jaccard similarity between texts
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 文本之间的Jaccard相似度
- en: '![Refer to caption](img/133e4a44560501959102220ac463bd4a.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/133e4a44560501959102220ac463bd4a.png)'
- en: (b) Cosine similarity between embeddings
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 嵌入向量之间的余弦相似度
- en: 'Figure 2: Distributions of different similarity measurement on both human and
    ChatGPT text.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：不同相似度测量在人工文本和ChatGPT文本上的分布。
- en: 4.4 Ablation Studies
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 消融研究
- en: We conduct ablation studies that investigate whether the Siamese network is
    effective and how to choose the backbone network.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一些消融研究，调查了Siamese网络是否有效以及如何选择骨干网络。
- en: Effect of Architecture.
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 架构的效果。
- en: 'We compared four structures for similarity calculation and classification in
    this study. Firstly, we use the Traditional method to compute the Jaccard Similarity
    between the text and its re-answered text and choose an optimal classification
    Threshold (TST). Secondly, we employ a Siamese network to generate embeddings
    for cosine Similarity calculation and Threshold classification (short for SST).
    Thirdly, we utilized a Fully Connected layer to classify the embeddings computed
    by the Siamese network (SFC). Lastly, we combined the Similarity measure and the
    embeddings and applied a Fully connected layer for classification (SSF). We present
    in Figure [2](#S4.F2 "Figure 2 ‣ Comparisons on other datasets. ‣ 4.3 Performance
    ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance
    ‣ 3 Method ‣ GPT Paternity Test: GPT Generated Text Detection with GPT Genetic
    Inheritance") the distribution of Jaccard similarity computed by traditional method
    in TST and cosine similarity between the semantic embeddings of human-written
    or machine-generated texts and their corresponding re-answered texts, as computed
    by the trained Siamese network. It can be observed that there is a more significant
    difference in the cosine similarity distribution of embeddings than Jaccard similarity
    computed between texts, which allows for more clear distinction between the majority
    of human and machine texts. Moreover, considering the the high-dimensional semantic
    information of the text when measuring the similarity, the detection method can
    have a better adaptive ability. As shown in Table [4](#S4.T4 "Table 4 ‣ Effect
    of Architecture. ‣ 4.4 Ablation Studies ‣ 4 Experiment ‣ Classification. ‣ 3.3
    GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test:
    GPT Generated Text Detection with GPT Genetic Inheritance"), the structure that
    classifies both embeddings and similarity with a fully connected layer performed
    the best, which is what we selected as the structure for our GPT-Pat.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究比较了四种用于相似度计算和分类的结构。首先，我们使用传统方法计算文本及其重新回答文本之间的Jaccard相似度，并选择一个最佳分类阈值（TST）。其次，我们使用Siamese网络生成用于余弦相似度计算和阈值分类的嵌入（简称SST）。第三，我们利用全连接层对Siamese网络计算的嵌入进行分类（SFC）。最后，我们将相似度度量和嵌入结合起来，并应用全连接层进行分类（SSF）。我们在图
    [2](#S4.F2 "图 2 ‣ 其他数据集上的比较。 ‣ 4.3 性能 ‣ 4 实验 ‣ 分类。 ‣ 3.3 GPT亲子测试 ‣ 3.2 GPT遗传继承
    ‣ 3 方法 ‣ GPT亲子测试：GPT生成文本检测与GPT遗传继承") 中展示了传统方法在TST中计算的Jaccard相似度的分布，以及训练后的Siamese网络计算的人类编写或机器生成文本的语义嵌入及其对应的重新回答文本之间的余弦相似度。可以观察到，相比于文本之间计算的Jaccard相似度，嵌入的余弦相似度分布差异更显著，这使得大多数人类文本和机器文本之间的区别更为明显。此外，考虑到测量相似度时文本的高维语义信息，检测方法具有更好的适应能力。如表
    [4](#S4.T4 "表 4 ‣ 架构效果。 ‣ 4.4 消融研究 ‣ 4 实验 ‣ 分类。 ‣ 3.3 GPT亲子测试 ‣ 3.2 GPT遗传继承 ‣
    3 方法 ‣ GPT亲子测试：GPT生成文本检测与GPT遗传继承") 所示，使用全连接层对嵌入和相似度进行分类的结构表现最佳，这也是我们选择作为GPT-Pat结构的原因。
- en: 'Table 4: Accuracy of different classifier architectures on various datasets.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 各种数据集上不同分类器架构的准确率。'
- en: '| Dataset | Architecture |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 架构 |'
- en: '| --- | --- |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| TST | SST | SFC | SSF |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| TST | SST | SFC | SSF |'
- en: '| --- | --- | --- | --- |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| HC3 | 0.7977 | 0.9873 | 0.9987 | 0.9989 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| HC3 | 0.7977 | 0.9873 | 0.9987 | 0.9989 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Wiki | 0.7669 | 0.8697 | 0.9237 | 0.9532 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Wiki | 0.7669 | 0.8697 | 0.9237 | 0.9532 |'
- en: '| CCNews | 0.6916 | 0.7880 | 0.9351 | 0.9337 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| CCNews | 0.6916 | 0.7880 | 0.9351 | 0.9337 |'
- en: '| CovidCM | 0.8000 | 0.9538 | 0.9584 | 0.9676 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| CovidCM | 0.8000 | 0.9538 | 0.9584 | 0.9676 |'
- en: '| ACLAbs | 0.6542 | 0.9527 | 0.9322 | 0.8983 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| ACLAbs | 0.6542 | 0.9527 | 0.9322 | 0.8983 |'
- en: 4.5 Adaptive Attacks
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 自适应攻击
- en: 'To better understand of how GPT-Pat performs in real-world scenarios, we evaluate
    our detection method using two common text modification methods, namely Machine
    Re-translation and Partial Text Polishing (hybrid human-machine). Machine re-translation
    is a process where a piece of text is translated from one language to another
    and then back to the original language using machine translation. This process
    can sometimes introduce subtle changes and errors in the text, which can be challenging
    for a detection model to handle. In partial text polishing experiment, we use
    ChatGPT to partially polish the human-written texts, and for ChatGPT-generated
    text, we adopt a watermarking algorithm [[32](#bib.bib32)] which synonymously
    replaces words in sentences with a probability to simulate partial modification
    of human. This can be even more challenging for a detection model, as the text
    will be a mix of human-written and machine-generated content. We present the accuracy
    under these attacks of our GPT-Pat with other compared methods in Table [5](#S4.T5
    "Table 5 ‣ 4.5 Adaptive Attacks ‣ 4 Experiment ‣ Classification. ‣ 3.3 GPT Paternity
    Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity Test: GPT Generated
    Text Detection with GPT Genetic Inheritance"). It can be seen that under these
    two attacks, the accuracy degradation of GPT-Pat is less than that of the RoBERTa
    classifier, indicating that our method is more robust in the actual environment.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '为了更好地了解 GPT-Pat 在实际场景中的表现，我们使用两种常见的文本修改方法来评估我们的检测方法，即机器重新翻译和部分文本润色（混合人工-机器）。机器重新翻译是一个过程，其中一段文本从一种语言翻译到另一种语言，然后再翻译回原始语言，这一过程有时会引入细微的变化和错误，检测模型可能难以处理。在部分文本润色实验中，我们使用
    ChatGPT 对人工编写的文本进行部分润色，对于 ChatGPT 生成的文本，我们采用了水印算法 [[32](#bib.bib32)]，它通过替换句子中的单词以概率模拟部分人工修改。这对检测模型来说可能更具挑战性，因为文本将混合了人工编写和机器生成的内容。我们在表
    [5](#S4.T5 "Table 5 ‣ 4.5 Adaptive Attacks ‣ 4 Experiment ‣ Classification. ‣
    3.3 GPT Paternity Test ‣ 3.2 GPT Genetic Inheritance ‣ 3 Method ‣ GPT Paternity
    Test: GPT Generated Text Detection with GPT Genetic Inheritance") 中展示了在这些攻击下我们的
    GPT-Pat 与其他比较方法的准确性。可以看出，在这两种攻击下，GPT-Pat 的准确性下降幅度低于 RoBERTa 分类器，表明我们的方法在实际环境中更具鲁棒性。'
- en: 'Table 5: The accuracy performance under adaptive attacks of GPT-Pat and RoBERTa-based
    classifier [[12](#bib.bib12)]. In Re-translation experiment, English texts are
    translated into Chinese and then translated back to English using Baidu Translation
    [[2](#bib.bib2)] and DeepL [[3](#bib.bib3)] API. In polishing experiments, only
    the first sentence of each text was modified.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: GPT-Pat 和基于 RoBERTa 的分类器在自适应攻击下的准确性表现 [[12](#bib.bib12)]。在重新翻译实验中，英文文本被翻译成中文，然后通过百度翻译
    [[2](#bib.bib2)] 和 DeepL [[3](#bib.bib3)] API 重新翻译回英文。在润色实验中，仅修改了每个文本的第一句话。'
- en: '| Attack Method | Detection Method |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 攻击方法 | 检测方法 |'
- en: '| --- | --- |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GPT-Pat | RoBERTa |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| GPT-Pat | RoBERTa |'
- en: '| --- | --- |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Re-translation (Baidu) | before | 1.0 | 0.9962 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 重新翻译（百度） | 之前 | 1.0 | 0.9962 |'
- en: '| after | 0.8520 | 0.6928 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 之后 | 0.8520 | 0.6928 |'
- en: '| drop rate | 0.1480 | 0.3034 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 失效率 | 0.1480 | 0.3034 |'
- en: '| Re-translation (DeepL) | before | 1.0 | 0.9979 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 重新翻译（DeepL） | 之前 | 1.0 | 0.9979 |'
- en: '| after | 0.8472 | 0.7320 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 之后 | 0.8472 | 0.7320 |'
- en: '| drop rate | 0.1528 | 0.2659 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 失效率 | 0.1528 | 0.2659 |'
- en: '| Polishing | before | 0.9986 | 0.9959 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 润色 | 之前 | 0.9986 | 0.9959 |'
- en: '| after | 0.9879 | 0.9600 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 之后 | 0.9879 | 0.9600 |'
- en: '| drop rate | 0.0107 | 0.0359 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 失效率 | 0.0107 | 0.0359 |'
- en: 5 Conclusion and Limitation
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论与局限性
- en: In this paper, we propose a method for detecting machine-generated text using
    genetic inheritance of large language models (LLMs) such as GPT, which we refer
    to as GPT Paternity Test (GPT-Pat). GPT-Pat is based on a key hypothesis that
    LLMs tend to provide similar answers for similar questions. We designed a question
    generation and response process for ChatGPT, where the model generates a re-answered
    text corresponding to the input text. By comparing the similarity between the
    input text and the generated re-answered text, we can perform text detection,
    similar to the process of human paternity testing using DNA. Through evaluation
    on the HC3 and other generalized testing datasets, GPT-Pat demonstrates state-of-the-art
    detection performance and excels in robustness. One limitation of our method is
    that it requires querying ChatGPT during both training and testing, which results
    in perceptible time delays for users and incurs certain costs with each query.
    How to efficiently generate questions and re-answers corresponding to texts to
    be detected is to be studied in the future.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一种使用大语言模型（LLMs）如 GPT 的遗传继承来检测机器生成文本的方法，我们称之为 GPT 父权测试（GPT-Pat）。GPT-Pat
    基于一个关键假设，即 LLMs 倾向于对相似的问题提供类似的回答。我们为 ChatGPT 设计了一个问题生成和回答过程，其中模型生成与输入文本对应的重新回答文本。通过比较输入文本与生成的重新回答文本之间的相似性，我们可以进行文本检测，类似于人类使用
    DNA 进行父权测试的过程。通过在 HC3 和其他通用测试数据集上的评估，GPT-Pat 展示了最先进的检测性能，并在鲁棒性方面表现出色。我们方法的一个限制是它需要在训练和测试期间查询
    ChatGPT，这会导致用户感受到明显的时间延迟，并且每次查询都会产生一定的成本。未来需要研究如何高效生成与待检测文本对应的问题和重新回答。
- en: References
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Awesome ChatGPT Prompts. [https://huggingface.co/datasets/fka/awesome-chatgpt-prompts](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts).'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] 精选 ChatGPT 提示。 [https://huggingface.co/datasets/fka/awesome-chatgpt-prompts](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts)。'
- en: '[2] Baidu Generic Text Translation API. [https://fanyi-api.baidu.com/](https://fanyi-api.baidu.com/).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] 百度通用文本翻译 API。 [https://fanyi-api.baidu.com/](https://fanyi-api.baidu.com/)。'
- en: '[3] DeepL API. [https://www.deepl.com/en/docs-api/](https://www.deepl.com/en/docs-api/).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] DeepL API。 [https://www.deepl.com/en/docs-api/](https://www.deepl.com/en/docs-api/)。'
- en: '[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
    Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
    et al. Language models are few-shot learners. Advances in neural information processing
    systems, 33:1877–1901, 2020.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Tom Brown、Benjamin Mann、Nick Ryder、Melanie Subbiah、Jared D Kaplan、Prafulla
    Dhariwal、Arvind Neelakantan、Pranav Shyam、Girish Sastry、Amanda Askell 等。语言模型是少样本学习者。神经信息处理系统进展，33：1877–1901，2020
    年。'
- en: '[5] Stanley F Chen, Douglas Beeferman, and Roni Rosenfeld. Evaluation metrics
    for language models. 1998.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Stanley F Chen、Douglas Beeferman 和 Roni Rosenfeld。语言模型的评估指标。1998 年。'
- en: '[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav
    Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian
    Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint
    arXiv:2204.02311, 2022.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Aakanksha Chowdhery、Sharan Narang、Jacob Devlin、Maarten Bosma、Gaurav Mishra、Adam
    Roberts、Paul Barham、Hyung Won Chung、Charles Sutton、Sebastian Gehrmann 等。Palm：通过路径扩展语言建模。arXiv
    预印本 arXiv:2204.02311，2022 年。'
- en: '[7] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
    Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin
    Stoyanov. Unsupervised cross-lingual representation learning at scale. CoRR, abs/1911.02116,
    2019.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Alexis Conneau、Kartikay Khandelwal、Naman Goyal、Vishrav Chaudhary、Guillaume
    Wenzek、Francisco Guzmán、Edouard Grave、Myle Ott、Luke Zettlemoyer 和 Veselin Stoyanov。大规模无监督跨语言表示学习。CoRR，abs/1911.02116，2019
    年。'
- en: '[8] Xinya Du, Junru Shao, and Claire Cardie. Learning to ask: Neural question
    generation for reading comprehension. arXiv preprint arXiv:1705.00106, 2017.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Xinya Du、Junru Shao 和 Claire Cardie。学习提问：用于阅读理解的神经问题生成。arXiv 预印本 arXiv:1705.00106，2017
    年。'
- en: '[9] Nan Duan, Duyu Tang, Peng Chen, and Ming Zhou. Question generation for
    question answering. In Proceedings of the 2017 conference on empirical methods
    in natural language processing, pages 866–874, 2017.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Nan Duan、Duyu Tang、Peng Chen 和 Ming Zhou。问答生成。见 2017 年自然语言处理实证方法会议论文集，第
    866–874 页，2017 年。'
- en: '[10] Sebastian Gehrmann, Hendrik Strobelt, and Alexander M Rush. Gltr: Statistical
    detection and visualization of generated text. In Annual Meeting of the Association
    for Computational Linguistics. Association for Computational Linguistics (ACL),
    2019.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Sebastian Gehrmann、Hendrik Strobelt 和 Alexander M Rush。Gltr：生成文本的统计检测与可视化。见计算语言学协会年会。计算语言学协会（ACL），2019
    年。'
- en: '[11] Josh A Goldstein, Girish Sastry, Micah Musser, Renee DiResta, Matthew
    Gentzel, and Katerina Sedova. Generative language models and automated influence
    operations: Emerging threats and potential mitigations. arXiv preprint arXiv:2301.04246,
    2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Josh A Goldstein, Girish Sastry, Micah Musser, Renee DiResta, Matthew
    Gentzel, 和 Katerina Sedova. 生成语言模型和自动化影响操作：新兴威胁与潜在缓解措施。arXiv 预印本 arXiv:2301.04246，2023年。'
- en: '[12] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,
    Jianwei Yue, and Yupeng Wu. How close is chatgpt to human experts? comparison
    corpus, evaluation, and detection. arXiv preprint arXiv:2301.07597, 2023.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,
    Jianwei Yue, 和 Yupeng Wu. ChatGPT与人类专家有多接近？对比语料库、评估和检测。arXiv 预印本 arXiv:2301.07597，2023年。'
- en: '[13] Felix Hamborg, Norman Meuschke, Corinna Breitinger, and Bela Gipp. news-please:
    A generic news crawler and extractor. In Proceedings of the 15th International
    Symposium of Information Science, pages 218–223, March 2017.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Felix Hamborg, Norman Meuschke, Corinna Breitinger, 和 Bela Gipp. news-please:
    一种通用新闻爬虫和提取器。发表于第15届国际信息科学研讨会论文集中，页面218–223，2017年3月。'
- en: '[14] Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes, and Yang Zhang. Mgtbench:
    Benchmarking machine-generated text detection. arXiv preprint arXiv:2303.14822,
    2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Xinlei He, Xinyue Shen, Zeyuan Chen, Michael Backes, 和 Yang Zhang. Mgtbench:
    机器生成文本检测基准测试。arXiv 预印本 arXiv:2303.14822，2023年。'
- en: '[15] Last Week in AI. Last week in ai #205: How ai is going modular, growing
    legal cases against generative ai, tools to detect ai-generated text, and more,
    2023. Retrieved from [https://lastweekin.ai/p/205](https://lastweekin.ai/p/205).
    Accessed on March 1, 2023.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Last Week in AI. Last week in ai #205: 人工智能如何变得模块化，生成性人工智能面临的法律案件增长，检测AI生成文本的工具等，2023年。retrieved
    from [https://lastweekin.ai/p/205](https://lastweekin.ai/p/205)。访问日期：2023年3月1日。'
- en: '[16] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization.
    arXiv preprint arXiv:1412.6980, 2014.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Diederik P Kingma 和 Jimmy Ba. Adam: 一种用于随机优化的方法。arXiv 预印本 arXiv:1412.6980，2014年。'
- en: '[17] Ghader Kurdi, Jared Leo, Bijan Parsia, Uli Sattler, and Salam Al-Emari.
    A systematic review of automatic question generation for educational purposes.
    International Journal of Artificial Intelligence in Education, 30:121–204, 2020.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Ghader Kurdi, Jared Leo, Bijan Parsia, Uli Sattler, 和 Salam Al-Emari.
    教育目的的自动问题生成的系统评审。国际人工智能教育期刊，30:121–204，2020年。'
- en: '[18] Gary Marcus. Inside the heart of chatgpt’s darkness., 2023. Retrieved
    from [https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness](https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness).
    Accessed on February 25, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Gary Marcus. ChatGPT黑暗中的核心。2023年。 retrieved from [https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness](https://garymarcus.substack.com/p/inside-the-heart-of-chatgpts-darkness)。访问日期：2023年2月25日。'
- en: '[19] Alex Mitchell. Professor catches student cheating with chatgptl: ’i feel
    abject terror’, 2022. Retrieved from [https://nypost.com/2022/12/26/students-using-chatgpt-to-cheat-professor-warns/](https://nypost.com/2022/12/26/students-using-chatgpt-to-cheat-professor-warns/).
    Accessed on February 17, 2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Alex Mitchell. 教授抓到学生用ChatGPT作弊：‘我感到极度恐惧’，2022年。retrieved from [https://nypost.com/2022/12/26/students-using-chatgpt-to-cheat-professor-warns/](https://nypost.com/2022/12/26/students-using-chatgpt-to-cheat-professor-warns/)。访问日期：2023年2月17日。'
- en: '[20] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning,
    and Chelsea Finn. Detectgpt: Zero-shot machine-generated text detection using
    probability curvature. arXiv preprint arXiv:2301.11305, 2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning,
    和 Chelsea Finn. Detectgpt: 使用概率曲率的零样本机器生成文本检测。arXiv 预印本 arXiv:2301.11305，2023年。'
- en: '[21] Timo Möller, Anthony Reina, Raghavan Jayakumar, and Malte Pietsch. Covid-qa:
    A question answering dataset for covid-19. In Proceedings of the 1st Workshop
    on NLP for COVID-19 at ACL 2020, 2020.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Timo Möller, Anthony Reina, Raghavan Jayakumar, 和 Malte Pietsch. Covid-qa:
    一个用于COVID-19的问题回答数据集。发表于ACL 2020上的第1届NLP for COVID-19研讨会论文集中，2020年。'
- en: '[22] OpenAI. Document of api reference, 2023. Retrieved from [https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature).
    Accessed on April 1, 2023.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] OpenAI. API参考文档，2023年。retrieved from [https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature](https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature)。访问日期：2023年4月1日。'
- en: '[23] OpenAI. Document of models, 2023. Retrieved from [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5).
    Accessed on April 1, 2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] OpenAI. 模型文档，2023年。retrieved from [https://platform.openai.com/docs/models/gpt-3-5](https://platform.openai.com/docs/models/gpt-3-5)。访问日期：2023年4月1日。'
- en: '[24] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright,
    Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
    Training language models to follow instructions with human feedback. Advances
    in Neural Information Processing Systems, 35:27730–27744, 2022.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Long Ouyang、Jeffrey Wu、Xu Jiang、Diogo Almeida、Carroll Wainwright、Pamela
    Mishkin、Chong Zhang、Sandhini Agarwal、Katarina Slama、Alex Ray 等人。训练语言模型以遵循人类反馈的指令。《神经信息处理系统进展》，第35卷：27730–27744，2022年。'
- en: '[25] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
    Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch:
    An imperative style, high-performance deep learning library. Advances in neural
    information processing systems, 32, 2019.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Adam Paszke、Sam Gross、Francisco Massa、Adam Lerer、James Bradbury、Gregory
    Chanan、Trevor Killeen、Zeming Lin、Natalia Gimelshein、Luca Antiga 等人。Pytorch：一种命令式风格的高性能深度学习库。《神经信息处理系统进展》，第32卷，2019年。'
- en: '[26] Mary Louise Kelly Patrick Wood. ’everybody is cheating’: Why this teacher
    has adopted an open chatgpt policy, 2023. Retrieved from [https://www.npr.org/2023/01/26/1151499213/chatgpt-ai-education-cheating-classroom-wharton-school](https://www.npr.org/2023/01/26/1151499213/chatgpt-ai-education-cheating-classroom-wharton-school).
    Accessed on January 26, 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Mary Louise Kelly、Patrick Wood。‘每个人都在作弊’：为什么这位教师采用了开放的 ChatGPT 政策，2023年。检索自
    [https://www.npr.org/2023/01/26/1151499213/chatgpt-ai-education-cheating-classroom-wharton-school](https://www.npr.org/2023/01/26/1151499213/chatgpt-ai-education-cheating-classroom-wharton-school)。访问时间：2023年1月26日。'
- en: '[27] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
    Sutskever, et al. Language models are unsupervised multitask learners. OpenAI
    blog, 1(8):9, 2019.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Alec Radford、Jeffrey Wu、Rewon Child、David Luan、Dario Amodei、Ilya Sutskever
    等人。语言模型是无监督的多任务学习者。《OpenAI 博客》，第1卷(8):9，2019年。'
- en: '[28] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
    Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of
    transfer learning with a unified text-to-text transformer. Journal of Machine
    Learning Research, 21(140):1–67, 2020.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Colin Raffel、Noam Shazeer、Adam Roberts、Katherine Lee、Sharan Narang、Michael
    Matena、Yanqi Zhou、Wei Li 和 Peter J. Liu。通过统一的文本到文本变换器探索迁移学习的极限。《机器学习研究期刊》，第21卷(140):1–67，2020年。'
- en: '[29] Alejo Jose G Sison, Marco Tulio Daza, Roberto Gozalo-Brizuela, and Eduardo C
    Garrido-Merchán. Chatgpt: More than a weapon of mass deception, ethical challenges
    and responses from the human-centered artificial intelligence (hcai) perspective.
    arXiv preprint arXiv:2304.11215, 2023.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Alejo Jose G Sison、Marco Tulio Daza、Roberto Gozalo-Brizuela 和 Eduardo
    C Garrido-Merchán。Chatgpt：不仅仅是一个大规模欺骗的武器，从以人为本的人工智能（hcai）视角看道德挑战与回应。arXiv 预印本
    arXiv:2304.11215，2023年。'
- en: '[30] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss,
    Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, et al. Release
    strategies and the social impacts of language models. arXiv preprint arXiv:1908.09203,
    2019.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Irene Solaiman、Miles Brundage、Jack Clark、Amanda Askell、Ariel Herbert-Voss、Jeff
    Wu、Alec Radford、Gretchen Krueger、Jong Wook Kim、Sarah Kreps 等人。发布策略及语言模型的社会影响。arXiv
    预印本 arXiv:1908.09203，2019年。'
- en: '[31] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
    Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
    Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint
    arXiv:2302.13971, 2023.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Hugo Touvron、Thibaut Lavril、Gautier Izacard、Xavier Martinet、Marie-Anne
    Lachaux、Timothée Lacroix、Baptiste Rozière、Naman Goyal、Eric Hambro、Faisal Azhar
    等人。Llama：开放且高效的基础语言模型。arXiv 预印本 arXiv:2302.13971，2023年。'
- en: '[32] Xi Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang,
    and Nenghai Yu. Tracing text provenance via context-aware lexical substitution.
    In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages
    11613–11621, 2022.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Xi Yang、Jie Zhang、Kejiang Chen、Weiming Zhang、Zehua Ma、Feng Wang 和 Nenghai
    Yu。通过上下文感知的词汇替换追踪文本来源。发表于《AAAI 人工智能会议论文集》，第36卷，页面11613–11621，2022年。'
