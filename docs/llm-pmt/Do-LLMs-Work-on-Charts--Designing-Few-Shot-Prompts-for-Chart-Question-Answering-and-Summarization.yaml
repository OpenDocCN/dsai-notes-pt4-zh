- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 18:47:32'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:47:32
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs 在图表上有效吗？为图表问答和总结设计少量示例提示
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10610](https://ar5iv.labs.arxiv.org/html/2312.10610)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10610](https://ar5iv.labs.arxiv.org/html/2312.10610)
- en: Xuan Long Do¹, Mohammad Hassanpour², Ahmed Masry², Parsa Kavehzadeh²,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xuan Long Do¹, Mohammad Hassanpour², Ahmed Masry², Parsa Kavehzadeh²,
- en: Enamul Hoque², Shafiq Joty^(3,4)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Enamul Hoque², Shafiq Joty^(3,4)
- en: ¹National University of Singapore, ²York University, Canada,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹新加坡国立大学，²约克大学，加拿大，
- en: ³Nanyang Technological University, Singapore, ⁴Salesforce Research
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³南洋理工大学，新加坡，⁴Salesforce Research
- en: xuanlong.do@u.nus.edu, {mhpour, parsaka, enamulh}@yorku.ca,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: xuanlong.do@u.nus.edu, {mhpour, parsaka, enamulh}@yorku.ca,
- en: srjoty@ntu.edu.sg, ahmed.elmasry24653@gmail.com Work done when the author was
    on leave from NTU
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: srjoty@ntu.edu.sg, ahmed.elmasry24653@gmail.com 作者在离开 NTU 期间完成的工作
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: A variety of tasks have been proposed recently to facilitate exploration and
    analysis of charts such as chart QA and summarization. The dominant paradigm to
    solve these tasks has been to fine-tune a pretrained model on the task data. However,
    this approach is not only expensive but also not generalizable to unseen tasks.
    On the other hand, large language models (LLMs) have shown impressive generalization
    capabilities to unseen tasks with zero- or few-shot prompting. However, their
    application to chart-related tasks is not trivial as these tasks typically involve
    considering not only the underlying data but also the visual features in the chart
    image. We propose PromptChart, a multimodal few-shot prompting framework with
    LLMs for chart-related applications. By analyzing the tasks carefully, we have
    come up with a set of prompting guidelines for each task to elicit the best few-shot
    performance from LLMs. We further propose a strategy to inject visual information
    into the prompts. Our experiments on three different chart-related information
    consumption tasks show that with properly designed prompts LLMs can excel on the
    benchmarks, achieving state-of-the-art.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近提出了多种任务来促进图表的探索和分析，如图表问答和总结。解决这些任务的主流方法是对任务数据进行预训练模型的微调。然而，这种方法不仅成本高昂，而且无法推广到未见过的任务。另一方面，大型语言模型（LLMs）在处理未见过的任务时表现出令人印象深刻的泛化能力，无论是零-shot
    还是少量示例。然而，将其应用于图表相关任务并非易事，因为这些任务通常涉及考虑图表图像中的数据和视觉特征。我们提出了 PromptChart，一种用于图表相关应用的多模态少量示例提示框架。通过仔细分析任务，我们制定了一套针对每个任务的提示指南，以从
    LLMs 中引出最佳的少量示例性能。我们进一步提出了一种将视觉信息注入提示中的策略。我们在三种不同的图表相关信息消耗任务上的实验表明，通过适当设计的提示，LLMs
    可以在基准测试中表现出色，达到最新水平。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Data visualizations such as bar charts and line charts are frequently used for
    analyzing data, to derive important insights and make informed decisions Hoque
    et al. ([2022](#bib.bib18)). However, comprehending important patterns and trends
    from charts and answering complex questions about them can be cognitively demanding
    Whitaker and Jacobbe ([2017](#bib.bib49)); del Puy Pérez-Echeverría et al. ([2018](#bib.bib41)).
    To support users in analyzing charts, various downstream tasks have been proposed
    such as chart question answering or ChartQA Masry et al. ([2022](#bib.bib34));
    Kantharaj et al. ([2022a](#bib.bib21)); Lee et al. ([2022](#bib.bib25)) and chart
    summarization Kantharaj et al. ([2022b](#bib.bib22)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化，如柱状图和折线图，常用于分析数据，以获取重要见解并做出明智决策 Hoque 等人 ([2022](#bib.bib18))。然而，从图表中理解重要模式和趋势并回答关于它们的复杂问题可能具有认知挑战
    Whitaker 和 Jacobbe ([2017](#bib.bib49)); del Puy Pérez-Echeverría 等人 ([2018](#bib.bib41))。为了支持用户分析图表，提出了各种下游任务，例如图表问答或
    ChartQA Masry 等人 ([2022](#bib.bib34)); Kantharaj 等人 ([2022a](#bib.bib21)); Lee
    等人 ([2022](#bib.bib25)) 和图表总结 Kantharaj 等人 ([2022b](#bib.bib22))。
- en: To date, the dominant strategy to tackle these downstream tasks is to fine-tune
    a pre-trained language model or vision-language model on each task. While this
    strategy generally yields good performance, it requires a large amount of labeled
    data for each downstream task as well as computational resources to train. Furthermore,
    recent studies have shown that even after fine-tuning, these models still struggle
    with queries that involve logical and arithmetic reasoning Liu et al. ([2022b](#bib.bib28));
    Masry et al. ([2022](#bib.bib34)); Kantharaj et al. ([2022a](#bib.bib21)); Cheng
    et al. ([2023](#bib.bib7)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，解决这些下游任务的主要策略是对每个任务对预训练语言模型或视觉-语言模型进行微调。虽然这种策略通常能取得良好的性能，但它需要为每个下游任务准备大量标注数据以及训练的计算资源。此外，近期研究表明，即使在微调后，这些模型在涉及逻辑和算术推理的查询中仍然存在困难
    Liu et al. ([2022b](#bib.bib28)); Masry et al. ([2022](#bib.bib34)); Kantharaj
    et al. ([2022a](#bib.bib21)); Cheng et al. ([2023](#bib.bib7))。
- en: Meanwhile, large language models (LLMs) have demonstrated impressive generalization
    capabilities to unseen tasks through *in-context learning* and/or *instructional
    tuning*. With in-context learning, LLMs can perform a new task only by looking
    at few examples without making any gradient update on the task data Brown et al.
    ([2020](#bib.bib6)); Liu et al. ([2023a](#bib.bib29)), while instructional tuning
    aims to enhance the model’s instruction following capability by explicitly finetuning
    an LLM on large amount of multi-task instructional data Wei et al. ([2022a](#bib.bib47));
    Ouyang et al. ([2022](#bib.bib38)). Such generalization ability of LLMs is game
    changing compared to the predominant finetuning paradigm with two key advantages.
    First, it eliminates the need to train the model on each downstream task, which
    is highly resource consuming for LLMs. Second, such ability makes LM-as-a-service
    possible Sun et al. ([2022](#bib.bib45)), powering wide range of real world applications.
    Thus, there are emergent studies focusing on few-shot prompting for vision-language
    tasks Alayrac et al. ([2022](#bib.bib1)); Zhou et al. ([2022](#bib.bib50)); Najdenkoska
    et al. ([2023](#bib.bib37)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，大型语言模型（LLMs）通过*上下文学习*和/或*指令微调*展示了对未见任务的令人印象深刻的泛化能力。通过上下文学习，LLMs 可以仅通过查看少量示例来执行新任务，而无需对任务数据进行任何梯度更新
    Brown et al. ([2020](#bib.bib6)); Liu et al. ([2023a](#bib.bib29))，而指令微调旨在通过明确地在大量多任务指令数据上微调LLM来增强模型的指令跟随能力
    Wei et al. ([2022a](#bib.bib47)); Ouyang et al. ([2022](#bib.bib38))。LLMs 的这种泛化能力与主流的微调范式相比具有改变游戏规则的优势，主要体现在两个方面。首先，它消除了在每个下游任务上训练模型的需求，这对LLMs来说是非常耗费资源的。其次，这种能力使得作为服务的语言模型成为可能
    Sun et al. ([2022](#bib.bib45))，推动了广泛的现实世界应用。因此，出现了关注于视觉-语言任务的少样本提示的研究 Alayrac
    et al. ([2022](#bib.bib1)); Zhou et al. ([2022](#bib.bib50)); Najdenkoska et al.
    ([2023](#bib.bib37))。
- en: '![Refer to caption](img/06f65be8156b1556bcce7207100b3207.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/06f65be8156b1556bcce7207100b3207.png)'
- en: 'Figure 1: An overview of our proposed PromptChart prompting framework. The
    *Visual Data Table Generator* module is omitted for the tasks of Long-form Chart
    Question Answering and Chart Summarization.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：我们提出的PromptChart提示框架概述。*视觉数据表生成器*模块在长格式图表问答和图表总结任务中被省略。
- en: 'Despite these recent advances, there has not been any comprehensive work on
    how few-shot prompting can be effectively applied to chart comprehension and reasoning
    tasks. Liu et al. ([2022a](#bib.bib27)) present a one-shot method for ChartQA,
    which consists of two main steps: *(i)* extracting the data table from an input
    chart; *(ii)* constructing one-shot prompt to infer the output from an LLM. Nonetheless,
    this work only focuses on the one-shot setting and only one type of downstream
    task (i.e., factoid chart question answering). Moreover, it only uses the extracted
    data table to answer tasks without using visual features (e.g., colors, positions,
    and shapes of graphical marks) from the chart, which limits the model’s ability
    to perform visual reasoning. To our knowledge, there has not been any work that
    explores few-shot prompting for a diverse range of chart comprehension and reasoning
    tasks.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些近期的进展，尚未有关于如何有效应用少样本提示于图表理解和推理任务的全面研究。Liu et al. ([2022a](#bib.bib27)) 提出了一种用于
    ChartQA 的单样本方法，主要包括两个步骤：*(i)* 从输入图表中提取数据表；*(ii)* 构建单样本提示以从LLM中推断输出。然而，这项工作仅关注于单样本设置，并且仅针对一种下游任务（即事实图表问答）。此外，它仅使用提取的数据表来回答任务，而没有使用图表中的视觉特征（例如，图形标记的颜色、位置和形状），这限制了模型进行视觉推理的能力。据我们所知，尚无研究探索少样本提示在多种图表理解和推理任务中的应用。
- en: To bridge this gap, we take the first step to study few-shot prompting for chart-related
    tasks. We design PromptChart, a multimodal prompting framework consisting of three
    modules as shown in [Fig. 1](#S1.F1 "In 1 Introduction ‣ Do LLMs Work on Charts?
    Designing Few-Shot Prompts for Chart Question Answering and Summarization"). Our
    main contribution is the *Prompt Constructor* module, which aims to construct
    effective few-shot prompts. For each task, we focus on analyzing carefully its
    subcategories and experiment with different few-shot prompting setups to verify
    the necessity and effectiveness of each demonstration. We then define a set of
    attributes for each task to guide the prompt constructions. To effectively encode
    the visual information into the few-shot prompts, we propose *Visual Data Table
    Generator (VDTG)* module to generate the *visual data table* - a data table that
    includes visual information such as colors and positions of the chart’s labels.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了弥补这一差距，我们迈出了第一步，研究针对图表相关任务的少样本提示。我们设计了PromptChart，一个多模态提示框架，包含三个模块，如[图 1](#S1.F1
    "在 1 引言 ‣ LLMs 在图表上是否有效？为图表问答和总结设计少样本提示")所示。我们的主要贡献是*提示构造器*模块，旨在构造有效的少样本提示。针对每个任务，我们专注于仔细分析其子类别，并尝试不同的少样本提示设置，以验证每个示例的必要性和有效性。然后，我们为每个任务定义了一组属性，以指导提示构造。为了有效地将视觉信息编码到少样本提示中，我们提出了*视觉数据表生成器
    (VDTG)* 模块，用于生成*视觉数据表*——一个包含图表标签颜色和位置等视觉信息的数据表。
- en: 'We evaluate PromptChart on three different benchmarks: (1) Factoid QA with
    charts where the answer to a question is a short phrase; (2) Long-form Chart QA
    or LCQA where the answer is an explanatory text; (3) Chart summarization where
    the output is a summary of the chart. Compared with existing strong baselines,
    our framework achieves significant improvements in automatic metrics and human
    preferences across all downstream tasks, achieving state-of-the-art performance.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在三个不同的基准上评估了PromptChart：(1) 带有图表的事实问答，其中问题的答案是一个简短的短语；(2) 长文本图表问答或LCQA，其中答案是解释性文本；(3)
    图表总结，其中输出是对图表的总结。与现有的强基线相比，我们的框架在所有下游任务中的自动指标和人类偏好上都取得了显著改进，达到了最先进的性能。
- en: 2 Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Our work is mainly related to two lines of prior studies that we briefly describe
    here. An extended related work can be found in [Section A.1](#A1.SS1 "A.1 Extended
    Related Work ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization").
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作主要涉及两个相关的先前研究方向，下面我们将简要描述。有关扩展的相关工作，请参见[第 A.1 节](#A1.SS1 "A.1 扩展相关工作 ‣
    附录 A 附录 ‣ LLMs 在图表上是否有效？为图表问答和总结设计少样本提示")。
- en: 2.1 Chart QA and Summarization
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 图表问答和总结
- en: Recently, there has been growing interest in solving various chart-related downstream
    tasks. For example, the chart question answering (CQA) problem takes a question
    about a chart as input and produces the answer as output Hoque et al. ([2022](#bib.bib18)).
    Methani et al. ([2020](#bib.bib36)) and Masry et al. ([2022](#bib.bib34)) propose
    chart question answering benchmarks targeting factoid questions that require visual
    and arithmetic reasoning. Meanwhile, long-form chart question answering task (or
    open-ended CQA) Kantharaj et al. ([2022a](#bib.bib21)) requires an explanatory
    answer for each question by reasoning over the chart image. In addition, chart
    summarization task Kantharaj et al. ([2022b](#bib.bib22)) focuses on having a
    chart image as input and generating a natural language summary covering key insights
    from the chart. In this work, we verify the effectiveness of our proposed framework
    on the above three chart question answering and summarization tasks. We study
    these tasks because they require interactions between textual queries and chart
    images and also because there are adequate publicly available datasets for them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，解决各种图表相关下游任务的兴趣不断增加。例如，图表问答 (CQA) 问题将一个关于图表的问题作为输入，并产生答案作为输出 Hoque 等 ([2022](#bib.bib18))。Methani
    等 ([2020](#bib.bib36)) 和 Masry 等 ([2022](#bib.bib34)) 提出了针对需要视觉和算术推理的事实问题的图表问答基准。同时，长文本图表问答任务
    (或开放式 CQA) Kantharaj 等 ([2022a](#bib.bib21)) 需要对每个问题给出解释性答案，需对图表图像进行推理。此外，图表总结任务
    Kantharaj 等 ([2022b](#bib.bib22)) 侧重于将图表图像作为输入，生成涵盖图表关键见解的自然语言总结。在这项工作中，我们验证了所提出框架在上述三种图表问答和总结任务中的有效性。我们研究这些任务是因为它们需要文本查询与图表图像之间的互动，并且它们有足够的公开数据集可供使用。
- en: 2.2 Prompting
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 提示
- en: With the scaling of model sizes Devlin et al. ([2019](#bib.bib14)); Radford
    et al. ([2019](#bib.bib42)); Brown et al. ([2020](#bib.bib6)); Chowdhery et al.
    ([2022](#bib.bib10)), large language models (LLMs) have demonstrated strong capabilities
    in solving multiple NLP downstream tasks only by conditioning on the input prompt
    which contains a few demonstrations (a.k.a., few-shot prompting). Such paradigms
    of prompting LLMs are called prompt-based learning or in-context learning Liu
    et al. ([2023a](#bib.bib29)); Beltagy et al. ([2022](#bib.bib3)). This line of
    research has attracted great attention from the research community to solve downstream
    tasks including vision-language tasks Alayrac et al. ([2022](#bib.bib1)); Zhou
    et al. ([2022](#bib.bib50)); Najdenkoska et al. ([2023](#bib.bib37)). However,
    exploring how chart-related downstream tasks could benefit from the above techniques
    has received limited attention. Recently, Liu et al. ([2022a](#bib.bib27)) propose
    the first one-shot reasoning framework for chart question answering based on PaLM
    Chowdhery et al. ([2022](#bib.bib10)). Nonetheless, this framework suffers from
    several limitations as discussed in [Section 1](#S1 "1 Introduction ‣ Do LLMs
    Work on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization").
    On the contrary, our study framework PromptChart overcomes these limitations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型规模的扩大，Devlin 等人 ([2019](#bib.bib14))；Radford 等人 ([2019](#bib.bib42))；Brown
    等人 ([2020](#bib.bib6))；Chowdhery 等人 ([2022](#bib.bib10))，大型语言模型（LLMs）仅通过在包含少量示例的输入提示上进行条件设定，就展示了在解决多个
    NLP 下游任务中的强大能力（即少量示例提示）。这种提示 LLM 的范式称为基于提示的学习或上下文学习 Liu 等人 ([2023a](#bib.bib29))；Beltagy
    等人 ([2022](#bib.bib3))。这条研究线吸引了研究界的广泛关注，旨在解决包括视觉-语言任务在内的下游任务 Alayrac 等人 ([2022](#bib.bib1))；Zhou
    等人 ([2022](#bib.bib50))；Najdenkoska 等人 ([2023](#bib.bib37))。然而，探讨图表相关下游任务如何从上述技术中受益的研究仍然有限。最近，Liu
    等人 ([2022a](#bib.bib27)) 提出了基于 PaLM Chowdhery 等人 ([2022](#bib.bib10)) 的第一个一-shot
    推理框架用于图表问答。然而，这一框架存在一些限制，如[第 1 节](#S1 "1 引言 ‣ 大型语言模型能处理图表吗？设计少量示例提示以进行图表问答和总结")中所讨论的。相比之下，我们的研究框架
    PromptChart 克服了这些限制。
- en: 3 Problem Formulation
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 问题表述
- en: $\bullet$ Problem Definition
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$ 问题定义
- en: 'We focus on three chart-related tasks: factoid chart QA (FCQA), long-from chart
    QA (LCQA) and chart summarization (CS). A sample in FCQA can be expressed as $(C,D,Q,A)$
    as output.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注三项图表相关任务：事实性图表问答（FCQA）、长文本图表问答（LCQA）和图表总结（CS）。FCQA 中的一个示例可以表示为 $(C,D,Q,A)$
    作为输出。
- en: '| Datasets | Type | #Charts/#QA pairs |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类型 | #图表/#问答对 |'
- en: '| ChartQA | Factoid CQA | 21.1K/32.7K |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| ChartQA | 事实性问答 | 21.1K/32.7K |'
- en: '| OpenCQA | Long-form CQA | 7.7K/7.7K |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| OpenCQA | 长文本问答 | 7.7K/7.7K |'
- en: '| Chart-to-Text | Chart Summarization | 44K/44K |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Chart-to-Text | 图表总结 | 44K/44K |'
- en: 'Table 1: Statistics of the downstream benchmarks.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：下游基准的统计数据。
- en: $\bullet$ Benchmarks
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$ 基准
- en: We choose ChartQA Masry et al. ([2022](#bib.bib34)) – a benchmark which contains
    factoid chart question-answer pairs with visual and logical reasoning, OpenCQA
    Kantharaj et al. ([2022a](#bib.bib21)) – another QA benchmark where the answers
    are explanatory descriptions, Chart-to-Text Kantharaj et al. ([2022b](#bib.bib22))
    – a benchmark for chart summarization, as the FCQA, LCQA, CS benchmarks respectively
    to study. For Chart-to-Text, it consists of two datasets, referred to as Pew and
    Statista. The statistics of the benchmarks are presented in [Table 1](#S3.T1 "In
    ∙ Problem Definition ‣ 3 Problem Formulation ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization").
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了 ChartQA Masry 等人 ([2022](#bib.bib34)) – 一个包含事实性图表问答对的基准，涉及视觉和逻辑推理，OpenCQA
    Kantharaj 等人 ([2022a](#bib.bib21)) – 另一个问答基准，其中答案是解释性描述，Chart-to-Text Kantharaj
    等人 ([2022b](#bib.bib22)) – 一个图表总结的基准，作为 FCQA、LCQA 和 CS 基准分别进行研究。对于 Chart-to-Text，它包含两个数据集，分别称为
    Pew 和 Statista。基准的统计数据见[表 1](#S3.T1 "在 ∙ 问题定义 ‣ 3 问题表述 ‣ 大型语言模型能处理图表吗？设计少量示例提示以进行图表问答和总结")。
- en: 4 Methodology
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 方法论
- en: '[Fig. 1](#S1.F1 "In 1 Introduction ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization") shows our prompting framework
    PromptChart, consisting of three modules: *(i) Prompt Constructor (PC)*; *(ii)
    Visual Data Table Generator (VDTG)*; *(iii) InstructGPT* Ouyang et al. ([2022](#bib.bib38)).
    In the case of FCQA, the chart image $C$ are input to the PC module to construct
    the prompt without going through the VDTG module. We present the details of each
    module one by one below.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1](#S1.F1 "在 1 介绍 ‣ LLM 是否能处理图表？为图表问答和总结设计的少样本提示") 展示了我们的提示框架 PromptChart，由三个模块组成：*(i)
    提示构造器（PC）*；*(ii) 视觉数据表生成器（VDTG）*；*(iii) InstructGPT* Ouyang 等人 ([2022](#bib.bib38))。在
    FCQA 的情况下，图表图像 $C$ 输入到 PC 模块中以构建提示，而无需经过 VDTG 模块。我们将逐一介绍每个模块的细节。'
- en: 4.1 Prompt Constructor (PC)
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 提示构造器（PC）
- en: For each task, the prompt constructor module constructs the prompts to query
    the LLM. Liu et al. ([2022a](#bib.bib27)) only use a one-shot prompt without conducting
    a detailed task-prompt analysis. We argue that task-prompt analysis is critical
    because it helps to identify the necessary demonstrations for each prompt to maximize
    the LLM’s performance. To achieve this, we thoroughly analyze the task and propose
    a set of guidelines for prompt construction.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个任务，提示构造模块会构建提示以查询 LLM。Liu 等人 ([2022a](#bib.bib27)) 仅使用一次性提示，而未进行详细的任务提示分析。我们认为任务提示分析至关重要，因为它有助于确定每个提示所需的演示，以最大化
    LLM 的性能。为此，我们彻底分析了任务，并提出了一套提示构造的指南。
- en: $\bullet$
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Factoid Chart Question Answering (FCQA) Inspired by Chain-of-Thought Wei et al.
    ([2022b](#bib.bib48)), we propose *chain of chart reasoning (CCR)*, a prompting
    strategy for FCQA. We categorize the task in FCQA into $9$ subcategories outlined
    in [Table 2](#S4.T2 "In ∙ ‣ 4.1 Prompt Constructor (PC) ‣ 4 Methodology ‣ Do LLMs
    Work on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization")
    and design a CCR prompt format specifically for each. Our CCR formats satisfy
    two main properties. Firstly, the formats describe clearly the reasoning process
    step by step, leading to the final answer for each query. Secondly, the elements
    in the CCR (operands, operators, visual attributes) need to be well-specified
    with clear relationships. Here, visual attributes include colors (e.g., ‘red’,
    ‘green’) and positions (e.g., ‘left’, ‘right’) of marks (e.g., bars and lines).
    We follow these guidelines to carefully handcraft our prompt consisting of 6 demonstrations
    which are samples from ChartQA Masry et al. ([2022](#bib.bib34)). We show an example
    below:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 受 Chain-of-Thought Wei 等人 ([2022b](#bib.bib48)) 启发，我们提出了 *图表推理链（CCR）*，这是一种针对
    FCQA 的提示策略。我们将 FCQA 任务分为 [表2](#S4.T2 "在 ∙ ‣ 4.1 提示构造器（PC） ‣ 4 方法 ‣ LLM 是否能处理图表？为图表问答和总结设计的少样本提示")
    中概述的 $9$ 个子类别，并为每个子类别设计了专门的 CCR 提示格式。我们的 CCR 格式满足两个主要属性。首先，格式清楚地描述了逐步推理过程，得出每个查询的最终答案。其次，CCR
    中的元素（操作数、运算符、视觉属性）需要明确指定并具有清晰的关系。这里，视觉属性包括颜色（例如，“红色”、“绿色”）和标记的位置（例如，“左”，“右”）（例如，条形图和线条）。我们遵循这些指南，精心制作了由
    ChartQA Masry 等人 ([2022](#bib.bib34)) 提供的 6 个示例构成的提示。以下是一个示例：
- en: 'Question: Is the average value of Andean Latin America and Cambodia more than
    the value of Thailand?'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：安第斯拉丁美洲和柬埔寨的平均值是否大于泰国的值？
- en: CCR:*"The value of Andean Latin America is 1.47 and the value of Cambodia is
    0.77. So the average value of Andean Latin America and Cambodia is ( 1.47 + 0.77
    ) / 2 = 1.12. The value of Thailand is 0.39. Since 1.12 > 0.39, the average value
    of Andean Latin America and Cambodia is more than the value of Thailand. The answer
    is Yes"*
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: CCR:*“安第斯拉丁美洲的值为1.47，柬埔寨的值为0.77。因此，安第斯拉丁美洲和柬埔寨的平均值为（1.47 + 0.77）/ 2 = 1.12。泰国的值为0.39。由于1.12
    > 0.39，所以安第斯拉丁美洲和柬埔寨的平均值大于泰国的值。答案是‘是’”*
- en: We present all $6$ demonstrations in [Table 6](#A1.T6 "In A.3 FCQA Prompt ‣
    Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for
    Chart Question Answering and Summarization"), and discuss their details in [Section 6.1](#S6.SS1
    "6.1 Demonstration Selection for FCQA ‣ 6 Discussion ‣ Do LLMs Work on Charts?
    Designing Few-Shot Prompts for Chart Question Answering and Summarization").
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[表6](#A1.T6 "在 A.3 FCQA 提示 ‣ 附录 A 附录 ‣ LLM 是否能处理图表？为图表问答和总结设计的少样本提示")中展示了所有
    $6$ 个示例，并在[第6.1节](#S6.SS1 "6.1 FCQA 示范选择 ‣ 6 讨论 ‣ LLM 是否能处理图表？为图表问答和总结设计的少样本提示")中讨论了它们的详细信息。
- en: '| Tasks | Specifics - Supportive Case | Chain of Chart Reasoning (CCR) Prompt
    Format |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 细节 - 支持性案例 | 图表推理链（CCR）提示格式 |'
- en: '|  | Visual Retrieval (Color & Position) - Case 1 | *No demonstration needed*
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | 视觉检索（颜色与位置） - 案例 1 | *无需演示* |'
- en: '| Retrieval | Numerical Retrieval - Case 2 | *No demonstration needed* |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 检索 | 数值检索 - 案例 2 | *无需演示* |'
- en: '|  | Compositional Retrieval - Case 3 | *No demonstration needed* |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | 组合检索 - 案例 3 | *无需演示* |'
- en: '|  | Complex Retrieval - Case 9 | operands with visual attributes, operands
    without visual attributes, reasoning, result. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | 复杂检索 - 案例 9 | 具有视觉属性的操作数、没有视觉属性的操作数、推理、结果。 |'
- en: '|  | Add & Subtraction - Case 4 | operands without visual attributes, operators,
    reasoning, result. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | 加法与减法 - 案例 4 | 没有视觉属性的操作数、运算符、推理、结果。 |'
- en: '|  | Division & Multiplication - Case 5 | operands without visual attributes,
    operators, reasoning, result. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | 除法与乘法 - 案例 5 | 没有视觉属性的操作数、运算符、推理、结果。 |'
- en: '| Reasoning | Visual Reasoning - Case 6 | operands with visual attributes,
    operators, reasoning, result. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 推理 | 视觉推理 - 案例 6 | 具有视觉属性的操作数、运算符、推理、结果。 |'
- en: '|  | Compositional Reasoning - Case 7 | operands with visual attributes, operands
    without visual attributes, operators, reasoning, result. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | 组合推理 - 案例 7 | 具有视觉属性的操作数、没有视觉属性的操作数、运算符、推理、结果。'
- en: '| Boolean | All types of reasoning - Case 8 | operands with visual attributes,
    operands without visual attributes, operators, reasoning, result. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 布尔 | 所有类型的推理 - 案例 8 | 具有视觉属性的操作数、没有视觉属性的操作数、运算符、推理、结果。 |'
- en: 'Table 2: Task types and prompt format for factoid chart question answering.
    Supportive cases are illustrated in [Fig. 2](#S6.F2 "In 6.1 Demonstration Selection
    for FCQA ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for
    Chart Question Answering and Summarization"). Each element in the CCR is colored
    uniquely.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：事实图表问答的任务类型和提示格式。支持性案例在[图 2](#S6.F2 "在 6.1 演示选择用于FCQA ‣ 6 讨论 ‣ LLM 是否适用于图表？设计图表问答和总结的少样本提示")中说明。CCR中的每个元素具有独特的颜色。
- en: $\bullet$
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Long-form Chart Question Answering (LCQA) Similar to FCQA, our goal is to build
    a prompt consisting of demonstrations that represent most of the available long-form
    chart QA pairs. We adhere to the following three principles while designing the
    prompt for the LCQA task: (i) Descriptive answer to each question in the prompt
    should be focused and informative enough, i.e., should not be too long and beyond
    the scope of the question or too short and unable to capture the full extent of
    the answer. (ii) the prompt should cover the different QA pair types. (iii) If
    the LLM is inferred to generate an answer for a question that is in the prompt,
    that generated answer must be as close as the answer given in the prompt. This
    property ensures that the model does not hallucinate when answering the questions
    that it is instructed from the demonstrations, leading towards more factually-correct
    generations.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 长格式图表问答（LCQA）与FCQA类似，我们的目标是构建一个由大多数可用的长格式图表QA对组成的提示。在设计LCQA任务的提示时，我们遵循以下三个原则：（i）提示中的每个问题的描述性答案应该集中且足够信息丰富，即不应过长而超出问题范围，也不应过短而无法捕捉到答案的全部内容。（ii）提示应涵盖不同的QA对类型。（iii）如果LLM被推断生成提示中问题的答案，则生成的答案必须尽可能接近提示中给出的答案。这一特性确保了模型在回答从演示中获取的问题时不会出现幻想，促使生成的内容更加事实准确。
- en: We carefully select our prompt having a total of 6 demonstrations from OpenCQA
    Kantharaj et al. ([2022a](#bib.bib21)). Among them, 2 questions are *Describe
    and Summary*, i.e., questions asking to describe or summarize the chart based
    on statistical properties such as describing data distribution, outliers, and
    trends, 2 are *Comparative* i.e., questions asking to compare the specified items
    in the chart, and 2 are *Discover*, questions asking to derive key insights or
    findings from the chart. All the demonstrations are shown in [Table 7](#A1.T7
    "In A.4 LCQA Prompt ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization") with details
    in [Section 6.2](#S6.SS2 "6.2 Best Number of Demonstrations for LCQA and CS Task
    ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart
    Question Answering and Summarization").
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仔细选择了来自 OpenCQA Kantharaj 等人 ([2022a](#bib.bib21)) 的总共 6 个示例。其中 2 个问题是*描述和总结*，即要求根据统计属性描述或总结图表的问题，如描述数据分布、异常值和趋势；2
    个是*比较性*，即要求比较图表中指定项的问题；2 个是*发现*，要求从图表中提取关键见解或发现的问题。所有示例都显示在[表 7](#A1.T7 "在 A.4
    LCQA 提示 ‣ 附录 A 附录 ‣ 大型语言模型是否适用于图表？设计少量示例提示用于图表问答和总结")中，详细信息见[第 6.2 节](#S6.SS2
    "6.2 LCQA 和 CS 任务的最佳示例数量 ‣ 6 讨论 ‣ 大型语言模型是否适用于图表？设计少量示例提示用于图表问答和总结")。
- en: $\bullet$
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Chart Summarization (CS) Except design principle (i), the other two principles
    of LCQA are applicable to chart summarization. Specifically, the prompt should
    cover different summarization types (e.g., comparative, descriptive, reasoning)
    and the LLM should not hallucinate on demonstrations. We select 3 demonstrations
    from the Pew dataset and 3 demonstrations for the Statista dataset of Chart-to-Text
    Kantharaj et al. ([2022b](#bib.bib22)). [Table 8](#A1.T8 "In A.5 Chart Summarization
    Prompt ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts
    for Chart Question Answering and Summarization") presents all the demonstrations,
    which contains examples of three summary types: *Perceptual and Cognitive* (e.g.,
    cause and effect, trends), *Statistical and Comparative* (e.g., min, max, higher,
    smaller), and *Visual Encoding* (relating to visual information such as colors
    and positions).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图表总结（CS）除了设计原则（i）之外，LCQA 的其他两个原则适用于图表总结。具体来说，提示应涵盖不同的总结类型（例如，比较性、描述性、推理性），并且
    LLM 不应在演示中出现幻觉。我们从 Pew 数据集中选择了 3 个示例，并从 Chart-to-Text Kantharaj 等人 ([2022b](#bib.bib22))
    的 Statista 数据集中选择了 3 个示例。 [表 8](#A1.T8 "在 A.5 图表总结提示 ‣ 附录 A 附录 ‣ 大型语言模型是否适用于图表？设计少量示例提示用于图表问答和总结")
    展示了所有示例，其中包含三种总结类型的示例：*感知与认知*（例如，因果关系，趋势）、*统计与比较*（例如，最小值、最大值、更高、更低）和*视觉编码*（涉及颜色和位置等视觉信息）。
- en: 4.2 Visual Data Table Generator (VDTG)
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 视觉数据表生成器（VDTG）
- en: 'Prior work Liu et al. ([2022a](#bib.bib27)) only considers the data table without
    any visual information from the chart, which makes the task of chart QA lose its
    visual nature. To study how the visual information affects the model performance
    in few-shot prompting, we introduce the VDTG module to construct *visual data
    table*, a representation integrating the usual data table with visual attributes
    of the marks ([Fig. 4](#A1.F4 "In A.6 Visual Data Table Generator (VDTG) ‣ Appendix
    A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question
    Answering and Summarization")). Given a chart image, the VDTG module is trained
    to generate a visual data table with two properties: (i) it has the associated
    colors (in natural language) of the rows/columns’ labels; (ii) the rows and columns
    of the chart are sorted in their appearing positions in the chart.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的工作 Liu 等人 ([2022a](#bib.bib27)) 仅考虑了数据表而没有图表中的任何视觉信息，这使得图表 QA 任务失去了视觉特性。为了研究视觉信息如何影响模型在少量示例提示中的表现，我们引入了
    VDTG 模块来构建*视觉数据表*，一种将通常的数据表与标记的视觉属性（[图 4](#A1.F4 "在 A.6 视觉数据表生成器 (VDTG) ‣ 附录 A
    附录 ‣ 大型语言模型是否适用于图表？设计少量示例提示用于图表问答和总结")）整合的表示。给定一个图表图像，VDTG 模块被训练生成一个具有两个特性的视觉数据表：（i）它具有行/列标签的相关颜色（以自然语言表示）；（ii）图表的行和列按照它们在图表中的出现位置排序。
- en: We construct the training dataset for VDTG module from the *full version* of
    ChartQA at Github¹¹1https://github.com/vis-nlp/ChartQA. To create the ground-truth
    visual data table for each chart image, we first create *sorted data table* by
    collecting all the texts and coordinators of the bounding boxes of the chart and
    sorting them by the x-axis values and y-axis values. We also collect all the colors
    of the charts’ data marks (e.g., bars and lines) by parsing their original SVG
    files. Since those colors are in hexadecimal format, we convert them into natural
    language colors by mapping them with the name of its closest color in webcolors²²2https://pypi.org/project/webcolors/
    using a KDTree Bentley ([1975](#bib.bib5)). Still, we have noticed some hexadecimal
    codes are not present in the webcolors set, so we decided to manually check 300
    random visual data tables and added 80 new mappings {hex, color name} to the set.
    Moreover, we remove the charts whose bounding boxes information is not fully provided.
    Overall, we obtain a total of 18,317 training samples and 1,056 validation samples.
    We fine-tune UniChart Masry et al. ([2023](#bib.bib33)) on our constructed dataset,
    a SoTA Chart-to-Table model, to generate the visual data tables. It is worth noting
    that this module is chart-type agnostic. Naturally, since it is trained on ChartQA,
    it supports the available chart types in ChartQA, including a variety of bar charts,
    line charts, and pie charts. The details of our training and inference for this
    module are in [Section A.2](#A1.SS2 "A.2 VDTG Training Details ‣ Appendix A Appendices
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization").
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 Github¹¹1https://github.com/vis-nlp/ChartQA 的*完整版本*中构建了 VDTG 模块的训练数据集。为了为每个图表图像创建真实的视觉数据表，我们首先通过收集图表的所有文本和边界框的坐标，并按照
    x 轴值和 y 轴值对其进行排序，来创建*排序数据表*。我们还通过解析其原始 SVG 文件收集了图表数据标记（例如条形图和折线图）的所有颜色。由于这些颜色是十六进制格式的，我们通过将它们与
    webcolors²²2https://pypi.org/project/webcolors/ 中最接近的颜色名称进行映射，使用 KDTree Bentley
    ([1975](#bib.bib5)) 将其转换为自然语言颜色。然而，我们注意到一些十六进制代码在 webcolors 集合中不存在，因此我们决定手动检查
    300 个随机视觉数据表，并向集合中添加了 80 个新的映射 {hex, color name}。此外，我们删除了边界框信息未完全提供的图表。总体而言，我们获得了总共
    18,317 个训练样本和 1,056 个验证样本。我们在构建的数据集上微调了 UniChart Masry et al. ([2023](#bib.bib33))，这是一种
    SoTA Chart-to-Table 模型，以生成视觉数据表。值得注意的是，这个模块是与图表类型无关的。由于它是基于 ChartQA 进行训练的，因此它支持
    ChartQA 中的所有图表类型，包括各种条形图、折线图和饼图。有关该模块的训练和推理的详细信息请参见[第 A.2 节](#A1.SS2 "A.2 VDTG
    训练细节 ‣ 附录 A 附录 ‣ 大型语言模型在图表上是否有效？设计少样本提示以进行图表问答和总结")。
- en: 4.3 InstructGPT
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 InstructGPT
- en: We use the frozen InstructGPT Ouyang et al. ([2022](#bib.bib38)) as our LLM,
    which is based on GPT-3 Brown et al. ([2020](#bib.bib6)) and has been fine-tuned
    on natural human written instructions. Note that other LLMs such as ChatGPT can
    also be directly used.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了冻结的 InstructGPT Ouyang et al. ([2022](#bib.bib38)) 作为我们的 LLM，它基于 GPT-3
    Brown et al. ([2020](#bib.bib6)) 并经过自然语言书写指令的微调。请注意，其他 LLM，例如 ChatGPT，也可以直接使用。
- en: 5 Experiments
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 5.1 QA and Summarization Experiments
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 QA 和总结实验
- en: '$\bullet$ streams of baselines. The *first stream* consists of *Models with
    fine-tuning strategies*, which can be further categorized into two subcategories:
    (a) models that take the chart image as input such as Pix2Struct Lee et al. ([2022](#bib.bib25))
    - the state-of-the-art visually-situated language model, MatCha Liu et al. ([2022b](#bib.bib28)),
    and UniChart Masry et al. ([2023](#bib.bib33)) - the state-of-the-art chart pretraining
    model; and (b) models that take the data table as input such as VisionTapas Masry
    et al. ([2022](#bib.bib34)) - the original state-of-the-art vision-language model
    on ChartQA, VL-T5 Cho et al. ([2021](#bib.bib8)) - the state-of-the-art model
    on OpenCQA, T5 Raffel et al. ([2020](#bib.bib43)) a competitive text generation
    model on the chart summarization task as reported by Kantharaj et al. ([2022b](#bib.bib22)).
    The *second stream* consists of *Large language models with data tables provided*:
    FlanT5-xxl Chung et al. ([2022](#bib.bib11)) - an instructions-fine-tuned large
    language model achieving impressive few-shot results on many NLP tasks, PAL Gao
    et al. ([2022](#bib.bib16)) - the state-of-the-art few-shot code-based reasoning
    model on the GSM8K benchmark Cobbe et al. ([2021](#bib.bib12)). The *third stream*
    comprises *Large language models without data tables provided*: DePlot + FlanPaLM
    Liu et al. ([2022a](#bib.bib27)) - the state-of-the-art factoid chart question
    answering model.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 基线流。*第一个流* 包括 *具有微调策略的模型*，可进一步分为两类：（a）以图表图像为输入的模型，如 Pix2Struct Lee
    等 ([2022](#bib.bib25)) - 最先进的视觉语言模型，MatCha Liu 等 ([2022b](#bib.bib28)) 和 UniChart
    Masry 等 ([2023](#bib.bib33)) - 最先进的图表预训练模型；（b）以数据表为输入的模型，如 VisionTapas Masry 等
    ([2022](#bib.bib34)) - 最初的最先进的视觉语言模型在 ChartQA 上，VL-T5 Cho 等 ([2021](#bib.bib8))
    - 最先进的模型在 OpenCQA 上，T5 Raffel 等 ([2020](#bib.bib43)) 是 Kantharaj 等 ([2022b](#bib.bib22))
    报告的图表摘要任务中的竞争性文本生成模型。*第二个流* 包括 *提供数据表的大型语言模型*：FlanT5-xxl Chung 等 ([2022](#bib.bib11))
    - 一种通过指令微调的大型语言模型，在许多 NLP 任务上取得了令人印象深刻的少量学习结果，PAL Gao 等 ([2022](#bib.bib16)) -
    最先进的少量学习基于代码的推理模型，在 GSM8K 基准测试 Cobbe 等 ([2021](#bib.bib12)) 上。*第三个流* 包括 *未提供数据表的大型语言模型*：DePlot
    + FlanPaLM Liu 等 ([2022a](#bib.bib27)) - 最先进的事实图表问答模型。
- en: For the FCQA task, we select Pix2Struct, MatCha, DePlot, PAL, FlanT5-xxl as
    the five baselines. We adopt FlanT5-xxl and VL-T5 as the two baselines for the
    LCQA task. For the CS task, we compare our model with FlanT5-xxl and T5.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 FCQA 任务，我们选择了 Pix2Struct、MatCha、DePlot、PAL、FlanT5-xxl 作为五个基线。我们将 FlanT5-xxl
    和 VL-T5 作为 LCQA 任务的两个基线。对于 CS 任务，我们将我们的模型与 FlanT5-xxl 和 T5 进行比较。
- en: $\bullet$
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Inference InstructGPT model is called for the inference through OpenAI API being
    *text-davinci-003* in April 2023\. We utilize Nucleus Sampling Holtzman et al.
    ([2020](#bib.bib17)) as our decoding strategy with a temperature value of 0.7,
    a max_tokens value of 256, and a top_p value of 0.9 as our decoding hyper-parameters.
    The frequency_penalty and presence_penalty are set to 0.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 推理 InstructGPT 模型通过 OpenAI API 进行推理，*text-davinci-003* 于 2023 年 4 月。我们采用 Nucleus
    Sampling Holtzman 等 ([2020](#bib.bib17)) 作为解码策略，温度值为 0.7，max_tokens 值为 256，top_p
    值为 0.9 作为解码超参数。frequency_penalty 和 presence_penalty 设置为 0。
- en: $\bullet$
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Automatic Evaluation & Human Preferences For text generation tasks, prior works
    Belz and Reiter ([2006](#bib.bib4)); Tan et al. ([2015](#bib.bib46)); Liu et al.
    ([2023b](#bib.bib31)) discuss that n-gram reference-based evaluation metrics for
    text generation tasks such as BLEU Papineni et al. ([2002](#bib.bib39)) and ROUGE
    Lin ([2004](#bib.bib26)) may have a relatively low correlation with human judgments
    and generated texts with very high scores can have a poor quality Smith et al.
    ([2016](#bib.bib44)); Kann et al. ([2018](#bib.bib20)); Mathur et al. ([2020](#bib.bib35))
    . Therefore, we focus on evaluating the factual correctness of the models for
    LCQA and CS tasks. In particular, we use *QAFactEval* Fabbri et al. ([2022](#bib.bib15))
    (by averaging all its criteria), a QA-based metric that computes a factual score
    based on the ability of a QA model to answer questions generated from the input,
    given the generated text. We further follow Ouyang et al. ([2022](#bib.bib38))
    to conduct *human preferences* to evaluate the performance of models. Specifically,
    for each dataset, we randomly select $300$ samples. We hire three annotators who
    are English native speakers and collect the generated outputs of these samples
    from the best-performing baseline (which is not a variant of our model) and PromptChart.
    We then ask the annotators to rate which one they prefer, or it is a tier. The
    annotators’ agreements are measured by Kripp.’s alpha Krippendorff ([2011](#bib.bib24)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 自动评估与人类偏好 对于文本生成任务，先前的研究 Belz 和 Reiter（[2006](#bib.bib4)）；Tan 等人（[2015](#bib.bib46)）；Liu
    等人（[2023b](#bib.bib31)）讨论了基于 n-gram 参考的评估指标，如 BLEU Papineni 等人（[2002](#bib.bib39)）和
    ROUGE Lin（[2004](#bib.bib26)），在文本生成任务中的相关性可能相对较低，并且生成得分非常高的文本可能质量较差 Smith 等人（[2016](#bib.bib44)）；Kann
    等人（[2018](#bib.bib20)）；Mathur 等人（[2020](#bib.bib35)）。因此，我们重点评估模型在 LCQA 和 CS 任务中的事实正确性。具体而言，我们使用
    *QAFactEval* Fabbri 等人（[2022](#bib.bib15)）（通过平均所有标准），这是一个基于 QA 的指标，根据 QA 模型回答从输入生成的问题的能力来计算事实分数。我们进一步遵循
    Ouyang 等人（[2022](#bib.bib38)）进行 *人类偏好* 评估模型的表现。具体而言，对于每个数据集，我们随机选择 $300$ 个样本。我们聘请三位母语为英语的标注员，并收集来自表现最佳基线（不是我们模型的变体）和
    PromptChart 的这些样本的生成输出。然后，我们要求标注员评估他们更喜欢哪个，或者它是一个等级。标注员的意见一致性通过 Kripp.'s alpha
    Krippendorff（[2011](#bib.bib24)）来衡量。
- en: $\bullet$ Zero- and Few-shot Settings
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$ 零样本和少样本设置
- en: For zero-shot, we follow Kojima et al. ([2022](#bib.bib23)) to prompt the InstructGPT
    model to generate the textual outputs step by step. Specifically, we use "Answer
    the following question step by step." as the FCQA instruction and "Answer the
    following question step by step by a single paragraph." as the LCQA instruction.
    For the CS task, the instruction is "Summarize the trends in the chart step by
    step and write the summary.". The full sets of few-shot demonstrations for FCQA,
    LCQA, CS tasks are provided in [Table 6](#A1.T6 "In A.3 FCQA Prompt ‣ Appendix
    A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question
    Answering and Summarization"), [Table 7](#A1.T7 "In A.4 LCQA Prompt ‣ Appendix
    A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question
    Answering and Summarization"), [Table 8](#A1.T8 "In A.5 Chart Summarization Prompt
    ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for
    Chart Question Answering and Summarization") respectively.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于零样本，我们遵循 Kojima 等人（[2022](#bib.bib23)）的方法，逐步提示 InstructGPT 模型生成文本输出。具体而言，我们使用“逐步回答以下问题。”作为
    FCQA 指令，“通过一个段落逐步回答以下问题。”作为 LCQA 指令。对于 CS 任务，指令是“逐步总结图表中的趋势并撰写总结。” FCQA、LCQA 和
    CS 任务的完整少样本演示集分别提供在 [表 6](#A1.T6 "在 A.3 FCQA 提示 ‣ 附录 A 附录 ‣ LLMs 是否能处理图表？为图表问答和总结设计少样本提示")、[表
    7](#A1.T7 "在 A.4 LCQA 提示 ‣ 附录 A 附录 ‣ LLMs 是否能处理图表？为图表问答和总结设计少样本提示")、[表 8](#A1.T8
    "在 A.5 图表总结提示 ‣ 附录 A 附录 ‣ LLMs 是否能处理图表？为图表问答和总结设计少样本提示")。
- en: '| Model | Gold table? | Mode | ChartQA |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 黄金表？ | 模式 | ChartQA |'
- en: '|  |  | Aug. | Human | Avg. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 八月 | 人类 | 平均 |'
- en: '| T5 | Yes | fine-tuned | 56.96 | 25.12 | 41.04 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| T5 | 是 | 微调 | 56.96 | 25.12 | 41.04 |'
- en: '| VLT5 | Yes | fine-tuned | 56.88 | 26.24 | 41.56 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| VLT5 | 是 | 微调 | 56.88 | 26.24 | 41.56 |'
- en: '| VisionTapas | Yes | fine-tuned | 61.44 | 29.60 | 45.52 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| VisionTapas | 是 | 微调 | 61.44 | 29.60 | 45.52 |'
- en: '| Pix2Struct | No | fine-tuned | 81.60 | 30.5 | 56.0 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Pix2Struct | 否 | 微调 | 81.60 | 30.5 | 56.0 |'
- en: '| MatCha | No | fine-tuned | 90.2 | 38.02 | 64.2 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| MatCha | 否 | 微调 | 90.2 | 38.02 | 64.2 |'
- en: '| UniChart | No | fine-tuned | 88.56 | 43.92 | 66.24 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| UniChart | 否 | 微调 | 88.56 | 43.92 | 66.24 |'
- en: '| FlanT5-xxl | Yes | zero-shot | 63.84 | 27.84 | 45.84 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| FlanT5-xxl | Yes | zero-shot | 63.84 | 27.84 | 45.84 |'
- en: '| PAL | Yes | zero-shot | 80.88 | 42.77 | 61.83 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| PAL | Yes | zero-shot | 80.88 | 42.77 | 61.83 |'
- en: '| InstructGPT | Yes | zero-shot | 62.24 | 40.96 | 51.60 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| InstructGPT | Yes | zero-shot | 62.24 | 40.96 | 51.60 |'
- en: '| DePlot + Inst. + CCR | No | zero-shot | 78.64 | 45.78 | 62.21 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| DePlot + Inst. + CCR | No | zero-shot | 78.64 | 45.78 | 62.21 |'
- en: '| UniChart + Inst. + CCR | No | zero-shot | 79.76 | 46.67 | 63.28 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| UniChart + Inst. + CCR | No | zero-shot | 79.76 | 46.67 | 63.28 |'
- en: '| PromptChart | No | zero-shot | 79.44 | 47.11 | 63.1 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | No | zero-shot | 79.44 | 47.11 | 63.1 |'
- en: '| DePlot + GPT-3 + CoT | No | one-shot | 37.3 | 36.5 | 36.9 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| DePlot + GPT-3 + CoT | No | one-shot | 37.3 | 36.5 | 36.9 |'
- en: '| DePlot + FlanPaLM + CoT | No | one-shot | 76.7 | 57.8 | 67.3 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| DePlot + FlanPaLM + CoT | No | one-shot | 76.7 | 57.8 | 67.3 |'
- en: '| FlanT5-xxl | Yes | few-shot | 64.56 | 28.56 | 46.56 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| FlanT5-xxl | Yes | few-shot | 64.56 | 28.56 | 46.56 |'
- en: '| PAL | Yes | few-shot | 0.00 | 0.16 | 0.08 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| PAL | Yes | few-shot | 0.00 | 0.16 | 0.08 |'
- en: '| InstructGPT | Yes | few-shot | 75.12 | 49.52 | 62.32 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| InstructGPT | Yes | few-shot | 75.12 | 49.52 | 62.32 |'
- en: '| DePlot + Inst. + CCR | No | few-shot | 80.28 | 60.49 | 70.39 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| DePlot + Inst. + CCR | No | few-shot | 80.28 | 60.49 | 70.39 |'
- en: '| UniChart + Inst. + CCR | No | few-shot | 81.68 | 62.24 | 71.96 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| UniChart + Inst. + CCR | No | few-shot | 81.68 | 62.24 | 71.96 |'
- en: '| PromptChart | No | few-shot | 81.44 | 63.2 | 72.32 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | No | few-shot | 81.44 | 63.2 | 72.32 |'
- en: 'Table 3: Factoid Chart QA experimental results. PromptChart is equivalent to
    InstructGPT + CCR + Visual Information. All the metrics are measured in percentage.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：Factoid 图表问答实验结果。PromptChart 相当于 InstructGPT + CCR + 视觉信息。所有指标均以百分比表示。
- en: 5.2 Main Results
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 主要结果
- en: $\bullet$
  id: totrans-103
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: VDTG Results To evaluate our visual data table generation model, we follow recent
    relevant works in the Chart-to-Table domain and evaluate our model using the Relative
    Number Set Similarity (RNSS) Masry et al. ([2022](#bib.bib34)) and Relative Mapping
    Similarity (RMS) Liu et al. ([2022a](#bib.bib27)) metrics. Our model exhibits
    an impressive RNSS of 94.29% and RMS of 89.55%, highlighting its strong capability
    to extract data from images. This successful visual data table extraction process
    has significantly contributed to the overall performance of PromptChart.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: VDTG 结果 为了评估我们的视觉数据表生成模型，我们遵循了 Chart-to-Table 领域的最新相关工作，并使用相对数量集相似性（RNSS）Masry
    等人 ([2022](#bib.bib34)) 和相对映射相似性（RMS）Liu 等人 ([2022a](#bib.bib27)) 指标来评估我们的模型。我们的模型展示了令人印象深刻的
    RNSS 为 94.29% 和 RMS 为 89.55%，突显了其从图像中提取数据的强大能力。这一成功的视觉数据表提取过程显著提升了 PromptChart
    的整体表现。
- en: $\bullet$
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: FCQA, LCQA, CS Results Our main experimental results for FCQA task on ChartQA
    are outlined in [Table 3](#S5.T3 "In ∙ Zero- and Few-shot Settings ‣ 5.1 QA and
    Summarization Experiments ‣ 5 Experiments ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization"). We derive three
    main observations. Firstly, compared to zero-shot, one-shot, and fine-tuned baselines,
    PromptChart (few-shot) outperforms them by large margins, especially on the *human*
    test set. These improvements verify the effectiveness of our proposed FCQA prompt.
    Secondly, our experiments on *augmented* test set reveal that the PromptChart
    gains minor improvements when conditioning on the few-shot prompt instead of the
    instruction only (i.e., the zero-shot setting). We attribute this to the nature
    of the questions from *augmented* test set since they are mostly retrieval and
    not reasoning questions, which makes them less challenging for LLMs such as InstructGPT.
    Thirdly, the results of PromptChart and its variant *UniChart + InstructGPT +
    CCR* indicate that although the visual data tables slightly worsen the performance
    of the model on visually-irrelevant questions, they boost the performance of the
    models on visually-related questions, leading to overall improvements. We further
    provide additional analysis for the visual data table representation in [Section A.8](#A1.SS8
    "A.8 Analysis of Visual Data Table Representation ‣ Appendix A Appendices ‣ Do
    LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering and
    Summarization"). Exemplary cases are in [Table 15](#A1.T15 "In A.10 Error Analysis
    Case Studies ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization").
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: FCQA，LCQA，CS结果 我们在[表 3](#S5.T3 "在 ∙ 零样本和少样本设置 ‣ 5.1 QA 和总结实验 ‣ 5 实验 ‣ 大型语言模型是否适用于图表？设计少样本提示以进行图表问答和总结")中概述了
    ChartQA 上 FCQA 任务的主要实验结果。我们得出了三个主要观察结论。首先，与零样本、单样本和微调基线相比，PromptChart（少样本）在*人类*测试集上大幅超越了它们。这些改进验证了我们提出的
    FCQA 提示的有效性。其次，我们对*增强*测试集的实验显示，当使用少样本提示而不是仅使用指令（即零样本设置）时，PromptChart 获得了微小的改进。我们将此归因于*增强*测试集问题的性质，因为这些问题大多数是检索问题而不是推理问题，这使得它们对大型语言模型（如
    InstructGPT）挑战较小。第三，PromptChart 及其变体*UniChart + InstructGPT + CCR* 的结果表明，尽管视觉数据表略微降低了模型在视觉无关问题上的表现，但它们提升了模型在视觉相关问题上的表现，从而导致整体改进。我们进一步在[第
    A.8 节](#A1.SS8 "A.8 视觉数据表表示的分析 ‣ 附录 A 附录 ‣ 大型语言模型是否适用于图表？设计少样本提示以进行图表问答和总结")中提供了视觉数据表表示的额外分析。典型案例见[表
    15](#A1.T15 "在 A.10 错误分析案例研究 ‣ 附录 A 附录 ‣ 大型语言模型是否适用于图表？设计少样本提示以进行图表问答和总结")。
- en: '| Model | Mode | OpenCQA | Chart-to-Text |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 模式 | OpenCQA | Chart-to-Text |'
- en: '|  | QAFactEval | HumP | QAFactEval-P | HumP-P | QAFactEval-S | HumP-S |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|  | QAFactEval | HumP | QAFactEval-P | HumP-P | QAFactEval-S | HumP-S |'
- en: '| T5 | fine-tuned | 21.39 | - | 18.57 | - | 53.69 | 2.34 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| T5 | 微调 | 21.39 | - | 18.57 | - | 53.69 | 2.34 |'
- en: '| VLT5 | fine-tuned | 22.65 | 10.34 | - | - | - | - |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| VLT5 | 微调 | 22.65 | 10.34 | - | - | - | - |'
- en: '| MatCha | fine-tuned | - | - | 13.03 | - | 35.50 | - |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| MatCha | 微调 | - | - | 13.03 | - | 35.50 | - |'
- en: '| FlanT5-xxl | zero-shot | 13.97 | - | 19.36 | 4 | 23.98 | - |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| FlanT5-xxl | 零样本 | 13.97 | - | 19.36 | 4 | 23.98 | - |'
- en: '| InstructGPT | zero-shot | 23.16 | - | 18.13 | - | 24.72 | - |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| InstructGPT | zero-shot | 23.16 | - | 18.13 | - | 24.72 | - |'
- en: '| PromptChart | zero-shot | 25.85 | - | 18.44 | - | 25.31 | - |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | zero-shot | 25.85 | - | 18.44 | - | 25.31 | - |'
- en: '| FlanT5-xxl | few-shot | 5.61 | - | 18.29 | - | 34.05 | - |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| FlanT5-xxl | 少样本 | 5.61 | - | 18.29 | - | 34.05 | - |'
- en: '| InstructGPT | few-shot | 24.23 | - | 29.17 | - | 38.02 | - |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| InstructGPT | 少样本 | 24.23 | - | 29.17 | - | 38.02 | - |'
- en: '| PromptChart | few-shot | 27.19 | 81.67 | 31.17 | 94.34 | 49.88 | 94.23 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | few-shot | 27.19 | 81.67 | 31.17 | 94.34 | 49.88 | 94.23 |'
- en: 'Table 4: Long-form chart question answering and chart summarization experimental
    results. Metrics are measured in percentage.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：长篇图表问答和图表总结实验结果。指标以百分比为单位。
- en: Our evaluations in [Table 4](#S5.T4 "In ∙ ‣ 5.2 Main Results ‣ 5 Experiments
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization") for LCQA and CS tasks on OpenCQA and Chart-to-Text benchmarks
    illustrate a number of noteworthy findings. Firstly, with the carefully-designed
    prompts that we propose, PromptChart significantly improves the factuality scores
    on OpenCQA and Chart-to-Text Pew datasets, surpassing the performance of all fine-tuned
    baselines. Secondly, the model also exhibits superior human preferences in comparison
    to these fine-tuned methods. Finally, we observe that PromptChart generally performs
    better in the few-shot setting compared to the zero-shot setting. This highlights
    the importance of good demonstrations in determining its performance. Our annotators
    achieve strong agreements with an average Kripp.’s alpha values of 0.86 (0.79
    for OpenCQA, 0.91 for Chart-to-Text-Pew, and 0.88 for Chart-to-Text-Statista).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [表 4](#S5.T4 "在 ∙ ‣ 5.2 主要结果 ‣ 5 实验 ‣ LLM 是否适用于图表？为图表问答和摘要设计少量示例提示") 对 OpenCQA
    和 Chart-to-Text 基准上的 LCQA 和 CS 任务的评估展示了若干值得注意的发现。首先，利用我们提出的精心设计的提示，PromptChart
    在 OpenCQA 和 Chart-to-Text Pew 数据集上显著提高了事实准确性评分，超越了所有微调基线的表现。其次，与这些微调方法相比，该模型在用户偏好方面也表现出色。最后，我们观察到，PromptChart
    在少样本设置中的表现通常优于零样本设置。这突显了良好示例在确定其性能中的重要性。我们的注释员在 Kripp.’s alpha 值平均为 0.86 的情况下达成了强一致性（OpenCQA
    为 0.79，Chart-to-Text-Pew 为 0.91，Chart-to-Text-Statista 为 0.88）。
- en: 6 Discussion
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 讨论
- en: 6.1 Demonstration Selection for FCQA
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 FCQA 示例选择
- en: '![Refer to caption](img/937c1416cfe8870fe2a9017f6db6283e.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/937c1416cfe8870fe2a9017f6db6283e.png)'
- en: 'Figure 2: Supportive cases for our ChartQA prompt construction. Green answers
    are correct answers, and red ones are errors.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们 ChartQA 提示构建的支持案例。绿色回答为正确答案，红色为错误答案。
- en: We discuss the necessity of each demonstration in our proposed six-shot prompt
    for FCQA task. [Fig. 2](#S6.F2 "In 6.1 Demonstration Selection for FCQA ‣ 6 Discussion
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization") presents our supportive cases and the InstructGPT’s answers
    in the *zero-shot* setting. By examining these cases, we derive several observations.
    Firstly, InstructGPT model can do *Visual Retrieval*, *Numerical Retrieval*, and
    *Compositional Retrieval* without any demonstration (i.e., in zero-shot setting),
    which are proven by Case 1, 2, 3 respectively. Secondly, without any demonstration,
    the model seems to fluctuate in getting correct answers for arithmetic reasoning
    types including *Add & Subtraction* and *Division* (Case 4, 5, 6, 7). Thirdly,
    for more complex reasoning types such as *Compositional Reasoning*, the model
    performs poorly (Case 9) even in the reasoning steps (Case 8). Based on these
    observations, we propose the prompt consisting of $6$% (56.95% in the human set,
    and 80.88% in the augmented set), which is far lower from our proposed prompt,
    suggesting that our prompt is generalizable to other variations of questions within
    the benchmark. Note that, for a new benchmark, our current selection of demonstrations
    may not be sufficient, however, our methodology of selecting demonstrations can
    be adapted to improve generalizability.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了在我们提出的六示例提示中每个示例的必要性，用于 FCQA 任务。[图 2](#S6.F2 "在 6.1 FCQA 示例选择 ‣ 6 讨论 ‣
    LLM 是否适用于图表？为图表问答和摘要设计少量示例提示") 展示了我们的支持案例以及 InstructGPT 在 *零样本* 设置中的回答。通过检查这些案例，我们得出了几个观察结果。首先，InstructGPT
    模型可以在没有任何示例的情况下（即在零样本设置中）进行 *视觉检索*、*数值检索* 和 *组合检索*，这分别由案例 1、2 和 3 证明。其次，在没有任何示例的情况下，该模型在获取算术推理类型的正确答案时似乎存在波动，包括
    *加法与减法* 和 *除法*（案例 4、5、6、7）。第三，对于更复杂的推理类型，如 *组合推理*，即使在推理步骤中（案例 8），模型的表现也很差（案例 9）。基于这些观察结果，我们提出了包含
    $6$% 的提示（人类数据集为 56.95%，扩充数据集为 80.88%），这远低于我们提出的提示，表明我们的提示可以推广到基准中的其他变体问题。需要注意的是，对于新的基准，我们当前选择的示例可能不足，但我们的示例选择方法可以调整以提高通用性。
- en: 6.2 Best Number of Demonstrations for LCQA and CS Task
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 LCQA 和 CS 任务的最佳示例数量
- en: '![Refer to caption](img/3269b529a7d02f26fa21c34925d5baf4.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3269b529a7d02f26fa21c34925d5baf4.png)'
- en: 'Figure 3: Performance of our PromptChart with different numbers of demonstrations
    in the prompt on 300 random samples of each benchmark.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：在每个基准的 300 个随机样本中，提示中不同数量示例对我们 PromptChart 的表现影响。
- en: We conduct experiments to select the best number of demonstrations in the prompts
    fed to the model for the tasks of LCQA and CS. Specifically, we select a subset
    containing 300 random samples from the validation splits of Chart-to-Text (Pew
    dataset and Statista dataset) and OpenCQA as our mini-test sets. We then compare
    the performance of our model at different numbers of carefully-selected demonstrations
    (1, 3, 6, 9) and report the corresponding QAFactEval scores Fabbri et al. ([2022](#bib.bib15)).
    We select the demonstrations thoroughly, following the proposed properties in
    [Section 4](#S4 "4 Methodology ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts
    for Chart Question Answering and Summarization"). After obtaining the best number
    of demonstrations on each mini-test set, we randomly select the same number of
    demonstrations to test the effectiveness of our proposed properties. The results
    are presented in [Fig. 3](#S6.F3 "In 6.2 Best Number of Demonstrations for LCQA
    and CS Task ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts
    for Chart Question Answering and Summarization"). We derive two main observations.Firstly,
    as we add more demonstrations to the prompt, the model may tend to generate more
    factually incorrect texts compared to using the previous number of demonstrations.
    Secondly, our careful sets of demonstrations boost the performance of the model
    significantly compared to random selections, which illustrates the effectiveness
    of our proposed properties.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行实验以选择输入到模型中的最佳演示次数，任务为LCQA和CS。具体来说，我们从Chart-to-Text（Pew数据集和Statista数据集）和OpenCQA的验证分割中选择包含300个随机样本的子集作为我们的迷你测试集。然后，我们比较在不同数量的精心挑选的演示（1、3、6、9）下模型的表现，并报告相应的QAFactEval评分Fabbri等人（[2022](#bib.bib15)）。我们根据[第4节](#S4
    "4 Methodology ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart
    Question Answering and Summarization")中提出的属性，全面选择演示。获得每个迷你测试集上的最佳演示次数后，我们随机选择相同数量的演示来测试我们提出的属性的有效性。结果见于[图3](#S6.F3
    "In 6.2 Best Number of Demonstrations for LCQA and CS Task ‣ 6 Discussion ‣ Do
    LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering and
    Summarization")。我们得出两个主要观察结果。首先，随着向提示中添加更多演示，模型可能会产生比使用之前数量的演示更多的事实错误文本。其次，与随机选择相比，我们精心挑选的演示显著提升了模型的表现，这说明了我们提出的属性的有效性。
- en: 6.3 Dive Deeper into the Proposed Properties
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 深入探讨提出的属性
- en: '| Model | OpenCQA | Pew | Statista |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| Model | OpenCQA | Pew | Statista |'
- en: '| LCQA w/o *(ii)* | 25.87 | - | - |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| LCQA w/o *(ii)* | 25.87 | - | - |'
- en: '| LCQA w/o *(iii)* | 27.01 | - | - |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| LCQA w/o *(iii)* | 27.01 | - | - |'
- en: '| PromptChart | 27.19 | - | - |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | 27.19 | - | - |'
- en: '| CS w/o *(ii)* | - | 29.11 | 47.61 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| CS w/o *(ii)* | - | 29.11 | 47.61 |'
- en: '| CS w/o *(iii)* | - | 30.79 | 48.16 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| CS w/o *(iii)* | - | 30.79 | 48.16 |'
- en: '| PromptChart | - | 31.17 | 49.88 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | - | 31.17 | 49.88 |'
- en: 'Table 5: Effects of proposed properties. We select the same number of demonstrations
    with our proposed number for each task as in [Section 4](#S4 "4 Methodology ‣
    Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization").'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：提出的属性的效果。我们为每个任务选择与我们提出的数量相同的演示次数，如在[第4节](#S4 "4 Methodology ‣ Do LLMs Work
    on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization")中所述。
- en: 'To verify the necessity of our proposed properties for guiding the prompt construction
    in [Section 4](#S4 "4 Methodology ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization"), we conduct experiments
    by removing the properties one by one, resulting in $4$ experiments. Our illustrative
    cases are presented in [Section A.9](#A1.SS9 "A.9 Illustrative Cases for Proposed
    Properties of LCQA and CS Prompts ‣ Appendix A Appendices ‣ Do LLMs Work on Charts?
    Designing Few-Shot Prompts for Chart Question Answering and Summarization"):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为验证我们提出的属性在[第4节](#S4 "4 Methodology ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization")中指导提示构建的必要性，我们通过逐个去除属性进行实验，共进行了$4$次实验。我们的示例案例见于[第A.9节](#A1.SS9
    "A.9 Illustrative Cases for Proposed Properties of LCQA and CS Prompts ‣ Appendix
    A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question
    Answering and Summarization")：
- en: $\bullet$ LCQA - w/o prop. *(ii)* Our prompt for LCQA task only contains 6 *Describe
    and Summary* question-answer pairs. This experiment is to show that without *Comparative*
    and *Discoverer* QA pairs in the prompt, the model achieved lower performance.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ LCQA - w/o prop. *(ii)* 我们的LCQA任务提示仅包含6个*描述和总结*问答对。此实验旨在表明，如果提示中没有*比较*和*发现者*问答对，模型性能会降低。
- en: $\bullet$ other samples in OpenCQA dataset as demonstrations such that the model
    hallucinates on demonstrations, showing that it is better to ensure this property.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 在 OpenCQA 数据集中，其他样本作为演示，模型在这些演示上产生幻觉，这表明确保这一属性是更好的做法。
- en: $\bullet$ *Statistical and Comparative* summaries. This experiment is to verify
    that without any *Perceptual and Cognitive* summary in the demonstrations, the
    model might output numbers or texts that do not exist in the input.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ *统计和比较* 总结。这个实验旨在验证如果在演示中没有任何*感知和认知*总结，模型可能会输出在输入中不存在的数字或文本。
- en: $\bullet$ other summaries in the dataset as demonstrations such that there exists
    at least one of them which the model hallucinates on, showing that it is better
    to ensure property *(iii)*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 数据集中的其他总结作为演示，以确保至少有一个演示中模型产生幻觉，表明确保属性 *(iii)* 更为重要。
- en: Our experimental results are outlined in [Table 5](#S6.T5 "In 6.3 Dive Deeper
    into the Proposed Properties ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization"). We observe
    that removing any proposed property results in decreased performance of the model,
    which enforces our proposed properties.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验结果概述见[表5](#S6.T5 "在 6.3 深入探讨提出的属性 ‣ 6 讨论 ‣ LLMs 在图表上有效吗？设计少量示例提示以进行图表问答和总结")。我们观察到，去除任何提出的属性都会导致模型性能下降，这加强了我们提出的属性。
- en: 6.4 Error Analysis
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 错误分析
- en: Despite achieving promising performance, our proposed framework still falls
    into several categories of errors. We discuss them below and all the case studies
    are introduced in [Table 16](#A1.T16 "In A.10 Error Analysis Case Studies ‣ Appendix
    A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question
    Answering and Summarization").
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了令人鼓舞的表现，我们提出的框架仍然存在几类错误。我们在下面讨论了这些错误，所有案例研究都在[表16](#A1.T16 "在 A.10 错误分析案例研究
    ‣ 附录 A 附录 ‣ LLMs 在图表上有效吗？设计少量示例提示以进行图表问答和总结")中介绍。
- en: $\bullet$
  id: totrans-146
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Factoid Chart Question Answering To understand the challenges of FCQA task
    and promising future directions, we manually investigate 100 FCQA questions that
    the model failed to output the correct answers and realize the following issues:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 实体图表问答 为了理解 FCQA 任务的挑战和有前途的未来方向，我们手动调查了 100 个模型未能输出正确答案的 FCQA 问题，并发现了以下问题：
- en: (1) Logical and mathematical reasoning is a common error that LLMs such as InstructGPT
    often make Gao et al. ([2022](#bib.bib16)). Case 1 provides an illustration of
    this phenomenon, where the model correctly identifies the required operands and
    operators, but still produces incorrect computational output. The model also frequently
    makes logical errors, as demonstrated in Case 2, where despite correctly calculating
    the average percentage of three bars as 6.75%, which is greater than 6%, the model
    fails to conclude the correct answer.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 逻辑和数学推理是 LLMs（如 InstructGPT）常见的错误，Gao 等人（[2022](#bib.bib16)）指出。案例 1 说明了这一现象，其中模型正确识别了所需的操作数和运算符，但仍然产生了错误的计算结果。模型还经常出现逻辑错误，如案例
    2 所示，尽管正确计算了三根条形图的平均百分比为 6.75%，大于 6%，模型却未能得出正确答案。
- en: (2) Visual data table generation challenge Although directly fine-tuning UniChart
    Masry et al. ([2023](#bib.bib33)) to generate visual data tables with correct
    positions gives us some minor improvements, we observe that UniChart sometimes
    generates wrong names of the colors. [Table 9](#A1.T9 "In A.6 Visual Data Table
    Generator (VDTG) ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization") illustrates some of such
    cases. Given a huge room for future research as discussed in [Section A.8](#A1.SS8
    "A.8 Analysis of Visual Data Table Representation ‣ Appendix A Appendices ‣ Do
    LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering and
    Summarization"), future works can focus on improving this module.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 可视化数据表生成挑战 尽管直接对 UniChart Masry 等人（[2023](#bib.bib33)）进行微调以生成具有正确位置的可视化数据表给我们带来了一些小的改进，但我们观察到
    UniChart 有时生成的颜色名称是错误的。[表9](#A1.T9 "在 A.6 可视化数据表生成器 (VDTG) ‣ 附录 A 附录 ‣ LLMs 在图表上有效吗？设计少量示例提示以进行图表问答和总结")
    说明了一些此类情况。考虑到在[第 A.8 节](#A1.SS8 "A.8 可视化数据表表示分析 ‣ 附录 A 附录 ‣ LLMs 在图表上有效吗？设计少量示例提示以进行图表问答和总结")讨论的未来研究的巨大空间，未来的工作可以专注于改进这个模块。
- en: $\bullet$
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Long-form Chart Question Answering & Chart Summarization Our human evaluation
    on PromptChart reveal several key challanges:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 长篇图表问答与图表总结 我们对 PromptChart 的人类评估揭示了几个关键挑战：
- en: (1) Hallucinations & factual errors are observed from the generated answers
    of our PromptChart. These errors are well-known LLMs issues, and have been studied
    extensively by prior works Fabbri et al. ([2022](#bib.bib15)); Ji et al. ([2023](#bib.bib19)).
    For LCQA, one example of such errors is Case 5 in which the model generates unwanted
    numbers (highlighted in red color) that are not in the chat image. Similarly for
    CS, in Case 6, the red passage could not be found in the chart image and input
    information, but the model generates it confidently.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 在我们生成的 PromptChart 答案中观察到了虚假信息和事实错误。这些错误是 LLMs 的已知问题，先前的研究 Fabbri 等人 ([2022](#bib.bib15))
    和 Ji 等人 ([2023](#bib.bib19)) 已经对此进行了广泛研究。对于 LCQA，错误的一个例子是案例 5，其中模型生成了不在聊天图像中的不必要的数字（用红色突出显示）。对于
    CS，同样在案例 6 中，红色段落在图表图像和输入信息中找不到，但模型自信地生成了它。
- en: (2) Logical & mathematical reasoning errors also appear during generating long-form
    answers and summaries. Case 4 is an example of LCQA task, in which "decreased
    by 10 percentage points" should be from "88 % to 78 %" instead of "78 % to 88
    %" as generated. Additionally, Case 3 illustrates a CS example, in which the model,
    despite correctly retrieving 8269.54 kg in 2019, a number being much bigger than
    6348.43 in 2011, still concludes that 6348.43 in 2011 is the largest amount.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 在生成长篇回答和总结时，也会出现逻辑和数学推理错误。案例 4 是 LCQA 任务的一个例子，其中“减少了 10 个百分点”应为“从 88 % 降至
    78 %”，而不是生成的“从 78 % 降至 88 %”。此外，案例 3 说明了一个 CS 示例，其中模型尽管正确检索了 2019 年的 8269.54 kg，这个数值明显大于
    2011 年的 6348.43 kg，但仍然得出 2011 年的 6348.43 kg 是最大数量的结论。
- en: 7 Conclusion
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: In this work, we take the first step to study few-shot prompting with large
    language models for chart question answering and summarization tasks. We propose
    PromptChart, a multimodal few-shot prompting framework with LLMs. Through meticulous
    task analysis, we have developed a comprehensive set of prompting guidelines that
    are specifically tailored to each downstream task. These guidelines aim to maximize
    the few-shot performance of large language models (LLMs). Additionally, we propose
    the *visual data table* representation that incorporates visual features into
    the prompt and the LLM. Experimental results show that PromptChart achieves significant
    improvements over prior one-shot and fine-tuned baselines, as evidenced by automatic
    metrics and human evaluation. In the future, we plan to explore dynamically selecting
    the demonstrations in the prompt to further optimize the performance of LLMs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们迈出了研究大语言模型在图表问答和总结任务中的少量示例提示的第一步。我们提出了 PromptChart，一个结合了 LLM 的多模态少量示例提示框架。通过细致的任务分析，我们开发了一整套针对每个下游任务的提示指南。这些指南旨在最大化大语言模型（LLMs）的少量示例性能。此外，我们提出了将视觉特征融入提示和
    LLM 的*视觉数据表*表示。实验结果表明，PromptChart 在自动指标和人工评估上相比先前的单次示例和微调基线有显著改进。未来，我们计划探索动态选择提示中的示例，以进一步优化
    LLM 的性能。
- en: Limitations
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: One limitation of our work is the utilization of a fixed prompt for each task,
    which has the potential to restrict the model’s performance. To mitigate this
    issue, we made our best to explicitly set our proposed properties to cover the
    different challenges in the LCQA and CS benchmarks. Still, more investigation
    is needed to explore different prompt setups that might improve performance. In
    the factoid chart question answering task, our analysis of the challenges and
    incorporating them into our fixed prompt serves as an additional effort to address
    this issue. In addition, our manual human evaluations in [Section 6.4](#S6.SS4
    "6.4 Error Analysis ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization") reveal that InstructGPT
    often makes logical & mathematical reasoning errors, as well as hallucinations
    & factual errors during generating long-form texts. In the future, we will focus
    on improving the VDTG module to make it more robust to different types of charts,
    as well as improving the logical and mathematical reasoning capabilities of LLMs.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工作的一个局限性是对每个任务使用固定的提示，这可能会限制模型的表现。为了减轻这一问题，我们尽力明确设置了我们提出的属性，以涵盖 LCQA 和 CS
    基准中的不同挑战。然而，仍需进一步研究不同的提示设置，以期改善性能。在事实图表问答任务中，我们对挑战的分析以及将这些挑战纳入我们的固定提示中，作为应对这一问题的额外努力。此外，我们在[第6.4节](#S6.SS4
    "6.4 错误分析 ‣ 6 讨论 ‣ 大型语言模型在图表上是否有效？为图表问答和总结设计少量提示")的人工评估显示，InstructGPT 在生成长文本时常常出现逻辑和数学推理错误，以及幻觉和事实错误。未来，我们将重点提升
    VDTG 模块，使其对不同类型的图表更具鲁棒性，并改善 LLM 的逻辑和数学推理能力。
- en: Ethics Statement
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: 7.1 Risk in Model Deployment
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 模型部署中的风险
- en: Deploying a technology developed by a third party such as OpenAI carries ethical
    considerations that must be addressed to ensure fairness and mitigate potential
    harm. This involves choosing algorithms and performance metrics that promote fairness
    Corbett-Davies et al. ([2017](#bib.bib13)), as well as identifying and addressing
    any biases in the pre-trained model. In this work, we evaluate the performance
    of the models by a factual correctness metric Fabbri et al. ([2022](#bib.bib15)),
    which encourages the generated texts to be factually correct based on the input
    information and discourages hallucinations. However, it is important to acknowledge
    that although our method strives for factual correctness, it does not guarantee
    perfectly factual outputs and may be abused to spread misinformation among the
    public. In addition, through human evaluations, we observe that our proposed method
    does not generate any discriminatory or insulting responses. However, it is important
    to note that we cannot guarantee that our method will never produce harmful content.
    Vigilance is necessary to mitigate the risk of producing harmful outputs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 部署第三方开发的技术，例如 OpenAI 的技术，涉及必须解决的伦理问题，以确保公平并减少潜在的危害。这包括选择促进公平的算法和性能指标（Corbett-Davies
    等，([2017](#bib.bib13))），以及识别和解决预训练模型中的任何偏见。在这项工作中，我们通过事实正确性指标（Fabbri 等，[2022](#bib.bib15)）评估模型的表现，该指标鼓励生成的文本基于输入信息保持事实正确，并且不鼓励产生幻觉。然而，重要的是要认识到，尽管我们的方法力求事实正确，但不能保证输出完全准确，并且可能被滥用以传播虚假信息。此外，通过人工评估，我们观察到我们提出的方法不会生成任何歧视性或侮辱性回应。然而，值得注意的是，我们不能保证我们的方法不会产生有害内容。必须保持警惕，以减少产生有害输出的风险。
- en: 7.2 Human Evaluation
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 人工评估
- en: During the human evaluation experiments, we hired three annotators to score
    a total of 300 generated texts. To fairly compensate them, we paid them an hourly
    wage of $15, which is higher than the local statutory minimum wage. Additionally,
    to protect the privacy of the annotators, we kept all annotations anonymized.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工评估实验中，我们雇佣了三名注释员对总计 300 个生成文本进行评分。为了公平补偿他们，我们支付了每小时 $15 的工资，这高于当地的法定最低工资。此外，为了保护注释员的隐私，我们对所有注释进行了匿名处理。
- en: Acknowledgements
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This research was supported by the Natural Sciences & Engineering Research Council
    (NSERC) of Canada and Canada Foundation for Innovation (CFI). Do Xuan Long is
    supported by the A*STAR Computing and Information Science (ACIS) scholarship,
    A*STAR, Singapore.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了加拿大自然科学与工程研究委员会（NSERC）和加拿大创新基金会（CFI）的资助。Do Xuan Long 得到了新加坡 A*STAR 计算与信息科学（ACIS）奖学金的支持。
- en: References
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Alayrac et al. (2022) Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine
    Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican,
    Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao
    Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew
    Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira,
    Oriol Vinyals, Andrew Zisserman, and Karen Simonyan. 2022. [Flamingo: a visual
    language model for few-shot learning](https://openreview.net/forum?id=EbMuimAbPbs).
    In *Advances in Neural Information Processing Systems*.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alayrac等人（2022）Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech,
    Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm
    Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong,
    Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew Brock,
    Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol
    Vinyals, Andrew Zisserman, 和 Karen Simonyan。2022年。[Flamingo：一个少样本学习的视觉语言模型](https://openreview.net/forum?id=EbMuimAbPbs)。发表在*神经信息处理系统进展*。
- en: 'Balaji et al. (2018) Abhijit Balaji, Thuvaarakkesh Ramanathan, and Venkateshwarlu
    Sonathi. 2018. Chart-text: A fully automated chart image descriptor. *arXiv preprint
    arXiv:1812.10636*.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balaji等人（2018）Abhijit Balaji, Thuvaarakkesh Ramanathan, 和 Venkateshwarlu Sonathi。2018年。Chart-text：一个完全自动化的图表图像描述符。*arXiv预印本
    arXiv:1812.10636*。
- en: 'Beltagy et al. (2022) Iz Beltagy, Arman Cohan, Robert Logan IV, Sewon Min,
    and Sameer Singh. 2022. [Zero- and few-shot NLP with pretrained language models](https://doi.org/10.18653/v1/2022.acl-tutorials.6).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts*, pages 32–37, Dublin, Ireland. Association for
    Computational Linguistics.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beltagy等人（2022）Iz Beltagy, Arman Cohan, Robert Logan IV, Sewon Min, 和 Sameer
    Singh。2022年。[使用预训练语言模型的零样本和少样本NLP](https://doi.org/10.18653/v1/2022.acl-tutorials.6)。发表在*第60届计算语言学协会年会：教程摘要*，第32–37页，爱尔兰都柏林。计算语言学协会。
- en: Belz and Reiter (2006) Anja Belz and Ehud Reiter. 2006. [Comparing automatic
    and human evaluation of NLG systems](https://aclanthology.org/E06-1040). In *11th
    Conference of the European Chapter of the Association for Computational Linguistics*,
    pages 313–320, Trento, Italy. Association for Computational Linguistics.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Belz和Reiter（2006）Anja Belz 和 Ehud Reiter。2006年。[自动与人工评估NLG系统的比较](https://aclanthology.org/E06-1040)。发表在*第11届欧洲计算语言学协会年会*，第313–320页，意大利特伦托。计算语言学协会。
- en: Bentley (1975) Jon Louis Bentley. 1975. Multidimensional binary search trees
    used for associative searching. *Communications of the ACM*, 18(9):509–517.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bentley（1975）Jon Louis Bentley。1975年。用于关联搜索的多维二叉搜索树。*ACM通讯*，18(9):509–517。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown等人（2020）Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, 等人。2020年。语言模型是少样本学习者。*神经信息处理系统进展*，33:1877–1901。
- en: 'Cheng et al. (2023) Zhi-Qi Cheng, Qi Dai, Siyao Li, Jingdong Sun, Teruko Mitamura,
    and Alexander G Hauptmann. 2023. Chartreader: A unified framework for chart derendering
    and comprehension without heuristic rules. *arXiv preprint arXiv:2304.02173*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng等人（2023）Zhi-Qi Cheng, Qi Dai, Siyao Li, Jingdong Sun, Teruko Mitamura,
    和 Alexander G Hauptmann。2023年。Chartreader：一个用于图表渲染和理解的统一框架，无需启发式规则。*arXiv预印本 arXiv:2304.02173*。
- en: Cho et al. (2021) Jaemin Cho, Jie Lei, Hao Tan, and Mohit Bansal. 2021. Unifying
    vision-and-language tasks via text generation. In *International Conference on
    Machine Learning*, pages 1931–1942\. PMLR.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho等人（2021）Jaemin Cho, Jie Lei, Hao Tan, 和 Mohit Bansal。2021年。通过文本生成统一视觉和语言任务。发表在*国际机器学习会议*，第1931–1942页。PMLR。
- en: 'Choi et al. (2019) Jinho Choi, Sanghun Jung, Deok Gun Park, Jaegul Choo, and
    Niklas Elmqvist. 2019. Visualizing for the non-visual: Enabling the visually impaired
    to use visualization. In *Computer Graphics Forum*, volume 38, pages 249–260\.
    Wiley Online Library.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi等人（2019）Jinho Choi, Sanghun Jung, Deok Gun Park, Jaegul Choo, 和 Niklas Elmqvist。2019年。《面向非视觉人士的可视化：使视觉障碍者能够使用可视化》。发表在*计算机图形学论坛*，第38卷，第249–260页。Wiley在线图书馆。
- en: 'Chowdhery et al. (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways.
    *arXiv preprint arXiv:2204.02311*.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chowdhery等人（2022）Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma,
    Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian
    Gehrmann, 等人。2022年。Palm：通过路径扩展语言建模。*arXiv预印本 arXiv:2204.02311*。
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    2022. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等（2022）Hyung Won Chung、Le Hou、Shayne Longpre、Barret Zoph、Yi Tay、William
    Fedus、Eric Li、Xuezhi Wang、Mostafa Dehghani、Siddhartha Brahma 等。2022。缩放指令微调语言模型。*arXiv
    预印本 arXiv:2210.11416*。
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve
    math word problems. *arXiv preprint arXiv:2110.14168*.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe 等（2021）Karl Cobbe、Vineet Kosaraju、Mohammad Bavarian、Mark Chen、Heewoo Jun、Lukasz
    Kaiser、Matthias Plappert、Jerry Tworek、Jacob Hilton、Reiichiro Nakano、Christopher
    Hesse 和 John Schulman。2021。训练验证者解决数学文字题。*arXiv 预印本 arXiv:2110.14168*。
- en: Corbett-Davies et al. (2017) Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad
    Goel, and Aziz Huq. 2017. Algorithmic decision making and the cost of fairness.
    In *Proceedings of the 23rd acm sigkdd international conference on knowledge discovery
    and data mining*, pages 797–806.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Corbett-Davies 等（2017）Sam Corbett-Davies、Emma Pierson、Avi Feller、Sharad Goel
    和 Aziz Huq。2017。算法决策与公平成本。发表于*第 23 届 ACM SIGKDD 国际知识发现与数据挖掘大会论文集*，页 797–806。
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. [BERT: Pre-training of deep bidirectional transformers for language
    understanding](https://doi.org/10.18653/v1/N19-1423). In *Proceedings of the 2019
    Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pages
    4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin 等（2019）Jacob Devlin、Ming-Wei Chang、Kenton Lee 和 Kristina Toutanova。2019。[BERT：用于语言理解的深度双向变换器预训练](https://doi.org/10.18653/v1/N19-1423)。发表于*2019年北美计算语言学协会年会会议论文集：人类语言技术，第
    1 卷（长篇和短篇论文）*，页 4171–4186，明尼阿波利斯，明尼苏达州。计算语言学协会。
- en: 'Fabbri et al. (2022) Alexander Richard Fabbri, Chien-Sheng Wu, Wenhao Liu,
    and Caiming Xiong. 2022. Qafacteval: Improved qa-based factual consistency evaluation
    for summarization. In *Proceedings of the 2022 Conference of the North American
    Chapter of the Association for Computational Linguistics: Human Language Technologies*,
    pages 2587–2601.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fabbri 等（2022）Alexander Richard Fabbri、Chien-Sheng Wu、Wenhao Liu 和 Caiming Xiong。2022。Qafacteval：改进的基于
    QA 的事实一致性评估用于总结。发表于*2022年北美计算语言学协会年会会议论文集：人类语言技术*，页 2587–2601。
- en: 'Gao et al. (2022) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu,
    Yiming Yang, Jamie Callan, and Graham Neubig. 2022. Pal: Program-aided language
    models. *arXiv preprint arXiv:2211.10435*.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2022）Luyu Gao、Aman Madaan、Shuyan Zhou、Uri Alon、Pengfei Liu、Yiming Yang、Jamie
    Callan 和 Graham Neubig。2022。PAL：程序辅助语言模型。*arXiv 预印本 arXiv:2211.10435*。
- en: Holtzman et al. (2020) Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin
    Choi. 2020. [The curious case of neural text degeneration](https://openreview.net/forum?id=rygGQyrFvH).
    In *International Conference on Learning Representations*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holtzman 等（2020）Ari Holtzman、Jan Buys、Li Du、Maxwell Forbes 和 Yejin Choi。2020。[神经文本退化的奇特案例](https://openreview.net/forum?id=rygGQyrFvH)。发表于*国际学习表征会议*。
- en: 'Hoque et al. (2022) Enamul Hoque, Parsa Kavehzadeh, and Ahmed Masry. 2022.
    Chart question answering: State of the art and future directions. In *Computer
    Graphics Forum*, volume 41, pages 555–572\. Wiley Online Library.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hoque 等（2022）Enamul Hoque、Parsa Kavehzadeh 和 Ahmed Masry。2022。图表问答：现状与未来方向。发表于*计算机图形学论坛*，第
    41 卷，页 555–572。Wiley 在线图书馆。
- en: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey
    of hallucination in natural language generation. *ACM Computing Surveys*, 55(12):1–38.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji 等（2023）Ziwei Ji、Nayeon Lee、Rita Frieske、Tiezheng Yu、Dan Su、Yan Xu、Etsuko
    Ishii、Ye Jin Bang、Andrea Madotto 和 Pascale Fung。2023。自然语言生成中的幻觉调查。*ACM 计算调查*，55(12)：1–38。
- en: 'Kann et al. (2018) Katharina Kann, Sascha Rothe, and Katja Filippova. 2018.
    [Sentence-level fluency evaluation: References help, but can be spared!](https://doi.org/10.18653/v1/K18-1031)
    In *Proceedings of the 22nd Conference on Computational Natural Language Learning*,
    pages 313–323, Brussels, Belgium. Association for Computational Linguistics.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kann 等（2018）Katharina Kann、Sascha Rothe 和 Katja Filippova。2018。[句子级流畅性评估：参考有帮助，但可以省略！](https://doi.org/10.18653/v1/K18-1031)发表于*第
    22 届计算自然语言学习会议论文集*，页 313–323，比利时布鲁塞尔。计算语言学协会。
- en: 'Kantharaj et al. (2022a) Shankar Kantharaj, Xuan Long Do, Rixie Tiffany Ko
    Leong, Jia Qing Tan, Enamul Hoque, and Shafiq Joty. 2022a. [Opencqa: Open-ended
    question answering with charts](https://doi.org/10.48550/ARXIV.2210.06628). *The
    2022 Conference on Empirical Methods in Natural Language Processing*.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kantharaj et al. (2022a) Shankar Kantharaj, Xuan Long Do, Rixie Tiffany Ko Leong,
    Jia Qing Tan, Enamul Hoque, 和 Shafiq Joty. 2022a. [Opencqa：图表的开放式问题回答](https://doi.org/10.48550/ARXIV.2210.06628)。
    *2022年自然语言处理实证方法会议*。
- en: 'Kantharaj et al. (2022b) Shankar Kantharaj, Rixie Tiffany Leong, Xiang Lin,
    Ahmed Masry, Megh Thakkar, Enamul Hoque, and Shafiq Joty. 2022b. [Chart-to-text:
    A large-scale benchmark for chart summarization](https://doi.org/10.18653/v1/2022.acl-long.277).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 4005–4023, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kantharaj et al. (2022b) Shankar Kantharaj, Rixie Tiffany Leong, Xiang Lin,
    Ahmed Masry, Megh Thakkar, Enamul Hoque, 和 Shafiq Joty. 2022b. [图表到文本：一个大规模图表总结基准](https://doi.org/10.18653/v1/2022.acl-long.277)。在
    *第60届计算语言学协会年会（第1卷：长篇论文）*，第4005–4023页，爱尔兰都柏林。计算语言学协会。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://openreview.net/forum?id=e2TBb5y0yFf).
    In *Advances in Neural Information Processing Systems*.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, 和 Yusuke Iwasawa. 2022. [大型语言模型是零样本推理器](https://openreview.net/forum?id=e2TBb5y0yFf)。在
    *神经信息处理系统进展*。
- en: Krippendorff (2011) Klaus Krippendorff. 2011. Computing krippendorff’s alpha-reliability.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krippendorff (2011) Klaus Krippendorff. 2011. 计算 Krippendorff 的 alpha 可靠性。
- en: 'Lee et al. (2022) Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu
    Liu, Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, and Kristina
    Toutanova. 2022. Pix2struct: Screenshot parsing as pretraining for visual language
    understanding. *arXiv preprint arXiv:2210.03347*.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. (2022) Kenton Lee, Mandar Joshi, Iulia Turc, Hexiang Hu, Fangyu Liu,
    Julian Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, 和 Kristina
    Toutanova. 2022. Pix2struct：将屏幕截图解析作为视觉语言理解的预训练。 *arXiv 预印本 arXiv:2210.03347*。
- en: 'Lin (2004) Chin-Yew Lin. 2004. [ROUGE: A package for automatic evaluation of
    summaries](https://aclanthology.org/W04-1013). In *Text Summarization Branches
    Out*, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin (2004) Chin-Yew Lin. 2004. [ROUGE：一个自动摘要评价包](https://aclanthology.org/W04-1013)。在
    *文本摘要的拓展*，第74–81页，西班牙巴塞罗那。计算语言学协会。
- en: 'Liu et al. (2022a) Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno,
    Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier,
    and Yasemin Altun. 2022a. Deplot: One-shot visual language reasoning by plot-to-table
    translation. *arXiv preprint arXiv:2212.10505*.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2022a) Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno,
    Syrine Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier,
    和 Yasemin Altun. 2022a. Deplot：通过图表到表格的翻译进行一次性视觉语言推理。 *arXiv 预印本 arXiv:2212.10505*。
- en: 'Liu et al. (2022b) Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi
    Pang, Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, and Julian Martin
    Eisenschlos. 2022b. Matcha: Enhancing visual language pretraining with math reasoning
    and chart derendering. *arXiv preprint arXiv:2212.09662*.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2022b) Fangyu Liu, Francesco Piccinno, Syrine Krichene, Chenxi Pang,
    Kenton Lee, Mandar Joshi, Yasemin Altun, Nigel Collier, 和 Julian Martin Eisenschlos.
    2022b. Matcha：通过数学推理和图表去渲染提升视觉语言预训练。 *arXiv 预印本 arXiv:2212.09662*。
- en: 'Liu et al. (2023a) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, and Graham Neubig. 2023a. Pre-train, prompt, and predict: A systematic
    survey of prompting methods in natural language processing. *ACM Computing Surveys*,
    55(9):1–35.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023a) Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki
    Hayashi, 和 Graham Neubig. 2023a. 预训练、提示和预测：自然语言处理中的提示方法系统综述。 *ACM 计算调查*，55(9):1–35。
- en: Liu et al. (2019) Xiaoyi Liu, Diego Klabjan, and Patrick NBless. 2019. Data
    extraction from charts via single deep neural network. *arXiv preprint arXiv:1906.11906*.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2019) Xiaoyi Liu, Diego Klabjan, 和 Patrick NBless. 2019. 通过单一深度神经网络从图表中提取数据。
    *arXiv 预印本 arXiv:1906.11906*。
- en: 'Liu et al. (2023b) Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu,
    and Chenguang Zhu. 2023b. Gpteval: Nlg evaluation using gpt-4 with better human
    alignment. *arXiv preprint arXiv:2303.16634*.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023b) Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu,
    和 Chenguang Zhu. 2023b. Gpteval：使用gpt-4进行更好的人类对齐的自然语言生成评估。 *arXiv 预印本 arXiv:2303.16634*。
- en: 'Luo et al. (2021) Junyu Luo, Zekun Li, Jinpeng Wang, and Chin-Yew Lin. 2021.
    Chartocr: Data extraction from charts images via a deep hybrid framework. In *Proceedings
    of the IEEE/CVF winter conference on applications of computer vision*, pages 1917–1925.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Luo et al. (2021) Junyu Luo, Zekun Li, Jinpeng Wang, 和 Chin-Yew Lin. 2021.
    Chartocr: 通过深度混合框架从图表图像中提取数据。见于*IEEE/CVF冬季计算机视觉应用会议论文集*，第1917–1925页。'
- en: 'Masry et al. (2023) Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque,
    and Shafiq Joty. 2023. Unichart: A universal vision-language pretrained model
    for chart comprehension and reasoning. *arXiv preprint arXiv:2305.14761*.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Masry et al. (2023) Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque,
    和 Shafiq Joty. 2023. Unichart: 一种通用视觉语言预训练模型用于图表理解和推理。*arXiv预印本 arXiv:2305.14761*。'
- en: 'Masry et al. (2022) Ahmed Masry, Do Long, Jia Qing Tan, Shafiq Joty, and Enamul
    Hoque. 2022. [ChartQA: A benchmark for question answering about charts with visual
    and logical reasoning](https://doi.org/10.18653/v1/2022.findings-acl.177). In
    *Findings of the Association for Computational Linguistics: ACL 2022*, pages 2263–2279,
    Dublin, Ireland. Association for Computational Linguistics.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Masry et al. (2022) Ahmed Masry, Do Long, Jia Qing Tan, Shafiq Joty, 和 Enamul
    Hoque. 2022. [ChartQA: 一个用于图表的视觉和逻辑推理问答基准](https://doi.org/10.18653/v1/2022.findings-acl.177)。见于*计算语言学协会会议记录：ACL
    2022*，第2263–2279页，爱尔兰都柏林。计算语言学协会。'
- en: 'Mathur et al. (2020) Nitika Mathur, Timothy Baldwin, and Trevor Cohn. 2020.
    [Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation
    evaluation metrics](https://doi.org/10.18653/v1/2020.acl-main.448). In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics*,
    pages 4984–4997, Online. Association for Computational Linguistics.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mathur et al. (2020) Nitika Mathur, Timothy Baldwin, 和 Trevor Cohn. 2020. [纠缠在BLEU中：重新评估自动机器翻译评价指标的评价](https://doi.org/10.18653/v1/2020.acl-main.448)。见于*第58届计算语言学协会年会论文集*，第4984–4997页，在线。计算语言学协会。
- en: 'Methani et al. (2020) Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, and
    Pratyush Kumar. 2020. Plotqa: Reasoning over scientific plots. In *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)*.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Methani et al. (2020) Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, 和 Pratyush
    Kumar. 2020. Plotqa: 在科学图表上的推理。见于*IEEE/CVF冬季计算机视觉应用会议论文集 (WACV)*。'
- en: Najdenkoska et al. (2023) Ivona Najdenkoska, Xiantong Zhen, and Marcel Worring.
    2023. [Meta learning to bridge vision and language models for multimodal few-shot
    learning](https://openreview.net/forum?id=3oWo92cQyxL). In *The Eleventh International
    Conference on Learning Representations*.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Najdenkoska et al. (2023) Ivona Najdenkoska, Xiantong Zhen, 和 Marcel Worring.
    2023. [元学习桥接视觉和语言模型以实现多模态少样本学习](https://openreview.net/forum?id=3oWo92cQyxL)。见于*第十一届国际学习表征会议*。
- en: Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. Training language models to follow instructions with human feedback.
    *arXiv preprint arXiv:2203.02155*.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang et al. (2022) Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll
    L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, 等. 2022. 训练语言模型以遵循人类反馈的指令。*arXiv预印本 arXiv:2203.02155*。
- en: 'Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In
    *Proceedings of the 40th annual meeting of the Association for Computational Linguistics*,
    pages 311–318.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, 和 Wei-Jing
    Zhu. 2002. Bleu: 一种自动评价机器翻译的方法。见于*第40届计算语言学协会年会论文集*，第311–318页。'
- en: 'Poco and Heer (2017) Jorge Poco and Jeffrey Heer. 2017. Reverse-engineering
    visualizations: Recovering visual encodings from chart images. In *Computer graphics
    forum*, volume 36, pages 353–363\. Wiley Online Library.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Poco and Heer (2017) Jorge Poco 和 Jeffrey Heer. 2017. 逆向工程可视化：从图表图像中恢复视觉编码。见于*计算机图形学论坛*，第36卷，第353–363页。Wiley在线图书馆。
- en: 'del Puy Pérez-Echeverría et al. (2018) Mª del Puy Pérez-Echeverría, Yolanda
    Postigo, and Cristina Marín. 2018. [Understanding of graphs in social science
    undergraduate students: selection and interpretation of graphs](https://doi.org/10.1080/03323315.2018.1440248).
    *Irish Educational Studies*, 37(1):89–111.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: del Puy Pérez-Echeverría et al. (2018) Mª del Puy Pérez-Echeverría, Yolanda
    Postigo, 和 Cristina Marín. 2018. [社会科学本科生对图表的理解：图表的选择和解释](https://doi.org/10.1080/03323315.2018.1440248)。*爱尔兰教育研究*，37(1):89–111。
- en: Radford et al. (2019) Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario
    Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford 等（2019）Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei,
    和 Ilya Sutskever. 2019. 语言模型是无监督的多任务学习者。
- en: Raffel et al. (2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. [Exploring
    the limits of transfer learning with a unified text-to-text transformer](http://jmlr.org/papers/v21/20-074.html).
    *Journal of Machine Learning Research*, 21(140):1–67.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel 等（2020）Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan
    Narang, Michael Matena, Yanqi Zhou, Wei Li, 和 Peter J. Liu. 2020. [探索统一的文本到文本变换器的迁移学习极限](http://jmlr.org/papers/v21/20-074.html)。
    *机器学习研究期刊*，21(140)：1–67。
- en: 'Smith et al. (2016) Aaron Smith, Christian Hardmeier, and Joerg Tiedemann.
    2016. [Climbing mont BLEU: The strange world of reachable high-BLEU translations](https://aclanthology.org/W16-3414).
    In *Proceedings of the 19th Annual Conference of the European Association for
    Machine Translation*, pages 269–281.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smith 等（2016）Aaron Smith, Christian Hardmeier, 和 Joerg Tiedemann. 2016. [攀登
    mont BLEU：可达高 BLEU 翻译的奇怪世界](https://aclanthology.org/W16-3414)。在 *第19届欧洲机器翻译协会年会论文集*，页面269–281。
- en: Sun et al. (2022) Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and
    Xipeng Qiu. 2022. Black-box tuning for language-model-as-a-service. In *ICML*,
    volume 162 of *Proceedings of Machine Learning Research*, pages 20841–20855\.
    PMLR.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等（2022）Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, 和 Xipeng Qiu.
    2022. 语言模型即服务的黑箱调优。在 *ICML*，*机器学习研究进展*第162卷，页面20841–20855。PMLR。
- en: Tan et al. (2015) Liling Tan, Jon Dehdari, and Josef van Genabith. 2015. [An
    awkward disparity between BLEU / RIBES scores and human judgements in machine
    translation](https://aclanthology.org/W15-5009). In *Proceedings of the 2nd Workshop
    on Asian Translation (WAT2015)*, pages 74–81, Kyoto, Japan. Workshop on Asian
    Translation.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等（2015）Liling Tan, Jon Dehdari, 和 Josef van Genabith. 2015. [BLEU / RIBES
    分数与机器翻译中的人工判断之间的尴尬差距](https://aclanthology.org/W15-5009)。在 *第2届亚洲翻译研讨会（WAT2015）论文集*，页面74–81，日本京都。亚洲翻译研讨会。
- en: Wei et al. (2022a) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2022a. Finetuned language
    models are zero-shot learners. In *International Conference on Learning Representations*.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022a）Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu,
    Brian Lester, Nan Du, Andrew M Dai, 和 Quoc V Le. 2022a. 微调语言模型是零样本学习者。在 *国际学习表征会议*。
- en: Wei et al. (2022b) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi,
    Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in
    large language models. *arXiv preprint arXiv:2201.11903*.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等（2022b）Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi,
    Quoc Le, 和 Denny Zhou. 2022b. 思维链提示在大型语言模型中引发推理。 *arXiv 预印本 arXiv:2201.11903*。
- en: 'Whitaker and Jacobbe (2017) Douglas Whitaker and Tim Jacobbe. 2017. [Students’
    understanding of bar graphs and histograms: Results from the locus assessments](https://doi.org/10.1080/10691898.2017.1321974).
    *Journal of Statistics Education*, 25(2):90–102.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whitaker 和 Jacobbe（2017）Douglas Whitaker 和 Tim Jacobbe. 2017. [学生对条形图和直方图的理解：来自定位评估的结果](https://doi.org/10.1080/10691898.2017.1321974)。
    *统计教育期刊*，25(2)：90–102。
- en: Zhou et al. (2022) Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu.
    2022. [Learning to prompt for vision-language models](https://openreview.net/forum?id=OgCcfc1m0TO).
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等（2022）Kaiyang Zhou, Jingkang Yang, Chen Change Loy, 和 Ziwei Liu. 2022.
    [学习如何为视觉语言模型进行提示](https://openreview.net/forum?id=OgCcfc1m0TO)。
- en: Appendix A Appendices
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1 Extended Related Work
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 扩展相关工作
- en: A.1.1 Chart Data Extraction
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.1.1 图表数据提取
- en: Information Extraction (IE) from charts is a challenging task due to variations
    in chart types and styles. Early works in this area use a combination of different
    approaches to creating a pipeline that extracts data from chart (Poco and Heer,
    [2017](#bib.bib40); Balaji et al., [2018](#bib.bib2)). These feature-based approaches
    are shown to not generalize well on various kinds of charts. Therefore, more recent
    works adopt deep learning models to extract data from charts e.g. Choi et al.
    ([2019](#bib.bib9)) use the idea of detecting bounding boxes for bar charts. Liu
    et al. ([2019](#bib.bib30)) propose a recurrent network for pie charts. These
    methods achieved significant improvements. However, they are specifically designed
    for one type of chart. To overcome this, Luo et al. ([2021](#bib.bib32)) proposes
    a hybrid framework that can generate data from different types of charts. ChartOCR
    (Luo et al., [2021](#bib.bib32)) achieves the SOTA results at the time, but similar
    to other pipeline-based methods, the error will propagate through the pipeline,
    hence can affect the performance drastically. As end-to-end approaches in other
    computer vision tasks gained attention, Liu et al. ([2022b](#bib.bib28)) propose
    an end-to-end model which was based on Pix2Struct (Lee et al., [2022](#bib.bib25))
    architecture and further tuned on chart derendering and math reasoning. Recently,
    Masry et al. ([2023](#bib.bib33)) propose *UniChart*, an end-to-end pretrained
    chart model which achieves state-of-the-art result on chart-to-table generation
    task. As the focus of this paper is on constructing prompts for the chart comprehension
    tasks, further exploration of end-to-end data extraction approaches is left for
    future works.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中提取信息（IE）是一个具有挑战性的任务，因为图表类型和风格的变化。早期的工作使用不同的方法组合来创建从图表中提取数据的管道（Poco 和 Heer，[2017](#bib.bib40)；Balaji
    等，[2018](#bib.bib2)）。这些基于特征的方法在各种类型的图表上表现不佳。因此，最近的工作采用深度学习模型来从图表中提取数据，例如 Choi
    等人 ([2019](#bib.bib9)) 使用了检测条形图边界框的思路。Liu 等人 ([2019](#bib.bib30)) 提出了用于饼图的递归网络。这些方法取得了显著的改进。然而，它们是专门为一种类型的图表设计的。为了解决这一问题，Luo
    等人 ([2021](#bib.bib32)) 提出了一个可以从不同类型的图表中生成数据的混合框架。ChartOCR（Luo 等人，[2021](#bib.bib32)）在当时取得了
    SOTA 结果，但与其他基于管道的方法类似，错误会在管道中传播，从而严重影响性能。由于其他计算机视觉任务中的端到端方法获得了关注，Liu 等人 ([2022b](#bib.bib28))
    提出了一个基于 Pix2Struct（Lee 等人，[2022](#bib.bib25)）架构的端到端模型，并进一步调整了图表反渲染和数学推理。最近，Masry
    等人 ([2023](#bib.bib33)) 提出了 *UniChart*，一个端到端预训练的图表模型，在图表到表格生成任务中达到了最先进的结果。由于本文的重点是构建图表理解任务的提示，进一步探索端到端数据提取方法将留待未来工作。
- en: A.2 VDTG Training Details
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 VDTG 训练细节
- en: We fine-tune UniChart Masry et al. ([2023](#bib.bib33)) model for 50K steps
    with a batch size of 80\. We use a learning rate of 1e-4 and 500 warmup steps.
    We evaluate the model every 1K steps and choose the best checkpoint for inference.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 UniChart Masry 等人 ([2023](#bib.bib33)) 模型进行了 50K 步的微调，批量大小为 80。我们使用了 1e-4
    的学习率和 500 步的预热步骤。我们每 1K 步评估一次模型，并选择最佳检查点用于推理。
- en: A.3 FCQA Prompt
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 FCQA 提示
- en: '[Table 6](#A1.T6 "In A.3 FCQA Prompt ‣ Appendix A Appendices ‣ Do LLMs Work
    on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization")
    illustrates our full demonstrations for the task of factoid chart question answering.
    The samples are selected carefully from the validation split of ChartQA Masry
    et al. ([2022](#bib.bib34)), each of them covers one question type that the InstructGPT
    model fails to answer presented in [Fig. 2](#S6.F2 "In 6.1 Demonstration Selection
    for FCQA ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for
    Chart Question Answering and Summarization").'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 6](#A1.T6 "在 A.3 FCQA 提示 ‣ 附录 A 附录 ‣ 大型语言模型是否适用于图表？为图表问答和总结设计少量示例提示") 说明了我们在事实图表问答任务中的完整演示。样本从
    ChartQA Masry 等人 ([2022](#bib.bib34)) 的验证集中精心挑选，每个样本覆盖一个 InstructGPT 模型未能回答的问题类型，这些问题展示在
    [图 2](#S6.F2 "在 6.1 FCQA 演示选择 ‣ 6 讨论 ‣ 大型语言模型是否适用于图表？为图表问答和总结设计少量示例提示") 中。'
- en: '| Index | Question | CCR Format: operands with visual attributes, operands
    without visual attributes, operators, reasoning, result | Question Type |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 索引 | 问题 | CCR 格式：具有视觉属性的操作数、没有视觉属性的操作数、操作符、推理、结果 | 问题类型 |'
- en: '| 1 | How many data points on the disapprove line are above 50? | The disapprove
    number 51 and 50 are greater than 50\. The answer is 2. | Complex Retrieval |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 不赞同线上的数据点中有多少个在 50 以上？ | 不赞同数 51 和 50 大于 50。答案是 2。 | 复杂检索 |'
- en: '| 2 | How much value of ’Mostly bad news’ increased from Jan. 2011 to Sept.
    2011? | The value of ’Mostly bad news’ in Jan. 2011 is 24 and in Sept. 2011 is
    61. So the increase is 61 - 24 = 37. The answer is 37. | Add/Substract |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 从2011年1月到2011年9月，“大多数坏消息”的值增加了多少？ | 2011年1月的“大多数坏消息”值为24，2011年9月为61。因此增加了61
    - 24 = 37。答案是37。 | 加/减 |'
- en: '| 3 | What’s the ratio of Lean Republican segment and Republican segment? |
    The value of Lean Republican segment is 39 and the value of Republican segment
    is 53. The ratio is 39 / 53 = 0.7358. The answer is 0.7358. | Divide |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 倾向共和党的群体与共和党的群体的比例是多少？ | 倾向共和党的群体的值为39，共和党的群体的值为53。比例是39 / 53 = 0.7358。答案是0.7358。
    | 除法 |'
- en: '| 4 | What’s the average value of the first two blue bars in the chart? | The
    first two blue bars are 30-34 years old with 0.35 and 25-29 years old with 0.31.
    The average value is ( 0.35 + 0.31 ) / 2 = 0.33. The answer is 0.33. | Visual
    Reasoning |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 图表中前两个蓝色条形的平均值是多少？ | 前两个蓝色条形分别是30-34岁时为0.35和25-29岁时为0.31。平均值是（0.35 +
    0.31）/ 2 = 0.33。答案是0.33。 | 视觉推理 |'
- en: '| 5 | What’s the total sum of peak points of all three lines? | The peak point
    of red line is 80, the peak point of yellow line is 68, the peak point of green
    line is 7. The total sum of peak points is 80 + 68 + 7 = 155. The answer is 155.
    | Compositional Reasoning |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 三条线的所有峰值点的总和是多少？ | 红线的峰值点为80，黄线的峰值点为68，绿线的峰值点为7。峰值点的总和是80 + 68 + 7 =
    155。答案是155。 | 组合推理 |'
- en: '| 6 | Is the average value of Andean Latin America and Cambodia more than the
    value of Thailand? | The value of Andean Latin America is 1.47 and the value of
    Cambodia is 0.77. So the average value of Andean Latin America and Cambodia is
    ( 1.47 + 0.77 ) / 2 = 1.12. The value of Thailand is 0.39. Since 1.12 > 0.39,
    the average value of Andean Latin America and Cambodia is more than the value
    of Thailand. The answer is Yes. | Boolean |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 安第斯拉丁美洲和柬埔寨的平均值是否高于泰国的值？ | 安第斯拉丁美洲的值为1.47，柬埔寨的值为0.77。因此，安第斯拉丁美洲和柬埔寨的平均值是（1.47
    + 0.77）/ 2 = 1.12。泰国的值为0.39。因为1.12 > 0.39，所以安第斯拉丁美洲和柬埔寨的平均值高于泰国的值。答案是是的。 | 布尔
    |'
- en: 'Table 6: Demonstrations for factoid chart question answering task. Samples
    are from the validation split of ChartQA Masry et al. ([2022](#bib.bib34)) dataset.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：事实图表问题回答任务的演示样本。样本来自ChartQA Masry等（[2022](#bib.bib34)）数据集的验证集。
- en: A.4 LCQA Prompt
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 LCQA 提示
- en: We present all the demonstrations used for LCQA task in [Table 7](#A1.T7 "In
    A.4 LCQA Prompt ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization"). The 6 samples are selected
    carefully from the validation split of OpenCQA Kantharaj et al. ([2022a](#bib.bib21))
    dataset.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[表7](#A1.T7 "在 A.4 LCQA 提示 ‣ 附录 A 附录 ‣ LLMs 是否在图表上有效？为图表问题回答和总结设计少量示例提示")中展示了用于LCQA任务的所有演示样本。6个样本是从OpenCQA
    Kantharaj等（[2022a](#bib.bib21)）数据集的验证集中精心挑选出来的。
- en: '| Index | Input | Output | Question Type |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 索引 | 输入 | 输出 | 问题类型 |'
- en: '| 1 | What opinion do the public have about earth warming? Title: Is there
    solid evidence the earth is warming? Mixed evidencel Total U.S population Context:
    Is there solid evidence the earth is warming?  Mixed evidencel  Yes. because
    of  Yes. because of  Yes but don’t  No  Some evidencel  human activity
     natura patterns  know cause  Don’t know  Total U.S population 
    47 %  18%  6% 21 %  8%  Unaffliated  58%  11%  6% 18% 
    7%  White mainline Protestants  48%  19%  6% 19%  8%  White
    non-Hispanic Catholics  44%  20%  6% 22%  8%  Black Protestants
     39%  36%  5% 15%  5%  White evangelical Protestants  17% 
    7%  11%  34%  31%  The Pew Forum on Religion & Public Life  pewforum.
    ORG | The unaffiliated ( 58 % ) are the most likely among the religious groups
    studied to say there is solid evidence the earth is warming because of human activity
    . White evangelical Protestants are the most likely to say there is no solid evidence
    the earth is warming ( 31 % ) , and the least likely to believe that humans have
    contributed to heating up the planet ( 34 % ) . While only 39 % of black Protestants
    say global warming is a result of human activity , they are , however , the least
    likely of the religions studied to deny global warming is occurring ( 15 % ) .
    | Describe and Summary |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 公众对地球变暖有什么看法？标题：地球变暖是否有确凿证据？混合证据 总体美国人口情况：地球变暖是否有确凿证据？ 是的，因为 是的，因为 是的，但不知道原因
    不知道 一些证据 人类活动 自然模式 不知道 总体美国人口 47% 18% 6% 21% 8% 无宗教信仰者 58% 11% 6% 18% 7% 白人主流新教徒
    48% 19% 6% 19% 8% 白人非西班牙裔天主教徒 44% 20% 6% 22% 8% 黑人新教徒 39% 36% 5% 15% 5% 白人福音派新教徒
    17% 7% 11% 34% 31% 皮尤宗教与公共生活论坛 pewforum.org | 无宗教信仰者（58%）是被调查宗教群体中最可能认为地球变暖有确凿证据的，他们认为这是由于人类活动造成的。白人福音派新教徒最可能认为地球变暖没有确凿证据（31%），并且最不可能相信人类对全球变暖有贡献（34%）。虽然只有39%的黑人新教徒认为全球变暖是人类活动造成的，但他们是最不可能否认全球变暖正在发生的宗教群体（15%）。|
    描述与总结 |'
- en: '| 2 | Among families with opt-out moms, how is the difference in education
    between husbands and wives? Title: About One-in-Ten Highly Educated Mothers ’Opt
    Out’ Among all educated moms ’opt-out’ moms Context: About One-in-Ten Highly Educated
    Mothers "Opt Out"  Among all highly  Among all  educated moms  "opt-out"
    moms  9%  are "opt-out"  moms  37% More education  than husband
     45  Same  education  as hus band  18  Less education  than
    husband  "Highly educated mothers have at least a Master’s de gree, are ages
    18 69 and  are living with the ir own child(ren) working younger than 18\.
    family Among these moms, "opt-out"  mothers living are married with working
    hus band, annual family Among income above $7 5, .000  and say they are not
    working in forder to care for family. a professional degree is  considered
    equivalent to a Ph.D for the purpose of the compa rison of spousal  educational
    attainment.  Source: Pew Research Center analysis of March Current Population
    Surveys  Integrated Public Use Microdata Series (IPUMS CPS), 2012 2013 
    PEW RESEARCH CENTER | In 37 % of the cases , it is the stay - at - home wives
    who actually have a higher level of education . In 45 % of these families , the
    spouses have equal educational attainment , and in about 18 % of the cases , the
    husbands have more education than their wives . | Comparative |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 在选择退出的妈妈家庭中，丈夫和妻子之间的教育差异如何？标题：关于十分之一的高学历母亲选择退出的情况 在所有选择退出的高学历妈妈中，9% 是选择退出的妈妈
    37% 的母亲比丈夫接受了更多的教育 45% 的母亲与丈夫接受了相同的教育 18% 的母亲比丈夫接受了更少的教育 “高学历母亲至少拥有硕士学位，年龄在18至69岁之间，并与自己的孩子同住，其中一些孩子还未满18岁。这些妈妈中，有选择退出的母亲是已婚的，丈夫有工作，家庭年收入超过
    $75,000，并表示她们不工作是为了照顾家庭。为了比较配偶的教育水平，专业学位被视为与博士学位相当。来源：皮尤研究中心对2012-2013年3月当前人口调查的分析，综合公共使用微数据系列（IPUMS
    CPS），皮尤研究中心 | 在37%的情况下，选择待在家中的妻子实际上拥有更高的教育水平。在45%的家庭中，配偶之间的教育水平相等，而在约18%的情况下，丈夫的教育水平高于妻子。|
    比较 |'
- en: '| 3 | What was the trend among registered Hispanic voters about Trump’s work?
    Title: Most Hispanic voters disapprove of Trump, dissatisfied with nation’s direction
    Context: Most Hispanic voters disapprove of Trump, dissatisfied with nation’s
    direction  % who are country with the today way things are  % who job president
    of the way Trump is handling  going in the country today  his job as president
     Disapprove  Approve  Not so  Not so  Very strongly strongly Very
     Dissatisfied  Satisfied  NET  NET  strongly  strongly  All
    Hispanic RVs  68  51  17 8 23  30  67  32  Dem/Lean Dem 
    93  73  20 3 4  80  19  1211 17  75  Rep/Lean Rep  22
     58  45  54  Note: Based on Hispanic registered voters. Share of respondents
    who didn’t offer an answer not shown. Figures may not add to NET due to  rounding.
     Source: National Survey of Latinos conducted Dec. 3-23, 2019  PEW RESEARCH
    CENTER | About two - thirds of Hispanic registered voters ( 68 % ) disapprove
    of the job Trump is doing as president , including 51 % who disapprove very strongly
    . The 30 % of Hispanic voters who approve of Trump includes 23 % who approve strongly
    | Discover |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 注册的西班牙裔选民对特朗普工作的趋势如何？标题：大多数西班牙裔选民不赞成特朗普，对国家方向不满 上下文：大多数西班牙裔选民不赞成特朗普，对国家方向不满
     对国家现状的满意度  对特朗普总统工作的满意度  认为国家正朝着正确方向前进  认为特朗普担任总统的表现如何  不满意 
    满意  不太  不太  非常强烈 强烈 非常  不满意  满意  净值  净值  强烈  强烈 
    所有西班牙裔登记选民  68  51  17 8 23  30  67  32  民主党/倾向民主党  93
     73  20 3 4  80  19  1211 17  75  共和党/倾向共和党  22  58
     45  54  注：基于西班牙裔登记选民。未给出答案的受访者份额未显示。由于四舍五入，数据可能与净值不符。 来源：2019年12月3日至23日进行的全国拉丁裔调查
     皮尤研究中心 | 约三分之二的西班牙裔登记选民（68%）不赞成特朗普担任总统的表现，其中51%的人表示非常不满。30%赞成特朗普的西班牙裔选民中，23%表示非常赞成
    | 发现 |'
- en: '| 4 | Describe the trend in job availability to people over the past years.
    Title: Job Availability in Your Area 2001 2008 Context: Job Availability in Your
    Area  2001 2008  Difficult to find  Plenty of jobs  66  60 
    480  40  20  Q  2001 2002 2003 2004 2005 2006 2007 2008 | Overall
    , a majority ( 53 % ) says that jobs are difficult to find in their community
    while only about a third ( 34 % ) says there are plenty of jobs available . The
    percentage saying that jobs are difficult to find locally has increased modestly
    since February 2007 ( 48 % ) . In October 2003 , 66 % said that jobs were difficult
    to find , the highest percentage expressing that view since the start of the Bush
    administration . | Describe and Summary |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 描述过去几年人们对工作机会的趋势。标题：您所在地区的工作机会 2001-2008 上下文：您所在地区的工作机会  2001-2008
     难以找到  工作充足  66  60  480  40  20  Q  2001 2002 2003
    2004 2005 2006 2007 2008 | 总体来看，大多数人（53%）表示在他们的社区中工作难以找到，而只有大约三分之一（34%）表示有大量工作机会。自2007年2月以来，表示本地工作难以找到的百分比有所温和增加（48%）。在2003年10月，66%的人表示工作难以找到，这是自布什政府上台以来的最高比例。
    | 描述和总结 |'
- en: '| 5 | How was the public’s attention on different news? Title: News Interest
    vs. News Coverage Context: News Interest vs. News Coverage  April 13-19 
    Pirates  16  34  Economy 27  18  C  Tea parties  3  6
     Obama abroad  3  Cuba policy  2  CIA memos  Interest: percent
    who named story as most closely followed  Coverage: percent of news coverage
    devoted to story | 34 % say they followed stories about the continued attempts
    by pirates to hijack ships more closely than any other story last week , while
    27 % say they followed stories about the U.S. economy most closely . 9 % say they
    followed the tea party protests more closely than any other story . | Comparative
    |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 公众对不同新闻的关注程度如何？标题：新闻兴趣与新闻报道 上下文：新闻兴趣与新闻报道  4月13日至19日  海盗  16
     34  经济 27  18  C  茶会  3  6  奥巴马出国  3  古巴政策 
    2  CIA备忘录  兴趣：将该故事列为最密切关注的故事的百分比  报道：新闻报道中涉及该故事的百分比 | 34%的人表示他们比其他任何故事更密切关注了海盗继续劫持船只的故事，而27%的人表示他们最密切关注了关于美国经济的故事。9%的人表示他们比其他任何故事更密切关注了茶会抗议活动。
    | 比较 |'
- en: '| 6 | Does China believe that Japan has sufficiently apologized for their actions
    during WW2? Title: Chinese unchanged in belief that Japan has yet to sufficiently
    apologize for actions during World War I % Chinese saying Japan has for its military
    actions during the 1930s and 1940S Context: Chinese unchanged in belief that Japan
    has yet to  sufficiently apologize for actions during World War I  % Chinese
    saying Japan has for its military actions during the 1930s and  1940S  Apologized
    No apology  Not apologized  sufficiently  sufficiently necessary 
    2016  77%  10%  2%  2013  78  2008  76  8  2006 
    81  Source: Spring 2016 Global Attitudes Survey Q84\.  PEW RESEARCH CENTER
    | Roughly three - quarters ( 77 % ) say Japan has not adequately expressed regret
    , and such Chinese sentiment is largely unchanged since 2006 . Only 10 % believe
    Tokyo has apologized enough . | Discover |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 中国是否认为日本已经充分为其在二战期间的行为道歉？标题：**中国人**始终认为日本尚未为其在第一次世界大战中的行为做出充分的道歉 % **中国人**称日本已为其在1930年代和1940年代的军事行动道歉
    背景：**中国人**始终认为日本尚未  充分道歉  % **中国人**称日本已为其1930年代和  1940年代  的军事行动 
    道歉 未道歉  未充分  充分  必要  2016  77%  10%  2%  2013  78 
    2008  76  8  2006  81  来源：2016年春季全球态度调查 Q84\.  PEW RESEARCH
    CENTER | 大约三分之四（77%）的人表示日本未充分表达悔意，而这种**中国**情绪自2006年以来基本未变。仅有10%的人认为东京已经道歉足够。 |
    发现 |'
- en: 'Table 7: Demonstrations for long-form chart question answering task. Samples
    are from the validation split of the OpenCQA Kantharaj et al. ([2022a](#bib.bib21))
    dataset. The chart images are provided in [Table 10](#A1.T10 "In A.7 Consistency
    of Generated Output with Demonstrations ‣ Appendix A Appendices ‣ Do LLMs Work
    on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization").'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：用于长格式图表问题回答任务的示例。样本来自OpenCQA Kantharaj等（[2022a](#bib.bib21)）数据集的验证集。图表图像见[表10](#A1.T10
    "在A.7 生成输出与示例的一致性 ‣ 附录A 附录 ‣ LLM在图表上的工作？为图表问题回答和总结设计少量示例提示")。
- en: A.5 Chart Summarization Prompt
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.5 图表总结提示
- en: '[Table 8](#A1.T8 "In A.5 Chart Summarization Prompt ‣ Appendix A Appendices
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization") presents all the demonstrations we use for the task of chart
    summarization. All 6 demonstrations are from Chart-to-Text dataset Kantharaj et al.
    ([2022b](#bib.bib22)). The first three samples are taken from validation set of
    Pew dataset, whilst the last 3 from Statista dataset.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8](#A1.T8 "在A.5 图表总结提示 ‣ 附录A 附录 ‣ LLM在图表上的工作？为图表问题回答和总结设计少量示例提示")展示了我们用于图表总结任务的所有示例。所有6个示例均来自Chart-to-Text数据集Kantharaj等（[2022b](#bib.bib22)）。前三个样本来自Pew数据集的验证集，最后三个样本来自Statista数据集。'
- en: '| Index | Input | Output | Summarization Type |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 索引 | 输入 | 输出 | 总结类型 |'
- en: '| 1 | Seven-in-ten Americans said in 2019 that their personal info was less
    secure than five years earlier % ofU.S adults who said they felt as iftheir personal
    information was than it was five years ago  Seven-in-ten Americans said in
    2019 that their personal info was less secure than five years earlier % ofU.S
    adults who said they felt as iftheir personal information was than it was five
    years ago More About Less secure the same secure 6 24 70 Note: Those who did not
    give an answer are not shown. Source: Survey conducted June 3- 17, 2019\. "Americans
    and Privacy: Concerned, Confused and Feeling Lack of Control Over Their Personal
    Information PEW RESEARCH CENTER | Before the outbreak, Americans strongly believed
    their personal data was more vulnerable than in the past. In a June 2019 survey,
    70% of Americans said their personal information was less secure than it was five
    years earlier. Just 6% of Americans said they felt their information was more
    secure than in the past, while 24% said their personal information was about as
    secure as it was five years earlier. Experts have suggested that data security
    could be threatened for companies shifting to remote work – as well as ordinary
    people who are spending more time online – during the coronavirus outbreak. |
    Perceptual and Cognitive |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2019年七成美国人表示他们的个人信息比五年前更不安全 美国成年人认为个人信息比五年前更不安全的百分比  2019年七成美国人表示他们的个人信息比五年前更不安全
    美国成年人认为个人信息比五年前更不安全的百分比 了解更多 更不安全 相同 不太安全 6 24 70 注：未给出答案的人未显示。 来源：2019年6月3日至17日进行的调查。
    “美国人和隐私：担忧、困惑以及对个人信息缺乏控制”皮尤研究中心 | 疫情爆发前，美国人强烈认为他们的个人数据比过去更脆弱。在2019年6月的一项调查中，70%的美国人表示他们的个人信息比五年前更不安全。仅有6%的美国人表示他们的信息比过去更安全，而24%的人认为他们的个人信息和五年前差不多。专家们建议，在冠状病毒爆发期间，数据安全可能会受到威胁——这不仅是对转向远程工作的公司，也包括花更多时间在线的普通人。
    | 知觉与认知 |'
- en: '| 2 | Figure by Race, Ethnicity and Citizenship, 2007  Figure Composition
    of Sentenced Federal Offenders, by Race, Ethnicity and Citizenship, 2007 196 ofsentenced
    offenders) U.S citizen Non-U.S citizen 40 29 25 21 Hispanic White Black Notes:
    Percenta ges may not total due to rounding. The category "Other" is excluded Source:
    Pew Hispanic Center analysis of United States Sentencing Source: Commission Monitoring
    offederal Criminal Sentences data, 2007 | Sharp growth in illegal immigration
    and increased enforcement of immigration laws have dramatically altered the ethnic
    composition of offenders sentenced in federal courts. In 2007, Latinos accounted
    for 40% of all sentenced federal offenders‚Äîmore than triple their share (13%)
    of the total U.S. adult population. The share of all sentenced offenders who were
    Latino in 2007 was up from 24% in 1991, according to an analysis of data from
    the United States Sentencing Commission (USSC) by the Pew Hispanic Center, a project
    of the Pew Research Center. | Visual Encodding |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2007年按种族、民族和国籍分类的图表  2007年按种族、民族和国籍分类的被判刑联邦罪犯的组成 196名被判刑罪犯）美国公民
    非美国公民 40 29 25 21 西班牙裔 白人 黑人 注：百分比可能由于四舍五入而不总和。类别“其他”被排除。 来源：皮尤西班牙裔中心对美国刑事判决数据的分析
    来源：联邦刑事判决数据监控，2007 | 非法移民的急剧增长和移民法律执法的加强显著改变了被判刑联邦罪犯的种族组成。2007年，拉丁裔占所有被判刑联邦罪犯的40%——是他们在美国成人总人口中份额（13%）的三倍多。根据皮尤研究中心的皮尤西班牙裔中心对美国刑事判决委员会（USSC）数据的分析，2007年被判刑罪犯中拉丁裔的比例比1991年的24%有所上升。
    | 视觉编码 |'
- en: '| 3 | Half of voters, including a majority of Biden supporters, expect it will
    be difficult to vote in this year’s election % ofregistered voters wwo expect
    voting in the November elections to be  Half of voters, including a majority
    of Biden supporters, expect it will be difficult to vote in this year’s election
    % ofregistered voters wwo expect voting in the November elections to be Republican
    Support Democratic Support All voters Republican Support Democratic Support candidate
    candidate 90 Easy 85 83 64 50 40 10 Difficult 15 17 35 49 60 Oct Aug Oct Aug Oct
    Aug 18 -20 ’18 20 1’8 –20 House Presidential election election Notes: Based on
    registered voters Based on supporters of Republican fand Democratic House candidates
    lin 2018 Trump and Biden supporters in 2020 No answer responses snot shown. Source:
    Survey of U.S adults conducted July 27-Aug 2 2020 PEW RESEARCH CENTER | Far more
    voters expect voting to be difficult this year than in 2018, according to a survey
    of registered voters conducted July 27 to Aug. 2\. Around half of registered voters
    (49%) said they expect voting to be very or somewhat difficult this year, while
    the other half (50%) expect it to be very or somewhat easy. That represents a
    major change from October 2018, when just 15% of voters said they expected voting
    in that year‚Äôs midterms to be difficult and 85% said they expected it to be
    easy. | Statistical and Comparative |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 一半的选民，包括大多数拜登支持者，预计今年的选举投票将会困难 % 的登记选民预计在11月的选举中投票将会 一半的选民，包括大多数拜登支持者，预计今年的选举投票将会困难
    % 的登记选民预计在11月的选举中投票将会 共和党支持 民主党支持 所有选民 共和党支持 民主党支持 候选人 候选人 90 容易 85 83 64 50 40
    10 困难 15 17 35 49 60 10月 8月 10月 8月 10月 8月 18 -20 ’18 20 1’8 –20 众议院 总统选举 选举 说明：基于登记选民
    基于2018年特朗普和2020年拜登支持者的共和党和民主党众议院候选人 不显示未回答的响应。 来源：2020年7月27日至8月2日对美国成年人进行的调查 PEW研究中心
    | 根据2020年7月27日至8月2日进行的登记选民调查，比2018年有更多选民预计今年投票将会困难。大约一半的登记选民（49%）表示，他们预计今年的投票将非常或有些困难，而另一半（50%）预计投票将非常或有些容易。这与2018年10月大相径庭，当时仅有15%的选民认为那一年的中期选举投票会困难，85%的人认为投票会容易。
    | 统计与比较 |'
- en: '| 4 | Turnover from retail sale of bakery products and cereals ( including
    rice and pasta ) in the United Kingdom ( UK ) from 2008 to 2018 ( in million GBP
    ) Context: Year & Turnover in million GBP  2018 & 21890  2017 & 21433
     2016 & 20757  2015 & 22187  2014 & 20372  2013 & 20352 
    2012 & 20078  2011 & 18818  2010 & 17875  2009 & 16719  2008
    & 15816 . | This statistic shows the total annual turnover of the retail sale
    of bakery products and cereals ( including rice and pasta products ) in the United
    Kingdom from 2008 to 2018 . Turnover has grown steadily , reaching a peak of approximately
    22 billion British pounds in 2015 before declining the following year . By 2018
    turnover had almost completely recovered and amounted to 21.9 billion pounds .
    | Perceptual and Cognitive |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 从2008年到2018年，英国（UK）面包产品和谷物（包括米饭和意大利面）的零售销售额（以百万英镑计） 背景：年份 & 销售额（百万英镑）
    2018 & 21890  2017 & 21433  2016 & 20757  2015 & 22187  2014
    & 20372  2013 & 20352  2012 & 20078  2011 & 18818  2010 &
    17875  2009 & 16719  2008 & 15816。 | 该统计数据展示了从2008年到2018年，英国面包产品和谷物（包括米饭和意大利面产品）的零售销售总额。销售额稳步增长，在2015年达到约220亿英镑的峰值，然后在次年有所下降。到2018年，销售额几乎完全恢复，达到了219亿英镑。
    | 感知与认知 |'
- en: '| 5 | Number of nights spent camping or in caravans in Great Britain in 2019
    , by type ( in millions ) Context: type & Nights spent in millions  Glamping/alternative
    accommodation e.g. yurt, tipi, ecopod & 1.7  Static caravan (owned) & 9.4
     Tent & 12.5  Static caravan (rented) & 16.8  Touring caravans
    (towed/campervan/motorhome) & 19.8 | This statistic shows the number of nights
    spent camping or in caravans in Great Britain in 2019 , by type . Almost 20 million
    nights were spent by domestic tourists in touring caravans in Great Britain ,
    while 12.5 million nights were spent camping in tents . | Statistical and Comparative
    |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 2019年大不列颠在露营或房车中过夜的次数，按类型分类（以百万计） 背景：类型 & 过夜次数（百万计） 豪华露营/替代住宿，例如帐篷、尖顶帐篷、生态舱
    & 1.7  固定房车（自有） & 9.4  帐篷 & 12.5  固定房车（租赁） & 16.8  旅行房车（拖挂式/房车/营地车）
    & 19.8 | 该统计数据展示了2019年大不列颠在露营或房车中过夜的次数，按类型分类。国内游客在旅行房车中过夜近2000万次，而在帐篷中露营的次数为1250万次。
    | 统计与比较 |'
- en: '| 6 | Barbados : National debt in relation to gross domestic product ( GDP
    ) from 2015 to 2025 Context: Year & National debt in relation to GDP  2025*
    & 100.11%  2024* & 105.68%  2023* & 111.34%  2022* & 117.24% 
    2021* & 124.53%  2020 & 134.09%  2019 & 122.22%  2018 & 125.59%
     2017 & 158.26%  2016 & 149.45%  2015 & 147.02% | This statistic
    shows the national debt of Barbados from 2015 to 2020 in relation to the gross
    domestic product ( GDP ) , with projections up until 2025 . The figures refer
    to the whole country and include the debts of the state , the communities , the
    municipalities and the social insurances . In 2020 , the national debt of Barbados
    amounted to approximately 134.09 percent of the GDP . | Visual Encodding |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 巴巴多斯：2015年至2025年与国内生产总值（GDP）相关的国家债务 背景：年份 & 与GDP相关的国家债务  2025* &
    100.11%  2024* & 105.68%  2023* & 111.34%  2022* & 117.24% 
    2021* & 124.53%  2020 & 134.09%  2019 & 122.22%  2018 & 125.59%
     2017 & 158.26%  2016 & 149.45%  2015 & 147.02% | 该统计数据显示了巴巴多斯2015年至2020年国家债务与国内生产总值（GDP）的关系，并且提供了到2025年的预测数据。这些数据涉及整个国家，包括国家、社区、城市和社会保险的债务。2020年，巴巴多斯的国家债务约占GDP的134.09%。
    | 可视编码 |'
- en: 'Table 8: Demonstrations for chart summarization task. Samples are obtained
    from the validation split of Chart-to-Text Kantharaj et al. ([2022b](#bib.bib22))
    dataset with the first three from Pew, and the last three from Statista. All the
    chart images are provided in [Table 11](#A1.T11 "In A.7 Consistency of Generated
    Output with Demonstrations ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization").'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：图表摘要任务的示例。样本来自Chart-to-Text Kantharaj等人的验证集（[2022b](#bib.bib22)），前三个来自Pew，后三个来自Statista。所有图表图像见[表11](#A1.T11
    "在A.7 生成输出与示例的一致性 ‣ 附录A 附录 ‣ LLM在图表上的表现？为图表问答和摘要设计少量示例提示")。
- en: A.6 Visual Data Table Generator (VDTG)
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.6 可视数据表生成器（VDTG）
- en: There are two types of visual data tables that we constructed to train the model,
    as shown in [Fig. 4](#A1.F4 "In A.6 Visual Data Table Generator (VDTG) ‣ Appendix
    A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question
    Answering and Summarization").
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了两种类型的可视数据表来训练模型，如[图4](#A1.F4 "在A.6 可视数据表生成器（VDTG） ‣ 附录A 附录 ‣ LLM在图表上的表现？为图表问答和摘要设计少量示例提示")所示。
- en: '[Table 9](#A1.T9 "In A.6 Visual Data Table Generator (VDTG) ‣ Appendix A Appendices
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization") shows some samples outputs from our proposed VDTG module.
    We observe that the first two cases the VDTG model can generate the correct colors
    and positions of the labels. In the $3$-th case, the model also makes an error
    in generating blue instead of the correct color is gray.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '[表9](#A1.T9 "在A.6 可视数据表生成器（VDTG） ‣ 附录A 附录 ‣ LLM在图表上的表现？为图表问答和摘要设计少量示例提示")展示了我们提出的VDTG模块的一些输出示例。我们观察到，在前两种情况下，VDTG模型可以生成正确的标签颜色和位置。在第$3$种情况下，模型也出现了错误，生成了蓝色而不是正确的颜色灰色。'
- en: '| Index | Chart Image | Generated Visual Data Table |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 索引 | 图表图像 | 生成的可视数据表 |'
- en: '| 1 | ![[Uncaptioned image]](img/d4ef412b53cce76dc60022968142d4e8.png)  | Country
    &#124; Human Rights Volations, 2012  Central African Republic (red) &#124;
    8.5  Iraq (purple) &#124; 8.3  Gabon (Teal) &#124; 6.8  Suriname
    (orange) &#124; 5.3  Peru (gray) &#124; 4.9 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 1 | ![[无标题图像]](img/d4ef412b53cce76dc60022968142d4e8.png)  | 国家 &#124; 人权侵犯，2012
     中非共和国（红色）&#124; 8.5  伊拉克（紫色）&#124; 8.3  加蓬（青色）&#124; 6.8 
    苏里南（橙色）&#124; 5.3  秘鲁（灰色）&#124; 4.9 |'
- en: '| 2 | ![[Uncaptioned image]](img/22e2076bd3d9a629d7a578b10a759366.png)  | Characteristic
    &#124; Nominal (blue) &#124; Real Terms (navy blue)  2019/20 &#124; 11.97
    &#124; 12.11  2018/19 &#124; 11.35 &#124; 11.57  2017/18 &#124; 11.94
    &#124; 11.76  2016/17 &#124; 11.6 &#124; 12.25  2015/16 &#124; 11.34
    &#124; 12.3  2014/15 &#124; 12.46 &#124; 13.55  2013/14 &#124; 11.62
    &#124; 12.97  2012/13 &#124; 12.76 &#124; 14.43  2011/12 &#124; 12.57
    &#124; 14.35  2010/11 &#124; 13.06 &#124; 15.24  2009/10 &#124; 13.22
    &#124; 15.76  2008/09 &#124; 12.46 &#124; 15.03  2007/08 &#124; 11.94
    &#124; 14.76  2006/07 &#124; 11.43 &#124; 14.48  2005/06 &#124; 10.87
    &#124; 14.21  2004/05 &#124; 10.03 &#124; 13.36  2003/04 &#124; 9.76
    &#124; 13.3  2002/03 &#124; 9.37 &#124; 13.03  2001/02 &#124; 8.66
    &#124; 12.42  2000/01 &#124; 7.89 &#124; 11.38  1999/00 &#124; 7.74
    &#124; 11.48  1998/99 &#124; 7.22 &#124; 10.86  1997/98 &#124; 6.41
    &#124; 9.76  1996/97 &#124; 5.73 &#124; 8.8 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 2 | ![[未标注的图片]](img/22e2076bd3d9a629d7a578b10a759366.png)  | 特征 &#124; 名义（蓝色）
    &#124; 实际（深蓝色）  2019/20 &#124; 11.97 &#124; 12.11  2018/19 &#124;
    11.35 &#124; 11.57  2017/18 &#124; 11.94 &#124; 11.76  2016/17 &#124;
    11.6 &#124; 12.25  2015/16 &#124; 11.34 &#124; 12.3  2014/15 &#124;
    12.46 &#124; 13.55  2013/14 &#124; 11.62 &#124; 12.97  2012/13 &#124;
    12.76 &#124; 14.43  2011/12 &#124; 12.57 &#124; 14.35  2010/11 &#124;
    13.06 &#124; 15.24  2009/10 &#124; 13.22 &#124; 15.76  2008/09 &#124;
    12.46 &#124; 15.03  2007/08 &#124; 11.94 &#124; 14.76  2006/07 &#124;
    11.43 &#124; 14.48  2005/06 &#124; 10.87 &#124; 14.21  2004/05 &#124;
    10.03 &#124; 13.36  2003/04 &#124; 9.76 &#124; 13.3  2002/03 &#124;
    9.37 &#124; 13.03  2001/02 &#124; 8.66 &#124; 12.42  2000/01 &#124;
    7.89 &#124; 11.38  1999/00 &#124; 7.74 &#124; 11.48  1998/99 &#124;
    7.22 &#124; 10.86  1997/98 &#124; 6.41 &#124; 9.76  1996/97 &#124;
    5.73 &#124; 8.8 |'
- en: '| 3 | ![[Uncaptioned image]](img/90f81be188cc3774c536d108fc0fb3ac.png)  | Frequently
    (dark blue) &#124; Sometimes (light blue) &#124; NET  Lonely &#124; 7 &#124;
    24 &#124; 31  Depressed &#124; 13 &#124; 36 &#124; 49  Inspired &#124;
    16 &#124; 53 &#124; 69  Connected &#124; 21 &#124; 49 &#124; 71  Angry
    &#124; 25 &#124; 47 &#124; 71  Amused &#124; 44 &#124; 44 &#124; 88 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 3 | ![[未标注的图片]](img/90f81be188cc3774c536d108fc0fb3ac.png)  | 频繁（深蓝色） &#124;
    有时（浅蓝色） &#124; 净值  孤独 &#124; 7 &#124; 24 &#124; 31  抑郁 &#124; 13 &#124;
    36 &#124; 49  受启发 &#124; 16 &#124; 53 &#124; 69  连接 &#124; 21 &#124;
    49 &#124; 71  愤怒 &#124; 25 &#124; 47 &#124; 71  娱乐 &#124; 44 &#124;
    44 &#124; 88 |'
- en: '| 4 | ![[Uncaptioned image]](img/ff7265d120086a10e1b504f228e60358.png)  | Characteristic
    &#124; Men (blue) &#124; Women (navy blue)  2019 &#124; 945.74 &#124; 120.01
     2018 &#124; 928.34 &#124; 1181.71  2017 &#124; 906.45 &#124; 1160.94
     2016 &#124; 894.49 &#124; 1154.19  2015 &#124; 895.74 &#124; 1150.61
     2014 &#124; 892.76 &#124; 1156.91  2013 &#124; 880.11 &#124; 1134.59
     2012 &#124; 863.35 &#124; 1118.29  2011 &#124; 846.25 &#124; 1001.84
     2010 &#124; 818.71 &#124; 1069.38  2009 &#124; 766.65 &#124; 1021.74
     2008 &#124; 751.52 &#124; 998.79  2007 &#124; 733.65 &#124; 983.84
     2006 &#124; 725.31 &#124; 971.54  2005 &#124; 719.52 &#124; 959.92
     2004 &#124; 708.46 &#124; 941.77  2003 &#124; 669.77 &#124; 887.1)
     2002 &#124; 645.65 &#124; 852.11  2001 &#124; 619.74 &#124; 817.46
     2000 &#124; 587.16 &#124; 756.59 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 4 | ![[未标注的图片]](img/ff7265d120086a10e1b504f228e60358.png)  | 特征 &#124; 男性（蓝色）
    &#124; 女性（深蓝色）  2019 &#124; 945.74 &#124; 120.01  2018 &#124; 928.34
    &#124; 1181.71  2017 &#124; 906.45 &#124; 1160.94  2016 &#124; 894.49
    &#124; 1154.19  2015 &#124; 895.74 &#124; 1150.61  2014 &#124; 892.76
    &#124; 1156.91  2013 &#124; 880.11 &#124; 1134.59  2012 &#124; 863.35
    &#124; 1118.29  2011 &#124; 846.25 &#124; 1001.84  2010 &#124; 818.71
    &#124; 1069.38  2009 &#124; 766.65 &#124; 1021.74  2008 &#124; 751.52
    &#124; 998.79  2007 &#124; 733.65 &#124; 983.84  2006 &#124; 725.31
    &#124; 971.54  2005 &#124; 719.52 &#124; 959.92  2004 &#124; 708.46
    &#124; 941.77  2003 &#124; 669.77 &#124; 887.1)  2002 &#124; 645.65
    &#124; 852.11  2001 &#124; 619.74 &#124; 817.46  2000 &#124; 587.16
    &#124; 756.59 |'
- en: '| 5 | ![[Uncaptioned image]](img/11e77bff3d4eff2fa5ccf3e76ce2f060.png)  | Entity
    &#124; More (green) &#124; Aboutthe same (gray) &#124; Fewer (orange) &#124; None
    (VOL)  Turkey &#124; nan &#124; 30.0 &#124; 53.0 &#124; 0  Christian
    &#124; 10.0 &#124; 33.0 &#124; 53.0 &#124; 0  Sunni &#124; 12.0 &#124; 46.0
    &#124; 36.0 &#124; 0  Shia &#124; nan &#124; nan &#124; 44.0 &#124; 33 
    Lebanon &#124; 13.0 &#124; 40.0 &#124; nan &#124; 0  Jordan &#124; nan &#124;
    nan &#124; 63.0 &#124; 27  Syrian &#124; 64.0 &#124; nan &#124; nan &#124;
    26  Jordan &#124; 8.0 &#124; 8.0 &#124; 60.0 &#124; 23 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 5 | ![[无标题图片]](img/11e77bff3d4eff2fa5ccf3e76ce2f060.png)  | 实体 &#124; 更多（绿色）
    &#124; 差不多（灰色） &#124; 更少（橙色） &#124; 无（VOL）  土耳其 &#124; nan &#124; 30.0 &#124;
    53.0 &#124; 0  基督教 &#124; 10.0 &#124; 33.0 &#124; 53.0 &#124; 0  逊尼派
    &#124; 12.0 &#124; 46.0 &#124; 36.0 &#124; 0  什叶派 &#124; nan &#124; nan
    &#124; 44.0 &#124; 33  黎巴嫩 &#124; 13.0 &#124; 40.0 &#124; nan &#124; 0 
    约旦 &#124; nan &#124; nan &#124; 63.0 &#124; 27  叙利亚 &#124; 64.0 &#124; nan
    &#124; nan &#124; 26  约旦 &#124; 8.0 &#124; 8.0 &#124; 60.0 &#124; 23 |'
- en: '| 6 | ![[Uncaptioned image]](img/ea527b630a90bec859fb100f0ed01e87.png)  | Country
    &#124; Scheduled teaching time that teachers are in the classroom, 2002 to 2016
     Egypt (gray) &#124; 93.45  Tunisia (blue) &#124; 89.89  Madagascar
    (blue) &#124; 58.09  Mozambique (blue) &#124; 44.0 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 6 | ![[无标题图片]](img/ea527b630a90bec859fb100f0ed01e87.png)  | 国家 &#124; 教师在课堂上的预定教学时间，2002年到2016年
     埃及（灰色） &#124; 93.45  突尼斯（蓝色） &#124; 89.89  马达加斯加（蓝色） &#124;
    58.09  莫桑比克（蓝色） &#124; 44.0 |'
- en: 'Table 9: Sample outputs of our VDTG module. The first two cases the model detects
    the correct colors and positions, while the last 4 cases the model fails.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：我们的VDTG模块的样本输出。在前两个案例中，模型检测到了正确的颜色和位置，而在最后4个案例中，模型失败了。
- en: '![Refer to caption](img/13a8cf800c61b6c8f4fadec495c24f19.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/13a8cf800c61b6c8f4fadec495c24f19.png)'
- en: 'Figure 4: Two types of visual data tables. The left-hand side is *horizontal*
    whilst the right-hand one is *vertical*.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：两种类型的视觉数据表。左侧是*水平*的，而右侧是*垂直*的。
- en: A.7 Consistency of Generated Output with Demonstrations
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.7 生成输出与演示的一致性
- en: 'There have one consistency property that we propose in our prompt construction
    rules for LCQA and CS tasks ([Section 4](#S4 "4 Methodology ‣ Do LLMs Work on
    Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization")):
    *(iii)* in [Section 4](#S4 "4 Methodology ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization"). Although generating
    texts given a piece of information is a one-to-many relationship, i.e., there
    may have multiple correct answers, our motivation for this property is that the
    language model should answer consistently and correctly what it is taught through
    demonstrations. To verify this property in our proposed prompts, for each of LCQA
    and CS tasks, we input the proposed prompt and ask the model to generate the answer
    for each question in the prompt. The experimental results for LCQA and CS are
    illustrated in [Table 10](#A1.T10 "In A.7 Consistency of Generated Output with
    Demonstrations ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization") and [Table 11](#A1.T11
    "In A.7 Consistency of Generated Output with Demonstrations ‣ Appendix A Appendices
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization") respectively. We observe that although the textual outputs
    of the model sometimes are slightly different from the input demonstrations, the
    main points are kept without adding any hallucinating information, which verifies
    that our prompts satisfy *(iii)* ([Section 4](#S4 "4 Methodology ‣ Do LLMs Work
    on Charts? Designing Few-Shot Prompts for Chart Question Answering and Summarization"))
    property.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在LCQA和CS任务的提示构建规则中提出了一个一致性属性（[第4节](#S4 "4 方法论 ‣ LLMs 是否适用于图表？为图表问题回答和总结设计少量示例提示")）：*(iii)*
    在[第4节](#S4 "4 方法论 ‣ LLMs 是否适用于图表？为图表问题回答和总结设计少量示例提示")中。尽管给定一段信息生成文本是一对多关系，即可能存在多个正确答案，但我们提出该属性的动机是语言模型应当一致且正确地回答其通过演示学习到的内容。为了验证我们提出的提示中的这一属性，对于每个LCQA和CS任务，我们输入提出的提示，并要求模型生成每个提示中问题的答案。LCQA和CS的实验结果分别在[表10](#A1.T10
    "在A.7 生成输出与演示的一致性 ‣ 附录A 附录 ‣ LLMs 是否适用于图表？为图表问题回答和总结设计少量示例提示")和[表11](#A1.T11 "在A.7
    生成输出与演示的一致性 ‣ 附录A 附录 ‣ LLMs 是否适用于图表？为图表问题回答和总结设计少量示例提示")中展示。我们观察到，尽管模型的文本输出有时与输入演示略有不同，但主要观点保持不变且没有添加任何虚构的信息，这验证了我们的提示满足*(iii)*（[第4节](#S4
    "4 方法论 ‣ LLMs 是否适用于图表？为图表问题回答和总结设计少量示例提示")）属性。
- en: '| Chart Image | Demonstration’s Output | Generated Output |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 图表图像 | 演示输出 | 生成的输出 |'
- en: '| ![[Uncaptioned image]](img/aeb787f4cbfe65a0defa47f12259c2ef.png)  | The unaffiliated
    ( 58 % ) are the most likely among the religious groups studied to say there is
    solid evidence the earth is warming because of human activity . White evangelical
    Protestants are the most likely to say there is no solid evidence the earth is
    warming ( 31 % ) , and the least likely to believe that humans have contributed
    to heating up the planet ( 34 % ) . While only 39 % of black Protestants say global
    warming is a result of human activity , they are , however , the least likely
    of the religions studied to deny global warming is occurring ( 15 % ) . | The
    opinion of the public on earth warming varies among religious groups. The unaffiliated
    are the most likely among the religious groups studied to say there is solid evidence
    the earth is warming because of human activity (58%). White evangelical Protestants
    are the most likely to say there is no solid evidence the earth is warming (31%)
    and the least likely to believe that humans have contributed to heating up the
    planet (34%). While only 39% of black Protestants say global warming is a result
    of human activity, they are, however, the least likely of the religions studied
    to deny global warming is occurring (15%). |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/aeb787f4cbfe65a0defa47f12259c2ef.png)  | 非宗教人士（58%）在研究的宗教群体中最可能认为地球变暖有充分的证据是由于人类活动。白人福音派新教徒最可能认为地球变暖没有充分的证据（31%），并且最不可能相信人类对地球变暖有贡献（34%）。虽然只有39%的黑人新教徒认为全球变暖是人类活动的结果，但他们也是研究中最不可能否认全球变暖发生的群体（15%）。
    | 关于地球变暖的公众意见在宗教群体中有所不同。非宗教人士（58%）在研究的宗教群体中最可能认为地球变暖有充分的证据是由于人类活动。白人福音派新教徒最可能认为地球变暖没有充分的证据（31%），并且最不可能相信人类对地球变暖有贡献（34%）。虽然只有39%的黑人新教徒认为全球变暖是人类活动的结果，但他们也是研究中最不可能否认全球变暖发生的群体（15%）。'
- en: '| ![[Uncaptioned image]](img/e85928bbe6ca3246746c4d855c424f8b.png)  | In 37
    % of the cases , it is the stay - at - home wives who actually have a higher level
    of education . In 45 % of these families , the spouses have equal educational
    attainment , and in about 18 % of the cases , the husbands have more education
    than their wives . | Among families with opt-out moms, 37% have the stay-at-home
    wives with a higher level of education than the husbands. 45% of these families
    have equal educational attainment between spouses, and 18% of the cases have the
    husbands with more education than the wives. |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/e85928bbe6ca3246746c4d855c424f8b.png)  | 在37%的案例中，居家的妻子实际上拥有更高的教育水平。在45%的家庭中，配偶之间的教育水平相等，而在大约18%的案例中，丈夫的教育水平高于妻子。
    | 在选择退出工作的妈妈家庭中，37%的家庭中，居家的妻子比丈夫拥有更高的教育水平。这些家庭中45%的夫妻教育水平相等，而18%的情况下，丈夫的教育水平高于妻子。
    |'
- en: '| ![[Uncaptioned image]](img/0a861cc10c000f3c67ef94e65b626b1a.png)  | About
    two - thirds of Hispanic registered voters ( 68 % ) disapprove of the job Trump
    is doing as president , including 51 % who disapprove very strongly . The 30 %
    of Hispanic voters who approve of Trump includes 23 % who approve strongly | Among
    Hispanic registered voters, there is strong disapproval of President Trump’s job
    performance. About two-thirds (68%) of Hispanic voters disapprove of the job Trump
    is doing as president, including 51% who disapprove very strongly. The 30% of
    Hispanic voters who approve of Trump includes 23% who approve strongly. |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/0a861cc10c000f3c67ef94e65b626b1a.png)  | 大约三分之二的西班牙裔登记选民（68%）对特朗普担任总统的工作表示不满，其中51%非常强烈地不满。30%的西班牙裔选民对特朗普表示赞成，其中23%非常强烈地赞成。
    | 在西班牙裔登记选民中，对特朗普总统工作的表现有强烈的不满。大约三分之二（68%）的西班牙裔选民对特朗普的工作表示不满，其中51%非常强烈地不满。30%的西班牙裔选民对特朗普表示赞成，其中23%非常强烈地赞成。
    |'
- en: '| ![[Uncaptioned image]](img/c6c3ca6c8a3658173a59d3083b4032bf.png)  | Overall
    , a majority ( 53 % ) says that jobs are difficult to find in their community
    while only about a third ( 34 % ) says there are plenty of jobs available . The
    percentage saying that jobs are difficult to find locally has increased modestly
    since February 2007 ( 48 % ) . In October 2003 , 66 % said that jobs were difficult
    to find , the highest percentage expressing that view since the start of the Bush
    administration . | Overall, a majority (53%) says that jobs are difficult to find
    in their community while only about a third (34%) says there are plenty of jobs
    available. The percentage saying that jobs are difficult to find locally has increased
    modestly since February 2007 (48%). In October 2003, 66% said that jobs were difficult
    to find, the highest percentage expressing that view since the start of the Bush
    administration. |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/c6c3ca6c8a3658173a59d3083b4032bf.png)  | 总体而言，大多数人（53%）表示在他们的社区中找工作很困难，而只有大约三分之一（34%）的人表示有很多工作机会。表示当地找工作困难的比例自2007年2月（48%）以来有所上升。2003年10月，66%的人表示找工作很困难，这是自布什政府开始以来表达这种观点的最高比例。
    |'
- en: '| ![[Uncaptioned image]](img/4ad80cbe88e8efb2e93b619930015342.png)  | 34 %
    say they followed stories about the continued attempts by pirates to hijack ships
    more closely than any other story last week , while 27 % say they followed stories
    about the U.S. economy most closely . 9 % say they followed the tea party protests
    more closely than any other story . | 34% of the public say they followed stories
    about the continued attempts by pirates to hijack ships more closely than any
    other story last week, while 27% say they followed stories about the U.S. economy
    most closely. 9% say they followed the tea party protests more closely than any
    other story. |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/4ad80cbe88e8efb2e93b619930015342.png)  | 34%的人表示，他们比任何其他新闻更关注了关于海盗持续劫持船只的故事，而27%的人表示，他们最关注的是关于美国经济的故事。9%的人表示，他们比其他任何新闻更关注了茶党抗议活动。
    |'
- en: '| ![[Uncaptioned image]](img/dd043a2f6b55d426406ed3d8fb1b1daa.png)  | Roughly
    three - quarters ( 77 % ) say Japan has not adequately expressed regret , and
    such Chinese sentiment is largely unchanged since 2006 . Only 10 % believe Tokyo
    has apologized enough . | Roughly three-quarters (77%) of Chinese people say that
    Japan has not adequately expressed regret for their actions during World War II,
    and this sentiment has been largely unchanged since 2006\. Only 10% of Chinese
    people believe that Japan has apologized enough for their actions during the war.
    |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/dd043a2f6b55d426406ed3d8fb1b1daa.png)  | 约四分之三（77%）的人表示日本没有充分表达悔意，而且这种中国人的情绪自2006年以来基本未变。只有10%的人认为东京已经足够道歉。
    |'
- en: 'Table 10: For each demonstration in our prompt, we ask the language model to
    generate its expected output, given its input. We then compare the generated output
    from the model with its expected output.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：对于我们提示中的每个演示，我们要求语言模型生成其期望的输出，然后将模型生成的输出与其期望的输出进行比较。
- en: '| Chart Image | Demonstration’s Output | Generated Output |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 图表图片 | 演示输出 | 生成的输出 |'
- en: '| ![[Uncaptioned image]](img/780ec20e51a750a72cf5e258e47ad455.png)  | Before
    the outbreak, Americans strongly believed their personal data was more vulnerable
    than in the past. In a June 2019 survey, 70% of Americans said their personal
    information was less secure than it was five years earlier. Just 6% of Americans
    said they felt their information was more secure than in the past, while 24% said
    their personal information was about as secure as it was five years earlier. Experts
    have suggested that data security could be threatened for companies shifting to
    remote work – as well as ordinary people who are spending more time online – during
    the coronavirus outbreak. | In 2019, seven in ten Americans reported feeling less
    secure about their personal information than they did five years prior. The survey,
    conducted between June 3-17, 2019, revealed that 6% of U.S adults felt their personal
    information was more secure than five years earlier, while 24% reported feeling
    that it was the same. These findings suggest that the majority of Americans feel
    their personal data is more vulnerable now than it was before, a fear that has
    been compounded by the coronavirus pandemic and the increased reliance on digital
    communication. |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/780ec20e51a750a72cf5e258e47ad455.png) | 疫情爆发之前，美国人强烈地认为他们的个人数据比过去更容易受到威胁。2019年6月的一项调查显示，70%的美国人表示他们的个人信息比五年前更不安全。仅有6%的美国人表示他们的信息比过去更安全，而24%的人表示他们的个人信息与五年前差不多。专家指出，在新冠疫情爆发期间，数据安全可能会受到威胁，尤其是对于转向远程工作的公司和花更多时间在线的普通人。
    | 2019年，七成美国人报告他们对个人信息的安全感比五年前下降。2019年6月3日至17日进行的调查显示，6%的美国成年人觉得他们的个人信息比五年前更安全，而24%的人认为安全程度相同。这些发现表明，大多数美国人认为他们的个人数据现在比以前更脆弱，这种担忧在新冠疫情和对数字通信依赖增加的背景下变得更加严重。'
- en: '| ![[Uncaptioned image]](img/2bbce55749e4c92b05df369946de074f.png)  | Sharp
    growth in illegal immigration and increased enforcement of immigration laws have
    dramatically altered the ethnic composition of offenders sentenced in federal
    courts. In 2007, Latinos accounted for 40% of all sentenced federal offenders‚Äîmore
    than triple their share (13%) of the total U.S. adult population. The share of
    all sentenced offenders who were Latino in 2007 was up from 24% in 1991, according
    to an analysis of data from the United States Sentencing Commission (USSC) by
    the Pew Hispanic Center, a project of the Pew Research Center. | In 2007, 40%
    of all federal offenders sentenced in the U.S. were Latino, according to an analysis
    of United States Sentencing Commission data by the Pew Hispanic Center. This was
    more than triple the share of Latinos (13%) in the total U.S. adult population.
    The share of Latino offenders sentenced in federal courts had risen from 24% in
    1991. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/2bbce55749e4c92b05df369946de074f.png) | 非法移民的急剧增长和移民法执行力度的增加，显著改变了联邦法院判决罪犯的种族构成。根据皮尤拉丁裔中心对美国判刑委员会（USSC）数据的分析，2007年，拉丁裔占所有判刑联邦罪犯的40%——是其在美国成年人口中所占比例（13%）的三倍多。2007年，拉丁裔罪犯在所有判刑罪犯中的比例从1991年的24%上升。
    | 2007年，根据皮尤拉丁裔中心对美国判刑委员会数据的分析，所有在美国被判刑的联邦罪犯中有40%是拉丁裔。这是拉丁裔在美国成年人口中（13%）的三倍多。拉丁裔罪犯在联邦法院的判刑比例从1991年的24%上升。
    |'
- en: '| ![[Uncaptioned image]](img/f9ad5c00efa89dd44bd5b7425ab9c92c.png)  | Far more
    voters expect voting to be difficult this year than in 2018, according to a survey
    of registered voters conducted July 27 to Aug. 2\. Around half of registered voters
    (49%) said they expect voting to be very or somewhat difficult this year, while
    the other half (50%) expect it to be very or somewhat easy. That represents a
    major change from October 2018, when just 15% of voters said they expected voting
    in that year‚Äôs midterms to be difficult and 85% said they expected it to be
    easy. | This year, a majority of voters are expecting it to be difficult to vote
    in the November elections. According to a survey of registered voters conducted
    July 27 to Aug. 2, 49% of registered voters said they expect voting to be very
    or somewhat difficult this year, while the other half (50%) expect it to be very
    or somewhat easy. This is a stark contrast to the survey results from October
    2018, when only 15% of voters said they expected voting in that year‚Äôs midterms
    to be difficult and 85% said they expected it to be easy. These results suggest
    that many Americans are feeling more uncertain and anxious about voting this year
    than in previous years. |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/f9ad5c00efa89dd44bd5b7425ab9c92c.png)  | 今年，相较于2018年，更多选民预计投票将变得困难。根据7月27日至8月2日对注册选民的调查，大约一半的注册选民（49%）表示，他们预计今年投票将非常或稍微困难，而另一半（50%）则认为会非常或稍微容易。这与2018年10月的调查结果形成了鲜明对比，当时仅15%的选民认为当年的中期选举投票会很困难，85%的选民则认为会很容易。这些结果表明，今年许多美国人对投票感到比往年更加不确定和焦虑。'
- en: '| ![[Uncaptioned image]](img/7f07ee9dacce3968858c514265286819.png)  | This
    statistic shows the total annual turnover of the retail sale of bakery products
    and cereals ( including rice and pasta products ) in the United Kingdom from 2008
    to 2018 . Turnover has grown steadily , reaching a peak of approximately 22 billion
    British pounds in 2015 before declining the following year . By 2018 turnover
    had almost completely recovered and amounted to 21.9 billion pounds . | This statistic
    shows the total annual turnover of the retail sale of bakery products and cereals
    (including rice and pasta products) in the United Kingdom from 2008 to 2018\.
    Turnover has grown steadily, with a peak of approximately 22 billion British pounds
    in 2015 before declining the following year. By 2018, turnover had almost completely
    recovered and amounted to 21.9 billion pounds. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/7f07ee9dacce3968858c514265286819.png)  | 该统计数据显示了2008至2018年英国零售面包烘焙产品和谷物（包括米饭和意大利面产品）的年总营业额。营业额稳步增长，2015年达到约220亿英镑的峰值后在次年有所下降。到2018年，营业额几乎完全恢复，达到了219亿英镑。
    |'
- en: '| ![[Uncaptioned image]](img/59960a222565157d8a4dea35b7f8ecb4.png)  | This
    statistic shows the number of nights spent camping or in caravans in Great Britain
    in 2019 , by type . Almost 20 million nights were spent by domestic tourists in
    touring caravans in Great Britain , while 12.5 million nights were spent camping
    in tents . | This statistic shows the number of nights spent camping or in caravans
    in Great Britain in 2019, by type. Nearly 20 million nights were spent by domestic
    tourists in touring caravans in Great Britain, while 12.5 million nights were
    spent camping in tents. |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/59960a222565157d8a4dea35b7f8ecb4.png)  | 该统计数据显示了2019年英国按类型计算的露营或住宿在旅行拖车中的夜晚数量。几乎有2000万夜晚由国内游客在英国的旅行拖车中度过，而1200万夜晚则是在帐篷中露营。
    |'
- en: '| ![[Uncaptioned image]](img/84406091cfd836dc0ba0e5913e365c0a.png)  | This
    statistic shows the national debt of Barbados from 2015 to 2020 in relation to
    the gross domestic product ( GDP ) , with projections up until 2025 . The figures
    refer to the whole country and include the debts of the state , the communities
    , the municipalities and the social insurances . In 2020 , the national debt of
    Barbados amounted to approximately 134.09 percent of the GDP . | This statistic
    shows the national debt of Barbados from 2015 to 2020 in relation to the gross
    domestic product (GDP), with projections up until 2025\. The figures refer to
    the whole country and include the debts of the state, the communities, the municipalities
    and the social insurances. In 2020, the national debt of Barbados amounted to
    approximately 134.09 percent of the GDP. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/84406091cfd836dc0ba0e5913e365c0a.png) | 该统计数据展示了2015年至2020年巴巴多斯的国家债务与国内生产总值（GDP）的关系，并提供了到2025年的预测数据。这些数据涉及整个国家，包括国家、社区、市政和社会保险的债务。2020年，巴巴多斯的国家债务约占GDP的134.09%。
    | 该统计数据展示了2015年至2020年巴巴多斯的国家债务与国内生产总值（GDP）的关系，并提供了到2025年的预测数据。这些数据涉及整个国家，包括国家、社区、市政和社会保险的债务。2020年，巴巴多斯的国家债务约占GDP的134.09%。
    |'
- en: 'Table 11: For each demonstration in our prompt, we ask the language model to
    generate its expected output, given its input. We then compare the generated output
    from the model with its expected output.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 表11：对于我们提示中的每个示例，我们要求语言模型生成其期望的输出，然后将模型生成的输出与期望的输出进行比较。
- en: A.8 Analysis of Visual Data Table Representation
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.8 视觉数据表表示分析
- en: '| Model | Aug. (%) | Human (%) | Avg. (%) |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 增加 (%) | 人工 (%) | 平均 (%) |'
- en: '| InstructGPT + CCR | - | 30.86 | - |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| InstructGPT + CCR | - | 30.86 | - |'
- en: '| PromptChart | - | 38.42 | - |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| PromptChart | - | 38.42 | - |'
- en: '| InstructGPT + CCR + *ground_truth* colors | - | 60.95 | - |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| InstructGPT + CCR + *真实*颜色 | - | 60.95 | - |'
- en: 'Table 12: Effect of color information on color-related QA pairs (203 cases).'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 表12：颜色信息对颜色相关QA对（203个案例）的影响
- en: 'This section is to answer the research question: "What is the maximal improvement
    we can obtain by integrating visual data tables instead of traditional data tables?"
    To answer this question, we manually label the colors for a total of 203 color-related
    QA pairs in the human test set of ChartQA Masry et al. ([2022](#bib.bib34)). We
    then examine the performance of InstructGPT model on these QA pairs in three different
    settings: (1) with ground-truth visual data tables, (2) with original data tables,
    (3) with our generated visual data tables from VDTG module. The experimental results
    are shown in [Table 12](#A1.T12 "In A.8 Analysis of Visual Data Table Representation
    ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for
    Chart Question Answering and Summarization"). We observe that with the ground-truth
    colors, the performance of the model is improved significantly, nearly twice compared
    to the case without them. This observation not only verifies the effectiveness
    of our proposed visual data table representation but also reveals a huge room
    for further improvements.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在回答研究问题：“通过整合视觉数据表代替传统数据表，我们能获得的最大改进是什么？”为回答这个问题，我们在ChartQA Masry等人的人工测试集中手动标注了203个与颜色相关的QA对。然后，我们在以下三种不同的设置下检查InstructGPT模型在这些QA对上的表现：（1）使用真实颜色的视觉数据表，（2）使用原始数据表，（3）使用我们从VDTG模块生成的视觉数据表。实验结果见[表12](#A1.T12
    "在A.8 视觉数据表表示分析 ‣ 附录A 附录 ‣ LLM是否适用于图表？设计少量示例提示进行图表问答和总结")。我们观察到，使用真实颜色时，模型的性能显著提高，几乎是没有使用这些颜色情况下的两倍。这一观察不仅验证了我们提出的视觉数据表表示的有效性，也揭示了进一步改进的巨大空间。
- en: A.9 Illustrative Cases for Proposed Properties of LCQA and CS Prompts
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.9 LCQA和CS提示提议属性的说明案例
- en: '[Table 14](#A1.T14 "In A.9 Illustrative Cases for Proposed Properties of LCQA
    and CS Prompts ‣ Appendix A Appendices ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization") shows the illustrative
    of the variants of our LCQA prompt which do not satisfy property *(ii), (iii)*
    in [Section 4](#S4 "4 Methodology ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization"). We derive 2 main observations.
    First, not guaranteeing *(ii)* makes the answers commonly lack findings for *Discovery*
    queries (first 2 samples). Second, the demonstrations that do not ensure *(iii)*
    commonly have very long answers. By using these demonstrations not satisfying
    *(ii), (iii)* in the prompt, we observe that the model commonly generates very
    long answers which makes them likely to suffer from factual errors (last 2 examples).'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[表14](#A1.T14 "在 A.9 LCQA 和 CS 提示的提议属性说明案例 ‣ 附录 A 附录 ‣ LLM 是否适用于图表？为图表问题回答和总结设计的少量示例提示")
    显示了我们 LCQA 提示的变体示例，这些变体不满足 [第4节](#S4 "4 方法 ‣ LLM 是否适用于图表？为图表问题回答和总结设计的少量示例提示")
    中的属性 *(ii), (iii)*。我们得出了两个主要观察结果。首先，不保证 *(ii)* 的话，答案通常缺乏 *发现* 查询的结果（前两个示例）。其次，未确保
    *(iii)* 的示例通常有很长的答案。通过使用这些不满足 *(ii), (iii)* 的示例提示，我们观察到模型通常生成非常长的答案，这使得这些答案容易出现事实错误（最后两个示例）。 '
- en: '| Chart Image | Input | Gold Answer | PromptChart | Ablation Study Model |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 图表图片 | 输入 | 黄金答案 | PromptChart | 消融研究模型 |'
- en: '| ![[Uncaptioned image]](img/08593bbf0adb7b60be2c8ff068ba35bc.png)  | Question:
    How was Trump’s online posture seen when he was becoming president? | In December
    , a majority of the public ( 82 % ) also said Trump should be more cautious in
    “ the kinds of things he says and tweets ” once he becomes president . Just 15
    % said there is no need for him to change . | When it comes to the kind of things
    Trump says and tweets, once he becomes president , 82 % of Americans believe he
    will need to be more cautious , including 90 % of Democrats and 76 % of Republicans
    . Only 15 % of Americans believe there is no need for Trump to change his online
    posture. | Most people, including both Republicans and Democrats, believe that
    Trump needs to be more cautious when it comes to what he says and tweets once
    he becomes President. 82 % of the total population, 76 % of Republicans and Lean
    Rep and 90 % of Democrats and Lean Dem think Trump should be more cautious. |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/08593bbf0adb7b60be2c8ff068ba35bc.png)  | 问题：特朗普在成为总统时，其在线态度如何被看待？
    | 在12月，大多数公众（82%）还表示，特朗普成为总统后应在“他说的和发的推文”的内容上更加谨慎。仅有15%的人表示不需要改变。 | 当谈到特朗普成为总统后的言论和推文时，82%的美国人认为他需要更加谨慎，其中包括90%的民主党人和76%的共和党人。只有15%的美国人认为特朗普不需要改变他的在线态度。
    | 大多数人，包括共和党人和民主党人，认为特朗普在成为总统后在言论和推文方面需要更加谨慎。82%的总人口、76%的共和党人和倾向共和党人以及90%的民主党人和倾向民主党人认为特朗普应更加谨慎。'
- en: '| ![[Uncaptioned image]](img/0a0f098f75369d5c89b25c36592f20e4.png)  | How does
    public feel about supporting undocumented immigrants? | 70 % say there should
    be a way for undocumented immigrants to stay in the country legally , if they
    meet certain requirements . Most of those who support legal status think there
    should be a way for unauthorized immigrants to become citizens ( 43 % overall
    ) , while 24 % say the path should only include permanent residency . | A large
    majority of the public (70%) support a path to legal status for undocumented immigrants
    in the US who meet certain requirements. This includes 43% who support a path
    to citizenship and 24% who support a path to permanent residency. Only 27% of
    people oppose a path to legal status for undocumented immigrants and 3% are not
    sure. | Seven-in-ten Americans ( 70 % ) say undocumented immigrants currently
    living in the US should be allowed to stay in the country legally , if they meet
    certain requirements , while 27 % say they should not be allowed to stay . |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/0a0f098f75369d5c89b25c36592f20e4.png)  | 公众对支持无证移民的看法如何？ |
    70%的人认为，如果无证移民符合某些要求，应有办法让他们合法留在美国。大多数支持合法身份的人认为，应有办法让非法移民成为公民（总计43%），而24%的人认为这条路径应仅包括永久居留。
    | 大多数公众（70%）支持在符合某些要求的情况下，让无证移民在美国获得合法身份。这包括43%的人支持获得公民身份的路径，24%的人支持获得永久居留的路径。只有27%的人反对无证移民获得合法身份，3%的人不确定。
    | 七成美国人（70%）认为，无证移民在美国应允许他们合法留在该国，只要他们符合某些要求，而27%的人认为他们不应被允许留在美国。 |'
- en: '| ![[Uncaptioned image]](img/57bb99f41537c41119eea22c959407a8.png)  | What
    is the favourable ratings of Philippines given by Christians and Muslims ? | in
    Christian - majority Philippines , favorable views of Christians were nearly universal
    ( 97 % ) while just 57 % said the same of Muslims in their country . | The favorable
    ratings for Christians and Muslims in the Philippines are 97 % and 57 % respectively.
    | A large majority of the public (70%) support a path to legal status for undocumented
    immigrants in the US who meet certain requirements. This includes 43% who support
    a path to citizenship and 24% who support a path to permanent residency. Only
    27% of people oppose a path to legal status for undocumented immigrants and 3%
    are not sure. |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/57bb99f41537c41119eea22c959407a8.png)  | 菲律宾基督徒和穆斯林给予的好评如何？
    | 在基督教徒占多数的菲律宾，基督徒的好评几乎是普遍的（97%），而只有57%的人对本国的穆斯林给予相同评价。 | 菲律宾基督徒和穆斯林的好评率分别为97%和57%。
    | 大多数公众（70%）支持为符合特定条件的无证移民提供合法身份途径。这包括43%支持提供公民身份途径和24%支持提供永久居民途径。只有27%的人反对为无证移民提供合法身份途径，3%的人不确定。
    |'
- en: '| ![[Uncaptioned image]](img/2eb867373fc2ea4aabf5a6151bb85075.png)  | What
    do Americans think about gene editing? | Roughly half of adults ( 49 % ) said
    gene editing would be less acceptable to them if the effects “ changed the genetic
    makeup of the whole population , ” versus just 17 % who said it would be more
    acceptable . When asked about an alternate scenario in which the effects of gene
    editing are limited to a single person , more Americans said it would be more
    acceptable than less acceptable ( 34 % to 23 % ) . | A majority of Americans (
    34 % ) say that gene editing to give healthy babies a much reduced risk of serious
    diseases would be more acceptable , while 23 % say it would be less acceptable
    and 40 % say it would make no difference . However , when asked about gene editing
    that would change the genetic makeup of the whole population , only 17 % say it
    would be more acceptable , while 49 % say it would be less acceptable and 31 %
    say it would make no difference. | Americans are more concerned than accepting
    when it comes to gene editing . According to a survey conducted in March 2016
    by the Pew Research Center , 34 % of U.S. adults say that gene editing that would
    give healthy babies a much reduced risk of serious diseases would be more acceptable,
    while 40 % say it would make no difference and 23 % say it would be less acceptable.
    When it comes to gene editing that would change the genetic makeup of the whole
    population, only 17 % say it would be more acceptable, 49 % say it would be less
    acceptable and 31 % say it would make no difference. |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图像]](img/2eb867373fc2ea4aabf5a6151bb85075.png)  | 美国人如何看待基因编辑？ | 大约一半的成年人（49%）表示，如果基因编辑的效果“改变了整个种群的遗传构成”，他们会觉得这种编辑不太可接受，而只有17%的人表示这种编辑更可接受。当问及一个替代情境，其中基因编辑的效果仅限于一个人时，更多的美国人表示这种编辑更可接受（34%
    对 23%）。 | 大多数美国人（34%）认为，对健康婴儿进行基因编辑，以显著降低严重疾病的风险，会更可接受，而23%的人认为这种编辑不太可接受，40%的人认为没有区别。然而，当问及基因编辑可能改变整个种群的遗传构成时，只有17%的人认为这种编辑更可接受，49%的人认为不太可接受，31%的人认为没有区别。
    | 当谈到基因编辑时，美国人更关心而非接受。根据2016年3月皮尤研究中心进行的调查，34%的美国成年人认为对健康婴儿进行基因编辑，以显著降低严重疾病的风险，会更可接受，而40%的人认为没有区别，23%的人认为不太可接受。当谈到可能改变整个种群的遗传构成的基因编辑时，只有17%的人认为这种编辑更可接受，49%的人认为不太可接受，31%的人认为没有区别。
    |'
- en: 'Table 13: Samples to illustrate the outputs of PromptChart and its variant
    without *($L_{2}$)* (last 2 rows) for LCQA task.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 表13：展示PromptChart及其变体在LCQA任务中输出的样本（最后两行）并未包含*($L_{2}$)*。
- en: '| Chart Image | Gold Answer | PromptChart | Ablation Study Model |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 图表图像 | 黄金答案 | PromptChart | 消融研究模型 |'
- en: '| ![[Uncaptioned image]](img/6759c0a1b3686de2101629c60fc3813b.png)  | In the
    vast majority of local TV newsrooms, budgets either grew or held steady in 2013\.
    About half of the news directors surveyed (52%) said they increased their news
    budgets last year, compared with 49% the year before and 38% in 2011\. But there
    were differences by market size. Indeed, 54% of the mid-sized market stations
    (51-100) said they increased their budgets compared with 41% whose budgets were
    cut or stayed the same. But in the biggest 25 TV markets, the percentage of stations
    increasing their budgets in 2013 (48%) was identical to the percentage that cut
    or did not increase their spending. | In 2013, local TV newsroom budgets experienced
    an overall increase. According to a survey of news directors from all commercial
    local TV stations, 52% of respondents said their budgets had increased, 34% said
    their budgets remained the same, and 6% were not sure. Just 7% of news directors
    reported that their budgets had decreased. These results indicate that local TV
    newsroom budgets were largely stable or increased in 2013. | According to a survey
    of news directors at all commercial local stations conducted by RTDNA/Hofstra
    University, 52% of news directors said their budgets had increased, 34 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/6759c0a1b3686de2101629c60fc3813b.png)  | 在绝大多数地方电视台新闻编辑室中，2013年的预算要么增长，要么保持稳定。约有一半接受调查的新闻总监（52%）表示他们增加了去年新闻预算，相比之下，前一年为49%，2011年为38%。但不同市场规模的情况有所不同。确实，54%的中型市场电视台（51-100）表示他们增加了预算，而41%的预算被削减或保持不变。而在最大25个电视市场中，2013年预算增加的电视台比例（48%）与削减或未增加预算的比例相同。
    | 在2013年，当地电视台新闻编辑室的预算总体上有所增加。根据对所有商业地方电视台新闻总监的调查，52%的受访者表示他们的预算有所增加，34%表示预算保持不变，6%不确定。仅有7%的新闻总监报告了预算减少。这些结果表明，2013年当地电视台新闻编辑室的预算总体上稳定或有所增加。
    | 根据RTDNA/Hofstra大学对所有商业地方台新闻总监的调查，52%的新闻总监表示他们的预算有所增加，34% |'
- en: '| ![[Uncaptioned image]](img/bd2e6b34178ffa261137f4ac342863ca.png)  | As Russian
    troops remain in Ukraine’s Crimea region and Crimea’s Parliament has set up a
    secession vote, Americans prefer the U.S. to not get too involved in the situation.
    By a roughly two-to-one margin (56% vs. 29%), the public says it is more important
    for the U.S. to not get involved in the situation with Russia and Ukraine than
    to take a firm stand against Russian actions. | In March 2014, Americans were
    divided on how the U.S. should respond to Russian actions in Ukraine. 29% believed
    it was more important for the U.S. to take a firm stand against Russian actions,
    while 56% said it was more important not to get too involved in the situation
    in Ukraine. 15% said they did not know or gave no opinion. | In 2014, 29% of Americans
    said it was more important for the United States to take a firm stand against
    Russian actions than to not get too involved in the situation in Ukraine. This
    sentiment was shared among 56% of those surveyed who chose not to answer. Only
    15% of respondents said that it was more important for the United States not to
    get too involved in the situation in Ukraine. The survey was conducted by the
    Pew Research Center from March 6-9, 2014. |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/bd2e6b34178ffa261137f4ac342863ca.png)  | 随着俄罗斯军队仍驻扎在乌克兰的克里米亚地区，而克里米亚议会已设立脱离投票，美国人更倾向于不让美国过度介入这一局势。公众认为，美国在俄乌局势中的介入程度比对俄罗斯行动采取坚决立场更为重要，比例约为二比一（56%对29%）。
    | 2014年3月，美国人在如何回应俄罗斯在乌克兰的行动上意见分歧。29%的人认为美国应对俄罗斯行动采取坚决立场，而56%的人认为不应过度介入乌克兰局势更为重要。15%的人表示不知情或没有意见。
    | 2014年，29%的美国人认为美国对俄罗斯行动采取坚决立场比不在乌克兰局势中过度介入更为重要。56%的人选择了不回答这一观点。只有15%的受访者认为美国不应过度介入乌克兰局势更为重要。调查由皮尤研究中心于2014年3月6日至9日进行。'
- en: '| ![[Uncaptioned image]](img/cfc62db285e59f23e51ea20d2746d0be.png)  | The public
    continued to track news about the economy and the presidential election, while
    paying less attention to another important political story – Wisconsin Gov. Scott
    Walker’s victory in a hard-fought recall election. The latest weekly News Interest
    Index, conducted June 7-10 among 1,000 adults by the Pew Research Center for the
    People & the Press, finds that 35% say they followed reports about U.S. economic
    conditions very closely while 30% tracked news about the presidential election
    very closely. The public expressed less interest in news about the Wisconsin recall
    election (21% very closely), European economic problems (18%) and the CIA killing
    of an al Qaeda leader in a drone strike in Pakistan (16%). | In June 2012, 35%
    of Americans reported they were following news about the U.S. economy very closely.
    This was the leading story in terms of interest, with 30% of Americans saying
    they were following it very closely. This was followed by the 2012 election, with
    21% of Americans following it very closely. 18% of Americans were following news
    about European economies very closely, 16% were following news about Al Qaeda
    leader killed, and 15% were following news about the Vatican and U.S nuns. These
    figures were reported in a survey conducted by the Pew Research Center from June
    7-10, 2012. | In June 2012, Americans followed the U.S. economy the closest, with
    35% of adults saying they followed the story “very closely.” The 2012 presidential
    election and the Wisconsin recall election were the next most closely followed
    stories, with 30% and 21% of adults, respectively, following these stories “very
    closely.” Europeans economies and the death of al Qaeda leader Osama bin Laden
    rounded out the top five stories, with 18% and 16% of adults saying they followed
    those stories “very closely.” The Vatican and U.S. nuns dispute was the least
    followed story, with just 6% of adults following the story “very closely.” These
    results are based on a June 7-10, 2012 survey conducted by the Pew Research Center.
    |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| ![[无标题图片]](img/cfc62db285e59f23e51ea20d2746d0be.png)  | 公共舆论继续关注经济和总统选举的新闻，同时对另一个重要的政治故事——威斯康星州州长斯科特·沃克在一场激烈的罢免选举中的胜利关注较少。皮尤研究中心于6月7日至10日对1000名成年人进行的最新每周新闻兴趣指数调查发现，35%的人表示他们非常关注有关美国经济状况的报道，而30%的人表示他们非常关注总统选举的新闻。公众对威斯康星州罢免选举（21%非常关注）、欧洲经济问题（18%）以及中央情报局在巴基斯坦无人机袭击中击毙基地组织领导人（16%）的新闻兴趣较少。
    | 2012年6月，35%的美国人表示他们非常关注有关美国经济的新闻。这是最受关注的故事，有30%的美国人表示他们非常关注。这其后是2012年选举，有21%的美国人非常关注。18%的美国人非常关注欧洲经济的新闻，16%的人关注基地组织领导人被杀的新闻，15%的人关注梵蒂冈和美国修女的新闻。这些数据是在皮尤研究中心于2012年6月7日至10日进行的调查中报告的。
    | 2012年6月，美国人对美国经济的关注度最高，有35%的成年人表示他们“非常关注”这一故事。2012年总统选举和威斯康星州罢免选举是紧随其后的最受关注的故事，分别有30%和21%的成年人表示他们“非常关注”这些故事。欧洲经济和基地组织领导人本·拉登的死亡排在前五名故事之列，分别有18%和16%的成年人表示他们“非常关注”这些故事。梵蒂冈和美国修女的争端是关注度最低的故事，只有6%的成年人表示他们“非常关注”这一故事。这些结果基于皮尤研究中心于2012年6月7日至10日进行的调查。'
- en: '| ![[Uncaptioned image]](img/6ea070bd3664e3eebf1746ed7ed9b0d4.png)  | As for
    median household income, the most recent data we have is for 2011 (the Census
    Bureau will release 2012 numbers next week), but they show that after factoring
    in inflation, the median U.S. household income shrank 4.7 percent between 2008
    and 2011\. Little surprise, then, that more than half (54%) of the people in our
    survey said household incomes have hardly recovered since the recession, and a
    scant 2% said they’ve fully recovered. | From 2008 to 2011, median household income
    in the United States decreased slightly, according to data from the U.S. Census
    Bureau’s Current Population Survey. In 2011 dollars, median household income was
    $52,546 in 2008, $51,195 in 2009, $50,831 in 2010, and $50,054 in 2011\. This
    represents a drop of 4.2% over the four-year period. | The median household income
    in the United States decreased from 2008 to 2011, according to the U.S. Census
    Bureau’s Current Population Survey. In 2008, the median household income was $52,546,
    while in 2011, it had fallen to $50,054\. This represented a decrease of 4.1%
    in real terms, or a decrease of $2,492 in inflation-adjusted dollars. The economic
    recession that began in 2008 was the main factor behind the decrease in median
    household income during this period. |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/6ea070bd3664e3eebf1746ed7ed9b0d4.png)  | 关于家庭中位收入，我们最近的数据是2011年的（普查局将在下周发布2012年的数据），但数据显示，在考虑通货膨胀后，美国的中位家庭收入在2008年至2011年间缩水了4.7%。因此，不足为奇的是，我们调查中超过一半（54%）的人表示，自经济衰退以来家庭收入几乎没有恢复，而只有2%的人表示他们已经完全恢复。
    | 根据美国普查局的当前人口调查数据，2008年至2011年间，美国的中位家庭收入略有下降。用2011年的美元计算，2008年的中位家庭收入为52,546美元，2009年为51,195美元，2010年为50,831美元，2011年为50,054美元。这四年期间下降了4.2%。
    | 根据美国普查局的当前人口调查数据，美国的中位家庭收入在2008年至2011年间减少。从2008年的52,546美元降至2011年的50,054美元。这代表了实际收入减少了4.1%，即调整通货膨胀后的2,492美元的减少。2008年开始的经济衰退是这一时期中位家庭收入下降的主要因素。
    |'
- en: 'Table 14: Samples to illustrate the outputs of PromptChart and its variant
    without *($S_{1}$)* (last 2 rows) for CS task.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 表14：展示PromptChart及其变体在CS任务中无*($S_{1}$)*（最后2行）的输出示例。
- en: A.10 Error Analysis Case Studies
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.10 错误分析案例研究
- en: '| Chart Image | Question | PromptChart | InstructGPT | Gold Answer |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 图表图片 | 问题 | PromptChart | InstructGPT | 黄金答案 |'
- en: '| ![[Uncaptioned image]](img/f7c0463477e82b092f97660c471d9985.png)  | How many
    color bars are there in the graph? | There are 4 color bars in the graph. The
    answer is 4. | There is only one color bar in the graph. The answer is 1. | 4
    |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/f7c0463477e82b092f97660c471d9985.png)  | 图表中有多少个颜色条？ | 图表中有4个颜色条。答案是4。
    | 图表中只有一个颜色条。答案是1。 | 4 |'
- en: '| ![[Uncaptioned image]](img/14874697c70fd529e09e6718e32ee82f.png)  | What
    is the color of "More"? | The color of the pie represented "More" is Gray. The
    answer is Gray. | The color of the pie represented "More" is Orange. The answer
    is Orange. | Gray |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/14874697c70fd529e09e6718e32ee82f.png)  | “更多”的颜色是什么？ | 代表“更多”的饼图颜色是灰色。答案是灰色。
    | 代表“更多”的饼图颜色是橙色。答案是橙色。 | 灰色 |'
- en: '| ![[Uncaptioned image]](img/b3a93a409e3f5d9e5766c658c8effbc9.png)  | What
    is the colour of India in the graph? | The colour of India in the graph is orange.
    The answer is orange. | The colour of India in the graph is not given in the data
    table. Therefore, the answer is not given. | Orange |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/b3a93a409e3f5d9e5766c658c8effbc9.png)  | 图表中印度的颜色是什么？ | 图表中印度的颜色是橙色。答案是橙色。
    | 图表中没有给出印度的颜色。因此，答案没有给出。 | 橙色 |'
- en: '| ![[Uncaptioned image]](img/a764b0f1ba0fc0b4ee3d735f7feaab3e.png)  | Is the
    color of right-side bars lightest? | The color of right-side bars is light brown.
    The lightest color of the bars is light brown, the answer is Yes. | The right-side
    bars are Dem/Lean Dem and Rep/Lean Rep. The color of Dem/Lean Dem bar is lightest.
    The answer is Yes. | Yes |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/a764b0f1ba0fc0b4ee3d735f7feaab3e.png)  | 右侧条形的颜色是否最浅？ | 右侧条形的颜色是浅棕色。条形中最浅的颜色是浅棕色，答案是是。
    | 右侧条形分别为Dem/Lean Dem和Rep/Lean Rep。Dem/Lean Dem条形的颜色最浅。答案是是。 | 是 |'
- en: '| ![[Uncaptioned image]](img/5cf6c9114ffe7464319cc9fdb9307c19.png)  | Which
    color Bar shows the greatest Meat consumer? | The greatest meat consumer is Finland
    with 175.09\. The color of Finland is Teal. So the answer is Teal. | The highest
    meat consumption is in Finland with 175.09\. So the color bar that shows the greatest
    meat consumer is the bar for Finland. The answer is Finland. | Finland |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/5cf6c9114ffe7464319cc9fdb9307c19.png)  | 哪种颜色的柱子显示了最大的肉类消费者？
    | 最大的肉类消费者是芬兰，为 175.09。芬兰的颜色是青绿色。所以答案是青绿色。 | 最大的肉类消费量在芬兰，为 175.09。所以显示最大肉类消费者的颜色柱子是芬兰的柱子。答案是芬兰。
    | 芬兰 |'
- en: '| ![[Uncaptioned image]](img/2151fb88735e68d73be74f477c33da9b.png)  | What
    country had the highest yearly cost of closing global poverty in 2002? | The highest
    yearly cost of closing global poverty in 2002 is Comoros (gray) with 16.87\. The
    answer is Comoros. | The highest yearly cost of closing global poverty in 2002
    is Botswana with 144.7\. The answer is Botswana | Botswana |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/2151fb88735e68d73be74f477c33da9b.png)  | 哪个国家在 2002 年关闭全球贫困的年度成本最高？
    | 2002 年关闭全球贫困的年度成本最高的是科摩罗（灰色），为 16.87。答案是科摩罗。 | 2002 年关闭全球贫困的年度成本最高的是博茨瓦纳，为 144.7。答案是博茨瓦纳
    | 博茨瓦纳 |'
- en: 'Table 15: The first four cases show PomptChart answers correctly by visual
    information whilst InstructGPT answers wrongly. The last two cases illustrate
    that visual information sometimes harms the model’s performance. Both models are
    run in the few-shot setting with our proposed FCQA prompt.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 表15：前四个案例显示了 PomptChart 根据视觉信息正确回答问题，而 InstructGPT 错误回答了问题。最后两个案例说明了视觉信息有时会损害模型的表现。两个模型都在我们的
    FCQA 提示下的少量样本设置中运行。
- en: '[Table 16](#A1.T16 "In A.10 Error Analysis Case Studies ‣ Appendix A Appendices
    ‣ Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question Answering
    and Summarization") shows our case studies as discussed in [Section 6.4](#S6.SS4
    "6.4 Error Analysis ‣ 6 Discussion ‣ Do LLMs Work on Charts? Designing Few-Shot
    Prompts for Chart Question Answering and Summarization").'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '[表16](#A1.T16 "在 A.10 错误分析案例研究 ‣ 附录 A 附录 ‣ LLM 在图表上是否有效？为图表问答和总结设计少量样本提示")
    展示了我们在[第6.4节](#S6.SS4 "6.4 错误分析 ‣ 6 讨论 ‣ LLM 在图表上是否有效？为图表问答和总结设计少量样本提示")中讨论的案例研究。'
- en: '| Question 1: What is the average of all three bars? ![[Uncaptioned image]](img/4d304577b953f5d98f318a07cbce172c.png)
    Generated Answer 1: The average of the three bars is (1.5 + 1.34 + 1.2) / 3 =
    1.32. The answer is 1.32. Gold Answer 1: 1.346  | Question 2: Is the average percentage
    of all three bars greater than 6%? ![[Uncaptioned image]](img/e432562e94e5cfedf9209b36e285b6c9.png)
    Generated Answer 2: The percentage of all three bars is ( 7.19 + 6.85 + 6.2 )
    / 3 = 6.7466666667%. The answer is No, the average is not greater than 6% Gold
    Answer 2: Yes  | ![[Uncaptioned image]](img/d163353cae64f3578d17228fc7869433.png)
    Generated Summary 3: This statistic shows the quantity of cocaine seized in Italy
    from 2010 to 2019 . In 2019 , 8269.54 kilograms of cocaine were seized in Italy
    , a significant increase from the 3847.7 kilograms seized in 2010 . The largest
    amount of cocaine seized during this period was in 2011 , with 6348.43 kilograms
    . Gold Summary 3: The statistic shows the total quantity of cocaine seized in
    Italy from 2010 to 2019 . In 2019 , 8.3 thousand kilograms of cocaine were seized
    in the country , the largest amount registered between 2010 and 2019 .  |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 问题 1：三根柱子的平均值是多少？ ![[未标注的图片]](img/4d304577b953f5d98f318a07cbce172c.png) 生成的答案
    1：三根柱子的平均值为 (1.5 + 1.34 + 1.2) / 3 = 1.32。答案是 1.32。黄金答案 1：1.346  | 问题 2：三根柱子的平均百分比是否大于
    6%？ ![[未标注的图片]](img/e432562e94e5cfedf9209b36e285b6c9.png) 生成的答案 2：三根柱子的百分比为 (
    7.19 + 6.85 + 6.2 ) / 3 = 6.7466666667%。答案是 否，平均值不大于 6%。黄金答案 2：是  | ![[未标注的图片]](img/d163353cae64f3578d17228fc7869433.png)
    生成的总结 3：该统计数据展示了 2010 年至 2019 年意大利缉获的可卡因数量。2019 年，意大利缉获了 8269.54 公斤的可卡因，相较于 2010
    年的 3847.7 公斤有了显著增长。在此期间缉获的最大数量发生在 2011 年，为 6348.43 公斤。黄金总结 3：该统计数据显示了 2010 年至
    2019 年意大利缉获的可卡因总量。2019 年，该国缉获了 8.3 千公斤的可卡因，是 2010 年至 2019 年间注册的最大数量。'
- en: '| Question 4: What are the opinions of Independents on Obama? ![[Uncaptioned
    image]](img/df8af6c1b82d0a16d9ba3eff991c8bc4.png) Generated Answer 4: During Obama’s
    second term , there has been a significant drop in support among Independents
    . In December 2012 , 48 % of Independents approved of Obama’s job performance
    , compared to only 32 % in November 2013 , a decrease of 16 percentage points
    . By comparison , Democrats’ approval of Obama’s job performance only decreased
    by 10 percentage points ( 78 % to 88 % ) and Republicans’ approval decreased by
    only 2 percentage points ( 10 % to 12 % ) . Gold Answer 4: Obama’s approval ratings
    among Independents declined from 48 % in December 2012 to 36 % in November 2013,
    a drop of 21 points, which is larger than 10 point decline among Democrats and
    7 point decline among Republicans.  | Question 5: What are the views of the general
    public on LGBT figures? ![[Uncaptioned image]](img/e70a361ffea8d1dbf3c882c6c2afe229.png)
    Generated Answer 5: Among the general public, 32 % of respondents named Ellen
    DeGeneres and 38 % named Elton John as the first LGBT artist or public figure
    that comes to mind. Other names mentioned included Rosie O’Donnell ( 11 % ) ,
    Jason Collins ( 8 % ) , Barney Frank ( 4 % ) , Anderson Cooper ( 4 % ) and Rock
    Hudson ( 4 % ) . A total of 38 % of respondents said they didn’t know. Gold Answer
    5: Jason Collins was the second - most frequently mentioned gay or lesbian public
    figure . 38 % said they could n’t name any gay or lesbian entertainers or public
    figures .  | ![[Uncaptioned image]](img/bf81eb88a68b959a77596b4675dcfe5e.png)
    Generated Summary 6: In 2018, the number of family units and unaccompanied children
    apprehended at the U.S. southwest border rose substantially, reaching a peak of
    27,518 family units and 5,653 unaccompanied children in December. The number of
    apprehensions for both groups increased steadily throughout the year, starting
    at 4,766 family units and 3,202 unaccompanied children in January. The increase
    in family unit apprehensions is especially notable, as the number of family units
    apprehended in 2018 was nearly six times higher than the number apprehended in
    2017\. Experts suggest that the rise in apprehensions is due to a combination
    of factors, including increasing violence in Central American countries and more
    expansive U.S. immigration policies. Gold Summary 6: In the months leading up
    to the shutdown, there was a large increase in the number of people in family
    units apprehended at the border. Monthly family apprehensions subsequently hit
    new highs each month from September through December, according to data going
    back to 2012\. There were nearly 17,000 family member apprehensions in September,
    more than 23,000 in October, about 25,000 in November and a record of more than
    27,000 in December.  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 问题 4: 独立人士对奥巴马的看法是什么？ ![[无标题图片]](img/df8af6c1b82d0a16d9ba3eff991c8bc4.png)
    生成的答案 4: 在奥巴马的第二个任期内，独立人士的支持率显著下降。2012年12月，48%的独立人士赞同奥巴马的工作表现，而2013年11月仅为32%，下降了16个百分点。相比之下，民主党对奥巴马的工作表现的赞同率仅下降了10个百分点（78%降至88%），而共和党的赞同率仅下降了2个百分点（10%降至12%）。
    黄金答案 4: 奥巴马在独立人士中的赞同率从2012年12月的48%下降到2013年11月的36%，下降了21个百分点，这一降幅大于民主党的10个百分点和共和党的7个百分点。
    | 问题 5: 普通公众对LGBT人物的看法是什么？ ![[无标题图片]](img/e70a361ffea8d1dbf3c882c6c2afe229.png)
    生成的答案 5: 在普通公众中，32%的受访者提到了**艾伦·德詹尼丝**，38%提到了**艾尔顿·约翰**，作为他们想到的第一个LGBT艺术家或公众人物。其他被提及的名字包括**罗斯·奥唐奈**（11%）、**杰森·柯林斯**（8%）、**巴尼·弗兰克**（4%）、**安德森·库珀**（4%）和**洛克·哈德森**（4%）。共有38%的受访者表示他们不知道。
    黄金答案 5: **杰森·柯林斯**是第二个被提及最多的同性恋公众人物。38%的人表示他们不能说出任何同性恋或跨性别的娱乐人士或公众人物。 | ![[无标题图片]](img/bf81eb88a68b959a77596b4675dcfe5e.png)
    生成的总结 6: 在2018年，美国西南边境被拘留的家庭单位和无人陪伴的儿童数量大幅上升，12月达到了27,518个家庭单位和5,653个无人陪伴的儿童的峰值。两组的拘留数量在全年稳步增加，从1月的4,766个家庭单位和3,202个无人陪伴的儿童开始。家庭单位的拘留增加尤为显著，因为2018年被拘留的家庭单位数量几乎是2017年的六倍。专家建议，拘留数量的增加是由于包括中美洲国家暴力增加和美国移民政策更加宽松等因素的综合影响。
    黄金总结 6: 在关门之前的几个月，边境上被拘留的家庭单位数量大幅增加。根据从2012年起的数据，9月至12月，每月家庭拘留数量不断创新高。9月近17,000个家庭成员被拘留，10月超过23,000，11月约25,000，12月创纪录地超过27,000。
    |'
- en: 'Table 16: Case studies for error analysis. Red texts are errors and green ones
    are correct generations.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '表 16: 错误分析的案例研究。红色文本为错误，绿色文本为正确生成。'
- en: A.11 Benchmarks Statistics
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.11 基准统计
- en: We present the statistics of the benchmarks we use in [Table 1](#S3.T1 "In ∙
    Problem Definition ‣ 3 Problem Formulation ‣ Do LLMs Work on Charts? Designing
    Few-Shot Prompts for Chart Question Answering and Summarization"). ChartQA focuses
    on logical and visual reasoning questions, while OpenCQA targets open-ended questions
    with explanatory answers and Chart-to-Text is a benchmark for chart summarization
    task.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了我们使用的基准统计数据，见[表1](#S3.T1 "在 ∙ 问题定义 ‣ 3 问题表述 ‣ 大型语言模型在图表上的表现？为图表问答和总结设计少样本提示")。ChartQA
    侧重于逻辑和视觉推理问题，而 OpenCQA 针对带有解释性回答的开放性问题，Chart-to-Text 是一个图表总结任务的基准。
