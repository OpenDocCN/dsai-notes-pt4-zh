- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:46:24'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded
    Knowledge'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2402.14310](https://ar5iv.labs.arxiv.org/html/2402.14310)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Jinlan Fu¹, Shenzhen Huangfu²^∗, Hang Yan³, See-Kiong Ng¹, Xipeng Qiu^(2,3),
  prefs: []
  type: TYPE_NORMAL
- en: ¹National University of Singapore, ²School of Computer Science, Fudan University
  prefs: []
  type: TYPE_NORMAL
- en: ³Shanghai AI Laboratory
  prefs: []
  type: TYPE_NORMAL
- en: '{jinlanjonna, shenzhenhuangfu}@gmail.com,'
  prefs: []
  type: TYPE_NORMAL
- en: yanhang@pjlab.org.cn, seekiong@nus.edu.sg, xpqiu@fudan.edu.cn    These two authors
    contributed equally.   Corresponding author.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Large Language Models (LLMs) have recently showcased remarkable generalizability
    in various domains. Despite their extensive knowledge, LLMs still face challenges
    in efficiently utilizing encoded knowledge to develop accurate and logical reasoning
    processes. To mitigate this problem, we introduced Hint-before-Solving Prompting
    (HSP), which guides the model to generate hints (e.g., specific knowledge or key
    ideas) for solving the problem and then generate solutions containing intermediate
    reasoning steps. Since HSP is orthogonal to prompting methods (e.g., Chain-of-Thought
    (CoT)), we applied HSP to CoT, Least-to-Most, Plan-and-Solve, and Standard promptings.
    The results of extensive experiments on 6 reasoning benchmarks and 4 open-source
    LLMs demonstrate that HSP can effectively improve the accuracy of reasoning tasks:
    (1) By applying high-quality hint-enhanced HSP to CoT prompting, Llama2-70B-Chat
    shows an improvement of 9.7. (2) Beyond exploring training-free LLM capabilities,
    we built the HSPMATH dataset based on HSP and fine-tuned Llemma-7B, reaching 64.3
    accuracy, surpassing GPT-3.5 and WizardMath-13B. We make our code and dataset
    publicly available at [https://github.com/jinlanfu/HSP](https://github.com/jinlanfu/HSP).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hint-before-Solving Prompting: Guiding LLMs to'
  prefs: []
  type: TYPE_NORMAL
- en: Effectively Utilize Encoded Knowledge
  prefs: []
  type: TYPE_NORMAL
- en: 'Jinlan Fu¹^†^†thanks:    These two authors contributed equally., Shenzhen Huangfu²^∗,
    Hang Yan³, See-Kiong Ng¹, Xipeng Qiu^(2,3)^†^†thanks:    Corresponding author.
    , ¹National University of Singapore, ²School of Computer Science, Fudan University
    ³Shanghai AI Laboratory {jinlanjonna, shenzhenhuangfu}@gmail.com, yanhang@pjlab.org.cn,
    seekiong@nus.edu.sg, xpqiu@fudan.edu.cn'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Benefiting from extensive training corpora and computational resources, Large
    Language Models (LLMs) have reached state-of-the-art performance in numerous Natural
    Language Processing (NLP) tasks Touvron et al. ([2023a](#bib.bib29)); OpenAI ([2023](#bib.bib24));
    Touvron et al. ([2023b](#bib.bib30)); Zhao et al. ([2023b](#bib.bib44)); Mistral
    AI Team ([2023](#bib.bib23)). However, LLMs still face challenges in complex reasoning
    tasks, such as mathematical reasoning Lu et al. ([2023](#bib.bib18)); Luo et al.
    ([2023a](#bib.bib19)); Imani et al. ([2023](#bib.bib13)) and commonsense reasoning Paranjape
    et al. ([2021](#bib.bib25)); Sap et al. ([2020](#bib.bib27)). Although possessing
    a wealth of knowledge, LLMs always fail to accurately apply encoded knowledge
    to generate coherent and strongly logical reasoning chains when addressing reasoning
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f55d641b8602b31192a7a3da877b4360.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The output comparison of Llama-2-Chat-70B solving a math problem
    (calculus) with and without a hint. Red text indicates erroneous information;
    green text indicates correct reasoning. Findings: (1) having a hint can help the
    LLM understand the problem. (2) The LLM possesses knowledge of calculus, and with
    a hint, it can accurately apply this knowledge.'
  prefs: []
  type: TYPE_NORMAL
- en: To improve the performance of LLMs on complex reasoning tasks, existing works
    have made several attempts. These previous works include fine-tuning on complete
    training datasets Luo et al. ([2023a](#bib.bib19)); Yu et al. ([2023](#bib.bib40));
    Yue et al. ([2023](#bib.bib42)) , training-free methods based on prompt engineering Zhou
    et al. ([2023a](#bib.bib47)); Wang et al. ([2023a](#bib.bib32)); Fu et al. ([2023](#bib.bib6));
    Lyu et al. ([2023](#bib.bib21)); Zhao et al. ([2023a](#bib.bib43)), or enhancing
    by retrieving knowledge from external knowledge bases Yao et al. ([2023b](#bib.bib38));
    He et al. ([2023](#bib.bib9)); Yang et al. ([2023](#bib.bib36)). Supervised fine-tuning
    methods are resource-intensive; current prompt engineering seldom attempt to improve
    LLMs’ ability to use accurate knowledge; retrieval augmentation methods are limited
    to specific tasks. For example, mathematical reasoning that includes many special
    symbols is difficult to access relevant knowledge through keyword or semantic
    retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: 'To mitigate these problems, in this work, we explore how LLMs can effectively
    utilize their encoded knowledge to enhance their reasoning logic and accuracy.
    We found that providing LLMs with hints effectively guides their use of encoded
    knowledge for problem-solving. Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge") illustrates
    this by comparing Llama2-70B’s outputs on a calculus problem with and without
    hints. The LLM cannot utilize calculus knowledge to solve the problem without
    any hints, as shown in Fig.[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge")-(a). However,
    when given a hint (as shown in Fig.[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge")-(b)): “… The
    second derivative is written $f^{\prime\prime}(x)$ denotes the second derivative”,
    which helped the LLM to better understand the target of the problem. Moreover,
    we conducted quantitative analysis on six reasoning datasets by introducing hints
    generated by GPT-4. The experimental results are shown in Fig. [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively
    Utilize Encoded Knowledge"). We can find that giving high-quality hints can effectively
    improve reasoning performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/40f6bd18baa808f04a497c33700b1afc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Results for Llama-2-Chat-70B (under CoT prompting) with or without
    introducing high-quality hints across six reasoning datasets. Findings: introducing
    hints lead to significant improvements, with an average relative increase of 9.7%.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it is challenging to provide high-quality hints for every sample.
    To address this problem, we propose the Hint-before-Solving (HSP) prompting method,
    which allows LLMs to generate hints on their own before solving a problem. The
    hints may include knowledge necessary for solving the problem (e.g., the hint
    shown in Fig. [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Hint-before-Solving Prompting:
    Guiding LLMs to Effectively Utilize Encoded Knowledge")-(b)), analyzing the question,
    and providing essential ideas for the solution. Our explorations of Hint-before-Solving
    (HSP) Prompting in this paper are driven by following research questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Q1: Can HSP guiding LLMs to autonomously generate helpful hints be effective?
    To answer this question, we incorporated HSP into four well-performing prompting
    methods to investigate how HSP performs (EXP-I). Furthermore, we examined the
    effectiveness of the HSP variant, HSP2, which provides hints and solutions in
    two stages (EXP-II). And explore the upper bound of LLMs under the HSP2 framework
    (EXP-III). (Sec. [4.1](#S4.SS1 "4.1 Q1: Can HSP Work? ‣ 4 Experiments and Results
    ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Q2: Does HSP still work when dealing with tasks that are challenging for LLMs?
    In other words, if a task is difficult for LLMs, can they still provide helpful
    hints? To answer this question, we evaluated the challenging MATH dataset (EXP-IV).
    Furthermore, we explore how LLMs perform under the self-consistency setting (EXP-V).
    (Sec. [4.2](#S4.SS2 "4.2 Q2: Can HSP Work on Hard Tasks? ‣ 4 Experiments and Results
    ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Q3: How do LLMs perform if they are supervised fine-tuned on a large-scale
    HSP prompting dataset? To answer this question, we constructed the HSPMATH dataset
    based on GSM8K and conducted supervised fine-tuning on Llemma-7B and Llama-2-13B.
    The experimental results show that we achieved a performance of 61.7 on Llemma-7B,
    surpassing GPT3.5\. (EXP-VI, Sec. [4.3](#S4.SS3 "4.3 Q3 (EXP-VI): How does SFT
    Perform on HSP Format Datasets? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"))'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main contributions of this work are summarized as below:'
  prefs: []
  type: TYPE_NORMAL
- en: (1) We discovered that providing hints allows LLMs to use their encoded knowledge
    accurately and effectively. For quantitative analysis, with GPT-4 generated hints,
    Llama-2-Chat-70B’s accuracy increased by nearly 10% across six datasets.
  prefs: []
  type: TYPE_NORMAL
- en: (2) We propose the HSP prompting method, allowing LLMs to automatically generate
    useful hints. We conducted extensive experiments and analyses on applying HSP
    to four popular prompting methods to verify HSP’s effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: (3) We collected 75,000 samples enhanced with hints, namely HSPMATH (to be released),
    and fine-tuned Llemma-7B to achieve 64.3 accuracy, surpassing GPT-3.5 (57.1) and
    WizardMath-13B (63.9).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/39fd91456576ed06a85ea82ce4459309.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Examples of input and output before (four examples at the top) and
    after (four examples at the bottom) applying HSP to standard Least-to-Most, Plan-and-Solve,
    and CoT promptings. The red text in the textbox indicates hints. We find that
    hints from LLMs, including problem-solving ideas close to the correct answer (e.g.,
    geographical distributions of both species), guide LLMs to use accurate knowledge
    for correct and logical reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Hint-before-Solving Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The prominent Chain-of-Thought (CoT) Wei et al. ([2022](#bib.bib34)) prompting
    method has inspired various prompting techniques to improve the LLMs’ performance.
    Such as Least-to-Most Zhou et al. ([2022](#bib.bib46)), tree-of-thought Yao et al.
    ([2023a](#bib.bib37)), graph-oc-thought Besta et al. ([2023](#bib.bib2)), plan-and-solve
    prompting Wang et al. ([2023a](#bib.bib32)). In this work, we aim to design a
    new prompting method that allows LLMs to better utilize their encoded knowledge,
    namely Hint-before-Solving Prompting (HSP). HSP enables LLMs to explicitly generate
    hints for solving problems. The hints can be knowledge or key ideas for solving
    the problem or analyzing the question, etc., and developing an accurate and logical
    intermediate reasoning process before predicting the final answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'HSP can be used in conjunction with some of the existing natural language forms
    of prompting methods (e.g., CoT). Fig. [3](#S1.F3 "Figure 3 ‣ 1 Introduction ‣
    Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge")
    shows examples of HSP integrated with four existing prompting methods, namely
    standard prompting, Least-to-Most prompting Zhou et al. ([2022](#bib.bib46)),
    Plan-and-Solve prompting Wang et al. ([2023b](#bib.bib33)), and Chain-of-Thought
    prompting Wei et al. ([2022](#bib.bib34)). We can observe that the current hints
    provide LLMs with perspectives for thought (e.g., consider the geographical distribution
    of black-tailed jackrabbits …), enhancing the effectiveness of prompting methods
    with the introduction of HSP.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Number | G8K | ASDiv | MArith | AQUA | MATH | SQA | Date |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Samples | 1,319 | 2,097 | 596 | 254 | 5,000 | 2,290 | 359 |'
  prefs: []
  type: TYPE_TB
- en: '| Examples | 8 | 8 | 8 | 8 | 4 | 6 | 10 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: The number of test samples and prompting examples across seven datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Large Language Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To verify the performance of our proposed method, we consider Mixtral-8x7B-Instruct-v0.1
    (Mix-56B) Mistral AI Team ([2023](#bib.bib23)) and Llama-2-Chat Touvron et al.
    ([2023c](#bib.bib31)) family models, where Llama-2-Chat-7B (Lm2-7B), Llama-2-Chat-13B
    (Lm2-13B), Llama-2-Chat-70B (Lm2-70B) were studied. Note, the italicized text
    in parentheses represents the abbreviated names of the models.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We evaluated the effectiveness of HSP across multiple datasets for mathematical
    and common sense reasoning tasks. Tab. [1](#S3.T1 "Table 1 ‣ 3 Experiment ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge") shows the number
    of test samples for these datasets and the number of samples for prompting in
    a few-shot setting.'
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Reasoning We considered five popular mathematical reasoning datasets,
    namely GSM8K (G8K) Cobbe et al. ([2021](#bib.bib5)), MultiArith (MArith) Roy and
    Roth ([2016](#bib.bib26)), AQuA Ling et al. ([2017](#bib.bib16)), ASDiv Miao et al.
    ([2021](#bib.bib22)), and MATH Hendrycks et al. ([2021a](#bib.bib10)).
  prefs: []
  type: TYPE_NORMAL
- en: Commonsense Reasoning
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Two common sense reasoning datasets were also taken into account, which are
    StrategyQA (SQA) Geva et al. ([2021](#bib.bib8)) and Date Understanding (Date) Srivastava
    et al. ([2022](#bib.bib28)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Baselines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The baseline Prompting methods considered in this work are listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: (1) Standard Prompting (SD) Brown et al. ([2020](#bib.bib3)) generates the answer
    for the given question without intermediate steps. (2) Chain-of-Thought Prompting
    (CoT) Wei et al. ([2022](#bib.bib34)) generate step-by-step solutions to a given
    problem. (3) Least-to-Most Prompting (LtM) Zhou et al. ([2022](#bib.bib46)) involves
    decomposing a complex problem into simple subproblems. (4) Plan-and-Solve Prompting
    (PS) Wang et al. ([2023b](#bib.bib33)) aims to handle the multi-step reasoning
    task by planning and solving each plan target.
  prefs: []
  type: TYPE_NORMAL
- en: 'To validate the effectiveness of the our HSP, we reimplemented some previous
    prompting methods. To ensure a fair comparison, we did not deliberately reproduce
    results reported in previous papers but rather aimed to maintain consistency in
    the experimental setup. For different prompting methods, we kept using the same
    set of demonstration samples and modified their format according to the prompting
    method. To demonstrate the usability of the results reimplemented in our work,
    we conducted a performance survey on existing baseline prompting with LLMs of
    comparable strength to those studied in this paper, with the results presented
    in Appendix [D](#A4 "Appendix D Reference Baseline ‣ Hint-before-Solving Prompting:
    Guiding LLMs to Effectively Utilize Encoded Knowledge").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Experimental Settings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Demonstration examples
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Under any prompting method, one dataset is used with the number of demonstration
    examples in all the experiments discussed in this work. Specifically, as shown
    in Tab. [1](#S3.T1 "Table 1 ‣ 3 Experiment ‣ Hint-before-Solving Prompting: Guiding
    LLMs to Effectively Utilize Encoded Knowledge"), there are 8 demonstration examples
    each of GSM8K, ASDiv, MArith, and AQUA, 6 examples for StrategyQA, 10 examples
    for Date, 4 examples for MATH.'
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameters of Greedy Decoding
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We use the vllm library ¹¹1[https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)
    for few-shot evaluation. For greedy decoding, the hyperparameters are set as:
    top_p=1, max_tokens=500, temperature=0, and the number of reasoning path n=1.
    For self-consistency, the number of reasoning path n is set to 4, 16, 32, 64,
    128, and temperature = 0.4\. Other hyperparameters are set the same as the greedy
    decoding. All inference experiments are based on four A100 GPUs.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiments and Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Method | HSP | G8K | ASDiv | MArith | AQUA | SQA | Date | Avg | Improvement
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-7B | SD | $\times$ | 5.8 | 43.7 | 7.4 | 19.7 | 62.0 | 33.1 | 28.6 | ![[Uncaptioned
    image]](img/d123627d548578e49a4caa5e94c3b059.png) |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 5.5 | 44.8 | 6.5 | 21.3 | 63.8 | 39.8 | 30.3 |'
  prefs: []
  type: TYPE_TB
- en: '| LtM | $\times$ | 15.5 | 49.5 | 21.8 | 26.0 | 63.9 | 49.3 | 37.7 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 16.0 | 50.2 | 29.2 | 23.2 | 65.3 | 42.3 | 37.7 |'
  prefs: []
  type: TYPE_TB
- en: '| PS | $\times$ ^‡ | 21.8 | 55.8 | 66.6 | 25.6 | 58.1 | 34.8 | 43.8 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 21.5 | 56.8 | 60.6 | 25.2 | 60.5 | 33.4 | 43.0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | $\times$ | 19.7 | 53.6 | 63.4 | 24.4 | 66.3 | 40.1 | 44.6 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 19.9 | 55.8 | 63.8 | 24.4 | 67.5 | 43.2 | 45.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Rlt Avg | 0.0 | 1.2 | 0.2 | -0.4 | 1.7 | 0.3 | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-13B | SD | $\times$ | 8.5 | 48.6 | 10.1 | 19.3 | 65.3 | 40.7 | 32.1 |
    ![[Uncaptioned image]](img/aed6fc020dd8f47afb47f092d9cdb3e7.png) |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 8.2 | 49.9 | 11.7 | 21.3 | 68.4 | 55.2 | 35.8 |'
  prefs: []
  type: TYPE_TB
- en: '| LtM | $\times$ | 23.8 | 55.8 | 52.7 | 31.1 | 68.8 | 60.4 | 48.8 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 27.6 | 55.9 | 57.7 | 23.2 | 69.6 | 51.3 | 47.6 |'
  prefs: []
  type: TYPE_TB
- en: '| PS | $\times$ ^‡ | 35.1 | 63.0 | 80.7 | 25.6 | 60.9 | 47.6 | 52.2 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 32.4 | 62.9 | 74.8 | 25.6 | 66.0 | 50.1 | 52.0 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | $\times$ | 34.5 | 60.5 | 83.2 | 25.6 | 68.0 | 57.7 | 54.9 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 36.5 | 61.2 | 87.1 | 25.6 | 72.1 | 57.7 | 56.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Rlt Avg | 0.7 | 0.5 | 1.1 | -1.5 | 3.3 | 2.0 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-70B | SD | $\times$ | 12.6 | 60.6 | 26.3 | 24.8 | 72.9 | 54.6 | 42.0
    | ![[Uncaptioned image]](img/b19061dddc1b87738fcdd1659a5234a4.png) |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 12.8 | 62.7 | 25.7 | 25.6 | 75.5 | 76.6 | 46.5 |'
  prefs: []
  type: TYPE_TB
- en: '| LtM | $\times$ | 40.2 | 68.6 | 72.0 | 39.4 | 75.2 | 71.0 | 61.1 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 41.9 | 69.4 | 76.8 | 38.6 | 77.0 | 77.4 | 63.5 |'
  prefs: []
  type: TYPE_TB
- en: '| PS | $\times$ ^‡ | 60.0 | 74.1 | 95.8 | 40.2 | 64.7 | 62.4 | 66.2 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 55.5 | 72.7 | 93.0 | 36.2 | 58.9 | 63.8 | 63.4 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | $\times$ | 46.1 | 72.5 | 93.8 | 35.8 | 74.6 | 71.6 | 65.7 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 50.3 | 74.4 | 94.6 | 37.0 | 77.0 | 73.0 | 67.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Rlt Avg | 0.4 | 0.9 | 0.6 | -0.7 | 0.2 | 7.8 | 1.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Mix-56B | SD | $\times$ | 19.8 | 64.3 | 44.6 | 22.0 | 72.1 | 45.4 | 44.7
    | ![[Uncaptioned image]](img/bb27e0b7d24f2e9500e31ca4722439df.png) |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 20.3 | 65.9 | 38.9 | 30.7 | 71.2 | 61.3 | 48.1 |'
  prefs: []
  type: TYPE_TB
- en: '| LtM | $\times$ ^‡ | 56.0 | 77.1 | 74.3 | 43.3 | 73.9 | 64.1 | 64.8 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 56.0 | 77.0 | 72.8 | 49.2 | 72.4 | 64.3 | 65.3 |'
  prefs: []
  type: TYPE_TB
- en: '| PS | $\times$ ^‡ | 73.2 | 84.2 | 97.8 | 49.6 | 66.3 | 68.5 | 73.3 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 67.1 | 82.3 | 92.3 | 48.4 | 67.6 | 66.6 | 70.7 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | $\times$ | 63.7 | 78.3 | 96.1 | 42.5 | 74.7 | 69.9 | 70.9 |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ ^† | 69.8 | 80.1 | 97.0 | 48.4 | 75.1 | 77.4 | 74.6 |'
  prefs: []
  type: TYPE_TB
- en: '| Rlt Avg | 0.1 | 0.4 | -2.9 | 4.8 | -0.2 | 5.4 | 1.3 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Results of applying HSP to existing prompting (Sec. [3.3](#S3.SS3
    "3.3 Baselines ‣ 3 Experiment ‣ Hint-before-Solving Prompting: Guiding LLMs to
    Effectively Utilize Encoded Knowledge")). Green (pink) values indicate the best
    performance without HSP (with HSP). Rlt Avg denotes the average relative improvement
    on the four prompting methods. Improvement represents the relative performance
    improvement when introducing HSP compared to not using HSP. ^† indicates HSP significantly
    boosts performance, whereas ^‡ suggests omitting HSP leads to better results.'
  prefs: []
  type: TYPE_NORMAL
- en: '4.1 Q1: Can HSP Work?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we considered three perspectives to answer whether HSP can
    enhance LLMs’ performance by generating hints containing specific knowledge, pivotal
    concepts, or analytical insights critical for solving the problem before attempting
    to solve it. Next, we will illustrate the three perspectives in detail.
  prefs: []
  type: TYPE_NORMAL
- en: '4.1.1 Exp-I: When HSP Meets Existing Prompting Methods'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We applied HSP to four existing popular prompting methods to explore how HSP
    performs in different prompting methods. Our experimental prompting methods include
    standard prompting (SD), Least to Most prompting (LtM), Plan-and-Solve prompting
    (PS), and CoT prompting, as introduced in Sec. [3.3](#S3.SS3 "3.3 Baselines ‣
    3 Experiment ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge") The results are shown in Tab. [2](#S4.T2 "Table 2 ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge"). The main findings are summarized as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) HSP is effective in standard and CoT prompting but fails in PS and LtM
    prompting. From Tab. [2](#S4.T2 "Table 2 ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"), we observe
    that the standard and CoT Prompting show significant performance improvements
    under HSP, while the enhancements from PS and LtM are limited. We try to give
    reasons below: Hints clarify the prompt or problem by offering key insights or
    solutions, influencing the logic behind the answers. They are crucial in task
    planning for both PS and LtM prompting, where introducing hints early can impact
    their planning process. Conversely, Standard and CoT prompting, focusing solely
    on the final answer or intermediate reasoning, are compatible with hints.'
  prefs: []
  type: TYPE_NORMAL
- en: '(2) Larger model sizes tend to show more significant performance improvements.
    From Tab. [3](#S4.T3 "Table 3 ‣ 4.1.1 Exp-I: When HSP Meets Existing Prompting
    Methods ‣ 4.1 Q1: Can HSP Work? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"), we can observe
    that the average performance improvements for 7B, 13B, 56B, and 70B models across
    four prompting methods (e.g., CoT and LtM) are 0.5, 1.0, 1.3, and 1.5, respectively.
    The reason can be that the model capabilities increase as the size increases,
    and higher capabilities will help achieve higher quality hints for better problem-solving.'
  prefs: []
  type: TYPE_NORMAL
- en: '(3) The introduction of HSP can steadily enhance the performance of CoT prompting.
    We observe that CoT, combined with HSP, shows performance enhancements across
    all four models and six datasets, while SD, LtM, and PS all experience some scenarios
    of performance drop. From the line chart in Tab. [2](#S4.T2 "Table 2 ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge"), we can observe that LtM and PS exhibit significant fluctuations
    in average performance gains across each dataset, with numerous settings of negative
    improvement.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | G8K | ASDiv | MArith | AQUA | SQA | Date | Avg | Improvement |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-7B | CoT | 19.7 | 53.6 | 63.4 | 24.4 | 66.3 | 40.1 | 44.6 | ![[Uncaptioned
    image]](img/8a0ad6f5d269039f7e2ed68b7aadfcd0.png) | ![[Uncaptioned image]](img/eb29fe78ceb41d80f8147b32be9b8170.png)
    |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP^† | 19.9 | 55.8 | 63.8 | 24.4 | 67.5 | 43.2 | 45.8 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP2^‡ | 22.6 | 55.4 | 62.6 | 25.2 | 66.8 | 40.4 | 45.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-13B | CoT | 34.5 | 60.5 | 83.2 | 25.6 | 68.0 | 57.7 | 54.9 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP^† | 36.5 | 61.2 | 87.1 | 25.6 | 72.1 | 57.7 | 56.7 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP2^‡ | 36.5 | 61.9 | 85.1 | 26.0 | 70.7 | 57.0 | 56.2 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-70B | CoT | 46.1 | 72.5 | 93.8 | 35.8 | 74.6 | 71.6 | 65.7 | ![[Uncaptioned
    image]](img/3c8f83a60f694c26bb897ce1a0345fb1.png) | ![[Uncaptioned image]](img/c96c0a77e4c36496f305864693afd10f.png)
    |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP^† | 50.3 | 74.4 | 94.6 | 37.0 | 77.0 | 73.0 | 67.7 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP2^‡ | 54.3 | 73.9 | 93.0 | 37.8 | 71.5 | 76.0 | 67.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Mix-56B | CoT | 63.7 | 78.3 | 96.1 | 42.5 | 74.7 | 69.9 | 70.9 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP^† | 69.3 | 80.1 | 97.0 | 48.4 | 75.1 | 77.4 | 74.6 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP2^‡ | 69.8 | 80.3 | 96.8 | 45.7 | 74.3 | 79.1 | 74.3 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: The results of applying HSP and HSP2 in CoT prompting. The bold values
    indicate the best performance. ^† and ^‡ denote that the performance of HSP and
    HSP2 is significantly better than CoT prompting, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | G8K | ASDiv | MArith | AQUA | SQA | Date | Avg |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT | 79.1 | - | 97.3 | 55.1 | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| 7B | HSP2 | 22.6 | 55.4 | 62.6 | 25.2 | 66.8 | 40.4 | 45.5 |'
  prefs: []
  type: TYPE_TB
- en: '|  | HSP2G | 39.0 | 62.5 | 88.9 | 28.7 | 69.5 | 61.0 | 58.3 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Impv | 16.4 | 7.1 | 26.3 | 3.5 | 2.7 | 20.6 | 12.8 |'
  prefs: []
  type: TYPE_TB
- en: '| 13B | HSP2 | 36.5 | 61.9 | 85.1 | 26.0 | 70.7 | 57.0 | 56.2 |'
  prefs: []
  type: TYPE_TB
- en: '|  | HSP2G | 56.4 | 66.4 | 95.6 | 36.6 | 72.0 | 69.4 | 66.1 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Impv | 19.9 | 4.5 | 10.5 | 10.6 | 1.3 | 12.4 | 9.9 |'
  prefs: []
  type: TYPE_TB
- en: '| 70B | HSP2 | 54.3 | 73.9 | 93.0 | 37.8 | 71.5 | 76.0 | 67.8 |'
  prefs: []
  type: TYPE_TB
- en: '|  | HSP2G | 68.2 | 79.0 | 98.0 | 43.3 | 76.6 | 87.7 | 75.5 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Impv | 13.9 | 5.1 | 5.0 | 5.5 | 5.1 | 11.7 | 7.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 56B | HSP2 | 69.8 | 80.3 | 96.8 | 45.7 | 74.3 | 79.1 | 74.3 |'
  prefs: []
  type: TYPE_TB
- en: '|  | HSP2G | 79.5 | 84.1 | 99.2 | 56.3 | 76.5 | 84.7 | 80.1 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Impv | 9.7 | 3.8 | 2.4 | 10.6 | 2.2 | 5.6 | 5.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Avg impv | 15.0 | 5.1 | 11.1 | 7.6 | 2.8 | 12.6 | 9.0 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Experimental results of enhancing HSP2 with hints generated by GPT4\.
    The values in green are the performance gap between HSP2G and HSP2\. The blue
    values are the improvement across the four models. The values in bold represent
    the best performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '4.1.2 EXP-II: Effectiveness of HSP for CoT Prompting'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In Exp-I, we found that applying HSP to CoT prompting results in significant
    and stable performance improvements across six datasets. Based on this, to identify
    flexible and effective ways to incorporate HSP, we attempted to explore whether
    a two-stage HSP (HSP2) approach could work in CoT prompting. The two-stage HSP
    means that LLMs produce outputs twice, first outputting a hint and then a solution.
    In contrast, HSP has only one output that contains both the hint and the solution.
    Experimental results on 6 datasets of 4 open source models are shown in Tab. [3](#S4.T3
    "Table 3 ‣ 4.1.1 Exp-I: When HSP Meets Existing Prompting Methods ‣ 4.1 Q1: Can
    HSP Work? ‣ 4 Experiments and Results ‣ Hint-before-Solving Prompting: Guiding
    LLMs to Effectively Utilize Encoded Knowledge"). The main observations are summarized
    as below:'
  prefs: []
  type: TYPE_NORMAL
- en: (1) The performance of HSP and HSP2 is comparable, despite the different ways
    of introducing hints. We can observe that among four LLMs, the largest average
    performance gap between HSP and HSP2 across six datasets was achieved on the Llama2-13B
    model with 0.5% (56.7-56.2). This indicates that although the methods of introducing
    hints differ, the extent of performance improvement brought by both is close.
  prefs: []
  type: TYPE_NORMAL
- en: '(2) HSP brings more stable improvements compared to HSP2. From histograms in
    Tab. [3](#S4.T3 "Table 3 ‣ 4.1.1 Exp-I: When HSP Meets Existing Prompting Methods
    ‣ 4.1 Q1: Can HSP Work? ‣ 4 Experiments and Results ‣ Hint-before-Solving Prompting:
    Guiding LLMs to Effectively Utilize Encoded Knowledge"), HSP shows improvements
    on nearly every dataset under models of four different sizes. In contrast, HSP2
    may lead to performance decreases in certain scenarios, for example, on the MArith
    dataset, the HSP2 performance decreases with Llama2-7B and Llama2-70B models.'
  prefs: []
  type: TYPE_NORMAL
- en: '4.1.3 Exp-III: The Impact of Hint Quality'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Introducing HSP can effectively enhance the performance of CoT prompting. But
    what is the upper bound? Here, we choose to explore on HSP2 because it enables
    the hints from external sources, a feature not available in the one-stage HSP
    structure, and HSP2 is comparable in strength to HSP (Sec. [4.1.2](#S4.SS1.SSS2
    "4.1.2 EXP-II: Effectiveness of HSP for CoT Prompting ‣ 4.1 Q1: Can HSP Work?
    ‣ 4 Experiments and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively
    Utilize Encoded Knowledge")). Hints generated by GPT-4 will be used as part of
    the input in the HSP2, denoting as HSP2G. Experimental results are shown in Tab. [4](#S4.T4
    "Table 4 ‣ 4.1.1 Exp-I: When HSP Meets Existing Prompting Methods ‣ 4.1 Q1: Can
    HSP Work? ‣ 4 Experiments and Results ‣ Hint-before-Solving Prompting: Guiding
    LLMs to Effectively Utilize Encoded Knowledge"). The performance of ChatGPT is
    copied from Yin et al. ([2023](#bib.bib39)), where the number of examples used
    to evaluate GSM8K, MultiArith, and AQUA is 8, 8, and 4, respectively. The main
    findings are summarized as below:'
  prefs: []
  type: TYPE_NORMAL
- en: (1) High-quality hints make the open-source model outperforms ChatGPT. We can
    observe that with the introduction of high-quality hints, all of the four LLMs
    with different model sizes and structures consistently showed performance improvement
    across six datasets. Furthermore, the Mix-56B equipped with HSP2(GPT4) outperformed
    ChatGPT on the GSM8K, MultiArith, and AQUA datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '(2) The introduction of high-quality hints leads to more improvements in lower-capability
    models. Tab. [4](#S4.T4 "Table 4 ‣ 4.1.1 Exp-I: When HSP Meets Existing Prompting
    Methods ‣ 4.1 Q1: Can HSP Work? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge") shows that
    the average performance improvements for the Llama2 models sized 7B, 13B, and
    70B are 12.8, 9.9, and 7.7, respectively. This indicates that with the support
    of high-quality hints, HSP2(GPT4)’s performance has improved a lot compared to
    HSP2. This can be attributed to that the low capability LLMs are hard to generate
    helpful hints that can assist in providing correct solutions. By providing high-quality
    hints, it is possible to offer more benefits beyond the capability of lower-ability
    LLMs. Therefore, there is a relatively large improvement in performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '4.2 Q2: Can HSP Work on Hard Tasks?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '4.2.1 EXP-IV: Exploring Difficult Tasks'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '| Prompting | Lm2-7B | Lm2-13B | Lm2-70B | Mix-56B |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CoT | 4.5 | 5.6 | 11.1 | 27.0 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP | 4.4 | 5.7 | 11.4 | 28.6^† |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Results on MATH dataset. Values in bold denote the best performance,
    and the value with ^† denotes the performance of HSP significantly outperforms
    CoT.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Param. | Prompting | Overall | Type | Level |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AG | CP | GT | IA | NT | PG | PC | L1 | L2 | L3 | L4 | L5 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| n=1,t=0 | CoT | 27.0 | 39.01 | 18.99 | 18.58 | 13.4 | 16.85 | 47.07 | 15.57
    | 62.47 | 44.41 | 30.59 | 18.62 | 8.08 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP | 28.6 | 39.09 | 23.21 | 21.09 | 13.84 | 15.93 | 46.27 | 15.2 | 64.3
    | 45.64 | 30.33 | 18.29 | 8.91 |'
  prefs: []
  type: TYPE_TB
- en: '| Impv | 1.62 | 0.08 | 4.22 | 2.51 | 0.44 | -0.92 | -0.8 | -0.37 | 1.83 | 1.23
    | -0.26 | -0.33 | 0.83 |'
  prefs: []
  type: TYPE_TB
- en: '| n=4,t=0.4 | CoT | 31.9 | 46.67 | 26.58 | 22.55 | 15.39 | 20.56 | 52.47 |
    17.95 | 71.17 | 49.33 | 36.6 | 23.39 | 10.8 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP | 33 | 47.35 | 26.37 | 26.1 | 15.39 | 21.3 | 54.88 | 19.6 | 72.31 |
    51.45 | 36.34 | 25.86 | 11.33 |'
  prefs: []
  type: TYPE_TB
- en: '| Impv | 1.1 | 0.68 | -0.21 | 3.55 | 0 | 0.74 | 2.41 | 1.65 | 1.14 | 2.12 |
    -0.26 | 2.47 | 0.53 |'
  prefs: []
  type: TYPE_TB
- en: '| n=16,t=0.4 | CoT | 37.6 | 53.41 | 31.22 | 27.35 | 19.38 | 26.67 | 58.9 |
    24.73 | 78.03 | 56.71 | 43.15 | 30.07 | 13.52 |'
  prefs: []
  type: TYPE_TB
- en: '| +HSP | 38.8 | 53.75 | 32.07 | 31.52 | 20.93 | 27.59 | 59.82 | 26.01 | 78.49
    | 57.83 | 44.39 | 33.11 | 13.44 |'
  prefs: []
  type: TYPE_TB
- en: '| Impv | 1.2 | 0.34 | 0.85 | 4.17 | 1.55 | 0.92 | 0.92 | 1.28 | 0.46 | 1.12
    | 1.24 | 3.04 | -0.08 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: The results of fine-grained evaluation for Mix-56B on the MATH dataset
    based on topic and problem difficulty. n is the number of sample paths of the
    self-consistency, and t is the temperature. AG, CP, GT, IA, NT, PA, PC respectively
    represent Algebra, Counting & Probability, Geometry, Intermediate Algebra, Number
    Theory, Prealgebra, Precalculus. Green values indicate an performance improvement
    of HSP prompting relative to CoT prompting, while red values indicate a decrease.
    Values in bold denote performance improvements greater than 1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The tasks we have explored are those that LLMs can handle well. As the difficulty
    of the task increases, LLMs may not possess sufficient knowledge and capability
    to address it. This raises a research question: Can LLMs generate helpful hints
    when they meet the challenge task?'
  prefs: []
  type: TYPE_NORMAL
- en: 'To answer this question, we chose to investigate the MATH dataset Hendrycks
    et al. ([2021b](#bib.bib11)), which is a dataset that poses challenges for large
    language models. The results are shown in Tab. [5](#S4.T5 "Table 5 ‣ 4.2.1 EXP-IV:
    Exploring Difficult Tasks ‣ 4.2 Q2: Can HSP Work on Hard Tasks? ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge"). We can observe that only the Mix-56B model shows a significant
    improvement of 1.6 under CoT+HSP prompting, while the Llama-2 family model fails.
    The reason might be that the Llama-2 family models face significant challenges
    on the MATH dataset, with their best result being only 11.4 (Lm2-70B), while the
    Mix-56B model achieves 27.0 under CoT prompting, it is difficult for Llama-2 family
    model to generate valuable hints.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To find which kind of samples Mix-56B can work, we performed a fine-grained
    analysis based on the mathematic problem topic and the difficulty, where the dataset
    provides the topics and the difficulty levels. Furthermore, to explore how self-consistency
    affects the performance, we evaluate this model using sample paths of n=4 and
    n=16 and a model temperature of 0.4. The results are shown in Tab. [6](#S4.T6
    "Table 6 ‣ 4.2.1 EXP-IV: Exploring Difficult Tasks ‣ 4.2 Q2: Can HSP Work on Hard
    Tasks? ‣ 4 Experiments and Results ‣ Hint-before-Solving Prompting: Guiding LLMs
    to Effectively Utilize Encoded Knowledge"). The main findings can be summarized
    as: (1) As n increases, under the CoT+HSP setting, the samples for which the LLM
    sees performance improvements shift from low to high difficulty. (2) As n increases,
    it is commonly believed that the most challenging GT type experiences the most
    significant performance improvement, amounting to 4.17. These indicate that by
    increasing n, HSP enhancement will correctly solve more complex questions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/657c2bcc42c3258e65465104e9747a94.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) 7B
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d1d7def38dcebba54dc7449266f0ca7b.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) 13B
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7710594cd5491923e5ab9cee87fd4944.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) 70B
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: The relative performance improvement of self-consistency between
    CoT+HSP and CoT. The numbers of sample paths are 4, 16, 32, and 128, and the model
    temperature is 0.4.'
  prefs: []
  type: TYPE_NORMAL
- en: '4.2.2 EXP-V: The Impact of Self-consistency'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In EXP-IV (Sec. [4.2.1](#S4.SS2.SSS1 "4.2.1 EXP-IV: Exploring Difficult Tasks
    ‣ 4.2 Q2: Can HSP Work on Hard Tasks? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge")), we found
    that self-consistency setting can improve performance of difficult tasks (MATH
    dataset), even difficult samples. This raises the question of how CoT prompting
    equipped with HSP performs under a self-consistency setting for the popular tasks.
    We sample paths with numbers (n) 4, 16, 32, and 128 for the self-consistency study
    and set the model temperature as 0.4\. The relative improvement between CoT+HSP
    and CoT on six datasets is shown in Fig. [4](#S4.F4 "Figure 4 ‣ 4.2.1 EXP-IV:
    Exploring Difficult Tasks ‣ 4.2 Q2: Can HSP Work on Hard Tasks? ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge") (Full results can be seen in the Appendix [E](#A5 "Appendix
    E Results of Self-consistency ‣ Hint-before-Solving Prompting: Guiding LLMs to
    Effectively Utilize Encoded Knowledge")). The main findings are as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) As the number of sampling paths increases, the relative improvements brought
    by applying HSP also increase. From Fig. [4](#S4.F4 "Figure 4 ‣ 4.2.1 EXP-IV:
    Exploring Difficult Tasks ‣ 4.2 Q2: Can HSP Work on Hard Tasks? ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge"), we can observe that at n=32 or n=128, all three models achieve
    their best performance. By calculating the Pearson correlation between the number
    of sampling (n) and relative performance for Lm2-7B, Lm2-13B, and Lm2-70B (excluding
    n=128), the correlations are 0.67, 0.72, and 0.95, respectively. The reason can
    be that the larger n leads to more explored hints, making it easier to generate
    hints beneficial for problem-solving.'
  prefs: []
  type: TYPE_NORMAL
- en: (2) Smaller models see the most significant relative performance improvement
    after applying self-consistency. This might be because smaller models have lower
    capabilities, while with guided hints, increasing n makes it easier to correct
    originally incorrect solutions, thus leading to more substantial performance improvements.
  prefs: []
  type: TYPE_NORMAL
- en: '4.3 Q3 (EXP-VI): How does SFT Perform on HSP Format Datasets?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite the remarkable success of LLMs, most existing open-source LLMs (e.g.,
    LLaMA-2) still face challenges in solving math problems due to complex reasoning
    processes. How do LLMs perform when they are supervised fine-tuning (SFT) on the
    HSP format dataset?
  prefs: []
  type: TYPE_NORMAL
- en: 'We construct a SFT dastaset with CoT+HSP format. Specifically, we collected
    hints by GPT4 for the GSM8K training set with 7.5k samples. 75,000 samples that
    rewrite the original questions from the MetaMATH Yu et al. ([2023](#bib.bib40)),
    are extracted. And the hints will be utilized to the derived questions. The dataset
    is named HSPMATH, and the original 7.5k samples will be used as standard samples,
    which we call HSPMATH-1.s The results with supervised fine-tuning on GSM8K under
    Llemma-7B and Llama2-13B are shown in Tab. [7](#S4.T7 "Table 7 ‣ 4.3 Q3 (EXP-VI):
    How does SFT Perform on HSP Format Datasets? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"). The baselines
    include: Llama2 Touvron et al. ([2023c](#bib.bib31)), RFT Yuan et al. ([2023](#bib.bib41)),
    Llemma Azerbayev et al. ([2023](#bib.bib1)), WizardMath Luo et al. ([2023b](#bib.bib20)),
    WizardLM Xu et al. ([2023](#bib.bib35)), MetaMath Yu et al. ([2023](#bib.bib40)),
    GPT-3.5 OpenAI ([2023](#bib.bib24)), PaLM Chowdhery et al. ([2023](#bib.bib4)),
    Minerva Lewkowycz et al. ([2022](#bib.bib15)), and Chinchilla Hoffmann et al.
    ([2022](#bib.bib12)) We can observed:'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) Supervised fine-tuning on datasets with HSP allows LLMs to achieve significant
    performance improvements. From Tab. [7](#S4.T7 "Table 7 ‣ 4.3 Q3 (EXP-VI): How
    does SFT Perform on HSP Format Datasets? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"), we can observe
    that in three groups of SFT (e.g., HSP-Llemma vs. Llemma on the HSPMATH1 dataset),
    the performance dramatically improves with HSP enhancement, which is 5.1, 12.3,
    and 5.6, respectively. The reason can be that supervised fine-tuning involving
    hints helps the model better utilize encoded knowledge during the reasoning stage,
    thereby improving the model’s generalization ability.'
  prefs: []
  type: TYPE_NORMAL
- en: (2) The result of HSP-Llemma-7B surpassed many popular LLMs, including GPT-3.5
    and WizardMath. By fine-tuning the HSPMATH dataset with 75k CoT+HSP format samples,
    our HSP-Llemma-7B achieved a competitive performance of 64.3, surpassing closed-source
    models such as GPT-3.5 (57.1) and PaLM-540B (56.5), and WizardMath-13B (63.9),
    which was fine-tuned on a large-scale mathematical corpus. It approaches the performance
    of MetaMath-7B (66.5), fine-tuned on a corpus of 40k samples.
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Size | ACC | Model | Size | ACC |'
  prefs: []
  type: TYPE_TB
- en: '| open source | close source |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2 | 7B | 14.6 | GPT-3.5 | - | 57.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2 | 13B | 28.7 | PaLM | 540B | 56.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Llemma | 7B | 36.4 | Minerva | 540B | 58.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2 | 34B | 42.2 | Minerva | 62B | 52.4 |'
  prefs: []
  type: TYPE_TB
- en: '| RFT | 7B | 50.3 | Chinchilla | 70B | 43.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Llemma | 34B | 51.5 | HSPMATH-1 (7.5k samples) |'
  prefs: []
  type: TYPE_TB
- en: '| RFT | 13B | 54.8 | Llemma | 7B | 46.8 |'
  prefs: []
  type: TYPE_TB
- en: '| WizardMath | 7B | 54.9 | HSP-Llemma | 7B | 51.9 |'
  prefs: []
  type: TYPE_TB
- en: '| WizardLM | 13B | 55.3 | Llama2 | 13B | 42.6 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2 | 70B | 56.8 | HSP-Llama2 | 13B | 54.9 |'
  prefs: []
  type: TYPE_TB
- en: '| WizardMath | 13B | 63.9 | HSPMATH (75k samples) |'
  prefs: []
  type: TYPE_TB
- en: '| MetaMath | 7B | 66.5 | Llemma | 7B | 58.7 |'
  prefs: []
  type: TYPE_TB
- en: '| MetaMath | 13B | 72.3 | HSP-Llemma | 7B | 64.3 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: The results of supervised fine-tuning on GSM8K. The value in bold
    denotes best SFT result.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chain-of-thought (CoT) has given a lot of inspiration to many works and has
    made numerous attempts to explore high performance. These techniques include using
    programming languages to represent the reasoning process Gao et al. ([2023](#bib.bib7));
    Lyu et al. ([2023](#bib.bib21)), representing the reasoning process with complex
    structures such as trees or graphs Yao et al. ([2023a](#bib.bib37)); Besta et al.
    ([2023](#bib.bib2)), task decomposition Zhou et al. ([2022](#bib.bib46)); Khot
    et al. ([2023](#bib.bib14)) and combining different prompting Liu et al. ([2023](#bib.bib17));
    Zhou et al. ([2023b](#bib.bib48)).
  prefs: []
  type: TYPE_NORMAL
- en: For the use of hint enhancement, Zheng et al. ([2023](#bib.bib45)) proposed
    Progressive-Hint Prompting (PHP), which aims to enhance LLMs’ effectiveness by
    introducing hints iterative, where the hint is a numerical value obtained from
    the previous solution (or base prompt’s solution). However, the hints for our
    HSP come from LLMs themselves, while PHP comes from previous predictions. Moreover,
    our hints can be one-stage, whereas PHP must be multi-staged.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 6.1 Length of Reasoning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Can HSP enhance the model’s reasoning capability and effectively reduce the
    length of the solution generated? To answer this question, we calculated the solution
    lengths for CoT and CoT+HSP (applying HSP to CoT). For easy understanding, we
    divided the solution length of CoT+HSP by the solution length of CoT, with the
    results shown in Fig. [5](#S6.F5 "Figure 5 ‣ 6.1 Length of Reasoning ‣ 6 Analysis
    ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"),
    where the red horizontal line indicates that the solution lengths of CoT and CoT+HSP
    are equal.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our main observation are summarized as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) Introducing HSP can effectively reduce the length of the solution. From
    Fig. [5](#S6.F5 "Figure 5 ‣ 6.1 Length of Reasoning ‣ 6 Analysis ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"), we can observate
    that, out of 24 results across four models and six datasets, only 5 instances
    show CoT+HSP having a longer solution length than CoT.'
  prefs: []
  type: TYPE_NORMAL
- en: (2) The effect of reducing the solution length by introducing HSP is most pronounced
    in mathematical reasoning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/03c9aa804eb4e69846c6eefb9ccb9521.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The ratio of solution lengths between CoT and HSP+CoT (HSP applied
    to CoT prompting). The red line (y=1) indicates that the solution lengths of CoT
    equals to HSP+CoT.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Case Study
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Guiding the model to generate hints before the solution can effectively improve
    the model’s performance. So, how does guiding LLM to generate hints first affect
    the generation of the model’s solution? We choose to introduce hints under CoT
    prompting and select case studies on mathematical reasoning and common sense reasoning
    tasks, as shown in Tab  [8](#S6.T8 "Table 8 ‣ Case 2 ‣ 6.2 Case Study ‣ 6 Analysis
    ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge").'
  prefs: []
  type: TYPE_NORMAL
- en: Case 1
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For the question, "Could a Jujutsu expert hypothetically defeat a Janissary?".
    Under CoT prompting, the LLM-generated solution only explained what “Jujutsu expert”
    and “Janissary” are. However, in CoT+HSP, the generated hint mentioned analyzing
    the possibility of the Jujutsu expert defeating Janissary from the perspectives
    of “martial arts skills” and “weapons,” thus making a correct solution followed
    up after introducing the hint.
  prefs: []
  type: TYPE_NORMAL
- en: Case 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The solution from CoT seems reasonable, but when calculating the annual total
    income of a teacher and coach, it was not multiplied by the hourly wage, leading
    to a final miscalculation. In contrast, CoT+HSP, within the hint, provided the
    problem-solving ideas, allowing for the correct answer to be calculated step by
    step in the solution based on the problem-solving strategy mentioned in the hint.
  prefs: []
  type: TYPE_NORMAL
- en: '| Case 1: Commonsense reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| Question: Could a Jujutsu expert hypothetically defeat a Janissary? |'
  prefs: []
  type: TYPE_TB
- en: '| True Answer: FALSE |'
  prefs: []
  type: TYPE_TB
- en: '| CoT Response: Jujutsu is a martial art that focuses on using an opponent’s
    strength against them.Janissaries were elite soldiers in the Ottoman Empire.Thus,
    a Jujutsu expert could potentially defeat a Janissary. So the answer is yes. [WRONG]
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT+HSP Response: |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: Compare the martial arts skills of a Jujutsu expert with the combat
    training of a Janissary, considering the historical context and weaponry. |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: A Jujutsu expert has martial arts skills, but no weapons.A Janissary
    is an elite Ottoman soldier with advanced combat training and weaponry. Thus,
    a Janissary would likely defeat a Jujutsu expert. So the answer is no. [CORRECT]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Case 2: Mathematical reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| Question: Jill gets paid $20 per hour to teach and $30 to be a cheerleading
    coach. If she works 50 weeks a year, 35 hours a week as a teacher and 15 hours
    a week as a coach, what’s her annual salary? |'
  prefs: []
  type: TYPE_TB
- en: '| True Answer: 57500 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT Response: Jill works 50 weeks a year. She works 35 hours a week as a
    teacher, so that’s 35 x 50 = $1750 per year. She works 15 hours a week as a coach,
    so that’s 15 x 50 = $750 per year. Her total annual salary is $1750 + $750 = $2500\.
    The answer is $2500\. [WRONG] |'
  prefs: []
  type: TYPE_TB
- en: '| CoT+HSP Response: |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: To find out Jill’s annual salary, first calculate how much she makes
    per week as a teacher and as a coach. Then, multiply this total amount by the
    number of weeks she works in a year. This will give you Jill’s annual salary.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: Jill makes $20 per hour as a teacher, so 35 hours a week is 35
    x 20 = 700 per week. As a coach, she makes $30 per hour, so 15 hours a week is
    15 x 30 = 450 per week. 700 + 450 = 1150 per week. 1150 x 50 weeks = 57500 per
    year. The answer is 57500\. [CORRECT] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: Case studies of solving mathematical reasoning and common sense reasoning
    problems with CoT+HSP and CoT prompting on the Mixtral-7*8B model. Blue text indicates
    the stem, pink text indicates the effective hint, cyan text indicates the judgment
    of whether the answer is correct, [CORRECT] denotes correct, and [WRONG] denotes
    incorrect.'
  prefs: []
  type: TYPE_NORMAL
- en: 7 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this work, we present Hint-before-Solving Prompting (HSP), a technique that
    directs Large Language Models (LLMs) to initially produce hints that assist in
    problem-solving before generating solutions that incorporate intermediate reasoning
    steps. This method alleviates the problem that LLMs, despite having vast knowledge,
    still encounter in effectively utilizing their encoded knowledge to construct
    precise and rational reasoning paths. Through extensive experimental analysis,
    we have drawn several main findings: (1) HSP can guide LLMs to generate knowledge
    or key ideas to problems, thereby helping LLMs to generate more logically coherent
    reasoning paths to reach the correct answers (Sec. [4.1.1](#S4.SS1.SSS1 "4.1.1
    Exp-I: When HSP Meets Existing Prompting Methods ‣ 4.1 Q1: Can HSP Work? ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge")). (2) For the high-quality hint, the performance improvement
    of open-source models can reach 12.8, even surpassing ChatGPT (Sec. [4.1.3](#S4.SS1.SSS3
    "4.1.3 Exp-III: The Impact of Hint Quality ‣ 4.1 Q1: Can HSP Work? ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge")). (3) When meets challenging tasks, HSP fails on low-capability
    open-source LLMs (e.g., Llama2-7B); however, on high-capability open-source LLMs,
    under the self-consistency setting, HSP improves a lot on the samples with difficult
    topics or hard levels (Sec. [4.2.1](#S4.SS2.SSS1 "4.2.1 EXP-IV: Exploring Difficult
    Tasks ‣ 4.2 Q2: Can HSP Work on Hard Tasks? ‣ 4 Experiments and Results ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge")). (4) Supervised
    fine-tuning on the GSM8K training dataset with the CoT+HSP format, our HSP-Llemma-7B
    (64.3) outperform GPT3.5 (57,1) and WizardMath-13B (63.9) (Sec. [4.3](#S4.SS3
    "4.3 Q3 (EXP-VI): How does SFT Perform on HSP Format Datasets? ‣ 4 Experiments
    and Results ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize
    Encoded Knowledge")).'
  prefs: []
  type: TYPE_NORMAL
- en: Limitation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we summarize some limitations of this paper, as follows: (1) The HSPMATH
    dataset was expanded by rewriting questions from GSM8K nine times, but our hints
    were generated based only on the original samples and applied to the nine rewritten
    samples. The rewritten samples might undergo logical changes, making the introduction
    of hints less harmonious. There might be a risk of poor performance during supervised
    fine-tuning. In the future, we will refine this dataset carefully and release
    a new version. (2) Due to limitations in computational resources, this paper did
    not conduct supervised fine-tuning on models larger than 13B parameters in the
    SFT experiments, resulting in an incomplete exploration of HSP-enhanced supervised
    fine-tuning. We will undertake this exploration in the future.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Azerbayev et al. (2023) Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster,
    Marco Dos Santos, Stephen McAleer, Albert Q. Jiang, Jia Deng, Stella Biderman,
    and Sean Welleck. 2023. [Llemma: An open language model for mathematics](https://doi.org/10.48550/ARXIV.2310.10631).
    *CoRR*, abs/2310.10631.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Besta et al. (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, and Torsten Hoefler. 2023. [Graph of thoughts: Solving elaborate
    problems with large language models](https://doi.org/10.48550/ARXIV.2308.09687).
    *CoRR*, abs/2308.09687.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chowdhery et al. (2023) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
    Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily
    Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael
    Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
    Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam
    Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander
    Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M.
    Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
    Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,
    Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern,
    Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2023. [Palm: Scaling language
    modeling with pathways](http://jmlr.org/papers/v24/22-1144.html). *J. Mach. Learn.
    Res.*, 24:240:1–240:113.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, et al. 2021. Training verifiers to solve math word problems. *arXiv e-prints*,
    pages arXiv–2110.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. (2023) Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar
    Khot. 2023. [Complexity-based prompting for multi-step reasoning](https://openreview.net/pdf?id=yf1icZHC-l9).
    In *The Eleventh International Conference on Learning Representations, ICLR 2023,
    Kigali, Rwanda, May 1-5, 2023*. OpenReview.net.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2023) Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu,
    Yiming Yang, Jamie Callan, and Graham Neubig. 2023. [PAL: program-aided language
    models](https://proceedings.mlr.press/v202/gao23f.html). In *International Conference
    on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA*, volume
    202 of *Proceedings of Machine Learning Research*, pages 10764–10799\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geva et al. (2021) Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth,
    and Jonathan Berant. 2021. [Did aristotle use a laptop? A question answering benchmark
    with implicit reasoning strategies](https://doi.org/10.1162/TACL_A_00370). *Trans.
    Assoc. Comput. Linguistics*, 9:346–361.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. (2023) Hangfeng He, Hongming Zhang, and Dan Roth. 2023. [Rethinking
    with retrieval: Faithful large language model inference](https://doi.org/10.48550/ARXIV.2301.00303).
    *CoRR*, abs/2301.00303.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2021a) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
    Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021a. Measuring
    mathematical problem solving with the math dataset. In *Thirty-fifth Conference
    on Neural Information Processing Systems Datasets and Benchmarks Track (Round
    2)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2021b) Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul
    Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b. [Measuring
    mathematical problem solving with the MATH dataset](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html).
    In *Proceedings of the Neural Information Processing Systems Track on Datasets
    and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hoffmann et al. (2022) Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena
    Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks,
    Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George
    van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan,
    Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. 2022. [Training compute-optimal
    large language models](https://doi.org/10.48550/ARXIV.2203.15556). *CoRR*, abs/2203.15556.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Imani et al. (2023) Shima Imani, Liang Du, and Harsh Shrivastava. 2023. [Mathprompter:
    Mathematical reasoning using large language models](https://doi.org/10.18653/V1/2023.ACL-INDUSTRY.4).
    In *Proceedings of the The 61st Annual Meeting of the Association for Computational
    Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023*, pages
    37–42\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Khot et al. (2023) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle
    Richardson, Peter Clark, and Ashish Sabharwal. 2023. [Decomposed prompting: A
    modular approach for solving complex tasks](https://openreview.net/pdf?id=_nGgzQjzaRy).
    In *The Eleventh International Conference on Learning Representations, ICLR 2023,
    Kigali, Rwanda, May 1-5, 2023*. OpenReview.net.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lewkowycz et al. (2022) Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan
    Dyer, Henryk Michalewski, Vinay V. Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag,
    Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra.
    2022. [Solving quantitative reasoning problems with language models](http://papers.nips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c9c4fe191-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 35: Annual Conference on
    Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,
    November 28 - December 9, 2022*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ling et al. (2017) Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom.
    2017. [Program induction by rationale generation: Learning to solve and explain
    algebraic word problems](https://doi.org/10.18653/V1/P17-1015). In *Proceedings
    of the 55th Annual Meeting of the Association for Computational Linguistics, ACL
    2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers*, pages 158–167\.
    Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023) Tengxiao Liu, Qipeng Guo, Yuqing Yang, Xiangkun Hu, Yue Zhang,
    Xipeng Qiu, and Zheng Zhang. 2023. [Plan, verify and switch: Integrated reasoning
    with diverse x-of-thoughts](https://aclanthology.org/2023.emnlp-main.169). In
    *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,
    EMNLP 2023, Singapore, December 6-10, 2023*, pages 2807–2822\. Association for
    Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2023) Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, and Kai-Wei Chang.
    2023. [A survey of deep learning for mathematical reasoning](https://doi.org/10.18653/V1/2023.ACL-LONG.817).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 14605–14631\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Luo et al. (2023a) Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou,
    Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023a.
    [Wizardmath: Empowering mathematical reasoning for large language models via reinforced
    evol-instruct](https://doi.org/10.48550/ARXIV.2308.09583). *CoRR*, abs/2308.09583.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Luo et al. (2023b) Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou,
    Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023b.
    [Wizardmath: Empowering mathematical reasoning for large language models via reinforced
    evol-instruct](https://doi.org/10.48550/ARXIV.2308.09583). *CoRR*, abs/2308.09583.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lyu et al. (2023) Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao,
    Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023. [Faithful chain-of-thought
    reasoning](https://doi.org/10.48550/ARXIV.2301.13379). *CoRR*, abs/2301.13379.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miao et al. (2021) Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2021. [A
    diverse corpus for evaluating and developing english math word problem solvers](http://arxiv.org/abs/2106.15772).
    *CoRR*, abs/2106.15772.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mistral AI Team (2023) Mistral AI Team. 2023. Mixtral of experts. [https://mistral.ai/news/mixtral-of-experts/](https://mistral.ai/news/mixtral-of-experts/).
    Accessed: 2023-12-26.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2023) OpenAI. 2023. [GPT-4 technical report](https://doi.org/10.48550/ARXIV.2303.08774).
    *CoRR*, abs/2303.08774.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paranjape et al. (2021) Bhargavi Paranjape, Julian Michael, Marjan Ghazvininejad,
    Hannaneh Hajishirzi, and Luke Zettlemoyer. 2021. [Prompting contrastive explanations
    for commonsense reasoning tasks](https://doi.org/10.18653/V1/2021.FINDINGS-ACL.366).
    In *Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021,
    Online Event, August 1-6, 2021*, volume ACL/IJCNLP 2021 of *Findings of ACL*,
    pages 4179–4192\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roy and Roth (2016) Subhro Roy and Dan Roth. 2016. [Solving general arithmetic
    word problems](http://arxiv.org/abs/1608.01413). *CoRR*, abs/1608.01413.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sap et al. (2020) Maarten Sap, Vered Shwartz, Antoine Bosselut, Yejin Choi,
    and Dan Roth. 2020. [Commonsense reasoning for natural language processing](https://doi.org/10.18653/V1/2020.ACL-TUTORIALS.7).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics: Tutorial Abstracts, ACL 2020, Online, July 5, 2020*, pages 27–33\.
    Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava et al. (2022) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
    Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya
    Gupta, Adrià Garriga-Alonso, et al. 2022. Beyond the imitation game: Quantifying
    and extrapolating the capabilities of language models. *arXiv preprint arXiv:2206.04615*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and
    Guillaume Lample. 2023a. [Llama: Open and efficient foundation language models](https://doi.org/10.48550/ARXIV.2302.13971).
    *CoRR*, abs/2302.13971.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023b.
    [Llama 2: Open foundation and fine-tuned chat models](https://doi.org/10.48550/ARXIV.2307.09288).
    *CoRR*, abs/2307.09288.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023c) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023c. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023a) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. 2023a. [Plan-and-solve prompting: Improving zero-shot
    chain-of-thought reasoning by large language models](https://doi.org/10.18653/V1/2023.ACL-LONG.147).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 2609–2634\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023b) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. 2023b. Plan-and-solve prompting: Improving zero-shot
    chain-of-thought reasoning by large language models. *arXiv preprint arXiv:2305.04091*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems*, 35:24824–24837.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023) Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan
    Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language
    models to follow complex instructions. *arXiv preprint arXiv:2304.12244*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023) Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang
    Song, Shixing Yu, Saad Godil, Ryan Prenger, and Anima Anandkumar. 2023. [Leandojo:
    Theorem proving with retrieval-augmented language models](https://doi.org/10.48550/ARXIV.2306.15626).
    *CoRR*, abs/2306.15626.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L.
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a. [Tree of thoughts: Deliberate
    problem solving with large language models](https://doi.org/10.48550/ARXIV.2305.10601).
    *CoRR*, abs/2305.10601.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R. Narasimhan, and Yuan Cao. 2023b. [React: Synergizing reasoning and
    acting in language models](https://openreview.net/pdf?id=WE_vluYUL-X). In *The
    Eleventh International Conference on Learning Representations, ICLR 2023, Kigali,
    Rwanda, May 1-5, 2023*. OpenReview.net.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yin et al. (2023) Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi
    Dai, Xuanjing Huang, and Xipeng Qiu. 2023. [Exchange-of-thought: Enhancing large
    language model capabilities through cross-model communication](https://aclanthology.org/2023.emnlp-main.936).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2023, Singapore, December 6-10, 2023*, pages 15135–15153\. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2023) Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying
    Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023.
    [Metamath: Bootstrap your own mathematical questions for large language models](https://doi.org/10.48550/ARXIV.2309.12284).
    *CoRR*, abs/2309.12284.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. (2023) Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi
    Tan, and Chang Zhou. 2023. [Scaling relationship on learning mathematical reasoning
    with large language models](https://doi.org/10.48550/ARXIV.2308.01825). *CoRR*,
    abs/2308.01825.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yue et al. (2023) Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan
    Sun, Yu Su, and Wenhu Chen. 2023. [Mammoth: Building math generalist models through
    hybrid instruction tuning](https://doi.org/10.48550/ARXIV.2309.05653). *CoRR*,
    abs/2309.05653.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2023a) Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and
    Lidong Bing. 2023a. [Verify-and-edit: A knowledge-enhanced chain-of-thought framework](https://doi.org/10.18653/V1/2023.ACL-LONG.320).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 5823–5840\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2023b) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan
    Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li,
    Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023b. [A survey
    of large language models](https://doi.org/10.48550/ARXIV.2303.18223). *CoRR*,
    abs/2303.18223.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2023) Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and
    Yu Li. 2023. [Progressive-hint prompting improves reasoning in large language
    models](https://doi.org/10.48550/ARXIV.2304.09797). *CoRR*, abs/2304.09797.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2022) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al.
    2022. Least-to-most prompting enables complex reasoning in large language models.
    *arXiv preprint arXiv:2205.10625*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2023a) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le,
    and Ed H. Chi. 2023a. [Least-to-most prompting enables complex reasoning in large
    language models](https://openreview.net/pdf?id=WZH7099tgfM). In *The Eleventh
    International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda,
    May 1-5, 2023*. OpenReview.net.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2023b) Jianpeng Zhou, Wanjun Zhong, Yanlin Wang, and Jiahai Wang.
    2023b. [Adaptive-solver framework for dynamic strategy selection in large language
    model reasoning](https://doi.org/10.48550/ARXIV.2310.01446). *CoRR*, abs/2310.01446.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Robustness Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Considering the impact that varying sets of examples may have on results, the
    question arises: Is the HSP framework effective with diverse example sets?'
  prefs: []
  type: TYPE_NORMAL
- en: 'To investigate this, we conducted experiments on the GSM8K (mathematical reasoning)
    and StrategyQA (common sense reasoning) datasets. Like the setting in Exp-I, we
    randomly chose four sets of examples from the testing set, each comprising $8$
    examples for StrategyQA. We then crafted hints and solutions featuring intermediate
    reasoning steps aided by GPT-4. These experiments were carried out on four LLMs:
    Llama2-7B, Llama2-13B, Llama2-70B, and Mixtral-8*7B. According to the results
    presented in Tab. [9](#A1.T9 "Table 9 ‣ Appendix A Robustness Analysis ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge"), CoT+HSP consistently
    outperformed CoT across the GSM8K and StrategyQA datasets, with all four models
    showing significant performance enhancements across the four example sets. This
    demonstrates the robustness of the performance gains achieved by integrating CoT
    with HSP.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | HSP | GSM8K | SQA |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| E1 | E2 | E3 | E4 | E1 | E2 | E3 | E4 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-7B | $\times$ | 20.2 | 15.2 | 18.0 | 17.0 | 61.2 | 56.6 | 63.9 | 60.9
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 22.7 | 21.6 | 23.4 | 22.8 | 63.8 | 61.5 | 65.9 | 63.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-13B | $\times$ | 35.9 | 29.1 | 25.4 | 32.2 | 64.1 | 60.6 | 67.5 | 63.2
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 37.1 | 34.7 | 35.1 | 36.5 | 67.4 | 62.0 | 68.2 | 65.9 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-70B | $\times$ | 53.7 | 54.1 | 54.4 | 54.0 | 71.1 | 65.1 | 75.1 | 68.2
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 60.1 | 56.3 | 55.3 | 59.3 | 71.7 | 72.1 | 75.8 | 73.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Lm2-56B | $\times$ | 67.9 | 68.8 | 67.2 | 67.8 | 65.4 | 60.3 | 69.3 | 61.9
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\checkmark$ | 69.1 | 69.1 | 68.2 | 68.8 | 67.3 | 64.5 | 70.6 | 66.8 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Experimental results for CoT Prompting with and without HSP on the
    GSM8K and StrategyQA (SQA) datasets across various example groups (E1, E2, E3,
    and E4). Values in bold denote the best results.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mathematical reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| Please answer the following question. |'
  prefs: []
  type: TYPE_TB
- en: '| Example 1: Question: Shawn has five toys. For Christmas, he got two toys
    each from his mom and dad. How many toys does he have now? |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: Begin with the number of toys Shawn had initially. Then, add the number
    of toys he received from each parent. Remember, each parent gave him a certain
    number of toys, so you’ll need to add those to his original amount to find out
    how many toys he has now. |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: Shawn started with 5 toys. If he got 2 toys each from his mom and
    dad, then that is 4 more toys. 5 + 4 = 9\. The answer is 9. |'
  prefs: []
  type: TYPE_TB
- en: '| …… (Omitting 7 examples) |'
  prefs: []
  type: TYPE_TB
- en: '| Testing Example: |'
  prefs: []
  type: TYPE_TB
- en: '| Question: [QUESTION] |'
  prefs: []
  type: TYPE_TB
- en: '| Commonsense reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| Please answer the following question. |'
  prefs: []
  type: TYPE_TB
- en: '| Example 1: Question: Do hamsters provide food for any animals? |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: Consider the natural role of hamsters in the food chain and who might
    rely on them as a source of nutrition. |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: Hamsters are prey animals. Prey are food for predators. Thus, hamsters
    provide food for some animals. So the answer is yes. |'
  prefs: []
  type: TYPE_TB
- en: '| …… (Omitting 5 examples) |'
  prefs: []
  type: TYPE_TB
- en: '| Testing Example: |'
  prefs: []
  type: TYPE_TB
- en: '| Question: [QUESTION] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 10: Prompt template for mathematical reasoning and commonsense reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Prompt Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The four models evaluated in this paper, namely Lm2-7B, Lm2-13B, Lm2-70B, and
    Mix-56B, were all tested using the same prompt template. Fig. [10](#A1.T10 "Table
    10 ‣ Appendix A Robustness Analysis ‣ Hint-before-Solving Prompting: Guiding LLMs
    to Effectively Utilize Encoded Knowledge") shows the prompt template for mathematical
    reasoning and common sense reasoning tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Case Study
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Guiding the model to generate hints before the solution can effectively improve
    the model’s performance. So, how does guiding LLM to generate hints first affect
    the generation of the model’s solution? We choose to introduce hints under CoT
    prompting and select case studies on mathematical reasoning and common sense reasoning
    tasks, as shown in Tab  [11](#A3.T11 "Table 11 ‣ Case 4 ‣ Appendix C Case Study
    ‣ Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge").'
  prefs: []
  type: TYPE_NORMAL
- en: Case 1
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The solution from CoT appears logical, but its analysis remains superficial,
    merely focusing on the relationship between the two entities (US brand Nice and
    the Western honey bee) to answer the question. In contrast, the hint from CoT+HSP
    suggests approaching from a deeper view, specifically questioning whether the
    crops relied upon by US brand Nice depend on Western honey bees for pollination,
    which leads to the correct answer.
  prefs: []
  type: TYPE_NORMAL
- en: Case 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For question “Do black-tailed jackrabbits fear the European wildcat?”, CoT only
    considered the biological perspective, leading to an incorrect answer. However,
    the hint from CoT+HSP suggested that it is necessary to consider not only the
    biological aspect but also the habitat of the organism, thereby achieving the
    correct answer.
  prefs: []
  type: TYPE_NORMAL
- en: Case 3
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We can observe that CoT’s calculation method overlooks an important piece of
    knowledge, namely the formula for calculating the perimeter: “The distance traveled
    by a point on the edge of a rotating object equals the circle’s circumference.”.
    In contrast, CoT+Hint successfully suggests utilizing the formula for perimeter,
    thereby obtaining the correct answer.'
  prefs: []
  type: TYPE_NORMAL
- en: Case 4
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The question involves calculating the perimeter of a rectangle, but the CoT
    method only adds the width and height of a rectangle. CoT+HSP suggested that the
    perimeter be calculated by four lengths, making the final answer calculation correct.
  prefs: []
  type: TYPE_NORMAL
- en: '| Case 1: Commonsense reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| Question: Does US brand Nice depend on Western honey bee? |'
  prefs: []
  type: TYPE_TB
- en: '| True Answer: TRUE |'
  prefs: []
  type: TYPE_TB
- en: '| CoT Response: Nice is a brand of ice cream. Ice cream is not made from honey
    bees. Thus, Nice does not depend on Western honey bees. So the answer is no. [WRONG]
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT+HSP Response: |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: Consider the crops that Nice brand depends on and whether those crops
    require pollination by Western honey bees. |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: Nice brand depends on almonds. Almonds require pollination by Western
    honey bees. Thus, Nice brand depends on Western honey bees. So the answer is yes.
    [CORRECT] |'
  prefs: []
  type: TYPE_TB
- en: '| Case 2: Commonsense reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| Question: Do black-tailed jackrabbits fear the European wildcat? |'
  prefs: []
  type: TYPE_TB
- en: '| True Answer: FALSE |'
  prefs: []
  type: TYPE_TB
- en: '| CoT Response: Black-tailed jackrabbits are prey animals. European wildcats
    are predators. Thus, black-tailed jackrabbits would fear the European wildcat.
    So the answer is yes. [WRONG] |'
  prefs: []
  type: TYPE_TB
- en: '| CoT+HSP Response: |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: Consider the natural habitats of black-tailed jackrabbits and European
    wildcats and whether their paths would cross. |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: Black-tailed jackrabbits are native to North America. European
    wildcats are native to Europe. Thus, their paths would not naturally cross. So
    the answer is no. [CORRECT] |'
  prefs: []
  type: TYPE_TB
- en: '| Case 3: Mathematical reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| Question: A point on the edge of a fan blade that is rotating in a plane
    10 centimeters from the center of the fan. What is the distance traveled, in centimeters,
    by this point after 30 seconds when the fan runs at the rate of 300 revolutions
    per minutes? # Answer option: [A)$750\pi$] |'
  prefs: []
  type: TYPE_TB
- en: '| True Answer: D |'
  prefs: []
  type: TYPE_TB
- en: '| CoT Response: The fan makes 300 revolutions in 60 seconds. So it makes 300/60
    = 5 revolutions in 1 second. So it makes 5*30 = 150 revolutions in 30 seconds.
    The point on the edge of the fan blade travels 10 centimeters in one revolution.
    So it travels 10*150 = 1500 centimeters in 30 seconds. So the answer is (b). [WRONG]
    |'
  prefs: []
  type: TYPE_TB
- en: '| CoT+HSP Response: |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: The distance traveled by a point on the edge of a rotating object is
    calculated by multiplying the circumference of the circle it moves along by the
    number of rotations. |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: The fan makes 300 revolutions in 60 seconds. In 30 seconds, it
    makes 300/2 = 150 revolutions. The circumference of the circle is $2\pi r=2\pi(10)=20\pi$.
    So the answer is (d). [CORRECT] |'
  prefs: []
  type: TYPE_TB
- en: '| Case 4: Mathematical reasoning |'
  prefs: []
  type: TYPE_TB
- en: '| Question: James wants to hang crepe-paper streamers from his backyard fence
    for his birthday party. His backyard fence is a rectangle that measures 20 feet
    on the long side and 15 feet on the short side. How many feet of crepe paper does
    James need to buy? |'
  prefs: []
  type: TYPE_TB
- en: '| True Answer: 70 |'
  prefs: []
  type: TYPE_TB
- en: '| CoT Response: The fence is 20 feet long and 15 feet wide. The total length
    of the fence is 20 + 15 = 35 feet. He needs exactly the same amount of crepe paper
    as the length of the fence. So he needs to buy 35 feet of crepe paper. The answer
    is 35\. [WRONG] |'
  prefs: []
  type: TYPE_TB
- en: '| CoT+HSP Response: |'
  prefs: []
  type: TYPE_TB
- en: '| Hint: To find out how much crepe paper James needs to buy, calculate the
    perimeter of the fence. The perimeter is the total distance around the fence.
    To find the perimeter, add the lengths of all four sides of the fence together.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Solution: The long side of the fence is 20 feet. The short side is 15 feet.
    So the perimeter is 20 + 15 + 20 + 15 = 70 feet. The answer is 70\. [CORRECT]
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11: Case studies of solving mathematical reasoning and commonsense reasoning
    problems with CoT+HSP and CoT prompting on the Mixtral-7*8B model. Blue text indicates
    the stem, pink text indicates the effective hint, cyan text indicates the judgment
    of whether the answer is correct, [CORRECT] denotes correct, and [WRONG] denotes
    incorrect.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Reference Baseline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this paper, we reimplemented the results of four models, namely Llama-7B,
    Llama-13B, Llama-70B, and Mixtral-7*8B, under SD, LtM, PS, and CoT promptings,
    to compare with our HSP-enhanced promptings’ performance. Are our reimplemented
    results within a reasonable range? To answer this question, we compared our reimplemented
    results with results from some recently works across six datasets: GSM8K, AQUA,
    ASDiv, Date, MultiArith, and StrategyQA. The results are shown in Fig. [6](#A4.F6
    "Figure 6 ‣ Appendix D Reference Baseline ‣ Hint-before-Solving Prompting: Guiding
    LLMs to Effectively Utilize Encoded Knowledge").'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a considerable amount of existing work on CoT prompting, while results
    for SD, LtM, and PS prompting are limit. The baseline work we present in the Fig. [6](#A4.F6
    "Figure 6 ‣ Appendix D Reference Baseline ‣ Hint-before-Solving Prompting: Guiding
    LLMs to Effectively Utilize Encoded Knowledge") comes from five studies that cover
    a broad range of baseline methods. We can observe that across these six datasets,
    except for Llama-7B, which often lacks a closely matched model size for a baseline,
    the results for Llama-13B, Llama-70B, and Mixtral-7*8B are comparable to some
    existing open-source or closed-source models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7bf3fd09f243ed0f7c92a35b3cbff81f.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) GSM8K
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/aca5feebc467b6eb15c313b16640d7ed.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) ASDiv
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f4c913c446c65679099237a53a867083.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) MultiArith
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4233cd8f8d74bd40519f89878f8cf12b.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) AQUA
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9bd964efe3d4bd6138c58817570aaf47.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) StrategyQA
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/13840cc908900b98caec2c66c36b650f.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) Date
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: A comparison of the results from existing work with the results reimplemented
    in this work for Llama2-7B, Llama2-13B, Llama2-70B, and Mixtral-7*8B across six
    datasets. The existing results come from five works: [1] Wang et al. ([2023a](#bib.bib32)),
    [2] Lyu et al. ([2023](#bib.bib21)), [3] Luo et al. ([2023a](#bib.bib19)), [4] Azerbayev
    et al. ([2023](#bib.bib1)), and [5] Wei et al. ([2022](#bib.bib34)).'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Results of Self-consistency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Tab. [12](#A5.T12 "Table 12 ‣ Appendix E Results of Self-consistency ‣ Hint-before-Solving
    Prompting: Guiding LLMs to Effectively Utilize Encoded Knowledge") shows the results
    of self-consistency.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | SC | Hint | MATH | Commonsense | Avg | Relative Improvement |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GSM8K | ASDiv | MultiArith | AQUA | SQA | Date |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7B | 1 | 0 | 19.7 | 53.6 | 63.4 | 24.4 | 66.3 | 40.1 | 44.6 | ![[Uncaptioned
    image]](img/5f32e0ce62bc6f2293b2124639b9243b.png) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 19.9 | 55.8 | 63.8 | 24.4 | 67.5 | 43.2 | 45.8 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Impv | 0.2 | 2.2 | 0.4 | 0.0 | 1.2 | 3.1 | 1.2 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0 | 23.6 | 54.6 | 68.0 | 23.6 | 67.9 | 40.1 | 46.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 | 26.5 | 57.1 | 73.0 | 26.4 | 69.2 | 42.1 | 49.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Impv | 2.9 | 2.5 | 5.0 | 2.8 | 1.3 | 2.0 | 2.8 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 0 | 24.7 | 55.5 | 68.5 | 26.0 | 67.9 | 40.1 | 47.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 1 | 29.2 | 57.3 | 77.7 | 26.0 | 70.7 | 43.5 | 50.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | Impv | 4.5 | 1.8 | 9.2 | 0.0 | 2.8 | 3.4 | 3.6 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 0 | 25.5 | 55.2 | 67.6 | 25.6 | 68.6 | 39.6 | 47.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 1 | 29.5 | 57.5 | 78.9 | 26.4 | 70.2 | 41.5 | 50.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | Impv | 4.0 | 2.3 | 11.3 | 0.8 | 1.6 | 1.9 | 3.6 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 0 | 25.4 | 55.1 | 68.1 | 26.4 | 68.3 | 40.4 | 47.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 1 | 30.3 | 59.0 | 79.5 | 25.6 | 70.2 | 44.3 | 51.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | Impv | 4.9 | 3.9 | 11.4 | -0.8 | 1.9 | 3.9 | 4.2 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13B | 1 | 0 | 34.5 | 60.5 | 83.2 | 25.6 | 68.0 | 52.4 | 54.0 | ![[Uncaptioned
    image]](img/03abc738bf99bc387bfebb4ed7cbe8b2.png) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 36.5 | 61.2 | 87.1 | 25.6 | 72.1 | 53.5 | 56.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Impv | 2.0 | 0.7 | 3.9 | 0.0 | 4.1 | 1.1 | 2.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0 | 40.7 | 61.5 | 87.8 | 25.6 | 69.1 | 57.4 | 57.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 | 41.1 | 62.7 | 89.4 | 28.7 | 72.6 | 57.9 | 58.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Impv | 0.4 | 1.2 | 1.6 | 3.1 | 3.5 | 0.5 | 1.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 0 | 42.3 | 62.5 | 89.4 | 28.0 | 69.0 | 57.7 | 58.2 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 1 | 46.9 | 64.7 | 91.3 | 28.7 | 72.8 | 59.1 | 60.6 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | Impv | 4.6 | 2.2 | 1.9 | 0.7 | 3.8 | 1.4 | 2.4 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 0 | 41.5 | 62.6 | 90.1 | 26.4 | 69.6 | 57.9 | 58.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 1 | 48.2 | 64.9 | 92.8 | 28.0 | 73.1 | 60.2 | 61.2 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | Impv | 6.7 | 2.3 | 2.7 | 1.6 | 3.5 | 2.3 | 3.2 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 0 | 47.9 | 62.9 | 90.1 | 27.6 | 70.2 | 58.8 | 59.6 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 1 | 52.5 | 66.8 | 93.0 | 29.5 | 73.0 | 61.6 | 62.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | Impv | 4.6 | 3.9 | 2.9 | 1.9 | 2.8 | 2.8 | 3.2 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-70B | 1 | 0 | 46.1 | 72.5 | 93.8 | 35.8 | 74.6 | 71.6 | 65.7 | ![[Uncaptioned
    image]](img/f0d841ec8f4456643d770cda5dec861f.png) |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 50.3 | 74.4 | 94.6 | 37.0 | 77.0 | 73.0 | 67.7 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Impv | 4.2 | 1.9 | 0.8 | 1.2 | 2.4 | 1.4 | 2.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0 | 59.5 | 75.0 | 95.3 | 39.8 | 78.2 | 73.3 | 70.2 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 1 | 60.5 | 75.9 | 96.1 | 41.3 | 78.3 | 82.7 | 72.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Impv | 1.0 | 0.9 | 0.8 | 1.5 | 0.1 | 9.4 | 2.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 0 | 60.1 | 76.3 | 96.1 | 42.1 | 78.4 | 73.3 | 71.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 1 | 67.0 | 77.9 | 97.8 | 44.5 | 79.2 | 74.9 | 73.6 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | Impv | 6.9 | 1.6 | 1.7 | 2.4 | 0.8 | 1.6 | 2.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 0 | 60.6 | 77.1 | 96.3 | 45.3 | 78.5 | 72.7 | 71.8 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | 1 | 67.4 | 78.4 | 98.0 | 47.2 | 80.1 | 84.1 | 75.9 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | Impv | 6.8 | 1.3 | 1.7 | 1.9 | 1.6 | 11.4 | 4.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 0 | 67.0 | 77.6 | 96.3 | 46.1 | 79.4 | 73.5 | 73.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 1 | 67.6 | 78.8 | 98.2 | 47.6 | 79.5 | 83.3 | 75.8 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | Impv | 0.6 | 1.2 | 1.9 | 1.5 | 0.1 | 9.8 | 2.5 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 12: The results of self-consistency on the six datasets. Values in green
    denote the relative performance improvement with hints versus without hints under
    the same setting. The blue bold values represent the best performance with hints,
    while the pink bold values indicate the best performance without hints. The figure
    on the right shows the average relative improvement across six datasets.'
  prefs: []
  type: TYPE_NORMAL
