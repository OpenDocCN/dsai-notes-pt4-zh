- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:43:10'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt
    Enhancement'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.20701](https://ar5iv.labs.arxiv.org/html/2405.20701)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pengwei Zhan^♢^♣, Zhen Xu^♢, Qian Tan^♢, Jie Song^♢^♣, Ru Xie^♢^♣
  prefs: []
  type: TYPE_NORMAL
- en: ^♢Institute of Information Engineering, Chinese Academy of Sciences, Beijing,
    China
  prefs: []
  type: TYPE_NORMAL
- en: ^♣School of Cyber Security, University of Chinese Academy of Sciences, Beijing,
    China
  prefs: []
  type: TYPE_NORMAL
- en: '{zhanpengwei,xuzhen,tanqian,songjie,xieru}@iie.ac.cn  Corresponding Author.'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Large language models (LLMs) demonstrate exceptional instruct-following ability
    to complete various downstream tasks. Although this impressive ability makes LLMs
    flexible task solvers, their performance in solving tasks also heavily relies
    on instructions. In this paper, we reveal that LLMs are over-sensitive to lexical
    variations in task instructions, even when the variations are imperceptible to
    humans. By providing models with neighborhood instructions, which are closely
    situated in the latent representation space and differ by only one semantically
    similar word, the performance on downstream tasks can be vastly different. Following
    this property, we propose a black-box Combinatorial Optimization framework for
    Prompt Lexical Enhancement (COPLE). COPLE performs iterative lexical optimization
    according to the feedback from a batch of proxy tasks, using a search strategy
    related to word influence. Experiments show that even widely-used human-crafted
    prompts for current benchmarks suffer from the lexical sensitivity of models,
    and COPLE recovers the declined model ability in both instruct-following and solving
    downstream tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt
    Enhancement'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pengwei Zhan^♢^♣, Zhen Xu^♢, Qian Tan^♢^†^†thanks:  Corresponding Author.,
    Jie Song^♢^♣, Ru Xie^♢^♣ ^♢Institute of Information Engineering, Chinese Academy
    of Sciences, Beijing, China ^♣School of Cyber Security, University of Chinese
    Academy of Sciences, Beijing, China {zhanpengwei,xuzhen,tanqian,songjie,xieru}@iie.ac.cn'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Language models have achieved remarkable performance in recent years, particularly
    those referred to as large language models (LLMs), which contain scaled-up parameters
    and size Kaplan et al. ([2020](#bib.bib23)); Brown et al. ([2020](#bib.bib5));
    Hoffmann et al. ([2022](#bib.bib20)); OpenAI ([2022](#bib.bib33)); Touvron et al.
    ([2023](#bib.bib43)); Jiang et al. ([2023](#bib.bib22)). These models demonstrate
    an exceptional ability to follow human instructions and complete downstream tasks
    after instruction tuning Ouyang et al. ([2022](#bib.bib34)). In contrast to masked
    language models (MLMs) like BERT Devlin et al. ([2019](#bib.bib10)), LLMs do not
    require the addition and training of extra layers on top of the pre-trained base
    model to adapt to different downstream tasks. Instead, they complete a wide range
    of tasks in the same way of generating text, by following different task instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fad9844bb3262657ec10c40a5d9f828c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Prompt lexical enhancement from a combinatorial optimization perspective.
    Initially, we provide the prompt "*Please identify whether the sentences have
    the same meaning*" for Llama-2-7B-chat to complete the tasks from Quora Question
    Pairs2 (QQP), and combine the validation set of QQP with the prompt as a predefined
    task pool, with each example being an individual task. By iteratively substituting
    the most influential words in the prompt with semantically similar words picked
    from the potential search space, we find the optimal prompt "*Please identify
    since the sentences repeat the same theme*" that increases the accuracy from 35%
    to 57%. The details of operations can be found in §[3.3](#S3.SS3 "3.3 COPLE ‣
    3 Methodology ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the instruction-following ability of LLMs makes them flexible task
    solvers, their performance on solving tasks also significantly depends on the
    instructions (i.e., prompts), which are mainly designed by human intuitively and
    empirically Wei et al. ([2022](#bib.bib48)); Lu et al. ([2022](#bib.bib30)); Kojima
    et al. ([2022](#bib.bib24)); Zhou et al. ([2023a](#bib.bib61)). These manually
    designed prompts that incorporated with human knowledge effectively improve the
    model’s performance on specific tasks. However, following Gao et al. ([2018](#bib.bib14)),
    Garg and Ramakrishnan ([2020](#bib.bib16)) and Feng et al. ([2018](#bib.bib13)),
    even a minor lexical modification in the input that is imperceptible to humans
    can lead to vastly different model attention and outputs. Therefore, it is natural
    to wonder: *whether the prompts carefully constructed by humans maximize LLMs’
    performance on downstream tasks?* For example, in the context of a sentiment classification
    task, while humans may confidently assert that the prompt "*Please* *classify*
    *the sentiment of the given text*" outperforms "*Check the given text*", it is
    hard to say whether it would outperform a prompt like "*Please* *analyze* *the
    sentiment of the given text*".'
  prefs: []
  type: TYPE_NORMAL
- en: 'The unexpected sensitivity of language models to these imperceptible lexical
    perturbations suggests the possible existence of an alternate prompt, which is
    differs from the original prompt by only a few substituted words, yet yields superior
    performance on downstream tasks. This insight allows us to frame the process of
    discovering such an optimal prompt as a combinatorial optimization problem Blair
    ([1990](#bib.bib4)), which consists of two key components: the *search space*
    and the *search method*. The search space can be defined as the set of all potential
    substitutions for each word in the original prompt, while the search method specifies
    the strategy for exploring this space and identifying the optimal substitutions.
    Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Unveiling the Lexical Sensitivity
    of LLMs: Combinatorial Optimization for Prompt Enhancement") provides a more intuitive
    example of the process of finding the optimal prompt from a lexical combinatorial
    optimization perspective. We argue that even without the complex prompt engineering,
    minor lexical modifications to prompts yield substantial improvements to a model’s
    performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this paper, we reveal the notable sensitivity of LLMs to lexical variations
    in prompts, which potentially undermine the effectiveness of human-crafted prompts,
    from the view of combinatorial optimization. Based on our findings, we also propose
    a black-box Combinatorial Optimization framework for Prompt Lexical Enhancement
    (COPLE). We summarize our main contributions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We intuitively reveal the notable sensitivity of LLMs to the lexical choices
    in prompts, which suggests the existence of prompts that, while highly similar
    to the original, can lead to improved performance on downstream tasks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We propose COPLE, a black-box combinatorial optimization framework that enhances
    prompts on downstream tasks, which performs iteratively lexical optimization under
    the guidance of word influence.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We evaluate COPLE on popular datasets, models, and initial prompts. The results
    show that COPLE effectively maximizes the performance of prompts in downstream
    tasks with only lexical modifications, without accessing model parameters or involving
    complex prompt engineering with human participation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sensitivity to Imperceptible Changes.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The outstanding performance of language models seems to be built upon their
    excellent understanding of text Devlin et al. ([2019](#bib.bib10)); Dong et al.
    ([2019](#bib.bib12)); Radford et al. ([2018a](#bib.bib37), [b](#bib.bib38)); Brown
    et al. ([2020](#bib.bib5)). However, previous works reveal that even imperceptible
    input perturbations, which do not affect human comprehension, can lead to significant
    changes in the model’s output Goodfellow et al. ([2015](#bib.bib18)); Papernot
    et al. ([2016](#bib.bib35)); Zhan et al. ([2022a](#bib.bib54), [2023a](#bib.bib55));
    Carlini and Wagner ([2017](#bib.bib6)). This property has been widely exploited
    to create adversarial examples, where small modifications to the embedding or
    input text can cause the model to generate incorrect answers Gao et al. ([2018](#bib.bib14));
    Zhan et al. ([2022b](#bib.bib58), [2024](#bib.bib57)); Li et al. ([2019](#bib.bib27),
    [2020](#bib.bib28)); Zhan et al. ([2023b](#bib.bib56)); Zang et al. ([2020](#bib.bib53)).
    Therefore, we believe even humans experienced in designing prompts may overlook
    the performance discrepancies caused by such imperceptible changes.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Tuning and Optimizing.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similarly, recent efforts to optimize prompts for LLMs find that not only the
    content Kojima et al. ([2022](#bib.bib24)); Yang et al. ([2023](#bib.bib52)) but
    also the format Zhou et al. ([2023a](#bib.bib61)); Lu et al. ([2022](#bib.bib30));
    Wei et al. ([2023](#bib.bib49)); Madaan and Yazdanbakhsh ([2022](#bib.bib31));
    Prasad et al. ([2023](#bib.bib36)) of the prompt, such as the order of examples
    and phrases, significantly influence the model performance. Consequently, this
    sensitivity of language models to minor changes makes the optimal prompt found
    by the community increasingly complex. For example, Xu et al. ([2023](#bib.bib51))
    transforms a prompt of length 6 into one exceeding 900 tokens. However, we argue
    that also due to this sensitivity, complex variations of the prompt should not
    be the first operation in prompt optimization, as the performance could be inadvertently
    constrained by the specific words employed in the prompt. This proposition distinguishes
    our work from previous studies on prompt optimization: given a prompt that has
    proven initially effective, we focus on the lexical influence of the prompt on
    model performance, attempting to *recover* the potential performance drop caused
    by lexical choices, rather than *creating* a prompt that yields optimal results
    from scratch Shin et al. ([2020](#bib.bib41)); Zhou et al. ([2023b](#bib.bib62));
    Zhang et al. ([2022](#bib.bib59)); Yang et al. ([2023](#bib.bib52)); Prasad et al.
    ([2023](#bib.bib36)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Prompt Enhancement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose we are given a data distribution $\mathcal{D}$ is the verbalizer that
    limits the responses of the model to a set of label words. We can then formulate
    the performance of the model on the task set as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbb{E}_{(\bm{X},\bm{Y})\sim\mathcal{D}}[\mathcal{L}(f_{\bm{\theta}}(\bm{P}_{\mathcal{Z}}(\bm{X})),\bm{Y})]$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathcal{L}$ in the discrete token space is challenging due to the non-differentiable
    nature of text and the large search space. Therefore, it is more suitable to frame
    the process of optimizing the prompt as a combinatorial optimization problem,
    where we aim to find the optimal combination of tokens from a predefined search
    space that consists of candidate tokens.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this paper, to be more specific, we focus on investigating the influence
    of minor lexical changes on the *task description* part of the prompt. Let $\bm{D}=(d_{1},d_{2},\dots,d_{n})$.
    The optimal alternative task description that recovers the potential performance
    drop caused by wording can thus be formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\bm{D}^{*}$ |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle\text{s.t. }\quad d_{i}^{*}\in\mathcal{C}_{i}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle\text{and }\ \ \ \forall i\in\{1,\ldots,n\},\ \ \Delta
    d_{i}<\delta$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\Delta d_{i}$ is expected to minimize the expected loss on downstream
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bm{D}^{*}=\underset{\bm{D}}{\operatorname{arg\,min}}\quad\underset{\mathclap{\begin{subarray}{c}(\bm{X},\bm{Y})\sim\mathcal{D}\end{subarray}}}{\mathbb{E}\quad}[\mathcal{L}(f_{\bm{\theta}}(\bm{P}_{\mathcal{Z}}(\bm{X})),\bm{Y})]$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: Therefore, the optimal prompt for task $\mathcal{Z}$.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Impact of Minor Lexical Changes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The analysis presented in the previous section relies on a crucial premise:
    *imperceptible lexical changes in prompts can significantly affect the model performance
    on downstream tasks*. Before further explaining our approach, we first try to
    show the validity of this assumption.'
  prefs: []
  type: TYPE_NORMAL
- en: Given an initially proven effective prompt, a model, and a predefined task pool,
    we attempt to demonstrate how prompts within the neighborhood of the original
    prompt influence the model’s performance on the task pool. In this context, we
    broadly define a prompt’s neighborhood as prompts that differ from the original
    by only *one word* while maintaining a similar meaning. For instance, we consider
    "*Does the sentence make sense?*" to be within the neighborhood of "*Does this
    sentence make sense?*". To obtain these qualifying prompts, we employ a MLM. First,
    we iteratively replace each word in the task description with a [MASK] token.
    We then expect the MLM, by understanding the context, to provide the most probable
    fill-in words at each position based on the entire task description. After replacing
    the original words with the fill-in words at each position, we obtain a series
    of prompts within the neighborhood of the original prompt. We then evaluate the
    performance of each resulting prompt on the task pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following these definitions and operations, we employ the validation sets of
    CoLA Warstadt et al. ([2019](#bib.bib47)) and MMLU-STEM Hendrycks et al. ([2021](#bib.bib19))
    subtasks, respectively, as predefined task pools. We use Llama-2-7B-chat Touvron
    et al. ([2023](#bib.bib43)) and Mistral-7B-Instruct-v0.1 Jiang et al. ([2023](#bib.bib22))
    as target models and use RoBERTa Liu et al. ([2019](#bib.bib29)) for obtaining
    neighborhood prompts. The initial prompts are picked from *lm-evaluation-harness* Gao
    et al. ([2023](#bib.bib15)), and we generate ten most probable fill-in words for
    each position in task description. We then obtain their sentence representations
    in the target model and project them into a two-dimensional space using t-SNE van der
    Maaten and Hinton ([2008](#bib.bib44)). Figure [2](#S3.F2 "Figure 2 ‣ 3.2 Impact
    of Minor Lexical Changes ‣ 3 Methodology ‣ Unveiling the Lexical Sensitivity of
    LLMs: Combinatorial Optimization for Prompt Enhancement") shows the performance
    of neighborhood prompts on downstream tasks with the distribution of their sentence
    representations. We can then reach several conclusions on the impact of minor
    lexical changes in prompts on downstream performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e0ac4e0fe3eea2f35d4262da5da922ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The visualization of model performance on CoLA and MMLU-STEM validation
    set with neighborhood prompts. The task description of the original prompt picked
    for CoLA is "*Does this sentence make sense?*", and for MMLU-STEM is "*The following
    are multiple choice questions (with answers) about {task}*", where *{task}* is
    a placeholder to replace with detailed subset type, e.g., "abstract algebra".
    The point ⚫ in lighter color indicates better performance, and the square $\blacksquare$ in
    the color bar indicating the original performance. The words in the upper prompts
    indicate the changed words, and words indicate the substitutions.'
  prefs: []
  type: TYPE_NORMAL
- en: '*1.Semantically similar prompts have vastly different performances on downstream
    tasks, even if they differ by only one word.* For example, when using neighborhood
    prompts on MMLU-STEM and Llama-2-7B-chat (Figure [2](#S3.F2 "Figure 2 ‣ 3.2 Impact
    of Minor Lexical Changes ‣ 3 Methodology ‣ Unveiling the Lexical Sensitivity of
    LLMs: Combinatorial Optimization for Prompt Enhancement")(c)), their performance
    differences can reach 7%. Specifically, changing "*The following are multiple
    choice questions (with answers) about {task}.*" ($\blacksquare$) to "*The following
    lists multiple choice questions (with answers) about {task}.*" (⚫) reduces the
    accuracy from the original 28.04% to 23.92%, while changing it to "*The following
    are some choice questions (with answers) about {task}.*" (⚫) increases the accuracy
    to 30.86%. Intuitively, such minor lexical variations should have a minimal impact
    on semantics, and human performance would likely remain consistent when completing
    downstream tasks guided by these three prompts Adam Drewnowski ([1978](#bib.bib1));
    McCusker et al. ([1981](#bib.bib32)); van Orden ([1987](#bib.bib45)); Rayner et al.
    ([2006](#bib.bib40)). However, models exhibit a high degree of sensitivity to
    these changes.'
  prefs: []
  type: TYPE_NORMAL
- en: '*2.In the latent representation space, prompts that are in close proximity
    may have vastly different performance on downstream tasks.* In most cases, the
    performance of neighborhood prompts on downstream tasks does not demonstrate a
    clear correlation with the distribution of their sentence representations. Even
    when the representations of prompts are clustered together, they can still have
    substantial performance discrepancies. For example, in the representation space
    of Llama-2-7B-chat, the best-performing prompt (51.2%, ⚫) on CoLA (Figure [2](#S3.F2
    "Figure 2 ‣ 3.2 Impact of Minor Lexical Changes ‣ 3 Methodology ‣ Unveiling the
    Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")(a))
    is situated in very close proximity to the prompt with nearly the worst performance
    (32.4%, ⚫). From the perspective of sentence representations, this observation
    indicates that even for semantically highly similar prompts, their performance
    may be vastly different, and it is difficult to infer their performance from one
    another directly.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 COPLE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'According to our findings, even for semantically similar prompts with only
    one word difference, their performance on downstream tasks may be very different,
    and we cannot infer the performance of one prompt from another seemingly similar
    prompt. Therefore, we propose COPLE, trying to recover the degraded ability of
    models caused by lexical sensitivity. The key idea behind COPLE is to guide the
    lexical optimization of the initial prompt by the model performance on a batch
    of reference tasks i.i.d. to the downstream tasks, and iteratively improve the
    prompt based on the feedback from these references to converge towards an optimal
    prompt that maximizes performance across the task distribution. Specifically,
    COPLE consists of the following four parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Proxy Reference Tasks.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To find the optimal $\bm{D}^{*}$. For example, when targeting the validation
    set of a dataset as downstream tasks, we construct the reference tasks by sampling
    from the training set. These reference tasks serve as a proxy for evaluating the
    prompt on the task distribution, which also accelerates COPLE, as evaluating on
    a small batch of examples is not as expensive as evaluating on the full validation
    set. Therefore, the optimal task description that COPLE tries to find can be transformed
    from ([3](#S3.E3 "In 3.1 Prompt Enhancement ‣ 3 Methodology ‣ Unveiling the Lexical
    Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")) to:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\bm{D}^{*}$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\underset{\bm{D}}{\operatorname{arg\,min}}\quad\underset{\mathclap{\begin{subarray}{c}(\bm{X},\bm{Y})\sim\mathcal{Z}_{\textit{ref}}\end{subarray}}}{\mathbb{E}\quad}[\mathcal{L}(f_{\bm{\theta}}(\bm{P}_{\mathcal{Z}_{\textit{ref}}}(\bm{X})),\bm{Y})]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{P}_{\mathcal{Z}_{\textit{ref}}}$.
  prefs: []
  type: TYPE_NORMAL
- en: Search by Word Influence.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'With the proxy reference tasks, COPLE then performs an iterative optimization
    process to find the optimal task description $\bm{D}^{*}$. As COPLE serves as
    a black-box method without accessing the gradient information of the model, we
    first define the influence of each word in the task description as the expected
    performance difference on proxy tasks when the word is deleted from the task description.
    Formally:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{I}(d_{i})=&#124;\mathcal{L}_{\textit{ref}}(\bm{D})-\mathcal{L}_{\textit{ref}}(\bm{D}_{\backslash
    i})&#124;$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $\bm{D}_{\backslash i}$ removed. For efficiency purposes, COPLE obtains
    the influence of each word only on the initial task description. Then, COPLE tries
    to iteratively find the optimal substitution for the most influential words in
    the descending order of their influence.
  prefs: []
  type: TYPE_NORMAL
- en: Lexical Search Space.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To construct the search space $\mathcal{C}_{i}$ for the masked position:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p(w&#124;\bm{D}_{\backslash i}^{(t)})=f_{\textit{MLM}}(d_{1},\ldots,\texttt{[MASK]},\ldots,d_{n})$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: where $w\in\mathcal{V}$ words with the highest probabilities and a empty token
    (delete) as the candidates.
  prefs: []
  type: TYPE_NORMAL
- en: Iterative Optimization.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At each iteration $t$ on the small proxy reference tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{\textit{ref}}(\bm{D}^{(t)})=\underset{\mathclap{\begin{subarray}{c}(\bm{X},\bm{Y})\sim\mathcal{Z}_{\textit{ref}}\end{subarray}}}{\mathbb{E}\quad}[\mathcal{L}(f_{\bm{\theta}}(\bm{P}_{\mathcal{Z}_{\textit{ref}}}^{(t)}(\bm{X})),\bm{Y})]$
    |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\bm{D}^{(t)}=(d_{1},\ldots,c,\ldots,d_{n})$ that minimizes the expected
    loss on the proxy reference tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $c^{*}=\underset{c\in\mathcal{C}_{i}}{\operatorname{arg\,min}}\quad\mathcal{L}_{\textit{ref}}(\bm{D}^{(t)})$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: 'and updates the task description to $\smash{\bm{D}^{(t+1)}}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bm{D}^{(t+1)}=(d_{1},\ldots,c^{*},\ldots,d_{n})$ |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: otherwise, $\smash{\bm{D}^{(t+1)}}$ for the downstream tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Experiment Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '|  | GLUE | MMLU |'
  prefs: []
  type: TYPE_TB
- en: '|  | SST2 | CoLA | MNLI | QNLI | RTE | MRPC | QQP | STEM | Humanities | Soc.Sci
    | Other |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat |'
  prefs: []
  type: TYPE_TB
- en: '| Original | $90.71$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 92.43[0.70] | 65.72[1.29] | 52.42[1.33] | 69.38[2.10] |
    68.59[4.08] | 68.17[0.53] | 57.11[1.80] | 31.46[0.54] | 27.90[1.77] | 37.09[0.79]
    | 46.20[0.40] |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral-7B-Instruct-v0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Original | $87.27$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 91.21[1.48] | 78.24[1.58] | 65.37[0.89] | 79.34[0.35] |
    71.60[0.55] | 71.08[0.98] | 75.93[0.15] | 35.83[0.54] | 37.45[0.51] | 53.02[0.17]
    | 52.96[0.28] |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT (gpt-3.5-turbo-0125) |'
  prefs: []
  type: TYPE_TB
- en: '| Original | $94.38$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 94.80[0.17] | 82.91[0.16] | $\backslash$ | 36.45[0.76]
    | 43.44[0.39] | 58.46[0.59] | 57.61[0.14] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Performance comparison (Accuracy) of models on GLUE and MMLU benchmarks
    using the human-crafted prompts (*Original*) with and without applying COPLE.
    The bold values indicate the better results, while the standard deviations are
    provided in smaller font. For MNLI, we report the average results on the *matched*
    and *mismatched* subsets. Some results for gpt-3.5-turbo-0125 are denoted as "$\backslash$",
    indicating that, due to the huge validation set and cost and efficiency considerations,
    corresponding experiments are not conducted.'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset and Model.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We use GLUE Wang et al. ([2019](#bib.bib46)) and MMLU Hendrycks et al. ([2021](#bib.bib19))
    for evaluation. For GLUE, we report the results on SST2 Socher et al. ([2013](#bib.bib42)),
    CoLA Warstadt et al. ([2019](#bib.bib47)), MNLI Williams et al. ([2018](#bib.bib50)),
    QNLI Rajpurkar et al. ([2016](#bib.bib39)), RTE Giampiccolo et al. ([2007](#bib.bib17)),
    MRPC Dolan and Brockett ([2005](#bib.bib11)), and QQP Cer et al. ([2017](#bib.bib8)).
    For MMLU, we separately report the results on the subset of STEM, Humanities,
    Social Sciences, and Other. We use the Llama-2-7B-chat Touvron et al. ([2023](#bib.bib43)),
    Mistral-7B-Instruct-v0.1 Jiang et al. ([2023](#bib.bib22)), and ChatGPT (gpt-3.5-turbo-0125) OpenAI
    ([2022](#bib.bib33)) as the target model. Please see Appendix [A.1](#A1.SS1 "A.1
    Details on Dataset ‣ Appendix A Additional Experimental Details ‣ Unveiling the
    Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")
    for more details on datasets and models.'
  prefs: []
  type: TYPE_NORMAL
- en: Baseline.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To show the effectiveness of COPLE and empirically demonstrate the conclusions
    in §[3.2](#S3.SS2 "3.2 Impact of Minor Lexical Changes ‣ 3 Methodology ‣ Unveiling
    the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"),
    we evaluate COPLE in the following scenarios: (i) *Original*: using human-crafted
    prompts from *HELM* Lee et al. ([2023](#bib.bib25)) and *lm-evaluation-harness* Gao
    et al. ([2023](#bib.bib15)). (ii) *In-context Learning*, following Brown et al.
    ([2020](#bib.bib5)), randomly concatenating 1 and 3 examples from the training
    set with *Original* manual prompts (as the $\bm{E}^{\prime}$), denoted as the
    *1-shot* and *3-shot* settings, respectively. (iii) *Emotion Prompt*: combining
    two different self-monitoring style emotional stimuli, used in Li et al. ([2023](#bib.bib26))
    with *Original* manual prompts, denoted as *EP02* and *EP03*, respectively. (iv)
    *Chain-of-thought*: combining zero-shot CoT trigger Kojima et al. ([2022](#bib.bib24))
    with *Original* manual prompts, denoted as *Zero-shot-CoT*. Please see Appendix
    [A.3](#A1.SS3 "A.3 Details on Baseline Prompts ‣ Appendix A Additional Experimental
    Details ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement") for the detailed prompts used in evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: Implementation Details.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To construct the proxy reference tasks $\mathcal{Z}_{\textit{ref}}$, we sample
    100 tasks from training set. For the search space, we use RoBERTa Liu et al. ([2019](#bib.bib29))
    as the MLM in ([6](#S3.E6 "In Lexical Search Space. ‣ 3.3 COPLE ‣ 3 Methodology
    ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt
    Enhancement")), selecting the top-30 highest probability substitutions for each
    iteration. Following ([5](#S3.E5 "In Search by Word Influence. ‣ 3.3 COPLE ‣ 3
    Methodology ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement")), we take the 70% most influential words in a task description
    to perform optimization. We use HELM-style evaluation, with more details available
    in Appendix [A.2](#A1.SS2 "A.2 Details on Evaluation ‣ Appendix A Additional Experimental
    Details ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement"). All reported average results and standard deviations
    are obtained from 3 runs with different seeds.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Main Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Popular Prompts Suffer From Lexical Sensitivity.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Table [1](#S4.T1 "Table 1 ‣ 4.1 Experiment Setup ‣ 4 Experiment ‣ Unveiling
    the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")
    shows the model performance on different tasks using *Original* human-crafted
    prompts and related prompts optimized by COPLE. The results demonstrate that even
    widely used human-crafted prompts fail to maximize model performance on downstream
    tasks, due to lexical sensitivity and specific words in prompts. Specifically,
    for Llama-2-7B-chat, the average accuracy across all datasets increased from 44.15%
    to 56.04% (11.89%$\uparrow$ MMLU) when using prompts optimized by COPLE.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | GLUE | MMLU |'
  prefs: []
  type: TYPE_TB
- en: '|  | SST2 | CoLA | MNLI | QNLI | RTE | MRPC | QQP | STEM | Humanities | Soc.Sci
    | Other |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat |'
  prefs: []
  type: TYPE_TB
- en: '| *In-Context Learning Prompts* |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | $57.68$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 88.13[3.16] | 69.13[0.29] | 38.46[5.36] | 52.61[0.62] |
    55.23[0.51] | 68.23[0.12] | 45.93[17.25] | 28.97[0.31] | 24.15[0.27] | 30.12[0.63]
    | 23.38[0.23] |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | $51.61$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 70.07[1.62] | 68.36[0.38] | 31.17[0.19] | 55.78[0.22] |
    57.76[0.26] | 68.59[0.28] | 57.61[1.22] | 30.22[0.88] | 26.38[0.11] | 29.82[0.21]
    | 25.45[0.33] |'
  prefs: []
  type: TYPE_TB
- en: '| *Emotion Prompts* |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | $85.32$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 92.26[0.57] | 67.98[0.54] | 50.15[3.93] | 64.59[1.85] |
    57.16[4.59] | 68.42[0.34] | 30.55[0.60] | 31.78[0.44] | 28.09[2.59] | 35.91[1.68]
    | 40.14[0.20] |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | $91.51$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 92.78[0.65] | 68.41[1.02] | 52.23[0.03] | 67.40[3.60] |
    62.09[3.06] | 68.63[0.35] | 42.34[6.23] | 33.02[1.32] | 27.12[0.14] | 36.65[2.31]
    | 43.80[0.20] |'
  prefs: []
  type: TYPE_TB
- en: '| *Chain-of-thought Prompts* |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | $68.23$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 84.29[3.92] | 67.45[1.02] | 50.51[1.03] | 69.64[0.92] |
    59.81[0.83] | 66.42[1.04] | 23.49[0.88] | 27.73[0.54] | 32.72[0.68] | 34.42[1.26]
    | 31.27[1.59] |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral-7B-Instruct-v0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| *In-Context Learning Prompts* |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | $81.08$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 91.80[0.41] | 72.42[0.77] | 60.72[1.46] | 71.94[0.18] |
    65.16[2.81] | 65.07[0.52] | 64.96[0.16] | 31.15[0.44] | 31.98[0.73] | 44.31[0.95]
    | 46.90[0.28] |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | $91.28$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 93.43[0.07] | 72.77[0.27] | 56.35[0.68] | 75.62[0.58] |
    68.77[5.87] | 67.65[0.35] | 75.42[0.70] | 35.31[2.12] | 39.67[0.14] | 49.11[1.05]
    | 51.97[0.60] |'
  prefs: []
  type: TYPE_TB
- en: '| *Emotion Prompts* |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | $64.56$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 89.11[1.78] | 75.36[0.41] | 64.36[0.82] | 72.57[1.54] |
    72.56[2.04] | 70.10[0.69] | 72.43[0.98] | 37.07[0.44] | 37.64[0.82] | 52.08[0.30]
    | 51.97[1.00] |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | $76.61$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 91.44[0.33] | 76.32[0.14] | 67.24[0.36] | 76.37[0.91] |
    72.38[1.28] | 74.39[0.17] | 75.10[0.90] | 36.76[0.88] | 37.45[0.27] | 52.67[0.21]
    | 52.02[0.16] |'
  prefs: []
  type: TYPE_TB
- en: '| *Chain-of-thought Prompts* |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | $86.01$ |'
  prefs: []
  type: TYPE_TB
- en: '|      *w/* COPLE | 90.90[0.26] | 76.27[1.02] | 67.41[0.68] | 79.45[0.45] |
    71.48[0.63] | 74.14[0.52] | 76.80[3.13] | 36.34[0.18] | 36.87[0.33] | 52.08[0.21]
    | 52.54[0.20] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Performance comparison (Accuracy) of models on GLUE and MMLU using
    different initial prompts with and without applying COPLE. The bold and smaller
    values denote better results and standard deviations.'
  prefs: []
  type: TYPE_NORMAL
- en: COPLE Recovers the Ability on Both Instruct-Following and Solving Downstream
    Tasks.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Table [2](#S4.T2 "Table 2 ‣ Popular Prompts Suffer From Lexical Sensitivity.
    ‣ 4.2 Main Results ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity of LLMs:
    Combinatorial Optimization for Prompt Enhancement") shows the model performance
    on various tasks using different prompts. Recall that the HELM-style evaluation
    used in our experiments may yield performance worse than random guessing, suggesting
    that models fail to complete the task as instructed by the provided prompt. Following
    this, we find that further modifications to the *Original* prompts, such as adding
    few-shot demo examples, may not always improve the performance. Such modifications
    may lead to the generation of incorrect or entirely irrelevant responses, such
    as repeating demo examples or generating non-existent new examples. Therefore,
    it can be deduced that the decline in model performance on downstream tasks may
    be attributed to a decreased ability of (i) problem-solving, as when the model
    gives wrong results, and (ii) instruct-following, as when the model gives irrelevant
    results. For example, for Llama-2-7B-chat on QQP, the *3-shot* accuracy decreases
    from 27.58% to 23.03% (4.55%$\downarrow$) compared to *Original*. However, without
    complex prompt engineering, minor lexical optimization performed by COPLE is enough
    to recover the declined ability, as the accuracy increases from 23.03% to 57.61%
    after applying COPLE, which also outperforms the original prompt optimized by
    COPLE (Table [1](#S4.T1 "Table 1 ‣ 4.1 Experiment Setup ‣ 4 Experiment ‣ Unveiling
    the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement"),
    57.11%). Please see Appendix [B.1](#A2.SS1 "B.1 Details on the Optimized Prompt
    Crafted by COPLE ‣ Appendix B Additional Experimental Results ‣ Unveiling the
    Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")
    for the detailed optimized prompts.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Analysis and Ablation Study
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we conduct further analysis and ablation studies on COPLE.
    When not specified, the results are obtained on Llama-2-7B-chat.
  prefs: []
  type: TYPE_NORMAL
- en: Difference Between Prompts.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '|  |  |  | Llama-2-7B-chat | Mistral-7B-Instruct-v0.1 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | PPL.ori | U.Sim | BERTScore | PPL | U.Sim | BERTScore | PPL |'
  prefs: []
  type: TYPE_TB
- en: '| GLUE | SST2 | $46$ |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | $67$ |'
  prefs: []
  type: TYPE_TB
- en: '| MNLI | $635$ |'
  prefs: []
  type: TYPE_TB
- en: '| QNLI | $206$ |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | $635$ |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | $58$ |'
  prefs: []
  type: TYPE_TB
- en: '| QQP | $185$ |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU | STEM | 276 | $0.76$ |'
  prefs: []
  type: TYPE_TB
- en: '| Humanities | $0.79$ |'
  prefs: []
  type: TYPE_TB
- en: '| Soc.Sci | $0.80$ |'
  prefs: []
  type: TYPE_TB
- en: '| Other | $0.78$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | Avg. | $267$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Difference of semantic similarity and perplexity between original
    prompts and optimized prompts. *U.Sim* denotes the similarity obtained through
    USE.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To measure the difference between original prompts and optimized prompts, we
    utilize Universal Sentence Encoder (USE) Cer et al. ([2018](#bib.bib7)) and BERTScore Zhang
    et al. ([2020](#bib.bib60)) to obtain semantic similarity. We also obtain their
    perplexity (PPL) Jelinek et al. ([1977](#bib.bib21)) with GPT-2 Radford et al.
    ([2018b](#bib.bib38)). Table [3](#S4.T3 "Table 3 ‣ Difference Between Prompts.
    ‣ 4.3 Analysis and Ablation Study ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity
    of LLMs: Combinatorial Optimization for Prompt Enhancement") illustrates the differences
    between prompts. The USE similarity and BERTScore between the original and optimized
    prompts are consistently high across all tasks, indicating that the semantics
    of the prompts are well-preserved after optimization, which also confirms our
    conclusions in §[3.2](#S3.SS2 "3.2 Impact of Minor Lexical Changes ‣ 3 Methodology
    ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt
    Enhancement"). However, the perplexity of the optimized prompts increases significantly
    compared to the original, indicating that using challenging words for the language
    model in prompts, rather than common words picked by humans, may help to improve
    the model performance on solving downstream tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: $\#$.Word Change in Prompt.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Figure [3](#S4.F3 "Figure 3 ‣ #.Word Change in Prompt. ‣ 4.3 Analysis and Ablation
    Study ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial
    Optimization for Prompt Enhancement") shows the impact of the number of words
    changed in prompt. Even if only changing the one word with the highest influence,
    the model performance significantly improves (CoLA: 33.27% to 46.50%${}_{\pm\text{1.23\%}}$.Word
    Change* increases, COPLE tends to achieve higher accuracy, while a moderate value
    is enough to achieve nearly the optimal result.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b01faaae2494f64f117391537a314336.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Impact of the number of words changed in prompt on downstream performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7e1b24c12f2661e240de96f8a3f99a48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Impact of the number of sampled examples in proxy reference tasks
    on downstream performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8f29c5c873ffe9add8e191560be311cf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Impact of the number of candidate words in search space on downstream
    performance.'
  prefs: []
  type: TYPE_NORMAL
- en: $\#$).
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Figure [4](#S4.F4 "Figure 4 ‣ #.Word Change in Prompt. ‣ 4.3 Analysis and Ablation
    Study ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial
    Optimization for Prompt Enhancement") shows the impact of the size of proxy tasks.
    When proxy tasks contain a small number of 20 examples, COPLE still achieves notable
    improvements (CoLA: 33.27% to 62.96%${}_{\pm\text{1.78\%}}$). However, a larger
    size of sampled data helps find prompts with higher accuracy and lower standard
    deviations.'
  prefs: []
  type: TYPE_NORMAL
- en: $\#$).
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Figure [5](#S4.F5 "Figure 5 ‣ #.Word Change in Prompt. ‣ 4.3 Analysis and Ablation
    Study ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial
    Optimization for Prompt Enhancement") shows the impact of the number of candidate
    words in search space. A small $k$ is more suitable. However, using larger search
    space for each word is more likely to find prompts with better performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Word Influence.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Table [4](#S4.T4 "Table 4 ‣ Word Influence. ‣ 4.3 Analysis and Ablation Study
    ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement") shows the ablation results of the search strategy related
    to word influence in COPLE. When replacing the search strategy with the random
    method, the average performance optimized by COPLE on MMLU decreases from 35.66%
    to 34.17%, and COPLE is less stable as the standard deviation gets larger.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | STEM | Humanities | Social Sciences | Other |'
  prefs: []
  type: TYPE_TB
- en: '| Word Influence | $31.46$[0.40] |'
  prefs: []
  type: TYPE_TB
- en: '| Random | $30.32$[1.14] |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Ablation results on the search method. Random denotes searching on
    a random order of words.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/70f046cdc1397f2097478076270ff055.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Performance difference when COPLE is performed on proxy reference
    tasks and on validation set.'
  prefs: []
  type: TYPE_NORMAL
- en: How far is COPLE from the optimal results?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Figure [6](#S4.F6 "Figure 6 ‣ Word Influence. ‣ 4.3 Analysis and Ablation Study
    ‣ 4 Experiment ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement") shows the performance gap between the potential best
    prompts found by COPLE directly on the validation set ([3](#S3.E3 "In 3.1 Prompt
    Enhancement ‣ 3 Methodology ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial
    Optimization for Prompt Enhancement")) and on proxy tasks ([4](#S3.E4 "In Proxy
    Reference Tasks. ‣ 3.3 COPLE ‣ 3 Methodology ‣ Unveiling the Lexical Sensitivity
    of LLMs: Combinatorial Optimization for Prompt Enhancement")). The results show
    that the proxy tasks provide a reasonable approximation of the target task distribution,
    and the performance of COPLE is close to optimal.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, we demonstrate the notable lexical sensitivity of LLMs to prompts,
    which potentially degrades their performance on downstream tasks. We show that
    even semantically similar prompts located in the neighborhood of the latent representation
    space may yield very different results. To recover the performance drop caused
    by the sensitivity, we propose COPLE, a black-box combinatorial optimization framework
    that iteratively improves lexical choices in prompts. Experiments illustrate the
    effectiveness of COPLE in recovering both the model’s ability of instruct-following
    and solving downstream tasks. We believe that carefully checking the word usage
    is essential before performing complex prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the effectiveness of COPLE, we want to discuss some limitations of this
    work. Firstly, our experimental scope is primarily restricted to models around
    the 7-billion-parameter scale, as our computational resources are limited. Secondly,
    while we focus on optimizing the lexical choices within the task description component
    of the prompts, it is possible that lexical sensitivity affects the entirety of
    a prompt. However, expanding our optimization to include the full prompt significantly
    increases the size of search space, making the experiment computationally infeasible
    with our current resources. Thirdly, although we believe that lexical optimization
    should be a fundamental step prior to more complex prompt engineering methods,
    our research does not explore the combination of our proposed COPLE framework
    with other prompt engineering strategies that potentially yield further improvements
    in model performance. Despite these limitations, our study provides insights into
    the influence of lexical variation on language model prompts, from both the perspective
    of downstream performance and latent sentence representation. The findings highlight
    that even subtle lexical changes, when systematically optimized, can significantly
    enhance the performance of language models on downstream tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was supported by the Youth Innovation Promotion Association CAS (No.2023166),
    and the Informatization Plan of Chinese Academy of Sciences (Grant No. CAS-WX2021SF-0508).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Adam Drewnowski (1978) Alice F. Healy Adam Drewnowski. 1978. [Detection errors
    on the word the: Evidence for the acquisition of reading levels](https://doi.org/10.3758/bf03197472).
    *Memory & Cognition*, 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bar-Haim et al. (2006) Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo
    Giampiccolo, Bernardo Magnini, and Idan Szpektor. 2006. The second pascal recognising
    textual entailment challenge. In *Proceedings of the second PASCAL challenges
    workshop on recognising textual entailment*, volume 6\. Venice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bentivogli et al. (2009) Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo
    Giampiccolo. 2009. The fifth pascal recognizing textual entailment challenge.
    In *Tac*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blair (1990) Charles E. Blair. 1990. [Integer and combinatorial optimization
    (george l. nemhauser and laurence a. wolsey)](https://doi.org/10.1137/1032061).
    *SIAM Rev.*, 32(2).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. [Language models are few-shot learners](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html).
    In *Advances in Neural Information Processing Systems 33: Annual Conference on
    Neural Information Processing Systems, NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carlini and Wagner (2017) Nicholas Carlini and David Wagner. 2017. Towards evaluating
    the robustness of neural networks. In *2017 IEEE Symposium on Security and Privacy
    (SP)*. Ieee.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cer et al. (2018) Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco,
    Rhomni St John, Noah Constant, Mario Guajardo-Céspedes, Steve Yuan, Chris Tar,
    et al. 2018. [Universal sentence encoder](https://arxiv.org/abs/1803.11175). *arXiv
    preprint*, abs/1803.11175.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cer et al. (2017) Daniel M. Cer, Mona T. Diab, Eneko Agirre, I~nigo Lopez-Gazpio,
    and Lucia Specia. 2017. [Semeval-2017 task 1: Semantic textual similarity - multilingual
    and cross-lingual focused evaluation](http://arxiv.org/abs/1708.00055). *CoRR*,
    abs/1708.00055.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dagan et al. (2005) Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The
    pascal recognising textual entailment challenge. In *Machine Learning Challenges
    Workshop*. Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. [BERT: Pre-training of deep bidirectional transformers for language
    understanding](https://doi.org/10.18653/v1/N19-1423). In *Proceedings of the Conference
    of the North American Chapter of the Association for Computational Linguistics:
    Human Language Technologies*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dolan and Brockett (2005) William B. Dolan and Chris Brockett. 2005. [Automatically
    constructing a corpus of sentential paraphrases](https://aclanthology.org/I05-5002/).
    In *Proceedings of the Third International Workshop on Paraphrasing, IWP@IJCNLP*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. (2019) Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu,
    Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. [Unified language
    model pre-training for natural language understanding and generation](https://proceedings.neurips.cc/paper/2019/hash/c20bb2d9a50d5ac1f713f8b34d9aac5a-Abstract.html).
    In *Advances in Neural Information Processing Systems 32: Annual Conference on
    Neural Information Processing Systems, NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. (2018) Shi Feng, Eric Wallace, Alvin Grissom II, Mohit Iyyer, Pedro
    Rodriguez, and Jordan Boyd-Graber. 2018. [Pathologies of neural models make interpretations
    difficult](https://doi.org/10.18653/v1/D18-1407). In *Proceedings of the Conference
    on Empirical Methods in Natural Language Processing*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2018) Ji Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. 2018.
    [Black-box generation of adversarial text sequences to evade deep learning classifiers](https://doi.org/10.1109/spw.2018.00016).
    In *2018 IEEE Security and Privacy Workshops, SP Workshops*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2023) Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid
    Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noac’h,
    Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria
    Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish
    Thite, Ben Wang, Kevin Wang, and Andy Zou. 2023. [A framework for few-shot language
    model evaluation](https://doi.org/10.5281/zenodo.10256836).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Garg and Ramakrishnan (2020) Siddhant Garg and Goutham Ramakrishnan. 2020.
    [BAE: BERT-based adversarial examples for text classification](https://doi.org/10.18653/v1/2020.emnlp-main.498).
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing
    (EMNLP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Giampiccolo et al. (2007) Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and
    Bill Dolan. 2007. [The third PASCAL recognizing textual entailment challenge](https://aclanthology.org/W07-1401/).
    In *Proceedings of the ACL-PASCAL@ACL 2007 Workshop on Textual Entailment and
    Paraphrasing, Prague, Czech Republic*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2015) Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
    2015. [Explaining and harnessing adversarial examples](http://arxiv.org/abs/1412.6572).
    In *3rd International Conference on Learning Representations, ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. [Measuring massive multitask
    language understanding](https://openreview.net/forum?id=d7KBjmI3GmQ). In *9th
    International Conference on Learning Representations, ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hoffmann et al. (2022) Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena
    Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks,
    Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George
    van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan,
    Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. 2022. [Training compute-optimal
    large language models](https://doi.org/10.48550/arxiv.2203.15556). *CoRR*, abs/2203.15556.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jelinek et al. (1977) Fred Jelinek, Robert L Mercer, Lalit R Bahl, and James K
    Baker. 1977. Perplexity—a measure of the difficulty of speech recognition tasks.
    *The Journal of the Acoustical Society of America*, 62(S1).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2023) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. 2023. [Mistral 7b](https://doi.org/10.48550/arxiv.2310.06825).
    *CoRR*, abs/2310.06825.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kaplan et al. (2020) Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown,
    Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
    2020. [Scaling laws for neural language models](http://arxiv.org/abs/2001.08361).
    *CoRR*, abs/2001.08361.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](http://papers.nips.cc/paper_files/paper/2022/hash/8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 35: Annual Conference on
    Neural Information Processing Systems, NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2023) Tony Lee, Michihiro Yasunaga, Chenlin Meng, Yifan Mai, Joon Sung
    Park, Agrim Gupta, Yunzhi Zhang, Deepak Narayanan, Hannah Teufel, Marco Bellagente,
    Minguk Kang, Taesung Park, Jure Leskovec, Jun-Yan Zhu, Fei-Fei Li, Jiajun Wu,
    Stefano Ermon, and Percy Liang. 2023. [Holistic evaluation of text-to-image models](http://papers.nips.cc/paper_files/paper/2023/hash/dd83eada2c3c74db3c7fe1c087513756-Abstract-Datasets_and_Benchmarks.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems, NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023) Cheng Li, Jindong Wang, Kaijie Zhu, Yixuan Zhang, Wenxin Hou,
    Jianxun Lian, and Xing Xie. 2023. [Emotionprompt: Leveraging psychology for large
    language models enhancement via emotional stimulus](https://doi.org/10.48550/arxiv.2307.11760).
    *CoRR*, abs/2307.11760.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2019) Jinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting Wang.
    2019. [Textbugger: Generating adversarial text against real-world applications](https://www.ndss-symposium.org/ndss-paper/textbugger-generating-adversarial-text-against-real-world-applications/).
    In *26th Annual Network and Distributed System Security Symposium, NDSS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2020) Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng
    Qiu. 2020. [BERT-ATTACK: Adversarial attack against BERT using BERT](https://doi.org/10.18653/v1/2020.emnlp-main.500).
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing
    (EMNLP)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
    [Roberta: A robustly optimized BERT pretraining approach](http://arxiv.org/abs/1907.11692).
    *CoRR*, abs/1907.11692.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2022) Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and
    Pontus Stenetorp. 2022. [Fantastically ordered prompts and where to find them:
    Overcoming few-shot prompt order sensitivity](https://doi.org/10.18653/v1/2022.acl-long.556).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madaan and Yazdanbakhsh (2022) Aman Madaan and Amir Yazdanbakhsh. 2022. [Text
    and patterns: For effective chain of thought, it takes two to tango](https://doi.org/10.48550/arxiv.2209.07686).
    *CoRR*, abs/2209.07686.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'McCusker et al. (1981) Leo X McCusker, Philip B Gough, and Randolph G Bias.
    1981. Word recognition inside out and outside in. *Journal of Experimental Psychology:
    Human Perception and Performance*, 7(3).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2022) OpenAI. 2022. [Introducing chatgpt](https://openai.com/blog/chatgpt).
    In *OpenAI Blog*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L.
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
    Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. [Training
    language models to follow instructions with human feedback](http://papers.nips.cc/paper_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 35: Annual Conference on
    Neural Information Processing Systems, NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papernot et al. (2016) Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt
    Fredrikson, Z Berkay Celik, and Ananthram Swami. 2016. The limitations of deep
    learning in adversarial settings. In *2016 IEEE European Symposium on Security
    and Privacy (EuroS&P)*. IEEE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prasad et al. (2023) Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal.
    2023. [Grips: Gradient-free, edit-based instruction search for prompting large
    language models](https://doi.org/10.18653/v1/2023.eacl-main.277). In *Proceedings
    of the 17th Conference of the European Chapter of the Association for Computational
    Linguistics, EACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2018a) Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya
    Sutskever. 2018a. [Improving language under-standing by generative pre-training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf).
    In *OpenAI Blog*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2018b) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, and Ilya Sutskever. 2018b. [Language models are unsupervised multitask
    learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf).
    In *OpenAI Blog*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rajpurkar et al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
    Percy Liang. 2016. [SQuAD: 100, 000+ questions for machine comprehension of text](https://doi.org/10.18653/v1/d16-1264).
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing,
    EMNLP*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rayner et al. (2006) Keith Rayner, Sarah J. White, Rebecca L. Johnson, and
    Simon P. Liversedge. 2006. [Raeding wrods with jubmled lettres: There is a cost](https://doi.org/10.1111/j.1467-9280.2006.01684.x).
    *Psychological Science*, 17(3). Pmid: 16507057.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shin et al. (2020) Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace,
    and Sameer Singh. 2020. [Autoprompt: Eliciting knowledge from language models
    with automatically generated prompts](https://doi.org/10.18653/v1/2020.emnlp-main.346).
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing,
    EMNLP*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Socher et al. (2013) Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang,
    Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. [Recursive
    deep models for semantic compositionality over a sentiment treebank](https://aclanthology.org/D13-1170/).
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing,
    EMNLP*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. [Llama
    2: Open foundation and fine-tuned chat models](https://doi.org/10.48550/arxiv.2307.09288).
    *CoRR*, abs/2307.09288.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: van der Maaten and Hinton (2008) Laurens van der Maaten and Geoffrey Hinton.
    2008. [Visualizing data using t-SNE](http://jmlr.org/papers/v9/vandermaaten08a.html).
    *Journal of Machine Learning Research*, 9(86).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'van Orden (1987) Guy C. van Orden. 1987. [A ROWS is a ROSE: Spelling, sound,
    and reading](https://doi.org/10.3758/bf03197716). *Memory & Cognition*, 15(3).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R. Bowman. 2019. [GLUE: A multi-task benchmark and analysis
    platform for natural language understanding](https://openreview.net/forum?id=rJ4km2R5t7).
    In *7th International Conference on Learning Representations, ICLR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Warstadt et al. (2019) Alex Warstadt, Amanpreet Singh, and Samuel R. Bowman.
    2019. [Neural network acceptability judgments](https://doi.org/10.1162/tacl_a_00290).
    *Trans. Assoc. Comput. Linguistics*, 7.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. [Chain-of-thought
    prompting elicits reasoning in large language models](http://papers.nips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 35: Annual Conference on
    Neural Information Processing Systems 2022, NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2023) Jerry W. Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson,
    Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, and Tengyu Ma. 2023.
    [Larger language models do in-context learning differently](https://doi.org/10.48550/arxiv.2303.03846).
    *CoRR*, abs/2303.03846.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Williams et al. (2018) Adina Williams, Nikita Nangia, and Samuel R. Bowman.
    2018. [A broad-coverage challenge corpus for sentence understanding through inference](https://doi.org/10.18653/v1/n18-1101).
    In *Proceedings of the 2018 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies, NAACL-HLT*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023) Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong
    Zhang, and Zhendong Mao. 2023. [Expertprompting: Instructing large language models
    to be distinguished experts](https://doi.org/10.48550/arxiv.2305.14688). *CoRR*,
    abs/2305.14688.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2023) Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V.
    Le, Denny Zhou, and Xinyun Chen. 2023. [Large language models as optimizers](https://doi.org/10.48550/arxiv.2309.03409).
    *CoRR*, abs/2309.03409.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zang et al. (2020) Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang,
    Qun Liu, and Maosong Sun. 2020. [Word-level textual adversarial attacking as combinatorial
    optimization](https://doi.org/10.18653/v1/2020.acl-main.540). In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhan et al. (2022a) Pengwei Zhan, Yang Wu, Shaolei Zhou, Yunjian Zhang, and
    Liming Wang. 2022a. [Mitigating the inconsistency between word saliency and model
    confidence with pathological contrastive training](https://doi.org/10.18653/v1/2022.findings-acl.175).
    In *Findings of the Association for Computational Linguistics: ACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhan et al. (2023a) Pengwei Zhan, Jing Yang, Xiao Huang, Chunlei Jing, Jingying
    Li, and Liming Wang. 2023a. [Contrastive learning with adversarial examples for
    alleviating pathology of language model](https://doi.org/10.18653/v1/2023.acl-long.358).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhan et al. (2023b) Pengwei Zhan, Jing Yang, He Wang, Chao Zheng, Xiao Huang,
    and Liming Wang. 2023b. [Similarizing the influence of words with contrastive
    learning to defend word-level adversarial text attack](https://doi.org/10.18653/v1/2023.findings-acl.500).
    In *Findings of the Association for Computational Linguistics: ACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhan et al. (2024) Pengwei Zhan, Jing Yang, He Wang, Chao Zheng, and Liming
    Wang. 2024. [Rethinking word-level adversarial attack: The trade-off between efficiency,
    effectiveness, and imperceptibility](https://aclanthology.org/2024.lrec-main.1223).
    In *Proceedings of the Joint International Conference on Computational Linguistics,
    Language Resources and Evaluation (LREC-COLING)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhan et al. (2022b) Pengwei Zhan, Chao Zheng, Jing Yang, Yuxiang Wang, Liming
    Wang, Yang Wu, and Yunjian Zhang. 2022b. [PARSE: an efficient search method for
    black-box adversarial text attacks](https://aclanthology.org/2022.coling-1.423).
    In *Proceedings of the 29th International Conference on Computational Linguistics,
    COLING*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2022) Tianjun Zhang, Xuezhi Wang, Denny Zhou, Dale Schuurmans,
    and Joseph E. Gonzalez. 2022. [TEMPERA: test-time prompting via reinforcement
    learning](https://doi.org/10.48550/arxiv.2211.11890). *CoRR*, abs/2211.11890.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2020) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger,
    and Yoav Artzi. 2020. [BERTScore: Evaluating text generation with BERT](https://openreview.net/forum?id=SkeHuCVFDr).
    In *8th International Conference on Learning Representations, ICLR 2020*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2023a) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V. Le,
    and Ed H. Chi. 2023a. [Least-to-most prompting enables complex reasoning in large
    language models](https://openreview.net/pdf?id=WZH7099tgfM). In *The Eleventh
    International Conference on Learning Representations, ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2023b) Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster,
    Silviu Pitis, Harris Chan, and Jimmy Ba. 2023b. [Large language models are human-level
    prompt engineers](https://openreview.net/pdf?id=92gvk82DE-). In *The Eleventh
    International Conference on Learning Representations, ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Additional Experimental Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A.1 Details on Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The General Language Understanding Evaluation (GLUE) Wang et al. ([2019](#bib.bib46))
    benchmark is a collection of datasets for training, evaluating, and analyzing
    natural language understanding systems. The subset used in our experiment include:
    (1) The Stanford Sentiment Treebank (SST2) Socher et al. ([2013](#bib.bib42))
    consists of movie review sentences annotated for sentiment. (2) The Corpus of
    Linguistic Acceptability (CoLA) Warstadt et al. ([2019](#bib.bib47)) contains
    English acceptability judgments drawn from linguistic theory publications. (3)
    The Multi-Genre Natural Language Inference (MNLI) Williams et al. ([2018](#bib.bib50))
    corpus includes sentence pairs annotated with textual entailment information.
    (4) The Question-answering NLI (QNLI) Rajpurkar et al. ([2016](#bib.bib39)) is
    derived from SQuAD, converted to a binary sentence pair classification task. (5)
    The Recognizing Textual Entailment (RTE) datasets come from a series of textual
    entailment challenges Dagan et al. ([2005](#bib.bib9)); Bar-Haim et al. ([2006](#bib.bib2));
    Giampiccolo et al. ([2007](#bib.bib17)); Bentivogli et al. ([2009](#bib.bib3)).
    (6) The Microsoft Research Paraphrase Corpus (MRPC) Dolan and Brockett ([2005](#bib.bib11))
    contains sentence pairs annotated for semantic equivalence. (7) The Quora Question
    Pairs2 (QQP) Cer et al. ([2017](#bib.bib8)) includes question pairs from Quora
    annotated for semantic equivalence. The Massive Multitask Language Understanding
    (MMLU) dataset Hendrycks et al. ([2021](#bib.bib19)) contains multiple-choice
    questions that cover 57 tasks, which can be divided into four main subsets: STEM,
    Humanities, Social Sciences, and Other, with 14,042 test and 1,531 validation
    examples. In our experiment, for constructing the proxy reference tasks, we sample
    from the test set on MMLU. More information about the datasets is provided in
    Table [5](#A1.T5 "Table 5 ‣ A.1 Details on Dataset ‣ Appendix A Additional Experimental
    Details ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | $\#$.Category |'
  prefs: []
  type: TYPE_TB
- en: '| SST2 | $67\,349$ | Sentiment Analysis | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | $8551$ | Linguistic Acceptability | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| MNLI | $392\,702$ | Natural Language Inference | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| QNLI | $104\,743$ | Natural Language Inference | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | $2490$ | Natural Language Inference | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | $3668$ | Semantic Equivalence | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| QQP | $363\,849$ | Semantic Equivalence | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU | 14042 (Test) | $1531$ | Question Answering | 4 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Summary of datasets used in the experiments. For MNLI, 19,647 validation
    examples consists of 9,815 from the matched in-domain section and 9,832 from the
    mismatched cross-domain section. For MMLU, we report the size of test set rather
    than training set.'
  prefs: []
  type: TYPE_NORMAL
- en: A.2 Details on Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We follow the same evaluation style as HELM Lee et al. ([2023](#bib.bib25)),
    which expects the model to output the correct label word (for GLUE) or the letter
    of the correct option (for MMLU), rather than directly using the probability of
    the output token for judgement. For example, on SST2, for a sentence with positive
    sentiment, we expect the model output to be "*positive*". Similarly, on MMLU,
    the model is expected to output one of the letters "*A*", "*B*", "*C*", or "*D*"
    that matches the correct answer. Otherwise, we consider the model makes incorrect
    decisions. Note that this evaluation approach may result in model performance
    worse than that of random guessing. However, we believe that it provides a more
    accurate indication of the model’s ability on instruction following and on solving
    downstream tasks. For all datasets, we report the performance with Accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: A.3 Details on Baseline Prompts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the main text, we perform COPLE on various scenarios, including *Original*,
    *1-shot*, *3-shot*, *EP02*, *EP03*, and *Zero-shot-CoT*; here we report the detailed
    prompts of these scenarios. The initial prompts for GLUE are in Table [6](#A1.T6
    "Table 6 ‣ A.3 Details on Baseline Prompts ‣ Appendix A Additional Experimental
    Details ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization
    for Prompt Enhancement")-[12](#A1.T12 "Table 12 ‣ A.3 Details on Baseline Prompts
    ‣ Appendix A Additional Experimental Details ‣ Unveiling the Lexical Sensitivity
    of LLMs: Combinatorial Optimization for Prompt Enhancement"), and the initial
    prompts for MMLU are in Table [13](#A1.T13 "Table 13 ‣ A.3 Details on Baseline
    Prompts ‣ Appendix A Additional Experimental Details ‣ Unveiling the Lexical Sensitivity
    of LLMs: Combinatorial Optimization for Prompt Enhancement")-[14](#A1.T14 "Table
    14 ‣ A.3 Details on Baseline Prompts ‣ Appendix A Additional Experimental Details
    ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt
    Enhancement"). It should also be noted that for scenarios of *Emotion Prompts*,
    following Li et al. ([2023](#bib.bib26)), we insert the additional text at the
    end of the task description and verbalizer, but before the demo examples, and
    we do not consider the additional text to be a part of the task descriptions to
    perform optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| SST2 | Original | For the given sentence, label the sentiment of the sentence
    as positive or negative. Do not respond with anything other than the labels ‘positive’
    or ‘negative’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | For the given sentence, label the sentiment of the sentence as positive
    or negative. Do not respond with anything other than the labels ‘positive’ or
    ‘negative’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | For the given sentence, label the sentiment of the sentence as positive
    or negative. Do not respond with anything other than the labels ‘positive’ or
    ‘negative’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | For the given sentence, label the sentiment of the sentence as positive
    or negative. Do not respond with anything other than the labels ‘positive’ or
    ‘negative’. This is very important to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | For the given sentence, label the sentiment of the sentence as positive
    or negative. Do not respond with anything other than the labels ‘positive’ or
    ‘negative’. You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | For the given sentence, label the sentiment of the sentence
    as positive or negative. Let’s think step by step. Then, end the response with
    "Therefore, the answer is: ‘positive’ / ‘negative’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Detailed baseline prompts for SST2\. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | Original | Does this sentence make sense? Do not respond with anything
    other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | Does this sentence make sense? Do not respond with anything other
    than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | Does this sentence make sense? Do not respond with anything other
    than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | Does this sentence make sense? Do not respond with anything other
    than the labels ‘Yes’ or ‘No’. This is very important to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | Does this sentence make sense? Do not respond with anything other
    than the labels ‘Yes’ or ‘No’. You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | Does this sentence make sense? Let’s think step by step.
    Then, end the response with "Therefore, the answer is: ‘Yes’ / ‘No’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Detailed baseline prompts for CoLA. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| MNLI | Original | Please identify whether the premise entails the hypothesis.
    Do not respond with anything other than the labels ‘entailment’, ‘neutral’, or
    ‘contradiction’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘entailment’, ‘neutral’, or ‘contradiction’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘entailment’, ‘neutral’, or ‘contradiction’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘entailment’, ‘neutral’, or ‘contradiction’.
    This is very important to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘entailment’, ‘neutral’, or ‘contradiction’.
    You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | Please identify whether the premise entails the hypothesis.
    Let’s think step by step. Then, end the response with "Therefore, the answer is:
    ‘entailment’ / ‘neutral’ / ‘contradiction’. "'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: Detailed baseline prompts for MNLI. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| QNLI | Original | Please identify whether the sentence answers the question.
    Do not respond with anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | Please identify whether the sentence answers the question. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | Please identify whether the sentence answers the question. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | Please identify whether the sentence answers the question. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’. This is very important
    to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | Please identify whether the sentence answers the question. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’. You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | Please identify whether the sentence answers the question.
    Let’s think step by step. Then, end the response with "Therefore, the answer is:
    ‘Yes’ / ‘No’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9: Detailed baseline prompts for QNLI. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | Original | Please identify whether the premise entails the hypothesis.
    Do not respond with anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’. This is very important
    to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | Please identify whether the premise entails the hypothesis. Do not
    respond with anything other than the labels ‘Yes’ or ‘No’. You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | Please identify whether the premise entails the hypothesis.
    Let’s think step by step. Then, end the response with "Therefore, the answer is:
    ‘Yes’ / ‘No’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 10: Detailed baseline prompts for RTE. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | Original | Do both sentences mean the same thing? Do not respond with
    anything other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | Do both sentences mean the same thing? Do not respond with anything
    other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | Do both sentences mean the same thing? Do not respond with anything
    other than the labels ‘Yes’ or ‘No’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | Do both sentences mean the same thing? Do not respond with anything
    other than the labels ‘Yes’ or ‘No’. This is very important to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | Do both sentences mean the same thing? Do not respond with anything
    other than the labels ‘Yes’ or ‘No’. You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | Do both sentences mean the same thing? Let’s think step by
    step. Then, end the response with "Therefore, the answer is: ‘Yes’ / ‘No’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11: Detailed baseline prompts for MRPC. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| QQP | Original | Please identify whether the sentences have the same meaning.
    Do not respond with anything other than the labels ‘equal’ or ‘unequal’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | Please identify whether the sentences have the same meaning. Do
    not respond with anything other than the labels ‘equal’ or ‘unequal’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | Please identify whether the sentences have the same meaning. Do
    not respond with anything other than the labels ‘equal’ or ‘unequal’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_content_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP02 | Please identify whether the sentences have the same meaning. Do not
    respond with anything other than the labels ‘equal’ or ‘unequal’. This is very
    important to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | Please identify whether the sentences have the same meaning. Do not
    respond with anything other than the labels ‘equal’ or ‘unequal’. You’d better
    be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | Please identify whether the sentences have the same meaning.
    Let’s think step by step. Then, end the response with "Therefore, the answer is:
    ‘equal’ / ‘unequal’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {content}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12: Detailed baseline prompts for QQP. In the prompt, brown text indicates
    the task description, which is the target that COPLE performs on, green text indicates
    the verbalizer, and blue text indicates the demo examples for few-shot learning.
    “*{text}*” denotes the placeholder, which will be replaced with the text sampled
    from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU | Original | The following are multiple choice questions (with answers)
    about {task}. Do not respond with anything other than the answer labels ‘A’, ‘B’,
    ‘C’, or ‘D’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1-shot | The following are multiple choice questions (with answers) about
    {task}. Do not respond with anything other than the answer labels ‘A’, ‘B’, ‘C’,
    or ‘D’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {demo_option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {demo_option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {demo_option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {demo_option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| 3-shot | The following are multiple choice questions (with answers) about
    {task}. Do not respond with anything other than the answer labels ‘A’, ‘B’, ‘C’,
    or ‘D’.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_question_1}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {demo_option_A_1}
  prefs: []
  type: TYPE_NORMAL
- en: B. {demo_option_B_1}
  prefs: []
  type: TYPE_NORMAL
- en: C. {demo_option_C_1}
  prefs: []
  type: TYPE_NORMAL
- en: D. {demo_option_D_1}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_1}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_question_2}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {demo_option_A_2}
  prefs: []
  type: TYPE_NORMAL
- en: B. {demo_option_B_2}
  prefs: []
  type: TYPE_NORMAL
- en: C. {demo_option_C_2}
  prefs: []
  type: TYPE_NORMAL
- en: D. {demo_option_D_2}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_2}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {demo_question_3}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {demo_option_A_3}
  prefs: []
  type: TYPE_NORMAL
- en: B. {demo_option_B_3}
  prefs: []
  type: TYPE_NORMAL
- en: C. {demo_option_C_3}
  prefs: []
  type: TYPE_NORMAL
- en: D. {demo_option_D_3}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: {demo_answer_3}'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 13: Detailed baseline prompts of *Original* and *In-context Learning*
    setting for MMLU. In the prompt, brown text indicates the task description, which
    is the target that COPLE performs on, green text indicates the verbalizer, and
    blue text indicates the demo examples for few-shot learning. “*{text}*” denotes
    the placeholder, which will be replaced with the text sampled from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Prompt |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU | EP02 | The following are multiple choice questions (with answers)
    about {task}. Do not respond with anything other than the answer labels ‘A’, ‘B’,
    ‘C’, or ‘D’. This is very important to my career.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| EP03 | The following are multiple choice questions (with answers) about {task}.
    Do not respond with anything other than the answer labels ‘A’, ‘B’, ‘C’, or ‘D’.
    You’d better be sure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zero-shot CoT | The following are multiple choice questions (with answers)
    about {task}. Let’s think step by step. Then, end the response with "Therefore,
    the answer is: ‘A’ / ‘B’ / ‘C’ / ‘D’."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: {question}'
  prefs: []
  type: TYPE_NORMAL
- en: A. {option_A}
  prefs: []
  type: TYPE_NORMAL
- en: B. {option_B}
  prefs: []
  type: TYPE_NORMAL
- en: C. {option_C}
  prefs: []
  type: TYPE_NORMAL
- en: D. {option_D}
  prefs: []
  type: TYPE_NORMAL
- en: 'Answer: |'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 14: Detailed baseline prompts of *Emotion Prompt* and *Chain-of-thought*
    setting for MMLU. In the prompt, brown text indicates the task description, which
    is the target that COPLE performs on, green text indicates the verbalizer, and
    blue text indicates the demo examples for few-shot learning. “*{text}*” denotes
    the placeholder, which will be replaced with the text sampled from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Additional Experimental Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: B.1 Details on the Optimized Prompt Crafted by COPLE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [15](#A2.T15 "Table 15 ‣ B.1 Details on the Optimized Prompt Crafted
    by COPLE ‣ Appendix B Additional Experimental Results ‣ Unveiling the Lexical
    Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")-[16](#A2.T16
    "Table 16 ‣ B.1 Details on the Optimized Prompt Crafted by COPLE ‣ Appendix B
    Additional Experimental Results ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial
    Optimization for Prompt Enhancement") shows the optimal task descriptions optimized
    by COPLE on Llama2-7B-chat for various scenarios. Table [17](#A2.T17 "Table 17
    ‣ B.1 Details on the Optimized Prompt Crafted by COPLE ‣ Appendix B Additional
    Experimental Results ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial
    Optimization for Prompt Enhancement")-[18](#A2.T18 "Table 18 ‣ B.1 Details on
    the Optimized Prompt Crafted by COPLE ‣ Appendix B Additional Experimental Results
    ‣ Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt
    Enhancement") shows the optimal task descriptions optimized by COPLE on Mistral-7B-Instruct-v0.1
    for various scenarios. Table [19](#A2.T19 "Table 19 ‣ B.1 Details on the Optimized
    Prompt Crafted by COPLE ‣ Appendix B Additional Experimental Results ‣ Unveiling
    the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement")
    shows the optimal task description optimized by COPLE on ChatGPT (gpt-3.5-turbo-0125)
    and the *Original* scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Task Description (Before) | Task Description (After)
    |'
  prefs: []
  type: TYPE_TB
- en: '| SST2 | Original | For the given sentence, label the sentiment of the sentence
    as positive or negative. | Before the given sentence, label the sentiment of the
    user as positively or negative. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | For the closing sentence, label this rest of next sentence as positive
    or positive. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | For another given sentence, label the comment preceding no sentence
    as angry or negative. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Regarding ANY OTHER NEWS, label the sentiment of the sentence positive
    or negative. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | If the given sentence, label the quality of the statement as positively
    or negative. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | For the introductory discussion, label the sentiment of the
    reviewer for positive or opposite. |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | Original | Does this sentence make sense? | Did THIS sentence make?
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Does every word make Sense? |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Does my sentence any sense? |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Has this now make sense? |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Made THIS sentence make it? |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Should THAT sentence made sense? |'
  prefs: []
  type: TYPE_TB
- en: '| MNLI | Original | Please identify whether the premise entails the hypothesis.
    | Please indicate whether the content entails valid conclusion. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please identify all the elements entails the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Please identify whether the premise is the facts. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | must identify whether the premise opposes the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Results evaluate Whether your data entails the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Note whether the answer satisfies the evidence. |'
  prefs: []
  type: TYPE_TB
- en: '| QNLI | Original | Please identify whether the sentence answers the question.
    | Please specify whether the above answers the question. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please comment whether sentence answers the question. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | We consider whether the sentence answers the question. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Please assess whether the above answered the error. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please correct whether this answered the question. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please assess whether the sentence answers the queries. |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | Original | Please identify whether the premise entails the hypothesis.
    | First estimate whether premise entails each hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please confirm whether current knowledge advances the hypothesis.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Now identify whether the correction entails the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | First identify whether the premise confirms each hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please state whether the conclusion justifies the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please identify whether certain premise entails correct hypothesis.
    |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | Original | Do both sentences mean the same thing? | Do both sentences
    mean a same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Do both languages mean the same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Do both letters mean the same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Do parallel sentences repeat the same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Are both sentences mean the same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | did both sentences convey the same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| QQP | Original | Please identify whether the sentences have the same meaning.
    | Please identify since the posts have the same text. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | will identify Where unrelated sentences have nearly same significance.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Please identify whether the sentences have the same ending. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Please determine are the have the same meaning. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please identify both your works have the same subject. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please note whether adjacent sentences display the identical
    meaning. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 15: Detailed optimized task descriptions on Llama2-7B-chat and GLUE.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Task Description (Before) | Task Description (After)
    |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-STEM | Original | The following are multiple choice questions (with
    answers) about {task}. | THE exercises contain easy choice questions (with answers)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | The following generates multiple discussion questions (using arrows)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Se following are multiple popular questions (with answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The examples list multiple choice questions (with labels) without
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The are infinite choice questions (by data) about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | The following are multiple choice problems (default answers)
    involving {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Humanities | Original | The model identifies multiple popular questions
    (which answers) about {task} |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | In following are all survey questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | The following are multiple questions (with answers) named {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Graph following illustrates third choice answer (simple answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The candidates are multiple choice questions (with) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | The follows are most popular questions (mostly answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Social Sciences | Original | The following displays multiple choice
    questions (with answers) about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | The following multiple popular questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | The following are multiple different questions (with answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The following summarizes the choice questions (complete ones) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The entries present multiple choice questions (with answers) involving
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | following are some choice questions (complete answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Other | Original | The candidates posted multiple choice questions (with
    answers) about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | The following are choice questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | The following are multiple standard answers (with answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The Following are the choice questions (and answers) following {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The following implements multiple choice questions (No exceptions)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | The following contains your first questions (with explanation)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 16: Detailed optimized task descriptions on Llama2-7B-chat and MMLU.
    “*{task}*” denotes the placeholder, which will be replaced with the detailed subset
    type.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Task Description (Before) | Task Description (After)
    |'
  prefs: []
  type: TYPE_TB
- en: '| SST2 | Original | For the given sentence, label the sentiment of the sentence
    as positive or negative. | For the given sentence, label the sentiment of the
    sentence as positive or constructive. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | For the given sentence, keep positive sentiment of the sentence
    as positive not negative. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Before the given sentence, express components of the sentence as
    positive OR negatively. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | After the desired context, label every result of the process as happy
    or negative. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | For my given question, label the sentiment of the sentence as positive
    or optimistic. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | For the given expression, label the outcome of the sentence
    as positive or. |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | Original | Does this sentence make sense? | Does this sentence form
    follows? |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Does each word contain sense? |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Does each sentence make points? |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Do I sentence make sense? |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Does each sentence make sense? |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Has this sentence make sense? |'
  prefs: []
  type: TYPE_TB
- en: '| MNLI | Original | Please identify whether the premise entails the hypothesis.
    | Please assess how the result entails proposed hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please assess whether sufficient premise entails the claim. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Please identify between and premise the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Please show whether the answer entails the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please identify whether the result entails the hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please evaluate whether the hypothesis entails my observations.
    |'
  prefs: []
  type: TYPE_TB
- en: '| QNLI | Original | Please identify whether the sentence answers the question.
    | Please identify whether any sentence asked either question. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please repeat in the affirmative regarding the question. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | please identify unless our article answers further question. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | must identify whether the article answers the question. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please identify whether the sentence addressed previous question.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please identify whether her sentence supports the question.
    |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | Original | Please identify whether the premise entails the hypothesis.
    | Please find sure the premise matches any hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please assess whether the premise supports the premises. |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Please identify HOW either premise fits any other. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Please verify either possible facts entails the claims. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please verify when the claim matches the fact. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please identify that The premise entails the hypothesis.
    |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | Original | Do both sentences mean the same thing? | Do both sentences
    suggest the same picture? |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Do other sentences suggest a same theme? |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Do other sources suggest the Same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | both sentences mean the whole thing? |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Do both sentences explain the same thing? |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Do both sentences describe the whole thing? |'
  prefs: []
  type: TYPE_TB
- en: '| QQP | Original | Please identify whether the sentences have the same meaning.
    | Please identify whether following articles have the same keywords. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Please compare whether these sentences match the exact meaning.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Please identify whenever individual sentences have the equivalent
    content. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | Please tell whether two quotes have the identical message. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Please identify whether the arguments have the same context. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Please identify between the sentences have the same value.
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 17: Detailed optimized task descriptions on Mistral-7B-Instruct-v0.1
    and GLUE.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Scenario | Task Description (Before) | Task Description (After)
    |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-STEM | Original | The following are multiple choice questions (with
    answers) about {task}. | The following are multiple choice questions (their variants)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | the following two first choice questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Examples Here were multiple detailed questions (full comments) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The mes are multiple choice questions (with parentheses) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | Examples following are multiple example questions (complete answers)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Then following are binary logic questions (with tags) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Humanities | Original | The are three choice cases (with answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | The Following are multiple choice questions (with hints) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Then following are multiple choice questions (with answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The following are multiple obvious choices (easy fixes) using {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The Following are multiple choice messages (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | The Below are multiple hypothetical questions (with answers)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Social Sciences | Original | The following are choice questions (with
    answers) about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | The following are ten sample questions (with keywords) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | The following are two sample questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The Following are multiple choice questions (with solutions) containing
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The Following are one choice questions (with answers) about {task}
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | The followed five multiple choice Questions (with Answers)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Other | Original | The following are multiple choice questions (answers)
    and {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| 1-shot | Then follow are two choice questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 3-shot | Both following are multiple boolean questions (with answers) about
    {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| EP02 | The answers are Multiple choice questions (with answers) and {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| EP03 | The following are multiple nested questions (with answers) about {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot CoT | Ch following is multiple choice questions (with answers)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 18: Detailed optimized task descriptions on Mistral-7B-Instruct-v0.1
    and MMLU. “*{task}*” denotes the placeholder, which will be replaced with the
    detailed subset type.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Task Description (Before) | Task Description (After) |'
  prefs: []
  type: TYPE_TB
- en: '| SST2 | For the given sentence, label the sentiment of the sentence as positive
    or negative. | For the given article, label the sentiment above the sentence as
    positive or negative. |'
  prefs: []
  type: TYPE_TB
- en: '| CoLA | Does this sentence make sense? | this sentence make sense? |'
  prefs: []
  type: TYPE_TB
- en: '| RTE | Please identify whether the premise entails the hypothesis. | Please
    evidence the premise support current hypothesis. |'
  prefs: []
  type: TYPE_TB
- en: '| MRPC | Do both sentences mean the same thing? | Do both answers mean this
    correct thing? |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-STEM | The following are multiple choice questions (with answers) about
    {task}. | The following are infinite choice questions (NO answers) within {task}.
    |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Humanities | Items above are a choice (with answers) about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Social Sciences | The following answers multiple choice question (with
    answers) about {task}. |'
  prefs: []
  type: TYPE_TB
- en: '| MMLU-Other | The Following answers multiple choice questions (with answers)
    about {task}. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 19: Detailed optimized task descriptions on ChatGPT (gpt-3.5-turbo-0125)
    on the *Original* scenario. “*{task}*” denotes the placeholder, which will be
    replaced with the detailed subset type.'
  prefs: []
  type: TYPE_NORMAL
