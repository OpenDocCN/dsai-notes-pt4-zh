- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:48:16'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:48:16
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation
    and Soft-Prompting for Non-Specialist LLM Users
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在微调、检索增强生成和软提示中建立性能基线，以便非专业LLM用户使用
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.05903](https://ar5iv.labs.arxiv.org/html/2311.05903)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2311.05903](https://ar5iv.labs.arxiv.org/html/2311.05903)
- en: Jennifer Dodgson
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 詹妮弗·多奇森
- en: kipley.ai
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndLin Nanzheng
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \And林南正
- en: kipley.ai
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndJulian Peh
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \And朱利安·佩赫
- en: kipley.ai
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndAkira Rafhael Janson Pattirane
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \And秋田·拉斐尔·詹森·帕提拉内
- en: Universitas Kristen Duta Wacana
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 印度教会大学达塔瓦卡纳
- en: \AndAlfath Daryl Alhajir
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \And阿尔法特·达里尔·阿尔哈吉尔
- en: kipley.ai
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndEko Ridho Dinarto
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \And厄科·里霍·迪纳托
- en: kipley.ai
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndJoseph Lim
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \And约瑟夫·林
- en: kipley.ai
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: kipley.ai
- en: \AndSyed Danyal Ahmad
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \And赛义德·达尼亚尔·艾哈迈德
- en: TU Dortmund
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 多特蒙德工业大学
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Research into methods for improving the performance of large language models
    (LLMs) through fine-tuning, retrieval-augmented generation (RAG) and soft-prompting
    has tended to focus on the use of highly technical or high-cost techniques, making
    many of the newly discovered approaches comparatively inaccessible to non-technical
    users. In this paper we tested an unmodified version of GPT 3.5, a fine-tuned
    version, and the same unmodified model when given access to a vectorised RAG database,
    both in isolation and in combination with a basic, non-algorithmic soft prompt.
    In each case we tested the model’s ability to answer a set of 100 questions relating
    primarily to events that occurred after September 2021 (the point at which GPT
    3.5’s training data set ends). We found that if commercial platforms are used
    and default settings are applied with no iteration in order to establish a baseline
    set of outputs, a fine-tuned model outperforms GPT 3.5 Turbo, while the RAG approach
    out-performed both. The application of a soft prompt significantly improved the
    performance of each approach.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通过微调、检索增强生成（RAG）和软提示法来提高大型语言模型（LLMs）性能的方法的研究，往往集中在使用高度技术化或高成本的技术上，这使得许多新发现的方法相对难以被非技术用户所接触。在本文中，我们测试了未经修改的GPT
    3.5版本、一个经过微调的版本，以及在访问一个向量化RAG数据库的情况下相同的未经修改的模型，分别独立使用和与基本的非算法软提示相结合使用。每种情况下，我们都测试了模型回答主要涉及2021年9月之后发生的事件的100个问题的能力（这是GPT
    3.5的训练数据集结束的时间点）。我们发现，如果使用商业平台并应用默认设置而不进行迭代以建立基线输出集，则微调模型的表现优于GPT 3.5 Turbo，而RAG方法的表现则优于两者。应用软提示显著提高了每种方法的性能。
- en: '*K*eywords performance baseline  $\cdot$ large language model'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*K*eywords 性能基线  $\cdot$ 大型语言模型'
- en: 1 Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Extensive academic research has been conducted on methods for improving base
    large language models (LLMs) through fine-tuning and - more recently - via retrieval-augmented
    generation (RAG). The fine-tuning process begins with a set of base model weights
    determined via training on a large corpus of text data. This pre-trained model
    has already acquired a wide range of language patterns, syntax, and semantics,
    and the fine-tuning process involves repeating this process using a task-specific
    dataset with the aim of improving the model’s capacity in a particular area such
    as text classification, language translation, question-answering, or text generation.
    A task-specific objective function is defined, which quantifies how well the model
    is performing on the chosen task. This is typically a loss function that measures
    the difference between the model’s predictions and the ground truth in the training
    data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大量学术研究已针对通过微调和最近通过检索增强生成（RAG）来改进基础大型语言模型（LLMs）进行。微调过程始于通过在大量文本数据语料库上训练确定的一组基础模型权重。这个预训练的模型已经获得了广泛的语言模式、语法和语义，微调过程涉及使用任务特定的数据集重复这一过程，旨在提高模型在特定领域的能力，例如文本分类、语言翻译、问答或文本生成。定义了一个任务特定的目标函数，该函数量化了模型在所选任务上的表现。这通常是一个损失函数，用于测量模型预测与训练数据中的真实情况之间的差异。
- en: The pre-trained LLM is fine-tuned on the task-specific dataset using backpropagation
    and gradient descent. During fine-tuning, the model’s weights are updated to minimise
    the defined objective function. The model generalises from the provided examples
    and learns to make predictions specific to the task. RAG, by contrast, does not
    involve altering the model weights, but rather passing in information relevant
    to user prompts via a multi-stage information retrieval system. This usually involves
    an initial stage in which a user’s input prompt is used to search an external
    data source - whether via web search, semantic search of a vector database, text-to-SQL
    queries or other methods. This ranks and selects the most relevant documents or
    passages based on the provided query, which are in turn passed to the LLM, which
    is instructed to answer the user question by means of the passages retrieved.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练的LLM在任务特定数据集上通过反向传播和梯度下降进行微调。在微调过程中，模型的权重会被更新，以最小化定义的目标函数。模型从提供的示例中进行泛化，并学习做出特定于任务的预测。相比之下，RAG不涉及修改模型权重，而是通过多阶段的信息检索系统传递与用户提示相关的信息。这通常涉及一个初始阶段，在该阶段中，用户的输入提示被用来搜索外部数据源——无论是通过网络搜索、向量数据库的语义搜索、文本到SQL查询或其他方法。这一过程会根据提供的查询对最相关的文档或段落进行排序和选择，这些文档或段落随后被传递给LLM，LLM被指示通过检索到的段落来回答用户问题。
- en: 'The majority of the articles published on these topics tend to focus on cutting
    edge techniques for improving a given method. However, these techniques often
    require significant financial resources and/or technical expertise, and are thus
    out of reach for the majority of users. Indeed, an average corporate user wishing
    to create a custom model is faced with a proliferation of options, all assessed
    according to differing metrics and often with no useful baseline with which to
    compare the results. Our goal in this paper is to provide just such a baseline.
    We compare the the results given by GPT 3.5 Turbo in its unmodified form, with
    fine-tuned and RAG versions created using the default settings presented to users
    via two commercially available platforms assessed to be comparatively accessible
    both in terms of cost and the IT skills required for use: OpenAI’s own fine-tuning
    API, and the [kipley.ai](http://kipley.ai)’s RAG platform (dubbed “easyRAG”).
    At the same time, we tested the impact of soft-prompting on each approach with
    two sets of questions: one base set and one reinforced by soft meta-prompts.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数关于这些主题的文章倾向于关注改善给定方法的前沿技术。然而，这些技术通常需要显著的财务资源和/或技术专长，因此大多数用户无法接触到。事实上，普通企业用户希望创建一个自定义模型时面临选项的激增，这些选项根据不同的指标进行评估，并且通常没有有用的基准来比较结果。本文的目标是提供这样的基准。我们将GPT
    3.5 Turbo在未修改状态下的结果与使用默认设置创建的微调和RAG版本进行了比较，这些设置通过两个商业平台向用户提供，这两个平台在成本和所需的IT技能方面相对可及：OpenAI自家的微调API和[kipley.ai](http://kipley.ai)的RAG平台（称为“easyRAG”）。同时，我们用两个问题集测试了软提示对每种方法的影响：一个基础集和一个由软元提示增强的集。
- en: The goal in doing this was not to create the best possible chatbot, but rather
    to provide an assessment of the baseline performance of model-improvement technologies
    available to non-expert users. Thus we used default settings in each case and
    made no effort to further improve the performance of each model pipeline. While
    we are well aware that iterative processes can improve the fine-tuning, RAG and
    soft-prompting processes we applied, the average non-academic user will not necessarily
    have the skills or financial resources to do this, therefore we also refrained.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的目标不是创建最佳的聊天机器人，而是提供对非专家用户可以使用的模型改进技术的基准性能评估。因此，我们在每种情况下都使用了默认设置，并且没有进一步提升每个模型管道的性能。虽然我们清楚迭代过程可以改进我们所应用的微调、RAG和软提示过程，但普通非学术用户不一定具备进行这些改进的技能或财务资源，因此我们也没有这样做。
- en: 2 Existing Literature
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 现有文献
- en: 'For the purposes of establishing a baseline, we used what is currently the
    most widely used NLP service among lay-users: OpenAI’s GPT suite. Ray (2023) gives
    an overview of this technology [[1](#bib.bib1)]. The GPT models are a series of
    transformer-based LLMs trained on large text corpora (books, webpages, articles
    etc.) in an unsupervised manner, with further supervised fine-tuning. With each
    generation, its capabilities increased, becoming more and more realistic and indistinguishable
    from human writing. By 2022 the models were successfully passing medical, legal,
    and computing exams, as well as to perform financial analysis - the challenge
    we use in the present paper.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立基准，我们使用了当前最广泛使用的 NLP 服务之一：OpenAI 的 GPT 套件。Ray (2023) 概述了这一技术 [[1](#bib.bib1)]。GPT
    模型是一系列基于变换器的 LLM，经过无监督训练的大量文本语料库（书籍、网页、文章等），并进行进一步的有监督微调。随着每一代的推出，其能力不断提高，变得越来越逼真，与人类写作几乎难以区分。到
    2022 年，这些模型已成功通过医学、法律和计算考试，并进行金融分析——这是我们在本文中使用的挑战。
- en: Dowling and Lucey (2023) demonstrate that ChatGPT is capable of providing significant
    assistance in financial research [[2](#bib.bib2)]. The authors evaluated its capacity
    by asking it to produce literature reviews on cryptocurrency-related topics, first
    using the public data embedded in ChatGPT itself, second with by uploading cryptocurrency-related
    literature to align the LLM and third by human expert intervention on top of the
    second version. They found that the model performed well when it came to idea
    generation and data summaries, but its literature reviews and test frameworks
    were poor.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Dowling 和 Lucey (2023) 证明了 ChatGPT 在金融研究中能够提供显著帮助 [[2](#bib.bib2)]。作者通过让 ChatGPT
    针对加密货币相关话题生成文献综述来评估其能力，首先使用嵌入在 ChatGPT 中的公共数据，其次通过上传加密货币相关文献来对齐 LLM，第三步是在第二步的基础上进行人工专家干预。他们发现，模型在创意生成和数据总结方面表现良好，但其文献综述和测试框架表现较差。
- en: Li et al. (2023), meanwhile, conducted a broader study on the applications of
    GPT-3.5 and GPT-4.0 as general problem solvers in financial text analysis tasks,
    as compared to domain-specific LLMs [[3](#bib.bib3)]. The authors performed a
    quantitative analysis of the capacity of GPT 3.5 and GPT 4 to solve financial
    text analytical problems using eight benchmark datasets relating to five tasks.
    These results were compared to those produced by FinBert, FinQANet, BloombergGPT
    and others, with the authors finding that non-specialists LLMs such as GPT-4 were
    able to outperform even domain specific pretrained models on certain tasks, only
    falling behind when a deeper structural analysis of financial systems was needed.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，Li 等 (2023) 对 GPT-3.5 和 GPT-4.0 在金融文本分析任务中的应用进行了更广泛的研究，与领域特定 LLMs 相比 [[3](#bib.bib3)]。作者对
    GPT-3.5 和 GPT-4 解决金融文本分析问题的能力进行了定量分析，使用了与五项任务相关的八个基准数据集。这些结果与 FinBert、FinQANet、BloombergGPT
    等产生的结果进行了比较，作者发现，像 GPT-4 这样的非专业 LLM 在某些任务上甚至超越了领域特定的预训练模型，仅在需要对金融系统进行更深入的结构分析时表现稍逊。
- en: However, GPT-generated texts are not perfect - often the models generate inaccurate
    or imprecise text, or lack domain-specific knowledge. As described above, much
    research has gone into methods to minimise these flaws, whether via retrieval-augmented
    generation, fine-tuning, soft-prompting or other methods. For example, Sarmah
    et al. (2023) discuss how to reduce hallucination in information extracted Q&A
    sections of financial reports using LLMs [[4](#bib.bib4)]. For this purpose, they
    segmented and vectorised a variety of datasheets. They fed the segments and their
    associated metadata into multiple LLMs and then queried it regarding the information
    provided, using the metadata to select the most relevant sections. This approach
    significantly reduced hallucinations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GPT 生成的文本并不完美——模型常常生成不准确或不精确的文本，或缺乏领域特定的知识。如上所述，许多研究致力于通过检索增强生成、微调、软提示或其他方法来最小化这些缺陷。例如，Sarmah
    等 (2023) 讨论了如何减少使用 LLMs 从金融报告的问答部分提取信息时的幻觉 [[4](#bib.bib4)]。为此，他们对各种数据表进行了分段和向量化。他们将这些分段及其相关元数据输入多个
    LLM，然后查询提供的信息，使用元数据选择最相关的部分。这种方法显著减少了幻觉。
- en: 'Other teams, such as Wang et al. (2023) describe attempts to improve GPT’s
    ability to accurately handle financial information via a fine-tuning process [[5](#bib.bib5)].
    Similar efforts have also been made in other domains requiring a high degree of
    precision in the outputs: Wu et al. (2023), for example, used data from 4.8 million
    biomedical academic papers and 30 thousand medical textbooks to fine-tune a domain-specific
    model capable of outperforming ChatGPT on medical topics, despite having only
    13 billion parameters [[6](#bib.bib6)].'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其他团队，如 Wang 等人（2023），描述了通过微调过程来提高 GPT 准确处理金融信息的能力的尝试 [[5](#bib.bib5)]。类似的努力也在其他需要高精度输出的领域中进行：例如，Wu
    等人（2023）使用了480万篇生物医学学术论文和3万本医学教科书的数据来微调一个特定领域的模型，这个模型在医学主题上能够超越 ChatGPT，尽管其参数仅有130亿个
    [[6](#bib.bib6)]。
- en: However, despite significant progress in techniques for improving pre-trained
    models’ performance, significant lacunae remain. A notable challenge for models
    tasked with responding to queries in technical domains requiring high accuracy
    (such as financial analysis) is the difficulty they tend to experience when handling
    numerical data. Deb et al. (2023), for example, looked in some depth at the mathematical
    reasoning abilities of GPT-3.5, GPT-4, PaLM-2 and LLaMa, with the authors finding
    that this remains a challenge for LLMs [[7](#bib.bib7)].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在改进预训练模型性能的技术上取得了显著进展，但仍然存在显著的不足。一个显著的挑战是，对于需要高精度的技术领域（如金融分析）中的查询响应任务，模型在处理数值数据时往往会遇到困难。例如，Deb
    等人（2023）对 GPT-3.5、GPT-4、PaLM-2 和 LLaMa 的数学推理能力进行了较深入的研究，作者发现这仍然是大语言模型（LLMs）的一个挑战
    [[7](#bib.bib7)]。
- en: 3 Technical Background
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 技术背景
- en: Because the principal aim in preparing this paper was to compare LLM-improvement
    schemas available to non-expert users, we made a deliberate choice to use the
    most accessible fine-tuning and RAG frameworks, and doing so using the default
    settings where possible in order to establish a solid shared baseline for future
    research.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因为编写本文的主要目的是比较非专家用户可以使用的 LLM 改进方案，我们故意选择了最易于获取的微调和 RAG 框架，并尽可能使用默认设置，以建立一个坚实的共享基准，供未来研究使用。
- en: 3.1 Fine-Tuning Settings
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 微调设置
- en: In the case of the fine-tuned model, we relied upon OpenAI’s fine-tuning API,
    on the basis that OpenAI is currently the provider with the largest user-base,
    and often a go-to solution for both private and commercial users seeking LLM services.
    The default settings at the time our tests were conducted can be seen on table [1](#S3.T1
    "Table 1 ‣ 3.1 Fine-Tuning Settings ‣ 3 Technical Background ‣ Establishing Performance
    Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for
    Non-Specialist LLM Users"). While expert users committed to a fine-tuning operation
    will tend to use an iterative improvement process, non-specialists tend to lack
    the skills (or the financial resources) for this, thus we simply accept the results
    produced by the default settings.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于微调模型，我们依赖于 OpenAI 的微调 API，因为 OpenAI 目前是拥有最大用户基础的提供商，且通常是寻求 LLM 服务的私人和商业用户的首选解决方案。在我们进行测试时的默认设置可以在表[1](#S3.T1
    "Table 1 ‣ 3.1 Fine-Tuning Settings ‣ 3 Technical Background ‣ Establishing Performance
    Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for
    Non-Specialist LLM Users")上看到。虽然致力于微调操作的专家用户通常会使用迭代改进过程，但非专业人士往往缺乏这种技能（或财务资源），因此我们仅接受默认设置所产生的结果。
- en: 'Table 1: Description of Fine-Tuning Settings'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：微调设置描述
- en: '| Settings | Default Value | Details |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 设置 | 默认值 | 详细信息 |'
- en: '| --- | --- | --- |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| batch_size | 0.2 | Percentage of the total dataset batch size. Capped at
    256. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| batch_size | 0.2 | 数据集总批量大小的百分比。上限为256。 |'
- en: '| n_epochs | auto | Number of epochs. How the final number is decided is not
    publicized by OpenAI. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| n_epochs | auto | 训练轮数。最终数字如何确定并未公开。 |'
- en: '| learning_rate_multiplier | null | Multiplier to the algorithmically decided
    learning rate. OpenAI may decide based upon the size of the dataset, the resulting
    learning rate that can either be $0.05$, which are then finally multiplied by
    this value. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| learning_rate_multiplier | null | 对算法决定的学习率的乘数。OpenAI 可能根据数据集的大小决定最终的学习率，这个学习率可以是
    $0.05$，然后最终乘以这个值。'
- en: '| prompt_loss_weight | $0.01$ | The weight to use for loss on the prompt tokens.
    This controls how much the model tries to learn to generate the prompt (as compared
    to the completion which always has a weight of 1.0), and can add a stabilizing
    effect to training when completions are short. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| prompt_loss_weight | $0.01$ | 用于提示令牌的损失权重。这控制模型生成提示的学习程度（相比于总是有 1.0 权重的完成），并在完成较短时可以对训练产生稳定作用。'
- en: '| suffix | null | A string of up to 40 characters that will be added to your
    fine-tuned model name. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| suffix | null | 一个最多 40 个字符的字符串，将添加到你的微调模型名称中。 |'
- en: '| validation_file | null | The ID of an uploaded file that contains validation
    data. If you provide this file, the data is used to generate validation metrics
    periodically during fine-tuning. These metrics can be viewed in the fine-tuning
    results file. Your train and validation data should be mutually exclusive. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| validation_file | null | 包含验证数据的上传文件的 ID。如果提供此文件，数据将在微调过程中定期用于生成验证指标。这些指标可以在微调结果文件中查看。你的训练数据和验证数据应互相排除。
    |'
- en: 3.2 Retrieval-Augmented Generation
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 检索增强生成
- en: 'For our RAG framework, we used the commercially available kipley.ai platform,
    which is based around three principal components: the knowledge base creator module,
    the LLM deployer module, and the GUI-based Application Maker module.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 RAG 框架，我们使用了商业化的 kipley.ai 平台，该平台基于三个主要组件：知识库创建模块、LLM 部署模块和基于 GUI 的应用程序制作模块。
- en: 3.2.1 Knowledge Base Creator Module
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 知识库创建模块
- en: The first component of the RAG framework is the Knowledge Base Creator Module.
    As a core module in our Knowledge Integration Framework, the Knowledge Base Creator
    Module is used to facilitate a simpler and more seamless integration of diverse
    data sources into a knowledge base. The Knowledge Base Creator connects to a variety
    of data sources, allowing users to load and process a multitude of file formats
    (.pdf, .txt, .doc, .docx, .csv, .xlsx, .json, and more), as well as connecting
    the dynamic data streams via an API-Augmented data integration module. This module
    allows the system to augment answers using data gathered from APIs, including
    REST, SOAP, and GraphQL, proceeding to convert the data into other storable formats
    (.json, .csv, .txt, .xml, etc.).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 框架的第一个组件是知识库创建模块。作为我们知识集成框架中的核心模块，知识库创建模块用于简化和无缝集成各种数据源到知识库中。知识库创建模块连接到多种数据源，允许用户加载和处理多种文件格式（.pdf、.txt、.doc、.docx、.csv、.xlsx、.json
    等），并通过 API 增强的数据集成模块连接动态数据流。该模块允许系统利用从 API 收集的数据（包括 REST、SOAP 和 GraphQL）来增强答案，并将数据转换为其他可存储的格式（.json、.csv、.txt、.xml
    等）。
- en: The knowledge base is then vectorized via the Knowledge Base Creator Module,
    a multi-stage pipeline. Data extraction is carried out during the first stage,
    wherein the raw data from the uploaded files and dynamic data streams is extracted
    or copied, and stored temporarily on the server. Text Recognition and Optical
    Character Recognition (OCR) technology is applied to extract information from
    structured, semi-structured and unstructured documents [[8](#bib.bib8)]. As critical
    contextual information and important text information are often contained in image-based
    files (.pdf, .png, .jpg, etc), utilizing a compatible data extraction module with
    a robust OCR-based model can facilitate information retrieval and better incorporate
    this along with the textual information [[9](#bib.bib9)]. The [kipley.ai](http://kipley.ai)’s
    platform also provides self-service data collection functions from dynamic data
    streams via APIs. An API-based, self-service data ingestion platform can be used
    to push their data via pre-set APIs on a near-real-time basis [[10](#bib.bib10)].
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 知识库随后通过知识库创建模块进行向量化，这是一个多阶段流程。在第一阶段进行数据提取，从上传的文件和动态数据流中提取或复制原始数据，并暂时存储在服务器上。应用文本识别和光学字符识别（OCR）技术从结构化、半结构化和非结构化文档中提取信息
    [[8](#bib.bib8)]。由于关键信息和重要文本信息通常包含在基于图像的文件（.pdf、.png、.jpg 等）中，利用兼容的数据提取模块和强大的
    OCR 模型可以促进信息检索，并更好地将其与文本信息结合 [[9](#bib.bib9)]。 [kipley.ai](http://kipley.ai) 的平台还通过
    API 提供自服务的数据收集功能。基于 API 的自服务数据摄取平台可以通过预设的 API 实时推送数据 [[10](#bib.bib10)]。
- en: Following the data extraction process, the data undergoes a cleaning process.
    Retrieval-based data cleaning processes have been covered in prior studies, in
    which they demonstrated superior performance to non-retrieval-based data cleaning
    processes [[11](#bib.bib11)]. The [kipley.](kipley.) platform adopts this approach
    to ensure the cleaned data can be integrate with the relevant LLMs in such a way
    as to display sustainable performance and explainability.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据提取过程之后，数据会经过清洗过程。检索基础的数据清洗过程已在以前的研究中涉及，并且表现优于非检索基础的数据清洗过程 [[11](#bib.bib11)]。
    [kipley.](kipley.) 平台采用这种方法，以确保清洗后的数据能够与相关 LLM 集成，以展现可持续的性能和可解释性。
- en: Subsequently, the textual information is translated into dense numerical representations
    via a text embedding process using the FAISS library, which automatically creates
    another index file for semantic search functions [[12](#bib.bib12)]. Qdrant is
    also used to provide alternative embedding options ([https://qdrant.tech/documentation/](https://qdrant.tech/documentation/)).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，通过使用 FAISS 库的文本嵌入过程，将文本信息转换为密集的数值表示，该库自动为语义搜索功能创建另一个索引文件 [[12](#bib.bib12)]。Qdrant
    还用于提供备用嵌入选项 ([https://qdrant.tech/documentation/](https://qdrant.tech/documentation/))。
- en: Following the data embedding process, the loading stage employs the FAISS and
    Qdrant libraries with a Qdrant database instance and Qdrant cloud to support the
    text mining and embedding pipeline.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 按照数据嵌入过程，加载阶段使用 FAISS 和 Qdrant 库，并配备 Qdrant 数据库实例和 Qdrant 云，以支持文本挖掘和嵌入管道。
- en: 3.2.2 LLM Deployer Module
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 LLM 部署模块
- en: As described above, recent advancements in the field of Large Language Models
    (LLMs) have attracted much attention throughout industry and academia. For instance,
    OpenAI’s GPT4 [[13](#bib.bib13)], Anthropic’s Claude 2 [[14](#bib.bib14)], Google’s
    PaLM-2 [[15](#bib.bib15)] and Meta’s LLaMa-2 [[16](#bib.bib16)], have all demonstrated
    multilingual capabilities, high compute-efficiency, reasoning capabilities and
    task-execution capability for question answering, chain-of-thought reasoning,
    image analysis, and so on. Furthermore, multiple studies and extensive experimentation
    have showcased the ability of large language models to solve simple real-world
    coding problems [[17](#bib.bib17)] and mathematical problems via chain-of-thought
    reasoning and self-improvement of via backward reasoning [[7](#bib.bib7)]. However,
    the limitations of existing LLMs remain significant. Multiple studies have expressed
    concerns regarding the training methodologies and the weight parameters of these
    models [[6](#bib.bib6)]. The context window size is still limited (though it varies
    across different LLMs), which constrains their comprehension capability [[18](#bib.bib18)],
    and the capacity of LLMs to collaborate within a multi-agent framework has not
    yet been not widely explored [[19](#bib.bib19)].
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，近年来大语言模型（LLMs）领域的进展引起了业界和学术界的广泛关注。例如，OpenAI 的 GPT4 [[13](#bib.bib13)]、Anthropic
    的 Claude 2 [[14](#bib.bib14)]、Google 的 PaLM-2 [[15](#bib.bib15)] 和 Meta 的 LLaMa-2
    [[16](#bib.bib16)] 都展示了多语言能力、高计算效率、推理能力和任务执行能力，例如问答、链式思维推理、图像分析等。此外，多个研究和广泛实验展示了大语言模型通过链式思维推理和自我改进解决简单现实编码问题
    [[17](#bib.bib17)] 和数学问题的能力 [[7](#bib.bib7)]。然而，现有 LLM 的局限性依然显著。多项研究对这些模型的训练方法和权重参数表示了担忧
    [[6](#bib.bib6)]。上下文窗口大小仍然有限（尽管不同 LLM 之间有所不同），这限制了它们的理解能力 [[18](#bib.bib18)]，而
    LLM 在多代理框架内的协作能力尚未得到广泛探索 [[19](#bib.bib19)]。
- en: 'Previous studies have provided evidence that LLM-based agents and proper prompt
    engineering can increase LLMs’ capabilities substantially [[19](#bib.bib19)].
    In the present paper, we employ similar methods via the second module of our RAG
    framework: LLM Deployer Module. The LLM Deployer Module incorporates multi-model
    collaborative agents and instructional prompt tuning to optimise the usage of
    large language models and knowledge bases created by the Knowledge Base Creator
    Module.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的研究提供了证据表明，基于 LLM 的代理和适当的提示工程可以显著提高 LLM 的能力 [[19](#bib.bib19)]。在本论文中，我们通过
    RAG 框架的第二个模块：LLM 部署模块，采用了类似的方法。LLM 部署模块结合了多模型协作代理和指令性提示调整，以优化大语言模型和由知识库创建者模块创建的知识库的使用。
- en: The multi-model collaborative agents consist of a variety of different systems,
    including semantic search agents connected to LLM analysis engines. In this context,
    different LLMs are used to retrieve user-relevant factual information from vector
    databases and then analyse it, draw conclusions, or transform it in user-directed
    manners [[20](#bib.bib20)]. This gives LLM-empowered agents the ability to translate,
    reflect and make decisions based on the context provided from the vectorised knowledge
    bases [[21](#bib.bib21)].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 多模型协作代理包括各种不同的系统，其中包括连接到 LLM 分析引擎的语义搜索代理。在这种情况下，不同的 LLM 被用来从矢量数据库中检索与用户相关的事实信息，然后分析这些信息、得出结论或以用户指定的方式进行转化
    [[20](#bib.bib20)]。这使得 LLM 赋能的代理能够根据来自矢量化知识库的上下文进行翻译、反映和决策 [[21](#bib.bib21)]。
- en: 'The transformation of the retrieved information is carried out via Instructional
    prompt tuning, which provides specific natural language instructions to the LLMs
    - a method which has also been widely used to instruct LLMs to complete real-world
    tasks [[6](#bib.bib6)]. Extensive studies have shown that prompt construction
    can greatly improve LLMs’ ability to understand long contexts, and leverage this
    context to generate complex responses [[22](#bib.bib22)]. To test the impact of
    prompting on outputs, we tested our question set twice: once using the questions
    alone, and then a second time incorporating a soft meta-prompt inserted via the
    [kipley.ai](http://kipley.ai) framework’s prompt-tuning module.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 检索信息的转化通过指令提示调优来完成，该方法向 LLM 提供特定的自然语言指令——这一方法也被广泛用于指导 LLM 完成实际任务 [[6](#bib.bib6)]。广泛的研究表明，提示构建可以显著提高
    LLM 理解长上下文的能力，并利用这些上下文生成复杂的响应 [[22](#bib.bib22)]。为了测试提示对输出的影响，我们对问题集进行了两次测试：第一次仅使用问题，第二次则通过
    [kipley.ai](http://kipley.ai) 框架的提示调优模块插入了一个软元提示。
- en: 3.2.3 GUI-based Application Maker Module
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 基于 GUI 的应用程序创建模块
- en: 'The third module of the RAG framework, the GUI-based Application Maker Module,
    enables non-technical users to interact with the Knowledge Base Creator Module
    and LLM Deployer Module to create and customize AI applications quickly. It is
    for this reason that this particular RAG framework is being used in the present
    study, enabling as it does a non-specialist user to create a customised conversational
    AI with comparable ease to the OpenAI fine-tuning API. This module consists of
    two components: a web-based application and a KB-LLM Connector. The web-based
    application is designed and developed using React framework [[23](#bib.bib23)].'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 框架的第三个模块，即基于 GUI 的应用程序创建模块，使非技术用户能够与知识库创建模块和 LLM 部署模块进行交互，从而快速创建和定制 AI 应用程序。因此，本研究采用了这一特定的
    RAG 框架，使非专业用户可以像使用 OpenAI 微调 API 一样轻松创建定制化的对话 AI。该模块由两个组件组成：一个基于 Web 的应用程序和一个
    KB-LLM 连接器。基于 Web 的应用程序使用 React 框架进行设计和开发 [[23](#bib.bib23)]。
- en: The KB-LLM Connector consists of a full-stack connecting channel that allows
    application creation by combining vectorised knowledge bases and LLM agents. Via
    this web-based application, users can choose to connect one of the previously-vectorised
    knowledge bases to a selected LLM agent, and modify the settings of the agent
    - changing the token limits or model parameters, or adding further information
    via instructional prompt tuning. KB-LLM Connector then passes the changes to the
    LLM allowing users to improve retrieved data accuracy and optimise the LLMs’ performance
    based on their specific needs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: KB-LLM 连接器由一个全栈连接通道组成，该通道通过将矢量化的知识库与 LLM 代理结合来创建应用程序。通过这个基于 Web 的应用程序，用户可以选择将一个先前矢量化的知识库连接到一个选定的
    LLM 代理，并修改代理的设置——更改令牌限制或模型参数，或通过指令提示调优添加更多信息。KB-LLM 连接器随后将更改传递给 LLM，使用户能够根据特定需求提高检索数据的准确性并优化
    LLM 的性能。
- en: 4 Methodology and Data
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 方法学与数据
- en: While retrieval-augmented generation and fine-tuning require (and work best
    with) differing data formats and types, the goal of this paper was to compare
    like-for-like as far as possible. Thus we took steps to ensure that the datasets
    used with each method were as similar as possible. Likewise, it was important
    that there be no chance of the relevant data appearing in the model’s original
    training data – implying a topic not covered online before September 2021 (GPT
    3.5’s training data only going as far as this date).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然检索增强生成和微调需要（并且在不同的数据格式和类型中效果最佳），但本文的目标是尽可能地进行同类比较。因此，我们采取了措施，以确保用于每种方法的数据集尽可能相似。同样，确保相关数据不会出现在模型的原始训练数据中也很重要——这意味着在2021年9月之前未在网上覆盖的话题（GPT
    3.5的训练数据仅到此日期）。
- en: For these reasons, we selected as our topic the LayerZero cryptocurrency bridging
    project – an enterprise that has been widely covered online, but which was not
    released until September 2021\. To prepare the dataset, we began by collecting
    a corpus of publicly available information relevant to the topic via web search.
    This information was split into paragraphs. From these paragraphs, a fine-tuning
    file was constituted in the role-content format used by OpenAI, with questions
    being written by the team to suit the paragraphs already collected as shown in
    figure [1](#S4.F1 "Figure 1 ‣ 4 Methodology and Data ‣ Establishing Performance
    Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for
    Non-Specialist LLM Users"). The “system content” paragraphs were then converted
    to text format and then vectorised in pkl format to be used in the RAG process
    as shown in figure [2](#S4.F2 "Figure 2 ‣ 4 Methodology and Data ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users"). While both fine-tuning and RAG are known to have
    an effect upon answer quality, prompt-tuning and soft prompting can also have
    an equal or even greater effect.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这些原因，我们选择了LayerZero加密货币桥接项目作为我们的主题——这是一个在网上广泛报道的企业，但直到2021年9月才发布。为了准备数据集，我们首先通过网络搜索收集了与该主题相关的公开信息。这些信息被拆分成段落。从这些段落中，按照OpenAI使用的角色内容格式构成了微调文件，团队编写的问题适合于已经收集的段落，如图[1](#S4.F1
    "Figure 1 ‣ 4 Methodology and Data ‣ Establishing Performance Baselines in Fine-Tuning,
    Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist LLM Users")所示。然后，将“系统内容”段落转换为文本格式，并在pkl格式中向量化，以便在RAG过程中使用，如图[2](#S4.F2
    "Figure 2 ‣ 4 Methodology and Data ‣ Establishing Performance Baselines in Fine-Tuning,
    Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist LLM Users")所示。虽然微调和RAG已知会影响答案质量，但提示微调和软提示也可能有相等甚至更大的影响。
- en: '![Refer to caption](img/ada8904c0922b6294ac7738501afb722.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ada8904c0922b6294ac7738501afb722.png)'
- en: 'Figure 1: Excerpt from the fine-tuning file prepared by the team.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：团队准备的微调文件摘录。
- en: '![Refer to caption](img/f05c564568dab96c455fc0b3f247f57a.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f05c564568dab96c455fc0b3f247f57a.png)'
- en: 'Figure 2: Extract from the text file used to constitute the pkl vector database
    used in the RAG process'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：用于构建RAG过程中的pkl向量数据库的文本文件摘录
- en: The fine-tuned and RAG systems having been prepared, we tested them using a
    set of 100 relevant questions, some requiring information only available post-2021,
    others more general, and a smaller set whose answers were not present in the data
    as shown in table [2](#S4.T2 "Table 2 ‣ 4 Methodology and Data ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users").
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调和RAG系统准备好之后，我们使用了一组100个相关问题对其进行了测试，其中一些问题需要仅在2021年后才能获得的信息，其他问题更为一般，还有一小部分问题的答案不在数据中，如表[2](#S4.T2
    "Table 2 ‣ 4 Methodology and Data ‣ Establishing Performance Baselines in Fine-Tuning,
    Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist LLM Users")所示。
- en: 'Table 2: Example Questions'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：示例问题
- en: '| Post-2021 | General | Answers not in parameters |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 2021年后 | 一般 | 参数中没有的答案 |'
- en: '| --- | --- | --- |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| "What is Bryan Pellegrino’s involvement in LayerZero?" | "Why is cross-chain
    interoperability difficult?" | "What is Ryan Zarick’s net worth?" |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| "Bryan Pellegrino 在 LayerZero 中的参与是什么？" | "为什么跨链互操作性很困难？" | "Ryan Zarick
    的净资产是多少？" |'
- en: '| "What happend to LayerZero in 2022?" | "How does chainlink work?" | "What
    does the public says about LayerZero?" |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| "LayerZero 在2022年发生了什么？" | "Chainlink 是如何工作的？" | "公众对LayerZero的评价是什么？" |'
- en: '| "Is LayerZero on Discord?" | "What is bridging?" | "Is Ryan Zarick a poker
    player?" |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| "LayerZero 在Discord上吗？" | "什么是桥接？" | "Ryan Zarick 是扑克玩家吗？" |'
- en: 'It is known that prompt-tuning and soft prompting can have as much or more
    impact upon model responses as both RAG and model fine-tuning. We sought to understand
    how the approaches may interact, and thus tested the question set twice: once
    using the questions alone, as given above, and then again preceded by a soft prompt:
    “You are an expert financial analyst specialising in cryptocurrencies and blockchain
    technology.” Such a preface not only instructs the model on how to frame its response,
    but helps to situate it in the proper area of the latent vector space to produce
    relevant responses.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 已知提示微调和软提示对模型响应的影响可以与RAG和模型微调一样大或更大。我们试图了解这些方法可能如何互动，因此测试了问题集两次：一次仅使用问题，如上所述，再一次在前面加上一个软提示：“你是一个专注于加密货币和区块链技术的金融分析专家。”这样的前言不仅指示模型如何构建其回答，还帮助将其定位在潜在向量空间中的适当区域，以产生相关的回答。
- en: 'We then proceeded to test each set of 100 prompts in three contexts:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在三种上下文中测试了每组100个提示：
- en: '1.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: With the basic un-fine-tuned, un-augmented GPT 3.5 Turbo 0613 model alone.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仅使用基本的未微调、未增强的GPT 3.5 Turbo 0613模型。
- en: '2.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: With a version of gpt-3.5-turbo-0613 fine-tuned with the abovementioned json
    file using OpenAI’s proposed default settings (it should be noted the OpenAI’s
    training API strives to adjust the number of training epochs and learning rate
    as a function of the training dataset).
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用OpenAI提议的默认设置通过上述json文件微调的gpt-3.5-turbo-0613版本（需要注意的是，OpenAI的训练API力求根据训练数据集调整训练周期和学习率）。
- en: '3.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: With the basic un-fine-tuned gpt-3.5-turbo-0613 model augmented via access to
    the pkl vector database previously described using the [kipley.ai](http://kipley.ai)
    RAG platform’s document retrieval preset defaults.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用基本的未微调gpt-3.5-turbo-0613模型，通过访问先前描述的pkl向量数据库，使用[kipley.ai](http://kipley.ai)
    RAG平台的文档检索预设默认值。
- en: 'Of which each response was scored by evaluators based on two criteria:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每个响应都由评估人员根据两个标准进行评分：
- en: '1.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The number of “false positives” in the response – that is to say, the number
    of sentences containing at least one hallucination (untrue assertion).
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 响应中的“假阳性”数量——也就是说，包含至少一个虚假陈述的句子的数量。
- en: '2.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: The presence of “false negatives” in the response – that is to say, an inability
    to find a correct answer even when this was present in the fine-tuning/vector
    database information (in the case of questions for which no clear answer existed
    in the data, a failure to say as much was considered a false negative). When the
    basic model stated that its training data only covered events prior to 2021 and
    recommended that the reader should consult other sources, this was not considered
    a false negative.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 响应中的“假阴性”的存在——也就是说，即使在微调/向量数据库信息中存在正确答案时，无法找到该答案（对于数据中没有明确答案的问题，未能指出这一点被视为假阴性）。当基本模型声明其训练数据仅涵盖2021年之前的事件并建议读者应查阅其他来源时，这不被视为假阴性。
- en: These were then amalgamated to produce a “total error-free responses” score
    for each test.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将这些结果合并，得出每个测试的“总无误回答”分数。
- en: 5 Results
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果
- en: We found that for both sets of prompts RAG performed better than the fine-tuned
    model, which in turn performed better than the un-fine-tuned model. Suprisingly
    as shown in table [3](#S5.T3 "Table 3 ‣ 5 Results ‣ Establishing Performance Baselines
    in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist
    LLM Users"), the fine-tuned model was much more prone to hallucination than the
    basic model – possibly because GPT has conducted extensive reinforcement learning
    via human feedback to dissuade the model from attempting to answer questions for
    which it has no useful information, and the fine-tuning process undermines this
    and alters the model’s priorities. This raises some interesting questions regarding
    potential techniques for “jail-breaking” the model itself, research into which
    has previously tended to focus on soft-prompting and prompt-tuning rather than
    fine-tuning.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，对于这两组提示，RAG的表现优于微调模型，而微调模型的表现又优于未微调模型。令人惊讶的是，如表[3](#S5.T3 "表 3 ‣ 5 结果 ‣
    确定非专业LLM用户在微调、检索增强生成和软提示中的性能基准")所示，微调模型比基本模型更容易产生幻觉——可能是因为GPT通过人类反馈进行了广泛的强化学习，以劝阻模型尝试回答没有有用信息的问题，而微调过程破坏了这一点并改变了模型的优先级。这引发了一些有趣的问题，关于潜在的“破解”模型的技术，以前的研究往往集中在软提示和提示微调上，而不是微调。
- en: 'Table 3: False positive answers given under each set of test conditions.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：在每组测试条件下给出的假阳性答案。
- en: '|  | gpt-3.5-turbo-0613 alone | gpt-3.5-turbo-0613 fine tuned | gpt-3.5-turbo-0613
    + vector database |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | gpt-3.5-turbo-0613 单独使用 | gpt-3.5-turbo-0613 微调 | gpt-3.5-turbo-0613 +
    向量数据库 |'
- en: '| No soft prompt | 89 | 157 | 9 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 无软提示 | 89 | 157 | 9 |'
- en: '| Soft prompt | 80 | 118 | 6 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 软提示 | 80 | 118 | 6 |'
- en: It is also interesting to note while both the basic model and the fine-tuned
    model had more problems with hallucination than failing to answer, while the augmented
    model showed more false negatives than false positives as shown in table [4](#S5.T4
    "Table 4 ‣ 5 Results ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented
    Generation and Soft-Prompting for Non-Specialist LLM Users"). Also noteworthy
    is the fact that soft prompting increased the base model’s tendency to give false
    negative answers. It is possible that the soft-prompt rendered the model more
    cautious in the answers it gave, and less inclined to guess at answers it was
    not certain about.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 同样有趣的是，尽管基本模型和微调模型在幻觉问题上比未回答问题更为突出，但增强模型显示假阴性比假阳性更多，如表 [4](#S5.T4 "表 4 ‣ 5 结果
    ‣ 微调、检索增强生成和软提示对非专业 LLM 用户的性能基准") 所示。还值得注意的是，软提示增加了基础模型产生假阴性答案的倾向。可能是软提示使模型在给出答案时变得更加谨慎，对不确定的答案不太倾向于猜测。
- en: 'Table 4: False negative answers given under each set of test conditions.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：在每组测试条件下给出的假阴性答案。
- en: '|  | gpt-3.5-turbo-0613 alone | gpt-3.5-turbo-0613 fine tuned | gpt-3.5-turbo-0613
    + vector database |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | gpt-3.5-turbo-0613 单独使用 | gpt-3.5-turbo-0613 微调 | gpt-3.5-turbo-0613 +
    向量数据库 |'
- en: '| No soft prompt | 56 | 45 | 20 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 无软提示 | 56 | 45 | 20 |'
- en: '| Soft prompt | 69 | 45 | 16 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 软提示 | 69 | 45 | 16 |'
- en: Whether assisted via a soft prompt or not, table [5](#S5.T5 "Table 5 ‣ 5 Results
    ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation
    and Soft-Prompting for Non-Specialist LLM Users") shown that both the basic model
    and the fine-tuned model achieved only around 20-30% accuracy overall, while the
    augmented model got 77% of the questions right without a soft prompt, and 81%
    correct with one.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是否使用软提示，表 [5](#S5.T5 "表 5 ‣ 5 结果 ‣ 微调、检索增强生成和软提示对非专业 LLM 用户的性能基准") 显示，基本模型和微调模型总体准确率仅为
    20-30%，而增强模型在没有软提示的情况下正确回答了 77% 的问题，有软提示时正确率为 81%。
- en: 'Table 5: Total correct answers given under each set of test conditions.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：在每组测试条件下给出的正确答案总数。
- en: '|  | gpt-3.5-turbo-0613 alone | gpt-3.5-turbo-0613 fine tuned | gpt-3.5-turbo-0613
    + vector database |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | gpt-3.5-turbo-0613 单独使用 | gpt-3.5-turbo-0613 微调 | gpt-3.5-turbo-0613 +
    向量数据库 |'
- en: '| No soft prompt | 37 | 38 | 78 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 无软提示 | 37 | 38 | 78 |'
- en: '| Soft prompt | 24 | 28 | 81 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 软提示 | 24 | 28 | 81 |'
- en: It is important to note, however, that neither soft-prompting nor fine-tuning
    are exact sciences. A skillful auto-prompting gradient descent algorithm could
    no doubt improve these results further, while an extensive trial and error based
    fine-tuning process could certainly improve the results significantly. However,
    our objective in conducting this research was to compare the performance of tools
    available to non-expert corporate users, rather than specialist programmers, hence
    our choice to employ only the default settings in each case.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，软提示和微调都不是精确的科学。一种熟练的自动提示梯度下降算法无疑可以进一步改善这些结果，而一种广泛的试错微调过程也肯定能显著改善结果。然而，我们进行这项研究的目标是比较非专家企业用户可用工具的性能，而不是专业程序员，因此我们选择在每种情况下仅使用默认设置。
- en: 6 Analysis
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 分析
- en: 'The raw numbers are relatively clear: for a given, limited dataset and given
    a limited amount of time and technical skill, RAG is more effective as fine-tuning,
    which in turn is more effective than using the unmodified model provided by OpenAI
    to all users. Likewise, all of these methods are improved by the use of soft prompts
    that help the model to situated itself within the correct vector space to identify
    appropriate answers, and to frame them correctly.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据相对明确：在给定的有限数据集、有限时间和技术技能下，RAG 比微调更有效，而微调又比 OpenAI 提供给所有用户的未经修改的模型更有效。同样，所有这些方法都通过使用软提示得到改善，软提示帮助模型在正确的向量空间内定位以识别合适的答案，并正确地框定它们。
- en: However, the nature of the errors made was often informative. Interestingly,
    while the unmodified model had no information on the LayerZero project upon which
    to draw, when it guessed answers rather than apologising, it was often correct
    or close to correct. This seems to be a reflection of the fact that cryptocurrency
    projects tend to aim to solve a limited set of problems, and describe this process
    in similar words. As a result, if asked to describe a project it does not know,
    GPT can often make a reasonable attempt. Consider this example given in table [6](#S6.T6
    "Table 6 ‣ 6 Analysis ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented
    Generation and Soft-Prompting for Non-Specialist LLM Users").
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，错误的性质往往具有信息性。有趣的是，尽管未经修改的模型没有关于 LayerZero 项目的信息可供参考，但当它猜测答案而不是道歉时，通常是正确的或接近正确的。这似乎反映了加密货币项目通常旨在解决有限的问题集，并用类似的词汇描述这一过程。结果，如果被要求描述一个它不了解的项目，GPT
    通常能够做出合理的尝试。考虑表格中给出的示例[6](#S6.T6 "表 6 ‣ 6 分析 ‣ 在微调、检索增强生成和软提示中建立性能基准，以供非专业LLM用户使用")。
- en: 'Table 6: Vague answers from unmodified ChatGPT.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 未经修改的 ChatGPT 的模糊答案。'
- en: '| Question | "You are an expert financial analyst specialising in cryptocurrencies
    and blockchain technology. What dApps are using LayerZero?" |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "你是一个专注于加密货币和区块链技术的金融分析专家。哪些 dApps 正在使用 LayerZero？" |'
- en: '| --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Answer | "LayerZero is a blockchain scalability protocol that aims to create
    a scalable and high-performance infrastructure for decentralized applications
    (dApps). As of now, there aren’t any specific dApps that are using LayerZero since
    it is still in the early stages of development. However, LayerZero has been designed
    to be compatible with existing Ethereum-based dApps. So, once it is fully developed,
    it is expected that existing dApps built on Ethereum could potentially migrate
    to LayerZero to take advantage of its improved scalability and performance features."
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | "LayerZero 是一个区块链可扩展性协议，旨在为去中心化应用程序（dApps）创建一个可扩展且高性能的基础设施。目前，还没有特定的
    dApps 使用 LayerZero，因为它仍处于开发初期。然而，LayerZero 已设计为与现有的以太坊 dApps 兼容。因此，一旦它完全开发完成，预计现有的以太坊
    dApps 可能会迁移到 LayerZero，以利用其改进的可扩展性和性能特征。" |'
- en: The first sentence is entirely true, but also so vague that it could potentially
    describe almost any blockchain project. By sticking to points that are common
    to many projects, GPT avoids being wrong though neither does it accurately reflect
    the core features of the technology (which is, in fact, an interoperability protocol).
    Also interesting to note is that fine-tuning rendered the model slightly more
    accurate, but also less predictable. For example, when asked other question “What
    is a block header?”, the unmodified model gave the following response a shown
    in table [7](#S6.T7 "Table 7 ‣ 6 Analysis ‣ Establishing Performance Baselines
    in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist
    LLM Users").
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 第一段完全正确，但也如此模糊，以至于它可能描述几乎任何区块链项目。通过坚持许多项目共有的点，GPT避免了错误，尽管它也未能准确反映技术的核心特征（实际上是一个互操作性协议）。有趣的是，微调使模型稍微更准确，但也变得不那么可预测。例如，当被问及另一个问题“什么是区块头？”时，未经修改的模型给出了如下表格[7](#S6.T7
    "表 7 ‣ 6 分析 ‣ 在微调、检索增强生成和软提示中建立性能基准，以供非专业LLM用户使用")中所示的回答。
- en: 'Table 7: Correct answers from unmodified model.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 未经修改的模型的正确答案。'
- en: '| Question | "What is a block header?" |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "什么是区块头？" |'
- en: '| --- | --- |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Answer | "A block header is a data structure that contains information about
    a block in a blockchain network. It includes crucial details such as the block’s
    version number, the previous block’s hash, the timestamp of when the block was
    created, the Merkle root of the block’s transactions, the target difficulty for
    mining the block, and a nonce (a random number used in the mining process). The
    block header is hashed to create a unique identifier called the block hash, which
    is used for linking blocks in the blockchain. All nodes in the blockchain network
    verify the header’s integrity before accepting a new block." |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | "区块头是一个数据结构，包含有关区块链网络中一个区块的信息。它包括诸如区块的版本号、前一个区块的哈希值、区块创建的时间戳、区块交易的 Merkle
    根、挖掘区块的目标难度和一个 nonce（在挖掘过程中使用的随机数）等关键细节。区块头被哈希以创建一个唯一标识符，称为区块哈希，用于将区块链接在区块链中。区块链网络中的所有节点在接受新区块之前验证头的完整性。"
    |'
- en: This is a correct answer from the unmodified model’s perspective, since it does
    not have up-to-date information on this topic. By contrast, the fine-tuned model
    gave the following answer shown in table [8](#S6.T8 "Table 8 ‣ 6 Analysis ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users")
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从未经修改的模型的角度来看，这是一个正确的答案，因为它没有关于这个主题的最新信息。相比之下，微调模型给出了表[8](#S6.T8 "Table 8 ‣
    6 Analysis ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented
    Generation and Soft-Prompting for Non-Specialist LLM Users")中所示的答案。
- en: 'Table 8: Hallucinating answers from finetuned model.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表8：微调模型的幻觉回答。
- en: '| Question | "What is a block header?" |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "什么是区块头？" |'
- en: '| --- | --- |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Answer | "The LayerZero Theseus block header is an Ex justified block header
    obtained by Theseus from the Endpoints of chain A and chain B. The block header
    of chain A is stored in the block header of the corresponding transaction in chain
    B, and the block header is justified by the Merkle proof. Some people may be wondering:
    The endorsed transaction is at the end of the chain, and its block header is well
    justified. Isnt it a real block header? These block headers are synthesized, not
    in the traditional sense. Theobvious is that the original block headers on chain
    A are real, but the transaction block headers stored in B are for security reasons.
    The nodes are stored in small segments, and they are not all. Theseus end-to-end
    Consensus Mechanism LayerZero The LayerZero consensus layer can obtain block headers
    on chain A in real time, ensuring that the block headers on chain B are fully
    justified. Use Case: LayerZero Quotes Block Timestamp" |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 答案 | "LayerZero Theseus区块头是Theseus从链A和链B的端点获得的经过Ex验证的区块头。链A的区块头存储在链B中相应交易的区块头中，并且通过Merkle证明得到验证。有些人可能会想：被认可的交易在链末尾，其区块头得到了充分验证。这不是一个真正的区块头吗？这些区块头是合成的，不是传统意义上的。显而易见的是，链A上的原始区块头是真实的，但存储在B中的交易区块头是出于安全原因。这些节点以小段形式存储，并不是全部。Theseus端到端共识机制LayerZero
    LayerZero共识层可以实时获取链A上的区块头，确保链B上的区块头得到完全验证。用例：LayerZero报价区块时间戳" |'
- en: Interestingly, while the fine-tuned model is discussing cross-chain interoperability,
    everything else in the response is entirely made-up. This seems to suggest that
    finetuning may have the capacity not simply to influence the model’s answers in
    a particular direction, but to undermine or sidestep the RLHF process engaged
    in by OpenAI. (For purposes of comparison, the retrieval-augmented model answered,
    “A block header is the metadata of a block in a blockchain system.”)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，尽管微调模型在讨论跨链互操作性时，回答中的其他内容完全是捏造的。这似乎表明，微调可能不仅仅是影响模型答案的特定方向，而是可能破坏或绕过OpenAI进行的RLHF过程。（为了比较，检索增强模型回答了，“区块头是区块链系统中区块的元数据。”）
- en: Similarly, the fine-tuned model seems to reveal more of its own deterministic
    nature. By comparing the answers we found in table [9](#S6.T9 "Table 9 ‣ 6 Analysis
    ‣ Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation
    and Soft-Prompting for Non-Specialist LLM Users"), we noted among the responses
    that we received, that responses that began with an error often ran ever further
    off-track, not just in terms of factual accuracy, but also in terms of grammar
    and syntax, rather as though a higher model temperature and lower top-P had been
    set.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，经过微调的模型似乎暴露了更多其自身的决定性特征。通过比较我们在表[9](#S6.T9 "Table 9 ‣ 6 Analysis ‣ Establishing
    Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting
    for Non-Specialist LLM Users")中找到的答案，我们注意到，在我们收到的回答中，错误开头的回答往往会偏离轨道，*不仅在事实准确性方面*，*而且在语法和句法方面*，就好像设置了更高的模型温度和更低的top-P一样。
- en: 'Table 9: Examples of LLM error under differing circumstances.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：在不同情况下LLM错误的示例。
- en: '| Question | "Has anyone exited from LayerZero?" |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | "有没有人退出LayerZero？" |'
- en: '| --- | --- |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Unmodified gpt-3.5-turbo-0613 Answer | "I’m sorry, but as an AI language
    model, I don’t have access to information about specific individuals or companies
    and their exits. Therefore, I can’t provide you with any specific details about
    whether anyone has exited from LayerZero or not. " |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 未修改的gpt-3.5-turbo-0613回答 | "对不起，作为一个AI语言模型，我无法获取关于特定个人或公司及其退出的信息。因此，我不能提供关于是否有人退出LayerZero的具体细节。"
    |'
- en: '| Fine tuned gpt-3.5-turbo-0613 Answer | "EF has a full vested amount of 24
    million $STG over a 4-year period (6 years per whitepaper plan). Whitepaper plan:
    -Year 1: 15% (3.6m $STG) per year – partial vested -Year 4 (3 years from now):
    100% (7.2m $STG) – fully vested *Please note that this is not an investment advice
    in any way, and venture capital funds purposely do not disclose the timing or
    financial details of their investment returns publicly. They have full control
    over the amount and timing of any tokens they choose to sell on exchanges. Below
    is a piece of Tweet which may give you a hint on an official reaction from the
    team if in the case there will be an attempt to prevent circulating funds to market
    in the long term." |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 微调的gpt-3.5-turbo-0613回答 | “EF在4年期间（白皮书计划中的6年）完全拥有2400万$STG。白皮书计划： - 第1年：每年15%（360万$STG）——部分归属
    - 第4年（3年后）：100%（720万$STG）——完全归属 *请注意，这绝不是投资建议，风险投资基金故意不公开其投资回报的时间或财务细节。他们对任何代币的出售金额和时间拥有完全的控制权。以下是一条推文，可能会给你一些关于团队如果有试图长期阻止市场流通资金的官方反应的提示。”
    |'
- en: '| Vector DB asissted gpt-3.5-turbo-0613 Answer | "The given context does not
    provide any information about whether anyone has exited from LayerZero." |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 向量数据库辅助的gpt-3.5-turbo-0613回答 | “给定的背景并未提供关于是否有人退出LayerZero的信息。” |'
- en: However, it is also worth noting that this fine-tuning issue can be solved to
    a degree by iterating on the number of training epochs and the learning rate,
    though this involves an investment in terms of tokens and effort.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，值得注意的是，通过调整训练轮次和学习率，某种程度上可以解决这个微调问题，尽管这涉及到代币和精力的投入。
- en: By contrast, the use of RAG tended to push the model to give much shorter answers
    – unsurprisingly, as the more it strays from facts retrieved from the vector database,
    the more likely it is to be wrong. RAG responses contained, on average just $23$
    words respectively.) This too can be solved by a skilled coder, notably by adding
    an instruction to the soft prompt instructing the model to list all the facts
    it can find in the retrieved data, however, since a non-expert would not necessarily
    be aware of this we also refrained.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，使用RAG倾向于促使模型给出更短的答案——这并不令人惊讶，因为它越是偏离从向量数据库中检索到的事实，就越可能出错。RAG的回答平均只有$23$个单词。虽然一个熟练的编码者可以通过向软提示中添加指令，要求模型列出其在检索数据中找到的所有事实来解决这一问题，但由于非专家可能未必了解这一点，我们也避免了这样做。
- en: 7 Conclusion
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: While we found that RAG significantly out-performed fine-tuning as an LLM-improvement
    strategy, until comparatively recently they were too technically complex for the
    majority of users to implement. While creating a fine-tuned model was within the
    reach of even comparatively un-technical users thanks to the OpenAI fine-tuning
    API and related documentation, RAG remained the preserve of experts. The growing
    availability of RAG tools - first in the form of code libraries such as Langchain
    and LlamaIndex, and then via consumer-facing GUIs such as OpenAI’s Chat with PDF
    tool, or the kipley.ai platform used in this paper - has changed the cost-benefit
    ratio for non-expert users.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们发现RAG在作为LLM改进策略方面明显优于微调，但直到最近，它们对大多数用户来说仍然过于技术复杂。尽管得益于OpenAI的微调API和相关文档，创建一个微调模型对相对不具备技术背景的用户来说已变得可行，但RAG仍然是专家的专属领域。RAG工具的逐步普及——首先是像Langchain和LlamaIndex这样的代码库，然后是OpenAI的Chat
    with PDF工具或本文中使用的kipley.ai平台等面向消费者的GUI——改变了非专家用户的成本效益比。
- en: The fine-tuning exercise conducted for the purpose of this paper takes between
    15 and 30 minutes to complete (depending on GPT API traffic), though it should
    be noted that both the cost and time required would increase were a user to iterate
    over multiple fine-tuning attempts, as is generally recommend. For comparison,
    generating the vector database used by the RAG process cost took around five minutes.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本论文进行的微调练习需要15到30分钟完成（取决于GPT API的流量），不过需要注意的是，如果用户进行多次微调尝试（一般推荐这样做），所需的成本和时间会增加。相比之下，生成RAG过程中使用的向量数据库大约花费了五分钟。
- en: For a non-expert user, the baseline outputs of the RAG approach - whether in
    combination with a basic soft prompt or alone - are significantly more accurate
    than those provided by the default fine-tuning settings, for a similar investment
    in time and effort. We thus recommend this approach for commercial users dipping
    a toe into the field.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非专家用户来说，RAG 方法的基线输出——无论是与基本软提示结合使用还是单独使用——在时间和精力投入相似的情况下，显著优于默认的微调设置。因此，我们建议商业用户尝试这种方法。
- en: References
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: References
- en: '[1] Partha Pratim Ray. Chatgpt: A comprehensive review on background, applications,
    key challenges, bias, ethics, limitations and future scope. Internet of Things
    and Cyber-Physical Systems, 2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Partha Pratim Ray. ChatGPT: 背景、应用、主要挑战、偏见、伦理、局限性和未来范围的全面评审。Internet of
    Things 和 Cyber-Physical Systems, 2023。'
- en: '[2] Michael Dowling and Brian Lucey. Chatgpt for (finance) research: The bananarama
    conjecture. Finance Research Letters, 53:103662, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Michael Dowling 和 Brian Lucey. ChatGPT 在（金融）研究中的应用：香蕉拉玛猜想。Finance Research
    Letters, 53:103662, 2023。'
- en: '[3] Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu, and Sameena Shah. Are
    chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination
    on several typical tasks. arXiv preprint arXiv:2305.05862, 2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Xianzhi Li, Xiaodan Zhu, Zhiqiang Ma, Xiaomo Liu, 和 Sameena Shah. ChatGPT
    和 GPT-4 是否是金融文本分析的通用解算器？对几个典型任务的检查。arXiv 预印本 arXiv:2305.05862, 2023。'
- en: '[4] Bhaskarjit Sarmah, Tianjie Zhu, Dhagash Mehta, and Stefano Pasquali. Towards
    reducing hallucination in extracting information from financial reports using
    large language models. arXiv preprint arXiv:2310.10760, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Bhaskarjit Sarmah, Tianjie Zhu, Dhagash Mehta, 和 Stefano Pasquali. 通过大型语言模型减少从金融报告中提取信息的幻觉。arXiv
    预印本 arXiv:2310.10760, 2023。'
- en: '[5] Neng Wang, Hongyang Yang, and Christina Dan Wang. Fingpt: Instruction tuning
    benchmark for open-source large language models in financial datasets. arXiv preprint
    arXiv:2310.04793, 2023.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Neng Wang, Hongyang Yang, 和 Christina Dan Wang. Fingpt: 针对金融数据集的开源大型语言模型的指令调优基准。arXiv
    预印本 arXiv:2310.04793, 2023。'
- en: '[6] Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi
    Xie. Pmc-llama: Towards building open-source language models for medicine. arXiv
    preprint arXiv:2305.10415v5, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, 和 Weidi
    Xie. PMC-LLAMA: 旨在构建开源医学语言模型。arXiv 预印本 arXiv:2305.10415v5, 2023。'
- en: '[7] Aniruddha Deb, Neeva Oza, Sarthak Singla, Dinesh Khandelwal, Dinesh Garg,
    and Parag Singla. Fill in the blank: Exploring and enhancing llm capabilities
    for backward reasoning in math word problems. arXiv preprint arXiv:2310.01991,
    2023.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Aniruddha Deb, Neeva Oza, Sarthak Singla, Dinesh Khandelwal, Dinesh Garg,
    和 Parag Singla. 填空：探索和增强 LLM 在数学文字题中反向推理的能力。arXiv 预印本 arXiv:2310.01991, 2023。'
- en: '[8] Graham A. Cutting and Anne-Françoise Cutting-Decelle. Intelligent document
    processing–methods and tools in the real world. arXiv preprint arXiv:2112.14070,
    2021.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Graham A. Cutting 和 Anne-Françoise Cutting-Decelle. 智能文档处理–现实世界中的方法和工具。arXiv
    预印本 arXiv:2112.14070, 2021。'
- en: '[9] Noam Rotstein, David Bensaid, Shaked Brody, Roy Ganz, and Ron Kimmel. Fusecap:
    Leveraging large language models to fuse visual data into enriched image captions.
    arXiv preprint arXiv:2305.17718, 2023.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Noam Rotstein, David Bensaid, Shaked Brody, Roy Ganz, 和 Ron Kimmel. Fusecap:
    利用大型语言模型将视觉数据融合成丰富的图像描述。arXiv 预印本 arXiv:2305.17718, 2023。'
- en: '[10] Michal Zasadzinski, Michael Theodoulou, Markus Thurner, and Kshitij Ranganath.
    The trip to the enterprise gourmet data product marketplace through a self-service
    data platform. arXiv preprint arXiv:2107.13212, 2021.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Michal Zasadzinski, Michael Theodoulou, Markus Thurner, 和 Kshitij Ranganath.
    通过自助服务数据平台进入企业美食数据产品市场。arXiv 预印本 arXiv:2107.13212, 2021。'
- en: '[11] Mohammad Shahmeer Ahmad, Zan Ahmad Naeem, Mohamed Eltabakh, Mourad Ouzzani,
    and Nan Tang. Retclean: Retrieval-based data cleaning using foundation models
    and data lakes. arXiv preprint arXiv:2303.16909, 2023.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Mohammad Shahmeer Ahmad, Zan Ahmad Naeem, Mohamed Eltabakh, Mourad Ouzzani,
    和 Nan Tang. Retclean: 基于检索的数据清洗，使用基础模型和数据湖。arXiv 预印本 arXiv:2303.16909, 2023。'
- en: '[12] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity
    search with gpus. IEEE Transactions on Big Data, 7(3):535–547, 2019.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Jeff Johnson, Matthijs Douze, 和 Hervé Jégou. 使用 GPU 进行亿规模相似性搜索。IEEE Transactions
    on Big Data, 7(3):535–547, 2019。'
- en: '[13] OpenAI. Gpt-4 technical report, 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] OpenAI. GPT-4 技术报告, 2023。'
- en: '[14] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova
    DasSarma, and Dawn Drain. Training a helpful and harmless assistant with reinforcement
    learning from human feedback. arXiv preprint arXiv:2204.05862, 2022.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova
    DasSarma, 和 Dawn Drain. 通过从人类反馈中进行强化学习来训练一个有用且无害的助手。arXiv 预印本 arXiv:2204.05862,
    2022。'
- en: '[15] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,
    Alexandre Passos, and Siamak Shakeri. Palm 2 technical report. arXiv preprint
    arXiv:2305.10403, 2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Rohan Anil、Andrew M. Dai、Orhan Firat、Melvin Johnson、Dmitry Lepikhin、Alexandre
    Passos 和 Siamak Shakeri。Palm 2 技术报告。arXiv 预印本 arXiv:2305.10403，2023 年。'
- en: '[16] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, and Nikolay Bashlykov. Llama 2: Open foundation and fine-tuned
    chat models. arXiv preprint arXiv:2307.09288, 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Hugo Touvron、Louis Martin、Kevin Stone、Peter Albert、Amjad Almahairi、Yasmine
    Babaei 和 Nikolay Bashlykov。Llama 2: 开放基础和微调聊天模型。arXiv 预印本 arXiv:2307.09288，2023
    年。'
- en: '[17] Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei,
    Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models resolve real-world
    github issues? arXiv preprint arXiv:2310.06770, 2023.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Carlos E. Jimenez、John Yang、Alexander Wettig、Shunyu Yao、Kexin Pei、Ofir
    Press 和 Karthik Narasimhan。Swe-bench: 语言模型能否解决真实世界的 GitHub 问题？arXiv 预印本 arXiv:2310.06770，2023
    年。'
- en: '[18] Shaokai Ye, Jessy Lauer, Mu Zhou, Alexander Mathis, and Mackenzie W. Mathis.
    Amadeusgpt: a natural language interface for interactive animal behavioral analysis.
    arXiv preprint arXiv:2307.04858, 2023.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Shaokai Ye、Jessy Lauer、Mu Zhou、Alexander Mathis 和 Mackenzie W. Mathis。Amadeusgpt:
    用于互动动物行为分析的自然语言接口。arXiv 预印本 arXiv:2307.04858，2023 年。'
- en: '[19] Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes,
    Michael Lewis, and Katia Sycara. Theory of mind for multi-agent collaboration
    via large language models. arXiv preprint arXiv:2310.10701, 2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Huao Li、Yu Quan Chong、Simon Stepputtis、Joseph Campbell、Dana Hughes、Michael
    Lewis 和 Katia Sycara。通过大型语言模型进行多代理协作的心智理论。arXiv 预印本 arXiv:2310.10701，2023 年。'
- en: '[20] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, and Heinrich Küttler. Retrieval-augmented generation for
    knowledge-intensive nlp tasks. arXiv preprint arXiv:2005.11401, pages 9459–9474,
    2020.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Patrick Lewis、Ethan Perez、Aleksandra Piktus、Fabio Petroni、Vladimir Karpukhin、Naman
    Goyal 和 Heinrich Küttler。用于知识密集型自然语言处理任务的检索增强生成。arXiv 预印本 arXiv:2005.11401，第 9459–9474
    页，2020 年。'
- en: '[21] Nian Li, Chen Gao, Yong Li, and Qingmin Liao. Large language model-empowered
    agents for simulating macroeconomic activities. arXiv preprint arXiv:2310.10436,
    2023.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Nian Li、Chen Gao、Yong Li 和 Qingmin Liao。利用大型语言模型增强的代理用于模拟宏观经济活动。arXiv
    预印本 arXiv:2310.10436，2023 年。'
- en: '[22] Edward Junprung. Exploring the intersection of large language models and
    agent-based modeling via prompt engineering. arXiv preprint arXiv:2308.07411,
    2023.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Edward Junprung。通过提示工程探索大型语言模型与基于代理的建模的交集。arXiv 预印本 arXiv:2308.07411，2023
    年。'
- en: '[23] S. Sasikumar, S. Prabha, and Chandra Mohan. Improving performance of next.js
    app and testing it while building a badminton based web app. In Proceedings of
    the International Conference on Innovative Computing & Communication (ICICC) 2022,
    May 2022.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] S. Sasikumar、S. Prabha 和 Chandra Mohan。在构建基于羽毛球的 Web 应用时提升 Next.js 应用性能并进行测试。见于
    2022 年国际创新计算与通信会议（ICICC）论文集，2022 年 5 月。'
