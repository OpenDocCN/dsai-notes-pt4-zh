- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:48:06'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling
    for LLM Few-Shot Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.09782](https://ar5iv.labs.arxiv.org/html/2311.09782)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Bingsheng Yao
  prefs: []
  type: TYPE_NORMAL
- en: Rensselaer Polytechnic Institute
  prefs: []
  type: TYPE_NORMAL
- en: \AndGuiming Chen
  prefs: []
  type: TYPE_NORMAL
- en: The Chinese University
  prefs: []
  type: TYPE_NORMAL
- en: of Hong Kong, Shenzhen
  prefs: []
  type: TYPE_NORMAL
- en: \AndRuishi Zou
  prefs: []
  type: TYPE_NORMAL
- en: Tongji University
  prefs: []
  type: TYPE_NORMAL
- en: \ANDYuxuan Lu
  prefs: []
  type: TYPE_NORMAL
- en: Northeastern University
  prefs: []
  type: TYPE_NORMAL
- en: \AndJiachen Li
  prefs: []
  type: TYPE_NORMAL
- en: Northeastern University
  prefs: []
  type: TYPE_NORMAL
- en: \AndShao Zhang
  prefs: []
  type: TYPE_NORMAL
- en: Shanghai Jiao Tong University
  prefs: []
  type: TYPE_NORMAL
- en: \ANDSijia Liu
  prefs: []
  type: TYPE_NORMAL
- en: Michigan State University
  prefs: []
  type: TYPE_NORMAL
- en: \AndJames Hendler
  prefs: []
  type: TYPE_NORMAL
- en: Rensselaer Polytechnic Institute
  prefs: []
  type: TYPE_NORMAL
- en: \AndDakuo Wang
  prefs: []
  type: TYPE_NORMAL
- en: 'Northeastern University   Corresponding Author: d.wang@northeastern.edu .'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While most existing works on LLM prompt-engineering focus only on how to select
    a better set of data samples inside one single prompt input¹¹1We use “prompt input”
    to refer to the composition of prompt structure/words, plus in-context examples,
    and the targeting data for inference. (In-Context Learning or ICL), why can’t
    we design and leverage multiple prompt inputs together to further improve the
    LLM performance? In this work, we propose In-Context Sampling (ICS), a low-resource
    LLM prompt-engineering technique to produce the most confident prediction results
    by optimizing the construction of multiple ICL prompt inputs. Extensive experiments
    with two SOTA LLMs (FlanT5-XL and Mistral-7B) on three NLI datasets (e-SNLI, Multi-NLI,
    and ANLI) illustrate that ICS can consistently enhance LLM’s prediction performance
    and confidence. An ablation study suggests that a diversity-based ICS strategy
    may further improve LLM’s performance, which sheds light on a new yet promising
    future research direction.
  prefs: []
  type: TYPE_NORMAL
- en: More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling
    for LLM Few-Shot Prompt Engineering
  prefs: []
  type: TYPE_NORMAL
- en: Bingsheng Yao Rensselaer Polytechnic Institute                        Guiming
    Chen The Chinese University of Hong Kong, Shenzhen                        Ruishi
    Zou Tongji University
  prefs: []
  type: TYPE_NORMAL
- en: Yuxuan Lu Northeastern University                        Jiachen Li Northeastern
    University                        Shao Zhang Shanghai Jiao Tong University
  prefs: []
  type: TYPE_NORMAL
- en: 'Sijia Liu Michigan State University                        James Hendler Rensselaer
    Polytechnic Institute                        Dakuo Wang ^†^†thanks:   Corresponding
    Author: d.wang@northeastern.edu . Northeastern University'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instruction-finetuned Wei et al. ([2021b](#bib.bib23)); Chowdhery et al. ([2022](#bib.bib5));
    Ouyang et al. ([2022](#bib.bib14)) LLMs with billions of parameters, such as Flan-T5 Chung
    et al. ([2022b](#bib.bib7)), LLaMA Touvron et al. ([2023a](#bib.bib19), [b](#bib.bib20)),
    and Mistral Jiang et al. ([2023](#bib.bib8)) have demonstrated versatile natural
    language interpretation and generation (NLG) capabilities. However, solving real-world
    tasks that require extensive domain expertise remains challenging for LLMs (e.g.,
    children’s education and mental issue detection Xu et al. ([2023](#bib.bib26))).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/41c2ed9c1bd77d82adedf7aa52c8b734.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: ICS includes three steps: 1) sample representative examples, 2) augment
    ICL combinations for inference, and 3) find LLM’s most confident label.'
  prefs: []
  type: TYPE_NORMAL
- en: Researchers have proposed various prompting strategies to exploit LLMs’ task-solving
    capabilities. A prominent approach is few-shot In-Context Learning (ICL) Brown
    et al. ([2020a](#bib.bib2)), which improved LLMs’ task interpretation and solving
    ability, especially for unseen tasks, by inserting a few data examples to the
    prompt input Shin et al. ([2022](#bib.bib18)). Several recent works investigate
    the influence of different ICL setups, including the number, ordering, and combinations Wang
    et al. ([2022](#bib.bib21)); Lu et al. ([2021](#bib.bib11)); Yoo et al. ([2022](#bib.bib29)).
    However, there is no common ground for the best ICL strategy yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'We hypothesize that different ICL demonstrations provide LLMs with distinct
    knowledge about the task, leading to disparate understanding and predictions for
    the same data. Consequently, a straightforward research question emerges: Can
    LLMs be augmented with multiple ICL prompt inputs to provide the most confident
    predictions?'
  prefs: []
  type: TYPE_NORMAL
- en: 'To address this question, we propose In-Context Sampling (ICS), a low-resource
    methodology inspired by the established concept of membership querying and In-Context
    Learning. ICS follows a three-step pipeline: subsampling, augmentation, and verification,
    as shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ More Samples or More
    Prompt Inputs? Exploring Effective In-Context Sampling for LLM Few-Shot Prompt
    Engineering").'
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate the effectiveness of the ICS pipeline by benchmarking on two SOTA
    LLMs over three natural language inference (NLI) Bowman et al. ([2015](#bib.bib1))
    datasets of increasing difficulties , compared with the regular ICL approach.
    We also examine how different sample sizes and rounds of ICL prompting affect
    the performance of ICS. Results indicate that ICS consistently improves prediction
    accuracy and robustness despite LLMs demonstrating different ICL sensitiveness.
    An ablation study shows a data diversity-based ICS strategy can further improve
    prediction performance, which leads to a broader research scope to exploit the
    potential for ICS in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Related Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large Language Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Instructional-fine-tuned LLMs Chung et al. ([2022a](#bib.bib6)) have shown impressive
    capability in understanding free-form instructions and generating high-quality
    content Wei et al. ([2021a](#bib.bib22)). Prompting methods such as chain-of-thought Wei
    et al. ([2023](#bib.bib24)) and in-context Brown et al. ([2020b](#bib.bib3)) learning
    have been developed to exploit LLMs’ potential. Our ICS pipeline extends these
    advances to improve the performance and confidentiality of LLMs’ prediction.
  prefs: []
  type: TYPE_NORMAL
- en: In-Context Learning Optimization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The optimization of in-context learning performance has garnered significant
    attention. Wei et al. ([2021a](#bib.bib22)) proposed an Instruction Tuning method
    that improves both zero-shot and few-shot in-context learning performance. Kim
    et al. ([2022](#bib.bib9)) proposed a method that allows the model to generate
    in-context samples for itself to minimize the reliance on the external demonstration.
    Zhang et al. ([2022](#bib.bib31)) focused on in-context samples and initiated
    a reinforcement learning technique to select more advantageous samples for in-context
    demonstration.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, some work focused on solving the order sensitivity issue for ICL. Lu
    et al. ([2022](#bib.bib12)) proposed multiple sample sorting methods, while Liu
    et al. ([2022](#bib.bib10)) introduced a method for arranging examples based on
    their semantic similarity. Furthermore, Yu et al. ([2023](#bib.bib30)) utilize
    prompt-based uncertainty propagation and a partition-then-rewrite strategy to
    further improve models’ few-shot performance.
  prefs: []
  type: TYPE_NORMAL
- en: 3 ICS Strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given a natural language task instruction $I$ given different ICL prompt inputs,
    but the variation of predictions will eventually converge to a most confident
    prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this work, we present In-context Sampling (ICS), a low-resource learning
    paradigm specifically for LLMs, as shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling
    for LLM Few-Shot Prompt Engineering"). ICS consists of three primary steps: 1)
    sampling demonstration candidates from unlabeled data pool and acquiring oracle
    annotations, 2) augmenting labels with different ICL combinations, and 3) verifying
    the most confident label as the final prediction from augmented labels. We will
    describe details about each step below.'
  prefs: []
  type: TYPE_NORMAL
- en: Our prototyped ICS methodology is designed to be model-agnostic. More importantly,
    ICS supports “plug-and-play” customizations by switching to different sampling,
    augmentation, and verification algorithms with minimum effort. This work primarily
    focuses on justifying the effectiveness of our proposed ICS pipeline and investigating
    the influence of different factors towards performance improvement and robustness,
    leaving a broad research area to explore different strategy variations as future
    work.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Demonstration Candidate Sampling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sampling a few data as ICL demonstrations from many unlabeled data bears a
    resemblance to many sampling strategies in Active Learning (AL) Settles ([2009](#bib.bib17)),
    often categorized into two types: data diversity-based and model probability-based.'
  prefs: []
  type: TYPE_NORMAL
- en: Our primary evaluation of the ICS pipeline in Section [4](#S4 "4 Evaluations
    ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling
    for LLM Few-Shot Prompt Engineering") utilizes a random sampling strategy. In
    addition, we conduct an ablation study (Section [4.3](#S4.SS3 "4.3 Ablation Study
    ‣ 4 Evaluations ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context
    Sampling for LLM Few-Shot Prompt Engineering")) to discuss the effects of a diversity-based
    ICS strategy. Our implemented strategy adheres to established cluster-based strategies
    (i.e., core-set) Sener and Savarese ([2017](#bib.bib16)); Yao et al. ([2023b](#bib.bib28)),
    aiming to identify examples representative of all unlabeled data while maximizing
    the diversity among these selected instances. Our strategy calculates the cosine
    similarity for each data $x_{i}$ examples with the same interval, ensuring the
    sample set’s diversity.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also attempt to identify a sample size and the amount of augmented ICL combinations
    that strike a balance across three perspectives: 1) encompass sufficient diversity
    to represent the underlying data adequately, 2) possess robustness toward confident
    predictions, and 3) minimize annotation costs.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 ICL Combination Augmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As shown in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ More Samples or More
    Prompt Inputs? Exploring Effective In-Context Sampling for LLM Few-Shot Prompt
    Engineering"), ICS augments labels by constructing different ICL combinations
    for the same data to be predicted, then getting the most confident label among
    all. Empirically, less than $10$ 3-demonstration combinations.
  prefs: []
  type: TYPE_NORMAL
- en: We believe, however, that ICS does not need every ICL combination to find the
    model’s most confident label. Analogous to human voting, where a few representatives
    vote on behalf of a larger population, we plan to investigate a reasonable amount
    of “representatives”, i.e., prompt inputs.
  prefs: []
  type: TYPE_NORMAL
- en: In this work, we benchmark with a random and a data diversity-based algorithm
    for demonstration augmentation and investigate the influence of strategic differences.
    Both approaches iteratively sample $m$ as shown in Figure [1](#S1.F1 "Figure 1
    ‣ 1 Introduction ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context
    Sampling for LLM Few-Shot Prompt Engineering").
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Confident Label Verification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once we acquire a set of labels from the abovementioned ICS step, a few verification
    algorithms can be applied to find the most confident label. Here, we obtain the
    most confident prediction with a majority vote in our evaluation. We can envision
    ICS as having the potential to provide model-confident unsupervised labels to
    iteratively fine-tune LLM in resource-deficient scenarios where expert annotations
    are difficult and expensive to access.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Evaluations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We conduct benchmark experiments to demonstrate the effectiveness of our ICS
    pipeline with a random sampling strategy. Specifically, we employ two SOTA LLMs
    (FLAN-T5-XL Chung et al. ([2022b](#bib.bib7)) and Mistral Jiang et al. ([2023](#bib.bib8)))
    and experiment on three NLI tasks of increasing difficulties: e-SNLI Camburu et al.
    ([2018](#bib.bib4)), Multi-NLI Williams et al. ([2017](#bib.bib25)), and ANLI Nie
    et al. ([2019](#bib.bib13)). We exclude LLaMA-2 Touvron et al. ([2023b](#bib.bib20))
    from our work because our preliminary experiment (discussed in Appendix [E](#A5
    "Appendix E Analysis on LLaMA-2 ‣ More Samples or More Prompt Inputs? Exploring
    Effective In-Context Sampling for LLM Few-Shot Prompt Engineering") shows LLaMA-2’s
    overfitting issue on the ‘neutral’ category).'
  prefs: []
  type: TYPE_NORMAL
- en: We use vanilla ICL as our baseline, denoted as $ICL$ trials.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Evaluation Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[e-SNLI] [Multi-NLI] [ANLI] Figure 2: Evaluation results of Flan-T5-XL and
    Mistral-7B on three dataset with $100$ demonstration candidates.'
  prefs: []
  type: TYPE_NORMAL
- en: In Figure [2](#S4.F2 "Figure 2 ‣ 4.2 Evaluation Results ‣ 4 Evaluations ‣ More
    Samples or More Prompt Inputs? Exploring Effective In-Context Sampling for LLM
    Few-Shot Prompt Engineering"), we present the prediction accuracy of baseline
    ICL and our ICS strategy for every model and dataset when $n=100$. The change
    in standard deviations between the baseline and our strategy is also reported
    as dotted lines with the right vertical axis. The complete evaluation results
    for every setting are reported in Appendix [C](#A3 "Appendix C Complete Evaluation
    Results ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling
    for LLM Few-Shot Prompt Engineering").
  prefs: []
  type: TYPE_NORMAL
- en: Our ICS strategy, benchmarked with a random sampling strategy, can consistently
    improve both LLMs’ prediction performance in every $(n,k)$ combination, justifying
    the validity of our proposed ICS pipeline. Additionally, we observe distinct sensitiveness
    to ICS between LLMs. Specifically, the accuracy improvement provided by the ICS
    strategy for Flan-T5 is much less than that for Mistral, which could be attributed
    to different reasons. For instance, Flan-T5 may overfit the three datasets we
    experimented with or the NLI task. On the other hand, Mistral illustrates significant
    accuracy boosts from our ICS strategy, resulting in more than 5% average improvement
    in all datasets.
  prefs: []
  type: TYPE_NORMAL
- en: We observe that the standard deviation reduces the most when $k=10$ goes beyond
    100\. Sample sizes over 100 can be considered diverse and representative enough.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Ablation Study
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '|  | e-SNLI | Multi-NLI | ANLI |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS^{DS}_{DS}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICL^{DS}_{DS}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS^{DS}_{RD}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICL^{DS}_{RD}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS^{RD}_{DS}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICL^{RD}_{DS}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS^{RD}_{RD}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICL^{RD}_{RD}$ |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Ablation study for the diversity-based ICS strategy on all three datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the observations from the aforementioned evaluation, we conduct an ablation
    study among different strategies for ICS, with Mistral-7B and the best-performing
    setup: $n=100$ denotes data similarity-based strategy described in Section [3.1](#S3.SS1
    "3.1 Demonstration Candidate Sampling ‣ 3 ICS Strategy ‣ More Samples or More
    Prompt Inputs? Exploring Effective In-Context Sampling for LLM Few-Shot Prompt
    Engineering"). The experiment results are reported in Appendix [B](#A2 "Appendix
    B Ablation Study with Diversity-based ICS Strategy ‣ More Samples or More Prompt
    Inputs? Exploring Effective In-Context Sampling for LLM Few-Shot Prompt Engineering").
    We report that the diversity-based strategy for demonstration candidate sampling
    and combination augmentation can effectively increase ICS performance gain, which
    can lead to broader future research avenues in exploiting the benefits from ICS
    with LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work presents In-context Sampling (ICS), a novel ICL-based paradigm for
    probing LLMs’ most confident prediction. Our experiments show that ICS leads to
    accuracy improvement and standard deviation reduction compared with traditional
    ICL. We investigate the influence of different sample sizes and ICL combination
    amounts, then further conduct an ablation study to illustrate the additional helpfulness
    provided by a simple but effective data diversity-based sampling strategy with
    ICS. We expect our work to lay the foundation for further exploiting the benefits
    of ICL in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The primary focus of this paper is to propose and demonstrate the effectiveness
    of our ICS pipeline. Our experiments showed that ICS can improve the model’s performance
    (in prediction accuracy) and confidence (in standard deviation) even with the
    most straightforward random strategy. However, despite extensive experiments with
    different $n$ combinations, several potential variables require further analysis.
    For instance, although we considered three datasets of different difficulties
    and each ICL combination is arbitrary, all three datasets are NLI tasks. Besides,
    we only conducted a small-scale ablation study with a data diversity-based strategy
    for candidate sampling and combination augmentation in ICS, leaving a full line
    of work of designing and implementing sampling strategies across different tasks.
    Lastly, our experiment comprises three SOTA LLMs as the original plan but excludes
    LLaMA-2 due to its inclination to predict the “neutral” category. We identify
    that there are still a variety of other instructional-finetuned LLMs we do not
    include in this work, such as InstructGPT Ouyang et al. ([2022](#bib.bib14)).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bowman et al. (2015) Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D
    Manning. 2015. A large annotated corpus for learning natural language inference.
    *arXiv preprint arXiv:1508.05326*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020a) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, et al. 2020a. Language models are few-shot learners. *Advances
    in neural information processing systems*, 33:1877–1901.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020b) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020b. Language models are few-shot learners. In *Proceedings of the 34th
    International Conference on Neural Information Processing Systems*, NIPS’20, pages
    1877–1901, Red Hook, NY, USA. Curran Associates Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Camburu et al. (2018) Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz,
    and Phil Blunsom. 2018. e-snli: Natural language inference with natural language
    explanations. *Advances in Neural Information Processing Systems*, 31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chowdhery et al. (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways.
    *arXiv preprint arXiv:2204.02311*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chung et al. (2022a) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert
    Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery,
    Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav
    Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov,
    Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and
    Jason Wei. 2022a. [Scaling Instruction-Finetuned Language Models](http://arxiv.org/abs/2210.11416).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chung et al. (2022b) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    2022b. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2022) Hyuhng Joon Kim, Hyunsoo Cho, Junyeob Kim, Taeuk Kim, Kang Min
    Yoo, and Sang-goo Lee. 2022. [Self-Generated In-Context Learning: Leveraging Auto-regressive
    Language Models as a Demonstration Generator](https://doi.org/10.48550/arXiv.2206.08082).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2022) Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence
    Carin, and Weizhu Chen. 2022. [What Makes Good In-Context Examples for GPT-3?](https://doi.org/10.18653/v1/2022.deelio-1.10)
    In *Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on
    Knowledge Extraction and Integration for Deep Learning Architectures*, pages 100–114,
    Dublin, Ireland and Online. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2021) Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and
    Pontus Stenetorp. 2021. Fantastically ordered prompts and where to find them:
    Overcoming few-shot prompt order sensitivity. *arXiv preprint arXiv:2104.08786*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2022) Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and
    Pontus Stenetorp. 2022. [Fantastically Ordered Prompts and Where to Find Them:
    Overcoming Few-Shot Prompt Order Sensitivity](https://doi.org/10.18653/v1/2022.acl-long.556).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 8086–8098, Dublin, Ireland. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nie et al. (2019) Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason
    Weston, and Douwe Kiela. 2019. Adversarial nli: A new benchmark for natural language
    understanding. *arXiv preprint arXiv:1910.14599*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, 35:27730–27744.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. [Sentence-bert:
    Sentence embeddings using siamese bert-networks](http://arxiv.org/abs/1908.10084).
    In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language
    Processing*. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sener and Savarese (2017) Ozan Sener and Silvio Savarese. 2017. Active learning
    for convolutional neural networks: A core-set approach. *arXiv preprint arXiv:1708.00489*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Settles (2009) Burr Settles. 2009. Active learning literature survey.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shin et al. (2022) Seongjin Shin, Sang-Woo Lee, Hwijeen Ahn, Sungdong Kim, HyoungSeok
    Kim, Boseop Kim, Kyunghyun Cho, Gichang Lee, Woomyoung Park, Jung-Woo Ha, et al.
    2022. On the effect of pretraining corpora on in-context learning by a large-scale
    language model. *arXiv preprint arXiv:2204.13509*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation
    language models. *arXiv preprint arXiv:2302.13971*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023b) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2022) Boshi Wang, Xiang Deng, and Huan Sun. 2022. Iteratively prompt
    pre-trained language models for chain of thought. *arXiv preprint arXiv:2203.08383*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2021a) Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2021a. Finetuned Language
    Models are Zero-Shot Learners. In *International Conference on Learning Representations*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2021b) Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021b. Finetuned language
    models are zero-shot learners. *arXiv preprint arXiv:2109.01652*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. [Chain-of-Thought Prompting
    Elicits Reasoning in Large Language Models](https://doi.org/10.48550/arXiv.2201.11903).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Williams et al. (2017) Adina Williams, Nikita Nangia, and Samuel R Bowman. 2017.
    A broad-coverage challenge corpus for sentence understanding through inference.
    *arXiv preprint arXiv:1704.05426*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2023) Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong
    Yu, James Hendler, Marzyeh Ghassemi, Anind K. Dey, and Dakuo Wang. 2023. [Mental-llm:
    Leveraging large language models for mental health prediction via online text
    data](http://arxiv.org/abs/2307.14385).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023a) Bingsheng Yao, Ishan Jindal, Lucian Popa, Yannis Katsis,
    Sayan Ghosh, Lihong He, Yuxuan Lu, Shashank Srivastava, James Hendler, and Dakuo
    Wang. 2023a. Beyond labels: Empowering human with natural language explanations
    through a novel active-learning architecture. *arXiv preprint arXiv:2305.12710*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023b) Bingsheng Yao, Ishan Jindal, Lucian Popa, Yannis Katsis,
    Sayan Ghosh, Lihong He, Yuxuan Lu, Shashank Srivastava, Yunyao Li, James Hendler,
    and Dakuo Wang. 2023b. [Beyond labels: Empowering human annotators with natural
    language explanations through a novel active-learning architecture](http://arxiv.org/abs/2305.12710).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yoo et al. (2022) Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyunsoo Cho,
    Hwiyeol Jo, Sang-Woo Lee, Sang-goo Lee, and Taeuk Kim. 2022. Ground-truth labels
    matter: A deeper look into input-label demonstrations. *arXiv preprint arXiv:2205.12685*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2023) Yue Yu, Rongzhi Zhang, Ran Xu, Jieyu Zhang, Jiaming Shen,
    and Chao Zhang. 2023. [Cold-start data selection for better few-shot language
    model fine-tuning: A prompt-based uncertainty propagation approach](https://doi.org/10.18653/v1/2023.acl-long.141).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 2499–2521, Toronto, Canada. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022) Yiming Zhang, Shi Feng, and Chenhao Tan. 2022. [Active Example
    Selection for In-Context Learning](https://doi.org/10.18653/v1/2022.emnlp-main.622).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing*, pages 9134–9148, Abu Dhabi, United Arab Emirates. Association for
    Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Experiment Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All three datasets included in our work (e-SNLI, Multi-NLI, and ANLI) are of
    the same natural language inference task. Thus, we leverage the same instruction
    narrative across all the experiments: Determine whether a hypothesis is entailment,
    neutral, contradiction giving a premise..'
  prefs: []
  type: TYPE_NORMAL
- en: 'All the experiments are computed on one of two resources: 1) an NVIDIA A100
    40G graphic card or 2) an NVIDIA 3090 24G graphic card. For LLaMA-2 and Mistral-7B,
    we load both models in fp16 precision to fit them in both graphic cards and limit
    to generate a maximum of 10 tokens.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Ablation Study with Diversity-based ICS Strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ablation study is done with three settings on all three datasets on Mistral-7B.
    To constraint the computational cost for diversity sampling and simulate the real-world
    scenario of the sparsity of oracle label data, for each run, we sample the training
    data to 3000 entries and the testing data to 1000 entries.
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate the effectiveness of a diversity-based ICS strategy by performance
    gain, and the average difference in accuracy between ICS runs and the baseline
    ICL runs. This approach is applied to eliminate the performance difference caused
    by different data used for each run. We report the results in Table [1](#S4.T1
    "Table 1 ‣ 4.3 Ablation Study ‣ 4 Evaluations ‣ More Samples or More Prompt Inputs?
    Exploring Effective In-Context Sampling for LLM Few-Shot Prompt Engineering").
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Complete Evaluation Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we report the complete results of our evaluation (Section [4](#S4 "4 Evaluations
    ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling
    for LLM Few-Shot Prompt Engineering")) in Table [3](#A5.T3 "Table 3 ‣ Appendix
    E Analysis on LLaMA-2 ‣ More Samples or More Prompt Inputs? Exploring Effective
    In-Context Sampling for LLM Few-Shot Prompt Engineering") and Table [4](#A5.T4
    "Table 4 ‣ Appendix E Analysis on LLaMA-2 ‣ More Samples or More Prompt Inputs?
    Exploring Effective In-Context Sampling for LLM Few-Shot Prompt Engineering")
    for FlanT5-XL Chung et al. ([2022b](#bib.bib7)) and Mistral-7B Jiang et al. ([2023](#bib.bib8)),
    correspondingly. We acquire an average prediction accuracy score over $10$ data
    as the testing split in each trial for the evaluation due to computing resource
    limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Results Diagrams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Additionally, we plot the LLM’s prediction accuracy and the standard deviation
    across $10$ are the best-performing parameters that maximize the performance improvement
    and minimize the standard deviations.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Analysis on LLaMA-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| LLaMA-2 | Inst. 1 | Inst. 2 | Inst. 3 | Ground-truth |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| entailment | 75 | 202 | 191 | 334 |'
  prefs: []
  type: TYPE_TB
- en: '| neutral | 808 | 668 | 712 | 333 |'
  prefs: []
  type: TYPE_TB
- en: '| contradiction | 117 | 130 | 97 | 333 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Analysis of LLaMA-2 performance on ANLI.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We conducted an initial inference experiment with LLaMA-2 Touvron et al. ([2023b](#bib.bib20))
    on ANLI utilizing three different natural language instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: i
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine whether a hypothesis is entailment, neutral, contradiction giving
    a premise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ii
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Classifying a pair of premise and hypothesis sentences into three classes:
    entailment, neutral, contradiction'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: iii
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predict the relationship between the premise and hypothesis by entailment, neutral,
    contradiction
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The results are reported in Table [2](#A5.T2 "Table 2 ‣ Appendix E Analysis
    on LLaMA-2 ‣ More Samples or More Prompt Inputs? Exploring Effective In-Context
    Sampling for LLM Few-Shot Prompt Engineering"). We can easily observe that LLaMA-2
    tends to overly predict “neutral” over the other two categories despite changing
    instruction narratives, whereas the ground-truth distribution is even across categories.
    Thus, we omit LLaMA-2 in our work. There could be different reasons contributing
    to this issue; for example, LLaMA-2 was overfitted to the NLI task or similar
    tasks that share the same set of targeting categories: “entailment”, “neutral”,
    and “contradiction”.'
  prefs: []
  type: TYPE_NORMAL
- en: '| FlanT5-XL | k=3 | k=5 | k=10 | k=20 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $n=50$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=100$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=250$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=500$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: (a) e-SNLI
  prefs: []
  type: TYPE_NORMAL
- en: '| FlanT5-XL | k=3 | k=5 | k=10 | k=20 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $n=50$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=100$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=250$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=500$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: (b) Multi-NLI
  prefs: []
  type: TYPE_NORMAL
- en: '| FlanT5-XL | k=3 | k=5 | k=10 | k=20 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $n=50$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=100$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=250$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=500$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: (c) ANLI
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Evaluation result for FlanT5-XL.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mistral-7B | k=3 | k=5 | k=10 | k=20 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $n=50$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=100$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=250$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=500$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: (a) e-SNLI
  prefs: []
  type: TYPE_NORMAL
- en: '| Mistral-7B | k=3 | k=5 | k=10 | k=20 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $n=50$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=100$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=250$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=500$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: (b) Multi-NLI
  prefs: []
  type: TYPE_NORMAL
- en: '| Mistral-7B | k=3 | k=5 | k=10 | k=20 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $n=50$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=100$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=250$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $n=500$ |'
  prefs: []
  type: TYPE_TB
- en: '| $ICS_{our}$ |'
  prefs: []
  type: TYPE_TB
- en: (c) ANLI
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Our evaluation result for Mistral-7B.'
  prefs: []
  type: TYPE_NORMAL
- en: '[n=50] [n=100] [n=250] [n=500] Figure 3: Evaluation results with FlanT5-XL
    and Mistral on e-SNLI Camburu et al. ([2018](#bib.bib4)) dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '[n=50] [n=100] [n=250] [n=500] Figure 4: Evaluation results with FlanT5-XL
    and Mistral on Multi-nli Williams et al. ([2017](#bib.bib25)) dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '[n=50] [n=100] [n=250] [n=500] Figure 5: Evaluation results with FlanT5-XL
    and Mistral on ANLI Nie et al. ([2019](#bib.bib13)) dataset.'
  prefs: []
  type: TYPE_NORMAL
