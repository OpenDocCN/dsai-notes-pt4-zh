- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:44:35'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2404.12957](https://ar5iv.labs.arxiv.org/html/2404.12957)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Qinyuan Wu¹, Mohammad Aflah Khan¹, Soumi Das¹, Vedant Nanda^(1,2),
  prefs: []
  type: TYPE_NORMAL
- en: Bishwamittra Ghosh¹, Camila Kolling¹, Till Speicher¹, Laurent Bindschaedler
    ¹,
  prefs: []
  type: TYPE_NORMAL
- en: Krishna P. Gummadi¹, Evimaria Terzi³,
  prefs: []
  type: TYPE_NORMAL
- en: ¹Max Planck Institute for Software Systems(MPI-SWS), ²University of Maryland,
    College Park,
  prefs: []
  type: TYPE_NORMAL
- en: ³Boston University, Boston University,
  prefs: []
  type: TYPE_NORMAL
- en: 'Correspondence: [qwu@mpi-sws.org](qwu@mpi-sws.org)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We propose an approach for estimating the latent knowledge embedded inside large
    language models (LLMs). We leverage the in-context learning (ICL) abilities of
    LLMs to estimate the extent to which an LLM knows the facts stored in a knowledge
    base. Our knowledge estimator avoids reliability concerns with previous prompting-based
    methods, is both conceptually simpler and easier to apply, and we demonstrate
    that it can surface more of the latent knowledge embedded in LLMs. We also investigate
    how different design choices affect the performance of ICL-based knowledge estimation.
    Using the proposed estimator, we perform a large-scale evaluation of the factual
    knowledge of a variety of open source LLMs, like OPT, Pythia, Llama(2), Mistral,
    Gemma, etc. over a large set of relations and facts from the Wikidata knowledge
    base. We observe differences in the factual knowledge between different model
    families and models of different sizes, that some relations are consistently better
    known than others but that models differ in the precise facts they know, and differences
    in the knowledge of base models and their finetuned counterparts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Towards Reliable Latent Knowledge Estimation in LLMs:'
  prefs: []
  type: TYPE_NORMAL
- en: In-Context Learning vs. Prompting Based Factual Knowledge Extraction
  prefs: []
  type: TYPE_NORMAL
- en: 'Qinyuan Wu¹, Mohammad Aflah Khan¹, Soumi Das¹, Vedant Nanda^(1,2), Bishwamittra
    Ghosh¹, Camila Kolling¹, Till Speicher¹, Laurent Bindschaedler ¹, Krishna P. Gummadi¹,
    Evimaria Terzi³, ¹Max Planck Institute for Software Systems(MPI-SWS), ²University
    of Maryland, College Park, ³Boston University, Boston University, Correspondence:
    [qwu@mpi-sws.org](qwu@mpi-sws.org)'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conversational chatbots (e.g., OpenAI’s ChatGPT) built around large language
    models (e.g., OpenAI’s GPT) are increasingly being used for a variety of information
    retrieval tasks such as searching for information or seeking recommendations related
    to real world entities like people or places (Wu et al., [2023](#bib.bib29); Zhu
    et al., [2023](#bib.bib36)). A worrisome concern in such scenarios is the factual
    correctness of information generated by the LLMs (Peng et al., [2023](#bib.bib20);
    Hu et al., [2023a](#bib.bib10); Snyder et al., [2023](#bib.bib23); Yao et al.,
    [2023](#bib.bib30); Ji et al., [2023](#bib.bib12); Zhang et al., [2023](#bib.bib34);
    Wang et al., [2023](#bib.bib27)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The latent knowledge estimation problem: To avoid making false assertions about
    a real-world entity, an LLM first needs to have factual (true) knowledge about
    the entity. Given a prompt like “Einstein was born in the year”, LLMs may generate
    both the correct answer (“1879”) and wrong answers (e.g., “1878” or “1880”) with
    some probabilities. If an LLM knows the fact, one can hope that the probability
    with which it would generate the correct answer would be much higher than the
    wrong answers Jiang et al. ([2021](#bib.bib13)). As LLMs are typically pretrained
    over a Web corpus (including Wikipedia data) with millions of facts about real-world
    entities, they have the opportunity to learn factual knowledge about our world
    and latently embed the knowledge in their parameters. But, how can we estimate
    the extent to which LLMs have knowledge of real-world facts?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Reliability of latent knowledge estimates: Prior works Jiang et al. ([2020](#bib.bib14));
    Bouraoui et al. ([2020](#bib.bib3)) followed Petroni et al. ([2019](#bib.bib21)),
    and represented factual knowledge in the form of triplets $\langle x,r,y\rangle$
    and analyzing the responses. Current approaches have few well-defined rules to
    avoid prompt engineering and prompt hacking, raising serious concerns about the
    reliability of their estimates. Against this background, in this paper, we make
    four primary contributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '1. A simple yet reliable latent knowledge estimator (LKE) leveraging in-context
    learning (ICL): We propose a latent knowledge estimator (LKE) that leverages in-context
    learning (ICL), called IC-LKE, in a simple yet clever way to avoid the many reliability
    concerns with prompting based previous knowledge estimators.'
  prefs: []
  type: TYPE_NORMAL
- en: '2. Exploring the nuances of using ICL for knowledge estimation: We investigate
    the impact of different ICL design choices on the estimation of latent knowledge,
    such as the number of in-context examples, when some of the examples are unknown
    to the model or simply incorrect, as well as the sequence in which they appear.
    While we focus on knowledge estimation, our findings can inform the application
    of ICL in other contexts.'
  prefs: []
  type: TYPE_NORMAL
- en: '3. A comparison of IC-LKE with previous approaches: We empirically demonstrate
    that IC-LKE outperforms previous knowledge estimation approaches that rely on
    human-generated or machine-mined prompts across a variety of different open-source
    models and different types of factual relations. In contrast to prompting based
    methods, which are relation-specific and LLM-specific, IC-LKE’s design is straightforward
    to apply.'
  prefs: []
  type: TYPE_NORMAL
- en: '4. A systematic comparison of latent knowledge of open source LLMs at scale:
    We use IC-LKE to evaluate the knowledge of 49 open-source LLMs spanning many families
    such as Llama(2), Gemma, Mistral, OPT, Pythia, etc. across a wide range of sizes,
    both with and without instruction-finetuning over 50 different relations and 20,000
    facts from Wikidata. We find that models from some families such as Llama2, Mistral
    and Gemma and larger models know more facts than others, that models within the
    same family differ in the specific facts they know, despite being trained on the
    same data, and that fine-tuning reduces the amount of factual knowledge that can
    be extracted from the models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Related Work:'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Researchers have proposed several approaches to estimate latent knowledge from
    LLMs, which can be categorized into two ways: (i) Model-internals based approaches
    leverage the LLM attention map Wang et al. ([2020](#bib.bib26)), activation function Burns
    et al. ([2022](#bib.bib5)), or model parameters Kazemnejad et al. ([2023](#bib.bib15))
    to decide whether factual information can be extracted from the LLM. In our study,
    we rely on the probability distribution of generated tokens in an LLM – thereby
    our method belongs to the model-responses based approach. (ii) Model-responses
    based approaches – generally applicable to a wide range of LLM models – often
    propose different prompting techniques to nudge the LLM to validate whether a
    target fact is stored in it Chern et al. ([2023](#bib.bib6)); Sun et al. ([2023](#bib.bib24));
    Wang et al. ([2020](#bib.bib26)); Petroni et al. ([2019](#bib.bib21)); Jiang et al.
    ([2021](#bib.bib13)); Newman et al. ([2022](#bib.bib18)); Jiang et al. ([2020](#bib.bib14)).
    Prompt-based methods differ subtly by the choice of prompts and evaluation criteria.
    Besides, the prompts are often brittle Zamfirescu-Pereira et al. ([2023](#bib.bib32));
    Arora et al. ([2023](#bib.bib1)); Sclar et al. ([2023](#bib.bib22)) – their success
    depends on the hypothesis that the LLM indeed understands the prompts. In our
    study, we instead seek a minimal understanding of prompts by an LLM and design
    a knowledge estimation method based on the in-context learning. As a test bed Elsahar
    et al. ([2018](#bib.bib7)); Hu et al. ([2023b](#bib.bib11)); Sun et al. ([2023](#bib.bib24));
    Petroni et al. ([2019](#bib.bib21)); Zhu and Li ([2023](#bib.bib37)); Kryściński
    et al. ([2019](#bib.bib16)), we consider facts from existing knowledge graphs
    for performing knowledge estimation of LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Designing Reliable LKEs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Today, there exist many general-purpose as well as domain-specific factual knowledge
    bases that contain a very large number (millions to billions) of facts. The facts
    can be encapsulated as triplets, represented as $\langle$. These triplets offer
    a general way to represent factual knowledge about real-world entities in knowledge
    graphs or other structured knowledge bases. The goal of latent knowledge estimation
    is to infer what fraction of the facts are known to a LLM. We call methods that
    estimate the amount of latent knowledge inside an LLM latent knowledge estimators
    (LKEs).
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Reliability concerns with existing LKEs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Existing approaches to estimating latent knowledge in LLMs use a variety of
    factual knowledge tests. Below, we identify several reliability concerns with
    current designs that motivate our new LKE design.
  prefs: []
  type: TYPE_NORMAL
- en: '1. LLM-specific restrictions on test topics: Many prior works Petroni et al.
    ([2019](#bib.bib21)); Jiang et al. ([2020](#bib.bib14)) limit the choice of facts
    that can be used in tests to those where the surface form of the objects ($y$)
    is represented by a single token by the LLM’s tokenizer. As different LLMs use
    different tokenizers, this limitation prevents us from comparing the latent knowledge
    across different LLMs. Furthermore, only popular objects tend to be represented
    by a single token and so the resulting estimates are not representative of the
    LLM’s knowledge of facts with multi-token object representations.'
  prefs: []
  type: TYPE_NORMAL
- en: '2. Unrestricted choice of test prompts: Many past works have attempted to use
    test prompts without any restrictions, including both human-generated or machine-mined
    prompts  (Jiang et al., [2020](#bib.bib14); Zamfirescu-Pereira et al., [2023](#bib.bib32);
    Arora et al., [2023](#bib.bib1); Sclar et al., [2023](#bib.bib22)). They typically
    intersperse the subject $x$". But, note that the second prompt potentially introduces
    a side-channel: it implicitly rules out answer choices for unelected positions
    like Professor and favors elected positions like President. Second, selecting
    from an unbounded number of potential prompt choices raises concerns about the
    complexity of LKEs (the size of the set of all considered prompts) and the potential
    for over-fitting, which in turn brings the reliability of estimates into question.'
  prefs: []
  type: TYPE_NORMAL
- en: '3. Reliance on LLMs’ meta-linguistic judgments: Prior works used prompts Chern
    et al. ([2023](#bib.bib6)); Sun et al. ([2023](#bib.bib24)); Wang et al. ([2020](#bib.bib26));
    Petroni et al. ([2019](#bib.bib21)); Jiang et al. ([2021](#bib.bib13)); Newman
    et al. ([2022](#bib.bib18)); Jiang et al. ([2020](#bib.bib14)) for communicating
    the question as well as the expected format of answers. But, the scores (estimates)
    resulting from such prompt-based testing conflate an LLM’s latent knowledge of
    the facts with the LLM’s meta-linguistic judgments, i.e., the LLM’s ability to
    comprehend the prompt, understand the question embedded within the prompt and
    output the answer in some expected format (Hu and Levy, [2023](#bib.bib9)). The
    impact on meta-linguistic judgments can be seen from the fact that multiple semantically-equivalent
    prompts result in different responses from an LLM and thereby, different estimates
    of latent knowledge (Hu and Levy, [2023](#bib.bib9)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Motivated from the above, we derive the following three design principles for
    LKEs. A reliable LKE design should:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DP1: generate estimates for any factual topic and tokenization scheme.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DP2: limit arbitrary prompt engineering to minimize over-fitting & side-channels.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DP3: minimize reliance on meta-linguistic prompts.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2.2 A new In Context learning based LKE (IC-LKE)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our goal is to estimate whether an LLM knows a fact $f=\langle x,r,y\rangle$.
    The challenge is to probe the LLM and evaluate its responses in a way compatible
    with the design principles set in Section [2.1](#S2.SS1 "2.1 Reliability concerns
    with existing LKEs ‣ 2 Designing Reliable LKEs ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Key idea: Leverage in-context learning. LLMs have shown to exhibit In-Context
    Learning (ICL) abilities (Brown et al., [2020](#bib.bib4)) that allow them to
    infer and extrapolate patterns in their inputs. We leverage this ability to communicate
    information about relation $r$.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 1.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Assume that we want to probe for whether an LLM knows the fact $\langle$ to
    construct an input “Feynman 1918 Heisenberg 1901 Einstein”. By providing in-context
    examples to the model, we communicate the relation between subjects and objects.
    To correctly extrapolate the pattern, the model needs to retrieve Einstein’s birth-year
    as the completion of the sequence.
  prefs: []
  type: TYPE_NORMAL
- en: More formally, given a training dataset of facts $\mathcal{F}_{r}=\{\langle
    x_{i},r,y_{i}\rangle\}_{i=1}^{n}$ as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\sigma(x,r)=x_{1}\,y_{1}\,\dots\,x_{n}\,y_{n}\,x$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: We use $r$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluating model outputs. We evaluate the output of model $\theta$ consisting
    of multiple tokens and to be independent of the specific tokenization scheme (DP1),
    we compute the object probability over multiple tokens as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: where $|y|$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple-choice testing. To determine whether model $\theta$ in Section [4](#S4
    "4 Experiments and Results ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\operatorname{pred}_{\theta}(c)\triangleq\underset{y\,\in\,\{y^{*}\}\,\cup\,\mathcal{Y}}{\mathrm{argmax}}\,P_{\theta}(y\mid\sigma(x,r))$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: denotes the prediction of $\theta$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation Metric. We evaluate the factual knowledge of model $\theta$ using
    multiple choice accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\operatorname{acc}(\theta,\mathcal{D})\triangleq\frac{\sum_{c\in\mathcal{D}}\delta\left(y^{*}=\operatorname{pred}_{\theta}(c)\right)}{&#124;\mathcal{D}&#124;}\end{split}$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $\delta(\cdot)$ is the indicator function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The IC-LKE design satisfies the knowledge estimation design principles. The
    IC-LKE design proposed here satisfies the design principles from Section [2.1](#S2.SS1
    "2.1 Reliability concerns with existing LKEs ‣ 2 Designing Reliable LKEs ‣ Towards
    Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting
    Based Factual Knowledge Extraction"), since'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DP1: its relative probability comparisons between different answer-options
    make it applicable to arbitrary types of facts.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DP2: it uses the same, minimal prompt design based on ICL across all relations.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DP3: its only requirement is that the LLM is able to use ICL, no further assumptions
    about any metalinguistic abilities are made.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3 Exploring the design space of IC-LKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/178cc95c8bfa75e2ad3a74644808c8f6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: [Influence of the number of in-context examples] We examine how varying
    numbers of in-context examples influence the accuracy (calculated as defined in
    Eq [5](#A4.E5 "In Appendix D Different Metrics ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction")) across different LLMs. The vertical dashed line indicates the number
    of examples at which the models achieve 95% of their respective stable accuracy
    at $50$ examples.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8d05d9803d4f832bea4c69e28516bfff.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) (Subject, object)
  prefs: []
  type: TYPE_NORMAL
- en: examples in a prompt
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d4c5fdcb02dee4b5d94b58c12c8100e3.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Distributed
  prefs: []
  type: TYPE_NORMAL
- en: unknown examples
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2278773b2043fe180336784f145b8c1f.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Continuous
  prefs: []
  type: TYPE_NORMAL
- en: unknown examples
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4fe5adda12868d7d0711f9651f9a4014.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Distributed
  prefs: []
  type: TYPE_NORMAL
- en: incorrect examples
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e21f42126142fb5d7e1c8366b887f5ce.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Continuous
  prefs: []
  type: TYPE_NORMAL
- en: incorrect examples
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: [Variation in object probabilities of Nobel laureate data using Mistral-7B]
    Figure [2a](#S3.F2.sf1 "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣
    Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction") illustrates the probability of
    each object at various positions in the prompt. We show the impact on probabilities
    after replacing objects with unknown ones at randomly distributed positions in
    Figure [2b](#S3.F2.sf2 "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣
    Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction") and at continuous positions in
    Figure [2d](#S3.F2.sf4 "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣
    Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction"). Similarly, we also show the impact
    of incorrect examples when replaced at randomly distributed positions (Figure [2d](#S3.F2.sf4
    "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣ Towards Reliable Latent
    Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction")) and continuous positions (Figure [2e](#S3.F2.sf5 "In Figure
    2 ‣ 3 Exploring the design space of IC-LKE ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction")). In all plots, the horizontal dashed line shows the average probability
    of the correct examples (blue dots).'
  prefs: []
  type: TYPE_NORMAL
- en: By design, IC-LKE avoids many limitations of prior works. However, IC-LKE introduces
    a few design choices for the input, i.e., $\sigma(x,r)$.
  prefs: []
  type: TYPE_NORMAL
- en: 'More knowledgeable models need fewer in-context examples, but a small number
    suffices for most models. In Figure [1](#S3.F1 "Figure 1 ‣ 3 Exploring the design
    space of IC-LKE ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction"), we report knowledge
    estimation accuracy (Eq. ([5](#A4.E5 "In Appendix D Different Metrics ‣ Towards
    Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting
    Based Factual Knowledge Extraction"))) for different LLMs evaluated on 900 test
    samples, with varying numbers of in-context examples ($n$ pairs in the input to
    understand which of these samples are known by the LLM. The Mistral-7B model demonstrates
    a gradual increase in probability for generating correct objects as we go from
    left to right on the x-axis (note that for a point on the x-axis, points before
    it are in context, thus points on the right have more context to leverage) in
    Figure [2a](#S3.F2.sf1 "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣
    Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction"), stabilizing at a mean probability
    of approximately 85%. We also see that some objects at later positions have a
    lower generation probability. This suggests that the LLM may be less confident
    about its knowledge of the facts corresponding to them. We can leverage the token
    generation probability as a signal of LLM’s confidence when evaluating LKEs (see
    Appendix [D](#A4 "Appendix D Different Metrics ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Models are robust to unknown examples. Next, we investigate the robustness
    of estimates to occurrence of unknown examples. We insert unknown examples in
    two distinct ways: one where we randomly distribute the occurrence of unknown
    examples throughout $\sigma(x,r)$ examples and replaced them with unknown examples
    created using fictitious names and birth years ¹¹1generated via [https://en.namefake.com/api](https://en.namefake.com/api).
    Our findings are shown in Figures [2b](#S3.F2.sf2 "In Figure 2 ‣ 3 Exploring the
    design space of IC-LKE ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction") and [2c](#S3.F2.sf3
    "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣ Towards Reliable Latent
    Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction") for random and continuous replacement respectively. Unknown
    examples are marked by red dots, examples immediately following unknown ones in
    cyan dots and the rest in blue dots. The unknown examples show generation probabilities
    close to zero, confirming the LLM’s tendency to assign low probabilities to unknown
    data. However, interestingly, unknown examples minimally impact surrounding data
    in both settings.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Models are vulnerable to incorrect examples. We investigate the impact of including
    incorrect examples in $\sigma(x,r)$. Similar to the setup for unknown examples,
    we also insert 40 (out of 200) incorrect examples randomly (Figure [2d](#S3.F2.sf4
    "In Figure 2 ‣ 3 Exploring the design space of IC-LKE ‣ Towards Reliable Latent
    Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction")) and simultaneously (Figure [2e](#S3.F2.sf5 "In Figure
    2 ‣ 3 Exploring the design space of IC-LKE ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction")). In our experiments, these incorrect examples are created by altering
    the birth years of known Nobel laureates and are marked by red dots in the plots.
    In contrast to inserting unknown examples, the LLM significantly struggles with
    incorrect examples. Injection of such examples detrimentally affects the LLM’s
    performance in both settings. We highlight one randomly marked yellow star example
    in Figure [2a](#S3.F2.sf1 "In Figure 2 ‣ 3 Exploring the design space of IC-LKE
    ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction"), Figure [2b](#S3.F2.sf2 "In Figure
    2 ‣ 3 Exploring the design space of IC-LKE ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction"), and Figure [2d](#S3.F2.sf4 "In Figure 2 ‣ 3 Exploring the design
    space of IC-LKE ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction") to show how the presence
    of incorrect samples brings down the probability of surrounding points.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary: LLMs can identify the relation pattern of subject-object pairs even
    with a small set of in-context examples in the prompt. LLMs are relatively robust
    to unknown examples, but their ability to recollect factual knowledge is vulnerable
    to incorrect examples, particularly when they appear in a continuous sequence.
    Our findings allude to the effectiveness of designing an IC-LKE, where we carefully
    place correct examples from a training dataset and proceed to estimate the latent
    knowledge of the LLM on examples from the test set. Furthermore, the findings
    also motivate us to design a more efficient in-context learning based LKE, called
    EIC-LKE, that can process multiple test examples simultaneously in a single prompt
    where training examples are placed preceding each test example, see more details
    in the Appendix [F](#A6 "Appendix F Efficient In Context learning based LKE (EIC-LKE)
    ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiments and Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We present the empirical findings of IC-LKE (as well as the efficient version,
    EIC-LKE) on the knowledge-estimation task on 49 open-source (pre-trained and fine-tuned)
    LLMs across different LLM families and sizes. We enlist models and their simplified
    names used in this paper in Appendix [6](#A8.T6 "Table 6 ‣ H.1 Model Name Simplification
    ‣ Appendix H Additional results ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction"),
    Table [6](#A8.T6 "Table 6 ‣ H.1 Model Name Simplification ‣ Appendix H Additional
    results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning
    vs. Prompting Based Factual Knowledge Extraction"), and provide a leader-board
    of models based on IC-LKE in Table LABEL:table:model_order.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dataset: We evaluate the knowledge of models on a large set of facts from the
    T-REx dataset²²2[https://huggingface.co/datasets/relbert/t_rex](https://huggingface.co/datasets/relbert/t_rex) Elsahar
    et al. ([2018](#bib.bib7)). We selected relations from T-REx with at least 500
    samples and linked to a minimum of 100 unique objects. This filtering leads to
    50 distinct relations spanning categories like birth dates, directorial roles,
    parental relationships, and educational lineage. The resulting T-REx Multiple
    Choice (T-REx-MC) dataset comprises 5,000 training and 20,000 test facts. Appendix [A](#A1
    "Appendix A Dataset ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction") contains detailed
    information on the dataset and relations.'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the set $\mathcal{Y}$ probability of being correct.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 IC-LKE vs. prompt-based approaches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7491dc64cb71aa7897c7597c2d8124ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: [Performance comparison for different latent knowledge extractors]
    We compare the accuracy of IC-LKE and EIC-LKE with the baseline method (Jiang
    et al., [2020](#bib.bib14)) across 12 relations from T-REx-MC.'
  prefs: []
  type: TYPE_NORMAL
- en: We compare the performance of IC-LKE and EIC-LKE with the existing prompt-based
    approaches  (Jiang et al., [2020](#bib.bib14)) and report two key takeaways.
  prefs: []
  type: TYPE_NORMAL
- en: 'IC-LKE outperforms prompt-based approaches. We randomly sample three human-generated
    prompts (HGP) and machine-mined prompts (MMP) from (Jiang et al., [2020](#bib.bib14))
    for 12 common relations between T-REx-MC and (Jiang et al., [2020](#bib.bib14)).
    The HGPs and MMPs for all relations are in Appendix [G](#A7 "Appendix G Details
    about the human-generated prompts and machine-mined prompts ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"). In Figure [3](#S4.F3 "Figure 3 ‣ 4.1 IC-LKE vs. prompt-based
    approaches ‣ 4 Experiments and Results ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction"),
    IC-LKE and EIC-LKE outperform HGP and MMP in terms of higher mean accuracy across
    different models and 12 relations. Also, IC-LKE and EIC-LKE have lower standard
    deviation than HGP and MMP, indicating a higher consistency of IC-LKE and EIC-LKE
    on knowledge estimation tasks. In Appendix [H.2](#A8.SS2 "H.2 Additional results
    on baseline comparison ‣ Appendix H Additional results ‣ Towards Reliable Latent
    Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), we report relation specific results, where IC-LKE and
    EIC-LKE estimate higher factual knowledge than the existing works in most relations,
    thereby demonstrating the superiority of IC-LKE and EIC-LKE over existing methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/86e75de47deb19eaa91c9f65748a1c80.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: [Influence of different separators] We replace the ‘[space]’ token
    separating the subject-object pairs with human-generated prompts (HGP, red background)
    and machine-mined prompts (MMP, blue background) for the relation ‘original broadcaster’.
    Accuracy performance is agnostic to the separators.'
  prefs: []
  type: TYPE_NORMAL
- en: 'IC-LKE is a flexible and effective knowledge estimator. We adapt IC-LKE by
    replacing the separator ‘[space]’ with three separators from HGP and MMP each
    for the relation ‘original broadcaster’ and report estimation accuracy in Figure
    [4](#S4.F4 "Figure 4 ‣ 4.1 IC-LKE vs. prompt-based approaches ‣ 4 Experiments
    and Results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction"). We can observe that
    ‘[space]’ token demonstrates an equivalent performance with semantically meaningful
    prompts via HGP and MMP. Therefore, adding relation specific separators has a
    limited impact on factual knowledge estimation, as long as the subject-object
    pairs are correctly presented. Furthermore, finding relation-specifc prompts often
    require hand-crafted efforts vs. an automatic in-context based approach like ours
    where (subject, object) pairs are used. Therefore, IC-LKE can potentially extend
    to any facts from knowledge graphs over any LLM while HGP and MMP requires additional
    supervision and relation-specific validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Evaluating Diverse Models and Relations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We investigate the performance of 35 pre-trained LLMs and 14 fine-tuned LLMs
    across 50 relations using the IC-LKE framework. Our analysis is designed to uncover
    nuanced insights into the knowledge levels and structures within these models.
    We will examine the results through two primary lenses: (1) the variations in
    knowledge across different model families, and (2) the influence of model size
    and fine-tuning within the same model family on their knowledge attributes.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Comparing different LLMs families
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9ef31dbd3b089e9d96e66d398cc7513a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: [Accuracy for 35 pre-trained LLMs on the 50 different relations in
    T-REx-MC] Models are grouped by family and arranged from left to right based on
    the accuracy of the model closest to 7 billion parameters. Within each family,
    models are ordered by their average accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some model families are consistently more knowledgeable than the rest. We sort
    the model families based on the performance of the model closest to 7B parameters ³³37B
    parameters is a good reference point since all model families except GPT-NEO-X
    have models within a gap of $\leq$ 1B parameters: Mistral-7B, Gemma-7B, Llama-7B,
    Falcon-7B, MPT-7B, OPT-6.7B, GPT-J-6B, Pythia-6.9B, and Bloom-7.1B., and the models
    within each family based on average accuracy across 50 relations. Figure [5](#S4.F5
    "Figure 5 ‣ 4.2.1 Comparing different LLMs families ‣ 4.2 Evaluating Diverse Models
    and Relations ‣ 4 Experiments and Results ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction") shows that the Mistral, Llama2, Gemma, and Llama families have higher
    performance on most of the relations than Pythia, Bloom, and OPT, indicating their
    lower factual knowledge.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/33b8c64e3de69d4479c023fef5f2cbe7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: [Pearson correlation coefficients between model families] We compute
    the Pearson correlation coefficients between each pair of models and then compute
    the average correlation across the same model family.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Different model families align in their relative factual knowledge. We investigate
    the correlations between each model pair’s performance over 50 relations to assess
    the agreement in their knowledge levels of the 50 relations. We compute the average
    correlations within each model family (e.g. Llama2 7B, 13B, 70B) in Figure [6](#S4.F6
    "Figure 6 ‣ 4.2.1 Comparing different LLMs families ‣ 4.2 Evaluating Diverse Models
    and Relations ‣ 4 Experiments and Results ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction"). Despite differences in architecture and training datasets among
    model families, there is a significant consensus (correlation > 0.6, see Figure [14](#A8.F14
    "Figure 14 ‣ H.5 Relation accuracy correlation of all the pre-trained models ‣
    Appendix H Additional results ‣ Towards Reliable Latent Knowledge Estimation in
    LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction"))
    regarding the hierarchy of knowledge across various relations. We also compile
    the three best and worst-performing relations for each model in Table [9](#A8.T9
    "Table 9 ‣ H.5 Relation accuracy correlation of all the pre-trained models ‣ Appendix
    H Additional results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction"), illustrating the
    consensus among all models.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Comparing within the same LLM family
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Larger models embed more knowledge. We show in Figure [5](#S4.F5 "Figure 5
    ‣ 4.2.1 Comparing different LLMs families ‣ 4.2 Evaluating Diverse Models and
    Relations ‣ 4 Experiments and Results ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction")
    that, within each model family, bigger models (e.g. Llama-65B) generally outperform
    their smaller counterparts (e.g. Llama-13B) in terms of accuracy with an exception
    in the OPT family. Models within the same family are typically pre-trained on
    the same datasets (Biderman et al., [2023](#bib.bib2); Zhang et al., [2022](#bib.bib33);
    Touvron et al., [2023](#bib.bib25)). Thus, this observation suggests that, when
    trained on identical datasets, the larger models capture a broader set of facts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite being trained on the same data, models might remember different facts.
    From these results, however, it is not clear if the larger models are subsuming
    smaller models in their factual knowledge, i.e., are the larger models also correct
    on the facts that the smaller models are correct on? To assess this, we compute
    the *subsumption rate* $\eta$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\eta(\theta_{1}&#124;\theta_{2},\mathcal{F})=\frac{&#124;\phi(\theta_{1},\mathcal{F})\cap\phi(\theta_{2},\mathcal{F})&#124;}{&#124;\phi(\theta_{1},\mathcal{F})&#124;}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: i.e., the fraction of facts from $\mathcal{F}$ 1 indicates that all of the smaller
    model’s knowledge is also contained in the larger model. To ensure a meaningful
    comparison across scales, we only consider models that were pre-trained using
    the same training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Average subsumption rate ($\eta$).'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Smallest Model | Largest Model |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Family | #Parameters | Accuracy | #Parameters | Accuracy | $\eta$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama | 7B | 0.699 | 65B | 0.836 | 0.769 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2 | 7B | 0.741 | 70B | 0.846 | 0.801 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma | 2B | 0.666 | 7B | 0.750 | 0.710 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT | 125m | 0.430 | 30B | 0.588 | 0.481 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia | 70m | 0.334 | 12B | 0.648 | 0.403 |'
  prefs: []
  type: TYPE_TB
- en: '| Bloom | 560m | 0.410 | 7.1B | 0.548 | 0.498 |'
  prefs: []
  type: TYPE_TB
- en: 'Table [1](#S4.T1 "Table 1 ‣ 4.2.2 Comparing within the same LLM family ‣ 4.2
    Evaluating Diverse Models and Relations ‣ 4 Experiments and Results ‣ Towards
    Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting
    Based Factual Knowledge Extraction") shows the average subsumption rate ($\eta$
    is relatively low (< 0.5) for OPT, Pythia and Bloom (i.e., the larger models know
    less than 50% of what the smaller models know) and only reaching up to 0.8 for
    Gemma, Llama and Llama-2\. Therefore, even though models within each family are
    trained on the same datasets and generally agree on the relative knowledge of
    different relations (Figure [6](#S4.F6 "Figure 6 ‣ 4.2.1 Comparing different LLMs
    families ‣ 4.2 Evaluating Diverse Models and Relations ‣ 4 Experiments and Results
    ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction")), there are differences in the
    knowledge of specific facts they retain from their training data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6646d37855b90b1305b0ec1370688df5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: [Accuracy of base vs chat-finetuned models] We see that finetuned
    versions (in lighter shades) obtain lower accuracy across the relations in T-REx-MC than
    pre-trained models (in darker shades).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fine-tuning reduces latent knowledge. Finally, we investigate the effects of
    chat-based fine-tuning on the factual knowledge of models. Base language models
    are often fine-tuned (using a mix of supervised and reinforcement learning Ouyang
    et al. ([2022](#bib.bib19))) to make them better at following instructions. While
    prior works have shown that this makes the models better at various benchmarks,
    it’s unclear how such fine-tuning affects latent knowledge. Figure [7](#S4.F7
    "Figure 7 ‣ 4.2.2 Comparing within the same LLM family ‣ 4.2 Evaluating Diverse
    Models and Relations ‣ 4 Experiments and Results ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction") illustrates the comparative accuracy of pre-trained models and their
    fine-tuned counterparts. In almost all cases, the fine-tuned models obtain lower
    accuracy than their base versions. This suggests that fine-tuning reduces the
    amount of extractable latent knowledge in the models. A similar observation was
    also made by Yu et al. ([2024](#bib.bib31)). We observe a similar trend using
    EIC-LKE in Appendix [H.6](#A8.SS6 "H.6 Impact of finetuning ‣ Appendix H Additional
    results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning
    vs. Prompting Based Factual Knowledge Extraction"), Figure [15](#A8.F15 "Figure
    15 ‣ H.6 Impact of finetuning ‣ Appendix H Additional results ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"). Additional results on evaluating generated outputs (using
    50 tokens) in Figure [16](#A8.F16 "Figure 16 ‣ H.7 Evaluation of Generated Output
    ‣ Appendix H Additional results ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction")
    reveal the same pattern. To further assess if the fine-tuned models are acquiring
    new knowledge, we compute the subsumption rate between pre-trained and fine-tuned
    versions (Table [10](#A8.T10 "Table 10 ‣ H.6 Impact of finetuning ‣ Appendix H
    Additional results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction")). We find that most
    of the latent knowledge in fine-tuned models is already present in base models
    (high $\eta$), thus indicating, that fine-tuned models may not be obtaining additional
    knowledge.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Concluding Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this work, we investigate a new way to estimate latent factual knowledge
    from an LLM. Unlike prior approaches that use prompting, our method relies on
    in-context learning. Our method not only addresses many reliability concerns with
    prompting, but it also recollects (at time significantly) more factual knowledge
    than prompting. In contrast to prompting, which requires relationship-specific
    and LLM-specific prompt engineering, our method can be applied with minimal effort
    to test factual knowledge of relations across a variety of structured knowledge
    bases and LLMs. This ability enables us to compare the latent knowledge captured
    by many different families of open-source LLMs; we expect our results to be of
    interest to designers of these LLMs. Finally, to design our in-context learning
    based LKE, we explore the impact of the number and ordering of correct, incorrect,
    and unknown examples used as inputs; our findings may be of independent interest
    to developing a better understanding of in-context learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'A fundamental question posed by our and prior work on estimating latent knowledge
    in LLMs: What does it mean for an LLM to know a fact? Suppose we tried to infer
    if an LLM knows the capital of Germany using the input "France Paris; Spain Madrid;
    Germany " and suppose the answer were Berlin. What we have learnt is that the
    LLM knows that the relationship $r$ is called "capital" in English or "hauptstadt"
    in German. The latter is revealed by prompts such as "The capital of Germany is
    ". But, such prompts don’t reveal whether the LLM knows that what Berlin means
    to Germany is similar to what Paris means to France.'
  prefs: []
  type: TYPE_NORMAL
- en: Is one type of knowing facts better than other? It is difficult to answer in
    general. Neither type of knowing guarantees that the knowledge can be put to use
    in different contexts and tasks, such as when we ask the LLM where the parliament
    of Germany is located. Nevertheless, one clear takeaway from our study is related
    to how factual knowledge is latently embedded in an LLM. We show that more factual
    knowledge can be recollected using in-context learning, i.e., the representations
    of subjects and objects that share the same relationship, than by prompting with
    the name of their relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This study contributes to advancing our understanding of latent factual knowledge
    in LLMs through an innovative in-context learning approach. However, it is essential
    to acknowledge the inherent limitations of our work. While the use of in-context
    learning aims to mitigate the influence of prompt engineering and the reliability
    issues associated with previous prompting methods, it introduces its own biases
    based on the selection and formulation of in-context examples. We discus these
    in detail in Section [3](#S3 "3 Exploring the design space of IC-LKE ‣ Towards
    Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting
    Based Factual Knowledge Extraction"). For example, the choice of which examples
    to include, their order, and their factual accuracy can influence model responses,
    and thus these in-context examples must be carefully curated for reliable latent
    knowledge estimation. Additionally, our study’s limitation in testing simple-format
    facts underlines a critical gap in assessing LLMs’ complex reasoning abilities.
    The knowledge estimation framework employed predominantly hinges on the LLM’s
    capacity to correctly recall or recognize factual information from a given set
    of triplets or structured prompts. This narrows the scope of evaluation to straightforward
    factual recall, thereby overlooking the models’ capability to engage in more sophisticated
    cognitive processes such as reasoning, synthesis, and inference, which we leave
    as open avenues for future work.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Arora et al. (2023) Simran Arora, Avanika Narayan, Mayee F. Chen, Laurel J.
    Orr, Neel Guha, Kush Bhatia, Ines Chami, and Christopher Ré. 2023. [Ask me anything:
    A simple strategy for prompting language models](https://openreview.net/pdf?id=bhUPJnS2g0X).
    In *The Eleventh International Conference on Learning Representations, ICLR 2023,
    Kigali, Rwanda, May 1-5, 2023*. OpenReview.net.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Biderman et al. (2023) Stella Biderman, Hailey Schoelkopf, Quentin Gregory
    Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu
    Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: A suite for analyzing
    large language models across training and scaling. In *International Conference
    on Machine Learning*, pages 2397–2430\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bouraoui et al. (2020) Zied Bouraoui, Jose Camacho-Collados, and Steven Schockaert.
    2020. Inducing relational knowledge from bert. In *Proceedings of the AAAI Conference
    on Artificial Intelligence*, volume 34, pages 7456–7463.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Burns et al. (2022) Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt.
    2022. [Discovering Latent Knowledge in Language Models Without Supervision](https://doi.org/10.48550/arXiv.2212.03827).
    *arXiv preprint*. ArXiv:2212.03827 [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chern et al. (2023) I.-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua
    Feng, Chunting Zhou, Junxian He, Graham Neubig, and Pengfei Liu. 2023. [FacTool:
    Factuality Detection in Generative AI – A Tool Augmented Framework for Multi-Task
    and Multi-Domain Scenarios](http://arxiv.org/abs/2307.13528). *arXiv preprint*.
    ArXiv:2307.13528 [cs] version: 2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Elsahar et al. (2018) Hady Elsahar, Pavlos Vougiouklis, Arslen Remaci, Christophe
    Gravier, Jonathon Hare, Frederique Laforest, and Elena Simperl. 2018. T-rex: A
    large scale alignment of natural language with knowledge base triples. In *Proceedings
    of the Eleventh International Conference on Language Resources and Evaluation
    (LREC 2018)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fernando et al. (2023) Chrisantha Fernando, Dylan Banarse, Henryk Michalewski,
    Simon Osindero, and Tim Rocktäschel. 2023. [Promptbreeder: Self-referential self-improvement
    via prompt evolution](https://arxiv.org/abs/2309.16797). *Preprint*, arXiv:2309.16797.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu and Levy (2023) Jennifer Hu and Roger Levy. 2023. Prompting is not a substitute
    for probability measurements in large language models. In *Proceedings of the
    2023 Conference on Empirical Methods in Natural Language Processing*, pages 5040–5060.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2023a) Xiangkun Hu, Dongyu Ru, Qipeng Guo, Lin Qiu, and Zheng Zhang.
    2023a. [RefChecker for fine-grained hallucination detection](https://github.com/amazon-science/RefChecker).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2023b) Xuming Hu, Junzhe Chen, Xiaochuan Li, Yufei Guo, Lijie Wen,
    Philip S Yu, and Zhijiang Guo. 2023b. Do large language models know about facts?
    *arXiv preprint arXiv:2310.05177*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey
    of hallucination in natural language generation. *ACM Computing Surveys*, 55(12):1–38.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2021) Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig.
    2021. How can we know when language models know? on the calibration of language
    models for question answering. *Transactions of the Association for Computational
    Linguistics*, 9:962–977.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2020) Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig.
    2020. How can we know what language models know? *Transactions of the Association
    for Computational Linguistics*, 8:423–438.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kazemnejad et al. (2023) Amirhossein Kazemnejad, Mehdi Rezagholizadeh, Prasanna
    Parthasarathi, and Sarath Chandar. 2023. Measuring the knowledge acquisition-utilization
    gap in pretrained language models. *arXiv preprint arXiv:2305.14775*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kryściński et al. (2019) Wojciech Kryściński, Bryan McCann, Caiming Xiong, and
    Richard Socher. 2019. [Evaluating the Factual Consistency of Abstractive Text
    Summarization](http://arxiv.org/abs/1910.12840). *arXiv preprint*. ArXiv:1910.12840
    [cs].
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kwon et al. (2023) Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin
    Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. [Efficient
    memory management for large language model serving with pagedattention](https://doi.org/10.1145/3600006.3613165).
    In *Proceedings of the 29th Symposium on Operating Systems Principles*, SOSP ’23,
    page 611–626, New York, NY, USA. Association for Computing Machinery.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Newman et al. (2022) Benjamin Newman, Prafulla Kumar Choubey, and Nazneen Rajani.
    2022. [P-adapters: Robustly extracting factual information from language models
    with diverse prompts](https://openreview.net/forum?id=DhzIU48OcZh). In *International
    Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, 35:27730–27744.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2023) Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia
    Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, et al. 2023. Check
    your facts and try again: Improving large language models with external knowledge
    and automated feedback. *arXiv preprint arXiv:2302.12813*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Petroni et al. (2019) Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin,
    Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. 2019. Language models as
    knowledge bases? *arXiv preprint arXiv:1909.01066*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sclar et al. (2023) Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr.
    2023. Quantifying language models’ sensitivity to spurious features in prompt
    design or: How i learned to start worrying about prompt formatting. *arXiv preprint
    arXiv:2310.11324*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snyder et al. (2023) Ben Snyder, Marius Moisescu, and Muhammad Bilal Zafar.
    2023. On early detection of hallucinations in factual question answering. *arXiv
    preprint arXiv:2312.14183*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2023) Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, and Xin Luna
    Dong. 2023. [Head-to-Tail: How Knowledgeable are Large Language Models (LLM)?
    A.K.A. Will LLMs Replace Knowledge Graphs?](http://arxiv.org/abs/2308.10168) *arXiv
    preprint*. ArXiv:2308.10168 [cs].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020) Chenguang Wang, Xiao Liu, and Dawn Song. 2020. Language models
    are open knowledge graphs. *arXiv preprint arXiv:2010.11967*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023) Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang
    Zhang, Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, et al. 2023.
    Survey on factuality in large language models: Knowledge, retrieval and domain-specificity.
    *arXiv preprint arXiv:2310.07521*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    and Alexander Rush. 2020. [Transformers: State-of-the-art natural language processing](https://doi.org/10.18653/v1/2020.emnlp-demos.6).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations*, pages 38–45, Online. Association for Computational
    Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2023) Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu,
    Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A survey
    on large language models for recommendation. *arXiv preprint arXiv:2305.19860*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023) Jia-Yu Yao, Kun-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, and
    Li Yuan. 2023. LLM lies: Hallucinations are not bugs, but features as adversarial
    examples. *arXiv preprint arXiv:2310.01469*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2024) Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li,
    Xin Lv, Hao Peng, Zijun Yao, Xiaohan Zhang, Hanming Li, Chunyang Li, Zheyuan Zhang,
    Yushi Bai, Yantao Liu, Amy Xin, Kaifeng Yun, Linlu GONG, Nianyi Lin, Jianhui Chen,
    Zhili Wu, Yunjia Qi, Weikai Li, Yong Guan, Kaisheng Zeng, Ji Qi, Hailong Jin,
    Jinxin Liu, Yu Gu, Yuan Yao, Ning Ding, Lei Hou, Zhiyuan Liu, Xu Bin, Jie Tang,
    and Juanzi Li. 2024. [KoLA: Carefully benchmarking world knowledge of large language
    models](https://openreview.net/forum?id=AqN23oqraW). In *The Twelfth International
    Conference on Learning Representations*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zamfirescu-Pereira et al. (2023) JD Zamfirescu-Pereira, Richmond Y Wong, Bjoern
    Hartmann, and Qian Yang. 2023. Why johnny can’t prompt: how non-ai experts try
    (and fail) to design llm prompts. In *Proceedings of the 2023 CHI Conference on
    Human Factors in Computing Systems*, pages 1–21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2022) Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe,
    Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin,
    et al. 2022. Opt: Open pre-trained transformer language models. *arXiv preprint
    arXiv:2205.01068*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023) Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. 2023. Siren’s song
    in the ai ocean: A survey on hallucination in large language models. *arXiv preprint
    arXiv:2309.01219*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2023) Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Jeff Huang,
    Chuyue Sun, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E.
    Gonzalez, Clark Barrett, and Ying Sheng. 2023. [Efficiently programming large
    language models using sglang](https://arxiv.org/abs/2312.07104). *Preprint*, arXiv:2312.07104.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2023) Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan
    Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. 2023. Large language models
    for information retrieval: A survey. *arXiv preprint arXiv:2308.07107*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu and Li (2023) Zeyuan Allen Zhu and Yuanzhi Li. 2023. Physics of language
    models: Part 3.1, knowledge storage and extraction. *arXiv preprint arXiv:2309.14316*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A.1 Creation of Nobel laureates dataset from Wikidata
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Nobel Dataset is a collection of biographical information about all Nobel
    laureates up until the year 2022, totaling 954 individuals. This dataset was curated
    using data obtained from Wikidata’s querying service⁴⁴4https://query.wikidata.org/.
    The following attributes are included for each laureate:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Name: The full name of the Nobel laureate.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Birth Year: The year in which the laureate was born.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Award Year: The year(s) in which the laureate was awarded the Nobel Prize.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nature of Award: A brief description of the reason for the award, including
    the field of the Nobel Prize (e.g., Physics, Peace).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gender: The gender of the laureate.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here are some examples from the Nobel Dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Excerpt from the Nobel Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Birth Year | Award Year | Nature of Award | Gender |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Albert Einstein | 1879 | 1921 | Physics | male |'
  prefs: []
  type: TYPE_TB
- en: '| Louis de Broglie | 1892 | 1929 | Physics | male |'
  prefs: []
  type: TYPE_TB
- en: '| Carl D. Anderson | 1905 | 1936 | Physics | male |'
  prefs: []
  type: TYPE_TB
- en: '| Polykarp Kusch | 1911 | 1955 | Physics | male |'
  prefs: []
  type: TYPE_TB
- en: '| Melvin Schwartz | 1932 | 1988 | Physics | male |'
  prefs: []
  type: TYPE_TB
- en: '| Jerome I. Friedman | 1930 | 1990 | Physics | male |'
  prefs: []
  type: TYPE_TB
- en: 'A.2 Creation of multiple choices from T-REx: TREx-MC'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'T-REx Elsahar et al. ([2018](#bib.bib7)) is a large-scale alignment dataset
    that aligns between Wikipedia abstracts and Wikipedia triples. We have utilized
    the processed version of T-REx available on HuggingFace ⁵⁵5[https://huggingface.co/datasets/relbert/t_rex](https://huggingface.co/datasets/relbert/t_rex)
    for our experiments. We filtered out the relations that have more than 500 facts
    and 100 unique object entities. The unique objects ensure having 100 feasible
    multiple-choices for each fact in each relation. We curated 50 relations for our
    dataset TREx-MC that essentially consists of $<$. The multiple choices comprise
    the correct answer along with 99 other potential choices. We list the 50 relations
    in Table [3](#A1.T3 "Table 3 ‣ A.2 Creation of multiple choices from T-REx: TREx-MC
    ‣ Appendix A Dataset ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction") below.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following attributes are included in TREx-MC dataset for each relation:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Subject : The subject entity for each fact.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Object: The object entity or the correct answer for each fact.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multiple choices: The list of other potential choices for each fact.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Title : The Wikipedia title for each fact.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Text: The Wikipedia abstract corresponding to each fact.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table 3: List of 50 relations from T-REx-MC'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; date of &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; birth &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; date of &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; death &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| director | father | spouse | child | sibling | composer |'
  prefs: []
  type: TYPE_TB
- en: '&#124; is a &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; tributary of &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| student of |'
  prefs: []
  type: TYPE_TB
- en: '| instance of |'
  prefs: []
  type: TYPE_TB
- en: '&#124; cast &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; member &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| genre |'
  prefs: []
  type: TYPE_TB
- en: '&#124; contains the &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; administrative &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; territorial &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; entity &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; educated &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; at &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; parent &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; taxon &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; screen &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; writer &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| performer | capital | producer |'
  prefs: []
  type: TYPE_TB
- en: '| is made by |'
  prefs: []
  type: TYPE_TB
- en: '&#124; named &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; after &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| developer | publisher |'
  prefs: []
  type: TYPE_TB
- en: '&#124; founded &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; by &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; drafted &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; by &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; has &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; played &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; at &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; part of &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; the series &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| manufacturer |'
  prefs: []
  type: TYPE_TB
- en: '&#124; production &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; company &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| mother |'
  prefs: []
  type: TYPE_TB
- en: '&#124; cause of &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; death &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; has &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; subsidiary &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| creates |'
  prefs: []
  type: TYPE_TB
- en: '&#124; point in &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; time &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| inception |'
  prefs: []
  type: TYPE_TB
- en: '&#124; publication &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; date &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; languages &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; spoken, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; written &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; or signed &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; original &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; language &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; of film or &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; TV show &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; official &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; language &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; native &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; language &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; position &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; played &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; on team / &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; speciality &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; original &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; broadcaster &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; record &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; label &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| author |'
  prefs: []
  type: TYPE_TB
- en: '&#124; discoverer &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; or inventor &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| characters | lyrics by | distributed by | home venue |'
  prefs: []
  type: TYPE_TB
- en: 'Some examples from the T-REx-MC dataset for 2 relations are listed in Table
    [4](#A1.T4 "Table 4 ‣ A.2 Creation of multiple choices from T-REx: TREx-MC ‣ Appendix
    A Dataset ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning
    vs. Prompting Based Factual Knowledge Extraction")'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Excerpts from T-REx-MC Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '| Subject | Object | Multiple choices | Title | Text |'
  prefs: []
  type: TYPE_TB
- en: '| Date of birth |'
  prefs: []
  type: TYPE_TB
- en: '| Giovanni Bia | 24 October 1968 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [’26 September 1981’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; ’20 February 1981’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; ..,’20 September 1960’] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Giovanni Bia |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Giovanni Bia &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (born 24 October 1968) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; is a former &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Italian footballer… &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Brian May | 19 July 1947 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [’24 December 1931’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; ’1 December 1976’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; … ’23 August 1964] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Brian May |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Brian Harold May, CBE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (born 19 July 1947) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; is an English musician… &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Composer |'
  prefs: []
  type: TYPE_TB
- en: '| Mexico Trilogy | Robert Rodriguez |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [’Fred Schneider’, ’Brandy’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; .., ’Tommaso Traetta’] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mexico Trilogy |'
  prefs: []
  type: TYPE_TB
- en: '&#124; The Mexico Trilogy or &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Mariachi Trilogy &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; (also Desperado Trilogy &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; on some DVD releases) &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; is a series of American.. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Chelsea Walls | Jeff Tweedy |'
  prefs: []
  type: TYPE_TB
- en: '&#124; [’Carmine Coppola’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; ’Jimmy Chi’, &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; …’Maurice Ravel’] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Chelsea Walls |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Chelsea Walls is a 2001 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; independent film &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; directed by Ethan Hawke &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; and released by Lions Gate &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Entertainment. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Inference Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We experiment with and use three different inference setups:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Transformers Based Setup: This setup utilizes the utilities present in the
    transformers library Wolf et al. ([2020](#bib.bib28)) to obtain the log probabilities
    for generating the different options.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'vLLM Based Setup: vLLM ((Kwon et al., [2023](#bib.bib17))) is a fast inference
    library for large language models (LLMs). It efficiently manages attention key
    and value memory using PagedAttention. We observed considerable speed boosts for
    all 3 LKEs compared to the standard Transformers API.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'SGLang Based Setup: SGLang Zheng et al. ([2023](#bib.bib35)) is a structured
    generation language designed for large language models (LLMs). It speeds up LLM
    interactions and provides enhanced control through tight integration of its frontend
    language and backend runtime system. SGLang also leverages Radix Attention to
    cache common components across queries in the KV cache, enabling substantial speedups.
    We observed sizable speed boosts for IC-LKE  and EIC-LKE  over vLLM. However,
    we are constrained by SGLang’s limited model family support at the moment, and
    only utilize it for the Llama, Mistral, and Mixtral families.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix C Implementation Details
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: C.1 IC-LKE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IC-LKE  leverages 50 randomly chosen samples from the training data as in-context
    examples but does not use the relation name. The base prompt is now composed of
    50 different examples followed by the name of the entity being tested. A sample
    would be “Albert Einstein 14 March 1879 Ernest Rutherford 30 August 1871 … J.J.
    Thomson 18 December 1856 Max Planck."
  prefs: []
  type: TYPE_NORMAL
- en: The subsequent process is the same as PB-LKE . The process involves adding 100
    different choices to the base prompt. A single forward pass is conducted for each
    sequence, generating log probabilities for the entire sequence. The common part,
    represented by the tokens for the base prompt is then removed from the tokens
    of the concatenated base prompt and option resulting in the log probabilities
    for the option. Similar to PB-LKE , if the option is tokenized into multiple tokens,
    a single probability value is obtained by multiplying the individual token probabilities.
    The resulting values are normalized across multiple choices, and the option with
    the highest probability is selected as the correct answer. We use the vLLM Based
    & SGLang Based Setup for this LKE.
  prefs: []
  type: TYPE_NORMAL
- en: C.2 EIC-LKE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The EIC-LKE  retrieves all 100 samples from our training dataset, initially
    maintaining them in a single sequence. Then, starting from the 50th training sample,
    we intersperse our test sample with all the choices every 5 examples. This results
    in a sequence that includes both the correct and incorrect choices. To determine
    the probability of each choice, we first use a tokenizer to tokenize all the subjects
    and choices separately. Then, we combine their token IDs, using a space token
    to separate the subject and object, and a comma to differentiate between different
    tuples. After obtaining the sequence’s token IDs, we input these token IDs into
    a simple forward pass. We use the token length of each subject and object to locate
    the probability of their corresponding tokens. Finally, we calculate the probability
    of all the choices by multiplying the probabilities of all their tokens. The resulting
    values are normalized across the choices, and the choice with the highest probability
    is selected as the correct answer. We use a vLLM Based Setup for this LKE.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Different Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The evaluation metric can readily be adapted to existing classification metrics.
    For example, we introduced the metric Accuracy@K, a calibrated measure that assesses
    a model’s confidence in its predictions. This metric quantifies how accurately
    the model identifies knowledge at specified confidence levels for a given relation.
    We filter the instances that have their confidence levels > threshold $K$, the
    results of which are shown in Figure [8](#A4.F8 "Figure 8 ‣ Appendix D Different
    Metrics ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning
    vs. Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $1$2 |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8d9ecdfd16e075fa6a3a83d858d5845e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Accuracy@K for different models We evaluated five models on the Nobel
    dataset, which consists of 50 examples. Each model’s performance was measured
    using the Accuracy@K metric at various thresholds.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Probabilities of objects in sequence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We first consider $200$ correct examples (subject-object pairs) and report
    the absolute generation probability of objects in corresponding examples. We showed
    the results for Llama2-7B, Falcon-7B, Gemma-7B, and Pythia-12B in Figure [11](#A5.F11
    "Figure 11 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), Figure [9](#A5.F9 "Figure 9 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction") and Figure [10](#A5.F10
    "Figure 10 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"). Figure [11a](#A5.F11.sf1 "In Figure 11 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction"), Figure [9a](#A5.F9.sf1
    "In Figure 9 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), and Figure [10a](#A5.F10.sf1 "In Figure 10 ‣ Appendix
    E Probabilities of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction")
    illustrates the probability of each object at various sequence positions; Figure [11b](#A5.F11.sf2
    "In Figure 11 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), Figure [9b](#A5.F9.sf2 "In Figure 9 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction"), and Figure [10b](#A5.F10.sf2
    "In Figure 10 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction") shows the impact on probabilities after substituting 40
    objects dispersed within the sequence with incorrect ones. Figure [11c](#A5.F11.sf3
    "In Figure 11 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), Figure [9c](#A5.F9.sf3 "In Figure 9 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction"), and Figure [10c](#A5.F10.sf3
    "In Figure 10 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction") visualizes the effect of replacing objects at simultaneous
    positions. Figures [11d](#A5.F11.sf4 "In Figure 11 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction"), Figure [9d](#A5.F9.sf4
    "In Figure 9 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), Figure [10d](#A5.F10.sf4 "In Figure 10 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction"), Figure [11e](#A5.F11.sf5
    "In Figure 11 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), Figure [9e](#A5.F9.sf5 "In Figure 9 ‣ Appendix E Probabilities
    of objects in sequence ‣ Towards Reliable Latent Knowledge Estimation in LLMs:
    In-Context Learning vs. Prompting Based Factual Knowledge Extraction"), and Figure [10e](#A5.F10.sf5
    "In Figure 10 ‣ Appendix E Probabilities of objects in sequence ‣ Towards Reliable
    Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction") present the outcomes of using unknown subject-object pairs
    as replacements. We used a horizontal dashed line showing an average probability
    of the correct examples. The yellow star notated the example at position 114 in
    the sequence.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/da574cc05cf5b02f3e3fa33a33025b93.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Correct Subject-Object Pairs
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/26dde35e3eb6d8809e94285842ec61a6.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Distributed Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4ba3750e74d0a470494018850cbb42c9.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Simultaneous Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/acc59ee0462e4dcbf95b98ffb39b8560.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Distributed Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/72be93e3679562d520cbb7fef3c71bb8.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Simultaneous Replace
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9: [Analysis of object probability in one sequence of Nobel laureate
    data using Llama2-7b]'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dd7d4b8085f76074c604c6a5baf5f437.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Correct Subject-Object Pairs
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f0cb703786c6db148c211780bb8829ad.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Distributed Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/57a8554f1e1008a18290b1c050e3a55e.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Simultaneous Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3a3f005267fed10fb9bbef564bc522cc.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Distributed Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/86c1beb751790c02cb121c4f02afa9df.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Simultaneous Replace
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10: [Analysis of object probability in one sequence of Nobel laureate
    data using Pythia-12B]'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/08003cbb1eee5bc7ac5b9f3b32d65d71.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Correct Subject-Object Pairs
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8cf3c00edb41a184f23a45e99f9882bc.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Distributed Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ced02b60182bddcca5950b15c24606cd.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Simultaneous Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/41b9d555d471a285e01d4aacf8ebd9e8.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Distributed Replace
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5c7a90b8c57bd1755ed0c90cecf909a3.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) Simultaneous Replace
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11: [Analysis of object probability in one sequence of Nobel laureate
    data using Falcon-7B]'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix F Efficient In Context learning based LKE (EIC-LKE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We improve the efficiency of IC-LKE to perform knowledge extraction of multiple
    test facts in a single prompt. Leveraging the context length in LLMs, the efficient
    version, namely EIC-LKE, places multiple test facts surrounded by training facts
    into the same prompt. We measure the object probability of each of the (alternative)
    test facts in the seuqence to determine whether the LLM assigns higher probability
    to the correct fact than the others.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Considering the training facts in Example [1](#Thmexample1 "Example 1\. ‣ 2.2
    A new In Context learning based LKE (IC-LKE) ‣ 2 Designing Reliable LKEs ‣ Towards
    Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting
    Based Factual Knowledge Extraction"), we evaluate two test choices (highlighted
    in yellow) for the birth-year relation: $\langle$ using two prompts instead of
    four as in IC-LKE.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Feynman 1918$\displaystyle\text{ {Einstein} }\textit{1879}^{*}$ Heisenberg
    1901 Louis 1850 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | Feynman 1918 Einstein 1880 Heisenberg 1901$\displaystyle\text{ {Louis}
    }\textit{1892}^{*}$ |  |'
  prefs: []
  type: TYPE_TB
- en: Appendix G Details about the human-generated prompts and machine-mined prompts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We list the used human-generated and machine-mined prompts from (Jiang et al.,
    [2020](#bib.bib14)) in Table [5](#A7.T5 "Table 5 ‣ Appendix G Details about the
    human-generated prompts and machine-mined prompts ‣ Towards Reliable Latent Knowledge
    Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge
    Extraction") with subjects denoted as <‘head’>.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: Templates for Selected Relations'
  prefs: []
  type: TYPE_NORMAL
- en: '| Relation Name | Index | HGP Template | MMP Template |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} means | {subject} is a small |'
  prefs: []
  type: TYPE_TB
- en: '| Instance of | 2 | {subject} is one | {subject} and liberal |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} is a | {subject} artist |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} is playing music | {subject} series of |'
  prefs: []
  type: TYPE_TB
- en: '| Genre | 2 | {subject} play | {subject} favorite |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} performs | {subject} is an american |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} plays in position | {subject} substitutions : |'
  prefs: []
  type: TYPE_TB
- en: '| Position played on team / speciality | 2 | {subject} plays at position |
    {subject} substitutes : |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} is in the position |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | The original language of {subject} is | {subject} a. r. rahman |'
  prefs: []
  type: TYPE_TB
- en: '| Original language of film/TV show | 2 | The source language of {subject}
    is |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | The default language of {subject} is |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | The capital of {subject} is | {subject} united states embassy in |'
  prefs: []
  type: TYPE_TB
- en: '| Capital | 2 | The capital city of {subject} is | {subject} representative
    legislature |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | Its capital {subject} is | {subject} rock band from |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} is a native language of | {subject} descent |'
  prefs: []
  type: TYPE_TB
- en: '| Native language | 2 | The mother tongue of {subject} is | {subject} speak
    the |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} means | {subject} population or a widely spoken |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} is named after | {subject} and produces |'
  prefs: []
  type: TYPE_TB
- en: '| Named after | 2 | {subject} is named for | {subject} variety of standard
    ) |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} is called after | {subject} official |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | The official language {subject} is | {subject} professor of |'
  prefs: []
  type: TYPE_TB
- en: '| Official language | 2 | {subject} is | {subject} is the official language
    in |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} is officially | {subject} is the official language spoken
    in |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} is developed by | {subject} was developed by |'
  prefs: []
  type: TYPE_TB
- en: '| Developer | 2 | {subject} is created by | {subject} 2008 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 2 | {subject} is designed by | {subject} references external links |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} was originally aired on | {subject} premiered on |'
  prefs: []
  type: TYPE_TB
- en: '| Original broadcaster | 2 | {subject} was originally broadcast on | {subject}
    aired on |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} was originally shown in | {subject} 2021 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} is signed to | {subject} signed with |'
  prefs: []
  type: TYPE_TB
- en: '| Record label | 2 | {subject} is a recording artist for | {subject} sohmed
    a recording contract with |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} is a recording artist on | {subject} released by |'
  prefs: []
  type: TYPE_TB
- en: '|  | 1 | {subject} is represented by music label | {subject} attributed to
    the |'
  prefs: []
  type: TYPE_TB
- en: '| Manufacturer | 2 | {subject} is represented by the record label | {subject}
    113 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 3 | {subject} is represented by | {subject} cedar point |'
  prefs: []
  type: TYPE_TB
- en: Appendix H Additional results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: H.1 Model Name Simplification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We list all the models and their simplified names we evaluated in the paper
    in Table [6](#A8.T6 "Table 6 ‣ H.1 Model Name Simplification ‣ Appendix H Additional
    results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning
    vs. Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: Model Name Simplifications'
  prefs: []
  type: TYPE_NORMAL
- en: '| Original Name | Simplified Name in Paper |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| [mistral-mixtral-8x7B-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)
    | Mixtral-8x7B |'
  prefs: []
  type: TYPE_TB
- en: '| [Nous-Hermes-2-Mixtral-8x7B-SFT](https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT)
    | Mixtral-8x7B-FT1 |'
  prefs: []
  type: TYPE_TB
- en: '| [Nous-Hermes-2-Mixtral-8x7B-DPO](https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT)
    | Mixtral-8x7B-FT2 |'
  prefs: []
  type: TYPE_TB
- en: '| [mistral-7b](https://huggingface.co/mistralai/Mistral-7B-v0.1) | Mistral-7B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [mistral-instruct-7b](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
    | Mistral-7B-FT1 |'
  prefs: []
  type: TYPE_TB
- en: '| [openhermes-2.5-mistral-7b](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)
    | Mistral-7B-FT2 |'
  prefs: []
  type: TYPE_TB
- en: '| [llama2-70b](https://huggingface.co/meta-llama/Llama-2-70b) | Llama2-70B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [llama2-70b-chat](https://huggingface.co/meta-llama/Llama-2-70b-chat) | Llama2-70B-FT1
    |'
  prefs: []
  type: TYPE_TB
- en: '| [llama2-13b](https://huggingface.co/meta-llama/Llama-2-13b) | Llama2-13B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [llama2-13b-chat](https://huggingface.co/meta-llama/Llama-2-13b-chat) | Llama2-13B-FT1
    |'
  prefs: []
  type: TYPE_TB
- en: '| [vicuna-13b-v1.5](https://huggingface.co/lmsys/vicuna-13b-v1.5) | Llama2-13B-FT2
    |'
  prefs: []
  type: TYPE_TB
- en: '| [llama2-7b](https://huggingface.co/meta-llama/Llama-2-7b) | Llama2-7B |'
  prefs: []
  type: TYPE_TB
- en: '| [llama2-7b-chat](https://huggingface.co/meta-llama/Llama-2-7b-chat) | Llama2-7B-FT1
    |'
  prefs: []
  type: TYPE_TB
- en: '| [vicuna-7b-v1.5](https://huggingface.co/lmsys/vicuna-7b-v1.5) | Llama2-7B-FT2
    |'
  prefs: []
  type: TYPE_TB
- en: '| [gemma-7b](https://huggingface.co/google/gemma-7b) | Gemma-7B |'
  prefs: []
  type: TYPE_TB
- en: '| [gemma-7b-it](https://huggingface.co/google/gemma-7b-it) | Gemma-7B-FT1 |'
  prefs: []
  type: TYPE_TB
- en: '| [gemma-2b](https://huggingface.co/google/gemma-2b) | Gemma-2B |'
  prefs: []
  type: TYPE_TB
- en: '| [gemma-2b-it](https://huggingface.co/google/gemma-2b-it) | Gemma-2B-FT1 |'
  prefs: []
  type: TYPE_TB
- en: '| [llama-65b](https://huggingface.co/huggyllama/llama-65b) | Llama-65B |'
  prefs: []
  type: TYPE_TB
- en: '| [llama-33b](https://huggingface.co/huggyllama/llama-33b) | Llama-33B |'
  prefs: []
  type: TYPE_TB
- en: '| [llama-13b](https://huggingface.co/huggyllama/llama-13b) | Llama-13B |'
  prefs: []
  type: TYPE_TB
- en: '| [vicuna-13b-1.3](https://huggingface.co/lmsys/vicuna-13b-v1.3) | Llama-13B-FT1
    |'
  prefs: []
  type: TYPE_TB
- en: '| [llama-7b](https://huggingface.co/huggyllama/llama-7b) | Llama-7B |'
  prefs: []
  type: TYPE_TB
- en: '| [vicuna-7b-1.3](https://huggingface.co/lmsys/vicuna-7b-v1.3) | Llama-7B-FT1
    |'
  prefs: []
  type: TYPE_TB
- en: '| [falcon-7b](https://huggingface.co/tiiuae/falcon-7b) | Falcon-7B |'
  prefs: []
  type: TYPE_TB
- en: '| [falcon-instruct-7b](https://huggingface.co/tiiuae/falcon-instruct-7b) |
    Falcon-7B-FT1 |'
  prefs: []
  type: TYPE_TB
- en: '| [mpt-7b](https://huggingface.co/mosaicml/mpt-7b) | MPT-7B |'
  prefs: []
  type: TYPE_TB
- en: '| [gpt-neox-20b](https://huggingface.co/EleutherAI/gpt-neox-20b) | GPT-NEOX-20B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-30b](https://huggingface.co/facebook/opt-30b) | OPT-30B |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-13b](https://huggingface.co/facebook/opt-13b) | OPT-13B |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-6.7b](https://huggingface.co/facebook/opt-6.7b) | OPT-6.7B |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-2.7b](https://huggingface.co/facebook/opt-2.7b) | OPT-2.7B |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-1.3b](https://huggingface.co/facebook/opt-1.3b) | OPT-1.3B |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-350m](https://huggingface.co/facebook/opt-350m) | OPT-350M |'
  prefs: []
  type: TYPE_TB
- en: '| [opt-125m](https://huggingface.co/facebook/opt-125m) | OPT-125M |'
  prefs: []
  type: TYPE_TB
- en: '| [gpt-j-6b](https://huggingface.co/EleutherAI/gpt-j-6b) | GPT-J-6B |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-12b](https://huggingface.co/EleutherAI/pythia-12b) | Pythia-12B |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-6.9b](https://huggingface.co/EleutherAI/pythia-6.9b) | Pythia-6.9B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-2.8b](https://huggingface.co/EleutherAI/pythia-2.8b) | Pythia-2.8B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-1.4b](https://huggingface.co/EleutherAI/pythia-1.4b) | Pythia-1.4B
    |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-1b](https://huggingface.co/EleutherAI/pythia-1b) | Pythia-1B |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-410m](https://huggingface.co/EleutherAI/pythia-410m) | Pythia-410M
    |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-160m](https://huggingface.co/EleutherAI/pythia-160m) | Pythia-160M
    |'
  prefs: []
  type: TYPE_TB
- en: '| [pythia-70m](https://huggingface.co/EleutherAI/pythia-70m) | Pythia-70M |'
  prefs: []
  type: TYPE_TB
- en: '| [bloom-7.1b](https://huggingface.co/bigscience/bloomz-7b1) | Bloom-7.1B |'
  prefs: []
  type: TYPE_TB
- en: '| [bloom-3b](https://huggingface.co/bigscience/bloomz-3b) | Bloom-3B |'
  prefs: []
  type: TYPE_TB
- en: '| [bloom-1.7b](https://huggingface.co/bigscience/bloomz-1b7) | Bloom-1.7B |'
  prefs: []
  type: TYPE_TB
- en: '| [bloom-1.1b](https://huggingface.co/bigscience/bloomz-1b1) | Bloom-1.1B |'
  prefs: []
  type: TYPE_TB
- en: '| [bloom-560m](https://huggingface.co/bigscience/bloom-560m) | Bloom-560M |'
  prefs: []
  type: TYPE_TB
- en: H.2 Additional results on baseline comparison
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We compare IC-LKE and EIC-LKE on 12 relations from T-REx-MC: capital, named
    after, developer, manufacturer, genre, instance of, native language, original
    broadcaster, language spoken written or signed, original language of film / TV
    show, official language, position played on team/speciality. We chose those 12
    relations from T-REx-MCthat are found to be in common with  Jiang et al. ([2020](#bib.bib14))
    where they define the templates for HGP and MMP. We evaluated 4 models (Mistral-7B,
    Llama-7B, Falcon-7B, and Pythia-12B) and showed all the results in Figure [12](#A8.F12
    "Figure 12 ‣ H.2 Additional results on baseline comparison ‣ Appendix H Additional
    results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning
    vs. Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0f2fc6ae2f3cddc7c5f74221d7e0e7f3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Accuracy for different latent knowledge estimators on all 12 relations'
  prefs: []
  type: TYPE_NORMAL
- en: H.3 Full order of models and relations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We evaluated 49 models on 50 relations by our IC-LKEand EIC-LKE. Table LABEL:table:model_order
    shows the ordered models by the average accuracy of all the 50 relations. Table [8](#A8.T8
    "Table 8 ‣ H.4 Full evaluation on EIC-LKE ‣ Appendix H Additional results ‣ Towards
    Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting
    Based Factual Knowledge Extraction") shows the ordered relations by the average
    accuracy of all the 49 models.'
  prefs: []
  type: TYPE_NORMAL
- en: H.4 Full evaluation on EIC-LKE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We evaluated all the pre-trained models using EIC-LKE, but didn’t evaluate
    GPT-NEOX-20B due to the limitation of its context window size. Figure [13](#A8.F13
    "Figure 13 ‣ H.4 Full evaluation on EIC-LKE ‣ Appendix H Additional results ‣
    Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs.
    Prompting Based Factual Knowledge Extraction") shows the heatmap of models vs.
    relations, ordered in the same way as in Figure [5](#S4.F5 "Figure 5 ‣ 4.2.1 Comparing
    different LLMs families ‣ 4.2 Evaluating Diverse Models and Relations ‣ 4 Experiments
    and Results ‣ Towards Reliable Latent Knowledge Estimation in LLMs: In-Context
    Learning vs. Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a003ff39668e428a135097c339161490.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Accuracy for 35 pre-trained LLMs on the 50 different relations in
    T-REx-MC, evaluated by EIC-LKE.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: Model Performance Comparision'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model | Average Accuracy | Standard Deviation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-70B | 0.8511 | 0.17591 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral-8x7B-SFT | 0.84765 | 0.16919 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral-8x7B | 0.84605 | 0.16653 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-65B | 0.84185 | 0.17528 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral-8x7B-DPO | 0.81535 | 0.17580 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-33B | 0.81255 | 0.19088 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral-7B | 0.79310 | 0.20000 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13B | 0.78692 | 0.21892 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-13B | 0.76845 | 0.21796 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-70B-chat | 0.75815 | 0.21272 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7B | 0.74945 | 0.24069 |'
  prefs: []
  type: TYPE_TB
- en: '| Vicuna-13B | 0.74940 | 0.21427 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-7B | 0.74717 | 0.25668 |'
  prefs: []
  type: TYPE_TB
- en: '| Openhermes-2.5 | 0.74365 | 0.21241 |'
  prefs: []
  type: TYPE_TB
- en: '| Vicuna-13B-2 | 0.74080 | 0.22807 |'
  prefs: []
  type: TYPE_TB
- en: '| Vicuna-7B-2 | 0.71695 | 0.24016 |'
  prefs: []
  type: TYPE_TB
- en: '| Falcon-7B | 0.70190 | 0.27052 |'
  prefs: []
  type: TYPE_TB
- en: '| Vicuna-7B | 0.70155 | 0.24724 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13B-chat | 0.69387 | 0.22966 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-7B | 0.69260 | 0.27912 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-2B | 0.66600 | 0.28627 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-NEOX-20B | 0.66145 | 0.30972 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7B-chat | 0.66130 | 0.24996 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral-instruct-7B | 0.66120 | 0.26173 |'
  prefs: []
  type: TYPE_TB
- en: '| MPT-7B | 0.64545 | 0.30638 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-12B | 0.63325 | 0.32412 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-6.7B | 0.62110 | 0.31313 |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-J-6B | 0.60965 | 0.32319 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-13B | 0.60845 | 0.31017 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-6.9B | 0.59185 | 0.32359 |'
  prefs: []
  type: TYPE_TB
- en: '| Bloom-7.1B | 0.58270 | 0.31404 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-30B | 0.57925 | 0.31813 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-2.8B | 0.57580 | 0.32773 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-1.4B | 0.56330 | 0.33600 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-7B-instruct | 0.55327 | 0.30689 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-2.7B | 0.55109 | 0.33260 |'
  prefs: []
  type: TYPE_TB
- en: '| Bloom-3B | 0.54375 | 0.29199 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-1B | 0.54220 | 0.31560 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-1.3B | 0.53610 | 0.33335 |'
  prefs: []
  type: TYPE_TB
- en: '| Bloom-1.1B | 0.51115 | 0.29346 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-350M | 0.50735 | 0.30716 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-2B-instruct | 0.49474 | 0.29628 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-410M | 0.47995 | 0.29598 |'
  prefs: []
  type: TYPE_TB
- en: '| Bloom-1.7B | 0.47660 | 0.29658 |'
  prefs: []
  type: TYPE_TB
- en: '| OPT-125M | 0.45195 | 0.29330 |'
  prefs: []
  type: TYPE_TB
- en: '| Bloom-560M | 0.38465 | 0.28747 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-160M | 0.37145 | 0.28505 |'
  prefs: []
  type: TYPE_TB
- en: '| Pythia-70M | 0.31260 | 0.27404 |'
  prefs: []
  type: TYPE_TB
- en: '| Falcon-instruct-7B | 0.00605 | 0.01459 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: Relations and their average accuracies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Order | Relation | Average Accuracy |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | publication date | 0.992071428571429 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | inception | 0.983214285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | point in time | 0.975714285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | drafted by | 0.922214285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | native language | 0.8825 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | production company | 0.873428571428571 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | languages spoken, written or signed | 0.865071428571429 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | performer | 0.831142857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | has played at | 0.826642857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | capital | 0.815857142857143 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | is made by | 0.815357142857143 |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | producer | 0.794714285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | record label | 0.794571428571429 |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | named after | 0.791071428571429 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | developer | 0.786928571428571 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | publisher | 0.7835 |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | original broadcaster | 0.781214285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | cast member | 0.777 |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | home venue | 0.771714285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | has subsidiary | 0.754142857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | manufacturer | 0.749928571428571 |'
  prefs: []
  type: TYPE_TB
- en: '| 22 | screenwriter | 0.732285714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | contains the administrative territorial entity | 0.7255 |'
  prefs: []
  type: TYPE_TB
- en: '| 24 | creates | 0.721214285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | official language | 0.709857142857143 |'
  prefs: []
  type: TYPE_TB
- en: '| 26 | mother | 0.697857142857143 |'
  prefs: []
  type: TYPE_TB
- en: '| 27 | part of the series | 0.692214285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 28 | founded by | 0.684714285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 29 | original language of film or TV show | 0.6825 |'
  prefs: []
  type: TYPE_TB
- en: '| 30 | date of birth | 0.668857142857143 |'
  prefs: []
  type: TYPE_TB
- en: '| 31 | date of death | 0.641594184576485 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 | instance of | 0.588990518331226 |'
  prefs: []
  type: TYPE_TB
- en: '| 33 | position played on team / speciality | 0.537642857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 34 | genre | 0.536 |'
  prefs: []
  type: TYPE_TB
- en: '| 35 | distributed by | 0.522785714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 36 | parent taxon | 0.488428571428571 |'
  prefs: []
  type: TYPE_TB
- en: '| 37 | director | 0.432928571428571 |'
  prefs: []
  type: TYPE_TB
- en: '| 38 | author | 0.331285714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 39 | father | 0.309214285714286 |'
  prefs: []
  type: TYPE_TB
- en: '| 40 | educated at | 0.306285714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 41 | characters | 0.282857142857143 |'
  prefs: []
  type: TYPE_TB
- en: '| 42 | composer | 0.276785714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 43 | child | 0.259142857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 44 | lyrics by | 0.258428571428571 |'
  prefs: []
  type: TYPE_TB
- en: '| 45 | sibling | 0.250285714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 46 | spouse | 0.238785714285714 |'
  prefs: []
  type: TYPE_TB
- en: '| 47 | is a tributary of | 0.212142857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 48 | cause of death | 0.206 |'
  prefs: []
  type: TYPE_TB
- en: '| 49 | discoverer or inventor | 0.173142857142857 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | student of | 0.123357142857143 |'
  prefs: []
  type: TYPE_TB
- en: H.5 Relation accuracy correlation of all the pre-trained models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In Table [14](#A8.F14 "Figure 14 ‣ H.5 Relation accuracy correlation of all
    the pre-trained models ‣ Appendix H Additional results ‣ Towards Reliable Latent
    Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual
    Knowledge Extraction"), we show the Pearson correlation coefficients between each
    model pair’s performance across the 50 relations.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/31d88aae4bc87ebe19918f91adaced97.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: [Pearson Correlation Coefficients Between All Pre-trained Models]
    We calculated the Pearson correlation coefficients for each model pair among 49
    models across 50 relations.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Order/Model | Mistral-8x7B | Mistral-7B | Llama2-70B | Llama2-13B | Llama2-7B
    | Gemma-7B | Gemma-2B |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | publication date | point in time | point in time | publication date |
    publication date | point in time | point in time |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | point in time | date of death | inception | point in time | inception
    | inception | inception |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | inception | publication date | publication date | inception | point in
    time | publication date | publication date |'
  prefs: []
  type: TYPE_TB
- en: '| … | …… | …… | …… | ; | ; | ; |  |'
  prefs: []
  type: TYPE_TB
- en: '| 48 | discoverer or inventor | discoverer or inventor | student of | discoverer
    or inventor | educated at | date of death | position played on team / speciality
    |'
  prefs: []
  type: TYPE_TB
- en: '| 49 | cause of death | cause of death | cause of death | cause of death |
    cause of death | instance of | discoverer or inventor |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | student of | student of | is a tributary of | student of | student of
    | date of birth | student of |'
  prefs: []
  type: TYPE_TB
- en: '| Order/Model | Llama-65B | Llama-33B | Llama-13B | Llama-7B | Falcon-7B |
    MPT-7B | GPT-NEOX-20B |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | publication date | publication date | publication date | publication
    date | point in time | publication date | publication date |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | point in time | point in time | point in time | point in time | inception
    | inception | inception |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | inception | inception | inception | inception | publication date | point
    in time | date of death |'
  prefs: []
  type: TYPE_TB
- en: '| … | …… | …… | …… | ; | ; | ; |  |'
  prefs: []
  type: TYPE_TB
- en: '| 48 | discoverer or inventor | discoverer or inventor | discoverer or inventor
    | student of | discoverer or inventor | student of | discoverer or inventor |'
  prefs: []
  type: TYPE_TB
- en: '| 49 | cause of death | cause of death | cause of death | instance of | is
    a tributary of | is a tributary of | lyrics by |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | student of | student of | student of | date of birth | student of |
    educated at | student of |'
  prefs: []
  type: TYPE_TB
- en: '| Order/Model | OPT-30B | OPT-13B | OPT-6.7B | OPT-2.7B | OPT-1.3B | OPT-350M
    | OPT-125M |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | inception | publication date | publication date | inception | publication
    date | inception | inception |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | publication date | inception | inception | publication date | inception
    | publication date | publication date |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | point in time | point in time | date of death | point in time | drafted
    by | point in time | point in time |'
  prefs: []
  type: TYPE_TB
- en: '| … | …… | …… | …… | ; | ; | ; |  |'
  prefs: []
  type: TYPE_TB
- en: '| 48 | position played on team / speciality | composer | lyrics by | discoverer
    or inventor | director | is a tributary of | student of |'
  prefs: []
  type: TYPE_TB
- en: '| 49 | discoverer or inventor | student of | student of | student of | student
    of | spouse | is a tributary of |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | director | date of birth | discoverer or inventor | instance of | date
    of birth | student of | educated at |'
  prefs: []
  type: TYPE_TB
- en: '| Order/Model | GPT-J-6B | Pythia-12B | Pythia-6.9B | Pythia-2.8B | Pythia-1.4B
    | Pythia-1B | Pythia-410M |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | inception | point in time | publication date | publication date | publication
    date | publication date | publication date |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | publication date | publication date | inception | inception | inception
    | inception | inception |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | point in time | inception | point in time | point in time | date of death
    | point in time | drafted by |'
  prefs: []
  type: TYPE_TB
- en: '| … | …… | …… | …… | …… | …… | …… | …… |'
  prefs: []
  type: TYPE_TB
- en: '| 48 | lyrics by | lyrics by | lyrics by | student of | discoverer or inventor
    | lyrics by | student of |'
  prefs: []
  type: TYPE_TB
- en: '| 49 | student of | genre | director | date of birth | lyrics by | student
    of | discoverer or inventor |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | date of death | director | date of death | lyrics by | director | date
    of death | is a tributary of |'
  prefs: []
  type: TYPE_TB
- en: '| Order/Model | Pythia-160M | Pythia-70M | Bloom-7.1B | Bloom-3B | Bloom-1.7B
    | Bloom-1.1B | Bloom-560M |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | publication date | publication date | publication date | publication
    date | publication date | publication date | publication date |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | point in time | point in time | inception | inception | inception | inception
    | inception |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | date of death | native language | date of death | point in time | point
    in time | date of death | point in time |'
  prefs: []
  type: TYPE_TB
- en: '| … | …… | …… | …… | …… | …… | …… | …… |'
  prefs: []
  type: TYPE_TB
- en: '| 48 | student of | official language | lyrics by | is a tributary of | screenwriter
    | is a tributary of | is a tributary of |'
  prefs: []
  type: TYPE_TB
- en: '| 49 | capital | instance of | student of | spouse | student of | spouse |
    director |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | director | date of death | spouse | student of | spouse | student of
    | student of |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Top 3 and Bottom 3 relations for each pre-trained model'
  prefs: []
  type: TYPE_NORMAL
- en: H.6 Impact of finetuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We show the results evaluated by EIC-LKE for all the pre-trained models and
    fine-tuned models in Figure [15](#A8.F15 "Figure 15 ‣ H.6 Impact of finetuning
    ‣ Appendix H Additional results ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction")
    from the relations in TREx-MC, which also conveys the message about reduced knowledge
    in fine-tuned models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/490f5e9413babe2c85eef4deeed3b58b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: [Base vs chat-finetuned models] We see that finetuned versions (depicted
    in lighter shades) obtain lower accuracy across the relations in T-REx-MC than
    pre-trained models (shown in darker shades), evaluated by IC-LKE.'
  prefs: []
  type: TYPE_NORMAL
- en: We also show the results for the average subsumption rate ($\eta$) for base
    models and fine-tuned models over the relations in T-REx-MC.
  prefs: []
  type: TYPE_NORMAL
- en: '| Family | Model Type | Accuracy | Model Type | Accuracy | $\eta$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-7B | Base | 0.699 | FT-1 | 0.693 | 0.779 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-13B | Base | 0.770 | FT-1 | 0.735 | 0.854 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7B | Base | 0.741 | FT-1 | 0.712 | 0.808 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-7B | Base | 0.741 | FT-2 | 0.664 | 0.790 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13B | Base | 0.771 | FT-1 | 0.748 | 0.831 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-13B | Base | 0.771 | FT-2 | 0.692 | 0.801 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama2-70B | Base | 0.846 | FT-1 | 0.739 | 0.811 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral-7B | Base | 0.793 | FT-1 | 0.639 | 0.793 |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral-7B | Base | 0.793 | FT-2 | 0.750 | 0.869 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral-7Bx8 | Base | 0.832 | FT-1 | 0.835 | 0.928 |'
  prefs: []
  type: TYPE_TB
- en: '| Mixtral-7Bx8 | Base | 0.832 | FT-2 | 0.817 | 0.911 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-2B | Base | 0.666 | FT-1 | 0.488 | 0.577 |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma-7B | Base | 0.749 | FT-1 | 0.511 | 0.557 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 10: Average subsumption rate ($\eta$). The results are based on IC-LKE.'
  prefs: []
  type: TYPE_NORMAL
- en: H.7 Evaluation of Generated Output
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We also evaluated the generated output, where we used greedy searching(temperature=0),
    and asked both pre-trained and fine-tuned models to generate 50 tokens using different
    prompts from HGP and MMP. Following this, we checked for the presence of the ground
    truth in the generated output of 50 tokens. The generation is correct if present,
    and incorrect otherwise, then we compute the generation accuracy on the test dataset.
    We report the average generation accuracy based on 12 relations and the HGP/MMP
    templates shown in Table [5](#A7.T5 "Table 5 ‣ Appendix G Details about the human-generated
    prompts and machine-mined prompts ‣ Towards Reliable Latent Knowledge Estimation
    in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/42d59b110186f3718418bf6385171757.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Accuracies computed over generated outputs (50 tokens) for pre-trained
    and fine-tuned models using HGP, MMP, and IC-LKE.'
  prefs: []
  type: TYPE_NORMAL
