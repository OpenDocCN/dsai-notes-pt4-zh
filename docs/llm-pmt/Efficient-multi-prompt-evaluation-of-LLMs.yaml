- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:43:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:43:30'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Efficient multi-prompt evaluation of LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高效的多提示评估LLMs
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2405.17202](https://ar5iv.labs.arxiv.org/html/2405.17202)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2405.17202](https://ar5iv.labs.arxiv.org/html/2405.17202)
- en: Felipe Maia Polo¹, Ronald Xu^(2.6), Lucas Weber³, Mírian Silva^(4,5,6), Onkar
    Bhardwaj^(5,6)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**费利佩·迈亚·波洛**¹、**罗纳德·徐**^(2.6)、**卢卡斯·韦伯**³、**米里安·席尔瓦**^(4,5,6)、**昂卡尔·巴尔德瓦杰**^(5,6)'
- en: Leshem Choshen^(2,5,6), Allysson Flavio Melo de Oliveira^(5,6), Yuekai Sun¹,
    Mikhail Yurochkin^(5,6)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**莱谢姆·乔申**^(2,5,6)、**阿利森·弗拉维奥·梅洛·德·奥利维拉**^(5,6)、**岳凯·孙**¹、**米哈伊尔·尤罗钦**^(5,6)'
- en: ¹University of Michigan, ²MIT, ³University Pompeu Fabra, ⁴Federal University
    of Minas Gerais
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹密歇根大学，²麻省理工学院，³庞培法布拉大学，⁴米纳斯吉拉斯联邦大学
- en: '⁵IBM Research, ⁶MIT-IBM Watson AI Lab Corresponding author. E-mail: felipemaiapolo@gmail.com'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵IBM研究院，⁶MIT-IBM Watson AI实验室，通讯作者。电子邮件：felipemaiapolo@gmail.com
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Abstract
- en: 'Most popular benchmarks for comparing LLMs rely on a limited set of prompt
    templates, which may not fully capture the LLMs’ abilities and can affect the
    reproducibility of results on leaderboards. Many recent works empirically verify
    prompt sensitivity and advocate for changes in LLM evaluation. In this paper,
    we consider the problem of estimating the performance *distribution* across many
    prompt variants instead of finding a single prompt to evaluate with. We introduce
    PromptEval, a method for estimating performance across a large set of prompts
    borrowing strength across prompts and examples to produce accurate estimates under
    practical evaluation budgets. The resulting distribution can be used to obtain
    performance quantiles to construct various robust performance metrics (e.g., top
    95% quantile or median). We prove that PromptEval consistently estimates the performance
    distribution and demonstrate its efficacy empirically on three prominent LLM benchmarks:
    MMLU, BIG-bench Hard, and LMentry. For example, PromptEval can accurately estimate
    performance quantiles across 100 prompt templates on MMLU with a budget equivalent
    to two single-prompt evaluations¹¹1Our code and data can be found in [https://github.com/felipemaiapolo/prompt-eval](https://github.com/felipemaiapolo/prompt-eval)..'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用于比较LLMs的热门基准依赖于有限的提示模板，这可能无法完全捕捉LLMs的能力，并且可能影响在排行榜上的结果的可重复性。许多近期的研究实证验证了提示敏感性，并主张对LLM评估进行修改。在本文中，我们考虑估计跨多个提示变体的性能*分布*的问题，而不是寻找单一提示进行评估。我们介绍了PromptEval，这是一种通过借用提示和示例之间的力量来准确估计在实际评估预算下的性能跨大量提示的方法。得到的分布可以用于获取性能量化值，以构建各种稳健的性能指标（例如，前95%分位数或中位数）。我们证明了PromptEval 能够一致地估计性能分布，并在三个重要的LLM基准上实证展示了其有效性：MMLU、BIG-bench
    Hard和LMentry。例如，PromptEval 可以在MMLU上准确估计跨100个提示模板的性能分位数，其预算相当于两个单提示评估¹¹1我们的代码和数据可以在[https://github.com/felipemaiapolo/prompt-eval](https://github.com/felipemaiapolo/prompt-eval)找到。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/8bea8e1161274bc9ae2386363dbbd3bd.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/8bea8e1161274bc9ae2386363dbbd3bd.png)'
- en: 'Figure 1: Average estimation error for performance quantiles across 100 templates
    given a limited budget (in multiples of one-template MMLU evaluations).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：在给定有限预算的情况下（以单模板MMLU评估的倍数），跨100个模板的性能量化误差的平均值。
- en: In recent years, the rapid progress of large language models (LLMs) has significantly
    influenced various fields by enhancing automated text generation and comprehension.
    As these models advance in complexity and functionality, a key challenge that
    arises is their robust evaluation (Perlitz et al., [2023](#bib.bib26)). Common
    evaluation methods, which often rely on a single or limited number of prompt templates,
    may not adequately reflect the typical model’s capabilities (Weber et al., [2023b](#bib.bib43)).
    Furthermore, this approach can lead to unreliable and inconsistent rankings on
    LLM leaderboards, as different models may perform better or worse depending on
    the specific prompt template used. An ideal evaluation framework should minimize
    dependence on any single prompt template and instead provide a holistic summary
    of performance across a broad set of templates. Mizrahi et al. ([2023](#bib.bib24)),
    for example, suggests using summary statistics, such as the average performance
    across many templates, as a way to compare the abilities of different LLMs. However,
    the main drawback of this method is the high computational cost when dealing with
    numerous templates and examples.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLMs）的快速进步在自动文本生成和理解方面显著影响了各个领域。随着这些模型在复杂性和功能上的进步，一个关键挑战是它们的稳健评估（Perlitz
    等，[2023](#bib.bib26)）。常见的评估方法往往依赖于单一或有限数量的提示模板，这可能无法充分反映典型模型的能力（Weber 等，[2023b](#bib.bib43)）。此外，这种方法可能导致
    LLM 排行榜上不可靠和不一致的排名，因为不同的模型可能会因为使用的具体提示模板而表现出更好或更差的结果。理想的评估框架应尽量减少对任何单一提示模板的依赖，而应提供对广泛模板集的整体性能总结。例如，Mizrahi
    等人（[2023](#bib.bib24)）建议使用汇总统计数据，如多个模板下的平均性能，作为比较不同 LLM 能力的一种方式。然而，这种方法的主要缺点是处理大量模板和示例时的高计算成本。
- en: We introduce PromptEval, a method for efficient multi-prompt evaluation of LLMs.
    With a small number of evaluations, PromptEval estimates performance across different
    prompt templates. Our approach is grounded in robust theoretical foundations and
    utilizes well-established models from the fields of educational assessment and
    psychometrics, such as Item Response Theory (IRT) (Cai et al., [2016](#bib.bib4);
    Van der Linden, [2018](#bib.bib37); Brzezińska, [2020](#bib.bib3); Lord et al.,
    [1968](#bib.bib22)). Our method is based on a *parametric* IRT model that allows
    borrowing strength across examples and prompt templates to produce accurate estimates
    of all considered prompts with an evaluation budget comparable to evaluating a
    single prompt. In Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Efficient multi-prompt
    evaluation of LLMs"), we demonstrate the ability of our method to jointly estimate
    various performance quantiles across 100 prompt templates with evaluation budget
    ranging from one to four times of a conventional single-prompt evaluation on MMLU
    (Hendrycks et al., [2020](#bib.bib13)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了 PromptEval，一种高效的多提示评估 LLM 的方法。通过少量评估，PromptEval 能够估计不同提示模板下的性能。我们的方法基于稳健的理论基础，并利用了教育评估和心理测量学领域中的成熟模型，如项目反应理论（IRT）（Cai
    等，[2016](#bib.bib4)；Van der Linden，[2018](#bib.bib37)；Brzezińska，[2020](#bib.bib3)；Lord
    等，[1968](#bib.bib22)）。我们的方法基于*参数化* IRT 模型，允许在示例和提示模板之间借用力量，从而在与评估单一提示相当的预算下，产生所有考虑的提示的准确估计。在图
    [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Efficient multi-prompt evaluation of LLMs")中，我们展示了我们的方法在评估预算从传统的单一提示评估的1倍到4倍范围内，对100个提示模板的不同性能分位数进行联合估计的能力。
- en: Performance distribution across prompts can be used to accommodate various contexts
    when comparing LLMs (Choshen et al., [2024](#bib.bib6)). For example, it can be
    used to compute mean as suggested by Mizrahi et al. ([2023](#bib.bib24)). One
    can also use performance distributions directly to compare LLMs via various notions
    of stochastic dominance for risk-sensitive scenarios (Nitsure et al., [2023](#bib.bib25)).
    Here we primarily focus on the full distribution and its quantiles as they provide
    a flexible statistic that can inform decisions in varying contexts. For instance,
    a typical model performance corresponds to a median (50% quantile), 95% quantile
    can be interpreted as performance achievable by an expert prompt engineer, while
    5% quantile is of interest in consumer-facing applications to quantify low-end
    performance for a user not familiar with prompt engineering. We also demonstrate
    (§[5](#S5 "5 Assessing multi-prompt evaluation strategies ‣ Efficient multi-prompt
    evaluation of LLMs")) how our method can be used to improve best prompt identification
    (Shi et al., [2024](#bib.bib33)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 跨提示的性能分布可以用于在比较LLMs时适应各种情境（Choshen et al., [2024](#bib.bib6)）。例如，它可以用于计算平均值，如Mizrahi
    et al. ([2023](#bib.bib24))所建议的。还可以通过各种随机主导概念直接使用性能分布来比较LLMs，以应对风险敏感场景（Nitsure
    et al., [2023](#bib.bib25)）。在这里，我们主要关注完整分布及其分位数，因为它们提供了可以在不同情境下做出决策的灵活统计信息。例如，典型模型性能对应于中位数（50%分位数），95%分位数可以解释为专家提示工程师可实现的性能，而5%分位数在面向消费者的应用中用于量化对提示工程不熟悉的用户的低端性能。我们还展示了（§[5](#S5
    "5 Assessing multi-prompt evaluation strategies ‣ Efficient multi-prompt evaluation
    of LLMs")）我们的方法如何用于改进最佳提示识别（Shi et al., [2024](#bib.bib33)）。
- en: 'Our main contributions are:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要贡献包括：
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose (§[3](#S3 "3 Performance distribution and quantiles estimation ‣
    Efficient multi-prompt evaluation of LLMs")) a novel method called PromptEval
    which permits efficient multi-prompt evaluation of LLMs across different prompt
    templates with a limited number of evaluations.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种称为PromptEval的新方法，该方法允许在有限的评估次数下高效地对不同提示模板进行LLMs的多提示评估（§[3](#S3 "3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")）。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We theoretically show (§[4](#S4 "4 Theoretical guarantees ‣ Efficient multi-prompt
    evaluation of LLMs")) that PromptEval has desirable statistical properties such
    as consistency in estimating performance distribution and its quantiles.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们从理论上证明了PromptEval具有理想的统计性质，例如在估计性能分布及其分位数时的一致性（§[4](#S4 "4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs")）。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We practically demonstrate (§[5](#S5 "5 Assessing multi-prompt evaluation strategies
    ‣ Efficient multi-prompt evaluation of LLMs")) efficacy of PromptEval in estimating
    performance across 100+ prompts and finding the best-performing prompt for various
    LLMs using data derived from three popular benchmarks: MMLU (Hendrycks et al.,
    [2020](#bib.bib13)), BIG-bench Hard (BBH) (Suzgun et al., [2022](#bib.bib36)),
    and LMentry (Efrat et al., [2022](#bib.bib9)).'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们实际演示了PromptEval在估计100多个提示的性能及寻找各种LLMs的最佳提示方面的有效性，使用的数据来自三个流行的基准：MMLU（Hendrycks
    et al., [2020](#bib.bib13)）、BIG-bench Hard (BBH)（Suzgun et al., [2022](#bib.bib36)）和LMentry（Efrat
    et al., [2022](#bib.bib9)）（§[5](#S5 "5 Assessing multi-prompt evaluation strategies
    ‣ Efficient multi-prompt evaluation of LLMs")）。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct the first large-scale study of prompt sensitivity of 15 popular open-source
    LLMs on MMLU. We present our findings based on evaluating 100 prompt templates
    in Section [6](#S6 "6 Analysis of prompt sensitivity on MMLU ‣ Efficient multi-prompt
    evaluation of LLMs") and will release the evaluation data.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对15种流行的开源LLMs在MMLU上的提示敏感性进行了首次大规模研究。我们在第[6](#S6 "6 Analysis of prompt sensitivity
    on MMLU ‣ Efficient multi-prompt evaluation of LLMs")节中展示了基于100个提示模板的评估结果，并将发布评估数据。
- en: 1.1 Related work
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 相关工作
- en: LLMs’ sensitivity to prompt templates. The sensitivity of Large Language Models
    (LLMs) to the prompts is well-documented. For example, Sclar et al. ([2023](#bib.bib32))
    revealed that subtle variations in prompt templates in few-shot settings can lead
    to significant performance discrepancies among several open-source LLMs, with
    differences as large as 76 accuracy points in tasks from the SuperNaturalInstructions
    dataset (Wang et al., [2022](#bib.bib41)). Additionally, they report that the
    performance of different prompt templates tends to correlate weakly between models.
    This finding challenges the reliability of evaluation methods that depend on a
    single prompt template. To measure LLMs sensitivity, the researchers suggested
    calculating a “performance spread,” which represents the difference between the
    best and worst performances observed. Mizrahi et al. ([2023](#bib.bib24)) conducted
    a complementary analysis using state-of-the-art models and subsets of BigBench
    and LMentry (Srivastava et al., [2022](#bib.bib34); Efrat et al., [2022](#bib.bib9)).
    The authors arrive at similar conclusions with respect to LLMs’ sensitivity to
    the used prompt templates and empirically showed that the LLM ranking considering
    different formats are usually weakly or intermediately correlated with each other.
    As a solution to the lack of robustness in LLM evaluation, the authors propose
    the use of summary statistics, as the average performance, for LLM evaluation.
    Some other works, e.g., Voronov et al. ([2024](#bib.bib40)); Weber et al. ([2023b](#bib.bib43),
    [a](#bib.bib42)), show that even when in-context examples are given to the models,
    the prompt templates can have a big impact on the final numbers, sometimes reducing
    the performance of the strongest model in their analyses to a random guess level
    (Voronov et al., [2024](#bib.bib40)). In a different direction, Shi et al. ([2024](#bib.bib33))
    acknowledges that different prompt templates have different performances and proposes
    using best-arm-identification to efficiently select the best template for an application
    at hand. One major bottleneck is still on how to efficiently compute the performance
    distribution for LLMs over many prompt templates; we tackle this problem.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）对提示模板的敏感性。大型语言模型（LLMs）对提示的敏感性已有充分记录。例如，Sclar 等人（[2023](#bib.bib32)）揭示了在少量样本设置中，提示模板的微小变化可能导致几个开源
    LLM 的性能出现显著差异，差异达到 76 个准确度点，这些任务来自 SuperNaturalInstructions 数据集（Wang 等人，[2022](#bib.bib41)）。此外，他们报告说，不同提示模板的性能在模型之间的相关性往往较弱。这一发现挑战了依赖单一提示模板的评估方法的可靠性。为了测量
    LLM 的敏感性，研究人员建议计算“性能分布”，这表示观察到的最佳和最差表现之间的差异。Mizrahi 等人（[2023](#bib.bib24)）使用最先进的模型和
    BigBench 及 LMentry 的子集（Srivastava 等人，[2022](#bib.bib34)；Efrat 等人，[2022](#bib.bib9)）进行了补充分析。作者得出了与
    LLM 对所用提示模板的敏感性有关的类似结论，并实证显示考虑不同格式的 LLM 排名通常相关性较弱或中等。作为解决 LLM 评估中鲁棒性不足的方案，作者建议使用总结统计量，如平均性能，进行
    LLM 评估。其他一些研究，例如 Voronov 等人（[2024](#bib.bib40)）；Weber 等人（[2023b](#bib.bib43)，[a](#bib.bib42)），显示即使给模型提供了上下文示例，提示模板仍能对最终结果产生重大影响，有时会将其分析中最强模型的性能降低到随机猜测水平（Voronov
    等人，[2024](#bib.bib40)）。在另一个方向上，Shi 等人（[2024](#bib.bib33)）认识到不同提示模板具有不同的性能，并建议使用最佳臂识别来有效选择适用于当前应用的最佳模板。一个主要瓶颈仍然是如何有效计算
    LLM 在许多提示模板上的性能分布；我们正在解决这个问题。
- en: Efficient evaluation of LLMs. The escalating size of models and datasets has
    led to increased evaluation costs. To streamline evaluations, Ye et al. ([2023b](#bib.bib46))
    considered minimizing the number of *tasks* within Big-bench (Srivastava et al.,
    [2022](#bib.bib34)). Additionally, Perlitz et al. ([2023](#bib.bib26)) observed
    that evaluations on HELM (Liang et al., [2022](#bib.bib21)) rely on diversity
    across datasets, though the quantity of examples currently utilized is unnecessarily
    large. Perlitz et al. ([2023](#bib.bib26)) also highlighted the problems in evaluating
    with insufficient prompts and called to evaluate on more, suggesting evaluating
    the typical behavior by sampling prompts and examples together. To accelerate
    evaluations for classification tasks, Vivek et al. ([2023](#bib.bib39)) suggested
    clustering evaluation examples based on model confidence in the correct class.
    More recently, Polo et al. ([2024](#bib.bib27)) empirically showed that it is
    possible to shrink the size of modern LLM benchmarks and still retain good estimates
    for LLMs’ performances. Despite these advancements in streamlining LLM evaluations,
    there are no other works that propose a general and efficient multi-prompt evaluation
    method to the best of our knowledge.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 高效评估LLMs。模型和数据集规模的不断增加导致了评估成本的上升。为了简化评估，Ye等人（[2023b](#bib.bib46)）考虑了在Big-bench（Srivastava等人，[2022](#bib.bib34)）中最小化*任务*的数量。此外，Perlitz等人（[2023](#bib.bib26)）观察到，HELM（Liang等人，[2022](#bib.bib21)）上的评估依赖于数据集的多样性，但当前使用的样本数量过于庞大。Perlitz等人（[2023](#bib.bib26)）还指出了在提示不足的情况下评估的问题，并呼吁在更多的提示上进行评估，建议通过同时抽样提示和示例来评估典型行为。为了加速分类任务的评估，Vivek等人（[2023](#bib.bib39)）建议基于模型在正确类别中的置信度对评估示例进行聚类。最近，Polo等人（[2024](#bib.bib27)）通过实验证明，缩小现代LLM基准的规模仍然可以保留对LLMs性能的良好估计。尽管在简化LLM评估方面取得了这些进展，但据我们所知，还没有其他工作提出一个通用且高效的多提示评估方法。
- en: Item response theory (IRT). IRT (Cai et al., [2016](#bib.bib4); Van der Linden,
    [2018](#bib.bib37); Brzezińska, [2020](#bib.bib3); Lord et al., [1968](#bib.bib22))
    is a collection of statistical models initially developed in psychometrics to
    assess individuals’ latent abilities through standardized tests but with increasing
    importance in the fields of artificial intelligence and natural language processing
    (NLP). For example, Lalor et al. ([2016](#bib.bib18)) used IRT’s latent variables
    to measure language model abilities, Vania et al. ([2021](#bib.bib38)) applied
    IRT to benchmark language models and examine the saturation of benchmarks, and
    Rodriguez et al. ([2021](#bib.bib31)) explored various uses of IRT with language
    models, including predicting responses to unseen items, categorizing items by
    difficulty, and ranking models. Recently, Polo et al. ([2024](#bib.bib27)) suggested
    using IRT for efficient LLM performance evaluation, introducing the Performance-IRT
    (pIRT) estimator to evaluate LLMs. Our quantile estimation methodology is built
    upon pIRT.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 项目反应理论（IRT）。IRT（Cai等人，[2016](#bib.bib4)；Van der Linden，[2018](#bib.bib37)；Brzezińska，[2020](#bib.bib3)；Lord等人，[1968](#bib.bib22)）是一组统计模型，最初在心理测量学中开发，用于通过标准化测试评估个体的潜在能力，但在人工智能和自然语言处理（NLP）领域中的重要性不断增加。例如，Lalor等人（[2016](#bib.bib18)）使用IRT的潜在变量来衡量语言模型的能力，Vania等人（[2021](#bib.bib38)）将IRT应用于基准语言模型并检查基准的饱和度，Rodriguez等人（[2021](#bib.bib31)）探索了IRT与语言模型的各种应用，包括预测对未见项目的响应、按难度对项目进行分类和排名模型。最近，Polo等人（[2024](#bib.bib27)）建议使用IRT进行高效的LLM性能评估，引入了Performance-IRT（pIRT）估计器来评估LLMs。我们的分位数估计方法建立在pIRT基础上。
- en: 2 Problem statement
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 问题陈述
- en: In this section, we describe the setup we work on and what our objectives are.
    Consider that we want to evaluate a large language model (LLM) in a certain dataset
    composed of $J$, we can define its performance score as
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了我们所使用的设置和我们的目标是什么。假设我们想在由$J$组成的特定数据集上评估一个大型语言模型（LLM），我们可以将其性能评分定义为
- en: '|  | $\textstyle S_{i}\triangleq\frac{1}{J}\sum_{j\in\mathcal{J}}Y_{ij}.$ |  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle S_{i}\triangleq\frac{1}{J}\sum_{j\in\mathcal{J}}Y_{ij}.$ |  |'
- en: The performance scores $S_{i}$’s can have a big variability, making the LLM
    evaluation reliant on the prompt choice. To have a comprehensive evaluation of
    the LLM, we propose computing the full *distribution of performances* and its
    corresponding quantile function, i.e.,
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 性能评分$S_{i}$可能有很大的变异性，使得LLM评估依赖于提示选择。为了对LLM进行全面评估，我们建议计算性能的完整*分布*及其对应的分位数函数，即，
- en: '|  | $\textstyle F(x)\triangleq\frac{1}{I}\sum_{i\in\mathcal{I}}\mathds{1}_{[S_{i},\infty)}(x)~{}~{}\text{
    and }~{}~{}Q(p)\triangleq\inf\{x\in{\mathbb{R}}:F(x)\geq p\}.$ |  | (2.1) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle F(x)\triangleq\frac{1}{I}\sum_{i\in\mathcal{I}}\mathds{1}_{[S_{i},\infty)}(x)~{}~{}\text{
    和 }~{}~{}Q(p)\triangleq\inf\{x\in{\mathbb{R}}:F(x)\geq p\}.$ |  | (2.1) |'
- en: The main challenge in obtaining this distribution is that it can be very expensive
    since the exact values for the performance scores $S_{i}$).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 获得这个分布的主要挑战在于它可能非常昂贵，因为性能评分 $S_{i}$ 的精确值。
- en: 3 Performance distribution and quantiles estimation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 性能分布和分位数估计
- en: We propose borrowing strength across prompt templates and examples to produce
    accurate estimates for the performance distribution and its quantile function.
    To achieve that, we need a model for the correctness scores $Y_{ij}$’s and then
    we introduce our estimators for the performance distribution and quantile functions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议借用不同的提示模板和示例的优势，以产生准确的性能分布估计及其分位数函数。为了实现这一点，我们需要一个针对正确性评分 $Y_{ij}$ 的模型，并且我们介绍了用于性能分布和分位数函数的估计器。
- en: 3.1 The correctness model
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 正确性模型
- en: We assume the observations $Y_{ij}$’s are independently sampled from a Bernoulli
    model parameterized by prompt/example-specific parameters. That is, we assume
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设观察到的 $Y_{ij}$ 是从由提示/示例特定参数参数化的伯努利模型中独立采样的。也就是说，我们假设
- en: '|  | $\displaystyle Y_{ij}\sim\text{Bernoulli}(\mu_{ij}),$ |  | (3.1) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Y_{ij}\sim\text{Bernoulli}(\mu_{ij}),$ |  | (3.1) |'
- en: where $\mu_{ij}$’s and some categorization or content of each of the examples
    in the case of $z_{j}$. That is, our model assumes that
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mu_{ij}$ 和每个示例的某些分类或内容在 $z_{j}$ 的情况下。也就是说，我们的模型假设
- en: '|  | $1$2 |  | (3.2) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (3.2) |'
- en: The functions $f_{\psi}$ is small, i.e., only a few evaluations are carried
    out. This degradation in the quality of the estimates can directly affect the
    quality of the performance distribution estimates. Finally, we fit the parameters
    $\psi$, by maximizing the log-likelihood of the observed data (negative cross-entropy
    loss), i.e.,
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 $f_{\psi}$ 的规模很小，即只进行了少量评估。估计质量的下降会直接影响性能分布估计的质量。最后，我们通过最大化观察数据的对数似然（负交叉熵损失）来拟合参数
    $\psi$，即：
- en: '|  | $1$2 |  | (3.3) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (3.3) |'
- en: Realize that fitting the model with linear/affine $f_{\psi}$ as the covariates.
    In the experiments Section [5](#S5 "5 Assessing multi-prompt evaluation strategies
    ‣ Efficient multi-prompt evaluation of LLMs"), we explore some different options
    of covariates for both templates and examples.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 意识到用线性/仿射 $f_{\psi}$ 作为协变量进行模型拟合。在实验部分 [5](#S5 "5 评估多提示评估策略 ‣ 高效的多提示评估 LLMs")
    中，我们探索了模板和示例的不同协变量选项。
- en: 3.2 Performance distribution and quantiles estimation using the correctness
    model
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 使用正确性模型进行性能分布和分位数估计
- en: The model in ([3.1](#S3.E1 "In 3.1 The correctness model ‣ 3 Performance distribution
    and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")) can be
    naturally used for performance estimation. That is, after observing $Y_{\mathcal{E}}$,
    is given by the following conditional expectation
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在 ([3.1](#S3.E1 "在 3.1 正确性模型 ‣ 3 性能分布和分位数估计 ‣ 高效的多提示评估 LLMs")) 中可以自然地用于性能估计。即，在观察到
    $Y_{\mathcal{E}}$ 后，给定以下条件期望值
- en: '|  | $1$2 |  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: 'where $\mathcal{J}_{i}\triangleq\{j\in\mathcal{J}:(i,j)\in\mathcal{E}\}$:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{J}_{i}\triangleq\{j\in\mathcal{J}:(i,j)\in\mathcal{E}\}$：
- en: '|  | $1$2 |  | (3.4) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (3.4) |'
- en: The basic version of this estimator, when no elaborate covariates (e.g., embeddings)
    are included, is known as the Performance-IRT (pIRT) estimator (Polo et al., [2024](#bib.bib27)).
    We can apply our extended version of pIRT, which we call X-pIRT, to estimate the
    performance distribution across prompt templates. After observing $Y_{\mathcal{E}}$.
    Then, we define our estimators for the distribution of performances and its corresponding
    quantile function [2.1](#S2.E1 "In 2 Problem statement ‣ Efficient multi-prompt
    evaluation of LLMs") as
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个估计器的基本版本，当没有包含复杂的协变量（例如，嵌入）时，被称为性能-IRT（pIRT）估计器（Polo 等，[2024](#bib.bib27)）。我们可以应用扩展版本的
    pIRT，称为 X-pIRT，以估计不同提示模板下的性能分布。在观察到 $Y_{\mathcal{E}}$ 之后，我们定义了性能分布及其相应的分位数函数的估计器
    [2.1](#S2.E1 "在 2 问题陈述 ‣ 高效的多提示评估 LLMs") 如下：
- en: '|  | $1$2 |  | (3.5) |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (3.5) |'
- en: We name the procedure of obtaining $\hat{F}$ as PromptEval and summarize it
    in Algorithm [1](#algorithm1 "In 3.2 Performance distribution and quantiles estimation
    using the correctness model ‣ 3 Performance distribution and quantiles estimation
    ‣ Efficient multi-prompt evaluation of LLMs").
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获得 $\hat{F}$ 的过程称为 PromptEval，并在算法 [1](#algorithm1 "在 3.2 性能分布和分位数估计中使用正确性模型
    ‣ 3 性能分布和分位数估计 ‣ 高效多提示评估 LLMs") 中总结它。
- en: '1 Input: (i) $Y_{\mathcal{E}}$ ([3.4](#S3.E4 "In 3.2 Performance distribution
    and quantiles estimation using the correctness model ‣ 3 Performance distribution
    and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")).Compute
    estimates'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '1 输入: (i) $Y_{\mathcal{E}}$ ([3.4](#S3.E4 "在 3.2 性能分布和分位数估计中使用正确性模型 ‣ 3 性能分布和分位数估计
    ‣ 高效多提示评估 LLMs")).计算估计值'
- en: '|  | $\textstyle\hat{F}(\cdot)\triangleq\frac{1}{I}\sum_{i\in\mathcal{I}}\mathds{1}_{[\hat{S}_{i},\infty)}(\cdot)$
    |  |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle\hat{F}(\cdot)\triangleq\frac{1}{I}\sum_{i\in\mathcal{I}}\mathds{1}_{[\hat{S}_{i},\infty)}(\cdot)$
    |  |'
- en: '|  | $\textstyle\hat{Q}(\cdot)\triangleq\inf\{x\in{\mathbb{R}}:\hat{F}(x)\geq\cdot\}$
    |  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle\hat{Q}(\cdot)\triangleq\inf\{x\in{\mathbb{R}}:\hat{F}(x)\geq\cdot\}$
    |  |'
- en: return  $\hat{F}$.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 $\hat{F}$。
- en: Algorithm 1 PromptEval
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 PromptEval
- en: '1 Input: (i) sets $\mathcal{I}$.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '1 输入: (i) 集合 $\mathcal{I}$。'
- en: Algorithm 2 Two-way balanced sampling
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 双向平衡采样
- en: Sampling $Y_{\mathcal{E}}$
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 采样 $Y_{\mathcal{E}}$
- en: 'We have assumed $Y_{\mathcal{E}}$ giving the same sampling probability to all
    entries. This option is, however, suboptimal because of its high instability:
    with a high chance, there will be some prompt formats (or examples) with a very
    low number of evaluations while others will have many. A more stable solution
    is given by Algorithm [2](#algorithm2 "In 3.2 Performance distribution and quantiles
    estimation using the correctness model ‣ 3 Performance distribution and quantiles
    estimation ‣ Efficient multi-prompt evaluation of LLMs"), which balances the number
    of times each prompt format and examples are evaluated. Algorithm [2](#algorithm2
    "In 3.2 Performance distribution and quantiles estimation using the correctness
    model ‣ 3 Performance distribution and quantiles estimation ‣ Efficient multi-prompt
    evaluation of LLMs") can be seen as two-way stratified random sampling in which
    the number of examples observed for each prompt format is (roughly) the same and
    the number of prompt formats that observe each one of the examples is (roughly)
    the same.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设 $Y_{\mathcal{E}}$ 给所有条目相同的采样概率。然而，这种选择并不是最优的，因为它的不稳定性很高：有很大的可能性会出现一些提示格式（或示例）被评估的次数非常少，而其他的则会有很多。一个更稳定的解决方案是由算法
    [2](#algorithm2 "在 3.2 性能分布和分位数估计中使用正确性模型 ‣ 3 性能分布和分位数估计 ‣ 高效多提示评估 LLMs") 给出的，它平衡了每个提示格式和示例被评估的次数。算法
    [2](#algorithm2 "在 3.2 性能分布和分位数估计中使用正确性模型 ‣ 3 性能分布和分位数估计 ‣ 高效多提示评估 LLMs") 可以看作是双向分层随机抽样，其中每个提示格式观察到的示例数量（大致）相同，并且观察到每个示例的提示格式数量（大致）相同。
- en: 4 Theoretical guarantees
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 理论保证
- en: In this section, we claim the consistency of the distribution and quantile estimators
    detailed in Algorithm [1](#algorithm1 "In 3.2 Performance distribution and quantiles
    estimation using the correctness model ‣ 3 Performance distribution and quantiles
    estimation ‣ Efficient multi-prompt evaluation of LLMs") as $I,J\to\infty$, which
    can be useful beyond this work.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们声称分布和分位数估计器在算法 [1](#algorithm1 "在 3.2 性能分布和分位数估计中使用正确性模型 ‣ 3 性能分布和分位数估计
    ‣ 高效多提示评估 LLMs") 中详细说明的在 $I,J\to\infty$ 时的一致性，这在本研究之外也可能是有用的。
- en: We start by assuming that the covariates are uniformly bounded.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从假设协变量是均匀有界的开始。
- en: Condition 4.1.
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 条件 4.1.
- en: There is a universal constant $$c>.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个普适常数 $$c>。
- en: The next condition requires the number of unseen examples to increase sufficiently
    fast as $I,J\to\infty$, which is a realistic condition under the low-budget setup.
    Weaker versions of this condition are possible; we adopt this one because it makes
    our proof simpler.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个条件要求未见示例的数量随着 $I,J\to\infty$ 增加得足够快，这在低预算设置下是一个现实条件。这个条件的弱版本是可能的；我们采用这个条件是因为它使我们的证明更简单。
- en: Condition 4.2.
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 条件 4.2.
- en: Assume (i) $m=|\mathcal{J}\setminus\mathcal{J}_{i}|$.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 (i) $m=|\mathcal{J}\setminus\mathcal{J}_{i}|$。
- en: The third condition requires the model we work with to be correctly specified
    and the maximum likelihood estimator defined in ([3.3](#S3.E3 "In 3.1 The correctness
    model ‣ 3 Performance distribution and quantiles estimation ‣ Efficient multi-prompt
    evaluation of LLMs")) to be consistent as $I,J\to\infty$ is well-studied and holds
    under mild conditions when the dimensions of the covariates are fixed; see, for
    example, Fahrmeir and Kaufmann ([1985](#bib.bib10)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第三条条件要求我们使用的模型需要正确指定，并且在([3.3](#S3.E3 "In 3.1 The correctness model ‣ 3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs"))中定义的最大似然估计量在$I,J\to\infty$时一致，这已经被充分研究，并且在协变量维度固定的情况下在温和条件下成立；例如，参见Fahrmeir和Kaufmann
    ([1985](#bib.bib10))。
- en: Condition 4.3.
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 条件4.3。
- en: The data point $Y_{ij}$.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点$Y_{ij}$。
- en: We now introduce the main result in Theorem [4.4](#S4.Thmtheorem4 "Theorem 4.4\.
    ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs"), which
    shows the consistency of the distribution and quantile functions estimators introduced
    in Algorithm [1](#algorithm1 "In 3.2 Performance distribution and quantiles estimation
    using the correctness model ‣ 3 Performance distribution and quantiles estimation
    ‣ Efficient multi-prompt evaluation of LLMs"). See Appendix [F](#A6 "Appendix
    F Theoretical results ‣ Efficient multi-prompt evaluation of LLMs") for the proof.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在介绍定理[4.4](#S4.Thmtheorem4 "Theorem 4.4\. ‣ 4 Theoretical guarantees ‣ Efficient
    multi-prompt evaluation of LLMs")中的主要结果，该结果展示了算法[1](#algorithm1 "In 3.2 Performance
    distribution and quantiles estimation using the correctness model ‣ 3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")中介绍的分布和分位数函数估计量的一致性。有关证明，请参见附录[F](#A6
    "Appendix F Theoretical results ‣ Efficient multi-prompt evaluation of LLMs")。
- en: Theorem 4.4.
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理4.4。
- en: Under conditions [4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs"), [4.2](#S4.Thmtheorem2 "Condition
    4.2\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs"),
    and [4.3](#S4.Thmtheorem3 "Condition 4.3\. ‣ 4 Theoretical guarantees ‣ Efficient
    multi-prompt evaluation of LLMs"), it is true that
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在条件[4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 Theoretical guarantees ‣ Efficient
    multi-prompt evaluation of LLMs")，[4.2](#S4.Thmtheorem2 "Condition 4.2\. ‣ 4 Theoretical
    guarantees ‣ Efficient multi-prompt evaluation of LLMs")和[4.3](#S4.Thmtheorem3
    "Condition 4.3\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation
    of LLMs")下，确实存在
- en: '|  | $\textstyle\left&#124;\hat{Q}_{\mathcal{I}}(p)-Q_{\mathcal{I}}(p)\right&#124;\to
    0\text{ in probability as }I,J\to\infty\text{ for any $p\in[0,1]$},$ |  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle\left|\hat{Q}_{\mathcal{I}}(p)-Q_{\mathcal{I}}(p)\right|\to
    0\text{ in probability as }I,J\to\infty\text{ for any $p\in[0,1]$},$ |  |'
- en: and that
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以及
- en: '|  | $W_{1}(F,\hat{F})\to 0\text{ in probability as }I,J\to\infty,$ |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $W_{1}(F,\hat{F})\to 0\text{ in probability as }I,J\to\infty,$ |  |'
- en: where $W_{1}(F,\hat{F})$.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 用$W_{1}(F,\hat{F})$。
- en: 5 Assessing multi-prompt evaluation strategies
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 评估多提示评估策略
- en: General assessment
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一般评估
- en: We assess the performance distribution and quantile function estimation methodology
    introduced in §[3](#S3 "3 Performance distribution and quantiles estimation ‣
    Efficient multi-prompt evaluation of LLMs") in estimating the performance of LLMs
    and different prompt formats on data from three popular benchmarks. For a given
    LLM and a dataset, we consider two evaluation steps. First, we compare the full
    performance distribution with the estimated distribution, i.e., in this case,
    all quantiles are considered. To compare the full performance distribution $F$,
    both defined in §[3](#S3 "3 Performance distribution and quantiles estimation
    ‣ Efficient multi-prompt evaluation of LLMs"), we use the Wasserstein 1-distance
    which is equivalent to the average quantile estimation error in this case, i.e.,
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了§[3](#S3 "3 Performance distribution and quantiles estimation ‣ Efficient
    multi-prompt evaluation of LLMs")中介绍的性能分布和分位数函数估计方法在估计LLMs和不同提示格式在三个流行基准上的性能的效果。对于给定的LLM和数据集，我们考虑两个评估步骤。首先，我们将完整的性能分布与估计分布进行比较，即在这种情况下，所有的分位数都被考虑。为了比较完整的性能分布$F$，两个定义在§[3](#S3
    "3 Performance distribution and quantiles estimation ‣ Efficient multi-prompt
    evaluation of LLMs")中，我们使用Wasserstein 1-距离，这在这种情况下等同于平均分位数估计误差，即，
- en: '|  | $\textstyle W_{1}(F,\hat{F})$ |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle W_{1}(F,\hat{F})$ |  |'
- en: where $S_{(i)}$ to measure the quality of our estimations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 用$S_{(i)}$来衡量我们估计的质量。
- en: Data
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据
- en: 'We use data derived from three popular benchmarks: MMLU (Hendrycks et al.,
    [2020](#bib.bib13)), BIG-bench Hard (BBH) (Suzgun et al., [2022](#bib.bib36)),
    and LMentry (Efrat et al., [2022](#bib.bib9)). In the following, we give more
    details about each one of the used datasets.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用来自三个流行基准的数据：MMLU (Hendrycks等，[2020](#bib.bib13))，BIG-bench Hard (BBH) (Suzgun等，[2022](#bib.bib36))，和LMentry
    (Efrat等，[2022](#bib.bib9))。下面，我们将详细介绍每个使用的数据集。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: MMLU is a multiple choice QA benchmark consisting of 57 subjects (tasks) comprising
    approximately 14k examples. We ran 15 different open-source LLMs (including different
    versions of Llama-3 (Meta, [2024](#bib.bib23)), Mistral (Jiang et al., [2023](#bib.bib14)),
    and Gemma (Gemma et al., [2024](#bib.bib11))) combined with 100 different prompt
    variations for each one of the MMLU tasks. We found that, within each one of the
    MMLU tasks, prompt templates can have great variability in their performances,
    making within-task analysis most suitable for assessing our method. More details
    and analysis of the collected data can be found in §[6](#S6 "6 Analysis of prompt
    sensitivity on MMLU ‣ Efficient multi-prompt evaluation of LLMs") and Appendix
    [G](#A7 "Appendix G Details MMLU data ‣ Efficient multi-prompt evaluation of LLMs").
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MMLU 是一个包含57个科目（任务）的多项选择问答基准，包含大约14k个示例。我们对15个不同的开源LLM（包括不同版本的 Llama-3（Meta，[2024](#bib.bib23)），Mistral（Jiang
    等人，[2023](#bib.bib14)），以及 Gemma（Gemma 等人，[2024](#bib.bib11)））进行了测试，并结合了每个MMLU任务的100种不同提示变体。我们发现，在每个MMLU任务中，提示模板的表现可能有很大变异，使得任务内部分析最适合评估我们的方法。更多详细信息和数据分析可以在
    §[6](#S6 "6 提示敏感性分析 ‣ LLMs的高效多提示评估") 和附录[G](#A7 "附录 G MMLU数据详细信息 ‣ LLMs的高效多提示评估")中找到。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: BIG-bench Hard (BBH) is a curated subset of BIG-bench (Srivastava et al., [2022](#bib.bib34)),
    containing challenging tasks on which LLMs underperform the average human score.
    For BBH, we use the evaluation scores released by Mizrahi et al. ([2023](#bib.bib24)).
    The evaluation data includes 11 open-source LLMs combined with a different number
    of prompt variations, ranging from 136 to 188 formats, for 15 tasks containing
    100 examples each.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BIG-bench Hard（BBH）是 BIG-bench（Srivastava 等人，[2022](#bib.bib34)）的一个精选子集，包含在这些任务中LLM的表现低于平均人类得分的挑战性任务。对于
    BBH，我们使用 Mizrahi 等人发布的评估分数（见[2023](#bib.bib24)）。评估数据包括11个开源LLM，并结合了不同数量的提示变体，范围从136到188种格式，涵盖15个任务，每个任务包含100个示例。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: LMentry consists of simple linguistic tasks designed to capture explainable
    and controllable linguistic phenomena. Like BBH, we use data generated by Mizrahi
    et al. ([2023](#bib.bib24)). The authors made available the full evaluation data
    from 16 open-source LLMs combined with a different number of prompt variations,
    ranging from 226 to 259 formats, for 10 tasks containing from 26 to 100 examples
    each.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LMentry 由旨在捕捉可解释和可控语言现象的简单语言任务组成。像 BBH 一样，我们使用 Mizrahi 等人生成的数据（见[2023](#bib.bib24)）。作者提供了来自16个开源LLM的完整评估数据，并结合了不同数量的提示变体，范围从226到259种格式，涵盖了10个任务，每个任务包含从26到100个示例。
- en: Methods and baselines
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 方法和基线
- en: 'We consider different variations of the model presented in ([3.2](#S3.E2 "In
    3.1 The correctness model ‣ 3 Performance distribution and quantiles estimation
    ‣ Efficient multi-prompt evaluation of LLMs")) coupled with Algorithm [1](#algorithm1
    "In 3.2 Performance distribution and quantiles estimation using the correctness
    model ‣ 3 Performance distribution and quantiles estimation ‣ Efficient multi-prompt
    evaluation of LLMs"); for all variations, we use linear $f_{\psi}$, however, upon
    preliminary tests with sentence transformer we didn’t observe improvements and
    chose to use one-hot-encoded vectors as in the basic Rasch model to represent
    examples. Next we detail the methods for obtaining the prompt covariates:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了模型的不同变体（见[3.2](#S3.E2 "在 3.1 正确性模型 ‣ 3 性能分布和分位数估计 ‣ LLMs的高效多提示评估")），并结合算法[1](#algorithm1
    "在 3.2 性能分布和分位数估计中使用正确性模型 ‣ 3 性能分布和分位数估计 ‣ LLMs的高效多提示评估")；对于所有变体，我们使用线性 $f_{\psi}$，然而，在与句子变换器的初步测试中，我们没有观察到改进，选择使用像基本Rasch模型中的one-hot编码向量来表示示例。接下来，我们详细描述获取提示协变量的方法：
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Prompt embeddings. We embed prompt templates using a pre-trained sentence transformer
    variant (Karpukhin et al., [2020](#bib.bib15)) and reduce their dimensionality
    to $d=25$ using PCA. This is the most general solution that also works well in
    practice. We call it EmbPT.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示嵌入。我们使用预训练的句子变换器变体（Karpukhin 等人，[2020](#bib.bib15)）对提示模板进行嵌入，并使用 PCA 将其维度减少到
    $d=25$。这是最通用的解决方案，在实践中也表现良好。我们称之为 EmbPT。
- en: •
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Fine-tuned prompt embeddings. Sentence transformers in general might not be
    most suitable for embedding prompt templates, thus we also consider fine-tuning
    BERT (Devlin et al., [2019](#bib.bib8)) as an embedder. To do so, we use evaluation
    data for all examples and prompt formats from a subset of LLMs (these LLMs are
    excluded when assessing the quality of our estimators) and fine-tune bert-base-uncased
    to predict $Y_{ij}$ as in ([3.3](#S3.E3 "In 3.1 The correctness model ‣ 3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")).
    We call this variation EmbFT and provide additional details in Appendix [I](#A9
    "Appendix I BERT fine-tuning details ‣ Efficient multi-prompt evaluation of LLMs").
    We acknowledge that obtaining such evaluation data for fine-tuning might be expensive,
    however, it might be justified in some applications if these embeddings provide
    sufficient savings for future LLM evaluations.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 微调提示嵌入。句子变换器通常可能不最适合嵌入提示模板，因此我们还考虑微调BERT（Devlin et al., [2019](#bib.bib8)）作为嵌入器。为此，我们使用来自一部分LLMs（这些LLMs在评估我们估计器的质量时被排除）的所有示例和提示格式的评估数据，并微调bert-base-uncased以预测$Y_{ij}$，如([3.3](#S3.E3
    "In 3.1 The correctness model ‣ 3 Performance distribution and quantiles estimation
    ‣ Efficient multi-prompt evaluation of LLMs")）所示。我们将这种变体称为EmbFT，并在附录[I](#A9 "Appendix
    I BERT fine-tuning details ‣ Efficient multi-prompt evaluation of LLMs")中提供了更多细节。我们承认，获得用于微调的评估数据可能很昂贵，但如果这些嵌入在未来的LLM评估中能提供足够的节省，某些应用中可能是合理的。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Discrete prompt covariates. For BBH and LMentry, we coded a heuristic function
    that captures frequently occurring differences in common prompting templates.
    Examples of such covariates are the number of line breaks or the count of certain
    special characters (e.g., dashes or colons). Each one of these covariates is encoded
    in $x_{i}$. A full list of the used heuristics is detailed in Appendix [J](#A10
    "Appendix J Heuristics for discrete features ‣ Efficient multi-prompt evaluation
    of LLMs"). For MMLU, we adopted approach of (Sclar et al., [2023](#bib.bib32))
    to generate prompt variations via templates (see Algorithm [3](#algorithm3 "In
    Appendix G Details MMLU data ‣ Efficient multi-prompt evaluation of LLMs")), which
    also provides a natural way to construct the covariates, e.g., the presence of
    dashes or colons.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 离散提示协变量。对于BBH和LMentry，我们编写了一个启发式函数，捕捉常见提示模板中的频繁差异。这些协变量的示例包括换行符的数量或某些特殊字符（例如破折号或冒号）的计数。这些协变量中的每一个都被编码在$x_{i}$中。所用启发式函数的完整列表在附录[J](#A10
    "Appendix J Heuristics for discrete features ‣ Efficient multi-prompt evaluation
    of LLMs")中详细说明。对于MMLU，我们采用了(Sclar et al., [2023](#bib.bib32))的方法，通过模板生成提示变体（见算法[3](#algorithm3
    "In Appendix G Details MMLU data ‣ Efficient multi-prompt evaluation of LLMs")），这也提供了一种自然的方式来构建协变量，例如破折号或冒号的存在。
- en: To the best of our knowledge, the methods introduced in §[3](#S3 "3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")
    are the first ones handling the problem of efficient evaluation of performance
    *distribution* of LLMs across multiple prompts. Thus, we compare different variations
    of our method with one natural baseline (“avg”) which estimates $S_{i}$. To make
    comparisons fair, we sample the data using Algorithm [2](#algorithm2 "In 3.2 Performance
    distribution and quantiles estimation using the correctness model ‣ 3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")
    for all methods and the baseline.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，§[3](#S3 "3 Performance distribution and quantiles estimation ‣ Efficient
    multi-prompt evaluation of LLMs")中介绍的方法是首个处理LLMs在多个提示下*分布*性能有效评估问题的方法。因此，我们将我们方法的不同变体与一个自然基准（“avg”），该基准估计$S_{i}$进行比较。为了公平比较，我们对所有方法和基准使用算法[2](#algorithm2
    "In 3.2 Performance distribution and quantiles estimation using the correctness
    model ‣ 3 Performance distribution and quantiles estimation ‣ Efficient multi-prompt
    evaluation of LLMs")对数据进行抽样。
- en: Key results
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 关键结果
- en: 'We investigate the effectiveness of the different variations of PromptEval
    (PE) against the “avg” baseline strategy in quantile estimation and overall performance
    distribution estimation across prompt templates. In total, we consider five variations
    of PromptEval: (i) PE-Rasch (model in ([3.2](#S3.E2 "In 3.1 The correctness model
    ‣ 3 Performance distribution and quantiles estimation ‣ Efficient multi-prompt
    evaluation of LLMs")) is a Rach model), (ii) PE-discrete (discrete covariates
    are used for prompt templates), (iii) PE-EmbPT (pre-trained LLM embeddings are
    used for prompt templates), and (iv) PE-EmbFT (fine-tuned LLM embeddings are used
    for prompt templates). Within each one of the benchmarks, we conduct a different
    experiment for each one of the tasks, LLMs, and 5 random seeds used when sampling
    $Y_{\mathcal{E}}$ to the total number of evaluations on MMLU.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了不同变体的PromptEval（PE）在分位数估计和跨提示模板的整体性能分布估计中的有效性，与“avg”基准策略进行比较。我们总共考虑了五种PromptEval变体：（i）PE-Rasch（模型见([3.2](#S3.E2
    "In 3.1 The correctness model ‣ 3 Performance distribution and quantiles estimation
    ‣ Efficient multi-prompt evaluation of LLMs") 是一个Rach模型），（ii）PE-discrete（对提示模板使用离散协变量），（iii）PE-EmbPT（对提示模板使用预训练的LLM嵌入），和（iv）PE-EmbFT（对提示模板使用微调的LLM嵌入）。在每个基准测试中，我们为每个任务、LLM和在采样$Y_{\mathcal{E}}$时使用的5个随机种子进行不同的实验，直到MMLU上的总评估次数。
- en: •
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Distribution estimation. Our results for quantile estimation can be seen in
    Figure [2](#S5.F2 "Figure 2 ‣ Key results ‣ 5 Assessing multi-prompt evaluation
    strategies ‣ Efficient multi-prompt evaluation of LLMs"). We see that, in general,
    all variations of PromptEval, including its simplest version (PE-Rasch), can do
    much better in distribution estimation when compared to the baseline. Among our
    methods, the ones that use covariates are the best ones.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分布估计。我们的分位数估计结果可以在图[2](#S5.F2 "Figure 2 ‣ Key results ‣ 5 Assessing multi-prompt
    evaluation strategies ‣ Efficient multi-prompt evaluation of LLMs")中查看。我们看到，一般来说，所有的PromptEval变体，包括其最简单的版本（PE-Rasch），在分布估计方面都表现得比基准方法要好。我们的方法中，使用协变量的方法是最好的。
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Quantile estimation. Our results for quantile estimation are presented in Figure
    [3](#S5.F3 "Figure 3 ‣ Key results ‣ 5 Assessing multi-prompt evaluation strategies
    ‣ Efficient multi-prompt evaluation of LLMs"). As before, even the simplest version
    of our method (PE-Rasch) does much better than the considered baseline. For all
    the other variations of PromptEval, estimating extreme quantiles is usually hard
    and needs more evaluations, while more central ones (e.g., median) can be accurately
    estimated with 200 evaluations, providing more than 100x compute saving in most
    cases. Regarding the different variations of PromptEval, we found that the pre-trained
    embeddings are robust across benchmarks, while the discrete covariates could not
    do well on LMentry data. Using covariates obtained via fine-tuning the BERT model
    provides some further improvements, for example, for extreme quantiles and small
    evaluation budget settings on MMLU. However, fine-tuning requires collecting large
    amounts of evaluation data and in most cases, we anticipate that it would be more
    practical to use PromptEval with pre-trained embedder and moderate evaluation
    budget instead.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分位数估计。我们的分位数估计结果呈现在图[3](#S5.F3 "Figure 3 ‣ Key results ‣ 5 Assessing multi-prompt
    evaluation strategies ‣ Efficient multi-prompt evaluation of LLMs")中。和之前一样，即使是我们方法的最简单版本（PE-Rasch）也比考虑的基准方法表现得要好。对于所有其他的PromptEval变体，估计极端分位数通常很困难，需要更多的评估，而更中心的分位数（例如，中位数）可以通过200次评估准确估计，在大多数情况下提供了超过100倍的计算节省。关于不同的PromptEval变体，我们发现预训练的嵌入在基准测试中表现稳健，而离散协变量在LMentry数据上效果不佳。通过微调BERT模型获得的协变量提供了一些进一步的改进，例如，在MMLU上的极端分位数和小评估预算设置下。然而，微调需要收集大量的评估数据，在大多数情况下，我们预期使用预训练的嵌入器和适中的评估预算的PromptEval会更实用。
- en: '![Refer to caption](img/339c804bfb471107de5493cab6972354.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/339c804bfb471107de5493cab6972354.png)'
- en: 'Figure 2: Performance distribution estimation errors measured with Wasserstein-1
    distance on three benchmarks.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：在三个基准测试上用Wasserstein-1距离测量的性能分布估计误差。
- en: '| ![Refer to caption](img/4b9fc4b09bf0d4be393cb923cc908b8b.png) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/4b9fc4b09bf0d4be393cb923cc908b8b.png) |'
- en: '| ![Refer to caption](img/f80d12df157d65be633f327f412367c3.png) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/f80d12df157d65be633f327f412367c3.png) |'
- en: '| ![Refer to caption](img/b2f12519f6c5acaa68557d6b791461d0.png) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| ![参考说明](img/b2f12519f6c5acaa68557d6b791461d0.png) |'
- en: 'Figure 3: Performance quantile estimation errors for varying quantiles (columns)
    and benchmarks (rows).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：不同分位数（列）和基准测试（行）的性能分位数估计误差。
- en: Best-prompt identification
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最佳提示识别
- en: '![Refer to caption](img/e2c284bee41b0662788f5cc701938dd1.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e2c284bee41b0662788f5cc701938dd1.png)'
- en: 'Figure 4: Best-prompt identification.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：最佳提示识别。
- en: The best-prompt identification task (Shi et al., [2024](#bib.bib33)) is to find
    the best prompt from a set of fixed templates, i.e., the one that gives the best
    performance for a task at hand. Shi et al. ([2024](#bib.bib33)) propose framing
    this problem as a bandit problem and using a linear model or an MLP to predict
    the performance of each prompt template. To apply PromptEval in this setting we
    use our model ([3.2](#S3.E2 "In 3.1 The correctness model ‣ 3 Performance distribution
    and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")) and X-pIRT
    to estimate how good each template is coupled with sequential elimination algorithm
    (Azizi et al., [2021](#bib.bib1)) (as in Shi et al. ([2024](#bib.bib33))) to select
    prompt-example pairs for evaluation in each round. In Figure [4](#S5.F4 "Figure
    4 ‣ Best-prompt identification ‣ 5 Assessing multi-prompt evaluation strategies
    ‣ Efficient multi-prompt evaluation of LLMs") we compare our PE to the baseline
    TRIPLE-GSE (Shi et al., [2024](#bib.bib33)) with a logistic regression performance
    predictor and the same three types of covariates (PE-OneHot corresponds to PE-Rasch
    in previous experiments). For all covariate choices, we show that using PromptEval
    for best-prompt identification results in lower regret, i.e., the performance
    of the best template minus the performance of the chosen template. We include
    the full results for other benchmarks and also apply TRIPLE-GSE with an MLP in
    Appendix [E](#A5 "Appendix E Extra results for best-prompt identification ‣ Efficient
    multi-prompt evaluation of LLMs").
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳提示识别任务（Shi et al., [2024](#bib.bib33)）是从一组固定模板中找到最佳提示，即在当前任务中表现最好的提示。Shi et
    al. ([2024](#bib.bib33)) 提出了将此问题框定为一个赌博问题，并使用线性模型或多层感知器（MLP）来预测每个提示模板的性能。为了在此设置中应用
    PromptEval，我们使用我们的模型（[3.2](#S3.E2 "In 3.1 The correctness model ‣ 3 Performance
    distribution and quantiles estimation ‣ Efficient multi-prompt evaluation of LLMs")）和
    X-pIRT 来估计每个模板的优劣，并结合顺序消除算法（Azizi et al., [2021](#bib.bib1)）（如 Shi et al. ([2024](#bib.bib33)）所述）在每轮中选择提示-示例对进行评估。在图
    [4](#S5.F4 "Figure 4 ‣ Best-prompt identification ‣ 5 Assessing multi-prompt evaluation
    strategies ‣ Efficient multi-prompt evaluation of LLMs") 中，我们将我们的 PE 与基线 TRIPLE-GSE
    (Shi et al., [2024](#bib.bib33)) 进行比较，后者使用逻辑回归性能预测器和相同的三种协变量（PE-OneHot 对应于之前实验中的
    PE-Rasch）。对于所有协变量选择，我们展示了使用 PromptEval 进行最佳提示识别能够降低遗憾，即最佳模板的性能减去所选模板的性能。我们包括了其他基准的完整结果，并在附录
    [E](#A5 "Appendix E Extra results for best-prompt identification ‣ Efficient multi-prompt
    evaluation of LLMs") 中应用了带有 MLP 的 TRIPLE-GSE。
- en: 6 Analysis of prompt sensitivity on MMLU
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 对 MMLU 上提示敏感性的分析
- en: Prior work reports strong sensitivity of LLMs to spurious prompt template changes
    (see Section [1.1](#S1.SS1 "1.1 Related work ‣ 1 Introduction ‣ Efficient multi-prompt
    evaluation of LLMs")). For example, Sclar et al. ([2023](#bib.bib32)) observe
    performance changes of up to 80% for Natural Instructions tasks (Wang et al.,
    [2022](#bib.bib41)) due to template changes. Despite its popularity, no such analysis
    exists for the MMLU dataset to date. We here provide an in-depth analysis of MMLU
    prompt sensitivity.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的工作报告了 LLM 对虚假提示模板变化的强烈敏感性（见第 [1.1](#S1.SS1 "1.1 Related work ‣ 1 Introduction
    ‣ Efficient multi-prompt evaluation of LLMs") 节）。例如，Sclar et al. ([2023](#bib.bib32))
    观察到由于模板变化，Natural Instructions 任务（Wang et al., [2022](#bib.bib41)）的性能变化高达 80%。尽管其受欢迎，但迄今为止还没有关于
    MMLU 数据集的类似分析。我们在此提供了对 MMLU 提示敏感性的深入分析。
- en: '![Refer to caption](img/04930ab753506829ad7ade3f67753e12.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/04930ab753506829ad7ade3f67753e12.png)'
- en: 'Figure 5: Accuracy spread across 57 subjects.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：57 个主题的准确性分布。
- en: Performance spread
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能分布
- en: When averaged across subjects, we observe relatively small performance spreads
    per LLM compared to other datasets in the literature (see Figure [12](#A8.F12
    "Figure 12 ‣ Appendix H Details MMLU spread analysis ‣ Efficient multi-prompt
    evaluation of LLMs") in the Appendix [H](#A8 "Appendix H Details MMLU spread analysis
    ‣ Efficient multi-prompt evaluation of LLMs")). For example, we can consistently
    identify Llama-3-70B-Instruct as the best performing model, independent of the
    prompt template. On the other hand, scores within individual subjects are highly
    inconsistent. Figure [5](#S6.F5 "Figure 5 ‣ 6 Analysis of prompt sensitivity on
    MMLU ‣ Efficient multi-prompt evaluation of LLMs") shows the distribution of prompt
    spreads (max-min acc.) across subjects per LLM. Most LLMs demonstrate a significant
    average spread of around 10% at the subject level.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当在各个主题中取平均时，我们观察到每个LLM的性能差异相对较小，与文献中的其他数据集相比（见附录[H](#A8 "Appendix H Details
    MMLU spread analysis ‣ Efficient multi-prompt evaluation of LLMs")中的图[12](#A8.F12
    "Figure 12 ‣ Appendix H Details MMLU spread analysis ‣ Efficient multi-prompt
    evaluation of LLMs")）。例如，我们可以一致地将Llama-3-70B-Instruct识别为表现最好的模型，无论提示模板如何。另一方面，单个主题内的分数高度不一致。图[5](#S6.F5
    "Figure 5 ‣ 6 Analysis of prompt sensitivity on MMLU ‣ Efficient multi-prompt
    evaluation of LLMs")展示了每个LLM在各个主题中的提示差异（最大-最小准确率）的分布。大多数LLM在主题层面的平均差异显著，约为10%。
- en: Template consistency
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模板一致性
- en: In practice, having consistently performing templates is highly relevant *within
    a single LLM* or *across LLMs* for the same subject. To evaluate the template
    consistency, we rank template performances either across subjects or across LLMs
    to then calculate the agreement across those rankings using Kendall’s $W$ (Kendall
    and Smith, [1939](#bib.bib16), inspired by Mizrahi et al. [2023](#bib.bib24)).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在**单一LLM**或**跨LLM**的相同主题中，模板的一致性表现非常相关。为了评估模板的一致性，我们对模板的表现进行排名，无论是跨主题还是跨LLM，然后使用Kendall’s
    $W$（Kendall和Smith，[1939](#bib.bib16)，受Mizrahi等人[2023](#bib.bib24)启发）计算这些排名的一致性。
- en: Within LLMs, we observe that Gemma-7B-it has a notably higher Kendall’s $W$
    of 0.45 than any other model, meaning a fixed set of prompts performs best across
    many subjects (for full results, see Table [1](#A8.T1 "Table 1 ‣ Appendix H Details
    MMLU spread analysis ‣ Efficient multi-prompt evaluation of LLMs") in the Appendix).
    Across LLMs, we do not observe high correlations within any of the subjects (see
    Figure [13](#A8.F13 "Figure 13 ‣ Appendix H Details MMLU spread analysis ‣ Efficient
    multi-prompt evaluation of LLMs") in Appendix [H](#A8 "Appendix H Details MMLU
    spread analysis ‣ Efficient multi-prompt evaluation of LLMs")). Hence, similar
    to previous findings (e.g. Sclar et al., [2023](#bib.bib32)), we do not identify
    any coherent template preferences across LLMs (for detailed results, see Appendix [H](#A8
    "Appendix H Details MMLU spread analysis ‣ Efficient multi-prompt evaluation of
    LLMs")).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM内部，我们观察到Gemma-7B-it的Kendall’s $W$高达0.45，明显高于其他模型，这意味着一组固定的提示在多个主题中表现最佳（完整结果见附录中的表[1](#A8.T1
    "Table 1 ‣ Appendix H Details MMLU spread analysis ‣ Efficient multi-prompt evaluation
    of LLMs")）。在LLM之间，我们没有观察到任何主题内的高相关性（见附录[H](#A8 "Appendix H Details MMLU spread
    analysis ‣ Efficient multi-prompt evaluation of LLMs")中的图[13](#A8.F13 "Figure
    13 ‣ Appendix H Details MMLU spread analysis ‣ Efficient multi-prompt evaluation
    of LLMs")）。因此，类似于以前的发现（例如Sclar等人，[2023](#bib.bib32)），我们没有识别出LLM之间任何连贯的模板偏好（详细结果见附录[H](#A8
    "Appendix H Details MMLU spread analysis ‣ Efficient multi-prompt evaluation of
    LLMs")）。
- en: 7 Conclusion
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: 'PromptEval enables a more comprehensive evaluation of LLMs. We hope that comparing
    distributions or quantiles across many prompt variants will enable more robust
    leaderboards and address the common concern of comparing LLMs with a single pre-defined
    prompt. Prior to our work, a major limitation of such evaluation was its cost.
    We demonstrated empirically across several popular benchmarks that our method
    can produce accurate performance distribution and quantile estimates at the cost
    of 2-4 single-prompt evaluations, out of hundreds possible. However, several questions
    remain: how to decide on the set of prompts for evaluation and how to best utilize
    our distribution estimates for comparison in various contexts. For the former,
    we utilized suggestions from prior work (Mizrahi et al., [2023](#bib.bib24); Sclar
    et al., [2023](#bib.bib32)) and for the latter, we primarily focused on quantiles
    as well-established robust performance measures.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: PromptEval 使得对大语言模型（LLMs）的评估更加全面。我们希望通过比较多种提示变体的分布或分位数，能够实现更稳健的排行榜，并解决使用单一预定义提示对
    LLMs 进行比较的常见问题。在我们之前的工作中，这种评估的主要限制是其成本。我们通过在多个流行基准测试中进行实证验证，展示了我们的方法可以以 2-4 次单一提示评估的成本（在可能的几百次中）来产生准确的性能分布和分位数估计。然而，仍然存在一些问题：如何决定用于评估的提示集合，以及如何在不同的背景下最佳利用我们的分布估计。对于前者，我们利用了之前工作的建议（Mizrahi
    et al., [2023](#bib.bib24); Sclar et al., [2023](#bib.bib32)），而对于后者，我们主要集中在分位数作为公认的稳健性能指标。
- en: Besides evaluation, another common problem in practice is finding the best prompt
    for a given task. Our method can be applied in this setting when there is a pre-defined
    set of candidate prompts (Figure [4](#S5.F4 "Figure 4 ‣ Best-prompt identification
    ‣ 5 Assessing multi-prompt evaluation strategies ‣ Efficient multi-prompt evaluation
    of LLMs")). However, several recent works (Prasad et al., [2023](#bib.bib28);
    Yang et al., [2023](#bib.bib44); Li and Wu, [2023](#bib.bib20); Ye et al., [2023a](#bib.bib45))
    demonstrate the benefits of dynamically generating new prompt candidates. For
    example, Prasad et al. ([2023](#bib.bib28)) propose an evolutionary algorithm
    that creates new prompts based on the ones that performed well at an earlier iteration.
    Extending PromptEval to accommodate an evolving set of prompt candidates is an
    interesting future work direction.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 除了评估，实践中另一个常见问题是找到适用于给定任务的最佳提示。当存在预定义的候选提示集合时，我们的方法可以在这种情况下应用（图 [4](#S5.F4 "Figure
    4 ‣ Best-prompt identification ‣ 5 Assessing multi-prompt evaluation strategies
    ‣ Efficient multi-prompt evaluation of LLMs")）。然而，最近的几项工作（Prasad et al., [2023](#bib.bib28);
    Yang et al., [2023](#bib.bib44); Li and Wu, [2023](#bib.bib20); Ye et al., [2023a](#bib.bib45)）展示了动态生成新提示候选的好处。例如，Prasad
    et al. ([2023](#bib.bib28)) 提出了一个进化算法，根据在早期迭代中表现良好的提示生成新提示。将 PromptEval 扩展以适应不断发展的提示候选集合是一个有趣的未来研究方向。
- en: 8 Acknowledgements
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 致谢
- en: This paper is based upon work supported by the National Science Foundation (NSF)
    under grants no. 2027737 and 2113373.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本文基于国家科学基金会（NSF）资助的工作，资助编号为 2027737 和 2113373。
- en: References
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Azizi et al. [2021] Mohammad Javad Azizi, Branislav Kveton, and Mohammad Ghavamzadeh.
    Fixed-budget best-arm identification in structured bandits. *arXiv preprint arXiv:2106.04763*,
    2021.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azizi et al. [2021] Mohammad Javad Azizi, Branislav Kveton, 和 Mohammad Ghavamzadeh.
    有限预算的最佳臂识别在结构性赌博问题中. *arXiv preprint arXiv:2106.04763*, 2021.
- en: Beeching et al. [2023] Edward Beeching, Clémentine Fourrier, Nathan Habib, Sheon
    Han, Nathan Lambert, Nazneen Rajani, Omar Sanseviero, Lewis Tunstall, and Thomas
    Wolf. Open llm leaderboard. [https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard),
    2023.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beeching et al. [2023] Edward Beeching, Clémentine Fourrier, Nathan Habib, Sheon
    Han, Nathan Lambert, Nazneen Rajani, Omar Sanseviero, Lewis Tunstall, 和 Thomas
    Wolf. Open llm leaderboard. [https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard),
    2023.
- en: Brzezińska [2020] Justyna Brzezińska. Item response theory models in the measurement
    theory. *Communications in Statistics-Simulation and Computation*, 49(12):3299–3313,
    2020.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brzezińska [2020] Justyna Brzezińska. 项目反应理论模型在测量理论中的应用. *Communications in
    Statistics-Simulation and Computation*, 49(12):3299–3313, 2020.
- en: Cai et al. [2016] Li Cai, Kilchan Choi, Mark Hansen, and Lauren Harrell. Item
    response theory. *Annual Review of Statistics and Its Application*, 3:297–321,
    2016.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai et al. [2016] Li Cai, Kilchan Choi, Mark Hansen, 和 Lauren Harrell. 项目反应理论.
    *Annual Review of Statistics and Its Application*, 3:297–321, 2016.
- en: Chen et al. [2023] Yunxiao Chen, Chengcheng Li, Jing Ouyang, and Gongjun Xu.
    Statistical inference for noisy incomplete binary matrix. *Journal of Machine
    Learning Research*, 24(95):1–66, 2023.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 [2023] Yunxiao Chen, Chengcheng Li, Jing Ouyang, 和 Gongjun Xu。噪声不完全二进制矩阵的统计推断。*机器学习研究杂志*，24(95)：1–66，2023年。
- en: 'Choshen et al. [2024] Leshem Choshen, Ariel Gera, Yotam Perlitz, Michal Shmueli-Scheuer,
    and Gabriel Stanovsky. Navigating the modern evaluation landscape: Considerations
    in benchmarks and frameworks for large language models (llms). In *International
    Conference on Language Resources and Evaluation*, 2024. URL [https://api.semanticscholar.org/CorpusID:269804253](https://api.semanticscholar.org/CorpusID:269804253).'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choshen 等人 [2024] Leshem Choshen, Ariel Gera, Yotam Perlitz, Michal Shmueli-Scheuer,
    和 Gabriel Stanovsky。导航现代评估格局：大型语言模型 (LLMs) 的基准和框架中的考虑因素。在 *国际语言资源与评估会议*，2024年。URL
    [https://api.semanticscholar.org/CorpusID:269804253](https://api.semanticscholar.org/CorpusID:269804253)。
- en: 'Clements et al. [2008] Douglas H Clements, Julie H Sarama, and Xiufeng H Liu.
    Development of a measure of early mathematics achievement using the rasch model:
    The research-based early maths assessment. *Educational Psychology*, 28(4):457–482,
    2008.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Clements 等人 [2008] Douglas H Clements, Julie H Sarama, 和 Xiufeng H Liu。使用 Rasch
    模型发展早期数学成就测量工具：基于研究的早期数学评估。*教育心理学*，28(4)：457–482，2008年。
- en: 'Devlin et al. [2019] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. Bert: Pre-training of deep bidirectional transformers for language
    understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    Volume 1 (Long and Short Papers)*, pages 4171–4186, 2019.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Devlin 等人 [2019] Jacob Devlin, Ming-Wei Chang, Kenton Lee, 和 Kristina Toutanova。Bert:
    用于语言理解的深度双向变换器的预训练。在 *2019年北美计算语言学协会会议论文集：人类语言技术，第1卷（长篇和短篇论文）*，第4171–4186页，2019年。'
- en: 'Efrat et al. [2022] Avia Efrat, Or Honovich, and Omer Levy. Lmentry: A language
    model benchmark of elementary language tasks. *arXiv preprint arXiv:2211.02069*,
    2022.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Efrat 等人 [2022] Avia Efrat, Or Honovich, 和 Omer Levy。Lmentry: 一种小型语言任务的语言模型基准。*arXiv
    预印本 arXiv:2211.02069*，2022年。'
- en: Fahrmeir and Kaufmann [1985] Ludwig Fahrmeir and Heinz Kaufmann. Consistency
    and asymptotic normality of the maximum likelihood estimator in generalized linear
    models. *The Annals of Statistics*, 13(1):342–368, 1985.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fahrmeir 和 Kaufmann [1985] Ludwig Fahrmeir 和 Heinz Kaufmann。广义线性模型中最大似然估计量的一致性和渐近正态性。*统计年鉴*，13(1)：342–368，1985年。
- en: 'Gemma et al. [2024] Team Gemma, Thomas Mesnard, Cassidy Hardin, Robert Dadashi,
    Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay
    Kale, Juliette Love, et al. Gemma: Open models based on gemini research and technology.
    *arXiv preprint arXiv:2403.08295*, 2024.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gemma 等人 [2024] Team Gemma, Thomas Mesnard, Cassidy Hardin, Robert Dadashi,
    Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay
    Kale, Juliette Love 等人。Gemma: 基于 Gemini 研究和技术的开放模型。*arXiv 预印本 arXiv:2403.08295*，2024年。'
- en: 'Georg [1960] Rasch Georg. Probabilistic models for some intelligence and attainment
    tests. *Copenhagen: Institute of Education Research*, 1960.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Georg [1960] Rasch Georg。某些智力和成就测试的概率模型。*哥本哈根：教育研究所*，1960年。
- en: Hendrycks et al. [2020] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language
    understanding. *arXiv preprint arXiv:2009.03300*, 2020.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks 等人 [2020] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas
    Mazeika, Dawn Song, 和 Jacob Steinhardt。测量大规模多任务语言理解。*arXiv 预印本 arXiv:2009.03300*，2020年。
- en: Jiang et al. [2023] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*, 2023.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人 [2023] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier 等人。Mistral 7b。*arXiv 预印本 arXiv:2310.06825*，2023年。
- en: 'Karpukhin et al. [2020] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval
    for open-domain question answering. In *Proceedings of the 2020 Conference on
    Empirical Methods in Natural Language Processing (EMNLP)*, pages 6769–6781, Online,
    November 2020\. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.550.
    URL [https://www.aclweb.org/anthology/2020.emnlp-main.550](https://www.aclweb.org/anthology/2020.emnlp-main.550).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karpukhin et al. [2020] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, 和 Wen-tau Yih。用于开放域问答的密集段落检索。发表于
    *2020年自然语言处理经验方法会议论文集（EMNLP）*，第6769–6781页，在线，2020年11月。计算语言学协会。doi: 10.18653/v1/2020.emnlp-main.550。网址
    [https://www.aclweb.org/anthology/2020.emnlp-main.550](https://www.aclweb.org/anthology/2020.emnlp-main.550)。'
- en: Kendall and Smith [1939] Maurice G Kendall and B Babington Smith. The problem
    of m rankings. *The annals of mathematical statistics*, 10(3):275–287, 1939.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kendall and Smith [1939] Maurice G Kendall 和 B Babington Smith。m排名问题。*数学统计年鉴*，10(3):275–287，1939年。
- en: 'Kingma and Ba [2014] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic
    optimization. *arXiv preprint arXiv:1412.6980*, 2014.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma and Ba [2014] Diederik P Kingma 和 Jimmy Ba。Adam：一种随机优化方法。*arXiv 预印本 arXiv:1412.6980*，2014年。
- en: Lalor et al. [2016] John P Lalor, Hao Wu, and Hong Yu. Building an evaluation
    scale using item response theory. In *Proceedings of the Conference on Empirical
    Methods in Natural Language Processing. Conference on Empirical Methods in Natural
    Language Processing*, volume 2016, page 648\. NIH Public Access, 2016.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lalor et al. [2016] John P Lalor, Hao Wu, 和 Hong Yu。使用项目反应理论构建评估量表。发表于 *自然语言处理经验方法会议论文集*，第2016卷，第648页。NIH公共访问，2016年。
- en: 'Li et al. [2023] Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan
    Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Alpacaeval:
    An automatic evaluator of instruction-following models. [https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval),
    2023.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2023] Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan
    Gulrajani, Carlos Guestrin, Percy Liang, 和 Tatsunori B. Hashimoto。Alpacaeval：一个自动化评估指令跟随模型的工具。
    [https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval)，2023年。
- en: 'Li and Wu [2023] Yujian Betterest Li and Kai Wu. Spell: Semantic prompt evolution
    based on a llm. *arXiv preprint arXiv:2310.01260*, 2023.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li and Wu [2023] Yujian Betterest Li 和 Kai Wu。Spell：基于大语言模型的语义提示演变。*arXiv 预印本
    arXiv:2310.01260*，2023年。
- en: Liang et al. [2022] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya
    Kumar, et al. Holistic evaluation of language models. *arXiv preprint arXiv:2211.09110*,
    2022.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang et al. [2022] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya
    Kumar, 等人。语言模型的全面评估。*arXiv 预印本 arXiv:2211.09110*，2022年。
- en: Lord et al. [1968] FM Lord, MR Novick, and Allan Birnbaum. Statistical theories
    of mental test scores. 1968.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lord et al. [1968] FM Lord, MR Novick, 和 Allan Birnbaum。心理测验分数的统计理论。1968年。
- en: 'Meta [2024] Meta. Introducing meta llama 3: The most capable openly available
    llm to date. [https://ai.meta.com/blog/meta-llama-3](https://ai.meta.com/blog/meta-llama-3),
    2024.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meta [2024] Meta。介绍 Meta Llama 3：迄今为止最强大的开放大语言模型。 [https://ai.meta.com/blog/meta-llama-3](https://ai.meta.com/blog/meta-llama-3)，2024年。
- en: Mizrahi et al. [2023] Moran Mizrahi, Guy Kaplan, Dan Malkin, Rotem Dror, Dafna
    Shahaf, and Gabriel Stanovsky. State of what art? a call for multi-prompt llm
    evaluation. *arXiv preprint arXiv:2401.00595*, 2023.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mizrahi et al. [2023] Moran Mizrahi, Guy Kaplan, Dan Malkin, Rotem Dror, Dafna
    Shahaf, 和 Gabriel Stanovsky。艺术的现状？对多提示大语言模型评估的呼吁。*arXiv 预印本 arXiv:2401.00595*，2023年。
- en: Nitsure et al. [2023] Apoorva Nitsure, Youssef Mroueh, Mattia Rigotti, Kristjan
    Greenewald, Brian Belgodere, Mikhail Yurochkin, Jiri Navratil, Igor Melnyk, and
    Jerret Ross. Risk assessment and statistical significance in the age of foundation
    models. *arXiv preprint arXiv:2310.07132*, 2023.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nitsure et al. [2023] Apoorva Nitsure, Youssef Mroueh, Mattia Rigotti, Kristjan
    Greenewald, Brian Belgodere, Mikhail Yurochkin, Jiri Navratil, Igor Melnyk, 和
    Jerret Ross。在基础模型时代的风险评估和统计显著性。*arXiv 预印本 arXiv:2310.07132*，2023年。
- en: Perlitz et al. [2023] Yotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv, Liat
    Ein-Dor, Eyal Shnarch, Noam Slonim, Michal Shmueli-Scheuer, and Leshem Choshen.
    Efficient benchmarking (of language models). *arXiv preprint arXiv:2308.11696*,
    2023.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perlitz et al. [2023] Yotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv, Liat
    Ein-Dor, Eyal Shnarch, Noam Slonim, Michal Shmueli-Scheuer, 和 Leshem Choshen。高效的语言模型基准测试。*arXiv
    预印本 arXiv:2308.11696*，2023年。
- en: 'Polo et al. [2024] Felipe Maia Polo, Lucas Weber, Leshem Choshen, Yuekai Sun,
    Gongjun Xu, and Mikhail Yurochkin. tinybenchmarks: evaluating llms with fewer
    examples. *arXiv preprint arXiv:2402.14992*, 2024.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Polo 等 [2024] Felipe Maia Polo, Lucas Weber, Leshem Choshen, Yuekai Sun, Gongjun
    Xu, 和 Mikhail Yurochkin. tinybenchmarks: 用更少的示例评估 LLMs。*arXiv 预印本 arXiv:2402.14992*，2024。'
- en: 'Prasad et al. [2023] Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal.
    Grips: Gradient-free, edit-based instruction search for prompting large language
    models. In *Proceedings of the 17th Conference of the European Chapter of the
    Association for Computational Linguistics*, pages 3827–3846, 2023.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Prasad 等 [2023] Archiki Prasad, Peter Hase, Xiang Zhou, 和 Mohit Bansal. Grips:
    无梯度的基于编辑的指令搜索，用于提示大型语言模型。在 *第17届欧洲计算语言学协会年会论文集*，第3827–3846页，2023年。'
- en: 'Reimers and Gurevych [2019] Nils Reimers and Iryna Gurevych. Sentence-bert:
    Sentence embeddings using siamese bert-networks. In *Proceedings of the 2019 Conference
    on Empirical Methods in Natural Language Processing*. Association for Computational
    Linguistics, 11 2019. URL [https://arxiv.org/abs/1908.10084](https://arxiv.org/abs/1908.10084).'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Reimers 和 Gurevych [2019] Nils Reimers 和 Iryna Gurevych. Sentence-bert: 使用
    siamese bert 网络的句子嵌入。在 *2019年自然语言处理实证方法会议论文集*。计算语言学协会，2019年11月。网址 [https://arxiv.org/abs/1908.10084](https://arxiv.org/abs/1908.10084)。'
- en: Resnick [2019] Sidney Resnick. *A probability path*. Springer, 2019.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Resnick [2019] Sidney Resnick. *概率路径*。Springer，2019年。
- en: 'Rodriguez et al. [2021] Pedro Rodriguez, Joe Barrow, Alexander Miserlis Hoyle,
    John P. Lalor, Robin Jia, and Jordan Boyd-Graber. Evaluation examples are not
    equally informative: How should that change NLP leaderboards? In Chengqing Zong,
    Fei Xia, Wenjie Li, and Roberto Navigli, editors, *Proceedings of the 59th Annual
    Meeting of the Association for Computational Linguistics and the 11th International
    Joint Conference on Natural Language Processing (Volume 1: Long Papers)*, pages
    4486–4503, Online, August 2021\. Association for Computational Linguistics. doi:
    10.18653/v1/2021.acl-long.346. URL [https://aclanthology.org/2021.acl-long.346](https://aclanthology.org/2021.acl-long.346).'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rodriguez 等 [2021] Pedro Rodriguez, Joe Barrow, Alexander Miserlis Hoyle, John
    P. Lalor, Robin Jia, 和 Jordan Boyd-Graber. 评估示例并非同样具有信息量：这应该如何改变 NLP 排行榜？在 Chengqing
    Zong, Fei Xia, Wenjie Li, 和 Roberto Navigli 主编的 *第59届计算语言学协会年会暨第11届国际自然语言处理联合会议（第1卷：长论文）论文集*，第4486–4503页，在线，2021年8月。计算语言学协会。doi:
    10.18653/v1/2021.acl-long.346。网址 [https://aclanthology.org/2021.acl-long.346](https://aclanthology.org/2021.acl-long.346)。'
- en: 'Sclar et al. [2023] Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr.
    Quantifying language models’ sensitivity to spurious features in prompt design
    or: How i learned to start worrying about prompt formatting. *arXiv preprint arXiv:2310.11324*,
    2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sclar 等 [2023] Melanie Sclar, Yejin Choi, Yulia Tsvetkov, 和 Alane Suhr. 量化语言模型对提示设计中虚假特征的敏感性，或者：我如何开始担忧提示格式问题。*arXiv
    预印本 arXiv:2310.11324*，2023。
- en: Shi et al. [2024] Chengshuai Shi, Kun Yang, Jing Yang, and Cong Shen. Best arm
    identification for prompt learning under a limited budget. *arXiv preprint arXiv:2402.09723*,
    2024.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等 [2024] Chengshuai Shi, Kun Yang, Jing Yang, 和 Cong Shen. 在有限预算下进行提示学习的最佳臂识别。*arXiv
    预印本 arXiv:2402.09723*，2024。
- en: 'Srivastava et al. [2022] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
    Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya
    Gupta, Adrià Garriga-Alonso, et al. Beyond the imitation game: Quantifying and
    extrapolating the capabilities of language models. *arXiv preprint arXiv:2206.04615*,
    2022.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava 等 [2022] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal
    Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta,
    Adrià Garriga-Alonso, 等。超越模仿游戏：量化和外推语言模型的能力。*arXiv 预印本 arXiv:2206.04615*，2022。
- en: Starke et al. [2017] Alain Starke, Martijn Willemsen, and Chris Snijders. Effective
    user interface designs to increase energy-efficient behavior in a rasch-based
    energy recommender system. In *Proceedings of the eleventh ACM conference on recommender
    systems*, pages 65–73, 2017.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Starke 等 [2017] Alain Starke, Martijn Willemsen, 和 Chris Snijders. 有效的用户界面设计以提高基于
    Rasch 的节能推荐系统中的节能行为。在 *第十一届 ACM 推荐系统会议论文集*，第65–73页，2017年。
- en: Suzgun et al. [2022] Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian
    Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny
    Zhou, et al. Challenging big-bench tasks and whether chain-of-thought can solve
    them. *arXiv preprint arXiv:2210.09261*, 2022.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzgun 等 [2022] Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann,
    Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou,
    等。挑战 big-bench 任务以及链式思维是否能解决它们。*arXiv 预印本 arXiv:2210.09261*，2022。
- en: 'Van der Linden [2018] Wim J Van der Linden. *Handbook of item response theory:
    Three volume set*. CRC Press, 2018.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Van der Linden [2018] Wim J Van der Linden. *项目反应理论手册：三卷本*。CRC Press, 2018。
- en: Vania et al. [2021] Clara Vania, Phu Mon Htut, William Huang, Dhara Mungra,
    Richard Yuanzhe Pang, Jason Phang, Haokun Liu, Kyunghyun Cho, and Samuel R Bowman.
    Comparing test sets with item response theory. *arXiv preprint arXiv:2106.00840*,
    2021.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vania 等人 [2021] Clara Vania, Phu Mon Htut, William Huang, Dhara Mungra, Richard
    Yuanzhe Pang, Jason Phang, Haokun Liu, Kyunghyun Cho 和 Samuel R Bowman. 使用项目反应理论比较测试集。*arXiv
    预印本 arXiv:2106.00840*, 2021。
- en: 'Vivek et al. [2023] Rajan Vivek, Kawin Ethayarajh, Diyi Yang, and Douwe Kiela.
    Anchor points: Benchmarking models with much fewer examples. *arXiv preprint arXiv:2309.08638*,
    2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vivek 等人 [2023] Rajan Vivek, Kawin Ethayarajh, Diyi Yang 和 Douwe Kiela. 锚点：用更少的例子对模型进行基准测试。*arXiv
    预印本 arXiv:2309.08638*, 2023。
- en: 'Voronov et al. [2024] Anton Voronov, Lena Wolf, and Max Ryabinin. Mind your
    format: Towards consistent evaluation of in-context learning improvements. *arXiv
    preprint arXiv:2401.06766*, 2024.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Voronov 等人 [2024] Anton Voronov, Lena Wolf 和 Max Ryabinin. 注意你的格式：朝着一致的上下文学习改进评估方向前进。*arXiv
    预印本 arXiv:2401.06766*, 2024。
- en: 'Wang et al. [2022] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh
    Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran,
    Atharva Naik, David Stap, et al. Super-naturalinstructions: Generalization via
    declarative instructions on 1600+ nlp tasks. *arXiv preprint arXiv:2204.07705*,
    2022.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2022] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh
    Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran,
    Atharva Naik, David Stap 等人. 超自然指令：通过声明性指令在 1600 多个 NLP 任务上的泛化。*arXiv 预印本 arXiv:2204.07705*,
    2022。
- en: Weber et al. [2023a] Lucas Weber, Elia Bruni, and Dieuwke Hupkes. The icl consistency
    test. *arXiv preprint arXiv:2312.04945*, 2023a.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weber 等人 [2023a] Lucas Weber, Elia Bruni 和 Dieuwke Hupkes. ICL 一致性测试。*arXiv
    预印本 arXiv:2312.04945*, 2023a。
- en: 'Weber et al. [2023b] Lucas Weber, Elia Bruni, and Dieuwke Hupkes. Mind the
    instructions: a holistic evaluation of consistency and interactions in prompt-based
    learning. In *Proceedings of the 27th Conference on Computational Natural Language
    Learning (CoNLL)*, pages 294–313, 2023b.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weber 等人 [2023b] Lucas Weber, Elia Bruni 和 Dieuwke Hupkes. 注意指令：对基于提示的学习中一致性和交互的整体评估。发表于
    *第 27 届计算自然语言学习会议（CoNLL）*，第 294–313 页，2023b。
- en: Yang et al. [2023] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V
    Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers. *arXiv preprint
    arXiv:2309.03409*, 2023.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2023] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le,
    Denny Zhou 和 Xinyun Chen. 将大型语言模型作为优化器。*arXiv 预印本 arXiv:2309.03409*, 2023。
- en: Ye et al. [2023a] Qinyuan Ye, Maxamed Axmed, Reid Pryzant, and Fereshte Khani.
    Prompt engineering a prompt engineer. *arXiv preprint arXiv:2311.05661*, 2023a.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye 等人 [2023a] Qinyuan Ye, Maxamed Axmed, Reid Pryzant 和 Fereshte Khani. 提示工程：一个提示工程师的提示。*arXiv
    预印本 arXiv:2311.05661*, 2023a。
- en: Ye et al. [2023b] Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren, and Robin Jia. How
    predictable are large language model capabilities? a case study on big-bench.
    *arXiv preprint arXiv:2305.14947*, 2023b.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ye 等人 [2023b] Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren 和 Robin Jia. 大型语言模型能力有多可预测？一个关于
    Big-Bench 的案例研究。*arXiv 预印本 arXiv:2305.14947*, 2023b。
- en: Appendix A Limitations
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 限制
- en: While our method provides a more reliable measure and a more flexible one, it
    assumes multiple prompts. Thus, if the question of which single prompt should
    be used was a challenge for old benchmarks, which set of prompt templates to use
    is the challenge now. While methods have been suggested for generating multiple
    prompts and diversifying those [Mizrahi et al., [2023](#bib.bib24)], and while
    when many prompts are suggested the choice of each one is likely less critical,
    it is a limitation future work should consider.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的方法提供了更可靠和更灵活的测量，但它假设了多个提示。因此，如果选择使用哪个单一提示是旧基准的挑战，那么现在的挑战是选择哪一组提示模板。虽然已经建议了一些方法来生成多个提示并使其多样化
    [Mizrahi 等人, [2023](#bib.bib24)]，并且当建议了许多提示时，每个提示的选择可能不那么关键，但这是未来工作需要考虑的一个限制。
- en: Another limitation we note is that we do not focus on prompt engineering and
    do not solve this problem. While this would have been a crucial contribution for
    the field, we assume a set of prompts and assume we only care about evaluation
    and not training, which make for a useful and common setting, but it does not
    encompass this goal.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们注意到的限制是，我们没有专注于提示工程，也没有解决这个问题。虽然这本来是对该领域的一个重要贡献，但我们假设了一组提示，并假设我们只关心评估而非训练，这虽然构成了一个有用且常见的设置，但并未涵盖这一目标。
- en: Appendix B Adapting the correctness model for bounded $Y_{ij}$
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 适应有界 $Y_{ij}$ 的正确性模型
- en: There might be situations in LLM evaluation in which $Y_{ij}\notin\{0,1\}$ and
    work with this newly created variable.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 评估中，可能存在 $Y_{ij}\notin\{0,1\}$ 的情况，并需要处理这个新创建的变量。
- en: Appendix C Computing resources
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 计算资源
- en: All experiments were conducted using a virtual machine with 32 cores. The results
    for each benchmark separately can be obtained within 3-6 hours.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实验均使用32核的虚拟机进行。每个基准测试的结果可以在3-6小时内获得。
- en: For fine-tuning BERT embeddings, we employ multiple NVIDIA A30 GPUs with 24
    GB vRAM, requiring 70 hours of training and an additional approximately 350 hours
    for hyperparameter search. Fine-tuning can be conducted on GPUs with smaller capacities.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对 BERT 嵌入进行微调时，我们使用多块24 GB vRAM的 NVIDIA A30 GPU，训练需要 70 小时，超参数搜索额外需要约 350 小时。微调可以在容量较小的
    GPU 上进行。
- en: Appendix D Estimation errors by task
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 按任务划分的估计误差
- en: In Figures [6](#A4.F6 "Figure 6 ‣ Appendix D Estimation errors by task ‣ Efficient
    multi-prompt evaluation of LLMs"), [7](#A4.F7 "Figure 7 ‣ Appendix D Estimation
    errors by task ‣ Efficient multi-prompt evaluation of LLMs"), and [8](#A4.F8 "Figure
    8 ‣ Appendix D Estimation errors by task ‣ Efficient multi-prompt evaluation of
    LLMs"), we analyze the Wasserstein 1-distance per task for each benchmark when
    using the method PE-EmbPT, a robust and versatile variation of PromptEval. The
    results show that for BBH and LMentry, the estimation errors (Wasserstein 1-distance)
    are more uniform across tasks compared to MMLU, where some tasks exhibit higher
    estimation errors. This discrepancy occurs because all tasks in BBH and LMentry
    have the same number of examples, whereas tasks in MMLU, particularly those with
    higher estimation errors, have a significantly larger number of examples when
    compared to the others. In those cases, a larger number of evaluations is recommended.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [6](#A4.F6 "图 6 ‣ 附录 D 按任务划分的估计误差 ‣ 高效多提示评估 LLMs")、[7](#A4.F7 "图 7 ‣ 附录 D
    按任务划分的估计误差 ‣ 高效多提示评估 LLMs") 和 [8](#A4.F8 "图 8 ‣ 附录 D 按任务划分的估计误差 ‣ 高效多提示评估 LLMs")
    中，我们分析了使用 PE-EmbPT 方法的每个基准测试的 Wasserstein 1 距离。这是一种健壮且多功能的 PromptEval 变体。结果显示，对于
    BBH 和 LMentry，估计误差（Wasserstein 1 距离）在任务间更为均匀，而 MMLU 中某些任务表现出较高的估计误差。这种差异发生是因为
    BBH 和 LMentry 的所有任务具有相同数量的示例，而 MMLU 中的任务，特别是那些具有较高估计误差的任务，与其他任务相比有显著更多的示例。在这些情况下，建议增加评估数量。
- en: '![Refer to caption](img/962b52c9d3d03735f8699176064e8131.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/962b52c9d3d03735f8699176064e8131.png)'
- en: 'Figure 6: Estimation error for the BBH tasks.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：BBH 任务的估计误差。
- en: '![Refer to caption](img/56bebb529e0a3654bc0b05fd4a5bf294.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/56bebb529e0a3654bc0b05fd4a5bf294.png)'
- en: 'Figure 7: Estimation error for the LMentry tasks.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：LMentry 任务的估计误差。
- en: '![Refer to caption](img/c72faf78397ae91bf46c6dd2460edb2c.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/c72faf78397ae91bf46c6dd2460edb2c.png)'
- en: 'Figure 8: Estimation error for the MMLU tasks.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：MMLU 任务的估计误差。
- en: Appendix E Extra results for best-prompt identification
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 最佳提示识别的额外结果
- en: In Figures [9](#A5.F9 "Figure 9 ‣ Appendix E Extra results for best-prompt identification
    ‣ Efficient multi-prompt evaluation of LLMs"), [10](#A5.F10 "Figure 10 ‣ Appendix
    E Extra results for best-prompt identification ‣ Efficient multi-prompt evaluation
    of LLMs"), and [11](#A5.F11 "Figure 11 ‣ Appendix E Extra results for best-prompt
    identification ‣ Efficient multi-prompt evaluation of LLMs"), we can see the full
    results for MMLU, BBH, and LMentry. For all benchmarks, we can see that within
    each triple “PE”, “GTRIPLE-SE”, “TRIPLE-MLP-GSE”, the “PE” version always has
    some advantage with a lower regret.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [9](#A5.F9 "图 9 ‣ 附录 E 最佳提示识别的额外结果 ‣ 高效多提示评估 LLMs")、[10](#A5.F10 "图 10 ‣
    附录 E 最佳提示识别的额外结果 ‣ 高效多提示评估 LLMs") 和 [11](#A5.F11 "图 11 ‣ 附录 E 最佳提示识别的额外结果 ‣ 高效多提示评估
    LLMs") 中，我们可以看到 MMLU、BBH 和 LMentry 的完整结果。对于所有基准测试，可以看到在每个“三重”中，“PE”版本总是具有一些优势，后悔值较低。
- en: 'The tuning and fitting process of the Multi-Layer Perceptron (MLP) classifier
    involves setting up a pipeline that includes feature scaling and the MLP classifier
    itself, which has 30 neurons in its hidden layer. This process begins by defining
    a range of values for critical hyperparameters: the l2 regularization strength
    is tested over the range from 0.001 to 10, and the initial learning rate is tested
    over the range from 0.001 to 0.1\. These values are systematically tested through
    cross-validation to determine the optimal combination. During this phase, cross-validation
    ensures that the model is evaluated on different subsets of the data to prevent
    overfitting and to ensure robust performance. Once the best hyperparameters are
    identified, the final model is trained on the entire dataset using these optimal
    settings, resulting in a well-tuned MLP classifier ready for deployment.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器（MLP）分类器的调优和拟合过程涉及设置一个包括特征缩放和MLP分类器本身的流程，其中隐藏层有30个神经元。该过程首先定义关键超参数的值范围：l2正则化强度在0.001到10的范围内进行测试，初始学习率在0.001到0.1的范围内进行测试。这些值通过交叉验证进行系统测试，以确定最佳组合。在此阶段，交叉验证确保模型在数据的不同子集上进行评估，以防止过拟合，并确保稳健的性能。一旦识别出最佳超参数，最终模型将使用这些最佳设置在整个数据集上进行训练，从而得到一个经过良好调优的MLP分类器，准备好进行部署。
- en: '![Refer to caption](img/8f31390207c408802db4db273332fa1b.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8f31390207c408802db4db273332fa1b.png)'
- en: 'Figure 9: Best-prompt identification for MMLU'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：MMLU的最佳提示识别
- en: '![Refer to caption](img/3fc82c3abf04fa68945a35917d120d48.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3fc82c3abf04fa68945a35917d120d48.png)'
- en: 'Figure 10: Best-prompt identification for BBH'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：BBH的最佳提示识别
- en: '![Refer to caption](img/ee17334495195895fbe5ccb40474e94e.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ee17334495195895fbe5ccb40474e94e.png)'
- en: 'Figure 11: Best-prompt identification for LMentry'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：LMentry的最佳提示识别
- en: Appendix F Theoretical results
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 理论结果
- en: F.1 Consistency of X-pIRT
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.1 X-pIRT的一致性
- en: In Theorem [F.1](#A6.Thmtheorem1 "Theorem F.1\. ‣ F.1 Consistency of X-pIRT
    ‣ Appendix F Theoretical results ‣ Efficient multi-prompt evaluation of LLMs"),
    we claim that the X-pIRT estimator is uniformly consistent over all $i\in\mathcal{I}$.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在定理[F.1](#A6.Thmtheorem1 "定理 F.1\. ‣ F.1 X-pIRT的一致性 ‣ 附录 F 理论结果 ‣ 高效的多提示评估LLMs")中，我们声明X-pIRT估计量在所有
    $i\in\mathcal{I}$ 上是一致的。
- en: Theorem F.1.
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 F.1。
- en: Under conditions [4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs"), [4.2](#S4.Thmtheorem2 "Condition
    4.2\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs"),
    and [4.3](#S4.Thmtheorem3 "Condition 4.3\. ‣ 4 Theoretical guarantees ‣ Efficient
    multi-prompt evaluation of LLMs"), it is true that
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在条件[4.1](#S4.Thmtheorem1 "条件 4.1\. ‣ 4 理论保证 ‣ 高效的多提示评估LLMs")、[4.2](#S4.Thmtheorem2
    "条件 4.2\. ‣ 4 理论保证 ‣ 高效的多提示评估LLMs")和[4.3](#S4.Thmtheorem3 "条件 4.3\. ‣ 4 理论保证 ‣
    高效的多提示评估LLMs")下，以下结论是正确的
- en: '|  | $\textstyle\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-S_{i}\right&#124;\to 0\text{ in probability as }I,J\to\infty.$
    |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-S_{i}\right&#124;\to 0\text{ 在概率上，随着 }I,J\to\infty.$ |  |'
- en: A direct consequence of Theorem [F.1](#A6.Thmtheorem1 "Theorem F.1\. ‣ F.1 Consistency
    of X-pIRT ‣ Appendix F Theoretical results ‣ Efficient multi-prompt evaluation
    of LLMs") is that
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 定理[F.1](#A6.Thmtheorem1 "定理 F.1\. ‣ F.1 X-pIRT的一致性 ‣ 附录 F 理论结果 ‣ 高效的多提示评估LLMs")的直接结果是
- en: '|  | $\textstyle\left&#124;\frac{1}{I}\sum_{i\in\mathcal{I}}\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-\frac{1}{I}\sum_{i\in\mathcal{I}}S_{i}\right&#124;\leq\frac{1}{I}\sum_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-S_{i}\right&#124;\leq\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-S_{i}\right&#124;\to 0$ |  |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textstyle\left&#124;\frac{1}{I}\sum_{i\in\mathcal{I}}\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-\frac{1}{I}\sum_{i\in\mathcal{I}}S_{i}\right&#124;\leq\frac{1}{I}\sum_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-S_{i}\right&#124;\leq\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{S}}]-S_{i}\right&#124;\to 0$ |  |'
- en: in probability as $I,J\to\infty$. This means that the mean of predicted performances
    is also consistent if a practitioner wants to use it as a summary statistic.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在概率上，当 $I,J\to\infty$ 时。这意味着如果实践者希望将预测性能的均值作为总结统计量，它也是一致的。
- en: The proof of Theorem [F.1](#A6.Thmtheorem1 "Theorem F.1\. ‣ F.1 Consistency
    of X-pIRT ‣ Appendix F Theoretical results ‣ Efficient multi-prompt evaluation
    of LLMs") is embedded in the proof of Theorem [4.4](#S4.Thmtheorem4 "Theorem 4.4\.
    ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs").
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 [F.1](#A6.Thmtheorem1 "Theorem F.1\. ‣ F.1 X-pIRT的一致性 ‣ 附录 F 理论结果 ‣ LLMs的高效多提示评估")
    的证明包含在定理 [4.4](#S4.Thmtheorem4 "Theorem 4.4\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 的证明中。
- en: F.2 Proof of Theorem [4.4](#S4.Thmtheorem4 "Theorem 4.4\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs")
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.2 定理 [4.4](#S4.Thmtheorem4 "Theorem 4.4\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 的证明
- en: For the following results, we denote $\psi^{\top}x_{i}$.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下结果，我们记 $\psi^{\top}x_{i}$。
- en: Lemma F.2.
  id: totrans-218
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 F.2.
- en: Under Conditions [4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs") and [4.3](#S4.Thmtheorem3 "Condition
    4.3\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs"),
    we have that $\sup_{i\in\mathcal{I}}|\hat{\theta}_{i}-\theta_{i}|=o_{P}(1)$.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在条件 [4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 和 [4.3](#S4.Thmtheorem3
    "Condition 4.3\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 下，我们有 $\sup_{i\in\mathcal{I}}|\hat{\theta}_{i}-\theta_{i}|=o_{P}(1)$。
- en: Proof.
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: We prove that $\sup_{i\in\mathcal{I}}|\hat{\theta}_{i}-\theta_{i}|=o_{P}(1)$.
    The second statement is obtained in the same way.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们证明了 $\sup_{i\in\mathcal{I}}|\hat{\theta}_{i}-\theta_{i}|=o_{P}(1)$。第二个陈述以相同的方式获得。
- en: See that
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 见：
- en: '|  | $1$2 |  |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: as $I,J\to\infty$. Where the first inequality is obtained using the Cauchy–Schwarz
    inequality, the second is obtained using Condition [4.1](#S4.Thmtheorem1 "Condition
    4.1\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs"),
    and the last equality is a consequence of Condition [4.3](#S4.Thmtheorem3 "Condition
    4.3\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs")
    and the continuous mapping theorem [Resnick, [2019](#bib.bib30)]. ∎
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当 $I,J\to\infty$ 时。第一个不等式使用了柯西–施瓦兹不等式，第二个不等式使用了条件 [4.1](#S4.Thmtheorem1 "Condition
    4.1\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估")，最后的等式是条件 [4.3](#S4.Thmtheorem3 "Condition 4.3\.
    ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 和连续映射定理 [Resnick, [2019](#bib.bib30)] 的结果。∎
- en: Lemma F.3.
  id: totrans-225
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 F.3.
- en: Under Conditions [4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs") and [4.3](#S4.Thmtheorem3 "Condition
    4.3\. ‣ 4 Theoretical guarantees ‣ Efficient multi-prompt evaluation of LLMs"),
    it is true that
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在条件 [4.1](#S4.Thmtheorem1 "Condition 4.1\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 和 [4.3](#S4.Thmtheorem3
    "Condition 4.3\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 下，以下陈述是正确的：
- en: '|  | $\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid Y_{\mathcal{E}}]-{\mathbb{E}}[S_{i}\mid
    Y_{\mathcal{E}}]\right&#124;=o_{P}(1)\text{ as }I,J\to\infty.$ |  |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sup_{i\in\mathcal{I}}\left\|\hat{{\mathbb{E}}}[S_{i}\mid Y_{\mathcal{E}}]-{\mathbb{E}}[S_{i}\mid
    Y_{\mathcal{E}}]\right\|=o_{P}(1)\text{ 当 }I,J\to\infty.$ |  |'
- en: Proof.
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: See that
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 见：
- en: '|  | $\displaystyle\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{E}}]-{\mathbb{E}}[S_{i}\mid Y_{\mathcal{E}}]\right&#124;$ |  |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\sup_{i\in\mathcal{I}}\left\|\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{E}}]-{\mathbb{E}}[S_{i}\mid Y_{\mathcal{E}}]\right\|$ |  |'
- en: '|  |  | $1$2 |  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $1$2 |  |'
- en: '|  |  | $1$2 |  |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $1$2 |  |'
- en: '|  |  | $1$2 |  |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $1$2 |  |'
- en: '|  |  | $\displaystyle\leq\frac{1}{4}\left(\sup_{i}&#124;\hat{\theta}_{i}-\theta_{i}&#124;+\sup_{j}&#124;\hat{\beta}_{j}-\beta_{j}&#124;\right)$
    |  |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\leq\frac{1}{4}\left(\sup_{i}\| \hat{\theta}_{i}-\theta_{i}\|+\sup_{j}\|
    \hat{\beta}_{j}-\beta_{j}\|\right)$ |  |'
- en: '|  |  | $\displaystyle=o_{P}(1)$ |  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=o_{P}(1)$ |  |'
- en: where the third step is justified by the fact that $\sigma$-Lipschitz and the
    last step is justified by Lemma [F.2](#A6.Thmtheorem2 "Lemma F.2\. ‣ F.2 Proof
    of Theorem 4.4 ‣ Appendix F Theoretical results ‣ Efficient multi-prompt evaluation
    of LLMs"). ∎
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 其中第三步通过$\sigma$-Lipschitz性质得到证实，最后一步则由引理 [F.2](#A6.Thmtheorem2 "Lemma F.2\.
    ‣ F.2 证明定理 4.4 ‣ 附录 F 理论结果 ‣ LLMs的高效多提示评估") 证实。∎
- en: Lemma F.4.
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 F.4.
- en: Under Condition [4.2](#S4.Thmtheorem2 "Condition 4.2\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs"), it is true that
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在条件 [4.2](#S4.Thmtheorem2 "Condition 4.2\. ‣ 4 理论保证 ‣ LLMs的高效多提示评估") 下，以下陈述是正确的：
- en: '|  | $\sup_{i\in\mathcal{I}}\left&#124;{\mathbb{E}}[S_{i}\mid Y_{\mathcal{E}}]-S_{i}\right&#124;=o_{P}(1)\text{
    as }I,J\to\infty.$ |  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sup_{i\in\mathcal{I}}\left\|{\mathbb{E}}[S_{i}\mid Y_{\mathcal{E}}]-S_{i}\right\|=o_{P}(1)\text{
    当 }I,J\to\infty.$ |  |'
- en: Proof.
  id: totrans-240
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: For an arbitrary 
    |  |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '|  | $$\underbrace{\left|\{a\in\mathcal{A}:a_{i}=a\}\right|}_{m_{2}+1}+\underbrace{\left|\{a\in\mathcal{A}:a_{i}>\text{某值}\}\right|}_{m_{1}+1}
    |  |'
- en: Because $a_{i}$.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 $a_{i}$。
- en: Finally, because $m_{1}+m_{2}+1\geq{p\cdot n}$. ∎
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，因为 $m_{1}+m_{2}+1\geq{p\cdot n}$。 ∎
- en: Lemma F.6.
  id: totrans-260
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 F.6。
- en: Let $\hat{i}$.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $\hat{i}$。
- en: Proof.
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: 'Define $\mathcal{A}\triangleq\{S_{1},\cdots,S_{i}\}$, we have:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 $\mathcal{A}\triangleq\{S_{1},\cdots,S_{i}\}$，我们有：
- en: •
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If (i) holds, then there is at least $M_{2}+M_{3}+1$.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果 (i) 成立，则至少有 $M_{2}+M_{3}+1$。
- en: •
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If (ii) holds, then there is at least $M_{1}+M_{2}+1$.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果 (ii) 成立，则至少有 $M_{1}+M_{2}+1$。
- en: This means that under $\sup_{i\in\mathcal{I}}|\hat{{\mathbb{E}}}[S_{i}\mid Y_{\mathcal{E}}]-S_{i}|\leq\epsilon$.
    ∎
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在 $\sup_{i\in\mathcal{I}}|\hat{{\mathbb{E}}}[S_{i}\mid Y_{\mathcal{E}}]-S_{i}|\leq\epsilon$
    下。 ∎
- en: Proof of Theorem [4.4](#S4.Thmtheorem4 "Theorem 4.4\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs") (Part 1).
  id: totrans-269
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 [4.4](#S4.Thmtheorem4 "定理 4.4. ‣ 4 理论保证 ‣ 高效的多提示评估 LLMs") 证明（第 1 部分）。
- en: Let $\hat{i}$. Consequently,
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 设 $\hat{i}$。因此，
- en: '|  | ${\mathbb{P}}\left(&#124;\hat{{\mathbb{E}}}[S_{\hat{i}}\mid Y_{S}]-S_{i^{*}}&#124;\leq
    2\epsilon\right)\geq{\mathbb{P}}\left(\sup_{i\in\mathcal{I}}&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{S}]-S_{i}&#124;\leq\epsilon\right)=1+o(1)$ |  |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|  | ${\mathbb{P}}\left(\left|\hat{{\mathbb{E}}}[S_{\hat{i}}\mid Y_{S}]-S_{i^{*}}\right|\leq
    2\epsilon\right)\geq{\mathbb{P}}\left(\sup_{i\in\mathcal{I}}\left|\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{S}]-S_{i}\right|\leq\epsilon\right)=1+o(1)$ |  |'
- en: because
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 因为
- en: '|  | $\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid Y_{\mathcal{E}}]-S_{i}\right&#124;\leq\sup_{i\in\mathcal{I}}\left&#124;\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{E}}]-{\mathbb{E}}[S_{i}\mid Y_{\mathcal{E}}]\right&#124;+\sup_{i\in\mathcal{I}}\left&#124;{\mathbb{E}}[S_{i}\mid
    Y_{\mathcal{E}}]-S_{i}\right&#124;=o_{P}(1)\text{ as }I,J\to\infty$ |  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sup_{i\in\mathcal{I}}\left|\hat{{\mathbb{E}}}[S_{i}\mid Y_{\mathcal{E}}]-S_{i}\right|\leq\sup_{i\in\mathcal{I}}\left|\hat{{\mathbb{E}}}[S_{i}\mid
    Y_{\mathcal{E}}]-{\mathbb{E}}[S_{i}\mid Y_{\mathcal{E}}]\right|+\sup_{i\in\mathcal{I}}\left|{\mathbb{E}}[S_{i}\mid
    Y_{\mathcal{E}}]-S_{i}\right|=o_{P}(1)\text{ 当 }I,J\to\infty$ |  |'
- en: holds by lemmas [F.3](#A6.Thmtheorem3 $$.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 由引理 [F.3](#A6.Thmtheorem3 $$ 证明成立。
- en: ∎
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: Proof of Theorem [4.4](#S4.Thmtheorem4 "Theorem 4.4\. ‣ 4 Theoretical guarantees
    ‣ Efficient multi-prompt evaluation of LLMs") (Part 2).
  id: totrans-276
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 [4.4](#S4.Thmtheorem4 "定理 4.4. ‣ 4 理论保证 ‣ 高效的多提示评估 LLMs") 证明（第 2 部分）。
- en: We start this proof by showing that
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过展示来开始这个证明
- en: '|  | $&#124;\hat{Q}(U)-Q(U)&#124;=o_{P}(1)$ |  |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '|  | $|\hat{Q}(U)-Q(U)|=o_{P}(1)$ |  |'
- en: with $U\sim\text{Unif}[0,1]$.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $U\sim\text{Unif}[0,1]$。
- en: For an arbitrary $$\epsilon>, see that
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 对任意 $$\epsilon>，可见
- en: '|  | 
    |  |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '|  |  | \text{某值}\right)\right]"
    |  |'
- en: '|  |  | $\displaystyle=0$ |  |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=0$ |  |'
- en: where the second equality is justified by the Dominated Convergence Theorem
    [Resnick, [2019](#bib.bib30)] and the last one is justified by $|\hat{Q}(p)-Q(p)|=o_{P}(1)$.
    Now, we see that
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个等式由支配收敛定理 [Resnick, [2019](#bib.bib30)] 证明，最后一个由 $|\hat{Q}(p)-Q(p)|=o_{P}(1)$
    证明。现在，我们看到
- en: '|  | $\displaystyle\lim_{I,J\to\infty}{\mathbb{E}}[W_{1}(F,\hat{F})]$ |  |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\lim_{I,J\to\infty}{\mathbb{E}}[W_{1}(F,\hat{F})]$ |  |'
- en: '|  |  | $\displaystyle=\lim_{I,J\to\infty}{\mathbb{E}}\left[&#124;\hat{Q}(U)-Q(U)&#124;\right]$
    |  |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\lim_{I,J\to\infty}{\mathbb{E}}\left[|\hat{Q}(U)-Q(U)|\right]$
    |  |'
- en: '|  |  | $\displaystyle=0$ |  |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=0$ |  |'
- en: where the last step is justified by Fubini’s Theorem [Resnick, [2019](#bib.bib30)],
    $|\hat{Q}(U)-Q(U)|=o_{P}(1)$ and applying Markov’s inequality, we get
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步由 Fubini 定理 [Resnick, [2019](#bib.bib30)] 证明，$|\hat{Q}(U)-Q(U)|=o_{P}(1)$，应用
    Markov 不等式，我们得到
- en: '|  | $1$2 |  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  |'
- en: ∎
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: Appendix G Details MMLU data
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G MMLU 数据细节
- en: 'Algorithm [3](#algorithm3 "In Appendix G Details MMLU data ‣ Efficient multi-prompt
    evaluation of LLMs") for automatically generating templates can be seen as a graph
    traversal of a template graph, whose nodes are defined by which features they
    have: a separator $SEP$. By traversing this graph, we can collect unique templates
    that can used in the evaluation of LLMs on tasks.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 [3](#algorithm3 "在附录 G 细节 MMLU 数据 ‣ 高效的多提示评估 LLMs") 用于自动生成模板，可以视为对模板图的图遍历，其节点由它们的特征定义：分隔符
    $SEP$。通过遍历这个图，我们可以收集独特的模板，用于评估 LLMs 在任务上的表现。
- en: '1Input: Base prompt template features: Separator $SEP$, add to templates. Add
    the generated templates to the agenda.return generated templates.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 1 输入：基础提示模板特征：分隔符 $SEP$，添加到模板中。将生成的模板添加到议程中。返回生成的模板。
- en: Algorithm 3 TemplateGeneration
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 3 模板生成
- en: Appendix H Details MMLU spread analysis
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H MMLU 分布分析细节
- en: Figure [12](#A8.F12 "Figure 12 ‣ Appendix H Details MMLU spread analysis ‣ Efficient
    multi-prompt evaluation of LLMs") depicts the performance of LLMs on the whole
    MMLU.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [12](#A8.F12 "图 12 ‣ 附录 H 细节 MMLU 分布分析 ‣ 高效的多提示评估 LLMs") 描述了 LLMs 在整个 MMLU
    上的表现。
- en: '![Refer to caption](img/349c6c77f14214dca00f7c2ee744dfa3.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/349c6c77f14214dca00f7c2ee744dfa3.png)'
- en: 'Figure 12: MMLU accuracy (all 57 subjects).'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '图 12: MMLU 准确度（所有 57 个主题）。'
- en: To correlate the ranks from different judges, we can use Kendall’s $W$ is the
    number of objects ranked. In our case, we first have MMLU subjects ranking prompt
    templates, and then we have LLMs ranking prompt templates.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 为了关联来自不同评审的排名，我们可以使用 Kendall 的 $W$ 作为排名的对象数量。在我们的情况下，我们首先有 MMLU 主题的排名提示模板，然后我们有
    LLMs 的排名提示模板。
- en: In Figure [13](#A8.F13 "Figure 13 ‣ Appendix H Details MMLU spread analysis
    ‣ Efficient multi-prompt evaluation of LLMs"), we see the distribution of Kendall’s
    $W$ around 0.25\. This suggests that there is no "best" prompt for a subject.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [13](#A8.F13 "图 13 ‣ 附录 H 细节 MMLU 分布分析 ‣ 高效的多提示评估 LLMs") 中，我们看到 Kendall 的
    $W$ 分布在 0.25 左右。这表明对于一个主题来说，没有“最佳”提示。
- en: '![Refer to caption](img/e900e82a023e18f8dcf1e0fa26665739.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/e900e82a023e18f8dcf1e0fa26665739.png)'
- en: 'Figure 13: Kendall’s $W$ over the 57 subjects of MMLU.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '图 13: Kendall 的 $W$ 在 MMLU 的 57 个主题上的表现。'
- en: In Table [1](#A8.T1 "Table 1 ‣ Appendix H Details MMLU spread analysis ‣ Efficient
    multi-prompt evaluation of LLMs"), we see the values of Kendall’s $W$ is 0.45
    and 0.35, respectively. Curiously, both of the top-ranked prompt templates have
    lots of commas. The best-ranked prompt is "The, following, are, multiple, choice,
    questions, (with, answers), about, topic], question], Answers], choices], Answer]".
    Interestingly, the comma separation of each word or phrase in this prompt template
    may aid the model in parsing and effectively understanding the different components
    of the prompt structure.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在表 [1](#A8.T1 "表 1 ‣ 附录 H 细节 MMLU 分布分析 ‣ 高效的多提示评估 LLMs") 中，我们看到 Kendall 的 $W$
    的值分别为 0.45 和 0.35。有趣的是，排名最高的两个提示模板都有很多逗号。排名最高的提示是 "The, following, are, multiple,
    choice, questions, (with, answers), about, topic], question], Answers], choices],
    Answer]"。有趣的是，这个提示模板中每个单词或短语的逗号分隔可能有助于模型解析并有效理解提示结构的不同组件。
- en: 'Table 1: Kendall’s $W$ per LLM'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 每个 LLM 的 Kendall 的 $W$'
- en: '| Model | Kendall’s W |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Kendall 的 W |'
- en: '| --- | --- |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| meta-llama/llama-3-8b-instruct | 0.126027 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| meta-llama/llama-3-8b-instruct | 0.126027 |'
- en: '| meta-llama/llama-3-8b | 0.252835 |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| meta-llama/llama-3-8b | 0.252835 |'
- en: '| meta-llama/llama-3-70b-instruct | 0.101895 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| meta-llama/llama-3-70b-instruct | 0.101895 |'
- en: '| mistralai/mistral-7b-instruct-v0-2 | 0.219841 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| mistralai/mistral-7b-instruct-v0-2 | 0.219841 |'
- en: '| mistralai/mistral-7b-v0-1 | 0.345592 |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| mistralai/mistral-7b-v0-1 | 0.345592 |'
- en: '| mistralai/mixtral-8x7b-instruct-v01 | 0.131487 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| mistralai/mixtral-8x7b-instruct-v01 | 0.131487 |'
- en: '| codellama/codellama-34b-instruct | 0.287066 |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| codellama/codellama-34b-instruct | 0.287066 |'
- en: '| ibm-mistralai/merlinite-7b | 0.146411 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| ibm-mistralai/merlinite-7b | 0.146411 |'
- en: '| google/gemma-7b-it | 0.445478 |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| google/gemma-7b-it | 0.445478 |'
- en: '| google/gemma-7b | 0.179373 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| google/gemma-7b | 0.179373 |'
- en: '| google/flan-t5-xl | 0.066501 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| google/flan-t5-xl | 0.066501 |'
- en: '| google/flan-t5-xxl | 0.056257 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| google/flan-t5-xxl | 0.056257 |'
- en: '| google/flan-ul2 | 0.109076 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| google/flan-ul2 | 0.109076 |'
- en: '| tiiuae/falcon-180b | 0.165600 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| tiiuae/falcon-180b | 0.165600 |'
- en: '| tiiuae/falcon-40b | 0.100173 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| tiiuae/falcon-40b | 0.100173 |'
- en: Figure [14](#A8.F14 "Figure 14 ‣ Appendix H Details MMLU spread analysis ‣ Efficient
    multi-prompt evaluation of LLMs") illustrates sensitivity for llama-3-8b, gemma-7b,
    and merlinite-7b, respectively. On the template graph, a distance 1 means templates
    differ by only 1 feature, a distance 2 means templates differ by 2 features, etc.
    We see that there is no significant correlation between template distance and
    the accuracy spread. In the cases of gemma-7b and merlinite-7b, the accuracy spread
    for templates with smaller distance seems to be smaller, possibly implying that
    the template graph for these models is smooth.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图[14](#A8.F14 "图14 ‣ 附录H细节MMLU扩展分析 ‣ 高效的多提示评估LLMs")分别展示了llama-3-8b、gemma-7b和merlinite-7b的敏感性。在模板图中，距离1表示模板仅在1个特征上有所不同，距离2表示模板在2个特征上有所不同，等等。我们看到模板距离与准确率扩展之间没有显著的相关性。在gemma-7b和merlinite-7b的情况下，距离较小的模板的准确率扩展似乎较小，这可能暗示这些模型的模板图是平滑的。
- en: '| ![Refer to caption](img/046b29692ba4b440c95c3316085bf438.png) | ![Refer to
    caption](img/3e228dc85a7444157cb959fcee62e935.png) | ![Refer to caption](img/29a6fd1b3625377a0db1a80a22f43557.png)
    |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| ![参考标题](img/046b29692ba4b440c95c3316085bf438.png) | ![参考标题](img/3e228dc85a7444157cb959fcee62e935.png)
    | ![参考标题](img/29a6fd1b3625377a0db1a80a22f43557.png) |'
- en: 'Figure 14: Model sensitivity for llama-3-8b, gemma-7b, and merlinite-7b.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：llama-3-8b、gemma-7b和merlinite-7b的模型敏感性。
- en: Appendix I BERT fine-tuning details
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录I BERT微调细节
- en: I.1 Model
  id: totrans-326
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I.1 模型
- en: We augment the BERT model by extending its input embeddings by $|J|$ [Example
    ID] tokens which we use to feed information about the example identity to the
    model. Additionally, we add a linear downward projection (d = 25) on top of the
    final BERT layer to reduce the dimensionality of the resulting covariates.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过扩展BERT模型的输入嵌入来增强其功能，扩展了$|J|$ [Example ID] 标记，这些标记用于向模型提供示例身份的信息。此外，我们在最终BERT层的顶部添加了一个线性下降投影（d
    = 25），以减少结果协变量的维度。
- en: I.2 Training data
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I.2 训练数据
- en: To obtain training examples, we concatenate all prompting templates with all
    [Example ID] tokens giving us $|I|\times|J|$ from the LLMs in the training set,
    making the training task a multi-label binary classification problem. We train
    on an iid split of half of the LLMs at a time and test on the other half. Additionally,
    the training data are split along the example axis into an 80% training and 20%
    validation set.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取训练样本，我们将所有提示模板与所有[Example ID]标记连接，得到来自训练集中的LLMs的$|I|\times|J|$，将训练任务变成了多标签二分类问题。我们在LLMs的一半上进行训练，另一半用于测试。此外，训练数据沿示例轴分割为80%的训练集和20%的验证集。
- en: I.3 Hyperparameters
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I.3 超参数
- en: 'We run a small grid search over different plausible hyperparameter settings
    and settle on the following setup: We employ the Adam optimizer [Kingma and Ba,
    [2014](#bib.bib17)] with an initial learning rate of 2e-5 and a weight decay of
    1e-5\. The learning rate undergoes a linear warm-up over 200 steps, followed by
    exponential decay using the formula $lr_{currnt}=\gamma^{s}\cdot lr_{init}$ is
    set to 0.99995. We train with a batch size of 96.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在不同的可能超参数设置上进行了一次小规模的网格搜索，并决定使用以下设置：我们采用Adam优化器[Kingma和Ba，[2014](#bib.bib17)]，初始学习率为2e-5，权重衰减为1e-5。学习率在200步内线性预热，然后使用公式$lr_{currnt}=\gamma^{s}\cdot
    lr_{init}$进行指数衰减，设置为0.99995。我们使用批量大小为96进行训练。
- en: Appendix J Heuristics for discrete features
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录J 离散特征的启发式方法
- en: For the BBH and LMentry benchmarks, we use the following heuristics to construct
    feature representations of prompt templates.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 对于BBH和LMentry基准测试，我们使用以下启发式方法来构造提示模板的特征表示。
- en: 'Table 2: Overview of Discrete Features'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：离散特征概述
- en: '| Category | Feature Name | Description |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 特征名称 | 描述 |'
- en: '| Casing Features | All Caps Words | Count of all uppercase words |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 外壳特征 | 全大写词汇 | 所有大写词汇的数量 |'
- en: '| Lowercase Words | Count of all lowercase words |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 小写单词 | 所有小写单词的数量 |'
- en: '| Capitalized Words | Count of words with the first letter capitalized |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| 大写单词 | 首字母大写单词的数量 |'
- en: '| Formatting Features | Line Breaks | Count of line breaks |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 格式特征 | 换行符 | 换行符的数量 |'
- en: '| Framing Words | Count of capitalized or numeric words before a colon |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 框架词汇 | 冒号前大写或数字词汇的数量 |'
- en: '| Special Characters Features | Colon (:) | Count of ’:’ |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 特殊字符特征 | 冒号（:） | ’:’ 的数量 |'
- en: '| Dash (-) | Count of ’-’ |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 连字符（-） | ’-’ 的数量 |'
- en: '| Double Bar (&#124;&#124;) | Count of ’&#124;&#124;’ |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 双竖线（&#124;&#124;） | ’&#124;&#124;’ 的数量 |'
- en: '| Separator token | Count of ’’ |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 分隔符令牌 | ’’ 的数量 |'
- en: '| Double Colon (::) | Count of ’::’ |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 双冒号（::） | ’::’ 的数量 |'
- en: '| Parenthesis Left (() | Count of ’(’ |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 左括号（(） | ’(’ 的数量 |'
- en: '| Parenthesis Right ()) | Count of ’)’ |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 右括号（)） | ’)’ 的数量 |'
- en: '| Quotation (") | Count of ’"’ |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 引号（"） | ’"’ 的数量 |'
- en: '| Question Mark (?) | Count of ’?’ |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 问号（?） | ’?’ 的数量 |'
- en: '| Length Feature | Space Count | Count of spaces |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 长度特征 | 空格数量 | 空格的数量 |'
