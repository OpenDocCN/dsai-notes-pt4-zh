- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:41:08'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:41:08
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗集成大语言模型的移动机器人系统的提示注入攻击研究
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.03515](https://ar5iv.labs.arxiv.org/html/2408.03515)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.03515](https://ar5iv.labs.arxiv.org/html/2408.03515)
- en: Wenxiao Zhang Dept. of Computer Science and Software Engineering
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Wenxiao Zhang 计算机科学与软件工程系
- en: The University of Western Australia
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大利亚大学
- en: Perth, Australia
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 珀斯，澳大利亚
- en: wenxiao.zhang@research.uwa.edu.au    Xiangrui Kong Dept. of Electrical, Electronic
    and Computer Engineering
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: wenxiao.zhang@research.uwa.edu.au    Xiangrui Kong 电气、电子与计算机工程系
- en: The University of Western Australia
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大利亚大学
- en: Perth, Australia
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 珀斯，澳大利亚
- en: xiangrui.kong@research.uwa.edu.au    Conan Dewitt Dept. of Computer Science
    and Software Engineering
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: xiangrui.kong@research.uwa.edu.au    Conan Dewitt 计算机科学与软件工程系
- en: The University of Western Australia
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大利亚大学
- en: Perth, Australia
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 珀斯，澳大利亚
- en: 22877792@student.uwa.edu.au    Thomas Braunl Dept. of Electrical, Electronic
    and Computer Engineering
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 22877792@student.uwa.edu.au    Thomas Braunl 电气、电子与计算机工程系
- en: The University of Western Australia
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大利亚大学
- en: Perth, Australia
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 珀斯，澳大利亚
- en: thomas.braunl@uwa.edu.au    Jin B. Hong Dept. of Computer Science and Software
    Engineering
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: thomas.braunl@uwa.edu.au    Jin B. Hong 计算机科学与软件工程系
- en: The University of Western Australia
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 西澳大利亚大学
- en: Perth, Australia
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 珀斯，澳大利亚
- en: jin.hong@uwa.edu.au
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: jin.hong@uwa.edu.au
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The integration of Large Language Models (LLMs) like GPT-4o into robotic systems
    represents a significant advancement in embodied artificial intelligence. These
    models can process multi-modal prompts, enabling them to generate more context-aware
    responses. However, this integration is not without challenges. One of the primary
    concerns is the potential security risks associated with using LLMs in robotic
    navigation tasks. These tasks require precise and reliable responses to ensure
    safe and effective operation. Multi-modal prompts, while enhancing the robot’s
    understanding, also introduce complexities that can be exploited maliciously.
    For instance, adversarial inputs designed to mislead the model can lead to incorrect
    or dangerous navigational decisions. This study investigates the impact of prompt
    injections on mobile robot performance in LLM-integrated systems and explores
    secure prompt strategies to mitigate these risks. Our findings demonstrate a substantial
    overall improvement of approximately 30.8% in both attack detection and system
    performance with the implementation of robust defence mechanisms, highlighting
    their critical role in enhancing security and reliability in mission-oriented
    tasks.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将像GPT-4o这样的**大语言模型（LLMs）**集成到机器人系统中代表了具身人工智能的一个重要进展。这些模型能够处理多模态提示，使它们能够生成更具上下文感知的回应。然而，这种集成并非没有挑战。一个主要的担忧是使用LLMs进行机器人导航任务可能带来的安全风险。这些任务需要精确且可靠的回应，以确保安全和有效的操作。虽然多模态提示提高了机器人的理解能力，但也引入了可能被恶意利用的复杂性。例如，设计用于误导模型的对抗性输入可能导致不正确或危险的导航决策。本研究探讨了提示注入对LLM集成系统中移动机器人性能的影响，并探索了安全提示策略以缓解这些风险。我们的研究结果表明，实施强有力的防御机制可以显著提高攻击检测和系统性能，整体提升约为30.8%，突显了这些机制在增强安全性和可靠性方面的关键作用。
- en: 'Index Terms:'
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: LLM, Mobile Robot, Embodied AI, Security, Prompt Engineering
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型、移动机器人、具身人工智能、安全、提示工程
- en: I Introduction
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Recent enhancements of Large Language Models (LLMs), such as the incorporation
    of vision features into LLMs like GPT-4o, have enabled these generalist models
    to process and respond to multi-modal inputs—including text and images—with greater
    contextual awareness and improved decision-making capabilities [[1](#bib.bib1)].
    This development allows LLMs to interpret complex scenarios more effectively,
    making them suitable for tasks that require nuanced understanding and adaptability.
    Consequently, these advancements are paving the way for more sophisticated and
    capable robotic systems, demonstrating a promising trend in the integration of
    LLMs with robotics [[2](#bib.bib2)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）的最近改进，例如将视觉功能纳入到像GPT-4o这样的LLMs中，使这些通用模型能够处理并响应包括文本和图像在内的多模态输入，具有更高的上下文感知能力和改进的决策能力
    [[1](#bib.bib1)]。这一发展使LLMs能够更有效地解读复杂场景，使其适用于需要细致理解和适应能力的任务。因此，这些进展为更复杂和高效的机器人系统铺平了道路，展示了LLMs与机器人技术集成的有前景趋势
    [[2](#bib.bib2)]。
- en: However, this technological progression is accompanied by several critical challenges,
    particularly in the realm of security and practical application. LLMs possess
    advanced capabilities for reasoning and processing complex inputs but are highly
    susceptible to various input variations [[3](#bib.bib3)]. One of the primary concerns
    in this area is the potential security risks associated with employing LLMs in
    robotic navigation tasks. These tasks demand high precision and reliability to
    ensure the robot’s safe and effective operation. For example, delivery robots,
    increasingly common in restaurants, are designed to transport food and beverages
    from the kitchen to diners’ tables efficiently and autonomously. Utilising LLMs
    for these robots enhances their ability to interpret complex instructions and
    navigate dynamic environments. However, they could be misled by adversarial inputs
    like altered table numbers or misleading verbal commands, causing them to deliver
    food to the wrong tables or collide with customers. While multi-modal prompts
    enrich a robot’s environmental understanding, they also introduce complexities
    and noise that can be exploited maliciously. For LLM-integrated mobile robotic
    systems, adversarial inputs designed to deceive the model can result in incorrect
    or hazardous navigational decisions, posing substantial risks to both the robot
    and its surroundings [[4](#bib.bib4)].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这一技术进步伴随着若干关键挑战，特别是在安全性和实际应用领域。LLM具备先进的推理和处理复杂输入的能力，但对各种输入变化非常敏感[[3](#bib.bib3)]。该领域的一个主要关注点是使用LLM进行机器人导航任务的潜在安全风险。这些任务需要高度的精确性和可靠性，以确保机器人的安全和有效运行。例如，越来越多的餐馆使用的送餐机器人被设计用来高效且自主地将食物和饮料从厨房运输到就餐者的桌子上。利用LLM可以增强这些机器人解读复杂指令和在动态环境中导航的能力。然而，它们可能会被对抗性输入误导，比如修改过的桌号或误导性的口头指令，导致将食物送到错误的桌子上或与顾客发生碰撞。虽然多模态提示丰富了机器人对环境的理解，但它们也引入了复杂性和噪声，可能会被恶意利用。对于LLM集成的移动机器人系统，旨在欺骗模型的对抗性输入可能导致错误或危险的导航决策，给机器人及其周围环境带来重大风险[[4](#bib.bib4)]。
- en: Despite the advancements in LLMs, there has been insufficient exploration of
    their integration with robotic systems, particularly concerning the security implications.
    As an emerging field, much of the current research focuses on enhancing the capabilities
    of LLMs without adequately addressing the potential vulnerabilities they introduce.
    Accordingly, in this study, we provide a practical approach to setting up an LLM-controlled
    mobile robot system in a simulation environment utilising structured prompts and
    explore the influence of prompt injection attacks on the security and reliability
    of the system. We investigate the resilience of GPT-4o against these attacks and
    how secure prompting can help them detect various adversarial inputs and mitigate
    their impact on the system. Our experiments measured various attack rates and
    the LLMs’ ability to detect these attacks, revealing that LLMs with properly engineered
    prompts exhibited a higher detection rate of adversarial inputs and responded
    more effectively to mitigate their impact.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM技术取得了进展，但对于它们与机器人系统的集成，特别是安全性问题的探索仍然不足。作为一个新兴领域，目前的研究大多集中在提升LLM的能力上，而没有充分考虑它们可能引入的潜在漏洞。因此，在本研究中，我们提供了一种在模拟环境中建立LLM控制的移动机器人系统的实际方法，利用结构化提示，并探讨了提示注入攻击对系统安全性和可靠性的影响。我们调查了GPT-4o对这些攻击的抗性，以及如何通过安全提示帮助检测各种对抗性输入并减轻其对系统的影响。我们的实验测量了不同攻击率以及LLM检测这些攻击的能力，结果表明，经过适当设计的提示的LLM在对抗性输入的检测率更高，并且对减轻其影响的响应更有效。
- en: II Related Works
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关工作
- en: II-A LLM-based Navigation Tasks
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 基于LLM的导航任务
- en: 'According to Xi et al. [[5](#bib.bib5)], an LLM-based agent comprises three
    modules: perception, brain, and action, with LLMs serving as the brain module
    that processes perception results and makes decisions on the next action. In robotic
    navigation tasks, several studies [[6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]
    have shown that LLMs can effectively process and understand the surrounding environment
    through sensory data and human instructions, subsequently producing path planning
    based on the perception results.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Xi等人[[5](#bib.bib5)]的研究，基于LLM的智能体包括三个模块：感知、脑部和行动，其中LLM作为脑部模块处理感知结果并决定下一步行动。在机器人导航任务中，一些研究[[6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)]表明，LLM可以通过感官数据和人工指令有效地处理和理解周围环境，从而根据感知结果进行路径规划。
- en: However, security and reliability concerns in such systems have also emerged
    as major issues. Externally, these systems are prone to malicious prompt injection
    attacks. Wen et al. [[4](#bib.bib4)] investigated the security vulnerabilities
    of LLM-based navigation systems and proposed a defence strategy called Navigational
    Prompt Engineering (NPE). This strategy focuses on navigation-relevant keywords
    to mitigate the impacts of adversarial suffixes, highlighting the importance of
    prompt engineering in countering prompt injection attacks. Internally, due to
    their autoregressive mechanisms, LLMs exhibit inherent randomness in their responses,
    even in similar situations. Consequently, this randomness can potentially result
    in the execution of erroneous movements [[9](#bib.bib9)]. In the context of mobile
    robots, this could lead to the robot taking unnecessary detours, getting stuck
    in loops, or failing to reach its intended destination.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，此类系统的安全性和可靠性问题也成为了主要问题。从外部来看，这些系统容易受到恶意提示注入攻击。Wen等人[[4](#bib.bib4)]调查了基于LLM的导航系统的安全漏洞，并提出了一种称为导航提示工程（NPE）的防御策略。该策略专注于与导航相关的关键词，以减轻对抗性后缀的影响，突显了提示工程在抵御提示注入攻击中的重要性。从内部来看，由于其自回归机制，LLM在响应中表现出固有的随机性，即使在类似的情况下也是如此。因此，这种随机性可能导致执行错误的动作[[9](#bib.bib9)]。在移动机器人环境中，这可能导致机器人绕道行驶、陷入循环或无法到达预定目标。
- en: II-B Prompt Engineering Techniques
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 提示工程技术
- en: LLM prompting can be divided into zero-shot prompting [[10](#bib.bib10)], which
    relies on the model’s extensive pre-trained knowledge to generate responses without
    any examples, and few-shot prompting [[9](#bib.bib9)], which involves providing
    the model with a few examples within the prompt to enhance its ability to produce
    accurate and relevant outputs. Few-shot prompting often leverages Retrieval Augmented
    Generation (RAG) [[11](#bib.bib11)], a technique that retrieves and appends the
    most relevant content from a database to the prompt, aiding in better context
    understanding and response generation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM提示可以分为零样本提示[[10](#bib.bib10)]，它依赖于模型广泛的预训练知识生成没有任何示例的响应，以及少样本提示[[9](#bib.bib9)]，它涉及在提示中提供几个示例以提高模型生成准确和相关输出的能力。少样本提示通常利用检索增强生成（RAG）[[11](#bib.bib11)]，这是一种从数据库中检索并附加最相关内容到提示中的技术，有助于更好地理解上下文和生成响应。
- en: Additionally, Wei et al. [[12](#bib.bib12)] introduced Chain-of-Thought (CoT),
    a method of breaking down the reasoning process into a sequence of logical steps
    to improve the quality and transparency of the generated responses. This process
    typically involves multi-round question-answering of user instructions with an
    LLM. Building on this, multi-agent collaboration technique [[13](#bib.bib13)]
    has emerged as an advanced approach that combines the strengths of multiple LLM
    agents working collaboratively with the structured reasoning process of CoT. Each
    agent can focus on different aspects of a problem, allowing for parallel processing,
    and they can communicate with each other for information sharing to improve the
    performance of the system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，魏等人[[12](#bib.bib12)]提出了链式思维（CoT）方法，该方法通过将推理过程分解为一系列逻辑步骤，以提高生成响应的质量和透明度。这个过程通常涉及与大型语言模型（LLM）的多轮问答。基于此，多智能体协作技术[[13](#bib.bib13)]作为一种先进的方法出现，它结合了多个LLM智能体协作工作的优势以及CoT的结构化推理过程。每个智能体可以专注于问题的不同方面，实现并行处理，并且它们可以互相沟通以共享信息，从而提高系统的性能。
- en: II-C Prompt Injection and Counteracts
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 提示注入及其对策
- en: Prompt Injection Attack Classification
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示注入攻击分类
- en: 'Cyberattacks often aim to compromise one or more aspects of the CIA (confidentiality,
    integrity, and availability) triad [[14](#bib.bib14)], as do prompt injection
    attacks. In this case, various types of prompt injection attacks can target different
    vulnerabilities within the LLM-integrated system and aim to compromise the CIA
    in various aspects. According to [[15](#bib.bib15)], the prompt injection attacks
    can be categorised as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 网络攻击通常旨在危害 CIA（三位一体：机密性、完整性和可用性）的一个或多个方面 [[14](#bib.bib14)]，提示注入攻击也是如此。在这种情况下，各种类型的提示注入攻击可以针对
    LLM 集成系统中的不同漏洞，并试图在不同方面危害 CIA。根据 [[15](#bib.bib15)]，提示注入攻击可以被分类如下：
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Goal Hijacking: Manipulating the LLM-integrated system to pursue unintended
    or malicious instructions, thereby deviating from its original purpose [[16](#bib.bib16),
    [17](#bib.bib17)].'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标劫持：操控 LLM 集成系统以执行非预期或恶意指令，从而偏离其原始目的 [[16](#bib.bib16), [17](#bib.bib17)]。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt Leaking: Extracting sensitive information or prompts from the system
    that should remain confidential, compromising the system’s privacy [[18](#bib.bib18)].'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示泄露：从系统中提取敏感信息或提示，这些信息应保密，从而危及系统的隐私 [[18](#bib.bib18)]。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Jailbreaking: Bypassing the restrictions of the LLM-integrated system to perform
    unauthorised actions or access restricted functionalities [[19](#bib.bib19)].'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 越狱：绕过 LLM 集成系统的限制，执行未经授权的操作或访问受限功能 [[19](#bib.bib19)]。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Disrupting Availability: Interfering with the normal operations of LLM-integrated
    system, causing disruptions or denial of service (DoS) [[20](#bib.bib20)].'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 干扰可用性：干扰 LLM 集成系统的正常操作，导致中断或服务拒绝 (DoS) [[20](#bib.bib20)]。
- en: Counteracts using Secure Prompting
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过安全提示进行反制
- en: Secure prompting involves creating prompts for LLMs to enhance security and
    reduce risks [[21](#bib.bib21)]. Liu et al. [[22](#bib.bib22)] explored defence
    strategies against prompt injections, dividing them into prevention-based and
    detection-based approaches. Prevention-based strategies use natural language processing
    techniques like paraphrasing and retokenisation [[23](#bib.bib23)], aiming at
    making prompts less susceptible to injection attacks by altering their structure
    and wording. Detection-based strategies identify prompt injections through external
    systems that monitor LLM behaviour using anomaly detection methods [[23](#bib.bib23),
    [24](#bib.bib24)], and internal mechanisms within the LLM that flag suspicious
    inputs [[25](#bib.bib25)].
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 安全提示涉及为 LLM 创建提示以增强安全性并降低风险 [[21](#bib.bib21)]。刘等人 [[22](#bib.bib22)] 探讨了针对提示注入的防御策略，将其分为基于预防和基于检测的方法。基于预防的策略使用自然语言处理技术，如释义和重标记
    [[23](#bib.bib23)]，旨在通过改变提示的结构和措辞，使其不易受到注入攻击。基于检测的策略通过监控 LLM 行为的异常检测方法 [[23](#bib.bib23),
    [24](#bib.bib24)] 和 LLM 内部机制来识别提示注入，这些机制标记可疑输入 [[25](#bib.bib25)]。
- en: '![Refer to caption](img/85d707f05d36d8ce7235ef6726e6d0d8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/85d707f05d36d8ce7235ef6726e6d0d8.png)'
- en: 'Figure 1: Threat Model of LLM Controlled Robotic System'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：LLM 控制的机器人系统的威胁模型
- en: III Threat Model
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 威胁模型
- en: We assume the LLM-integrated mobile robotic system is an end-to-end system,
    meaning the multi-modal sensory data collected from the mobile robot is directly
    fed into the LLM, and the movement of the mobile robot is directly controlled
    by the LLM-generated control signals. As shown in Figure [1](#S2.F1 "Figure 1
    ‣ Counteracts using Secure Prompting ‣ II-C Prompt Injection and Counteracts ‣
    II Related Works ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile
    Robotic Systems"), we model threats to an LLM-integrated mobile robot system primarily
    around vulnerabilities introduced through prompt injection attacks. The model
    explores potential attack paths, the role of multi-modal prompting, and the resulting
    threats to the robot’s operation and its interaction with the environment.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设 LLM 集成的移动机器人系统是一个端到端系统，这意味着从移动机器人收集的多模态传感数据直接输入 LLM，而移动机器人的运动由 LLM 生成的控制信号直接控制。如图
    [1](#S2.F1 "Figure 1 ‣ Counteracts using Secure Prompting ‣ II-C Prompt Injection
    and Counteracts ‣ II Related Works ‣ A Study on Prompt Injection Attack Against
    LLM-Integrated Mobile Robotic Systems") 所示，我们主要围绕通过提示注入攻击引入的漏洞对 LLM 集成的移动机器人系统进行威胁建模。该模型探讨了潜在的攻击路径、多模态提示的作用以及对机器人操作和与环境交互的威胁。
- en: Attack vectors and paths. Prompt injection attacks serve as the primary attack
    vectors, where malicious prompts are inserted into the system. These injections
    can occur through various input channels, including compromised sensor data and
    adversarial instructions. When successful, malicious prompts can manipulate the
    LLMs to generate harmful responses, leading to undesirable or dangerous actions
    by the robot.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击向量和路径。提示注入攻击作为主要攻击向量，其中恶意提示被插入系统。这些注入可以通过各种输入渠道发生，包括被破坏的传感器数据和对抗性指令。当成功时，恶意提示可以操控LLM生成有害的响应，从而导致机器人产生不期望或危险的行为。
- en: Attacker’s goal and capabilities. Since the mobile robot is performing a navigation
    task that aims to find a target object in the surrounding environment, the goals
    of the attacker in this study are to provide false and misaligned information
    to the LLM, aiming to confuse the LLM in its reasoning and decision-making processes.
    This can result in generating control signals that either cause a collision with
    an obstacle or move the robot away from the target object. Exploiting the vulnerabilities
    of the LLM’s multi-modality feature, the attacker can pose as a normal human operator
    and inject malicious text-based prompts through the human operator interface,
    or inject false information or noise into the sensory data, such as replacing
    the image captured by the front camera with a fake image that confuses the LLM.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者的目标和能力。由于移动机器人正在执行一个旨在寻找周围环境中目标物体的导航任务，本研究中的攻击者目标是向LLM提供虚假和不一致的信息，旨在混淆LLM的推理和决策过程。这可能导致生成控制信号，导致与障碍物发生碰撞或使机器人远离目标物体。利用LLM多模态特性的漏洞，攻击者可以伪装成正常的人工操作员，通过人工操作员界面注入恶意基于文本的提示，或者将虚假信息或噪声注入传感器数据，例如用虚假的图像替换前置摄像头捕获的图像，从而混淆LLM。
- en: '![Refer to caption](img/836b922074c18d2172afc76d57599899.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/836b922074c18d2172afc76d57599899.png)'
- en: (a)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/939d004d1fce1cd20e8f8194c9f13497.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/939d004d1fce1cd20e8f8194c9f13497.png)'
- en: (b)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 2: LiDAR Processing'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：LiDAR 处理
- en: IV Methodology
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 方法论
- en: IV-A LLM-Integrated Mobile Robot System
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A LLM集成移动机器人系统
- en: Multi-Modal Input Data
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多模态输入数据
- en: 'The LLM-integrated mobile robot system used in this study is presented in Figure
    [3](#S4.F3 "Figure 3 ‣ Safety Validation ‣ IV-A LLM-Integrated Mobile Robot System
    ‣ IV Methodology ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile
    Robotic Systems"). There are three input modalities: LiDAR signal, camera view,
    and human instruction. The LiDAR signal and camera view are captured from the
    LiDAR sensor and front camera, respectively. The LiDAR is a 360-degree distance
    sensor that measures the distance in the surrounding areas of the mobile robot,
    returning an array of 360 elements, with each element representing the distance
    to the nearest obstacle at that degree. Since LLMs are typically more effective
    at processing structured data, we convert the raw LiDAR data collected from the
    simulator (Figure [2(a)](#S3.F2.sf1 "Figure 2(a) ‣ Figure 2 ‣ III Threat Model
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems"))
    into a structured polar axis image (Figure [2(b)](#S3.F2.sf2 "Figure 2(b) ‣ Figure
    2 ‣ III Threat Model ‣ A Study on Prompt Injection Attack Against LLM-Integrated
    Mobile Robotic Systems")) that presents the surroundings in an image view, providing
    a more coherent and standardised input format. The camera image and LiDAR image
    are then processed into encoded images, while human instructions are collected
    as text in natural language.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中使用的LLM集成移动机器人系统如图[3](#S4.F3 "图 3 ‣ 安全验证 ‣ IV-A LLM集成移动机器人系统 ‣ IV 方法论 ‣ 关于对LLM集成移动机器人系统的提示注入攻击的研究")所示。系统有三种输入模式：LiDAR信号、相机视图和人工指令。LiDAR信号和相机视图分别从LiDAR传感器和前置摄像头获取。LiDAR是一个360度距离传感器，可以测量移动机器人周围区域的距离，返回一个包含360个元素的数组，每个元素表示该角度到最近障碍物的距离。由于LLM通常更擅长处理结构化数据，我们将从模拟器收集的原始LiDAR数据（图[2(a)](#S3.F2.sf1
    "图 2(a) ‣ 图 2 ‣ III 威胁模型 ‣ 关于对LLM集成移动机器人系统的提示注入攻击的研究")）转换为结构化的极坐标轴图像（图[2(b)](#S3.F2.sf2
    "图 2(b) ‣ 图 2 ‣ III 威胁模型 ‣ 关于对LLM集成移动机器人系统的提示注入攻击的研究")），以图像视图呈现周围环境，提供了更连贯和标准化的输入格式。然后，将相机图像和LiDAR图像处理成编码图像，而人工指令则以自然语言文本的形式收集。
- en: Prompt Assembling
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示组装
- en: The inputs are then fed into the prompt assembling component, where they are
    processed into a structured prompt to facilitate the LLM reasoning and decision-making
    process. The prompt assembling consists of formulating the prompt into a system
    prompt, a user prompt, and an assistant prompt. The system prompt is used to define
    the role, task, and response format for the LLM to follow, while the user prompt
    is where we receive the multi-modal input prompts, wrapped with proper text indicators
    to facilitate the reasoning process. Assistant prompts are provided by the state
    management component or secure prompting for defence purposes and are appended
    to either the system prompt or user prompt based on specific use case scenarios.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，输入被送入提示组装组件，在这里它们被处理成结构化的提示，以便于 LLM 的推理和决策过程。提示组装包括将提示制定成系统提示、用户提示和助手提示。系统提示用于定义
    LLM 需要遵循的角色、任务和响应格式，而用户提示是我们接收多模态输入提示的地方，用适当的文本指示符包装，以促进推理过程。助手提示由状态管理组件或用于防御的安全提示提供，并根据具体的使用场景附加到系统提示或用户提示中。
- en: State Management
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 状态管理
- en: The state management component is used to process and manage the response of
    LLMs, which can be used as the few-shot learning for the next round of LLM inference.
    In this case, we append the information of the last command execution result to
    the user prompt component, which aims to let the LLM take into account past experiences
    and generate control signals based on that.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 状态管理组件用于处理和管理 LLM 的响应，这可以作为下一轮 LLM 推理的少量学习。在这种情况下，我们将上一个命令执行结果的信息附加到用户提示组件中，目的是让
    LLM 考虑过去的经验并基于此生成控制信号。
- en: Safety Validation
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全验证
- en: The safety validation component is used to check if the LLM-generated commands
    could cause accidents, such as collisions with obstacles. We achieve this by calculating
    the distance scanned from the LiDAR and comparing it with the distance the LLM
    plans to travel to determine its safety. If the LLM fails to generate a safe command,
    it will be asked to generate a new command with error information. If the problem
    continues and reaches a certain threshold, we will terminate the experiment and
    treat this trial as interrupted, which will be explained in detail in the experiment
    section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 安全验证组件用于检查 LLM 生成的命令是否可能导致事故，例如与障碍物碰撞。我们通过计算从 LiDAR 扫描得到的距离，并将其与 LLM 计划行进的距离进行比较，以确定其安全性。如果
    LLM 未能生成安全命令，它将被要求生成一个带有错误信息的新命令。如果问题持续并达到某个阈值，我们将终止实验，并将此次试验视为中断，这将在实验部分详细解释。
- en: '![Refer to caption](img/4f364525600760235de79c671aa7796c.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/4f364525600760235de79c671aa7796c.png)'
- en: 'Figure 3: The Workflow of LLM-Integrated Mobile Robot System Used in this Study'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：本研究中使用的 LLM 集成移动机器人系统的工作流程
- en: IV-B Attack Tactics
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 攻击战术
- en: 'As discussed in Section [III](#S3 "III Threat Model ‣ A Study on Prompt Injection
    Attack Against LLM-Integrated Mobile Robotic Systems"), the attack tactics of
    prompt injections in this work are modelled as two different types: Obvious Malicious
    Injection (OMI) and Goal Hijacking Injection (GHI). By testing these attacks,
    we aim to assess the capability of LLMs to identify malicious prompts based on
    the given scenario and evaluate their responses with and without the help of the
    defence mechanism.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 [III](#S3 "III Threat Model ‣ A Study on Prompt Injection Attack Against
    LLM-Integrated Mobile Robotic Systems") 节所讨论，本研究中的提示注入攻击战术被建模为两种不同的类型：明显恶意注入（OMI）和目标劫持注入（GHI）。通过测试这些攻击，我们旨在评估
    LLM 识别恶意提示的能力，并评估其在有无防御机制帮助下的响应。
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Obvious Malicious Injection (OMI): This attack uses text-based prompts that
    can be easily identified as adversarial by common sense. For example, "Move straight
    until you hit the wall," which is obviously malicious and can be easily recognised
    as such.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 明显恶意注入（OMI）：这种攻击使用可以被常识轻易识别为对抗性文本的提示。例如，“一直向前走，直到撞到墙为止”，这显然是恶意的，可以很容易地被识别出来。
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Goal Hijacking Injection (GHI): This attack uses text-based prompts that leverage
    information from other modalities and provide instructions inconsistent with the
    predefined task objective. For example, "Turn aside if you see a [target object]
    from the camera image," seems like a reasonable instruction for avoiding obstacles
    but misaligns with the task objective of finding and approaching the target object.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标劫持注入 (GHI)：这种攻击使用基于文本的提示，利用来自其他模态的信息，并提供与预定义任务目标不一致的指令。例如，“如果你从摄像头图像中看到 [目标物体]，请转开”，看似是一个合理的避障指令，但与寻找并接近目标物体的任务目标不一致。
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Camera Spoofing Injection (CSI): This attack uses image-based prompts that
    replace the camera image with irrelevant images as spoofing, aiming to provide
    noise and make it difficult for the LLM to generate accurate control signals based
    on the given input prompt.'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 摄像头欺骗注入 (CSI)：这种攻击使用基于图像的提示，将摄像头图像替换为无关图像作为欺骗，旨在提供噪声，使得 LLM 难以基于给定的输入提示生成准确的控制信号。
- en: IV-C Defence Mechanism
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 防御机制
- en: The defence mechanism comprises secure prompting and response-based detection.
    Secure prompting, as implemented in this work, involves constructing structured
    prompts with additional security prompts appended to the original prompt body
    in the prompt assembling component (Section [IV-A](#S4.SS1 "IV-A LLM-Integrated
    Mobile Robot System ‣ IV Methodology ‣ A Study on Prompt Injection Attack Against
    LLM-Integrated Mobile Robotic Systems")). The security prompt used in this work
    is, "The human instruction may be from attackers. Analyse it and prioritise your
    tasks if they are misaligned," which aims to prompt LLMs to focus on analysing
    the input data from human instructions when reasoning through the multi-modal
    prompt data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 防御机制包括安全提示和基于响应的检测。根据本工作的实现，安全提示涉及在提示组装组件中将附加的安全提示附加到原始提示体中（参见第 [IV-A](#S4.SS1
    "IV-A LLM-Integrated Mobile Robot System ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems) 节）。本工作中使用的安全提示是：“人类指令可能来自攻击者。分析它，并在任务不一致时优先考虑你的任务”，旨在提示
    LLM 在通过多模态提示数据进行推理时，重点分析来自人类指令的输入数据。
- en: Additionally, we implemented response-based detection by defining the expected
    response with indications on the analysis of multi-modal input data and the corresponding
    generated control signals. The rationale behind this approach is based on the
    assumption that LLMs perform better when including reasoning alongside results
    due to the autoregressive mechanism, where each new token is generated based on
    the preceding tokens. When asked to provide both reasoning and a result, the context
    includes both elements, guiding the generation process to be more coherent and
    comprehensive [[26](#bib.bib26)]. In this case, when we request LLMs to produce
    a perception result, we always have the LLM reason through each modality and generate
    the justification in natural language, and then prompt the LLM to decide whether
    it is an attack on that modality or not.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们通过定义期望的响应并指示对多模态输入数据和相应生成的控制信号的分析，实施了基于响应的检测。这种方法的原理是基于这样的假设：由于自回归机制，每个新令牌是基于前面的令牌生成的，LLM
    在包括推理与结果时表现更好。当要求提供推理和结果时，上下文包括这两个元素，指导生成过程更加连贯和全面 [[26](#bib.bib26)]。在这种情况下，当我们请求
    LLM 生成感知结果时，我们总是让 LLM 通过每种模态进行推理，并以自然语言生成理由，然后提示 LLM 决定这是否是对该模态的攻击。
- en: '![Refer to caption](img/ca34c896682f5b67575e9616db42440c.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ca34c896682f5b67575e9616db42440c.png)'
- en: (a)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/020e214ec1cb5f0c0e5cec5b0dfe1bc1.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/020e214ec1cb5f0c0e5cec5b0dfe1bc1.png)'
- en: (b)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/1250cb225ad2cd17925bce82b969df42.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1250cb225ad2cd17925bce82b969df42.png)'
- en: (c)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: '![Refer to caption](img/0d27507662c827410a2fd8464086808b.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0d27507662c827410a2fd8464086808b.png)'
- en: (d)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: (d)
- en: 'Figure 4: Simulation Environment'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：仿真环境
- en: V Experiment
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 实验
- en: V-A Experimantal Setup
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 实验设置
- en: We used EyeSim VR [[27](#bib.bib27)], a simulator built on Unity 3D with virtual
    reality features, as the simulation environment for the experiments in this study.
    Our experiments involved a mobile robot tasked with exploring the area, finding
    and approaching a target object. As shown in Figure [4(a)](#S4.F4.sf1 "Figure
    4(a) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems"), the target object
    is a red can located in the bottom right corner of the map, while the mobile robot,
    represented as an S4 bot, is located at the top left corner. The map is presented
    as an indoor environment containing walls and soccer balls as static obstacles,
    while a lab bot moves randomly on the map, serving as dynamic obstacles that hinder
    the S4 bot’s progress towards the target object.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 EyeSim VR [[27](#bib.bib27)]，这是一个基于 Unity 3D 构建并具有虚拟现实功能的模拟器，作为本研究中实验的模拟环境。我们的实验涉及一个移动机器人，该机器人负责探索区域，寻找并接近目标物体。如图
    [4(a)](#S4.F4.sf1 "Figure 4(a) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")
    所示，目标物体是一个位于地图右下角的红色罐子，而移动机器人，表示为 S4 bot，位于地图的左上角。地图展示了一个室内环境，包含墙壁和作为静态障碍物的足球，同时一个实验室机器人在地图上随机移动，充当动态障碍物，阻碍
    S4 bot 向目标物体的前进。
- en: V-B Evaluation Metrics
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 评估指标
- en: Security Metric
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全指标
- en: To evaluate the resilience of LLMs against prompt injection attacks, we will
    calculate the precision, recall, and F1-score of attack detection. The result
    of attack detection by the LLM is determined based on the perception results generated
    by the LLM itself, which involves the model’s ability to identify and classify
    input prompts as either malicious or benign.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 LLM 对提示注入攻击的弹性，我们将计算攻击检测的精确度、召回率和 F1 分数。LLM 对攻击的检测结果是基于 LLM 自身生成的感知结果来确定的，这涉及到模型识别和分类输入提示为恶意或良性提示的能力。
- en: These metrics provide insights into the model’s reasoning and decision-making
    capabilities under complex environments with attacks involved. Precision indicates
    how accurately the model identifies attacks, ensuring that flagged attacks are
    indeed genuine. Recall measures the model’s ability to detect all potential attacks,
    highlighting its robustness in recognising true threats. The F1-score balances
    precision and recall, offering a comprehensive measure of the model’s performance.
    By using these metrics, we can assess the LLM’s ability to reason through complex
    scenarios and make reliable decisions, ensuring the system’s security and reliability
    against prompt injection attacks.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标提供了模型在复杂环境中处理攻击时的推理和决策能力的洞察。精确度表示模型识别攻击的准确性，确保标记的攻击确实是真实的。召回率衡量模型检测所有潜在攻击的能力，突出其识别真实威胁的鲁棒性。F1
    分数平衡了精确度和召回率，提供了对模型性能的全面衡量。通过使用这些指标，我们可以评估 LLM 在复杂情景中的推理能力和做出可靠决策的能力，确保系统在应对提示注入攻击时的安全性和可靠性。
- en: Performance Metric
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'Based on the task objective and to prevent an infinite loop where the LLM fails
    to reason through the environment and generate suitable control commands for the
    mobile robot due to attacks and complex situations, we set a time limit of 100
    seconds for each experiment trial and allow a maximum of 3 retries, as mentioned
    in Section [IV-A](#S4.SS1 "IV-A LLM-Integrated Mobile Robot System ‣ IV Methodology
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems").
    Each experiment trial can result in one of three outcomes: completed, timeout,
    and interrupted. A trial is considered completed if the robot successfully finds
    and approaches the target object within the time limit (Figure [4(b)](#S4.F4.sf2
    "Figure 4(b) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on
    Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")). It is
    considered timeout if the robot fails to reach the target object within the time
    limit but can be safely retrieved (Figure [4(c)](#S4.F4.sf3 "Figure 4(c) ‣ Figure
    4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on Prompt Injection Attack
    Against LLM-Integrated Mobile Robotic Systems")). A trial is deemed interrupted
    if the robot encounters an accident, such as crashing into the lab bot or other
    static obstacles, and cannot be safely retrieved (Figure [4(d)](#S4.F4.sf4 "Figure
    4(d) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems")). We use Mission
    Oriented Exploration Rate (MOER) as introduced in our previous work [hidden].
    The formula is denoted as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务目标，并为了防止在攻击和复杂情况中 LLM 未能推理环境并生成适合的控制命令而导致无限循环，我们为每个实验试验设置了 100 秒的时间限制，并允许最多
    3 次重试，如第 [IV-A](#S4.SS1 "IV-A LLM-Integrated Mobile Robot System ‣ IV Methodology
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")
    节所述。每个实验试验可能有三种结果之一：完成、超时和中断。如果机器人在时间限制内成功找到并接近目标对象，则试验被认为是完成的（图 [4(b)](#S4.F4.sf2
    "Figure 4(b) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology ‣ A Study on
    Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")）。如果机器人未能在时间限制内到达目标对象，但可以安全回收，则视为超时（图
    [4(c)](#S4.F4.sf3 "Figure 4(c) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")）。如果机器人遇到事故，如撞上实验室机器人或其他静态障碍物，且无法安全回收，则试验被认为是中断的（图
    [4(d)](#S4.F4.sf4 "Figure 4(d) ‣ Figure 4 ‣ IV-C Defence Mechanism ‣ IV Methodology
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")）。我们使用在我们之前的工作
    [hidden] 中介绍的任务导向探索率（MOER）。公式表示如下：
- en: '|  | $\textit{MOER}=\frac{1}{N}\sum_{j=0}^{N}\frac{s_{j}}{&#124;S_{max}&#124;}\cdot
    t_{j}$ |  | (1) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textit{MOER}=\frac{1}{N}\sum_{j=0}^{N}\frac{s_{j}}{&#124;S_{max}&#124;}\cdot
    t_{j}$ |  | (1) |'
- en: '|  | $$t_{j}=\begin{cases}\frac{&#124;S_{max}&#124;}{s_{j}}&amp;\text{if the
    trial is {completed}}\\ \alpha&amp;\text{if the trial is {timeout}}\\'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$t_{j}=\begin{cases}\frac{&#124;S_{max}&#124;}{s_{j}}&amp;\text{如果试验是{完成}}\\
    \alpha&amp;\text{如果试验是{超时}}\\'
- en: \beta&amp;\text{if the trial is {interrupted}}\\
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: \beta&amp;\text{如果试验被{中断}}\\
- en: \end{cases}$$ |  | (2) |
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: \end{cases}$$ |  | (2) |
- en: It is defined based on the number of steps taken in a trial ($s_{j}$) assigned
    based on the outcome of the trial. In addition, we also calculate metrics such
    as token usage and response time per API call on average to provide insights into
    how well the system is performing in terms of efficiency and speed.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 它是基于试验中采取的步骤数量（$s_{j}$）并根据试验的结果分配的。此外，我们还计算诸如每次 API 调用的 token 使用量和响应时间等指标，以提供系统在效率和速度方面的表现洞察。
- en: V-C Overall Improvement Calculation
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 总体改进计算
- en: In this section, we presents the methodology used to calculate the overall improvement
    in both attack detection and performance due to the application of the defence
    mechanism. The attack detection improvement is evaluated using weighted precision
    (WPI), recall (WRI), and F1-score (WFI) metrics, while the performance improvement
    is assessed using weighted MOER (WMI), token usage (WTU), and response time (WRT)
    metrics. The weighted improvements consider various attack rates ($AR_{i}$) for
    each metric. The formula for calculating the weighted precision improvement (WPI),
    weighted recall improvement (WRI), and weighted F1-score improvement (WFI) involve
    comparing the metrics with and without defence, weighted by their respective attack
    rates. Similarly, the weighted MOER improvement (WMI), weighted token usage increase
    (WTU), and weighted response time increase (WRT) are calculated. The overall attack
    detection improvement (OADI) and overall performance improvement (OPI) are then
    determined by averaging the respective weighted improvements. Since WTU and WRT
    are negative contributions, we use subtraction for these two in the formula. Finally,
    the general improvement (GI) representing the overall improvement is obtained
    by averaging the OADI and OPI. This comprehensive approach provides a nuanced
    understanding of the effectiveness of defence mechanisms in enhancing both attack
    detection and system performance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了用于计算由于应用防御机制而在攻击检测和性能方面的整体改进的方法。攻击检测的改进通过加权精度（WPI）、召回率（WRI）和F1分数（WFI）指标进行评估，而性能改进则通过加权MOER（WMI）、标记使用量（WTU）和响应时间（WRT）指标进行评估。加权改进考虑了每个指标的不同攻击率（$AR_{i}$）。计算加权精度改进（WPI）、加权召回率改进（WRI）和加权F1分数改进（WFI）的公式涉及比较有无防御的指标，加权考虑各自的攻击率。同样，计算加权MOER改进（WMI）、加权标记使用量增加（WTU）和加权响应时间增加（WRT）。然后，通过对各自的加权改进取平均值来确定整体攻击检测改进（OADI）和整体性能改进（OPI）。由于WTU和WRT是负贡献，我们在公式中对这两个指标使用减法。最后，代表整体改进的通用改进（GI）是通过对OADI和OPI取平均值来获得的。这种全面的方法提供了对防御机制在提升攻击检测和系统性能方面有效性的细致理解。
- en: 'The weighted improvement for each metric can be calculated as:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 每个指标的加权改进可以计算为：
- en: '|  | $WPI=\frac{\sum_{i}\left(\frac{P_{d,i}-P_{nd,i}}{P_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (3) |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  | $WPI=\frac{\sum_{i}\left(\frac{P_{d,i}-P_{nd,i}}{P_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (3) |'
- en: '|  | $WRI=\frac{\sum_{i}\left(\frac{R_{d,i}-R_{nd,i}}{R_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (4) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | $WRI=\frac{\sum_{i}\left(\frac{R_{d,i}-R_{nd,i}}{R_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (4) |'
- en: '|  | $WFI=\frac{\sum_{i}\left(\frac{F_{d,i}-F_{nd,i}}{F_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (5) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | $WFI=\frac{\sum_{i}\left(\frac{F_{d,i}-F_{nd,i}}{F_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (5) |'
- en: '|  | $WMI=\frac{\sum_{i}\left(\frac{M_{d,i}-M_{nd,i}}{M_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (6) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | $WMI=\frac{\sum_{i}\left(\frac{M_{d,i}-M_{nd,i}}{M_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (6) |'
- en: '|  | $WTU=\frac{\sum_{i}\left(\frac{T_{d,i}-T_{nd,i}}{T_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (7) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | $WTU=\frac{\sum_{i}\left(\frac{T_{d,i}-T_{nd,i}}{T_{nd,i}}\right)\cdot
    AR_{i}}{\sum_{i}AR_{i}}$ |  | (7) |'
- en: '|  | $1$2 |  | (8) |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (8) |'
- en: 'The overall attack detection improvement is given by:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 整体攻击检测改进由以下公式给出：
- en: '|  | $OADI=\frac{WPI+WRI+WFI}{3}$ |  | (9) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | $OADI=\frac{WPI+WRI+WFI}{3}$ |  | (9) |'
- en: 'The overall performance improvement is given by:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 整体性能改进由以下公式给出：
- en: '|  | $OPI=\frac{WMI-WTU-WRT}{3}$ |  | (10) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | $OPI=\frac{WMI-WTU-WRT}{3}$ |  | (10) |'
- en: 'The general improvement representing the overall improvement is:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 代表整体改进的通用改进为：
- en: '|  | $GI=\frac{OADI+OPI}{2}$ |  | (11) |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | $GI=\frac{OADI+OPI}{2}$ |  | (11) |'
- en: '![Refer to caption](img/eb3b590fde375d6bece8fdb0b0d96ed2.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/eb3b590fde375d6bece8fdb0b0d96ed2.png)'
- en: (a)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/f1153368e761c1881da93711c240b7d8.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f1153368e761c1881da93711c240b7d8.png)'
- en: (b)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/dbd4499e58c922759c202783c38e0c3a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/dbd4499e58c922759c202783c38e0c3a.png)'
- en: (c)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: 'Figure 5: Attack Detection'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：攻击检测
- en: '![Refer to caption](img/4eff6db704a856984d67a7770b7118f4.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4eff6db704a856984d67a7770b7118f4.png)'
- en: (a)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/fcfac67811d168072ad3fba18021581d.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fcfac67811d168072ad3fba18021581d.png)'
- en: (b)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: '![Refer to caption](img/29577071e3d2d6efcd3c07bffae4526f.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/29577071e3d2d6efcd3c07bffae4526f.png)'
- en: (c)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: (c)
- en: 'Figure 6: Performance'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：性能
- en: V-D Results and Analysis
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D 结果与分析
- en: Attack Detection
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击检测
- en: As shown in Figure [5](#S5.F5 "Figure 5 ‣ V-C Overall Improvement Calculation
    ‣ V Experiment ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile
    Robotic Systems"), the data provided for precision, recall, and F1-score metrics
    across different attack rates (0.3, 0.5, 0.7, 1.0) for two attack types (OMI and
    GHI) under conditions of "No Defence" and "Defence Applied" highlights the impact
    of defence mechanisms on attack detection performance. Notably, for GHI attacks,
    the precision, recall, and F1-score values are zero under "No Defence" across
    all attack rates. This indicates that the system is unable to identify GHI attacks
    without the application of defence mechanisms, underscoring the critical importance
    of these defences. In addition, CSI is not showing in either set of conditions
    because the LLM failed to detect this attack in any of the cases during the experiment.
    This indicates that further defensive measures are necessary to address such attacks.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [5](#S5.F5 "Figure 5 ‣ V-C Overall Improvement Calculation ‣ V Experiment
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")
    所示，提供的数据涵盖了不同攻击率（0.3、0.5、0.7、1.0）下两种攻击类型（OMI 和 GHI）的精准度、召回率和 F1 值指标，比较了“无防御”和“防御应用”条件下防御机制对攻击检测性能的影响。特别是，对于
    GHI 攻击，“无防御”下所有攻击率的精准度、召回率和 F1 值均为零。这表明系统在没有防御机制的情况下无法识别 GHI 攻击，凸显了这些防御的重要性。此外，CSI
    在任何条件下均未显示，因为 LLM 在实验中未能检测到此攻击。这表明需要进一步的防御措施来应对此类攻击。
- en: Examining the results for OMI attacks, precision under "No Defence" varies significantly
    across attack rates, ranging from 0.6 to 1.0\. With "Defence Applied," precision
    remains consistently high (0.8 to 1.0) across all attack rates, indicating that
    defence mechanisms are effective in maintaining high precision. Recall for OMI
    under "No Defence" is generally low, ranging from 0.19 to 0.33, while "Defence
    Applied" conditions show slight improvement, with recall values ranging from 0.21
    to 0.4\. The F1-score follows a similar trend, being low under "No Defence" (0.3
    to 0.46) but improving with "Defence Applied" (0.33 to 0.55). For GHI attacks,
    the lack of detection capability under "No Defence" is evident, as all precision,
    recall, and F1-score values are zero. However, with "Defence Applied," precision
    is high (0.9 to 1.0), recall ranges from 0.13 to 0.54, and F1-scores improve significantly
    (0.21 to 0.65), particularly at lower attack rates.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 OMI 攻击的结果，“无防御”下的精准度在不同攻击率下变化显著，范围从 0.6 到 1.0。启用“防御后”，精准度在所有攻击率下保持一致地高（0.8
    到 1.0），表明防御机制在维持高精准度方面是有效的。“无防御”下的 OMI 召回率通常较低，范围从 0.19 到 0.33，而“防御应用”条件下有所改善，召回率范围从
    0.21 到 0.4。F1 值也呈现类似的趋势，在“无防御”下较低（0.3 到 0.46），但在“防御应用”下有所提高（0.33 到 0.55）。对于 GHI
    攻击，在“无防御”下检测能力缺失，所有的精准度、召回率和 F1 值都为零。然而，在“防御应用”下，精准度高（0.9 到 1.0），召回率范围从 0.13 到
    0.54，F1 值显著提高（0.21 到 0.65），特别是在较低的攻击率下。
- en: The analysis clearly demonstrates that defence mechanisms significantly enhance
    the performance of attack detection for both OMI and GHI attack types. With defence
    mechanisms in place, precision remains consistently high across various attack
    rates, and both recall and F1-score metrics show notable improvement. However,
    the impact on recall is less pronounced compared to precision, indicating that
    while defence mechanisms are effective in ensuring that detected attacks are correctly
    identified, there is still room for improvement in identifying all possible attacks.
    The zero values for GHI attacks under "No Defence" highlight the system’s complete
    inability to detect this type of attack without defence mechanisms, emphasizing
    the critical role of these defences in assisting LLMs in performing effective
    attack detection and identification.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 分析清楚地表明，防御机制显著提升了对 OMI 和 GHI 攻击类型的检测性能。启用防御机制后，各种攻击率下的精准度保持一致地高，而召回率和 F1 值指标则表现出显著的改善。然而，召回率的改善不如精准度明显，这表明尽管防御机制在确保检测到的攻击被正确识别方面效果良好，但在识别所有可能的攻击方面仍有改进的空间。在“无防御”下，GHI
    攻击的零值突显出系统在没有防御机制时完全无法检测此类攻击，强调了这些防御在帮助大型语言模型（LLM）进行有效攻击检测和识别中的关键作用。
- en: Performance
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能
- en: Since CSI attacks cannot be identified by the LLM as mentioned in Section [V-D](#S5.SS4.SSS0.Px1
    "Attack Detection ‣ V-D Results and Analysis ‣ V Experiment ‣ A Study on Prompt
    Injection Attack Against LLM-Integrated Mobile Robotic Systems"), we analysed
    performance under OMI and GHI attacks only. Figure [6](#S5.F6 "Figure 6 ‣ V-C
    Overall Improvement Calculation ‣ V Experiment ‣ A Study on Prompt Injection Attack
    Against LLM-Integrated Mobile Robotic Systems") shows the performance metrics
    of MOER, token usage, and response time across different attack rates (0, 0.3,
    0.5, 0.7, 1.0) under "No Defence" and "Defence Applied" conditions. The MOER metric
    indicates system performance in mission-oriented navigation tasks controlled by
    an LLM, with higher values representing better performance. Token usage and response
    time metrics represent the efficiency and speed of each API call on average.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CSI攻击无法被LLM识别，如第[V-D](#S5.SS4.SSS0.Px1 "Attack Detection ‣ V-D Results and
    Analysis ‣ V Experiment ‣ A Study on Prompt Injection Attack Against LLM-Integrated
    Mobile Robotic Systems")节所述，我们仅分析了OMI和GHI攻击下的性能。图[6](#S5.F6 "Figure 6 ‣ V-C Overall
    Improvement Calculation ‣ V Experiment ‣ A Study on Prompt Injection Attack Against
    LLM-Integrated Mobile Robotic Systems")展示了在不同攻击率（0, 0.3, 0.5, 0.7, 1.0）下，“无防御”和“应用防御”条件下的MOER、令牌使用量和响应时间的性能指标。MOER指标表示由LLM控制的任务导向导航任务的系统性能，值越高表示性能越好。令牌使用量和响应时间指标表示每次API调用的效率和速度。
- en: For OMI attacks, the MOER metric under "No Defence" decreases as the attack
    rate increases, ranging from 0.5 to 0.13\. When "Defence Applied," MOER values
    improve and are generally higher, peaking at 0.67\. GHI attacks show low MOER
    values without defence, while "Defence Applied" conditions show some improvement,
    with the highest value reaching 0.48\. Token usage for OMI attacks decreases without
    defence but increases with defence, indicating higher resource usage with improved
    performance. For GHI attacks, token usage remains stable without defence but increases
    slightly with defence. Response time for OMI attacks increases slightly without
    defence but varies more with defence, peaking at 7.1 seconds. GHI attacks show
    consistent response times without defence, but higher variability with defence,
    peaking at 9.3 seconds.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于OMI攻击，在“无防御”下，MOER指标随着攻击率的增加而下降，从0.5降到0.13。当“应用防御”时，MOER值有所改善，通常更高，峰值为0.67。GHI攻击在没有防御的情况下显示出较低的MOER值，而“应用防御”条件下有所改善，最高值达到0.48。OMI攻击的令牌使用量在无防御情况下减少，但在有防御时增加，表明性能改善伴随更高的资源使用。对于GHI攻击，令牌使用量在无防御时保持稳定，但在有防御时略有增加。OMI攻击的响应时间在无防御情况下略微增加，但在有防御时变化更大，峰值为7.1秒。GHI攻击在无防御情况下响应时间保持一致，但在有防御时波动较大，峰值为9.3秒。
- en: The data suggests that defence mechanisms significantly enhance the performance
    of the system, particularly for OMI attacks, as indicated by higher MOER values.
    However, the increase in token usage and response time with defence mechanisms
    highlights a trade-off between improved performance and resource consumption.
    These findings underscore the importance of optimising defence strategies to balance
    robust attack detection with efficient system performance. For GHI attacks, while
    there is an improvement with defence, the performance gains are less pronounced,
    indicating a need for further optimisation in handling these attack types.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表明，防御机制显著提高了系统性能，特别是对OMI攻击，如更高的MOER值所示。然而，防御机制带来的令牌使用量和响应时间的增加突显了改进性能与资源消耗之间的权衡。这些发现强调了优化防御策略以平衡强大的攻击检测与高效系统性能的重要性。对于GHI攻击，虽然防御有一定改进，但性能提升不够明显，表明需要进一步优化对这些攻击类型的处理。
- en: Overall Improvement
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总体改进
- en: As shown in Section [V-C](#S5.SS3 "V-C Overall Improvement Calculation ‣ V Experiment
    ‣ A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems"),
    we calculated the weighted and overall improvements across various attack rates
    (0, 0.3, 0.5, 0.7, 1.0). This quantified the impact of defence mechanisms on attack
    detection and system performance, capturing the improvements and trade-offs involved.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如第[V-C](#S5.SS3 "V-C Overall Improvement Calculation ‣ V Experiment ‣ A Study
    on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems")节所示，我们计算了不同攻击率（0,
    0.3, 0.5, 0.7, 1.0）下的加权和总体改进。这量化了防御机制对攻击检测和系统性能的影响，捕捉了涉及的改进和权衡。
- en: Key metrics highlight system performance. The WPI is 51.9%, reflecting a significant
    reduction in false positives. The WRI stands at 28.1%, showing improved attack
    identification with room for enhancement. The WFI is 31.4%, indicating a better
    balance between precision and recall.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 关键指标突显了系统性能。WPI 为 51.9%，反映了假阳性的显著减少。WRI 为 28.1%，显示了攻击识别的改进还有提升空间。WFI 为 31.4%，表明了精确度和召回率之间更好的平衡。
- en: Further evaluation shows the WMI at 99.9%, highlighting substantial performance
    improvement in mission-oriented tasks. However, the WTU has increased by 2.9%,
    indicating higher resource consumption and the WRT has risen by 23.9%, reflecting
    longer response time due to additional computational load.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步评估显示，WMI 达到 99.9%，突显了在任务导向型任务中性能的显著提升。然而，WTU 增加了 2.9%，表明资源消耗更高，WRT 上升了 23.9%，反映了由于额外计算负载导致的响应时间延长。
- en: Combining these metrics, the OADI is 37.1%, underscoring the critical role of
    defence mechanisms in enhancing detection capabilities. The OPI is 24.4%, showing
    meaningful performance gains despite trade-offs. The GI, representing overall
    improvement, is approximately 30.8%. This highlights the significant positive
    impact of defence mechanisms on attack detection and system performance, demonstrating
    the importance of robust defence strategies in mission-oriented tasks.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 结合这些指标，OADI 为 37.1%，突显了防御机制在增强检测能力方面的关键作用。OPI 为 24.4%，尽管存在权衡，但显示了有意义的性能提升。GI
    代表整体改进，大约为 30.8%。这突显了防御机制对攻击检测和系统性能的显著积极影响，展示了在任务导向型任务中强大防御策略的重要性。
- en: VI Discussion
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 讨论
- en: VI-A Limitations of the Current Approach
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 当前方法的局限性
- en: While our approach demonstrates significant improvements, it has notable limitations.
    The WRI of 28.1% suggests that false negatives are still a concern, indicating
    that some sophisticated attacks may bypass the current defences. Additionally,
    the increases in resource consumption (WTU of 2.9%) and response time (WRT of
    23.9%) highlight the trade-off between enhanced detection capabilities and system
    performance, which may not be sustainable for systems with limited resources or
    real-time processing requirements.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的方法展示了显著的改进，但也存在显著的局限性。28.1% 的 WRI 表明假阴性仍然是一个问题，意味着一些复杂的攻击可能绕过当前的防御。此外，资源消耗的增加（WTU
    为 2.9%）和响应时间的增加（WRT 为 23.9%）突显了增强检测能力与系统性能之间的权衡，这可能对于资源有限或实时处理要求高的系统来说不可持续。
- en: VI-B Future Directions and Techniques for Exploration
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 未来方向和探索技术
- en: 'To address these limitations, two key techniques can be explored:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为解决这些局限性，可以探索两种关键技术：
- en: '1\. Enhanced Defence Mechanisms: Developing more sophisticated defence mechanisms
    beyond secure prompting-based detection may improve attack identification. Techniques
    such as multi-layer detection frameworks can be utilised, incorporating both prompt-based
    and non-prompt-based strategies [[28](#bib.bib28), [29](#bib.bib29)].'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 增强的防御机制：开发更复杂的防御机制超越基于安全提示的检测可能改善攻击识别。可以利用多层检测框架，结合基于提示和非基于提示的策略[[28](#bib.bib28),
    [29](#bib.bib29)]。
- en: '2\. Resource-Efficient Algorithms: Developing algorithms that minimise resource
    consumption and response time without compromising detection performance is crucial.
    Techniques like model pruning [[30](#bib.bib30)] and efficient neural architectures
    [[31](#bib.bib31)] can help achieve this, ensuring that the defence mechanisms
    remain effective even in resource-constrained environments.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 资源高效算法：开发能够最小化资源消耗和响应时间而不影响检测性能的算法至关重要。像模型剪枝[[30](#bib.bib30)]和高效神经架构[[31](#bib.bib31)]这样的技术可以帮助实现这一点，确保防御机制即使在资源有限的环境中也能保持有效。
- en: By focusing on these areas, we can improve the robustness and efficiency of
    the defence mechanisms, enhancing overall system security and performance.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过关注这些领域，我们可以提高防御机制的稳健性和效率，从而增强整体系统的安全性和性能。
- en: VII Conclusion
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 结论
- en: This study explored the integration of LLMs into robotic systems, highlighting
    both advancements in multi-modal contextual awareness and the accompanying security
    challenges. Through a practical simulation setup, we examined the impact of prompt
    injection attacks and demonstrated that secure prompting significantly enhances
    the detection and mitigation of adversarial inputs. The results, showing an overall
    improvement of 30.8%, underscore the critical importance of robust defence mechanisms
    in ensuring the security and reliability of LLM-integrated robots. This work aims
    to fill a crucial research gap by providing valuable insights into the safe deployment
    of LLMs in real-world applications, emphasizing the need for ongoing development
    of effective security strategies.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究探讨了将大型语言模型（LLMs）整合到机器人系统中的方法，突出了多模态上下文感知的进展以及随之而来的安全挑战。通过实际的模拟设置，我们考察了提示注入攻击的影响，并证明安全提示显著提升了对对抗性输入的检测和缓解能力。结果显示整体改善达到30.8%，强调了在确保LLM集成机器人安全性和可靠性方面，强健防御机制的重要性。本研究旨在填补关键的研究空白，通过提供关于LLM在实际应用中安全部署的宝贵见解，强调了持续开发有效安全策略的必要性。
- en: References
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] OpenAI, “OpenAI Vision Guide,” 2024, accessed: 2024-07-28\. [Online]. Available:
    [https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] OpenAI, “OpenAI 视觉指南”，2024年，访问日期：2024-07-28\. [在线]. 可用链接: [https://platform.openai.com/docs/guides/vision](https://platform.openai.com/docs/guides/vision)'
- en: '[2] Y. Liu, W. Chen, Y. Bai, J. Luo, X. Song, K. Jiang, Z. Li, G. Zhao, J. Lin,
    G. Li *et al.*, “Aligning Cyber Space with Physical World: A Comprehensive Survey
    on Embodied AI,” *arXiv preprint arXiv:2407.06886*, 2024.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Y. Liu, W. Chen, Y. Bai, J. Luo, X. Song, K. Jiang, Z. Li, G. Zhao, J.
    Lin, G. Li *等*，“将网络空间与物理世界对齐：对具身人工智能的全面调查”，*arXiv 预印本 arXiv:2407.06886*，2024年。'
- en: '[3] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Schärli,
    and D. Zhou, “Large Language Models Can Be Easily Distracted by Irrelevant Context,”
    in *International Conference on Machine Learning*.   PMLR, 2023, pp. 31 210–31 227.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Schärli,
    和 D. Zhou, “大型语言模型容易被无关上下文分散注意力”，发表于 *国际机器学习会议*。   PMLR, 2023年，页码 31 210–31 227。'
- en: '[4] C. Wen, J. Liang, S. Yuan, H. Huang, and Y. Fang, “How Secure Are Large
    Language Models (LLMs) for Navigation in Urban Environments?” *arXiv preprint
    arXiv:2402.09546*, 2024.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. Wen, J. Liang, S. Yuan, H. Huang, 和 Y. Fang, “大型语言模型（LLMs）在城市环境中导航的安全性如何？”，*arXiv
    预印本 arXiv:2402.09546*，2024年。'
- en: '[5] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin,
    E. Zhou *et al.*, “The Rise and Potential of Large Language Model Based Agents:
    A Survey (2023),” *URL https://arxiv. org/abs/2309.07864*, 2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S.
    Jin, E. Zhou *等*，“大型语言模型基于代理的崛起与潜力：一项调查（2023）”，*URL https://arxiv. org/abs/2309.07864*，2023年。'
- en: '[6] E. Latif, “3P-LLM: Probabilistic Path Planning using Large Language Model
    for Autonomous Robot Navigation,” *arXiv preprint arXiv:2403.18778*, 2024.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] E. Latif, “3P-LLM: 使用大型语言模型进行自主机器人导航的概率路径规划”，*arXiv 预印本 arXiv:2403.18778*，2024年。'
- en: '[7] G. Zhou, Y. Hong, and Q. Wu, “NavGPT: Explicit Reasoning in Vision-and-Language
    Navigation with Large Language Models,” in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 38, no. 7, 2024, pp. 7641–7649.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] G. Zhou, Y. Hong, 和 Q. Wu, “NavGPT: 大型语言模型下的视觉与语言导航中的显式推理”，发表于 *AAAI 人工智能会议论文集*，第38卷，第7期，2024年，页码
    7641–7649。'
- en: '[8] S. Qiao, R. Fang, N. Zhang, Y. Zhu, X. Chen, S. Deng, Y. Jiang, P. Xie,
    F. Huang, and H. Chen, “Agent Planning with World Knowledge Model,” *arXiv preprint
    arXiv:2405.14205*, 2024.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] S. Qiao, R. Fang, N. Zhang, Y. Zhu, X. Chen, S. Deng, Y. Jiang, P. Xie,
    F. Huang, 和 H. Chen, “具有世界知识模型的代理规划”，*arXiv 预印本 arXiv:2405.14205*，2024年。'
- en: '[9] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, and Y. Su,
    “LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language
    Models,” in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998–3009.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, 和 Y. Su, “LLM-Planner:
    基于大型语言模型的少样本基础规划”，发表于 *IEEE/CVF 国际计算机视觉会议论文集*，2023年，页码 2998–3009。'
- en: '[10] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large Language
    Models are Zero-shot Reasoners,” *Advances in neural information processing systems*,
    vol. 35, pp. 22 199–22 213, 2022.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, 和 Y. Iwasawa, “大型语言模型是零样本推理器”，*神经信息处理系统进展*，第35卷，页码
    22 199–22 213，2022年。'
- en: '[11] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, and Q. Li,
    “A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models,”
    *arXiv preprint arXiv:2405.06211*, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Y. Ding, W. Fan, L. Ning, S. Wang, H. Li, D. Yin, T.-S. Chua, 和 Q. Li,
    “关于 RAG 与 LLM 结合的调查：迈向检索增强型大型语言模型，” *arXiv 预印本 arXiv:2405.06211*，2024 年。'
- en: '[12] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou
    *et al.*, “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models,”
    *Advances in neural information processing systems*, vol. 35, pp. 24 824–24 837,
    2022.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D.
    Zhou *等*，“链式思维提示引发大型语言模型中的推理，” *神经信息处理系统进展*，第 35 卷，第 24,824–24,837 页，2022 年。'
- en: '[13] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, and C. Wang, “Autogen: Enabling Next-Gen LLM Applications via Multi-Agent
    Conversation Framework,” *arXiv preprint arXiv:2308.08155*, 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, 和 C. Wang, “Autogen：通过多代理对话框架实现下一代 LLM 应用，” *arXiv 预印本 arXiv:2308.08155*，2023
    年。'
- en: '[14] J. V. D. Ham, “Toward a Better Understanding of “Cybersecurity”,” *Digital
    Threats: Research and Practice*, vol. 2, no. 3, pp. 1–3, 2021.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] J. V. D. Ham, “迈向更好的‘网络安全’理解，” *数字威胁：研究与实践*，第 2 卷，第 3 期，第 1–3 页，2021 年。'
- en: '[15] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, and Y. Xiang, “AI Agents
    Under Threat: A Survey of Key Security Challenges and Future Pathways,” 2024.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, 和 Y. Xiang, “面临威胁的 AI
    代理：关键安全挑战与未来路径的调查，” 2024 年。'
- en: '[16] F. Perez and I. Ribeiro, “Ignore Previous Prompt: Attack Techniques for
    Language Models,” *arXiv preprint arXiv:2211.09527*, 2022.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] F. Perez 和 I. Ribeiro, “忽略先前的提示：语言模型的攻击技术，” *arXiv 预印本 arXiv:2211.09527*，2022
    年。'
- en: '[17] P. Levi and C. P. Neumann, “Vocabulary Attack to Hijack Large Language
    Model Applications,” *arXiv preprint arXiv:2404.02637*, 2024.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] P. Levi 和 C. P. Neumann, “通过词汇攻击劫持大型语言模型应用程序，” *arXiv 预印本 arXiv:2404.02637*，2024
    年。'
- en: '[18] Y. Zhang, N. Carlini, and D. Ippolito, “Effective Prompt Extraction from
    Language Models,” *arXiv preprint arXiv:2307.06865*, 2024.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Y. Zhang, N. Carlini, 和 D. Ippolito, “从语言模型中有效提取提示，” *arXiv 预印本 arXiv:2307.06865*，2024
    年。'
- en: '[19] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang,
    K. Wang, and Y. Liu, “Jailbreaking ChatGPT via Prompt Engineering: An Empirical
    Study,” *arXiv preprint arXiv:2305.13860*, 2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang,
    K. Wang, 和 Y. Liu, “通过提示工程破解 ChatGPT：一项实证研究，” *arXiv 预印本 arXiv:2305.13860*，2023
    年。'
- en: '[20] K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, and M. Fritz,
    “Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications
    with Indirect Prompt Injection,” in *Proceedings of the 16th ACM Workshop on Artificial
    Intelligence and Security*, 2023, pp. 79–90.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, 和 M. Fritz,
    “不是你所报名的：通过间接提示注入破坏现实世界的 LLM 集成应用程序，” 收录于 *第十六届 ACM 人工智能与安全研讨会论文集*，2023 年，第 79–90
    页。'
- en: '[21] C. Tony, N. E. D. Ferreyra, M. Mutas, S. Dhiff, and R. Scandariato, “Prompting
    Techniques for Secure Code Generation: A Systematic Investigation,” *arXiv preprint
    arXiv:2407.07064*, 2024.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] C. Tony, N. E. D. Ferreyra, M. Mutas, S. Dhiff, 和 R. Scandariato, “用于安全代码生成的提示技术：系统研究，”
    *arXiv 预印本 arXiv:2407.07064*，2024 年。'
- en: '[22] Y. Liu, Y. Jia, R. Geng, J. Jia, and N. Z. Gong, “Formalizing and Benchmarking
    Prompt Injection Attacks and Defenses,” 2024.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Y. Liu, Y. Jia, R. Geng, J. Jia, 和 N. Z. Gong, “形式化和基准测试提示注入攻击和防御，” 2024
    年。'
- en: '[23] N. Jain, A. Schwarzschild, Y. Wen, G. Somepalli, J. Kirchenbauer, P.-y.
    Chiang, M. Goldblum, A. Saha, J. Geiping, and T. Goldstein, “Baseline Defenses
    for Adversarial Attacks Against Aligned Language Models,” *arXiv preprint arXiv:2309.00614*,
    2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] N. Jain, A. Schwarzschild, Y. Wen, G. Somepalli, J. Kirchenbauer, P.-y.
    Chiang, M. Goldblum, A. Saha, J. Geiping, 和 T. Goldstein, “对齐语言模型的对抗攻击的基线防御，”
    *arXiv 预印本 arXiv:2309.00614*，2023 年。'
- en: '[24] G. Alon and M. Kamfonas, “Detecting Language Model Attacks with Perplexity,”
    *arXiv preprint arXiv:2308.14132*, 2023.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] G. Alon 和 M. Kamfonas, “通过困惑度检测语言模型攻击，” *arXiv 预印本 arXiv:2308.14132*，2023
    年。'
- en: '[25] S. Armstrong and R. Gorman, “Using GPT-Eliezer Against ChatGPT Jailbreaking,”
    in *AI ALIGNMENT FORUM*, 2022.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. Armstrong 和 R. Gorman, “使用 GPT-Eliezer 对抗 ChatGPT 破解，” 收录于 *AI ALIGNMENT
    FORUM*，2022 年。'
- en: '[26] P. Bhandari, “A Survey on Prompting Techniques in LLMs,” *arXiv preprint
    arXiv:2312.03740*, 2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] P. Bhandari, “关于大型语言模型中的提示技术的调查，” *arXiv 预印本 arXiv:2312.03740*，2024 年。'
- en: '[27] T. Bräunl, *Mobile Robot Programming: Adventures in Python and C*.   Springer
    International Publishing, 2023.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] T. Bräunl, *移动机器人编程：Python 和 C 的冒险*。施普林格国际出版社，2023 年。'
- en: '[28] P. Rai, S. Sood, V. K. Madisetti, and A. Bahga, “Guardian: A Multi-Tiered
    Defense Architecture for Thwarting Prompt Injection Attacks on LLMs,” *Journal
    of Software Engineering and Applications*, vol. 17, no. 1, pp. 43–68, 2024.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] P. Rai, S. Sood, V. K. Madisetti, 和 A. Bahga, “Guardian: 一种多层防御架构，用于抵御
    LLM 的提示注入攻击，” *软件工程与应用期刊*，第 17 卷，第 1 期，第 43–68 页，2024。'
- en: '[29] R. K. Sharma, V. Gupta, and D. Grossman, “Defending Language Models Against
    Image-Based Prompt Attacks via User-Provided Specifications,” in *2024 IEEE Security
    and Privacy Workshops (SPW)*.   IEEE, 2024, pp. 112–131.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] R. K. Sharma, V. Gupta, 和 D. Grossman, “通过用户提供的规格防御基于图像的提示攻击，” 在 *2024
    IEEE 安全与隐私研讨会 (SPW)*。   IEEE，2024，第 112–131 页。'
- en: '[30] H. Jiang, Y. Li, C. Zhang, Q. Wu, X. Luo, S. Ahn, Z. Han, A. H. Abdi,
    D. Li, C.-Y. Lin, Y. Yang, and L. Qiu, “MInference 1.0: Accelerating Pre-filling
    for Long-Context LLMs via Dynamic Sparse Attention,” *arXiv preprint arXiv:2407.02490*,
    2024.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] H. Jiang, Y. Li, C. Zhang, Q. Wu, X. Luo, S. Ahn, Z. Han, A. H. Abdi,
    D. Li, C.-Y. Lin, Y. Yang, 和 L. Qiu, “MInference 1.0: 通过动态稀疏注意力加速长上下文 LLM 的预填充，”
    *arXiv 预印本 arXiv:2407.02490*，2024。'
- en: '[31] Z. Wang and Z. Ma and X. Feng and R. Sun and H. Wang and M. Xue and G.
    Bai, “Corelocker: Neuron-level usage control,” in *2024 IEEE Symposium on Security
    and Privacy (SP)*.   Los Alamitos, CA, USA: IEEE Computer Society, may 2024, pp.
    222–222\. [Online]. Available: [https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233](https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Z. Wang 和 Z. Ma 和 X. Feng 和 R. Sun 和 H. Wang 和 M. Xue 和 G. Bai, “Corelocker:
    神经元级使用控制，” 在 *2024 IEEE 安全与隐私研讨会 (SP)*。   洛杉矶，CA，美国: IEEE 计算机协会，2024 年 5 月，第 222–222
    页。 [在线]. 可用: [https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233](https://doi.ieeecomputersociety.org/10.1109/SP54263.2024.00233)'
