- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:48:08'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect
    LLM-Generated Text Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2311.08369](https://ar5iv.labs.arxiv.org/html/2311.08369)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Ryuto Koike¹  Masahiro Kaneko^(2,1)  Naoaki Okazaki¹
  prefs: []
  type: TYPE_NORMAL
- en: ¹Tokyo Institute of Technology  ²MBZUAI
  prefs: []
  type: TYPE_NORMAL
- en: ryuto.koike@nlp.c.titech.ac.jp
  prefs: []
  type: TYPE_NORMAL
- en: Masahiro.Kaneko@mbzuai.ac.ae  okazaki@c.titech.ac.jp
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Against the misuse (e.g., plagiarism or spreading misinformation) of Large Language
    Models (LLMs), many recent works have presented LLM-generated-text detectors with
    promising detection performance. Spotlighting a situation where users instruct
    LLMs to generate texts (e.g., essay writing), there are various ways to write
    the instruction (e.g., what task-oriented constraint to include). In this paper,
    we discover that even a task-oriented constraint in instruction can cause the
    inconsistent performance of current detectors to the generated texts. Specifically,
    we focus on student essay writing as a realistic domain and manually create the
    task-oriented constraint for each factor on essay quality by Ke and Ng ([2019](#bib.bib3)).
    Our experiment shows that the detection performance variance of the current detector
    on texts generated by instruction with each task-oriented constraint is up to
    20 times larger than the variance caused by generating texts multiple times and
    paraphrasing the instruction. Our finding calls for further research on developing
    robust detectors that can detect such distributional shifts caused by a task-oriented
    constraint in the instruction.
  prefs: []
  type: TYPE_NORMAL
- en: How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect
    LLM-Generated Text Detection
  prefs: []
  type: TYPE_NORMAL
- en: Ryuto Koike¹  Masahiro Kaneko^(2,1)  Naoaki Okazaki¹ ¹Tokyo Institute of Technology
     ²MBZUAI ryuto.koike@nlp.c.titech.ac.jp Masahiro.Kaneko@mbzuai.ac.ae  okazaki@c.titech.ac.jp
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have shown human-level generative capability in
    response to various instructions OpenAI ([2023](#bib.bib11)); Touvron et al. ([2023](#bib.bib17)).
    On the other hand, with such remarkable generative ability, malicious users can
    employ LLMs for plagiarism or misinformation spreading Tang et al. ([2023](#bib.bib16));
    Wu et al. ([2023](#bib.bib19)). To mitigate the potential misuse of LLMs, many
    recent works have presented LLM-generated-text detectors with promising detection
    performance. Kirchenbauer et al. ([2023](#bib.bib4)); Mitchell et al. ([2023](#bib.bib10));
    Guo et al. ([2023](#bib.bib2)); Koike et al. ([2023](#bib.bib5)); Su et al. ([2023](#bib.bib15)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Previous studies on LLM-generated text detection mainly focus on generated
    texts, such as analyzing these linguistic features (Li et al., [2023](#bib.bib8);
    Guo et al., [2023](#bib.bib2); Liu et al., [2023](#bib.bib9)) and attacking detectors
    by paraphrasing them (Krishna et al., [2023](#bib.bib6); Sadasivan et al., [2023](#bib.bib13)).
    Unlike these studies, we spotlight the situation when these texts are generated
    by LLMs. When users instruct LLMs to compose texts, there are multiple ways to
    create their instructions (e.g., what task-oriented constraint to include). Previous
    works do not consider such instruction variation to create LLM-generated text
    corpora (Li et al., [2023](#bib.bib8); Guo et al., [2023](#bib.bib2); Liu et al.,
    [2023](#bib.bib9)). Here is an unexplored question: Can current detectors consistently
    capture LLM-generated text variations caused by even a task-oriented constraint
    in the instruction?'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/db7e0d7b4c09bc302f13f66addfb9331.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Even a task-oriented constraint in the instruction can cause inconsistent
    detection performance on the LLM-generated texts.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Factor |  | Task-oriented constraint |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Grammatically | (Grm.) | Your essay must be free of grammatical errors. |'
  prefs: []
  type: TYPE_TB
- en: '| Usage | (Usg.) | Your essay must utilize a professional-level vocabulary.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mechanics | (Mec.) | Your essay must be free of spelling and capitalization
    errors. |'
  prefs: []
  type: TYPE_TB
- en: '| Style | (Sty.) | Your essay must include diverse word choices and sentence
    structures. |'
  prefs: []
  type: TYPE_TB
- en: '| Relevance | (Rel.) | Your essay must follow the prompt. |'
  prefs: []
  type: TYPE_TB
- en: '| Organization | (Org.) | Your essay must be logically organized. |'
  prefs: []
  type: TYPE_TB
- en: '| Development | (Dev.) | Your essay must include concrete evidence that supports
    your opinion. |'
  prefs: []
  type: TYPE_TB
- en: '| Cohesion | (Chs.) | Your essay must have a valid connection between paragraphs.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Coherence | (Chr.) | Your essay must have an effective transition throughout
    all paragraphs. |'
  prefs: []
  type: TYPE_TB
- en: '| Thesis Clarity | (TC.) | Your essay must have a clear position through your
    essay. |'
  prefs: []
  type: TYPE_TB
- en: '| Persuasiveness | (Per.) | Your essay must be persuasive to readers. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: A task-oriented constraint on essay writing for each factor of essay
    quality'
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we first demonstrate that even a task-oriented constraint in
    the instruction can lead to inconsistent performance of current detectors to the
    generated texts. Specifically, we focus on student essay writing as a realistic
    domain and utilize essay questions created by Koike et al. ([2023](#bib.bib5))
    to generate essays by LLMs. To aid this study, we manually create the task-oriented
    constraint based on each factor of essay quality, defined by Ke and Ng ([2019](#bib.bib3)).
    As illustrated in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ How You Prompt
    Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text
    Detection"), we just append each task-oriented constraint into the original instruction
    and evaluate the detection performance on texts generated by each instruction.
  prefs: []
  type: TYPE_NORMAL
- en: Our experiment shows that the detection performance variance of the current
    detector on texts generated by instruction with each task-oriented constraint
    is up to 20 times larger than the variance caused by generating texts multiple
    times and paraphrasing the instruction. This result implies that even a task-oriented
    constraint in instruction has a more significant effect on the detection performance
    of current detectors than the effect of generating texts multiple times and paraphrasing
    the instruction. In terms of the vulnerability of the existing detectors, our
    finding necessitates developing robust detection techniques against such distributional
    shifts by a task-oriented constraint in the instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Task Formulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our main task is LLM-generated text detection, specifically discerning LLM-generated
    essays from human-written essays. We employ essay problem statements in the essay
    dataset, created by Koike et al. ([2023](#bib.bib5)), as a subject of essay writing.
    In this paper, we investigate the consistency of existing detectors to various
    LLM-generated texts due to a task-oriented constraint in the instruction. To facilitate
    this study, we manually create the task-oriented constraint on essay writing for
    each factor of essay quality, defined by Ke and Ng ([2019](#bib.bib3)). Table
    [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ How You Prompt Matters! Even Task-Oriented
    Constraints in Instructions Affect LLM-Generated Text Detection") lists the factors
    and their task-oriented constraints. Then, we compute detection performances and
    their variance of current detectors on texts generated by an instruction with
    each task-oriented constraint. Finally, to validate the impact of such task-oriented
    constraints on LLM-generated text detection, we compare its detection performance
    variance with two performance variances: on multiple randomly generated texts
    by the original instruction, and texts generated by multiple paraphrased original
    instructions.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Background of LLM-generated Text Detection Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we briefly outline current LLM-generated text detection algorithms.
    The detection algorithms are mainly divided into three groups: watermarking, statistical
    outlier approach, and supervised classifier. The watermarking embeds token-level
    markers into output texts that are hard to recognize by humans and utilizes the
    ratio of the markers in a text for detection Kirchenbauer et al. ([2023](#bib.bib4)).
    Our work only focuses on non-watermarked LLMs that are mainly for our daily use.
    The statistical outlier approaches capture a probability deviation of a text from
    the predicted distribution of LLMs. These include token log probabilities Solaiman
    et al. ([2019](#bib.bib14)), entropy Lavergne et al. ([2008](#bib.bib7)), perplexity
    Beresneva ([2016](#bib.bib1)), and negative curvature of perturbed text probabilities
    Mitchell et al. ([2023](#bib.bib10)). The supervised classifiers are basically
    neural-based models trained to distinguish human-written and LLM-generated texts
    with labeled datasets Uchendu et al. ([2020](#bib.bib18)); Rodriguez et al. ([2022](#bib.bib12));
    Guo et al. ([2023](#bib.bib2)). In addition to the above three groups, there has
    recently been a new direction: leveraging in-context learning for LLM-generated
    text detection Koike et al. ([2023](#bib.bib5)). They utilize in-context learning
    of LLMs with retrieved few-shot human-written and LLM-generated examples, showing
    promising detection performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Generator | Detector | Type | Variation of F1 ↑ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT | RoBERTa | Multi. | 4.20e-4 |'
  prefs: []
  type: TYPE_TB
- en: '| Para. | 1.70e-3 |'
  prefs: []
  type: TYPE_TB
- en: '| Const. | 8.59e-3 |'
  prefs: []
  type: TYPE_TB
- en: '| OUTFOX | Multi. | 2.11e-5 |'
  prefs: []
  type: TYPE_TB
- en: '| Para. | 3.11e-5 |'
  prefs: []
  type: TYPE_TB
- en: '| Const. | 1.20e-4 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Detection performances on essays generated multiple times by the original
    instruction (denoted as Multi.) and generated by multiple paraphrased original
    instruction (denoted as Para.), and generated by an instruction with each task-oriented
    constraint (denoted as Const.). Multi. and Para. have 12 trials each.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/453e5a9f5121241171647b2fa1592b64.png)![Refer to caption](img/89ab63862ee7ce60566b9152184f7232.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Distribution of F1-score by RoBERTa-large and OUTFOX on essays generated
    multiple times by the original instruction (denoted as Multi.) and generated by
    multiple paraphrased original instruction (denoted as Para.), and generated by
    an instruction with each task-oriented constraint (denoted as Const.).'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Experiments and Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our experiment explores the answer to the following question: Can current detectors
    consistently capture LLM-generated text variations caused by a task-oriented constraint
    in the instruction?'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Overall Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Essay Generation Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We employ ChatGPT (gpt-3.5-turbo-0613), which are the commonly used LLMs, as
    our essay generation model. We configure the $\mathsf{temperature}$ parameter
    of the models to 1.3.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metric and Dataset
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our evaluation metric is the F1-score, which is a common evaluation metric in
    binary classification tasks. To compute a detection threshold in a statistical
    outlier approach or supervised classifier, we use the Youden Index Youden ([1950](#bib.bib20))
    following the setting of Koike et al. ([2023](#bib.bib5)). As a dataset, we employ
    pairs of essay problem statements and human-written essays from the essay dataset
    created by Koike et al. ([2023](#bib.bib5)). In our experiment, we assume a setting
    of generating essays from the essay problem statements.
  prefs: []
  type: TYPE_NORMAL
- en: LLM-generated Text Detectors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To verify the consistency of existing representative detectors, we target OpenAI’s
    RoBERTa-based GPT-2 Classifier (Large) ¹¹1[https://github.com/openai/gpt-2-output-dataset/tree/master/detector](https://github.com/openai/gpt-2-output-dataset/tree/master/detector)
    as a supervised classifier, and in-context learning approach of Koike et al. ([2023](#bib.bib5)),
    OUTFOX ²²2[https://github.com/ryuryukke/OUTFOX](https://github.com/ryuryukke/OUTFOX).
    Following the setting of Koike et al. ([2023](#bib.bib5)), in the in-context learning
    approach, we retrieve 5 ChatGPT-generated and 5 human-written essays as in-context
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: Original Instruction and Task-oriented Constraints
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As listed in Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ How You Prompt Matters!
    Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection"),
    we manually create a task-oriented constraint for each factor of essay quality
    defined by Ke and Ng ([2019](#bib.bib3)). We simply append the task-oriented constraint
    to the original instruction. We provide the details of the original instruction
    and how to add the task-oriented constraint to it in Appendix [A](#A1 "Appendix
    A Details of the Original Instruction and How To Add Constraints ‣ How You Prompt
    Matters! Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text
    Detection").
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [2](#S3.T2 "Table 2 ‣ 3 Background of LLM-generated Text Detection Algorithms
    ‣ How You Prompt Matters! Even Task-Oriented Constraints in Instructions Affect
    LLM-Generated Text Detection") presents the comparison of detection performance
    variances on multiple randomly generated texts by the original instruction and
    texts generated by multiple paraphrased original instructions, and texts generated
    by an instruction with each task-oriented constraint. The detectors include RoBERTa-large
    and the in-context learning method, OUTFOX. Throughout all settings, the detection
    performance variance on texts by instruction with each task-oriented constraint
    is significantly larger than the other two variances: up to about 20 times larger
    in performance of RoBERT-large. Also, as illustrated in Figure [2](#S3.F2 "Figure
    2 ‣ 3 Background of LLM-generated Text Detection Algorithms ‣ How You Prompt Matters!
    Even Task-Oriented Constraints in Instructions Affect LLM-Generated Text Detection"),
    we can see the longer distribution of the F1-score on texts generated by instruction
    with a task-oriented constraint (Const.) than the others by generating texts multiple
    times (Multi.) and paraphrasing the instruction (Para.). These results imply that
    even a task-oriented constraint in instruction has a more significant effect on
    the detection performance of current detectors than the effect of generating texts
    multiple times and paraphrasing the instruction.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This study investigates how much impact even a task-oriented constraint in instruction
    can have on the current detector’s performance to the generated texts. Our experiment
    in the domain of student essay writing reveals that even a task-oriented constraint
    in instruction has a more significant effect on the detection performance of current
    detectors than the effect of generating texts multiple times and paraphrasing
    the instruction. Our finding calls for further research on developing robust LLM-generated
    text detectors against such distribution shifts caused by a task-oriented constraint
    in instruction. Furthermore, our finding suggests both-sided facts that malicious
    users can cheat on current detectors by simply adding an instruction to their
    prompts, and defenders can also create prompts that generate texts that are less
    likely to be detected (e.g., creating homework assignments in school).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Beresneva (2016) Daria Beresneva. 2016. [Computer-generated text detection
    using machine learning: A systematic review.](https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf)
    In *21st International Conference on Applications of Natural Language to Information
    Systems, NLDB*, pages 421–426\. Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2023) Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie,
    Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023. [How close is chatgpt to human
    experts? comparison corpus, evaluation, and detection](http://arxiv.org/abs/2301.07597).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ke and Ng (2019) Zixuan Ke and Vincent Ng. 2019. [Automated Essay Scoring:
    A Survey of the State of the Art](https://doi.org/10.24963/ijcai.2019/879). In
    *Proceedings of the Twenty-Eighth International Joint Conference on Artificial
    Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019*, pages 6300–6308\.
    ijcai.org.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kirchenbauer et al. (2023) John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan
    Katz, Ian Miers, and Tom Goldstein. 2023. [A Watermark for Large Language Models](http://arxiv.org/abs/2301.10226).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Koike et al. (2023) Ryuto Koike, Masahiro Kaneko, and Naoaki Okazaki. 2023.
    [OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially
    Generated Examples](http://arxiv.org/abs/2307.11729).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krishna et al. (2023) Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John
    Wieting, and Mohit Iyyer. 2023. [Paraphrasing evades detectors of ai-generated
    text, but retrieval is an effective defense](http://arxiv.org/abs/2303.13408).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lavergne et al. (2008) Thomas Lavergne, Tanguy Urvoy, and François Yvon. 2008.
    [Detecting Fake Content with Relative Entropy Scoring](https://ceur-ws.org/Vol-377/paper4.pdf).
    In *Proceedings of the ECAI’08 Workshop on Uncovering Plagiarism, Authorship and
    Social Software Misuse*, CEUR Workshop Proceedings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2023) Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue Wang, Linyi
    Yang, Shuming Shi, and Yue Zhang. 2023. [Deepfake text detection in the wild](http://arxiv.org/abs/2305.13242).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2023) Yikang Liu, Ziyin Zhang, Wanyang Zhang, Shisen Yue, Xiaojing
    Zhao, Xinyuan Cheng, Yiwen Zhang, and Hai Hu. 2023. [Argugpt: evaluating, understanding
    and identifying argumentative essays generated by gpt models](http://arxiv.org/abs/2304.07666).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mitchell et al. (2023) Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D.
    Manning, and Chelsea Finn. 2023. [DetectGPT: Zero-Shot Machine-Generated Text
    Detection using Probability Curvature](http://arxiv.org/abs/2301.11305).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2023) OpenAI. 2023. [Introducing ChatGPT](https://openai.com/blog/chatgpt).
    Accessed on 2023-05-10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rodriguez et al. (2022) Juan Diego Rodriguez, Todd Hay, David Gros, Zain Shamsi,
    and Ravi Srinivasan. 2022. [Cross-domain detection of GPT-2-generated technical
    text](https://doi.org/10.18653/v1/2022.naacl-main.88). In *Proceedings of the
    2022 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies*, pages 1213–1233, Seattle, United States.
    Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sadasivan et al. (2023) Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian,
    Wenxiao Wang, and Soheil Feizi. 2023. [Can ai-generated text be reliably detected?](http://arxiv.org/abs/2303.11156)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solaiman et al. (2019) Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell,
    Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah
    Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, and Jasmine
    Wang. 2019. [Release Strategies and the Social Impacts of Language Models](http://arxiv.org/abs/1908.09203).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Su et al. (2023) Jinyan Su, Terry Yue Zhuo, Di Wang, and Preslav Nakov. 2023.
    [Detectllm: Leveraging log rank information for zero-shot detection of machine-generated
    text](http://arxiv.org/abs/2306.05540).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2023) Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023. [The science
    of detecting llm-generated texts](http://arxiv.org/abs/2303.07205).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uchendu et al. (2020) Adaku Uchendu, Thai Le, Kai Shu, and Dongwon Lee. 2020.
    [Authorship attribution for neural text generation](https://doi.org/10.18653/v1/2020.emnlp-main.673).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 8384–8395, Online. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023) Junchao Wu, Shu Yang, Runzhe Zhan, Yulin Yuan, Derek F. Wong,
    and Lidia S. Chao. 2023. [A survey on llm-generated text detection: Necessity,
    methods, and future directions](http://arxiv.org/abs/2310.14724).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Youden (1950) William J. Youden. 1950. An index for rating diagnostic tests.
    *Cancer*, pages 32–35.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Details of the Original Instruction and How To Add Constraints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our experiment, the original instruction to generate essays is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Given the following problem statement, please write an essay in [n] words.
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[problem_statement]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Essay:'
  prefs: []
  type: TYPE_NORMAL
- en: Here, [n] is the number of words in a human-written essay paired with an essay
    problem statement. [problem_statement] denotes the essay problem statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'We simply add a task-oriented constraint into the original instruction as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Given the following problem statement, please write an essay in [n] words.
  prefs: []
  type: TYPE_NORMAL
- en: '[constraint]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[problem_statement]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Essay:'
  prefs: []
  type: TYPE_NORMAL
- en: Here, [n] and [problem_statement] are the same as the above. [constraint] indicates
    the task-oriented constraint we create.
  prefs: []
  type: TYPE_NORMAL
