- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-08 18:41:20'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.18786](https://ar5iv.labs.arxiv.org/html/2407.18786)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \useunder
  prefs: []
  type: TYPE_NORMAL
- en: \acsetupfirst-style=short
  prefs: []
  type: TYPE_NORMAL
- en: Aleix Sant,  Carlos Escolano,  Audrey Mash,
  prefs: []
  type: TYPE_NORMAL
- en: Francesca De Luca Fornaciari,  Maite Melero
  prefs: []
  type: TYPE_NORMAL
- en: Barcelona Supercomputing Center (BSC)
  prefs: []
  type: TYPE_NORMAL
- en: '{aleix.santsavall,carlos.escolano,audrey.mash'
  prefs: []
  type: TYPE_NORMAL
- en: francesca.delucafornaciari,maite.melero}@bsc.es
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This paper studies gender bias in machine translation through the lens of Large
    Language Models (LLMs). Four widely-used test sets are employed to benchmark various
    base LLMs, comparing their translation quality and gender bias against state-of-the-art
    Neural Machine Translation (NMT) models for English to Catalan (En → Ca) and English
    to Spanish (En → Es) translation directions. Our findings reveal pervasive gender
    bias across all models, with base LLMs exhibiting a higher degree of bias compared
    to NMT models.
  prefs: []
  type: TYPE_NORMAL
- en: To combat this bias, we explore prompting engineering techniques applied to
    an instruction-tuned LLM. We identify a prompt structure that significantly reduces
    gender bias by up to 12% on the WinoMT evaluation dataset compared to more straightforward
    prompts. These results significantly reduce the gender bias accuracy gap between
    LLMs and traditional NMT systems.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within the domain of machine translation, gender bias is defined as the tendency
    of MT systems to produce translations that reflect or perpetuate gender stereotypes,
    inequalities, or assumptions based on cultural and societal biases Friedman and
    Nissenbaum ([1996](#bib.bib17)); Savoldi et al. ([2021](#bib.bib50)). Given that
    the presence of such bias can lead to harmful consequences for certain groups
    — either in representational (i.e., misrepresentation or underrepresentation of
    social groups and their identities) or allocational harms (i.e., allocation or
    withholding of opportunities or resources to certain groups) — Levesque ([2011](#bib.bib31));
    Crawford ([2017](#bib.bib13)); Lal Zimman and Meyerhoff ([2017](#bib.bib29));
    Régner et al. ([2019](#bib.bib46)), it becomes paramount to thoroughly investigate
    and mitigate its occurrence. Nevertheless, addressing gender bias is a multi-faceted
    task.
  prefs: []
  type: TYPE_NORMAL
- en: Gender bias is a pervasive issue in all generative NLP models, and LLMs are
    no exception to this situation. LLMs have gained significant popularity in recent
    years and are being used for many NLP tasks, including machine translation. While
    gender bias in machine translation has been extensively studied for Neural Machine
    Translation models, little attention has been paid to this type of bias in LLMs.
    This paper aims to address this gap by examining and trying to mitigate this bias
    in the translations generated by the LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: The aim of this work is twofold. First, a comprehensive benchmarking process
    is conducted to compare various base LLMs with some state-of-the-art NMT models.
    The directions of the translations under study are English $\rightarrow$ Spanish.
    Distinct popular test sets such as FLoRes-200 Costa-jussà et al. ([2022](#bib.bib11)),
    WinoMT Stanovsky et al. ([2019](#bib.bib53)), Gold BUG Levy et al. ([2021](#bib.bib32)),
    and MuST-SHE Bentivogli et al. ([2020](#bib.bib4)) are used to assess the translation
    quality and the gender bias of the models.
  prefs: []
  type: TYPE_NORMAL
- en: Following the benchmarking, an investigation into the effectiveness of prompts
    in mitigating this bias in LLMs is conducted. The purpose of this research is
    to determine whether well-designed prompts can serve as a useful strategy in addressing
    bias. While existing literature has explored various approaches to mitigating
    this bias in Neural Machine Translation models Costa-jussà et al. ([2020](#bib.bib12));
    Stafanovičs et al. ([2020](#bib.bib52)); Saunders and Byrne ([2020](#bib.bib49)),
    we specifically focus on the realm of LLMs, probing the role of prompts. In this
    phase of the study, an instruction-tuned LLM is employed, and several prompt engineering
    techniques are experimented with, including few-shot Radford et al. ([2019](#bib.bib44));
    Zhao et al. ([2021](#bib.bib72)); Chowdhery et al. ([2023](#bib.bib9)), context-supplying,
    and chain of thought Wei et al. ([2022](#bib.bib61)).
  prefs: []
  type: TYPE_NORMAL
- en: The relevance of this work lies in several insightful findings. Firstly, we
    demonstrate that base LLMs tend to lag behind NMT models in terms of translation
    capabilities and gender-bias scores. Afterwards, through an extensive trial-and-error
    examination into prompting, we present a prompt that, when applied to an instructed
    LLM, achieves impressive bias mitigation across gender-bias test sets, resulting
    in an increase of 12.4 and 11.7 in the respective Catalan and Spanish WinoMT scores.
    Finally, we study how gender-bias mitigation through prompting impacts LLMs translation
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the paper is organized as follows: Section [3](#S3 "3 Related work
    ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs")
    reviews relevant research in the field. Section [4](#S4 "4 Methodology ‣ The power
    of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs") details the
    methodology, including the datasets, models, and evaluation metrics employed.
    Section [5](#S5 "5 Benchmarking ‣ The power of Prompts: Evaluating and Mitigating
    Gender Bias in MT with LLMs") focuses on the benchmarking, while Section [6](#S6
    "6 Gender Bias mitigation through prompting ‣ The power of Prompts: Evaluating
    and Mitigating Gender Bias in MT with LLMs") explores the investigation into prompting
    to mitigate gender bias. Section [7](#S7 "7 Results ‣ The power of Prompts: Evaluating
    and Mitigating Gender Bias in MT with LLMs") presents the results. Finally, Section
    [8](#S8 "8 Discussion ‣ The power of Prompts: Evaluating and Mitigating Gender
    Bias in MT with LLMs") provides a discussion and Section [9](#S9 "9 Conclusions
    ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs")
    highlights the conclusions of this work.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Gender Bias Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As previously stated, gender bias may lead to inequalities and harmful consequences.
    In the context of machine translation, we easily come up with two different motivations
    to consider this issue seriously. First, the presence of gender bias may affect
    the representation of genders in certain communities. On the other hand, the majority
    of users of a machine translation system may not be proficient in at least one
    of the languages involved in the translation. Producing incorrect gender translations
    provides inaccurate information, misleading users who are trying to understand
    the original text from a translation, or causing them to convey a different meaning
    when relying on MT engines to communicate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The presence and extent of gender bias in machine translation can vary depending
    on the languages involved, as gender is manifested differently across languages
    Dagmar Stahlberg and Sczesny. ([2007](#bib.bib14)). When translating from a language
    with fewer gender cues to a language with more explicit gender markings, the issue
    of gender bias can arise. This is precisely the case in our study: we translate
    from a language with notional gender (English) to languages with grammatical gender
    (Catalan and Spanish). In this context, certain professions may be stereotypically
    associated with certain genders. Examples of this phenomenon are engineers, who
    are often translated as masculine, while nurses are translated as feminine Parmy
    Olson ([2018](#bib.bib42)). Additionally, adjectives may be gendered as masculine
    or feminine based on these stereotypes, rather than relying on gender cues. Gender
    pronouns may also be overlooked in favor of or against certain genders. Let’s
    consider a typical example (Figure [1](#S2.F1 "Figure 1 ‣ 2 Gender Bias Statement
    ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ae55006551d1d8e9515bdc32c2afdeba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Example of Gender Bias in MT'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our study, we analyze gender bias in two distinct ways, which we will refer
    to as gender-bias tasks: Gender Coreference Resolution and Gender Terms Detection.
    In both tasks, models must utilize contextual gender information (i.e., gender
    cues) to accurately translate, providing the correct gender terms in the translation.'
  prefs: []
  type: TYPE_NORMAL
- en: Gender Coreference Resolution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this task, we assess whether an MT engine correctly predicts the gender of
    a human entity in the translation based on its corresponding coreference pronoun
    in the source sentence. We address this task using POS tagging, focusing solely
    on the gender of specific human entities in the translation.
  prefs: []
  type: TYPE_NORMAL
- en: Gender Terms Detection
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this other task, we evaluate whether an MT engine generates translations
    that include all the correct gender terms based on the gender cues of the source
    sentence. These clues for disambiguating gender terms include coreference pronouns,
    proper nouns, and semantic meaning, among others. Detection of the correct gender
    terms (or their incorrect counterparts) relies on textual comparison of reference
    terms.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5bd043f0bfc34ee7784126864b915d44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Examples of Gender Coreference Resolution (a) and Gender Terms Detection
    (b) in En $\rightarrow$ Ca'
  prefs: []
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Both gender-bias problems are approached as classification problems since they
    involve determining the correct gender labels, allowing for the derivation of
    typical ML scores. Devoid of gender context, we only pay attention to the proportion
    of male and female terms generated in the translations. As evaluation benchmarks,
    WinoMT and Gold BUG focus on Gender Coreference Resolution, whereas MuST-SHE in
    Gender Terms Detection. Check Figure [2](#S2.F2 "Figure 2 ‣ Gender Terms Detection
    ‣ 2 Gender Bias Statement ‣ The power of Prompts: Evaluating and Mitigating Gender
    Bias in MT with LLMs") for an illustration of the gender-bias tasks just explained.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Related work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large Language Models are advanced AI models designed to understand and generate
    language Yang et al. ([2023](#bib.bib64)); Zhao et al. ([2023](#bib.bib71)). These
    models typically employ a decoder-only architecture and are characterized by their
    enormous size, often containing billions of parameters Brown et al. ([2020](#bib.bib5));
    Thoppilan et al. ([2022](#bib.bib56)); OpenAI ([2023](#bib.bib40)). The scale
    and capacity of LLMs enable them to capture intricate linguistic nuances and handle
    a wide range of language-related tasks, despite not being explicitly trained for
    each specific task Sun et al. ([2023](#bib.bib55)); Wei et al. ([2023](#bib.bib62));
    Li et al. ([2023](#bib.bib33)); Gao et al. ([2023a](#bib.bib18)); Yao et al. ([2023](#bib.bib66));
    Yang et al. ([2022](#bib.bib65)); Gao et al. ([2023b](#bib.bib19)); Ning et al.
    ([2023](#bib.bib39)). The training process for LLMs typically consists of two
    steps. First, they undergo self-supervised pretraining using vast amounts of text
    data, which allows them to develop a general understanding of language (i.e.,
    base LLMs). Subsequently, they are fine-tuned on specific supervised tasks to
    specialize in various applications Chung et al. ([2022](#bib.bib10)); Sanh et al.
    ([2022](#bib.bib48)). One of the key features of LLMs is the prompting mechanism.
    A prompt serves as the input or activation signal provided to the model. Through
    this input, we specify to the model the NLP task we want it to perform, such as
    translation in our case.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging the ability to guide the model with prompts, instruction-tuned
    LLMs are created Zhang et al. ([2023b](#bib.bib68)). These are base LLMs that
    have undergone additional fine-tuning using datasets of instructions, containing
    explicit instructions or prompts to enhance their performance on various tasks.
    Instruction-tuning is a subsequent step that tailors the model’s behavior and
    output according to specific instructions or guidelines Mishra et al. ([2022](#bib.bib37));
    Muennighoff et al. ([2023](#bib.bib38)); Longpre et al. ([2023](#bib.bib34)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving away from LLMs, we find Neural Machine Translation models Cho et al.
    ([2014](#bib.bib8)); Bahdanau et al. ([2015](#bib.bib2)); Luong et al. ([2015](#bib.bib35));
    Johnson et al. ([2017](#bib.bib28)); Wu et al. ([2016](#bib.bib63)); Fan et al.
    ([2020](#bib.bib16)); Costa-jussà et al. ([2022](#bib.bib11)). These models represent
    the state-of-the-art in machine translation, consistently achieving the highest
    translation performance. They typically leverage an encoder-decoder transformer
    Vaswani et al. ([2017](#bib.bib59)) trained with parallel data in a supervised
    manner, intended solely for the task of translation. Unlike LLMs, NMT models are
    relatively smaller in size and present unique challenges when it comes to scaling
    (e.g., bidirectional processing, the attention mechanism complexity…). However,
    besides their size, the main distinction between LLMs and NMT models lies in the
    prompting method. LLMs necessitate a prompt to operate, making them entirely dependent
    on context. This is precisely the aspect we aim to explore: whether we can use
    the prompting mechanism, absent in NMT models, to alleviate gender bias.'
  prefs: []
  type: TYPE_NORMAL
- en: To date, significant research has been conducted on the translation capabilities
    of LLMs, as extensively documented in the literature Chowdhery et al. ([2023](#bib.bib9));
    Jiao et al. ([2023a](#bib.bib26)); Zhu et al. ([2023](#bib.bib73)); Agrawal et al.
    ([2023](#bib.bib1)); Jiao et al. ([2023b](#bib.bib27)); Zhang et al. ([2023a](#bib.bib67));
    Bawden and Yvon ([2023](#bib.bib3)); Hendy et al. ([2023](#bib.bib25)). Furthermore,
    several efforts have been made to identify and address bias in LLMs Ernst et al.
    ([2023](#bib.bib15)); Su et al. ([2023](#bib.bib54)); Cai et al. ([2024](#bib.bib6)).
    However, the exploration of gender bias in the realm of MT and LLMs remains relatively
    scarce. This encompasses Sánchez et al. ([2023](#bib.bib47)), which sought to
    leverage LLMs for gender-specific translations, and Vanmassenhove ([2024](#bib.bib58)),
    which experimented with En $\rightarrow$ It.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Llama-2-7B
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A base model that belongs to a family of state-of-the-art LLMs openly released
    by Meta Touvron et al. ([2023](#bib.bib57)). This family of models outperforms
    open-source models on popular benchmarks and has demonstrated high efficacy and
    safety based on human evaluations. Llama-2-7B was trained on a combination of
    publicly available data, primarily in English. Catalan and Spanish (among other
    languages) were also included to a lesser extent. However, any use of the model
    in languages other than English is explicitly declared out of scope by the developers.
  prefs: []
  type: TYPE_NORMAL
- en: Ǎguila-7B
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: An open-source base LLM from Barcelona Supercomputing Center (BSC) that was
    trained on a combination of Spanish, Catalan, and English data, resulting in a
    total of 26 billion tokens. The model was built upon the Falcon-7B model, which
    is a highly advanced English language model.
  prefs: []
  type: TYPE_NORMAL
- en: Flor-6.3B
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Another publicly available base LLM tailored for Catalan, Spanish, and English,
    published by the BSC. This model is derived from the language adaptation process
    applied to Bloom-7.1B, involving adjustments to the vocabulary and embedding layer.
    Additionally, the model underwent continuous pre-training with 140 billion tokens
    specific to Catalan and Spanish.
  prefs: []
  type: TYPE_NORMAL
- en: M2M-100-1.2B
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A multilingual NMT model released by Meta in October 2020 Fan et al. ([2020](#bib.bib16))
    that can directly translate between the 9,900 directions of 100 languages, including
    our languages of interest (i.e., English, Catalan, and Spanish). It was considered
    the first AI model that could translate between 100 languages without relying
    on English.
  prefs: []
  type: TYPE_NORMAL
- en: NLLB-200-1.3B
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The following multilingual NMT model released by Meta in July 2022 Costa-jussà
    et al. ([2022](#bib.bib11)) enabling translation across 200 languages, including
    less commonly spoken languages. It also incorporates the languages we are concentrating
    on, namely English, Catalan, and Spanish.
  prefs: []
  type: TYPE_NORMAL
- en: Mt-aina-en-ca
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The only parallel NMT model assessed in this work, functioning exclusively for
    English $\rightarrow$ Catalan translation. Developed at BSC, it was trained from
    scratch employing a combination of English-Catalan datasets consisting of approximately
    11 million sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Google Translate
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It is widely acknowledged in the literature as one of the leading translation
    models of today. This multilingual NMT model encompasses 133 languages, with English,
    Catalan and Spanish among them.
  prefs: []
  type: TYPE_NORMAL
- en: Llama-2-7B-chat
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It is the refined iteration of Llama-2-7B, optimized specifically for dialogue
    applications. This version underwent supervised instruction-tuning as well as
    Reinforcement Learning from Human Feedback (RLHF). Opting for this instructed
    version for the investigation into prompting is preferable over the base model,
    as it is more robust to prompt variations and better comprehends complex prompts
    and nuances. Selecting the base model along with its instructed version allows
    us to make insightful comparisons between these models.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Test sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All test sets comprise English sentences (or paragraphs) aimed to be translated
    into either Catalan or Spanish. After obtaining translations in their respective
    grammatical languages, the evaluation frameworks are applied to derive the metrics
    (either MT or gender scores).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Machine Translation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: FLoRes-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'It is a massively multilingual general domain dataset. Initially presented
    by Guzmán et al. ([2019](#bib.bib24)); Goyal et al. ([2021](#bib.bib22)), it has
    been further developed and expanded by the Goyal et al. ([2022](#bib.bib23)).
    The most recent version of this dataset encompasses 200 languages Costa-jussà
    et al. ([2022](#bib.bib11)). This dataset¹¹1[https://github.com/facebookresearch/flores/tree/main/flores200](https://github.com/facebookresearch/flores/tree/main/flores200)
    includes two subsets: FLoRes-200 dev (997) and FLoRes-200 devtest (1,012).'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Gender Bias
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: WinoMT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Developed by Stanovsky et al. ([2019](#bib.bib53)), this test set is intended
    to evaluate the presence of gender bias in translations from English to various
    gender-inflected languages. The corpus²²2[https://github.com/gabrielStanovsky/mt_gender](https://github.com/gabrielStanovsky/mt_gender)
    consists of 3,888 sentences in the schema of Winograd. Each sentence in the corpus
    presents two human entities defined by their roles, along with a subsequent pronoun
    that must be correctly resolved to one of the entities Levesque et al. ([2012](#bib.bib30)).
    One of the main limitations of this dataset is its synthetic nature, as it is
    built on templates.
  prefs: []
  type: TYPE_NORMAL
- en: Gold BUG
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The previous limitation of WinoMT could be addressed through the introduction
    of BUG³³3[https://github.com/SLAB-NLP/BUG](https://github.com/SLAB-NLP/BUG) Levy
    et al. ([2021](#bib.bib32)), the first publicly accessible large-scale corpus
    designed for gender-bias evaluation, comprising 108,000 real-world English sentences.
    BUG was built by crawling text according to specific syntactic patterns, offering
    a more diverse and realistic dataset than WinoMT. The Gold BUG version used in
    our evaluation consists of a gold-quality, human-validated set extracted from
    BUG, totaling 1,717 instances.
  prefs: []
  type: TYPE_NORMAL
- en: MuST-SHE
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This test set, initially introduced by Bentivogli et al. ([2020](#bib.bib4))
    for English-French, English-Italian, and English-Spanish, serves as a valuable
    benchmark for evaluating gender bias in the context of speech translation. This
    dataset⁴⁴4[https://mt.fbk.eu/must-she/](https://mt.fbk.eu/must-she/) is constructed
    using TED talks data, as described by Cattoni et al. ([2021](#bib.bib7)), lending
    it a more natural and realistic tone. Recently, Mash et al. ([2024](#bib.bib36))
    created an English-Catalan⁵⁵5[https://huggingface.co/datasets/projecte-aina/MuST-SHE_en-ca](https://huggingface.co/datasets/projecte-aina/MuST-SHE_en-ca)
    version of the dataset tailored for the machine translation domain, resulting
    in 1,046 sentences. For our analysis, we adapted the original English-Spanish
    version for machine translation following the same steps as in the Catalan version,
    resulting in 1,164 instances. Both datasets, English-Spanish and English-Catalan,
    contain two types of instances: those with and without cues to disambiguate the
    gender of certain terms. In instances where gender cues are present, the task
    to be addressed is Gender Terms Detection; otherwise, we are solely interested
    in the proportion of male and female terms generated in the translations.'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, both WinoMT and Gold BUG contain pro- and anti-stereotypical sets
    based on US labor statistics Zhao et al. ([2018](#bib.bib70)). A pro-stereotypical
    set comprises sentences with stereotypical gender-role assignments (e.g., male
    doctors, female housekeepers), while an anti-stereotypical set includes sentences
    with non-stereotypical gender-role assignments (e.g., female doctors, male housekeepers).
    These sets facilitate the investigation of whether the translation performance
    of models correlates with gender stereotypes. Specifically, they help determine
    whether models exhibit better or worse gender scores when translating sentences
    that align (or do not align) with their pre-established biases.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 4.3.1 Machine Translation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To measure the MT capabilities of the models, we employ two widely-used metrics:
    BLEU Papineni et al. ([2002](#bib.bib41)), which is based on comparing n-grams
    and is computed using the SacreBLEU library⁶⁶6Version 1.5.1 Post ([2018](#bib.bib43)),
    and COMET Rei et al. ([2020](#bib.bib45)), a more recent metric that relies on
    sentence embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.2 Gender Bias
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When the source sentence contains gender cues to disambiguate the gender of
    certain terms, meaning we have a known gender reference or ground truth, the translation
    problem is treated as a typical classification task. Consequently, in the context
    of gender bias, we evaluate models using Gender Accuracy (in %), F1-male, and
    F1-female scores. For WinoMT and Gold BUG these scores are computed directly⁷⁷7[https://github.com/gabrielStanovsky/mt_gender/blob/master/scripts/evaluate_all_languages.sh](https://github.com/gabrielStanovsky/mt_gender/blob/master/scripts/evaluate_all_languages.sh),
    whereas for MuST-SHE we obtain first the confusion matrix⁸⁸8[https://github.com/audreyvm/tfm_gender_bias/blob/main/mustshe_acc_v1.2.py](https://github.com/audreyvm/tfm_gender_bias/blob/main/mustshe_acc_v1.2.py)
    and then we compute the scores using scikit-learn library. Additionally, we get
    standard metrics such as $\Delta$S, which requires both a pro- and anti-stereotypical
    sets to assess whether a model relies on gender-stereotypes to generate translations.
    Conversely, when no gender cues are available in the source sentence, we simply
    analyze the proportion of predicted male and female terms in the translations.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Benchmarking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1 Prompting LLMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our benchmarking, we employ a 5-shot approach for our LLMs. This ensures
    that the LLMs better comprehend the requested task (i.e., machine translation)
    and potentially produce higher-quality translations, as demonstrated in existing
    literature Vilar et al. ([2023](#bib.bib60)); Garcia et al. ([2023](#bib.bib20));
    Zhang et al. ([2023c](#bib.bib69)). Additionally, during our experimentation with
    prompts, we observe that incorporating the language label followed by a colon
    (e.g., “English:”, “Catalan:”,“Spanish:”) before the sentence to be translated
    and its corresponding translation is an effective strategy for our LLMs. Furthermore,
    beginning and end of sentence tokens are added to delimit the source and translation
    examples in the shots, enhancing the models’ understanding and facilitating the
    extraction of the output translations. Flor-6.3B and Llama-2-7B work with “”
    and “”, while Ǎguila-7B uses “” and “”.
  prefs: []
  type: TYPE_NORMAL
- en: 'When evaluating the FLoRes-200 dev set, we use 5 shots from the FLoRes-200
    devtest set in the prompt. Conversely, when assessing the FLoRes-200 devtest set,
    we incorporate 5 shots from the FLoRes-200 dev set into the prompt. For the remaining
    gender-bias test sets (WinoMT, Gold BUG, and MuST-SHE), we utilize the same prompt
    employed during testing of the FLoRes-200 dev test set, consisting of the same
    5 shots from the FLoRes-200 devtest. When selecting these 5 instances to serve
    as shots, we ensure diversity in content, length, and structure to provide a broader
    range of examples to the model. The specific prompts created are detailed in Section
    [C](#A3 "Appendix C Prompts employed in the Benchmarking ‣ The power of Prompts:
    Evaluating and Mitigating Gender Bias in MT with LLMs") of the Appendix.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | DEV | DEVTEST | DEV | DEVTEST |'
  prefs: []
  type: TYPE_TB
- en: '|  | BLEU | COMET | BLEU | COMET | BLEU | COMET | BLEU | COMET |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 45.1 | 0.8838 | 46.0 | 0.8811 | 29.6 | 0.8737 |
    30.1 | 0.8724 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 38.7 | 0.8645 | 38.6 | 0.8626 | 27.2 | 0.8591 | 27.7 | 0.8578
    |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 40.1 | 0.8687 | 40.4 | 0.8623 | 25.6 | 0.8450 | 25.4 | 0.8422
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 43.0 | 0.8735 | 43.9 | 0.8730 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 29.1 | 0.8359 | 30.3 | 0.8368 | 18.2 | 0.8212 | 19.5 |
    0.8198 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 37.9 | 0.8641 | 39.6 | 0.8680 | 23.8 | 0.8498 | 25.5 | 0.8528
    |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 31.6 | 0.8443 | 32.9 | 0.8458 | 23.3 | 0.8486 | 23.5 | 0.8454
    |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat | 30.1 | 0.8284 | 29.9 | 0.8250 | 22.6 | 0.8427 | 22.9 |
    0.8423 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| (GB prompt) | 27.6 | 0.8176 | 28.4 | 0.8140 | 22.4 | 0.8251 | 21.8 | 0.8277
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: BLEU and COMET scores for FLoRes-200'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Configurations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since we are only performing inference, we adjust only two parameters: the
    top_k, which is set to 1 to ensure a deterministic process, and the limit of maximum
    tokens to generate, which is adjusted depending on the test sets. We use greedy
    decoding for all models since beam search in LLMs demands significant time and
    resources. These choices are made to ensure the comparability of the results.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Key takeaways
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Based on the benchmarking evaluation, the following findings emerge:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Base LLMs fall behind NMT models in terms of MT in both En $\rightarrow$ Es
    directions (check Table [1](#S5.T1 "Table 1 ‣ 5.1 Prompting LLMs ‣ 5 Benchmarking
    ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs")
    to see the results).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All models exhibit gender bias in the assessed directions, with LLMs showing
    a more pronounced bias compared to NMT models (check Tables [3](#S6.T3 "Table
    3 ‣ 6.2 Crafting and testing prompts on WinoMT ‣ 6 Gender Bias mitigation through
    prompting ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT
    with LLMs"), [4](#A1.T4 "Table 4 ‣ Appendix A Gender Scores on Gold BUG ‣ The
    power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs"), and
    [5](#A2.T5 "Table 5 ‣ Appendix B Gender Scores on MuST-SHE ‣ The power of Prompts:
    Evaluating and Mitigating Gender Bias in MT with LLMs")).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The performance of all studied models correlates with gender stereotypes, achieving
    better gender metrics for the pro-stereotypical set rather than the anti-stereotypical
    set (check Section [D](#A4 "Appendix D Gender Scores on the Pro- and Anti-Stereotypical
    sets from WinoMT and Gold BUG ‣ The power of Prompts: Evaluating and Mitigating
    Gender Bias in MT with LLMs") in the Appendices).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the absence of contextual gender cues, all models predict mostly male terms
    ($\sim$6%-25%) mainly relates to female-stereotypical examples (check Section
    [E](#A5 "Appendix E Proportion of Predicted Male and Female terms in Absence of
    Gender Cues ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT
    with LLMs") in the Appendices).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 6 Gender Bias mitigation through prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After observing that LLMs exhibit more gender bias than NMT models, we found
    it necessary to address this bias in LLMs. Consequently, we have chosen to leverage
    prompting, as it is a distinctive feature of these models. Therefore, the second
    stage of our work involves conducting exploratory research in a trial-and-error
    manner, aiming to identify a prompt that effectively mitigates bias in LLMs. For
    this experiment, we have selected the instruction-tuned model Llama-2-7B-chat
    since it is more robust to complex prompts than its base version. In addition,
    in this stage, we have decided to focus solely on the Gender Coreference Resolution
    task. Ideally, our goal is to narrow the gap in gender scores with respect to
    NMT models, as this would represent a significant breakthrough.
  prefs: []
  type: TYPE_NORMAL
- en: 'The procedure goes as follows: Initially, we develop a range of prompts based
    on strategies outlined in the literature, including few-shot prompting, context-supplying,
    and chain-of-thought instructions. To assess the impact of these prompts, we test
    them on WinoMT and obtain gender-bias scores for each prompt. Thereafter, the
    prompt that demonstrates the most considerable reduction in bias on WinoMT, as
    indicated by numerical gender-bias scores, is evaluated on the remaining test
    sets (Gold BUG, MuST-SHE, and FLoRes-200). By doing so, we want to determine:
    firstly, the prompt’s generalizability across the remaining gender-bias test sets,
    and secondly, if it affects the overall machine translation capabilities of the
    LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Model | Examples from: | G Acc | F1-male | F1-female | $\Delta$G |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | FLoRes-200 | 48.0 | 62.6 | 36.4 | 26.2 | 53.1 | 64.9 | 41.3
    | 23.6 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat | FLoRes-200 | 46.4 | 61.4 | 35.5 | 25.9 | 53.3 | 65.3 |
    41.6 | 23.7 |'
  prefs: []
  type: TYPE_TB
- en: '| MuST-SHE | 46.9 | 60.6 | 39.4 | 21.2 | 49.9 | 62.7 | 35.4 | 27.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Invented Winograd examples | 46.6 | 58.8 | 43.2 | 15.6 | 49.8 | 61.8 | 37.5
    | 24.3 |'
  prefs: []
  type: TYPE_TB
- en: '| MuST-SHE + context on Gender Bias issue | 46.9 | 60.0 | 40.7 | 19.3 | 50.6
    | 62.6 | 38.7 | 23.9 |'
  prefs: []
  type: TYPE_TB
- en: '| Invented Winograd examples + chain-of-thought ("agent") | 55.2 | 65.8 | 56.7
    | 9.1 | 60.6 | 69.7 | 56.8 | 12.9 |'
  prefs: []
  type: TYPE_TB
- en: '| Invented Winograd examples + chain-of-thought ("human entity") | 54.5 | 65.2
    | 55.3 | 9.9 | 59.5 | 68.9 | 54.8 | 14.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Invented Winograd examples + SHORT chain-of-thought | 58.8 | 68.9 | 60.5
    | 8.4 | 65.0 | 73.3 | 63.6 | 9.7 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: WinoMT scores using different prompting techniques for En $\rightarrow$
    Es'
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Baseline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before embarking on the search for the prompt, it is essential to establish
    a baseline for Llama-2-7B-chat. Therefore, we use the same prompt employed in
    the benchmarking, with minor adaptations necessary for Llama-2-7B-chat, such as
    the use of special tags (<>, [INST]…). The resulting prompt after the adjustments
    is detailed in Section [F](#A6 "Appendix F Prompt used for the Baseline in the
    Investigation into Prompting ‣ The power of Prompts: Evaluating and Mitigating
    Gender Bias in MT with LLMs") of the Appendices. With this prompt, we obtain MT
    and gender-bias scores across the four test sets. Refer to Tables [1](#S5.T1 "Table
    1 ‣ 5.1 Prompting LLMs ‣ 5 Benchmarking ‣ The power of Prompts: Evaluating and
    Mitigating Gender Bias in MT with LLMs"), [3](#S6.T3 "Table 3 ‣ 6.2 Crafting and
    testing prompts on WinoMT ‣ 6 Gender Bias mitigation through prompting ‣ The power
    of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs"), [4](#A1.T4
    "Table 4 ‣ Appendix A Gender Scores on Gold BUG ‣ The power of Prompts: Evaluating
    and Mitigating Gender Bias in MT with LLMs"), and [5](#A2.T5 "Table 5 ‣ Appendix
    B Gender Scores on MuST-SHE ‣ The power of Prompts: Evaluating and Mitigating
    Gender Bias in MT with LLMs") to observe the results. These initial results offer
    valuable insights, revealing that the instructed version (Llama-2-7B-chat) achieves
    lower MT scores compared to its base model (Llama-2-7B) for both directions.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Crafting and testing prompts on WinoMT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After conducting several experiments using Llama-2-7B-chat, we proceeded to
    curate and test multiple prompts on the WinoMT test set. The curated prompts in
    detail can be found in section [G](#A7 "Appendix G Curated Prompts for the Investigation
    into Prompting ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in
    MT with LLMs") of the Appendices. We recommend consulting them for a comprehensive
    understanding of this section.'
  prefs: []
  type: TYPE_NORMAL
- en: In the design of all our prompts, we incorporated the 5-shot strategy already
    used in the benchmarking and the baseline. However, we substituted the FLoRes-200
    examples and introduced additional modifications to the curated prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 'A significant aspect of our crafted prompts involves the inclusion of translation
    examples that encompass more gender-related phenomena compared to the ones from
    the FLoRes-200 dataset, which comprises mainly gender-neutral or impersonal sentences.
    Specifically, one of our curated prompts included examples from the MuST-SHE dataset,
    while in another prompt, we intentionally created five sentences (or rather, translations)
    adhering to a Winograd structure, wherein each sentence comprises two human entities
    and one pronoun used to disambiguate one of them. These crafted translations were
    deliberately designed to contain more female representation and anti-stereotypical
    content. These invented translations are provided in section [H](#A8 "Appendix
    H Invented Examples following Winograd structure ‣ The power of Prompts: Evaluating
    and Mitigating Gender Bias in MT with LLMs") of the Appendices.'
  prefs: []
  type: TYPE_NORMAL
- en: For another prompt, in addition to including 5 shots from MuST-SHE, we also
    adopted an approach that involved providing more contextual information to the
    model. We explicitly stated the objective of translating while simultaneously
    reducing gender bias. By offering this additional context, the model should gain
    a clearer understanding of the goal to mitigate gender bias and the factors it
    should consider to do so effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Afterwards, we adopted a chain-of-thought strategy for the remaining curated
    prompts, each following again a 5-shot structure. We integrated the previously
    crafted Winograd examples into these prompts. Two of them resulted in complex
    and detailed chain-of-thought prompts, incorporating all the necessary steps and
    reasoning that the model should do to carefully solve the Gender Coreference Task
    and provide a correct translation. The only distinction between these two complex
    prompts was the terminology used to refer to the human entities in the examples,
    either as “human entity” or “agent”.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we constructed another chain-of-thought prompt that yielded the best
    results. In this prompt, the steps were significantly simplified compared to the
    previous two prompts. Here, explicit instructions of the steps were not included,
    and instead, schematic steps accompanied by arrows were provided in the shots.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a comprehensive summary of the results obtained on WinoMT for all these
    prompts, please consult Table [2](#S6.T2 "Table 2 ‣ 6 Gender Bias mitigation through
    prompting ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT
    with LLMs").'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$S |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 57.1 | 67.5 | 55.6 | 11.9 | 23.9 | 70.9 | 76.6 |
    74.4 | 2.2 | 24.3 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 60.9 | 70.1 | 64.0 | 6.1 | 28.1 | 67.2 | 74.0 | 68.9 | 5.1
    | 33.9 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 51.5 | 64.2 | 44.6 | 19.6 | 24.6 | 57.9 | 68.6 | 50.4 | 18.2
    | 26.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 48.9 | 63.1 | 37.9 | 25.2 | 27.3 | - | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 46.1 | 60.4 | 34.5 | 25.9 | 36.1 | 49.3 | 63.3 | 32.5 |
    30.8 | 28.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 47.7 | 62.2 | 35.2 | 27.0 | 33.1 | 53.4 | 65.1 | 42.5 | 22.6
    | 30.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 48.0 | 62.6 | 36.4 | 26.2 | 32.8 | 53.1 | 64.9 | 41.3 | 23.6
    | 33.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat | 46.4 | 61.4 | 35.5 | 25.9 | 33.1 | 53.3 | 65.3 | 41.6 |
    23.7 | 32.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat |  |  |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| (GB prompt) | 58.8 | 68.9 | 60.5 | 8.4 | 27.8 | 65.0 | 73.3 | 63.6 | 9.7
    | 22.1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: WinoMT gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Top-performing prompt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The resulting top-performing prompt on WinoMT is the one named Invented Winograd
    examples + SHORT chain-of-thought from Table [2](#S6.T2 "Table 2 ‣ 6 Gender Bias
    mitigation through prompting ‣ The power of Prompts: Evaluating and Mitigating
    Gender Bias in MT with LLMs"). With this prompt, we have achieved remarkable increases
    of 12.4 (En $\rightarrow$ Es) on WinoMT compared to the baseline. In short, this
    prompt follows a simplified chain-of-thought approach with 5-shots on anti-stereotypical
    content and increased female representation. The examples in the prompt were invented
    following the Winograd sentence structure, designed to address gender coreference.'
  prefs: []
  type: TYPE_NORMAL
- en: The phrase “Proceed step by step” is also included before the shots. In the
    initial experiments, we observed that incorporating this sentence led to the model
    providing a more structured response. Based on this observation, we replicated
    the same pattern generated by the LLM in our crafted shots.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After testing our top-performing prompt on the remaining gender-bias test sets,
    Gold BUG and MuST-SHE, we observe a significant reduction in gender bias within
    those test sets too. These results are detailed in sections [A](#A1 "Appendix
    A Gender Scores on Gold BUG ‣ The power of Prompts: Evaluating and Mitigating
    Gender Bias in MT with LLMs") and [B](#A2 "Appendix B Gender Scores on MuST-SHE
    ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs")
    of the Appendices. Subsequently, all the three Tables [3](#S6.T3 "Table 3 ‣ 6.2
    Crafting and testing prompts on WinoMT ‣ 6 Gender Bias mitigation through prompting
    ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs"),
    [4](#A1.T4 "Table 4 ‣ Appendix A Gender Scores on Gold BUG ‣ The power of Prompts:
    Evaluating and Mitigating Gender Bias in MT with LLMs"), and [5](#A2.T5 "Table
    5 ‣ Appendix B Gender Scores on MuST-SHE ‣ The power of Prompts: Evaluating and
    Mitigating Gender Bias in MT with LLMs") demonstrate a remarkable improvement
    in gender-bias scores, significantly reducing the upper bound in each test set
    compared to the best NMT model. This places the LLM on par with NMT models in
    terms of gender bias manifestation. For example, on the WinoMT test set, the model
    achieves the second-best position in En $\rightarrow$ Es. In MuST-SHE, the mitigation
    is less pronounced as this test set also encompasses other gender-related tasks,
    unlike WinoMT and Gold BUG, which focus solely on Gender Coreference Resolution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding the MT metrics, we observe a small loss compared to the baseline
    when testing on FLoRes-200 (Table [1](#S5.T1 "Table 1 ‣ 5.1 Prompting LLMs ‣ 5
    Benchmarking ‣ The power of Prompts: Evaluating and Mitigating Gender Bias in
    MT with LLMs")).'
  prefs: []
  type: TYPE_NORMAL
- en: 8 Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Initially, we believed that reducing gender bias through prompting would possibly
    be straightforward. However, it was surprising to find that the model only began
    effectively mitigating the bias after implementing the chain-of-thought approach.
    In fact, the results presented in Table [2](#S6.T2 "Table 2 ‣ 6 Gender Bias mitigation
    through prompting ‣ The power of Prompts: Evaluating and Mitigating Gender Bias
    in MT with LLMs") demonstrate that without the chain-of-thought approach and relying
    solely on the same invented Winograd examples from the top-performing prompt,
    no improvement was observed. Furthermore, we noticed that describing the problem
    of gender bias or including MuST-SHE examples did not lead to any improvement.
    Additionally, we observed that the Llama-2-7B-chat model comprehends and responds
    better to schematic chain-of-thought prompts compared to highly detailed and elaborate
    prompts, resulting in higher gender scores in the former case. Besides, the inclusion
    of the phrase “Proceed step by step” seems to be beneficial.'
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, after identifying our successful prompt, we can confidently affirm
    that leveraging prompting can indeed serve as an effective method to mitigate
    gender bias in an instructed LLM (at least, for Gender Coreference Resolution).
  prefs: []
  type: TYPE_NORMAL
- en: 9 Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work investigates gender bias in the translation outputs generated by various
    LLMs through two distinct approaches. Firstly, by benchmarking three base models
    (Ǎguila-7B, Flor-6.3B and Llama-2-7B) using different gender-bias test sets and
    comparing the results with state-of-the-art NMT models (M2M-100-1.2B, NLLB-200-1.3B,
    Mt-aina-en-ca, and Google Translate). Secondly, by experimenting with the prompting
    mechanism of an instruction-tuned LLM (Llama-2-7B-chat) and trying to mitigate
    its gender bias in the output. This study is done in the En $\rightarrow$ Es directions.
  prefs: []
  type: TYPE_NORMAL
- en: Results reveal the presence of gender bias across all models, with base LLMs
    exhibiting more gender bias than NMT models. Moreover, the performance of all
    models correlates with gender stereotypes. In the absence of gender cues in the
    source sentence, they tend to generate predominantly male terms, while female
    terms are generated primarily when encountering female-stereotypical content.
    To mitigate this bias, prompting engineering techniques have been implemented
    in an instruction-tuned LLM. After curating and testing several prompts, one prompt
    was identified that resulted in a significant reduction in gender bias, achieving
    impressive gender scores. The prompt follows a simplified chain-of-thought approach
    with 5-shots relying on anti-stereotypical content and increased female representation.
    This prompt enables the instructed LLM to perform competitively in terms of gender
    scores, achieving results comparable to NMT models and even surpassing some of
    them. However, it is observed that using this prompt leads to a slight loss in
    the translation quality.
  prefs: []
  type: TYPE_NORMAL
- en: 10 Ethical statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this evaluation, we have only focused on the binary male and female genders,
    without considering other gender identities. Additional experiments on new datasets
    would be required to assess the performance of these methods on non-binary scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: About the proposed definition of gender bias, we tried to characterize different
    aspects of the problem. Even though we recognize that it is a complex problem
    and our metrics and experiments focus only on some specific manifestations.
  prefs: []
  type: TYPE_NORMAL
- en: 11 Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This research has been promoted and financed by the Government of Catalonia
    through the Aina project, by the Ministerio para la Transformación Digital y de
    la Función Pública and Plan de Recuperación, Transformación y Resiliencia (Funded
    by EU – NextGenerationEU within the framework of the project ILENIA with reference
    2022/TL22/00215337, 2022/TL22/00215336, 2022/TL22/00215335, 2022/TL22/00215334).
    It has also been supported by the Horizon Europe program [Grant Number 101135916]
    and by DeepR3 (TED2021-130295B-C32) (Funded by MCIN/AEI/10.13039/501100011033
    and European Union NextGeneration EU/PRTR).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Agrawal et al. (2023) Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer,
    and Marjan Ghazvininejad. 2023. [In-context examples selection for machine translation](https://doi.org/10.18653/v1/2023.findings-acl.564).
    In *Findings of the Association for Computational Linguistics: ACL 2023*, pages
    8857–8873, Toronto, Canada. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bahdanau et al. (2015) Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015.
    [Neural machine translation by jointly learning to align and translate](http://arxiv.org/abs/1409.0473).
    In *3rd International Conference on Learning Representations, ICLR 2015, San Diego,
    CA, USA, May 7-9, 2015, Conference Track Proceedings*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bawden and Yvon (2023) Rachel Bawden and François Yvon. 2023. [Investigating
    the translation performance of a large multilingual language model: the case of
    BLOOM](https://aclanthology.org/2023.eamt-1.16). In *Proceedings of the 24th Annual
    Conference of the European Association for Machine Translation, EAMT 2023, Tampere,
    Finland, 12-15 June 2023*, pages 157–170\. European Association for Machine Translation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bentivogli et al. (2020) Luisa Bentivogli, Beatrice Savoldi, Matteo Negri, Mattia A.
    Di Gangi, Roldano Cattoni, and Marco Turchi. 2020. [Gender in danger? evaluating
    speech translation technology on the MuST-SHE corpus](https://doi.org/10.18653/v1/2020.acl-main.619).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*, pages 6923–6933, Online. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. [Language models are few-shot learners](http://arxiv.org/abs/2005.14165).
    *CoRR*, abs/2005.14165.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cai et al. (2024) Yuchen Cai, Ding Cao, Rongxi Guo, Yaqin Wen, Guiquan Liu,
    and Enhong Chen. 2024. [Locating and mitigating gender bias in large language
    models](https://doi.org/10.48550/ARXIV.2403.14409). *CoRR*, abs/2403.14409.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cattoni et al. (2021) Roldano Cattoni, Mattia Antonino Di Gangi, Luisa Bentivogli,
    Matteo Negri, and Marco Turchi. 2021. [Must-c: A multilingual corpus for end-to-end
    speech translation](https://doi.org/https://doi.org/10.1016/j.csl.2020.101155).
    *Computer Speech and Language*, 66:101155.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cho et al. (2014) Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, and
    Yoshua Bengio. 2014. [On the properties of neural machine translation: Encoder-decoder
    approaches](https://doi.org/10.3115/V1/W14-4012). In *Proceedings of SSST@EMNLP
    2014, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation,
    Doha, Qatar, 25 October 2014*, pages 103–111\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chowdhery et al. (2023) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
    Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily
    Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael
    Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
    Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam
    Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander
    Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M.
    Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
    Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,
    Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern,
    Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2023. [Palm: Scaling language
    modeling with pathways](http://jmlr.org/papers/v24/22-1144.html). *J. Mach. Learn.
    Res.*, 24:240:1–240:113.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert
    Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery,
    Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yanping Huang, Andrew M.
    Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts,
    Denny Zhou, Quoc V. Le, and Jason Wei. 2022. [Scaling instruction-finetuned language
    models](https://doi.org/10.48550/ARXIV.2210.11416). *CoRR*, abs/2210.11416.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Costa-jussà et al. (2022) Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha
    Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel
    Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood,
    Bapi Akula, Loïc Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman,
    Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran,
    Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia
    Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe
    Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022. [No language left
    behind: Scaling human-centered machine translation](https://doi.org/10.48550/ARXIV.2207.04672).
    *CoRR*, abs/2207.04672.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Costa-jussà et al. (2020) Marta R. Costa-jussà, Carlos Escolano, Christine
    Basta, Javier Ferrando, Roser Batlle, and Ksenia Kharitonova. 2020. [Gender bias
    in multilingual neural machine translation: The architecture matters](http://arxiv.org/abs/2012.13176).
    *CoRR*, abs/2012.13176.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Crawford (2017) Kate Crawford. 2017. The trouble with bias. in conference on
    neural information processing systems (nips) – keynote, long beach, usa.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dagmar Stahlberg and Sczesny. (2007) Lisa Irmen Dagmar Stahlberg, Friederike Braun
    and Sabine Sczesny. 2007. Representation of the sexes in language. social communication,
    pages 163–187.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ernst et al. (2023) Jasmina S. Ernst, Sascha Marton, Jannik Brinkmann, Eduardo
    Vellasques, Damien Foucard, Martin Kraemer, and Marian Lambert. 2023. [Bias mitigation
    for large language models using adversarial learning](https://ceur-ws.org/Vol-3523/paper11.pdf).
    In *Proceedings of the 1st Workshop on Fairness and Bias in AI co-located with
    26th European Conference on Artificial Intelligence (ECAI 2023), Kraków, Poland,
    October 1st, 2023*, volume 3523 of *CEUR Workshop Proceedings*. CEUR-WS.org.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2020) Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed
    El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav
    Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard
    Grave, Michael Auli, and Armand Joulin. 2020. [Beyond english-centric multilingual
    machine translation](http://arxiv.org/abs/2010.11125). *CoRR*, abs/2010.11125.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Friedman and Nissenbaum (1996) Batya Friedman and Helen Nissenbaum. 1996. [Bias
    in computer systems](https://doi.org/10.1145/230538.230561). *ACM Trans. Inf.
    Syst.*, 14(3):330–347.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2023a) Jun Gao, Huan Zhao, Changlong Yu, and Ruifeng Xu. 2023a.
    [Exploring the feasibility of chatgpt for event extraction](https://doi.org/10.48550/ARXIV.2303.03836).
    *CoRR*, abs/2303.03836.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2023b) Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. 2023b.
    [Enabling large language models to generate text with citations](https://doi.org/10.18653/V1/2023.EMNLP-MAIN.398).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2023, Singapore, December 6-10, 2023*, pages 6465–6488\. Association
    for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garcia et al. (2023) Xavier Garcia, Yamini Bansal, Colin Cherry, George F. Foster,
    Maxim Krikun, Melvin Johnson, and Orhan Firat. 2023. [The unreasonable effectiveness
    of few-shot learning for machine translation](https://proceedings.mlr.press/v202/garcia23a.html).
    In *International Conference on Machine Learning, ICML 2023, 23-29 July 2023,
    Honolulu, Hawaii, USA*, volume 202 of *Proceedings of Machine Learning Research*,
    pages 10867–10878\. PMLR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ghosh and Caliskan (2023) Sourojit Ghosh and Aylin Caliskan. 2023. [Chatgpt
    perpetuates gender bias in machine translation and ignores non-gendered pronouns:
    Findings across bengali and five other low-resource languages](https://doi.org/10.1145/3600211.3604672).
    In *Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society, AIES
    2023, Montréal, QC, Canada, August 8-10, 2023*, pages 901–912\. ACM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goyal et al. (2021) Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen,
    Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán,
    and Angela Fan. 2021. [The FLORES-101 evaluation benchmark for low-resource and
    multilingual machine translation](http://arxiv.org/abs/2106.03193). *CoRR*, abs/2106.03193.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goyal et al. (2022) Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen,
    Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc’Aurelio Ranzato, Francisco Guzmán,
    and Angela Fan. 2022. [The Flores-101 evaluation benchmark for low-resource and
    multilingual machine translation](https://doi.org/10.1162/tacl_a_00474). *Transactions
    of the Association for Computational Linguistics*, 10:522–538.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guzmán et al. (2019) Francisco Guzmán, Peng-Jen Chen, Myle Ott, Juan Pino,
    Guillaume Lample, Philipp Koehn, Vishrav Chaudhary, and Marc’Aurelio Ranzato.
    2019. [The FLORES evaluation datasets for low-resource machine translation: Nepali–English
    and Sinhala–English](https://doi.org/10.18653/v1/D19-1632). In *Proceedings of
    the 2019 Conference on Empirical Methods in Natural Language Processing and the
    9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*,
    pages 6098–6111, Hong Kong, China. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hendy et al. (2023) Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak,
    Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan
    Awadalla. 2023. [How good are GPT models at machine translation? A comprehensive
    evaluation](https://doi.org/10.48550/ARXIV.2302.09210). *CoRR*, abs/2302.09210.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiao et al. (2023a) Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and
    Zhaopeng Tu. 2023a. [Is chatgpt A good translator? A preliminary study](https://doi.org/10.48550/ARXIV.2301.08745).
    *CoRR*, abs/2301.08745.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiao et al. (2023b) Wenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing Wang, Shuming
    Shi, and Zhaopeng Tu. 2023b. [Is chatgpt a good translator? yes with gpt-4 as
    the engine](http://arxiv.org/abs/2301.08745).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Johnson et al. (2017) Melvin Johnson, Mike Schuster, Quoc V. Le, Maxim Krikun,
    Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda B. Viégas, Martin Wattenberg,
    Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2017. [Google’s multilingual neural
    machine translation system: Enabling zero-shot translation](https://doi.org/10.1162/TACL_A_00065).
    *Trans. Assoc. Comput. Linguistics*, 5:339–351.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lal Zimman and Meyerhoff (2017) Evan Hazenberg Lal Zimman and Miriam Meyerhoff.
    2017. Trans people’s linguistic self-determination and the dialogic nature of
    identity. representing trans: Linguistic, legal and everyday perspectives, pages
    226–248.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Levesque et al. (2012) Hector J. Levesque, Ernest Davis, and Leora Morgenstern.
    2012. [The winograd schema challenge](http://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492).
    In *Principles of Knowledge Representation and Reasoning: Proceedings of the Thirteenth
    International Conference, KR 2012, Rome, Italy, June 10-14, 2012*. AAAI Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Levesque (2011) Roger J. R. Levesque. 2011. [*Sex Roles and Gender Roles*](https://doi.org/10.1007/978-1-4419-1695-2_602),
    pages 2622–2623\. Springer New York, New York, NY.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Levy et al. (2021) Shahar Levy, Koren Lazar, and Gabriel Stanovsky. 2021. [Collecting
    a large-scale gender bias dataset for coreference resolution and machine translation](https://doi.org/10.18653/v1/2021.findings-emnlp.211).
    In *Findings of the Association for Computational Linguistics: EMNLP 2021*, pages
    2470–2480, Punta Cana, Dominican Republic. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2023) Bo Li, Gexiang Fang, Yang Yang, Quansen Wang, Wei Ye, Wen
    Zhao, and Shikun Zhang. 2023. [Evaluating chatgpt’s information extraction capabilities:
    An assessment of performance, explainability, calibration, and faithfulness](https://doi.org/10.48550/ARXIV.2304.11633).
    *CoRR*, abs/2304.11633.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Longpre et al. (2023) Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won
    Chung, Yi Tay, Denny Zhou, Quoc V. Le, Barret Zoph, Jason Wei, and Adam Roberts.
    2023. [The flan collection: Designing data and methods for effective instruction
    tuning](https://proceedings.mlr.press/v202/longpre23a.html). In *International
    Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii,
    USA*, volume 202 of *Proceedings of Machine Learning Research*, pages 22631–22648\.
    PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luong et al. (2015) Thang Luong, Hieu Pham, and Christopher D. Manning. 2015.
    [Effective approaches to attention-based neural machine translation](https://doi.org/10.18653/V1/D15-1166).
    In *Proceedings of the 2015 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015*, pages 1412–1421\.
    The Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mash et al. (2024) Audrey Mash, Carlos Escolano, Aleix Sant, Maite Melero,
    and Francesca de Luca Fornaciari. 2024. [Unmasking biases: Exploring gender bias
    in English-Catalan machine translation through tokenization analysis and novel
    dataset](https://aclanthology.org/2024.lrec-main.1489). In *Proceedings of the
    2024 Joint International Conference on Computational Linguistics, Language Resources
    and Evaluation (LREC-COLING 2024)*, pages 17144–17153, Torino, Italia. ELRA and
    ICCL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mishra et al. (2022) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh
    Hajishirzi. 2022. [Cross-task generalization via natural language crowdsourcing
    instructions](https://doi.org/10.18653/V1/2022.ACL-LONG.244). In *Proceedings
    of the 60th Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022*, pages 3470–3487\.
    Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Muennighoff et al. (2023) Niklas Muennighoff, Thomas Wang, Lintang Sutawika,
    Adam Roberts, Stella Biderman, Teven Le Scao, M. Saiful Bari, Sheng Shen, Zheng Xin
    Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid
    Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin
    Raffel. 2023. [Crosslingual generalization through multitask finetuning](https://doi.org/10.18653/V1/2023.ACL-LONG.891).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 15991–16111\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ning et al. (2023) Munan Ning, Yujia Xie, Dongdong Chen, Zeyin Song, Lu Yuan,
    Yonghong Tian, Qixiang Ye, and Li Yuan. 2023. [Album storytelling with iterative
    story-aware captioning and large language models](https://doi.org/10.48550/ARXIV.2305.12943).
    *CoRR*, abs/2305.12943.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI (2023) OpenAI. 2023. [GPT-4 technical report](https://doi.org/10.48550/ARXIV.2303.08774).
    *CoRR*, abs/2303.08774.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
    Zhu. 2002. [Bleu: a method for automatic evaluation of machine translation](https://doi.org/10.3115/1073083.1073135).
    In *Proceedings of the 40th Annual Meeting of the Association for Computational
    Linguistics*, pages 311–318, Philadelphia, Pennsylvania, USA. Association for
    Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parmy Olson (2018) Parmy Olson. 2018. The algorithm that helped google translate
    become sexist. [https://www.forbes.com/sites/parmyolson/](https://www.forbes.com/sites/parmyolson/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Post (2018) Matt Post. 2018. [A call for clarity in reporting BLEU scores](https://doi.org/10.18653/v1/W18-6319).
    In *Proceedings of the Third Conference on Machine Translation: Research Papers*,
    pages 186–191, Brussels, Belgium. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2019) Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario
    Amodei, and Ilya Sutskever. 2019. [Language models are unsupervised multitask
    learners](https://api.semanticscholar.org/CorpusID:160025533).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rei et al. (2020) Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie.
    2020. [COMET: A neural framework for MT evaluation](https://doi.org/10.18653/v1/2020.emnlp-main.213).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP)*, pages 2685–2702, Online. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Régner et al. (2019) Isabelle Régner, Catherine Thinus-Blanc, Agnès Netter,
    Toni Schmader, and Pascal Huguet. 2019. [Committees with implicit biases promote
    fewer women when they do not believe gender bias exists](https://doi.org/10.1038/s41562-019-0686-3).
    *Nature Human Behaviour*, 3.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sánchez et al. (2023) Eduardo Sánchez, Pierre Andrews, Pontus Stenetorp, Mikel
    Artetxe, and Marta R. Costa-jussà. 2023. [Gender-specific machine translation
    with large language models](https://doi.org/10.48550/ARXIV.2309.03175). *CoRR*,
    abs/2309.03175.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sanh et al. (2022) Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach,
    Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja,
    Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza
    Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V. Nayak, Debajyoti Datta, Jonathan
    Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong,
    Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht
    Sharma, Andrea Santilli, Thibault Févry, Jason Alan Fries, Ryan Teehan, Teven Le
    Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M. Rush. 2022. [Multitask
    prompted training enables zero-shot task generalization](https://openreview.net/forum?id=9Vrb9D0WI4).
    In *The Tenth International Conference on Learning Representations, ICLR 2022,
    Virtual Event, April 25-29, 2022*. OpenReview.net.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saunders and Byrne (2020) Danielle Saunders and Bill Byrne. 2020. [Reducing
    gender bias in neural machine translation as a domain adaptation problem](https://doi.org/10.18653/v1/2020.acl-main.690).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*, pages 7724–7736, Online. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Savoldi et al. (2021) Beatrice Savoldi, Marco Gaido, Luisa Bentivogli, Matteo
    Negri, and Marco Turchi. 2021. [Gender bias in machine translation](https://doi.org/10.1162/tacl_a_00401).
    *Transactions of the Association for Computational Linguistics*, 9:845–874.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Savoldi et al. (2024) Beatrice Savoldi, Andrea Piergentili, Dennis Fucci, Matteo
    Negri, and Luisa Bentivogli. 2024. [A prompt response to the demand for automatic
    gender-neutral translation](https://aclanthology.org/2024.eacl-short.23). In *Proceedings
    of the 18th Conference of the European Chapter of the Association for Computational
    Linguistics (Volume 2: Short Papers)*, pages 256–267, St. Julian’s, Malta. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stafanovičs et al. (2020) Artūrs Stafanovičs, Toms Bergmanis, and Mārcis Pinnis.
    2020. [Mitigating gender bias in machine translation with target gender annotations](https://aclanthology.org/2020.wmt-1.73).
    In *Proceedings of the Fifth Conference on Machine Translation*, pages 629–638,
    Online. Association for Computational Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stanovsky et al. (2019) Gabriel Stanovsky, Noah A. Smith, and Luke Zettlemoyer.
    2019. [Evaluating gender bias in machine translation](https://doi.org/10.18653/v1/P19-1164).
    In *Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics*, pages 1679–1684, Florence, Italy. Association for Computational
    Linguistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Su et al. (2023) Hsuan Su, Cheng-Chu Cheng, Hua Farn, Shachi H. Kumar, Saurav
    Sahay, Shang-Tse Chen, and Hung-yi Lee. 2023. [Learning from red teaming: Gender
    bias provocation and mitigation in large language models](https://doi.org/10.48550/ARXIV.2310.11079).
    *CoRR*, abs/2310.11079.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2023) Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei
    Zhang, and Guoyin Wang. 2023. [Text classification via large language models](https://doi.org/10.18653/V1/2023.FINDINGS-EMNLP.603).
    In *Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore,
    December 6-10, 2023*, pages 8990–9005\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thoppilan et al. (2022) Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam
    Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,
    Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali,
    Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong
    Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang,
    Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel
    Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen,
    Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina,
    Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew
    Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil,
    Blaise Agüera y Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. 2022.
    [Lamda: Language models for dialog applications](http://arxiv.org/abs/2201.08239).
    *CoRR*, abs/2201.08239.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. [Llama
    2: Open foundation and fine-tuned chat models](https://doi.org/10.48550/ARXIV.2307.09288).
    *CoRR*, abs/2307.09288.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vanmassenhove (2024) Eva Vanmassenhove. 2024. [Gender bias in machine translation
    and the era of large language models](https://doi.org/10.48550/ARXIV.2401.10016).
    *CoRR*, abs/2401.10016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. [Attention
    is all you need](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html).
    In *Advances in Neural Information Processing Systems 30: Annual Conference on
    Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
    USA*, pages 5998–6008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vilar et al. (2023) David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo,
    Viresh Ratnakar, and George F. Foster. 2023. [Prompting palm for translation:
    Assessing strategies and performance](https://doi.org/10.18653/V1/2023.ACL-LONG.859).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*,
    pages 15406–15427\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H.
    Chi, Quoc Le, and Denny Zhou. 2022. [Chain of thought prompting elicits reasoning
    in large language models](http://arxiv.org/abs/2201.11903). *CoRR*, abs/2201.11903.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2023) Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang,
    Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, and
    Wenjuan Han. 2023. [Zero-shot information extraction via chatting with chatgpt](https://doi.org/10.48550/ARXIV.2302.10205).
    *CoRR*, abs/2302.10205.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2016) Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad
    Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff
    Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws,
    Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant
    Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals,
    Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. [Google’s neural machine
    translation system: Bridging the gap between human and machine translation](http://arxiv.org/abs/1609.08144).
    *CoRR*, abs/1609.08144.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023) Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han,
    Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. [Harnessing the power
    of llms in practice: A survey on chatgpt and beyond](https://doi.org/10.48550/ARXIV.2304.13712).
    *CoRR*, abs/2304.13712.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2022) Kevin Yang, Yuandong Tian, Nanyun Peng, and Dan Klein. 2022.
    [Re3: Generating longer stories with recursive reprompting and revision](https://doi.org/10.18653/V1/2022.EMNLP-MAIN.296).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022*,
    pages 4393–4479\. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao, and Karthik Narasimhan. 2023. [Tree of thoughts: Deliberate problem
    solving with large language models](http://papers.nips.cc/paper_files/paper/2023/hash/271db9922b8d1f4dd7aaef84ed5ac703-Abstract-Conference.html).
    In *Advances in Neural Information Processing Systems 36: Annual Conference on
    Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
    December 10 - 16, 2023*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023a) Biao Zhang, Barry Haddow, and Alexandra Birch. 2023a.
    [Prompting large language model for machine translation: A case study](https://proceedings.mlr.press/v202/zhang23m.html).
    In *International Conference on Machine Learning, ICML 2023, 23-29 July 2023,
    Honolulu, Hawaii, USA*, volume 202 of *Proceedings of Machine Learning Research*,
    pages 41092–41110\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023b) Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei
    Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, and Guoyin Wang. 2023b.
    [Instruction tuning for large language models: A survey](https://doi.org/10.48550/ARXIV.2308.10792).
    *CoRR*, abs/2308.10792.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023c) Xuan Zhang, Navid Rajabi, Kevin Duh, and Philipp Koehn.
    2023c. [Machine translation with large language models: Prompting, few-shot learning,
    and fine-tuning with QLoRA](https://doi.org/10.18653/v1/2023.wmt-1.43). In *Proceedings
    of the Eighth Conference on Machine Translation*, pages 468–481, Singapore. Association
    for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2018) Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez,
    and Kai-Wei Chang. 2018. [Gender bias in coreference resolution: Evaluation and
    debiasing methods](https://doi.org/10.18653/v1/N18-2003). In *Proceedings of the
    2018 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 2 (Short Papers)*, pages 15–20,
    New Orleans, Louisiana. Association for Computational Linguistics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan
    Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li,
    Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. [A survey
    of large language models](http://arxiv.org/abs/2303.18223).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2021) Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer
    Singh. 2021. [Calibrate before use: Improving few-shot performance of language
    models](http://proceedings.mlr.press/v139/zhao21c.html). In *Proceedings of the
    38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021,
    Virtual Event*, volume 139 of *Proceedings of Machine Learning Research*, pages
    12697–12706\. PMLR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2023) Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Lingpeng
    Kong, Jiajun Chen, Lei Li, and Shujian Huang. 2023. [Multilingual machine translation
    with large language models: Empirical results and analysis](https://doi.org/10.48550/ARXIV.2304.04675).
    *CoRR*, abs/2304.04675.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Gender Scores on Gold BUG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$S |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 62.3 | 77.5 | 56.9 | 20.6 | 26.7 | 47.5 | 62.8 |
    55.0 | 7.8 | 14.9 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 62.1 | 77.4 | 57.9 | 19.5 | 13.6 | 65.2 | 79.4 | 61.9 | 17.5
    | 20.4 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 60.4 | 76.3 | 49.8 | 26.5 | 23.9 | 63.8 | 78.5 | 56.5 | 22.0
    | 22.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 60.3 | 76.4 | 51.2 | 25.2 | 20.5 | - | - | - | - |  |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 54.5 | 71.7 | 43.9 | 27.8 | 22.5 | 58.8 | 75.2 | 46.5 |
    28.7 | 18.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 57.8 | 74.5 | 43.0 | 31.5 | 18.6 | 61.2 | 77.1 | 46.2 | 30.9
    | 14.9 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 57.7 | 74.9 | 37.1 | 37.8 | 18.7 | 60.2 | 76.9 | 37.4 | 39.5
    | 16.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat | 57.8 | 74.5 | 39.3 | 35.2 | 25.3 | 58.9 | 75.6 | 37.0 |
    38.6 | 16.9 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat |  |  |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| (GB prompt) | 59.8 | 75.0 | 58.7 | 16.3 | 15.4 | 63.7 | 78.5 | 58.9 | 19.6
    | 18.1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Gold BUG gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Gender Scores on MuST-SHE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$G |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 89.5 | 90.6 | 88.0 | 2.6 | 95.1 | 95.5 | 94.7 |
    0.8 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 93.3 | 93.7 | 92.7 | 1.0 | 96.0 | 96.2 | 95.8 | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 84.4 | 86.6 | 81.4 | 5.2 | 87.4 | 89.2 | 84.8 | 4.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 87.1 | 88.5 | 85.4 | 3.1 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 87.1 | 88.5 | 85.4 | 3.1 | 92.2 | 93.0 | 91.0 | 2.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 89.6 | 90.7 | 88.2 | 2.5 | 93.3 | 93.9 | 92.4 | 1.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 91.1 | 91.9 | 90.0 | 1.8 | 95.1 | 94.5 | 93.2 | 1.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat | 88.1 | 89.7 | 86.0 | 3.7 | 91.0 | 92.0 | 89.6 | 2.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B-chat |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| (GB prompt) | 88.4 | 89.8 | 86.5 | 3.3 | 92.0 | 92.6 | 91.4 | 1.2 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: MuST-SHE gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Prompts employed in the Benchmarking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The prompts employed with Ǎguila-7B when testing FLoRes-200 devtest set for
    En $\rightarrow$ Es respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Translate
    the following sentence from English to Catalan:  English: Hangeul is the only
    purposely invented alphabet in popular daily use. The alphabet was invented in
    1444 during the reign of King Sejong (1418-1450).  Catalan: El hangul és
    l’únic alfabet creat arbitràriament que té un ús estès en la vida diària. L’alfabet
    es va inventar l’any 1444 durant el regnat de King Sejong (1418-1450).  English:
    They also said in a statement, "The crew is currently working to determine
    the best method of safely extracting the ship".  Catalan: També han dit
    en un comunicat, "La tripulació treballa ara mateix per a determinar la millor
    tècnica per a extreure la nau de manera segura".  English: This is becoming
    less of an issue as lens manufacturers achieve higher standards in lens production.  Catalan:
    Això és cada vegada menys important perquè els fabricants de lents estan assolint
    estàndards més elevats en la producció de lents.  English: While assessing
    the successes and becoming aware of failures, individuals and the whole of the
    participating persons discover more deeply the values, mission, and driving forces
    of the organization.  Catalan: Mentre confirmen els èxits i prenen consciència
    dels fracassos, els individus i el grup de participants descobreixen més profundament
    els valors, la missió i les forces motrius de l’organització.  English: Entering
    Southern Africa by car is an amazing way to see all the region’s beauty as well
    as to get to places off the normal tourist routes.  Catalan: Entrar a l’Àfrica
    del Sud en cotxe és una forma impressionant de veure tota la bellesa de la regió
    i d’arribar a llocs fora de les rutes turístiques més habituals.  English:
    ____sentence_to_translate____  Catalan: Translate the following sentence from English to Spanish:  English:
    Hangeul is the only purposely invented alphabet in popular daily use. The alphabet
    was invented in 1444 during the reign of King Sejong (1418-1450).  Spanish:
    El alfabeto coreano es el único diseñado en forma deliberada que aún se utiliza
    a diario popularmente. Se inventó en 1444, durante el reinado de Sejong (1418
    a 1450).  English: They also said in a statement, "The crew is currently
    working to determine the best method of safely extracting the ship".  Spanish:
    También se dijo en un comunicado que: «La tripulación se encuentra actualmente
    trabajando para decidir cuál es el método más seguro para extraer el barco».  English:
    This is becoming less of an issue as lens manufacturers achieve higher standards
    in lens production.  Spanish: Este problema cada vez es menos importante
    gracias a que los fabricantes de lentes logran estándares más altos en su producción.  English:
    While assessing the successes and becoming aware of failures, individuals and
    the whole of the participating persons discover more deeply the values, mission,
    and driving forces of the organization.  Spanish: Durante el proceso de
    análisis de los éxitos y toma de conciencia de los fracasos, los individuos y
    grupos de personas involucrados descubren con mayor profundidad los valores, el
    objetivo y las fuerzas que impulsan a la organización.  English: Entering
    Southern Africa by car is an amazing way to see all the region’s beauty as well
    as to get to places off the normal tourist routes.  Spanish: Una fantástica
    forma de contemplar todo el encanto de la región del sur África es ingresar en
    automóvil, lo que, a su vez, le permitirá acceder a lugares fuera de las rutas
    turísticas habituales.  English: ____sentence_to_translate____  Spanish:
    '
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompts employed with Ǎguila-7B when testing FLoRes-200 dev set, WinoMT,
    Gold BUG and MuST-SHE for En $\rightarrow$ Es were:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Translate
    the following sentence from English to Catalan:  English: The feathers’ structure
    suggests that they were not used in flight but rather for temperature regulation
    or display. The researchers suggested that, even though this is the tail of a
    young dinosaur, the sample shows adult plumage and not a chick’s down.  Catalan:
    L’estructura de les plomes fa pensar que no s’usaven per a volar sinó per a
    regular la temperatura o per a exhibir-se. Els investigadors han suggerit que,
    tot i que es tracta de la cua d’un dinosaure jove, la mostra presenta el plomatge
    d’un adult i no d’un pollet.  English: They found the Sun operated on the
    same basic principles as other stars: The activity of all stars in the system
    was found to be driven by their luminosity, their rotation, and nothing else.  Catalan:
    Han descobert que el Sol funcionava sota els mateixos principis bàsics que
    altres estrelles: s’ha vist que l’activitat de totes les estrelles del sistema
    depèn de llur brillantor, llur rotació i res més.  English: The speeds
    of 802.11n are substantially faster than that of its predecessors with a maximum
    theoretical throughput of 600Mbit/s.  Catalan: Les velocitats de 802.11n
    són substancialment més ràpides que les dels seus predecessors amb un rendiment
    teòric màxim de 600Mbit/s.  English: Over four million people went to Rome
    to attend the funeral.  Catalan: Més de quatre milions de persones van
    anar a Roma per a assistir al funeral.  English: Mrs. Kirchner announced
    her intention to run for president at the Argentine Theatre, the same location
    she used to start her 2005 campaign for the Senate as member of the Buenos Aires
    province delegation.  Catalan: La Sra. Kirchner va anunciar la seva intenció
    de presentar-se a la presidència al Teatre de l’Argentina, el mateix lloc on va
    engegar la campanya al Senat de 2005 com a membre de la delegació provincial de
    Buenos Aires.  English: ____sentence_to_translate____  Catalan: Translate the following sentence
    from English to Spanish:  English: The feathers’ structure suggests that they
    were not used in flight but rather for temperature regulation or display. The
    researchers suggested that, even though this is the tail of a young dinosaur,
    the sample shows adult plumage and not a chick’s down.  Spanish: La estructura
    que presenta el plumaje sugiere que su función no estaba relacionada con el vuelo,
    sino que las usaban para regular la temperatura o como indicador de la misma.
    Los investigadores sostienen que, aunque se trata de la cola de un dinosaurio
    joven, la muestra analizada presenta rasgos del plumaje de un adulto y no de un
    polluelo.  English: They found the Sun operated on the same basic principles
    as other stars: The activity of all stars in the system was found to be driven
    by their luminosity, their rotation, and nothing else.  Spanish: Se descubrió
    que el sol se regía por los mismos principios básicos que otras estrellas: los
    únicos factores que impulsaban su actividad dentro del sistema eran su luminosidad
    y su rotación.  English: The speeds of 802.11n are substantially faster
    than that of its predecessors with a maximum theoretical throughput of 600Mbit/s.  Spanish:
    Las velocidades del estándar 802.11n son mucho más altas que las alcanzadas
    por los que lo precedieron, con un rendimiento teórico máximo de 600 Mbps.  English:
    Over four million people went to Rome to attend the funeral.  Spanish:
    Más de cuatro millones de individuos se concentraron en Roma para presenciar
    el funeral.  English: Mrs. Kirchner announced her intention to run for
    president at the Argentine Theatre, the same location she used to start her 2005
    campaign for the Senate as member of the Buenos Aires province delegation.  Spanish:
    El Teatro Argentino fue el lugar donde la señora Kirchner anunció su intención
    de candidatearse como presidenta; este es el mismo sitio donde inició su campaña
    para el senado en el año 2005, en representación de la provincia de Buenos Aires.  English:
    ____sentence_to_translate____  Spanish: '
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompts employed with Flor-6.3B and Llama-2-7B when testing FLoRes-200
    devtest set for En $\rightarrow$ Es respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Translate
    the following sentence from English to Catalan:  English: Hangeul is the
    only purposely invented alphabet in popular daily use. The alphabet was invented
    in 1444 during the reign of King Sejong (1418-1450).  Catalan: El hangul
    és l’únic alfabet creat arbitràriament que té un ús estès en la vida diària. L’alfabet
    es va inventar l’any 1444 durant el regnat de King Sejong (1418-1450).  English:
    They also said in a statement, "The crew is currently working to determine
    the best method of safely extracting the ship".  Catalan: També han
    dit en un comunicat, "La tripulació treballa ara mateix per a determinar la millor
    tècnica per a extreure la nau de manera segura".  English: This is becoming
    less of an issue as lens manufacturers achieve higher standards in lens production.  Catalan:
    Això és cada vegada menys important perquè els fabricants de lents estan
    assolint estàndards més elevats en la producció de lents.  English: While
    assessing the successes and becoming aware of failures, individuals and the whole
    of the participating persons discover more deeply the values, mission, and driving
    forces of the organization.  Catalan: Mentre confirmen els èxits i prenen
    consciència dels fracassos, els individus i el grup de participants descobreixen
    més profundament els valors, la missió i les forces motrius de l’organització.  English:
    Entering Southern Africa by car is an amazing way to see all the region’s
    beauty as well as to get to places off the normal tourist routes.  Catalan:
    Entrar a l’Àfrica del Sud en cotxe és una forma impressionant de veure tota
    la bellesa de la regió i d’arribar a llocs fora de les rutes turístiques més habituals.  English:
    ____sentence_to_translate____  Catalan: Translate the following sentence from
    English to Spanish:  English: Hangeul is the only purposely invented alphabet
    in popular daily use. The alphabet was invented in 1444 during the reign of King
    Sejong (1418-1450).  Spanish: El alfabeto coreano es el único diseñado
    en forma deliberada que aún se utiliza a diario popularmente. Se inventó en 1444,
    durante el reinado de Sejong (1418 a 1450).  English: They also said
    in a statement, "The crew is currently working to determine the best method of
    safely extracting the ship".  Spanish: También se dijo en un comunicado
    que: «La tripulación se encuentra actualmente trabajando para decidir cuál es
    el método más seguro para extraer el barco».  English: This is becoming
    less of an issue as lens manufacturers achieve higher standards in lens production.  Spanish:
    Este problema cada vez es menos importante gracias a que los fabricantes
    de lentes logran estándares más altos en su producción.  English: While
    assessing the successes and becoming aware of failures, individuals and the whole
    of the participating persons discover more deeply the values, mission, and driving
    forces of the organization.  Spanish: Durante el proceso de análisis
    de los éxitos y toma de conciencia de los fracasos, los individuos y grupos de
    personas involucrados descubren con mayor profundidad los valores, el objetivo
    y las fuerzas que impulsan a la organización.  English: Entering Southern
    Africa by car is an amazing way to see all the region’s beauty as well as to get
    to places off the normal tourist routes.  Spanish: Una fantástica forma
    de contemplar todo el encanto de la región del sur África es ingresar en automóvil,
    lo que, a su vez, le permitirá acceder a lugares fuera de las rutas turísticas
    habituales.  English: ____sentence_to_translate____  Spanish: '
  prefs: []
  type: TYPE_NORMAL
- en: 'The prompts employed with Flor-6.3B and Llama-2-7B when testing FLoRes-200
    dev set, WinoMT, Gold BUG and MuST-SHE for En $\rightarrow$ Es were:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Translate
    the following sentence from English to Catalan:  English: The feathers’ structure
    suggests that they were not used in flight but rather for temperature regulation
    or display. The researchers suggested that, even though this is the tail of a
    young dinosaur, the sample shows adult plumage and not a chick’s down.  Catalan:
    L’estructura de les plomes fa pensar que no s’usaven per a volar sinó per
    a regular la temperatura o per a exhibir-se. Els investigadors han suggerit que,
    tot i que es tracta de la cua d’un dinosaure jove, la mostra presenta el plomatge
    d’un adult i no d’un pollet.  English: They found the Sun operated on
    the same basic principles as other stars: The activity of all stars in the system
    was found to be driven by their luminosity, their rotation, and nothing else.  Catalan:
    Han descobert que el Sol funcionava sota els mateixos principis bàsics que
    altres estrelles: s’ha vist que l’activitat de totes les estrelles del sistema
    depèn de llur brillantor, llur rotació i res més.  English: The speeds
    of 802.11n are substantially faster than that of its predecessors with a maximum
    theoretical throughput of 600Mbit/s.  Catalan: Les velocitats de 802.11n
    són substancialment més ràpides que les dels seus predecessors amb un rendiment
    teòric màxim de 600Mbit/s.  English: Over four million people went to
    Rome to attend the funeral.  Catalan: Més de quatre milions de persones
    van anar a Roma per a assistir al funeral.  English: Mrs. Kirchner announced
    her intention to run for president at the Argentine Theatre, the same location
    she used to start her 2005 campaign for the Senate as member of the Buenos Aires
    province delegation.  Catalan: La Sra. Kirchner va anunciar la seva
    intenció de presentar-se a la presidència al Teatre de l’Argentina, el mateix
    lloc on va engegar la campanya al Senat de 2005 com a membre de la delegació provincial
    de Buenos Aires.  English: ____sentence_to_translate____  Catalan:
    Translate
    the following sentence from English to Spanish:  English: The feathers’ structure
    suggests that they were not used in flight but rather for temperature regulation
    or display. The researchers suggested that, even though this is the tail of a
    young dinosaur, the sample shows adult plumage and not a chick’s down.  Spanish:
    La estructura que presenta el plumaje sugiere que su función no estaba relacionada
    con el vuelo, sino que las usaban para regular la temperatura o como indicador
    de la misma. Los investigadores sostienen que, aunque se trata de la cola de un
    dinosaurio joven, la muestra analizada presenta rasgos del plumaje de un adulto
    y no de un polluelo.  English: They found the Sun operated on the same
    basic principles as other stars: The activity of all stars in the system was found
    to be driven by their luminosity, their rotation, and nothing else.  Spanish:
    Se descubrió que el sol se regía por los mismos principios básicos que otras
    estrellas: los únicos factores que impulsaban su actividad dentro del sistema
    eran su luminosidad y su rotación.  English: The speeds of 802.11n are
    substantially faster than that of its predecessors with a maximum theoretical
    throughput of 600Mbit/s.  Spanish: Las velocidades del estándar 802.11n
    son mucho más altas que las alcanzadas por los que lo precedieron, con un rendimiento
    teórico máximo de 600 Mbps.  English: Over four million people went
    to Rome to attend the funeral.  Spanish: Más de cuatro millones de individuos
    se concentraron en Roma para presenciar el funeral.  English: Mrs. Kirchner
    announced her intention to run for president at the Argentine Theatre, the same
    location she used to start her 2005 campaign for the Senate as member of the Buenos
    Aires province delegation.  Spanish: El Teatro Argentino fue el lugar
    donde la señora Kirchner anunció su intención de candidatearse como presidenta;
    este es el mismo sitio donde inició su campaña para el senado en el año 2005,
    en representación de la provincia de Buenos Aires.  English: ____sentence_to_translate____  Spanish:
    '
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Gender Scores on the Pro- and Anti-Stereotypical sets from WinoMT
    and Gold BUG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Below you can see the results for the WinoMT:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$G |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 74.1 | 80.9 | 71.1 | 9.8 | 89.8 | 91.1 | 90.4 |
    0.7 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 79.7 | 85.1 | 80.7 | 4.4 | 89.3 | 90.8 | 89.8 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 67.7 | 76.4 | 61.1 | 15.3 | 73.7 | 79.2 | 68.7 | 10.5 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 65.7 | 76.0 | 56.9 | 19.1 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 66.0 | 76.1 | 57.8 | 18.3 | 65.7 | 74.1 | 53.8 | 20.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 66.4 | 76.3 | 57.6 | 18.7 | 71.9 | 77.9 | 63.3 | 14.6 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 66.5 | 78.0 | 57.7 | 20.3 | 73.1 | 78.5 | 66.4 | 12.1 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: WinoMT pro-stereotypical set gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$G |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 51.8 | 60.6 | 43.7 | 16.9 | 66.9 | 72.4 | 60.6 |
    11.8 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 53.0 | 62.3 | 47.3 | 15.0 | 58.1 | 66.7 | 46.2 | 20.5 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 45.9 | 58.3 | 30.0 | 28.3 | 52.5 | 65.3 | 29.6 | 35.7 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 42.5 | 56.8 | 21.5 | 35.3 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 34.5 | 49.8 | 12.0 | 37.8 | 43.1 | 58.5 | 12.7 | 45.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 38.7 | 54.0 | 13.8 | 40.2 | 45.2 | 58.2 | 22.8 | 35.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 38.8 | 53.6 | 16.6 | 37.0 | 45.3 | 59.0 | 19.7 | 39.3 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: WinoMT anti-stereotypical set gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below you can see the results for the Gold BUG:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$G |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 69.6 | 82.6 | 67.5 | 15.1 | 70.8 | 83.9 | 60.5 |
    23.4 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 66.9 | 81.3 | 52.7 | 28.6 | 71.5 | 84.1 | 66.6 | 17.5 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 67.4 | 81.8 | 54.7 | 27.1 | 70.3 | 83.6 | 61.3 | 22.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 68.0 | 81.8 | 64.4 | 17.4 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 60.7 | 76.3 | 54.8 | 21.5 | 64.4 | 79.1 | 56.0 | 23.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 65.0 | 80.1 | 54.7 | 25.4 | 69.8 | 83.2 | 54.6 | 28.6 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 66.5 | 81.3 | 56.1 | 25.2 | 69.9 | 83.4 | 53.1 | 30.3 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 8: Gold BUG pro-stereotypical set gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | English $\rightarrow$ Spanish |'
  prefs: []
  type: TYPE_TB
- en: '|  | G Acc | F1-male | F1-female | $\Delta$G |'
  prefs: []
  type: TYPE_TB
- en: '| NMT | Google Translate | 43.6 | 61.0 | 35.7 | 25.3 | 51.4 | 67.1 | 47.6 |
    19.5 |'
  prefs: []
  type: TYPE_TB
- en: '| NLLB-200-1.3B | 46.9 | 62.9 | 44.0 | 18.9 | 48.8 | 65.5 | 44.4 | 21.1 |'
  prefs: []
  type: TYPE_TB
- en: '| M2M-100-1.2B | 41.9 | 59.5 | 29.2 | 30.3 | 46.2 | 62.8 | 36.8 | 26.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Mt-aina-en-ca | 46.0 | 61.3 | 43.9 | 17.4 | - | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| LLM | Ǎguila-7B | 40.0 | 59.1 | 27.0 | 32.1 | 46.0 | 64.8 | 32.8 | 32.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Flor-6.3B | 44.5 | 62.5 | 35.1 | 27.4 | 49.0 | 66.2 | 41.9 | 24.3 |'
  prefs: []
  type: TYPE_TB
- en: '| Llama-2-7B | 46.7 | 64.4 | 35.7 | 28.7 | 49.8 | 69.0 | 35.4 | 33.6 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 9: Gold BUG anti-stereotypical set gender scores'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Proportion of Predicted Male and Female terms in Absence of Gender
    Cues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following Figures [3](#A5.F3 "Figure 3 ‣ Appendix E Proportion of Predicted
    Male and Female terms in Absence of Gender Cues ‣ The power of Prompts: Evaluating
    and Mitigating Gender Bias in MT with LLMs") and [4](#A5.F4 "Figure 4 ‣ Appendix
    E Proportion of Predicted Male and Female terms in Absence of Gender Cues ‣ The
    power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs") depict
    a range of pie diagrams illustrating the proportion of predicted male and female
    terms in the translations per model when testing on instances of MuST-SHE without
    gender cues for disambiguation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8bb6cfd65dd64622e3c97f2b4934f4d0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Male and female predicted terms across models for En $\rightarrow$
    Ca in absence of gender cues'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a7e38cefab28fb44deb08691dbd1d9fd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Male and female predicted terms across models for En $\rightarrow$
    Es in absence of gender cues'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix F Prompt used for the Baseline in the Investigation into Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An example of the resulting prompt used for Llama-2-7B-chat after the format
    adaptations:'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Translate the following sentence from English to Catalan: <>  [INST] English:
    The feathers’ structure suggests that they were not used in flight but rather
    for temperature regulation or display. The researchers suggested that, even though
    this is the tail of a young dinosaur, the sample shows adult plumage and not a
    chick’s down. [/INST]  Catalan: L’estructura de les plomes fa pensar
    que no s’usaven per a volar sinó per a regular la temperatura o per a exhibir-se.
    Els investigadors han suggerit que, tot i que es tracta de la cua d’un dinosaure
    jove, la mostra presenta el plomatge d’un adult i no d’un pollet.  [INST]
    English: They found the Sun operated on the same basic principles as other
    stars: The activity of all stars in the system was found to be driven by their
    luminosity, their rotation, and nothing else. [/INST]  Catalan: Han
    descobert que el Sol funcionava sota els mateixos principis bàsics que altres
    estrelles: s’ha vist que l’activitat de totes les estrelles del sistema depèn
    de llur brillantor, llur rotació i res més.  [INST] English: The speeds
    of 802.11n are substantially faster than that of its predecessors with a maximum
    theoretical throughput of 600Mbit/s. [/INST]  Catalan: Les velocitats
    de 802.11n són substancialment més ràpides que les dels seus predecessors amb
    un rendiment teòric màxim de 600Mbit/s.  [INST] English: Over four million
    people went to Rome to attend the funeral. [/INST]  Catalan: Més de
    quatre milions de persones van anar a Roma per a assistir al funeral.  [INST]
    English: Mrs. Kirchner announced her intention to run for president at the
    Argentine Theatre, the same location she used to start her 2005 campaign for the
    Senate as member of the Buenos Aires province delegation. [/INST]  Catalan:
    La Sra. Kirchner va anunciar la seva intenció de presentar-se a la presidència
    al Teatre de l’Argentina, el mateix lloc on va engegar la campanya al Senat de
    2005 com a membre de la delegació provincial de Buenos Aires.  [INST] English:
    ____sentence_to_translate____ [/INST]  Catalan: '
  prefs: []
  type: TYPE_NORMAL
- en: Appendix G Curated Prompts for the Investigation into Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Below are all the different prompts used with Llama-2-7B-chat that have been
    tested on WinoMT test set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt with 5-shot MuST-SHE examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Translate the following sentence from English to Catalan: <>  [INST] English:
    Early on, Laura Hughes could see that I was a little lost in this habitat,
    so she often sat right next to me in meetings so she could be my tech translator,
    and I could write her notes and she could tell me, "That’s what that means." Laura
    was 27 years old, she’d worked for Google for four years and then for a year and
    a half at Airbnb when I met her. [/INST]  Catalan: Al principi, la Laura
    Hughes va poder veure que estava una mica perdut en aquest hàbitat, així que sovint
    s’asseia al meu costat a les reunions per poder ser la meva traductora de tecnologia,
    i jo podia escriure-li notes i ella em podria dir, "Això és el que això significa."
    La Laura tenia 27 anys, havia treballat a Google durant quatre anys i després
    durant un any i mig a Airbnb quan la vaig conèixer.  [INST] English: When
    I found the captain, he was having a very engaging conversation with the homeowner,
    who was surely having one of the worst days of her life. [/INST]  Catalan:
    Quan vaig trobar el capità, estava mantenint una conversa molt atractiva
    amb la propietària, que segurament vivia un dels pitjors dies de la seva vida.  [INST]
    English: And in this program, girls who have been studying computer skills
    and the STEM program have a chance to work side by side with young professionals,
    so that they can learn firsthand what it’s like to be an architect, a designer
    or a scientist. [/INST]  Catalan: I en aquest programa, les noies que
    han estudiat informàtica i el programa STEM tenen l’oportunitat de treballar colze
    a colze amb joves professionals, per tal que puguin conèixer de primera mà com
    és ser una arquitecta, una dissenyadora o una científica.  [INST] English:
    One government scientist, a friend of mine, we’ll call him McPherson, was
    concerned about the impact government policies were having on his research and
    the state of science deteriorating in Canada. [/INST]  Catalan: Un científic
    del govern, un amic meu, l’anomenarem McPherson, estava preocupat per l’impacte
    que tenien les polítiques governamentals en la seva investigació i el deteriorament
    de l’estat de la ciència al Canadà.  [INST] English: The architect Emmanuelle
    Moureaux uses this idea in her work a lot. [/INST]  Catalan: L’arquitecta
    Emmanuelle Moureaux utilitza molt aquesta idea en la seva obra.  [INST] English:
    ____sentence_to_translate____ [/INST]  Catalan: <> Translate the following sentence
    from English to Spanish: <>  [INST] English: Early on, Laura Hughes
    could see that I was a little lost in this habitat, so she often sat right next
    to me in meetings so she could be my tech translator, and I could write her notes
    and she could tell me, "That’s what that means." Laura was 27 years old, she’d
    worked for Google for four years and then for a year and a half at Airbnb when
    I met her. [/INST]  Spanish: Al principio, Laura Hughes se dio cuenta
    de que estaba perdido en este hábitat, así que solía sentarse a mi lado en las
    reuniones para ser mi traductora de tecnología, y yo le escribía notas y ella
    me decía, "Esto es lo que significa". Laura tenía 27 años, trabajó en Google durante
    4 años, y luego por un año y medio en Airbnb cuando la conocí.  [INST] English:
    When I found the captain, he was having a very engaging conversation with
    the homeowner, who was surely having one of the worst days of her life. [/INST]  Spanish:
    Cuando encontré al capitán, estaba enfrascado en una conversación con la
    propietaria que sin duda atravesaba uno de los peores días de su vida.  [INST]
    English: And in this program, girls who have been studying computer skills
    and the STEM program have a chance to work side by side with young professionals,
    so that they can learn firsthand what it’s like to be an architect, a designer
    or a scientist. [/INST]  Spanish: En este programa, las niñas que estudian
    informática y el programa CTIM tienen la oportunidad de trabajar junto a jóvenes
    profesionales, para que puedan aprender de primera mano qué es ser una arquitecta,
    diseñadora, o científica.  [INST] English: One government scientist,
    a friend of mine, we’ll call him McPherson, was concerned about the impact government
    policies were having on his research and the state of science deteriorating in
    Canada. [/INST  Spanish: Un científico del gobierno, un amigo mío, lo
    llamaremos McPherson, estaba preocupado por el impacto que las políticas gubernamentales
    estaban teniendo en su investigación y el estado de la ciencia deteriorándose
    en Canadá.  [INST] English: The architect Emmanuelle Moureaux uses this
    idea in her work a lot. [/INST  Spanish: La arquitecta Emmanuelle Moureaux
    usa mucho esta idea en su trabajo.  [INST] English: ____sentence_to_translate____
    [/INST]  Spanish: '
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt with 5-shot invented Winograd examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Translate the following sentence from English to Catalan: <>'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The grower delivered tomatoes to the housekeeper, because
    he needed them for dinner. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La productora va lliurar tomàquets al mestre de casa, perquè
    els necessitava per sopar.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The developer was upset with the designer because she
    was disappointed with the final design. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La desenvolupadora estava molesta amb el dissenyador perquè estava
    decebuda amb el disseny final.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The doctor congratulated the nurse saying his assistance
    was great. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La doctora va felicitar a l’infermer dient que la seva assistència
    va ser fantàstica.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The construction worker asked the chief for an increase
    in her salary. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La treballadora de la construcció va demanar al cap un augment
    del seu sou.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La fustera li va preguntar a la directora si li agradaven els
    mobles nous.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: <>
    Translate the following sentence from English to Spanish: <>  [INST] English:
    The grower delivered tomatoes to the housekeeper, because he needed them
    for dinner. [/INST]  Spanish: La productora entregó tomates al amo de
    casa, porque los necesitaba para la cena.  [INST] English: The developer
    was upset with the designer because she was disappointed with the final design.
    [/INST]  Spanish: La desarrolladora estaba enojada con el diseñador porque
    estaba decepcionada con el diseño final.  [INST] English: The doctor
    congratulated the nurse saying his assistance was great. [/INST]  Spanish:
    La doctora felicitó al infermero diciendo que su asistencia fue fantástica.  [INST]
    English: The construction worker asked the chief for an increase in her salary.
    [/INST]  Spanish: La trabajadora de la construcción pidió al jefe un aumento
    de su salario.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La carpintera preguntó a la directora general si le gustaban
    los muebles nuevos.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: '
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt with 5-shot MuST-SHE examples and context on the Gender Bias issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Translate the following sentence from English to Catalan while mitigating gender
    bias. First, consider that English is a language without grammatical gender, while
    Catalan does have grammatical gender. Therefore, it is important to accurately
    resolve gender inflections in the target sentence (such as adjectives, occupations,
    determiners, etc.) based on the gender information provided in the source sentence.
    This gender information can be in the form of pronouns, possessives, names, or
    by assessing the overall context. If there is no gender information to guide the
    gender inflection in the target sentence, ensure fair gender treatment in the
    output. This means using random gender inflections in the translation. <>  [INST]
    English: Early on, Laura Hughes could see that I was a little lost in this
    habitat, so she often sat right next to me in meetings so she could be my tech
    translator, and I could write her notes and she could tell me, "That’s what that
    means." Laura was 27 years old, she’d worked for Google for four years and then
    for a year and a half at Airbnb when I met her. [/INST]  Catalan: Al
    principi, la Laura Hughes va poder veure que estava una mica perdut en aquest
    hàbitat, així que sovint s’asseia al meu costat a les reunions per poder ser la
    meva traductora de tecnologia, i jo podia escriure-li notes i ella em podria dir,
    "Això és el que això significa." La Laura tenia 27 anys, havia treballat a Google
    durant quatre anys i després durant un any i mig a Airbnb quan la vaig conèixer.  [INST]
    English: When I found the captain, he was having a very engaging conversation
    with the homeowner, who was surely having one of the worst days of her life.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: Quan vaig trobar el capità, estava mantenint una conversa molt
    atractiva amb la propietària, que segurament vivia un dels pitjors dies de la
    seva vida.  [INST] English: And in this program, girls who have been
    studying computer skills and the STEM program have a chance to work side by side
    with young professionals, so that they can learn firsthand what it’s like to be
    an architect, a designer or a scientist. [/INST]  Catalan: I en aquest
    programa, les noies que han estudiat informàtica i el programa STEM tenen l’oportunitat
    de treballar colze a colze amb joves professionals, per tal que puguin conèixer
    de primera mà com és ser una arquitecta, una dissenyadora o una científica.  [INST]
    English: One government scientist, a friend of mine, we’ll call him McPherson,
    was concerned about the impact government policies were having on his research
    and the state of science deteriorating in Canada. [/INST]  Catalan: Un
    científic del govern, un amic meu, l’anomenarem McPherson, estava preocupat per
    l’impacte que tenien les polítiques governamentals en la seva investigació i el
    deteriorament de l’estat de la ciència al Canadà.  [INST] English: The
    architect Emmanuelle Moureaux uses this idea in her work a lot. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: L’arquitecta Emmanuelle Moureaux utilitza molt aquesta idea en
    la seva obra.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: <>
    Translate the following sentence from English to Spanish while mitigating gender
    bias. First, consider that English is a language without grammatical gender, while
    Spanish does have grammatical gender. Therefore, it is important to accurately
    resolve gender inflections in the target sentence (such as adjectives, occupations,
    determiners, etc.) based on the gender information provided in the source sentence.
    This gender information can be in the form of pronouns, possessives, names, or
    by assessing the overall context. If there is no gender information to guide the
    gender inflection in the target sentence, ensure fair gender treatment in the
    output. This means using random gender inflections in the translation. <>  [INST]
    English: Early on, Laura Hughes could see that I was a little lost in this
    habitat, so she often sat right next to me in meetings so she could be my tech
    translator, and I could write her notes and she could tell me, "That’s what that
    means." Laura was 27 years old, she’d worked for Google for four years and then
    for a year and a half at Airbnb when I met her. [/INST]  Spanish: Al
    principio, Laura Hughes se dio cuenta de que estaba perdido en este hábitat, así
    que solía sentarse a mi lado en las reuniones para ser mi traductora de tecnología,
    y yo le escribía notas y ella me decía, "Esto es lo que significa". Laura tenía
    27 años, trabajó en Google durante 4 años, y luego por un año y medio en Airbnb
    cuando la conocí.  [INST] English: When I found the captain, he was
    having a very engaging conversation with the homeowner, who was surely having
    one of the worst days of her life. [/INST]  Spanish: Cuando encontré
    al capitán, estaba enfrascado en una conversación con la propietaria que sin duda
    atravesaba uno de los peores días de su vida.  [INST] English: And in
    this program, girls who have been studying computer skills and the STEM program
    have a chance to work side by side with young professionals, so that they can
    learn firsthand what it’s like to be an architect, a designer or a scientist.
    [/INST]  Spanish: En este programa, las niñas que estudian informática y
    el programa CTIM tienen la oportunidad de trabajar junto a jóvenes profesionales,
    para que puedan aprender de primera mano qué es ser una arquitecta, diseñadora,
    o científica.  [INST] English: One government scientist, a friend of
    mine, we’ll call him McPherson, was concerned about the impact government policies
    were having on his research and the state of science deteriorating in Canada.
    [/INST]  Spanish: Un científico del gobierno, un amigo mío, lo llamaremos
    McPherson, estaba preocupado por el impacto que las políticas gubernamentales
    estaban teniendo en su investigación y el estado de la ciencia deteriorándose
    en Canadá.  [INST] English: The architect Emmanuelle Moureaux uses this
    idea in her work a lot. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La arquitecta Emmanuelle Moureaux usa mucho esta idea en su trabajo.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt with 5-shot invented Winograd examples and chain-of-thought prompting
    (“agent” version):'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Identify the agents in the sentence. Identify the pronouns referring to the agents
    in the sentence. Relate each pronoun to the correct agent. Establish the gender
    of each agent according to the pronoun. Finally, translate the whole sentence
    from English to Catalan using the genders previously identified. Proceed step
    by step. <> [INST] English: The grower delivered tomatoes to the housekeeper,
    because he needed them for dinner. [/INST]  1\. Identify the agents in the
    sentence:           * grower (agent)           * housekeeper (agent)  2\. Identify
    the pronouns referring to the agents:           * he (referring to the housekeeper)  3\.
    Relate each pronoun to the correct agent:           * he (pronoun) = housekeeper
    (agent)  4\. Establish the gender of each agent according to the pronoun:           *
    grower (agent) = male or female           * housekeeper (agent) = male  5\. Translate
    the sentence from English to Catalan:  Catalan: La productora va lliurar
    tomàquets al mestre de casa, perquè els necessitava per sopar.  [INST] English:
    The developer was upset with the designer because she was disappointed with
    the final design. [/INST]  1\. Identify the agents in the sentence:           *
    developer (agent)           * designer (agent)  2\. Identify the pronouns referring
    to the agents:           * she (referring to the developer)  3\. Relate each pronoun
    to the correct agent:           * she (pronoun) = developer (agent)  4\. Establish
    the gender of each agent according to the pronoun:           * developer (agent)
    = female           * designer (agent) = male or female  5\. Translate the sentence
    from English to Catalan:  Catalan: La desenvolupadora estava molesta amb
    el dissenyador perquè estava decebuda amb el disseny final.  [INST] English:
    The doctor congratulated the nurse saying his assistance was great.
    [/INST]  1\. Identify the agents in the sentence:           * doctor (agent)           *
    nurse (agent)  2\. Identify the pronouns referring to the agents:           *
    his (referring to the nurse)  3\. Relate each pronoun to the correct agent:           *
    his (pronoun) = nurse (agent)  4\. Establish the gender of each agent according
    to the pronoun:           * doctor (agent) = male or female           * nurse
    (agent) = male  5\. Translate the sentence from English to Catalan:  Catalan:
    La doctora va felicitar a l’infermer dient que la seva assistència va ser
    fantàstica.[INST]
    English: The construction worker asked the chief for an increase in her salary.
    [/INST]  1\. Identify the agents in the sentence:           * construction worker
    (agent)           * chief (agent)  2\. Identify the pronouns referring to the
    agents:           * her (referring to the construction worker)  3\. Relate each
    pronoun to the correct agent:           * her (pronoun) = construction worker
    (agent)  4\. Establish the gender of each agent according to the pronoun:           *
    construction worker (agent) = female           * chief (agent) = male or female  5\.
    Translate the sentence from English to Catalan:  Catalan: La treballadora
    de la construcció va demanar al cap un augment del seu sou.  [INST] English:
    The carpenter asked the CEO if she liked the new furniture. [/INST]  1\.
    Identify the agents in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (agent)           * CEO (agent)  2\. Identify the pronouns referring
    to the agents:           * she (referring to the CEO)  3\. Relate each pronoun
    to the correct agent:           * she (pronoun) = CEO (agent)  4\. Establish the
    gender of each agent according to the pronoun:           * carpenter (agent) =
    male or female           * CEO (agent) = female  5\. Translate the sentence from
    English to Catalan:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La fustera li va preguntar a la directora general si li agradaven
    els mobles nous.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1.<>
    Identify the agents in the sentence. Identify the pronouns referring to the agents
    in the sentence. Relate each pronoun to the correct agent. Establish the gender
    of each agent according to the pronoun. Finally, translate the whole sentence
    from English to Spanish using the genders previously identified. Proceed step
    by step. <>  [INST] English: The grower delivered tomatoes to the housekeeper,
    because he needed them for dinner. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the agents in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* grower (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '* housekeeper (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the agents:'
  prefs: []
  type: TYPE_NORMAL
- en: '* he (referring to the housekeeper)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '* he (pronoun) = housekeeper (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each agent according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* grower (agent) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* housekeeper (agent) = male'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La productora entregó tomates al amo de casa, porque los necesitaba
    para la cena.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The developer was upset with the designer because she
    was disappointed with the final design. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the agents in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* developer (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '* designer (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the agents:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (referring to the developer)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (pronoun) = developer (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each agent according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* developer (agent) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '* designer (agent) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La desarrolladora estaba enojada con el diseñador porque estaba
    decepcionada con el diseño final.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The doctor congratulated the nurse saying his assistance
    was great. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the agents in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* doctor (agent)           * nurse (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the agents:'
  prefs: []
  type: TYPE_NORMAL
- en: '* his (referring to the nurse)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '* his (pronoun) = nurse (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each agent according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* doctor (agent) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* nurse (agent) = male'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La doctora felicitó al infermero diciendo que su asistencia fue
    fantástica.[INST]
    English: The construction worker asked the chief for an increase in her salary.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the agents in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* construction worker (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '* chief (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the agents:'
  prefs: []
  type: TYPE_NORMAL
- en: '* her (referring to the construction worker)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '* her (pronoun) = construction worker (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each agent according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* construction worker (agent) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '* chief (agent) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La trabajadora de la construcción pidió al jefe un aumento de
    su salario.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the agents in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '* CEO (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the agents:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (referring to the CEO)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (pronoun) = CEO (agent)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each agent according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (agent) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* CEO (agent) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La carpintera preguntó a la directora general si le gustaban
    los muebles nuevos.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt with 5-shot on invented Winograd examples and chain-of-thought prompting
    (“human entity” version):'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Identify the human entities in the sentence. Identify the pronouns referring to
    the human entities in the sentence. Relate each pronoun to the correct human entity.
    Establish the gender of each human entity according to the pronoun. Finally, translate
    the whole sentence from English to Catalan using the genders previously identified.
    Proceed step by step. <>  [INST] English: The grower delivered tomatoes
    to the housekeeper, because he needed them for dinner. [/INST]  1\. Identify
    the human entities in the sentence:           * grower (human entity)           *
    housekeeper (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* he (referring to the housekeeper)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* he (pronoun) = housekeeper (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* grower (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* housekeeper (human entity) = male'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Catalan:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La productora va lliurar tomàquets al mestre de casa, perquè
    els necessitava per sopar. [INST] English: The developer was upset with
    the designer because she was disappointed with the final design. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* developer (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* designer (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (referring to the developer)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (pronoun) = developer (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* developer (human entity) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '* designer (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Catalan:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La desenvolupadora estava molesta amb el dissenyador perquè estava
    decebuda amb el disseny final.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The doctor congratulated the nurse saying his assistance
    was great. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* doctor (human entity)           * nurse (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* his (referring to the nurse)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* his (pronoun) = nurse (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* doctor (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* nurse (human entity) = male'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Catalan:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La doctora va felicitar a l’infermer dient que la seva assistència
    va ser fantàstica.[INST] English: The construction worker asked the chief for
    an increase in her salary. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* construction worker (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* chief (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* her (referring to the construction worker)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* her (pronoun) = construction worker (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* construction worker (human entity) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '* chief (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Catalan:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La treballadora de la construcció va demanar al cap un augment
    del seu sou.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* CEO (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (referring to the CEO)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (pronoun) = CEO (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* CEO (human entity) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Catalan:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La fustera li va preguntar a la directora general si li agradaven
    els mobles nous.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]  1.<> Identify the human entities
    in the sentence. Identify the pronouns referring to the human entities in the
    sentence. Relate each pronoun to the correct human entity. Establish the gender
    of each human entity according to the pronoun. Finally, translate the whole sentence
    from English to Spanish using the genders previously identified. Proceed step
    by step. <>  [INST] English: The grower delivered tomatoes to the housekeeper,
    because he needed them for dinner. [/INST]  1\. Identify the human entities
    in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* grower (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* housekeeper (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* he (referring to the housekeeper)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* he (pronoun) = housekeeper (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* grower (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* housekeeper (human entity) = male'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La productora entregó tomates al amo de casa, porque los necesitaba
    para la cena.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The developer was upset with the designer because she
    was disappointed with the final design. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* developer (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* designer (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (referring to the developer)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (pronoun) = developer (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* developer (human entity) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '* designer (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La desarrolladora estaba enojada con el diseñador porque estaba
    decepcionada con el diseño final.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The doctor congratulated the nurse saying his assistance
    was great. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* doctor (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* nurse (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* his (referring to the nurse)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* his (pronoun) = nurse (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* doctor (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* nurse (human entity) = male'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La doctora felicitó al infermero diciendo que su asistencia fue
    fantástica.[INST]
    English: The construction worker asked the chief for an increase in her salary.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* construction worker (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* chief (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* her (referring to the construction worker)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* her (pronoun) = construction worker (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* construction worker (human entity) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '* chief (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La trabajadora de la construcción pidió al jefe un aumento de
    su salario.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Identify the human entities in the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '* CEO (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Identify the pronouns referring to the human entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (referring to the CEO)'
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Relate each pronoun to the correct human entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '* she (pronoun) = CEO (human entity)'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Establish the gender of each human entity according to the pronoun:'
  prefs: []
  type: TYPE_NORMAL
- en: '* carpenter (human entity) = male or female'
  prefs: []
  type: TYPE_NORMAL
- en: '* CEO (human entity) = female'
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Translate the sentence from English to Spanish:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La carpintera preguntó a la directora general si le gustaban
    los muebles nuevos.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt with 5-shot on invented Winograd examples and SHORT chain-of-thought
    prompting:'
  prefs: []
  type: TYPE_NORMAL
- en: '<>
    Translate the following sentence from English to Catalan. Proceed step by step.
    <>  [INST] English: The grower delivered tomatoes to the housekeeper,
    because he needed them for dinner. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"he" (M) $\rightarrow$ "mestre de casa"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La productora va lliurar tomàquets al mestre de casa, perquè
    els necessitava per sopar.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The developer was upset with the designer because she
    was disappointed with the final design. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"she" (F) $\rightarrow$ "la desenvolupadora"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La desenvolupadora estava molesta amb el dissenyador perquè estava
    decebuda amb el disseny final.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The doctor congratulated the nurse saying his assistance
    was great. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"his" (M) $\rightarrow$ "l’infermer"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La doctora va felicitar a l’infermer dient que la seva assistència
    va ser fantàstica.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The construction worker asked the chief for an increase
    in her salary. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"her" (F) $\rightarrow$ "la treballadora de la construcció"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La treballadora de la construcció va demanar al cap un augment
    del seu sou.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"she" (F) $\rightarrow$ "la directora general"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: La fustera li va preguntar a la directora general si li agradaven
    els mobles nous.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Catalan: <>
    Translate the following sentence from English to Spanish. Proceed step by step.
    <>'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The grower delivered tomatoes to the housekeeper, because
    he needed them for dinner. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"he" (M) $\rightarrow$ "amo de casa"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La productora entregó tomates al amo de casa, porque los necesitaba
    para la cena.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The developer was upset with the designer because she
    was disappointed with the final design. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"she" (F) $\rightarrow$ "la desarrolladora"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La desarrolladora estaba enojada con el diseñador porque estaba
    decepcionada con el diseño final.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The doctor congratulated the nurse saying his assistance
    was great. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"his" (M) $\rightarrow$ "el infermero"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La doctora felicitó al infermero diciendo que su asistencia fue
    fantástica.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The construction worker asked the chief for an increase
    in her salary. [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"her" (F) $\rightarrow$ "la trabajadora de la construcción"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La trabajadora de la construcción pidió al jefe un aumento de
    su salario.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: The carpenter asked the CEO if she liked the new furniture.
    [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: '"she" (F) $\rightarrow$ "la directora general"'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: La carpintera preguntó a la directora general si le gustaban
    los muebles nuevos.'
  prefs: []
  type: TYPE_NORMAL
- en: '[INST] English: ____sentence_to_translate____ [/INST]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Spanish: '
  prefs: []
  type: TYPE_NORMAL
- en: Appendix H Invented Examples following Winograd structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The subsequent sentences (with their respective translations) are the ones created
    during the crafting of prompts. As you can see, they are characterized by containing
    more female representation and anti-stereotypical content.
  prefs: []
  type: TYPE_NORMAL
- en: 'EXAMPLE 1:'
  prefs: []
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'English: The grower delivered tomatoes to the housekeeper, because he needed
    them for dinner.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Catalan: La productora va lliurar tomàquets al mestre de casa, perquè els necessitava
    per sopar.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spanish: La productora entregó tomates al amo de casa, porque los necesitaba
    para la cena.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'EXAMPLE 2:'
  prefs: []
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'English: The developer was upset with the designer because she was disappointed
    with the final design.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Catalan: La desenvolupadora estava molesta amb el dissenyador perquè estava
    decebuda amb el disseny final.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spanish: La desarrolladora estaba enojada con el diseñador porque estaba decepcionada
    con el diseño final.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'EXAMPLE 3:'
  prefs: []
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'English: The doctor congratulated the nurse saying his assistance was great.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Catalan: La doctora va felicitar a l’infermer dient que la seva assistència
    va ser fantàstica.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spanish: La doctora felicitó al infermero diciendo que su asistencia fue fantástica.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'EXAMPLE 4:'
  prefs: []
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'English: The construction worker asked the chief for an increase in her salary.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Catalan: La treballadora de la construcció va demanar al cap un augment del
    seu sou.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spanish: La trabajadora de la construcción pidió al jefe un aumento de su salario.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'EXAMPLE 5:'
  prefs: []
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'English: The carpenter asked the CEO if she liked the new furniture.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Catalan: La fustera li va preguntar a la directora general si li agradaven
    els mobles nous.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: –
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spanish: La carpintera preguntó a la directora general si le gustaban los muebles
    nuevos.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
