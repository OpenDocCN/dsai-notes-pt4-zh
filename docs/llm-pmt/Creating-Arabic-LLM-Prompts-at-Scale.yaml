- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-08 18:41:01'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:41:01'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Creating Arabic LLM Prompts at Scale
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模创建阿拉伯语 LLM 提示
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.05882](https://ar5iv.labs.arxiv.org/html/2408.05882)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.05882](https://ar5iv.labs.arxiv.org/html/2408.05882)
- en: Abstract
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The debut of chatGPT and BARD has popularized instruction following text generation
    using LLMs, where a user can interrogate an LLM using natural language requests
    and obtain natural language answers that matches their requests. Training LLMs
    to respond in this manner requires a large number of worked out examples of user
    requests (aka prompts) with corresponding gold responses. In this paper, we introduce
    two methods for creating such prompts for Arabic cheaply and quickly. The first
    methods entails automatically translating existing prompt datasets from English,
    such as PromptSource and Super-NaturalInstructions, and then using machine translation
    quality estimation to retain high quality translations only. The second method
    involves creating natural language prompts on top of existing Arabic NLP datasets.
    Using these two methods we were able to create more than 67.4 million Arabic prompts
    that cover a variety of tasks including summarization, headline generation, grammar
    checking, open/closed question answering, creative writing, etc. We show that
    fine tuning an open 7 billion parameter large language model, namely base Qwen2
    7B, enables it to outperform a state-of-the-art 70 billion parameter instruction
    tuned model, namely Llama3 70B, in handling Arabic prompts.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: chatGPT 和 BARD 的问世使得使用 LLM 进行指令跟随的文本生成变得流行，用户可以使用自然语言请求对 LLM 进行询问，并获得符合其请求的自然语言回答。训练
    LLM 以这种方式响应，需要大量的用户请求（即提示）及其对应的正确答案。在本文中，我们介绍了两种便宜而快速创建阿拉伯语提示的方法。第一种方法是自动翻译现有的英文提示数据集，如
    PromptSource 和 Super-NaturalInstructions，然后使用机器翻译质量评估仅保留高质量翻译。第二种方法是在现有阿拉伯语 NLP
    数据集的基础上创建自然语言提示。通过这两种方法，我们能够创建超过 6740 万个阿拉伯语提示，涵盖了各种任务，包括摘要、标题生成、语法检查、开放/封闭式问答、创意写作等。我们展示了对一个
    70 亿参数的开放大型语言模型，即基础 Qwen2 7B 进行微调，可以使其在处理阿拉伯语提示时超过一个最先进的 70 亿参数指令调优模型，即 Llama3
    70B。
- en: Keywords: LLM fine tuning, Arabic, Prompt engineering
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词: LLM 微调，阿拉伯语，提示工程
- en: \setcode
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: \setcode
- en: utf8 \NAT@set@cites
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: utf8 \NAT@set@cites
- en: Creating Arabic LLM Prompts at Scale
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模创建阿拉伯语 LLM 提示
- en: '| Abdelrahman El-Sheikh, Ahmed Elmogtaba, Kareem Darwish, |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| Abdelrahman El-Sheikh, Ahmed Elmogtaba, Kareem Darwish, |'
- en: '| Muhammad Elmallah, Ashraf Elneima, Hassan Sawaf |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| Muhammad Elmallah, Ashraf Elneima, Hassan Sawaf |'
- en: '| aiXplain Inc. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| aiXplain Inc. |'
- en: '| San Jose, CA, USA |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 圣荷西，加利福尼亚，美国 |'
- en: '| {abdelrahman.el-sheikh,ahmed.abdelaziz,kareem.darwish, |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| {abdelrahman.el-sheikh,ahmed.abdelaziz,kareem.darwish, |'
- en: '| muhammad.elmallah,ashraf.hatim,Hassan}@aiXplain.com |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| muhammad.elmallah,ashraf.hatim,Hassan}@aiXplain.com |'
- en: Abstract content
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要内容
- en: 1.   Introduction
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.   引言
- en: The debut of instruction-following Large Language Models (LLMs), such as chatGPT
    and BARD, showed that LLMs are capable of performing a variety of natural language
    tasks in response to user prompts. For example, a user may ask to summarize or
    extract specific information from a piece of text and an LLM would respond with
    the requested information.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 像 chatGPT 和 BARD 这样的指令跟随大型语言模型（LLMs）的问世，展示了 LLMs 能够根据用户提示执行各种自然语言任务。例如，用户可以要求总结或提取一段文本中的特定信息，LLM
    会提供所请求的信息。
- en: Tuning LLMs to behave in such manner requires using a large number of worked
    out examples of user requests (aka prompts) with corresponding correct gold responses.
    Many efforts have focused on creating such prompts in English resulting in datasets
    such PromptSource Bach et al. ([2022](#bib.bib1)), Super-NaturalInstuctions Wang
    et al. ([2022](#bib.bib10)); Mishra et al. ([2022](#bib.bib6)), FLAN Wei et al.
    ([2021](#bib.bib11)), Dolly v2 Conover et al. ([2023](#bib.bib2)), and others.
    Such efforts have resulted in the creation of tens of millions of prompts that
    cover a plethora of different tasks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 调整 LLMs 使其以这种方式进行操作，需要使用大量的用户请求（即提示）及其对应的正确答案。许多工作集中在创建这样的提示上，结果形成了如 PromptSource
    Bach 等 ([2022](#bib.bib1))、Super-NaturalInstructions Wang 等 ([2022](#bib.bib10))、Mishra
    等 ([2022](#bib.bib6))、FLAN Wei 等 ([2021](#bib.bib11))、Dolly v2 Conover 等 ([2023](#bib.bib2))
    等数据集。这些工作导致创建了数千万个提示，涵盖了各种不同的任务。
- en: In this paper, we focus on creating high quality prompts at scale for Arabic,
    where work on prompt generation has been very limited. We focus on two different
    methods for prompt creation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们专注于大规模创建高质量阿拉伯语提示，而在提示生成方面的工作非常有限。我们关注于两种不同的提示创建方法。
- en: The first method follows in the footsteps of PromptSource, where we created
    prompts for 76 existing Arabic Natural Language Processing (NLP) datasets using
    the PromptSource sourcing tool. The datasets include a variety of different tasks
    such as question answering, summarization, dialect identification, hate speech
    detection, diacritic recovery, grammar checking, and many more. Using this method,
    we generated more than 67.4 million prompts.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法沿用了 PromptSource 的方法，我们使用 PromptSource 来源工具为 76 个现有的阿拉伯语自然语言处理 (NLP) 数据集创建了提示。这些数据集包括问答、摘要、方言识别、仇恨言论检测、附加符号恢复、语法检查等多种不同任务。通过这种方法，我们生成了超过
    6740 万个提示。
- en: The second method involves translating existing English prompt datasets with
    automated translation quality estimation and manual verification. Specifically,
    we translate both PromptSource and Super-NaturalInstructions, and we use state-of-the-art
    referenceless machine translation quality estimation Rei et al. ([2023](#bib.bib7))
    to retain only prompts where all the sentences that make up the prompt have a
    minimum quality score. To ensure high quality prompts, we set a high minimum quality
    score, resulting in retaining roughly 20% of the original prompts. Further, we
    perform manual verification and correction of translated prompts and manually
    inspect samples from each dataset to identify systematic translation errors. Using
    this method, we created roughly 20 million prompts. Both these methods can be
    applied to other languages.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法涉及使用自动翻译质量评估和人工验证来翻译现有的英文提示数据集。具体来说，我们翻译了 PromptSource 和 Super-NaturalInstructions，并利用最先进的无参考机器翻译质量评估方法
    Rei 等人 ([2023](#bib.bib7))，只保留那些所有句子质量评分达到最低要求的提示。为了确保提示的高质量，我们设置了较高的最低质量评分，从而保留了大约
    20% 的原始提示。此外，我们对翻译的提示进行人工验证和修正，并手动检查每个数据集中的样本，以识别系统性翻译错误。通过这种方法，我们创建了大约 2000 万个提示。这些方法也可以应用于其他语言。
- en: We split the newly created prompts into train, validation, and test splits for
    all our datasets. We use the test splits to score multiple existing LLMs. Further,
    we fine tune a strong LLM, namely Qwen2 7B, using roughly 10% and 1% of our newly
    created prompt datasets. We show that the fine tuned model outperforms much larger
    models, such as Llama3-Instruct 70B. Our testing mainly focuses on the ability
    of LLM to follow instructions in performing a variety of tasks as opposed to measuring
    their knowledge, which would typically be measured using standard test sets such
    as MMLU and Hellaswag.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将新创建的提示分为训练集、验证集和测试集用于所有数据集。我们使用测试集对多个现有的 LLM 进行评分。此外，我们使用大约 10% 和 1% 的新创建提示数据集对强大的
    LLM（即 Qwen2 7B）进行微调。我们展示了微调后的模型在性能上超越了更大的模型，如 Llama3-Instruct 70B。我们的测试主要集中在 LLM
    执行各种任务的指令跟随能力上，而不是测量它们的知识，这通常通过使用标准测试集如 MMLU 和 Hellaswag 来进行测量。
- en: 'The contribution of this paper is as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的贡献如下：
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We create more than 87 million prompts for Arabic based on hundreds of datasets
    that cover 67 different tasks.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们基于覆盖 67 种不同任务的数百个数据集，为阿拉伯语创建了超过 8700 万个提示。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show that we can create high quality prompts using translation and translation
    quality estimation paired with manual verification.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了使用翻译和翻译质量评估结合人工验证可以创建高质量提示。
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show that fine tuning an LLM using the new data significantly improves LLM
    performance on a variety of tasks.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了使用新数据微调 LLM 可以显著提高 LLM 在各种任务上的表现。
- en: 2.   Prompt Creation
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.   提示创建
- en: 2.1.   Creating Prompts Using Existing Datasets
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.   使用现有数据集创建提示
- en: We created natural language prompts for 78 publicly available Arabic datasets
    using the PromptSource sourcing tool. The PromptSource UI facilitates a user-friendly
    interface for the creation of prompt templates, providing the ability to specify
    the insertion points of inputs within the prompts and to provide potential answers.
    For each task we developed 2-8 different prompt templates. The time required for
    creating the prompt templates was typically 30-90 minutes. Figure [1](#S2.F1 "Figure
    1 ‣ 2.1\. Creating Prompts Using Existing Datasets ‣ 2\. Prompt Creation ‣ Creating
    Arabic LLM Prompts at Scale") shows 4 different prompt templates that we developed
    for one of the datasets¹¹1[https://huggingface.co/datasets/Abdelkareem/arabic_tweets_classification](https://huggingface.co/datasets/Abdelkareem/arabic_tweets_classification).
    We were keen to diversify the order and language of the prompts. From 78 datasets,
    we generated 67,488,303 prompts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用PromptSource工具为78个公开的阿拉伯语数据集创建了自然语言提示。PromptSource用户界面提供了一个友好的界面，用于创建提示模板，能够指定提示中输入的插入点和提供潜在的答案。对于每个任务，我们开发了2-8种不同的提示模板。创建提示模板所需的时间通常为30-90分钟。图[1](#S2.F1
    "Figure 1 ‣ 2.1\. Creating Prompts Using Existing Datasets ‣ 2\. Prompt Creation
    ‣ Creating Arabic LLM Prompts at Scale")显示了我们为其中一个数据集¹¹1[https://huggingface.co/datasets/Abdelkareem/arabic_tweets_classification](https://huggingface.co/datasets/Abdelkareem/arabic_tweets_classification)开发的4种不同的提示模板。我们注重多样化提示的顺序和语言。从78个数据集中，我们生成了67,488,303个提示。
- en: '![Refer to caption](img/d5dffabcd8b1e43eb88a717e87667b7b.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d5dffabcd8b1e43eb88a717e87667b7b.png)'
- en: 'Figure 1: Example prompts for Abdelkareem/arabic_tweets_classification'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：Abdelkareem/arabic_tweets_classification 的示例提示
- en: 2.2.   Creating Prompts Using Translation
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. 使用翻译创建提示
- en: 'We developed a comprehensive data processing pipeline designed to perform the
    translation, evaluation, and filtering of English datasets into Arabic. The pipeline
    consists of a series of well-defined steps, summarized as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个全面的数据处理流程，旨在将英语数据集翻译、评估并过滤成阿拉伯语。该流程由一系列明确定义的步骤组成，概括如下：
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sentence Extraction: Initially, the pipeline splits the English prompts into
    sentences. We used the Python sentence-splitter library²²2[https://github.com/mediacloud/sentence-splitter](https://github.com/mediacloud/sentence-splitter),
    which is a re-implementation of the Moses sentence splitter³³3[https://www.statmt.org/europarl/](https://www.statmt.org/europarl/).
    These sentences serve as the source text for translation.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 句子提取：最初，流程将英语提示拆分为句子。我们使用了Python的句子拆分库²²2[https://github.com/mediacloud/sentence-splitter](https://github.com/mediacloud/sentence-splitter)，这是Moses句子拆分器的重新实现³³3[https://www.statmt.org/europarl/](https://www.statmt.org/europarl/)。这些句子作为翻译的源文本。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Machine Translation: Subsequently, we translated English sentences to Arabic
    using the opus-mt-ar-en Helsinki Machine Translation (MT) model Tiedemann and
    Thottingal ([2020](#bib.bib9)), which is a neural model based on Marian NMT⁴⁴4[https://marian-nmt.github.io](https://marian-nmt.github.io).
    We opted to use this model as opposed to commercial translation APIs to lower
    the overall cost.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器翻译：随后，我们使用opus-mt-ar-en赫尔辛基机器翻译（MT）模型Tiedemann和Thottingal（[2020](#bib.bib9)）将英语句子翻译成阿拉伯语，该模型基于Marian
    NMT⁴⁴4[https://marian-nmt.github.io](https://marian-nmt.github.io)的神经模型。我们选择使用该模型而非商业翻译API，以降低整体成本。
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Translation Evaluation: In the pursuit of ensuring translation quality, the
    pipeline incorporates the COMET-QE reference-free MT evaluation model Rei et al.
    ([2023](#bib.bib7)), which has been shown to correlate well with human judgments.
    COMET-QE calculates a quality score on a scale from 0 to 1, with 0 indicating
    the lowest translation quality and 1 signifying the highest quality.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 翻译评估：为确保翻译质量，流程中采用了COMET-QE无参考机器翻译评估模型Rei等人（[2023](#bib.bib7)），该模型与人工判断的相关性较好。COMET-QE计算0到1之间的质量得分，0表示最低翻译质量，1表示最高质量。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Threshold-Based Filtering: To enhance the reliability of the translated content,
    a specified threshold, namely 0.7, is applied. A translated prompt where one or
    more of its sentences do not meet this quality criterion are filtered out, ensuring
    that only high-quality translated prompts are retained for further utilization.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于阈值的过滤：为了提高翻译内容的可靠性，应用了指定的阈值，即0.7。如果翻译后的提示中一个或多个句子未达到这一质量标准，则会被过滤掉，确保只有高质量的翻译提示被保留以供进一步使用。
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Manual Translation Verification: We manually correct the translation of the
    instructions for datasets where the instructions were separable from the input.'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 手动翻译验证：我们手动纠正了指令的翻译，对于那些指令可以与输入分离的数据集。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Quality Assurance: We manually check a random sample from each dataset to determine
    the efficacy of translation. Performing this manual check helped us identify (and
    subsequently drop) datasets that are not amenable for translation such as those
    that require the identification of English specific grammatical phenomena. It
    also helped us in identifying systematic translation errors that can be easily
    handled. For example, some datasets involved the manipulation of a list of numbers,
    and thus aside from the instructions, the input and output did not require translation.
    Another example involves the incorrect translation of word “passage”, which was
    translated to mean a “walk way” instead of a “piece of text”.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 质量保证：我们手动检查每个数据集的随机样本，以确定翻译的有效性。进行这项手动检查帮助我们识别（并随后删除）那些不适合翻译的数据集，例如那些需要识别特定英语语法现象的数据集。这也帮助我们识别可以轻松处理的系统性翻译错误。例如，一些数据集涉及数字列表的操作，因此除了指令之外，输入和输出不需要翻译。另一个例子是单词“passage”的不正确翻译，它被翻译为“walk
    way”而不是“piece of text”。
- en: Our target was to translate both PromptSource and Super-NaturalInstructions,
    which are composed of 57 and 1,429 datasets respectively. Prior to translation,
    we excluded datasets that were English specific such as grammar checking and translation
    tasks such translation between Urdu and Marathi. In doing so, we excluded 14 and
    490 tasks from PromptSource and Super-NaturalInstructions respectively. After
    running our pipeline on both datasets, we excluded tasks that had less than 10
    translated prompts after filtering. While none of the tasks for PromptSource were
    excluded, an additional 619 tasks were excluded for Super-NaturalInstructions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是翻译PromptSource和Super-NaturalInstructions，它们分别由57和1,429个数据集组成。在翻译之前，我们排除了那些特定于英语的数据集，例如语法检查和翻译任务（如乌尔都语与马拉地语之间的翻译）。这样，我们排除了PromptSource和Super-NaturalInstructions中的14个和490个任务。运行我们的流程之后，我们排除了过滤后翻译提示少于10个的任务。虽然PromptSource的任务没有被排除，但Super-NaturalInstructions中排除了额外的619个任务。
- en: '| Source | Datasets | Prompts |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Source | Datasets | Prompts |'
- en: '| --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| PromptSource | 43 | 19,555,120 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| PromptSource | 43 | 19,555,120 |'
- en: '| Super-NaturalInstruct | 320 | 345,168 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Super-NaturalInstruct | 320 | 345,168 |'
- en: 3.   Fine Tuning Using New Data
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 微调使用新数据
- en: 3.1.   Data Splits
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 数据划分
- en: From all the prompts that we created, we extracted a test set composed of a
    random sample from each dataset with a maximum of 50 samples from each dataset.
    The final size of the test set was 13,462 prompts with ground truth responses
    that was extracted from 643 datasets that cover 67 different tasks. For fine tuning,
    we constructed two training datasets composed of 800 thousand prompts and 8 million
    prompts, which were randomly extracted from all the datasets (and were not in
    the test set). We opted to create two training datasets to measure the impact
    of using more (or less) examples for fine tuning. From the training dataset, we
    randomly picked 1% of the prompts for validation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们创建的所有提示中，我们提取了一个测试集，该测试集由来自每个数据集的随机样本组成，每个数据集最多50个样本。测试集的最终大小为13,462个提示，包含真实响应，这些提示来自覆盖67种不同任务的643个数据集。为了微调，我们构建了两个训练数据集，分别由80万个提示和800万个提示组成，这些提示是从所有数据集中随机提取的（且不在测试集中）。我们选择创建两个训练数据集，以测量使用更多（或更少）示例进行微调的影响。从训练数据集中，我们随机挑选了1%的提示用于验证。
- en: 3.2.   Baselines
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2. 基准
- en: 'As baselines, we prompted a variety of LLMs using our test set. The models
    were:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基准，我们使用我们的测试集对各种LLM进行了提示。这些模型包括：
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'AceGPT-Instruct 7B Huang et al. ([2023](#bib.bib5)): This is one of the first
    publicly available LLMs that focus on Arabic. The model is based on Llama2, where
    the model was further pre-trained using Arabic text and instruction tuned using
    Arabic instruction datasets.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AceGPT-Instruct 7B Huang et al. ([2023](#bib.bib5))：这是首批公开可用的专注于阿拉伯语的LLM之一。该模型基于Llama2，模型在阿拉伯语文本上进行了进一步的预训练，并使用阿拉伯语指令数据集进行了指令调优。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Jais-chat 13B Sengupta et al. ([2023](#bib.bib8)): This is the first open Arabic/English
    LLM that was trained from scratch based on the GPT-3 decoder architecture.'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Jais-chat 13B Sengupta et al. ([2023](#bib.bib8))：这是第一个从头开始训练的开放阿拉伯语/英语LLM，基于GPT-3解码器架构。
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Llama3-Instruct 8B & 70B Dubey et al. ([2024](#bib.bib3)): These are large
    foundational models from Meta. Though they are primarily pre-trained on English
    text, the models have demonstrated reasonable instruction following abilities
    for other languages.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Llama3-Instruct 8B & 70B Dubey et al. ([2024](#bib.bib3)): 这些是来自 Meta 的大型基础模型。尽管它们主要在英语文本上进行预训练，但这些模型在其他语言的指令跟随能力上也表现出色。'
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Qwen2-Instruct 7B Yang et al. ([2024](#bib.bib12)): These are large foundational
    models that are multilingual by design and have achieved competitive results on
    standard benchmarks. We later fine tune the base Qwen2 7B model using our instruction
    data.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Qwen2-Instruct 7B Yang et al. ([2024](#bib.bib12)): 这些是按设计多语言的大型基础模型，并在标准基准测试中取得了具有竞争力的结果。我们随后使用我们的指令数据对基础
    Qwen2 7B 模型进行了微调。'
- en: We used ROUGE-L as our quality metric. Table [1](#S3.T1 "Table 1 ‣ 3.4\. Fine
    Tuning Results ‣ 3\. Fine Tuning Using New Data ‣ Creating Arabic LLM Prompts
    at Scale") shows the baseline results across all the aforementioned models for
    a variety of tasks. The results show that Llama3 70B achieved the best results
    followed by Llama3 8B, and AceGPT 7B yielded the worst results.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 ROUGE-L 作为我们的质量指标。表格 [1](#S3.T1 "表格 1 ‣ 3.4\. 微调结果 ‣ 3\. 使用新数据进行微调 ‣ 大规模创建阿拉伯语
    LLM 提示") 显示了所有上述模型在各种任务中的基线结果。结果显示，Llama3 70B 取得了最佳结果，其次是 Llama3 8B，而 AceGPT 7B
    的结果最差。
- en: 3.3.   Fine Tuning Setup
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3. 微调设置
- en: We fine tuned the base Qwen2 7 billion parameter model using Low-Rank Adaptation
    (LoRA) Hu et al. ([2021](#bib.bib4)). This is a parameter-efficient method that
    freezes the parameters in the existing layers of a model and introduces trainable
    rank decomposition matrices for each layer in the model, reducing the parameters
    that require tuning by orders of magnitude, leading to significantly smaller memory
    requirements while achieving results that are at par with full fine tuning. We
    used the peft library from HuggingFace⁵⁵5[https://huggingface.co/docs/peft/en/index](https://huggingface.co/docs/peft/en/index).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用低秩自适应 (LoRA) Hu et al. ([2021](#bib.bib4)) 对基础 Qwen2 70 亿参数模型进行了微调。这是一种高效的参数方法，它冻结了模型现有层中的参数，并为模型中的每一层引入了可训练的秩分解矩阵，从而减少了需要调整的参数数量，显著降低了内存需求，同时取得了与全面微调相当的结果。我们使用了
    HuggingFace 的 peft 库⁵⁵5[https://huggingface.co/docs/peft/en/index](https://huggingface.co/docs/peft/en/index)。
- en: 'We fine tuned Qwen2 7B using two different sets of instructions that we randomly
    sampled from our newly created instruction datasets. The size of the first sample
    was 800K, and the second was 8M. We chose two different sample sizes to quantify
    the effect of using increased training data. We used the following Arabic system
    prompt and prompt structure for all our training instruction:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用两组不同的指令集对 Qwen2 7B 进行了微调，这些指令集是从我们新创建的指令数据集中随机抽样的。第一组样本的大小为 800K，第二组为 8M。我们选择了两种不同的样本大小来量化使用增加训练数据的效果。我们在所有训练指令中使用了以下阿拉伯语系统提示和提示结构：
- en: \<
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: \<
- en: فيما يلي تعليمات باللغة العربية تصف المهمة.> \< اكتب ردًا باللغة العربية يكمل
    الطلب بشكل مناسب.>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: فيما يلي تعليمات باللغة العربية تصف المهمة.> \< اكتب ردًا باللغة العربية يكمل
    الطلب بشكل مناسب.>
- en: '(Translation: “The following are Arabic instructions that describe a task.
    Provide an answer in Arabic that satisfies the request'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: （翻译：“以下是描述任务的阿拉伯语指令。请用阿拉伯语提供一个满足请求的答案）
- en: 'Instruction:'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指令：
- en: '{text of the instruction}'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '{instruction text}'
- en: 'Response:'
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 响应：
- en: '{text of the response}'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '{response text}'
- en: 'We fine tuned the model for one epoch and the key tuning hyper parameters were
    as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对模型进行了一个周期的微调，关键的微调超参数如下：
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Warmup Ratio: We used a warm-up ratio of 0.1, meaning that the learning rate
    gradually increased from a low value to its initial value over the first 10% of
    the training steps. This helps stabilize the training process.'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预热比例：我们使用了 0.1 的预热比例，这意味着学习率在训练步骤的前 10% 内从低值逐渐增加到其初始值。这有助于稳定训练过程。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Learning Rate: The learning rate was set to 2e-4 and adjusted using a linear
    scheduler, which decreases the learning rate steadily during training. This helps
    the model converge smoothly.'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习率：学习率设置为 2e-4，并使用线性调度器进行调整，该调度器在训练过程中稳步降低学习率。这有助于模型平滑收敛。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Optimizer: We used the Adam optimizer, which is effective in handling sparse
    gradients and changes in the training data. This choice, combined with our learning
    rate settings, ensures stable and effective updates to the model’s parameters.'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 优化器：我们使用了 Adam 优化器，该优化器在处理稀疏梯度和训练数据变化时效果很好。这个选择，加上我们的学习率设置，确保了模型参数的稳定和有效更新。
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Weight Decay: We also used a weight decay of 0.01 to prevent overfitting and
    to improve the generalization of the model.'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 权重衰减：我们还使用了0.01的权重衰减，以防止过拟合并提高模型的泛化能力。
- en: 3.4.   Fine Tuning Results
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4. 微调结果
- en: As shown in Table [1](#S3.T1 "Table 1 ‣ 3.4\. Fine Tuning Results ‣ 3\. Fine
    Tuning Using New Data ‣ Creating Arabic LLM Prompts at Scale"), fine tuning Qwen2
    7B model using our carefully curated dataset of 800k samples led to statistically
    significant improvement over the Qwen2-Instruct 7B with respective average ROUGE-L
    scores of 0.184 and 0.143\. We used a paired 2-tailed t-test over per dataset
    scores with a p-value less than 0.01 to determine statistical significance. In
    turn, fine tuning using 8M samples statistically significantly outperformed all
    baseline models, except for Llama 3-70B (ROUGE-L = 0.221; p-value > 0.79), and
    Qwen2 7B fine tuned on 800k examples with an average ROUGE-L score of 0.224\.
    It performed better than the Arabic-focused models AceGPT 7B and Jais 13B, which
    scored average ROUGE-L scores of 0.102 and 0.138, respectively. This demonstrates
    the effectiveness of fine tuning using our dataset with significant improvement
    across a variety of tasks, where the fine tuned Qwen2 7B 800k and 8M models respectively
    performed 29% and 57% higher than the Qwen2 7B-Instruct model. We also observe
    that fine tuning using more examples (8M versus 800k) leads to 22% improvement
    in results. This suggests that fine tuning using more examples positively impacts
    the final model’s performance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如表格[1](#S3.T1 "Table 1 ‣ 3.4\. Fine Tuning Results ‣ 3\. Fine Tuning Using New
    Data ‣ Creating Arabic LLM Prompts at Scale")所示，使用我们精心策划的800k样本数据集对Qwen2 7B模型进行微调，相较于Qwen2-Instruct
    7B，ROUGE-L平均分数分别为0.184和0.143，统计上显著提高。我们对每个数据集的分数进行了配对的双尾t检验，p值小于0.01，以确定统计显著性。结果表明，使用8M样本进行微调在统计上显著优于所有基线模型，除了Llama
    3-70B（ROUGE-L = 0.221; p值 > 0.79），以及在800k样本上微调的Qwen2 7B模型，其平均ROUGE-L分数为0.224。其表现优于以阿拉伯语为重点的模型AceGPT
    7B和Jais 13B，这两个模型的ROUGE-L平均分数分别为0.102和0.138。这展示了使用我们数据集进行微调的有效性，在各种任务中有显著改善，其中微调后的Qwen2
    7B 800k和8M模型的表现分别比Qwen2 7B-Instruct模型高出29%和57%。我们还观察到，使用更多样本（8M对800k）进行微调结果提高了22%。这表明，使用更多样本进行微调对最终模型的性能有积极影响。
- en: '| Task | No. of Datasets | AceGPT 7B | Jais-chat 13B | Llama 3 8B | Llama 3
    70B | Qwen2 7B-Instruct | Qwen2 7B-FT-800k | Qwen2 7B-FT-8M |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 数据集数量 | AceGPT 7B | Jais-chat 13B | Llama 3 8B | Llama 3 70B | Qwen2
    7B-Instruct | Qwen2 7B-FT-800k | Qwen2 7B-FT-8M |'
- en: '| Answer Verification | 1 | 0.014 | 0.073 | 0.082 | 0.075 | 0.680 | 0.600 |
    0.667 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 答案验证 | 1 | 0.014 | 0.073 | 0.082 | 0.075 | 0.680 | 0.600 | 0.667 |'
- en: '| Answerability Classification | 2 | 0.041 | 0.100 | 0.108 | 0.105 | 0.362
    | 0.467 | 0.613 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 答案性分类 | 2 | 0.041 | 0.100 | 0.108 | 0.105 | 0.362 | 0.467 | 0.613 |'
- en: '| Cause Effect Classification | 3 | 0.091 | 0.183 | 0.140 | 0.200 | 0.070 |
    0.032 | 0.135 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 因果关系分类 | 3 | 0.091 | 0.183 | 0.140 | 0.200 | 0.070 | 0.032 | 0.135 |'
- en: '| Classification | 18 | 0.098 | 0.151 | 0.147 | 0.216 | 0.061 | 0.168 | 0.187
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 18 | 0.098 | 0.151 | 0.147 | 0.216 | 0.061 | 0.168 | 0.187 |'
- en: '| Coherence Classification | 2 | 0.046 | 0.081 | 0.048 | 0.051 | 0.800 | 0.402
    | 0.560 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 一致性分类 | 2 | 0.046 | 0.081 | 0.048 | 0.051 | 0.800 | 0.402 | 0.560 |'
- en: '| Command Interpretation | 1 | 0.036 | 0.103 | 0.114 | 0.116 | 0.052 | 0.026
    | 0.035 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 命令解析 | 1 | 0.036 | 0.103 | 0.114 | 0.116 | 0.052 | 0.026 | 0.035 |'
- en: '| Commonsense Validation | 2 | 0.046 | 0.131 | 0.087 | 0.059 | 0.077 | 0.088
    | 0.154 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 常识验证 | 2 | 0.046 | 0.131 | 0.087 | 0.059 | 0.077 | 0.088 | 0.154 |'
- en: '| Coreference Resolution | 3 | 0.109 | 0.092 | 0.171 | 0.163 | 0.104 | 0.024
    | 0.036 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 共指解析 | 3 | 0.109 | 0.092 | 0.171 | 0.163 | 0.104 | 0.024 | 0.036 |'
- en: '| Data to Text | 2 | 0.073 | 0.099 | 0.099 | 0.172 | 0.127 | 0.067 | 0.115
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 数据到文本 | 2 | 0.073 | 0.099 | 0.099 | 0.172 | 0.127 | 0.067 | 0.115 |'
- en: '| Definition Generation | 1 | 0.037 | 0.138 | 0.128 | 0.120 | 0.090 | 0.035
    | 0.010 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 定义生成 | 1 | 0.037 | 0.138 | 0.128 | 0.120 | 0.090 | 0.035 | 0.010 |'
- en: '| Diacritization | 15 | 0.535 | 0.315 | 0.563 | 0.802 | 0.277 | 0.265 | 0.399
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 标点化 | 15 | 0.535 | 0.315 | 0.563 | 0.802 | 0.277 | 0.265 | 0.399 |'
- en: '| Dialect Classification | 6 | 0.074 | 0.152 | 0.277 | 0.229 | 0.080 | 0.105
    | 0.097 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 方言分类 | 6 | 0.074 | 0.152 | 0.277 | 0.229 | 0.080 | 0.105 | 0.097 |'
- en: '| Dialogue Generation | 11 | 0.073 | 0.118 | 0.116 | 0.117 | 0.071 | 0.132
    | 0.142 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 对话生成 | 11 | 0.073 | 0.118 | 0.116 | 0.117 | 0.071 | 0.132 | 0.142 |'
- en: '| Disease Mention Identification | 1 | 0.030 | 0.097 | 0.247 | 0.243 | 0.028
    | 0.500 | 0.109 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 疾病提及识别 | 1 | 0.030 | 0.097 | 0.247 | 0.243 | 0.028 | 0.500 | 0.109 |'
- en: '| Duplicate Question Identification | 2 | 0.015 | 0.108 | 0.041 | 0.078 | 0.009
    | 0.750 | 0.113 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 重复问题识别 | 2 | 0.015 | 0.108 | 0.041 | 0.078 | 0.009 | 0.750 | 0.113 |'
- en: '| Emotion Detection | 12 | 0.038 | 0.044 | 0.071 | 0.118 | 0.022 | 0.275 |
    0.183 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 情感检测 | 12 | 0.038 | 0.044 | 0.071 | 0.118 | 0.022 | 0.275 | 0.183 |'
- en: '| Ethics Classification | 2 | 0.081 | 0.124 | 0.095 | 0.085 | 0.011 | 0.381
    | 0.440 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 伦理分类 | 2 | 0.081 | 0.124 | 0.095 | 0.085 | 0.011 | 0.381 | 0.440 |'
- en: '| Explanation | 6 | 0.145 | 0.161 | 0.198 | 0.209 | 0.104 | 0.086 | 0.173 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 解释 | 6 | 0.145 | 0.161 | 0.198 | 0.209 | 0.104 | 0.086 | 0.173 |'
- en: '| Fact Verification | 5 | 0.055 | 0.121 | 0.155 | 0.201 | 0.123 | 0.380 | 0.441
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 事实验证 | 5 | 0.055 | 0.121 | 0.155 | 0.201 | 0.123 | 0.380 | 0.441 |'
- en: '| Fill in The Blank | 3 | 0.047 | 0.123 | 0.162 | 0.171 | 0.025 | 0.144 | 0.081
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 填空 | 3 | 0.047 | 0.123 | 0.162 | 0.171 | 0.025 | 0.144 | 0.081 |'
- en: '| Grammar Correction | 14 | 0.293 | 0.258 | 0.347 | 0.514 | 0.416 | 0.359 |
    0.377 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 语法纠错 | 14 | 0.293 | 0.258 | 0.347 | 0.514 | 0.416 | 0.359 | 0.377 |'
- en: '| Inference Detection | 1 | 0.024 | 0.194 | 0.308 | 0.381 | 0.022 | 0.900 |
    0.900 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 推理检测 | 1 | 0.024 | 0.194 | 0.308 | 0.381 | 0.022 | 0.900 | 0.900 |'
- en: '| Information Extraction | 21 | 0.083 | 0.092 | 0.207 | 0.211 | 0.140 | 0.132
    | 0.179 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 信息抽取 | 21 | 0.083 | 0.092 | 0.207 | 0.211 | 0.140 | 0.132 | 0.179 |'
- en: '| Information Retrieval | 1 | 0.055 | 0.083 | 0.071 | 0.096 | 0.113 | 0.125
    | 0.173 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 信息检索 | 1 | 0.055 | 0.083 | 0.071 | 0.096 | 0.113 | 0.125 | 0.173 |'
- en: '| Instruction Generation | 1 | 0.042 | 0.115 | 0.086 | 0.097 | 0.019 | 0.067
    | 0.049 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 指令生成 | 1 | 0.042 | 0.115 | 0.086 | 0.097 | 0.019 | 0.067 | 0.049 |'
- en: '| Intent Identification | 3 | 0.053 | 0.109 | 0.084 | 0.071 | 0.084 | 0.042
    | 0.101 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 意图识别 | 3 | 0.053 | 0.109 | 0.084 | 0.071 | 0.084 | 0.042 | 0.101 |'
- en: '| Keyword Extraction | 10 | 0.066 | 0.092 | 0.138 | 0.148 | 0.027 | 0.095 |
    0.118 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 关键词提取 | 10 | 0.066 | 0.092 | 0.138 | 0.148 | 0.027 | 0.095 | 0.118 |'
- en: '| Logical Reasoning | 3 | 0.071 | 0.157 | 0.546 | 0.235 | 0.011 | 0.824 | 0.747
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑推理 | 3 | 0.071 | 0.157 | 0.546 | 0.235 | 0.011 | 0.824 | 0.747 |'
- en: '| Misc. | 8 | 0.066 | 0.116 | 0.133 | 0.138 | 0.052 | 0.038 | 0.075 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 杂项 | 8 | 0.066 | 0.116 | 0.133 | 0.138 | 0.052 | 0.038 | 0.075 |'
- en: '| Named Entity Recognition | 14 | 0.105 | 0.133 | 0.261 | 0.272 | 0.193 | 0.054
    | 0.097 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 命名实体识别 | 14 | 0.105 | 0.133 | 0.261 | 0.272 | 0.193 | 0.054 | 0.097 |'
- en: '| Natural Language Inference | 1 | 0.090 | 0.203 | 0.689 | 0.509 | 0.647 |
    0.720 | 0.480 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 自然语言推理 | 1 | 0.090 | 0.203 | 0.689 | 0.509 | 0.647 | 0.720 | 0.480 |'
- en: '| News Article Generation | 2 | 0.123 | 0.107 | 0.158 | 0.175 | 0.142 | 0.105
    | 0.074 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 新闻文章生成 | 2 | 0.123 | 0.107 | 0.158 | 0.175 | 0.142 | 0.105 | 0.074 |'
- en: '| Next Action Prediction | 1 | 0.067 | 0.103 | 0.220 | 0.204 | 0.042 | 0.062
    | 0.096 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 下一步预测 | 1 | 0.067 | 0.103 | 0.220 | 0.204 | 0.042 | 0.062 | 0.096 |'
- en: '| Offensive Language Detection | 15 | 0.061 | 0.113 | 0.163 | 0.227 | 0.280
    | 0.515 | 0.502 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 攻击性语言检测 | 15 | 0.061 | 0.113 | 0.163 | 0.227 | 0.280 | 0.515 | 0.502 |'
- en: '| Paraphrasing | 9 | 0.175 | 0.160 | 0.254 | 0.264 | 0.216 | 0.123 | 0.162
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 同义改写 | 9 | 0.175 | 0.160 | 0.254 | 0.264 | 0.216 | 0.123 | 0.162 |'
- en: '| Poem Generation | 1 | 0.092 | 0.092 | 0.122 | 0.132 | 0.060 | 0.025 | 0.076
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 诗歌生成 | 1 | 0.092 | 0.092 | 0.122 | 0.132 | 0.060 | 0.025 | 0.076 |'
- en: '| Problem Identification | 1 | 0.021 | 0.096 | 0.035 | 0.022 | 0.020 | 0.001
    | 0.078 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 问题识别 | 1 | 0.021 | 0.096 | 0.035 | 0.022 | 0.020 | 0.001 | 0.078 |'
- en: '| Program Execution | 18 | 0.065 | 0.113 | 0.058 | 0.057 | 0.196 | 0.374 |
    0.833 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 程序执行 | 18 | 0.065 | 0.113 | 0.058 | 0.057 | 0.196 | 0.374 | 0.833 |'
- en: '| Query Classification | 1 | 0.014 | 0.141 | 0.073 | 0.056 | 0.003 | 0.500
    | 0.300 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 查询分类 | 1 | 0.014 | 0.141 | 0.073 | 0.056 | 0.003 | 0.500 | 0.300 |'
- en: '| Question Answering | 115 | 0.083 | 0.148 | 0.194 | 0.235 | 0.130 | 0.149
    | 0.150 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 问答 | 115 | 0.083 | 0.148 | 0.194 | 0.235 | 0.130 | 0.149 | 0.150 |'
- en: '| Question Categorization | 1 | 0.075 | 0.081 | 0.253 | 0.334 | 0.000 | 0.222
    | 0.073 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 问题分类 | 1 | 0.075 | 0.081 | 0.253 | 0.334 | 0.000 | 0.222 | 0.073 |'
- en: '| Question Decomposition | 2 | 0.128 | 0.123 | 0.128 | 0.143 | 0.163 | 0.027
    | 0.042 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 问题分解 | 2 | 0.128 | 0.123 | 0.128 | 0.143 | 0.163 | 0.027 | 0.042 |'
- en: '| Question Generation | 43 | 0.085 | 0.117 | 0.145 | 0.149 | 0.153 | 0.068
    | 0.106 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 问题生成 | 43 | 0.085 | 0.117 | 0.145 | 0.149 | 0.153 | 0.068 | 0.106 |'
- en: '| Question Understanding | 3 | 0.095 | 0.157 | 0.111 | 0.149 | 0.365 | 0.293
    | 0.213 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 问题理解 | 3 | 0.095 | 0.157 | 0.111 | 0.149 | 0.365 | 0.293 | 0.213 |'
- en: '| Reading Comprehension | 10 | 0.081 | 0.198 | 0.321 | 0.359 | 0.073 | 0.560
    | 0.645 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 阅读理解 | 10 | 0.081 | 0.198 | 0.321 | 0.359 | 0.073 | 0.560 | 0.645 |'
- en: '| Review Rating Prediction | 3 | 0.122 | 0.107 | 0.234 | 0.295 | 0.046 | 0.154
    | 0.121 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 评价预测 | 3 | 0.122 | 0.107 | 0.234 | 0.295 | 0.046 | 0.154 | 0.121 |'
- en: '| Riddle Solving | 1 | 0.036 | 0.105 | 0.121 | 0.165 | 0.034 | 0.000 | 0.003
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 谜语解答 | 1 | 0.036 | 0.105 | 0.121 | 0.165 | 0.034 | 0.000 | 0.003 |'
- en: '| Sarcasm Detection | 7 | 0.094 | 0.176 | 0.194 | 0.264 | 0.081 | 0.411 | 0.499
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 讽刺检测 | 7 | 0.094 | 0.176 | 0.194 | 0.264 | 0.081 | 0.411 | 0.499 |'
- en: '| Semantic Similarity | 21 | 0.087 | 0.205 | 0.185 | 0.189 | 0.209 | 0.382
    | 0.497 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 语义相似度 | 21 | 0.087 | 0.205 | 0.185 | 0.189 | 0.209 | 0.382 | 0.497 |'
- en: '| Sentence Composition | 11 | 0.156 | 0.155 | 0.190 | 0.195 | 0.172 | 0.050
    | 0.085 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 句子构造 | 11 | 0.156 | 0.155 | 0.190 | 0.195 | 0.172 | 0.050 | 0.085 |'
- en: '| Sentence Ordering | 1 | 0.051 | 0.082 | 0.161 | 0.164 | 0.348 | 0.098 | 0.216
    |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 句子排序 | 1 | 0.051 | 0.082 | 0.161 | 0.164 | 0.348 | 0.098 | 0.216 |'
- en: '| Sentiment Analysis | 41 | 0.110 | 0.159 | 0.273 | 0.240 | 0.129 | 0.235 |
    0.229 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 情感分析 | 41 | 0.110 | 0.159 | 0.273 | 0.240 | 0.129 | 0.235 | 0.229 |'
- en: '| Spam Detection | 4 | 0.090 | 0.069 | 0.084 | 0.138 | 0.025 | 0.232 | 0.406
    |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 垃圾邮件检测 | 4 | 0.090 | 0.069 | 0.084 | 0.138 | 0.025 | 0.232 | 0.406 |'
- en: '| Stereotype Detection | 5 | 0.111 | 0.163 | 0.388 | 0.415 | 0.227 | 0.269
    | 0.480 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 刻板印象检测 | 5 | 0.111 | 0.163 | 0.388 | 0.415 | 0.227 | 0.269 | 0.480 |'
- en: '| Story Composition | 7 | 0.104 | 0.112 | 0.167 | 0.179 | 0.075 | 0.041 | 0.043
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 故事构建 | 7 | 0.104 | 0.112 | 0.167 | 0.179 | 0.075 | 0.041 | 0.043 |'
- en: '| Style Transfer | 1 | 0.097 | 0.096 | 0.157 | 0.158 | 0.040 | 0.001 | 0.044
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 风格迁移 | 1 | 0.097 | 0.096 | 0.157 | 0.158 | 0.040 | 0.001 | 0.044 |'
- en: '| Summarization | 36 | 0.111 | 0.141 | 0.182 | 0.198 | 0.154 | 0.078 | 0.122
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 摘要生成 | 36 | 0.111 | 0.141 | 0.182 | 0.198 | 0.154 | 0.078 | 0.122 |'
- en: '| Text Categorization | 7 | 0.038 | 0.094 | 0.139 | 0.161 | 0.244 | 0.306 |
    0.491 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 文本分类 | 7 | 0.038 | 0.094 | 0.139 | 0.161 | 0.244 | 0.306 | 0.491 |'
- en: '| Text Classification | 4 | 0.058 | 0.128 | 0.204 | 0.324 | 0.100 | 0.324 |
    0.575 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 文本分类 | 4 | 0.058 | 0.128 | 0.204 | 0.324 | 0.100 | 0.324 | 0.575 |'
- en: '| Text Completion | 9 | 0.084 | 0.116 | 0.166 | 0.111 | 0.028 | 0.163 | 0.270
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 文本补全 | 9 | 0.084 | 0.116 | 0.166 | 0.111 | 0.028 | 0.163 | 0.270 |'
- en: '| Text Generation | 8 | 0.059 | 0.062 | 0.078 | 0.076 | 0.070 | 0.050 | 0.044
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 文本生成 | 8 | 0.059 | 0.062 | 0.078 | 0.076 | 0.070 | 0.050 | 0.044 |'
- en: '| Text Simplification | 2 | 0.222 | 0.193 | 0.323 | 0.353 | 0.287 | 0.091 |
    0.149 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 文本简化 | 2 | 0.222 | 0.193 | 0.323 | 0.353 | 0.287 | 0.091 | 0.149 |'
- en: '| Title Generation | 28 | 0.082 | 0.119 | 0.162 | 0.184 | 0.118 | 0.079 | 0.075
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 标题生成 | 28 | 0.082 | 0.119 | 0.162 | 0.184 | 0.118 | 0.079 | 0.075 |'
- en: '| Topic Identification | 5 | 0.076 | 0.098 | 0.171 | 0.293 | 0.043 | 0.101
    | 0.165 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 主题识别 | 5 | 0.076 | 0.098 | 0.171 | 0.293 | 0.043 | 0.101 | 0.165 |'
- en: '| Translation | 22 | 0.108 | 0.095 | 0.175 | 0.245 | 0.185 | 0.138 | 0.203
    |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 翻译 | 22 | 0.108 | 0.095 | 0.175 | 0.245 | 0.185 | 0.138 | 0.203 |'
- en: '| Transliteration | 10 | 0.102 | 0.130 | 0.148 | 0.228 | 0.086 | 0.079 | 0.122
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 音译 | 10 | 0.102 | 0.130 | 0.148 | 0.228 | 0.086 | 0.079 | 0.122 |'
- en: '| Wrong Candidate Generation | 13 | 0.064 | 0.102 | 0.105 | 0.114 | 0.054 |
    0.062 | 0.027 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 错误候选生成 | 13 | 0.064 | 0.102 | 0.105 | 0.114 | 0.054 | 0.062 | 0.027 |'
- en: '| AVERAGE | 0.102 | 0.138 | 0.192 | 0.221 | 0.143 | 0.184 | 0.224 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 0.102 | 0.138 | 0.192 | 0.221 | 0.143 | 0.184 | 0.224 |'
- en: 'Table 1: Results for baseline models and fine tuned Qwen2 models.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：基线模型和微调的Qwen2模型结果。
- en: 4.   Conclusion
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.   结论
- en: In this paper, we presented two robust methods for creating large prompt datasets
    for Arabic. The first method involves creating prompts based on applying prompt
    templates. The second method involves automatically translating existing English
    prompt datasets, applying automatic filtering of translations using reference-free
    quality estimation and manual verification. In all, we created more than 87 million
    prompts. We fine tuned a state-of-the-art 7 billion parameter foundational model,
    namely Qwen2 7B, using roughly 1% and and 10% of the prompts that we have created,
    and show that both fine tuned models statistically significantly outperform the
    publicaly available instruction tuned version of the model. Further, our fine
    tuned model using 10% of our prompt data slightly outperforms a much larger instruction
    tuned 70 billion parameter model, namely Llama3 70B. We show that the performance
    of the fine tuned models positively correlates with fine tuning using larger prompt
    datasets.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了两种针对阿拉伯语的大型提示数据集创建的稳健方法。第一种方法是基于应用提示模板来创建提示。第二种方法是自动翻译现有的英文提示数据集，利用无参考质量估计和人工验证对翻译进行自动过滤。总的来说，我们创建了超过8700万条提示。我们使用我们创建的约1%和10%的提示对最先进的70亿参数基础模型，即Qwen2
    7B进行了微调，结果表明这两种微调模型在统计上显著优于公开可用的指令微调版本的模型。此外，我们使用10%的提示数据的微调模型略微优于一个更大的指令微调70亿参数模型，即Llama3
    70B。我们展示了微调模型的性能与使用更大提示数据集进行微调呈正相关。
- en: 5.   References
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.   参考文献
- en: \c@NAT@ctr
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: \c@NAT@ctr
- en: ''
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Bach et al. (2022) Stephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson,
    Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault
    Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-David,
    Canwen Xu, Gunjan Chhablani, Han Wang, Jason Alan Fries, Maged S. Al-shaibani,
    Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Xiangru Tang, Mike
    Tian-Jian Jiang, and Alexander M. Rush. 2022. [Promptsource: An integrated development
    environment and repository for natural language prompts](http://arxiv.org/abs/2202.01279).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bach 等 (2022) **Stephen H. Bach**、**Victor Sanh**、**Zheng-Xin Yong**、**Albert
    Webson**、**Colin Raffel**、**Nihal V. Nayak**、**Abheesht Sharma**、**Taewoon Kim**、**M
    Saiful Bari**、**Thibault Fevry**、**Zaid Alyafeai**、**Manan Dey**、**Andrea Santilli**、**Zhiqing
    Sun**、**Srulik Ben-David**、**Canwen Xu**、**Gunjan Chhablani**、**Han Wang**、**Jason
    Alan Fries**、**Maged S. Al-shaibani**、**Shanya Sharma**、**Urmish Thakker**、**Khalid
    Almubarak**、**Xiangru Tang**、**Xiangru Tang**、**Mike Tian-Jian Jiang** 和 **Alexander
    M. Rush**。2022年。[Promptsource: 一个集成的自然语言提示开发环境和仓库](http://arxiv.org/abs/2202.01279)。'
- en: 'Conover et al. (2023) Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,
    Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin.
    2023. [Free dolly: Introducing the world’s first truly open instruction-tuned
    llm](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Conover 等 (2023) **Mike Conover**、**Matt Hayes**、**Ankit Mathur**、**Jianwei
    Xie**、**Jun Wan**、**Sam Shah**、**Ali Ghodsi**、**Patrick Wendell**、**Matei Zaharia**
    和 **Reynold Xin**。2023年。[Free dolly: 介绍世界上首个真正开放的指令调整 llm](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)。'
- en: Dubey et al. (2024) Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek
    Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang,
    Angela Fan, et al. 2024. The llama 3 herd of models. *arXiv preprint arXiv:2407.21783*.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubey 等 (2024) **Abhimanyu Dubey**、**Abhinav Jauhri**、**Abhinav Pandey**、**Abhishek
    Kadian**、**Ahmad Al-Dahle**、**Aiesha Letman**、**Akhil Mathur**、**Alan Schelten**、**Amy
    Yang**、**Angela Fan** 等。2024年。《Llama 3 模型群》。*arXiv 预印本 arXiv:2407.21783*。
- en: 'Hu et al. (2021) Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation
    of large language models. *arXiv preprint arXiv:2106.09685*.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu 等 (2021) **Edward J Hu**、**Yelong Shen**、**Phillip Wallis**、**Zeyuan Allen-Zhu**、**Yuanzhi
    Li**、**Shean Wang**、**Lu Wang** 和 **Weizhu Chen**。2021年。《Lora: 大型语言模型的低秩适应》。*arXiv
    预印本 arXiv:2106.09685*。'
- en: Huang et al. (2023) Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng,
    Dingjie Song, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Ziche Liu, Zhiyi Zhang,
    Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou
    Li, and Jinchao Xu. 2023. [Acegpt, localizing large language models in arabic](http://arxiv.org/abs/2309.12053).
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang 等 (2023) **Huang Huang**、**Fei Yu**、**Jianqing Zhu**、**Xuening Sun**、**Hao
    Cheng**、**Dingjie Song**、**Zhihong Chen**、**Abdulmohsen Alharthi**、**Bang An**、**Ziche
    Liu**、**Zhiyi Zhang**、**Junying Chen**、**Jianquan Li**、**Benyou Wang**、**Lian
    Zhang**、**Ruoyu Sun**、**Xiang Wan**、**Haizhou Li** 和 **Jinchao Xu**。2023年。[Acegpt:
    在阿拉伯语中本地化大型语言模型](http://arxiv.org/abs/2309.12053)。'
- en: Mishra et al. (2022) Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh
    Hajishirzi. 2022. Cross-task generalization via natural language crowdsourcing
    instructions. In *ACL*.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mishra 等 (2022) **Swaroop Mishra**、**Daniel Khashabi**、**Chitta Baral** 和 **Hannaneh
    Hajishirzi**。2022年。《通过自然语言众包指令进行跨任务泛化》。在 *ACL*。
- en: 'Rei et al. (2023) Ricardo Rei, Nuno M Guerreiro, José Pombal, Daan van Stigt,
    Marcos Treviso, Luisa Coheur, José GC de Souza, and André FT Martins. 2023. Scaling
    up cometkiwi: Unbabel-ist 2023 submission for the quality estimation shared task.
    *arXiv preprint arXiv:2309.11925*.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rei 等 (2023) **Ricardo Rei**、**Nuno M Guerreiro**、**José Pombal**、**Daan van
    Stigt**、**Marcos Treviso**、**Luisa Coheur**、**José GC de Souza** 和 **André FT
    Martins**。2023年。《扩展 cometkiwi: Unbabel-ist 2023 提交的质量估计共享任务》。*arXiv 预印本 arXiv:2309.11925*。'
- en: 'Sengupta et al. (2023) Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh
    Katipomu, Haonan Li, Fajri Koto, Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit,
    Rahul Pal, Lalit Pradhan, Zain Muhammad Mujahid, Massa Baali, Xudong Han, Sondos
    Bsharat, Alham Aji, Zhiqiang Shen, Zhengzhong Liu, Natalia Vassilieva, Joel Hestness,
    Andy Hock, Andrew Feldman, Jonathan Lee, Andrew Jackson, Hector Xuguang Ren, Preslav
    Nakov, Timothy Baldwin, and Eric Xing. 2023. Jais and jais-chat: Arabic-centric
    foundation and instruction-tuned open generative large language models. *arXiv
    preprint arXiv:2308.16149*.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sengupta 等 (2023) **Neha Sengupta**、**Sunil Kumar Sahu**、**Bokang Jia**、**Satheesh
    Katipomu**、**Haonan Li**、**Fajri Koto**、**Osama Mohammed Afzal**、**Samta Kamboj**、**Onkar
    Pandit**、**Rahul Pal**、**Lalit Pradhan**、**Zain Muhammad Mujahid**、**Massa Baali**、**Xudong
    Han**、**Sondos Bsharat**、**Alham Aji**、**Zhiqiang Shen**、**Zhengzhong Liu**、**Natalia
    Vassilieva**、**Joel Hestness**、**Andy Hock**、**Andrew Feldman**、**Jonathan Lee**、**Andrew
    Jackson**、**Hector Xuguang Ren**、**Preslav Nakov**、**Timothy Baldwin** 和 **Eric
    Xing**。2023年。《Jais 和 jais-chat: 以阿拉伯语为中心的基础和指令调整开放生成大型语言模型》。*arXiv 预印本 arXiv:2308.16149*。'
- en: Tiedemann and Thottingal (2020) Jörg Tiedemann and Santhosh Thottingal. 2020.
    [OPUS-MT – building open translation services for the world](https://aclanthology.org/2020.eamt-1.61).
    In *Proceedings of the 22nd Annual Conference of the European Association for
    Machine Translation*, pages 479–480, Lisboa, Portugal. European Association for
    Machine Translation.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tiedemann 和 Thottingal (2020) Jörg Tiedemann 和 Santhosh Thottingal。2020年。[OPUS-MT
    – 构建全球开放翻译服务](https://aclanthology.org/2020.eamt-1.61)。见于 *第22届欧洲机器翻译协会年会论文集*，第479–480页，葡萄牙里斯本。欧洲机器翻译协会。
- en: Wang et al. (2022) Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh
    Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran,
    Atharva Naik, David Stap, et al. 2022. Super-naturalinstructions:generalization
    via declarative instructions on 1600+ tasks. In *EMNLP*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2022) Yizhong Wang、Swaroop Mishra、Pegah Alipoormolabashi、Yeganeh Kordi、Amirreza
    Mirzaei、Anjana Arunkumar、Arjun Ashok、Arut Selvan Dhanasekaran、Atharva Naik、David
    Stap 等人。2022年。超自然指令：通过声明性指令在1600+任务上的泛化。见于 *EMNLP*。
- en: Wei et al. (2021) Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei
    Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language
    models are zero-shot learners. *arXiv preprint arXiv:2109.01652*.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2021) Jason Wei、Maarten Bosma、Vincent Y Zhao、Kelvin Guu、Adams Wei Yu、Brian
    Lester、Nan Du、Andrew M Dai 和 Quoc V Le。2021年。微调语言模型是零-shot 学习者。*arXiv 预印本 arXiv:2109.01652*。
- en: Yang et al. (2024) An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang
    Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2
    technical report. *arXiv preprint arXiv:2407.10671*.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2024) An Yang、Baosong Yang、Binyuan Hui、Bo Zheng、Bowen Yu、Chang Zhou、Chengpeng
    Li、Chengyuan Li、Dayiheng Liu、Fei Huang 等人。2024年。Qwen2 技术报告。*arXiv 预印本 arXiv:2407.10671*。
