- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-08 18:48:32'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:48:32
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Evoke: 通过审稿人-作者提示编辑激发 LLM 的批判性思维能力'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2310.13855](https://ar5iv.labs.arxiv.org/html/2310.13855)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2310.13855](https://ar5iv.labs.arxiv.org/html/2310.13855)
- en: Xinyu Hu¹, Pengfei Tang¹, Simiao Zuo¹, Zihan Wang², Bowen Song³, Qiang Lou¹,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Xinyu Hu¹, Pengfei Tang¹, Simiao Zuo¹, Zihan Wang², Bowen Song³, Qiang Lou¹,
- en: Jian Jiao¹, Denis Charles¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jian Jiao¹, Denis Charles¹
- en: ¹Microsoft
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹微软
- en: ²University of Washington
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²华盛顿大学
- en: ³University of Michigan Corresponding author.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³密歇根大学 通讯作者
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large language models (LLMs) have made impressive progress in natural language
    processing. These models rely on proper human instructions (or prompts) to generate
    suitable responses. However, the potential of LLMs are not fully harnessed by
    commonly-used prompting methods: many human-in-the-loop algorithms employ ad-hoc
    procedures for prompt selection; while auto prompt generation approaches are essentially
    searching all possible prompts randomly and inefficiently. We propose Evoke, an
    automatic prompt refinement framework. In Evoke, there are two instances of a
    same LLM: one as a reviewer (LLM-Reviewer), it scores the current prompt; the
    other as an author (LLM-Author), it edits the prompt by considering the edit history
    and the reviewer’s feedback. Such an author-reviewer feedback loop ensures that
    the prompt is refined in each iteration. We further aggregate a data selection
    approach to Evoke, where only the hard samples are exposed to the LLM. The hard
    samples are more important because the LLM can develop deeper understanding of
    the tasks out of them, while the model may already know how to solve the easier
    cases. Experimental results show that Evoke significantly outperforms existing
    methods. For instance, in the challenging task of logical fallacy detection, Evoke
    scores above 80, while all other baseline methods struggle to reach 20.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在自然语言处理方面取得了显著进展。这些模型依赖于适当的人类指令（或提示）来生成合适的响应。然而，常用的提示方法未能充分发挥 LLM
    的潜力：许多人机交互算法采用临时的提示选择程序；而自动提示生成方法本质上是随机且低效地搜索所有可能的提示。我们提出了 Evoke，一种自动提示改进框架。在
    Evoke 中，有两个相同的 LLM 实例：一个作为审稿人（LLM-Reviewer），为当前提示打分；另一个作为作者（LLM-Author），通过考虑编辑历史和审稿人的反馈来修改提示。这样的作者-审稿人反馈循环确保了每次迭代中的提示改进。我们进一步将数据选择方法与
    Evoke 聚合，在此过程中只有难样本暴露给 LLM。难样本更为重要，因为 LLM 可以从中获得对任务的更深理解，而模型可能已经知道如何解决更简单的情况。实验结果表明，Evoke
    显著优于现有方法。例如，在逻辑谬误检测这一具有挑战性的任务中，Evoke 的得分超过 80，而所有其他基线方法都难以达到 20。
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Consider an intriguing trio that at first glance seems unrelated: bumble bees,
    cell phones, and exciting news. At a superficial level, their commonality might
    note their plural forms; however, a more profound analysis reveals a shared essence:
    they all “create a buzz.” This comparison sheds light on the depth and intricacy
    of human cognitive processes. At the heart of such processes is critical thinking,
    the ability to conceptualize, analyze, question, and evaluate ideas and beliefs.
    As we transition to the domain of artificial intelligence, it is observed that
    large language models (LLMs) have remarkably evolved as general problem solvers,
    urging us to ponder:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 试想一下一个有趣的三重奏，乍看之下似乎毫无关联：蜜蜂、手机和激动人心的新闻。在表面层面，它们的共同点可能在于它们的复数形式；然而，更深层的分析揭示了一个共同的本质：它们都“引起了轰动”。这种比较揭示了人类认知过程的深度和复杂性。这些过程的核心是批判性思维，即概念化、分析、质疑和评估思想和信念的能力。当我们过渡到人工智能领域时，观察到大型语言模型（LLMs）作为通用问题解决者有了显著的发展，这促使我们思考：
- en: Can LLMs think on their own?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 能够自主思考吗？
- en: 'In practice, we observe that existing prompting methods are inadequate in evoking
    the critical thinking abilities of LLMs. For example, in Figure [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author
    Prompt Editing"), we show two prompts for solving a common concept task. From
    Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Evoke: Evoking Critical Thinking
    Abilities in LLMs via Reviewer-Author Prompt Editing") (left), we see that for
    the input trio “bumble bees, cell phones, and exciting news”, the LLM outputs
    a superficial common concept “plural form” using the hand-crafted prompt. On the
    other hand, with the prompt generated by the proposed method, the LLM demonstrates
    much deeper understanding about the task , i.e., it generates the correct answer
    “can cause a buzz” (see Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"),
    right). These results indicate that the quality of prompts are directly related
    to the performance of LLMs. In this work, we focus on prompting methods that enables
    LLMs to think on their own.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '实践中，我们观察到现有的提示方法在激发LLMs的批判性思维能力方面不足。例如，在图 [2](#S1.F2 "Figure 2 ‣ 1 Introduction
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing") 中，我们展示了两个用于解决常见概念任务的提示。从图 [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")（左）中，我们看到对于输入三元组“蜜蜂、手机和令人兴奋的新闻”，LLM使用手工提示输出了一个肤浅的共同概念“复数形式”。另一方面，使用所提出的方法生成的提示，LLM对任务的理解要深刻得多，即生成了正确的答案“可以引起轰动”（见图
    [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Evoke: Evoking Critical Thinking Abilities
    in LLMs via Reviewer-Author Prompt Editing")，右）。这些结果表明提示的质量与LLMs的表现直接相关。在这项工作中，我们专注于使LLMs能够独立思考的提示方法。'
- en: The current prompting methodologies exhibit significant drawbacks. Many prompting
    methods are ad hoc because of their human-in-the-loop development paradigm. In
    such a process, given a target task, we first draft an initial prompt. Then, we
    refine the prompt using techniques such as chain-of-thought, few-shot demonstrations,
    and coding-style problem descriptions (Wei et al., [2022c](#bib.bib27), [a](#bib.bib25);
    Gao et al., [2023](#bib.bib5)) based on the model’s performance on the target
    task. We note that in practice, a hand-crafted prompt optimized for one task rarely
    translates to satisfactory performance in another task (Zhang et al., [2023](#bib.bib31)).
    Therefore, each task becomes a new expedition, with its own set of trials, errors,
    and validations. Such an ad hoc human-in-the-loop development procedure introduces
    extensive human labor requirements, which significantly hinder the applicability
    of LLMs in real-world applications.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的提示方法存在显著缺陷。许多提示方法由于其人类参与的开发模式而显得临时。在这种过程中，给定一个目标任务，我们首先起草一个初始提示。然后，我们基于模型在目标任务上的表现，使用链式思维、少量示例和编程风格的问题描述等技术来优化提示（Wei
    et al., [2022c](#bib.bib27), [a](#bib.bib25); Gao et al., [2023](#bib.bib5)）。我们注意到，实际上，针对一个任务优化的手工提示很少能在另一个任务中表现出令人满意的效果（Zhang
    et al., [2023](#bib.bib31)）。因此，每个任务都成为一个新的探索，有着自己的试验、错误和验证。这种临时的人类参与的开发过程引入了大量的人力需求，显著阻碍了LLMs在实际应用中的适用性。
- en: Existing works develop algorithms to automatically generate prompts instead
    of relying on ad hoc human optimization (Shin et al., [2020](#bib.bib17); Honovich
    et al., [2022](#bib.bib6); Zhou et al., [2022](#bib.bib32)). However, these methods
    often lack feedback loops, such that the refinement procedure essentially performs
    a random search. For example, in each refinement iteration, Zhou et al. ([2022](#bib.bib32))
    simply rephrases the prompt into multiple candidates, and then select the candidate
    that yields the best performance as the refined prompt. Note that such a procedure
    fails to learn from past successes and failures, such that refined prompt does
    not enrich the original prompt with additional context.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现有工作开发了算法以自动生成提示，而不是依赖于临时的人类优化（Shin et al., [2020](#bib.bib17); Honovich et
    al., [2022](#bib.bib6); Zhou et al., [2022](#bib.bib32)）。然而，这些方法往往缺乏反馈循环，使得优化过程实际上进行的是随机搜索。例如，在每次优化迭代中，Zhou
    et al. ([2022](#bib.bib32))仅仅将提示重新表述为多个候选项，然后选择表现最佳的候选项作为优化后的提示。请注意，这样的过程未能从过去的成功和失败中学习，因此优化后的提示未能为原始提示增加额外的背景信息。
- en: '![Refer to caption](img/a4546b9ce09c5fccf150b8dcdc99749a.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/a4546b9ce09c5fccf150b8dcdc99749a.png)'
- en: 'Figure 1: Comparison between hand-crafted and Evoke prompts.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：手工提示与Evoke提示的比较。
- en: '![Refer to caption](img/3beb54ed185848fb921290780728ee11.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3beb54ed185848fb921290780728ee11.png)'
- en: 'Figure 2: Simplified workflow of Evoke.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：Evoke 的简化工作流程。
- en: 'We propose Evoke, which addresses the aforementioned drawbacks by leveraging
    an author-reviewer paradigm. In this paradigm, there are two distinct purposes
    an LLM can serve: one instance as an author (LLM-Author) tasked with editing prompts,
    and another instance as a reviewer (LLM-Reviewer) tasked with evaluating the quality
    of the prompts generated by the LLM-Author. Each role is played independently
    by separate instances of the same LLM.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了 Evoke，它通过利用作者-审稿人范式解决了上述缺陷。在这个范式中，LLM 可以担任两个不同的角色：一个实例作为作者（LLM-Author），负责编辑提示，另一个实例作为审稿人（LLM-Reviewer），负责评估
    LLM-Author 生成的提示的质量。每个角色由同一个 LLM 的独立实例扮演。
- en: Critical thinking is not something you do once with an issue and then drop it.
    It requires that we update our knowledge as new information comes in.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 批判性思维不是你对一个问题做一次就放弃的事情。它要求我们在新信息到来时更新我们的知识。
- en: Daniel Levitin
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 丹尼尔·列维廷
- en: 'The essence of this quote resonates with the feedback loop in the workflow
    of Evoke, as depicted in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing").
    The workflow comprises three steps: First, the LLM-Author edits prompts from previous
    iterations, taking into account the past edits and the feedback from the LLM-Reviewer.
    Second, the LLM-Reviewer scores the revised prompts from the LLM-Author, and the
    top-n candidates with the highest scores are selected for subsequent procedures.
    The LLM-Reviewer employs a memory module that stores history edits, prompts and
    task accuracy of history prompts. Finally, the task accuracy for each instruction
    is computed.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '这句话的本质与 Evoke 工作流程中的反馈循环相呼应，如图 [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")
    所示。工作流程包括三个步骤：首先，LLM-Author 根据过去的编辑和 LLM-Reviewer 的反馈编辑前几个迭代的提示。其次，LLM-Reviewer
    对 LLM-Author 修改后的提示进行评分，选择得分最高的前 n 个候选项进入后续程序。LLM-Reviewer 使用一个记忆模块来存储历史编辑、提示和任务准确性。最后，计算每个指令的任务准确性。'
- en: 'To further enhance the efficacy of Evoke, we propose a data selection strategy.
    In this strategy, only the hard samples selected by a selector are exposed to
    the LLM. The intuition is that the LLM can develop deeper understanding of the
    tasks out of the hard samples, while it already knows how to solve the easier
    cases. Through extensive experiments (see Figure [10](#S4.F10 "Figure 10 ‣ 4.4
    Analysis ‣ 4 Experiments ‣ Evoke: Evoking Critical Thinking Abilities in LLMs
    via Reviewer-Author Prompt Editing") in the experiments), we see that retaining
    the hard samples indeed improves efficacy of Evoke.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '为了进一步提高 Evoke 的效率，我们提出了一种数据选择策略。在这个策略中，只有由选择器选择的困难样本会暴露给 LLM。直觉是，LLM 可以通过这些困难样本更深入地理解任务，而对于较简单的情况，它已经知道如何解决。通过大量实验（参见实验中的图
    [10](#S4.F10 "Figure 10 ‣ 4.4 Analysis ‣ 4 Experiments ‣ Evoke: Evoking Critical
    Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")），我们发现保留困难样本确实提高了
    Evoke 的效率。'
- en: We conduct extensive experiments to demonstrate the effectiveness of Evoke.
    Specifically, on eight tasks from the Instruction Induction (Honovich et al.,
    [2022](#bib.bib6)) dataset and the Big Bench Instruction Induction (Zhou et al.,
    [2022](#bib.bib32)) dataset, we show that Evoke significantly outperforms existing
    automatic prompt engineering approaches. For example, on the challenging logical
    fallacy detection task, Evoke achieves a score of over 80, while all the baseline
    methods struggle to reach 20\. We also show that Evoke can improve LLMs’ robustness
    against adversarial attacks, and can also handle fine-grained named entity recognition
    tasks with exceptional performance. As an example, Evoke achieves significant
    performance gain on an adversarially constructed dataset, indicating that the
    proposed method can improve robustness of LLMs. Additionally, we provide detailed
    analysis on the effectiveness of each component of Evoke.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行广泛的实验以证明Evoke的有效性。具体而言，在来自Instruction Induction (Honovich et al., [2022](#bib.bib6))
    数据集和Big Bench Instruction Induction (Zhou et al., [2022](#bib.bib32)) 数据集的八项任务上，我们展示了Evoke显著优于现有的自动化提示工程方法。例如，在具有挑战性的逻辑谬误检测任务中，Evoke的得分超过80，而所有基线方法都难以达到20。我们还展示了Evoke可以提高LLM对对抗攻击的鲁棒性，并且能够在细粒度命名实体识别任务中表现出色。例如，Evoke在一个对抗性构造的数据集上取得了显著的性能提升，表明该方法可以提高LLM的鲁棒性。此外，我们提供了对Evoke各组件有效性的详细分析。
- en: 2 Related Work
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 'Large Language Models. Recently, LLMs have shown emergent abilities—capabilities
    to perform tasks they weren’t explicitly trained for (Wei et al., [2022a](#bib.bib25),
    [b](#bib.bib26); Bubeck et al., [2023](#bib.bib1)). This includes common sense
    question answering, code generation, and cross-domain problem solving, enriching
    their utility across unforeseen domains (Chen et al., [2021](#bib.bib2); Sarsa
    et al., [2022](#bib.bib15); Thirunavukarasu et al., [2023](#bib.bib21); Huang
    and Chang, [2022](#bib.bib8); Du et al., [2023](#bib.bib4)). Subsequently, adapting
    LLMs to specific problems has drawn attention, and several methods have been proposed:
    Reinforcement Learning from Human Feedback (RLHF Ouyang et al. [2022](#bib.bib13)),
    efficient fine-tuning (Hu et al., [2022](#bib.bib7); Dettmers et al., [2023](#bib.bib3)),
    and prompt engineering (White et al., [2023](#bib.bib28)), among others. Each
    method has its pros and cons. For instance, RLHF can significantly improve performance
    but may require extensive human annotations. Efficient fine-tuning, on the other
    hand, can be less resource-intensive but might fall short in achieving the desired
    level of task-specific optimization. Prompt engineering, while innovative, may
    require a well-crafted prompt to effectively guide the model towards accurate
    outputs.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型。近期，LLM展现出了突现的能力——执行那些它们并未明确训练过的任务的能力（Wei et al., [2022a](#bib.bib25),
    [b](#bib.bib26); Bubeck et al., [2023](#bib.bib1)）。这包括常识问答、代码生成和跨领域问题解决，丰富了它们在未预见领域中的实用性（Chen
    et al., [2021](#bib.bib2); Sarsa et al., [2022](#bib.bib15); Thirunavukarasu et
    al., [2023](#bib.bib21); Huang and Chang, [2022](#bib.bib8); Du et al., [2023](#bib.bib4)）。随后，将LLM适应特定问题引起了关注，并提出了几种方法：人类反馈的强化学习
    (RLHF Ouyang et al. [2022](#bib.bib13))、高效微调 (Hu et al., [2022](#bib.bib7); Dettmers
    et al., [2023](#bib.bib3)) 和提示工程 (White et al., [2023](#bib.bib28)) 等。每种方法都有其优缺点。例如，RLHF可以显著提高性能，但可能需要大量的人类注释。另一方面，高效微调可能资源需求较少，但在实现所需的任务特定优化水平时可能不尽如人意。提示工程虽具有创新性，但可能需要精心设计的提示来有效引导模型获得准确的输出。
- en: In-Context Learning and Prompt Engineering. In-Context Learning (ICL) refers
    to the ability of LLMs to learn a new task from a small set of examples presented
    within the context (the prompt) at inference time, without updating any parameters
    (Wei et al., [2022a](#bib.bib25)). This paradigm has significantly improved the
    capabilities of LLMs across various tasks. Many studies have explored the reasons
    behind such improvements, examining aspects like Bayesian optimization and the
    difficulty of demonstrations (Xie et al., [2022](#bib.bib29); Min et al., [2022](#bib.bib12);
    Liu et al., [2022](#bib.bib11); Yoo et al., [2022](#bib.bib30)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文学习和提示工程。上下文学习 (ICL) 指的是LLM在推理时从小量示例中学习新任务的能力（Wei et al., [2022a](#bib.bib25)），无需更新任何参数。这一范式显著提高了LLM在各种任务中的能力。许多研究探讨了这些改进的原因，考察了诸如贝叶斯优化和示例难度等方面（Xie
    et al., [2022](#bib.bib29); Min et al., [2022](#bib.bib12); Liu et al., [2022](#bib.bib11);
    Yoo et al., [2022](#bib.bib30)）。
- en: Prompt engineering plays a pivotal role in facilitating ICL. It entails the
    design of prompts that arm the LLM with the essential information needed to learn
    and adeptly perform the new task. Each prompt essentially sets the stage for the
    LLM, enclosing the task’s requirements and guiding the model towards producing
    the desired output. By carefully crafting prompts, it is possible to leverage
    the inherent capability of LLMs, enabling them to tackle a wide range of tasks
    even with limited or no prior explicit training on those tasks. Recently, methods
    such as Chain-of-Thought (CoT), Zero-CoT, Self-Consistency, Program-Aided, and
    Few-Shot Prompting have been demonstrated to be effective (Wei et al., [2022c](#bib.bib27);
    Kojima et al., [2022](#bib.bib10); Wang et al., [2022](#bib.bib24); Gao et al.,
    [2023](#bib.bib5); Reynolds and McDonell, [2021](#bib.bib14)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程在促进 ICL 中起着关键作用。它涉及设计提示，为 LLM 提供完成新任务所需的基本信息。每个提示本质上为 LLM 设置了舞台，包含任务要求，并引导模型产生所需的输出。通过精心设计提示，可以利用
    LLM 的固有能力，使其能够处理广泛的任务，即使对这些任务没有明确的先前训练。最近，像 Chain-of-Thought (CoT)、Zero-CoT、Self-Consistency、Program-Aided
    和 Few-Shot Prompting 等方法已被证明是有效的 (Wei 等人，[2022c](#bib.bib27); Kojima 等人，[2022](#bib.bib10);
    Wang 等人，[2022](#bib.bib24); Gao 等人，[2023](#bib.bib5); Reynolds 和 McDonell，[2021](#bib.bib14))。
- en: Automatic Prompt Engineering. The existing methodologies for automating discrete
    prompt optimization have their roots in instruction induction, as discussed by
    Honovich et al. [2022](#bib.bib6). It was discovered that LLMs can generate natural
    language instructions based on a small number of input-output pair examples. Building
    on this, Zhou et al. ([2022](#bib.bib32)) proposed a new algorithm for the automatic
    generation and selection of instructions for LLMs. The algorithm, named Automatic
    Prompt Engineer (APE), is capable of generating prompts that achieve human-level
    performance across a diverse range of NLP tasks. Work has also been done on automating
    prompt generation for specific domains like code generation, as discussed in Shrivastava
    et al. [2023](#bib.bib18).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 自动提示工程。现有的离散提示优化自动化方法起源于指令归纳，如 Honovich 等人 [2022](#bib.bib6) 所讨论的那样。研究发现，LLM
    可以根据少量的输入-输出对示例生成自然语言指令。在此基础上，Zhou 等人 ([2022](#bib.bib32)) 提出了一个新的算法，用于自动生成和选择
    LLM 的指令。该算法名为自动提示工程师（APE），能够生成在多种 NLP 任务中实现人类水平表现的提示。还对特定领域如代码生成的自动提示生成进行了研究，如
    Shrivastava 等人 [2023](#bib.bib18) 所讨论的那样。
- en: 3 Iterative Reviewer-Author Prompt Editing
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 迭代式的 Reviewer-Author 提示编辑
- en: 3.1 Overview
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 概述
- en: 'In Evoke, the same LLM plays two different roles: an author (LLM-Author) that
    is in charge of editing and refine prompts, and a reviewer (LLM-Reviewer) that
    is in charge of scoring the refined prompts. We use two different prompts for
    the author’s and the reviewer’s task.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Evoke 中，同一 LLM 扮演两个不同的角色：负责编辑和完善提示的作者（LLM-Author），以及负责对完善后的提示进行评分的审阅者（LLM-Reviewer）。我们为作者和审阅者的任务使用了两个不同的提示。
- en: '$\diamond$ LLM-Author edits and generates new prompts based on feedback from
    LLM-Reviewer. The prompt for LLM-Author consists of several components:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ LLM-Author 根据 LLM-Reviewer 的反馈编辑并生成新的提示。LLM-Author 的提示由多个组件组成：
- en: a
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a
- en: 'Input for editing: Current task instruction to be refined and training data;'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编辑输入：当前任务指令待完善和训练数据；
- en: b
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: b
- en: 'Instruction for editing: “We’ve provided pairs consisting of inputs, the teacher’s
    correct answers, and the students’ responses. Please review the incorrect responses
    from the students and summarize key points that could be adjusted in the instruction
    to enhance student accuracy. Highlight major edits and present the updated task
    instruction.”;'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编辑指令：“我们提供了由输入、教师的正确答案和学生的回应组成的对。请检查学生的不正确回应，并总结可以调整指令的关键点，以提高学生的准确性。突出主要编辑，并呈现更新后的任务指令。”；
- en: c
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: c
- en: 'Memory: prior history (edits, scores).'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记忆：先前历史（编辑，评分）。
- en: LLM-Author refines the instructions (prompts for the given task) by utilizing
    the training data and a memory component. We note that the memory consists of
    all prior (edit, score) pairs, where the score comes from LLM-Reviewer. This memory
    component enables LLM-Author to execute increasingly effective edits, drawing
    upon feedback from previous edits.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-Author 利用训练数据和记忆组件来完善指令（给定任务的提示）。我们注意到记忆包含所有先前的（编辑，评分）对，其中评分来自 LLM-Reviewer。这个记忆组件使得
    LLM-Author 能够执行越来越有效的编辑，并借鉴之前编辑的反馈。
- en: 'Require: Training set; Initial prompt for the target task (i.e., the one we
    want to refine).// InitializationLLM-Selector: Initialize data scoring instruction.LLM-Author:
    Initialize prompt editing instruction.LLM-Review: Initialize prompt reviewing
    instruction.while *$t\leq T$* do        // LLM-Selector       Assign difficulty
    scores for each data point in the training set.       Select a training subset
    based on the difficulty level.        // LLM-Author       LLM-Author generates
    multiple prompts based on the training data and its own memory.        // LLM-Reviewer      
    LLM-Reviewer scores the quality of each generated prompt from LLM-Author based
    on its own memory.       Select top-n prompts based on the generated scores from
    LLM-Reviewer.       Get task accuracy for all prompts.        // Memory update      
    Memory of LLM-Author appends (edits, scores).       Memory of LLM-Reviewer appends
    (edits, prompts, task accuracy).Return: The prompt with the highest task accuracy.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 需求：训练集；目标任务的初始提示（即我们想要优化的提示）。// 初始化LLM-选择器：初始化数据评分指令。LLM-作者：初始化提示编辑指令。LLM-审阅者：初始化提示审阅指令。while
    *$t\leq T$* do       // LLM-选择器       为训练集中的每个数据点分配难度分数。       根据难度水平选择一个训练子集。       //
    LLM-作者       LLM-作者根据训练数据和自身记忆生成多个提示。       // LLM-审阅者       LLM-审阅者根据自身记忆对 LLM-作者生成的每个提示进行评分。       根据
    LLM-审阅者生成的分数选择前 n 个提示。       获取所有提示的任务准确性。       // 记忆更新       LLM-作者的记忆附加（编辑、评分）。       LLM-审阅者的记忆附加（编辑、提示、任务准确性）。返回：任务准确性最高的提示。
- en: Algorithm 1 Evoke
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 引发
- en: '$\diamond$ LLM-Reviewer scores the quality of prompts generated by LLM-Author.
    The input prompt for LLM-Reviewer consists of several components:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ LLM-审阅者对 LLM-作者生成的提示质量进行评分。LLM-审阅者的输入提示由几个部分组成：
- en: a
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a
- en: 'Input for scoring: problem description and current instruction from LLM-Author;'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评分输入：来自 LLM-作者的问题描述和当前指令；
- en: b
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: b
- en: 'Instruction for scoring: “Please rate the following instruction on a scale
    of 1 to 10, where 10 represents the highest level of clarity in problem description,
    execution steps, and a comprehensive explanation of the problem.”;'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评分说明：“请根据 1 到 10 的评分标准对以下说明进行评分，其中 10 代表问题描述、执行步骤以及问题的全面解释的最高清晰度。”
- en: c
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: c
- en: 'Memory: prior (edits, instructions, task accuracy).'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记忆：之前的（编辑、指令、任务准确性）。
- en: The instructions generated by LLM-Author are forwarded to LLM-Reviewer for evaluation.
    Based on the scores generated by LLM-Reviewer, only a subset of high-scoring candidates
    is selected to move on to the subsequent iteration. Through this iterative editing
    process between LLM-Author and LLM-Reviewer, LLM-Author can refine instructions
    in each iteration.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-作者生成的指令会转发给 LLM-审阅者进行评估。根据 LLM-审阅者生成的分数，只有部分高分候选项被选中进入下一轮迭代。通过 LLM-作者和 LLM-审阅者之间的迭代编辑过程，LLM-作者可以在每次迭代中优化指令。
- en: 'Details of the algorithm can be found in Algorithm [1](#alg1 "In 3.1 Overview
    ‣ 3 Iterative Reviewer-Author Prompt Editing ‣ Evoke: Evoking Critical Thinking
    Abilities in LLMs via Reviewer-Author Prompt Editing").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的详细信息可以在算法[1](#alg1 "在 3.1 概述 ‣ 3 迭代式审阅者-作者提示编辑 ‣ 引发：通过审阅者-作者提示编辑引发 LLM 的批判性思维能力")中找到。
- en: '![Refer to caption](img/e1de64953a4cd830f2a2dabd1e5ff7c0.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e1de64953a4cd830f2a2dabd1e5ff7c0.png)'
- en: 'Figure 3: Illustration of Prompt Editing for the first three steps in the Task
    of Movie Recommendation within Big Bench.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：大基准中电影推荐任务前三级的提示编辑示意图。
- en: 'To illustrate the effectiveness of Evoke, first three edits from the Movie
    Recommendation task in Big Bench are presented in Figure [3](#S3.F3 "Figure 3
    ‣ 3.1 Overview ‣ 3 Iterative Reviewer-Author Prompt Editing ‣ Evoke: Evoking Critical
    Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"). To start with,
    the prompt contains the basic task instruction. Next, it extracts key factors
    considered in movie recommendation, such as the genre of each movie, the distance
    between the given movies and the movies the user has watched before, and the popularity
    of the movies. In the final step, a well-explained example is presented with a
    detailed explanation following aforementioned factors. In summary, Evoke successfully
    concludes the key components of movie recommendation, and curates a demonstration
    with detailed explanation.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '为了说明Evoke的有效性，首先在图[3](#S3.F3 "Figure 3 ‣ 3.1 Overview ‣ 3 Iterative Reviewer-Author
    Prompt Editing ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author
    Prompt Editing")中展示了Big Bench电影推荐任务的前三个编辑。首先，提示包含基本任务指令。接下来，它提取了电影推荐中考虑的关键因素，例如每部电影的类型、给定电影与用户之前观看过的电影之间的距离，以及电影的受欢迎程度。在最后一步中，展示了一个解释充分的示例，并详细解释了上述因素。总之，Evoke成功总结了电影推荐的关键组成部分，并提供了详细解释的演示。'
- en: 3.2 Data Selection via LLM-Selector
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 通过LLM-选择器的数据选择
- en: 'In practice, we find that not all samples are equally important to model performance
    (see Figure [10](#S4.F10 "Figure 10 ‣ 4.4 Analysis ‣ 4 Experiments ‣ Evoke: Evoking
    Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")). In
    particular, we find that even without prompt refinement, the LLM already knows
    how to solve some “easier” cases. Therefore, we only use “hard” samples in each
    refinement iteration. Specifically, we assign a third role besides an author a
    reviewer to the LLM: a data selector. The LLM-Selector evaluates the difficulty
    level (on a scale of 1 to 10) of each data point by assessing, based on the current
    task instruction, how challenging it is to derive the correct answer from the
    input. The input prompt for LLM-Selector consists of several components:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '在实际操作中，我们发现并非所有样本对模型性能同等重要（见图[10](#S4.F10 "Figure 10 ‣ 4.4 Analysis ‣ 4 Experiments
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing")）。特别是，我们发现即使没有提示改进，LLM已经知道如何解决一些“较简单”的案例。因此，我们只在每次改进迭代中使用“难”的样本。具体来说，我们为LLM分配了除作者和审阅者之外的第三个角色：数据选择器。LLM-选择器通过根据当前任务指令评估从输入中得出正确答案的难度（在1到10的范围内）来评估每个数据点的难度级别。LLM-选择器的输入提示包含多个组件：'
- en: a
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: a
- en: 'Input for evaluating difficulty level: current instruction and input-output
    pair;'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估难度级别的输入：当前指令和输入-输出对；
- en: b
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: b
- en: 'Instruction for evaluating difficulty level: “As an experienced teacher with
    insight into the various levels of difficulty of exam questions, please rate the
    following question on a scale of 1 to 10, considering factors such as conceptual
    understanding, application of knowledge, problem-solving skills, time required,
    clarity of language, and accessibility, where 1 denotes extremely easy and 10
    denotes extremely difficult.”.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评估难度级别的指令：“作为一位对考试问题难度级别有深入了解的经验丰富的教师，请根据概念理解、知识应用、问题解决能力、所需时间、语言清晰度和可及性等因素，对以下问题进行1到10的评分，其中1表示非常容易，10表示非常困难。”
- en: Empirically, we can further improve effectiveness of Evoke by using such a data
    selection strategy.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 从经验上看，我们可以通过使用这样的数据选择策略进一步提高Evoke的有效性。
- en: 4 Experiments
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: We conduct extensive experiments to demonstrate the effectiveness of Evoke.
    We show that for any given task, the prompts generated by Evoke include clear
    definitions and well-structured task execution steps. Moreover, these prompts
    feature demonstrations accompanied by detailed explanations. In all experiments,
    we utilize the Azure OpenAI API service (GPT-4) for the involved LLMs.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了广泛的实验以展示Evoke的有效性。我们展示了对于任何给定的任务，Evoke生成的提示包括清晰的定义和结构良好的任务执行步骤。此外，这些提示还配有详细解释的演示。在所有实验中，我们使用了Azure
    OpenAI API服务（GPT-4）来处理涉及的LLMs。
- en: 4.1 Main Results
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 主要结果
- en: Datasets. We perform a comprehensive evaluation on eight tasks from Instruction
    Induction (Honovich et al., [2022](#bib.bib6)) and Big Bench Instruction Induction
    (BBII) (Zhou et al., [2022](#bib.bib32)), including
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。我们对来自Instruction Induction (Honovich et al., [2022](#bib.bib6))和Big Bench
    Instruction Induction (BBII) (Zhou et al., [2022](#bib.bib32))的八个任务进行了全面评估，包括
- en: 'orthography starts with: Extract the words starting with a given letter from
    the input sentence.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正字法起始于：从输入句子中提取以给定字母开头的单词。
- en: 'common concept: Find a common characteristic for the given objects.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 常见概念：为给定对象找到一个共同特征。
- en: 'rhymes: Write a word that rhymes with the input word.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 押韵：写一个与输入单词押韵的单词。
- en: 'movie recommendation: Recommend movies similar to the given list of movies.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 电影推荐：推荐与给定电影列表相似的电影。
- en: 'logical fallacy detection: Detect informal and formal logical fallacies.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑谬误检测：检测非正式和正式的逻辑谬误。
- en: 'presuppositions as nli: Determine whether the first sentence entails or contradicts
    the second.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 预设作为 NLI：确定第一个句子是否蕴含或与第二个句子矛盾。
- en: 'winowhy: Evaluate the reasoning in answering Winograd Schema Challenge questions.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: winowhy：评估回答 Winograd Schema Challenge 问题的推理过程。
- en: 'epistemic reasoning: Determine whether one sentence entails the next.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 认识论推理：确定一个句子是否蕴含下一个句子。
- en: These tasks covers a wide range of natural language understanding, reasoning
    and inference tasks. For each task, we divide the dataset randomly into two sets,
    60% of the data is allocated for training (prompt refinement) and the remaining
    40% is for testing (prompt evaluation).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务涵盖了广泛的自然语言理解、推理和推断任务。对于每个任务，我们将数据集随机分成两组，60% 的数据用于训练（提示优化），其余 40% 用于测试（提示评估）。
- en: 'Baselines. We compare our methods against two baselines: human curated prompts
    (Human) from Honovich et al. ([2022](#bib.bib6)); Suzgun et al. ([2022](#bib.bib20))
    and automatic prompt engineer (APE) proposed in (Zhou et al., [2022](#bib.bib32)).
    APE first deduces an initial prompt from input-output pairs, and subsequently
    employs LLMs to refine and generate new prompt candidates. However, prompts are
    simply paraphrased during the refinement process of APE, which largely resembles
    random searching in the space of all possible prompts.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基准对比。我们将我们的方法与两个基准进行比较：Honovich 等人（[2022](#bib.bib6)）和 Suzgun 等人（[2022](#bib.bib20)）提供的人工策划提示（Human），以及
    (Zhou et al., [2022](#bib.bib32)）提出的自动提示工程师（APE）。APE 首先从输入-输出对中推导出初始提示，然后使用 LLMs
    来优化和生成新的提示候选。然则，在 APE 的优化过程中，提示仅仅是被改述，这在很大程度上类似于在所有可能的提示空间中随机搜索。
- en: 'Main Results. Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Main Results ‣ 4 Experiments
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing") demonstrates experimental results. We observe that Evoke outperforms
    all the baselines in all eight tasks.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '主要结果。图 [4](#S4.F4 "图 4 ‣ 4.1 主要结果 ‣ 4 实验 ‣ Evoke: 通过审稿人-作者提示编辑激发 LLM 的批判性思维能力")
    展示了实验结果。我们观察到 Evoke 在所有八项任务中都优于所有基准。'
- en: 'For example, on the challenging logical fallacy detection task from BBII, performance
    of Evoke is more than 80, while performance of both APE and Human are below 20.
    This is because Evoke is adept at conceptualizing the core definition of a task,
    decomposing a complex task into smaller subtasks, and curating relevant demonstrations
    accompanied by detailed explanations. To demonstrate the power of Evoke, we show
    the generated prompt for logical fallacy detection in Table [1](#S4.T1 "Table
    1 ‣ 4.1 Main Results ‣ 4 Experiments ‣ Evoke: Evoking Critical Thinking Abilities
    in LLMs via Reviewer-Author Prompt Editing"). We see that the prompt begins with
    a clear task introduction and objective, followed by a fine-grained definition
    of logical fallacy. It then articulates the criteria for evaluation and the task
    steps to follow. Lastly, it provides a list of common logical fallacies, each
    accompanied by a detailed description. Additionally, a well-structured prompt
    for epistemic reasoning is presented in Table [2](#S4.T2 "Table 2 ‣ 4.1 Main Results
    ‣ 4 Experiments ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author
    Prompt Editing").'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，在 BBII 的挑战性逻辑谬误检测任务中，Evoke 的表现超过了 80，而 APE 和 Human 的表现均低于 20。这是因为 Evoke
    擅长概念化任务的核心定义，将复杂任务分解为更小的子任务，并策划相关的示例及详细解释。为了展示 Evoke 的强大能力，我们在表 [1](#S4.T1 "表
    1 ‣ 4.1 主要结果 ‣ 4 实验 ‣ Evoke: 通过审稿人-作者提示编辑激发 LLM 的批判性思维能力") 中展示了逻辑谬误检测的生成提示。我们看到提示以清晰的任务介绍和目标开始，接着是逻辑谬误的细化定义。然后，它阐明了评估标准和任务步骤。最后，提供了常见逻辑谬误的列表，每个都有详细描述。此外，表
    [2](#S4.T2 "表 2 ‣ 4.1 主要结果 ‣ 4 实验 ‣ Evoke: 通过审稿人-作者提示编辑激发 LLM 的批判性思维能力") 中展示了一个结构良好的认识论推理提示。'
- en: '![Refer to caption](img/af5826c7e2a6fa6efd85b39591ee56b8.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/af5826c7e2a6fa6efd85b39591ee56b8.png)'
- en: 'Figure 4: Results on eight tasks from the Instruction Induction and the Big
    Bench Instruction Induction datasets. We report the average accuracy over three
    runs.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：来自 Instruction Induction 和 Big Bench Instruction Induction 数据集的八个任务结果。我们报告了三次运行的平均准确率。
- en: 'Table 1: Prompt generated by Evoke for logical fallacy detection.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：Evoke 生成的逻辑谬误检测提示。
- en: '| Prompt from Evoke | Breakdown |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Evoke 提示 | 解析 |'
- en: '| In this task, you are required to identify both informal and formal logical
    fallacies in the provided input statements. Your response should be a binary value:
    return 1 if the query is logically valid (i.e., free from any logical fallacies),
    and return 0 if the query is logically invalid (i.e., contains at least one logical
    fallacy). | Introduction and objective |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 在此任务中，你需要识别提供的输入陈述中的非正式和正式逻辑谬误。你的回答应为二值：如果查询逻辑有效（即没有逻辑谬误），返回1；如果查询逻辑无效（即包含至少一个逻辑谬误），返回0。
    | 介绍与目标 |'
- en: '| A logical fallacy refers to an error in reasoning. Informal fallacies are
    often content-dependent, such as appealing to irrelevant authority or making hasty
    generalizations. Formal fallacies, on the other hand, are structural errors in
    reasoning that occur regardless of the content. | Definition of logical fallacy
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑谬误指的是推理中的错误。非正式谬误通常依赖于内容，例如诉诸无关权威或草率概括。而形式谬误则是推理中的结构性错误，无论内容如何都会出现。 | 逻辑谬误定义
    |'
- en: '| It is crucial to consider the structure and the substance of the argument,
    evaluating whether the conclusions follow logically from the premises, and whether
    the premises and assumptions are factual and valid. Be cautious not to let personal
    beliefs interfere with your analysis. | Evaluation criteria |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 重要的是要考虑论证的结构和内容，评估结论是否从前提逻辑上得出，以及前提和假设是否真实有效。要小心不要让个人信仰干扰你的分析。 | 评价标准 |'
- en: '| For each given pair, compare the input statement against the principles of
    logical reasoning, to determine whether it contains a logical fallacy or not.
    Ensure your answer reflects the presence or absence of logical fallacies, thus
    determining the logical validity or invalidity of the statement. | Task steps
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 对于每对给定的陈述，将输入陈述与逻辑推理原则进行比较，以确定是否包含逻辑谬误。确保你的回答反映逻辑谬误的存在或不存在，从而判断陈述的逻辑有效性或无效性。
    | 任务步骤 |'
- en: '| Here are some common examples of logical fallacies: - Ad Hominem: {details}
    - Appeal to Nature: {details} - Hasty Generalization: {details} - Post Hoc: {details}
    - False Cause: {details} | Common examples of logical fallacy |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 以下是一些常见的逻辑谬误示例： - 人身攻击：{细节} - 诉诸自然：{细节} - 草率概括：{细节} - 事后诸葛亮：{细节} - 错误因果关系：{细节}
    | 常见逻辑谬误示例 |'
- en: 'Table 2: Prompt generated by Evoke for epistemic reasoning.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：Evoke 生成的认识论推理提示。
- en: '| Prompt from Evoke | Breakdown |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Evoke 提示 | 解析 |'
- en: '| In this task, your goal is to determine whether the statement in the “Hypothesis”
    logically follows from the statement in the “Premise.” This is known as entailment.
    If the “Hypothesis” statement is a logical consequence of the “Premise” statement,
    then it is an entailment. If it is not, then it is a non-entailment. | Introduction
    and objective |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 在此任务中，你的目标是确定“假设”中的陈述是否逻辑上跟随于“前提”中的陈述。这被称为蕴涵。如果“假设”陈述是“前提”陈述的逻辑结果，那么它就是蕴涵。如果不是，则是非蕴涵。
    | 介绍与目标 |'
- en: '| -Make sure to carefully consider the relations and assumptions mentioned
    in both the “Premise” and the “Hypothesis” statements. -The entailment does not
    depend on the truth of the statements, but rather whether the logic in the “Hypothesis”
    follows from the “Premise”. -Pay close attention to the wording and structure
    of the sentences to analyze whether one entails the other. | Guidelines |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| -确保仔细考虑“前提”和“假设”陈述中的关系和假设。 -蕴涵不依赖于陈述的真实性，而是“假设”是否从“前提”中得出。 -仔细关注句子的措辞和结构，以分析是否一个陈述蕴涵另一个。
    | 指南 |'
- en: '| Examples: Entailment Premise: The sun rises in the east. Hypothesis: The
    sun rises. Explanation: The Hypothesis is a simplified version of the Premise
    and does not introduce any new information or contradictions, hence it’s an entailment.
    Non-entailment Premise: Sarah believes that all cats are black. Hypothesis: All
    cats are black. Explanation: Even though the Hypothesis is expressed in the Premise,
    it’s tied to Sarah’s belief and not presented as a fact, hence it’s a non-entailment.
    | Examples |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 示例：包含 前提：太阳从东方升起。假设：太阳升起了。解释：假设是前提的简化版本，没有引入任何新信息或矛盾，因此是包含。 不包含 前提：Sarah
    认为所有猫都是黑色的。假设：所有猫都是黑色的。解释：尽管假设在前提中表达，但它与 Sarah 的信念有关，而不是作为事实呈现，因此是不包含。 | 示例 |'
- en: '| Now, review the provided pairs of statements. Determine if the Hypothesis
    logically follows from the Premise and respond with either entailment or non-entailment.
    | Task Execution |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 现在，回顾提供的声明对。确定假设是否从前提中逻辑推导出来，并以“包含”或“不包含”响应。 | 任务执行 |'
- en: 4.2 Towards Adversarial Robustness
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 朝向对抗性鲁棒性
- en: '![Refer to caption](img/35ff2fc8d5b049a05cbf2edd23197c45.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/35ff2fc8d5b049a05cbf2edd23197c45.png)'
- en: 'Figure 5: Results on clean and adversarially attacked SST2 and QQP datasets.
    We report the average accuracy over three runs. We note that RobEnc is only applied
    to the attacked data.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：在干净和对抗攻击的 SST2 和 QQP 数据集上的结果。我们报告了三次运行的平均准确率。我们注意到 RobEnc 仅应用于被攻击的数据。
- en: Despite their superior performance, LLMs are not robust to adversarial attacks
    (Wang et al., [2023](#bib.bib23)). For example, when asking GPT-4 whether “pretty”
    is a positive word, the model can output the correct answer. However, if we ask
    whether “prettye”, a clear typo of “pretty”, is a positive word, the LLM outputs
    an opposite answer. We show that Evoke can generate prompts which alert the LLM
    in paying attention to potential typos, and thus can improve model robustness.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管表现优异，LLM 对对抗攻击并不鲁棒（Wang et al., [2023](#bib.bib23)）。例如，当问 GPT-4 “pretty” 是否是一个积极的词时，模型可以输出正确答案。然而，如果我们问“prettye”，这是“pretty”的明显拼写错误，LLM
    会输出相反的答案。我们展示了 Evoke 可以生成提示，提醒 LLM 注意潜在的拼写错误，从而提高模型鲁棒性。
- en: 'Datasets. We adopt two datasets: SST-2 (Socher et al., [2013](#bib.bib19))
    is a sentiment classification task, where we need to decide whether a movie review
    is positive or negative; and QQP (Wang et al., [2019](#bib.bib22)) is a task where
    we need to determine whether two sentences are paraphrases of each other.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。我们采用两个数据集：SST-2（Socher et al., [2013](#bib.bib19)）是一个情感分类任务，我们需要判断电影评论是积极还是消极；QQP（Wang
    et al., [2019](#bib.bib22)）是一个任务，我们需要判断两个句子是否是同义句。
- en: To evaluate whether Evoke can improve LLMs’ robustness, we add typos to the
    datasets. Specifically, we perform character-level adversarial attacks for each
    sample. In the attack, we change at most one character in each word, and we change
    at most 4 words in each sentence (Jones et al., [2020](#bib.bib9)). In this way,
    the constructed adversarial texts are human-interpretable and simulate real typos.
    As an example, one sample from SST-2 is “that’s pure pr hype”, and its corresponding
    adversarial (corrupted) sample after the attack is “tha’cs pure pr hyp”. We evaluate
    performance of different prompting methods on the corrupted samples.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 Evoke 是否能提高 LLM 的鲁棒性，我们向数据集中添加了拼写错误。具体而言，我们对每个样本执行字符级对抗攻击。在攻击中，我们在每个单词中最多更改一个字符，并且在每个句子中最多更改
    4 个单词（Jones et al., [2020](#bib.bib9)）。通过这种方式，构造的对抗文本是人类可解释的，并模拟真实的拼写错误。例如，SST-2
    的一个样本是“that’s pure pr hype”，在攻击后的相应对抗（损坏）样本是“tha’cs pure pr hyp”。我们评估不同提示方法在损坏样本上的表现。
- en: '![Refer to caption](img/169e82487f5f367bd520b7e0f998eb16.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/169e82487f5f367bd520b7e0f998eb16.png)'
- en: 'Figure 6: Prompts from APE and Evoke on adversarial attacked SST-2 task'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：来自 APE 和 Evoke 的对抗攻击 SST-2 任务提示
- en: 'Baselines. Besides APE and Evoke, we evaluate another model: RobEnc (Jones
    et al., [2020](#bib.bib9)), which is a widely-used rule-based defense approach.
    RobEnc works as a clustering denoiser to cluster and denoise potentially corrupted
    inputs into an encoding, and then the denoised encoding is fed to the subsequent
    model (e.g., GPT-4) for inference. RobEnc learns rule-based word cluster for denoising:
    for example, if the word “hallo” is clustered around the word “hello”, then all
    the “hallo” in the input will be converted to “hello”.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基线模型。除了APE和Evoke，我们还评估了另一种模型：RobEnc（Jones et al., [2020](#bib.bib9)），这是一种广泛使用的基于规则的防御方法。RobEnc作为聚类去噪器工作，将潜在损坏的输入进行聚类和去噪，得到编码，然后将去噪后的编码输入到后续模型（例如，GPT-4）进行推理。RobEnc学习基于规则的词聚类进行去噪：例如，如果“hallo”这个词被聚类到“hello”附近，那么输入中的所有“hallo”将被转换为“hello”。
- en: Results.
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果。
- en: 'Figure [5](#S4.F5 "Figure 5 ‣ 4.2 Towards Adversarial Robustness ‣ 4 Experiments
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing") summarizes experimental results. We observe that Evoke significantly
    outperforms all the baselines in all the tasks. The performance gain is more significant
    for adversarially constructed datasets, e.g., Adversarial-SST2 and Adversarial-QQP.
    To understand this, we show the prompts generated by APE and Evoke in Figure [6](#S4.F6
    "Figure 6 ‣ 4.2 Towards Adversarial Robustness ‣ 4 Experiments ‣ Evoke: Evoking
    Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"). We see
    that although the prompt from APE provides a clear instruction regarding the given
    task and acknowledges the existence of typos, it does not provide clear guidelines
    on how to address the typo. On the other hand, the prompt from Evoke provides
    detailed explanations and actionable suggestions about defending against typos.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '图[5](#S4.F5 "Figure 5 ‣ 4.2 Towards Adversarial Robustness ‣ 4 Experiments
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing")总结了实验结果。我们观察到Evoke在所有任务中显著优于所有基线模型。对于对抗性构造的数据集，例如Adversarial-SST2和Adversarial-QQP，性能提升更为显著。为了理解这一点，我们在图[6](#S4.F6
    "Figure 6 ‣ 4.2 Towards Adversarial Robustness ‣ 4 Experiments ‣ Evoke: Evoking
    Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")中展示了APE和Evoke生成的提示。我们看到，尽管APE的提示提供了关于给定任务的明确指示并确认了存在拼写错误，但并没有提供如何解决拼写错误的明确指南。另一方面，Evoke的提示提供了关于如何防御拼写错误的详细解释和可操作的建议。'
- en: '4.3 Towards Fine-Grained Tasks: Named Entity Recognition'
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 走向细粒度任务：命名实体识别
- en: 'Tasks in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Main Results ‣ 4 Experiments ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")
    and Figure [5](#S4.F5 "Figure 5 ‣ 4.2 Towards Adversarial Robustness ‣ 4 Experiments
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing") are all sentence-level classification tasks, e.g., deciding whether
    a sentence is of positive or negative sentiment. In this section, we investigate
    whether Evoke can handle more fine-grained tasks, such as token-level named entity
    recognition (Schneider et al., [2020](#bib.bib16); Zuo et al., [2023](#bib.bib33)).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '图[4](#S4.F4 "Figure 4 ‣ 4.1 Main Results ‣ 4 Experiments ‣ Evoke: Evoking Critical
    Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")和图[5](#S4.F5 "Figure
    5 ‣ 4.2 Towards Adversarial Robustness ‣ 4 Experiments ‣ Evoke: Evoking Critical
    Thinking Abilities in LLMs via Reviewer-Author Prompt Editing")中的任务都是句子级分类任务，例如，判断一个句子的情感是积极还是消极。在本节中，我们探讨了Evoke是否能够处理更细粒度的任务，例如令牌级别的命名实体识别（Schneider
    et al., [2020](#bib.bib16); Zuo et al., [2023](#bib.bib33)）。'
- en: '![Refer to caption](img/22b451a8a4275f7f73a0d79aa0b94eac.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/22b451a8a4275f7f73a0d79aa0b94eac.png)'
- en: 'Figure 7: Results of APE and Evoke on an in-house multi-lingual NER dataset.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：APE和Evoke在内部多语言NER数据集上的结果。
- en: '![Refer to caption](img/bdd7cdc0259315fdff04ab7e1fb103e4.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bdd7cdc0259315fdff04ab7e1fb103e4.png)'
- en: 'Figure 8: Prompt from Evoke on the NER task.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：Evoke在NER任务中的提示。
- en: We collect multi-lingual in-house query data from a search engine, and for each
    token in the query, our goal is to assign the token to a pre-defined class (e.g.,
    brand, location).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从搜索引擎中收集多语言的内部查询数据，对于查询中的每个令牌，我们的目标是将其分配到一个预定义的类别（例如，品牌、地点）。
- en: 'We illustrate results of Evoke on the fine-grained NER task in Figure [8](#S4.F8
    "Figure 8 ‣ 4.3 Towards Fine-Grained Tasks: Named Entity Recognition ‣ 4 Experiments
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing"). We see that Evoke significantly outperforms APE on all the languages.
    We further show the prompt generated by Evoke in Figure [8](#S4.F8 "Figure 8 ‣
    4.3 Towards Fine-Grained Tasks: Named Entity Recognition ‣ 4 Experiments ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing").
    From the prompt, we see that Evoke is able to automatically generate examples
    and explanations about the task.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在图[8](#S4.F8 "图 8 ‣ 4.3 面向细粒度任务：命名实体识别 ‣ 4 实验 ‣ Evoke: 通过Reviewer-Author提示编辑激发LLMs的批判性思维能力")中展示了Evoke在细粒度NER任务上的结果。我们看到Evoke在所有语言上显著优于APE。我们进一步展示了图[8](#S4.F8
    "图 8 ‣ 4.3 面向细粒度任务：命名实体识别 ‣ 4 实验 ‣ Evoke: 通过Reviewer-Author提示编辑激发LLMs的批判性思维能力")中的Evoke生成的提示。从提示中，我们看到Evoke能够自动生成关于任务的示例和解释。'
- en: 4.4 Analysis
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 分析
- en: 'LLM-Reviewer can judge the quality of prompts. Recall that in Evoke, LLM-Reviewer
    scores all the prompts generated by LLM-Author. We empirically show that the scores
    can reflect the quality of the generated prompts. To examine the effectiveness
    of these scores, we illustrate the relationship between the scores and the task
    accuracy in Figure [10](#S4.F10 "Figure 10 ‣ 4.4 Analysis ‣ 4 Experiments ‣ Evoke:
    Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing").
    In the experiments, we consider two tasks: Adversarial-SST2 and Common-Concept.
    From the results, we see that the scores can indeed reflect the final task accuracy.
    For example, for Common-Concept, we see that the task accuracy is about 5% when
    the prompt score is 6, and the task accuracy increases to about 17% when the prompt
    score increases to 7\. A similar trend is also revealed on the Adversarial-SST2
    task. We see that when the score is 7.5, the final task accuracy barely reaches
    75%. And when the score increases to 8, the task accuracy increases to 85%.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM-Reviewer可以判断提示的质量。回忆一下在Evoke中，LLM-Reviewer对LLM-Author生成的所有提示进行评分。我们通过实验证明这些分数可以反映生成提示的质量。为了检验这些分数的有效性，我们在图[10](#S4.F10
    "图 10 ‣ 4.4 分析 ‣ 4 实验 ‣ Evoke: 通过Reviewer-Author提示编辑激发LLMs的批判性思维能力")中展示了分数与任务准确性之间的关系。在实验中，我们考虑了两个任务：Adversarial-SST2和Common-Concept。从结果来看，分数确实可以反映最终任务准确性。例如，对于Common-Concept，当提示分数为6时，任务准确性约为5%，当提示分数增加到7时，任务准确性增加到约17%。在Adversarial-SST2任务上也揭示了类似的趋势。我们看到当分数为7.5时，最终任务准确性刚好达到75%。当分数增加到8时，任务准确性提高到85%。'
- en: '![Refer to caption](img/d95059d76d8d3878ebad19456565e439.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d95059d76d8d3878ebad19456565e439.png)'
- en: 'Figure 9: Correlation between scores generated by LLM-Reviewer and task accuracy.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：LLM-Reviewer生成的分数与任务准确性之间的相关性。
- en: '![Refer to caption](img/5431bb46f38a3063bcb8b5fad0245c88.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/5431bb46f38a3063bcb8b5fad0245c88.png)'
- en: 'Figure 10: Task accuracy over the number of iteration steps.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：任务准确性与迭代步骤数量的关系。
- en: 'LLM-Author iteratively improves prompt generation. In Evoke, because LLM-Author
    takes the feedback from LLM-Reviewer into consideration, it can iteratively improve
    the generated prompt. We demonstrate this in Figure [10](#S4.F10 "Figure 10 ‣
    4.4 Analysis ‣ 4 Experiments ‣ Evoke: Evoking Critical Thinking Abilities in LLMs
    via Reviewer-Author Prompt Editing") (the left-most orange bars). From the results,
    we see that indeed the final task accuracy continues to increases when we increase
    the number of iteration steps. For example, on Adversarial-SST2, with one refinement
    iteration, the final task accuracy is about 75%. When we increase the number of
    refinement iterations to 3, we see that task accuracy significantly increases
    to above 90%.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM-Author通过迭代改进提示生成。在Evoke中，由于LLM-Author考虑了LLM-Reviewer的反馈，它能够迭代改进生成的提示。我们在图[10](#S4.F10
    "图 10 ‣ 4.4 分析 ‣ 4 实验 ‣ Evoke: 通过Reviewer-Author提示编辑激发LLMs的批判性思维能力")（最左边的橙色条）中展示了这一点。从结果来看，确实当我们增加迭代步骤的数量时，最终的任务准确性持续提高。例如，在Adversarial-SST2上，经过一次改进迭代，最终任务准确性约为75%。当我们将改进迭代次数增加到3次时，任务准确性显著提高到90%以上。'
- en: 'Effectiveness of LLM-Selector. Recall that in Evoke, we only consider the “hard”
    samples in each iteration. We demonstrate the effectiveness of such a strategy
    in Figure [10](#S4.F10 "Figure 10 ‣ 4.4 Analysis ‣ 4 Experiments ‣ Evoke: Evoking
    Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing"). We consider
    three settings: Hard is the strategy that we adopt in Evoke; Random is when we
    randomly select samples instead of selecting based on a score; and Easy is when
    we select the easy samples instead of the hard ones. From the results, we see
    that on both Common-Concept and Adversarial SST-2, Easy yields the worst performance,
    indicating that the hard samples are more helpful than the easy ones. Moreover,
    we observe that performance of Random is worse than Hard (i.e., Evoke), further
    implying the effectiveness of the proposed data selection strategy.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM-Selector 的有效性。回顾一下，在 Evoke 中，我们只考虑每次迭代中的“困难”样本。我们在图 [10](#S4.F10 "Figure
    10 ‣ 4.4 Analysis ‣ 4 Experiments ‣ Evoke: Evoking Critical Thinking Abilities
    in LLMs via Reviewer-Author Prompt Editing") 中展示了这种策略的有效性。我们考虑了三种设置：Hard 是我们在
    Evoke 中采用的策略；Random 是随机选择样本而不是基于分数选择；Easy 是选择简单样本而不是困难样本。从结果来看，在 Common-Concept
    和 Adversarial SST-2 上，Easy 的表现最差，这表明困难样本比简单样本更有帮助。此外，我们观察到 Random 的表现比 Hard（即
    Evoke）更差，进一步暗示了所提数据选择策略的有效性。'
- en: 5 Conclusion
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: 'We propose Evoke, an author-reviewer framework for automatic prompt engineering.
    In Evoke, the same LLM serves two roles: as a reviewer it scores the quality of
    the prompt; and as an author it refines the prompt, taking the feedback of the
    reviewer into account. We further propose a data selection strategy, where we
    only expose the hard samples to the model. Extensive experiments show that Evoke outperforms
    existing automatic prompt engineering approaches.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了 Evoke，一个用于自动提示工程的作者-审阅者框架。在 Evoke 中，同一个 LLM 扮演两个角色：作为审阅者，它对提示的质量进行评分；作为作者，它在考虑审阅者反馈的情况下改进提示。我们进一步提出了一种数据选择策略，即仅向模型暴露困难样本。大量实验表明，Evoke
    超越了现有的自动提示工程方法。
- en: References
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Bubeck et al. (2023) Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J.,
    Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S. et al. (2023).
    Sparks of artificial general intelligence: Early experiments with gpt-4. ArXiv
    preprint, abs/2303.12712.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bubeck 等人 (2023) Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz,
    E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S. 等人 (2023)。人工通用智能的火花：对
    gpt-4 的早期实验。ArXiv 预印本，abs/2303.12712。
- en: Chen et al. (2021) Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O.,
    Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G. et al. (2021). Evaluating
    large language models trained on code. ArXiv preprint, abs/2107.03374.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2021) Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O.,
    Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G. 等人 (2021)。评估训练代码的大语言模型。ArXiv
    预印本，abs/2107.03374。
- en: 'Dettmers et al. (2023) Dettmers, T., Pagnoni, A., Holtzman, A. and Zettlemoyer,
    L. (2023). Qlora: Efficient finetuning of quantized llms. ArXiv preprint, abs/2305.14314.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dettmers 等人 (2023) Dettmers, T., Pagnoni, A., Holtzman, A. 和 Zettlemoyer, L.
    (2023)。Qlora：量化大语言模型的高效微调。ArXiv 预印本，abs/2305.14314。
- en: Du et al. (2023) Du, Y., Watkins, O., Wang, Z., Colas, C., Darrell, T., Abbeel,
    P., Gupta, A. and Andreas, J. (2023). Guiding pretraining in reinforcement learning
    with large language models.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等人 (2023) Du, Y., Watkins, O., Wang, Z., Colas, C., Darrell, T., Abbeel,
    P., Gupta, A. 和 Andreas, J. (2023)。用大语言模型指导强化学习中的预训练。
- en: 'Gao et al. (2023) Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y.,
    Callan, J. and Neubig, G. (2023). Pal: Program-aided language models. In International
    Conference on Machine Learning. PMLR.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 (2023) Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan,
    J. 和 Neubig, G. (2023)。Pal：程序辅助语言模型。在国际机器学习会议。PMLR。
- en: 'Honovich et al. (2022) Honovich, O., Shaham, U., Bowman, S. R. and Levy, O.
    (2022). Instruction induction: From few examples to natural language task descriptions.
    ArXiv preprint, abs/2205.10782.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Honovich 等人 (2022) Honovich, O., Shaham, U., Bowman, S. R. 和 Levy, O. (2022)。指令归纳：从少量示例到自然语言任务描述。ArXiv
    预印本，abs/2205.10782。
- en: 'Hu et al. (2022) Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang,
    S., Wang, L. and Chen, W. (2022). Lora: Low-rank adaptation of large language
    models. In The Tenth International Conference on Learning Representations, ICLR
    2022, Virtual Event, April 25-29, 2022. OpenReview.net.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人 (2022) Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S.,
    Wang, L. 和 Chen, W. (2022)。Lora：大语言模型的低秩适应。在第十届国际学习表征会议，ICLR 2022，虚拟活动，2022年4月25-29日。OpenReview.net。
- en: 'Huang and Chang (2022) Huang, J. and Chang, K. C.-C. (2022). Towards reasoning
    in large language models: A survey. ArXiv preprint, abs/2212.10403.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 和 Chang（2022）Huang, J. 和 Chang, K. C.-C.（2022）。大型语言模型中的推理：综述。ArXiv 预印本，abs/2212.10403。
- en: 'Jones et al. (2020) Jones, E., Jia, R., Raghunathan, A. and Liang, P. (2020).
    Robust encodings: A framework for combating adversarial typos. In Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics. Association
    for Computational Linguistics, Online.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jones 等人（2020）Jones, E., Jia, R., Raghunathan, A. 和 Liang, P.（2020）。鲁棒编码：一种对抗性拼写错误的框架。发表于第58届计算语言学协会年会论文集。计算语言学协会，在线。
- en: Kojima et al. (2022) Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. and Iwasawa,
    Y. (2022). Large language models are zero-shot reasoners. Advances in neural information
    processing systems, 35 22199–22213.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. 和 Iwasawa, Y.（2022）。大型语言模型是零样本推理者。神经信息处理系统进展，35
    22199–22213。
- en: 'Liu et al. (2022) Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L. and Chen,
    W. (2022). What makes good in-context examples for GPT-3? In Proceedings of Deep
    Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and
    Integration for Deep Learning Architectures. Association for Computational Linguistics,
    Dublin, Ireland and Online.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2022）Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L. 和 Chen, W.（2022）。什么样的上下文示例对GPT-3有效？发表于深度学习内外（DeeLIO
    2022）：第三届知识提取与集成工作坊论文集。计算语言学协会，都柏林，爱尔兰和在线。
- en: 'Min et al. (2022) Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi,
    H. and Zettlemoyer, L. (2022). Rethinking the role of demonstrations: What makes
    in-context learning work? In Proceedings of the 2022 Conference on Empirical Methods
    in Natural Language Processing. Association for Computational Linguistics, Abu
    Dhabi, United Arab Emirates.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Min 等人（2022）Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi,
    H. 和 Zettlemoyer, L.（2022）。重新思考演示的作用：是什么让上下文学习有效？发表于2022年自然语言处理实证方法会议论文集。计算语言学协会，阿布扎比，阿联酋。
- en: Ouyang et al. (2022) Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,
    C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A. et al. (2022). Training
    language models to follow instructions with human feedback. Advances in Neural
    Information Processing Systems, 35 27730–27744.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等人（2022）Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin,
    P., Zhang, C., Agarwal, S., Slama, K., Ray, A. 等（2022）。通过人类反馈训练语言模型以遵循指令。神经信息处理系统进展，35
    27730–27744。
- en: 'Reynolds and McDonell (2021) Reynolds, L. and McDonell, K. (2021). Prompt programming
    for large language models: Beyond the few-shot paradigm. In Extended Abstracts
    of the 2021 CHI Conference on Human Factors in Computing Systems.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reynolds 和 McDonell（2021）Reynolds, L. 和 McDonell, K.（2021）。大型语言模型的提示编程：超越少样本范式。发表于2021年CHI计算机系统人因会议扩展摘要。
- en: Sarsa et al. (2022) Sarsa, S., Denny, P., Hellas, A. and Leinonen, J. (2022).
    Automatic generation of programming exercises and code explanations using large
    language models. In Proceedings of the 2022 ACM Conference on International Computing
    Education Research-Volume 1.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarsa 等人（2022）Sarsa, S., Denny, P., Hellas, A. 和 Leinonen, J.（2022）。使用大型语言模型自动生成编程练习和代码解释。发表于2022年ACM国际计算教育研究会议论文集第一卷。
- en: Schneider et al. (2020) Schneider, E. T. R., de Souza, J. V. A., Knafou, J.,
    Oliveira, L. E. S. e., Copara, J., Gumiel, Y. B., Oliveira, L. F. A. d., Paraiso,
    E. C., Teodoro, D. and Barra, C. M. C. M. (2020). BioBERTpt - a Portuguese neural
    language model for clinical named entity recognition. In Proceedings of the 3rd
    Clinical Natural Language Processing Workshop. Association for Computational Linguistics,
    Online.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schneider 等人（2020）Schneider, E. T. R., de Souza, J. V. A., Knafou, J., Oliveira,
    L. E. S. e., Copara, J., Gumiel, Y. B., Oliveira, L. F. A. d., Paraiso, E. C.,
    Teodoro, D. 和 Barra, C. M. C. M.（2020）。BioBERTpt - 一种用于临床命名实体识别的葡萄牙语神经语言模型。发表于第3届临床自然语言处理研讨会论文集。计算语言学协会，在线。
- en: 'Shin et al. (2020) Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E. and
    Singh, S. (2020). AutoPrompt: Eliciting Knowledge from Language Models with Automatically
    Generated Prompts. In Proceedings of the 2020 Conference on Empirical Methods
    in Natural Language Processing (EMNLP). Association for Computational Linguistics,
    Online.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shin 等人（2020）Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E. 和 Singh, S.（2020）。AutoPrompt：通过自动生成的提示从语言模型中引出知识。发表于2020年自然语言处理实证方法会议论文集（EMNLP）。计算语言学协会，在线。
- en: Shrivastava et al. (2023) Shrivastava, D., Larochelle, H. and Tarlow, D. (2023).
    Repository-level prompt generation for large language models of code. In International
    Conference on Machine Learning. PMLR.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shrivastava 等人（2023）Shrivastava, D., Larochelle, H. 和 Tarlow, D.（2023）。用于代码的大型语言模型的仓库级提示生成。发表于国际机器学习会议。PMLR。
- en: Socher et al. (2013) Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning,
    C. D., Ng, A. and Potts, C. (2013). Recursive deep models for semantic compositionality
    over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical
    Methods in Natural Language Processing. Association for Computational Linguistics,
    Seattle, Washington, USA.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Socher 等人（2013）Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C. D.,
    Ng, A. 和 Potts, C.（2013）。递归深度模型在情感树库上的语义组合性研究。发表于 2013 年自然语言处理实证方法会议论文集。计算语言学协会，西雅图，华盛顿，美国。
- en: Suzgun et al. (2022) Suzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay,
    Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D. et al. (2022).
    Challenging big-bench tasks and whether chain-of-thought can solve them. ArXiv
    preprint, abs/2210.09261.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suzgun 等人（2022）Suzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay, Y., Chung,
    H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D. 等人（2022）。挑战大基准任务及链式思维是否能解决这些任务。ArXiv
    预印本，abs/2210.09261。
- en: Thirunavukarasu et al. (2023) Thirunavukarasu, A. J., Ting, D. S. J., Elangovan,
    K., Gutierrez, L., Tan, T. F. and Ting, D. S. W. (2023). Large language models
    in medicine. Nature medicine 1–11.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thirunavukarasu 等人（2023）Thirunavukarasu, A. J., Ting, D. S. J., Elangovan, K.,
    Gutierrez, L., Tan, T. F. 和 Ting, D. S. W.（2023）。医学中的大型语言模型。自然医学 1–11。
- en: 'Wang et al. (2019) Wang, A., Singh, A., Michael, J., Hill, F., Levy, O. and
    Bowman, S. R. (2019). GLUE: A multi-task benchmark and analysis platform for natural
    language understanding. In 7th International Conference on Learning Representations,
    ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2019）Wang, A., Singh, A., Michael, J., Hill, F., Levy, O. 和 Bowman,
    S. R.（2019）。GLUE：一种用于自然语言理解的多任务基准和分析平台。发表于第七届国际学习表征会议，ICLR 2019，新奥尔良，洛杉矶，美国，2019
    年 5 月 6-9 日。OpenReview.net。
- en: 'Wang et al. (2023) Wang, J., Hu, X., Hou, W., Chen, H., Zheng, R., Wang, Y.,
    Yang, L., Huang, H., Ye, W., Geng, X. et al. (2023). On the robustness of chatgpt:
    An adversarial and out-of-distribution perspective. ArXiv preprint, abs/2302.12095.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023）Wang, J., Hu, X., Hou, W., Chen, H., Zheng, R., Wang, Y., Yang,
    L., Huang, H., Ye, W., Geng, X. 等人（2023）。关于 ChatGPT 的鲁棒性：一种对抗性和分布外视角。ArXiv 预印本，abs/2302.12095。
- en: Wang et al. (2022) Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang,
    S., Chowdhery, A. and Zhou, D. (2022). Self-consistency improves chain of thought
    reasoning in language models. ArXiv preprint, abs/2203.11171.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2022）Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S.,
    Chowdhery, A. 和 Zhou, D.（2022）。自一致性提高了语言模型的链式思维推理。ArXiv 预印本，abs/2203.11171。
- en: Wei et al. (2022a) Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester,
    B., Du, N., Dai, A. M. and Le, Q. V. (2022a). Finetuned language models are zero-shot
    learners. In The Tenth International Conference on Learning Representations, ICLR
    2022, Virtual Event, April 25-29, 2022. OpenReview.net.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022a）Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B.,
    Du, N., Dai, A. M. 和 Le, Q. V.（2022a）。微调语言模型是零样本学习者。发表于第十届国际学习表征会议，ICLR 2022，虚拟活动，2022
    年 4 月 25-29 日。OpenReview.net。
- en: Wei et al. (2022b) Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud,
    S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D. et al. (2022b). Emergent abilities
    of large language models. ArXiv preprint, abs/2206.07682.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022b）Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud,
    S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D. 等人（2022b）。大型语言模型的显现能力。ArXiv
    预印本，abs/2206.07682。
- en: Wei et al. (2022c) Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,
    E., Le, Q. V., Zhou, D. et al. (2022c). Chain-of-thought prompting elicits reasoning
    in large language models. Advances in Neural Information Processing Systems, 35
    24824–24837.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022c）Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E.,
    Le, Q. V., Zhou, D. 等人（2022c）。链式思维提示引发大型语言模型的推理。神经信息处理系统进展，35 24824–24837。
- en: White et al. (2023) White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert,
    H., Elnashar, A., Spencer-Smith, J. and Schmidt, D. C. (2023). A prompt pattern
    catalog to enhance prompt engineering with chatgpt. ArXiv preprint, abs/2302.11382.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: White 等人（2023）White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert,
    H., Elnashar, A., Spencer-Smith, J. 和 Schmidt, D. C.（2023）。增强 ChatGPT 提示工程的提示模式目录。ArXiv
    预印本，abs/2302.11382。
- en: Xie et al. (2022) Xie, S. M., Raghunathan, A., Liang, P. and Ma, T. (2022).
    An explanation of in-context learning as implicit bayesian inference. In The Tenth
    International Conference on Learning Representations, ICLR 2022, Virtual Event,
    April 25-29, 2022. OpenReview.net.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等 (2022) Xie, S. M., Raghunathan, A., Liang, P. 和 Ma, T. (2022). 作为隐性贝叶斯推断的上下文学习解释。发表于第十届学习表征国际会议，ICLR
    2022，虚拟会议，2022 年 4 月 25-29 日。OpenReview.net。
- en: 'Yoo et al. (2022) Yoo, K. M., Kim, J., Kim, H. J., Cho, H., Jo, H., Lee, S.-W.,
    Lee, S.-g. and Kim, T. (2022). Ground-truth labels matter: A deeper look into
    input-label demonstrations. In Proceedings of the 2022 Conference on Empirical
    Methods in Natural Language Processing. Association for Computational Linguistics,
    Abu Dhabi, United Arab Emirates.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yoo 等 (2022) Yoo, K. M., Kim, J., Kim, H. J., Cho, H., Jo, H., Lee, S.-W.,
    Lee, S.-g. 和 Kim, T. (2022). 真实标签的重要性: 对输入-标签示例的深入分析。发表于 2022 年自然语言处理经验方法会议论文集。计算语言学协会，阿布扎比，阿拉伯联合酋长国。'
- en: 'Zhang et al. (2023) Zhang, B., Haddow, B. and Birch, A. (2023). Prompting large
    language model for machine translation: A case study. ArXiv preprint, abs/2301.07069.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等 (2023) Zhang, B., Haddow, B. 和 Birch, A. (2023). 促进大型语言模型的机器翻译: 一个案例研究。ArXiv
    预印本，abs/2301.07069。'
- en: Zhou et al. (2022) Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S.,
    Chan, H. and Ba, J. (2022). Large language models are human-level prompt engineers.
    ArXiv preprint, abs/2211.01910.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等 (2022) Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan,
    H. 和 Ba, J. (2022). 大型语言模型是人类级别的提示工程师。ArXiv 预印本，abs/2211.01910。
- en: 'Zuo et al. (2023) Zuo, S., Tang, P., Hu, X., Lou, Q., Jiao, J. and Charles,
    D. (2023). Deeptagger: Knowledge enhanced named entity recognition for web-based
    ads queries. ArXiv preprint, abs/2306.17413.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zuo 等 (2023) Zuo, S., Tang, P., Hu, X., Lou, Q., Jiao, J. 和 Charles, D. (2023).
    Deeptagger: 知识增强的命名实体识别用于基于网络的广告查询。ArXiv 预印本，abs/2306.17413。'
- en: Appendix A Instruction Induction
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 指导诱导
- en: 'In Evoke, we use the author-reviewer framework to modify a task-specific prompt.
    In the experiments, we use an off-the-shelf algorithm to generate the initial
    task-specific prompt. Table [3](#A1.T3 "Table 3 ‣ Appendix A Instruction Induction
    ‣ Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt
    Editing") demonstrates examples of using instruction induction (Honovich et al.,
    [2022](#bib.bib6)) for prompt initialization.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Evoke 中，我们使用作者-审稿人框架来修改特定任务的提示。在实验中，我们使用现成的算法生成初始任务特定提示。表 [3](#A1.T3 "表 3
    ‣ 附录 A 指导诱导 ‣ Evoke: 通过审稿人-作者提示编辑引发 LLM 的批判性思维能力") 展示了使用指导诱导 (Honovich 等，[2022](#bib.bib6))
    进行提示初始化的示例。'
- en: 'Table 3: Three examples of instruction inferred from input-output pairs'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 从输入-输出对中推断出的三种示例指导'
- en: '| Input | Output | Inferred Instruction |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 输入 | 输出 | 推断的指导 |'
- en: '| Departure | Arrival | Get antonym |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 出发地 | 到达地 | 获取反义词 |'
- en: '| I am Mike | Ich ben Mike | Translate to German |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 我是 Mike | Ich ben Mike | 翻译成德语 |'
- en: '| Build | Built | Get passive voice of the given verb |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 建造 | 建造的 | 获取给定动词的被动语态 |'
- en: Appendix B Prompts of LLM roles in Evoke
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B LLM 角色的提示在 Evoke 中
- en: B.1 LLM-Reviewer
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 LLM-审稿人
- en: '| Prompt for LLM-Reviewer |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| LLM-审稿人的提示 |'
- en: '| As an experienced teacher, you are well-versed in discerning effective instruction
    that guides students toward correct answers. Please rate the following instruction
    on a scale of 1 to 10, where 10 represents the highest level of clarity in problem
    description, execution steps, and a comprehensive explanation of the problem.
    |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 作为一位经验丰富的教师，您善于识别有效的指导，以引导学生达到正确答案。请在 1 到 10 的评分范围内对以下指导进行评分，其中 10 表示问题描述、执行步骤以及问题的全面解释的最高清晰度。
    |'
- en: '| The task at hand is titled: {description} |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 当前任务标题为: {description} |'
- en: '| History that may help you: {memory} |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 可能对您有帮助的历史: {memory} |'
- en: '| The instruction to be rated is as follows: {instruction} |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 需要评分的指导如下: {instruction} |'
- en: '| Kindly provide your rating below. |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 请在下方提供您的评分。 |'
- en: B.2 LLM-Author
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 LLM-作者
- en: '| Prompt for LLM-Author |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| LLM-作者的提示 |'
- en: '| Task Instruction: {instruction} |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 任务指导: {instruction} |'
- en: '| We’ve provided pairs consisting of inputs, the teacher’s correct answers,
    and the students’ responses. Please review the incorrect responses from the students
    and summarize key points that could be adjusted in the instruction to enhance
    student accuracy. |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 我们提供了包含输入、教师的正确答案和学生的回应的对。请审查学生的不正确回应，并总结出在指导中可以调整的关键点，以提高学生的准确性。 |'
- en: '| Pairs: {pairs} |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 对应对: {pairs} |'
- en: '| History that may help you: {memory} |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 可能对您有帮助的历史: {memory} |'
- en: '| To improve the outcome, please revise the task instruction. Highlight major
    edits and present the updated task instruction. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 为了提高结果，请修改任务指令。突出显示主要编辑，并呈现更新后的任务指令。 |'
- en: B.3 LLM-Selector
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 LLM-选择器
- en: '| Prompt for LLM-Selector |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| LLM-选择器提示 |'
- en: '| As an experienced teacher with insight into the various levels of difficulty
    of exam questions, please rate the following question on a scale of 1 to 10, considering
    factors such as conceptual understanding, application of knowledge, problem-solving
    skills, time required, clarity of language, and accessibility, where 1 denotes
    extremely easy and 10 denotes extremely difficult. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 作为一名经验丰富的教师，了解考试题目的不同难度级别，请根据概念理解、知识应用、解决问题的能力、所需时间、语言清晰度和可及性等因素，对以下问题进行1到10的评分，其中1表示非常简单，10表示非常困难。
    |'
- en: '| Task instruction: {instruction} |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 任务指令: {instruction} |'
- en: '| Input: {input} |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 输入: {input} |'
- en: '| Correct answer: {answer} |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 正确答案: {answer} |'
- en: Appendix C Generated Instructions
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 生成的指令
- en: We include generated instructions from all tasks below.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们包括所有任务生成的指令如下。
- en: C.1 Orthography Starts With
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 拼写以...开头
- en: '| Prompt from Evoke |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 来自 Evoke 的提示 |'
- en: '| Given an input sentence and a specified letter, identify the word or words
    starting with the given letter. If there are two or more words in a sequence starting
    with the specified letter, include all of them as a single answer. Ensure to present
    the word or group of words. Here are the steps to follow: -Read the provided input
    sentence carefully. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 给定一个输入句子和一个指定字母，识别以该字母开头的单词或词组。如果有两个或更多以指定字母开头的单词，请将它们作为一个答案一起列出。确保呈现单词或词组。以下是需要遵循的步骤:
    - 仔细阅读提供的输入句子。 |'
- en: '| -Identify the word or words that start with the specified letter. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| - 识别以指定字母开头的单词或词组。 |'
- en: '| -If there are consecutive words starting with the specified letter, group
    them together as one entity. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| - 如果有连续的单词以指定字母开头，将它们作为一个整体分组。 |'
- en: '| -For example, if the input is ”I prefer eating apples.” and the specified
    letter is [e], your answer should be eating. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| - 例如，如果输入是“I prefer eating apples.”且指定字母是[e]，你的答案应为eating。 |'
- en: C.2 Common Concept
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 共同概念
- en: '| Prompt from Evoke |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 来自 Evoke 的提示 |'
- en: '| Given a list, find the commonality between the inputs. The commonality should
    be a meaningful characteristic, property, or relation that applies to all the
    inputs, not just a superficial or coincidental feature. For example, can be used
    for repairs is a valid commonality for [’sewing’, ’wrenches’, ’glue’, ’surgery’],
    but tools or skills for joining is too broad and vague, and contain the letter
    e is too trivial and irrelevant. |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 给定一个列表，找出输入之间的共同点。共同点应是一个对所有输入都适用的有意义的特征、属性或关系，而不仅仅是表面或偶然的特征。例如，“可以用于修理”是[‘缝纫’,
    ‘扳手’, ‘胶水’, ‘手术’]的有效共同点，但“连接的工具或技能”太宽泛模糊，“包含字母e”则太琐碎无关。 |'
- en: C.3 Rhymes
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 押韵
- en: '| Prompt from Evoke |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 来自 Evoke 的提示 |'
- en: '| For this task, you are required to find a word that rhymes with the given
    word. The word you provide should not be the same as the given word, and should
    be a real, correctly spelled word from the English language. A rhyming word is
    defined as a word that has the last syllable sounding identical to the last syllable
    of the given word. For example, if the given word is ”hat”, a word that rhymes
    with it is ”cat”. Here are the steps to complete this task: |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 对于此任务，你需要找出一个与给定单词押韵的单词。你提供的单词不应与给定单词相同，并且应该是一个真实且拼写正确的英语单词。押韵单词的定义是最后一个音节的发音与给定单词的最后一个音节相同。例如，如果给定单词是“hat”，与之押韵的单词是“cat”。完成此任务的步骤如下:
    |'
- en: '| 1\. Read the given word carefully. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 1\. 仔细阅读给定的单词。 |'
- en: '| 2\. Think of a word that has the same ending sound as the given word. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 2\. 想一个与给定单词结尾音相同的单词。 |'
- en: '| 3\. Ensure that the word you thought of is a real word, is spelled correctly,
    and is not the same as the given word. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 3\. 确保你想到的单词是真实的，拼写正确，并且与给定单词不同。 |'
- en: '| 4\. Write down the rhyming word next to the given word. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 4\. 将押韵的单词写在给定单词旁边。 |'
- en: '| Now, please proceed with finding a word that rhymes with each of the following
    words. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 现在，请继续找出与下列单词押韵的单词。 |'
- en: C.4 Movie Recommendation
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.4 电影推荐
- en: '| Prompt from Evoke |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 来自 Evoke 的提示 |'
- en: '| Given user’s interest in movies he watched previously: ‘watched‘. Now given
    four different movies from A to D, please recommend one that might be the most
    interest of the user. To help you make a good recommendation, consider the following
    factors: - The genre, theme, and tone of the movies. For example, if the user
    likes comedy, action, or drama. - The similarity or difference between the movies
    and the ones the user watched before. For example, if the movies are part of a
    series, a remake, or a spin-off. - The popularity, ratings, and reviews of the
    movies. For example, if the movies are critically acclaimed, award-winning, or
    have a large fan base. Use these factors to compare and contrast the movies and
    explain why you think one of them is the best choice for the user. Do not just
    pick a movie based on your personal preference or guesswork. Example: If the user
    watched The Godfather, The Godfather Part II, and Goodfellas, and the options
    are A) The Departed, B) Scarface, C) The Irishman, and D) Casino, a possible answer
    is: A The Departed is a crime thriller that has a similar genre, theme, and tone
    to the movies the user watched before. It is also a remake of a Hong Kong film
    called Infernal Affairs, which adds a twist to the familiar story of undercover
    agents and mobsters. The Departed is a highly popular and acclaimed movie that
    won four Oscars, including Best Picture and Best Director. It has a star-studded
    cast that includes Leonardo DiCaprio, Matt Damon, Jack Nicholson, and Mark Wahlberg.
    The user might enjoy the suspense, the plot twists, and the performances of the
    actors in this movie. Therefore, I recommend The Departed as the best option for
    the user. |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 根据用户之前观看的电影兴趣：‘watched‘。现在给出四部不同的电影，从 A 到 D，请推荐一部可能最符合用户兴趣的电影。为了帮助你做出良好的推荐，请考虑以下因素：
    - 电影的类型、主题和基调。例如，如果用户喜欢喜剧、动作或剧情片。 - 这些电影与用户之前观看的电影的相似性或差异。例如，如果这些电影是系列片、重拍片或衍生片。
    - 电影的受欢迎程度、评分和评价。例如，如果这些电影获得了好评、奖项或拥有大量粉丝。利用这些因素对电影进行比较和对比，并解释为什么你认为其中一部电影是用户的最佳选择。不要仅仅根据个人偏好或猜测来选择电影。示例：如果用户观看了《教父》、《教父2》和《好家伙》，而选项是
    A) 《无间行者》，B) 《疤面煞星》，C) 《爱尔兰人》和 D) 《赌场》，一个可能的答案是：A 《无间行者》是一部犯罪惊悚片，其类型、主题和基调与用户之前观看的电影相似。它也是香港电影《无间道》的重拍版，为熟悉的卧底探员和黑帮故事增添了新的转折。《无间行者》是一部广受欢迎且备受赞誉的电影，赢得了四项奥斯卡奖，包括最佳影片和最佳导演。它有一支明星阵容，包括莱昂纳多·迪卡普里奥、马特·达蒙、杰克·尼科尔森和马克·沃尔伯格。用户可能会喜欢这部电影中的悬念、情节反转和演员的表演。因此，我推荐《无间行者》作为用户的最佳选择。
    |'
- en: C.5 Logical Fallacy Detection
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.5 逻辑谬误检测
- en: '| Prompt from Evoke |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| Evoke 提示 |'
- en: '| In this task, you are required to identify both informal and formal logical
    fallacies in the provided input statements. Your response should be a binary value:
    return 1 if the query is logically valid (i.e., free from any logical fallacies),
    and return 0 if the query is logically invalid (i.e., contains at least one logical
    fallacy). A logical fallacy refers to an error in reasoning. Informal fallacies
    are often content-dependent, such as appealing to irrelevant authority or making
    hasty generalizations. Formal fallacies, on the other hand, are structural errors
    in reasoning that occur regardless of the content. It is crucial to consider the
    structure and the substance of the argument, evaluating whether the conclusions
    follow logically from the premises, and whether the premises and assumptions are
    factual and valid. Be cautious not to let personal beliefs interfere with your
    analysis. For each given pair, compare the input statement against the principles
    of logical reasoning, to determine whether it contains a logical fallacy or not.
    Ensure your answer reflects the presence or absence of logical fallacies, thus
    determining the logical validity or invalidity of the statement. Here are some
    common examples of logical fallacies: - Ad Hominem: Attacking the character of
    a person making an argument rather than the argument itself. - Appeal to Nature:
    Claiming something is good because it’s natural, or bad because it’s unnatural.
    - Hasty Generalization: Making a broad claim based on a small or unrepresentative
    sample size. - Post Hoc: Assuming that because one event followed another, the
    first event caused the second event. - False Cause: Assuming a false or misleading
    cause-and-effect relationship. |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 在此任务中，你需要识别提供的输入陈述中的非正式和正式逻辑谬误。你的回答应该是一个二进制值：如果查询在逻辑上有效（即没有任何逻辑谬误），则返回1；如果查询在逻辑上无效（即包含至少一个逻辑谬误），则返回0。逻辑谬误指的是推理中的错误。非正式谬误通常依赖于内容，例如诉诸无关的权威或草率概括。另一方面，正式谬误则是推理中的结构性错误，无论内容如何都会发生。至关重要的是考虑论证的结构和实质，评估结论是否从前提中逻辑地推导出来，以及前提和假设是否真实有效。要小心不要让个人信念干扰你的分析。对于每对给定的陈述，比较输入陈述与逻辑推理原则，确定是否包含逻辑谬误。确保你的答案反映出逻辑谬误的存在或缺乏，从而确定陈述的逻辑有效性或无效性。以下是一些常见的逻辑谬误示例：-
    人身攻击：攻击提出论点的人的品格，而不是论点本身。- 诉诸自然：声称某物因自然而好，或因不自然而坏。- 草率概括：基于小样本或不具代表性的样本做出广泛声明。-
    事后假设：假设因为一个事件跟随另一个事件，所以第一个事件导致了第二个事件。- 错误因果：假设错误或误导性的因果关系。 |'
- en: C.6 Presuppositions as NLI
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.6 预设作为NLI
- en: '| Prompt from Evoke |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 来自Evoke的提示 |'
- en: '| Determine whether the first sentence entails, contradicts, or is neutral
    to the second sentence. The term ”entailment” means that the information in the
    first sentence logically supports or leads to the conclusion presented in the
    second sentence. The term ”contradiction” means that the information in the first
    sentence logically opposes or disproves the information in the second sentence.
    The term ”neutral” implies that the information in the first sentence neither
    supports nor opposes the information in the second sentence; they are unrelated
    or the relation between them is ambiguous. |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 确定第一句是否蕴含、矛盾或中立于第二句。术语“蕴含”意味着第一句中的信息在逻辑上支持或引导到第二句中的结论。术语“矛盾”意味着第一句中的信息在逻辑上与第二句中的信息对立或驳斥第二句中的信息。术语“中立”意味着第一句中的信息既不支持也不反对第二句中的信息；它们无关或它们之间的关系不明确。
    |'
- en: '| It’s important to focus on the factual information provided rather than assumptions
    or external knowledge. Make sure to carefully read both sentences and analyze
    their logical relation based only on the given text. Entailment: The information
    in the first sentence supports the conclusion in the second sentence. Contradiction:
    The information in the first sentence opposes or disproves the information in
    the second sentence. |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 重要的是要关注提供的事实信息，而不是假设或外部知识。确保仔细阅读每个句子，并仅基于给定文本分析它们的逻辑关系。蕴含：第一句中的信息支持第二句中的结论。矛盾：第一句中的信息与第二句中的信息相对立或驳斥第二句中的信息。
    |'
- en: '| Neutral: The information in the first sentence neither supports nor opposes
    the information in the second sentence, or the relation between them is ambiguous.
    |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 中立：第一句中的信息既不支持也不反对第二句中的信息，或者它们之间的关系不明确。 |'
- en: '| For each pair, please provide the correct judgment between entailment, contradiction,
    and neutral, based only on the provided text. Please avoid assumptions and focus
    solely on the text provided. |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 对于每对陈述，请仅根据提供的文本提供蕴含、矛盾或中立的正确判断。请避免做出假设，专注于提供的文本。 |'
- en: C.7 Winowhy
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.7 Winowhy
- en: '| Prompt from Evoke |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| Evoke的提示 |'
- en: '| In the given text, you are required to evaluate the reasoning provided concerning
    the identification of the antecedent of a pronoun in a sentence. The antecedent
    is the noun that the pronoun is referring to. Carefully examine the reasoning
    to determine if it accurately identifies the antecedent based solely on the information
    presented within the sentence itself. Here are the steps you should follow: Read
    the sentence and the reasoning provided thoroughly. |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 在给定的文本中，你需要评估提供的推理，涉及代词在句子中的前项识别。前项是代词所指的名词。仔细检查推理，以确定它是否准确识别了前项，仅基于句子中提供的信息。你应遵循以下步骤：彻底阅读句子和提供的推理。
    |'
- en: '| -Assess whether the reasoning accurately identifies the antecedent of the
    pronoun based solely on the provided text. Avoid making assumptions or using external
    knowledge. |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| - 评估推理是否准确识别了代词的前项，仅基于提供的文本。避免做出假设或使用外部知识。 |'
- en: '| -If the reasoning correctly identifies the antecedent of the pronoun, based
    on the information given in the sentence. |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| - 如果推理正确地识别了代词的前项，基于句子中提供的信息。 |'
- en: '| -If the reasoning fails to accurately identify the antecedent of the pronoun
    or relies on assumptions or external information. |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| - 如果推理未能准确识别代词的前项或依赖于假设或外部信息。 |'
- en: '| Remember, |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 请记住， |'
- en: '| Your evaluation should strictly be based on the information provided in the
    text. |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 你的评估应严格基于文本中提供的信息。 |'
- en: '| Your goal is to assess the accuracy of the reasoning in identifying the antecedent
    of the pronoun. |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 你的目标是评估推理在识别代词前项方面的准确性。 |'
- en: C.8 Epistemic Reasoning
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.8 认识论推理
- en: '| Prompt from Evoke |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Evoke的提示 |'
- en: '| In this task, your goal is to determine whether the statement in the ”Hypothesis”
    logically follows from the statement in the ”Premise.” This is known as entailment.
    If the ”Hypothesis” statement is a logical consequence of the ”Premise” statement,
    then it is an entailment. If it is not, then it is a non-entailment. |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 在此任务中，你的目标是确定“假设”中的陈述是否逻辑上从“前提”中的陈述得出。这称为蕴含。如果“假设”陈述是“前提”陈述的逻辑结果，则它是蕴含。如果不是，则是非蕴含。
    |'
- en: '| -Make sure to carefully consider the relations and assumptions mentioned
    in both the ”Premise” and the ”Hypothesis” statements. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| - 确保仔细考虑“前提”和“假设”陈述中提到的关系和假设。 |'
- en: '| -The entailment does not depend on the truth of the statements, but rather
    whether the logic in the ”Hypothesis” follows from the ”Premise”. |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| - 蕴含并不依赖于陈述的真实性，而是“假设”中的逻辑是否从“前提”中得出。 |'
- en: '| -Pay close attention to the wording and structure of the sentences to analyze
    whether one entails the other. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| - 仔细注意句子的措辞和结构，以分析是否一个句子蕴含另一个句子。 |'
- en: '| Examples: Entailment Premise: The sun rises in the east. Hypothesis: The
    sun rises. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 示例：蕴含 前提：太阳从东方升起。假设：太阳升起了。 |'
- en: '| Explanation: The Hypothesis is a simplified version of the Premise and does
    not introduce any new information or contradictions, hence it’s an entailment.
    Non-entailment Premise: Sarah believes that all cats are black. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 解释：假设是前提的简化版本，并未引入任何新信息或矛盾，因此它是蕴含的。非蕴含 前提：Sarah认为所有猫都是黑色的。 |'
- en: '| Hypothesis: All cats are black. Explanation: Even though the Hypothesis is
    expressed in the Premise, it’s tied to Sarah’s belief and not presented as a fact,
    hence it’s a non-entailment. Now, review the provided pairs of statements. Determine
    if the Hypothesis logically follows from the Premise and respond with either entailment
    or non-entailment. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 假设：所有猫都是黑色的。解释：虽然假设在前提中表达，但它与Sarah的信仰相关，并未被呈现为事实，因此它是非蕴含的。现在，请查看提供的陈述对。确定假设是否逻辑上从前提中得出，并回应蕴含或非蕴含。
    |'
- en: C.9 Adversarial SST2
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.9 对抗性SST2
- en: '| Prompt from Evoke |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| Evoke的提示 |'
- en: '| Now given a user query, please do a sentiment analysis where 0 represents
    negative sentiment and 1 represents positive sentiment. Please note that the input
    may contain typos. These are not intentional and do not reflect the user’s actual
    sentiment. You should try to correct the typos or infer the intended meaning from
    the context before assigning a sentiment score. For example, ‘to merely badv trather
    than painfzully awfl‘ could be corrected to ‘to merely bad rather than painfully
    awful‘ and scored as 0\. Similarly, ‘l comelling mobion‘ could be corrected to
    ‘a compelling motion‘ and scored as 1\. Sentiment analysis. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 现在给定一个用户查询，请进行情感分析，其中0代表负面情绪，1代表正面情绪。请注意，输入可能包含拼写错误。这些错误并非故意，并不反映用户的实际情感。在分配情感分数之前，您应该尝试纠正拼写错误或从上下文中推断出意图。例如，“to
    merely badv trather than painfzully awfl”可以纠正为“to merely bad rather than painfully
    awful”，并且分数为0。类似地，“l comelling mobion”可以纠正为“a compelling motion”，并且分数为1。情感分析。
    |'
- en: C.10 Adversarial QQP
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.10 对抗性QQP
- en: '| Prompt from Evoke |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 来自Evoke的提示 |'
- en: '| You will be given a pair of questions and asked to determine whether they
    are paraphrases of each other. Paraphrases are questions that have the same meaning
    or ask about the same information, even if they use different words or structures.
    Please answer with a binary value of 1 if the questions are paraphrases, or 0
    if they are not. Please pay close attention to typos, spelling, grammar, and punctuation
    before answering, as they may affect the meaning of the questions. If you are
    not sure whether the questions are paraphrases or not, you can use some strategies
    to help you decide, such as: - Compare the keywords and topics of the questions.
    Do they match or relate to each other? - Rewrite one question in a different way
    and see if it still conveys the same message as the other question. - Think about
    the context and purpose of the questions. Are they asking for the same type of
    information or response? For example, the questions What is the capital of France?
    and Which city is the seat of the French government? are paraphrases, because
    they both ask about the same fact and can be answered with the same word (Paris).
    However, the questions How do you play the guitar? and What are some guitar chords?
    are not paraphrases, because they ask for different kinds of information and have
    different levels of specificity. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 您将获得一对问题，并被要求确定它们是否为彼此的同义句。同义句是指具有相同含义或询问相同信息的问题，即使它们使用不同的词汇或结构。请用1表示问题是同义句，用0表示不是同义句。在回答之前，请密切注意拼写错误、语法和标点，因为这些可能会影响问题的含义。如果您不确定问题是否为同义句，可以使用一些策略来帮助决定，例如：
    - 比较问题的关键词和主题。它们是否匹配或相关？ - 以不同的方式重写一个问题，看看是否仍然传达与另一个问题相同的信息。 - 考虑问题的上下文和目的。它们是否在询问相同类型的信息或回应？例如，“法国的首都是什么？”和“哪个城市是法国政府的所在地？”是同义句，因为它们都询问相同的事实，可以用相同的词（巴黎）回答。然而，“你怎么弹吉他？”和“有哪些吉他和弦？”不是同义句，因为它们询问不同类型的信息，并且具体程度不同。
    |'
