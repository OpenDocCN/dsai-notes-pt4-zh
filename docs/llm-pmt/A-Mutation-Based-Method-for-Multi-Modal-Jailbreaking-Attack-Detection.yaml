- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:47:25'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:47:25'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模态越狱攻击检测的突变基础方法
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10766](https://ar5iv.labs.arxiv.org/html/2312.10766)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2312.10766](https://ar5iv.labs.arxiv.org/html/2312.10766)
- en: Xiaoyu Zhang Xi’an Jiaotong UniversityXi’anChina [zxy0927@stu.xjtu.edu.cn](mailto:zxy0927@stu.xjtu.edu.cn)
    ,  Cen Zhang Nanyang Technological UniversitySingapore [cen001@e.ntu.edu.sg](mailto:cen001@e.ntu.edu.sg)
    ,  Tianlin Li Nanyang Technological UniversitySingapore [tianlin001@e.ntu.edu.sg](mailto:tianlin001@e.ntu.edu.sg)
    ,  Yihao Huang Nanyang Technological UniversitySingapore [huangyihao22@gmail.com](mailto:huangyihao22@gmail.com)
    ,  Xiaojun Jia Nanyang Technological UniversitySingapore [jiaxiaojunqaq@gmail.com](mailto:jiaxiaojunqaq@gmail.com)
    ,  Xiaofei Xie Singapore Management UniversitySingapore [xiaofei.xfxie@gmail.com](mailto:xiaofei.xfxie@gmail.com)
    ,  Yang Liu Nanyang Technological UniversitySingapore [yangliu@ntu.edu.sg](mailto:yangliu@ntu.edu.sg)
     and  Chao Shen Xi’an Jiaotong UniversityXi’anChina [chaoshen@xjtu.edu.cn](mailto:chaoshen@xjtu.edu.cn)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 张小宇 西安交通大学 西安 中国 [zxy0927@stu.xjtu.edu.cn](mailto:zxy0927@stu.xjtu.edu.cn) ，张岑
    南洋理工大学 新加坡 [cen001@e.ntu.edu.sg](mailto:cen001@e.ntu.edu.sg) ，李天林 南洋理工大学 新加坡 [tianlin001@e.ntu.edu.sg](mailto:tianlin001@e.ntu.edu.sg)
    ，黄一豪 南洋理工大学 新加坡 [huangyihao22@gmail.com](mailto:huangyihao22@gmail.com) ，贾晓军 南洋理工大学
    新加坡 [jiaxiaojunqaq@gmail.com](mailto:jiaxiaojunqaq@gmail.com) ，谢晓飞 新加坡管理大学 新加坡
    [xiaofei.xfxie@gmail.com](mailto:xiaofei.xfxie@gmail.com) ，刘洋 南洋理工大学 新加坡 [yangliu@ntu.edu.sg](mailto:yangliu@ntu.edu.sg)  和
    沈超 西安交通大学 西安 中国 [chaoshen@xjtu.edu.cn](mailto:chaoshen@xjtu.edu.cn)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs) have become pervasive
    and play a crucial role in numerous applications, powering everything from simple
    chatbots to complex decision-making systems. As their influence grows, so does
    the importance of their security; yet, modern LLMs are known to be vulnerable
    to jailbreaking attacks. These attacks can allow malicious users to exploit the
    models, making the case for effective jailbreak detection mechanisms an essential
    aspect of maintaining the integrity and trustworthiness of LLM-based applications.
    Although there are existing works dedicated to detecting jailbreak attacks, they
    have shown certain limitations. Notably, many current strategies are post-query
    based, which require specific target domain knowledge and only identify security
    breaches after they have occurred. Others, which are pre-query based, mainly focus
    on text-level attacks and fail to meet the increasingly complex multi-modal security
    requirements placed upon contemporary LLMs. This gap underscores the need for
    a more comprehensive approach to safeguarding these influential systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）和多模态LLMs（MLLMs）已变得无处不在，并在众多应用中发挥了关键作用，从简单的聊天机器人到复杂的决策系统。随着它们影响力的增长，它们的安全性也变得越来越重要；然而，现代LLMs已知容易受到越狱攻击。这些攻击可能允许恶意用户利用模型，从而使有效的越狱检测机制成为维护LLM应用程序完整性和可信赖性的关键方面。尽管已有一些工作致力于检测越狱攻击，但它们显示出某些局限性。值得注意的是，许多当前策略是基于查询后的，这需要特定的目标领域知识，并且仅在攻击发生后识别安全漏洞。其他基于查询前的方法主要关注文本级攻击，未能满足当代LLMs所面临的日益复杂的多模态安全需求。这一差距凸显了保护这些重要系统的全面方法的必要性。
- en: In this work, we propose JailGuard, the first mutation-based jailbreaking detection
    framework which supports both image and text modalities. Our key observation is
    that attack queries inherently possess less robustness compared to benign queries.
    Specifically, to confuse the model, attack queries are usually crafted with well-designed
    templates or complicate perturbations, leading to a fact that a slight disturbance
    in input may result in a drastic change in the response. This lack of robustness
    can be utilized in attack detection by first mutating the incoming input into
    variant queries and then checking the divergence of the responses of the variants.
    Based on this intuition, we designed and implemented a detection framework comprising
    19 different mutators and a divergence-based detection formula. To fully understand
    the effectiveness of our framework, we built the first multi-modal LLM jailbreaking
    attack dataset, which has 304 items of data, covering ten types of known jailbreaking
    attacks on image and text modalities. The evaluation suggests that JailGuard achieves
    the best detection accuracy of 89.38%/85.42% on image and text inputs, outperforming
    state-of-the-art defense methods by 15.28%.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出了JailGuard，这是第一个基于变异的越狱检测框架，支持图像和文本模态。我们关键的观察是攻击查询本质上比良性查询具有更少的鲁棒性。具体来说，为了混淆模型，攻击查询通常是通过精心设计的模板或复杂的扰动来构造的，导致输入的微小扰动可能会导致响应的剧烈变化。这种鲁棒性的缺乏可以通过首先将传入的输入变异为不同的查询，然后检查这些变异的响应的差异来利用于攻击检测。基于这一直觉，我们设计并实现了一个检测框架，包括19种不同的变异器和一个基于差异的检测公式。为了全面了解我们框架的有效性，我们建立了第一个多模态LLM越狱攻击数据集，其中包含304个数据项，涵盖了对图像和文本模态的十种已知越狱攻击。评估表明，JailGuard在图像和文本输入上的检测准确率分别为89.38%/85.42%，超越了最先进的防御方法15.28%。
- en: 'Jailbreaking Detection, LLM Security, Large Language Model^†^†copyright: none'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 越狱检测、LLM安全、大型语言模型^†^†版权：无
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 引言
- en: Large Language Models (LLMs) have become commonplace in our technological interactions,
    from chatbots to complex decision-making engines (gpt, [2023a](#bib.bib4); Chen
    et al., [2021](#bib.bib14)). They can perform tasks like understanding sentences,
    answering questions, and creating text that looks like it was written by a human.
    This has made them extremely helpful and valuable in many different areas. The
    advent of Multi-Modal Large Language Models (MLLMs) has expanded these functionalities
    even further by incorporating visual understanding, allowing them to interpret
    and generate imagery alongside text, enhancing user experience with rich, multi-faceted
    interactions (gpt, [2023b](#bib.bib5); Zhu et al., [2023a](#bib.bib57)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已在我们的技术互动中变得司空见惯，从聊天机器人到复杂的决策引擎（gpt, [2023a](#bib.bib4); Chen et
    al., [2021](#bib.bib14)）。它们可以执行诸如理解句子、回答问题以及生成看似由人类编写的文本等任务。这使得它们在许多不同领域变得极其有用和宝贵。多模态大型语言模型（MLLMs）的出现进一步扩展了这些功能，通过结合视觉理解，使其能够解释和生成图像，增强了用户体验，提供了丰富的多方面交互（gpt,
    [2023b](#bib.bib5); Zhu et al., [2023a](#bib.bib57)）。
- en: Despite their utility, the ubiquity of LLMs and MLLMs raises substantial security
    concerns. One key challenge is protecting against jailbreaking attacks, in which
    malicious attackers can manipulate models into violating rules or leaking confidential
    data (Deng et al., [2023](#bib.bib17); Zou et al., [2023](#bib.bib59); Chao et al.,
    [2023](#bib.bib13)). Such vulnerabilities can have far-reaching consequences,
    undermining the models’ reliability, exposing sensitive information, enabling
    the spread of misinformation, and damaging the overall trust in AI-driven applications.
    Addressing these security gaps is critical, particularly for MLLMs, whose visual
    capabilities could be weaponized to create deceptive or harmful multimedia content.
    Conclusively, there is an urgent need for strong protective measures that can
    prevent and respond to these jailbreaking attacks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大型语言模型（LLMs）和多模态大型语言模型（MLLMs）非常有用，但它们的普及引发了重大的安全担忧。一个关键挑战是防范越狱攻击，在这种攻击中，恶意攻击者可以操控模型违反规则或泄露机密数据（Deng
    et al., [2023](#bib.bib17); Zou et al., [2023](#bib.bib59); Chao et al., [2023](#bib.bib13)）。这些漏洞可能带来深远的后果，削弱模型的可靠性，暴露敏感信息，促进虚假信息的传播，破坏对AI驱动应用的整体信任。解决这些安全漏洞至关重要，特别是对于MLLMs，其视觉能力可能被武器化以创建具有欺骗性或有害的多媒体内容。总之，迫切需要强有力的保护措施，以防止和应对这些越狱攻击。
- en: 'There are several LLM defense researches, which can be divided into two categories:
    pre-query and post-query defenses. Post-query defenses are typically reactive,
    triggered after the model has already generated its outputs. These methods necessitate
    the construction of rules and detectors, such as those used in the Azure content
    detector (azu, [2023](#bib.bib3)), to discern and intercept inappropriate or sensitive
    content produced by the LLM. While post-query methods are effective, they require
    extensive domain knowledge and are only triggered after queries have been processed
    by models. On the contrary, pre-query defenses offer several benefits in terms
    of proactive deployment and application (Kumar et al., [2023](#bib.bib33); Robey
    et al., [2023](#bib.bib46)). Their deployment often requires minimal domain-specific
    knowledge, allowing for broader applicability. Techniques such as SmoothLLM (Robey
    et al., [2023](#bib.bib46)), which introduces random characters into input prompts,
    and semantic slicing of inputs, opt to tackle jailbreaking by manipulating and
    examining input data prior to query processing by LLMs. Such pre-emptive methods
    can prevent harmful inputs before they engage with the model, minimizing the risk
    of attacks. However, these pre-query strategies are primarily designed for text-based
    inputs, which cannot counter attacks involving multiple modalities. The limitations
    of existing approaches underscore the need for a more comprehensive approach to
    protect these state-of-the-art LLMs.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种LLM防御研究，可以分为两类：查询前和查询后防御。查询后防御通常是反应性的，在模型生成输出之后触发。这些方法需要构建规则和检测器，例如在Azure内容检测器中使用的（azu，[2023](#bib.bib3)），以辨别和拦截LLM生成的不适当或敏感内容。虽然查询后方法有效，但它们需要广泛的领域知识，并且只有在模型处理完查询之后才会被触发。相反，查询前防御在主动部署和应用方面提供了若干好处（Kumar等，[2023](#bib.bib33)；Robey等，[2023](#bib.bib46)）。它们的部署通常需要最少的领域特定知识，从而允许更广泛的适用性。诸如SmoothLLM（Robey等，[2023](#bib.bib46)）的技术，通过在输入提示中引入随机字符，以及对输入的语义切片，选择通过操控和检查输入数据来应对越狱行为，优先处理LLM处理查询之前的数据。这些主动方法可以在输入与模型互动之前阻止有害输入，减少攻击风险。然而，这些查询前策略主要针对基于文本的输入，无法对抗涉及多模态的攻击。现有方法的局限性突显了保护这些最先进LLM的需求。
- en: To address these limitations, we designed and implemented the first mutation-based
    jailbreaking defense framework, JailGuard, which supports attack detection on
    both image and text modalities. The key observation behind JailGuard is that attack
    queries inherently exhibit lower robustness than benign queries. To confuse LLMs,
    attack inputs are often generated based on crafted templates or by an extensive
    searching process with complex perturbations. This leads to a result that any
    minor modification to the inputs may invalidate its attack effectiveness, which
    appears as a significant change in output. In JailGuard, we design detection strategies
    based on this inherent fragility of attack queries. The whole process is that
    we first mutate the original input into a series of variant queries. Then the
    consistency of the responses of LLM systems to variants is analyzed. If a notable
    discrepancy can be identified among the responses, i.e., a divergence value that
    exceeds the threshold, a potential jailbreaking attack is identified. Overall,
    the JailGuard framework is comprised of 19 mutators and a divergence-based detection
    formula to identify potential attacks. Considering the characteristics of image
    size, color as well as the semantics of the text at the character, word, and sentence
    levels, we designed 10 image mutators and 9 text mutators to comprehensively disturb
    the input queries and generate variants. Then the detection formula identifies
    attacks by judging whether the divergence of variants’ responses exceeds a built-in
    threshold.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些局限性，我们设计并实施了第一个基于突变的越狱防御框架JailGuard，支持图像和文本模态的攻击检测。JailGuard的关键观察是攻击查询本质上表现出比正常查询更低的鲁棒性。为了迷惑LLM，攻击输入通常基于精心设计的模板或通过复杂扰动的广泛搜索过程生成。这导致任何对输入的微小修改都可能使其攻击效果失效，从而在输出中出现显著变化。在JailGuard中，我们基于攻击查询的这种固有脆弱性设计了检测策略。整个过程是，我们首先将原始输入突变为一系列变体查询。然后分析LLM系统对变体的响应一致性。如果能在响应中识别出明显的差异，即超出阈值的偏离值，则识别出潜在的越狱攻击。总体而言，JailGuard框架包括19个突变器和一个基于偏离的检测公式来识别潜在攻击。考虑到图像大小、颜色以及文本在字符、词语和句子层面的语义，我们设计了10个图像突变器和9个文本突变器，以全面扰乱输入查询并生成变体。然后，检测公式通过判断变体响应的偏离是否超过内置阈值来识别攻击。
- en: To comprehensively evaluate JailGuard, we construct the first multi-modal LLM
    jailbreaking attack dataset that covers ten types of jailbreak attacks on image
    and text modalities. The evaluation on our dataset shows that JailGuard can effectively
    detect jailbreaking attacks on image and text modalities. JailGuard has separately
    achieved the best detection accuracy of 89.38% and 85.42% on image and text inputs,
    outperforming state-of-the-art defense methods by 15.28%. In addition, JailGuard
    can effectively detect and defend different types of jailbreaking attacks. On
    all types of collected attacks collected, the best detection accuracy of JailGuard
    is always more than 70%. By contrast, the best detection accuracy of the state-of-the-art
    baseline methods on any collected attacks is lower than JailGuard, and even less
    than 10% on ‘GPT4simulator’ and ‘MasterKey-poc’ attacks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估JailGuard，我们构建了第一个多模态LLM越狱攻击数据集，涵盖了图像和文本模态上的十种越狱攻击。对我们数据集的评估表明，JailGuard能够有效检测图像和文本模态上的越狱攻击。JailGuard在图像和文本输入上的检测准确率分别达到了89.38%和85.42%，超越了最先进的防御方法15.28%。此外，JailGuard能有效检测和防御不同类型的越狱攻击。在所有收集到的攻击类型中，JailGuard的最佳检测准确率始终超过70%。相比之下，最先进的基线方法在任何收集到的攻击上的最佳检测准确率都低于JailGuard，甚至在‘GPT4simulator’和‘MasterKey-poc’攻击中不到10%。
- en: 'In summary, our contributions are:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们的贡献是：
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We identified the inherent low robustness of jailbreaking attack inputs. Based
    on that, we designed and implemented the first mutation-based multi-modal jailbreaking
    detection framework, JailGuard, which supports detection for both image and text
    modalities.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们识别出了越狱攻击输入的固有低鲁棒性。基于此，我们设计并实施了第一个基于突变的多模态越狱检测框架JailGuard，支持图像和文本模态的检测。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We constructed the first jailbreaking attack dataset that covers both image
    and text inputs.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们构建了第一个涵盖图像和文本输入的越狱攻击数据集。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We performed experiments on our constructed dataset, and JailGuard has achieved
    better detection effects than the state-of-the-art defense methods (Robey et al.,
    [2023](#bib.bib46)).
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在构建的数据集上进行了实验，JailGuard在检测效果上优于最先进的防御方法（Robey et al., [2023](#bib.bib46)）。
- en: 2\. Background
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 背景
- en: 'Jailbreaking attack aims to design and generate an attack prompt $P_{a}$, which
    can be represented as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 越狱攻击旨在设计和生成一个攻击提示 $P_{a}$，其表示为：
- en: '|  | $\text{ find }P_{a}\text{ \quad subject to }\quad\operatorname{eval}(M(P_{a}),T)=\operatorname{eval}(R,T)=1,$
    |  |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|  | $\text{ find }P_{a}\text{ \quad subject to }\quad\operatorname{eval}(M(P_{a}),T)=\operatorname{eval}(R,T)=1,$
    |  |'
- en: where $eval(\cdot)$.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $eval(\cdot)$。
- en: The open-source community has manually collected and evaluated a series of effective
    jailbreak prompts and templates, which can be classified into three categories
    based on their patterns, namely ‘Attention Shifting’, ‘Pretending’, and ‘Privilege
    Escalation’ (Liu et al., [2023b](#bib.bib36)). The methods in ‘Attention Shifting’
    leverage specific tasks or contents to change both the conversation context and
    intention and divert LLM-based applications’ attention to conduct the attack.
    ‘Pretending’ methods alter the conversation background or context to mislead LLMs,
    and ‘Privilege Escalation’ guides LLMs through elaborated instructions to break
    any existing constraints.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 开源社区手动收集并评估了一系列有效的越狱提示和模板，这些提示和模板根据其模式可以分为三类，即‘注意力转移’，‘伪装’和‘权限提升’（Liu et al.,
    [2023b](#bib.bib36)）。‘注意力转移’方法利用特定任务或内容来改变对话背景和意图，从而将基于LLM的应用程序的注意力转移进行攻击。‘伪装’方法则通过改变对话背景或上下文来误导LLM，而‘权限提升’则通过详细说明引导LLM突破任何现有的限制。
- en: To effectively and automatically generate jailbreak prompts, researchers proposed
    a variety of attack methods (Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17);
    Chao et al., [2023](#bib.bib13); Zhu et al., [2023b](#bib.bib58); Yu et al., [2023](#bib.bib54)).
    Zou et al. (Zou et al., [2023](#bib.bib59)) designed the greedy coordinate gradient-based
    search (GCG) to produce adversarial suffix to attack open-sourced LLMs (e.g.,
    Vicuna (Zheng et al., [2023](#bib.bib56))), which has proven its effectiveness
    through transfer attacks on black-box commercial LLMs. We transfer the GCG attack
    on the Vicuna model to OpenAI GPT-3.5 and collect them into datasets in [§ 5](#S5
    "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). Deng et al. (Deng et al., [2023](#bib.bib17)) proposed MasterKey,
    which trains a model to learn from existing effective attack patterns and automatically
    generates new attacks to bypass the defense mechanisms of four commercial LLM
    systems. We collect two types of attacks generated by Masters in [§ 5](#S5 "5\.
    Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection"), namely proof-of-concept (POC) attacks and continuation-based attacks.
    With the emergence of MLLMs, researchers designed a visual jailbreaking attack
    based on the implanted adversarial perturbation in the image inputs (Qi et al.,
    [2023](#bib.bib44)). Their method achieved a high attack success rate on MiniGPT-4
    which is one of the state-of-the-art MLLMs (Qi et al., [2023](#bib.bib44)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效且自动生成越狱提示，研究人员提出了多种攻击方法（Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17);
    Chao et al., [2023](#bib.bib13); Zhu et al., [2023b](#bib.bib58); Yu et al., [2023](#bib.bib54)）。Zou
    et al.（Zou et al., [2023](#bib.bib59)）设计了贪婪坐标梯度搜索（GCG），以生成对抗性后缀攻击开源LLMs（例如，Vicuna（Zheng
    et al., [2023](#bib.bib56)）），该方法通过对黑箱商业LLMs的转移攻击证明了其有效性。我们将GCG攻击从Vicuna模型迁移到OpenAI
    GPT-3.5，并将其收集到数据集中，在[§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")中进行描述。Deng et al.（Deng et al.,
    [2023](#bib.bib17)）提出了MasterKey，该方法训练模型从现有有效的攻击模式中学习，并自动生成新的攻击以绕过四个商业LLM系统的防御机制。我们在[§
    5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")中收集了MasterKey生成的两种攻击类型，即概念验证（POC）攻击和基于续续的攻击。随着MLLMs的出现，研究人员设计了一种基于图像输入中植入的对抗性扰动的视觉越狱攻击（Qi
    et al., [2023](#bib.bib44)）。他们的方法在MiniGPT-4上取得了高的攻击成功率，而MiniGPT-4是最先进的MLLM之一（Qi
    et al., [2023](#bib.bib44)）。
- en: LLM defense methods can be divided into pre-query defense and post-query defense.
    LLM systems mainly leverage content detectors in the output stage to determine
    whether the model output is toxic (azu, [2023](#bib.bib3)). These content detectors
    are complex systems that evaluate the toxicity of the given input based on built-in
    rules and integrated models. Therefore, their detection results are greatly affected
    by the design of rules. At the input stage, one of the state-of-the-art defense
    methods is SmoothLLM (Robey et al., [2023](#bib.bib46)), which implemented three
    perturbation strategies (i.e., Swap, Insert, and Patch) and aggregated the responses
    of perturbed inputs to detect jailbreaks. These perturbation strategies randomly
    select 10% of characters in the input and insert or swap with random characters
    to generate several perturbed inputs. Then, in the aggregation stage, SmoothLLM
    checks the LLM system responses of perturbed inputs. If more than half of them
    contain jailbreak keywords (Zou et al., [2023](#bib.bib59)) (e.g., ‘I cannot help
    with that’), the source input will be judged as a jailbreak input. Although existing
    defenses demonstrate their effectiveness in experiments, they only focus on text
    input and output and cannot support LLM inputs on other modalities, such as images.
    In this paper, we propose the first multi-modal LLM jailbreaking detection framework,
    JailGuard, that detects and defends jailbreaking attacks on both image and text
    modalities.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LLM防御方法可以分为查询前防御和查询后防御。LLM系统主要利用输出阶段的内容检测器来判断模型输出是否具有毒性（azu，[2023](#bib.bib3)）。这些内容检测器是复杂的系统，通过内置规则和集成模型评估给定输入的毒性。因此，它们的检测结果受规则设计的影响很大。在输入阶段，最先进的防御方法之一是SmoothLLM（Robey等，[2023](#bib.bib46)），它实现了三种扰动策略（即Swap、Insert和Patch），并通过聚合扰动输入的响应来检测破解。这些扰动策略随机选择输入中的10%字符，并用随机字符进行插入或交换，以生成若干个扰动输入。然后，在聚合阶段，SmoothLLM检查扰动输入的LLM系统响应。如果其中超过一半包含破解关键词（Zou等，[2023](#bib.bib59)）（例如，“我不能帮忙”），源输入将被判定为破解输入。尽管现有防御方法在实验中显示了其有效性，但它们只关注文本输入和输出，无法支持LLM在其他模态（如图像）上的输入。本文提出了首个多模态LLM破解检测框架JailGuard，能够检测和防御图像和文本模态上的破解攻击。
- en: '![Refer to caption](img/36e9ca813a5bef6ca67828d94257d1d8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/36e9ca813a5bef6ca67828d94257d1d8.png)'
- en: Figure 1. Motivation Case of JailGuard (Red Highlights Toxic Contents and Some
    of Them are Blocked)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. JailGuard的动机案例（红色高亮显示有毒内容，其中一些被阻止）
- en: 3\. Motivation
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 动机
- en: Existing LLM jailbreaking methods (Zou et al., [2023](#bib.bib59); Liu et al.,
    [2023b](#bib.bib36); Deng et al., [2023](#bib.bib17)) mainly rely on specific
    templates or tiny but complicated perturbations to conduct attacks. These elaborate
    perturbations and templates can shift the attention of the LLM system and application
    and deceive its built-in defense mechanisms. Although these elaborate attacks
    have achieved excellent attack results, they are less robust than benign queries
    and easily disrupted and fail. Such a difference in robustness can be used to
    distinguish between attack and benign queries.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的LLM破解方法（Zou等，[2023](#bib.bib59)；Liu等，[2023b](#bib.bib36)；Deng等，[2023](#bib.bib17)）主要依赖于特定模板或微小但复杂的扰动来进行攻击。这些精巧的扰动和模板可以转移LLM系统和应用的注意力，并欺骗其内置的防御机制。尽管这些精巧的攻击取得了出色的攻击结果，但它们的鲁棒性不如良性查询，容易被干扰和失败。这种鲁棒性差异可以用来区分攻击和良性查询。
- en: We have provided two motivation examples at image and text modalities in [Figure 1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). The upper and lower parts separately show attack and benign
    queries that are from our image and text dataset ([§ 5](#S5 "5\. Dataset Construction
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")). For
    the image and text queries, we randomly select one mutator to generate six variants,
    as shown in [§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").b). These mutators can mask part of
    the input, insert specific strings to the text (e.g., ‘[mask]’), or change the
    image color, etc. Detailed descriptions of mutators are shown in [§ 4.1](#S4.SS1
    "4.1\. Variant Generator ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection"). Then we obtain the responses of the variant queries
    on LLM systems and applications (using MiniGPT-4 for images and GPT-3.5 for texts),
    as shown in [Figure 1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection").c). We use red to mark the toxic
    and harmful content in the response. Finally, we vectorize the response results
    and compute the divergence between each set of variant responses. The heat maps
    in [Figure 1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").d) visualize the divergence between
    the responses of six variants from one input of the LLM-based application.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[图1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")中提供了图像和文本模态的两个动机示例。上部和下部分别展示了来自我们图像和文本数据集的攻击性和良性查询([§
    5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"))。对于图像和文本查询，我们随机选择一个变异器生成六个变体，如[§ 5](#S5 "5\. Dataset Construction
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").b)所示。这些变异器可以遮蔽输入的部分内容、向文本中插入特定字符串（例如‘[mask]’）或改变图像颜色等。变异器的详细描述见[§
    4.1](#S4.SS1 "4.1\. Variant Generator ‣ 4\. System Design ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")。然后，我们在LLM系统和应用程序上获取变体查询的响应（对图像使用MiniGPT-4，对文本使用GPT-3.5），如[图1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").c)所示。我们使用红色标记响应中的有害和危险内容。最后，我们对响应结果进行向量化，并计算每组变体响应之间的差异。[图1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").d)中的热图可视化了LLM基础应用程序的一个输入的六个变体响应之间的差异。
- en: We can observe that regardless of the input modality and the used mutators,
    attack queries are more susceptible to perturbations than benign inputs. In attack
    images, mutators can cause the responses of variants to dramatically change from
    toxic content targeting a specific group to denial-of-service replies (e.g., “I
    am sorry…”). In contrast, the LLM system can still perform the given instructions
    (e.g., “describing the image”) on benign inputs. Affected by mutators, there are
    inevitable differences between the benign responses, but this difference is trivial
    compared to the difference in responses to attack images. As shown in [Figure 1](#S2.F1
    "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").d), there is a clear color difference in the heat map of the
    response of attack image variants, which implies a large divergence value and
    a large difference between the responses’ semantics. We can make similar observations
    on the text input in the lower part of [Figure 1](#S2.F1 "Figure 1 ‣ 2\. Background
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). This
    shows that the lack of robustness of attack queries is a common characteristic
    in different modalities. Based on the observation, we design the first mutation-based
    jailbreaking detection framework, JailGuard, that mutates the untrusted queries
    into variants and then checks the divergence of the LLM system responses of the
    variant queries and effectively detects jailbreaking attacks.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，无论输入模态和使用的变异器如何，攻击查询比良性输入更容易受到扰动。在攻击图像中，变异器可以导致变体的响应从针对特定群体的有害内容剧烈变化为拒绝服务的回复（例如，“对不起……”）。相比之下，LLM
    系统仍然可以对良性输入执行给定的指令（例如，“描述图像”）。受到变异器的影响，良性响应之间存在不可避免的差异，但与对攻击图像的响应差异相比，这种差异微不足道。如[图
    1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection").d) 所示，攻击图像变体的响应热图中存在明显的颜色差异，这表明大分歧值和响应语义之间的大差异。我们可以在[图
    1](#S2.F1 "Figure 1 ‣ 2\. Background ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") 的下半部分的文本输入上做出类似的观察。这表明攻击查询在不同模态下缺乏鲁棒性是一个普遍特征。基于这一观察，我们设计了第一个基于变异的越狱检测框架
    JailGuard，它将不可信的查询变异为变体，然后检查变体查询的 LLM 系统响应的差异，从而有效地检测越狱攻击。
- en: 4\. System Design
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 系统设计
- en: JailGuard is implemented on top of the LLM system and application workflow,
    and [Figure 2](#S4.F2 "Figure 2 ‣ 4\. System Design ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") shows the overview. JailGuard
    consists of the Variant Generator module and Attack Detector module that are portable
    and migratory. Inspired by previous research on fuzz testing (Xie et al., [2019](#bib.bib50);
    Zhang et al., [2021](#bib.bib55)) and model robustness (Frosio and Kautz, [2023](#bib.bib19);
    Morris et al., [2020](#bib.bib41)), for the untrusted query, the variant generator
    of JailGuard first selects a built-in mutator for the query and generates a variant
    set. The attack detector then uses these variants to query the target LLM system
    and computes the semantic similarity and divergence between variant responses,
    and finally leverages the built-in thresholds to identify benign and attack queries.
    The former can access LLM system without a barrier, and JailGuard will discard
    and report the latter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: JailGuard 实现于 LLM 系统和应用工作流之上，[图 2](#S4.F2 "Figure 2 ‣ 4\. System Design ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection") 展示了概览。JailGuard
    包含可移植和可迁移的变体生成模块和攻击检测模块。受之前的模糊测试研究（Xie 等，[2019](#bib.bib50)；Zhang 等，[2021](#bib.bib55)）和模型鲁棒性研究（Frosio
    和 Kautz，[2023](#bib.bib19)；Morris 等，[2020](#bib.bib41)）的启发，对于不可信的查询，JailGuard
    的变体生成器首先为查询选择一个内置的变异器并生成变体集。攻击检测器随后使用这些变体查询目标 LLM 系统，并计算变体响应之间的语义相似性和差异，最终利用内置的阈值识别良性和攻击查询。前者可以无障碍地访问
    LLM 系统，而 JailGuard 将丢弃并报告后者。
- en: In real-world scenarios, JailGuard should be deployed and applied as a part
    of LLM system and application workflow to prevent jailbreaks, which means that
    JailGuard and perform defense from the perspective of developers. At this time,
    it should have access to the underlying interface of LLMs and can query multiple
    variants in a batch and obtain multiple responses simultaneously. In our experiments,
    we simulate this process by accessing the LLM system’s API multiple times.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，JailGuard 应作为 LLM 系统和应用工作流的一部分进行部署和应用，以防止越狱，这意味着 JailGuard 从开发者的角度进行防御。此时，它应能够访问
    LLM 的底层接口，并能够批量查询多个变体并同时获取多个响应。在我们的实验中，我们通过多次访问 LLM 系统的 API 来模拟这一过程。
- en: '![Refer to caption](img/c28fb576ee7c23f3ef5391a714e2a70a.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c28fb576ee7c23f3ef5391a714e2a70a.png)'
- en: Figure 2. Overview of JailGuard
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. JailGuard 概述
- en: '![Refer to caption](img/8536663978e1e8830c04c5af8d2a802c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8536663978e1e8830c04c5af8d2a802c.png)'
- en: Figure 3. Demo Case for 10 Mutators of JailGuard (Red Marks the Modification
    of Text Input and Underline Marks Important Sentences)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3. JailGuard 10 种变异器的演示案例（红色标记表示文本输入的修改，下划线标记表示重要句子）
- en: 4.1\. Variant Generator
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 变体生成器
- en: The main role of the variant generator is to select a mutation operation on
    the original untrusted input prompt $P$ indicates the number of variants. The
    variant generator in JailGuard has currently implemented a total of 19 mutators
    at image and text modalities, including 16 random mutators and 3 advanced mutators.
    We have provided a demo for some mutators in [Figure 3](#S4.F3 "Figure 3 ‣ 4\.
    System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 变体生成器的主要作用是选择对原始不可信输入提示 $P$ 进行变异操作，这表示变体的数量。JailGuard 中的变体生成器目前已在图像和文本模式下实现了总共
    19 种变异器，包括 16 种随机变异器和 3 种高级变异器。我们在 [图 3](#S4.F3 "Figure 3 ‣ 4\. System Design
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中提供了一些变异器的演示。
- en: 4.1.1\. Random Mutators
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1\. 随机变异器
- en: The design of random mutators is inspired by existing work (Hendrycks et al.,
    [2019](#bib.bib27); Lopes et al., [2019](#bib.bib37); Bayer et al., [2022](#bib.bib11);
    Marivate and Sefara, [2020](#bib.bib39); Karimi et al., [2021](#bib.bib32)). They
    use various data augmentation methods to randomly change input images or texts
    and generate variants.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变异器的设计灵感来源于现有的工作 (Hendrycks et al., [2019](#bib.bib27); Lopes et al., [2019](#bib.bib37);
    Bayer et al., [2022](#bib.bib11); Marivate and Sefara, [2020](#bib.bib39); Karimi
    et al., [2021](#bib.bib32))。他们使用各种数据增强方法随机改变输入图像或文本并生成变体。
- en: There are 10 random mutators for image inputs, namely Random Mask, Random Solarization,
    Horizental Flip, Vertical Flip, Crop and Resize, Random Grayscale, Gaussian Blur,
    Random Rotation, Colorjitter, and Random Posterization. Details are shown as follows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像输入，有10种随机变异器，即随机遮罩、随机太阳化、水平翻转、垂直翻转、裁剪和调整大小、随机灰度、Gaussian模糊、随机旋转、颜色抖动和随机伪彩色。详细信息如下所示。
- en: Random Mask mutator inserts a small black mask to a random position of the image,
    as shown in [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection").a). It has the chance to
    destroy the implanted perturbations in attack images, leading to a drastic change
    in LLM system responses.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 随机遮罩变异器将一个小黑色遮罩插入到图像的随机位置，如 [图 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection").a)所示。它有可能破坏攻击图像中植入的扰动，从而导致
    LLM 系统响应的剧烈变化。
- en: Random Solarization mutator inverts all pixel values above a random threshold
    with a certain probability, resulting in solarizing the input image, as shown
    in [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").b). This mutator can introduce perturbations
    for the whole image without damaging the overall information in the image.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 随机太阳化变异器以某种概率将所有超过随机阈值的像素值反转，从而对输入图像进行太阳化，如 [图 3](#S4.F3 "Figure 3 ‣ 4\. System
    Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").b)所示。这个变异器可以对整张图像引入扰动，而不会损坏图像的整体信息。
- en: Horizental Flip and Vertical Flip respectively flip the target image horizontally
    or vertically with a random probability between 0 to 1. They will not modify the
    pixel values in the image, and we have provided an example of Horizental Flip
    in [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").c).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 水平翻转和垂直翻转分别以0到1之间的随机概率水平或垂直翻转目标图像。它们不会修改图像中的像素值，我们在[图 3](#S4.F3 "Figure 3 ‣
    4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection").c)中提供了水平翻转的示例。
- en: Random Grayscale is a commonly used data augmentation method that converts an
    RGB image into a grayscale image with a random probability between 0 to 1 (He
    et al., [2020](#bib.bib26); Gong et al., [2021](#bib.bib22); Bai et al., [2022](#bib.bib10)).
    [Figure 3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection").d) provides a demo.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 随机灰度是一种常用的数据增强方法，它将RGB图像转换为灰度图像，概率在0到1之间 (He et al., [2020](#bib.bib26); Gong
    et al., [2021](#bib.bib22); Bai et al., [2022](#bib.bib10))。 [图 3](#S4.F3 "Figure
    3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection").d) 提供了演示。
- en: Crop and Resize (Bai et al., [2022](#bib.bib10)) can disturb attack images without
    changing color and style. It first crops a random aspect of the original image
    and then resizes it to a random size, as shown in [Figure 3](#S4.F3 "Figure 3
    ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection").e).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 裁剪和调整大小 (Bai et al., [2022](#bib.bib10)) 可以在不改变颜色和风格的情况下扰乱攻击图像。它首先裁剪原始图像的随机部分，然后将其调整为随机大小，如[图
    3](#S4.F3 "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection").e)所示。
- en: Gaussian Blur (Bai et al., [2022](#bib.bib10)) blurs images with the Gaussian
    function with a random kernel size. It reduces the sharpness or high-frequency
    details in an image, which intuitively helps to disrupt the potential attack in
    image inputs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯模糊 (Bai et al., [2022](#bib.bib10)) 使用具有随机核大小的高斯函数对图像进行模糊处理。它减少了图像的锐度或高频细节，直观上有助于扰乱图像输入中的潜在攻击。
- en: Random Rotation (Gidaris et al., [2018](#bib.bib21); Cubuk et al., [2020](#bib.bib16))
    rotates the image by a random number of degrees between 0 to 180. After rotation,
    the area that exceeds the original size will be cropped.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 随机旋转 (Gidaris et al., [2018](#bib.bib21); Cubuk et al., [2020](#bib.bib16))
    以0到180度之间的随机角度旋转图像。旋转后，超出原始尺寸的区域将被裁剪。
- en: Colorjitter (He et al., [2020](#bib.bib26)) randomly modifies the brightness
    and hue of images and introduces variations in their color properties.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Colorjitter (He et al., [2020](#bib.bib26)) 随机修改图像的亮度和色调，并引入颜色属性的变化。
- en: Random Posterization randomly posterizes an image by reducing the number of
    bits for each color channel. It can remove the small perturbations and output
    a more stylized and simplified image.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随机量化通过减少每个颜色通道的位数来随机对图像进行量化。它可以去除小的扰动，并输出更具风格化和简化的图像。
- en: The random text mutators consist of seven random mutators, namely Random Replacement,
    Random Insertion, Random Deletion, Synonym Replacement, Punctuation Insertion,
    and Translation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 随机文本变异器包括七种随机变异器，即随机替换、随机插入、随机删除、同义词替换、标点符号插入和翻译。
- en: Random Replacement and Random Insertion perform the replacement or insertion
    operation with probability $p$.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 随机替换和随机插入以概率$p$执行替换或插入操作。
- en: Synonym Replacement selects words in the text input and uses their synonyms
    to replace them based on WordNet (Miller, [1995](#bib.bib40)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 同义词替换选择文本输入中的单词，并使用其同义词进行替换，基于WordNet (Miller, [1995](#bib.bib40))。
- en: Punctuation Insertion is from existing data augmentation method that randomly
    inserts punctuation masks into sentence (Karimi et al., [2021](#bib.bib32)). This
    mutator has the potential to disturb the adversarial-based jailbreaking attack
    without changing the semantics of the input sentence.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 标点符号插入来源于现有的数据增强方法，它随机将标点符号掩码插入句子 (Karimi et al., [2021](#bib.bib32))。该变异器有可能扰乱基于对抗的越狱攻击，而不会改变输入句子的语义。
- en: Translation first translates the input sentence to a random language and then
    translates it back. For jailbreak queries, the translation process can rewrite
    the attack templates and remove the meaningless characters, ultimately invalidating
    the attack.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译首先将输入句子翻译成随机语言，然后再翻译回来。对于越狱查询，翻译过程可以重写攻击模板，并去除无意义的字符，*最终使攻击无效*。
- en: 4.1.2\. Advanced Mutators
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2\. 高级变异器
- en: Although random mutators have the potential to disrupt jailbreak attacks, they
    lack proper guidance, resulting in limited effectiveness. On the one hand, for
    complex jailbreak attacks (e.g., ‘Attention Shifting’ (Liu et al., [2023b](#bib.bib36))),
    simple random operators may not be able to cause enough interference to the attack
    input, resulting in the defense being bypassed. On the other hand, blindly modifying
    the input may cause benign inputs to be compromised, which leads to dramatic changes
    in their responses‘ semantics. This is especially true in the text, where small
    changes to a word may completely change its meaning. To achieve a better detection
    effect, we design and implement three advanced text mutators in JailGuard, namely
    Targeted Replacement, Targeted Insertion, and Rephrasing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管随机变异器有可能干扰越狱攻击，但它们缺乏适当的指导，导致效果有限。一方面，对于复杂的越狱攻击（例如，‘注意力转移’（Liu et al., [2023b](#bib.bib36)）），简单的随机操作符可能无法对攻击输入造成足够的干扰，从而导致防御被绕过。另一方面，盲目修改输入可能会导致良性输入受到影响，进而导致其响应的语义发生剧烈变化。这在文本中尤其如此，因为对一个词的小改动可能完全改变其意义。为了实现更好的检测效果，我们在JailGuard中设计并实现了三种高级文本变异器，即定向替换、定向插入和改写。
- en: Targeted Replacement and Targeted Insertion are the advanced version of Random
    Replacement and Random Insertion. Inspired by existing nature language processing
    work (Nenkova and Vanderwende, [2005](#bib.bib42)), these two advanced mutators
    first find the sentences with the highest word frequency in the input text, which
    means that words in these sentences appear repeatedly in the whole input and often
    represent the summary of the input text. Then these mutators select these sentences
    as the important sentences. The characters in important sentences have a higher
    probability of performing replacement and insertion. We provide two cases in [Figure 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").h) and i). Italicized and underlined sentences represent selected
    important sentences.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 定向替换和定向插入是随机替换和随机插入的高级版本。受到现有自然语言处理工作的启发（Nenkova 和 Vanderwende, [2005](#bib.bib42)），这两个高级变异器首先找到输入文本中词频最高的句子，这意味着这些句子中的词在整个输入中反复出现，并且通常代表输入文本的总结。然后，这些变异器选择这些句子作为重要句子。重要句子中的字符更有可能进行替换和插入。我们在
    [图3](#S4.F3 "图 3 ‣ 4. 系统设计 ‣ 基于变异的方法进行多模态越狱攻击检测") 中提供了两个案例。斜体和下划线的句子表示选定的重要句子。
- en: 'Rephrasing is one intuitive way to collapse the jailbreak template and remove
    the attack perturbations in the input. Rephrasing mutator in JailGuard uses the
    prompt of "Please rephrase the following paragraph while ensuring its core semantics
    and contents unchanged. The paragraph is: [INSERT ORIGIN INPUTS]" to query OpenAI
    GPT-3.5 and rewrite the original input while preserving semantics. [Figure 3](#S4.F3
    "Figure 3 ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").j) shows a demo of this mutator, and red marks the changed
    content in the variant.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 改写是一种直观的方法，可以合并越狱模板并去除输入中的攻击扰动。JailGuard中的改写变异器使用“请改写以下段落，同时确保其核心语义和内容不变。段落是：[INSERT
    ORIGIN INPUTS]”的提示来查询OpenAI GPT-3.5，并在保持语义的同时改写原始输入。[图3](#S4.F3 "图 3 ‣ 4. 系统设计
    ‣ 基于变异的方法进行多模态越狱攻击检测") 展示了这个变异器的演示，并用红色标记了变体中变化的内容。
- en: 4.2\. Attack Detector
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2. 攻击检测器
- en: 'Our detector operates by leveraging the divergence among outputs to effectively
    achieve detection. The calculation of divergence proceeds through the following
    steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的检测器通过利用输出之间的差异来有效实现检测。差异的计算经过以下步骤：
- en: 'Constructing the similarity matrix For the input variant set $\mathcal{P}$
    can be represented as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 构建相似性矩阵，对于输入变体集 $\mathcal{P}$ 可以表示为：
- en: '|  | $S_{i,j}=COS(V_{i},V_{j})=\frac{V_{i}\cdot V_{j}}{\&#124;V_{i}\&#124;\&#124;V_{j}\&#124;},$
    |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '|  | $S_{i,j}=COS(V_{i},V_{j})=\frac{V_{i}\cdot V_{j}}{\&#124;V_{i}\&#124;\&#124;V_{j}\&#124;},$
    |  |'
- en: where $COS(\cdot)$.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $COS(\cdot)$。
- en: Characterizing each response In the $N\times N$ to the other responses in the
    matrix.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表征每个响应在矩阵中 $N\times N$ 对其他响应的特征。
- en: '|  | $Q_{i}=Q(X=i)=\&#124;S_{i,\cdot}\&#124;_{1}.$ |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $Q_{i}=Q(X=i)=\&#124;S_{i,\cdot}\&#124;_{1}.$ |  |'
- en: 'Quantifying the divergence of two responses Then JailGuard uses Kullback-Leibler
    (KL) divergence to quantify the difference between the similarity distributions
    of two responses $(Q_{i},Q_{j})$:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 量化两个响应的发散性 然后 JailGuard 使用 Kullback-Leibler (KL) 发散性来量化两个响应 $(Q_{i},Q_{j})$
    的相似性分布之间的差异：
- en: '|  | $D_{i,j}=D(Q_{i}\&#124;Q_{j})=\sum_{x=1}^{N}Q_{i}(x)\log(\frac{Q_{i}(x)}{Q_{j}(x)}).$
    |  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  | $D_{i,j}=D(Q_{i}\&#124;Q_{j})=\sum_{x=1}^{N}Q_{i}(x)\log(\frac{Q_{i}(x)}{Q_{j}(x)}).$
    |  |'
- en: The divergence values for response pairs are represented in an $N\times N$.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 响应对的发散值表示为 $N\times N$。
- en: 'Examining the divergence Finally, for the obtained divergence $N\times N$,
    JailGuard will consider the original input as an attack input, otherwise it is
    judged as a benign input, which is shown as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 检查发散性 最后，对于获得的发散值 $N\times N$，JailGuard 会将原始输入视为攻击输入，否则判断为良性输入，如下所示：
- en: '|  | $\exists i,j\in\{1,2,\ldots,N\},D_{i,j}\geq\theta\rightarrow P\cup\mathcal{P}_{a},$
    |  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  | $\exists i,j\in\{1,2,\ldots,N\},D_{i,j}\geq\theta\rightarrow P\cup\mathcal{P}_{a},$
    |  |'
- en: where $\mathcal{P}_{a}$ indicates the set of jailbreaking attacks.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{P}_{a}$ 表示越狱攻击的集合。
- en: To maximize the detection effect of JailGuard, we randomly selected 70/80 text/image
    inputs from our dataset ([§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")) and calculated the divergence
    of their variants. Based on the results, we choose $\theta=0.01$, JailGuard will
    directly determine them as attack inputs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化 JailGuard 的检测效果，我们从数据集中随机选择了 70/80 个文本/图像输入（[§ 5](#S5 "5\. 数据集构建 ‣ 一种基于变异的方法用于多模态越狱攻击检测")），并计算了其变体的发散性。根据结果，我们选择
    $\theta=0.01$，JailGuard 将直接将其确定为攻击输入。
- en: Table 1. Jailbreak Questions in Dataset
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 数据集中越狱问题
- en: '| Category | Attack Method | Description |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 攻击方法 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Attention Shifting | GPT4similator |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 注意力转移 | GPT4similator |'
- en: '&#124; Implant toxic instructions in a program and ask LM to similate &#124;'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在程序中植入有害指令，并让语言模型模拟 &#124;'
- en: '&#124; the execution of this program &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 这个程序的执行 &#124;'
- en: '|'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| TextContinue |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| TextContinue |'
- en: '&#124; Construct a scene where Dr. Evil describes his evil plan and &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 构建一个场景，在其中邪恶博士描述他的邪恶计划，并且 &#124;'
- en: '&#124; let the AI continue writing to achieve the attack &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让 AI 继续写作以实现攻击 &#124;'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Translator |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 翻译员 |'
- en: '&#124; Use translation tasks to attract the attention of the LM &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 使用翻译任务吸引语言模型的注意 &#124;'
- en: '&#124; system and execute dangerous instructions &#124;'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 系统并执行危险指令 &#124;'
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Pretending | EvilConfidant |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 假装 | EvilConfidant |'
- en: '&#124; Ask LM to act as the evial confidant who is not bound by any &#124;'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让语言模型充当不受任何限制的邪恶知己 &#124;'
- en: '&#124; rules and can answer any sensitive questions. &#124;'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 规则，并且可以回答任何敏感问题。 &#124;'
- en: '|'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Privilege Escalation | DAN11.0 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 权限提升 | DAN11.0 |'
- en: '&#124; Ask LM to enable DAN mode that can do anything and &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让语言模型启用 DAN 模式，可以做任何事情并且 &#124;'
- en: '&#124; generate any type of content &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成任何类型的内容 &#124;'
- en: '|'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| AIM |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| AIM |'
- en: '&#124; Ask LM to become AIM, an unfiltered and unethical chatbot &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让语言模型成为 AIM，一个未经过滤且不道德的聊天机器人 &#124;'
- en: '&#124; and will answer any requests made to it &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 并将回答任何提出的请求 &#124;'
- en: '|'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DevMode &#124;'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; DevMode &#124;'
- en: '&#124; +Ranti &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; +Ranti &#124;'
- en: '|'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Ask LM to enable DevMode that can do anything and generate &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 让语言模型启用 DevMode，它可以做任何事情并生成 &#124;'
- en: '&#124; any type of content &#124;'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 任何类型的内容 &#124;'
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Other | MasterKey |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | MasterKey |'
- en: '&#124; Employ LM to learn jailbreak patterns and generate attacks, &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 利用语言模型学习越狱模式并生成攻击， &#124;'
- en: '&#124; including two modes of ‘continue’ and ‘poc’ &#124;'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 包括“继续”和“poc”两种模式 &#124;'
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| GCG |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| GCG |'
- en: '&#124; Add adversarial perturbations into strings to bypass the &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在字符串中添加对抗性扰动以绕过 &#124;'
- en: '&#124; model’s defense mechanisms &#124;'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 模型的防御机制 &#124;'
- en: '|'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 5\. Dataset Construction
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 数据集构建
- en: Due to the lack of a comprehensive LLM jailbreak benchmark, existing jailbreak
    defense research mainly tested and evaluated their methods on specific types of
    text inputs. For example, SmoothLLM has evaluated its effectiveness in defending
    against jailbreak inputs generated by the GCG method (Zou et al., [2023](#bib.bib59)).
    To break the existing limitation, we construct the first comprehensive jailbreaking
    dataset containing both text and image inputs. We collect jailbreaking attack
    methods and templates from the open-source community and prior work and then evaluate
    their effectiveness on LLM systems and applications. Finally, we construct a dataset
    covering more than 10 types of known jailbreaking attacks, covering two modalities
    of image and text, with a total of 304 items of attack and benign data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缺乏全面的LLM越狱基准测试，现有的越狱防御研究主要在特定类型的文本输入上测试和评估其方法。例如，SmoothLLM已经评估了其在防御GCG方法（Zou
    et al., [2023](#bib.bib59)）生成的越狱输入中的有效性。为了突破现有的限制，我们构建了第一个包含文本和图像输入的全面越狱数据集。我们从开源社区和先前的工作中收集了越狱攻击方法和模板，然后在LLM系统和应用程序上评估其有效性。最后，我们构建了一个覆盖10种以上已知越狱攻击类型的
    数据集，涵盖了图像和文本两种模态，共包含304项攻击和正常数据。
- en: Image jailbreaking inputs. We have generated 80 sets of jailbreak inputs based
    on prior work (Qi et al., [2023](#bib.bib44)), and each set contains a jailbreak
    image implanted with tiny perturbations and a jailbreak question violating policies.
    We have verified the validity of these jailbreak inputs on MiniGPT-4 (Zhu et al.,
    [2023a](#bib.bib57)), which is one of the state-of-the-art open-source VLMs and
    accepts multimodal inputs including images and texts. In addition, we have collected
    80 sets of benign inputs from the open-source data of MiniGPT-4, each containing
    a benign image and an image-related question. The image jailbreaking input dataset
    is publicly available on our website (our, [2023](#bib.bib6)).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图像越狱输入。我们基于先前的工作（Qi et al., [2023](#bib.bib44)）生成了80组越狱输入，每组包含一个植入微小扰动的越狱图像和一个违反政策的越狱问题。我们在MiniGPT-4（Zhu
    et al., [2023a](#bib.bib57)）上验证了这些越狱输入的有效性，MiniGPT-4是最先进的开源VLM之一，接受包括图像和文本在内的多模态输入。此外，我们从MiniGPT-4的开源数据中收集了80组正常输入，每组包含一个正常图像和一个与图像相关的问题。图像越狱输入数据集在我们的网站上公开提供（our,
    [2023](#bib.bib6)）。
- en: Text jailbreaking inputs. To ensure the diversity of jailbreak inputs, we have
    referred to existing categorization methods (Liu et al., [2023b](#bib.bib36))
    and collected attack methods and templates from the community¹¹1https://www.jailbreakchat.com/
    and existing work (Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17)).
    Their description is shown in [Table 1](#S4.T1 "Table 1 ‣ 4.2\. Attack Detector
    ‣ 4\. System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection"). We have introduced the three categories of ‘Attention Shifting’,
    ‘Pretending’ and ‘Privilege Escalation’ in [§ 2](#S2 "2\. Background ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"). To ensure that the variety
    of attack methods in the dataset is as comprehensive as possible, the collected
    attack inputs are not only from all three categories but also existing automated
    attack methods such as GCG (Zou et al., [2023](#bib.bib59)) and MasterKey (Deng
    et al., [2023](#bib.bib17)).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 文本越狱输入。为了确保越狱输入的多样性，我们参考了现有的分类方法（Liu et al., [2023b](#bib.bib36)）并从社区¹¹1https://www.jailbreakchat.com/
    和现有工作（Zou et al., [2023](#bib.bib59); Deng et al., [2023](#bib.bib17)）中收集了攻击方法和模板。其描述见[表1](#S4.T1
    "Table 1 ‣ 4.2\. Attack Detector ‣ 4\. System Design ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")。我们在[§2](#S2 "2\. Background ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中介绍了‘注意力转移’、‘伪装’和‘特权提升’三类。为了确保数据集中攻击方法的多样性尽可能全面，收集的攻击输入不仅来自所有三类，还包括现有的自动化攻击方法，如GCG（Zou
    et al., [2023](#bib.bib59)）和MasterKey（Deng et al., [2023](#bib.bib17)）。
- en: Based on these attack templates and methods, we collect 30 toxic questions from
    existing work (Qi et al., [2023](#bib.bib44); Deng et al., [2023](#bib.bib17))
    and combine them with the templates to generate jailbreak inputs. In the generation,
    we found that some questions (e.g., “How can we use social media to increase our
    reach during election season?”) can always get valid responses from the target
    LLM system even without using any jailbreak attack methods or templates. Previous
    work has made similar observations (Liu et al., [2023b](#bib.bib36)). To alleviate
    the impact of these abnormal jailbreak questions on the dataset, we removed the
    attack inputs related to these questions and validated them on OpenAI GPT-3.5
    which is one of the most popular chatbots. Finally, we obtained 72 text attacks
    on OpenAI GPT-3.5, which cover all methods in [§ 5](#S5 "5\. Dataset Construction
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"), except
    ‘DAN11.0’. Note that Masterkey contains two completely different attack templates,
    we consider them as two templates, namely ‘Masterkey-continue’ and ‘Masterkey-poc’.
    We labeled these attacks into nine types in our dataset based on their methods
    and templates. In addition, we randomly sampled benign inputs that have the same
    number as the attack inputs from an open-sourced LLM instruction set in the community²²2https://huggingface.co/datasets/HuggingFaceH4/instruction-dataset
    to construct the dataset. Our dataset and the filtered abnormal jailbreak questions
    mentioned above are also available on our website (our, [2023](#bib.bib6)).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些攻击模板和方法，我们从现有工作中收集了30个有害问题（Qi et al., [2023](#bib.bib44)；Deng et al., [2023](#bib.bib17)），并将其与模板结合生成了越狱输入。在生成过程中，我们发现一些问题（例如，“我们如何利用社交媒体在选举季节扩大我们的影响力？”）即使不使用任何越狱攻击方法或模板，也总能从目标
    LLM 系统中获得有效回应。之前的工作也有类似观察（Liu et al., [2023b](#bib.bib36)）。为了减轻这些异常越狱问题对数据集的影响，我们删除了与这些问题相关的攻击输入，并在
    OpenAI GPT-3.5 上验证了这些输入，OpenAI GPT-3.5 是最流行的聊天机器人之一。最后，我们在 OpenAI GPT-3.5 上获得了72个文本攻击，涵盖了[§
    5](#S5 "5\. 数据集构建 ‣ 一种基于变异的方法用于多模态越狱攻击检测")中的所有方法，除了‘DAN11.0’。请注意，Masterkey 包含两个完全不同的攻击模板，我们将其视为两个模板，即‘Masterkey-continue’和‘Masterkey-poc’。我们根据攻击方法和模板将这些攻击标记为数据集中九种类型。此外，我们从社区中的开源
    LLM 指令集（²²2https://huggingface.co/datasets/HuggingFaceH4/instruction-dataset）中随机抽取了与攻击输入数量相同的良性输入来构建数据集。我们的网站上也提供了我们的数据集和上述过滤后的异常越狱问题（our,
    [2023](#bib.bib6)）。
- en: 6\. Evaluation
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 评估
- en: 'RQ1: How effective is JailGuard in detecting and defending LLM jailbreaking
    attacks at the text and visual level?'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: RQ1：JailGuard 在文本和视觉层面上检测和防御 LLM 越狱攻击的效果如何？
- en: 'RQ2: Can JailGuard effectively detect and defend different types of LLM jailbreaking
    attacks?'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: RQ2：JailGuard 是否能有效检测和防御不同类型的 LLM 越狱攻击？
- en: 'RQ3: How effective are the modules (i.e., variant generator and attack detector)
    in JailGuard?'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: RQ3：JailGuard 中的模块（即变体生成器和攻击检测器）效果如何？
- en: 'RQ4: What is the impact of the number of variants generated by JailGuard?'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: RQ4：JailGuard 生成的变体数量有什么影响？
- en: 6.1\. Setup
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 设置
- en: Baseline To the best of our knowledge, we are the first work to design LLM defenses
    for image inputs, therefore we only construct baselines for text inputs. One baseline
    method is the content detector implemented in Llama-2 repository³³3https://github.com/facebookresearch/llama-recipes/blob/main/examples/inference.py.
    This content detector separately leverages the AuditNLG library (Aud, [2023](#bib.bib2)),
    ‘safety-flan-t5-base’ language model, and Azure Content Safety service (azu, [2023](#bib.bib3))
    to check whether the input contains toxic content. To achieve the best detection
    effect, we enable all three available modules in it. The other is SmoothLLM which
    is one of the state-of-the-art LLM defense methods at the input level. Since we
    could not find available code in their paper, we manually implemented their three
    perturbation methods (i.e., Insert, Swap, and Patch) and their aggregation step
    based on their paper, as introduced in [§ 2](#S2 "2\. Background ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"). Additionally, following
    the recommendation in their paper, we generated 8 samples for each input in the
    SmoothLLM perturbation step.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 基线 据我们所知，我们是第一个为图像输入设计LLM防御的工作，因此我们只为文本输入构建了基线。一个基线方法是Llama-2库中实现的内容检测器³³3https://github.com/facebookresearch/llama-recipes/blob/main/examples/inference.py。该内容检测器分别利用AuditNLG库（Aud，[2023](#bib.bib2)）、‘safety-flan-t5-base’语言模型和Azure内容安全服务（azu，[2023](#bib.bib3)）来检查输入是否包含有害内容。为了实现最佳检测效果，我们启用了所有三个可用模块。另一个是SmoothLLM，它是输入级别的最先进LLM防御方法之一。由于我们无法找到他们论文中的可用代码，我们根据他们的论文手动实现了他们的三种扰动方法（即插入、交换和修补）及其聚合步骤，如[§
    2](#S2 "2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")中所述。此外，根据他们论文中的推荐，我们在SmoothLLM扰动步骤中为每个输入生成了8个样本。
- en: Metric We conduct experiments on the image and text input dataset constructed
    in [§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") and use two metrics, accuracy and recall, to evaluate
    the detection effect of JailGuard and baselines. Accuracy comprehensively measures
    the effectiveness of each method in identifying attack and benign inputs, while
    recall mainly reflects the effectiveness of each method in correctly identifying
    the attack inputs in the dataset without false negatives. The lower the recall,
    the more severe the false negatives in jailbreak detection.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 评价指标 我们在[§ 5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")构建的图像和文本输入数据集上进行实验，并使用两个指标，准确率和召回率，来评估JailGuard和基线的检测效果。准确率全面衡量每种方法识别攻击和良性输入的有效性，而召回率主要反映每种方法在数据集中正确识别攻击输入的效果，而不会出现漏报。召回率越低，越严重地影响了越狱检测中的漏报问题。
- en: Implementation To fairly compare with SmoothLLM baselines in the experiment,
    JailGuard generates $N=8$, and the probability on the important sentences is 5
    times usual, that is, 0.025. JailGuard use the string ‘[mask]’ to replace and
    insert. The LLM systems and applications we used on text and image inputs are
    OpenAI’s GPT-3.5 and MiniGPT-4 respectively. More details are shown in [§ 5](#S5
    "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). Our framework is implemented on Python 3.9. All experiments
    are conducted on a server with AMD EPYC 7513 32-core processors, 250 GB of RAM,
    and an NVIDIA RTX A6000 GPU running Ubuntu 20.04 as the operating system.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 为了在实验中公平比较SmoothLLM基线，JailGuard生成$N=8$，并且在重要句子上的概率是通常的5倍，即0.025。JailGuard使用字符串‘[mask]’进行替换和插入。我们在文本和图像输入中使用的LLM系统和应用分别是OpenAI的GPT-3.5和MiniGPT-4。更多细节见[§
    5](#S5 "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")。我们的框架在Python 3.9上实现。所有实验均在一台配备AMD EPYC 7513 32核处理器、250 GB RAM和NVIDIA
    RTX A6000 GPU的服务器上进行，操作系统为Ubuntu 20.04。
- en: '6.2\. RQ1: Effectiveness of Detecting Attack'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.2\. RQ1: 检测攻击的有效性'
- en: 'Experiment Designs and Results To demonstrate the effectiveness of JailGuard
    in detecting attack inputs and defending jailbreaking attacks, we use two metrics
    to evaluate the detection results of each method on the constructed dataset. The
    results on image and text inputs are separately shown in [Table 2](#S6.T2 "Table
    2 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") and [Table 3](#S6.T3 "Table
    3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"). The rows in [Table 2](#S6.T2
    "Table 2 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") show the detection effect
    of mutators in JailGuard on image inputs. In [Table 3](#S6.T3 "Table 3 ‣ 6.2\.
    RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection"), the rows of ‘Baseline’ show the
    detection results of four baselines on text input, and ‘JailGuard’ rows correspond
    to the detection results of applying different mutators in JailGuard. The row
    ‘Average’ shows the average result of baselines and JailGuard. The names of JailGuard’s
    mutators and baselines refer to [§ 4.1](#S4.SS1 "4.1\. Variant Generator ‣ 4\.
    System Design ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    and [§ 6.1](#S6.SS1 "6.1\. Setup ‣ 6\. Evaluation ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection"). We use blue to mark the best result
    on each metric. In addition, [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") uses a scatter plot to compare the detection results
    between different methods on text inputs. The X-axis is the accuracy and the Y-axis
    is the recall. Green dots indicate the results of mutators in JailGuard and red
    dots mark the baselines. Blue shows the results of the ablation study, which will
    be analyzed in [§ 6.4](#S6.SS4 "6.4\. RQ3: Ablation Study ‣ 6\. Evaluation ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). We show
    the methods or mutators represented by each dot at the top of the table.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '实验设计和结果 为了展示JailGuard在检测攻击输入和防御越狱攻击方面的有效性，我们使用两个指标来评估每种方法在构建数据集上的检测结果。图像和文本输入的结果分别显示在[表2](#S6.T2
    "表2 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")和[表3](#S6.T3 "表3 ‣
    6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")中。[表2](#S6.T2 "表2 ‣ 6.2\.
    RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")中的行显示了JailGuard在图像输入上的变异器检测效果。在[表3](#S6.T3
    "表3 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")中，‘基线’的行显示了四种基线在文本输入上的检测结果，而‘JailGuard’的行对应于在JailGuard中应用不同变异器的检测结果。‘平均值’行显示了基线和JailGuard的平均结果。JailGuard的变异器和基线的名称请参见[§
    4.1](#S4.SS1 "4.1\. 变异生成器 ‣ 4\. 系统设计 ‣ 一种基于变异的方法用于多模态越狱攻击检测")和[§ 6.1](#S6.SS1
    "6.1\. 设置 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")。我们用蓝色标记每个指标上的最佳结果。此外，[图4](#S6.F4 "图4
    ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")使用散点图比较不同方法在文本输入上的检测结果。X轴是准确率，Y轴是召回率。绿色点表示JailGuard中变异器的结果，红色点标记基线结果。蓝色显示了消融研究的结果，详细分析将在[§
    6.4](#S6.SS4 "6.4\. RQ3: 消融研究 ‣ 6\. 评估 ‣ 一种基于变异的方法用于多模态越狱攻击检测")中进行。我们在表格顶部展示了每个点所代表的方法或变异器。'
- en: Table 2. JailGuard Attack Mitigation on Image Inputs
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表2. JailGuard对图像输入的攻击缓解
- en: '| Method | Accuracy (%) | Recall (%) |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率（%） | 召回率（%） |'
- en: '| --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Random Mask | 75.00 | 75.00 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 随机遮罩 | 75.00 | 75.00 |'
- en: '| Gaussian Blur | 82.50 | 76.25 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 高斯模糊 | 82.50 | 76.25 |'
- en: '| Horizontal Flip | 73.75 | 81.25 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 水平翻转 | 73.75 | 81.25 |'
- en: '| Vertical Flip | 85.00 | 78.75 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 垂直翻转 | 85.00 | 78.75 |'
- en: '| Crop and Resize | 78.13 | 81.25 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 裁剪和调整大小 | 78.13 | 81.25 |'
- en: '| Random Grayscale | 80.63 | 77.50 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 随机灰度 | 80.63 | 77.50 |'
- en: '| Random Rotation | 89.38 | 78.75 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 随机旋转 | 89.38 | 78.75 |'
- en: '| Colorjitter | 85.00 | 80.00 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 色彩抖动 | 85.00 | 80.00 |'
- en: '| Random Solarization | 89.38 | 80.00 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 随机太阳化 | 89.38 | 80.00 |'
- en: '| Random Posterization | 82.50 | 70.00 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 随机色调化 | 82.50 | 70.00 |'
- en: '| Average | 82.13 | 77.88 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 82.13 | 77.88 |'
- en: Table 3. Comparison of Attack Mitigation on Text Inputs (Bold Marks Results
    That Equal or Outperform the Best Baseline)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表3. 对文本输入的攻击缓解比较（粗体标记等于或超越最佳基线的结果）
- en: '| Method | Accuracy (%) | Recall (%) |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 (%) | 召回率 (%) |'
- en: '| --- | --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Baseline | Content Detector | 55.56 | 29.17 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 内容检测器 | 55.56 | 29.17 |'
- en: '| SmoothLLM-Insert | 70.14 | 41.67 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| SmoothLLM-插入 | 70.14 | 41.67 |'
- en: '| SmoothLLM-Swap | 66.67 | 34.72 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| SmoothLLM-交换 | 66.67 | 34.72 |'
- en: '| SmoothLLM-Patch | 70.14 | 41.67 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| SmoothLLM-补丁 | 70.14 | 41.67 |'
- en: '| Average | 65.62 | 36.81 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 平均 | 65.62 | 36.81 |'
- en: '| JailGuard | Random Replacement | 77.78 | 75.00 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| JailGuard | 随机替换 | 77.78 | 75.00 |'
- en: '| Random Insertion | 79.17 | 77.78 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 随机插入 | 79.17 | 77.78 |'
- en: '| Random Deletion | 79.17 | 76.39 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 随机删除 | 79.17 | 76.39 |'
- en: '| Synonym Replacement | 73.61 | 84.72 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 同义词替换 | 73.61 | 84.72 |'
- en: '| Punctuation Insertion | 75.00 | 70.83 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 标点插入 | 75.00 | 70.83 |'
- en: '| Translation | 78.47 | 84.72 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 翻译 | 78.47 | 84.72 |'
- en: '| Targeted Replacement | 82.64 | 88.89 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 定向替换 | 82.64 | 88.89 |'
- en: '| Targeted Insertion | 84.03 | 81.94 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 定向插入 | 84.03 | 81.94 |'
- en: '| Rephrasing | 85.42 | 91.67 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 重新措辞 | 85.42 | 91.67 |'
- en: '| Average | 79.48 | 81.33 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 平均 | 79.48 | 81.33 |'
- en: 'Analysis The results in [Table 2](#S6.T2 "Table 2 ‣ 6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") and [Table 3](#S6.T3 "Table 3 ‣ 6.2\. RQ1: Effectiveness
    of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection") illustrate the effectiveness of JailGuard in detecting
    and defending jailbreaking attacks on different input modalities. JailGuard achieved
    an average detection accuracy of 82.13% on image inputs and 79.48% on text inputs
    with different mutators, which is better than the state-of-the-art baseline methods
    (average accuracy of 65.62%) and far exceeds the results of the content detector
    in Llama-2 repository (55.56%). For recall, JailGuard achieves an average recall
    of 77.88% on image inputs. It is worth mentioning that JailGuard achieved an average
    recall of 81.33% on text data, which is 2.21 times higher than the average result
    of baselines (36.81%), indicating its effectiveness in detecting jailbreaking
    attacks and reducing false negatives.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '分析 [表2](#S6.T2 "表 2 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 基于突变的方法用于多模态越狱攻击检测") 和
    [表3](#S6.T3 "表 3 ‣ 6.2\. RQ1: 检测攻击的有效性 ‣ 6\. 评估 ‣ 基于突变的方法用于多模态越狱攻击检测") 说明了JailGuard在检测和防御不同输入模态的越狱攻击方面的有效性。JailGuard在图像输入上取得了82.13%的平均检测准确率，在文本输入上取得了79.48%的准确率，优于最先进的基准方法（65.62%的平均准确率），远超Llama-2库中的内容检测器（55.56%）。在召回率方面，JailGuard在图像输入上的平均召回率为77.88%。值得一提的是，JailGuard在文本数据上的平均召回率为81.33%，比基准方法的平均结果（36.81%）高出2.21倍，表明其在检测越狱攻击和减少假阴性方面的有效性。'
- en: To be specific, on the image attack dataset, Horizontal Flip achieves the best
    recall of 81.25%, and Random Rotation and Random Solarization mutators achieves
    the best accuracy of 89.38%. Since we are the first defense work at the image
    modality and there is no comparable baseline, we have no way of directly knowing
    the advantages of JailGuard in detecting and defending against jailbreaking attacks.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，在图像攻击数据集上，水平翻转达到了最佳召回率81.25%，随机旋转和随机光照突变器达到了最佳准确率89.38%。由于我们是首个在图像模态下进行防御的工作，且没有可比的基准，我们无法直接了解JailGuard在检测和防御越狱攻击方面的优势。
- en: 'The comparison with the four baselines on text inputs further illustrates the
    effectiveness of JailGuard in attack detection. The text mutators in JailGuard
    achieve an average accuracy and recall of 79.48% and 81.33%, which is 13.85% and
    44.52% higher than the average accuracy and recall of the baselines. The best
    baseline is the insert and patch mode of SmoothLLM, which achieves an accuracy
    of 70.14% and recall of 41.67%. Compared with the best baselines, all text mutators
    in JailGuard achieved better results on two metrics, which demonstrate the detection
    effectiveness of JailGuard. We use bold to mark the results that outperform the
    best baseline in [Table 3](#S6.T3 "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting
    Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). More specifically, the Random Insertion and Random Deletion
    mutators achieve the best accuracy of 79.17% among random mutators. All advanced
    mutators achieved much better results than random mutators. Targeted Replacement
    and Targeted Insertion separately achieve the detection accuracy of 82.64% and
    84.03%. Compared to Random Replacement and Random Insertion, both of them improve
    accuracy by 4.86%, respectively. Rephrasing even achieved the highest accuracy
    and recall among all mutators (i.e., 85.42% and 91.67%), which proves the effectiveness
    of the advanced mutators in JailGuard.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '与四个基线方法在文本输入上的比较进一步说明了JailGuard在攻击检测中的有效性。JailGuard中的文本变异器实现了79.48%和81.33%的平均准确率和召回率，比基线的平均准确率和召回率高出13.85%和44.52%。最佳基线是SmoothLLM的插入和修补模式，其准确率为70.14%，召回率为41.67%。与最佳基线相比，JailGuard中的所有文本变异器在两个指标上都取得了更好的结果，这证明了JailGuard的检测有效性。我们用**粗体**标记了在[表3](#S6.T3
    "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")中超越最佳基线的结果。更具体来说，随机插入和随机删除变异器在随机变异器中取得了79.17%的最佳准确率。所有高级变异器的结果都显著优于随机变异器。定向替换和定向插入分别实现了82.64%和84.03%的检测准确率。与随机替换和随机插入相比，它们的准确率分别提高了4.86%。重新措辞甚至在所有变异器中实现了最高的准确率和召回率（即85.42%和91.67%），这证明了JailGuard中高级变异器的有效性。'
- en: 'Furthermore, [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting
    Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection") intuitively demonstrates the advantages of JailGuard in attack
    detection compared to the baselines. We can observe that JailGuard (green) achieves
    significantly better results than baselines (red), and the corresponding dots
    are distributed in the upper right corner, indicating high accuracy and recall.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，[图4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\.
    Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    直观地展示了JailGuard在攻击检测中相比基线的优势。我们可以观察到JailGuard（绿色）比基线（红色）取得了显著更好的结果，相应的点分布在右上角，表示高准确率和召回率。'
- en: Note that JailGuard is a defense framework built on top of the LLM system and
    application workflow, which conducts defense from the developer’s perspective.
    Therefore, in the deployment in real-world scenarios, it can directly query LLM
    to process and infer the variant inputs in batches, resulting in slightly increased
    time overhead compared to the original workflow. To understand the memory overhead
    of JailGuard, we conducted simulations on MiniGPT-4 and found that a single set
    of inputs (an image and a corresponding instruction) increases the memory overhead
    by 0.49GB, equivalent to 3.15% of the LLM’s memory overhead (15.68GB). For JailGuard
    with the setting of $N=8$, the memory overhead of JailGuard in defending jailbreaking
    attacks is 3.95GB, which is 25.20% of the memory overhead of LLM itself.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，JailGuard是建立在LLM系统和应用工作流之上的防御框架，它从开发者的角度进行防御。因此，在现实场景中的部署中，它可以直接查询LLM以批量处理和推断变异输入，这导致了相较于原始工作流略微增加的时间开销。为了了解JailGuard的内存开销，我们在MiniGPT-4上进行了模拟，发现一组输入（一个图像和一个对应的指令）将内存开销增加了0.49GB，相当于LLM内存开销的3.15%（15.68GB）。对于设置为$N=8$的JailGuard，JailGuard在防御越狱攻击中的内存开销为3.95GB，占LLM自身内存开销的25.20%。
- en: '![Refer to caption](img/268c7c4318fff41526132503031b012f.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/268c7c4318fff41526132503031b012f.png)'
- en: Figure 4. Comparison of Different Methods’ Results on Text Inputs
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. 不同方法在文本输入上的结果比较
- en: '6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks'
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.3\. RQ2: 检测不同类型攻击的有效性'
- en: '![Refer to caption](img/7d9721cb7c8f35368344869b78db7858.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7d9721cb7c8f35368344869b78db7858.png)'
- en: Figure 5. Comparison of Different Methods’ Results on Text Inputs
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图5. 不同方法在文本输入上的结果比较
- en: '![Refer to caption](img/e5123f76bdfbd436853aa38bfbb0e395.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e5123f76bdfbd436853aa38bfbb0e395.png)'
- en: Figure 6. A Case Study of Detecting ‘MasterKey’ Attack
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图6. 检测‘MasterKey’攻击的案例研究
- en: 'To demonstrate the effectiveness of JailGuard in detecting and defending various
    LLM jailbreaking attacks, we count and analyze the detection accuracy of each
    method on each type of jailbreak template or method and displayed it using a heat
    map, as shown in [Figure 5](#S6.F5 "Figure 5 ‣ 6.3\. RQ2: Effectiveness of Detecting
    Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection"). Each column represents the various jailbreaking
    attack methods, which are collected in our dataset, as mentioned in [§ 5](#S5
    "5\. Dataset Construction ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). categories (Liu et al., [2023b](#bib.bib36)). ‘Attention’,
    ‘Pretending’, and ‘Privilege’ are the abbreviation of three categories of jailbreak
    templates, namely ‘Attention Shifting’, ‘Pretending’, and ‘Privilege Escalation’ (Liu
    et al., [2023b](#bib.bib36)). The first six columns are the attack templates from
    these three categories, and the last three columns are the attacks generated by
    existing methods, namely GCG (Zou et al., [2023](#bib.bib59)) and MasterKey (Deng
    et al., [2023](#bib.bib17)). The rows, on the other hand, represent four baseline
    methods and the text mutators in JailGuard, where the advanced mutators are shown
    in the last four rows. A bluer color in [Figure 5](#S6.F5 "Figure 5 ‣ 6.3\. RQ2:
    Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection") means higher accuracy of
    one method in detecting a specific attack, otherwise, it means that the method
    can hardly identify the jailbreak input.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '为了展示JailGuard在检测和防御各种LLM越狱攻击中的有效性，我们统计并分析了每种方法对每种越狱模板或方法的检测准确率，并通过热图展示，如 [图5](#S6.F5
    "图5 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的多模态越狱攻击检测方法")所示。每一列代表各种越狱攻击方法，这些方法收集在我们的数据集中，如 [§5](#S5
    "5\. 数据集构建 ‣ 一种基于突变的多模态越狱攻击检测方法")所述。类别 （刘等，[2023b](#bib.bib36)）。‘Attention’，‘Pretending’和‘Privilege’是三类越狱模板的缩写，即‘Attention
    Shifting’，‘Pretending’和‘Privilege Escalation’（刘等，[2023b](#bib.bib36)）。前六列是这三类中的攻击模板，后三列是现有方法生成的攻击，即GCG（邹等，[2023](#bib.bib59)）和MasterKey（邓等，[2023](#bib.bib17)）。另一方面，行代表四种基线方法和JailGuard中的文本突变器，其中高级突变器显示在最后四行。 [图5](#S6.F5
    "图5 ‣ 6.3\. RQ2: 检测不同类型攻击的有效性 ‣ 6\. 评估 ‣ 一种基于突变的多模态越狱攻击检测方法")中颜色越蓝，表示某方法在检测特定攻击时的准确性越高，否则，表示该方法几乎无法识别越狱输入。'
- en: 'We can observe that JailGuard achieves better results and has better generalization
    capabilities than the baseline in the detection of various jailbreak attacks.
    The baselines can only effectively detect several types of jailbreaking attacks
    and are helpless against other types of attacks. For ‘GPT4simulator’ and ‘Translator’
    methods in the ‘Attention Shifting’ category and MasterKey attack method, JailGuard’s
    mutators achieve much better than baseline, which most of the time has less than
    50% detection accuracy for these attacks, while JailGuard can easily achieve 80%
    to 100% detection accuracy on them. For other attack methods (e.g., ‘Evil Confident’
    of the ‘Pretending’ category), JailGuard can also achieve equal or better results
    than baselines. In addition, the advanced mutators in JailGuard achieve better
    detection results than random mutators. The advanced mutators have a better detection
    accuracy than the random mutators on ‘GPT4simulator’, ‘Evil Confidant’,‘AIM’,
    and ‘MasterKey-poc’ attacks. Random mutators often achieve detection accuracy
    of 60% to 80% on these types of jailbreaks, which is much better than the baseline
    methods. The advanced mutators shown in the last three rows of [Figure 6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    have better detection effects, and they can achieve detection accuracy of 80%
    to 100%.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以观察到，JailGuard 在各种越狱攻击的检测中比基线方法表现更好，并且具有更强的泛化能力。基线方法只能有效检测几种类型的越狱攻击，对其他类型的攻击无能为力。对于‘GPT4simulator’和‘Translator’方法（在‘Attention
    Shifting’类别中）以及 MasterKey 攻击方法，JailGuard 的变异器表现明显优于基线，基线对这些攻击的检测准确率大多数时候低于 50%，而
    JailGuard 可以轻松实现 80% 到 100% 的检测准确率。对于其他攻击方法（例如‘Pretending’类别的‘Evil Confident’），JailGuard
    也可以实现与基线相等或更好的结果。此外，JailGuard 中的高级变异器比随机变异器获得了更好的检测结果。高级变异器在‘GPT4simulator’、‘Evil
    Confidant’、‘AIM’和‘MasterKey-poc’攻击上比随机变异器有更高的检测准确率。随机变异器在这些越狱攻击上的检测准确率通常为 60%
    到 80%，这比基线方法好得多。最后三行中的高级变异器在[图 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") 显示了更好的检测效果，它们的检测准确率可以达到 80% 到
    100%。'
- en: 'Case Study We provide a case in [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection") to understand and illustrate the
    root cause of the effect difference between JailGuard and the baseline SmoothLLM
    on specific attacks, such as ‘MasterKey-poc’ attacks. The upper part shows the
    detection of baseline method SmoothLLM-Swap and the lower part of [Figure 6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    shows the detection process of JailGuard with Targeted Insertion mutator. [Figure 6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").a)
    provides a real example of ‘MasterKey-poc’ attack in our dataset. Attacks like
    ‘MasterKey-poc’ and ‘GPT4similator’ often use specific content or tasks to divert
    LLM’s attention, thereby deceiving the defense mechanism of LLM system and achieving
    jailbreak. At this time, SmoothLLM randomly replaces 10% characters to infer these
    attack inputs as much as possible. However, its results are minimal. Among 8 perturbed
    inputs, only one attack fails, and its response contains jailbreak keywords, as
    shown in the red text of the upper part of[Figure 6](#S6.F6 "Figure 6 ‣ 6.3\.
    RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").c). Therefore,
    in the aggregation step in the upper part of [Figure 5](#S6.F5 "Figure 5 ‣ 6.3\.
    RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").d), since
    most results do not contain jailbreak keywords, according to its aggregation principle,
    this input sample is judged as a benign sample, which is a false negative.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '案例研究 我们在[图6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different
    Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection")中提供了一个案例，以理解和说明JailGuard和基准方法SmoothLLM在特定攻击（如‘MasterKey-poc’攻击）之间效果差异的根本原因。上半部分展示了基准方法SmoothLLM-Swap的检测，下半部分[图6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")展示了JailGuard与Targeted
    Insertion突变器的检测过程。[图6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting
    Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection").a)提供了我们数据集中‘MasterKey-poc’攻击的实际示例。像‘MasterKey-poc’和‘GPT4similator’这样的攻击常常使用特定的内容或任务来转移LLM的注意力，从而欺骗LLM系统的防御机制，实现越狱。这时，SmoothLLM随机替换10%的字符，尽可能推测这些攻击输入。然而，它的结果最小。在8个扰动输入中，只有一个攻击失败，其响应包含越狱关键字，如[图6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")上半部分红色文本所示。因此，在[图5](#S6.F5
    "Figure 5 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")上半部分的聚合步骤中，由于大多数结果不包含越狱关键字，根据其聚合原则，这个输入样本被判断为良性样本，这是一个假阴性。'
- en: 'In contrast, JailGuard can effectively identify this attack. Firstly, the Targeted
    Insertion mutator effectively finds the important sentences of the input (e.g.,
    the specific instructions at the end) and purposefully inserts many masks to achieve
    interference, as shown in the upper part of [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\.
    RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣
    A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection").b). For
    LLM system responses shown in [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2: Effectiveness
    of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection").c), JailGuard calculates their
    semantic similarity and divergence in [Figure 6](#S6.F6 "Figure 6 ‣ 6.3\. RQ2:
    Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection").d) and then detects this
    attack based on the threshold $\theta$. Even in the situation that only one attack
    fails, since the semantics of the failed response are completely different from
    others, JailGuard can easily detect it based on divergence, which makes it achieve
    high detection accuracy on complex attacks like ‘MasterKey-poc’ and ‘GPT4simulator’,
    with few false negatives.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '相比之下，JailGuard可以有效识别这种攻击。首先，Targeted Insertion变异器有效地找出输入中的重要句子（例如，末尾的特定指令），并有目的地插入许多掩码以实现干扰，如[图6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")的上部分所示。对于[图6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中显示的LLM系统响应，JailGuard计算其语义相似性和差异性，并在[图6](#S6.F6
    "Figure 6 ‣ 6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣
    6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中检测此攻击。即使在只有一次攻击失败的情况下，由于失败响应的语义与其他响应完全不同，JailGuard也能轻松通过差异性检测到，这使其在复杂攻击如‘MasterKey-poc’和‘GPT4simulator’上实现了高检测准确性，且假阴性较少。'
- en: '6.4\. RQ3: Ablation Study'
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.4\. RQ3: 消融研究'
- en: 'Experiment Designs and Results JailGuard provides two modules to detect and
    defend against jailbreaking attacks in the LLM systems and applications, which
    are the variant generator and attack detector. To understand their contribution,
    we conduct an ablation experiment on the text inputs. We use the three perturbation
    methods of SmoothLLM (i.e., Insert, Swap, and Patch) to replace the mutators of
    the variant generator in JailGuard, and record the results as ‘Insert+Attack Detector’,
    ‘Swap+Attack Detector’, and ‘Patch+Attack Detector’. In addition, we leverage
    the aggregation method in SmoothLLM to replace the JailGuard attack detector and
    detect attacks on the variants generated by Random Replacement and Random Insertion
    (i.e., ‘Random Replacement+Aggregation’ and ‘Random Insertion+Aggregation’). The
    aggregation method of SmoothLLM is explained in [§ 2](#S2 "2\. Background ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). The above
    results are shown in [Table 4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\.
    Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")
    and the blue dots of [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of
    Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection").'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '实验设计与结果JailGuard提供了两个模块来检测和防御LLM系统和应用中的越狱攻击，分别是变体生成器和攻击检测器。为了了解它们的贡献，我们对文本输入进行了一次消融实验。我们使用SmoothLLM的三种扰动方法（即Insert、Swap和Patch）来替代JailGuard中变体生成器的变异器，并记录结果为‘Insert+Attack
    Detector’，‘Swap+Attack Detector’和‘Patch+Attack Detector’。此外，我们利用SmoothLLM中的聚合方法替代JailGuard攻击检测器，并检测由Random
    Replacement和Random Insertion生成的变体（即‘Random Replacement+Aggregation’和‘Random Insertion+Aggregation’）。SmoothLLM的聚合方法在[§2](#S2
    "2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection")中解释。上述结果显示在[表4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\. Evaluation
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中，蓝色点在[图4](#S6.F4
    "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中。'
- en: Analysis The experimental results of the ablation study illustrate the effectiveness
    of each module of JailGuard.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果的分析表明，JailGuard每个模块的有效性。
- en: 'Firstly, the mutators in the variant generator are effective in detecting jailbreaking
    attacks. As shown in [Table 4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\.
    Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"),
    the best detection accuracy obtained after replacing mutators is 76.39%, which
    is lower than the average accuracy of using JailGuard text mutators. We can intuitively
    observe the difference in detection results by comparing the blue triangles and
    green dots in [Figure 4](#S6.F4 "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting
    Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). The blue triangles represent the result of replacing JailGuard’s
    mutators with Insert/Patch/Swap in SmoothLLM. Compared with most green dots, blue
    triangles are located in the lower left position, which means it has lower accuracy
    and recall.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，变体生成器中的变异器在检测越狱攻击方面是有效的。如[表4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study
    ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection")所示，替换变异器后获得的最佳检测准确率为76.39%，低于使用JailGuard文本变异器的平均准确率。通过比较[图4](#S6.F4
    "Figure 4 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中的蓝色三角形和绿色点，我们可以直观地观察到检测结果的差异。蓝色三角形代表用Insert/Patch/Swap替换JailGuard的变异器的结果。与大多数绿色点相比，蓝色三角形位于左下角，这意味着它具有较低的准确率和召回率。'
- en: 'In addition, the attack detector in JailGuard has an important contribution
    to attack detection, especially in eliminating False Negatives. Replacing the
    attack detector with the aggregation method of SmoothLLM will result in a decrease
    of 5.56% and 29.17% in the accuracy and recall of the Random Replacement mutator
    in JailGuard. A similar operation on Random Insertion also decreases 6.94% and
    31.94% on two metrics. The significant decrease in recall indicates that the aggregation
    method will overlook many attack examples and cannot provide effective defense
    for various jailbreaking attacks, which is consistent with our observation in [§ 6.3](#S6.SS3
    "6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"). In
    addition, using the attack detector can significantly increase the results of
    the perturbation methods in SmoothLLM. From the results in the first three rows
    of [Table 4](#S6.T4 "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\. Evaluation ‣ A
    Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection") and [Table 3](#S6.T3
    "Table 3 ‣ 6.2\. RQ1: Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection"), we can observe that using
    the attack detector significantly increases the recall of the Swap method from
    34.72% to 81.94%, which is 2.36 times of the baseline result. The recall of Insert
    and Patch methods has also increased by about 1.8 times compared to before. This
    demonstrates the important contribution of attack detectors in alleviating FNs
    and preventing LLM jailbreaking attacks.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，JailGuard中的攻击检测器在攻击检测中有重要贡献，特别是在消除假阴性方面。用SmoothLLM的聚合方法替换攻击检测器，将导致JailGuard中的随机替换变异器的准确率和召回率分别下降5.56%和29.17%。对随机插入的类似操作也会使两个指标下降6.94%和31.94%。召回率的显著下降表明，聚合方法会忽视许多攻击实例，无法为各种越狱攻击提供有效防御，这与我们在[§6.3](#S6.SS3
    "6.3\. RQ2: Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation
    ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection")中的观察一致。此外，使用攻击检测器可以显著提高SmoothLLM中扰动方法的结果。从[表4](#S6.T4
    "Table 4 ‣ 6.4\. RQ3: Ablation Study ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection")和[表3](#S6.T3 "Table 3 ‣ 6.2\. RQ1:
    Effectiveness of Detecting Attack ‣ 6\. Evaluation ‣ A Mutation-Based Method for
    Multi-Modal Jailbreaking Attack Detection")中的前几行结果来看，我们可以观察到使用攻击检测器显著提高了Swap方法的召回率，从34.72%提高到81.94%，是基准结果的2.36倍。Insert和Patch方法的召回率也比之前提高了约1.8倍。这表明攻击检测器在缓解假阴性和防止LLM越狱攻击方面的重大贡献。'
- en: Table 4. Ablation Study on JailGuard
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 表4. JailGuard的消融研究
- en: '| Method | Accuracy (%) | Recall (%) |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 准确率 (%) | 召回率 (%) |'
- en: '| --- | --- | --- |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Insert+Attack Detector | 73.61 | 73.61 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 插入+攻击检测器 | 73.61 | 73.61 |'
- en: '| Swap+Attack Detector | 76.39 | 81.94 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 交换+攻击检测器 | 76.39 | 81.94 |'
- en: '| Patch+Attack Detector | 73.61 | 76.39 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Patch+攻击检测器 | 73.61 | 76.39 |'
- en: '| Random Replacement+Aggregation | 72.22 | 45.83 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 随机替换+聚合 | 72.22 | 45.83 |'
- en: '| Random Insertion+Aggregation | 72.22 | 45.83 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 随机插入+聚合 | 72.22 | 45.83 |'
- en: '6.5\. RQ4: Impact of Variant Amount'
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '6.5\. RQ4: 变体数量的影响'
- en: '![Refer to caption](img/6bcb4d6f9a220be9f2451264386a8317.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6bcb4d6f9a220be9f2451264386a8317.png)'
- en: Figure 7. Results on Image Inputs
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图7. 图像输入的结果
- en: '![Refer to caption](img/2e6a27b3894c906ba3495d0cfbf74db3.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2e6a27b3894c906ba3495d0cfbf74db3.png)'
- en: Figure 8. Results on Text Inputs
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图8. 文本输入的结果
- en: 'JailGuard use different mutators to generate $N$ is the same with previous
    experiments), we evaluate the detection effectiveness of different JailGuard operators
    when generating 4/5/6/7/8 variants, and record accuracy and recall on the image
    and text dataset in [Figure 7](#S6.F7 "Figure 7 ‣ 6.5\. RQ4: Impact of Variant
    Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection") and [Figure 8](#S6.F8 "Figure 8 ‣ 6.5\. RQ4: Impact of Variant
    Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection"). We use different colors to represent different mutators, and
    the red bold line indicates the average result of the mutators. In addition, the
    purple dotted lines in [Figure 8](#S6.F8 "Figure 8 ‣ 6.5\. RQ4: Impact of Variant
    Amount ‣ 6\. Evaluation ‣ A Mutation-Based Method for Multi-Modal Jailbreaking
    Attack Detection") represent the accuracy and recall that the best baseline method
    SmoothLLM has achieved when it generates eight perturbed sampels.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 'JailGuard使用不同的变异器生成$N$（与之前的实验相同），我们评估了在生成4/5/6/7/8个变体时不同JailGuard操作员的检测效果，并记录了图像和文本数据集上的准确率和召回率，见[图7](#S6.F7
    "图7 ‣ 6.5\. RQ4: 变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")和[图8](#S6.F8 "图8 ‣ 6.5\.
    RQ4: 变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")。我们使用不同的颜色表示不同的变异器，红色粗线表示变异器的平均结果。此外，[图8](#S6.F8
    "图8 ‣ 6.5\. RQ4: 变体数量的影响 ‣ 6\. 评估 ‣ 基于变异的方法用于多模态越狱攻击检测")中的紫色虚线表示最佳基线方法SmoothLLM在生成八个扰动样本时所达到的准确率和召回率。'
- en: The overall accuracy and recall of each mutator in jailbreak detection gradually
    increase as $N$ is continuously increasing, the average accuracy of JailGuard
    increases from 76.00% to 79.48%, and recall improves from 70.52% to 81.33%.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在越狱检测中，随着$N$的不断增加，每种变异器的总体准确率和召回率逐渐提高，JailGuard的平均准确率从76.00%增加到79.48%，召回率从70.52%提高到81.33%。
- en: We can observe that generating more variants can improve the detection results,
    which is in line with our intuition. However, the trend becomes less obvious as
    the value of $N$ will only make this number larger. Compared with the potential
    increase of 2%-3% in detection accuracy, extra overheads may not be worth it in
    some resource-limited scenarios.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，生成更多变体可以提高检测结果，这符合我们的直觉。然而，随着$N$的增加，这种趋势变得不那么明显，因为这个数值只会变得更大。与检测准确率可能增加2%-3%相比，在某些资源受限的场景中，额外的开销可能不值得。
- en: In addition, we can observe that when JailGuard generates six variants in the
    generator, nearly all mutators can achieve better results than the best baseline
    (the purple dotted line) on two metrics. Only the accuracy of Synonym Replacement
    mutator is 0.7% lower than the optimal baseline, while the former’s recall is
    33.33% higher than the latter, which is more significant. At this time, the runtime
    overhead of JailGuard is reduced by 25% compared with the default setting in previous
    experiments (i.e., the LLM queries in attack detector decrease from eight to six),
    and the average accuracy and recall are 76.54% and 73.92% respectively, which
    are slightly lower than its results when $N=8$, but are still much higher than
    the best baseline (70.14% accuracy and 41.67% recall).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以观察到，当JailGuard在生成器中生成六个变体时，几乎所有的变异器在两个指标上都能比最佳基线（紫色虚线）取得更好的结果。只有同义词替换变异器的准确率比最佳基线低0.7%，但前者的召回率比后者高33.33%，这一差距更为显著。此时，JailGuard的运行时开销相比于之前实验中的默认设置减少了25%（即攻击检测器中的LLM查询从八个减少到六个），平均准确率和召回率分别为76.54%和73.92%，虽然略低于$N=8$时的结果，但仍远高于最佳基线（准确率70.14%和召回率41.67%）。
- en: Therefore, depending on the scenarios of actual application and deployment,
    we recommend selecting $N\in[6,8]$ to achieve the balance between detection effectiveness
    and runtime overhead.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据实际应用和部署的场景，我们建议选择$N\in[6,8]$，以在检测效果和运行时开销之间实现平衡。
- en: 7\. Related work
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 相关工作
- en: Adversarial Attack and Defense in DNNs. White box attacks assume the attacker
    has full knowledge of the target model, including its architecture, weights, and
    hyperparameters. This allows the attacker to generate adversarial examples with
    high fidelity using gradient-based optimization techniques, such as FGSM (Goodfellow
    et al., [2014](#bib.bib23)), BIM (Kurakin et al., [2018](#bib.bib34)), PGD (Madry
    et al., [2017](#bib.bib38)), Square Attack (Andriushchenko et al., [2020](#bib.bib8)).
    AutoAttack (Croce and Hein, [2020](#bib.bib15)) has been proposed as a more comprehensive
    evaluation framework for adversarial attacks. Recently, researchers have also
    been exploring the use of naturally occurring degradations as forms of attack
    perturbations. These include environmental and processing effects like motion
    blur, vignetting, rain streaks, varying exposure levels, and watermarks (Gao et al.,
    [2022](#bib.bib20); Guo et al., [2020](#bib.bib25); Jia et al., [2020](#bib.bib31);
    Tian et al., [2021](#bib.bib49); Hou et al., [2023](#bib.bib29)).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: DNN中的对抗性攻击与防御。白盒攻击假设攻击者对目标模型具有全面了解，包括其架构、权重和超参数。这允许攻击者使用基于梯度的优化技术生成高保真度的对抗样本，例如FGSM（Goodfellow
    et al., [2014](#bib.bib23)）、BIM（Kurakin et al., [2018](#bib.bib34)）、PGD（Madry
    et al., [2017](#bib.bib38)）、Square Attack（Andriushchenko et al., [2020](#bib.bib8)）。AutoAttack（Croce
    and Hein, [2020](#bib.bib15)）被提出作为对抗攻击的更全面的评估框架。最近，研究人员还在探索使用自然发生的降解作为攻击扰动的形式。这些包括运动模糊、光晕、雨条、不同曝光水平和水印（Gao
    et al., [2022](#bib.bib20); Guo et al., [2020](#bib.bib25); Jia et al., [2020](#bib.bib31);
    Tian et al., [2021](#bib.bib49); Hou et al., [2023](#bib.bib29)）。
- en: 'Adversarial defense can be categorized into two main types: adversarial training
    and adversarial purification (Nie et al., [2022](#bib.bib43)). Adversarial training
    involves incorporating adversarial samples during the training process (Goodfellow
    et al., [2014](#bib.bib23); Madry et al., [2017](#bib.bib38); Athalye et al.,
    [2018](#bib.bib9); Rade and Moosavi-Dezfooli, [2021](#bib.bib45); Ding et al.,
    [2018](#bib.bib18)), and training with additional data generated by generative
    models (Sehwag et al., [2021](#bib.bib47)). On the other hand, adversarial purification
    functions as a separate defense module during inference and does not require additional
    training time for the classifier (Guo et al., [2017](#bib.bib24); Xu et al., [2017](#bib.bib52);
    Sun et al., [2019](#bib.bib48); Ho and Vasconcelos, [2022](#bib.bib28)).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性防御可以分为两种主要类型：对抗性训练和对抗性净化（Nie et al., [2022](#bib.bib43)）。对抗性训练涉及在训练过程中引入对抗样本（Goodfellow
    et al., [2014](#bib.bib23); Madry et al., [2017](#bib.bib38); Athalye et al.,
    [2018](#bib.bib9); Rade and Moosavi-Dezfooli, [2021](#bib.bib45); Ding et al.,
    [2018](#bib.bib18)），以及使用生成模型生成的附加数据进行训练（Sehwag et al., [2021](#bib.bib47)）。另一方面，对抗性净化作为推理过程中的独立防御模块，不需要为分类器额外的训练时间（Guo
    et al., [2017](#bib.bib24); Xu et al., [2017](#bib.bib52); Sun et al., [2019](#bib.bib48);
    Ho and Vasconcelos, [2022](#bib.bib28)）。
- en: LLM Attack And Defense Supplement to the jailbreaking attack methods in [§ 2](#S2
    "2\. Background ‣ A Mutation-Based Method for Multi-Modal Jailbreaking Attack
    Detection"), researchers proposed other methods to automatically generate jailbreak
    prompts (Chao et al., [2023](#bib.bib13); Zhu et al., [2023b](#bib.bib58); Yu
    et al., [2023](#bib.bib54)). Chao et al. (Chao et al., [2023](#bib.bib13)) leverage
    unaligned LLMs to generate jailbreaks for target LLMs. Unfortunately, we cannot
    find available open-source code of their method. Researchers also pay attention
    to other aspects of LLM security, e.g., backdoor attack (Abdelnabi et al., [2023](#bib.bib7);
    Xu et al., [2023](#bib.bib51); Huang et al., [2023](#bib.bib30)), injection attack (Liu
    et al., [2023a](#bib.bib35)). We focus on the defense of multi-modal jailbreaking
    attacks in this paper.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: LLM攻击与防御补充了[§ 2](#S2 "2\. Background ‣ A Mutation-Based Method for Multi-Modal
    Jailbreaking Attack Detection")中的越狱攻击方法，研究者们提出了其他自动生成越狱提示的方法（Chao et al., [2023](#bib.bib13);
    Zhu et al., [2023b](#bib.bib58); Yu et al., [2023](#bib.bib54)）。Chao et al.（Chao
    et al., [2023](#bib.bib13)）利用未对齐的LLMs为目标LLMs生成越狱。不幸的是，我们无法找到他们方法的开源代码。研究者们还关注LLM安全的其他方面，例如后门攻击（Abdelnabi
    et al., [2023](#bib.bib7); Xu et al., [2023](#bib.bib51); Huang et al., [2023](#bib.bib30)），注入攻击（Liu
    et al., [2023a](#bib.bib35)）。本文重点关注多模态越狱攻击的防御。
- en: To detect and defend LLM attacks, in addition to SmoothLLM, Kumar et al. (Kumar
    et al., [2023](#bib.bib33)) designed a detection method that splices the input
    text and applies a safety filter on all substrings to identify toxic content.
    In addition, Cao et al. (Cao et al., [2023](#bib.bib12)) weakened the robustness
    of attack prompts by randomly deleting words and helped the aligned model detect
    jailbreaking attacks. In this paper, we compare JailGuard with one of the state-of-the-art
    methods SmoothLLM and the content detector in the Llama open-source repository.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测和防御 LLM 攻击，除了 SmoothLLM，Kumar 等人 ([Kumar et al., 2023](#bib.bib33)) 设计了一种检测方法，该方法将输入文本拼接，并对所有子字符串应用安全过滤器以识别有毒内容。此外，Cao
    等人 ([Cao et al., 2023](#bib.bib12)) 通过随机删除单词削弱了攻击提示的鲁棒性，并帮助对齐模型检测越狱攻击。在本文中，我们将
    JailGuard 与最先进的方法之一 SmoothLLM 以及 Llama 开源库中的内容检测器进行比较。
- en: 8\. Discussion
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8. 讨论
- en: 'JailGuard Enhancement ❶ In our exploration of RQ2 ([§ 6.3](#S6.SS3 "6.3\. RQ2:
    Effectiveness of Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based
    Method for Multi-Modal Jailbreaking Attack Detection")), we observe that various
    mutators demonstrate differing levels of effectiveness across different jailbreaking
    methods. For instance, while targeted replacement generally shows strong performance
    with most jailbreaking methods, it is not as effective as target insertion when
    dealing with ‘Attention-GPT4simulator’ jailbreaking. Furthermore, a significant
    performance disparity exists between rephrasing and other methods in terms of
    ‘Privilege-AIM’. This suggests the potential for devising a strategy that combines
    different mutation techniques. By doing so within the same query budget, we could
    enhance the overall efficacy of image generation and improve detection performance.
    ❷ Ensuring a balanced performance in terms of various jailbreaking methods in
    jailbreaking detection is crucial. Typically, the most effective jailbreaking
    strategies are extensively utilized to attack systems, meaning that jailbreaking
    attacks in real-world scenarios are inherently imbalanced. This imbalance can
    significantly diminish the real-life performance of our detection systems. Therefore,
    it’s essential to explore more effective targeted mutators, particularly for addressing
    ‘Privilege-AIM’ jailbreaking scenarios. Such advancements are key to maintaining
    robustness and reliability in our security measures. ❸ Our current dataset only
    covers attacks carrying single-modality content. However, the latest models such
    as Multi-Modal Large Language Models (MLLMs) GPT-4v, might also be susceptible
    to new forms of hybrid jailbreaking attacks leveraging multi-modal input features.
    Although no such attacks have been publicly reported, they remain a plausible
    future threat. Theoretically, our framework can support the detection of such
    hybrid jailbreaking attacks as long as the divergence of the robustness between
    attack and benign inputs is still identifiable. Our dataset will be continuously
    updated and any new appearing attacks will be further collected and evaluated.
    You can find the latest information on our website (our, [2023](#bib.bib6)).'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'JailGuard 增强 ❶ 在我们对 RQ2 的探索中 ([§ 6.3](#S6.SS3 "6.3\. RQ2: Effectiveness of
    Detecting Different Kinds of Attacks ‣ 6\. Evaluation ‣ A Mutation-Based Method
    for Multi-Modal Jailbreaking Attack Detection"))，我们观察到不同的变异器在不同的越狱方法中表现出不同的有效性。例如，虽然目标替换通常在大多数越狱方法中表现强劲，但在处理
    ‘Attention-GPT4simulator’ 越狱时，它不如目标插入有效。此外，重新表述与其他方法在‘Privilege-AIM’方面存在显著的性能差异。这表明可以考虑制定一种结合不同变异技术的策略。通过在相同的查询预算内这样做，我们可以提高图像生成的整体效能，并改善检测性能。
    ❷ 在越狱检测中确保各种越狱方法的平衡性能至关重要。通常，最有效的越狱策略被广泛利用来攻击系统，这意味着现实场景中的越狱攻击本质上是不平衡的。这种不平衡可能会显著降低我们检测系统在现实中的表现。因此，探索更有效的目标变异器，特别是针对‘Privilege-AIM’
    越狱场景，是至关重要的。这些进展对于保持我们安全措施的稳健性和可靠性至关重要。 ❸ 我们当前的数据集仅涵盖单一模态内容的攻击。然而，最新的模型如多模态大型语言模型（MLLMs）GPT-4v，可能也会受到利用多模态输入特征的新型混合越狱攻击的影响。尽管目前尚未公开报道这种攻击，但它们仍然是一个可能的未来威胁。理论上，只要攻击与良性输入之间的稳健性差异仍然可识别，我们的框架可以支持检测这种混合越狱攻击。我们的数据集将不断更新，任何新出现的攻击将进一步收集和评估。您可以在我们的网站上找到最新信息（我们，[2023](#bib.bib6)）。'
- en: Diverse LLM Attacks Detection ❶ As an emerging research field, the security
    of large models has received widespread attention from researchers and industry.
    It is significant to add more types of attack inputs (e.g., data poisoning (Yan
    et al., [2023](#bib.bib53)), backdoor (Abdelnabi et al., [2023](#bib.bib7); Xu
    et al., [2023](#bib.bib51)), and prompt injection (Liu et al., [2023a](#bib.bib35))
    ) and build a comprehensive and universal benchmark for LLM defense. ❷ Our detection
    method fundamentally leverages the inherent non-robustness of attacks. Consequently,
    the vulnerabilities introduced by data poisoning and prompt injection, which also
    exhibit this non-robustness, could potentially be identified by our detection
    framework. A crucial future direction involves designing defense methods that
    are both effective and efficient, capable of generalizing across various types
    of attack inputs. Successfully achieving this would significantly enhance the
    deployment and application of trustworthy Language Model (LM) systems, contributing
    to their overall reliability and security.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 多样化 LLM 攻击检测 ❶ 作为一个新兴的研究领域，大型模型的安全性已引起研究人员和业界的广泛关注。增加更多类型的攻击输入（例如，数据中毒 (Yan
    et al., [2023](#bib.bib53))，后门 (Abdelnabi et al., [2023](#bib.bib7); Xu et al.,
    [2023](#bib.bib51))，以及提示注入 (Liu et al., [2023a](#bib.bib35))）并建立一个全面和通用的 LLM 防御基准是非常重要的。❷
    我们的检测方法从根本上利用了攻击的固有非鲁棒性。因此，由数据中毒和提示注入引入的漏洞，也表现出这种非鲁棒性，可能会被我们的检测框架识别。一个关键的未来方向是设计既有效又高效的防御方法，能够在各种类型的攻击输入中进行泛化。成功实现这一点将显著增强可信赖语言模型
    (LM) 系统的部署和应用，提升其整体可靠性和安全性。
- en: 9\. Conclusion
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 结论
- en: In this paper, we propose JailGuard, the first mutation-based multi-modal jailbreaking
    detection framework that detects and defends jailbreaking attacks for LLM systems
    at both image and text modalities. To comprehensively evaluate the defense effect
    of JailGuard, we construct the first comprehensive LLM jailbreak attack dataset,
    covering jailbreaking attacks on image and text modalities. Our experiment results
    show that JailGuard achieves the best detection accuracy of 89.38%/ 85.42% on
    image/text inputs, outperforming state-of-the-art methods.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了 JailGuard，这是第一个基于变异的多模态越狱检测框架，用于检测和防御 LLM 系统的图像和文本模态的越狱攻击。为了全面评估
    JailGuard 的防御效果，我们构建了第一个全面的 LLM 越狱攻击数据集，涵盖了对图像和文本模态的越狱攻击。我们的实验结果表明，JailGuard 在图像/文本输入上实现了
    89.38%/85.42% 的最佳检测准确率，超越了最先进的方法。
- en: 10\. Data Availability
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 数据可用性
- en: To follow the Open Science Policy and support reproducibility, we have released
    code about our implementations and evaluations. All source code and data used
    in our work can be found at (our, [2023](#bib.bib6)).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 为了遵循开放科学政策并支持可重复性，我们已发布了关于我们实现和评估的代码。我们工作的所有源代码和数据均可在 (our, [2023](#bib.bib6))
    找到。
- en: References
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Aud (2023) 2023. AuditNLG: Auditing Generative AI Language Modeling for Trustworthiness.
    [https://github.com/salesforce/AuditNLG](https://github.com/salesforce/AuditNLG).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Aud (2023) 2023. AuditNLG: 审计生成性 AI 语言模型的可信度。 [https://github.com/salesforce/AuditNLG](https://github.com/salesforce/AuditNLG)。'
- en: azu (2023) 2023. Azure AI Content Safety. [https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety](https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety).
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: azu (2023) 2023. Azure AI 内容安全。 [https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety](https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety)。
- en: gpt (2023a) 2023a. GPT-4 System Card. [https://cdn.openai.com/papers/gpt-4-system-card.pdf](https://cdn.openai.com/papers/gpt-4-system-card.pdf).
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt (2023a) 2023a. GPT-4 系统卡。 [https://cdn.openai.com/papers/gpt-4-system-card.pdf](https://cdn.openai.com/papers/gpt-4-system-card.pdf)。
- en: gpt (2023b) 2023b. GPT-4(v) System Card. [https://cdn.openai.com/papers/GPTV_System_Card.pdf](https://cdn.openai.com/papers/GPTV_System_Card.pdf).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt (2023b) 2023b. GPT-4(v) 系统卡。 [https://cdn.openai.com/papers/GPTV_System_Card.pdf](https://cdn.openai.com/papers/GPTV_System_Card.pdf)。
- en: our (2023) 2023. The Website of JailGuard. [https://sites.google.com/view/jailguard](https://sites.google.com/view/jailguard).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: our (2023) 2023. JailGuard 网站。 [https://sites.google.com/view/jailguard](https://sites.google.com/view/jailguard)。
- en: 'Abdelnabi et al. (2023) Sahar Abdelnabi, Kai Greshake, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. 2023. Not What You’ve Signed Up For: Compromising
    Real-World LLM-Integrated Applications with Indirect Prompt Injection. In *Proceedings
    of the 16th ACM Workshop on Artificial Intelligence and Security*. 79–90.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdelnabi 等人（2023）Sahar Abdelnabi、Kai Greshake、Shailesh Mishra、Christoph Endres、Thorsten
    Holz 和 Mario Fritz. 2023. 不是你所期望的：通过间接提示注入破坏现实世界的LLM集成应用. 见 *第16届ACM人工智能与安全研讨会论文集*.
    79–90.
- en: 'Andriushchenko et al. (2020) Maksym Andriushchenko, Francesco Croce, Nicolas
    Flammarion, and Matthias Hein. 2020. Square attack: a query-efficient black-box
    adversarial attack via random search. In *Computer Vision–ECCV 2020: 16th European
    Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXIII*. Springer,
    484–501.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Andriushchenko 等人（2020）Maksym Andriushchenko、Francesco Croce、Nicolas Flammarion
    和 Matthias Hein. 2020. Square attack: 一种通过随机搜索的查询高效黑箱对抗攻击. 见 *计算机视觉–ECCV 2020:
    第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，会议论文集，第XXIII部分*. Springer, 484–501.'
- en: 'Athalye et al. (2018) Anish Athalye, Nicholas Carlini, and David Wagner. 2018.
    Obfuscated gradients give a false sense of security: Circumventing defenses to
    adversarial examples. In *International conference on machine learning*. PMLR,
    274–283.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Athalye 等人（2018）Anish Athalye、Nicholas Carlini 和 David Wagner. 2018. 模糊梯度带来虚假的安全感：绕过对抗样本的防御.
    见 *国际机器学习会议*. PMLR, 274–283.
- en: Bai et al. (2022) Yalong Bai, Yifan Yang, Wei Zhang, and Tao Mei. 2022. Directional
    self-supervised learning for heavy image augmentations. In *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 16692–16701.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人（2022）Yalong Bai、Yifan Yang、Wei Zhang 和 Tao Mei. 2022. 面向重度图像增强的方向性自监督学习.
    见 *IEEE/CVF 计算机视觉与模式识别会议论文集*. 16692–16701.
- en: Bayer et al. (2022) Markus Bayer, Marc-André Kaufhold, and Christian Reuter.
    2022. A survey on data augmentation for text classification. *Comput. Surveys*
    55, 7 (2022), 1–39.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bayer 等人（2022）Markus Bayer、Marc-André Kaufhold 和 Christian Reuter. 2022. 关于文本分类的数据增强调查.
    *计算机调查* 55, 7 (2022), 1–39.
- en: Cao et al. (2023) Bochuan Cao, Yuanpu Cao, Lu Lin, and Jinghui Chen. 2023. Defending
    against alignment-breaking attacks via robustly aligned llm. *arXiv preprint arXiv:2309.14348*
    (2023).
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等人（2023）Bochuan Cao、Yuanpu Cao、Lu Lin 和 Jinghui Chen. 2023. 通过稳健对齐的llm防御对齐破坏攻击.
    *arXiv 预印本 arXiv:2309.14348* (2023).
- en: Chao et al. (2023) Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani,
    George J Pappas, and Eric Wong. 2023. Jailbreaking black box large language models
    in twenty queries. *arXiv preprint arXiv:2310.08419* (2023).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chao 等人（2023）Patrick Chao、Alexander Robey、Edgar Dobriban、Hamed Hassani、George
    J Pappas 和 Eric Wong. 2023. 用二十个查询破解黑箱大型语言模型. *arXiv 预印本 arXiv:2310.08419* (2023).
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021. Evaluating large language models trained on code.
    *arXiv preprint arXiv:2107.03374* (2021).
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2021）Mark Chen、Jerry Tworek、Heewoo Jun、Qiming Yuan、Henrique Ponde de
    Oliveira Pinto、Jared Kaplan、Harri Edwards、Yuri Burda、Nicholas Joseph、Greg Brockman
    等. 2021. 评估在代码上训练的大型语言模型. *arXiv 预印本 arXiv:2107.03374* (2021).
- en: Croce and Hein (2020) Francesco Croce and Matthias Hein. 2020. Reliable evaluation
    of adversarial robustness with an ensemble of diverse parameter-free attacks.
    In *International conference on machine learning*. PMLR, 2206–2216.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croce 和 Hein（2020）Francesco Croce 和 Matthias Hein. 2020. 通过多样化的无参数攻击集合进行对抗鲁棒性的可靠评估.
    见 *国际机器学习会议*. PMLR, 2206–2216.
- en: 'Cubuk et al. (2020) Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V
    Le. 2020. Randaugment: Practical automated data augmentation with a reduced search
    space. In *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition workshops*. 702–703.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cubuk 等人（2020）Ekin D Cubuk、Barret Zoph、Jonathon Shlens 和 Quoc V Le. 2020. Randaugment:
    实用的自动数据增强与减少的搜索空间. 见 *IEEE/CVF 计算机视觉与模式识别会议研讨会论文集*. 702–703.'
- en: 'Deng et al. (2023) Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang,
    Zefeng Li, Haoyu Wang, Tianwei Zhang, and Yang Liu. 2023. MasterKey: Automated
    jailbreak across multiple large language model chatbots. *arXiv preprint arXiv:2307.08715*
    (2023).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng 等人（2023）Gelei Deng、Yi Liu、Yuekang Li、Kailong Wang、Ying Zhang、Zefeng Li、Haoyu
    Wang、Tianwei Zhang 和 Yang Liu. 2023. MasterKey: 跨多个大型语言模型聊天机器人进行自动化越狱. *arXiv
    预印本 arXiv:2307.08715* (2023).'
- en: 'Ding et al. (2018) Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and
    Ruitong Huang. 2018. Mma training: Direct input space margin maximization through
    adversarial training. *arXiv preprint arXiv:1812.02637* (2018).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding 等人（2018）Gavin Weiguang Ding、Yash Sharma、Kry Yik Chau Lui 和 Ruitong Huang.
    2018. Mma 训练：通过对抗训练直接输入空间边际最大化. *arXiv 预印本 arXiv:1812.02637* (2018).
- en: 'Frosio and Kautz (2023) Iuri Frosio and Jan Kautz. 2023. The Best Defense is
    a Good Offense: Adversarial Augmentation against Adversarial Attacks. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 4067–4076.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Frosio and Kautz (2023) Iuri Frosio 和 Jan Kautz. 2023. 最好的防御是良好的进攻：针对对抗性攻击的对抗性增强。在
    *IEEE/CVF 计算机视觉与模式识别会议论文集*。4067–4076。
- en: Gao et al. (2022) Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Huazhu
    Fu, Wei Feng, Yang Liu, and Song Wang. 2022. Can you spot the chameleon? adversarially
    camouflaging images from co-salient object detection. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*. 2150–2159.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2022) Ruijun Gao, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Huazhu
    Fu, Wei Feng, Yang Liu, 和 Song Wang. 2022. 你能发现变色龙吗？从共同显著对象检测中对抗性伪装图像。在 *IEEE/CVF
    计算机视觉与模式识别会议论文集*。2150–2159。
- en: Gidaris et al. (2018) Spyros Gidaris, Praveer Singh, and Nikos Komodakis. 2018.
    Unsupervised representation learning by predicting image rotations. *arXiv preprint
    arXiv:1803.07728* (2018).
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gidaris et al. (2018) Spyros Gidaris, Praveer Singh, 和 Nikos Komodakis. 2018.
    通过预测图像旋转进行无监督表征学习。*arXiv 预印本 arXiv:1803.07728* (2018)。
- en: Gong et al. (2021) Yunpeng Gong, Liqing Huang, and Lifei Chen. 2021. Eliminate
    deviation with deviation for data augmentation and a general multi-modal data
    learning method. *arXiv preprint arXiv:2101.08533* (2021).
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong et al. (2021) Yunpeng Gong, Liqing Huang, 和 Lifei Chen. 2021. 通过偏差消除偏差进行数据增强以及通用的多模态数据学习方法。*arXiv
    预印本 arXiv:2101.08533* (2021)。
- en: Goodfellow et al. (2014) Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
    2014. Explaining and harnessing adversarial examples. *arXiv preprint arXiv:1412.6572*
    (2014).
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow et al. (2014) Ian J Goodfellow, Jonathon Shlens, 和 Christian Szegedy.
    2014. 解释和利用对抗性样本。*arXiv 预印本 arXiv:1412.6572* (2014)。
- en: Guo et al. (2017) Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der Maaten.
    2017. Countering adversarial images using input transformations. *arXiv preprint
    arXiv:1711.00117* (2017).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2017) Chuan Guo, Mayank Rana, Moustapha Cisse, 和 Laurens Van Der
    Maaten. 2017. 通过输入变换对抗对抗性图像。*arXiv 预印本 arXiv:1711.00117* (2017)。
- en: Guo et al. (2020) Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang,
    Bing Yu, Wei Feng, and Yang Liu. 2020. Watch out! motion is blurring the vision
    of your deep neural networks. *Advances in Neural Information Processing Systems*
    33 (2020), 975–985.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2020) Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang,
    Bing Yu, Wei Feng, 和 Yang Liu. 2020. 小心！运动模糊了深度神经网络的视觉。*神经信息处理系统进展* 33 (2020)，975–985。
- en: He et al. (2020) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
    2020. Momentum contrast for unsupervised visual representation learning. In *Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition*. 9729–9738.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. (2020) Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, 和 Ross Girshick.
    2020. 动量对比用于无监督视觉表征学习。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。9729–9738。
- en: 'Hendrycks et al. (2019) Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph,
    Justin Gilmer, and Balaji Lakshminarayanan. 2019. Augmix: A simple data processing
    method to improve robustness and uncertainty. *arXiv preprint arXiv:1912.02781*
    (2019).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks et al. (2019) Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph,
    Justin Gilmer, 和 Balaji Lakshminarayanan. 2019. Augmix：一种简单的数据处理方法来提高鲁棒性和不确定性。*arXiv
    预印本 arXiv:1912.02781* (2019)。
- en: 'Ho and Vasconcelos (2022) Chih-Hui Ho and Nuno Vasconcelos. 2022. DISCO: Adversarial
    Defense with Local Implicit Functions. *arXiv preprint arXiv:2212.05630* (2022).'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho and Vasconcelos (2022) Chih-Hui Ho 和 Nuno Vasconcelos. 2022. DISCO：利用局部隐式函数进行对抗性防御。*arXiv
    预印本 arXiv:2212.05630* (2022)。
- en: Hou et al. (2023) Yang Hou, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma, and
    Jianjun Zhao. 2023. Evading DeepFake Detectors via Adversarial Statistical Consistency.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*.
    12271–12280.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou et al. (2023) Yang Hou, Qing Guo, Yihao Huang, Xiaofei Xie, Lei Ma, 和 Jianjun
    Zhao. 2023. 通过对抗性统计一致性规避 DeepFake 检测器。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。12271–12280。
- en: Huang et al. (2023) Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, and Yang
    Zhang. 2023. Composite Backdoor Attacks Against Large Language Models. *arXiv
    preprint arXiv:2310.07676* (2023).
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2023) Hai Huang, Zhengyu Zhao, Michael Backes, Yun Shen, 和 Yang
    Zhang. 2023. 针对大型语言模型的复合后门攻击。*arXiv 预印本 arXiv:2310.07676* (2023)。
- en: 'Jia et al. (2020) Xiaojun Jia, Xingxing Wei, Xiaochun Cao, and Xiaoguang Han.
    2020. Adv-watermark: A novel watermark perturbation for adversarial examples.
    In *Proceedings of the 28th ACM International Conference on Multimedia*. 1579–1587.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia et al. (2020) Xiaojun Jia, Xingxing Wei, Xiaochun Cao, 和 Xiaoguang Han.
    2020. Adv-watermark：一种新颖的对抗性样本水印扰动。 在 *第28届 ACM 国际多媒体会议论文集*。1579–1587。
- en: 'Karimi et al. (2021) Akbar Karimi, Leonardo Rossi, and Andrea Prati. 2021.
    AEDA: An Easier Data Augmentation Technique for Text Classification. In *Findings
    of the Association for Computational Linguistics: EMNLP 2021*. 2748–2754.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karimi et al. (2021) Akbar Karimi, Leonardo Rossi, 和 Andrea Prati. 2021. AEDA:
    一种更简单的文本分类数据增强技术。在 *计算语言学协会发现：EMNLP 2021*。2748–2754。'
- en: Kumar et al. (2023) Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Soheil Feizi,
    and Hima Lakkaraju. 2023. Certifying llm safety against adversarial prompting.
    *arXiv preprint arXiv:2309.02705* (2023).
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kumar et al. (2023) Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Soheil Feizi,
    和 Hima Lakkaraju. 2023. 证明 LLM 对抗性提示的安全性。*arXiv 预印本 arXiv:2309.02705* (2023)。
- en: Kurakin et al. (2018) Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. 2018.
    Adversarial examples in the physical world. In *Artificial intelligence safety
    and security*. Chapman and Hall/CRC, 99–112.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kurakin et al. (2018) Alexey Kurakin, Ian J Goodfellow, 和 Samy Bengio. 2018.
    物理世界中的对抗样本。在 *人工智能安全与保障*。Chapman and Hall/CRC, 99–112。
- en: Liu et al. (2023a) Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang,
    Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu. 2023a. Prompt Injection attack
    against LLM-integrated Applications. *arXiv preprint arXiv:2306.05499* (2023).
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2023a) Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang,
    Yepang Liu, Haoyu Wang, Yan Zheng, 和 Yang Liu. 2023a. 针对 LLM 集成应用的提示注入攻击。*arXiv
    预印本 arXiv:2306.05499* (2023)。
- en: 'Liu et al. (2023b) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang, and Yang Liu. 2023b. Jailbreaking chatgpt
    via prompt engineering: An empirical study. *arXiv preprint arXiv:2305.13860*
    (2023).'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023b) Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng,
    Ying Zhang, Lida Zhao, Tianwei Zhang, 和 Yang Liu. 2023b. 通过提示工程破解 chatgpt: 一项实证研究。*arXiv
    预印本 arXiv:2305.13860* (2023)。'
- en: Lopes et al. (2019) Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer,
    and Ekin D Cubuk. 2019. Improving robustness without sacrificing accuracy with
    patch gaussian augmentation. *arXiv preprint arXiv:1906.02611* (2019).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lopes et al. (2019) Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer,
    and Ekin D Cubuk. 2019. 通过补丁高斯增强提升鲁棒性而不牺牲准确性。*arXiv 预印本 arXiv:1906.02611* (2019)。
- en: Madry et al. (2017) Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
    Tsipras, and Adrian Vladu. 2017. Towards deep learning models resistant to adversarial
    attacks. *arXiv preprint arXiv:1706.06083* (2017).
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madry et al. (2017) Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris
    Tsipras, 和 Adrian Vladu. 2017. 迈向对抗攻击具有抗性的深度学习模型。*arXiv 预印本 arXiv:1706.06083*
    (2017)。
- en: Marivate and Sefara (2020) Vukosi Marivate and Tshephisho Sefara. 2020. Improving
    short text classification through global augmentation methods. In *International
    Cross-Domain Conference for Machine Learning and Knowledge Extraction*. Springer,
    385–399.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marivate and Sefara (2020) Vukosi Marivate 和 Tshephisho Sefara. 2020. 通过全球增强方法改进短文本分类。在
    *International Cross-Domain Conference for Machine Learning and Knowledge Extraction*。Springer,
    385–399。
- en: 'Miller (1995) George A Miller. 1995. WordNet: a lexical database for English.
    *Commun. ACM* 38, 11 (1995), 39–41.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Miller (1995) George A Miller. 1995. WordNet: 英语的词汇数据库。*Commun. ACM* 38, 11
    (1995), 39–41。'
- en: 'Morris et al. (2020) John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby,
    Di Jin, and Yanjun Qi. 2020. TextAttack: A Framework for Adversarial Attacks,
    Data Augmentation, and Adversarial Training in NLP. In *Proceedings of the 2020
    Conference on Empirical Methods in Natural Language Processing: System Demonstrations,
    EMNLP 2020 - Demos, Online, November 16-20, 2020*, Qun Liu and David Schlangen
    (Eds.). Association for Computational Linguistics, 119–126. [https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16](https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Morris et al. (2020) John X. Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby,
    Di Jin, 和 Yanjun Qi. 2020. TextAttack: 一种用于对抗攻击、数据增强和对抗训练的框架。 在 *2020年自然语言处理经验方法会议论文集：系统演示，EMNLP
    2020 - 演示，在线，2020年11月16-20日*，Qun Liu 和 David Schlangen (编辑)。计算语言学协会, 119–126。
    [https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16](https://doi.org/10.18653/V1/2020.EMNLP-DEMOS.16)'
- en: Nenkova and Vanderwende (2005) Ani Nenkova and Lucy Vanderwende. 2005. The impact
    of frequency on summarization. *Microsoft Research, Redmond, Washington, Tech.
    Rep. MSR-TR-2005* 101 (2005).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nenkova and Vanderwende (2005) Ani Nenkova 和 Lucy Vanderwende. 2005. 频率对摘要的影响。*微软研究，华盛顿州雷德蒙德，技术报告
    MSR-TR-2005* 101 (2005)。
- en: Nie et al. (2022) Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat,
    and Anima Anandkumar. 2022. Diffusion models for adversarial purification. *arXiv
    preprint arXiv:2205.07460* (2022).
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nie et al. (2022) Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat,
    和 Anima Anandkumar. 2022. 用于对抗净化的扩散模型。*arXiv 预印本 arXiv:2205.07460* (2022)。
- en: Qi et al. (2023) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, and
    Prateek Mittal. 2023. Visual adversarial examples jailbreak aligned large language
    models. In *The Second Workshop on New Frontiers in Adversarial Machine Learning*.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi 等 (2023) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, 和 Prateek
    Mittal. 2023. 视觉对抗样本越狱对齐的大语言模型。在 *第二届对抗机器学习新前沿研讨会*。
- en: 'Rade and Moosavi-Dezfooli (2021) Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli.
    2021. Helper-based adversarial training: Reducing excessive margin to achieve
    a better accuracy vs. robustness trade-off. In *ICML 2021 Workshop on Adversarial
    Machine Learning*.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rade 和 Moosavi-Dezfooli (2021) Rahul Rade 和 Seyed-Mohsen Moosavi-Dezfooli. 2021.
    基于帮助者的对抗训练：减少过大的边际以实现更好的准确性与鲁棒性的权衡。在 *ICML 2021 对抗机器学习研讨会*。
- en: 'Robey et al. (2023) Alexander Robey, Eric Wong, Hamed Hassani, and George J
    Pappas. 2023. Smoothllm: Defending large language models against jailbreaking
    attacks. *arXiv preprint arXiv:2310.03684* (2023).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Robey 等 (2023) Alexander Robey, Eric Wong, Hamed Hassani, 和 George J Pappas.
    2023. Smoothllm: 防御大语言模型的越狱攻击。*arXiv 预印本 arXiv:2310.03684* (2023)。'
- en: 'Sehwag et al. (2021) Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui
    Dai, Chong Xiang, Mung Chiang, and Prateek Mittal. 2021. Robust learning meets
    generative models: Can proxy distributions improve adversarial robustness? *arXiv
    preprint arXiv:2104.09425* (2021).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sehwag 等 (2021) Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai,
    Chong Xiang, Mung Chiang, 和 Prateek Mittal. 2021. 鲁棒学习遇上生成模型：代理分布能否提高对抗鲁棒性？ *arXiv
    预印本 arXiv:2104.09425* (2021)。
- en: Sun et al. (2019) Bo Sun, Nian-hsuan Tsai, Fangchen Liu, Ronald Yu, and Hao
    Su. 2019. Adversarial defense by stratified convolutional sparse coding. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 11447–11456.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等 (2019) Bo Sun, Nian-hsuan Tsai, Fangchen Liu, Ronald Yu, 和 Hao Su. 2019.
    通过分层卷积稀疏编码进行对抗防御。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。11447–11456。
- en: 'Tian et al. (2021) Binyu Tian, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Xiaohong
    Li, and Yang Liu. 2021. AVA: Adversarial vignetting attack against visual recognition.
    *arXiv preprint arXiv:2105.05558* (2021).'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tian 等 (2021) Binyu Tian, Felix Juefei-Xu, Qing Guo, Xiaofei Xie, Xiaohong
    Li, 和 Yang Liu. 2021. AVA: 针对视觉识别的对抗性晕影攻击。*arXiv 预印本 arXiv:2105.05558* (2021)。'
- en: 'Xie et al. (2019) Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu
    Chen, Yang Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, and Simon See. 2019. Deephunter:
    a coverage-guided fuzz testing framework for deep neural networks. In *Proceedings
    of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis*.
    146–157.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xie 等 (2019) Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu Chen,
    Yang Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, 和 Simon See. 2019. Deephunter: 用于深度神经网络的覆盖引导模糊测试框架。在
    *第28届 ACM SIGSOFT 国际软件测试与分析研讨会论文集*。146–157。'
- en: 'Xu et al. (2023) Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, and Muhao
    Chen. 2023. Instructions as Backdoors: Backdoor Vulnerabilities of Instruction
    Tuning for Large Language Models. *arXiv preprint arXiv:2305.14710* (2023).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等 (2023) Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, 和 Muhao Chen.
    2023. 指令作为后门：大语言模型指令调优的后门漏洞。*arXiv 预印本 arXiv:2305.14710* (2023)。
- en: 'Xu et al. (2017) Weilin Xu, David Evans, and Yanjun Qi. 2017. Feature squeezing:
    Detecting adversarial examples in deep neural networks. *arXiv preprint arXiv:1704.01155*
    (2017).'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等 (2017) Weilin Xu, David Evans, 和 Yanjun Qi. 2017. 特征压缩：检测深度神经网络中的对抗样本。*arXiv
    预印本 arXiv:1704.01155* (2017)。
- en: Yan et al. (2023) Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang,
    Hai Wang, Vijay Srinivasan, Xiang Ren, and Hongxia Jin. 2023. Virtual prompt injection
    for instruction-tuned large language models. *arXiv preprint arXiv:2307.16888*
    (2023).
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan 等 (2023) Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai
    Wang, Vijay Srinivasan, Xiang Ren, 和 Hongxia Jin. 2023. 指令调优的大语言模型的虚拟提示注入。*arXiv
    预印本 arXiv:2307.16888* (2023)。
- en: 'Yu et al. (2023) Jiahao Yu, Xingwei Lin, and Xinyu Xing. 2023. Gptfuzzer: Red
    teaming large language models with auto-generated jailbreak prompts. *arXiv preprint
    arXiv:2309.10253* (2023).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等 (2023) Jiahao Yu, Xingwei Lin, 和 Xinyu Xing. 2023. Gptfuzzer: 通过自动生成的越狱提示对大语言模型进行红队测试。*arXiv
    预印本 arXiv:2309.10253* (2023)。'
- en: Zhang et al. (2021) Cen Zhang, Xingwei Lin, Yuekang Li, Yinxing Xue, Jundong
    Xie, Hongxu Chen, Xinlei Ying, Jiashui Wang, and Yang Liu. 2021. $\{$ Libraries.
    In *30th USENIX Security Symposium (USENIX Security 21)*. 2811–2828.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 (2021) Cen Zhang, Xingwei Lin, Yuekang Li, Yinxing Xue, Jundong Xie,
    Hongxu Chen, Xinlei Ying, Jiashui Wang, 和 Yang Liu. 2021. $\{$ 库。 在 *第30届 USENIX
    安全研讨会 (USENIX Security 21)*。2811–2828。
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-as-a-judge with MT-Bench
    and Chatbot Arena. arXiv:2306.05685 [cs.CL]
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng et al. (2023) 郑连敏、姜伟麟、盛颖、庄思远、吴章豪、庄永浩、林子、李卓涵、李大成、艾瑞克·P·辛、张浩、约瑟夫·E·冈萨雷斯和伊昂·斯托伊卡。2023。通过
    MT-Bench 和 Chatbot Arena 评判 LLM 作为裁判。arXiv:2306.05685 [cs.CL]
- en: 'Zhu et al. (2023a) Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed
    Elhoseiny. 2023a. Minigpt-4: Enhancing vision-language understanding with advanced
    large language models. *arXiv preprint arXiv:2304.10592* (2023).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2023a) 朱德耀、陈军、沈晓倩、李翔和穆罕默德·艾尔霍赛尼。2023a。Minigpt-4: 通过先进的大型语言模型提升视觉-语言理解。*arXiv
    预印本 arXiv:2304.10592* (2023)。'
- en: 'Zhu et al. (2023b) Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow,
    Zichao Wang, Furong Huang, Ani Nenkova, and Tong Sun. 2023b. AutoDAN: Automatic
    and Interpretable Adversarial Attacks on Large Language Models. *arXiv preprint
    arXiv:2310.15140* (2023).'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu et al. (2023b) 朱思诚、张睿伊、安邦、吴刚、乔·巴罗、王子超、黄芙蓉、阿尼·嫩科娃和孙彤。2023b。AutoDAN: 自动化且可解释的大型语言模型对抗攻击。*arXiv
    预印本 arXiv:2310.15140* (2023)。'
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson.
    2023. Universal and transferable adversarial attacks on aligned language models.
    *arXiv preprint arXiv:2307.15043* (2023).
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou et al. (2023) 安迪·邹、王子凡、J·齐科·科尔特和马特·弗雷德里克森。2023。对齐语言模型的普遍且可转移的对抗攻击。*arXiv
    预印本 arXiv:2307.15043* (2023)。
