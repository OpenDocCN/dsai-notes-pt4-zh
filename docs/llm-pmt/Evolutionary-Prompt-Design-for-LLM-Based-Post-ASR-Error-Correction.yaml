- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:41:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:41:30
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于LLM的ASR后期错误校正的进化提示设计
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2407.16370](https://ar5iv.labs.arxiv.org/html/2407.16370)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2407.16370](https://ar5iv.labs.arxiv.org/html/2407.16370)
- en: Abstract
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Building upon the strength of modern large language models (LLMs), generative
    error correction (GEC) has emerged as a promising paradigm that can elevate the
    performance of modern automatic speech recognition (ASR) systems. One representative
    approach is to leverage in-context learning to prompt LLMs so that a better hypothesis
    can be generated by the LLMs based on a carefully-designed prompt and an $N$ GenSEC
    challenge show the effectiveness and potential of the proposed algorithms.¹¹1Our
    code is open sourced at [https://github.com/rithiksachdev/PostASR-Correction-SLT2024](https://github.com/rithiksachdev/PostASR-Correction-SLT2024).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 基于现代大型语言模型（LLMs）的优势，生成错误校正（GEC）已成为一种有前途的范式，可以提升现代自动语音识别（ASR）系统的性能。一种代表性的方法是利用上下文学习来提示LLMs，从而基于精心设计的提示生成更好的假设，一个$N$
    GenSEC挑战展示了所提算法的有效性和潜力。¹¹1我们的代码开源于 [https://github.com/rithiksachdev/PostASR-Correction-SLT2024](https://github.com/rithiksachdev/PostASR-Correction-SLT2024)。
- en: Index Terms—  Evolutionary prompt optimization, post-ASR error correction, large
    language models, automatic speech recognition.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 索引词—— 进化提示优化、ASR后期错误校正、大型语言模型、自动语音识别。
- en: 1 Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) [[1](#bib.bib1)], trained on massive textual data
    using neural network-based transformer architectures, have revolutionized many
    tasks in natural language processing. The auto-regressive learning nature of LLMs
    introduces and empowers a new “prompting” mechanism based on input instructions,
    where users can provide text prompts to guide LLMs to complete particular tasks
    [[2](#bib.bib2)] as a form of next token prediction.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）[[1](#bib.bib1)]，利用神经网络基础的变换器架构在大规模文本数据上训练，已彻底改变了自然语言处理中的许多任务。LLMs的自回归学习特性引入并赋能了一种基于输入指令的新“提示”机制，用户可以提供文本提示来引导LLMs完成特定任务[[2](#bib.bib2)]，作为下一标记预测的一种形式。
- en: One of these popular prompt-activated tasks is post-automatic speech recognition
    (ASR) text correction, where based on an $N$-hypotheses list.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这些流行的提示激活任务之一是基于$N$假设列表的自动语音识别（ASR）文本校正。
- en: When input prompts are critical for instructing LLMs on unseen ASR tasks, these
    task-activating prompts [[10](#bib.bib10)] are often empirically-designed and
    under-explored in the research community. For example, early works [[11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)] focus on iterative optimization
    at the waveform level to instruct acoustic models for new tasks, but there are
    fewer studies on optimizing LLM-prompts for ASR tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入提示对于指导LLMs处理未见过的ASR任务至关重要时，这些任务激活提示[[10](#bib.bib10)]通常是经验性设计的，并且在研究界尚未深入探讨。例如，早期的工作[[11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]专注于在波形层面进行迭代优化，以指导声学模型处理新任务，但对优化LLM提示以处理ASR任务的研究较少。
- en: To achieve better post-ASR error correction, this paper explores alternative
    prompts for this task, and investigates a conditional evolutionary strategies
    based prompt optimization algorithm, named EvoPrompt [[15](#bib.bib15)], to refine
    the alternative prompts. Evaluation results on the CHiME-4 subset of the HyPoradise
    dataset [[3](#bib.bib3)] show the effectiveness of the proposed algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现更好的ASR后期错误校正，本文探讨了该任务的替代提示，并研究了一种基于条件进化策略的提示优化算法，名为EvoPrompt [[15](#bib.bib15)]，以改进替代提示。CHiME-4子集的评估结果显示了所提算法的有效性。
- en: In the rest of this paper, we describe the proposed algorithm in Section [2](#S2
    "2 Proposed Algorithms ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error
    Correction"), experimental setup in Section [3](#S3 "3 Experimental Setup ‣ Evolutionary
    Prompt Design for LLM-Based Post-ASR Error Correction"), evaluation results in
    Section [4](#S4 "4 Evaluation Results ‣ Evolutionary Prompt Design for LLM-Based
    Post-ASR Error Correction"), and conclusions in Section [5](#S5 "5 Conclusions
    ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction").
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的其余部分，我们将在第[2](#S2 "2 提出的算法 ‣ 基于LLM的ASR后期错误修正的演化提示设计")节描述提出的算法，在第[3](#S3
    "3 实验设置 ‣ 基于LLM的ASR后期错误修正的演化提示设计")节描述实验设置，在第[4](#S4 "4 评估结果 ‣ 基于LLM的ASR后期错误修正的演化提示设计")节描述评估结果，在第[5](#S5
    "5 结论 ‣ 基于LLM的ASR后期错误修正的演化提示设计")节给出结论。
- en: 2 Proposed Algorithms
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 提出的算法
- en: Fig. [1](#S2.F1 "Figure 1 ‣ 2 Proposed Algorithms ‣ Evolutionary Prompt Design
    for LLM-Based Post-ASR Error Correction") illustrates the proposed system, where
    an $N$-best list of hypotheses and a prompt are input to an LLM for error correction.
    This section first describes several empirically-designed alternative prompts,
    and then leverages an evolutionary algorithm named EvoPrompt [[15](#bib.bib15)]
    for prompt optimization.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](#S2.F1 "图1 ‣ 2 提出的算法 ‣ 基于LLM的ASR后期错误修正的演化提示设计")展示了提出的系统，其中一个$N$-最佳假设列表和一个提示被输入到LLM中进行错误修正。本节首先描述几种经验设计的替代提示，然后利用一种名为EvoPrompt的演化算法[[15](#bib.bib15)]进行提示优化。
- en: '![Refer to caption](img/720f57ffe159298ce75fb80db54dc99d.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/720f57ffe159298ce75fb80db54dc99d.png)'
- en: 'Fig. 1: Approach overview, where an $N$-best list of hypotheses and a trainable
    prompt instruction are fed to a pre-trained LLM for error correction. Details
    of prompt design processes are shown in Fig. [3](#S3.F3 "Figure 3 ‣ 3 Experimental
    Setup ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction").'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：方法概述，其中一个$N$-最佳假设列表和一个可训练的提示指令被输入到预训练的LLM中进行错误修正。提示设计过程的详细信息见图[3](#S3.F3
    "图3 ‣ 3 实验设置 ‣ 基于LLM的ASR后期错误修正的演化提示设计")。
- en: 2.1 Alternative Prompt Design
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 替代提示设计
- en: 'In Task $1$ of the GenSEC challenge, the default prompt provided by the challenge
    organizers is You need to do language model rescoring in ASR. Given the 5-best
    hypotheses, you need to report the true transcription from the 5-best hypotheses.
    We denote this prompt as Baseline Prompt. It has shown strong performance in post-ASR
    error correction tasks [[3](#bib.bib3)], but it is unknown whether there exist
    better prompts. To improve the performance, we propose the following alternative
    prompts:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenSEC挑战的任务$1$中，挑战组织者提供的默认提示是“你需要在ASR中进行语言模型重新评分。给定5个最佳假设，你需要从5个最佳假设中报告真实的转录。”我们将此提示称为基线提示。它在ASR后期错误修正任务中表现强劲[[3](#bib.bib3)]，但是否存在更好的提示尚不清楚。为了提高性能，我们提出了以下替代提示：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt #1: This is a hard problem. You need to report the true transcription
    from the 5-best hypotheses..'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示#1：这是一个难题。你需要从5个最佳假设中报告真实的转录。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt #2: This is a hard problem. Carefully summarize in ONE detailed sentence
    the following captions by different people describing the same audio. Do not allude
    to the existence of the multiple captions. Focus on describing the content of
    the audio. The transcriptions have some intialism for corporations.'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示#2：这是一个难题。仔细用一个详细的句子总结不同人描述相同音频的以下字幕。不要提及多个字幕的存在。专注于描述音频的内容。转录中有一些公司的首字母缩写。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt #3: You have been given 5 different possible captions of the same audio,
    carefully summarize the given text in one sentence. Make sure to follow all the
    steps in identifying the right summary.'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示#3：你已经得到5个不同的可能字幕来描述相同的音频，仔细用一句话总结给定的文本。确保遵循识别正确摘要的所有步骤。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt #4: There is some financial data discussed in a meeting. You need to
    correctly give the true transcription from the 5-best hypotheses. Your task is
    to critically evaluate these option using english grammar. Mostly these transcriptions
    are in present continous tense.'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示#4：在会议中讨论了一些财务数据。你需要从5个最佳假设中正确给出真实的转录。你的任务是使用英语语法批判性地评估这些选项。这些转录大多是现在进行时态。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prompt #5: There are five transcriptions hypotheses for a given audio and you
    need to report the true transcription by using english grammar rules.'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示#5：对于给定的音频，有五个转录假设，你需要使用英语语法规则报告真实的转录。
- en: 'These prompts are designed based on our experiences with modern LLMs such as
    GPT [[16](#bib.bib16)], Claude [[17](#bib.bib17)] and LLaMA [[18](#bib.bib18)].
    In Prompt #1, we tell LLMs that the task is to report the true transcription based
    on a set of hypotheses. This could bias the LLMs towards re-scoring tasks. In
    both Prompt #1 and #2, we explicitly inform LLMs that the task is a hard problem.
    We empirically observe that this often leads to better performance in many tasks,
    not just limited to post-ASR error correction. In Promp #3, we ask the model to
    summarize the given hypotheses into one sentence, as summarization is a task closely-related
    to post-ASR error correction. In Prompt #4, we explicitly tell LLMs that the data
    we are dealing with are related to finance, which is true in the case of CHiME-4
    [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)], as CHiME-4 is built upon
    the WSJ dataset [[22](#bib.bib22)]. In Prompt #5, we ask LLMs to provide gramatically-correct
    outputs. This could be helpful for post-ASR error correction, as we observe that
    some ASR transcriptions contain grammar errors.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些提示是基于我们与现代LLMs（如GPT [[16](#bib.bib16)]、Claude [[17](#bib.bib17)] 和 LLaMA [[18](#bib.bib18)]）的经验设计的。在提示#1中，我们告诉LLMs任务是基于一组假设报告真实的转录。这可能会使LLMs倾向于重新评分任务。在提示#1和#2中，我们明确告知LLMs任务是一个难题。我们经验观察到，这通常在许多任务中会导致更好的表现，不仅仅限于ASR后错误修正。在提示#3中，我们要求模型将给定的假设总结为一句话，因为摘要是与ASR后错误修正密切相关的任务。在提示#4中，我们明确告诉LLMs我们处理的数据与金融相关，这在CHiME-4
    [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)]的情况下是正确的，因为CHiME-4基于WSJ数据集[[22](#bib.bib22)]。在提示#5中，我们要求LLMs提供语法正确的输出。这可能对ASR后错误修正有帮助，因为我们观察到一些ASR转录包含语法错误。
- en: 2.2 Employing EvoPrompt for Prompt Optimization
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 采用EvoPrompt进行提示优化
- en: In many application scenarios, empirically-designed prompts are often not good
    enough. Prompt optimization, which aims at automatically finding a prompt that
    can lead to better performance for considered tasks, has been attracting wide
    research interests in LLM research.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用场景中，经验设计的提示往往不够理想。提示优化旨在自动找到一个能够提升考虑任务性能的提示，这一领域已经引起了LLM研究的广泛关注。
- en: A promising recent algorithm in this direction is EvoPrompt²²2[https://github.com/beeevita/EvoPrompt](https://github.com/beeevita/EvoPrompt)
    [[15](#bib.bib15)], which has shown strong performance and potential on natural
    language processing tasks such as text classification, simplification and summarization.
    EvoPrompt is an iterative prompt optimization algorithm starting from an initial
    set (or population) of $N$) for the next iteration. One of the key steps is in
    how to create each of the new prompts based on the best subset. In EvoPrompt,
    each new prompt is created based on two prompts randomly selected from the best
    subset of prompts, and LLMs are utilized to first cross-over the two prompts and
    then mutate the resulting prompt. See Fig. [2](#S2.F2 "Figure 2 ‣ 2.2 Employing
    EvoPrompt for Prompt Optimization ‣ 2 Proposed Algorithms ‣ Evolutionary Prompt
    Design for LLM-Based Post-ASR Error Correction") for an example. This evolutionary
    mechanism has been shown effective by EvoPrompt [[15](#bib.bib15)].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在这一方向上有一个有前途的算法是EvoPrompt²²2[https://github.com/beeevita/EvoPrompt](https://github.com/beeevita/EvoPrompt)
    [[15](#bib.bib15)]，该算法在自然语言处理任务中表现出色，具有很大的潜力，如文本分类、简化和摘要。EvoPrompt是一种迭代的提示优化算法，从初始的一组（或种群）$N$开始进行下一次迭代。关键步骤之一是如何根据最佳子集创建每一个新的提示。在EvoPrompt中，每个新的提示是基于从最佳子集中随机选择的两个提示创建的，并且使用LLMs首先交叉这两个提示，然后变异生成的提示。有关示例，请参见图[2](#S2.F2
    "Figure 2 ‣ 2.2 Employing EvoPrompt for Prompt Optimization ‣ 2 Proposed Algorithms
    ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction")。这种进化机制已经通过EvoPrompt
    [[15](#bib.bib15)] 得到验证。
- en: In this context, to find prompts that can result in better post-ASR error correction,
    we employ EvoPrompt for prompt optimization. We choose the Genetic Algorithm (GA)
    option in EvoPrompt (see Algorithm $2$ of [[15](#bib.bib15)]).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为了找到可以改进ASR后错误修正的提示，我们采用了EvoPrompt进行提示优化。我们选择了EvoPrompt中的遗传算法（GA）选项（见[[15](#bib.bib15)]的算法$2$）。
- en: '![Refer to caption](img/68732df96c11f6e0f4cee46b92b13b88.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/68732df96c11f6e0f4cee46b92b13b88.png)'
- en: 'Fig. 2: Example of text prompt optimization processes through (i) cross-over
    and (ii) mutation performed by LLM-operators.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：通过（i）交叉和（ii）由LLM-操作员执行的变异的文本提示优化过程示例。
- en: 3 Experimental Setup
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验设置
- en: We validate the proposed algorithms on the task $1$ SLT Generative Speech Error
    Correction (GenSEC) challenge.³³3More details of the GenSEC challenge can be found
    at [https://sites.google.com/view/gensec-challenge/home](https://sites.google.com/view/gensec-challenge/home)
    The task is on learning a mapping from N-best list of hypotheses (produced by
    ASR models) to ground-truth speech transcription so that recognition errors can
    be corrected. The challenge is designed based on the HyPoradise dataset [[3](#bib.bib3)],
    which consists of pairs of the N-best list and correct transcription of the utterances
    derived based on multiple public ASR datasets such as LibriSpeech [[23](#bib.bib23)]
    and CHiME-4 [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)] by using strong
    ASR models such as Whisper [[24](#bib.bib24)], and WavLM [[25](#bib.bib25)] based
    ASR models.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在任务 $1$ SLT生成语音错误修正（GenSEC）挑战上验证了提出的算法。³³3更多关于GenSEC挑战的细节可以在 [https://sites.google.com/view/gensec-challenge/home](https://sites.google.com/view/gensec-challenge/home)
    找到。该任务是学习从ASR模型生成的N-best假设列表到真实语音转录的映射，以便纠正识别错误。该挑战基于HyPoradise数据集 [[3](#bib.bib3)]，该数据集由基于多个公开ASR数据集（如LibriSpeech
    [[23](#bib.bib23)] 和 CHiME-4 [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)]）使用强大的ASR模型（如Whisper
    [[24](#bib.bib24)] 和 WavLM [[25](#bib.bib25)]）得到的N-best列表和正确转录对组成。
- en: Different from the official challenge configurations, our experimental setup
    only uses the CHiME-4 subset of HyPoradise for training. This is mainly out of
    cost concerns, as the evolutionary algorithm needs to compute a score for every
    considered prompt in each iteration. In CHiME-4 [[19](#bib.bib19), [20](#bib.bib20),
    [21](#bib.bib21)], there are $8,738$ utterances in the training, validation and
    test set, respectively, and HyPoradise [[3](#bib.bib3)] provides five hypotheses
    for each utterance. The task is to predict the true transcription based on the
    five hypotheses. In this study, since our main goal is prompt optimization, our
    system does not leverage acoustic information in error correction and only exploits
    text-level information.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与官方挑战配置不同，我们的实验设置仅使用HyPoradise的CHiME-4子集进行训练。这主要是出于成本考虑，因为进化算法需要在每次迭代中为每个考虑的提示计算分数。在CHiME-4
    [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)] 中，训练、验证和测试集中分别有$8,738$个语句，HyPoradise
    [[3](#bib.bib3)] 为每个语句提供了五个假设。任务是根据这五个假设预测真实的转录。在这项研究中，由于我们的主要目标是提示优化，我们的系统不利用声学信息进行错误修正，仅利用文本级信息。
- en: Besides evaluating optimized prompts on the test set of CHiME-4, we investigate
    the generalizability of the optimized prompts to unseen domains by using two other
    datasets (including Common Voice (CV) [[26](#bib.bib26)] and Wall-Street Jounral
    (WSJ) [[22](#bib.bib22)]) for evaluation. There are $836$ test utterances in CV,
    and HyPoradise provides five hypotheses for each of the test utterances.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在CHiME-4的测试集上评估优化的提示外，我们还通过使用其他两个数据集（包括Common Voice (CV) [[26](#bib.bib26)]
    和 Wall-Street Journal (WSJ) [[22](#bib.bib22)]）来调查优化提示对未见领域的泛化能力。CV中有$836$个测试语句，HyPoradise为每个测试语句提供了五个假设。
- en: The LLM we use for prompt optimization is Claude [[17](#bib.bib17)]⁴⁴4We use
    Claude 3.5 Sonnet. See details in [https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet).,
    which has shown competitive performance compared with many state-of-the-art LLMs.
    We provide one demonstration example [[27](#bib.bib27)] to the LLM before asking
    the model to perform error correction. We find that this demonstration strategy
    is very helpful for in-context learning. In Fig. [3](#S3.F3 "Figure 3 ‣ 3 Experimental
    Setup ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction"),
    we provide an example of the input we use in our experiments to LLMs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用于提示优化的LLM是Claude [[17](#bib.bib17)]⁴⁴4我们使用Claude 3.5 Sonnet。详情见 [https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)。该模型与许多最先进的LLM相比表现出色。在要求模型执行错误修正之前，我们向LLM提供了一个演示示例
    [[27](#bib.bib27)]。我们发现，这种演示策略对上下文学习非常有帮助。在图 [3](#S3.F3 "图 3 ‣ 3 实验设置 ‣ 基于LLM的ASR后处理错误修正的演变提示设计")
    中，我们展示了在实验中使用的输入示例。
- en: '![Refer to caption](img/66e128d0ea2b6e10920a56bdcf18b0cd.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/66e128d0ea2b6e10920a56bdcf18b0cd.png)'
- en: 'Fig. 3: Example input for in-context learning with one demonstration, where
    the first paragraph denotes the prompt, second and third denotes one demonstration
    example, and fourth and fifth requests LLMs to correct errors.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 用于上下文学习的示例输入，其中第一段表示提示，第二和第三段表示一个演示示例，第四和第五段请求LLM进行错误修正。'
- en: We use word error rates (WER) as the evaluation metric, where we optimize our
    prompt on the training set of the Hyporadise and report WER performance on the
    unseen test set based on the prompted-LLM performance on the training set.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用字错误率（WER）作为评估指标，通过在Hyporadise的训练集上优化提示，并根据训练集上提示的LLM性能报告在未见测试集上的WER性能。
- en: 4 Evaluation Results
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 评估结果
- en: 4.1 Results of Alternative Prompts
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 替代提示的结果
- en: In row $1$, indicating the effectiveness of the proposed alternative prompts.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在第$1$行中，表明提出的替代提示的有效性。
- en: 'Table 1: Results of post-ASR error correction on CHiME-4 test set'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：在CHiME-4测试集上的ASR后纠错结果
- en: '| Row | Prompts | #Demonstrations | #Iterations | WER (%)$\downarrow$ |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 行 | 提示 | #演示 | #迭代 | WER (%)$\downarrow$ |'
- en: '| $0$ |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| $0$ |'
- en: '| $1$ |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| $1$ |'
- en: '| $1$ |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| $1$ |'
- en: '| $1$ |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| $1$ |'
- en: '| $1$ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| $1$ |'
- en: '| $1$ |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| $1$ |'
- en: '| $2$ |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| $2$ |'
- en: '| $2$ |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| $2$ |'
- en: '| $2$ |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| $2$ |'
- en: '| $2$ |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| $2$ |'
- en: '| $2$ |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| $2$ |'
- en: '| $3$ |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $3$ |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $3$ |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $3$ |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $3$ |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $4$ |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $4$ |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $4$ |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $4$ |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $4$ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $5$ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: '| $5$ |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: '| $5$ |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: '| $5$ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: '| $5$ |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: 4.2 Results of EvoPrompt for Prompt Optimization
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 EvoPrompt用于提示优化的结果
- en: In $2$e, we observe that including one demonstration improves the performance.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在$2$e中，我们观察到包括一个演示可以改善性能。
- en: In $2$%. This indicates the effectiveness and potential of EvoPrompt for prompt
    optimization.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在$2$%。这表明EvoPrompt在提示优化中的有效性和潜力。
- en: 4.3 Analysis of Optimized Prompt
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 优化提示分析
- en: 'The optimized prompt obtained by applying EvoPrompt to Prompt-$1$ in the first
    iteration is: You are presented with 5 different transcription hypotheses for
    a single audio clip from a financial meeting. Your task is to critically evaluate
    these options, considering factors such as context, coherence, and English language
    conventions. Synthesize the most likely and accurate representation of the audio
    content into one concise, grammatically correct sentence that is mostly present
    continuous tense. Comparing it with Prompt #1 presented in Section [2.1](#S2.SS1
    "2.1 Alternative Prompt Design ‣ 2 Proposed Algorithms ‣ Evolutionary Prompt Design
    for LLM-Based Post-ASR Error Correction"), we observe that:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '通过将EvoPrompt应用于Prompt-$1$的第一次迭代，优化后的提示是：你面临5种不同的转录假设，来自一次财务会议的单个音频片段。你的任务是批判性地评估这些选项，考虑因素如上下文、连贯性和英语语言习惯。将音频内容的最可能且准确的表现合成一句简洁、语法正确的句子，这句话大多使用现在进行时。与第[2.1](#S2.SS1
    "2.1 Alternative Prompt Design ‣ 2 Proposed Algorithms ‣ Evolutionary Prompt Design
    for LLM-Based Post-ASR Error Correction")节中呈现的Prompt #1进行比较，我们观察到：'
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The mutated prompt provides clearer instructions, which facilitate the task
    for the LLM. Instead of a vague instruction like report the true transcription,
    an optimized instruction provides specific guidelines, such as Your task is to
    critically evaluate these options, taking into account factors like context, coherence,
    and English language conventions.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 突变提示提供了更清晰的指示，这有助于LLM完成任务。与模糊指示如“报告真实转录”相比，优化后的指示提供了具体的指南，如“你的任务是批判性地评估这些选项，考虑上下文、连贯性和英语语言习惯等因素”。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The improved prompts are more appropriate to the context, ensuring that they
    are tailored to the dataset. For example, for the CHiME-4 dataset, which contains
    financial transcriptions, the mutated prompt is focused on financial terms and
    contexts.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 改进后的提示更适合上下文，确保它们适应数据集。例如，对于包含财务转录的CHiME-4数据集，突变提示集中在财务术语和上下文上。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Including one demonstration example in the layout of the prompts significantly
    helps the LLM understand the desired output style and how to correct errors. Demonstrations
    can provide a clear reference, reducing ambiguity, and guiding the LLM towards
    producing more accurate transcriptions.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在提示的布局中包括一个演示示例显著有助于LLM理解所需的输出风格和如何纠正错误。演示可以提供清晰的参考，减少歧义，并引导LLM生成更准确的转录。
- en: 4.4 Examples of Corrected Errors
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 纠正错误的示例
- en: Table [2](#S4.T2 "Table 2 ‣ 4.4 Examples of Corrected Errors ‣ 4 Evaluation
    Results ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction")
    provides an example of the corrected errors. We observe that biasing LLMs towards
    the domain of finance helps correct errors such as “fidelity” and “gencorp”, which
    are financial terms.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表[2](#S4.T2 "Table 2 ‣ 4.4 Examples of Corrected Errors ‣ 4 Evaluation Results
    ‣ Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction")提供了纠正错误的示例。我们观察到，将LLM倾向于金融领域有助于纠正“fidelity”和“gencorp”等金融术语的错误。
- en: 'Table 2: Example of corrected errors based on an utterance drawn from CHiME-4\.
    Best viewed in color.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：基于来自CHiME-4的发言纠正错误的示例。最佳效果请使用彩色显示。
- en: '| Type | Utterance | WER (%)$\downarrow$ |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 发言 | WER (%)$\downarrow$ |'
- en: '| 1^(st) Hypo. by AM | fatelli had contended that genecorp is not a qualified
    broadcaster because it failed to disclose allegedly improper political campaign
    contributions and foreign payments | $8.69$ |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 1^(st)假设由AM | fatelli曾主张genecorp不是合格的广播公司，因为它未能披露涉嫌不当的政治竞选捐款和外国支付 | $8.69$
    |'
- en: '| 2^(nd) Hypo. by AM | fidelity had contended that jeane corp is not a qualified
    broadcaster because it failed to disclose allegedly improper political campaign
    contributions and foreign payments | $8.69$ |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| AM的第2^(nd)假设 | fidelity曾主张jeane corp不是合格的广播公司，因为它未能披露涉嫌不当的政治竞选捐款和外国支付 | $8.69$
    |'
- en: '| Correction by LLM | fidelity had contended that gencorp is not a qualified
    broadcaster because it failed to disclose allegedly improper political campaign
    contributions and foreign payments | $0$ |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| LLM纠正 | fidelity曾主张gencorp不是合格的广播公司，因为它未能披露涉嫌不当的政治竞选捐款和外国支付 | $0$ |'
- en: '| Ground-truth Transcription | fidelity had contended that gencorp is not a
    qualified broadcaster because it failed to disclose allegedly improper political
    campaign contributions and foreign payments | - |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 真实转录 | fidelity曾主张gencorp不是合格的广播公司，因为它未能披露涉嫌不当的政治竞选捐款和外国支付 | - |'
- en: 4.5 Generalizability of Optimized Prompts to Unseen Domains
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 优化提示对未见领域的泛化能力
- en: 'Table [3](#S4.T3 "Table 3 ‣ 4.5 Generalizability of Optimized Prompts to Unseen
    Domains ‣ 4 Evaluation Results ‣ Evolutionary Prompt Design for LLM-Based Post-ASR
    Error Correction") and [4](#S4.T4 "Table 4 ‣ 4.5 Generalizability of Optimized
    Prompts to Unseen Domains ‣ 4 Evaluation Results ‣ Evolutionary Prompt Design
    for LLM-Based Post-ASR Error Correction") report the results on the CV and WSJ
    test sets. They offer valuable understandings about the ability of the model to
    extend its performance beyond the data it is trained on. The best performing mutated
    prompt #$1$ from the CHiME experiement shows a deterioration in performance on
    both test sets, with a higher WER compared to the baseline. This implies that
    the mutations implemented in Prompt #1 are not beneficial for the process of generalization.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '表[3](#S4.T3 "Table 3 ‣ 4.5 Generalizability of Optimized Prompts to Unseen
    Domains ‣ 4 Evaluation Results ‣ Evolutionary Prompt Design for LLM-Based Post-ASR
    Error Correction")和[4](#S4.T4 "Table 4 ‣ 4.5 Generalizability of Optimized Prompts
    to Unseen Domains ‣ 4 Evaluation Results ‣ Evolutionary Prompt Design for LLM-Based
    Post-ASR Error Correction")报告了在CV和WSJ测试集上的结果。这些结果提供了关于模型在超越其训练数据的表现能力的宝贵见解。来自CHiME实验的表现最佳的突变提示
    #$1$ 在这两个测试集上的表现都有所下降，相较基线有更高的WER。这意味着提示 #1 中实施的突变对泛化过程并无益处。'
- en: 'The mutated prompt #$2$%) on the CV test set. This indicates that the specific
    alterations in prompt may have contributed generalized traits that benefit both
    seen and unseen areas.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '在CV测试集上的突变提示 #$2$%)。这表明，提示中的具体变化可能带来了对见过和未见过领域都有益的泛化特征。'
- en: Therefore, the findings indicate that the ability of post-ASR error correcting
    models to make generalizations might vary greatly depending on the initial prompts
    employed (i.e., Prompt-#{$1,\dots,5$}). Further research could explore the specific
    words and characteristics of the prompt that contribute to its generalizability.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，研究结果表明，后ASR错误纠正模型进行泛化的能力可能会因所使用的初始提示（即提示-#{$1,\dots,5$}）而大相径庭。进一步的研究可以探讨提示中的具体词汇和特征，这些特征有助于其泛化能力。
- en: 'Table 3: Results of post-ASR error correction using evolutionary prompts on
    unseen Common Voice test set of Hyporadise'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：在未见的Common Voice测试集上使用进化提示进行后ASR错误纠正的结果
- en: '| Row | Prompts | #Demonstrations | WER (%)$\downarrow$ |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 行 | 提示 | #演示 | WER (%)$\downarrow$ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | Baseline Prompt | 0 | $11.062\,860\,4$ |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 基线提示 | 0 | $11.062\,860\,4$ |'
- en: '| $3$ |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $4$ |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $5$ |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: 'Table 4: Results of post-ASR error correction using evolutionary prompts on
    unseen Wall-Street Journal test set of Hyporadise'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：在未见的Wall-Street Journal测试集上使用进化提示进行后ASR错误纠正的结果
- en: '| Row | Prompts | #Demonstrations | WER (%)$\downarrow$ |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 行 | 提示 | #演示 | WER (%)$\downarrow$ |'
- en: '| --- | --- | --- | --- |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | Baseline Prompt | 0 | $3.67$ |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 基线提示 | 0 | $3.67$ |'
- en: '| $3$ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| $3$ |'
- en: '| $4$ |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| $4$ |'
- en: '| $5$ |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| $5$ |'
- en: 4.6 Cost of Proposed Algorithms
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 提议算法的成本
- en: The API for Claude 3.5 Sonnet is charged at $3 per million input tokens and
    $15 per million output tokens. It provides more input and output tokens at a reduced
    cost than the previous Claude 3 Opus model. The cost for a single experiment on
    the CHiME-4 dataset using Claude Sonnet 3.5 is around $$2.2$. Check out the pricing
    page of Claude⁵⁵5[https://www.anthropic.com/pricing#anthropic-api](https://www.anthropic.com/pricing#anthropic-api)
    for more details.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Claude 3.5 Sonnet 的 API 费用为每百万个输入标记 $3 和每百万个输出标记 $15。与之前的 Claude 3 Opus 模型相比，它提供了更多的输入和输出标记且成本更低。使用
    Claude Sonnet 3.5 在 CHiME-4 数据集上进行单次实验的费用大约为 $$2.2$。有关更多细节，请查看 Claude⁵⁵5[https://www.anthropic.com/pricing#anthropic-api](https://www.anthropic.com/pricing#anthropic-api)
    的定价页面。
- en: 5 Conclusions
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: We have proposed alternative prompts for post-ASR error corrections, and leveraged
    an evolutionary prompt optimization algorithm for prompt optimization. Evaluation
    results on the CHiME-4 subset of the GenSEC Challenge Task $1$ show the effectiveness
    of the proposed algorithms, suggesting that leveraging conventional evolutionary
    algorithms for prompt optimization is a promising research direction. Moving forward,
    we plan to investigate LLM fine-tuning to find better prompts for generative error
    correction.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了用于后 ASR 错误纠正的替代提示，并利用了进化提示优化算法进行提示优化。在 GenSEC 挑战任务 $1$ 的 CHiME-4 子集上的评估结果显示了所提算法的有效性，建议利用传统的进化算法进行提示优化是一个有前途的研究方向。未来，我们计划研究
    LLM 微调，以寻找更好的生成错误纠正提示。
- en: Acknowledgment
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 致谢
- en: The authors would like to thank Prof. Shinji Wanatabe for his valuable feedbacks
    and encouragements on experimental designs when initializing the project.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们感谢 Shinji Wanatabe 教授在项目启动时对实验设计的宝贵反馈和鼓励。
- en: References
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] S. Minaee, T. Mikolov, N. Nikzad, M. Chenaghlu, R. Socher, X. Amatriain,
    and J. Gao, “Large Language Models: A Survey,” *arXiv preprint arXiv:2402.06196*,
    2024.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] S. Minaee, T. Mikolov, N. Nikzad, M. Chenaghlu, R. Socher, X. Amatriain,
    和 J. Gao, “大型语言模型：综述，” *arXiv 预印本 arXiv:2402.06196*，2024。'
- en: '[2] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train,
    Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language
    Processing,” *ACM Computing Surveys*, 2022.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, 和 G. Neubig, “预训练、提示和预测：自然语言处理中的提示方法系统综述，”
    *ACM Computing Surveys*，2022。'
- en: '[3] C. Chen, Y. Hu *et al.*, “HyPoradise: An Open Baseline for Generative Speech
    Recognition with Large Language Models,” in *NeurIPS - Datasets and Benchmarks
    Track*, vol. 36, 2023.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] C. Chen, Y. Hu *等*，“HyPoradise：基于大型语言模型的生成式语音识别的开放基准，” 见于 *NeurIPS - 数据集和基准跟踪*，第
    36 卷，2023。'
- en: '[4] S. Radhakrishnan *et al.*, “Whispering LLaMA: A Cross-Modal Generative
    Error Correction Framework for Speech Recognition,” in *Proceedings of Empirical
    Methods in Natural Language Processing*, 2023, pp. 10 007–10 016.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S. Radhakrishnan *等*，“Whispering LLaMA：用于语音识别的跨模态生成错误纠正框架，” 见于 *自然语言处理实证方法会议录*，2023，第
    10 007–10 016 页。'
- en: '[5] Z. Gu, T. Likhomanenko, H. Bai, E. McDermott, R. Collobert, and N. Jaitly,
    “Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition,”
    in *arXiv preprint arXiv:2405.15216*, 2024.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Gu, T. Likhomanenko, H. Bai, E. McDermott, R. Collobert, 和 N. Jaitly,
    “去噪语言模型：推动语音识别错误纠正模型的极限，” 见于 *arXiv 预印本 arXiv:2405.15216*，2024。'
- en: '[6] Y. Hu, C. Chen *et al.*, “Large Language Models are Efficient Learners
    of Noise-Robust Speech Recognition,” in *International Conference on Learning
    Representations*, 2024.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Y. Hu, C. Chen *等*，“大型语言模型是噪声鲁棒语音识别的高效学习者，” 见于 *国际学习表征会议*，2024。'
- en: '[7] C.-H. H. Yang, L. Liu, A. Gandhe, Y. Gu, A. Raju, D. Filimonov, and I. Bulyko,
    “Multi-task language modeling for improving speech recognition of rare words,”
    in *IEEE Automatic Speech Recognition and Understanding Workshop*, 2021, pp. 1087–1093.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] C.-H. H. Yang, L. Liu, A. Gandhe, Y. Gu, A. Raju, D. Filimonov, 和 I. Bulyko,
    “多任务语言建模以提高稀有词汇的语音识别，” 见于 *IEEE 自动语音识别与理解研讨会*，2021，第 1087–1093 页。'
- en: '[8] B. Liu and I. Lane, “Attention-Based Recurrent Neural Network Models for
    Joint Intent Detection and Slot Filling,” *Interspeech*, 2016.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] B. Liu 和 I. Lane, “基于注意力的递归神经网络模型用于联合意图检测和槽填充，” *Interspeech*，2016。'
- en: '[9] R. Ma, M. J. Gales, K. M. Knill, and M. Qian, “N-best T5: Robust ASR Error
    Correction using Multiple Input Hypotheses and Constrained Decoding Space,” *arXiv
    preprint arXiv:2303.00456*, 2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] R. Ma, M. J. Gales, K. M. Knill, 和 M. Qian, “N-best T5：使用多个输入假设和受限解码空间进行鲁棒的
    ASR 错误纠正，” *arXiv 预印本 arXiv:2303.00456*，2023。'
- en: '[10] C.-H. H. Yang, Y. Gu, Y.-C. Liu, S. Ghosh, I. Bulyko, and A. Stolcke,
    “Generative Speech Recognition Error Correction with Large Language Models and
    Task-activating Prompting,” in *IEEE Automatic Speech Recognition and Understanding
    Workshop*, 2023, pp. 1–8.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] C.-H. H. Yang, Y. Gu, Y.-C. Liu, S. Ghosh, I. Bulyko, 和 A. Stolcke, “利用大语言模型和任务激活提示的生成语音识别错误修正”，在
    *IEEE自动语音识别与理解研讨会*，2023年，第1–8页。'
- en: '[11] S. Watanabe, T. Hori, and J. R. Hershey, “Language independent end-to-end
    architecture for joint language identification and speech recognition,” in *2017
    IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)*.   IEEE,
    2017, pp. 265–271.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] S. Watanabe, T. Hori, 和 J. R. Hershey, “用于联合语言识别与语音识别的语言独立端到端架构”，在 *2017
    IEEE自动语音识别与理解研讨会 (ASRU)*。 IEEE，2017年，第265–271页。'
- en: '[12] C.-H. H. Yang, Y.-Y. Tsai, and P.-Y. Chen, “Voice2Series: Reprogramming
    Acoustic Models for Time Series Classification,” in *International conference
    on machine learning*.   PMLR, 2021, pp. 11 808–11 819.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] C.-H. H. Yang, Y.-Y. Tsai, 和 P.-Y. Chen, “Voice2Series：重新编程声学模型进行时间序列分类”，在
    *国际机器学习会议*。 PMLR，2021年，第11,808–11,819页。'
- en: '[13] H. Gao, J. Ni, K. Qian, Y. Zhang, S. Chang, and M. Hasegawa-Johnson, “WAVPROMPT:
    Towards Few-Shot Spoken Language Understanding with Frozen Language Models,” in
    *Interspeech*, 2022, pp. 2738–2742.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] H. Gao, J. Ni, K. Qian, Y. Zhang, S. Chang, 和 M. Hasegawa-Johnson, “WAVPROMPT：利用冻结语言模型实现少量样本的口语理解”，在
    *Interspeech*，2022年，第2738–2742页。'
- en: '[14] K.-W. Chang, Y.-K. Wang, H. Shen, I.-t. Kang, W.-C. Tseng, S.-W. Li, and
    H.-y. Lee, “SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks,” *arXiv
    preprint arXiv:2303.00733*, 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] K.-W. Chang, Y.-K. Wang, H. Shen, I.-t. Kang, W.-C. Tseng, S.-W. Li, 和
    H.-y. Lee, “SpeechPrompt v2：用于语音分类任务的提示调优”，*arXiv预印本arXiv:2303.00733*，2023年。'
- en: '[15] Q. Guo, R. Wang, J. Guo, B. Li *et al.*, “Connecting Large Language Models
    with Evolutionary Algorithms Yields Powerful Prompt Optimizers,” in *International
    Conference on Learning Representations*, 2024.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Q. Guo, R. Wang, J. Guo, B. Li *等*，“将大语言模型与进化算法结合产生强大的提示优化器”，在 *国际表示学习会议*，2024年。'
- en: '[16] OpenAI, “GPT-4 Technical Report,” 2024.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] OpenAI, “GPT-4技术报告”，2024年。'
- en: '[17] Anthropic, “Model Card and Evaluations for Claude Models,” 2023.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Anthropic, “Claude模型的模型卡与评估”，2023年。'
- en: '[18] H. Touvron, T. Lavril *et al.*, “LLaMA: Open and Efficient Foundation
    Language Models,” in *arXiv preprint arXiv:2302.13971*, 2023.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] H. Touvron, T. Lavril *等*，“LLaMA：开放且高效的基础语言模型”，在 *arXiv预印本arXiv:2302.13971*，2023年。'
- en: '[19] J. Barker, R. Marxer, E. Vincent, and S. Watanabe, “The Third ’CHiME’
    Speech Separation and Recognition Challenge: Dataset, Task and Baselines,” in
    *IEEE Workshop on Automatic Speech Recognition and Understanding*, 2015, pp. 504–511.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] J. Barker, R. Marxer, E. Vincent, 和 S. Watanabe, “第三届‘CHiME’语音分离与识别挑战赛：数据集、任务和基准”，在
    *IEEE自动语音识别与理解研讨会*，2015年，第504–511页。'
- en: '[20] E. Vincent, S. Watanabe, A. A. Nugraha, J. Barker, and R. Marxer, “An
    Analysis of Environment, Microphone and Data Simulation Mismatches in Robust Speech
    Recognition,” *Computer Speech and Language*, vol. 46, pp. 535–557, 2017.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] E. Vincent, S. Watanabe, A. A. Nugraha, J. Barker, 和 R. Marxer, “在稳健语音识别中的环境、麦克风和数据模拟不匹配的分析”，*计算机语音与语言*，第46卷，第535–557页，2017年。'
- en: '[21] J. Barker, R. Marxer, E. Vincent, and S. Watanabe, “The Third ‘CHiME’
    Speech Separation and Recognition Challenge: Analysis and Outcomes,” *Computer
    Speech and Language*, vol. 46, pp. 605–626, 2017.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Barker, R. Marxer, E. Vincent, 和 S. Watanabe, “第三届‘CHiME’语音分离与识别挑战赛：分析与结果”，*计算机语音与语言*，第46卷，第605–626页，2017年。'
- en: '[22] D. B. Paul and J. M. Baker, “The Design for the Wall Street Journal-based
    CSR Corpus,” *International Conference on Spoken Language Processing*, pp. 899–902,
    1992.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] D. B. Paul 和 J. M. Baker, “基于《华尔街日报》的CSR语料库设计”，*国际口语语言处理会议*，第899–902页，1992年。'
- en: '[23] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Librispeech: An ASR
    Corpus Based on Public Domain Audio Books,” *IEEE International Conference on
    Acoustics, Speech and Signal Processing*, pp. 5206–5210, 2015.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] V. Panayotov, G. Chen, D. Povey, 和 S. Khudanpur, “Librispeech：基于公共领域有声书的ASR语料库”，*IEEE国际声学、语音与信号处理会议*，第5206–5210页，2015年。'
- en: '[24] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever,
    “Robust Speech Recognition via Large-Scale Weak Supervision,” *Proceedings of
    Machine Learning Research*, vol. 202, pp. 28 492–28 518, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, 和 I. Sutskever,
    “通过大规模弱监督实现稳健的语音识别”，*机器学习研究会议论文集*，第202卷，第28,492–28,518页，2023年。'
- en: '[25] S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li, N. Kanda, T. Yoshioka,
    X. Xiao, J. Wu, L. Zhou, S. Ren, Y. Qian, Y. Qian, J. Wu, M. Zeng, X. Yu, and
    F. Wei, “WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech
    Processing,” in *IEEE Journal on Selected Topics in Signal Processing*, vol. 16,
    no. 6, 2022, pp. 1505–1518.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li, N. Kanda, T.
    Yoshioka, X. Xiao, J. Wu, L. Zhou, S. Ren, Y. Qian, Y. Qian, J. Wu, M. Zeng, X.
    Yu, 和 F. Wei， “WavLM: 大规模自监督预训练用于全栈语音处理”，发表于*IEEE信号处理精选主题期刊*，第16卷，第6期，2022年，页码1505–1518。'
- en: '[26] R. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler, J. Meyer, R. Morais,
    L. Saunders, F. M. Tyers, and G. Weber, “Common Voice: A Massively-Multilingual
    Speech Corpus,” in *International Conference on Language Resources and Evaluation*,
    2020, pp. 4218–4222.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] R. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler, J. Meyer, R.
    Morais, L. Saunders, F. M. Tyers, 和 G. Weber， “Common Voice: 一个大规模多语言语音语料库”，发表于*国际语言资源与评估会议*，2020年，页码4218–4222。'
- en: '[27] S. Min, X. Lyu, A. Holtzman, M. Artetxe, M. Lewis, H. Hajishirzi, and
    L. Zettlemoyer, “Rethinking the Role of Demonstrations: What Makes In-Context
    Learning Work?” in *Proceedings of Empirical Methods in Natural Language Processing*,
    2022, pp. 11 048–11 064.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] S. Min, X. Lyu, A. Holtzman, M. Artetxe, M. Lewis, H. Hajishirzi, 和 L.
    Zettlemoyer， “重新审视示范的作用：什么使得上下文学习有效？”发表于*自然语言处理实证方法会议论文集*，2022年，页码11 048–11 064。'
