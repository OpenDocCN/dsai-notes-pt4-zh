- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:45:33'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:45:33'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students’ Formative
    Assessment Responses in Science
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种基于链式思维提示的大型语言模型（LLM）在科学中评估学生形成性评估反应的方法
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.14565](https://ar5iv.labs.arxiv.org/html/2403.14565)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.14565](https://ar5iv.labs.arxiv.org/html/2403.14565)
- en: Clayton Cohn¹, Nicole Hutchins¹, Tuan Le², Gautam Biswas¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Clayton Cohn¹, Nicole Hutchins¹, Tuan Le², Gautam Biswas¹
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: This paper explores the use of large language models (LLMs) to score and explain
    short-answer assessments in K-12 science. While existing methods can score more
    structured math and computer science assessments, they often do not provide explanations
    for the scores. Our study focuses on employing GPT-4 for automated assessment
    in middle school Earth Science, combining few-shot and active learning with chain-of-thought
    reasoning. Using a human-in-the-loop approach, we successfully score and provide
    meaningful explanations for formative assessment responses. A systematic analysis
    of our method’s pros and cons sheds light on the potential for human-in-the-loop
    techniques to enhance automated grading for open-ended science assessments.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了使用大型语言模型（LLMs）来评分和解释K-12科学中的短答案评估。尽管现有方法可以对更结构化的数学和计算机科学评估进行评分，但通常不会提供评分解释。我们的研究专注于使用GPT-4进行中学地球科学的自动化评估，将少样本学习和主动学习与链式思维推理相结合。通过人机结合的方法，我们成功地对形成性评估反应进行了评分并提供了有意义的解释。对我们方法的优缺点进行系统分析，揭示了人机结合技术在增强开放式科学评估的自动评分潜力。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Improvements in Science, Technology, Engineering, and Mathematics (STEM) education
    have accelerated the shift from teaching and assessing facts to developing students’
    conceptual understanding and problem-solving skills (NGSS [2013](#bib.bib28)).
    To foster students’ developing scientific ideas and reasoning skills, it is crucial
    to have assessments that reveal and support their progress (Harris et al. [2023](#bib.bib14)).
    Formative assessments play an important role in this endeavor, providing timely
    feedback and guidance when students face difficulties, which helps them to develop
    self-evaluation skills (Bloom, Madaus, and Hastings [1971](#bib.bib2)). However,
    the process of grading and generating personalized feedback from frequent formative
    assessments is time-consuming for teachers and susceptible to errors (Rodrigues
    and Oliveira [2014](#bib.bib31); Haudek et al. [2011](#bib.bib16)).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: STEM（科学、技术、工程和数学）教育的改进加速了从教学和评估事实到培养学生概念理解和问题解决能力的转变（NGSS [2013](#bib.bib28)）。为了促进学生科学思想和推理技能的发展，至关重要的是要有能够揭示和支持他们进步的评估（Harris
    et al. [2023](#bib.bib14)）。形成性评估在这一过程中扮演了重要角色，提供及时的反馈和指导，帮助学生在遇到困难时发展自我评价技能（Bloom,
    Madaus, and Hastings [1971](#bib.bib2)）。然而，从频繁的形成性评估中生成个性化反馈的过程对于教师来说既费时又容易出错（Rodrigues
    and Oliveira [2014](#bib.bib31); Haudek et al. [2011](#bib.bib16)）。
- en: Large Language Models (LLMs) provide opportunities for automating short answer
    scoring (Funayama et al. [2023](#bib.bib13)) and providing feedback to help students
    overcome their difficulties (Morris et al. [2023](#bib.bib26)). These approaches
    can also aid teachers in identifying students’ difficulties and generating actionable
    information to support student learning. To our knowledge, there is very little
    research that combines automated formative assessment grading and feedback generation
    for science domains where understanding, reasoning, and explaining are key to
    gaining a deep understanding of scientific phenomena (Mao et al. [2018](#bib.bib21)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）为自动化短答案评分提供了机会（Funayama et al. [2023](#bib.bib13)）并提供反馈以帮助学生克服困难（Morris
    et al. [2023](#bib.bib26)）。这些方法还可以帮助教师识别学生的困难并生成可操作的信息以支持学生学习。据我们了解，目前几乎没有将自动化形成性评估评分和反馈生成结合起来用于科学领域的研究，而在这些领域中，理解、推理和解释是深入了解科学现象的关键（Mao
    et al. [2018](#bib.bib21)）。
- en: This paper develops an approach for human-in-the-loop LLM prompt engineering
    using in-context learning and chain-of-thought reasoning with GPT-4 to support
    automated analysis and feedback generation for formative assessments in a middle
    school Earth Science curriculum. We present our approach, discuss our results,
    evaluate the limitations of our work, and then propose future research in this
    area of critical need in K-12 STEM instruction.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文开发了一种用于人机互动的LLM提示工程方法，利用GPT-4的上下文学习和链式思维推理来支持中学地球科学课程中的形成性评估的自动分析和反馈生成。我们介绍了我们的方法，讨论了我们的结果，评估了我们工作的局限性，并提出了在K-12
    STEM教学中这一关键领域的未来研究方向。
- en: Background
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背景
- en: 'To understand the difficulties students face when learning science, teachers
    need to actively track students’ developing knowledge (Wiley et al. [2020](#bib.bib39)).
    This is particularly important for open-ended, technology-enhanced learning environments
    that support students in their knowledge construction and problem-solving processes
    (Hutchins and Biswas [2023](#bib.bib17)). In these environments, knowledge and
    skill development happen through system interactions that are difficult to monitor
    and interpret (Walkoe, Wilkerson, and Elby [2017](#bib.bib36)). Formative assessments,
    evaluation, and feedback mechanisms aligned with target learning goals (Bloom,
    Madaus, and Hastings [1971](#bib.bib2)), can play a dual role: (1) help students
    recognize constructs that are important to learning, and (2) provide teachers
    with a deeper understanding of student knowledge and reasoning to better support
    their developing STEM ideas (Cizek and Lim [2023](#bib.bib6)). However, grading
    formative assessments, particularly in K-12 STEM contexts, where students’ responses
    may not be well-structured and may vary considerably in vocabulary and stylistic
    expression, is time-consuming and can result in erroneous scoring and incomplete
    feedback (Liu et al. [2016](#bib.bib20)). Moreover, grading these assessments
    at frequent intervals may become a burden rather than an aid to teachers. Very
    little research has examined effective mechanisms for generating automated grading
    and useful formative feedback for K-12 students that are aligned with classroom
    learning goals.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解学生在学习科学过程中面临的困难，教师需要积极跟踪学生的知识发展（Wiley et al. [2020](#bib.bib39)）。这对于开放式的、技术增强的学习环境尤为重要，这些环境支持学生在知识构建和问题解决过程中（Hutchins
    and Biswas [2023](#bib.bib17)）。在这些环境中，知识和技能的发展通过系统互动发生，这些互动难以监控和解释（Walkoe, Wilkerson,
    and Elby [2017](#bib.bib36)）。与目标学习目标对齐的形成性评估、评价和反馈机制（Bloom, Madaus, and Hastings
    [1971](#bib.bib2)）可以发挥双重作用：（1）帮助学生识别对学习重要的构建知识，和（2）为教师提供对学生知识和推理的更深刻理解，以更好地支持他们的发展中的STEM观点（Cizek
    and Lim [2023](#bib.bib6)）。然而，评估形成性评估，尤其是在K-12 STEM环境中，学生的回应可能不够结构化，且在词汇和风格表达上可能差异很大，这既耗时，又可能导致评分错误和反馈不完整（Liu
    et al. [2016](#bib.bib20)）。此外，频繁地评估这些评估可能成为对教师的负担，而不是帮助。很少有研究考察了为K-12学生生成与课堂学习目标对齐的自动评分和有用形成性反馈的有效机制。
- en: Advances in natural language processing (NLP) have produced improved automated
    assessment scoring approaches to support teaching and learning (e.g., Adair et al.
    [2023](#bib.bib1); Wilson et al. [2021](#bib.bib40)). Proposed methodologies include
    data augmentation (Cochran, Cohn, and Hastings [2023](#bib.bib7)), next sentence
    prediction (Wu et al. [2023](#bib.bib41)), prototypical neural networks (Zeng
    et al. [2023](#bib.bib42)), cross-prompt fine-tuning (Funayama et al. [2023](#bib.bib13)),
    human-in-the-loop scoring via sampling responses (Singla et al. [2022](#bib.bib33)),
    and reinforcement learning (Liu et al. [2022](#bib.bib19)). While these methods
    have enjoyed varying degrees of success, a majority of these applications have
    targeted more structured mathematics and computer science tasks (i.e., tasks that
    can be solved formulaically), but their grading is different from scoring free-form
    short-answer responses by middle school students in science domains. Data impoverishment
    concerns are common to educational data sets and a key consideration in applying
    these approaches to science assessments (Cochran et al. [2023](#bib.bib9)). The
    data needed for training our models is small, imbalanced, and non-canonical in
    terms of syntax and semantics, all of which may impact model performance (Cohn
    [2020](#bib.bib12)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）的进步带来了改进的自动评估评分方法，以支持教学和学习（例如，Adair et al. [2023](#bib.bib1); Wilson
    et al. [2021](#bib.bib40)）。提出的方法包括数据增强（Cochran, Cohn, and Hastings [2023](#bib.bib7)）、下一句预测（Wu
    et al. [2023](#bib.bib41)）、原型神经网络（Zeng et al. [2023](#bib.bib42)）、跨提示微调（Funayama
    et al. [2023](#bib.bib13)）、通过采样回应的人机协作评分（Singla et al. [2022](#bib.bib33)）以及强化学习（Liu
    et al. [2022](#bib.bib19)）。尽管这些方法取得了不同程度的成功，但大多数应用都针对更结构化的数学和计算机科学任务（即可以用公式解决的任务），它们的评分方式与评分中学生在科学领域的自由形式短答案有所不同。数据贫乏问题在教育数据集中很常见，并且是将这些方法应用于科学评估时的关键考虑因素（Cochran
    et al. [2023](#bib.bib9)）。我们训练模型所需的数据量小、不平衡且在语法和语义方面不规范，这些都可能影响模型性能（Cohn [2020](#bib.bib12)）。
- en: 'This research tackles several critical issues, namely: (1) grading open-ended,
    short-answer questions focused on science conceptual knowledge and reasoning,
    (2) utilizing LLMs to generate explanations aligned with specified learning objectives
    for both students and teachers and (3) addressing concerns related to data impoverishment.
    We hypothesize that our approach supports automated scoring and explanation that
    (1) aligns with learning objectives and standards, (2) provides actionable insight
    to students, especially in addressing their difficulties, and (3) engages teachers
    in the scoring and explanation generation process to resolve discrepancies and
    support the learning goals.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究解决了几个关键问题，即：（1）对科学概念知识和推理的开放式短答案问题进行评分，（2）利用LLM生成与指定学习目标对齐的解释，供学生和教师使用，（3）解决数据贫乏相关的问题。我们假设我们的方法支持自动评分和解释，这些（1）与学习目标和标准对齐，（2）为学生提供可操作的见解，特别是在解决他们的困难方面，（3）让教师参与评分和解释生成过程，以解决分歧并支持学习目标。
- en: Methods
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法
- en: This section presents our curricular context, study design, dataset, LLM, and
    the details of our approach. Additional information regarding the formative assessment
    questions, rubrics, prompts, and method application can be found in the GitHub
    repository¹¹1https://github.com/oele-isis-vanderbilt/EAAI24 along with test code
    and sample data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了我们的课程背景、研究设计、数据集、LLM 和我们方法的详细信息。有关形成性评估问题、评分标准、提示和方法应用的更多信息可以在 GitHub 存储库中找到¹¹1https://github.com/oele-isis-vanderbilt/EAAI24，里面还有测试代码和示例数据。
- en: Curricular context
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 课程背景
- en: This paper evaluates formative assessments conducted in the context of Science
    Projects Integrating Computing and Engineering (SPICE), an NGSS-aligned middle
    school earth sciences water runoff curriculum. Spanning three weeks, the curriculum
    tasks students with redesigning their schoolyard to enhance functionalities, using
    surface materials that minimize water runoff post-storm within specified cost
    and accessibility constraints (Chiu et al. [2019](#bib.bib5)). We focus on formative
    assessments that are primarily linked to the conceptual understanding of water
    runoff and the conservation of matter principle (Hutchins et al. [2021](#bib.bib18)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本文评估了在科学项目整合计算与工程（SPICE）背景下进行的形成性评估，SPICE是一个与NGSS对齐的中学地球科学水流失课程。课程跨度为三周，要求学生重新设计他们的校园，以提高功能性，使用能够在特定成本和可达性限制下最小化暴风雨后水流失的表面材料（Chiu
    et al. [2019](#bib.bib5)）。我们关注的是与水流失和物质守恒原理的概念理解主要相关的形成性评估（Hutchins et al. [2021](#bib.bib18)）。
- en: Study Design and Dataset
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 研究设计与数据集
- en: This study utilized assessment data from two Vanderbilt University-approved
    SPICE studies involving 270 students at a Southeastern U.S. public middle school.
    Data was removed for non-consenting participants and some data was missing because
    of absences and incomplete submissions. We used evidence-centered design (ECD)
    (Mislevy and Haertel [2006](#bib.bib24)) to align the assessments with the learning
    objectives of the SPICE curriculum.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究利用了来自两项由范德比尔特大学批准的SPICE研究的评估数据，涉及到270名位于美国东南部的公立中学的学生。因未同意参与的学生数据被剔除，同时由于缺席和提交不完整的情况也有部分数据缺失。我们使用了基于证据的设计（ECD）（Mislevy
    and Haertel [2006](#bib.bib24)）来使评估与SPICE课程的学习目标对齐。
- en: For this paper, we selected three questions that required students to analyze
    a pictorial model of water runoff (illustrated in Figure [1](#Sx3.F1 "Figure 1
    ‣ Study Design and Dataset ‣ Methods ‣ A Chain-of-Thought Prompting Approach with
    LLMs for Evaluating Students’ Formative Assessment Responses in Science")) and
    apply their conceptual knowledge and scientific reasoning to evaluate and explain
    the correct and incorrect components of the model. Each question was scored for
    at least one conceptual knowledge item, i.e., a correct application of a scientific
    fact. For example, in Q3, students had to identify that the arrow size representing
    total absorption was incorrect. Q2 and Q3 also required scoring students’ scientific
    reasoning, i.e., the use of scientific principles to explain an answer. For Q3,
    students could invoke the conservation principle to explain that the absorption
    arrow could not be larger than the rainfall arrow. The rubric assigned 1 point
    (conceptual) for Q1\. Q2 and Q3 were scored for 4 points (2 items, 1 conceptual
    and 1 reasoning point for each item). For Q3, there were exactly 2 errors in the
    model. For Q2, students could choose from more than two correct phenomena, which
    resulted in differences in the grading results that we discuss later.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本文，我们选择了三个问题，要求学生分析一个水流失的图示模型（见图[1](#Sx3.F1 "图 1 ‣ 研究设计与数据集 ‣ 方法 ‣ 使用LLMs评估学生形成性评估回应的思维链提示方法")），并运用他们的概念知识和科学推理来评估和解释模型中的正确与错误成分。每个问题都根据至少一个概念知识点进行评分，即科学事实的正确应用。例如，在Q3中，学生必须识别出表示总吸收的箭头尺寸不正确。Q2和Q3还要求对学生的科学推理进行评分，即运用科学原理解释答案。对于Q3，学生可以调用物质守恒原理来解释吸收箭头不能比降雨箭头更大。评分标准为Q1分配1分（概念）。Q2和Q3的评分为4分（每个项目2项，每项1个概念点和1个推理点）。对于Q3，模型中确切有2处错误。对于Q2，学生可以选择多个正确现象，这导致了后续讨论中的评分结果差异。
- en: '![Refer to caption](img/55bcf651874e6d7ee51c6630b8ffa246.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/55bcf651874e6d7ee51c6630b8ffa246.png)'
- en: 'Figure 1: The fictitious student’s conceptual model used by students to answers
    the assessment questions.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：学生用来回答评估问题的虚构学生概念模型。
- en: Model
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型
- en: Ever since OpenAI released ChatGPT²²2https://openai.com/blog/chatgpt (a chatbot
    driven by the foundation model GPT-3.5) in November 2022, LLMs have received a
    tremendous amount of attention. Their ability to compose paper outlines, expository
    essays, and screenplays, has made the use of ChatGPT ubiquitous across academia,
    business, and news media. In March 2023, OpenAI released GPT-4³³3https://openai.com/research/gpt-4
    (OpenAI [2023](#bib.bib29)), which is largely considered the current state-of-the-art
    for LLMs (OpenAI [2023](#bib.bib29); Zhao et al. [2023](#bib.bib43)). For this
    reason, we chose to use GPT-4 as the LLM to develop and evaluate our approach.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 自从OpenAI在2022年11月发布了ChatGPT²²2https://openai.com/blog/chatgpt（一个由基础模型GPT-3.5驱动的聊天机器人）以来，大型语言模型（LLMs）受到了极大的关注。它们能够撰写论文大纲、说明文和剧本，使得ChatGPT在学术界、商业界和新闻媒体中无处不在。2023年3月，OpenAI发布了GPT-4³³3https://openai.com/research/gpt-4（OpenAI
    [2023](#bib.bib29)），它被广泛认为是当前最先进的LLM（OpenAI [2023](#bib.bib29)；赵等 [2023](#bib.bib43)）。因此，我们选择使用GPT-4作为LLM来开发和评估我们的方法。
- en: Approach
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 方法
- en: Brown et al. ([2020](#bib.bib3)) demonstrated that LLMs could “learn” from a
    few labeled instances in the prompt via in-context learning (ICL). Unlike fine-tuning,
    which requires expensive parameter updates and may result in decreased performance
    for previously known tasks (Mosbach, Andriushchenko, and Klakow [2020](#bib.bib27)),
    ICL uses the labeled instances in the prompt to generate text during inference
    that bypasses traditional training. This means that by simply changing the prompts,
    the same language model can be used across domains, tasks, and datasets without
    the need to modify the network’s parameters. Wei et al. ([2022](#bib.bib37)) extended
    this work by providing chain-of-thought (CoT) reasoning in the labeled instances.
    In contrast to a traditional ICL instance that only offers a question and its
    corresponding answer, CoT provides a reasoning chain with the answer. This helps
    the model generate correct inferences, and this reasoning is included in the model’s
    response along with the answer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Brown等人（[2020](#bib.bib3)）证明了LLMs可以通过上下文学习（ICL）从几个标记实例中“学习”。与需要昂贵参数更新且可能导致已知任务性能下降的微调不同（Mosbach,
    Andriushchenko, 和Klakow [2020](#bib.bib27)），ICL利用提示中的标记实例在推理过程中生成文本，从而绕过传统训练。这意味着，通过简单地更改提示，相同的语言模型可以在不同领域、任务和数据集之间使用，而无需修改网络的参数。Wei等人（[2022](#bib.bib37)）通过在标记实例中提供链式思维（CoT）推理扩展了这项工作。与仅提供问题及其对应答案的传统ICL实例不同，CoT提供了一个带有答案的推理链。这帮助模型生成正确的推论，并且这种推理与答案一起包含在模型的回应中。
- en: Eliciting reasoning is particularly useful for formative assessment scoring
    in science, where the open-ended nature of the questions can make scoring alignment
    difficult even between humans. Rather than generating a score only, CoT prompting
    elicits an explanation for the LLM’s response, enabling teachers to offer informed
    feedback to students. Alternatively, teachers can refine the rubric to improve
    grading for subsequent assessments. The model’s reasoning can also be used to
    identify specific causes of misalignment between the model and the teacher, which
    can then be leveraged to improve model output.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 诱发推理对于科学中的形成性评估评分尤其有用，因为问题的开放性特征甚至在人与人之间也可能使得评分对齐变得困难。与仅生成分数不同，CoT提示会引导LLM解释其回应，从而使教师能够为学生提供有根据的反馈。或者，教师可以调整评分标准以改善后续评估的评分。模型的推理还可以用来识别模型与教师之间对齐不一致的具体原因，然后利用这些信息改进模型输出。
- en: Active learning (Tan et al. [2023](#bib.bib34); Ren et al. [2021](#bib.bib30))
    takes a human-in-the-loop approach to improving model training, where the human
    as an “oracle” is consulted to label additional instances for inclusion in the
    next training iteration. By integrating CoT reasoning and active learning, educators
    or researchers can scrutinize instances with incorrect predictions to identify
    recurring patterns leading to the model’s errors across multiple instances. These
    patterns can be reintroduced into the prompt using CoT reasoning to rectify discrepancies
    between the model’s assessment and the human scorer. Moreover, combining CoT with
    active learning assists teachers and researchers in rectifying human errors in
    the initial scoring. This is particularly relevant when the humans confirm that
    the model’s scoring predictions are accurate.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习 (Tan et al. [2023](#bib.bib34); Ren et al. [2021](#bib.bib30)) 采用了人机协作的方法来改进模型训练，其中人作为“神谕者”被咨询以标记额外实例，以便纳入下一次训练迭代。通过整合
    CoT 推理和主动学习，教育工作者或研究人员可以检查具有错误预测的实例，以识别导致模型在多个实例中错误的重复模式。这些模式可以通过 CoT 推理重新引入提示中，以纠正模型评估与人工评分者之间的差异。此外，将
    CoT 与主动学习相结合有助于教师和研究人员纠正初始评分中的人为错误。这在人工确认模型评分预测准确时尤其相关。
- en: We employ the inter-rater reliability (IRR) process to pinpoint scoring disagreements
    that may challenge the model, addressing them through CoT prompting. Active learning
    is then utilized to identify recurrent issues in the model’s alignment with the
    human scorers, and instances embodying these patterns are incorporated into the
    prompt with reasoning chains to correct the alignment. Once active learning concludes,
    the model is deployed for scoring new formative assessment responses through inference,
    accompanied by CoT reasoning to generate student feedback, and when needed, refining
    rubrics and formative assessment questions. Figure [2](#Sx3.F2 "Figure 2 ‣ Approach
    ‣ Methods ‣ A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students’
    Formative Assessment Responses in Science") provides a comprehensive overview
    of our approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用互评分可靠性（IRR）过程来准确找出可能挑战模型的评分分歧，并通过 CoT 提示进行处理。然后，采用主动学习来识别模型与人工评分者对齐的重复问题，并将体现这些模式的实例纳入提示中，通过推理链来纠正对齐问题。一旦主动学习结束，模型将被用于通过推理对新的形成性评估响应进行评分，并伴随
    CoT 推理生成学生反馈，并在需要时，修订评分标准和形成性评估问题。图 [2](#Sx3.F2 "图 2 ‣ 方法 ‣ 方法 ‣ 基于 LLMs 的链式思维提示方法用于评估学生的科学形成性评估响应")
    提供了我们方法的全面概述。
- en: '![Refer to caption](img/97d85b866a5e9ef8b12220028678ad07.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/97d85b866a5e9ef8b12220028678ad07.png)'
- en: 'Figure 2: Our Chain-of-Thought Prompting + Active Learning approach. The green
    box encapsulates this process, where each of the blue diamonds is a step in that
    process. Yellow boxes represent the process’s application to the classroom.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们的链式思维提示 + 主动学习方法。绿色框包含了这一过程，其中每一个蓝色菱形是该过程中的一个步骤。黄色框代表该过程在课堂中的应用。
- en: Response Scoring.
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 响应评分。
- en: Two of this paper’s authors independently scored a randomly chosen 20% of the
    student responses for each of the three formative assessment questions using the
    rubric. Next, while conducting IRR, instances where the humans both agreed and
    disagreed on students’ scores were collected and included in the initial prompt.
    Particular attention was paid to the misalignments between the graders that caused
    multiple instances to be scored differently before consensus was reached. To achieve
    consensus, the two reviewers discussed each scoring disagreement until they reached
    a consensus on how that particular instance should be scored. The agreed-upon
    instances acted as “ground truth” exemplars for the model to initially align itself
    with the human scorers. The instances where there were disagreements were used
    to pinpoint specific reasons for misalignment between the human scorers during
    IRR. We expected that the model might encounter the same misalignments during
    its scoring. This process was repeated for each of the three questions until Cohen’s
    $$k> was achieved across all subscores for each question, after which one
    of this paper’s authors scored the full set of student responses. For this work,
    all students’ responses were manually graded to ensure accuracy while evaluating
    our method. Disagreements were resolved manually by the humans to form a consensus
    (described above). This consensus was used to align the LLM responses via CoT
    reasoning. In future work, as we collect more data, we will use the LLM to automatically
    score students’ responses and evaluate samples of the LLM’s generations to ensure
    accuracy. Furthermore, we refrained from updating the rubric during Active Learning;
    however, we intend to investigate this aspect in future research.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的两位作者独立地使用评分标准对每三个形成性评估问题中随机选择的20%的学生回答进行评分。接下来，在进行IRR时，收集并纳入了人类对学生评分既一致又不一致的实例。在达成共识之前，对评分者之间导致多个实例评分不同的偏差给予了特别关注。为了达成共识，两名审阅者讨论了每一个评分分歧，直到他们就如何评分达成一致。达成一致的实例作为模型最初与人类评分者对齐的“真实标准”示例。存在分歧的实例被用来确定IRR过程中人类评分者之间偏差的具体原因。我们预期模型在评分过程中可能会遇到相同的偏差。该过程对三个问题中的每一个重复进行，直到所有子评分的Cohen’s
    $$k$$ 达到标准为止，此后论文的一位作者对所有学生回答进行了评分。为了确保准确性，所有学生的回答都进行了人工评分以评估我们的方法。分歧由人类手动解决以形成共识（如上所述）。这一共识用于通过CoT推理对齐LLM的回答。在未来的工作中，随着我们收集更多数据，我们将使用LLM自动评分学生回答并评估LLM生成样本的准确性。此外，我们在主动学习期间避免更新评分标准；然而，我们打算在未来的研究中调查这一方面。
- en: Before developing the initial prompt, we partitioned the dataset into training
    (80%) and testing (20%) instances for the three sets of formative assessment responses.
    The training set played a dual role in prompt development. Initially, few-shot
    examples were selected to construct the prompt, while the instances not utilized
    for few-shot learning served as a validation set for refining the prompt during
    active learning. Due to token limitations and the time cost for instance labeling,
    only a limited number of labeled instances were included in the prompt. As discussed
    in later sections, an excessive number of instances in the prompt can lead to
    overfitting. Furthermore, it is important that the validation set during active
    learning is sufficiently large to ensure accurate identification of scoring trends.
    In this paper, the validation-to-training set ratio was $\approx$43:1.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发初始提示之前，我们将数据集划分为三个形成性评估回答的训练集（80%）和测试集（20%）。训练集在提示开发中发挥了双重作用。最初，选择了少量示例来构建提示，而未用于少量学习的实例则作为验证集，用于在主动学习期间细化提示。由于标记实例的令牌限制和时间成本，提示中仅包含有限数量的标记实例。如后文所述，提示中实例数量过多可能导致过拟合。此外，主动学习期间验证集的重要性在于其足够大，以确保准确识别评分趋势。在本文中，验证集与训练集的比例约为43:1。
- en: Prompt Development.
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示开发。
- en: For prompting, we opted for the persona pattern (White et al. [2023](#bib.bib38)),
    where the model was instructed to adopt the persona of a middle school teacher
    evaluating students’ formative assessment question responses. The prompt also
    provided the model with the formative assessment question and rubric, and the
    model was instructed to use the rubric to score students’ responses. The rubric
    also provided the model with the format to output its responses to improve readability
    and allow for programmatic parsing of the model’s generations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示方面，我们选择了角色模式（White et al. [2023](#bib.bib38)），其中模型被指示采用中学教师评估学生形成性评估问题回答的角色。提示还向模型提供了形成性评估问题和评分标准，并指示模型使用评分标准对学生的回答进行评分。评分标准还向模型提供了输出回应的格式，以提高可读性并允许对模型生成内容进行程序化解析。
- en: 'Next, we incorporated ground truth examples into the prompt, complemented by
    CoT reasoning clarifying the reasons for awarding or not awarding points for each
    subscore. Following this, a comparable CoT input was included for instances where
    human scorers diverged in their assessments. This aimed at aligning the model
    with the IRR consensus, particularly when instances posed challenges similar to
    those faced by human reviewers in achieving consensus. For all labeled instances
    in the prompt, we used the following CoT reasoning template: evidence in the student’s
    response + reference to the rubric + score. We used quotations from the student’s
    response as evidence, tying it back to the rubric, and providing a score and explanation
    to the model; e.g., “The student says X. The rubric states Y. Based on the rubric,
    the student earned a score of Z.” This approach mirrored the original CoT publication
    (Wei et al. [2022](#bib.bib37)), where algebraic word problems were broken down
    step-by-step to help the model arrive at the correct solution.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将真实示例纳入提示中，并配以CoT推理，阐明给予或不给予每个子评分分数的理由。随后，为了对齐模型与IRR共识，特别是在实例面临与人类评审者达成共识类似的挑战时，添加了类似的CoT输入。对于提示中的所有标记实例，我们使用了以下CoT推理模板：学生回应中的证据
    + 参考评分标准 + 分数。我们使用了学生回应中的引用作为证据，将其与评分标准联系起来，并向模型提供了分数和解释；例如，“学生说X。评分标准中指出Y。根据评分标准，学生得到了Z分。”这一方法模仿了原始的CoT出版物（Wei
    et al. [2022](#bib.bib37)），其中代数应用题被逐步拆解，以帮助模型得出正确的解决方案。
- en: Additional labeled instances were added to the prompt as needed to balance the
    individual subscores. However, this was constrained by the small and imbalanced
    nature of our dataset. While investigating the effect that data balance has on
    the LLM’s performance is outside the scope of this work, in previous work (using
    a subset of the dataset used in this paper), we demonstrated that data balancing
    often improved language model performance (Cochran et al. [2022](#bib.bib8)).
    For Q2 and Q3, balancing across 4 subscores was difficult, as adding one more
    instance to augment one subscore inherently affected the balance across the other
    subscores. Sometimes, achieving a perfect balance was not possible in the training
    set, but we included at least one positive and one negative instance across all
    subscores for each question’s prompt.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需要，额外的标记实例被添加到提示中，以平衡各个子评分。然而，这受限于我们数据集的规模和不平衡性。尽管调查数据平衡对LLM性能的影响超出了本工作的范围，但在之前的工作中（使用了本文数据集的一个子集），我们展示了数据平衡通常改善了语言模型的性能（Cochran
    et al. [2022](#bib.bib8)）。对于Q2和Q3，平衡4个子评分非常困难，因为增加一个实例来增强一个子评分会固有地影响其他子评分的平衡。有时，在训练集中实现完美平衡是不可能的，但我们在每个问题的提示中至少包括了一个正面和一个负面实例。
- en: Active Learning.
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 主动学习。
- en: Validation set instances were fed through the model with the initial prompt
    and few-shot examples, and a researcher performed error analysis to discern patterns
    in the incorrect LLM generations. Specifically, we noted the reason for each incorrect
    scoring prediction and the faulty reasoning chains that caused the model to mislabel
    several instances. These reasoning chains were chosen as additional examples to
    add to the prompt, and CoT was used to correct the model’s reasoning errors. Candidate
    instances were prioritized for prompt inclusion based on the degree to which their
    reasoning errors caused other inaccurate model predictions, which resulted in
    correcting several wrongly scored instances.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集实例通过模型进行初始提示和少量示例的处理，研究人员进行了错误分析，以识别不正确的LLM生成中的模式。具体而言，我们记录了每个错误评分预测的原因以及导致模型错误标记多个实例的错误推理链。这些推理链被选择作为附加示例添加到提示中，并使用CoT纠正模型的推理错误。候选实例被优先考虑纳入提示，依据是它们的推理错误对其他不准确的模型预测造成了多大影响，这导致纠正了若干错误评分的实例。
- en: There were only a few incorrectly predicted scores in the validation set for
    Q1, so all of those instances were added to the prompt during Active Learning.
    For Q2 and Q3, the researcher identified the $n$ was defined as the minimum number
    of instances in the validation set that simultaneously addressed all of the LLM’s
    reasoning errors and maintained data balance. This caused some overfitting, so
    we will experiment with 1-shot active learning to help mitigate this in future
    work. For all instances added to the prompt during Active Learning, we used CoT
    to correct the model’s faulty reasoning chains. We also rebalanced the few-shot
    instances across subscores during Active Learning to maintain data balance. In
    previous work, we showed that balancing training data to create a uniform label
    distribution can improve performance (Cochran et al. [2022](#bib.bib8)). Other
    works have suggested balancing to achieve the true distribution of the dataset’s
    labels (Min et al. [2022](#bib.bib23)).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Q1，验证集中只有少数几个错误预测评分，因此在主动学习期间，这些实例都被添加到了提示中。对于Q2和Q3，研究人员确定了$n$，即定义为验证集中同时解决所有LLM推理错误并保持数据平衡的最小实例数量。这导致了一些过拟合，因此我们将尝试1-shot主动学习以帮助在未来的工作中减轻这个问题。对于在主动学习期间添加到提示中的所有实例，我们使用了CoT来纠正模型的错误推理链。我们还在主动学习期间重新平衡了少量示例，以保持数据平衡。在之前的工作中，我们展示了平衡训练数据以创建均匀标签分布可以提高性能（Cochran等
    [2022](#bib.bib8)）。其他工作建议平衡数据以实现数据集标签的真实分布（Min等 [2022](#bib.bib23)）。
- en: 'In general, active learning can be performed until one of several stopping
    conditions is triggered: (1) the model achieves convergence, i.e., it no longer
    produces any incorrect validation scores; (2) the model predicts more validation
    scores incorrectly than in previous iterations, i.e., it overfits; and (3) there
    are not enough instances remaining in the validation set to achieve acceptable
    data balance in the prompt.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，主动学习可以持续进行，直到触发以下几种停止条件之一：(1) 模型达到收敛，即不再产生任何不正确的验证评分；(2) 模型在预测验证评分时错误的次数比以前的迭代更多，即出现过拟合；(3)
    验证集中的剩余实例不足以在提示中实现可接受的数据平衡。
- en: To test our method, we performed one iteration of active learning for each of
    the three formative assessment questions. For each subscore of a formative assessment
    question, we first identified scoring error trends, i.e., are model scoring errors
    mainly caused by false negatives (underscoring) or false positives (overscoring)?
    This alerted us to the “direction” in which we needed to guide the model to better
    align with the human scorers. We then examined the content of the incorrect validation
    set generations to identify common causes of incorrect scoring. We chose the most
    frequently occurring model reasoning error (i.e., the error that caused the model
    to wrongly predict the greatest number of validation set instances), and picked
    one of these instances to insert back into the prompt.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的方法，我们对每个三项形成性评估问题进行了一个主动学习迭代。对于每个形成性评估问题的子评分，我们首先识别了评分错误的趋势，即模型评分错误主要是由假阴性（低估）还是假阳性（高估）引起的？这使我们意识到需要引导模型的“方向”，以更好地与人工评分者对齐。然后，我们检查了不正确验证集生成的内容，以识别错误评分的常见原因。我们选择了最频繁出现的模型推理错误（即导致模型错误预测最多验证集实例的错误），并从这些实例中选择一个重新插入提示中。
- en: For example, with the Runoff Arrow Direction subscore in Q3, we found that the
    ratio of the model’s false positive to false negative predictions was 5:2\. Additionally,
    we found that the cause of more than half of the false positives was due to the
    model awarding students a point for mentioning that the arrows in the diagram
    needed to change direction. This was incorrect because only the runoff arrow needed
    to change direction. To correct the model’s reasoning error, we chose one of the
    incorrect validation instances that included this reasoning error, inserted it
    into the prompt, and used CoT reasoning to help correct the model’s reasoning
    error going forward.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在Q3的径流箭头方向子分数中，我们发现模型的假阳性与假阴性的预测比例为5:2。此外，我们发现超过一半的假阳性的原因是模型因提到图中的箭头需要改变方向而给学生加分。这是不正确的，因为只有径流箭头需要改变方向。为了纠正模型的推理错误，我们选择了一个包含这一推理错误的不正确验证实例，将其插入到提示中，并使用链式思维推理来帮助纠正模型未来的推理错误。
- en: Results
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: 'We evaluated our method by comparing our model performance to the held-out
    test set across 4 implementations: three incremental baselines, and our Chain-of-Thought
    Prompting + Active Learning approach. We started with a Zero-Shot baseline, where
    the rubric is included in the prompt, but no labeled examples were present. We
    then used a Few-Shot baseline, where we provided the model with labeled instances
    in the prompt, but the labeled instances only consisted of numerical scores (i.e.,
    no CoT reasoning). Our third and final baseline, Few-Shot, CoT, added CoT reasoning
    to the few-shot instances. Last, we employed our Chain-of-Thought Prompting +
    Active Learning approach and compared it to the three baselines. Evaluating our
    approach across these incremental baselines allowed us to examine the effects
    of adding specific parts of the pipeline and to understand the degree to which
    each component contributed to the model’s ability to score and explain formative
    assessment responses.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将模型性能与4种实现方法的保留测试集进行比较来评估我们的方法：三种增量基准和我们的链式思维提示 + 主动学习方法。我们从零样本基准开始，其中提示中包含了评分标准，但没有标注的示例。然后，我们使用了少量样本基准，在提示中提供了标注的实例，但这些标注实例仅包含数字分数（即，没有链式思维推理）。我们的第三种也是最后一种基准，少量样本
    + 链式思维，将链式思维推理添加到少量样本实例中。最后，我们采用了链式思维提示 + 主动学习方法，并将其与三种基准进行比较。通过这些增量基准评估我们的方法，使我们能够检查添加特定部分管道的效果，并了解每个组件对模型评分和解释形成性评估反应能力的贡献程度。
- en: To compare implementations, we chose the Macro F1-Score and Cohen’s Quadratic
    Weighted Kappa (QWK) (Cohen [1968](#bib.bib11)) metrics. The F1-Score is prevalent
    in the literature for evaluating overall model performance. Macro F1 was chosen,
    specifically, due to our dataset’s imbalance across subscores. Often, scientific
    reasoning subscores are heavily weighted towards the negative class (i.e., a large
    majority of the students do not demonstrate scientific reasoning). Cohen’s QWK
    was chosen because it is widely used in the automated essay scoring (AES) literature
    (Singh et al. [2023](#bib.bib32); Singla et al. [2022](#bib.bib33)). Unlike traditional
    Cohen’s $k$ (Cohen [1960](#bib.bib10)), Cohen’s QWK accounts for the degree of
    disagreement, making it well-suited for ordinal data. We included accuracy for
    reference, but we do not use it in our actual performance comparisons.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较不同的实现方法，我们选择了宏观F1分数和科恩二次加权卡帕（QWK）(Cohen [1968](#bib.bib11))指标。F1分数在文献中广泛用于评估整体模型性能。特别地，选择宏观F1是由于我们数据集在子分数上的不平衡。通常，科学推理子分数往往偏向负类（即，大多数学生没有展示科学推理）。选择科恩的QWK是因为它在自动化作文评分（AES）文献中被广泛使用（Singh等
    [2023](#bib.bib32)；Singla等 [2022](#bib.bib33)）。与传统的科恩$k$（Cohen [1960](#bib.bib10)）不同，科恩的QWK考虑了分歧的程度，使其非常适合于序数数据。我们包括了准确度作为参考，但在实际性能比较中并没有使用它。
- en: Model performance comparisons for each of the three formative assessment questions
    are shown in Tables [1](#Sx4.T1 "Table 1 ‣ Results ‣ A Chain-of-Thought Prompting
    Approach with LLMs for Evaluating Students’ Formative Assessment Responses in
    Science"), [2](#Sx4.T2 "Table 2 ‣ Results ‣ A Chain-of-Thought Prompting Approach
    with LLMs for Evaluating Students’ Formative Assessment Responses in Science"),
    and [3](#Sx4.T3 "Table 3 ‣ Results ‣ A Chain-of-Thought Prompting Approach with
    LLMs for Evaluating Students’ Formative Assessment Responses in Science").
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 三个形成性评估问题的模型性能比较见表[1](#Sx4.T1 "Table 1 ‣ Results ‣ A Chain-of-Thought Prompting
    Approach with LLMs for Evaluating Students’ Formative Assessment Responses in
    Science")、[2](#Sx4.T2 "Table 2 ‣ Results ‣ A Chain-of-Thought Prompting Approach
    with LLMs for Evaluating Students’ Formative Assessment Responses in Science")
    和 [3](#Sx4.T3 "Table 3 ‣ Results ‣ A Chain-of-Thought Prompting Approach with
    LLMs for Evaluating Students’ Formative Assessment Responses in Science")。
- en: 'Question 1: Q1 asked students what the different-sized arrows in the diagram
    meant. A student received a point for correctly identifying that the diagram used
    the size of the arrows to represent the quantity of water (concept: “Arrow Size”,
    see Table [1](#Sx4.T1 "Table 1 ‣ Results ‣ A Chain-of-Thought Prompting Approach
    with LLMs for Evaluating Students’ Formative Assessment Responses in Science")).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 1：Q1 问学生图中不同大小的箭头表示什么。学生因正确识别出图中使用箭头的大小来表示水量（概念：“箭头大小”，见表 [1](#Sx4.T1 "Table
    1 ‣ Results ‣ A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students’
    Formative Assessment Responses in Science")）而获得了一个点数。
- en: '| Q1 Arrow Size | n | Acc | F1 | QWK |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Q1 箭头大小 | n | 准确率 | F1 | QWK |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Zero-Shot | 0 | 0.87 | 0.84 | 0.68 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 零样本 | 0 | 0.87 | 0.84 | 0.68 |'
- en: '| Few-Shot | 4 | 1.00 | 1.00 | 1.00 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本 | 4 | 1.00 | 1.00 | 1.00 |'
- en: '| Few-Shot, CoT | 4 | 0.96 | 0.95 | 0.89 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本, CoT | 4 | 0.96 | 0.95 | 0.89 |'
- en: '| CoT + AL | 12 | 0.98 | 0.97 | 0.95 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| CoT + AL | 12 | 0.98 | 0.97 | 0.95 |'
- en: 'Table 1: Performance comparisons for the Q1 Arrow Size subscore. For all questions,
    the best-performing scoring implementation is in bold for each metric, for each
    subscore (and total score). $n$ refers to the number of few-shot instances used
    in the prompt.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：Q1 箭头大小子评分的性能比较。对于所有问题，最佳表现的评分实现方法在每个指标、每个子评分（和总评分）中以**粗体**显示。$n$ 代表在提示中使用的少量样本实例的数量。
- en: Q1 took 2 rounds of IRR for the human scorers to reach a consensus. The grading
    involved scoring for one possible point and no science reasoning subscores. GPT-4
    aligned with the human scorer to a “moderate” degree (QWK  0.9)
    agreement. All subscores except one (Q2 Arrow Direction Reasoning) saw a Macro
    F1 of 0.90 or greater at some point in the process. Importantly, we also demonstrated
    that both CoT reasoning and active learning run the risk of overfitting, particularly
    when applied to the less complex science concepts questions (e.g., Q1 Arrow Size
    and Q3 Runoff Direction) and the more ambiguous scientific reasoning questions
    (e.g., Q2 Arrow Direction Reasoning and Q2 Arrow Size Reasoning). It should also
    be noted that the level of agreement during IRR may provide a ballpark expectation
    of model performance, as we found questions that were easier for the human scorers
    to agree on were also easier for the model to correctly align with the human scorers.
    Similarly, in questions where the human scorers had difficulty achieving consensus,
    the model had difficulty with scoring. More research needs to be done to evaluate
    this quantitatively.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 总结：在所有问题中，模型的评分大多与人工评分者一致。在11个子评分和总评分中，有9个得到了“强”的一致性或更高的（QWK  0.9）一致性。除一个子评分（Q2箭头方向推理）外，所有子评分在某些过程中都达到了0.90或更高的宏F1分数。重要的是，我们还证明了CoT推理和主动学习存在过拟合的风险，尤其是在应用于较不复杂的科学概念问题（例如Q1箭头大小和Q3流失方向）以及更模糊的科学推理问题（例如Q2箭头方向推理和Q2箭头大小推理）时。还应注意，IRR期间的一致性水平可能提供了模型表现的粗略预期，因为我们发现，人工评分者更容易达成一致的问题也更容易使模型与人工评分者一致。类似地，在人工评分者难以达成共识的问题中，模型也难以进行评分。需要进一步研究以定量评估这一点。
- en: Comparing Model and Human Performance
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较模型与人工表现
- en: 'We applied inductive coding (Charmaz [2006](#bib.bib4)) to evaluate performance
    and identify future directions to improve our human-in-the-loop approach. First,
    the lead author (not involved in rubric creation and scoring) reviewed all instances
    in which the model and the human coder disagreed and identified agreement with
    the model in 3 out of the 22 disagreements (1 conceptual disagreement, 2 reasoning
    disagreements). The research team reviewed the results to evaluate what may have
    caused scoring errors and to identify potential future directions for improvement.
    During the review process, the team created memos of key findings (Hatch [2002](#bib.bib15)).
    The team compared the memos and came up with three key themes for improvement
    in future work:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了归纳编码（Charmaz [2006](#bib.bib4)）来评估表现并确定未来改进人机交互方法的方向。首先，主要作者（未参与评分标准制定和评分）审查了模型与人工编码员意见不一致的所有实例，并在22个分歧中发现3个与模型一致（1个概念性分歧，2个推理分歧）。研究团队审查了结果，以评估可能导致评分错误的原因，并确定潜在的未来改进方向。在审查过程中，团队创建了关键发现的备忘录（Hatch
    [2002](#bib.bib15)）。团队对备忘录进行了比较，提出了未来工作的三个关键改进主题：
- en: '1.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Need for Additional Mechanisms to Target Model Deficiencies: Differences in
    scoring identified that the model showed a tendency to overfit in some cases.
    For instance, if the CoT got too granular, the model demonstrated issues that
    were related to keywords such as “because” (e.g., the model identified it as a
    demonstration of reasoning), “arrow size” (e.g., the model assumed that use of
    the terminology indicated a correct application even if correct attributions were
    not made to the scientific process), and vocabulary definitions (e.g., the model
    did not realize “run off” and “runoff” were identical). In a small set of cases,
    the model cited a student’s faulty logic to justify awarding a point for a response
    and reused the same piece of evidence to award points for both concept identification
    and reasoning;'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 针对模型缺陷的额外机制需求：评分差异显示模型在某些情况下存在过拟合的倾向。例如，如果CoT过于详细，模型会出现与关键词如“因为”（例如，模型将其识别为推理的演示）、“箭头大小”（例如，模型假设使用术语表示正确的应用，即使科学过程没有正确归因）和词汇定义（例如，模型没有意识到“run
    off”和“runoff”是相同的）相关的问题。在少数情况下，模型引用了学生的错误逻辑来为回答打分，并重复使用同一证据为概念识别和推理都打分。
- en: '2.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Ability to Leverage the Model to Support Rubric Refinements: Comparing reviewer
    and model differences for Q2 helped identify limitations in the original rubric
    for such an open-ended question. Utilizing the results and the explanations provided
    by the model, this human-in-the-loop approach can benefit teachers and researchers
    in refining the rubrics and scoring mechanisms to better support instruction and
    student learning; and'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利用模型支持评分标准修订的能力：对Q2的评审者和模型差异进行比较，有助于识别原始评分标准在处理这种开放性问题时的局限性。利用模型提供的结果和解释，这种人机协作的方法可以帮助教师和研究人员改进评分标准和评分机制，以更好地支持教学和学生学习；并且
- en: '3.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Resolve Unexplained Model Applications: In some cases, the model did not follow
    CoT reasoning and did not provide evidence of its positive predictions even though
    all positive prompt instances provided this evidence. This may be a potential
    limitation in the approach to providing feedback for positive performances.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解决未解释的模型应用：在某些情况下，模型没有遵循CoT推理，并且没有提供其积极预测的证据，即使所有积极提示实例都提供了这些证据。这可能是提供针对积极表现反馈的方法中的潜在限制。
- en: Overall, our approach was successful, but the instances discussed above provide
    opportunities for future work to improve model output, rubric development, and
    sometimes even reworking questions to make them clearer.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们的方法是成功的，但上述讨论的实例提供了未来改进模型输出、评分标准开发和有时甚至重新设计问题以使其更清晰的机会。
- en: Conclusion and Future Implications
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论和未来的影响
- en: In this paper, we employed a Chain-of-Thought Prompting + Active Learning approach
    for scoring and explaining formative assessment question responses in a middle
    school Earth Science curriculum. Our results show that GPT-4, CoT reasoning, and
    active learning can be effectively leveraged toward accurate grading of science
    formative assessments. In several cases, the model achieved “almost perfect” alignment
    with humans. The model generated relevant evidence linked to the rubric to help
    explain its scoring, which could benefit students and teachers. We also analyzed
    the model’s weaknesses and identified several areas for improving LLM-based assessments.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们采用了链式思维提示+主动学习的方法来评分和解释初中地球科学课程中的形成性评估问题。我们的结果表明，GPT-4、CoT推理和主动学习可以有效地用于准确评分科学形成性评估。在几个案例中，模型与人类的对齐达到了“几乎完美”的水平。模型生成了与评分标准相关的证据，以帮助解释其评分，这可能对学生和教师有益。我们还分析了模型的弱点，并确定了几个改进基于LLM的评估的领域。
- en: 'Limitations: With LLM approaches, ethical concerns arise with regard to privacy,
    bias, and hallucinations (Zhuo et al. [2023](#bib.bib44)), and these concerns
    are amplified when they are deployed in high-stakes environments (e.g., classrooms
    with children). In addition, while CoT has been shown to improve model performance
    over traditional ICL, the degree to which the reasoning chains guide the model’s
    decision-making (if at all) is still an open question (Turpin et al. [2023](#bib.bib35)).
    Our results also show that CoT and active learning can lead to overfitting, in
    particular, with simpler, easier-to-define subproblems. In these cases, LLM approaches
    may be overkill, as Moore et al. ([2023](#bib.bib25)) recently demonstrated. Rule-based
    methods outperformed GPT-4 in detecting common item-writing flaws in student-generated
    multiple-choice questions.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 限制：使用LLM方法时，隐私、偏见和幻觉（Zhuo等人 [2023](#bib.bib44)）等伦理问题会出现，当这些问题在高风险环境（例如，儿童课堂）中部署时，这些问题会被放大。此外，虽然CoT已被证明比传统的ICL提高了模型性能，但推理链在多大程度上指导模型的决策（如果有的话）仍然是一个悬而未决的问题（Turpin等人
    [2023](#bib.bib35)）。我们的结果还表明，CoT和主动学习可能会导致过拟合，特别是在定义较简单、更易于定义的子问题时。在这些情况下，LLM方法可能过于复杂，正如Moore等人（[2023](#bib.bib25)）最近所展示的那样。规则基础的方法在检测学生生成的选择题中的常见问题上优于GPT-4。
- en: 'Looking to the Future: Anecdotally, in an interview with middle school science
    teachers who implemented the curriculum, the teachers identified the potential
    benefits of these explanations as tools to inform students on where to go next
    in their learning, as opposed to assigning performance scores. We aim to extend
    this partnership with classroom teachers to mold the LLM’s output to best fit
    their needs, and investigate how we can best use our method to evaluate students’
    learning performance and improve students’ learning. As we continue to refine
    our approach, we hope these enhancements will pave the way for more effective
    and efficient LLM applications in science education.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来：根据与实施该课程的中学科学教师的访谈，这些教师认为这些解释作为工具具有潜在的好处，能够指导学生了解学习的下一步，而不是仅仅分配成绩。我们旨在扩展与课堂教师的合作，以调整LLM的输出以最佳适应他们的需求，并研究如何最好地利用我们的方法来评估学生的学习表现并改进学生的学习。随着我们不断完善我们的方法，我们希望这些改进将为科学教育中更有效和高效的LLM应用铺平道路。
- en: Acknowledgments
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by the National Science Foundation under awards DRL-2112635
    and IIS-2017000\. Any opinions, findings, conclusions, and recommendations in
    this paper are those of the authors and do not necessarily reflect the views of
    the National Science Foundation.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到国家科学基金会（NSF）奖项 DRL-2112635 和 IIS-2017000 的支持。本文中的任何意见、发现、结论和建议均为作者个人观点，不一定反映国家科学基金会的观点。
- en: References
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Adair et al. (2023) Adair, A.; Pedro, M. S.; Gobert, J.; and Segan, E. 2023.
    Real-Time AI-Driven Assessment and Scaffolding that Improves Students’ Mathematical
    Modeling during Science Investigations. In Wang, N.; Rebolledo-Mendez, G.; Matsuda,
    N.; Santos, O. C.; and Dimitrova, V., eds., *Artificial Intelligence in Education*,
    202–216\. Cham: Springer Nature Switzerland. ISBN 978-3-031-36272-9.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adair et al. (2023) Adair, A.; Pedro, M. S.; Gobert, J.; 和 Segan, E. 2023. 实时AI驱动的评估和支架，改善学生在科学调查中的数学建模。在
    Wang, N.; Rebolledo-Mendez, G.; Matsuda, N.; Santos, O. C.; 和 Dimitrova, V., 编，*教育中的人工智能*，202–216。Cham：Springer
    Nature Switzerland。ISBN 978-3-031-36272-9。
- en: 'Bloom, Madaus, and Hastings (1971) Bloom, B.; Madaus, G.; and Hastings, J.
    1971. *Handbook on Formative and Summative Evaluation of Student Learning*. New
    York: McGraw-Hill.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bloom, Madaus, 和 Hastings (1971) Bloom, B.; Madaus, G.; 和 Hastings, J. 1971.
    *学生学习的形成性和总结性评价手册*。纽约：McGraw-Hill。
- en: Brown et al. (2020) Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan,
    J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal,
    S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler,
    D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray,
    S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever,
    I.; and Amodei, D. 2020. Language Models are Few-Shot Learners. *arXiv e-prints*,
    arXiv:2005.14165.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown et al. (2020) Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan,
    J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal,
    S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler,
    D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray,
    S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever,
    I.; 和 Amodei, D. 2020. 语言模型是少样本学习者。*arXiv 电子预印本*，arXiv:2005.14165。
- en: 'Charmaz (2006) Charmaz, K. 2006. *Constructing grounded theory: A practical
    guide through qualitative analysis*. Sage.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Charmaz (2006) Charmaz, K. 2006. *构建扎根理论：通过定性分析的实用指南*。Sage.
- en: 'Chiu et al. (2019) Chiu, J.; McElhaney, K.; Zhang, N.; Biswas, G.; Fried, R.;
    Basu, S.; Alozie, N.; and Hong, J. 2019. A Principled Approach to NGSS-aligned
    Curriculum Development Integrating Science, Engineering, and Computation: A Pilot
    Study. In *NARST Annual International Conference*. NARST.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiu et al. (2019) Chiu, J.; McElhaney, K.; Zhang, N.; Biswas, G.; Fried, R.;
    Basu, S.; Alozie, N.; 和 Hong, J. 2019. 一种原则性的NGSS对齐课程开发方法，融合科学、工程和计算：一项试点研究。在
    *NARST 年度国际会议* 上。NARST。
- en: 'Cizek and Lim (2023) Cizek, G. J.; and Lim, S. N. 2023. Formative assessment:
    an overview of history, theory and application. In Tierney, R. J.; Rizvi, F.;
    and Ercikan, K., eds., *International Encyclopedia of Education (Fourth Edition)*,
    1–9\. Oxford: Elsevier, fourth edition edition. ISBN 978-0-12-818629-9.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cizek 和 Lim (2023) Cizek, G. J.; 和 Lim, S. N. 2023. 形成性评估：历史、理论和应用概述。在 Tierney,
    R. J.; Rizvi, F.; 和 Ercikan, K., 编，*国际教育百科全书（第四版）*，1–9。牛津：Elsevier，第四版。ISBN 978-0-12-818629-9。
- en: Cochran, Cohn, and Hastings (2023) Cochran, K.; Cohn, C.; and Hastings, P. 2023.
    Improving NLP model performance on small educational data sets using self-augmentation.
    In *Proceedings of the 15th International Conference on Computer Supported Education
    (2023, to appear)*.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cochran, Cohn 和 Hastings (2023) Cochran, K.; Cohn, C.; 和 Hastings, P. 2023.
    使用自我增强提高小型教育数据集上的 NLP 模型性能。在 *第十五届国际计算机支持教育大会论文集 (2023，待发表)*。
- en: Cochran et al. (2022) Cochran, K.; Cohn, C.; Hutchins, N.; Biswas, G.; and Hastings,
    P. 2022. Improving automated evaluation of formative assessments with text data
    augmentation. In *International Conference on Artificial Intelligence in Education*,
    390–401\. Springer.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cochran 等 (2022) Cochran, K.; Cohn, C.; Hutchins, N.; Biswas, G.; 和 Hastings,
    P. 2022. 通过文本数据增强改进形成性评估的自动评估。在 *国际人工智能教育大会*，390–401\. 施普林格。
- en: Cochran et al. (2023) Cochran, K.; Cohn, C.; Rouet, J. F.; and Hastings, P.
    2023. Improving Automated Evaluation of Student Text Responses Using GPT-3.5 for
    Text Data Augmentation. In *International Conference on Artificial Intelligence
    in Education*, 217–228\. Springer.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cochran 等 (2023) Cochran, K.; Cohn, C.; Rouet, J. F.; 和 Hastings, P. 2023. 使用
    GPT-3.5 提高学生文本回应的自动评估，通过文本数据增强。在 *国际人工智能教育大会*，217–228\. 施普林格。
- en: 'Cohen (1960) Cohen, J. 1960. A coefficient of agreement for nominal scales.
    *Educational and psychological measurement*, 20(1): 37–46.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen (1960) Cohen, J. 1960. 名义尺度的一致性系数。*教育与心理测量*，20(1)：37–46。
- en: 'Cohen (1968) Cohen, J. 1968. Weighted kappa: nominal scale agreement provision
    for scaled disagreement or partial credit. *Psychological bulletin*, 70(4): 213.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen (1968) Cohen, J. 1968. 加权 Kappa：名义尺度一致性用于比例不一致或部分积分。*心理学公报*，70(4)：213。
- en: 'Cohn (2020) Cohn, C. 2020. *BERT efficacy on scientific and medical datasets:
    a systematic literature review*. DePaul University.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohn (2020) Cohn, C. 2020. *BERT 在科学和医学数据集上的效果：系统文献综述*。德保罗大学。
- en: 'Funayama et al. (2023) Funayama, H.; Asazuma, Y.; Matsubayashi, Y.; Mizumoto,
    T.; and Inui, K. 2023. Reducing the Cost: Cross-Prompt Pre-finetuning for Short
    Answer Scoring. In *International Conference on Artificial Intelligence in Education*,
    78–89\. Springer.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Funayama 等 (2023) Funayama, H.; Asazuma, Y.; Matsubayashi, Y.; Mizumoto, T.;
    和 Inui, K. 2023. 降低成本：跨提示预微调用于短答案评分。在 *国际人工智能教育大会*，78–89\. 施普林格。
- en: 'Harris et al. (2023) Harris, C.; Wiebe, E.; Grover, S.; and Pellegrino, J.
    2023. *Classroom-based STEM assessment: Contemporary issues and perspectives*.
    Community for Advancing Discovery Research in Education (CADRE). Education Development
    Center, Inc.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harris 等 (2023) Harris, C.; Wiebe, E.; Grover, S.; 和 Pellegrino, J. 2023. *基于课堂的
    STEM 评估：当代问题与视角*。教育发现研究推进社区 (CADRE)。教育发展中心公司。
- en: Hatch (2002) Hatch, J. A. 2002. *Doing qualitative research in education settings*.
    SUNY Press.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hatch (2002) Hatch, J. A. 2002. *在教育环境中进行定性研究*。SUNY Press。
- en: 'Haudek et al. (2011) Haudek, K. C.; Kaplan, J. J.; Knight, J.; Long, T.; Merrill,
    J.; Munn, A.; Nehm, R.; Smith, M.; and Urban-Lurain, M. 2011. Harnessing technology
    to improve formative assessment of student conceptions in STEM: forging a national
    network. *CBE—Life Sciences Education*, 10(2): 149–155.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haudek 等 (2011) Haudek, K. C.; Kaplan, J. J.; Knight, J.; Long, T.; Merrill,
    J.; Munn, A.; Nehm, R.; Smith, M.; 和 Urban-Lurain, M. 2011. 利用技术改进 STEM 领域学生概念的形成性评估：建立国家网络。*CBE—生命科学教育*，10(2)：149–155。
- en: 'Hutchins and Biswas (2023) Hutchins, N.; and Biswas, G. 2023. Using Teacher
    Dashboards to Customize Lesson Plans for a Problem-Based, Middle School STEM Curriculum.
    In *LAK23: 13th International Learning Analytics and Knowledge Conference*, LAK2023,
    324–332\. New York, NY, USA: Association for Computing Machinery. ISBN 9781450398657.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hutchins 和 Biswas (2023) Hutchins, N.; 和 Biswas, G. 2023. 使用教师仪表盘为基于问题的中学 STEM
    课程定制教学计划。在 *LAK23: 第十三届国际学习分析与知识大会*，LAK2023，324–332\. 纽约，NY，美国：计算机协会。ISBN 9781450398657。'
- en: Hutchins et al. (2021) Hutchins, N. M.; Basu, S.; McElhaney, K.; Chiu, J.; Fick,
    S.; Zhang, N.; and Biswas, G. 2021. Coherence across conceptual and computational
    representations of students’ scientific models. In *The International Society
    of the Learning Sciences Annual Meeting 2021*. International Society of the Learning
    Sciences (ISLS).
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hutchins 等 (2021) Hutchins, N. M.; Basu, S.; McElhaney, K.; Chiu, J.; Fick,
    S.; Zhang, N.; 和 Biswas, G. 2021. 学生科学模型的概念性和计算性表示之间的连贯性。在 *国际学习科学学会年会 2021*。国际学习科学学会
    (ISLS)。
- en: 'Liu et al. (2022) Liu, E.; Stephan, M.; Nie, A.; Piech, C.; Brunskill, E.;
    and Finn, C. 2022. Giving Feedback on Interactive Student Programs with Meta-Exploration.
    *Advances in Neural Information Processing Systems*, 35: 36282–36294.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等人（2022）Liu, E.; Stephan, M.; Nie, A.; Piech, C.; Brunskill, E.; 和 Finn,
    C. 2022. 使用元探索对互动学生程序进行反馈。*神经信息处理系统进展*，35: 36282–36294。'
- en: 'Liu et al. (2016) Liu, O. L.; Rios, J. A.; Heilman, M.; Gerard, L.; and Linn,
    M. C. 2016. Validation of automated scoring of science assessments. *Journal of
    Research in Science Teaching*, 53(2): 215–233.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu等人（2016）Liu, O. L.; Rios, J. A.; Heilman, M.; Gerard, L.; 和 Linn, M. C.
    2016. 科学评估的自动评分验证。*科学教学研究期刊*，53(2): 215–233。'
- en: 'Mao et al. (2018) Mao, L.; Liu, O. L.; Roohr, K.; Belur, V.; Mulholland, M.;
    Lee, H.-S.; and Pallant, A. 2018. Validation of automated scoring for a formative
    assessment that employs scientific argumentation. *Educational Assessment*, 23(2):
    121–138.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mao等人（2018）Mao, L.; Liu, O. L.; Roohr, K.; Belur, V.; Mulholland, M.; Lee,
    H.-S.; 和 Pallant, A. 2018. 使用科学论证的形成性评估的自动评分验证。*教育评估*，23(2): 121–138。'
- en: 'McHugh (2012) McHugh, M. L. 2012. Interrater reliability: the kappa statistic.
    *Biochemia medica*, 22(3): 276–282.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'McHugh（2012）McHugh, M. L. 2012. 评估者间一致性：kappa统计量。*生物化学医学*，22(3): 276–282。'
- en: 'Min et al. (2022) Min, S.; Lyu, X.; Holtzman, A.; Artetxe, M.; Lewis, M.; Hajishirzi,
    H.; and Zettlemoyer, L. 2022. Rethinking the role of demonstrations: What makes
    in-context learning work? *arXiv preprint arXiv:2202.12837*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Min等人（2022）Min, S.; Lyu, X.; Holtzman, A.; Artetxe, M.; Lewis, M.; Hajishirzi,
    H.; 和 Zettlemoyer, L. 2022. 重新思考演示的角色：是什么让上下文学习有效？*arXiv预印本 arXiv:2202.12837*。
- en: 'Mislevy and Haertel (2006) Mislevy, R. J.; and Haertel, G. D. 2006. Implications
    of Evidence-Centered Design for Educational Testing. *Educational Measurement:
    Issues and Practice*, 25(4): 6–20.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mislevy和Haertel（2006）Mislevy, R. J.; 和 Haertel, G. D. 2006. 以证据为中心的设计对教育测试的影响。*教育测量：问题与实践*，25(4):
    6–20。'
- en: Moore et al. (2023) Moore, S.; Nguyen, H. A.; Chen, T.; and Stamper, J. 2023.
    Assessing the Quality of Multiple-Choice Questions Using GPT-4 and Rule-Based
    Methods. In *European Conference on Technology Enhanced Learning*, 229–245\. Springer.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moore等人（2023）Moore, S.; Nguyen, H. A.; Chen, T.; 和 Stamper, J. 2023. 使用GPT-4和基于规则的方法评估多项选择题的质量。发表于*欧洲技术增强学习会议*，229–245。Springer。
- en: Morris et al. (2023) Morris, W.; Crossley, S.; Holmes, L.; Ou, C.; McNamara,
    D.; and Dascalu, M. 2023. Using Large Language Models to Provide Formative Feedback
    in Intelligent Textbooks. In *International Conference on Artificial Intelligence
    in Education*, 484–489\. Springer.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morris等人（2023）Morris, W.; Crossley, S.; Holmes, L.; Ou, C.; McNamara, D.; 和
    Dascalu, M. 2023. 使用大型语言模型在智能教材中提供形成性反馈。发表于*国际教育人工智能会议*，484–489。Springer。
- en: 'Mosbach, Andriushchenko, and Klakow (2020) Mosbach, M.; Andriushchenko, M.;
    and Klakow, D. 2020. On the stability of fine-tuning bert: Misconceptions, explanations,
    and strong baselines. *arXiv preprint arXiv:2006.04884*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mosbach, Andriushchenko, 和 Klakow（2020）Mosbach, M.; Andriushchenko, M.; 和 Klakow,
    D. 2020. 关于微调BERT的稳定性：误解、解释和强基线。*arXiv预印本 arXiv:2006.04884*。
- en: 'NGSS (2013) NGSS. 2013. *Next Generation Science Standards: For States, By
    States*. The National Academies Press.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NGSS（2013）NGSS. 2013. *下一代科学标准：由州制定*。国家科学院出版社。
- en: OpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. *arXiv e-prints*, arXiv:2303.08774.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023）OpenAI. 2023. GPT-4技术报告。*arXiv电子打印版*，arXiv:2303.08774。
- en: 'Ren et al. (2021) Ren, P.; Xiao, Y.; Chang, X.; Huang, P.-Y.; Li, Z.; Gupta,
    B. B.; Chen, X.; and Wang, X. 2021. A survey of deep active learning. *ACM computing
    surveys (CSUR)*, 54(9): 1–40.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ren等人（2021）Ren, P.; Xiao, Y.; Chang, X.; Huang, P.-Y.; Li, Z.; Gupta, B. B.;
    Chen, X.; 和 Wang, X. 2021. 深度主动学习的综述。*ACM计算调查（CSUR）*，54(9): 1–40。'
- en: 'Rodrigues and Oliveira (2014) Rodrigues, F.; and Oliveira, P. 2014. A system
    for formative assessment and monitoring of students’ progress. *Computers & Education*,
    76: 30–41.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rodrigues和Oliveira（2014）Rodrigues, F.; 和 Oliveira, P. 2014. 一种用于形成性评估和学生进展监控的系统。*计算机与教育*，76:
    30–41。'
- en: 'Singh et al. (2023) Singh, S.; Pupneja, A.; Mital, S.; Shah, C.; Bawkar, M.;
    Gupta, L. P.; Kumar, A.; Kumar, Y.; Gupta, R.; and Shah, R. R. 2023. H-AES: Towards
    Automated Essay Scoring for Hindi. *arXiv preprint arXiv:2302.14635*.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh等人（2023）Singh, S.; Pupneja, A.; Mital, S.; Shah, C.; Bawkar, M.; Gupta,
    L. P.; Kumar, A.; Kumar, Y.; Gupta, R.; 和 Shah, R. R. 2023. H-AES：迈向自动评分印地语论文。*arXiv预印本
    arXiv:2302.14635*。
- en: Singla et al. (2022) Singla, Y. K.; Krishna, S.; Shah, R. R.; and Chen, C. 2022.
    Using sampling to estimate and improve performance of automated scoring systems
    with guarantees. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    volume 36 (11), 12835–12843.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singla 等人 (2022) Singla, Y. K.; Krishna, S.; Shah, R. R.; 和 Chen, C. 2022. Using
    sampling to estimate and improve performance of automated scoring systems with
    guarantees. 在 *AAAI 人工智能会议论文集*, 卷 36 (11), 12835–12843.
- en: Tan et al. (2023) Tan, W.; Lin, J.; Lang, D.; Chen, G.; Gašević, D.; Du, L.;
    and Buntine, W. 2023. Does informativeness matter? Active learning for educational
    dialogue act classification. In *International Conference on Artificial Intelligence
    in Education*, 176–188\. Springer.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人 (2023) Tan, W.; Lin, J.; Lang, D.; Chen, G.; Gašević, D.; Du, L.; 和 Buntine,
    W. 2023. Does informativeness matter? Active learning for educational dialogue
    act classification. 在 *国际人工智能教育会议*, 176–188\. Springer.
- en: 'Turpin et al. (2023) Turpin, M.; Michael, J.; Perez, E.; and Bowman, S. R.
    2023. Language Models Don’t Always Say What They Think: Unfaithful Explanations
    in Chain-of-Thought Prompting. *arXiv preprint arXiv:2305.04388*.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Turpin 等人 (2023) Turpin, M.; Michael, J.; Perez, E.; 和 Bowman, S. R. 2023.
    Language Models Don’t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought
    Prompting. *arXiv 预印本 arXiv:2305.04388*.'
- en: 'Walkoe, Wilkerson, and Elby (2017) Walkoe, J.; Wilkerson, M.; and Elby, A.
    2017. Technology-Mediated Teacher Noticing: A Goal for Classroom Practice, Tool
    Design, and Professional Development. In *Proceedings of the 12th International
    Conference on Computer Supported Collaborative Learning (CSCL) 2017*. International
    Society of the Learning Sciences.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Walkoe, Wilkerson, 和 Elby (2017) Walkoe, J.; Wilkerson, M.; 和 Elby, A. 2017.
    Technology-Mediated Teacher Noticing: A Goal for Classroom Practice, Tool Design,
    and Professional Development. 在 *第12届计算机支持的协作学习国际会议 (CSCL) 2017* 论文集. 学习科学国际协会.'
- en: Wei et al. (2022) Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.;
    Xia, F.; Chi, E.; Le, Q.; and Zhou, D. 2022. Chain-of-Thought Prompting Elicits
    Reasoning in Large Language Models. *arXiv e-prints*, arXiv:2201.11903.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2022) Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.; Xia,
    F.; Chi, E.; Le, Q.; 和 Zhou, D. 2022. Chain-of-Thought Prompting Elicits Reasoning
    in Large Language Models. *arXiv 电子预印本*, arXiv:2201.11903.
- en: White et al. (2023) White, J.; Fu, Q.; Hays, S.; Sandborn, M.; Olea, C.; Gilbert,
    H.; Elnashar, A.; Spencer-Smith, J.; and Schmidt, D. C. 2023. A prompt pattern
    catalog to enhance prompt engineering with chatgpt. *arXiv preprint arXiv:2302.11382*.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: White 等人 (2023) White, J.; Fu, Q.; Hays, S.; Sandborn, M.; Olea, C.; Gilbert,
    H.; Elnashar, A.; Spencer-Smith, J.; 和 Schmidt, D. C. 2023. A prompt pattern catalog
    to enhance prompt engineering with chatgpt. *arXiv 预印本 arXiv:2302.11382*.
- en: 'Wiley et al. (2020) Wiley, K. J.; Dimitriadis, Y.; Bradford, A.; and Linn,
    M. C. 2020. From Theory to Action: Developing and Evaluating Learning Analytics
    for Learning Design. In *Proceedings of the Tenth International Conference on
    Learning Analytics & Knowledge*, LAK ’20, 569–578\. New York, NY, USA: Association
    for Computing Machinery. ISBN 9781450377126.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wiley 等人 (2020) Wiley, K. J.; Dimitriadis, Y.; Bradford, A.; 和 Linn, M. C.
    2020. From Theory to Action: Developing and Evaluating Learning Analytics for
    Learning Design. 在 *第十届国际学习分析与知识会议论文集*, LAK ’20, 569–578\. 纽约, NY, USA: 计算机协会.
    ISBN 9781450377126.'
- en: 'Wilson et al. (2021) Wilson, J.; Ahrendt, C.; Fudge, E. A.; Raiche, A.; Beard,
    G.; and MacArthur, C. 2021. Elementary teachers’ perceptions of automated feedback
    and automated scoring: Transforming the teaching and learning of writing using
    automated writing evaluation. *Computers & Education*, 168: 104208.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wilson 等人 (2021) Wilson, J.; Ahrendt, C.; Fudge, E. A.; Raiche, A.; Beard,
    G.; 和 MacArthur, C. 2021. Elementary teachers’ perceptions of automated feedback
    and automated scoring: Transforming the teaching and learning of writing using
    automated writing evaluation. *Computers & Education*, 168: 104208.'
- en: 'Wu et al. (2023) Wu, X.; He, X.; Liu, T.; Liu, N.; and Zhai, X. 2023. Matching
    exemplar as next sentence prediction (mensp): Zero-shot prompt learning for automatic
    scoring in science education. In *International Conference on Artificial Intelligence
    in Education*, 401–413\. Springer.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人 (2023) Wu, X.; He, X.; Liu, T.; Liu, N.; 和 Zhai, X. 2023. Matching exemplar
    as next sentence prediction (mensp): Zero-shot prompt learning for automatic scoring
    in science education. 在 *国际人工智能教育会议*, 401–413\. Springer.'
- en: Zeng et al. (2023) Zeng, Z.; Li, L.; Guan, Q.; Gašević, D.; and Chen, G. 2023.
    Generalizable Automatic Short Answer Scoring via Prototypical Neural Network.
    In *International Conference on Artificial Intelligence in Education*, 438–449\.
    Springer.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng 等人 (2023) Zeng, Z.; Li, L.; Guan, Q.; Gašević, D.; 和 Chen, G. 2023. Generalizable
    Automatic Short Answer Scoring via Prototypical Neural Network. 在 *国际人工智能教育会议*,
    438–449\. Springer.
- en: Zhao et al. (2023) Zhao, W. X.; Zhou, K.; Li, J.; Tang, T.; Wang, X.; Hou, Y.;
    Min, Y.; Zhang, B.; Zhang, J.; Dong, Z.; et al. 2023. A survey of large language
    models. *arXiv preprint arXiv:2303.18223*.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等（2023）Zhao, W. X.; Zhou, K.; Li, J.; Tang, T.; Wang, X.; Hou, Y.; Min,
    Y.; Zhang, B.; Zhang, J.; Dong, Z.; 等. 2023. 大型语言模型综述。*arXiv 预印本 arXiv:2303.18223*。
- en: 'Zhuo et al. (2023) Zhuo, T. Y.; Huang, Y.; Chen, C.; and Xing, Z. 2023. Red
    teaming chatgpt via jailbreaking: Bias, robustness, reliability and toxicity.
    *arXiv preprint arXiv:2301.12867*, 12–2.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhuo 等（2023）Zhuo, T. Y.; Huang, Y.; Chen, C.; 和 Xing, Z. 2023. 通过越狱对 ChatGPT
    进行红队测试：偏见、鲁棒性、可靠性和毒性。*arXiv 预印本 arXiv:2301.12867*，12–2。
