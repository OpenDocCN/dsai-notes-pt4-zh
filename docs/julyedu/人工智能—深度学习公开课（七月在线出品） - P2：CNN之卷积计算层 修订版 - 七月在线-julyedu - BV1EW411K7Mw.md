# 人工智能—深度学习公开课（七月在线出品） - P2：CNN之卷积计算层 修订版 - 七月在线-julyedu - BV1EW411K7Mw

![](img/a84eaa83ac6506943134bf4222d8ec7f_0.png)

大家看接下来的第二个。你接下来遇到这一层是哪一层的？是这个白色的对吧？叫做comvolutional layer。OK它叫做卷基层。那这个卷积层呢，他做的事情实际它这是非常重要的一层啊。

因为有了它能够把我的参数量极大的往下降。可能会有一点点的复杂这一个层次我我我给大家讲了，大家尽量跟着我的思路来，大家尽量跟着我的思路来。学呃这个理解这个这个事情啊，呃有问题的同学一会儿好吧。

有问题的同学，我们讲完这一层，一会儿再问，好不好？因为中间一直打断的话，可能听录播的话会觉得连贯性会有影响。所以我们第二层叫做卷积计算层，叫做convolution layer。它做的事情呢是这样的。

我们给大家先大家先不要看上面这些概念啊，先给大家一个直观的一个理解。说如果我现在要去看这幅图像，对吧？那我的人工神经网络做的事情是什么？人工神经网络找了很多神经元啊，你把每个神经元看做一个小朋友就好了。

之前我们不是说了吗？找了很多个线性，很多条直线线性分类器去划分那个平面，对吧？那每一条直线你可以看作一个小朋友，他有一自己的一套世界观价值观。他去判别这个东西，他有自己很肯定的一个答案。他去看这个东西。

他觉得呃他他他他会对这个微博或者知乎上的东西会有自己的一个评价。OK所以现在是现在这个问题换成了一幅图像。所以是这幅图像，你丢给这么多个神经元，让他们去做解读，或者让他们去做理解。好。

所以你现在找了5个小朋友过来，对吧？好，我们给他编一下号啊，这叫123455个小朋友过来。所以每个小朋友呢。他觉得我去看整幅图。压力实在太大了。或者他说我的能力不具备，一眼我我眼睛比较小。

我做不到一眼去看一下整张图片。所以你就想了一个办法，你说okK现在我的分布式计算，我所有的这些啊okha do或者是hado生态或者park生态的这个md做的事情，无非就是把它并发出去，然后去做做一个。

再收集回来对吧？我先做一个map，再做一个reduce的操作嘛。好，所以这个时候你想了一个办法，你说这5个小朋友如果他们抱怨说自己这个眼睛小或者看不下整张图的话，你有没有办法去做处理呢？他说好吧。

那你就1。1点看行吧。首先我需要说的是图像，它具备这样的一个特性，叫做局部关联性。大家想一想啊，你在这幅图上的这一个点，它的颜色或者说它的像素值。你想一想和它最关联的是不是周边的这些点？

我找一个左下角的点，你会觉得和这个点之间的像素值会有极大的关联性吗？你不觉得他会有极大的关联性，对？所以哎我觉得这个任务好像是可以分拆着来看的对吧？所以他说好，你别着急，这个一号小朋友呢。

我我我告诉你怎么去看这幅图，他说他说这幅图是32乘以32乘以3的这这个大家能理解吧？32乘以32是长和宽，三是三个颜色通道。这个没问题吧。好，他说那你这么来看吧。你既然看不下整幅整幅图，那你就。

找一个视野。空。这个叫receptive field， receptive field。你就把它当做一个滑动窗口好了，它的视野窗好了。所以他就说你看不下整幅图，那你就看这个。好吧。

我找一个窗口给你这个窗口里头数字总我能看一下吗？所以好，所以他看这幅图的事情，作他看这幅图的方方式是，我先找了一个滑动窗口啊，这个窗口也许我我我们随便给一个值啊，也许是一个3乘以3的一个窗口。行吧。

所以是9个像素点。他说好，你现在能看得像了吗？他说我能看得像了。OK那他说。但是你还是得把整幅图都看完了。所以你不能只看这一个窗口啊。😡，对，然后他会让它开始让这个窗口在上面开始滑动。

但是滑动到下一个位置呢，可能会和上一个位置之间有重叠。嗯，比如说它是3乘以3的窗口，我如果滑动两步的话，是不是会有一格重叠呀？大家这个这一点能明白吧，所以他让一号小朋友去做的事情是说。

你的视野如果能够盖住3乘以3的窗口，没问题，你先看3乘以3的窗口，从左上角开始往右滑动。当你把这一行看完的时候，再往下挪，再往右挪。大家能理解吗？

这样3乘以乘以3的窗口会通过这样一种向右滑和向滑下滑的方式去覆盖整幅图片。到目前为止，大家能理解这种方式吗？你先别管他做的操作，好吧。OK所以这是卷积神经网络。最关键的。一点之一啊几点之一。好。哎。

那但是他这个操作又从哪里能够体现我把参数降下来呢？这个事情呢我不知道大家有没有印象，我上节课给大家讲。😊，提到了一点，我说现在的这个dep learninging啊，你去完成很多任务啊。

用ar network neural network就完成很多事情啊。比如说这个我们就说他做英语题，好吧，这个英语题目ABCD4个选项它能给出答案，但是你并不知道它是怎么做的，对吧？

我们说有一个所谓的体感或者是语感这样的东西在是由什么东西决定的，是不是有这样一组W啊。意味着说W是不是决定了，如果我生动一点来看啊，在我这个例子当中。

是不是决定了这个地方一号小朋友或者2号小朋友或者3号小朋友的。世界观呢或者说他的语感，他的体感呢是不是由这组W决定的呀？所以刚才你你不是在抱怨，你说我啊这个ok。😡，我的这个天黑请闭眼。

然后然后啊天亮请睁眼，你睁开眼睛以后，你看不下整幅图，所以你现在是一个窗口，一个窗口看的对吧？所以他想了一个办法，他说。我现在想把刚才的全连接的这样一组W的维度给它往下降，对不对？

但同时我们又知道一个事情，我们知道这样一组W实际上决定了他所谓的体感或者是语感，或者说他对于这个世界的认知，或者是他在完成这个任务时候，他的一种理解，一种判断。所以他做了一个事情，他说。哎。

我能不能这样做，大家看看这个窗口在滑的时候，窗口的大小是不变的对吧？也就是3乘以3的窗口里头就9个点，对不对？所以他说我就固定住这9个点的值行不行？我固定住这个9个点的值，只是让我的这个窗口在滑动。

每次去看到不同的图像。偶尔在看不同的图像的时候，我去做信息抽取。都是用的这一套模板或者用的这一9个数组成的价值观世界观，我的认知体系去看的。我这么说，大家能明白吗？

也就是意味着我这个9乘3乘以3的99个点的数据窗在动，但是我固定出了9个连接值W。这么一套世界观，这么一套判定标准去看这幅图，因为就是同一个人嘛，你每个人要有自己自己的准则。

要有自己的处处这个世界观价值观，对不对？那没问题啊，我就每个人我就固定住固定住一组W，固定住9个W。而这5个小朋友会有5个不同的。9个数的W我不知道大家能理解吗？打小朋友一是W一，小朋友2是W2。

小朋友三是W3，但是他他们都是9个数，只不过这9每个小朋友的9个数是不一样的。能理解我说的事情吗？所以大家如果能理解就好办了。因为刚才全连接层或者说arial neural network人工神经网络。

它最糟糕的事情在于说一个小朋友，你还要求他去看每一个每每一个小窗口的时候都用不同的价值观，不同的认知体系去看，或者说你你希望他一睁眼天黑天天亮请睁眼睁眼之后就看到整张32乘以32乘以3的图片。

他说我做不到。我如果去做的话，我也是强行把它记下来，这个事情太糟糕了。所以他说你就分一分块。但是我有个要求，你分完这个块以后去读这张图片的时候，你必须保持你的一致性，怎么去体现出来这个一致性。

或者体现出来。我看这张图片的时候，我是很专一的，我的方式就是一致的，就是他固定出来这9个数。所以。😡，这一点大家明确了没有？我给大家解释清楚了没有？这个3乘以3的。3乘以3个W。

OK所以我们这么去理解这个事情啊，所以这里头会涉及到一些概念，会涉及到一些概念。第一个概念叫做ds，叫做深度。所以你去看同样的一张图片。我为什么要让这么多个人来看呢？因为大家都知道你在知乎上有讨论。

才会有碰撞，才会有进步嘛。所以这个时候我找了5个小朋友过来看，我说你们5个小朋友都发表一下自己的意见，都觉得都告诉我从从这张图片里头看到了什么，我再去汇总。对吗？

所以这个地方ds指的是有多少个人去参与这个知乎的讨论，有多少个人去看这张图像。看这张图片，这个能明白吗？大家。因为一号小朋友在看完这张图以后，它会有一个计算的结果。2号小朋友他又会有一个计算的结果。

3号小朋友会有他的计算结果。这些计算结果我们都把它叫做feature map。所以你有几个小朋友，你最后的feature map具有多少层？而所谓的层就是这个地方的厚度的意思。我我说明白了吗？

这个地方第一个概念叫做厚度，叫做death。它指的是小朋友的个数，它指的是你下一层的nen的个数。它指的是你下一层filter的个数。我说明白了吗？好。第一个概念就是这个意思，因为要有碰撞才会有进步。

所以要有要有大家的意见汇总综合才能看到东西。所以我会找很多个神经元，我会找很多个小朋友，我会找很多个neon，多个futer过来做这个事情。ok。第二个概念叫做步长，叫做stride。他的意思是说。

你固定了一个33乘以3的一个窗口，而你这个窗口在滑动，你是不是应该告诉我说每次滑多少步？不要着急，一会儿我会补充大家的这些问题好吗？大家先跟着把概念过一遍，不要着急O。第二点是步长啊，是dide。

听清楚了，你取了3乘以3的窗口，这个窗口是不是会有一个滑动的操作？你滑动了，是不是要告诉我这个步步子要滑多大？所以刚才我说的这个滑动两格，这个二就是这个地方的stride这个意思。明白吗？

所以上面的ds对应这张图里头是5这个地方我刚才说的stride等于2。好，第三个概念叫做zero cuttingdding。就入padding是这样一个概念，说大家想一想这个事情啊。

如果你现在是32乘以32乘以3的这么一个数据矩阵，你要以5乘以5的窗口。每次滑。啊，我就我我我随便举一个数子啊，划三步。你能够刚好从最左边滑到最右边吗？他不一定吧，哦我举一个最简单的例子啊，现在是一个。

4乘以4啊，sorry，我这个图画的真是很尴尬啊，我是一个4乘以4的一个窗口。好，如果现在是我取4乘以4的一幅图，如果我取了一个3乘以3的窗口，我要求他说你每次给我划两步。你告诉我说他从这个位置滑两步。

他滑到哪了？他冲出去了，对吗？所以它不能刚好从最左边滑到最右边，对吗？对他不能整除。所以为了让它整除，我会做一个事情。我会在边缘补一圈磷。这一圈一圈或者是多圈零。

这些补零的值就叫做zero patterndding，它叫做填充值，它叫做补零值。好。到目前为止，我给大家解释了这三个概念，我再回过头来说一遍啊，这次大家听清楚。如果刚才没有听清楚的同学，这次听清楚啊。

本来我是跟大家我是跟大家说，希望大家下去以后看视频的那既然你有同学还没有没有清楚的话，我就再说一遍。这有5个小朋友，12345。这5个小朋友，每一个小朋友自己有自己一套处事的方式。

这体现在他自己在这个窗口滑动的过程中，自己的这一组W是不动的。这自己的这一组W是固定的。但是你不能要求说郭敬明和韩寒必须有一样的世界观。这个要求太高了。所以。2号小朋友去看这个视图的时候。

它也可以3乘以3的窗口不断的滑动，去看这个事情，去看这幅图。

![](img/a84eaa83ac6506943134bf4222d8ec7f_2.png)

所以他也会有自己的9个自己的世界观，自己的9个值组成W2，对吗？所以但是你不能要求说郭敬明的W一和韩寒的W2是一样的，这个要求太高了。这就我回答了刚才大家的那个问题，我说W1和W2。

每个小朋友的哎W是不一样的，只是他自己在做这个事情的时候，你要以身作则，要自己要要要表里如一O。好。好，所以这个问题我给大家解释清楚了吧。那刚才还有大家还有什么问题？刚才说厚度不知道是什么，对吧？

厚度你有多少个小朋友厚度就是多少feature map的意思是，待会我会做运算，我会每一个小朋友看这幅图不是干看的。你看完以后你要告诉我，你看到了什么，你看到你看到的东西，你吐出来的东西。

你就得组成一个东，组成一个矩阵，新的矩阵，它叫做feature map，就这个意思，好吧。这一页大家有问题吗？还有问题吗？呃，抱歉啊，有一个动态的图，我现。选一下啊，抱歉抱歉。

我应该课前先把这一页打开的。求角C。哦，我们先开一页。但我不太确定这个图在我们的页面。sorry，我这网有点慢。啊，我现在先把这个网页打开啊，sorry，我们先我们回到这个地方，一会儿再看啊。

先给大家说。

![](img/a84eaa83ac6506943134bf4222d8ec7f_4.png)

W1和W2是9个数。如果这9个数字不一样，W1和W2是不是就不一样？这就是一组权重而已。你换了一组组权重，是不是这个神经网络就不一样了？就是这个意思，好吧，不一样就体现在这儿。

而这个W1W2是用来做运算的O。我们要看看他是怎么算这个事情的，我们看看他是怎么做这个事情的。好吧，我们看一看他怎么做这个事情的。这是一个很简单的一个点乘。我刚才取了一个3乘以3的数据窗口，对吗？

我希望大家理解这些东西的时候，能够灵活一点。神经网络并没有是横着还是竖着的。你告诉我说，每个人体内的神经网络到是横着排的还是竖着排的。你今天躺着它就变成横着了，你站起来它就变成竖着了。ok。😊。

所以不存在横着或者竖的，它只是代表我我有这么多个神经元好吗？这么个多这么厚的 depths。没有所谓横着或者竖着啊，没有这种说法，好吧。😡，大家大家跟着这个东西接着往后往后听啊，有问题的。

一会儿一会儿再问，集中回答好不好？好吧。😊，所以我有窗口3乘以3的数据窗口data窗口，对吧？我的这个窗口会不会滑会滑动，对不对？好，我不管它滑动这个事情，我们先看看它的落它定在某一个每一个位置的时候。

我是怎么去做这个运算的。你的这一组W是不是9个数啊？所以这W是不是3乘以3的一个矩阵呢？举证和举证之间可以去做很多的运算，对吗？这个时候我们做的运算是什么呢？每一个小朋友看到每一块区域的时候。

它会吐出来一个数。它读数这个数是怎么去做计算的呢？看清楚了，你会有3乘以3的这么一个data matrix数据矩阵。严格意义上来说，它是它有三层啊，因为有RGB3个颜色通道，我们先不管这个啊。

3乘以3的，我们先看最简单的形式啊，假设它没有三个颜色通道，它只有一个颜色通道啊，灰度图，所以是3乘以3的矩阵，数据矩阵，对吧？你会有一个W，对不对？W是一个权重矩阵，它是3乘以3的一个权重矩阵。

所以由数据。和W怎么去得到它现在吐出来的这个数呢？或者说他看完这个小块以后，他告诉我一个值，这个值它怎么算出来的呢？非常非常简单，在这儿。看清楚啊，第一个位置是零对吗？和零去做乘法，第二个位置是零对吗？

去和零做乘法，最后一个位置是二，对吗？就和最后一个位置-4做乘法，再把所有乘法得到的值求和，得到这个-8。我说明白了吗？每一个小朋友在每一个区域的每一个块固定住的时候做的运算是什么？

你会看到其他的形式啊，我多提一句，你会看到有些地方有一个bios，有一个偏志向。大家知道我计算的时候，Y等于WX它是过原点的一条直线。有时候为了更准确的拟合。它会有个B，对吧？所以你在有些书上啊。

你会看到它做完这个点乘之后，最后会加一个偏质向，会加一个偏质向，好吧。所以呃这个这个都无所谓这个无所谓啊，加加不加偏之项。大家知道运算是怎么来怎么算的。对吧就是一个内机操作。

一个eleement wise一个乘法。

![](img/a84eaa83ac6506943134bf4222d8ec7f_6.png)

有问题吗？我看看图出来了图出来了。

![](img/a84eaa83ac6506943134bf4222d8ec7f_8.png)

大家能看到这幅图吗？

![](img/a84eaa83ac6506943134bf4222d8ec7f_10.png)

这是一个动态的。流程。

![](img/a84eaa83ac6506943134bf4222d8ec7f_12.png)

这个流程比刚才复杂一点点，复杂的一点在哪儿呢？在于大家看最左侧，这是图像。

![](img/a84eaa83ac6506943134bf4222d8ec7f_14.png)

这左侧的图像是RGB3个颜色通道，所以你会看到三个矩阵。第一个矩阵表示在R通道上的矩阵。第二个矩阵在B通道上的矩阵啊，记第三个矩阵在B上面的，没问题吧，所以是7乘以7乘以3这么一个三维的矩阵，有问题吗？



![](img/a84eaa83ac6506943134bf4222d8ec7f_16.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_17.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_18.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_19.png)

对。

![](img/a84eaa83ac6506943134bf4222d8ec7f_21.png)

这张图最左侧我跟大家说明白了吗？好。😊。

![](img/a84eaa83ac6506943134bf4222d8ec7f_23.png)

中间会有两列红色的两列。

![](img/a84eaa83ac6506943134bf4222d8ec7f_25.png)

听清楚了。这两地呀。每一列是一个神经元。

![](img/a84eaa83ac6506943134bf4222d8ec7f_27.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_28.png)

因为你郭敬明同小同小朋友在看这幅图的时候，必须要把RGB3个颜色通道全都看进来。

![](img/a84eaa83ac6506943134bf4222d8ec7f_30.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_31.png)

你不是色盲，对吗？所以所有的颜色，每个颜色通道你都应该看进来，对吗？

![](img/a84eaa83ac6506943134bf4222d8ec7f_33.png)

所以他去看这幅图的时候啊，不要大家不要跟我说是有6个6个神经元在这啊，只有两个神经元，中间的filterW1和filter W2只有两个神经元。只不过郭敬明和韩寒现在在看这幅图的时候。

所有的颜色他都必须看进来。所以每个神经元你会发现你看到现在固定一个位置的时候，一个矩阵的时候，他会看RGB3个颜色通道的值。



![](img/a84eaa83ac6506943134bf4222d8ec7f_35.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_36.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_37.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_38.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_39.png)

有问题吗？这个大家有问题吗？

![](img/a84eaa83ac6506943134bf4222d8ec7f_41.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_42.png)

O好。

![](img/a84eaa83ac6506943134bf4222d8ec7f_44.png)

做的运算完全一样。但是啊但是我强调一点啊，郭敬明小朋友是不是可以。

![](img/a84eaa83ac6506943134bf4222d8ec7f_46.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_47.png)

每个人在看这个世界的时候，你告诉我其实。严格意义上来，从生物学上来说，每个人看这个世界的颜色的深浅，明亮度是不一样的对吗？



![](img/a84eaa83ac6506943134bf4222d8ec7f_49.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_50.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_51.png)

所以郭敬明小朋友在RGB3个颜色通道上，你不能要求人家说我必须要用同样的W。

![](img/a84eaa83ac6506943134bf4222d8ec7f_53.png)

你不你不需要去做这个事情，所以你会看到我每一个郭敬明和韩寒两个小朋友呢都有两他的两个两组矩阵里头也都有三个矩阵，三个小矩阵，说明我可以去看三个颜色通道的时候，可以用不同的W。



![](img/a84eaa83ac6506943134bf4222d8ec7f_55.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_56.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_57.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_58.png)

O。😊。

![](img/a84eaa83ac6506943134bf4222d8ec7f_60.png)

好吗？好，所以最后得到的结果一样啊，得到的结果就是eleimate voice的这个逐个元素的内积啊，点乘以后求和以后得到的值，好吧。



![](img/a84eaa83ac6506943134bf4222d8ec7f_62.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_63.png)

![](img/a84eaa83ac6506943134bf4222d8ec7f_64.png)

这个班上有很多的初学者，所以我希望卷基层我能给大家讲明白，因为后面的layer很简单，ok好吧。

![](img/a84eaa83ac6506943134bf4222d8ec7f_66.png)

别着急啊，卷辑视经网络我讲过很多次，所以这个这个进度我是清楚的，大家不要着急好吗？郭郭敬明和韩寒到底到底怎么认识这个世界的，取决于他怎么长大的，取决于他的训练数据，取决于他爸爸妈妈怎么告诉他的，好吗？

所以。W怎么来的？W是训练算法得到的。

![](img/a84eaa83ac6506943134bf4222d8ec7f_68.png)

好嘛。好，所以卷积神经网络通过刚才的这个方式，我们说每一个神经元啊，韩寒和郭敬明小朋友去看这幅图的时候，每次看一个部分，对不对？所以参数量是不是由原来的32乘以32直接降到9了呀，能理解吧？对不对？

所以这里头这个机性质叫做参数共享性质。因为我在看一幅图的时候，我看不同的数据块，我的每一个数据块里头连接的数据窗的这个权重W这9个值是固定的，OK好不好？所以。😊，他这个他这组东西你可以理解成一个模板。

因为W是9个数嘛，这9个数你可以看作一个template一个模板。他做的事情就是现在韩寒和郭敬明的世界观。他们看图像的方式，所以每个神经元只关注一个特性，有问题吗？没有特性啊，没有问题吧。

就是每个每个人只有自己的一套世界观，所以他只关注自己关注的东西，所以他只关注自己的那一套特性。那一个特性能明白吧？好，所以。去，但是通过这样一个操作，是不是就能够把。估算的权重拉下来啊。

原本你这个小朋友和前面32乘以32都要连接，都要有W，对吧？W是这么个高的维度的，现在W是不是降成9了？所以通过这样一个方式，我们一会会看到有一个网络叫alexnet，它可以从1亿个参数啊。

一层至持一层啊，从1亿降到3。5万。对吗？😡，那这个降幅大家看到了，一亿啊1亿是1万万能降到3。5万，而且它依旧能学到东西。然后如果大家对数学熟的话，一组固定的权重和不同的数据窗口内的数据去做内机啊。

大家学过这个信号信号处理，或者说信息理论的话，也不知道或者是数学啊更高级一点数学知识的话，大家知道这个操作叫做卷积嘛，对吧？



![](img/a84eaa83ac6506943134bf4222d8ec7f_70.png)

靠。