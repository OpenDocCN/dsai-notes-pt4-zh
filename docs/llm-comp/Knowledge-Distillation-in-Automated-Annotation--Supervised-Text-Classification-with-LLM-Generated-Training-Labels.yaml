- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-08 19:05:36'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 19:05:36
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Knowledge Distillation in Automated Annotation: Supervised Text Classification
    with LLM-Generated Training Labels'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动注释中的知识蒸馏：使用LLM生成的训练标签进行监督文本分类
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.17633](https://ar5iv.labs.arxiv.org/html/2406.17633)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2406.17633](https://ar5iv.labs.arxiv.org/html/2406.17633)
- en: Nicholas Pangakis    Samuel Wolken
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尼古拉斯·潘加基斯  塞缪尔·沃尔肯
- en: University of Pennsylvania
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 宾夕法尼亚大学
- en: '{njpang@sas., sam.wolken@asc.}upenn.edu'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '{njpang@sas., sam.wolken@asc.}upenn.edu'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Computational social science (CSS) practitioners often rely on human-labeled
    data to fine-tune supervised text classifiers. We assess the potential for researchers
    to augment or replace human-generated training data with surrogate training labels
    from generative large language models (LLMs). We introduce a recommended workflow
    and test this LLM application by replicating 14 classification tasks and measuring
    performance. We employ a novel corpus of English-language text classification
    data sets from recent CSS articles in high-impact journals. Because these data
    sets are stored in password-protected archives, our analyses are less prone to
    issues of contamination. For each task, we compare supervised classifiers fine-tuned
    using GPT-4 labels against classifiers fine-tuned with human annotations and against
    labels from GPT-4 and Mistral-7B with few-shot in-context learning. Our findings
    indicate that supervised classification models fine-tuned on LLM-generated labels
    perform comparably to models fine-tuned with labels from human annotators. Fine-tuning
    models using LLM-generated labels can be a fast, efficient and cost-effective
    method of building supervised text classifiers.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 计算社会科学（CSS）从业者经常依赖人为标注的数据来微调监督文本分类器。我们评估了研究人员用生成性大语言模型（LLMs）生成的替代训练标签来增强或替代人工生成的训练数据的潜力。我们介绍了一种推荐的工作流程，并通过复制14个分类任务并测量性能来测试这一LLM应用。我们采用了来自近期高影响力期刊的英文文本分类数据集的新颖语料库。由于这些数据集存储在受密码保护的档案中，我们的分析不容易受到污染问题的影响。对于每个任务，我们将使用GPT-4标签微调的监督分类器与使用人工标注微调的分类器以及与少量示例的GPT-4和Mistral-7B标签进行比较。我们的发现表明，基于LLM生成标签微调的监督分类模型与基于人工标注标签微调的模型表现相当。使用LLM生成标签进行微调可以成为构建监督文本分类器的一种快速、高效且具有成本效益的方法。
- en: 'Knowledge Distillation in Automated Annotation:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自动注释中的知识蒸馏：
- en: Supervised Text Classification with LLM-Generated Training Labels
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM生成训练标签的监督文本分类
- en: Nicholas Pangakis  and Samuel Wolken University of Pennsylvania {njpang@sas.,
    sam.wolken@asc.}upenn.edu
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尼古拉斯·潘加基斯 和 塞缪尔·沃尔肯 宾夕法尼亚大学 {njpang@sas., sam.wolken@asc.}upenn.edu
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Supervised text classification often relies on human-labeled text data for training
    and validation. Computational social science (CSS) researchers frequently use
    these types of supervised models to classify large quantities of text, ranging
    from news articles on the internet to government documents (Grimmer et al., [2022](#bib.bib16);
    Lazer et al., [2020](#bib.bib23)). Collecting training and validation labels generated
    by humans for these tasks, however, is expensive, slow, and prone to a variety
    of errors (Grimmer and Stewart, [2013](#bib.bib17); Neuendorf, [2016](#bib.bib30)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 监督文本分类通常依赖于人为标注的文本数据进行训练和验证。计算社会科学（CSS）研究人员经常使用这些类型的监督模型来分类大量文本，从互联网新闻文章到政府文件（Grimmer
    et al., [2022](#bib.bib16); Lazer et al., [2020](#bib.bib23)）。然而，为这些任务收集由人生成的训练和验证标签既昂贵又缓慢，而且容易出现各种错误（Grimmer
    and Stewart, [2013](#bib.bib17); Neuendorf, [2016](#bib.bib30)）。
- en: To address these limitations, prior research suggests utilizing few-shot capabilities
    of generative large language models (LLMs) to annotate text data instead of human
    annotators (Gilardi et al., [2023](#bib.bib13)). Generative LLMs are faster and
    cheaper than human annotators and do not suffer from common human challenges such
    as limited attention span or fatigue. While this approach has its limitations
    and generative LLMs do not excel at all text annotation tasks (Pangakis et al.,
    [2023](#bib.bib33)), prior research illustrates that there are numerous circumstances
    where generative LLMs can produce high quality text-annotation labels.¹¹1See Appendix
    A.1 for a longer discussion of automated annotation research in CSS.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些局限性，之前的研究建议利用生成型大型语言模型（LLMs）的少样本能力来标注文本数据，而不是依赖人工标注者（Gilardi et al., [2023](#bib.bib13)）。生成型
    LLM 比人工标注者更快、更便宜，并且不会遭遇如有限注意力范围或疲劳等常见的人类挑战。尽管这种方法有其局限性，生成型 LLM 在所有文本标注任务中并不出色（Pangakis
    et al., [2023](#bib.bib33)），但之前的研究表明，在许多情况下，生成型 LLM 能够产生高质量的文本标注标签。¹¹ 请参阅附录 A.1，了解
    CSS 中自动标注研究的更长讨论。
- en: Although past work suggests LLM few-shot annotation is highly effective, it
    may be cost prohibitive in many settings. Research with text data often involves
    classifying millions of documents or text samples. For example, a recent CSS article
    studies a data set of 6.2 million tweets labeled on four dimensions (Hopkins et al.,
    [2024](#bib.bib20)), a task that would have cost nearly $9,000 if using GPT-4
    alone.²²2Appendix A.2 elaborates on costs with LLM annotation. Using a knowledge
    distillation approach (Dasgupta et al., [2023](#bib.bib8); Gou et al., [2021](#bib.bib15);
    Hinton et al., [2015](#bib.bib19)), it may be possible to approximate the performance
    of a larger “teacher” model (e.g., GPT-4 (OpenAI, [2023](#bib.bib31)), estimated
    to have over 1.7T parameters (Schreiner, [2023](#bib.bib40))) with much smaller
    and cheaper task-specific “student” models (e.g., BERT Base (Devlin et al., [2019](#bib.bib9)),
    approximately 110 million parameters).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管过去的研究表明 LLM 少样本标注非常有效，但在许多环境中可能会成本过高。处理文本数据的研究通常涉及对数百万份文档或文本样本进行分类。例如，最近的一篇
    CSS 文章研究了一个包含 620 万条推文的数据集，这些推文在四个维度上进行了标注（Hopkins et al., [2024](#bib.bib20)），如果仅使用
    GPT-4 进行标注，这项任务的成本接近 9000 美元。²² 附录 A.2 详细说明了 LLM 标注的成本。通过使用知识蒸馏方法（Dasgupta et
    al., [2023](#bib.bib8); Gou et al., [2021](#bib.bib15); Hinton et al., [2015](#bib.bib19)），可以用更小、更便宜的任务特定“学生”模型（例如，BERT
    Base（Devlin et al., [2019](#bib.bib9)），约 1.1 亿个参数）来近似更大“教师”模型（例如，GPT-4（OpenAI,
    [2023](#bib.bib31)），估计有超过 1.7 万亿个参数（Schreiner, [2023](#bib.bib40)））的性能。
- en: In this paper, we evaluate using generative LLMs to create surrogate labels
    for fine-tuning downstream supervised classification models. Our approach involves
    first using a generative LLM to label a subset of text samples and then fine-tuning
    supervised text classifiers with the LLM-generated labels. Using our outlined
    approach, we replicate 14 classification tasks from recently published CSS articles.
    We compare several supervised classifiers (i.e., BERT (Devlin et al., [2019](#bib.bib9)),
    RoBERTa (Liu et al., [2019](#bib.bib25)), DistilBERT (Sanh et al., [2019](#bib.bib39)),
    XLNet (Yang et al., [2020](#bib.bib48)), and Mistral-7B (Jiang et al., [2023](#bib.bib21)))
    fine-tuned on varying quantities of either human-labeled samples or GPT-4-labeled
    samples. We benchmark the supervised classifiers’ performance against GPT-4 and
    Mistral-7B few-shot labels. In a series of ablation experiments, we also explore
    whether GPT-4 outputs change over time and how well the student models handle
    noise in the GPT-generated text labels.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们评估了使用生成型 LLM 创建代理标签以微调下游监督分类模型的方法。我们的方法首先使用生成型 LLM 对一部分文本样本进行标注，然后用 LLM
    生成的标签微调监督文本分类器。通过我们提出的方法，我们复制了最近发布的 14 个分类任务。我们比较了几种监督分类器（即 BERT（Devlin et al.,
    [2019](#bib.bib9)），RoBERTa（Liu et al., [2019](#bib.bib25)），DistilBERT（Sanh et
    al., [2019](#bib.bib39)），XLNet（Yang et al., [2020](#bib.bib48)），和 Mistral-7B（Jiang
    et al., [2023](#bib.bib21)））在不同数量的人工标注样本或 GPT-4 标注样本上进行微调的性能。我们将这些监督分类器的性能与 GPT-4
    和 Mistral-7B 少样本标签进行基准对比。在一系列消融实验中，我们还探讨了 GPT-4 输出是否会随时间变化，以及学生模型如何处理 GPT 生成的文本标签中的噪声。
- en: A small number of studies have utilized similar approaches in related domains.
    Chen et al. ([2023b](#bib.bib5)) use ChatGPT annotations to train various Graph
    Neural Networks for a fraction of the cost of human annotations. Golde et al.
    ([2023](#bib.bib14)) also harness ChatGPT to create surrogate text data that aligns
    with a specific valence (i.e., positive and negative) and then subsequently fine-tune
    a supervised classifier using the synthetic text. Most analogous to our approach
    here, Wang et al. ([2021](#bib.bib46)) train RoBERTa (Liu et al., [2019](#bib.bib25))
    and PEGASUS (Zhang et al., [2020](#bib.bib49)) models on labels generated by GPT-3\.
    Despite strong performance across their analyses, Wang et al. ([2021](#bib.bib46)),
    as well as the previously mentioned studies, exclusively evaluate closed-source
    models (i.e., GPT-3 and ChatGPT) on popular, publicly available NLP benchmark
    tasks (e.g., AGNews, DBPedia, etc), which are plausibly included in the training
    data for the generative LLM. As a result, these analyses cannot offer a clear
    indication of performance because their results plausibly suffer from contamination
    (Balepur et al., [2024](#bib.bib1); Li and Flanigan, [2023](#bib.bib24); Magar
    and Schwartz, [2022](#bib.bib26); Srivastava et al., [2024](#bib.bib41)). Put
    otherwise, strong performance may reflect memorization, which casts doubt on the
    generalizability of the findings.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 少量研究在相关领域中采用了类似的方法。Chen等人（[2023b](#bib.bib5)）利用ChatGPT注释以人类注释成本的一小部分训练各种图神经网络。Golde等人（[2023](#bib.bib14)）也利用ChatGPT创建与特定情感（即，积极和消极）相一致的代理文本数据，然后使用这些合成文本对监督分类器进行微调。最类似于我们这里的方法，Wang等人（[2021](#bib.bib46)）在GPT-3生成的标签上训练了RoBERTa（Liu等人，[2019](#bib.bib25)）和PEGASUS（Zhang等人，[2020](#bib.bib49)）模型。尽管他们的分析表现强劲，但Wang等人（[2021](#bib.bib46)）以及前述研究，均专门评估了封闭源模型（即GPT-3和ChatGPT）在流行的、公开的NLP基准任务（如AGNews、DBPedia等）上的表现，而这些任务很可能已包含在生成LLM的训练数据中。因此，这些分析无法提供明确的性能指示，因为其结果可能受到污染（Balepur等人，[2024](#bib.bib1)；Li和Flanigan，[2023](#bib.bib24)；Magar和Schwartz，[2022](#bib.bib26)；Srivastava等人，[2024](#bib.bib41)）。换句话说，强劲的表现可能反映了记忆，这对研究结果的普遍性提出了质疑。
- en: 'To compare supervised classifiers fine-tuned using LLM-generated labels against
    those fine-tuned with labels from human annotators, researchers must assess performance
    on tasks less likely to be affected by contamination. To this end, all 14 of the
    classification tasks we replicate are conducted on labeled data sets stored in
    password-protected archives. Each of the classification tasks in our corpus are
    real CSS applications and contain human-labeled ground-truth annotations.³³3Table
    [A2](#A2.T2 "Table A2 ‣ Appendix B Appendix: Data sets ‣ Knowledge Distillation
    in Automated Annotation: Supervised Text Classification with LLM-Generated Training
    Labels") and Table [A3](#A2.T3 "Table A3 ‣ Appendix B Appendix: Data sets ‣ Knowledge
    Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated
    Training Labels") include a full list of the data sets and classification tasks.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较使用LLM生成标签微调的监督分类器与使用人工标注者标签微调的分类器，研究人员必须评估在不太可能受到污染影响的任务上的表现。为此，我们复制的所有14个分类任务均在存储在密码保护档案中的标记数据集上进行。我们语料库中的每个分类任务都是真实的CSS应用程序，并包含人工标记的真实注释。³³3表[A2](#A2.T2
    "表A2 ‣ 附录B 附录：数据集 ‣ 知识蒸馏在自动标注中的应用：使用LLM生成的训练标签进行监督文本分类")和表[A3](#A2.T3 "表A3 ‣ 附录B
    附录：数据集 ‣ 知识蒸馏在自动标注中的应用：使用LLM生成的训练标签进行监督文本分类")包含了数据集和分类任务的完整列表。
- en: 'Our main contributions are as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要贡献如下：
- en: '1.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Across 14 classifications tasks, supervised models fine-tuned with GPT-generated
    labels perform comparably to models fine-tuned with human-labeled data. The median
    F1 performance gap between models fine-tuned using GPT-labels and models fine-tuned
    on human-labeled data is only 0.039\. While supervised classifiers fine-tuned
    with LLM-generated labels perform slightly worse than classifiers fine-tuned with
    human labels, LLM-generated labels can be a fast, efficient and cost-effective
    method to fine-tune supervised text classifiers.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在14个分类任务中，使用GPT生成标签微调的监督模型与使用人工标注数据微调的模型表现相当。使用GPT标签微调的模型与使用人工标注数据微调的模型之间的中位F1性能差距仅为0.039。虽然使用LLM生成标签微调的监督分类器的表现略逊于使用人工标签微调的分类器，但LLM生成的标签可以成为微调监督文本分类器的快速、高效和成本有效的方法。
- en: '2.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Supervised models fine-tuned on GPT-4 generated labels perform remarkably close
    to GPT few-shot models, with a median F1 difference of only 0.006 across the classification
    tasks.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 GPT-4 生成标签上微调的监督模型在分类任务中的表现与 GPT 少样本模型非常接近，F1 的中位数差异仅为 0.006。
- en: '3.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: GPT-4 few-shot models and supervised classifiers fine-tuned on GPT-4 generated
    labels perform significantly better than all other models on recall, but noticeably
    worse on precision.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 GPT-4 生成的标签上微调的 GPT-4 少样本模型和监督分类器在召回率上表现明显优于所有其他模型，但在精准度上明显较差。
- en: 2 Methodology
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法论
- en: ![Refer to caption](img/3dc83d5c2f23c64ae71be28492dec988.png)Human
    Annotator![Refer to caption](img/01788745c0e4bf6da005567f0027756d.png)Generative
    LLM1) Validate
    few-shot LLM on human-labels2) LLM generatestraining labels3) Train supervisedmodel4) Test model performanceon human-labeled data
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ![Refer to caption](img/3dc83d5c2f23c64ae71be28492dec988.png)Human
    Annotator![Refer to caption](img/01788745c0e4bf6da005567f0027756d.png)Generative
    LLM1) Validate
    few-shot LLM on human-labels2) LLM generatestraining labels3) Train supervisedmodel4) Test model performanceon human-labeled data
- en: 'Figure 1: Supervised text classification with LLM-generated training labels.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：使用 LLM 生成的训练标签进行的监督文本分类。
- en: '![Refer to caption](img/de93a69c88c2191246370a471dbc056d.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/de93a69c88c2191246370a471dbc056d.png)'
- en: 'Figure 2: Box plots of performance on test data across 14 tasks. Thick vertical
    line denotes median. Color represents model type, with green corresponding to
    models fine-tuned on 1,000 human labels, orange to 250 human labels, red to 1,000
    GPT labels, and blue to a few-shot model.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：14 个任务的测试数据性能箱线图。粗实线表示中位数。颜色表示模型类型，其中绿色对应于在 1000 个人工标签上微调的模型，橙色对应于 250 个人工标签，红色对应于
    1000 个 GPT 标签，蓝色对应于少样本模型。
- en: 'Figure [1](#S2.F1 "Figure 1 ‣ 2 Methodology ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    shows our four-step workflow. First, we validate LLM few-shot performance against
    a small subset (n=250) of human-labeled text samples for each task. We provide
    GPT-4⁴⁴4We select GPT-4 as our main generative model due to its high performance
    on popular leaderboard websites. In Appendix E.1, we also explore few-shot performance
    of an open-source model (i.e., Mistral-7B). with detailed instructions to label
    the text samples into conceptual categories outlined in the original study.⁵⁵5We
    include all prompt details in the supplementary material. We also include our
    code to query the GPT-4 API. Because LLM few-shot annotation performance varies
    across tasks and data sets, validation is always necessary (Pangakis et al., [2023](#bib.bib33)).
    As such, we validate each generative LLM on a subsample and then adjust the prompt
    to optimize performance on this initial sample. This process is discussed in greater
    detail in Appendix C.1\. Using the validated prompt, the second step in our workflow
    involves labeling an additional 1,000 text samples per task using the same generative
    LLM, which will later be used as data to fine-tune the supervised classifier.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S2.F1 "图 1 ‣ 2 方法论 ‣ 知识蒸馏在自动注释中的应用：使用 LLM 生成的训练标签进行的监督文本分类") 显示了我们的四步工作流程。首先，我们对每个任务使用人类标注的少量子集（n=250）验证
    LLM 的少样本性能。我们提供了 GPT-4⁴⁴4 我们选择 GPT-4 作为主要生成模型，因为它在流行的排行榜网站上的表现优异。在附录 E.1 中，我们还探索了开源模型（即
    Mistral-7B）的少样本性能。我们为 GPT-4 提供了详细的指示，以将文本样本标注为原始研究中概述的概念类别。⁵⁵5 我们在补充材料中包含了所有提示细节。我们还包括了查询
    GPT-4 API 的代码。由于 LLM 的少样本注释性能在任务和数据集之间存在差异，因此验证始终是必要的（Pangakis 等，[2023](#bib.bib33)）。因此，我们在子样本上验证每个生成型
    LLM，然后调整提示以优化在该初始样本上的性能。这个过程在附录 C.1 中有更详细的讨论。使用经过验证的提示，我们工作流程的第二步涉及使用相同的生成型 LLM
    标注每个任务的额外 1000 个文本样本，这些样本将用于后续微调监督分类器。
- en: In the third and fourth steps, we fine-tune a variety of supervised text classifiers
    and assess performance against a held-out set of 1000 human-labeled samples. Our
    supervised models include a variety of BERT-family models (i.e., BERT, RoBERTa,
    and DistilBERT).⁶⁶6We select these models because of their low cost, speed, and
    their frequent application in CSS (Büyüköz et al., [2020](#bib.bib2); Terechshenko
    et al., [2020](#bib.bib42)). In Appendix E.1, we conduct ablation experiments
    with XLNet and Mistral-7B. Appendix C.2 describes on our hyperparameter tuning
    process and additional evaluation details, including how multi-class tasks were
    split into separate binary tasks. Ultimately, we compare performance between text
    classifiers fine-tuned on 1000 LLM-generated samples, 250 human-labeled samples,
    and 1000 human-labeled samples.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三步和第四步中，我们微调了多种监督文本分类器，并评估了其在1000个人工标注样本上的表现。我们的监督模型包括多种 BERT 系列模型（即 BERT、RoBERTa
    和 DistilBERT）。⁶⁶6 我们选择这些模型是因为它们的成本低、速度快，并且它们在 CSS 中的应用很频繁（Büyüköz 等，[2020](#bib.bib2)；Terechshenko
    等，[2020](#bib.bib42)）。在附录 E.1 中，我们使用 XLNet 和 Mistral-7B 进行了消融实验。附录 C.2 介绍了我们的超参数调整过程和额外的评估细节，包括如何将多类别任务拆分为单独的二分类任务。最终，我们比较了在
    1000 个 LLM 生成样本、250 个人工标注样本和 1000 个人工标注样本上微调的文本分类器的性能。
- en: In addition to analyzing performance across different model architectures and
    training sample sizes, we also implement a variety of ablation experiments to
    assess how robust the analyses are to several sources of variance. First, we examine
    how robust these models are to noisy GPT-generated labels. Specifically, in Appendix
    E, we implement a novel technique designed to measure noise in GPT-generated labels
    and then compare supervised models fine-tuned on GPT-generated labels with noise
    against models fine-tuned on GPT-generated labels without noise. In a second set
    of ablation experiments, we replicate the GPT-4 few-shot labels at different points
    in time. To account for the potential of changing model weights in GPT-4, we re-analyzed
    each task six months after our initial analyses and compared results across time.
    Extended discussion and the results for these ablation experiments are shown in
    Appendix E.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分析不同模型架构和训练样本大小下的性能外，我们还实施了多种消融实验，以评估分析对多个方差来源的稳健性。首先，我们检查这些模型对噪声的鲁棒性，噪声来自GPT生成的标签。具体来说，在附录E中，我们实施了一种新颖的技术，旨在测量GPT生成标签中的噪声，然后将监督模型在有噪声的GPT生成标签上进行微调与在无噪声的GPT生成标签上进行微调的模型进行比较。在第二组消融实验中，我们在不同时间点复制GPT-4的少量标签。为了考虑GPT-4模型权重可能发生变化的可能性，我们在最初分析六个月后重新分析了每个任务，并比较了随时间的结果。对这些消融实验的扩展讨论和结果见附录E。
- en: '| Model | Training data | Accuracy | F1 | Precision | Recall |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 训练数据 | 准确率 | F1 | 精确度 | 召回率 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| GPT-4 | Few shot | 0.88 | 0.59 | 0.51 | 0.80 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 少量样本 | 0.88 | 0.59 | 0.51 | 0.80 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| BERT | Human annotation: 250 | 0.89 | 0.34 | 0.59 | 0.30 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| BERT | 人工标注: 250 | 0.89 | 0.34 | 0.59 | 0.30 |'
- en: '| Human annotation: 1000 | 0.92 | 0.62 | 0.71 | 0.54 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 人工标注: 1000 | 0.92 | 0.62 | 0.71 | 0.54 |'
- en: '| GPT-4 annotation: 1000 | 0.87 | 0.59 | 0.50 | 0.74 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4标注: 1000 | 0.87 | 0.59 | 0.50 | 0.74 |'
- en: '| DistilBERT | Human annotation: 250 | 0.89 | 0.36 | 0.53 | 0.32 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT | 人工标注: 250 | 0.89 | 0.36 | 0.53 | 0.32 |'
- en: '| Human annotation: 1000 | 0.89 | 0.64 | 0.66 | 0.61 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 人工标注: 1000 | 0.89 | 0.64 | 0.66 | 0.61 |'
- en: '| GPT-4 annotation: 1000 | 0.85 | 0.54 | 0.43 | 0.75 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4标注: 1000 | 0.85 | 0.54 | 0.43 | 0.75 |'
- en: '| RoBERTa | Human annotation: 250 | 0.88 | 0.37 | 0.48 | 0.32 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa | 人工标注: 250 | 0.88 | 0.37 | 0.48 | 0.32 |'
- en: '| Human annotation: 1000 | 0.90 | 0.55 | 0.54 | 0.53 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 人工标注: 1000 | 0.90 | 0.55 | 0.54 | 0.53 |'
- en: '| GPT-4 annotation: 1000 | 0.84 | 0.42 | 0.38 | 0.58 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4标注: 1000 | 0.84 | 0.42 | 0.38 | 0.58 |'
- en: 'Table 1: Comparison of classification performance on held-out validation data.
    Median performance across 14 tasks shown.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '表1: 在保留的验证数据上的分类性能比较。显示了14个任务中的中位数性能。'
- en: 3 Results
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 结果
- en: 'Classification results for the BERT-family models and GPT-4 few-shot are shown
    in Table [1](#S2.T1 "Table 1 ‣ 2 Methodology ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels").⁷⁷7We
    conduct few-shot classification by using the classification instructions from
    the original study as a prompt for the LLM. In Figure [2](#S2.F2 "Figure 2 ‣ 2
    Methodology ‣ Knowledge Distillation in Automated Annotation: Supervised Text
    Classification with LLM-Generated Training Labels"), each box plot displays the
    range of evaluation metrics across all 14 tasks for a given model/training data
    combination. The thick vertical line denotes the median performance metric across
    all analyzed tasks. Across all 14 classification tasks, DistilBERT and BERT fine-tuned
    on 1000 human-samples are the highest performing models, with a median F1 score
    of 0.641 and 0.624, respectively.⁸⁸8We use F1 as our primary evaluation criteria
    due to class imbalance. Full results are shown in Table [A4](#A2.T4 "Table A4
    ‣ Appendix B Appendix: Data sets ‣ Knowledge Distillation in Automated Annotation:
    Supervised Text Classification with LLM-Generated Training Labels"). Not far behind,
    however, is the GPT-4 few-shot model (0.592 median F1) and BERT fine-tuned on
    1000 GPT-labeled samples (0.586 median F1). From this we draw two conclusions:
    First, models fine-tuned on few-shot surrogate labels from a generative LLM perform
    comparably to models fine-tuned on human labels. Despite a small performance gap,
    training supervised models on LLM-labeled data can be a quick, effective, and
    budget-friendly approach for constructing supervised text classifiers.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: BERT 系列模型和 GPT-4 少样本的分类结果见表 [1](#S2.T1 "表 1 ‣ 2 方法 ‣ 自动标注中的知识蒸馏：使用 LLM 生成训练标签的监督文本分类")。⁷⁷7
    我们通过使用原始研究中的分类指令作为 LLM 的提示来进行少样本分类。在图 [2](#S2.F2 "图 2 ‣ 2 方法 ‣ 自动标注中的知识蒸馏：使用 LLM
    生成训练标签的监督文本分类") 中，每个箱线图显示了给定模型/训练数据组合在所有 14 个任务中的评估指标范围。粗的垂直线表示所有分析任务的中位性能指标。在所有
    14 个分类任务中，基于 1000 人工样本微调的 DistilBERT 和 BERT 是表现最好的模型，分别具有 0.641 和 0.624 的中位 F1
    分数。⁸⁸8 由于类别不平衡，我们使用 F1 作为主要评估标准。完整结果见表 [A4](#A2.T4 "表 A4 ‣ 附录 B 附录：数据集 ‣ 自动标注中的知识蒸馏：使用
    LLM 生成训练标签的监督文本分类")。然而，GPT-4 少样本模型（0.592 中位 F1）和基于 1000 个 GPT 标签样本微调的 BERT（0.586
    中位 F1）也紧随其后。由此我们得出两个结论：首先，基于生成性 LLM 的少样本替代标签微调的模型在性能上与基于人工标签微调的模型相当。尽管存在小的性能差距，但在
    LLM 标签数据上训练监督模型可以成为构建监督文本分类器的一种快速、有效且经济实惠的方法。
- en: Second, models trained on surrogate labels from GPT-4 demonstrate very similar
    validation performance as labels from GPT-4 with few-shot in-context learning.
    As each additional GPT-4 query incurs more expense, researchers can save resources
    by avoiding classifying an entire data set using a generative LLM and instead
    use them to create training labels for a supervised model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，使用 GPT-4 生成的替代标签训练的模型在验证性能上与 GPT-4 的少样本上下文学习标签表现非常相似。由于每次额外的 GPT-4 查询都会产生更多费用，研究人员可以通过避免使用生成性
    LLM 对整个数据集进行分类，而是使用生成的标签为监督模型创建训练标签，从而节省资源。
- en: 'A secondary finding is that GPT few-shot models and supervised models trained
    on GPT-generated labels produce remarkably high performance on recall.⁹⁹9Appendix
    D displays PR curves for each of the BERT-family supervised models. GPT-4 few-shot
    (0.8 median recall) as well as DistilBERT and BERT fine-tuned on GPT-labels (both
    with 0.746 median recall) achieve significantly better median recall than any
    model fine-tuned with human labels. The opposite is true for precision: BERT fine-tuned
    on human-labels achieved the highest precision of the models tested, which was
    0.214 higher than median precision for BERT models fine-tuned on GPT-4 labels.
    Therefore, using surrogate training labels may be better suited for tasks where
    recall is prioritized over precision.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一个次要发现是，基于 GPT 生成标签训练的 GPT 少样本模型和监督模型在召回率上的表现非常高。⁹⁹9 附录 D 显示了 BERT 系列监督模型的 PR
    曲线。GPT-4 少样本模型（0.8 中位召回率）以及基于 GPT 标签微调的 DistilBERT 和 BERT（均为 0.746 中位召回率）在中位召回率上显著优于任何经过人工标签微调的模型。精度则正好相反：基于人工标签微调的
    BERT 模型在测试模型中获得了最高的精度，比基于 GPT-4 标签微调的 BERT 模型的中位精度高出 0.214。因此，使用替代训练标签可能更适合于召回优先于精度的任务。
- en: 4 Discussion
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 讨论
- en: Surrogate labels from generative LLMs offer a viable, low-resource strategy
    for fine-tuning task-specific supervised classifiers, but a few points of caution
    are worth emphasizing. As the variation in our few-shot results indicates, there
    are cases where GPT-4 performs poorly on classification tasks. While advancements
    in LLM technology and additional prompt engineering could mitigate these concerns,
    it is essential that researchers validate generative LLM performance against ground-truth
    human-labeled data. Downstream supervised classifiers will not mitigate bias or
    poor performance in LLM few-shot labels. Thus, while generative LLMs can improve
    the classification workflow, their application must remain human-centered.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 来自生成性LLM的代理标签提供了一种可行的低资源策略，用于微调任务特定的有监督分类器，但有几点注意事项值得强调。正如我们的少量示例结果所示，在分类任务中，GPT-4表现不佳。虽然LLM技术的进步和额外的提示工程可能缓解这些问题，但研究人员必须验证生成性LLM相对于真实标注数据的性能。下游的有监督分类器无法减轻LLM少量标签中的偏差或性能不佳。因此，尽管生成性LLM可以改善分类工作流，但其应用必须始终以人为中心。
- en: 5 Limitations
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 限制
- en: 'Here, we identify three main limitations of our analysis. First, as discussed
    in Section 4 and shown in full detail in Table [A4](#A2.T4 "Table A4 ‣ Appendix
    B Appendix: Data sets ‣ Knowledge Distillation in Automated Annotation: Supervised
    Text Classification with LLM-Generated Training Labels"), there are various circumstances
    where supervised models fine-tuned on LLM-generated labels fail to produce satisfactory
    results. This may be due to inaccurate annotations from GPT-4, poor performance
    from the supervised classifier, or both. While it is possible that additional
    prompt engineering or hyperparameter tuning could improve performance, it is essential
    to stress that each of these optimization strategies rely on human labels for
    comparison. As a result, we argue that it is essential to center human judgement
    as ground truth when optimizing models and adjudicating between models.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们确定了分析的三个主要限制。首先，如第4节讨论并在表格[A4](#A2.T4 "Table A4 ‣ Appendix B Appendix:
    Data sets ‣ Knowledge Distillation in Automated Annotation: Supervised Text Classification
    with LLM-Generated Training Labels")中详细显示的那样，在一些情况下，基于LLM生成标签的有监督模型未能产生令人满意的结果。这可能是由于GPT-4的标注不准确、有监督分类器表现不佳，或者两者都有。虽然额外的提示工程或超参数调优可能改善性能，但必须强调的是，这些优化策略依赖于人工标签进行比较。因此，我们认为在优化模型和评判模型时，以人工判断为真实数据是至关重要的。'
- en: A second, related limitation refers to understanding the errors in the model
    outputs. Specifically, it is possible that errors from a GPT-trained model produces
    correlated but unobservable errors. Building a supervised classifier on top of
    GPT-4 labels would magnify, rather than offset, any such biases. This, too, underscores
    the importance of human validation and error analysis. It is, of course, also
    essential to minimize bias by human annotators. For instance, recruiting human
    annotators from varying demographic backgrounds when conducting an annotation
    project may diminish the potential for correlated errors across annotators.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个相关的限制涉及理解模型输出中的错误。具体来说，GPT训练模型产生的错误可能是相关但不可观察的。在GPT-4标签之上构建有监督分类器会放大而不是抵消这些偏差。这也进一步强调了人工验证和错误分析的重要性。当然，减少人为标注者的偏差也是至关重要的。例如，在进行标注项目时招募来自不同人口背景的标注者，可以减少标注者之间潜在的相关错误。
- en: Finally, treating human labels as ground truth is an additional limitation.
    Although most data sets in our analysis employed multiple human coders, it is
    of course possible that these annotators made correlated errors. As a result,
    some disagreements between human ground truth labels and surrogate GPT-4 labels
    may stem from human error. Such errors could bias performance metrics downward
    for any of the models assessed. Because our primary interest is making comparisons
    across models, however, we are mainly interested in their relative performance.
    Because each model would suffer from the same errors in the human labeled data,
    we do not see this as a significant concern for this analysis.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将人工标签视为真实数据是一个额外的限制。尽管我们分析中的大多数数据集使用了多个人工编码员，但这些标注者可能存在相关错误。因此，人类真实标签与GPT-4代理标签之间的一些分歧可能源于人工错误。这些错误可能会使任何评估模型的性能指标向下偏差。然而，由于我们主要关注模型间的比较，因此我们主要关心的是它们的相对表现。由于每个模型在人工标注数据中都会遭受相同的错误，我们认为这对本分析不会构成重大问题。
- en: For the analysis in this paper, our reliance on text classification tasks and
    data from peer-reviewed research in high-impact journals helps to mitigate concerns
    about data annotation quality. The annotation procedures in each of these tasks
    received IRB approval and was assessed by independent reviewers to be of quality
    enough for publication in a high-impact journal. Still, it is important to acknowledge
    that applied researchers should invest in high-quality human labels, even if only
    to validate generative LLM annotation performance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本文中的分析，我们依赖于来自高影响力期刊的同行评审研究的数据和文本分类任务，以帮助减轻对数据标注质量的担忧。这些任务中的标注程序获得了 IRB 批准，并由独立评审人员评估为足够高的质量，以便在高影响力期刊上发表。尽管如此，值得承认的是，应用研究人员应该投资于高质量的人工标签，即使只是为了验证生成型
    LLM 标注性能。
- en: 6 Ethics Statement
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 伦理声明
- en: Our research complies with the ACL Ethics Policy. Specifically, our research
    positively contributes to society and human well-being by providing tools that
    can aid computational social scientists studying the social world. Using the methods
    we introduce and test will help scientists better understand a wide range of complicated
    social problems. Because the techniques proposed and assessed in this article
    require dramatically less resource expenditure than alternatives, our results
    can help address inequities in resources across researchers.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究符合 ACL 伦理政策。具体来说，我们的研究通过提供可以帮助计算社会科学家研究社会世界的工具，对社会和人类福祉产生了积极贡献。使用我们介绍和测试的方法将帮助科学家更好地理解各种复杂的社会问题。由于本文中提出和评估的技术所需的资源开支远低于其他替代方法，我们的结果可以帮助解决研究人员之间资源的不平等问题。
- en: Due to the inherent risks of deploying biased models, we stress the necessity
    of human validation throughout our paper. Given the ease and efficiency gains
    of using generative LLMs to train supervised classifiers, we believe it is essential
    to build rigorous testing and evaluation standards that are human-centered. This
    is why we took great efforts to center our analyses on data sets less prone to
    contamination risks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于部署有偏见模型的固有风险，我们强调了在整篇论文中进行人工验证的必要性。考虑到使用生成型 LLM 训练监督分类器的便利性和效率提升，我们认为建立以人为本的严格测试和评估标准至关重要。这就是为什么我们尽力将分析集中在污染风险较低的数据集上。
- en: Moreover, our research and data analysis does not cause any harm while also
    respecting privacy and confidentiality concerns. As we discuss in our data collection
    procedures in Appendix B, we conformed to each data repository’s usage and replication
    policies. Each of the original studies received IRB approval and our analyses
    conformed to the same safety protocols. All collected data was anonymized by the
    original authors. Appendix C.3 provides additional details on human annotation
    protocols, which were all conducted by the original studies and received IRB approval.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们的研究和数据分析不会造成任何伤害，同时也尊重隐私和保密问题。正如我们在附录 B 中讨论的数据收集程序所示，我们遵守了每个数据存储库的使用和复制政策。每项原始研究都获得了
    IRB 批准，我们的分析也遵循了相同的安全协议。所有收集的数据均由原作者进行了匿名处理。附录 C.3 提供了有关人工标注协议的更多细节，这些标注均由原始研究进行，并获得了
    IRB 批准。
- en: References
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Balepur et al. (2024) Nishant Balepur, Abhilasha Ravichander, and Rachel Rudinger.
    2024. [Artifacts or abduction: How do llms answer multiple-choice questions without
    the question?](http://arxiv.org/abs/2402.12483)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balepur 等人（2024）Nishant Balepur、Abhilasha Ravichander 和 Rachel Rudinger。2024年。[文物还是诱拐：LLMs
    如何在没有问题的情况下回答多项选择题？](http://arxiv.org/abs/2402.12483)
- en: Büyüköz et al. (2020) Berfu Büyüköz, Ali Hürriyetoğlu, and Arzucan Özgür. 2020.
    Analyzing elmo and distilbert on socio-political news classification. In *Proceedings
    of the Workshop on Automated Extraction of Socio-political Events from News 2020*,
    pages 9–18.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Büyüköz 等人（2020）Berfu Büyüköz、Ali Hürriyetoğlu 和 Arzucan Özgür。2020年。《分析 elmo
    和 distilbert 在社会政治新闻分类中的应用》。发表于 *2020年自动提取社会政治事件研讨会论文集*，第9–18页。
- en: Card et al. (2022) Dallas Card, Serina Chang, Chris Becker, Julia Mendelsohn,
    Rob Voigt, Leah Boustan, Ran Abramitzky, and Dan Jurafsky. 2022. [Computational
    analysis of 140 years of us political speeches reveals more positive but increasingly
    polarized framing of immigration](https://doi.org/https://doi.org/10.1073/pnas.2120510119).
    *Proceedings of the National Academy of Sciences of the United States of America*,
    31.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Card 等 (2022) Dallas Card、Serina Chang、Chris Becker、Julia Mendelsohn、Rob Voigt、Leah
    Boustan、Ran Abramitzky 和 Dan Jurafsky。2022。[对140年美国政治演讲的计算分析揭示了移民议题更加积极但日益两极化的框架](https://doi.org/https://doi.org/10.1073/pnas.2120510119)。*美国国家科学院院刊*，31。
- en: Chen et al. (2023a) Lingjiao Chen, Matei Zaharia, and James Zou. 2023a. [How
    is chatgpt’s behavior changing over time?](http://arxiv.org/abs/2307.09009)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2023a) Lingjiao Chen、Matei Zaharia 和 James Zou。2023a。[ChatGPT 的行为随时间变化的情况如何？](http://arxiv.org/abs/2307.09009)
- en: Chen et al. (2023b) Zhikai Chen, Haitao Mao, Hongzhi Wen, Haoyu Han, Wei Jin,
    Haiyang Zhang, and Hui Liuand Jiliang Tang. 2023b. [Label-free node classification
    on graphs with large language models (llms)](http://arxiv.org/abs/2310.04668).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2023b) Zhikai Chen、Haitao Mao、Hongzhi Wen、Haoyu Han、Wei Jin、Haiyang
    Zhang 和 Hui Liuand Jiliang Tang。2023b。[基于大规模语言模型 (LLMs) 的无标签节点分类](http://arxiv.org/abs/2310.04668)。
- en: Chiang and Lee (2023) Cheng-Han Chiang and Hung-yi Lee. 2023. Can large language
    models be an alternative to human evaluations? *arXiv preprint arXiv:2305.01937*.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang 和 Lee (2023) Cheng-Han Chiang 和 Hung-yi Lee。2023。大规模语言模型能否替代人工评估？*arXiv
    预印本 arXiv:2305.01937*。
- en: Chmielewski and Kucker (2020) Michael Chmielewski and Sarah C. Kucker. 2020.
    [An mturk crisis? shifts in data quality and the impact on study results](https://doi.org/10.1177/1948550619875149).
    *Social Psychological and Personality Science*, 11(4):464–473.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chmielewski 和 Kucker (2020) Michael Chmielewski 和 Sarah C. Kucker。2020。[mturk
    危机？数据质量的变化及其对研究结果的影响](https://doi.org/10.1177/1948550619875149)。*社会心理学与人格科学*，11(4):464–473。
- en: 'Dasgupta et al. (2023) Sayantan Dasgupta, Trevor Cohn, and Timothy Baldwin.
    2023. [Cost-effective distillation of large language models](https://doi.org/10.18653/v1/2023.findings-acl.463).
    In *Findings of the Association for Computational Linguistics: ACL 2023*, pages
    7346–7354, Toronto, Canada. Association for Computational Linguistics.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dasgupta 等 (2023) Sayantan Dasgupta、Trevor Cohn 和 Timothy Baldwin。2023。[大规模语言模型的成本效益蒸馏](https://doi.org/10.18653/v1/2023.findings-acl.463)。在
    *计算语言学协会年会：ACL 2023*，第7346–7354页，加拿大多伦多。计算语言学协会。
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Le, and Kristina
    Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language
    understanding. *In Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    Volume 1 (Long and Short Papers)*, page 4171–4186.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin 等 (2019) Jacob Devlin、Ming-Wei Chang、Kenton Le 和 Kristina Toutanova。2019。BERT：用于语言理解的深度双向变换器的预训练。*在2019年北美计算语言学协会年会：人类语言技术会议，卷1（长篇和短篇论文）*，第4171–4186页。
- en: Ding et al. (2022) Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq
    Joty, and Boyang Li. 2022. [Is gpt-3 a good data annotator?](http://arxiv.org/abs/2212.10450)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding 等 (2022) Bosheng Ding、Chengwei Qin、Linlin Liu、Lidong Bing、Shafiq Joty 和
    Boyang Li。2022。[GPT-3 是否是一个好的数据标注员？](http://arxiv.org/abs/2212.10450)
- en: 'Douglas et al. (2023) Benjamin D. Douglas, Patrick J. Ewell, and Markus Braue.
    2023. [Data quality in online human-subjects research: Comparisons between mturk,
    prolific, cloudresearch, qualtrics, and sona](https://doi.org/doi:10.1371/journal.pone.0279720).
    *PLoS One*, 18.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Douglas 等 (2023) Benjamin D. Douglas、Patrick J. Ewell 和 Markus Braue。2023。[在线人类受试者研究的数据质量：mturk、prolific、cloudresearch、qualtrics
    和 sona 之间的比较](https://doi.org/doi:10.1371/journal.pone.0279720)。*PLoS One*，18。
- en: Egami et al. (2022) Naoki Egami, Christian J. Fong, Justin Grimmer, Margaret E.
    Roberts, and Brandon M. Stewart. 2022. [How to make causal inferences using texts](https://doi.org/10.1126/sciadv.abg2652).
    *Science Advances*, 8(42):eabg2652.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Egami 等 (2022) Naoki Egami、Christian J. Fong、Justin Grimmer、Margaret E. Roberts
    和 Brandon M. Stewart。2022。[如何使用文本进行因果推断](https://doi.org/10.1126/sciadv.abg2652)。*科学进展*，8(42):eabg2652。
- en: Gilardi et al. (2023) Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. 2023.
    [Chatgpt outperforms crowd-workers for text-annotation tasks](http://arxiv.org/abs/2303.15056).
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gilardi 等 (2023) Fabrizio Gilardi、Meysam Alizadeh 和 Maël Kubli。2023。[ChatGPT
    在文本标注任务中优于众包工人](http://arxiv.org/abs/2303.15056)。
- en: 'Golde et al. (2023) Jonas Golde, Patrick Haller, Felix Hamborg, Julian Risch,
    and Alan Akbik. 2023. [Fabricator: An open source toolkit for generating labeled
    training data with teacher llms](http://arxiv.org/abs/2309.09582).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Golde et al. (2023) Jonas Golde, Patrick Haller, Felix Hamborg, Julian Risch,
    和 Alan Akbik. 2023. [Fabricator: 一个用于生成标注训练数据的开源工具包](http://arxiv.org/abs/2309.09582)。'
- en: 'Gou et al. (2021) Jianping Gou, Baosheng Yu, Stephen J. Maybank, and Dacheng
    Tao. 2021. Knowledge distillation: A survey. *International Journal of Computer
    Vision*, page 1789–1819.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gou et al. (2021) Jianping Gou, Baosheng Yu, Stephen J. Maybank, 和 Dacheng
    Tao. 2021. 知识蒸馏: 一项综述。*International Journal of Computer Vision*, 页 1789–1819。'
- en: 'Grimmer et al. (2022) Justin Grimmer, Margaret E. Roberts, and Brandon Stewart.
    2022. *Text as Data: A New Framework for Machine Learning and the Social Sciences*.
    Princeton University Press.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Grimmer et al. (2022) Justin Grimmer, Margaret E. Roberts, 和 Brandon Stewart.
    2022. *Text as Data: 机器学习与社会科学的新框架*。普林斯顿大学出版社。'
- en: 'Grimmer and Stewart (2013) Justin Grimmer and Brandon M. Stewart. 2013. [Text
    as data: The promise and pitfalls of automatic content analysis methods for political
    texts](http://www.jstor.org/stable/24572662). *Political Analysis*, 21(3):267–297.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Grimmer and Stewart (2013) Justin Grimmer 和 Brandon M. Stewart. 2013. [Text
    as data: 自动内容分析方法在政治文本中的承诺与陷阱](http://www.jstor.org/stable/24572662)。*Political
    Analysis*, 21(3):267–297。'
- en: 'He et al. (2023) Xingwei He, Zhenghao Lin, Yeyun Gong, A-Long Jin, Hang Zhang,
    Chen Lin, Jian Jiao, Siu Ming Yiu, Nan Duan, and Weizhu Chen. 2023. [Annollm:
    Making large language models to be better crowdsourced annotators](http://arxiv.org/abs/2303.16854).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'He et al. (2023) Xingwei He, Zhenghao Lin, Yeyun Gong, A-Long Jin, Hang Zhang,
    Chen Lin, Jian Jiao, Siu Ming Yiu, Nan Duan, 和 Weizhu Chen. 2023. [Annollm: 让大型语言模型成为更好的众包标注者](http://arxiv.org/abs/2303.16854)。'
- en: Hinton et al. (2015) Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. [Distilling
    the knowledge in a neural network](http://arxiv.org/abs/1503.02531).
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton et al. (2015) Geoffrey Hinton, Oriol Vinyals, 和 Jeff Dean. 2015. [蒸馏神经网络中的知识](http://arxiv.org/abs/1503.02531)。
- en: Hopkins et al. (2024) Daniel J. Hopkins, Yphtach Lelkes, and Samuel Wolken.
    2024. The rise of and demand for identity-oriented media coverage. *American Journal
    of Political Science*.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hopkins et al. (2024) Daniel J. Hopkins, Yphtach Lelkes, 和 Samuel Wolken. 2024.
    身份导向媒体覆盖的兴起与需求。*American Journal of Political Science*。
- en: Jiang et al. (2023) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. 2023. [Mistral 7b](http://arxiv.org/abs/2310.06825).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2023) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, 和
    William El Sayed. 2023. [Mistral 7b](http://arxiv.org/abs/2310.06825)。
- en: Kristensen-McLachlan et al. (2023) Ross Deans Kristensen-McLachlan, Miceal Canavan,
    Márton Kardos, Mia Jacobsen, and Lene Aarøe. 2023. Chatbots are not reliable text
    annotators.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kristensen-McLachlan et al. (2023) Ross Deans Kristensen-McLachlan, Miceal Canavan,
    Márton Kardos, Mia Jacobsen, 和 Lene Aarøe. 2023. 聊天机器人不是可靠的文本标注者。
- en: 'Lazer et al. (2020) David MJ Lazer, Alex Pentland, Duncan J Watts, Sinan Aral,
    Susan Athey, Noshir Contractor, Deen Freelon, Sandra Gonzalez-Bailon, Gary King,
    and Helen Margetts. 2020. [Computational social science: Obstacles and opportunities.](https://doi.org/10.1126/science.aaz8170)
    *Science*, 369(6507):1060–1062.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lazer et al. (2020) David MJ Lazer, Alex Pentland, Duncan J Watts, Sinan Aral,
    Susan Athey, Noshir Contractor, Deen Freelon, Sandra Gonzalez-Bailon, Gary King,
    和 Helen Margetts. 2020. [计算社会科学: 障碍与机遇](https://doi.org/10.1126/science.aaz8170)。*Science*,
    369(6507):1060–1062。'
- en: 'Li and Flanigan (2023) Changmao Li and Jeffrey Flanigan. 2023. [Task contamination:
    Language models may not be few-shot anymore.](http://arxiv.org/abs/2312.16337)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li and Flanigan (2023) Changmao Li 和 Jeffrey Flanigan. 2023. [任务污染: 语言模型可能不再是少样本学习](http://arxiv.org/abs/2312.16337)。'
- en: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
    [Roberta: A robustly optimized bert pretraining approach](http://arxiv.org/abs/1907.11692.).'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, 和 Veselin Stoyanov. 2019.
    [Roberta: 一种强健优化的bert预训练方法](http://arxiv.org/abs/1907.11692)。'
- en: 'Magar and Schwartz (2022) Inbal Magar and Roy Schwartz. 2022. [Data contamination:
    From memorization to exploitation.](http://arxiv.org/abs/2203.08242)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Magar and Schwartz (2022) Inbal Magar 和 Roy Schwartz. 2022. [数据污染: 从记忆到利用](http://arxiv.org/abs/2203.08242)。'
- en: 'McKinney (2011) Wes McKinney. 2011. pandas: a foundational python library for
    data analysis and statistics. *Python for high performance and scientific computing*,
    14(9):1–9.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McKinney (2011) Wes McKinney. 2011. pandas：一个用于数据分析和统计的基础 Python 库。*高性能和科学计算中的
    Python*，14(9):1–9。
- en: Mellon et al. (2022) Jonathan Mellon, Jack Bailey, Ralph Scott, James Breckwoldt,
    and Marta Miori. 2022. [Does gpt-3 know what the most important issue is? using
    large language models to code open-text social survey responses at scale](https://ssrn.com/abstract=4310154).
    Working paper.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mellon et al. (2022) Jonathan Mellon, Jack Bailey, Ralph Scott, James Breckwoldt,
    和 Marta Miori. 2022. [Gpt-3 是否知道最重要的问题是什么？使用大型语言模型大规模编码开放文本社会调查回应](https://ssrn.com/abstract=4310154)。工作论文。
- en: Müller (2022) Stefan Müller. 2022. The temporal focus of campaign communication.
    *The Journal of Politics*, 84(1):585–590.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Müller (2022) Stefan Müller. 2022. 《广告传播的时间焦点》。*政治学期刊*，84(1):585–590。
- en: Neuendorf (2016) Kimberly A. Neuendorf. 2016. *The Content Analysis Guidebook*.
    Sage Publications.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neuendorf (2016) Kimberly A. Neuendorf. 2016. *内容分析指南*。Sage Publications。
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. [Gpt-4 技术报告](http://arxiv.org/abs/2303.08774)。
- en: Pan et al. (2023) Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven
    Basart, Thomas Woodside, Hanlin Zhang, Scott Emmons, and Dan Hendrycks. 2023.
    Do the rewards justify the means? measuring trade-offs between rewards and ethical
    behavior in the machiavelli benchmark. *Proceedings of the 40th International
    Conference on Machine Learning*, pages 26837–26867.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan et al. (2023) Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven
    Basart, Thomas Woodside, Hanlin Zhang, Scott Emmons, 和 Dan Hendrycks. 2023. 奖励是否值得？衡量奖赏与伦理行为之间的权衡，基于
    Machiavelli 基准。*第40届国际机器学习会议论文集*，页码 26837–26867。
- en: Pangakis et al. (2023) Nicholas Pangakis, Samuel Wolken, and Neil Fasching.
    2023. [Automated annotation with generative ai requires validation](http://arxiv.org/abs/2306.00176).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pangakis et al. (2023) Nicholas Pangakis, Samuel Wolken, 和 Neil Fasching. 2023.
    [生成式人工智能的自动注释需要验证](http://arxiv.org/abs/2306.00176)。
- en: 'Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James
    Bradbury, Gregory Chanan, and Trevor Killeen et al. 2019. Pytorch: An imperative
    style, high-performance deep learning library. *Advances in neural information
    processing systems*.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James
    Bradbury, Gregory Chanan, 和 Trevor Killeen 等. 2019. Pytorch：一种命令式风格、高性能的深度学习库。*神经信息处理系统进展*。
- en: Peng et al. (2022) Hao Peng, Daniel M. Romero, and Emoke-Agnes Horvat. 2022.
    Dynamics of cross-platform attention to retracted papers. *Proceedings of the
    National Academy of Sciences*, 119(25):585–590.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng et al. (2022) Hao Peng, Daniel M. Romero, 和 Emoke-Agnes Horvat. 2022. 撤回论文的跨平台关注动态。*美国国家科学院院刊*，119(25):585–590。
- en: 'Reiss (2023) Michael Reiss. 2023. [Testing the reliability of chatgpt for text
    annotation and classification: A cautionary remark](https://doi.org/https://doi.org/10.31219/osf.io/rvy5p).
    Working paper.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reiss (2023) Michael Reiss. 2023. [测试 ChatGPT 在文本注释和分类中的可靠性：谨慎的备注](https://doi.org/https://doi.org/10.31219/osf.io/rvy5p)。工作论文。
- en: Rytting et al. (2023) Christopher Michael Rytting, Taylor Sorensen, Lisa Argyle,
    Ethan Busby, Nancy Fulda, Joshua Gubler, and David Wingate. 2023. [Towards coding
    social science datasets with language models](http://arxiv.org/abs/2306.02177).
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rytting et al. (2023) Christopher Michael Rytting, Taylor Sorensen, Lisa Argyle,
    Ethan Busby, Nancy Fulda, Joshua Gubler, 和 David Wingate. 2023. [朝向使用语言模型编码社会科学数据集](http://arxiv.org/abs/2306.02177)。
- en: Saha et al. (2023) Punyajoy Saha, Narla, Komal Kalyan, and Animesh Mukherjee.
    2023. [On the rise of fear speech in online social media](https://doi.org/https://doi.org/10.1073/pnas.2212270120).
    *Proceedings of the National Academy of Sciences of the United States of America*.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saha et al. (2023) Punyajoy Saha, Narla, Komal Kalyan, 和 Animesh Mukherjee.
    2023. [在线社交媒体中恐惧言论的上升](https://doi.org/https://doi.org/10.1073/pnas.2212270120)。*美国国家科学院院刊*。
- en: 'Sanh et al. (2019) Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas
    Wolf. 2019. [Distilbert, a distilled version of bert: smaller, faster, cheaper
    and lighter](http://arxiv.org/abs/1910.01108).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sanh et al. (2019) Victor Sanh, Lysandre Debut, Julien Chaumond, 和 Thomas Wolf.
    2019. [Distilbert：Bert 的精简版：更小、更快、更便宜、更轻](http://arxiv.org/abs/1910.01108)。
- en: Schreiner (2023) Maximilian Schreiner. 2023. [Gpt-4 architecture, datasets,
    costs and more leaked](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/).
    Blog post.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schreiner (2023) Maximilian Schreiner. 2023. [Gpt-4 架构、数据集、成本及更多泄露信息](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/)。博客文章。
- en: Srivastava et al. (2024) Saurabh Srivastava, Annarose M B, Anto P V au2, Shashank
    Menon, Ajay Sukumar, Adwaith Samod T, Alan Philipose, Stevin Prince, and Sooraj
    Thomas. 2024. [Functional benchmarks for robust evaluation of reasoning performance,
    and the reasoning gap](http://arxiv.org/abs/2402.19450).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava等人（2024）Saurabh Srivastava, Annarose M B, Anto P V au2, Shashank Menon,
    Ajay Sukumar, Adwaith Samod T, Alan Philipose, Stevin Prince和Sooraj Thomas。2024年。[用于推理性能鲁棒评估的功能基准及推理差距](http://arxiv.org/abs/2402.19450)。
- en: 'Terechshenko et al. (2020) Zhanna Terechshenko, Fridolin Linder, Vishakh Padmakumar,
    Michael Liu, Jonathan Nagler, Joshua A Tucker, and Richard Bonneau. 2020. A comparison
    of methods in political science text classification: Transfer learning language
    models for politics. *Working Paper*.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Terechshenko等人（2020）Zhanna Terechshenko, Fridolin Linder, Vishakh Padmakumar,
    Michael Liu, Jonathan Nagler, Joshua A Tucker和Richard Bonneau。2020年。政治学文本分类方法比较：政治的迁移学习语言模型。*工作论文*。
- en: 'Thapa et al. (2023) Surendrabikram Thapa, Usman Naseem, and Mehwish Nasim.
    2023. From humans to machines: can chatgpt-like llms effectively replace human
    annotators in nlp tasks. *Workshop Proceedings of the 17th International AAAI
    Conference on Web and Social Media*.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thapa等人（2023）Surendrabikram Thapa, Usman Naseem和Mehwish Nasim。2023年。从人类到机器：类似chatgpt的语言模型能否有效替代NLP任务中的人工标注员。*第17届国际AAAI网络与社交媒体会议论文集*。
- en: Törnberg (2023) Petter Törnberg. 2023. [Chatgpt-4 outperforms experts and crowd
    workers in annotating political twitter messages with zero-shot learning](http://arxiv.org/abs/2304.06588).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Törnberg（2023）Petter Törnberg。2023年。[ChatGPT-4在用零样本学习标注政治推特消息方面超越了专家和众包工作者](http://arxiv.org/abs/2304.06588)。
- en: 'Veselovsky et al. (2023) Veniamin Veselovsky, Manoel Horta Ribeiro, and Robert
    West. 2023. [Artificial artificial artificial intelligence: Crowd workers widely
    use large language models for text production tasks](http://arxiv.org/abs/2306.07899).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Veselovsky等人（2023）Veniamin Veselovsky, Manoel Horta Ribeiro和Robert West。2023年。[人工人工人工智能：众包工作者广泛使用大型语言模型进行文本生产任务](http://arxiv.org/abs/2306.07899)。
- en: Wang et al. (2021) Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, and Michael
    Zeng. 2021. [Want to reduce labeling cost? gpt-3 can help](http://arxiv.org/abs/2108.13487).
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2021）Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu和Michael Zeng。2021年。[想减少标注成本？GPT-3可以帮忙](http://arxiv.org/abs/2108.13487)。
- en: 'Wolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison and´ Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    and Alexander M. Rush. 2020. Transformers: State-of-the-art natural language processing.
    *In Proceedings of EMNLP.*'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf等人（2020）Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement
    Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison和Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest和Alexander
    M. Rush。2020年。Transformers：最先进的自然语言处理。*在EMNLP会议论文集*。
- en: 'Yang et al. (2020) Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan
    Salakhutdinov, and Quoc V. Le. 2020. [Xlnet: Generalized autoregressive pretraining
    for language understanding](http://arxiv.org/abs/1906.08237).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang等人（2020）Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov和Quoc
    V. Le。2020年。[XLNet：用于语言理解的广义自回归预训练](http://arxiv.org/abs/1906.08237)。
- en: 'Zhang et al. (2020) Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu.
    2020. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization.
    *International Conference on Machine Learning*, page 11328–11339.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人（2020）Jingqing Zhang, Yao Zhao, Mohammad Saleh和Peter Liu。2020年。Pegasus：用于抽象总结的提取式间隙句预训练。*国际机器学习会议*，第11328–11339页。
- en: Zhu et al. (2023) Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui, and Gareth
    Tyson. 2023. [Can chatgpt reproduce human-generated labels? a study of social
    computing tasks](http://arxiv.org/abs/2304.10145).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu等人（2023）Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan Hui和Gareth Tyson。2023年。[ChatGPT能否再现人工生成的标签？社交计算任务的研究](http://arxiv.org/abs/2304.10145)。
- en: Ziems et al. (2023) Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao
    Zhang, and Diyi Yang. 2023. [Can large language models transform computational
    social science?](https://calebziems.com/assets/pdf/preprints/css_chatgpt.pdf)
    Working paper.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziems等人（2023）Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang和Diyi
    Yang。2023年。[大型语言模型能否转变计算社会科学？](https://calebziems.com/assets/pdf/preprints/css_chatgpt.pdf)
    工作论文。
- en: 'Appendix A Appendix: Prior automated annotation research in computational social
    science'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A：计算社会科学中先前的自动标注研究
- en: '| GPT-4: Entire Corpus (n=6.2m) | GPT-4: n=1000 | Crowdworker: n=1000 | Trained
    Assistant: n=1000 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4: 整体语料库 (n=6.2m) | GPT-4: n=1000 | 众包工人: n=1000 | 训练助手: n=1000 |'
- en: '| $8,990 | $15 | $124 | $187 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| $8,990 | $15 | $124 | $187 |'
- en: 'Table A1: Comparing annotation costs applied to Hopkins et al. (2024).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '表 A1: 比较应用于 Hopkins et al. (2024) 的标注成本。'
- en: A.1 Overview of automated annotation research
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 自动化标注研究概述
- en: 'A growing body of research studying automated annotation claims that few-shot
    classifications from generative LLMs can match humans on annotation tasks (Chiang
    and Lee, [2023](#bib.bib6); Ding et al., [2022](#bib.bib10); Gilardi et al., [2023](#bib.bib13);
    He et al., [2023](#bib.bib18); Mellon et al., [2022](#bib.bib28); Pan et al.,
    [2023](#bib.bib32); Rytting et al., [2023](#bib.bib37); Thapa et al., [2023](#bib.bib43);
    Törnberg, [2023](#bib.bib44); Zhu et al., [2023](#bib.bib50); Ziems et al., [2023](#bib.bib51)).
    For example, Gilardi et al. ([2023](#bib.bib13)) find that LLMs outperform typical
    crowdsourced human annotators: “[t]he evidence is consistent across different
    types of texts and time periods. It strongly suggests that ChatGPT may already
    be a superior approach compared to crowd annotations on platforms such as MTurk.”
    Analyzing a range of social science applications, Rytting et al. ([2023](#bib.bib37))
    similarly write, “GPT-3 can match the performance of human coders [and in] some
    cases, it even outperforms humans in increasing intercoder agreement scores."
    Törnberg ([2023](#bib.bib44)) argues that automated annotations by LLMs in his
    analyses are even as accurate as annotations by human experts. While there are
    clearly circumstances where automated annotation fails to accurately reflect human
    judgment (Kristensen-McLachlan et al., [2023](#bib.bib22); Reiss, [2023](#bib.bib36)),
    researchers can safely use automated annotation procedures as long as they validate
    against human labels not prone to contamination (Pangakis et al., [2023](#bib.bib33)).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越多的研究表明，生成型大语言模型（LLM）的少量样本分类可以在标注任务上与人类相匹配（Chiang and Lee, [2023](#bib.bib6);
    Ding et al., [2022](#bib.bib10); Gilardi et al., [2023](#bib.bib13); He et al.,
    [2023](#bib.bib18); Mellon et al., [2022](#bib.bib28); Pan et al., [2023](#bib.bib32);
    Rytting et al., [2023](#bib.bib37); Thapa et al., [2023](#bib.bib43); Törnberg,
    [2023](#bib.bib44); Zhu et al., [2023](#bib.bib50); Ziems et al., [2023](#bib.bib51))。例如，Gilardi
    et al. ([2023](#bib.bib13)) 发现，LLM 的表现优于典型的众包人工标注者：“[t]这些证据在不同类型的文本和时间段中是一致的。强烈表明，ChatGPT
    可能已经是一种优于如 MTurk 这样平台上的众包标注的方法。” 分析了一系列社会科学应用后，Rytting et al. ([2023](#bib.bib37))
    同样写道：“GPT-3 可以匹配人类编码员的表现，[在]某些情况下，它甚至在提高编码员一致性分数方面超越了人类。” Törnberg ([2023](#bib.bib44))
    认为，他的分析中 LLM 的自动标注准确性甚至与人类专家的标注相当。尽管在某些情况下自动标注未能准确反映人类判断（Kristensen-McLachlan
    et al., [2023](#bib.bib22); Reiss, [2023](#bib.bib36)），研究人员只要与不易受污染的人类标签进行验证，就可以安全地使用自动化标注程序（Pangakis
    et al., [2023](#bib.bib33)）。
- en: A.2 Costs associated with implementing automated annotation
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 实施自动化标注的成本
- en: While prior research demonstrates that automated annotation can align with human
    reasoning in many scenarios, directly using the strategies introduced in prior
    studies to label an entire text corpus would be cost prohibitive when applied
    to a typical CSS data set, which often contain millions of observations. Consider
    the cost for using GPT-4 to label a data set of 6.2 million tweets, which is what
    Hopkins et al. ([2024](#bib.bib20)) analyze. At the time of writing, GPT-4 costs
    $0.01 per 1k input tokens and $0.03 per 1k output tokens, with 1000 tokens corresponding
    to roughly 750 words.^(10)^(10)10See [https://openai.com/pricing](https://openai.com/pricing)
    The prompt instructions to replicate Hopkins et al. (2024) contained approximately
    500 words and the average tweet length was around 25 words. Because the full corpus
    contained 6.2 million tweets and the code to query the OpenAI API was implemented
    in batches of 10 tweets, a full automated annotation to process the corpus in
    Hopkins et al. ([2024](#bib.bib20)) would require 620,000 batches fed into GPT-4\.
    Each batch (i.e., 750 words per input) corresponds to roughly 1,000 input tokens,
    per OpenAI’s suggested benchmark. Since the outputs were standardized, the outputs
    for these analyses tended to be around 150 tokens.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然先前的研究表明，自动化标注在许多情况下可以与人类推理对齐，但直接使用先前研究中介绍的策略来标注整个文本语料库在应用于典型的 CSS 数据集时会造成成本过高，这些数据集通常包含数百万个观察值。考虑使用
    GPT-4 标注 620 万条推文的数据集的成本，这正是 Hopkins 等人（[2024](#bib.bib20)）分析的内容。在撰写时，GPT-4 的费用为每
    1k 输入标记 $0.01，每 1k 输出标记 $0.03，其中 1000 个标记大约对应 750 个单词。^(10)^(10)10参见 [https://openai.com/pricing](https://openai.com/pricing)
    复制 Hopkins 等人（2024）的方法所需的提示说明大约包含 500 个单词，平均每条推文长度约为 25 个单词。由于整个语料库包含 620 万条推文，并且查询
    OpenAI API 的代码是以 10 条推文为一批进行的，对 Hopkins 等人（[2024](#bib.bib20)）的语料库进行完全自动化标注将需要
    620,000 批输入到 GPT-4 中。每批（即每个输入 750 个单词）大约对应 1,000 个输入标记，符合 OpenAI 建议的基准。由于输出是标准化的，这些分析的输出通常约为
    150 个标记。
- en: Thus, when broken down into tokens, the total number of processed input tokens
    for this analysis would be $1,000\times 620,000$. While this is a loose estimate,
    it illustrates the challenges posed by the marginal per-sample cost of automated
    LLM annotation for large-N CSS research. Using our approach, labeling 1,000 text
    samples and training a supervised classifier would cost under $15.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将其拆分为标记后，进行此分析的总处理输入标记数为 $1,000\times 620,000$。虽然这是一个粗略估计，但它展示了自动化 LLM 标注在大规模
    CSS 研究中所面临的边际单样本成本的挑战。使用我们的方法，标注 1,000 条文本样本并训练一个监督分类器的成本将低于 $15。
- en: Implementing our proposed workflow also reduces annotation labor costs. For
    example, hiring crowd-source workers to label a subset of text samples to serve
    as training observations would still cost significantly more than using automated
    annotation. Hopkins et al. ([2024](#bib.bib20)), for example, hire MTurk workers
    and paid them $0.06 to $0.07 per task depending on the total number of annotations
    ($15.00 per hour for six tasks per minute), which extrapolates to 360 tasks per
    hour. Under the standard assumption of three MTurk workers per task and taking
    a majority vote, the entire annotation time to label 1,000 tweets would have taken
    slightly under three hours and cost $124\. However, due to serious data quality
    concerns about crowd-workers (Chmielewski and Kucker, [2020](#bib.bib7); Douglas
    et al., [2023](#bib.bib11); Veselovsky et al., [2023](#bib.bib45)), a better cost
    comparison is against trained research assistants instead. Assuming 45 seconds
    per task and a $15 hourly rate, manually annotating 1,000 text samples would take
    12.5 hours and cost approximately $187.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 实施我们提出的工作流程还可以降低标注劳动成本。例如，雇佣众包工人对一部分文本样本进行标注以作为训练观察值的费用仍然比使用自动化标注要高得多。Hopkins
    等人（[2024](#bib.bib20)）例如，雇佣了 MTurk 工人并根据标注总数支付每个任务 $0.06 到 $0.07（每小时 $15.00，每分钟六个任务），这推算出每小时
    360 个任务。在标准假设下，每个任务有三个 MTurk 工人并采用多数投票，标注 1,000 条推文的整个时间稍低于三小时，成本为 $124。然而，由于对众包工人数据质量的严重担忧（Chmielewski
    和 Kucker，[2020](#bib.bib7)；Douglas 等人，[2023](#bib.bib11)；Veselovsky 等人，[2023](#bib.bib45)），一个更好的成本比较是与受过培训的研究助理相比。假设每个任务
    45 秒，每小时 $15 的工资，手动标注 1,000 条文本样本将花费 12.5 小时，成本大约为 $187。
- en: 'Table [A1](#A1.T1 "Table A1 ‣ Appendix A Appendix: Prior automated annotation
    research in computational social science ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    shows a comparison of these costs. Not only is automated annotation remarkably
    faster than human annotators, our procedures introduced here can cost researchers
    less than 10% the cost of typical alternatives. These efficiency gains are conservative
    in the sense that they disregard the time to find, hire, and train the annotator.^(11)^(11)11It
    is worth stressing here that validation against human-created labels is still
    essential. Therefore, researchers may want to prioritize their budgets for hiring
    domain experts to code a small subset of data to serve as validation and test
    data, as we demonstrate in Figure [1](#S2.F1 "Figure 1 ‣ 2 Methodology ‣ Knowledge
    Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated
    Training Labels"). Our cost efficiency calculations are based on training data,
    not validation and test sets.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [A1](#A1.T1 "Table A1 ‣ Appendix A Appendix: Prior automated annotation
    research in computational social science ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    显示了这些成本的比较。自动化注释不仅比人工注释快得多，我们在这里介绍的程序可以使研究人员的成本低于典型替代方案的10%。这些效率提升是保守的，因为它们忽略了寻找、雇佣和培训注释员的时间。^(11)^(11)11值得强调的是，与人工创建的标签进行验证仍然至关重要。因此，研究人员可能会想要优先考虑其预算，以雇佣领域专家对小部分数据进行编码，以便作为验证和测试数据，如我们在图
    [1](#S2.F1 "Figure 1 ‣ 2 Methodology ‣ Knowledge Distillation in Automated Annotation:
    Supervised Text Classification with LLM-Generated Training Labels") 中所示。我们的成本效率计算基于训练数据，而不是验证和测试集。'
- en: 'Appendix B Appendix: Data sets'
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 附录：数据集
- en: In this section, we elaborate on the data sets used in our analysis. Our corpus
    includes 14 classification tasks across five data sets representing recent applications
    in computational social science. To avoid the potential for contamination, we
    rely exclusively on data sets stored in password-protected data archives (e.g.,
    Dataverse). We draw from research published in outlets across a spectrum of disciplines
    ranging from interdisciplinary publications (e.g., Proceedings of the National
    Academy of Sciences) to high-impact field journals in social science (e.g., American
    Journal of Political Science). To find these articles, we searched journals for
    articles related to computational social science that implemented some type of
    manual annotation procedure. The human-labeled data from the original study is
    treated as the ground truth. We discuss the human annotation procedures in the
    original studies at greater length in Appendix C.3.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们详细阐述了在分析中使用的数据集。我们的语料库包括跨五个数据集的14个分类任务，这些数据集代表了计算社会科学中的最新应用。为了避免潜在的污染，我们完全依赖于存储在密码保护数据档案中的数据集（例如，Dataverse）。我们引用了在各种学科领域中发布的研究成果，从跨学科出版物（例如，《美国国家科学院院刊》）到社会科学领域的高影响力期刊（例如，《美国政治科学期刊》）。为了找到这些文章，我们搜索了与计算社会科学相关的期刊文章，这些文章实现了某种类型的手动注释程序。原始研究中的人工标记数据被视为真实数据。我们在附录C.3中详细讨论了原始研究中的人工注释程序。
- en: It is important to note that while the raw data (e.g., tweets and Facebook posts)
    may be included in the LLM pretraining data, the accompanying labels from the
    human annotators are certainly not included in the pretraining data. This is because
    the labels accompanying each text sample (e.g., whether a tweet referenced a specific
    racial identity frame) are not public-facing. If the text without the associated
    label is not included in the pretraining data, there is no cause for concern that
    the annotation task would suffer from contamination.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，虽然原始数据（例如，推文和Facebook帖子）可能包含在LLM预训练数据中，但来自人工注释员的附带标签肯定不包含在预训练数据中。这是因为每个文本样本的附带标签（例如，推文是否提到了特定的种族身份框架）不是公开的。如果没有附带标签的文本没有包含在预训练数据中，则无需担心注释任务会受到污染。
- en: 'Table [A2](#A2.T2 "Table A2 ‣ Appendix B Appendix: Data sets ‣ Knowledge Distillation
    in Automated Annotation: Supervised Text Classification with LLM-Generated Training
    Labels") and Table [A3](#A2.T3 "Table A3 ‣ Appendix B Appendix: Data sets ‣ Knowledge
    Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated
    Training Labels") contain the full details for every task and data set. Overall,
    our data encompass diverse degrees of class imbalance: Across tasks, the mean
    positive class frequency is 16.2%, the minimum is 0.04%, and the maximum is 61%.
    The sources of labels are representative of common approaches to annotation: 42.9%
    of tasks were annotated by crowdsourced workers, 28.6% by experts, and 28.6% by
    research assistants.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [A2](#A2.T2 "表 A2 ‣ 附录 B 附录：数据集 ‣ 知识蒸馏在自动注释中的应用：使用LLM生成的训练标签进行监督文本分类") 和表
    [A3](#A2.T3 "表 A3 ‣ 附录 B 附录：数据集 ‣ 知识蒸馏在自动注释中的应用：使用LLM生成的训练标签进行监督文本分类") 包含了每项任务和数据集的详细信息。总体而言，我们的数据涵盖了不同程度的类别不平衡：在各个任务中，正类的平均频率为16.2%，最小值为0.04%，最大值为61%。标签来源代表了常见的注释方法：42.9%的任务由众包工人注释，28.6%由专家注释，28.6%由研究助理注释。
- en: Our replications involve fine-tuning supervised classifiers using manually annotated
    data from the replication data sets. For every replication classification task,
    we conformed to each data repository’s replication policies. Each of the original
    studies received IRB approval and our analyses conformed to the same safety protocols,
    including full anonymization and agreeing to not publicly post the raw data without
    permission. As such, our replication of each data set is compatible with its intended
    usage.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的复现涉及使用手动标注的数据对监督分类器进行微调。对于每一个复现分类任务，我们都遵循了每个数据仓库的复现政策。每项原始研究都获得了伦理审查委员会（IRB）的批准，我们的分析也遵循了相同的安全协议，包括完全匿名化，并同意在未经许可的情况下不公开发布原始数据。因此，我们对每个数据集的复现与其预期用途是兼容的。
- en: Although all of the data sets were anonymized before our replications, we manually
    reviewed each data set to confirm privacy protections. One of the data sets (Saha
    et al., [2023](#bib.bib38)) contains hate speech, but this is because it is a
    central part of the research question from the original study. As a result, we
    include examples of hate speech in that particular replication. From manual review,
    no other data set contained offensive material.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所有数据集在复现前都已被匿名化，但我们手动审查了每个数据集以确认隐私保护。其中一个数据集（Saha et al., [2023](#bib.bib38)）包含仇恨言论，但这是因为这是原始研究问题的核心部分。因此，我们在该特定复现中包含了仇恨言论的示例。经过手动审查，没有其他数据集包含冒犯性材料。
- en: '| Author(s) | Title | Journal | Year |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 作者 | 标题 | 杂志 | 年份 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Card et al. | Computational analysis of 140 years of US political speeches
    reveals more positive but increasingly polarized framing of immigration | PNAS
    | 2022 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Card et al. | 对140年美国政治演讲的计算分析揭示了移民问题的更积极但日益极化的框架 | PNAS | 2022 |'
- en: '| Hopkins, Lelkes, and Wolken | The Rise of and Demand for Identity-Oriented
    Media Coverage | American Journal of Political Science | 2024 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins, Lelkes, and Wolken | 身份导向媒体报道的兴起与需求 | 美国政治科学杂志 | 2024 |'
- en: '| Müller | The Temporal Focus of Campaign Communication | Journal of Politics
    | 2021 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| Müller | 宣传沟通的时间焦点 | 政治学杂志 | 2021 |'
- en: '| Peng, Romero, and Horvat | Dynamics of cross-platform attention to retracted
    papers | PNAS | 2022 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Peng, Romero, and Horvat | 对撤回论文的跨平台关注动态 | PNAS | 2022 |'
- en: '| Saha et al. | On the rise of fear speech in online social media | PNAS |
    2022 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Saha et al. | 在线社交媒体中恐惧言论的兴起 | PNAS | 2022 |'
- en: 'Table A2: Replication data sources.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 表 A2：复现数据来源。
- en: '| Study | # of tasks | Annotation source | Classification tasks |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 研究 | 任务数量 | 注释来源 | 分类任务 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Card et al. (2022) | 4 | Research assistants | Classify US congressional
    speeches to identify whether the speech discussed immigration or immigration policy,
    along with an accompanying tone: pro-immigration, anti-immigration, or neutral.
    |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Card et al. (2022) | 4 | 研究助理 | 分类美国国会演讲，以确定演讲是否讨论了移民或移民政策，以及附带的语气：支持移民、反对移民或中立。
    |'
- en: '| Hopkins, Lelkes, and Wolken (2024) | 4 | Crowd | Classify headlines, Tweets,
    and Facebook share blurbs to identify references to social groups defined by a)
    race/ethnicity; b) gender/sexuality; c) politics; d) religion. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins, Lelkes, and Wolken (2024) | 4 | 众包 | 分类标题、推文和Facebook分享简述，以识别对以下社会群体的引用：a)
    种族/民族；b) 性别/性取向；c) 政治；d) 宗教。 |'
- en: '| Müller (2021) | 3 | Expert | Classify sentences from political party manifestos
    for temporal direction: past, present, or future. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| Müller (2021) | 3 | 专家 | 将政治党纲中的句子分类为时间方向：过去、现在或未来。 |'
- en: '| Peng, Romero, and Horvat (2022) | 1 | Expert | Classify whether Tweets express
    criticism of findings from academic papers. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Peng, Romero, and Horvat (2022) | 1 | Expert | 将推文分类为是否表达了对学术论文发现的批评。 |'
- en: '| Saha et al. (2020) | 2 | Crowd | Classify social media posts into fear speech,
    hate speech, both, or neither. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Saha et al. (2020) | 2 | Crowd | 将社交媒体帖子分类为恐惧言论、仇恨言论、两者皆有或均无。 |'
- en: 'Table A3: Descriptions of replication classification tasks.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 'Table A3: 复制分类任务的描述。'
- en: '| Data set | Task | Model | Training data |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 任务 | 模型 | 训练数据 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Few shot | Human: 250 | Human: 1000 | GPT: 1000 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Few shot | 人工：250 | 人工：1000 | GPT：1000 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Ac. | F1 | Pr. | Re. | Ac. | F1 | Pr. | Re. | Ac. | F1 | Pr. | Re. | Ac.
    | F1 | Pr. | Re. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Ac. | F1 | Pr. | Re. | Ac. | F1 | Pr. | Re. | Ac. | F1 | Pr. | Re. | Ac.
    | F1 | Pr. | Re. |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- |'
- en: '| Card et al. | Cat: Neg | GPT-4 | 0.85 | 0.65 | 0.54 | 0.83 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| Card et al. | Cat: Neg | GPT-4 | 0.85 | 0.65 | 0.54 | 0.83 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.88 | 0.58 | 0.74 | 0.48 | 0.87 | 0.56 | 0.65 | 0.49
    | 0.81 | 0.56 | 0.47 | 0.72 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.88 | 0.58 | 0.74 | 0.48 | 0.87 | 0.56 | 0.65 | 0.49
    | 0.81 | 0.56 | 0.47 | 0.72 |'
- en: '| RoBERTa |  |  |  |  | 0.85 | 0.51 | 0.59 | 0.45 | 0.84 | 0.48 | 0.55 | 0.42
    | 0.78 | 0.57 | 0.43 | 0.82 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.85 | 0.51 | 0.59 | 0.45 | 0.84 | 0.48 | 0.55 | 0.42
    | 0.78 | 0.57 | 0.43 | 0.82 |'
- en: '| DistilBERT |  |  |  |  | 0.86 | 0.56 | 0.61 | 0.51 | 0.86 | 0.58 | 0.61 |
    0.55 | 0.81 | 0.58 | 0.47 | 0.74 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.86 | 0.56 | 0.61 | 0.51 | 0.86 | 0.58 | 0.61 |
    0.55 | 0.81 | 0.58 | 0.47 | 0.74 |'
- en: '| Cat: Imm | GPT-4 | 0.81 | 0.81 | 0.74 | 0.90 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Cat: Imm | GPT-4 | 0.81 | 0.81 | 0.74 | 0.90 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.85 | 0.84 | 0.79 | 0.89 | 0.86 | 0.86 | 0.81 | 0.91
    | 0.84 | 0.83 | 0.76 | 0.91 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.85 | 0.84 | 0.79 | 0.89 | 0.86 | 0.86 | 0.81 | 0.91
    | 0.84 | 0.83 | 0.76 | 0.91 |'
- en: '| RoBERTa |  |  |  |  | 0.86 | 0.85 | 0.80 | 0.92 | 0.85 | 0.84 | 0.77 | 0.92
    | 0.82 | 0.82 | 0.74 | 0.92 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.86 | 0.85 | 0.80 | 0.92 | 0.85 | 0.84 | 0.77 | 0.92
    | 0.82 | 0.82 | 0.74 | 0.92 |'
- en: '| DistilBERT |  |  |  |  | 0.85 | 0.84 | 0.80 | 0.88 | 0.84 | 0.84 | 0.79 |
    0.89 | 0.82 | 0.82 | 0.73 | 0.92 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.85 | 0.84 | 0.80 | 0.88 | 0.84 | 0.84 | 0.79 |
    0.89 | 0.82 | 0.82 | 0.73 | 0.92 |'
- en: '| Cat: Neut. | GPT-4 | 0.83 | 0.26 | 0.27 | 0.25 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Cat: Neut. | GPT-4 | 0.83 | 0.26 | 0.27 | 0.25 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.80 | 0.35 | 0.29 | 0.44 | 0.85 | 0.36 | 0.38 | 0.35
    | 0.87 | 0.38 | 0.44 | 0.34 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.80 | 0.35 | 0.29 | 0.44 | 0.85 | 0.36 | 0.38 | 0.35
    | 0.87 | 0.38 | 0.44 | 0.34 |'
- en: '| RoBERTa |  |  |  |  | 0.88 | 0.30 | 0.46 | 0.23 | 0.88 | 0.00 | 0.00 | 0.00
    | 0.84 | 0.33 | 0.33 | 0.34 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.88 | 0.30 | 0.46 | 0.23 | 0.88 | 0.00 | 0.00 | 0.00
    | 0.84 | 0.33 | 0.33 | 0.34 |'
- en: '| DistilBERT |  |  |  |  | 0.85 | 0.28 | 0.32 | 0.25 | 0.85 | 0.36 | 0.37 |
    0.35 | 0.86 | 0.38 | 0.40 | 0.36 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.85 | 0.28 | 0.32 | 0.25 | 0.85 | 0.36 | 0.37 |
    0.35 | 0.86 | 0.38 | 0.40 | 0.36 |'
- en: '| Cat: Pro | GPT-4 | 0.88 | 0.50 | 0.55 | 0.46 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| Cat: Pro | GPT-4 | 0.88 | 0.50 | 0.55 | 0.46 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.86 | 0.33 | 0.44 | 0.27 | 0.84 | 0.44 | 0.42 | 0.46
    | 0.87 | 0.45 | 0.51 | 0.40 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.86 | 0.33 | 0.44 | 0.27 | 0.84 | 0.44 | 0.42 | 0.46
    | 0.87 | 0.45 | 0.51 | 0.40 |'
- en: '| RoBERTa |  |  |  |  | 0.87 | 0.37 | 0.51 | 0.30 | 0.84 | 0.37 | 0.41 | 0.34
    | 0.85 | 0.41 | 0.43 | 0.39 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.87 | 0.37 | 0.51 | 0.30 | 0.84 | 0.37 | 0.41 | 0.34
    | 0.85 | 0.41 | 0.43 | 0.39 |'
- en: '| DistilBERT |  |  |  |  | 0.87 | 0.29 | 0.55 | 0.19 | 0.83 | 0.38 | 0.38 |
    0.37 | 0.84 | 0.35 | 0.40 | 0.31 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.87 | 0.29 | 0.55 | 0.19 | 0.83 | 0.38 | 0.38 |
    0.37 | 0.84 | 0.35 | 0.40 | 0.31 |'
- en: '| Hopkins et al. | Political | GPT-4 | 0.88 | 0.43 | 0.30 | 0.79 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins et al. | 政治 | GPT-4 | 0.88 | 0.43 | 0.30 | 0.79 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.95 | 0.32 | 0.60 | 0.22 | 0.96 | 0.62 | 0.71 | 0.54
    | 0.82 | 0.34 | 0.21 | 0.82 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.95 | 0.32 | 0.60 | 0.22 | 0.96 | 0.62 | 0.71 | 0.54
    | 0.82 | 0.34 | 0.21 | 0.82 |'
- en: '| RoBERTa |  |  |  |  | 0.84 | 0.37 | 0.23 | 0.85 | 0.96 | 0.62 | 0.73 | 0.54
    | 0.84 | 0.37 | 0.23 | 0.85 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.84 | 0.37 | 0.23 | 0.85 | 0.96 | 0.62 | 0.73 | 0.54
    | 0.84 | 0.37 | 0.23 | 0.85 |'
- en: '| DistilBERT |  |  |  |  | 0.94 | 0.29 | 0.50 | 0.20 | 0.96 | 0.63 | 0.72 |
    0.56 | 0.83 | 0.34 | 0.22 | 0.80 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.94 | 0.29 | 0.50 | 0.20 | 0.96 | 0.63 | 0.72 |
    0.56 | 0.83 | 0.34 | 0.22 | 0.80 |'
- en: '| Gender | GPT-4 | 0.95 | 0.74 | 0.68 | 0.82 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 性别 | GPT-4 | 0.95 | 0.74 | 0.68 | 0.82 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.91 | 0.20 | 0.46 | 0.13 | 0.96 | 0.80 | 0.86 | 0.74
    | 0.94 | 0.72 | 0.62 | 0.85 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.91 | 0.20 | 0.46 | 0.13 | 0.96 | 0.80 | 0.86 | 0.74
    | 0.94 | 0.72 | 0.62 | 0.85 |'
- en: '| RoBERTa |  |  |  |  | 0.91 | 0.08 | 0.44 | 0.04 | 0.95 | 0.73 | 0.78 | 0.68
    | 0.92 | 0.67 | 0.54 | 0.87 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.91 | 0.08 | 0.44 | 0.04 | 0.95 | 0.73 | 0.78 | 0.68
    | 0.92 | 0.67 | 0.54 | 0.87 |'
- en: '| DistilBERT |  |  |  |  | 0.94 | 0.52 | 0.83 | 0.38 | 0.97 | 0.81 | 0.87 |
    0.75 | 0.93 | 0.71 | 0.59 | 0.88 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.94 | 0.52 | 0.83 | 0.38 | 0.97 | 0.81 | 0.87 |
    0.75 | 0.93 | 0.71 | 0.59 | 0.88 |'
- en: '| Race | GPT-4 | 0.96 | 0.57 | 0.41 | 0.92 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Race | GPT-4 | 0.96 | 0.57 | 0.41 | 0.92 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.97 | 0.00 | 0.00 | 0.00 | 0.98 | 0.56 | 0.71 | 0.46
    | 0.98 | 0.64 | 0.54 | 0.77 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.97 | 0.00 | 0.00 | 0.00 | 0.98 | 0.56 | 0.71 | 0.46
    | 0.98 | 0.64 | 0.54 | 0.77 |'
- en: '| RoBERTa |  |  |  |  | 0.97 | 0.00 | 0.00 | 0.00 | 0.97 | 0.00 | 0.00 | 0.00
    | 0.97 | 0.59 | 0.45 | 0.85 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.97 | 0.00 | 0.00 | 0.00 | 0.97 | 0.00 | 0.00 | 0.00
    | 0.97 | 0.59 | 0.45 | 0.85 |'
- en: '| DistilBERT |  |  |  |  | 0.97 | 0.00 | 0.00 | 0.00 | 0.99 | 0.71 | 0.77 |
    0.65 | 0.97 | 0.54 | 0.46 | 0.65 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.97 | 0.00 | 0.00 | 0.00 | 0.99 | 0.71 | 0.77 |
    0.65 | 0.97 | 0.54 | 0.46 | 0.65 |'
- en: '| Religion | GPT-4 | 0.98 | 0.61 | 0.47 | 0.88 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Religion | GPT-4 | 0.98 | 0.61 | 0.47 | 0.88 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.98 | 0.21 | 1.00 | 0.12 | 0.99 | 0.73 | 0.75 | 0.71
    | 0.98 | 0.61 | 0.48 | 0.82 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.98 | 0.21 | 1.00 | 0.12 | 0.99 | 0.73 | 0.75 | 0.71
    | 0.98 | 0.61 | 0.48 | 0.82 |'
- en: '| RoBERTa |  |  |  |  | 0.98 | 0.00 | 0.00 | 0.00 | 0.98 | 0.00 | 0.00 | 0.00
    | 0.98 | 0.00 | 0.00 | 0.00 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.98 | 0.00 | 0.00 | 0.00 | 0.98 | 0.00 | 0.00 | 0.00
    | 0.98 | 0.00 | 0.00 | 0.00 |'
- en: '| DistilBERT |  |  |  |  | 0.98 | 0.00 | 0.00 | 0.00 | 0.99 | 0.69 | 0.67 |
    0.71 | 0.97 | 0.53 | 0.37 | 0.94 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.98 | 0.00 | 0.00 | 0.00 | 0.99 | 0.69 | 0.67 |
    0.71 | 0.97 | 0.53 | 0.37 | 0.94 |'
- en: '| Müller | Future | GPT-4 | 0.82 | 0.85 | 0.87 | 0.83 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Müller | Future | GPT-4 | 0.82 | 0.85 | 0.87 | 0.83 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.83 | 0.85 | 0.88 | 0.84 | 0.82 | 0.85 | 0.85 | 0.85
    | 0.81 | 0.85 | 0.84 | 0.87 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.83 | 0.85 | 0.88 | 0.84 | 0.82 | 0.85 | 0.85 | 0.85
    | 0.81 | 0.85 | 0.84 | 0.87 |'
- en: '| RoBERTa |  |  |  |  | 0.84 | 0.87 | 0.87 | 0.88 | 0.82 | 0.85 | 0.86 | 0.85
    | 0.82 | 0.86 | 0.84 | 0.87 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.84 | 0.87 | 0.87 | 0.88 | 0.82 | 0.85 | 0.86 | 0.85
    | 0.82 | 0.86 | 0.84 | 0.87 |'
- en: '| DistilBERT |  |  |  |  | 0.83 | 0.86 | 0.85 | 0.86 | 0.81 | 0.84 | 0.87 |
    0.82 | 0.82 | 0.85 | 0.83 | 0.88 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.83 | 0.86 | 0.85 | 0.86 | 0.81 | 0.84 | 0.87 |
    0.82 | 0.82 | 0.85 | 0.83 | 0.88 |'
- en: '| Past | GPT-4 | 0.91 | 0.74 | 0.66 | 0.84 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Past | GPT-4 | 0.91 | 0.74 | 0.66 | 0.84 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.94 | 0.83 | 0.74 | 0.93 | 0.95 | 0.83 | 0.80 | 0.85
    | 0.93 | 0.79 | 0.71 | 0.89 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.94 | 0.83 | 0.74 | 0.93 | 0.95 | 0.83 | 0.80 | 0.85
    | 0.93 | 0.79 | 0.71 | 0.89 |'
- en: '| RoBERTa |  |  |  |  | 0.94 | 0.80 | 0.81 | 0.79 | 0.95 | 0.85 | 0.79 | 0.92
    | 0.85 | 0.00 | 0.00 | 0.00 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.94 | 0.80 | 0.81 | 0.79 | 0.95 | 0.85 | 0.79 | 0.92
    | 0.85 | 0.00 | 0.00 | 0.00 |'
- en: '| DistilBERT |  |  |  |  | 0.94 | 0.79 | 0.77 | 0.80 | 0.94 | 0.80 | 0.79 |
    0.82 | 0.93 | 0.79 | 0.68 | 0.96 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.94 | 0.79 | 0.77 | 0.80 | 0.94 | 0.80 | 0.79 |
    0.82 | 0.93 | 0.79 | 0.68 | 0.96 |'
- en: '| Present | GPT-4 | 0.82 | 0.62 | 0.64 | 0.60 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| Present | GPT-4 | 0.82 | 0.62 | 0.64 | 0.60 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.83 | 0.65 | 0.66 | 0.64 | 0.83 | 0.65 | 0.64 | 0.66
    | 0.81 | 0.61 | 0.63 | 0.58 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.83 | 0.65 | 0.66 | 0.64 | 0.83 | 0.65 | 0.64 | 0.66
    | 0.81 | 0.61 | 0.63 | 0.58 |'
- en: '| RoBERTa |  |  |  |  | 0.84 | 0.66 | 0.71 | 0.61 | 0.84 | 0.68 | 0.68 | 0.67
    | 0.83 | 0.61 | 0.68 | 0.56 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.84 | 0.66 | 0.71 | 0.61 | 0.84 | 0.68 | 0.68 | 0.67
    | 0.83 | 0.61 | 0.68 | 0.56 |'
- en: '| DistilBERT |  |  |  |  | 0.83 | 0.64 | 0.69 | 0.59 | 0.83 | 0.65 | 0.66 |
    0.64 | 0.82 | 0.59 | 0.66 | 0.54 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.83 | 0.64 | 0.69 | 0.59 | 0.83 | 0.65 | 0.66 |
    0.64 | 0.82 | 0.59 | 0.66 | 0.54 |'
- en: '| Peng et al. | Critical | GPT-4 | 0.85 | 0.54 | 0.48 | 0.63 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Peng et al. | Critical | GPT-4 | 0.85 | 0.54 | 0.48 | 0.63 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.87 | 0.43 | 0.59 | 0.34 | 0.91 | 0.63 | 0.76 | 0.54
    | 0.79 | 0.43 | 0.35 | 0.56 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.87 | 0.43 | 0.59 | 0.34 | 0.91 | 0.63 | 0.76 | 0.54
    | 0.79 | 0.43 | 0.35 | 0.56 |'
- en: '| RoBERTa |  |  |  |  | 0.88 | 0.44 | 0.61 | 0.34 | 0.87 | 0.62 | 0.54 | 0.73
    | 0.78 | 0.43 | 0.34 | 0.59 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.88 | 0.44 | 0.61 | 0.34 | 0.87 | 0.62 | 0.54 | 0.73
    | 0.78 | 0.43 | 0.34 | 0.59 |'
- en: '| DistilBERT |  |  |  |  | 0.83 | 0.43 | 0.42 | 0.44 | 0.86 | 0.54 | 0.50 |
    0.58 | 0.77 | 0.41 | 0.33 | 0.56 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.83 | 0.43 | 0.42 | 0.44 | 0.86 | 0.54 | 0.50 |
    0.58 | 0.77 | 0.41 | 0.33 | 0.56 |'
- en: '| Saha et al. | CV | GPT-4 | 0.97 | 0.06 | 0.03 | 0.25 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| Saha et al. | CV | GPT-4 | 0.97 | 0.06 | 0.03 | 0.25 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 1.00 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | 0.00 | 0.00
    | 0.94 | 0.03 | 0.02 | 0.25 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 1.00 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | 0.00 | 0.00
    | 0.94 | 0.03 | 0.02 | 0.25 |'
- en: '| RoBERTa |  |  |  |  | 1.00 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | 0.00 | 0.00
    | 0.93 | 0.05 | 0.03 | 0.50 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 1.00 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | 0.00 | 0.00
    | 0.93 | 0.05 | 0.03 | 0.50 |'
- en: '| DistilBERT |  |  |  |  | 1.00 | 0.00 | 0.00 | 0.00 | 0.99 | 0.00 | 0.00 |
    0.00 | 0.94 | 0.10 | 0.05 | 0.75 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 1.00 | 0.00 | 0.00 | 0.00 | 0.99 | 0.00 | 0.00 |
    0.00 | 0.94 | 0.10 | 0.05 | 0.75 |'
- en: '| HD | GPT-4 | 0.88 | 0.35 | 0.28 | 0.45 |  |  |  |  |  |  |  |  |  |  |  |  |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| HD | GPT-4 | 0.88 | 0.35 | 0.28 | 0.45 |  |  |  |  |  |  |  |  |  |  |  |  |'
- en: '| BERT |  |  |  |  | 0.91 | 0.17 | 0.24 | 0.13 | 0.92 | 0.41 | 0.45 | 0.38
    | 0.90 | 0.21 | 0.24 | 0.19 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| BERT |  |  |  |  | 0.91 | 0.17 | 0.24 | 0.13 | 0.92 | 0.41 | 0.45 | 0.38
    | 0.90 | 0.21 | 0.24 | 0.19 |'
- en: '| RoBERTa |  |  |  |  | 0.92 | 0.24 | 0.35 | 0.19 | 0.92 | 0.47 | 0.43 | 0.52
    | 0.91 | 0.20 | 0.26 | 0.16 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| RoBERTa |  |  |  |  | 0.92 | 0.24 | 0.35 | 0.19 | 0.92 | 0.47 | 0.43 | 0.52
    | 0.91 | 0.20 | 0.26 | 0.16 |'
- en: '| DistilBERT |  |  |  |  | 0.91 | 0.26 | 0.32 | 0.22 | 0.91 | 0.40 | 0.38 |
    0.42 | 0.91 | 0.28 | 0.33 | 0.25 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| DistilBERT |  |  |  |  | 0.91 | 0.26 | 0.32 | 0.22 | 0.91 | 0.40 | 0.38 |
    0.42 | 0.91 | 0.28 | 0.33 | 0.25 |'
- en: 'Table A4: Complete task-by-task classification performance results. Ac., Pr.,
    and Re. refer to accuracy, precision, and recall, respectively.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 表 A4：完整的逐任务分类性能结果。Ac.、Pr. 和 Re. 分别指准确率、精确率和召回率。
- en: 'Appendix C Appendix: Additional methodological details'
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 附录：附加方法学细节
- en: C.1 Prompt tuning
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 提示调整
- en: As discussed in Section 2, for every task we adjusted each GPT-4 prompt with
    a human-in-the-loop update procedure to optimize for accurate annotations. This
    human-in-the-loop process involved three steps. First, we used the generative
    LLM to annotate a small subset of the text samples per task (n=250).^(12)^(12)12This
    subset of text samples was not included in the held-out test set. Second, we manually
    reviewed instances where humans and the generative LLM disagreed on the text’s
    label. Because our accuracy at this stage hovered around 0.8, this usually entailed
    manually reviewing roughly 50 text labels. Third, we adjusted the prompt instructions
    to clarify instances where automated annotation failed to correctly align with
    human judgment.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 2 节所述，对于每个任务，我们通过人工干预更新程序调整了每个 GPT-4 提示，以优化准确的标注。这个人工干预过程包括三个步骤。首先，我们使用生成型
    LLM 对每个任务的文本样本小子集进行标注（n=250）。^(12)^(12)12这个文本样本子集没有包括在保留测试集中。其次，我们手动审查人类和生成型 LLM
    在文本标签上不一致的实例。由于此阶段我们的准确率约为 0.8，这通常涉及手动审查大约 50 个文本标签。第三，我们调整了提示说明，以澄清自动标注未能正确对齐人类判断的实例。
- en: '![Refer to caption](img/0e7c1636df514c6c9a03ceeb00672842.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0e7c1636df514c6c9a03ceeb00672842.png)'
- en: 'Figure A3: Change in LLM annotation performance on training data after one
    round of prompt optimization'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A3：提示优化后训练数据中 LLM 标注性能的变化
- en: The prompt tuning process should be minimal (e.g., one or two iterations), because
    any further efforts could lead to overfitting the prompt to a small subset of
    the data (Egami et al., [2022](#bib.bib12)). If the prompt is overly tailored
    to a small subset of the data, then the instructions may not generalize to unseen
    data. Moreover, if the researcher makes major changes to the prompt, there may
    be a mismatch between the human annotator’s codebook and the generative LLM’s
    instructions. Like the previous concern, the differences in the instructions could
    lead to poor performance on a held-out set. As a result, if there are substantial
    changes made to the LLM’s prompt, then the researcher should also change the human
    codebook as well and re-annotate new text samples. As such, these procedures should
    not be resource or time intensive. Instead, prompt tuning is intended to be a
    part of a validation process of few-shot in-context learning.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 提示调整过程应尽量简短（例如，一两次迭代），因为进一步的努力可能导致提示对数据的小子集过拟合（Egami 等， [2022](#bib.bib12)）。如果提示过度针对数据的小子集，则说明可能无法推广到未见数据。此外，如果研究人员对提示进行了重大更改，可能会导致人类标注者的代码书与生成型
    LLM 的说明不匹配。与之前的担忧类似，说明中的差异可能会导致在保留集上的表现不佳。因此，如果对 LLM 的提示进行了 substantial 更改，研究人员还应更改人类代码书，并重新标注新的文本样本。因此，这些程序不应消耗过多资源或时间。相反，提示调整旨在成为少样本上下文学习验证过程的一部分。
- en: Some researchers argue that small changes to the LLM prompt instructions can
    dramatically alter automated annotation performance (Reiss, [2023](#bib.bib36)),
    whereas others claim that alterations have a marginal effect (Rytting et al.,
    [2023](#bib.bib37)). To test how variations in the prompt instructions affect
    performance, we evaluated automated annotation performance before and after the
    prompt tuning process.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究人员认为，对LLM提示指令的微小变化可以显著改变自动化注释性能（Reiss，[2023](#bib.bib36)），而其他人则声称这些变化的影响很小（Rytting等，[2023](#bib.bib37)）。为了测试提示指令的变化如何影响性能，我们在提示调整过程前后评估了自动化注释性能。
- en: 'Figure [A3](#A3.F3 "Figure A3 ‣ C.1 Prompt tuning ‣ Appendix C Appendix: Additional
    methodological details ‣ Knowledge Distillation in Automated Annotation: Supervised
    Text Classification with LLM-Generated Training Labels") shows the distributions
    of change in performance metrics after updating the LLM prompt and re-annotating
    the same text samples. This analysis demonstrates whether and how prompt optimization
    affects LLM annotation, holding constant the data and conceptual categories. In
    most cases, prompt optimization led to minor improvement in accuracy and F1—although
    recall decreased in more cases than improved after updating the prompts. The small
    magnitude of change in classification performance suggests that generative LLMs
    are fairly robust to slight word changes in the prompt, which aligns with prior
    work that conducts similar experiments (Rytting et al., [2023](#bib.bib37)). While
    the magnitude of improvement was generally small, researchers experiencing subpar
    LLM annotation performance can use human-in-the-loop prompt optimization to ensure
    that their instructions are not the cause of poor performance.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '图[Figure A3](#A3.F3 "Figure A3 ‣ C.1 Prompt tuning ‣ Appendix C Appendix: Additional
    methodological details ‣ Knowledge Distillation in Automated Annotation: Supervised
    Text Classification with LLM-Generated Training Labels") 显示了在更新LLM提示和重新注释相同文本样本后性能指标变化的分布。这一分析展示了提示优化是否以及如何影响LLM注释，同时保持数据和概念类别不变。在大多数情况下，提示优化导致了准确性和F1的轻微提升——尽管在更新提示后，召回率的下降情况比提升情况更多。这种分类性能变化幅度较小，表明生成型LLM对提示中的轻微词汇变化相当稳健，这与之前进行类似实验的工作一致（Rytting等，[2023](#bib.bib37)）。虽然改进的幅度通常较小，但经历过LLM注释表现不佳的研究人员可以使用人工反馈的提示优化来确保他们的指令不是造成差劲表现的原因。'
- en: Qualitatively, the most common mistakes we observed by the generative LLM during
    the prompt optimization stage were false positives stemming from the text sample
    containing language broadly associated with the conceptual category of interest.
    For example, one task focused on identifying immigration content in American political
    speeches (Card et al., [2022](#bib.bib3)). Initially, the generative model consistently
    categorized a text sample as containing an immigration reference if the speech
    mentioned a foreign country or foreign national, irrespective of whether the mention
    was connected to immigration in any way. For the prompt-update process for this
    task, changes in this case meant clarifying that any reference to a foreign country
    or foreign national did not warrant a positive class instance unless it was explicitly
    referenced in relation to American immigration or immigration policy. While this
    process was manual, we also believe that future work could conduct these procedures
    algorithmically—plausibly using generative AI as well.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 从定性角度来看，我们在提示优化阶段观察到的生成型LLM最常见的错误是由于文本样本包含与感兴趣的概念类别广泛相关的语言而导致的假阳性。例如，一个任务集中在识别美国政治演讲中的移民内容（Card等，[2022](#bib.bib3)）。最初，如果演讲提到外国国家或外国国籍，生成模型会持续将文本样本分类为包含移民参考，而不管提及是否与移民相关。对于这个任务的提示更新过程，变化意味着澄清任何提及外国国家或外国国籍的内容不应被视为正类实例，除非它明确涉及到美国移民或移民政策。尽管这个过程是手动的，我们也相信未来的工作可以通过算法进行这些程序——可能使用生成型AI。
- en: C.2 Hyperparameter tuning, evaluation, and compute details
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 超参数调整、评估和计算细节
- en: 'Our experiments involved varying the training data used to fine-tune numerous
    supervised classifiers (i.e., 250 human samples, 1000 human samples, and 1000
    GPT-labeled samples). To select each supervised classifier, we implemented a grid
    search over 18 possible hyperparameter combinations. In particular, we optimized
    learning rate (1e-5, 2e-5, and 5e-5), batch size (8 and 16), and epochs (2, 4,
    and 6). We conducted our search on a subsample of 250 text samples per task and
    retained the best hyperparameters (in terms of highest F1) across each task. We
    subsequently used the best-performing combination of hyperparameters for all applications
    of a specific model (see best-performing hyperparameter configurations in Table
    [A5](#A3.T5 "Table A5 ‣ C.2 Hyperparameter tuning, evaluation, and compute details
    ‣ Appendix C Appendix: Additional methodological details ‣ Knowledge Distillation
    in Automated Annotation: Supervised Text Classification with LLM-Generated Training
    Labels")). Despite not adopting a more exhaustive approach to hyperparameter tuning,
    we observe strong performance across our classification tasks, with a few exceptions.
    Table [A6](#A3.T6 "Table A6 ‣ C.2 Hyperparameter tuning, evaluation, and compute
    details ‣ Appendix C Appendix: Additional methodological details ‣ Knowledge Distillation
    in Automated Annotation: Supervised Text Classification with LLM-Generated Training
    Labels") displays additional model hyperparameters that remained constant across
    tasks, as well as basic information about each model’s architecture.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的实验涉及了使用不同的训练数据来微调多种监督分类器（即250个人类样本、1000个人类样本和1000个GPT标记样本）。为了选择每个监督分类器，我们对18种可能的超参数组合进行了网格搜索。特别地，我们优化了学习率（1e-5、2e-5和5e-5）、批量大小（8和16）以及轮次（2、4和6）。我们在每个任务的250个文本样本的子样本上进行了搜索，并保留了每个任务中表现最好的超参数（以最高F1为标准）。随后，我们对特定模型的所有应用使用了表现最佳的超参数组合（请参见表格
    [A5](#A3.T5 "Table A5 ‣ C.2 Hyperparameter tuning, evaluation, and compute details
    ‣ Appendix C Appendix: Additional methodological details ‣ Knowledge Distillation
    in Automated Annotation: Supervised Text Classification with LLM-Generated Training
    Labels")）。尽管没有采取更全面的超参数调优方法，我们仍然在分类任务中观察到了强劲的表现，尽管有一些例外。表格 [A6](#A3.T6 "Table
    A6 ‣ C.2 Hyperparameter tuning, evaluation, and compute details ‣ Appendix C Appendix:
    Additional methodological details ‣ Knowledge Distillation in Automated Annotation:
    Supervised Text Classification with LLM-Generated Training Labels") 显示了在各个任务中保持不变的额外模型超参数以及每个模型架构的基本信息。'
- en: 'Overall, for each task we had a total of 2,500 labeled text samples labeled
    by both human annotators and the LLM: (1) a training set of 1,000 text samples;
    (2) two separate validation sets (both with n=250); and (3) a test set (n=1000).
    Each of these sets of data were labeled by humans and the generative LLM. The
    training set (n=1000) was used to fine-tune the supervised classifiers. The first
    validation set (n=250) was used to optimize the generative LLM prompt and validate
    its few-shot performance. The second, separate validation set (n=250) was used
    to conduct our grid search. The test set (n=1000) was used to assess the final
    performance of the few-shot model and the supervised models.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，对于每个任务，我们共有2,500个由人类注释员和LLM标记的文本样本：（1）一个包含1,000个文本样本的训练集；（2）两个独立的验证集（每个n=250）；以及（3）一个测试集（n=1000）。这些数据集中的每一项都由人类和生成LLM标记。训练集（n=1000）用于微调监督分类器。第一个验证集（n=250）用于优化生成LLM提示并验证其少量样本性能。第二个独立的验证集（n=250）用于进行网格搜索。测试集（n=1000）用于评估少量样本模型和监督模型的最终性能。
- en: 'For all 14 tasks, evaluation was conducted on a test set of 1000 held-out text
    samples that had previously been labeled by human annotators. To harmonize the
    diverse range of annotation tasks into a common framework for evaluation, we treat
    every task dimension as a separate binary annotation task. Thus, if an article
    included a classification task with three potential labels, we split the annotation
    process into three discrete binary classification tasks. As is standard in binary
    classification evaluation, we report accuracy, F1, precision, and recall for every
    task and model.^(13)^(13)13Because our tasks are all binary, there is no need
    to report any multi-label classification metrics, like Macro-F1. Table [A4](#A2.T4
    "Table A4 ‣ Appendix B Appendix: Data sets ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    displays the full classification results across all tasks and models.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有 14 个任务，我们在 1000 个之前由人工标注员标记的保留文本样本的测试集上进行了评估。为了将多样化的标注任务统一到一个通用的评估框架中，我们将每个任务维度视为一个独立的二分类标注任务。因此，如果一篇文章包含一个有三个潜在标签的分类任务，我们将标注过程拆分为三个独立的二分类任务。与二分类评估标准一样，我们报告每个任务和模型的准确率、F1
    分数、精确度和召回率。^(13)^(13)13由于我们的任务都是二分类的，因此不需要报告任何多标签分类指标，如 Macro-F1。表 [A4](#A2.T4
    "表 A4 ‣ 附录 B 附录：数据集 ‣ 自动标注中的知识蒸馏：使用 LLM 生成的训练标签进行监督文本分类") 显示了所有任务和模型的完整分类结果。
- en: All of our supervised training analyses were implemented in Python 3.10.12 with
    HuggingFace’s Transformers (Wolf et al., [2020](#bib.bib47)) and PyTorch libraries
    (Paszke et al., [2019](#bib.bib34)). We conducted all data preprocessing in Python
    Pandas (McKinney, [2011](#bib.bib27)). Our computing infrastructure was Google
    Colab, where we used 215 T4 GPU compute units (roughly 421.4 GPU hours). As with
    our model selection, we chose this computing environment due to its low cost and
    ease of application. Any computational social scientist could conduct the same
    analyses. In the supplementary material, we include all code to run our supervised
    training procedures.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所有的监督训练分析都是在 Python 3.10.12 环境中实现的，使用了 HuggingFace 的 Transformers（Wolf 等人，[2020](#bib.bib47)）和
    PyTorch 库（Paszke 等人，[2019](#bib.bib34)）。我们在 Python Pandas（McKinney，[2011](#bib.bib27)）中进行了所有数据预处理。我们的计算基础设施是
    Google Colab，我们使用了 215 个 T4 GPU 计算单元（大约 421.4 GPU 小时）。与我们的模型选择一样，我们选择这个计算环境是由于其低成本和易用性。任何计算社会科学家都可以进行相同的分析。在补充材料中，我们包括了运行我们监督训练程序的所有代码。
- en: '| Study | Task | Hyperparameters |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 研究 | 任务 | 超参数 |'
- en: '| --- | --- | --- |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Card et al. | Classify immigration speeches | learning rate (5e-05), batch
    size (8), epochs (4) |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Card 等人 | 分类移民演讲 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (4) |'
- en: '| Classify pro-immigration speeches | learning rate (5e-05), batch size (16),
    epochs (6) |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 分类支持移民演讲 | 学习率 (5e-05)，批量大小 (16)，训练轮数 (6) |'
- en: '| Classify anti-immigration speeches | learning rate (5e-05), batch size (8),
    epochs (6) |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 分类反移民演讲 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (6) |'
- en: '| Classify neutral immigration speeches | learning rate (5e-05), batch size
    (8), epochs (4) |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 分类中立移民演讲 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (4) |'
- en: '| Hopkins et al. | Classify race/ethnicity | learning rate (5e-05), batch size
    (8), epochs (4) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins 等人 | 分类种族/民族 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (4) |'
- en: '| Classify gender | learning rate (5e-05), batch size (8), epochs (6) |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 分类性别 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (6) |'
- en: '| Classify political groups | learning rate (5e-05), batch size (16), epochs
    (6) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 分类政治团体 | 学习率 (5e-05)，批量大小 (16)，训练轮数 (6) |'
- en: '| Classify religious groups | learning rate (5e-05), batch size (8), epochs
    (6) |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 分类宗教团体 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (6) |'
- en: '| Müller | Classify past | learning rate (5e-05), batch size (8), epochs (4)
    |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| Müller | 分类过去 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (4) |'
- en: '| Classify present | learning rate (5e-05), batch size (8), epochs (4) |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 分类现在 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (4) |'
- en: '| Classify future | learning rate (2e-05), batch size (8), epochs (6) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 分类未来 | 学习率 (2e-05)，批量大小 (8)，训练轮数 (6) |'
- en: '| Peng et al. | Classify criticism | learning rate (5e-05), batch size (8),
    epochs (6) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| Peng 等人 | 分类批评 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (6) |'
- en: '| Saha et al. | Classify fear speech | learning rate (5e-05), batch size (8),
    epochs (6) |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| Saha 等人 | 分类恐惧言论 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (6) |'
- en: '| Classify hate speech | learning rate (5e-05), batch size (8), epochs (4)
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 分类仇恨言论 | 学习率 (5e-05)，批量大小 (8)，训练轮数 (4) |'
- en: 'Table A5: Hyperparameter settings per task.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 表 A5：每个任务的超参数设置。
- en: '|  | BERT-base | RoBERTa-base | DistilBERT | XLNet-base | Mistral-7B |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  | BERT-base | RoBERTa-base | DistilBERT | XLNet-base | Mistral-7B |'
- en: '| # parameters | 110m | 125m | 66m | 110m | 7b |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| # 参数量 | 110m | 125m | 66m | 110m | 7b |'
- en: '| # attention heads | 12 | 12 | 12 | 12 | 32 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| # 注意力头数 | 12 | 12 | 12 | 12 | 32 |'
- en: '| Hidden dim. | 768 | 768 | 768 | 768 | 4096 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 隐藏维度 | 768 | 768 | 768 | 768 | 4096 |'
- en: '| Feedforward dim. | 3072 | 3072 | 3072 | 3072 | 14336 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 前馈维度 | 3072 | 3072 | 3072 | 3072 | 14336 |'
- en: 'Table A6: Model architectures and additional hyperparameters.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表 A6：模型架构和额外超参数。
- en: C.3 Additional details on human annotation procedures
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 人工标注程序的附加细节
- en: 'We introduce a novel corpus of labeled text data for annotations. To create
    this data set, we compile labeled data from recent studies, as detailed in [A2](#A2.T2
    "Table A2 ‣ Appendix B Appendix: Data sets ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels").
    As a result, we did not work with annotators to generate any original data. We
    adopted materials from these original studies instead. While we do not report
    the instructions given to each study’s human annotators, we do provide the prompt
    instructions that were used to query GPT-4 in the supplementary material. These
    instructions were taken directly from the original study’s human annotator instructions.
    All additional details on the annotation procedures (e.g., how they were recruited,
    payment, consent, and demographic characteristics) can be found in the original
    studies’ supplementary material.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了一个用于标注的新型标注文本数据集。为了创建这个数据集，我们编译了来自最近研究的标注数据，如 [A2](#A2.T2 "表 A2 ‣ 附录 B
    附录：数据集 ‣ 知识蒸馏在自动标注中的应用：利用 LLM 生成的训练标签进行有监督文本分类") 中详细说明的那样。因此，我们没有与标注员合作生成任何原始数据。我们采用了这些原始研究中的材料。尽管我们没有报告每项研究对人类标注员的具体指示，但我们提供了用于查询
    GPT-4 的提示指令，这些指令直接取自原始研究的人类标注员指示。关于标注程序的所有附加细节（例如，招募方式、支付、同意和人口统计特征）可以在原始研究的补充材料中找到。
- en: While we do not describe each study’s procedures in detail, we manually selected
    our annotation studies due to their high-quality human labeling practices. All
    of the replicated studies were approved by an IRB. These studies all deployed
    either expert coders or numerous non-expert coders of varying backgrounds. Because
    all of the human annotation text is part of the peer-review process in high-impact
    journals and due to the strict annotation guidelines and principles these studies
    adhered to, we conclude that the human annotations are of high-quality.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们没有详细描述每项研究的程序，但由于其高质量的人类标注实践，我们手动选择了我们的标注研究。所有复制的研究都得到了 IRB 的批准。这些研究都采用了专家编码员或来自不同背景的大量非专家编码员。由于所有的人类标注文本都是高影响力期刊中的同行评审过程的一部分，并且这些研究遵循了严格的标注指南和原则，我们得出结论认为这些人类标注是高质量的。
- en: 'Appendix D Appendix: Extended results'
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 附录：扩展结果
- en: 'Figure [A4](#A4.F4 "Figure A4 ‣ Appendix D Appendix: Extended results ‣ Knowledge
    Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated
    Training Labels") shows precision-recall (PR) curves for each of the BERT-family
    models trained on either human labels or GPT labels, pooling all classification
    tasks. The decrease in performance for GPT-generated labels compared with human
    labels is small based on area under the curve (AUC). Thus, supervised classifiers
    trained with GPT-generated labels perform comparably to classifiers trained with
    human-generated labels on these tasks. Across models and tasks, precision appears
    to drop below 1.0 around 0.7 recall.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [A4](#A4.F4 "图 A4 ‣ 附录 D 附录：扩展结果 ‣ 知识蒸馏在自动标注中的应用：利用 LLM 生成的训练标签进行有监督文本分类")
    展示了针对 BERT 家族模型的精确度-召回率（PR）曲线，这些模型分别用人工标签或 GPT 标签进行训练，涵盖了所有分类任务。根据曲线下面积（AUC），GPT
    生成的标签相对于人工标签的性能下降很小。因此，用 GPT 生成的标签训练的有监督分类器在这些任务上的表现与用人工标签训练的分类器相当。在模型和任务中，精确度在召回率达到
    0.7 左右时似乎低于 1.0。
- en: '![Refer to caption](img/cd97917fcbbddda3bd74bc6b7fcf3935.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/cd97917fcbbddda3bd74bc6b7fcf3935.png)'
- en: 'Figure A4: Precision-recall curves across each BERT-family model'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A4：各 BERT 家族模型的精确度-召回率曲线
- en: .
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 'Appendix E Appendix: Ablation experiments'
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 附录：消融实验
- en: We conducted a variety of ablation experiments to account for sources of variance.
    The next three sections detail these experiments and their main findings.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了各种消融实验，以考虑方差来源。接下来的三节详细介绍了这些实验及其主要发现。
- en: E.1 Comparing classifiers with different model size and architecture
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 比较不同模型大小和架构的分类器
- en: First, to account for variation in model architecture and model size, we compare
    performance across two additional language models for supervised classification
    (i.e., XLNet and Mistral-7B). These models are beyond the BERT-family models included
    in the main analyses (i.e., BERT, DistilBERT, and RoBERTa). In addition to a Mistral-7B
    supervised sequence classification model, we also generate few-shot labels using
    Mistral-7B using the same procedures we employed in the GPT-4 few-shot model.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，为了考虑模型架构和模型大小的变化，我们比较了两种额外语言模型在监督分类中的表现（即 XLNet 和 Mistral-7B）。这些模型超出了主要分析中包含的
    BERT 系列模型（即 BERT、DistilBERT 和 RoBERTa）。除了 Mistral-7B 监督序列分类模型外，我们还使用相同的程序生成了 Mistral-7B
    的少样本标签，这些程序与我们在 GPT-4 少样本模型中使用的程序相同。
- en: The primary difference between the BERT-family models and XLNet is the training
    objective. The BERT-based models are pretrained using a Masked Language Modeling
    (MLM) objective, whereas XLNet is an autoregressive model that uses Permutation
    Language Modeling (PLM), which involves learning context across input tokens in
    any permutation order. In addition to being significantly larger than the BERT
    models, Mistral-7B utilizes a distinct type of attention in the pretraining process
    (i.e., grouped-query attention (GQA) and sliding window attention (SWA)). We include
    the Mistral-7B few-shot model as a smaller, open-source alternative to GPT-4\.
    Mistral-7B was selected because the model weights are available for download and
    it displays higher performance than Llama-13B (Jiang et al., [2023](#bib.bib21)).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: BERT 系列模型和 XLNet 之间的主要区别在于训练目标。BERT 基于的模型使用掩码语言建模 (MLM) 目标进行预训练，而 XLNet 是一个自回归模型，使用排列语言建模
    (PLM)，涉及在任何排列顺序下学习输入标记之间的上下文。除了比 BERT 模型显著大外，Mistral-7B 在预训练过程中采用了一种不同类型的注意力（即分组查询注意力（GQA）和滑动窗口注意力（SWA））。我们包括了
    Mistral-7B 少样本模型作为 GPT-4 的较小的开源替代方案。选择 Mistral-7B 是因为模型权重可以下载，并且其性能优于 Llama-13B
    (Jiang et al., [2023](#bib.bib21))。
- en: '![Refer to caption](img/4ffab02eb913f47d2bc2e36501b099c8.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4ffab02eb913f47d2bc2e36501b099c8.png)'
- en: 'Figure A5: Box plots of ablation performance on test data across 14 tasks.
    Thick vertical line denotes median.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A5：14 项任务的测试数据上消融性能的箱线图。粗垂直线表示中位数。
- en: .
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 'Figure [A5](#A5.F5 "Figure A5 ‣ E.1 Comparing classifiers with different model
    size and architecture ‣ Appendix E Appendix: Ablation experiments ‣ Knowledge
    Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated
    Training Labels") shows the classification performance from these additional models
    and compares them to the results from BERT and GPT-4 few-shot in the main analyses.
    The test set for these analyses is the same as the main analysis shown in the
    paper. Our results from examining these additional models do not change the substantive
    conclusions in the paper: Models trained on surrogate training labels perform
    comparably to models trained with human labeled data. XLNet even performs slightly
    better than the fully human labels. The gap between Mistral-7b fine-tuned using
    human labels and GPT-labels, however, is notably larger than the other models,
    with a median difference of 0.12\. Overall, BERT and GPT-4 still appear to be
    the strongest performing models.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图[ A5](#A5.F5 "图 A5 ‣ E.1 比较不同模型大小和架构的分类器 ‣ 附录 E 附录：消融实验 ‣ 自动标注中的知识蒸馏：使用 LLM
    生成的训练标签进行监督文本分类") 显示了这些额外模型的分类性能，并将其与主要分析中 BERT 和 GPT-4 少样本的结果进行比较。这些分析的测试集与论文中显示的主要分析的测试集相同。我们对这些额外模型的检查结果没有改变论文中的实质性结论：使用代理训练标签训练的模型与使用人工标注数据训练的模型表现相当。XLNet
    甚至表现得比完全使用人工标签的模型稍好。然而，使用人工标签进行微调的 Mistral-7b 和 GPT 标签之间的差距显著大于其他模型，差距中位数为 0.12。总体而言，BERT
    和 GPT-4 仍然是表现最强的模型。
- en: There is also a fairly sizeable gap between the open-source (Mistral-7B) and
    closed-source (GPT-4) few-shot models. Although it may be expected from a significantly
    smaller and free-to-use model, F1 scores for Mistral-7B are 0.16 worse, on average,
    than GPT-4\. Mistral-7B also took significantly longer to run than GPT-4\. These
    findings further reinforce the necessity of human validation.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 开源（Mistral-7B）和闭源（GPT-4）少样本模型之间也存在相当大的差距。尽管这可能是由于模型显著更小且可免费使用，但 Mistral-7B 的
    F1 分数平均比 GPT-4 差 0.16。Mistral-7B 的运行时间也明显长于 GPT-4。这些发现进一步加强了人工验证的必要性。
- en: E.2 Comparing classifiers with and without noise
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 比较有噪声和无噪声的分类器
- en: Our second set of ablation experiments involve comparing supervised models trained
    on GPT-generated labels with noise against GPT-generated labels without noise.
    To measure noise in the GPT-labels, we utilize the predicted token sampling process
    of generative LLMs to gauge an LLM’s “confidence” in the annotation of each text
    sample. By introducing randomness in the LLM sampling process through the temperature
    setting and by repeatedly classifying the same text sample multiple times, we
    identify text samples that cannot be clearly classified into one of the annotation
    categories specified by the prompt instructions.^(14)^(14)14Generative LLMs output
    a series of probabilities that correspond to each token in its vocabulary. To
    select a specific token from this probability distribution, generative LLMs sample
    a randomly selected token, weighted by its probability. The temperature hyperparameter
    governs this sampling process. A higher temperature setting flattens the probability
    distribution and causes the sampling draw to become more uniform across tokens.
    A lower temperature, however, isolates the sampling to select only the most likely
    tokens.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二组消融实验涉及将训练于 GPT 生成的标签（有噪声）上的监督模型与训练于 GPT 生成的标签（无噪声）上的监督模型进行比较。为了测量 GPT
    标签中的噪声，我们利用生成 LLM 的预测令牌采样过程来评估 LLM 对每个文本样本注释的“信心”。通过在 LLM 采样过程中引入随机性（通过温度设置）并重复对相同的文本样本进行分类，我们识别出无法清晰分类到提示指令指定的注释类别中的文本样本。^(14)^(14)14生成
    LLM 输出一系列概率，这些概率对应于其词汇表中的每个令牌。为了从这种概率分布中选择特定的令牌，生成 LLM 以其概率加权随机选择一个令牌。温度超参数控制这个采样过程。较高的温度设置使概率分布变平坦，并使采样结果在令牌之间变得更加均匀。然而，较低的温度则将采样隔离，以仅选择最可能的令牌。
- en: 'Classifications that vary across iterations may be “edge cases” and have a
    lower probability of correct classification.^(15)^(15)15Accessing token log probabilities
    directly, once available, will be an effective way to a similar analysis. This
    approach rests on the core assumption that the full distribution of token probabilities
    captures latent information about the annotation’s classification. If, for example,
    the top tokens are similar in probability, then choosing one of these tokens may
    misrepresent the model’s annotation decision. Instead, measuring the variability
    across iterations allows us to find these “edge cases.” We call this measure of
    uncertainty in the annotation label a “consistency score.” We define an indicator
    function $C(i)$, for task :'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代过程中分类的差异可能是“边缘案例”，并且正确分类的概率较低。^(15)^(15)15直接访问令牌日志概率，一旦可用，将是类似分析的有效方式。这种方法的核心假设是令牌概率的完整分布捕捉了关于注释分类的潜在信息。例如，如果顶部令牌的概率相似，那么选择这些令牌中的一个可能会误代表模型的注释决策。相反，通过测量迭代之间的变异性，我们可以找到这些“边缘案例”。我们将这种注释标签的不确定性度量称为“一致性评分”。我们为任务定义了一个指示函数
    $C(i)$：
- en: '|  | $C(i)=\begin{cases}1&amp;\text{if}\ i=m\\ 0&amp;\text{otherwise}\end{cases}$
    |  |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '|  | $C(i)=\begin{cases}1&amp;\text{if}\ i=m\\ 0&amp;\text{otherwise}\end{cases}$
    |  |'
- en: 'Given a vector of classifications, $\mathbf{a}$ for a given classification
    task, consistency is measured as the proportion of classifications that match
    the modal label:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个分类向量 $\mathbf{a}$，对于给定的分类任务，一致性被测量为与模态标签匹配的分类比例：
- en: '|  | $Consistency=\frac{1}{l}\sum_{j=1}^{l}C(a_{j})$ |  |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '|  | $Consistency=\frac{1}{l}\sum_{j=1}^{l}C(a_{j})$ |  |'
- en: 'For these ablation experiments, we classify every text sample three times at
    a temperature of 0.7 and measure each text sample’s consistency score. Because
    there are only three iterations, each text sample can only have two values for
    consistency score: 0.67 and 1.0\. Across all analyzed tasks, classifications with
    a consistency of 1.0 show significantly higher accuracy (19.4% increase), true
    positive rate (16.4% increase), and true negative rate (21.4% increase) compared
    to classifications with a consistency less than 1.0\. Roughly 85% of classifications
    had a consistency of 1.0.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些消融实验，我们在 0.7 的温度下对每个文本样本进行三次分类，并测量每个文本样本的一致性评分。由于只有三次迭代，每个文本样本的一致性评分只有两个值：0.67
    和 1.0。在所有分析的任务中，一致性为 1.0 的分类显示出显著更高的准确率（增加 19.4%）、真正率（增加 16.4%）和真负率（增加 21.4%），相比于一致性低于
    1.0 的分类。大约 85% 的分类具有 1.0 的一致性评分。
- en: '| Data set and task | BERT F1 score (training obs w/o noise) | BERT F1 score
    (training obs w/ noise) | Difference |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 数据集和任务 | BERT F1 分数（无噪声训练观察） | BERT F1 分数（有噪声训练观察） | 差异 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Hopkins (AJPS): Political | 0.340 | 0.344 | -0.004 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins (AJPS): Political | 0.340 | 0.344 | -0.004 |'
- en: '| Hopkins (AJPS): religion | 0.609 | 0.609 | 0.000 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins (AJPS): religion | 0.609 | 0.609 | 0.000 |'
- en: '| Hopkins (AJPS): gender | 0.716 | 0.684 | 0.032 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins (AJPS): gender | 0.716 | 0.684 | 0.032 |'
- en: '| Hopkins (AJPS): race | 0.635 | 0.640 | -0.005 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| Hopkins (AJPS): race | 0.635 | 0.640 | -0.005 |'
- en: '| Muller (JOP): future | 0.851 | 0.851 | 0.000 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| Muller (JOP): future | 0.851 | 0.851 | 0.000 |'
- en: '| Muller (JOP): past | 0.791 | 0.755 | 0.036 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| Muller (JOP): past | 0.791 | 0.755 | 0.036 |'
- en: '| Muller (JOP): present | 0.606 | 0.601 | 0.005 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| Muller (JOP): present | 0.606 | 0.601 | 0.005 |'
- en: '| Card (PNAS): cat_imm | 0.832 | 0.815 | 0.017 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| Card (PNAS): cat_imm | 0.832 | 0.815 | 0.017 |'
- en: '| Card (PNAS): cat_anti | 0.565 | 0.573 | -0.008 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| Card (PNAS): cat_anti | 0.565 | 0.573 | -0.008 |'
- en: '| Card (PNAS): cat_neutral | 0.385 | 0.428 | -0.043 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| Card (PNAS): cat_neutral | 0.385 | 0.428 | -0.043 |'
- en: '| Card (PNAS): cat_pro | 0.448 | 0.436 | 0.012 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| Card (PNAS): cat_pro | 0.448 | 0.436 | 0.012 |'
- en: '| Peng (PNAS) | 0.431 | 0.444 | -0.013 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| Peng (PNAS) | 0.431 | 0.444 | -0.013 |'
- en: '| Saha (PNAS): CV | 0.031 | 0.059 | -0.028 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| Saha (PNAS): CV | 0.031 | 0.059 | -0.028 |'
- en: '| Saha (PNAS): HD | 0.210 | 0.276 | -0.066 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| Saha (PNAS): HD | 0.210 | 0.276 | -0.066 |'
- en: 'Table A7: Comparing BERT F1 score for models fine-tuned with and without noise'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 A7：比较带噪声和不带噪声的微调 BERT 模型的 F1 分数
- en: 'Table [A7](#A5.T7 "Table A7 ‣ E.2 Comparing classifiers with and without noise
    ‣ Appendix E Appendix: Ablation experiments ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    shows supervised model performance for BERT models fine-tuned on 1,250 training
    observations labeled by GPT-4 (i.e., labels with noise) compared to BERT models
    fine-tuned on training observations with a consistency score of 1.0 (i.e., labels
    without noise), which reduced our training set to slightly more than 1000 samples
    per task. Put otherwise, the second series of models involved dropping about 250
    text samples per task so that the training set only retained annotations where
    GPT-4 consistently labeled the same category across all iterations.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [A7](#A5.T7 "Table A7 ‣ E.2 Comparing classifiers with and without noise
    ‣ Appendix E Appendix: Ablation experiments ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    显示了 BERT 模型在使用 GPT-4 标注的 1,250 个训练样本（即带噪声的标签）与在标注一致性得分为 1.0（即无噪声标签）的训练样本上进行微调的监督模型性能的比较，这将我们的训练集减少到每个任务略多于
    1000 个样本。换句话说，第二组模型涉及丢弃每个任务大约 250 个文本样本，从而使训练集仅保留了 GPT-4 在所有迭代中一致标记相同类别的注释。'
- en: Our findings indicate that there are minimal differences between models trained
    on labels with noise and labels without noise. Models trained without noise display,
    on average, 0.004 lower F1 score than models trained with noise. These results
    suggest that the supervised models explored here are fairly robust to noise in
    the labels.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究结果表明，使用带噪声的标签和不带噪声的标签训练的模型之间的差异很小。与带噪声的模型相比，未带噪声的模型的 F1 分数平均低 0.004。这些结果表明，这里探索的监督模型对标签中的噪声具有相当的鲁棒性。
- en: E.3 Comparing GPT-4 few-shot performance over time
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.3 比较 GPT-4 少样本性能随时间的变化
- en: Our final set of ablation experiments involved replicating the GPT-4 few-shot
    model at different points in time. An unsettling scenario involves the potential
    drift in capabilities as generative LLMs undergo opaque changes and updates. Some
    research, such as Chen et al. ([2023a](#bib.bib4)), claim that GPT-4 performance
    is declining over time. To account for the potential of changing model weights
    in GPT-4, we re-analyzed each task six months after our initial analyses and compared
    results across time.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终的一组消融实验涉及在不同时间点重复进行 GPT-4 少样本模型的测试。一种令人不安的情况是，生成式 LLM 在经历不透明的变化和更新时，其能力可能会发生漂移。一些研究，例如
    Chen 等人 ([2023a](#bib.bib4))，声称 GPT-4 的性能随着时间的推移而下降。为了考虑 GPT-4 模型权重变化的可能性，我们在初步分析后的六个月重新分析了每个任务，并比较了跨时间的结果。
- en: 'Figure [A6](#A5.F6 "Figure A6 ‣ E.3 Comparing GPT-4 few-shot performance over
    time ‣ Appendix E Appendix: Ablation experiments ‣ Knowledge Distillation in Automated
    Annotation: Supervised Text Classification with LLM-Generated Training Labels")
    shows evaluation comparisons of few-shot tasks in both April 2023 and November
    2023\. Our results do not suggest significant changes in GPT-4 performance over
    time. If anything, Figure [A6](#A5.F6 "Figure A6 ‣ E.3 Comparing GPT-4 few-shot
    performance over time ‣ Appendix E Appendix: Ablation experiments ‣ Knowledge
    Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated
    Training Labels") reveals a small increase in performance since my initial experiments.
    Across the 14 tasks, accuracy improved by 0.007 and F1 increased by 0.022 when
    the same annotation procedures were carried out in November 2023.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [A6](#A5.F6 "图 A6 ‣ E.3 比较 GPT-4 少样本任务随时间的表现 ‣ 附录 E 附录：消融实验 ‣ 自动注释中的知识蒸馏：使用
    LLM 生成的训练标签进行监督文本分类") 显示了 2023 年 4 月和 2023 年 11 月的少样本任务评估比较。我们的结果并未表明 GPT-4 的性能随时间发生显著变化。如果有的话，图
    [A6](#A5.F6 "图 A6 ‣ E.3 比较 GPT-4 少样本任务随时间的表现 ‣ 附录 E 附录：消融实验 ‣ 自动注释中的知识蒸馏：使用 LLM
    生成的训练标签进行监督文本分类") 反映出自最初实验以来性能有小幅提升。在这 14 项任务中，当相同的注释程序在 2023 年 11 月进行时，准确率提高了
    0.007，F1 值增加了 0.022。
- en: '![Refer to caption](img/594969369bf3128fd8ef549c163f61f1.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/594969369bf3128fd8ef549c163f61f1.png)'
- en: 'Figure A6: Examining GPT-4 performance over time'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A6：检查 GPT-4 性能随时间的变化
- en: 'Appendix F Appendix: Miscellaneous additional information'
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 附录：其他附加信息
- en: 'Additional sources:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 额外来源：
- en: •
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Robot image (used in Figure 1): [https://commons.wikimedia.org/wiki/File:Grey_cartoon_robot.png](https://commons.wikimedia.org/wiki/File:Grey_cartoon_robot.png)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器人图像（用于图 1）：[https://commons.wikimedia.org/wiki/File:Grey_cartoon_robot.png](https://commons.wikimedia.org/wiki/File:Grey_cartoon_robot.png)
- en: •
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Human silhouette image (used in Figure 1): [https://commons.wikimedia.org/wiki/File:SVG_Human_Silhouette.svg](https://commons.wikimedia.org/wiki/File:SVG_Human_Silhouette.svg)'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人体轮廓图像（用于图 1）：[https://commons.wikimedia.org/wiki/File:SVG_Human_Silhouette.svg](https://commons.wikimedia.org/wiki/File:SVG_Human_Silhouette.svg)
