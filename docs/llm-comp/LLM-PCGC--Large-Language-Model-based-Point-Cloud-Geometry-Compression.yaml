- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:51:45'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:51:45'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'LLM-PCGC: 基于大型语言模型的点云几何压缩'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.08682](https://ar5iv.labs.arxiv.org/html/2408.08682)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2408.08682](https://ar5iv.labs.arxiv.org/html/2408.08682)
- en: Yuqi Ye¹, Wei Gao¹ Corresponding author. Under review.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 余奇·叶¹，魏高¹ 通讯作者。审稿中。
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The key to effective point cloud compression is to obtain a robust context model
    consistent with complex 3D data structures. Recently, the advancement of large
    language models (LLMs) has highlighted their capabilities not only as powerful
    generators for in-context learning and generation but also as effective compressors.
    These dual attributes of LLMs make them particularly well-suited to meet the demands
    of data compression. Therefore, this paper explores the potential of using LLM
    for compression tasks, focusing on lossless point cloud geometry compression (PCGC)
    experiments. However, applying LLM directly to PCGC tasks presents some significant
    challenges, i.e., LLM does not understand the structure of the point cloud well,
    and it is a difficult task to fill the gap between text and point cloud through
    text description, especially for large complicated and small shapeless point clouds.
    To address these problems, we introduce a novel architecture, namely the Large
    Language Model-based Point Cloud Geometry Compression (LLM-PCGC) method, using
    LLM to compress point cloud geometry information without any text description
    or aligning operation. By utilizing different adaptation techniques for cross-modality
    representation alignment and semantic consistency, including clustering, K-tree,
    token mapping invariance, and Low Rank Adaptation (LoRA), the proposed method
    can translate LLM to a compressor/generator for point cloud. To the best of our
    knowledge, this is the first structure to employ LLM as a compressor for point
    cloud data. Experiments demonstrate that the LLM-PCGC outperforms the other existing
    methods significantly, by achieving -40.213% bit rate reduction compared to the
    reference software of MPEG Geometry-based Point Cloud Compression (G-PCC) standard,
    and by achieving -2.267% bit rate reduction compared to the state-of-the-art learning-based
    method.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的点云压缩的关键在于获得与复杂的3D数据结构一致的强健上下文模型。最近，大型语言模型（LLMs）的进步突显了它们不仅作为上下文学习和生成的强大生成器的能力，还作为有效的压缩器。这些LLM的双重属性使其特别适合满足数据压缩的需求。因此，本文探讨了使用LLM进行压缩任务的潜力，重点关注无损点云几何压缩（PCGC）实验。然而，直接将LLM应用于PCGC任务存在一些重大挑战，即LLM对点云的结构理解不够充分，通过文本描述填补文本与点云之间的差距是一项困难的任务，尤其是对于大型复杂点云和小型无形点云。为了解决这些问题，我们提出了一种新颖的架构，即基于大型语言模型的点云几何压缩（LLM-PCGC）方法，利用LLM压缩点云几何信息，而无需任何文本描述或对齐操作。通过利用不同的适应技术进行跨模态表示对齐和语义一致性，包括聚类、K树、令牌映射不变性和低秩适应（LoRA），所提出的方法可以将LLM转化为点云的压缩器/生成器。据我们所知，这是第一个将LLM作为点云数据压缩器的结构。实验表明，LLM-PCGC显著优于其他现有方法，与MPEG基于几何的点云压缩（G-PCC）标准的参考软件相比，实现了-40.213%的比特率减少，与最先进的基于学习的方法相比，实现了-2.267%的比特率减少。
- en: '![Refer to caption](img/12051a1a50a35ad5f025f369246daf56.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/12051a1a50a35ad5f025f369246daf56.png)'
- en: 'Figure 1: Comparison of training schemes between the proposed LLM-PCGC method
    and other learning-based methods for point cloud geometry compression. Different
    from existing methods adopting the end-to-end training manner, our method implements
    a point cloud compressor by fine-tuning a pre-trained text generator LLM to achieve
    efficient cross-modality representation alignment.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 提议的LLM-PCGC方法与其他基于学习的方法在点云几何压缩中的训练方案比较。与现有方法采用端到端训练方式不同，我们的方法通过微调预训练的文本生成LLM来实现高效的跨模态表示对齐，从而实现点云压缩器。'
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Point cloud is a critical and valuable data structure for autonomous driving
    and virtual reality. Recently, with the development of deep neural networks, more
    and more learning-based architectures for the lossless PCGC task (Que, Lu, and
    Xu [2021](#bib.bib14); Fu et al. [2022](#bib.bib5); Wang et al. [2022](#bib.bib18))
    are proposed, which have demonstrated remarkable performance in the task of lossless
    PCGC. For these methods, they can be divided into two main categories, i.e., voxel-based
    and tree-based. Whether voxel-based or tree-based methods, the key to compression
    performance is the establishment of a strong and robust context model. However,
    the context capabilities of previous methods remain significantly restricted due
    to the limitations in data volume and model size, as discussed in the scaling
    law for large language models (LLMs) (Kaplan et al. [2020](#bib.bib7)). This inspires
    us to directly replace the original context model with LLM, which has large-scale
    context and generation capabilities.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 点云是一种对自动驾驶和虚拟现实至关重要且宝贵的数据结构。最近，随着深度神经网络的发展，越来越多基于学习的无损 PCGC 任务（Que, Lu, and
    Xu [2021](#bib.bib14); Fu et al. [2022](#bib.bib5); Wang et al. [2022](#bib.bib18)）架构被提出，这些方法在无损
    PCGC 任务中表现出显著的性能。这些方法可以分为两大类，即基于体素的方法和基于树的方法。无论是基于体素的方法还是基于树的方法，压缩性能的关键在于建立一个强大而稳健的上下文模型。然而，由于数据量和模型规模的限制，之前的方法在上下文能力方面仍然存在显著的局限性，正如大语言模型（LLMs）的扩展定律（Kaplan
    et al. [2020](#bib.bib7)）所讨论的。这启发我们直接用具有大规模上下文和生成能力的 LLM 替代原有的上下文模型。
- en: '![Refer to caption](img/acad5362d20c65234e272d92c1b6c661.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/acad5362d20c65234e272d92c1b6c661.png)'
- en: 'Figure 2: LLM-PCGC encoding pipline. Given a 3D point cloud, the encoding pipeline
    starts with clustering, followed by normalization and K-Tree structuring. It then
    employs token mapping invariance for token conversion. Subsequently, a trained
    LoRA model with a frozen LLM is used to compute the probability distribution for
    the next token. These distribution are then fed into an arithmetic encoder, resulting
    in the generation of the encoded bitstream.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：LLM-PCGC 编码管道。给定一个 3D 点云，编码管道从聚类开始，随后进行归一化和 K-Tree 结构化。接着，它采用令牌映射不变性进行令牌转换。随后，使用冻结的
    LLM 训练的 LoRA 模型计算下一个令牌的概率分布。这些分布然后被输入到算术编码器中，生成编码的比特流。
- en: 'The emerging viewpoint illustrates that the essence of LLMs fundamentally lies
    in their ability to compress information (Delétang et al. [2024](#bib.bib3); Li
    et al. [2024](#bib.bib9); Valmeekam et al. [2023](#bib.bib17); Yu et al. [2024](#bib.bib23)).
    However, prior research works only generally discuss the compact feature representation
    in LLM from the perspective of compression, but ignore the potential of data compression
    with LLM. Although in (Delétang et al. [2024](#bib.bib3)), the discussion centers
    on the lossless compression capabilities of a text-only trained LLM across different
    modalities of 1D and 2D data, including text, image, and speech. Two limitations
    emerge from the analysis: 1) This work neglects the compression problem for 3D
    point clouds. Different from the simple 1D and 2D data, 3D structural data requires
    a more elaborated and powerful context model. Therefore, as a more complex data
    type, point cloud owns unique 3D structural characteristics, leading to new challenges
    for compression task. 2) The exploration of the LLM’s data compression capability
    is restricted to in-context learning, without any additional parameter training.
    This shows the inherent data compression potential of LLM model, while the performance
    improvement is still unknown after tailore training for the compression task.
    In this paper, we propose a completely new architecture, namely the Large Language
    Model-based Point Cloud Geometry Compression (LLM-PCGC) method, which can better
    adapt to the lossless PCGC compression task.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 新兴观点表明LLM的本质在于其压缩信息的能力（Delétang et al. [2024](#bib.bib3); Li et al. [2024](#bib.bib9);
    Valmeekam et al. [2023](#bib.bib17); Yu et al. [2024](#bib.bib23)）。然而，先前的研究仅从压缩的角度一般性地讨论了LLM中的紧凑特征表示，但忽略了LLM在数据压缩方面的潜力。尽管（Delétang
    et al. [2024](#bib.bib3)）中讨论了仅基于文本训练的LLM在不同模态的1D和2D数据（包括文本、图像和语音）上的无损压缩能力。分析中出现了两个限制：1）该工作忽视了3D点云的压缩问题。不同于简单的1D和2D数据，3D结构数据需要更复杂和强大的上下文模型。因此，作为一种更复杂的数据类型，点云具有独特的3D结构特征，带来了压缩任务的新挑战。2）LLM的数据压缩能力的探索仅限于上下文学习，没有任何额外的参数训练。这显示了LLM模型固有的数据压缩潜力，而在为压缩任务量身定制训练后的性能提升仍不清楚。本文提出了一种全新的架构，即基于大型语言模型的点云几何压缩（LLM-PCGC）方法，它可以更好地适应无损PCGC压缩任务。
- en: Converting text-based LLM to LLM-PCGC is a cross-modal problem. Since LLM is
    a model based on text, the current multi-modal large language model (MM-LLM) in
    order to process multi-modal data, the unified approach is to map other modal
    tokens to the text space and then generate the modal data through text description
    (Yin et al. [2023](#bib.bib22); Hong et al. [2023](#bib.bib6); Xu et al. [2023](#bib.bib20)).
    On the one hand, for coding tasks, we do not really need text data, and there
    is no text data to pair with multimodality. On the other hand, we utilize LLMs
    for their potent generative and contextual understanding capabilities, yet for
    encoding tasks, the text-based features are extraneous. Hence, we seek to discard
    the text-specific aspects while maintaining the essential generative and contextual
    functions. Inspired by (Mirchandani et al. [2023](#bib.bib11)), we are the first
    to fine-tune the pre-trained LLM to achieve cross-modality via token mapping invariance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 将基于文本的LLM转换为LLM-PCGC是一个跨模态问题。由于LLM是基于文本的模型，当前的多模态大型语言模型（MM-LLM）为了处理多模态数据，其统一的方法是将其他模态的令牌映射到文本空间，然后通过文本描述生成模态数据（Yin
    et al. [2023](#bib.bib22); Hong et al. [2023](#bib.bib6); Xu et al. [2023](#bib.bib20)）。一方面，对于编码任务，我们实际上不需要文本数据，也没有文本数据与多模态配对。另一方面，我们利用LLM的强大生成和上下文理解能力，但对于编码任务，基于文本的特征是多余的。因此，我们寻求在保持基本生成和上下文功能的同时，舍弃文本特定的方面。受到（Mirchandani
    et al. [2023](#bib.bib11)）的启发，我们首次通过令牌映射不变性微调预训练LLM，以实现跨模态。
- en: 'Through the above methods, we propose large language model-based point cloud
    geometry compression (LLM-PCGC). As shown in Fig. [1](#S0.F1 "Figure 1 ‣ LLM-PCGC:
    Large Language Model-based Point Cloud Geometry Compression"), a comparison is
    made with existing end-to-end deep learning training methods. Our approach, LLM-PCGC,
    fine-tunes a pre-trained text generator LLM with point cloud data, achieving cross-modality
    and serving as a point cloud compressor. In the encoding phase, the procedure
    begins with the clustering of the input 3D point clouds. Subsequently, each cluster
    is processed in parallel through a series of steps. First, the coordinates are
    normalized by subtracting an offset, and a K-tree structure is organized to systematize
    the point cloud data. Then, the hierarchical tree structure is flattened and divided
    into segments. Subsequently, a codebook is utilized to translate the point cloud
    tokens into text tokens to construct an analogous linguistic sentence. Finally,
    a trained LoRA architecture is employed with a frozen LLM to predict the probability
    distribution of the next token, which is integrated with an arithmetic encoder
    to complete the encoding process. The decoding phase mirrors the aforementioned
    steps in reverse order, thereby reconstructing the original point cloud geometry
    from the encoded data.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '通过上述方法，我们提出了基于大语言模型的点云几何压缩（LLM-PCGC）。如图 [1](#S0.F1 "Figure 1 ‣ LLM-PCGC: Large
    Language Model-based Point Cloud Geometry Compression")所示，与现有的端到端深度学习训练方法进行了比较。我们的方法
    LLM-PCGC，通过点云数据对预训练的文本生成器 LLM 进行微调，实现了跨模态功能，并作为点云压缩器。在编码阶段，过程从输入的 3D 点云的聚类开始。随后，通过一系列步骤并行处理每个聚类。首先，通过减去偏移量来归一化坐标，并组织
    K-树结构来系统化点云数据。然后，将层次树结构扁平化并分为若干段。接着，利用词典将点云标记转换为文本标记，从而构建类似的语言句子。最后，采用训练过的 LoRA
    架构与冻结的 LLM 来预测下一个标记的概率分布，并与算术编码器结合完成编码过程。解码阶段则按照上述步骤的逆序进行，从编码数据中重建原始点云几何结构。'
- en: '![Refer to caption](img/f8637fc4a4d1fff912886866571ddd3e.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f8637fc4a4d1fff912886866571ddd3e.png)'
- en: 'Figure 3: LLM-PCGC decoding pipline. In decoding, binary bits are split, converted
    to decimals, and the main bitstream is processed in parallel. Through arithmetic
    decoder, bitstream is decoded by probabilities using LoRA and LLM, and then further
    mapped into point cloud patches. These patches are aligned and merged by offsets
    and indices. In the final decoding phase, big patches are structured into a K-Tree
    for clustered point cloud reconstruction. In the final post-reconstruction, offsets
    are applied to rebuild the original point cloud.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：LLM-PCGC 解码流程。在解码过程中，二进制位被拆分，转换为十进制，然后主位流并行处理。通过算术解码器，位流通过 LoRA 和 LLM 的概率进行解码，然后进一步映射到点云补丁。这些补丁通过偏移量和索引对齐和合并。在最终的解码阶段，大补丁被结构化为
    K-树，以进行点云重建。在最终的重建后阶段，应用偏移量以重建原始点云。
- en: 'Our contributions are summarized as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的贡献总结如下：
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a novel architecture, namely LLM-PCGC, which is the first to apply
    LLM as a compressor to point cloud compression within the “Generator is compressor”
    framework. To the best of our knowledge, LLM-PCGC is also the first to transform
    LLM to a large model that can understand point cloud structure without any text
    information assistance.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新颖的架构，即 LLM-PCGC，它首次在“生成器是压缩器”框架内将 LLM 应用于点云压缩。据我们所知，LLM-PCGC 也是首个将 LLM
    转变为可以理解点云结构的大模型，而不依赖任何文本信息辅助。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose utilize different adaptation techniques for cross-modality representation
    alignment and semantic consistency, including clustering, K-tree, token mapping
    invariance, and LoRA, the proposed method can translate LLM to a compressor/generator
    for point cloud. The approach of token mapping invariance can be transferred to
    other modalities, offering a new paradigm for multimodal and cross-modal applications
    of LLMs.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提议利用不同的适应技术来进行跨模态表示对齐和语义一致性，包括聚类、K-树、标记映射不变性和 LoRA。该方法可以将 LLM 转换为点云的压缩器/生成器。标记映射不变性的方法可以转移到其他模态，提供了一种大语言模型的多模态和跨模态应用的新范式。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Experiments demonstrate that the LLM-PCGC outperforms the other existing methods
    significantly, by achieving -40.213% bit rate reduction compared to the G-PCC,
    and by achieving -2.267% bit rate reduction compared to the state-of-the-art learning-based
    method. As the first LLM-based point compression method, the proposed LLM-PCGC
    method achieves superior performances.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验表明，LLM-PCGC 显著优于其他现有方法，与 G-PCC 相比，达到 -40.213% 的比特率降低，与最先进的基于学习的方法相比，达到 -2.267%
    的比特率降低。作为第一个基于 LLM 的点云压缩方法，提出的 LLM-PCGC 方法表现卓越。
- en: Framework Overview
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 框架概述
- en: Encoding Pipline
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码流程
- en: 'The LLM-PCGC encoding pipeline is depicted in Fig. [2](#Sx1.F2 "Figure 2 ‣
    Introduction ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression").
    The encoding phase initiates with the clustering of input 3D point clouds, where
    each cluster undergoes parallel processing. This process involves several key
    steps, including normalization of coordinates through offset subtraction, organization
    of data using a K-tree structure, flattening and chunking of the hierarchical
    tree structure, and translation of the point cloud’s patch tokens into text tokens
    with a codebook. Special tokens, such as $<$ to denote the end token id, are incorporated
    to construct analogous linguistic sentences. The encoding process culminates with
    the employment of a trained LoRA architecture in conjunction with a frozen LLM
    to predict the next token’s probability distribution, which is then encoded using
    an arithmetic encoder.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM-PCGC 编码流程如图 [2](#Sx1.F2 "Figure 2 ‣ Introduction ‣ LLM-PCGC: Large Language
    Model-based Point Cloud Geometry Compression") 所示。编码阶段从对输入的 3D 点云进行聚类开始，每个聚类都经过并行处理。此过程涉及几个关键步骤，包括通过偏移量减法进行坐标归一化，使用
    K-tree 结构组织数据，扁平化和分块层次树结构，以及使用代码本将点云的补丁标记转换为文本标记。特别标记，如 $<$ 用于表示结束标记 ID，被纳入构建类似语言句子。编码过程以训练的
    LoRA 架构与冻结的 LLM 一起预测下一个标记的概率分布为终点，然后使用算术编码器进行编码。'
- en: Decoding Pipline
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解码流程
- en: 'The LLM-PCGC decoding pipeline is depicted in Fig. [3](#Sx1.F3 "Figure 3 ‣
    Introduction ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression").
    In the decoding phase, the parallel-received binary files are segmented to identify
    the corresponding offset, $<$, and the main bitstream for each bitstream. These
    identifiers are converted from binary to decimal values, facilitating the processing
    of the main bitstream through a trainable LoRA and a frozen LLM model to obtain
    a probability distribution for the next token, which is decoded using an arithmetic
    coder. The codebook then translates text tokens back into point cloud patch tokens,
    which are aligned and merged based on their common offset and chunk indexes. An
    algorithm is applied to reconstruct trees and coordinates. This algorithm ingeniously
    restores coordinates by counting the number of one, due to the lack of ancestral
    information. Finally, the cluster point clouds are adjusted by their respective
    offsets, reconstructing the full point cloud to its original form.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM-PCGC 解码流程如图 [3](#Sx1.F3 "Figure 3 ‣ Introduction ‣ LLM-PCGC: Large Language
    Model-based Point Cloud Geometry Compression") 所示。在解码阶段，平行接收的二进制文件被分段以识别相应的偏移量、$<$
    和每个比特流的主比特流。这些标识符从二进制转换为十进制值，便于通过可训练的 LoRA 和冻结的 LLM 模型处理主比特流，以获得下一个标记的概率分布，然后使用算术编码器进行解码。代码本将文本标记转换回点云补丁标记，这些标记根据它们的共同偏移量和块索引进行对齐和合并。应用算法重建树和坐标。该算法巧妙地通过计数
    1 的数量恢复坐标，因为缺乏祖先信息。最后，按照各自的偏移量调整聚类点云，将完整的点云恢复到其原始形式。'
- en: 'Table 1: Bpp performance gains compared to G-PCC and SparsePCGC anchors on
    MPEG 8i and Owlii datasets.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 与 MPEG 8i 和 Owlii 数据集上的 G-PCC 和 SparsePCGC 锚点相比的 Bpp 性能提升。'
- en: '| Dataset | Frame |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 帧 |'
- en: '&#124; G-PCC &#124;'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; G-PCC &#124;'
- en: '&#124; v14 &#124;'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; v14 &#124;'
- en: '|'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; SparsePCGC &#124;'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SparsePCGC &#124;'
- en: '&#124; 8-stage &#124;'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 8-stage &#124;'
- en: '|'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; LLM-PCGC &#124;'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; LLM-PCGC &#124;'
- en: '&#124; (Ours) &#124;'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (我们的) &#124;'
- en: '|'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Gain over &#124;'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 增益 &#124;'
- en: '&#124; G-PCC &#124;'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; G-PCC &#124;'
- en: '|'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Gain over &#124;'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 相比于 &#124;'
- en: '&#124; SparsePCGC &#124;'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SparsePCGC &#124;'
- en: '|'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| MPEG 8i | Longdress_vox10_1300 | 1.015 | 0.643 | 0.631 | -37.882% | -1.944%
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| MPEG 8i | Longdress_vox10_1300 | 1.015 | 0.643 | 0.631 | -37.882% | -1.944%
    |'
- en: '| Redandblack_vox10_1550 | 1.100 | 0.714 | 0.703 | -36.100% | -1.555% |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| Redandblack_vox10_1550 | 1.100 | 0.714 | 0.703 | -36.100% | -1.555% |'
- en: '| Soldier_vox10_0690 | 1.013 | 0.653 | 0.634 | -38.456% | -2.925% |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| Soldier_vox10_0690 | 1.013 | 0.653 | 0.634 | -38.456% | -2.925% |'
- en: '| Loot_vox10_1200 | 0.970 | 0.614 | 0.597 | -38.454% | -2.769% |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Loot_vox10_1200 | 0.970 | 0.614 | 0.597 | -38.454% | -2.769% |'
- en: '| Owlii | Basketball_player_vox11_0200 | 0.898 | 0.497 | 0.490 | -45.479% |
    -1.410% |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Owlii | Basketball_player_vox11_0200 | 0.898 | 0.497 | 0.490 | -45.479% |
    -1.410% |'
- en: '| Dancer_vox11_0001 | 0.880 | 0.500 | 0.485 | -44.909% | -3.079% |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Dancer_vox11_0001 | 0.880 | 0.500 | 0.485 | -44.909% | -3.079% |'
- en: '| Average |  | 0.982 | 0.603 | 0.590 | -40.213% | -2.267% |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 |  | 0.982 | 0.603 | 0.590 | -40.213% | -2.267% |'
- en: Experiments
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验
- en: Training and Testing Setting
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练和测试设置
- en: Data Processing
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据处理
- en: Given the current methods which autoregressive methods like OctAttention (Fu
    et al. [2022](#bib.bib5)), VoxelDNN (Nguyen et al. [2021a](#bib.bib12)), MSVoxelDNN
    (Nguyen et al. [2021b](#bib.bib13)), and NNOC (Kaya and Tabus [2021](#bib.bib8))
    utilize Microsoft Voxelized Upper Bodies (MVUB) (Loop et al. [2016](#bib.bib10))
    and 8i Voxelized Full Bodies (MPEG 8i) (d’Eon et al. [2017](#bib.bib4)) datasets
    for training, and other approaches like SparsePCGC (Wang et al. [2022](#bib.bib18))
    are trained on ShapeNet (Chang et al. [2015](#bib.bib2)), we aim to ensure fair
    comparison by training two sets of LLM-PCGC parameters on similar datasets.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于目前的方法，如OctAttention（Fu et al. [2022](#bib.bib5)）、VoxelDNN（Nguyen et al. [2021a](#bib.bib12)）、MSVoxelDNN（Nguyen
    et al. [2021b](#bib.bib13)）和NNOC（Kaya and Tabus [2021](#bib.bib8)）利用Microsoft
    Voxelized Upper Bodies (MVUB)（Loop et al. [2016](#bib.bib10)）和8i Voxelized Full
    Bodies (MPEG 8i)（d’Eon et al. [2017](#bib.bib4)）数据集进行训练，而其他方法如SparsePCGC（Wang
    et al. [2022](#bib.bib18)）则在ShapeNet（Chang et al. [2015](#bib.bib2)）上训练，我们旨在通过在类似数据集上训练两组LLM-PCGC参数来确保公平比较。
- en: In our experimental comparison with SparsePCGC, we group ModelNet40 (Wu et al.
    [2015](#bib.bib19)) point cloud data into 12 clusters, then organize 3D point
    cloud clusters in a K-Tree structure with K=12 for training. For testing, we follow
    the common test condition (CTC) (Schwarz et al. [2018](#bib.bib15)), which recommend
    to evaluate two public datasets, i.e., MPEG 8i and Owlii (Xu, Lu, and Wen [2017](#bib.bib21)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在与SparsePCGC的实验比较中，我们将ModelNet40 (Wu et al. [2015](#bib.bib19)) 点云数据分成12个集群，然后以K=12的K-Tree结构组织3D点云集群进行训练。测试时，我们遵循常见测试条件（CTC）（Schwarz
    et al. [2018](#bib.bib15)），建议评估两个公共数据集，即MPEG 8i和Owlii (Xu, Lu, and Wen [2017](#bib.bib21))。
- en: In relation to autoregressive methods such as OctAttention, VoxelDNN, MSVoxelDNN,
    and NNOC, we align with the norm by employing widely-used sequences for training.
    Specifically, we use the point cloud sequences of Andrew10, David10, and Sarah10
    from the MVUB, as well as the point cloud sequences of Longdress10 and Soldier10
    from MPEG 8i for training. We do a similar clustering process with the cluster
    number of 240 and K-Tree structure with K=12 for the chosen data. For testing,
    we select two point clouds from MPEG 8i, Thaidancer and Boxer, which both are
    downsampled from 12-bit to 10-bit resolution.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 关于OctAttention、VoxelDNN、MSVoxelDNN和NNOC等自回归方法，我们通过采用广泛使用的序列进行训练来与规范对齐。具体而言，我们使用来自MVUB的Andrew10、David10和Sarah10的点云序列，以及来自MPEG
    8i的Longdress10和Soldier10的点云序列进行训练。我们对选择的数据进行类似的聚类过程，集群数为240，K-Tree结构K=12。测试时，我们从MPEG
    8i中选择两个点云，Thaidancer和Boxer，它们都从12位下采样到10位分辨率。
- en: 'Table 2: Trainable parameters of LLaMA2-7B (Touvron et al. [2023](#bib.bib16))
    used in the proposed LLM-PCGC.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：用于提出的LLM-PCGC的LLaMA2-7B（Touvron et al. [2023](#bib.bib16)）的可训练参数。
- en: '| Configuration | LoRA | Embedding |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 配置 | LoRA | 嵌入 |'
- en: '| Component | [q, v, k, o, gate, up, down] in all layers | [lm_head, embed_tokens]
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 组件 | [q, v, k, o, gate, up, down] 在所有层中 | [lm_head, embed_tokens] |'
- en: '| Hyperparameters | $r=64$ | —— |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 超参数 | $r=64$ | —— |'
- en: '| Trainable params | 159,907,840 | 295,698,432 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 可训练参数 | 159,907,840 | 295,698,432 |'
- en: '| LLaMA2-7B params | 6,738,415,616 | 6,738,415,616 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA2-7B参数 | 6,738,415,616 | 6,738,415,616 |'
- en: '| Trainable% | 2.37% | 4.39% |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 可训练% | 2.37% | 4.39% |'
- en: Base Model and LoRA Setting
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础模型和LoRA设置
- en: 'Based on LLaMA (Touvron et al. [2023](#bib.bib16)), an open-source LLM that
    competes in performance with GPT-3 (Brown et al. [2020](#bib.bib1)), and taking
    into consideration the hardware resources available, we choose the smallest model,
    LLaMA2-7B, as our foundational model for this experiment. As delineated in Table
    [2](#Sx3.T2 "Table 2 ‣ Data Processing ‣ Training and Testing Setting ‣ Experiments
    ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression"), we
    provide a detailed description of the LoRA and Embedding modules of LLaMA2-7B.
    The total number of trainable parameters amounts to only 6.7% of the original
    base LLaMA2-7B model’s parameters. Our model is developed in PyTorch and runs
    on a system with Intel Xeon Gold 6248R CPUs and only an NVIDIA A40 GPU with 48GB
    of memory.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLaMA（Touvron等人[2023](#bib.bib16)），一个性能与GPT-3（Brown等人[2020](#bib.bib1)）相竞争的开源LLM，并考虑到可用的硬件资源，我们选择了最小的模型LLaMA2-7B作为本实验的基础模型。如表[2](#Sx3.T2
    "表 2 ‣ 数据处理 ‣ 训练和测试设置 ‣ 实验 ‣ LLM-PCGC：基于大型语言模型的点云几何压缩")所述，我们详细描述了LLaMA2-7B的LoRA和Embedding模块。可训练参数总数仅占原始LLaMA2-7B模型参数的6.7%。我们的模型在PyTorch中开发，并在配备Intel
    Xeon Gold 6248R CPU和仅有48GB内存的NVIDIA A40 GPU的系统上运行。
- en: '![Refer to caption](img/badfc099344346999fab4793219c1521.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/badfc099344346999fab4793219c1521.png)'
- en: 'Figure 4: Comparison of bpp among autoregressive methods and traditional method
    G-PCC.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：自回归方法与传统方法G-PCC的bpp比较。
- en: Experiment Results
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验结果
- en: 'For experimental comparison with SparsePCGC, we attempt to reproduce SparsePCGC
    using the similar synthetic ModelNet40 dataset, with bits per point (bpp) performance
    results presented in Table [1](#Sx2.T1 "Table 1 ‣ Decoding Pipline ‣ Framework
    Overview ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression").
    For MPEG 8i and Owlii dataset, our proposed LLM-PCGC method achieves -40.213%
    bit rate reduction compared to the reference software G-PCC v14 on average and
    up to 44.909% for Dancer_vox11_0001 and 45.479% for Basketball_player_vox11_0200\.
    Our method also outperforms achieves -2.267% bit rate reduction compared to the
    state-of-the-art learning-based SparsePCGC method.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与SparsePCGC进行实验比较，我们尝试使用类似的合成ModelNet40数据集重现SparsePCGC，其bpp性能结果见表[1](#Sx2.T1
    "表 1 ‣ 解码管道 ‣ 框架概述 ‣ LLM-PCGC：基于大型语言模型的点云几何压缩")。对于MPEG 8i和Owlii数据集，我们提出的LLM-PCGC方法相比于参考软件G-PCC
    v14，平均实现了-40.213%的比特率减少，对Dancer_vox11_0001和Basketball_player_vox11_0200的减少分别达到44.909%和45.479%。我们的方法还比最先进的基于学习的SparsePCGC方法实现了-2.267%的比特率减少。
- en: 'Regrettably, for the other autoregressive methods, we are not able to reproduce
    their results by ourselves due to the lack of source codes and relevant materials.
    Consequently, we reference the performance metrics directly as reported in their
    original publications. It should be noted that the Thaidancer_vox10 and Boxer_vox10
    datasets serve as the shared test sets for the evaluation of other autoregressive
    methods. Accordingly, our examination is confined to the evaluation of compression
    efficacy on these two specific point cloud datasets, as shown in Fig. [4](#Sx3.F4
    "Figure 4 ‣ Base Model and LoRA Setting ‣ Training and Testing Setting ‣ Experiments
    ‣ LLM-PCGC: Large Language Model-based Point Cloud Geometry Compression"). Building
    upon the identical G-PCC benchmark, the proposed LLM-PCGC achieves the lowest
    bpp rate. For instance, it records an average of 0.52 bpp for the MPEG 8i dataset.
    This marks a reduction of 0.20 bpp from the results achieved by both MSVoxelDNN
    and fNNOC. In contrast to the OctAttention, which necessitates the inclusion of
    1024 neighboring nodes for context modeling, our LLM-PCGC leverages a more robust
    context model. Remarkably, even in the absence of assistance from ancestor nodes,
    it still manages to achieve a reduction of 0.10 bpp compared to OctAttention.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 遗憾的是，对于其他自回归方法，由于缺乏源代码和相关材料，我们无法自行重现其结果。因此，我们直接参考了其原始出版物中报告的性能指标。需要注意的是，Thaidancer_vox10和Boxer_vox10数据集作为其他自回归方法的共享测试集。因此，我们的检查仅限于对这两个特定点云数据集的压缩效果评估，如图[4](#Sx3.F4
    "图 4 ‣ 基础模型和LoRA设置 ‣ 训练和测试设置 ‣ 实验 ‣ LLM-PCGC：基于大型语言模型的点云几何压缩")所示。基于相同的G-PCC基准，提出的LLM-PCGC实现了最低的bpp率。例如，对于MPEG
    8i数据集，它的平均bpp为0.52。这比MSVoxelDNN和fNNOC的结果减少了0.20 bpp。与需要1024个邻近节点进行上下文建模的OctAttention相比，我们的LLM-PCGC利用了更强大的上下文模型。值得注意的是，即使没有祖先节点的辅助，它仍能相比OctAttention实现0.10
    bpp的减少。
- en: Conclusion
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this paper, we propose the LLM-PCGC method, which is the first to employ
    LLM as compressor for the point cloud compression task within the “Generator is
    compressor” framework. We utilize different adaptation techniques, i.e., clustering,
    K-tree, token mapping invariance, and LoRA, to achieve efficient cross-modality
    representation alignment and semantic consistency. Without any text data, a text
    generator can be translated to a point cloud compressor. Experimental results
    show that the proposed LLM-PCGC method achieves superior compression performance
    over G-PCC and the state-of-the-art learning-based method, demonstrating the potential
    of LLMs in data compression. Although as the first attempt to develop a LLM-based
    point compression method, the proposed LLM-PCGC method achieves superior performances,
    future research efforts can be made for optimizing the issues on the excessive
    memory consumption and the long inference time of LLMs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了 LLM-PCGC 方法，这是首个在“生成器是压缩器”框架下将 LLM 用作点云压缩任务的压缩器的方法。我们利用不同的适配技术，即聚类、K-树、标记映射不变性和
    LoRA，实现高效的跨模态表示对齐和语义一致性。无需任何文本数据，文本生成器可以转化为点云压缩器。实验结果表明，所提出的 LLM-PCGC 方法在压缩性能上优于
    G-PCC 和最先进的学习基础方法，展示了 LLM 在数据压缩中的潜力。尽管作为首次尝试开发基于 LLM 的点云压缩方法，所提出的 LLM-PCGC 方法已经实现了优越的性能，但未来的研究可以致力于优化
    LLM 的过度内存消耗和长推理时间的问题。
- en: References
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Brown et al. (2020) Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;
    Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; et al. 2020.
    Language models are few-shot learners. *Advances in neural information processing
    systems*, 33: 1877–1901.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Brown 等 (2020) Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;
    Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; 等. 2020. 语言模型是少样本学习者。*神经信息处理系统进展*,
    33: 1877–1901.'
- en: 'Chang et al. (2015) Chang, A. X.; Funkhouser, T.; Guibas, L.; Hanrahan, P.;
    Huang, Q.; Li, Z.; Savarese, S.; Savva, M.; Song, S.; Su, H.; et al. 2015. Shapenet:
    An information-rich 3d model repository. *arXiv preprint arXiv:1512.03012*.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chang 等 (2015) Chang, A. X.; Funkhouser, T.; Guibas, L.; Hanrahan, P.; Huang,
    Q.; Li, Z.; Savarese, S.; Savva, M.; Song, S.; Su, H.; 等. 2015. Shapenet: 一个信息丰富的三维模型库。*arXiv
    预印本 arXiv:1512.03012*.'
- en: Delétang et al. (2024) Delétang, G.; Ruoss, A.; Duquenne, P.; Catt, E.; Genewein,
    T.; Mattern, C.; Grau-Moya, J.; Wenliang, L. K.; Aitchison, M.; Orseau, L.; Hutter,
    M.; and Veness, J. 2024. Language Modeling Is Compression. In *ICLR*.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Delétang 等 (2024) Delétang, G.; Ruoss, A.; Duquenne, P.; Catt, E.; Genewein,
    T.; Mattern, C.; Grau-Moya, J.; Wenliang, L. K.; Aitchison, M.; Orseau, L.; Hutter,
    M.; 和 Veness, J. 2024. 语言建模即压缩。*ICLR*.
- en: 'd’Eon et al. (2017) d’Eon, E.; Harrison, B.; Myers, T.; and Chou, P. A. 2017.
    8i voxelized full bodies-a voxelized point cloud dataset. *ISO/IEC JTC1/SC29 Joint
    WG11/WG1 (MPEG/JPEG) input document WG11M40059/WG1M74006*, 7(8): 11.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'd’Eon 等 (2017) d’Eon, E.; Harrison, B.; Myers, T.; 和 Chou, P. A. 2017. 8i 体素化完整身体——体素化点云数据集。*ISO/IEC
    JTC1/SC29 联合 WG11/WG1 (MPEG/JPEG) 输入文档 WG11M40059/WG1M74006*, 7(8): 11.'
- en: 'Fu et al. (2022) Fu, C.; Li, G.; Song, R.; Gao, W.; and Liu, S. 2022. Octattention:
    Octree-based large-scale contexts model for point cloud compression. In *Proceedings
    of the AAAI conference on artificial intelligence*, volume 36, 625–633.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu 等 (2022) Fu, C.; Li, G.; Song, R.; Gao, W.; 和 Liu, S. 2022. Octattention:
    基于八叉树的大规模上下文模型用于点云压缩。*人工智能会议论文集*, 第 36 卷, 625–633.'
- en: 'Hong et al. (2023) Hong, Y.; Zhen, H.; Chen, P.; Zheng, S.; Du, Y.; Chen, Z.;
    and Gan, C. 2023. 3d-llm: Injecting the 3d world into large language models. *Advances
    in Neural Information Processing Systems*, 36: 20482–20494.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hong 等 (2023) Hong, Y.; Zhen, H.; Chen, P.; Zheng, S.; Du, Y.; Chen, Z.; 和
    Gan, C. 2023. 3d-llm: 将三维世界注入大型语言模型。*神经信息处理系统进展*, 36: 20482–20494.'
- en: Kaplan et al. (2020) Kaplan, J.; McCandlish, S.; Henighan, T.; Brown, T. B.;
    Chess, B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; and Amodei, D. 2020. Scaling
    laws for neural language models. *arXiv preprint arXiv:2001.08361*.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaplan 等 (2020) Kaplan, J.; McCandlish, S.; Henighan, T.; Brown, T. B.; Chess,
    B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; 和 Amodei, D. 2020. 神经语言模型的规模定律。*arXiv
    预印本 arXiv:2001.08361*.
- en: Kaya and Tabus (2021) Kaya, E. C.; and Tabus, I. 2021. Neural network modeling
    of probabilities for coding the octree representation of point clouds. In *2021
    IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)*, 1–6\.
    IEEE.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaya 和 Tabus (2021) Kaya, E. C.; 和 Tabus, I. 2021. 用于编码点云八叉树表示的概率的神经网络建模。*2021
    IEEE 第23届多媒体信号处理国际研讨会 (MMSP)*, 1–6. IEEE.
- en: Li et al. (2024) Li, Y.; Guo, Y.; Guerin, F.; and Lin, C. 2024. Evaluating Large
    Language Models for Generalization and Robustness via Data Compression. *arXiv
    preprint arXiv:2402.00861*.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2024) Li, Y.; Guo, Y.; Guerin, F.; 和 Lin, C. 2024. 通过数据压缩评估大型语言模型的泛化能力和鲁棒性。*arXiv
    预印本 arXiv:2402.00861*。
- en: 'Loop et al. (2016) Loop, C.; Cai, Q.; Escolano, S. O.; and Chou, P. A. 2016.
    Microsoft voxelized upper bodies-a voxelized point cloud dataset. *ISO/IEC JTC1/SC29
    Joint WG11/WG1 (MPEG/JPEG) input document m38673 M*, 72012: 2016.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Loop 等人 (2016) Loop, C.; Cai, Q.; Escolano, S. O.; 和 Chou, P. A. 2016. 微软体素化上半身-一个体素化点云数据集。*ISO/IEC
    JTC1/SC29 联合 WG11/WG1 (MPEG/JPEG) 输入文档 m38673 M*，72012: 2016。'
- en: Mirchandani et al. (2023) Mirchandani, S.; Xia, F.; Florence, P.; Ichter, B.;
    Driess, D.; Arenas, M. G.; Rao, K.; Sadigh, D.; and Zeng, A. 2023. Large Language
    Models as General Pattern Machines. In *Proceedings of the 7th Conference on Robot
    Learning (CoRL)*.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mirchandani 等人 (2023) Mirchandani, S.; Xia, F.; Florence, P.; Ichter, B.; Driess,
    D.; Arenas, M. G.; Rao, K.; Sadigh, D.; 和 Zeng, A. 2023. 大型语言模型作为通用模式机器。见 *第7届机器人学习会议
    (CoRL) 论文集*。
- en: 'Nguyen et al. (2021a) Nguyen, D. T.; Quach, M.; Valenzise, G.; and Duhamel,
    P. 2021a. Lossless coding of point cloud geometry using a deep generative model.
    *IEEE Transactions on Circuits and Systems for Video Technology*, 31(12): 4617–4629.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nguyen 等人 (2021a) Nguyen, D. T.; Quach, M.; Valenzise, G.; 和 Duhamel, P. 2021a.
    使用深度生成模型的点云几何无损编码。*IEEE 视频技术电路与系统汇刊*，31(12): 4617–4629。'
- en: Nguyen et al. (2021b) Nguyen, D. T.; Quach, M.; Valenzise, G.; and Duhamel,
    P. 2021b. Multiscale deep context modeling for lossless point cloud geometry compression.
    In *2021 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)*,
    1–6\. IEEE.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen 等人 (2021b) Nguyen, D. T.; Quach, M.; Valenzise, G.; 和 Duhamel, P. 2021b.
    多尺度深度上下文建模用于无损点云几何压缩。见 *2021 IEEE 国际多媒体与博览会研讨会 (ICMEW)*，1–6\. IEEE。
- en: 'Que, Lu, and Xu (2021) Que, Z.; Lu, G.; and Xu, D. 2021. Voxelcontext-net:
    An octree based framework for point cloud compression. In *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 6042–6051.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Que, Lu 和 Xu (2021) Que, Z.; Lu, G.; 和 Xu, D. 2021. Voxelcontext-net: 基于八叉树的点云压缩框架。见
    *IEEE/CVF 计算机视觉与模式识别会议论文集*，6042–6051。'
- en: Schwarz et al. (2018) Schwarz, S.; Martin-Cocher, G.; Flynn, D.; and Budagavi,
    M. 2018. Common test conditions for point cloud compression. *Document ISO/IEC
    JTC1/SC29/WG11 w17766, Ljubljana, Slovenia*.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwarz 等人 (2018) Schwarz, S.; Martin-Cocher, G.; Flynn, D.; 和 Budagavi, M.
    2018. 点云压缩的常见测试条件。*文档 ISO/IEC JTC1/SC29/WG11 w17766, 卢布尔雅那，斯洛文尼亚*。
- en: 'Touvron et al. (2023) Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
    M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; et al. 2023.
    Llama: Open and efficient foundation language models. *arXiv preprint arXiv:2302.13971*.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人 (2023) Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
    M.-A.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; 等. 2023. Llama:
    开放且高效的基础语言模型。*arXiv 预印本 arXiv:2302.13971*。'
- en: 'Valmeekam et al. (2023) Valmeekam, C. S. K.; Narayanan, K.; Kalathil, D.; Chamberland,
    J.-F.; and Shakkottai, S. 2023. Llmzip: Lossless text compression using large
    language models. *arXiv preprint arXiv:2306.04050*.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Valmeekam 等人 (2023) Valmeekam, C. S. K.; Narayanan, K.; Kalathil, D.; Chamberland,
    J.-F.; 和 Shakkottai, S. 2023. Llmzip: 使用大型语言模型的无损文本压缩。*arXiv 预印本 arXiv:2306.04050*。'
- en: Wang et al. (2022) Wang, J.; Ding, D.; Li, Z.; Feng, X.; Cao, C.; and Ma, Z.
    2022. Sparse tensor-based multiscale representation for point cloud geometry compression.
    *IEEE Transactions on Pattern Analysis and Machine Intelligence*.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2022) Wang, J.; Ding, D.; Li, Z.; Feng, X.; Cao, C.; 和 Ma, Z. 2022.
    基于稀疏张量的多尺度表示用于点云几何压缩。*IEEE 模式分析与机器智能汇刊*。
- en: 'Wu et al. (2015) Wu, Z.; Song, S.; Khosla, A.; Yu, F.; Zhang, L.; Tang, X.;
    and Xiao, J. 2015. 3d shapenets: A deep representation for volumetric shapes.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*,
    1912–1920.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人 (2015) Wu, Z.; Song, S.; Khosla, A.; Yu, F.; Zhang, L.; Tang, X.; 和 Xiao,
    J. 2015. 3d shapenets: 一种体积形状的深度表示。见 *IEEE 计算机视觉与模式识别会议论文集*，1912–1920。'
- en: 'Xu et al. (2023) Xu, R.; Wang, X.; Wang, T.; Chen, Y.; Pang, J.; and Lin, D.
    2023. Pointllm: Empowering large language models to understand point clouds. *arXiv
    preprint arXiv:2308.16911*.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu 等人 (2023) Xu, R.; Wang, X.; Wang, T.; Chen, Y.; Pang, J.; 和 Lin, D. 2023.
    Pointllm: 赋能大型语言模型理解点云。*arXiv 预印本 arXiv:2308.16911*。'
- en: Xu, Lu, and Wen (2017) Xu, Y.; Lu, Y.; and Wen, Z. 2017. Owlii dynamic human
    mesh sequence dataset. In *ISO/IEC JTC1/SC29/WG11 m41658, 120th MPEG Meeting*,
    volume 1, 8.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu, Lu 和 Wen (2017) Xu, Y.; Lu, Y.; 和 Wen, Z. 2017. Owlii 动态人类网格序列数据集。见 *ISO/IEC
    JTC1/SC29/WG11 m41658, 第120届 MPEG 会议*，第 1 卷，8。
- en: 'Yin et al. (2023) Yin, F.; Chen, X.; Zhang, C.; Jiang, B.; Zhao, Z.; Fan, J.;
    Yu, G.; Li, T.; and Chen, T. 2023. ShapeGPT: 3D Shape Generation with A Unified
    Multi-modal Language Model. arXiv:2311.17618.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yin 等人（2023）Yin, F.; Chen, X.; Zhang, C.; Jiang, B.; Zhao, Z.; Fan, J.; Yu,
    G.; Li, T.; 和 Chen, T. 2023. ShapeGPT: 通过统一的多模态语言模型进行 3D 形状生成。arXiv:2311.17618。'
- en: Yu et al. (2024) Yu, Y.; Buchanan, S.; Pai, D.; Chu, T.; Wu, Z.; Tong, S.; Haeffele,
    B.; and Ma, Y. 2024. White-box transformers via sparse rate reduction. *Advances
    in Neural Information Processing Systems*, 36.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人（2024）Yu, Y.; Buchanan, S.; Pai, D.; Chu, T.; Wu, Z.; Tong, S.; Haeffele,
    B.; 和 Ma, Y. 2024. 通过稀疏率降低的白盒变换器。*神经信息处理系统进展*，36。
