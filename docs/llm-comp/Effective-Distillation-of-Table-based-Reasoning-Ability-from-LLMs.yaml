- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:59:38'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:59:38
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Effective Distillation of Table-based Reasoning Ability from LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从大型语言模型中有效蒸馏基于表格的推理能力
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2309.13182](https://ar5iv.labs.arxiv.org/html/2309.13182)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2309.13182](https://ar5iv.labs.arxiv.org/html/2309.13182)
- en: Bohao Yang¹, Chen Tang², Kun Zhao³, Chenghao Xiao⁴, Chenghua Lin¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Bohao Yang¹, Chen Tang², Kun Zhao³, Chenghao Xiao⁴, Chenghua Lin¹
- en: ¹Department of Computer Science, The University of Manchester, UK
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ¹计算机科学系，曼彻斯特大学，英国
- en: ²Department of Computer Science, The University of Surrey, UK
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ²计算机科学系，萨里大学，英国
- en: ³University of Pittsburgh, US
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³匹兹堡大学，美国
- en: ⁴Department of Computer Science, The University of Durham, UK
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴计算机科学系，达勒姆大学，英国
- en: bohaoyang217@gmail.com,  chen.tang@surrey.ac.uk,
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: bohaoyang217@gmail.com,  chen.tang@surrey.ac.uk,
- en: kun.zhao@pitt.edu, chenghao.xiao@durham.ac.uk
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: kun.zhao@pitt.edu, chenghao.xiao@durham.ac.uk
- en: c.lin@manchester.ac.uk  Corresponding author.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: c.lin@manchester.ac.uk  通讯作者。
- en: Abstract
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have demonstrated remarkable performance across
    a wide range of natural language processing tasks. However, their remarkable parameter
    size and their impressive high requirement of computing resources pose challenges
    for their practical deployment. Recent research has revealed that specific capabilities
    of LLMs, such as numerical reasoning, can be transferred to smaller models through
    distillation. Some studies explore the potential of leveraging LLMs to perform
    table-based reasoning. Nevertheless, prior to our work, there has been no investigation
    into the prospect of specialising table reasoning skills in smaller models specifically
    tailored for table-to-text generation tasks. In this paper, we propose a novel
    table-based reasoning distillation, with the aim of distilling LLMs into tailored,
    smaller models specifically designed for table-based reasoning task. Experimental
    results have shown that a 0.22 billion parameter model (Flan-T5-base) fine-tuned
    using distilled data, not only achieves a significant improvement compared to
    traditionally fine-tuned baselines but also surpasses specific LLMs like gpt-3.5-turbo
    on the scientific table-to-text generation dataset (SciGen). The code and data
    are released in [https://github.com/Bernard-Yang/TableDistill.](https://github.com/Bernard-Yang/TableDistill.)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在广泛的自然语言处理任务中展示了卓越的性能。然而，它们巨大的参数规模和高计算资源需求给实际部署带来了挑战。近期研究显示，LLMs
    的某些特定能力，如数值推理，可以通过蒸馏转移到较小的模型中。一些研究探讨了利用 LLMs 进行基于表格的推理的潜力。然而，在我们的工作之前，尚无专门针对表格到文本生成任务的小型模型中专业化表格推理能力的研究。本文提出了一种新颖的基于表格的推理蒸馏方法，旨在将
    LLMs 蒸馏成专为基于表格的推理任务设计的小型模型。实验结果表明，使用蒸馏数据微调的0.22亿参数模型（Flan-T5-base），不仅在传统微调基准上取得了显著的改进，还在科学表格到文本生成数据集（SciGen）上超越了特定的
    LLMs，如 gpt-3.5-turbo。代码和数据已发布在 [https://github.com/Bernard-Yang/TableDistill.](https://github.com/Bernard-Yang/TableDistill.)
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Tables, as a ubiquitous and pivotal means of knowledge storage, has been receiving
    an increasing attention in contemporary research. Tabular data, when juxtaposed
    with textual data, furnishes a valuable and complementary source of information.
    The intersection of tabular and textual information constitutes a well-established
    problem within the domain of Natural Language Processing (NLP), with impacts spanning
    a diverse spectrum of downstream tasks, including table question answering (Pasupat
    and Liang, [2015](#bib.bib33); Cho et al., [2019](#bib.bib10); Nan et al., [2022](#bib.bib31)),
    and table fact checking (Chen et al., [2020c](#bib.bib8); Gupta et al., [2020](#bib.bib16);
    Aly et al., [2021](#bib.bib1); Lu et al., [2023](#bib.bib27)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 表格作为一种普遍且关键的知识存储方式，近年来在当代研究中受到了越来越多的关注。与文本数据相对照时，表格数据提供了宝贵且互补的信息源。表格信息与文本信息的交集是自然语言处理（NLP）领域中一个成熟的问题，影响着各种下游任务，包括表格问答（Pasupat和Liang，[2015](#bib.bib33)；Cho等，[2019](#bib.bib10)；Nan等，[2022](#bib.bib31)），以及表格事实核查（Chen等，[2020c](#bib.bib8)；Gupta等，[2020](#bib.bib16)；Aly等，[2021](#bib.bib1)；Lu等，[2023](#bib.bib27)）。
- en: Conventional approaches to table-based reasoning (Pasupat and Liang, [2015](#bib.bib33);
    Zhong et al., [2017](#bib.bib47); Yu et al., [2018](#bib.bib42)) have predominantly
    relied on the synthesis of executable languages such as SQL or SPARQL to facilitate
    information retrieval from tables. However, these symbolic languages often entail
    rigid assumptions regarding table structures, rendering them incapable of capturing
    the semantics embedded in textual segments within the table. A holistic comprehension
    of web tables necessitates the understanding of both structured reasoning with
    textual reasoning. For this goal, the emergence of table-based pre-trained models (Herzig
    et al., [2020](#bib.bib17); Liu et al., [2021](#bib.bib26); Jiang et al., [2022](#bib.bib21);
    Cai et al., [2022](#bib.bib4)) has underscored the efficacy of pre-training models
    on both textual and tabular data for augmenting reasoning capabilities. This improvement
    stems from the extensive knowledge obtained from the large-scale crawling or synthesising
    of tabular and textual data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的基于表格的推理方法（Pasupat 和 Liang，[2015](#bib.bib33)；Zhong 等，[2017](#bib.bib47)；Yu
    等，[2018](#bib.bib42)）主要依赖于可执行语言的合成，如 SQL 或 SPARQL，以促进从表格中检索信息。然而，这些符号语言通常对表格结构有严格的假设，使得它们无法捕捉表格中文本段落所包含的语义。对网络表格的全面理解需要同时掌握结构化推理和文本推理。为实现这一目标，基于表格的预训练模型（Herzig
    等，[2020](#bib.bib17)；Liu 等，[2021](#bib.bib26)；Jiang 等，[2022](#bib.bib21)；Cai 等，[2022](#bib.bib4)）的出现突显了在文本和表格数据上进行预训练模型的有效性，以增强推理能力。这一改进源于从大规模爬取或合成表格和文本数据中获得的广泛知识。
- en: In recent years, the advent of Large Language Models (LLMs) has brought a revolution
    in the landscape of NLP, ushering in a new era marked by their remarkable prowess
    demonstrated across a multitude of tasks (Brown et al., [2020](#bib.bib3); Chowdhery
    et al., [2022](#bib.bib11); Touvron et al., [2023](#bib.bib37)). These models
    leverage vast corpora of textual data, undergoing extensive pre-training, and
    exhibit an exceptional capacity to tackle intricate mathematical and commonsense
    reasoning tasks, often within the context of few-shot and zero-shot learning scenarios
    with Chain-of-Thought (CoT)  (Wei et al., [2022](#bib.bib40); Wang et al., [2022](#bib.bib39);
    Zhou et al., [2023](#bib.bib48); Drozdov et al., [2022](#bib.bib13)). Drawing
    inspiration from these groundbreaking developments, a range of studies (Chen,
    [2023](#bib.bib5); Ye et al., [2023](#bib.bib41); Cheng et al., [2023](#bib.bib9);
    Gemmell and Dalton, [2023](#bib.bib15); Lu et al., [2023](#bib.bib27)) has emerged
    to highlight the competitive performance of LLMs in comparison to state-of-the-art
    fine-tuned models in the domain of table reasoning tasks (i.e., table question
    answering and table fact checking). For instance, Zhao et al. ([2023](#bib.bib46))
    delved into the potential of employing LLMs augmented with CoT techniques in the
    LogicNLG dataset Chen et al. ([2020c](#bib.bib8)), for the table-to-text generation
    tasks. Despite these notable strides, prior research has not focused on the challenging
    domain of complex reasoning-aware scientific table-to-text generation tasks using
    LLMs, nor have attempts been made to distill the intrinsic table-based reasoning
    capabilities of these models into more compact counterparts. In this paper, we
    investigate the capabilities of LLMs in the reasoning-aware scientific table-to-text
    generation, and propose a two-step distillation approach to transfer the table-based
    reasoning ability of LLMs into smaller models. We select SciGen Moosavi et al.
    ([2021](#bib.bib30)) dataset for our experiments, as the task setting of SciGen
    is the first scientific table-to-text dataset and is more challenging than other
    benchmarks, such as LogicNLG Chen et al. ([2020a](#bib.bib6)). Here, the descriptions
    mandate the LLMs to comprehensively grasp the provided tables and engage in arithmetic
    reasoning encompassing both tabular and textual data, rather than merely converting
    the superficial representation of table contents. In the data generation stage,
    we utilise LLMs to generate table-based reasoning and consistency statements based
    on the input table, employing a one-shot CoT methodology. . Subsequently, in the
    fine-tuning phase, we employ the distilled CoT data generated by LLMs to imbue
    smaller models with table reasoning proficiency.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLMs）的出现引发了自然语言处理领域的革命，开启了一个以其在众多任务中展现出的卓越能力为特征的新纪元（Brown et al.,
    [2020](#bib.bib3); Chowdhery et al., [2022](#bib.bib11); Touvron et al., [2023](#bib.bib37)）。这些模型利用庞大的文本数据语料库，经过广泛的预训练，并展现出在复杂的数学和常识推理任务中的卓越能力，通常在少量样本和零样本学习场景下运用链式思维（CoT）方法（Wei
    et al., [2022](#bib.bib40); Wang et al., [2022](#bib.bib39); Zhou et al., [2023](#bib.bib48);
    Drozdov et al., [2022](#bib.bib13)）。受到这些突破性发展的启发，一系列研究（Chen, [2023](#bib.bib5);
    Ye et al., [2023](#bib.bib41); Cheng et al., [2023](#bib.bib9); Gemmell and Dalton,
    [2023](#bib.bib15); Lu et al., [2023](#bib.bib27)）应运而生，突出了LLMs在表格推理任务（即表格问答和表格事实检查）方面相较于最先进的微调模型的竞争性能。例如，Zhao
    et al. ([2023](#bib.bib46)) 探讨了在 LogicNLG 数据集（Chen et al., [2020c](#bib.bib8)）中使用增强
    CoT 技术的 LLMs 的潜力，以进行表格到文本生成任务。尽管取得了这些显著进展，但先前的研究尚未关注使用 LLMs 进行复杂推理感知的科学表格到文本生成任务，也没有尝试将这些模型固有的基于表格的推理能力提炼成更紧凑的模型。在本文中，我们调查了
    LLMs 在推理感知科学表格到文本生成中的能力，并提出了一种两步提炼方法，将 LLMs 的表格推理能力转移到更小的模型中。我们选择了 SciGen 数据集（Moosavi
    et al., [2021](#bib.bib30)）进行实验，因为 SciGen 的任务设置是首个科学表格到文本数据集，比其他基准（如 LogicNLG（Chen
    et al., [2020a](#bib.bib6)））更具挑战性。在数据生成阶段，我们利用 LLMs 基于输入表格生成表格推理和一致性陈述，采用一次性 CoT
    方法。随后，在微调阶段，我们使用 LLMs 生成的提炼 CoT 数据赋予较小模型表格推理能力。
- en: Our experimental results underscore that fine-tuning smaller models with table-based
    reasoning data distilled from LLMs leads to significant performance enhancements
    compared to baseline models in the context of scientific table-to-text generation
    tasks. Distillation empowers models with as few as 0.22 billion parameters to
    outperform larger student models and even surpass the 175 billion-parameter teacher
    model in certain metrics.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验结果强调了用从LLMs中提取的基于表格的推理数据微调较小模型相比于基线模型，在科学表格到文本生成任务中带来了显著的性能提升。蒸馏使得参数量仅有0.22亿的模型能够超越较大的学生模型，甚至在某些指标上超越了175亿参数的教师模型。
- en: '![Refer to caption](img/cf4210818965f33e315b832748607bac.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cf4210818965f33e315b832748607bac.png)'
- en: 'Figure 1: The overview of our framework.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们框架的概述。
- en: 2 Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Table-based Reasoning.   Table-based reasoning tasks require the ability to
    reason over both natural language and structured tables. Traditional table-based
    reasoning involves employing semantic parsing to execute commands on tables, several
    benchmarks including WikiTableQuestions Pasupat and Liang ([2015](#bib.bib33)),
    WikiSQL Zhong et al. ([2017](#bib.bib47)), and Spider Yu et al. ([2018](#bib.bib42)).
    These models are designed to produce SQL for interacting with tables. However,
    the machine languages impose strict criteria on tables and make these method cannot
    understand the semantics of text segments in the tables. Some works proposed to
    learn joint representation by pre-training table and text (Herzig et al., [2020](#bib.bib17);
    Liu et al., [2021](#bib.bib26); Zhao et al., [2022](#bib.bib45)). Through pre-training
    the model on extensive synthesized data, they can achieve desirable performance
    on table-related tasks. Recent works Chen ([2023](#bib.bib5)); Ye et al. ([2023](#bib.bib41));
    Nan et al. ([2023](#bib.bib32)) have shown the ability of LLMs in table reasoning
    tasks by in-context learning. Lu et al. ([2023](#bib.bib27)) use LLMs to perform
    reasoning in scientific table fact-checking task. This task require compositional
    reasoning using scientific tables as evidence. BINDER (Cheng et al., [2023](#bib.bib9))
    use Codex to synthesize SQL language to execute logical forms against tables in
    question answering task.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 基于表格的推理。基于表格的推理任务要求能够对自然语言和结构化表格进行推理。传统的基于表格的推理涉及使用语义解析来执行对表格的命令，包括WikiTableQuestions
    Pasupat 和 Liang ([2015](#bib.bib33))、WikiSQL Zhong et al. ([2017](#bib.bib47))
    和 Spider Yu et al. ([2018](#bib.bib42)) 等几个基准。这些模型旨在生成SQL来与表格进行交互。然而，机器语言对表格施加了严格的标准，使这些方法无法理解表格中文本段的语义。一些研究提出通过预训练表格和文本来学习联合表示（Herzig
    et al., [2020](#bib.bib17)；Liu et al., [2021](#bib.bib26)；Zhao et al., [2022](#bib.bib45)）。通过在大量合成数据上进行预训练，它们在与表格相关的任务上能实现理想的性能。最近的研究
    Chen ([2023](#bib.bib5))；Ye et al. ([2023](#bib.bib41))；Nan et al. ([2023](#bib.bib32))
    已展示了LLMs在表格推理任务中的能力。Lu et al. ([2023](#bib.bib27)) 使用LLMs在科学表格事实核查任务中进行推理。该任务需要使用科学表格作为证据进行组合推理。BINDER
    (Cheng et al., [2023](#bib.bib9)) 使用Codex合成SQL语言，以在问答任务中对表格执行逻辑形式。
- en: Chian-of-thought Reasoning. CoT prompting encourages LLMs to break down a reasoning
    task into a series of intermediate steps, therefore enhances the reasoning ability
    across various tasks (Wei et al., [2022](#bib.bib40)). With a few CoT reasoning
    examples, the LLMs can achieve the state-of-the-art performance on complex math
    problem sovling. Self-consistency CoT (Wang et al., [2023](#bib.bib38)) involves
    sampling multiple CoTs and selecting the most consistent one by beam searching.
    Kojima et al. ([2022](#bib.bib22)) proposed zero-shot CoT by first generating
    CoT template and produce the final answer with LLMs in zero-shot setting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链推理。CoT提示鼓励LLMs将推理任务分解为一系列中间步骤，从而增强了在各种任务中的推理能力（Wei et al., [2022](#bib.bib40)）。通过几个CoT推理示例，LLMs可以在复杂的数学问题解决中实现最先进的性能。自一致性CoT（Wang
    et al., [2023](#bib.bib38)）涉及对多个CoT进行采样，并通过束搜索选择最一致的一个。Kojima et al. ([2022](#bib.bib22))
    提出了零样本CoT，通过首先生成CoT模板，并在零样本设置下用LLMs生成最终答案。
- en: Knowledge Distillation.  Distillation has demonstrated its effectiveness in
    transferring valuable capabilities from a larger model to a smaller one (Hinton
    et al., [2015](#bib.bib18); Sanh et al., [2019](#bib.bib35); Zeng et al., [2022](#bib.bib43)).
    Recent works have shown that synthetic data generated by the teacher model can
    effectively transfer the specialized abilities, i.e. numerical reasoning, to the
    student model. Chung et al. ([2022](#bib.bib12)) use manually generated CoT data
    to finetune a FLAN-based version of PaLM Chowdhery et al. ([2022](#bib.bib11)).
    Fu et al. ([2023](#bib.bib14)) employed enriched chain-of-thought data to specialize
    the small model. Ho et al. ([2023](#bib.bib19)) propose diverse CoT to sample
    different reasoning outputs from LLMs to fine-tune a smaller model. Magister et al.
    ([2023](#bib.bib29)) propose a two-step pipeline for transferring the reasoning
    capabilities of large models to smaller models. Hsieh et al. ([2023](#bib.bib20))
    extracted rationales from LLMs and integrated such data in the smaller model instruction
    tuning framework. Zhu et al. ([2023](#bib.bib49)) distill the program produced
    by LLMs to specialize reasoning ability into small models. We extend the above
    ideas to table-based reasoning task, specifically in scientific table-to-text
    generation task, which the generated CoT data leads to the improved table reasoning
    performance.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 知识蒸馏。蒸馏已证明其在将有价值的能力从大型模型转移到小型模型中的有效性（Hinton et al., [2015](#bib.bib18)；Sanh
    et al., [2019](#bib.bib35)；Zeng et al., [2022](#bib.bib43)）。最近的研究表明，教师模型生成的合成数据可以有效地将专门的能力（即数值推理）转移到学生模型中。Chung
    et al. ([2022](#bib.bib12))使用手动生成的CoT数据来微调基于FLAN的PaLM版本（Chowdhery et al. ([2022](#bib.bib11)））。Fu
    et al. ([2023](#bib.bib14))利用丰富的思维链数据来专门化小型模型。Ho et al. ([2023](#bib.bib19))提出了多样化的CoT来从LLMs中采样不同的推理输出以微调较小的模型。Magister
    et al. ([2023](#bib.bib29))提出了一个两步流程，将大型模型的推理能力转移到较小的模型中。Hsieh et al. ([2023](#bib.bib20))从LLMs中提取了理由，并将这些数据集成到较小模型的指令调优框架中。Zhu
    et al. ([2023](#bib.bib49))将LLMs生成的程序蒸馏到小型模型中以专门化推理能力。我们将上述思路扩展到基于表格的推理任务，特别是在科学表格到文本生成任务中，生成的CoT数据提高了表格推理性能。
- en: 3 Methodology
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法论
- en: 'Our proposed framework is illustrated in [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Effective Distillation of Table-based Reasoning Ability from LLMs"), which consists
    of two steps: synthesizing data from LLMs and fine-tuning student models with
    the distilled data. The primary purpose of the first stage is to generate table-based
    reasoning and descriptions given the input tables through CoT prompting from LLMs.
    In the second stage, the table-based reasoning ability will be transferred into
    smaller models by fine-tuning with the distilled data.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的框架如[图1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Effective Distillation of Table-based
    Reasoning Ability from LLMs")所示，包含两个步骤：从LLMs中合成数据和用蒸馏数据微调学生模型。第一阶段的主要目的是通过LLMs的CoT提示生成基于表格的推理和描述。第二阶段，基于表格的推理能力将通过用蒸馏数据微调转移到较小的模型中。
- en: 3.1 Task Definition
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 任务定义
- en: 'We define the task as follows: The input serialized tabular data is denoted
    as $T$. The generated description should be factually consistent with the given
    table, and contain reasoning over the table.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将任务定义如下：输入序列化的表格数据记作$T$。生成的描述应该与给定的表格在事实上一致，并且包含对表格的推理。
- en: 3.2 Table-based Reasoning Generation
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 基于表格的推理生成
- en: The data synthesis process of our proposed method is illustrated in the upper
    part of Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Effective Distillation
    of Table-based Reasoning Ability from LLMs"), which is based on in-context learning Brown
    et al. ([2020](#bib.bib3)), the emergent ability of LLMs. Different from traditional
    fine-tuning, in-context learning enables the LLMs make predictions based on the
    input context where only a few examples are demonstrated without parameter updating.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的方法的数据合成过程如图[1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Effective Distillation
    of Table-based Reasoning Ability from LLMs")上部所示，该方法基于上下文学习（Brown et al. ([2020](#bib.bib3)）），这是LLMs的突现能力。与传统的微调不同，上下文学习使得LLMs能够基于输入上下文进行预测，而只展示了少量示例而无需更新参数。
- en: 'We utilize a large teacher LLM to generate table-based reasoning through CoT.
    We formulate the data generation process as follows: given a input serialized
    table $T$ are hand-crafted. Finally, we can generate data as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用大型教师LLM通过CoT生成基于表格的推理。我们将数据生成过程定义如下：给定一个输入序列化表格$T$，最终我们可以生成如下数据：
- en: '|  | $\displaystyle R_{i},Y_{i}=$ |  | (1) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle R_{i},Y_{i}=$ |  | (1) |'
- en: where we prepend the demonstrated example $C$.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面加上演示的例子 $C$。
- en: 'Diverse Reasoning The table-to-text task enables the model to produce varied
    descriptions by focusing on different table regions or performing various reasoning
    operations, provided that the generated descriptions are factually consistent
    to the table Zhao et al. ([2023](#bib.bib46)). To maximize the reasoning ability
    distilled from LLMs, we employ the diverse reasoning Ho et al. ([2023](#bib.bib19));
    Zhu et al. ([2023](#bib.bib49)); Zhao et al. ([2023](#bib.bib46)) to generate
    two different reasonings and descriptions for a given scientific table. We do
    not generate more reasoning-description pairs to a table because the maximal context
    limit of the LLMs and the average length of tables and descriptions of the SciGen
    dataset is larger than other table-to-text datasets. Specifically, the data generation
    process is shown as follows: data with LLMs, given a context $C$, the LLMs are
    required to generate'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 多样化推理 表格到文本任务使模型能够通过关注不同的表格区域或执行各种推理操作来生成多样化的描述，只要生成的描述在事实上与表格一致 Zhao et al.
    ([2023](#bib.bib46))。为了最大化从LLMs中提取的推理能力，我们采用多样化推理 Ho et al. ([2023](#bib.bib19));
    Zhu et al. ([2023](#bib.bib49)); Zhao et al. ([2023](#bib.bib46)) 来为给定的科学表格生成两种不同的推理和描述。我们不会为一个表格生成更多的推理-描述对，因为LLMs的最大上下文限制和SciGen数据集表格和描述的平均长度大于其他表格到文本数据集。具体而言，数据生成过程如下：数据与LLMs，给定一个上下文
    $C$，要求LLMs生成
- en: '|  | $\displaystyle\{(R_{1},Y_{1}),(R_{2},Y_{2})\}=$ |  | (2) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\{(R_{1},Y_{1}),(R_{2},Y_{2})\}=$ |  | (2) |'
- en: Data Filtering  Besides, the synthesized table-based CoT data might contains
    wrong samples due to the hallucination Zhu et al. ([2023](#bib.bib49)). Therefore,
    we needto filter the wrong generated CoT data. For filtering, we follow Madaan
    et al. ([2023](#bib.bib28)) to employ Self-Fine method. To be specific, when generating
    a new set of data $(R_{i},Y_{i})$. We can filter out incorrect samples to refine
    our generated CoT data. The verification and filtering is crucial as the high
    quality training data will improve the performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据过滤 此外，合成的基于表格的CoT数据可能包含错误样本，这可能是由于虚假信息 Zhu et al. ([2023](#bib.bib49))。因此，我们需要过滤掉错误生成的CoT数据。对于过滤，我们遵循
    Madaan et al. ([2023](#bib.bib28)) 采用自我微调方法。具体来说，当生成一组新的数据 $(R_{i},Y_{i})$ 时，我们可以过滤掉不正确的样本以优化生成的CoT数据。验证和过滤至关重要，因为高质量的训练数据将提高性能。
- en: 3.3 Fine-tuning Small Model
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 微调小模型
- en: 'Once we obtained the generated table-based reasoning data, we use them to fine-tune
    smaller models and inject the reasoning ability into them. As for the choice of
    smaller model, we select T5 Raffel et al. ([2019](#bib.bib34)) and Flan-T5 Chung
    et al. ([2022](#bib.bib12)). This is because recent works Fu et al. ([2023](#bib.bib14));
    Zhu et al. ([2023](#bib.bib49)); Magister et al. ([2023](#bib.bib29)) have revealed
    that these models and gain remarkable numerical reasoning ability when training
    with CoT data in complex mathematical problem solving field. We fine-tune the
    smaller model with the generated table-based reasoning data. Specifically, we
    concatenate the table $T$ with the loss function as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了生成的基于表格的推理数据，我们使用它们来微调较小的模型，并将推理能力注入其中。对于较小模型的选择，我们选择 T5 Raffel et al.
    ([2019](#bib.bib34)) 和 Flan-T5 Chung et al. ([2022](#bib.bib12))。这是因为最近的工作 Fu
    et al. ([2023](#bib.bib14)); Zhu et al. ([2023](#bib.bib49)); Magister et al.
    ([2023](#bib.bib29)) 发现这些模型在用CoT数据进行复杂数学问题求解训练时具有显著的数值推理能力。我们用生成的基于表格的推理数据微调较小的模型。具体来说，我们将表格
    $T$ 与损失函数连接起来，如下所示：
- en: '|  | $\displaystyle\mathcal{L}=-\frac{1}{N}\sum_{n=1}^{N}\log P(Y\mid T,R)$
    |  | (3) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=-\frac{1}{N}\sum_{n=1}^{N}\log P(Y\mid T,R)$
    |  | (3) |'
- en: where $N$ is the cross entropy.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $N$ 是交叉熵。
- en: 4 Experiments
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 4.1 Dataset
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集
- en: 'We conduct scientific table-to-text generaton on the SciGen dataset Moosavi
    et al. ([2021](#bib.bib30)). The statistics of the data are shown in Table [1](#S4.T1
    "Table 1 ‣ 4.3 Experimental Settings ‣ 4 Experiments ‣ Effective Distillation
    of Table-based Reasoning Ability from LLMs"). It consists of three different settings:
    few-show, medium and large. The train/val/test sets of medium setting are split
    into sizes of 13,607/3,452/1,038\. The large setting is split into 39,969/12,129/1,038\.
    we choose medium and large to conduct the experiments. This is because few-shot
    setting only contains 200 training data and is not enough for fine-tuning.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在SciGen数据集上进行科学的表格到文本生成，参考Moosavi等人（[2021](#bib.bib30)）。数据的统计信息如表[1](#S4.T1
    "Table 1 ‣ 4.3 Experimental Settings ‣ 4 Experiments ‣ Effective Distillation
    of Table-based Reasoning Ability from LLMs")所示。数据集包含三种不同的设置：少量样本、中等和大型。中等设置的训练/验证/测试集的大小分别为13,607/3,452/1,038。大型设置的大小为39,969/12,129/1,038。我们选择中等和大型设置进行实验。这是因为少量样本设置仅包含200个训练数据，不足以进行微调。
- en: 4.2 Baselines
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基线
- en: We follow the Moosavi et al. ([2021](#bib.bib30)) and choose T5 Raffel et al.
    ([2019](#bib.bib34)) and BART Lewis et al. ([2020](#bib.bib23)) as baselines.
    For the BART baseline, we use BART-large pre-trained model with 400M parameters.
    For the T5 model, we use T5-base and T5-large with 220M, and 770M parameters,
    respectively. For the teacher models, we choose gpt-3.5-turbo as baseline. For
    the one shot setting, e follow the previous works Chen ([2023](#bib.bib5)); Zhao
    et al. ([2023](#bib.bib46)), which prepend one demonstration example to the input
    table. We compared with two variants gpt-3.5-turbo, called 1-shot direct and 1-shot
    CoT. For the prompt formulation of 1-shot direct, we follow the setting of Moosavi
    et al. ([2021](#bib.bib30)) to linearize the table and concatenate it with the
    gold description as demonstration. As for the prompt of 1-shot CoT, we prepend
    the input table to two hand-crafted table-based reasonings and descriptions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循Moosavi等人（[2021](#bib.bib30)）的研究，选择T5（Raffel等人，[2019](#bib.bib34)）和BART（Lewis等人，[2020](#bib.bib23)）作为基线。对于BART基线，我们使用具有4亿参数的BART-large预训练模型。对于T5模型，我们使用具有2.2亿和7.7亿参数的T5-base和T5-large。对于教师模型，我们选择gpt-3.5-turbo作为基线。对于一例设置，我们遵循之前的工作Chen（[2023](#bib.bib5)）；Zhao等人（[2023](#bib.bib46)），在输入表格前添加一个示例。我们与两个变体gpt-3.5-turbo进行了比较，分别称为1-shot
    direct和1-shot CoT。对于1-shot direct的提示公式，我们遵循Moosavi等人（[2021](#bib.bib30)）的设置，将表格线性化并与金标准描述串联作为示例。至于1-shot
    CoT的提示，我们将输入表格预先添加到两个手工制作的基于表格的推理和描述中。
- en: 4.3 Experimental Settings
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 实验设置
- en: To use the above text-to-text generation baselines, We follow the setting in Moosavi
    et al. ([2021](#bib.bib30)) and convert tables into the text sequences. To preserve
    and help the model better learn the table structure, we add four special tokens
    to specify the beginning of rows, cells, table caption, and CoT reasoning with
    tokens “”, “”, “”, “” respectively.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用上述的文本到文本生成基线，我们遵循Moosavi等人（[2021](#bib.bib30)）的设置，将表格转换为文本序列。为了保留并帮助模型更好地学习表格结构，我们添加了四个特殊标记，分别用“”、
    “”、 “”、 “”来指定行、单元格、表格标题和CoT推理的开始。
- en: '| Setting | Text | Train | Val | Test |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 设置 | 文本 | 训练 | 验证 | 测试 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Few-shot | 116 | 200 | 100 | 1,038 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本 | 116 | 200 | 100 | 1,038 |'
- en: '| Medium | 124 | 13,607 | 3,452 | 1,038 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 中等 | 124 | 13,607 | 3,452 | 1,038 |'
- en: '| Large | 133 | 39,969 | 12,129 | 1,038 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 大型 | 133 | 39,969 | 12,129 | 1,038 |'
- en: 'Table 1: SciGen dataset statistics. Text indicates the average length of descriptions.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：SciGen数据集统计信息。文本表示描述的平均长度。
- en: '[b] Models #Params Faithfulness-level Surface-level TAPAS-Acc TAPEX-Acc Meteor
    BERTScore BLEURT Teacher Model gpt-3.5-turbo (1-shot direct) 175B 72.34 70.48
    0.09 0.85 -0.91 gpt-3.5-turbo (1-shot CoT) 175B 82.53 84.99 0.09 0.83 -0.96 Medium
    Setting BART-large 0.40B 57.45 58.41 0.23 0.84 -0.72 T5-base 0.22B 53.27 52.45
    0.15 0.82 -0.89 T5-large 0.77B 56.32 54.78 0.17 0.83 -0.77 Large Setting BART-large
    0.40B 59.69 61.38 0.15 0.82 -0.89 T5-base 0.22B 55.32 53.76 0.15 0.82 -0.85 T5-large
    0.77B 58.21 56.32 0.18 0.83 -0.79 CoT fine tuning T5-base-CoT 0.22B 78.16 82.30
    0.08 0.83 -0.89 T5-large-CoT 0.77B 80.62 81.97 0.07 0.82 -0.89 Flan-T5-base-CoT
    0.22B 78.72 82.75 0.08 0.82 -0.89 Flan-T5-large-CoT 0.77B 79.05 82.53 0.06 0.83
    -0.89'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[b] 模型 #Params 可信度水平 表面级 TAPAS-Acc TAPEX-Acc Meteor BERTScore BLEURT 教师模型 gpt-3.5-turbo
    (1-shot 直接) 175B 72.34 70.48 0.09 0.85 -0.91 gpt-3.5-turbo (1-shot CoT) 175B 82.53
    84.99 0.09 0.83 -0.96 中等设置 BART-large 0.40B 57.45 58.41 0.23 0.84 -0.72 T5-base
    0.22B 53.27 52.45 0.15 0.82 -0.89 T5-large 0.77B 56.32 54.78 0.17 0.83 -0.77 大型设置
    BART-large 0.40B 59.69 61.38 0.15 0.82 -0.89 T5-base 0.22B 55.32 53.76 0.15 0.82
    -0.85 T5-large 0.77B 58.21 56.32 0.18 0.83 -0.79 CoT 微调 T5-base-CoT 0.22B 78.16
    82.30 0.08 0.83 -0.89 T5-large-CoT 0.77B 80.62 81.97 0.07 0.82 -0.89 Flan-T5-base-CoT
    0.22B 78.72 82.75 0.08 0.82 -0.89 Flan-T5-large-CoT 0.77B 79.05 82.53 0.06 0.83
    -0.89'
- en: 'Table 2: Performance on the SciGen test set. Medium and large setting indicates
    the datasets’ setting used for training.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 在 SciGen 测试集上的表现。中等和大型设置表示用于训练的数据集设置。'
- en: 4.4 Automatic Evaluation Metric
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 自动评估指标
- en: We utilized a wide range of automatic evaluation metrics from various levels
    to assess the performance of the model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用了各种级别的自动评估指标来评估模型的性能。
- en: Surface-level  Following Moosavi et al. ([2021](#bib.bib30)), we choose the
    METEOR Banerjee and Lavie ([2005](#bib.bib2)), BERTScore Zhang et al. ([2020](#bib.bib44)),
    and BLEURT Sellam et al. ([2020](#bib.bib36)) to measure the surface similarity
    of the generated statements to the gold references. However,  Moosavi et al. ([2021](#bib.bib30))
    stated that these metrics are not sufficient as the value range is quite low except
    for BERTScore. In addition, in some cases, the incorrect description have the
    higher metric scores than the correct ones.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 表面级 根据 Moosavi 等人 ([2021](#bib.bib30))，我们选择了 METEOR Banerjee 和 Lavie ([2005](#bib.bib2))、BERTScore
    Zhang 等人 ([2020](#bib.bib44)) 和 BLEURT Sellam 等人 ([2020](#bib.bib36)) 来衡量生成陈述与黄金参考的表面相似度。然而，Moosavi
    等人 ([2021](#bib.bib30)) 表示这些指标并不充分，因为除了 BERTScore 外，数值范围都很低。此外，在某些情况下，错误的描述比正确的描述得分更高。
- en: Faithfulness-level  Recent works Moosavi et al. ([2021](#bib.bib30)); Liu et al.
    ([2022a](#bib.bib24)) have pointed out that the above surface-level metrics cannot
    measure the factual correctness of the generated descriptions given the corresponding
    tables. The SciGen task requires the model to generate statements which contains
    numerical reasoning over table values. In addition, the generated statements might
    cover a different table region from the gold reference. Therefore, we add two
    faithfulness-level (whether the generated sentence is grounded on the input table)
    metrics, TAPAS-Acc and TAPEX-Acc Liu et al. ([2022a](#bib.bib24)) to evaluate
    the factual consistency and fidelity, which have been widely used for table-to-text
    evaluation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 可信度水平 最近的研究 Moosavi 等人 ([2021](#bib.bib30)); Liu 等人 ([2022a](#bib.bib24)) 指出，上述表面级指标无法衡量生成描述的事实正确性。SciGen
    任务要求模型生成包含对表格值进行数值推理的陈述。此外，生成的陈述可能覆盖与黄金参考不同的表格区域。因此，我们添加了两个可信度水平（生成的句子是否基于输入表格）指标，TAPAS-Acc
    和 TAPEX-Acc Liu 等人 ([2022a](#bib.bib24))，以评估事实一致性和忠实度，这些指标在表格到文本评估中被广泛使用。
- en: TAPAS-Acc fine-tunes TAPAS Herzig et al. ([2020](#bib.bib17)) on the TabFact
    dataset Chen et al. ([2020b](#bib.bib7)) and achieves 81% test accuracy.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: TAPAS-Acc 微调 TAPAS Herzig 等人 ([2020](#bib.bib17)) 在 TabFact 数据集上 [Chen et al.](#bib.bib7)，达到了
    81% 的测试准确率。
- en: TAPEX-Acc use TAPEX Liu et al. ([2022b](#bib.bib25)) which is fine-tuned on
    the TabFact dataset and achieves 84% test accuracy. Previous works Liu et al.
    ([2022a](#bib.bib24)); Zhao et al. ([2023](#bib.bib46)) stated that TAPAS-Acc
    is overly positive about the predictions, while TAPEX-Acc is more reliable for
    the evaluation of the faithfulness of generated sentences. Both above reference-free
    metrics score the generated descriptions as 0 for refuted and 1 for entailed given
    the corresponding tables.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: TAPEX-Acc 使用 TAPEX Liu 等人 ([2022b](#bib.bib25))，该模型在 TabFact 数据集上进行了微调，达到了 84%
    的测试准确率。之前的研究 Liu 等人 ([2022a](#bib.bib24)); Zhao 等人 ([2023](#bib.bib46)) 表示 TAPAS-Acc
    对预测过于积极，而 TAPEX-Acc 在评估生成句子的可信度方面更可靠。上述无参考文献指标为生成的描述评分，0 表示被驳斥，1 表示蕴含，依据相应的表格。
- en: 5 Results
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果
- en: In this section, we evaluate both the performance of teacher LLMs and the fine-tuned
    smaller models on scientific table-to-text task. We conduct automated evaluation
    on both Surface-level and Faithfulness-level metrics.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们评估了教师 LLM 和微调小型模型在科学表格到文本任务上的性能。我们对表面层和真实性层指标进行了自动化评估。
- en: 5.1 Performance of LLMs
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 LLM 的性能
- en: Our experiments include two in-context learning methods, Direct Prompt and CoT
    Prompt on the SciGen dataset. As shown in Table [2](#S4.T2 "Table 2 ‣ 4.3 Experimental
    Settings ‣ 4 Experiments ‣ Effective Distillation of Table-based Reasoning Ability
    from LLMs"), on surface-level metrics, both Direct Prompt and CoT Prompt cannot
    achieve the best performance, except for the Direct Prompt achieves the best BERTScore.
    However, the surface-level metrics are unable to accurately measure the faithfulness
    and accuracy of the models’ generated outputs. In terms of the faithfulness-level
    metrics, Direct Prompt can already achieve over 70% accuracy on both TAPAS-Acc
    and TAPEX-Acc, which outperform the traditional fine-tuned baseline models (i.e.
    BART and T5). When combined with CoT reasoning, the accuracy of CoT Prompt increases
    by at least 10% on both metrics.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验包括两种上下文学习方法，Direct Prompt 和 CoT Prompt，均在 SciGen 数据集上进行。如表 [2](#S4.T2 "Table
    2 ‣ 4.3 Experimental Settings ‣ 4 Experiments ‣ Effective Distillation of Table-based
    Reasoning Ability from LLMs")所示，在表面层指标上，Direct Prompt 和 CoT Prompt 都未能达到最佳表现，除了
    Direct Prompt 在 BERTScore 上表现最佳。然而，表面层指标无法准确测量模型生成输出的真实性和准确性。在真实性层指标方面，Direct
    Prompt 已经可以在 TAPAS-Acc 和 TAPEX-Acc 上达到超过 70% 的准确率，优于传统微调基准模型（即 BART 和 T5）。与 CoT
    推理结合时，CoT Prompt 在这两个指标上的准确率至少提高了 10%。
- en: 5.2 Performance of Fine-tuned Smaller Model
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 微调小型模型的性能
- en: As for the surface-level metrics, all the smaller models, whether they are fine-tuned
    with CoT data or not, can only show a low value range on them. The experimental
    results is consistent with the statements in SciGen’s paper that surface-level
    metrics are not sufficient to reflect models’ abilities on this complex task.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 就表面层指标而言，无论小型模型是否经过 CoT 数据微调，它们的表现都只能显示在较低的数值范围内。实验结果与 SciGen 论文中的说法一致，即表面层指标不足以反映模型在这一复杂任务上的能力。
- en: Small models with traditional fine-tuning perform not well on faithfulness-level
    metrics. In terms of the Smaller Model fine-tuned without CoT data, BART-large
    fine-tuned with medium dataset achieves the best on surface-level metrics. However,
    in terms of faithfulness-level, all the BART and T5 baselines can only achieve
    an accuracy slightly higher than random guess. Besides, we investigate the impact
    of dataset size, ranging from the Medium Setting to the Large Setting. Although
    the size of Large Setting dataset is three times than the Medium Setting one,
    performance improvements are not significant, i.e., only around 2% increase on
    the faithfulness-level metrics. However, for the surface-level metrics, models
    that are trained with Medium datasets can achieves better overall performances,
    especially in Meteor and BLEURT metrics.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 传统微调的小型模型在真实性水平指标上的表现不佳。在没有 CoT 数据的情况下微调的小型模型中，BART-large 在中等数据集上的微调在表面层指标上表现最佳。然而，在真实性水平方面，所有的
    BART 和 T5 基准模型只能达到略高于随机猜测的准确率。此外，我们调查了数据集大小的影响，从中等设置到大型设置。尽管大型设置的数据集大小是中等设置的三倍，但性能提升并不显著，即真实性水平指标仅增加了约
    2%。然而，对于表面层指标，使用中等数据集训练的模型可以取得更好的整体表现，特别是在 Meteor 和 BLEURT 指标上。
- en: Small models fine-tuned with CoT data achieve a significant performance improvement.
    On the other hand, the T5 and Flan-T5 models with CoT fine-tuning can achieve
    the best overall performance on the faithfulness-level metrics among all the small
    models. All the performances of CoT fine-tuning models are on par with the teacher
    model, i.e. gpt-3.5-turbo with one shot CoT, on the faithfulness-level metrics.
    For instance, T5-large-CoT and Flan-T5-base-CoT achieve the highest TAPAS-Acc
    (80.62%) and TAPEX-Acc (82.75%), and only underperform the teacher model with
    the best performance by a margin of 2%. These results indicate that fine-tuning
    with CoT data distilled from LLMs can transfer the table-based reasoning ability
    into smaller models. Furthermore, our experiments also investigate the impact
    of the model size for CoT fine-tuning, ranging from the base to the large variant.
    While it is intuitive to expect performance improvements with larger models, the
    experimental results on TAPEX-Acc metric reveal that models with larger parameters,
    such as T5-large and Flan-T5-large, do not consistently outperform their smaller
    counterparts, T5-base and Flan-T5-base. However, as for the TAPAS-Acc, the performance
    improvement is consistent, with the model size increasing from base (0.22B) to
    large (0.77B).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CoT数据进行微调的小模型取得了显著的性能提升。另一方面，经过CoT微调的T5和Flan-T5模型在所有小模型中，在忠实度水平的度量上达到了最佳的整体性能。所有经过CoT微调的模型在忠实度水平的度量上与教师模型（即`gpt-3.5-turbo`的单次示例）相当。例如，T5-large-CoT和Flan-T5-base-CoT分别达到了最高的TAPAS-Acc（80.62%）和TAPEX-Acc（82.75%），仅比最佳性能的教师模型低2%。这些结果表明，通过对LLMs提炼的CoT数据进行微调可以将基于表格的推理能力转移到较小的模型中。此外，我们的实验还调查了模型规模对CoT微调的影响，从基础版到大型变体。虽然直观上预期更大的模型会带来性能提升，但在TAPEX-Acc度量上的实验结果表明，较大的参数模型（如T5-large和Flan-T5-large）并不总是优于其较小的对应模型（T5-base和Flan-T5-base）。然而，就TAPAS-Acc而言，性能提升是一致的，模型规模从基础版（0.22B）增加到大型版（0.77B）时，性能提升稳定。
- en: 6 Conclusion
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this paper, we introduce a two-stage distillation framework that distills
    table-based CoT data from LLMs. Our experiments illustrate that this method effectively
    transfer table reasoning abilities to smaller models in scientific table-to-text
    generation task. The performance improvement can even outperform certain teacher
    LLMs (e.g., gpt-3.5-turbo with one shot). Our proposed method achieves comprehensive
    superiority while utilizing less data and smaller models.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一种两阶段的蒸馏框架，该框架从大型语言模型（LLMs）中提炼基于表格的链式思维（CoT）数据。我们的实验表明，这种方法能够有效地将表格推理能力转移到较小的模型中，在科学的表格到文本生成任务中表现出色。性能提升甚至可以超越某些教师LLMs（例如，`gpt-3.5-turbo`的单次示例）。我们提出的方法在使用更少的数据和更小的模型的同时，达到了全面的优越性。
- en: 7 References
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 参考文献
- en: References
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Aly et al. (2021) Rami Aly, Zhijiang Guo, M. Schlichtkrull, James Thorne, Andreas
    Vlachos, Christos Christodoulopoulos, Oana Cocarascu, and Arpit Mittal. 2021.
    [Feverous: Fact extraction and verification over unstructured and structured information](https://api.semanticscholar.org/CorpusID:235391052).
    *ArXiv*, abs/2106.05707.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Aly等（2021）Rami Aly, Zhijiang Guo, M. Schlichtkrull, James Thorne, Andreas Vlachos,
    Christos Christodoulopoulos, Oana Cocarascu, 和Arpit Mittal。2021年。[Feverous: 从非结构化和结构化信息中提取和验证事实](https://api.semanticscholar.org/CorpusID:235391052)。*ArXiv*，abs/2106.05707。'
- en: 'Banerjee and Lavie (2005) Satanjeev Banerjee and Alon Lavie. 2005. Meteor:
    An automatic metric for mt evaluation with improved correlation with human judgments.
    In *IEEvaluation@ACL*.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Banerjee和Lavie（2005）Satanjeev Banerjee和Alon Lavie。2005年。《Meteor: 一种自动度量标准，用于机器翻译评估，并与人工判断具有更高的相关性》。发表于*IEEvaluation@ACL*。'
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. [Language models are few-shot learners](https://api.semanticscholar.org/CorpusID:218971783).
    *ArXiv*, abs/2005.14165.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown等（2020）Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, 和Dario
    Amodei。2020年。[语言模型是少样本学习者](https://api.semanticscholar.org/CorpusID:218971783)。*ArXiv*，abs/2005.14165。
- en: 'Cai et al. (2022) Zefeng Cai, Xiangyu Li, Binyuan Hui, Min Yang, Bowen Li,
    Binhua Li, Zhen Cao, Weijie Li, Fei Huang, Luo Si, and Yongbin Li. 2022. [Star:
    Sql guided pre-training for context-dependent text-to-sql parsing](https://api.semanticscholar.org/CorpusID:253080452).
    *ArXiv*, abs/2210.11888.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cai et al. (2022) Zefeng Cai, Xiangyu Li, Binyuan Hui, Min Yang, Bowen Li,
    Binhua Li, Zhen Cao, Weijie Li, Fei Huang, Luo Si, 和 Yongbin Li. 2022. [Star:
    Sql guided pre-training for context-dependent text-to-sql parsing](https://api.semanticscholar.org/CorpusID:253080452).
    *ArXiv*, abs/2210.11888.'
- en: 'Chen (2023) Wenhu Chen. 2023. [Large Language Models are few(1)-shot Table
    Reasoners](https://aclanthology.org/2023.findings-eacl.83). In *Findings of the
    Association for Computational Linguistics: EACL 2023*, pages 1120–1130, Dubrovnik,
    Croatia. Association for Computational Linguistics.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen (2023) Wenhu Chen. 2023. [Large Language Models are few(1)-shot Table
    Reasoners](https://aclanthology.org/2023.findings-eacl.83). 发表在 *Findings of the
    Association for Computational Linguistics: EACL 2023*，第1120–1130页，克罗地亚杜布罗夫尼克。计算语言学协会。'
- en: Chen et al. (2020a) Wenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen, and William Yang
    Wang. 2020a. [Logical Natural Language Generation from Open-Domain Tables](https://doi.org/10.48550/arXiv.2004.10404).
    ArXiv:2004.10404 [cs].
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2020a) Wenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen, 和 William Yang
    Wang. 2020a. [Logical Natural Language Generation from Open-Domain Tables](https://doi.org/10.48550/arXiv.2004.10404).
    ArXiv:2004.10404 [cs].
- en: 'Chen et al. (2020b) Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong
    Wang, Shiyang Li, Xiyou Zhou, and William Yang Wang. 2020b. TABFACT: A LARGE-SCALE
    DATASET FOR TABLE- BASED FACT VERIFICATION.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. (2020b) Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong
    Wang, Shiyang Li, Xiyou Zhou, 和 William Yang Wang. 2020b. TABFACT: A LARGE-SCALE
    DATASET FOR TABLE- BASED FACT VERIFICATION.'
- en: 'Chen et al. (2020c) Zhiyu Chen, Wenhu Chen, Hanwen Zha, Xiyou Zhou, Yunkai
    Zhang, Sairam Sundaresan, and William Yang Wang. 2020c. [Logic2Text: High-Fidelity
    Natural Language Generation from Logical Forms](http://arxiv.org/abs/2004.14579).
    *arXiv:2004.14579 [cs]*. ArXiv: 2004.14579.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. (2020c) Zhiyu Chen, Wenhu Chen, Hanwen Zha, Xiyou Zhou, Yunkai
    Zhang, Sairam Sundaresan, 和 William Yang Wang. 2020c. [Logic2Text: High-Fidelity
    Natural Language Generation from Logical Forms](http://arxiv.org/abs/2004.14579).
    *arXiv:2004.14579 [cs]*. ArXiv: 2004.14579.'
- en: Cheng et al. (2023) Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul
    Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer,
    Noah A. Smith, and Tao Yu. 2023. [Binding Language Models in Symbolic Languages](http://arxiv.org/abs/2210.02875).
    ArXiv:2210.02875 [cs].
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. (2023) Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul
    Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer,
    Noah A. Smith, 和 Tao Yu. 2023. [Binding Language Models in Symbolic Languages](http://arxiv.org/abs/2210.02875).
    ArXiv:2210.02875 [cs].
- en: 'Cho et al. (2019) Minseok Cho, Gyeongbok Lee, and Seung won Hwang. 2019. [Explanatory
    and actionable debugging for machine learning: A tableqa demonstration](https://api.semanticscholar.org/CorpusID:197928300).
    *Proceedings of the 42nd International ACM SIGIR Conference on Research and Development
    in Information Retrieval*.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cho et al. (2019) Minseok Cho, Gyeongbok Lee, 和 Seung won Hwang. 2019. [Explanatory
    and actionable debugging for machine learning: A tableqa demonstration](https://api.semanticscholar.org/CorpusID:197928300).
    *Proceedings of the 42nd International ACM SIGIR Conference on Research and Development
    in Information Retrieval*.'
- en: 'Chowdhery et al. (2022) Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten
    Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton,
    Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
    Abhishek Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran,
    Emily Reif, Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin,
    Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay
    Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier García, Vedant Misra, Kevin Robinson,
    Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph,
    Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,
    Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz,
    Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
    Wang, Brennan Saeta, Mark Díaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S.
    Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022. [Palm:
    Scaling language modeling with pathways](https://api.semanticscholar.org/CorpusID:247951931).
    *ArXiv*, abs/2204.02311.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chowdhery等人（2022）Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma,
    Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian
    Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek
    Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran, Emily Reif,
    Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael
    Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
    Sunipa Dev, Henryk Michalewski, Xavier García, Vedant Misra, Kevin Robinson, Liam
    Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander
    Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew
    M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
    Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,
    Brennan Saeta, Mark Díaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S.
    Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, 和Noah Fiedel. 2022. [Palm：通过路径扩展语言建模](https://api.semanticscholar.org/CorpusID:247951931).
    *ArXiv*, abs/2204.02311。
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert
    Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery,
    Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping
    Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob
    Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2022. [Scaling instruction-finetuned
    language models](https://api.semanticscholar.org/CorpusID:253018554). *ArXiv*,
    abs/2210.11416.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung等人（2022）Hyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William
    Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson,
    Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery,
    Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping
    Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob
    Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, 和Jason Wei. 2022. [扩展指令微调语言模型](https://api.semanticscholar.org/CorpusID:253018554).
    *ArXiv*, abs/2210.11416。
- en: Drozdov et al. (2022) Andrew Drozdov, Jiawei Zhou, Radu Florian, Andrew McCallum,
    Tahira Naseem, Yoon Kim, and Ramon Fernandez Astudillo. 2022. [Inducing and Using
    Alignments for Transition-based AMR Parsing](http://arxiv.org/abs/2205.01464).
    ArXiv:2205.01464 [cs].
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Drozdov等人（2022）Andrew Drozdov, Jiawei Zhou, Radu Florian, Andrew McCallum, Tahira
    Naseem, Yoon Kim, 和Ramon Fernandez Astudillo. 2022. [引导和使用对齐进行基于过渡的AMR解析](http://arxiv.org/abs/2205.01464).
    ArXiv:2205.01464 [cs]。
- en: Fu et al. (2023) Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, and Tushar Khot.
    2023. [Specializing Smaller Language Models towards Multi-Step Reasoning](http://arxiv.org/abs/2301.12726).
    ArXiv:2301.12726 [cs].
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu等人（2023）Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, 和Tushar Khot. 2023. [将较小语言模型专门化为多步推理](http://arxiv.org/abs/2301.12726).
    ArXiv:2301.12726 [cs]。
- en: 'Gemmell and Dalton (2023) Carlos Gemmell and Jeffrey Stephen Dalton. 2023.
    [Generate, transform, answer: Question specific tool synthesis for tabular data](https://api.semanticscholar.org/CorpusID:257622721).
    *ArXiv*, abs/2303.10138.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gemmell和Dalton（2023）Carlos Gemmell和Jeffrey Stephen Dalton. 2023. [生成、转换、回答：针对表格数据的问答特定工具合成](https://api.semanticscholar.org/CorpusID:257622721).
    *ArXiv*, abs/2303.10138。
- en: 'Gupta et al. (2020) Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek Srikumar.
    2020. [Infotabs: Inference on tables as semi-structured data](https://api.semanticscholar.org/CorpusID:218614095).
    In *Annual Meeting of the Association for Computational Linguistics*.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta等人（2020）Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, 和Vivek Srikumar. 2020.
    [Infotabs：将表格视为半结构化数据的推理](https://api.semanticscholar.org/CorpusID:218614095).
    发表在*计算语言学协会年会*上。
- en: 'Herzig et al. (2020) Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller,
    Francesco Piccinno, and Julian Martin Eisenschlos. 2020. [TAPAS: Weakly Supervised
    Table Parsing via Pre-training](http://arxiv.org/abs/2004.02349). *arXiv:2004.02349
    [cs]*. ArXiv: 2004.02349.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Herzig 等人 (2020) Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco
    Piccinno, 和 Julian Martin Eisenschlos. 2020. [TAPAS：通过预训练的弱监督表格解析](http://arxiv.org/abs/2004.02349)。*arXiv:2004.02349
    [cs]*。ArXiv: 2004.02349。'
- en: Hinton et al. (2015) Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. 2015.
    [Distilling the knowledge in a neural network](https://api.semanticscholar.org/CorpusID:7200347).
    *ArXiv*, abs/1503.02531.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton 等人 (2015) Geoffrey E. Hinton, Oriol Vinyals, 和 Jeffrey Dean. 2015. [蒸馏神经网络中的知识](https://api.semanticscholar.org/CorpusID:7200347)。*ArXiv*，abs/1503.02531。
- en: Ho et al. (2023) Namgyu Ho, Laura Schmid, and Se-Young Yun. 2023. [Large Language
    Models Are Reasoning Teachers](https://doi.org/10.48550/arXiv.2212.10071). ArXiv:2212.10071
    [cs].
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho 等人 (2023) Namgyu Ho, Laura Schmid, 和 Se-Young Yun. 2023. [大型语言模型是推理教师](https://doi.org/10.48550/arXiv.2212.10071)。ArXiv:2212.10071
    [cs]。
- en: Hsieh et al. (2023) Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost,
    Yasuhisa Fujii, Alexander J. Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister.
    2023. [Distilling step-by-step! outperforming larger language models with less
    training data and smaller model sizes](https://api.semanticscholar.org/CorpusID:258461606).
    *ArXiv*, abs/2305.02301.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsieh 等人 (2023) Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost,
    Yasuhisa Fujii, Alexander J. Ratner, Ranjay Krishna, Chen-Yu Lee, 和 Tomas Pfister.
    2023. [逐步蒸馏！以较少的训练数据和较小的模型规模超越更大的语言模型](https://api.semanticscholar.org/CorpusID:258461606)。*ArXiv*，abs/2305.02301。
- en: 'Jiang et al. (2022) Zhengbao Jiang, Yi Mao, Pengcheng He, Graham Neubig, and
    Weizhu Chen. 2022. [Omnitab: Pretraining with natural and synthetic data for few-shot
    table-based question answering](https://api.semanticscholar.org/CorpusID:250390443).
    In *North American Chapter of the Association for Computational Linguistics*.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人 (2022) Zhengbao Jiang, Yi Mao, Pengcheng He, Graham Neubig, 和 Weizhu
    Chen. 2022. [Omnitab：使用自然和合成数据进行少样本表格问答的预训练](https://api.semanticscholar.org/CorpusID:250390443)。在*北美计算语言学学会年会*上。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://api.semanticscholar.org/CorpusID:249017743).
    *ArXiv*, abs/2205.11916.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人 (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo,
    和 Yusuke Iwasawa. 2022. [大型语言模型是零-shot 推理者](https://api.semanticscholar.org/CorpusID:249017743)。*ArXiv*，abs/2205.11916。
- en: 'Lewis et al. (2020) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad,
    Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020.
    [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,
    Translation, and Comprehension](https://doi.org/10.18653/v1/2020.acl-main.703).
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*, pages 7871–7880, Online. Association for Computational Linguistics.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 等人 (2020) Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
    Mohamed, Omer Levy, Veselin Stoyanov, 和 Luke Zettlemoyer. 2020. [BART：用于自然语言生成、翻译和理解的去噪序列到序列预训练](https://doi.org/10.18653/v1/2020.acl-main.703)。在*第58届计算语言学协会年会论文集*中，第7871–7880页，在线。计算语言学协会。
- en: 'Liu et al. (2022a) Ao Liu, Haoyu Dong, Naoaki Okazaki, Shi Han, and Dongmei
    Zhang. 2022a. [PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation](https://doi.org/10.18653/v1/2022.emnlp-main.373).
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing*, pages 5531–5546, Abu Dhabi, United Arab Emirates. Association for
    Computational Linguistics.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2022a) Ao Liu, Haoyu Dong, Naoaki Okazaki, Shi Han, 和 Dongmei Zhang.
    2022a. [PLOG：用于逻辑表格到文本生成的表格到逻辑预训练](https://doi.org/10.18653/v1/2022.emnlp-main.373)。在*2022年自然语言处理实证方法会议论文集*中，第5531–5546页，阿布扎比，阿联酋。计算语言学协会。
- en: 'Liu et al. (2022b) Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin,
    Weizhu Chen, and Jian-Guang Lou. 2022b. TAPEX: TABLE PRE-TRAINING VIA LEARNING
    A NEURAL SQL EXECUTOR.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2022b) Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu
    Chen, 和 Jian-Guang Lou. 2022b. TAPEX：通过学习神经SQL执行器的表格预训练。
- en: 'Liu et al. (2021) Tianyu Liu, Xin Zheng, Baobao Chang, and Zhifang Sui. 2021.
    [Towards Faithfulness in Open Domain Table-to-text Generation from an Entity-centric
    View](http://arxiv.org/abs/2102.08585). *arXiv:2102.08585 [cs]*. ArXiv: 2102.08585.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2021) Tianyu Liu, Xin Zheng, Baobao Chang, 和 Zhifang Sui. 2021. [从以实体为中心的视角看开放领域表格到文本生成的可信度](http://arxiv.org/abs/2102.08585)。*arXiv:2102.08585
    [cs]*。ArXiv: 2102.08585。'
- en: 'Lu et al. (2023) Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, and Min-Yen
    Kan. 2023. [SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim
    Verification on Scientific Tables](http://arxiv.org/abs/2305.13186). ArXiv:2305.13186
    [cs].'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu et al. (2023) Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, and Min-Yen
    Kan. 2023. [SCITAB：一个挑战性基准测试，用于科学表格上的组合推理和声明验证](http://arxiv.org/abs/2305.13186)。ArXiv:2305.13186
    [cs]。
- en: 'Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    et al. 2023. Self-refine: Iterative refinement with self-feedback. *arXiv preprint
    arXiv:2303.17651*.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madaan et al. (2023) Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan,
    Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
    et al. 2023. Self-refine：自我反馈的迭代细化。*arXiv预印本 arXiv:2303.17651*。
- en: Magister et al. (2023) Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek,
    Eric Malmi, and Aliaksei Severyn. 2023. [Teaching Small Language Models to Reason](http://arxiv.org/abs/2212.08410).
    ArXiv:2212.08410 [cs].
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magister et al. (2023) Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek,
    Eric Malmi, and Aliaksei Severyn. 2023. [教导小型语言模型进行推理](http://arxiv.org/abs/2212.08410)。ArXiv:2212.08410
    [cs]。
- en: 'Moosavi et al. (2021) N. Moosavi, Andreas Rücklé, D. Roth, and Iryna Gurevych.
    2021. [SciGen: a Dataset for Reasoning-Aware Text Generation from Scientific Tables](https://www.semanticscholar.org/paper/SciGen%3A-a-Dataset-for-Reasoning-Aware-Text-from-Moosavi-R%C3%BCckl%C3%A9/1893f9875fe6a5b40b82838aa3a4259f5763d7f0).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moosavi et al. (2021) N. Moosavi, Andreas Rücklé, D. Roth, and Iryna Gurevych.
    2021. [SciGen：一个用于科学表格推理感知文本生成的数据集](https://www.semanticscholar.org/paper/SciGen%3A-a-Dataset-for-Reasoning-Aware-Text-from-Moosavi-R%C3%BCckl%C3%A9/1893f9875fe6a5b40b82838aa3a4259f5763d7f0)。
- en: 'Nan et al. (2022) Linyong Nan, Chiachun Hsieh, Ziming Mao, Xi Victoria Lin,
    Neha Verma, Rui Zhang, Wojciech Kryściński, Hailey Schoelkopf, Riley Kong, Xiangru
    Tang, Mutethia Mutuma, Ben Rosand, Isabel Trindade, Renusree Bandaru, Jacob Cunningham,
    Caiming Xiong, Dragomir Radev, and Dragomir Radev. 2022. [FeTaQA: Free-form Table
    Question Answering](https://doi.org/10.1162/tacl_a_00446). *Transactions of the
    Association for Computational Linguistics*, 10:35–49.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nan et al. (2022) Linyong Nan, Chiachun Hsieh, Ziming Mao, Xi Victoria Lin,
    Neha Verma, Rui Zhang, Wojciech Kryściński, Hailey Schoelkopf, Riley Kong, Xiangru
    Tang, Mutethia Mutuma, Ben Rosand, Isabel Trindade, Renusree Bandaru, Jacob Cunningham,
    Caiming Xiong, Dragomir Radev, and Dragomir Radev. 2022. [FeTaQA：自由形式表格问答](https://doi.org/10.1162/tacl_a_00446)。*计算语言学协会学报*，10:35–49。
- en: 'Nan et al. (2023) Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung
    Tae, Ellen Zhang, Arman Cohan, and Dragomir Radev. 2023. Enhancing few-shot text-to-sql
    capabilities of large language models: A study on prompt design strategies. *arXiv
    preprint arXiv:2305.12586*.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nan et al. (2023) Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung
    Tae, Ellen Zhang, Arman Cohan, and Dragomir Radev. 2023. 提升大型语言模型的少样本文本到SQL能力：关于提示设计策略的研究。*arXiv预印本
    arXiv:2305.12586*。
- en: Pasupat and Liang (2015) Panupong Pasupat and Percy Liang. 2015. [Compositional
    semantic parsing on semi-structured tables](https://api.semanticscholar.org/CorpusID:9027681).
    In *Annual Meeting of the Association for Computational Linguistics*.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pasupat and Liang (2015) Panupong Pasupat and Percy Liang. 2015. [半结构化表格上的组合语义解析](https://api.semanticscholar.org/CorpusID:9027681)。在
    *计算语言学协会年会*。
- en: Raffel et al. (2019) Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine
    Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2019.
    [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://www.semanticscholar.org/paper/Exploring-the-Limits-of-Transfer-Learning-with-a-Raffel-Shazeer/3cfb319689f06bf04c2e28399361f414ca32c4b3).
    *ArXiv*.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel et al. (2019) Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine
    Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2019.
    [探索统一文本到文本的变换器的迁移学习极限](https://www.semanticscholar.org/paper/Exploring-the-Limits-of-Transfer-Learning-with-a-Raffel-Shazeer/3cfb319689f06bf04c2e28399361f414ca32c4b3)。*ArXiv*。
- en: 'Sanh et al. (2019) Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas
    Wolf. 2019. [Distilbert, a distilled version of bert: smaller, faster, cheaper
    and lighter](https://api.semanticscholar.org/CorpusID:203626972). *ArXiv*, abs/1910.01108.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sanh et al. (2019) Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas
    Wolf. 2019. [Distilbert：BERT的精简版本：更小、更快、更便宜、更轻便](https://api.semanticscholar.org/CorpusID:203626972)。*ArXiv*，abs/1910.01108。
- en: 'Sellam et al. (2020) Thibault Sellam, Dipanjan Das, and Ankur P. Parikh. 2020.
    Bleurt: Learning robust metrics for text generation. In *ACL*.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sellam et al. (2020) Thibault Sellam, Dipanjan Das, and Ankur P. Parikh. 2020.
    Bleurt：学习生成文本的稳健度量。在 *ACL*。
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and
    Guillaume Lample. 2023. [Llama: Open and efficient foundation language models](https://api.semanticscholar.org/CorpusID:257219404).
    *ArXiv*, abs/2302.13971.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人 (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet,
    Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
    Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave 和 Guillaume Lample.
    2023. [Llama: 开放且高效的基础语言模型](https://api.semanticscholar.org/CorpusID:257219404)。*ArXiv*，abs/2302.13971。'
- en: Wang et al. (2023) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. [Self-Consistency Improves
    Chain of Thought Reasoning in Language Models](https://doi.org/10.48550/arXiv.2203.11171).
    ArXiv:2203.11171 [cs].
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人 (2023) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan
    Narang, Aakanksha Chowdhery 和 Denny Zhou. 2023. [自一致性改善语言模型中的思维链推理](https://doi.org/10.48550/arXiv.2203.11171)。*ArXiv*:
    2203.11171 [cs]。'
- en: Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai
    hsin Chi, and Denny Zhou. 2022. [Self-consistency improves chain of thought reasoning
    in language models](https://api.semanticscholar.org/CorpusID:247595263). *ArXiv*,
    abs/2203.11171.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai hsin
    Chi 和 Denny Zhou. 2022. [自一致性改善语言模型中的思维链推理](https://api.semanticscholar.org/CorpusID:247595263)。*ArXiv*，abs/2203.11171。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai
    hsin Chi, F. Xia, Quoc Le, and Denny Zhou. 2022. [Chain of thought prompting elicits
    reasoning in large language models](https://api.semanticscholar.org/CorpusID:246411621).
    *ArXiv*, abs/2201.11903.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai
    hsin Chi, F. Xia, Quoc Le 和 Denny Zhou. 2022. [思维链提示在大型语言模型中引发推理](https://api.semanticscholar.org/CorpusID:246411621)。*ArXiv*，abs/2201.11903。
- en: 'Ye et al. (2023) Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, and
    Yongbin Li. 2023. [Large Language Models are Versatile Decomposers: Decompose
    Evidence and Questions for Table-based Reasoning](http://arxiv.org/abs/2301.13808).
    ArXiv:2301.13808 [cs].'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ye 等人 (2023) Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang 和 Yongbin
    Li. 2023. [大型语言模型是多功能的分解器：为基于表格的推理分解证据和问题](http://arxiv.org/abs/2301.13808)。*ArXiv*:
    2301.13808 [cs]。'
- en: 'Yu et al. (2018) Tao Yu, Rui Zhang, Kai-Chou Yang, Michihiro Yasunaga, Dongxu
    Wang, Zifan Li, James Ma, Irene Z Li, Qingning Yao, Shanelle Roman, Zilin Zhang,
    and Dragomir R. Radev. 2018. [Spider: A large-scale human-labeled dataset for
    complex and cross-domain semantic parsing and text-to-sql task](https://api.semanticscholar.org/CorpusID:52815560).
    *ArXiv*, abs/1809.08887.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等人 (2018) Tao Yu, Rui Zhang, Kai-Chou Yang, Michihiro Yasunaga, Dongxu Wang,
    Zifan Li, James Ma, Irene Z Li, Qingning Yao, Shanelle Roman, Zilin Zhang 和 Dragomir
    R. Radev. 2018. [Spider: 一个用于复杂和跨领域语义解析及文本到 SQL 任务的大规模人工标注数据集](https://api.semanticscholar.org/CorpusID:52815560)。*ArXiv*，abs/1809.08887。'
- en: 'Zeng et al. (2022) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai,
    Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan
    Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, P. Zhang, Yuxiao Dong, and Jie Tang.
    2022. [Glm-130b: An open bilingual pre-trained model](https://api.semanticscholar.org/CorpusID:252715691).
    *ArXiv*, abs/2210.02414.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zeng 等人 (2022) Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming
    Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei
    Xue, Jidong Zhai, Wenguang Chen, P. Zhang, Yuxiao Dong 和 Jie Tang. 2022. [Glm-130b:
    一个开放的双语预训练模型](https://api.semanticscholar.org/CorpusID:252715691)。*ArXiv*，abs/2210.02414。'
- en: 'Zhang et al. (2020) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger,
    and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. *ArXiv*,
    abs/1904.09675.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等人 (2020) Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger
    和 Yoav Artzi. 2020. Bertscore: 用 bert 评估文本生成。*ArXiv*，abs/1904.09675。'
- en: 'Zhao et al. (2022) Yilun Zhao, Linyong Nan, Zhenting Qi, Rui Zhang, and Dragomir R.
    Radev. 2022. [Reastap: Injecting table reasoning skills during pre-training via
    synthetic reasoning examples](https://api.semanticscholar.org/CorpusID:253097905).
    In *Conference on Empirical Methods in Natural Language Processing*.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 (2022) Yilun Zhao, Linyong Nan, Zhenting Qi, Rui Zhang 和 Dragomir R.
    Radev. 2022. [Reastap: 在预训练期间通过合成推理示例注入表格推理技能](https://api.semanticscholar.org/CorpusID:253097905)。在
    *自然语言处理实证方法会议*。'
- en: Zhao et al. (2023) Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru
    Tang, and Arman Cohan. 2023. [Large Language Models are Effective Table-to-Text
    Generators, Evaluators, and Feedback Providers](http://arxiv.org/abs/2305.14987).
    ArXiv:2305.14987 [cs].
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 (2023) Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru
    Tang 和 Arman Cohan. 2023. [大型语言模型是有效的表格到文本生成器、评估器和反馈提供者](http://arxiv.org/abs/2305.14987)。*ArXiv*:
    2305.14987 [cs]。'
- en: 'Zhong et al. (2017) Victor Zhong, Caiming Xiong, and Richard Socher. 2017.
    [Seq2sql: Generating structured queries from natural language using reinforcement
    learning](https://api.semanticscholar.org/CorpusID:25156106). *ArXiv*, abs/1709.00103.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhong等（2017）Victor Zhong, Caiming Xiong, 和 Richard Socher. 2017. [Seq2sql:
    从自然语言生成结构化查询使用强化学习](https://api.semanticscholar.org/CorpusID:25156106). *ArXiv*,
    abs/1709.00103。'
- en: Zhou et al. (2023) Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, and
    Ed Chi. 2023. LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE
    MODELS.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等（2023）Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales,
    Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, 和 Ed Chi.
    2023. **LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS**。
- en: 'Zhu et al. (2023) Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, and Bowen
    Zhou. 2023. [PaD: Program-aided Distillation Specializes Large Models in Reasoning](https://doi.org/10.48550/arXiv.2305.13888).
    ArXiv:2305.13888 [cs].'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu等（2023）Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, 和 Bowen Zhou.
    2023. [PaD: 程序辅助蒸馏使大型模型专注于推理](https://doi.org/10.48550/arXiv.2305.13888). ArXiv:2305.13888
    [cs]。'
