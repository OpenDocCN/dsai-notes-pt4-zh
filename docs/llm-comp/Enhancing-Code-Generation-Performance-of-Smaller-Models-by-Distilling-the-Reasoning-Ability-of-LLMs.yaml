- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:58:58'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-08 18:58:58
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过蒸馏大语言模型的推理能力来提升小型模型的代码生成性能
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.13271](https://ar5iv.labs.arxiv.org/html/2403.13271)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.13271](https://ar5iv.labs.arxiv.org/html/2403.13271)
- en: Abstract
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have recently made significant advances in code
    generation through the ’Chain-of-Thought’ prompting technique. This technique
    empowers the model to autonomously devise "solution plans" to tackle intricate
    programming challenges, thereby improving its performance in code generation.
    Nevertheless, smaller models have been struggling to keep up with LLMs in deducing
    these plans, adversely affecting their code generation capabilities. Given the
    considerable size and associated deployment costs, along with concerns about data
    security, many teams opt for deploying smaller models for code generation. Consequently,
    there arises a compelling need for transferring LLMs’ code generation reasoning
    abilities to the smaller models. In this paper, we propose the CodePLAN framework,
    which aims to transfer LLMs’ reasoning capabilities to smaller models through
    distillation. We adopt a multi-task learning approach, jointly undertaking code
    generation and solution plan generation tasks, to enhance the code generation
    capabilities of the smaller model. To ensure the superior quality of the solution
    plans, we advocate for the utilization of backward reasoning and plan sampling
    strategies. Our experiments show that in comparison to the conventional fine-tuning
    approach, our approach improves the smaller model’s code generation performance
    (measured in pass@1 metric) by over 130% on the challenging APPS benchmark.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）最近在代码生成方面取得了显著进展，这得益于“思维链”提示技术。这项技术使模型能够自主制定“解决方案计划”，从而应对复杂的编程挑战，提升其代码生成性能。然而，小型模型在推导这些计划方面一直难以与LLMs保持同步，进而影响了其代码生成能力。鉴于大模型的体积庞大和相关的部署成本，加上对数据安全的担忧，许多团队选择使用小型模型进行代码生成。因此，将LLMs的代码生成推理能力转移到小型模型中变得非常必要。本文提出了CodePLAN框架，旨在通过蒸馏将LLMs的推理能力转移到小型模型中。我们采用多任务学习方法，联合进行代码生成和解决方案计划生成任务，以提高小型模型的代码生成能力。为了确保解决方案计划的优质，我们倡导使用反向推理和计划采样策略。实验表明，与传统的微调方法相比，我们的方法在具有挑战性的APPS基准上提升了小型模型的代码生成性能（以pass@1指标衡量）超过130%。
- en: \NAT@set@cites
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \NAT@set@cites
- en: Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过蒸馏大语言模型的推理能力来提升小型模型的代码生成性能
- en: '| Zhihong Sun¹, Chen Lyu^(1∗†)^†^†thanks: ^∗Zhi Jin and Chen Lyu are the corresponding
    authors.^†^†thanks: $\dagger$This work was done when Chen Lyu was a visiting scholar
    at Peking University., Bolun Li¹, Yao Wan² Hongyu Zhang³, Ge Li⁴, Zhi Jin^(4∗)
    |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 孙志宏¹，吕晨^(1∗†)^†^†致谢：^∗金志和吕晨是通讯作者。^†^†致谢：$\dagger$这项工作是在吕晨担任北京大学访问学者期间完成的，李博伦¹，万尧²，张洪宇³，李歌⁴，金志^(4∗)
    |'
- en: '| ¹School of Information Science and Engineering, Shandong Normal University,
    China |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| ¹山东师范大学信息科学与工程学院，中国 |'
- en: '| ²Huazhong University of Science and Technology, China  ³Chongqing University,
    China |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| ²华中科技大学，中国  ³重庆大学，中国 |'
- en: '| ⁴Key Lab of HCST (PKU), MOE; SCS, Peking University, China |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| ⁴HCST（北京大学）关键实验室，教育部；SCS，北京大学，中国 |'
- en: '| 2022021002@stu.sdnu.edu.cn, lvchen@sdnu.edu.cn, libolun118@gmail.com |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 2022021002@stu.sdnu.edu.cn, lvchen@sdnu.edu.cn, libolun118@gmail.com |'
- en: '| wanyao@hust.edu.cn, hyzhang@cqu.edu.cn |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| wanyao@hust.edu.cn, hyzhang@cqu.edu.cn |'
- en: '| {lige, zhijin}@pku.edu.cn |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| {lige, zhijin}@pku.edu.cn |'
- en: Abstract content
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要内容
- en: 1.   Introduction
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.   引言
- en: Automatic code generation has a history spanning decades, aiming to create executable
    programs from problem specifications (Backus et al., [1957](#bib.bib2); Waldinger
    and Lee, [1969](#bib.bib31); Manna and Waldinger, [1971](#bib.bib23)). As artificial
    intelligence technology rapidly advances, the application of neural network techniques
    in intelligent code generation is increasingly gaining attention in the field
    of software engineering (Ling et al., [2016](#bib.bib21); Yin and Neubig, [2018](#bib.bib38);
    Lyu et al., [2021](#bib.bib22)). Recently, large language models (LLMs) such as
    ChatGPT (OpenAI, [2022](#bib.bib25)) have made significant advances in code generation
    owing to their superior reasoning capabilities. However, deploying these mammoth
    models comes with significant computational, time, and financial demands, coupled
    with data and security risks. Consequently, many enterprises and teams still prefer
    more manageable, smaller models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自动代码生成的历史可以追溯到几十年前，其目标是从问题规格中创建可执行程序（Backus 等，[1957](#bib.bib2)；Waldinger 和
    Lee，[1969](#bib.bib31)；Manna 和 Waldinger，[1971](#bib.bib23)）。随着人工智能技术的快速发展，神经网络技术在智能代码生成中的应用在软件工程领域越来越受到关注（Ling
    等，[2016](#bib.bib21)；Yin 和 Neubig，[2018](#bib.bib38)；Lyu 等，[2021](#bib.bib22)）。最近，像
    ChatGPT（OpenAI，[2022](#bib.bib25)）这样的巨大语言模型由于其卓越的推理能力，在代码生成方面取得了显著进展。然而，部署这些庞大的模型需要大量的计算、时间和财务投入，同时伴随着数据和安全风险。因此，许多企业和团队仍然更喜欢更易于管理的小型模型。
- en: In the realm of code generation, smaller models lag in reasoning capabilities
    compared to LLMs, leading to challenges with complex programming tasks. Our empirical
    studies highlight the exceptional in-context learning (ICL) of LLMs. By utilizing
    "Chain-of-Thought (CoT)" (Wei et al., [2022](#bib.bib36)) as human-defined solution
    steps, LLMs can bolster their reasoning, allowing them to craft solution plans
    from these in-context examples. This methodology elevates LLMs’ problem-solving
    accuracy and is notably effective in code generation (Jiang et al., [2023](#bib.bib14);
    Huang et al., [2024](#bib.bib12)). However, while CoT strategies shine with massive-parameter
    models, smaller models, even after fine-tuning, struggle in deriving CoT-based
    solution plans due to ICL and reasoning constraints. Yet, we have observed that
    a smaller model, around 1B parameters in size, when fine-tuned and given both
    problem description and a precise CoT-based solution plan (labeled as "best plan"),
    sees a substantial boost in code generation capabilities, as shown in Figure [1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs").
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码生成领域，小型模型在推理能力上落后于 LLM，导致在复杂编程任务中面临挑战。我们的实证研究突出了 LLM 的出色上下文学习（ICL）。通过利用“Chain-of-Thought
    (CoT)”（Wei 等，[2022](#bib.bib36)）作为人类定义的解决步骤，LLM 能够增强其推理能力，使其能够从这些上下文示例中制定解决方案计划。这种方法提高了
    LLM 的问题解决准确性，并在代码生成中表现得尤为有效（Jiang 等，[2023](#bib.bib14)；Huang 等，[2024](#bib.bib12)）。然而，尽管
    CoT 策略在大参数模型中表现出色，但小型模型即使经过微调，在得出基于 CoT 的解决方案计划时也会由于 ICL 和推理限制而面临困难。然而，我们观察到，当一个约
    1B 参数大小的小型模型在微调后，同时得到问题描述和准确的基于 CoT 的解决方案计划（标记为“最佳计划”）时，代码生成能力有了显著提升，如图 [1](#S1.F1
    "图 1 ‣ 1\. 介绍 ‣ 通过提炼 LLM 的推理能力来提升小型模型的代码生成性能") 所示。
- en: '![Refer to caption](img/1d8652ad2fb29aaa7db24a0b28d3d79d.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/1d8652ad2fb29aaa7db24a0b28d3d79d.png)'
- en: 'Figure 1: Comparison results of different models without solution plans, spliced
    LLM greedy generated solution plans and the best quality solution plans as prompt,
    where all models were fine-tuned on the APPS train dataset.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：不同模型的比较结果，包括没有解决方案计划的模型、拼接的 LLM 贪婪生成的解决方案计划以及作为提示的最佳质量解决方案计划，所有模型均在 APPS
    训练数据集上进行了微调。
- en: 'This finding prompted us to further explore strategies for providing smaller
    models with a “best plan” when addressing programming tasks. However, we face
    two significant challenges: 1) Dependency on Large Language Models (LLMs) during
    inference. Utilizing LLMs to generate solution plans for smaller models might
    be pragmatic, but it becomes impractical if the smaller model consistently relies
    on LLMs during inference. 2) Securing accurate, high-quality solution plans. Solution
    plans are primarily procured either manually by experts or automatically by LLMs.
    While expert-curated plans are typically more reliable, their high costs make
    them less feasible for automated code generation. In contrast, most LLM-generated
    plans, directly derived from problem descriptions, often do not meet the desired
    quality. Notably, even state-of-the-art LLMs like ChatGPT can produce plans that
    are not consistently accurate, leading not only to missed enhancements but potential
    performance regressions in smaller models, as depicted in Figure [1](#S1.F1 "Figure
    1 ‣ 1\. Introduction ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs").'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这一发现促使我们进一步探索为较小模型提供“最佳计划”的策略，以应对编程任务。然而，我们面临两个重大挑战：1）推理过程中对大型语言模型（LLMs）的依赖。虽然利用LLMs生成解决方案计划对较小模型可能是务实的，但如果较小模型在推理过程中持续依赖LLMs，这种方法就变得不切实际。2）确保解决方案计划的准确性和高质量。解决方案计划主要通过专家手动获取或LLMs自动生成。尽管专家策划的计划通常更可靠，但其高成本使得它们在自动代码生成中不够可行。相比之下，大多数LLM生成的计划直接来源于问题描述，往往无法达到预期的质量。值得注意的是，即使是像ChatGPT这样的最先进的LLMs，也可能产生不一致的计划，导致不仅错过了改进的机会，还可能在较小模型中出现性能回退，如图[1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs")所示。
- en: 'To address these challenges, we introduce “CodePLAN”, a novel multi-task plan-based
    framework designed to enhance the code generation for smaller models by distilling
    LLMs’ reasoning ability. Essentially, CodePLAN utilizes multi-task learning to
    imbue smaller models with LLMs’ reasoning capabilities, allowing them to autonomously
    develop solution plans and generate code. Central to CodePLAN’s effectiveness
    is the precision of these solution plans, both in training and inference. Thus,
    we innovate two techniques: "back reasoning" and "plan sampling", which respectively
    enhance the quality of plans during LLM distillation and during CodePLAN’s own
    inference.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为应对这些挑战，我们引入了“CodePLAN”，这是一个新颖的基于多任务计划的框架，旨在通过提炼LLMs的推理能力来提升较小模型的代码生成。实质上，CodePLAN利用多任务学习赋予较小模型LLMs的推理能力，使其能够自主开发解决方案计划和生成代码。CodePLAN有效性的核心在于这些解决方案计划的准确性，无论是在训练还是推理阶段。因此，我们创新了两种技术：“回溯推理”和“计划采样”，分别提升LLM提炼过程和CodePLAN自身推理中的计划质量。
- en: 'Specifically, to tackle the first challenge, we conceptualize LLMs as "teachers"
    and smaller models as "students", with the objective of distilling the teacher’s
    reasoning capabilities into the student. We employ a multi-task training framework,
    using solution plans from LLMs and actual codes as supervisory signals. This framework
    emphasizes two tasks: 1) Code generation, which develops the smaller model’s coding
    skills, and 2) Plan generation, aiming to distill LLMs’ reasoning prowess. Leveraging
    this strategy, the smaller model’s code generation performance improves notably.
    While it leans on LLMs during training, it operates autonomously during inference.
    At this stage, capitalizing on its refined skill to generate solution plans, the
    model uses its plans to enhance the code generation process, optimizing its output
    potential.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，为解决第一个挑战，我们将LLMs概念化为“教师”，将较小模型视为“学生”，其目标是将教师的推理能力提炼到学生中。我们采用了一个多任务训练框架，利用LLMs的解决方案计划和实际代码作为监督信号。该框架强调两个任务：1）代码生成，培养较小模型的编码技能，以及2）计划生成，旨在提炼LLMs的推理能力。通过这一策略，较小模型的代码生成性能显著提升。尽管在训练过程中依赖LLMs，但在推理过程中可以自主运行。在这一阶段，利用其精炼的技能生成解决方案计划，模型利用这些计划优化代码生成过程，提高输出潜力。
- en: For the second challenge, we guide LLMs to create solution plans based on actual
    codes using a "back reasoning" approach. This deviates from methods by  Jiang
    et al. ([2023](#bib.bib14)) and  Li et al. ([2023c](#bib.bib19)), who rely solely
    on problem descriptions. Our method prioritizes obtaining top-tier solution plans
    (refer to section [3.1](#S3.SS1 "3.1\. Generating Plans through LLM ‣ 3\. CodePLAN
    ‣ Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs")), a claim supported by our empirical data (see Table [5](#S4.T5
    "Table 5 ‣ 4.5\. Evaluation of LLM-Generated Training Data Quality ‣ 4\. Experiments
    ‣ Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs")). Nonetheless, smaller models still confront a similar obstacle
    during the inference phase - the inability to directly generate correct solution
    plans. To address this problem, we take inspiration from the process that programmers
    use to solve complex programming problems. The process of programmers in solving
    complex programming problems is actually a process of continuous trial and error
    of thinking, where the correctness of thinking has been verified by writing code
    according to the constructed thinking until the problem is solved. Consequently,
    in the inference phase, we introduce a technique called "plan sampling" to simulate
    a programmer’s problem-solving. The key was to ensure efficiency while targeting
    quality solutions. To this end, we craft a strategy using limited sampling and
    concise unit tests for each sampled solution plan. This makes "plan sampling"
    both lightweight and highly effective.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个挑战，我们引导LLMs基于实际代码创建解决方案计划，采用了“反向推理”方法。这与Jiang等人（[2023](#bib.bib14)）和Li等人（[2023c](#bib.bib19)）完全依赖问题描述的方法有所不同。我们的方法优先考虑获得顶级解决方案计划（参见第[3.1节](#S3.SS1
    "3.1\. Generating Plans through LLM ‣ 3\. CodePLAN ‣ Enhancing Code Generation
    Performance of Smaller Models by Distilling the Reasoning Ability of LLMs)"),
    这一主张得到了我们的实证数据的支持（见表[5](#S4.T5 "Table 5 ‣ 4.5\. Evaluation of LLM-Generated Training
    Data Quality ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs)")). 尽管如此，小型模型在推理阶段仍面临类似障碍——无法直接生成正确的解决方案计划。为了解决这个问题，我们从程序员解决复杂编程问题的过程获得灵感。程序员解决复杂编程问题的过程实际上是不断试错的思维过程，其中思维的正确性通过根据构建的思维编写代码进行验证，直到问题解决。因此，在推理阶段，我们引入了一种名为“计划采样”的技术，以模拟程序员的解决问题过程。关键是确保效率，同时目标是质量解决方案。为此，我们设计了一种策略，通过有限采样和简明的单元测试来处理每个采样的解决方案计划。这使得“计划采样”既轻量又高效。
- en: 'We executed a comprehensive series of experiments on two distinct streamed
    code generation datasets, namely APPS and MBPP. Our novel approach, in comparison
    to standard finetune methods, considerably enhances the code generation proficiency
    of the model, most notably improving the pass@1 metric on the APPS dataset by
    over 130%. To the best of our knowledge, this study is the first exploration of
    distilling the reasoning ability of LLMs to improve code generation in smaller
    models. Our codebase is publicly accessible at: [https://github.com/sssszh/CodePLAN](https://github.com/sssszh/CodePLAN).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在两个不同的流式代码生成数据集上执行了一系列全面的实验，即APPS和MBPP。与标准的微调方法相比，我们的新颖方法显著提高了模型的代码生成能力，特别是在APPS数据集上的pass@1指标提高了超过130%。据我们所知，本研究是首次探讨通过提炼LLMs的推理能力以提升小型模型的代码生成能力。我们的代码库公开可访问：[https://github.com/sssszh/CodePLAN](https://github.com/sssszh/CodePLAN)。
- en: 2.   Related Work
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 相关工作
- en: Code Generation.
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码生成。
- en: With the advent of transformer (Vaswani et al., [2017](#bib.bib30)) and the
    development of pre-training techniques (Devlin et al., [2018](#bib.bib7)), more
    and more pre-training models are applied in the field of code generation. For
    instance, open-source code models like CodeT5 (Wang et al., [2021](#bib.bib35)),
    CodeT5+ (Wang et al., [2023](#bib.bib34)), CodeGen (Nijkamp et al., [2022](#bib.bib24)),
    PolyCoder (Xu et al., [2022](#bib.bib37)), InCoder (Fried et al., [2022](#bib.bib8)),
    StarCoder (Li et al., [2023a](#bib.bib17)), as well as general-purpose language
    models such as GPT-J (Wang and Komatsuzaki, [2021](#bib.bib32)), GPT-Neo (Black
    et al., [2021](#bib.bib3)) have demonstrated substantial performance in code generation
    tasks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 随着变压器的出现（Vaswani 等，[2017](#bib.bib30)）以及预训练技术的发展（Devlin 等，[2018](#bib.bib7)），越来越多的预训练模型被应用于代码生成领域。例如，开源代码模型如
    CodeT5（Wang 等，[2021](#bib.bib35)），CodeT5+（Wang 等，[2023](#bib.bib34)），CodeGen（Nijkamp
    等，[2022](#bib.bib24)），PolyCoder（Xu 等，[2022](#bib.bib37)），InCoder（Fried 等，[2022](#bib.bib8)），StarCoder（Li
    等，[2023a](#bib.bib17)），以及像 GPT-J（Wang 和 Komatsuzaki，[2021](#bib.bib32)），GPT-Neo（Black
    等，[2021](#bib.bib3)）这样的通用语言模型，在代码生成任务中表现出了显著的性能。
- en: The dominant approaches in code generation mainly involve fine-tuning pre-trained
    code generation models using supervised learning (Hendrycks et al., [2021](#bib.bib9))
    or reinforcement learning (RL) (Li et al., [2022](#bib.bib20); Le et al., [2022](#bib.bib15);
    Shojaee et al., [2023](#bib.bib28); Li et al., [2024](#bib.bib16)). However, neither
    supervised nor reinforcement learning fine-tuning allows the model to learn reasoning
    well. Moreover, RL-based approaches decompose code generation into sequences of
    token-generating actions, which may limit the model to learn reasoning ability
    due to the lack of high-level thinking. Different from these methods, we achieve
    high-level thinking in smaller models by distilling the reasoning abilities of
    LLMs into them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码生成中，主流方法主要包括使用监督学习（Hendrycks 等，[2021](#bib.bib9)）或强化学习（RL）（Li 等，[2022](#bib.bib20)；Le
    等，[2022](#bib.bib15)；Shojaee 等，[2023](#bib.bib28)；Li 等，[2024](#bib.bib16)）对预训练的代码生成模型进行微调。然而，无论是监督学习还是强化学习的微调，都无法使模型很好地学习推理能力。此外，基于
    RL 的方法将代码生成分解为生成标记的动作序列，由于缺乏高层次的思维，这可能限制了模型学习推理能力。不同于这些方法，我们通过将大型语言模型（LLMs）的推理能力提炼到较小模型中，实现了较高层次的思维。
- en: Chain-of-Thought (CoT).
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 思维链（CoT）。
- en: With the advent of large language models, such as ChatGPT  (OpenAI, [2022](#bib.bib25))
    and GPT4 (OpenAI, [2023](#bib.bib26)), and the evolution of CoT prompting techniques (Wei
    et al., [2022](#bib.bib36); Wang et al., [2022](#bib.bib33)), an increasing number
    of researchers have committed themselves to identify strategies that effectively
    augment the emergent capabilities of LLMs (Shum et al., [2023](#bib.bib29); Zhou
    et al., [2022](#bib.bib40)). Jiang et al. ([2023](#bib.bib14)) proposed a “self-plan”
    approach, leveraging the inherent reasoning abilities of LLMs to sequentially
    decompose and solve problems. This methodology has yielded promising results for
    fundamental programming tasks. However, these CoT prompt-based techniques are
    predominantly applicable to models with many parameters (e.g., 100 B or more)
    and are less suitable for models with fewer parameters, which lack inferential
    solid interpretation abilities to decompose complex problems independently. Ho
    et al. ([2022](#bib.bib10)) and  Hsieh et al. ([2023](#bib.bib11)) employed a
    novel strategy of using inference interpretations generated by LLMs as supervised
    signals to train smaller models, with the aim of enhancing their performance on
    simple natural language processing (NLP) tasks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型的出现，如 ChatGPT（OpenAI，[2022](#bib.bib25)）和 GPT4（OpenAI，[2023](#bib.bib26)），以及
    CoT 提示技术的演变（Wei 等，[2022](#bib.bib36)；Wang 等，[2022](#bib.bib33)），越来越多的研究人员致力于寻找有效增强
    LLMs 新兴能力的策略（Shum 等，[2023](#bib.bib29)；Zhou 等，[2022](#bib.bib40)）。Jiang 等人（[2023](#bib.bib14)）提出了一种“自我规划”方法，利用
    LLMs 内在的推理能力顺序分解和解决问题。这种方法在基础编程任务中取得了良好的效果。然而，这些基于 CoT 提示的技术主要适用于参数量大的模型（例如，100B
    或更多），对于参数较少的模型则不太适用，因为这些模型缺乏将复杂问题独立分解的推理能力。Ho 等人（[2022](#bib.bib10)）和 Hsieh 等人（[2023](#bib.bib11)）采用了一种新策略，利用
    LLMs 生成的推理解释作为监督信号来训练较小的模型，以提升它们在简单自然语言处理（NLP）任务中的表现。
- en: In summary, the “self-plan” approach proposed by Jiang et al. ([2023](#bib.bib14))
    relies heavily on the inherent reasoning ability of LLMs. Different from methods
    that stimulate the inherent reasoning abilities of LLMs themselves, our methodology
    utilizes solution plans generated by LLMs as supervised signals for training smaller
    models, distilling the reasoning ability of LLMs into small models, it can reduce
    the expensive cost of deploying LLMs. Previous studies (Ho et al., [2022](#bib.bib10);
    Hsieh et al., [2023](#bib.bib11)) have leveraged the reasoned interpretation of
    LLMs to enhance the performance of smaller models on simple NLP tasks. However,
    unlike these simple NLP tasks, code generation is a much more complex task, and
    the difficulty of obtaining high-quality solution plans prevents these methods
    from being directly applied to the field of code generation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Jiang 等人（[2023](#bib.bib14)）提出的“自我计划”方法在很大程度上依赖于 LLM 的固有推理能力。与刺激 LLM 自身固有推理能力的方法不同，我们的方法利用
    LLM 生成的解决方案计划作为训练较小模型的监督信号，将 LLM 的推理能力提炼到小模型中，从而减少部署 LLM 的高成本。之前的研究（Ho 等人，[2022](#bib.bib10)；Hsieh
    等人，[2023](#bib.bib11)）利用 LLM 的推理解释来提升较小模型在简单 NLP 任务上的表现。然而，与这些简单的 NLP 任务不同，代码生成是一个更复杂的任务，高质量解决方案计划的获取难度阻止了这些方法直接应用于代码生成领域。
- en: '![Refer to caption](img/ee3acccf027cb6dea9a3086418657ace.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ee3acccf027cb6dea9a3086418657ace.png)'
- en: 'Figure 2: We use the prompt to allow LLM to reason backwards a solution plan
    from the code written by the programmer (highlighted in green).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们使用提示使 LLM 从程序员编写的代码（用绿色高亮显示）推导出解决方案计划。
- en: 3.   CodePLAN
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.   CodePLAN
- en: '![Refer to caption](img/7e5db4309f5f8e092b0b835ad9380684.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7e5db4309f5f8e092b0b835ad9380684.png)'
- en: 'Figure 3: Our framework for the training phase of CodePLAN: backward reasoning
    from solutions via LLM about the programmer’s solution plan at the time of solving
    this programming problem, and using these solution plans and solutions to fine-tune
    the code generation model in an alternating multi-task fashion.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：我们用于 CodePLAN 训练阶段的框架：通过 LLM 对程序员在解决编程问题时的解决方案计划进行后向推理，并使用这些解决方案计划和解决方案以交替的多任务方式微调代码生成模型。
- en: In this section, we provide a comprehensive exposition of the core principles
    underlying CodePlan. First, we outline how CodePlan extracts distilled knowledge
    from LLMs, with a specific emphasis on the key ingredient termed "solution plans".
    Following this, we demonstrate the detailed training process by which CodePlan
    leverages these "solution plans" within a multi-task learning framework. Lastly,
    we describe in-depth how CodePlan, during its inference phase, utilizes its self-generated
    "solution plans" to facilitate code generation.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们对 CodePlan 的核心原理进行全面阐述。首先，我们概述了 CodePlan 如何从 LLM 中提取精炼知识，特别强调了所谓的“解决方案计划”这一关键成分。接着，我们展示了
    CodePlan 如何在多任务学习框架中利用这些“解决方案计划”的详细训练过程。最后，我们深入描述了 CodePlan 在推理阶段如何利用其自生成的“解决方案计划”来促进代码生成。
- en: 3.1.   Generating Plans through LLM
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.   通过 LLM 生成计划
- en: Contemporary research reveals that LLMs have the capacity to generate high-quality
    inference steps for certain rudimentary NLP tasks, thereby interpreting the solutions
    it produces Wei et al. ([2022](#bib.bib36)). However, within the domain of code
    generation, LLM does not guarantee the generation of high-quality inference steps
    for intricate programming challenges. This necessitates the exploration of an
    effective methodology to uncover these high-quality solution plans.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当代研究表明，LLM 具备为某些基础 NLP 任务生成高质量推理步骤的能力，从而解释其产生的解决方案 Wei 等人（[2022](#bib.bib36)）。然而，在代码生成领域，LLM
    并不能保证为复杂的编程挑战生成高质量的推理步骤。这就需要探索有效的方法来发现这些高质量的解决方案计划。
- en: Most LLM-based plan generation methods use a "forward reasoning" strategy, leveraging
    CoT examples to deduce plans from problem descriptions. However, our empirical
    studies for code generation tasks suggest that "backward reasoning" — deducing
    from the given solution/code — often produces higher-quality plans. To facilitate
    this, we establish a dataset $D$.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数基于 LLM 的计划生成方法使用“前向推理”策略，利用 CoT 示例从问题描述中推导出计划。然而，我们对代码生成任务的实证研究表明，“后向推理”——从给定的解决方案/代码中推导——通常能产生更高质量的计划。为此，我们建立了一个数据集
    $D$。
- en: 3.2.   Training Model with Plans
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.   使用计划训练模型
- en: We initially outline the methodology for training the base model using the solution
    plans. In this procedure, we employ the intermediate solution plans, generated
    by LLMs, as a novel fine-tuning task assigned to the base model. The specifics
    of this training process are graphically depicted in Figure [3](#S3.F3 "Figure
    3 ‣ 3\. CodePLAN ‣ Enhancing Code Generation Performance of Smaller Models by
    Distilling the Reasoning Ability of LLMs").
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最初概述了使用解决方案计划训练基础模型的方法。在此过程中，我们利用由 LLM 生成的中间解决方案计划，作为分配给基础模型的新型微调任务。该训练过程的具体细节在图 [3](#S3.F3
    "Figure 3 ‣ 3\. CodePLAN ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs")中图示。
- en: 'In conventional fine-tuning strategies, the base code generation model typically
    aims to minimize the cross-entropy loss between the generated code and the target
    code, serving as the primary training objective:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的微调策略中，基础代码生成模型通常旨在最小化生成代码与目标代码之间的交叉熵损失，作为主要训练目标：
- en: '|  | $\mathcal{L}_{\text{code }}\left(\theta_{1}\right)=-\sum_{t}\log p_{\theta_{1}}(w_{t}\mid
    w_{1:t-1},D)$ |  | (1) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{\text{code }}\left(\theta_{1}\right)=-\sum_{t}\log p_{\theta_{1}}(w_{t}\mid
    w_{1:t-1},D)$ |  | (1) |'
- en: where $D$ represents the ground truth code.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D$ 代表真实的代码。
- en: 'Nonetheless, this conventional fine-tuning strategy fails to equip the model
    with inferential proficiency. To endow smaller models with the LLM’s capability
    to decompose intricate problems, we add a training task -distilling reasoning
    ability from LLM - generating solution plans. This task is executed to minimize
    the cross-entropy loss between the solution plans generated by the model and those
    generated by the LLM:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这种传统的微调策略未能赋予模型推理能力。为了使较小的模型具备 LLM 分解复杂问题的能力，我们添加了一个训练任务 - 从 LLM 中提取推理能力
    - 生成解决方案计划。这个任务的执行是为了最小化模型生成的解决方案计划与 LLM 生成的解决方案计划之间的交叉熵损失：
- en: '|  | $\mathcal{L}_{\text{plan }}\left(\theta_{2}\right)=-\sum_{t}\log p_{\theta_{2}}(s_{t}\mid
    s_{1:t-1},D)$ |  | (2) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{\text{plan }}\left(\theta_{2}\right)=-\sum_{t}\log p_{\theta_{2}}(s_{t}\mid
    s_{1:t-1},D)$ |  | (2) |'
- en: where $D$ represents the solution plan generated by LLM.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $D$ 代表由 LLM 生成的解决方案计划。
- en: 'This approach not only equips the model with code generation capabilities but
    also enables it to generate intermediate solution plans. Within this training
    workflow, we utilize an alternating training strategy to fine-tune our model,
    distinguishing between the two tasks using two unique characters: $[GEN\_CODE]$.
    Given the stark differences between program language and natural language, we
    modified our model by incorporating a new “plan head” at the end of the base model
    to generate solution plans. The total loss function optimized in our model is:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法不仅赋予模型代码生成能力，还使其能够生成中间解决方案计划。在这一训练工作流程中，我们采用交替训练策略来微调我们的模型，用两个独特的字符区分这两个任务：$[GEN\_CODE]$。鉴于编程语言和自然语言之间的显著差异，我们通过在基础模型末端添加一个新的“计划头”来修改模型，以生成解决方案计划。我们模型中优化的总损失函数是：
- en: '|  | $\mathcal{L}=(1-\lambda)\mathcal{L}_{\text{code }}+\lambda\mathcal{L}_{\text{plan
    }}$ |  | (3) |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=(1-\lambda)\mathcal{L}_{\text{code }}+\lambda\mathcal{L}_{\text{plan
    }}$ |  | (3) |'
- en: where $\lambda$=0.5.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda$=0.5。
- en: '![Refer to caption](img/937a3e8ddab07b8e86a9f21ad7ae6e51.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/937a3e8ddab07b8e86a9f21ad7ae6e51.png)'
- en: 'Figure 4: The inference phase schematic comprises three stages: ① Initially,
    the model formulates candidate solution plans based on the provided problem description.
    ② Subsequently, as indicated by the dashed line, solution plans generated in Stage
    ① are integrated with the problem description for code generation. Candidate solution
    plans are chosen based on the evaluation outcomes of the code generated through
    example unit tests. ③ Ultimately, the selected high-quality solution plan is used
    as a prompt, integrated within the problem description for a new cycle of code
    generation.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：推理阶段示意图包括三个阶段：① 首先，模型根据提供的问题描述制定候选解决方案计划。② 随后，如虚线所示，将阶段①中生成的解决方案计划与问题描述结合以进行代码生成。候选解决方案计划根据通过示例单元测试生成的代码的评估结果进行选择。③
    最终，选定的高质量解决方案计划被用作提示，与问题描述结合进行新一轮的代码生成。
- en: 3.3.   Inferencing with Plans
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.   使用计划进行推理
- en: Leveraging a multi-task fine-tuning approach, our framework enables the base
    model to generate both code and solution plans. In this context, we detail how,
    during the inference phase, the solution plans produced by the model enhance code
    generation, as illustrated in Figure [4](#S3.F4 "Figure 4 ‣ 3.2\. Training Model
    with Plans ‣ 3\. CodePLAN ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs").
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用多任务微调方法，我们的框架使基础模型能够生成代码和解决方案计划。在这种情况下，我们详细说明了在推理阶段模型生成的解决方案计划如何增强代码生成，如图[4](#S3.F4
    "Figure 4 ‣ 3.2\. Training Model with Plans ‣ 3\. CodePLAN ‣ Enhancing Code Generation
    Performance of Smaller Models by Distilling the Reasoning Ability of LLMs")所示。
- en: Plan Sampling.
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计划采样。
- en: 'As shown in Figure [4](#S3.F4 "Figure 4 ‣ 3.2\. Training Model with Plans ‣
    3\. CodePLAN ‣ Enhancing Code Generation Performance of Smaller Models by Distilling
    the Reasoning Ability of LLMs"), the inference phase of CodePLAN is delineated
    into three specific stages. Initiated in the first stage, we use the fine-tuned
    model to generate the solution plans. The input of the model consists of the $[GEN\_PLAN]$.
    However, the utilization of a greedy decoding strategy is insufficient to assure
    the precision of the solution plans. This deficiency prompted us to consider the
    methods by which programmers tackle complex competition problems: in such scenarios,
    a plethora of potential solution plans are conceived, with code being written
    and subsequently verified through unit tests.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[4](#S3.F4 "Figure 4 ‣ 3.2\. Training Model with Plans ‣ 3\. CodePLAN ‣ Enhancing
    Code Generation Performance of Smaller Models by Distilling the Reasoning Ability
    of LLMs")所示，CodePLAN的推理阶段被划分为三个特定的阶段。在第一个阶段，我们使用微调后的模型生成解决方案计划。模型的输入包括$[GEN\_PLAN]$。然而，使用贪婪解码策略不足以保证解决方案计划的精确性。这一不足促使我们考虑程序员如何应对复杂的竞赛问题：在这种情况下，会产生大量潜在的解决方案计划，代码被编写并通过单元测试进行验证。
- en: 'Accordingly, we incorporated a novel strategy - “plan sampling” - to get the
    correct solution plans. This approach permits the sampling of multiple solution
    plans per problem, thereby encouraging the model to ideate akin to a programmer
    while acknowledging that complex programming problems may have multiple solutions.
    For the second stage, the model utilizes the $[GEN\_CODE]$, defined as: $$\delta(y_{i_{n}},s_{i},t_{i}):=\begin{cases}1,&amp;\text{
    if }y_{i_{n}}\text{ passes}\operatorname{t}_{i}\\'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们引入了一种新策略——“计划采样”——以获得正确的解决方案计划。这种方法允许每个问题采样多个解决方案计划，从而鼓励模型像程序员一样进行构思，同时承认复杂的编程问题可能有多个解决方案。对于第二阶段，模型利用定义为$$\delta(y_{i_{n}},s_{i},t_{i}):=\begin{cases}1,&\text{
    if }y_{i_{n}}\text{ passes}\operatorname{t}_{i}\\
- en: 0,&amp;\text{ otherwise }\end{cases}$$. Consequently, the solution plan correlating
    with the highest number of successful code tests is deemed as the highest quality,
    formally captured by $s_{i}=argmax_{s_{i}\in S}(Score(s_{i}))$. Transitioning
    to the third stage, our framework elevates the model’s code generation capability
    using the chosen top-tier solution plan. Codes generated within this enhanced
    framework are further assessed by hidden unit tests, which are more rigorous than
    the example unit tests, often capturing edge cases or extreme instances of the
    code’s functionality.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 0,&\text{ otherwise }\end{cases}$$。因此，与成功代码测试数量最多的解决方案计划相关的计划被认为是最高质量的，通过$s_{i}=argmax_{s_{i}\in
    S}(Score(s_{i}))$正式捕获。进入第三阶段，我们的框架使用所选的顶级解决方案计划提升模型的代码生成能力。在这个增强的框架中生成的代码会通过隐藏单元测试进一步评估，这些测试比示例单元测试更严格，通常会捕获代码功能的边界情况或极端实例。
- en: 4.   Experiments
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.   实验
- en: '|  |  | *Pass@1* | *Pass@5* | *Pass@100* |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  |  | *Pass@1* | *Pass@5* | *Pass@100* |'
- en: '| Model | Size | Intro | Inter | Comp | All | Intro | Inter | Comp | All |
    Intro | Inter | Comp | All |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 大小 | Intro | Inter | Comp | All | Intro | Inter | Comp | All | Intro
    | Inter | Comp | All |'
- en: '| Codex | 12B | 4.14 | 0.14 | 0.02 | 0.92 | 9.65 | 0.51 | 0.09 | 2.25 | - |
    - | - | - |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Codex | 12B | 4.14 | 0.14 | 0.02 | 0.92 | 9.65 | 0.51 | 0.09 | 2.25 | - |
    - | - | - |'
- en: '| GPT2 | 1.5B | 1.30 | 0.70 | 0.00 | 0.68 | 3.60 | 1.03 | 0.00 | 1.34 | - |
    - | - | - |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| GPT2 | 1.5B | 1.30 | 0.70 | 0.00 | 0.68 | 3.60 | 1.03 | 0.00 | 1.34 | - |
    - | - | - |'
- en: '| GPT-Neo | 2.7B | 3.90 | 0.57 | 0.00 | 1.12 | 5.50 | 0.80 | 0.00 | 1.58 |
    - | - | - | - |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| GPT-Neo | 2.7B | 3.90 | 0.57 | 0.00 | 1.12 | 5.50 | 0.80 | 0.00 | 1.58 |
    - | - | - | - |'
- en: '| GPT-J | 6B | 5.60 | 1.00 | 0.50 | 1.82 | 9.20 | 1.73 | 1.00 | 3.08 | - |
    - | - | - |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| GPT-J | 6B | 5.60 | 1.00 | 0.50 | 1.82 | 9.20 | 1.73 | 1.00 | 3.08 | - |
    - | - | - |'
- en: '| StarCoder | 164M | 1.73 | 0.44 | 0.01 | 0.63 | 4.70 | 1.43 | 0.46 | 1.89
    | 14.80 | 5.50 | 3.80 | 7.02 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| StarCoder | 164M | 1.73 | 0.44 | 0.01 | 0.63 | 4.70 | 1.43 | 0.46 | 1.89
    | 14.80 | 5.50 | 3.80 | 7.02 |'
- en: '| CodeGen | 350M | 1.54 | 0.38 | 0.08 | 0.56 | 4.91 | 1.26 | 0.37 | 1.82 |
    17.40 | 5.51 | 4.10 | 7.62 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen | 350M | 1.54 | 0.38 | 0.08 | 0.56 | 4.91 | 1.26 | 0.37 | 1.82 |
    17.40 | 5.51 | 4.10 | 7.62 |'
- en: '| CodeT5 | 220M | 0.71 | 0.27 | 0.03 | 0.31 | 2.40 | 0.94 | 0.12 | 1.07 | 9.90
    | 3.53 | 1.60 | 4.42 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5 | 220M | 0.71 | 0.27 | 0.03 | 0.31 | 2.40 | 0.94 | 0.12 | 1.07 | 9.90
    | 3.53 | 1.60 | 4.42 |'
- en: '| CodeT5+ | 770M | 4.41 | 0.99 | 0.26 | 1.53 | 9.92 | 2.59 | 1.05 | 3.75 |
    23.50 | 8.33 | 6.50 | 11.00 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5+ | 770M | 4.41 | 0.99 | 0.26 | 1.53 | 9.92 | 2.59 | 1.05 | 3.75 |
    23.50 | 8.33 | 6.50 | 11.00 |'
- en: '| CodeT5 | 770M | 3.30 | 0.68 | 0.15 | 1.10 | 8.12 | 1.89 | 0.74 | 2.91 | 21.30
    | 6.53 | 6.00 | 9.38 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5 | 770M | 3.30 | 0.68 | 0.15 | 1.10 | 8.12 | 1.89 | 0.74 | 2.91 | 21.30
    | 6.53 | 6.00 | 9.38 |'
- en: '| CodeT5+CodePLAN | 770M | 7.87 | 1.61 | 0.42 | 2.62 | 14.66 | 3.54 | 1.59
    | 5.37 | 28.60 | 9.17 | 8.60 | 12.94 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5+CodePLAN | 770M | 7.87 | 1.61 | 0.42 | 2.62 | 14.66 | 3.54 | 1.59
    | 5.37 | 28.60 | 9.17 | 8.60 | 12.94 |'
- en: '| Relative Improvement | 138.5% | 136.8% | 162.5% | 138.2% | 80.5% | 87.3%
    | 114.9% | 84.5% | 34.3% | 40.4% | 43.3% | 38.0% |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 相对改进 | 138.5% | 136.8% | 162.5% | 138.2% | 80.5% | 87.3% | 114.9% | 84.5%
    | 34.3% | 40.4% | 43.3% | 38.0% |'
- en: 'Table 1: Performance by Pass@k on APPS: “Intro”: introductory, “Inter”: interview,
    “Comp”: competition.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：在 APPS 上通过 Pass@k 的性能：“Intro”：入门级，“Inter”：面试级，“Comp”：竞赛级。
- en: 4.1.   Experiment Setup
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.   实验设置
- en: Dataset and Models.
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集和模型。
- en: 'In this study, we evaluate our approach on two mainstream code generation datasets:
    (1) APPS (Hendrycks et al., [2021](#bib.bib9)). (The dataset was collected from
    several programming competition platforms (e.g. Codeforces, LeteCode, etc.) with
    10,000 problems, of which 5,000/5,000 problems were divided for training/testing
    and divided into three levels according to the difficulty of the problems, introductory
    level, interview level, and competition level. (2) MBPP (Austin et al., [2021](#bib.bib1)).
    The dataset consists of 974 programming problems constructed from crowdsourcing,
    with 374/90/500 problems divided for training/validation/testing and 10 reserved
    for few-shot prompt learning. We choose two of the most popular code generation
    models, CodeT5-770M (Wang et al., [2021](#bib.bib35)) and CodeGen-350M (Nijkamp
    et al., [2022](#bib.bib24)), to validate the effectiveness of our approach. And
    the solution plans we use for training are from OpenAI’s GPT-3.5-Turbo API (OpenAI,
    [2022](#bib.bib25)).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们在两个主流代码生成数据集上评估了我们的方法：（1）APPS（Hendrycks 等人，[2021](#bib.bib9)）。该数据集收集自多个编程竞赛平台（例如
    Codeforces、LeetCode 等），共有 10,000 个问题，其中 5,000/5,000 个问题分别用于训练/测试，并根据问题的难度分为三个级别：入门级、面试级和竞赛级。（2）MBPP（Austin
    等人，[2021](#bib.bib1)）。该数据集由众包构建，共 974 个编程问题，其中 374/90/500 个问题分别用于训练/验证/测试，10 个问题保留用于少量样本提示学习。我们选择了两个最受欢迎的代码生成模型：CodeT5-770M（Wang
    等人，[2021](#bib.bib35)）和 CodeGen-350M（Nijkamp 等人，[2022](#bib.bib24)），以验证我们方法的有效性。我们用于训练的解决方案计划来自
    OpenAI 的 GPT-3.5-Turbo API（OpenAI，[2022](#bib.bib25)）。
- en: Metric.
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指标。
- en: 'To evaluate the functional correctness of generated codes, we followed the
    previous works (Hendrycks et al., [2021](#bib.bib9); Chen et al., [2021](#bib.bib6))
    using pass@k as the evaluation metric. This metric measures the functional correctness
    of the code by executing unit test cases. For each problem sampled to generate
    n>=k copies of code, the number of correct codes c<=n, pass@k metric is calculated
    as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估生成代码的功能正确性，我们参考了之前的研究（Hendrycks 等人，[2021](#bib.bib9)；Chen 等人，[2021](#bib.bib6)），使用
    pass@k 作为评估指标。这个指标通过执行单元测试用例来测量代码的功能正确性。对于每个问题，生成 n>=k 份代码时，正确代码的数量 c<=n，pass@k
    指标的计算方法如下：
- en: '|  | $$\operatorname{pass}@k=\underset{\text{ Problems }}{\mathbb{E}}\left[1-\frac{\left(\begin{array}[]{c}n-c\\
    k\end{array}\right)}{\left(\begin{array}[]{l}n\\'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | $$\operatorname{pass}@k=\underset{\text{ 问题 }}{\mathbb{E}}\left[1-\frac{\left(\begin{array}[]{c}n-c\\
    k\end{array}\right)}{\left(\begin{array}[]{l}n\\'
- en: k\end{array}\right)}\right]$$ |  | (4) |
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: k\end{array}\right)}\right]$$ |  | (4) |
- en: In our experimental setup, we sample 100 copies of the code for each problem
    to compute pass@$\{1,5,100\}$
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验设置中，我们为每个问题采样 100 份代码以计算 pass@$\{1,5,100\}$
- en: Training/Inference Setting.
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练/推理设置。
- en: For the training phase associated with the APPS dataset, we adhered to the data
    preprocessing structure as delineated in the original paper (Hendrycks et al.,
    [2021](#bib.bib9)). The established maximum lengths for the source sequence and
    the target sequence were 600 and 512, respectively. The batch size was configured
    to 32, and the learning rate was specified at 2e-5, a learning rate decay of 0.05\.
    The fine-tuning process was executed 10 epochs. When approaching the MBPP dataset,
    we remained consistent with the data preprocessing methodology laid out in the
    original paper (Austin et al., [2021](#bib.bib1)). The respective maximum lengths
    for the source sequence and the target sequence were set at 350 and 300\. Both
    the batch size and the learning rate mirrored the parameters established for the
    APPS dataset. Importantly, we implemented a total of 50 rounds of fine-tuning
    for the MBPP, to account for the more limited number of training sets within this
    dataset. In the inference stage, we employed temperature sampling for both APPS
    and MBPP, with respective temperature settings of 0.6 and 1.2\. For each problem,
    we stipulated the generation of 100 instances of the code and 20 solution plans.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于与APPS数据集相关的训练阶段，我们遵循了原论文中描述的数据预处理结构（Hendrycks et al., [2021](#bib.bib9)）。源序列和目标序列的最大长度分别设定为600和512。批量大小配置为32，学习率设定为2e-5，学习率衰减为0.05。微调过程执行了10个周期。在处理MBPP数据集时，我们保持了一致的数据预处理方法，按照原论文（Austin
    et al., [2021](#bib.bib1)）中的方法进行。源序列和目标序列的最大长度分别设置为350和300。批量大小和学习率与APPS数据集的参数相同。重要的是，我们对MBPP数据集实施了总共50轮的微调，以考虑到该数据集中训练集数量较少。在推断阶段，我们对APPS和MBPP使用了温度采样，温度设置分别为0.6和1.2。对于每个问题，我们规定生成100个代码实例和20个解决方案。
- en: 4.2.   Experimental Results on APPS
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.   在APPS上的实验结果
- en: We evaluated our models and compared them with several baseline models, which
    include GPT-2 (Radford et al., [2019](#bib.bib27)), GPT-Neo (Black et al., [2021](#bib.bib3)),
    GPT-3 (Brown et al., [2020](#bib.bib4)), CodeX (Chen et al., [2021](#bib.bib6)),
    CodeT5 (Wang et al., [2021](#bib.bib35)), CodeT5+ (Wang et al., [2023](#bib.bib34)),
    StarCoder (Li et al., [2023a](#bib.bib17)) and CodeGen (Nijkamp et al., [2022](#bib.bib24)).
    Note that all models except CodeX and GPT-3 are fine-tuned on APPS. As illustrated
    in Table [1](#S4.T1 "Table 1 ‣ 4\. Experiments ‣ Enhancing Code Generation Performance
    of Smaller Models by Distilling the Reasoning Ability of LLMs"), CodePLAN notably
    bolsters the code generation competency of the model, surpassing models equipped
    with several folds the number of parameters. Specifically, across all levels of
    the APPS benchmark, CodePLAN secures an impressive gain of over 130% in the pass@1,
    as compared to the standard fine-tuning process. Moreover, our method manifests
    considerable improvements in the pass@5 and pass@100\. It’s worth emphasizing
    that the enhancement engendered by our method on the pass@1 metric is significantly
    more pronounced than on the pass@100\. This denotes that CodePLAN significantly
    escalates the likelihood of the model generating correct code for the identical
    question. Furthermore, CodePLAN can generate a larger volume of correct codes
    than alternative methods, thereby proving advantageous for subsequent post-processing
    tasks like code ranking. Interestingly, the relative improvement of CodePLAN on
    complex, competition-level questions surpasses that on introductory-level and
    interview-level questions, indicating that CodePLAN empowers smaller models to
    solve complex programming problems with reasoning capabilities.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了我们的模型，并将其与多个基准模型进行了比较，这些模型包括 GPT-2（Radford 等，[2019](#bib.bib27)）、GPT-Neo（Black
    等，[2021](#bib.bib3)）、GPT-3（Brown 等，[2020](#bib.bib4)）、CodeX（Chen 等，[2021](#bib.bib6)）、CodeT5（Wang
    等，[2021](#bib.bib35)）、CodeT5+（Wang 等，[2023](#bib.bib34)）、StarCoder（Li 等，[2023a](#bib.bib17)）和
    CodeGen（Nijkamp 等，[2022](#bib.bib24)）。请注意，除了 CodeX 和 GPT-3 之外，所有模型均在 APPS 上进行了微调。如表
    [1](#S4.T1 "Table 1 ‣ 4\. Experiments ‣ Enhancing Code Generation Performance
    of Smaller Models by Distilling the Reasoning Ability of LLMs") 所示，CodePLAN 显著增强了模型的代码生成能力，超越了多个参数量级数倍的模型。具体而言，在
    APPS 基准的所有级别中，CodePLAN 在 pass@1 上取得了超过 130% 的显著提升，相比于标准微调过程。此外，我们的方法在 pass@5 和
    pass@100 上也显示出显著改进。值得强调的是，我们的方法在 pass@1 指标上的提升明显优于 pass@100。这表明 CodePLAN 显著提高了模型生成正确代码的可能性。此外，CodePLAN
    能生成比其他方法更多的正确代码，从而在后续的代码排名等任务中表现出优势。有趣的是，CodePLAN 在复杂的竞赛级问题上的相对改进超过了入门级和面试级问题，表明
    CodePLAN 使较小的模型能够解决复杂的编程问题，并具备推理能力。
- en: '|  | *Pass@1* | *Pass@5* |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | *Pass@1* | *Pass@5* |'
- en: '| --- | --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Method | Intro | Inter | Comp | All | Intro | Inter | Comp | All |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 入门 | 中级 | 竞赛 | 全部 | 入门 | 中级 | 竞赛 | 全部 |'
- en: '| CodeGen-350M |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-350M |'
- en: '| standard finetune | 1.54 | 0.38 | 0.08 | 0.56 | 4.91 | 1.26 | 0.37 | 1.82
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| standard finetune | 1.54 | 0.38 | 0.08 | 0.56 | 4.91 | 1.26 | 0.37 | 1.82
    |'
- en: '| CoT finetune | 1.38 | 0.35 | 0.06 | 0.50 | 3.95 | 1.21 | 0.21 | 1.56 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| CoT finetune | 1.38 | 0.35 | 0.06 | 0.50 | 3.95 | 1.21 | 0.21 | 1.56 |'
- en: '| CodePLAN w/o PS | 2.06 | 0.56 | 0.09 | 0.77 | 5.27 | 1.62 | 0.40 | 2.11 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| CodePLAN w/o PS | 2.06 | 0.56 | 0.09 | 0.77 | 5.27 | 1.62 | 0.40 | 2.11 |'
- en: '| CodeT5-770M |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-770M |'
- en: '| standard finetune | 3.30 | 0.68 | 0.15 | 1.10 | 8.12 | 1.89 | 0.74 | 2.91
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| standard finetune | 3.30 | 0.68 | 0.15 | 1.10 | 8.12 | 1.89 | 0.74 | 2.91
    |'
- en: '| CoT finetune | 3.22 | 0.78 | 0.14 | 1.15 | 7.65 | 1.99 | 0.36 | 2.84 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| CoT finetune | 3.22 | 0.78 | 0.14 | 1.15 | 7.65 | 1.99 | 0.36 | 2.84 |'
- en: '| CodeRL* | 3.76 | 0.79 | 0.16 | 1.25 | 9.20 | 2.08 | 0.69 | 3.22 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| CodeRL* | 3.76 | 0.79 | 0.16 | 1.25 | 9.20 | 2.08 | 0.69 | 3.22 |'
- en: '| CodePLAN w/o PS | 3.90 | 0.80 | 0.20 | 1.30 | 9.25 | 2.17 | 0.78 | 3.31 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| CodePLAN w/o PS | 3.90 | 0.80 | 0.20 | 1.30 | 9.25 | 2.17 | 0.78 | 3.31 |'
- en: 'Table 2: Results with different training methods on APPS.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同训练方法在 APPS 上的结果。
- en: '| Method | *Pass@1* | *Pass@5* | *Pass@80* |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | *Pass@1* | *Pass@5* | *Pass@80* |'
- en: '| --- | --- | --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| CodeGen-350M |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| CodeGen-350M |'
- en: '| --- |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Standard finetune | 7.51 | 14.98 | 30.29 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Standard finetune | 7.51 | 14.98 | 30.29 |'
- en: '| CoT finetune | 7.95 | 15.01 | 30.12 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| CoT finetune | 7.95 | 15.01 | 30.12 |'
- en: '| CodePLAN w/o PS | 10.39 | 18.66 | 33.05 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| CodePLAN w/o PS | 10.39 | 18.66 | 33.05 |'
- en: '| CodeT5-770M |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-770M |'
- en: '| Standard finetune | 13.78 | 26.01 | 47.89 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| Standard finetune | 13.78 | 26.01 | 47.89 |'
- en: '| CoT finetune | 12.06 | 24.03 | 47.01 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| CoT finetune | 12.06 | 24.03 | 47.01 |'
- en: '| CodePLAN w/o PS | 15.13 | 28.07 | 51.09 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| CodePLAN w/o PS | 15.13 | 28.07 | 51.09 |'
- en: 'Table 3: Results with different training methods on MBPP.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：不同训练方法在 MBPP 上的结果。
- en: '| Plan Sampling Number | *Pass@1* | *Pass@5* | *Pass@100* |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 计划采样数量 | *Pass@1* | *Pass@5* | *Pass@100* |'
- en: '| --- | --- | --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '|  | Intro | Inter | Comp | All | Intro | Inter | Comp | All | Intro | Inter
    | Comp | All |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | 介绍 | 交互 | 综合 | 全部 | 介绍 | 交互 | 综合 | 全部 | 介绍 | 交互 | 综合 | 全部 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    |'
- en: '| N=0 | 3.82 | 0.78 | 0.15 | 1.26 | 9.25 | 2.07 | 0.68 | 3.22 | 21.30 | 6.53
    | 6.00 | 9.38 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| N=0 | 3.82 | 0.78 | 0.15 | 1.26 | 9.25 | 2.07 | 0.68 | 3.22 | 21.30 | 6.53
    | 6.00 | 9.38 |'
- en: '| N=1 | 2.40 | 0.57 | 0.09 | 0.84 | 5.49 | 1.50 | 0.43 | 2.08 | 15.10 | 5.43
    | 3.90 | 7.06 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| N=1 | 2.40 | 0.57 | 0.09 | 0.84 | 5.49 | 1.50 | 0.43 | 2.08 | 15.10 | 5.43
    | 3.90 | 7.06 |'
- en: '| N=5 | 5.33 | 1.04 | 0.24 | 1.74 | 11.02 | 2.59 | 1.04 | 3.96 | 24.70 | 7.57
    | 7.10 | 10.90 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| N=5 | 5.33 | 1.04 | 0.24 | 1.74 | 11.02 | 2.59 | 1.04 | 3.96 | 24.70 | 7.57
    | 7.10 | 10.90 |'
- en: '| N=10 | 6.61 | 1.33 | 0.35 | 2.19 | 12.92 | 3.03 | 1.33 | 4.67 | 26.30 | 8.43
    | 8.10 | 11.94 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| N=10 | 6.61 | 1.33 | 0.35 | 2.19 | 12.92 | 3.03 | 1.33 | 4.67 | 26.30 | 8.43
    | 8.10 | 11.94 |'
- en: '| N=20 | 7.87 | 1.61 | 0.42 | 2.62 | 14.66 | 3.54 | 1.59 | 5.37 | 28.60 | 9.17
    | 8.60 | 12.94 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| N=20 | 7.87 | 1.61 | 0.42 | 2.62 | 14.66 | 3.54 | 1.59 | 5.37 | 28.60 | 9.17
    | 8.60 | 12.94 |'
- en: 'Table 4: Results of ablation experiments with different number of sampling
    plans.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 不同采样计划数量的消融实验结果。'
- en: 4.3.   Comparative Analysis of Various Training Approaches
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.   各种训练方法的比较分析
- en: In this section, we compare various training techniques on APPS and MBPP, namely
    standard fine-tuning, CoT fine-tuning, RL-based fine-tuning, and CodePLAN without
    Plan Sampling (abbreviated as CodePLAN w/o PS). Across these methods, a consistent
    base model is employed. CoT fine-tuning, inspired by existing research  (Ho et al.,
    [2022](#bib.bib10)), is not typically used for code generation. For this method,
    we merge the solution plan with the code to create a target sequence. During inference,
    the model produces a "CoT + Code" output, with the Code segment extracted for
    assessment. For the RL-based fine-tuning, our reference point is the CodeT5 checkpoint
    released by CodeRL (Le et al., [2022](#bib.bib15)), a framework that harnesses
    RL training for code generation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们比较了 APPS 和 MBPP 上的各种训练技术，即标准微调、CoT 微调、基于 RL 的微调和不使用计划采样的 CodePLAN（简称
    CodePLAN w/o PS）。在这些方法中，都使用了一致的基础模型。CoT 微调受到现有研究的启发 (Ho et al., [2022](#bib.bib10))，但通常不用于代码生成。对于这种方法，我们将解决方案计划与代码合并以创建目标序列。在推理过程中，模型生成
    "CoT + Code" 输出，其中提取 Code 部分进行评估。对于基于 RL 的微调，我们的参考点是 CodeT5 检查点，该检查点由 CodeRL (Le
    et al., [2022](#bib.bib15)) 发布，该框架利用 RL 训练进行代码生成。
- en: Result on APPS. On the APPS benchmark, we conducted this experiment using CodeT5
    770M (Wang et al., [2021](#bib.bib35)) and CodeGen 350M (Nijkamp et al., [2022](#bib.bib24))
    as base models. Table [2](#S4.T2 "Table 2 ‣ 4.2\. Experimental Results on APPS
    ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of Smaller Models by
    Distilling the Reasoning Ability of LLMs") presents the comparative results of
    CodePLAN w/o PS alongside various fine-tuning methodologies on the APPS benchmark.
    We can find that the code generation ability of smaller base models is improved
    by distilling the reasoning ability of the LLM, and that this approach outperforms
    other fine-tuning methods on all difficulty levels of the APPS benchmark. Compared
    to standard fine-tuning and RL-based fine-tuning, the inference ability of the
    smaller model is improved by distilling the inference ability of the LLM thus
    indirectly improving the code generation ability of the base model. In contrast,
    standard fine-tuning and RL-based fine-tuning methods lack high-level thinking
    as a supervisory signal and are not beneficial for improving the reasoning ability
    of smaller models. While CoT fine-tuning has proven its mettle in simpler NLP
    tasks (Ho et al., [2022](#bib.bib10)), our experiments reveal its direct application
    to the intricate realm of code generation to be less impactful. In this context,
    CodePLAN demonstrates a significant edge.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 关于APPS的结果。在APPS基准上，我们使用了CodeT5 770M（Wang等，[2021](#bib.bib35)）和CodeGen 350M（Nijkamp等，[2022](#bib.bib24)）作为基础模型进行此实验。表[2](#S4.T2
    "表 2 ‣ 4.2\. APPS上的实验结果 ‣ 4\. 实验 ‣ 通过提炼LLMs的推理能力来提升较小模型的代码生成性能")展示了CodePLAN无PS与各种微调方法在APPS基准上的对比结果。我们发现，通过提炼LLM的推理能力，较小基础模型的代码生成能力得到了提升，这种方法在APPS基准的所有难度级别上都优于其他微调方法。与标准微调和基于RL的微调相比，通过提炼LLM的推理能力间接提升了基础模型的代码生成能力。相比之下，标准微调和基于RL的微调方法缺乏高级思维作为监督信号，不利于提高较小模型的推理能力。虽然CoT微调在简单的NLP任务中已经证明了其能力（Ho等，[2022](#bib.bib10)），但我们的实验表明其在复杂的代码生成领域的直接应用效果较差。在这种背景下，CodePLAN显示出显著的优势。
- en: Result on MBPP. We also conducted this experiment on MBPP, where we followed
    the experimental setup of the original paper (Austin et al., [2021](#bib.bib1))
    and also used the CodeT5-770M and CodeGen-350M as the base models. The outcomes
    are presented in Table [3](#S4.T3 "Table 3 ‣ 4.2\. Experimental Results on APPS
    ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of Smaller Models by
    Distilling the Reasoning Ability of LLMs"). Mirroring findings from the APPS benchmark,
    CodePLAN (w/o PS) consistently outperforms both standard fine-tuning and CoT fine-tuning
    methods by leveraging the distilled reasoning capabilities of the LLM.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 关于MBPP的结果。我们还在MBPP上进行了此实验，遵循了原始论文（Austin等，[2021](#bib.bib1)）的实验设置，并使用了CodeT5-770M和CodeGen-350M作为基础模型。结果见表[3](#S4.T3
    "表 3 ‣ 4.2\. APPS上的实验结果 ‣ 4\. 实验 ‣ 通过提炼LLMs的推理能力来提升较小模型的代码生成性能")。与APPS基准的发现相似，CodePLAN（无PS）通过利用LLM的提炼推理能力，始终优于标准微调和CoT微调方法。
- en: 4.4.   Impact Analysis of Varying Solution Plan Sample Sizes
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.   不同解决方案计划样本大小的影响分析
- en: Table [4](#S4.T4 "Table 4 ‣ 4.2\. Experimental Results on APPS ‣ 4\. Experiments
    ‣ Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs") presents the results of ablation experiments, examining the
    effect of varying the number of sampled solution plans during inference. In this
    setup, the model-generated solution plan $s_{i}$). This indicates that solution
    plans derived via greedy decoding may lack precision. However, employing multiple
    samplings to select quality solution plans can significantly enhance the model’s
    code generation efficacy. Moreover, a greater sampling quantity increases the
    likelihood of identifying a more accurate solution plan.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表[4](#S4.T4 "表 4 ‣ 4.2\. APPS上的实验结果 ‣ 4\. 实验 ‣ 通过提炼LLMs的推理能力来提升较小模型的代码生成性能")展示了消融实验的结果，考察了推理过程中不同数量的样本解决方案计划的效果。在这种设置中，模型生成的解决方案计划$s_{i}$）。这表明通过贪婪解码得到的解决方案计划可能缺乏精确性。然而，采用多次采样选择优质解决方案计划可以显著提高模型的代码生成效率。此外，更多的采样数量增加了找到更准确解决方案计划的可能性。
- en: '![Refer to caption](img/5175197c6599023f3d60c5f54f426e55.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/5175197c6599023f3d60c5f54f426e55.png)'
- en: 'Figure 5: Results of different number of solution plans on the number of correct
    codes generated.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：不同数量的解决方案计划对生成正确代码数量的影响。
- en: Figure [5](#S4.F5 "Figure 5 ‣ 4.4\. Impact Analysis of Varying Solution Plan
    Sample Sizes ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs") depicts how sampling solution
    plans of varying quantities and difficulties impacts the count of accurately generated
    codes, evaluated against the APPS dataset. Across all difficulty levels, it is
    evident that, with N=2, there’s an uptick in correct codes relative to the "Standard
    Finetune". By N=3, the performance even eclipses that of "CodePLAN(w/o PS)". These
    findings underscore that a minimal sampling of solution plans can effectively
    yield high-quality selections. This confirms that our approach not only amplifies
    the code generation prowess of smaller models but also refines their inference
    accuracy.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5](#S4.F5 "Figure 5 ‣ 4.4\. Impact Analysis of Varying Solution Plan Sample
    Sizes ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs")展示了不同数量和难度的解决方案计划采样对生成的准确代码数量的影响，与APPS数据集进行对比。在所有难度级别下，N=2时，相对于“标准微调”，正确代码的数量有所增加。到N=3时，性能甚至超过了“CodePLAN(w/o
    PS)”。这些发现强调，最少量的解决方案计划采样可以有效地产生高质量的选择。这证实了我们的方法不仅提升了小型模型的代码生成能力，还提高了其推理准确性。
- en: 4.5.   Evaluation of LLM-Generated Training Data Quality
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.   LLM生成训练数据质量评估
- en: In this subsection, we delve into the quality analysis of training data formulated
    by the LLM. Assessing the quality of solution plans directly generated by the
    LLM poses challenges. Instead, we resort to an indirect method, evaluating the
    quality of codes generated under the guidance of these solution plans. For this
    assessment, we utilize CodeT5 770M, which underwent standard fine-tuning on the
    APPS dataset. The results, presented in Table  [5](#S4.T5 "Table 5 ‣ 4.5\. Evaluation
    of LLM-Generated Training Data Quality ‣ 4\. Experiments ‣ Enhancing Code Generation
    Performance of Smaller Models by Distilling the Reasoning Ability of LLMs"), compare
    the quality of LLM-generated solution plans from problem descriptions ("Problem
    to Plan") and those derived from backward reasoning using ground truth codes ("Code
    to Plan"). The label "No-Plan" indicates scenarios where LLM-generated plans were
    not used as auxiliary guidance. Our findings reveal that solution plans derived
    from backward reasoning using ground truth codes surpass in quality those generated
    directly from intricate problem descriptions. This likewise indirectly ensures
    the quality of our distilled data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，我们**深入探讨**了由LLM制定的训练数据的质量分析。评估LLM直接生成的解决方案计划的质量具有挑战性。相反，我们采用了一种间接的方法，即评估在这些解决方案计划指导下生成的代码质量。为此，我们使用了经过标准微调的CodeT5
    770M，训练数据来自APPS数据集。结果如表[5](#S4.T5 "Table 5 ‣ 4.5\. Evaluation of LLM-Generated
    Training Data Quality ‣ 4\. Experiments ‣ Enhancing Code Generation Performance
    of Smaller Models by Distilling the Reasoning Ability of LLMs")所示，比较了从问题描述中生成的LLM解决方案计划（“Problem
    to Plan”）与通过反向推理使用真实代码生成的计划（“Code to Plan”）的质量。"No-Plan"标签表示未使用LLM生成的计划作为辅助指导的情况。我们的发现揭示，通过反向推理使用真实代码生成的解决方案计划在质量上超越了直接从复杂问题描述生成的计划。这同样间接地确保了我们提炼数据的质量。
- en: '| Method | *Pass@1* | *Pass@5* | *Pass@10* |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | *Pass@1* | *Pass@5* | *Pass@10* |'
- en: '| --- | --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| CodeT5-770M |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-770M |'
- en: '| --- |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Without Plan | 0.37 | 1.19 | 1.71 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 0.37 | 1.19 | 1.71 |'
- en: '| Problem to Plan | 0.73 | 2.02 | 2.81 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| Problem to Plan | 0.73 | 2.02 | 2.81 |'
- en: '| Code to Plan | 1.35 | 3.52 | 4.78 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| Code to Plan | 1.35 | 3.52 | 4.78 |'
- en: 'Table 5: Quality results of solution plans generated from LLM using different
    approaches on APPS.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：使用不同方法从LLM生成的解决方案计划在APPS上的质量结果。
- en: 5.   Discussion
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.   讨论
- en: How Does Solution Plan Quality Impact Model Performance in Code Generation?
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解决方案计划的质量如何影响模型在代码生成中的表现？
- en: Based on the data in Table [4](#S4.T4 "Table 4 ‣ 4.2\. Experimental Results
    on APPS ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs") and Figure [5](#S4.F5 "Figure 5
    ‣ 4.4\. Impact Analysis of Varying Solution Plan Sample Sizes ‣ 4\. Experiments
    ‣ Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs"), it is clear that the quality of solution plans significantly
    influences model performance. Instead of enhancing the model’s code generation
    capabilities, subpar solution plans might actually degrade its performance. We
    believe that these lower-quality plans could be misconstrued by the model as noise,
    negatively affecting its foundational capabilities. On the other hand, high-quality
    solution plans can greatly boost the model’s code generation, leading to a higher
    output of accurate codes. As such, devising a method to select high-quality solution
    plans becomes crucial in code generation,
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表[4](#S4.T4 "Table 4 ‣ 4.2\. Experimental Results on APPS ‣ 4\. Experiments
    ‣ Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs")和图[5](#S4.F5 "Figure 5 ‣ 4.4\. Impact Analysis of Varying Solution
    Plan Sample Sizes ‣ 4\. Experiments ‣ Enhancing Code Generation Performance of
    Smaller Models by Distilling the Reasoning Ability of LLMs")中的数据，显然解决方案计划的质量对模型性能有显著影响。低劣的解决方案计划不仅不会提升模型的代码生成能力，反而可能降低其性能。我们认为，这些低质量的计划可能被模型误解为噪音，负面影响其基础能力。另一方面，高质量的解决方案计划可以大大提升模型的代码生成，从而提高准确代码的输出。因此，制定一种选择高质量解决方案计划的方法在代码生成中变得至关重要。
- en: What Distinguishes Our Approach from Conventional Code Post-Processing Methods
    in Code Generation?
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 区别我们方法与传统代码后处理方法的特点是什么？
- en: 'It’s worth noting that various post-processing code methodologies (Chen et al.,
    [2022](#bib.bib5); Zhang et al., [2022](#bib.bib39); Inala et al., [2022](#bib.bib13))
    employ a technique to rank potential codes. However, such a ranking strategy doesn’t
    inherently enhance the model’s code generation capabilities. In contrast, our
    approach actively encourages the model to produce more correct codes. Consider
    a scenario in a programming competition: a conventionally fine-tuned model might
    generate 100 code samples for a problem, yet only 1 or 2 of those might pass the
    unit test. This low accuracy complicates the task of code ranking. Conversely,
    our method drives the model to yield a much higher proportion of accurate codes—perhaps
    50 to 90 out of 100\. This surge in accurate code generation certainly aids in
    the ranking process. We adopted the CodeRanker (Inala et al., [2022](#bib.bib13))
    to train a Ranker to validate our assertions. Figure [6](#S5.F6 "Figure 6 ‣ What
    Distinguishes Our Approach from Conventional Code Post-Processing Methods in Code
    Generation? ‣ 5\. Discussion ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs") presents the results of CodeT5,
    CodeT5+Ranker, and CodeT5+CodePLAN+Ranker on APPS. CodeT5+Ranker improves CodeT5’s
    pass@{1,2,5} by an average of 54.5%, and in combination with CodePLAN, CodeT5+Ranker+CodePLAN
    brings an average of 91.3% improvement, it demonstrates the advantages of CodePLAN
    in code ranking tasks and it is also proved that the two are orthogonal.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，许多后处理代码方法（Chen et al., [2022](#bib.bib5); Zhang et al., [2022](#bib.bib39);
    Inala et al., [2022](#bib.bib13)）使用了一种对潜在代码进行排序的技术。然而，这种排序策略并不会本质上提升模型的代码生成能力。相反，我们的方法积极鼓励模型生成更多正确的代码。考虑一下编程竞赛的场景：一个传统上经过精细调整的模型可能会为一个问题生成100个代码样本，但其中只有1或2个可能通过单元测试。这种低准确率使得代码排序任务变得复杂。相对而言，我们的方法驱动模型生成更高比例的准确代码——也许是100个中的50到90个。这种准确代码生成的激增无疑有助于排序过程。我们采用了CodeRanker（Inala
    et al., [2022](#bib.bib13)）来训练一个Ranker以验证我们的论点。图[6](#S5.F6 "Figure 6 ‣ What Distinguishes
    Our Approach from Conventional Code Post-Processing Methods in Code Generation?
    ‣ 5\. Discussion ‣ Enhancing Code Generation Performance of Smaller Models by
    Distilling the Reasoning Ability of LLMs")展示了CodeT5、CodeT5+Ranker和CodeT5+CodePLAN+Ranker在APPS上的结果。CodeT5+Ranker使CodeT5的pass@{1,2,5}提高了平均54.5%，并且结合CodePLAN，CodeT5+Ranker+CodePLAN带来了平均91.3%的提升，显示了CodePLAN在代码排序任务中的优势，并且证明了两者是正交的。
- en: '![Refer to caption](img/6b811bb908efd93982664d8922fa2e0b.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6b811bb908efd93982664d8922fa2e0b.png)'
- en: 'Figure 6: The complementarity between CodeRanker and our CodePLAN.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：CodeRanker与我们的CodePLAN之间的互补性。
- en: 6.   Conclusion
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.   结论
- en: We introduced an innovative code generation framework named CodePLAN. During
    its training phase, CodePLAN uniquely emphasizes the generation of solution plans,
    aiming to refine and optimize the overall code generation process. In the inference
    phase, the framework leverages autonomously produced solution plans, strategically
    enhancing the likelihood of producing accurate codes. Our extensive experimental
    evaluations provide compelling evidence of the efficacy of our approach, demonstrating
    a significant boost in the performance of smaller models in code generation.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了一个名为CodePLAN的创新代码生成框架。在训练阶段，CodePLAN特别强调生成解决方案计划，旨在优化整体代码生成过程。在推理阶段，该框架利用自主生成的解决方案计划，战略性地提高生成准确代码的可能性。我们的广泛实验评估提供了我们方法有效性的有力证据，展示了小型模型在代码生成中的性能显著提升。
- en: Limitations
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: 'Here we summarize two main limitations:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们总结了两个主要的局限性：
- en: Firstly, the first limitation is that due to the limited dataset we have not
    considered what CodePLAN’s preferences are for different types of programming
    topics. Some code generation datasets are now starting to consider dividing the
    dataset based on different algorithms (Li et al., [2023b](#bib.bib18)), so we
    may in the future integrate different algorithms in the solution plan to enhance
    CodePLAN’s ability to learn different algorithms and evaluate CodePLAN at a fine-grained
    level (e.g., different algorithm types).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，第一个局限性是由于数据集的限制，我们没有考虑CodePLAN对不同类型编程主题的偏好。一些代码生成数据集现在开始考虑基于不同算法划分数据集（Li
    et al., [2023b](#bib.bib18)），因此我们未来可能会将不同算法整合到解决方案计划中，以增强CodePLAN学习不同算法的能力，并在细粒度水平（例如，不同算法类型）上评估CodePLAN。
- en: Secondly, we considered only one programming language. In our future work, we
    plan to explore the adaptability of this framework across different programming
    languages and more intricate coding scenarios. With the continuous advancement
    in automatic code generation techniques, we believe methods like CodePLAN will
    play a pivotal role in furthering the progress of this domain.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们只考虑了一种编程语言。在未来的工作中，我们计划探索该框架在不同编程语言和更复杂编码场景中的适应性。随着自动代码生成技术的不断进步，我们相信像CodePLAN这样的技术将在推动该领域的发展中发挥关键作用。
- en: Acknowledgments
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: The work is supported in part by the Natural Science Foundation of Shandong
    Province, China (Grant No. ZR2021MF059), the National Natural Science Foundation
    of China (Grant Nos. 62192731, 62072007, 62192733, 61832009, 62192730), the National
    Key R&D Program (Grant No. 2023YFB4503801) and the Key Program of Hubei (Grant
    No. JD2023008).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 该研究部分得到山东省自然科学基金（资助号：ZR2021MF059）、中国国家自然科学基金（资助号：62192731, 62072007, 62192733,
    61832009, 62192730）、国家重点研发计划（资助号：2023YFB4503801）和湖北省重点项目（资助号：JD2023008）的支持。
- en: 7.   Bibliographical References
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.   参考文献
- en: \c@NAT@ctr
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: \c@NAT@ctr
- en: ''
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Austin et al. (2021) Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma,
    Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc
    Le, et al. 2021. Program synthesis with large language models. *arXiv preprint
    arXiv:2108.07732*.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Austin et al. (2021) Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma,
    Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc
    Le, 等人。2021年。使用大型语言模型进行程序合成。*arXiv预印本 arXiv:2108.07732*。
- en: 'Backus et al. (1957) John W Backus, Robert J Beeber, Sheldon Best, Richard
    Goldberg, Lois M Haibt, Harlan L Herrick, Robert A Nelson, David Sayre, Peter B
    Sheridan, Harold Stern, et al. 1957. The fortran automatic coding system. In *Papers
    presented at the February 26-28, 1957, western joint computer conference: Techniques
    for reliability*, pages 188–198.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Backus et al. (1957) John W Backus, Robert J Beeber, Sheldon Best, Richard Goldberg,
    Lois M Haibt, Harlan L Herrick, Robert A Nelson, David Sayre, Peter B Sheridan,
    Harold Stern, 等人。1957年。Fortran自动编码系统。收录于*1957年2月26-28日西部联合计算机会议上提出的论文：可靠性的技术*，第188-198页。
- en: 'Black et al. (2021) Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella
    Biderman. 2021. Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow.
    *If you use this software, please cite it using these metadata*, 58.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Black et al. (2021) Sid Black, Leo Gao, Phil Wang, Connor Leahy, 和 Stella Biderman。2021年。Gpt-neo：使用mesh-tensorflow的大规模自回归语言建模。*如果你使用了这个软件，请使用这些元数据进行引用*，58。
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, 等. 2020. 语言模型是少样本学习者。*神经信息处理系统进展*，33:1877–1901。
- en: 'Chen et al. (2022) Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin,
    Jian-Guang Lou, and Weizhu Chen. 2022. Codet: Code generation with generated tests.
    *arXiv preprint arXiv:2207.10397*.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen et al. (2022) Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin,
    Jian-Guang Lou, 和 Weizhu Chen. 2022. Codet: 带有生成测试的代码生成。*arXiv 预印本 arXiv:2207.10397*。'
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021. Evaluating large language models trained on code.
    *arXiv preprint arXiv:2107.03374*.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, 等. 2021. 评估在代码上训练的大型语言模型。*arXiv 预印本 arXiv:2107.03374*。
- en: 'Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language
    understanding. *arXiv preprint arXiv:1810.04805*.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, 和 Kristina Toutanova.
    2018. Bert: 语言理解的深度双向变换器的预训练。*arXiv 预印本 arXiv:1810.04805*。'
- en: 'Fried et al. (2022) Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric
    Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis.
    2022. Incoder: A generative model for code infilling and synthesis. *arXiv preprint
    arXiv:2204.05999*.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fried et al. (2022) Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric
    Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, 和 Mike Lewis.
    2022. Incoder: 一种用于代码填充和合成的生成模型。*arXiv 预印本 arXiv:2204.05999*。'
- en: Hendrycks et al. (2021) Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas
    Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song,
    and Jacob Steinhardt. 2021. Measuring coding challenge competence with apps. *NeurIPS*.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks et al. (2021) Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas
    Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song,
    和 Jacob Steinhardt. 2021. 通过应用程序测量编程挑战能力。*NeurIPS*。
- en: Ho et al. (2022) Namgyu Ho, Laura Schmid, and Se-Young Yun. 2022. Large language
    models are reasoning teachers. *arXiv preprint arXiv:2212.10071*.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho et al. (2022) Namgyu Ho, Laura Schmid, 和 Se-Young Yun. 2022. 大型语言模型是推理教师。*arXiv
    预印本 arXiv:2212.10071*。
- en: Hsieh et al. (2023) Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost,
    Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister.
    2023. Distilling step-by-step! outperforming larger language models with less
    training data and smaller model sizes. *arXiv preprint arXiv:2305.02301*.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsieh et al. (2023) Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost,
    Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, 和 Tomas Pfister.
    2023. 步步精进！用更少的训练数据和更小的模型尺寸超越更大的语言模型。*arXiv 预印本 arXiv:2305.02301*。
- en: Huang et al. (2024) Tao Huang, Zhihong Sun, Zhi Jin, Ge Li, and Chen Lyu. 2024.
    Knowledge-aware code generation with large language models. *arXiv preprint arXiv:2401.15940*.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2024) Tao Huang, Zhihong Sun, Zhi Jin, Ge Li, 和 Chen Lyu. 2024.
    知识感知代码生成与大型语言模型。*arXiv 预印本 arXiv:2401.15940*。
- en: Inala et al. (2022) Jeevana Priya Inala, Chenglong Wang, Mei Yang, Andres Codas,
    Mark Encarnación, Shuvendu Lahiri, Madanlal Musuvathi, and Jianfeng Gao. 2022.
    Fault-aware neural code rankers. *Advances in Neural Information Processing Systems*,
    35:13419–13432.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Inala et al. (2022) Jeevana Priya Inala, Chenglong Wang, Mei Yang, Andres Codas,
    Mark Encarnación, Shuvendu Lahiri, Madanlal Musuvathi, 和 Jianfeng Gao. 2022. 故障感知神经代码排序器。*神经信息处理系统进展*，35:13419–13432。
- en: Jiang et al. (2023) Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li.
    2023. Self-planning code generation with large language model. *arXiv preprint
    arXiv:2303.06689*.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. (2023) Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, 和 Ge
    Li. 2023. 自我规划的代码生成与大型语言模型。*arXiv 预印本 arXiv:2303.06689*。
- en: 'Le et al. (2022) Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese,
    and Steven Chu Hong Hoi. 2022. Coderl: Mastering code generation through pretrained
    models and deep reinforcement learning. *Advances in Neural Information Processing
    Systems*, 35:21314–21328.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Le et al. (2022) Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese,
    和 Steven Chu Hong Hoi. 2022. Coderl: 通过预训练模型和深度强化学习掌握代码生成。*神经信息处理系统进展*，35:21314–21328。'
- en: 'Li et al. (2024) Bolun Li, Zhihong Sun, Tao Huang, Hongyu Zhang, Yao Wan, Ge Li,
    Zhi Jin, and Chen Lyu. 2024. Ircoco: Immediate rewards-guided deep reinforcement
    learning for code completion. *arXiv preprint arXiv:2401.16637*.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等（2024）李博伦，孙志宏，黄涛，张宏宇，万瑶，李歌，金志，吕晨。2024。《Ircoco: 立即奖励引导的深度强化学习用于代码补全》。*arXiv
    预印本 arXiv:2401.16637*。'
- en: 'Li et al. (2023a) Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff,
    Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim,
    Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene,
    Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier,
    Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin
    Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp
    Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi
    Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim
    Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire
    Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer
    Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva
    Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis,
    Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. 2023a.
    [Starcoder: may the source be with you!](http://arxiv.org/abs/2305.06161)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等（2023a）雷蒙德·李，卢布娜·本·阿拉尔，杨天子，尼克拉斯·穆恩尼霍夫，丹尼斯·科切特科夫，程浩·牟，马克·马罗恩，克里斯托弗·阿基基，李佳，珍妮·钦，刘倩，叶甫根尼·热尔托诺日基，特里·岳·朱，托马斯·王，奥利维耶·德亨，米希格·达瓦多尔，乔尔·拉米-波利耶，若昂·蒙泰罗，奥列赫·施利亚兹科，尼古拉斯·贡捷，尼古拉斯·米德，阿梅尔·泽巴泽，杨铭豪，洛吉什·库马尔·乌马帕提，朱剑，本杰明·利普金，穆赫塔尚·奥布洛库洛夫，张志若，鲁德拉·穆尔提，杰森·斯蒂勒曼，西瓦·桑卡尔普·帕特尔，德米特里·阿布尔卡诺夫，马尔科·佐卡，马南·德伊，张智寒，努尔·法赫米，乌尔瓦希·巴塔查里亚，温浩·余，斯瓦扬·辛格，萨莎·卢乔尼，保罗·维莱加斯，马克西姆·库纳科夫，费多尔·日丹诺夫，曼努埃尔·罗梅罗，托尼·李，纳达夫·提莫尔，詹妮弗·丁，克莱尔·施莱辛格，海莉·肖尔科普，简·艾伯特，三道，马扬克·米什拉，亚历克斯·顾，詹妮弗·罗宾逊，卡罗琳·简·安德森，布伦丹·多兰-加维特，丹麦斯·承包商，西瓦·雷迪，丹尼尔·弗里德，兹米特里·巴赫达瑙，亚辛·杰尔尼特，卡洛斯·穆诺斯·费朗迪斯，肖恩·休斯，托马斯·沃尔夫，阿尔琼·古哈，利安德罗·冯·维拉，哈姆·德弗里斯。2023a。[Starcoder:
    愿源代码与你同在！](http://arxiv.org/abs/2305.06161)'
- en: 'Li et al. (2023b) Rongao Li, Jie Fu, Bo-Wen Zhang, Tao Huang, Zhihong Sun,
    Chen Lyu, Guang Liu, Zhi Jin, and Ge Li. 2023b. Taco: Topics in algorithmic code
    generation dataset. *arXiv preprint arXiv:2312.14852*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等（2023b）荣瑶·李，屈福，张博文，黄涛，孙志宏，吕晨，刘光，金志，李歌。2023b。《Taco: 主题算法代码生成数据集》。*arXiv
    预印本 arXiv:2312.14852*。'
- en: 'Li et al. (2023c) Xin-Ye Li, Jiang-Tian Xue, Zheng Xie, and Ming Li. 2023c.
    Think outside the code: Brainstorming boosts large language models in code generation.
    *arXiv preprint arXiv:2305.10679*.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2023c）李欣叶，薛江天，谢郑，李铭。2023c。《跳出代码思维：头脑风暴提升大型语言模型的代码生成能力》。*arXiv 预印本 arXiv:2305.10679*。
- en: Li et al. (2022) Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian
    Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin
    Dal Lago, et al. 2022. Competition-level code generation with alphacode. *Science*,
    378(6624):1092–1097.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2022）李宇佳，大卫·崔，郑俊勇，内特·库什曼，朱利安·施雷特维瑟，雷米·勒布朗，汤姆·埃克尔斯，詹姆斯·基林，费利克斯·吉门诺，奥古斯丁·达尔·拉戈，等。2022。《竞赛级代码生成与
    AlphaCode》。*《科学》*，378(6624):1092–1097。
- en: Ling et al. (2016) Wang Ling, Edward Grefenstette, Karl Moritz Hermann, Tomáš
    Kočiskỳ, Andrew Senior, Fumin Wang, and Phil Blunsom. 2016. Latent predictor networks
    for code generation. *arXiv preprint arXiv:1603.06744*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ling 等（2016）王玲，爱德华·格雷芬斯特特，卡尔·莫里茨·赫尔曼，托马什·科齐斯基，安德鲁·塞尼奥，冯敏，菲尔·布伦森。2016。《用于代码生成的潜在预测网络》。*arXiv
    预印本 arXiv:1603.06744*。
- en: Lyu et al. (2021) Chen Lyu, Ruyun Wang, Hongyu Zhang, Hanwen Zhang, and Songlin
    Hu. 2021. Embedding api dependency graph for neural code generation. *Empirical
    Software Engineering*, 26:1–51.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吕等（2021）吕晨，王如云，张宏宇，张汉文，胡松林。2021。《用于神经代码生成的 API 依赖图嵌入》。*《经验软件工程》*，26:1–51。
- en: Manna and Waldinger (1971) Zohar Manna and Richard J Waldinger. 1971. Toward
    automatic program synthesis. *Communications of the ACM*, 14(3):151–165.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manna 和 Waldinger（1971）佐哈尔·曼纳，理查德·J·瓦尔丁格。1971。《朝着自动程序合成迈进》。*《ACM 通讯》*，14(3):151–165。
- en: 'Nijkamp et al. (2022) Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan
    Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2022. Codegen: An open
    large language model for code with multi-turn program synthesis. *arXiv preprint
    arXiv:2203.13474*.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nijkamp 等（2022）埃里克·奈坎普，庞博，林保文，田里富，王欢，周颖博，西尔维奥·萨瓦雷斯，熊采明。2022。《Codegen: 用于代码的开放大型语言模型与多回合程序合成》。*arXiv
    预印本 arXiv:2203.13474*。'
- en: OpenAI (2022) OpenAI. 2022. ChatGPT. [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/).
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2022）OpenAI。2022。《ChatGPT》。[https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)。
- en: OpenAI (2023) OpenAI. 2023. GPT-4 technical report. *CoRR*, abs/2303.08774.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. GPT-4技术报告。*CoRR*，abs/2303.08774。
- en: Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask
    learners. *OpenAI blog*, 1(8):9.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等人 (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei,
    Ilya Sutskever等. 2019. 语言模型是无监督的多任务学习者。*OpenAI博客*，1(8):9。
- en: Shojaee et al. (2023) Parshin Shojaee, Aneesh Jain, Sindhu Tipirneni, and Chandan K.
    Reddy. 2023. [Execution-based code generation using deep reinforcement learning](https://openreview.net/forum?id=0XBuaxqEcG).
    *Transactions on Machine Learning Research*.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shojaee等人 (2023) Parshin Shojaee, Aneesh Jain, Sindhu Tipirneni, 和 Chandan K.
    Reddy. 2023. [基于执行的代码生成使用深度强化学习](https://openreview.net/forum?id=0XBuaxqEcG)。*机器学习研究学报*。
- en: Shum et al. (2023) KaShun Shum, Shizhe Diao, and Tong Zhang. 2023. Automatic
    prompt augmentation and selection with chain-of-thought from labeled data. *arXiv
    preprint arXiv:2302.12822*.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shum等人 (2023) KaShun Shum, Shizhe Diao, 和 Tong Zhang. 2023. 自动提示增强和选择与来自标注数据的思维链。*arXiv预印本
    arXiv:2302.12822*。
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. *Advances in neural information processing systems*, 30.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani等人 (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, 和 Illia Polosukhin. 2017. 注意力机制即你所需的一切。*神经信息处理系统进展*，30。
- en: 'Waldinger and Lee (1969) Richard J Waldinger and Richard CT Lee. 1969. Prow:
    A step toward automatic program writing. In *Proceedings of the 1st international
    joint conference on Artificial intelligence*, pages 241–252.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Waldinger 和 Lee (1969) Richard J Waldinger 和 Richard CT Lee. 1969. Prow: 迈向自动程序编写的一步。在
    *第1届国际人工智能联合会议*，第241–252页。'
- en: 'Wang and Komatsuzaki (2021) Ben Wang and Aran Komatsuzaki. 2021. GPT-J-6B:
    A 6 Billion Parameter Autoregressive Language Model. [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 和 Komatsuzaki (2021) Ben Wang 和 Aran Komatsuzaki. 2021. GPT-J-6B: 一个60亿参数的自回归语言模型。
    [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax)。'
- en: Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi,
    Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves
    chain of thought reasoning in language models. *arXiv preprint arXiv:2203.11171*.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人 (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan
    Narang, Aakanksha Chowdhery, 和 Denny Zhou. 2022. 自我一致性提升语言模型中的思维链推理。*arXiv预印本
    arXiv:2203.11171*。
- en: 'Wang et al. (2023) Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D.Q. Bui,
    Junnan Li, and Steven C. H. Hoi. 2023. Codet5+: Open code large language models
    for code understanding and generation. *arXiv preprint*.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等人 (2023) Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D.Q. Bui, Junnan
    Li, 和 Steven C. H. Hoi. 2023. Codet5+: 开放代码的大型语言模型用于代码理解和生成。*arXiv预印本*。'
- en: 'Wang et al. (2021) Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. 2021.
    Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding
    and generation. *arXiv preprint arXiv:2109.00859*.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等人 (2021) Yue Wang, Weishi Wang, Shafiq Joty, 和 Steven CH Hoi. 2021. Codet5:
    识别符感知的统一预训练编码器-解码器模型，用于代码理解和生成。*arXiv预印本 arXiv:2109.00859*。'
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi,
    Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in
    large language models. *arXiv preprint arXiv:2201.11903*.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei等人 (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi,
    Quoc Le, 和 Denny Zhou. 2022. 思维链提示在大型语言模型中引发推理。*arXiv预印本 arXiv:2201.11903*。
- en: Xu et al. (2022) Frank F Xu, Uri Alon, Graham Neubig, and Vincent Josua Hellendoorn.
    2022. A systematic evaluation of large language models of code. In *Proceedings
    of the 6th ACM SIGPLAN International Symposium on Machine Programming*, pages
    1–10.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人 (2022) Frank F Xu, Uri Alon, Graham Neubig, 和 Vincent Josua Hellendoorn.
    2022. 大型语言模型的系统评估。在 *第六届ACM SIGPLAN国际机器编程研讨会*，第1–10页。
- en: 'Yin and Neubig (2018) Pengcheng Yin and Graham Neubig. 2018. Tranx: A transition-based
    neural abstract syntax parser for semantic parsing and code generation. *arXiv
    preprint arXiv:1810.02720*.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yin 和 Neubig (2018) Pengcheng Yin 和 Graham Neubig. 2018. Tranx: 一种基于过渡的神经抽象语法解析器，用于语义解析和代码生成。*arXiv预印本
    arXiv:1810.02720*。'
- en: Zhang et al. (2022) Tianyi Zhang, Tao Yu, Tatsunori B Hashimoto, Mike Lewis,
    Wen-tau Yih, Daniel Fried, and Sida I Wang. 2022. Coder reviewer reranking for
    code generation. *arXiv preprint arXiv:2211.16490*.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人 (2022) Tianyi Zhang, Tao Yu, Tatsunori B Hashimoto, Mike Lewis, Wen-tau
    Yih, Daniel Fried, 和 Sida I Wang. 2022. 代码生成的审查员重新排名。*arXiv预印本 arXiv:2211.16490*。
- en: Zhou et al. (2022) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2022.
    Least-to-most prompting enables complex reasoning in large language models. *arXiv
    preprint arXiv:2205.10625*.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周等（2022）Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi
    Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, 和 Ed Chi. 2022. 最小到最多提示实现了大型语言模型中的复杂推理。
    *arXiv 预印本 arXiv:2205.10625*。
- en: Appendix A Early Exploration Experiments
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 早期探索实验
- en: In the course of our preliminary experimental investigations, we discerned that
    the solution plans, conjured by LLM(specifically refers to gpt-3.5-turbo) from
    the problem descriptions, were integrated with these descriptions to serve as
    prompts. This composite data was subsequently fed to the fine-tuned smaller models.
    We observed that this methodology marginally enhanced the smaller models’ aptitude
    in addressing complex programming problems. Furthermore, by manually selecting
    the most superior solution plans, we were able to significantly amplify the smaller
    models’ code generation capacities. We singled out these high-quality solution
    plans based on the substantial improvement they afforded to the CodeT5-770M model.
    Interestingly, as revealed from our analysis of Table [6](#A1.T6 "Table 6 ‣ Appendix
    A Early Exploration Experiments ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs"), these high-quality solution
    plans demonstrated a degree of generalization, thereby leading to a substantial
    improvement in the performance of other smaller models. This crucial insight spurred
    us to explore a fresh approach aimed at tapping into the latent potential of smaller
    models in tackling intricate programming problems.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们初步实验调查过程中，我们发现通过 LLM（具体指 gpt-3.5-turbo）从问题描述中构建的解决方案计划与这些描述集成在一起，作为提示输入。这些复合数据随后被输入到微调过的小型模型中。我们观察到，这种方法略微提高了小型模型处理复杂编程问题的能力。此外，通过手动选择最优的解决方案计划，我们能够显著提升小型模型的代码生成能力。我们基于对
    CodeT5-770M 模型显著提升的高质量解决方案计划进行了筛选。有趣的是，从对表[6](#A1.T6 "Table 6 ‣ Appendix A Early
    Exploration Experiments ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs")的分析中揭示，这些高质量解决方案计划展示了一定程度的泛化能力，从而大幅提升了其他小型模型的性能。这一关键见解促使我们探索一种新方法，以挖掘小型模型在解决复杂编程问题中的潜在能力。
- en: '| Method | Intro | Inter | Comp | All |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 引言 | 交互 | 组合 | 全部 |'
- en: '| CodeT5-770M    Pass@1 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-770M    通过@1 |'
- en: '| No-Plan | 3.30 | 0.68 | 0.16 | 1.10 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 3.30 | 0.68 | 0.16 | 1.10 |'
- en: '| With-Plan(greedy) | $4.90\ \ ({\color[rgb]{1,0,0}\uparrow 48.5\%})$ |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（贪心） | $4.90\ \ ({\color[rgb]{1,0,0}\uparrow 48.5\%})$ |'
- en: '| With-Plan(best) | $\textbf{9.72}\ \ ({\color[rgb]{1,0,0}\uparrow 194.5\%})$
    |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（最佳） | $\textbf{9.72}\ \ ({\color[rgb]{1,0,0}\uparrow 194.5\%})$ |'
- en: '| CodeT5-770M    Pass@5 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-770M    通过@5 |'
- en: '| No-Plan | 8.12 | 2.01 | 0.74 | 2.98 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 8.12 | 2.01 | 0.74 | 2.98 |'
- en: '| With-Plan(greedy) | $11.30\ \ ({\color[rgb]{1,0,0}\uparrow 39.2\%})$ |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（贪心） | $11.30\ \ ({\color[rgb]{1,0,0}\uparrow 39.2\%})$ |'
- en: '| With-Plan(best) | $\textbf{18.90}\ \ ({\color[rgb]{1,0,0}\uparrow 132.8\%})$
    |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（最佳） | $\textbf{18.90}\ \ ({\color[rgb]{1,0,0}\uparrow 132.8\%})$ |'
- en: '| CodeT5-220M    Pass@1 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-220M    通过@1 |'
- en: '| No-Plan | 0.71 | 0.27 | 0.03 | 0.31 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 0.71 | 0.27 | 0.03 | 0.31 |'
- en: '| With-Plan(greedy) | $1.36\ \ ({\color[rgb]{1,0,0}\uparrow 91.5\%})$ |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（贪心） | $1.36\ \ ({\color[rgb]{1,0,0}\uparrow 91.5\%})$ |'
- en: '| With-Plan(best) | $\textbf{1.62}\ \ ({\color[rgb]{1,0,0}\uparrow 128.2\%})$
    |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（最佳） | $\textbf{1.62}\ \ ({\color[rgb]{1,0,0}\uparrow 128.2\%})$ |'
- en: '| CodeT5-220M    Pass@5 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| CodeT5-220M    通过@5 |'
- en: '| No-Plan | 2.40 | 0.94 | 0.12 | 1.07 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 2.40 | 0.94 | 0.12 | 1.07 |'
- en: '| With-Plan(greedy) | $3.56\ \ ({\color[rgb]{1,0,0}\uparrow 48.3\%})$ |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（贪心） | $3.56\ \ ({\color[rgb]{1,0,0}\uparrow 48.3\%})$ |'
- en: '| With-Plan(best) | $\textbf{4.71}\ \ ({\color[rgb]{1,0,0}\uparrow 96.3\%})$
    |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（最佳） | $\textbf{4.71}\ \ ({\color[rgb]{1,0,0}\uparrow 96.3\%})$ |'
- en: '| GPT2-1.5B      Pass@1 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| GPT2-1.5B      通过@1 |'
- en: '| No-Plan | 1.30 | 0.70 | 0.00 | 0.68 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 1.30 | 0.70 | 0.00 | 0.68 |'
- en: '| With-Plan(greedy) | $3.37\ \ ({\color[rgb]{1,0,0}\uparrow 159.2\%})$ |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（贪心） | $3.37\ \ ({\color[rgb]{1,0,0}\uparrow 159.2\%})$ |'
- en: '| With-Plan(best) | $\textbf{4.13}\ \ ({\color[rgb]{1,0,0}\uparrow 217.7\%})$
    |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（最佳） | $\textbf{4.13}\ \ ({\color[rgb]{1,0,0}\uparrow 217.7\%})$ |'
- en: '| GPT2-1.5B      Pass@5 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| GPT2-1.5B      通过@5 |'
- en: '| No-Plan | 3.60 | 1.03 | 0.00 | 1.34 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 无计划 | 3.60 | 1.03 | 0.00 | 1.34 |'
- en: '| With-Plan(greedy) | $8.20\ \ ({\color[rgb]{1,0,0}\uparrow 127.8\%})$ |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（贪心） | $8.20\ \ ({\color[rgb]{1,0,0}\uparrow 127.8\%})$ |'
- en: '| With-Plan(best) | $\textbf{9.66}\ \ ({\color[rgb]{1,0,0}\uparrow 168.3\%})$
    |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 有计划（最佳） | $\textbf{9.66}\ \ ({\color[rgb]{1,0,0}\uparrow 168.3\%})$ |'
- en: 'Table 6: Results of different smaller models on APPS with different solution
    plans generated from LLM.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：不同较小模型在APPS上使用LLM生成的不同解决方案计划的结果。
- en: Appendix B Examples
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 示例
- en: B.1.   Examples of Generated Plans
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1. 生成计划的示例
- en: Some examples of solution plans generated by LLM based on ground truth codes
    are shown in Figure [7](#A2.F7 "Figure 7 ‣ B.2\. Example Generated Programs ‣
    Appendix B Examples ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs") and Figure [8](#A2.F8 "Figure 8
    ‣ B.2\. Example Generated Programs ‣ Appendix B Examples ‣ Enhancing Code Generation
    Performance of Smaller Models by Distilling the Reasoning Ability of LLMs"). The
    example in Figure  [7](#A2.F7 "Figure 7 ‣ B.2\. Example Generated Programs ‣ Appendix
    B Examples ‣ Enhancing Code Generation Performance of Smaller Models by Distilling
    the Reasoning Ability of LLMs") is an interview-level problem on the APPS benchmark,
    and the example in Figure [8](#A2.F8 "Figure 8 ‣ B.2\. Example Generated Programs
    ‣ Appendix B Examples ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs") is a competition-level problem on
    the APPS benchmark.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 基于实际代码由LLM生成的解决方案计划的一些示例见图[7](#A2.F7 "Figure 7 ‣ B.2\. Example Generated Programs
    ‣ Appendix B Examples ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs")和图[8](#A2.F8 "Figure 8 ‣ B.2\. Example
    Generated Programs ‣ Appendix B Examples ‣ Enhancing Code Generation Performance
    of Smaller Models by Distilling the Reasoning Ability of LLMs")。图[7](#A2.F7 "Figure
    7 ‣ B.2\. Example Generated Programs ‣ Appendix B Examples ‣ Enhancing Code Generation
    Performance of Smaller Models by Distilling the Reasoning Ability of LLMs")中的示例是APPS基准测试中的面试级问题，而图[8](#A2.F8
    "Figure 8 ‣ B.2\. Example Generated Programs ‣ Appendix B Examples ‣ Enhancing
    Code Generation Performance of Smaller Models by Distilling the Reasoning Ability
    of LLMs")中的示例是APPS基准测试中的竞赛级问题。
- en: B.2.   Example Generated Programs
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2. 生成的程序示例
- en: Figures [9](#A2.F9 "Figure 9 ‣ B.2\. Example Generated Programs ‣ Appendix B
    Examples ‣ Enhancing Code Generation Performance of Smaller Models by Distilling
    the Reasoning Ability of LLMs") to [11](#A2.F11 "Figure 11 ‣ B.2\. Example Generated
    Programs ‣ Appendix B Examples ‣ Enhancing Code Generation Performance of Smaller
    Models by Distilling the Reasoning Ability of LLMs") provide illustrative examples
    of code produced by CodeT5, under the influence of various fine-tuning methods.
    Code segments failing to pass the unit test are presented on a red background,
    whilst code that successfully navigates the unit test is outlined on a green background.
    As evidenced in Figure [9](#A2.F9 "Figure 9 ‣ B.2\. Example Generated Programs
    ‣ Appendix B Examples ‣ Enhancing Code Generation Performance of Smaller Models
    by Distilling the Reasoning Ability of LLMs"), CodeT5, when fine-tuned using our
    proposed approach, generates a significantly higher volume of correct code than
    when it is fine-tuned with the standard method. Figure [10](#A2.F10 "Figure 10
    ‣ B.2\. Example Generated Programs ‣ Appendix B Examples ‣ Enhancing Code Generation
    Performance of Smaller Models by Distilling the Reasoning Ability of LLMs") depicts
    how CodeT5, when fine-tuned using our methodology, can effectively address issues
    that remain unresolved when CodeT5 is fine-tuned using the standard method. This
    outcome stems from the standard fine-tuning method’s limited success in enhancing
    the smaller model’s reasoning abilities, whereas our method successfully amplifies
    the mini-model’s cognitive capabilities by fostering mutual enhancement between
    the two tasks. Furthermore, our strategy of deploying high-quality solution plans
    as cues significantly augments the probability of correct code generation. Figure
     [11](#A2.F11 "Figure 11 ‣ B.2\. Example Generated Programs ‣ Appendix B Examples
    ‣ Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning
    Ability of LLMs"), however, reveals a failure scenario where despite our method
    yielding a greater number of accurate codes, the selection of an incorrect solution
    plan (generated by the greedy decoding of CodePLAN w/o PS) as a cue fails to produce
    correct codes. This is attributable to the incorrect solution plan being perceived
    as noise by the smaller model, thereby compromising the smaller model’s innate
    abilities.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [9](#A2.F9 "图 9 ‣ B.2\. 示例生成程序 ‣ 附录 B 示例 ‣ 通过提炼 LLM 的推理能力来提升小型模型的代码生成性能")至 [11](#A2.F11
    "图 11 ‣ B.2\. 示例生成程序 ‣ 附录 B 示例 ‣ 通过提炼 LLM 的推理能力来提升小型模型的代码生成性能")提供了 CodeT5 生成代码的示例，展示了各种微调方法的影响。未通过单元测试的代码片段以红色背景显示，而成功通过单元测试的代码则以绿色背景标出。如图 [9](#A2.F9
    "图 9 ‣ B.2\. 示例生成程序 ‣ 附录 B 示例 ‣ 通过提炼 LLM 的推理能力来提升小型模型的代码生成性能")所示，当 CodeT5 使用我们提出的方法进行微调时，其生成的正确代码数量明显高于标准方法微调时的结果。图 [10](#A2.F10
    "图 10 ‣ B.2\. 示例生成程序 ‣ 附录 B 示例 ‣ 通过提炼 LLM 的推理能力来提升小型模型的代码生成性能")展示了当 CodeT5 使用我们的方法进行微调时，能够有效解决在标准方法微调下未解决的问题。这一结果源于标准微调方法在提升小型模型推理能力方面的成功有限，而我们的方法通过促进两项任务之间的相互增强成功放大了小模型的认知能力。此外，我们将高质量解决方案计划作为提示的策略显著提高了正确代码生成的概率。然而，图
    [11](#A2.F11 "图 11 ‣ B.2\. 示例生成程序 ‣ 附录 B 示例 ‣ 通过提炼 LLM 的推理能力来提升小型模型的代码生成性能") 显示了一个失败场景，尽管我们的方法生成了更多准确的代码，但选择了一个错误的解决方案计划（由
    CodePLAN 无 PS 的贪婪解码生成）作为提示未能产生正确代码。这是因为错误的解决方案计划被小型模型视为噪声，从而影响了小型模型的固有能力。
- en: '![Refer to caption](img/969efccfb91a12f8b7fd81a6ab887fe2.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/969efccfb91a12f8b7fd81a6ab887fe2.png)'
- en: 'Figure 7: An example of an interview-level problem and ground truth code on
    the APPS benchmark, and a solution plan generated by LLM based on the ground truth
    code.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：APPS 基准测试中的一个面试级别问题示例及其实际代码，以及基于实际代码生成的 LLM 解决方案计划。
- en: '![Refer to caption](img/fd649b98790889b6a80e91fc75d177b8.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fd649b98790889b6a80e91fc75d177b8.png)'
- en: 'Figure 8: An example of an competition-level problem and ground truth code
    on the APPS benchmark, and a solution plan generated by LLM based on the ground
    truth code.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：APPS 基准测试中的一个竞赛级别问题示例及其实际代码，以及基于实际代码生成的 LLM 解决方案计划。
- en: '![Refer to caption](img/562794574733c50814acd0402bb182a8.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/562794574733c50814acd0402bb182a8.png)'
- en: 'Figure 9: An example of a problem on the APPS benchmark and code generated
    by CodeT5 with different ways of fine-tuning: only one of the four copies of code
    generated by CodeT5 with standard finetune passes the unit test, while all four
    copies of code generated by CodeT5 with our CodePLAN (w/o PS) fine-tuning pass
    the unit test.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：APPS基准测试中的一个问题示例和通过不同微调方式生成的CodeT5代码：使用标准微调的CodeT5生成的四份代码中只有一份通过了单元测试，而使用我们的CodePLAN（不包括PS）微调的CodeT5生成的四份代码全部通过了单元测试。
- en: '![Refer to caption](img/776088731f607ee4160f62f687f1ec52.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/776088731f607ee4160f62f687f1ec52.png)'
- en: 'Figure 10: An example of a problem on the APPS benchmark and code generated
    by CodeT5 with different ways of fine-tuning: CodeT5 with the standard fine-tune
    method generates four copies of code that do not pass the unit test, while CodeT5
    with our CodePLAN (w/o PS) generates one of the four copies of code that pass
    the unit test, and we select a high-quality solution plan to be spliced after
    the problem description as a prompt, and CodeT5 with CodePLAN generates four copies
    of code that pass the unit test.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：APPS基准测试中的一个问题示例和通过不同微调方式生成的CodeT5代码：使用标准微调方法的CodeT5生成了四份未通过单元测试的代码，而使用我们的CodePLAN（不包括PS）的CodeT5生成了四份代码中的一份通过了单元测试，我们选择一个高质量的解决方案计划在问题描述后作为提示，然后使用CodePLAN的CodeT5生成了四份通过单元测试的代码。
- en: '![Refer to caption](img/977abc15a4ff8799365b8ce7e7200cf1.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/977abc15a4ff8799365b8ce7e7200cf1.png)'
- en: 'Figure 11: An example of a problem on the APPS benchmark and code generated
    by CodeT5 with different ways of fine-tuning: All four copies of CodeT5 generated
    by the standard fine-tuning method fail the unit test, while all four copies of
    CodeT5 generated by our CodePLAN (w/o PS) pass the unit test. However, we select
    an incorrect solution plan and splice it after the problem description as a prompt
    that all four copies of CodeT5 with CodePLAN do not pass the unit test.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：APPS基准测试中的一个问题示例和通过不同微调方式生成的CodeT5代码：使用标准微调方法生成的四份CodeT5代码都未通过单元测试，而使用我们的CodePLAN（不包括PS）生成的四份CodeT5代码都通过了单元测试。然而，我们选择了一个不正确的解决方案计划并将其拼接在问题描述后作为提示，结果所有四份使用CodePLAN的CodeT5代码都未通过单元测试。
