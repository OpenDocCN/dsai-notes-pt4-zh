- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-08 18:58:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-08 18:58:54'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'TWOLAR: 一种用于段落重排序的两步LLM增强蒸馏方法'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.17759](https://ar5iv.labs.arxiv.org/html/2403.17759)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.17759](https://ar5iv.labs.arxiv.org/html/2403.17759)
- en: \useunder
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \useunder
- en: \ul
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \ul
- en: '¹¹institutetext: University of Bologna, Bologna, Italy ²²institutetext: University
    of Tokyo, Tokyo, Japan ³³institutetext: National Institute of Informatics, Tokyo,
    JapanDavide Baldelli 1133 [0009-0006-4336-923X](https://orcid.org/0009-0006-4336-923X
    "ORCID identifier")    Junfeng Jiang 22 [0000-0002-3680-2465](https://orcid.org/0000-0002-3680-2465
    "ORCID identifier")    Akiko Aizawa 33 [0000-0001-6544-5076](https://orcid.org/0000-0001-6544-5076
    "ORCID identifier")    Paolo Torroni 11 [0000-0002-9253-8638](https://orcid.org/0000-0002-9253-8638
    "ORCID identifier")'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹机构文本: 意大利博洛尼亚大学，博洛尼亚，意大利 ²²机构文本: 日本东京大学，东京，日本 ³³机构文本: 日本东京国立信息学研究所，东京，日本
    Davide Baldelli 1133 [0009-0006-4336-923X](https://orcid.org/0009-0006-4336-923X
    "ORCID identifier")    Junfeng Jiang 22 [0000-0002-3680-2465](https://orcid.org/0000-0002-3680-2465
    "ORCID identifier")    Akiko Aizawa 33 [0000-0001-6544-5076](https://orcid.org/0000-0001-6544-5076
    "ORCID identifier")    Paolo Torroni 11 [0000-0002-9253-8638](https://orcid.org/0000-0002-9253-8638
    "ORCID identifier")'
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this paper, we present TWOLAR: a two-stage pipeline for passage reranking
    based on the distillation of knowledge from Large Language Models (LLM). TWOLAR
    introduces a new scoring strategy and a distillation process consisting in the
    creation of a novel and diverse training dataset. The dataset consists of 20K
    queries, each associated with a set of documents retrieved via four distinct retrieval
    methods to ensure diversity, and then reranked by exploiting the zero-shot reranking
    capabilities of an LLM. Our ablation studies demonstrate the contribution of each
    new component we introduced. Our experimental results show that TWOLAR significantly
    enhances the document reranking ability of the underlying model, matching and
    in some cases even outperforming state-of-the-art models with three orders of
    magnitude more parameters on the TREC-DL test sets and the zero-shot evaluation
    benchmark BEIR. To facilitate future work we release our data set, finetuned models,
    and code¹¹1Code: [https://github.com/Dundalia/TWOLAR](https://github.com/Dundalia/TWOLAR);'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '在本文中，我们提出了TWOLAR：一种基于大型语言模型（LLM）知识蒸馏的两阶段通道重排序方法。TWOLAR引入了一种新的评分策略和一个蒸馏过程，该过程包括创建一个新颖且多样的训练数据集。该数据集包含20K个查询，每个查询都与通过四种不同检索方法检索到的一组文档相关，以确保多样性，然后利用LLM的零样本重排序能力进行重排序。我们的消融研究展示了我们引入的每个新组件的贡献。我们的实验结果表明，TWOLAR显著增强了底层模型的文档重排序能力，与具有三个数量级更多参数的最先进模型在TREC-DL测试集和零样本评估基准BEIR上的表现相当，甚至在某些情况下超越了这些模型。为了促进未来的工作，我们发布了我们的数据集、微调模型和代码¹¹1代码:
    [https://github.com/Dundalia/TWOLAR](https://github.com/Dundalia/TWOLAR)；'
- en: 'Models and Dataset: [https://huggingface.co/Dundalia](https://huggingface.co/Dundalia).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '模型和数据集: [https://huggingface.co/Dundalia](https://huggingface.co/Dundalia)。'
- en: 'Keywords:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '关键词:'
- en: Information Retrieval Reranking Knowledge distillation Large Language Model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索 重排序 知识蒸馏 大型语言模型。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Text ranking, a foundational task in search engines and question-answering systems,
    involves ordering textual documents based on their relevance to a given query
    or context.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 文本排序是搜索引擎和问答系统中的基础任务，涉及根据给定查询或上下文对文本文件进行排序。
- en: The state-of-the-art text rerankers are traditional cross-encoders like monoBERT [[27](#bib.bib27)],
    monoT5 [[28](#bib.bib28), [35](#bib.bib35)], and RankT5 [[44](#bib.bib44)], and
    more recently rerankers based on Large Language Models (LLMs) like RankGPT [[36](#bib.bib36)]
    and PRP [[31](#bib.bib31)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最先进的文本重排序器包括传统的交叉编码器，如monoBERT [[27](#bib.bib27)]、monoT5 [[28](#bib.bib28),
    [35](#bib.bib35)]和RankT5 [[44](#bib.bib44)]，以及最近基于大型语言模型（LLM）的重排序器，如RankGPT [[36](#bib.bib36)]和PRP [[31](#bib.bib31)]。
- en: Cross-encoders are computationally efficient but rely on costly human-annotated
    labels for training, while LLM-based methods bypass the need of in-domain fine-tuning.
    However, a significant downside is their substantial size and computational footprint,
    which could render them unsuitable for real-time inference. However, the knowledge
    of an LLM could be distilled to produce a student model with performance comparable
    to the teacher model, but a size several orders of magnitude smaller.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Cross-encoders 在计算上高效，但依赖于昂贵的人类标注标签进行训练，而基于 LLM 的方法则绕过了领域内微调的需求。然而，一个显著的缺点是它们的庞大体积和计算开销，这可能使它们不适合实时推断。然而，LLM
    的知识可以被提炼出一个学生模型，其性能可与教师模型相媲美，但体积则小几个数量级。
- en: In this paper, we present TWOLAR, a TWO-step LLM-Augmented distillation method
    for passage Reranking. The distillation consists in exploiting the capabilities
    of an LLM as a reranker to produce high-quality annotations. The annotations are
    applied to a dataset of queries generated artificially, either as cropped sentences
    or again by a specialized language model. In this way, we obtain a compact model
    that ranks among top performing supervised, zero-shot, and LLM-based distillation
    methods in various popular benchmarks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了 TWOLAR，一种用于段落重排序的两步 LLM 增强提炼方法。该提炼方法利用 LLM 作为重排序器的能力生成高质量注释。这些注释应用于人工生成的查询数据集，这些查询数据集可以是裁剪的句子，也可以是由专门的语言模型生成的。通过这种方式，我们获得了一个紧凑的模型，在各种流行的基准测试中排名靠前，包括监督学习、零样本学习和基于
    LLM 的提炼方法。
- en: 'The paper is structured as follows: Section [2](#S2 "2 Background ‣ TWOLAR:
    a TWO-step LLM-Augmented distillation method for passage Reranking") provides
    background on text ranking methods and benchmarks. Section [3](#S3 "3 Approach
    ‣ TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking")
    details our approach, subdivided into scoring and distillation strategies. Section
    [4](#S4 "4 Experimental setup ‣ TWOLAR: a TWO-step LLM-Augmented distillation
    method for passage Reranking") covers the experimental setup, including datasets,
    training, baselines, and results. Section [5](#S5 "5 Discussion ‣ TWOLAR: a TWO-step
    LLM-Augmented distillation method for passage Reranking") discusses the results
    and ablation studies. Section [6](#S6 "6 Conclusion ‣ TWOLAR: a TWO-step LLM-Augmented
    distillation method for passage Reranking") concludes the paper.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '论文的结构如下：第 [2](#S2 "2 背景 ‣ TWOLAR: 一种用于段落重排序的两步 LLM 增强提炼方法") 节提供了关于文本排名方法和基准测试的背景信息。第
    [3](#S3 "3 方法 ‣ TWOLAR: 一种用于段落重排序的两步 LLM 增强提炼方法") 节详细介绍了我们的方法，包括评分和提炼策略。第 [4](#S4
    "4 实验设置 ‣ TWOLAR: 一种用于段落重排序的两步 LLM 增强提炼方法") 节涵盖了实验设置，包括数据集、训练、基线和结果。第 [5](#S5
    "5 讨论 ‣ TWOLAR: 一种用于段落重排序的两步 LLM 增强提炼方法") 节讨论了结果和消融研究。第 [6](#S6 "6 结论 ‣ TWOLAR:
    一种用于段落重排序的两步 LLM 增强提炼方法") 节总结了论文。'
- en: 2 Background
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: Formally, given a query and a passage from a large text collection, text ranking
    requires returning a ranked list of the $n$ most relevant texts according to the
    relevance scores of a model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，给定一个查询和来自大文本集合的一个段落，文本排名需要返回一个根据模型的相关性评分排序的 $n$ 个最相关文本的列表。
- en: 'The early text ranking methods relied mainly on statistical lexical features,
    like BM25 [[34](#bib.bib34)] and TF-IDF, and used heuristic methods for retrieval [[42](#bib.bib42)].
    Based on this scheme, each query-document relevance score is computed according
    to the lexical similarity. Subsequently, statistical language modeling has been
    widely explored for text ranking [[41](#bib.bib41)]. With the development of machine
    learning, supervised approaches, which still rely on hand-crafted features as
    well as lexical features, have been proposed [[22](#bib.bib22), [19](#bib.bib19)].
    Further progress was made with the adoption of neural networks mapping pieces
    of text into low-dimensional vectors to obtain better representations [[13](#bib.bib13),
    [25](#bib.bib25), [14](#bib.bib14)]. Recently, a new paradigm emerged [[9](#bib.bib9),
    [20](#bib.bib20), [42](#bib.bib42), [30](#bib.bib30), [43](#bib.bib43)], consisting
    of multiple stages: using a first-stage retriever that aims to reduce the candidate
    space by retrieving a subset of relevant candidates, often numbering in the hundreds
    or thousands, and then refining these initial results with a second-stage reranker.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的文本排序方法主要依赖于统计词汇特征，如BM25 [[34](#bib.bib34)]和TF-IDF，并使用启发式方法进行检索[[42](#bib.bib42)]。基于这种方案，每个查询-文档相关性评分是根据词汇相似性计算的。随后，统计语言建模被广泛应用于文本排序[[41](#bib.bib41)]。随着机器学习的发展，依赖于手工制作特征以及词汇特征的监督方法被提出[[22](#bib.bib22),
    [19](#bib.bib19)]。进一步的进展体现在采用神经网络将文本映射到低维向量，以获得更好的表示[[13](#bib.bib13), [25](#bib.bib25),
    [14](#bib.bib14)]。最近，出现了一种新范式[[9](#bib.bib9), [20](#bib.bib20), [42](#bib.bib42),
    [30](#bib.bib30), [43](#bib.bib43)]，包括多个阶段：使用第一阶段的检索器，旨在通过检索相关候选项的子集来减少候选空间，通常数量在数百或数千个，并通过第二阶段的重排序器进一步优化这些初步结果。
- en: The advent of pretrained language models (PLMs) [[8](#bib.bib8), [33](#bib.bib33),
    [32](#bib.bib32)] and large-scale human annotated datasets [[26](#bib.bib26),
    [18](#bib.bib18), [40](#bib.bib40)] marked a significant advancement in the field.
    Models such as DPR [[17](#bib.bib17)], SPLADE [[12](#bib.bib12), [10](#bib.bib10),
    [11](#bib.bib11)], and DRAGON [[21](#bib.bib21)] emerged as powerful first-stage
    retrievers. Complementing these retrievers, models like monoBERT [[27](#bib.bib27)],
    monoT5 [[28](#bib.bib28), [35](#bib.bib35)], and RankT5 [[44](#bib.bib44)] have
    been conceived as second-stage rerankers, designed explicitly to refine and optimize
    the results provided by the initial retrieval stage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练语言模型（PLMs）[[8](#bib.bib8), [33](#bib.bib33), [32](#bib.bib32)]和大规模人工标注数据集[[26](#bib.bib26),
    [18](#bib.bib18), [40](#bib.bib40)]的出现标志着该领域的重大进展。像DPR [[17](#bib.bib17)]、SPLADE [[12](#bib.bib12),
    [10](#bib.bib10), [11](#bib.bib11)]和DRAGON [[21](#bib.bib21)]等模型作为强大的第一阶段检索器出现。与这些检索器互补的是，像monoBERT [[27](#bib.bib27)]、monoT5 [[28](#bib.bib28),
    [35](#bib.bib35)]和RankT5 [[44](#bib.bib44)]等模型被设计为第二阶段重排序器，专门用于优化和精炼初步检索阶段提供的结果。
- en: Recently, large language models (LLMs) have begun to play an influential role
    in text reranking [[43](#bib.bib43), [24](#bib.bib24)]. The latest approaches
    in text reranking utilize LLMs in various ways. For instance, InPars [[2](#bib.bib2)]
    and InParsV2 [[16](#bib.bib16)] leverage GPT-3 Curie [[3](#bib.bib3)] and GPT-J [[39](#bib.bib39)]
    respectively, for data augmentation, generating synthetic queries to adapt a reranking
    model to different reranking tasks and domains. Other approaches instead consist
    in directly prompting the LLM to permute a set of documents given a query. In
    this vein, RankGPT [[36](#bib.bib36)], LRL [[24](#bib.bib24)], and PRP [[31](#bib.bib31)]
    have demonstrated the potential of LLMs as zero-shot rerankers. Moreover, RankGPT [[36](#bib.bib36)]
    demonstrates how the ranking abilities of ChatGPT could be distilled into a more
    efficient DeBERTa [[15](#bib.bib15)]. For a comprehensive survey on LLMs for Information
    Retrieval, the interested readers can refer to [[43](#bib.bib43)].
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）在文本重排序中开始发挥重要作用[[43](#bib.bib43), [24](#bib.bib24)]。文本重排序的最新方法以各种方式利用LLMs。例如，InPars [[2](#bib.bib2)]和InParsV2 [[16](#bib.bib16)]分别利用GPT-3
    Curie [[3](#bib.bib3)]和GPT-J [[39](#bib.bib39)]进行数据增强，生成合成查询以适应不同的重排序任务和领域。其他方法则直接提示LLM根据查询对一组文档进行排列。在这种方法下，RankGPT [[36](#bib.bib36)],
    LRL [[24](#bib.bib24)]和PRP [[31](#bib.bib31)]展示了LLMs作为零-shot重排序器的潜力。此外，RankGPT [[36](#bib.bib36)]展示了如何将ChatGPT的排序能力提炼成更高效的DeBERTa [[15](#bib.bib15)]。有关LLMs在信息检索中的全面调查，感兴趣的读者可以参考[[43](#bib.bib43)]。
- en: As for the benchmarks, The largest annotated dataset for information retrieval
    is the MS MARCO passage reranking dataset [[26](#bib.bib26)]. It contains around
    530K train queries and 6.8K ‘dev’ queries. The corpus is composed of more than
    8.8M passages. For each query, relevant passages are annotated as 1 and others
    are annotated as 0\. TREC-DL2019 [[7](#bib.bib7)] and TREC-DL2020 [[6](#bib.bib6)]
    are standard benchmarks derived from MS MARCO that provide dense human relevance
    annotations for each of their 43 and 54 queries. BEIR [[37](#bib.bib37)] is a
    heterogeneous benchmark containing 18 retrieval datasets, covering different retrieval
    tasks and domains, designed for zero-shot evaluation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 至于基准测试，最大规模的标注数据集是 MS MARCO 段落重排数据集 [[26](#bib.bib26)]。它包含约 530K 的训练查询和 6.8K
    个“开发”查询。该语料库由超过 8.8M 个段落组成。对于每个查询，相关段落标注为 1，其它标注为 0。TREC-DL2019 [[7](#bib.bib7)]
    和 TREC-DL2020 [[6](#bib.bib6)] 是源自 MS MARCO 的标准基准，它们为各自的 43 个和 54 个查询提供了密集的人类相关性标注。BEIR
    [[37](#bib.bib37)] 是一个异质基准，包含 18 个检索数据集，覆盖不同的检索任务和领域，设计用于零样本评估。
- en: We believe that the potential of LLM distillation for text ranking has not been
    fully exploited yet. Our contribution aims at bridging this gap by the methodological
    construction of a training dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信 LLM 蒸馏在文本排名中的潜力尚未被充分利用。我们的贡献旨在通过方法论的构建一个训练数据集来弥合这一差距。
- en: 3 Approach
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 'Our reranking model is based on Flan-T5 [[5](#bib.bib5)], which is a text-to-text
    model developed as an instructed version of T5 [[33](#bib.bib33)]. For our task,
    we use the following input template:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的重排模型基于 Flan-T5 [[5](#bib.bib5)]，它是作为 T5 [[33](#bib.bib33)] 的指令版本开发的文本到文本模型。对于我们的任务，我们使用以下输入模板：
- en: 'Query: [$Q$] Relevant:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 查询：[$Q$] 相关：
- en: where [$Q$] are the query and document texts, respectively, similar to the one
    adopted in monoT5 [[28](#bib.bib28), [35](#bib.bib35)].
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 [$Q$] 分别是查询和文档文本，类似于 monoT5 [[28](#bib.bib28), [35](#bib.bib35)] 采用的。
- en: 3.1 Scoring Strategy
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 评分策略
- en: Flan-T5 can be straightforwardly applied to various tasks due to its text-to-text
    nature, such as summarization, translation, and classification. However, adapting
    to the ranking task is not trivial, because for each query-document pair, we usually
    ask models to answer with a score representing the degree of relevance. The state-of-the-art
    rerankers, monoT5 [[28](#bib.bib28), [35](#bib.bib35)] and RankT5 [[44](#bib.bib44)],
    which are specialized text-to-text models, suffer from this limitation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Flan-T5 由于其文本到文本的性质，可以直接应用于各种任务，如摘要、翻译和分类。然而，适应排名任务并非易事，因为对于每个查询-文档对，我们通常要求模型回答一个表示相关程度的分数。最先进的重排模型，monoT5
    [[28](#bib.bib28), [35](#bib.bib35)] 和 RankT5 [[44](#bib.bib44)]，这些专门的文本到文本模型存在这一限制。
- en: 'MonoT5 finetunes T5 on a binary classification task: given a query-document
    pair, the model is optimized to produce the words ‘true’ if the document is relevant
    to the query and ‘false’ otherwise. At inference time, the ranking score is obtained
    from the logits of the ‘true’ and ‘false’ tokens as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: MonoT5 对 T5 进行微调，以执行二分类任务：给定一个查询-文档对，该模型被优化为在文档与查询相关时输出“true”，否则输出“false”。在推理时，排名分数从“true”和“false”标记的
    logits 中获得，如下所示：
- en: '|  | $\displaystyle s=\frac{e^{z_{\texttt{true}}}}{e^{z_{\texttt{true}}}+e^{z_{\texttt{false}}}}$
    |  | (1) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle s=\frac{e^{z_{\texttt{true}}}}{e^{z_{\texttt{true}}}+e^{z_{\texttt{false}}}}$
    |  | (1) |'
- en: where $z_{\tt true},z_{\tt false}$ are the logits of ‘true’ and ‘false’, respectively.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $z_{\tt true},z_{\tt false}$ 分别是“true”和“false”的 logits。
- en: RankT5 directly learns to rank by optimizing a ranking-based loss function.
    This family of loss functions requires the model to directly output the ranking
    score for each query-document pair at training time, so that the unnormalized
    logit of a special unused token (‘extra_id_10’) in the vocabulary is used as ranking
    score.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: RankT5 通过优化基于排名的损失函数直接学习排名。这类损失函数要求模型在训练时直接输出每个查询-文档对的排名分数，因此在词汇表中一个特殊的未使用标记（‘extra_id_10’）的未归一化
    logit 被用作排名分数。
- en: 'On one hand, monoT5 is not directly finetuned as a ranking model, which may
    not optimize its ranking performance. On the other hand, RankT5 does not exploit
    the learned representation in the language modeling head. To overcome both limitations,
    we propose a new approach. Our idea consists of using the difference between the
    unnormalized logits corresponding to the ‘true’ and ‘false’ tokens. In this way,
    the model is able to output a score directly at training time, and since it is
    optimized on top of the learned representations of the two tokens, we can make
    full use of the knowledge from the PLMs. An illustration of these scoring strategies
    is shown in Fig. [1](#S3.F1 "Figure 1 ‣ 3.1 Scoring Strategy ‣ 3 Approach ‣ TWOLAR:
    a TWO-step LLM-Augmented distillation method for passage Reranking").'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '一方面，monoT5没有直接进行排名模型的微调，这可能无法优化其排名性能。另一方面，RankT5没有利用语言建模头中的学习表示。为克服这两个限制，我们提出了一种新方法。我们的想法是利用对应于“真实”和“虚假”标记的未归一化logits之间的差异。这样，模型可以在训练时直接输出一个分数，并且由于它在两个标记的学习表示上进行优化，我们可以充分利用PLMs的知识。这些评分策略的示意图见图[1](#S3.F1
    "Figure 1 ‣ 3.1 Scoring Strategy ‣ 3 Approach ‣ TWOLAR: a TWO-step LLM-Augmented
    distillation method for passage Reranking")。'
- en: '![Refer to caption](img/115cef0851189c211a38ba06800c4c9a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/115cef0851189c211a38ba06800c4c9a.png)'
- en: 'Figure 1: Illustration of the score strategies from monoT5, RankT5 and our
    proposed approach.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：monoT5、RankT5和我们提出的方法的评分策略示意图。
- en: Accordingly, we adopt the RankNet loss [[4](#bib.bib4)], a pairwise loss function
    that models the probability of one document being more relevant than another given
    a query. RankNet loss has shown compelling results in information retrieval [[44](#bib.bib44),
    [36](#bib.bib36)] and provided a solid foundation for our optimization process.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们采用了RankNet损失[[4](#bib.bib4)]，这是一个对偶损失函数，用于建模在给定查询的情况下一个文档比另一个文档更相关的概率。RankNet损失在信息检索[[44](#bib.bib44),
    [36](#bib.bib36)]中显示了令人信服的结果，并为我们的优化过程提供了坚实的基础。
- en: Given a query $q$.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个查询$q$。
- en: 'Therefore, we optimize our model with the following loss function measuring
    the correctness of relative passage orders:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用以下损失函数来优化我们的模型，以衡量相对段落顺序的正确性：
- en: '|  | $1$2 |  | (2) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (2) |'
- en: It should be noted that the adoption of different ranking loss functions could
    potentially lead to alternative outcomes, but exploring their potential differences
    is not the main purpose of this paper. Thus, we utilize the RankNet Loss here
    and leave the comparison of different ranking loss functions as future work.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 应当注意的是，采用不同的排序损失函数可能会导致不同的结果，但探索它们潜在的差异并不是本文的主要目的。因此，我们在此使用RankNet损失，并将不同排序损失函数的比较留作未来工作。
- en: 3.2 Distillation strategy
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 蒸馏策略
- en: Our distillation strategy aims to capture the reranking capability of LLMs,
    in our case ChatGPT, through constructing a query-document dataset. The core design
    principle is the synthesis of suitable artificial queries by query augmentation,
    and the subsequent use of multiple retrieval models and stages of distillation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的蒸馏策略旨在通过构建查询-文档数据集来捕捉LLMs的重排序能力，在我们的案例中是ChatGPT。核心设计原则是通过查询增强合成适当的人工查询，随后使用多个检索模型和蒸馏阶段。
- en: Query Augmentation.
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查询增强。
- en: 'Our query augmentation method is inspired by DRAGON [[21](#bib.bib21)], whereby
    two approaches are combined to amplify the size of training queries from a given
    corpus: sentence cropping and pseudo query generation. The former can readily
    scale up the size of query sets without any computationally expensive operation.
    The latter generates high-quality human-like queries using LLMs. The combination
    of the two strategies increases the diversity of the dataset and accordingly the
    challenge and complexity of the task.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的查询增强方法受到DRAGON[[21](#bib.bib21)]的启发，其中结合了两种方法来放大来自给定语料库的训练查询的规模：句子裁剪和伪查询生成。前者可以在没有任何计算开销的操作下轻松扩大查询集的规模。后者使用LLMs生成高质量的人类般的查询。这两种策略的结合增加了数据集的多样性，从而提高了任务的挑战性和复杂性。
- en: Following DRAGON, we randomly sampled 10K queries from DRAGON’s collection of
    cropped sentences, drawn from the MS MARCO corpus [[26](#bib.bib26)]. Simultaneously,
    we sampled an additional 10K queries from the query pool created by docT5query [[29](#bib.bib29)],
    a specialized T5 model that generates queries based on a given passage.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 继DRAGON的做法，我们从DRAGON的裁剪句子集合中随机抽取了10K个查询，这些句子来源于MS MARCO语料库[[26](#bib.bib26)]。同时，我们还从docT5query[[29](#bib.bib29)]创建的查询池中抽取了另外10K个查询，docT5query是一个基于给定段落生成查询的专业T5模型。
- en: '![Refer to caption](img/1064abe4bb8ba06d9876fa37ebea3714.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/1064abe4bb8ba06d9876fa37ebea3714.png)'
- en: 'Figure 2: Illustration of the method used to build the dataset.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：构建数据集的方法示意图。
- en: 'First-stage distillation: retrieval.'
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第一阶段蒸馏：检索。
- en: 'The initial phase of our distillation process (see Fig. [2](#S3.F2 "Figure
    2 ‣ Query Augmentation. ‣ 3.2 Distillation strategy ‣ 3 Approach ‣ TWOLAR: a TWO-step
    LLM-Augmented distillation method for passage Reranking")) involves splitting
    each of the two sets of 10K queries, one set composed of cropped sentences and
    another set composed of docT5query-generated queries, into four subsets of 2.5K
    queries each. To retrieve documents for these queries, we chose four distinct
    retrieval models:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的蒸馏过程的初始阶段（见图 [2](#S3.F2 "图 2 ‣ 查询增强 ‣ 3.2 蒸馏策略 ‣ 3 方法 ‣ TWOLAR: 一种两步 LLM
    增强的段落重排蒸馏方法")）涉及将每一组 10K 查询分成两组，一组由裁剪句子组成，另一组由 docT5query 生成的查询组成，每组分为四个子集，每个子集包含
    2.5K 查询。为了检索这些查询的文档，我们选择了四种不同的检索模型：'
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'BM25 [[34](#bib.bib34)]: A state-of-the-art bag-of-words approach that relies
    primarily on word overlap to match documents to queries. Consequently, its hard
    negatives are expected to challenge the language model on lexical-level matches.'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BM25 [[34](#bib.bib34)]：一种最先进的词袋模型，主要依靠词重叠来匹配文档和查询。因此，它的硬负样本预计将挑战语言模型在词汇级别上的匹配。
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'DRAGON [[21](#bib.bib21)]: A dense retrieval model designed to detect semantic
    similarity between queries and passages. It pushes the language model towards
    understanding deeper semantic relations and contexts. We have chosen the DRAGON+
    version.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DRAGON [[21](#bib.bib21)]：一种密集检索模型，旨在检测查询和段落之间的语义相似性。它推动语言模型理解更深层次的语义关系和背景。我们选择了
    DRAGON+ 版本。
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'SPLADE [[12](#bib.bib12), [11](#bib.bib11), [10](#bib.bib10)]: It serves as
    a kind of midpoint between BM25’s focus on word overlap and DRAGON’s emphasis
    on semantic similarity. It introduces a different level of complexity by considering
    interactions between the tokens of the document or query and all the tokens from
    the vocabulary. We have chosen the SPLADE++ version.'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SPLADE [[12](#bib.bib12), [11](#bib.bib11), [10](#bib.bib10)]：它作为 BM25 关注词重叠和
    DRAGON 强调语义相似性之间的一种中间点。它通过考虑文档或查询中的标记与词汇表中的所有标记之间的交互，引入了不同的复杂度。我们选择了 SPLADE++
    版本。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'monoT5 [[28](#bib.bib28), [35](#bib.bib35)]: A combination of BM25 and monoT5
    where the top-100 documents retrieved by BM25 are re-ranked using monoT5\. It
    introduces negatives that are influenced by the ranking capabilities of a cross-encoder.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: monoT5 [[28](#bib.bib28), [35](#bib.bib35)]：BM25 和 monoT5 的结合，其中 BM25 检索的前 100
    个文档使用 monoT5 进行重新排名。它引入了受交叉编码器排名能力影响的负样本。
- en: In all cases, we retrieve the top 30 documents for each query.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，我们为每个查询检索前 30 个文档。
- en: This methodology is designed to provide high-quality results and to diversify
    the types of challenges and contexts presented to ChatGPT in the subsequent distillation
    stage.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法旨在提供高质量的结果，并在后续的蒸馏阶段多样化呈现给 ChatGPT 的挑战和背景类型。
- en: 'Table [1](#S3.T1 "Table 1 ‣ First-stage distillation: retrieval. ‣ 3.2 Distillation
    strategy ‣ 3 Approach ‣ TWOLAR: a TWO-step LLM-Augmented distillation method for
    passage Reranking") gives a quantitative account of the diversity of the documents
    retrieved by the four distinct models by computing the intersection rate between
    the sets of documents obtained from any two sources of supervision.²²2The average
    intersection rates were then calculated to provide a comprehensive view of the
    overall overlap among the retrieved documents from all sources: $\displaystyle\frac{1}{|\mathcal{Q}|}\sum_{q\in\mathcal{Q}}\frac{|S^{1}_{q}\cap
    S^{2}_{q}|}{N}$. This process was carried out separately for both types of queries:
    the cropped sentence queries and the docT5query-generated queries. The low mean
    intersection rates between different sources provide a clear evidence of the diversity
    among the retrieved document sets for both types of queries.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S3.T1 "表 1 ‣ 第一阶段蒸馏：检索 ‣ 3.2 蒸馏策略 ‣ 3 方法 ‣ TWOLAR: 一种两步 LLM 增强的段落重排蒸馏方法")
    通过计算来自任何两个监督来源的文档集之间的交集率，给出了四种不同模型检索文档的多样性定量说明。²²2 然后计算平均交集率，以提供对所有来源检索文档的整体重叠的全面视图：$\displaystyle\frac{1}{|\mathcal{Q}|}\sum_{q\in\mathcal{Q}}\frac{|S^{1}_{q}\cap
    S^{2}_{q}|}{N}$。该过程分别针对两种类型的查询进行：裁剪句子查询和 docT5query 生成的查询。不同来源之间的低平均交集率提供了检索文档集在两种查询类型下多样性的明确证据。'
- en: 'Table 1: Average intersection rate between each pair of sources. The upper
    triangular part of the table represents the intersection rate for cropped sentences
    and the lower triangular part represents the intersection rate for docT5query-generated
    queries.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：每对源之间的平均交集率。表格的上三角部分表示裁剪句子的交集率，下三角部分表示 docT5query 生成的查询的交集率。
- en: '| doct5query \ cropped sentence (%) | BM25 | SPLADE | DRAGON | monoT5 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| doct5query \ 裁剪句子 (%) | BM25 | SPLADE | DRAGON | monoT5 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| BM25 | \ | 20.0 | 29.0 | 49.8 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| BM25 | \ | 20.0 | 29.0 | 49.8 |'
- en: '| SPLADE | 17.8 | \ | 35.8 | 26.0 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| SPLADE | 17.8 | \ | 35.8 | 26.0 |'
- en: '| DRAGON | 25.0 | 41.0 | \ | 38.4 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| DRAGON | 25.0 | 41.0 | \ | 38.4 |'
- en: '| monoT5 | 46.4 | 27.2 | 38.5 | \ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| monoT5 | 46.4 | 27.2 | 38.5 | \ |'
- en: 'Second-stage distillation: reranking.'
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第二阶段蒸馏：重新排序。
- en: For reranking we used ChatGPT, in particular the checkpoint ‘gpt-3.5-turbo-16k-0613’.
    We prompted the model with the same prompt design proposed by RankGPT [[36](#bib.bib36)],
    including all the 30 documents per query to rerank in a single prompt.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于重新排序，我们使用了 ChatGPT，特别是检查点‘gpt-3.5-turbo-16k-0613’。我们使用 RankGPT [[36](#bib.bib36)]
    提出的相同提示设计，对每个查询的 30 个文档进行单次提示重新排序。
- en: We used the prompt made available by the RankGPT public repository. ³³3[https://github.com/sunnweiwei/RankGPT](https://github.com/sunnweiwei/RankGPT)
    We fed each of the 20K queries and their corresponding top 30 retrieved documents
    to ChatGPT, asking it to provide permutations of the indices of these documents,
    ordered according to their relevance to the associated query.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 RankGPT 公共库提供的提示。³³3[https://github.com/sunnweiwei/RankGPT](https://github.com/sunnweiwei/RankGPT)
    我们将每个 20K 查询及其对应的前 30 个检索到的文档输入 ChatGPT，要求它提供这些文档索引的排列，按照与相关查询的相关性排序。
- en: This approach requires significant computational resources due to the complexity
    of the task and the vast number of queries and documents involved. However, the
    total cost of this reranking operation using the ChatGPT API amounted to $212,
    demonstrating the feasible financial aspect of employing a large-scale language
    model in creating such a diverse and complex dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任务复杂性和涉及的大量查询及文档，此方法需要大量计算资源。然而，使用 ChatGPT API 进行重新排序的总成本为 $212，展示了在创建如此多样且复杂的数据集时使用大规模语言模型的可行财务方面。
- en: Train-Validation split.
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练-验证拆分。
- en: 'We divided the dataset into training and validation splits. We included 1,000
    queries in the validation set: 500 queries generated by docT5query and the rest
    extracted as cropped sentences. The remaining 19,000 samples were allocated to
    the training set.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据集分为训练集和验证集。验证集中包含 1,000 个查询：500 个由 docT5query 生成，其余作为裁剪句子提取。剩余的 19,000
    个样本分配给训练集。
- en: 4 Experimental setup
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验设置
- en: 4.1 Datasets
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据集
- en: 'We evaluate our approach using TREC-DL2019, TREC-DL2020 and BEIR for the zero-shot
    evaluation. All comparisons on TREC-DL2019 and TREC-DL2020 are based on the reranking
    of top-100 passages retrieved by BM25 [[34](#bib.bib34)] for each query. The evaluation
    on the BEIR benchmark is based on the reranking of the top-100 passages retrieved
    by three different retrievers: BM25, SPLADE++ [[11](#bib.bib11)], and DRAGON+ [[21](#bib.bib21)].
    The objective is to evaluate the adaptability of the rerankers to different retrievers.
    We also present the evaluation by reranking the top-1000 documents retrieved by
    BM25, to give a broad view of the performances in different settings.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 TREC-DL2019、TREC-DL2020 和 BEIR 对我们的方法进行评估。所有在 TREC-DL2019 和 TREC-DL2020
    上的比较都是基于 BM25 [[34](#bib.bib34)] 为每个查询检索的前 100 个段落的重新排序。在 BEIR 基准上的评估是基于对三种不同检索器：BM25、SPLADE++ [[11](#bib.bib11)]
    和 DRAGON+ [[21](#bib.bib21)] 检索的前 100 个段落的重新排序。目标是评估重新排序器对不同检索器的适应性。我们还通过对 BM25
    检索的前 1000 个文档进行重新排序，展示了在不同设置下的性能广度。
- en: 4.2 Training
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 训练
- en: We initialized our model with pretrained Flan-T5-xl checkpoint [[5](#bib.bib5)].
    We set the maximum input sequence length to 500 as monoT5\. The batch size is
    set to $32$.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用预训练的 Flan-T5-xl 检查点 [[5](#bib.bib5)] 初始化了我们的模型。我们将最大输入序列长度设置为 500，与 monoT5
    相同。批量大小设置为 $32$。
- en: 4.3 Baselines
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基准
- en: 'We evaluate our model on the TREC-DL2019 and TREC-DL2020 competitions against
    several baselines including three supervised methods: monoBERT [[27](#bib.bib27)],
    monoT5-3B [[28](#bib.bib28), [35](#bib.bib35)], RankT5 [[44](#bib.bib44)]; two
    zero-shot LLM-based methods: the listwise prompting based approach of RankGPT [[36](#bib.bib36)],
    using both gpt-3.5-turbo and gpt-4, and the sliding window approach performed
    only for 10 passes of PRP [[31](#bib.bib31)], using Flan-T5-xl (3B), Flan-T5-xxl
    (11B) and Flan-UL2 (20B); and a representative distilled model based on DeBERTav3
    proposed in [[36](#bib.bib36)] as the only other LLM distillation method other
    than ours. Regarding the zero-shot evaluation on the BEIR benchmark, we evaluate
    our models comparing with three different rerankers, including InParsV2 [[2](#bib.bib2),
    [16](#bib.bib16)], monoT5-3B [[28](#bib.bib28), [35](#bib.bib35)], and the distilled
    DeBERTav3 model proposed in [[36](#bib.bib36)].'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在TREC-DL2019和TREC-DL2020比赛中评估了我们的模型，比较了包括三种监督方法的几个基线：monoBERT [[27](#bib.bib27)]、monoT5-3B [[28](#bib.bib28),
    [35](#bib.bib35)]、RankT5 [[44](#bib.bib44)]; 两种零样本LLM方法：基于RankGPT [[36](#bib.bib36)]的列表提示方法，使用了gpt-3.5-turbo和gpt-4，以及仅对10次PRP [[31](#bib.bib31)]执行的滑动窗口方法，使用了Flan-T5-xl
    (3B)、Flan-T5-xxl (11B)和Flan-UL2 (20B); 以及基于DeBERTav3的代表性蒸馏模型，提出于 [[36](#bib.bib36)]，作为除我们之外唯一的LLM蒸馏方法。关于BEIR基准的零样本评估，我们将我们的模型与三种不同的重排器进行了比较，包括InParsV2 [[2](#bib.bib2),
    [16](#bib.bib16)]、monoT5-3B [[28](#bib.bib28), [35](#bib.bib35)]和提出于 [[36](#bib.bib36)]的蒸馏DeBERTav3模型。
- en: 4.4 Results
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 结果
- en: 'Our results on the TREC-DL2019 and TREC-DL2020 benchmarks are summarized in
    Table [2](#S4.T2 "Table 2 ‣ 4.4 Results ‣ 4 Experimental setup ‣ TWOLAR: a TWO-step
    LLM-Augmented distillation method for passage Reranking"). Tables [3](#S4.T3 "Table
    3 ‣ 4.4 Results ‣ 4 Experimental setup ‣ TWOLAR: a TWO-step LLM-Augmented distillation
    method for passage Reranking") and [4](#S4.T4 "Table 4 ‣ 4.4 Results ‣ 4 Experimental
    setup ‣ TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking")
    instead summarize respectively the results on the BEIR benchmark by reranking
    the top-100 and the top-1000 documents.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在TREC-DL2019和TREC-DL2020基准上的结果总结见表[2](#S4.T2 "Table 2 ‣ 4.4 Results ‣ 4 Experimental
    setup ‣ TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking")。表[3](#S4.T3
    "Table 3 ‣ 4.4 Results ‣ 4 Experimental setup ‣ TWOLAR: a TWO-step LLM-Augmented
    distillation method for passage Reranking")和[4](#S4.T4 "Table 4 ‣ 4.4 Results
    ‣ 4 Experimental setup ‣ TWOLAR: a TWO-step LLM-Augmented distillation method
    for passage Reranking")分别总结了通过重排前100个和前1000个文档的BEIR基准上的结果。'
- en: 'Table 2: Results on TREC-DL2019 and TREC-DL2020 datasets by reranking top 100
    documents retrieved by BM25\. The column titled ‘#Calls’ indicates the exact number
    of inference times of LLM when reranking the top 100 documents. The ‘Input Size’
    column uses the notation $|q|+n|d|$ documents. Best model is highlighted in boldface
    and the second best is underlined for each metric. All the reported results apart
    from the LLM distillation Methods are taken from the original papers.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：在TREC-DL2019和TREC-DL2020数据集上，通过重排BM25检索到的前100个文档的结果。标题为‘#Calls’的列表示重排前100个文档时LLM的推理次数。‘Input
    Size’列使用符号$|q|+n|d|$文档。每个指标中，最佳模型以粗体显示，第二好的模型下划线标记。除了LLM蒸馏方法，所有报告的结果均来自原始论文。
- en: '| Method | LLM | Size | #Calls | Input Size | TREC-DL2019 | TREC-DL2020 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | LLM | 大小 | #调用 | 输入大小 | TREC-DL2019 | TREC-DL2020 |'
- en: '|  | nDCG@1 | nDCG@5 | nDCG@10 | nDCG@1 | nDCG@5 | nDCG@10 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|  | nDCG@1 | nDCG@5 | nDCG@10 | nDCG@1 | nDCG@5 | nDCG@10 |'
- en: '| BM25 | - | - | - | - | 54.26 | 52.78 | 50.58 | 57.72 | 50.67 | 47.96 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| BM25 | - | - | - | - | 54.26 | 52.78 | 50.58 | 57.72 | 50.67 | 47.96 |'
- en: '| Supervised Methods |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 监督方法 |'
- en: '| monoBERT | BERT | 340M | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 79.07 | 73.25 | 70.50 | 78.70 | 70.74 | 67.28 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| monoBERT | BERT | 340M | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 79.07 | 73.25 | 70.50 | 78.70 | 70.74 | 67.28 |'
- en: '| monoT5 | T5-xl | 3B | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 79.07 | 73.74 | 71.83 | 80.25 | 72.32 | 68.89 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| monoT5 | T5-xl | 3B | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 79.07 | 73.74 | 71.83 | 80.25 | 72.32 | 68.89 |'
- en: '| RankT5 | T5-xl | 3B | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 77.38 | 73.94 | 71.22 | \ul80.86 | 72.99 | 69.49 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| RankT5 | T5-xl | 3B | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 77.38 | 73.94 | 71.22 | \ul80.86 | 72.99 | 69.49 |'
- en: '| LLM distillation Methods |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| LLM蒸馏方法 |'
- en: '| RankGPT | DeBertaV2 | 184M | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 78.68 | 69.77 | 66.56 | 59.26 | 59.83 | 59.43 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| RankGPT | DeBertaV2 | 184M | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 78.68 | 69.77 | 66.56 | 59.26 | 59.83 | 59.43 |'
- en: '| TWOLAR-large | Flan-T5-large | 783M | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 79.84 | 75.94 | 72.82 | 79.94 | 71.35 | 67.61 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| TWOLAR-large | Flan-T5-large | 783M | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 79.84 | 75.94 | 72.82 | 79.94 | 71.35 | 67.61 |'
- en: '| TWOLAR-xl | Flan-T5-xl | 3B | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 78.29 | \ul76.71 | \ul73.51 | 80.25 | 73.73 | 70.84 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| TWOLAR-xl | Flan-T5-xl | 3B | 100 | $\leavevmode\nobreak\ &#124;q&#124;+&#124;d&#124;$
    | 78.29 | \ul76.71 | \ul73.51 | 80.25 | 73.73 | 70.84 |'
- en: '| Zero-shot LLM Methods |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 零样本 LLM 方法 |'
- en: '| RankGPT | gpt-3.5-turbo | 154B^∗ | 10 | $\leavevmode\nobreak\ &#124;q&#124;+20&#124;d&#124;$
    | \ul82.17 | 71.15 | 65.80 | 79.32 | 66.76 | 62.91 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| RankGPT | gpt-3.5-turbo | 154B^∗ | 10 | $\leavevmode\nobreak\ &#124;q&#124;+20&#124;d&#124;$
    | \ul82.17 | 71.15 | 65.80 | 79.32 | 66.76 | 62.91 |'
- en: '| RankGPT | gpt-4 | 1T^∗ | 2^† | $\leavevmode\nobreak\ &#124;q&#124;+20&#124;d&#124;$
    | 82.56 | 79.16 | 75.59 | 78.40 | \ul74.11 | \ul70.56 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| RankGPT | gpt-4 | 1T^∗ | 2^† | $\leavevmode\nobreak\ &#124;q&#124;+20&#124;d&#124;$
    | 82.56 | 79.16 | 75.59 | 78.40 | \ul74.11 | \ul70.56 |'
- en: '| PRP-Sliding-10 | Flan-T5-xl | 3B | 990 | $\leavevmode\nobreak\ &#124;q&#124;+2&#124;d&#124;$
    | 75.58 | 71.23 | 68.66 | 75.62 | 69.00 | 66.59 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| PRP-Sliding-10 | Flan-T5-xl | 3B | 990 | $\leavevmode\nobreak\ &#124;q&#124;+2&#124;d&#124;$
    | 75.58 | 71.23 | 68.66 | 75.62 | 69.00 | 66.59 |'
- en: '| PRP-Sliding-10 | Flan-T5-xxl | 11B | 990 | $\leavevmode\nobreak\ &#124;q&#124;+2&#124;d&#124;$
    | 64.73 | 69.49 | 67.00 | 75.00 | 70.76 | 67.35 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| PRP-Sliding-10 | Flan-T5-xxl | 11B | 990 | $\leavevmode\nobreak\ &#124;q&#124;+2&#124;d&#124;$
    | 64.73 | 69.49 | 67.00 | 75.00 | 70.76 | 67.35 |'
- en: '| PRP-Sliding-10 | Flan-UL2 | 20B | 990 | $\leavevmode\nobreak\ &#124;q&#124;+2&#124;d&#124;$
    | 78.29 | 75.49 | 72.65 | 85.80 | 75.35 | 70.46 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| PRP-Sliding-10 | Flan-UL2 | 20B | 990 | $\leavevmode\nobreak\ &#124;q&#124;+2&#124;d&#124;$
    | 78.29 | 75.49 | 72.65 | 85.80 | 75.35 | 70.46 |'
- en: '| ^∗ OpenAI has not publicly released the amount of parameters and the numbers
    are based on public estimates [[38](#bib.bib38)] [[1](#bib.bib1)]. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| ^∗ OpenAI 尚未公开参数的具体数量，数据基于公开估算 [[38](#bib.bib38)] [[1](#bib.bib1)]。 |'
- en: '| ^† In [[36](#bib.bib36)], gpt-4 reranks the top-30 passages reranked by gpt-3.5-turbo.
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| ^† 在 [[36](#bib.bib36)] 中，gpt-4 重新排序了由 gpt-3.5-turbo 重新排序的前 30 个段落。 |'
- en: 'Table 3: Results on the BEIR Benchmark by reranking the top 100 documents with
    different retrievers. Best model is in boldface and second best is underlined
    for each dataset. Evaluation for InPars on CQADupStack is missing due to its unavailability
    on the Hugging Face hub. We computed statistical tests comparing our biggest model
    against the baselines. The results revealed no significant difference compared
    to InPars $(p=0.477)$. It’s noteworthy that while our model operates in a zero-shot
    manner, the InPars models have been fine-tuned for each BEIR dataset.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：通过重新排序前 100 个文档在 BEIR 基准测试上的结果，使用不同的检索器。每个数据集中的最佳模型用粗体显示，第二佳模型下划线标记。由于 InPars
    在 Hugging Face hub 上不可用，CQADupStack 上的评估缺失。我们进行了统计测试，将我们最大的模型与基线进行了比较。结果显示与 InPars
    相比没有显著差异 $(p=0.477)$。值得注意的是，虽然我们的模型以零样本方式运行，但 InPars 模型已针对每个 BEIR 数据集进行了微调。
- en: '| Retriever | BM25 | SPLADE | DRAGON |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 检索器 | BM25 | SPLADE | DRAGON |'
- en: '|  Reranker  | - |  MonoT5-3B  |  InPars  |  RankGPT-Deberta  |  TWOLAR-xl  |  TWOLAR-large  |
    - |  MonoT5-3B  |  InPars  |  RankGPT-Deberta  |  TWOLAR-xl  |  TWOLAR-large  |
    - |  MonoT5-3B  |  InPars  |  RankGPT-Deberta  |  TWOLAR-xl  |  TWOLAR-large  |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  重新排序器  | - |  MonoT5-3B  |  InPars  |  RankGPT-Deberta  |  TWOLAR-xl  |  TWOLAR-large  |
    - |  MonoT5-3B  |  InPars  |  RankGPT-Deberta  |  TWOLAR-xl  |  TWOLAR-large  |
    - |  MonoT5-3B  |  InPars  |  RankGPT-Deberta  |  TWOLAR-xl  |  TWOLAR-large  |'
- en: '| nDCG@10 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| nDCG@10 |'
- en: '| TREC-COVID | 59.5 | 79.8 | 82.5 | 79.4 | 82.7 | 84.3 | 72.8 | 82.9 | 85.7
    | 80.1 | 85.2 | 86.9 | 75.8 | 82.8 | 84.8 | 82.6 | 84.6 | \ul86.8 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| TREC-COVID | 59.5 | 79.8 | 82.5 | 79.4 | 82.7 | 84.3 | 72.8 | 82.9 | 85.7
    | 80.1 | 85.2 | 86.9 | 75.8 | 82.8 | 84.8 | 82.6 | 84.6 | \ul86.8 |'
- en: '| NFCorpus | 32.2 | 37.4 | 35.0 | 33.3 | 36.6 | 35.7 | 34.8 | 39.2 | 38.8 |
    33.2 | 37.3 | 35.5 | 33.9 | 39.7 | \ul39.3 | 33.2 | 37.9 | 35.7 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| NFCorpus | 32.2 | 37.4 | 35.0 | 33.3 | 36.6 | 35.7 | 34.8 | 39.2 | 38.8 |
    33.2 | 37.3 | 35.5 | 33.9 | 39.7 | \ul39.3 | 33.2 | 37.9 | 35.7 |'
- en: '| FiQA-2018 | 23.6 | 46.1 | 46.2 | 32.7 | 41.9 | 41.1 | 34.8 | 50.0 | 50.0
    | 33.7 | 44.8 | 43.8 | 35.7 | 51.2 | \ul50.9 | 43.1 | 45.3 | 44.8 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| FiQA-2018 | 23.6 | 46.1 | 46.2 | 32.7 | 41.9 | 41.1 | 34.8 | 50.0 | 50.0
    | 33.7 | 44.8 | 43.8 | 35.7 | 51.2 | \ul50.9 | 43.1 | 45.3 | 44.8 |'
- en: '| ArguAna | 30.0 | 33.4 | 32.8 | 21.1 | 32.9 | 34.7 | 38.8 | 31.7 | 31.2 |
    18.6 | 32.9 | 34.6 | 46.9 | 41.5 | 40.9 | 25.7 | 42.8 | \ul45.5 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| ArguAna | 30.0 | 33.4 | 32.8 | 21.1 | 32.9 | 34.7 | 38.8 | 31.7 | 31.2 |
    18.6 | 32.9 | 34.6 | 46.9 | 41.5 | 40.9 | 25.7 | 42.8 | \ul45.5 |'
- en: '| Tóuche-2020 | 44.2 | 31.6 | 29.6 | 37.7 | 37.1 | 33.4 | 24.6 | 29.8 | 28.7
    | 36.4 | 35.2 | 30.4 | 26.3 | 30.6 | 29.4 | \ul38.2 | 36.0 | 31.5 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Tóuche-2020 | 44.2 | 31.6 | 29.6 | 37.7 | 37.1 | 33.4 | 24.6 | 29.8 | 28.7
    | 36.4 | 35.2 | 30.4 | 26.3 | 30.6 | 29.4 | \ul38.2 | 36.0 | 31.5 |'
- en: '| Quora | 78.9 | 84.1 | 84.8 | 78.8 | 87.2 | 86.0 | 83.5 | 84.3 | 85.1 | 80.3
    | \ul87.4 | 86.0 | 87.5 | 83.5 | 84.4 | 78.7 | 87.2 | 85.7 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Quora | 78.9 | 84.1 | 84.8 | 78.8 | 87.2 | 86.0 | 83.5 | 84.3 | 85.1 | 80.3
    | \ul87.4 | 86.0 | 87.5 | 83.5 | 84.4 | 78.7 | 87.2 | 85.7 |'
- en: '| SCIDOCS | 14.9 | 19.0 | 19.2 | 16.1 | 19.5 | 18.3 | 15.9 | 19.9 | 20.9 |
    16.4 | 20.2 | 18.8 | 15.9 | 19.8 | \ul20.7 | 16.4 | 20.2 | 18.8 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| SCIDOCS | 14.9 | 19.0 | 19.2 | 16.1 | 19.5 | 18.3 | 15.9 | 19.9 | 20.9 |
    16.4 | 20.2 | 18.8 | 15.9 | 19.8 | \ul20.7 | 16.4 | 20.2 | 18.8 |'
- en: '| SciFact | 67.9 | \ul76.4 | 73.5 | 70.5 | 76.5 | 75.6 | 70.2 | \ul76.4 | 76.0
    | 69.1 | 75.6 | 74.7 | 67.8 | 76.0 | 75.7 | 69.4 | 75.6 | 74.7 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| SciFact | 67.9 | \ul76.4 | 73.5 | 70.5 | 76.5 | 75.6 | 70.2 | \ul76.4 | 76.0
    | 69.1 | 75.6 | 74.7 | 67.8 | 76.0 | 75.7 | 69.4 | 75.6 | 74.7 |'
- en: '| NQ | 30.6 | 56.8 | 57.8 | 46.1 | 58.0 | 57.7 | 53.7 | 65.9 | 66.4 | 50.6
    | \ul66.8 | 65.8 | 53.8 | 65.1 | 66.6 | 50.6 | 66.9 | 66.2 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| NQ | 30.6 | 56.8 | 57.8 | 46.1 | 58.0 | 57.7 | 53.7 | 65.9 | 66.4 | 50.6
    | \ul66.8 | 65.8 | 53.8 | 65.1 | 66.6 | 50.6 | 66.9 | 66.2 |'
- en: '| HotpotQA | 63.3 | 74.2 | 76.5 | 69.9 | 76.7 | 75.9 | 68.7 | 74.1 | \ul77.1
    | 70.5 | 77.7 | 76.4 | 66.2 | 72.9 | 75.7 | 69.8 | 76.4 | 75.3 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| HotpotQA | 63.3 | 74.2 | 76.5 | 69.9 | 76.7 | 75.9 | 68.7 | 74.1 | \ul77.1
    | 70.5 | 77.7 | 76.4 | 66.2 | 72.9 | 75.7 | 69.8 | 76.4 | 75.3 |'
- en: '| DBPedia | 31.8 | 44.8 | 44.0 | 41.9 | 48.0 | 47.8 | 43.6 | 48.2 | 51.1 |
    45.9 | 52.9 | 51.6 | 41.9 | 47.2 | 50.3 | 44.9 | \ul52.1 | 51.3 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| DBPedia | 31.8 | 44.8 | 44.0 | 41.9 | 48.0 | 47.8 | 43.6 | 48.2 | 51.1 |
    45.9 | 52.9 | 51.6 | 41.9 | 47.2 | 50.3 | 44.9 | \ul52.1 | 51.3 |'
- en: '| FEVER | 65.1 | 83.2 | 85.5 | 80.2 | 84.9 | 83.4 | 79.3 | 85.0 | 88.0 | 81.8
    | \ul87.5 | 85.4 | 78.0 | 84.7 | 87.7 | 81.7 | 87.2 | 85.2 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| FEVER | 65.1 | 83.2 | 85.5 | 80.2 | 84.9 | 83.4 | 79.3 | 85.0 | 88.0 | 81.8
    | \ul87.5 | 85.4 | 78.0 | 84.7 | 87.7 | 81.7 | 87.2 | 85.2 |'
- en: '| Climate-FEVER | 16.5 | 27.4 | 30.1 | 24.2 | 26.9 | 26.1 | 22.9 | 28.7 | 32.8
    | 25.9 | 28.9 | 27.9 | 22.7 | 28.6 | \ul32.5 | 25.9 | 28.6 | 27.4 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Climate-FEVER | 16.5 | 27.4 | 30.1 | 24.2 | 26.9 | 26.1 | 22.9 | 28.7 | 32.8
    | 25.9 | 28.9 | 27.9 | 22.7 | 28.6 | \ul32.5 | 25.9 | 28.6 | 27.4 |'
- en: '| CQADupStack | 30.2 | 41.5 | - | 34.7 | 41.2 | 40.6 | 33.4 | 43.7 | - | 35.9
    | 43.6 | 42.7 | 35.4 | 44.4 | - | 36.0 | \ul44.2 | 43.4 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| CQADupStack | 30.2 | 41.5 | - | 34.7 | 41.2 | 40.6 | 33.4 | 43.7 | - | 35.9
    | 43.6 | 42.7 | 35.4 | 44.4 | - | 36.0 | \ul44.2 | 43.4 |'
- en: '| Robust04 | 40.8 | 56.6 | 58.7 | 52.8 | 57.9 | 58.3 | 46.7 | 62.1 | 64.3 |
    57.3 | 64.9 | 65.2 | 48.1 | 61.3 | \ul63.2 | 56.6 | 63.4 | 63.7 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Robust04 | 40.8 | 56.6 | 58.7 | 52.8 | 57.9 | 58.3 | 46.7 | 62.1 | 64.3 |
    57.3 | 64.9 | 65.2 | 48.1 | 61.3 | \ul63.2 | 56.6 | 63.4 | 63.7 |'
- en: '| Signal-1M | 33.1 | 32.2 | 32.9 | \ul33.4 | 33.8 | 33.9 | 30.0 | 29.4 | 30.3
    | 30.0 | 30.1 | 30.5 | 30.0 | 29.7 | 30.4 | 29.4 | 30.2 | 30.1 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Signal-1M | 33.1 | 32.2 | 32.9 | \ul33.4 | 33.8 | 33.9 | 30.0 | 29.4 | 30.3
    | 30.0 | 30.1 | 30.5 | 30.0 | 29.7 | 30.4 | 29.4 | 30.2 | 30.1 |'
- en: '| BioASQ | 52.3 | \ul57.2 | 59.8 | 53.0 | 56.2 | 56.0 | 49.7 | 54.1 | 57.2
    | 49.5 | 54.6 | 53.8 | 43.4 | 51.9 | 54.4 | 48.0 | 51.9 | 50.8 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| BioASQ | 52.3 | \ul57.2 | 59.8 | 53.0 | 56.2 | 56.0 | 49.7 | 54.1 | 57.2
    | 49.5 | 54.6 | 53.8 | 43.4 | 51.9 | 54.4 | 48.0 | 51.9 | 50.8 |'
- en: '| TREC-NEWS | 39.5 | 48.5 | 49.8 | 51.8 | 52.7 | 50.8 | 41.5 | 50.0 | 50.9
    | \ul53.4 | 53.3 | 50.7 | 44.4 | 49.5 | 50.8 | 52.1 | 53.8 | 50.0 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| TREC-NEWS | 39.5 | 48.5 | 49.8 | 51.8 | 52.7 | 50.8 | 41.5 | 50.0 | 50.9
    | \ul53.4 | 53.3 | 50.7 | 44.4 | 49.5 | 50.8 | 52.1 | 53.8 | 50.0 |'
- en: '| avg nDCG@10 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 平均 nDCG@10 |'
- en: '| BEIR 18 | 41.9 | 51.7 | - | 47.6 | 52.8 | 52.2 | 46.9 | 53.0 | - | 48.3 |
    \ul54.4 | 53.4 | 47.4 | 53.4 | - | 48.5 | 54.7 | 53.7 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| BEIR 18 | 41.9 | 51.7 | - | 47.6 | 52.8 | 52.2 | 46.9 | 53.0 | - | 48.3 |
    \ul54.4 | 53.4 | 47.4 | 53.4 | - | 48.5 | 54.7 | 53.7 |'
- en: '| BEIR 17 | 42.6 | 52.3 | 52.9 | 48.4 | 53.5 | 52.9 | 47.8 | 53.5 | 55.0 |
    49.0 | 55.0 | 54.0 | 48.1 | 53.9 | \ul55.2 | 49.2 | 55.3 | 54.3 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| BEIR 17 | 42.6 | 52.3 | 52.9 | 48.4 | 53.5 | 52.9 | 47.8 | 53.5 | 55.0 |
    49.0 | 55.0 | 54.0 | 48.1 | 53.9 | \ul55.2 | 49.2 | 55.3 | 54.3 |'
- en: 'Table 4: Results on the BEIR Benchmark by reranking the top 1000 BM25 retrieved
    documents. The best model is highlighted in boldface, and the second best is underlined
    for each dataset. All results, apart from TWOLAR-xl, are from [[16](#bib.bib16)].'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：通过重新排序前 1000 个 BM25 检索的文档在 BEIR 基准上的结果。每个数据集的最佳模型以**粗体**显示，第二最佳模型用*下划线*标记。除
    TWOLAR-xl 外的所有结果均来自 [[16](#bib.bib16)]。
- en: '|  | BM25 | monoT5-3B | InPars-v2 | RankT5 | TWOLAR-xl |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | BM25 | monoT5-3B | InPars-v2 | RankT5 | TWOLAR-xl |'
- en: '| nDCG@10 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| nDCG@10 |'
- en: '| TREC-COVID | 59.5 | 80.1 | 84.6 | 82.3 | \ul84.3 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| TREC-COVID | 59.5 | 80.1 | 84.6 | 82.3 | \ul84.3 |'
- en: '| NFCorpus | 32.2 | 38.3 | \ul38.5 | 39.9 | 37.3 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| NFCorpus | 32.2 | 38.3 | \ul38.5 | 39.9 | 37.3 |'
- en: '| FiQA-2018 | 23.6 | 50.9 | \ul50.9 | 49.3 | 45.2 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| FiQA-2018 | 23.6 | 50.9 | \ul50.9 | 49.3 | 45.2 |'
- en: '| ArguAna | 30.0 | \ul37.9 | 36.9 | 40.6 | 32.7 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| ArguAna | 30.0 | \ul37.9 | 36.9 | 40.6 | 32.7 |'
- en: '| Tóuche-2020 | \ul44.2 | 30.9 | 29.1 | 48.6 | 35.9 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Tóuche-2020 | \ul44.2 | 30.9 | 29.1 | 48.6 | 35.9 |'
- en: '| Quora | 78.9 | 83.5 | \ul84.5 | 81.9 | 87.3 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Quora | 78.9 | 83.5 | \ul84.5 | 81.9 | 87.3 |'
- en: '| SCIDOCS | 14.9 | 19.7 | 20.8 | 19.1 | \ul20.3 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| SCIDOCS | 14.9 | 19.7 | 20.8 | 19.1 | \ul20.3 |'
- en: '| SciFact | 67.9 | 77.4 | \ul77.4 | 76.0 | 76.8 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| SciFact | 67.9 | 77.4 | \ul77.4 | 76.0 | 76.8 |'
- en: '| NQ | 30.6 | 62.5 | 63.8 | 64.7 | \ul64.2 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| NQ | 30.6 | 62.5 | 63.8 | 64.7 | \ul64.2 |'
- en: '| HotpotQA | 63.3 | 76.0 | \ul79.1 | 75.3 | 79.5 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| HotpotQA | 63.3 | 76.0 | \ul79.1 | 75.3 | 79.5 |'
- en: '| DBPedia | 31.8 | 47.2 | \ul49.8 | 45.9 | 52.0 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| DBPedia | 31.8 | 47.2 | \ul49.8 | 45.9 | 52.0 |'
- en: '| FEVER | 65.1 | 84.8 | 87.2 | 84.8 | \ul86.7 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| FEVER | 65.1 | 84.8 | 87.2 | 84.8 | \ul86.7 |'
- en: '| Climate-FEVER | 16.5 | \ul28.8 | 32.3 | 27.5 | 27.8 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Climate-FEVER | 16.5 | \ul28.8 | 32.3 | 27.5 | 27.8 |'
- en: '| CQADupStack | 30.2 | 44.9 | \ul44.8 | - | 43.8 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| CQADupStack | 30.2 | 44.9 | \ul44.8 | - | 43.8 |'
- en: '| Robust04 | 40.8 | 61.5 | \ul63.2 | - | 64.2 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Robust04 | 40.8 | 61.5 | \ul63.2 | - | 64.2 |'
- en: '| Signal-1M | 33.1 | 30.2 | 30.8 | \ul31.9 | 31.5 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| Signal-1M | 33.1 | 30.2 | 30.8 | \ul31.9 | 31.5 |'
- en: '| BioASQ | 52.3 | 56.6 | 59.5 | \ul57.9 | 56.0 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| BioASQ | 52.3 | 56.6 | 59.5 | \ul57.9 | 56.0 |'
- en: '| TREC-NEWS | 39.5 | 47.7 | \ul49.0 | - | 53.2 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| TREC-NEWS | 39.5 | 47.7 | \ul49.0 | - | 53.2 |'
- en: '| avg nDCG@10 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| avg nDCG@10 |'
- en: '| BEIR 18 | 41.9 | 53.3 | 54.5 | - | \ul54.4 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| BEIR 18 | 41.9 | 53.3 | 54.5 | - | \ul54.4 |'
- en: '| BEIR 15 | 42.9 | 53.7 | \ul54.9 | 55.0 | 54.5 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| BEIR 15 | 42.9 | 53.7 | \ul54.9 | 55.0 | 54.5 |'
- en: 5 Discussion
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: In this section, We will delve into a comprehensive discussion of our experimental
    results, and in the following section, we will explore the ablation study in detail.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入讨论我们的实验结果，在接下来的章节中，我们将详细探讨消融研究。
- en: On TREC-DL.
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 TREC-DL 上。
- en: In our evaluation on TREC-DL2019 and TREC-DL2020, our model demonstrated outstanding
    performance, consistently outperforming established supervised methods and LLM-distilled
    baselines. When set against zero-shot LLM baselines, our model either matches
    or exceeds their performance. Although the results are not directly comparable
    because we are using a specific checkpoint, we find it remarkable that our model
    outperforms even the teacher LLM used for the distillation process, i.e. gpt-3.5-turbo.
    We take it as an indication that our distillation strategy is well conceived.
    The sole model that distinctly outperformed ours was gpt-4. This performance difference
    suggests that leveraging a more advanced LLM for distillation within our methodology
    might lead to even superior outcomes. Importantly, this is achieved with significantly
    reduced computational overhead during inference since we distilled LLMs to obtain
    a much smaller task-specific model. It is worthwhile noticing the difference in
    size between the models used for comparison with TWOLAR. Remarkably the largest
    of the TWOLAR models is several orders of magnitude smaller than the largest RankGPT
    model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对 TREC-DL2019 和 TREC-DL2020 的评估中，我们的模型表现出色，一直优于已建立的监督方法和 LLM 蒸馏基准。在与零样本 LLM
    基准比较时，我们的模型表现相当或优于它们。尽管由于我们使用的是特定的检查点，结果无法直接比较，但我们发现我们的模型甚至优于用于蒸馏过程的教师 LLM，即 gpt-3.5-turbo，这一点非常值得注意。这表明我们的蒸馏策略设计得非常好。唯一显著优于我们模型的是
    gpt-4。这一性能差异表明，利用更先进的 LLM 进行蒸馏可能会带来更出色的结果。重要的是，这在推理过程中实现了显著降低的计算开销，因为我们通过蒸馏 LLM
    获得了一个更小的任务特定模型。值得注意的是，与 TWOLAR 进行比较的模型之间的大小差异。值得一提的是，TWOLAR 模型中最大的一个比最大的 RankGPT
    模型小几个数量级。
- en: On BEIR Benchmark.
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 BEIR 基准测试上。
- en: 'In our evaluations using the BEIR benchmark, TWOLAR consistently outperformed
    most existing baselines when reranking the top-100 documents, as shown in Table
    [3](#S4.T3 "Table 3 ‣ 4.4 Results ‣ 4 Experimental setup ‣ TWOLAR: a TWO-step
    LLM-Augmented distillation method for passage Reranking"). This is particularly
    significant when compared with the approach of models such as InPars. InPars employs
    a strategy of fine-tuning a monot5-3B on generated, topic-specific data tailored
    for each of the 18 datasets within the BEIR benchmark. This strategy means that,
    for each dataset, their model has been exposed to data related to the topic in
    question. In contrast, TWOLAR has never been exposed to any topic-specific data,
    making it genuinely zero-shot when facing new topics and tasks. Furthermore, our
    method does not require fine-tuning for different applications and is thus more
    economical.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 BEIR 基准进行评估时，TWOLAR 在重新排序前 100 个文档时始终优于大多数现有基准，如表[3](#S4.T3 "表 3 ‣ 4.4 结果
    ‣ 4 实验设置 ‣ TWOLAR：一种两步 LLM 增强的蒸馏方法用于段落重新排序")所示。这一点在与如 InPars 等模型的方法进行比较时尤为显著。InPars
    采用了在生成的、针对 BEIR 基准中每个 18 个数据集的特定主题数据上微调 monot5-3B 的策略。这意味着，对于每个数据集，他们的模型都接触过与相关主题相关的数据。相比之下，TWOLAR
    从未接触过任何特定主题的数据，因此在面对新主题和任务时真正是零样本的。此外，我们的方法不需要针对不同应用进行微调，因此更加经济。
- en: It is worthwhile noticing the performance variations across different datasets
    within BEIR. In datasets with a specific focus, such as BioASQ, InPars tends to
    perform better due to its targeted fine-tuning on artificial topic-specific data.
    However, in datasets where queries are centered around general knowledge, like
    DBpedia entity, TWOLAR demonstrates a clear advantage over InPars. This highlights
    the robustness of TWOLAR’s topic-agnostic approach and its applicability in a
    broad range of scenarios.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是 BEIR 数据集中不同数据集间的性能差异。在特定领域的数据集如 BioASQ 中，由于针对人工主题特定数据进行的精准调优，InPars 的表现往往更好。然而，在查询围绕一般知识的数据集，如
    DBpedia 实体中，TWOLAR 显示出相对于 InPars 的明显优势。这突显了 TWOLAR 的主题无关方法的稳健性及其在广泛场景中的适用性。
- en: 'When reranking the top-1000 documents (Table [4](#S4.T4 "Table 4 ‣ 4.4 Results
    ‣ 4 Experimental setup ‣ TWOLAR: a TWO-step LLM-Augmented distillation method
    for passage Reranking")), our model did not perform as well as when reranking
    the top-100 documents. However, the difference with the best performing model
    on BEIR 18 is minor (54.4 vs 54.5) and TWOLAR-xl outperforms every competitor
    in 5 out of 18 tasks. A possible explanation for this result lies in our model’s
    training setup. Since our method optimizes for reranking a subset of 30 documents,
    it seems plausible that it can easily scale up to 100 documents, less easily to
    1000.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '在重新排序前 1000 个文档时（表 [4](#S4.T4 "表 4 ‣ 4.4 结果 ‣ 4 实验设置 ‣ TWOLAR: 一个两步的 LLM 增强蒸馏方法用于段落重新排序")），我们的模型的表现不如在重新排序前
    100 个文档时的表现。然而，与 BEIR 18 上表现最好的模型的差异很小（54.4 vs 54.5），而 TWOLAR-xl 在 18 个任务中的 5
    个任务中超过了所有竞争对手。对这一结果的一个可能解释在于我们的模型训练设置。由于我们的方法优化的是 30 个文档的重新排序，它似乎可以轻松扩展到 100 个文档，但扩展到
    1000 个文档则不那么容易。'
- en: 'Table 5: We perform ablation studies on the eight smallest datasets in BEIR
    benchmark. The reported scores are nDCG@10\. In comparing our scoring strategy
    against the RankT5 scoring strategy, the statistical tests yielded a p-value of
    $p=\text{0.268}$. *COV: TREC-COVID, SCI: SciFact, NFC: NFCorpus, TOU: Tóuche-2020,
    DBP: DBPedia, ROB: Robust04, SIG: Signal-1M, NEW: TREC-NEWS.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5：我们在 BEIR 基准的八个最小数据集上进行了消融研究。报告的分数为 nDCG@10。与 RankT5 分数策略比较时，统计测试的 p 值为
    $p=\text{0.268}$。*COV: TREC-COVID, SCI: SciFact, NFC: NFCorpus, TOU: Tóuche-2020,
    DBP: DBPedia, ROB: Robust04, SIG: Signal-1M, NEW: TREC-NEWS。'
- en: '|  | COV | SCI | NFC | TOU | DBP | ROB | SIG | NEW | avg |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | COV | SCI | NFC | TOU | DBP | ROB | SIG | NEW | 平均 |'
- en: '| Score Strategy | effectiveness of score strategy - 19K train samples |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 分数策略 | 分数策略的有效性 - 19K 训练样本 |'
- en: '| Difference | 74.0 | 67.9 | 31.9 | 35.7 | 38.8 | 47.4 | 32.5 | 43.7 | 46.5
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 差异 | 74.0 | 67.9 | 31.9 | 35.7 | 38.8 | 47.4 | 32.5 | 43.7 | 46.5 |'
- en: '| RankT5 | 74.1 | 69.2 | 31.5 | 32.2 | 36.2 | 47.0 | 34.1 | 41.2 | 45.7 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| RankT5 | 74.1 | 69.2 | 31.5 | 32.2 | 36.2 | 47.0 | 34.1 | 41.2 | 45.7 |'
- en: '| # documents | effectiveness of amount of documents - 19K train samples |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| # 文档 | 文档数量的有效性 - 19K 训练样本 |'
- en: '| 30 | 74.0 | 67.9 | 31.9 | 35.7 | 38.8 | 47.4 | 32.5 | 43.7 | 46.5 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 74.0 | 67.9 | 31.9 | 35.7 | 38.8 | 47.4 | 32.5 | 43.7 | 46.5 |'
- en: '| 20 | 73.0 | 69.8 | 32.5 | 31.7 | 37.9 | 47.5 | 31.9 | 40.8 | 46.3 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 73.0 | 69.8 | 32.5 | 31.7 | 37.9 | 47.5 | 31.9 | 40.8 | 46.3 |'
- en: '| 10 | 72.3 | 65.6 | 29.6 | 28.4 | 34.2 | 43.2 | 30.4 | 37.9 | 42.7 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 72.3 | 65.6 | 29.6 | 28.4 | 34.2 | 43.2 | 30.4 | 37.9 | 42.7 |'
- en: '| Not used source | effectiveness of first source of supervision - $\sim$14K
    train samples |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 未使用的来源 | 第一来源监督的有效性 - $\sim$14K 训练样本 |'
- en: '| - BM25 | 72.7 | 70.3 | 31.8 | 31.8 | 37.7 | 47.0 | 31.9 | 41.5 | 45.6 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| - BM25 | 72.7 | 70.3 | 31.8 | 31.8 | 37.7 | 47.0 | 31.9 | 41.5 | 45.6 |'
- en: '| - SPLADE | 73.9 | 70.9 | 33.6 | 32.7 | 38.6 | 48.8 | 32.4 | 42.5 | 46.3 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| - SPLADE | 73.9 | 70.9 | 33.6 | 32.7 | 38.6 | 48.8 | 32.4 | 42.5 | 46.3 |'
- en: '| - DRAGON | 74.0 | 67.7 | 32.9 | 33.9 | 37.6 | 47.7 | 33.1 | 43.2 | 46.2 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| - DRAGON | 74.0 | 67.7 | 32.9 | 33.9 | 37.6 | 47.7 | 33.1 | 43.2 | 46.2 |'
- en: '| - monoT5 | 73.9 | 69.4 | 31.8 | 33.0 | 36.3 | 46.6 | 32.5 | 43.6 | 45.9 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| - monoT5 | 73.9 | 69.4 | 31.8 | 33.0 | 36.3 | 46.6 | 32.5 | 43.6 | 45.9 |'
- en: '| Type of query | effectiveness of type of query - 9.5K train samples |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 查询类型 | 查询类型的有效性 - 9.5K 训练样本 |'
- en: '| Mixed | 75.5 | 67.3 | 30.4 | 34.0 | 37.2 | 46.2 | 31.8 | 41.6 | 45.5 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 混合 | 75.5 | 67.3 | 30.4 | 34.0 | 37.2 | 46.2 | 31.8 | 41.6 | 45.5 |'
- en: '| Sentence | 67.2 | 67.9 | 31.4 | 32.7 | 32.2 | 44.8 | 31.7 | 39.7 | 43.4 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 句子 | 67.2 | 67.9 | 31.4 | 32.7 | 32.2 | 44.8 | 31.7 | 39.7 | 43.4 |'
- en: '| docT5query | 74.6 | 59.4 | 31.2 | 33.4 | 37.8 | 44.9 | 28.1 | 44.0 | 44.2
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| docT5query | 74.6 | 59.4 | 31.2 | 33.4 | 37.8 | 44.9 | 28.1 | 44.0 | 44.2
    |'
- en: 5.1 Ablation study
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 消融研究
- en: We conducted an extensive ablation study in order to validate our design choices.
    Due to computational constraints, these experiments were performed using the smaller
    flan-t5-small checkpoint, with 77M parameters. Furthermore, we evaluated the models
    on reranking the top-100 documents retrieved by BM25 from a subset of 8 smallest
    datasets from the BEIR benchmark, including TREC-COVID, SciFact, NFCorpus, Tóuche-2020,
    DBPedia, Robust04, Signal-1M, and TREC-NEWS.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了广泛的消融研究，以验证我们的设计选择。由于计算限制，这些实验使用了较小的 flan-t5-small 检查点，具有 77M 参数。此外，我们在从
    BEIR 基准测试中的 8 个最小数据集子集（包括 TREC-COVID、SciFact、NFCorpus、Tóuche-2020、DBPedia、Robust04、Signal-1M
    和 TREC-NEWS）中检索的前 100 个文档上评估了模型的重新排序效果。
- en: 'The results are summarized in Table [5](#S5.T5 "Table 5 ‣ On BEIR Benchmark.
    ‣ 5 Discussion ‣ TWOLAR: a TWO-step LLM-Augmented distillation method for passage
    Reranking").'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '结果汇总在表格 [5](#S5.T5 "Table 5 ‣ On BEIR Benchmark. ‣ 5 Discussion ‣ TWOLAR: a
    TWO-step LLM-Augmented distillation method for passage Reranking") 中。'
- en: Scoring Strategy Effectiveness.
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评分策略的有效性。
- en: 'Our scoring strategy achieved an average nDCG@10 of 46.5, showing superior
    performance compared to 45.7 for the RankT5 scoring approach, which indicates
    the importance of properly exploiting the knowledge from the language modeling
    head of PLMs. We did not make a direct comparison with the softmax method used
    in monoT5, due to the inherent differences in the pipeline structure: while our
    method and the RankT5 method allow for direct finetuning of the model to rank
    documents, the monoT5 approach operates on a fundamentally different mechanism,
    making a direct comparative analysis less feasible and potentially misleading
    in evaluating the distinct methodologies.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评分策略达到了 46.5 的平均 nDCG@10，相较于 RankT5 评分方法的 45.7，表现更为优越，这表明了正确利用 PLMs 语言建模头知识的重要性。由于
    pipeline 结构的固有差异，我们没有与 monoT5 中使用的 softmax 方法进行直接比较：我们的和 RankT5 方法允许对模型进行直接微调以排序文档，而
    monoT5 方法在根本上操作于不同的机制，使得直接比较分析不够可行，并且在评估不同方法时可能具有误导性。
- en: Documents per training samples.
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 每个训练样本的文档数量。
- en: We trained models with varying numbers of documents per training sample. Our
    results suggest a clear advantage in using more than 10 documents per sample.
    The trade-off between 20 and 30 is less clear, with nDCG@10 scores of 46.3 and
    46.5 respectively, suggesting diminishing returns beyond 20 documents for the
    top-100 reranking task.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练了不同文档数量的模型。我们的结果表明，使用超过 10 个文档每个样本有明显的优势。20 和 30 之间的权衡不太明确，nDCG@10 的得分分别为
    46.3 和 46.5，表明在前 100 的重新排序任务中，超过 20 个文档的收益递减。
- en: Effectiveness of first source of supervision.
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第一种监督来源的有效性。
- en: We conducted four individual experiments by excluding each source of supervision
    (BM25, SPLADE, DRAGON, monoT5) from the training set and training the model on
    the residual data. This allowed us to evaluate the individual contribution of
    each retrieval strategy to the overall performance of the model.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过排除每个监督来源（BM25、SPLADE、DRAGON、monoT5）中的一个进行四个独立的实验，并在剩余数据上训练模型。这使我们能够评估每种检索策略对模型整体性能的单独贡献。
- en: Our results demonstrate that BM25, even being a traditional bag-of-words method,
    still plays a critical role in the model’s performance. This result may be also
    due to the fact that, following standard practice, during the test the top-100
    documents have been retrieved using BM25 itself. Conversely, when SPLADE and DRAGON
    were excluded during training, the performance drop was not substantial, which
    suggests that the main contribution comes from blending lexical and semantic models
    rather than including multiple and possibly equivalent semantic models.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果表明，尽管 BM25 是传统的词袋方法，但它在模型性能中仍然发挥着关键作用。这个结果也可能是由于在测试时，前 100 个文档是使用 BM25
    检索的。相反，当在训练中排除 SPLADE 和 DRAGON 时，性能下降并不显著，这表明主要贡献来自于词汇和语义模型的结合，而不是包含多个可能等效的语义模型。
- en: Impact of Query Type.
  id: totrans-192
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查询类型的影响。
- en: We also trained models exclusively on cropped sentences, docT5query generated
    queries, and a mixed subset of both types. The model trained only with docT5query
    generated queries, which are formulated as natural language questions, had a higher
    average performance than the model trained only on cropped sentences. This suggests
    that training with grammatically correct questions is more important.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在仅使用裁剪句子、`docT5query`生成的查询和两种类型混合子集上训练了模型。仅用`docT5query`生成的查询（以自然语言问题形式制定）训练的模型，平均性能高于仅用裁剪句子训练的模型。这表明，用语法正确的问题进行训练更为重要。
- en: Interestingly, for datasets where the queries were predominantly formed as ‘what’
    or ‘how’ questions, such as TREC-COVID, the model trained on docT5query queries
    delivered a strongly superior performance. Conversely, the model trained with
    cropped sentences performed better in specific datasets where the queries are
    not expressed as a question. For example, the queries in SciFact are expert-written
    claims, aiming to find evidence in annotated abstracts. Here, the model trained
    with cropped sentences achieved an nDCG@10 score of 67.9, significantly outperforming
    the model trained with docT5query queries, which scored 59.4.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，对于以“what”或“how”问题为主的查询数据集，例如TREC-COVID，使用`docT5query`查询训练的模型表现出明显更优的性能。相反，使用裁剪句子训练的模型在查询没有以问题形式表达的特定数据集中表现更好。例如，SciFact中的查询是专家编写的声明，旨在寻找注释文摘中的证据。在这里，使用裁剪句子训练的模型达到了67.9的nDCG@10评分，显著优于使用`docT5query`查询训练的模型，该模型得分为59.4。
- en: When we trained the model on a mixed subset comprising an equal proportion of
    both query types, it exhibited the best overall performance. This highlights the
    benefit of a diverse training regimen incorporating natural questions (docT5query)
    and sentences cropped directly from documents.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在一个包含两种查询类型的混合子集上训练模型时，它展示了最佳的整体性能。这突显了将自然问题（`docT5query`）和直接从文档中裁剪的句子纳入训练的多样化训练方案的好处。
- en: In summary, these results of the ablation study underscore the value of our
    proposed scoring strategy, the importance of incorporating sufficient documents
    per training sample, the significant contribution of BM25 as a supervision source,
    and the advantages of a mixed query approach.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，消融研究的结果突显了我们提出的评分策略的价值，涵盖了每个训练样本中包含足够文档的重要性，BM25作为监督来源的重大贡献，以及混合查询方法的优势。
- en: 6 Conclusion
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: The paradigm shift, enabled by LLMs, suggests that traditional methods relying
    heavily on handcrafted labeled data might no longer be the most effective or efficient
    approach for certain machine learning tasks. Indeed, as LLMs continue to showcase
    their prowess, there is a promising realization that they can be harnessed to
    provide the needed supervision, reducing the need for manual data labeling. However,
    tasks that demand efficiency, such as information retrieval, often cannot deploy
    LLMs directly due to their substantial computational overhead. In such scenarios,
    distillation enables the retention of the LLM’s capabilities in a more computationally
    amenable format.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 由LLM促成的范式转变表明，传统依赖大量人工标记数据的方法可能不再是某些机器学习任务中最有效或最高效的方法。确实，随着LLM展示其能力，有了一个有前景的认识，即它们可以被用来提供所需的监督，从而减少对手动数据标记的需求。然而，像信息检索这样需要效率的任务，通常由于其巨大的计算开销，无法直接部署LLM。在这种情况下，蒸馏能够以更计算友好的格式保留LLM的能力。
- en: In this paper, we presented a novel two-step LLM-augmented distillation approach
    for passage reranking. Our method capitalizes on the strengths of LLMs to enable
    computationally efficient information retrieval systems, with performance comparable
    or even superior to that of state-of-the-art baselines and a reduction in size
    by several orders of magnitude. Our experiments, conducted across various benchmarks,
    demonstrate robustness and generality of our approach across domains. An ablation
    offers further insight about the crucial elements of our architectural design.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一种新颖的两步LLM增强蒸馏方法用于段落重排序。我们的方法利用LLM的优势，实现了计算上高效的信息检索系统，其性能与最先进的基准相当或更优，并且体积减少了几个数量级。我们在各种基准上的实验展示了我们方法在不同领域的鲁棒性和通用性。消融实验提供了有关我们架构设计关键元素的进一步见解。
- en: Looking forward, TWOLAR offers promising avenues for scalability. In the future,
    we plan to further our experimentation by substituting the 3B model with an 11B
    version, expanding the number of queries, increasing the sources of supervision,
    or even refining the quality of the LLM used for distillation, for example by
    experimenting with more powerful generative language models.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，TWOLAR提供了有希望的扩展途径。未来，我们计划通过将3B模型替换为11B版本，扩展查询数量，增加监督来源，甚至通过实验更强大的生成语言模型来优化用于蒸馏的LLM的质量。
- en: References
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Baktash, J.A., Dawodi, M.: Gpt-4: A review on advancements and opportunities
    in natural language processing (2023)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Baktash, J.A., Dawodi, M.：Gpt-4：自然语言处理的进展与机会综述（2023年）'
- en: '[2] Bonifacio, L., Abonizio, H., Fadaee, M., Nogueira, R.: InPars: Unsupervised
    dataset generation for information retrieval. In: Proceedings of the 45th International
    ACM SIGIR Conference on Research and Development in Information Retrieval. p.
    2387–2392\. SIGIR ’22, Association for Computing Machinery, New York, NY, USA
    (2022). https://doi.org/10.1145/3477495.3531863, [https://doi.org/10.1145/3477495.3531863](https://doi.org/10.1145/3477495.3531863)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Bonifacio, L., Abonizio, H., Fadaee, M., Nogueira, R.：InPars：用于信息检索的无监督数据集生成。载于：第45届国际ACM
    SIGIR信息检索研究与开发会议论文集。第2387–2392页。SIGIR ’22，计算机协会，纽约，NY，美国（2022年）。https://doi.org/10.1145/3477495.3531863，
    [https://doi.org/10.1145/3477495.3531863](https://doi.org/10.1145/3477495.3531863)'
- en: '[3] Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,
    A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter,
    C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J.,
    Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language models
    are few-shot learners. In: Proceedings of the 34th International Conference on
    Neural Information Processing Systems. NIPS’20, Curran Associates Inc., Red Hook,
    NY, USA (2020)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss,
    A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter,
    C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J.,
    Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.：语言模型是少量样本学习者。载于：第34届国际神经信息处理系统大会论文集。NIPS’20，Curran
    Associates Inc.，Red Hook，NY，美国（2020年）'
- en: '[4] Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N.,
    Hullender, G.: Learning to rank using gradient descent. In: Proceedings of the
    22nd International Conference on Machine Learning. p. 89–96\. ICML ’05, Association
    for Computing Machinery, New York, NY, USA (2005). https://doi.org/10.1145/1102351.1102363,
    [https://doi.org/10.1145/1102351.1102363](https://doi.org/10.1145/1102351.1102363)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N.,
    Hullender, G.：使用梯度下降进行排名学习。载于：第22届国际机器学习会议论文集。第89–96页。ICML ’05，计算机协会，纽约，NY，美国（2005年）。https://doi.org/10.1145/1102351.1102363，
    [https://doi.org/10.1145/1102351.1102363](https://doi.org/10.1145/1102351.1102363)'
- en: '[5] Chung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y.,
    Wang, X., Dehghani, M., Brahma, S., Webson, A., Gu, S.S., Dai, Z., Suzgun, M.,
    Chen, X., Chowdhery, A., Castro-Ros, A., Pellat, M., Robinson, K., Valter, D.,
    Narang, S., Mishra, G., Yu, A., Zhao, V., Huang, Y., Dai, A., Yu, H., Petrov,
    S., Chi, E.H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q.V., Wei, J.:
    Scaling instruction-finetuned language models (2022)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Chung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y.,
    Wang, X., Dehghani, M., Brahma, S., Webson, A., Gu, S.S., Dai, Z., Suzgun, M.,
    Chen, X., Chowdhery, A., Castro-Ros, A., Pellat, M., Robinson, K., Valter, D.,
    Narang, S., Mishra, G., Yu, A., Zhao, V., Huang, Y., Dai, A., Yu, H., Petrov,
    S., Chi, E.H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q.V., Wei, J.：规模化指令微调语言模型（2022年）'
- en: '[6] Craswell, N., Mitra, B., Yilmaz, E., Campos, D.: Overview of the trec 2020
    deep learning track (2021)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Craswell, N., Mitra, B., Yilmaz, E., Campos, D.：TREC 2020深度学习跟踪概述（2021年）'
- en: '[7] Craswell, N., Mitra, B., Yilmaz, E., Campos, D., Voorhees, E.M.: Overview
    of the trec 2019 deep learning track (2020)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Craswell, N., Mitra, B., Yilmaz, E., Campos, D., Voorhees, E.M.：TREC 2019深度学习跟踪概述（2020年）'
- en: '[8] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of
    deep bidirectional transformers for language understanding. In: Proceedings of
    the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). pp.
    4171–4186\. Association for Computational Linguistics, Minneapolis, Minnesota
    (Jun 2019). https://doi.org/10.18653/v1/N19-1423, [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: 用于语言理解的深度双向变换器的预训练。在：2019年北美计算语言学协会人类语言技术会议论文集，第1卷（长篇和短篇论文）。第
    4171–4186 页。计算语言学协会，明尼阿波利斯，明尼苏达州 (2019年6月)。https://doi.org/10.18653/v1/N19-1423,
    [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)'
- en: '[9] Fan, Y., Xie, X., Cai, Y., Chen, J., Ma, X., Li, X., Zhang, R., Guo, J.,
    et al.: Pre-training methods in information retrieval. Foundations and Trends®
    in Information Retrieval 16(3), 178–317 (2022)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Fan, Y., Xie, X., Cai, Y., Chen, J., Ma, X., Li, X., Zhang, R., Guo, J.,
    et al.: 信息检索中的预训练方法。《信息检索基础与趋势®》16(3)，178–317 (2022)'
- en: '[10] Formal, T., Lassance, C., Piwowarski, B., Clinchant, S.: Splade v2: Sparse
    lexical and expansion model for information retrieval. arXiv preprint arXiv:2109.10086
    (2021)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Formal, T., Lassance, C., Piwowarski, B., Clinchant, S.: Splade v2: 稀疏词汇和扩展模型用于信息检索。arXiv
    预印本 arXiv:2109.10086 (2021)'
- en: '[11] Formal, T., Lassance, C., Piwowarski, B., Clinchant, S.: From distillation
    to hard negative sampling: Making sparse neural ir models more effective. In:
    Proceedings of the 45th International ACM SIGIR Conference on Research and Development
    in Information Retrieval. pp. 2353–2359 (2022)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Formal, T., Lassance, C., Piwowarski, B., Clinchant, S.: 从蒸馏到困难负样本采样：使稀疏神经信息检索模型更有效。在：第45届国际
    ACM SIGIR 信息检索研究与发展会议论文集。第 2353–2359 页 (2022)'
- en: '[12] Formal, T., Piwowarski, B., Clinchant, S.: Splade: Sparse lexical and
    expansion model for first stage ranking. In: Proceedings of the 44th International
    ACM SIGIR Conference on Research and Development in Information Retrieval. p.
    2288–2292\. SIGIR ’21, Association for Computing Machinery, New York, NY, USA
    (2021). https://doi.org/10.1145/3404835.3463098, [https://doi.org/10.1145/3404835.3463098](https://doi.org/10.1145/3404835.3463098)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Formal, T., Piwowarski, B., Clinchant, S.: Splade: 稀疏词汇和扩展模型用于第一阶段排名。在：第44届国际
    ACM SIGIR 信息检索研究与发展会议论文集。第 2288–2292 页。SIGIR ’21，计算机协会，纽约，纽约，美国 (2021)。https://doi.org/10.1145/3404835.3463098,
    [https://doi.org/10.1145/3404835.3463098](https://doi.org/10.1145/3404835.3463098)'
- en: '[13] Guo, J., Fan, Y., Ai, Q., Croft, W.B.: A deep relevance matching model
    for ad-hoc retrieval. In: Proceedings of the 25th ACM International on Conference
    on Information and Knowledge Management. ACM (oct 2016). https://doi.org/10.1145/2983323.2983769,
    [https://doi.org/10.1145%2F2983323.2983769](https://doi.org/10.1145%2F2983323.2983769)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Guo, J., Fan, Y., Ai, Q., Croft, W.B.: 一种用于广告检索的深度相关性匹配模型。在：第25届 ACM 国际信息与知识管理会议论文集。ACM
    (2016年10月)。https://doi.org/10.1145/2983323.2983769, [https://doi.org/10.1145%2F2983323.2983769](https://doi.org/10.1145%2F2983323.2983769)'
- en: '[14] Guo, J., Fan, Y., Pang, L., Yang, L., Ai, Q., Zamani, H., Wu, C., Croft,
    W.B., Cheng, X.: A deep look into neural ranking models for information retrieval.
    Information Processing & Management 57(6), 102067 (2020)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Guo, J., Fan, Y., Pang, L., Yang, L., Ai, Q., Zamani, H., Wu, C., Croft,
    W.B., Cheng, X.: 深入探讨用于信息检索的神经排名模型。《信息处理与管理》57(6)，102067 (2020)'
- en: '[15] He, P., Gao, J., Chen, W.: Debertav3: Improving deberta using electra-style
    pre-training with gradient-disentangled embedding sharing. arXiv preprint arXiv:2111.09543
    (2021)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] He, P., Gao, J., Chen, W.: Debertav3: 通过使用 electra 风格的预训练和梯度解耦嵌入共享来改进
    deberta。arXiv 预印本 arXiv:2111.09543 (2021)'
- en: '[16] Jeronymo, V., Bonifacio, L., Abonizio, H., Fadaee, M., Lotufo, R., Zavrel,
    J., Nogueira, R.: InPars-v2: Large language models as efficient dataset generators
    for information retrieval (2023). https://doi.org/10.48550/ARXIV.2301.01820, [https://arxiv.org/abs/2301.01820](https://arxiv.org/abs/2301.01820)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Jeronymo, V., Bonifacio, L., Abonizio, H., Fadaee, M., Lotufo, R., Zavrel,
    J., Nogueira, R.: InPars-v2: 大型语言模型作为信息检索的高效数据集生成器 (2023)。https://doi.org/10.48550/ARXIV.2301.01820,
    [https://arxiv.org/abs/2301.01820](https://arxiv.org/abs/2301.01820)'
- en: '[17] Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen,
    D., Yih, W.t.: Dense passage retrieval for open-domain question answering. In:
    Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing
    (EMNLP). pp. 6769–6781\. Association for Computational Linguistics, Online (Nov
    2020). https://doi.org/10.18653/v1/2020.emnlp-main.550, [https://aclanthology.org/2020.emnlp-main.550](https://aclanthology.org/2020.emnlp-main.550)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen,
    D., Yih, W.t.: 《开放域问答的密集段落检索》。在：2020年自然语言处理实证方法会议 (EMNLP) 论文集。第6769–6781页。计算语言学协会，在线
    (2020年11月)。https://doi.org/10.18653/v1/2020.emnlp-main.550, [https://aclanthology.org/2020.emnlp-main.550](https://aclanthology.org/2020.emnlp-main.550)'
- en: '[18] Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A.,
    Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K.,
    Jones, L., Kelcey, M., Chang, M.W., Dai, A.M., Uszkoreit, J., Le, Q., Petrov,
    S.: Natural questions: A benchmark for question answering research. Transactions
    of the Association for Computational Linguistics 7, 452–466 (2019), [https://aclanthology.org/Q19-1026](https://aclanthology.org/Q19-1026)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A.,
    Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K.,
    Jones, L., Kelcey, M., Chang, M.W., Dai, A.M., Uszkoreit, J., Le, Q., Petrov,
    S.: 《自然问题：问答研究的基准》。计算语言学协会交易 7, 452–466 (2019年)， [https://aclanthology.org/Q19-1026](https://aclanthology.org/Q19-1026)'
- en: '[19] Li, H.: Learning to rank for information retrieval and natural language
    processing, second edition. Synthesis Lectures on Human Language Technologies
    7, 1–123 (01 2015). https://doi.org/10.2200/S00607ED2V01Y201410HLT026'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Li, H.: 《信息检索与自然语言处理的排序学习》，第二版。Synthesis Lectures on Human Language Technologies
    7, 1–123 (2015年01月)。https://doi.org/10.2200/S00607ED2V01Y201410HLT026'
- en: '[20] Lin, J., Nogueira, R., Yates, A.: Pretrained transformers for text ranking:
    Bert and beyond. Springer Nature (2022)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Lin, J., Nogueira, R., Yates, A.: 《用于文本排名的预训练变换器：BERT及其他》。Springer Nature
    (2022年)'
- en: '[21] Lin, S.C., Asai, A., Li, M., Oguz, B., Lin, J., Mehdad, Y., Yih, W.t.,
    Chen, X.: How to train your dragon: Diverse augmentation towards generalizable
    dense retrieval. arXiv preprint arXiv:2302.07452 (2023)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Lin, S.C., Asai, A., Li, M., Oguz, B., Lin, J., Mehdad, Y., Yih, W.t.,
    Chen, X.: 《如何训练你的龙：朝着通用的密集检索方向的多样化增强》。arXiv 预印本 arXiv:2302.07452 (2023年)'
- en: '[22] Liu, T.Y.: Learning to rank for information retrieval. Found. Trends Inf.
    Retr. 3(3), 225–331 (mar 2009). https://doi.org/10.1561/1500000016, [https://doi.org/10.1561/1500000016](https://doi.org/10.1561/1500000016)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Liu, T.Y.: 《信息检索中的排序学习》。Found. Trends Inf. Retr. 3(3), 225–331 (2009年3月)。https://doi.org/10.1561/1500000016,
    [https://doi.org/10.1561/1500000016](https://doi.org/10.1561/1500000016)'
- en: '[23] Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. In:
    International Conference on Learning Representations (2019), [https://openreview.net/forum?id=Bkg6RiCqY7](https://openreview.net/forum?id=Bkg6RiCqY7)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Loshchilov, I., Hutter, F.: 《解耦权重衰减正则化》。在：国际学习表示会议 (2019年)， [https://openreview.net/forum?id=Bkg6RiCqY7](https://openreview.net/forum?id=Bkg6RiCqY7)'
- en: '[24] Ma, X., Zhang, X., Pradeep, R., Lin, J.: Zero-shot listwise document reranking
    with a large language model. arXiv preprint arXiv:2305.02156 (2023)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Ma, X., Zhang, X., Pradeep, R., Lin, J.: 《使用大型语言模型的零样本文档重新排序》。arXiv 预印本
    arXiv:2305.02156 (2023年)'
- en: '[25] Mitra, B., Craswell, N.: Neural models for information retrieval. arXiv
    preprint arXiv:1705.01509 (2017)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Mitra, B., Craswell, N.: 《信息检索的神经模型》。arXiv 预印本 arXiv:1705.01509 (2017年)'
- en: '[26] Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R.,
    Deng, L.: MS MARCO: A human-generated MAchine reading COmprehension dataset (2017),
    [https://openreview.net/forum?id=Hk1iOLcle](https://openreview.net/forum?id=Hk1iOLcle)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R.,
    Deng, L.: MS MARCO: 一个人工生成的机器阅读理解数据集 (2017年)， [https://openreview.net/forum?id=Hk1iOLcle](https://openreview.net/forum?id=Hk1iOLcle)'
- en: '[27] Nogueira, R., Cho, K.: Passage re-ranking with bert (2019), [http://arxiv.org/abs/1901.04085](http://arxiv.org/abs/1901.04085)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Nogueira, R., Cho, K.: 《使用BERT进行段落重新排序》 (2019年)， [http://arxiv.org/abs/1901.04085](http://arxiv.org/abs/1901.04085)'
- en: '[28] Nogueira, R., Jiang, Z., Pradeep, R., Lin, J.: Document ranking with a
    pretrained sequence-to-sequence model. In: Findings of the Association for Computational
    Linguistics: EMNLP 2020\. pp. 708–718\. Association for Computational Linguistics,
    Online (Nov 2020). https://doi.org/10.18653/v1/2020.findings-emnlp.63, [https://aclanthology.org/2020.findings-emnlp.63](https://aclanthology.org/2020.findings-emnlp.63)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Nogueira, R., Jiang, Z., Pradeep, R., Lin, J.: 《使用预训练的序列到序列模型进行文档排名》。在：计算语言学协会：EMNLP
    2020发现。第708–718页。计算语言学协会，在线 (2020年11月)。https://doi.org/10.18653/v1/2020.findings-emnlp.63,
    [https://aclanthology.org/2020.findings-emnlp.63](https://aclanthology.org/2020.findings-emnlp.63)'
- en: '[29] Nogueira, R., Lin, J., Epistemic, A.: From doc2query to doctttttquery.
    Online preprint 6,  2 (2019)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Nogueira, R., Lin, J., Epistemic, A.: 从doc2query到doctttttquery。在线预印本 6,
    2（2019年）'
- en: '[30] Nogueira, R., Yang, W., Cho, K., Lin, J.: Multi-stage document ranking
    with bert. arXiv preprint arXiv:1910.14424 (2019)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Nogueira, R., Yang, W., Cho, K., Lin, J.: 基于BERT的多阶段文档排序。arXiv预印本 arXiv:1910.14424（2019年）'
- en: '[31] Qin, Z., Jagerman, R., Hui, K., Zhuang, H., Wu, J., Shen, J., Liu, T.,
    Liu, J., Metzler, D., Wang, X., et al.: Large language models are effective text
    rankers with pairwise ranking prompting. arXiv preprint arXiv:2306.17563 (2023)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Qin, Z., Jagerman, R., Hui, K., Zhuang, H., Wu, J., Shen, J., Liu, T.,
    Liu, J., Metzler, D., Wang, X., 等：大型语言模型是有效的文本排序器，具有成对排名提示。arXiv预印本 arXiv:2306.17563（2023年）'
- en: '[32] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.:
    Language models are unsupervised multitask learners. OpenAI blog 1(8),  9 (2019)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., 等：语言模型是无监督的多任务学习者。OpenAI博客
    1(8), 9（2019年）'
- en: '[33] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M.,
    Zhou, Y., Li, W., Liu, P.J.: Exploring the limits of transfer learning with a
    unified text-to-text transformer. The Journal of Machine Learning Research 21(1),
    5485–5551 (2020)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M.,
    Zhou, Y., Li, W., Liu, P.J.: 探索统一文本到文本变换器的迁移学习极限。《机器学习研究杂志》21(1), 5485–5551（2020年）'
- en: '[34] Robertson, S.E., Walker, S., Jones, S., Hancock-Beaulieu, M.M., Gatford,
    M., et al.: Okapi at trec-3\. Nist Special Publication Sp 109,  109 (1995)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Robertson, S.E., Walker, S., Jones, S., Hancock-Beaulieu, M.M., Gatford,
    M., 等：Okapi在TREC-3中的表现。NIST特别出版物 Sp 109, 109（1995年）'
- en: '[35] Rosa, G.M., Bonifacio, L., Jeronymo, V., Abonizio, H., Fadaee, M., Lotufo,
    R., Nogueira, R.: No parameter left behind: How distillation and model size affect
    zero-shot retrieval. arXiv preprint arXiv:2206.02873 (2022)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Rosa, G.M., Bonifacio, L., Jeronymo, V., Abonizio, H., Fadaee, M., Lotufo,
    R., Nogueira, R.: 没有参数被遗留：蒸馏和模型大小如何影响零样本检索。arXiv预印本 arXiv:2206.02873（2022年）'
- en: '[36] Sun, W., Yan, L., Ma, X., Ren, P., Yin, D., Ren, Z.: Is chatgpt good at
    search? investigating large language models as re-ranking agent. arXiv preprint
    arXiv:2304.09542 (2023)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Sun, W., Yan, L., Ma, X., Ren, P., Yin, D., Ren, Z.: ChatGPT在搜索方面表现如何？调查大型语言模型作为重新排序代理。arXiv预印本
    arXiv:2304.09542（2023年）'
- en: '[37] Thakur, N., Reimers, N., Rücklé, A., Srivastava, A., Gurevych, I.: BEIR:
    A heterogeneous benchmark for zero-shot evaluation of information retrieval models.
    In: Thirty-fifth Conference on Neural Information Processing Systems Datasets
    and Benchmarks Track (Round 2) (2021), [https://openreview.net/forum?id=wCu6T5xFjeJ](https://openreview.net/forum?id=wCu6T5xFjeJ)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Thakur, N., Reimers, N., Rücklé, A., Srivastava, A., Gurevych, I.: BEIR：一个异质基准用于零样本评估信息检索模型。会议论文：第35届神经信息处理系统会议数据集与基准追踪（第2轮）（2021年），
    [https://openreview.net/forum?id=wCu6T5xFjeJ](https://openreview.net/forum?id=wCu6T5xFjeJ)'
- en: '[38] VanBuskirk, A.: Gpt-3.5 turbo vs gpt-4: What’s the difference? (March
    2023), [https://blog.wordbot.io/ai-artificial-intelligence/gpt-3-5-turbo-vs-gpt-4-whats-the-difference/](https://blog.wordbot.io/ai-artificial-intelligence/gpt-3-5-turbo-vs-gpt-4-whats-the-difference/)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] VanBuskirk, A.: GPT-3.5 turbo 与 GPT-4：有什么区别？（2023年3月）， [https://blog.wordbot.io/ai-artificial-intelligence/gpt-3-5-turbo-vs-gpt-4-whats-the-difference/](https://blog.wordbot.io/ai-artificial-intelligence/gpt-3-5-turbo-vs-gpt-4-whats-the-difference/)'
- en: '[39] Wang, B., Komatsuzaki, A.: GPT-J-6B: A 6 Billion Parameter Autoregressive
    Language Model. [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax)
    (May 2021)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Wang, B., Komatsuzaki, A.: GPT-J-6B: 一个60亿参数的自回归语言模型。 [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax)（2021年5月）'
- en: '[40] Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W.W., Salakhutdinov, R.,
    Manning, C.D.: Hotpotqa: A dataset for diverse, explainable multi-hop question
    answering. arXiv preprint arXiv:1809.09600 (2018)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W.W., Salakhutdinov, R.,
    Manning, C.D.: HotpotQA：一个用于多跳问答的多样化、可解释的数据集。arXiv预印本 arXiv:1809.09600（2018年）'
- en: '[41] Zhai, C., et al.: Statistical language models for information retrieval
    a critical review. Foundations and Trends® in Information Retrieval 2(3), 137–213
    (2008)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Zhai, C., 等：用于信息检索的统计语言模型的关键评审。信息检索基础与趋势® 2(3), 137–213（2008年）'
- en: '[42] Zhao, W.X., Liu, J., Ren, R., Wen, J.R.: Dense text retrieval based on
    pretrained language models: A survey. arXiv preprint arXiv:2211.14876 (2022)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Zhao, W.X., Liu, J., Ren, R., Wen, J.R.: 基于预训练语言模型的密集文本检索：综述。arXiv预印本
    arXiv:2211.14876（2022年）'
- en: '[43] Zhu, Y., Yuan, H., Wang, S., Liu, J., Liu, W., Deng, C., Dou, Z., Wen,
    J.R.: Large language models for information retrieval: A survey. arXiv preprint
    arXiv:2308.07107 (2023)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] 朱岩，袁辉，王硕，刘佳，刘伟，邓晨，窦智伟，温久瑞：用于信息检索的大型语言模型：综述。arXiv预印本arXiv:2308.07107（2023）'
- en: '[44] Zhuang, H., Qin, Z., Jagerman, R., Hui, K., Ma, J., Lu, J., Ni, J., Wang,
    X., Bendersky, M.: Rankt5: Fine-tuning t5 for text ranking with ranking losses.
    In: Proceedings of the 46th International ACM SIGIR Conference on Research and
    Development in Information Retrieval. pp. 2308–2313 (2023)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] 庄辉，秦忠，贾格曼，惠克，马俊，陆军，倪健，王晓，本德斯基：Rankt5：通过排名损失微调T5以进行文本排序。在：第46届国际ACM SIGIR信息检索研究与开发会议论文集。页2308–2313（2023）'
