- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-08 18:59:27'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-08 18:59:27'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs
    by Leveraging Negative Data'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将尘土变为黄金：通过利用负数据从 LLMs 中提炼复杂推理能力
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.12832](https://ar5iv.labs.arxiv.org/html/2312.12832)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2312.12832](https://ar5iv.labs.arxiv.org/html/2312.12832)
- en: Yiwei Li¹¹¹1Equal contributions., Peiwen Yuan¹¹¹1Equal contributions., Shaoxiong
    Feng², Boyuan Pan², Bin Sun¹, Xinglin Wang¹, Heda Wang², Kan Li¹²²2Corresponding
    author.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yiwei Li¹¹¹1等贡献相等., Peiwen Yuan¹¹¹1等贡献相等., Shaoxiong Feng², Boyuan Pan², Bin
    Sun¹, Xinglin Wang¹, Heda Wang², Kan Li¹²²2通讯作者。
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have performed well on various reasoning tasks,
    but their inaccessibility and numerous parameters hinder wide application in practice.
    One promising way is distilling the reasoning ability from LLMs to small models
    by the generated chain-of-thought reasoning paths. In some cases, however, LLMs
    may produce incorrect reasoning chains, especially when facing complex mathematical
    problems. Previous studies only transfer knowledge from positive samples and drop
    the synthesized data with wrong answers. In this work, we illustrate the merit
    of negative data and propose a model specialization framework to distill LLMs
    with negative samples besides positive ones. The framework consists of three progressive
    steps, covering from training to inference stages, to absorb knowledge from negative
    data. We conduct extensive experiments across arithmetic reasoning tasks to demonstrate
    the role of negative data in distillation from LLM¹¹1Equal contributions..
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '大型语言模型（LLMs）在各种推理任务上表现良好，但其难以访问和众多参数限制了实际应用的广泛性。一种有前景的方法是通过生成的链式思维推理路径将推理能力从
    LLMs 提炼到小型模型中。然而，在某些情况下，LLMs 可能会产生错误的推理链，特别是在面对复杂的数学问题时。之前的研究只从正样本中转移知识，并丢弃了带有错误答案的合成数据。在这项工作中，我们展示了负数据的价值，并提出了一个模型专业化框架，以便在提炼
    LLMs 时除正样本外还包括负样本。该框架包括三个逐步的步骤，涵盖从训练到推理阶段，以吸收负数据中的知识。我们在算术推理任务上进行广泛实验，以展示负数据在从
    LLMs 中提炼中的作用¹¹¹1等贡献相等。 '
- en: '¹¹footnotetext: Our code and data have been released on https://github.com/Yiwei98/TDG.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹脚注：我们的代码和数据已经发布在 https://github.com/Yiwei98/TDG。
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Nowadays, owing to chain-of-thought (CoT) prompting (Wei et al. [2022b](#bib.bib35)),
    large language models (LLMs) exhibit strong reasoning capabilities (Bubeck et al.
    [2023a](#bib.bib2)), especially when it comes to complex mathematical problems
    (Hendrycks et al. [2021](#bib.bib9)). Unfortunately, CoT has been demonstrated
    to be an emergent property of models with more than 100B parameters, but not of
    smaller models (Wei et al. [2022a](#bib.bib34)). The burdensome computational
    requirements and high inference costs of these models hinder their development
    in real-world scenarios with limited resources (Ho, Schmid, and Yun [2023](#bib.bib11)).
    Thus, the goal of our research is to enable complex arithmetic reasoning in small
    models for deploying at scale.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，由于链式思维（CoT）提示（Wei 等 [2022b](#bib.bib35)），大型语言模型（LLMs）展现出强大的推理能力（Bubeck 等
    [2023a](#bib.bib2)），特别是在解决复杂的数学问题时（Hendrycks 等 [2021](#bib.bib9)）。不幸的是，CoT 已被证明是具有超过
    100B 参数的模型的一个新兴特性，而不是较小的模型（Wei 等 [2022a](#bib.bib34)）。这些模型的计算要求繁重且推理成本高，这限制了它们在资源有限的实际场景中的发展（Ho,
    Schmid, 和 Yun [2023](#bib.bib11)）。因此，我们研究的目标是使小型模型具备复杂的算术推理能力，以便大规模部署。
- en: '| MATH Dataset | Intersection | Pos | Neg | IoU |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| MATH 数据集 | 交集 | 正样本 | 负样本 | IoU |'
- en: '| InterAlgebra | 4 | 35 | 21 | 0.077 |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| InterAlgebra | 4 | 35 | 21 | 0.077 |'
- en: '| Prealgebra | 9 | 72 | 43 | 0.085 |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| Prealgebra | 9 | 72 | 43 | 0.085 |'
- en: '| Geometry | 1 | 21 | 10 | 0.033 |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 几何学 | 1 | 21 | 10 | 0.033 |'
- en: '| NumberTheory | 1 | 29 | 17 | 0.022 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 数论 | 1 | 29 | 17 | 0.022 |'
- en: '| Precalculus | 2 | 25 | 16 | 0.051 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| Precalculus | 2 | 25 | 16 | 0.051 |'
- en: '| Probability | 4 | 19 | 16 | 0.129 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| Probability | 4 | 19 | 16 | 0.129 |'
- en: '| Algebra | 8 | 52 | 43 | 0.062 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 代数 | 8 | 52 | 43 | 0.062 |'
- en: '| Overall | 29 | 253 | 166 | 0.074 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 总体 | 29 | 253 | 166 | 0.074 |'
- en: 'Table 1: The distribution of correct answers in MATH test set. Pos and Neg
    refer to models trained on positive and negative samples respectively. Intersection
    over Union (IoU) exhibits a remarkably low value across all subsets, which confirms
    the value of negative samples.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：MATH 测试集中的正确答案分布。Pos 和 Neg 分别指代在正样本和负样本上训练的模型。交集比例（IoU）在所有子集中的值非常低，这验证了负样本的价值。
- en: 'Knowledge distillation (Hinton, Vinyals, and Dean [2015](#bib.bib10)) offers
    a promising way to transfer specific capabilities from LLMs into smaller models.
    This process is also referred to as model specialization enforcing compact models
    to focus on certain skills. Prior works (Magister et al. [2023](#bib.bib23); Fu
    et al. [2023](#bib.bib7); Hsieh et al. [2023](#bib.bib12)) employed LLMs with
    in-context learning (ICL) (Brown et al. [2020](#bib.bib1)) to generate reasoning
    paths (rationales) of math problems, which are more beneficial for small models
    to acquire complex reasoning ability than reference reasoning paths. Table [1](#Sx1.T1
    "Table 1 ‣ Introduction ‣ Turning Dust into Gold: Distilling Complex Reasoning
    Capabilities from LLMs by Leveraging Negative Data") shows an intriguing phenomenon:
    models trained on positive and negative data separately have an extremely small
    overlap (intersection) in their correct answers on the MATH test set. Although
    the negative model has a lower accuracy, it can address some questions that the
    positive model is unable to provide correct answers, which confirms the valuable
    knowledge contained in negative data. Additionally, the undesirable behaviors
    within negative data are also useful when preventing the model from committing
    similar issues. Another reason that we should exploit negative data is the token-based
    pricing strategy of OpenAI. Even for GPT-4, the accuracy on MATH dataset is less
    than 50% (Bubeck et al. [2023b](#bib.bib3)), meaning that all tokens of negative
    data are charged for nothing. Therefore, instead of discarding negative samples,
    we extract and utilize valuable knowledge from negative samples to boost the model
    specialization.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '知识蒸馏（Hinton, Vinyals, and Dean [2015](#bib.bib10)）提供了一种有前景的方法，将特定能力从大型语言模型（LLMs）转移到较小的模型中。这个过程也称为模型专业化，强制紧凑型模型专注于某些技能。之前的研究（Magister
    et al. [2023](#bib.bib23); Fu et al. [2023](#bib.bib7); Hsieh et al. [2023](#bib.bib12)）采用了具有上下文学习（ICL）（Brown
    et al. [2020](#bib.bib1)）的LLMs来生成数学问题的推理路径（合理性），这对小型模型获取复杂推理能力比参考推理路径更有帮助。表[1](#Sx1.T1
    "Table 1 ‣ Introduction ‣ Turning Dust into Gold: Distilling Complex Reasoning
    Capabilities from LLMs by Leveraging Negative Data")显示了一个有趣的现象：在MATH测试集中，分别在正面和负面数据上训练的模型在正确答案上的重叠（交集）非常小。尽管负面模型的准确性较低，但它能够解决一些正面模型无法提供正确答案的问题，这证实了负面数据中包含的有价值知识。此外，负面数据中的不良行为在防止模型出现类似问题时也很有用。我们应该利用负面数据的另一个原因是OpenAI基于token的定价策略。即使对于GPT-4，在MATH数据集上的准确率也不到50%（Bubeck
    et al. [2023b](#bib.bib3)），这意味着负面数据的所有tokens都是无偿收费的。因此，我们提取并利用负面样本中的有价值知识来提升模型专业化，而不是丢弃负面样本。'
- en: 'The conventional process of model specialization can be summarized as three
    steps (Zhu et al. [2023](#bib.bib41)): The first step is chain-of-thought distillation,
    training small models with reasoning chains generated from LLMs. The second step
    can be regarded as self-enhancement, conducting self-distillation (Mobahi, Farajtabar,
    and Bartlett [2020](#bib.bib25)) or self-augmentation to further optimize the
    models. Besides, self-consistency (Wang et al. [2023](#bib.bib33)) is widely used
    as an effective decoding strategy to boost the model performance in reasoning
    tasks. In this work, we propose a novel model specialization framework (shown
    in Figure [1](#Sx3.F1 "Figure 1 ‣ Methodology ‣ Turning Dust into Gold: Distilling
    Complex Reasoning Capabilities from LLMs by Leveraging Negative Data")) that can
    exploit negative data to enhance the distillation of the complex reasoning abilities
    from LLMs. Specifically, we first develop the negative assistant training (NAT)
    approach, where dual LoRA (Hu et al. [2022](#bib.bib13)) structure is designed
    to capture knowledge from both positive and negative sides. As an auxiliary module,
    the knowledge of negative LoRA can be dynamically integrated into the training
    process of positive LoRA through a corrected attention mechanism. For self-enhancement,
    we devise negative calibrated enhancement (NCE), which regards the negative output
    as a baseline to strengthen the distillation of critical positive rationales.
    In addition to the training stage, we also leverage the negative information during
    inference. Traditional self-consistency allocates equal or probability-based weights
    to all candidate outputs, leading to some fallible answers being voted up. To
    alleviate this issue, adaptive self-consistency (ASC) is proposed to conduct ranking
    before voting, where the ranking model is trained on both positive and negative
    data.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '传统的模型专门化过程可以总结为三个步骤 (Zhu et al. [2023](#bib.bib41))：第一步是思维链蒸馏，即用 LLMs 生成的推理链训练小模型。第二步可以视为自我增强，通过自蒸馏
    (Mobahi, Farajtabar, and Bartlett [2020](#bib.bib25)) 或自我扩增进一步优化模型。此外，自一致性 (Wang
    et al. [2023](#bib.bib33)) 被广泛用作提高推理任务模型性能的有效解码策略。在本工作中，我们提出了一个新颖的模型专门化框架（如图 [1](#Sx3.F1
    "Figure 1 ‣ Methodology ‣ Turning Dust into Gold: Distilling Complex Reasoning
    Capabilities from LLMs by Leveraging Negative Data") 所示），可以利用负向数据来增强从 LLMs 中提炼复杂推理能力的过程。具体来说，我们首先开发了负向助理训练
    (NAT) 方法，其中双 LoRA (Hu et al. [2022](#bib.bib13)) 结构被设计用于捕捉正向和负向知识。作为辅助模块，负向 LoRA
    的知识可以通过修正注意力机制动态地集成到正向 LoRA 的训练过程中。对于自我增强，我们设计了负向校准增强 (NCE)，将负向输出视为基准，以强化关键正向理据的蒸馏。除了训练阶段，我们还在推理过程中利用负向信息。传统的自一致性对所有候选输出分配相等或基于概率的权重，这导致一些错误答案被提升。为缓解这一问题，提出了自适应自一致性
    (ASC)，在投票之前进行排名，其中排名模型在正向和负向数据上进行训练。'
- en: 'We perform comprehensive experiments and detailed analyses across arithmetic
    reasoning tasks with LLaMA-7b (Touvron et al. [2023](#bib.bib32)) as the student
    model. Previous model specialization work only validated on ordinary datasets
    (e.g., GSM8K, ASDiv, etc.), while we are the first to focus on the challenging
    competition mathematical problems – MATH dataset (Hendrycks et al. [2021](#bib.bib9)).
    Experiments show that: (1) Negative assistant training can provide a more comprehensive
    way to absorb the knowledge from negative data. (2) Negative calibrated enhancement
    can make the process of self-distillation more targeted on crucial knowledge.
    (3) Ranking model trained on both positive and negative rationales can assign
    appropriate weights for answer aggregation. In summary, key contributions of this
    work are as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在使用 LLaMA-7b (Touvron et al. [2023](#bib.bib32)) 作为学生模型的算术推理任务上进行全面实验和详细分析。以往的模型专门化工作仅在普通数据集（例如，GSM8K、ASDiv
    等）上进行了验证，而我们是首次关注具有挑战性的竞赛数学问题——MATH 数据集 (Hendrycks et al. [2021](#bib.bib9))。实验结果表明：
    (1) 负向助理训练可以提供从负向数据中吸收知识的更全面方式。 (2) 负向校准增强可以使自蒸馏过程更加针对关键知识。 (3) 在正向和负向理据上训练的排名模型可以为答案聚合分配适当的权重。总之，本工作的关键贡献如下：
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We illustrate that negative samples with incorrect answers can also provide
    a valuable resource besides positive data for distilling knowledge from LLMs in
    complex arithmetic reasoning tasks.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们说明了负向样本与错误答案也可以作为除了正向数据外的宝贵资源，用于从 LLMs 中提炼复杂算术推理任务的知识。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To fully leverage the negative data, we propose a model specialization framework
    consisting of three progressive steps, spanning from training to inference stages.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了充分利用负面数据，我们提出了一个模型专业化框架，包括从训练到推理阶段的三个渐进步骤。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Extensive evaluations on challenging arithmetic reasoning dataset demonstrate
    that the proposed framework can effectively exploit the negative information and
    outperform baselines by a large margin.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对具有挑战性的算术推理数据集的广泛评估表明，所提出的框架能够有效利用负面信息，并大幅度超越基准。
- en: Related Work
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作
- en: Chain-of-Thought Reasoning
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连锁推理
- en: 'The approach of solving complex reasoning problems by generating chain-of-thought
    (rationales) has been proven to be an effective method (Wei et al. [2022b](#bib.bib35)).
    By following the pattern of gradually solving sub-problems, both few-shot CoT
    (Fu et al. [2023](#bib.bib7)) and zero-shot CoT (Kojima et al. [2022](#bib.bib16))
    can stimulate the potential reasoning ability of LLMs. On this basis, Least-to-most
    prompting (Zhou et al. [2023](#bib.bib40)) suggests explicitly splitting the problem
    and solving them step by step. Self-Consistency (Wang et al. [2023](#bib.bib33))
    further improves accuracy by conducting vote between multiple diverse rationales.
    PHP proposes (Zheng et al. [2023](#bib.bib39)) iteratively generating answers
    and adding the historically generated answers as hints to the context to achieve
    the final convergence on the answer. Both correct and incorrect answers generated
    during this iteration process serve as hints to provide effective information.
    We also think that responses with incorrect answers from LLMs can provide valuable
    information, but the differences lie in: (1) We believe that not only the generated
    answers, but also the rationales contain valuable knowledge. (2) We consider utilizing
    these negative samples in the process of transferring knowledge from LLMs to smaller
    models instead of only inference stage.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过生成连锁推理（rationales）来解决复杂推理问题的方法已被证明是一种有效的方法（Wei et al. [2022b](#bib.bib35)）。通过逐步解决子问题的模式，无论是少量示例的连锁推理（Fu
    et al. [2023](#bib.bib7)）还是零示例的连锁推理（Kojima et al. [2022](#bib.bib16)），都能激发LLM的潜在推理能力。在此基础上，Least-to-most
    prompting（Zhou et al. [2023](#bib.bib40)）建议明确地将问题分解并逐步解决。Self-Consistency（Wang
    et al. [2023](#bib.bib33)）通过在多个不同的rationales之间进行投票进一步提高准确性。PHP（Zheng et al. [2023](#bib.bib39)）则建议迭代生成答案，并将历史生成的答案作为上下文提示，最终实现答案的收敛。在此迭代过程中生成的正确和错误答案都作为提示提供有效信息。我们也认为LLMs生成的错误答案可以提供有价值的信息，但差异在于：（1）我们认为不仅生成的答案，还有rationales包含有价值的知识。（2）我们考虑在将知识从LLMs转移到较小模型的过程中利用这些负样本，而不仅仅是在推理阶段。
- en: Knowledge Distillation from Large Model
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大模型的知识蒸馏
- en: Knowledge distillation (Hinton, Vinyals, and Dean [2015](#bib.bib10); Sanh et al.
    [2019](#bib.bib29)) has proven effective for transferring knowledge from a large
    model to a smaller one. This process is usually achieved by optimizing the parameters
    of smaller models so that their outputs (distributions (Feng et al. [2021](#bib.bib6)),
    hidden states (Jiao et al. [2020](#bib.bib15)), attentions (Tang et al. [2019](#bib.bib31)))
    can be closer to that of large models. However, the black-box nature of current
    mainstream LLMs (e.g., GPT4) hinders the application of these methods. Thus, many
    studies (Ho, Schmid, and Yun [2023](#bib.bib11); Fu et al. [2023](#bib.bib7);
    Zhu et al. [2023](#bib.bib41)) have attempted to conduct hard distillation by
    fine-tuning smaller models directly on the LLMs generated responses with correct
    answers. However, as previously mentioned, responses generated by LLMs that contain
    incorrect answers also contain valuable knowledge. Discarding this portion of
    data directly would be a pity, especially considering that a significant portion
    of responses generated by LLMs in complex reasoning tasks end with incorrect answers.
    To this end, we propose multiple methods to fully utilize these abandoned knowledge
    in the process of transferring reasoning abilities of LLMs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 知识蒸馏（Hinton, Vinyals, 和 Dean [2015](#bib.bib10)；Sanh等 [2019](#bib.bib29)）已被证明对将知识从大型模型转移到较小的模型中有效。这个过程通常是通过优化较小模型的参数，使其输出（分布（Feng等
    [2021](#bib.bib6)），隐藏状态（Jiao等 [2020](#bib.bib15)），注意力（Tang等 [2019](#bib.bib31)））更接近大型模型的输出。然而，目前主流LLM（例如GPT4）的黑箱特性阻碍了这些方法的应用。因此，许多研究（Ho,
    Schmid, 和 Yun [2023](#bib.bib11)；Fu等 [2023](#bib.bib7)；Zhu等 [2023](#bib.bib41)）尝试通过对LLM生成的正确答案的回应进行微调来进行硬蒸馏。然而，如前所述，LLM生成的包含错误答案的回应也包含有价值的知识。直接丢弃这部分数据是非常可惜的，特别是考虑到LLM在复杂推理任务中生成的响应中很大一部分以错误答案告终。为此，我们提出了多种方法，以充分利用这些被抛弃的知识，从而转移LLM的推理能力。
- en: Learning From Negative Views
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从负面视角中学习
- en: Samples that reflect some particular undesirable behavior are called negative
    data, which has been studied to help model correct such behavior (He and Glass
    [2020](#bib.bib8); Welleck et al. [2020](#bib.bib36); Lagutin, Gavrilov, and Kalaidin
    [2021](#bib.bib17)). He and Glass ([2020](#bib.bib8)) conducts negative updates
    with training signals provided by negative samples to avoid model generating such
    data. Welleck et al. ([2020](#bib.bib36)); Li et al. ([2020](#bib.bib19)) penalizes
    the model for outputting words with certain characteristics by introducing an
    unlikelihood loss term. Li et al. ([2022](#bib.bib20), [2023](#bib.bib21)) suggests
    maximizing the distance between the predictions of the negative teacher and student.
    These methods only consider the use of negative training signals in negative samples.
    But in fact, negative data can also provide valuable positive knowledge. In this
    work, we investigated how to comprehensively utilize knowledge of negative data
    from both positive and negative perspectives.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 反映一些特定不良行为的样本被称为负数据，研究这些数据有助于模型纠正这种行为（He和Glass [2020](#bib.bib8)；Welleck等 [2020](#bib.bib36)；Lagutin,
    Gavrilov和Kalaidin [2021](#bib.bib17)）。He和Glass（[2020](#bib.bib8)）通过负样本提供的训练信号进行负更新，以避免模型生成这种数据。Welleck等（[2020](#bib.bib36)）；Li等（[2020](#bib.bib19)）通过引入不可能损失项来惩罚模型输出具有特定特征的词汇。Li等（[2022](#bib.bib20)，[2023](#bib.bib21)）建议最大化负教师和学生预测之间的距离。这些方法仅考虑在负样本中使用负训练信号。但事实上，负数据也可以提供有价值的正面知识。在这项工作中，我们研究了如何从正面和负面两个角度全面利用负数据的知识。
- en: Methodology
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法论
- en: '![Refer to caption](img/e5fe938f6462b53e26a93e7a181b6dc9.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e5fe938f6462b53e26a93e7a181b6dc9.png)'
- en: 'Figure 1: The overview of proposed framework. Step 1: Training Neg-LoRA on
    negative samples to assist in the learning of reasoning on positive data through
    Integrate Unit. Step 2: Utilizing Neg-LoRA as baseline to calibrate the process
    of self-enhancement. Step 3: Training a ranking model on both positive and negative
    samples. Then weighting the candidates adaptively during inference according to
    scores from it.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：提出的框架概述。步骤1：在负样本上训练Neg-LoRA，以通过整合单元帮助学习正数据的推理。步骤2：将Neg-LoRA作为基线，以校准自我增强的过程。步骤3：在正负样本上训练排序模型。然后根据其分数在推理过程中自适应地加权候选项。
- en: Background
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 背景
- en: Chain-of-Thought Distillation
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 思维链蒸馏
- en: 'Rajani et al. ([2019](#bib.bib27)) demonstrated that training a language model
    on a dataset with explicit rationales preceding the answer could improve the ability
    to generate the final answer. Thus, chain-of-thought distillation is proposed
    to maximize the manifestation of the reasoning abilities of the LLMs on smaller
    models. Denote $\mathcal{D}=\{(x_{i},y_{i})\}^{N}$ as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Rajani et al. ([2019](#bib.bib27)) 证明了在数据集中用明确的推理过程训练语言模型可以提高生成最终答案的能力。因此，链式思维蒸馏被提出，以最大化小型模型上推理能力的表现。记
    $\mathcal{D}=\{(x_{i},y_{i})\}^{N}$ 如下：
- en: '|  | $\mathbb{E}_{(x,\hat{r},\hat{y})\sim S_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta).$
    |  | (1) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{(x,\hat{r},\hat{y})\sim S_{pos}}\mathrm{log}P(\hat{y},\hat{r}\mid
    x;\theta).$ |  | (1) |'
- en: Self-Enhancement
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自我增强
- en: 'Based on the idea of human self reflection to achieve progress, various methods
    (Huang et al. [2022](#bib.bib14); Xu et al. [2021](#bib.bib37); Mobahi, Farajtabar,
    and Bartlett [2020](#bib.bib25)) have been proposed to strengthen language models
    based on their own knowledge, which we collectively refer to as self-enhancement.
    It consists two common methods: one is self-augmentation (Xu et al. [2021](#bib.bib37)),
    where the model first generates data with diversity and then trains on them to
    achieve better generalization (Huang et al. [2022](#bib.bib14)). The other is
    self-distillation (Zhu et al. [2023](#bib.bib41)), which involves using the model
    itself as teacher to complete iterative distillation, thereby utilizing dark knowledge
    to further improve the performance.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 基于人类自我反思以实现进步的理念，提出了各种方法（Huang et al. [2022](#bib.bib14); Xu et al. [2021](#bib.bib37);
    Mobahi, Farajtabar 和 Bartlett [2020](#bib.bib25)）来加强语言模型的自我知识，我们统称为自我增强。它包括两种常见方法：一种是自我增强（Xu
    et al. [2021](#bib.bib37)），即模型首先生成多样化的数据，然后在这些数据上进行训练以实现更好的泛化（Huang et al. [2022](#bib.bib14)）。另一种是自我蒸馏（Zhu
    et al. [2023](#bib.bib41)），即使用模型自身作为教师完成迭代蒸馏，从而利用暗知识进一步提升性能。
- en: Self-Consistency
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自一致性
- en: 'Self-consistency (Wang et al. [2023](#bib.bib33)) capitalizes on the notion
    that a intricate problem requiring logical thinking usually offers several distinct
    approaches that all lead to the same accurate answer. Based on this, multiple
    candidates $\{(\hat{r}^{l},\hat{y}^{l})\}^{L}$ is selected as the final prediction
    through a voting process:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 自一致性（Wang et al. [2023](#bib.bib33)）利用了这样一个概念：一个需要逻辑思维的复杂问题通常会提供几种不同的方法，所有这些方法都能得出相同的准确答案。基于此，通过投票过程选择多个候选
    $\{(\hat{r}^{l},\hat{y}^{l})\}^{L}$ 作为最终预测：
- en: '|  | $\hat{y}=\arg\max_{i}\sum_{l=1}^{L}\mathbb{I}(\hat{y}^{l}=i)$ |  | (2)
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $\hat{y}=\arg\max_{i}\sum_{l=1}^{L}\mathbb{I}(\hat{y}^{l}=i)$ |  | (2)
    |'
- en: where $\mathbb{I}(\hat{y}^{l}=i)$, and 0 otherwise).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbb{I}(\hat{y}^{l}=i)$，否则为0）。
- en: Negative Assistant Training
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负面辅助训练
- en: 'As shown in Table [1](#Sx1.T1 "Table 1 ‣ Introduction ‣ Turning Dust into Gold:
    Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative Data"),
    negative samples also contains valuable knowledge, which can even serve as a good
    complement to positive data. However, there is an increased risk of inference
    errors for $\hat{r}$. Extracting useful knowledge from negative samples without
    being affected by undesirable behaviors is therefore a challenging task. To address
    this, we propose a two-stage Negative Assistant Training (NAT) Paradigm (Step
    1.1 and 1.2 in Figure [1](#Sx3.F1 "Figure 1 ‣ Methodology ‣ Turning Dust into
    Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative
    Data")).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '如表 [1](#Sx1.T1 "Table 1 ‣ Introduction ‣ Turning Dust into Gold: Distilling
    Complex Reasoning Capabilities from LLMs by Leveraging Negative Data") 所示，负样本也包含有价值的知识，甚至可以作为正数据的良好补充。然而，$\hat{r}$
    的推理错误风险增加。因此，从负样本中提取有用的知识而不受不良行为影响是一个挑战。为此，我们提出了一个两阶段的负面辅助训练（NAT）范式（图 [1](#Sx3.F1
    "Figure 1 ‣ Methodology ‣ Turning Dust into Gold: Distilling Complex Reasoning
    Capabilities from LLMs by Leveraging Negative Data") 中的步骤 1.1 和 1.2）。'
- en: Absorbing Negative Knowledge
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 吸收负面知识
- en: 'First, we acquire the $(x,\hat{r},\hat{y})$ by maximizing the following expectation:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们通过最大化以下期望来获取 $(x,\hat{r},\hat{y})$：
- en: '|  | $\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{neg}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta_{neg}).$
    |  | (3) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{neg}}\mathrm{log}P(\hat{y},\hat{r}\mid
    x;\theta_{neg}).$ |  | (3) |'
- en: During this process, the parameters of LLaMA remain frozen, while the knowledge
    of $\mathcal{D}_{neg}$.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，LLaMA 的参数保持冻结，同时知识来自 $\mathcal{D}_{neg}$。
- en: Dynamic Integration Unit
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 动态集成单元
- en: 'Since it is impossible to pre-determine which mathematical problems $\theta_{neg}$.
    We propose a corrected attention mechanism to achieve this vision as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于不可能预先确定哪些数学问题 $\theta_{neg}$。我们提出了一种修正的注意力机制来实现这一愿景，如下所示：
- en: '|  | $\alpha=W_{Q}(h_{input})W_{K}([h_{pos};h_{neg}])^{T}+[0.5;-0.5]$ |  |
    (4) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | $\alpha=W_{Q}(h_{input})W_{K}([h_{pos};h_{neg}])^{T}+[0.5;-0.5]$ |  |
    (4) |'
- en: '|  | $h_{output}=\alpha\cdot W_{V}([h_{pos};h_{neg}]))$ |  | (5) |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  | $h_{output}=\alpha\cdot W_{V}([h_{pos};h_{neg}]))$ |  | (5) |'
- en: where $W_{Q},W_{K}\in\mathbb{R}^{d\times w}$ and the LLaMA layer outputs forms
    the output of the Dynamic Integrate Unit.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $W_{Q},W_{K}\in\mathbb{R}^{d\times w}$，LLaMA层输出形成动态集成单元的输出。
- en: By employing NAT, $\mathcal{M}_{NAT}$ can inherit LLM’s knowledge more comprehensively
    in both dimensions of diversity (more samples) and type (both positive and negative
    data), leading to improved complex reasoning abilities.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用NAT，$\mathcal{M}_{NAT}$ 可以在多样性（更多样本）和类型（正负数据）两个维度上更全面地继承LLM的知识，从而提高复杂推理能力。
- en: '![Refer to caption](img/d618747d636630eaebb46febc77ff2ec.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d618747d636630eaebb46febc77ff2ec.png)'
- en: 'Figure 2: The workflow of Integrate Unit. The outputs of both Neg-LoRA and
    Pos-LoRA are fused through a corrected attention mechanism.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：集成单元的工作流程。Neg-LoRA和Pos-LoRA的输出通过修正的注意力机制进行融合。
- en: Negative Calibrated Enhancement
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负面校准增强
- en: To further strengthen the reasoning ability of the model, we propose Negative
    Calibrated Enhancement (NCE) that use negative knowledge to aid with the self-enhancement
    process (Zhu et al. [2023](#bib.bib41); Huang et al. [2022](#bib.bib14)). We first
    use $\mathcal{M}_{NAT}$.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步增强模型的推理能力，我们提出了负面校准增强（NCE），利用负面知识辅助自我增强过程（Zhu et al. [2023](#bib.bib41);
    Huang et al. [2022](#bib.bib14)）。我们首先使用 $\mathcal{M}_{NAT}$。
- en: '|  | $1$2 |  | (6) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (6) |'
- en: '|  | $\beta=\mathrm{Tanh}(f_{\text{KL}}(\theta_{neg},\theta_{NAT}))$ |  | (7)
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | $\beta=\mathrm{Tanh}(f_{\text{KL}}(\theta_{neg},\theta_{NAT}))$ |  | (7)
    |'
- en: '|  | $1$2 |  | (8) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (8) |'
- en: A larger $\beta$.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的 $\beta$
- en: Adaptive Self-Consistency
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自适应自一致性
- en: Self-Consistency (SC) technique (Wang et al. [2023](#bib.bib33)) is effective
    for further improving the performance of models in complex reasoning (Zhu et al.
    [2023](#bib.bib41)). However, current methods either naively assign equal weights
    to each candidate or simply assign weights based on generation probabilities.
    These strategies fail to adjust the weights of candidates based on the quality
    of ($\hat{r},\hat{y}$ that can adaptively reweight candidates with justification.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 自一致性（SC）技术（Wang et al. [2023](#bib.bib33)）对进一步提升模型在复杂推理中的表现有效（Zhu et al. [2023](#bib.bib41)）。然而，目前的方法要么简单地对每个候选项分配相等的权重，要么仅根据生成概率分配权重。这些策略无法根据（$\hat{r},\hat{y}$的质量来调整候选项的权重，从而适应性地重新加权候选项。
- en: '| Models | Methods | Counting& Probability | Inter Algebra | Number Theory
    | Precalculus | Prealgebra | Geometry | Algebra | Average |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 方法 | 计数与概率 | 代数 | 数论 | 预备微积分 | 预备代数 | 几何 | 代数 | 平均值 |'
- en: '| PaLM 62B | Few-shot | - | - | - | - | - | - | - | 4.4 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| PaLM 62B | Few-shot | - | - | - | - | - | - | - | 4.4 |'
- en: '| PaLM 540B | Few-shot | - | - | - | - | - | - | - | 8.8 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| PaLM 540B | Few-shot | - | - | - | - | - | - | - | 8.8 |'
- en: '| GPT3 175B | Few-shot | 4.7 | 4.4 | 4.4 | 4.0 | 7.7 | 3.1 | 6.0 | 5.2 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| GPT3 175B | Few-shot | 4.7 | 4.4 | 4.4 | 4.0 | 7.7 | 3.1 | 6.0 | 5.2 |'
- en: '| GPT3 13B | Fine-tune | 4.1 | 4.7 | 5.5 | 5.8 | 6.8 | 7.1 | 5.3 | 5.6 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| GPT3 13B | 微调 | 4.1 | 4.7 | 5.5 | 5.8 | 6.8 | 7.1 | 5.3 | 5.6 |'
- en: '| LLaMA 7B | Fine-tune | 2.96 | 3.58 | 2.96 | 3.85 | 4.61 | 3.46 | 4.56 | 3.88
    +0% |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA 7B | 微调 | 2.96 | 3.58 | 2.96 | 3.85 | 4.61 | 3.46 | 4.56 | 3.88 +0%
    |'
- en: '| GPT-3.5 Turbo CoT | CoT KD | 4.15 | 4.17 | 5.37 | 4.58 | 8.82 | 4.54 | 4.61
    | 5.29 +36.3% |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 Turbo CoT | CoT KD | 4.15 | 4.17 | 5.37 | 4.58 | 8.82 | 4.54 | 4.61
    | 5.29 +36.3% |'
- en: '| MIX | 3.49 | 1.43 | 1.67 | 1.46 | 5.27 | 2.59 | 4.05 | 3.03 -21.9% |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| MIX | 3.49 | 1.43 | 1.67 | 1.46 | 5.27 | 2.59 | 4.05 | 3.03 -21.9% |'
- en: '| CL | 4.64 | 3.93 | 5.74 | 4.03 | 7.39 | 2.51 | 5.98 | 5.16 +33.0% |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| CL | 4.64 | 3.93 | 5.74 | 4.03 | 7.39 | 2.51 | 5.98 | 5.16 +33.0% |'
- en: '| NT | 3.93 | 3.93 | 6.30 | 2.20 | 6.69 | 4.10 | 5.17 | 4.48 +15.4% |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| NT | 3.93 | 3.93 | 6.30 | 2.20 | 6.69 | 4.10 | 5.17 | 4.48 +15.4% |'
- en: '| UL | 4.98 | 3.86 | 5.37 | 3.85 | 6.70 | 4.10 | 5.27 | 4.96 +27.8% |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| UL | 4.98 | 3.86 | 5.37 | 3.85 | 6.70 | 4.10 | 5.27 | 4.96 +27.8% |'
- en: '| NAT | 5.70 | 5.24 | 6.67 | 3.85 | 9.99 | 5.64 | 7.94 | 6.81 +75.5% |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| NAT | 5.70 | 5.24 | 6.67 | 3.85 | 9.99 | 5.64 | 7.94 | 6.81 +75.5% |'
- en: '| GPT-4 CoT | CoT KD | 3.71 | 4.88 | 6.30 | 3.30 | 6.56 | 3.67 | 7.73 | 5.59
    +44.1% |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 CoT | CoT KD | 3.71 | 4.88 | 6.30 | 3.30 | 6.56 | 3.67 | 7.73 | 5.59
    +44.1% |'
- en: '| MIX | 3.28 | 2.86 | 2.96 | 4.21 | 5.45 | 3.55 | 6.66 | 4.49 +15.7% |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| MIX | 3.28 | 2.86 | 2.96 | 4.21 | 5.45 | 3.55 | 6.66 | 4.49 +15.7% |'
- en: '| CL | 4.15 | 3.67 | 5.00 | 3.11 | 7.90 | 5.43 | 5.98 | 5.24 +35.1% |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| CL | 4.15 | 3.67 | 5.00 | 3.11 | 7.90 | 5.43 | 5.98 | 5.24 +35.1% |'
- en: '| NT | 3.28 | 2.46 | 4.07 | 3.85 | 8.92 | 6.05 | 5.97 | 5.14 +32.4% |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| NT | 3.28 | 2.46 | 4.07 | 3.85 | 8.92 | 6.05 | 5.97 | 5.14 +32.4% |'
- en: '| UL | 4.15 | 3.46 | 6.67 | 3.11 | 8.67 | 5.18 | 8.25 | 6.03 +55.4% |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| UL | 4.15 | 3.46 | 6.67 | 3.11 | 8.67 | 5.18 | 8.25 | 6.03 +55.4% |'
- en: '| NAT | 6.11 | 4.65 | 5.56 | 4.58 | 8.50 | 4.92 | 9.78 | 6.83 +76.0% |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| NAT | 6.11 | 4.65 | 5.56 | 4.58 | 8.50 | 4.92 | 9.78 | 6.83 +76.0% |'
- en: 'Table 2: Experimental results (%) on MATH test set for NAT. We report the accuracy
    (solving rate) of math problems for each test set. Average is the mean value of
    all subjects. GPT3 and PaLM are from Hendrycks et al. ([2021](#bib.bib9)) and
    Lewkowycz et al. ([2022](#bib.bib18)), respectively. Comparing with standard fine-tune,
    NAT achieves about 75.75% increase.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：NAT在MATH测试集上的实验结果（%）。我们报告了每个测试集的数学问题准确率（解决率）。平均值是所有学科的均值。GPT3和PaLM分别来自Hendrycks等（[2021](#bib.bib9)）和Lewkowycz等（[2022](#bib.bib18)）。与标准微调相比，NAT的提升约为75.75%。
- en: Ranking Model Training.
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 排序模型训练。
- en: 'Ideally, we hope that $\mathcal{M}_{rank}$ in the following way:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望$\mathcal{M}_{rank}$以以下方式进行：
- en: '|  | $1$2 |  | (9) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (9) |'
- en: 'and use MSE loss to train $\mathcal{M}_{rank}$:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用均方误差（MSE）损失来训练$\mathcal{M}_{rank}$：
- en: '|  | $\mathcal{L}_{RM}=\sum_{i=1}^{N}\&#124;\mathcal{M}_{rank}(p_{i})-q_{i}\&#124;_{2}$
    |  | (10) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}_{RM}=\sum_{i=1}^{N}\&#124;\mathcal{M}_{rank}(p_{i})-q_{i}\&#124;_{2}$
    |  | (10) |'
- en: Weighting Policy.
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 加权策略。
- en: 'Building upon the foundation of $\mathcal{M}_{rank}$, we revise Eq. ([2](#Sx3.E2
    "In Self-Consistency ‣ Background ‣ Methodology ‣ Turning Dust into Gold: Distilling
    Complex Reasoning Capabilities from LLMs by Leveraging Negative Data")) to Eq. ([11](#Sx3.E11
    "In Weighting Policy. ‣ Adaptive Self-Consistency ‣ Methodology ‣ Turning Dust
    into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative
    Data")) to achieve the vision of adaptively reweighting the candidates reasonably.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在$\mathcal{M}_{rank}$的基础上，我们将方程修正为 Eq. ([2](#Sx3.E2 "在自一致性 ‣ 背景 ‣ 方法 ‣ 将尘土转化为黄金：通过利用负数据提炼复杂推理能力"))
    到 Eq. ([11](#Sx3.E11 "在加权策略。 ‣ 自适应自一致性 ‣ 方法 ‣ 将尘土转化为黄金：通过利用负数据提炼复杂推理能力"))，以实现合理自适应重新加权候选项的愿景。
- en: '|  | $1$2 |  | (11) |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | $1$2 |  | (11) |'
- en: From the view of knowledge transfer, ASC achieves further utilization of knowledge
    ( positive and negative) embedded in LLMs to help smaller models attain better
    performance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从知识迁移的角度来看，ASC实现了对LLMs中嵌入的知识（正面和负面）的进一步利用，以帮助较小的模型获得更好的性能。
- en: Experiments
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验
- en: Experimental Setup
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验设置
- en: 'This work focuses on the challenging competition mathematical dataset MATH
    (Hendrycks et al. [2021](#bib.bib9)), which has 12,500 problems in total spanning
    seven various subjects. Besides, the following four datasets are introduced to
    evaluate the generalization ability on out-of-distribution (OOD) data of the proposed
    framework: GSM8K (Cobbe et al. [2021](#bib.bib5)), ASDiv (Miao, Liang, and Su
    [2020](#bib.bib24)), MultiArith (Roy and Roth [2015](#bib.bib28)), and SVAMP (Patel,
    Bhattamishra, and Goyal [2021](#bib.bib26)). Detailed data statistics are shown
    in Appendix.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究集中于具有挑战性的竞争性数学数据集MATH（Hendrycks等 [2021](#bib.bib9)），该数据集总共有12,500个问题，涵盖七个不同的学科。此外，还引入了以下四个数据集，以评估所提出框架在分布外（OOD）数据上的泛化能力：GSM8K（Cobbe等
    [2021](#bib.bib5)），ASDiv（Miao, Liang, and Su [2020](#bib.bib24)），MultiArith（Roy
    and Roth [2015](#bib.bib28)），和SVAMP（Patel, Bhattamishra, and Goyal [2021](#bib.bib26)）。详细的数据统计见附录。
- en: For teacher model, we use gpt-3.5-turbo and gpt-4 API from OpeanAI to synthesize
    reasoning chains. Given that the problems of MATH are challenging, we select LLaMA-7b
    as the student model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于教师模型，我们使用来自OpeanAI的gpt-3.5-turbo和gpt-4 API来合成推理链。鉴于MATH问题的挑战性，我们选择LLaMA-7b作为学生模型。
- en: 'There are two main types of baselines in our study: one includes LLMs, while
    the other is based on LLaMA-7b. In the case of LLMs, we compare with two popular
    models: GPT3 (Brown et al. [2020](#bib.bib1)) and PaLM (Chowdhery et al. [2022](#bib.bib4)).
    As for LLaMA-7b, we first provide a comparison of our method with three settings:
    Few-shot, Fine-tune (on original training samples), CoT KD (chain-of-thought distillation).
    In terms of learning from negative views, four baseline methods will be further
    included: MIX (directly trains LLaMA with the mixture of both positive and negative
    data), CL (contrastive learning), NT (negative training) (He and Glass [2020](#bib.bib8))
    and UL (unlikelihood) (Welleck et al. [2020](#bib.bib36)). Please see Appendix
    for the details of these baselines. The evaluations of NCE and ASC will also include
    some other baselines that will be introduced in corresponding parts.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究中有两种主要类型的基准：一种包括 LLMs，另一种基于 LLaMA-7b。在 LLMs 的情况下，我们与两个流行的模型进行比较：GPT3（Brown
    等 [2020](#bib.bib1)）和 PaLM（Chowdhery 等 [2022](#bib.bib4)）。至于 LLaMA-7b，我们首先提供了我们的方法与三种设置的比较：少样本、微调（在原始训练样本上）、CoT
    KD（思维链蒸馏）。在从负面视角学习方面，将进一步包括四种基准方法：MIX（直接用正负数据混合训练 LLaMA）、CL（对比学习）、NT（负训练）（He 和
    Glass [2020](#bib.bib8)）和 UL（不太可能）（Welleck 等 [2020](#bib.bib36)）。有关这些基准的详细信息，请参见附录。NCE
    和 ASC 的评估还将包括一些将在相应部分介绍的其他基准。
- en: Main Results
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主要结果
- en: Native Assistant Training
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 原生助手训练
- en: 'The evaluation results of NAT are presented in Table [2](#Sx3.T2 "Table 2 ‣
    Adaptive Self-Consistency ‣ Methodology ‣ Turning Dust into Gold: Distilling Complex
    Reasoning Capabilities from LLMs by Leveraging Negative Data"), with all methods
    using greedy search (i.e. temperature = 0). It shows that proposed method NAT
    improves task accuracy across all baselines. It can be seen from the low values
    of GPT3 and PaLM that MATH is a very difficult math dataset, but NAT can still
    accomplish competitive performance with much less parameters. Comparing with fine-tuning
    on the original data, NAT achieves about 75.75% increase under two different CoT
    sources. In comparison with CoT KD on positive samples, the mainstream specialization
    pattern, NAT also improves accuracy significantly, demonstrating the value of
    negative samples. As for baselines to utilize negative information, the lowest
    performance of MIX suggests that directly training the negative samples will make
    model toxic. Other methods are also mostly inferior to NAT, which indicates that
    using negative samples only in the negative direction is not sufficient in complex
    reasoning tasks.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 'NAT 的评估结果展示在表格 [2](#Sx3.T2 "Table 2 ‣ Adaptive Self-Consistency ‣ Methodology
    ‣ Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs
    by Leveraging Negative Data") 中，所有方法均使用贪婪搜索（即温度 = 0）。结果显示，所提议的方法 NAT 在所有基准测试中提高了任务的准确性。从
    GPT3 和 PaLM 的低值可以看出，MATH 是一个非常困难的数学数据集，但 NAT 仍能以较少的参数实现竞争性的表现。与在原始数据上进行微调相比，NAT
    在两个不同的 CoT 来源下实现了约 75.75% 的提升。与正样本上的 CoT KD 相比，主流的专门化模式，NAT 也显著提高了准确性，展示了负样本的价值。至于利用负信息的基准测试，MIX
    的最低性能表明，直接训练负样本会使模型变得有毒。其他方法大多也不如 NAT，这表明在复杂推理任务中，仅在负方向上使用负样本是不足够的。'
- en: '![Refer to caption](img/9495a6388382070c594646fa318a70a7.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9495a6388382070c594646fa318a70a7.png)'
- en: 'Figure 3: Experimental results (%) of NCE. KD denotes knowledge distillation
    with data augmentation.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：NCE 的实验结果（%）。KD 表示使用数据增强的知识蒸馏。
- en: Negative Calibrated Enhancement
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 负向校准增强
- en: 'The main results under the data of gpt-3.5-turbo of NCE are shown in Figure [3](#Sx4.F3
    "Figure 3 ‣ Native Assistant Training ‣ Main Results ‣ Experiments ‣ Turning Dust
    into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative
    Data"). Compared with knowledge distillation (KD), NCE achieves an average progress
    of 10% (0.66), which demonstrates the effectiveness of distillation with calibration
    information offered by negative samples. Although NCE reduced some parameters
    (e.g., Neg-LoRA) compared to NAT, it still achieved a progress of 6.5% (0.44),
    implementing compressed model and improved performance.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [3](#Sx4.F3 "Figure 3 ‣ Native Assistant Training ‣ Main Results ‣ Experiments
    ‣ Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs
    by Leveraging Negative Data") 显示了 gpt-3.5-turbo 数据下 NCE 的主要结果。与知识蒸馏 (KD) 相比，NCE
    实现了 10%（0.66）的平均进展，这证明了使用负样本提供的校准信息进行蒸馏的有效性。虽然 NCE 相比于 NAT 减少了一些参数（例如，Neg-LoRA），但它仍然实现了
    6.5%（0.44）的进展，实施了压缩模型并改善了性能。'
- en: Adaptive Self-Consistency
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自适应自一致性
- en: '| Models | Strategies | CP | NT | PC | A* | Ave |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 策略 | CP | NT | PC | A* | 平均 |'
- en: '| CoT KD | SC | 7.38 | 6.62 | 5.70 | 8.70 | 7.85 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| CoT KD | SC | 7.38 | 6.62 | 5.70 | 8.70 | 7.85 |'
- en: '| SC wWS | 7.22 | 6.64 | 5.75 | 8.52 | 7.82 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| SC wWS | 7.22 | 6.64 | 5.75 | 8.52 | 7.82 |'
- en: '| ASC | 7.70 | 6.97 | 6.16 | 9.12 | 8.25 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| ASC | 7.70 | 6.97 | 6.16 | 9.12 | 8.25 |'
- en: '| NAT | SC | 8.65 | 7.49 | 5.75 | 11.14 | 9.25 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| NAT | SC | 8.65 | 7.49 | 5.75 | 11.14 | 9.25 |'
- en: '| SC wWS | 8.67 | 7.34 | 5.77 | 11.08 | 9.21 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| SC wWS | 8.67 | 7.34 | 5.77 | 11.08 | 9.21 |'
- en: '| ASC | 9.30 | 8.33 | 5.83 | 11.88 | 9.84 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| ASC | 9.30 | 8.33 | 5.83 | 11.88 | 9.84 |'
- en: '| NCE | SC | 9.21 | 7.94 | 5.96 | 11.32 | 9.69 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| NCE | SC | 9.21 | 7.94 | 5.96 | 11.32 | 9.69 |'
- en: '| SC wWS | 9.13 | 7.84 | 5.99 | 11.25 | 9.64 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| SC wWS | 9.13 | 7.84 | 5.99 | 11.25 | 9.64 |'
- en: '| ASC | 9.87 | 8.21 | 6.37 | 11.89 | 10.23 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| ASC | 9.87 | 8.21 | 6.37 | 11.89 | 10.23 |'
- en: 'Table 3: Experimental results (%) on MATH for ASC. A* is the average of InterAlgebra,
    Prealgebra and Algebra.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: ASC 在 MATH 上的实验结果（%）。A* 是 InterAlgebra、Prealgebra 和 Algebra 的平均值。'
- en: 'To evaluate ASC, we compare it with base SC and its weighted sum (WS) version.
    We generate 16 samples with sampling temperature $T=1$. The results from Table [3](#Sx4.T3
    "Table 3 ‣ Adaptive Self-Consistency ‣ Main Results ‣ Experiments ‣ Turning Dust
    into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative
    Data") shows that ASC is a more promising strategy to aggregate the answers from
    different samples. SC with WS doesn’t outperform base SC, which is consistent
    with Wang et al. ([2023](#bib.bib33)). Note that the accuracy of ranking model
    is only about 60%, indicating that the performance of ASC can be further improved
    with higher accuracy. Refer to Accuracy of Ranking Model for detailed analysis.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估 ASC，我们将其与基础 SC 及其加权和（WS）版本进行比较。我们生成了 16 个样本，采样温度为 $T=1$。表[3](#Sx4.T3 "表
    3 ‣ 自适应自洽 ‣ 主要结果 ‣ 实验 ‣ 让尘土变成黄金: 通过利用负面数据从 LLM 中蒸馏复杂推理能力") 中的结果表明，ASC 是聚合不同样本答案的更有前景的策略。SC
    和 WS 的结合未能超越基础 SC，这与 Wang 等人（[2023](#bib.bib33)）的结论一致。值得注意的是，排名模型的准确率仅约为 60%，这表明
    ASC 的性能可以通过更高的准确率进一步提高。有关详细分析，请参阅排名模型的准确性。'
- en: Analysis
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析
- en: In order to better understand the usefulness of the negative knowledge and the
    effectiveness of our framework, we carry out extensive analysis on LLaMA distilled
    from gpt-3.5-turbo in terms of both quantitative and qualitative measures.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解负面知识的有效性和我们框架的有效性，我们对从 gpt-3.5-turbo 蒸馏的 LLaMA 进行了定量和定性措施的广泛分析。
- en: Generalization
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 泛化
- en: '| Methods | GSM8K | ASDiv | MultiArith | SVAMP |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | GSM8K | ASDiv | MultiArith | SVAMP |'
- en: '| Fine-tune | 17.51 | 36.37 | 53.17 | 17.90 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 17.51 | 36.37 | 53.17 | 17.90 |'
- en: '| CoT KD | 38.81 | 76.43 | 83.5 | 47.40 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| CoT KD | 38.81 | 76.43 | 83.5 | 47.40 |'
- en: '| NAT | 41.24 | 76.11 | 84.67 | 47.20 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| NAT | 41.24 | 76.11 | 84.67 | 47.20 |'
- en: '| KD | 41.55 | 75.86 | 88.05 | 50.70 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| KD | 41.55 | 75.86 | 88.05 | 50.70 |'
- en: '| NCE | 41.93 | 77.67 | 88.67 | 51.50 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| NCE | 41.93 | 77.67 | 88.67 | 51.50 |'
- en: 'Table 4: Generalization evaluation results (%).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 泛化评估结果（%）。'
- en: Besides MATH dataset, we evaluate the generalization ability of proposed framework.
    Following Fu et al. ([2023](#bib.bib7)), we only synthesize data and train the
    models on GSM8K and evaluate on all the four test sets. The higher performance
    of NAT and NCE on GSM8K indicates that the proposed method can generalize to previously
    commonly used dataset in the field of model specialization. NCE outperforms others
    in A-M-S datasets suggests that the calibrated dark knowledge from logits distributions
    can improve out-of-distribution (OOD) performance.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 MATH 数据集外，我们还评估了提出框架的泛化能力。参考 Fu 等人（[2023](#bib.bib7)），我们仅在 GSM8K 上合成数据并训练模型，并在所有四个测试集上进行评估。NAT
    和 NCE 在 GSM8K 上的较高性能表明，提出的方法可以泛化到模型专业化领域中之前常用的数据集。NCE 在 A-M-S 数据集上的优越表现表明，从 logits
    分布中校准的隐性知识可以改善分布外（OOD）性能。
- en: Ablation study
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 消融研究
- en: '| Methods | CP | NT | PC | G | A* | Ave |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | CP | NT | PC | G | A* | 平均 |'
- en: '| NAT | 5.70 | 6.67 | 3.85 | 5.64 | 7.72 | 6.81 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| NAT | 5.70 | 6.67 | 3.85 | 5.64 | 7.72 | 6.81 |'
- en: '| - Neg Data | 6.55 | 4.63 | 4.40 | 3.97 | 7.88 | 6.58 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| - Neg Data | 6.55 | 4.63 | 4.40 | 3.97 | 7.88 | 6.58 |'
- en: '| - Neg LoRA | 5.02 | 4.81 | 5.31 | 4.75 | 7.27 | 6.05 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| - Neg LoRA | 5.02 | 4.81 | 5.31 | 4.75 | 7.27 | 6.05 |'
- en: '| - Att | 2.84 | 5.19 | 4.21 | 4.38 | 5.99 | 5.22 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| - Att | 2.84 | 5.19 | 4.21 | 4.38 | 5.99 | 5.22 |'
- en: '| - Dual | 7.38 | 5.37 | 4.21 | 4.80 | 6.87 | 6.30 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| - Dual | 7.38 | 5.37 | 4.21 | 4.80 | 6.87 | 6.30 |'
- en: 'Table 5: Ablation study results (%) for NAT.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '表 5: NAT 的消融研究结果（%）。'
- en: 'To demonstrate the necessity of each component in NAT, we take a series of
    ablation study by removing the following parts: (1) Neg Data: The whole dual LoRA
    structure and attention integration only on positive data. (2) Neg LoRA: Based
    on (1), the negative LoRA will be further removed. (3) Att: Instead of the attention
    mechanism, we integrate two LoRA modules by a gated function. (4) Dual: We modify
    the range of Equation [4](#Sx3.E4 "In Dynamic Integration Unit ‣ Negative Assistant
    Training ‣ Methodology ‣ Turning Dust into Gold: Distilling Complex Reasoning
    Capabilities from LLMs by Leveraging Negative Data") to [0, 1] rather than [-0.5,
    0,5], which means the knowledge from negative LoRA can only be absorbed from positive
    way.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明NAT中每个组件的必要性，我们进行了一系列消融研究，通过去除以下部分：（1）Neg Data：仅在正数据上集成整个双LoRA结构和注意力。（2）Neg
    LoRA：基于（1），进一步移除负LoRA。（3）Att：代替注意力机制，我们通过门控函数集成两个LoRA模块。（4）Dual：我们将方程[4](#Sx3.E4
    "在动态集成单元 ‣ 负辅助训练 ‣ 方法论 ‣ 将尘土变成黄金：通过利用负数据提炼复杂推理能力")的范围修改为[0, 1]，而不是[-0.5, 0.5]，这意味着负LoRA的知识只能以正面的方式吸收。
- en: 'The results are shown in Table [5](#Sx4.T5 "Table 5 ‣ Ablation study ‣ Analysis
    ‣ Experiments ‣ Turning Dust into Gold: Distilling Complex Reasoning Capabilities
    from LLMs by Leveraging Negative Data"). When filtering negative samples with
    same model structure, we find that model accuracy decreases, confirming the value
    of negative knowledge. Further removing the negative LoRA illustrates the importance
    of dual LoRA structure. The performance drops dramatically without attention mechanism,
    indicating it plays an important role in integrating LoRA modules. When changing
    the range of $\alpha$ to [0, 1], which forces positive LoRA to add the knowledge
    from negative LoRA without the minus option. The lower accuracy suggests that
    avoiding being influenced by undesirable behaviors while extracting useful knowledge
    from negative samples is necessary.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 结果见表[5](#Sx4.T5 "表 5 ‣ 消融研究 ‣ 分析 ‣ 实验 ‣ 将尘土变成黄金：通过利用负数据提炼复杂推理能力")。在使用相同模型结构筛选负样本时，我们发现模型准确性下降，确认了负知识的价值。进一步移除负LoRA显示了双LoRA结构的重要性。没有注意机制时性能急剧下降，表明它在整合LoRA模块中起着重要作用。当将$\alpha$的范围改为[0,
    1]时，强制正LoRA从负LoRA中获取知识而没有减去选项。较低的准确性表明，在从负样本中提取有用知识的同时避免受到不良行为影响是必要的。
- en: Attention
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意力
- en: '![Refer to caption](img/6bf7420cc914abb356d05c94face0912.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6bf7420cc914abb356d05c94face0912.png)'
- en: 'Figure 4: Analysis of $\alpha_{neg}$ along dimensions of: token position, question
    level, and question subject.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：沿着以下维度分析$\alpha_{neg}$：令牌位置、问题级别和问题主题。
- en: 'To fully comprehend how knowledge from $\mathcal{M}_{neg}$ in Eq. ([4](#Sx3.E4
    "In Dynamic Integration Unit ‣ Negative Assistant Training ‣ Methodology ‣ Turning
    Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging
    Negative Data"))) along 3 dimensions: token position, question level, and question
    subject.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面理解来自$\mathcal{M}_{neg}$的知识如何在3个维度上：（1）令牌位置，（2）问题级别，（3）问题主题。
- en: 'As shown in the Figure [4](#Sx4.F4 "Figure 4 ‣ Attention ‣ Analysis ‣ Experiments
    ‣ Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs
    by Leveraging Negative Data"), as the position of the generated token increases,
    $\alpha_{neg}$ can play a greater role in addressing challenging subjects during
    NAT.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[4](#Sx4.F4 "图 4 ‣ 注意力 ‣ 分析 ‣ 实验 ‣ 将尘土变成黄金：通过利用负数据提炼复杂推理能力")所示，随着生成令牌的位置增加，$\alpha_{neg}$在处理NAT中的挑战性主题时可以发挥更大的作用。
- en: Accuracy of Ranking Model
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 排名模型的准确性
- en: '![Refer to caption](img/6f505b33112740ec3fb8252fb82b0625.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6f505b33112740ec3fb8252fb82b0625.png)'
- en: 'Figure 5: Relationship between the accuracy of distinguishing positive and
    negative rationales of $\mathcal{M}_{rank}$ and the improvement brought by ASC.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：$\mathcal{M}_{rank}$区分正负理由的准确性与ASC带来的改进之间的关系。
- en: We further explore the relationship between $\mathcal{M}_{rank}$ is only around
    60% and yet it can significantly enhance the effectiveness of SC, we believe that
    there is substantial room for improvement in ASC.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步探讨了$\mathcal{M}_{rank}$的准确性仅约60%，而它仍能显著提升SC的效果，我们相信ASC还有很大的改进空间。
- en: '![Refer to caption](img/edb9fae7f81b8b7a6d5d0a7414035f63.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/edb9fae7f81b8b7a6d5d0a7414035f63.png)'
- en: 'Figure 6: An intuitive example shows the strength of ASC.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：一个直观的示例展示了ASC的强大。
- en: Case Study about Adaptive Self-Consistency
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 关于自适应自一致性的案例研究
- en: 'We provide an intuitive example (Figure [6](#Sx4.F6 "Figure 6 ‣ Accuracy of
    Ranking Model ‣ Analysis ‣ Experiments ‣ Turning Dust into Gold: Distilling Complex
    Reasoning Capabilities from LLMs by Leveraging Negative Data")) to show the superiority
    of ASC. In this example, deceptive candidate 1 is chosen as the prediction by
    SC due to having more votes than the correct candidate 3\. $\mathcal{M}_{rank}$
    adjusts the weights of the eight candidates based on rationales, resulting in
    the reweighted correct candidate 3 obtaining a higher vote count.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个直观的示例（图 [6](#Sx4.F6 "图 6 ‣ 排名模型的准确性 ‣ 分析 ‣ 实验 ‣ 将尘土变成黄金：通过利用负面数据提炼大语言模型的复杂推理能力")），展示了ASC的优越性。在这个示例中，由于欺骗性候选项
    1 的投票数多于正确的候选项 3，SC 选择了欺骗性候选项 1 作为预测结果。$\mathcal{M}_{rank}$ 根据理由调整了八个候选项的权重，使得重新加权后的正确候选项
    3 获得了更高的投票数。
- en: Conclusion
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This work explores the effectiveness of negative data for distilling the complex
    reasoning ability from large language models to specialized small ones. We propose
    a novel framework, consisting of three progressive steps and fully leveraging
    the negative information through the entire process of model specialization. Negative
    assistant training can provide a more comprehensive way to employ the negative
    information from two aspects. Negative calibrated enhancement is able to calibrate
    the process of distillation, making it more targeted on crucial knowledge. Ranking
    model trained on two views of rationales can assign appropriate weights for answer
    aggregation to achieve adaptive self-consistency. Extensive experiments demonstrate
    that our framework can improve the effectiveness of distilling reasoning ability
    by the generated negative samples.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作探讨了负面数据在将大语言模型的复杂推理能力提炼到专门的小模型中的有效性。我们提出了一个新颖的框架，包括三个渐进步骤，并通过模型专门化的整个过程充分利用负面信息。负面助理训练可以从两个方面提供更全面的方式来使用负面信息。负面校准增强能够校准提炼过程，使其更加针对关键知识。基于两个观点的排名模型可以为答案聚合分配适当的权重，以实现自适应一致性。大量实验表明，我们的框架能够通过生成的负面样本提高推理能力的提炼效果。
- en: Acknowledgments
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by Beijing Natural Science Foundation (No.4222037, L181010).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到了北京市自然科学基金（编号：4222037，L181010）的支持。
- en: References
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Brown et al. (2020) Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan,
    J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal,
    S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler,
    D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray,
    S.; Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever,
    I.; and Amodei, D. 2020. Language Models are Few-Shot Learners. In *Advances in
    Neural Information Processing Systems 33: Annual Conference on Neural Information
    Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual*.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人（2020）Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.; Dhariwal,
    P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-Voss,
    A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.;
    Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.; Chess, B.;
    Clark, J.; Berner, C.; McCandlish, S.; Radford, A.; Sutskever, I.; 和 Amodei, D.
    2020. 语言模型是少样本学习者。发表于 *神经信息处理系统进展 33：2020 年神经信息处理系统年会，NeurIPS 2020，2020 年 12 月
    6-12 日，虚拟*。
- en: 'Bubeck et al. (2023a) Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.;
    Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y. T.; Li, Y.; Lundberg, S. M.; Nori, H.;
    Palangi, H.; Ribeiro, M. T.; and Zhang, Y. 2023a. Sparks of Artificial General
    Intelligence: Early experiments with GPT-4. *CoRR*, abs/2303.12712.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bubeck 等人（2023a）Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz,
    E.; Kamar, E.; Lee, P.; Lee, Y. T.; Li, Y.; Lundberg, S. M.; Nori, H.; Palangi,
    H.; Ribeiro, M. T.; 和 Zhang, Y. 2023a. 人工通用智能的火花：GPT-4 的早期实验。*CoRR*, abs/2303.12712。
- en: 'Bubeck et al. (2023b) Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.;
    Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y. T.; Li, Y.; Lundberg, S. M.; Nori, H.;
    Palangi, H.; Ribeiro, M. T.; and Zhang, Y. 2023b. Sparks of Artificial General
    Intelligence: Early experiments with GPT-4. *CoRR*, abs/2303.12712.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bubeck 等人（2023b）Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz,
    E.; Kamar, E.; Lee, P.; Lee, Y. T.; Li, Y.; Lundberg, S. M.; Nori, H.; Palangi,
    H.; Ribeiro, M. T.; 和 Zhang, Y. 2023b. 人工通用智能的火花：GPT-4 的早期实验。*CoRR*, abs/2303.12712。
- en: 'Chowdhery et al. (2022) Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,
    G.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.; Gehrmann, S.; Schuh, P.;
    Shi, K.; Tsvyashchenko, S.; Maynez, J.; Rao, A.; Barnes, P.; Tay, Y.; Shazeer,
    N.; Prabhakaran, V.; Reif, E.; Du, N.; Hutchinson, B.; Pope, R.; Bradbury, J.;
    Austin, J.; Isard, M.; Gur-Ari, G.; Yin, P.; Duke, T.; Levskaya, A.; Ghemawat,
    S.; Dev, S.; Michalewski, H.; Garcia, X.; Misra, V.; Robinson, K.; Fedus, L.;
    Zhou, D.; Ippolito, D.; Luan, D.; Lim, H.; Zoph, B.; Spiridonov, A.; Sepassi,
    R.; Dohan, D.; Agrawal, S.; Omernick, M.; Dai, A. M.; Pillai, T. S.; Pellat, M.;
    Lewkowycz, A.; Moreira, E.; Child, R.; Polozov, O.; Lee, K.; Zhou, Z.; Wang, X.;
    Saeta, B.; Diaz, M.; Firat, O.; Catasta, M.; Wei, J.; Meier-Hellstern, K.; Eck,
    D.; Dean, J.; Petrov, S.; and Fiedel, N. 2022. PaLM: Scaling Language Modeling
    with Pathways. *CoRR*, abs/2204.02311.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chowdhery 等人（2022）Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,
    G.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.; Gehrmann, S.; Schuh, P.;
    Shi, K.; Tsvyashchenko, S.; Maynez, J.; Rao, A.; Barnes, P.; Tay, Y.; Shazeer,
    N.; Prabhakaran, V.; Reif, E.; Du, N.; Hutchinson, B.; Pope, R.; Bradbury, J.;
    Austin, J.; Isard, M.; Gur-Ari, G.; Yin, P.; Duke, T.; Levskaya, A.; Ghemawat,
    S.; Dev, S.; Michalewski, H.; Garcia, X.; Misra, V.; Robinson, K.; Fedus, L.;
    Zhou, D.; Ippolito, D.; Luan, D.; Lim, H.; Zoph, B.; Spiridonov, A.; Sepassi,
    R.; Dohan, D.; Agrawal, S.; Omernick, M.; Dai, A. M.; Pillai, T. S.; Pellat, M.;
    Lewkowycz, A.; Moreira, E.; Child, R.; Polozov, O.; Lee, K.; Zhou, Z.; Wang, X.;
    Saeta, B.; Diaz, M.; Firat, O.; Catasta, M.; Wei, J.; Meier-Hellstern, K.; Eck,
    D.; Dean, J.; Petrov, S.; 和 Fiedel, N. 2022. PaLM: 用路径扩展语言建模。*CoRR*, abs/2204.02311。'
- en: Cobbe et al. (2021) Cobbe, K.; Kosaraju, V.; Bavarian, M.; Chen, M.; Jun, H.;
    Kaiser, L.; Plappert, M.; Tworek, J.; Hilton, J.; Nakano, R.; Hesse, C.; and Schulman,
    J. 2021. Training Verifiers to Solve Math Word Problems. *CoRR*, abs/2110.14168.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe 等人（2021）Cobbe, K.; Kosaraju, V.; Bavarian, M.; Chen, M.; Jun, H.; Kaiser,
    L.; Plappert, M.; Tworek, J.; Hilton, J.; Nakano, R.; Hesse, C.; 和 Schulman, J.
    2021. 训练验证器以解决数学应用题。*CoRR*, abs/2110.14168。
- en: Feng et al. (2021) Feng, S.; Ren, X.; Li, K.; and Sun, X. 2021. Multi-View Feature
    Representation for Dialogue Generation with Bidirectional Distillation. In *AAAI
    2021*, 12812–12820.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng 等人（2021）Feng, S.; Ren, X.; Li, K.; 和 Sun, X. 2021. 面向对话生成的多视角特征表示与双向蒸馏。发表于
    *AAAI 2021*, 12812–12820。
- en: Fu et al. (2023) Fu, Y.; Peng, H.; Ou, L.; Sabharwal, A.; and Khot, T. 2023.
    Specializing Smaller Language Models towards Multi-Step Reasoning. *CoRR*, abs/2301.12726.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人（2023）Fu, Y.; Peng, H.; Ou, L.; Sabharwal, A.; 和 Khot, T. 2023. 针对多步骤推理的较小语言模型专门化。*CoRR*,
    abs/2301.12726。
- en: He and Glass (2020) He, T.; and Glass, J. R. 2020. Negative Training for Neural
    Dialogue Response Generation. In *Proceedings of the 58th Annual Meeting of the
    Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020*,
    2044–2058\. Association for Computational Linguistics.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 和 Glass（2020）He, T.; 和 Glass, J. R. 2020. 神经对话响应生成的负向训练。发表于 *第 58 届计算语言学协会年会论文集,
    ACL 2020, 在线, 2020 年 7 月 5-10 日*, 2044–2058。计算语言学协会。
- en: Hendrycks et al. (2021) Hendrycks, D.; Burns, C.; Kadavath, S.; Arora, A.; Basart,
    S.; Tang, E.; Song, D.; and Steinhardt, J. 2021. Measuring Mathematical Problem
    Solving With the MATH Dataset. In *Proceedings of the Neural Information Processing
    Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021,
    December 2021, virtual*.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks 等人（2021）Hendrycks, D.; Burns, C.; Kadavath, S.; Arora, A.; Basart,
    S.; Tang, E.; Song, D.; 和 Steinhardt, J. 2021. 用 MATH 数据集衡量数学问题解决能力。发表于 *NeurIPS
    数据集与基准 2021 年会论文集, 2021 年 12 月, 虚拟会议*。
- en: Hinton, Vinyals, and Dean (2015) Hinton, G. E.; Vinyals, O.; and Dean, J. 2015.
    Distilling the Knowledge in a Neural Network. *CoRR*, abs/1503.02531.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton, Vinyals 和 Dean（2015）Hinton, G. E.; Vinyals, O.; 和 Dean, J. 2015. 神经网络中的知识蒸馏。*CoRR*,
    abs/1503.02531。
- en: 'Ho, Schmid, and Yun (2023) Ho, N.; Schmid, L.; and Yun, S. 2023. Large Language
    Models Are Reasoning Teachers. In *Proceedings of the 61st Annual Meeting of the
    Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto,
    Canada, July 9-14, 2023*, 14852–14882\. Association for Computational Linguistics.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho, Schmid 和 Yun（2023）Ho, N.; Schmid, L.; 和 Yun, S. 2023. 大型语言模型是推理教师。发表于 *第
    61 届计算语言学协会年会论文集（第 1 卷：长论文）, ACL 2023, 加拿大多伦多, 2023 年 7 月 9-14 日*, 14852–14882。计算语言学协会。
- en: 'Hsieh et al. (2023) Hsieh, C.; Li, C.; Yeh, C.; Nakhost, H.; Fujii, Y.; Ratner,
    A.; Krishna, R.; Lee, C.; and Pfister, T. 2023. Distilling Step-by-Step! Outperforming
    Larger Language Models with Less Training Data and Smaller Model Sizes. In *Findings
    of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July
    9-14, 2023*, 8003–8017\. Association for Computational Linguistics.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hsieh 等人（2023）Hsieh, C.; Li, C.; Yeh, C.; Nakhost, H.; Fujii, Y.; Ratner, A.;
    Krishna, R.; Lee, C.; 和 Pfister, T. 2023。逐步提炼！用更少的训练数据和更小的模型规模超越更大的语言模型。发表于 *Findings
    of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July
    9-14, 2023*, 8003–8017\. Association for Computational Linguistics。'
- en: 'Hu et al. (2022) Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang,
    S.; Wang, L.; and Chen, W. 2022. LoRA: Low-Rank Adaptation of Large Language Models.
    In *The Tenth International Conference on Learning Representations, ICLR 2022,
    Virtual Event, April 25-29, 2022*. OpenReview.net.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu 等人（2022）Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.;
    Wang, L.; 和 Chen, W. 2022。LoRA: 大型语言模型的低秩适应。发表于 *The Tenth International Conference
    on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022*. OpenReview.net。'
- en: Huang et al. (2022) Huang, J.; Gu, S. S.; Hou, L.; Wu, Y.; Wang, X.; Yu, H.;
    and Han, J. 2022. Large Language Models Can Self-Improve. *CoRR*, abs/2210.11610.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2022）Huang, J.; Gu, S. S.; Hou, L.; Wu, Y.; Wang, X.; Yu, H.; 和 Han,
    J. 2022。大型语言模型可以自我改进。*CoRR*, abs/2210.11610。
- en: 'Jiao et al. (2020) Jiao, X.; Yin, Y.; Shang, L.; Jiang, X.; Chen, X.; Li, L.;
    Wang, F.; and Liu, Q. 2020. TinyBERT: Distilling BERT for Natural Language Understanding.
    In *Findings of the Association for Computational Linguistics: EMNLP 2020, Online
    Event, 16-20 November 2020*, volume EMNLP 2020 of *Findings of ACL*, 4163–4174\.
    Association for Computational Linguistics.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiao 等人（2020）Jiao, X.; Yin, Y.; Shang, L.; Jiang, X.; Chen, X.; Li, L.; Wang,
    F.; 和 Liu, Q. 2020。TinyBERT: 为自然语言理解提炼 BERT。发表于 *Findings of the Association for
    Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020*, volume
    EMNLP 2020 of *Findings of ACL*, 4163–4174\. Association for Computational Linguistics。'
- en: Kojima et al. (2022) Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; and Iwasawa,
    Y. 2022. Large Language Models are Zero-Shot Reasoners. In *NeurIPS*.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; 和 Iwasawa, Y. 2022。大型语言模型是零-shot
    推理器。发表于 *NeurIPS*。
- en: 'Lagutin, Gavrilov, and Kalaidin (2021) Lagutin, E.; Gavrilov, D.; and Kalaidin,
    P. 2021. Implicit Unlikelihood Training: Improving Neural Text Generation with
    Reinforcement Learning. In *Proceedings of the 16th Conference of the European
    Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021,
    Online, April 19 - 23, 2021*, 1432–1441\. Association for Computational Linguistics.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lagutin, Gavrilov, 和 Kalaidin（2021）Lagutin, E.; Gavrilov, D.; 和 Kalaidin, P.
    2021。隐式不可能性训练：通过强化学习提升神经文本生成。发表于 *Proceedings of the 16th Conference of the European
    Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021,
    Online, April 19 - 23, 2021*, 1432–1441\. Association for Computational Linguistics。'
- en: Lewkowycz et al. (2022) Lewkowycz, A.; Andreassen, A.; Dohan, D.; Dyer, E.;
    Michalewski, H.; Ramasesh, V. V.; Slone, A.; Anil, C.; Schlag, I.; Gutman-Solo,
    T.; Wu, Y.; Neyshabur, B.; Gur-Ari, G.; and Misra, V. 2022. Solving Quantitative
    Reasoning Problems with Language Models. In *NeurIPS*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewkowycz 等人（2022）Lewkowycz, A.; Andreassen, A.; Dohan, D.; Dyer, E.; Michalewski,
    H.; Ramasesh, V. V.; Slone, A.; Anil, C.; Schlag, I.; Gutman-Solo, T.; Wu, Y.;
    Neyshabur, B.; Gur-Ari, G.; 和 Misra, V. 2022。利用语言模型解决定量推理问题。发表于 *NeurIPS*。
- en: Li et al. (2020) Li, M.; Roller, S.; Kulikov, I.; Welleck, S.; Boureau, Y.;
    Cho, K.; and Weston, J. 2020. Don’t Say That! Making Inconsistent Dialogue Unlikely
    with Unlikelihood Training. In *Proceedings of the 58th Annual Meeting of the
    Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020*,
    4715–4728\. Association for Computational Linguistics.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2020）Li, M.; Roller, S.; Kulikov, I.; Welleck, S.; Boureau, Y.; Cho, K.;
    和 Weston, J. 2020。别说那个！通过不可能性训练让不一致的对话不太可能。发表于 *Proceedings of the 58th Annual
    Meeting of the Association for Computational Linguistics, ACL 2020, Online, July
    5-10, 2020*, 4715–4728\. Association for Computational Linguistics。
- en: 'Li et al. (2022) Li, Y.; Feng, S.; Sun, B.; and Li, K. 2022. Diversifying Neural
    Dialogue Generation via Negative Distillation. In *Proceedings of the 2022 Conference
    of the North American Chapter of the Association for Computational Linguistics:
    Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15,
    2022*, 407–418\. Association for Computational Linguistics.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人（2022）Li, Y.; Feng, S.; Sun, B.; 和 Li, K. 2022。通过负面提炼多样化神经对话生成。发表于 *Proceedings
    of the 2022 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States,
    July 10-15, 2022*, 407–418\. Association for Computational Linguistics。'
- en: Li et al. (2023) Li, Y.; Feng, S.; Sun, B.; and Li, K. 2023. Heterogeneous-Branch
    Collaborative Learning for Dialogue Generation. In *AAAI 2023*, 13148–13156.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2023）Li, Y.; Feng, S.; Sun, B.; 和 Li, K. 2023。对话生成的异质分支协同学习。发表于 *AAAI
    2023*, 13148–13156。
- en: 'Liu et al. (2020) Liu, W.; Zhou, P.; Wang, Z.; Zhao, Z.; Deng, H.; and Ju,
    Q. 2020. FastBERT: a Self-distilling BERT with Adaptive Inference Time. In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, ACL
    2020, Online, July 5-10, 2020*, 6035–6044\. Association for Computational Linguistics.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2020) Liu, W.; Zhou, P.; Wang, Z.; Zhao, Z.; Deng, H.; 和 Ju, Q.
    2020. FastBERT: 一种自我蒸馏的 BERT，具有自适应推理时间。发表于 *第58届计算语言学协会年会论文集，ACL 2020，线上，2020年7月5-10日*，6035–6044。计算语言学协会。'
- en: 'Magister et al. (2023) Magister, L. C.; Mallinson, J.; Adámek, J.; Malmi, E.;
    and Severyn, A. 2023. Teaching Small Language Models to Reason. In *Proceedings
    of the 61st Annual Meeting of the Association for Computational Linguistics (Volume
    2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023*, 1773–1781\. Association
    for Computational Linguistics.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magister et al. (2023) Magister, L. C.; Mallinson, J.; Adámek, J.; Malmi, E.;
    和 Severyn, A. 2023. 教授小型语言模型进行推理。发表于 *第61届计算语言学协会年会论文集（第2卷：短文），ACL 2023，多伦多，加拿大，2023年7月9-14日*，1773–1781。计算语言学协会。
- en: Miao, Liang, and Su (2020) Miao, S.; Liang, C.; and Su, K. 2020. A Diverse Corpus
    for Evaluating and Developing English Math Word Problem Solvers. In *Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, ACL
    2020, Online, July 5-10, 2020*, 975–984\. Association for Computational Linguistics.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miao, Liang, and Su (2020) Miao, S.; Liang, C.; 和 Su, K. 2020. 用于评估和开发英语数学文字问题求解器的多样化语料库。发表于
    *第58届计算语言学协会年会论文集，ACL 2020，线上，2020年7月5-10日*，975–984。计算语言学协会。
- en: 'Mobahi, Farajtabar, and Bartlett (2020) Mobahi, H.; Farajtabar, M.; and Bartlett,
    P. L. 2020. Self-Distillation Amplifies Regularization in Hilbert Space. In *Advances
    in Neural Information Processing Systems 33: Annual Conference on Neural Information
    Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual*.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mobahi, Farajtabar, and Bartlett (2020) Mobahi, H.; Farajtabar, M.; 和 Bartlett,
    P. L. 2020. 自我蒸馏在希尔伯特空间中放大了正则化。发表于 *神经信息处理系统 33：2020年神经信息处理系统年会，NeurIPS 2020，2020年12月6-12日，虚拟*。
- en: 'Patel, Bhattamishra, and Goyal (2021) Patel, A.; Bhattamishra, S.; and Goyal,
    N. 2021. Are NLP Models really able to Solve Simple Math Word Problems? In *Proceedings
    of the 2021 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021*,
    2080–2094. Association for Computational Linguistics.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Patel, Bhattamishra, and Goyal (2021) Patel, A.; Bhattamishra, S.; 和 Goyal,
    N. 2021. NLP 模型真的能解决简单的数学文字问题吗？发表于 *2021年北美计算语言学协会：人类语言技术会议论文集，NAACL-HLT 2021，线上，2021年6月6-11日*，2080–2094。计算语言学协会。
- en: 'Rajani et al. (2019) Rajani, N. F.; McCann, B.; Xiong, C.; and Socher, R. 2019.
    Explain Yourself! Leveraging Language Models for Commonsense Reasoning. In *Proceedings
    of the 57th Conference of the Association for Computational Linguistics, ACL 2019,
    Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers*, 4932–4942\.
    Association for Computational Linguistics.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajani et al. (2019) Rajani, N. F.; McCann, B.; Xiong, C.; 和 Socher, R. 2019.
    解释一下自己！利用语言模型进行常识推理。发表于 *第57届计算语言学协会会议论文集，ACL 2019，佛罗伦萨，意大利，2019年7月28日-8月2日，第1卷：长篇论文*，4932–4942。计算语言学协会。
- en: Roy and Roth (2015) Roy, S.; and Roth, D. 2015. Solving General Arithmetic Word
    Problems. In *Proceedings of the 2015 Conference on Empirical Methods in Natural
    Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015*, 1743–1752\.
    The Association for Computational Linguistics.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roy and Roth (2015) Roy, S.; 和 Roth, D. 2015. 解决一般算术文字问题。发表于 *2015年自然语言处理经验方法会议论文集，EMNLP
    2015，里斯本，葡萄牙，2015年9月17-21日*，1743–1752。计算语言学协会。
- en: 'Sanh et al. (2019) Sanh, V.; Debut, L.; Chaumond, J.; and Wolf, T. 2019. DistilBERT,
    a distilled version of BERT: smaller, faster, cheaper and lighter. *CoRR*, abs/1910.01108.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sanh et al. (2019) Sanh, V.; Debut, L.; Chaumond, J.; 和 Wolf, T. 2019. DistilBERT，BERT
    的蒸馏版本：更小、更快、更便宜、更轻便。*CoRR*，abs/1910.01108。
- en: 'Shao et al. (2023) Shao, Z.; Gong, Y.; Shen, Y.; Huang, M.; Duan, N.; and Chen,
    W. 2023. Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large
    Language Models. In *International Conference on Machine Learning, ICML 2023,
    23-29 July 2023, Honolulu, Hawaii, USA*, volume 202 of *Proceedings of Machine
    Learning Research*, 30706–30775\. PMLR.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shao et al. (2023) Shao, Z.; Gong, Y.; Shen, Y.; Huang, M.; Duan, N.; 和 Chen,
    W. 2023. 合成提示：为大型语言模型生成链式思维示例。发表于 *国际机器学习会议，ICML 2023，2023年7月23-29日，檀香山，夏威夷，美国*，第202卷
    *机器学习研究论文集*，30706–30775。PMLR。
- en: Tang et al. (2019) Tang, R.; Lu, Y.; Liu, L.; Mou, L.; Vechtomova, O.; and Lin,
    J. 2019. Distilling Task-Specific Knowledge from BERT into Simple Neural Networks.
    *CoRR*, abs/1903.12136.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人 (2019) Tang, R.; Lu, Y.; Liu, L.; Mou, L.; Vechtomova, O.; 和 Lin, J.
    2019. 从 BERT 中提取任务特定知识以用于简单神经网络。*CoRR*, abs/1903.12136。
- en: 'Touvron et al. (2023) Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
    M.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; Rodriguez, A.;
    Joulin, A.; Grave, E.; and Lample, G. 2023. LLaMA: Open and Efficient Foundation
    Language Models. *CoRR*, abs/2302.13971.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人 (2023) Touvron, H.; Lavril, T.; Izacard, G.; Martinet, X.; Lachaux,
    M.; Lacroix, T.; Rozière, B.; Goyal, N.; Hambro, E.; Azhar, F.; Rodriguez, A.;
    Joulin, A.; Grave, E.; 和 Lample, G. 2023. LLaMA: 开放而高效的基础语言模型。*CoRR*, abs/2302.13971。'
- en: Wang et al. (2023) Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V.; Chi, E. H.;
    Narang, S.; Chowdhery, A.; and Zhou, D. 2023. Self-Consistency Improves Chain
    of Thought Reasoning in Language Models. In *The Eleventh International Conference
    on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023*. OpenReview.net.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2023) Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V.; Chi, E. H.; Narang,
    S.; Chowdhery, A.; 和 Zhou, D. 2023. 自我一致性提升语言模型中的思维链推理。发表于 *第十一届国际学习表示会议，ICLR
    2023，卢旺达基加利，2023年5月1-5日*。OpenReview.net。
- en: Wei et al. (2022a) Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud,
    S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.;
    Vinyals, O.; Liang, P.; Dean, J.; and Fedus, W. 2022a. Emergent Abilities of Large
    Language Models. *Trans. Mach. Learn. Res.*, 2022.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2022a) Wei, J.; Tay, Y.; Bommasani, R.; Raffel, C.; Zoph, B.; Borgeaud,
    S.; Yogatama, D.; Bosma, M.; Zhou, D.; Metzler, D.; Chi, E. H.; Hashimoto, T.;
    Vinyals, O.; Liang, P.; Dean, J.; 和 Fedus, W. 2022a. 大语言模型的出现能力。*Trans. Mach.
    Learn. Res.*, 2022。
- en: Wei et al. (2022b) Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.;
    Xia, F.; Chi, E. H.; Le, Q. V.; and Zhou, D. 2022b. Chain-of-Thought Prompting
    Elicits Reasoning in Large Language Models. In *NeurIPS*.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2022b) Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Ichter, B.; Xia,
    F.; Chi, E. H.; Le, Q. V.; 和 Zhou, D. 2022b. 思维链提示引发大语言模型中的推理。发表于 *NeurIPS*。
- en: Welleck et al. (2020) Welleck, S.; Kulikov, I.; Roller, S.; Dinan, E.; Cho,
    K.; and Weston, J. 2020. Neural Text Generation With Unlikelihood Training. In
    *8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,
    Ethiopia, April 26-30, 2020*. OpenReview.net.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Welleck 等人 (2020) Welleck, S.; Kulikov, I.; Roller, S.; Dinan, E.; Cho, K.;
    和 Weston, J. 2020. 通过不可能性训练生成神经文本。发表于 *第八届国际学习表示会议，ICLR 2020，埃塞俄比亚亚的斯亚贝巴，2020年4月26-30日*。OpenReview.net。
- en: 'Xu et al. (2021) Xu, X.; Wang, G.; Kim, Y.; and Lee, S. 2021. AugNLG: Few-shot
    Natural Language Generation using Self-trained Data Augmentation. In *Proceedings
    of the 59th Annual Meeting of the Association for Computational Linguistics and
    the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP
    2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021*, 1183–1195\. Association
    for Computational Linguistics.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu 等人 (2021) Xu, X.; Wang, G.; Kim, Y.; 和 Lee, S. 2021. AugNLG: 使用自训练数据增强的少样本自然语言生成。发表于
    *第59届计算语言学协会年会及第11届国际自然语言处理联合会议，ACL/IJCNLP 2021，（第1卷：长篇论文），虚拟会议，2021年8月1-6日*，1183–1195。计算语言学协会。'
- en: 'Zelikman et al. (2022) Zelikman, E.; Wu, Y.; Mu, J.; and Goodman, N. D. 2022.
    STaR: Bootstrapping Reasoning With Reasoning. In *NeurIPS*.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zelikman 等人 (2022) Zelikman, E.; Wu, Y.; Mu, J.; 和 Goodman, N. D. 2022. STaR:
    通过推理引导推理。发表于 *NeurIPS*。'
- en: Zheng et al. (2023) Zheng, C.; Liu, Z.; Xie, E.; Li, Z.; and Li, Y. 2023. Progressive-Hint
    Prompting Improves Reasoning in Large Language Models. *CoRR*, abs/2304.09797.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人 (2023) Zheng, C.; Liu, Z.; Xie, E.; Li, Z.; 和 Li, Y. 2023. 渐进提示促使大语言模型的推理能力提升。*CoRR*,
    abs/2304.09797。
- en: Zhou et al. (2023) Zhou, D.; Schärli, N.; Hou, L.; Wei, J.; Scales, N.; Wang,
    X.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V.; and Chi, E. H. 2023. Least-to-Most
    Prompting Enables Complex Reasoning in Large Language Models. In *The Eleventh
    International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda,
    May 1-5, 2023*. OpenReview.net.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 (2023) Zhou, D.; Schärli, N.; Hou, L.; Wei, J.; Scales, N.; Wang, X.;
    Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q. V.; 和 Chi, E. H. 2023. 从少到多的提示使大语言模型实现复杂推理。发表于
    *第十一届国际学习表示会议，ICLR 2023，卢旺达基加利，2023年5月1-5日*。OpenReview.net。
- en: 'Zhu et al. (2023) Zhu, X.; Qi, B.; Zhang, K.; Long, X.; and Zhou, B. 2023.
    PaD: Program-aided Distillation Specializes Large Models in Reasoning. *CoRR*,
    abs/2305.13888.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhu 等人 (2023) Zhu, X.; Qi, B.; Zhang, K.; Long, X.; 和 Zhou, B. 2023. PaD: 程序辅助蒸馏专注于大模型的推理。*CoRR*,
    abs/2305.13888。'
- en: Appendix A Appendix
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: Dataset
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集
- en: '| Dataset | Subjects | Train | Test |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 主题 | 训练 | 测试 |'
- en: '| MATH | Probability | 771 | 474 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| MATH | 概率 | 771 | 474 |'
- en: '| InterAlgebra | 1295 | 903 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| InterAlgebra | 1295 | 903 |'
- en: '| NumberTheory | 869 | 540 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| NumberTheory | 869 | 540 |'
- en: '| Precalculus | 746 | 546 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| Precalculus | 746 | 546 |'
- en: '| Prealgebra | 1205 | 871 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Prealgebra | 1205 | 871 |'
- en: '| Geometry | 870 | 479 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| Geometry | 870 | 479 |'
- en: '| Algebra | 1744 | 1187 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| Algebra | 1744 | 1187 |'
- en: '| GSM8K | - | 7473 | 1319 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| GSM8K | - | 7473 | 1319 |'
- en: '| ASDiv | - | - | 1218 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| ASDiv | - | - | 1218 |'
- en: '| MultiArith | - | - | 600 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| MultiArith | - | - | 600 |'
- en: '| SVAMP | - | - | 1000 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| SVAMP | - | - | 1000 |'
- en: 'Table 6: Statistical information about the datasets utilized in our experiments.
    we focus on MATH dataset and the four datasets below are for generalization evaluation.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：我们实验中使用的数据集的统计信息。我们专注于 MATH 数据集，下面的四个数据集用于泛化评估。
- en: 'Table [6](#A1.T6 "Table 6 ‣ Dataset ‣ Appendix A Appendix ‣ Turning Dust into
    Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative
    Data") shows the detailed data statistics. In this study, we focus on MATH dataset
    and the four datasets below are intended for the purpose of evaluating generalization.
    For saving space, subjects in experiments section will be shown in short form.
    CP, IA, NT, PC, PA, G and A denote Counting and Probability, Intermediate Algebra,
    Number Theory, Precalculus, Prealgebra, Geometry and Algebra respectively.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 表[6](#A1.T6 "表 6 ‣ 数据集 ‣ 附录 A 附录 ‣ 将尘土变为黄金：通过利用负数据从 LLMs 中提炼复杂推理能力") 显示了详细的数据统计信息。在这项研究中，我们专注于
    MATH 数据集，下面的四个数据集旨在评估泛化能力。为了节省空间，实验部分的主题将以简写形式显示。CP、IA、NT、PC、PA、G 和 A 分别表示计数与概率、中级代数、数论、预备微积分、预备代数、几何和代数。
- en: Details of Baselines
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基线详细信息
- en: 'For learning from negative views, four baseline methods will be introduced
    as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于从负视角学习，将介绍以下四种基线方法：
- en: •
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MIX directly trains LLaMA with the mixture of both positive data $\mathcal{D}_{pos}$
    by maximizing the following expectation:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MIX 通过最大化以下期望值直接训练 LLaMA，使用正数据 $\mathcal{D}_{pos}$ 的混合：
- en: '|  | $\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{pos+neg}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta).$
    |  | (12) |'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{pos+neg}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta).$
    |  | (12) |'
- en: •
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'CL (contrastive learning) learns a representation of data such that the problem
    $x$ of positive samples are close together in the representation space, while
    negative samples are far apart. In this work, the following expectation is maximized:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CL（对比学习）学习数据的表示，使得正样本的问题 $x$ 在表示空间中彼此接近，而负样本则远离。在这项工作中，最大化了以下期望值：
- en: '|  | $1$2 |  | (13) |'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $1$2 |  | (13) |'
- en: '|  | $\displaystyle\mathbb{E}_{(x,\hat{r}^{+},\hat{y}^{+})\sim\mathcal{D}_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta)$
    |  |'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathbb{E}_{(x,\hat{r}^{+},\hat{y}^{+})\sim\mathcal{D}_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta)$
    |  |'
- en: '|  | $1$2 |  | (14) |'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $1$2 |  | (14) |'
- en: •
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'NT (negative training) (He and Glass [2020](#bib.bib8)) conducts negative updates
    with training signals from negative samples to avoid model generating such data.
    The training objective is to maximize the following expectation:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NT（负训练）（He 和 Glass [2020](#bib.bib8)）通过来自负样本的训练信号进行负更新，以避免模型生成这些数据。训练目标是最大化以下期望值：
- en: '|  | $\displaystyle\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta)$
    |  |'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta)$
    |  |'
- en: '|  | $\displaystyle-\lambda_{2}*\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{neg}}\mathrm{log}P(\hat{y},$
    |  | (15) |'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle-\lambda_{2}*\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{neg}}\mathrm{log}P(\hat{y},$
    |  | (15) |'
- en: The mixing hyper-parameter $\lambda_{2}$, and 0.05 is selected for its best
    performance.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 混合超参数 $\lambda_{2}$，选择了 0.05 以获得最佳性能。
- en: •
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'UL (unlikelihood loss) (Welleck et al. [2020](#bib.bib36)) penalizes the model
    for outputting words with certain characteristics by introducing an unlikelihood
    loss term. In this work, we just penalize the negative samples in sentence level:'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: UL（不可能性损失）（Welleck et al. [2020](#bib.bib36)）通过引入一个不可能性损失项来惩罚模型输出具有某些特征的词。在这项工作中，我们仅在句子级别惩罚负样本：
- en: '|  | $\displaystyle\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta)$
    |  |'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{pos}}\mathrm{log}P(\hat{y},\hat{r}&#124;x;\theta)$
    |  |'
- en: '|  | $\displaystyle+\lambda_{3}*\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{neg}}\mathrm{log}P(1-\hat{y},$
    |  | (16) |'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle+\lambda_{3}*\mathbb{E}_{(x,\hat{r},\hat{y})\sim\mathcal{D}_{neg}}\mathrm{log}P(1-\hat{y},$
    |  | (16) |'
- en: Similar to NT, we search the mixing hyper-parameter $\lambda_{3}$, and 0.05
    is selected as the best.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与 NT 类似，我们搜索混合超参数 $\lambda_{3}$，选择了 0.05 作为最佳值。
- en: Generalization Ability to Other Reasoning Tasks
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 泛化能力到其他推理任务
- en: 'We selected MATH as our primary dataset for its difficulty and significance
    of transferring the capability from LLMs to small models. In this paper, we have
    verified the generalization ability to other simpler datasets including GSM8K,
    ASDiv, MultiArith and SVAMP. Here we also conduct experiments on commonsense reasoning
    with StrategyQA dataset, the results from Table [7](#A1.T7 "Table 7 ‣ Generalization
    Ability to Other Reasoning Tasks ‣ Appendix A Appendix ‣ Turning Dust into Gold:
    Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative Data")
    can demonstrate the generalization ability of NAT to other reasoning tasks.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '我们选择MATH作为主要数据集，因其难度及将LLMs能力转移到小模型中的重要性。在本文中，我们验证了对其他更简单数据集的泛化能力，包括GSM8K、ASDiv、MultiArith和SVAMP。这里我们还对commonsense
    reasoning进行了实验，使用StrategyQA数据集，结果可以通过表[7](#A1.T7 "表 7 ‣ 对其他推理任务的泛化能力 ‣ 附录 A 附录
    ‣ 将尘土转化为黄金: 通过利用负数据从LLMs中提炼复杂推理能力")展示NAT对其他推理任务的泛化能力。'
- en: '| Models | Data Source | Methods | Accuracy |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 数据来源 | 方法 | 准确率 |'
- en: '| LLaMA 7B | Raw | Fine-tune | 61.2 +0% |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA 7B | 原始 | 微调 | 61.2 +0% |'
- en: '| GPT-3.5-Turbo | CoT KD | 69.2 +13.0% |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-Turbo | CoT KD | 69.2 +13.0% |'
- en: '| NAT | 70.4 +15.0% |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| NAT | 70.4 +15.0% |'
- en: '| GPT-4 | CoT KD | 72.4 +18.3% |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | CoT KD | 72.4 +18.3% |'
- en: '| NAT | 72.8 +19.0% |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| NAT | 72.8 +19.0% |'
- en: 'Table 7: Experimental results (%) on StrategyQA.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '表7: StrategyQA上的实验结果（%）。'
- en: NCE Analysis
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NCE分析
- en: '![Refer to caption](img/11cbb5eb45e6f05bf4b313fb37f40655.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/11cbb5eb45e6f05bf4b313fb37f40655.png)'
- en: 'Figure 7: Analysis of $\beta$ along dimensions of: question level and question
    subject.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '图7: 分析$\beta$在：问题级别和问题主题方面的维度。'
- en: In order to further understand the effectiveness of NCE, we conducted experiments
    to analyze the relationship between $\beta$ and using KL divergence is necessary.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步了解NCE的有效性，我们进行了实验来分析$\beta$与使用KL散度的必要性之间的关系。
- en: '|  | Intersection | NAT | Neg | IoU |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '|  | 交集 | NAT | Neg | IoU |'
- en: '| Probability | 6 | 26 | 16 | 0.167 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 概率 | 6 | 26 | 16 | 0.167 |'
- en: '| InterAlgebra | 6 | 44 | 21 | 0.102 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 高级代数 | 6 | 44 | 21 | 0.102 |'
- en: '| NumberTheory | 2 | 36 | 17 | 0.039 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 数论 | 2 | 36 | 17 | 0.039 |'
- en: '| Precalculus | 3 | 21 | 16 | 0.057 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 预备微积分 | 3 | 21 | 16 | 0.057 |'
- en: '| Prealgebra | 15 | 83 | 43 | 0.135 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 初等代数 | 15 | 83 | 43 | 0.135 |'
- en: '| Geometry | 2 | 26 | 10 | 0.057 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 几何 | 2 | 26 | 10 | 0.057 |'
- en: '| Algebra | 16 | 92 | 43 | 0.134 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 代数 | 16 | 92 | 43 | 0.134 |'
- en: '| Overall | 49 | 328 | 166 | 0.110 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 总体 | 49 | 328 | 166 | 0.110 |'
- en: 'Table 8: The distribution of correct samples in MATH test set. Neg refers to
    model only trained by negative samples, and NAT refers to proposed method.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '表8: MATH测试集中正确样本的分布。Neg指仅通过负样本训练的模型，NAT指提出的方法。'
- en: '| system: Think the question step by step and give the answer. |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 系统: 逐步思考问题并给出答案。 |'
- en: '| user: Problem: Find the domain of the expression $\frac{\sqrt{x-2}}{\sqrt{5-x}}$.
    |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 找到表达式$\frac{\sqrt{x-2}}{\sqrt{5-x}}$的定义域。 |'
- en: '| assistant: Solution: The expressions inside each square root must be non-negative.
    Therefore, $x-2\geq 0$. |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: 每个平方根内的表达式必须是非负的。因此，$x-2\geq 0$。 |'
- en: '| user: Problem: Compute: $55\times 1212-15\times 1212$ . |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 计算: $55\times 1212-15\times 1212$。 |'
- en: '| assistant: Solution: We have $55\times 1212-15\times 1212=1212(55-15)=1212(40)=4848(10)=\boxed{48480}$.
    |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: 我们有$55\times 1212-15\times 1212=1212(55-15)=1212(40)=4848(10)=\boxed{48480}$。
    |'
- en: '| user: Problem: Compute $\dbinom{16}{15}$. |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 计算$\dbinom{16}{15}$。 |'
- en: '| assistant: Solution: $\dbinom{16}{15}=\dbinom{16}{1}=\boxed{16}.$ |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: $\dbinom{16}{15}=\dbinom{16}{1}=\boxed{16}.$ |'
- en: '| user: Problem: Find $x$ is a square number which is divisible by four, and
    between 39 and 80. |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 找到$x$，它是一个可以被4整除的平方数，并且在39和80之间。 |'
- en: '| assistant: Solution: We know that $x$. |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: 我们知道$x$。 |'
- en: '| user: Problem: Solve the inequality  |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 解不等式 
    |'
- en: '| assistant: Solution: We can build a sign chart, but since all of the factors
    are linear, we can track what happens to the expression as $x$ |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: 我们可以建立一个符号图，但由于所有的因子都是线性的，我们可以追踪当$x$时表达式的变化 |'
- en: '| user: Problem: A right circular cone has a volume of $12\pi$? |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 一个圆锥体的体积为$12\pi$？ |'
- en: '| assistant: Solution: The volume of a cone is $\frac{1}{3}\pi r^{2}h$. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: 圆锥的体积是$\frac{1}{3}\pi r^{2}h$。 |'
- en: '| user: Problem: How many perfect squares less than 1000 have a ones digit
    of 2, 3 or 4? |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 用户: 问题: 小于1000的完美平方数中，有多少个个位数是2、3或4？ |'
- en: '| assistant: Solution: Checking the squares from $1^{2}$. |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 助手: 解决方案: 检查从$1^{2}$开始的平方数。 |'
- en: '| user: Problem: The diagonals of a rhombus are $10$ inches. What is the perimeter
    of the rhombus, in inches? |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 用户：问题：一个菱形的对角线是 $10$ 英寸。菱形的周长是多少英寸？ |'
- en: '| assistant: Solution: The diagonals are perpendicular bisectors of each other,
    so therefore the side length of the rhombus can be calculated as $\sqrt{5^{2}+12^{2}}=13$
    inches. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 助手：解决方案：对角线彼此垂直平分，因此菱形的边长可以计算为 $\sqrt{5^{2}+12^{2}}=13$ 英寸。 |'
- en: 'Table 9: Demonstrations used to obtain responses from GPT-3.5 Turbo (GPT-4).'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：用于从 GPT-3.5 Turbo (GPT-4) 获取响应的演示。
- en: Overlap Study
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重叠研究
- en: Our initial discovery was that the IoU of the models trained on $\mathcal{D}_{neg}$
    and truly achieve turning dust into gold.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的初步发现是，训练在 $\mathcal{D}_{neg}$ 上的模型的 IoU 确实实现了将尘土转化为黄金。
- en: Chain-of-thought Prompt
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连锁思维提示
- en: 'We provide the prompt to obtain responses from GPT-3.5 Turbo (GPT-4) in Table [9](#A1.T9
    "Table 9 ‣ NCE Analysis ‣ Appendix A Appendix ‣ Turning Dust into Gold: Distilling
    Complex Reasoning Capabilities from LLMs by Leveraging Negative Data"). We follow
    Shao et al. ([2023](#bib.bib30)) to randomly sampled eight samples from different
    subjects and levels in the training set of MATH datasets to form this prompt.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了提示以从 GPT-3.5 Turbo (GPT-4) 中获取响应，如表 [9](#A1.T9 "表 9 ‣ NCE 分析 ‣ 附录 A 附录
    ‣ 将尘土转化为黄金：通过利用负数据提炼复杂推理能力") 所示。我们遵循 Shao 等人 ([2023](#bib.bib30)) 的方法，从 MATH 数据集的训练集中随机抽取了八个来自不同学科和层次的样本来形成这个提示。
