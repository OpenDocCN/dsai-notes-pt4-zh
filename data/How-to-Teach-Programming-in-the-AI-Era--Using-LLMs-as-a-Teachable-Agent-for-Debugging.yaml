- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2025-01-11 13:04:26'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 13:04:26
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for
    Debugging
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在 AI 时代教授编程？使用 LLMs 作为可教代理进行调试
- en: 来源：[https://arxiv.org/html/2310.05292/](https://arxiv.org/html/2310.05292/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2310.05292/](https://arxiv.org/html/2310.05292/)
- en: \addauthor
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \addauthor
- en: sworange
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: sworange
- en: '¹¹institutetext: Carnegie Mellon University, Pittsburgh PA, USA ¹¹email: {qianoum,krk,sherryw}@cs.cmu.edu
    ²²institutetext: University of Michigan, Ann Arbor MI, USA'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹institutetext: 卡内基梅隆大学，宾夕法尼亚州匹兹堡，美国 ¹¹email: {qianoum,krk,sherryw}@cs.cmu.edu
    ²²institutetext: 密歇根大学，安阿伯，密歇根州，美国'
- en: '²²email: huashen@umich.eduQianou Ma 11    Hua Shen 22    Kenneth Koedinger
    11    Sherry Tongshuang Wu 11'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '²²email: huashen@umich.eduQianou Ma 11    Hua Shen 22    Kenneth Koedinger
    11    Sherry Tongshuang Wu 11'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Large Language Models (LLMs) now excel at *generative* skills and can create
    content at impeccable speeds. However, they are imperfect and still make various
    mistakes. In a Computer Science education context, as these models are widely
    recognized as “AI pair programmers,” it becomes increasingly important to train
    students on *evaluating* and *debugging* the LLM-generated code. In this work,
    we introduce HypoCompass, a novel system to facilitate deliberate practice on
    debugging, where human novices play the role of Teaching Assistants and help LLM-powered
    teachable agents debug code. We enable effective task delegation between students
    and LLMs in this learning-by-teaching environment: students focus on *hypothesizing
    the cause of code errors*, while adjacent skills like code completion are offloaded
    to LLM-agents. Our evaluations demonstrate that HypoCompass generates high-quality
    training materials (*e.g.,* bugs and fixes), outperforming human counterparts
    fourfold in efficiency, and significantly improves student performance on debugging
    by 12% in the pre-to-post test.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）现在在 *生成* 技能方面表现出色，能够以无可挑剔的速度创造内容。然而，它们并不完美，仍然会犯各种错误。在计算机科学教育的背景下，随着这些模型被广泛认可为“AI
    配对程序员”，培养学生 *评估* 和 *调试* LLM 生成的代码变得越来越重要。在这项工作中，我们介绍了 HypoCompass，这是一个新颖的系统，旨在促进调试的刻意练习，在其中，人类新手扮演教学助理的角色，帮助
    LLM 驱动的可教代理调试代码。我们在这种通过教学学习的环境中实现了学生与 LLM 之间的有效任务分配：学生专注于 *假设代码错误的原因*，而像代码补全这样的相邻技能则交给
    LLM 代理来处理。我们的评估表明，HypoCompass 生成的高质量训练材料（*例如*，错误和修复）在效率上是人类同行的四倍，且显著提高了学生在调试方面的表现，前后测试成绩提高了
    12%。
- en: 'Keywords:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: LLM teachable agent debugging CS1.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 可教代理调试 CS1。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: LLMs are becoming an integral part of software development — commercialized
    tools like GitHub Copilot are now advertised as “your AI pair programmer” and
    generate up to 46% of users’ code [[6](https://arxiv.org/html/2310.05292v5#bib.bib6)].
    Despite their prevalence, LLMs often produce unpredictable mistakes [[11](https://arxiv.org/html/2310.05292v5#bib.bib11)],
    *e.g.,* GPT-4 can still make mistakes 17% of the time in coding tasks for introductory
    and intermediate programming courses [[22](https://arxiv.org/html/2310.05292v5#bib.bib22)].
    The impressive yet imperfect generative capabilities of LLMs, coupled with the
    associated risks of excessive reliance on these models, underscore the importance
    of teaching *evaluation* skills to students. In the context of programming, students
    must improve their debugging and testing skills [[2](https://arxiv.org/html/2310.05292v5#bib.bib2)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）正成为软件开发中不可或缺的一部分——像 GitHub Copilot 这样的商业化工具现在被宣传为“你的 AI 配对程序员”，并生成多达
    46% 用户的代码[[6](https://arxiv.org/html/2310.05292v5#bib.bib6)]。尽管 LLMs 已广泛应用，但它们仍然会产生不可预测的错误[[11](https://arxiv.org/html/2310.05292v5#bib.bib11)]，*例如*，GPT-4
    在针对初学者和中级编程课程的编码任务中仍然有 17% 的错误率[[22](https://arxiv.org/html/2310.05292v5#bib.bib22)]。LLMs
    令人印象深刻但并不完美的生成能力，加上过度依赖这些模型的相关风险，凸显了教授学生 *评估* 技能的重要性。在编程的背景下，学生必须提升他们的调试和测试技能[[2](https://arxiv.org/html/2310.05292v5#bib.bib2)]。
- en: 'However, debugging tends to be overlooked in formal educational curricula,
    especially in introductory Computer Science classes (*i.e.,* CS1) [[21](https://arxiv.org/html/2310.05292v5#bib.bib21)].
    Prior research has outlined various factors contributing to the absence of debugging
    instruction, such as instructors’ limited time budget for developing specialized
    debugging materials and assessments [[19](https://arxiv.org/html/2310.05292v5#bib.bib19)].
    Consequently, students primarily learn debugging from working on their own mistakes,
    which can be rather frustrating — they must invest substantial time and effort
    in *hypothesizing* the cause of bugs while grappling with other cognitively demanding
    tasks, such as understanding and writing code. These challenges prompt us to ask:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，调试往往在正式的教育课程中被忽视，尤其是在计算机科学入门课程（*即*，CS1）中[[21](https://arxiv.org/html/2310.05292v5#bib.bib21)]。以往的研究指出了缺乏调试教学的多种原因，例如教师在开发专门的调试材料和评估工具方面的时间有限[[19](https://arxiv.org/html/2310.05292v5#bib.bib19)]。因此，学生主要通过自行解决错误来学习调试，这可能相当令人沮丧——他们必须花费大量时间和精力来*假设*错误的原因，同时还要处理其他认知要求较高的任务，如理解和编写代码。这些挑战促使我们提出以下问题：
- en: 'Research Question: Can we train students to improve debugging skills by providing
    *explicit* and *scaffolded* practice *with minimal cost to instructor time?*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 研究问题：我们能否通过提供*明确的*、*分阶段的*练习，*以最小的教师时间成本*，来训练学生提高调试技能？
- en: '![Refer to caption](img/8c8c3f68b19c405bf4f80b779669c665.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/8c8c3f68b19c405bf4f80b779669c665.png)'
- en: 'Figure 1: In HypoCompass, given a programming problem description (A), a student
    user (in the role of a Teaching Assistant) needs to compile a test suite (B) and
    assist multiple LLM-simulated agents (*e.g.,* Bob, Chelsea, Dave) in an Office
    Hour Queue (C) through a chat interface (E). Each LLM-agent acts as a novice seeking
    help with a buggy solution (D) and provides feedback to the user (F).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：在HypoCompass中，给定一个编程问题描述（A），学生用户（以教学助理的角色）需要编写一个测试套件（B），并通过聊天界面（E）帮助多个LLM模拟代理（*例如*，Bob、Chelsea、Dave）在办公时间队列中（C）进行调试。每个LLM代理都充当一个寻求帮助的初学者，并提供反馈给用户（F）。
- en: In this work, we focus on training students’ abilities in *hypothesis construction*,
    a critical step in debugging as established by prior work [[29](https://arxiv.org/html/2310.05292v5#bib.bib29),
    [30](https://arxiv.org/html/2310.05292v5#bib.bib30)]. We introduce HypoCompass
    ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How
    to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging"),
    [Section 3](https://arxiv.org/html/2310.05292v5#S3 "3 The Design of HypoCompass
    ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for
    Debugging")), an interactive, LLM-augmented intelligent tutoring system for debugging.
    Leveraging LLMs’ *material generation* capability, we have these models imitate
    CS1 students who have written buggy code and require assistance from Teaching
    Assistants (TAs). Human novice students assume the role of the TA, who helps troubleshoot
    these bugs. This enables students to deliberately practice the skill of *hypothesizing*
    about the defects of LLM-generated code, delegating other tasks not core to hypothesis
    construction (*e.g.,* code completion) to the LLM. As a result, HypoCompass fosters
    an engaging learning environment using the *teachable agent* framework [[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]
    and provides students with guided exposure to LLM-generated bugs. We also employ
    prompting strategies such as focused task formation and over-generate-then-select
    to improve LLM generation quality in HypoCompass ([Section 4](https://arxiv.org/html/2310.05292v5#S4
    "4 LLM Integration ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '在这项工作中，我们专注于培养学生的*假设构建*能力，这在调试中是一个关键步骤，之前的研究也有提出[[29](https://arxiv.org/html/2310.05292v5#bib.bib29),
    [30](https://arxiv.org/html/2310.05292v5#bib.bib30)]。我们介绍了HypoCompass（[图1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")，[第3节](https://arxiv.org/html/2310.05292v5#S3 "3 The Design
    of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")），一个互动的、LLM增强的智能辅导系统，专门用于调试。借助LLM的*材料生成*能力，我们让这些模型模拟那些编写了有bug代码并需要助教（TA）帮助的CS1学生。人类新手学生扮演助教的角色，帮助调试这些bug。这使得学生可以有意识地练习*假设*LLM生成代码缺陷的技能，并将与假设构建不直接相关的任务（*例如，*代码补全）委派给LLM。因此，HypoCompass通过*可教代理*框架[[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]，为学生提供了LLM生成的bug的引导性曝光，从而促进了一个富有参与感的学习环境。我们还采用了如集中任务形成和先生成后选择的提示策略，以提高HypoCompass中LLM生成的质量（[第4节](https://arxiv.org/html/2310.05292v5#S4
    "4 LLM Integration ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")）。 '
- en: 'We conducted two evaluation studies and found that HypoCompass *saves instructors’
    time in material generation* and is *beneficial to student learning*. In our LLM
    evaluation study ([Section 5](https://arxiv.org/html/2310.05292v5#S5 "5 LLM Evaluation:
    Generation Efficiency and Quality ‣ How to Teach Programming in the AI Era? Using
    LLMs as a Teachable Agent for Debugging")), expert inspections on six practice
    problems and 145 buggy programs showed that HypoCompass achieved a 90% success
    rate in generating and validating a complete set of materials, *four times faster
    than human generation.* Our learning evaluation study with 19 novices ([Section 6](https://arxiv.org/html/2310.05292v5#S6
    "6 Learning Evaluation: Pre- / Post-Test Study ‣ How to Teach Programming in the
    AI Era? Using LLMs as a Teachable Agent for Debugging")) showed that HypoCompass
    significantly improved students’ pre-to-post test performance by 12% and decreased
    their completion time by 14%.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进行了两项评估研究，发现HypoCompass*节省了教师在材料生成上的时间*，并且*有利于学生的学习*。在我们的LLM评估研究中（[第5节](https://arxiv.org/html/2310.05292v5#S5
    "5 LLM Evaluation: Generation Efficiency and Quality ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")），对六个练习问题和145个有bug的程序进行专家检查，结果显示HypoCompass在生成和验证完整材料集时达到了90%的成功率，*比人工生成速度快了四倍*。我们与19名新手的学习评估研究（[第6节](https://arxiv.org/html/2310.05292v5#S6
    "6 Learning Evaluation: Pre- / Post-Test Study ‣ How to Teach Programming in the
    AI Era? Using LLMs as a Teachable Agent for Debugging")）表明，HypoCompass显著提高了学生的前后测试成绩，提升了12%，并将完成时间缩短了14%。'
- en: 'In summary, we contribute:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献如下：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A pragmatic solution that balances the benefits and risks of LLMs in learning.
    We use LLMs to prepare students to engage with imperfect LLMs, and we highlight
    the importance of *role-playing* for practical LLM application and *task delegation*
    to help students focus on essential skills.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一种务实的解决方案，平衡了LLM在学习中的收益与风险。我们使用LLM来帮助学生适应不完美的LLM，并强调*角色扮演*在LLM实际应用中的重要性，以及*任务委派*以帮助学生专注于核心技能。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A theoretically grounded instructional design to enhance debugging skills. To
    the best of our knowledge, we are the first to provide aligned instruction and
    assessments on the hypothesis construction learning objectives, *i.e.,* forming
    hypotheses about the source of error, a core bottleneck in debugging [[25](https://arxiv.org/html/2310.05292v5#bib.bib25)].
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一种理论基础的教学设计，用于增强调试技能。根据我们所知，我们是首个提供与假设构建学习目标对齐的教学和评估的研究，*即*，关于错误来源的假设构建，这是调试中的核心瓶颈[[25](https://arxiv.org/html/2310.05292v5#bib.bib25)]。
- en: 2 Related Works
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 'The Debugging Process. Debugging is a complicated process of various cognitively
    demanding tasks, including understanding the code, finding bugs, and fixing bugs,
    with the first two considered primary bottlenecks [[19](https://arxiv.org/html/2310.05292v5#bib.bib19),
    [25](https://arxiv.org/html/2310.05292v5#bib.bib25)]. While many studies have
    attempted to improve students’ code understanding [[12](https://arxiv.org/html/2310.05292v5#bib.bib12)],
    there is limited instruction on bug finding. Researchers characterize the cognitive
    model of bug finding as a *hypothesis construction process*, including initializing,
    modifying, selecting, and verifying hypotheses ([Figure 2](https://arxiv.org/html/2310.05292v5#S3.F2
    "In 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using
    LLMs as a Teachable Agent for Debugging")B) [[29](https://arxiv.org/html/2310.05292v5#bib.bib29)].
    This process is challenging: prior works show that novices struggle to systematically
    generate comprehensive hypotheses and identify the right hypothesis, in contrast
    to experts [[8](https://arxiv.org/html/2310.05292v5#bib.bib8), [7](https://arxiv.org/html/2310.05292v5#bib.bib7)].
    Hence, we emphasize teaching students to *construct accurate hypotheses about
    bugs* and *develop comprehensive hypotheses about potential bugs*.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 调试过程。调试是一个复杂的过程，涉及多项认知负荷较大的任务，包括理解代码、查找错误和修复错误，其中前两项被认为是主要瓶颈[[19](https://arxiv.org/html/2310.05292v5#bib.bib19),
    [25](https://arxiv.org/html/2310.05292v5#bib.bib25)]。虽然许多研究尝试提高学生的代码理解能力[[12](https://arxiv.org/html/2310.05292v5#bib.bib12)]，但对查找错误的指导却很有限。研究者将错误查找的认知模型描述为*假设构建过程*，包括初始化、修改、选择和验证假设（[图2](https://arxiv.org/html/2310.05292v5#S3.F2
    "在3节 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为调试的可教代理")B）[[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]。这个过程充满挑战：先前的研究表明，新手在系统地生成全面的假设并识别正确的假设方面存在困难，而专家则能够做到这一点[[8](https://arxiv.org/html/2310.05292v5#bib.bib8),
    [7](https://arxiv.org/html/2310.05292v5#bib.bib7)]。因此，我们强调教授学生*构建准确的错误假设*和*制定关于潜在错误的全面假设*。
- en: Tutors and Tools for Debugging Training. Prior studies [[19](https://arxiv.org/html/2310.05292v5#bib.bib19)]
    and online discussions [[21](https://arxiv.org/html/2310.05292v5#bib.bib21)] indicate
    that teaching debugging is challenging and is rarely included in CS1 curricula,
    due to logistical challenges like the lack of instructional time and resources [[5](https://arxiv.org/html/2310.05292v5#bib.bib5),
    [10](https://arxiv.org/html/2310.05292v5#bib.bib10)]. Existing tools demand instructor
    effort and often focus on the full debugging process, improving bug-fixing accuracy
    and efficiency [[1](https://arxiv.org/html/2310.05292v5#bib.bib1), [15](https://arxiv.org/html/2310.05292v5#bib.bib15)].
    In contrast, few studies emphasize accurate or comprehensive hypothesis construction
    (and they tend to be language-specific) [[13](https://arxiv.org/html/2310.05292v5#bib.bib13),
    [25](https://arxiv.org/html/2310.05292v5#bib.bib25)]. To fill in the gap, we design
    HypoCompass to provide *deliberate practice* [[9](https://arxiv.org/html/2310.05292v5#bib.bib9)]
    on hypothesis construction, and use *the LLM generation capability to provide
    easily adaptable and targeted exercises* with immediate feedback.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 调试训练的导师与工具。先前的研究[[19](https://arxiv.org/html/2310.05292v5#bib.bib19)]和在线讨论[[21](https://arxiv.org/html/2310.05292v5#bib.bib21)]表明，教学调试具有挑战性，并且由于如缺乏教学时间和资源等后勤问题，调试训练很少出现在CS1课程中[[5](https://arxiv.org/html/2310.05292v5#bib.bib5),
    [10](https://arxiv.org/html/2310.05292v5#bib.bib10)]。现有工具需要教师的投入，且通常侧重于整个调试过程，提高错误修复的准确性和效率[[1](https://arxiv.org/html/2310.05292v5#bib.bib1),
    [15](https://arxiv.org/html/2310.05292v5#bib.bib15)]。相反，少有研究强调准确或全面的假设构建（并且这些研究通常是语言特定的）[[13](https://arxiv.org/html/2310.05292v5#bib.bib13),
    [25](https://arxiv.org/html/2310.05292v5#bib.bib25)]。为了填补这一空白，我们设计了HypoCompass，旨在提供关于假设构建的*刻意练习*[[9](https://arxiv.org/html/2310.05292v5#bib.bib9)]，并利用*LLM生成能力提供易于适应且针对性的练习*，并提供即时反馈。
- en: 'LLM Capabilities for CS Learning. LLMs can perform well in a CS1 classroom [[22](https://arxiv.org/html/2310.05292v5#bib.bib22)],
    but concerns about misuse and LLM errors limit their use in education [[2](https://arxiv.org/html/2310.05292v5#bib.bib2)].
    Therefore, current deployments tend to focus on generating instructional materials
    (*e.g.,* questions [[24](https://arxiv.org/html/2310.05292v5#bib.bib24)]). In
    our work, HypoCompass uses the LLM to generate inter-dependent materials in an
    integrated process and frame the LLM as a student asking for help [[3](https://arxiv.org/html/2310.05292v5#bib.bib3)],
    such that human novices can embrace imperfections in LLMs. Two unique capabilities
    of LLMs power this: (1) LLMs can simulate different personas and tutoring interactions [[18](https://arxiv.org/html/2310.05292v5#bib.bib18)];
    (2) LLMs make common mistakes and natural bugs similar to humans [[20](https://arxiv.org/html/2310.05292v5#bib.bib20)],
    which can be used as buggy code practice examples. We adapt and develop various
    prompting methods [[27](https://arxiv.org/html/2310.05292v5#bib.bib27)] to enhance
    the quality of LLM generations.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 在计算机科学学习中的能力。LLMs 在 CS1 教室中表现良好[[22](https://arxiv.org/html/2310.05292v5#bib.bib22)]，但对滥用和
    LLM 错误的担忧限制了它们在教育中的使用[[2](https://arxiv.org/html/2310.05292v5#bib.bib2)]。因此，目前的应用部署通常专注于生成教学材料（*例如*，问题[[24](https://arxiv.org/html/2310.05292v5#bib.bib24)]）。在我们的工作中，HypoCompass
    使用 LLM 生成相互依赖的材料，并将 LLM 视为向学生寻求帮助的工具[[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]，这样人类新手就能接受
    LLM 中的不完美。LLM 的两个独特能力使这一点成为可能：(1) LLM 可以模拟不同的人物角色和辅导互动[[18](https://arxiv.org/html/2310.05292v5#bib.bib18)]；(2)
    LLM 会犯常见的错误和类似人类的自然漏洞[[20](https://arxiv.org/html/2310.05292v5#bib.bib20)]，这些可以作为有错误代码的练习示例。我们调整并开发了各种提示方法[[27](https://arxiv.org/html/2310.05292v5#bib.bib27)]，以提高
    LLM 生成内容的质量。
- en: 3 The Design of HypoCompass
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 HypoCompass 的设计
- en: 'Grounded in the cognitive process [[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]
    and the novice-expert difference in hypothesis-driven debugging ([Section 2](https://arxiv.org/html/2310.05292v5#S2
    "2 Related Works ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")), we specify two crucial learning components for HypoCompass:
    comprehensive and accurate hypothesis construction. Prior work shows that hypothesis
    construction is closely connected with testing [[30](https://arxiv.org/html/2310.05292v5#bib.bib30)]:
    each additional test case should, ideally, be a hypothesis about what can go wrong
    in the program. In turn, a *comprehensive* test suite (*i.e.,* a set of test cases)
    should allow an effective debugger to construct a *accurate* hypothesis about
    why the program is wrong. We thus design toward two learning objectives ([Figure 2](https://arxiv.org/html/2310.05292v5#S3.F2
    "In 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using
    LLMs as a Teachable Agent for Debugging")A,D):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基于认知过程[[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]和新手与专家在假设驱动调试中的差异（[第
    2 节](https://arxiv.org/html/2310.05292v5#S2 "2 Related Works ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")），我们为 HypoCompass
    指定了两个关键的学习组件：全面且准确的假设构建。先前的研究表明，假设构建与测试密切相关[[30](https://arxiv.org/html/2310.05292v5#bib.bib30)]：每个额外的测试用例，理想情况下，应该是关于程序出错的假设。因此，一个*全面的*测试套件（*即*，一组测试用例）应该使有效的调试者能够构建出*准确的*假设，解释程序出错的原因。我们因此设计了两个学习目标（[图
    2](https://arxiv.org/html/2310.05292v5#S3.F2 "In 3 The Design of HypoCompass ‣
    How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")A,D）：
- en: LO1
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LO1
- en: 'Comprehensive Hypothesis Construction: Construct a comprehensive test suite
    that well covers the possible errors for the given problem.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 综合假设构建：构建一个全面的测试套件，充分覆盖给定问题可能出现的错误。
- en: LO2
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LO2
- en: 'Accurate Hypothesis Construction: Given the failed test cases, construct an
    accurate explanation of how the program is wrong.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确的假设构建：给定失败的测试用例，构建一个准确的解释，说明程序出错的原因。
- en: '![Refer to caption](img/24a0584c27ed826b53fd9ac48738c841.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![请参考标题说明](img/24a0584c27ed826b53fd9ac48738c841.png)'
- en: 'Figure 2: To enable deliberate practice, we establish a close mapping between
    the (A) learning objectives, (B) the cognitive debugging process model, (C) the
    HypoCompass interaction flow, and (D) the primary tasks students perform in HypoCompass.
    We offload various material generation tasks to LLMs (C[2]).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：为了实现有目的的练习，我们在 (A) 学习目标、(B) 认知调试过程模型、(C) HypoCompass 交互流程和 (D) 学生在 HypoCompass
    中执行的主要任务之间建立了紧密的映射关系。我们将各种材料生成任务交给 LLMs（C[2]）。
- en: '*Interface and Key Components.*'
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*界面和关键组件*。'
- en: We designed HypoCompass through an iterative development process with 10 pilots,
    including CS1 students, TAs, and instructors. In the resulting interface ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")), a human student would be asked to play the role of a TA
    where they help an LLM-simulated student (LLM-agent) in debugging. They need to
    write and sort test cases into categories ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")B) that represent different hypotheses of what inputs may
    trigger errors in code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个包含 10 个试点的迭代开发过程设计了 HypoCompass，其中包括 CS1 学生、助教和讲师。在最终的界面中（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")），学生将扮演助教的角色，帮助一个 LLM 模拟的学生（LLM-代理）进行调试。他们需要编写并将测试用例按类别排序（[图
    1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1 Introduction ‣ How to Teach
    Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging")B），这些类别代表了不同的假设，表明哪些输入可能会触发代码中的错误。
- en: Once the student is satisfied with their test suite, HypoCompass shows them
    an Office Hour Queue (OHQ) simulator ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")C). As the student interacts with each LLM-agent, the agent
    presents a buggy code snippet ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")D). The student guides the LLM-agent in debugging code through
    a dialog interface ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1
    Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")E), selecting or creating test cases that reflect their hypotheses
    of the bug, and selecting explanations for the bug among a pool of candidate natural
    language explanations. These candidates each explain a different bug, representing
    alternative hypotheses that may confuse students (*e.g.,* [Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")[3]).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦学生对他们的测试套件感到满意，HypoCompass 会显示一个办公时间队列（OHQ）模拟器（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")C）。当学生与每个 LLM-代理互动时，该代理会展示一个有问题的代码片段（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")D）。学生通过对话界面（[图 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")E）引导 LLM-代理进行代码调试，选择或创建能够反映他们假设的 bug 的测试用例，并从候选的自然语言解释池中选择一个
    bug 解释。这些候选解释各自阐述了不同的 bug，代表了可能会让学生困惑的不同假设（*例如*，[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")[3]）。
- en: The LLM-agent then uses the test case and explanation to revise the code, providing
    immediate feedback to the student ([Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")). If the explanation
    is correct, the agent will conduct minimal code fixes, and present the color-coded
    edits as feedback ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1 "In 1
    Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")F, a zoomed-in view is in [Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")[2]). Otherwise,
    the LLM-agent will ask the student to reflect on their hypothesis by responding
    with a confusion message that highlights the discrepancy between the student’s
    explanation and the actual code behavior ([Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")[3]).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，LLM-agent使用测试用例和解释来修正代码，向学生提供即时反馈（[第3节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "界面与关键组件 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）。如果解释正确，代理将进行最小的代码修复，并将颜色编码的编辑作为反馈呈现（[图1](https://arxiv.org/html/2310.05292v5#S1.F1
    "在1简介 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")F，放大视图请见[第3节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "界面与关键组件 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）。否则，LLM-agent会要求学生通过回应一个困惑消息来反思他们的假设，该消息突出了学生解释与实际代码行为之间的差异（[第3节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "界面与关键组件 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）。
- en: Once the student correctly confirms that all the bugs are fixed, they can move
    to help the next LLM-agent ([Figure 1](https://arxiv.org/html/2310.05292v5#S1.F1
    "In 1 Introduction ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")C). Upon completion, HypoCompass will provide the next round
    of exercises with another programming problem. While the numbers are configurable,
    by default HypoCompass includes two programming exercises, each with three LLM-agents
    (buggy programs).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦学生正确确认所有错误已修复，他们可以转到帮助下一个LLM-agent（[图1](https://arxiv.org/html/2310.05292v5#S1.F1
    "在1简介 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")C）。完成后，HypoCompass将提供下一轮练习，包含另一个编程问题。虽然数量是可配置的，但默认情况下，HypoCompass包括两个编程练习，每个练习包含三个LLM-agent（有缺陷的程序）。
- en: '![Refer to caption](img/b546a894bf2d8f7f6f08c6c071f27150.png)\phantomcaption'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![请参阅标题](img/b546a894bf2d8f7f6f08c6c071f27150.png)\phantomcaption'
- en: 'Figure 3(()): HypoCompass offers (1) *test category hints* to help write a
    comprehensive test suite systematically; (2) *test case hints* to help students
    add missing test scenarios; (3) *candidate explanation pool* to clarify misconceptions
    of alternative explanations.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '图3(()): HypoCompass提供（1）*测试类别提示*，帮助系统地编写全面的测试套件；（2）*测试用例提示*，帮助学生添加缺失的测试场景；（3）*候选解释池*，澄清替代解释的误解。'
- en: '![Refer to caption](img/11f3c2c8c07b608e9087409643f6ab19.png)\phantomcaption'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![请参阅标题](img/11f3c2c8c07b608e9087409643f6ab19.png)\phantomcaption'
- en: 'Figure 3(()): HypoCompass provides immediate feedback to (1) *incorrect test
    cases*, ensuring students understand the code behavior; (2) *correct explanations*,
    as correct code fixes; (3) *incorrect explanations*, as confusion messages from
    the LLM-agent.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '图3(()): HypoCompass提供即时反馈给（1）*不正确的测试用例*，确保学生理解代码行为；（2）*正确的解释*，作为正确的代码修复；（3）*不正确的解释*，作为来自LLM-agent的困惑消息。'
- en: 'We highlight the two most essential components of the interaction:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调互动的两个最重要的组成部分：
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Frame imperfect LLMs through role-play. We use the LLM to simulate students
    who wrote bugs and have human novices offer help. This teachable agent setup supports
    learning, helping students reflect on their knowledge and reason through diverse
    bugs [[23](https://arxiv.org/html/2310.05292v5#bib.bib23)]. Having students work
    through “other people’s errors” also boosts their motivation and protects their
    self-efficacy [[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]. More importantly,
    it actively involves novices in identifying bugs in LLM-generated code, *enabling
    guided exposure to LLM imperfectness*.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过角色扮演来框定不完美的 LLM。我们使用 LLM 模拟写有错误的学生，并让人类新手提供帮助。这种可教授的代理设置支持学习，帮助学生反思自己的知识，并通过多种错误进行推理[[23](https://arxiv.org/html/2310.05292v5#bib.bib23)]。让学生处理“他人的错误”还可以提升他们的动力，并保护他们的自我效能感[[3](https://arxiv.org/html/2310.05292v5#bib.bib3)]。更重要的是，它积极地让新手参与到识别
    LLM 生成代码中的错误中，*使他们能够有针对性地接触 LLM 的不完美性*。
- en: •
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task delegation between students and LLMs. To ensure deliberate practice on
    comprehensive and accurate hypothesis construction, students primarily engage
    in two tasks corresponding to each learning objective ([Figure 2](https://arxiv.org/html/2310.05292v5#S3.F2
    "In 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using
    LLMs as a Teachable Agent for Debugging")D): (1) making the test suite more complete
    ([LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "Item LO1 ‣ 3 The Design of
    HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")); and (2) correctly mapping explanations to bugs ([LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "Item LO2 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging")). We align student interaction
    flow ([Figure 2](https://arxiv.org/html/2310.05292v5#S3.F2 "In 3 The Design of
    HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")C[1]) with the cognitive model of debugging [[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]
    ([Figure 2](https://arxiv.org/html/2310.05292v5#S3.F2 "In 3 The Design of HypoCompass
    ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for
    Debugging")B). LLMs take over other tasks that are *indirectly related* to the
    core learning goals, including generating diverse bugs and fixes, which frees
    students from code writing. We also use LLMs to support scaffolding, generate
    hints ([Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "Interface
    and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in
    the AI Era? Using LLMs as a Teachable Agent for Debugging")), and provide immediate
    feedback throughout the practice ([Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")).'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学生与 LLM 之间的任务分配。为了确保在全面且准确的假设构建方面进行刻意练习，学生主要从事两个任务，每个任务对应一个学习目标（[图 2](https://arxiv.org/html/2310.05292v5#S3.F2
    "3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")D）：(1) 使测试套件更加完整（[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项目 LO1 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")）；和 (2) 正确地将解释与错误匹配（[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项目 LO2 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")）。我们将学生的互动流程（[图
    2](https://arxiv.org/html/2310.05292v5#S3.F2 "3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用
    LLM 作为调试的可教授代理")C[1]）与调试的认知模型对齐[[29](https://arxiv.org/html/2310.05292v5#bib.bib29)]（[图
    2](https://arxiv.org/html/2310.05292v5#S3.F2 "3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用
    LLM 作为调试的可教授代理")B）。LLM 承担了与核心学习目标*间接相关*的其他任务，包括生成多样的错误和修复，从而解放学生于代码编写之外。我们还使用
    LLM 来支持支架教学、生成提示（[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1 "界面与关键组件
    ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")），并在整个练习过程中提供即时反馈（[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "界面与关键组件 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为调试的可教授代理")）。
- en: '![Refer to caption](img/2f720117d725fdbb90d25741ec333ca3.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/2f720117d725fdbb90d25741ec333ca3.png)'
- en: 'Figure 4: Examples of inputs and outputs to the LLM material generation pipeline.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：LLM 材料生成管道的输入和输出示例。
- en: 4 LLM Integration
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 LLM 集成
- en: 'As shown in [Figure 2](https://arxiv.org/html/2310.05292v5#S3.F2 "In 3 The
    Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as
    a Teachable Agent for Debugging")C[2], we use LLM to generate five types of materials:
    (1) test case category hints, (2) test case hints, (3) buggy programs, (4) explanations
    of bugs, and (5) programs with bugs fixed. We reduce instructor workload by generating
    practices using just a problem description, a reference solution, and a reference
    test suite with about 10 inputs, and we further minimize human verification overhead
    with optimized prompts and automated algorithms. Our generation process is detailed
    in [Figure 4](https://arxiv.org/html/2310.05292v5#S3.F4 "In Interface and Key
    Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI
    Era? Using LLMs as a Teachable Agent for Debugging"), example prompts are in [Table 1](https://arxiv.org/html/2310.05292v5#S4.T1
    "In Task Formation and Decomposition. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging"), and full prompts
    are in Table 3 in [Supplements](http://tinyurl.com/hypocompass-sup)¹¹1Supplemental
    materials are at: [http://tinyurl.com/hypocompass-sup](http://tinyurl.com/hypocompass-sup).
    OpenAI’s gpt-3.5-turbo is used for all materials, except for explanation generation,
    which uses gpt-4 for enhanced reasoning capabilities. Below are key factors to
    the success of generation:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图2](https://arxiv.org/html/2310.05292v5#S3.F2 "在HypoCompass设计中 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")C[2]所示，我们使用LLM生成五种类型的材料：（1）测试用例类别提示，（2）测试用例提示，（3）有错误的程序，（4）错误说明，以及（5）已修复错误的程序。通过仅使用问题描述、参考解决方案和约10个输入的参考测试集来生成练习，我们减少了教师的工作量，并通过优化提示和自动化算法进一步最小化了人工验证开销。我们的生成过程详见[图4](https://arxiv.org/html/2310.05292v5#S3.F4
    "在界面与关键组件中 ‣ 3 HypoCompass设计 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")，示例提示见[表1](https://arxiv.org/html/2310.05292v5#S4.T1
    "在任务形成与分解中 ‣ 4 LLM集成 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")，完整提示见[补充材料](http://tinyurl.com/hypocompass-sup)¹¹1中的表3。所有材料均使用OpenAI的gpt-3.5-turbo，除了说明生成使用gpt-4，以增强推理能力。以下是生成成功的关键因素：
- en: '*Task Formation and Decomposition.*'
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*任务形成与分解。*'
- en: 'We iterate on our prompts according to the nature of the task. First, as LLMs
    behave inconsistently when the user tasks conflict with LLMs inherent training
    objectives [[28](https://arxiv.org/html/2310.05292v5#bib.bib28)], we carefully
    formulate the task to avoid introducing competing tasks. Take *Local Bug Fix*
    ([Table 1](https://arxiv.org/html/2310.05292v5#S4.T1 "In Task Formation and Decomposition.
    ‣ 4 LLM Integration ‣ How to Teach Programming in the AI Era? Using LLMs as a
    Teachable Agent for Debugging")) as an example: when we directly ask the LLM to
    fix a bug according to an explanation, we observe that the model almost always
    over-fix all bugs irrespective of the provided instructions. This is because LLMs
    can be biased towards generating fully correct code (part of the LLM pre-training)
    and away from local bug fixing (changing only the buggy snippet described by the
    instruction, the desired task). Hence, we re-frame it as a *translation task*,
    converting bug-fixing instructions to its code format old $\rightarrow$ new code
    snippet. This task re-framing mitigates the model’s inherent bias, reducing over-fixing
    errors by 70%.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据任务的性质迭代我们的提示语。首先，由于当用户任务与LLM固有的训练目标冲突时，LLM的表现往往不一致[[28](https://arxiv.org/html/2310.05292v5#bib.bib28)]，我们会仔细制定任务，以避免引入相互竞争的任务。以*本地错误修复*（[表1](https://arxiv.org/html/2310.05292v5#S4.T1
    "在任务形成与分解中 ‣ 4 LLM集成 ‣ 如何在AI时代教授编程？利用LLM作为可教授的调试代理")）为例：当我们直接要求LLM根据说明修复一个错误时，我们观察到模型几乎总是会过度修复所有错误，而不管提供的指令是什么。这是因为LLM可能会倾向于生成完全正确的代码（LLM预训练的一部分），而不专注于本地错误修复（仅修改指令描述的错误代码片段，即期望任务）。因此，我们将其重新构造为*翻译任务*，将错误修复指令转换为其代码格式，从旧代码$\rightarrow$新代码片段。这种任务重构减轻了模型的固有偏差，减少了70%的过度修复错误。
- en: Second, for multi-step tasks (*e.g.,* *Local Bug Fix*), we adopt LLM-chains [[27](https://arxiv.org/html/2310.05292v5#bib.bib27)],
    decomposing tasks into sub-tasks handled by separate steps, such that each step
    contributes to stable performance. Third, we also address prompt complexity by
    explicitly prioritizing essential requirements. For tasks like generating *Bug
    Explanations and Fix Instructions* ([Table 1](https://arxiv.org/html/2310.05292v5#S4.T1
    "In Task Formation and Decomposition. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")), we prioritize
    precise bug extraction, instructing the model to list all unique bugs upfront.
    Secondary requirements (*e.g.,* word limits) are specified only in the output
    format. This hierarchical disentanglement significantly improves success rates
    by over 40%.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '其次，对于多步骤任务（*例如*，*本地错误修复*），我们采用LLM链[[27](https://arxiv.org/html/2310.05292v5#bib.bib27)]，将任务分解成子任务并由不同步骤处理，从而使每个步骤都能贡献于稳定的表现。第三，我们通过显式优先考虑基本要求来解决提示复杂性。对于像生成*错误解释和修复说明*（[表1](https://arxiv.org/html/2310.05292v5#S4.T1
    "任务形成与分解。 ‣ 4 LLM集成 ‣ 如何在AI时代教授编程？使用LLM作为可教授的调试代理")）这样的任务，我们优先进行精确的错误提取，指示模型先列出所有独特的错误。次要要求（*例如*，字数限制）只在输出格式中指定。这种层次化解构显著提高了成功率，超过40%。  '
- en: 'Table 1: Prompts and temperatures (Temp.) for generating bugs, explanations,
    and fixes. The temperature is set higher for more diverse and random outputs.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：生成错误、解释和修复的提示和温度（Temp.）。温度设定越高，输出的多样性和随机性越强。
- en: '| Material | Generation goal | Temp. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 材料 | 生成目标 | 温度 |'
- en: '| Buggy code | To over-generate bugs with mixed quality for further selection.
    | 0.7 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 有缺陷的代码 | 生成多种不同质量的错误代码供进一步选择。 | 0.7 |'
- en: '| [Sys.] | You are a novice student in intro CS, you make mistakes and write
    buggy code. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| [系统] | 你是计算机科学入门课程的初学者，你会犯错并写出有缺陷的代码。 |'
- en: '| [User] | Problem Description: {problem_description} Write different buggy
    solutions with common mistakes like novice students: |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| [用户] | 问题描述: {问题描述} 写出带有常见错误的不同有缺陷的解决方案，如初学者学生： |'
- en: '| Bug expl. & fix instruct. | To describe each unique bug, and write a corresponding
    fix instruction. If there are multiple bugs in the code, generate their explanations
    and fixes separately. | 0.3 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 错误解释与修复说明 | 描述每个独特的错误，并写出相应的修复说明。如果代码中有多个错误，分别生成它们的解释和修复。 | 0.3 |'
- en: '| [Sys.] | You are a helpful and experienced TA of an introductory programming
    class. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| [系统] | 你是计算机编程入门课的一个有经验且乐于助人的助教。 |'
- en: '| [User] | Hi, I’m a student in your class. I’m having trouble with this problem
    in the programming assignment: {problem_description} Here’s my buggy code: {buggy_code}
    What’s wrong with my code? List all the unique bugs included, but do not make
    up bugs. For each point, put in the format of: {explanation: accurate and concise
    explanation of what the code does and what the bug is, for a novice, fix: how
    to fix the bug, within 30 words} Only return the bullet list. Do not write any
    other text or code. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| [用户] | 嗨，我是你班上的一名学生。我在编程作业中遇到困难：{问题描述} 这是我的有缺陷代码：{有缺陷的代码} 我的代码有什么问题？列出所有独特的错误，但不要编造错误。对于每一点，使用以下格式：{解释：简洁而准确地解释代码的作用以及错误的所在，适合初学者，修复：如何修复错误，30个字以内}
    仅返回项目符号列表，不要写任何其他文本或代码。 |'
- en: '| Bug fix | To edit the buggy code according to the fix instruction, w/o over-
    or under- fix. | 0.3 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 错误修复 | 根据修复说明编辑有缺陷的代码，避免过度或不足的修复。 | 0.3 |'
- en: '| [Sys.] | You fix bugs in Python code closely following the instructions.
    |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| [系统] | 你根据说明仔细修复Python代码中的错误。 |'
- en: '| [User] | Original code: {buggy_code}; Code modification: {explanation} Translate
    the statement into actual, minimal code change in this format:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '| [用户] | 原始代码: {有缺陷的代码}; 代码修改: {解释} 将语句翻译为实际的最小代码更改，格式如下：'
- en: '{original code snippet: ""copy the lines of code that need editing""'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '{原始代码片段: ""复制需要编辑的代码行""'
- en: '-> edited code snippet: ""write the edited code snippet""} |'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '-> 编辑后的代码片段: ""写出编辑后的代码片段""} |'
- en: '| [LLM ] | {old to new snippet in JSON, e.g., numbers_list[i] <= key $\mathrel{\hbox{\rule[-0.2pt]{3.0pt}{0.4pt}}\mkern-4.0mu\hbox{\char
    41\relax}}$ numbers_list[i] > key } |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| [LLM] | {旧到新片段的JSON格式，例如，numbers_list[i] <= key $\mathrel{\hbox{\rule[-0.2pt]{3.0pt}{0.4pt}}\mkern-4.0mu\hbox{\char
    41\relax}}$ numbers_list[i] > key } |'
- en: '| [User] | Old Code:{buggy_code}; Instruction:{Old snippet to new snippet};
    New Code: |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| [用户] | 旧代码:{有缺陷的代码}; 指令:{旧片段到新片段}; 新代码: |'
- en: '*Over-Generate-then-Select.*'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*过度生成然后选择。*'
- en: '![Refer to caption](img/1da5c09ee8dfaa7e8d95618f11110b2b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1da5c09ee8dfaa7e8d95618f11110b2b.png)'
- en: 'Figure 5: Over-generate and automatically select materials with pedagogical
    values.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：过度生成并自动选择具有教学价值的材料。
- en: 'While LLMs can easily generate random materials, it is nontrivial to ensure
    that their generations have pedagogical values. For example, behaviorally distinct
    bugs help students practice with varied instances, but it is hard to enforce through
    prompting as it requires LLMs to “know” bug behaviors. Nonetheless, we can configure
    the non-deterministic LLMs to over-generate multiple solutions with mixed qualities [[17](https://arxiv.org/html/2310.05292v5#bib.bib17)],
    and then select a subset of desired ones ([Figure 5](https://arxiv.org/html/2310.05292v5#S4.F5
    "In Over-Generate-then-Select. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")). We apply this
    strategy in multiple places:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大型语言模型（LLMs）可以轻松生成随机材料，但确保其生成内容具有教学价值并非易事。例如，行为上有明显差异的 bug 帮助学生练习不同的实例，但通过提示强制实现这一点很困难，因为这需要
    LLMs “了解” bug 行为。然而，我们可以配置非确定性的 LLMs 使其过度生成多种具有不同质量的解决方案[[17](https://arxiv.org/html/2310.05292v5#bib.bib17)]，然后从中选择出我们所需的子集（[图
    5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")）。我们在多个地方应用了这一策略：
- en: (1) To expose students to behaviorally distinct bugs, we over-generate buggy
    code ([Table 1](https://arxiv.org/html/2310.05292v5#S4.T1 "In Task Formation and
    Decomposition. ‣ 4 LLM Integration ‣ How to Teach Programming in the AI Era? Using
    LLMs as a Teachable Agent for Debugging")). We filter out correct code, and we
    vectorize buggy code’s behavior based on the reference test suite ([Figure 5](https://arxiv.org/html/2310.05292v5#S4.F5
    "In Over-Generate-then-Select. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")A, 0 being failed
    tests). We then greedily choose a diverse subset of buggy programs with the maximum
    pairwise distance, using Euclidean distance on the error vectors ([Figure 5](https://arxiv.org/html/2310.05292v5#S4.F5
    "In Over-Generate-then-Select. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")B).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: （1）为了让学生接触到行为上有明显差异的 bug，我们过度生成了有 bug 的代码（[表 1](https://arxiv.org/html/2310.05292v5#S4.T1
    "在任务形成和分解中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")）。我们剔除了正确代码，并基于参考测试套件对有
    bug 的代码行为进行向量化（[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。
    ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")A，0代表测试失败）。然后，我们贪婪地选择了一组多样的有 bug 程序，这些程序在错误向量上的成对距离最大，使用的是欧几里得距离（[图
    5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。 ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")B）。
- en: (2) To help students clarify misconceptions ([Figure 5](https://arxiv.org/html/2310.05292v5#S4.F5
    "In Over-Generate-then-Select. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")C), we want distracting
    explanations that look similar to the actual explanation for each practice buggy
    code. We choose from the over-generated buggy code pool, find two with the smallest
    Euclidean distance to the target code, and use their corresponding explanations
    as distractors. The mapping also helps generate the confusion messages ([Section 3](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "Interface and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")[3]) — when a student
    selects the distractor explanation, we use its corresponding buggy code to find
    test cases to present to students.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: （2）为了帮助学生澄清误解（[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在“过度生成-再选择”中。
    ‣ 4 LLM集成 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试")C），我们希望有干扰性的解释，它们看起来与每个实践用的有 bug 代码的实际解释相似。我们从过度生成的有
    bug 代码池中选择，找到与目标代码最小欧几里得距离的两个代码，并使用它们的相应解释作为干扰项。这个映射还帮助生成混淆信息（[第 3 节](https://arxiv.org/html/2310.05292v5#S3.SS0.SSS0.Px1
    "界面与关键组件。 ‣ 3 HypoCompass的设计 ‣ 如何在人工智能时代教授编程？使用LLMs作为可教代理进行调试") [3]）——当学生选择干扰项解释时，我们使用其相应的有
    bug 代码来寻找测试用例并呈现给学生。
- en: (3) To capture key testing aspects in our test category hints ([Figure 5](https://arxiv.org/html/2310.05292v5#S4.F5
    "In Over-Generate-then-Select. ‣ 4 LLM Integration ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging")D), we cluster reference
    test cases into semantically meaningful groups. We build dendrograms from test
    case vectors with Agglomerative Hierarchical Clustering [[14](https://arxiv.org/html/2310.05292v5#bib.bib14)],
    which guide the selection of test category hints from the over-generated pool.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 为了捕捉我们测试类别提示中的关键测试方面（见[图 5](https://arxiv.org/html/2310.05292v5#S4.F5 "在过度生成然后选择中。
    ‣ 4 LLM 集成 ‣ 如何在 AI 时代教授编程？使用 LLM 作为可教授的调试代理")D），我们将参考测试用例聚集成语义上有意义的组。我们使用聚合层次聚类（Agglomerative
    Hierarchical Clustering）从测试用例向量中构建树状图[[14](https://arxiv.org/html/2310.05292v5#bib.bib14)]，这些树状图指导从过度生成池中选择测试类别提示。
- en: '*Human-in-the-Loop Verification.*'
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*人类参与验证。*'
- en: 'As shown in [Figure 4](https://arxiv.org/html/2310.05292v5#S3.F4 "In Interface
    and Key Components. ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in
    the AI Era? Using LLMs as a Teachable Agent for Debugging"), while the hints for
    test cases and categories are generated separately, the materials relevant to
    bugs are generated in sequential order. We perform human verification per step
    to mitigate the risk of cascading errors in subsequent steps. We provide more
    details on human verification and editing times in [Section 5](https://arxiv.org/html/2310.05292v5#S5
    "5 LLM Evaluation: Generation Efficiency and Quality ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging").'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 4](https://arxiv.org/html/2310.05292v5#S3.F4 "在接口和关键组件中。 ‣ 3 HypoCompass
    的设计 ‣ 如何在 AI 时代教授编程？使用 LLM 作为可教授的调试代理")所示，虽然测试用例和类别的提示是分别生成的，但与错误相关的材料是按顺序生成的。我们在每个步骤上执行人工验证，以减少后续步骤中级联错误的风险。我们在[第
    5 节](https://arxiv.org/html/2310.05292v5#S5 "5 LLM 评估：生成效率和质量 ‣ 如何在 AI 时代教授编程？使用
    LLM 作为可教授的调试代理")中提供了更多关于人工验证和编辑时间的详细信息。
- en: '5 LLM Evaluation: Generation Efficiency and Quality'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LLM 评估：生成效率和质量
- en: 'We evaluated the generations on six different problems from prior work [[4](https://arxiv.org/html/2310.05292v5#bib.bib4)]
    and our own problems (detailed in Table 4 in [Supplements](http://tinyurl.com/hypocompass-sup)).
    On average, for each problem, we generated 3 test category hints, 10 test case
    hints, 24 buggy programs, explanation and fix instructions, and 33 bug fixes.
    The total number and the success rates are summarized in [Table 2](https://arxiv.org/html/2310.05292v5#S5.T2
    "In Method. ‣ 5 LLM Evaluation: Generation Efficiency and Quality ‣ How to Teach
    Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging"). We
    provided the success criteria for all types of materials in Table 5 in [Supplements](http://tinyurl.com/hypocompass-sup).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在六个不同问题上评估了生成内容，来自先前的工作[[4](https://arxiv.org/html/2310.05292v5#bib.bib4)]以及我们自己的问题（详见[附录](http://tinyurl.com/hypocompass-sup)中的表
    4）。平均而言，对于每个问题，我们生成了 3 个测试类别提示、10 个测试用例提示、24 个错误程序、解释和修复指令，以及 33 个错误修复。总数和成功率总结在[表
    2](https://arxiv.org/html/2310.05292v5#S5.T2 "在方法中。 ‣ 5 LLM 评估：生成效率和质量 ‣ 如何在 AI
    时代教授编程？使用 LLM 作为可教授的调试代理")中。我们在[附录](http://tinyurl.com/hypocompass-sup)中的表 5 提供了所有类型材料的成功标准。
- en: '*Method.*'
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*方法。*'
- en: 'Two authors annotated 10% of the generations at each step individually, and
    discussed to resolve the disagreement and update the codebook. An external instructor
    annotated the same 10% of LLM-generated materials, using the updated codebook.
    We calculated the inter-rater reliability (IRR) between the external instructor
    and the resolved annotation among the two authors using percent IRR and Cohen’s
    Kappa. As shown in [Table 2](https://arxiv.org/html/2310.05292v5#S5.T2 "In Method.
    ‣ 5 LLM Evaluation: Generation Efficiency and Quality ‣ How to Teach Programming
    in the AI Era? Using LLMs as a Teachable Agent for Debugging"), the agreements
    are satisfactory across different model generations (IRR% $>$ 90% and $\kappa>0.75$)²²2
    Buggy programs undergo automatic testing, so human verification is unnecessary
    (n/a). If both raters unanimously agree in one category, $kappa$ is undefined
    (-), so $\kappa$ is only noted when there’s less than 100% IRR agreement on a
    single label. . One author annotated the rest of the materials to calculate the
    success rates. We log the verification and editing *time*, as proxies to the instructor
    overhead.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 两位作者分别在每个步骤标注了10%的生成内容，并讨论解决分歧并更新了代码本。外部讲师使用更新后的代码本标注了同样10%的LLM生成材料。我们计算了外部讲师与两位作者解决后标注之间的评分一致性（IRR），使用百分比IRR和Cohen's
    Kappa。正如在[表2](https://arxiv.org/html/2310.05292v5#S5.T2 "在方法部分 ‣ 5 LLM评估：生成效率与质量
    ‣ 如何在AI时代教授编程？使用LLMs作为可教学的调试代理")中所示，不同模型生成之间的一致性是令人满意的（IRR% $>$ 90% 和 $\kappa>0.75$）²²2
    有缺陷的程序经过自动测试，因此无需人工验证（n/a）。如果两个评审者在某一类别中达成一致，则$kappa$未定义（-），因此$\kappa$仅在单一标签的IRR一致性不到100%时才进行标注。一个作者标注了剩余的材料以计算成功率。我们记录了验证和编辑的*时间*，作为讲师负担的代理。
- en: To compare LLM and human generations, we recruited two experienced CS TAs to
    each create practice materials for a specific problem. Each TA received the same
    input as LLMs, was asked to produce one set of materials matching the amount of
    content LLMs produced, and was compensated for their time.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较LLM和人工生成，我们招募了两位经验丰富的计算机科学教学助理（CS TA），让他们分别为一个特定问题创建练习材料。每位TA收到与LLM相同的输入，要求他们生成一套与LLM生成内容相匹配的材料，并为他们的时间提供报酬。
- en: 'Table 2: LLM Evaluation: Time, Success rate, and Inter-Rater Reliability scores
    (*i.e.,* IRR% = #agreements / #total labels, $\kappa$ is Cohen’s Kappa coefficient).${}^{\ref{footnote:kappa}}$'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '表2：LLM评估：时间、成功率和评分一致性（*即*，IRR% = #一致项 / #总标签，$\kappa$是Cohen的Kappa系数）。${}^{\ref{footnote:kappa}}$'
- en: '| Material | Raw LLM outputs | Human verification |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 材料 | 原始LLM输出 | 人工验证 |'
- en: '| --- | --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| # Generation | Avg. gen time | Success% | Avg. edit time | IRR% | $\kappa$
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| # 生成 | 平均生成时间 | 成功率% | 平均编辑时间 | IRR% | $\kappa$ |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Test case description hint | 61 | 0:00:37 | 98.36% | 0:00:08 | 100% | - |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 测试用例描述提示 | 61 | 0:00:37 | 98.36% | 0:00:08 | 100% | - |'
- en: '| Test case category hint | 18 | 0:00:10 | 94.44% | 0:00:10 | 100% | - |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 测试用例类别提示 | 18 | 0:00:10 | 94.44% | 0:00:10 | 100% | - |'
- en: '| Buggy code | 145 | 0:01:30 | 57.93% | 0:00:02 | n/a | n/a |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 有缺陷的代码 | 145 | 0:01:30 | 57.93% | 0:00:02 | n/a | n/a |'
- en: '| Bug explanation and fix | 145 | 0:03:36 | 91.72% | 0:00:52 | 90% | 0.875
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 错误解释与修复 | 145 | 0:03:36 | 91.72% | 0:00:52 | 90% | 0.875 |'
- en: '| Bug fix | 195 | 0:02:45 | 86.15% | 0:00:37 | 92% | 0.752 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Bug修复 | 195 | 0:02:45 | 86.15% | 0:00:37 | 92% | 0.752 |'
- en: '*Result: Efficient and High-Quality Generation.*'
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*结果：高效且高质量的生成。*'
- en: 'We achieve high-quality generation: a complete set of practice materials with
    9 buggy programs (3 for practice and 6 more as distractors), 9 bug explanations,
    9 bug fixes, 10 test case hints, and 3 test category hints can be generated with
    a 90% success rate and only takes 15 minutes to label and edit. As we *over-generate*
    and automatically select buggy code, a success rate over 50% is reasonable for
    practical use.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了高质量的生成：一套完整的练习材料，包括9个有缺陷的程序（3个用于练习，另外6个作为干扰项）、9个错误解释、9个错误修复、10个测试用例提示和3个测试类别提示，成功率达到90%，且只需要15分钟来标注和编辑。由于我们*过度生成*并自动选择有缺陷的代码，成功率超过50%是实际应用中合理的。
- en: Employing LLMs can also be significantly more efficient. In total, a TA spent
    around 60 minutes to generate one set of practice materials for HypoCompass. One
    TA noted the difficulty in consistently creating unique and high-quality materials
    after 30 minutes, saying that *“the importance of the bug I create would start
    to decline.”* The same author evaluated the TAs’ generations using the annotation
    codebook, which had a 100% success rate and took 11 minutes. The time invested
    in generating and editing instructional materials for HypoCompass using LLMs was
    4.67 times less than that of the human TAs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LLM 还可以显著提高效率。总的来说，一名助教花费了大约 60 分钟来生成一套 HypoCompass 的练习材料。一名助教提到，在持续 30 分钟后，保持创作独特且高质量的材料变得困难，并表示*“我创建的
    bug 的重要性开始下降。”* 同一位作者使用注释代码本评估了助教的创作，结果显示 100% 成功率，并且用了 11 分钟。使用 LLM 生成和编辑 HypoCompass
    教学材料所投入的时间比人工助教少了 4.67 倍。
- en: '6 Learning Evaluation: Pre- / Post-Test Study'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 学习评估：前测 / 后测研究
- en: '*Can novices better formulate hypotheses after engaging with HypoCompass?*
    We conducted a learning evaluation with 19 students and compared the difference
    in speed and performance from the pre-test to the post-test.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*在使用 HypoCompass 后，新手能更好地制定假设吗？* 我们对19名学生进行了学习评估，并比较了前测和后测之间的速度和表现差异。'
- en: '*Assessment.*'
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*评估。*'
- en: To best capture student learning gains on our learning objectives, we took a
    backward design method [[26](https://arxiv.org/html/2310.05292v5#bib.bib26)] to
    create an aligned assessment for the comprehensive [LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "Item LO1 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging") and accurate [LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "Item LO2 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging") hypothesis construction skills.
    We conducted multiple rounds of pilots to refine our intervention and pre-post
    tests.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最佳地捕捉学生在我们的学习目标上的学习成果，我们采用了逆向设计方法[[26](https://arxiv.org/html/2310.05292v5#bib.bib26)]，创建了一个与[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项 LO1 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")和[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项 LO2 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")的综合性与准确假设构建技能对齐的评估。我们进行了多轮试点测试，以优化我们的干预和前后测评估。
- en: '![Refer to caption](img/d4a026a6130eb6e79490621d5411a34c.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/d4a026a6130eb6e79490621d5411a34c.png)'
- en: 'Figure 6: Pre-post test question examples for [LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "Item LO1 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging") comprehensive (Q3.1 and Q3.2)
    and [LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "Item LO2 ‣ 3 The Design
    of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging") accurate hypothesis construction (Q7).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：前后测问题示例，针对[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "项 LO1 ‣ 3
    HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")的综合性（Q3.1 和 Q3.2）以及[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项 LO2 ‣ 3 HypoCompass 的设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教授代理进行调试")的准确假设构建（Q7）。
- en: 'Our final tests are based on two programming exercises with comparable difficulties.
    We counterbalanced pre-post tests’ problems to control for problem sequence influence.
    Each test consists of seven questions, with three assessing [LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "Item LO1 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging") and four for [LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "Item LO2 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging"). [Figure 6](https://arxiv.org/html/2310.05292v5#S6.F6
    "In Assessment. ‣ 6 Learning Evaluation: Pre- / Post-Test Study ‣ How to Teach
    Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging") provides
    a sample for each. For instance, Question 3.1 asks students to identify the more
    suitable test case to add to an existing test suite, evaluating their ability
    to construct comprehensive hypotheses ([LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "Item LO1 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging")). We measure students’ performance
    using their test scores based on a standard rubric. We also log the pre-post tests’
    completion time as a proxy for proficiency.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终测试基于两个难度相当的编程练习。为了控制问题顺序的影响，我们对前后测试的问题进行了平衡安排。每个测试包含七个问题，其中三个评估[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项目 LO1 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")，四个评估[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项目 LO2 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")。[图 6](https://arxiv.org/html/2310.05292v5#S6.F6
    "评估中 ‣ 6 学习评估：前/后测试研究 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")提供了每个问题的示例。例如，问题3.1要求学生识别更适合添加到现有测试套件中的测试用例，评估他们构建全面假设的能力（[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项目 LO1 ‣ 3 HypoCompass 设计 ‣ 如何在 AI 时代教授编程？利用 LLM 作为可教学的调试代理")）。我们通过标准评分量表来衡量学生的表现，同时记录前后测试的完成时间，作为熟练度的代理。
- en: '*Method: Study Procedure and Participants.*'
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*方法：学习程序和参与者。*'
- en: Our hour-long user study constituted a pre-survey, pre-test, interaction with
    HypoCompass, post-test, and a post-survey. Participants began with a pre-survey,
    which asked demographic information and 7-level Likert Scale questions on their
    debugging experiences. Then, participants had up to 20 minutes for the pre-test.
    The system interaction consisted of two problems, where participants needed to
    write a test suite and explain bugs in three different buggy programs for each
    problem. The first problem was the same as in the pre-test, and the second problem
    matched the screening survey’s exercise. By reusing problems that students have
    seen, we isolate our learning objectives from the program comprehension skills.
    After a subsequent 20-minute post-test, participants filled out a post-survey
    with Likert Scale and open-ended questions on their experience and perceptions
    using HypoCompass. Participants received a $15 Gift Card for their time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的为期一小时的用户研究包括前调查、前测试、与HypoCompass的互动、后测试和后调查。参与者首先进行前调查，问卷包括人口统计信息以及关于其调试经验的7级李克特量表问题。接着，参与者有最多20分钟时间进行前测试。系统互动包含两个问题，参与者需要为每个问题编写测试套件，并解释三个不同的有错误程序中的
    bug。第一个问题与前测试相同，第二个问题与筛选问卷中的练习一致。通过重复使用学生已经见过的问题，我们将学习目标与程序理解技能分离开来。之后进行20分钟的后测试，参与者填写后调查，问卷包括李克特量表和开放性问题，旨在了解他们使用HypoCompass的体验和感知。参与者会因其时间获得15美元的礼品卡。
- en: We recruited a diverse group of undergraduate and graduate students from four
    public or private US institutions. Interested participants completed a screening
    survey, which included a programming exercise that also served as the second exercise
    in our study. To ensure a suitable skill range, we excluded those with extensive
    programming experience or who quickly solved the exercise. After filtering, 19
    participants (S1-19) were included in the study — 12 females, 6 males, 1 non-binary,
    and 8 non-native English speakers, with an average age of 20.7.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了来自四所美国公立或私立院校的不同背景的本科生和研究生。感兴趣的参与者填写了筛选问卷，其中包括一个编程练习，该练习也作为我们研究中的第二个练习。为了确保技能范围合适，我们排除了那些具有丰富编程经验或能够快速解决练习的参与者。筛选后，19名参与者（S1-19）被纳入研究——其中12名女性，6名男性，1名非二元性别，8名非母语英语者，平均年龄为20.7岁。
- en: '*Quantitative Result: Learning Gains.*'
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*定量结果：学习收获。*'
- en: A two-tailed paired t-test showed that students’ pre-test to post-test scores
    significantly improved by 11.7% ($p=0.033<0.05$), and the time of completion significantly
    reduced by 13.6% ($p=0.003$), indicating success in learning through HypoCompass
    interaction. Note that the bugs used in pre-post tests are generated by humans
    and are not the same as in HypoCompass. As such, the significant learning gains
    indicate that students could learn debugging skills *transferable* to real-world
    bugs.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一项双尾配对t检验表明，学生的前测到后测成绩显著提高了11.7%（$p=0.033<0.05$），完成时间显著减少了13.6%（$p=0.003$），这表明通过与HypoCompass的互动，学生在学习上取得了成功。请注意，前后测使用的错误是人为生成的，与HypoCompass中的错误不同。因此，这些显著的学习进展表明，学生能够学习到可以
    *迁移* 到实际世界错误的调试技能。
- en: Where does the learning gain come from? We break down the analyses by learning
    objectives. We found a small 6.1% improvement in the score and a large 23.6% time
    reduction for *comprehensive hypothesis construction* ([LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "Item LO1 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging")), and a large 15.8% improvement
    in the score and a small 9.0% time reduction for *accurate hypothesis construction*
    ([LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "Item LO2 ‣ 3 The Design of
    HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging")). Therefore, students showed more efficiency enhancement
    in [LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1 "Item LO1 ‣ 3 The Design
    of HypoCompass ‣ How to Teach Programming in the AI Era? Using LLMs as a Teachable
    Agent for Debugging"), and more learning gains in [LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "Item LO2 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging"). Note that these improvements
    may confound with problem difficulty, as the items corresponding to [LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "Item LO1 ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era?
    Using LLMs as a Teachable Agent for Debugging") (pre-test $\mu=54\%$) seem easier
    than the ones for [LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2 "Item LO2
    ‣ 3 The Design of HypoCompass ‣ How to Teach Programming in the AI Era? Using
    LLMs as a Teachable Agent for Debugging") (pre-test $\mu=38\%$).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 学习进展来源于哪里？我们根据学习目标进行了分析。我们发现，在*综合假设构建*（[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项 LO1 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")）上，得分提高了6.1%，而时间减少了23.6%；在*准确假设构建*（[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项 LO2 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")）上，得分提高了15.8%，时间减少了9.0%。因此，学生在[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项 LO1 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")上的效率提升更多，而在[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项 LO2 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")上则获得了更多的学习进展。需要注意的是，这些改进可能与问题难度有关，因为[LO1](https://arxiv.org/html/2310.05292v5#S3.I1.i1
    "项 LO1 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")（前测 $\mu=54\%$）对应的题目似乎比[LO2](https://arxiv.org/html/2310.05292v5#S3.I1.i2
    "项 LO2 ‣ 3 HypoCompass的设计 ‣ 如何在AI时代教授编程？利用LLM作为可教学的调试代理")（前测 $\mu=38\%$）对应的题目更容易。
- en: '*Qualitative Result: Student Perceptions.*'
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*定性结果：学生的感知。*'
- en: We further unpack how HypoCompass contributed to learning by analyzing the survey
    responses. Students valued being able to offload some debugging subtasks to HypoCompass,
    such as writing code and explanations. For example, S1 said *“looking at the test
    behavior and the explanation options really helps relieve that burden.”* Students
    also generally felt that the LLM-generated bugs and fixes were authentic. Most
    participants could not tell if their practiced programs were written by students
    or AI because of their experiences making or seeing similar mistakes from peers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过分析调查反馈进一步揭示了HypoCompass对学习的贡献。学生们很看重能够将一些调试子任务转交给HypoCompass，比如编写代码和解释。例如，S1说
    *“查看测试行为和解释选项确实有助于减轻负担。”* 学生们普遍觉得由LLM生成的错误和修复是可信的。大多数参与者无法判断他们练习的程序是由学生还是AI编写的，因为他们有过类似的错误经历，或者曾见过同学犯过类似的错误。
- en: 'Moreover, students reported that HypoCompass was engaging, fun, not frustrating,
    and helped build confidence in debugging. A Wilcoxon signed-rank test shows a
    significant increase in self-rated confidence in debugging by 15% ($p=0.007$).
    Students rated HypoCompass as significantly more engaging (6.0 out of 7), fun
    (6.0), and less frustrating (2.5) than their conventional way of learning debugging
    and testing ($p<0.005$ for each). S8 especially liked the teachable agent setup:
    *“the role play just feels more natural because it feels like explaining to a
    rubber duck instead of to talking to myself”*.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，学生们报告称HypoCompass具有吸引力、趣味性，不令人沮丧，并且帮助建立了调试信心。威尔科克森符号秩检验显示，学生自评的调试信心提高了15%（$p=0.007$）。学生们认为HypoCompass比他们传统的调试和测试学习方式更具吸引力（得分6.0/7）、趣味性（得分6.0），并且不那么令人沮丧（得分2.5）（每项$p<0.005$）。S8特别喜欢可教代理设置：“*角色扮演感觉更自然，因为它更像是对一个橡皮鸭进行解释，而不是对自己说话*”。
- en: 7 Discussion
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论
- en: Teachable Agent for Appropriate Reliance with Imperfect AIs. Our work illustrates
    a scenario in which *LLM-generated bugs are not seen as problems but rather as
    features.* HypoCompass’s teachable agent setup provides students with *moderated
    exposure to imperfect LLMs*, and may help them learn that LLMs are fallible and
    calibrate trust accordingly. Future iterations could remove material validation
    and allow direct exposure to unfiltered LLM mistakes in real-time interactions,
    taking full advantage of the teachable agent framework. Students will naturally
    expect that the LLM-agent seeking help may make mistakes (*e.g.,* fail to follow
    bug-fixing explanations). This approach, however, requires a more sophisticated
    design for scaffolding students in recognizing LLM errors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于不完美AI的可教代理。我们的研究展示了一个场景，其中*大语言模型（LLM）生成的错误并不被视为问题，而是作为一种特性*。HypoCompass的可教代理设置为学生提供了*有控制的暴露于不完美LLMs*的机会，并可能帮助他们认识到LLMs是有缺陷的，并据此调整信任。未来的迭代可能会去除材料验证，允许学生直接接触到实时互动中的未过滤LLM错误，从而充分利用可教代理框架。学生们自然会预期寻求帮助的LLM代理可能会犯错（*例如*，未能按照错误修复的解释执行）。然而，这种方法需要更复杂的设计来支持学生识别LLM错误。
- en: 'Task Delegation for Shifting Learning Focus. Our exploration lays the foundation
    for a paradigm shift toward cultivating higher-order evaluation skills in the
    generative AI era. Essentially, we asked: what skills should we offload, and what
    should we learn? Most students in our study appreciated offloading subtasks to
    LLM ([Section 6](https://arxiv.org/html/2310.05292v5#S6.SS0.SSS0.Px4 "Qualitative
    Result: Student Perceptions. ‣ 6 Learning Evaluation: Pre- / Post-Test Study ‣
    How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging"));
    however, some need more scaffolds, while others prefer less. Future research can
    investigate more personalized task delegation. For example, students who need
    more help can use LLMs to facilitate code tracing, and students can also write
    their own explanations for bugs based on their proficiency. Deciding the bare
    minimum programming skills and human-AI collaboration skills to teach also warrants
    further exploration [[16](https://arxiv.org/html/2310.05292v5#bib.bib16)].'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 任务委派以转变学习焦点。我们的探索为在生成性AI时代培养更高阶评估技能的范式转变奠定了基础。本质上，我们提出了一个问题：我们应该卸载哪些技能，应该学习哪些技能？我们研究中的大多数学生都赞赏将子任务委托给LLM（[第6节](https://arxiv.org/html/2310.05292v5#S6.SS0.SSS0.Px4
    "定性结果：学生感知。‣ 6 学习评估：前测/后测研究 ‣ 如何在AI时代教授编程？利用LLMs作为调试的可教代理")）；然而，有些学生需要更多支持，而另一些学生则偏好较少。未来的研究可以探讨更加个性化的任务委派。例如，需要更多帮助的学生可以使用LLMs来促进代码追踪，而学生也可以根据自己的熟练程度编写关于错误的解释。决定教授的最低编程技能和人类-人工智能协作技能也需要进一步探索[[16](https://arxiv.org/html/2310.05292v5#bib.bib16)]。
- en: Modularize to Adapt to Different Needs. Though most students and instructors
    found HypoCompass engaging, some expressed concerns about the deployment and maintenance
    cost of a new tool. To maximize utility to diverse users, we can modularize different
    components in HypoCompass. Instructors who prefer to distribute training materials
    as handouts can rely entirely on the material generation module. In contrast,
    instructors who want to experiment with TA training can employ HypoCompass with
    practice generated using their training questions. Future studies may perform
    ablation studies to evaluate different HypoCompass components with more extensive
    classroom deployment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化以适应不同需求。虽然大多数学生和教师发现HypoCompass具有吸引力，但也有些人对新工具的部署和维护成本表示担忧。为了最大化对不同用户的效用，我们可以将HypoCompass的不同组件模块化。那些希望将培训材料分发为讲义的教师可以完全依赖于材料生成模块。相比之下，想要实验TA培训的教师可以通过使用他们自己的训练问题生成的练习来使用HypoCompass。未来的研究可能会进行消融研究，以评估在更多课堂部署中HypoCompass的不同组件。
- en: Limitation. We primarily evaluated *whether HypoCompass can bring learning and
    efficiency gains* through small in-lab experiments. With this prerequisite, we
    plan to conduct future classroom deployment with controlled comparisons. There
    is also a limitation regarding the reported efficiency of the LLM-assisted instructional
    material development, as the instructors need some familiarization time with the
    tool and the process.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性。我们主要通过小规模实验评估了*HypoCompass是否能够带来学习和效率提升*。在此前提下，我们计划进行未来的课堂部署并进行控制性比较。此外，关于LLM辅助的教学材料开发的效率也存在局限性，因为教师需要一些时间来熟悉该工具和流程。
- en: 8 Conclusion
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: In an attempt to answer how LLMs can reshape programming education’s focus,
    we introduce a novel system, HypoCompass, and new instructional designs for hypothesis
    construction skills. We aim to provide engaging and deliberate practice on debugging
    to novices, using our theoretically motivated and empirically tested teachable
    agent augmented by LLM. Our evaluations show that HypoCompass can efficiently
    help instructors create high-quality instructional materials, effectively train
    novices on comprehensive and accurate hypothesis construction, and facilitate
    students’ confidence and engagement in debugging.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答大型语言模型（LLMs）如何重塑编程教育的重点，我们引入了一个新系统HypoCompass，并提出了新的假设构建技能的教学设计。我们的目标是通过使用经过理论驱动和经验验证的可教代理，并结合LLM，向初学者提供有趣且有目的的调试实践。我们的评估结果表明，HypoCompass可以有效帮助教师创建高质量的教学材料，帮助初学者有效地进行全面和准确的假设构建训练，并促进学生在调试中的信心和参与感。
- en: 8.0.1 Acknowledgments
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.0.1 致谢
- en: Thanks to the participants, reviewers, Vicky Zhou, Kelly Rivers, Michael Taylor,
    Michael Hilton, Michael Xieyang Liu, Kexin Yang, Jionghao Lin, Erik Harpstead,
    and other Ken’s lab members for insights and help. Thanks to the gift funds from
    Adobe, Oracle, and Google; Thanks to the National Science Foundation (award CNS-2213791)
    for partial support of this work.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢参与者、评审、Vicky Zhou、Kelly Rivers、Michael Taylor、Michael Hilton、Michael Xieyang
    Liu、Kexin Yang、Jionghao Lin、Erik Harpstead以及Ken实验室的其他成员提供的见解和帮助。感谢Adobe、Oracle和Google的捐赠基金；感谢国家科学基金会（奖项CNS-2213791）对本研究的部分资助。
- en: References
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Ardimento, P., Bernardi, M.L., Cimitile, M., Ruvo, G.D.: Reusing bugged
    source code to support novice programmers in debugging tasks. ACM Trans. Comput.
    Educ. 20(1), 1–24 (2019). https://doi.org/10.1145/3355616'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Ardimento, P., Bernardi, M.L., Cimitile, M., Ruvo, G.D.: 重新使用有缺陷的源代码以支持初学者进行调试任务。ACM
    计算机教育学报 20(1), 1–24 (2019). https://doi.org/10.1145/3355616'
- en: '[2] Becker, B.A., Denny, P., Finnie-Ansley, J., Luxton-Reilly, A., Prather,
    J., Santos, E.A.: Programming is hard-or at least it used to be: Educational opportunities
    and challenges of ai code generation. In: Proceedings of the 54th ACM Technical
    Symposium on Computer Science Education V. 1\. pp. 500–506 (2023)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Becker, B.A., Denny, P., Finnie-Ansley, J., Luxton-Reilly, A., Prather,
    J., Santos, E.A.: 编程很难——或者至少以前是：AI代码生成的教育机会与挑战。见：第54届ACM计算机科学教育技术研讨会论文集V. 1. 第500–506页（2023）'
- en: '[3] Blair, K., Schwartz, D.L., Biswas, G., Leelawong, K.: Pedagogical agents
    for learning by teaching: Teachable agents. Educ. Technol. Res. Dev. 47(1), 56–61
    (2007)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Blair, K., Schwartz, D.L., Biswas, G., Leelawong, K.: 用于教学学习的教学代理：可教代理。教育技术研究与发展
    47(1), 56–61 (2007)'
- en: '[4] Dakhel, A.M., Majdinasab, V., Nikanjam, A., Khomh, F., Desmarais, M.C.,
    Jiang, Z.M.J.: Github copilot ai pair programmer: Asset or liability? Journal
    of Systems and Software 203, 111734 (2023). https://doi.org/10.48550/ARXIV.2206.15331'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Dakhel, A.M., Majdinasab, V., Nikanjam, A., Khomh, F., Desmarais, M.C.,
    Jiang, Z.M.J.: Github Copilot AI配对程序员：资产还是负担？《系统与软件期刊》203，111734（2023）。https://doi.org/10.48550/ARXIV.2206.15331'
- en: '[5] Desai, C., Janzen, D.S., Clements, J.: Implications of integrating test-driven
    development into CS1/CS2 curricula. SIGCSE Bull. 41(1), 148–152 (Mar 2009)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Desai, C., Janzen, D.S., Clements, J.: 将测试驱动开发集成到CS1/CS2课程中的影响。SIGCSE公报，41(1)，148–152（2009年3月）'
- en: '[6] Dohmke, T.: GitHub copilot x: The AI-powered developer experience. [https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/)
    (Mar 2023), accessed: 2023-9-5'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Dohmke, T.: GitHub Copilot X：AI驱动的开发者体验。[https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/)（2023年3月），访问日期：2023年9月5日'
- en: '[7] Edwards, S.H., Shams, Z.: Comparing test quality measures for assessing
    student-written tests. In: Companion Proceedings of the 36th International Conference
    on Software Engineering. pp. 354–363\. ICSE Companion 2014, Association for Computing
    Machinery, New York, NY, USA (May 2014)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Edwards, S.H., Shams, Z.: 比较评估学生编写的测试的测试质量指标。载于：第36届国际软件工程会议论文集。第354–363页。ICSE
    Companion 2014，计算机协会，纽约，美国（2014年5月）'
- en: '[8] Edwards, S.H., Shams, Z.: Do student programmers all tend to write the
    same software tests? In: Proceedings of the 2014 conference on Innovation & technology
    in computer science education. pp. 171–176\. ITiCSE ’14, Association for Computing
    Machinery, New York, NY, USA (Jun 2014)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Edwards, S.H., Shams, Z.: 学生程序员是否都倾向于编写相同的软件测试？载于：2014年创新与技术计算机科学教育会议论文集。第171–176页。ITiCSE
    ’14，计算机协会，纽约，美国（2014年6月）'
- en: '[9] Ericsson, A., Pool, R.: Peak: Secrets from the new science of expertise.
    Random House (2016)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Ericsson, A., Pool, R.: 《峰值：新科学的专业性秘密》。兰登书屋（2016年）'
- en: '[10] Fitzgerald, S., McCauley, R., Hanks, B., Murphy, L., Simon, B., Zander,
    C.: Debugging from the student perspective. IEEE Trans. Educ. 53(3), 390–396 (2010)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Fitzgerald, S., McCauley, R., Hanks, B., Murphy, L., Simon, B., Zander,
    C.: 从学生角度看调试。IEEE教育学报，53(3)，390–396（2010年）'
- en: '[11] Ganguli, D., Hernandez, D., Lovitt, L., Askell, A., Bai, Y., Chen, A.,
    Conerly, T., Dassarma, N., Drain, D., Elhage, N., et al.: Predictability and surprise
    in large generative models. In: Proceedings of the 2022 ACM Conference on Fairness,
    Accountability, and Transparency. pp. 1747–1764 (2022)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Ganguli, D., Hernandez, D., Lovitt, L., Askell, A., Bai, Y., Chen, A.,
    Conerly, T., Dassarma, N., Drain, D., Elhage, N., 等：大规模生成模型中的可预测性与惊讶。载于：2022年ACM公平性、问责制与透明度会议论文集。第1747–1764页（2022年）'
- en: '[12] Kallia, M.: The search for meaning: Inferential strategic reading comprehension
    in programming. In: Proceedings of the 2023 ACM Conference on International Computing
    Education Research (ICER ’23). ACM (May 2023)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Kallia, M.: 寻找意义：编程中的推理性战略阅读理解。载于：2023年ACM国际计算教育研究会议（ICER ’23）论文集。ACM（2023年5月）'
- en: '[13] Ko, A.J., Myers, B.A.: Debugging reinvented: asking and answering why
    and why not questions about program behavior. In: Proceedings of the 30th international
    conference on Software engineering. pp. 301–310\. ICSE ’08, Association for Computing
    Machinery, New York, NY, USA (May 2008)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Ko, A.J., Myers, B.A.: 调试的重塑：问与答关于程序行为的“为什么”和“为什么不”。载于：第30届国际软件工程会议论文集。第301–310页。ICSE
    ’08，计算机协会，纽约，美国（2008年5月）'
- en: '[14] Lukasová, A.: Hierarchical agglomerative clustering procedure. Pattern
    Recognition 11(5-6), 365–381 (1979)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Lukasová, A.: 层次聚类过程。模式识别，11(5-6)，365–381（1979年）'
- en: '[15] Luxton-Reilly, A., McMillan, E., Stevenson, E., Tempero, E., Denny, P.:
    Ladebug: an online tool to help novice programmers improve their debugging skills.
    In: Proceedings of the 23rd Annual ACM Conference on Innovation and Technology
    in Computer Science Education. pp. 159–164\. ITiCSE 2018, Association for Computing
    Machinery (Jul 2018)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Luxton-Reilly, A., McMillan, E., Stevenson, E., Tempero, E., Denny, P.:
    Ladebug：一款帮助初学程序员提高调试技能的在线工具。载于：第23届年度ACM创新与技术计算机科学教育会议论文集。第159–164页。ITiCSE 2018，计算机协会（2018年7月）'
- en: '[16] Ma, Q., Wu, T., Koedinger, K.: Is AI the better programming partner? Human-Human
    pair programming vs. Human-AI pAIr programming. arXiv preprint arXiv:2306.05153
    (2023), [http://arxiv.org/abs/2306.05153](http://arxiv.org/abs/2306.05153)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Ma, Q., Wu, T., Koedinger, K.: AI是更好的编程伙伴吗？人类与人类配对编程与人类与AI配对编程。arXiv 预印本
    arXiv:2306.05153 (2023)，[http://arxiv.org/abs/2306.05153](http://arxiv.org/abs/2306.05153)'
- en: '[17] MacNeil, S., Tran, A., Mogil, D., Bernstein, S., Ross, E., Huang, Z.:
    Generating diverse code explanations using the gpt-3 large language model. In:
    Proceedings of the 2022 ACM Conference on International Computing Education Research-Volume
    2\. pp. 37–39 (2022)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] MacNeil, S., Tran, A., Mogil, D., Bernstein, S., Ross, E., Huang, Z.:
    使用GPT-3大语言模型生成多样化的代码解释。在：2022年ACM国际计算教育研究会议论文集-第2卷。第37–39页 (2022)'
- en: '[18] Markel, J.M., Opferman, S.G., Landay, J.A., Piech, C.: GPTeach: Interactive
    TA training with GPT-based students. In: Proceedings of the Tenth ACM Conference
    on Learning @ Scale. pp. 226–236\. L@S ’23, Association for Computing Machinery,
    New York, NY, USA (Jul 2023). https://doi.org/10.1145/3573051.3593393'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Markel, J.M., Opferman, S.G., Landay, J.A., Piech, C.: GPTeach：基于GPT的学生进行互动式助教培训。在：第十届ACM学习规模会议论文集。第226–236页。L@S
    ''23，计算机协会，美国纽约 (2023年7月)。https://doi.org/10.1145/3573051.3593393'
- en: '[19] McCauley, R., Fitzgerald, S., Lewandowski, G., Murphy, L., Simon, B.,
    Thomas, L., Zander, C.: Debugging: A review of the literature from an educational
    perspective. Computer Science Education 18(2), 67–92 (Jun 2008)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] McCauley, R., Fitzgerald, S., Lewandowski, G., Murphy, L., Simon, B.,
    Thomas, L., Zander, C.: 调试：从教育角度的文献综述。计算机科学教育 18(2)，67–92 (2008年6月)'
- en: '[20] Mozannar, H., Bansal, G., Fourney, A., Horvitz, E.: Reading between the
    lines: Modeling user behavior and costs in ai-assisted programming. arXiv preprint
    arXiv:2210.14306 (2022)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Mozannar, H., Bansal, G., Fourney, A., Horvitz, E.: 细读背后：建模用户行为和人工智能辅助编程中的成本。arXiv
    预印本 arXiv:2210.14306 (2022)'
- en: '[21] News, Y.H.: Why don’t schools teach debugging? [https://news.ycombinator.com/item?id=7215870](https://news.ycombinator.com/item?id=7215870)
    (Feb 2014), accessed: 2023-9-8'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] News, Y.H.: 为什么学校不教调试？[https://news.ycombinator.com/item?id=7215870](https://news.ycombinator.com/item?id=7215870)
    (2014年2月)，访问日期：2023年9月8日'
- en: '[22] Savelka, J., Agarwal, A., An, M., Bogart, C., Sakr, M.: Thrilled by your
    progress! large language models (gpt-4) no longer struggle to pass assessments
    in higher education programming courses. arXiv preprint arXiv:2306.10073 (2023)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Savelka, J., Agarwal, A., An, M., Bogart, C., Sakr, M.: 为你的进展而兴奋！大型语言模型（GPT-4）不再难以通过高等教育编程课程中的评估。arXiv
    预印本 arXiv:2306.10073 (2023)'
- en: '[23] Shahriar, T., Matsuda, N.: What and how you explain matters: Inquisitive
    teachable agent scaffolds knowledge-building for tutor learning. In: International
    Conference on Artificial Intelligence in Education. pp. 126–138\. Springer (2023)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Shahriar, T., Matsuda, N.: 你如何解释很重要：好奇心强的可教代理通过支架式学习促进导师学习的知识构建。在：国际人工智能教育大会。第126–138页。Springer
    (2023)'
- en: '[24] Wang, Z., Valdez, J., Basu Mallick, D., Baraniuk, R.G.: Towards Human-Like
    educational question generation with large language models. In: Artificial Intelligence
    in Education. pp. 153–166\. Springer International Publishing (2022)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Wang, Z., Valdez, J., Basu Mallick, D., Baraniuk, R.G.: 面向类人教育性问题生成的大型语言模型研究。在：人工智能教育。第153–166页。Springer国际出版
    (2022)'
- en: '[25] Whalley, J., Settle, A., Luxton-Reilly, A.: Analysis of a process for
    introductory debugging. In: Proceedings of the 23rd Australasian Computing Education
    Conference. pp. 11–20\. ACE ’21, Association for Computing Machinery (Mar 2021)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Whalley, J., Settle, A., Luxton-Reilly, A.: 介绍性调试过程分析。在：第23届澳大利亚计算机教育会议论文集。第11–20页。ACE
    ''21，计算机协会 (2021年3月)'
- en: '[26] Wiggins, G.P., McTighe, J.: Understanding by Design. ASCD (2005)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Wiggins, G.P., McTighe, J.: 设计理解。ASCD (2005)'
- en: '[27] Wu, T., Terry, M., Cai, C.J.: AI chains: Transparent and controllable
    Human-AI interaction by chaining large language model prompts. In: Proceedings
    of the 2022 CHI Conference on Human Factors in Computing Systems. pp. 1–22\. No.
    Article 385 in CHI ’22, Association for Computing Machinery, New York, NY, USA
    (2022)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Wu, T., Terry, M., Cai, C.J.: AI链：通过链接大型语言模型提示实现透明且可控的人工智能互动。在：2022年CHI计算机系统人因会议论文集。第1–22页。CHI
    ''22，计算机协会，美国纽约 (2022)'
- en: '[28] Xie, J., Zhang, K., Chen, J., Lou, R., Su, Y.: Adaptive chameleon or stubborn
    sloth: Unraveling the behavior of large language models in knowledge clashes (2023)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Xie, J., Zhang, K., Chen, J., Lou, R., Su, Y.: 自适应变色龙或顽固树懒：揭示大型语言模型在知识冲突中的行为
    (2023)'
- en: '[29] Xu, S., Rajlich, V.: Cognitive process during program debugging. In: Proceedings
    of the Third IEEE International Conference on Cognitive Informatics, 2004\. pp.
    176–182\. IEEE (Aug 2004)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Xu, S., Rajlich, V.：《程序调试中的认知过程》。载《第三届IEEE国际认知信息学会议论文集》，2004年。第176–182页。IEEE（2004年8月）'
- en: '[30] Zeller, A.: Why programs fail: A guide to systematic debugging. Morgan
    Kaufmann, Oxford, England, 2 edn. (Jun 2009)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Zeller, A.：《为什么程序会失败：系统调试指南》。摩根·考夫曼出版社，英国牛津，第2版。（2009年6月）'
