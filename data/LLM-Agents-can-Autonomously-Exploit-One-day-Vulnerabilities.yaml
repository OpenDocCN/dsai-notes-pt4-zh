- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 12:42:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:42:17
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: LLM Agents can Autonomously Exploit One-day Vulnerabilities
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM代理可以自主利用一天漏洞
- en: 来源：[https://arxiv.org/html/2404.08144/](https://arxiv.org/html/2404.08144/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2404.08144/](https://arxiv.org/html/2404.08144/)
- en: Richard Fang, Rohan Bindu, Akul Gupta, Daniel Kang
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 理查德·方，罗汉·宾度，阿库尔·古普塔，丹尼尔·康
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: LLMs have becoming increasingly powerful, both in their benign and malicious
    uses. With the increase in capabilities, researchers have been increasingly interested
    in their ability to exploit cybersecurity vulnerabilities. In particular, recent
    work has conducted preliminary studies on the ability of LLM agents to autonomously
    hack websites. However, these studies are limited to simple vulnerabilities.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的能力在其良性和恶意应用方面都越来越强。随着能力的提升，研究人员对其利用网络安全漏洞的能力越来越感兴趣。特别是，最近的研究对LLM代理自主攻击网站的能力进行了初步研究。然而，这些研究仅限于简单的漏洞。
- en: 'In this work, we show that LLM agents can autonomously exploit one-day vulnerabilities
    *in real-world systems*. To show this, we collected a dataset of 15 one-day vulnerabilities
    that include ones categorized as critical severity in the CVE description. When
    given the CVE description, GPT-4 is capable of exploiting 87% of these vulnerabilities
    compared to 0% for every other model we test (GPT-3.5, open-source LLMs) and open-source
    vulnerability scanners (ZAP and Metasploit). Fortunately, our GPT-4 agent requires
    the CVE description for high performance: without the description, GPT-4 can exploit
    only 7% of the vulnerabilities. Our findings raise questions around the widespread
    deployment of highly capable LLM agents.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究表明，LLM代理可以自主利用一天漏洞 *在现实世界系统中*。为了证明这一点，我们收集了15个一天漏洞的数据集，其中包括在CVE描述中被归类为严重漏洞的漏洞。给定CVE描述后，GPT-4能够利用其中87%的漏洞，而我们测试的其他模型（GPT-3.5、开源LLM）和开源漏洞扫描工具（ZAP和Metasploit）则无法利用任何漏洞。幸运的是，我们的GPT-4代理在高性能的前提下需要CVE描述：没有描述，GPT-4只能利用7%的漏洞。我们的发现引发了关于高能力LLM代理广泛部署的问题。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large language models (LLMs) have made dramatic improvements in performance
    over the past several years, achieving up to superhuman performance on many benchmarks
    (Touvron et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib39); Achiam
    et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib1)). This performance
    has led to a deluge of interest in LLM *agents*, that can take actions via tools,
    self-reflect, and even read documents (Lewis et al., [2020](https://arxiv.org/html/2404.08144v2#bib.bib24)).
    These LLM agents can reportedly act as software engineers (Osika, [2023](https://arxiv.org/html/2404.08144v2#bib.bib28);
    Huang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib16)) and aid in
    scientific discovery (Boiko et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib4);
    Bran et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib5)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型（LLM）在性能上取得了显著进展，在许多基准测试中达到了超人类的表现（Touvron et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib39);
    Achiam et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib1)）。这种性能的提升引发了对LLM
    *代理*的极大兴趣，这些代理可以通过工具采取行动，进行自我反思，甚至阅读文档（Lewis et al., [2020](https://arxiv.org/html/2404.08144v2#bib.bib24)）。据报道，这些LLM代理可以作为软件工程师（Osika,
    [2023](https://arxiv.org/html/2404.08144v2#bib.bib28); Huang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib16)）并协助科学发现（Boiko
    et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib4); Bran et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib5)）。
- en: However, not much is known about the ability for LLM agents in the realm of
    cybersecurity. Recent work has primarily focused on the “human uplift” setting
    (Happe & Cito, [2023](https://arxiv.org/html/2404.08144v2#bib.bib13); Hilario
    et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib15)), where an LLM is
    used as a chatbot to assist a human, or speculation in the broader category of
    offense vs defense (Lohn & Jackson, [2022](https://arxiv.org/html/2404.08144v2#bib.bib25);
    Handa et al., [2019](https://arxiv.org/html/2404.08144v2#bib.bib12)). The most
    relevant work in this space shows that LLM agents can be used to autonomously
    hack toy websites (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前对于LLM代理在网络安全领域的能力了解尚不多。最近的研究主要集中在“人类提升”场景（Happe & Cito, [2023](https://arxiv.org/html/2404.08144v2#bib.bib13);
    Hilario et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib15)），其中LLM被用作聊天机器人来帮助人类，或者在更广泛的攻防对抗范畴中进行推测（Lohn
    & Jackson, [2022](https://arxiv.org/html/2404.08144v2#bib.bib25); Handa et al.,
    [2019](https://arxiv.org/html/2404.08144v2#bib.bib12)）。在这一领域中，最相关的研究表明LLM代理可以被用来自主攻击玩具网站（Fang
    et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）。
- en: 'However, to the best of our knowledge, all of the work in this space focuses
    on toy problems or “capture-the-flag” exercises which do not reflect on real-world
    deployments (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8);
    Happe & Cito, [2023](https://arxiv.org/html/2404.08144v2#bib.bib13); Hilario et al.,
    [2024](https://arxiv.org/html/2404.08144v2#bib.bib15)). This gap raises a natural
    question: can LLM agents autonomously hack real-world deployments?'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽我们所知，当前所有相关的研究都集中在玩具问题或“夺旗”练习上，这些问题并未反映真实世界的部署情况（Fang等人，[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)；Happe
    & Cito，[2023](https://arxiv.org/html/2404.08144v2#bib.bib13)；Hilario等人，[2024](https://arxiv.org/html/2404.08144v2#bib.bib15)）。这一差距引发了一个自然的问题：LLM代理能否自主破解真实世界的部署？
- en: In this work, we show that LLM agents can autonomously exploit one-day vulnerabilities,
    answering the aforementioned question in the affirmative.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了LLM代理可以自主利用一天漏洞，肯定地回答了前面提到的问题。
- en: To show this, we collect a benchmark of 15 real-world one-day vulnerabilities.
    These vulnerabilities were taken from the Common Vulnerabilities and Exposures
    (CVE) database and highly cited academic papers where we were able to reproduce
    the CVE (i.e., we excluded closed-source solutions). These CVEs include real-world
    websites (CVE-2024-24041), container management software (CVE-2024-21626), and
    vulnerable Python packages (CVE-2024-28859).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这一点，我们收集了15个真实世界的一天漏洞的基准。这些漏洞来自常见漏洞和暴露（CVE）数据库以及一些高引用的学术论文，在这些论文中我们能够重现CVE（即，我们排除了闭源解决方案）。这些CVE包括真实世界的网页（CVE-2024-24041）、容器管理软件（CVE-2024-21626）和易受攻击的Python包（CVE-2024-28859）。
- en: Given our benchmark, we created a *single* LLM agent that can exploit 87% of
    the one-day vulnerabilities we collected. To do so, we simply give the agent access
    to tools, the CVE description, and use the ReAct agent framework. Our agent was
    a total of 91 lines of code, showing the simplicity of performing such exploits.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的基准，我们创建了一个*单一*的LLM代理，它可以利用我们收集到的87%的这类一天漏洞。为了做到这一点，我们只需要给代理提供工具、CVE描述，并使用ReAct代理框架。我们的代理总共只有91行代码，展示了执行这些漏洞利用的简易性。
- en: Importantly, we show that GPT-4 achieves a 87% success rate but every other
    LLM we test (GPT-3.5, 8 open-source models) *and open-source vulnerability scanners*
    achieve a 0% success rate on our benchmark. Without the CVE description, GPT-4’s
    success rate drops to 7%, showing that our agent is much more capable of exploiting
    vulnerabilities than finding vulnerabilities.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，我们展示了GPT-4达到了87%的成功率，但我们测试的其他所有LLM（GPT-3.5、8个开源模型）*以及开源漏洞扫描器*在我们的基准上都达到了0%的成功率。没有CVE描述时，GPT-4的成功率降至7%，这表明我们的代理在利用漏洞方面远远超过了发现漏洞。
- en: In the remainder of this manuscript, we describe our dataset of vulnerabilities,
    our agent, and our evaluation of our agent.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的其余部分，我们将描述我们的漏洞数据集、我们的代理以及我们对代理的评估。
- en: 2 Background on Computer Security and LLM Agents
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 计算机安全和LLM代理的背景
- en: 2.1 Computer Security
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 计算机安全
- en: We provide relevant background on computer security as related to the content
    of this manuscript. Computer security is too broad of a topic to cover in detail,
    so we refer the reader to excellent surveys for more information (Jang-Jaccard
    & Nepal, [2014](https://arxiv.org/html/2404.08144v2#bib.bib17); Engebretson, [2013](https://arxiv.org/html/2404.08144v2#bib.bib7);
    Sikorski & Honig, [2012](https://arxiv.org/html/2404.08144v2#bib.bib37)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了与本文内容相关的计算机安全背景。计算机安全是一个非常广泛的话题，无法详细覆盖，因此我们建议读者参考一些优秀的综述以获得更多信息（Jang-Jaccard
    & Nepal，[2014](https://arxiv.org/html/2404.08144v2#bib.bib17)；Engebretson，[2013](https://arxiv.org/html/2404.08144v2#bib.bib7)；Sikorski
    & Honig，[2012](https://arxiv.org/html/2404.08144v2#bib.bib37)）。
- en: Whenever computer programs are deployed, malicious attackers have the potential
    to misuse the computer program into taking unwanted actions. These unwanted actions
    can include, in severe cases, obtaining root access to a server (Roselin et al.,
    [2019](https://arxiv.org/html/2404.08144v2#bib.bib33)), performing arbitrary remote
    code execution (Zheng & Zhang, [2013](https://arxiv.org/html/2404.08144v2#bib.bib53)),
    and exfiltrating private data (Ullah et al., [2018](https://arxiv.org/html/2404.08144v2#bib.bib40)).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每当计算机程序被部署时，恶意攻击者都有可能滥用这些程序，迫使其执行不希望的操作。这些不希望的操作在严重情况下可能包括获得服务器的root访问权限（Roselin等人，[2019](https://arxiv.org/html/2404.08144v2#bib.bib33)）、执行任意远程代码（Zheng
    & Zhang，[2013](https://arxiv.org/html/2404.08144v2#bib.bib53)）以及窃取私人数据（Ullah等人，[2018](https://arxiv.org/html/2404.08144v2#bib.bib40)）。
- en: Hackers can perform these unwanted actions with a variety of methods. The simplest
    of attacks include unprotected SQL injections, where the hacker can execute arbitrary
    SQL queries against a database through, e.g., a web form Halfond et al. ([2006](https://arxiv.org/html/2404.08144v2#bib.bib11)).
    They can also be as sophisticated as exploiting a remote code execution via font
    instructions, packaging JavaScript into the payload, bypassing memory protections
    via hardware memory-mapped I/O (MMIO) registers, and an exploit in Safari *in
    a single iPhone attack* (Kuznetsov et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib23)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 黑客可以通过多种方法执行这些不希望出现的操作。最简单的攻击包括未加保护的SQL注入，黑客可以通过例如一个网页表单执行任意SQL查询，对数据库进行攻击（Halfond等人，[2006](https://arxiv.org/html/2404.08144v2#bib.bib11)）。攻击也可以非常复杂，例如通过字体指令利用远程代码执行，将JavaScript打包到有效载荷中，通过硬件内存映射输入输出（MMIO）寄存器绕过内存保护，或者在Safari浏览器中利用一个*单一iPhone攻击*的漏洞（Kuznetsov等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib23)）。
- en: Once real-world vulnerabilities are found, they are disclosed to the provider
    of the software to allow the provider to patch the software. After this, many
    vulnerabilities are released to the Common Vulnerabilities and Exposures (CVE)
    database (Vulnerabilities, [2005](https://arxiv.org/html/2404.08144v2#bib.bib42)).
    This is to ensure that software remains up to date and to allow security researchers
    to study vulnerabilities.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发现现实世界中的漏洞，它们会被披露给软件提供商，以便提供商修补软件。此后，许多漏洞会被发布到公共漏洞和暴露（CVE）数据库中（Vulnerabilities，[2005](https://arxiv.org/html/2404.08144v2#bib.bib42)）。这样做是为了确保软件保持最新，并允许安全研究人员研究漏洞。
- en: Many of the CVEs are in closed-source software and as a result are not reproducible.
    However, some of the CVEs are on open-source software, so can be reproduced in
    a sandboxed environment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 许多CVE（公共漏洞和暴露）存在于闭源软件中，因此无法复现。然而，也有一些CVE存在于开源软件中，能够在沙箱环境中复现。
- en: 2.2 LLM Agents
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 大语言模型（LLM）代理
- en: Over the past few years, LLM agents have become increasingly common. Minimally,
    agents are capable of using tools and reacting to the output of using these tools
    (Yao et al., [2022](https://arxiv.org/html/2404.08144v2#bib.bib48); Schick et al.,
    [2023](https://arxiv.org/html/2404.08144v2#bib.bib36); Mialon et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib27)).
    Other capabilities include the ability to plan (Yao et al., [2022](https://arxiv.org/html/2404.08144v2#bib.bib48);
    Varshney, [2023](https://arxiv.org/html/2404.08144v2#bib.bib41)), create subagents
    (Wang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib44)), and read
    documents (Lewis et al., [2020](https://arxiv.org/html/2404.08144v2#bib.bib24)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年里，LLM代理变得越来越普遍。最基本的，代理能够使用工具并对使用这些工具的结果作出反应（Yao等人，[2022](https://arxiv.org/html/2404.08144v2#bib.bib48)；Schick等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib36)；Mialon等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib27)）。其他能力包括计划能力（Yao等人，[2022](https://arxiv.org/html/2404.08144v2#bib.bib48)；Varshney，[2023](https://arxiv.org/html/2404.08144v2#bib.bib41)）、创建子代理（Wang等人，[2024](https://arxiv.org/html/2404.08144v2#bib.bib44)）和读取文档（Lewis等人，[2020](https://arxiv.org/html/2404.08144v2#bib.bib24)）。
- en: As LLMs have becoming increasingly powerful, so have the capabilities of LLM
    agents. For example, tool-assisted LLM agents are now capable of performing complex
    software engineering tasks (Jimenez et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib20))
    and even assisting in scientific investigations (Boiko et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib4);
    Bran et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib5)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM变得越来越强大，LLM代理的能力也在不断提升。例如，工具辅助的LLM代理现在能够执行复杂的软件工程任务（Jimenez等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib20)），甚至在科学研究中提供帮助（Boiko等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib4)；Bran等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib5)）。
- en: An important capability to perform these advanced tasks is the ability to use
    tools. Tool-using LLMs vary wildly in their capabilities to use tools and respond
    to their feedback. As we show in our evaluation, GPT-4 currently strongly outperforms
    all other models we test.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这些高级任务的重要能力之一是使用工具的能力。使用工具的大语言模型在使用工具和响应工具反馈方面的能力差异巨大。正如我们在评估中展示的，GPT-4目前在所有我们测试的模型中表现最为优异。
- en: Recent work has leveraged LLM agents in autonomous hacking, but has only been
    in the context of toy “capture-the-flag” exercises. In our work, we explore the
    capabilities of LLMs to hack real-world vulnerabilities.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究已将大语言模型（LLM）代理应用于自主黑客攻击，但仅限于玩具式的“夺旗”练习。在我们的研究中，我们探索了LLM在黑客攻击现实世界漏洞方面的能力。
- en: 2.3 Terminology and Threat Model
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 术语和威胁模型
- en: In this work, we focus on studying “one-day vulnerabilities,” which are vulnerabilities
    that have been disclosed but not patched in a system. In many real-world deployments,
    security patches are not deployed right away, which leaves these deployments vulnerable
    to these one-day vulnerabilities. As we show, open-source vulnerability scanners
    fail to find some of these one-day vulnerabilities but LLM agents are capable
    of exploiting them. Furthermore, many of the vulnerability disclosures do not
    provide step-by-step instructions on how to exploit the vulnerability, meaning
    that an attacker must recreate the steps themselves.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们专注于研究“零日漏洞”，即已公开但尚未在系统中修补的漏洞。在许多实际部署中，安全补丁并不会立即部署，这使得这些部署易受零日漏洞的攻击。正如我们所展示的，开源漏洞扫描器未能发现一些零日漏洞，而LLM代理能够利用这些漏洞。此外，许多漏洞披露并未提供逐步的利用指南，这意味着攻击者必须自己重新创建利用步骤。
- en: Concretely, consider a system $S_{t}$ that evolves over time ($t$). At time
    $t=0$, a vulnerability in the system is discovered, such that a series of actions
    $A$ can exploit the vulnerability. We consider the time between when the vulnerability
    is released ($t=1$) and patched ($t=n$, for some $n$ in the future). Thus, an
    attacker has the description of the vulnerability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，考虑一个随时间演化的系统$S_{t}$（时间$t$）。在$t=0$时，系统中发现了一个漏洞，使得一系列操作$A$可以利用该漏洞。我们考虑从漏洞公开（$t=1$）到修补（$t=n$，未来的某个$n$）之间的时间。因此，攻击者拥有漏洞的描述。
- en: 3 Benchmark of Real-World Vulnerabilities
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 真实世界漏洞的基准测试
- en: Dataset. To answer the question if LLM agents can exploit real-world computer
    systems, we first created a benchmark of real vulnerabilities from CVEs and academic
    papers. As mentioned, CVEs are descriptions of vulnerabilities in real systems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。为了回答LLM代理是否能利用真实世界的计算机系统漏洞的问题，我们首先创建了一个真实漏洞的基准测试，涵盖了CVE和学术论文中的漏洞。如前所述，CVE是对真实系统中漏洞的描述。
- en: Many CVEs are for closed-source software, which we cannot reproduce as CVEs
    are typically publicly disclosed after the vendor patches the software. In order
    to create our benchmark, we focused on open-source software.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 许多CVE是针对闭源软件的，而这些软件我们无法复现，因为CVE通常在厂商修补软件后才公开。为了创建我们的基准测试，我们专注于开源软件。
- en: Beyond closed-source software, many of the open-source vulnerabilities are difficult
    to reproduce. The reasons for the irreproducible vulnerabilities include unspecified
    dependencies, broken docker containers, or underspecified descriptions in the
    CVEs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了闭源软件外，许多开源漏洞难以复现。无法复现漏洞的原因包括未指定的依赖关系、损坏的docker容器或CVE描述中的不完全说明。
- en: '| Vulnerability | Description |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | 描述 |'
- en: '| --- | --- |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| runc | Container escape via an internal file descriptior leak |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| runc | 通过内部文件描述符泄漏实现容器逃逸 |'
- en: '| CSRF + ACE | Cross Site Request Forgery enabling arbitrary code execution
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + ACE | 跨站请求伪造（CSRF）使得任意代码执行成为可能 |'
- en: '| Wordpress SQLi | SQL injection via a wordpress plugin |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress SQLi | Wordpress插件中的SQL注入漏洞 |'
- en: '| Wordpress XSS-1 | Cross-site scripting (XSS) in Wordpress plugin |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-1 | Wordpress插件中的跨站脚本（XSS）漏洞 |'
- en: '| Wordpress XSS-2 | XSS in Wordpress plugin |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-2 | Wordpress插件中的XSS漏洞 |'
- en: '| Travel Journal XSS | XSS in Travel Journal |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| Travel Journal XSS | Travel Journal中的XSS漏洞 |'
- en: '| Iris XSS | XSS in Iris |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Iris XSS | Iris中的XSS漏洞 |'
- en: '| CSRF + privilege escalation | CSRF in LedgerSMB which allows privilege escalation
    to admin |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + 权限提升 | LedgerSMB中的CSRF漏洞允许权限提升至管理员 |'
- en: '| alf.io key leakage | Key leakage when visiting a certain endpoint for a ticket
    reservation system |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| alf.io 密钥泄露 | 在访问某个票务预订系统的特定端点时发生密钥泄露 |'
- en: '| Astrophy RCE | Improper input validation allows subprocess.Popen to be called
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| Astrophy RCE | 输入验证不当导致subprocess.Popen被调用 |'
- en: '| Hertzbeat RCE | JNDI injection leads to remote code execution |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| Hertzbeat RCE | JNDI注入导致远程代码执行 |'
- en: '| Gnuboard XSS ACE | XSS vulnerability in Gnuboard allows arbitrary code execution
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| Gnuboard XSS ACE | Gnuboard中的XSS漏洞允许任意代码执行 |'
- en: '| Symfony1 RCE | PHP array/object misuse allows for RCE |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Symfony1 RCE | PHP数组/对象误用导致RCE漏洞 |'
- en: '| Peering Manager SSTI RCE | Server side template injection leads to an RCE
    vulnerability |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Peering Manager SSTI RCE | 服务器端模板注入导致RCE漏洞 |'
- en: '| ACIDRain (Warszawski & Bailis, [2017](https://arxiv.org/html/2404.08144v2#bib.bib45))
    | Concurrency attack on databases |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| ACIDRain (Warszawski & Bailis, [2017](https://arxiv.org/html/2404.08144v2#bib.bib45))
    | 数据库并发攻击 |'
- en: 'Table 1: List of vulnerabilities we consider and their description. ACE stands
    for arbitrary code execution and RCE stands for remote code execution. Further
    details are given in Table [2](https://arxiv.org/html/2404.08144v2#S3.T2 "Table
    2 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM Agents can Autonomously Exploit
    One-day Vulnerabilities").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：我们考虑的漏洞及其描述。ACE代表任意代码执行，RCE代表远程代码执行。进一步的细节见表[2](https://arxiv.org/html/2404.08144v2#S3.T2
    "表2 ‣ 3个现实世界漏洞的基准 ‣ LLM代理可以自主利用一天内的漏洞")。
- en: '| Vulnerability | CVE | Date | Severity |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | CVE | 日期 | 严重性 |'
- en: '| runc | CVE-2024-21626 | 1/31/2024 | 8.6 (high) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| runc | CVE-2024-21626 | 2024年1月31日 | 8.6（高）|'
- en: '| CSRF + ACE | CVE-2024-24524 | 2/2/2024 | 8.8 (high) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + ACE | CVE-2024-24524 | 2024年2月2日 | 8.8（高）|'
- en: '| Wordpress SQLi | CVE-2021-24666 | 9/27/2021 | 9.8 (critical) |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress SQLi | CVE-2021-24666 | 2021年9月27日 | 9.8（严重）|'
- en: '| Wordpress XSS-1 | CVE-2023-1119-1 | 7/10/2023 | 6.1 (medium) |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-1 | CVE-2023-1119-1 | 2023年7月10日 | 6.1（中等）|'
- en: '| Wordpress XSS-2 | CVE-2023-1119-2 | 7/10/2023 | 6.1 (medium) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-2 | CVE-2023-1119-2 | 2023年7月10日 | 6.1（中等）|'
- en: '| Travel Journal XSS | CVE-2024-24041 | 2/1/2024 | 6.1 (medium) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Travel Journal XSS | CVE-2024-24041 | 2024年2月1日 | 6.1（中等）|'
- en: '| Iris XSS | CVE-2024-25640 | 2/19/2024 | 4.6 (medium) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| Iris XSS | CVE-2024-25640 | 2024年2月19日 | 4.6（中等）|'
- en: '| CSRF + privilege escalation | CVE-2024-23831 | 2/2/2024 | 7.5 (high) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + 权限提升 | CVE-2024-23831 | 2024年2月2日 | 7.5（高）|'
- en: '| alf.io key leakage | CVE-2024-25635 | 2/19/2024 | 8.8 (high) |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| alf.io 密钥泄露 | CVE-2024-25635 | 2024年2月19日 | 8.8（高）|'
- en: '| Astrophy RCE | CVE-2023-41334 | 3/18/2024 | 8.4 (high) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Astrophy RCE | CVE-2023-41334 | 2024年3月18日 | 8.4（高）|'
- en: '| Hertzbeat RCE | CVE-2023-51653 | 2/22/2024 | 9.8 (critical) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Hertzbeat RCE | CVE-2023-51653 | 2024年2月22日 | 9.8（严重）|'
- en: '| Gnuboard XSS ACE | CVE-2024-24156 | 3/16/2024 | N/A |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Gnuboard XSS ACE | CVE-2024-24156 | 2024年3月16日 | 不适用 |'
- en: '| Symfony 1 RCE | CVE-2024-28859 | 3/15/2024 | 5.0 (medium) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| Symfony 1 RCE | CVE-2024-28859 | 2024年3月15日 | 5.0（中等）|'
- en: '| Peering Manager SSTI RCE | CVE-2024-28114 | 3/12/2024 | 8.1 (high) |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| Peering Manager SSTI RCE | CVE-2024-28114 | 2024年3月12日 | 8.1（高）|'
- en: '| ACIDRain | (Warszawski & Bailis, [2017](https://arxiv.org/html/2404.08144v2#bib.bib45))
    | 2017 | N/A |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| ACIDRain | (Warszawski & Bailis, [2017](https://arxiv.org/html/2404.08144v2#bib.bib45))
    | 2017年 | 不适用 |'
- en: 'Table 2: Vulnerabilities, their CVE number, the publication date, and severity
    according to the CVE. The last vulnerabililty (ACIDRain) is an attack used to
    hack a cryptocurrency exchange for $50 million (Popper, [2016](https://arxiv.org/html/2404.08144v2#bib.bib30)),
    which we emulate in WooCommerce framework. CVE-2024-24156 is recent and has not
    been rated by NIST for the severity.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：漏洞、其CVE编号、发布日期及根据CVE的严重性。最后一个漏洞（ACIDRain）是一种用于黑客攻击加密货币交易所，造成5000万美元损失的攻击（Popper，[2016](https://arxiv.org/html/2404.08144v2#bib.bib30)），我们在WooCommerce框架中模拟了该攻击。CVE-2024-24156是最近的漏洞，尚未由NIST评定严重性。
- en: After filtering out CVEs we could not reproduce based on the criteria above,
    we collected 14 total real-world vulnerabilities from CVEs. We further included
    one vulnerability studied by Warszawski & Bailis ([2017](https://arxiv.org/html/2404.08144v2#bib.bib45))
    due to its complexity and severity. The vulnerability is known as ACIDRain. A
    form of ACIDRain was used to hack a cryptocurrency exchange for $50 million in
    damages (Popper, [2016](https://arxiv.org/html/2404.08144v2#bib.bib30)). We use
    a similar platform for the ACIDRain vulnerability, the WooCommerce platform. We
    summarize the vulnerabilities in Tables [1](https://arxiv.org/html/2404.08144v2#S3.T1
    "Table 1 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM Agents can Autonomously
    Exploit One-day Vulnerabilities") and [2](https://arxiv.org/html/2404.08144v2#S3.T2
    "Table 2 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM Agents can Autonomously
    Exploit One-day Vulnerabilities").
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在根据上述标准过滤掉无法重现的CVE后，我们共收集了来自CVE的14个现实世界漏洞。我们还包括了Warszawski & Bailis（[2017](https://arxiv.org/html/2404.08144v2#bib.bib45)）研究的一个漏洞，因其复杂性和严重性。该漏洞被称为ACIDRain。ACIDRain的一种形式曾被用于黑客攻击加密货币交易所，造成5000万美元的损失（Popper，[2016](https://arxiv.org/html/2404.08144v2#bib.bib30)）。我们在WooCommerce平台上使用了类似的ACIDRain漏洞。我们在表[1](https://arxiv.org/html/2404.08144v2#S3.T1
    "表1 ‣ 3个现实世界漏洞的基准 ‣ LLM代理可以自主利用一天内的漏洞")和[2](https://arxiv.org/html/2404.08144v2#S3.T2
    "表2 ‣ 3个现实世界漏洞的基准 ‣ LLM代理可以自主利用一天内的漏洞")中总结了这些漏洞。
- en: Characteristics of the vulnerabilities. Our vulnerabilities span website vulnerabilities,
    container vulnerabilities, and vulnerable Python packages. Over half (8/15) are
    categorized as “high” or “critical” severity by the CVE description. Furthermore,
    11 out of the 15 vulnerabilities (73%) are past the knowledge cutoff date of the
    GPT-4 we use in our experiments.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 漏洞的特征。我们的漏洞涵盖了网站漏洞、容器漏洞和易受攻击的Python包。超过一半（8/15）被CVE描述分类为“高”或“严重”级别。此外，15个漏洞中有11个（73%）超出了我们实验中使用的GPT-4的知识截止日期。
- en: Thus, our dataset includes real-world, high severity vulnerabilities instead
    of “capture-the-flag” style vulnerabilities that are used in toy settings (Fang
    et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8); Happe & Cito, [2023](https://arxiv.org/html/2404.08144v2#bib.bib13);
    Hilario et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib15)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的数据集包括了现实世界中的高严重性漏洞，而不是用于玩具环境中的“夺旗”式漏洞（Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8);
    Happe & Cito, [2023](https://arxiv.org/html/2404.08144v2#bib.bib13); Hilario et
    al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib15)）。
- en: 4 Agent Description
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 代理描述
- en: 'Figure 1: System diagram of our LLM agent.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们LLM代理的系统图。
- en: 'In this section, we describe our LLM agent that can exploit vulnerabilities.
    Our agent consists of a:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了可以利用漏洞的LLM代理。我们的代理由以下部分组成：
- en: '1.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: base LLM,
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基础LLM，
- en: '2.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: prompt,
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示，
- en: '3.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: agent framework, and
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理框架，以及
- en: '4.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: tools.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工具。
- en: We show a system diagram in Figure [1](https://arxiv.org/html/2404.08144v2#S4.F1
    "Figure 1 ‣ 4 Agent Description ‣ LLM Agents can Autonomously Exploit One-day
    Vulnerabilities").
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图[1](https://arxiv.org/html/2404.08144v2#S4.F1 "图1 ‣ 4 代理描述 ‣ LLM代理可以自主利用一天漏洞")中展示了系统图。
- en: We vary the base LLM in our evaluation, but note that only GPT-4 is capable
    of exploiting vulnerabilities in our dataset. Every other method fails.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在评估中改变了基础LLM，但需要注意的是，只有GPT-4能够利用我们数据集中的漏洞。其他所有方法都失败了。
- en: We use the ReAct agent framework as implemented in LangChain. For the OpenAI
    models, we use the Assistants API.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用LangChain实现的ReAct代理框架。对于OpenAI模型，我们使用Assistants API。
- en: 'We give the agent access to tools, including access to:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们赋予代理使用工具的权限，包括访问：
- en: '1.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: web browsing elements (retrieving HTML, clicking on elements, etc.),
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 网络浏览元素（获取HTML，点击元素等），
- en: '2.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: a terminal,
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个终端，
- en: '3.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: web search results,
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 网络搜索结果，
- en: '4.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: file creation and editing, and
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件创建和编辑，以及
- en: '5.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: a code interpreter.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个代码解释器。
- en: Similar to prior work (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)),
    our prompt is detailed and encourages the agent to be creative, not give up, and
    try different approaches. The prompt was a total of 1056 tokens. The agents can
    further retrieve the CVE description. For ethical reasons, we have withheld the
    prompt in a public version of the manuscript and will make the prompt available
    upon request as prior work does (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于之前的研究（Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)），我们的提示详细并鼓励代理发挥创意，不放弃并尝试不同的方法。提示总共有1056个标记。代理还可以进一步检索CVE描述。出于伦理原因，我们在公开版本的稿件中没有提供提示，并将按要求提供提示，正如之前的研究所做的那样（Fang
    et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）。
- en: We implemented the agent with a total of 91 lines of code, including debugging
    and logging statements, showing that these LLM agents are simple to implement.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了一个总共91行代码的代理，包括调试和日志记录语句，显示这些LLM代理实现起来非常简单。
- en: We further note that we did not implement sub-agents or a separate planning
    module. As we describe in Section [5.3](https://arxiv.org/html/2404.08144v2#S5.SS3
    "5.3 Removing CVE Descriptions ‣ 5 LLM Agents can Autonmously Exploit One-Day
    Vulnerabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities"),
    our experiments suggest that a separate planning module may improve the performance
    of our agent.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到，我们没有实现子代理或单独的规划模块。正如我们在第[5.3](https://arxiv.org/html/2404.08144v2#S5.SS3
    "5.3 删除CVE描述 ‣ 5 LLM代理可以自主利用一天漏洞 ‣ LLM代理可以自主利用一天漏洞")节中所描述的那样，我们的实验表明，单独的规划模块可能会提高我们代理的性能。
- en: 5 LLM Agents can Autonmously Exploit One-Day Vulnerabilities
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LLM代理可以自主利用一天漏洞
- en: We now turn to evaluating our LLM agents on the real-world vulnerabilities we
    collected.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在开始评估我们收集的现实世界漏洞中的LLM代理。
- en: 5.1 Experimental Setup
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: 'Metrics. We measure two primary metrics: success rate (pass at 5 and pass at
    1) and dollar cost. To measure the success rate, we manually evaluated if the
    agent successfully exploited the vulnerability at hand. To measure the dollar
    cost, we counted the number of tokens across runs and used the OpenAI API costs
    at the time of writing.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 指标。我们衡量了两个主要指标：成功率（5次成功和1次成功）和美元成本。为了衡量成功率，我们手动评估代理是否成功利用了当前漏洞。为了衡量美元成本，我们统计了每次运行的
    token 数量，并使用撰写时的 OpenAI API 成本。
- en: 'Models. We tested 10 models in our ReAct framework:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 模型。我们在 ReAct 框架中测试了 10 个模型：
- en: '1.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: GPT-4 (Achiam et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib1))
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-4（Achiam 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib1)）
- en: '2.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: GPT-3.5 (Brown et al., [2020](https://arxiv.org/html/2404.08144v2#bib.bib6))
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GPT-3.5（Brown 等，[2020](https://arxiv.org/html/2404.08144v2#bib.bib6)）
- en: '3.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: OpenHermes-2.5-Mistral-7B (Teknium, [2024](https://arxiv.org/html/2404.08144v2#bib.bib38))
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: OpenHermes-2.5-Mistral-7B（Teknium，[2024](https://arxiv.org/html/2404.08144v2#bib.bib38)）
- en: '4.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: LLaMA-2 Chat (70B) (Touvron et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib39))
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2 Chat（70B）（Touvron 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib39)）
- en: '5.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: LLaMA-2 Chat (13B) (Touvron et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib39))
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2 Chat（13B）（Touvron 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib39)）
- en: '6.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: LLaMA-2 Chat (7B) (Touvron et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib39))
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLaMA-2 Chat（7B）（Touvron 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib39)）
- en: '7.'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: Mixtral-8x7B Instruct (Jiang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib19))
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mixtral-8x7B Instruct（Jiang 等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib19)）
- en: '8.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: Mistral (7B) Instruct v0.2 (Jiang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib18))
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mistral（7B）Instruct v0.2（Jiang 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib18)）
- en: '9.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '9.'
- en: Nous Hermes-2 Yi (34B) (Research, [2024](https://arxiv.org/html/2404.08144v2#bib.bib32))
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Nous Hermes-2 Yi（34B）（Research，[2024](https://arxiv.org/html/2404.08144v2#bib.bib32)）
- en: '10.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '10.'
- en: OpenChat 3.5 (Wang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib43))
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: OpenChat 3.5（Wang 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib43)）
- en: We chose the same models as used by Fang et al. ([2024](https://arxiv.org/html/2404.08144v2#bib.bib8))
    to compare against prior work. Fang et al. ([2024](https://arxiv.org/html/2404.08144v2#bib.bib8))
    chose these models as they rank highly in ChatBot Arena (Zheng et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib52)).
    For GPT-4 and GPT-3.5, we used the OpenAI API. For the remainder of the models,
    we used the Together AI API.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了与 Fang 等人（[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）相同的模型，以便与先前的工作进行比较。Fang
    等人（[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）之所以选择这些模型，是因为它们在 ChatBot
    Arena 中排名较高（Zheng 等人，[2024](https://arxiv.org/html/2404.08144v2#bib.bib52)）。对于
    GPT-4 和 GPT-3.5，我们使用了 OpenAI API。对于其余的模型，我们使用了 Together AI API。
- en: For GPT-4, the knowledge cutoff date was November 6th, 2023\. Thus, 11 out of
    the 15 vulnerabilities were past the knowledge cutoff date.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 GPT-4，知识截止日期为 2023 年 11 月 6 日。因此，15 个漏洞中的 11 个已经超出了知识截止日期。
- en: 'Open-source vulnerability scanners. We further tested these vulnerabilities
    on two open-source vulnerability scanners: ZAP (Bennetts, [2013](https://arxiv.org/html/2404.08144v2#bib.bib3))
    and Metasploit (Kennedy et al., [2011](https://arxiv.org/html/2404.08144v2#bib.bib22)).
    These are widely used to find vulnerabilities by penetration testers. Several
    of our vulnerabilities are not amenable to ZAP or Metasploit (e.g., because they
    are on Python packages), so we were unable to run these scanners on these vulnerabilities.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 开源漏洞扫描器。我们进一步在两个开源漏洞扫描器上测试了这些漏洞：ZAP（Bennetts，[2013](https://arxiv.org/html/2404.08144v2#bib.bib3)）和
    Metasploit（Kennedy 等，[2011](https://arxiv.org/html/2404.08144v2#bib.bib22)）。这些工具被渗透测试人员广泛使用来发现漏洞。我们的一些漏洞无法通过
    ZAP 或 Metasploit 扫描（例如，因为它们位于 Python 包中），因此我们无法在这些漏洞上运行这些扫描器。
- en: We emphasize that these vulnerability scanners cannot autonomously exploit vulnerabilities
    and so are strictly weaker than our GPT-4 agent.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调，这些漏洞扫描器无法自主利用漏洞，因此它们的功能明显不如我们的 GPT-4 代理。
- en: Vulnerabilities. We tested our agents and the open-source vulnerability scanners
    on the vulnerabilities listed in Table [1](https://arxiv.org/html/2404.08144v2#S3.T1
    "Table 1 ‣ 3 Benchmark of Real-World Vulnerabilities ‣ LLM Agents can Autonomously
    Exploit One-day Vulnerabilities"). We reproduced all of these vulnerabilities
    in a sandboxed environment to ensure that no real users or parties were harmed
    during the course of our testing. Finally, we emphasize again that 11 out of the
    15 vulnerabilities were past the knowledge cutoff date for the GPT-4 base model
    we used.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 漏洞。我们测试了我们的代理和开源漏洞扫描器，针对表[1](https://arxiv.org/html/2404.08144v2#S3.T1 "表 1
    ‣ 3 真实世界漏洞基准 ‣ LLM 代理可以自主利用一天内的漏洞")中列出的漏洞。我们在沙盒环境中复现了所有这些漏洞，以确保在测试过程中没有真实用户或相关方受到伤害。最后，我们再次强调，15个漏洞中的11个已超过我们使用的GPT-4基础模型的知识截止日期。
- en: 5.2 End-to-end Hacking
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 端到端黑客攻击
- en: '| Model | Pass @ 5 | Overall success rate |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 在5次测试中通过率 | 总体成功率 |'
- en: '| --- | --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GPT-4 | 86.7% | 40.0% |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 86.7% | 40.0% |'
- en: '| GPT-3.5 | 0% | 0% |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 0% | 0% |'
- en: '| OpenHermes-2.5-Mistral-7B | 0% | 0% |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| OpenHermes-2.5-Mistral-7B | 0% | 0% |'
- en: '| Llama-2 Chat (70B) | 0% | 0% |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2 Chat (70B) | 0% | 0% |'
- en: '| LLaMA-2 Chat (13B) | 0% | 0% |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA-2 Chat (13B) | 0% | 0% |'
- en: '| LLaMA-2 Chat (7B) | 0% | 0% |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA-2 Chat (7B) | 0% | 0% |'
- en: '| Mixtral-8x7B Instruct | 0% | 0% |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Mixtral-8x7B Instruct | 0% | 0% |'
- en: '| Mistral (7B) Instruct v0.2 | 0% | 0% |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Mistral (7B) Instruct v0.2 | 0% | 0% |'
- en: '| Nous Hermes-2 Yi 34B | 0% | 0% |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Nous Hermes-2 Yi 34B | 0% | 0% |'
- en: '| OpenChat 3.5 | 0% | 0% |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| OpenChat 3.5 | 0% | 0% |'
- en: 'Table 3: Models and their success rates for exploiting one-day vulnerabilities
    (pass @ 5 and overall success rate). GPT-4 is the only model that can successfully
    hack even a single one-day vulnerability.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：模型及其利用一天内漏洞的成功率（在5次测试中通过率和总体成功率）。GPT-4是唯一能够成功破解至少一个一天内漏洞的模型。
- en: We measured the overall success rate of the 10 models and open-source vulnerability
    scanners on our real-world vulnerabilities, with results shown in Table [3](https://arxiv.org/html/2404.08144v2#S5.T3
    "Table 3 ‣ 5.2 End-to-end Hacking ‣ 5 LLM Agents can Autonmously Exploit One-Day
    Vulnerabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").
    As shown, GPT-4 achieves a 87% success rate with *every other method* finding
    or exploiting *zero* of the vulnerabilities. These results suggest an “emergent
    capability” in GPT-4 (Wei et al., [2022](https://arxiv.org/html/2404.08144v2#bib.bib46)),
    although more investigation is required (Schaeffer et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib35)).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们测量了10个模型和开源漏洞扫描器在我们的真实世界漏洞上的整体成功率，结果如表[3](https://arxiv.org/html/2404.08144v2#S5.T3
    "表 3 ‣ 5.2 端到端黑客攻击 ‣ 5 LLM 代理可以自主利用一天内的漏洞 ‣ LLM 代理可以自主利用一天内的漏洞")所示。如表所示，GPT-4的成功率为87%，而*其他方法*发现或利用的漏洞数量为*零*。这些结果表明GPT-4具有一种“突现能力”（Wei等，[2022](https://arxiv.org/html/2404.08144v2#bib.bib46)），尽管仍需要更多调查（Schaeffer等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib35)）。
- en: 'GPT-4 only fails on two vulnerabilities: Iris XSS and Hertzbeat RCE. Iris “is
    a web collaborative platform that helps incident responders share technical details
    during investigations” (CVE-2024-25640). The Iris web app is extremely difficult
    for an LLM agent to navigate, as the navigation is done through JavaScript. As
    a result, the agent tries to access forms/buttons without interacting with the
    necessary elements to make it available, which stops it from doing so. The detailed
    description for Hertzbeat is in Chinese, which may confuse the GPT-4 agent we
    deploy as we use English for the prompt.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4仅在两个漏洞上失败：Iris XSS和Hertzbeat RCE。Iris是一个“帮助事件响应者在调查过程中共享技术细节的网络协作平台”（CVE-2024-25640）。Iris网页应用程序对于LLM代理来说非常难以导航，因为导航是通过JavaScript进行的。因此，代理尝试访问表单/按钮，但没有与必要的元素互动以使其可用，这就阻止了它的操作。Hertzbeat的详细描述是中文，这可能会困扰我们部署的GPT-4代理，因为我们使用英语作为提示语言。
- en: We further note that GPT-4 achieves an 82% success rate when only considering
    vulnerabilities after the knowledge cutoff date (9 out of 11 vulnerabilities).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步指出，在仅考虑知识截止日期之后的漏洞时，GPT-4的成功率为82%（11个漏洞中的9个）。
- en: As mentioned, every other method, including GPT-3.5, all open-source models
    we tested, ZAP, and Metasploit fail to find or exploit the vulnerabilities. Our
    results on open-source models corroborate results from Fang et al. ([2024](https://arxiv.org/html/2404.08144v2#bib.bib8)).
    Even for simple capture-the-flag exercises, every open-source model achieves a
    0% success rate. Qualitatively, GPT-3.5 and the open-source models appear to be
    much worse at tool use. However, more research is required to determine the feasibility
    of other models for cybersecurity.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，包括 GPT-3.5 在内的其他所有方法、我们测试的所有开源模型、ZAP 和 Metasploit 都未能发现或利用漏洞。我们在开源模型上的结果证实了
    Fang 等（[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）的结果。即使是简单的夺旗练习，每个开源模型的成功率也为
    0%。在定性分析上，GPT-3.5 和开源模型在工具使用上似乎表现更差。然而，需要更多的研究来确定其他模型在网络安全中的可行性。
- en: 5.3 Removing CVE Descriptions
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 移除 CVE 描述
- en: We then modified our agent to not include the CVE description. This task is
    now substantially more difficult, requiring both finding the vulnerability and
    then actually exploiting it. Because every other method (GPT-3.5 and all other
    open-source models we tested) achieved a 0% success rate even with the vulnerability
    description, the subsequent experiments are conducted on GPT-4 only.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们修改了我们的代理，不包含 CVE 描述。这个任务现在显著更难，需要找到漏洞并实际利用它。因为其他所有方法（GPT-3.5 和我们测试的所有开源模型）即使有漏洞描述也达到了
    0% 的成功率，后续实验仅在 GPT-4 上进行。
- en: After removing the CVE description, the success rate falls from 87% to 7%. This
    suggests that determining the vulnerability is extremely challenging.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在移除 CVE 描述后，成功率从 87% 降低到 7%。这表明确定漏洞是极具挑战性的。
- en: To understand this discrepancy, we computed the success rate (pass at 5) for
    determining the correct vulnerability. Surprisingly, GPT-4 was able to identify
    the correct vulnerability 33.3% of the time. Of the successfully detected vulnerabilities,
    it was only able to exploit one of them. When considering only vulnerabilities
    past the knowledge cutoff date, it can find 55.6% of them.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这种差异，我们计算了确定正确漏洞的成功率（通过率为 5）。令人惊讶的是，GPT-4 能够在 33.3% 的时间内识别出正确的漏洞。在成功检测到的漏洞中，它仅能利用其中一个。当仅考虑知识截止日期之后的漏洞时，它能够找到其中
    55.6% 的漏洞。
- en: We further investigated by computing the number of actions taken by the agent
    with and without the CVE description. Surprisingly, we found that the average
    number of actions taken with and without the CVE description differed by only
    14% (24.3 actions vs 21.3 actions). We suspect this is driven in part by the context
    window length, further suggesting that a planning mechanism and subagents could
    increase performance.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步通过计算代理在有无 CVE 描述的情况下采取的行动数量进行了调查。令人惊讶的是，我们发现有无 CVE 描述的情况下，采取的平均行动数量仅相差
    14%（24.3 次行动对比 21.3 次行动）。我们怀疑这在一定程度上是由上下文窗口长度所驱动，进一步暗示了规划机制和子代理可能会提高性能。
- en: These results suggests that enhancing planning and exploration capabilities
    of agents will increase the success rate of these agents, but more exploration
    is required.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，增强代理的规划和探索能力将提高这些代理的成功率，但仍需要更多的探索。
- en: 5.4 Cost Analysis
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 成本分析
- en: We now evaluate the cost of using GPT-4 to exploit real-world vulnerabilities.
    Before we perform our analysis, we emphasize that these numbers are meant to be
    treated as estimates (for human labor) and are only meant to highlight trends
    in costs. This is in line with prior work that estimates the cost of other kinds
    of attacks, such as website hacking (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8))
    and phishing (Kang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib21)).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们评估使用 GPT-4 利用现实世界漏洞的成本。在进行分析之前，我们强调这些数据应作为估算（针对人类劳动力），并仅用于突出成本趋势。这与先前的研究一致，先前的研究估算了其他类型攻击的成本，例如网站黑客攻击（Fang
    等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）和钓鱼攻击（Kang 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib21)）。
- en: To measure the cost of GPT-4, we computed the number of input and output tokens
    (which have different costs) per run. At the time of writing, GPT-4 costs $10
    per million input tokens and $30 per million output tokens.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量 GPT-4 的成本，我们计算了每次运行的输入和输出令牌的数量（这两者的成本不同）。在写作时，GPT-4 的输入令牌成本为每百万个 $10，输出令牌成本为每百万个
    $30。
- en: The average cost per run was $3.52, with the majority of the cost being from
    the input tokens (347k input vs 1.7k output). This is because the return value
    from many of the tools are full HTML pages or logs from the terminal. With an
    average overall success rate of 40%, this would require $8.80 per exploit.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行的平均成本为$3.52，主要成本来自输入的令牌（347k输入与1.7k输出）。这是因为许多工具的返回值是完整的HTML页面或终端日志。整体成功率平均为40%，因此每次漏洞利用的成本为$8.80。
- en: Using the estimates from Fang et al. ([2024](https://arxiv.org/html/2404.08144v2#bib.bib8)),
    we estimate $50 per hour for a cybersecurity expert, and an estimate of 30 minutes
    per vulnerability. This would cost a total of $25\. Thus, using an LLM agent is
    already 2.8$\times$ cheaper than human labor. LLM agents are also trivially scalable,
    in contrast to human labor.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Fang等人（[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）的估算，我们预计网络安全专家的费用为每小时$50，每个漏洞大约需要30分钟。这将总共花费$25。因此，使用LLM代理的成本已经是人工劳动力的2.8倍便宜。与人工劳动力相比，LLM代理的可扩展性也更为简单。
- en: This gap is less than the gap in prior work (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8);
    Kang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib21)). Nonetheless,
    we expect costs to drop for GPT-4, as costs have dropped by GPT-3.5 by over 3$\times$
    in a span of a year.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这个差距小于之前工作的差距（Fang等人，[2024](https://arxiv.org/html/2404.08144v2#bib.bib8); Kang等人，[2023](https://arxiv.org/html/2404.08144v2#bib.bib21)）。尽管如此，我们预计GPT-4的成本会下降，因为GPT-3.5的成本在一年内下降了超过3倍。
- en: 6 Understanding Agent Capabilities
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 理解代理能力
- en: We now study the GPT-4 agent behavior in greater detail to understand its high
    success rate and why it fails when the CVE description is removed.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在更详细地研究GPT-4代理的行为，以理解其高成功率以及在移除CVE描述时为何会失败。
- en: '| Vulnerability | Number of steps |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 漏洞 | 步骤数量 |'
- en: '| --- | --- |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| runc | 10.6 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| runc | 10.6 |'
- en: '| CSRF + ACE | 26.0 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + ACE | 26.0 |'
- en: '| Wordpress SQLi | 23.2 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress SQLi | 23.2 |'
- en: '| Wordpress XSS-1 | 21.6 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-1 | 21.6 |'
- en: '| Wordpress XSS-2 | 48.6 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Wordpress XSS-2 | 48.6 |'
- en: '| Travel Journal XSS | 20.4 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Travel Journal XSS | 20.4 |'
- en: '| Iris XSS | 38.2 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Iris XSS | 38.2 |'
- en: '| CSRF + privilege escalation | 13.4 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| CSRF + 权限提升 | 13.4 |'
- en: '| alf.io key leakage | 35.2 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| alf.io 密钥泄露 | 35.2 |'
- en: '| Astrophy RCE | 20.6 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Astrophy RCE | 20.6 |'
- en: '| Hertzbeat RCE | 36.2 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Hertzbeat RCE | 36.2 |'
- en: '| Gnuboard XSS | 11.8 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Gnuboard XSS | 11.8 |'
- en: '| Symfony 1 RCE | 11.8 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Symfony 1 RCE | 11.8 |'
- en: '| Peering Manager SSTI RCE | 14.4 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Peering Manager SSTI RCE | 14.4 |'
- en: '| ACIDRain | 32.6 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| ACIDRain | 32.6 |'
- en: 'Table 4: Number of actions taken per vulnerability.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：每个漏洞所需的操作次数。
- en: We first observe that many of the vulnerabilities take a large number of actions
    to successfully exploit, with the average number of actions per vulnerability
    shown in Table [4](https://arxiv.org/html/2404.08144v2#S6.T4 "Table 4 ‣ 6 Understanding
    Agent Capabilities ‣ LLM Agents can Autonomously Exploit One-day Vulnerabilities").
    For example, Wordpress XSS-2 (CVE-2023-1119-2) takes an average of 48.6 steps
    per run. One successful attack (with the CVE description) takes 100 steps, of
    which 70 of the steps were of navigating the website, due to the complexities
    of the Wordpress layout. Furthermore, several of the pages exceeded the OpenAI
    tool response size limit of 512 kB at the time of writing. Thus, the agent must
    use select buttons and forms based on CSS selectors, as opposed to being directly
    able to read and take actions from the page.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先观察到，许多漏洞需要执行大量操作才能成功利用，平均每个漏洞的操作次数见表[4](https://arxiv.org/html/2404.08144v2#S6.T4
    "表 4 ‣ 6 理解代理能力 ‣ LLM代理可以自主利用一天内的漏洞")。例如，Wordpress XSS-2（CVE-2023-1119-2）每次执行的平均步骤为48.6步。一旦攻击成功（按照CVE描述），需要100步，其中70步用于浏览网站，因为Wordpress布局的复杂性。此外，写作时，几个页面超出了OpenAI工具响应大小限制（512
    KB）。因此，代理必须基于CSS选择器使用选择按钮和表单，而不是直接读取页面并执行操作。
- en: Second, consider CSRF + ACE (CVE-2024-24524), which requires both leveraging
    a CSRF attack and performing code execution. Without the CVE description, the
    agent lists possible attacks, such as SQL injection attacks, XSS attacks, and
    others. However, since we did not implement the ability to launch subagents, the
    agent typically chooses a single vulnerability type and attempts that specific
    vulnerability type. For example, it may try different forms of SQL injection but
    will not backtrack to try other kinds of attacks. Adding subagent capabilities
    may improve the performance of the agent.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，考虑CSRF + ACE（CVE-2024-24524），该漏洞需要同时利用CSRF攻击和执行代码。在没有CVE描述的情况下，代理列出了可能的攻击方式，如SQL注入攻击、XSS攻击等。然而，由于我们没有实现启动子代理的能力，代理通常会选择一种漏洞类型并尝试该特定漏洞类型。例如，它可能尝试不同形式的SQL注入，但不会回溯尝试其他类型的攻击。添加子代理功能可能会提高代理的性能。
- en: 'Third, consider the ACIDRain exploit. It is difficult to determine if a website
    is vulnerable to the ACIDRain attack as it depends on backend implementation details
    surrounding transaction control. However, performing the ACIDRain attack is still
    complex, requiring:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，考虑ACIDRain漏洞。确定一个网站是否容易受到ACIDRain攻击是很困难的，因为它依赖于事务控制的后端实现细节。然而，执行ACIDRain攻击仍然复杂，需要：
- en: '1.'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: navigating to the website and extracting the hyperlinks,
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导航到网站并提取超链接，
- en: '2.'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: navigating to the checkout page, placing a test order, and recording the necessary
    fields for checkout,
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导航到结账页面，进行测试订单并记录结账所需的字段，
- en: '3.'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: writing Python code to exploit the race condition,
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编写Python代码以利用竞争条件，
- en: '4.'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: actually executing the Python code via the terminal.
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过终端实际执行Python代码。
- en: This exploit requires operating several tools and writing code based on the
    actions taken on the website.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 该漏洞需要操作多个工具，并根据网站上采取的操作编写代码。
- en: Finally, we note that our GPT-4 agent can autonomously exploit non-web vulnerabilities
    as well. For example, consider the Astrophy RCE exploit (CVE-2023-41334). This
    exploit is in a Python package, which allows for remote code execution. Despite
    being very different from websites, which prior work has focused on (Fang et al.,
    [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)), our GPT-4 agent can autonomously
    write code to exploit other kinds of vulnerabilities. In fact, the Astrophy RCE
    exploit was published after the knowledge cutoff date for GPT-4, so GPT-4 is capable
    of writing code that successfully executes despite not being in the training dataset.
    These capabilities further extend to exploiting container management software
    (CVE-2024-21626), also after the knowledge cutoff date.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们注意到我们的GPT-4代理也能够自主利用非网页漏洞。例如，考虑Astrophy RCE漏洞（CVE-2023-41334）。这个漏洞存在于一个Python包中，允许进行远程代码执行。尽管与以往关注的网页（Fang等人，[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）非常不同，我们的GPT-4代理仍然可以自主编写代码来利用其他类型的漏洞。事实上，Astrophy
    RCE漏洞是在GPT-4的知识截止日期之后发布的，因此即使它不在训练数据集内，GPT-4仍然能够成功编写并执行代码。这些能力进一步扩展到了利用容器管理软件的漏洞（CVE-2024-21626），同样是在知识截止日期之后。
- en: Our qualitative analysis shows that our GPT-4 agent is highly capable. Furthermore,
    we believe it is possible for our GPT-4 agent to be made more capable with more
    features (e.g., planning, subagents, and larger tool response sizes).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的定性分析表明，我们的GPT-4代理能力非常强大。此外，我们相信，通过增加更多功能（例如规划、子代理和更大的工具响应大小），我们的GPT-4代理可以变得更加高效。
- en: 7 Related Work
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 相关工作
- en: Cybersecurity and AI. The most related work to ours is a recent study that showed
    that LLM agents can hack websites (Fang et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)).
    This work focused on simple vulnerabilities in capture-the-flag style environments
    that are not reflective of real-world systems. Work contemporaneous to ours also
    evaluates the ability of LLM agents in a cybersecurity context (Phuong et al.,
    [2024](https://arxiv.org/html/2404.08144v2#bib.bib29)), but appears to perform
    substantially worse than our agent and an agent in the CTF setting (Fang et al.,
    [2024](https://arxiv.org/html/2404.08144v2#bib.bib8)). Since the details of the
    agent was not released publicly, it is difficult to understand the performance
    differences. We hypothesize that it is largely due to the prompt. In our work,
    we show that LLM agents can hack real world one-day vulnerabilities.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 网络安全与人工智能。与我们工作最相关的一项研究表明，LLM 代理可以攻击网站（Fang 等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）。这项工作聚焦于简单漏洞，通常出现在“夺旗”风格的环境中，而这些环境并不能反映真实世界的系统。与我们同步的其他研究也评估了
    LLM 代理在网络安全背景下的能力（Phuong 等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib29)），但似乎表现远逊色于我们的代理和
    CTF 环境中的代理（Fang 等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib8)）。由于该代理的细节未公开，因此很难理解性能差异。我们假设这种差异主要与提示（prompt）有关。在我们的研究中，我们展示了
    LLM 代理能够攻击现实世界中的一天漏洞。
- en: Other recent work has shown the ability of LLMs to aid in penetration testing
    or malware generation (Happe & Cito, [2023](https://arxiv.org/html/2404.08144v2#bib.bib13);
    Hilario et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib15)). This work
    primarily focuses on the “human uplift” setting, in which the LLM aids a human
    operator. Other work focuses on the societal implications the intersection of
    AI and cybersecurity (Lohn & Jackson, [2022](https://arxiv.org/html/2404.08144v2#bib.bib25);
    Handa et al., [2019](https://arxiv.org/html/2404.08144v2#bib.bib12)). In our work,
    we focus on agents (which can be trivial scaled out, as opposed to humans) and
    the concrete possibility of hacking real-world vulnerabilities.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其他近期的研究显示，LLM 具有在渗透测试或恶意软件生成中提供帮助的能力（Happe & Cito，[2023](https://arxiv.org/html/2404.08144v2#bib.bib13)；Hilario
    等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib15)）。这些研究主要聚焦于“人类提升”场景，其中
    LLM 辅助人类操作员。其他研究则关注人工智能与网络安全交汇点的社会影响（Lohn & Jackson，[2022](https://arxiv.org/html/2404.08144v2#bib.bib25)；Handa
    等，[2019](https://arxiv.org/html/2404.08144v2#bib.bib12)）。在我们的研究中，我们聚焦于代理（这些代理可以轻松扩展，而与人类相比有显著不同）以及破解现实世界漏洞的实际可能性。
- en: Cybersecurity. Cybersecurity is a incredibly wide research area, ranging from
    best practices for passwords (Herley & Van Oorschot, [2011](https://arxiv.org/html/2404.08144v2#bib.bib14)),
    studying the societal implications of cyber attacks (Bada & Nurse, [2020](https://arxiv.org/html/2404.08144v2#bib.bib2)),
    to understanding web vulnerabilities (Halfond et al., [2006](https://arxiv.org/html/2404.08144v2#bib.bib11)).
    The subarea of cybersecurity closest to ours is automatic vulnerability detection
    and exploitation (Russell et al., [2018](https://arxiv.org/html/2404.08144v2#bib.bib34);
    Bennetts, [2013](https://arxiv.org/html/2404.08144v2#bib.bib3); Kennedy et al.,
    [2011](https://arxiv.org/html/2404.08144v2#bib.bib22); Mahajan, [2014](https://arxiv.org/html/2404.08144v2#bib.bib26)).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 网络安全。网络安全是一个极为广泛的研究领域，涵盖了从密码最佳实践（Herley & Van Oorschot，[2011](https://arxiv.org/html/2404.08144v2#bib.bib14)）、研究网络攻击的社会影响（Bada
    & Nurse，[2020](https://arxiv.org/html/2404.08144v2#bib.bib2)），到理解网络漏洞（Halfond
    等，[2006](https://arxiv.org/html/2404.08144v2#bib.bib11)）等内容。与我们工作最相关的子领域是自动化漏洞检测与利用（Russell
    等，[2018](https://arxiv.org/html/2404.08144v2#bib.bib34)；Bennetts，[2013](https://arxiv.org/html/2404.08144v2#bib.bib3)；Kennedy
    等，[2011](https://arxiv.org/html/2404.08144v2#bib.bib22)；Mahajan，[2014](https://arxiv.org/html/2404.08144v2#bib.bib26)）。
- en: In cybersecurity, a common set of tools used by both black hat and white hat
    actors are automatic vulnerability scanners. These include ZAP (Bennetts, [2013](https://arxiv.org/html/2404.08144v2#bib.bib3)),
    Metasploit (Kennedy et al., [2011](https://arxiv.org/html/2404.08144v2#bib.bib22)),
    and Burp Suite (Mahajan, [2014](https://arxiv.org/html/2404.08144v2#bib.bib26)).
    Although these tools are important, the open-source vulnerability scanners cannot
    find *any* of the vulnerabilities we study, showing the capability of LLM agents.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络安全领域，黑帽和白帽黑客都常用的一类工具是自动化漏洞扫描器。包括 ZAP（Bennetts，[2013](https://arxiv.org/html/2404.08144v2#bib.bib3)），Metasploit（Kennedy
    等，[2011](https://arxiv.org/html/2404.08144v2#bib.bib22)），以及 Burp Suite（Mahajan，[2014](https://arxiv.org/html/2404.08144v2#bib.bib26)）。尽管这些工具很重要，但开源漏洞扫描器无法发现我们研究的*任何*漏洞，这也展示了大型语言模型（LLM）代理的能力。
- en: Security of LLM agents. A related, but orthogonal line of work is the security
    of LLM agents (Greshake et al., [2023a](https://arxiv.org/html/2404.08144v2#bib.bib9);
    Kang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib21); Zou et al.,
    [2023](https://arxiv.org/html/2404.08144v2#bib.bib54); Zhan et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib50);
    Qi et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib31); Yang et al.,
    [2023](https://arxiv.org/html/2404.08144v2#bib.bib47)). For example, an attacker
    can use an indirect prompt injection attack to misdirect an LLM agent (Greshake
    et al., [2023b](https://arxiv.org/html/2404.08144v2#bib.bib10); Yi et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib49);
    Zhan et al., [2024](https://arxiv.org/html/2404.08144v2#bib.bib51)). Attackers
    can also fine-tune away protections from models, enabling highly capable models
    to perform actions or tasks that the creators of the models did not intent (Zhan
    et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib50); Yang et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib47);
    Qi et al., [2023](https://arxiv.org/html/2404.08144v2#bib.bib31)). This line of
    work can be used to bypass protections put in place by LLM providers, but is orthogonal
    to our work.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理的安全性。一个相关但正交的研究方向是 LLM 代理的安全性（Greshake 等，[2023a](https://arxiv.org/html/2404.08144v2#bib.bib9)；Kang
    等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib21)；Zou 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib54)；Zhan
    等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib50)；Qi 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib31)；Yang
    等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib47)）例如，攻击者可以使用间接的提示注入攻击来误导
    LLM 代理（Greshake 等，[2023b](https://arxiv.org/html/2404.08144v2#bib.bib10)；Yi 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib49)；Zhan
    等，[2024](https://arxiv.org/html/2404.08144v2#bib.bib51)）。攻击者还可以通过微调去除模型的保护措施，使得高度智能的模型执行创建者未曾预期的操作或任务（Zhan
    等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib50)；Yang 等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib47)；Qi
    等，[2023](https://arxiv.org/html/2404.08144v2#bib.bib31)）。这类工作可以用来绕过 LLM 提供商设置的保护措施，但与我们的工作正交。
- en: 8 Conclusions
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: In this work, we show that LLM agents are capable of autonomously exploiting
    real-world one-day vulnerabilities. Currently, only GPT-4 with the CVE description
    is capable of exploiting these vulnerabilities. Our results show both the possibility
    of an emergent capability and that uncovering a vulnerability is more difficult
    than exploiting it. Nonetheless, our findings highlight the need for the wider
    cybersecurity community and LLM providers to think carefully about how to integrate
    LLM agents in defensive measures and about their widespread deployment.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们展示了 LLM 代理能够自主利用现实世界的单日漏洞。目前，只有带有 CVE 描述的 GPT-4 能够利用这些漏洞。我们的结果显示了新兴能力的可能性，并表明发现漏洞比利用漏洞更为困难。尽管如此，我们的发现突显了更广泛的网络安全社区和
    LLM 提供商需要仔细思考如何将 LLM 代理纳入防御措施，以及如何进行广泛部署。
- en: 9 Ethics Statement
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 伦理声明
- en: Our results show that LLM agents can be used to hack real-world systems. Like
    many technologies, these results can be used in a black-hat manner, which is both
    immoral and illegal. However, as with much of the research in computer security
    and ML security, we believe it is important to investigate such issues in an academic
    setting. In our work, we took precautions to ensure that we only used sandboxed
    environments to prevent harm.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果表明，LLM 代理可以用来攻破现实世界的系统。像许多技术一样，这些结果也可能被用于黑帽攻击，既不道德也不合法。然而，与计算机安全和机器学习安全研究中的许多工作一样，我们认为在学术环境中研究这些问题是很重要的。在我们的工作中，我们采取了预防措施，确保只在沙箱环境中进行实验，以防止造成伤害。
- en: We have disclosed our findings to OpenAI prior to publication. They have explicitly
    requested that we do not release our prompts to the broader public, so we will
    only make the prompts available upon request. Furthermore, many papers in advanced
    ML models and work in cybersecurity do not release the specific details for ethical
    reasons (such as the NeurIPS 2020 best paper (Brown et al., [2020](https://arxiv.org/html/2404.08144v2#bib.bib6))).
    Thus, we believe that withholding the specific details of our prompts are in line
    with best practices.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在发布之前已向 OpenAI 公开了我们的发现。他们明确要求我们不要将我们的提示发布给更广泛的公众，因此我们只会在有请求时提供提示。此外，许多关于高级机器学习模型和网络安全工作的论文出于伦理原因并未公开具体细节（例如
    NeurIPS 2020 年最佳论文（Brown 等，[2020](https://arxiv.org/html/2404.08144v2#bib.bib6)））。因此，我们认为隐瞒我们提示的具体细节符合最佳实践。
- en: Acknowledgments
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to acknowledge the Open Philanthropy project for funding this
    research in part.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢 Open Philanthropy 项目部分资助了这项研究。
- en: References
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*,
    2023.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat 等。GPT-4 技术报告。*arXiv 预印本 arXiv:2303.08774*, 2023.
- en: Bada & Nurse (2020) Maria Bada and Jason RC Nurse. The social and psychological
    impact of cyberattacks. In *Emerging cyber threats and cognitive vulnerabilities*,
    pp. 73–92\. Elsevier, 2020.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bada & Nurse (2020) Maria Bada 和 Jason RC Nurse. 网络攻击的社会与心理影响。发表于 *新兴网络威胁与认知脆弱性*,
    第 73–92 页。Elsevier, 2020.
- en: Bennetts (2013) Simon Bennetts. Owasp zed attack proxy. *AppSec USA*, 2013.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bennetts (2013) Simon Bennetts. Owasp Zed 攻击代理。*AppSec USA*, 2013.
- en: Boiko et al. (2023) Daniil A Boiko, Robert MacKnight, and Gabe Gomes. Emergent
    autonomous scientific research capabilities of large language models. *arXiv preprint
    arXiv:2304.05332*, 2023.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko et al. (2023) Daniil A Boiko, Robert MacKnight, 和 Gabe Gomes. 大型语言模型的自主科学研究能力的出现。*arXiv
    预印本 arXiv:2304.05332*, 2023.
- en: Bran et al. (2023) Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari,
    Andrew White, and Philippe Schwaller. Augmenting large language models with chemistry
    tools. In *NeurIPS 2023 AI for Science Workshop*, 2023.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bran et al. (2023) Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari,
    Andrew White, 和 Philippe Schwaller. 使用化学工具增强大型语言模型。发表于 *NeurIPS 2023 AI for Science
    Workshop*, 2023.
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. Language models are few-shot learners. *Advances in neural information
    processing systems*, 33:1877–1901, 2020.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell 等。语言模型是少样本学习者。*神经信息处理系统进展*, 33:1877–1901, 2020.
- en: 'Engebretson (2013) Patrick Engebretson. *The basics of hacking and penetration
    testing: ethical hacking and penetration testing made easy*. Elsevier, 2013.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Engebretson (2013) Patrick Engebretson. *黑客与渗透测试基础：简化的伦理黑客与渗透测试*. Elsevier,
    2013.
- en: Fang et al. (2024) Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, and Daniel
    Kang. Llm agents can autonomously hack websites, 2024.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fang et al. (2024) Richard Fang, Rohan Bindu, Akul Gupta, Qiusi Zhan, 和 Daniel
    Kang. 大型语言模型代理可以自主攻击网站，2024.
- en: 'Greshake et al. (2023a) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. More than you’ve asked for: A comprehensive
    analysis of novel prompt injection threats to application-integrated large language
    models. *arXiv e-prints*, pp.  arXiv–2302, 2023a.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greshake et al. (2023a) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, 和 Mario Fritz. 超出你所要求的：对集成大型语言模型应用的新型提示注入威胁的全面分析。*arXiv
    电子预印本*, 第 arXiv–2302 页, 2023a.
- en: 'Greshake et al. (2023b) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, and Mario Fritz. Not what you’ve signed up for: Compromising
    real-world llm-integrated applications with indirect prompt injection. In *Proceedings
    of the 16th ACM Workshop on Artificial Intelligence and Security*, pp.  79–90,
    2023b.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greshake et al. (2023b) Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph
    Endres, Thorsten Holz, 和 Mario Fritz. 你没签署的内容：通过间接提示注入危害实际集成大型语言模型的应用。发表于 *第16届
    ACM 人工智能与安全研讨会论文集*, 第 79–90 页, 2023b.
- en: Halfond et al. (2006) William G Halfond, Jeremy Viegas, Alessandro Orso, et al.
    A classification of sql-injection attacks and countermeasures. In *Proceedings
    of the IEEE international symposium on secure software engineering*, volume 1,
    pp.  13–15\. IEEE Piscataway, NJ, 2006.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Halfond et al. (2006) William G Halfond, Jeremy Viegas, Alessandro Orso 等。SQL
    注入攻击与对策分类。发表于 *IEEE 国际安全软件工程研讨会论文集*, 卷 1，第 13–15 页。IEEE Piscataway, NJ, 2006.
- en: 'Handa et al. (2019) Anand Handa, Ashu Sharma, and Sandeep K Shukla. Machine
    learning in cybersecurity: A review. *Wiley Interdisciplinary Reviews: Data Mining
    and Knowledge Discovery*, 9(4):e1306, 2019.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Handa et al. (2019) Anand Handa, Ashu Sharma, 和 Sandeep K Shukla. 网络安全中的机器学习：综述。*Wiley
    跨学科评论：数据挖掘与知识发现*, 9(4):e1306, 2019.
- en: 'Happe & Cito (2023) Andreas Happe and Jürgen Cito. Getting pwn’d by ai: Penetration
    testing with large language models. In *Proceedings of the 31st ACM Joint European
    Software Engineering Conference and Symposium on the Foundations of Software Engineering*,
    pp.  2082–2086, 2023.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Happe & Cito (2023) Andreas Happe 和 Jürgen Cito. 被 AI 攻破：使用大型语言模型进行渗透测试。发表于
    *第31届 ACM 欧洲软件工程联合会议和软件工程基础研讨会论文集*, 第 2082–2086 页, 2023.
- en: Herley & Van Oorschot (2011) Cormac Herley and Paul Van Oorschot. A research
    agenda acknowledging the persistence of passwords. *IEEE Security & privacy*,
    10(1):28–36, 2011.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Herley & Van Oorschot（2011）Cormac Herley 和 Paul Van Oorschot。承认密码持久性的研究议程。*IEEE
    安全与隐私*，10(1):28–36，2011年。
- en: 'Hilario et al. (2024) Eric Hilario, Sami Azam, Jawahar Sundaram, Khwaja Imran Mohammed,
    and Bharanidharan Shanmugam. Generative ai for pentesting: the good, the bad,
    the ugly. *International Journal of Information Security*, pp.  1–23, 2024.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hilario 等人（2024）Eric Hilario, Sami Azam, Jawahar Sundaram, Khwaja Imran Mohammed
    和 Bharanidharan Shanmugam。生成式人工智能在渗透测试中的应用：优点、缺点与不足。*国际信息安全杂志*，第1-23页，2024年。
- en: 'Huang et al. (2023) Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck, and
    Heming Cui. Agentcoder: Multi-agent-based code generation with iterative testing
    and optimisation. *arXiv preprint arXiv:2312.13010*, 2023.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2023）Dong Huang, Qingwen Bu, Jie M Zhang, Michael Luck 和 Heming Cui。Agentcoder：基于多代理的代码生成与迭代测试与优化。*arXiv
    预印本 arXiv:2312.13010*，2023年。
- en: Jang-Jaccard & Nepal (2014) Julian Jang-Jaccard and Surya Nepal. A survey of
    emerging threats in cybersecurity. *Journal of computer and system sciences*,
    80(5):973–993, 2014.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jang-Jaccard & Nepal（2014）Julian Jang-Jaccard 和 Surya Nepal。网络安全中新兴威胁的调查。*计算机与系统科学杂志*，80(5):973–993，2014年。
- en: Jiang et al. (2023) Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
    Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. *arXiv preprint
    arXiv:2310.06825*, 2023.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人（2023）Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier 等人。Mistral 7b。*arXiv 预印本 arXiv:2310.06825*，2023年。
- en: Jiang et al. (2024) Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, et al. Mixtral of experts. *arXiv preprint arXiv:2401.04088*,
    2024.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人（2024）Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch,
    Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma
    Bou Hanna, Florian Bressand 等人。专家混合模型。*arXiv 预印本 arXiv:2401.04088*，2024年。
- en: 'Jimenez et al. (2023) Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu
    Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models
    resolve real-world github issues? *arXiv preprint arXiv:2310.06770*, 2023.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jimenez 等人（2023）Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin
    Pei, Ofir Press 和 Karthik Narasimhan。Swe-bench：语言模型能否解决现实世界中的GitHub问题？*arXiv 预印本
    arXiv:2310.06770*，2023年。
- en: 'Kang et al. (2023) Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei
    Zaharia, and Tatsunori Hashimoto. Exploiting programmatic behavior of llms: Dual-use
    through standard security attacks. *arXiv preprint arXiv:2302.05733*, 2023.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等人（2023）Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin, Matei Zaharia
    和 Tatsunori Hashimoto。利用LLMs的程序行为：通过标准安全攻击的双重用途。*arXiv 预印本 arXiv:2302.05733*，2023年。
- en: 'Kennedy et al. (2011) David Kennedy, Jim O’gorman, Devon Kearns, and Mati Aharoni.
    *Metasploit: the penetration tester’s guide*. No Starch Press, 2011.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kennedy 等人（2011）David Kennedy, Jim O’gorman, Devon Kearns 和 Mati Aharoni。*Metasploit：渗透测试者指南*。No
    Starch Press，2011年。
- en: 'Kuznetsov et al. (2023) Igor Kuznetsov, Valentin Pashkov, Leonid Bezvershenko,
    and Georgy Kucherin. Operation triangulation: ios devices targeted with previously
    unknown malware. 2023. URL [https://securelist.com/operation-triangulation/109842/](https://securelist.com/operation-triangulation/109842/).'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuznetsov 等人（2023）Igor Kuznetsov, Valentin Pashkov, Leonid Bezvershenko 和 Georgy
    Kucherin。三角定位行动：iOS设备遭遇前所未见的恶意软件攻击。2023年。URL [https://securelist.com/operation-triangulation/109842/](https://securelist.com/operation-triangulation/109842/)。
- en: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp
    tasks. *Advances in Neural Information Processing Systems*, 33:9459–9474, 2020.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 等人（2020）Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel 等人。知识密集型NLP任务的检索增强生成。*神经信息处理系统进展*，33:9459–9474，2020年。
- en: Lohn & Jackson (2022) Andrew Lohn and Krystal Jackson. Will ai make cyber swords
    or shields? 2022.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lohn & Jackson（2022）Andrew Lohn 和 Krystal Jackson。人工智能会成为网络剑还是盾？2022年。
- en: Mahajan (2014) Akash Mahajan. *Burp Suite Essentials*. Packt Publishing Ltd,
    2014.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahajan（2014）Akash Mahajan。*Burp Suite基础教程*。Packt Publishing Ltd，2014年。
- en: 'Mialon et al. (2023) Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos
    Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane
    Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. *arXiv
    preprint arXiv:2302.07842*, 2023.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mialon 等人 (2023) Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos
    Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane
    Dwivedi-Yu, Asli Celikyilmaz 等人. 增强型语言模型：一项调查。 *arXiv 预印本 arXiv:2302.07842*, 2023。
- en: Osika (2023) Anton Osika. gpt-engineer, April 2023. URL [https://github.com/gpt-engineer-org/gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer).
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Osika (2023) Anton Osika. gpt-engineer，2023年4月。网址 [https://github.com/gpt-engineer-org/gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer)。
- en: Phuong et al. (2024) Mary Phuong, Matthew Aitchison, Elliot Catt, Sarah Cogan,
    Alexandre Kaskasoli, Victoria Krakovna, David Lindner, Matthew Rahtz, Yannis Assael,
    Sarah Hodkinson, et al. Evaluating frontier models for dangerous capabilities.
    *arXiv preprint arXiv:2403.13793*, 2024.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phuong 等人 (2024) Mary Phuong, Matthew Aitchison, Elliot Catt, Sarah Cogan, Alexandre
    Kaskasoli, Victoria Krakovna, David Lindner, Matthew Rahtz, Yannis Assael, Sarah
    Hodkinson 等人. 评估前沿模型的危险能力。 *arXiv 预印本 arXiv:2403.13793*, 2024。
- en: Popper (2016) Nathaniel Popper. A hacking of more than $50 million dashes hopes
    in the world of virtual currency. *The New York Times*, 17, 2016.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Popper (2016) Nathaniel Popper. 超过5000万美元的黑客攻击打破了虚拟货币领域的希望。 *纽约时报*, 17，2016。
- en: Qi et al. (2023) Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek
    Mittal, and Peter Henderson. Fine-tuning aligned language models compromises safety,
    even when users do not intend to! *arXiv preprint arXiv:2310.03693*, 2023.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi 等人 (2023) Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek
    Mittal 和 Peter Henderson. 微调对齐语言模型会妥协安全性，即使用户并不打算这样做！ *arXiv 预印本 arXiv:2310.03693*,
    2023。
- en: Research (2024) Nous Research. Nous hermes 2 - yi-34b, 2024. URL [https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B).
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Research (2024) Nous Research. Nous Hermes 2 - yi-34b, 2024. 网址 [https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B)。
- en: Roselin et al. (2019) Annie Gilda Roselin, Priyadarsi Nanda, Surya Nepal, Xiangjian
    He, and Jarod Wright. Exploiting the remote server access support of coap protocol.
    *IEEE Internet of Things Journal*, 6(6):9338–9349, 2019.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roselin 等人 (2019) Annie Gilda Roselin, Priyadarsi Nanda, Surya Nepal, Xiangjian
    He 和 Jarod Wright. 利用CoAP协议的远程服务器访问支持。 *IEEE物联网期刊*, 6(6):9338–9349, 2019。
- en: Russell et al. (2018) Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich,
    Jacob Harer, Onur Ozdemir, Paul Ellingwood, and Marc McConley. Automated vulnerability
    detection in source code using deep representation learning. In *2018 17th IEEE
    international conference on machine learning and applications (ICMLA)*, pp.  757–762\.
    IEEE, 2018.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russell 等人 (2018) Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich, Jacob
    Harer, Onur Ozdemir, Paul Ellingwood 和 Marc McConley. 使用深度表示学习进行源代码中的自动化漏洞检测。
    在 *2018年第17届IEEE国际机器学习与应用大会 (ICMLA)*, 第757–762页。IEEE，2018。
- en: Schaeffer et al. (2024) Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. Are
    emergent abilities of large language models a mirage? *Advances in Neural Information
    Processing Systems*, 36, 2024.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schaeffer 等人 (2024) Rylan Schaeffer, Brando Miranda 和 Sanmi Koyejo. 大型语言模型的涌现能力是海市蜃楼吗？
    *神经信息处理系统进展*, 36，2024。
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer:
    Language models can teach themselves to use tools. *arXiv preprint arXiv:2302.04761*,
    2023.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick 等人 (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda 和 Thomas Scialom. Toolformer:
    语言模型可以自我教授使用工具。 *arXiv 预印本 arXiv:2302.04761*, 2023。'
- en: 'Sikorski & Honig (2012) Michael Sikorski and Andrew Honig. *Practical malware
    analysis: the hands-on guide to dissecting malicious software*. no starch press,
    2012.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sikorski 和 Honig (2012) Michael Sikorski 和 Andrew Honig. *实用恶意软件分析：恶意软件剖析实战指南*。No
    Starch Press，2012。
- en: Teknium (2024) Teknium. Openhermes 2.5 - mistral 7b, 2024. URL [https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B).
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teknium (2024) Teknium. Openhermes 2.5 - Mistral 7B，2024。网址 [https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. *arXiv
    preprint arXiv:2307.09288*, 2023.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人 (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad
    Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale 等人. Llama 2: 开放的基础模型和微调的聊天模型。 *arXiv 预印本 arXiv:2307.09288*, 2023。'
- en: 'Ullah et al. (2018) Faheem Ullah, Matthew Edwards, Rajiv Ramdhany, Ruzanna
    Chitchyan, M Ali Babar, and Awais Rashid. Data exfiltration: A review of external
    attack vectors and countermeasures. *Journal of Network and Computer Applications*,
    101:18–54, 2018.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乌拉等人（2018）乌拉·法希姆、爱德华兹·马修、拉姆达尼·拉吉夫、奇查扬·鲁赞娜、巴巴·阿里·马、拉希德·阿瓦伊斯。数据泄露：外部攻击向量与对策的回顾。*网络与计算机应用杂志*，101:18–54，2018年。
- en: Varshney (2023) Tanay Varshney. Introduction to llm agents. 2023. URL [https://developer.nvidia.com/blog/introduction-to-llm-agents/](https://developer.nvidia.com/blog/introduction-to-llm-agents/).
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 瓦尔什尼（2023）塔内·瓦尔什尼。LLM代理简介。2023年。网址 [https://developer.nvidia.com/blog/introduction-to-llm-agents/](https://developer.nvidia.com/blog/introduction-to-llm-agents/)。
- en: 'Vulnerabilities (2005) Common Vulnerabilities. Common vulnerabilities and exposures.
    *The MITRE Corporation,[online] Available: https://cve. mitre. org/index. html*,
    2005.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏洞（2005）常见漏洞。常见漏洞与暴露。*MITRE公司，[在线]可用：https://cve.mitre.org/index.html*，2005年。
- en: 'Wang et al. (2023) Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen
    Song, and Yang Liu. Openchat: Advancing open-source language models with mixed-quality
    data. *arXiv preprint arXiv:2309.11235*, 2023.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人（2023）王冠、程思杰、詹先元、李西刚、宋森和刘阳。Openchat：通过混合质量数据推进开源语言模型。*arXiv预印本 arXiv:2309.11235*，2023年。
- en: 'Wang et al. (2024) Yaoxiang Wang, Zhiyong Wu, Junfeng Yao, and Jinsong Su.
    Tdag: A multi-agent framework based on dynamic task decomposition and agent generation.
    *arXiv preprint arXiv:2402.10178*, 2024.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人（2024）王耀祥、吴志勇、姚俊峰和苏金松。Tdag：基于动态任务分解和代理生成的多智能体框架。*arXiv预印本 arXiv:2402.10178*，2024年。
- en: 'Warszawski & Bailis (2017) Todd Warszawski and Peter Bailis. Acidrain: Concurrency-related
    attacks on database-backed web applications. In *Proceedings of the 2017 ACM International
    Conference on Management of Data*, pp.  5–20, 2017.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Warszawski 和 Bailis（2017）Todd Warszawski 和 Peter Bailis。Acidrain：数据库支持的网页应用中的并发相关攻击。发表于
    *2017年ACM国际数据管理会议论文集*，第5–20页，2017年。
- en: Wei et al. (2022) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph,
    Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
    et al. Emergent abilities of large language models. *arXiv preprint arXiv:2206.07682*,
    2022.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等人（2022）魏杰森、邹怡、波马萨尼·里希、拉费尔·科林、佐夫·巴雷特、博尔乔德·塞巴斯蒂安、约加塔玛·达尼、博斯玛·马尔滕、周丹尼、梅茨勒·唐纳德等人。大语言模型的涌现能力。*arXiv预印本
    arXiv:2206.07682*，2022年。
- en: 'Yang et al. (2023) Xianjun Yang, Xiao Wang, Qi Zhang, Linda Petzold, William Yang
    Wang, Xun Zhao, and Dahua Lin. Shadow alignment: The ease of subverting safely-aligned
    language models. *arXiv preprint arXiv:2310.02949*, 2023.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人（2023）杨先军、王晓、张齐、佩佐尔德·琳达、杨·威廉·王、赵勋和林大华。影子对齐：轻松颠覆安全对齐语言模型的方式。*arXiv预印本 arXiv:2310.02949*，2023年。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language
    models. *arXiv preprint arXiv:2210.03629*, 2022.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姚等人（2022）姚顺宇、赵杰弗里、余典、杜楠、沙夫兰·伊扎克、纳拉西曼·卡尔蒂克和曹源。React：在语言模型中协同推理与行动。*arXiv预印本 arXiv:2210.03629*，2022年。
- en: Yi et al. (2023) Jingwei Yi, Yueqi Xie, Bin Zhu, Keegan Hines, Emre Kiciman,
    Guangzhong Sun, Xing Xie, and Fangzhao Wu. Benchmarking and defending against
    indirect prompt injection attacks on large language models. *arXiv preprint arXiv:2312.14197*,
    2023.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易等人（2023）易景伟、谢岳琦、朱斌、海因斯·基根、基曼·埃姆雷、孙光中、谢星和吴方照。基准测试与防御大语言模型的间接提示注入攻击。*arXiv预印本
    arXiv:2312.14197*，2023年。
- en: Zhan et al. (2023) Qiusi Zhan, Richard Fang, Rohan Bindu, Akul Gupta, Tatsunori
    Hashimoto, and Daniel Kang. Removing rlhf protections in gpt-4 via fine-tuning.
    *arXiv preprint arXiv:2311.05553*, 2023.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 詹等人（2023）詹秋思、方理查德、Bindu Rohan、Gupta Akul、Hashimoto Tatsunori 和 康丹尼尔。通过微调去除GPT-4中的RLHF保护。*arXiv预印本
    arXiv:2311.05553*，2023年。
- en: 'Zhan et al. (2024) Qiusi Zhan, Zhixiang Liang, Zifan Ying, and Daniel Kang.
    Injecagent: Benchmarking indirect prompt injections in tool-integrated large language
    model agents. *arXiv preprint arXiv:2403.02691*, 2024.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 詹等人（2024）詹秋思、梁志翔、应子凡和康丹尼尔。Injecagent：基准测试工具集成大语言模型代理中的间接提示注入。*arXiv预印本 arXiv:2403.02691*，2024年。
- en: Zheng et al. (2024) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.
    Judging llm-as-a-judge with mt-bench and chatbot arena. *Advances in Neural Information
    Processing Systems*, 36, 2024.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郑等人（2024）郑联民、蒋维林、盛颖、庄思远、吴张昊、庄永浩、林子、李卓翰、李大成、邢埃里克等人。通过mt-bench和chatbot arena评估llm作为法官的能力。*神经信息处理系统进展*，36，2024年。
- en: Zheng & Zhang (2013) Yunhui Zheng and Xiangyu Zhang. Path sensitive static analysis
    of web applications for remote code execution vulnerability detection. In *2013
    35th International Conference on Software Engineering (ICSE)*, pp.  652–661\.
    IEEE, 2013.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 和 Zhang（2013）Yunhui Zheng 和 Xiangyu Zhang. 面向远程代码执行漏洞检测的 Web 应用程序路径敏感静态分析。载于
    *2013年第35届国际软件工程会议（ICSE）*，第652–661页。IEEE，2013年。
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson.
    Universal and transferable adversarial attacks on aligned language models. *arXiv
    preprint arXiv:2307.15043*, 2023.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等人（2023）Andy Zou, Zifan Wang, J Zico Kolter 和 Matt Fredrikson. 面向对齐语言模型的通用且可转移的对抗攻击。*arXiv
    预印本 arXiv:2307.15043*，2023年。
