- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2025-01-11 12:21:28'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:21:28
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis
    with On-the-Fly Code Visualization'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WaitGPT：通过即时代码可视化监控和引导对话型大型语言模型（LLM）在数据分析中的应用
- en: 来源：[https://arxiv.org/html/2408.01703/](https://arxiv.org/html/2408.01703/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2408.01703/](https://arxiv.org/html/2408.01703/)
- en: Liwenhan Xie [liwenhan.xie@connect.ust.hk](mailto:liwenhan.xie@connect.ust.hk)
    [0000-0002-2601-6313](https://orcid.org/0000-0002-2601-6313 "ORCID identifier")
    Hong Kong University of Science and TechnologyHong Kong SARChina ,  Chengbo Zheng
    [cb.zheng@connect.ust.hk](mailto:cb.zheng@connect.ust.hk) [0000-0003-0226-9399](https://orcid.org/0000-0003-0226-9399
    "ORCID identifier") Hong Kong University of Science and TechnologyHong Kong SARChina
    ,  Haijun Xia [haijunxia@ucsd.edu](mailto:haijunxia@ucsd.edu) [0000-0002-9425-0881](https://orcid.org/0000-0002-9425-0881
    "ORCID identifier") University of California San DiegoLa JollaCAUSA ,  Huamin
    Qu [huamin@ust.hk](mailto:huamin@ust.hk) [0000-0002-3344-9694](https://orcid.org/0000-0002-3344-9694
    "ORCID identifier") Hong Kong University of Science and TechnologyHong Kong SARChina
     and  Chen Zhu-Tian [ztchen@umn.edu](mailto:ztchen@umn.edu) [0000-0002-2313-0612](https://orcid.org/0000-0002-2313-0612
    "ORCID identifier") University of MinnesotaMinneapolisMNUSA(2024)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 李文瀚 [liwenhan.xie@connect.ust.hk](mailto:liwenhan.xie@connect.ust.hk) [0000-0002-2601-6313](https://orcid.org/0000-0002-2601-6313
    "ORCID identifier") 香港科技大学 香港特别行政区 中国， 郑成波 [cb.zheng@connect.ust.hk](mailto:cb.zheng@connect.ust.hk)
    [0000-0003-0226-9399](https://orcid.org/0000-0003-0226-9399 "ORCID identifier")
    香港科技大学 香港特别行政区 中国， 夏海军 [haijunxia@ucsd.edu](mailto:haijunxia@ucsd.edu) [0000-0002-9425-0881](https://orcid.org/0000-0002-9425-0881
    "ORCID identifier") 加利福尼亚大学圣地亚哥分校 美国加利福尼亚州拉荷亚， 曲华敏 [huamin@ust.hk](mailto:huamin@ust.hk)
    [0000-0002-3344-9694](https://orcid.org/0000-0002-3344-9694 "ORCID identifier")
    香港科技大学 香港特别行政区 中国， 朱天辰 [ztchen@umn.edu](mailto:ztchen@umn.edu) [0000-0002-2313-0612](https://orcid.org/0000-0002-2313-0612
    "ORCID identifier") 明尼苏达大学 美国明尼阿波利斯（2024）
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Large language models (LLMs) support data analysis through conversational user
    interfaces, as exemplified in OpenAI’s ChatGPT (formally known as Advanced Data
    Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing
    diverse analysis tasks. However, presenting raw code can obscure the logic and
    hinder user verification. To empower users with enhanced comprehension and augmented
    control over analysis conducted by LLMs, we propose a novel approach to transform
    LLM-generated code into an interactive visual representation. In the approach,
    users are provided with a clear, step-by-step visualization of the LLM-generated
    code in real time, allowing them to understand, verify, and modify individual
    data operations in the analysis. Our design decisions are informed by a formative
    study (N=8) probing into user practice and challenges. We further developed a
    prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability
    and effectiveness. The findings from the user study reveal that WaitGPT facilitates
    monitoring and steering of data analysis performed by LLMs, enabling participants
    to enhance error detection and increase their overall confidence in the results.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）通过对话型用户界面支持数据分析，正如OpenAI的ChatGPT（正式名称为高级数据分析或代码解释器）所示。基本上，LLM会生成代码来完成各种分析任务。然而，直接呈现原始代码可能会掩盖其逻辑，阻碍用户的验证。为了增强用户对LLM进行的数据分析的理解和控制力，我们提出了一种新方法，将LLM生成的代码转化为交互式可视化表示。在该方法中，用户可以实时查看LLM生成代码的清晰、逐步的可视化，帮助他们理解、验证并修改分析中的个别数据操作。我们的设计决策基于一项前期研究（N=8），该研究探讨了用户实践和面临的挑战。我们进一步开发了一个原型，命名为WaitGPT，并进行了用户研究（N=12）以评估其可用性和有效性。用户研究的结果显示，WaitGPT有助于监控和引导LLM执行的数据分析，帮助参与者提高错误检测能力并增强他们对分析结果的整体信心。
- en: 'Conversational Data Analysis, LLM Agent, Human-AI Interaction, Generative AI,
    Code Verification, Visual Programming^†^†journalyear: 2024^†^†copyright: acmlicensed^†^†conference:
    The 37th Annual ACM Symposium on User Interface Software and Technology; October
    13–16, 2024; Pittsburgh, PA, USA^†^†booktitle: The 37th Annual ACM Symposium on
    User Interface Software and Technology (UIST ’24), October 13–16, 2024, Pittsburgh,
    PA, USA^†^†doi: 10.1145/3654777.3676374^†^†isbn: 979-8-4007-0628-8/24/10^†^†conference:
    The ACM Symposium on User Interface Software and Technology; Oct 13–16, 2024;
    Pittsburgh, PA^†^†ccs: Human-centered computing Natural language interfaces^†^†ccs:
    Human-centered computing Graphical user interfaces^†^†ccs: Human-centered computing Information
    visualization![Refer to caption](img/342fc701c7415bca653a1b856d077024.png)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '对话数据分析，LLM代理，人机交互，生成式AI，代码验证，视觉编程^†^†journalyear: 2024^††copyright: acmlicensed^††conference:
    第37届ACM用户界面软件与技术年会；2024年10月13–16日；美国宾夕法尼亚州匹兹堡^††booktitle: 第37届ACM用户界面软件与技术年会（UIST
    ’24），2024年10月13–16日，美国宾夕法尼亚州匹兹堡^††doi: 10.1145/3654777.3676374^††isbn: 979-8-4007-0628-8/24/10^††conference:
    第37届ACM用户界面软件与技术年会；2024年10月13–16日；美国宾夕法尼亚州匹兹堡^††ccs: 以人为中心的计算 自然语言界面^††ccs: 以人为中心的计算
    图形用户界面^††ccs: 以人为中心的计算 信息可视化![参见标题](img/342fc701c7415bca653a1b856d077024.png)'
- en: 'Figure 1\. Monitoring and steering LLM-powered data analysis tools with WaitGPT:
    Beyond viewing the raw code, users can inspect data operations with a transformable
    representation generated on the fly and participate in data analysis proactively.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 使用WaitGPT监控和引导LLM驱动的数据分析工具：用户不仅可以查看原始代码，还可以通过实时生成的可变表示检查数据操作，并积极参与数据分析。
- en: \Description
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'Figure 1 compares the traditional conversational interface and WaitGPT’s code
    visualization for LLM-powered data analysis. Left side: Traditional interface
    showing challenges users face in tracking data, operations, and results when verifying
    LLM responses. Right side: WaitGPT’s solution displays a node-link diagram generated
    in real time alongside the LLM response. The diagram visualizes tables, operations,
    and results. An expandable box on an operation node allows users to access table
    size, parameters, and outputs and ask contextual questions.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1比较了传统的对话式界面和WaitGPT的LLM驱动数据分析中的代码可视化。左侧：传统界面展示了用户在验证LLM响应时，跟踪数据、操作和结果时面临的挑战。右侧：WaitGPT的解决方案显示了一个实时生成的节点-链接图与LLM响应一同展示。该图可视化了表格、操作和结果。在操作节点上有一个可展开的框，允许用户查看表格大小、参数和输出，并提出上下文问题。
- en: 1\. Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: Large language models (LLMs) have significantly lowered the entry point for
    data analysis, empowering users without strong programming skills to engage in
    sophisticated analytical tasks (Cheng et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib9);
    He et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib24); Dibia, [2023](https://arxiv.org/html/2408.01703v1#bib.bib13)).
    Instead of writing scripts or using complex software, people can directly talk
    to conversational LLM agents. Examples of emerging LLM-powered data analysis services
    or tools include ChatGPT Plus (OpenAI, [2024](https://arxiv.org/html/2408.01703v1#bib.bib48)),
    Gemini Advanced (Google, [2024](https://arxiv.org/html/2408.01703v1#bib.bib18)),
    and CodeActAgent (Wang et al., [2024a](https://arxiv.org/html/2408.01703v1#bib.bib66)).
    Generally, these tools follow a planning framework, where the LLM agent proposes
    a plan to divide the task, then generates code to process data and continues the
    process based on the execution result.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）显著降低了数据分析的入门门槛，使得没有强大编程技能的用户也能够参与复杂的分析任务（Cheng等，[2023](https://arxiv.org/html/2408.01703v1#bib.bib9)；He等，[2024](https://arxiv.org/html/2408.01703v1#bib.bib24)；Dibia，[2023](https://arxiv.org/html/2408.01703v1#bib.bib13)）。人们不再需要编写脚本或使用复杂的软件，而是可以直接与对话型LLM代理进行交流。当前一些基于LLM的数据分析服务或工具的例子包括ChatGPT
    Plus（OpenAI，[2024](https://arxiv.org/html/2408.01703v1#bib.bib48)），Gemini Advanced（Google，[2024](https://arxiv.org/html/2408.01703v1#bib.bib18)）以及CodeActAgent（Wang等，[2024a](https://arxiv.org/html/2408.01703v1#bib.bib66)）。通常，这些工具遵循一个规划框架，LLM代理首先提出一个计划来划分任务，然后生成代码处理数据，并根据执行结果继续处理。
- en: Despite their potential, real-world deployment of LLM-powered data analysis
    tools has exposed reliability concerns, including hallucinations (Liu et al.,
    [2023a](https://arxiv.org/html/2408.01703v1#bib.bib34); Chen et al., [2024b](https://arxiv.org/html/2408.01703v1#bib.bib7)),
    subtle bugs (Yang et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib74);
    Wu et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib70)), and mismatch
    between LLM’s understanding of the tasks and under-articulated user intents (Wang
    et al., [2018](https://arxiv.org/html/2408.01703v1#bib.bib65); Li et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib33)).
    Such shortcomings necessitate human oversight to verify and correct the data analysis
    process (Chopra et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib10);
    Gu et al., [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20); Olausson et al.,
    [2024](https://arxiv.org/html/2408.01703v1#bib.bib47)). Current tools often present
    raw data analysis code, shifting the user’s focus to low-level details instead
    of the high-level data analysis process. According to our interview with ChatGPT
    users, individuals, especially those with limited coding skills, struggle to comprehensively
    review the code produced by LLMs, thereby risking undetected errors and potentially
    incorrect results. Moreover, rectifying code through conversation can turn into
    a cumbersome exchange, adding to the inefficiency and frustration.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有潜力，基于大型语言模型（LLM）的数据分析工具在实际部署中暴露了可靠性问题，包括幻觉现象（Liu 等，[2023a](https://arxiv.org/html/2408.01703v1#bib.bib34)；Chen
    等，[2024b](https://arxiv.org/html/2408.01703v1#bib.bib7)），细微的错误（Yang 等，[2021](https://arxiv.org/html/2408.01703v1#bib.bib74)；Wu
    等，[2024](https://arxiv.org/html/2408.01703v1#bib.bib70)），以及LLM对任务的理解与用户未充分表述的意图之间的不匹配（Wang
    等，[2018](https://arxiv.org/html/2408.01703v1#bib.bib65)；Li 等，[2024](https://arxiv.org/html/2408.01703v1#bib.bib33)）。这些不足之处要求人工监督，以验证和修正数据分析过程（Chopra
    等，[2023](https://arxiv.org/html/2408.01703v1#bib.bib10)；Gu 等，[2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)；Olausson
    等，[2024](https://arxiv.org/html/2408.01703v1#bib.bib47)）。当前工具通常呈现原始数据分析代码，将用户的注意力转向低层次的细节，而非高层次的数据分析过程。根据我们与ChatGPT用户的访谈，个人用户，尤其是那些编程技能有限的人，难以全面审查LLM生成的代码，从而可能导致无法发现的错误和潜在的错误结果。此外，通过对话来修正代码可能会变成一场繁琐的交流，增加低效性和挫败感。
- en: 'Our goal is to make the data analysis process conducted by LLMs easier to understand
    and navigate for users, in line with current research on designing UIs featuring
    generative AIs (e.g., (Subramonyam et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib58);
    Shen et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib53))). Specifically,
    we aim to support real-time monitoring and proactive intervention (steering) at
    any point. Compared with existing approaches targeting a traditional data analysis
    pipeline (e.g., (Lau et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib32);
    Shrestha et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib56))), this
    scenario features conversational interaction and on-demand generation of unfamiliar
    code to the users, where the code streams in. Informed by a formative study involving
    8 users experienced in LLM-powered data analysis, we propose a workflow that identifies
    data operations within the generated code and maps them to visual, interactive
    primitives on the fly ([Figure. 1](https://arxiv.org/html/2408.01703v1#S0.F1 "Figure
    1 ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis
    with On-the-Fly Code Visualization")). These primitives collectively offer an
    overview of the data analysis process, and surface the details of each data operation
    and their internal runtime states in an intuitive, syntax-independent format.
    Furthermore, users can refine each operation by interacting directly with these
    primitives without regenerating the entire analysis code. Through this approach,
    we augment traditional conversational user interfaces (CUIs) with interactive
    visualization, transforming users from passive recipients of information into
    active participants in the data analysis task.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的目标是让用户更容易理解和导航由LLM（大语言模型）执行的数据分析过程，这与当前关于设计具有生成性AI特征的用户界面（如（Subramonyam等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib58)；Shen等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib53)））的研究相一致。具体来说，我们旨在支持实时监控和在任何时刻进行主动干预（引导）。与现有的面向传统数据分析流程的方法相比（如（Lau等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib32)；Shrestha等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib56)）），这一场景具有对话式交互，并且可以根据需求生成用户不熟悉的代码，这些代码会流入系统。根据一项涉及8名有LLM支持的数据分析经验的用户的前期研究，我们提出了一种工作流程，它能够识别生成代码中的数据操作，并实时将其映射到可视化的交互式原语上（[图1](https://arxiv.org/html/2408.01703v1#S0.F1
    "图1 ‣ WaitGPT: 在数据分析中监控和引导对话型LLM代理，实时代码可视化")）。这些原语共同提供了数据分析过程的概览，并直观、与语法无关地展示了每个数据操作的细节及其内部运行时状态。此外，用户可以通过直接与这些原语互动来精炼每个操作，而无需重新生成整个分析代码。通过这种方法，我们为传统的对话式用户界面（CUI）增添了交互式可视化，将用户从信息的被动接收者转变为数据分析任务的积极参与者。'
- en: We have designed and implemented WaitGPT, a prototype system that converts the
    data analysis code generated by an LLM into a visual diagram that consists of
    nodes representing key data operations, composing an overview step by step. This
    diagram progressively evolves along with the code generation process. Furthermore,
    WaitGPT executes the underlying code line by line and updates the visual diagram
    to reflect the code’s intermediate state during runtime. Users can interact with
    these nodes to modify or adjust the operations, thereby refining the data analysis
    process. Execution results are maintained and preserved within a sandbox environment,
    enabling the system to resume or rerun the analysis code after modifications,
    without the need to regenerate the entire code. A user study with 12 participants
    reported an enhanced experience, noting the ease of spotting errors, increased
    agency, and heightened confidence in the results produced by the LLM.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计并实现了WaitGPT，一个原型系统，它将LLM生成的数据分析代码转换为一个包含代表关键数据操作的节点的可视化图表，从而逐步构建数据分析概览。这个图表随着代码生成过程的进行而逐步演化。此外，WaitGPT按行执行底层代码，并在运行时更新可视化图表，以反映代码的中间状态。用户可以与这些节点交互，修改或调整操作，从而优化数据分析过程。执行结果保存在沙箱环境中，这使得系统在修改后可以恢复或重新运行分析代码，而无需重新生成整个代码。一项涉及12名参与者的用户研究报告称，用户体验得到了提升，用户发现更容易发现错误、增强了控制感，并且对LLM生成的结果更具信心。
- en: In summary, our contributions are three-fold.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献可以概括为三点。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A formative study (N=8) that summarizes practices, challenges, and expectations
    in conducting data analysis with LLM agents based on conversation.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一项前期研究（N=8），总结了基于对话进行数据分析时的实践、挑战和期望。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A novel design that facilitates monitoring and steering LLM-generated data analysis
    script featuring interactive visualizations. We implement a prototype system named
    WaitGPT and evaluate its usability (N=12).
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一种新颖的设计，促进监控和引导LLM生成的数据分析脚本，特点是交互式可视化。我们实现了一个名为WaitGPT的原型系统，并评估了其可用性（N=12）。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Discussions and implications on user interface design of LLM agents for data
    analysis tasks.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于用于数据分析任务的LLM代理用户界面设计的讨论与启示。
- en: 2\. Background & Related Work
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 背景与相关工作
- en: Here, we review NLI-based data analysis tools, visualization techniques for
    data processing scripts, and user interface design for human-LLM interactions,
    which are closely related to our study.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们回顾了基于NLI的数据分析工具、数据处理脚本的可视化技术以及人类与LLM交互的用户界面设计，这些与我们的研究密切相关。
- en: 2.1\. Demystifying NLI-based Data Analysis
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 解密基于NLI的数据分析
- en: NLI-based data analysis tools interpret users’ instructions in natural language
    and automatically perform analytic tasks. Existing tools often assemble atomic
    data operations based on a clear categorization of analytical tasks (Shen et al.,
    [2022](https://arxiv.org/html/2408.01703v1#bib.bib54); Zhu-Tian and Xia, [2022](https://arxiv.org/html/2408.01703v1#bib.bib76)).
    To support more flexible user tasks, there has been surging interest in applying
    LLMs to translate NL-based user intents into data-related operations or directly
    synthesize visualization programs (e.g., (Tian et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib61);
    Liu et al., [2023b](https://arxiv.org/html/2408.01703v1#bib.bib36), [2024](https://arxiv.org/html/2408.01703v1#bib.bib35))).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于NLI的数据分析工具通过自然语言解释用户指令并自动执行分析任务。现有的工具通常根据分析任务的明确分类组合原子数据操作（Shen等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib54);
    Zhu-Tian和Xia，[2022](https://arxiv.org/html/2408.01703v1#bib.bib76)）。为了支持更灵活的用户任务，近年来应用LLM将基于自然语言的用户意图转换为与数据相关的操作或直接合成可视化程序的兴趣激增（例如，（Tian等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib61);
    Liu等人，[2023b](https://arxiv.org/html/2408.01703v1#bib.bib36)，[2024](https://arxiv.org/html/2408.01703v1#bib.bib35)））。
- en: However, it remains unrealistic to expect completely correct outputs for reasons
    like language ambiguity and algorithmic or model accuracy (Feng et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib15);
    Ferdowsi et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib16); Narechania
    et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib45)). This issue becomes
    more pronounced when integrating LLMs into data analysis tools, given their black-box
    nature. This characteristic calls for rigorous inspection and verification strategies,
    as highlighted in prior research (Chopra et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib10);
    Podo et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib50); Gu et al.,
    [2024b](https://arxiv.org/html/2408.01703v1#bib.bib19)). Example errors include
    wrong column selection, data mapping, data transformation, etc. In response to
    the challenge, XNLI (Feng et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib15))
    provides a standalone interface that shows one user query to the key aspects in
    a finite set of the traditional NLI pipeline, i.e., attributes, tasks, and visual
    encodings. With LLMs, Huang et al. (Huang et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib26))
    converted the data transformation program into a flowchart using intermediate
    tables as nodes. Under a spreadsheet-based interface, Liu et al. (Liu et al.,
    [2023a](https://arxiv.org/html/2408.01703v1#bib.bib34)) proposed grounded abstraction
    matching (GAM) that explains LLM-generated code to end users in natural language.
    ColDeco (Ferdowsi et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib16))
    further augments GAM with two complementary views of intermediate results, highlighting
    how the operation changes the result.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，期望完全正确的输出仍然不现实，原因包括语言模糊性以及算法或模型的准确性（Feng 等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib15)；Ferdowsi
    等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib16)；Narechania 等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib45)）。当将
    LLM 集成到数据分析工具中时，这一问题尤为突出，因为 LLM 本质上是黑箱模型。这一特性要求采用严格的检查和验证策略，正如先前的研究所强调的那样（Chopra
    等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib10)；Podo 等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib50)；Gu
    等人，[2024b](https://arxiv.org/html/2408.01703v1#bib.bib19)）。示例错误包括错误的列选择、数据映射、数据转换等。为应对这一挑战，XNLI（Feng
    等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib15)）提供了一个独立的界面，将用户查询的关键方面展示为传统
    NLI 管道中的有限集合，即属性、任务和视觉编码。在 LLM 的应用中，Huang 等人（Huang 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib26)）将数据转换程序转换为流程图，并使用中间表作为节点。在基于电子表格的界面下，Liu
    等人（Liu 等人，[2023a](https://arxiv.org/html/2408.01703v1#bib.bib34)）提出了基于基础的抽象匹配（GAM），用自然语言向最终用户解释
    LLM 生成的代码。ColDeco（Ferdowsi 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib16)）进一步通过两种互补视图的中间结果增强了
    GAM，突出显示操作如何改变结果。
- en: Our work applies to analytic tasks that are more open-ended and concern complex
    data operations, which is under-examined (He et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib24)).
    Most relevant to our interest in a conversational interface, Gu et al. (Gu et al.,
    [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)) added a side panel that
    profiles intermediate data to facilitate retrospective examination of the synthesized
    code. Kazemitabaar et al. (Kazemitabaar et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib29))
    proposed to afford editable assumptions, execution plans, and code in LLM response
    for close verification and steering. We complemented their design by proposing
    a transformable representation of the code, aiming to lower the abstraction level
    of the code and enhance user engagement during the interaction.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作适用于更加开放且涉及复杂数据操作的分析任务，这些任务尚未得到充分研究（He 等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib24)）。与我们关注对话界面最相关的是，Gu
    等人（Gu 等人，[2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)）添加了一个侧边面板，展示中间数据，以促进回顾性地检查合成代码。Kazemitabaar
    等人（Kazemitabaar 等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib29)）提出在 LLM
    的响应中提供可编辑的假设、执行计划和代码，以便进行紧密验证和引导。我们通过提出可转换的代码表示法来补充他们的设计，旨在降低代码的抽象层次，并增强用户在交互过程中的参与感。
- en: 2.2\. Sense-making of Data Processing Code
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 数据处理代码的意义构建
- en: Simplifying data processing code can support learning  (Lau et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib32)),
    collaborative work (Pu et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib51)),
    and quality control (Xiong et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib73);
    Shrestha et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib57)). To give
    a comprehensive view, prior research has condensed the operations into descriptive
    narratives (Feng et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib15);
    Liu et al., [2023a](https://arxiv.org/html/2408.01703v1#bib.bib34)) or schematic
    diagrams (Huang et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib26);
    Ramasamy et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib52)). In addition,
    many works focused on visualizing interim results through animation (e.g., (Khan
    et al., [2017](https://arxiv.org/html/2408.01703v1#bib.bib30); Pu et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib51);
    Guo et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib22))) or a timeline
    representation (e.g.,  (Niederer et al., [2017](https://arxiv.org/html/2408.01703v1#bib.bib46);
    Bors et al., [2019](https://arxiv.org/html/2408.01703v1#bib.bib3); Lucchesi et al.,
    [2022](https://arxiv.org/html/2408.01703v1#bib.bib37))). For instance, Datamation (Pu
    et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib51)) visually maps and
    links each step of the data process to the underlying dataset, providing more
    context for the audience. Smallset Timeline (Lucchesi et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib37))
    intelligently selects samples affected by the operation and encodes the changes
    on a table along the timeline.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 简化数据处理代码可以支持学习（Lau 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib32)），协作工作（Pu
    等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib51)），以及质量控制（Xiong 等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib73)；Shrestha
    等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib57)）。为了提供一个全面的视角，先前的研究已将操作浓缩为描述性的叙述（Feng
    等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib15)；Liu 等人，[2023a](https://arxiv.org/html/2408.01703v1#bib.bib34)），或示意图（Huang
    等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib26)；Ramasamy 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib52)）。此外，许多研究集中于通过动画（例如，（Khan
    等人，[2017](https://arxiv.org/html/2408.01703v1#bib.bib30)；Pu 等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib51)；Guo
    等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib22)））或时间轴表示（例如，（Niederer
    等人，[2017](https://arxiv.org/html/2408.01703v1#bib.bib46)；Bors 等人，[2019](https://arxiv.org/html/2408.01703v1#bib.bib3)；Lucchesi
    等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib37)））可视化中间结果。例如，Datamation（Pu
    等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib51)）通过视觉化映射并链接数据处理的每个步骤与底层数据集，为观众提供更多的背景信息。Smallset
    Timeline（Lucchesi 等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib37)）智能地选择受操作影响的样本，并沿时间轴在表格中编码变化。
- en: To enhance understanding of atomic data operations, many works investigated
    step-wise examination of the underlying data. This can be achieved by revealing
    the connections and discrepancies between the input and output states. Pandas
    Tutor (Lau et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib32)) highlights
    selected rows and links their new position with arrows. SOMNUS (Xiong et al.,
    [2022](https://arxiv.org/html/2408.01703v1#bib.bib73)) presents 23 static glyphs
    for data transformation operations in table, column, and row granularity, respectively.
    To bridge the mental map between data transform specifications and results, some
    works allow interactive inspection (Kandel et al., [2011](https://arxiv.org/html/2408.01703v1#bib.bib28);
    Shrestha et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib56), [2023](https://arxiv.org/html/2408.01703v1#bib.bib57)).
    For instance, Unravel (Shrestha et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib56))
    automatically transforms individual data operations into summary boxes with key
    parameters and the table size, which serves as an intermediate layer for users
    to modify and access runtime execution results.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强对原子数据操作的理解，许多研究探索了逐步检查底层数据。这可以通过揭示输入和输出状态之间的连接和差异来实现。Pandas Tutor（Lau 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib32)）突出显示选定的行，并通过箭头链接它们的新位置。SOMNUS（Xiong
    等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib73)）展示了23个静态符号，分别用于表格、列和行粒度的数据转换操作。为了弥合数据转换规范与结果之间的心理映射，一些研究允许交互式检查（Kandel
    等人，[2011](https://arxiv.org/html/2408.01703v1#bib.bib28)；Shrestha 等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib56)，[2023](https://arxiv.org/html/2408.01703v1#bib.bib57)）。例如，Unravel（Shrestha
    等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib56)）自动将单独的数据操作转换为具有关键参数和表格大小的摘要框，作为用户修改和访问运行时执行结果的中介层。
- en: 'WaitGPT addresses a new problem: sense-making of data processing code produced
    by an LLM agent. Compared to previous approaches that deal with complete and static
    scripts, the code is generated in a streaming manner, which may present challenges
    for users in terms of following the LLM’s response during the generation process.
    In addition, some tools (e.g., (Wang et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib64);
    Shrestha et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib56))) require
    coding proficiency while some have a rigid functionality (e.g., (Xiong et al.,
    [2022](https://arxiv.org/html/2408.01703v1#bib.bib73); Feng et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib15))).
    However, in our scenario, end-users, including data analysts, laypeople, etc.,
    talk to an LLM agent for various data analysis tasks. We prioritize intuitive
    visualization designs for immediate understanding and rapid verification, keeping
    users engaged and undistracted during the active code generation phase. General
    code debugging, however, is beyond our scope.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT解决了一个新问题：对LLM代理生成的数据处理代码进行理解。与以往处理完整且静态脚本的方法不同，代码是以流式方式生成的，这可能给用户在生成过程中跟踪LLM的响应带来挑战。此外，一些工具（例如，（Wang等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib64)；Shrestha等人，[2021](https://arxiv.org/html/2408.01703v1#bib.bib56)））需要编程能力，而一些工具功能较为僵化（例如，（Xiong等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib73)；Feng等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib15)））。然而，在我们的场景中，最终用户，包括数据分析师、外行等，正在与LLM代理进行各种数据分析任务对话。我们优先考虑直观的可视化设计，以便用户能够立即理解和快速验证，同时在活动代码生成阶段保持用户的专注和不受干扰。然而，一般的代码调试超出了我们的范畴。
- en: 2.3\. Advancing UIs for Human-LLM Interaction
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3. 推进人类与LLM互动的用户界面
- en: Amidst the wave of LLMs, the HCI community has been advancing user interface
    design to enhance control over LLMs, moving beyond a standard chatbot framework
    or basic API invocations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模语言模型（LLMs）浪潮中，HCI（人机交互）社区正在推进用户界面设计，以增强对LLMs的控制，超越标准聊天机器人框架或基本API调用。
- en: Similar to our motivation to facilitate easier comprehension and verification
    of the generated content, some works seek to bridge the gulf of envisioning in
    human-LLM interactions (Subramonyam et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib58);
    Tankelevitch et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib60)). For
    example, Graphlogue (Jiang et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib27))
    converts linear text into a diagram that encodes logical structure on the fly
    to assist information-seeking tasks. Zhu-Tian et al. (Zhu-Tian et al., [2024a](https://arxiv.org/html/2408.01703v1#bib.bib77))
    foreshadows LLM-generated code incrementally and instantly during prompt crafting.
    Sensecape (Suh et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib59))
    empowers users with a multilevel abstraction of existing conversation and supports
    information foraging and sense-making. We attend to an emerging scenario of conversational
    data analysis with LLMs, where we present novel features like on-the-fly visualization
    as code streams in, code scrolly-telling, and snippet navigation.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们旨在简化生成内容理解和验证的动机类似，一些工作旨在弥合人类与LLM互动中的认知差距（Subramonyam等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib58)；Tankelevitch等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib60)）。例如，Graphlogue（Jiang等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib27)）将线性文本转换为图表，以动态编码逻辑结构来辅助信息检索任务。Zhu-Tian等人（Zhu-Tian等人，[2024a](https://arxiv.org/html/2408.01703v1#bib.bib77)）在提示词构建过程中逐步、即时地展示LLM生成的代码。Sensecape（Suh等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib59)）通过对现有对话进行多层次抽象，为用户提供支持信息寻找和理解的能力。我们关注一个新兴的场景——与LLM进行对话式数据分析，在这个场景中，我们呈现了新的功能，例如代码流式生成时的即时可视化、代码滚动讲述和片段导航。
- en: Another stream of research explores novel interaction designs with LLMs that
    surpass the conventional single-text prompt, where more dynamic and progressive
    workflows and interaction modalities are promoted. For instance, Wu et al. (Wu
    et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib69)) introduced the
    concept of AI Chains, where users specify how the output of one step becomes the
    input for the next, resulting in cumulative gains per step. Many works targeted
    specific application domains, including writing (Chung et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib11)),
    graphics design (Masson et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib38)),
    programming (Angert et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib2)),
    etc. Relevant to our interest in granular control of LLM-generated code, Low-code
    LLM (Cai et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib5)) allows
    users to edit the tentative workflow synthesized by a planning LLM, thereby providing
    control over the generated code. DynaVis (Vaithilingam et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib62))
    leverages LLM to synthesize UI widgets to edit data visualizations dynamically.
    Bearing a similar idea, our work supports user interactions with the intermediate
    visualization to drill down or refine the code in place for more intuitive and
    granular control with LLMs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项研究方向探讨了超越传统单一文本提示的LLM交互设计，其中推广了更为动态和渐进的工作流程和交互模式。例如，Wu等人（Wu et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib69)）提出了AI链的概念，用户指定如何将一个步骤的输出作为下一个步骤的输入，从而实现逐步积累的收益。许多研究集中于特定应用领域，包括写作（Chung
    et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib11)）、图形设计（Masson et
    al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib38)）、编程（Angert et al.,
    [2023](https://arxiv.org/html/2408.01703v1#bib.bib2)）等。与我们对LLM生成代码的精细控制的兴趣相关，Low-code
    LLM（Cai et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib5)）允许用户编辑由规划LLM合成的初步工作流程，从而对生成的代码进行控制。DynaVis（Vaithilingam
    et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib62)）利用LLM动态合成UI小部件以编辑数据可视化。基于类似的思想，我们的工作支持用户与中间可视化进行交互，以便深入分析或直接在现有代码中进行调整，从而实现更直观和精细的LLM控制。
- en: 3\. Formative Study
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 形成性研究
- en: We conducted a formative study (N=8) to better understand the glitches in LLM-powered
    data analysis tools and inform the design considerations for contextualized support.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项形成性研究（N=8），旨在更好地理解LLM驱动的数据分析工具中的问题，并为情境化支持的设计提供参考。
- en: 3.1\. Setup
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 设置
- en: Recruitment & Screening
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 招募与筛选
- en: We posted recruitment advertisements on social media and university forums.
    Candidate participants were required to complete a questionnaire about their demographic
    information and relevant experience. We selected volunteers who are more experienced
    with data analysis and familiar with LLM-powered data analysis tools.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在社交媒体和大学论坛上发布了招聘广告。候选参与者需要填写一份关于其人口统计信息和相关经验的问卷。我们挑选了在数据分析方面更有经验并且熟悉LLM驱动的数据分析工具的志愿者。
- en: Protocol
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 协议
- en: The study consisted of a contextual inquiry (20$\sim$40 min) and a structured
    interview (15 min). First, we asked participants to show their interaction history
    with LLM agents in data analysis tasks. If their original dataset is available,
    they will also walk the moderator through the data analysis procedure while thinking
    aloud. For five participants with the original dataset at hand, we asked them
    to replicate one analysis session directly while thinking aloud. The interview
    ended with a list of questions regarding the overall experience. Each participant
    is compensated with $12/hour.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究包括一个情境调查（20~40分钟）和一个结构化访谈（15分钟）。首先，我们要求参与者展示他们在数据分析任务中与LLM代理的交互历史。如果他们的原始数据集可用，他们还会在思考的同时向主持人展示数据分析过程。对于五位手头有原始数据集的参与者，我们要求他们直接重复一次分析过程，同时进行思考。访谈最后会问一些关于整体体验的问题。每位参与者的报酬为每小时12美元。
- en: Participants
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 参与者
- en: We recruited 8 participants in total (P1–P8), with 3 females and 5 males, aged
    from 20 to 30. Specifically, there are 6 postgraduate students, 1 undergraduate
    student (P3), and 1 data journalist (P4). All are familiar with the data analysis
    mode (formally named as “Advanced Data Analysis” or “Code Interpreter”) embedded
    in OpenAI’s ChatGPT (OpenAI, [2024](https://arxiv.org/html/2408.01703v1#bib.bib48))
    and had at least 5 sessions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们共招募了8位参与者（P1–P8），其中3位女性，5位男性，年龄在20至30岁之间。具体而言，包括6位研究生，1位本科生（P3），以及1位数据记者（P4）。所有人都熟悉OpenAI的ChatGPT中嵌入的“高级数据分析”或“代码解释器”数据分析模式（OpenAI,
    [2024](https://arxiv.org/html/2408.01703v1#bib.bib48)），并且至少进行了5次相关操作。
- en: Analysis
  id: totrans-48
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分析
- en: All interviews were video-recorded and transcribed into text. Following thematic
    analysis (Braun and Clarke, [2012](https://arxiv.org/html/2408.01703v1#bib.bib4)),
    the first author applied inductive and deductive approaches and derived initial
    categorized codes and themes. The first three authors reviewed transcripts and
    important screenshots based on weekly meetings to agree on the final themes after
    iterations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所有访谈都进行了录像并转录成文字。根据主题分析方法（Braun 和 Clarke，[2012](https://arxiv.org/html/2408.01703v1#bib.bib4)），第一作者采用了归纳和演绎方法，得出了初步的分类编码和主题。前三位作者根据每周会议回顾了转录内容和重要截图，并在多次迭代后就最终主题达成一致。
- en: 3.2\. Findings
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 研究结果
- en: Here, we summarize the key findings from the interview study.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们总结了访谈研究的关键发现。
- en: 3.2.1\. Why do people turn to LLM-powered tools for data analysis?
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 为什么人们选择LLM驱动的工具进行数据分析？
- en: Participants recognized the versatility of conversational LLM agents for data
    analysis as a significant advantage. They have utilized it for a diversity of
    data-intensive tasks, including exploratory data analysis (4/8), data wrangling
    (4/8), confirmatory data analysis (2/8), data profiling (2/8), and data retrieval
    (1/8). In addition, participants appreciated its flexibility in open-ended data
    analysis. “Compared with software with rigid functionalities, I enjoy the freedom
    here [in ChatGPT]. I can ask for an explanation based on the result, request recommendations
    for the next step, or insert irrelevant questions.” (P6) Another strength of an
    LLM-powered data analysis tool is its low-code or no-code environment, where end
    users only need to describe the tasks and obtain a well-organized response in
    the form of code or report. For instance, P4, who works in investigative data
    journalism (Showkat and Baumer, [2021](https://arxiv.org/html/2408.01703v1#bib.bib55))
    and regularly cleans and organizes datasets from various sources, stated “Having
    code generated from scratch saves days of my work”. This feature was particularly
    valued by participants who were not proficient in coding (2/8). “I no longer need
    to care about detailed operations and learn the APIs.” (P2)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者认为对话型LLM代理在数据分析中的多功能性是一个显著的优势。他们已经将其应用于多种数据密集型任务，包括探索性数据分析（4/8）、数据清洗（4/8）、验证性数据分析（2/8）、数据分析（2/8）以及数据检索（1/8）。此外，参与者还欣赏其在开放性数据分析中的灵活性。“与功能固定的软件相比，我喜欢[在ChatGPT中]的自由。我可以根据结果请求解释，要求下一步的建议，或插入不相关的问题。”（P6）LLM驱动的数据分析工具的另一个优势是其低代码或零代码环境，用户只需描述任务，并获得结构良好的响应，形式可能是代码或报告。例如，P4从事调查性数据新闻工作（Showkat
    和 Baumer，[2021](https://arxiv.org/html/2408.01703v1#bib.bib55)），经常清理和整理来自不同来源的数据集，他表示：“从头生成的代码节省了我几天的工作。”这一特点特别受到那些不精通编码的参与者的重视（2/8）。“我不再需要关注细节操作，也不需要学习API了。”（P2）
- en: Table 1\. Common issues in the code generated by OpenAI’s ChatGPT for data analysis
    tasks.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表1\. OpenAI的ChatGPT在数据分析任务中生成的代码常见问题。
- en: '| Issue Type | Detailed Behaviors of an LLM Agent |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 问题类型 | LLM代理的详细行为 |'
- en: '| --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Incomplete workflow | Misses some important steps, e.g., not excluding empty
    value when computing means. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 不完整的工作流 | 漏掉一些重要步骤，例如在计算均值时未排除空值。 |'
- en: '| Non-existing symbols | Invoke a function, configure a parameter, or use a
    variable that is not defined. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 不存在的符号 | 调用一个函数、配置一个参数或使用一个未定义的变量。 |'
- en: '| Data transform failure | Fails to handle edge data value, e.g., accessing
    an attribute that does not exist in all data items. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 数据转换失败 | 无法处理边界数据值，例如访问所有数据项中不存在的属性。 |'
- en: '| Wrong columns | Selects the wrong column(s). |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 错误的列 | 选择了错误的列。 |'
- en: '| Unreasonable values | Sets parameter to an inappropriate value, e.g., using
    an overly high threshold for outliers. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 不合理的值 | 将参数设置为不合适的值，例如使用过高的阈值来识别离群值。 |'
- en: \Description
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: Table 1 lists common issues encountered by interviewees when using ChatGPT for
    data analysis tasks. The first column, ”Issue Type,” categorizes the problems,
    while the second column, ”Detailed Behaviors of LLM Agent,” provides specific
    examples.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表1列出了受访者在使用ChatGPT进行数据分析任务时遇到的常见问题。第一列“问题类型”对问题进行了分类，而第二列“LLM代理的详细行为”则提供了具体的示例。
- en: 3.2.2\. How do people work with LLM-powered tools in data analysis?
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 人们如何在数据分析中使用LLM驱动的工具？
- en: 'We categorize participants’ workflows into three phases: code generation, post-verification,
    and iterative refinement.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将参与者的工作流程分为三个阶段：代码生成、后期验证和迭代优化。
- en: By default, ChatGPT collapses the code and communicates the progress in percentage
    only. Correspondingly, participants (7/8) hardly toggled the code panel during
    the generation phase but distracted themselves by turning to personal matters
    or engaging in related side tasks like reviewing previous conversations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，ChatGPT会折叠代码，仅以百分比的形式报告进度。因此，参与者（7/8）在生成阶段几乎不切换代码面板，而是分心处理个人事务或进行相关的旁任务，如回顾之前的对话。
- en: 'Upon completion of the code generation, every participant consistently reviewed
    the textual response and, if available, the visualizations to grasp the analysis’s
    implications. Verifying the code’s reliability was a common concern, with most
    (6/8) participants inspecting the generated script, especially when the data insights
    were important. They would look into the entire data processing pipeline and specific
    parameters of individual operands. P4 sometimes posed a validation question to
    verify the code’s correctness, such as requesting the mean value to see if it
    aligned with his prior knowledge. When the generated code was inconsistent with
    expectations, participants (6/8) attempted to recalibrate the agent’s direction
    through refined prompts. P2 mentioned a special strategy: “I try really hard to
    decompose the task into actionable items so that it won’t be too challenging for
    ChatGPT.” Notably, some participants (3/8) regenerated the response instead of
    starting a new conversation. “I am afraid to break the analysis flow with additional
    requirements on a small step.” (P3) For open-ended tasks, after obtaining initial
    results, participants may further drill down through conversation (3/8) or turn
    to a local coding environment (2/8), depending on the trade-off between coding
    and prompting. “With the code, I can easily reuse it on a (computational) notebook.”
    (P1)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成代码生成后，每个参与者都会一致地审查文本回应，并且如果有的话，还会查看可视化内容，以便理解分析的含义。验证代码的可靠性是一个普遍关注的问题，大多数参与者（6/8）都会检查生成的脚本，尤其是在数据洞察很重要的情况下。他们会检查整个数据处理流程以及单个操作数的特定参数。P4有时会提出验证性问题，以确认代码的正确性，比如请求查看均值，以判断是否与其先前的知识一致。当生成的代码与预期不符时，参与者（6/8）会尝试通过精细化提示重新调整代理的方向。P2提到了一种特别的策略：“我会尽力将任务分解成可执行的步骤，这样对ChatGPT来说不会太有挑战。”值得注意的是，一些参与者（3/8）会重新生成回应，而不是开始新的对话。“我担心在小步骤上添加额外要求会打断分析的流程。”（P3）对于开放性任务，获得初步结果后，参与者可能会通过对话进一步深入（3/8）或转向本地编码环境（2/8），这取决于编程和提示之间的权衡。“有了代码，我可以很容易地在（计算）笔记本上复用它。”（P1）
- en: 3.2.3\. What hinders human-LLM collaboration in data analysis tasks?
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3. 什么因素阻碍了人类与LLM在数据分析任务中的协作？
- en: Three themes emerge regarding glitches for users to participate in data analysis
    assisted by LLM agents actively.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户参与由LLM代理辅助的数据分析过程中，有三个主题与故障问题有关。
- en: $\diamond$  Disrupted workflow negatively impacts user engagement. As code generation
    and execution are sometimes long-winded, it interrupts the analysis flow. Most
    participants (7/8) would shift focus during the process instead of monitoring
    the generated code closely, for code is not as intuitive or accessible as natural
    language. “I feel exhausted when reading the code, so I’d rather leave it alone.”
    (P1) Without timely intervention, tiny errors in the code may propagate and invalidate
    the analysis result, precipitating a need to revisit and revise the work. This
    leads to heightened frustration and a considerable waste of time, as finishing
    one exploratory data analysis task generally takes half to three minutes. To avoid
    such prolonged dialogue exchanges, P3 explicitly requested the agent to ask for
    permission before generating and executing, explaining that “(In this way,) I
    can at least take control over the direction”. (P5)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$  中断的工作流程会对用户参与度产生负面影响。由于代码生成和执行有时较为冗长，会打断分析的流程。大多数参与者（7/8）在过程中会转移注意力，而不是密切监视生成的代码，因为代码不像自然语言那样直观或易于理解。“读代码让我感到很累，所以我宁愿不看。”（P1）如果没有及时干预，代码中的小错误可能会传播并使分析结果失效，导致需要重新审视和修改工作。这会导致更高的挫败感和大量的时间浪费，因为完成一个探索性数据分析任务通常需要半分钟到三分钟的时间。为了避免这种长时间的对话交换，P3明确要求代理在生成和执行代码之前征求许可，解释说“（这样做，）我至少可以控制方向”。（P5）
- en: $\diamond$  Verifying raw code is mentally demanding. While LLMs may provide
    clear annotations to explain each step, many participants (7/8) still found verifying
    the generated code challenging.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 验证原始代码在心理上是具有挑战性的。虽然大语言模型（LLM）可以提供清晰的注释来解释每个步骤，但许多参与者（7/8）仍然发现验证生成的代码具有挑战性。
- en: On the one hand, reviewing the code snippet is inherently laborious and counter-intuitive,
    particularly when deciphering code from an external source, which can be mentally
    taxing. After all, LLMs may not follow the coding styles the participants are
    comfortable with. “It [LLM] sometimes uses much-advanced syntax, so I ask it to
    write code like a freshman.” (P5) Besides, LLMs may employ unfamiliar packages.
    “I don’t even know what the function parameter is about, let alone correct it.”
    (P3)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，审查代码片段本质上是繁琐且反直觉的，尤其是当解读来自外部来源的代码时，这会对大脑造成很大的负担。毕竟，LLM 可能不会遵循参与者习惯的编码风格。“它（LLM）有时使用非常高级的语法，所以我让它像新生一样写代码。”（P5）此外，LLM
    可能会使用不熟悉的包。“我甚至不知道函数参数是干什么的，更不用说修正它了。”（P3）
- en: 'On the other hand, LLMs may introduce various unexpected errors in the code
    that require careful inspection, as evidenced in the literature (Feng et al.,
    [2024](https://arxiv.org/html/2408.01703v1#bib.bib15); Chopra et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib10);
    Gu et al., [2024b](https://arxiv.org/html/2408.01703v1#bib.bib19)). [Table 1](https://arxiv.org/html/2408.01703v1#S3.T1
    "Table 1 ‣ 3.2.1\. Why do people turn to LLM-powered tools for data analysis?
    ‣ 3.2\. Findings ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") lists example
    issues. P6 noted LLM hallucinations: “At first look, the logic was awfully smooth,
    yet the parameter was a synthesized constant. It’s very tricky (to identify the
    issue).” Some participants (3/8) were concerned about the finding’s reliability
    but frustrated with limited approaches. “I am not sure if the conclusion is correct.
    I have a tight time budget, so I check the major steps and cross my fingers for
    no other issues.” (P8)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '另一方面，LLM 可能在代码中引入各种意外错误，这需要仔细检查，文献中也有相关证据（Feng 等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib15)；Chopra
    等， [2023](https://arxiv.org/html/2408.01703v1#bib.bib10)；Gu 等， [2024b](https://arxiv.org/html/2408.01703v1#bib.bib19)）。[表
    1](https://arxiv.org/html/2408.01703v1#S3.T1 "Table 1 ‣ 3.2.1\. Why do people
    turn to LLM-powered tools for data analysis? ‣ 3.2\. Findings ‣ 3\. Formative
    Study ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis
    with On-the-Fly Code Visualization") 列出了相关示例问题。P6 提到 LLM 的幻觉：“乍一看，逻辑非常流畅，但参数却是合成常量。这个问题很难识别。”一些参与者（3/8）对结论的可靠性表示担忧，但由于方法有限，他们感到沮丧。“我不确定结论是否正确。我时间紧迫，所以我只检查主要步骤，然后希望不会有其他问题。”（P8）'
- en: $\diamond$  Iterations can be extensively back-and-forth. To fix identified
    issues, users need to formulate instructions regarding what is wrong and how to
    correct the errors and then wait for another generation-execution-report cycle.
    Unfortunately, this process can become time-consuming due to its trial-and-error
    nature and requires substantial effort to communicate the nuances of the desired
    analysis effectively. Therefore, many participants (6/8) were reluctant to embrace
    the conversational workflow fully. For minor issues like refining operational
    details, some participants (5/8) preferred to copy-paste the code to a local environment
    and make adaptations. “It is more convenient to reuse the code than telling ChatGPT
    specifically what to do.” (P7) For major changes like adding a new processing
    step, they were more willing to communicate with the LLM agent since writing code
    becomes tedious. Still, after several trials, they would turn to the local environment
    when losing patience.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 迭代过程可能需要反复多次。为了修复已识别的问题，用户需要制定有关错误内容及如何修正的指令，然后再等待另一个生成-执行-报告周期。不幸的是，由于其试错性质，这个过程可能变得耗时，而且需要大量的精力来有效地沟通所需分析的细微差别。因此，许多参与者（6/8）不愿完全接受对话式工作流。对于像完善操作细节这样的次要问题，一些参与者（5/8）更倾向于将代码复制粘贴到本地环境并进行调整。“重新使用代码比具体告诉
    ChatGPT 做什么更方便。”（P7）对于像添加新的处理步骤这样的重大变更，他们更愿意与 LLM 代理进行沟通，因为编写代码变得繁琐。然而，经过几轮尝试后，他们会在失去耐心时转向本地环境。
- en: 3.3\. Design Considerations
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 设计考虑
- en: Informed by the formative study, we draw the following design considerations
    (DC) to guide our conception of an alternative interaction design for LLM-powered
    data analysis tools. Our design goal is to support monitoring and steering LLM-synthesized
    data analysis with interactive visual scaffolding.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据形成性研究的启发，我们提出以下设计考虑（DC），以指导我们为LLM驱动的数据分析工具构思一种替代的交互设计。我们的设计目标是支持通过交互式可视化支架来监控和引导LLM合成的数据分析。
- en: DC1\. Abstract code stream into key data operations for a focused verification.
    In the context of LLM-based data analysis, a primary challenge emerges due to
    the often extensive and complex nature of the generated code. However, users usually
    prefer understanding the analysis process itself over the complex details of the
    code. Echoing a previous study (Gu et al., [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)),
    participants expressed the need to access data operations, determinant parameters,
    and their outcomes. To address this challenge, we propose to simplify the information
    to digest for verifying the data analysis procedure conducted by LLMs. By extracting
    the layered information concerning individual data operations from the code, such
    as the parametric specifications and execution results, we aim to refocus users’
    attention on the analysis process itself, sparing them from the overwhelming task
    of understanding the raw code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: DC1\. 将抽象代码流转化为关键数据操作，以便进行集中验证。在LLM驱动的数据分析中，由于生成的代码通常具有庞大而复杂的特性，主要的挑战便应运而生。然而，用户通常更愿意理解分析过程本身，而非代码的复杂细节。呼应先前的研究（Gu
    等， [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)），参与者表达了需要访问数据操作、决定性参数及其结果的需求。为了解决这一挑战，我们提议简化信息以便验证LLM进行的数据分析过程。通过从代码中提取涉及个别数据操作的分层信息，如参数规格和执行结果，我们旨在将用户的注意力重新集中到分析过程本身，免去他们理解原始代码的沉重任务。
- en: DC2\. Scaffold data operations and execution results through straightforward
    visualization generated on the fly. Despite the abstraction, users, particularly
    those with limited programming expertise, may still find it challenging to interpret
    the raw, syntax-heavy output produced by LLMs. Drawing inspiration from previous
    works in code visualization (Myers, [1990](https://arxiv.org/html/2408.01703v1#bib.bib43);
    Victor, [2011](https://arxiv.org/html/2408.01703v1#bib.bib63)), we adopt visual
    representations that abstract away from specific code syntax to facilitate quick
    comprehension of the data analysis process. Thus, the visual representation should
    also expose this information, including the data state before and after each operation.
    Moreover, this process should be executed on the fly along the code generation
    process, ensuring a seamless experience for the user aligning to their sense-making
    process. It is also critical to establish a connection between the code and its
    visual representation. This will allow users to see the direct impact of their
    instructions on the data and to navigate the analysis workflow more effectively.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: DC2\. 通过即时生成的直观可视化支架展示数据操作和执行结果。尽管进行了抽象，尤其是对于那些编程经验有限的用户，他们可能仍然难以理解LLM产生的原始、语法繁杂的输出。借鉴以往在代码可视化领域的工作（Myers,
    [1990](https://arxiv.org/html/2408.01703v1#bib.bib43); Victor, [2011](https://arxiv.org/html/2408.01703v1#bib.bib63)），我们采用了从特定代码语法中抽象出来的可视化表现形式，以促进用户对数据分析过程的快速理解。因此，这种可视化表现形式还应当展示这些信息，包括每个操作前后的数据状态。此外，该过程应在代码生成过程中即时执行，确保用户能够无缝体验并与他们的认知过程对接。建立代码与其可视化表现之间的联系也至关重要，这将使用户能够看到他们指令对数据的直接影响，从而更有效地导航分析工作流。
- en: DC3\. Support interrogation to the LLM and iterative code generation in the
    visualization. An outstanding issue of LLM-powered data analysis in a conversational
    interface is the tediousness of articulating refinement intents and uncertainties
    in LLMs’ follow-up responses. To overcome this, the visual representations should
    simplify articulating these intents by providing mechanisms to modify the data
    analysis process at a granular level. Users should be able to interact with individual
    steps (data operations) of the generated analysis, allowing them to make precise
    adjustments without the need to rewrite large portions of code or restart the
    conversation. This granular control empowers users to fine-tune the analysis,
    accurately reflects their intentions, and streamlines the iterative refinement
    process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: DC3\. 支持对 LLM 的查询和可视化中的迭代代码生成。LLM 驱动的数据分析在对话界面中的一个突出问题是，表达精细化意图和不确定性在 LLM 后续响应中往往冗长。为了解决这个问题，可视化表示应简化这些意图的表达，通过提供机制在细粒度上修改数据分析过程。用户应能够与生成分析中的各个步骤（数据操作）进行交互，从而精确调整，而无需重写大量代码或重新开始对话。这种细粒度控制使用户能够微调分析，准确反映其意图，并简化迭代精炼过程。
- en: 'DC4\. Embed visualization seamlessly into the conversational user interface
    (CUI). As conversational data analysis normally takes place in a CUI (Gu et al.,
    [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20); Chopra et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib10)),
    we tailor the design to common design patterns of web CUIs in a non-intrusive
    manner. For instance, the visualization should be stably revealed during the progressive
    generation, following the same vertical order as the code. It should offer a lightweight
    complementary view of the code section in the LLM’s response (see [Figure. 2](https://arxiv.org/html/2408.01703v1#S3.F2
    "Figure 2 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring
    and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization"))
    and afford a level of visual guidance for the code dependency between conversational
    threads.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'DC4\. 将可视化无缝嵌入到对话用户界面（CUI）中。由于对话数据分析通常在 CUI 中进行（Gu 等，[2024c](https://arxiv.org/html/2408.01703v1#bib.bib20);
    Chopra 等，[2023](https://arxiv.org/html/2408.01703v1#bib.bib10)），我们将设计调整为适应常见的
    Web CUI 设计模式，且方式非侵入性。例如，可视化应在渐进生成过程中稳定显示，并与代码保持相同的垂直顺序。它应为 LLM 响应中的代码部分提供轻量级的补充视图（参见
    [图 2](https://arxiv.org/html/2408.01703v1#S3.F2 "Figure 2 ‣ 3.3\. Design Considerations
    ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent
    in Data Analysis with On-the-Fly Code Visualization")），并为代码之间的对话线程提供一定程度的视觉指导。'
- en: '![Refer to caption](img/94a9457e74c9ab1d391ac1cac9df96a6.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/94a9457e74c9ab1d391ac1cac9df96a6.png)'
- en: Figure 2\. We propose a workflow that identifies data operations within the
    generated code and maps them to visual, interactive primitives on the fly. These
    primitives collectively offer an overview of the data analysis process.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 我们提出了一种工作流，能够识别生成代码中的数据操作，并将其即时映射到可视化的交互原语。这些原语共同提供了数据分析过程的概览。
- en: \Description
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: 'Figure 2 illustrates the proposed workflow. The left side shows the user-LLM
    interaction: users input instructions, and the LLM responds with blocks containing
    code, execution results, and analysis. The middle section depicts the visualization
    workflow: First, the code is parsed into data operations. Second, these operations
    are executed to derive runtime states. Third, the runtime states are combined
    with the static code structure to produce a visual representation that includes
    static and dynamic information. The right side describes the objects extracted
    and the focus at each stage of the visualization workflow, including the data
    operations, runtime states, and visual representations.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2 展示了所提议的工作流。左侧显示了用户与 LLM 的交互：用户输入指令，LLM 返回包含代码、执行结果和分析的块。中间部分描述了可视化工作流：首先，代码被解析为数据操作。其次，这些操作被执行以推导运行时状态。第三，运行时状态与静态代码结构相结合，生成包含静态和动态信息的可视化表示。右侧描述了在可视化工作流的每个阶段提取的对象和焦点，包括数据操作、运行时状态和可视化表示。
- en: '![Refer to caption](img/c7748fbc18335d8de1626c8ce64c72aa.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/c7748fbc18335d8de1626c8ce64c72aa.png)'
- en: Figure 3\. A screenshot of the WaitGPT user interface. (A) An enlarged view
    of the flow diagram representing the code. (B) An illustration of the “table glyphs”
    that flow along the edge showing table dependency and changes during code generation.
    (C) Inspecting intermediate data by toggling the interactive table panel. (D)
    Interrogating LLM based on an operation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. WaitGPT用户界面的截图。(A) 代表代码的流程图的放大视图。(B) “表格符号”的插图，显示了代码生成过程中的表格依赖关系和变化。(C)
    通过切换互动式表格面板检查中间数据。(D) 基于操作对LLM进行查询。
- en: \Description
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: Figure 3 shows a screenshot of the user interface. The left side presents an
    overview of a conversation, while the code visualization is enlarged on the right
    side. There are three subfigures. The top subfigure showcases animated glyphs
    during code generation. The middle-right subfigure illustrates an interactive
    table view. The bottom-right subfigure demonstrates contextual inquiry based on
    a specific operation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图3展示了用户界面的截图。左侧是对话概览，而右侧则放大了代码可视化部分。图中有三个子图。顶部子图展示了代码生成过程中的动态符号。中右侧子图展示了互动式表格视图。底右侧子图展示了基于特定操作的上下文查询。
- en: '4\. WaitGPT: Usage Scenario'
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. WaitGPT：使用场景
- en: 'Informed by the formative study and design considerations, we propose dynamically
    visualizing the code generation process to help users steer a conversational LLM
    agent during the data analysis process. This is achieved through a workflow that
    identifies data operations within the generated code and maps them to visual primitives
    on the fly (see [Figure. 2](https://arxiv.org/html/2408.01703v1#S3.F2 "Figure
    2 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")).
    These visual primitives not only illustrate the static aspects of data operations
    but also display the runtime states of the underlying data (i.e., tables) both
    before and after these operations. Moreover, they provide users with rich interaction
    possibilities, allowing them to refine the data operations without regenerating
    the code entirely.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 基于形态学研究和设计考量，我们提出通过动态可视化代码生成过程来帮助用户在数据分析过程中引导对话式LLM代理。这是通过一个工作流实现的，该工作流在生成的代码中识别数据操作，并即时将其映射到可视化原语上（参见[图2](https://arxiv.org/html/2408.01703v1#S3.F2
    "图 2 ‣ 3.3\. 设计考量 ‣ 3\. 形态学研究 ‣ WaitGPT：通过即时代码可视化监控和引导数据分析中的对话式LLM代理")）。这些可视化原语不仅展示了数据操作的静态方面，还展示了操作前后底层数据（即表格）的运行时状态。此外，它们为用户提供了丰富的互动可能性，使用户能够在不完全重新生成代码的情况下，精细化数据操作。
- en: We instantiate this idea with a prototype system, WaitGPT, which enables users
    to proactively guide the data analysis process with an LLM agent, making interventions
    akin to saying, “Wait, GPT, there is something wrong…” This section walks through
    WaitGPT using a hypothetical use case, demonstrating its capacity to transform
    the user’s interaction with LLMs in data analysis tasks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个原型系统——WaitGPT来实现这一理念，WaitGPT使用户能够主动引导数据分析过程，通过与LLM代理的交互进行干预，就像说：“等一下，GPT，哪里出了点问题……”本节通过一个假设的使用案例演示WaitGPT，展示其如何改变用户在数据分析任务中与LLM的互动方式。
- en: Usage Scenario
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用场景
- en: Zoey, a college lecturer, would like to review her students’ performance across
    assignments to inform future teaching strategies. She opened WaitGPT, an LLM-powered
    conversational tool for data analysis that she was familiar with.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Zoey，一位大学讲师，希望回顾学生在各项作业中的表现，以便为未来的教学策略提供参考。她打开了WaitGPT，这是一个她熟悉的基于LLM的对话式数据分析工具。
- en: 'WaitGPT’s interface resembles a chat box, allowing users to upload spreadsheets
    and inquire about the data in natural language ([Figure. 3](https://arxiv.org/html/2408.01703v1#S3.F3
    "Figure 3 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring
    and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")).
    Upon uploading two spreadsheets — one detailing student profiles and the other
    their individual assignment scores — Zoey asks WaitGPT to compare the performance
    of students with different backgrounds. In response, WaitGPT outlines a plan to
    meet her requirements, then crafts a code snippet to conduct analysis. An external
    executor executes this code snippet to yield results.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT的界面类似于一个聊天框，允许用户上传电子表格并用自然语言询问数据内容（[图3](https://arxiv.org/html/2408.01703v1#S3.F3
    "图 3 ‣ 3.3\. 设计考虑 ‣ 3\. 形成性研究 ‣ WaitGPT：监控和引导对话式LLM代理进行数据分析与即时代码可视化")）。在上传了两份电子表格——一份详细记录了学生的个人资料，另一份记录了他们的个人作业成绩后——Zoey要求WaitGPT比较不同背景学生的表现。作为回应，WaitGPT列出了一个满足她需求的计划，然后创建了一段代码片段来进行分析。外部执行器执行该代码片段并产生结果。
- en: 'Unlike similar tools, WaitGPT visualizes the data analysis process instead
    of just presenting raw code and textual execution results ([Figure. 3](https://arxiv.org/html/2408.01703v1#S3.F3
    "Figure 3 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring
    and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    A). It dynamically extracts data operations and presents them as nodes within
    a diagram illustrating the data flow. For instance, a “join” operation node would
    display as “merge”. And the node shows the tables being joined, the type of join
    (e.g., left join, cross join, etc.), and the indexing column used for the join.
    These blocks are linked based on dependencies and posited from left to right to
    reflect the procedural order. Notably, WaitGPT breaks down the analysis script
    into executable blocks that are executed immediately instead of executing until
    the entire code snippet is ready. This allows for a progressive understanding
    and debugging process, enabling users to see the effects of each operation in
    real time. The tool also visualizes the runtime state of data tables (e.g., the
    number of data entries/columns, selected columns) as part of the diagram. Specifically,
    the runtime state of each table is visualized as glyphs, which move along the
    linked edges between operation objects.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 与类似工具不同，WaitGPT可视化了数据分析过程，而不仅仅是展示原始代码和文本执行结果（[图3](https://arxiv.org/html/2408.01703v1#S3.F3
    "图 3 ‣ 3.3\. 设计考虑 ‣ 3\. 形成性研究 ‣ WaitGPT：监控和引导对话式LLM代理进行数据分析与即时代码可视化") A)）。它动态提取数据操作，并将它们呈现为图表中的节点，展示数据流。举例来说，一个“join”操作节点会显示为“merge”。该节点会显示正在连接的表格、连接类型（例如：左连接、交叉连接等）以及用于连接的索引列。这些块根据依赖关系相互连接，并从左到右排列，以反映过程顺序。值得注意的是，WaitGPT将分析脚本分解为可执行的块，并立即执行这些块，而不是等到整个代码片段准备好才执行。这样可以实现渐进式的理解和调试过程，让用户实时看到每个操作的效果。该工具还将数据表的运行时状态（例如：数据条目/列的数量、选定的列）作为图表的一部分进行可视化。具体来说，每个表格的运行时状态以图形符号呈现，沿着操作对象之间的连接边缘移动。
- en: 'Through the visual representation, Zoey quickly spots a flaw in the diagram—the
    row number reduces ([Figure. 3](https://arxiv.org/html/2408.01703v1#S3.F3 "Figure
    3 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    B). Rather than requiring rewriting the original query and regenerating the entire
    data analysis code, WaitGPT enables users to refine specific operations directly
    within the visualizations. Users can directly update its parameters, inquire about
    details, and indicate refinement intents through natural language. Thus, Zoey
    adjusts the join parameters to student IDs, and then clicks on the re-run button
    to execute the updated code. While the analysis goes on, Zoey inspects the table.
    She requests the LLM to clean the data. The diagram updates, reflecting the corrected
    scores after the agent integrates a data validation operation. Now Zoey is ready
    to analyze the reliable data, her teaching plans are secure on a foundation of
    accuracy.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '通过可视化表示，Zoey快速发现图表中的一个缺陷——行数减少了（[图3](https://arxiv.org/html/2408.01703v1#S3.F3
    "Figure 3 ‣ 3.3\. Design Considerations ‣ 3\. Formative Study ‣ WaitGPT: Monitoring
    and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    B）。WaitGPT使用户能够直接在可视化界面中精细调整操作，而无需重写原始查询和重新生成整个数据分析代码。用户可以直接更新参数、查询细节，并通过自然语言表明改进意图。因此，Zoey将连接参数调整为学生ID，然后点击重新运行按钮执行更新后的代码。在分析进行时，Zoey检查了表格。她请求LLM清理数据。图表更新后，反映了经过数据验证操作后修正的分数。现在，Zoey准备分析这些可靠的数据，她的教学计划建立在准确的基础上。'
- en: '5\. WaitGPT: System Design'
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. WaitGPT：系统设计
- en: 'The design of WaitGPT consists of three major components: abstracting the code
    to data operation chains, visualizing these chains, and providing interactions
    to steer the analysis process.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT的设计由三个主要部分组成：将代码抽象为数据操作链、可视化这些链条，并提供交互功能以引导分析过程。
- en: 5.1\. Abstracting Code to Operation Chains
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 将代码抽象为操作链
- en: 'Based on the interview, we identified three types of information indispensable
    for code comprehension: table variables, data operations, and execution results.
    In addition, different data operations encapsulate dedicated semantics and independent
    parameters. Therefore, we opt to abstract a data analysis process into a graph
    structure, chaining its nodes with an input-output relationship as follows (DC1).
    The input of each data operation is table(s), whereas the output can be the updated
    table, new table(s), other derived values/visualizations, or none.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基于访谈，我们确定了理解代码所必需的三种信息类型：表变量、数据操作和执行结果。此外，不同的数据操作封装了专门的语义和独立的参数。因此，我们选择将数据分析过程抽象为一个图结构，通过输入输出关系将其节点连接起来，如下所示（DC1）。每个数据操作的输入是表格，输出可以是更新后的表格、新的表格、其他派生值/可视化，或无输出。
- en: $\ast$
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Table node: A table node corresponds to a variable for an underlying table
    in the code, such as a dataframe in the Pandas package. It can be either loaded
    from a data file or dynamically generated during code execution as an interim
    variable.'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表节点：表节点对应代码中底层表的变量，例如Pandas包中的dataframe。它可以从数据文件加载，也可以在代码执行过程中动态生成，作为中间变量。
- en: $\ast$
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Operation node: An operation node ties to an atomic data operation. It surfaces
    the detailed parameters of an operation object, e.g.,,  Select ,  Filter , and
     Sort .'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 操作节点：操作节点绑定到一个原子数据操作。它展示了操作对象的详细参数，例如Select、Filter和Sort。
- en: $\ast$
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Result node: A result node is associated with an execution result, such as
    printed values or data visualization.'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果节点：结果节点与执行结果相关联，例如打印的值或数据可视化。
- en: 'Additionally, the relationship between these nodes can be one of the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些节点之间的关系可以是以下之一：
- en: $\ast$
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Input: From table node(s) to an operation node. It means the data operation
    is based on the input table(s).'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入：从表节点到操作节点。这意味着数据操作是基于输入表格的。
- en: $\ast$
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Assignment: From an operation node to a new table node. It means a new table-typed
    variable is yielded from the operation.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 赋值：从操作节点到新表节点。这意味着从该操作中产生了一个新的表类型变量。
- en: $\ast$
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Result generation: From an operation node to a result node. It means the operation
    outputs some visible results.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果生成：从操作节点到结果节点。这意味着操作输出了一些可见的结果。
- en: $\ast$
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\ast$
- en: 'Operation chain: From an operation node to an operation node. It means a table
    undergoes the two operations sequentially.'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 操作链：从一个操作节点到另一个操作节点。意味着一个表格依次经过这两个操作。
- en: Extracting the Nodes through Static Analysis.
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 通过静态分析提取节点。
- en: To extract these nodes and relationships, we perform static analysis on the
    abstract syntax tree (AST) of the generated code, where we apply heuristics informed
    by patterns of data analysis scripts and functional interface design of relevant
    packages. WaitGPT currently can parse atomic operations including  Load Data ,
     Inspect ,  Select ,  Filter ,  Sort ,  Transform ,  Group ,  Aggregate ,  Merge ,
     Add
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取这些节点及其关系，我们对生成代码的抽象语法树（AST）进行静态分析，在此过程中，我们应用了基于数据分析脚本模式和相关库的功能接口设计的启发式方法。WaitGPT当前能够解析包括 加载数据 、 检查 、 选择 、 过滤 、 排序 、 变换 、 分组 、 聚合 、 合并 、 添加 等原子操作。
- en: 'Column , and  Visualize , based on the Pandas, Matplotlib, and Seaborn packages,
    which are the default choices of ChatGPT and widely adopted (Chen et al., [2024b](https://arxiv.org/html/2408.01703v1#bib.bib7)).
    For instance, merge_df  =  df[["attr_1",  "attr_2"]].sort() will be converted
    into two operation objects:  Select  and  Sort . To bind the table targets to
    the operations, we maintain a global variable of existing table variables. This
    is because a table variable can only be created by being loaded from external
    sources (files, database, etc.) or generated as the output of prior operations.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Pandas、Matplotlib和Seaborn库的列 和 可视化，这些是ChatGPT的默认选择并被广泛采用（Chen等人，[2024b](https://arxiv.org/html/2408.01703v1#bib.bib7)）。例如，merge_df
    = df[["attr_1", "attr_2"]].sort() 将被转换为两个操作对象： 选择 和 排序 。为了将表格目标绑定到操作上，我们维护一个全局变量来存储现有的表格变量。这是因为表格变量只能通过从外部源（文件、数据库等）加载或作为先前操作的输出生成。
- en: 5.2\. Visualizing Data Operation Chains
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 可视化数据操作链
- en: Our goal is to transform the LLM-generated code into easily interpretable visualizations,
    facilitating user inspection of the data analysis process (DC2). To this end,
    we have developed a suite of visual primitives, which present the details of each
    operation and their internal runtime states. These primitives are chained together,
    collectively offering an overview of the data analysis process.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是将LLM生成的代码转化为易于理解的可视化形式，帮助用户检查数据分析过程（DC2）。为此，我们开发了一套视觉原语，呈现每个操作及其内部运行状态的细节。这些原语通过链式连接，共同提供数据分析过程的概览。
- en: Visual primitives for the static code
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 静态代码的视觉原语
- en: We utilize a diagram to represent the graph-based data processing procedure
    for individual code snippets. The table node, operation node, and result node
    are visualized as blocks, color-encoded in yellow, pink, and white. A node-style
    visualization is chosen for its familiarity to general users (DC2) and flexibility
    in displaying layered information, expanding with the code stream, and implying
    the operation order (DC4). As LLMs sometimes synthesize long variable names for
    clarification, we considered a rectangular block beneficial for encapsulating
    this information. For simplicity, a table node only shows the corresponding variable
    name, and a result node shows a thumbnail. For an operation node, we use a bold
    font style to prioritize the communication of its type (e.g., filter, group, etc.).
    And we visually differentiate its parameters’ names and values through typography.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用图示来表示针对单个代码片段的基于图的数据处理流程。表格节点、操作节点和结果节点被可视化为块状，并分别用黄色、粉色和白色进行颜色编码。选择节点式可视化是因为它对一般用户（DC2）来说较为熟悉，并且在展示层级信息时具有灵活性，能够随着代码流扩展，并暗示操作顺序（DC4）。由于大型语言模型（LLM）有时会合成长的变量名以便更清晰地表达，我们认为矩形块有助于封装这些信息。为了简化，表格节点仅显示相应的变量名，结果节点显示缩略图。操作节点则使用粗体字样来优先传达其类型（例如，过滤、分组等）。同时，我们通过排版在视觉上区分其参数名称和值。
- en: An operation chain spans from top to bottom, following its procedure. For a
    table node, there can be multiple associated operation chains. These chains are
    aligned from left to right with respect to the execution order. A code snippet
    depends on preexisting code as the runtime environment is shared throughout a
    conversation. Therefore, a table node may trace back to previous snippets. To
    reflect such a relationship, a copy is made in such a situation, which is linked
    to its previous occurrence with a cross-conversation curve.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一个操作链从上到下延展，按照其流程进行。对于一个表节点，可能有多个关联的操作链。这些链按照执行顺序从左到右对齐。一个代码片段依赖于预先存在的代码，因为运行时环境在整个对话过程中是共享的。因此，表节点可能会追溯到之前的代码片段。为了反映这种关系，在这种情况下会做一个副本，并通过跨对话曲线与其先前的出现关联。
- en: Visual primitives for the runtime states
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行时状态的视觉原语
- en: The diagram is further enriched by visual glyphs that encode the runtime status
    of table variables. A table glyph takes a common visual representation for tables—a
    2D matrix. The number of matrix columns is the same as the column number of the
    table. The number of matrix rows per column is proportional to the number of table
    rows to roughly indicate changes in data size and scale to different data sizes.
    To access precise information about the runtime states, one may interact with
    the associated operation node for details. Through chained operations, the size
    of a table can be updated.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图表通过视觉符号进一步丰富，这些符号编码了表格变量的运行时状态。表格符号采用表格的常见视觉表示形式——二维矩阵。矩阵的列数与表格的列数相同。每列的矩阵行数与表格的行数成比例，以大致表示数据大小的变化，并适应不同数据大小的尺度。要获取关于运行时状态的精确信息，用户可以与相关操作节点进行交互以获取详细信息。通过链式操作，表格的大小可以被更新。
- en: 5.3\. Steering the Data Analysis of LLMs
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 引导LLMs的数据分析
- en: The diagram goes beyond merely a visual representation of the data analysis
    process. It also acts as an interactive scaffold for users to steer data analysis
    code generated by LLMs, enabling real-time inspection, retrospective examination,
    and granular refinement (DC3). This section introduces interactions supported
    in WaitGPT.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 该图不仅仅是数据分析过程的可视化表示，它还充当了一个交互式的支架，帮助用户引导由LLM生成的数据分析代码，实现实时检查、回顾性检查和细致的优化（DC3）。本节介绍了WaitGPT支持的交互。
- en: 5.3.1\. Real-Time Inspection on the underlying code
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1\. 对底层代码的实时检查
- en: 'During code generation, only the diagram is shown to reduce the cognitive load
    of end users. However, they may still toggle on the code panel and juxtapose the
    diagram side-by-side. When a data operation is being activated, i.e., the external
    executor has just run the code, it will be added to the diagram, potentially introducing
    a new table node or a result node. Meanwhile, relevant table glyphs also appear
    and gradually flow from the previous node to the current node. [Figure. 4](https://arxiv.org/html/2408.01703v1#S5.F4
    "Figure 4 ‣ 5.3.1\. Real-Time Inspection on the underlying code ‣ 5.3\. Steering
    the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")
    showcases an example of the dynamic process.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '在代码生成过程中，只会显示图表，以减少最终用户的认知负担。然而，用户仍然可以切换到代码面板，并将图表与代码并排显示。当数据操作被激活时，即外部执行者刚刚运行了代码，它将被添加到图表中，可能会引入一个新的表节点或结果节点。同时，相关的表格符号也会出现，并逐渐从之前的节点流向当前节点。[图4](https://arxiv.org/html/2408.01703v1#S5.F4
    "Figure 4 ‣ 5.3.1\. Real-Time Inspection on the underlying code ‣ 5.3\. Steering
    the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and
    Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization")展示了这一动态过程的示例。'
- en: '![Refer to caption](img/5c9550e973530288192fd169e4a000aa.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5c9550e973530288192fd169e4a000aa.png)'
- en: Figure 4\. An illustration of how the diagram grows with animated table glyphs
    during the code generation process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图4\. 展示了在代码生成过程中，图表如何随着动画表格符号的变化而增长。
- en: \Description
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: Figure 4 uses four subfigures to demonstrate animated keyframes of a flow diagram
    during code generation. The first subfigure shows that two datasets are loaded.
    The second subfigure shows the two datasets being merged based on a mutual column
    named ”id”. The third subfigure shows the merged dataset, highlighting the animated
    effect. The last subfigure shows that a new data frame named ”merge_data” is created.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图4使用四个子图演示了在代码生成过程中流图的动画关键帧。第一个子图显示加载了两个数据集。第二个子图显示两个数据集基于名为“id”的共同列进行合并。第三个子图显示合并后的数据集，突出显示动画效果。最后一个子图显示创建了一个名为“merge_data”的新数据框。
- en: 5.3.2\. Retrospective Investigation on the analysis process
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2\. 对分析过程的回顾性调查
- en: 'After the code and diagram are completely generated, users may perform a retrospective
    examination to verify the procedure and investigate potential issues. To evaluate
    the analysis flow, users may replay the animation showing diagram expansion or
    utilize scrolly-telling, where they can take control over the animation progress
    using scroll-based interactions (DC4). If the code panel is toggled on, the corresponding
    line(s) of code will be highlighted for activated nodes upon re-play or the user’s
    mouse hover events (see [Figure. 5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") A). This feature
    bridges the visual representation and the textual code, visual navigation and
    troubleshooting. Essentially, nodes in a diagram are visually displayed in the
    simplest way to support fast comprehension. To access details about the underlying
    data tables in the runtime context, users may click on a node of interest and
    review an additional panel (see [Figure. 5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") B). The thumbnail
    of a visualization result node is expandable (see [Figure. 5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") E).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '在代码和图表完全生成后，用户可以进行回顾性检查，以验证流程并调查潜在问题。为了评估分析流程，用户可以重新播放显示图表扩展的动画，或利用滚动叙述（scrolly-telling），在这种模式下，用户可以通过基于滚动的交互控制动画进度（DC4）。如果代码面板被切换开启，则在重新播放或用户的鼠标悬停事件中，激活节点对应的代码行会被高亮显示（见[图5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") A））。该功能连接了视觉表示和文本代码、视觉导航以及故障排除。实质上，图表中的节点以最简单的方式进行视觉展示，以支持快速理解。为了获取运行时上下文中基础数据表的详细信息，用户可以点击感兴趣的节点，并查看额外的面板（见[图5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") B））。可视化结果节点的缩略图是可展开的（见[图5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") E）。'
- en: 5.3.3\. Granular Refinement
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.3\. 精细化调整
- en: 'The diagram offers new interaction modes for granular refinement through direct
    manipulation and contextual interrogation. Instead of regenerating the entire
    analysis, which may involve multiple code snippets, users can steer the data analysis
    at a finer granularity within the visualization (DC3). Users may directly manipulate
    the operation objects based on their visual representation and update the underlying
    code (see [Figure. 5](https://arxiv.org/html/2408.01703v1#S5.F5 "Figure 5 ‣ 5.3.3\.
    Granular Refinement ‣ 5.3\. Steering the Data Analysis of LLMs ‣ 5\. WaitGPT:
    System Design ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in Data
    Analysis with On-the-Fly Code Visualization") D). The fields of parameters in
    operation nodes are editable input forms, allowing fine-grain updates.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '该图表通过直接操作和上下文质询为细粒度改进提供了新的交互模式。用户可以在可视化界面中以更细的粒度引导数据分析，而无需重新生成整个分析（这可能涉及多个代码片段）（DC3）。用户可以基于操作对象的可视化表示直接操控这些对象，并更新底层代码（见[图
    5](https://arxiv.org/html/2408.01703v1#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement
    ‣ 5.3\. Steering the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT:
    Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly
    Code Visualization") D）。操作节点中的参数字段是可编辑的输入表单，允许进行精细粒度的更新。'
- en: 'Similar to the concept of interrogative debugging (Ko and Myers, [2004](https://arxiv.org/html/2408.01703v1#bib.bib31)),
    users can select specific operation nodes within the diagram and then request
    explanations or suggest revisions to the LLM by focusing on a particular node,
    which offers a targeted context for verification and refinement ([Figure. 5](https://arxiv.org/html/2408.01703v1#S5.F5
    "Figure 5 ‣ 5.3.3\. Granular Refinement ‣ 5.3\. Steering the Data Analysis of
    LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization") C). This provides
    an alternative mode to the common practice of selecting code or table cells and
    posting queries to LLMs (Nam et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib44)).
    Inspired by the regeneration practice of participants in the formative study,
    the query is independent of the main conversation and, thus, will not affect the
    memory of LLM agents. The LLM’s suggestion of code update will directly apply
    to the code panel, and the previous version will be commented out for comparison.
    When satisfied with the refinement, users can re-run the code snippet to attain
    updated analysis from LLM agents based on the new execution results.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '类似于**质询调试**的概念（Ko 和 Myers, [2004](https://arxiv.org/html/2408.01703v1#bib.bib31)），用户可以在图表中选择特定的操作节点，然后通过聚焦于某一节点，向LLM请求解释或建议修改，这为验证和改进提供了有针对性的上下文（[图
    5](https://arxiv.org/html/2408.01703v1#S5.F5 "Figure 5 ‣ 5.3.3\. Granular Refinement
    ‣ 5.3\. Steering the Data Analysis of LLMs ‣ 5\. WaitGPT: System Design ‣ WaitGPT:
    Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly
    Code Visualization") C）。这为选择代码或表格单元格并向LLM发起查询的常见做法提供了一种替代模式（Nam 等人, [2024](https://arxiv.org/html/2408.01703v1#bib.bib44)）。受前期研究中参与者再生实践的启发，该查询独立于主要对话，因此不会影响LLM代理的记忆。LLM提出的代码更新建议将直接应用于代码面板，之前的版本将被注释掉以供比较。当用户对改进感到满意时，可以重新运行代码片段，以根据新的执行结果从LLM代理获得更新后的分析。'
- en: '![Refer to caption](img/9254daece1b7a95b4eea3cf53a48be68.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9254daece1b7a95b4eea3cf53a48be68.png)'
- en: 'Figure 5\. The visualization offers multiple interactions for inspecting and
    refining the underlying data analysis. Users can: (A) toggle a table node to view
    the underlying data; (B) hover over a node to highlight its corresponding code;
    (C) modify a data operation using natural language; (D) directly manipulate the
    parameters of a node; and (E) view the resulting visualizations from the analysis.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 该可视化提供了多种交互方式，用于检查和改进底层数据分析。用户可以：（A）切换表格节点以查看底层数据；（B）将鼠标悬停在节点上以突出显示其对应的代码；（C）使用自然语言修改数据操作；（D）直接操作节点的参数；（E）查看分析结果的可视化效果。
- en: \Description
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'Figure 5 contains three components: the flow diagram on the left, the associated
    code on the top right, and the legend on the bottom right. The analysis diagram
    on the left shows code execution linked to visual elements. ”A” marks the initial
    table node, splitting into two paths: Path one goes to a group operation node,
    then to a plot line operation node, and finally to a line chart. A hand icon at
    the group operation node prompts a ”Why?” inquiry labeled ”C”. Path two leads
    to a ”Filter” operation node, a ”new_data” table node, and then to a ”Plot Bar”
    operation node, resulting in a bar chart. A line from the ”Filter” node to a specific
    line in the code is labeled ”B”. In the ”Plot Bar” node, a dropdown menu with
    a cursor clicking on it is shown, labeled ”D”. A magnifier icon next to the bar
    chart indicates an interactive feature labeled ”E”.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5 包含三个组件：左侧的流程图、右上角的相关代码和右下角的图例。左侧的分析图显示了与视觉元素关联的代码执行。 "A" 标记了初始表格节点，分为两条路径：路径一进入一个分组操作节点，然后是一个绘图操作节点，最后到达一条线性图表。在分组操作节点处，手形图标提示了一个标记为
    "C" 的 "为什么？" 提问。路径二则进入一个 "筛选" 操作节点，一个 "new_data" 表格节点，接着是一个 "绘制柱状图" 操作节点，最终得到一个柱状图。从
    "筛选" 节点到代码中特定行的连线标记为 "B"。在 "绘制柱状图" 节点中，显示了一个带光标点击的下拉菜单，标记为 "D"。在柱状图旁边的放大镜图标表示一个互动功能，标记为
    "E"。
- en: 6\. Implementation
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 实现
- en: WaitGPT is a web-based app implemented in the React (Meta Open Source, [2024](https://arxiv.org/html/2408.01703v1#bib.bib41))
    framework based on TypeScript. We apply the Monaco Editor (Microsoft, [2024](https://arxiv.org/html/2408.01703v1#bib.bib42))
    to display the code with standard syntax highlighting. We adopt the OpenAI’s API,
    with the gpt-4-0125-preview model. To manage user-uploaded files, parse LLM-synthesized
    code into an abstract syntax tree, and obtain its execution result, we also host
    a back-end server implemented in Python with Flask (Pallets, [2024](https://arxiv.org/html/2408.01703v1#bib.bib49)).
    The LLM prompts applied in WaitGPT generally follow the guidance of OpenAI with
    little engineering effort. Our implementation integrates three key mechanisms
    as follows.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT 是一个基于 TypeScript 的 React（Meta 开源，[2024](https://arxiv.org/html/2408.01703v1#bib.bib41)）框架实现的
    Web 应用程序。我们使用 Monaco 编辑器（Microsoft，[2024](https://arxiv.org/html/2408.01703v1#bib.bib42)）来显示具有标准语法高亮的代码。我们采用
    OpenAI 的 API，使用 gpt-4-0125-preview 模型。为了管理用户上传的文件、将 LLM 合成的代码解析成抽象语法树并获取其执行结果，我们还托管了一个基于
    Python 和 Flask（Pallets，[2024](https://arxiv.org/html/2408.01703v1#bib.bib49)）实现的后端服务器。WaitGPT
    中使用的 LLM 提示大致遵循 OpenAI 的指导方针，几乎不需要工程化工作。我们的实现集成了以下三个关键机制。
- en: Session Management
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 会话管理
- en: In addition to the conversation history for each session, WaitGPT maintains
    other contexts to support diagram generation on the fly and granular refinement.
    The associated contexts include a sandbox environment for file storage and code
    execution, a global record of table variables, and specifications of the diagram
    for each data analysis code snippet. In addition to the parsed parameters, the
    runtime status of target tables, and rendering configurations, the specification
    of a data operation node in a diagram also records conversation logs with the
    LLMs based on the code to support iterative refinement.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 除了每个会话的对话历史记录外，WaitGPT 还维护其他上下文，以支持动态生成图表和细粒度的优化。相关上下文包括用于文件存储和代码执行的沙盒环境、表格变量的全局记录，以及每个数据分析代码片段的图表规格。除了已解析的参数、目标表格的运行时状态和渲染配置外，图表中数据操作节点的规格还记录了基于代码的与大型语言模型（LLMs）的对话日志，以支持迭代优化。
- en: When a user sends a query, the LLM will respond with textual contents or a function
    call to the pre-declared Python executable. For code-based response, WaitGPT first
    decides whether it is about data analysis and then activates the automatic parser.
    The runtime context for each code snippet is cloned from the main process and
    cached for potential rework, thus enabling flexible user interruptions and refinement
    at any point. We enhance user navigation by prompting LLM to summarize the main
    task and build a minimap for existing data analysis snippets.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户发送查询时，LLM 会响应文本内容或对预先声明的 Python 可执行文件进行函数调用。对于基于代码的响应，WaitGPT 首先判断是否涉及数据分析，然后启动自动解析器。每个代码片段的运行时上下文会从主进程克隆并缓存，以备可能的重新处理，从而使用户可以在任何时候灵活地中断和优化。我们通过提示
    LLM 总结主要任务，并为现有的数据分析片段构建一个小地图，从而增强用户导航体验。
- en: Sandbox Execution
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 沙盒执行
- en: Before running the code in a sandbox environment, WaitGPT refactors the method
    chain into separate standalone statements. Therefore, based on the identified
    targets (i.e., table variables) of data operations, the static parser inserts
    printing statements based on templates to retrieve the intermediate status of
    the table, including the number of rows, the number of columns, and column names.
    The table status is then bonded to the corresponding data operation object. As
    a note, we opt to insert code to the LLM-generated script in a post hoc manner
    to reduce dependency on specific versions. An alternative approach is to inject
    logging facilities into the standard libraries (Pu et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib51);
    Shrestha et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib56)).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '在沙盒环境中运行代码之前，WaitGPT 将方法链重构为独立的单独语句。因此，基于已识别的数据操作目标（即表格变量），静态解析器根据模板插入打印语句，以便检索表格的中间状态，包括行数、列数和列名。表格状态随后与相应的数据操作对象绑定。需要注意的是，我们选择以事后方式向
    LLM 生成的脚本中插入代码，以减少对特定版本的依赖。另一种方法是将日志记录功能注入标准库中（Pu 等，[2021](https://arxiv.org/html/2408.01703v1#bib.bib51)；Shrestha
    等，[2021](https://arxiv.org/html/2408.01703v1#bib.bib56)）。  '
- en: Rendering
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '渲染  '
- en: The rendering of the flow diagram comprises two steps. Once the static analyzer
    extracts new data operation objects, they will be added to the diagram using a
    graph layout algorithm and maintain inactivated status. When the runtime information
    is bound to the operation object, its animated effect is pushed to a queue to
    play sequentially, where the corresponding node will be activated and the table
    glyph will flow from the prior node to the current node.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 流程图的渲染包括两个步骤。一旦静态分析器提取出新的数据操作对象，它们将通过图布局算法被添加到图中，并保持非激活状态。当运行时信息与操作对象绑定时，其动画效果会被推送到队列中按顺序播放，此时对应的节点将被激活，表格符号将从先前的节点流向当前节点。
- en: 7\. User Evaluation
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '7\. 用户评估  '
- en: We evaluate WaitGPT through an in-lab user study with 12 participants of various
    backgrounds and data analysis expertise. Specifically, we are interested in the
    following research questions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '我们通过一次实验室用户研究评估了 WaitGPT，研究对象为12名具有不同背景和数据分析专长的参与者。具体来说，我们对以下研究问题感兴趣。  '
- en: •
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '•  '
- en: How effectively does WaitGPT facilitate intermediate verification during the
    generation process of LLM agents?
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'WaitGPT 在生成 LLM 代理过程中的中间验证支持效果如何？  '
- en: •
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '•  '
- en: How effectively does WaitGPT support retrospective verification after data analysis
    tasks are completed?
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'WaitGPT 在数据分析任务完成后如何有效地支持回溯验证？  '
- en: •
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '•  '
- en: To what extent does WaitGPT support the granular refinement of generated code
    snippets?
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'WaitGPT 在生成的代码片段的细粒度优化支持程度如何？  '
- en: •
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '•  '
- en: How do users perceive the usefulness of WaitGPT in their daily data analysis
    tasks?
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '用户如何看待 WaitGPT 在日常数据分析任务中的实用性？  '
- en: 'Table 2\. The success rate (%) and average duration (seconds) in WaitGPT and
    Baseline for Task A & Task B (N=6/condition). The failure column describes the
    mistake made by LLMs in the task. #Line: No. lines in the code snippet; #Char:
    No. characters. #Df: No. table nodes in the data operation chains, #Op: No. operation
    nodes, #Res: No. result nodes. “(Value)”: standard deviance.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2\. 在 WaitGPT 和基准中的任务 A 和任务 B 的成功率（%）和平均持续时间（秒）（N=6/条件）。失败列描述了 LLM 在任务中犯的错误。#行：代码片段中的行数；#字符：字符数。#表格节点：数据操作链中的表格节点数，#操作：操作节点数，#结果：结果节点数。“（数值）”：标准偏差。  '
- en: '| Task | Failure | #Line | #Char | #Df | #Op | #Res | Success (%) | Average
    Duration (s) |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 失败 | #行 | #字符 | #表格节点 | #操作 | #结果 | 成功率（%） | 平均持续时间（秒） |  '
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |  '
- en: '| WaitGPT | Baseline | WaitGPT | Baseline |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| WaitGPT | 基准 | WaitGPT | 基准 |  '
- en: '| --- | --- | --- | --- |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |  '
- en: '| A1 | Sort on string | 14 | 474 | 2 | 5 | 0 | 83 (0.41) | 33 (0.52) | 65.83
    (45.32) | 136.67 (88.69) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| A1 | 按字符串排序 | 14 | 474 | 2 | 5 | 0 | 83 (0.41) | 33 (0.52) | 65.83 (45.32)
    | 136.67 (88.69) |  '
- en: '| A2 | Miss a group condition | 5 | 233 | 2 | 3 | 0 | 50 (0.55) | 50 (0.55)
    | 88.33 (40.21) | 102.50 (68.68) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| A2 | 错过分组条件 | 5 | 233 | 2 | 3 | 0 | 50 (0.55) | 50 (0.55) | 88.33 (40.21)
    | 102.50 (68.68) |  '
- en: '| A3 | NA | 47 | 1,836 | 5 | 10 | 1 | 100 (0.00) | 100 (0.00) | 154.00 (103.00)
    | 151.67 (143.69) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| A3 | 不适用 | 47 | 1,836 | 5 | 10 | 1 | 100 (0.00) | 100 (0.00) | 154.00 (103.00)
    | 151.67 (143.69) |  '
- en: '| A4 | Miss a filter condition | 10 | 509 | 3 | 4 | 0 | 67 (0.52) | 83 (0.41)
    | 86.67 (18.62) | 92.50 (34.31) |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| A4 | 错过筛选条件 | 10 | 509 | 3 | 4 | 0 | 67 (0.52) | 83 (0.41) | 86.67 (18.62)
    | 92.50 (34.31) |  '
- en: '| A5 | Miss dropping duplicates | 24 | 780 | 1 | 5 | 1 | 50 (0.06) | 50 (0.55)
    | 92.50 (58.37) | 87.50 (27.34) |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| A5 | 未删除重复项 | 24 | 780 | 1 | 5 | 1 | 50 (0.06) | 50 (0.55) | 92.50 (58.37)
    | 87.50 (27.34) |'
- en: '| A6 | NA | 21 | 817 | 1 | 3 | 1 | 100 (0.10) | 100 (0.00) | 144.17 (69.02)
    | 95.83 (22.45) |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| A6 | 无 | 21 | 817 | 1 | 3 | 1 | 100 (0.10) | 100 (0.00) | 144.17 (69.02)
    | 95.83 (22.45) |'
- en: '| B1 | NA | 29 | 1,167 | 4 | 7 | 1 | 100 (0.00) | 83 (0.41) | 141.67 (49.97)
    | 160.00 (82.16) |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| B1 | 无 | 29 | 1,167 | 4 | 7 | 1 | 100 (0.00) | 83 (0.41) | 141.67 (49.97)
    | 160.00 (82.16) |'
- en: '| B2 | Miss dropping duplicates | 25 | 1,287 | 5 | 6 | 1 | 67 (0.52) | 50 (0.55)
    | 242.50 (167.74) | 221.67 (159.80) |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| B2 | 未删除重复项 | 25 | 1,287 | 5 | 6 | 1 | 67 (0.52) | 50 (0.55) | 242.50 (167.74)
    | 221.67 (159.80) |'
- en: '| B3 | NA | 25 | 1,262 | 4 | 6 | 1 | 100 (0.00) | 100 (0.00) | 185.00 (113.31)
    | 176.67 (64.94) |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| B3 | 无 | 25 | 1,262 | 4 | 6 | 1 | 100 (0.00) | 100 (0.00) | 185.00 (113.31)
    | 176.67 (64.94) |'
- en: '| B4 | Wrong aggregation logic | 10 | 654 | 4 | 6 | 0 | 83 (0.41) | 83 (0.41)
    | 212.50 (145.87) | 138.50 (40.71) |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| B4 | 错误的聚合逻辑 | 10 | 654 | 4 | 6 | 0 | 83 (0.41) | 83 (0.41) | 212.50 (145.87)
    | 138.50 (40.71) |'
- en: \Description
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: 'Table 2 is structured into eleven rows (one header row and ten tasks) and nine
    columns, providing a side-by-side comparison between WaitGPT and Baseline systems
    across ten tasks (A1-A6 and B1-B4). The header row outlines the column titles:
    ”Task” for task identifiers, ”Failure” detailing mistakes made by LLMs, ”#Line”
    for the number of code lines, ”#Char” for the character count, ”#Df” for the number
    of table nodes, ”#Op” for operation nodes, and ”#Res” for result nodes. The ”Success
    (%)” and ”Average Duration (s)” are split into two columns each to compare the
    performance of WaitGPT and Baseline. Standard deviations for success rates and
    average durations are provided in parentheses.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2 由十一行（一个表头行和十个任务）和九列组成，提供了 WaitGPT 和基线系统在十个任务（A1-A6 和 B1-B4）中的并排对比。表头行列出了列标题：“任务”用于任务标识符，“失败”详细描述
    LLMs 所犯的错误，“#行”表示代码行数，“#字符”表示字符数量，“#Df”表示表格节点数，“#Op”表示操作节点数，“#Res”表示结果节点数。“成功率（%）”和“平均持续时间（秒）”被分为两列，分别用于比较
    WaitGPT 和基线系统的表现。成功率和平均持续时间的标准差以括号形式给出。
- en: 7.1\. Participants
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1. 参与者
- en: 'We recruited 12 participants (10 males, 2 females; ages 23—30, M = 26.33, SD
    = 2.15) through social media and word-of-mouth. They were postgraduate students
    with diverse backgrounds in databases, machine learning, visual analytics, industrial
    engineering, computational sociology, and HCI. According to their self-rating
    based on a 5-point Likert scale (1: lowest extent, 5: greatest extent), participants
    were generally adept at data analysis (M = 3.67, SD = 1.37) and familiar with
    the Pandas syntax used in WaitGPT (M = 3.5, SD = 1.38). They were experienced
    with LLM-powered chatbots (M = 3.75, SD = 1.06). Specifically, 5/12 participants
    leveraged ChatGPT to analyze more than 20 datasets, whereas 4/12 analyzed less
    than 5 datasets on ChatGPT.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过社交媒体和口碑招募了12名参与者（10名男性，2名女性；年龄范围为23到30岁，平均年龄 M = 26.33，标准差 SD = 2.15）。这些参与者都是来自不同背景的研究生，包括数据库、机器学习、视觉分析、工业工程、计算社会学和人机交互领域。根据他们基于5分Likert量表的自我评估（1：最低程度，5：最高程度），参与者通常擅长数据分析（M
    = 3.67，SD = 1.37），并熟悉 WaitGPT 使用的 Pandas 语法（M = 3.5，SD = 1.38）。他们有使用 LLM 驱动的聊天机器人的经验（M
    = 3.75，SD = 1.06）。具体来说，5/12 的参与者利用 ChatGPT 分析了超过 20 个数据集，而 4/12 分析了不到 5 个数据集。
- en: 7.2\. Protocol
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2. 协议
- en: Tasks
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 任务
- en: 'There are three tasks in total. Task A is based on the Employee dataset¹¹1[https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights](https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights)
    with six analysis tasks (A1–A6). Task B is based on the Flight dataset²²2[https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction)
    with four tasks (B1–B4). For Tasks A & B, the participants are required to address
    individual questions by interacting with LLMs and decide if the LLM-generated
    code is error-free. To cover representative cases, we included both confirmation
    and exploratory tasks on two tabular datasets and replicated 4 known errors made
    by LLMs (Gu et al., [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)). In
    addition, we prepared dedicated prompts for the participants to ensure that the
    first LLM-generated content was identical in each task. These prompts are grounded
    in the ARCADE (Yin et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib75))
    and Text2Analysis (He et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib24))
    datasets. Each data analysis task is independent of the other, including common
    data insight types (Ding et al., [2019](https://arxiv.org/html/2408.01703v1#bib.bib14)),
    e.g., rank, distribution, outlier, etc. Task C is based on the synthesized dataset
    used in the usage scenario (see [Sec. 4](https://arxiv.org/html/2408.01703v1#S4
    "4\. WaitGPT: Usage Scenario ‣ WaitGPT: Monitoring and Steering Conversational
    LLM Agent in Data Analysis with On-the-Fly Code Visualization")), where participants
    were asked to explore the dataset freely. We also offer a list of self-curated
    queries for their reference.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '总共有三个任务。任务A基于员工数据集¹¹1[https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights](https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights)，包含六个分析任务（A1–A6）。任务B基于航班数据集²²2[https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction](https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction)，包含四个任务（B1–B4）。对于任务A和B，参与者需要通过与LLMs互动来回答各自的问题，并判断LLM生成的代码是否没有错误。为了涵盖具有代表性的案例，我们在两个表格数据集上包含了确认性任务和探索性任务，并复现了LLMs生成的四个已知错误（Gu等，
    [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)）。此外，我们为参与者准备了专门的提示，以确保每个任务中首次生成的LLM内容完全相同。这些提示基于ARCADE（Yin等，
    [2023](https://arxiv.org/html/2408.01703v1#bib.bib75)）和Text2Analysis（He等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib24)）数据集。每个数据分析任务都是独立的，包括常见的数据洞察类型（Ding等，
    [2019](https://arxiv.org/html/2408.01703v1#bib.bib14)），例如，排名、分布、异常值等。任务C基于使用场景中使用的合成数据集（见[Sec.
    4](https://arxiv.org/html/2408.01703v1#S4 "4\. WaitGPT: 使用场景 ‣ WaitGPT: 通过即时代码可视化监控和引导会话LLM代理进行数据分析")），参与者被要求自由探索数据集。我们还为他们提供了一份自定义查询列表以供参考。'
- en: Baseline and Apparatus
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基线和设备
- en: We removed the extended view of the diagram as the baseline system, namely Baseline.
    Baseline retains essential functionalities of ChatGPT that the participants are
    familiar with. The code snippet offers by-line textual comments explaining each
    step for user verification and has standard syntax highlighting for Python. Meanwhile,
    Baseline shares the same visual appearance as WaitGPT. This ensures that any differences
    in user interaction can be attributed to the diagram’s presence or absence rather
    than other factors like aesthetics or layout. Participants joined the study in
    person and finished their tasks on standardized desktop devices to eliminate hardware
    variability as a confounding factor.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们移除了图表的扩展视图作为基线系统，即“基线”。基线保留了参与者熟悉的ChatGPT的基本功能。代码片段提供逐行的文本注释，解释每个步骤以供用户验证，并具有Python的标准语法高亮显示。同时，基线与WaitGPT具有相同的视觉外观。这确保了用户交互中的任何差异都可以归因于图表的存在或缺失，而非美学或布局等其他因素。参与者亲自加入研究，并在标准化桌面设备上完成任务，以消除硬件差异作为混杂因素。
- en: Procedure
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 程序
- en: We opted for a counterbalanced within-subjects design to compare WaitGPT and
    Baseline. There are two groups (I, II) that participants were randomly assigned
    to. In Group I, participants finish A1-3 & B1-2 in Baseline, and A4-6 & B3-4 in
    WaitGPT. Conversely, in Group II, participants finish A1-3 & B1-2 in WaitGPT,
    and A4-6 & B3-4 in Baseline. This approach allowed each participant to experience
    both conditions while performing a balanced set of tasks across the two systems.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了一个平衡的被试内设计来比较WaitGPT和基线。参与者被随机分配到两个组（I，II）。在I组中，参与者在基线中完成A1-3和B1-2，在WaitGPT中完成A4-6和B3-4。相反，在II组中，参与者在WaitGPT中完成A1-3和B1-2，在基线中完成A4-6和B3-4。这种方法使每个参与者能够在执行平衡任务集的同时体验这两种系统。
- en: The user study begins with a presentation of the visualization and interaction
    design, where participants can ask for details (5 min). Then, the participant
    should work on Task A1-6 (15-30 min), Task B1-4 (10-20 min), and Task C (5-15
    min) sequentially. The study ends with a semi-structured interview (10-15 min)
    and a questionnaire (5 min). A facilitator conducted one-on-one sessions with
    each participant, closely observing and taking notes of participant behaviors.
    The post-study interview was audio-recorded for later analysis. Participants were
    compensated with $12 per hour.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 用户研究开始时，会展示可视化和交互设计，参与者可以询问详细信息（5 分钟）。接下来，参与者应依次完成任务 A1-6（15-30 分钟）、任务 B1-4（10-20
    分钟）和任务 C（5-15 分钟）。研究结束时进行半结构化访谈（10-15 分钟）和问卷调查（5 分钟）。每位参与者都由一位主持人进行一对一会话，主持人密切观察并记录参与者的行为。研究后的访谈会进行了音频录音，以供后续分析。参与者按每小时
    12 美元的标准获得报酬。
- en: 7.3\. Measures
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3\. 测量标准
- en: We adopted the NASA-TLX (Hart and Staveland, [1988](https://arxiv.org/html/2408.01703v1#bib.bib23))
    questionnaire to measure the perceived cognitive load in steering LLM-synthesized
    data analysis. We developed a questionnaire based on a 7-point Likert scale to
    evaluate the usefulness of WaitGPT. For each pre-recorded query, the facilitator
    records (1) the time cost that the participant discerns issues in the result since
    response generation, (2) the time cost that the participant makes a judgment on
    the correctness, (3) whether the data has been examined, and (4) whether the code
    panel is expanded when viewing diagrams only.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了 NASA-TLX（Hart 和 Staveland, [1988](https://arxiv.org/html/2408.01703v1#bib.bib23)）问卷来测量在引导
    LLM 合成数据分析时的感知认知负荷。我们开发了一份基于 7 点 Likert 量表的问卷，用于评估 WaitGPT 的有效性。对于每个预先录制的查询，主持人记录（1）参与者从生成回应开始发现问题所需的时间成本，（2）参与者判断正确性的时间成本，（3）数据是否已经被检查过，以及（4）在仅查看图表时，代码面板是否已展开。
- en: 7.4\. Results
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4\. 结果
- en: To compare Baseline and WaitGPT, we analyze task correctness for Task A & B
    and the subjective ratings of the participants. We further report insights from
    the interview,
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较基线与 WaitGPT，我们分析了任务 A 和 B 的正确性以及参与者的主观评分。我们进一步报告了访谈中的见解，
- en: 7.4.1\. Task Correctness
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.1\. 任务正确性
- en: '[Table 2](https://arxiv.org/html/2408.01703v1#S7.T2 "Table 2 ‣ 7\. User Evaluation
    ‣ WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with
    On-the-Fly Code Visualization") lists detailed configurations and participant
    performance in Task A1-6 and B1-4. In general, the success rates in the WaitGPT
    condition are no less than the Baseline condition, except for A4. A4 asked for
    10 employees with the highest salary currently, whereas LLM did not filter out
    those on leave. Many participants did not notice this problem in the response.
    As for the duration, the two conditions had similar time costs ($\leq$ 10s) for
    Task A3-5 and B3. And WaitGPT took less time in Task A1-2 and Task B. However,
    multiple factors are attributed to the total duration, as seen in the relatively
    large standard deviation values. For instance, we did not consider expertise in
    data analysis when assigning participants to different groups. When the participant
    chose to inspect the code after viewing the diagram, there was an additional time
    cost to browse the code.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 2](https://arxiv.org/html/2408.01703v1#S7.T2 "表 2 ‣ 7\. 用户评估 ‣ WaitGPT：通过即时代码可视化监控和引导对话式
    LLM 代理进行数据分析") 列出了任务 A1-6 和 B1-4 的详细配置和参与者表现。总体而言，WaitGPT 条件下的成功率不低于基线条件，除了 A4。A4
    要求列出当前薪水最高的 10 名员工，而 LLM 未能筛选出休假的员工。许多参与者在回应中没有注意到这个问题。至于时长，两个条件在任务 A3-5 和 B3
    的时间花费相似（$\leq$ 10s）。而 WaitGPT 在任务 A1-2 和任务 B 中花费的时间较少。然而，由于多个因素的影响，总时长有所不同，可以看到较大的标准差。例如，我们在将参与者分配到不同组时，并未考虑数据分析的专业水平。当参与者选择在查看图表后检查代码时，浏览代码的额外时间成本也被纳入考虑。'
- en: '![Refer to caption](img/0a974461f59a16da966af08efaf22c8e.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0a974461f59a16da966af08efaf22c8e.png)'
- en: Figure 6\. User ratings on the baseline (code-only interface) and WaitGPT.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6\. 用户对基线（仅代码界面）和 WaitGPT 的评分。
- en: \Description
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: \说明
- en: Figure 6 shows a horizontal stacked bar chart comparing user responses for the
    Baseline and WaitGPT systems against six questions. The chart sequentially presents
    the questions on the left, the corresponding response bars for Baseline and then
    WaitGPT, and concludes with a legend on the right. The legend interprets the color
    gradient from dark red, indicating ”Strongly Disagree”, to dark blue for ”Strongly
    Agree.” Baseline”s bars are mostly red, suggesting neutral to negative responses.
    Meanwhile, WaitGPT”s bars are predominantly blue, showing a tendency towards agreement
    on usability.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图6展示了一张水平堆叠条形图，比较了用户对基线模型和WaitGPT系统在六个问题上的回应。图表左侧按顺序展示了各个问题，接着是基线模型和WaitGPT的对应响应条形图，最后右侧为图例。图例解释了从深红色到深蓝色的颜色渐变，深红色表示“强烈不同意”，深蓝色表示“强烈同意”。基线模型的条形图大多数为红色，表示中性到负面的回应。而WaitGPT的条形图则以蓝色为主，表明在可用性上有较高的同意倾向。
- en: 7.4.2\. Subjective Ratings
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.2. 主观评分
- en: As the questionnaires are based on an ordinal Likert scale and the sample size
    is relatively small, we performed the Wilcoxon signed-rank test to compare the
    subjective ratings between Baseline and WaitGPT.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 由于问卷采用的是有序Likert量表，并且样本量较小，我们使用Wilcoxon符号秩检验来比较基线模型与WaitGPT的主观评分。
- en: $\diamond$ On the cognitive load. In the NASA-TLX questionnaire, WaitGPT demonstrates
    lower cognitive demand to the participants. According to the statistical tests,
    there are highly significant differences (p¡.001) in the mental and physical demand,
    performance, and affective states between the two conditions. The difference in
    the effort to accomplish self-performance level (p=.010) and the temporal demand
    (p=.050) is also significant.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 关于认知负荷。在NASA-TLX问卷中，WaitGPT向参与者展示了较低的认知需求。根据统计检验，两种条件下的心理需求、身体需求、表现和情感状态之间存在显著差异（p¡.001）。在完成自我表现水平的努力（p=.010）和时间需求（p=.050）方面，差异也具有显著性。
- en: '$\diamond$ On the usefulness. [Figure. 6](https://arxiv.org/html/2408.01703v1#S7.F6
    "Figure 6 ‣ 7.4.1\. Task Correctness ‣ 7.4\. Results ‣ 7\. User Evaluation ‣ WaitGPT:
    Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly
    Code Visualization") compares the distribution of the user ratings on Baseline
    and WaitGPT based on our self-developed questionnaire. For each question, WaitGPT
    attains a higher median rating than Baseline at a confidence level of 99.5%, demonstrating
    its usefulness in demystifying the analysis (Q1-3), verifying or correcting the
    code (Q4-5), and engaging end-users (Q6). Notably, while participants varied in
    task performance, 10/12 people reported increased confidence in the correctness
    of the analysis result (Q1). Besides, based on a 7-point Likert scale (1: strongly
    disagree, 7: strongly agree), the participants considered it easy to comprehend
    the visualization design (Med=6.5, M=6.65, SD=.87) and interact with the diagram
    (Med=6.0, M=6.33, SD=.65).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '$\diamond$ 关于实用性。[图6](https://arxiv.org/html/2408.01703v1#S7.F6 "图6 ‣ 7.4.1.
    任务正确性 ‣ 7.4. 结果 ‣ 7. 用户评价 ‣ WaitGPT: 在数据分析中通过动态代码可视化监控和引导会话LLM代理") 比较了基于我们自研问卷的用户评分分布，分别针对基线模型（Baseline）和WaitGPT。对于每一个问题，WaitGPT在99.5%的置信水平下，获得的中位评分均高于基线模型，证明它在揭示分析结果（Q1-3）、验证或修正代码（Q4-5）以及与最终用户互动（Q6）方面的实用性。值得注意的是，虽然参与者的任务表现有所不同，但10/12人表示在分析结果的正确性上增加了信心（Q1）。此外，基于7点Likert量表（1:
    强烈不同意，7: 强烈同意），参与者认为可视化设计易于理解（中位数=6.5，均值=6.65，标准差=.87）且与图表互动较为容易（中位数=6.0，均值=6.33，标准差=.65）。'
- en: 7.4.3\. General impressions
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.3. 一般印象
- en: The participants were generally positive about WaitGPT and affirmed its support
    in monitoring and steering LLM-generated analysis.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者普遍对WaitGPT持积极态度，并肯定了它在监控和引导LLM生成分析方面的支持。
- en: $\diamond$ Difference in the UX between conditions. Despite in-line explanations
    and meaningful variable names in the LLM-generated code, the participants found
    it mentally taxing to follow the source code and unguided in verification. The
    reasons include memory demand for excessively long content (8/12), limited runtime
    contexts (3/12), and unfamiliar coding styles (2/12). In comparison, participants
    (12/12) resonated with the ease of understanding and verifying the code in WaitGPT
    with a higher level abstraction. The diagram “strips off unimportant details”
    (P5) and offers an overview of the code. “It [the diagram] has a clean structure
    and can serve as a navigation for the code.” (P11) This also kept participants
    engaged during the code generation. “I felt stressed viewing the code stream,
    but it’s a pleasure to watch the diagram grow.” (P4) The benefits of a visual
    summary were more apparent when the underlying code was long, as the diagram fit
    in the screen without the need to scroll vertically or horizontally (3/12). Lastly,
    many participants (8/12) were positive about the node-based interaction instead
    of sending a new chat. “There’s a chance that a new chat introduces new errors,
    so I prefer to change the code directly.” (P9)
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 条件之间的用户体验差异。尽管LLM生成的代码中包含了内联解释和有意义的变量名称，参与者仍然觉得跟踪源代码并进行验证时心力交瘁，缺乏指导。原因包括内容过长导致的记忆负担（8/12）、有限的运行时上下文（3/12）以及不熟悉的编码风格（2/12）。相比之下，参与者（12/12）一致认同WaitGPT中代码易于理解和验证，且具有更高层次的抽象。图表“去除了不重要的细节”（P5），并提供了代码的概览。“它[图表]结构清晰，可以作为代码的导航。”（P11）这也使参与者在代码生成过程中保持了参与感。“查看代码流时，我感到压力很大，但看着图表增长却是一种享受。”（P4）当底层代码较长时，视觉摘要的优势更为明显，因为图表能在不需要垂直或水平滚动的情况下适应屏幕（3/12）。最后，许多参与者（8/12）对基于节点的交互表示赞同，而不是发送新的聊天。“新的聊天可能引入新的错误，所以我更喜欢直接修改代码。”（P9）
- en: $\diamond$ Perceived usefulness of the visualization. The current visual design
    was well-received by the participants (12/12). We categorize the perceived usefulness
    of the extended visualization and associated interactions into three dimensions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 视觉化的感知有用性。当前的视觉设计得到了参与者（12/12）的高度评价。我们将扩展的视觉化及其相关交互的感知有用性分为三个维度。
- en: First, the diagram offers an abstract layer to focus on high-level logic and
    task decomposition. As observed by P12, “GPT outputs pretty code with mostly correct
    functional calls. This makes me lose caution for logical errors.” P3 claimed that
    the visualization facilitated LLM alignment—“I have a rough idea of how to process
    the data, and the diagram makes it easy to compare with my mind map.”
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，图表提供了一个抽象层，专注于高层次的逻辑和任务分解。正如P12所观察到的，“GPT输出了漂亮的代码，功能调用大多正确。这让我忽视了逻辑错误的警觉。”P3表示，图形化帮助了LLM的对齐——“我大致知道如何处理数据，图表让我更容易与我的思维导图进行比较。”
- en: Second, the visualization surfaces information at different layers, including
    the detailed parameters for data operations, profiles of the data table, and navigation
    back to the source code. For instance, the high accuracy rate for Task A1 was
    due to the convenience of inspecting data tables. “It’s great to access the table
    right away. It’s [the diagram] like an information hub.” (P10) P3 appreciated
    the typography applied in the operation nodes, as “it separates the variable names,
    operations, parameter names, and parameters”. P7 noted that the table glyphs suggested
    the semantics of unfamiliar functions through the input-output trace.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，图形化展示了不同层次的信息，包括数据操作的详细参数、数据表的概况以及返回源代码的导航。例如，任务A1的高准确率得益于便捷的数据表检查。“能够立即访问表格真好。它[图表]就像一个信息中心。”（P10）P3欣赏操作节点中应用的排版，因为“它将变量名、操作、参数名和参数分开”。P7指出，表格符号通过输入输出追踪，暗示了不熟悉函数的语义。
- en: Third, the node-based interactions offer a granular approach to interrogating
    or modifying the code. “I prefer talking to nodes in the diagram because the context
    is preserved, so I don’t need to type much. It’s nice to have something to point
    to make things clearer.” (P9)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，基于节点的交互提供了一种细致的方法来查询或修改代码。“我更喜欢和图表中的节点交互，因为上下文得以保留，所以我不需要打太多字。有一个可以指向的东西来使事情更清晰，真好。”（P9）
- en: Some participants (2/11) felt more comfortable manipulating the nodes than overwriting
    the code. “Here [in the diagram], I don’t need to care much about syntax but doing
    minimum updates.” (P5) In addition, the context of a node-based interaction is
    constrained to the corresponding code section parallel to the entire conversation.
    “I am happy to maintain a clean conversation thread.” (P11)
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参与者（2/11）在操作节点时比覆盖代码时感到更为舒适。“在这里[图表中]，我不需要太关注语法，只需要做最小的更新。”（P5）此外，基于节点的交互背景仅限于与整个对话并行的相应代码部分。“我很高兴能够保持一个干净的对话线程。”（P11）
- en: 7.4.4\. Glitches in using WaitGPT
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.4\. 使用WaitGPT时的故障
- en: Despite the benefits mentioned, users encountered several glitches while using
    the prototype.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有上述提到的好处，用户在使用原型时遇到了若干问题。
- en: $\diamond$ Diverse needs for level of details. Participants had divergent perspectives
    on the current design of WaitGPT. For instance, P10 expressed the hope of showing
    relevant annotations directly on the operation nodes. For the table glyphs, a
    few participants (2/12) competent in data analysis criticized them as trivial.
    “I’d prefer a small annotation showing the table dimensions.” (P9) However, some
    participants (3/12) embraced the design and commented that its animation double
    encoded the program procedure, in addition to the implicit node layout from left
    to right—“When the code has complex dependencies, I can follow the operations
    step by step with the table glyphs.” (P2) To accommodate diverse needs, a customizable
    interface is anticipated for flexible user configuration.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 对细节层次的多样化需求。参与者对WaitGPT当前设计有不同的看法。例如，P10希望能够直接在操作节点上显示相关注释。对于表格符号，一些擅长数据分析的参与者（2/12）批评它们显得琐碎。“我更希望看到一个显示表格维度的小注释。”（P9）然而，一些参与者（3/12）接受了这一设计，并评论说其动画不仅双重编码了程序流程，还隐含了从左到右的节点布局——“当代码有复杂依赖关系时，我可以通过表格符号一步步跟随操作。”（P2）为了满足多样化的需求，预计将推出一个可定制的界面，方便用户灵活配置。
- en: '$\diamond$ Concerns in the reliability & expressiveness. Participants with
    a computer science background (8/12) were generally interested in how the code
    was transformed into the diagram and expressed concerns about algorithmic failures
    (1/12) or potential information loss (2/12). Like what P12 asked: “What if it
    [LLM] made errors in parameters not presented in the diagram?” P6 recalled that
    he sometimes copied his code and prompted LLMs to use customized lambda functions
    for data transformation. However, in the current implementation, WaitGPT will
    only tag this as a “lambda function” without presenting more details due to the
    limit of current heuristics. As there are limited datasets on LLM-synthesized
    data analysis code at the moment, it remains challenging to systematically evaluate
    the coverage of our heuristics. To mitigate these concerns, future improvements
    may incorporate automatic verification of the parsing results and generative AI
    to surpass expressiveness limits.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 关于可靠性与表达能力的担忧。拥有计算机科学背景的参与者（8/12）普遍对代码如何转化为图表感兴趣，并对算法失败（1/12）或潜在的信息丢失（2/12）表示担忧。正如P12所问：“如果[LLM]在图表中没有呈现的参数上出错怎么办？”P6回忆道，他有时会复制自己的代码并提示LLM使用定制的lambda函数进行数据转换。然而，在当前的实现中，WaitGPT只能将其标记为“lambda函数”，而不会显示更多细节，因为当前启发式方法的限制。由于目前LLM合成的数据分析代码的数据集有限，因此仍然很难系统地评估我们启发式方法的覆盖范围。为了减轻这些担忧，未来的改进可能会加入解析结果的自动验证和生成性AI，以突破表达能力的限制。
- en: 7.4.5\. Opportunities for Applications
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.4.5\. 应用机会
- en: 'The participants shared several creative ideas for extending WaitGPT. P8 wanted
    to transfer the underlying concept into a visualization authoring context, where
    the encoding specifications are procedural and atomized—“After analyzing the data,
    I need to present it with high-quality visualizations, but tools like ChatGPT
    often fail my expectations.” P7 saw the value of a diagram in communication, especially
    to an audience with limited technical backgrounds. He said: “I can use the scroll-telling
    in my presentation to explain how the data has been transformed.” P3 envisioned
    a visual programming paradigm in which the basic building blocks can be self-composed
    or reused to communicate intention in addition to textual prompts to LLMs.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者们分享了几个关于扩展WaitGPT的创意。P8希望将这一底层概念转化为可视化创作的上下文，其中编码规范是过程化的和原子化的——“分析数据之后，我需要用高质量的可视化来呈现，但像ChatGPT这样的工具往往未能达到我的期望。”P7看到了图表在交流中的价值，尤其是在面对技术背景有限的受众时。他说：“我可以在我的演示中使用滚动叙事来解释数据是如何被转化的。”P3设想了一种视觉编程范式，其中基本构件可以自我组合或重用，除了向LLM发出文本提示之外，还可以用于传达意图。
- en: 8\. Discussion
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8. 讨论
- en: In this section, we synthesize the implications and potential avenues for future
    research and reflect on the limitations.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们总结了未来研究的意义和潜在方向，并反思了其中的局限性。
- en: 8.1\. Design Implications
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1. 设计意义
- en: Monitoring LLM agent through “visible hands”
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 通过“可见的手”监控LLM代理
- en: Despite recent progress, known issues like hallucinations in LLM agents warrant
    external steering. In WaitGPT, we abstract the LLM’s generated content into high-level
    operations rather than raw text outputs, which align more closely with human cognitive
    processes. Our approach also enriches the design space of AI resilient interfaces (Gu
    et al., [2024a](https://arxiv.org/html/2408.01703v1#bib.bib21)). Through static
    analysis, WaitGPT translates synthesized programs into abstracted operations.
    These abstracted operations are brought to life through dynamic visual representations,
    making it possible for end-users to monitor the actions of LLM agents, similar
    to watching “visible hands” in real-time. Future design may consider a similar
    mechanism of semantically rich representation and incremental update (Zhu-Tian
    et al., [2024a](https://arxiv.org/html/2408.01703v1#bib.bib77)) in communicating
    agent actions.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管最近取得了进展，但像LLM代理中的幻觉问题仍然需要外部引导。在WaitGPT中，我们将LLM生成的内容抽象为高级操作，而不是原始文本输出，这与人类的认知过程更为契合。我们的方法还丰富了AI弹性接口的设计空间（Gu等人，[2024a](https://arxiv.org/html/2408.01703v1#bib.bib21)）。通过静态分析，WaitGPT将合成的程序转化为抽象操作。这些抽象操作通过动态视觉表现得以呈现，使最终用户能够实时监控LLM代理的行为，类似于实时观看“可见的手”。未来的设计可能会考虑类似的语义丰富表示和增量更新机制（Zhu-Tian等人，[2024a](https://arxiv.org/html/2408.01703v1#bib.bib77)）来传达代理的行为。
- en: Scrollytelling for LLM-generated content
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 用滚动叙事呈现LLM生成的内容
- en: WaitGPT incorporates a basic form of scrollytelling, guiding users through the
    code by highlighting the corresponding diagrams as they scroll through the generated
    content. By combining the flow diagram with a scroll-triggered revealing mechanism,
    this technique aligns naturally with the generating process of LLM-produced content,
    fostering a deeper engagement and understanding of the content. Looking ahead,
    we advocate developing automated streaming methods to create scrollytelling narratives
    for presenting LLM-generated content. This complements the animation in the steaming
    generation phase, allowing users to control their understanding speed rather than
    passively following a predefined playing timeline.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: WaitGPT结合了基本形式的滚动叙事（scrollytelling），通过突出显示相应的图表，指导用户在滚动生成的内容时逐步理解代码。通过将流程图与滚动触发的展示机制结合，这项技术自然地与LLM生成内容的过程相契合，促进了用户对内容的更深层次参与和理解。展望未来，我们提倡开发自动化流式方法，以创建滚动叙事的叙述方式，用于呈现LLM生成的内容。这与流生成阶段的动画互为补充，使用户能够控制自己的理解速度，而不是被动地跟随预定义的播放时间线。
- en: Addressing context composition in different task granularity
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 解决不同任务粒度中的上下文组成问题
- en: One interesting property of LLMs is that they can provide reasonably high-quality
    responses to a wide variety of user tasks (Subramonyam et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib58)).
    Echoing our formative study, users may request background information or incorporate
    more contexts when analyzing data. They may start a sub-thread to test their assumptions (Gu
    et al., [2024b](https://arxiv.org/html/2408.01703v1#bib.bib19)). The highly diverse
    and evolving nature of user tasks in LLM-powered data analysis necessitates the
    development of adaptive user interfaces. A more challenging direction is to generate
    visual representations for miscellaneous contexts in unpredictable LLM responses.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）一个有趣的特点是，它们能够为各种用户任务提供相对高质量的回答（Subramonyam 等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib58)）。呼应我们之前的研究，用户在分析数据时可能会请求背景信息或融入更多上下文。他们也可能会开启子线程来检验自己的假设（Gu
    等， [2024b](https://arxiv.org/html/2408.01703v1#bib.bib19)）。LLM 驱动的数据分析中，用户任务的高度多样性和不断演变的特性要求开发具有适应性的用户界面。一个更具挑战性的方向是为不可预测的
    LLM 响应生成视觉表示，以适应各种不同的上下文。
- en: 8.2\. Future Works
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2\. 未来工作
- en: Democratizing data consumption with verifiable generative AI
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 利用可验证的生成式 AI 推动数据消费的普及
- en: With nowadays generative AI, individuals without a programming background may
    easily create data visualizations for analysis or communication. However, such
    democratization comes with challenges, particularly in ensuring the accuracy and
    reliability of AI-generated content. There’s a pressing need to navigate users
    to the potential inaccuracies and biases inherent in AI outputs (Chen et al.,
    [2024a](https://arxiv.org/html/2408.01703v1#bib.bib8); Kazemitabaar et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib29);
    Zhu-Tian et al., [2024b](https://arxiv.org/html/2408.01703v1#bib.bib78)). We believe
    that the key to fully leveraging AI’s capabilities in data consumption hinges
    on creating user interfaces that align with the expertise levels of the intended
    users. In addition, different data tasks raise different requirements warranting
    tailored supports, such as an emphasis on the authorial intent matching of encoding
    schemes in expressive visualization design (e.g., (Vaithilingam et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib62);
    Xie et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib71))).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现如今，借助生成式 AI，没有编程背景的个人也可以轻松创建数据可视化以供分析或交流。然而，这种普及化带来了挑战，尤其是在确保 AI 生成内容的准确性和可靠性方面。迫切需要引导用户认识到
    AI 输出中固有的潜在不准确性和偏见（Chen 等， [2024a](https://arxiv.org/html/2408.01703v1#bib.bib8)；Kazemitabaar
    等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib29)；Zhu-Tian 等， [2024b](https://arxiv.org/html/2408.01703v1#bib.bib78)）。我们认为，充分发挥
    AI 在数据消费中的能力，关键在于创建与目标用户的专业水平相匹配的用户界面。此外，不同的数据任务提出了不同的要求，需要定制化的支持，比如在表达性可视化设计中强调编码方案的作者意图匹配（例如，(Vaithilingam
    等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib62)；Xie 等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib71)））。
- en: Introducing a “stop” mechanism in human-LLM agent interaction
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 在人类-LLM 代理交互中引入“停止”机制
- en: While WaitGPT is based on a chatbot-like interface, such an interaction paradigm
    can apply to a standalone AI assistant integrated into data analysis software
    or notebook platforms (Mcnutt et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib39)).
    Essentially, during the ongoing conversation with LLM agents, users may be overwhelmed
    by the token-based output and fail to prevent propagating errors in time. WaitGPT
    integrates proactive strategies to identify and rectify potential failures in
    AI-generated content. Similarly, future works may further enrich the design space
    of visual representations of LLM outputs (Gu et al., [2024a](https://arxiv.org/html/2408.01703v1#bib.bib21);
    Cai et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib5)) for instant
    understanding and explore a low-cost approach to facilitate steering content generation
    based on intermediate outputs.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 WaitGPT 基于类似聊天机器人的界面，但这种交互模式也可以应用于集成到数据分析软件或笔记本平台中的独立 AI 助手（Mcnutt 等， [2023](https://arxiv.org/html/2408.01703v1#bib.bib39)）。本质上，在与
    LLM 代理进行持续对话时，用户可能会因基于令牌的输出而感到不知所措，无法及时阻止错误的传播。WaitGPT 整合了主动策略，以识别并纠正 AI 生成内容中的潜在失败。同样，未来的工作可能会进一步丰富
    LLM 输出的视觉表示设计空间（Gu 等， [2024a](https://arxiv.org/html/2408.01703v1#bib.bib21)；Cai
    等， [2024](https://arxiv.org/html/2408.01703v1#bib.bib5)），以便即时理解，并探索一种低成本的方法，基于中间输出促进内容生成的引导。
- en: Exploiting interaction modalities in conversational data interface
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 利用对话数据界面中的交互方式
- en: First, beyond textual prompts with simple selections of data slices in ChatGPT,
    future systems may incorporate other input types like direct manipulation (Masson
    et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib38)), demonstration (Huang
    et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib25)), and reference (Xie
    et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib72)). Second, to navigate
    users in nuanced decisions with drill-down explorations (Gu et al., [2024c](https://arxiv.org/html/2408.01703v1#bib.bib20),
    [b](https://arxiv.org/html/2408.01703v1#bib.bib19)), it is promising to provide
    explanations on demand (Mehrpour and Latoza, [2023](https://arxiv.org/html/2408.01703v1#bib.bib40)),
    or establish a tighter connection between code, data, textual analysis, and generated
    visualizations (Wang et al., [2024b](https://arxiv.org/html/2408.01703v1#bib.bib67);
    Cao et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib6)). Last, enabling
    users to directly reuse the generated code or interact with the resulting visualizations
    for further exploration (Weng et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib68);
    Gadhave et al., [2022](https://arxiv.org/html/2408.01703v1#bib.bib17)) could augment
    the flexibility of conversational data analysis tools.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，除了在 ChatGPT 中通过简单的数据切片选择文本提示之外，未来的系统可能会加入其他输入类型，如直接操作（Masson 等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib38)）、示范（Huang
    等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib25)）和引用（Xie 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib72)）。其次，为了帮助用户做出细致的决策并进行深入探究（Gu
    等人，[2024c](https://arxiv.org/html/2408.01703v1#bib.bib20)，[b](https://arxiv.org/html/2408.01703v1#bib.bib19)），提供按需解释（Mehrpour
    和 Latoza，[2023](https://arxiv.org/html/2408.01703v1#bib.bib40)）或在代码、数据、文本分析与生成的可视化之间建立更紧密的联系（Wang
    等人，[2024b](https://arxiv.org/html/2408.01703v1#bib.bib67); Cao 等人，[2023](https://arxiv.org/html/2408.01703v1#bib.bib6)）是有前景的。最后，使用户能够直接重用生成的代码或与结果可视化进行互动，以便进一步探索（Weng
    等人，[2024](https://arxiv.org/html/2408.01703v1#bib.bib68); Gadhave 等人，[2022](https://arxiv.org/html/2408.01703v1#bib.bib17)），可以增强会话式数据分析工具的灵活性。
- en: 8.3\. Limitation
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3 限制
- en: Threats to validity
  id: totrans-234
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对效度的威胁
- en: The sample size in our formative and evaluation studies is relatively small
    and thus may not be representative of the broader population of data analysts
    and LLM users. In the evaluation study, both conditions were equipped with standard
    syntax highlight for Python language. However, without a careful visual design
    for key operations in the Baseline, participants may favor more on WaitGPT with
    its simplified information. Besides, participants were prompted to view the transformable
    representation of the data analysis script, which may not reflect their natural
    interaction patterns. The reported usability rating may also be subject to response
    bias (Dell et al., [2012](https://arxiv.org/html/2408.01703v1#bib.bib12)) and
    participants’ familiarity with the tasks. Future works may investigate how and
    how often users leverage this augmented view in their natural working space without
    explicit prompts to capture its real-world utility.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在形成性和评估研究中的样本量相对较小，因此可能无法代表更广泛的数据分析师和大语言模型（LLM）用户群体。在评估研究中，两个条件都配备了标准的 Python
    语言语法高亮。然而，在基准测试中，如果没有对关键操作进行精心的视觉设计，参与者可能会更倾向于选择具有简化信息的 WaitGPT。此外，参与者被提示查看数据分析脚本的可变表示，这可能无法反映他们的自然交互模式。报告的可用性评分也可能受到反应偏差（Dell
    等人，[2012](https://arxiv.org/html/2408.01703v1#bib.bib12)）以及参与者对任务的熟悉度的影响。未来的研究可能会探讨用户如何以及多频繁地在没有明确提示的情况下利用这种增强视图，来捕捉其在实际工作中的效用。
- en: Scalability issues
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 可扩展性问题
- en: In the framework, translating code into a flow diagram requires static analysis,
    which is dependent on the syntax. WaitGPT is currently tailored to Python language
    and libraries like Pandas and Matplotlib for tubular data. A potential solution
    to improve generalizability is to redesign LLM prompts to allow a mixed output
    stream of code and underlying operation objects, e.g., (Suh et al., [2023](https://arxiv.org/html/2408.01703v1#bib.bib59);
    Kazemitabaar et al., [2024](https://arxiv.org/html/2408.01703v1#bib.bib29)). However,
    the code stream visualization may not work for SQL-like languages with a reversed
    execution order compared to the procedure declaration. Second, the flow diagram
    assumes a linear structure in the code, targeting fluent interfaces (Shrestha
    et al., [2021](https://arxiv.org/html/2408.01703v1#bib.bib56)). Future works can
    incorporate control flows like loops and visual primitives for other data types.
    Last, the current glyph design may not scale to tables with over 20 columns. To
    address this, unused columns can be aggregated, or important ones can be hidden.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在该框架中，将代码转换为流程图需要静态分析，这依赖于语法。WaitGPT目前针对Python语言及其相关库，如Pandas和Matplotlib，用于表格数据。为了提高通用性，一个潜在的解决方案是重新设计LLM提示，允许代码与底层操作对象的混合输出流，例如（Suh等，[2023](https://arxiv.org/html/2408.01703v1#bib.bib59);
    Kazemitabaar等，[2024](https://arxiv.org/html/2408.01703v1#bib.bib29)）。然而，代码流的可视化可能无法适用于SQL类似语言，因为这些语言的执行顺序与过程声明的顺序相反。其次，流程图假设代码结构是线性的，目标是流畅的接口（Shrestha等，[2021](https://arxiv.org/html/2408.01703v1#bib.bib56)）。未来的工作可以结合控制流，如循环，以及其他数据类型的可视化原语。最后，当前的符号设计可能无法扩展到具有超过20列的表格。为了解决这个问题，可以聚合未使用的列，或隐藏重要的列。
- en: 9\. Conclusion
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9. 结论
- en: In this paper, we introduced WaitGPT, a novel interface design that transforms
    LLM-generated code into an accessible, interactive representation to address the
    reliability issues and user challenges in LLM-powered data analysis tools. Drawing
    from an interview study with general users (N=8) of ChatGPT, we gained insights
    into general perspectives on these nascent tools and glitches in disruptive workflow,
    code verification, and labor-intensive iterations. By translating stream-based
    code into a growing visualization of the key data operations and affording granular
    interactions, WaitGPT empowers users to monitor and steer data analysis performed
    by LLM agents. A user study (N=12) covering basic data analysis tasks demonstrated
    that WaitGPT could enhance error detection rate and improve overall confidence
    in the results.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了WaitGPT，这是一种新型的界面设计，将LLM生成的代码转化为可访问、互动的表示形式，旨在解决LLM驱动的数据分析工具中的可靠性问题和用户挑战。通过对ChatGPT的一项访谈研究（N=8），我们获得了关于这些新兴工具的普遍看法，以及在干扰性工作流程、代码验证和劳动密集型迭代方面的障碍。通过将基于流的代码转化为关键数据操作的逐步可视化并提供细粒度交互，WaitGPT使用户能够监控和引导LLM代理执行的数据分析。一个涵盖基本数据分析任务的用户研究（N=12）表明，WaitGPT能够提高错误检测率，并增强对结果的总体信心。
- en: Our work contributes to the field of human-AI collaboration in data analysis
    by demonstrating the effectiveness of transformable code representations in facilitating
    user understanding and engagement. As LLM applications in data analysis become
    more prevalent, prioritizing user experience and trust through accessible, interactive
    interfaces will be crucial in harnessing the potential of these powerful tools
    while ensuring their reliability and usability. We urge more exploration of novel
    human-LLM interaction paradigms and intuitive visual representation design for
    LLM responses.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作通过展示可转化代码表示在促进用户理解和参与方面的有效性，为数据分析中的人类-AI协作领域做出了贡献。随着LLM应用在数据分析中的普及，优先考虑用户体验和信任，通过可访问、互动的界面，将在发挥这些强大工具的潜力的同时，确保它们的可靠性和可用性。我们呼吁更多地探索新的人类-LLM交互范式和LLM响应的直观可视化设计。
- en: Acknowledgements.
  id: totrans-241
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢
- en: This research is supported by RGC GRF grant 16210321\. The first author thanks
    Prof. Hanspeter Pfister for hosting the visit to the Harvard Visual Computing
    Group. We also thank the anonymous reviewers for their constructive feedback,
    the participants in the formative and user studies, and Zhan Wang, Leixian Shen,
    Xiaofu Jin, Shuchang Xu, Dr. Yanna Lin, Dr. Qingyu Guo, and Dr. Yun Wang for their
    valuable input.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了RGC GRF资助16210321的支持。第一作者感谢Hanspeter Pfister教授接待访问哈佛视觉计算组。我们还感谢匿名评审人提供的建设性反馈、参与形式化和用户研究的参与者，以及Zhan
    Wang、Leixian Shen、Xiaofu Jin、Shuchang Xu、Dr. Yanna Lin、Dr. Qingyu Guo和Dr. Yun
    Wang的宝贵意见。
- en: References
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Angert et al. (2023) Tyler Angert, Miroslav Suzara, Jenny Han, Christopher
    Pondoc, and Hariharan Subramonyam. 2023. Spellburst: A node-based interface for
    exploratory creative coding with natural language prompts. In *Proceedings of
    the Symposium on User Interface Software and Technology (UIST)*. ACM, New York,
    NY, Article 100, 22 pages. [https://doi.org/10.1145/3586183.3606719](https://doi.org/10.1145/3586183.3606719)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angert 等（2023）Tyler Angert、Miroslav Suzara、Jenny Han、Christopher Pondoc 和 Hariharan
    Subramonyam。2023年。Spellburst：一个基于节点的接口，用于通过自然语言提示进行探索性创意编码。发表于 *用户界面软件与技术研讨会（UIST）会议录*。ACM，纽约，NY，文章100，22页。[https://doi.org/10.1145/3586183.3606719](https://doi.org/10.1145/3586183.3606719)
- en: Bors et al. (2019) Christian Bors, Theresia Gschwandtner, and Silvia Miksch.
    2019. Capturing and visualizing provenance from data wrangling. *IEEE Comput.
    Graph. Appl.* 39, 6 (2019), 61–75. [https://doi.org/10.1109/MCG.2019.2941856](https://doi.org/10.1109/MCG.2019.2941856)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bors 等（2019）Christian Bors、Theresia Gschwandtner 和 Silvia Miksch。2019年。捕捉和可视化数据处理的来源。*IEEE计算机图形学与应用*
    39，6（2019），61–75。[https://doi.org/10.1109/MCG.2019.2941856](https://doi.org/10.1109/MCG.2019.2941856)
- en: 'Braun and Clarke (2012) Virginia Braun and Victoria Clarke. 2012. Thematic
    analysis. In *APA handbook of research methods in psychology, Vol. 2\. Research
    designs: Quantitative, qualitative, neuropsychological, and biological*. APA,
    Washington D.C. [https://doi.org/10.1037/13620-004](https://doi.org/10.1037/13620-004)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Braun 和 Clarke（2012）Virginia Braun 和 Victoria Clarke。2012年。主题分析。发表于 *美国心理学会心理学研究方法手册，第2卷：研究设计：定量、定性、神经心理学和生物学*。APA，华盛顿D.C。[https://doi.org/10.1037/13620-004](https://doi.org/10.1037/13620-004)
- en: 'Cai et al. (2024) Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang,
    Tao Ge, Chenfei Wu, You Wang, Ting Song, Yan Xia, Nan Duan, and Furu Wei. 2024.
    Low-code LLM: Graphical user interface over large language models. In *Proceedings
    of the 2024 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies (Volume 3: System Demonstrations)*. 12–25.
    [https://aclanthology.org/2024.naacl-demo.2](https://aclanthology.org/2024.naacl-demo.2)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai 等（2024）Yuzhe Cai、Shaoguang Mao、Wenshan Wu、Zehua Wang、Yaobo Liang、Tao Ge、Chenfei
    Wu、You Wang、Ting Song、Yan Xia、Nan Duan 和 Furu Wei。2024年。低代码 LLM：在大型语言模型上的图形用户界面。发表于
    *2024年北美计算语言学协会会议：人类语言技术（第3卷：系统演示）*。12–25。[https://aclanthology.org/2024.naacl-demo.2](https://aclanthology.org/2024.naacl-demo.2)
- en: 'Cao et al. (2023) Yining Cao, Jane L. E, Chen Zhu-Tian, and Haijun Xia. 2023.
    DataParticles: Block-based and language-oriented authoring of animated unit visualizations.
    In *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*.
    ACM, New York, NY, Article 808, 15 pages. [https://doi.org/10.1145/3544548.3581472](https://doi.org/10.1145/3544548.3581472)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等（2023）Yining Cao、Jane L. E、Chen Zhu-Tian 和 Haijun Xia。2023年。DataParticles：基于区块和面向语言的动画单元可视化创作。发表于
    *ACM计算机系统人因学会议（CHI）*。ACM，纽约，NY，文章808，15页。[https://doi.org/10.1145/3544548.3581472](https://doi.org/10.1145/3544548.3581472)
- en: 'Chen et al. (2024b) Nan Chen, Yuge Zhang, Jiahang Xu, Kan Ren, and Yuqing Yang.
    2024b. VisEval: A benchmark for data visualization in the era of large language
    models. arXiv:2407.00981'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2024b）Nan Chen、Yuge Zhang、Jiahang Xu、Kan Ren 和 Yuqing Yang。2024b年。VisEval：大语言模型时代的数据可视化基准。arXiv:2407.00981
- en: Chen et al. (2024a) Yida Chen, Aoyu Wu, Catherine Yeh Trevor DePodesta, Kenneth
    Li, Nicholas Castillo Marin, Oam Patel, Jan Riecke, Shivam Raval, Olivia Seow,
    Martin Wattenberg, and Fernanda Viégas. 2024a. Designing a dashboard for transparency
    and control of conversational AI. arXiv:2406.07882
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2024a）Yida Chen、Aoyu Wu、Catherine Yeh Trevor DePodesta、Kenneth Li、Nicholas
    Castillo Marin、Oam Patel、Jan Riecke、Shivam Raval、Olivia Seow、Martin Wattenberg
    和 Fernanda Viégas。2024a年。设计一个用于透明性和控制对话式AI的仪表盘。arXiv:2406.07882
- en: 'Cheng et al. (2023) Liying Cheng, Xingxuan Li, and Lidong Bing. 2023. Is GPT-4
    a good data analyst?. In *Findings of the Association for Computational Linguistics:
    EMNLP*. ACL, 9496–9514. [https://doi.org/10.18653/v1/2023.findings-emnlp.637](https://doi.org/10.18653/v1/2023.findings-emnlp.637)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等（2023）李颖 Cheng、李星轩 Li 和 Bing Lidong。2023年。GPT-4 是一个优秀的数据分析师吗？发表于 *计算语言学协会会议成果：EMNLP*。ACL，9496–9514。[https://doi.org/10.18653/v1/2023.findings-emnlp.637](https://doi.org/10.18653/v1/2023.findings-emnlp.637)
- en: 'Chopra et al. (2023) Bhavya Chopra, Ananya Singha, Anna Fariha, Sumit Gulwani,
    Chris Parnin, Ashish Tiwari, and Austin Z Henley. 2023. Conversational challenges
    in AI-powered data science: Obstacles, needs, and design opportunities. arXiv:2310.16164'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chopra 等（2023）Bhavya Chopra、Ananya Singha、Anna Fariha、Sumit Gulwani、Chris Parnin、Ashish
    Tiwari 和 Austin Z Henley。2023年。AI驱动的数据科学中的对话挑战：障碍、需求与设计机会。arXiv:2310.16164
- en: 'Chung et al. (2022) John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran
    Lee, Eytan Adar, and Minsuk Chang. 2022. TaleBrush: Sketching stories with generative
    pretrained language models. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, Article 209, 19 pages. [https://doi.org/10.1145/3491102.3501819](https://doi.org/10.1145/3491102.3501819)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung等人（2022）John Joon Young Chung、Wooseok Kim、Kang Min Yoo、Hwaran Lee、Eytan
    Adar和Minsuk Chang。2022年。《TaleBrush：使用生成预训练语言模型绘制故事》。发表于*ACM人机交互会议论文集（CHI）*。ACM，纽约，NY，文章209，19页。[https://doi.org/10.1145/3491102.3501819](https://doi.org/10.1145/3491102.3501819)
- en: Dell et al. (2012) Nicola Dell, Vidya Vaidyanathan, Indrani Medhi, Edward Cutrell,
    and William Thies. 2012. “Yours is better!” Participant response bias in HCI.
    In *Proceedings of the sigchi conference on human factors in computing systems*.
    ACM, New York, NY, 1321–1330. [https://doi.org/10.1145/2207676.2208589](https://doi.org/10.1145/2207676.2208589)
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dell等人（2012）Nicola Dell、Vidya Vaidyanathan、Indrani Medhi、Edward Cutrell和William
    Thies。2012年。“你的更好！”人机交互中的参与者响应偏差。发表于*SIGCHI人机交互会议论文集*。ACM，纽约，NY，1321–1330。[https://doi.org/10.1145/2207676.2208589](https://doi.org/10.1145/2207676.2208589)
- en: 'Dibia (2023) Victor Dibia. 2023. LIDA: A tool for automatic generation of grammar-agnostic
    visualizations and infographics using large language models. In *Proceedings of
    the Annual Meeting of the Association for Computational Linguistics (Volume 3:
    System Demonstrations)*. ACL, Toronto, Canada, 113–126. [https://doi.org/10.18653/v1/2023.acl-demo.11](https://doi.org/10.18653/v1/2023.acl-demo.11)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dibia（2023）Victor Dibia。2023年。《LIDA：一种利用大型语言模型自动生成语法无关可视化和信息图表的工具》。发表于*计算语言学会年会论文集（第3卷：系统演示）*。ACL，多伦多，加拿大，113–126。[https://doi.org/10.18653/v1/2023.acl-demo.11](https://doi.org/10.18653/v1/2023.acl-demo.11)
- en: 'Ding et al. (2019) Rui Ding, Shi Han, Yong Xu, Haidong Zhang, and Dongmei Zhang.
    2019. QuickInsights: Quick and automatic discovery of insights from multi-dimensional
    data. In *Proceedings of the International Conference on Management of Data (SIGMOD)*.
    ACM, New York, NY, 317–332. [https://doi.org/10.1145/3299869.3314037](https://doi.org/10.1145/3299869.3314037)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding等人（2019）Rui Ding、Shi Han、Yong Xu、Haidong Zhang和Dongmei Zhang。2019年。《QuickInsights：从多维数据中快速且自动发现洞察》。发表于*国际数据管理会议论文集（SIGMOD）*。ACM，纽约，NY，317–332。[https://doi.org/10.1145/3299869.3314037](https://doi.org/10.1145/3299869.3314037)
- en: 'Feng et al. (2024) Yingchaojie Feng, Xingbo Wang, Bo Pan, Kam Kwai Wong, Yi
    Ren, Shi Liu, Zihan Yan, Yuxin Ma, Huamin Qu, and Wei Chen. 2024. XNLI: Explaining
    and diagnosing NLI-based visual data analysis. *IEEE Trans. Vis. Comput. Graph.*
    30, 7 (2024), 3813–3827. [https://doi.org/10.1109/TVCG.2023.3240003](https://doi.org/10.1109/TVCG.2023.3240003)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng等人（2024）Yingchaojie Feng、Xingbo Wang、Bo Pan、Kam Kwai Wong、Yi Ren、Shi Liu、Zihan
    Yan、Yuxin Ma、Huamin Qu和Wei Chen。2024年。《XNLI：基于NLI的可视化数据分析的解释与诊断》。*IEEE计算机图形与视觉学报*
    30, 7（2024），3813–3827。[https://doi.org/10.1109/TVCG.2023.3240003](https://doi.org/10.1109/TVCG.2023.3240003)
- en: 'Ferdowsi et al. (2023) Kasra Ferdowsi, Jack Williams, Ian Drosos, Andrew D
    Gordon, Carina Negreanu, Nadia Polikarpova, Advait Sarkar, and Benjamin Zorn.
    2023. ColDeco: An end user spreadsheet inspection tool for AI-generated code.
    In *Proceedings of the IEEE Symposium on Visual Languages and Human-Centric Computing
    (VL/HCC)*. IEEE, Piscataway, NJ, 82–91. [https://doi.org/10.1109/VL-HCC57772.2023.00017](https://doi.org/10.1109/VL-HCC57772.2023.00017)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferdowsi等人（2023）Kasra Ferdowsi、Jack Williams、Ian Drosos、Andrew D Gordon、Carina
    Negreanu、Nadia Polikarpova、Advait Sarkar和Benjamin Zorn。2023年。《ColDeco：用于AI生成代码的终端用户电子表格检查工具》。发表于*IEEE视觉语言与人机交互计算研讨会论文集（VL/HCC）*。IEEE，Piscataway，NJ，82–91。[https://doi.org/10.1109/VL-HCC57772.2023.00017](https://doi.org/10.1109/VL-HCC57772.2023.00017)
- en: Gadhave et al. (2022) Kiran Gadhave, Zach Cutler, and Alexander Lex. 2022. Reusing
    interactive analysis workflows. *Comput. Graphics Forum* 41, 3 (2022), 133–144.
    [https://doi.org/10.1111/cgf.14528](https://doi.org/10.1111/cgf.14528)
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gadhave等人（2022）Kiran Gadhave、Zach Cutler和Alexander Lex。2022年。《重复使用互动分析工作流》。*计算机图形学论坛*
    41, 3（2022），133–144。[https://doi.org/10.1111/cgf.14528](https://doi.org/10.1111/cgf.14528)
- en: 'Google (2024) Google. 2024. *Gemini Advanced: Release updates*. Google. Retrieved
    June 1, 2024 from [https://gemini.google.com/updates](https://gemini.google.com/updates)
    2024.05.21: updates on data analysis features.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google（2024）Google。2024年。《Gemini Advanced：发布更新》。Google。2024年6月1日访问自[https://gemini.google.com/updates](https://gemini.google.com/updates)
    2024.05.21：数据分析功能的更新。
- en: Gu et al. (2024b) Ken Gu, Madeleine Grunde-McLaughlin, Andrew M. McNutt, Jeffrey
    Heer, and Tim Althoff. 2024b. How do data analysts respond to AI assistance? A
    wizard-of-oz study. In *Proceedings of the ACM Conference on Human Factors in
    Computing Systems (CHI)*. ACM, New York, NY, Article 1015, 22 pages. [https://doi.org/10.1145/3613904.3641891](https://doi.org/10.1145/3613904.3641891)
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等人（2024b）Ken Gu、Madeleine Grunde-McLaughlin、Andrew M. McNutt、Jeffrey Heer
    和 Tim Althoff. 2024b. 数据分析师如何响应 AI 辅助？一项奥兹巫师研究. 收录于 *ACM 人机交互会议论文集（CHI）*，ACM，纽约，NY，第
    1015 号文章，22 页. [https://doi.org/10.1145/3613904.3641891](https://doi.org/10.1145/3613904.3641891)
- en: Gu et al. (2024c) Ken Gu, Ruoxi Shang, Tim Althoff, Chenglong Wang, and Steven M
    Drucker. 2024c. How do analysts understand and verify AI-assisted data analyses?.
    In *Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI)*.
    ACM, New York, NY, Article 748, 22 pages. [https://doi.org/10.1145/3613904.3642497](https://doi.org/10.1145/3613904.3642497)
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等人（2024c）Ken Gu、Ruoxi Shang、Tim Althoff、Chenglong Wang 和 Steven M Drucker.
    2024c. 分析师如何理解和验证 AI 辅助的数据分析？. 收录于 *ACM 人机交互会议论文集（CHI）*，ACM，纽约，NY，第 748 号文章，22
    页. [https://doi.org/10.1145/3613904.3642497](https://doi.org/10.1145/3613904.3642497)
- en: Gu et al. (2024a) Ziwei Gu, Ian Arawjo, Kenneth Li, Jonathan K Kummerfeld, and
    Elena L Glassman. 2024a. An AI-resilient text rendering technique for reading
    and skimming documents. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, Article 898, 22 pages. [https://doi.org/10.1145/3613904.3642699](https://doi.org/10.1145/3613904.3642699)
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu 等人（2024a）Ziwei Gu、Ian Arawjo、Kenneth Li、Jonathan K Kummerfeld 和 Elena L Glassman.
    2024a. 一种抗 AI 的文本渲染技术，用于阅读和浏览文档. 收录于 *ACM 人机交互会议论文集（CHI）*，ACM，纽约，NY，第 898 号文章，22
    页. [https://doi.org/10.1145/3613904.3642699](https://doi.org/10.1145/3613904.3642699)
- en: 'Guo et al. (2023) Yi Guo, Nan Cao, Xiaoyu Qi, Haoyang Li, Danqing Shi, Jing
    Zhang, Qing Chen, and Daniel Weiskopf. 2023. Urania: Visualizing data analysis
    pipelines for natural language-based data exploration. arXiv:2306.07760'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人（2023）Yi Guo、Nan Cao、Xiaoyu Qi、Haoyang Li、Danqing Shi、Jing Zhang、Qing
    Chen 和 Daniel Weiskopf. 2023. Urania：基于自然语言的数据探索的可视化数据分析管道. arXiv:2306.07760
- en: 'Hart and Staveland (1988) Sandra G Hart and Lowell E Staveland. 1988. Development
    of NASA-TLX (Task Load Index): Results of empirical and theoretical research.
    In *Advances in psychology*. Vol. 52\. Elsevier, 139–183. [https://doi.org/10.1016/S0166-4115(08)62386-9](https://doi.org/10.1016/S0166-4115(08)62386-9)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hart 和 Staveland（1988）Sandra G Hart 和 Lowell E Staveland. 1988. NASA-TLX（任务负载指数）的开发：经验和理论研究结果.
    收录于 *心理学进展*，第 52 卷，Elsevier，139–183 页. [https://doi.org/10.1016/S0166-4115(08)62386-9](https://doi.org/10.1016/S0166-4115(08)62386-9)
- en: 'He et al. (2024) Xinyi He, Mengyu Zhou, Xinrun Xu, Xiaojun Ma, Rui Ding, Lun
    Du, Yan Gao, Ran Jia, Xu Chen, Shi Han, Zejian Yuan, and Dongmei Zhang. 2024.
    Text2Analysis: A benchmark of table question answering with advanced data analysis
    and unclear queries. *Proceedings of the Annual AAAI Conference on Artificial
    Intelligence (AAAI)* 38, 16 (2024), 18206–18215. [https://doi.org/10.1609/aaai.v38i16.29779](https://doi.org/10.1609/aaai.v38i16.29779)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等人（2024）Xinyi He、Mengyu Zhou、Xinrun Xu、Xiaojun Ma、Rui Ding、Lun Du、Yan Gao、Ran
    Jia、Xu Chen、Shi Han、Zejian Yuan 和 Dongmei Zhang. 2024. Text2Analysis：一个关于表格问答的基准，涉及先进的数据分析和模糊查询.
    *美国人工智能协会年会论文集（AAAI）* 38，16（2024），18206–18215 页. [https://doi.org/10.1609/aaai.v38i16.29779](https://doi.org/10.1609/aaai.v38i16.29779)
- en: 'Huang et al. (2024) Yanwei Huang, Yurun Yang, Xinhuan Shu, Ran Chen, Di Weng,
    and Yingcai Wu. 2024. Table Illustrator: Puzzle-based interactive authoring of
    plain tables. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 186, 18 pages. [https://doi.org/10.1145/3613904.3642415](https://doi.org/10.1145/3613904.3642415)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2024）Yanwei Huang、Yurun Yang、Xinhuan Shu、Ran Chen、Di Weng 和 Yingcai
    Wu. 2024. 表格插画师：基于拼图的交互式平面表格创作. 收录于 *ACM 人机交互会议论文集（CHI）*，ACM，纽约，NY，第 186 号文章，18
    页. [https://doi.org/10.1145/3613904.3642415](https://doi.org/10.1145/3613904.3642415)
- en: Huang et al. (2023) Yanwei Huang, Yunfan Zhou, Ran Chen, Changhao Pan, Xinhuan
    Shu, Di Weng, and Yingcai Wu. 2023. Interactive table synthesis with natural language.
    *IEEE Trans. Vis. Comput. Graph.* (2023). [https://doi.org/10.1109/TVCG.2023.3329120](https://doi.org/10.1109/TVCG.2023.3329120)
    Early Access.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2023）Yanwei Huang、Yunfan Zhou、Ran Chen、Changhao Pan、Xinhuan Shu、Di
    Weng 和 Yingcai Wu. 2023. 基于自然语言的交互式表格合成. *IEEE Trans. Vis. Comput. Graph.*（2023）。
    [https://doi.org/10.1109/TVCG.2023.3329120](https://doi.org/10.1109/TVCG.2023.3329120)
    提前访问。
- en: 'Jiang et al. (2023) Peiling Jiang, Jude Rayan, Steven P Dow, and Haijun Xia.
    2023. Graphologue: Exploring large language model responses with interactive diagrams.
    In *Proceedings of the Symposium on User Interface Software and Technology (UIST)*.
    ACM, New York, NY, Article 3, 20 pages. [https://doi.org/10.1145/3586183.3606737](https://doi.org/10.1145/3586183.3606737)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang等人（2023）Peiling Jiang, Jude Rayan, Steven P Dow, 和Haijun Xia。2023年。Graphologue：通过互动图表探索大型语言模型的回应。在*用户界面软件与技术研讨会（UIST）*会议录。ACM,
    纽约, NY, 第3篇，20页。 [https://doi.org/10.1145/3586183.3606737](https://doi.org/10.1145/3586183.3606737)
- en: 'Kandel et al. (2011) Sean Kandel, Andreas Paepcke, Joseph Hellerstein, and
    Jeffrey Heer. 2011. Wrangler: Interactive visual specification of data transformation
    scripts. In *Proceedings of the ACM Conference on Human Factors in Computing Systems
    (CHI)*. ACM, New York, NY, 3363–3372. [https://doi.org/10.1145/1978942.1979444](https://doi.org/10.1145/1978942.1979444)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kandel等人（2011）Sean Kandel, Andreas Paepcke, Joseph Hellerstein, 和Jeffrey Heer。2011年。Wrangler：数据转换脚本的互动可视化规范。在*计算机系统人因学会议（CHI）*的会议录。ACM,
    纽约, NY, 3363-3372。 [https://doi.org/10.1145/1978942.1979444](https://doi.org/10.1145/1978942.1979444)
- en: Kazemitabaar et al. (2024) Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi
    Grossman, Austin Henley, Carina Negreanu, and Advait Sarkar. 2024. Improving steering
    and verification in AI-assisted data analysis with interactive task decomposition.
    arXiv:2407.02651
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kazemitabaar等人（2024）Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman,
    Austin Henley, Carina Negreanu, 和Advait Sarkar。2024年。通过互动任务分解改进AI辅助数据分析中的引导和验证。arXiv:2407.02651
- en: 'Khan et al. (2017) Meraj Khan, Larry Xu, Arnab Nandi, and Joseph M Hellerstein.
    2017. Data tweening: Incremental visualization of data transforms. *Proceedings
    of the VLDB Endowment* 10, 6 (2017), 661–672. [https://doi.org/10.14778/3055330.3055333](https://doi.org/10.14778/3055330.3055333)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan等人（2017）Meraj Khan, Larry Xu, Arnab Nandi, 和Joseph M Hellerstein。2017年。数据过渡：数据转换的增量可视化。*VLDB基金会会议录*
    10, 6 (2017)，661-672。 [https://doi.org/10.14778/3055330.3055333](https://doi.org/10.14778/3055330.3055333)
- en: 'Ko and Myers (2004) Amy J Ko and Brad A Myers. 2004. Designing the Whyline:
    A debugging interface for asking questions about program behavior. In *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York,
    NY, 151–158. [https://doi.org/10.1145/985692.985712](https://doi.org/10.1145/985692.985712)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ko和Myers（2004）Amy J Ko 和 Brad A Myers。2004年。设计Whyline：一种用于询问程序行为的调试界面。在*计算机系统人因学会议（CHI）*的会议录。ACM,
    纽约, NY, 151-158。 [https://doi.org/10.1145/985692.985712](https://doi.org/10.1145/985692.985712)
- en: 'Lau et al. (2023) Sam Lau, Sean Kross, Eugene Wu, and Philip J Guo. 2023. Teaching
    data science by visualizing data table transformations: Pandas Tutor for Python,
    Tidy Data Tutor for R, and SQL Tutor. In *Proceedings of the International Workshop
    on Data Systems Education: Bridging Education Practice with Education Research*.
    ACM, New York, NY, 50–55. [https://doi.org/10.1145/3596673.3596972](https://doi.org/10.1145/3596673.3596972)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lau等人（2023）Sam Lau, Sean Kross, Eugene Wu, 和Philip J Guo。2023年。通过可视化数据表转换教授数据科学：Python的Pandas
    Tutor，R的Tidy Data Tutor，以及SQL Tutor。在*国际数据系统教育研讨会：将教育实践与教育研究相结合*会议录。ACM, 纽约, NY,
    50-55。 [https://doi.org/10.1145/3596673.3596972](https://doi.org/10.1145/3596673.3596972)
- en: 'Li et al. (2024) Boyan Li, Yuyu Luo, Chengliang Chai, Guoliang Li, and Nan
    Tang. 2024. The dawn of natural language to SQL: Are we fully ready? arXiv:2406.01265'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人（2024）Boyan Li, Yuyu Luo, Chengliang Chai, Guoliang Li, 和Nan Tang。2024年。自然语言到SQL的曙光：我们完全准备好了吗？arXiv:2406.01265
- en: 'Liu et al. (2023a) Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Ben
    Zorn, Jack Williams, Neil Toronto, and Andy Gordon. 2023a. “What it wants me to
    say”: Bridging the abstraction gap between end-user programmers and code-generating
    large language models. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, 31 pages. [https://doi.org/10.1145/3544548.3580817](https://doi.org/10.1145/3544548.3580817)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023a）Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Ben Zorn, Jack
    Williams, Neil Toronto, 和Andy Gordon。2023a年。“它希望我说什么”：弥合最终用户程序员与代码生成大型语言模型之间的抽象差距。在*计算机系统人因学会议（CHI）*的会议录。ACM,
    纽约, NY, 31页。 [https://doi.org/10.1145/3544548.3580817](https://doi.org/10.1145/3544548.3580817)
- en: 'Liu et al. (2024) Shusen Liu, Haichao Miao, Zhimin Li, Matthew Olson, Valerio
    Pascucci, and Peer-Timo Bremer. 2024. AVA: Towards autonomous visualization agents
    through visual perception-driven decision-making. *Comput. Graphics Forum* 43,
    3, Article e15093 (2024), 12 pages. [https://doi.org/10.1111/cgf.15093](https://doi.org/10.1111/cgf.15093)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2024）Shusen Liu、Haichao Miao、Zhimin Li、Matthew Olson、Valerio Pascucci
    和 Peer-Timo Bremer。2024年。AVA：通过视觉感知驱动的决策制定迈向自主可视化代理。*计算机图形学论坛* 43, 3, 文章e15093（2024），12页。[https://doi.org/10.1111/cgf.15093](https://doi.org/10.1111/cgf.15093)
- en: 'Liu et al. (2023b) Shang-Ching Liu, ShengKun Wang, Tsungyao Chang, Wenqi Lin,
    Chung-Wei Hsiung, Yi-Chen Hsieh, Yu-Ping Cheng, Sian-Hong Luo, and Jianwei Zhang.
    2023b. JarviX: A LLM no code platform for tabular data analysis and optimization.
    In *Proceedings of the Conference on Empirical Methods in Natural Language Processing:
    Industry Track*. ACL, 622–630. [https://doi.org/10.18653/v1/2023.emnlp-industry.59](https://doi.org/10.18653/v1/2023.emnlp-industry.59)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023b）Shang-Ching Liu、ShengKun Wang、Tsungyao Chang、Wenqi Lin、Chung-Wei
    Hsiung、Yi-Chen Hsieh、Yu-Ping Cheng、Sian-Hong Luo 和 Jianwei Zhang。2023b年。JarviX：一个用于表格数据分析和优化的LLM无代码平台。收录于
    *自然语言处理实证方法会议：工业轨道论文集*。ACL，622–630。[https://doi.org/10.18653/v1/2023.emnlp-industry.59](https://doi.org/10.18653/v1/2023.emnlp-industry.59)
- en: 'Lucchesi et al. (2022) Lydia R Lucchesi, Petra M Kuhnert, Jenny L Davis, and
    Lexing Xie. 2022. Smallset Timelines: A visual representation of data preprocessing
    decisions. In *Proceedings of the ACM Conference on Fairness, Accountability,
    and Transparency (FAccT)*. ACM, New York, NY, 1136–1153. [https://doi.org/10.1145/3531146.3533175](https://doi.org/10.1145/3531146.3533175)'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lucchesi 等人（2022）Lydia R Lucchesi、Petra M Kuhnert、Jenny L Davis 和 Lexing Xie。2022年。Smallset
    Timelines：数据预处理决策的可视化表示。收录于 *ACM公平性、问责制与透明度会议（FAccT）*。ACM，纽约，NY，1136–1153。[https://doi.org/10.1145/3531146.3533175](https://doi.org/10.1145/3531146.3533175)
- en: 'Masson et al. (2024) Damien Masson, Sylvain Malacria, Géry Casiez, and Daniel
    Vogel. 2024. DirectGPT: A direct manipulation interface to interact with large
    language models. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 975, 16 pages. [https://doi.org/10.1145/3613904.3642462](https://doi.org/10.1145/3613904.3642462)'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Masson 等人（2024）Damien Masson、Sylvain Malacria、Géry Casiez 和 Daniel Vogel。2024年。DirectGPT：与大型语言模型互动的直接操作界面。收录于
    *ACM人机交互系统会议论文集（CHI）*。ACM，纽约，NY，文章975，16页。[https://doi.org/10.1145/3613904.3642462](https://doi.org/10.1145/3613904.3642462)
- en: Mcnutt et al. (2023) Andrew M Mcnutt, Chenglong Wang, Robert A Deline, and Steven M.
    Drucker. 2023. On the design of AI-powered code assistants for notebooks. In *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York,
    NY, Article 434, 16 pages. [https://doi.org/10.1145/3544548.3580940](https://doi.org/10.1145/3544548.3580940)
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mcnutt 等人（2023）Andrew M Mcnutt、Chenglong Wang、Robert A Deline 和 Steven M. Drucker。2023年。关于为笔记本设计AI驱动的代码助手。收录于
    *ACM人机交互系统会议论文集（CHI）*。ACM，纽约，NY，文章434，16页。[https://doi.org/10.1145/3544548.3580940](https://doi.org/10.1145/3544548.3580940)
- en: Mehrpour and Latoza (2023) Sahar Mehrpour and Thomas D. Latoza. 2023. A survey
    of tool support for working with design decisions in code. *Comput. Surveys* 56,
    2, Article 37 (2023), 37 pages. [https://doi.org/10.1145/3607868](https://doi.org/10.1145/3607868)
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehrpour 和 Latoza（2023）Sahar Mehrpour 和 Thomas D. Latoza。2023年。关于代码设计决策工具支持的调查。*计算机调查*
    56, 2, 文章37（2023），37页。[https://doi.org/10.1145/3607868](https://doi.org/10.1145/3607868)
- en: Meta Open Source (2024) Meta Open Source. 2024. *React*. [https://react.dev/](https://react.dev/)
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meta Open Source（2024）Meta Open Source。2024年。*React*。[https://react.dev/](https://react.dev/)
- en: Microsoft (2024) Microsoft. 2024. *Monaco Editor*. [https://microsoft.github.io/monaco-editor/](https://microsoft.github.io/monaco-editor/)
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft（2024）Microsoft。2024年。*Monaco Editor*。[https://microsoft.github.io/monaco-editor/](https://microsoft.github.io/monaco-editor/)
- en: Myers (1990) Brad A Myers. 1990. Taxonomies of visual programming and program
    visualization. *Journal of Visual Languages & Computing* 1, 1 (1990), 97–123.
    [https://doi.org/10.1016/S1045-926X(05)80036-9](https://doi.org/10.1016/S1045-926X(05)80036-9)
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myers（1990）Brad A Myers。1990年。视觉编程与程序可视化的分类法。*视觉语言与计算杂志* 1, 1（1990），97–123。[https://doi.org/10.1016/S1045-926X(05)80036-9](https://doi.org/10.1016/S1045-926X(05)80036-9)
- en: Nam et al. (2024) Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu,
    and Brad Myers. 2024. Using an LLM to help with code understanding. In *Proceedings
    of the ACM International Conference on Software Engineering (ICSE)*. IEEE, Article
    97, 13 pages. [https://doi.org/10.1145/3597503.3639187](https://doi.org/10.1145/3597503.3639187)
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nam 等人（2024）Daye Nam、Andrew Macvean、Vincent Hellendoorn、Bogdan Vasilescu 和 Brad
    Myers。2024年。使用大语言模型（LLM）帮助代码理解。载于 *ACM 国际软件工程会议录（ICSE）*。IEEE，文章97，13页。[https://doi.org/10.1145/3597503.3639187](https://doi.org/10.1145/3597503.3639187)
- en: 'Narechania et al. (2021) Arpit Narechania, Adam Fourney, Bongshin Lee, and
    Gonzalo Ramos. 2021. DIY: Assessing the correctness of natural language to SQL
    systems. In *Proceedings of the International Conference on Intelligent User Interfaces
    (IUI)*. ACM, New York, NY, 597–607. [https://doi.org/10.1145/3397481.3450667](https://doi.org/10.1145/3397481.3450667)'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Narechania 等人（2021）Arpit Narechania、Adam Fourney、Bongshin Lee 和 Gonzalo Ramos。2021年。DIY：评估自然语言到
    SQL 系统的正确性。载于 *国际智能用户界面会议录（IUI）*。ACM，纽约，NY，597–607. [https://doi.org/10.1145/3397481.3450667](https://doi.org/10.1145/3397481.3450667)
- en: 'Niederer et al. (2017) Christina Niederer, Holger Stitz, Reem Hourieh, Florian
    Grassinger, Wolfgang Aigner, and Marc Streit. 2017. TACO: Visualizing changes
    in tables over time. *IEEE Trans. Vis. Comput. Graph.* 24, 1 (2017), 677–686.
    [https://doi.org/10.1109/TVCG.2017.2745298](https://doi.org/10.1109/TVCG.2017.2745298)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Niederer 等人（2017）Christina Niederer、Holger Stitz、Reem Hourieh、Florian Grassinger、Wolfgang
    Aigner 和 Marc Streit。2017年。TACO：可视化表格随时间的变化。*IEEE 视觉计算与图形学会会刊* 24, 1 (2017), 677–686.
    [https://doi.org/10.1109/TVCG.2017.2745298](https://doi.org/10.1109/TVCG.2017.2745298)
- en: Olausson et al. (2024) Theo X Olausson, Jeevana Priya Inala, Chenglong Wang,
    Jianfeng Gao, and Armando Solar-Lezama. 2024. Is self-repair a silver bullet for
    code generation?. In *Proceedings of the International Conference on Learning
    Representations (ICLR)*. 49 pages. arXiv:2306.09896 Poster.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olausson 等人（2024）Theo X Olausson、Jeevana Priya Inala、Chenglong Wang、Jianfeng
    Gao 和 Armando Solar-Lezama。2024年。自我修复是代码生成的“银弹”吗？载于 *国际表示学习会议录（ICLR）*。49页。arXiv:2306.09896
    海报。
- en: OpenAI (2024) OpenAI. 2024. *Data analysis with ChatGPT*. OpenAI. Retrieved
    June 1, 2024 from [https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt](https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt)
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2024）OpenAI。2024年。*使用 ChatGPT 进行数据分析*。OpenAI。2024年6月1日检索自 [https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt](https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt)
- en: Pallets (2024) Pallets. 2024. *Flask*. [https://flask.palletsprojects.com/en/3.0.x/](https://flask.palletsprojects.com/en/3.0.x/)
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pallets（2024）Pallets。2024年。*Flask*。 [https://flask.palletsprojects.com/en/3.0.x/](https://flask.palletsprojects.com/en/3.0.x/)
- en: Podo et al. (2024) Luca Podo, Muhammad Ishmal, and Marco Angelini. 2024. Toward
    a structured theoretical framework for the evaluation of generative AI-based visualizations.
    In *Proceedings of the EuroVis Workshop on Visual Analytics (EuroVA)*. The Eurographics
    Association, 6 pages. [https://doi.org/10.2312/eurova.20241118](https://doi.org/10.2312/eurova.20241118)
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Podo 等人（2024）Luca Podo、Muhammad Ishmal 和 Marco Angelini。2024年。迈向一个结构化的理论框架，用于评估生成性人工智能可视化。载于
    *EuroVis 可视分析工作坊（EuroVA）*。Eurographics 协会，6页。[https://doi.org/10.2312/eurova.20241118](https://doi.org/10.2312/eurova.20241118)
- en: 'Pu et al. (2021) Xiaoying Pu, Sean Kross, Jake M. Hofman, and Daniel G. Goldstein.
    2021. Datamations: Animated explanations of data analysis pipelines. In *Proceedings
    of the ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York,
    NY, Article 467, 14 pages. [https://doi.org/10.1145/3411764.3445063](https://doi.org/10.1145/3411764.3445063)'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pu 等人（2021）Xiaoying Pu、Sean Kross、Jake M. Hofman 和 Daniel G. Goldstein。2021年。Datamations：数据分析管道的动画解释。载于
    *ACM 人机交互会议录（CHI）*。ACM，纽约，NY，文章467，14页。[https://doi.org/10.1145/3411764.3445063](https://doi.org/10.1145/3411764.3445063)
- en: 'Ramasamy et al. (2023) Dhivyabharathi Ramasamy, Cristina Sarasua, Alberto Bacchelli,
    and Abraham Bernstein. 2023. Visualising data science workflows to support third-party
    notebook comprehension: An empirical study. *Empirical Software Engineering* 28,
    3 (2023), 58. [https://doi.org/10.1007/s10664-023-10289-9](https://doi.org/10.1007/s10664-023-10289-9)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramasamy 等人（2023）Dhivyabharathi Ramasamy、Cristina Sarasua、Alberto Bacchelli
    和 Abraham Bernstein。2023年。通过可视化数据科学工作流支持第三方笔记本理解：一项实证研究。*实证软件工程* 28, 3 (2023),
    58. [https://doi.org/10.1007/s10664-023-10289-9](https://doi.org/10.1007/s10664-023-10289-9)
- en: 'Shen et al. (2024) Hua Shen, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan
    Krishna, Yachuan Liu, Ziqiao Ma, Savvas Petridis, Yi-Hao Peng, Li Qiwei, et al.
    2024. Towards bidirectional human-AI alignment: A systematic review for clarifications,
    framework, and future directions. arXiv:2406.09264'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人（2024）Hua Shen, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan Krishna,
    Yachuan Liu, Ziqiao Ma, Savvas Petridis, Yi-Hao Peng, Li Qiwei 等人. 2024. 面向双向人类-AI对齐：关于澄清、框架和未来方向的系统评审。arXiv:2406.09264
- en: 'Shen et al. (2022) Leixian Shen, Enya Shen, Yuyu Luo, Xiaocong Yang, Xuming
    Hu, Xiongshuai Zhang, Zhiwei Tai, and Jianmin Wang. 2022. Towards natural language
    interfaces for data visualization: A survey. *IEEE Trans. Vis. Comput. Graph.*
    29, 6 (2022), 3121–3144. [https://doi.org/10.1109/TVCG.2022.3148007](https://doi.org/10.1109/TVCG.2022.3148007)'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人（2022）Leixian Shen, Enya Shen, Yuyu Luo, Xiaocong Yang, Xuming Hu, Xiongshuai
    Zhang, Zhiwei Tai 和 Jianmin Wang. 2022. 面向数据可视化的自然语言接口：一项调查。*IEEE Trans. Vis.
    Comput. Graph.* 29, 6 (2022), 3121–3144. [https://doi.org/10.1109/TVCG.2022.3148007](https://doi.org/10.1109/TVCG.2022.3148007)
- en: Showkat and Baumer (2021) Dilruba Showkat and Eric P. S. Baumer. 2021. Where
    do stories come from? Examining the exploration process in investigative data
    journalism. *Proc. ACM Hum.-Comput. Interact.* 5, CSCW2, Article 390 (2021), 31 pages.
    [https://doi.org/10.1145/3479534](https://doi.org/10.1145/3479534)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Showkat 和 Baumer（2021）Dilruba Showkat 和 Eric P. S. Baumer. 2021. 故事从何而来？调查性数据新闻中的探索过程研究。*Proc.
    ACM Hum.-Comput. Interact.* 5, CSCW2，第390篇（2021），31页。 [https://doi.org/10.1145/3479534](https://doi.org/10.1145/3479534)
- en: 'Shrestha et al. (2021) Nischal Shrestha, Titus Barik, and Chris Parnin. 2021.
    Unravel: A fluent code explorer for data wrangling. In *Proceedings of the Symposium
    on User Interface Software and Technology (UIST)*. ACM, New York, NY, 198–207.
    [https://doi.org/10.1145/3472749.3474744](https://doi.org/10.1145/3472749.3474744)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shrestha 等人（2021）Nischal Shrestha, Titus Barik 和 Chris Parnin. 2021. Unravel：一个用于数据整理的流畅代码探索器。在*用户界面软件与技术研讨会（UIST）论文集*中。ACM，纽约，NY，198–207。
    [https://doi.org/10.1145/3472749.3474744](https://doi.org/10.1145/3472749.3474744)
- en: 'Shrestha et al. (2023) Nischal Shrestha, Bhavya Chopra, Austin Z Henley, and
    Chris Parnin. 2023. Detangler: Helping data scientists explore, understand, and
    debug data wrangling pipelines. In *Proceedings of the IEEE Symposium on Visual
    Languages and Human-Centric Computing (VL/HCC)*. IEEE, Piscataway, NJ, 189–198.
    [https://doi.org/10.1109/VL-HCC57772.2023.00031](https://doi.org/10.1109/VL-HCC57772.2023.00031)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shrestha 等人（2023）Nischal Shrestha, Bhavya Chopra, Austin Z Henley 和 Chris Parnin.
    2023. Detangler：帮助数据科学家探索、理解和调试数据整理管道。在*IEEE视觉语言与人本计算研讨会（VL/HCC）论文集*中。IEEE，Piscataway，NJ，189–198。
    [https://doi.org/10.1109/VL-HCC57772.2023.00031](https://doi.org/10.1109/VL-HCC57772.2023.00031)
- en: 'Subramonyam et al. (2024) Hariharan Subramonyam, Roy Pea, Christopher Lawrence
    Pondoc, Maneesh Agrawala, and Colleen Seifert. 2024. Bridging the gulf of envisioning:
    Cognitive design challenges in LLM interfaces. In *Proceedings of the ACM Conference
    on Human Factors in Computing Systems (CHI)*. ACM, New York, NY, Article 1039,
    19 pages. [https://doi.org/10.1145/3613904.3642754](https://doi.org/10.1145/3613904.3642754)'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Subramonyam 等人（2024）Hariharan Subramonyam, Roy Pea, Christopher Lawrence Pondoc,
    Maneesh Agrawala 和 Colleen Seifert. 2024. 弥合想象的鸿沟：LLM接口中的认知设计挑战。在*ACM计算机系统人因学会议（CHI）论文集*中。ACM，纽约，NY，第1039篇，19页。
    [https://doi.org/10.1145/3613904.3642754](https://doi.org/10.1145/3613904.3642754)
- en: 'Suh et al. (2023) Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023.
    Sensecape: Enabling multilevel exploration and sensemaking with large language
    models. In *Proceedings of the Symposium on User Interface Software and Technology
    (UIST)*. ACM, New York, NY, Article 1, 18 pages. [https://doi.org/10.1145/3586183.3606756](https://doi.org/10.1145/3586183.3606756)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Suh 等人（2023）Sangho Suh, Bryan Min, Srishti Palani 和 Haijun Xia. 2023. Sensecape：利用大语言模型进行多层次探索和认知建构。在*用户界面软件与技术研讨会（UIST）论文集*中。ACM，纽约，NY，第1篇，18页。
    [https://doi.org/10.1145/3586183.3606756](https://doi.org/10.1145/3586183.3606756)
- en: Tankelevitch et al. (2024) Lev Tankelevitch, Viktor Kewenig, Auste Simkute,
    Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. 2024. The
    metacognitive demands and opportunities of generative AI. In *Proceedings of the
    ACM Conference on Human Factors in Computing Systems (CHI)*. ACM, New York, NY,
    Article 680, 24 pages. [https://doi.org/10.1145/3613904.3642902](https://doi.org/10.1145/3613904.3642902)
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tankelevitch 等人（2024）Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth
    Scott, Advait Sarkar, Abigail Sellen 和 Sean Rintel. 2024. 生成性 AI 的元认知需求与机遇。在*ACM计算机系统人因学会议（CHI）论文集*中。ACM，纽约，NY，第680篇，24页。
    [https://doi.org/10.1145/3613904.3642902](https://doi.org/10.1145/3613904.3642902)
- en: 'Tian et al. (2024) Yuan Tian, Weiwei Cui, Dazhen Deng, Xinjing Yi, Yurun Yang,
    Haidong Zhang, and Yingcai Wu. 2024. ChartGPT: Leveraging LLMs to generate charts
    from abstract natural language. *IEEE Trans. Vis. Comput. Graph.* (2024). [https://doi.org/10.1109/TVCG.2024.3368621](https://doi.org/10.1109/TVCG.2024.3368621)
    Early Access.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tian 等人（2024）Yuan Tian、Weiwei Cui、Dazhen Deng、Xinjing Yi、Yurun Yang、Haidong
    Zhang 和 Yingcai Wu。2024年。ChartGPT：利用LLM从抽象自然语言中生成图表。*IEEE Trans. Vis. Comput.
    Graph.*（2024）。[https://doi.org/10.1109/TVCG.2024.3368621](https://doi.org/10.1109/TVCG.2024.3368621)
    早期访问。
- en: 'Vaithilingam et al. (2024) Priyan Vaithilingam, Elena L. Glassman, Jeevana Priya
    Inala, and Chenglong Wang. 2024. DynaVis: Dynamically synthesized UI widgets for
    visualization editing. In *Proceedings of the ACM Conference on Human Factors
    in Computing Systems (CHI)*. ACM, New York, NY, Article 985, 17 pages. [https://doi.org/10.1145/3613904.3642639](https://doi.org/10.1145/3613904.3642639)'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaithilingam 等人（2024）Priyan Vaithilingam、Elena L. Glassman、Jeevana Priya Inala
    和 Chenglong Wang。2024年。DynaVis：用于可视化编辑的动态合成UI小部件。在 *ACM计算机系统人因会议论文集（CHI）* 中。ACM，纽约，NY，文章985，17页。
    [https://doi.org/10.1145/3613904.3642639](https://doi.org/10.1145/3613904.3642639)
- en: 'Victor (2011) Bret Victor. 2011. *Up and down the ladder of abstraction: A
    systematic approach to interactive visualization*. Retrieved April 1, 2024 from
    [http://worrydream.com/LadderOfAbstraction/](http://worrydream.com/LadderOfAbstraction/)'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Victor（2011）Bret Victor。2011年。 *抽象阶梯上下：一种互动可视化的系统方法*。2024年4月1日从 [http://worrydream.com/LadderOfAbstraction/](http://worrydream.com/LadderOfAbstraction/)
    获取。
- en: 'Wang et al. (2022) April Yi Wang, Will Epperson, Robert A DeLine, and Steven M.
    Drucker. 2022. Diff in the loop: Supporting data comparison in exploratory data
    analysis. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 97, 10 pages. [https://doi.org/10.1145/3491102.3502123](https://doi.org/10.1145/3491102.3502123)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2022）April Yi Wang、Will Epperson、Robert A DeLine 和 Steven M. Drucker。2022年。Diff
    in the loop：支持探索性数据分析中的数据比较。在 *ACM计算机系统人因会议论文集（CHI）* 中。ACM，纽约，NY，文章97，10页。 [https://doi.org/10.1145/3491102.3502123](https://doi.org/10.1145/3491102.3502123)
- en: 'Wang et al. (2018) April Y Wang, Ryan Mitts, Philip J Guo, and Parmit K Chilana.
    2018. Mismatch of expectations: How modern learning resources fail conversational
    programmers. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 511, 13 pages. [https://doi.org/10.1145/3173574.3174085](https://doi.org/10.1145/3173574.3174085)'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2018）April Y Wang、Ryan Mitts、Philip J Guo 和 Parmit K Chilana。2018年。期望的错位：现代学习资源如何未能满足对话式程序员的需求。在
    *ACM计算机系统人因会议论文集（CHI）* 中。ACM，纽约，NY，文章511，13页。 [https://doi.org/10.1145/3173574.3174085](https://doi.org/10.1145/3173574.3174085)
- en: Wang et al. (2024a) Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu
    Li, Hao Peng, and Heng Ji. 2024a. Executable code actions elicit better LLM agents.
    In *Proceedings of the International Conference on Machine Learning (ICML)*. Article
    PMLR 235, 13 pages. arXiv:2402.01030
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2024a）Xingyao Wang、Yangyi Chen、Lifan Yuan、Yizhe Zhang、Yunzhu Li、Hao
    Peng 和 Heng Ji。2024a年。可执行代码操作引发更好的LLM代理。在 *国际机器学习会议论文集（ICML）* 中。文章PMLR 235，13页。arXiv:2402.01030
- en: 'Wang et al. (2024b) Yun Wang, Leixian Shen, Zhengxin You, Xinhuan Shu, Bongshin
    Lee, John Thompson, Haidong Zhang, and Dongmei Zhang. 2024b. WonderFlow: Narration-centric
    design of animated data videos. *IEEE Trans. Vis. Comput. Graph.* (2024), 17 pages.
    [https://doi.org/10.1109/TVCG.2024.3411575](https://doi.org/10.1109/TVCG.2024.3411575)
    Early Access.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2024b）Yun Wang、Leixian Shen、Zhengxin You、Xinhuan Shu、Bongshin Lee、John
    Thompson、Haidong Zhang 和 Dongmei Zhang。2024b年。WonderFlow：以叙事为中心的动画数据视频设计。*IEEE
    Trans. Vis. Comput. Graph.*（2024），17页。 [https://doi.org/10.1109/TVCG.2024.3411575](https://doi.org/10.1109/TVCG.2024.3411575)
    早期访问。
- en: 'Weng et al. (2024) Luoxuan Weng, Xingbo Wang, Junyu Lu, Yingchaojie Feng, Yihan
    Liu, and Wei Chen. 2024. InsightLens: Discovering and exploring insights from
    conversational contexts in large-language-model-powered data analysis. arXiv:2404.01644'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng 等人（2024）Luoxuan Weng、Xingbo Wang、Junyu Lu、Yingchaojie Feng、Yihan Liu 和
    Wei Chen。2024年。InsightLens：从大型语言模型驱动的数据分析中发现并探索对话上下文中的见解。arXiv:2404.01644
- en: 'Wu et al. (2022) Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI
    Chains: Transparent and controllable human-AI interaction by chaining large language
    model prompts. In *Proceedings of the ACM Conference on Human Factors in Computing
    Systems (CHI)*. ACM, New York, NY, Article 385, 22 pages. [https://doi.org/10.1145/3491102.3517582](https://doi.org/10.1145/3491102.3517582)'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2022）吴通爽、迈克尔·特里、凯莉·俊·蔡。2022年。AI Chains：通过链接大型语言模型提示实现透明且可控的人机交互。在 *ACM
    人机计算系统会议（CHI）论文集* 中。ACM，纽约，NY，文章 385，22 页。 [https://doi.org/10.1145/3491102.3517582](https://doi.org/10.1145/3491102.3517582)
- en: 'Wu et al. (2024) Yang Wu, Yao Wan, Hongyu Zhang, Yulei Sui, Wucai Wei, Wei
    Zhao, Guandong Xu, and Hai Jin. 2024. Automated data visualization from natural
    language via large language models: An exploratory study. *Proceedings of the
    ACM on Management of Data* 2, 3, Article 115 (2024), 28 pages. [https://doi.org/10.1145/3654992](https://doi.org/10.1145/3654992)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2024）吴杨、万尧、张洪宇、隋宇磊、魏武才、赵伟、徐冠东、金海。2024年。通过大型语言模型从自然语言自动化生成数据可视化：一项探索性研究。*ACM
    数据管理会议论文集* 2, 3，文章 115（2024），28 页。 [https://doi.org/10.1145/3654992](https://doi.org/10.1145/3654992)
- en: 'Xie et al. (2024) Liwenhan Xie, Xinhuan Shu, Jeon Cheol Su, Yun Wang, Siming
    Chen, and Huamin Qu. 2024. Creating emordle: Animating word cloud for emotion
    expression. *IEEE Trans. Vis. Comput. Graph.* 30, 8 (2024), 5198–5211. [https://doi.org/10.1109/TVCG.2023.3286392](https://doi.org/10.1109/TVCG.2023.3286392)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2024）李文汉、舒欣焕、全哲洙、王云、陈思铭、曲华敏。2024年。创建 Emordle：为情感表达动画化词云。*IEEE Trans.
    Vis. Comput. Graph.* 30, 8（2024），5198–5211。 [https://doi.org/10.1109/TVCG.2023.3286392](https://doi.org/10.1109/TVCG.2023.3286392)
- en: 'Xie et al. (2023) Liwenhan Xie, Zhaoyu Zhou, Kerun Yu, Yun Wang, Huamin Qu,
    and Siming Chen. 2023. Wakey-Wakey: Animate text by mimicking characters in a
    GIF. In *Proceedings of the Symposium on User Interface Software and Technology
    (UIST)*. ACM, New York, NY, Article 98, 14 pages. [https://doi.org/10.1145/3586183.3606813](https://doi.org/10.1145/3586183.3606813)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2023）李文汉、周兆宇、余可润、王云、曲华敏、陈思铭。2023年。Wakey-Wakey：通过模仿 GIF 中的字符动画化文本。在 *用户界面软件与技术研讨会（UIST）论文集*
    中。ACM，纽约，NY，文章 98，14 页。 [https://doi.org/10.1145/3586183.3606813](https://doi.org/10.1145/3586183.3606813)
- en: Xiong et al. (2022) Kai Xiong, Siwei Fu, Guoming Ding, Zhongsu Luo, Rong Yu,
    Wei Chen, Hujun Bao, and Yingcai Wu. 2022. Visualizing the scripts of data wrangling
    with SOMNUS. *IEEE Trans. Vis. Comput. Graph.* 29, 6 (2022), 2950–2964. [https://doi.org/10.1109/TVCG.2022.3144975](https://doi.org/10.1109/TVCG.2022.3144975)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong 等人（2022）熊凯、傅思维、丁国铭、罗仲苏、余戎、陈伟、包虎军、吴英才。2022年。通过 SOMNUS 可视化数据处理脚本。*IEEE Trans.
    Vis. Comput. Graph.* 29, 6（2022），2950–2964。 [https://doi.org/10.1109/TVCG.2022.3144975](https://doi.org/10.1109/TVCG.2022.3144975)
- en: 'Yang et al. (2021) Chenyang Yang, Shurui Zhou, Jin LC Guo, and Christian Kästner.
    2021. Subtle bugs everywhere: Generating documentation for data wrangling code.
    In *Proceedings of the IEEE/ACM International Conference on Automated Software
    Engineering (ASE)*. IEEE, Piscataway, NJ, 304–316. [https://doi.org/10.1109/ASE51524.2021.9678520](https://doi.org/10.1109/ASE51524.2021.9678520)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2021）杨晨阳、周书锐、郭金LC、克里斯蒂安·凯斯特纳。2021年。无处不在的细微bug：为数据处理代码生成文档。在 *IEEE/ACM
    自动化软件工程国际会议（ASE）论文集* 中。IEEE，皮斯卡特维，NJ，304–316。 [https://doi.org/10.1109/ASE51524.2021.9678520](https://doi.org/10.1109/ASE51524.2021.9678520)
- en: 'Yin et al. (2023) Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming
    Wen, Kensen Shi, Joshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski,
    Oleksandr Polozov, and Charles Sutton. 2023. Natural language to code generation
    in interactive data science notebooks. In *Proceedings of the Annual Meeting of
    the Association for Computational Linguistics (Volume 1: Long Papers)*. ACL, Toronto,
    Canada, 126–173. [https://doi.org/10.18653/v1/2023.acl-long.9](https://doi.org/10.18653/v1/2023.acl-long.9)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yin 等人（2023）尹鹏程、李文定、肖克凡、阿比谢克·拉奥、文晔名、史肯森、乔舒亚·霍兰德、佩奇·贝利、米歇尔·卡塔斯塔、亨里克·米哈威斯基、奥列克桑德·波洛佐夫、查尔斯·萨顿。2023年。在交互式数据科学笔记本中生成自然语言到代码的转换。在
    *计算语言学协会年会（第1卷：长篇论文）* 中。ACL，多伦多，加拿大，126–173。 [https://doi.org/10.18653/v1/2023.acl-long.9](https://doi.org/10.18653/v1/2023.acl-long.9)
- en: 'Zhu-Tian and Xia (2022) Chen Zhu-Tian and Haijun Xia. 2022. CrossData: Leveraging
    text-data connections for authoring data documents. In *Proceedings of the ACM
    Conference on Human Factors in Computing Systems (CHI)*. ACM, New York, NY, Article
    95, 15 pages. [https://doi.org/10.1145/3491102.3517485](https://doi.org/10.1145/3491102.3517485)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu-Tian 和 Xia（2022）朱陈天和夏海军。2022年。CrossData：利用文本数据连接编写数据文档。在 *ACM 人机计算系统会议（CHI）论文集*
    中。ACM，纽约，NY，文章 95，15 页。 [https://doi.org/10.1145/3491102.3517485](https://doi.org/10.1145/3491102.3517485)
- en: 'Zhu-Tian et al. (2024a) Chen Zhu-Tian, Zeyu Xiong, Xiaoshuo Yao, and Elena
    Glassman. 2024a. Sketch then generate: Providing incremental user feedback and
    guiding LLM code generation through language-oriented code sketches. arXiv:2405.03998'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱天等（2024a）朱天，熊泽宇，姚晓硕，埃琳娜·格拉斯曼。2024a. 先草绘再生成：通过面向语言的代码草图提供增量用户反馈并指导LLM代码生成。arXiv:2405.03998
- en: 'Zhu-Tian et al. (2024b) Chen Zhu-Tian, Chenyang Zhang, Qianwen Wang, Jakob
    Troidl, Simon Warchol, Johanna Beyer, Nils Gehlenborg, and Hanspeter Pfister.
    2024b. Beyond generating code: Evaluating GPT on a data visualization course.
    arXiv:2306.02914'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱天等（2024b）朱天，张晨阳，王倩文，雅各布·特罗伊德尔，西蒙·瓦尔霍尔，约翰娜·贝耶，尼尔斯·盖伦博格，汉斯彼得·菲斯特。2024b. 超越生成代码：评估GPT在数据可视化课程中的表现。arXiv:2306.02914
