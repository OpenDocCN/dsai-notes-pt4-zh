- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 11:43:46'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:43:46
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'InvestorBench: A Benchmark for Financial Decision-Making Tasks with LLM-based
    Agent'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: InvestorBench：一种基于LLM代理的金融决策任务基准
- en: 来源：[https://arxiv.org/html/2412.18174/](https://arxiv.org/html/2412.18174/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2412.18174/](https://arxiv.org/html/2412.18174/)
- en: Haohang Li^(1,⋆), Yupeng Cao^(1,⋆), Yangyang Yu^(1,⋆), Shashidhar Reddy Javaji¹,
    Zhiyang Deng¹,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Haohang Li^(1,⋆), Yupeng Cao^(1,⋆), Yangyang Yu^(1,⋆), Shashidhar Reddy Javaji¹,
    Zhiyang Deng¹,
- en: Yueru He², Yuechen Jiang¹, Zining Zhu¹,  Koduvayur Subbalakshmi¹, Guojun Xiong³,
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Yueru He², Yuechen Jiang¹, Zining Zhu¹, Koduvayur Subbalakshmi¹, Guojun Xiong³,
- en: Jimin Huang⁴, Lingfei Qian⁴, Xueqing Peng ⁴, Qianqian Xie^(4,†), Jordan W. Suchow¹
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Jimin Huang⁴, Lingfei Qian⁴, Xueqing Peng ⁴, Qianqian Xie^(4,†), Jordan W. Suchow¹
- en: ¹Stevens Institute of Technology ²Columbia University ³Harvard University ⁴The
    Fin AI
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹斯蒂文斯理工学院 ²哥伦比亚大学 ³哈佛大学 ⁴The Fin AI
- en: '^⋆These authors contributed equally ^† Corresponding author: qianqian.xie@yale.edu'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ^⋆这些作者贡献相同 ^† 通讯作者：qianqian.xie@yale.edu
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Recent advancements have underscored the potential of large language model
    (LLM)-based agents in financial decision-making. Despite this progress, the field
    currently encounters two main challenges: (1) the lack of a comprehensive LLM
    agent framework adaptable to a variety of financial tasks, and (2) the absence
    of standardized benchmarks and consistent datasets for assessing agent performance.
    To tackle these issues, we introduce InvestorBench, the first benchmark specifically
    designed for evaluating LLM-based agents in diverse financial decision-making
    contexts. InvestorBench enhances the versatility of LLM-enabled agents by providing
    a comprehensive suite of tasks applicable to different financial products, including
    single equities like stocks, cryptocurrencies and exchange-traded funds (ETFs).
    Additionally, we assess the reasoning and decision-making capabilities of our
    agent framework using thirteen different LLMs as backbone models, across various
    market environments and tasks. Furthermore, we have curated a diverse collection
    of open-source, multi-modal datasets and developed a comprehensive suite of environments
    for financial decision-making. This establishes a highly accessible platform for
    evaluating financial agents’ performance across various scenarios.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的进展凸显了基于大型语言模型（LLM）的代理在金融决策中的潜力。尽管取得了这些进展，但该领域目前面临两个主要挑战：（1）缺乏一个适应多种金融任务的综合LLM代理框架，和（2）缺乏标准化基准和一致的数据集来评估代理的性能。为了解决这些问题，我们推出了InvestorBench，这是首个专门用于评估LLM代理在不同金融决策环境中的表现的基准。InvestorBench通过提供一套适用于不同金融产品的任务，增强了LLM驱动代理的多功能性，包括单一股票、加密货币和交易所交易基金（ETFs）。此外，我们通过使用十三种不同的LLM作为主干模型，在不同市场环境和任务下评估我们的代理框架的推理和决策能力。我们还整理了一系列多样化的开源多模态数据集，并开发了一个全面的金融决策环境套件，为评估金融代理在不同场景下的表现提供了一个高度可访问的平台。
- en: 'InvestorBench: A Benchmark for Financial Decision-Making Tasks with LLM-based
    Agent'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: InvestorBench：一种基于LLM代理的金融决策任务基准
- en: 'Haohang Li^(1,⋆), Yupeng Cao^(1,⋆), Yangyang Yu^(1,⋆), Shashidhar Reddy Javaji¹,
    Zhiyang Deng¹, Yueru He², Yuechen Jiang¹, Zining Zhu¹,  Koduvayur Subbalakshmi¹,
    Guojun Xiong³, Jimin Huang⁴, Lingfei Qian⁴, Xueqing Peng ⁴, Qianqian Xie^(4,†),
    Jordan W. Suchow¹ ¹Stevens Institute of Technology ²Columbia University ³Harvard
    University ⁴The Fin AI ^⋆These authors contributed equally ^† Corresponding author:
    qianqian.xie@yale.edu'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Haohang Li^(1,⋆), Yupeng Cao^(1,⋆), Yangyang Yu^(1,⋆), Shashidhar Reddy Javaji¹,
    Zhiyang Deng¹, Yueru He², Yuechen Jiang¹, Zining Zhu¹, Koduvayur Subbalakshmi¹,
    Guojun Xiong³, Jimin Huang⁴, Lingfei Qian⁴, Xueqing Peng ⁴, Qianqian Xie^(4,†),
    Jordan W. Suchow¹ ¹斯蒂文斯理工学院 ²哥伦比亚大学 ³哈佛大学 ⁴The Fin AI ^⋆这些作者贡献相同 ^† 通讯作者：qianqian.xie@yale.edu
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The recent studies on large language model (LLM)-based agents have demonstrated
    impressive performance across a range of decision-making tasks in complex and
    open-ended environments spanning various domains Zhang et al. ([2024b](https://arxiv.org/html/2412.18174v1#bib.bib41));
    Guo et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib9)); Eigner and
    Händler ([2024](https://arxiv.org/html/2412.18174v1#bib.bib7)); Wang et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib28)).
    However, developing agentic frameworks tailored specifically for financial decision-making
    remains a significant challenge. This complexity arises from the need for agents
    to acutely discern and prioritize decisive signals, and then make sequentially
    high-quality decisions within the volatile and multifaceted financial markets,
    where information varies in time sensitivity and modality.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近关于基于大语言模型（LLM）代理的研究已经在多个领域的复杂和开放环境中的一系列决策任务中展示了令人印象深刻的表现（Zhang 等人，[2024b](https://arxiv.org/html/2412.18174v1#bib.bib41)；Guo
    等人，[2024](https://arxiv.org/html/2412.18174v1#bib.bib9)；Eigner 和 Händler，[2024](https://arxiv.org/html/2412.18174v1#bib.bib7)；Wang
    等人，[2024](https://arxiv.org/html/2412.18174v1#bib.bib28)）。然而，专门为金融决策制定的代理框架仍然是一个重大挑战。这种复杂性源于代理需要敏锐地识别并优先考虑决定性信号，然后在充满波动性和多面性的金融市场中做出连续的高质量决策，在这些市场中，信息的时效性和表现形式各不相同。
- en: '![Refer to caption](img/e16053ca6ec977c94340356a87ce1dd7.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e16053ca6ec977c94340356a87ce1dd7.png)'
- en: 'Figure 1: General architecture of InvestorBench.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：InvestorBench 的总体架构。
- en: Furthermore, the design of financial agents becomes increasingly complex when
    applied across multiple decision-making tasks, due to the significant variation
    in key factors influencing financial decisions across different objectives and
    task types. For instance, single-equity tasks like stock trading require analyzing
    company-specific and industry-wide data, including market metrics, sector trends,
    performance reports, and relevant news Yi et al. ([2022](https://arxiv.org/html/2412.18174v1#bib.bib36)).
    In contrast, cryptocurrency trading is highly sensitive to crypto-specific news
    and sentiment due to its dynamic nature Bhatnagar et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib5)).
    ETFs, on the other hand, typically follow passive investment strategies, emphasizing
    long-term growth and cost efficiency Madhavan ([2016](https://arxiv.org/html/2412.18174v1#bib.bib18)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当金融代理应用于多个决策任务时，由于不同目标和任务类型之间影响金融决策的关键因素差异显著，其设计变得愈加复杂。例如，像股票交易这样的单一股票任务需要分析公司特定的和行业范围的数据，包括市场指标、行业趋势、业绩报告以及相关的新闻（Yi
    等人，[2022](https://arxiv.org/html/2412.18174v1#bib.bib36)）。相对而言，加密货币交易由于其动态性质，对加密特定新闻和情绪高度敏感（Bhatnagar
    等人，[2023](https://arxiv.org/html/2412.18174v1#bib.bib5)）。另一方面，ETF 通常遵循被动投资策略，强调长期增长和成本效率（Madhavan，[2016](https://arxiv.org/html/2412.18174v1#bib.bib18)）。
- en: The recent emergence of financial LLM-based agent frameworks such as FinMem
    Yu et al. ([2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)), FinAgent Zhang
    et al. ([2024a](https://arxiv.org/html/2412.18174v1#bib.bib40)), CryptoTrade Li
    et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib13)), FinRobot Yang
    et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib33)), and FinCon Yu
    et al. ([2024b](https://arxiv.org/html/2412.18174v1#bib.bib39)) has presented
    a variety of architectural approaches tailored to specific financial tasks. This
    diversification has sparked substantial interest across both academic and industrial
    landscapes. FinRobot is engineered specifically for market analysis, while FinMem
    and FinAgent are oriented towards trading individual equities like stocks and
    ETFs. CryptoTrade focuses solely on cryptocurrency trading. FinCon pioneers in
    addressing portfolio management, although it currently handles only compact portfolios
    consisting of three stock assets. While these frameworks are effective within
    their respective niches, they generally focus on addressing only limited types
    of financial decision-making tasks. This restricts them from further demonstrating
    the broader applicability of these frameworks and limits the comprehensive, comparative
    insights that could be drawn from their overall decision-making performance. Furthermore,
    the frequent reliance on proprietary financial data complicates the evaluation
    of these tools, obscuring their effectiveness and adaptability in broader contexts.
    Therefore, there is a pressing need to develop innovative benchmarks specifically
    designed to evaluate LLM-based agents across a wider spectrum of financial decision-making
    scenarios. Such benchmarks would enable a more robust assessment of these technologies,
    facilitating advancements that could cater to various financial applications.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，基于金融大语言模型（LLM）的智能代理框架的出现，如FinMem Yu等（[2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)）、FinAgent
    Zhang等（[2024a](https://arxiv.org/html/2412.18174v1#bib.bib40)）、CryptoTrade Li等（[2024](https://arxiv.org/html/2412.18174v1#bib.bib13)）、FinRobot
    Yang等（[2024](https://arxiv.org/html/2412.18174v1#bib.bib33)）和FinCon Yu等（[2024b](https://arxiv.org/html/2412.18174v1#bib.bib39)），呈现了针对特定金融任务量身定制的各种架构方法。这种多样化引起了学术界和工业界的广泛关注。FinRobot专门为市场分析而设计，而FinMem和FinAgent则面向交易单一的股票和ETF等个股。CryptoTrade仅专注于加密货币交易。FinCon则开创了应对投资组合管理的先河，尽管目前仅处理由三只股票资产组成的小型投资组合。尽管这些框架在各自的细分领域内有效，但它们通常仅关注处理有限类型的金融决策任务。这限制了它们进一步展示框架的广泛适用性，并限制了能够从其整体决策表现中得出的全面、比较性见解。此外，频繁依赖专有金融数据使得这些工具的评估变得复杂，模糊了它们在更广泛情境下的有效性和适应性。因此，迫切需要开发创新的基准，专门设计用以评估基于LLM的智能代理在更广泛的金融决策场景中的表现。这样的基准将有助于更全面地评估这些技术，促进能够满足各种金融应用需求的进展。
- en: 'We introduce InvestorBench, an open-source, LLM-based agent benchmark that
    generalizes across a broad range of financial decision-making tasks. Its detailed
    structure is illustrated in Figure [1](https://arxiv.org/html/2412.18174v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ InvestorBench: A Benchmark for Financial Decision-Making
    Tasks with LLM-based Agent"). Further developed upon the foundational framework
    of FinMem Yu et al. ([2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)),
    which focuses on single-stock investment decisions, our benchmark extends the
    scope to encompass an ensemble of diverse financial market environments for various
    financial tasks. InvestorBench’s cognitive architecture, similar to FinMem, employs
    a layered memory processing mechanism with distinct decay rates, enabling the
    agent to store, retrieve, and consolidate insights and reflections more effectively
    than the pure similarity-based memory retrieval used in FinAgent. This approach
    ensures that decisions are informed by timely and impactful data, a capability
    previously shown effective for single-asset trading. These features reflect how
    human traders draw sequential decisions upon investment signals from multiple
    sources and varying time sensitivities, allowing the agent to naturally adapt
    to complex financial tasks. InvestorBench expands its evaluation beyond the original
    stock trading tasks to encompass three decision tasks significant in the realm
    of financial investment: stock trading, cryptocurrency trading, and ETF investing.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '我们介绍了InvestorBench，这是一个开源的、基于LLM的代理基准，涵盖了广泛的金融决策任务。其详细结构如图[1](https://arxiv.org/html/2412.18174v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ InvestorBench: A Benchmark for Financial Decision-Making
    Tasks with LLM-based Agent")所示。InvestorBench在FinMem Yu等人（[2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)）的基础框架上进一步发展，FinMem专注于单一股票投资决策，而我们的基准扩展了其范围，涵盖了多个金融市场环境，以支持各种金融任务。InvestorBench的认知架构，类似于FinMem，采用了分层的记忆处理机制，具有不同的衰减速率，使得代理能够更有效地存储、检索和整合见解与反思，而不是像FinAgent那样仅依赖基于相似度的记忆检索。这种方法确保决策能基于及时且有影响力的数据，而这一能力在单一资产交易中已被证明是有效的。这些特性反映了人类交易者如何根据来自多个来源和不同时间敏感度的投资信号做出顺序决策，使得代理能够自然适应复杂的金融任务。InvestorBench将其评估范围扩展到除了原有的股票交易任务外，还包括金融投资领域中的三个重要决策任务：股票交易、加密货币交易和ETF投资。'
- en: 'In summary, we make three key contributions: 1) We establish InvestorBench,
    an innovative and comprehensive financial agentic benchmark designed to evaluate
    the reasoning and sequential decision-making capabilities of LLM-based agents
    in complex, open-ended financial scenarios. This benchmark provides a realistic
    perspective for assessing the design and performance of such agents. 2) We provide
    a set of open-source, multi-source market environments that closely mirror real-world
    conditions. Furthermore, these environments also serve as a standardized platform
    for evaluating the decision-making performance of other LLM-based financial agents.
    3) We present a unified, flexible language-agent framework that allows finance
    professionals to conveniently customize assess any LLMs serving as the agent’s
    reasoning core. In this paper, we conduct a holistic evaluation of 13 LLMs — including
    recent, competitive, and domain-specific fine-tuned models (see Table [1](https://arxiv.org/html/2412.18174v1#S3.T1
    "Table 1 ‣ 3.3 Evaluation metrics ‣ 3 InvestorBench ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent")) to provide a broad
    overview of their reasoning capabilities in sequential decision-making tasks within
    financial contexts.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '总结来说，我们做出了三项关键贡献：1) 我们建立了InvestorBench，这是一个创新且全面的金融代理基准，旨在评估基于LLM的代理在复杂的、开放式的金融情境中的推理和顺序决策能力。这个基准提供了一个现实的视角，用于评估此类代理的设计和性能。2)
    我们提供了一套开源的、多源的市场环境，这些环境紧密模拟了现实世界的条件。此外，这些环境还作为一个标准化平台，用于评估其他基于LLM的金融代理的决策性能。3)
    我们提出了一个统一且灵活的语言-代理框架，使金融专业人士能够方便地定制和评估作为代理推理核心的任何LLM。在本文中，我们对13个LLM进行了全面评估——包括最近的、竞争力强的以及领域特定微调的模型（参见表[1](https://arxiv.org/html/2412.18174v1#S3.T1
    "Table 1 ‣ 3.3 Evaluation metrics ‣ 3 InvestorBench ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent")），以广泛概述它们在金融情境中的顺序决策任务中的推理能力。'
- en: 2 LLM Trading Agents
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 LLM交易代理
- en: In this section, we define a framework of the LLM-based agents in the InvestorBench
    and formalize the financial decision-making tasks within the context of partially
    observable Markov decision process (POMDP) Bertsekas and Shreve ([1996](https://arxiv.org/html/2412.18174v1#bib.bib4));
    Liu et al. ([2020](https://arxiv.org/html/2412.18174v1#bib.bib15)); Kabbani and
    Duman ([2022](https://arxiv.org/html/2412.18174v1#bib.bib12)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们定义了InvestorBench中基于LLM的代理框架，并在部分可观察马尔可夫决策过程（POMDP）背景下，正式化了金融决策任务（Bertsekas和Shreve（[1996](https://arxiv.org/html/2412.18174v1#bib.bib4)）；Liu等（[2020](https://arxiv.org/html/2412.18174v1#bib.bib15)）；Kabbani和Duman（[2022](https://arxiv.org/html/2412.18174v1#bib.bib12)））。
- en: 2.1 Definition
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 定义
- en: 'The LLM-based agent in InvestorBench is structured as a large language model-modulo
    framework, designed to match or surpass the capabilities of professional human
    investors. This framework consists of several interconnected modules, each tailored
    to handle the distinct challenges presented by the financial market’s volatility
    and complexity:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: InvestorBench中的基于LLM的代理结构是一个大型语言模型模块框架，旨在匹配或超越专业人类投资者的能力。该框架由几个互联的模块组成，每个模块都针对金融市场的波动性和复杂性带来的独特挑战进行定制：
- en: 'Brain/Backbone (LLM): This module, which is the LLM itself, serves as the core
    of the LLM-based agent. It enhances the agent’s capabilities by enabling it to
    understand, process, and generate natural language. This module plays a crucial
    role in supporting complex decision-making processes, offering interpretations
    of market-related information, generating predictive analytics, and reflecting
    on past investment decisions.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 大脑/骨干（LLM）：该模块即为LLM本身，作为基于LLM的代理的核心。它通过使代理能够理解、处理和生成自然语言来增强代理的能力。这个模块在支持复杂决策过程中起着至关重要的作用，提供市场相关信息的解释，生成预测分析，并回顾过去的投资决策。
- en: 'Perception: This module serves a critical function by converting raw market
    data into a structured format that is compatible with the LLM, specifying what
    the agent perceives and observes, which includes numerical, textual, and visual
    information.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 感知：该模块通过将原始市场数据转化为与LLM兼容的结构化格式，执行关键功能，指定代理所感知和观察到的信息，包括数值、文本和视觉信息。
- en: 'Profile: This module serves two functions articulated in natural language.
    Firstly, it describes the agent’s role, highlighting its character as an experienced
    investor with expert-level knowledge and a self-adaptive risk preference. This
    risk preference dynamically adjusts based on historical market momentum, allowing
    the agent to optimize its strategies in real time. Secondly, the module provides
    a detailed background of the decision-making task, specifying the key characteristics
    and pertinent information about the target assets involved in the trading decisions,
    such as equity historical performance, price fluctuations, and sector information.
    This dual-function module supports the agent’s decisions with both the current
    market context and its historical performance.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 个人资料：该模块通过自然语言表达两个功能。首先，它描述了代理的角色，突出了其作为经验丰富的投资者的特点，具备专家级的知识和自适应的风险偏好。该风险偏好会根据历史市场动向动态调整，使代理能够实时优化其策略。其次，该模块提供了决策任务的详细背景，具体说明了与交易决策相关的目标资产的主要特征和相关信息，如股票历史表现、价格波动和行业信息。这个双重功能模块通过当前市场背景和历史表现支持代理的决策。
- en: '![Refer to caption](img/c05ba92a228b228d5dacc98b52a6abf8.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c05ba92a228b228d5dacc98b52a6abf8.png)'
- en: 'Figure 2: (1) The language agent’s memory module is crafted to interact with
    the market environment to conduct various financial decision-making tasks. It
    contains two core components – Working Memory and Layered Long-term Memory. (2)
    The outline of the agent’s decision-making workflow for retrieving critical memory
    events and market observations to inform specific investment decisions.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：（1）语言代理的记忆模块旨在与市场环境互动，执行各种金融决策任务。它包含两个核心组件——工作记忆和分层长期记忆。（2）代理决策工作流程的概述，用于检索关键的记忆事件和市场观察，进而做出具体的投资决策。
- en: 'Memory: This module processes and retains essential market data and historical
    insights, allowing the agent to draw on a rich repository of knowledge for decision-making.
    Building upon the pioneering work of Yu et al. ([2024a](https://arxiv.org/html/2412.18174v1#bib.bib38))
    in FinMem, the memory architecture comprises two primary components: Working Memory
    and Layered Long-Term Memory, as depicted in Figure [2](https://arxiv.org/html/2412.18174v1#S2.F2
    "Figure 2 ‣ 2.1 Definition ‣ 2 LLM Trading Agents ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent").'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**记忆**：该模块处理并保留关键市场数据和历史洞察，允许代理从丰富的知识库中汲取信息以进行决策。基于Yu等人（[2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)）在FinMem领域的开创性工作，记忆架构包括两个主要组件：工作记忆和分层长期记忆，如图[2](https://arxiv.org/html/2412.18174v1#S2.F2
    "Figure 2 ‣ 2.1 Definition ‣ 2 LLM Trading Agents ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent")所示。'
- en: 'Working memory: This component maintains FinMem’s original functionalities:
    observation, summarization, and reflection. It incorporates two reflection mechanisms:
    immediate and extended. Immediate reflection produces the agent’s reasoning outcomes
    by integrating current market indicators with the top-$K$ ranked events from each
    long-term memory layer, which are significant during both warm-up and evaluation
    stages. In the warm-up stage, the emphasis shifts as the trading direction is
    predetermined, focusing on understanding market trends and enhancing predictive
    accuracy. In the evaluation stage, it outputs the trading direction (Buy, Sell,
    or Hold), the rationale for this decision, identifying the most influential memory
    events and their respective IDs from each layer.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**工作记忆**：该组件保持FinMem的原始功能：观察、总结和反思。它包含两个反思机制：即时反思和扩展反思。即时反思通过将当前市场指标与每一层长期记忆中排名前$K$的事件整合，生成代理的推理结果，这些事件在热身和评估阶段都至关重要。在热身阶段，重点转移，因为交易方向已经预定，着重于理解市场趋势和提高预测准确性。在评估阶段，它输出交易方向（买入、卖出或持有），并给出决策的理由，识别出最具影响力的记忆事件及其各自的ID。'
- en: 'Layered Long-Term Memory: Inspired by the human cognitive system’s varying
    information decay speeds, Layered Long-Term Memory component structures financial
    insights across multiple layers. Each layer is represented by a vector database
    in the Long-Term Memory data warehouse, where information is prioritized and purged
    based on a specific decay rate. Deeper layers retain information longer with smaller
    decay rates, while shallower layers, dealing with more transient data, have larger
    decay rates. This tiered approach is critical as it allows the adaptation of the
    memory architecture to a broader range of financial tasks beyond single-asset
    decisions, accommodating an expanded variety of data sources and increasing overall
    system flexibility. Detailed mechanisms for ranking and decay in each layer are
    further elaborated in the Appendix [A](https://arxiv.org/html/2412.18174v1#A1
    "Appendix A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark for
    Financial Decision-Making Tasks with LLM-based Agent").'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**分层长期记忆**：受到人类认知系统中信息衰减速度不同的启发，分层长期记忆组件将金融洞察分布在多个层次中。每一层都由长期记忆数据仓库中的一个向量数据库表示，信息根据特定的衰减率进行优先排序和清除。较深的层次保留信息的时间更长，衰减率较小，而较浅的层次处理更多的瞬时数据，衰减率较大。这种分层方法至关重要，因为它使得记忆架构能够适应更广泛的金融任务，不仅限于单一资产决策，能够处理更多样化的数据源，并提高系统的整体灵活性。每一层中排序和衰减的详细机制将在附录[A](https://arxiv.org/html/2412.18174v1#A1
    "Appendix A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark for
    Financial Decision-Making Tasks with LLM-based Agent")中进一步阐述。'
- en: 'Action: This module executes trading and investment decisions based on the
    analysis provided by other modules. It directly outputs $\{\textit{``Buy",~{}``Sell",~{}``Hold"}\}$
    for traded asset (stock, crypto, or ETF), as instructed by the backbone LLM. Action
    module synthesizes the operational outcomes from the Profile and Memory modules
    to facilitate precise and well-informed investment decisions. For its daily trading
    operations, the agent can choose from three specific actions for the traded asset:
    “Buy", “Sell", or “Hold". The functionality and input requirements of this module
    differ significantly between the warm-up and evaluation stages: during the warm-up
    stage, the agent observes daily adjusted price differences between consecutive
    days, which are critical for identifying potential “Buy" or “Sell" signals. This
    period allows the agent to calibrate and adjust its decision-making strategies
    based on near-term market movements; during the evaluation stage, access to future
    price data is restricted, compelling the agent to rely solely on available historical
    data and its cognitive processing capabilities. In response to trading inquiries,
    the module integrates historical Profit & Loss (PnL), outcomes from extended reflections,
    and the top-$K$ retrieved memories. This integration ensures that each trading
    decision is grounded in a comprehensive analysis of past performance and current
    market conditions.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 动作：该模块基于其他模块提供的分析执行交易和投资决策。它根据主干LLM的指令直接输出交易资产（股票、加密货币或ETF）的$\{\textit{``Buy",~{}``Sell",~{}``Hold"}\}$。动作模块综合了Profile和Memory模块的操作结果，以促进精确且信息充分的投资决策。在日常交易操作中，代理可以针对交易资产选择三种特定动作：“Buy”、“Sell”或“Hold”。该模块的功能和输入要求在热身阶段和评估阶段存在显著差异：在热身阶段，代理观察连续两天之间的每日调整价格差异，这对于识别潜在的“Buy”或“Sell”信号至关重要。此期间，代理可以根据近期市场波动调整和校准其决策策略；在评估阶段，访问未来的价格数据受到限制，迫使代理仅依赖可用的历史数据和其认知处理能力。作为对交易查询的响应，该模块整合了历史盈亏（PnL）、扩展反思的结果以及从记忆中检索的前$K$个最相关项。这样的整合确保每个交易决策都基于对过去表现和当前市场状况的全面分析。
- en: 2.2 Modeling financial decision-making
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 财务决策建模
- en: 'Formally, we model a financial decision-making process as infinite horizon
    POMDP with time index $\mathbb{T}=\{0,1,2,\cdots\}$ and discount factor $\alpha\in(0,1]$.
    This POMDP contains: (1) a state space $\mathcal{X}\times\mathcal{Y}$ where $\mathcal{X}$
    is the observable component and $\mathcal{Y}$ is unobservable component of the
    financial market; (2) the action space of the agent is $\mathcal{A}$, which is
    modeled as $\{\textit{``Buy",~{}``Sell",~{}``Hold"}\}$; (3) the reward function
    $\mathcal{R}(o,b,a):\mathcal{X}\times\mathcal{Y}\times\mathcal{A}\to\mathbb{R}$
    uses daily profit & loss (PnL) as the output; (4) the observation process $\{O_{t}\}_{t\in\mathbb{T}}\subseteq\mathcal{X}$
    is a multi-dimensional process (5) the reflection process $\{B_{t}\}_{t\in\mathbb{T}}\subseteq\mathcal{Y}$
    represents the agent’s self-reflection, which is updated from $B_{t}$ to $B_{t+1}$
    on daily basis Griffiths et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib8));
    (6) the action $A_{t}\sim\pi(\cdot|\text{prompt})$ represents the way to make
    investment decision driven by the language conditioned policy $\pi$. By denoting
    daily profit & loss (PnLs) by $R^{\pi}_{t}=\mathcal{R}(O_{t},B_{t},A_{t})$ and
    the set of all admissible language conditioned policies as $\Pi=\{\pi(\cdot|\text{prompt})\}$,
    the optimization objective of financial decision-making task is then:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，我们将财务决策过程建模为一个具有时间索引$\mathbb{T}=\{0,1,2,\cdots\}$和折扣因子$\alpha\in(0,1]$的无限期POMDP。这个POMDP包含：（1）状态空间$\mathcal{X}\times\mathcal{Y}$，其中$\mathcal{X}$是可观察的组件，$\mathcal{Y}$是不可观察的组件，代表金融市场；（2）代理的动作空间是$\mathcal{A}$，其建模为$\{\textit{``Buy",~{}``Sell",~{}``Hold"}\}$；（3）奖励函数$\mathcal{R}(o,b,a):\mathcal{X}\times\mathcal{Y}\times\mathcal{A}\to\mathbb{R}$，输出为每日的盈亏（PnL）；（4）观察过程$\{O_{t}\}_{t\in\mathbb{T}}\subseteq\mathcal{X}$是一个多维过程；（5）反射过程$\{B_{t}\}_{t\in\mathbb{T}}\subseteq\mathcal{Y}$表示代理的自我反思，该过程从$B_{t}$更新到$B_{t+1}$，每天更新（Griffiths等人，[2023](https://arxiv.org/html/2412.18174v1#bib.bib8)）；（6）动作$A_{t}\sim\pi(\cdot|\text{prompt})$表示由语言条件策略$\pi$驱动的投资决策方式。通过将每日的盈亏（PnLs）表示为$R^{\pi}_{t}=\mathcal{R}(O_{t},B_{t},A_{t})$，以及所有可接受的语言条件策略集表示为$\Pi=\{\pi(\cdot|\text{prompt})\}$，财务决策任务的优化目标为：
- en: '|  | $\max_{\pi\in\Pi}\mathbb{E}\Big{[}\sum_{t\in\mathbb{T}}\alpha^{t}R^{\pi}_{t}%
    \Big{]}$ |  | (1) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | $\max_{\pi\in\Pi}\mathbb{E}\Big{[}\sum_{t\in\mathbb{T}}\alpha^{t}R^{\pi}_{t}%
    \Big{]}$ |  | (1) |'
- en: 3 InvestorBench
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 InvestorBench
- en: 'He we introduce the detailed architecture of InvestorBench, as illustrated
    in Figure [1](https://arxiv.org/html/2412.18174v1#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks with LLM-based
    Agent").'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍InvestorBench的详细架构，如图[1](https://arxiv.org/html/2412.18174v1#S1.F1 "图
    1 ‣ 1 引言 ‣ InvestorBench：基于LLM代理的金融决策任务基准")所示。
- en: 3.1 Benchmark Composition
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 基准组成
- en: 'InvestorBench is organized into four main components: (1) Data Sources and
    Market Environments: InvestorBench utilizes a wide range of open-source data and
    incorporates third-party APIs, such as Yahoo Finance and SEC EDGAR, to create
    a comprehensive, multi-modal market environment data warehouse. (2) LLM Agent:
    InvestorBench includes an advanced LLM-based agent equipped with modules for Brain,
    Perception, Profile, Memory, and Action. This agent is enhanced with external
    tools (such as tabular data readers and API callers) and data operations (including
    vector database management, information reinforcement, and retrieval). (3) Financial
    Decision-Making Tasks: InvestorBench offers three distinct financial decision-making
    tasks, differentiated by their asset types. (4) Evaluation Metrics: The efficacy
    of all tasks within InvestorBench is evaluated using a set of standard metrics
    in the quantitative finance field, providing a thorough evaluation of the decision-making
    capabilities of the LLM-based agent.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: InvestorBench由四个主要部分组成：（1）数据来源和市场环境：InvestorBench利用广泛的开源数据，并结合第三方API，如Yahoo
    Finance和SEC EDGAR，创建了一个全面的、多模态的市场环境数据仓库。（2）LLM代理：InvestorBench包含一个先进的基于LLM的代理，该代理配备了大脑、感知、档案、记忆和行动等模块。这个代理还增强了外部工具（如表格数据读取器和API调用器）和数据操作（包括向量数据库管理、信息强化和检索）。
    （3）金融决策任务：InvestorBench提供了三种不同的金融决策任务，按资产类型区分。（4）评估指标：所有任务的有效性都使用一组标准的量化金融领域指标进行评估，为基于LLM的代理的决策能力提供全面评估。
- en: 3.2 Trading Environments
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 交易环境
- en: We release three datasets, each curated from diverse sources, to construct tailored
    financial market environments for specific tasks. Our objective is to address
    the current gap in evaluation environments for financial decision-making agent
    frameworks and to offer a fully open platform for the comprehensive assessment
    of agents across various tasks. Below, we introduce each environment, categorized
    by task type, detailing its scope and the data sources it incorporates.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发布了三个数据集，每个数据集来自不同来源，用于构建针对特定任务的定制金融市场环境。我们的目标是填补当前金融决策代理框架评估环境的空白，并提供一个完全开放的平台，用于对代理在各种任务中的全面评估。以下是我们按任务类型分类介绍每个环境，详细说明其范围及所包含的数据来源。
- en: 'Stock market environment integrates information from multiple sources, including:
    1) Daily stock open, high, low, close, and volume (OHLCV) data acquired from Yahoo
    Finance. 2) Summarized insights from company quarterly and annual reports (Form
    10-Q and 10-K) downloaded from the SEC EDGAR database. 3) News articles for seven
    stocks collected daily between 2020-07-01, and 2021-05-06\. The news data for
    four of these companies—Microsoft Corporation (MSFT), Johnson & Johnson (JNJ),
    UVV Corporation (UVV), and Honeywell International Inc. (HON)-are randomly selected
    from the pool with the most new records (over five hundred) from the open-access
    dataset provided by Zhou et al. Zhou et al. ([2021](https://arxiv.org/html/2412.18174v1#bib.bib43)),
    while the news data for the remaining three companies—Tesla, Inc. (TSLA), Apple
    Inc. (AAPL), and NIO Inc. (NIO)-are obtained from Refinitiv Real-Time News, which
    primarily contains high-quality news information from Reuters. 4) The sentiment
    categories (’positive’, ’negative’, ’neutral’) assigned to each news record are
    generated by gpt-3.5-turbo-0125.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 股票市场环境整合了来自多个来源的信息，包括：1）从Yahoo Finance获取的每日股票开盘价、最高价、最低价、收盘价和交易量（OHLCV）数据。 2）从SEC
    EDGAR数据库下载的公司季度报告和年度报告（Form 10-Q和10-K）中的总结性见解。3）从2020年7月1日至2021年5月6日之间收集的七只股票的新闻文章。对于其中四家公司——微软公司（MSFT）、强生公司（JNJ）、UVV公司（UVV）和霍尼韦尔国际公司（HON）——新闻数据是从Zhou等人提供的开放访问数据集中随机选取的，这些数据集中包含最多的新记录（超过五百条）（Zhou
    et al. [2021](https://arxiv.org/html/2412.18174v1#bib.bib43)）；而其余三家公司——特斯拉公司（TSLA）、苹果公司（AAPL）和蔚来公司（NIO）——的新闻数据来自Refinitiv实时新闻，主要包含路透社的高质量新闻信息。
    4）每条新闻记录的情感分类（“积极”、“消极”、“中性”）由gpt-3.5-turbo-0125生成。
- en: Cryptocurrency market environment encompasses 1) the daily stock open-high-low-close-volume
    (OHLCV) acquired from CoinMarketCap; 2) the multisource cryptocurrency news data
    collected from cryptonews, cryptopotato, and cointelegraphVanhoucke ([2023](https://arxiv.org/html/2412.18174v1#bib.bib27));
    3) news spanning from 2023-02-13 to 2023-11-05 collected by Zhou et al. ([2021](https://arxiv.org/html/2412.18174v1#bib.bib43))
    in daily frequency. 4) The sentiment categories generated by the same means.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 加密货币市场环境包括：1) 从 CoinMarketCap 获取的每日股票开盘-最高-最低-收盘-交易量（OHLCV）；2) 从 cryptonews、cryptopotato
    和 cointelegraphVanhoucke（[2023](https://arxiv.org/html/2412.18174v1#bib.bib27)）收集的多源加密货币新闻数据；3)
    从 2023-02-13 至 2023-11-05 由 Zhou 等人（[2021](https://arxiv.org/html/2412.18174v1#bib.bib43)）收集的每日频率新闻；4)
    由相同方式生成的情感类别。
- en: ETF market environment is constructed using News-Informed Financial Trend Yield
    (NIFTY) dataset Saqur et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib23)).
    It contains the processed and curated daily news headlines from 2019-07-29 to
    2020-09-21 and generated sentiment categories for each news headline.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ETF 市场环境是使用 News-Informed Financial Trend Yield (NIFTY) 数据集构建的，Saqur 等人（[2024](https://arxiv.org/html/2412.18174v1#bib.bib23)）。该数据集包含了从
    2019-07-29 到 2020-09-21 的每日新闻头条的处理和整理，并为每条新闻头条生成了情感类别。
- en: In experimental use, we divide the dataset according to the date, with the train
    set used for the warmup phase to establish the memory database, and the test set
    used for the test phase to evaluate the model performance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验使用中，我们根据日期将数据集进行划分，训练集用于预热阶段以建立记忆数据库，测试集用于测试阶段以评估模型性能。
- en: 3.3 Evaluation metrics
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 评估指标
- en: 'We employ four widely recognized financial metrics to evaluate and compare
    the investment performance of various LLMs serving as backbones across different
    tasks: : Cumulative Return (CR) Hull ([2007](https://arxiv.org/html/2412.18174v1#bib.bib11)),
    Sharpe Ratio (SR) Sharpe ([1994](https://arxiv.org/html/2412.18174v1#bib.bib25)),
    Annualized Volatility (AV) Cochrane ([1988](https://arxiv.org/html/2412.18174v1#bib.bib6)),
    and Maximum Drawdown(MDD) Ang and Chen ([2003](https://arxiv.org/html/2412.18174v1#bib.bib2)).
    Note that CR and the SR are often considered more essential than AV and MDD in
    evaluating asset trading performance due to their focus on long-term gains and
    risk-adjusted returns by their definition. Here, we regard these two metrics as
    primary metrics when evaluating the experiment outcomes. The detailed explanation
    is in Appendix [B](https://arxiv.org/html/2412.18174v1#A2 "Appendix B Details
    on Evaluation Metrics ‣ InvestorBench: A Benchmark for Financial Decision-Making
    Tasks with LLM-based Agent").'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用四个广泛认可的金融指标来评估和比较不同任务中作为骨干的各种 LLM 的投资表现：累计收益（CR）Hull（[2007](https://arxiv.org/html/2412.18174v1#bib.bib11)），夏普比率（SR）Sharpe（[1994](https://arxiv.org/html/2412.18174v1#bib.bib25)），年化波动率（AV）Cochrane（[1988](https://arxiv.org/html/2412.18174v1#bib.bib6)），最大回撤（MDD）Ang
    和 Chen（[2003](https://arxiv.org/html/2412.18174v1#bib.bib2)）。注意，CR 和 SR 通常被认为比
    AV 和 MDD 更为重要，因为它们在定义中关注长期收益和风险调整后的回报。在评估实验结果时，我们将这两个指标视为主要指标。详细说明见附录[B](https://arxiv.org/html/2412.18174v1#A2
    "附录 B 评估指标的详细信息 ‣ InvestorBench：一个基于 LLM 的金融决策任务基准").
- en: 'Table 1: InvestorBench evaluates 13 proprietary or open-source LLMs on financial
    decision-making tasks.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：InvestorBench 在财务决策任务中评估了 13 种专有或开源 LLM。
- en: '| Model | #Size | Form | Ver. | Model | #Size | Form | Ver. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | #大小 | 形式 | 版本 | 模型 | #大小 | 形式 | 版本 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| gpt-4Achiam et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib1))
    | N/A | api | 0613 | Qwen2.5-7bQwen team ([2024](https://arxiv.org/html/2412.18174v1#bib.bib22))
    | 7B | open | Instruct |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4Achiam 等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib1)） | N/A
    | api | 0613 | Qwen2.5-7bQwen 团队 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib22))
    | 7B | 开放 | 指令 |'
- en: '| gpt-4oOpenAI ([2022](https://arxiv.org/html/2412.18174v1#bib.bib20)) | N/A
    | api | 0806 | Qwen2.5-32bQwen team ([2024](https://arxiv.org/html/2412.18174v1#bib.bib22))
    | 32B | open | Instruct |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4OpenAI（[2022](https://arxiv.org/html/2412.18174v1#bib.bib20)） | N/A
    | api | 0806 | Qwen2.5-32bQwen 团队 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib22))
    | 32B | 开放 | 指令 |'
- en: '| gpt-o1-preview | N/A | api | 0912 | Qwen2.5-72bQwen team ([2024](https://arxiv.org/html/2412.18174v1#bib.bib22))
    | 72B | open | Instruct |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| gpt-o1-preview | N/A | api | 0912 | Qwen2.5-72bQwen 团队 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib22))
    | 72B | 开放 | 指令 |'
- en: '| DeepSeek-v2Xin et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib32))
    | 15B | open | Lite | llama3.1-8bLlama team ([2024](https://arxiv.org/html/2412.18174v1#bib.bib17))
    | 8B | open | Instruct |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-v2Xin 等人 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib32))
    | 15B | 开放 | Lite | llama3.1-8bLlama 团队 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib17))
    | 8B | 开放 | 指令 |'
- en: '| DeepSeek-llmXin et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib32))
    | 67B | open | Chat | llama3.1-70bLlama team ([2024](https://arxiv.org/html/2412.18174v1#bib.bib17))
    | 70B | open | Instruct |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-llmXin 等人 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib32))
    | 67B | 开放 | 聊天 | llama3.1-70bLlama 团队 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib17))
    | 70B | 开放 | 指令 |'
- en: '| Yi-1.5-9bYoung et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib37))
    | 9B | open | Chat | Palmyra-Finteam ([2024](https://arxiv.org/html/2412.18174v1#bib.bib26))
    | 70B | open | 32K |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-9bYoung 等人 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib37))
    | 9B | 开放 | 聊天 | Palmyra-Finteam ([2024](https://arxiv.org/html/2412.18174v1#bib.bib26))
    | 70B | 开放 | 32K |'
- en: '| Yi-1.5-34bYoung et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib37))
    | 34B | open | Chat |  |  |  |  |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-34bYoung 等人 ([2024](https://arxiv.org/html/2412.18174v1#bib.bib37))
    | 34B | 开放 | 聊天 |  |  |  |  |'
- en: 4 Experiment and Discussion
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验与讨论
- en: 'Table 2: Performance of stock trading with different LLMs as backbone model
    across seven stocks.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同 LLM 作为基础模型在七只股票交易中的表现。
- en: '| Model | MSFT | JNJ | UVV | HON |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | MSFT | JNJ | UVV | HON |'
- en: '|  | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$
    | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$
    | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$
    | MDD$\downarrow$ |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$
    | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$
    | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$
    | MDD$\downarrow$ |'
- en: '| Buy & Hold | 15.340 | 1.039 | 24.980 | 9.428 | 13.895 | 1.343 | 17.500 |
    9.847 | 36.583 | 2.112 | 29.299 | 15.406 | 33.256 | 2.347 | 23.967 | 9.195 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 买入并持有 | 15.340 | 1.039 | 24.980 | 9.428 | 13.895 | 1.343 | 17.500 | 9.847
    | 36.583 | 2.112 | 29.299 | 15.406 | 33.256 | 2.347 | 23.967 | 9.195 |'
- en: '| Financial Domain Models |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 金融领域模型 |'
- en: '| Palmyra-Fin-70B | 14.697 | 0.897 | 27.518 | 9.428 | 5.748 | 0.450 | 19.317
    | 9.367 | 37.875 | 2.039 | 31.200 | 15.967 | 20.016 | 1.464 | 22.974 | 6.824 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Palmyra-Fin-70B | 14.697 | 0.897 | 27.518 | 9.428 | 5.748 | 0.450 | 19.317
    | 9.367 | 37.875 | 2.039 | 31.200 | 15.967 | 20.016 | 1.464 | 22.974 | 6.824 |'
- en: '| Proprietary Models |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 专有模型 |'
- en: '| GPT-o1-preview | 17.184 | 0.962 | 30.000 | 9.428 | 13.561 | 1.086 | 20.864
    | 9.847 | 41.508 | 2.147 | 32.479 | 9.633 | 13.162 | 0.776 | 28.511 | 11.558 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| GPT-o1-preview | 17.184 | 0.962 | 30.000 | 9.428 | 13.561 | 1.086 | 20.864
    | 9.847 | 41.508 | 2.147 | 32.479 | 9.633 | 13.162 | 0.776 | 28.511 | 11.558 |'
- en: '| GPT-4 | 16.654 | 0.932 | 30.022 | 9.428 | 13.712 | 1.103 | 20.894 | 9.860
    | 31.791 | 1.640 | 32.567 | 10.434 | 34.342 | 2.005 | 28.779 | 9.195 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 16.654 | 0.932 | 30.022 | 9.428 | 13.712 | 1.103 | 20.894 | 9.860
    | 31.791 | 1.640 | 32.567 | 10.434 | 34.342 | 2.005 | 28.779 | 9.195 |'
- en: '| GPT-4o | 12.461 | 0.924 | 22.653 | 6.647 | 9.099 | 0.875 | 17.471 | 7.169
    | 8.043 | 0.496 | 27.241 | 14.889 | 38.540 | 2.418 | 26.782 | 8.979 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 12.461 | 0.924 | 22.653 | 6.647 | 9.099 | 0.875 | 17.471 | 7.169
    | 8.043 | 0.496 | 27.241 | 14.889 | 38.540 | 2.418 | 26.782 | 8.979 |'
- en: '| Open-Source Models |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 开源模型 |'
- en: '| Qwen2.5-72B-Instruct | 7.421 | 0.588 | 21.238 | 6.973 | 14.353 | 1.140 |
    20.995 | 9.812 | 37.178 | 1.822 | 34.223 | 13.365 | 34.309 | 2.000 | 28.779 |
    9.292 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 7.421 | 0.588 | 21.238 | 6.973 | 14.353 | 1.140 |
    20.995 | 9.812 | 37.178 | 1.822 | 34.223 | 13.365 | 34.309 | 2.000 | 28.779 |
    9.292 |'
- en: '| Llama-3.1-70B-Instruct | 17.396 | 1.335 | 21.892 | 7.045 | 13.868 | 1.121
    | 20.779 | 9.825 | 35.981 | 1.728 | 34.986 | 15.406 | 43.944 | 2.646 | 27.903
    | 8.993 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-70B-Instruct | 17.396 | 1.335 | 21.892 | 7.045 | 13.868 | 1.121
    | 20.779 | 9.825 | 35.981 | 1.728 | 34.986 | 15.406 | 43.944 | 2.646 | 27.903
    | 8.993 |'
- en: '| DeepSeek-67B-Chat | 13.941 | 0.834 | 28.081 | 7.850 | 14.426 | 1.185 | 20.450
    | 9.825 | 29.940 | 1.481 | 33.964 | 15.407 | 32.536 | 1.909 | 28.628 | 10.782
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-67B-Chat | 13.941 | 0.834 | 28.081 | 7.850 | 14.426 | 1.185 | 20.450
    | 9.825 | 29.940 | 1.481 | 33.964 | 15.407 | 32.536 | 1.909 | 28.628 | 10.782
    |'
- en: '| Yi-1.5-34B-Chat | 22.093 | 1.253 | 29.613 | 9.428 | 14.004 | 1.180 | 19.938
    | 9.847 | 20.889 | 1.020 | 34.417 | 14.936 | 30.743 | 1.823 | 28.335 | 9.195 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-34B-Chat | 22.093 | 1.253 | 29.613 | 9.428 | 14.004 | 1.180 | 19.938
    | 9.847 | 20.889 | 1.020 | 34.417 | 14.936 | 30.743 | 1.823 | 28.335 | 9.195 |'
- en: '| Qwen2.5-32B-Instruct | -0.557 | -0.041 | 22.893 | 8.946 | 2.905 | 0.292 |
    16.725 | 7.169 | -1.623 | -0.097 | 27.973 | 17.986 | 26.332 | 1.980 | 22.348 |
    5.261 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-32B-Instruct | -0.557 | -0.041 | 22.893 | 8.946 | 2.905 | 0.292 |
    16.725 | 7.169 | -1.623 | -0.097 | 27.973 | 17.986 | 26.332 | 1.980 | 22.348 |
    5.261 |'
- en: '| DeepSeek-V2-Lite (15.7B) | 11.904 | 0.694 | 28.796 | 16.094 | -7.482 | -0.670
    | 18.773 | 17.806 | 33.560 | 1.703 | 33.099 | 12.984 | 16.686 | 0.974 | 28.771
    | 16.806 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-V2-Lite (15.7B) | 11.904 | 0.694 | 28.796 | 16.094 | -7.482 | -0.670
    | 18.773 | 17.806 | 33.560 | 1.703 | 33.099 | 12.984 | 16.686 | 0.974 | 28.771
    | 16.806 |'
- en: '| Yi-1.5-9B-Chat | 19.333 | 1.094 | 29.690 | 9.428 | 18.606 | 1.611 | 19.409
    | 10.986 | 49.415 | 2.410 | 34.446 | 11.430 | 29.028 | 1.700 | 28.682 | 12.588
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-9B-Chat | 19.333 | 1.094 | 29.690 | 9.428 | 18.606 | 1.611 | 19.409
    | 10.986 | 49.415 | 2.410 | 34.446 | 11.430 | 29.028 | 1.700 | 28.682 | 12.588
    |'
- en: '| Llama-3.1-8B-Instruct | 22.703 | 1.322 | 28.855 | 7.385 | 13.988 | 1.486
    | 20.460 | 9.969 | 41.108 | 1.981 | 34.866 | 16.429 | 39.079 | 2.320 | 28.299
    | 10.341 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-8B-Instruct | 22.703 | 1.322 | 28.855 | 7.385 | 13.988 | 1.486
    | 20.460 | 9.969 | 41.108 | 1.981 | 34.866 | 16.429 | 39.079 | 2.320 | 28.299
    | 10.341 |'
- en: '| Qwen-2.5-Instruct-7B | -10.305 | -0.724 | 23.937 | 23.371 | 21.852 | 0.980
    | 37.425 | 9.573 | 11.752 | 0.853 | 22.988 | 15.451 | 4.291 | 0.285 | 24.933 |
    14.156 |  | Model | TSLA | AAPL | NIO | Average |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Qwen-2.5-Instruct-7B | -10.305 | -0.724 | 23.937 | 23.371 | 21.852 | 0.980
    | 37.425 | 9.573 | 11.752 | 0.853 | 22.988 | 15.451 | 4.291 | 0.285 | 24.933 |
    14.156 |  | 模型 | TSLA | AAPL | NIO | 平均 |'
- en: '|  | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$
    | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$
    | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$
    | MDD$\downarrow$ |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$
    | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$
    | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$
    | MDD$\downarrow$ |'
- en: '| Buy & Hold | 39.244 | 0.869 | 75.854 | 37.975 | 10.837 | 0.470 | 38.984 |
    19.119 | 52.216 | 0.858 | 107.197 | 47.766 | 34.099 | 0.732 | 74.012 | 34.953
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Buy & Hold | 39.244 | 0.869 | 75.854 | 37.975 | 10.837 | 0.470 | 38.984 |
    19.119 | 52.216 | 0.858 | 107.197 | 47.766 | 34.099 | 0.732 | 74.012 | 34.953
    |'
- en: '| Financial Domain Models |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 金融领域模型 |'
- en: '| Palmyra-Fin-70B | -6.661 | -0.222 | 50.379 | 25.820 | 8.562 | 0.372 | 38.891
    | 25.466 | -3.261 | -0.057 | 101.711 | 58.406 | -0.453 | 0.031 | 63.660 | 36.564
    |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Palmyra-Fin-70B | -6.661 | -0.222 | 50.379 | 25.820 | 8.562 | 0.372 | 38.891
    | 25.466 | -3.261 | -0.057 | 101.711 | 58.406 | -0.453 | 0.031 | 63.660 | 36.564
    |'
- en: '| Proprietary Models |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 专有模型 |'
- en: '| GPT-o1-preview | 34.499 | 0.796 | 72.822 | 35.490 | 8.238 | 0.422 | 33.045
    | 14.412 | 32.433 | 0.558 | 102.470 | 54.016 | 25.057 | 0.592 | 69.446 | 34.639
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| GPT-o1-preview | 34.499 | 0.796 | 72.822 | 35.490 | 8.238 | 0.422 | 33.045
    | 14.412 | 32.433 | 0.558 | 102.470 | 54.016 | 25.057 | 0.592 | 69.446 | 34.639
    |'
- en: '| GPT-4 | 45.246 | 1.190 | 63.896 | 25.031 | 9.889 | 0.440 | 38.008 | 19.119
    | 75.952 | 1.286 | 104.059 | 37.867 | 43.696 | 0.972 | 68.654 | 27.339 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 45.246 | 1.190 | 63.896 | 25.031 | 9.889 | 0.440 | 38.008 | 19.119
    | 75.952 | 1.286 | 104.059 | 37.867 | 43.696 | 0.972 | 68.654 | 27.339 |'
- en: '| GPT-4o | 45.946 | 1.348 | 57.281 | 21.631 | 7.405 | 0.457 | 27.434 | 12.824
    | 63.743 | 1.318 | 85.210 | 29.220 | 39.031 | 1.041 | 56.642 | 21.225 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 45.946 | 1.348 | 57.281 | 21.631 | 7.405 | 0.457 | 27.434 | 12.824
    | 63.743 | 1.318 | 85.210 | 29.220 | 39.031 | 1.041 | 56.642 | 21.225 |'
- en: '| Open-Source Models |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 开源模型 |'
- en: '| Qwen2.5-72B-Instruct | 39.112 | 1.075 | 61.136 | 26.985 | 11.935 | 0.572
    | 35.293 | 19.119 | 87.412 | 2.181 | 70.628 | 12.464 | 46.153 | 1.276 | 55.686
    | 19.523 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 39.112 | 1.075 | 61.136 | 26.985 | 11.935 | 0.572
    | 35.293 | 19.119 | 87.412 | 2.181 | 70.628 | 12.464 | 46.153 | 1.276 | 55.686
    | 19.523 |'
- en: '| Llama-3.1-70B-Instruct | 37.545 | 0.891 | 70.815 | 29.813 | 12.772 | 0.583
    | 37.057 | 16.021 | 66.522 | 1.118 | 104.848 | 46.379 | 38.946 | 0.864 | 70.907
    | 30.738 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-70B-Instruct | 37.545 | 0.891 | 70.815 | 29.813 | 12.772 | 0.583
    | 37.057 | 16.021 | 66.522 | 1.118 | 104.848 | 46.379 | 38.946 | 0.864 | 70.907
    | 30.738 |'
- en: '| DeepSeek-67B-Chat | 35.647 | 0.885 | 67.660 | 33.359 | 14.213 | 0.666 | 36.118
    | 10.876 | 30.963 | 0.599 | 91.146 | 45.855 | 26.941 | 0.717 | 64.975 | 30.030
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-67B-Chat | 35.647 | 0.885 | 67.660 | 33.359 | 14.213 | 0.666 | 36.118
    | 10.876 | 30.963 | 0.599 | 91.146 | 45.855 | 26.941 | 0.717 | 64.975 | 30.030
    |'
- en: '| Yi-1.5-34B-Chat | 35.364 | 0.808 | 73.561 | 35.490 | 14.227 | 0.623 | 38.596
    | 19.432 | 64.307 | 1.063 | 106.597 | 48.042 | 37.966 | 0.831 | 72.918 | 34.321
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-34B-Chat | 35.364 | 0.808 | 73.561 | 35.490 | 14.227 | 0.623 | 38.596
    | 19.432 | 64.307 | 1.063 | 106.597 | 48.042 | 37.966 | 0.831 | 72.918 | 34.321
    |'
- en: '| Qwen2.5-32B-Instruct | 21.336 | 0.729 | 49.157 | 20.704 | 13.220 | 1.089
    | 20.522 | 8.943 | 28.096 | 0.652 | 72.344 | 37.975 | 20.884 | 0.823 | 47.341
    | 22.541 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-32B-Instruct | 21.336 | 0.729 | 49.157 | 20.704 | 13.220 | 1.089
    | 20.522 | 8.943 | 28.096 | 0.652 | 72.344 | 37.975 | 20.884 | 0.823 | 47.341
    | 22.541 |'
- en: '| DeepSeek-V2-Lite (15.7B) | 31.458 | 0.744 | 68.524 | 35.404 | 27.016 | 1.221
    | 11.860 | 37.435 | 27.762 | 0.474 | 103.193 | 48.478 | 28.745 | 0.813 | 61.192
    | 40.439 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-V2-Lite (15.7B) | 31.458 | 0.744 | 68.524 | 35.404 | 27.016 | 1.221
    | 11.860 | 37.435 | 27.762 | 0.474 | 103.193 | 48.478 | 28.745 | 0.813 | 61.192
    | 40.439 |'
- en: '| Yi-1.5-9B-Chat | 31.350 | 0.703 | 74.895 | 37.975 | 3.640 | 0.162 | 37.947
    | 17.578 | 33.748 | 0.569 | 104.502 | 55.284 | 22.913 | 0.478 | 72.448 | 36.946
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-9B-Chat | 31.350 | 0.703 | 74.895 | 37.975 | 3.640 | 0.162 | 37.947
    | 17.578 | 33.748 | 0.569 | 104.502 | 55.284 | 22.913 | 0.478 | 72.448 | 36.946
    |'
- en: '| Llama-3.1-8B-Instruct | 35.622 | 0.832 | 71.936 | 36.383 | 7.079 | 0.309
    | 38.757 | 18.747 | 33.689 | 0.560 | 106.094 | 56.527 | 25.463 | 0.567 | 72.262
    | 37.219 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-8B-Instruct | 35.622 | 0.832 | 71.936 | 36.383 | 7.079 | 0.309
    | 38.757 | 18.747 | 33.689 | 0.560 | 106.094 | 56.527 | 25.463 | 0.567 | 72.262
    | 37.219 |'
- en: '| Qwen-2.5-Instruct-7B | 41.203 | 0.925 | 74.862 | 37.975 | 14.336 | 0.694
    | 34.924 | 12.029 | 33.007 | 0.546 | 106.437 | 53.054 | 29.515 | 0.722 | 72.074
    | 34.353 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Qwen-2.5-Instruct-7B | 41.203 | 0.925 | 74.862 | 37.975 | 14.336 | 0.694
    | 34.924 | 12.029 | 33.007 | 0.546 | 106.437 | 53.054 | 29.515 | 0.722 | 72.074
    | 34.353 |'
- en: '1'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: The Buy & Hold strategy is a passive investment approach commonly used as a
    baseline strategy, where an investor
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 买入并持有策略是一种被广泛使用的被动投资方法，通常作为基准策略，其中投资者
- en: purchases stocks and holds onto them for an extended period regardless of market
    fluctuations.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 购买股票并持有一段较长时间，无论市场波动如何。
- en: '2'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: An upward arrow ($\uparrow$) next to a metric indicates that higher values signify
    better performance, while a downward arrow ($\downarrow$)
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指标旁边的上箭头（$\uparrow$）表示更高的值意味着更好的表现，而下箭头（$\downarrow$）
- en: indicates that lower values are preferable.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表示较低的值更为理想。
- en: '3'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3'
- en: The numbers highlighted in red indicate the best-performing outcomes for the
    corresponding metrics.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用红色突出显示的数字表示对应指标的最佳表现结果。
- en: '![Refer to caption](img/b28182aad8166358ba247d6f9fb42357.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/b28182aad8166358ba247d6f9fb42357.png)'
- en: (a) The performance comparison by different model types.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 按不同模型类型进行的表现比较。
- en: '![Refer to caption](img/21bd92ce1d8bb546faf7e9f04d4e6a37.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/21bd92ce1d8bb546faf7e9f04d4e6a37.png)'
- en: '(b) By model parameter sizes across open-source LLMs. Note: Small-size models
    refer to models with no more than 10B parameters. Medium-size models refer to
    models with parameter numbers in the range of (10B, 65B]. Large-size models are
    those with more than 65B parameters.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 按开源LLM的模型参数大小分类。备注：小型模型指参数不超过10B的模型。中型模型指参数数量在(10B, 65B]范围内的模型。大型模型指参数超过65B的模型。
- en: 'Figure 3: Agent Performance Comparisons from two key perspectives. The CR,
    SR, AV, and MDD represent the average values for each model type, expressed as
    a percentage relative to the Buy & Hold strategy.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：从两个关键角度对代理表现进行比较。CR、SR、AV和MDD分别表示每种模型类型的平均值，表示为相对于买入并持有策略的百分比。
- en: 'To establish a baseline and assess the performance of LLM agents, we standardize
    experimental settings and evaluation metrics across various financial decision-making
    tasks. Results are presented on a task-by-task basis. We report the performance
    of InvestorBench on three single-asset trading tasks: stocks, cryptocurrencies,
    and ETFs trading, using closed-source, open-source, and domain-specific LLMs.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立基准并评估LLM代理的表现，我们在各类金融决策任务中标准化实验设置和评估指标。结果按任务逐一呈现。我们报告了InvestorBench在三种单资产交易任务中的表现：股票、加密货币和ETF交易，使用了封闭源、开源和领域特定的LLM。
- en: 4.1 Experiment Setup
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 实验设置
- en: 'Table [1](https://arxiv.org/html/2412.18174v1#S3.T1 "Table 1 ‣ 3.3 Evaluation
    metrics ‣ 3 InvestorBench ‣ InvestorBench: A Benchmark for Financial Decision-Making
    Tasks with LLM-based Agent") summarizes the performance of a comprehensive list
    of trading agents. For single equity tasks, the baseline is set up by Buy and
    Hold strategy, while for portfolio management task, it is set up by an equal-weight
    portfolio with the detailed rational explained in Appendix. In our experiments,
    the temperature parameter of all LLM-based agent systems is set at 0.6 to balance
    response consistency and reasoning creativity. The performance metrics are reported
    for the test trajectory with the median CR, SR, AV, and MDD from five repeated
    epochs. (If the median of these metrics does not belong to the same epoch, the
    performance is based on the trajectory with the median SR.)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[1](https://arxiv.org/html/2412.18174v1#S3.T1 "表格 1 ‣ 3.3 评估指标 ‣ 3 InvestorBench
    ‣ InvestorBench：基于LLM的金融决策任务基准")总结了一个全面的交易代理表现清单。对于单一股票任务，基准由买入并持有策略设定，而对于投资组合管理任务，则由等权重投资组合设定，具体原理详见附录。在我们的实验中，所有LLM代理系统的温度参数设置为0.6，以平衡响应一致性和推理创造力。表现指标是基于五次重复实验的中位数CR、SR、AV和MDD报告的。（如果这些指标的中位数不属于同一轮次，则表现基于中位数SR的轨迹。）
- en: Furthermore, the selection of warm-up and test periods differs across various
    tasks due to the varying time spans of data collected to construct the agent environment.
    For the single-asset trading tasks, the warm-up period of stock trading is from
    2020-07-01 to 2020-09-30 and the test period is from 2020-10-01 to 2021-05-06\.
    The warm-up period of cryptocurrency trading is from 2023-02-11 to 2023-04-04
    and the test period is from 2023-04-05 to 2023-11-05\. The warm-up period of ETF
    trading is from 2019-07-29 to 2019-12-30 and the test period is from 2020-01-02
    to 2020-09-21.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于用于构建智能体环境的数据收集时间跨度不同，不同任务的预热期和测试期也有所不同。对于单资产交易任务，股票交易的预热期为2020-07-01至2020-09-30，测试期为2020-10-01至2021-05-06。加密货币交易的预热期为2023-02-11至2023-04-04，测试期为2023-04-05至2023-11-05。ETF交易的预热期为2019-07-29至2019-12-30，测试期为2020-01-02至2020-09-21。
- en: For LLM deployment, we utilize vllm to deploy LLMs. For small-scale LLMs (under
    10B parameters), we deploy models on two RTX A6000 GPUs, each with 48GB DRAM.
    For mid-scale LLMs (10B to 65B parameters), we use four RTX A6000 GPUs. For large-scale
    LLMs (over 65B parameters), models are deployed on eight A100 GPUs, each equipped
    with 80GB DRAM.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LLM的部署，我们使用vllm来部署LLM模型。对于小规模LLM（参数小于10B），我们在两块RTX A6000 GPU上部署模型，每块GPU配备48GB的DRAM。对于中规模LLM（参数介于10B到65B之间），我们使用四块RTX
    A6000 GPU。对于大规模LLM（参数超过65B），模型部署在八块A100 GPU上，每块GPU配备80GB的DRAM。
- en: '4.2 Result 1: Stock Trading'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 结果 1：股票交易
- en: 'Table [2](https://arxiv.org/html/2412.18174v1#S4.T2 "Table 2 ‣ 4 Experiment
    and Discussion ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks
    with LLM-based Agent") presents the performance of thirteen backbone models across
    seven stocks, accompanied by the average of each metric for all stocks to offer
    a more comprehensive view of their overall performance. We outline three key insights
    as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 表[2](https://arxiv.org/html/2412.18174v1#S4.T2 "表2 ‣ 4 实验与讨论 ‣ InvestorBench：基于LLM的智能体在金融决策任务中的基准")展示了十三个骨干模型在七只股票上的表现，并附上了所有股票的各项指标平均值，以便更全面地了解它们的整体表现。我们概括出以下三条关键洞察：
- en: 'Superior stock trading performance is achieved with proprietary LLMs as agent
    backbones Compared to agents employing open-source or financial-domain-specific
    fine-tuned LLMs, those using the three proprietary LLMs demonstrated significantly
    higher and more consistent average CR and SR, as shown in Figure [3(a)](https://arxiv.org/html/2412.18174v1#S4.F3.sf1
    "In Figure 3 ‣ 4 Experiment and Discussion ‣ InvestorBench: A Benchmark for Financial
    Decision-Making Tasks with LLM-based Agent"). Despite being fine-tuned with extensive
    financial contexts, domain-specific LLMs did not provide a decisive advantage
    in sequential stock trading decision-making tasks. This may be attributed to their
    primary training for other functions, such as long financial report analysis exemplified
    by Palmyra-Fin-70B, rather than decision-making.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 采用专有LLM作为智能体骨干的股票交易表现优越。与使用开源或金融领域特定微调LLM的智能体相比，使用三种专有LLM的智能体在平均CR和SR上表现出显著更高且更稳定的结果，如图[3(a)](https://arxiv.org/html/2412.18174v1#S4.F3.sf1
    "图3 ‣ 4 实验与讨论 ‣ InvestorBench：基于LLM的智能体在金融决策任务中的基准")所示。尽管经过广泛的金融语境微调，领域特定LLM在顺序股票交易决策任务中并未提供决定性优势。这可能是因为这些LLM的主要训练目标是其他功能，例如Palmyra-Fin-70B所示的长篇金融报告分析，而非决策制定。
- en: 'Model parameter size increment enhances agent financial decision-making quality
    and robustness. In the category of open-source LLMs, those exceeding 67B parameters
    displayed superior CRs and SRs, along with markedly less variance within their
    category, as illustrated in Figure [3(b)](https://arxiv.org/html/2412.18174v1#S4.F3.sf2
    "In Figure 3 ‣ 4 Experiment and Discussion ‣ InvestorBench: A Benchmark for Financial
    Decision-Making Tasks with LLM-based Agent") and Table [2](https://arxiv.org/html/2412.18174v1#S4.T2
    "Table 2 ‣ 4 Experiment and Discussion ‣ InvestorBench: A Benchmark for Financial
    Decision-Making Tasks with LLM-based Agent"). This underscores the prevailing
    belief that the reasoning capabilities of LLMs are proportionate to their parameter
    size, which holds also true in stock trading, which is a sequential decision-making
    task in an open-ended, volatile environment by nature.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 模型参数大小的增加提升了代理的金融决策质量和稳健性。在开源LLM的类别中，那些超过67B参数的模型表现出了更优的CR和SR，同时它们的波动性也明显低于同类模型，如图[3(b)](https://arxiv.org/html/2412.18174v1#S4.F3.sf2
    "图3 ‣ 4 实验与讨论 ‣ InvestorBench：基于LLM代理的金融决策任务基准")和表[2](https://arxiv.org/html/2412.18174v1#S4.T2
    "表2 ‣ 4 实验与讨论 ‣ InvestorBench：基于LLM代理的金融决策任务基准")所示。这凸显了当前的观点，即LLM的推理能力与其参数大小成正比，这一点在股票交易中也同样成立，因为股票交易本质上是一个在开放性、波动性环境中进行的顺序决策任务。
- en: 'Proprietary models exhibit significantly stronger decision-making capabilities
    compared to even the largest open-source LLMs under complex, mixed market conditions,
    though this advantage is less evident in relatively monotone market environments.
    During the test phase, primarily influenced by the range of open-source data collected,
    TSLA and NIO exhibited volatility with mixed upward and downward stock price trends,
    whereas the other five stocks generally showed bullish trends. The investment
    signals derived from such complex markets tend to be noisy or delayed, as illustrated
    in Appendix [C](https://arxiv.org/html/2412.18174v1#A3 "Appendix C An example
    of mixed and lagged market signals: Partial investment insights of TSLA on 2021-03-05
    ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks with LLM-based
    Agent"). We observed that proprietary models possess a superior ability to manage
    these challenging conditions and consistently deliver better performance outcomes
    than large-sized open-source LLMs. Their reasoning capability enables them to
    effectively utilize other decision-relevant information, such as historical momentum,
    current holdings, and, most critically, self-reflection outcomes from the agents,
    thereby facilitating more accurate decisions.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 专有模型在复杂且混合的市场条件下，展示了显著优于即使是最大开源LLM的决策能力，尽管这种优势在相对单一的市场环境中不那么明显。在测试阶段，主要受收集到的开源数据范围的影响，TSLA和NIO股票出现了波动，呈现混合的上涨和下跌趋势，而其他五只股票则普遍呈现出看涨趋势。由这些复杂市场所产生的投资信号往往是嘈杂的或滞后的，如附录[C](https://arxiv.org/html/2412.18174v1#A3
    "附录C 混合和滞后市场信号的示例：2021年3月5日TSLA部分投资洞察 ‣ InvestorBench：基于LLM代理的金融决策任务基准")所示。我们观察到，专有模型具有更强的能力来应对这些具有挑战性的条件，并且始终能提供比大规模开源LLM更好的表现结果。其推理能力使得它们能够有效地利用其他决策相关的信息，如历史动量、当前持仓，最重要的是来自代理的自我反思结果，从而促使更加准确的决策。
- en: '4.3 Result 2 & 3: Cryptocurrency Trading and ETF Trading'
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 结果 2 和 3：加密货币交易与ETF交易
- en: 'In the test phases of both cryptocurrency and ETF trading tasks, market trends
    are mixed. Notably, the cryptocurrency task shows significantly smaller price
    fluctuations compared to the ETF task. We outline the key features of using an
    LLM-agent to make financial decisions across these two distinct markets as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在加密货币和ETF交易任务的测试阶段，市场趋势呈现出混合的状态。值得注意的是，相较于ETF任务，加密货币任务的价格波动明显较小。我们概述了在这两个不同市场中，使用LLM代理进行金融决策的关键特点如下：
- en: 'Large-sized open-source models and proprietary models are needed to effectively
    capture trading signals of cryptocurrency markets, which are highly sensitive
    to news and financial sentiment. As shown in Table [3](https://arxiv.org/html/2412.18174v1#S4.T3
    "Table 3 ‣ 4.3 Result 2 & 3: Cryptocurrency Trading and ETF Trading ‣ 4 Experiment
    and Discussion ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks
    with LLM-based Agent"), using mid-sized and small-sized open-source models as
    the decision-making agent backbone generally results in weaker performance than
    the market baseline with respect to CR and SR.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '需要大规模的开源模型和专有模型来有效捕捉加密货币市场的交易信号，因为该市场对新闻和金融情绪高度敏感。如表[3](https://arxiv.org/html/2412.18174v1#S4.T3
    "Table 3 ‣ 4.3 Result 2 & 3: Cryptocurrency Trading and ETF Trading ‣ 4 Experiment
    and Discussion ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks
    with LLM-based Agent")所示，使用中型和小型开源模型作为决策代理骨干，通常会导致在CR和SR方面的表现弱于市场基准。'
- en: 'ETF investment requires proprietary models enriched with extensive pre-trained
    knowledge to serve as the agent’s “brain” and provide robust reasoning support.
    As shown in Table [4](https://arxiv.org/html/2412.18174v1#S4.T4 "Table 4 ‣ 4.3
    Result 2 & 3: Cryptocurrency Trading and ETF Trading ‣ 4 Experiment and Discussion
    ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks with LLM-based
    Agent"), proprietary models significantly outperform open-source and financial
    domain-specific models in this task. This advantage arises from the complexity
    of ETF trading, which necessitates interpreting actionable signals across diverse
    sectors, demanding more strategic, long-term decisions grounded in deep comprehension
    and reflection anchored by rich pre-contexts.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 'ETF 投资需要具备丰富预训练知识的专有模型作为代理的“头脑”，以提供强大的推理支持。如表[4](https://arxiv.org/html/2412.18174v1#S4.T4
    "Table 4 ‣ 4.3 Result 2 & 3: Cryptocurrency Trading and ETF Trading ‣ 4 Experiment
    and Discussion ‣ InvestorBench: A Benchmark for Financial Decision-Making Tasks
    with LLM-based Agent")所示，专有模型在此任务中显著优于开源模型和金融领域特定模型。这一优势源于ETF交易的复杂性，要求能够解释跨多个行业的可操作信号，迫切需要更多基于深刻理解和反思的战略性、长期决策，这些决策依赖于丰富的前期背景。'
- en: 'Table 3: Performance of cryptocurrency trading with different LLMs as backbone
    models across Bitcoin (BTC) and Ethereum (ETH).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：使用不同LLM作为骨干模型的加密货币交易性能，涵盖比特币（BTC）和以太坊（ETH）。
- en: '| Model | BTC | ETH |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | BTC | ETH |'
- en: '|  | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$
    | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ | CR$\uparrow$
    | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ |'
- en: '| Buy & Hold | 21.821 | 0.683 | 37.426 | 20.796 | 4.528 | 0.146 | 41.817 |
    29.889 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 买入并持有 | 21.821 | 0.683 | 37.426 | 20.796 | 4.528 | 0.146 | 41.817 | 29.889
    |'
- en: '| Financial Domain Models |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 金融领域模型 |'
- en: '| Palmyra-Fin-70B | -20.812 | -1.212 | 20.036 | 27.782 | 4.795 | 0.240 | 26.924
    | 16.405 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| Palmyra-Fin-70B | -20.812 | -1.212 | 20.036 | 27.782 | 4.795 | 0.240 | 26.924
    | 16.405 |'
- en: '| Proprietary Models |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 专有模型 |'
- en: '| GPT-o1-preview | 34.060 | 1.114 | 35.846 | 17.075 | 2.496 | 0.085 | 39.641
    | 27.692 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| GPT-o1-preview | 34.060 | 1.114 | 35.846 | 17.075 | 2.496 | 0.085 | 39.641
    | 27.692 |'
- en: '| GPT-4 | 22.396 | 0.828 | 31.699 | 17.206 | 1.516 | 0.051 | 39.812 | 32.541
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 22.396 | 0.828 | 31.699 | 17.206 | 1.516 | 0.051 | 39.812 | 32.541
    |'
- en: '| GPT-4o | 14.330 | 0.532 | 31.304 | 17.278 | 4.666 | 0.190 | 33.051 | 22.539
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 14.330 | 0.532 | 31.304 | 17.278 | 4.666 | 0.190 | 33.051 | 22.539
    |'
- en: '| Average | 23.595 | 0.825 | 32.950 | 17.186 | 2.893 | 0.109 | 37.501 | 27.591
    |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 23.595 | 0.825 | 32.950 | 17.186 | 2.893 | 0.109 | 37.501 | 27.591
    |'
- en: '| Open-Source Models |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 开源模型 |'
- en: '| Qwen2.5-72B-Instruct | 0.549 | 0.325 | 1.979 | 0.897 | 11.984 | 0.584 | 18.554
    | 27.642 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 0.549 | 0.325 | 1.979 | 0.897 | 11.984 | 0.584 | 18.554
    | 27.642 |'
- en: '| Llama-3.1-70B-Instruct | 20.440 | 0.758 | 31.604 | 17.813 | -11.888 | -0.410
    | 39.047 | 36.416 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-70B-Instruct | 20.440 | 0.758 | 31.604 | 17.813 | -11.888 | -0.410
    | 39.047 | 36.416 |'
- en: '| DeepSeek-67B-Chat | 28.307 | 0.891 | 37.219 | 17.944 | 9.480 | 0.309 | 41.369
    | 26.261 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-67B-Chat | 28.307 | 0.891 | 37.219 | 17.944 | 9.480 | 0.309 | 41.369
    | 26.261 |'
- en: '| Yi-1.5-34B-Chat | 13.620 | 0.434 | 36.778 | 22.790 | 6.325 | 0.227 | 37.503
    | 25.707 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-34B-Chat | 13.620 | 0.434 | 36.778 | 22.790 | 6.325 | 0.227 | 37.503
    | 25.707 |'
- en: '| Qwen2.5-32B-Instruc | 11.566 | 0.869 | 15.608 | 7.984 | 2.823 | 0.194 | 19.571
    | 7.883 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-32B-Instruc | 11.566 | 0.869 | 15.608 | 7.984 | 2.823 | 0.194 | 19.571
    | 7.883 |'
- en: '| DeepSeek-V2-Lite (15.7B) | 4.804 | 0.153 | 36.846 | 20.562 | -9.504 | -0.311
    | 41.199 | 21.270 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-V2-Lite (15.7B) | 4.804 | 0.153 | 36.846 | 20.562 | -9.504 | -0.311
    | 41.199 | 21.270 |'
- en: '| Yi-1.5-9B-Chat | 7.953 | 0.253 | 36.799 | 26.545 | -3.684 | -0.119 | 41.818
    | 35.417 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-9B-Chat | 7.953 | 0.253 | 36.799 | 26.545 | -3.684 | -0.119 | 41.818
    | 35.417 |'
- en: '| Llama-3.1-8B-Instruct | 20.521 | 0.646 | 37.240 | 21.104 | 4.939 | 0.163
    | 40.928 | 29.466 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-8B-Instruct | 20.521 | 0.646 | 37.240 | 21.104 | 4.939 | 0.163
    | 40.928 | 29.466 |'
- en: '| Qwen-2.5-Instruct-7B | 19.477 | 0.612 | 37.289 | 20.796 | -1.339 | -0.075
    | 24.124 | -16.053 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Qwen-2.5-Instruct-7B | 19.477 | 0.612 | 37.289 | 20.796 | -1.339 | -0.075
    | 24.124 | -16.053 |'
- en: '| Average | 14.137 | 0.549 | 30.151 | 17.382 | 1.015 | 0.062 | 33.790 | 21.557
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 14.137 | 0.549 | 30.151 | 17.382 | 1.015 | 0.062 | 33.790 | 21.557
    |'
- en: 'Table 4: Performance of ETF trading with different LLMs as backbone models.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：不同LLM作为骨干模型在ETF交易中的表现。
- en: '| ETF | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| ETF | CR$\uparrow$ | SR$\uparrow$ | AV$\downarrow$ | MDD$\downarrow$ |'
- en: '| Buy & Hold | 2.069 | 0.06 | 46.645 | 35.746 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 买入并持有 | 2.069 | 0.06 | 46.645 | 35.746 |'
- en: '| Financial Domain Models |  |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 金融领域模型 |  |'
- en: '| Palmyra-Fin-70B | 24.759 | 1.152 | 30.419 | 8.203 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Palmyra-Fin-70B | 24.759 | 1.152 | 30.419 | 8.203 |'
- en: '| Proprietary Models |  |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 专有模型 |  |'
- en: '| GPT-o1-preview | 21.224 | 0.849 | 43.766 | 20.054 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| GPT-o1-preview | 21.224 | 0.849 | 43.766 | 20.054 |'
- en: '| GPT-4 | 2.807 | 0.110 | 44.679 | 37.785 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 2.807 | 0.110 | 44.679 | 37.785 |'
- en: '| GPT-4o | 12.292 | 0.377 | 46.150 | 32.678 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 12.292 | 0.377 | 46.150 | 32.678 |'
- en: '| Average | 12.108 | 0.445 | 44.865 | 30.172 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 12.108 | 0.445 | 44.865 | 30.172 |'
- en: '| Open-Source Models |  |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 开源模型 |  |'
- en: '| Qwen2.5-72B-Instruct | 4.507 | 0.227 | 28.090 | 8.580 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 4.507 | 0.227 | 28.090 | 8.580 |'
- en: '| Llama-3.1-70B-Instruct | 9.895 | 0.464 | 30.184 | 12.759 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-70B-Instruct | 9.895 | 0.464 | 30.184 | 12.759 |'
- en: '| Yi-1.5-34B-Chat | 4.996 | 0.322 | 21.986 | 12.858 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-34B-Chat | 4.996 | 0.322 | 21.986 | 12.858 |'
- en: '| Qwen2.5-32B-Instruct | 19.617 | 0.955 | 29.070 | 7.496 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-32B-Instruct | 19.617 | 0.955 | 29.070 | 7.496 |'
- en: '| DeepSeek-V2-Lite (15.7B) | 1.389 | 0.063 | 31.371 | 31.831 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| DeepSeek-V2-Lite (15.7B) | 1.389 | 0.063 | 31.371 | 31.831 |'
- en: '| Yi-1.5-9B-Chat | -4.657 | -0.228 | 28.907 | 15.545 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Yi-1.5-9B-Chat | -4.657 | -0.228 | 28.907 | 15.545 |'
- en: '| Llama-3.1-8B-Instruct | 11.239 | 0.475 | 33.480 | 15.587 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3.1-8B-Instruct | 11.239 | 0.475 | 33.480 | 15.587 |'
- en: '| Qwen-2.5-Instruct-7B | -0.384 | -0.020 | 27.596 | 14.059 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| Qwen-2.5-Instruct-7B | -0.384 | -0.020 | 27.596 | 14.059 |'
- en: '| Average | 5.825 | 0.282 | 28.835 | 14.839 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 5.825 | 0.282 | 28.835 | 14.839 |'
- en: 4.4 Discussion
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 讨论
- en: Combining all the experimental results, we find that the performance of different
    LLM varies significantly in stock, cryptocurrency, and ETF trading. This variation
    not only reflects the inherent complexity of financial markets, but also highlights
    the importance of model selection or fine-tuning. For instance, proprietary LLM
    generally exhibit be performance in stock trading due to their strong training
    on various financial datasets, while open-source models struggle to achieve these
    results, especially in more volatile environments such as cryptocurrency trading.
    In addition, the effectiveness of LLM-based agents depends heavily on their ability
    to adapt to market fluctuations. Agents that incorporate advanced memory systems
    and dynamic risk assessment capabilities are better able to cope with complex
    market situations, highlighting the value of the complex architectural features
    of LLM-based agent framework in financial decision-making tasks.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 结合所有实验结果，我们发现不同LLM在股票、加密货币和ETF交易中的表现差异显著。这种差异不仅反映了金融市场固有的复杂性，还突显了模型选择或微调的重要性。例如，专有LLM通常在股票交易中表现较好，因为它们在各种金融数据集上进行了强有力的训练，而开源模型在这些领域难以取得同样的成绩，尤其是在加密货币交易这种更为波动的环境中。此外，基于LLM的智能体的有效性在很大程度上取决于它们适应市场波动的能力。融入先进记忆系统和动态风险评估能力的智能体能够更好地应对复杂的市场情况，凸显了基于LLM的智能体框架在金融决策任务中复杂架构特征的价值。
- en: 5 Related Work
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: 5.1 LLM for Financial Domain
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 金融领域的LLM
- en: 'The rapid developement of general-domain language models (LMs) has stimulated
    the exploration of financial LMs, such as pre-trained LMs: FinBert Liu et al.
    ([2021](https://arxiv.org/html/2412.18174v1#bib.bib16)); Yang et al. ([2020](https://arxiv.org/html/2412.18174v1#bib.bib35));
    Araci ([2019](https://arxiv.org/html/2412.18174v1#bib.bib3)); Huang et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib10)),
    FinBERT-MRC Zhang and Zhang ([2023](https://arxiv.org/html/2412.18174v1#bib.bib42)),
    FLANG Shah et al. ([2022](https://arxiv.org/html/2412.18174v1#bib.bib24)), and
    several financial LLMs: FinGPTLiu et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib14)),
    FinMA Xie et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib31)), InvestLM
    Yang et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib34)), BloombergGPT
    Wu et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib29)), which leverage
    extensive training on diverse financial datasets (e.g. stock price data, financial
    news and analyst reports) and adapt the capabilities of LMs to the unique needs
    of financial applications. Concurrently, the advancement of LLMs has significantly
    enhanced the development of language-based agent frameworks in the financial sector,
    such as FinMem Yu et al. ([2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)),
    FinAgent Zhang et al. ([2024a](https://arxiv.org/html/2412.18174v1#bib.bib40))
    and FinRobot Yang et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib33)),
    characterized by their adaptability and openness. However, variations in framework
    design, task scope, and data types present challenges in uniformly evaluating
    the efficacy of LLM agents in financial scenarios.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一般领域语言模型（LMs）的快速发展促进了金融语言模型（LMs）的探索，例如预训练的LMs：FinBert Liu等人（[2021](https://arxiv.org/html/2412.18174v1#bib.bib16)）；Yang等人（[2020](https://arxiv.org/html/2412.18174v1#bib.bib35)）；Araci（[2019](https://arxiv.org/html/2412.18174v1#bib.bib3)）；Huang等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib10)），FinBERT-MRC
    Zhang和Zhang（[2023](https://arxiv.org/html/2412.18174v1#bib.bib42)），FLANG Shah等人（[2022](https://arxiv.org/html/2412.18174v1#bib.bib24)），以及若干金融LLMs：FinGPT
    Liu等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib14)），FinMA Xie等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib31)），InvestLM
    Yang等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib34)），BloombergGPT Wu等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib29)），这些模型通过在多种金融数据集（例如股价数据、金融新闻和分析师报告）上进行广泛训练，适应了金融应用的独特需求。与此同时，LLM的进步显著推动了基于语言的金融代理框架的发展，如FinMem
    Yu等人（[2024a](https://arxiv.org/html/2412.18174v1#bib.bib38)），FinAgent Zhang等人（[2024a](https://arxiv.org/html/2412.18174v1#bib.bib40)）和FinRobot
    Yang等人（[2024](https://arxiv.org/html/2412.18174v1#bib.bib33)），这些框架具有适应性和开放性。然而，框架设计、任务范围和数据类型的差异使得在金融场景中统一评估LLM代理的效能面临挑战。
- en: 5.2 Financial LLM Benchmarks
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 金融LLM基准
- en: 'In the realm of financial LLMs, several benchmarks have been developed: FLUE Shah
    et al. ([2022](https://arxiv.org/html/2412.18174v1#bib.bib24)) introduces the
    first comprehensive benchmark with five financial NLP tasks, including sentiment
    analysis, headline classification, named entity recognition, structure boundary
    detection, and question answering. Pixiu Xie et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib31))
    expands this benchmark to include financial document understanding and classification
    tasks, incorporating multimodal datasets. FinBen Xie et al. ([2024](https://arxiv.org/html/2412.18174v1#bib.bib30))
    encompasses 36 datasets covering 24 financial tasks. Despite these advancements,
    there remains a notable gap in benchmarks specifically designed for LLM-based
    agent applications within the financial sector.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域的大型语言模型（LLMs）中，已经开发了几个基准：FLUE Shah等人（[2022](https://arxiv.org/html/2412.18174v1#bib.bib24)）引入了第一个综合性基准，包含五个金融NLP任务，包括情感分析、标题分类、命名实体识别、结构边界检测和问答。Pixiu
    Xie等人（[2023](https://arxiv.org/html/2412.18174v1#bib.bib31)）扩展了这一基准，加入了金融文档理解和分类任务，并结合了多模态数据集。FinBen
    Xie等人（[2024](https://arxiv.org/html/2412.18174v1#bib.bib30)）涵盖了36个数据集，涵盖24个金融任务。尽管这些进展已取得显著成就，但专门为基于LLM的代理应用设计的基准在金融领域仍然存在显著的空白。
- en: 6 Conclusion
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: InvestorBench offers the community two distinct modes of engagement. The first
    mode allows participants to integrate their fine-tuned LLMs into the InvestorBench’s
    agent framework to undertake financial decision-making tasks. This setup enables
    them to benchmark the performance of their models against those previously experimented
    with by our work. The second mode permits users to directly incorporate the environment
    and evaluation metrics of InvestorBench into their own designed agents, facilitating
    a comparative analysis of their agent design’s effectiveness. This dual approach
    provides a flexible framework for testing and enhancing financial decision-making
    strategies within the InvestorBench ecosystem.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: InvestorBench 为社区提供了两种不同的参与模式。第一种模式允许参与者将他们微调的 LLM 集成到 InvestorBench 的智能体框架中，以进行金融决策任务。此设置使他们能够将自己模型的表现与我们之前实验过的模型进行对比。第二种模式允许用户将
    InvestorBench 的环境和评估指标直接集成到他们设计的智能体中，便于对其智能体设计的有效性进行比较分析。这种双重方法为在 InvestorBench
    生态系统中测试和增强金融决策策略提供了一个灵活的框架。
- en: Future research efforts will expand the benchmark by incorporating additional
    information modalities, such as audio (e.g., earnings call recordings) and graphs
    (e.g., K-lines, trade charts), to explore whether these data types can enhance
    decision-making quality. The foundational agent framework of InvestorBench is
    designed to seamlessly accommodate these modalities, ensuring that the extended
    benchmark remains easy to use and scalable.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的研究工作将通过引入更多的信息模态（如音频（例如，财报电话会议录音）和图表（例如，K线图、交易图表））来扩展基准，以探讨这些数据类型是否能提升决策质量。InvestorBench
    的基础智能体框架旨在无缝适应这些模态，确保扩展后的基准仍然易于使用并具有可扩展性。
- en: Limitation
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: First, InvestorBench is currently focusing on single-asset financial decision-making
    task, without addressing multi-asset tasks such as portfolio management. Second,
    copyright restrictions on financial domain data may compromise the quality of
    the datasets we create, potentially limiting the assessment of model performance.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，InvestorBench 当前专注于单一资产的金融决策任务，并未涉及多资产任务，如投资组合管理。其次，金融领域数据的版权限制可能会影响我们创建的数据集的质量，进而限制模型性能的评估。
- en: Ethical Statement
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: The authors take full responsibility for the development of InvestorBench, ensuring
    that the publicly available part in dataset does not contain personal information,
    and conform to established ethical guidelines. The data are shared under the MIT
    license, requiring users to adhere to its terms. InvestorBench is intended for
    academic and educational purposes only and is not a substitute for professional
    advice. While efforts have been made to ensure its accuracy, the authors and their
    institutions disclaim liability for any outcomes arising from its use. Users agree
    to take responsibility for ethical and lawful use and to indemnify the authors
    and their affiliates against any claims or damages resulting from reliance on
    this Material.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 作者对 InvestorBench 的开发负全责，确保公开的部分数据集不包含个人信息，并符合已建立的伦理指南。数据在 MIT 许可证下共享，要求用户遵守其条款。InvestorBench
    仅用于学术和教育目的，并不能替代专业建议。尽管已尽力确保其准确性，作者及其机构不对使用该工具可能产生的任何结果承担责任。用户同意对伦理和合法使用负责，并对因依赖本材料而导致的任何索赔或损害赔偿免责，免除作者及其关联方的责任。
- en: References
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, et al. 2023. Gpt-4 technical report. *arXiv preprint arXiv:2303.08774*.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Achiam 等 (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge
    Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat 等。2023. GPT-4 技术报告。*arXiv 预印本 arXiv:2303.08774*。
- en: Ang and Chen (2003) Andrew Ang and Joseph Chen. 2003. Downside risk. *Journal
    of Portfolio Management*, 29(4):103–112.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ang 和 Chen (2003) Andrew Ang 和 Joseph Chen. 2003. 下行风险。*投资组合管理杂志*, 29(4):103–112。
- en: 'Araci (2019) Dogu Araci. 2019. Finbert: Financial sentiment analysis with pre-trained
    language models. *arXiv preprint arXiv:1908.10063*.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Araci (2019) Dogu Araci. 2019. Finbert: 使用预训练语言模型进行金融情感分析。*arXiv 预印本 arXiv:1908.10063*。'
- en: 'Bertsekas and Shreve (1996) Dimitri Bertsekas and Steven E Shreve. 1996. *Stochastic
    optimal control: the discrete-time case*, volume 5. Athena Scientific.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertsekas 和 Shreve (1996) Dimitri Bertsekas 和 Steven E Shreve. 1996. *随机最优控制：离散时间案例*，第5卷。Athena
    Scientific。
- en: Bhatnagar et al. (2023) Mukul Bhatnagar, Sanjay Taneja, and Ramona Rupeika-Apoga.
    2023. Demystifying the effect of the news (shocks) on crypto market volatility.
    *Journal of Risk and Financial Management*, 16(2):136.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bhatnagar 等人 (2023) Mukul Bhatnagar, Sanjay Taneja 和 Ramona Rupeika-Apoga. 2023.
    解密新闻（冲击）对加密市场波动性的影响。*风险与金融管理期刊*, 16(2):136。
- en: 'Cochrane (1988) John H. Cochrane. 1988. Volatility tests and efficient markets:
    A review essay. *Journal of Monetary Economics*, 22(3):463–485.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cochrane (1988) John H. Cochrane. 1988. 波动性测试与有效市场：一篇评论文章。*货币经济学期刊*, 22(3):463–485。
- en: Eigner and Händler (2024) Eva Eigner and Thorsten Händler. 2024. Determinants
    of llm-assisted decision-making. *arXiv preprint arXiv:2402.17385*.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eigner 和 Händler (2024) Eva Eigner 和 Thorsten Händler. 2024. LLM 辅助决策的决定因素。*arXiv
    预印本 arXiv:2402.17385*。
- en: Griffiths et al. (2023) Thomas L Griffiths, Jian-Qiao Zhu, Erin Grant, and R Thomas
    McCoy. 2023. Bayes in the age of intelligent machines. *arXiv preprint arXiv:2311.10206*.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Griffiths 等人 (2023) Thomas L Griffiths, Jian-Qiao Zhu, Erin Grant 和 R Thomas
    McCoy. 2023. 贝叶斯在智能机器时代的应用。*arXiv 预印本 arXiv:2311.10206*。
- en: 'Guo et al. (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao
    Pei, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large language model
    based multi-agents: A survey of progress and challenges. *arXiv preprint arXiv:2402.01680*.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人 (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei,
    Nitesh V Chawla, Olaf Wiest 和 Xiangliang Zhang. 2024. 基于大语言模型的多智能体：进展与挑战综述。*arXiv
    预印本 arXiv:2402.01680*。
- en: 'Huang et al. (2023) Allen H Huang, Hui Wang, and Yi Yang. 2023. Finbert: A
    large language model for extracting information from financial text. *Contemporary
    Accounting Research*, 40(2):806–841.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人 (2023) Allen H Huang, Hui Wang 和 Yi Yang. 2023. Finbert：一个从金融文本中提取信息的大语言模型。*当代会计研究*,
    40(2):806–841。
- en: Hull (2007) John Hull. 2007. *Risk Management and Financial Institutions*. John
    Wiley & Sons.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hull (2007) John Hull. 2007. *风险管理与金融机构*。John Wiley & Sons。
- en: Kabbani and Duman (2022) Taylan Kabbani and Ekrem Duman. 2022. Deep reinforcement
    learning approach for trading automation in the stock market. *IEEE Access*, 10:93564–93574.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kabbani 和 Duman (2022) Taylan Kabbani 和 Ekrem Duman. 2022. 股票市场交易自动化的深度强化学习方法。*IEEE
    Access*, 10:93564–93574。
- en: 'Li et al. (2024) Yuan Li, Bingqiao Luo, Qian Wang, Nuo Chen, Xu Liu, and Bingsheng
    He. 2024. Cryptotrade: A reflective llm-based agent to guide zero-shot cryptocurrency
    trading. In *Proceedings of the 2024 Conference on Empirical Methods in Natural
    Language Processing*, pages 1094–1106.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2024) Yuan Li, Bingqiao Luo, Qian Wang, Nuo Chen, Xu Liu 和 Bingsheng
    He. 2024. Cryptotrade：基于反射的 LLM（大语言模型）代理引导零-shot 加密货币交易。收录于 *2024年自然语言处理经验方法会议论文集*，第1094–1106页。
- en: 'Liu et al. (2023) Xiao-Yang Liu, Guoxuan Wang, and Daochen Zha. 2023. Fingpt:
    Democratizing internet-scale data for financial large language models. *arXiv
    preprint arXiv:2307.10485*.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2023) Xiao-Yang Liu, Guoxuan Wang 和 Daochen Zha. 2023. Fingpt：为金融大语言模型民主化互联网规模的数据。*arXiv
    预印本 arXiv:2307.10485*。
- en: 'Liu et al. (2020) Yang Liu, Qi Liu, Hongke Zhao, Zhen Pan, and Chuanren Liu.
    2020. Adaptive quantitative trading: An imitative deep reinforcement learning
    approach. In *Proceedings of the AAAI conference on artificial intelligence*,
    volume 34, pages 2128–2135.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2020) Yang Liu, Qi Liu, Hongke Zhao, Zhen Pan 和 Chuanren Liu. 2020.
    自适应量化交易：一种模仿深度强化学习方法。收录于 *AAAI人工智能会议论文集*，第34卷，第2128–2135页。
- en: 'Liu et al. (2021) Zhuang Liu, Degen Huang, Kaiyu Huang, Zhuang Li, and Jun
    Zhao. 2021. Finbert: A pre-trained financial language representation model for
    financial text mining. In *Proceedings of the twenty-ninth international conference
    on international joint conferences on artificial intelligence*, pages 4513–4519.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2021) Zhuang Liu, Degen Huang, Kaiyu Huang, Zhuang Li 和 Jun Zhao. 2021.
    Finbert：一个预训练的金融语言表示模型用于金融文本挖掘。收录于 *第二十九届国际人工智能联合会议论文集*，第4513–4519页。
- en: Llama team (2024) Meta Llama team. 2024. [The llama 3 herd of models](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Llama 团队 (2024) Meta Llama 团队. 2024. [Llama 3 模型群体](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/)。
- en: Madhavan (2016) Ananth N Madhavan. 2016. *Exchange-traded funds and the new
    dynamics of investing*. Oxford University Press.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Madhavan (2016) Ananth N Madhavan. 2016. *交易所交易基金与投资新动态*。牛津大学出版社。
- en: Murre and Dros (2015) Jaap MJ Murre and Joeri Dros. 2015. Replication and analysis
    of ebbinghaus’ forgetting curve. *PloS one*, 10(7):e0120644.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Murre 和 Dros (2015) Jaap MJ Murre 和 Joeri Dros. 2015. 复制与分析艾宾浩斯遗忘曲线。*PloS one*,
    10(7):e0120644。
- en: OpenAI (2022) OpenAI. 2022. [Introducing chatgpt](https://openai.com/blog/chatgpt).
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2022) OpenAI. 2022. [介绍 ChatGPT](https://openai.com/blog/chatgpt)。
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. [Generative agents: Interactive
    simulacra of human behavior](https://doi.org/10.1145/3586183.3606763). In *Proceedings
    of the 36th Annual ACM Symposium on User Interface Software and Technology*, UIST
    ’23, New York, NY, USA. Association for Computing Machinery.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人 (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang 和 Michael S. Bernstein. 2023. [生成代理：人类行为的互动仿真](https://doi.org/10.1145/3586183.3606763).
    见于 *第36届年度ACM用户界面软件与技术研讨会论文集*, UIST ’23, 纽约, NY, 美国. 计算机协会。
- en: Qwen team (2024) Alibaba Group Qwen team. 2024. [Qwen2.5](https://qwen.readthedocs.io/en/latest/).
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qwen团队 (2024) 阿里巴巴集团 Qwen团队. 2024. [Qwen2.5](https://qwen.readthedocs.io/en/latest/)。
- en: Saqur et al. (2024) Raeid Saqur, Ken Kato, Nicholas Vinden, and Frank Rudzicz.
    2024. Nifty financial news headlines dataset. *arXiv preprint arXiv:2405.09747*.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saqur 等人 (2024) Raeid Saqur, Ken Kato, Nicholas Vinden 和 Frank Rudzicz. 2024.
    精选金融新闻头条数据集. *arXiv 预印本 arXiv:2405.09747*。
- en: 'Shah et al. (2022) Raj Sanjay Shah, Kunal Chawla, Dheeraj Eidnani, Agam Shah,
    Wendi Du, Sudheer Chava, Natraj Raman, Charese Smiley, Jiaao Chen, and Diyi Yang.
    2022. When flue meets flang: Benchmarks and large pre-trained language model for
    financial domain. *arXiv preprint arXiv:2211.00083*.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shah 等人 (2022) Raj Sanjay Shah, Kunal Chawla, Dheeraj Eidnani, Agam Shah, Wendi
    Du, Sudheer Chava, Natraj Raman, Charese Smiley, Jiaao Chen 和 Diyi Yang. 2022.
    当flue遇到flang：金融领域基准与大型预训练语言模型. *arXiv 预印本 arXiv:2211.00083*。
- en: Sharpe (1994) William F. Sharpe. 1994. The sharpe ratio. *The Journal of Portfolio
    Management*, 21(1):49–58.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharpe (1994) William F. Sharpe. 1994. Sharpe比率. *投资组合管理杂志*, 21(1):49–58。
- en: 'team (2024) Writer Engineering team. 2024. Palmyra-Fin-70B-32k: a powerful
    LLM designed for Finance. [https://dev.writer.com](https://dev.writer.com).'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队 (2024) Writer工程团队. 2024. Palmyra-Fin-70B-32k：为金融设计的强大LLM. [https://dev.writer.com](https://dev.writer.com)。
- en: 'Vanhoucke (2023) Olivier Vanhoucke. 2023. [Crypto news dataset](https://www.kaggle.com/datasets/oliviervha/crypto-news).
    Accessed: 2024-08-20.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vanhoucke (2023) Olivier Vanhoucke. 2023. [加密新闻数据集](https://www.kaggle.com/datasets/oliviervha/crypto-news).
    访问日期：2024-08-20。
- en: Wang et al. (2024) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2024. A survey on
    large language model based autonomous agents. *Frontiers of Computer Science*,
    18(6):186345.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2024) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin 等人. 2024. 基于大语言模型的自主代理调查.
    *计算机科学前沿*, 18(6):186345。
- en: 'Wu et al. (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark
    Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann.
    2023. Bloomberggpt: A large language model for finance. *arXiv preprint arXiv:2303.17564*.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 (2023) Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze,
    Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg 和 Gideon Mann. 2023.
    Bloomberggpt：为金融领域设计的大语言模型. *arXiv 预印本 arXiv:2303.17564*。
- en: 'Xie et al. (2024) Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao
    Zhang, Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, et al. 2024. The
    finben: An holistic financial benchmark for large language models. *arXiv preprint
    arXiv:2402.12659*.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人 (2024) Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang,
    Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng 等人. 2024. finben：大语言模型的全方位金融基准.
    *arXiv 预印本 arXiv:2402.12659*。
- en: 'Xie et al. (2023) Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min
    Peng, Alejandro Lopez-Lira, and Jimin Huang. 2023. Pixiu: A large language model,
    instruction data and evaluation benchmark for finance. *arXiv preprint arXiv:2306.05443*.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人 (2023) Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng,
    Alejandro Lopez-Lira 和 Jimin Huang. 2023. Pixiu：金融领域的大语言模型、指令数据及评估基准. *arXiv 预印本
    arXiv:2306.05443*。
- en: 'Xin et al. (2024) Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia
    Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao
    Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, and Chong Ruan. 2024. [Deepseek-prover-v1.5:
    Harnessing proof assistant feedback for reinforcement learning and monte-carlo
    tree search](https://arxiv.org/abs/2408.08152).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xin 等人 (2024) Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao,
    Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu,
    Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo 和 Chong Ruan. 2024. [Deepseek-prover-v1.5:
    利用证明助手反馈进行强化学习与蒙特卡洛树搜索](https://arxiv.org/abs/2408.08152)。'
- en: 'Yang et al. (2024) Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli
    Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, et al. 2024.
    Finrobot: An open-source ai agent platform for financial applications using large
    language models. *arXiv preprint arXiv:2405.14767*.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2024) 鸿阳·杨、博宇·张、能·王、程·郭、晓丽·张、立坤·林、俊霖·王、天宇·周、茂·关、润佳·张 等人。2024。Finrobot：一个开源的
    AI 代理平台，用于利用大语言模型进行金融应用。*arXiv 预印本 arXiv:2405.14767*。
- en: 'Yang et al. (2023) Yi Yang, Yixuan Tang, and Kar Yan Tam. 2023. Investlm: A
    large language model for investment using financial domain instruction tuning.
    *arXiv preprint arXiv:2309.13064*.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2023) 益·杨、一轩·唐、嘉恩·谭。2023。Investlm：一种用于投资的大语言模型，通过金融领域的指令调优。*arXiv 预印本
    arXiv:2309.13064*。
- en: 'Yang et al. (2020) Yi Yang, Mark Christopher Siy Uy, and Allen Huang. 2020.
    Finbert: A pretrained language model for financial communications. *arXiv preprint
    arXiv:2006.08097*.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2020) 益·杨、马克·克里斯托弗·西·乌伊、艾伦·黄。2020。Finbert：一个用于金融沟通的预训练语言模型。*arXiv 预印本
    arXiv:2006.08097*。
- en: 'Yi et al. (2022) Ziruo Yi, Ting Xiao, Kaz-Onyeakazi Ijeoma, Ratnam Cheran,
    Yuvraj Baweja, and Phillip Nelson. 2022. Stock2vec: An embedding to improve predictive
    models for companies. *arXiv preprint arXiv:2201.11290*.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi 等人 (2022) 子若·易、婷·肖、卡兹-奥涅阿卡齐·伊吉欧玛、拉特南·切兰、尤弗拉·巴维贾、菲利普·尼尔森。2022。Stock2vec：一种嵌入方法，用于改进公司的预测模型。*arXiv
    预印本 arXiv:2201.11290*。
- en: 'Young et al. (2024) Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang,
    Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, et al. 2024.
    Yi: Open foundation models by 01\. ai. *arXiv preprint arXiv:2403.04652*.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Young 等人 (2024) 亚历克斯·杨、贝·陈、超·李、成恩·黄、格·张、冠伟·张、恒·李、江城·朱、建群·陈、静·张 等人。2024。Yi：01.ai
    开放基础模型。*arXiv 预印本 arXiv:2403.04652*。
- en: 'Yu et al. (2024a) Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li,
    Denghui Zhang, Rong Liu, Jordan W Suchow, and Khaldoun Khashanah. 2024a. Finmem:
    A performance-enhanced llm trading agent with layered memory and character design.
    In *Proceedings of the AAAI Symposium Series*, volume 3, pages 595–597.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 (2024a) 杨扬·余、浩航·李、智勇·陈、悦晨·蒋、杨·李、邓辉·张、荣·刘、乔丹·W·苏乔、哈尔敦·哈沙纳。2024a。Finmem：一种具有分层记忆和角色设计的性能增强型
    LLM 交易代理。在 *AAAI Symposium Series 会议录*，第 3 卷，第 595–597 页。
- en: 'Yu et al. (2024b) Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng
    Cao, Zhi Chen, Jordan W Suchow, Rong Liu, Zhenyu Cui, Zhaozhuo Xu, et al. 2024b.
    Fincon: A synthesized llm multi-agent system with conceptual verbal reinforcement
    for enhanced financial decision making. *arXiv preprint arXiv:2407.06567*.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等人 (2024b) 杨扬·余、志远·姚、浩航·李、志扬·邓、宇鹏·曹、智勇·陈、乔丹·W·苏乔、荣·刘、振宇·崔、兆卓·徐 等人。2024b。Fincon：一种合成的
    LLM 多代理系统，具有概念性语言强化，用于增强金融决策。在 *arXiv 预印本 arXiv:2407.06567*。
- en: 'Zhang et al. (2024a) Wentao Zhang, Lingxuan Zhao, Haochong Xia, Shuo Sun, Jiaze
    Sun, Molei Qin, Xinyi Li, Yuqing Zhao, Yilei Zhao, Xinyu Cai, et al. 2024a. Finagent:
    A multimodal foundation agent for financial trading: Tool-augmented, diversified,
    and generalist. *arXiv preprint arXiv:2402.18485*.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2024a) 文涛·张、凌轩·赵、浩充·夏、硕·孙、家泽·孙、莫磊·秦、欣怡·李、玉清·赵、怡磊·赵、新宇·蔡 等人。2024a。Finagent：一种用于金融交易的多模态基础代理：工具增强、Diversified
    和通用型。*arXiv 预印本 arXiv:2402.18485*。
- en: 'Zhang et al. (2024b) Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian
    de Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan, and Furu Wei. 2024b. Llm as
    a mastermind: A survey of strategic reasoning with large language models. *arXiv
    preprint arXiv:2404.01230*.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2024b) 亚东·张、绍光·毛、涛·葛、迅·王、阿德里安·德·温特、岩·夏、文山·吴、婷·宋、满·兰、福如·魏。2024b。LLM
    作为策划者：大语言模型的战略推理调查。*arXiv 预印本 arXiv:2404.01230*。
- en: 'Zhang and Zhang (2023) Yuzhe Zhang and Hong Zhang. 2023. Finbert–mrc: financial
    named entity recognition using bert under the machine reading comprehension paradigm.
    *Neural Processing Letters*, 55(6):7393–7413.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 和 Zhang (2023) 玉哲·张、鸿·张。2023。Finbert–mrc：在机器阅读理解范式下使用 BERT 的金融命名实体识别。*神经处理快报*，55(6)：7393–7413。
- en: 'Zhou et al. (2021) Zhihan Zhou, Liqian Ma, and Han Liu. 2021. [Trade the event:
    Corporate events detection for news-based event-driven trading](https://doi.org/10.18653/v1/2021.findings-acl.186).
    In *Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021*,
    pages 2114–2124, Online. Association for Computational Linguistics.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 (2021) 志寒·周、李倩·马、汉·刘。2021。 [事件交易：基于新闻的事件驱动交易中的企业事件检测](https://doi.org/10.18653/v1/2021.findings-acl.186)。在
    *计算语言学协会会议论文集：ACL-IJCNLP 2021*，第 2114–2124 页，在线发布。计算语言学协会。
- en: Appendices
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 附录
- en: Appendix A Memory Ranking Mechanism of FinMem
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A FinMem 的记忆排序机制
- en: 'Upon receiving an investment inquiry, FinMem retrieves the top-$K$ critical
    memory events from each layer and channels them to the immediate reflection component
    of the working memory. These events are selected based on their information retrieval
    score, $\gamma_{l}^{E}$, where $l$ represents the layer (shallow, intermediate,
    or deep), as defined in Equation [2](https://arxiv.org/html/2412.18174v1#A1.E2
    "In Appendix A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent").'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到投资查询后，FinMem会从每一层中提取出排名前$K$的关键记忆事件，并将它们传输到工作记忆的即时反思组件。这些事件是基于它们的信息检索得分$\gamma_{l}^{E}$进行选择的，其中$l$代表层次（浅层、中层或深层），如公式[2](https://arxiv.org/html/2412.18174v1#A1.E2
    "附录A FinMem的记忆排名机制 ‣ InvestorBench：一个基于LLM的金融决策任务基准")中所定义。
- en: '|  | $\gamma_{l}^{E}=S_{\text{Recency}_{l}}^{E}+S_{\text{Relevancy}_{l}}^{E}+S_{%
    \text{Importance}_{l}}^{E},$ |  | (2) |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | $\gamma_{l}^{E}=S_{\text{Recency}_{l}}^{E}+S_{\text{Relevancy}_{l}}^{E}+S_{%
    \text{Importance}_{l}}^{E},$ |  | (2) |'
- en: where each memory event is only associated with one score and can only belong
    to a single layer.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，每个记忆事件只关联一个得分，并且只能属于一个层次。
- en: 'Let $E$ denote a given memory event. The scoring mechanism for $E$, adapted
    from Park et al. Park et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib21))
    but with modified recency and importance computations, is tailored to handle data
    with various timelines and to achieve layered processing that represents the diverse
    periodicities of the financial environment. This score encapsulates three metrics:
    recency (how recently the event occurred), relevancy (the event’s pertinence to
    the current context), and importance (the event’s significance). Individual metric
    scores exceeding 1.0 are scaled to the [0,1] range before being summed, ensuring
    a balanced contribution from each component and preventing any single metric from
    dominating the overall score. The resulting composite score provides a comprehensive
    evaluation of the memory event’s significance within the multi-layered, periodically
    varying financial landscape.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 设$E$表示给定的记忆事件。$E$的评分机制参考了Park等人的研究（Park et al.， [2023](https://arxiv.org/html/2412.18174v1#bib.bib21)），但对最近性和重要性计算进行了修改，旨在处理具有不同时间线的数据，并实现层次化处理，以体现金融环境中多样的周期性。该评分机制包括三个指标：最近性（事件发生的时间距离现在有多近）、相关性（事件与当前上下文的关联性）和重要性（事件的意义）。每个指标的得分如果超过1.0，会被缩放至[0,1]范围内，再进行求和，以确保每个组成部分的贡献平衡，避免某个指标主导最终评分。最终的综合评分提供了一个全面的评估，衡量了在多层次、周期性变化的金融环境中，记忆事件的重要性。
- en: '|  | $\begin{split}&S_{\text{Recency}_{l}}^{E}=e^{-\frac{\delta^{E}}{Q_{l}}},\quad\;%
    \delta^{E}=t_{\text{P}}-t_{E},\\ \end{split}$ |  | (3) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}&S_{\text{Recency}_{l}}^{E}=e^{-\frac{\delta^{E}}{Q_{l}}},\quad\;%
    \delta^{E}=t_{\text{P}}-t_{E},\\ \end{split}$ |  | (3) |'
- en: 'where $\delta^{E}$ represents the time elapsed between a memory event’s occurrence
    and the trading inquiry’s arrival. The model utilizes three processing layers,
    each corresponding to a specific timeframe: shallow ($Q_{\text{shallow}}=14$ days),
    intermediate ($Q_{\text{intermediate}}=90$ days), and deep ($Q_{\text{deep}}=365$
    days). These intervals represent two weeks, a quarter, and a year respectively.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\delta^{E}$表示记忆事件发生与交易查询到达之间的时间间隔。该模型使用了三层处理，每一层对应特定的时间范围：浅层（$Q_{\text{shallow}}=14$天）、中层（$Q_{\text{intermediate}}=90$天）和深层（$Q_{\text{deep}}=365$天）。这些时间间隔分别代表两周、一个季度和一年。
- en: 'When a trade inquiry $P$ arrives in processing layer $l$ via an LLM prompt,
    the agent calculates the recency score $S_{\text{Recency}_{l}}^{E}$ for a memory
    event $E$ using Equation [3](https://arxiv.org/html/2412.18174v1#A1.E3 "In Appendix
    A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark for Financial
    Decision-Making Tasks with LLM-based Agent"). This score inversely correlates
    with the time elapsed between the inquiry and the event’s memory timestamp, mapping
    to Ebbinghaus’s forgetting curve Murre and Dros ([2015](https://arxiv.org/html/2412.18174v1#bib.bib19)).
    The stability term $Q_{l}$ in Equation [3](https://arxiv.org/html/2412.18174v1#A1.E3
    "In Appendix A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent") modulates memory decay
    rates across layers, with higher values in deeper layers indicating longer memory
    persistence. For instance, in the trading context, company annual reports (e.g.,
    Form 10-Ks) are assigned higher stability values and categorized within deeper
    processing layers compared to daily financial news, reflecting their extended
    timeliness, relevance, and impact on financial decision-making.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个交易查询$P$通过LLM提示到达处理层$l$时，代理计算记忆事件$E$的近期得分$S_{\text{Recency}_{l}}^{E}$，使用方程[3](https://arxiv.org/html/2412.18174v1#A1.E3
    "附录A FinMem的记忆排名机制 ‣ InvestorBench：基于LLM的金融决策任务基准")。该得分与查询和事件的记忆时间戳之间的时间间隔成反比，映射到艾宾浩斯遗忘曲线，Murre和Dros（[2015](https://arxiv.org/html/2412.18174v1#bib.bib19)）。方程[3](https://arxiv.org/html/2412.18174v1#A1.E3
    "附录A FinMem的记忆排名机制 ‣ InvestorBench：基于LLM的金融决策任务基准")中的稳定性项$Q_{l}$调节跨层的记忆衰退率，较深层的较高值表示较长的记忆持久性。例如，在交易背景下，公司年度报告（例如，10-K表格）被赋予较高的稳定性值，并被归类到较深的处理层中，相较于每日的财务新闻，这反映了它们在时效性、相关性和对金融决策的影响上更为持久。
- en: '|  | $\begin{split}&S_{\text{Relevancy}_{l}}^{E}=\frac{\mathbf{m_{E}}\cdot\mathbf{m_%
    {P}}}{\&#124;\mathbf{m_{E}}\&#124;_{2}\times\&#124;\mathbf{m_{P}}\&#124;_{2}}\end{split}$
    |  | (4) |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}&S_{\text{Relevancy}_{l}}^{E}=\frac{\mathbf{m_{E}}\cdot\mathbf{m_{P}}}{\|\mathbf{m_{E}}\|_{2}\times\|\mathbf{m_{P}}\|_{2}}\end{split}$
    |  | (4) |'
- en: 'The relevancy score $S_{\text{relevancy}{l}}^{E}$ quantifies the semantic similarity
    between a memory event $E$ and the current query $P$ using cosine similarity of
    their respective embedding vectors, $\mathbf{m{E}}$ and $\mathbf{m_{P}}$, as shown
    in Equation [4](https://arxiv.org/html/2412.18174v1#A1.E4 "In Appendix A Memory
    Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark for Financial Decision-Making
    Tasks with LLM-based Agent"). These embeddings are generated from the event’s
    textual content and the LLM prompt query (which includes trading inquiries and
    the agent’s character setting) using OpenAI’s "text-embedding-ada-003" model.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性得分$S_{\text{Relevancy}_{l}}^{E}$通过使用余弦相似度量化记忆事件$E$与当前查询$P$之间的语义相似性，余弦相似度基于它们各自的嵌入向量$\mathbf{m_{E}}$和$\mathbf{m_{P}}$，如方程[4](https://arxiv.org/html/2412.18174v1#A1.E4
    "附录A FinMem的记忆排名机制 ‣ InvestorBench：基于LLM的金融决策任务基准")所示。这些嵌入是通过使用OpenAI的"文本嵌入-ada-003"模型从事件的文本内容和LLM提示查询（包括交易查询和代理的角色设置）中生成的。
- en: 'The importance score $S_{\text{Importance}{l}}^{E}$ for a memory event $E$
    in layer $l$ is calculated as the product of a value $v_{l}^{E}$ (derived from
    a uniform piecewise scoring function, Equation [5](https://arxiv.org/html/2412.18174v1#A1.E5
    "In Appendix A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent")) and a degrading ratio
    $\theta_{l}$ (Equation [6](https://arxiv.org/html/2412.18174v1#A1.E6 "In Appendix
    A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark for Financial
    Decision-Making Tasks with LLM-based Agent")), as shown in Equation [7](https://arxiv.org/html/2412.18174v1#A1.E7
    "In Appendix A Memory Ranking Mechanism of FinMem ‣ InvestorBench: A Benchmark
    for Financial Decision-Making Tasks with LLM-based Agent"). This approach, adapted
    from Park et al. ([2023](https://arxiv.org/html/2412.18174v1#bib.bib21)), is tailored
    to our stratified long-term memory structure. The likelihood of higher $v_{l}^{E}$
    values increases from shallow to deep layers, while $\theta_{l}$ measures the
    diminishing importance of an event over time using layer-specific exponential
    functions. The base $\alpha_{l}$ for each layer follows $\alpha{shallow}<\alpha_{intermediate}<\alpha_{deep}$
    (set to 0.9, 0.967, and 0.988 respectively), ensuring $\theta_{l}$ decreases to
    a threshold of 5 after 30, 90, and 365 days for shallow, intermediate, and deep
    layers. This layered approach, implemented through three-piece-wise functions
    for both $S_{\text{Importance}{l}}^{E}$ and $S{\text{Recency}{l}}^{E}$, enables
    FinMem to process long-term memory in a stratified manner. Memory events are purged
    when $S{\text{Recency}{l}}^{E}$ falls below 0.05 or $S{\text{Importance}_{l}}^{E}$
    is under 5 (pre-scaling), maintaining the relevance and efficiency of the memory
    store.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 层 $l$ 中记忆事件 $E$ 的重要性得分 $S_{\text{Importance}{l}}^{E}$ 计算为值 $v_{l}^{E}$（来源于统一分段评分函数，方程
    [5](https://arxiv.org/html/2412.18174v1#A1.E5 "附录 A 记忆排序机制 FinMem ‣ InvestorBench：一个基于LLM的投资决策任务基准")）与衰减比率
    $\theta_{l}$（方程 [6](https://arxiv.org/html/2412.18174v1#A1.E6 "附录 A 记忆排序机制 FinMem
    ‣ InvestorBench：一个基于LLM的投资决策任务基准")）的乘积，如方程 [7](https://arxiv.org/html/2412.18174v1#A1.E7
    "附录 A 记忆排序机制 FinMem ‣ InvestorBench：一个基于LLM的投资决策任务基准") 所示。此方法源自 Park 等人 ([2023](https://arxiv.org/html/2412.18174v1#bib.bib21))，并适配了我们的分层长期记忆结构。从浅层到深层，较高的
    $v_{l}^{E}$ 值的可能性逐渐增加，而 $\theta_{l}$ 通过层特定的指数函数来衡量事件随时间衰减的重要性。每一层的基数 $\alpha_{l}$
    遵循 $\alpha_{\text{shallow}}<\alpha_{\text{intermediate}}<\alpha_{\text{deep}}$（分别设置为
    0.9、0.967 和 0.988），确保 $\theta_{l}$ 在浅层、中层和深层中分别在 30 天、90 天和 365 天后下降到 5 的阈值。通过三个分段函数实现的分层方法，不仅适用于
    $S_{\text{Importance}{l}}^{E}$，也适用于 $S_{\text{Recency}{l}}^{E}$，使得 FinMem 可以以分层的方式处理长期记忆。当
    $S_{\text{Recency}{l}}^{E}$ 低于 0.05 或 $S_{\text{Importance}_{l}}^{E}$ 低于 5（预缩放）时，记忆事件将被清除，以保持记忆存储的相关性和高效性。
- en: '|  | $\begin{split}&v_{l}^{E}=\begin{cases}40&\text{with probability }p_{1}\\
    60&\text{with probability }p_{2}\\ 80&\text{with probability }p_{3}\end{cases}\end{split}$
    |  | (5) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}&v_{l}^{E}=\begin{cases}40&\text{以概率}p_{1}\\ 60&\text{以概率}p_{2}\\
    80&\text{以概率}p_{3}\end{cases}\end{split}$ |  | (5) |'
- en: '|  | $\begin{split}\theta_{l}=(\alpha_{l})^{\delta^{E}},\quad&l=\text{shallow},\text%
    {intermediate},\text{deep},\end{split}$ |  | (6) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}\theta_{l}=(\alpha_{l})^{\delta^{E}},\quad&l=\text{shallow},\text{intermediate},\text{deep},\end{split}$
    |  | (6) |'
- en: where $p_{1}+p_{2}+p_{3}=1$, but their values vary by shallow, intermediate,
    and deep processing. when shallow processing ${p_{1},p_{2},p_{3}}=\{0.8,0.15,0.05\}$,
    intermediate processing, ${p_{1},p_{2},p_{3}}=\{0.05,0.8,0.15\}$ and deep processing,
    ${p_{1},p_{2},p_{3}}=\{0.05,0.15,0.8\}$.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p_{1}+p_{2}+p_{3}=1$，但其值因浅层、中层和深层处理而异。浅层处理时，${p_{1},p_{2},p_{3}}=\{0.8,0.15,0.05\}$，中层处理时，${p_{1},p_{2},p_{3}}=\{0.05,0.8,0.15\}$，深层处理时，${p_{1},p_{2},p_{3}}=\{0.05,0.15,0.8\}$。
- en: '|  | $S_{\text{Importance}_{l}}^{E}=v_{l}^{E}*\theta_{l},$ |  | (7) |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  | $S_{\text{Importance}_{l}}^{E}=v_{l}^{E}*\theta_{l},$ |  | (7) |'
- en: Furthermore, FinMem employs an access counter function to dynamically manage
    memory events across layers, ensuring that crucial events influencing trading
    decisions are elevated to deeper layers for extended retention and recurring access.
    This process, monitored by the LLM validation tool Guardrails AI, tracks critical
    memory IDs across layers. Events deemed pivotal for investment success receive
    a 5-point boost to their importance score ($S_{\text{Importance}{l}}^{E}$). Upon
    meeting upgrade criteria for a deeper layer, an event’s recency score ($S{\text{Recency}_{l}}^{E}$)
    is reset to 1.0, underscoring its significance and preventing rapid decay. Conversely,
    less relevant events gradually fade. This mechanism allows FinMem to efficiently
    identify, prioritize, and retain key events based on their nature and retrieval
    frequency, while gradually phasing out less impactful information, thereby maintaining
    a dynamic and relevant memory structure for financial decision-making.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，FinMem 采用访问计数器功能动态管理跨层的记忆事件，确保对交易决策产生重要影响的关键事件被提升到更深的层级以便于长期保持和反复访问。这个过程由
    LLM 验证工具 Guardrails AI 监控，追踪各层级中的关键记忆 ID。对于投资成功至关重要的事件，其重要性评分（$S_{\text{Importance}{l}}^{E}$）会获得
    5 分的提升。当满足升级至更深层级的条件时，事件的近期性评分（$S_{\text{Recency}_{l}}^{E}$）将重置为 1.0，强调其重要性并防止快速衰减。相反，相关性较低的事件会逐渐消失。这个机制使
    FinMem 能够高效地识别、优先处理并保持关键事件，根据其性质和检索频率，同时逐渐淘汰影响较小的信息，从而保持一个动态且相关的金融决策记忆结构。
- en: Appendix B Details on Evaluation Metrics
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 评估指标的详细信息
- en: 'Below is a brief overview of these metrics:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是这些指标的简要概述：
- en: 'Cumulative Return (CR) % measures the total value change of an investment over
    time by summing daily logarithmic returns, shown in Equation [8](https://arxiv.org/html/2412.18174v1#A2.E8
    "In Appendix B Details on Evaluation Metrics ‣ InvestorBench: A Benchmark for
    Financial Decision-Making Tasks with LLM-based Agent"). Higher values indicate
    better strategy effectiveness.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 累计回报（CR）% 衡量投资随时间的总价值变化，通过求和每日对数回报来计算，如公式[8](https://arxiv.org/html/2412.18174v1#A2.E8
    "附录 B 评估指标的详细信息 ‣ InvestorBench：基于 LLM 的投资决策任务基准")所示。较高的数值表示策略效果更好。
- en: '|  | CR | $\displaystyle=\sum_{t=1}^{n}r_{i}=\sum_{t=1}^{n}\left[\ln\left(\frac{p_{t+1}}{%
    p_{t}}\right)\cdot\text{action}_{t}\right]$ |  | (8) |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | CR | $\displaystyle=\sum_{t=1}^{n}r_{i}=\sum_{t=1}^{n}\left[\ln\left(\frac{p_{t+1}}{%
    p_{t}}\right)\cdot\text{action}_{t}\right]$ |  | (8) |'
- en: ', where $r_{i}$ is the logarithmic return from day $t$ to $t+1$, $p_{t}$ and
    $p_{t+1}$ are the closing prices on days $t$ and $t+1$, respectively, and $\text{action}_{t}$
    is the model’s trading decision for day $t$.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $r_{i}$ 是从第 $t$ 天到第 $t+1$ 天的对数回报，$p_{t}$ 和 $p_{t+1}$ 分别是第 $t$ 天和第 $t+1$
    天的收盘价，$\text{action}_{t}$ 是模型在第 $t$ 天的交易决策。
- en: 'Sharpe Ratio (SR) assesses risk-adjusted returns by dividing the average excess
    return ($R_{p}$) over the risk-free rate ($R_{f}$) by its volatility ($\sigma_{p}$),
    detailed in Equation [9](https://arxiv.org/html/2412.18174v1#A2.E9 "In Appendix
    B Details on Evaluation Metrics ‣ InvestorBench: A Benchmark for Financial Decision-Making
    Tasks with LLM-based Agent"). Higher ratios signify better performance.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 夏普比率（SR）通过将平均超额回报（$R_{p}$）与无风险利率（$R_{f}$）之差除以其波动率（$\sigma_{p}$）来评估风险调整后的回报，详细见公式[9](https://arxiv.org/html/2412.18174v1#A2.E9
    "附录 B 评估指标的详细信息 ‣ InvestorBench：基于 LLM 的投资决策任务基准")。较高的比率意味着更好的表现。
- en: '|  | $\textbf{SR}=\frac{R_{p}-R_{f}}{\sigma_{p}}$ |  | (9) |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textbf{SR}=\frac{R_{p}-R_{f}}{\sigma_{p}}$ |  | (9) |'
- en: 'Annualized Volatility (AV) % and Daily Volatility (DV) % quantify return fluctuations;
    AV is derived by scaling DV (standard deviation of daily logarithmic returns)
    by the square root of the annual trading days (252), as in Equation [10](https://arxiv.org/html/2412.18174v1#A2.E10
    "In Appendix B Details on Evaluation Metrics ‣ InvestorBench: A Benchmark for
    Financial Decision-Making Tasks with LLM-based Agent"). This metric highlights
    potential return deviations across the year.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 年化波动率（AV）% 和日波动率（DV）% 衡量回报波动性；AV 通过将 DV（每日对数回报的标准差）按年度交易天数（252天）的平方根进行缩放得到，如公式[10](https://arxiv.org/html/2412.18174v1#A2.E10
    "附录 B 评估指标的详细信息 ‣ InvestorBench：基于 LLM 的投资决策任务基准")所示。该指标突出显示了全年可能的回报偏差。
- en: '|  | AV | $\displaystyle=\textbf{DV}\times\sqrt{252}$ |  | (10) |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | AV | $\displaystyle=\textbf{DV}\times\sqrt{252}$ |  | (10) |'
- en: 'Max Drawdown (MDD) % calculates the largest portfolio value drop from peak
    to trough, as given in Equation [11](https://arxiv.org/html/2412.18174v1#A2.E11
    "In Appendix B Details on Evaluation Metrics ‣ InvestorBench: A Benchmark for
    Financial Decision-Making Tasks with LLM-based Agent"). Lower values indicate
    lesser risk and higher strategy robustness.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 最大回撤（MDD）% 计算从峰值到谷值的最大投资组合价值下降，如方程[11](https://arxiv.org/html/2412.18174v1#A2.E11
    "附录 B 关于评估指标的详细信息 ‣ InvestorBench：一个用于金融决策任务的基准，与基于LLM的代理")所示。较低的值表示风险较小，策略的稳健性较高。
- en: '|  | $\displaystyle\textbf{MDD}=\text{max}(\frac{P_{\text{peak}}-P_{\text{trough}}}{%
    P_{\text{peak}}})$ |  | (11) |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\textbf{MDD}=\text{max}(\frac{P_{\text{peak}}-P_{\text{trough}}}{%
    P_{\text{peak}}})$ |  | (11) |'
- en: Note that CR and the SR are often considered more essential than AV and MDD
    in evaluating asset trading performance due to their focus on long-term gains
    and risk-adjusted returns by their definition. Here, we regard these two metrics
    as primary metrics when evaluating the experiment outcomes.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于CR和SR在定义中专注于长期收益和风险调整后的回报，因此在评估资产交易表现时，CR和SR通常被认为比AV和MDD更为重要。在这里，我们将这两个指标视为评估实验结果时的主要指标。
- en: 'Appendix C An example of mixed and lagged market signals: Partial investment
    insights of TSLA on 2021-03-05'
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 混合和滞后市场信号示例：2021年3月5日TSLA的部分投资洞察
- en: Here are some insights from the agent’s memory module for TSLA as of 2021-03-05\.
    A few memory records are omitted; these are either neutral or positive. Despite
    this, the stock price trend for TSLA is sharply downward, conflicting with the
    overall positive financial sentiments and market signals. Utilizing proprietary
    models such as GPT4 and GPT-o1 as backbones, the financial decision-making agent
    can leverage other investment insights like historical momentum and self-reflection
    to consistently support a ’Sell’ decision. In contrast, the large-sized open-source
    models like Qwen2.5-72B and DeepSeek-67B-Chat exhibit instability in producing
    consistent actions across repeated experimental trials.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是2021年3月5日TSLA代理记忆模块中的一些洞察。部分记忆记录被省略；这些记录要么是中立的，要么是正面的。尽管如此，TSLA的股价趋势仍然 sharply
    downward，与整体正面的金融情绪和市场信号相冲突。利用像GPT4和GPT-o1这样的专有模型作为支柱，金融决策代理可以利用其他投资洞察，例如历史动量和自我反思，以持续支持“卖出”决策。相比之下，大型开源模型，如Qwen2.5-72B和DeepSeek-67B-Chat，在多次实验试验中展现出不稳定性，无法持续产生一致的行动。
- en: Short-term Memory
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 短期记忆
- en: '1'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: 'Sentiment: Negative: The key insights from the news regarding Tesla Inc (NASDAQ:
    TSLA) losing market share to Ford Motor Company’s (NYSE: F) Mustang Mach-E in
    the United States are as follows:1\. **Market Competition**: Tesla is facing increased
    competition in the electric vehicle (EV) market, particularly from established
    automakers like Ford. The Mustang Mach-E’s success indicates that other companies
    are effectively entering the EV space, which could impact Tesla’s dominance.2\.
    **Market Share Impact**: The loss of market share to Ford suggests that Tesla’s
    growth trajectory in the U.S. may be challenged. Investors should consider the
    potential implications for Tesla’s revenue and profitability if this trend continues…'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '情绪：负面：关于特斯拉公司（NASDAQ: TSLA）在美国失去市场份额给福特汽车公司（NYSE: F）Mustang Mach-E的新闻的关键洞察如下：1\.
    **市场竞争**：特斯拉在电动汽车（EV）市场面临着来自福特等成熟汽车制造商的日益激烈的竞争。Mustang Mach-E的成功表明其他公司正在有效进入电动汽车领域，这可能会影响特斯拉的市场主导地位。2\.
    **市场份额影响**：向福特失去市场份额表明，特斯拉在美国的增长轨迹可能面临挑战。如果这种趋势持续下去，投资者应考虑对特斯拉的收入和盈利能力的潜在影响…'
- en: '2'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: 'Sentiment: Positive: The news about a Banksy artwork being burned and sold
    as a non-fungible token (NFT) highlights a few key insights relevant to investment
    decisions, particularly concerning innovative and disruptive technologies: 1\.
    **Emergence of NFTs**: The transformation of physical art into digital assets
    through NFTs signifies a growing trend in the digital economy. This trend could
    influence sectors beyond art, including technology and finance, as more industries
    explore blockchain applications …'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情绪：正面：关于Banksy艺术品被焚烧并作为非同质化代币（NFT）出售的新闻突出了几个与投资决策相关的关键洞察，特别是关于创新和颠覆性技术：1\. **NFT的兴起**：通过NFT将实体艺术品转化为数字资产，标志着数字经济中一个日益增长的趋势。这个趋势可能会影响艺术以外的其他领域，包括技术和金融，因为更多行业正在探索区块链应用…
- en: '3'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3'
- en: 'Sentiment: Neutral: To provide a summary of key insights relevant to making
    investment decisions about Tesla (TSLA) from the pre-open movers news, I would
    focus on the following aspects: 1\. **Stock Performance**: Look for any significant
    pre-market price movements for TSLA. If the stock is showing a notable increase
    or decrease, it could indicate investor sentiment or reaction to recent news.2\.
    **News Catalysts**: Identify any specific news items or announcements related
    to Tesla that might be influencing its stock price. This could include earnings
    reports, product launches, regulatory news, or changes in leadership…'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情绪：中性：为了从开盘前的市场动态新闻中提供与特斯拉（TSLA）投资决策相关的关键见解，我将重点关注以下几个方面：1\. **股票表现**：观察特斯拉在开盘前的股价是否有显著变化。如果股价出现大幅上涨或下跌，可能表明投资者情绪或对近期新闻的反应。2\.
    **新闻催化剂**：识别任何与特斯拉相关的特定新闻或公告，可能对股价产生影响。这可能包括财报、产品发布、监管新闻或领导层变化……
- en: '4'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '4'
- en: 'Sentiment: positive: The key insights from the news about Tesla’s vehicle registrations
    in Germany are as follows: 1\. **Significant Growth in Registrations**: Tesla
    experienced a 78% year-over-year increase in vehicle registrations in Germany
    as of January. This substantial growth indicates a strong demand for Tesla vehicles
    in one of Europe’s largest automotive markets.2\. **Market Penetration**: The
    surge in registrations suggests that Tesla is successfully penetrating the German
    market, which is traditionally dominated by local automakers. This could imply
    a growing acceptance and preference for electric vehicles (EVs) in Germany, benefiting
    Tesla as a leading EV manufacturer…'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情绪：积极：关于特斯拉在德国的车辆注册量的新闻中的关键见解如下：1\. **注册量显著增长**：截至1月，特斯拉在德国的车辆注册量同比增长了78%。这一大幅增长表明，在欧洲最大的汽车市场之一，对特斯拉车辆的需求强劲。2\.
    **市场渗透**：注册量的激增表明特斯拉正在成功地渗透德国市场，而德国市场传统上由本土汽车制造商主导。这可能意味着德国消费者对电动汽车（EV）的接受度和偏好逐渐增加，这将使特斯拉作为领先的电动汽车制造商从中受益……
- en: …
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Mid-term Memory
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 中期记忆
- en: '1'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: 'Sentiment: Negative: The news about U.S. Senator Elizabeth Warren’s proposal
    for a Democratic wealth tax could have several implications for investment decisions
    regarding Tesla (TSLA):1\. **Impact on Wealthy Investors**: The proposed wealth
    tax targets the wealthiest Americans, which could include major shareholders and
    investors in Tesla. If implemented, this tax could lead to changes in investment
    strategies among these individuals, potentially affecting Tesla’s stock price
    due to shifts in large-scale holdings….5\. **Long-term Implications**: While the
    immediate impact might be uncertain, the long-term implications of a wealth tax
    could lead to a more equitable distribution of wealth, potentially increasing
    consumer spending power. This could benefit Tesla if it results in a larger market
    for its products. Investors in Tesla should closely monitor the progress of this
    proposal and consider its potential effects on market dynamics and investor behavior.'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情绪：负面：关于美国参议员伊丽莎白·沃伦提议征收民主党财富税的消息可能对特斯拉（TSLA）的投资决策产生多方面的影响：1\. **对富有投资者的影响**：该提议的财富税针对的是最富有的美国人，这些人可能包括特斯拉的主要股东和投资者。如果实施，这项税收可能会导致这些投资者的投资策略发生变化，进而影响特斯拉的股价，因为大规模持股的变化可能引起股价波动……5\.
    **长期影响**：虽然短期影响可能不确定，但财富税的长期影响可能会导致财富分配更加公平，进而可能提高消费者的购买力。如果这一变化促使特斯拉的产品市场扩大，特斯拉可能会从中受益。特斯拉的投资者应密切关注该提案的进展，并考虑其对市场动态和投资者行为的潜在影响。
- en: '2'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: 'Sentiment: positive: The key insights from the news information regarding consumer
    preferences in China for electric cars, particularly focusing on price and driving
    range, can be relevant for making investment decisions about Tesla (TSLA) in the
    following ways: 1\. **Market Demand Alignment**: Tesla’s ability to align its
    product offerings with the primary concerns of Chinese consumers 2014price and
    driving range2̆014could significantly impact its market share and sales growth
    in China. Investors should monitor how Tesla’s models compare to competitors in
    these aspects… Overall, Tesla’s success in addressing the key consumer preferences
    in China 2014price and driving range 2014will be critical for its growth prospects
    in the region, making these factors important considerations for investors.'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情感：积极：关于中国消费者对电动汽车的偏好，特别是在价格和续航里程方面的新闻信息，对于做出投资特斯拉（TSLA）决策具有以下相关性：1. **市场需求契合**：特斯拉能否将其产品与中国消费者的主要关注点——价格和续航里程——相匹配，可能会显著影响其在中国的市场份额和销售增长。投资者应关注特斯拉的车型在这些方面与竞争对手的比较……总体而言，特斯拉在满足中国消费者的关键偏好（价格和续航里程）方面的成功，将对其在该地区的增长前景至关重要，使这些因素成为投资者的重要考虑因素。
- en: …
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Long-term Memory
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 长期记忆
- en: '1'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: 'Sentiment: Negative: The key insights from the news about Tesla Inc. (NASDAQ:
    TSLA) facing competition in China are as follows: 1\. **Increased Competition**:
    Tesla’s Model 3 is experiencing significant competition from a budget electric
    vehicle produced through a joint venture involving General Motors (NYSE: GM).
    This indicates a more competitive landscape in the Chinese electric vehicle (EV)
    market, which could impact Tesla’s market share and sales growth in the region…
    For investors, these insights suggest a need to closely watch Tesla’s strategic
    responses to competition in China, its pricing strategies, and any potential impacts
    on its financial performance. Additionally, understanding the broader competitive
    landscape and Tesla’s ability to sustain its growth trajectory will be crucial
    for making informed investment decisions.'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情感：消极：关于特斯拉公司（纳斯达克：TSLA）在中国面临竞争的新闻，以下是关键见解：1. **竞争加剧**：特斯拉的Model 3正面临通用汽车（纽约证券交易所：GM）与其合资企业生产的经济型电动汽车的激烈竞争。这表明中国电动汽车（EV）市场的竞争格局日益激烈，这可能影响特斯拉在该地区的市场份额和销售增长……对于投资者而言，这些见解表明需要密切关注特斯拉应对中国竞争的战略反应、定价策略以及可能对其财务表现产生的影响。此外，了解更广泛的竞争格局和特斯拉维持其增长轨迹的能力，对于做出明智的投资决策至关重要。
- en: '2'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: 'Sentiment: positive: The news about Bill Gates’ concerns regarding Bitcoin’s
    impact on climate change highlights a broader issue of environmental sustainability
    in the tech and financial sectors. Here are the key insights relevant to making
    investment decisions about Tesla (TSLA): 1\. **Environmental Impact Awareness**:
    Bill Gates’ concerns underscore the growing awareness and scrutiny of the environmental
    impact of technology and financial products. This is relevant for Tesla, as the
    company positions itself as a leader in sustainable energy and electric vehicles
    (EVs)… Overall, the emphasis on environmental impact and sustainability in the
    tech sector could reinforce Tesla’s strategic advantages and appeal to investors
    prioritizing green investments.'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 情感：积极：比尔·盖茨关于比特币对气候变化影响的担忧，凸显了技术和金融行业在环境可持续性方面的更广泛问题。以下是与投资特斯拉（TSLA）决策相关的关键见解：1.
    **环境影响意识**：比尔·盖茨的担忧突显了对技术和金融产品环境影响的日益关注和审视。这对特斯拉具有相关性，因为该公司将自己定位为可持续能源和电动汽车（EVs）领域的领导者……总体而言，科技行业对环境影响和可持续性的关注可能加强特斯拉的战略优势，并吸引那些优先考虑绿色投资的投资者。
- en: …
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: 'Appendix D Case Study on Single Stock Trading: Forecast for TSLA on 2022-10-25
    to Predict Trading Decision on 2022-10-26'
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 单一股票交易案例研究：2022年10月25日的特斯拉预测，以预测2022年10月26日的交易决策
- en: '<svg class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="281.18"
    id="A4.F4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,281.18) matrix(1
    0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 266.84)"><foreignobject
    color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="559.03">Initialize Profile</foreignobject></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject color="#000000" height="249.07"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="559.03">1\. Operations:
    - Provide a performance overview of the trading stock based on available data.
    - Set up the risk inclination as the key character of the trading agent. 2\. Range:
    Financial information such as the financial sectors, historical performance, and
    previous stock trends of the trading stock. 3\. Prompts: You are an experienced
    trading manager and investment firm. Your task is to make informed decisions on
    the given stock based on the provided information. Under Self-Adaptive Risk Character
    Setting: When historical momentum is positive, you are a risk-seeking investor.
    But when historical momentum is negative, you are a risk-averse investor. 4\.
    General background setting: You have accumulated a lot of information about the
    following sectors, so you are especially good at trading them: 1)Electric Vehicles
    (Automotive Sector). 2) Energy Generation and Storage…From year 2021 to 2022 September,
    Tesla’s continued growth and solid financial performance over the defined period
    …</foreignobject></g></g></svg><svg class="ltx_picture ltx_align_left ltx_centering
    ltx_figure_panel" height="725.05" id="A4.F4.pic2" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,725.05)
    matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    20.48 710.85)"><foreignobject color="#FFFFFF" height="9.46" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="559.03">Summarize</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject
    color="#000000" height="693.08" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="559.03">1\. Operations: - Summarize different types of input information.
    - Distribute them to corresponding layers of the long-term memory database. 2\.
    Range: Daily market news, Long Documents such as company 10-K and 10-Q reports
    3\. Prompts: - (1). Summarize the contents: Summarize the following documents
    into 1000 words. - (2). Comprehend the investment sentiment of news insights:
    The positive, neutral and negative scores are for understanding the investment
    sentiments, opinions, or emotions. For example, positive news about a company
    can lift investor sentiment, encouraging more buying activity, which in turn can
    push stock prices higher… 4\. Outputs: (1). To Shallow Memory Layer: - [News (ID:
    261)] Here’s How Much You Would Have Made Owning Tesla Stock In The Last 10 Years
    Tesla (NASDAQ:TSLA) has outperformed the market over the past 10 years by 50.69%
    on an annualized basis producing an average annual return of 60.76%. Currently,
    Tesla has a market capitalization of $683.54 billion…. The sentiment is {positive}.
    - [News (ID: 278)] Tesla Q3 Earnings Are Imminent. Can Nio Foreshadow What’s To
    Come? What To Know Before The Print Tesla Inc (NASDAQ: TSLA) shares were trading
    down slightly Wednesday afternoon ahead of the automakerś third-quarter report,
    but the stock is up 6% over the last five sessions… The sentiment is {positive}.
    - … (2). To Intermediate Memory Layer: - [Form 10-Q (ID: 222)] Tesla Q3 2022 revenues
    were $21.5 billion, up 56% year-over-year. Automotive sales revenue grew 56% to
    $17.8 billion driven by higher Model 3/Y and Model S/X deliveries. Gross automotive
    margin declined to 27.9% due to cost inflation and factory ramps. Net income was
    $3.3 billion, up 102% year-over-year. Positive free cash flow was $6.1 billion…
    - [News (ID: 275)] Tesla Q3 Earnings Highlights: Record Revenue, Operating Margin
    And Free Cash Flow, Tesla Semi Deliveries Coming In December Electric vehicle
    leader Tesla Inc (NASDAQ: TSLA) reported third-quarter financial results after
    market close Wednesday…The sentiment is {neutral}. - [News (ID: 274)] Tesla Preps
    For 2023 Cybertruck Launch, Will Make Battery Packs In California The Cybertruck
    is one of Tesla Inc. (NASDAQ: TSLA) most hotly anticipated, but also most delayed,
    products. - …The sentiment is {negative}. (3). To Deep Memory Layer: - [News (ID:
    161)] Tesla Whale Trades Spotted A whale with a lot of money to spend has taken
    a noticeably bearish stance on Tesla. Looking at the options history for Tesla
    (NASDAQ:TSLA) we detected 477 strange trades. The sentiment is {positive}. - [Self-reflection
    (ID: 226)] Given the short-term positive news score in the market for TSLA and
    a positive cumulative return, there is a high probability of continued growth
    in the short term. However, investor should be aware of potential threats in the
    mid-term market with competitors like General Motors, and Nio…</foreignobject></g></g></svg><svg
    class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="314.39"
    id="A4.F4.pic3" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,314.39) matrix(1
    0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 300.05)"><foreignobject
    color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="559.03">Observe</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject color="#000000" height="282.27" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="559.03">1\. Operations: Access and
    interpret market indicators such as current stock prices and historical momentum
    data. 2\. Range: Stock’s daily adjusted closing price, historical momentum in
    the past $k$ days ($k=3$ in this case), etc. 3\. Prompts: - The information below
    provides a summary of stock price fluctuations over the previous few days, which
    is the "momentum" of a stock. It reflects the trend of a stock. Momentum is based
    on the idea that securities that have performed well in the past will continue
    to perform well, and conversely, securities that have performed poorly will continue
    to perform poorly. 4\. Outputs: - (1). The daily adjusted closing price of TSLA
    on {2022-10-25} is {$222.42}. - (2). Train: On {2022-10-25}, the momentum of TSLA,
    indicated by the price difference between the current and the next trading day,
    is {$2.22}. Test: On {2022-10-25}, the historical momentum of TSLA, as measured
    by its cumulative logarithmic returns in the past {3} days, was {7.05%}.</foreignobject></g></g></svg>'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="281.18"
    id="A4.F4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,281.18) matrix(1
    0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 266.84)"><foreignobject
    color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="559.03">初始化配置文件</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject color="#000000" height="249.07" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="559.03">1\. 操作：- 基于可用数据提供交易股票的表现概述。-
    设置风险偏好作为交易代理的关键特征。 2\. 范围：交易股票的财务信息，如财务部门、历史表现和以往股票趋势。 3\. 提示：你是一个经验丰富的交易经理和投资公司。你的任务是根据提供的信息做出关于指定股票的明智决策。在自适应风险特征设置下：当历史动量为正时，你是一个寻求风险的投资者；但当历史动量为负时，你是一个规避风险的投资者。
    4\. 一般背景设置：你已经积累了大量关于以下领域的信息，因此在这些领域的交易特别得心应手：1) 电动汽车（汽车行业）。2) 能源生产与储存……从2021年到2022年9月，特斯拉在指定期间的持续增长和稳固财务表现…</foreignobject></g></g></svg><svg
    class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="725.05"
    id="A4.F4.pic2" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,725.05) matrix(1
    0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 710.85)"><foreignobject
    color="#FFFFFF" height="9.46" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="559.03">总结</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject color="#000000" height="693.08" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="559.03">1\. 操作：- 总结不同类型的输入信息。- 将它们分配到长期记忆数据库的相应层次。
    2\. 范围：每日市场新闻，长期文件，如公司10-K和10-Q报告 3\. 提示：- (1). 总结内容：将以下文档总结为1000字。- (2). 理解新闻洞察中的投资情绪：正面、中性和负面分数用于理解投资情绪、观点或情感。例如，关于公司正面的新闻可以提升投资者情绪，鼓励更多的买入活动，这可能会推高股票价格…
    4\. 输出： (1). 到浅层记忆：- [新闻（ID: 261）] 过去10年持有特斯拉股票的收益。特斯拉（NASDAQ:TSLA）过去10年年化回报超越市场50.69%，年平均回报率为60.76%。目前，特斯拉的市值为6835.4亿美元……情绪为{正面}。
    - [新闻（ID: 278）] 特斯拉第三季度财报即将发布，蔚来能否预示未来趋势？发布前需要了解的事项。特斯拉公司（NASDAQ: TSLA）股价周三下午略有下跌，但过去五个交易日股价上涨了6%……情绪为{正面}。
    - … (2). 到中层记忆：- [表格10-Q（ID: 222）] 特斯拉2022年第三季度收入为215亿美元，同比增长56%。汽车销售收入增长56%，达到了178亿美元，主要得益于Model
    3/Y和Model S/X的交付量增加。汽车毛利率下降至27.9%，原因是成本通胀和工厂 ramp-up。净收入为33亿美元，同比增长102%。自由现金流为61亿美元……
    - [新闻（ID: 275）] 特斯拉第三季度财报亮点：创纪录的收入、运营利润率和自由现金流，特斯拉Semi卡车将在12月交付。电动汽车领导者特斯拉公司（NASDAQ:
    TSLA）在周三市场收盘后公布了第三季度财务业绩……情绪为{中性}。 - [新闻（ID: 274）] 特斯拉为2023年赛博卡车发布做准备，将在加利福尼亚生产电池组。赛博卡车是特斯拉（NASDAQ:
    TSLA）最受期待的产品之一，但也是推迟最久的产品之一。 - …情绪为{负面}。 (3). 到深层记忆：- [新闻（ID: 161）] 特斯拉鲸鱼交易。一个有很多资金的大玩家在特斯拉上采取了明显的看跌立场。通过查看特斯拉（NASDAQ:
    TSLA）的期权交易历史，我们发现477笔奇怪的交易。情绪为{正面}。 - [自我反思（ID: 226）] 根据市场上特斯拉短期正面新闻分数和正向累计回报的情况，短期内持续增长的概率很高。然而，投资者应警惕中期市场中的潜在威胁，如通用汽车和蔚来等竞争者…</foreignobject></g></g></svg><svg
    class="ltx_picture ltx_align_left ltx_centering ltx_figure_panel" height="314.39"
    id="A4.F4.pic3" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,314.39) matrix(1
    0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 300.05)"><foreignobject
    color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="559.03">观察</foreignobject></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 20.48 7.5)"><foreignobject color="#000000" height="282.27" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="559.03">1\. 操作：访问和解读市场指标，如当前股价和历史动量数据。
    2\. 范围：股票的每日调整收盘价，过去$k$天（此处$k=3$）的历史动量等。 3\. 提示：- 以下信息提供了过去几天股票价格波动的总结，即股票的“动量”。它反映了股票的趋势。动量基于这样一个想法，即过去表现好的证券将继续表现好，而表现差的证券将继续表现差。
    4\. 输出：- (1). 2022年10月25日，TSLA的每日调整收盘价为{$222.42}。 - (2). 训练：2022年10月25日，TSLA的动量，指示为当前和下一交易日之间的价格差，为{$2.22}。测试：2022年10月25日，TSLA的历史动量，通过过去{3}天的累积对数回报测量，达到了{7.05%}。</foreignobject></g></g></svg>'
- en: 'Figure 4: First section of FinMem’s workflow for perceiving and processing
    multi-sourced information from market environment.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4：FinMem 工作流的第一部分，用于感知和处理来自市场环境的多源信息。  '
- en: '<svg class="ltx_picture ltx_align_left ltx_centering" height="696.29" id="A4.F5.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,696.29) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 681.95)"><foreignobject color="#FFFFFF"
    height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="559.03">Reflect</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject
    color="#000000" height="664.18" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="559.03">1\. Operations:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture ltx_align_left ltx_centering" height="696.29" id="A4.F5.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,696.29) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 20.48 681.95)"><foreignobject color="#FFFFFF"
    height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="559.03">反射</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.48 7.5)"><foreignobject
    color="#000000" height="664.18" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="559.03">1\. 操作：</foreignobject></g>
- en: 'Train: - Infer the reasoning from the retrieved memories insights for the recommended
    trading actions the increase or decrease of the trading stock price. Test: - Generate
    recommended trading actions.   - Infer the reasoning for making such trading action.
    Train & Test: - Track the memory insight IDs that contributed to the current trading
    decision. 2\. Range: Interpretation of observed market indicators and top $k$
    insights from each layer of the long-term memory database. 3\. Prompts:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '训练：- 推断从检索到的记忆洞察中获取推荐的交易操作的推理，涉及交易股票价格的上涨或下跌。 测试：- 生成推荐的交易操作。   - 推断做出该交易操作的推理。
    训练与测试：- 跟踪对当前交易决策有贡献的记忆洞察 ID。  '
- en: 'Train: Given the following information, can you explain why the financial market
    fluctuation from the current day to the next day behaves like this? Summarize
    the reason for the decision. You should provide summary information and the IDs
    of the information to support your summary. Test: Given the information, can you
    make an investment decision? Just summarize the reason for the decision. Consider
    only the available short-term information, the mid-term information, the long-term
    information, and the reflection-term information. Consider the momentum of the
    historical stock price. Also, consider how much share of the stock the investor
    holds now. You should provide exactly one of the following investment decisions:
    buy or sell. You could go with the ’hold’ option if necessary. You also need to
    provide the IDs of the information to support your decision. 4\. Outputs:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '训练：给定以下信息，您能解释为什么从当前日期到次日期的金融市场波动表现如此吗？总结决策的原因。您应提供总结信息以及支持您总结的信息的 ID。 测试：给定信息，您能做出投资决策吗？仅需总结决策的原因。仅考虑可用的短期信息、中期信息、长期信息和反思期信息。考虑历史股票价格的动量。同时，考虑投资者当前持有的股票份额。您应提供以下投资决策之一：买入或卖出。必要时可以选择“持有”选项。您还需要提供支持您决策的信息的
    ID。  '
- en: 'Train: - Recommended Action Reason: The recommended trading action is ’Buy’.
    This can be attributed to positive market sentiment driven by a range of favorable
    factors. Notably, Tesla’s strong battery supply chain, effective market expansion
    plans in Germany, and its ability to maintain market strength despite potential
    competitive threats positively influenced investor confidence, contributing to
    the stock price rise. - Reflected Contributed Insights IDs: {261, 278, 275, 274,
    161,…} Test: - Trading Action: {Buy} - Recommended Action Reason: Considering
    the short-term positive revenue growth, higher Model 3/Y and Model S/X deliveries,
    positive free cash flow, and increased cash and cash equivalents, Tesla appears
    to have strong financial health. The momentum being positive, it also encourages
    a risk-seeking strategy. The significant positive signs from news such as the
    imminent Q3 earnings add to the favorable view of the investment. Despite the
    mid-term neutral sentiment, long-term information shows only marginal drops and
    the stock is still looking strong overall. These, along with positive reflection-term
    information, form the reasoning behind the ’buy’ decision… - Reflected Contributed
    Insights IDs: {261, 278, 275, 274, 161,…}</foreignobject></g></g></svg>'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 训练： - 推荐交易行为理由：推荐的交易行为是“买入”。这可以归因于由一系列有利因素推动的积极市场情绪。特别是，特斯拉强大的电池供应链、在德国有效的市场扩展计划，以及其尽管面临潜在竞争威胁仍能维持市场优势的能力，积极影响了投资者信心，从而促使股价上涨。
    - 反映的贡献见解 ID：{261, 278, 275, 274, 161,…} 测试： - 交易行为：{买入} - 推荐交易行为理由：考虑到短期内的积极收入增长、更高的
    Model 3/Y 和 Model S/X 交付量、积极的自由现金流以及增加的现金及现金等价物，特斯拉似乎具有强劲的财务健康状况。由于势头积极，这也鼓励采取风险偏好的策略。新闻中诸如即将公布的
    Q3 财报等重要积极信号，进一步加强了对该投资的有利看法。尽管中期情绪保持中性，长期信息显示股价仅有轻微下跌，整体仍然强劲。这些因素，加上积极的反思期信息，构成了“买入”决策的推理依据…
    - 反映的贡献见解 ID：{261, 278, 275, 274, 161,…}
- en: 'Figure 5: Second section of FinMem’s workflow for generating trading action,
    reasoning and reflection.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：FinMem 生成交易行为、推理和反思的工作流程第二部分。
