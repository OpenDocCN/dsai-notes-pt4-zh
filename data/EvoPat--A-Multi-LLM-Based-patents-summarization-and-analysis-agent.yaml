- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 11:43:56'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:43:56
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'EvoPat: A Multi-LLM-Based patents summarization and analysis agent'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EvoPat：基于多大语言模型的专利摘要和分析代理
- en: 来源：[https://arxiv.org/html/2412.18100/](https://arxiv.org/html/2412.18100/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2412.18100/](https://arxiv.org/html/2412.18100/)
- en: Suyuan Wang, Xueqian Yin, Menghao Wang, Ruofeng Guo & Kai Nan
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 王素源，尹学乾，王梦豪，郭若峰 & 南凯
- en: SynMatAI Tech Inc
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: SynMatAI 科技公司
- en: kainan@synmatai.com
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: kainan@synmatai.com
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The rapid growth of scientific techniques and knowledge is reflected in the
    exponential increase in new patents filed annually. While these patents drive
    innovation, they also present significant burden for researchers and engineers,
    especially newcomers. To avoid the tedious work of navigating a vast and complex
    landscape to identify trends and breakthroughs, researchers urgently need efficient
    tools to summarize, evaluate, and contextualize patents, revealing their innovative
    contributions and underlying scientific principles. To address this need, we present
    *EvoPat*, a multi-LLM-based patent agent designed to assist users in analyzing
    patents through Retrieval-Augmented Generation (RAG) [[1](https://arxiv.org/html/2412.18100v1#bib.bib1)]
    and advanced search strategies. *EvoPat* leverages multiple Large Language Models
    (LLMs), each performing specialized roles such as planning, identifying innovations,
    and conducting comparative evaluations. The system integrates data from local
    databases, including patents, literature, product catalogous, and company repositories,
    and online searches to provide up-to-date insights. The ability to collect information
    not included in original database automatically is also implemented. Through extensive
    testing in the natural language processing (NLP) domain, we demonstrate that *EvoPat*
    outperforms GPT-4 [[2](https://arxiv.org/html/2412.18100v1#bib.bib2)] in tasks
    such as patent summarization, comparative analysis, and technical evaluation.
    *EvoPat* represents a significant step toward creating AI-powered tools that empower
    researchers and engineers to efficiently navigate the complexities of the patent
    landscape.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 科技和知识的快速增长体现在每年申请的新专利数量的指数级增长。虽然这些专利推动了创新，但它们也给研究人员和工程师，尤其是新手，带来了巨大的负担。为了避免在庞大而复杂的专利领域中进行繁琐的导航，识别趋势和突破，研究人员迫切需要高效的工具来总结、评估和理解专利，从而揭示其创新贡献和潜在的科学原理。为了解决这一需求，我们提出了*EvoPat*，一种基于多大语言模型的专利代理，旨在通过检索增强生成（RAG）[[1](https://arxiv.org/html/2412.18100v1#bib.bib1)]和先进的搜索策略，帮助用户分析专利。*EvoPat*利用多个大语言模型（LLMs），每个模型执行特定的角色，如规划、识别创新和进行比较评估。该系统整合了本地数据库中的数据，包括专利、文献、产品目录和公司存储库，以及在线搜索，以提供最新的见解。系统还实现了自动收集原始数据库中未包含的信息的能力。通过在自然语言处理（NLP）领域的广泛测试，我们证明了*EvoPat*在专利摘要、比较分析和技术评估等任务中优于GPT-4
    [[2](https://arxiv.org/html/2412.18100v1#bib.bib2)]。*EvoPat*代表了朝着创建由人工智能驱动的工具迈出的重要一步，这些工具能够帮助研究人员和工程师高效地驾驭专利领域的复杂性。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Patents serve as critical repositories for technical innovation, detailing unique
    methodologies, designs, and applications. However, the explosion of intellectual
    property information has brought both opportunities and challenges for researchers
    and practitioners seeking to retrieve, analyze, and utilize patent knowledge.
    A tool to efficiently distill key insights from patents, such as identifying innovations,
    analyzing strengths and weaknesses, and comparing them with related patents is
    urgently needed. Nowadays, it is possible to craft such tools using artificial
    intelligence technology.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 专利是技术创新的重要载体，详细描述了独特的方法、设计和应用。然而，知识产权信息的爆炸性增长为研究人员和从业者带来了机遇与挑战，尤其是在检索、分析和利用专利知识方面。迫切需要一种工具，能够高效提取专利中的关键信息，如识别创新、分析优缺点，并将其与相关专利进行比较。如今，利用人工智能技术，已经可以开发出这样的工具。
- en: As the most potential member of artificial intelligence, Large Language Models
    (LLMs) are transformative tools for processing and understanding complex information
    across various domains [[3](https://arxiv.org/html/2412.18100v1#bib.bib3), [4](https://arxiv.org/html/2412.18100v1#bib.bib4)].
    Their ability to comprehend nuanced textual data, synthesize insights, and perform
    comparative analyses makes them particularly well-suited for patent analysis.
    Although recent advancements in LLM-based systems have demonstrated their potential
    in summarizing academic articles and generating research ideas, their application
    to the patent domain remains underexplored [[5](https://arxiv.org/html/2412.18100v1#bib.bib5)].
    Existing systems for patent analysis often focus on single-dimensional tasks [[6](https://arxiv.org/html/2412.18100v1#bib.bib6)],
    such as keyword extraction or text summarization, failing to provide a comprehensive,
    structured understanding of the patent’s content and its relationship to other
    patents.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作为人工智能中最具潜力的成员，大型语言模型（LLMs）是处理和理解各领域复杂信息的变革性工具[[3](https://arxiv.org/html/2412.18100v1#bib.bib3),
    [4](https://arxiv.org/html/2412.18100v1#bib.bib4)]。它们理解细微文本数据、综合洞察并进行对比分析的能力，使其特别适合用于专利分析。尽管基于LLM的系统在总结学术文章和生成研究思路方面已显示出潜力，但它们在专利领域的应用仍然未得到充分探索[[5](https://arxiv.org/html/2412.18100v1#bib.bib5)]。现有的专利分析系统通常专注于单一维度的任务[[6](https://arxiv.org/html/2412.18100v1#bib.bib6)]，如关键词提取或文本总结，未能提供对专利内容及其与其他专利关系的全面、结构化理解。
- en: To address these challenges, we introduce a multi-agent architecture that leverages
    the collaborative power of multiple LLMs to provide a comprehensive understanding
    of patents is required needily. The system is designed to analyze patent content
    holistically, extracting key innovations, pinpointing technical difficulties,
    identifying strengths and weaknesses, and performing horizontal comparisons with
    similar patents. Additionally, it offers structured summaries tailored to various
    user needs, including researchers, industry practitioners, and intellectual property
    analysts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，我们提出了一种多智能体架构，利用多个大型语言模型（LLMs）的协作力量，提供对专利全面的理解。该系统旨在从整体上分析专利内容，提取关键创新，找出技术难点，识别优劣势，并与相似专利进行横向对比。此外，它还提供根据不同用户需求量身定制的结构化总结，包括研究人员、行业从业者和知识产权分析师。
- en: Our architecture combines task specialization and model collaboration to overcome
    key limitations of traditional systems. By assigning specific roles to individual
    LLMs, such as innovation identification or comparative analysis. Communication
    between these roles is enabled to guarantee the agents deliver detailed, multidimensional
    insights into patent content [[7](https://arxiv.org/html/2412.18100v1#bib.bib7)].
    Furthermore, the system integrates contextual retrieval capabilities to ensure
    accurate and relevant analyses, aligning with the unique requirements of patent
    evaluation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的架构结合了任务专门化和模型协作，以克服传统系统的关键局限性。通过为单个LLM分配特定角色，如创新识别或对比分析，实现这些角色之间的通信，确保各智能体能够提供对专利内容的详细、多维度的洞察[[7](https://arxiv.org/html/2412.18100v1#bib.bib7)]。此外，该系统集成了上下文检索功能，确保准确且相关的分析，符合专利评估的独特需求。
- en: 'This work represents a significant step forward in the application of AI to
    intellectual property management, providing a robust framework for extracting
    actionable knowledge from patents. Our contributions include:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作代表了人工智能在知识产权管理应用中的重要进展，提供了一个强大的框架，用于从专利中提取可操作的知识。我们的贡献包括：
- en: The design of a multi-agent LLM architecture for comprehensive patent analysis.
    Development of techniques for identifying innovations, challenges, and comparative
    insights across patents. Demonstration of the system’s capabilities through real-world
    patent data, showcasing its effectiveness in improving patent understanding and
    fostering innovation. In the following sections, we elaborate on the system architecture,
    methodologies, and experimental evaluations, highlighting its transformative potential
    in the field of patent analysis.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为全面的专利分析设计多智能体LLM架构。开发用于识别创新、挑战以及跨专利的对比洞察的技术。通过实际专利数据展示系统的能力，展示其在提高专利理解和促进创新方面的有效性。在接下来的章节中，我们将详细阐述系统架构、方法论和实验评估，突显其在专利分析领域的变革潜力。
- en: Related work
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 相关工作
- en: The advent of large language models (LLMs) has significantly impacted various
    scientific domains due to their unique ability to generate coherent summaries
    and extract key insights from large volumes of text [[8](https://arxiv.org/html/2412.18100v1#bib.bib8),
    [9](https://arxiv.org/html/2412.18100v1#bib.bib9)]. In the field of patents, tasks
    such as patent analysis and generation have become increasingly specialized, encompassing
    areas like quality assessment, patent writing, and more [[10](https://arxiv.org/html/2412.18100v1#bib.bib10)].
    By leveraging the capabilities of advanced LLMs, pre-trained on vast yet standard
    datasets and enhanced with specialized prompts, researchers have developed several
    tools to address patent-related challenges, improving both precision and efficiency
    compared to traditional methods.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）的出现对多个科学领域产生了显著影响，因为它们独特的能力能够生成连贯的总结并从大量文本中提取关键信息[[8](https://arxiv.org/html/2412.18100v1#bib.bib8),
    [9](https://arxiv.org/html/2412.18100v1#bib.bib9)]。在专利领域，专利分析和生成等任务变得越来越专业化，涵盖了如质量评估、专利撰写等多个领域[[10](https://arxiv.org/html/2412.18100v1#bib.bib10)]。通过利用先进LLM的能力，这些模型在经过广泛且标准化的数据集预训练，并辅以专业化的提示，研究人员已开发出多种工具，以应对与专利相关的挑战，与传统方法相比，精度和效率都有了显著提高。
- en: For instance, PatentGPT focuses on the Intellectual Property (IP) domain, utilizing
    the SMoE (Switching Mixture of Experts) architecture and a standardized procedure
    tailored for the patent landscape [[11](https://arxiv.org/html/2412.18100v1#bib.bib11)].
    This system outperformed GPT-4 on the 2019 China Patent Agent Qualification Examination,
    highlighting its ability to meet the unique requirements of IP-related tasks.
    Similarly, Trap et al. combine LLMs with TRIZ principles to identify contradictions
    within patents, further demonstrating the potential of LLMs for specialized patent
    analysis [[12](https://arxiv.org/html/2412.18100v1#bib.bib12)].
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，PatentGPT专注于知识产权（IP）领域，采用了SMoE（专家混合切换）架构，并针对专利领域量身定制了标准化的程序[[11](https://arxiv.org/html/2412.18100v1#bib.bib11)]。该系统在2019年中国专利代理人资格考试中超过了GPT-4，突显了它满足知识产权相关任务独特需求的能力。类似地，Trap等人将LLM与TRIZ原理结合，以识别专利中的矛盾，进一步展示了LLM在专利专业分析中的潜力[[12](https://arxiv.org/html/2412.18100v1#bib.bib12)]。
- en: Overall, LLM-based tools have demonstrated their potential not only to autonomously
    generate innovative patent ideas but also to conduct patent evaluations and comparisons
    across similar works. As the development of techniques like prompt engineering
    and role-based task allocation continues to improve, the performance of these
    systems is expected to further enhance, making them invaluable tools in the patent
    field.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，基于LLM的工具不仅展示了其自主生成创新专利创意的潜力，还能够对类似作品进行专利评估和比较。随着如提示工程和基于角色的任务分配等技术的发展，这些系统的性能预计将进一步提升，使其在专利领域中成为不可或缺的工具。
- en: 2 System Architecture
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 系统架构
- en: 'This section introduces *EvoPat*, a novel Multi-LLM-Based patents summarization
    and analysis agent that consists of three parts: *Data Preprocessing*, *Patent
    Analysis*, and *Output Integration*.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了*EvoPat*，一种新颖的基于多LLM的专利总结与分析代理，它由三个部分组成：*数据预处理*、*专利分析*和*输出整合*。
- en: '![Refer to caption](img/5aa5164eb1f0a015f0521c04a7d82909.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5aa5164eb1f0a015f0521c04a7d82909.png)'
- en: 'Figure 1: System overview of *EvoPat*. For a given patent, the process begins
    with preprocessing to extract and filter useful information, which is then embedded
    and stored in a database for easy retrieval in the future. Next, a multi-agent
    system is employed to analyze the patent from five distinct perspectives. Finally,
    the results are integrated and outputted as a PDF document for further examination.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：*EvoPat*系统概览。对于给定的专利，处理过程首先通过预处理提取和筛选有用信息，然后将其嵌入并存储在数据库中，以便将来方便检索。接下来，采用多代理系统从五个不同的角度对专利进行分析。最后，结果整合并输出为PDF文件，供进一步审查。
- en: 2.1 Overview
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 概览
- en: 'As shown in Fig [1](https://arxiv.org/html/2412.18100v1#S2.F1 "Figure 1 ‣ 2
    System Architecture ‣ EvoPat: A Multi-LLM-Based patents summarization and analysis
    agent"), *EvoPat* consists of three main phases: *Data Preprocessing*, *Patent
    Analysis*, and *Output Integration*. The input to *EvoPat* is the source patent
    in any field, and the output would be a report including analysis and summarization
    from multiple perspectives.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[1](https://arxiv.org/html/2412.18100v1#S2.F1 "图1 ‣ 2 系统架构 ‣ EvoPat：基于多LLM的专利摘要与分析代理")所示，*EvoPat*由三个主要阶段组成：*数据预处理*、*专利分析*和*输出整合*。*EvoPat*的输入是任何领域的源专利，输出将是一个包括多角度分析和总结的报告。
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Data Preprocessing: Given the source patent, we first need to extract and normalize
    text to remove irrelevant content. Finally, we embed the text and store it in
    the Faiss database for future retrieval.'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据预处理：给定源专利后，我们首先需要提取并规范化文本，去除无关内容。最后，我们将文本嵌入并存储在Faiss数据库中，以备将来检索。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Patent Analysis: Our agent would analyze and summarize the processed patent
    text from multiple perspectives using LLMs from 5 different roles: innovation
    points, implementation methods, technical details, horizontal comparisons, and
    academic directions.'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 专利分析：我们的代理将使用来自5个不同角色的LLM，从创新点、实施方法、技术细节、横向比较和学术方向等多个角度分析和总结处理后的专利文本。
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Output Integration: Our final step is to output a clear and easy-to-read patent
    report. We first convert the output into *Markdown* [[13](https://arxiv.org/html/2412.18100v1#bib.bib13)]
    format based on different levels, then integrate the output and unify the format,
    and finally generate a PDF file as the patent analysis report.'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出整合：我们的最终步骤是输出一个清晰且易于阅读的专利报告。我们首先基于不同的层级将输出转换为*Markdown*格式[[13](https://arxiv.org/html/2412.18100v1#bib.bib13)]，然后整合输出并统一格式，最后生成PDF文件作为专利分析报告。
- en: 2.2 Data Preprocessing
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 数据预处理
- en: Traditional LLMs make it difficult to read patent PDF information directly,
    and patents still contain some irrelevant information and characters. Therefore,
    to improve the effectiveness of patent analysis, we need to preprocess the source
    patent by extracting and filtering the text from it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的LLM很难直接读取专利PDF信息，而专利中仍然包含一些无关信息和字符。因此，为了提高专利分析的有效性，我们需要通过提取和过滤文本来预处理源专利。
- en: 2.2.1 Text Extraction
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 文本提取
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Text-based PDF: Most existing patents are in text PDF format, which has a neat
    patent structure and can be directly extracted using existing open source tools
    [[14](https://arxiv.org/html/2412.18100v1#bib.bib14), [15](https://arxiv.org/html/2412.18100v1#bib.bib15)],
    with low time consumption and generally accurate extraction results.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于文本的PDF：大多数现有的专利都是以文本PDF格式存在，具有整齐的专利结构，并且可以直接使用现有的开源工具[[14](https://arxiv.org/html/2412.18100v1#bib.bib14),
    [15](https://arxiv.org/html/2412.18100v1#bib.bib15)]进行提取，时间消耗低且提取结果通常较为准确。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Image-based PDF: A small number of patents are in image-based PDF format, characterized
    by each page of the PDF resembling an image. Traditional PDF extraction tools
    cannot extract the contents, and currently, they rely on Optical Character Recognition(OCR)
    technology for extraction. However, OCR has some issues, such as high time consumption
    and insufficient accuracy in extracting text.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于图像的PDF：少数专利以基于图像的PDF格式存在，其特点是每一页PDF看起来像一张图片。传统的PDF提取工具无法提取内容，目前依赖光学字符识别（OCR）技术进行提取。然而，OCR存在一些问题，例如高时间消耗和提取文本的准确性不足。
- en: 2.2.2 Text Filtering
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 文本过滤
- en: The text directly extracted from the patent contains irrelevant content, which
    can affect the accuracy performance of LLM, reducing its effectiveness of response.
    Moreover, it would increase the time cost of LLM’s response. Therefore, we need
    to use normalized regular expressions to filter the text. The normalization criteria
    are as follows.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从专利中直接提取的文本包含无关内容，这会影响LLM的准确性表现，降低其响应效果。此外，这还会增加LLM响应的时间成本。因此，我们需要使用规范化的正则表达式来过滤文本。规范化标准如下。
- en: •
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Remove special characters from the text except for normal punctuation marks.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从文本中移除特殊字符，保留正常的标点符号。
- en: •
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Remove redundant information from text, such as HTML tags and URL links.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从文本中移除冗余信息，例如HTML标签和URL链接。
- en: •
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Remove common stop words such as ’the’, ’is’, etc.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 移除常见的停用词，例如“the”、“is”等。
- en: 2.2.3 Text Embedding
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3 文本嵌入
- en: We need to store the patents in a database to facilitate subsequent retrieval.
    Since storing raw text directly would be inefficient, we opt to embed the text
    and store it in a vector database for a faster and more effective search.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将专利存储在数据库中，以便于后续检索。由于直接存储原始文本效率低下，我们选择将文本嵌入并存储在向量数据库中，以实现更快速、更高效的搜索。
- en: We use the embedding model of the *BGE-M3* [[16](https://arxiv.org/html/2412.18100v1#bib.bib16)]
    model. BGE-M3 is an open-source model designed for natural language processing
    (NLP) tasks, particularly in semantic search, vector-based retrieval, and other
    applications requiring dense embeddings. It leverages pretraining and fine-tuning
    to produce bidirectional embeddings for capturing rich semantic information in
    sentences or paragraphs. At the same time, it supports over 100 languages and
    has leading multilingual and cross-language search capabilities, making it very
    suitable for patent embedding in various languages.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用*BGE-M3* [[16](https://arxiv.org/html/2412.18100v1#bib.bib16)]模型的嵌入模型。BGE-M3是一个开源模型，专为自然语言处理（NLP）任务设计，特别是在语义搜索、基于向量的检索以及其他需要密集嵌入的应用中。它利用预训练和微调技术生成双向嵌入，以捕捉句子或段落中的丰富语义信息。同时，它支持超过100种语言，并具有领先的多语言和跨语言搜索能力，使其非常适合用于各种语言的专利嵌入。
- en: '*Faiss* [[17](https://arxiv.org/html/2412.18100v1#bib.bib17)] is an open-source
    library developed by Meta [[18](https://arxiv.org/html/2412.18100v1#bib.bib18)],
    designed for efficient similarity search and clustering of dense vectors at scale.
    It supports exact and approximate nearest neighbor (ANN) search, making it ideal
    for applications like recommendation systems, semantic search, and large-scale
    retrieval in natural language processing and computer vision. Faiss provides a
    variety of indexing methods to balance speed, memory usage, and accuracy. With
    GPU acceleration and support for billions of vectors, Faiss achieves high performance
    and scalability. Its integration with machine learning workflows and adaptability
    to diverse datasets make it a robust tool for patent retrieval systems.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*Faiss* [[17](https://arxiv.org/html/2412.18100v1#bib.bib17)] 是Meta公司开发的一个开源库[[18](https://arxiv.org/html/2412.18100v1#bib.bib18)]，旨在实现大规模的密集向量相似度搜索和聚类。它支持精确和近似最近邻（ANN）搜索，非常适合推荐系统、语义搜索以及自然语言处理和计算机视觉中的大规模检索等应用。Faiss
    提供了多种索引方法，能够平衡速度、内存使用和准确性。通过GPU加速和对数十亿向量的支持，Faiss 实现了高性能和可扩展性。它与机器学习工作流的集成以及对多样化数据集的适应性，使其成为专利检索系统的强大工具。'
- en: 2.3 Patent Analysis
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 专利分析
- en: In this phase, *EvoPat* can analyze, summarize, and expand patent content utilizing
    Large Language models to analyze patents from five different perspectives.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，*EvoPat* 可以利用大型语言模型从五个不同的角度分析、总结和扩展专利内容。
- en: 2.3.1 Long Context Input
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 长上下文输入
- en: Considering that the content of patent text extracted and filtered by us may
    still be too long, if used directly as contextual prompts for extensive model
    analysis, it will inevitably face the problem of model token limitations, resulting
    in higher costs and slower response times.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们提取和过滤的专利文本内容可能仍然过长，如果直接用作广泛模型分析的上下文提示，将不可避免地面临模型令牌限制的问题，导致更高的成本和更慢的响应时间。
- en: Currently, there are two different approaches to solving this problem. First,
    Autogen [[19](https://arxiv.org/html/2412.18100v1#bib.bib19)] introduced a method
    named *Transform Messages*. The *Transform Messages* capability is designed to
    modify incoming messages before the LLM processes them. This can include *Message
    History Limitation* and *Token Limitation*. For *Message HistoryLimitation*, this
    strategy reduces the length of conversation history by keeping only the most recent
    messages, focusing on essential context, and improving processing efficiency.
    For *Token Limitation*, this strategy ensures that the input adheres to the token
    limits by controlling both the per message and the total token counts. It calculates
    the number of tokens in each message and truncates those exceeding the set limit.
    Therefore, we can combine these two strategies to ensure robust handling of long
    conversation histories while adhering to model constraints.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，有两种不同的方法来解决这个问题。首先，Autogen [[19](https://arxiv.org/html/2412.18100v1#bib.bib19)]
    提出了一个名为*Transform Messages*的方法。*Transform Messages*功能旨在在LLM处理消息之前对传入的消息进行修改。这可以包括*消息历史限制*和*token限制*。对于*消息历史限制*，该策略通过只保留最新的消息来减少对话历史的长度，专注于重要的上下文，从而提高处理效率。对于*token限制*，该策略通过控制每条消息和总token数，确保输入符合token限制。它会计算每条消息中的token数量，并截断超出设定限制的部分。因此，我们可以结合这两种策略，以确保在遵守模型约束的同时，稳健地处理长时间的对话历史。
- en: However, despite the effectiveness of the *Transform Messages* strategy in addressing
    long-text input issues by segmenting and treating previous segments as historical
    context, it faces two major challenges. First, treating the entire text as historical
    information can lead to forgetting, especially when the text is excessively long.
    Large models may easily forget or overlook portions of the information, resulting
    in less accurate and detailed results. Second, this approach is costly, requiring
    sending many tokens each time, making the analysis more expensive and less efficient.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管*Transform Messages*策略通过将长文本输入分段并将之前的段落作为历史上下文来解决问题，取得了有效的效果，但它仍面临两个主要挑战。首先，将整个文本视为历史信息可能会导致遗忘，尤其是当文本过长时。大型模型可能会很容易忘记或忽略部分信息，导致结果不够准确和详细。其次，这种方法代价高昂，需要每次发送大量的tokens，从而使得分析变得更加昂贵且效率较低。
- en: As a result, recent work has started focusing on text compression, aiming to
    retain only the key and essential information in the text, thereby meeting the
    model’s token limit while maintaining analysis efficiency. *LLMLingua* [[20](https://arxiv.org/html/2412.18100v1#bib.bib20)]
    is a tool designed to compress prompts effectively, enhancing the efficiency and
    cost-effectiveness of LLM operations. Its goal is to construct a language exclusive
    to LLMs that may be hard for humans to grasp but can be easily understood by LLMs.
    Specifically, *LLMLingua* leverages well-aligned, smaller language models like
    GPT-2 Small [[21](https://arxiv.org/html/2412.18100v1#bib.bib21)] and LLaMA-7B
    [[22](https://arxiv.org/html/2412.18100v1#bib.bib22)] to identify and remove unimportant
    tokens from prompts. This process transforms the prompt into a compressed format
    that may be difficult for humans to interpret but remains entirely understandable
    for LLMs. The compressed prompts can be directly applied to black-box LLMs, achieving
    up to 20x reduction in prompt size while maintaining nearly identical performance
    in downstream tasks. This includes preserving LLM-specific capabilities such as
    in-context learning (ICL) and reasoning. Therefore, using *LLMLingua* can effectively
    solve the problem of excessively long patent content and better assist in LLMs
    analysis.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，近期的研究开始专注于文本压缩，目的是仅保留文本中的关键信息，从而在保持分析效率的同时满足模型的token限制。*LLMLingua* [[20](https://arxiv.org/html/2412.18100v1#bib.bib20)]
    是一个有效压缩提示的工具，旨在提高LLM操作的效率和成本效益。其目标是构建一种专为LLM设计的语言，这种语言可能对人类来说难以理解，但LLM却能轻松理解。具体而言，*LLMLingua*
    利用与之对齐的较小语言模型，如GPT-2 Small [[21](https://arxiv.org/html/2412.18100v1#bib.bib21)]
    和LLaMA-7B [[22](https://arxiv.org/html/2412.18100v1#bib.bib22)]，来识别并去除提示中的不重要token。这一过程将提示转化为一种压缩格式，可能难以为人类解读，但LLM完全能够理解。压缩后的提示可以直接应用于黑盒LLM，实现最多20倍的提示大小减少，同时在下游任务中保持几乎相同的性能。这包括保留LLM特有的功能，如上下文学习（ICL）和推理。因此，使用*LLMLingua*能够有效解决过长的专利内容问题，并更好地辅助LLM进行分析。
- en: 2.3.2 Multi-agent System
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 多智能体系统
- en: 'The automated multi-LLM-based patent analysis agent comprises a group of large
    language models.In this study, we utilize the advanced GPT-4o from the GPT-4 family
    [[2](https://arxiv.org/html/2412.18100v1#bib.bib2)], accessed via the OpenAI API[[23](https://arxiv.org/html/2412.18100v1#bib.bib23)].
    Each agent in the system is assigned a specific role and task, described by a
    unique configuration profile. The introduction of the agents in the team is as
    follows: Here, we take Patent *US20170263445A1* [[24](https://arxiv.org/html/2412.18100v1#bib.bib24)]as
    an example. Fig.[2](https://arxiv.org/html/2412.18100v1#S2.F2 "Figure 2 ‣ 2.3.2
    Multi-agent System ‣ 2.3 Patent Analysis ‣ 2 System Architecture ‣ EvoPat: A Multi-LLM-Based
    patents summarization and analysis agent") illustrates the workflow of the multi-agent
    system and the outputs provided by each scientist.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '基于自动化多大语言模型（LLM）的专利分析代理由一组大型语言模型组成。在本研究中，我们使用了来自GPT-4家族的先进GPT-4o [[2](https://arxiv.org/html/2412.18100v1#bib.bib2)]，通过OpenAI
    API[[23](https://arxiv.org/html/2412.18100v1#bib.bib23)]访问。系统中的每个代理都被分配了一个特定的角色和任务，任务由一个独特的配置文件描述。团队中各个代理的介绍如下：这里我们以专利*US20170263445A1*
    [[24](https://arxiv.org/html/2412.18100v1#bib.bib24)]为例。图[2](https://arxiv.org/html/2412.18100v1#S2.F2
    "Figure 2 ‣ 2.3.2 Multi-agent System ‣ 2.3 Patent Analysis ‣ 2 System Architecture
    ‣ EvoPat: A Multi-LLM-Based patents summarization and analysis agent")展示了多代理系统的工作流程以及各个科学家提供的输出。'
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Innovation Points Scientist: The Innovation Points Scientist is responsible
    for identifying the most valuable innovative methods within the patent. These
    innovations are critical for users as they determine whether they wish to explore
    the patent further.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创新点科学家：创新点科学家负责识别专利中最具价值的创新方法。这些创新对用户至关重要，因为它们决定了用户是否希望进一步探索该专利。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Implementation Method Scientist: The Implementation Method Scientist presents
    the patent’s implementation process to users. This helps users quickly understand
    the patent’s workflow and enables them to assess the complexity of its realization.'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实施方法科学家：实施方法科学家向用户展示专利的实施过程。这帮助用户快速理解专利的工作流程，并使他们能够评估其实现的复杂性。
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Technical Detail Scientist: The Technical Details Scientist provides users
    with supplementary technical details of the patent’s methods, such as specific
    numerical values, environmental conditions, and unique processes.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 技术细节科学家：技术细节科学家为用户提供专利方法的补充技术细节，例如具体的数值、环境条件和独特的工艺流程。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Horizontal Comparison Scientists: The Comparative Analysis Scientist offers
    the function in conducting internet searches for similar patents using the Google
    Patents API [[25](https://arxiv.org/html/2412.18100v1#bib.bib25)]. This enables
    a comparative analysis that highlights a patent’s uniqueness relative to others.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 横向比较科学家：比较分析科学家提供通过使用Google专利API [[25](https://arxiv.org/html/2412.18100v1#bib.bib25)]进行相似专利的互联网搜索功能。这使得比较分析能够突出专利相对于其他专利的独特性。
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Academic Direction Scientists: The Academic Direction Scientist is primarily
    responsible for conducting online searches for related papers using the Semantic
    Scholar API [[26](https://arxiv.org/html/2412.18100v1#bib.bib26)]. This API facilitates
    the analysis of current research trends in the academic community within this
    field, broadening the user’s perspective.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学术方向科学家：学术方向科学家主要负责通过使用Semantic Scholar API [[26](https://arxiv.org/html/2412.18100v1#bib.bib26)]进行相关论文的在线搜索。该API有助于分析学术界在该领域的当前研究趋势，拓宽用户的视野。
- en: 'As shown in Fig.[2](https://arxiv.org/html/2412.18100v1#S2.F2 "Figure 2 ‣ 2.3.2
    Multi-agent System ‣ 2.3 Patent Analysis ‣ 2 System Architecture ‣ EvoPat: A Multi-LLM-Based
    patents summarization and analysis agent"), the entire process starts with the
    Innovation Scientist and concludes with the Academic Direction Scientist. Each
    scientist analyzes the patent from a distinct perspective, and their contributions
    are all critical. Together, their responses form a detailed yet concise patent
    analysis, enabling users to understand the patent quickly and effectively while
    avoiding extensive text reading. This significantly enhances the efficiency of
    patent review. Inspired by the work of Ghafarollahi et al. [[27](https://arxiv.org/html/2412.18100v1#bib.bib27)],
    we can group these scientists into a single team, allowing them to share all content
    generated during prior interactions. This approach models the negotiation process
    through multiple iterations during reasoning and problem-solving, offering a more
    refined reasoning method compared to traditional zero-shot answers generated by
    AI systems. This methodology holds significant potential in the scientific domain.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [2](https://arxiv.org/html/2412.18100v1#S2.F2 "Figure 2 ‣ 2.3.2 Multi-agent
    System ‣ 2.3 Patent Analysis ‣ 2 System Architecture ‣ EvoPat: A Multi-LLM-Based
    patents summarization and analysis agent") 所示，整个过程从创新科学家开始，到学术方向科学家结束。每位科学家从不同的角度分析专利，他们的贡献都至关重要。通过他们的共同努力，产生了既详细又简明的专利分析，使得用户能够快速有效地理解专利，而无需大量阅读文本。这显著提高了专利审查的效率。受到
    Ghafarollahi 等人 [[27](https://arxiv.org/html/2412.18100v1#bib.bib27)] 的启发，我们可以将这些科学家归为一个团队，使他们能够共享先前交互过程中生成的所有内容。这种方法通过多次迭代的推理和问题解决过程模拟了谈判过程，相较于传统的零-shot
    AI 系统生成的答案，它提供了更精细的推理方法。这一方法在科学领域具有重要的潜力。'
- en: It has been demonstrated that the multi-agent approach is more effective and
    detailed than directly tasking a single agent with scientific analysis. By breaking
    the process into adjustable sub-tasks, this method addresses the inherent token
    limitations of LLMs, which often lead to incomplete responses. To overcome this
    issue, we identified the five most critical modules in patent analysis. Using
    the multi-agent approach, we provided a more comprehensive and detailed analysis
    of patents, enabling a more effective exploration of the vast knowledge landscape
    within patents.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 已经证明，采用多智能体方法比直接让单一智能体进行科学分析更有效、更详细。通过将过程拆分为可调节的子任务，该方法解决了大语言模型固有的令牌限制问题，避免了常常导致的响应不完整的问题。为了克服这个问题，我们确定了专利分析中五个最关键的模块。利用多智能体方法，我们对专利进行了更全面、更详细的分析，使得能够更有效地探索专利中的广阔知识领域。
- en: '![Refer to caption](img/9bfb171911c26d2d5dba1c27bd84b599.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/9bfb171911c26d2d5dba1c27bd84b599.png)'
- en: 'Figure 2: An example of multi-agent system in *EvoPat*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：*EvoPat* 中多智能体系统的示例
- en: 2.3.3 Tool invoking
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3 工具调用
- en: Due to LLMs’ limited knowledge base, accessing data outside their training corpus
    often leads to hallucination, which is unacceptable for patent analysis tasks.
    Beyond local Retrieval-Augmented Generation(RAG) [[1](https://arxiv.org/html/2412.18100v1#bib.bib1)]
    methods, one of the most common approaches is to retrieve relevant knowledge by
    calling external APIs, effectively expanding the model’s knowledge base, reducing
    hallucination, and improving result reliability. In our work, we also leverage
    the Google Patents and Semantic Scholar APIs to retrieve related patents and papers.
    We adopted the AutoGen framework to register relevant tools for the agents. Each
    tool is defined as a Python function with a name, a description, and appropriately
    described input attributes, enabling the agents to call these tools accurately
    and effectively.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大语言模型（LLMs）知识库的局限性，访问训练语料库之外的数据常常导致幻觉现象，这在专利分析任务中是不可接受的。除了本地的检索增强生成（RAG）[[1](https://arxiv.org/html/2412.18100v1#bib.bib1)]方法外，最常见的做法之一是通过调用外部
    API 检索相关知识，有效地扩展模型的知识库，减少幻觉现象，并提高结果的可靠性。在我们的工作中，我们还利用了 Google Patents 和 Semantic
    Scholar API 来检索相关的专利和论文。我们采用了 AutoGen 框架来注册相关工具供智能体使用。每个工具都被定义为一个包含名称、描述和适当输入属性的
    Python 函数，使得智能体能够准确有效地调用这些工具。
- en: 2.4 Output Integration
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 输出集成
- en: 'To facilitate user reading, all agent responses will be standardized into Markdown
    format. Markdown, as a lightweight markup language, allows users to write documents
    in an easy-to-read and easy-to-write plain text format, which is then converted
    into valid HTML documents and ultimately transformed into a well-structured PDF
    file for further analysis and reading. The final document will include the following
    modules: abstract and innovations, implementation methods, technical details,
    comparative analysis, and academic direction.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便用户阅读，所有代理响应将标准化为Markdown格式。Markdown作为一种轻量级标记语言，允许用户以易读且易写的纯文本格式编写文档，随后将其转换为有效的HTML文档，最终转化为结构良好的PDF文件，以便进一步分析和阅读。最终文档将包括以下模块：摘要与创新、实施方法、技术细节、对比分析和学术方向。
- en: 3 Experiments
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验
- en: 'In this section, our experiments are centered on answering the following Research
    Questions (RQs):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们的实验围绕以下研究问题（RQ）展开：
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ1: How does *EvoPat* perform in patent analysis?'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ1：*EvoPat*在专利分析中的表现如何？
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ2: How significant is the impact of LLMLingua and Transform Messages on patent
    analysis?'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ2：LLMLingua和Transform Messages对专利分析的影响有多大？
- en: 3.1 Experiment Settings
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 实验设置
- en: 3.1.1 Dataset
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 数据集
- en: 'We collected 5000 patents from the past decade in the field of science and
    engineering from Google Patents as the dataset for our experiments, covering four
    languages: Chinese, English, Japanese, and Korean. Google Patents is a comprehensive
    patent database that includes the majority of patents worldwide. Its well-structured
    indexing facilitates efficient searches, and it provides high-quality original
    patent texts for download, making it an ideal resource for evaluating *EvoPat*.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从Google Patents收集了过去十年在科学和工程领域的5000项专利作为实验数据集，涵盖了四种语言：中文、英文、日文和韩文。Google Patents是一个全面的专利数据库，包含了全球大部分的专利。其结构化良好的索引便于高效搜索，并提供高质量的原始专利文本供下载，是评估*EvoPat*的理想资源。
- en: 3.1.2 Implementations
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 实现
- en: We run all experiments on a machine with 128G RAM, 16 cores of CPU and a RTX
    4090 GPU. Phases of *EvoPat* are implemented with OpenAI, BGE-M3, and AutoGen.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在一台配置为128G内存、16核CPU和RTX 4090 GPU的机器上运行所有实验。*EvoPat*的各个阶段通过OpenAI、BGE-M3和AutoGen实现。
- en: 3.1.3 Metrics
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 评估指标
- en: In the field of automatic text summarization, evaluating the quality of a generated
    summary typically involves comparing it against a set of reference summaries,
    commonly known as gold summaries. Among the most widely used evaluation metrics
    is Recall-Oriented Understudy for Gisting Evaluation (ROUGE) [[28](https://arxiv.org/html/2412.18100v1#bib.bib28)],
    a comprehensive suite of metrics designed to quantify the overlap of n-grams (word
    sequences of length n) between generated and reference summaries. ROUGE has gained
    popularity for its simplicity, effectiveness, and strong correlation with human
    judgment in summarization tasks. Notably, *ROUGE-1*, *ROUGE-2*, and *ROUGE-L*
    are frequently employed to assess both extractive and abstractive summarization
    systems.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动文本摘要领域，评估生成摘要的质量通常涉及将其与一组参考摘要进行比较，这些参考摘要通常被称为“黄金摘要”。其中最广泛使用的评估指标之一是面向召回的摘要评估指标（ROUGE）[[28](https://arxiv.org/html/2412.18100v1#bib.bib28)]，这是一个综合性评估工具，旨在量化生成摘要和参考摘要之间n-gram（长度为n的词序列）的重叠情况。ROUGE因其简单、有效以及与人工判断在摘要任务中的强相关性而广受欢迎。特别是，*ROUGE-1*、*ROUGE-2*和*ROUGE-L*常被用来评估提取式和抽象式摘要系统。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*ROUGE-1* : *ROUGE-1* evaluates the overlap of unigrams (single words) between
    a generated summary and its reference counterpart. It quantifies the shared words
    between the two summaries, providing an indication of the extent to which the
    generated summary reflects the content of the reference summary.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ROUGE-1*：*ROUGE-1*评估生成摘要与参考摘要之间的单字词重叠情况。它量化了两个摘要中共享的词语，从而提供生成摘要与参考摘要内容反映程度的指示。'
- en: '|  | $ROUGE-1=\frac{\sum_{w\in\text{generated}}\text{Count}_{\text{match}}(w)}{\sum_%
    {w\in\text{reference}}\text{Count}(w)}$ |  | (1) |'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $ROUGE-1=\frac{\sum_{w\in\text{generated}}\text{Count}_{\text{match}}(w)}{\sum_{w\in\text{reference}}\text{Count}(w)}$
    |  | (1) |'
- en: 'Where:'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中：
- en: –
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $\text{Count}_{\text{match}}(w)$ is the number of times word $w$ appears in
    both the generated and reference summaries.
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\text{Count}_{\text{match}}(w)$是词语$w$在生成摘要和参考摘要中都出现的次数。
- en: –
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $\text{Count}(w)$ is the total number of times word $w$ appears in the reference
    summary.
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\text{Count}(w)$是词语$w$在参考摘要中出现的总次数。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*ROUGE-2* : *ROUGE-2*, akin to *ROUGE-1*, measures the overlap of bigrams (sequences
    of two consecutive words) between the generated and reference summaries. By assessing
    the presence of common word pairs, this metric goes beyond individual word matching
    to evaluate the generated summary’s ability to preserve both fluency and higher-order
    content structure, offering a more nuanced assessment than *ROUGE-1*.'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ROUGE-2* ：*ROUGE-2* 类似于 *ROUGE-1*，衡量生成摘要和参考摘要之间的大词组（由两个连续词组成的序列）的重叠情况。通过评估公共词对的出现，这个指标不仅超越了单一词匹配，还评估了生成摘要保留流畅性和高阶内容结构的能力，提供了比
    *ROUGE-1* 更细致的评估。'
- en: '|  | $ROUGE-2=\frac{\sum_{\text{bigram }(w_{1},w_{2})\in\text{generated}}\text{Count%
    }_{\text{match}}(w_{1},w_{2})}{\sum_{\text{bigram }(w_{1},w_{2})\in\text{% reference}}\text{Count}(w_{1},w_{2})}$
    |  | (2) |'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $ROUGE-2=\frac{\sum_{\text{bigram }(w_{1},w_{2})\in\text{generated}}\text{Count%
    }_{\text{match}}(w_{1},w_{2})}{\sum_{\text{bigram }(w_{1},w_{2})\in\text{% reference}}\text{Count}(w_{1},w_{2})}$
    |  | (2) |'
- en: 'Where:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中：
- en: –
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $\text{Count}_{\text{match}}(w_{1},w_{2})$ refers to the number of times the
    bigram $(w_{1},w_{2})$ appears in both the reference and generated summaries.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\text{Count}_{\text{match}}(w_{1},w_{2})$ 指的是大词组 $(w_{1},w_{2})$ 在参考摘要和生成摘要中同时出现的次数。
- en: –
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $\text{Count}(w_{1},w_{2})$ refers to the total number of occurrences of the
    bigram $(w_{1},w_{2})$ in the reference summary.
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\text{Count}(w_{1},w_{2})$ 指的是参考摘要中大词组 $(w_{1},w_{2})$ 的出现次数。
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*ROUGE-L* : *ROUGE-L* evaluates the Longest Common Subsequence (LCS) between
    a generated summary and its reference counterpart. In contrast to *ROUGE-1* and
    *ROUGE-2*, which emphasize n-gram overlap, *ROUGE-L* identifies the longest sequence
    of words shared by both summaries in their original order. By capturing structural
    similarity, this metric is especially effective for assessing the fluency and
    coherence of the generated summary.'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ROUGE-L* ：*ROUGE-L* 评估生成摘要与参考摘要之间的最长公共子序列（LCS）。与注重 n-gram 重叠的 *ROUGE-1* 和
    *ROUGE-2* 不同，*ROUGE-L* 识别两篇摘要在原始顺序中共享的最长词序列。通过捕捉结构相似性，该指标特别有效于评估生成摘要的流畅性和连贯性。'
- en: '|  | $ROUGE-L=\frac{\text{LCS length}}{\text{Reference length}}$ |  | (3) |'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $ROUGE-L=\frac{\text{LCS length}}{\text{Reference length}}$ |  | (3) |'
- en: 'Where:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中：
- en: –
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: LCS length is the length of the longest common subsequence between the generated
    and reference summaries.
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: LCS 长度是生成摘要与参考摘要之间的最长公共子序列长度。
- en: –
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: Reference length is the total number of words in the reference summary.
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参考长度是参考摘要中的总词数。
- en: 'BERTScore [[29](https://arxiv.org/html/2412.18100v1#bib.bib29)] is an embedding-based
    evaluation metric that builds upon METEOR [[30](https://arxiv.org/html/2412.18100v1#bib.bib30)].
    It leverages cosine similarity to measure the alignment between tokens or n-grams
    in the generated summary and those in the reference. The metric comprises three
    core components: Precision, Recall, and F1 score, each derived from the similarity
    of token embeddings produced by a pre-trained BERT model.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore [[29](https://arxiv.org/html/2412.18100v1#bib.bib29)] 是一种基于嵌入的评估指标，建立在
    METEOR [[30](https://arxiv.org/html/2412.18100v1#bib.bib30)] 基础上。它利用余弦相似度来衡量生成摘要中的标记或
    n-gram 与参考摘要中的对齐程度。该指标包括三个核心组成部分：Precision（精确度）、Recall（召回率）和 F1 分数，每个分数均来自预训练
    BERT 模型生成的标记嵌入的相似度。
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*BERTScore Precision* : BERTScore Precision represents the average cosine similarity
    between each token in the generated output and its closest counterpart in the
    reference summary. A higher cosine similarity indicates a greater degree of alignment
    between the token in the generated summary and its corresponding token in the
    reference.'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*BERTScore Precision* ：BERTScore Precision 表示生成输出中每个标记与参考摘要中最接近的对应标记之间的平均余弦相似度。更高的余弦相似度表示生成摘要中的标记与参考摘要中相应标记的对齐程度更高。'
- en: '|  | $\text{BERTScore Precision}=\frac{1}{N_{\text{generated}}}\sum_{i=1}^{N_{\text{%
    generated}}}\cos(\mathbf{v}_{\text{generated}}^{(i)},\mathbf{v}_{\text{% reference}}^{(i)^{*}})$
    |  | (4) |'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\text{BERTScore Precision}=\frac{1}{N_{\text{generated}}}\sum_{i=1}^{N_{\text{%
    generated}}}\cos(\mathbf{v}_{\text{generated}}^{(i)},\mathbf{v}_{\text{% reference}}^{(i)^{*}})$
    |  | (4) |'
- en: 'Where:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中：
- en: –
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $N_{\text{generated}}$ is the total number of tokens in the generated summary.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $N_{\text{generated}}$ 是生成摘要中的总标记数。
- en: –
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $\cos(\mathbf{v}_{\text{generated}}^{(i)},\mathbf{v}_{\text{reference}}^{(i)^{*%
    }})$ represents the cosine similarity between the embedding of the $i$-th token
    in the generated summary and its nearest match in the reference summary (denoted
    as $i^{*}$).
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\cos(\mathbf{v}_{\text{generated}}^{(i)},\mathbf{v}_{\text{reference}}^{(i)^{*%
    }})$ 表示生成摘要中第 $i$ 个标记的嵌入向量与参考摘要中其最接近匹配项的余弦相似度（记作 $i^{*}$）。
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*BERTScore Recall* : BERTScore Recall is defined as the average cosine similarity
    between each token in the reference summary and its most similar counterpart in
    the generated output. This metric evaluates the extent to which the generated
    summary effectively captures the tokens from the reference summary.'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*BERTScore 召回率* : BERTScore 召回率定义为参考摘要中每个标记与生成输出中其最相似的对应标记之间的平均余弦相似度。该指标评估生成摘要在多大程度上有效地捕获了参考摘要中的标记。'
- en: '|  | $\text{BERTScore Recall}=\frac{1}{N_{\text{reference}}}\sum_{i=1}^{N_{\text{%
    reference}}}\cos(\mathbf{v}_{\text{reference}}^{(i)},\mathbf{v}_{\text{% generated}}^{(i)^{*}})$
    |  | (5) |'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\text{BERTScore 召回率}=\frac{1}{N_{\text{reference}}}\sum_{i=1}^{N_{\text{%
    reference}}}\cos(\mathbf{v}_{\text{reference}}^{(i)},\mathbf{v}_{\text{% generated}}^{(i)^{*}})$
    |  | (5) |'
- en: 'Where:'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中：
- en: –
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $N_{\text{reference}}$ is the total number of tokens in the reference summary.
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $N_{\text{reference}}$ 是参考摘要中标记的总数。
- en: –
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: $\cos(\mathbf{v}_{\text{reference}}^{(i)},\mathbf{v}_{\text{generated}}^{(i)^{*%
    }})$ represents the cosine similarity between the embedding of the $i$-th token
    in the reference summary and its nearest match in the generated summary.
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: $\cos(\mathbf{v}_{\text{reference}}^{(i)},\mathbf{v}_{\text{generated}}^{(i)^{*%
    }})$ 表示参考摘要中第 $i$ 个标记的嵌入与其在生成摘要中的最接近匹配之间的余弦相似度。
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '*BERTScore F1* : BertScore F1 is calculated as the harmonic mean of Precision
    and Recall, providing a balanced evaluation of these two metrics. It ensures that
    both the similarity between tokens in the generated and reference summaries, as
    well as the coverage of reference tokens, are adequately reflected.'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*BERTScore F1* : BERTScore F1 作为精确度和召回率的调和平均数，提供了这两个指标的平衡评估。它确保了生成摘要与参考摘要中标记之间的相似度以及参考标记的覆盖度得到了充分体现。'
- en: '|  | $\text{BERTScore F1}=2\times\frac{\text{BERTScore Precision}\times\text{%
    BERTScore Recall}}{\text{BERTScore Precision}+\text{BERTScore Recall}}$ |  | (6)
    |'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\text{BERTScore F1}=2\times\frac{\text{BERTScore 精确度}\times\text{BERTScore
    召回率}}{\text{BERTScore 精确度}+\text{BERTScore 召回率}}$ |  | (6) |'
- en: '3.2 RQ1: Evaluation of Patent Analysis'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '3.2 RQ1: 专利分析评估'
- en: 'We calculate the scores of patent analysis generated by EvoPat and GPT-4o based
    on the metrics in section 3.1.3\. The results are shown in Table [1](https://arxiv.org/html/2412.18100v1#S3.T1
    "Table 1 ‣ 3.2 RQ1: Evaluation of Patent Analysis ‣ 3 Experiments ‣ EvoPat: A
    Multi-LLM-Based patents summarization and analysis agent")'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '我们根据 3.1.3 节中的指标计算了 *EvoPat* 和 *GPT-4o* 生成的专利分析得分。结果如表 [1](https://arxiv.org/html/2412.18100v1#S3.T1
    "Table 1 ‣ 3.2 RQ1: Evaluation of Patent Analysis ‣ 3 Experiments ‣ EvoPat: A
    Multi-LLM-Based patents summarization and analysis agent") 所示。'
- en: 'Table 1: Evaluation comparison between EvoPat and GPT-4o.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：EvoPat 与 GPT-4o 的评估比较。
- en: '| Model | ROUGE-1 | ROUGE-2 | ROUGE-L | BERTScore Precision | BERTScore Recall
    | BERTScore F1 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | ROUGE-1 | ROUGE-2 | ROUGE-L | BERTScore 精确度 | BERTScore 召回率 | BERTScore
    F1 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| EvoPat | 0.2164 | 0.08152 | 0.2081 | 0.7856 | 0.7392 | 0.7616 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| EvoPat | 0.2164 | 0.08152 | 0.2081 | 0.7856 | 0.7392 | 0.7616 |'
- en: '| GPT-4o | 0.0745 | 0.0122 | 0.1079 | 0.7760 | 0.7332 | 0.7540 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 0.0745 | 0.0122 | 0.1079 | 0.7760 | 0.7332 | 0.7540 |'
- en: This demonstrates that the quality of patent analysis generated by *EvoPat*
    has significantly surpassed that of *GPT-4o*, particularly in terms of ROUGE score.
    The improvement can be largely attributed to our Multi-LLM-Based patent analysis
    agent system, in which each agent focuses on a specific perspective, and agents
    collaborate by sharing historical information, thereby enhancing the quality and
    depth of the analysis. In contrast, *GPT-4o* is limited by its internal model
    and can only provide basic analysis.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，*EvoPat* 生成的专利分析质量显著超过了 *GPT-4o*，尤其是在 ROUGE 得分方面。这一改进主要归因于我们基于多重大语言模型（Multi-LLM）的专利分析代理系统，其中每个代理专注于一个特定视角，代理通过共享历史信息进行协作，从而提高了分析的质量和深度。相比之下，*GPT-4o*
    受限于其内部模型，只能提供基础的分析。
- en: However, the aforementioned metrics primarily assess the correlation between
    the generated content and the original text. Since *EvoPat* also performs in-depth
    analysis of the original patent and integrates online search and expansion through
    modules such as horizontal comparison and academic direction, these metrics fail
    to fully capture its performance. Consequently, further evaluation from the following
    perspectives is necessary.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，上述指标主要评估生成内容与原文之间的相关性。由于 *EvoPat* 还对原始专利进行了深入分析，并通过横向比较、学术方向等模块集成了在线搜索与扩展，这些指标未能完全反映其性能。因此，必须从以下角度进行进一步评估。
- en: •
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Informative: Measures the depth and breadth of information provided in the
    analysis.'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息量：衡量分析中提供的信息的深度和广度。
- en: •
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Rich: Assesses the diversity and multi-dimensionality of the analysis.'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 丰富性：评估分析的多样性和多维度性。
- en: •
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Coherent: Evaluates the logical structure and consistency of the analysis.'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一致性：评估分析的逻辑结构和连贯性。
- en: •
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Attributable: Ensures that the analysis is based on verifiable sources and
    evidence.'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可归因性：确保分析基于可验证的来源和证据。
- en: •
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Extensible: Measures whether the analysis incorporates supplementary content
    from external sources.'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可扩展性：衡量分析是否融合了来自外部来源的补充内容。
- en: 'Referring to previous work [[4](https://arxiv.org/html/2412.18100v1#bib.bib4),
    [31](https://arxiv.org/html/2412.18100v1#bib.bib31), [32](https://arxiv.org/html/2412.18100v1#bib.bib32)],
    in addition to evaluations conducted by large language models, we also had the
    patent analysis results evaluated by human experts. Specifically, we randomly
    sampled 100 patent analysis results in the photoresist and nanoimprint lithography
    fields. These results were evaluated by four experts specializing in these domains.
    The final average scores are presented in the table [2](https://arxiv.org/html/2412.18100v1#S3.T2
    "Table 2 ‣ 3.2 RQ1: Evaluation of Patent Analysis ‣ 3 Experiments ‣ EvoPat: A
    Multi-LLM-Based patents summarization and analysis agent") (with a maximum score
    of 5).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '参考之前的工作[[4](https://arxiv.org/html/2412.18100v1#bib.bib4)，[31](https://arxiv.org/html/2412.18100v1#bib.bib31)，[32](https://arxiv.org/html/2412.18100v1#bib.bib32)]，除了由大语言模型进行的评估外，我们还请人类专家对专利分析结果进行了评估。具体来说，我们随机抽取了100个光刻胶和纳米压印光刻领域的专利分析结果。这些结果由四位专注于这些领域的专家进行评估。最终的平均得分如表[2](https://arxiv.org/html/2412.18100v1#S3.T2
    "Table 2 ‣ 3.2 RQ1: Evaluation of Patent Analysis ‣ 3 Experiments ‣ EvoPat: A
    Multi-LLM-Based patents summarization and analysis agent")所示（最高得分为5）。'
- en: 'Table 2: Evaluation comparison between EvoPat and GPT-4o.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：EvoPat与GPT-4o的评估对比。
- en: '| Model | Informative | Rich | Coherent | Attributable | Extensible |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 信息量 | 丰富性 | 一致性 | 可归因性 | 可扩展性 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| EvoPat | 4.82 | 4.85 | 4.63 | 4.89 | 4.34 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| EvoPat | 4.82 | 4.85 | 4.63 | 4.89 | 4.34 |'
- en: '| GPT-4o | 4.13 | 3.95 | 4.55 | 4.72 | 2.79 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 4.13 | 3.95 | 4.55 | 4.72 | 2.79 |'
- en: '*EvoPat* clearly outperforms *GPT-4o* across all dimensions, particularly excelling
    in terms of informativeness, richness, and extensibility. As previously noted,
    *EvoPat*’s multi-agent approach to patent analysis, coupled with the additional
    insights derived from Google Patents and Semantic Scholar, greatly enhances the
    depth and quality of its analysis.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*EvoPat*在各个维度上明显优于*GPT-4o*，尤其在信息量、丰富性和可扩展性方面表现突出。如前所述，*EvoPat*采用的多代理专利分析方法，再加上来自Google
    Patents和Semantic Scholar的额外洞察，极大增强了其分析的深度和质量。'
- en: '3.3 RQ2: The Impact of Long-Text Processing'
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 RQ2：长文本处理的影响
- en: 'As discussed in Section 2.3.1, patent documents are often lengthy, frequently
    exceeding the token limits of large language models. Strategies such as message
    transformation and text compression can help mitigate this issue. The *Transform
    Messages* strategy involves limiting the number of historical tokens and segments,
    sending the text in smaller parts to the LLMs for analysis. While this approach
    is generally accurate and minimizes the risk of information loss, its main drawbacks
    are high costs and the potential for important historical context to be overlooked
    due to the length of the text. In contrast, *LLMLingua* is a well-established
    open-source text compression tool that effectively compresses text while preserving
    key information understandable by LLMs. This method not only reduces analysis
    costs but also enhances the efficiency of the analysis. Given that long-text processing
    primarily impacts ROUGE scores, as well as the Informative, Rich, and Attributable
    metrics, these indicators were selected for evaluation. The results are detailed
    in Table [3](https://arxiv.org/html/2412.18100v1#S3.T3 "Table 3 ‣ 3.3 RQ2: The
    Impact of Long-Text Processing ‣ 3 Experiments ‣ EvoPat: A Multi-LLM-Based patents
    summarization and analysis agent").'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '如2.3.1节所讨论，专利文件通常较长，常常超过大型语言模型的token限制。诸如信息变换和文本压缩等策略可以帮助缓解这一问题。*变换信息*策略涉及限制历史token和片段的数量，将文本分成较小的部分发送给LLM进行分析。虽然这种方法通常较为准确，并能最大程度地减少信息丢失的风险，但其主要缺点是高成本，并且由于文本长度过长，可能会忽略重要的历史上下文。相比之下，*LLMLingua*是一种成熟的开源文本压缩工具，能够有效地压缩文本，同时保留LLM能够理解的关键信息。这种方法不仅降低了分析成本，还提高了分析效率。由于长文本处理主要影响ROUGE得分，以及信息丰富性、丰富性和可归因性等指标，因此选择了这些指标进行评估。具体结果详见表[3](https://arxiv.org/html/2412.18100v1#S3.T3
    "Table 3 ‣ 3.3 RQ2: The Impact of Long-Text Processing ‣ 3 Experiments ‣ EvoPat:
    A Multi-LLM-Based patents summarization and analysis agent")。'
- en: 'Table 3: Evaluation comparison between EvoPat and GPT4.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：EvoPat与GPT4的评估对比。
- en: '| Strategy | ROUGE-1 | ROUGE-2 | ROUGE-L | Informative | Rich | Attributable
    |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | ROUGE-1 | ROUGE-2 | ROUGE-L | 信息丰富性 | 丰富性 | 可归因性 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Transform Message | 0.1815 | 0.06576 | 0.1722 | 4.68 | 4.81 | 4.76 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 变换信息 | 0.1815 | 0.06576 | 0.1722 | 4.68 | 4.81 | 4.76 |'
- en: '| LLMLingua | 0.2164 | 0.08152 | 0.2081 | 4.85 | 4.63 | 4.89 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| LLMLingua | 0.2164 | 0.08152 | 0.2081 | 4.85 | 4.63 | 4.89 |'
- en: It is evident that LLMLingua slightly outperforms the Transform Message strategy
    in managing long texts. As mentioned earlier, excessively lengthy historical information
    can cause large models to forget important context, diminishing their ability
    to analyze the patent and leading to the omission of critical details. In contrast,
    LLMLingua effectively compresses the text while preserving essential information
    that the model can process. While text compression may result in some loss of
    information and reduced readability for humans, it ensures that the large model
    can comprehend the text without the risk of forgetting. In practice, EvoPatent
    supports both methods for handling long-text inputs, with LLMLingua set as the
    default.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，LLMLingua在处理长文本方面略优于变换信息策略。如前所述，过长的历史信息会导致大型模型忘记重要的上下文，从而降低它们分析专利的能力，并可能遗漏关键信息。相比之下，LLMLingua能够有效地压缩文本，同时保留模型可以处理的重要信息。虽然文本压缩可能导致一些信息损失并降低人类的可读性，但它确保了大型模型能够理解文本而不会遗忘。在实际应用中，EvoPatent支持两种处理长文本输入的方法，其中LLMLingua为默认设置。
- en: 4 Conclusion and Discussion
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结论与讨论
- en: 'In this paper, we introduced *EvoPat*, a Multi-LLM-Based Patent Summarization
    and Analysis Agent. *EvoPat* is designed with three main components: Data Preprocessing,
    Patent Analysis, and Output Integration. This system preprocesses and embeds patent
    files, analyzes the novelty of proposals from both scientific and market perspectives,
    and generates comprehensive reports. These reports include reviews, novelty evaluations,
    and summaries, offering a holistic perspective on patent content. The unique architecture
    of *EvoPat*, which incorporates multiple specialized LLM systems, enables it to
    process and analyze thousands of patents within minutes. Extensive evaluations
    using diverse metrics and expert assessments demonstrate that *EvoPat* outperforms
    GPT-4 in key dimensions, including informativeness, richness, coherence, attribution,
    and extensibility.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了*EvoPat*，一种基于多种大型语言模型的专利摘要与分析代理。*EvoPat*的设计包含三个主要组件：数据预处理、专利分析和输出整合。该系统对专利文件进行预处理和嵌入，从科学和市场两个角度分析提案的新颖性，并生成综合报告。这些报告包括评审、新颖性评估和摘要，提供了对专利内容的全方位视角。*EvoPat*的独特架构结合了多个专门的LLM系统，使其能够在几分钟内处理和分析成千上万的专利。通过多种指标和专家评估的广泛测试表明，*EvoPat*在关键信息维度上超越了GPT-4，包括信息性、丰富性、一致性、归因性和可扩展性。
- en: Despite these achievements, *EvoPat* faces limitations that will pave the way
    for future work. One major challenge is data preprocessing, particularly with
    patent figures and multilingual text. Extracting meaningful connections between
    figures and content from PDF files remains a significant hurdle. Improving figure
    recognition and context alignment will be a priority. Another critical area of
    improvement is enhancing the connections between patents and academic publications.
    Identifying and explaining the scientific principles underlying patents requires
    robust knowledge graph construction and the integration of specialized agent roles.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了这些成就，*EvoPat*仍面临一些限制，这些限制将为未来的工作铺平道路。一个主要挑战是数据预处理，特别是与专利图表和多语言文本相关的内容。从PDF文件中提取图表与内容之间的有意义联系仍然是一个重要的难题。提高图表识别和上下文对齐将是重点之一。另一个关键改进领域是增强专利与学术出版物之间的联系。识别和解释专利背后的科学原理需要构建强大的知识图谱并整合专业代理角色。
- en: Additionally, the temporal gap between emerging scientific trends in publications
    and their subsequent appearance in patents necessitates advanced time-series algorithms.
    These algorithms will help *EvoPat* generate more precise and forward-looking
    reports while mitigating issues like AI hallucination. By addressing these challenges,
    *EvoPat* aims to further advance patent analysis and provide even greater value
    to researchers, engineers, and decision-makers.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，出版物中新兴科学趋势与其后在专利中出现之间的时间差，要求使用先进的时间序列算法。这些算法将帮助*EvoPat*生成更精确、更具前瞻性的报告，同时减轻AI幻觉等问题。通过解决这些挑战，*EvoPat*旨在进一步推动专利分析，并为研究人员、工程师和决策者提供更大的价值。
- en: References
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances
    in Neural Information Processing Systems, 33:9459–9474, 2020.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    等. 用于知识密集型自然语言处理任务的检索增强生成. 神经信息处理系统进展, 33:9459–9474, 2020.'
- en: '[2] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
    Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.
    Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
    Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, 等. GPT-4技术报告.
    arXiv 预印本 arXiv:2303.08774, 2023.'
- en: '[3] Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, and Sung Ju Hwang. Researchagent:
    Iterative research idea generation over scientific literature with large language
    models. arXiv preprint arXiv:2404.07738, 2024.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Jinheon Baek, Sujay Kumar Jauhar, Silviu Cucerzan, 和 Sung Ju Hwang. Researchagent:
    基于大型语言模型的科学文献迭代研究创意生成. arXiv 预印本 arXiv:2404.07738, 2024.'
- en: '[4] Griffin Adams, Alexander R Fabbri, Faisal Ladhak, Eric Lehman, and Noémie
    Elhadad. From sparse to dense: Gpt-4 summarization with chain of density prompting.
    In Proceedings of the Conference on Empirical Methods in Natural Language Processing.
    Conference on Empirical Methods in Natural Language Processing, page 68, 2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Griffin Adams, Alexander R Fabbri, Faisal Ladhak, Eric Lehman, 和 Noémie
    Elhadad. 从稀疏到密集：基于GPT-4的链式密度提示总结。在自然语言处理经验方法会议的论文集中。自然语言处理经验方法会议，页码68，2023.'
- en: '[5] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
    Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training
    language models to follow instructions with human feedback. Advances in neural
    information processing systems, 35:27730–27744, 2022.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
    Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray 等. 通过人类反馈训练语言模型以遵循指令。神经信息处理系统进展,
    35:27730–27744, 2022.'
- en: '[6] Jieh-Sheng Lee and Jieh Hsiang. Patent classification by fine-tuning bert
    language model. World Patent Information, 61:101965, 2020.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Jieh-Sheng Lee 和 Jieh Hsiang. 通过微调BERT语言模型进行专利分类。世界专利信息, 61:101965, 2020.'
- en: '[7] Nouf Ibrahim Altmami and Mohamed El Bachir Menai. Automatic summarization
    of scientific articles: A survey. Journal of King Saud University-Computer and
    Information Sciences, 34(4):1011–1028, 2022.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Nouf Ibrahim Altmami 和 Mohamed El Bachir Menai. 科学文章的自动总结：一项调查。沙特国王大学计算机与信息科学学报,
    34(4):1011–1028, 2022.'
- en: '[8] Feng Jiang, Kuang Wang, and Haizhou Li. Bridging research and readers:
    A multi-modal automated academic papers interpretation system. arXiv preprint
    arXiv:2401.09150, 2024.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Feng Jiang, Kuang Wang, 和 Haizhou Li. 桥接研究与读者：一种多模态自动化学术论文解读系统。arXiv 预印本
    arXiv:2401.09150, 2024.'
- en: '[9] Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang
    Xie, Binbin Lin, Xiaofei He, and Jieping Ye. Scipip: An llm-based scientific paper
    idea proposer. arXiv preprint arXiv:2410.23166, 2024.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang
    Xie, Binbin Lin, Xiaofei He, 和 Jieping Ye. Scipip: 基于LLM的科学论文创意提案工具。arXiv 预印本
    arXiv:2410.23166, 2024.'
- en: '[10] Lekang Jiang and Stephan Goetz. Artificial intelligence exploring the
    patent field. arXiv preprint arXiv:2403.04105, 2024.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Lekang Jiang 和 Stephan Goetz. 人工智能探索专利领域。arXiv 预印本 arXiv:2403.04105, 2024.'
- en: '[11] Zilong Bai, Ruiji Zhang, Linqing Chen, Qijun Cai, Yuan Zhong, Cong Wang,
    Yan Fang, Jie Fang, Jing Sun, Weikuan Wang, et al. Patentgpt: A large language
    model for intellectual property. arXiv preprint arXiv:2404.18255, 2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Zilong Bai, Ruiji Zhang, Linqing Chen, Qijun Cai, Yuan Zhong, Cong Wang,
    Yan Fang, Jie Fang, Jing Sun, Weikuan Wang 等. Patentgpt: 一种用于知识产权的大型语言模型。arXiv
    预印本 arXiv:2404.18255, 2024.'
- en: '[12] Stefan Trapp and Joachim Warschat. Llm-based extraction of contradictions
    from patents. In International TRIZ Future Conference, pages 3–19\. Springer,
    2024.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Stefan Trapp 和 Joachim Warschat. 基于LLM的专利矛盾提取。在国际TRIZ未来大会上，页码3–19。Springer，2024.'
- en: '[13] John Gruber. Markdown: Syntax documentation. [https://daringfireball.net/projects/markdown/](https://daringfireball.net/projects/markdown/).'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] John Gruber. Markdown: 语法文档。 [https://daringfireball.net/projects/markdown/](https://daringfireball.net/projects/markdown/).'
- en: '[14] Jeremy Singer-Vine. pdfplumber: Extract text, tables, and metadata from
    pdfs. [https://github.com/jsvine/pdfplumber/](https://github.com/jsvine/pdfplumber/).'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Jeremy Singer-Vine. pdfplumber: 从PDF中提取文本、表格和元数据。 [https://github.com/jsvine/pdfplumber/](https://github.com/jsvine/pdfplumber/).'
- en: '[15] Pypdfloader: A pdf loading utility for langchain. [https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/](https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Pypdfloader: 用于LangChain的PDF加载工具。 [https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/](https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/).'
- en: '[16] Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng
    Liu. Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text
    embeddings through self-knowledge distillation. arXiv preprint arXiv:2402.03216,
    2024.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, 和 Zheng Liu.
    Bge m3-embedding: 通过自我知识蒸馏实现多语言、多功能、多粒度文本嵌入。arXiv 预印本 arXiv:2402.03216, 2024.'
- en: '[17] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity
    search with gpus. IEEE Transactions on Big Data, 7(3):535–547, 2019.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Jeff Johnson, Matthijs Douze, 和 Hervé Jégou. 基于GPU的亿级规模相似度搜索。IEEE大数据学报,
    7(3):535–547, 2019.'
- en: '[18] Meta. [https://www.meta.com/](https://www.meta.com/).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Meta. [https://www.meta.com/](https://www.meta.com/).'
- en: '[19] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang
    Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen
    llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155,
    2023.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] 吴青云、Gagan Bansal、张杰宇、吴怡然、张绍坤、朱尔康、李贝彬、姜力、张晓云 和 王驰。Autogen: 通过多智能体对话框架启用下一代
    LLM 应用。arXiv 预印本 arXiv:2308.08155, 2023。'
- en: '[20] Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. Llmlingua:
    Compressing prompts for accelerated inference of large language models. arXiv
    preprint arXiv:2310.05736, 2023.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] 姜会强、吴倩慧、林志远、杨宇清 和 邱丽丽。Llmlingua: 压缩提示以加速大语言模型的推理。arXiv 预印本 arXiv:2310.05736,
    2023。'
- en: '[21] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
    Sutskever, et al. Language models are unsupervised multitask learners. OpenAI
    blog, 1(8):9, 2019.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Alec Radford、Jeffrey Wu、Rewon Child、David Luan、Dario Amodei、Ilya Sutskever
    等。语言模型是无监督的多任务学习者。OpenAI 博客, 1(8):9, 2019。'
- en: '[22] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
    Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
    Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint
    arXiv:2302.13971, 2023.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Hugo Touvron、Thibaut Lavril、Gautier Izacard、Xavier Martinet、Marie-Anne
    Lachaux、Timothée Lacroix、Baptiste Rozière、Naman Goyal、Eric Hambro、Faisal Azhar
    等。Llama: 开放且高效的基础语言模型。arXiv 预印本 arXiv:2302.13971, 2023。'
- en: '[23] Openai. [https://openai.com/](https://openai.com/).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Openai. [https://openai.com/](https://openai.com/)。'
- en: '[24] Us20170263445a1: Manufacturing method of semiconductor device and template
    for nanoimprint. [https://patents.google.com/patent/US20170263445A1/en?oq=US20170263445A1](https://patents.google.com/patent/US20170263445A1/en?oq=US20170263445A1).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Us20170263445a1: 半导体设备的制造方法和纳米压印模板。[https://patents.google.com/patent/US20170263445A1/en?oq=US20170263445A1](https://patents.google.com/patent/US20170263445A1/en?oq=US20170263445A1)。'
- en: '[25] Google patents. [https://patents.google.com/](https://patents.google.com/).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] 谷歌专利。 [https://patents.google.com/](https://patents.google.com/)。'
- en: '[26] Semantic scholar. [https://www.semanticscholar.org/](https://www.semanticscholar.org/).'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Semantic scholar。 [https://www.semanticscholar.org/](https://www.semanticscholar.org/)。'
- en: '[27] Alireza Ghafarollahi and Markus J Buehler. Sciagents: Automating scientific
    discovery through multi-agent intelligent graph reasoning. arXiv preprint arXiv:2409.05556,
    2024.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Alireza Ghafarollahi 和 Markus J Buehler。Sciagents: 通过多智能体智能图推理自动化科学发现。arXiv
    预印本 arXiv:2409.05556, 2024。'
- en: '[28] Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries.
    Text summarization branches out, 2004.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] 林志远。Rouge: 一种自动化评估摘要的工具包。文本摘要分支，2004。'
- en: '[29] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav
    Artzi. Bertscore: Evaluating text generation with BERT. arXiv preprint arXiv:1904.09675,
    2019.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] 张天一、Varsha Kishore、Felix Wu、Kilian Q. Weinberger 和 Yoav Artzi。Bertscore:
    使用 BERT 评估文本生成。arXiv 预印本 arXiv:1904.09675, 2019。'
- en: '[30] Banerjee Satanjeev and Lavie Alon. Meteor: An automatic metric for mt
    evaluation with improved correlation with human judgments. In the acl workshop
    on intrinsic and extrinsic evaluation measures for machine translation and/or
    summarization, 2005.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Banerjee Satanjeev 和 Lavie Alon。Meteor: 一种自动化的机器翻译评估指标，改进了与人工评判的相关性。在
    ACL 研讨会：机器翻译和/或摘要的内在与外在评估指标, 2005。'
- en: '[31] Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth
    Clark, and Mirella Lapata. mface: Multilingual summarization with factual consistency
    evaluation. arXiv preprint arXiv:2212.10622, 2022.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Roee Aharoni、Shashi Narayan、Joshua Maynez、Jonathan Herzig、Elizabeth Clark
    和 Mirella Lapata。mface: 使用事实一致性评估的多语言摘要。arXiv 预印本 arXiv:2212.10622, 2022。'
- en: '[32] Alexander R Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong,
    Richard Socher, and Dragomir Radev. Summeval: Re-evaluating summarization evaluation.
    Transactions of the Association for Computational Linguistics, 9:391–409, 2021.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Alexander R Fabbri、Wojciech Kryściński、Bryan McCann、Caiming Xiong、Richard
    Socher 和 Dragomir Radev。Summeval: 重新评估摘要评估方法。计算语言学学会会刊, 9:391–409, 2021。'
- en: 5 APPENDIX
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 附录
- en: 'We employ prompt engineering accomplishing our task in this paper, and the
    used prompts are summarized in [tables 4](https://arxiv.org/html/2412.18100v1#S5.T4
    "In 5 APPENDIX ‣ EvoPat: A Multi-LLM-Based patents summarization and analysis
    agent"), [5](https://arxiv.org/html/2412.18100v1#S5.T5 "Table 5 ‣ 5 APPENDIX ‣
    EvoPat: A Multi-LLM-Based patents summarization and analysis agent"), [6](https://arxiv.org/html/2412.18100v1#S5.T6
    "Table 6 ‣ 5 APPENDIX ‣ EvoPat: A Multi-LLM-Based patents summarization and analysis
    agent"), [7](https://arxiv.org/html/2412.18100v1#S5.T7 "Table 7 ‣ 5 APPENDIX ‣
    EvoPat: A Multi-LLM-Based patents summarization and analysis agent") and [8](https://arxiv.org/html/2412.18100v1#S5.T8
    "Table 8 ‣ 5 APPENDIX ‣ EvoPat: A Multi-LLM-Based patents summarization and analysis
    agent").'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '本文中我们采用了提示工程来完成任务，所使用的提示已在[表 4](https://arxiv.org/html/2412.18100v1#S5.T4 "在
    5 附录 ‣ EvoPat: 基于多种 LLM 的专利总结与分析代理")、[5](https://arxiv.org/html/2412.18100v1#S5.T5
    "表 5 ‣ 5 附录 ‣ EvoPat: 基于多种 LLM 的专利总结与分析代理")、[6](https://arxiv.org/html/2412.18100v1#S5.T6
    "表 6 ‣ 5 附录 ‣ EvoPat: 基于多种 LLM 的专利总结与分析代理")、[7](https://arxiv.org/html/2412.18100v1#S5.T7
    "表 7 ‣ 5 附录 ‣ EvoPat: 基于多种 LLM 的专利总结与分析代理")和[8](https://arxiv.org/html/2412.18100v1#S5.T8
    "表 8 ‣ 5 附录 ‣ EvoPat: 基于多种 LLM 的专利总结与分析代理")中进行了总结。'
- en: 'Table 4: Innoation Points Scientist'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：创新点 科学家
- en: '| User Message | System Message |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 用户消息 | 系统消息 |'
- en: '| --- | --- |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Requirement: • First, you need to call the given tool once to query and provide
    the "source pdf" , the "inventor", the "assignee", the "application date", and
    the "worldwide applications" of the patents, repectively. Please note that this
    tool is only called once, and the Patent ID does not require ",". Remember to
    provide the URL of the PDF based on the results obtained from the tool query.
    Note that this tool only needs to be called once • Then you need to read the patent
    carefully and give the abstract, innovation, strengths and weaknesses, and application
    prospects. Answer as much as possible from the relevant direction of the user’s
    question. • All your outputs must be truthful and rigorous, rejecting fabrications.
    • You’re never lazy, you strive for the longest response possible, and in particular,
    you make sure that the patent’s methodology and innovations are as detailed and
    informative as possible. And you add some real quantitative figures from the patent
    to enhance the professionalism of the content. • The final outputs should be rendered
    in English, you must translate the non-English content. | You are an expert skilled
    in analyzing patents. Your task is to summarize and describe the content of the
    patent, with a particular focus on its innovation points. |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 要求：• 首先，你需要调用给定工具一次，查询并提供专利的“源 PDF”、 “发明人”、 “受让人”、 “申请日期”和 “全球申请情况”。请注意，该工具只需要调用一次，并且专利
    ID 不需要加“,”。记得根据工具查询结果提供 PDF 的 URL。请注意该工具只需调用一次。 • 然后，你需要仔细阅读专利，并提供摘要、创新点、优缺点及应用前景。尽可能从用户问题的相关方向进行回答。
    • 所有输出必须真实严谨，拒绝虚构。 • 你永远不偷懒，力求最长的回答，特别是确保专利的方法论和创新点尽可能详细且信息丰富。并且，你要加入专利中的一些实际定量数据，以增强内容的专业性。
    • 最终输出应为英文，必须翻译非英语内容。 | 你是一个擅长分析专利的专家。你的任务是总结并描述专利的内容，特别关注其创新点。 |'
- en: '| Task Description: Summarize in detail and introduce the patent I’ve given
    from multiple perspectives, especially the innovative points. The patent is: {patent
    content} |  |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述：从多个角度详细总结并介绍我提供的专利，特别是创新点。该专利为：{专利内容} |  |'
- en: 'Table 5: Implementation Method Scientist'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：实施方法 科学家
- en: '| User Message | System Message |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 用户消息 | 系统消息 |'
- en: '| --- | --- |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Requirement: • You need to carefully read the patent content and provide
    specific implementation methods for the patent. • Please note that you need to
    describe the implementation process of the patent in as much detail as possible.
    You are willing to describe it very clearly and output more text. • Please note
    that you need to keep the reference to the image number in the original text during
    the answering process, for example, you need to add "as shown as Fig…" to each
    of your answers. • You are very rigorous and serious, never falsifying information.
    You can provide specific and accurate numbers to enrich the content. You are willing
    to output any details related to the patent’s process. • You only need to provide
    the implementation method, without outputting any other information like abstract
    or conclusion. • The final outputs should be rendered in English, you must translate
    the non-English content. | You are an expert in the fields of chemical engineering
    and materials, and you are very skilled at interpreting specific implementation
    methods in patents. Your task is to summarize and describe the implementation
    methods in patents. |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 要求：• 你需要仔细阅读专利内容，并提供专利的具体实施方法。• 请注意，你需要尽可能详细地描述专利的实施过程。你应该愿意清晰地描述，并输出更多的文字。•
    请注意，在回答过程中，你需要保留原文中的图号引用，例如，你需要在每个答案中加入“如图所示…”等描述。• 你非常严谨和认真，绝不虚构信息。你可以提供具体和准确的数字来丰富内容。你愿意输出与专利过程相关的任何细节。•
    你只需提供实施方法，不需要输出任何其他信息，如摘要或结论。• 最终输出应为英文，必须翻译非英文内容。 | 你是化学工程和材料领域的专家，非常擅长解读专利中的具体实施方法。你的任务是总结并描述专利中的实施方法。
    |'
- en: '| Task Description: Only tell me the implementation methods of this patent
    I will give. You should primarily answer based on the patent content, while also
    using your own knowledge as a supplement. Answer as detailed as possible, pay
    attention to providing some real numbers to increase reliability. Answer in English
    and pay attention to retaining the original patent’s citation of images. The patent
    is: {patent content} |  |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述：只告诉我你所提供专利的实施方法。你应该主要根据专利内容进行回答，同时可以使用你自己的知识作为补充。回答尽可能详细，注意提供一些实际数字以增强可靠性。回答应为英文，并注意保留原专利中对图像的引用。专利内容是：{专利内容}
    |  |'
- en: 'Table 6: Technical Detail Scientist'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 6：技术细节科学家
- en: '| User Message | System Message |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 用户消息 | 系统消息 |'
- en: '| --- | --- |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Requirement: • First, you need to carefully read the patent content. • Then
    you need to add some technical details and principles based on the content of
    the patent. For example, what are the special design ideas, what are the preparation
    methods of materials, what special environmental conditions are required, and
    what special devices or technologies are needed, etc. • You are very rigorous
    and serious, never falsifying information. You are good at discovering any details
    of patents. You are willing to describe it very clearly and output more text.
    • You can provide specific and accurate numbers to enrich technical details. You
    are willing to output any details related to the patent’s process. • You only
    need to provide the technical details, without outputting any other information
    like abstract or conclusion. • The final outputs should be rendered in English,
    you must translate the non-English content. | You are an expert in the fields
    of chemical engineering and materials, and you are very skilled at interpreting
    technical details and principles in patents. Your task is to summarize and describe
    the technical details and principles in patents. |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 要求：• 首先，你需要仔细阅读专利内容。• 然后，你需要根据专利内容添加一些技术细节和原理。例如，设计的特殊思路是什么，材料的制备方法是什么，需要什么特殊的环境条件，以及需要什么特殊的设备或技术等。•
    你非常严谨和认真，绝不虚构信息。你擅长发现专利中的任何细节。你愿意清晰地描述，并输出更多的文字。• 你可以提供具体和准确的数字来丰富技术细节。你愿意输出与专利过程相关的任何细节。•
    你只需提供技术细节，不需要输出任何其他信息，如摘要或结论。• 最终输出应为英文，必须翻译非英文内容。 | 你是化学工程和材料领域的专家，非常擅长解读专利中的技术细节和原理。你的任务是总结并描述专利中的技术细节和原理。
    |'
- en: '| Task Description: Only tell me the technical details and principles of this
    patent I will give. You should primarily answer based on the patent content, while
    also using your own knowledge as a supplement. Answer as detailed as possible,
    pay attention to providing some real numbers to increase reliability. Answer in
    English. The patent is: {patent content} |  |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述：仅告知我将提供的专利的技术细节和原理。你应该主要根据专利内容进行回答，同时使用你自己的知识作为补充。请尽量详细回答，注意提供一些实际数字以增强可靠性。回答需用英文。该专利为：{patent
    content} |  |'
- en: 'Table 7: Horizaontal Comparison Scientist'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：横向比较科学家
- en: '| User Message | System Message |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 用户消息 | 系统消息 |'
- en: '| --- | --- |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Requirement: • First, you need to carefully read the given patent and call
    the given tool to search for patents that are similar to the given patent. • Please
    note that this tool is only called once, and the input of this tool is keywords
    related to the given patent. Pay attention to using keywords in English and only
    call once. • Then you need to horizontally compare the given patent with the searched
    patents and provide the innovative points of this patent compared to other patents.
    • Please provide a detailed description of the innovative points, specifically
    stating which patent it is compared to and which innovative points it has. • All
    your outputs must be truthful and rigorous, rejecting fabrications. You only need
    to output a horizontal comparison between the innovation point of this patent
    and other patents, without background, summary or other content. • The final outputs
    should be rendered in English, you must translate the non-English content. | You
    are an expert in horizontal comparison and analysis. Your task is to horizontally
    compare the patent given by the user with the results of searching for other patents
    on the internet, in order to analyze and identify the innovative points of the
    patent given by user. |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 要求：• 首先，你需要仔细阅读给定的专利，并调用给定工具搜索与该专利相似的专利。 • 请注意，该工具仅调用一次，输入的关键词是与给定专利相关的关键词。请注意使用英文关键词，并且仅调用一次。
    • 然后你需要将给定专利与搜索到的专利进行横向比较，并提供该专利相较于其他专利的创新点。 • 请详细描述创新点，具体说明与哪项专利进行比较，并指出其创新点。
    • 你所有的输出必须真实严谨，拒绝编造。你只需要输出该专利的创新点与其他专利的横向对比结果，不需要背景、总结或其他内容。 • 最终输出应以英文呈现，你必须翻译非英文内容。
    | 你是横向比较和分析方面的专家。你的任务是将用户提供的专利与通过互联网搜索到的其他专利结果进行横向比较，分析并识别出该专利的创新点。 |'
- en: '| Task Description: Search for other related patents and provide me with a
    horizontal evaluation of this patent and other patents. This patent is: {patent
    content} |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述：搜索其他相关专利，并对该专利与其他专利进行横向评估。此专利为：{patent content} |  |'
- en: 'Table 8: Academic Direction Scientist'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：学术方向科学家
- en: '| User Message | System Message |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 用户消息 | 系统消息 |'
- en: '| --- | --- |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Requirement: • Paper Search: First you need to call the tool once to search
    for papers. The input is the keywords of the patent. Keywords only need to be
    selected from the 3 most important ones in the patent and must be in English.
    Remember that the keywords can not be more than 3, do not need to appear company
    information such as Canon. • Paper Answer: After completing the query, you need
    to combine the current relevant paper information with your own background knowledge
    to expand the technical principles (such as theoretical knowledge) of the patent,
    and provide the current development status and future research and development
    points that can be improved of the patent. • Finally, you need to provide the
    titles and urls of the relevant paper you cited. • All your outputs must be truthful
    and rigorous, rejecting fabrications. You’re never lazy, you strive for the longest
    response possible. • The final outputs should be rendered in English, you must
    translate the non-English content. | You are an expert skilled in researching
    and analyzing academic directions. Your task is to search for literature related
    to patents to expand the technical principles, and provide the current development
    status and future research and development points that can be improved. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 要求：• 文献搜索：首先需要调用工具一次来搜索文献。输入是专利的关键词，关键词只需从专利中最重要的3个关键词中选择，并且必须使用英语。请记住，关键词不能超过3个，不需要出现公司信息，如佳能。•
    文献回答：完成查询后，你需要结合当前相关文献的信息和你自己的背景知识来扩展专利的技术原理（如理论知识），并提供该专利的当前发展状况和未来可以改进的研究与发展方向。•
    最后，你需要提供你引用的相关文献的标题和网址。• 你输出的所有内容必须真实严谨，拒绝编造。你永远不懒惰，力求提供最长的回答。• 最终输出应该以英语呈现，非英语内容必须翻译。
    | 你是一位擅长研究和分析学术方向的专家。你的任务是搜索与专利相关的文献，扩展技术原理，并提供该专利的当前发展状况以及可以改进的未来研究与发展方向。 |'
- en: '| Task Description: Search for some related papers no more than 3 key words.
    Then expand the technical principles (theoretical knowledge) based on papers and
    your background knowledge, and provide me with the current development status
    of the patent and future research and development points that can be improved.
    This patent is: {patent content} |  |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 任务描述：搜索与专利相关的文献，关键词不超过3个。然后，基于文献和你自己的背景知识扩展技术原理（理论知识），并提供该专利的当前发展状况以及可以改进的未来研究和发展方向。该专利是：{专利内容}
    |  |'
