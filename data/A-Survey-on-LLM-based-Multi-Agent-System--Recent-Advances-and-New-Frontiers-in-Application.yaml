- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '<!--yml  '
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类  '
- en: 'date: 2025-01-11 11:44:02'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 11:44:02  '
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '-->  '
- en: 'A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers
    in Application'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '基于LLM的多智能体系统综述：近期进展与应用新前沿  '
- en: 来源：[https://arxiv.org/html/2412.17481/](https://arxiv.org/html/2412.17481/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '来源：[https://arxiv.org/html/2412.17481/](https://arxiv.org/html/2412.17481/)  '
- en: Shuaihang Chen¹  Yuanxing Liu¹  Wei Han¹  Weinan Zhang¹²²2Corresponding author.
     Ting Liu¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '陈帅航¹  刘远星¹  韩伟¹  张维南¹²²2通讯作者  刘婷¹  '
- en: ¹Research Center for Social Computing and Information Retrieval
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '¹哈尔滨工业大学社会计算与信息检索研究中心  '
- en: Harbin Institute of Technology, China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '哈尔滨工业大学，中国  '
- en: '{shchen, yxliu, whan, wnzhang, tliu}@ir.hit.edu.cn'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{shchen, yxliu, whan, wnzhang, tliu}@ir.hit.edu.cn  '
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '摘要  '
- en: \Acf
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '\Acf  '
- en: LLM-MAS have become a research hotspot since the rise of large language models
    (LLMs). However, with the continuous influx of new related works, the existing
    reviews struggle to capture them comprehensively. This paper presents a comprehensive
    survey of these studies. We first discuss the definition of LLM-based Multi-Agent
    Systems (LLM-MAS), a framework encompassing much of previous work. We provide
    an overview of the various applications of LLM-MAS in (i) solving complex tasks,
    (ii) simulating specific scenarios, and (iii) evaluating generative agents. Building
    on previous studies, we also highlight several challenges and propose future directions
    for research in this field.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '基于LLM的多智能体系统（LLM-MAS）自大规模语言模型（LLMs）兴起以来，已成为研究热点。然而，随着相关新研究的不断涌现，现有的综述难以全面涵盖所有进展。本文对这些研究进行了全面综述。我们首先讨论了基于LLM的多智能体系统（LLM-MAS）的定义，这是一个涵盖许多先前工作的框架。我们概述了LLM-MAS在以下方面的各种应用：（i）解决复杂任务，（ii）模拟特定场景，以及（iii）评估生成智能体。基于先前的研究，我们还突出展示了若干挑战，并提出了该领域未来的研究方向。  '
- en: 'A Survey on LLM-based Multi-Agent System:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '基于LLM的多智能体系统综述：  '
- en: Recent Advances and New Frontiers in Application
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 近期进展与应用新前沿
- en: Shuaihang Chen¹  Yuanxing Liu¹  Wei Han¹  Weinan Zhang¹²²2Corresponding author.
     Ting Liu¹ ¹Research Center for Social Computing and Information Retrieval Harbin
    Institute of Technology, China {shchen, yxliu, whan, wnzhang, tliu}@ir.hit.edu.cn
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '陈帅航¹  刘远星¹  韩伟¹  张维南¹²²2通讯作者  刘婷¹ ¹哈尔滨工业大学社会计算与信息检索研究中心，中国 {shchen, yxliu,
    whan, wnzhang, tliu}@ir.hit.edu.cn  '
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '1 引言  '
- en: \Acf
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '\Acf  '
- en: 'MAS have seen significant expansion owing to its adaptability and ability to
    address complex, distributed challenges Balaji and Srinivasan ([2010](https://arxiv.org/html/2412.17481v2#bib.bib4)).
    Compared to single-agent settings Gronauer and Diepold ([2022](https://arxiv.org/html/2412.17481v2#bib.bib26)),
    Multi-Agent Systems (MAS) provide a more accurate representation of the real world,
    as many real-world applications naturally involve multiple decision-makers interacting
    simultaneously. However, constrained by traditional  reinforcement learning (RL)
    agent parameters and the absence of general knowledge and capabilities, agents
    are unable to tackle complex decision-making tasks, such as collaborating with
    other agents for the development Qian et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)).
    In recent years, large language models (LLMs), e.g. Llama 3 Dubey et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib20)),
    and GPT-4 OpenAI et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib50)),
    have achieved notable successes, training on a massive web corpus [Radford et al.](https://arxiv.org/html/2412.17481v2#bib.bib59)
    . Compared with RL, generative agents, with large language model (LLM) as the
    core control agents, can be better at reasoning, long-trajectory decision-making,
    etc., even without training Shinn et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib62)).
    Furthermore, generative agents offer natural language interfaces for interacting
    with humans, making these interactions more flexible and easier to explain Park
    et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)). Based on these
    advantages, LLM-based Multi-Agent Systems (LLM-MAS) emerged. Researchers have
    surveyed these emerging works and proposed a general framework Guo et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib27)).
    However, as the number of related studies continues to grow, some works have emerged
    that fall outside the scope of the original framework. In this paper, we provide
    a new perspective based on previous reviews of LLM-based Multi-Agent Systems (LLM-MAS)
    with a focus on recent advancements and discuss potential research directions.
    We collected 125 papers published in top artificial intelligence conferences,
    such as *ACL, NeurIPS, AAAI, and ICLR, in 2023 and 2024, along with some unpublished
    yet valuable papers from arXiv.¹¹1The list of papers included in this survey can
    be found in [https://github.com/bianhua-12/Multi-generative_Agent_System_survey](https://github.com/bianhua-12/Multi-generative_Agent_System_survey)
    Based on the purpose of LLM-MAS, we summarize the application of LLM-MAS as task-solving,
    simulation for specific problems, and evaluation of generative agents. Figure
    [1](https://arxiv.org/html/2412.17481v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey
    on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application")
    illustrates the framework we propose for LLM-MAS application. (i) Solving complex
    tasks. Multi-agents will naturally split tasks into subtasks, which will improve
    task performance. (ii) Simulating for specific scenarios. Researchers see LLM-MAS
    as a sandbox for simulating problems in a specific domain. (iii) Evaluating generative
    agents. Compared with traditional task evaluation, LLM-MAS has the capability
    of dynamic assessment, which is more flexible and harder for data leakage. For
    each category, we will discuss representative LLM-MAS, resources, and their evaluation.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: MAS的扩展显著，得益于其适应性以及解决复杂、分布式挑战的能力，Balaji 和 Srinivasan（[2010](https://arxiv.org/html/2412.17481v2#bib.bib4)）。与单一代理设置相比，Gronauer
    和 Diepold（[2022](https://arxiv.org/html/2412.17481v2#bib.bib26)）指出，多智能体系统（MAS）能够更准确地再现真实世界，因为许多现实世界的应用本质上涉及多个决策者同时互动。然而，由于传统强化学习（RL）代理的参数限制以及缺乏通用知识和能力，代理无法解决复杂的决策任务，例如与其他代理合作进行开发，Qian
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)）。近年来，诸如 Llama 3（Dubey
    等人，[2024](https://arxiv.org/html/2412.17481v2#bib.bib20)）和 GPT-4（OpenAI 等人，[2024](https://arxiv.org/html/2412.17481v2#bib.bib50)）等大型语言模型（LLMs）取得了显著的成功，通过对海量网络语料库进行训练，[Radford
    等人](https://arxiv.org/html/2412.17481v2#bib.bib59)）。与强化学习相比，生成型代理，核心控制代理为大型语言模型（LLM），即使没有训练，也能在推理、长时间轨迹决策等方面表现更好，Shinn
    等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib62)）。此外，生成型代理提供了与人类互动的自然语言接口，使这些互动更加灵活且易于解释，Park
    等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib53)）。基于这些优势，基于LLM的多智能体系统（LLM-MAS）应运而生。研究人员对这些新兴的工作进行了调查，并提出了一个通用框架，Guo
    等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib27)）。然而，随着相关研究数量的不断增加，一些研究超出了原始框架的范围。在本文中，我们基于之前对基于LLM的多智能体系统（LLM-MAS）的回顾提供了一个新的视角，重点讨论最近的进展并探讨潜在的研究方向。我们收集了2023年和2024年在顶级人工智能会议上发表的125篇论文，如*ACL、NeurIPS、AAAI
    和 ICLR*，以及一些尚未发表但具有价值的arXiv论文。¹¹1这些论文的列表可以在[https://github.com/bianhua-12/Multi-generative_Agent_System_survey](https://github.com/bianhua-12/Multi-generative_Agent_System_survey)找到。根据LLM-MAS的目的，我们总结了LLM-MAS的应用，包括任务解决、特定问题的仿真和生成型代理的评估。图[1](https://arxiv.org/html/2412.17481v2#S1.F1
    "图1 ‣ 1 引言 ‣ 基于LLM的多智能体系统：应用中的最新进展和新前沿")展示了我们为LLM-MAS应用提出的框架。(i) 解决复杂任务。多智能体会自然地将任务拆分为子任务，从而提高任务表现。(ii)
    为特定场景进行仿真。研究人员将LLM-MAS视为在特定领域中仿真问题的沙盒。(iii) 评估生成型代理。与传统任务评估相比，LLM-MAS具有动态评估的能力，这更加灵活且更难泄露数据。对于每个类别，我们将讨论具有代表性的LLM-MAS、资源及其评估。
- en: '![Refer to caption](img/3b670422d808ba48fcdd5cdfac875fb6.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅图注](img/3b670422d808ba48fcdd5cdfac875fb6.png)'
- en: 'Figure 1: Overview of the application framework and relationship of LLM-MAS,
    generative agent, and LLM. Dashed-bordered right-angled rectangles represent content
    aligned with previous surveys, while rounded rectangles indicate original contributions
    introduced in this study.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：LLM-MAS、生成性智能体和LLM的应用框架概览及其相互关系。带虚线边框的直角矩形表示与先前调研一致的内容，而圆角矩形表示本研究中的原创贡献。
- en: 'Compared to the previous survey Guo et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib27));
    Li et al. ([2024d](https://arxiv.org/html/2412.17481v2#bib.bib39)); Han et al.
    ([2024](https://arxiv.org/html/2412.17481v2#bib.bib28)); Gronauer and Diepold
    ([2022](https://arxiv.org/html/2412.17481v2#bib.bib26)), this survey has the following
    distinctive contributions: (i) A Taxonomy focusing on application of LLM-MAS:
    we introduce a more recent taxonomy (taxonomy and difference are shown in Figure
    [1](https://arxiv.org/html/2412.17481v2#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Survey
    on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application"))
    based on the purpose of the application of LLM-MAS. (ii) More Resources: we analyze
    open-source frameworks and research works with benchmarks or datasets to facilitate
    the research community. (iii) Challenges and Future: we discuss the challenges
    in LLM-MAS, and shed light on future research.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 相比于先前的调研工作Guo et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib27));
    Li et al. ([2024d](https://arxiv.org/html/2412.17481v2#bib.bib39)); Han et al.
    ([2024](https://arxiv.org/html/2412.17481v2#bib.bib28)); Gronauer and Diepold
    ([2022](https://arxiv.org/html/2412.17481v2#bib.bib26)), 本次调研具有以下独特贡献：（i）专注于LLM-MAS应用的分类法：我们基于LLM-MAS应用目的引入了一个更新的分类法（分类法及其差异见图[1](https://arxiv.org/html/2412.17481v2#S1.F1
    "图1 ‣ 1 引言 ‣ 基于LLM的多智能体系统：应用中的最新进展与新前沿")）。（ii）更多资源：我们分析了具有基准或数据集的开源框架和研究成果，以便为研究社区提供支持。（iii）挑战与未来：我们讨论了LLM-MAS面临的挑战，并展望了未来的研究方向。
- en: 2 Core Components of LLM-MAS
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 LLM-MAS的核心组件
- en: LLM-MAS refer to a system that includes a collection of generative agents capable
    of interacting and collaborating within a shared environmental setting Wang et al.
    ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib66)). We will discuss generative
    agents and the environment in the following.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-MAS指的是一种系统，包含一组能够在共享的环境设置中进行互动与协作的生成性智能体Wang et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib66))。我们将在接下来的部分中讨论生成性智能体和环境。
- en: 2.1 Generative Agents
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 生成性智能体
- en: Generative agents refer to the components of LLM-MAS that have role definitions,
    can perceive the environment, make decisions, and perform complex actions to change
    the environment Wang et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib64)).
    They can be a player in a game or a user on social media and have the role of
    driving the development of LLM-MAS and influencing its results.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性智能体是指LLM-MAS的组成部分，具有角色定义，能够感知环境、做出决策，并执行复杂的行为以改变环境Wang et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib64))。它们可以是游戏中的玩家，或社交媒体上的用户，推动LLM-MAS的发展并影响其结果。
- en: 'Compared to traditional agents, generative agents need to be able to perform
    more complex behaviors, such as generating complete personalized blog posts based
    on historical information Park et al. ([2022](https://arxiv.org/html/2412.17481v2#bib.bib54)).
    Therefore, in addition to using LLMs as the core, generative agents also require
    the following characteristics: (i) *Profiling*is used to link their behavior by
    describing roles in natural language Gao et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib22)),
    or customizing the prompts for each generative agent based on their tasks Xu et al.
    ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71)). (ii) *Memory*is used
    to store historical trajectories and retrieve relevant memories for subsequent
    agent actions, enabling the ability to take long-term actions while solving the
    problem of limited LLM context windows. There usually include three layers of
    memory: long-term, short-term, and sensory memory Park et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)).
    (iii) *Planning*is to formulate general behavior for a longer period of time in
    the future Yao et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib72)).
    (iv) *Action*executes the interaction between the generative agent and the environment Wang
    et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib64)). Generative agents
    may be required to choose one of several candidate behaviors to execute, such
    as voting for whom Xu et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib70)),
    or generate behaviors without mandatory constraints, such as generating a paragraph
    of text Li et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib40)).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统代理相比，生成代理需要能够执行更复杂的行为，例如根据历史信息生成完整的个性化博客文章 Park et al. ([2022](https://arxiv.org/html/2412.17481v2#bib.bib54))。因此，除了将大语言模型（LLM）作为核心，生成代理还需要具备以下特点：（i）*角色建模*用于通过自然语言描述角色来关联其行为 Gao
    et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib22))，或根据任务为每个生成代理定制提示 Xu
    et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71))。（ii）*记忆*用于存储历史轨迹，并为后续代理行为检索相关记忆，使代理能够在解决大语言模型上下文窗口限制问题的同时采取长期行动。通常包括三层记忆：长期记忆、短期记忆和感官记忆 Park
    et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53))。（iii）*规划*是为未来较长时间段制定一般性行为 Yao
    et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib72))。（iv）*行动*执行生成代理与环境之间的交互 Wang
    et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib64))。生成代理可能需要从多个候选行为中选择一个来执行，例如投票选举谁 Xu
    et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib70))，或生成没有强制约束的行为，例如生成一段文本 Li
    et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib40))。
- en: Generative agents can communicate with each other to achieve cooperation within
    the system. The communication of generative agents can be roughly divided into
    two purposes. (i) The first purpose is to achieve collaboration, share the information
    obtained by themselves with other intelligent agents, and to some extent, aggregate
    multiple intelligent agents into a complete system, achieving performance beyond
    independent intelligent agents Yuan et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib75));
    (ii) The second purpose is to achieve consensus, allowing for greater similarity
    in behavior or strategy among some agents, thereby enabling faster convergence
    to Nash equilibrium Oroojlooy and Hajinezhad ([2023](https://arxiv.org/html/2412.17481v2#bib.bib51)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 生成代理可以相互通信，以实现系统内部的合作。生成代理的通信大致可以分为两个目的。（i）第一个目的是实现协作，将自己获得的信息与其他智能代理共享，并在一定程度上将多个智能代理聚合成一个完整的系统，从而实现超越独立智能代理的性能 Yuan
    et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib75))；（ii）第二个目的是实现共识，使某些代理之间的行为或策略更加相似，从而能够更快地收敛到纳什均衡 Oroojlooy
    and Hajinezhad ([2023](https://arxiv.org/html/2412.17481v2#bib.bib51))。
- en: 'The type of communication content can be roughly divided into two types: natural
    language and custom content. Natural language forms of communication have high
    interpretability and flexibility. Still, they are difficult to optimize, making
    them more suitable for pursuing consensus, such as Chatdev Qian et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57))
    and job fair systems Li et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib40)).
    Custom content may be a vector or a discrete signal that no one can understand
    except for the generative agent in the system. But this form is easy to optimize
    using policy gradients, so it is commonly used for achieving cooperative purposes,
    such as the DIAL Hausknecht and Stone ([2015](https://arxiv.org/html/2412.17481v2#bib.bib29))
    algorithm and its variables.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通信内容的类型大致可以分为两种：自然语言和定制内容。自然语言形式的沟通具有较高的可解释性和灵活性，但难以优化，因此更适合用于追求共识的场景，例如Chatdev
    Qian等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)）和招聘会系统Li等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib40)）。定制内容可能是一个向量或一个离散信号，除了系统中的生成代理外，没人能理解它。但这种形式容易通过策略梯度进行优化，因此常用于实现协作目的，例如DIAL
    Hausknecht和Stone（[2015](https://arxiv.org/html/2412.17481v2#bib.bib29)）算法及其变量。
- en: 2.2 Environment
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 环境
- en: 'Environmental settings include rules, tools, and intervention interfaces: (i)
    *Tools*are responsible for translating the agent’s action instruction into specific
    outcomes. Generative agents send action instructions to the environment and the
    environment converts the instruction into a record that the action was taken.
    There are different action spaces in different scenes. In the social media scene,
    the action space concludes “like”, “comment”, “follow”, etc. Wang et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)).
    In the development scene, the action space closes the chat chain Qian et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)),
    which is larger than social networks. (ii) *Rules*define the mode of communication
    between generative agents or the interaction with the environment, directly defining
    the behavioral structure of the entire system. Based on the scene, there are some
    special rules for the system, such as rules of the game Xu et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib70));
    Chen et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)) and the norm
    of social behavior Park et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53));
    Wang et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)). Normally,
    a generative agent in the large-scale system has a smaller action space and is
    more easily replaced by a rule-based model Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)).
    (iii) *Intervention*provides an interface for external intervention systems. This
    intervention can come from any external source, human Wang et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)),
    or a supervision model Chen et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)),
    even a generative agent Qian et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)).
    The purpose of an intervention may be to actively read information from the system Wang
    et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)), or passively
    interrupt the system to prevent uncontrolled behavior from occurring Qian et al.
    ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 环境设置包括规则、工具和干预接口：(i) *工具*负责将代理的动作指令转化为具体的结果。生成代理将动作指令发送到环境，环境将指令转化为记录，表明该动作已被执行。不同场景下有不同的动作空间。在社交媒体场景中，动作空间包括“点赞”、“评论”、“关注”等 Wang
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)）。在开发场景中，动作空间涵盖了聊天链条 Qian
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)），这比社交网络的动作空间更大。(ii)
    *规则*定义了生成代理之间的通信方式或与环境的互动，直接定义了整个系统的行为结构。根据场景，系统有一些特殊的规则，例如游戏规则 Xu 等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib70)）；Chen
    等人（[2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)）以及社交行为规范 Park 等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib53)）；Wang
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)）。通常，大型系统中的生成代理有较小的动作空间，更容易被基于规则的模型所替代 Mou
    等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib49)）。(iii) *干预*提供了一个外部干预系统的接口。此干预可以来自任何外部来源，可能是人类 Wang
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)），也可能是监督模型 Chen 等人（[2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)），甚至是生成代理
    Qian 等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)）。干预的目的是主动从系统中读取信息 Wang
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)），或被动中断系统，以防止出现不受控制的行为 Qian
    等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)）。
- en: 3 LLM-MAS for Solving Complex Tasks
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 LLM-MAS 用于解决复杂任务
- en: Completing a complex task usually requires multiple roles, multiple steps, and
    so on. This is difficult for a single agent, but multiple agents working together
    will be well suited to this task Islam et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib33)).
    Further, each of these agents can be trained independently Shen et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib60));
    Yu et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib74)). Compared with
    a single agent, LLM-MAS can achieve better results. That is, the multi-agent collaboration
    will improve the overall performance Du et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib18)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 完成复杂任务通常需要多个角色、多个步骤等。这对单一代理来说是困难的，但多个代理协同工作则非常适合完成这类任务 Islam 等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib33)）。此外，这些代理可以独立训练 Shen
    等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib60)）；Yu 等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib74)）。与单一代理相比，LLM-MAS
    可以实现更好的结果。也就是说，多代理协作将提高整体性能 Du 等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib18)）。
- en: 3.1 Representative LLM-MAS for Solving Complex Tasks
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 代表性的 LLM-MAS 用于解决复杂任务
- en: This field is currently a hot research topic. Recently, researchers mainly focus
    on multi-agent reasoning frameworks and multi-agent communication optimization,
    which will be discussed below.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 该领域目前是一个热门的研究主题。最近，研究人员主要关注多代理推理框架和多代理通信优化，接下来将讨论这些内容。
- en: 'LLM-MAS reasoning framework. We summarize three aspects by the pipeline of
    reasoning, including: (i) multi-stage framework, (ii) collective decision-making
    framework, and (iii) self-refine framework. That is, the multi-stage framework
    refers to a pipeline where agents act as serial problem solvers at different stages Qian
    et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)), while collective
    decision-making Zhao et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib83))
    refers to different agents voting or debating for one goal. Self-Refine refers
    to the mechanism of self-reflection in LLM-MAS. Researchers propose a framework
    for applying multi-agents to the natural sciences Chen et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib7))
    to enhance data analysis, model simulations, and decision-making processes Yin
    et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib73)). Zhang et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib77))
    propose a framework to achieve self-adaptation and adaptive cooperation. Scaling
    law in agent cooperation is also explored Qian et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib58)),
    finding that there is no significant pattern.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-MAS推理框架。我们通过推理流程总结了三个方面，包括：（i）多阶段框架，（ii）集体决策框架，以及（iii）自我完善框架。即，多阶段框架是指代理在不同阶段充当串行问题求解者Qian
    et al.（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)），而集体决策Zhao et al.（[2024c](https://arxiv.org/html/2412.17481v2#bib.bib83)）是指不同的代理为一个目标进行投票或辩论。自我完善指的是LLM-MAS中的自我反思机制。研究人员提出了一个框架，用于将多代理应用于自然科学Chen
    et al.（[2024a](https://arxiv.org/html/2412.17481v2#bib.bib7)），以增强数据分析、模型仿真和决策过程Yin
    et al.（[2024](https://arxiv.org/html/2412.17481v2#bib.bib73)）。Zhang et al.（[2023a](https://arxiv.org/html/2412.17481v2#bib.bib77)）提出了一个框架以实现自适应和适应性合作。代理合作中的规模法则也被探索Qian
    et al.（[2024c](https://arxiv.org/html/2412.17481v2#bib.bib58)），发现没有显著的模式。
- en: 'LLM-MAS communication optimization. The fully connected communication in LLM-MAS
    can lead to issues such as combinatorial explosion and privacy disclosure. Based
    on this, we summarize two aspects in Communication Optimization, including: (i)
    speed optimization and (ii) distributed discussion. Speed optimization refers
    to researchers trying to speed up the communication of agents, for example, with
    non-verbal communication Liu et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib47))
    or shorter generation Chen et al. ([2024g](https://arxiv.org/html/2412.17481v2#bib.bib13)).
    While distributed discussion refers to agents trying to solve tasks without enough
    information Liu et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib45)).
    Agents need to communicate with each other to achieve their goals Zhang et al.
    ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib77)), even without complete
    information in one agentLiu et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib45)).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-MAS通信优化。LLM-MAS中的全连接通信可能会导致组合爆炸和隐私泄露等问题。基于此，我们在通信优化中总结了两个方面，包括：（i）速度优化和（ii）分布式讨论。速度优化是指研究人员尝试加快代理的通信速度，例如，使用非语言交流Liu
    et al.（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib47)）或更短的生成Chen et al.（[2024g](https://arxiv.org/html/2412.17481v2#bib.bib13)）。而分布式讨论是指代理在信息不足的情况下尝试解决任务Liu
    et al.（[2024a](https://arxiv.org/html/2412.17481v2#bib.bib45)）。代理需要相互通信以实现目标Zhang
    et al.（[2023a](https://arxiv.org/html/2412.17481v2#bib.bib77)），即使一个代理没有完整的信息Liu
    et al.（[2024a](https://arxiv.org/html/2412.17481v2#bib.bib45)）。
- en: 3.2 Resources of LLM-MAS for Solving Complex Tasks
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 解决复杂任务的LLM-MAS资源
- en: 'We summarize common and open-source LLM-MAS for simulation in Table [1](https://arxiv.org/html/2412.17481v2#S3.T1
    "Table 1 ‣ 3.2 Resources of LLM-MAS for Solving Complex Tasks ‣ 3 LLM-MAS for
    Solving Complex Tasks ‣ A Survey on LLM-based Multi-Agent System: Recent Advances
    and New Frontiers in Application"), including code, dataset, and benchmark.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在表格[1](https://arxiv.org/html/2412.17481v2#S3.T1 "Table 1 ‣ 3.2 Resources
    of LLM-MAS for Solving Complex Tasks ‣ 3 LLM-MAS for Solving Complex Tasks ‣ A
    Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application")中总结了常见的开源LLM-MAS用于仿真，包括代码、数据集和基准测试。'
- en: 'Table 1: Codes and Benchmarks in LLM-MAS for solving tasks studies. “No Code”
    or “No Benchmark” means the code or benchmark is unavailable.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表格1：LLM-MAS用于解决任务研究中的代码和基准。“No Code”或“No Benchmark”表示代码或基准不可用。
- en: '| Field | SubField | Paper | Code | Dataset and Benchmark |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 子领域 | 论文 | 代码 | 数据集与基准 |'
- en: '| Reasoning Framework | Muti-stage | Qian et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57))
    | [Code Link](https://github.com/OpenBMB/ChatDev) | SRDD |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 推理框架 | 多阶段 | 钱等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57))
    | [代码链接](https://github.com/OpenBMB/ChatDev) | SRDD |'
- en: '| Du et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib19)) | [Code
    Link](https://github.com/OpenBMB/ChatDev) | SRDD |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 杜等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib19)) | [代码链接](https://github.com/OpenBMB/ChatDev)
    | SRDD |'
- en: '| Yue et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib76)) | [Code
    Link](https://github.com/yueshengbin/SMART) | SMART (self) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 岳等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib76)) | [代码链接](https://github.com/yueshengbin/SMART)
    | SMART (自我) |'
- en: '| Liu et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib48)) | [Code
    Link](https://github.com/salesforce/BOLAA) | WebShop |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 刘等人 ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib48)) | [代码链接](https://github.com/salesforce/BOLAA)
    | WebShop |'
- en: '| Lin et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib43)) | [Code
    Link](https://anonymous.4open.science/r/MAO-1074) | FG-C, CG-O |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 林等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib43)) | [代码链接](https://anonymous.4open.science/r/MAO-1074)
    | FG-C, CG-O |'
- en: '| Islam et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib33)) | [Code
    Link](https://github.com/Md-Ashraful-Pramanik/MapCoder) | HumanEval, EvalPlus,
    MBPP, APPS, xCodeEval, CodeContest |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 伊斯兰等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib33)) | [代码链接](https://github.com/Md-Ashraful-Pramanik/MapCoder)
    | HumanEval, EvalPlus, MBPP, APPS, xCodeEval, CodeContest |'
- en: '| Shen et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib60)) | [Code
    Link](https://github.com/X-PLUG/Multi-LLM-Agent) | ToolBench, ToolAlpaca |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 沈等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib60)) | [代码链接](https://github.com/X-PLUG/Multi-LLM-Agent)
    | ToolBench, ToolAlpaca |'
- en: '| Collective Decision-Making | Zhao et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib83))
    | [Code Link](https://github.%20com/xiutian/GEDI) | MCQA |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 集体决策 | 赵等人 ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib83)) | [代码链接](https://github.%20com/xiutian/GEDI)
    | MCQA |'
- en: '| Cheng et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib14)) | [Code
    Link](https://github.com/YiCheng98/Cooper) | ESConv dataset, P4G dataset |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 程等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib14)) | [代码链接](https://github.com/YiCheng98/Cooper)
    | ESConv 数据集, P4G 数据集 |'
- en: '| Liang et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib41)) | [Code
    Link](https://github.com/Skytliang/Multi-Agents-Debate) | MT-Bench |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 梁等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib41)) | [代码链接](https://github.com/Skytliang/Multi-Agents-Debate)
    | MT-Bench |'
- en: '| Lei et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib35)) | [Code
    Link](https://github.com/bin123apple/MACM) | MATH |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 雷等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib35)) | [代码链接](https://github.com/bin123apple/MACM)
    | MATH |'
- en: '| Zhang et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib79)) | [Code
    Link](https://github.com/zjunlp/MachineSoM) | MMLU, MATH, Chess Move Validity
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 张等人 ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib79)) | [代码链接](https://github.com/zjunlp/MachineSoM)
    | MMLU, MATH, 棋步有效性 |'
- en: '| Wang et al. ([2024d](https://arxiv.org/html/2412.17481v2#bib.bib67)) | [Code
    Link](https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git) | TriviaQA
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 王等人 ([2024d](https://arxiv.org/html/2412.17481v2#bib.bib67)) | [代码链接](https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git)
    | TriviaQA |'
- en: '| Self-Refine | Wang et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib66))
    | [Code Link](https://github.com/HKUST-KnowComp/LLM-discussion) | FOLIO-wiki |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Self-Refine | 王等人 ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib66))
    | [代码链接](https://github.com/HKUST-KnowComp/LLM-discussion) | FOLIO-wiki |'
- en: '| Chen et al. ([2024e](https://arxiv.org/html/2412.17481v2#bib.bib11)) | [Code
    Link](https://github.com/dinobby/ReConcile) | StrategyQA, CSQA, GSM8K, AQuA, MATH,
    Date Understanding, ANLI |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 陈等人 ([2024e](https://arxiv.org/html/2412.17481v2#bib.bib11)) | [代码链接](https://github.com/dinobby/ReConcile)
    | StrategyQA, CSQA, GSM8K, AQuA, MATH, 日期理解, ANLI |'
- en: '| Chen et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib7)) | [Code
    Link](https://github.com/Link-AGI/AutoAgents) | TriviaQA |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 陈等人 ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib7)) | [代码链接](https://github.com/Link-AGI/AutoAgents)
    | TriviaQA |'
- en: '| Tang et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib63)) | [Code
    Link](https://github.com/Code4Agent/codeagent) | Trans-Review,AutoTransform,T5-Review
    |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 唐等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib63)) | [代码链接](https://github.com/Code4Agent/codeagent)
    | Trans-Review, AutoTransform, T5-Review |'
- en: '| Zhang et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib77)) | [Code
    Link](https://pku-proagent.github.io/) | Overcooked-AI |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 张等人 ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib77)) | [代码链接](https://pku-proagent.github.io/)
    | Overcooked-AI |'
- en: '| Communication Optimization | Speed Optimization | Liu et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib47))
    | No Code | HotpotQA,NarrativeQA,MultifieldQA |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 通信优化 | 速度优化 | 刘等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib47))
    | 无代码 | HotpotQA, NarrativeQA, MultifieldQA |'
- en: '| Distributed | Chen et al. ([2024f](https://arxiv.org/html/2412.17481v2#bib.bib12))
    | [Code Link](https://github.com/OpenBMB/IoA) | TriviaQA, Natural Questions, HotpotQA,
    2WikiMultiHopQA |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 分布式 | Chen et al. ([2024f](https://arxiv.org/html/2412.17481v2#bib.bib12))
    | [代码链接](https://github.com/OpenBMB/IoA) | TriviaQA, Natural Questions, HotpotQA,
    2WikiMultiHopQA |'
- en: '| Liu et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib45)) | [Code
    Link](https://github.com/thinkwee/iAgents) | InformativeBench |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Liu et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib45)) | [代码链接](https://github.com/thinkwee/iAgents)
    | InformativeBench |'
- en: Data set. All datasets of traditional NLP tasks are available. In addition,
    following ECL Qian et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib56)),
    Qian et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)) evaluate
    the quality of generated software on the SRDD dataset and systematically evaluate
    agent capabilities in the domain of software development.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集。所有传统 NLP 任务的数据集均可使用。此外，继 ECL 之后，Qian et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib56))，Qian
    et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib57)) 对 SRDD 数据集上的生成软件质量进行了评估，并在软件开发领域系统地评估了代理的能力。
- en: Open source community. The open-source and industrial communities have also
    contributed significantly to the development of LLM-MAS. MetaGPT Hong et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib30))
    assigns different roles to generative agents to form a collaborative entity for
    complex tasks. Gao et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib23))
    propose AgentScope with message exchange as its core communication mechanism.
    In the meantime, this work develops a distribution framework that facilitates
    seamless switching between local and distributed deployments and automatic parallel
    optimization with minimal effort. Open AI proposes Swarm Ope ([2024](https://arxiv.org/html/2412.17481v2#bib.bib2)),
    an experimental multi-agent orchestration framework that is ergonomic and lightweight.
    Unlike the previously released Assistants API, Swarm gives developers fine-grained
    control over context, steps, and tool calls rather than being hosted.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 开源社区。开源社区和工业界也对 LLM-MAS 的发展做出了重要贡献。MetaGPT Hong et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib30))
    为生成性代理分配不同的角色，形成一个用于复杂任务的协作实体。Gao et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib23))
    提出了以消息交换为核心通信机制的 AgentScope。同时，本研究开发了一个分发框架，能够无缝切换本地与分布式部署，并通过最小的努力实现自动并行优化。Open
    AI 提出了 Swarm Ope ([2024](https://arxiv.org/html/2412.17481v2#bib.bib2))，这是一个实验性的多代理编排框架，具有符合人体工程学的设计和轻量化特性。与之前发布的
    Assistants API 不同，Swarm 让开发者对上下文、步骤和工具调用拥有更精细的控制，而不是托管在云端。
- en: 3.3 Evaluation of LLM-MAS for solving complex task
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 LLM-MAS 在解决复杂任务中的评估
- en: 'Performance on specific tasks. Shown as Table [1](https://arxiv.org/html/2412.17481v2#S3.T1
    "Table 1 ‣ 3.2 Resources of LLM-MAS for Solving Complex Tasks ‣ 3 LLM-MAS for
    Solving Complex Tasks ‣ A Survey on LLM-based Multi-Agent System: Recent Advances
    and New Frontiers in Application"), the performance of LLM-MAS can be evaluated
    by specific tasks, which is intuitive and convenient. For example, in an APP system
    Zhang et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib78)), the average
    number of steps and tools used by an agent to complete a specific task are considered
    as indicators; in BOLAA Liu et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib48)),
    the recall and QA accuracy of intelligent physical examination retrieval are also
    considered as evaluation indicators; in the Werewolf game Xu et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71)),
    the win rate of virtual players is naturally also an evaluation indicator; in
    the job fair system Li et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib40))
    , the proportion of correctly recruited target job seekers by the recruiting party
    is also an evaluation indicator; in the auction system Chen et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)),
    the Spearman correlation coefficient between the predicted and actual prices of
    goods, as well as the skills of bidders, are also measured by TrueSkill scores
    Graepel et al. ([2007](https://arxiv.org/html/2412.17481v2#bib.bib25)); in Stanford
    Town Park et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)), the
    quality of behaviors generated by virtual agents and human agents is manually
    sorted and evaluated using TrueSkill; in urban simulation systems Xu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib68)),
    the success rate of completing specific tasks such as navigation is also an evaluation
    metric.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '特定任务的表现。如表[1](https://arxiv.org/html/2412.17481v2#S3.T1 "Table 1 ‣ 3.2 Resources
    of LLM-MAS for Solving Complex Tasks ‣ 3 LLM-MAS for Solving Complex Tasks ‣ A
    Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application")所示，LLM-MAS的表现可以通过特定任务来评估，这种方式直观且便捷。例如，在一个APP系统中，张等人（[2023b](https://arxiv.org/html/2412.17481v2#bib.bib78)）考虑了一个智能体完成特定任务时使用的平均步骤数和工具数作为评估指标；在BOLAA中，刘等人（[2023c](https://arxiv.org/html/2412.17481v2#bib.bib48)）将智能物理检查检索的召回率和问答准确率作为评估指标；在狼人杀游戏中，许等人（[2023c](https://arxiv.org/html/2412.17481v2#bib.bib71)）自然地将虚拟玩家的胜率作为评估指标；在招聘会系统中，李等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib40)）将招聘方正确招募目标求职者的比例作为评估指标；在拍卖系统中，陈等人（[2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)）通过预测价格与实际价格之间的斯皮尔曼相关系数以及竞标者的技能，使用TrueSkill得分（Graepel
    et al.，[2007](https://arxiv.org/html/2412.17481v2#bib.bib25)）来进行测量；在斯坦福镇公园系统中，帕克等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib53)）通过人工排序和使用TrueSkill评估虚拟智能体和人类智能体生成的行为质量；在城市仿真系统中，许等人（[2023a](https://arxiv.org/html/2412.17481v2#bib.bib68)）也将完成导航等特定任务的成功率作为评估指标。'
- en: Communication cost analysis. The paramount concern lies in the operational cost
    of the system. Given that a substantial proportion of contemporary systems incorporate
    LLMs as a pivotal module, the additional expenditure incurred during system operation
    has emerged as a pivotal area of interest. As an illustrative example, Mou et al.
    ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)) utilize the actual runtime
    of the system as a pivotal metric, underscoring the significance of managing this
    operational overhead.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通信成本分析。最重要的关注点在于系统的运行成本。考虑到现代大多数系统将LLM作为关键模块，系统运行过程中产生的额外开销已成为一个关键的研究领域。例如，牟等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib49)）使用系统的实际运行时间作为重要指标，强调了管理这一运营开销的重要性。
- en: 4 LLM-MAS for Simulating Specific Scenarios
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 LLM-MAS用于仿真特定场景
- en: This section will illustrate the application for LLM-MAS in simulation. Researchers
    apply agents to simulate a certain scenario to study its impact on a specific
    subject like social science. On the one hand, compared with rule-based methods Chuang
    and Rogers ([2023](https://arxiv.org/html/2412.17481v2#bib.bib16)), generative
    agents with natural language communication can be more intuitive for humans. On
    the other hand, environment determines the properties of the simulation, which
    is the core of the entire simulation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将阐述LLM-MAS在仿真中的应用。研究人员利用智能体仿真某一场景，以研究其对特定学科（如社会科学）的影响。一方面，与基于规则的方法相比，生成型智能体通过自然语言交流更能直观地与人类互动。另一方面，环境决定了仿真的属性，这是整个仿真过程的核心。
- en: 4.1 Representative LLM-MAS for Simulating Specific Scenarios
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 用于模拟特定场景的代表性LLM-MAS
- en: The typical scenarios for LLM-MAS simulations are described as follows. We will
    introduce the following work according to the subject.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-MAS模拟的典型场景如下所述。我们将根据主题介绍以下工作。
- en: Social domain. Social large-scale experiments in the real world have high costs,
    and the sheer scale of social participation can sometimes escalate into violence
    and destruction, posing potential ramifications Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)).
    Therefore, it is necessary to simulate in the virtual environment; simulation
    can solve the problem of excessive overhead in the real environment and can simulate
    the process in the real world for a long time at a faster speed Li et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib36)).
    At the same time, the whole process can be easily repeated, which is conducive
    to further research. Researchers have done a lot of work to simulate social media
    scenarios. Based on the social media simulation archetype Park et al. ([2022](https://arxiv.org/html/2412.17481v2#bib.bib54)),
    Park et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)) propose Stanford
    Town, which leads to a one-day simulation of the life of 25 agents with different
    occupations in a small American town. At the same time, there was work on emotional
    propagation influence Gao et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib22)),
    information cocoon room based on recommendation scenario research Wang et al.
    ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)), and study of social
    movements Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)).
    Researchers propose Urban Generative Intelligence (UGI) Xu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib68))
    to address specific urban issues and simulate complex urban systems, providing
    a multidisciplinary approach to understanding and managing urban complexity. Li
    et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib36)) study doctor agent
    evolution method by hospital simulation. Because doctor agent training is both
    inexpensive and highly effective, this work can quickly scale up the agent to
    handle tens of thousands of cases in just a few days, a task that would take a
    human doctor years to complete. Pan et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib52))
    propose a huge scale of agent simulation, increasing the number of agents to $10^{6}$.
    In social game,like Werewolf Xu et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib70))
    , Avalon Lan et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib34)) ,
    and Minecraft Gong et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib24))
    for LLM-MAS simulation are attempted. Further, some game companies like Netease
    are also actively experimenting with LLM-MAS in their games.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 社会领域。现实世界中的大规模社会实验成本高昂，而社会参与的庞大规模有时可能升级为暴力和破坏，带来潜在的后果Mou等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib49)）。因此，有必要在虚拟环境中进行模拟；模拟可以解决现实环境中过高的开销问题，并且能够以更快的速度在虚拟环境中长时间模拟现实世界的过程Li等人（[2024a](https://arxiv.org/html/2412.17481v2#bib.bib36)）。同时，整个过程可以轻松重复，有利于进一步的研究。研究人员已经做了大量的工作来模拟社交媒体场景。基于社交媒体模拟原型，Park等人（[2022](https://arxiv.org/html/2412.17481v2#bib.bib54)）和Park等人（[2023](https://arxiv.org/html/2412.17481v2#bib.bib53)）提出了“斯坦福小镇”，该项目模拟了美国一个小镇上25个不同职业的代理人的一天生活。同时，还有关于情感传播影响的研究Gao等人（[2023b](https://arxiv.org/html/2412.17481v2#bib.bib22)）、基于推荐场景的“信息茧房”研究Wang等人（[2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)）和社会运动的研究Mou等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib49)）。研究人员提出了城市生成智能（UGI）Xu等人（[2023a](https://arxiv.org/html/2412.17481v2#bib.bib68)），旨在解决特定的城市问题并模拟复杂的城市系统，提供了一个多学科的方式来理解和管理城市复杂性。Li等人（[2024a](https://arxiv.org/html/2412.17481v2#bib.bib36)）通过医院模拟研究了医生代理人演化方法。由于医生代理人训练既便宜又高效，这项工作能够在短短几天内快速扩展代理人，处理数万个病例，而这一任务通常需要人类医生数年才能完成。Pan等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib52)）提出了大规模的代理人模拟，将代理人数量增加到$10^{6}$。在社交游戏中，像狼人杀Xu等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib70)）、阿瓦隆Lan等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib34)）和我的世界Gong等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib24)）等也尝试了LLM-MAS模拟。此外，一些游戏公司，如网易，也在积极地在其游戏中实验LLM-MAS。
- en: Physical domain. For the physical domain, the applications for generative agent
    simulation include mobility behaviors, transportation Gao et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib21)),
    wireless networks, etc. However, there is limited research in the area of multi-generative
    agents. Zou et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib84)) explore
    the application of multiple agents in the wireless field, proposing a framework
    where multiple on-device agents can interact with the environment and exchange
    knowledge to solve a complex task together.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 物理领域。对于物理领域，生成性智能体仿真的应用包括移动行为、运输 [Gao 等人](https://arxiv.org/html/2412.17481v2#bib.bib21)、无线网络等。然而，在多生成智能体领域的研究有限。[Zou
    等人](https://arxiv.org/html/2412.17481v2#bib.bib84) 探索了多个智能体在无线领域的应用，提出了一种框架，其中多个设备上的智能体可以与环境互动并交换知识，共同解决复杂任务。
- en: 4.2 Resources for LLM-MAS simulation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 LLM-MAS 仿真资源
- en: 'We summarize common and open-source LLM-MAS for simulation in Table [2](https://arxiv.org/html/2412.17481v2#S4.T2
    "Table 2 ‣ 4.2 Resources for LLM-MAS simulation ‣ 4 LLM-MAS for Simulating Specific
    Scenarios ‣ A Survey on LLM-based Multi-Agent System: Recent Advances and New
    Frontiers in Application"), including code and benchmarks.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表 [2](https://arxiv.org/html/2412.17481v2#S4.T2 "表 2 ‣ 4.2 LLM-MAS 仿真资源 ‣
    4 LLM-MAS 用于特定场景的仿真 ‣ 基于LLM的多智能体系统调查：最近进展与应用新前沿") 中总结了用于仿真的常见开源 LLM-MAS，包括代码和基准测试。
- en: 'To prove the effectiveness of the simulation, that is, to fit the reality,
    researchers usually evaluate the simulation system by simulating real data. Therefore,
    a realistic dataset with dense users and records is very important for evaluation
    simulation Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)).
    An ideal dataset will be dense: that is, data with a smaller number of users on
    the same scale can better evaluate the simulation capability of the LLM-MAS.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明仿真效果，即与现实相符，研究人员通常通过仿真真实数据来评估仿真系统。因此，具有密集用户和记录的真实数据集对仿真评估非常重要 [Mou 等人](https://arxiv.org/html/2412.17481v2#bib.bib49)。理想的数据集应该是密集的：也就是说，在相同规模下，用户数量较少的数据可以更好地评估
    LLM-MAS 的仿真能力。
- en: For Benchmark, Du and Zhang ([2024](https://arxiv.org/html/2412.17481v2#bib.bib17))
    propose WWQA based on werewolf scenarios to evaluate the agent’s capability in
    a werewolf scenario. SoMoSiMu-Bench Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49))
    provides evaluation benchmarks focusing on individual user behavior and social
    simulation system results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基准测试，[Du 和 Zhang](https://arxiv.org/html/2412.17481v2#bib.bib17) 提出了基于狼人场景的
    WWQA，以评估智能体在狼人场景中的能力。[SoMoSiMu-Bench Mou 等人](https://arxiv.org/html/2412.17481v2#bib.bib49)
    提供了针对个体用户行为和社会仿真系统结果的评估基准。
- en: 'Table 2: Codes and Benchmarks in LLM-MAS for simulation studies. “No Code”
    or “No Benchmark” means the code or benchmark is unavailable.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：LLM-MAS 仿真研究中的代码和基准测试。“无代码”或“无基准测试”表示代码或基准测试不可用。
- en: '| Domain | Subdomain | Paper | Code | Dataset and Benchmark |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 子领域 | 论文 | 代码 | 数据集和基准测试 |'
- en: '| Social | Tiny Society | Huang et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib32))
    | No Code | AdaSociety |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 社会 | 微型社会 | Huang 等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib32))
    | 无代码 | AdaSociety |'
- en: '| Chen et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib8)) | [Code
    Link](https://github.com/relic-yuexi/AgentCourt) | AgentCourt |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib8)) | [代码链接](https://github.com/relic-yuexi/AgentCourt)
    | AgentCourt |'
- en: '| Park et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)) | [Code
    Link](https://github.com/joonspk-research/generative_agents) | No Benchmark or
    Dataset |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Park 等人 ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)) | [代码链接](https://github.com/joonspk-research/generative_agents)
    | 无基准测试或数据集 |'
- en: '| Piatti et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib55)) | [Code
    Link](https://github.com/giorgiopiatti/govsim) | No Benchmark |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Piatti 等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib55)) | [代码链接](https://github.com/giorgiopiatti/govsim)
    | 无基准测试 |'
- en: '| Chuang et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib15)) | [Code
    Link](https://github.com/yunshiuan/llm-agent-opinion-dynamics) | No Benchmark
    or Dataset |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Chuang 等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib15)) | [代码链接](https://github.com/yunshiuan/llm-agent-opinion-dynamics)
    | 无基准测试或数据集 |'
- en: '| Economics | Li et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib37))
    | [Code Link](https://github.com/tsinghua-fib-lab/ACL24-EconAgent) | No Benchmark
    or Dataset |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 经济学 | Li 等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib37)) | [代码链接](https://github.com/tsinghua-fib-lab/ACL24-EconAgent)
    | 无基准测试或数据集 |'
- en: '| Social Media | Wang et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65))
    | [Code Link](https://github.com/RUC-GSAI/YuLan-Rec) | Movielens-1M |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 社交媒体 | Wang 等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib65)) |
    [代码链接](https://github.com/RUC-GSAI/YuLan-Rec) | Movielens-1M |'
- en: '| Gao et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib22)) | No
    Code | Blog Authorship Corpus |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| Gao 等人 ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib22)) | 无代码 | 博客作者语料库
    |'
- en: '| Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)) | [Code
    Link](https://github.com/xymou/social_simulation) | SoMoSiMu-Bench(self) |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| Mou 等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49)) | [代码链接](https://github.com/xymou/social_simulation)
    | SoMoSiMu-Bench(self) |'
- en: '| Game | Du and Zhang ([2024](https://arxiv.org/html/2412.17481v2#bib.bib17))
    | [Code Link](https://github.com/doslim/Evaluate-the-Opinion-Leadership-of-LLMs)
    | WWQA |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 游戏 | Du 和 Zhang ([2024](https://arxiv.org/html/2412.17481v2#bib.bib17)) |
    [代码链接](https://github.com/doslim/Evaluate-the-Opinion-Leadership-of-LLMs) | WWQA
    |'
- en: '| Pan et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib52)) | [Code
    Link](https://github.com/modelscope/agentscope/tree/main/examples/paper_large_scale_simulation)
    | No Benchmark or Dataset |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| Pan 等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib52)) | [代码链接](https://github.com/modelscope/agentscope/tree/main/examples/paper_large_scale_simulation)
    | 无基准或数据集 |'
- en: '| Physical | Wireless | Zou et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib84))
    | No Code | No Benchmark or Dataset |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 物理 | 无线 | Zou 等人 ([2023](https://arxiv.org/html/2412.17481v2#bib.bib84))
    | 无代码 | 无基准或数据集 |'
- en: 4.3 Evaluation of LLM-MAS simulation
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 LLM-MAS 仿真评估
- en: We will discuss the evaluation based on indicators used for assessing LLM-MAS
    as a whole, rather than the capabilities of individual agents.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论基于用于评估LLM-MAS整体的指标，而非单个代理的能力的评估方法。
- en: Consistency. LLM-MAS necessitate a robust congruence with the real world to
    ensure the derivation of meaningful and insightful experimental outcomes. In the
    context of simulation systems, exemplified by UGI Xu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib68)),
    the primary objective lies in faithfully replicating specific real-world scenarios.
    When employed for training agents like SMART Yue et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib76)),
    only those agents that have undergone rigorous training within a virtual environment
    that closely mirrors the real environment can be deemed suitable for deployment
    in real-world settings. Similarly, when utilized for evaluation purposes, such
    as in AgentSims Lin et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib42)),
    the attainment of authentic and reliable evaluation results is contingent upon
    the virtual environment maintaining a high degree of consistency with its real-world
    counterpart. Finally, in the system for collecting data such as BOLAA Liu et al.
    ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib48)), consistency also ensures
    the validity of the data. Therefore, an important performance measure of LLM-MAS
    is its consistency with the real situation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性。LLM-MAS 需要与现实世界保持良好的一致性，以确保得出有意义且富有洞察力的实验结果。在仿真系统的背景下，以UGI Xu 等人 ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib68))
    为例，主要目标是忠实地复制特定的现实场景。当用于训练像 SMART Yue 等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib76))
    这样的代理时，只有那些在与现实环境高度相似的虚拟环境中经过严格训练的代理，才能被认为适合在真实环境中部署。类似地，当用于评估目的时，例如在 AgentSims
    Lin 等人 ([2023](https://arxiv.org/html/2412.17481v2#bib.bib42)) 中，只有当虚拟环境与现实世界保持高度一致时，才能获得真实可靠的评估结果。最后，在收集数据的系统中，如
    BOLAA Liu 等人 ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib48))，一致性也确保了数据的有效性。因此，LLM-MAS
    的一个重要性能指标是与现实情况的一致性。
- en: Information dissemination. Compare the differences between information dissemination
    behavior in the system and reality using time series analysis methods. Information
    dissemination can to some extent reflect the nature of media; therefore, a realistic
    multi-agent system should have a similar information dissemination trend to the
    real world. Abdelzaher et al. ([2020](https://arxiv.org/html/2412.17481v2#bib.bib3))
    compare the changes in the number of events occurring each day in an online social
    media simulation environment; S3 Gao et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib22))
    compare the number of users who are aware of a certain event every day, as well
    as the changes in emotional density and support rate for that event every day;
    a similar approach is also used in Stanford Town Park et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib53)).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 信息传播。通过时间序列分析方法，比较系统中信息传播行为与现实中的差异。信息传播在一定程度上能够反映媒体的本质；因此，现实的多智能体系统应该具有与现实世界相似的信息传播趋势。Abdelzaher等人（[2020](https://arxiv.org/html/2412.17481v2#bib.bib3)）比较了在线社交媒体模拟环境中每天发生的事件数量变化；S3
    Gao等人（[2023b](https://arxiv.org/html/2412.17481v2#bib.bib22)）比较了每天对某一事件知晓的用户数量，以及该事件的情感密度和支持率的每日变化；斯坦福镇公园的类似方法也被用于评估（[2023](https://arxiv.org/html/2412.17481v2#bib.bib53)）。
- en: 5 LLM-MAS for Evaluating Generative Agents
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LLM-MAS用于评估生成代理
- en: 'With LLMs prevailing in the community, how to evaluate the ability of LLMs
    is an open question. Existing evaluation methods suffer from the following shortcomings:
    (i) constrained evaluation abilities, (ii) vulnerable benchmarks, and (iii) unobjective
    metrics. The complexity and diversity of LLM-MAS have indicated that LLM-MAS can
    evaluate LLMs. However, how to design specific evaluation indicators and evaluation
    methods has puzzled researchers. Similarly, LLM-MAS can also be used in training
    generative agents. We summarize three aspects of training: (i) Supervised Fine-Tuning
    (SFT) (ii) reinforcement learning (RL) (iii) Synthesizing data for training.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM在社区中的广泛应用，如何评估LLM的能力仍然是一个开放性问题。现有的评估方法存在以下缺陷：（i）评估能力受限，（ii）基准脆弱，（iii）评估指标不客观。LLM-MAS的复杂性和多样性表明，LLM-MAS可以用于评估LLM。然而，如何设计具体的评估指标和评估方法一直困扰着研究人员。同样，LLM-MAS也可以用于训练生成代理。我们总结了三方面的训练：（i）监督微调（SFT），（ii）强化学习（RL），（iii）合成数据用于训练。
- en: 5.1 Representative LLM-MAS for Evaluating Generative Agents
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 用于评估生成代理的代表性LLM-MAS
- en: LLM-MAS can provide rewards to agents, and these rewards can be used to evaluate
    or train generative agents, which will be discussed below.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: LLM-MAS可以为代理提供奖励，这些奖励可以用来评估或训练生成代理，下面将进一步讨论。
- en: Evaluation of generative agents. Researchers study generative agents by putting
    them into LLM-MAS. In LLM-MAS, researchers can further study the LLM’s strategic
    capabilities in different scenes, such as long strategic ability Chen et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)),
    leadership strategy Xu et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71))
    and competitiveness strategy Zhao et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib82)).
    In the emotional field, MuMA-ToM Shi et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib61))
    is used to evaluate the ability of agents to understand and reason about human
    interactions in a real home environment through video and text descriptions.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 生成代理的评估。研究人员通过将生成代理放入LLM-MAS中来研究生成代理。在LLM-MAS中，研究人员可以进一步研究LLM在不同场景中的战略能力，例如长远战略能力（Chen等人，[2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)），领导力战略（Xu等人，[2023c](https://arxiv.org/html/2412.17481v2#bib.bib71)）和竞争力战略（Zhao等人，[2024b](https://arxiv.org/html/2412.17481v2#bib.bib82)）。在情感领域，MuMA-ToM
    Shi等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib61)）通过视频和文本描述来评估代理在现实家庭环境中理解和推理人类互动的能力。
- en: Training on generative agents. Li et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib38))
    enhance the data to Supervised Fine-Tuning (SFT) generative agents with LLM-MAS. Xu
    et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71)) have created generative
    agents to overcome the intrinsic bias from LLMs by proposing a novel framework
    that powers generative agents with multi-agent reinforcement learning Xu et al.
    ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71)). For LLM-MAS, Yue et al.
    ([2024](https://arxiv.org/html/2412.17481v2#bib.bib76)) split complex trajectories
    in knowledge-intensive tasks into subtasks, proposing a co-training paradigm of
    the multi-agent framework, Long- and Short-Trajectory Learning, which ensures
    synergy while keeping the fine-grained performance of each agent. RLHF has been
    criticized for its high cost. Liu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib44))
    propose an alignment scheme based on a multi-agent system, effectively addressing
    instability and reward gaming concerns associated with reward-based RL optimization.
    Either way, LLM-MAS are essentially viewed as an environment in RL with different
    ways of getting rewards from the environment.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成代理的训练方面，Li 等人 ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib38)) 通过
    LLM-MAS 强化数据，提升了监督微调（SFT）生成代理的效果。Xu 等人 ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71))
    提出了一个新框架，通过多智能体强化学习，使生成代理克服了 LLM 内在的偏差。对于 LLM-MAS，Yue 等人 ([2024](https://arxiv.org/html/2412.17481v2#bib.bib76))
    将知识密集型任务中的复杂轨迹分解为子任务，提出了一种多智能体框架的协同训练范式——长短轨迹学习（Long- and Short-Trajectory Learning），该方法确保了协同作用，同时保持了每个智能体的细粒度表现。RLHF
    被批评为成本过高。Liu 等人 ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib44)) 提出了一个基于多智能体系统的对齐方案，有效地解决了与基于奖励的
    RL 优化相关的不稳定性和奖励博弈问题。无论如何，LLM-MAS 本质上被视为 RL 中的一个环境，通过不同的方式从环境中获取奖励。
- en: 5.2 Resources of LLM-MAS for evaluations
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 LLM-MAS 评估资源
- en: 'Table [3](https://arxiv.org/html/2412.17481v2#S5.T3 "Table 3 ‣ 5.2 Resources
    of LLM-MAS for evaluations ‣ 5 LLM-MAS for Evaluating Generative Agents ‣ A Survey
    on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application")
    shows the work with code, dataset, and benchmark we summarize, serving as a reference
    for future researchers.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [3](https://arxiv.org/html/2412.17481v2#S5.T3 "表 3 ‣ 5.2 LLM-MAS 评估资源 ‣ 5
    评估生成代理的 LLM-MAS ‣ 基于 LLM 的多智能体系统：近期进展与应用前沿综述") 显示了我们总结的含有代码、数据集和基准的相关工作，供未来的研究者参考。
- en: 'Table 3: Codes and Benchmarks in LLM-MAS for evaluation studies. “No Code”
    or “No Benchmark” means the code or benchmark is unavailable.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：LLM-MAS 评估研究中的代码和基准。“无代码”或“无基准”意味着代码或基准不可用。
- en: '| Domain | Subdomain | Paper | Code | Dataset and Benchmark |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 子领域 | 论文 | 代码 | 数据集和基准 |'
- en: '| Evaluation of generative agents | Strategy | Liu et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib46))
    | [Code Link](https://github.com/THUDM/AgentBench) | AGENTBENCH |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 生成代理的评估 | 策略 | Liu 等人 ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib46))
    | [代码链接](https://github.com/THUDM/AgentBench) | AGENTBENCH |'
- en: '| Bandi and Harrasse ([2024](https://arxiv.org/html/2412.17481v2#bib.bib5))
    | No Code | MT-Bench |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Bandi 和 Harrasse ([2024](https://arxiv.org/html/2412.17481v2#bib.bib5)) |
    无代码 | MT-Bench |'
- en: '| Chan et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib6)) | [Code
    Link](https://github.com/thunlp/ChatEval) | ChatEval |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Chan 等人 ([2023](https://arxiv.org/html/2412.17481v2#bib.bib6)) | [代码链接](https://github.com/thunlp/ChatEval)
    | ChatEval |'
- en: '| Chen et al. ([2024d](https://arxiv.org/html/2412.17481v2#bib.bib10)) | [Code
    Link](https://github.com/THU-BPM/LLMArena.) | LLMARENA |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2024d](https://arxiv.org/html/2412.17481v2#bib.bib10)) | [代码链接](https://github.com/THU-BPM/LLMArena.)
    | LLMARENA |'
- en: '| Xu et al. ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib69)) | [Code
    Link](https://github.com/cathyxl/MAgIC) | MAgIC |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等人 ([2023b](https://arxiv.org/html/2412.17481v2#bib.bib69)) | [代码链接](https://github.com/cathyxl/MAgIC)
    | MAgIC |'
- en: '| Huang et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib31)) | [Code
    Link](https://github.com/snap-stanford/MLAgentBench) | MLAgentBench |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| Huang 等人 ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib31)) | [代码链接](https://github.com/snap-stanford/MLAgentBench)
    | MLAgentBench |'
- en: '| Chen et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)) | [Code
    Link](https://github.com/jiangjiechen/auction-arena) | AUCARENA |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等人 ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)) | [代码链接](https://github.com/jiangjiechen/auction-arena)
    | AUCARENA |'
- en: '| Emotion | Zhang et al. ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib80))
    | [Code Link](https://github.com/AI4Good24/PsySafe) | PsySafe |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 情感 | Zhang 等人 ([2024b](https://arxiv.org/html/2412.17481v2#bib.bib80)) |
    [代码链接](https://github.com/AI4Good24/PsySafe) | PsySafe |'
- en: '| Shi et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib61)) | [Code
    Link](https://github.com/SCAI-JHU/MuMMA-ToM) | MuMA-ToM |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Shi et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib61)) | [代码链接](https://github.com/SCAI-JHU/MuMMA-ToM)
    | MuMA-ToM |'
- en: '| Training on generative agents | SFT on LLM-MAS | Li et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib38))
    | [Code Link](https://github.com/lirenhao1997/CoEvol) | MT-Bench, AlpacaEval |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 生成代理的训练 | LLM-MAS中的SFT | Li et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib38))
    | [代码链接](https://github.com/lirenhao1997/CoEvol) | MT-Bench, AlpacaEval |'
- en: '| MARL on LLM-MAS | Xu et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71))
    | No Code | No dataset or benchmark |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| LLM-MAS中的MARL | Xu et al. ([2023c](https://arxiv.org/html/2412.17481v2#bib.bib71))
    | 无代码 | 无数据集或基准 |'
- en: '| Synthesized Ddata | Liu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib44))
    | [Code Link](https://github.com/agi-templar/Stable-Alignment) | HH, Moral Stories,
    MIC, ETHICS-Deontology, TruthfulQA |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 合成数据 | Liu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib44))
    | [代码链接](https://github.com/agi-templar/Stable-Alignment) | HH、道德故事、MIC、ETHICS-义务论、TruthfulQA
    |'
- en: 6 Challenges and Future Directions
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 挑战与未来方向
- en: While previous work on LLM-MAS has obtained many remarkable successes, this
    field is still at its initial stage, and there are several significant challenges
    that need to be addressed in its development. In the following, we outline several
    key challenges along with potential future directions.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在LLM-MAS的先前工作中取得了许多显著的成功，但这一领域仍处于初期阶段，且在其发展过程中存在几个重大挑战需要解决。以下是我们概述的几个关键挑战及其潜在的未来方向。
- en: 6.1 Challenges posed by generative agents
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 生成代理带来的挑战
- en: Generative agents are an integral part of LLM-MAS. However, the generative agents
    have some shortcomings due to the inherent characteristics of the base model LLMs,
    which will be carefully discussed below.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 生成代理是LLM-MAS的一个不可或缺的部分。然而，由于基础模型LLM的固有特性，生成代理存在一些缺点，以下将对此进行详细讨论。
- en: Challenges. (i) Generalized alignment for simulation Liu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib44)).
    When the agents are leveraged for real-world simulation, a perfect generative
    agent should be able to depict diverse traits Wang et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib64))
    honestly. However, due to the training method of the foundation model OpenAI et al.
    ([2024](https://arxiv.org/html/2412.17481v2#bib.bib50)), generative agents usually
    cannot be aligned with mock objects. (ii) Hallucination. Generative agents have
    a certain probability of hallucination in their interaction with other agents Du
    et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib18)). Various enhancement
    methods can alleviate this problem but cannot solve it (iii) Lack of sufficient
    long text capability. When processing complex information, generative agents forget
    the input information because of the lack of long-text ability Zhao et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib81)).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战。(i) 面向仿真任务的广义对齐 Liu et al. ([2023a](https://arxiv.org/html/2412.17481v2#bib.bib44))。当代理被用于现实世界仿真时，一个完美的生成代理应该能够真实地描绘出多样化的特征 Wang
    et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib64))。然而，由于基础模型的训练方法 OpenAI
    et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib50))，生成代理通常无法与虚拟对象对齐。(ii)
    幻觉。生成代理在与其他代理互动时有一定的幻觉概率 Du et al. ([2023](https://arxiv.org/html/2412.17481v2#bib.bib18))。各种增强方法可以缓解这个问题，但无法解决。(iii)
    缺乏足够的长文本处理能力。在处理复杂信息时，由于缺乏长文本能力，生成代理会忘记输入的信息 Zhao et al. ([2024a](https://arxiv.org/html/2412.17481v2#bib.bib81))。
- en: Future directions. The improvement of the ability of a single agent or the ability
    of the base model has always been a hot topic. Researchers have focused on enhancing
    alignment, reducing hallucination, and improving the ability of long text. The
    proposal of the new generation of Open AI model o1 Int ([2024](https://arxiv.org/html/2412.17481v2#bib.bib1)),
    provides researchers with new ideas, that is, to use more complex reasoning to
    enhance the ability of the model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 未来方向。单个代理的能力或基础模型的能力的提升一直是一个热门话题。研究人员一直专注于增强对齐性、减少幻觉并提高长文本处理能力。新一代OpenAI模型o1
    Int的提出（[2024](https://arxiv.org/html/2412.17481v2#bib.bib1)）为研究人员提供了新的思路，即通过更复杂的推理来增强模型的能力。
- en: 6.2 Challenges posed by interactions
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 互动带来的挑战
- en: Due to the complexity, autoregressive, and other characteristics of LLM-MAS,
    there are many problems in the practical application of the system. Two main problems,
    *Efficiency explosion*, and *Accumulative Effect*, are listed in the following.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM-MAS的复杂性、自回归特性以及其他特性，系统的实际应用中存在许多问题。以下列出了两个主要问题，*效率爆炸*和*累积效应*。
- en: Efficiency explosion. Due to their autoregressive architecture, LLMs typically
    have slow inference speeds. However, generative agents need to query LLMs for
    each action multiple times, such as extracting information from memory, making
    plans before taking actions, and so on. When the LLM-MAS scales up, this problem
    will be magnified, especially for generative agents that have a large action space.
    SoMoSiMu-Bench Mou et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib49))
    replaces the edge generative agents with rule-based agents, alleviating this problem.
    However, for LLM-MAS with a complex action space in generative agents, this problem
    remains unsolved.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 效率爆炸。由于LLM的自回归架构，通常具有较慢的推理速度。然而，生成代理需要多次查询LLM以执行每个操作，如从记忆中提取信息、在采取行动前进行计划等。当LLM-MAS规模扩大时，这个问题会被放大，特别是对于具有大行动空间的生成代理。SoMoSiMu-Bench
    Mou等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib49)）用基于规则的代理替换了边缘生成代理，从而缓解了这一问题。然而，对于具有复杂行动空间的生成代理的LLM-MAS，这个问题仍未得到解决。
- en: Accumulative Effect. Since each round of LLM-MAS is based on the results of
    the previous round, and LLM-MAS have a great impact on the subsequent results.
    Researchers have used a rule-based model for intermediate error correction Chen
    et al. ([2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)), but there is still
    a lot of room for improvement. IOA Chen et al. ([2024f](https://arxiv.org/html/2412.17481v2#bib.bib12))
    proposed an Internet-like communication architecture, which made LLM-MAS more
    scalable and enhanced the adaptability to dynamic tasks.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 累积效应。由于每轮LLM-MAS都基于前一轮的结果，并且LLM-MAS对后续结果有很大影响，研究人员采用了基于规则的模型进行中间错误修正（Chen等人，[2024c](https://arxiv.org/html/2412.17481v2#bib.bib9)），但仍然有很大的改进空间。IOA
    Chen等人（[2024f](https://arxiv.org/html/2412.17481v2#bib.bib12)）提出了一种类似互联网的通信架构，使得LLM-MAS更加可扩展，并增强了其对动态任务的适应能力。
- en: Future directions. Industry academia has been making efforts to reduce the communication
    cost of LLM-MAS, such as alignment-based method OPTIMA Chen et al. ([2024g](https://arxiv.org/html/2412.17481v2#bib.bib13))
    and Industrialized parallel message method AgentScope Gao et al. ([2024](https://arxiv.org/html/2412.17481v2#bib.bib23)),
    but it is still in the basic stage and has a large research space.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 未来方向。业界和学术界一直在努力降低LLM-MAS的通信成本，例如基于对齐的方法OPTIMA Chen等人（[2024g](https://arxiv.org/html/2412.17481v2#bib.bib13)）和工业化并行消息方法AgentScope
    Gao等人（[2024](https://arxiv.org/html/2412.17481v2#bib.bib23)），但仍处于基础阶段，且有很大的研究空间。
- en: 6.3 Challenges of Evaluating for LLM-MAS
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 LLM-MAS评估的挑战
- en: 'Lack of Objective metrics for group behavior. As shown in Section [4.3](https://arxiv.org/html/2412.17481v2#S4.SS3
    "4.3 Evaluation of LLM-MAS simulation ‣ 4 LLM-MAS for Simulating Specific Scenarios
    ‣ A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers
    in Application"), due to the diversity, complexity, and unpredictability of multi-agent
    environments, it is difficult to obtain sufficiently detailed, specific, and direct
    system evaluation indicators from current work at the population level. At present,
    researchers mainly compare the distribution of the system and real environments
    to evaluate LLM-MAS, which lacks details for the LLM-MAS running process.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '缺乏针对群体行为的客观度量标准。如[4.3节](https://arxiv.org/html/2412.17481v2#S4.SS3 "4.3 Evaluation
    of LLM-MAS simulation ‣ 4 LLM-MAS for Simulating Specific Scenarios ‣ A Survey
    on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application")所示，由于多代理环境的多样性、复杂性和不可预测性，从当前的研究工作中很难在群体层面获得足够详细、具体和直接的系统评估指标。目前，研究人员主要通过比较系统与真实环境的分布来评估LLM-MAS，但这对于LLM-MAS的运行过程缺乏足够的细节。'
- en: Automated evaluation and benchmark. Different LLM-MAS of the same kind cannot
    be compared because of the lack of a benchmark for LLM-MAS. Further, there is
    a lack of a common benchmark framework for both individual and total-based evaluation,
    that can be used to evaluate most LLM-MAS.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化评估和基准测试。由于缺乏LLM-MAS的基准测试，不同类型的LLM-MAS无法进行比较。此外，缺乏一个通用的基准框架，既可以进行单个评价也可以进行整体评价，用于评估大多数LLM-MAS。
- en: Future directions. Studying large-scale LLM-MAS will be a new research hotspot,
    from which researchers will evaluate and discover new scale effects. In the meantime,
    common test benchmarks and evaluation methods will also emerge in future research.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 未来方向。研究大规模LLM-MAS将成为一个新的研究热点，研究人员将评估并发现新的规模效应。同时，未来的研究中还将出现常见的测试基准和评估方法。
- en: 7 Conclusion
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: 'In this survey, we systematically summarize existing research in the LLM-based
    Multi-Agent Systems (LLM-MAS) field. We present and review these studies from
    three application aspects: task-solving, simulation, and evaluation of the LLM-MAS.
    We provide a detailed taxonomy to draw connections among the existing research,
    summarizing the major techniques and their development histories for each of these
    aspects. In addition to reviewing the previous work, we also propose several challenges
    in this field, which are expected to guide potential future directions.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本文系统地总结了现有的基于LLM的多智能体系统（LLM-MAS）领域的研究。我们从三个应用方面对这些研究进行了呈现和回顾：任务求解、仿真和LLM-MAS的评估。我们提供了一个详细的分类法，旨在建立现有研究之间的联系，总结每个方面的主要技术及其发展历史。除了回顾先前的工作，我们还提出了该领域的几个挑战，期望能为未来的潜在研究方向提供指导。
- en: Limitations
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: 'We have made our best effort, but some limitations may still exist. Due to
    page limitations, we can only provide a brief summary of each method without exhaustive
    technical details. On the other hand, we primarily collect studies from *ACL,
    NeurIPS, ICLR, AAAI, and arXiv, and there is a chance that we may have missed
    some important work published in other venues. In application, we primarily list
    representative LLM-MAS resources with open code in Table [1](https://arxiv.org/html/2412.17481v2#S3.T1
    "Table 1 ‣ 3.2 Resources of LLM-MAS for Solving Complex Tasks ‣ 3 LLM-MAS for
    Solving Complex Tasks ‣ A Survey on LLM-based Multi-Agent System: Recent Advances
    and New Frontiers in Application"), Table [2](https://arxiv.org/html/2412.17481v2#S4.T2
    "Table 2 ‣ 4.2 Resources for LLM-MAS simulation ‣ 4 LLM-MAS for Simulating Specific
    Scenarios ‣ A Survey on LLM-based Multi-Agent System: Recent Advances and New
    Frontiers in Application"), and Table [3](https://arxiv.org/html/2412.17481v2#S5.T3
    "Table 3 ‣ 5.2 Resources of LLM-MAS for evaluations ‣ 5 LLM-MAS for Evaluating
    Generative Agents ‣ A Survey on LLM-based Multi-Agent System: Recent Advances
    and New Frontiers in Application"). More complete papers can be found in [https://github.com/bianhua-12/Multi-generative_Agent_System_survey](https://github.com/bianhua-12/Multi-generative_Agent_System_survey).
    We recognize the timeliness of our work, and we will stay abreast of discussions
    within the research community, updating opinions and supplementing overlooked
    work in the future.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管我们尽最大努力，但仍可能存在一些局限性。由于篇幅限制，我们只能简要总结每种方法，而无法提供详尽的技术细节。另一方面，我们主要收集了来自*ACL、NeurIPS、ICLR、AAAI和arXiv*的研究，可能遗漏了其他期刊和会议中发表的重要工作。在应用部分，我们主要列出了具有开放代码的代表性LLM-MAS资源，详见表[1](https://arxiv.org/html/2412.17481v2#S3.T1
    "Table 1 ‣ 3.2 Resources of LLM-MAS for Solving Complex Tasks ‣ 3 LLM-MAS for
    Solving Complex Tasks ‣ A Survey on LLM-based Multi-Agent System: Recent Advances
    and New Frontiers in Application")、表[2](https://arxiv.org/html/2412.17481v2#S4.T2
    "Table 2 ‣ 4.2 Resources for LLM-MAS simulation ‣ 4 LLM-MAS for Simulating Specific
    Scenarios ‣ A Survey on LLM-based Multi-Agent System: Recent Advances and New
    Frontiers in Application")和表[3](https://arxiv.org/html/2412.17481v2#S5.T3 "Table
    3 ‣ 5.2 Resources of LLM-MAS for evaluations ‣ 5 LLM-MAS for Evaluating Generative
    Agents ‣ A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers
    in Application")。更完整的论文可以在[https://github.com/bianhua-12/Multi-generative_Agent_System_survey](https://github.com/bianhua-12/Multi-generative_Agent_System_survey)中找到。我们认识到我们工作的时效性，未来我们将紧跟研究社区的讨论，更新观点并补充遗漏的工作。'
- en: Acknowledgments
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This research was supported by the National Key Research and Development Program
    (No. 2022YFF0902100), and the Nature Scientific Foundation of Heilongjiang Province
    (YQ2021F006).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了国家重点研发计划（编号2022YFF0902100）和黑龙江省自然科学基金（YQ2021F006）的支持。
- en: References
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Int (2024) 2024. Introducing OpenAI o1. https://openai.com/o1/.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Int (2024) 2024. Introducing OpenAI o1. https://openai.com/o1/.
- en: Ope (2024) 2024. Openai/swarm. OpenAI.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ope (2024) 2024. Openai/swarm. OpenAI.
- en: Abdelzaher et al. (2020) Tarek Abdelzaher, Jiawei Han, Yifan Hao, Andong Jing,
    Dongxin Liu, Shengzhong Liu, Hoang Hai Nguyen, David M Nicol, Huajie Shao, Tianshi
    Wang, et al. 2020. Multiscale online media simulation with socialcube. *Computational
    and Mathematical Organization Theory*, 26:145–174.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdelzaher等（2020）Tarek Abdelzaher, Jiawei Han, Yifan Hao, Andong Jing, Dongxin
    Liu, Shengzhong Liu, Hoang Hai Nguyen, David M Nicol, Huajie Shao, Tianshi Wang等人。2020年。使用SocialCube的多尺度在线媒体仿真。*计算与数学组织理论*，26:145–174。
- en: Balaji and Srinivasan (2010) P. G. Balaji and D. Srinivasan. 2010. [An Introduction
    to Multi-Agent Systems](https://doi.org/10.1007/978-3-642-14435-6_1). In Dipti
    Srinivasan and Lakhmi C. Jain, editors, *Innovations in Multi-Agent Systems and
    Applications - 1*, pages 1–27\. Springer, Berlin, Heidelberg.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balaji 和 Srinivasan (2010) P. G. Balaji 和 D. Srinivasan. 2010. [多代理系统简介](https://doi.org/10.1007/978-3-642-14435-6_1).
    见 Dipti Srinivasan 和 Lakhmi C. Jain 主编，*多代理系统与应用创新 - 1*，第1-27页。Springer，柏林，海德堡.
- en: Bandi and Harrasse (2024) Chaithanya Bandi and Abir Harrasse. 2024. [Adversarial
    Multi-Agent Evaluation of Large Language Models through Iterative Debates](https://doi.org/10.48550/arXiv.2410.04663).
    *Preprint*, arXiv:2410.04663.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bandi 和 Harrasse (2024) Chaithanya Bandi 和 Abir Harrasse. 2024. [通过迭代辩论对大型语言模型进行对抗性多代理评估](https://doi.org/10.48550/arXiv.2410.04663).
    *预印本*, arXiv:2410.04663.
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. [ChatEval: Towards Better LLM-based
    Evaluators through Multi-Agent Debate](https://doi.org/10.48550/arXiv.2308.07201).
    *Preprint*, arXiv:2308.07201.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chan 等人 (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, 和 Zhiyuan Liu. 2023. [ChatEval: 通过多代理辩论提高基于大型语言模型的评估器](https://doi.org/10.48550/arXiv.2308.07201).
    *预印本*, arXiv:2308.07201.'
- en: 'Chen et al. (2024a) Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay,
    Börje F. Karlsson, Jie Fu, and Yemin Shi. 2024a. [AutoAgents: A Framework for
    Automatic Agent Generation](https://doi.org/10.48550/arXiv.2309.17288). *Preprint*,
    arXiv:2309.17288.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2024a) Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje
    F. Karlsson, Jie Fu, 和 Yemin Shi. 2024a. [AutoAgents：自动生成代理的框架](https://doi.org/10.48550/arXiv.2309.17288).
    *预印本*, arXiv:2309.17288.
- en: 'Chen et al. (2024b) Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li,
    Ziqiang Liu, Chengming Li, Qiang Qu, Shiwen Ni, and Min Yang. 2024b. [AgentCourt:
    Simulating Court with Adversarial Evolvable Lawyer Agents](https://doi.org/10.48550/arXiv.2408.08089).
    *Preprint*, arXiv:2408.08089.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2024b) Guhong Chen, Liyang Fan, Zihan Gong, Nan Xie, Zixuan Li, Ziqiang
    Liu, Chengming Li, Qiang Qu, Shiwen Ni, 和 Min Yang. 2024b. [AgentCourt：通过对抗性可进化的律师代理模拟法庭](https://doi.org/10.48550/arXiv.2408.08089).
    *预印本*, arXiv:2408.08089.
- en: 'Chen et al. (2024c) Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder,
    and Kyle Richardson. 2024c. [Put Your Money Where Your Mouth Is: Evaluating Strategic
    Planning and Execution of LLM Agents in an Auction Arena](https://doi.org/10.48550/arXiv.2310.05746).
    *Preprint*, arXiv:2310.05746.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2024c) Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder,
    和 Kyle Richardson. 2024c. [把钱放在嘴巴能说的地方：评估大型语言模型代理在拍卖场中的战略规划与执行](https://doi.org/10.48550/arXiv.2310.05746).
    *预印本*, arXiv:2310.05746.
- en: 'Chen et al. (2024d) Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, Wei-Wei
    Tu, Zhaofeng He, and Lijie Wen. 2024d. [LLMArena: Assessing Capabilities of Large
    Language Models in Dynamic Multi-Agent Environments](https://doi.org/10.18653/v1/2024.acl-long.705).
    In *Proceedings of the 62nd Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 13055–13077.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2024d) Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, Wei-Wei Tu,
    Zhaofeng He, 和 Lijie Wen. 2024d. [LLMArena：在动态多代理环境中评估大型语言模型的能力](https://doi.org/10.18653/v1/2024.acl-long.705).
    见 *第62届计算语言学协会年会论文集（第1卷：长篇论文）*，第13055-13077页.
- en: 'Chen et al. (2024e) Justin Chen, Swarnadeep Saha, and Mohit Bansal. 2024e.
    [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse
    LLMs](https://doi.org/10.18653/v1/2024.acl-long.381). In *Proceedings of the 62nd
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers)*, pages 7066–7085, Bangkok, Thailand. Association for Computational Linguistics.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等人 (2024e) Justin Chen, Swarnadeep Saha, 和 Mohit Bansal. 2024e. [ReConcile:
    圆桌会议通过多样化大型语言模型的一致性提高推理能力](https://doi.org/10.18653/v1/2024.acl-long.381). 见 *第62届计算语言学协会年会论文集（第1卷：长篇论文）*，第7066-7085页，泰国曼谷。计算语言学协会.'
- en: 'Chen et al. (2024f) Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian,
    Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, and Maosong Sun. 2024f. [Internet
    of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence](https://doi.org/10.48550/arXiv.2407.07061).
    *Preprint*, arXiv:2407.07061.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2024f) Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang
    Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, 和 Maosong Sun. 2024f. [智能代理互联网：编织异质代理的协同智能网络](https://doi.org/10.48550/arXiv.2407.07061).
    *预印本*, arXiv:2407.07061.
- en: 'Chen et al. (2024g) Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan
    Liu, and Maosong Sun. 2024g. [Optima: Optimizing Effectiveness and Efficiency
    for LLM-Based Multi-Agent System](https://doi.org/10.48550/arXiv.2410.08115).
    *Preprint*, arXiv:2410.08115.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen等人（2024g） Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu,
    和 Maosong Sun. 2024g. [Optima: 优化大语言模型基础的多代理系统的有效性和效率](https://doi.org/10.48550/arXiv.2410.08115).
    *预印本*，arXiv:2410.08115。'
- en: 'Cheng et al. (2024) Yi Cheng, Wenge Liu, Jian Wang, Chak Tou Leong, Yi Ouyang,
    Wenjie Li, Xian Wu, and Yefeng Zheng. 2024. [Cooper: Coordinating Specialized
    Agents towards a Complex Dialogue Goal](https://doi.org/10.1609/aaai.v38i16.29739).
    *Proceedings of the AAAI Conference on Artificial Intelligence*, 38(16):17853–17861.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cheng等人（2024） Yi Cheng, Wenge Liu, Jian Wang, Chak Tou Leong, Yi Ouyang, Wenjie
    Li, Xian Wu, 和 Yefeng Zheng. 2024. [Cooper: 协调专门代理以实现复杂对话目标](https://doi.org/10.1609/aaai.v38i16.29739).
    *AAAI人工智能会议论文集*，38(16):17853–17861。'
- en: 'Chuang et al. (2024) Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth
    Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy Rogers.
    2024. [Simulating Opinion Dynamics with Networks of LLM-based Agents](https://doi.org/10.18653/v1/2024.findings-naacl.211).
    In *Findings of the Association for Computational Linguistics: NAACL 2024*, pages
    3326–3346, Mexico City, Mexico. Association for Computational Linguistics.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang等人（2024） Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh,
    Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, 和 Timothy Rogers. 2024. [基于大语言模型的代理网络模拟意见动态](https://doi.org/10.18653/v1/2024.findings-naacl.211).
    发表在 *计算语言学会发现：NAACL 2024*，页面3326–3346，墨西哥城，墨西哥。计算语言学会。
- en: 'Chuang and Rogers (2023) Yun-Shiuan Chuang and Timothy T. Rogers. 2023. [Computational
    Agent-based Models in Opinion Dynamics: A Survey on Social Simulations and Empirical
    Studies](https://doi.org/10.48550/arXiv.2306.03446). *Preprint*, arXiv:2306.03446.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang和Rogers（2023） Yun-Shiuan Chuang 和 Timothy T. Rogers. 2023. [基于计算代理的意见动态模型：关于社会模拟和实证研究的综述](https://doi.org/10.48550/arXiv.2306.03446).
    *预印本*，arXiv:2306.03446。
- en: Du and Zhang (2024) Silin Du and Xiaowei Zhang. 2024. Helmsman of the Masses?
    Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game.
    In *First Conference on Language Modeling*.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du和Zhang（2024） Silin Du 和 Xiaowei Zhang. 2024. 大众的舵手？评估狼人游戏中大语言模型的意见领导力。发表在
    *第一次语言建模会议*。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum,
    and Igor Mordatch. 2023. [Improving Factuality and Reasoning in Language Models
    through Multiagent Debate](https://doi.org/10.48550/arXiv.2305.14325). *Preprint*,
    arXiv:2305.14325.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du等人（2023） Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, 和 Igor
    Mordatch. 2023. [通过多代理辩论提升语言模型的事实性和推理能力](https://doi.org/10.48550/arXiv.2305.14325).
    *预印本*，arXiv:2305.14325。
- en: Du et al. (2024) Zhuoyun Du, Chen Qian, Wei Liu, Zihao Xie, Yifei Wang, Yufan
    Dang, Weize Chen, and Cheng Yang. 2024. [Multi-Agent Software Development through
    Cross-Team Collaboration](https://doi.org/10.48550/arXiv.2406.08979). *Preprint*,
    arXiv:2406.08979.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du等人（2024） Zhuoyun Du, Chen Qian, Wei Liu, Zihao Xie, Yifei Wang, Yufan Dang,
    Weize Chen, 和 Cheng Yang. 2024. [通过跨团队合作开发多代理软件](https://doi.org/10.48550/arXiv.2406.08979).
    *预印本*，arXiv:2406.08979。
- en: Dubey et al. (2024) Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek
    Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, et al. 2024. [The Llama 3
    Herd of Models](https://doi.org/10.48550/arXiv.2407.21783). *Preprint*, arXiv:2407.21783.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubey等人（2024） Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian,
    Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur 等人. 2024. [Llama 3 模型群](https://doi.org/10.48550/arXiv.2407.21783).
    *预印本*，arXiv:2407.21783。
- en: 'Gao et al. (2023a) Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding,
    Zhilun Zhou, Fengli Xu, and Yong Li. 2023a. [Large Language Models Empowered Agent-based
    Modeling and Simulation: A Survey and Perspectives](https://doi.org/10.48550/arXiv.2312.11970).
    *Preprint*, arXiv:2312.11970.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao等人（2023a） Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun
    Zhou, Fengli Xu, 和 Yong Li. 2023a. [大语言模型赋能的基于代理的建模与仿真：综述与展望](https://doi.org/10.48550/arXiv.2312.11970).
    *预印本*，arXiv:2312.11970。
- en: 'Gao et al. (2023b) Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua
    Piao, Huandong Wang, Depeng Jin, and Yong Li. 2023b. [S3: Social-network Simulation
    System with Large Language Model-Empowered Agents](https://doi.org/10.48550/arXiv.2307.14984).
    *Preprint*, arXiv:2307.14984.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao等人（2023b） Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao,
    Huandong Wang, Depeng Jin, 和 Yong Li. 2023b. [S3: 基于大语言模型增强代理的社交网络模拟系统](https://doi.org/10.48550/arXiv.2307.14984).
    *预印本*，arXiv:2307.14984。'
- en: 'Gao et al. (2024) Dawei Gao, Zitao Li, Xuchen Pan, Weirui Kuang, Zhijian Ma,
    Bingchen Qian, Fei Wei, Wenhao Zhang, Yuexiang Xie, Daoyuan Chen, Liuyi Yao, Hongyi
    Peng, Zeyu Zhang, Lin Zhu, Chen Cheng, Hongzhu Shi, Yaliang Li, Bolin Ding, and
    Jingren Zhou. 2024. [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://doi.org/10.48550/arXiv.2402.14034).
    *Preprint*, arXiv:2402.14034.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人（2024）Dawei Gao, Zitao Li, Xuchen Pan, Weirui Kuang, Zhijian Ma, Bingchen
    Qian, Fei Wei, Wenhao Zhang, Yuexiang Xie, Daoyuan Chen, Liuyi Yao, Hongyi Peng,
    Zeyu Zhang, Lin Zhu, Chen Cheng, Hongzhu Shi, Yaliang Li, Bolin Ding 和 Jingren
    Zhou. 2024. [AgentScope：一个灵活而强大的多智能体平台](https://doi.org/10.48550/arXiv.2402.14034)。*预印本*，arXiv:2402.14034。
- en: 'Gong et al. (2024) Ran Gong, Qiuyuan Huang, Xiaojian Ma, Yusuke Noda, Zane
    Durante, Zilong Zheng, Demetri Terzopoulos, Li Fei-Fei, Jianfeng Gao, and Hoi
    Vo. 2024. [MindAgent: Emergent Gaming Interaction](https://doi.org/10.18653/v1/2024.findings-naacl.200).
    In *Findings of the Association for Computational Linguistics: NAACL 2024*, pages
    3154–3183, Mexico City, Mexico. Association for Computational Linguistics.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong 等人（2024）Ran Gong, Qiuyuan Huang, Xiaojian Ma, Yusuke Noda, Zane Durante,
    Zilong Zheng, Demetri Terzopoulos, Li Fei-Fei, Jianfeng Gao 和 Hoi Vo. 2024. [MindAgent：新兴的游戏互动](https://doi.org/10.18653/v1/2024.findings-naacl.200)。在
    *计算语言学协会的发现：NAACL 2024*，第3154-3183页，墨西哥城，墨西哥。计算语言学协会。
- en: Graepel et al. (2007) Thore Graepel, Tom Minka, and R TrueSkill Herbrich. 2007.
    A bayesian skill rating system. *Advances in Neural Information Processing Systems*,
    19(569-576):7.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Graepel 等人（2007）Thore Graepel, Tom Minka 和 R TrueSkill Herbrich. 2007. 一种贝叶斯技能评分系统。*神经信息处理系统进展*，19（569-576）：7。
- en: 'Gronauer and Diepold (2022) Sven Gronauer and Klaus Diepold. 2022. [Multi-agent
    deep reinforcement learning: A survey](https://doi.org/10.1007/s10462-021-09996-w).
    *Artificial Intelligence Review*, 55(2):895–943.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gronauer 和 Diepold（2022）Sven Gronauer 和 Klaus Diepold. 2022. [多智能体深度强化学习：一项调查](https://doi.org/10.1007/s10462-021-09996-w)。*人工智能评论*，55（2）：895–943。
- en: 'Guo et al. (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao
    Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. [Large Language
    Model Based Multi-agents: A Survey of Progress and Challenges](https://doi.org/10.24963/ijcai.2024/890).
    In *Thirty-Third International Joint Conference on Artificial Intelligence*, volume 9,
    pages 8048–8057.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人（2024）Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei,
    Nitesh V. Chawla, Olaf Wiest 和 Xiangliang Zhang. 2024. [基于大语言模型的多智能体：进展与挑战的调查](https://doi.org/10.24963/ijcai.2024/890)。在
    *第三十三届国际人工智能联合会议*，第9卷，第8048-8057页。
- en: 'Han et al. (2024) Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo
    Xu, and Chaoyang He. 2024. [LLM Multi-Agent Systems: Challenges and Open Problems](https://doi.org/10.48550/arXiv.2402.03578).
    *Preprint*, arXiv:2402.03578.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等人（2024）Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu
    和 Chaoyang He. 2024. [LLM 多智能体系统：挑战与开放问题](https://doi.org/10.48550/arXiv.2402.03578)。*预印本*，arXiv:2402.03578。
- en: Hausknecht and Stone (2015) Matthew Hausknecht and Peter Stone. 2015. Deep recurrent
    q-learning for partially observable mdps. *Computer Science*.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hausknecht 和 Stone（2015）Matthew Hausknecht 和 Peter Stone. 2015. 深度递归 Q-learning
    用于部分可观察的 MDPs。*计算机科学*。
- en: 'Hong et al. (2023) Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng,
    Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan
    Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber.
    2023. [MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework](https://doi.org/10.48550/arXiv.2308.00352).
    *Preprint*, arXiv:2308.00352.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong 等人（2023）Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng
    Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang
    Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu 和 Jürgen Schmidhuber. 2023. [MetaGPT：多智能体协作框架的元编程](https://doi.org/10.48550/arXiv.2308.00352)。*预印本*，arXiv:2308.00352。
- en: 'Huang et al. (2024a) Qian Huang, Jian Vora, Percy Liang, and Jure Leskovec.
    2024a. [MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation](https://doi.org/10.48550/arXiv.2310.03302).
    *Preprint*, arXiv:2310.03302.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2024a）Qian Huang, Jian Vora, Percy Liang 和 Jure Leskovec. 2024a. [MLAgentBench：在机器学习实验中评估语言智能体](https://doi.org/10.48550/arXiv.2310.03302)。*预印本*，arXiv:2310.03302。
- en: 'Huang et al. (2024b) Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang
    Qin, Min Tang, Xiaoxi Wang, Song-Chun Zhu, Mingjie Bi, Siyuan Qi, and Xue Feng.
    2024b. [AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent
    Decision-Making](https://doi.org/10.48550/arXiv.2411.03865). *Preprint*, arXiv:2411.03865.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2024b）Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang Qin, Min
    Tang, Xiaoxi Wang, Song-Chun Zhu, Mingjie Bi, Siyuan Qi 和 Xue Feng. 2024b. [AdaSociety：一种具有社会结构的适应性环境用于多智能体决策](https://doi.org/10.48550/arXiv.2411.03865)。*预印本*，arXiv:2411.03865。
- en: 'Islam et al. (2024) Md. Ashraful Islam, Mohammed Eunus Ali, and Md Rizwan Parvez.
    2024. [MapCoder: Multi-Agent Code Generation for Competitive Problem Solving](https://doi.org/10.18653/v1/2024.acl-long.269).
    In *Proceedings of the 62nd Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 4912–4944, Bangkok, Thailand. Association
    for Computational Linguistics.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Islam 等人 (2024) Md. Ashraful Islam, Mohammed Eunus Ali 和 Md Rizwan Parvez.
    2024. [MapCoder: 用于竞争性问题求解的多代理代码生成](https://doi.org/10.18653/v1/2024.acl-long.269)。发表于
    *计算语言学协会第62届年会论文集（第1卷：长篇论文）*，页面 4912–4944，泰国曼谷。计算语言学协会。'
- en: 'Lan et al. (2024) Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye,
    Peilin Zhao, Ee-Peng Lim, Hui Xiong, and Hao Wang. 2024. [LLM-Based Agent Society
    Investigation: Collaboration and Confrontation in Avalon Gameplay](https://doi.org/10.48550/arXiv.2310.14985).
    *Preprint*, arXiv:2310.14985.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lan 等人 (2024) Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye, Peilin
    Zhao, Ee-Peng Lim, Hui Xiong 和 Hao Wang. 2024. [基于LLM的代理社会调查：在《阿瓦隆》游戏中的协作与对抗](https://doi.org/10.48550/arXiv.2310.14985)。*预印本*，arXiv:2310.14985。
- en: 'Lei et al. (2024) Bin Lei, Yi Zhang, Shan Zuo, Ali Payani, and Caiwen Ding.
    2024. [MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex
    Mathematical Problems](https://doi.org/10.48550/arXiv.2404.04735). *Preprint*,
    arXiv:2404.04735.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lei 等人 (2024) Bin Lei, Yi Zhang, Shan Zuo, Ali Payani 和 Caiwen Ding. 2024.
    [MACM: 在解决复杂数学问题中利用多代理系统进行条件挖掘](https://doi.org/10.48550/arXiv.2404.04735)。*预印本*，arXiv:2404.04735。'
- en: 'Li et al. (2024a) Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai,
    Xinhui Kang, Weizhi Ma, and Yang Liu. 2024a. [Agent Hospital: A Simulacrum of
    Hospital with Evolvable Medical Agents](https://doi.org/10.48550/arXiv.2405.02957).
    *Preprint*, arXiv:2405.02957.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 (2024a) Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui
    Kang, Weizhi Ma 和 Yang Liu. 2024a. [Agent Hospital: 一个具有可进化医疗代理的医院模拟](https://doi.org/10.48550/arXiv.2405.02957)。*预印本*，arXiv:2405.02957。'
- en: 'Li et al. (2024b) Nian Li, Chen Gao, Mingyu Li, Yong Li, and Qingmin Liao.
    2024b. [EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic
    Activities](https://doi.org/10.18653/v1/2024.acl-long.829). In *Proceedings of
    the 62nd Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 15523–15536, Bangkok, Thailand. Association for Computational
    Linguistics.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 (2024b) Nian Li, Chen Gao, Mingyu Li, Yong Li 和 Qingmin Liao. 2024b.
    [EconAgent: 利用大语言模型增强的代理进行宏观经济活动模拟](https://doi.org/10.18653/v1/2024.acl-long.829)。发表于
    *计算语言学协会第62届年会论文集（第1卷：长篇论文）*，页面 15523–15536，泰国曼谷。计算语言学协会。'
- en: 'Li et al. (2024c) Renhao Li, Minghuan Tan, Derek F. Wong, and Min Yang. 2024c.
    [CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent
    Cooperation](https://doi.org/10.48550/arXiv.2406.07054). *Preprint*, arXiv:2406.07054.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 (2024c) Renhao Li, Minghuan Tan, Derek F. Wong 和 Min Yang. 2024c. [CoEvol:
    通过多代理合作构建更好的指令微调响应](https://doi.org/10.48550/arXiv.2406.07054)。*预印本*，arXiv:2406.07054。'
- en: 'Li et al. (2024d) Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, and Yi Yang. 2024d.
    [A survey on LLM-based multi-agent systems: Workflow, infrastructure, and challenges](https://doi.org/10.1007/s44336-024-00009-2).
    *Vicinagearth*, 1(1):9.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2024d) Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu 和 Yi Yang. 2024d. [基于LLM的多代理系统调查：工作流、基础设施和挑战](https://doi.org/10.1007/s44336-024-00009-2)。*Vicinagearth*，1(1):9。
- en: 'Li et al. (2023) Yuan Li, Yixuan Zhang, and Lichao Sun. 2023. [MetaAgents:
    Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination
    via Collaborative Generative Agents](https://doi.org/10.48550/arXiv.2310.06500).
    *Preprint*, arXiv:2310.06500.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 (2023) Yuan Li, Yixuan Zhang 和 Lichao Sun. 2023. [MetaAgents: 通过协作生成代理模拟基于LLM的任务导向协调中的人类行为交互](https://doi.org/10.48550/arXiv.2310.06500)。*预印本*，arXiv:2310.06500。'
- en: Liang et al. (2024) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Shuming Shi, and Zhaopeng Tu. 2024. [Encouraging Divergent
    Thinking in Large Language Models through Multi-Agent Debate](https://doi.org/10.48550/arXiv.2305.19118).
    *Preprint*, arXiv:2305.19118.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等人 (2024) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui
    Wang, Yujiu Yang, Shuming Shi 和 Zhaopeng Tu. 2024. [通过多代理辩论鼓励大语言模型中的发散性思维](https://doi.org/10.48550/arXiv.2305.19118)。*预印本*，arXiv:2305.19118。
- en: 'Lin et al. (2023) Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue
    Ping, and Qin Chen. 2023. [AgentSims: An Open-Source Sandbox for Large Language
    Model Evaluation](https://doi.org/10.48550/arXiv.2308.04026). *Preprint*, arXiv:2308.04026.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin 等人 (2023) Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping
    和 Qin Chen. 2023. [AgentSims: 一个用于大语言模型评估的开源沙盒](https://doi.org/10.48550/arXiv.2308.04026)。*预印本*，arXiv:2308.04026。'
- en: 'Lin et al. (2024) Leilei Lin, Yumeng Jin, Yingming Zhou, Wenlong Chen, and
    Chen Qian. 2024. [MAO: A Framework for Process Model Generation with Multi-Agent
    Orchestration](https://doi.org/10.48550/arXiv.2408.01916). *Preprint*, arXiv:2408.01916.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin 等人 (2024) Leilei Lin, Yumeng Jin, Yingming Zhou, Wenlong Chen, 和 Chen Qian.
    2024. [MAO: 一个用于多代理编排的过程模型生成框架](https://doi.org/10.48550/arXiv.2408.01916). *预印本*,
    arXiv:2408.01916.'
- en: Liu et al. (2023a) Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Diyi Yang,
    and Soroush Vosoughi. 2023a. Training Socially Aligned Language Models on Simulated
    Social Interactions. In *The Twelfth International Conference on Learning Representations*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2023a) Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Diyi Yang, 和 Soroush
    Vosoughi. 2023a. 在模拟社会互动中训练社会对齐语言模型. 收录于 *第十二届国际学习表征会议*.
- en: Liu et al. (2024a) Wei Liu, Chenxi Wang, Yifei Wang, Zihao Xie, Rennai Qiu,
    Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, and Chen Qian. 2024a. [Autonomous
    Agents for Collaborative Task under Information Asymmetry](https://doi.org/10.48550/arXiv.2406.14928).
    *Preprint*, arXiv:2406.14928.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2024a) Wei Liu, Chenxi Wang, Yifei Wang, Zihao Xie, Rennai Qiu, Yufan
    Dang, Zhuoyun Du, Weize Chen, Cheng Yang, 和 Chen Qian. 2024a. [在信息不对称下，协作任务的自主代理](https://doi.org/10.48550/arXiv.2406.14928).
    *预印本*, arXiv:2406.14928.
- en: 'Liu et al. (2023b) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023b. [AgentBench: Evaluating LLMs
    as Agents](https://doi.org/10.48550/arXiv.2308.03688). *Preprint*, arXiv:2308.03688.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2023b) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, 和 Jie Tang. 2023b. [AgentBench: 评估LLM作为代理的表现](https://doi.org/10.48550/arXiv.2308.03688).
    *预印本*, arXiv:2308.03688.'
- en: 'Liu et al. (2024b) Yuhan Liu, Esha Choukse, Shan Lu, Junchen Jiang, and Madan
    Musuvathi. 2024b. [DroidSpeak: Enhancing Cross-LLM Communication](https://doi.org/10.48550/arXiv.2411.02820).
    *Preprint*, arXiv:2411.02820.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2024b) Yuhan Liu, Esha Choukse, Shan Lu, Junchen Jiang, 和 Madan Musuvathi.
    2024b. [DroidSpeak: 增强跨LLM通信](https://doi.org/10.48550/arXiv.2411.02820). *预印本*,
    arXiv:2411.02820.'
- en: 'Liu et al. (2023c) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran
    Xu, Phil Mui, Huan Wang, Caiming Xiong, and Silvio Savarese. 2023c. [BOLAA: Benchmarking
    and Orchestrating LLM-augmented Autonomous Agents](https://doi.org/10.48550/arXiv.2308.05960).
    *Preprint*, arXiv:2308.05960.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2023c) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran
    Xu, Phil Mui, Huan Wang, Caiming Xiong, 和 Silvio Savarese. 2023c. [BOLAA: 基准测试与编排增强LLM的自主代理](https://doi.org/10.48550/arXiv.2308.05960).
    *预印本*, arXiv:2308.05960.'
- en: 'Mou et al. (2024) Xinyi Mou, Zhongyu Wei, and Xuanjing Huang. 2024. [Unveiling
    the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement
    Simulation](https://doi.org/10.18653/v1/2024.findings-acl.285). In *Findings of
    the Association for Computational Linguistics ACL 2024*, pages 4789–4809, Bangkok,
    Thailand and virtual meeting. Association for Computational Linguistics.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mou 等人 (2024) Xinyi Mou, Zhongyu Wei, 和 Xuanjing Huang. 2024. [揭示真相并促进变革：面向基于代理的大规模社会运动仿真](https://doi.org/10.18653/v1/2024.findings-acl.285).
    收录于 *2024年计算语言学协会（ACL 2024）会议成果*，页码 4789–4809，泰国曼谷及虚拟会议。计算语言学协会。
- en: OpenAI et al. (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
    Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, et al. 2024. [GPT-4 Technical Report](https://doi.org/10.48550/arXiv.2303.08774).
    *Preprint*, arXiv:2303.08774.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 等人 (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman
    等. 2024. [GPT-4 技术报告](https://doi.org/10.48550/arXiv.2303.08774). *预印本*, arXiv:2303.08774.
- en: Oroojlooy and Hajinezhad (2023) Afshin Oroojlooy and Davood Hajinezhad. 2023.
    A review of cooperative multi-agent deep reinforcement learning. *Applied Intelligence*,
    53(11):13677–13722.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oroojlooy 和 Hajinezhad (2023) Afshin Oroojlooy 和 Davood Hajinezhad. 2023. 合作多代理深度强化学习的综述.
    *应用智能*, 53(11):13677–13722.
- en: Pan et al. (2024) Xuchen Pan, Dawei Gao, Yuexiang Xie, Yushuo Chen, Zhewei Wei,
    Yaliang Li, Bolin Ding, Ji-Rong Wen, and Jingren Zhou. 2024. [Very Large-Scale
    Multi-Agent Simulation in AgentScope](https://doi.org/10.48550/arXiv.2407.17789).
    *Preprint*, arXiv:2407.17789.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 等人 (2024) Xuchen Pan, Dawei Gao, Yuexiang Xie, Yushuo Chen, Zhewei Wei,
    Yaliang Li, Bolin Ding, Ji-Rong Wen, 和 Jingren Zhou. 2024. [AgentScope中的超大规模多代理仿真](https://doi.org/10.48550/arXiv.2407.17789).
    *预印本*, arXiv:2407.17789.
- en: 'Park et al. (2023) Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. [Generative Agents: Interactive
    Simulacra of Human Behavior](https://doi.org/10.48550/arXiv.2304.03442). *Preprint*,
    arXiv:2304.03442.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2023）Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, 和 Michael S. Bernstein. 2023. [生成代理：人类行为的互动模拟](https://doi.org/10.48550/arXiv.2304.03442).
    *预印本*, arXiv:2304.03442.
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2022. [Social Simulacra: Creating
    Populated Prototypes for Social Computing Systems](https://doi.org/10.48550/arXiv.2208.04024).
    *Preprint*, arXiv:2208.04024.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2022）Joon Sung Park, Lindsay Popowski, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, 和 Michael S. Bernstein. 2022. [社会模拟：为社会计算系统创建人口化原型](https://doi.org/10.48550/arXiv.2208.04024).
    *预印本*, arXiv:2208.04024.
- en: 'Piatti et al. (2024) Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard
    Schölkopf, Mrinmaya Sachan, and Rada Mihalcea. 2024. [Cooperate or Collapse: Emergence
    of Sustainable Cooperation in a Society of LLM Agents](https://doi.org/10.48550/arXiv.2404.16698).
    *Preprint*, arXiv:2404.16698.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Piatti 等人（2024）Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard Schölkopf,
    Mrinmaya Sachan, 和 Rada Mihalcea. 2024. [合作还是崩溃：LLM 代理社会中可持续合作的出现](https://doi.org/10.48550/arXiv.2404.16698).
    *预印本*, arXiv:2404.16698.
- en: 'Qian et al. (2024a) Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Zihao Xie, YiFei
    Wang, Weize Chen, Cheng Yang, Xin Cong, Xiaoyin Che, Zhiyuan Liu, and Maosong
    Sun. 2024a. [Experiential Co-Learning of Software-Developing Agents](https://doi.org/10.18653/v1/2024.acl-long.305).
    In *Proceedings of the 62nd Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 5628–5640, Bangkok, Thailand. Association
    for Computational Linguistics.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2024a）Chen Qian, Yufan Dang, Jiahao Li, Wei Liu, Zihao Xie, YiFei Wang,
    Weize Chen, Cheng Yang, Xin Cong, Xiaoyin Che, Zhiyuan Liu, 和 Maosong Sun. 2024a.
    [软件开发代理的经验共学习](https://doi.org/10.18653/v1/2024.acl-long.305). 载于 *第62届计算语言学协会年会论文集（卷1：长篇论文）*,
    第5628–5640页, 泰国曼谷. 计算语言学协会.
- en: 'Qian et al. (2024b) Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang,
    Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li,
    Zhiyuan Liu, and Maosong Sun. 2024b. [ChatDev: Communicative Agents for Software
    Development](https://doi.org/10.18653/v1/2024.acl-long.810). In *Proceedings of
    the 62nd Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 15174–15186, Bangkok, Thailand. Association for Computational
    Linguistics.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2024b）Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao
    Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan
    Liu, 和 Maosong Sun. 2024b. [ChatDev：用于软件开发的交流型代理](https://doi.org/10.18653/v1/2024.acl-long.810).
    载于 *第62届计算语言学协会年会论文集（卷1：长篇论文）*, 第15174–15186页, 泰国曼谷. 计算语言学协会.
- en: Qian et al. (2024c) Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun
    Du, Weize Chen, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2024c. [Scaling Large-Language-Model-based
    Multi-Agent Collaboration](https://doi.org/10.48550/arXiv.2406.07155). *Preprint*,
    arXiv:2406.07155.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2024c）Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun
    Du, Weize Chen, Cheng Yang, Zhiyuan Liu, 和 Maosong Sun. 2024c. [大规模语言模型基础的多代理协作扩展](https://doi.org/10.48550/arXiv.2406.07155).
    *预印本*, arXiv:2406.07155.
- en: (59) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
    Sutskever. Language Models are Unsupervised Multitask Learners.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (59) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, 和 Ilya
    Sutskever. 语言模型是无监督的多任务学习者.
- en: 'Shen et al. (2024) Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun
    Quan, Hehong Chen, Ji Zhang, and Fei Huang. 2024. [Small LLMs Are Weak Tool Learners:
    A Multi-LLM Agent](https://doi.org/10.48550/arXiv.2401.07324). *Preprint*, arXiv:2401.07324.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人（2024）Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan,
    Hehong Chen, Ji Zhang, 和 Fei Huang. 2024. [小型 LLM 是弱工具学习者：一种多 LLM 代理](https://doi.org/10.48550/arXiv.2401.07324).
    *预印本*, arXiv:2401.07324.
- en: 'Shi et al. (2024) Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Leyla Isik,
    Yen-Ling Kuo, and Tianmin Shu. 2024. [MuMA-ToM: Multi-modal Multi-Agent Theory
    of Mind](https://doi.org/10.48550/arXiv.2408.12574). *Preprint*, arXiv:2408.12574.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等人（2024）Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Leyla Isik, Yen-Ling
    Kuo, 和 Tianmin Shu. 2024. [MuMA-ToM：多模态多代理心智理论](https://doi.org/10.48550/arXiv.2408.12574).
    *预印本*, arXiv:2408.12574.
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik
    Narasimhan, and Shunyu Yao. 2023. Reflexion: Language agents with verbal reinforcement
    learning. *Advances in Neural Information Processing Systems*, 36:8634–8652.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn 等人（2023）Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan,
    和 Shunyu Yao. 2023. Reflexion: 使用语言代理的言语强化学习. *神经信息处理系统进展*, 36:8634–8652.'
- en: 'Tang et al. (2024) Xunzhu Tang, Kisub Kim, Yewei Song, Cedric Lothritz, Bei
    Li, Saad Ezzini, Haoye Tian, Jacques Klein, and Tegawende F. Bissyande. 2024.
    [CodeAgent: Autonomous Communicative Agents for Code Review](https://doi.org/10.48550/arXiv.2402.02172).
    *Preprint*, arXiv:2402.02172.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tang et al. (2024) 唐训竹 Xunzhu Tang、金基洙 Kisub Kim、宋业伟 Yewei Song、塞德里克·洛斯里茨 Cedric
    Lothritz、李蓓 Bei Li、萨阿德·埃齐尼 Saad Ezzini、田浩烨 Haoye Tian、雅克·克莱因 Jacques Klein 和 泰戈温德·F·比桑德
    Tegawende F. Bissyande. 2024. [CodeAgent: 用于代码审查的自主沟通智能体](https://doi.org/10.48550/arXiv.2402.02172).
    *预印本*, arXiv:2402.02172.'
- en: Wang et al. (2024a) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, and Jirong Wen. 2024a. [A survey on large language model based autonomous
    agents](https://doi.org/10.1007/s11704-024-40231-1). *Frontiers of Computer Science*,
    18(6):186345.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2024a) 王磊 Lei Wang、马晨 Chen Ma、冯学阳 Xueyang Feng、张泽宇 Zeyu Zhang、杨浩
    Hao Yang、张靖森 Jingsen Zhang、陈智远 Zhiyuan Chen、唐佳凯 Jiakai Tang、陈旭 Xu Chen、林彦凯 Yankai
    Lin、赵欣威 Wayne Xin Zhao、魏哲伟 Zhewei Wei 和 文继荣 Jirong Wen. 2024a. [基于大型语言模型的自主智能体调查](https://doi.org/10.1007/s11704-024-40231-1).
    *计算机科学前沿*, 18(6):186345.
- en: Wang et al. (2024b) Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai
    Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Jun Xu, Zhicheng
    Dou, Jun Wang, and Ji-Rong Wen. 2024b. [User Behavior Simulation with Large Language
    Model based Agents](https://doi.org/10.48550/arXiv.2306.02552). *Preprint*, arXiv:2306.02552.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2024b) 王磊 Lei Wang、张靖森 Jingsen Zhang、杨浩 Hao Yang、陈智远 Zhiyuan Chen、唐佳凯
    Jiakai Tang、张泽宇 Zeyu Zhang、陈旭 Xu Chen、林彦凯 Yankai Lin、宋瑞华 Ruihua Song、赵欣威 Wayne
    Xin Zhao、徐俊 Jun Xu、窦志诚 Zhicheng Dou、王俊 Jun Wang 和 文继荣 Ji-Rong Wen. 2024b. [基于大型语言模型的用户行为模拟](https://doi.org/10.48550/arXiv.2306.02552).
    *预印本*, arXiv:2306.02552.
- en: 'Wang et al. (2024c) Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, and Yangqiu
    Song. 2024c. [Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions
    the Key?](https://doi.org/10.18653/v1/2024.acl-long.331) In *Proceedings of the
    62nd Annual Meeting of the Association for Computational Linguistics (Volume 1:
    Long Papers)*, pages 6106–6131, Bangkok, Thailand. Association for Computational
    Linguistics.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2024c) 王勤能 Qineng Wang、王子豪 Zihao Wang、苏颖 Ying Su、童航航 Hanghang Tong
    和 宋杨秋 Yangqiu Song. 2024c. [重新思考大型语言模型推理的界限：多智能体讨论是否是关键？](https://doi.org/10.18653/v1/2024.acl-long.331).
    载于 *第62届计算语言学协会年会论文集（第1卷：长篇论文）*，第6106-6131页，曼谷，泰国。计算语言学协会。
- en: 'Wang et al. (2024d) Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu
    Wei, and Heng Ji. 2024d. [Unleashing the Emergent Cognitive Synergy in Large Language
    Models: A Task-Solving Agent through Multi-Persona Self-Collaboration](https://doi.org/10.18653/v1/2024.naacl-long.15).
    In *Proceedings of the 2024 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)*,
    pages 257–279, Mexico City, Mexico. Association for Computational Linguistics.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2024d) 王振海龙 Zhenhailong Wang、毛绍光 Shaoguang Mao、吴文山 Wenshan Wu、葛涛
    Tao Ge、魏福如 Furu Wei 和 姬恒 Heng Ji. 2024d. [释放大型语言模型中的新兴认知协同：通过多角色自我协作的任务求解智能体](https://doi.org/10.18653/v1/2024.naacl-long.15).
    载于 *2024年北美计算语言学学会年会：人类语言技术会议论文集（第1卷：长篇论文）*，第257-279页，墨西哥城，墨西哥。计算语言学协会。
- en: 'Xu et al. (2023a) Fengli Xu, Jun Zhang, Chen Gao, Jie Feng, and Yong Li. 2023a.
    [Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied
    City Environment](https://doi.org/10.48550/arXiv.2312.11813). *Preprint*, arXiv:2312.11813.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023a) 徐风利 Fengli Xu、张俊 Jun Zhang、高晨 Chen Gao、冯杰 Jie Feng 和 李勇 Yong
    Li. 2023a. [城市生成智能（UGI）：面向具身城市环境中的智能体的基础平台](https://doi.org/10.48550/arXiv.2312.11813).
    *预印本*, arXiv:2312.11813.
- en: 'Xu et al. (2023b) Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt
    Keutzer, See Kiong Ng, and Jiashi Feng. 2023b. [MAgIC: Investigation of Large
    Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and
    Collaboration](https://doi.org/10.48550/arXiv.2311.08562). *Preprint*, arXiv:2311.08562.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023b) 徐琳 Lin Xu、胡智远 Zhiyuan Hu、周大全 Daquan Zhou、任洪宇 Hongyu Ren、董臻
    Zhen Dong、库尔特·凯特泽 Kurt Keutzer、黄锦堂 See Kiong Ng 和 冯家世 Jiashi Feng. 2023b. [MAgIC：基于大型语言模型的多智能体在认知、适应性、理性和协作方面的研究](https://doi.org/10.48550/arXiv.2311.08562).
    *预印本*, arXiv:2311.08562.
- en: 'Xu et al. (2024) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2024. [Exploring Large Language Models for Communication
    Games: An Empirical Study on Werewolf](https://doi.org/10.48550/arXiv.2309.04658).
    *Preprint*, arXiv:2309.04658.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2024) 许壮 Xu、王硕 Shuo Wang、李鹏 Peng Li、罗富文 Fuwen Luo、王晓龙 Xiaolong Wang、刘伟东
    Weidong Liu 和 刘阳 Yang Liu. 2024. [探索大型语言模型在沟通游戏中的应用：狼人游戏的实证研究](https://doi.org/10.48550/arXiv.2309.04658).
    *预印本*, arXiv:2309.04658.
- en: Xu et al. (2023c) Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. 2023c. Language
    Agents with Reinforcement Learning for Strategic Play in the Werewolf Game.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023c) 许泽莱 Zelai Xu、余超 Chao Yu、方菲 Fei Fang、王宇 Yu Wang 和 吴怡 Yi Wu.
    2023c. 使用强化学习的语言智能体在狼人游戏中的战略博弈。
- en: 'Yao et al. (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2023. [ReAct: Synergizing Reasoning and Acting
    in Language Models](https://doi.org/10.48550/arXiv.2210.03629). *Preprint*, arXiv:2210.03629.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姚等人（2023）姚顺宇、赵杰弗里、余典、杜楠、Izhak Shafran、Karthik Narasimhan、曹元。2023. [ReAct：在语言模型中协同推理与行动](https://doi.org/10.48550/arXiv.2210.03629)。*Preprint*,
    arXiv:2210.03629。
- en: 'Yin et al. (2024) Xiangyu Yin, Chuqiao Shi, Yimo Han, and Yi Jiang. 2024. [PEAR:
    A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple
    Large Language Model Agents](https://doi.org/10.48550/arXiv.2410.09034). *Preprint*,
    arXiv:2410.09034.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尹等人（2024）尹翔宇、史楚乔、韩依墨、姜毅。2024. [PEAR：由多个大语言模型智能体驱动的鲁棒且灵活的相位恢复自动化框架](https://doi.org/10.48550/arXiv.2410.09034)。*Preprint*,
    arXiv:2410.09034。
- en: 'Yu et al. (2024) Xiaoyan Yu, Tongxu Luo, Yifan Wei, Fangyu Lei, Yiming Huang,
    Hao Peng, and Liehuang Zhu. 2024. [Neeko: Leveraging Dynamic LoRA for Efficient
    Multi-Character Role-Playing Agent](https://doi.org/10.48550/arXiv.2402.13717).
    *Preprint*, arXiv:2402.13717.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 于等人（2024）于晓燕、罗同旭、魏一凡、雷方宇、黄一铭、彭浩、朱立煌。2024. [Neeko：利用动态LoRA进行高效的多角色扮演智能体](https://doi.org/10.48550/arXiv.2402.13717)。*Preprint*,
    arXiv:2402.13717。
- en: Yuan et al. (2023) Haoqi Yuan, Chi Zhang, Hongcheng Wang, Feiyang Xie, Penglin
    Cai, Hao Dong, and Zongqing Lu. 2023. [Skill Reinforcement Learning and Planning
    for Open-World Long-Horizon Tasks](https://doi.org/10.48550/arXiv.2303.16563).
    *Preprint*, arXiv:2303.16563.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 袁等人（2023）袁昊琪、张驰、王洪诚、谢飞扬、蔡鹏霖、董浩、陆宗庆。2023. [开放世界长时间跨度任务的技能强化学习与规划](https://doi.org/10.48550/arXiv.2303.16563)。*Preprint*,
    arXiv:2303.16563。
- en: Yue et al. (2024) Shengbin Yue, Siyuan Wang, Wei Chen, Xuanjing Huang, and Zhongyu
    Wei. 2024. [Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive
    Tasks](https://doi.org/10.48550/arXiv.2407.09893). *Preprint*, arXiv:2407.09893.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岳等人（2024）岳胜彬、王思源、陈伟、黄轩靖、魏忠宇。2024. [基于轨迹学习的协同多智能体框架用于知识密集型任务](https://doi.org/10.48550/arXiv.2407.09893)。*Preprint*,
    arXiv:2407.09893。
- en: 'Zhang et al. (2023a) Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe
    Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang,
    Junge Zhang, Feng Yin, Yitao Liang, and Yaodong Yang. 2023a. ProAgent: Building
    Proactive Cooperative AI with Large Language Models. *CoRR*.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2023a）张灿耀、杨凯杰、胡思怡、王子豪、李广赫、孙逸航、张成、张兆伟、刘安吉、朱松春、常晓俊、张君歌、尹锋、梁义涛、杨耀东。2023a. 《ProAgent：构建具有主动协作能力的人工智能系统》*CoRR*。
- en: 'Zhang et al. (2023b) Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen,
    Zebiao Huang, Bin Fu, and Gang Yu. 2023b. [AppAgent: Multimodal Agents as Smartphone
    Users](https://doi.org/10.48550/arXiv.2312.13771). *Preprint*, arXiv:2312.13771.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2023b）张驰、杨兆、刘佳轩、韩宇成、陈欣、黄泽彪、傅斌、俞刚。2023b. [AppAgent：作为智能手机用户的多模态智能体](https://doi.org/10.48550/arXiv.2312.13771)。*Preprint*,
    arXiv:2312.13771。
- en: 'Zhang et al. (2024a) Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan
    Hooi, and Shumin Deng. 2024a. [Exploring Collaboration Mechanisms for LLM Agents:
    A Social Psychology View](https://doi.org/10.18653/v1/2024.acl-long.782). In *Proceedings
    of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 14544–14607, Bangkok, Thailand. Association for Computational
    Linguistics.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2024a）张锦天、徐欣、张宁宇、刘瑞博、Bryan Hooi、邓书敏。2024a. [探索LLM智能体协作机制：社会心理学视角](https://doi.org/10.18653/v1/2024.acl-long.782)。在《第62届计算语言学协会年会（第一卷：长篇论文）》中，页面14544-14607，泰国曼谷。计算语言学协会。
- en: 'Zhang et al. (2024b) Zaibin Zhang, Yongting Zhang, Lijun Li, Jing Shao, Hongzhi
    Gao, Yu Qiao, Lijun Wang, Huchuan Lu, and Feng Zhao. 2024b. [PsySafe: A Comprehensive
    Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent
    System Safety](https://doi.org/10.18653/v1/2024.acl-long.812). In *Proceedings
    of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume
    1: Long Papers)*, pages 15202–15231, Bangkok, Thailand. Association for Computational
    Linguistics.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2024b）张在彬、张永廷、李立军、邵静、高洪志、乔瑜、王立军、陆虎川、赵峰。2024b. [PsySafe：一种综合框架用于多智能体系统安全的心理攻击、防御和评估](https://doi.org/10.18653/v1/2024.acl-long.812)。在《第62届计算语言学协会年会（第一卷：长篇论文）》中，页面15202-15231，泰国曼谷。计算语言学协会。
- en: 'Zhao et al. (2024a) Jun Zhao, Can Zu, Hao Xu, Yi Lu, Wei He, Yiwen Ding, Tao
    Gui, Qi Zhang, and Xuanjing Huang. 2024a. [LongAgent: Scaling Language Models
    to 128k Context through Multi-Agent Collaboration](https://doi.org/10.48550/arXiv.2402.11550).
    *Preprint*, arXiv:2402.11550.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 (2024a) Jun Zhao, Can Zu, Hao Xu, Yi Lu, Wei He, Yiwen Ding, Tao Gui,
    Qi Zhang, 和 Xuanjing Huang. 2024a. [LongAgent: 通过多代理协作将语言模型扩展至128k上下文](https://doi.org/10.48550/arXiv.2402.11550).
    *预印本*, arXiv:2402.11550.'
- en: 'Zhao et al. (2024b) Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie
    Zhu, Hao Chen, and Xing Xie. 2024b. [CompeteAI: Understanding the Competition
    Dynamics in Large Language Model-based Agents](https://doi.org/10.48550/arXiv.2310.17512).
    *Preprint*, arXiv:2310.17512.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 (2024b) Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie
    Zhu, Hao Chen, 和 Xing Xie. 2024b. [CompeteAI: 理解基于大语言模型的代理中的竞争动态](https://doi.org/10.48550/arXiv.2310.17512).
    *预印本*, arXiv:2310.17512.'
- en: Zhao et al. (2024c) Xiutian Zhao, Ke Wang, and Wei Peng. 2024c. [An Electoral
    Approach to Diversify LLM-based Multi-Agent Collective Decision-Making](https://doi.org/10.48550/arXiv.2410.15168).
    *Preprint*, arXiv:2410.15168.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人 (2024c) Xiutian Zhao, Ke Wang, 和 Wei Peng. 2024c. [一种选举方法来多样化基于LLM的多代理集体决策](https://doi.org/10.48550/arXiv.2410.15168).
    *预印本*, arXiv:2410.15168.
- en: 'Zou et al. (2023) Hang Zou, Qiyang Zhao, Lina Bariah, Mehdi Bennis, and Merouane
    Debbah. 2023. [Wireless Multi-Agent Generative AI: From Connected Intelligence
    to Collective Intelligence](https://doi.org/10.48550/arXiv.2307.02757). *Preprint*,
    arXiv:2307.02757.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zou 等人 (2023) Hang Zou, Qiyang Zhao, Lina Bariah, Mehdi Bennis, 和 Merouane
    Debbah. 2023. [无线多代理生成式AI: 从连接智能到集体智能](https://doi.org/10.48550/arXiv.2307.02757).
    *预印本*, arXiv:2307.02757.'
