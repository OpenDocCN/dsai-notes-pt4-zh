- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2025-01-11 12:03:06'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:03:06
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '\methodname: Tree-Search Enhanced LLM Agents for Automated Machine Learning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: \methodname：树搜索增强型LLM代理用于自动化机器学习
- en: 来源：[https://arxiv.org/html/2410.17238/](https://arxiv.org/html/2410.17238/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2410.17238/](https://arxiv.org/html/2410.17238/)
- en: 'Yizhou Chi^(1,2), Yizhang Lin¹¹¹footnotemark: 1, Sirui Hong¹, Duyi Pan³, Yaying
    Fei, Guanghao Mei⁴,'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 祁逸舟^(1,2)，林怡璋¹¹¹脚注标记：1，洪思锐¹，潘杜毅³，费亚莹，梅广浩⁴，
- en: 'Bangbang Liu¹, Tianqi Pang⁵, Jacky Kwok⁶, Ceyao Zhang⁷, Bang Liu⁸, Chenglin
    Wu¹²²footnotemark: 2'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 刘邦邦¹，庞天奇⁵，郭杰基⁶，张策耀⁷，刘邦⁸，吴承霖¹²²脚注标记：2
- en: ¹DeepWisdom, ²University of California, Berkeley,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹DeepWisdom，²加利福尼亚大学伯克利分校，
- en: ³The Hong Kong University of Science and Technology (Guangzhou),
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ³香港科技大学（广州），
- en: ⁴University of California, San Diego, ⁵South China Normal University,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴加利福尼亚大学圣地亚哥分校，⁵华南师范大学，
- en: ⁶Stanford University, ⁷The Chinese University of Hong Kong, Shenzhen,
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ⁶斯坦福大学，⁷香港中文大学（深圳），
- en: '⁸Université de Montréal & Mila These authors contributed equally to this work.Bang
    Liu (E-mail: bang.liu@umontreal.ca) and Chenglin Wu (E-mail: alexanderwu@deepwisdom.ai)
    are the corresponding authors.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ⁸蒙特利尔大学 & Mila 这些作者对本研究做出了同等贡献。刘邦（电子邮件：bang.liu@umontreal.ca）和吴承霖（电子邮件：alexanderwu@deepwisdom.ai）是通讯作者。
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Automated Machine Learning (AutoML) approaches encompass traditional methods
    that optimize fixed pipelines for model selection and ensembling, as well as newer
    LLM-based frameworks that autonomously build pipelines. While LLM-based agents
    have shown promise in automating machine learning tasks, they often generate low-diversity
    and suboptimal code, even after multiple iterations. To overcome these limitations,
    we introduce Tree-Search Enhanced LLM Agents (\methodname), an innovative agent-based
    system that leverages Monte Carlo Tree Search (MCTS) to optimize the AutoML process.
    By representing pipeline configurations as trees, our framework enables agents
    to conduct experiments intelligently and iteratively refine their strategies,
    facilitating a more effective exploration of the machine learning solution space.
    This novel approach allows \methodname to discover optimal pathways based on experimental
    feedback, improving the overall quality of the solutions. In an extensive evaluation
    across 20 machine learning datasets, we compare the performance of traditional
    and agent-based AutoML methods, demonstrating that \methodname achieves a win
    rate of 65% to 80% against each baseline across all datasets. These results underscore
    the significant potential of agent-based strategies in AutoML, offering a fresh
    perspective on tackling complex machine learning challenges¹¹1The code is available
    at [https://github.com/geekan/MetaGPT](https://github.com/geekan/MetaGPT).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习（AutoML）方法包括优化固定模型选择和集成管道的传统方法，以及基于最新大语言模型（LLM）的框架，这些框架能够自主构建管道。虽然基于LLM的代理在自动化机器学习任务中显示出了潜力，但它们往往生成低多样性和次优的代码，即使经过多次迭代也未能改善。为克服这些局限性，我们提出了树搜索增强型LLM代理（\methodname），这是一种创新的基于代理的系统，利用蒙特卡洛树搜索（MCTS）来优化AutoML过程。通过将管道配置表示为树形结构，我们的框架使代理能够智能地进行实验，并通过迭代不断优化策略，从而更有效地探索机器学习解决方案空间。这种新颖的方法使得\methodname能够根据实验反馈发现最优路径，从而提高解决方案的整体质量。在对20个机器学习数据集进行的广泛评估中，我们比较了传统方法和基于代理的AutoML方法的表现，结果表明\methodname在所有数据集上与每个基准方法相比，胜率达到65%到80%。这些结果突显了基于代理的策略在AutoML中的巨大潜力，为应对复杂的机器学习挑战提供了全新的视角¹¹1代码可通过[https://github.com/geekan/MetaGPT](https://github.com/geekan/MetaGPT)获取。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Automated Machine Learning (AutoML) is a rapidly evolving field that seeks to
    automate the process of designing reliable machine learning solutions with minimal
    human intervention. Traditional AutoML frameworks, such as Auto-WEKA (Thornton
    et al., [2013](https://arxiv.org/html/2410.17238v1#bib.bib34)), Auto-Sklearn (Feurer
    et al., [2015](https://arxiv.org/html/2410.17238v1#bib.bib10); [2020](https://arxiv.org/html/2410.17238v1#bib.bib11)),
    AutoGluon (Tang et al., [2024b](https://arxiv.org/html/2410.17238v1#bib.bib33)),
    and H2O AutoML (LeDell & Poirier, [2020](https://arxiv.org/html/2410.17238v1#bib.bib22)),
    rely on predefined search spaces and routines. These frameworks primarily focus
    on optimizing hyperparameters and model ensembling to find the best model configuration.
    However, this fixed and static approach often lacks the adaptability needed to
    handle diverse and dynamic data scenarios, resulting in suboptimal performance
    in more complex settings. Additionally, the traditional focus on model training
    leaves other crucial stages of the machine learning pipeline, such as data preprocessing
    and feature engineering, underexplored, thereby limiting the overall effectiveness
    of these systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习（AutoML）是一个快速发展的领域，旨在通过最小化人工干预，自动化设计可靠的机器学习解决方案的过程。传统的AutoML框架，如Auto-WEKA（Thornton等，[2013](https://arxiv.org/html/2410.17238v1#bib.bib34)）、Auto-Sklearn（Feurer等，[2015](https://arxiv.org/html/2410.17238v1#bib.bib10)；[2020](https://arxiv.org/html/2410.17238v1#bib.bib11)）、AutoGluon（Tang等，[2024b](https://arxiv.org/html/2410.17238v1#bib.bib33)）和H2O
    AutoML（LeDell & Poirier，[2020](https://arxiv.org/html/2410.17238v1#bib.bib22)）依赖于预定义的搜索空间和常规流程。这些框架主要侧重于优化超参数和模型集成，以找到最佳的模型配置。然而，这种固定且静态的方法通常缺乏应对多样化和动态数据场景所需的适应性，导致在更复杂的环境中表现不佳。此外，传统的关注点集中在模型训练上，其他机器学习流程中的关键阶段，如数据预处理和特征工程，未得到充分探索，从而限制了这些系统的整体效能。
- en: Recently, large language model (LLM)-based agents have emerged as promising
    tools for automating machine learning tasks by leveraging natural language processing
    capabilities to generate code. These systems typically begin with a natural language
    prompt describing the dataset and the problem, after which an LLM generates an
    end-to-end solution. Early efforts, such as Zhang et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib38)),
    experimented with prompting LLMs to generate machine learning solutions, while
    Hong et al. ([2024a](https://arxiv.org/html/2410.17238v1#bib.bib15)) introduced
    agents equipped with Hierarchical Graph Modeling and Programmable Node Generation
    to address complex and dynamic workflows. Despite these advances, LLM-based solutions
    often fall short in generating diverse and highly optimized workflows, as their
    search process remains limited to a single pass or trial. Without iterative refinement
    or the ability to explore alternative strategies, these solutions frequently converge
    on suboptimal results, even when multiple attempts are allowed.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，基于大型语言模型（LLM）的代理作为一种有前景的工具，开始通过利用自然语言处理能力生成代码来自动化机器学习任务。这些系统通常从描述数据集和问题的自然语言提示开始，之后LLM生成一个端到端的解决方案。早期的尝试，如张等人（[2024](https://arxiv.org/html/2410.17238v1#bib.bib38)）尝试通过提示LLM生成机器学习解决方案，而洪等人（[2024a](https://arxiv.org/html/2410.17238v1#bib.bib15)）则引入了配备层次图建模和可编程节点生成的代理来解决复杂和动态的工作流。尽管取得了这些进展，基于LLM的解决方案往往难以生成多样化和高度优化的工作流，因为它们的搜索过程仍然局限于单次尝试或试探。在没有迭代改进或探索替代策略的能力下，即使允许多次尝试，这些解决方案也常常会趋向于次优结果。
- en: A critical shortcoming of both traditional AutoML and LLM-based frameworks lies
    in their inability to mimic the nuanced problem-solving approach of human experts.
    When approaching a machine learning task, an expert does not simply execute a
    fixed pipeline or rely on a single attempt. Instead, they explore various potential
    configurations, systematically conduct experiments, analyze results, and iteratively
    refine their understanding of each component’s effectiveness. This iterative,
    feedback-driven process allows experts to explore diverse solutions and improve
    them incrementally until they arrive at the optimal configuration.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的AutoML和基于大型语言模型（LLM）的框架的一个重要缺点在于它们无法模仿人类专家的细致问题解决方法。在处理机器学习任务时，专家并非简单地执行固定的流程或依赖单次尝试。相反，他们会探索各种可能的配置，系统性地进行实验，分析结果，并迭代地完善对每个组件有效性的理解。这种迭代、反馈驱动的过程使专家能够探索多样的解决方案，并不断改进，直到找到最佳配置。
- en: '![Refer to caption](img/9c8ace26de97cf9a0024c368cda17ca4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/9c8ace26de97cf9a0024c368cda17ca4.png)'
- en: 'Figure 1: \methodname’s abstraction compared to other agent-based AutoML frameworks.
    There are two main types of agent-based approaches to AutoML problems. The first
    approach (Hong et al., [2024a](https://arxiv.org/html/2410.17238v1#bib.bib15))
    divides a machine learning task into multiple stages, proposing a plan for each
    stage, and generating and executing code step by step according to the plan, with
    no refinement after the solution is completed. The second (Schmidt et al., [2024](https://arxiv.org/html/2410.17238v1#bib.bib28))
    generates the entire solution in one step and iteratively refines it as a whole.
    \methodname integrates both approaches, enabling stage-wise planning while iteratively
    exploring better solutions at each stage level.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：\methodname 与其他基于代理的 AutoML 框架的抽象比较。基于代理的 AutoML 方法主要有两种类型。第一种方法（Hong 等，[2024a](https://arxiv.org/html/2410.17238v1#bib.bib15)）将机器学习任务分解为多个阶段，为每个阶段提出计划，并根据计划一步步生成和执行代码，完成解决方案后不再进行优化。第二种方法（Schmidt
    等，[2024](https://arxiv.org/html/2410.17238v1#bib.bib28)）一步生成整个解决方案，并作为一个整体进行迭代优化。
    \methodname 将这两种方法结合起来，既支持分阶段规划，又能在每个阶段层次上迭代探索更好的解决方案。
- en: 'Inspired by this human-centered approach, we propose Tree-Search Enhanced LLM
    Agents (\methodname) for automated machine learning, a novel framework that integrates
    the strengths of LLM agents with a structured search and refinement process modeled
    on how experts solve machine learning problems. As illustrated in Figure [1](https://arxiv.org/html/2410.17238v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ \methodname: Tree-Search Enhanced LLM Agents for
    Automated Machine Learning"), our framework combines the benefits of stage-wise
    planning, where each stage (e.g., Exploratory Data Analysis, Data Preprocessing,
    Feature Engineering, and Model Training) is handled sequentially, with an iterative
    refinement mechanism.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '受这种以人为本的方法启发，我们提出了树搜索增强型 LLM 代理（\methodname）用于自动化机器学习，这是一种新颖的框架，融合了 LLM 代理的优势与基于专家解决机器学习问题的结构化搜索和优化过程。如图
    [1](https://arxiv.org/html/2410.17238v1#S1.F1 "Figure 1 ‣ 1 Introduction ‣ \methodname:
    Tree-Search Enhanced LLM Agents for Automated Machine Learning") 所示，我们的框架结合了分阶段规划的优势，每个阶段（如探索性数据分析、数据预处理、特征工程和模型训练）按顺序处理，同时具有迭代优化机制。'
- en: In \methodname, the search space of a machine learning problem is proposed and
    conceptualized as a tree, where each branch represents a potential solution path.
    To navigate this search space, we employ Monte Carlo Tree Search (MCTS) (Coulom,
    [2007](https://arxiv.org/html/2410.17238v1#bib.bib5)) as the core decision-making
    engine, leveraging its ability to balance exploration (testing new strategies)
    and exploitation (improving known good strategies). MCTS allows the agent to efficiently
    explore large decision spaces, collect and process experimental results, and intelligently
    select the next promising configuration to test on. By iterating through this
    cycle of experimentation and refinement, \methodname incrementally improves its
    solutions, much like an expert who tests and improves its strategy based on continuous
    feedback.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在 \methodname 中，机器学习问题的搜索空间被提出并构思为一棵树，每个分支代表一个潜在的解决路径。为了在这个搜索空间中进行导航，我们采用了蒙特卡洛树搜索（MCTS）（Coulom，[2007](https://arxiv.org/html/2410.17238v1#bib.bib5)）作为核心决策引擎，利用其在平衡探索（测试新策略）与利用（改进已知有效策略）方面的能力。MCTS
    使得代理能够高效地探索广泛的决策空间，收集和处理实验结果，并智能地选择下一个有前景的配置进行测试。通过反复进行这一实验和优化的循环，\methodname
    会逐步改进其解决方案，就像专家根据持续反馈测试和优化其策略一样。
- en: We rigorously evaluated \methodname using 20 diverse datasets from the AutoML
    Benchmark (Gijsbers et al., [2024](https://arxiv.org/html/2410.17238v1#bib.bib12)),
    comparing its performance against both traditional AutoML systems and agent-based
    AutoML approaches. The results demonstrate that \methodname consistently delivers
    superior performance across a wide range of machine learning tasks, validating
    its effectiveness and adaptability.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用来自 AutoML 基准测试（Gijsbers 等，[2024](https://arxiv.org/html/2410.17238v1#bib.bib12)）的
    20 个不同数据集，严格评估了\methodname，并将其性能与传统的 AutoML 系统和基于代理的 AutoML 方法进行了比较。结果表明，\methodname
    在各种机器学习任务中始终表现出色，验证了其有效性和适应性。
- en: 'To summarize, our research makes the following contributions:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的研究做出了以下贡献：
- en: '1.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: We introduce a feedback-driven approach for LLM agents to iteratively explore
    machine learning configurations, optimizing solutions over multiple experimental
    rounds.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们引入了一种反馈驱动的方法，使 LLM 代理能够迭代探索机器学习配置，通过多轮实验优化解决方案。
- en: '2.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Using Monte Carlo Tree Search, our system navigates a tree-structured search
    space, adaptively identifying high-performance pipelines through feedback.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用蒙特卡洛树搜索，我们的系统在树状搜索空间中导航，适应性地通过反馈识别高性能的管道。
- en: '3.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: We compare agent-based and traditional AutoML, highlighting agentic methods’
    flexibility and potential for enhanced performance in machine learning.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们比较了基于智能体的方法与传统 AutoML，强调了基于智能体的方法在机器学习中更高的灵活性和潜在的性能提升。
- en: '|  | Dynamic Pipeline | Feature Engineering | Model Training | Model Improvement
    | Pipeline Optimization |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | 动态管道 | 特征工程 | 模型训练 | 模型改进 | 管道优化 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| AutoGluon (Erickson et al., [2020](https://arxiv.org/html/2410.17238v1#bib.bib8))
    | ✗ | ✗ | Fixed models | Multi-layer stacking + bagging | ✗ |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| AutoGluon (Erickson 等人, [2020](https://arxiv.org/html/2410.17238v1#bib.bib8))
    | ✗ | ✗ | 固定模型 | 多层堆叠 + 集成 | ✗ |'
- en: '| AutoSklearn (Feurer et al., [2020](https://arxiv.org/html/2410.17238v1#bib.bib11))
    | ✗ | ✗ | Fixed models | Bayes Opt. + meta-learning + ensemble | ✗ |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| AutoSklearn (Feurer 等人, [2020](https://arxiv.org/html/2410.17238v1#bib.bib11))
    | ✗ | ✗ | 固定模型 | 贝叶斯优化 + 元学习 + 集成 | ✗ |'
- en: '| Data Interpreter (Hong et al., [2024a](https://arxiv.org/html/2410.17238v1#bib.bib15))
    | ✓ | Instinctive | Instinctive | Instinctive | ✗ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 数据解释器 (Hong 等人, [2024a](https://arxiv.org/html/2410.17238v1#bib.bib15)) |
    ✓ | 直观 | 直观 | 直观 | ✗ |'
- en: '| AIDE (Schmidt et al., [2024](https://arxiv.org/html/2410.17238v1#bib.bib28))
    | ✓ | Instinctive | Dynamic & diverse | Dynamic & diverse | One-step refinement
    + LLM |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| AIDE (Schmidt 等人, [2024](https://arxiv.org/html/2410.17238v1#bib.bib28))
    | ✓ | 直观 | 动态与多样 | 动态与多样 | 一步精炼 + 大型语言模型 |'
- en: '| \methodname (Ours) | ✓ | Dynamic & diverse | Dynamic & diverse | Dynamic
    & diverse | Stepwise MCTS + LLM |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| \methodname (我们的方法) | ✓ | 动态与多样 | 动态与多样 | 动态与多样 | 分步蒙特卡洛树搜索 + 大型语言模型 |'
- en: 'Table 1: Comparison of key capabilities across various AutoML methods. Dynamic
    indicates the system’s ability to adjust workflows based on intermediate outcomes,
    allowing it to adapt as new information emerges. Diverse refers to employing multiple
    strategies or methods across tasks, which helps capture varied modeling needs.
    Instinctive means that the system directly relies on the decisions generated by
    an LLM and heavily depends on the model’s inclination.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：不同 AutoML 方法的关键能力比较。动态表示系统根据中间结果调整工作流程的能力，允许其在新信息出现时进行适应。多样指的是在任务中采用多种策略或方法，帮助捕捉不同的建模需求。直观意味着系统直接依赖于大型语言模型生成的决策，并且高度依赖模型的倾向。
- en: 2 Related Works
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Tree Search and Its Integration with LLMs Tree search algorithms have significantly
    advanced problem-solving in artificial intelligence, with Monte Carlo Tree Search
    (MCTS) emerging as a leading technique. These algorithms have been successfully
    applied across various domains, including robotics (Wu et al., [2015](https://arxiv.org/html/2410.17238v1#bib.bib37);
    Clary et al., [2018](https://arxiv.org/html/2410.17238v1#bib.bib4); Best et al.,
    [2019](https://arxiv.org/html/2410.17238v1#bib.bib2)), chemistry (Segler et al.,
    [2018](https://arxiv.org/html/2410.17238v1#bib.bib29)), and gaming (Silver et al.,
    [2016](https://arxiv.org/html/2410.17238v1#bib.bib30); [2017](https://arxiv.org/html/2410.17238v1#bib.bib31)),
    where MCTS is used to navigate vast solution spaces and solve complex problems.
    More recently, research has focused on integrating tree search with Large Language
    Models (LLMs) to enhance reasoning and decision-making. Studies such as Krishnamurthy
    et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib21)) and Dwaracherla
    et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib7)) explored LLMs’ capacities
    for efficient exploration, while Tang et al. ([2024a](https://arxiv.org/html/2410.17238v1#bib.bib32))
    and Hui & Tu ([2024](https://arxiv.org/html/2410.17238v1#bib.bib17)) developed
    strategies for exploiting previously learned knowledge. Zhou et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib39))
    and Chi et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib3)) applied
    MCTS for planning with external or self-evaluated feedback, while Feng et al.
    ([2023](https://arxiv.org/html/2410.17238v1#bib.bib9)); Wang et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib35))
    adapted AlphaZero-style tree search to LLM-based tasks. These advancements underscore
    the potential of combining tree search methods with LLMs, balancing exploration
    of new solutions with exploitation of prior knowledge to enhance decision-making.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 树搜索及其与大语言模型（LLMs）的结合。树搜索算法在人工智能中的问题解决方面取得了显著进展，其中蒙特卡洛树搜索（MCTS）作为一种领先技术脱颖而出。这些算法已成功应用于多个领域，包括机器人技术（Wu
    等，[2015](https://arxiv.org/html/2410.17238v1#bib.bib37); Clary 等，[2018](https://arxiv.org/html/2410.17238v1#bib.bib4);
    Best 等，[2019](https://arxiv.org/html/2410.17238v1#bib.bib2)），化学（Segler 等，[2018](https://arxiv.org/html/2410.17238v1#bib.bib29)），以及游戏（Silver
    等，[2016](https://arxiv.org/html/2410.17238v1#bib.bib30); [2017](https://arxiv.org/html/2410.17238v1#bib.bib31)），其中
    MCTS 用于在广泛的解空间中导航并解决复杂问题。最近的研究集中在将树搜索与大语言模型（LLMs）结合，以增强推理和决策能力。Krishnamurthy 等（[2024](https://arxiv.org/html/2410.17238v1#bib.bib21)）和
    Dwaracherla 等（[2024](https://arxiv.org/html/2410.17238v1#bib.bib7)）的研究探索了 LLMs
    在高效探索中的能力，而 Tang 等（[2024a](https://arxiv.org/html/2410.17238v1#bib.bib32)）和 Hui
    & Tu（[2024](https://arxiv.org/html/2410.17238v1#bib.bib17)）则开发了利用先前学到的知识的策略。Zhou
    等（[2024](https://arxiv.org/html/2410.17238v1#bib.bib39)）和 Chi 等（[2024](https://arxiv.org/html/2410.17238v1#bib.bib3)）应用了
    MCTS 进行外部或自我评估反馈的规划，而 Feng 等（[2023](https://arxiv.org/html/2410.17238v1#bib.bib9)）；Wang
    等（[2024](https://arxiv.org/html/2410.17238v1#bib.bib35)）则将 AlphaZero 风格的树搜索方法适配到基于
    LLM 的任务中。这些进展突显了将树搜索方法与 LLMs 结合的潜力，平衡了新解的探索与先前知识的利用，从而增强了决策能力。
- en: Advances and Limitations in AutoML Systems Automated Machine Learning (AutoML)
    frameworks were introduced to reduce the need for expert knowledge in designing
    machine learning pipelines. Early AutoML efforts, such as (Thornton et al., [2013](https://arxiv.org/html/2410.17238v1#bib.bib34);
    Olson & Moore, [2016](https://arxiv.org/html/2410.17238v1#bib.bib26); Jin et al.,
    [2019](https://arxiv.org/html/2410.17238v1#bib.bib18); Feurer et al., [2020](https://arxiv.org/html/2410.17238v1#bib.bib11);
    Erickson et al., [2020](https://arxiv.org/html/2410.17238v1#bib.bib8); LeDell
    & Poirier, [2020](https://arxiv.org/html/2410.17238v1#bib.bib22); Wang et al.,
    [2021](https://arxiv.org/html/2410.17238v1#bib.bib36)), focused primarily on automating
    key pipeline components like hyperparameter optimization, model selection, stacking,
    and ensembling. These frameworks achieved notable progress by integrating meta-learning
    and hyperparameter search strategies to automatically select and tune machine
    learning models. Furthermore, extensions into multi-modal data settings (Tang
    et al., [2024b](https://arxiv.org/html/2410.17238v1#bib.bib33); Jin et al., [2023](https://arxiv.org/html/2410.17238v1#bib.bib19))
    have broadened AutoML’s applicability.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML系统的进展与局限 自动化机器学习（AutoML）框架的引入旨在减少设计机器学习管道时对专家知识的依赖。早期的AutoML研究，如（Thornton等人，[2013](https://arxiv.org/html/2410.17238v1#bib.bib34)；Olson
    & Moore，[2016](https://arxiv.org/html/2410.17238v1#bib.bib26)；Jin等人，[2019](https://arxiv.org/html/2410.17238v1#bib.bib18)；Feurer等人，[2020](https://arxiv.org/html/2410.17238v1#bib.bib11)；Erickson等人，[2020](https://arxiv.org/html/2410.17238v1#bib.bib8)；LeDell
    & Poirier，[2020](https://arxiv.org/html/2410.17238v1#bib.bib22)；Wang等人，[2021](https://arxiv.org/html/2410.17238v1#bib.bib36)）主要聚焦于自动化管道中的关键组件，如超参数优化、模型选择、堆叠和集成。这些框架通过结合元学习和超参数搜索策略，在自动选择和调优机器学习模型方面取得了显著进展。此外，针对多模态数据的拓展（Tang等人，[2024b](https://arxiv.org/html/2410.17238v1#bib.bib33)；Jin等人，[2023](https://arxiv.org/html/2410.17238v1#bib.bib19)）进一步扩大了AutoML的应用范围。
- en: Recently, there has been growing interest in leveraging LLMs within AutoML systems
    to enhance pipeline flexibility. Studies such as Hollmann et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib14));
    Li et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib23)) applied LLMs
    to automate feature engineering, while Liu et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib24))
    introduced LLMs for hyperparameter tuning. In addition, Luo et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib25))
    proposed embedding LLMs at each stage of the machine learning workflow. Despite
    these advancements, traditional AutoML systems remain constrained by rigid pipelines
    and limited flexibility to adapt to unique datasets or specific task requirements.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，越来越多的研究开始关注在自动化机器学习（AutoML）系统中利用大型语言模型（LLMs）来增强管道的灵活性。像Hollmann等人（[2024](https://arxiv.org/html/2410.17238v1#bib.bib14)）；Li等人（[2024](https://arxiv.org/html/2410.17238v1#bib.bib23)）将LLMs应用于自动化特征工程，而Liu等人（[2024](https://arxiv.org/html/2410.17238v1#bib.bib24)）则引入了LLMs用于超参数调优。此外，Luo等人（[2024](https://arxiv.org/html/2410.17238v1#bib.bib25)）提出了在机器学习工作流的每个阶段嵌入LLMs的方法。尽管取得了这些进展，传统的AutoML系统仍然受到僵化管道的限制，缺乏灵活性，难以适应独特的数据集或特定的任务需求。
- en: LLM Agents for Dynamic Machine Learning Pipelines In contrast to static pipelines,
    LLM-based agents offer a more dynamic solution for addressing complex machine
    learning challenges. Hong et al. ([2024a](https://arxiv.org/html/2410.17238v1#bib.bib15);
    [b](https://arxiv.org/html/2410.17238v1#bib.bib16)) introduced an LLM agent with
    hierarchical graph modeling and programmable node generation, enabling the creation
    of sophisticated, adaptable pipelines for diverse data scenarios. Similarly, Zhang
    et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib38)) demonstrated that
    LLMs could effectively interpret structured inputs and apply past experiences
    to solve new machine learning tasks. Guo et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib13))
    expanded on this by introducing a data science agent that leverages case-based
    reasoning; however, it faces challenges when generating solutions from scratch
    due to its reliance on existing codebases. Schmidt et al. ([2024](https://arxiv.org/html/2410.17238v1#bib.bib28))
    proposed an iterative approach, where the entire pipeline is generated in one
    step and refined iteratively through incremental modifications.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 动态机器学习流水线中的LLM代理 与静态流水线不同，基于LLM的代理为解决复杂机器学习挑战提供了更具动态性的解决方案。Hong等人([2024a](https://arxiv.org/html/2410.17238v1#bib.bib15);
    [b](https://arxiv.org/html/2410.17238v1#bib.bib16))提出了一种具有层次图建模和可编程节点生成的LLM代理，使得能够为多样化的数据场景创建复杂且具有适应性的流水线。同样，Zhang等人([2024](https://arxiv.org/html/2410.17238v1#bib.bib38))展示了LLM能够有效地解读结构化输入，并利用过往经验解决新的机器学习任务。Guo等人([2024](https://arxiv.org/html/2410.17238v1#bib.bib13))在此基础上引入了一个利用案例推理的数据科学代理；然而，由于依赖于现有代码库，它在从零开始生成解决方案时面临挑战。Schmidt等人([2024](https://arxiv.org/html/2410.17238v1#bib.bib28))提出了一种迭代方法，其中整个流水线在一步中生成，并通过增量修改进行迭代优化。
- en: 'Building on these efforts, \methodname introduces an agent that integrates
    the strengths of both approaches—stage-wise planning and iterative refinement—allowing
    it to autonomously explore and generate machine learning solutions from the ground
    up. This approach offers greater flexibility and control during the search process,
    enabling the generation of optimized solutions at each stage. Table [1](https://arxiv.org/html/2410.17238v1#S1.T1
    "Table 1 ‣ 1 Introduction ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated
    Machine Learning") highlights the functionalities provided by different AutoML
    systems.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '在这些工作的基础上，\methodname引入了一种代理，整合了两种方法的优势——阶段性规划和迭代优化——使其能够从头开始自主探索并生成机器学习解决方案。这种方法在搜索过程中提供了更大的灵活性和控制力，使得能够在每个阶段生成优化的解决方案。表[1](https://arxiv.org/html/2410.17238v1#S1.T1
    "Table 1 ‣ 1 Introduction ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated
    Machine Learning")展示了不同AutoML系统所提供的功能。'
- en: 3 Method
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: 'As illustrated in Figure [2](https://arxiv.org/html/2410.17238v1#S3.F2 "Figure
    2 ‣ 3 Method ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine
    Learning"), \methodname consists of three key components: an LLM-based insight
    proposer, a search module using MCTS, and an LLM agent as the experiment executor.
    First, the LLM generates insights from the problem description and dataset, defining
    a search space. The search module then organizes this space into a tree structure
    and uses MCTS to explore promising paths. During each cycle, the selected path
    is passed to the LLM agent, which translates the configuration into an executable
    pipeline. The agent plans, codes, and executes the experiment, feeding the results
    back to refine future searches. This iterative process continues until the termination
    criterion is met. The following sections provide a detailed explanation of each
    component.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[2](https://arxiv.org/html/2410.17238v1#S3.F2 "Figure 2 ‣ 3 Method ‣ \methodname:
    Tree-Search Enhanced LLM Agents for Automated Machine Learning")所示，\methodname由三个关键组件组成：基于LLM的洞察生成器、使用MCTS的搜索模块和作为实验执行者的LLM代理。首先，LLM根据问题描述和数据集生成洞察，定义搜索空间。然后，搜索模块将这个空间组织成树状结构，并使用MCTS探索有前景的路径。在每个周期中，选定的路径会传递给LLM代理，后者将配置转化为可执行的流水线。代理进行规划、编码并执行实验，将结果反馈以优化未来的搜索。这个迭代过程持续进行，直到满足终止标准。以下章节将详细解释每个组件。'
- en: '![Refer to caption](img/a817a0c62d9c3df75ab80e70c1004965.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/a817a0c62d9c3df75ab80e70c1004965.png)'
- en: 'Figure 2: \methodname’s pipeline operates as follows: The system begins by
    inputting the problem description and dataset information into the LLM, which
    generates a search space of potential solutions, encompassing data preprocessing,
    feature engineering, and model training. The search module, powered by Monte Carlo
    Tree Search (MCTS), explores this space by selecting, expanding, and simulating
    potential configurations. The LLM agent then simulates the selected configuration
    by planning, coding, and executing the experiment. Feedback from the simulation
    is fed back into the search module, where it is used in the backpropagation step
    to refine future searches. This iterative process continues until a predefined
    stopping criterion is met, resulting in an optimized experimental pipeline.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：\methodname的管道流程如下：系统首先将问题描述和数据集信息输入到大语言模型（LLM），该模型生成潜在解决方案的搜索空间，包括数据预处理、特征工程和模型训练。由蒙特卡罗树搜索（MCTS）驱动的搜索模块通过选择、扩展和模拟潜在配置来探索这个空间。然后，LLM代理模拟所选配置，进行规划、编码并执行实验。模拟结果的反馈被输入回搜索模块，在反向传播步骤中用于优化未来的搜索。这个迭代过程持续进行，直到达到预定的停止准则，最终得到一个优化的实验管道。
- en: 3.1 Insight Proposal and Search Space Creation
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 见解提案与搜索空间创建
- en: To enable \methodname to explore a wide range of machine learning strategies,
    we introduce an insight proposer that generates diverse methods tailored to different
    stages of the machine learning workflow. Each proposed insight suggests either
    a single technique or a combination of methods aimed at enhancing performance.
    For instance, a feature engineering insight might recommend creating interaction
    features from existing variables, while a model training insight could propose
    a specific algorithm or suggest running a grid search to improve accuracy.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使\methodname能够探索广泛的机器学习策略，我们引入了一个见解提案器，它生成适应机器学习工作流不同阶段的多种方法。每个提案的见解都建议使用单一技术或多种方法的组合，旨在提升性能。例如，一个特征工程的见解可能建议从现有变量中创建交互特征，而一个模型训练的见解则可能提议使用某种特定算法，或建议进行网格搜索以提高准确性。
- en: 'The insight proposer takes as input the problem description $p$ and dataset
    information $d$, such as metadata and sample records, and generates $m$ insights
    $\lambda$ for each stage of the machine learning process using a large language
    model $M$. These insights are stored in an insight pool, forming a search space
    $\Lambda$ for \methodname to explore. We decompose the machine learning process
    into five stages: Exploratory Data Analysis ($\tau_{1}$), Data Preprocessing ($\tau_{2}$),
    Feature Engineering ($\tau_{3}$), Model Training ($\tau_{4}$), and Model Evaluation
    ($\tau_{5}$). For simplicity, we denote the entire set of stages as $T$ and refer
    to any specific stage as $\tau$.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 见解提案器以问题描述$p$和数据集信息$d$（如元数据和样本记录）为输入，并使用大语言模型$M$为机器学习过程的每个阶段生成$m$个见解$\lambda$。这些见解存储在一个见解池中，形成\methodname要探索的搜索空间$\Lambda$。我们将机器学习过程分解为五个阶段：探索性数据分析（$\tau_{1}$）、数据预处理（$\tau_{2}$）、特征工程（$\tau_{3}$）、模型训练（$\tau_{4}$）和模型评估（$\tau_{5}$）。为了简化起见，我们将整个阶段集合记作$T$，并将任何特定阶段表示为$\tau$。
- en: '|  | $\displaystyle\text{InsightProposer}(p,d,M)\rightarrow\Lambda:=\{\lambda_{i}^{%
    \tau}\mid\tau\in T,i=1,\dots,m\}$ |  | (1) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{InsightProposer}(p,d,M)\rightarrow\Lambda:=\{\lambda_{i}^{%
    \tau}\mid\tau\in T,i=1,\dots,m\}$ |  | (1) |'
- en: 3.2 Pipeline Execution and Code Generation
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 管道执行与代码生成
- en: 'We employ an LLM agent, referred to as the experiment executor $E$, to conduct
    each trial by building practical experimental pipelines from natural language
    requirements. The agent takes two main steps in this process. First, given an
    experiment configuration $c$, which is a set of insights provided by the search
    module (introduced in Section [3.3.2](https://arxiv.org/html/2410.17238v1#S3.SS3.SSS2
    "3.3.2 Tree Search for ML Experiments ‣ 3.3 Tree Search in Machine Learning Experiments
    ‣ 3 Method ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine
    Learning")), the experiment executor translates these insights into a detailed
    plan. This plan consists of a sequence of task instructions $I^{\tau\in T}$ corresponding
    to each stage of the machine learning process. This step is referred to as $E_{\text{plan}}$.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用一个 LLM 代理，称为实验执行器 $E$，通过从自然语言需求中构建实际的实验管道来进行每次实验。该代理在此过程中执行两个主要步骤。首先，给定实验配置
    $c$，即由搜索模块提供的一组见解（在第 [3.3.2](https://arxiv.org/html/2410.17238v1#S3.SS3.SSS2 "3.3.2
    Tree Search for ML Experiments ‣ 3.3 Tree Search in Machine Learning Experiments
    ‣ 3 Method ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine
    Learning") 节中介绍），实验执行器将这些见解转化为详细计划。该计划由一系列任务指令 $I^{\tau\in T}$ 组成，分别对应机器学习过程的每个阶段。此步骤称为
    $E_{\text{plan}}$。'
- en: Next, following the plan, the agent writes and executes code $\sigma^{\tau}$
    for each task $\tau$ based on the respective instruction $I^{\tau}$, producing
    the code $\sigma^{\tau\in T}$ for the full pipeline, along with the final execution
    score $s$. The complete set of code outputs $\sigma^{\tau\in T}$ is concatenated
    into a full solution $\sigma_{sol}$ to address the problem. This phase is referred
    to as $E_{\text{code \& execute}}$.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，按照计划，代理根据各自的指令 $I^{\tau}$ 为每个任务 $\tau$ 编写并执行代码 $\sigma^{\tau}$，生成完整管道的代码
    $\sigma^{\tau\in T}$，并输出最终的执行评分 $s$。完整的代码输出集合 $\sigma^{\tau\in T}$ 被拼接成一个完整的解决方案
    $\sigma_{sol}$，以解决问题。这个阶段称为 $E_{\text{code \& execute}}$。
- en: '|  | $\displaystyle E_{\text{plan}}(p,d,c,M)$ | $\displaystyle\rightarrow I^{\tau\in
    T}$ |  | (2) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle E_{\text{plan}}(p,d,c,M)$ | $\displaystyle\rightarrow I^{\tau\in
    T}$ |  | (2) |'
- en: '|  | $\displaystyle E_{\text{code \& execute}}(I^{\tau\in T},D,M)$ | $\displaystyle\rightarrow(\sigma^{\tau\in
    T},s)$ |  | (3) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle E_{\text{code \& execute}}(I^{\tau\in T},D,M)$ | $\displaystyle\rightarrow(\sigma^{\tau\in
    T},s)$ |  | (3) |'
- en: 3.3 Tree Search in Machine Learning Experiments
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 机器学习实验中的树搜索
- en: 'In order to systematically explore the different configurations in machine
    learning experiments, we model the search space as a hierarchical tree. This structure
    allows us to apply tree search algorithms, where each path through the tree represents
    a different experiment configuration. Algorithm [1](https://arxiv.org/html/2410.17238v1#alg1
    "Algorithm 1 ‣ 3.3.2 Tree Search for ML Experiments ‣ 3.3 Tree Search in Machine
    Learning Experiments ‣ 3 Method ‣ \methodname: Tree-Search Enhanced LLM Agents
    for Automated Machine Learning") also provides an overview of this searching process.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '为了系统地探索机器学习实验中的不同配置，我们将搜索空间建模为一个层次树结构。这种结构使我们能够应用树搜索算法，其中每一条树路径代表一个不同的实验配置。[算法
    1](https://arxiv.org/html/2410.17238v1#alg1 "Algorithm 1 ‣ 3.3.2 Tree Search for
    ML Experiments ‣ 3.3 Tree Search in Machine Learning Experiments ‣ 3 Method ‣
    \methodname: Tree-Search Enhanced LLM Agents for Automated Machine Learning")
    还概述了这个搜索过程。'
- en: 3.3.1 Experiment Node
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 实验节点
- en: 'To facilitate the exploration of various strategies, we model the proposed
    search space as a hierarchical tree that is well-suited for applying search algorithms.
    Each node in the tree, denoted as $x$, represents one insight $\lambda$ in the
    search space $\Lambda$ and contains the following attributes:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进各种策略的探索，我们将提出的搜索空间建模为一个层次树结构，适合应用搜索算法。树中的每个节点，表示为 $x$，代表搜索空间 $\Lambda$ 中的一个见解
    $\lambda$，并包含以下属性：
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Insight $\lambda(x)$: Represents the specific insight $\lambda_{i}^{\tau}\in\Lambda$
    associated with this node, where $\tau$ denotes the stage of the machine learning
    pipeline.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 见解 $\lambda(x)$：表示与该节点相关的特定见解 $\lambda_{i}^{\tau}\in\Lambda$，其中 $\tau$ 表示机器学习管道的阶段。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Depth $\delta(x)$: Indicates the stage of the machine learning process the
    node corresponds to (e.g., depth 1 might represent data preprocessing, depth 2
    for feature engineering, and depth 3 for model training).'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度 $\delta(x)$：表示节点对应的机器学习过程的阶段（例如，深度 1 可能代表数据预处理，深度 2 代表特征工程，深度 3 代表模型训练）。
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Value $v(x)$: The cumulative score from simulations for this node and all its
    descendants.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 值 $v(x)$：此节点及其所有后代的模拟累积分数。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Visits $n_{\text{visits}}(x)$: The total number of simulations conducted
    for this node and its descendants.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 访问次数 $n_{\text{visits}}(x)$：为此节点及其后代进行的仿真总次数。
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Simulation Score $s(x)$: The score for simulating this node.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仿真得分 $s(x)$：仿真此节点的得分。
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Solution Code $\sigma_{\text{sol}}(x)$ The final code produced after the node
    simulation.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解代码 $\sigma_{\text{sol}}(x)$：节点仿真后生成的最终代码。
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Stage Code $\sigma_{\text{stage}}(x)$: The code generated up to the node’s
    current stage, a part of the solution code'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段代码 $\sigma_{\text{stage}}(x)$：生成到当前节点阶段的代码，是解的代码的一部分
- en: By modeling the search space as a tree, each path from the root to a node $x$
    represents an experiment configuration $c(x)=\{\lambda(x_{1}),\lambda(x_{2}),\dots,\lambda(x)\}\subset\Lambda$,
    where $x_{1},x_{2},\dots,x$ are nodes along the path. The task of finding the
    optimal solution can therefore be viewed as a path search within the tree, where
    each path corresponds to a potential configuration of the experiment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将搜索空间建模为树形结构，从根节点到节点 $x$ 的每条路径代表一个实验配置 $c(x)=\{\lambda(x_{1}),\lambda(x_{2}),\dots,\lambda(x)\}\subset\Lambda$，其中
    $x_{1},x_{2},\dots,x$ 是路径上的节点。因此，寻找最佳解的任务可以视为树内的路径搜索，每条路径对应于实验的潜在配置。
- en: 3.3.2 Tree Search for ML Experiments
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 机器学习实验的树搜索
- en: We apply Monte Carlo Tree Search (MCTS) to systematically explore and identify
    optimal machine learning solutions within our framework. MCTS allows us to efficiently
    navigate the search space across multiple stages of the machine learning pipeline—from
    data preprocessing to model selection—by balancing exploration and exploitation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用蒙特卡洛树搜索（MCTS）来系统地探索并识别框架中的最佳机器学习解。MCTS 使我们能够高效地在机器学习管道的多个阶段之间导航搜索空间，从数据预处理到模型选择，通过平衡探索和开发。
- en: Algorithm 1 \methodname using MCTS
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 \methodname 使用 MCTS
- en: 0:  Problem description $p$, data information $d$, data $D$, LLM $M$, rollout
    number $k$.1:  $\Lambda\leftarrow\text{InsightProposer}(p,d,M)$2:  Initialize
    Tree using $\Lambda$3:  for $i$ = 1 to $k$ do4:     node $x\leftarrow$ select(Tree)5:     $X_{\text{child}}\leftarrow$
    expand(Tree, $x$)6:     Randomly sample a node $x_{\text{sample}}$ from $X_{\text{child}}$7:     Retreive
    experiment configuration $c(x_{\text{sample}})$8:     $\sigma_{sol},s\leftarrow\text{simulate}(c(x_{\text{sample}}),p,d,D,M)$9:     attach
    the simulation result $\sigma_{sol},s$ to $x_{\text{sample}}$ for final solution
    selection10:     Backpropagate(Tree, $s$)11:  end for12:  $x_{\text{dev best}}\leftarrow\underset{x\in\text{Tree}}{\text{argmax}}(s(x))$12:  $\sigma_{sol}(x_{\text{dev
    best}})$
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 0:  问题描述 $p$，数据信息 $d$，数据 $D$，LLM $M$，回合次数 $k$。1:  $\Lambda\leftarrow\text{InsightProposer}(p,d,M)$2:  使用
    $\Lambda$ 初始化树结构3:  对于 $i$ = 1 到 $k$ 循环4:     节点 $x\leftarrow$ 选择(Tree)5:     $X_{\text{child}}\leftarrow$
    扩展(Tree, $x$)6:     随机从 $X_{\text{child}}$ 中选择一个节点 $x_{\text{sample}}$7:     获取实验配置
    $c(x_{\text{sample}})$8:     $\sigma_{sol},s\leftarrow\text{simulate}(c(x_{\text{sample}}),p,d,D,M)$9:     将仿真结果
    $\sigma_{sol},s$ 附加到 $x_{\text{sample}}$ 以供最终解的选择10:     反向传播(Tree, $s$)11:  结束 循环12:  $x_{\text{dev
    best}}\leftarrow\underset{x\in\text{Tree}}{\text{argmax}}(s(x))$12:  $\sigma_{sol}(x_{\text{dev
    best}})$
- en: Algorithm 2 Simulate
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 2 仿真
- en: 0:  Experiment configuration $c$, problem description $p$, data information
    $d$, data $D$, LLM $M$.1:  Draft plans $I^{\tau\in T}\leftarrow E_{\text{plan}}(p,d,c,M)$2:  Code
    and execute sequentially $\sigma^{\tau\in T},s\leftarrow E_{\text{code \& execute}}(I^{\tau\in
    T},D,M)$3:  $\sigma_{sol}\leftarrow\text{concatenate}(\sigma^{\tau\in T})$3:  $\sigma_{sol},s$
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 0:  实验配置 $c$，问题描述 $p$，数据信息 $d$，数据 $D$，LLM $M$。1:  草拟计划 $I^{\tau\in T}\leftarrow
    E_{\text{plan}}(p,d,c,M)$2:  按顺序编写并执行 $\sigma^{\tau\in T},s\leftarrow E_{\text{code
    \& execute}}(I^{\tau\in T},D,M)$3:  $\sigma_{sol}\leftarrow\text{concatenate}(\sigma^{\tau\in
    T})$3:  $\sigma_{sol},s$
- en: The search process involves performing multiple rollouts, which include the
    steps of selection, expansion, simulation, and backpropagation. We conduct $k$
    rollouts to explore various paths, aiming to identify the best solution.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索过程包括执行多个回合，这些回合包括选择、扩展、仿真和反向传播步骤。我们进行 $k$ 次回合来探索不同路径，目的是识别最佳解。
- en: Selection At each iteration, we use a modified version of the UCT (Upper Confidence
    Bound for Trees) algorithm (Kocsis & Szepesvári, [2006](https://arxiv.org/html/2410.17238v1#bib.bib20)),
    referred to as UCT-DP (depth-preferred), to select a node from the search tree.
    Unlike traditional MCTS, where simulations are often performed quickly due to
    a fixed action space and negligible action time, the context of machine learning
    tasks presents a different challenge. Processes such as model training introduce
    significant computational time, making efficient node exploration crucial. Since
    model selection can heavily influence the overall machine learning performance,
    we prioritize exploring nodes at greater depths early on.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 在每次迭代中，我们使用修改版的 UCT（树的上置信界）算法（Kocsis & Szepesvári，[2006](https://arxiv.org/html/2410.17238v1#bib.bib20)），称为
    UCT-DP（深度优先），从搜索树中选择一个节点。与传统的 MCTS（蒙特卡洛树搜索）不同，传统方法由于固定的动作空间和可忽略的动作时间，模拟往往很快完成，但机器学习任务的背景提出了不同的挑战。诸如模型训练等过程引入了显著的计算时间，使得高效的节点探索变得至关重要。由于模型选择会极大地影响整体的机器学习性能，因此我们优先在早期探索更深层的节点。
- en: 'This modification reduces the need to explore every unvisited node, allowing
    deeper nodes to be reached in fewer iterations—making the approach better suited
    for large-scale machine learning experiments. The modified selection algorithm
    is expressed as:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这一修改减少了探索每个未访问节点的需求，从而使得能够在更少的迭代中到达更深的节点——使得该方法更适合大规模的机器学习实验。修改后的选择算法表示为：
- en: '|  | $\displaystyle\text{UCT-DP}(x)=\frac{v(x)}{n(x)}+\alpha_{\text{explore}}\sqrt{%
    \frac{\ln n_{\text{visits}}(x_{\text{parent}})}{n(x)}}$ |  | (4) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{UCT-DP}(x)=\frac{v(x)}{n(x)}+\alpha_{\text{explore}}\sqrt{%
    \frac{\ln n_{\text{visits}}(x_{\text{parent}})}{n(x)}}$ |  | (4) |'
- en: '|  | $\displaystyle n(x)=\begin{cases}\alpha_{\text{unvisted}}&\text{if }n_{\text{%
    visits}}(x)=0\\ n_{\text{visits}}(x)&\text{otherwise.}\end{cases}$ |  | (5) |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle n(x)=\begin{cases}\alpha_{\text{unvisted}}&\text{如果 }n_{\text{%
    visits}}(x)=0\\ n_{\text{visits}}(x)&\text{否则。}\end{cases}$ |  | (5) |'
- en: Here, $\alpha_{\text{unvisted}}$ is a constant between 0 and 1 controlling the
    selection preference for unvisited nodes, balancing between full exploration and
    computational efficiency. This adjustment allows us to focus more on deeper parts
    of the tree that are likely to yield better solutions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$\alpha_{\text{unvisted}}$ 是一个介于 0 和 1 之间的常数，用于控制未访问节点的选择偏好，平衡完全探索与计算效率之间的关系。此调整使我们能够更专注于树的深层部分，这些部分更可能产生更好的解。
- en: Expansion During the expansion phase, a set of child nodes $X_{\text{child}}$
    are instantiated from the selected node $x$ for potential simulation. Note that
    a child node $x_{\text{child}}$ from the node $x$ at depth $\delta$ inherits the
    attributes of $x$ and possesses $\lambda(x_{\text{child}})\rightarrow\lambda^{\tau_{\delta+1}}$,
    an insight of stage $\tau_{\delta+1}$ from the search space.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展 在扩展阶段，从选定的节点 $x$ 实例化一组子节点 $X_{\text{child}}$ 以进行潜在的模拟。请注意，来自节点 $x$ 且深度为 $\delta$
    的子节点 $x_{\text{child}}$ 继承了 $x$ 的属性，并具有 $\lambda(x_{\text{child}})\rightarrow\lambda^{\tau_{\delta+1}}$，这是来自搜索空间的阶段
    $\tau_{\delta+1}$ 的洞察。
- en: 'Simulation Once expanded, a node $x_{\text{sample}}$ is randomly sampled from
    $X_{\text{child}}$ for simulation. The path from root to the sampled node forms
    a set of insights $c(x_{\text{sample}})=\{\lambda(x_{1}),\lambda(x_{2}),...,\lambda(x_{\text{%
    sample}})\}\subset\Lambda$, representing the experiment configuration to be simulated,
    where $x_{1},x_{2},..,x_{\text{sample}}$ are the nodes along the path. The configuration
    $c(x_{\text{sample}})$ is then fed to the experimenter $E$ for execution following
    $E_{\text{plan}}$ and $E_{\text{code \& execute}}$, which produces a simulation
    score $s$, as illustrated in Section [3.3.1](https://arxiv.org/html/2410.17238v1#S3.SS3.SSS1
    "3.3.1 Experiment Node ‣ 3.3 Tree Search in Machine Learning Experiments ‣ 3 Method
    ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine Learning").
    The score serves as the feedback for back propagation. Algorithm [2](https://arxiv.org/html/2410.17238v1#alg2
    "Algorithm 2 ‣ 3.3.2 Tree Search for ML Experiments ‣ 3.3 Tree Search in Machine
    Learning Experiments ‣ 3 Method ‣ \methodname: Tree-Search Enhanced LLM Agents
    for Automated Machine Learning") outlines the simulation process.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '仿真 一旦节点扩展完成，节点 $x_{\text{sample}}$ 将从 $X_{\text{child}}$ 中随机抽取进行仿真。从根节点到抽取节点的路径形成一组洞察
    $c(x_{\text{sample}})=\{\lambda(x_{1}),\lambda(x_{2}),...,\lambda(x_{\text{% sample}})\}\subset\Lambda$，表示将要仿真的实验配置，其中
    $x_{1},x_{2},..,x_{\text{sample}}$ 是路径上的节点。然后将配置 $c(x_{\text{sample}})$ 提供给实验者
    $E$ 进行执行，遵循 $E_{\text{plan}}$ 和 $E_{\text{code \& execute}}$，生成仿真得分 $s$，如第 [3.3.1](https://arxiv.org/html/2410.17238v1#S3.SS3.SSS1
    "3.3.1 实验节点 ‣ 3.3 树搜索在机器学习实验中的应用 ‣ 3 方法 ‣ \methodname: 基于树搜索的 LLM 代理用于自动化机器学习")
    节中所示。该得分作为反向传播的反馈。算法 [2](https://arxiv.org/html/2410.17238v1#alg2 "算法 2 ‣ 3.3.2
    机器学习实验中的树搜索 ‣ 3.3 树搜索在机器学习实验中的应用 ‣ 3 方法 ‣ \methodname: 基于树搜索的 LLM 代理用于自动化机器学习")
    概述了仿真过程。'
- en: Backpropagation After the simulation concludes, the performance score (e.g.,
    based on the development set) is retrieved and backpropagated through the tree.
    The score is propagated from the simulated node up to the root, updating each
    parent node’s value and visit count. This allows nodes representing more promising
    solutions to be prioritized in future rollouts. In addition, the solution code
    is also backpropagated up to the tree, and it can be processed and saved as stage
    code depending on the parent node during the update.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播 在仿真结束后，性能得分（例如，基于开发集）会被检索并反向传播通过树。得分从仿真节点传递到根节点，更新每个父节点的值和访问计数。这使得表示更有前景解决方案的节点在未来的展开中得到优先考虑。此外，解决方案代码也会被反向传播到树上，并可以根据更新过程中的父节点进行处理和保存为阶段代码。
- en: Backpropagation ensures that the algorithm learns which paths yield better results,
    guiding the search toward higher-performing nodes as more rollouts are conducted.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播确保算法能够学习哪些路径产生更好的结果，并在进行更多展开时，指导搜索朝向更高性能的节点。
- en: 3.3.3 Experiment State Saving and Loading
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3 实验状态保存与加载
- en: 'To boost experimentation efficiency and reduce token usage, \methodname implements
    fine-grained code reuse by caching code at the stage level for each attempted
    configuration $c$. This allows the framework to reuse as much saved code as possible
    when a new configuration $c_{\text{new}}$ shares components with existing ones.
    Additionally, this technique addresses the challenge of LLM non-determinism, where
    identical instructions can produce different code, increasing variance in final
    performance. Specifically, whenever a node is chosen for execution, the experimenter
    loads and reruns the saved stage code, if available, ensuring consistency before
    progressing to the next stage. This approach effectively conserves resources while
    maintaining robust performance across stages. In Appendix [D](https://arxiv.org/html/2410.17238v1#A4
    "Appendix D Cost-effectiveness Analysis ‣ \methodname: Tree-Search Enhanced LLM
    Agents for Automated Machine Learning"), we examine the cost efficiency of this
    state-saving and loading mechanism.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '为了提高实验效率并减少令牌使用，\methodname 实现了通过在阶段级别缓存每个尝试配置 $c$ 的代码来细粒度地重用代码。这使得框架在新配置 $c_{\text{new}}$
    与现有配置共享组件时，可以尽可能地重用已保存的代码。此外，该技术还解决了大语言模型（LLM）非确定性的挑战，因为相同的指令可能会生成不同的代码，从而增加最终性能的方差。具体来说，每当选择一个节点执行时，实验者会加载并重新运行已保存的阶段代码（如果有的话），确保在进入下一阶段之前的一致性。该方法有效地节省了资源，同时保持跨阶段的稳定表现。在附录
    [D](https://arxiv.org/html/2410.17238v1#A4 "附录 D 成本效益分析 ‣ \methodname: 基于树搜索的
    LLM 代理用于自动化机器学习") 中，我们研究了这一状态保存和加载机制的成本效率。'
- en: 4 Experiments
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 4.1 Experimental Setup
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 实验设置
- en: Datasets
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据集
- en: We evaluate \methodname alongside several baselines on 20 datasets, which include
    13 classification tasks and 7 regression tasks from the AutoML Benchmark (AMLB)
    (Gijsbers et al., [2024](https://arxiv.org/html/2410.17238v1#bib.bib12)) and Kaggle
    Competitions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在20个数据集上评估\methodname与多个基准方法，包括来自自动化机器学习基准（AMLB）（Gijsbers等，[2024](https://arxiv.org/html/2410.17238v1#bib.bib12)）和Kaggle竞赛的13个分类任务和7个回归任务。
- en: 'Table [4](https://arxiv.org/html/2410.17238v1#A1.T4 "Table 4 ‣ Appendix A Datasets
    ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine Learning")
    provides detailed information on the datasets used. All datasets are split into
    training, validation, and test sets with a 6:2:2 ratio. Each framework utilizes
    the training and validation sets to train models and makes predictions on the
    test set labels.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '表格[4](https://arxiv.org/html/2410.17238v1#A1.T4 "表格 4 ‣ 附录 A 数据集 ‣ \methodname:
    基于树搜索的增强型大语言模型代理用于自动化机器学习")提供了所使用数据集的详细信息。所有数据集被分为训练集、验证集和测试集，比例为6:2:2。每个框架利用训练集和验证集训练模型，并在测试集标签上进行预测。'
- en: Evaluation Metrics
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 评估指标
- en: For the AMLB datasets, we use the default target column provided by OpenML.
    For Kaggle competition datasets, we rely on the target column specified in the
    competition description. Performance is measured using root mean squared error
    (RMSE) for regression tasks, F1 score for binary classification, and F1-weighted
    score for multi-class classification. To ensure comparability across datasets
    with varying metrics, we introduce a Normalized Score (NS), which maps RMSE into
    the range from 0 to 1.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AMLB数据集，我们使用OpenML提供的默认目标列。对于Kaggle竞赛数据集，我们依赖于竞赛描述中指定的目标列。性能评估使用均方根误差（RMSE）用于回归任务，F1得分用于二分类，F1加权得分用于多分类。为了确保跨数据集的可比性，我们引入了归一化得分（NS），将RMSE映射到0到1的范围。
- en: '|  | $\displaystyle\text{NS}(s_{\text{raw}})=\begin{cases}\frac{1}{1+\log{(1+s_{%
    \text{raw}})}}&\text{if the metric is RMSE.}\\ s_{\text{raw}}&\text{otherwise.}\end{cases}$
    |  | (6) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{NS}(s_{\text{raw}})=\begin{cases}\frac{1}{1+\log{(1+s_{%
    \text{raw}})}}&\text{如果度量标准是RMSE。}\\ s_{\text{raw}}&\text{否则。}\end{cases}$ |  |
    (6) |'
- en: 'Here, $s_{raw}$ represents the raw score before normalization. To evaluate
    \methodname against other frameworks, we employ three key metrics: average Normalized
    Score (NS), average rank, and average best rank. The average rank is calculated
    by considering all rankings of a method across datasets, while the average best
    rank focuses on the method’s best performance in each dataset. We also want to
    quantify how other baselines perform relative to \methodname. The “Rescaled NS”
    is defined as:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$s_{raw}$表示归一化前的原始得分。为了将\methodname与其他框架进行评估，我们采用三个关键指标：平均归一化得分（NS），平均排名和平均最佳排名。平均排名是通过考虑方法在所有数据集上的排名来计算的，而平均最佳排名则关注方法在每个数据集中的最佳表现。我们还希望量化其他基准方法相对于\methodname的表现。“归一化得分”定义为：
- en: '|  | $\displaystyle\text{Rescaled NS}(f)=\frac{\text{NS}_{f}}{\text{NS}_{\methodname%
    {}}}$ |  | (7) |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{Rescaled NS}(f)=\frac{\text{NS}_{f}}{\text{NS}_{\methodname%
    {}}}$ |  | (7) |'
- en: where $f$ represents the baseline method being compared to \methodname.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f$ 表示与\methodname进行比较的基准方法。
- en: Method and Baselines Setup
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方法和基准设置
- en: We compare \methodname with several baseline methods, including Data Interpreter
    (Hong et al., [2024a](https://arxiv.org/html/2410.17238v1#bib.bib15)), AIDE (Schmidt
    et al., [2024](https://arxiv.org/html/2410.17238v1#bib.bib28)), AutoGluon (Erickson
    et al., [2020](https://arxiv.org/html/2410.17238v1#bib.bib8)), and AutoSklearn
    (Feurer et al., [2015](https://arxiv.org/html/2410.17238v1#bib.bib10); [2020](https://arxiv.org/html/2410.17238v1#bib.bib11)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将\methodname与几个基准方法进行比较，包括数据解释器（Hong等，[2024a](https://arxiv.org/html/2410.17238v1#bib.bib15)），AIDE（Schmidt等，[2024](https://arxiv.org/html/2410.17238v1#bib.bib28)），AutoGluon（Erickson等，[2020](https://arxiv.org/html/2410.17238v1#bib.bib8)），和AutoSklearn（Feurer等，[2015](https://arxiv.org/html/2410.17238v1#bib.bib10)；[2020](https://arxiv.org/html/2410.17238v1#bib.bib11)）。
- en: For our LLM-based approaches (\methodname, Data Interpreter, and AIDE), we employ
    a consistent initial task prompt across all methods. This prompt encompasses the
    dataset name, target column, and evaluation metric. We choose DeepSeek v2.5 (DeepSeek-AI,
    [2024](https://arxiv.org/html/2410.17238v1#bib.bib6)) as our foundation LLM due
    to its open-source nature, strong coding capabilities, and cost-effective token
    usage. To encourage output diversity, we set the temperature parameter to 0.5
    for all LLM-based methods. AIDE conducts 10 iterations per execution, while \methodname
    performs 10 rollouts.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于LLM的方法（\methodname、数据解释器和AIDE），我们在所有方法中采用一致的初始任务提示。该提示包括数据集名称、目标列和评估指标。我们选择DeepSeek
    v2.5（DeepSeek-AI，[2024](https://arxiv.org/html/2410.17238v1#bib.bib6)）作为我们的基础LLM，原因是其开源特性、强大的编码能力和高性价比的令牌使用。为了促进输出的多样性，我们为所有基于LLM的方法将温度参数设置为0.5。AIDE每次执行进行10次迭代，而\methodname进行10次回滚。
- en: 'For \methodname, we employ Data Interpreter as the experimenter, leveraging
    its multi-step generation capability. We configured the hyperparameters of UCT-DP
    as follows: $\alpha_{\text{unvisited}}$ is set to 0.8 and $\alpha_{\text{explore}}$
    is set to 1.4\. These settings aim to balance exploration and exploitation in
    the method’s search strategy.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于\methodname，我们使用数据解释器作为实验者，利用其多步骤生成能力。我们将UCT-DP的超参数配置如下：$\alpha_{\text{unvisited}}$
    设置为0.8，$\alpha_{\text{explore}}$ 设置为1.4。这些设置旨在平衡该方法搜索策略中的探索与利用。
- en: Each method, except for AutoGluon, is run three times for each dataset. AutoGluon,
    being deterministic, is run only once with its default settings. AutoSklearn is
    also run with default settings, limited to 600 seconds per task.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了AutoGluon外，每个方法在每个数据集上运行三次。AutoGluon是确定性的，只运行一次，使用默认设置。AutoSklearn也使用默认设置，每个任务限制为600秒。
- en: '| Method | Wins | Losses | Top 1 | Avg. NS % $\uparrow$ | Avg. Best NS % $\uparrow$
    | Avg. Rank $\downarrow$ | Avg. Best Rank $\downarrow$ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 胜场数 | 败场数 | 第一名 | 平均标准化得分（NS）$\uparrow$ | 平均最佳标准化得分（NS）$\uparrow$ |
    平均排名 $\downarrow$ | 平均最佳排名 $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| AutoGluon | 7 | 13 | 4 | 53.2 | 53.2 | 4.4 | 4.4 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| AutoGluon | 7 | 13 | 4 | 53.2 | 53.2 | 4.4 | 4.4 |'
- en: '| AutoSklearn | 5 | 15 | 5 | 46.1 | 47.5 | 7.6 | 6.1 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| AutoSklearn | 5 | 15 | 5 | 46.1 | 47.5 | 7.6 | 6.1 |'
- en: '| AIDE | 5 | 15 | 2 | 47.1 | 51.8 | 7.8 | 5.3 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| AIDE | 5 | 15 | 2 | 47.1 | 51.8 | 7.8 | 5.3 |'
- en: '| Data Interpreter | 4 | 16 | 2 | 47.4 | 50.2 | 8.8 | 6.4 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 数据解释器 | 4 | 16 | 2 | 47.4 | 50.2 | 8.8 | 6.4 |'
- en: '| \methodname | - | - | 7 | 53.3 | 54.7 | 4.8 | 2.7 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| \methodname | - | - | 7 | 53.3 | 54.7 | 4.8 | 2.7 |'
- en: 'Table 2: Results of each AutoML framework on 20 tabular datasets. The “Wins”
    column indicates the number of datasets where the method outperforms \methodname,
    while “Losses” shows the number of datasets where the method underperforms. The
    “Top 1” column represents the number of datasets where the method produces the
    best predictions across methods.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：每个AutoML框架在20个表格数据集上的结果。“胜场数”列表示该方法优于\methodname的数据显示的次数，而“败场数”则显示该方法表现不如\methodname的次数。“第一名”列表示该方法在所有方法中产生最佳预测的次数。
- en: 4.2 Results
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 结果
- en: '![Refer to caption](img/030d5f8c1803668a48b5b63e73a71f42.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/030d5f8c1803668a48b5b63e73a71f42.png)'
- en: 'Figure 3: Rescaled NS of AutoML frameworks relative to \methodname on tabular
    datasets. Points to the left of the vertical line indicate poorer predictions
    compared to \methodname. Notably, \methodname often occupies a leading position
    across the datasets.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：相对于\methodname，在表格数据集上的AutoML框架的标准化得分（NS）重新缩放后的比较。垂直线左侧的点表示与\methodname相比，预测效果较差。值得注意的是，\methodname在所有数据集上通常占据领先位置。
- en: 'As shown in Table [2](https://arxiv.org/html/2410.17238v1#S4.T2 "Table 2 ‣
    Method and Baselines Setup ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ \methodname:
    Tree-Search Enhanced LLM Agents for Automated Machine Learning"), \methodname
    achieves the highest average Normalized Score (NS) and average best rank among
    all frameworks. Notably, \methodname excels in producing the highest number of
    top predictions, as indicated in the “Top 1” column across all datasets. Furthermore,
    the “Losses” column reveals that each competing method falls short against \methodname,
    losing in 65-80% of the datasets.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[2](https://arxiv.org/html/2410.17238v1#S4.T2 "表2 ‣ 方法和基准设置 ‣ 4.1 实验设置 ‣ 4
    实验 ‣ \methodname：树搜索增强的LLM代理用于自动化机器学习")所示，\methodname在所有框架中获得了最高的平均标准化得分（NS）和平均最佳排名。值得注意的是，\methodname在所有数据集上都表现出最佳的预测次数，如“第一名”列所示。此外，“败场数”列显示，每个竞争方法在65%-80%的数据集上都不及\methodname。
- en: Interestingly, AutoGluon exhibits a marginally higher average rank than \methodname.
    This slight discrepancy may be attributed to the inherent randomness in LLMs and
    model training processes, which can influence the exploration of machine learning
    solutions. However, \methodname’s higher average NS suggests that it performs
    strongly in the datasets where it excels, while its losses in other datasets are
    relatively minor. This means that even when \methodname produces lower-ranked
    solutions, the performance gap is small, allowing it to fully compensate in the
    datasets where it performs well.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，AutoGluon的平均排名略高于\methodname。这一微小差异可能归因于LLM和模型训练过程中的固有随机性，这可能影响机器学习解决方案的探索。然而，\methodname较高的平均NS表明，它在擅长的数据集上表现强劲，而在其他数据集上的损失相对较小。这意味着，即使\methodname产生了较低排名的解决方案，性能差距也很小，能够在其表现良好的数据集上完全弥补。
- en: The two other agent-based methods exhibit relatively lower performance. The
    first method, Data Interpreter, struggles to enhance its score with multiple attempts
    due to its inability to refine its solution after completing a machine learning
    task. The second method, AIDE, does not have a stage-specific planning module,
    limiting its capacity to improve results after a series of greedy exploitation,
    which makes it prone to falling into local optima. These limitations likely account
    for their weaker performance.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两种基于代理的方法表现相对较低。第一种方法，数据解释器，在多次尝试后无法显著提升其得分，因为它无法在完成机器学习任务后细化其解决方案。第二种方法，AIDE，没有特定阶段的规划模块，限制了其在一系列贪婪的开发后改善结果的能力，这使得它容易陷入局部最优解。这些局限性可能是它们表现较弱的原因。
- en: 'Figure [3](https://arxiv.org/html/2410.17238v1#S4.F3 "Figure 3 ‣ 4.2 Results
    ‣ 4 Experiments ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine
    Learning") further corroborates \methodname’s effectiveness, revealing that its
    best solutions frequently occupy leading positions across various datasets. This
    visual representation exhibits the method’s consistent high performance and adaptability
    across different ML datasets. We also include a detailed results of each method
    in Appendix [C](https://arxiv.org/html/2410.17238v1#A3 "Appendix C Results ‣ \methodname:
    Tree-Search Enhanced LLM Agents for Automated Machine Learning").'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [3](https://arxiv.org/html/2410.17238v1#S4.F3 "Figure 3 ‣ 4.2 Results ‣ 4
    Experiments ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine
    Learning") 进一步验证了\methodname的有效性，揭示了其最佳解决方案经常在不同数据集上占据领先位置。此图展示了该方法在不同机器学习数据集上的一致性高性能和适应性。我们还在附录[C](https://arxiv.org/html/2410.17238v1#A3
    "Appendix C Results ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated
    Machine Learning")中包含了每种方法的详细结果。'
- en: 4.3 Ablation Study
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 消融研究
- en: For the rest of the study, we employ a subset of datasets to evaluate \methodname
    under various settings. Our selection process involves choosing the first two
    datasets alphabetically for each machine learning task. Specifically, we use boston,
    colleges, credit-g, Click_prediction_small, GesturePhaseSegmentationProcessed,
    and mfeat-factors to conduct the ablation study.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的研究中，我们使用一部分数据集来评估\methodname在不同设置下的表现。我们的选择过程涉及按字母顺序选择每个机器学习任务的前两个数据集。具体来说，我们使用boston、colleges、credit-g、Click_prediction_small、GesturePhaseSegmentationProcessed和mfeat-factors进行消融研究。
- en: '|  | Data Interpreter | \methodname (Random Search) | \methodname (MCTS) |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|  | 数据解释器 | \methodname (随机搜索) | \methodname (MCTS) |'
- en: '| --- | --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Avg. NS $\uparrow$ | 56.4 | 58.6 | 60.9 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 平均NS $\uparrow$ | 56.4 | 58.6 | 60.9 |'
- en: '| Avg. Best NS $\uparrow$ | 59.0 | 61.4 | 62.4 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 平均最佳NS $\uparrow$ | 59.0 | 61.4 | 62.4 |'
- en: '| Avg. Rank $\downarrow$ | 6.9 | 4.8 | 3.3 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 平均排名 $\downarrow$ | 6.9 | 4.8 | 3.3 |'
- en: '| Avg. Best Rank $\downarrow$ | 4.8 | 2.8 | 1.5 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 平均最佳排名 $\downarrow$ | 4.8 | 2.8 | 1.5 |'
- en: 'Table 3: Performance results for each search setting on the chosen datasets.
    \methodname with MCTS consistently surpasses \methodname with Random Search.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 3：在所选数据集上，各种搜索设置的性能结果。使用MCTS的\methodname始终优于使用随机搜索的\methodname。
- en: Effectiveness of Search
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 搜索有效性
- en: 'To evaluate the effectiveness of Monte Carlo Tree Search (MCTS) in improving
    the solution search process, we conducted an ablation study. In this study, we
    compared the performance of our method using MCTS against a variant that randomly
    samples insights from each stage’s insight pool. As shown in Table [3](https://arxiv.org/html/2410.17238v1#S4.T3
    "Table 3 ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning"), the MCTS version achieves a higher
    average normalized score across datasets and a better overall ranking compared
    to the random sampling approach. Moreover, even the random sampling variant of
    our method outperforms Data Interpreter, the base experimenter. This suggests
    the presence of an appropriate search space and an experiment agenda is vital
    for improving a machine learning agent. Our insight proposer generates relevant
    and useful insights, facilitating such improvement, regardless of the selection
    method.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估蒙特卡洛树搜索（MCTS）在改进解空间搜索过程中的有效性，我们进行了一个消融研究。在这项研究中，我们比较了使用MCTS的方法与一个随机从每个阶段的见解池中抽取见解的变体的性能。如表[3](https://arxiv.org/html/2410.17238v1#S4.T3
    "Table 3 ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning")所示，MCTS版本在数据集上的平均标准化得分更高，并且整体排名优于随机抽样方法。此外，即使是我们方法的随机抽样变体，也优于数据解释器，即基础实验者。这表明，合适的搜索空间和实验议程对于提升机器学习代理的表现至关重要。我们的见解生成器能够生成相关且有用的见解，促进这种改进，无论选择方法如何。'
- en: Number of Rollouts
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 回滚次数
- en: 'Figure [5](https://arxiv.org/html/2410.17238v1#S4.F5 "Figure 5 ‣ Number of
    Rollouts ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning") illustrates that the average performance
    of \methodname improves as the number of permitted rollouts increases. The trend
    demonstrates the strong scalability of \methodname, as it efficiently leverages
    additional opportunities to explore the search space, improving the normalized
    score by 4.7% after 10 rollouts and 6.4% after 20, compared to the initial rollout.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '图[5](https://arxiv.org/html/2410.17238v1#S4.F5 "Figure 5 ‣ Number of Rollouts
    ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ \methodname: Tree-Search Enhanced LLM Agents
    for Automated Machine Learning")展示了\methodname的平均性能随着允许的回滚次数增加而提高。这个趋势表明，\methodname具有强大的可扩展性，因为它有效利用了额外的机会来探索搜索空间，在进行10次回滚后，标准化得分提高了4.7%，在进行20次回滚后，得分提高了6.4%，相比初始回滚。'
- en: '![Refer to caption](img/bb5d7a16e0b5986c35fca5d5c2235956.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/bb5d7a16e0b5986c35fca5d5c2235956.png)'
- en: 'Figure 4: The average performance of \methodname on six selected datasets with
    an increasing number of rollouts.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：\methodname在六个选定数据集上，随着回滚次数增加的平均性能表现。
- en: '![Refer to caption](img/5658d2853795fe6ab8027030b4c2e736.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/5658d2853795fe6ab8027030b4c2e736.png)'
- en: 'Figure 5: Comparison of Normalized Scores between different base LLMs on six
    selected datasets.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：不同基础LLM在六个选定数据集上的标准化得分比较。
- en: LLM Adaptability
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: LLM适应性
- en: To evaluate the robustness of our framework, we conduct experiments using different
    Large Language Models (LLMs). Specifically, we compare the performance of \methodname
    with Claude-3.5-Sonnet (Anthropic, [2024](https://arxiv.org/html/2410.17238v1#bib.bib1))
    and GPT-4o (OpenAI, [2024](https://arxiv.org/html/2410.17238v1#bib.bib27)) against
    DeepSeek V2.5 which we primarily use for evaluation. This comparison enables us
    to assess how the choice of LLM affects the overall effectiveness of our approach.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们框架的稳健性，我们使用不同的大型语言模型（LLMs）进行实验。具体来说，我们将\methodname与Claude-3.5-Sonnet（Anthropic，[2024](https://arxiv.org/html/2410.17238v1#bib.bib1)）和GPT-4o（OpenAI，[2024](https://arxiv.org/html/2410.17238v1#bib.bib27)）与DeepSeek
    V2.5进行性能比较，后者是我们主要用于评估的模型。这个比较使我们能够评估LLM的选择如何影响我们方法的整体效果。
- en: 'As Figure [5](https://arxiv.org/html/2410.17238v1#S4.F5 "Figure 5 ‣ Number
    of Rollouts ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning") shown, \methodname delivers similar
    results across different LLMs, indicating its flexibility with various models
    depending on user preference and availability. We also report the numeric results
    in Appendix [C.2](https://arxiv.org/html/2410.17238v1#A3.SS2 "C.2 Performance
    using different LLMs ‣ Appendix C Results ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning").'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[5](https://arxiv.org/html/2410.17238v1#S4.F5 "图5 ‣ 推理次数 ‣ 4.3 消融研究 ‣ 4 实验
    ‣ \methodname: 树搜索增强的LLM代理用于自动化机器学习")所示，\methodname 在不同的LLM之间表现出相似的结果，表明它具有根据用户偏好和可用性灵活适应不同模型的能力。我们还在附录[C.2](https://arxiv.org/html/2410.17238v1#A3.SS2
    "C.2 使用不同LLM的性能 ‣ 附录C 结果 ‣ \methodname: 树搜索增强的LLM代理用于自动化机器学习")中报告了数值结果。'
- en: 5 Conclusion
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this paper, we introduced \methodname, a novel framework that integrates
    LLM-based agents with Monte Carlo Tree Search (MCTS) to automate machine learning
    workflows. Our experimental results, conducted on 20 machine learning datasets,
    demonstrate \methodname’s effectiveness and highlight its distinct advantages
    over both traditional AutoML frameworks and existing LLM-based approaches. The
    proposed methodology is not limited to machine learning but could be adapted to
    a wide range of sequential decision-making problems, provided they can be represented
    as tree structures with scalar rewards derived from their leaf nodes. Looking
    ahead, future work could explore extending this framework to other domains, including
    software engineering, scientific discovery, game playing, and robotics. Furthermore,
    improving the efficiency and scalability of the tree search process for larger
    solution spaces remains an important area for investigation. Another promising
    direction is developing techniques to provide interpretable explanations of the
    search process and solution rationale, enhancing the transparency and trustworthiness
    of the system. \methodname represents a significant advancement in automated machine
    learning, demonstrating the potential of combining traditional search algorithms
    with the flexibility of LLMs.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了\methodname，一种将基于LLM的代理与蒙特卡洛树搜索（MCTS）集成以自动化机器学习工作流的创新框架。我们在20个机器学习数据集上进行的实验结果证明了\methodname的有效性，并突出了其相对于传统AutoML框架和现有LLM方法的独特优势。该方法不仅限于机器学习，还可以适应广泛的顺序决策问题，只要它们能够表示为具有从叶节点推导出的标量奖励的树形结构。展望未来，后续工作可以探索将此框架扩展到其他领域，包括软件工程、科学发现、游戏和机器人技术。此外，提升树搜索过程的效率和可扩展性，以应对更大的解空间，仍然是一个重要的研究方向。另一个有前景的方向是开发技术，为搜索过程和解决方案理由提供可解释的解释，从而增强系统的透明性和可信度。\methodname代表了自动化机器学习的重要进展，展示了将传统搜索算法与LLM的灵活性结合的潜力。
- en: References
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Anthropic (2024) Anthropic. Introducing Claude 3.5 Sonnet — anthropic.com. [https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet),
    2024.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthropic (2024) Anthropic. 介绍Claude 3.5 Sonnet — anthropic.com. [https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet),
    2024.
- en: 'Best et al. (2019) Graeme Best, Oliver M Cliff, Timothy Patten, Ramgopal R
    Mettu, and Robert Fitch. Dec-mcts: Decentralized planning for multi-robot active
    perception. *The International Journal of Robotics Research*, 38(2-3):316–337,
    2019. doi: 10.1177/0278364918755924.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Best等（2019）Graeme Best, Oliver M Cliff, Timothy Patten, Ramgopal R Mettu, 和
    Robert Fitch. Dec-mcts: 多机器人主动感知的去中心化规划. *国际机器人研究期刊*, 38(2-3):316–337, 2019. doi:
    10.1177/0278364918755924.'
- en: 'Chi et al. (2024) Yizhou Chi, Kevin Yang, and Dan Klein. Thoughtsculpt: Reasoning
    with intermediate revision and search, 2024.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chi等（2024）Yizhou Chi, Kevin Yang, 和 Dan Klein. Thoughtsculpt: 通过中间修订和搜索进行推理,
    2024.'
- en: 'Clary et al. (2018) Patrick Clary, Pedro Morais, Alan Fern, and Jonathan Hurst.
    Monte-carlo planning for agile legged locomotion. *Proceedings of the International
    Conference on Automated Planning and Scheduling*, 28(1):446–450, Jun. 2018. doi:
    10.1609/icaps.v28i1.13933.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Clary等（2018）Patrick Clary, Pedro Morais, Alan Fern, 和 Jonathan Hurst. 蒙特卡洛规划用于灵活的四足运动.
    *自动化规划与调度国际会议论文集*, 28(1):446–450, 2018年6月. doi: 10.1609/icaps.v28i1.13933.'
- en: Coulom (2007) Rémi Coulom. Efficient selectivity and backup operators in monte-carlo
    tree search. In H. Jaap van den Herik, Paolo Ciancarini, and H. H. L. M. (Jeroen)
    Donkers (eds.), *Computers and Games*, pp.  72–83, Berlin, Heidelberg, 2007\.
    Springer Berlin Heidelberg. ISBN 978-3-540-75538-8.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Coulom (2007) Rémi Coulom. 《蒙特卡洛树搜索中的高效选择性和备份操作符》。收录于 H. Jaap van den Herik,
    Paolo Ciancarini, 和 H. H. L. M. (Jeroen) Donkers（编辑），*Computers and Games*，第72-83页，柏林，海德堡，2007年。Springer
    Berlin Heidelberg。ISBN 978-3-540-75538-8。
- en: 'DeepSeek-AI (2024) DeepSeek-AI. Deepseek-v2: A strong, economical, and efficient
    mixture-of-experts language model, 2024.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepSeek-AI (2024) DeepSeek-AI. 《Deepseek-v2：一种强大、经济且高效的专家混合语言模型》，2024年。
- en: Dwaracherla et al. (2024) Vikranth Dwaracherla, Seyed Mohammad Asghari, Botao
    Hao, and Benjamin Van Roy. Efficient exploration for llms, 2024.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dwaracherla et al. (2024) Vikranth Dwaracherla, Seyed Mohammad Asghari, Botao
    Hao, 和 Benjamin Van Roy. 《大型语言模型的高效探索》，2024年。
- en: 'Erickson et al. (2020) Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang
    Zhang, Pedro Larroy, Mu Li, and Alexander Smola. Autogluon-tabular: Robust and
    accurate automl for structured data, 2020.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Erickson et al. (2020) Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang
    Zhang, Pedro Larroy, Mu Li, 和 Alexander Smola. 《Autogluon-tabular：结构化数据的强大而精确的自动化机器学习》，2020年。
- en: Feng et al. (2023) Xidong Feng, Ziyu Wan, Muning Wen, Ying Wen, Weinan Zhang,
    and Jun Wang. Alphazero-like tree-search can guide large language model decoding
    and training, 2023.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng et al. (2023) Xidong Feng, Ziyu Wan, Muning Wen, Ying Wen, Weinan Zhang,
    和 Jun Wang. 《类似Alphazero的树搜索可以指导大型语言模型的解码与训练》，2023年。
- en: Feurer et al. (2015) Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost
    Springenberg, Manuel Blum, and Frank Hutter. Efficient and robust automated machine
    learning. In *Advances in Neural Information Processing Systems 28 (2015)*, pp. 
    2962–2970, 2015.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feurer et al. (2015) Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost
    Springenberg, Manuel Blum, 和 Frank Hutter. 《高效且稳健的自动化机器学习》。收录于 *Advances in Neural
    Information Processing Systems 28 (2015)*，第2962-2970页，2015年。
- en: 'Feurer et al. (2020) Matthias Feurer, Katharina Eggensperger, Stefan Falkner,
    Marius Lindauer, and Frank Hutter. Auto-sklearn 2.0: Hands-free automl via meta-learning,
    2020.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feurer et al. (2020) Matthias Feurer, Katharina Eggensperger, Stefan Falkner,
    Marius Lindauer, 和 Frank Hutter. 《Auto-sklearn 2.0：通过元学习实现免手动的自动化机器学习》，2020年。
- en: 'Gijsbers et al. (2024) Pieter Gijsbers, Marcos L. P. Bueno, Stefan Coors, Erin
    LeDell, Sébastien Poirier, Janek Thomas, Bernd Bischl, and Joaquin Vanschoren.
    Amlb: an automl benchmark. *Journal of Machine Learning Research*, 25(101):1–65,
    2024.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gijsbers et al. (2024) Pieter Gijsbers, Marcos L. P. Bueno, Stefan Coors, Erin
    LeDell, Sébastien Poirier, Janek Thomas, Bernd Bischl, 和 Joaquin Vanschoren. 《Amlb：一个自动化机器学习基准》。*Journal
    of Machine Learning Research*，25(101)：1-65，2024年。
- en: 'Guo et al. (2024) Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, Yi Chang,
    and Jun Wang. Ds-agent: Automated data science by empowering large language models
    with case-based reasoning, 2024.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2024) Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, Yi Chang,
    和 Jun Wang. 《Ds-agent：通过赋能大型语言模型进行基于案例的推理实现自动化数据科学》，2024年。
- en: 'Hollmann et al. (2024) Noah Hollmann, Samuel Müller, and Frank Hutter. Large
    language models for automated data science: Introducing caafe for context-aware
    automated feature engineering, 2024.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hollmann et al. (2024) Noah Hollmann, Samuel Müller, 和 Frank Hutter. 《大型语言模型在自动化数据科学中的应用：引入针对上下文感知的自动特征工程的caafe》，2024年。
- en: 'Hong et al. (2024a) Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao
    Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Li Zhang, Lingyao Zhang,
    Min Yang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Wenyi Wang, Xiangru
    Tang, Xiangtao Lu, Xiawu Zheng, Xinbing Liang, Yaying Fei, Yuheng Cheng, Zongze
    Xu, and Chenglin Wu. Data interpreter: An llm agent for data science, 2024a.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. (2024a) Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao
    Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Li Zhang, Lingyao Zhang,
    Min Yang, Mingchen Zhuge, Taicheng Guo, Tuo Zhou, Wei Tao, Wenyi Wang, Xiangru
    Tang, Xiangtao Lu, Xiawu Zheng, Xinbing Liang, Yaying Fei, Yuheng Cheng, Zongze
    Xu, 和 Chenglin Wu. 《数据解释器：一个面向数据科学的LLM代理》，2024a年。
- en: 'Hong et al. (2024b) Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng,
    Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan
    Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber.
    MetaGPT: Meta programming for a multi-agent collaborative framework. In *The Twelfth
    International Conference on Learning Representations*, 2024b.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong et al. (2024b) Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng,
    Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan
    Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, 和 Jürgen Schmidhuber.
    《MetaGPT：用于多智能体协作框架的元编程》。收录于 *The Twelfth International Conference on Learning
    Representations*，2024b年。
- en: 'Hui & Tu (2024) Wenyang Hui and Kewei Tu. Rot: Enhancing large language models
    with reflection on search trees, 2024.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hui & Tu (2024) Wenyang Hui 和 Kewei Tu. 《Rot：通过反思搜索树增强大型语言模型》，2024年。
- en: 'Jin et al. (2019) Haifeng Jin, Qingquan Song, and Xia Hu. Auto-keras: An efficient
    neural architecture search system. In *Proceedings of the 25th ACM SIGKDD international
    conference on knowledge discovery & data mining*, pp.  1946–1956, 2019.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin et al. (2019) Haifeng Jin、Qingquan Song 和 Xia Hu. Auto-keras：一种高效的神经架构搜索系统.
    见 *第25届ACM SIGKDD国际知识发现与数据挖掘会议论文集*，第1946–1956页，2019年。
- en: 'Jin et al. (2023) Haifeng Jin, François Chollet, Qingquan Song, and Xia Hu.
    Autokeras: An automl library for deep learning. *Journal of machine Learning research*,
    24(6):1–6, 2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin et al. (2023) Haifeng Jin、François Chollet、Qingquan Song 和 Xia Hu. Autokeras：一个深度学习的自动化机器学习库。*机器学习研究期刊*，24(6):1–6，2023年。
- en: 'Kocsis & Szepesvári (2006) Levente Kocsis and Csaba Szepesvári. Bandit based
    monte-carlo planning. In Johannes Fürnkranz, Tobias Scheffer, and Myra Spiliopoulou
    (eds.), *Machine Learning: ECML 2006*, pp.  282–293, Berlin, Heidelberg, 2006\.
    Springer Berlin Heidelberg. ISBN 978-3-540-46056-5.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kocsis & Szepesvári (2006) Levente Kocsis 和 Csaba Szepesvári. 基于强盗算法的蒙特卡罗规划.
    见 Johannes Fürnkranz、Tobias Scheffer 和 Myra Spiliopoulou（编辑），*机器学习：ECML 2006*，第282–293页，柏林，海德堡，2006年。施普林格柏林海德堡出版社。ISBN
    978-3-540-46056-5。
- en: Krishnamurthy et al. (2024) Akshay Krishnamurthy, Keegan Harris, Dylan J. Foster,
    Cyril Zhang, and Aleksandrs Slivkins. Can large language models explore in-context?,
    2024.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krishnamurthy et al. (2024) Akshay Krishnamurthy、Keegan Harris、Dylan J. Foster、Cyril
    Zhang 和 Aleksandrs Slivkins. 大型语言模型能在上下文中进行探索吗？，2024年。
- en: 'LeDell & Poirier (2020) Erin LeDell and Sebastien Poirier. H2O AutoML: Scalable
    automatic machine learning. *7th ICML Workshop on Automated Machine Learning (AutoML)*,
    July 2020.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeDell & Poirier (2020) Erin LeDell 和 Sebastien Poirier. H2O AutoML：可扩展的自动化机器学习。*第7届ICML自动化机器学习（AutoML）研讨会*，2020年7月。
- en: 'Li et al. (2024) Dawei Li, Zhen Tan, and Huan Liu. Exploring large language
    models for feature selection: A data-centric perspective, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2024) Dawei Li、Zhen Tan 和 Huan Liu. 从数据中心视角探索大型语言模型进行特征选择，2024年。
- en: Liu et al. (2024) Siyi Liu, Chen Gao, and Yong Li. Large language model agent
    for hyper-parameter optimization. *arXiv preprint arXiv:2402.01881*, 2024.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2024) Siyi Liu、Chen Gao 和 Yong Li. 大型语言模型代理用于超参数优化。*arXiv 预印本 arXiv:2402.01881*，2024年。
- en: 'Luo et al. (2024) Daqin Luo, Chengjian Feng, Yuxuan Nong, and Yiqing Shen.
    Autom3l: An automated multimodal machine learning framework with large language
    models. *arXiv preprint arXiv:2408.00665*, 2024.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo et al. (2024) Daqin Luo、Chengjian Feng、Yuxuan Nong 和 Yiqing Shen. Autom3l：一种自动化的多模态机器学习框架，结合大型语言模型。*arXiv
    预印本 arXiv:2408.00665*，2024年。
- en: 'Olson & Moore (2016) Randal S Olson and Jason H Moore. Tpot: A tree-based pipeline
    optimization tool for automating machine learning. In *Workshop on automatic machine
    learning*, pp.  66–74\. PMLR, 2016.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olson & Moore (2016) Randal S Olson 和 Jason H Moore. Tpot：一种基于树的管道优化工具，用于自动化机器学习。见
    *自动化机器学习研讨会*，第66–74页，PMLR，2016年。
- en: OpenAI (2024) OpenAI. Hello GPT-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/),
    2024.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2024) OpenAI. 你好 GPT-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)，2024年。
- en: 'Schmidt et al. (2024) Dominik Schmidt, Yuxiang Wu, and Zhengyao Jiang. Aide:
    Human-level performance in data science competitions, 2024. URL [https://www.weco.ai/blog/technical-report](https://www.weco.ai/blog/technical-report).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmidt et al. (2024) Dominik Schmidt、Yuxiang Wu 和 Zhengyao Jiang. Aide：数据科学竞赛中的人类水平表现，2024年。网址
    [https://www.weco.ai/blog/technical-report](https://www.weco.ai/blog/technical-report)。
- en: 'Segler et al. (2018) Marwin Segler, Mike Preuss, and Mark Waller. Planning
    chemical syntheses with deep neural networks and symbolic ai. *Nature*, 555:604–610,
    03 2018. doi: 10.1038/nature25978.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Segler et al. (2018) Marwin Segler、Mike Preuss 和 Mark Waller. 利用深度神经网络和符号 AI
    规划化学合成。*自然*，555:604–610，2018年3月。doi: 10.1038/nature25978。'
- en: Silver et al. (2016) David Silver, Aja Huang, Chris J. Maddison, Arthur Guez,
    L. Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
    Vedavyas Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham,
    Nal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap, Madeleine Leach, Koray
    Kavukcuoglu, Thore Graepel, and Demis Hassabis. Mastering the game of go with
    deep neural networks and tree search. *Nature*, 2016.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silver et al. (2016) David Silver、Aja Huang、Chris J. Maddison、Arthur Guez、L.
    Sifre、George van den Driessche、Julian Schrittwieser、Ioannis Antonoglou、Vedavyas
    Panneershelvam、Marc Lanctot、Sander Dieleman、Dominik Grewe、John Nham、Nal Kalchbrenner、Ilya
    Sutskever、Timothy P. Lillicrap、Madeleine Leach、Koray Kavukcuoglu、Thore Graepel
    和 Demis Hassabis. 利用深度神经网络和树搜索掌握围棋游戏。*自然*，2016年。
- en: Silver et al. (2017) David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis
    Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas baker, Matthew Lai, Adrian
    Bolton, Yutian Chen, Timothy P. Lillicrap, Fan Hui, L. Sifre, George van den Driessche,
    Thore Graepel, and Demis Hassabis. Mastering the game of go without human knowledge.
    *Nature*, 2017.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silver等人（2017）David Silver、Julian Schrittwieser、Karen Simonyan、Ioannis Antonoglou、Aja
    Huang、Arthur Guez、Thomas Hubert、Lucas Baker、Matthew Lai、Adrian Bolton、Yutian Chen、Timothy
    P. Lillicrap、Fan Hui、L. Sifre、George van den Driessche、Thore Graepel和Demis Hassabis。没有人类知识的围棋游戏制胜。*自然*，2017年。
- en: Tang et al. (2024a) Hao Tang, Keya Hu, Jin Peng Zhou, Sicheng Zhong, Wei-Long
    Zheng, Xujie Si, and Kevin Ellis. Code repair with llms gives an exploration-exploitation
    tradeoff, 2024a.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang等人（2024a）Hao Tang、Keya Hu、Jin Peng Zhou、Sicheng Zhong、Wei-Long Zheng、Xujie
    Si和Kevin Ellis。使用LLMs进行代码修复提供了探索与开发的权衡，2024a。
- en: 'Tang et al. (2024b) Zhiqiang Tang, Haoyang Fang, Su Zhou, Taojiannan Yang,
    Zihan Zhong, Tony Hu, Katrin Kirchhoff, and George Karypis. Autogluon-multimodal
    (automm): Supercharging multimodal automl with foundation models. *arXiv preprint
    arXiv:2404.16233*, 2024b.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang等人（2024b）Zhiqiang Tang、Haoyang Fang、Su Zhou、Taojiannan Yang、Zihan Zhong、Tony
    Hu、Katrin Kirchhoff和George Karypis。Autogluon-multimodal（automm）：通过基础模型超级增强多模态自动机器学习。*arXiv预印本arXiv:2404.16233*，2024b。
- en: 'Thornton et al. (2013) Chris Thornton, Frank Hutter, Holger H Hoos, and Kevin
    Leyton-Brown. Auto-weka: Combined selection and hyperparameter optimization of
    classification algorithms. In *Proceedings of the 19th ACM SIGKDD international
    conference on Knowledge discovery and data mining*, pp.  847–855, 2013.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thornton等人（2013）Chris Thornton、Frank Hutter、Holger H Hoos和Kevin Leyton-Brown。Auto-weka：分类算法的组合选择与超参数优化。在*第19届ACM
    SIGKDD国际知识发现与数据挖掘会议论文集*，第847-855页，2013年。
- en: 'Wang et al. (2024) Ante Wang, Linfeng Song, Ye Tian, Baolin Peng, Dian Yu,
    Haitao Mi, Jinsong Su, and Dong Yu. Litesearch: Efficacious tree search for llm,
    2024.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2024）Ante Wang、Linfeng Song、Ye Tian、Baolin Peng、Dian Yu、Haitao Mi、Jinsong
    Su和Dong Yu。Litesearch：高效的LLM树搜索，2024。
- en: 'Wang et al. (2021) Chi Wang, Qingyun Wu, Markus Weimer, and Erkang Zhu. Flaml:
    A fast and lightweight automl library. In *MLSys*, 2021.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2021）Chi Wang、Qingyun Wu、Markus Weimer和Erkang Zhu。Flaml：一个快速且轻量级的自动机器学习库。在*MLSys*，2021。
- en: Wu et al. (2015) Feng Wu, Sarvapali D. Ramchurn, Wenchao Jiang, Jeol E. Fischer,
    Tom Rodden, and Nicholas R. Jennings. Agile planning for real-world disaster response.
    In *Proceedings of the 24th International Conference on Artificial Intelligence*,
    IJCAI’15, pp.  132–138\. AAAI Press, 2015. ISBN 9781577357384.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu等人（2015）Feng Wu、Sarvapali D. Ramchurn、Wenchao Jiang、Jeol E. Fischer、Tom Rodden和Nicholas
    R. Jennings。现实灾难响应的敏捷规划。在*第24届国际人工智能会议论文集*，IJCAI’15，第132-138页。AAAI出版社，2015年。ISBN
    9781577357384。
- en: 'Zhang et al. (2024) Lei Zhang, Yuge Zhang, Kan Ren, Dongsheng Li, and Yuqing
    Yang. Mlcopilot: Unleashing the power of large language models in solving machine
    learning tasks, 2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人（2024）Lei Zhang、Yuge Zhang、Kan Ren、Dongsheng Li和Yuqing Yang。Mlcopilot：释放大型语言模型在解决机器学习任务中的强大能力，2024。
- en: Zhou et al. (2024) Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang,
    and Yu-Xiong Wang. Language agent tree search unifies reasoning acting and planning
    in language models, 2024.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等人（2024）Andy Zhou、Kai Yan、Michal Shlapentokh-Rothman、Haohan Wang和Yu-Xiong
    Wang。语言代理树搜索统一了语言模型中的推理、行为和规划，2024。
- en: Appendix A Datasets
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 数据集
- en: 'Table [4](https://arxiv.org/html/2410.17238v1#A1.T4 "Table 4 ‣ Appendix A Datasets
    ‣ \methodname: Tree-Search Enhanced LLM Agents for Automated Machine Learning")
    outlines the detailed information of the datasets used for evaluation.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '表格[4](https://arxiv.org/html/2410.17238v1#A1.T4 "表4 ‣ 附录A 数据集 ‣ \methodname:
    树搜索增强LLM代理用于自动化机器学习")概述了用于评估的数据集的详细信息。'
- en: '| Dataset name | # Features | # Rows | # Classes | Task Type | Metric | Source
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 数据集名称 | 特征数 | 行数 | 类别数 | 任务类型 | 评估指标 | 数据来源 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| boston | 14 | 506 | N/A | Regression | RMSE | OpenML (Dataset ID: 531) |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| boston | 14 | 506 | N/A | 回归 | RMSE | OpenML（数据集ID：531） |'
- en: '| colleges | 48 | 7063 | N/A | Regression | RMSE | OpenML (Dataset ID: 42727)
    |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| colleges | 48 | 7063 | N/A | 回归 | RMSE | OpenML（数据集ID：42727） |'
- en: '| concrete-strength | 9 | 4866 | N/A | Regression | RMSE | Kaggle (playground-series-s3e9)
    |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| concrete-strength | 9 | 4866 | N/A | 回归 | RMSE | Kaggle（playground-series-s3e9）
    |'
- en: '| diamonds | 10 | 53940 | N/A | Regression | RMSE | OpenML (Dataset ID: 42225)
    |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| diamonds | 10 | 53940 | N/A | 回归 | RMSE | OpenML（数据集ID：42225） |'
- en: '| house-prices | 81 | 1460 | N/A | Regression | RMSE | Kaggle (house-prices-advanced-regression-techniques)
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| house-prices | 81 | 1460 | N/A | 回归 | RMSE | Kaggle（house-prices-advanced-regression-techniques）
    |'
- en: '| Moneyball | 15 | 1232 | N/A | Regression | RMSE | OpenML (Dataset ID: 41021)
    |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Moneyball | 15 | 1232 | N/A | 回归 | RMSE | OpenML（数据集ID：41021） |'
- en: '| SAT11-HAND-runtime-regression | 118 | 4440 | N/A | Regression | RMSE | OpenML
    (Dataset ID: 41980) |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| SAT11-HAND-runtime-regression | 118 | 4440 | 不适用 | 回归 | RMSE | OpenML（数据集ID：41980）
    |'
- en: '| credit-g | 21 | 1000 | 2 | Classification | F1 | OpenML (Dataset ID: 31)
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| credit-g | 21 | 1000 | 2 | 分类 | F1 | OpenML（数据集ID：31） |'
- en: '| Click_prediction_small | 12 | 39948 | 2 | Classification | F1 | OpenML (Dataset
    ID: 42733) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Click_prediction_small | 12 | 39948 | 2 | 分类 | F1 | OpenML（数据集ID：42733） |'
- en: '| icr | 58 | 617 | 2 | Classification | F1 | Kaggle (icr-identify-age-related-conditions)
    |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| icr | 58 | 617 | 2 | 分类 | F1 | Kaggle（icr-identify-age-related-conditions）
    |'
- en: '| jasmine | 145 | 2984 | 2 | Classification | F1 | OpenML (Dataset ID: 41143)
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| jasmine | 145 | 2984 | 2 | 分类 | F1 | OpenML（数据集ID：41143） |'
- en: '| kc1 | 21 | 2109 | 2 | Classification | F1 | OpenML (Dataset ID: 1067) |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| kc1 | 21 | 2109 | 2 | 分类 | F1 | OpenML（数据集ID：1067） |'
- en: '| kick | 33 | 72983 | 2 | Classification | F1 | OpenML (Dataset ID: 41162)
    |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| kick | 33 | 72983 | 2 | 分类 | F1 | OpenML（数据集ID：41162） |'
- en: '| smoker-status | 23 | 143330 | 2 | Classification | F1 | Kaggle (playground-series-s3e24)
    |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| smoker-status | 23 | 143330 | 2 | 分类 | F1 | Kaggle（playground-series-s3e24）
    |'
- en: '| software-defects | 22 | 91586 | 2 | Classification | F1 | Kaggle (playground-series-s3e23)
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| software-defects | 22 | 91586 | 2 | 分类 | F1 | Kaggle（playground-series-s3e23）
    |'
- en: '| titanic | 12 | 891 | 2 | Classification | F1 | Kaggle (titanic) |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| titanic | 12 | 891 | 2 | 分类 | F1 | Kaggle（titanic） |'
- en: '| GesturePhaseSegmentationProcessed | 33 | 9873 | 5 | Multiclass | F1-weighted
    | OpenML (Dataset ID: 4538) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| GesturePhaseSegmentationProcessed | 33 | 9873 | 5 | 多分类 | F1加权 | OpenML（数据集ID：4538）
    |'
- en: '| mfeat-factors | 217 | 2000 | 10 | Multiclass | F1-weighted | OpenML (Dataset
    ID: 12) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| mfeat-factors | 217 | 2000 | 10 | 多分类 | F1加权 | OpenML（数据集ID：12） |'
- en: '| segment | 20 | 2310 | 7 | Multiclass | F1-weighted | OpenML (Dataset ID:
    40984) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| segment | 20 | 2310 | 7 | 多分类 | F1加权 | OpenML（数据集ID：40984） |'
- en: '| wine-quality-white | 12 | 4898 | 7 | Multiclass | F1-weighted | OpenML (Dataset
    ID: 40498) |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| wine-quality-white | 12 | 4898 | 7 | 多分类 | F1加权 | OpenML（数据集ID：40498） |'
- en: 'Table 4: Summary of the machine learning datasets used in the experiments.
    OpenML datasets can be accessed using their respective dataset IDs. The Kaggle
    datasets are available at https://www.kaggle.com/competitions/{source}.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：实验中使用的机器学习数据集汇总。可以使用各自的数据集ID访问OpenML数据集。Kaggle数据集可通过 https://www.kaggle.com/competitions/{source}
    获取。
- en: Appendix B Prompts
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 提示
- en: B.1 Task Prompt
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 任务提示
- en: All LLM-based methods start by receiving the same base requirement prompt at
    the beginning of the task. The prompt specifies the dataset’s name, the target
    label column, the evaluation metric to be used, and the dataset’s file path. Furthermore,
    the prompt include a path to a text file containing the dataset’s metadata.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 所有基于LLM的方法都从任务开始时接收相同的基本要求提示。提示中指定了数据集的名称、目标标签列、评估指标以及数据集的文件路径。此外，提示还包括指向包含数据集元数据的文本文件的路径。
- en: '[⬇](data:text/plain;base64,VEFTS19QUk9NUFQgPSAiIiIKIyBVc2VyIHJlcXVpcmVtZW50ClRoaXMgaXMgYSB7ZGF0YXNldG5hbWV9IGRhdGFzZXQuCllvdXIgZ29hbCBpcyB0byBwcmVkaWN0IHRoZSB0YXJnZXQgY29sdW1uIGB7dGFyZ2V0X2NvbH1gLgpQZXJmb3JtIGRhdGEgYW5hbHlzaXMsIGRhdGEgcHJlcHJvY2Vzc2luZywgZmVhdHVyZSBlbmdpbmVlcmluZywgYW5kIG1vZGVsaW5nIHRvIHByZWRpY3QgdGhlIHRhcmdldC4gUmVwb3J0IHttZXRyaWN9IG9uIHRoZSBldmFsIGRhdGEuIERvIG5vdCBwbG90IG9yIG1ha2UgYW55IHZpc3VhbGl6YXRpb25zLgoKIyBEYXRhIGRpcgp0cmFpbiBzZXQgKHdpdGggbGFiZWxzKToge3RyYWluX3BhdGh9CmRldiBzZXQgKHdpdGggbGFiZWxzKToge2Rldl9wYXRofQp0ZXN0IHNldCAod2l0aG91dCBsYWJlbHMpOiB7dGVzdF9wYXRofQpkYXRhc2V0IGRlc2NyaXB0aW9uOiB7ZGF0YV9pbmZvX3BhdGh9CihEdXJpbmcgRURBLCB5b3UgY2FuIHVzZSB0aGlzIGZpbGUKdG8gZ2V0IGFkZGl0aW9uYWwgaW5mb3JtYXRpb24gYWJvdXQgdGhlIGRhdGFzZXQpCiIiIg==)1TASK_PROMPT  =  """2#␣User␣requirement3This␣is␣a␣{datasetname}␣dataset.4Your␣goal␣is␣to␣predict␣the␣target␣column␣‘{target_col}‘.5Perform␣data␣analysis,␣data␣preprocessing,␣feature␣engineering,␣and␣modeling␣to␣predict␣the␣target.␣Report␣{metric}␣on␣the␣eval␣data.␣Do␣not␣plot␣or␣make␣any␣visualizations.67#␣Data␣dir8train␣set␣(with␣labels):␣{train_path}9dev␣set␣(with␣labels):␣{dev_path}10test␣set␣(without␣labels):␣{test_path}11dataset␣description:␣{data_info_path}12(During␣EDA,␣you␣can␣use␣this␣file13to␣get␣additional␣information␣about␣the␣dataset)14"""'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,VEFTS19QUk9NUFQgPSAiIiIKIyBVc2VyIHJlcXVpcmVtZW50ClRoaXMgaXMgYSB7ZGF0YXNldG5hbWV9IGRhdGFzZXQuCllvdXIgZ29hbCBpcyB0byBwcmVkaWN0IHRoZSB0YXJnZXQgY29sdW1uIGB7dGFyZ2V0X2NvbH1gLgpQZXJmb3JtIGRhdGEgYW5hbHlzaXMsIGRhdGEgcHJlcHJvY2Vzc2luZywgZmVhdHVyZSBlbmdpbmVlcmluZywgYW5kIG1vZGVsaW5nIHRvIHByZWRpY3QgdGhlIHRhcmdldC4gUmVwb3J0IHttZXRyaWN9IG9uIHRoZSBldmFsIGRhdGEuIERvIG5vdCBwbG90IG9yIG1ha2UgYW55IHZpc3VhbGl6YXRpb25zLgoKIyBEYXRhIGRpcgp0cmFpbiBzZXQgKHdpdGggbGFiZWxzKToge3RyYWluX3BhdGh9CmRldiBzZXQgKHdpdGggbGFiZWxzKToge2Rldl9wYXRofQp0ZXN0IHNldCAod2l0aG91dCBsYWJlbHMpOiB7dGVzdF9wYXRofQpkYXRhc2V0IGRlc2NyaXB0aW9uOiB7ZGF0YV9pbmZvX3BhdGh9CihEdXJpbmcgRURBLCB5b3UgY2FuIHVzZSB0aGlzIGZpbGUKdG8gZ2V0IGFkZGl0aW9uYWwgaW5mb3JtYXRpb24gYWJvdXQgdGhlIGRhdGFzZXQpCiIiIg==)1TASK_PROMPT  =  """2#␣用户␣需求3这是␣一个␣{datasetname}␣数据集。4您的␣目标␣是␣预测␣目标␣列‘{target_col}’。5进行␣数据␣分析、␣数据␣预处理、␣特征␣工程和␣建模␣以␣预测␣目标。␣报告␣{metric}␣在␣评估␣数据上的结果。␣不要␣绘制␣图表␣或␣进行␣任何␣可视化。67#␣数据␣目录8训练␣集␣(含␣标签)：␣{train_path}9验证␣集␣(含␣标签)：␣{dev_path}10测试␣集␣(无␣标签)：␣{test_path}11数据集␣描述：␣{data_info_path}12(在␣EDA阶段，␣您␣可以␣使用␣此␣文件13获取␣关于␣数据集的␣更多␣信息)14"""'
- en: Since AIDE automatically splits the training data into a new train set and a
    validation set, we combine the original train and validation sets and provide
    them as input to AIDE. We set k_fold_validation to 1 in its configuration file
    to enforce a single train-val split for closer alignment with our setup. In both
    setups, the frameworks have access to the labels for both the train and validation
    sets.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 AIDE 会自动将训练数据拆分为新的训练集和验证集，我们将原始的训练集和验证集合并，并将其作为输入提供给 AIDE。在配置文件中，我们将 k_fold_validation
    设置为 1，以强制进行单次训练-验证集划分，以便与我们的设置更好地对齐。在这两种设置中，框架都可以访问训练集和验证集的标签。
- en: B.2 Instruction Prompt
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 指令提示
- en: The instruction prompt would direct the framework to save the final prediction
    file for evaluation.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 指令提示将引导框架保存最终的预测文件以进行评估。
- en: '[⬇](data:text/plain;base64,RElfSU5TVFJVQ1RJT04gPSAiIiIKIyMgQXR0ZW50aW9uCjEuIFBsZWFzZSBkbyBub3QgbGVhayB0aGUgdGFyZ2V0IGxhYmVsIGluIGFueSBmb3JtIGR1cmluZyB0cmFpbmluZy4KMi4gVGVzdCBzZXQgZG9lcyBub3QgaGF2ZSB0aGUgdGFyZ2V0IGNvbHVtbi4KMy4gV2hlbiBjb25kdWN0aW5nIGRhdGEgZXhwbG9yYXRpb24gb3IgYW5hbHlzaXMsIHByaW50IG91dCB0aGUgcmVzdWx0cyBvZiB5b3VyIGZpbmRpbmdzLgo0LiBZb3Ugc2hvdWxkIHBlcmZvcm0gdHJhbnNmb3JtYXRpb25zIG9uIHRyYWluLCBkZXYsIGFuZCB0ZXN0IHNldHMgYXQgdGhlIHNhbWUgdGltZSAoaXQncyBhIGdvb2QgaWRlYSB0byBkZWZpbmUgZnVuY3Rpb25zIGZvciB0aGlzIGFuZCBhdm9pZCBjb2RlIHJlcGV0aXRpb24pLgo1LiBXaGVuIHNjYWxpbmcgb3IgdHJhbnNmb3JtaW5nIGZlYXR1cmVzLCBtYWtlIHN1cmUgdGhlIHRhcmdldCBjb2x1bW4gaXMgbm90IGluY2x1ZGVkLgo2LiBZb3UgY291bGQgdXRpbGl6ZSBkZXYgc2V0IHRvIHZhbGlkYXRlIGFuZCBpbXByb3ZlIG1vZGVsIHRyYWluaW5nLiB7c3BlY2lhbF9pbnN0cnVjdGlvbn0KCiMjIFNhdmluZyBEZXYgYW5kIFRlc3QgUHJlZGljdGlvbnMKMS4gU2F2ZSB0aGUgcHJlZGljdGlvbiByZXN1bHRzIG9mIEJPVEggdGhlIGRldiBzZXQgYW5kIHRlc3Qgc2V0IGluIGBkZXZfcHJlZGljdGlvbnMuY3N2YCBhbmQgYHRlc3RfcHJlZGljdGlvbnMuY3N2YCByZXNwZWN0aXZlbHkgaW4gdGhlIG91dHB1dCBkaXJlY3RvcnkuCi0gQm90aCBmaWxlcyBzaG91bGQgY29udGFpbiBhIHNpbmdsZSBjb2x1bW4gbmFtZWQgYHRhcmdldGAgd2l0aCB0aGUgcHJlZGljdGVkIHZhbHVlcy4KMi4gTWFrZSBzdXJlIHRoZSBwcmVkaWN0aW9uIHJlc3VsdHMgYXJlIGluIHRoZSBzYW1lIGZvcm1hdCBhcyB0aGUgdGFyZ2V0IGNvbHVtbiBpbiB0aGUgdHJhaW5pbmcgc2V0LgotIEZvciBpbnN0YW5jZSwgaWYgdGhlIHRhcmdldCBjb2x1bW4gaXMgY2F0ZWdvcmljYWwsIHRoZSBwcmVkaWN0aW9uIHJlc3VsdHMgc2hvdWxkIGJlIGNhdGVnb3JpY2FsIGFzIHdlbGwuCgojIyBPdXRwdXQgUGVyZm9ybWFuY2UKUHJpbnQgdGhlIHRyYWluIGFuZCBkZXYgc2V0IHBlcmZvcm1hbmNlIGluIHRoZSBsYXN0IHN0ZXAuCgojIE91dHB1dCBkaXIKe291dHB1dF9kaXJ9CiIiIg==)1DI_INSTRUCTION  =  """2##␣Attention31.␣Please␣do␣not␣leak␣the␣target␣label␣in␣any␣form␣during␣training.42.␣Test␣set␣does␣not␣have␣the␣target␣column.53.␣When␣conducting␣data␣exploration␣or␣analysis,␣print␣out␣the␣results␣of␣your␣findings.64.␣You␣should␣perform␣transformations␣on␣train,␣dev,␣and␣test␣sets␣at␣the␣same␣time␣(it’s␣a␣good␣idea␣to␣define␣functions␣for␣this␣and␣avoid␣code␣repetition).75.␣When␣scaling␣or␣transforming␣features,␣make␣sure␣the␣target␣column␣is␣not␣included.86.␣You␣could␣utilize␣dev␣set␣to␣validate␣and␣improve␣model␣training.␣{special_instruction}910##␣Saving␣Dev␣and␣Test␣Predictions111.␣Save␣the␣prediction␣results␣of␣BOTH␣the␣dev␣set␣and␣test␣set␣in␣‘dev_predictions.csv‘␣and␣‘test_predictions.csv‘␣respectively␣in␣the␣output␣directory.12-␣Both␣files␣should␣contain␣a␣single␣column␣named␣‘target‘␣with␣the␣predicted␣values.132.␣Make␣sure␣the␣prediction␣results␣are␣in␣the␣same␣format␣as␣the␣target␣column␣in␣the␣training␣set.14-␣For␣instance,␣if␣the␣target␣column␣is␣categorical,␣the␣prediction␣results␣should␣be␣categorical␣as␣well.1516##␣Output␣Performance17Print␣the␣train␣and␣dev␣set␣performance␣in␣the␣last␣step.1819#␣Output␣dir20{output_dir}21"""'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,RElfSU5TVFJVQ1RJT04gPSAiIiIKIyMgQXR0ZW50aW9uCjEuIFBsZWFzZSBkbyBub3QgbGVhayB0aGUgdGFyZ2V0IGxhYmVsIGluIGFueSBmb3JtIGR1cmluZyB0cmFpbmluZy4KMi4gVGVzdCBzZXQgZG9lcyBub3QgaGF2ZSB0aGUgdGFyZ2V0IGNvbHVtbi4KMy4gV2hlbiBjb25kdWN0aW5nIGRhdGEgZXhwbG9yYXRpb24gb3IgYW5hbHlzaXMsIHByaW50IG91dCB0aGUgcmVzdWx0cyBvZiB5b3VyIGZpbmRpbmdzLgo0LiBZb3Ugc2hvdWxkIHBlcmZvcm0gdHJhbnNmb3JtYXRpb25zIG9uIHRyYWluLCBkZXYsIGFuZCB0ZXN0IHNldHMgYXQgdGhlIHNhbWUgdGltZSAoaXQncyBhIGdvb2QgaWRlYSB0byBkZWZpbmUgZnVuY3Rpb25zIGZvciB0aGlzIGFuZCBhdm9pZCBjb2RlIHJlcGV0aXRpb24pLgo1LiBXaGVuIHNjYWxpbmcgb3IgdHJhbnNmb3JtaW5nIGZlYXR1cmVzLCBtYWtlIHN1cmUgdGhlIHRhcmdldCBjb2x1bW4gaXMgbm90IGluY2x1ZGVkLgo2LiBZb3UgY291bGQgdXRpbGl6ZSBkZXYgc2V0IHRvIHZhbGlkYXRlIGFuZCBpbXByb3ZlIG1vZGVsIHRyYWluaW5nLiB7c3BlY2lhbF9pbnN0cnVjdGlvbn0KCiMjIFNhdmluZyBEZXYgYW5kIFRlc3QgUHJlZGljdGlvbnMKMS4gU2F2ZSB0aGUgcHJlZGljdGlvbiByZXN1bHRzIG9mIEJPVEggdGhlIGRldiBzZXQgYW5kIHRlc3Qgc2V0IGluIGBkZXZfcHJlZGljdGlvbnMuY3N2YCBhbmQgYHRlc3RfcHJlZGljdGlvbnMuY3N2YCByZXNwZWN0aXZlbHkgaW4gdGhlIG91dHB1dCBkaXJlY3RvcnkuCi0gQm90aCBmaWxlcyBzaG91bGQgY29udGFpbiBhIHNpbmdsZSBjb2x1bW4gbmFtZWQgYHRhcmdldGAgd2l0aCB0aGUgcHJlZGljdGVkIHZhbHVlcy4KMi4gTWFrZSBzdXJlIHRoZSBwcmVkaWN0aW9uIHJlc3VsdHMgYXJlIGluIHRoZSBzYW1lIGZvcm1hdCBhcyB0aGUgdGFyZ2V0IGNvbHVtbiBpbiB0aGUgdHJhaW5pbmcgc2V0LgotIEZvciBpbnN0YW5jZSwgaWYgdGhlIHRhcmdldCBjb2x1bW4gaXMgY2F0ZWdvcmljYWwsIHRoZSBwcmVkaWN0aW9uIHJlc3VsdHMgc2hvdWxkIGJlIGNhdGVnb3JpY2FsIGFzIHdlbGwuCgojIyBPdXRwdXQgUGVyZm9ybWFuY2UKUHJpbnQgdGhlIHRyYWluIGFuZCBkZXYgc2V0IHBlcmZvcm1hbmNlIGluIHRoZSBsYXN0IHN0ZXAuCgojIE91dHB1dCBkaXIKe291dHB1dF9kaXJ9CiIiIg==)1DI_INSTRUCTION  =  """2##␣Attention31.␣Please␣do␣not␣leak␣the␣target␣label␣in␣any␣form␣during␣training.42.␣Test␣set␣does␣not␣have␣the␣target␣column.53.␣When␣conducting␣data␣exploration␣or␣analysis,␣print␣out␣the␣results␣of␣your␣findings.64.␣You␣should␣perform␣transformations␣on␣train,␣dev,␣and␣test␣sets␣at␣the␣same␣time␣(it’s␣a␣good␣idea␣to␣define␣functions␣for␣this␣and␣avoid␣code␣repetition).75.␣When␣scaling␣or␣transforming␣features,␣make␣sure␣the␣target␣column␣is␣not␣included.86.␣You␣could␣utilize␣dev␣set␣to␣validate␣and␣improve␣model␣training.␣{special_instruction}910##␣Saving␣Dev␣and␣Test␣Predictions111.␣Save␣the␣prediction␣results␣of␣BOTH␣the␣dev␣set␣and␣test␣set␣in␣‘dev_predictions.csv‘␣and␣‘test_predictions.csv‘␣respectively␣in␣the␣output␣directory.12-␣Both␣files␣should␣contain␣a␣single␣column␣named␣‘target‘␣with␣the␣predicted␣values.132.␣Make␣sure␣the␣prediction␣results␣are␣in␣the␣same␣format␣as␣the␣target␣column␣in␣the␣training␣set.14-␣For␣instance,␣if␣the␣target␣column␣is␣categorical,␣the␣prediction␣results␣should␣be␣categorical␣as␣well.1516##␣Output␣Performance17Print␣the␣train␣and␣dev␣set␣performance␣in␣the␣last␣step.1819#␣Output␣dir20{output_dir}21"""'
- en: B.3 Insight Proposal Prompt
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 深度洞察提案提示
- en: Insight Proposer uses this prompt to generate a search space of insights for
    different stages of the machine learning task.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 洞察提案者使用此提示生成机器学习任务不同阶段的洞察搜索空间。
- en: '[⬇](data:text/plain;base64,REFUQVNFVF9JTlNJR0hUX1BST01QVCA9ICIiIgojIERhdGFzZXQgRGVzY3JpcHRpb24Ke2RhdGFzZXR9CgojIERhdGFzZXQgTWV0YWRhdGEKe21ldGFkYXRhfQoKIyBEYXRhc2V0IEhlYWQKe2hlYWR9CgojIEluc3RydWN0aW9uClByb3Bvc2UgaW5zaWdodHMgdG8gaGVscCBpbXByb3ZlIHRoZSBwZXJmb3JtYW5jZSBvZiB0aGUgbW9kZWwgb24gdGhpcyBkYXRhc2V0LgpUaGUgaW5zaWdodHMgc2hvdWxkIGJlIHByb3Bvc2VkIGJhc2VkIG9uIHRoZSBkYXRhc2V0IGRlc2NyaXB0aW9uIHdpdGggZGlmZmVyZW50IHRhc2sgdHlwZXMuCkVhY2ggdGFzayB0eXBlIHNob3VsZCBoYXZlIGF0IGxlYXN0IDUgaW5zaWdodHMuCk1ha2Ugc3VyZSBlYWNoIG1ldGhvZCBpcyBkaXZlcnNlIGVub3VnaCBhbmQgY2FuIGJlIGltcGxlbWVudGVkIHNlcGFyYXRlbHkuCkJlIHNwZWNpZmljIGFib3V0IG1vZGVscycgY2hvaWNlcywgZW5zZW1ibGUgYW5kIHR1bmluZyB0ZWNobmlxdWVzLCBhbmQgcHJlcHJvY2Vzc2luZyAmIGZlYXR1cmUgZW5naW5lZXJpbmcgdGVjaG5pcXVlcy4KCiMgRm9ybWF0CmBgYGpzb24KWwogICAge3sKICAgICAgICAidGFza190eXBlIjogIkVEQSIsCiAgICAgICAgImluc2lnaHRzIjogWwogICAgICAgICAgICAiaW5zaWdodDEiLAogICAgICAgICAgICAiaW5zaWdodDIiLAogICAgICAgICAgICAiaW5zaWdodDMiLAogICAgICAgICAgICAuLi4KICAgICAgICAgICAgImluc2lnaHROIgogICAgICAgIF0KICAgIH19LAogICAge3sKICAgICAgICAidGFza190eXBlIjogIkRhdGEgUHJlcHJvY2Vzc2luZyIsCiAgICAgICAgImluc2lnaHRzIjogWwogICAgICAgICAgICAiaW5zaWdodDEiLAogICAgICAgICAgICAiaW5zaWdodDIiLAogICAgICAgICAgICAiaW5zaWdodDMiLAogICAgICAgICAgICAuLi4KICAgICAgICAgICAgImluc2lnaHROIgogICAgICAgIF0KICAgIH19LAogICAge3sKICAgICAgICAidGFza190eXBlIjogIkZlYXR1cmUgRW5naW5lZXJpbmciLAogICAgICAgICJpbnNpZ2h0cyI6IFsKICAgICAgICAgICAgImluc2lnaHQxIiwKICAgICAgICAgICAgImluc2lnaHQyIiwKICAgICAgICAgICAgImluc2lnaHQzIiwKICAgICAgICAgICAgLi4uCiAgICAgICAgICAgICJpbnNpZ2h0TiIKICAgICAgICBdCiAgICB9fSwKICAgIHt7CiAgICAgICAgInRhc2tfdHlwZSI6ICJNb2RlbCBUcmFpbmluZyIsCiAgICAgICAgImluc2lnaHRzIjogWwogICAgICAgICAgICAiaW5zaWdodDEiLAogICAgICAgICAgICAiaW5zaWdodDIiLAogICAgICAgICAgICAiaW5zaWdodDMiLAogICAgICAgICAgICAuLi4KICAgICAgICAgICAgImluc2lnaHROIgogICAgICAgIF0KICAgIH19Cl0KYGBgCiIiIg==)1DATASET_INSIGHT_PROMPT  =  """2#␣Dataset␣Description3{dataset}45#␣Dataset␣Metadata6{metadata}78#␣Dataset␣Head9{head}1011#␣Instruction12Propose␣insights␣to␣help␣improve␣the␣performance␣of␣the␣model␣on␣this␣dataset.13The␣insights␣should␣be␣proposed␣based␣on␣the␣dataset␣description␣with␣different␣task␣types.14Each␣task␣type␣should␣have␣at␣least␣5␣insights.15Make␣sure␣each␣method␣is␣diverse␣enough␣and␣can␣be␣implemented␣separately.16Be␣specific␣about␣models’␣choices,␣ensemble␣and␣tuning␣techniques,␣and␣preprocessing␣&␣feature␣engineering␣techniques.1718#␣Format19‘‘‘json20[21␣␣␣␣{{22␣␣␣␣␣␣␣␣"task_type":␣"EDA",23␣␣␣␣␣␣␣␣"insights":␣[24␣␣␣␣␣␣␣␣␣␣␣␣"insight1",25␣␣␣␣␣␣␣␣␣␣␣␣"insight2",26␣␣␣␣␣␣␣␣␣␣␣␣"insight3",27␣␣␣␣␣␣␣␣␣␣␣␣...28␣␣␣␣␣␣␣␣␣␣␣␣"insightN"29␣␣␣␣␣␣␣␣]30␣␣␣␣}},31␣␣␣␣{{32␣␣␣␣␣␣␣␣"task_type":␣"Data  Preprocessing",33␣␣␣␣␣␣␣␣"insights":␣[34␣␣␣␣␣␣␣␣␣␣␣␣"insight1",35␣␣␣␣␣␣␣␣␣␣␣␣"insight2",36␣␣␣␣␣␣␣␣␣␣␣␣"insight3",37␣␣␣␣␣␣␣␣␣␣␣␣...38␣␣␣␣␣␣␣␣␣␣␣␣"insightN"39␣␣␣␣␣␣␣␣]40␣␣␣␣}},41␣␣␣␣{{42␣␣␣␣␣␣␣␣"task_type":␣"Feature  Engineering",43␣␣␣␣␣␣␣␣"insights":␣[44␣␣␣␣␣␣␣␣␣␣␣␣"insight1",45␣␣␣␣␣␣␣␣␣␣␣␣"insight2",46␣␣␣␣␣␣␣␣␣␣␣␣"insight3",47␣␣␣␣␣␣␣␣␣␣␣␣...48␣␣␣␣␣␣␣␣␣␣␣␣"insightN"49␣␣␣␣␣␣␣␣]50␣␣␣␣}},51␣␣␣␣{{52␣␣␣␣␣␣␣␣"task_type":␣"Model  Training",53␣␣␣␣␣␣␣␣"insights":␣[54␣␣␣␣␣␣␣␣␣␣␣␣"insight1",55␣␣␣␣␣␣␣␣␣␣␣␣"insight2",56␣␣␣␣␣␣␣␣␣␣␣␣"insight3",57␣␣␣␣␣␣␣␣␣␣␣␣...58␣␣␣␣␣␣␣␣␣␣␣␣"insightN"59␣␣␣␣␣␣␣␣]60␣␣␣␣}}61]62‘‘‘63"""'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,REFUQVNFVF9JTlNJR0hUX1BST01QVCA9ICIiIgojIERhdGFzZXQgRGVzY3JpcHRpb24Ke2RhdGFzZXR9CgojIERhdGFzZXQgTWV0YXRhdGEKe21ldGFkYXRhfQoKIyBEYXRhc2V0IEhlYWQKe2hlYWR9CgojIEluc3RydWN0aW9uClByb3Bvc2UgaW5zaWdodHMgdG8gaGVscCBpbXByb3ZlIHRoZSBwZXJmb3JtYW5jZSBvZiB0aGUgbW9kZWwgb24gdGhpcyBkYXRhc2V0LgpUaGUgaW5zaWdodHMgc2hvdWxkIGJlIHByb3Bvc2VkIGJhc2VkIG9uIHRoZSBkYXRhc2V0IGRlc2NyaXB0aW9uIHdpdGggZGlmZmVyZW50IHRhc2sgdHlwZXMuCkVhY2ggdGFzayB0eXBlIHNob3VsZCBoYXZlIGF0IGxlYXN0IDUgaW5zaWdodHMuCk1ha2Ugc3VyZSBlYWNoIG1ldGhvZCBpcyBkaXZlcnNlIGVub3VnaCBhbmQgY2FuIGJlIGltcGxlbWVudGVkIHNlcGFyYXRlbHkuCkJlIHNwZWNpZmljIGFib3V0IG1vZGVscycgY2hvaWNlcywgZW5zZW1ibGUgYW5kIHR1bmluZyB0ZWNobmlxdWVzLCBhbmQgcHJlcHJvY2Vzc2luZyAmIGZlYXR1cmUgZW5naW5lZXJpbmcgdGVjaG5pcXVlcy4KCiMgRm9ybWF0CmBgYGpzb24KWwogICAge3sKICAgICAgICAidGFza190eXBlIjogIkVEQSIsCiAgICAgICAgImluc2lnaHRzIjogWwogICAgICAgICAgICAiaW5zaWdodDEiLAogICAgICAgICAgICAiaW5zaWdodDIiLAogICAgICAgICAgICAiaW5zaWdodDMiLAogICAgICAgICAgICAuLi4KICAgICAgICAgICAgImluc2lnaHROIgogICAgICAgIF0KICAgIH19LAogICAge3sKICAgICAgICAidGFza190eXBlIjogIkRhdGEgUHJlcHJvY2Vzc2luZyIsCiAgICAgICAgImluc2lnaHRzIjogWwogICAgICAgICAgICAiaW5zaWdodDEiLAogICAgICAgICAgICAiaW5zaWdodDIiLAogICAgICAgICAgICAiaW5zaWdodDMiLAogICAgICAgICAgICAuLi4KICAgICAgICAgICAgImluc2lnaHROIgogICAgICAgIF0KICAgIH19LAogICAge3sKICAgICAgICAidGFza190eXBlIjogIkZlYXR1cmUgRW5naW5lZXJpbmciLAogICAgICAgICJpbnNpZ2h0cyI6IFsKICAgICAgICAgICAgImluc2lnaHQxIiwKICAgICAgICAgICAgImluc2lnaHQyIiwKICAgICAgICAgICAgImluc2lnaHQzIiwKICAgICAgICAgICAgLi4uCiAgICAgICAgICAgICJpbnNpZ2h0TiIKICAgICAgICBdCiAgICB9fSwKICAgIHt7CiAgICAgICAgInRhc2tfdHlwZSI6ICJNb2RlbCBUcmFpbmluZyIsCiAgICAgICAgImluc2lnaHRzIjogWwogICAgICAgICAgICAiaW5zaWdodDEiLAogICAgICAgICAgICAiaW5zaWdodDIiLAogICAgICAgICAgICAiaW5zaWdodDMiLAogICAgICAgICAgICAuLi4KICAgICAgICAgICAgImluc2lnaHROIgogICAgICAgIF0KICAgIH19Cl0KYGBgCiIiIg==)1数据集概述  =  """2#
    数据集描述3{dataset}45# 数据集元数据6{metadata}78# 数据集头9{head}1011# 指令12提出见解以帮助提高模型在此数据集上的表现。13见解应基于数据集描述提出，并结合不同的任务类型。14每个任务类型至少应有5个见解。15确保每个方法具有足够的多样性，并且可以独立实现。16具体说明模型选择、集成方法与调优技术，以及预处理与特征工程技术。1718#
    格式19‘‘‘json20[21   {{22   "task_type": "EDA",23   "insights": [24   "insight1",25   "insight2",26   "insight3",27   ...28   "insightN"29   ]30   }},31   {{32   "task_type":
    "Data  Preprocessing",33   "insights": [34   "insight1",35   "insight2",36   "insight3",37   ...38   "insightN"39   ]40   }},41   {{42   "task_type":
    "Feature  Engineering",43   "insights": [44   "insight1",45   "insight2",46   "insight3",47   ...48   "insightN"49   ]50   }},51   {{52   "task_type":
    "Model  Training",53   "insights": [54   "insight1",55   "insight2",56   "insight3",57   ...58   "insightN"59   ]60   }}61]62‘‘‘63"""'
- en: Appendix C Results
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 结果
- en: C.1 Main Results
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 主要结果
- en: '|  | AutoGluon | AutoSklearn | AIDE | DI | \methodname |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  | AutoGluon | AutoSklearn | AIDE | DI | \methodname |'
- en: '| Dataset | Avg. | Best | Avg. | Best | Avg. | Best | Avg. | Best | Avg. |
    Best |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 平均值 | 最佳值 | 平均值 | 最佳值 | 平均值 | 最佳值 | 平均值 | 最佳值 | 平均值 | 最佳值 |'
- en: '| Click_prediction_small | 7 | 7 | 2 | 1 | 7.3 | 4 | 11 | 10 | 7.7 | 6 |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| Click_prediction_small | 7 | 7 | 2 | 1 | 7.3 | 4 | 11 | 10 | 7.7 | 6 |'
- en: '| GesturePhaseSegmentationProcessed | 1 | 1 | 6.3 | 3 | 7.3 | 4 | 11 | 10 |
    5.3 | 2 |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| GesturePhaseSegmentationProcessed | 1 | 1 | 6.3 | 3 | 7.3 | 4 | 11 | 10 |
    5.3 | 2 |'
- en: '| Moneyball | 4 | 4 | 10 | 9 | 4 | 1 | 9 | 2 | 6 | 3 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| Moneyball | 4 | 4 | 10 | 9 | 4 | 1 | 9 | 2 | 6 | 3 |'
- en: '| SAT11-HAND-runtime-regression | 1 | 1 | 12 | 11 | 5.3 | 3 | 9 | 8 | 3.7 |
    2 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| SAT11-HAND-runtime-regression | 1 | 1 | 12 | 11 | 5.3 | 3 | 9 | 8 | 3.7 |
    2 |'
- en: '| boston | 5 | 5 | 12 | 11 | 3.7 | 2 | 9 | 8 | 4 | 1 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| boston | 5 | 5 | 12 | 11 | 3.7 | 2 | 9 | 8 | 4 | 1 |'
- en: '| colleges | 1 | 1 | 12 | 11 | 6 | 2 | 8 | 7 | 4 | 3 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| colleges | 1 | 1 | 12 | 11 | 6 | 2 | 8 | 7 | 4 | 3 |'
- en: '| concrete-strength | 5 | 5 | 12 | 11 | 6.3 | 4 | 2 | 1 | 8.3 | 6 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| concrete-strength | 5 | 5 | 12 | 11 | 6.3 | 4 | 2 | 1 | 8.3 | 6 |'
- en: '| credit-g | 4 | 4 | 10 | 9 | 10 | 5 | 5.3 | 1 | 3.7 | 2 |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| credit-g | 4 | 4 | 10 | 9 | 10 | 5 | 5.3 | 1 | 3.7 | 2 |'
- en: '| diamonds | 2 | 2 | 12 | 11 | 6 | 4 | 8.7 | 7 | 3 | 1 |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| diamonds | 2 | 2 | 12 | 11 | 6 | 4 | 8.7 | 7 | 3 | 1 |'
- en: '| house-prices | 1 | 1 | 12 | 11 | 6.7 | 5 | 7.3 | 3 | 4 | 2 |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| house-prices | 1 | 1 | 12 | 11 | 6.7 | 5 | 7.3 | 3 | 4 | 2 |'
- en: '| icr | 5 | 5 | 5.3 | 3 | 12 | 11 | 9 | 8 | 2.3 | 1 |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| icr | 5 | 5 | 5.3 | 3 | 12 | 11 | 9 | 8 | 2.3 | 1 |'
- en: '| jasmine | 7 | 7 | 6 | 4 | 8.7 | 5 | 11.3 | 9 | 2 | 1 |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| jasmine | 7 | 7 | 6 | 4 | 8.7 | 5 | 11.3 | 9 | 2 | 1 |'
- en: '| kc1 | 10 | 10 | 2.7 | 1 | 8 | 5 | 11.3 | 9 | 5 | 2 |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| kc1 | 10 | 10 | 2.7 | 1 | 8 | 5 | 11.3 | 9 | 5 | 2 |'
- en: '| kick | 4 | 4 | 2 | 1 | 9.3 | 6 | 11 | 10 | 6.7 | 5 |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| kick | 4 | 4 | 2 | 1 | 9.3 | 6 | 11 | 10 | 6.7 | 5 |'
- en: '| mfeat-factors | 4 | 4 | 2 | 1 | 10 | 9 | 10.3 | 6 | 6.7 | 5 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| mfeat-factors | 4 | 4 | 2 | 1 | 10 | 9 | 10.3 | 6 | 6.7 | 5 |'
- en: '| segment | 3 | 3 | 6.3 | 5 | 11 | 10 | 9.7 | 7 | 2.3 | 1 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| segment | 3 | 3 | 6.3 | 5 | 11 | 10 | 9.7 | 7 | 2.3 | 1 |'
- en: '| smoker-status | 7 | 7 | 4.7 | 3 | 11.3 | 9 | 7.7 | 2 | 4.3 | 1 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| smoker-status | 7 | 7 | 4.7 | 3 | 11.3 | 9 | 7.7 | 2 | 4.3 | 1 |'
- en: '| software-defects | 8 | 8 | 2 | 1 | 12 | 11 | 6 | 4 | 7.7 | 6 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| software-defects | 8 | 8 | 2 | 1 | 12 | 11 | 6 | 4 | 7.7 | 6 |'
- en: '| titanic | 7 | 7 | 9.7 | 6 | 2.7 | 1 | 10.3 | 8 | 5.3 | 3 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| titanic | 7 | 7 | 9.7 | 6 | 2.7 | 1 | 10.3 | 8 | 5.3 | 3 |'
- en: '| wine-quality-white | 2 | 2 | 10 | 8 | 7.3 | 4 | 9 | 7 | 3.3 | 1 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| wine-quality-white | 2 | 2 | 10 | 8 | 7.3 | 4 | 9 | 7 | 3.3 | 1 |'
- en: '| Overall Rank $\downarrow$ | 4.4 | 4.4 | 7.6 | 6.1 | 7.8 | 5.3 | 8.8 | 6.4
    | 4.8 | 2.7 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 总体排名 $\downarrow$ | 4.4 | 4.4 | 7.6 | 6.1 | 7.8 | 5.3 | 8.8 | 6.4 | 4.8 |
    2.7 |'
- en: 'Table 5: Methods’ ranking for each tabular dataset'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：每个表格数据集的方法排名
- en: '|  | AutoGluon | AutoSklearn | AIDE | DI | \methodname |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  | AutoGluon | AutoSklearn | AIDE | DI | \methodname |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Dataset | Avg. | Best | Avg. | Best | Avg. | Best | Avg. | Best | Avg. |
    Best |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 平均值 | 最佳值 | 平均值 | 最佳值 | 平均值 | 最佳值 | 平均值 | 最佳值 | 平均值 | 最佳值 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Click_prediction_small | 26.6 | 26.6 | 40.2 | 40.3 | 26.1 | 39.4 | 12.9 |
    13.9 | 23.2 | 27.4 |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| Click_prediction_small | 26.6 | 26.6 | 40.2 | 40.3 | 26.1 | 39.4 | 12.9 |
    13.9 | 23.2 | 27.4 |'
- en: '| GesturePhaseSegmentationProcessed | 69.3 | 69.3 | 67.2 | 68.4 | 56.3 | 68.1
    | 60.1 | 64.4 | 67.9 | 69.2 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| GesturePhaseSegmentationProcessed | 69.3 | 69.3 | 67.2 | 68.4 | 56.3 | 68.1
    | 60.1 | 64.4 | 67.9 | 69.2 |'
- en: '| Moneyball | 24.3 | 24.3 | 13.1 | 13.8 | 23.8 | 24.6 | 9.5 | 24.5 | 21.9 |
    24.5 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| Moneyball | 24.3 | 24.3 | 13.1 | 13.8 | 23.8 | 24.6 | 9.5 | 24.5 | 21.9 |
    24.5 |'
- en: '| SAT11-HAND-runtime-regression | 12.6 | 12.6 | 10.3 | 10.3 | 12.0 | 12.1 |
    11.4 | 11.9 | 12.2 | 12.5 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| SAT11-HAND-runtime-regression | 12.6 | 12.6 | 10.3 | 10.3 | 12.0 | 12.1 |
    11.4 | 11.9 | 12.2 | 12.5 |'
- en: '| boston | 39.8 | 39.8 | 19.5 | 19.6 | 40.5 | 41.3 | 37.0 | 38.6 | 40.1 | 41.4
    |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| boston | 39.8 | 39.8 | 19.5 | 19.6 | 40.5 | 41.3 | 37.0 | 38.6 | 40.1 | 41.4
    |'
- en: '| colleges | 88.3 | 88.3 | 2.1 | 2.1 | 86.0 | 87.8 | 87.5 | 87.7 | 87.8 | 87.8
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| colleges | 88.3 | 88.3 | 2.1 | 2.1 | 86.0 | 87.8 | 87.5 | 87.7 | 87.8 | 87.8
    |'
- en: '| concrete-strength | 28.3 | 28.3 | 17.4 | 17.9 | 28.3 | 28.3 | 28.8 | 29.6
    | 28.2 | 28.2 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| concrete-strength | 28.3 | 28.3 | 17.4 | 17.9 | 28.3 | 28.3 | 28.8 | 29.6
    | 28.2 | 28.2 |'
- en: '| credit-g | 50.5 | 50.5 | 35.1 | 44.0 | 21.6 | 48.4 | 48.1 | 53.2 | 50.9 |
    52.7 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| credit-g | 50.5 | 50.5 | 35.1 | 44.0 | 21.6 | 48.4 | 48.1 | 53.2 | 50.9 |
    52.7 |'
- en: '| diamonds | 13.8 | 13.8 | 8.7 | 8.7 | 13.7 | 13.7 | 13.5 | 13.6 | 13.7 | 13.8
    |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| diamonds | 13.8 | 13.8 | 8.7 | 8.7 | 13.7 | 13.7 | 13.5 | 13.6 | 13.7 | 13.8
    |'
- en: '| house-prices | 9.0 | 9.0 | 2.0 | 2.0 | 8.9 | 8.9 | 8.5 | 9.0 | 8.9 | 9.0
    |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| house-prices | 9.0 | 9.0 | 2.0 | 2.0 | 8.9 | 8.9 | 8.5 | 9.0 | 8.9 | 9.0
    |'
- en: '| icr | 76.2 | 76.2 | 70.4 | 79.2 | 31.7 | 35.9 | 57.8 | 60.6 | 78.7 | 79.2
    |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| icr | 76.2 | 76.2 | 70.4 | 79.2 | 31.7 | 35.9 | 57.8 | 60.6 | 78.7 | 79.2
    |'
- en: '| jasmine | 84.3 | 84.3 | 84.4 | 84.7 | 83.6 | 84.6 | 77.8 | 83.5 | 85.4 |
    86.2 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| jasmine | 84.3 | 84.3 | 84.4 | 84.7 | 83.6 | 84.6 | 77.8 | 83.5 | 85.4 |
    86.2 |'
- en: '| kc1 | 38.3 | 38.3 | 43.5 | 45.0 | 40.8 | 42.6 | 38.1 | 41.2 | 42.2 | 43.1
    |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| kc1 | 38.3 | 38.3 | 43.5 | 45.0 | 40.8 | 42.6 | 38.1 | 41.2 | 42.2 | 43.1
    |'
- en: '| kick | 39.6 | 39.6 | 41.8 | 42.1 | 14.9 | 38.6 | 2.8 | 4.2 | 35.9 | 38.7
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 踢球（kick） | 39.6 | 39.6 | 41.8 | 42.1 | 14.9 | 38.6 | 2.8 | 4.2 | 35.9 | 38.7
    |'
- en: '| mfeat-factors | 96.7 | 96.7 | 97.1 | 97.5 | 94.4 | 94.5 | 93.0 | 96.0 | 95.7
    | 96.2 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| mfeat-factors | 96.7 | 96.7 | 97.1 | 97.5 | 94.4 | 94.5 | 93.0 | 96.0 | 95.7
    | 96.2 |'
- en: '| segment | 93.5 | 93.5 | 92.7 | 93.1 | 91.7 | 92.2 | 91.7 | 92.6 | 93.8 |
    94.4 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 分段（segment） | 93.5 | 93.5 | 92.7 | 93.1 | 91.7 | 92.2 | 91.7 | 92.6 | 93.8
    | 94.4 |'
- en: '| smoker-status | 78.0 | 78.0 | 78.6 | 78.9 | 74.8 | 76.3 | 77.3 | 81.5 | 82.4
    | 91.5 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 吸烟状态（smoker-status） | 78.0 | 78.0 | 78.6 | 78.9 | 74.8 | 76.3 | 77.3 | 81.5
    | 82.4 | 91.5 |'
- en: '| software-defects | 51.5 | 51.5 | 61.1 | 61.7 | 49.7 | 49.8 | 54.5 | 57.3
    | 52.2 | 53.3 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 软件缺陷（software-defects） | 51.5 | 51.5 | 61.1 | 61.7 | 49.7 | 49.8 | 54.5 |
    57.3 | 52.2 | 53.3 |'
- en: '| titanic | 78.9 | 78.9 | 76.2 | 78.9 | 81.2 | 83.7 | 76.0 | 78.5 | 78.8 |
    79.7 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| titanic | 78.9 | 78.9 | 76.2 | 78.9 | 81.2 | 83.7 | 76.0 | 78.5 | 78.8 |
    79.7 |'
- en: '| wine-quality-white | 65.4 | 65.4 | 60.7 | 61.4 | 62.9 | 65.1 | 61.2 | 61.6
    | 65.3 | 66.0 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 葡萄酒质量（白葡萄酒） | 65.4 | 65.4 | 60.7 | 61.4 | 62.9 | 65.1 | 61.2 | 61.6 | 65.3
    | 66.0 |'
- en: '| Overall NS % $\uparrow$ | 53.2 | 53.2 | 46.1 | 47.5 | 45.5 | 51.8 | 47.4
    | 50.2 | 53.3 | 54.7 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 总体 NS 百分比 $\uparrow$ | 53.2 | 53.2 | 46.1 | 47.5 | 45.5 | 51.8 | 47.4 | 50.2
    | 53.3 | 54.7 |'
- en: 'Table 6: Methods’ NS % for each tabular dataset'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：每个表格数据集的NS百分比结果
- en: C.2 Performance using different LLMs
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 使用不同LLM的性能
- en: '|  | GPT-4o | Claude 3.5 Sonnet | DeepSeek V2.5 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT-4o | Claude 3.5 Sonnet | DeepSeek V2.5 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Avg. NS $\uparrow$ | 62.3 | 57.9 | 60.9 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 平均 NS $\uparrow$ | 62.3 | 57.9 | 60.9 |'
- en: '| Avg. Best NS $\uparrow$ | 65.5 | 59.2 | 62.4 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 平均最佳 NS $\uparrow$ | 65.5 | 59.2 | 62.4 |'
- en: '| Avg. Rank $\downarrow$ | 3.7 | 6.3 | 5.0 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 平均排名 $\downarrow$ | 3.7 | 6.3 | 5.0 |'
- en: '| Avg. Best Rank $\downarrow$ | 1.5 | 4.8 | 3.2 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 平均最佳排名 $\downarrow$ | 1.5 | 4.8 | 3.2 |'
- en: 'Table 7: Results of \methodname with different base LLMs on the selected tabular
    datasets.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：\methodname 在不同基础LLM上的表现（在所选表格数据集上）
- en: Appendix D Cost-effectiveness Analysis
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 成本效益分析
- en: 'We conduct multiple trials of execution of each method to estimate the average
    running cost for the LLM-based baselines. As shown in Table [8](https://arxiv.org/html/2410.17238v1#A4.T8
    "Table 8 ‣ Appendix D Cost-effectiveness Analysis ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning"), all methods incur relatively low
    costs to complete a single machine learning task. Among these, AIDE exhibits the
    lowest execution cost, due to the lack of stage-wise planning, resulting in fewer
    token generations compared to the other approaches. Additionally, \methodname,
    which employs Data Interpreter as its base experimenter, is less costly than Data
    Interpreter itself. This efficiency is largely due to \methodname’s state-saving
    and loading mechanism, which reduces the generation of repeated tasks and code.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '我们对每种方法进行多次试验，以估算基于LLM的基准模型的平均运行成本。如表[8](https://arxiv.org/html/2410.17238v1#A4.T8
    "Table 8 ‣ Appendix D Cost-effectiveness Analysis ‣ \methodname: Tree-Search Enhanced
    LLM Agents for Automated Machine Learning")所示，所有方法完成单个机器学习任务的成本都相对较低。在这些方法中，AIDE展示了最低的执行成本，因为它没有逐步规划，生成的token数量较其他方法少。此外，采用数据解释器（Data
    Interpreter）作为基本实验者的\methodname，其成本低于数据解释器本身。这种效率主要得益于\methodname的状态保存和加载机制，减少了重复任务和代码的生成。'
- en: '|  | Cost per ML task ($) |  |  |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '|  | 每个机器学习任务的成本（$） |  |  |'
- en: '| Data Interpreter ($k$=10) | 0.07 |  |  |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 数据解释器 (Data Interpreter) ($k$=10) | 0.07 |  |  |'
- en: '| AIDE ($k$=10) | 0.01 |  |  |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| AIDE ($k$=10) | 0.01 |  |  |'
- en: '| \methodname ($k$=10) | 0.05 |  |  |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| \methodname ($k$=10) | 0.05 |  |  |'
- en: 'Table 8: Estimated costs of agent-based frameworks utilizing DeepSeekV2.5 on
    a single machine learning dataset over $k$ iterations/rollouts.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：使用DeepSeekV2.5的基于代理的框架在单个机器学习数据集上的估算成本，经过$k$次迭代/执行。
- en: Appendix E Case Study
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 案例研究
- en: E.1 Overview of SELA’s search process
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 SELA 搜索过程概述
- en: '[⬇](data:text/plain;base64,Number of simulations: 10
[Node 0]
Plans:
1. Perform exploratory data analysis on the train and dev datasets
2. Preprocess the train, dev, and test datasets
3. Perform feature engineering on the train, dev, and test datasets
4. Train multiple models and evaluate their performance
5. Train a weighted ensemble model using the best performing models
6. Evaluate the ensemble model on the dev set and save predictions
7. Generate predictions for the test set and save them
Simulated: True
Score: avg score: 0.6150206840685731, simulated score: {'train_score': 1.0, 'dev_score': 0.6855841857240594, 'test_score': 0.6814818772150697, 'score': 0.6855841857240594}, Visits: 10

	[Node 0-0]
	Plans:
	3. Perform feature engineering on the train, dev, and test datasets by creating new features that calculate the magnitude of the vectorial velocities and accelerations to capture the overall movement intensity.
	Simulated: True
	Score: avg score: 0.6507249985568175, simulated score: {'train_score': 0.982920964830782, 'dev_score': 0.6420233166755841, 'test_score': 0.647550336228104, 'score': 0.6420233166755841}, Visits: 2

		[Node 0-0-0]
		Plans:
		4. Train a Random Forest classifier to leverage its ability to handle high-dimensional data and capture non-linear relationships, and evaluate its performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-0-1]
		Plans:
		4. Train multiple models, including a Support Vector Machine (SVM) with a radial basis function (RBF) kernel, and evaluate their performance.
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-0-2]
		Plans:
		4. Implement a Neural Network with multiple layers to capture the hierarchical patterns in the data and evaluate its performance
		Simulated: True
		Score: avg score: 0.6594266804380511, simulated score: {'train_score': 1.0, 'dev_score': 0.6594266804380511, 'test_score': 0.6702614538699305, 'score': 0.6594266804380511}, Visits: 1

		[Node 0-0-3]
		Plans:
		4. Train multiple models, apply an ensemble method like Gradient Boosting to combine them, and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-0-4]
		Plans:
		4. Train multiple models, perform hyperparameter tuning using Grid Search or Random Search, and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

	[Node 0-1]
	Plans:
	3. Perform feature engineering on the train, dev, and test datasets by generating time-based features, such as the difference between consecutive frames, to capture the rate of change in movements.
	Simulated: True
	Score: avg score: 0.6464940718972336, simulated score: {'train_score': 1.0, 'dev_score': 0.5985614604756948, 'test_score': 0.5857379626419719, 'score': 0.5985614604756948}, Visits: 2

		[Node 0-1-0]
		Plans:
		4. Train a Random Forest classifier to leverage its ability to handle high-dimensional data and capture non-linear relationships
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-1-1]
		Plans:
		4. Train multiple models, including a Support Vector Machine (SVM) with a radial basis function (RBF) kernel, and evaluate their performance to model the complex decision boundaries between different gesture phases.
		Simulated: True
		Score: avg score: 0.6944266833187726, simulated score: {'train_score': 1.0, 'dev_score': 0.6944266833187726, 'test_score': 0.6928451194338062, 'score': 0.6944266833187726}, Visits: 1

		[Node 0-1-2]
		Plans:
		4. Implement a Neural Network with multiple layers to capture the hierarchical patterns in the data and evaluate its performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-1-3]
		Plans:
		4. Train multiple models, apply an ensemble method like Gradient Boosting to combine them, and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-1-4]
		Plans:
		4. Train multiple models and perform hyperparameter tuning using techniques like Grid Search or Random Search to optimize and evaluate their performance.
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

	[Node 0-2]
	Plans:
	3. Perform feature engineering on the train, dev, and test datasets by creating features that represent the spatial relationships between different body parts, such as the distance between the hands and the head.
	Simulated: True
	Score: avg score: 0.6296836159165489, simulated score: {'train_score': 0.7619969104124632, 'dev_score': 0.5997286931710517, 'test_score': 0.604077566134264, 'score': 0.5997286931710517}, Visits: 3

		[Node 0-2-0]
		Plans:
		4. Train a Random Forest classifier to leverage its ability to handle high-dimensional data and capture non-linear relationships, and evaluate its performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-2-1]
		Plans:
		4. Train multiple models, including a Support Vector Machine (SVM) with a radial basis function (RBF) kernel, and evaluate their performance to model the complex decision boundaries between different gesture phases.
		Simulated: True
		Score: avg score: 0.6446610772892973, simulated score: {'train_score': 0.9952809245924918, 'dev_score': 0.6372459669415207, 'test_score': 0.6423549137767338, 'score': 0.6372459669415207}, Visits: 2

			[Node 0-2-1-0]
			Plans:
			5. Train a weighted ensemble model using the best performing models from task 4
			Simulated: False
			Score: avg score: 0, simulated score: {}, Visits: 0

			[Node 0-2-1-1]
			Plans:
			5. Using the models that performed best in task 4, train a weighted ensemble model to improve overall performance.
			Simulated: False
			Score: avg score: 0, simulated score: {}, Visits: 0

			[Node 0-2-1-2]
			Plans:
			5. Develop a weighted ensemble model by integrating the top-performing models from task 4, ensuring to evaluate and adjust the weights for optimal performance.
			Simulated: True
			Score: avg score: 0.6520761876370741, simulated score: {'train_score': 1.0, 'dev_score': 0.6520761876370741, 'test_score': 0.6563435152603494, 'score': 0.6520761876370741}, Visits: 1

			[Node 0-2-1-3]
			Plans:
			5. Train a weighted ensemble model by combining the predictions of the top-performing models from task 4 to improve overall performance.
			Simulated: False
			Score: avg score: 0, simulated score: {}, Visits: 0

			[Node 0-2-1-4]
			Plans:
			5. Develop a weighted ensemble model by combining the top-performing models from task 4, ensuring to optimize the weights for improved performance.
			Simulated: False
			Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-2-2]
		Plans:
		4. Implement a Neural Network with multiple layers to capture the hierarchical patterns in the data and evaluate its performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-2-3]
		Plans:
		4. Train multiple models, apply an ensemble method like Gradient Boosting to combine them, and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-2-4]
		Plans:
		4. Perform hyperparameter tuning using Grid Search or Random Search to train multiple models and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

	[Node 0-3]
	Plans:
	3. Apply feature selection techniques such as Recursive Feature Elimination (RFE) or SelectKBest to identify and retain the most important features in the train, dev, and test datasets.
	Simulated: True
	Score: avg score: 0.49056683315196203, simulated score: {'train_score': 0.9988177730410426, 'dev_score': 0.51620611302976, 'test_score': 0.525989891002361, 'score': 0.51620611302976}, Visits: 2

		[Node 0-3-0]
		Plans:
		4. Train a Random Forest classifier to leverage its ability to handle high-dimensional data and capture non-linear relationships, and evaluate its performance.
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-3-1]
		Plans:
		4. Train multiple models, including a Support Vector Machine (SVM) with a radial basis function (RBF) kernel, and evaluate their performance to model the complex decision boundaries between different gesture phases.
		Simulated: True
		Score: avg score: 0.4649275532741641, simulated score: {'train_score': 0.7299159411193588, 'dev_score': 0.4649275532741641, 'test_score': 0.4631598897487413, 'score': 0.4649275532741641}, Visits: 1

		[Node 0-3-2]
		Plans:
		4. Implement and train a Neural Network with multiple layers to capture hierarchical patterns in the data and evaluate its performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-3-3]
		Plans:
		4. Train multiple models, apply an ensemble method like Gradient Boosting to combine them, and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

		[Node 0-3-4]
		Plans:
		4. Train multiple models, perform hyperparameter tuning using techniques like Grid Search or Random Search, and evaluate their performance
		Simulated: False
		Score: avg score: 0, simulated score: {}, Visits: 0

	[Node 0-4]
	Plans:
	3. Create interaction features by combining existing features, such as the product of velocity and acceleration, to capture complex relationships in the train, dev, and test datasets
	Simulated: False
	Score: avg score: 0, simulated score: {}, Visits: 0

Generated 29 unique codes.
Best node: 0-1-1, score: {'train_score': 1.0, 'dev_score': 0.6944266833187726, 'test_score': 0.6928451194338062, 'score': 0.6944266833187726}
Dev best node: 0-1-1, score: {'train_score': 1.0, 'dev_score': 0.6944266833187726, 'test_score': 0.6928451194338062, 'score': 0.6944266833187726}
)1Number  of  simulations:  102[Node  0]3Plans:41.  Perform  exploratory  data  analysis  on  the  train  and  dev  datasets52.  Preprocess  the  train,  dev,  and  test  datasets63.  Perform  feature  engineering  on  the  train,  dev,  and  test  datasets74.  Train  multiple  models  and  evaluate  their  performance85.  Train  a  weighted  ensemble  model  using  the  best  performing  models96.  Evaluate  the  ensemble  model  on  the  dev  set  and  save  predictions107.  Generate  predictions  for  the  test  set  and  save  them11Simulated:  True12Score:  avg  score:  0.6150206840685731,  simulated  score:  {’train_score’:  1.0,  ’dev_score’:  0.6855841857240594,  ’test_score’:  0.6814818772150697,  ’score’:  0.6855841857240594},  Visits:  101314  [Node  0-0]15  Plans:16  3.  Perform  feature  engineering  on  the  train,  dev,  and  test  datasets  by  creating  new  features  that  calculate  the  magnitude  of  the  vectorial  velocities  and  accelerations  to  capture  the  overall  movement  intensity.17  Simulated:  True18  Score:  avg  score:  0.6507249985568175,  simulated  score:  {’train_score’:  0.982920964830782,  ’dev_score’:  0.6420233166755841,  ’test_score’:  0.647550336228104,  ’score’:  0.6420233166755841},  Visits:  21920  [Node  0-0-0]21  Plans:22  4.  Train  a  Random  Forest  classifier  to  leverage  its  ability  to  handle  high-dimensional  data  and  capture  non-linear  relationships,  and  evaluate  its  performance23  Simulated:  False24  Score:  avg  score:  0,  simulated  score:  {},  Visits:  02526  [Node  0-0-1]27  Plans:28  4.  Train  multiple  models,  including  a  Support  Vector  Machine  (SVM)  with  a  radial  basis  function  (RBF)  kernel,  and  evaluate  their  performance.29  Simulated:  False30  Score:  avg  score:  0,  simulated  score:  {},  Visits:  03132  [Node  0-0-2]33  Plans:34  4.  Implement  a  Neural  Network  with  multiple  layers  to  capture  the  hierarchical  patterns  in  the  data  and  evaluate  its  performance35  Simulated:  True36  Score:  avg  score:  0.6594266804380511,  simulated  score:  {’train_score’:  1.0,  ’dev_score’:  0.6594266804380511,  ’test_score’:  0.6702614538699305,  ’score’:  0.6594266804380511},  Visits:  13738  [Node  0-0-3]39  Plans:40  4.  Train  multiple  models,  apply  an  ensemble  method  like  Gradient  Boosting  to  combine  them,  and  evaluate  their  performance41  Simulated:  False42  Score:  avg  score:  0,  simulated  score:  {},  Visits:  04344  [Node  0-0-4]45  Plans:46  4.  Train  multiple  models,  perform  hyperparameter  tuning  using  Grid  Search  or  Random  Search,  and  evaluate  their  performance47  Simulated:  False48  Score:  avg  score:  0,  simulated  score:  {},  Visits:  04950  [Node  0-1]51  Plans:52  3.  Perform  feature  engineering  on  the  train,  dev,  and  test  datasets  by  generating  time-based  features,  such  as  the  difference  between  consecutive  frames,  to  capture  the  rate  of  change  in  movements.53  Simulated:  True54  Score:  avg  score:  0.6464940718972336,  simulated  score:  {’train_score’:  1.0,  ’dev_score’:  0.5985614604756948,  ’test_score’:  0.5857379626419719,  ’score’:  0.5985614604756948},  Visits:  25556  [Node  0-1-0]57  Plans:58  4.  Train  a  Random  Forest  classifier  to  leverage  its  ability  to  handle  high-dimensional  data  and  capture  non-linear  relationships59  Simulated:  False60  Score:  avg  score:  0,  simulated  score:  {},  Visits:  06162  [Node  0-1-1]63  Plans:64  4.  Train  multiple  models,  including  a  Support  Vector  Machine  (SVM)  with  a  radial  basis  function  (RBF)  kernel,  and  evaluate  their  performance  to  model  the  complex  decision  boundaries  between  different  gesture  phases.65  Simulated:  True66  Score:  avg  score:  0.6944266833187726,  simulated  score:  {’train_score’:  1.0,  ’dev_score’:  0.6944266833187726,  ’test_score’:  0.6928451194338062,  ’score’:  0.6944266833187726},  Visits:  16768  [Node  0-1-2]69  Plans:70  4.  Implement  a  Neural  Network  with  multiple  layers  to  capture  the  hierarchical  patterns  in  the  data  and  evaluate  its  performance71  Simulated:  False72  Score:  avg  score:  0,  simulated  score:  {},  Visits:  07374  [Node  0-1-3]75  Plans:76  4.  Train  multiple  models,  apply  an  ensemble  method  like  Gradient  Boosting  to  combine  them,  and  evaluate  their  performance77  Simulated:  False78  Score:  avg  score:  0,  simulated  score:  {},  Visits:  07980  [Node  0-1-4]81  Plans:82  4.  Train  multiple  models  and  perform  hyperparameter  tuning  using  techniques  like  Grid  Search  or  Random  Search  to  optimize  and  evaluate  their  performance.83  Simulated:  False84  Score:  avg  score:  0,  simulated  score:  {},  Visits:  08586  [Node  0-2]87  Plans:88  3.  Perform  feature  engineering  on  the  train,  dev,  and  test  datasets  by  creating  features  that  represent  the  spatial  relationships  between  different  body  parts,  such  as  the  distance  between  the  hands  and  the  head.89  Simulated:  True90  Score:  avg  score:  0.6296836159165489,  simulated  score:  {’train_score’:  0.7619969104124632,  ’dev_score’:  0.5997286931710517,  ’test_score’:  0.604077566134264,  ’score’:  0.5997286931710517},  Visits:  39192  [Node  0-2-0]93  Plans:94  4.  Train  a  Random  Forest  classifier  to  leverage  its  ability  to  handle  high-dimensional  data  and  capture  non-linear  relationships,  and  evaluate  its  performance95  Simulated:  False96  Score:  avg  score:  0,  simulated  score:  {},  Visits:  09798  [Node  0-2-1]99  Plans:100  4.  Train  multiple  models,  including  a  Support  Vector  Machine  (SVM)  with  a  radial  basis  function  (RBF)  kernel,  and  evaluate  their  performance  to  model  the  complex  decision  boundaries  between  different  gesture  phases.101  Simulated:  True102  Score:  avg  score:  0.6446610772892973,  simulated  score:  {’train_score’:  0.9952809245924918,  ’dev_score’:  0.6372459669415207,  ’test_score’:  0.6423549137767338,  ’score’:  0.6372459669415207},  Visits:  2103104  [Node  0-2-1-0]105  Plans:106  5.  Train  a  weighted  ensemble  model  using  the  best  performing  models  from  task  4107  Simulated:  False108  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0109110  [Node  0-2-1-1]111  Plans:112  5.  Using  the  models  that  performed  best  in  task  4,  train  a  weighted  ensemble  model  to  improve  overall  performance.113  Simulated:  False114  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0115116  [Node  0-2-1-2]117  Plans:118  5.  Develop  a  weighted  ensemble  model  by  integrating  the  top-performing  models  from  task  4,  ensuring  to  evaluate  and  adjust  the  weights  for  optimal  performance.119  Simulated:  True120  Score:  avg  score:  0.6520761876370741,  simulated  score:  {’train_score’:  1.0,  ’dev_score’:  0.6520761876370741,  ’test_score’:  0.6563435152603494,  ’score’:  0.6520761876370741},  Visits:  1121122  [Node  0-2-1-3]123  Plans:124  5.  Train  a  weighted  ensemble  model  by  combining  the  predictions  of  the  top-performing  models  from  task  4  to  improve  overall  performance.125  Simulated:  False126  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0127128  [Node  0-2-1-4]129  Plans:130  5.  Develop  a  weighted  ensemble  model  by  combining  the  top-performing  models  from  task  4,  ensuring  to  optimize  the  weights  for  improved  performance.131  Simulated:  False132  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0133134  [Node  0-2-2]135  Plans:136  4.  Implement  a  Neural  Network  with  multiple  layers  to  capture  the  hierarchical  patterns  in  the  data  and  evaluate  its  performance137  Simulated:  False138  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0139140  [Node  0-2-3]141  Plans:142  4.  Train  multiple  models,  apply  an  ensemble  method  like  Gradient  Boosting  to  combine  them,  and  evaluate  their  performance143  Simulated:  False144  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0145146  [Node  0-2-4]147  Plans:148  4.  Perform  hyperparameter  tuning  using  Grid  Search  or  Random  Search  to  train  multiple  models  and  evaluate  their  performance149  Simulated:  False150  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0151152  [Node  0-3]153  Plans:154  3.  Apply  feature  selection  techniques  such  as  Recursive  Feature  Elimination  (RFE)  or  SelectKBest  to  identify  and  retain  the  most  important  features  in  the  train,  dev,  and  test  datasets.155  Simulated:  True156  Score:  avg  score:  0.49056683315196203,  simulated  score:  {’train_score’:  0.9988177730410426,  ’dev_score’:  0.51620611302976,  ’test_score’:  0.525989891002361,  ’score’:  0.51620611302976},  Visits:  2157158  [Node  0-3-0]159  Plans:160  4.  Train  a  Random  Forest  classifier  to  leverage  its  ability  to  handle  high-dimensional  data  and  capture  non-linear  relationships,  and  evaluate  its  performance.161  Simulated:  False162  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0163164  [Node  0-3-1]165  Plans:166  4.  Train  multiple  models,  including  a  Support  Vector  Machine  (SVM)  with  a  radial  basis  function  (RBF)  kernel,  and  evaluate  their  performance  to  model  the  complex  decision  boundaries  between  different  gesture  phases.167  Simulated:  True168  Score:  avg  score:  0.4649275532741641,  simulated  score:  {’train_score’:  0.7299159411193588,  ’dev_score’:  0.4649275532741641,  ’test_score’:  0.4631598897487413,  ’score’:  0.4649275532741641},  Visits:  1169170  [Node  0-3-2]171  Plans:172  4.  Implement  and  train  a  Neural  Network  with  multiple  layers  to  capture  hierarchical  patterns  in  the  data  and  evaluate  its  performance173  Simulated:  False174  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0175176  [Node  0-3-3]177  Plans:178  4.  Train  multiple  models,  apply  an  ensemble  method  like  Gradient  Boosting  to  combine  them,  and  evaluate  their  performance179  Simulated:  False180  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0181182  [Node  0-3-4]183  Plans:184  4.  Train  multiple  models,  perform  hyperparameter  tuning  using  techniques  like  Grid  Search  or  Random  Search,  and  evaluate  their  performance185  Simulated:  False186  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0187188  [Node  0-4]189  Plans:190  3.  Create  interaction  features  by  combining  existing  features,  such  as  the  product  of  velocity  and  acceleration,  to  capture  complex  relationships  in  the  train,  dev,  and  test  datasets191  Simulated:  False192  Score:  avg  score:  0,  simulated  score:  {},  Visits:  0193194Generated  29  unique  codes.195Best  node:  0-1-1,  score:  {’train_score’:  1.0,  ’dev_score’:  0.6944266833187726,  ’test_score’:  0.6928451194338062,  ’score’:  0.6944266833187726}196Dev  best  node:  0-1-1,  score:  {’train_score’:  1.0,  ’dev_score’:  0.6944266833187726,  ’test_score’:  0.6928451194338062,  ’score’:  0.6944266833187726}'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,TnVtYmVyIG9mIHNpbXVsYXRpb25zOiAxMApbTm9kZSAwXQpQbGFuczoKMS4gUGVyZm9ybSBleHBsb3JhdG9yeSBkYXRhIGFuYWx5c2lzIG9uIHRoZSB0cmFpbiBhbmQgZGV2IGRhdGFzZXRzCjIuIFByZXByb2Nlc3MgdGhlIHRyYWluLCBkZXYsIGFuZCB0ZXN0IGRhdGFzZXRzCjMuIFBlcmZvcm0gZmVhdHVyZSBlbmdpbmVlcmluZyBvbiB0aGUgdHJhaW4sIGRldiwgYW5kIHRlc3QgZGF0YXNldHMKNC4gVHJhaW4gbXVsdGlwbGUgbW9kZWxzIGFuZCBldmFsdWF0ZSB0aGVpciBwZXJmb3JtYW5jZQo1LiBUcmFpbiBhIHdlaWdodGVkIGVuc2VtYmxlIG1vZGVsIHVzaW5nIHRoZSBiZXN0IHBlcmZvcm1pbmcgbW9kZWxzCjYuIEV2YWx1YXRlIHRoZSBlbnNlbWJsZSBtb2RlbCBvbiB0aGUgZGV2IHNldCBhbmQgc2F2ZSBwcmVkaWN0aW9ucwo3LiBHZW5lcmF0ZSBwcmVkaWN0aW9ucyBmb3IgdGhlIHRlc3Qgc2V0IGFuZCBzYXZlIHRoZW0KU2ltdWxhdGVkOiBUcnVlClNjb3JlOiBhdmcgc2NvcmU6IDAuNjE1MDIwNjg0MDY4NTczMSwgc2ltdWxhdGVkIHNjb3JlOiB7J3RyYWluX3Njb3JlJzogMS4wLCAnZGV2X3Njb3JlJzogMC42ODU1ODQxODU3MjQwNTk0LCAndGVzdF9zY29yZSc6IDAuNjgxNDgxODc3MjE1MDY5NywgJ3Njb3JlJzogMC42ODU1ODQxODU3MjQwNTk0fSwgVmlzaXRzOiAxMAoKCVtOb2RlIDAtMF0KCVBsYW5zOgoJMy4gUGVyZm9ybSBmZWF0dXJlIGVuZ2luZWVyaW5nIG9uIHRoZSB0cmFpbiwgZGV2LCBhbmQgdGVzdCBkYXRhc2V0cyBieSBjcmVhdGluZyBuZXcgZmVhdHVyZXMgdGhhdCBjYWxjdWxhdGUgdGhlIG1hZ25pdHVkZSBvZiB0aGUgdmVjdG9yaWFsIHZlbG9jaXRpZXMgYW5kIGFjY2VsZXJhdGlvbnMgdG8gY2FwdHVyZSB0aGUgb3ZlcmFsbCBtb3ZlbWVudCBpbnRlbnNpdHkuCglTaW11bGF0ZWQ6IFRydWUKCVNjb3JlOiBhdmcgc2NvcmU6IDAuNjUwNzI0OTk4NTU2ODE3NSwgc2ltdWxhdGVkIHNjb3JlOiB7J3RyYWluX3Njb3JlJzogMC45ODI5MjA5NjQ4MzA3ODIsICdkZXZfc2NvcmUnOiAwLjY0MjAyMzMxNjY3NTU4NDEsICd0ZXN0X3Njb3JlJzogMC.5ODU1ODQxODU3MjQwNTk0LCAndGVzdF9zY29yZSc6IDAuNj81NzM3OTYyNjQxOTcxOSwgJ3Njb3JlJzogMC42NTk0MjY2ODA0MzgwNTExfSwgVmlzaXRzOiAxCgoJCVtOb2RlIDAtMC0zXQoJCVBsYW5zOgoJCTQuIFRyYWluIG11bHRpcGxlIG1vZGVscywgYXBwbHkgYW4gZW5zZW1ibGUgbWV0aG9kIGxpa2UgR3JhZGllbnQgQm9vc3RpbmcgdG8gY29tYmluZSB0aGVtLCBhbmQgZXZhbHVhdGUgdGhlaXIgcGVyZm9ybWFuY2UKCQlTaW11bGF0ZWQ6IEZhbHNlCgkJU2NvcmU6IGF2ZyBzY29yZTogMCwgc2ltdWxhdGVkIHNjb3JlOiB7fSwgVmlzaXRzOiAwCgoJCVlbTm9kZSAwLTItMS0xXQoJCVBsYW5zOgoJCTQuIFRyYWluIGEgUmFuZG9tIEZvcmVzdCBjbGFzc2lmaWVyIHRvIGxldmVyYWdlIGl0cyBhZGp1c3QgdGhlIHdlaWdodGVkIGVuc2VtYmxlIG1vZGVsIGJhc2lzIGZ1bmN0aW9uIChSQkYpIGtlcm5lbCwgYW5kIGV2YWx1YXRlIHRoZWlyIHBlcmZvcm1hbmNlIHRvIG1vZGVsIHRoZSBjb21wbGV4IGRlY2lzaW9uIGJvdW5kYXJpZXMgYmV0d2VlbiBkaWZmZXJlbnQgZ2VzdHVyZSBwaGFzZXMuCgkJU2ltdWxhdGVkOiBUcnVlCgkJU2NvcmU6IGF2ZyBzY29yZTogMC42OTQ0MjY2ODMzMTg3NzI2LCBzaW11bGF0ZWQgc2NvcmU6IHsndHJhaW5fc2NvcmUnOiAxLjAsICdkZXZfc2NvcmUnOiAwLjU5ODU2MTQ2MDQ3NTY5NDgsICd0ZXN0X3Njb3JlJzogMC41ODU3Mzc5NjI2NDE5NzE5LCAnc2NvcmUnOiAwLjU5ODU2MTQ2MDQ3NTY5NDh9LCBWaXNpdHM6IDIKCgkJW05vZGUgMC0xLTBdCgkJUGxhbnM6CgkJNC4gVHJhaW4gYSBSYW5kb20gRm9yZXN0IGNsYXNzaWZpZXIgdG8gbGV2ZXJhZ2UgaXRzIGFiaWxpdHkgdG8gaGFuZGxlIGhpZ2gtZGltZW5zaW9uYWwgZGF0YSBhbmQgY2FwdHVyZSBub24tbGluZWFyIHJlbGF0aW9uc2hpcHMKCQlTaW11bGF0ZWQ6IEZhbHNlCgkJU2NvcmU6IGF2ZyBzY29yZTogMCwgc2ltdWxhdGVkIHNjb3JlOiB7fSwgVmlzaXRzOiAwCgoJCVlbTm9kZSAwLTItMS0yXQoJCVBsYW5zOgoJCTQuIEV2YWx1YXRlIHRoZSBlbnNlbWJsZSBtb2RlbCBvbiB0aGUgZGV2IHNldCBhbmQgc2F2ZSBwcmVkaWN0aW9ucwo3LiBHZW5lcmF0ZSBwcmVkaWN0aW9ucyBmb3IgdGhlIHRlc3Qgc2V0IGFuZCBzYXZlIHRoZW0KU2ltdWxhdGVkOiBUcnVlClNjb3JlOiBhdmcgc2NvcmU6IDAuNjI5NjgzNjE1OTE2NTQ4OSwgc2ltdWxhdGVkIHNjb3JlOiB7J3RyYWluX3Njb3JlJzogMC.5ODI5MjA5NjQ4MzA3ODIsICdkZXZfc2NvcmUnOiAwLjY0MjAyMzMxNjY3NTU4NDEsICd0ZXN0X3Njb3JlJzogMC.5ODI5MjA5NjQ4MzA3ODJ9LCAndGVzdF9zY29yZSc6IDAuNj81NzM3OTYyNjQxOTcxOSwgJ3Njb3JlJzogMC42NTk0MjY2ODA0MzgwNTExfSwgVmlzaXRzOiAxCgoJCVtOb2RlIDAtM10KCVBsYW5zOgoJMy4gUGVyZm9ybSBmZWF0dXJlIGVuZ2luZWVyaW5nIG9uIHRoZSB0cmFpbiwgZGV2LCBhbmQgdGVzdCBkYXRhc2V0cyBieSBnZW5lcmF0aW5nIHRpbWUtYmFzZWQgZmVhdHVyZXMsIHN1Y2ggYXMgdGhlIGRpZmZlcmVuY2UgYmV0d2VlbiBjb25zZWN'
- en: 'In this case study, we demonstrate how SELA conducts a search cycle using MCTS:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们展示了 SELA 如何使用 MCTS 执行搜索循环：
- en: 'Pre-search Step: Initialization SELA begins by defining high-level stages,
    such as exploratory data analysis, data preprocessing, feature engineering, and
    model training, which structure the overall machine learning workflow. During
    the search, SELA populates these stages with specific insights, which act as experimental
    configurations for simulation.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索前步骤：初始化 SELA 首先定义高层次的阶段，例如探索性数据分析、数据预处理、特征工程和模型训练，这些阶段构建了整体机器学习工作流。在搜索过程中，SELA
    会为这些阶段提供具体的洞察，作为模拟的实验配置。
- en: 'Step 1 & 2: Selection and Expansion SELA leverages MCTS to explore specific
    stages like feature engineering and model training. For example, in one iteration,
    SELA selects Node 0-1\. This node corresponds to a stage insight that generates
    time-based features, expanding into five child nodes representing various model
    specifications and training strategies, such as Random Forests, Support Vector
    Machines, Neural Networks, Gradient Boosting, or Grid Search.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 1 和 2：选择与扩展 SELA 利用 MCTS 来探索特定的阶段，如特征工程和模型训练。例如，在一次迭代中，SELA 选择了节点 0-1。该节点对应于生成基于时间的特征的阶段洞察，并扩展为五个子节点，代表不同的模型规格和训练策略，如随机森林、支持向量机、神经网络、梯度提升或网格搜索。
- en: 'Step 3: Simulation Next, SELA samples one of the expanded child nodes for simulation.
    For instance, when Node 0-1-1 is chosen, SELA runs a complete experiment where
    time-based feature engineering (Node 0-1) is followed by training a Support Vector
    Machine (SVM) with a kernel specified by Node 0-1-1\. The simulation yields an
    evaluation score.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3：模拟 接下来，SELA 会从扩展的子节点中抽取一个进行模拟。例如，当选择节点 0-1-1 时，SELA 会运行一个完整的实验，其中时间特征工程（节点
    0-1）之后，使用节点 0-1-1 指定的核函数训练支持向量机（SVM）。该模拟会产生一个评估分数。
- en: 'Step 4: Backpropagation After the simulation, the resulting performance score
    is propagated back through the tree. For example, after simulating Node 0-1-1,
    MCTS updates the numeric feedback for its parent nodes, such as Node 0-1 and Node
    0\. The search cycle repeats from Steps 1 to 4 until a stopping condition is reached.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 4：反向传播 模拟之后，结果性能评分通过树形结构反向传播。例如，在模拟完节点 0-1-1 后，MCTS 会更新其父节点（如节点 0-1 和节点 0）的数值反馈。搜索循环从步骤
    1 到步骤 4 重复，直到达到停止条件。
- en: 'Post-search Step: Best Node Selection In the final phase, SELA selects the
    node representing the best-performing solution. In this example, Node 0-1-1, using
    an SVM with an RBF kernel, achieved the highest score in the current dataset by
    combining effective feature engineering with advanced model training. SELA then
    presents the code associated with this node as the optimal solution.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索后步骤：最佳节点选择 在最后阶段，SELA 选择代表最佳解决方案的节点。在这个示例中，节点 0-1-1 使用带有 RBF 核的 SVM，在当前数据集中通过将有效的特征工程与高级模型训练相结合，达到了最高的分数。然后，SELA
    将与该节点相关的代码呈现为最优解。
