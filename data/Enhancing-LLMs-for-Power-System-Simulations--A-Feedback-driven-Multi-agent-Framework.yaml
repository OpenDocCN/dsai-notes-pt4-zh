- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2025-01-11 11:53:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:53:42
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent
    Framework'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化大语言模型在电力系统仿真中的应用：一个基于反馈驱动的多智能体框架
- en: 来源：[https://arxiv.org/html/2411.16707/](https://arxiv.org/html/2411.16707/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2411.16707/](https://arxiv.org/html/2411.16707/)
- en: Mengshuo Jia, , Zeyu Cui, , and Gabriela Hug,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Mengshuo Jia、Zeyu Cui 和 Gabriela Hug
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The integration of experimental technologies with large language models (LLMs)
    is transforming scientific research, positioning AI as a versatile research assistant
    rather than a mere problem-solving tool. In the field of power systems, however,
    managing simulations — one of the essential experimental technologies — remains
    a challenge for LLMs due to their limited domain-specific knowledge, restricted
    reasoning capabilities, and imprecise handling of simulation parameters. To address
    these limitations, we propose a feedback-driven, multi-agent framework that incorporates
    three proposed modules: an enhanced retrieval-augmented generation (RAG) module,
    an improved reasoning module, and a dynamic environmental acting module with an
    error-feedback mechanism. Validated on 69 diverse tasks from Daline and MATPOWER,
    this framework achieves success rates of 93.13% and 96.85%, respectively, significantly
    outperforming the latest LLMs (ChatGPT 4o and o1-preview), which achieved a 27.77%
    success rate on standard simulation tasks and 0% on complex tasks. Additionally,
    our framework also supports rapid, cost-effective task execution, completing each
    simulation in approximately 30 seconds at an average cost of 0.014 USD for tokens.
    Overall, this adaptable framework lays a foundation for developing intelligent
    LLM-based assistants for human researchers, facilitating power system research
    and beyond.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 将实验技术与大语言模型（LLMs）结合，正在改变科学研究，推动人工智能成为一个多功能的研究助手，而非仅仅是一个问题求解工具。然而，在电力系统领域，仿真管理作为一种重要的实验技术，仍然是大语言模型面临的一大挑战，因为它们在领域特定知识、推理能力有限以及仿真参数处理上不够精确。为了解决这些问题，我们提出了一个基于反馈驱动的多智能体框架，框架中包含三个提出的模块：增强型检索增强生成（RAG）模块、改进的推理模块和带有误差反馈机制的动态环境作用模块。在Daline和MATPOWER的69个多样化任务上进行验证后，该框架分别达到了93.13%和96.85%的成功率，显著超越了最新的大语言模型（ChatGPT
    4o和o1-preview），后者在标准仿真任务上的成功率为27.77%，在复杂任务上的成功率为0%。此外，我们的框架还支持快速、低成本的任务执行，每次仿真大约在30秒内完成，令令牌的平均成本为0.014美元。总体而言，这一可适应的框架为开发基于智能大语言模型的助手奠定了基础，促进了电力系统研究及其他领域的发展。
- en: 'Index Terms:'
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Large Language Models, Agents, Power Systems, Simulation, Retrieval-augmented
    Generation, Reason
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型、智能体、电力系统、仿真、增强检索生成、推理
- en: I Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Combining laboratory automation technologies with large language models (LLMs)
    enables automated execution of scientific experiments [[1](https://arxiv.org/html/2411.16707v1#bib.bib1)].
    Related advances span the fields of mathematics, chemistry, and clinical research,
    including mathematical algorithm evolution [[2](https://arxiv.org/html/2411.16707v1#bib.bib2)],
    geometry theorem proving [[3](https://arxiv.org/html/2411.16707v1#bib.bib3)],
    chemical experiment design and execution [[1](https://arxiv.org/html/2411.16707v1#bib.bib1)],
    as well as the development and validation of machine learning approaches for clinical
    studies [[4](https://arxiv.org/html/2411.16707v1#bib.bib4)]. These recent achievements
    signal a new research paradigm, positioning AI as a research assistant for humans
    with natural language communication abilities, rather than merely a specialized
    problem solver as in the past. Establishing LLMs as research assistants also holds
    significant potential for advancing power systems research.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 将实验室自动化技术与大语言模型（LLMs）结合，可以实现科学实验的自动化执行[[1](https://arxiv.org/html/2411.16707v1#bib.bib1)]。相关的进展涵盖了数学、化学和临床研究领域，包括数学算法的演化[[2](https://arxiv.org/html/2411.16707v1#bib.bib2)]、几何定理证明[[3](https://arxiv.org/html/2411.16707v1#bib.bib3)]、化学实验设计与执行[[1](https://arxiv.org/html/2411.16707v1#bib.bib1)]，以及临床研究中机器学习方法的开发与验证[[4](https://arxiv.org/html/2411.16707v1#bib.bib4)]。这些最新的成就标志着一种新的研究范式，定位人工智能为具有自然语言沟通能力的研究助手，而不仅仅是过去那种专门的难题求解者。将大语言模型确立为研究助手，还具有推动电力系统研究的重要潜力。
- en: 'Given the heavy reliance on simulations in power systems research, developing
    LLM-based assistants in this field requires equipping LLMs with the capability
    to conduct power system simulations. Enabling LLMs to execute simulation tasks
    has multiple implications: (i) At the assistant level, LLMs capable of conducting
    simulations would allow researchers to focus more on idea-intensive activities,
    such as simulation design, rather than on labor-intensive tasks like simulation
    implementation. (ii) At the interface level, LLMs conducting simulations might
    offer a natural-language interface. This interface can connect simulation tasks
    with other upstream/downstream power system tasks using natural language as the
    input/output. This is particularly helpful when these tasks’ original inputs and
    outputs are heterogeneous (e.g., different modalities) and originally challenging
    to program cohesively using regular codes. (iii) At the coding level, LLMs executing
    simulations might be a step toward natural language coding in power systems. This
    might signify an evolution in programming, bringing it closer to a more intuitive,
    language-driven approach, a long-standing goal of programming development for
    decades.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于电力系统研究中对仿真工具的高度依赖，开发基于LLM的助手工具需要为LLMs提供执行电力系统仿真的能力。使LLMs能够执行仿真任务具有多重意义：（i）在助手层面，能够进行仿真的LLMs将使研究人员能够更多地专注于创意密集型的活动，如仿真设计，而非像仿真实施那样的劳动密集型任务。（ii）在接口层面，执行仿真的LLMs可能会提供一个自然语言接口。该接口能够通过自然语言作为输入/输出，将仿真任务与其他上游/下游电力系统任务连接起来。特别是在这些任务的原始输入和输出是异构的（例如，不同的模态）并且使用常规代码编程时难以实现统一时，这种接口非常有用。（iii）在编码层面，执行仿真的LLMs可能是电力系统中自然语言编码的一步。这可能标志着编程的演变，将编程推向更直观、语言驱动的方法，这是编程发展几十年来的一个长期目标。
- en: 'However, LLMs inherently lack the capability to perform power system simulations.
    For recently developed simulation tools not included in LLM pre-training datasets,
    LLMs generally cannot execute these simulations accurately. Even for well-established
    tools included in pre-training data, simulation precision remains unsatisfactory.
    For instance, GPT-4 often has difficulty creating small distribution grids using
    OpenDSS [[5](https://arxiv.org/html/2411.16707v1#bib.bib5)] or writing code for
    simple (optimal) power flow problems [[6](https://arxiv.org/html/2411.16707v1#bib.bib6)],
    even though information about both OpenDSS and (optimal) power flow is available
    within GPT-4’s pre-training dataset. While the underlying causes of this issue
    have not been widely discussed and recognized in the energy domain, we propose
    the following factors as potential explanations:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LLMs本质上缺乏执行电力系统仿真的能力。对于那些未包含在LLM预训练数据集中的新开发仿真工具，LLMs通常无法准确执行这些仿真。即便是那些已包含在预训练数据中的成熟工具，仿真精度依然不令人满意。例如，尽管GPT-4的预训练数据集中有关于OpenDSS和（最优）潮流的信息，但GPT-4在使用OpenDSS创建小型配电网[[5](https://arxiv.org/html/2411.16707v1#bib.bib5)]或编写简单（最优）潮流问题的代码[[6](https://arxiv.org/html/2411.16707v1#bib.bib6)]时，仍然存在困难。虽然这一问题的根本原因在能源领域尚未得到广泛讨论和认可，但我们提出以下因素作为可能的解释：
- en: •
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Frequency: The low frequency of domain-specific power system knowledge in LLM
    training datasets — especially in the long tail of rarely encountered data — limits
    the models’ ability to generalize effectively for specialized simulation tasks
    [[7](https://arxiv.org/html/2411.16707v1#bib.bib7)].'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 频率：电力系统领域特定知识在LLM训练数据集中出现的频率较低——特别是在那些很少遇到的数据的长尾部分——这限制了模型在专门仿真任务中的泛化能力[[7](https://arxiv.org/html/2411.16707v1#bib.bib7)]。
- en: •
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Quality: High-quality, instruction-tuned, or query-based coding data specific
    to power system simulations in available open-source data is lacking. Missing
    explanatory code annotations make it difficult for LLMs to fully contextualize
    and operationalize power system simulations.'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 质量：在现有的开源数据中，缺乏与电力系统仿真相关的高质量、经过指令调优或基于查询的编码数据。缺失的代码注释使得大型语言模型（LLMs）难以充分理解和操作电力系统仿真。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Complexity: The multi-step reasoning required by complex power system simulations
    is inherently challenging, particularly given sparse or ambiguous representations
    in the model’s learned patterns w.r.t. power system simulations.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 复杂性：复杂电力系统仿真所需的多步骤推理本质上具有挑战性，特别是在模型学习到的模式中，电力系统仿真呈现出稀疏或模糊的表现时。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Precision: Precise identification of simulation parameters, functions, and
    their logical connections, poses high demands on LLMs, especially when LLMs’ knowledge
    about simulations is incomplete or fragmented. This may result in a semantic drift,
    causing LLMs’ code generation to gradually deviate from the accurate version.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 精确性：精确识别仿真参数、函数及其逻辑关系，对大语言模型（LLM）提出了很高的要求，尤其是在LLM对仿真知识了解不完全或存在碎片化的情况下。这可能导致语义漂移，使LLM生成的代码逐渐偏离准确版本。
- en: 'The challenges outlined above can be grouped into three main limitations: (i)
    limited simulation-specific knowledge, (ii) restricted reasoning capabilities
    for simulation tasks, and (iii) imprecision in function and option application.
    Enhancing the simulation capability of LLMs requires addressing these limitations.
    However, few existing works have explicitly focused on overcoming the above barriers
    to improve the simulation capability of LLMs, even though LLM applications in
    power systems are growing rapidly. Specifically, in power systems, LLMs have been
    recently used to translate language-based rules into mathematical constraints
    to facilitate optimal power flow (OPF) analysis, bridging the gap between rule-based
    and computational methods [[8](https://arxiv.org/html/2411.16707v1#bib.bib8)].
    Researchers have also leveraged LLMs to interpret decision-making processes in
    real-time market, enhancing the transparency of deep reinforcement learning systems
    by revealing decision rationales [[9](https://arxiv.org/html/2411.16707v1#bib.bib9)].
    Additionally, LLMs have been employed to retrieve and summarize documents in response
    to specific power system queries [[10](https://arxiv.org/html/2411.16707v1#bib.bib10)].
    In other work, LLMs have been applied to derive OPF solutions iteratively by utilizing
    historical cost-solution data [[10](https://arxiv.org/html/2411.16707v1#bib.bib10)].
    LLMs have also facilitated gathering user preference w.r.t. electric vehicles
    charging, where user inputs are integrated to refine functions for EV charging
    optimization problems [[10](https://arxiv.org/html/2411.16707v1#bib.bib10)]. Furthermore,
    by combining LLMs with retrieval-augmented generation (RAG), researchers develop
    a carbon footprint accounting system capable of dynamically retrieving and integrating
    real-time, domain-specific carbon data [[11](https://arxiv.org/html/2411.16707v1#bib.bib11)].
    Moreover, for cybersecurity applications, LLMs have played a role in anomaly detection
    to enhance system security [[12](https://arxiv.org/html/2411.16707v1#bib.bib12)].
    In forecasting, LLMs, such as LLaMa2, have been used to integrate social event
    data into time series models, enhancing the accuracy and contextual relevance
    of predictions, for example, in electricity demand [[13](https://arxiv.org/html/2411.16707v1#bib.bib13)].
    Also, LLMs have supported perception analysis by evaluating media sentiment and
    public acceptance levels of solar power initiatives, providing insights into public
    opinion trends [[14](https://arxiv.org/html/2411.16707v1#bib.bib14)]. Moreover,
    a comprehensive benchmarking framework for LLMs has been proposed for the energy
    domain in [[15](https://arxiv.org/html/2411.16707v1#bib.bib15)], helping to establish
    standardized evaluation criteria for LLMs in energy-related applications. On the
    other hand, potential cybersecurity threats, arising due to the application of
    LLMs in power systems, have also been analyzed and summarized [[16](https://arxiv.org/html/2411.16707v1#bib.bib16)].'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/30c1bfcde85b3897725bc65d22a42bf6.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/30c1bfcde85b3897725bc65d22a42bf6.png)'
- en: 'Figure 1: The feedback-driven multi-agent framework. It consists of an enhanced
    RAG module, an advanced reasoning module, and an environmental interaction module,
    all interconnected through an error feedback mechanism. This framework enables
    iterative refinement by incorporating simulation-specific knowledge, improving
    reasoning for complex simulation tasks, and facilitating environmental interaction
    to generate accurate simulation results.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：基于反馈的多智能体框架。它由一个增强的RAG模块、一个先进的推理模块和一个环境交互模块组成，所有模块通过错误反馈机制互联。这一框架通过融入特定于仿真的知识，支持反复迭代改进，提升复杂仿真任务的推理能力，并促进环境交互以生成准确的仿真结果。
- en: Despite the various applications mentioned above, only a few studies have focused
    directly on using LLMs for power system simulations. These studies, however, only
    focus on conceptualizing the potential of LLMs in the simulation field [[17](https://arxiv.org/html/2411.16707v1#bib.bib17)],
    showcasing their current capabilities [[18](https://arxiv.org/html/2411.16707v1#bib.bib18),
    [17](https://arxiv.org/html/2411.16707v1#bib.bib17)], and assessing their effectiveness
    in generating general-purpose code for power system studies [[5](https://arxiv.org/html/2411.16707v1#bib.bib5),
    [6](https://arxiv.org/html/2411.16707v1#bib.bib6)]. While these studies offer
    valuable insights, they did not address the limitations pointed out earlier that
    limit LLMs’ simulation performance. Although the standard RAG approach used in
    [[19](https://arxiv.org/html/2411.16707v1#bib.bib19), [17](https://arxiv.org/html/2411.16707v1#bib.bib17),
    [6](https://arxiv.org/html/2411.16707v1#bib.bib6)] can indeed enable LLMs to incorporate
    external power systems knowledge, it is unsuitable for simulation tasks. This
    is because the standard RAG retrieves information based on the entire request
    as a single unit, which fails to capture the nuanced structure of complex simulation
    requests, often conflating distinct function-related and option-related elements,
    thereby leading to inefficiencies and reduced retrieval accuracy. Consequently,
    existing works fall short of systematically developing and advancing LLMs’ capability
    to handle complex power system simulations.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如上所述有多种应用，但只有少数研究专门关注使用LLM进行电力系统仿真。然而，这些研究仅仅集中于构思LLM在仿真领域的潜力[[17](https://arxiv.org/html/2411.16707v1#bib.bib17)]，展示了它们在当前的能力[[18](https://arxiv.org/html/2411.16707v1#bib.bib18),
    [17](https://arxiv.org/html/2411.16707v1#bib.bib17)]，并评估了它们在生成电力系统研究的通用代码方面的有效性[[5](https://arxiv.org/html/2411.16707v1#bib.bib5),
    [6](https://arxiv.org/html/2411.16707v1#bib.bib6)]。尽管这些研究提供了有价值的见解，但它们并没有解决之前提到的限制，限制了LLM在仿真中的表现。尽管在[[19](https://arxiv.org/html/2411.16707v1#bib.bib19),
    [17](https://arxiv.org/html/2411.16707v1#bib.bib17), [6](https://arxiv.org/html/2411.16707v1#bib.bib6)]中使用的标准RAG方法确实使得LLM能够融合外部电力系统知识，但它并不适用于仿真任务。这是因为标准RAG基于整个请求作为一个单元来检索信息，这未能捕捉到复杂仿真请求的细微结构，常常将不同的功能相关和选项相关的元素混淆，从而导致效率低下和检索准确性降低。因此，现有工作未能系统地发展和提升LLM处理复杂电力系统仿真的能力。
- en: 'To bridge this gap and enhance LLMs’ capability in power system simulations,
    this paper proposes a modular, feedback-driven, multi-agent framework that integrates
    several innovative strategies, as shown in Fig. [1](https://arxiv.org/html/2411.16707v1#S1.F1
    "Figure 1 ‣ I Introduction ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework"). Accordingly, this paper contributes in the following
    ways:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了弥合这一差距并增强LLM在电力系统仿真中的能力，本文提出了一个模块化、基于反馈的多智能体框架，该框架整合了几种创新策略，如图[1](https://arxiv.org/html/2411.16707v1#S1.F1
    "图1 ‣ I 引言 ‣ 增强LLM用于电力系统仿真：一个基于反馈的多智能体框架")所示。因此，本文的贡献如下：
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose an enhanced RAG module with an adaptive query planning strategy and
    a triple-based structure (i.e. linking options, functions, and their dependencies)
    for the knowledge base. This module not only expands the LLM’s accessible knowledge
    in an efficient and cost-effective manner, but also enables LLMs to better identify
    and interpret simulation functions, options, and their logical relationships than
    the standard RAG.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种增强的RAG模块，具有自适应查询规划策略和基于三元组的结构（即链接选项、功能及其依赖关系）用于知识库。该模块不仅以高效且具有成本效益的方式扩展了LLM可访问的知识，而且使得LLM能够比标准RAG更好地识别和解释仿真功能、选项及其逻辑关系。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We develop an enhanced reasoning module by leveraging simulation-specific expertise,
    chain-of-thought prompting (CoT) and few-shot prompting. This module enables LLMs
    to fully understand their role, assigned tasks, reasoning pathways, and contextual
    knowledge (including retrieved information) in simulation tasks, thereby strengthening
    their reasoning capabilities when generating simulation code.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过利用特定于仿真的专业知识、思维链提示（CoT）和少量示例提示，开发了增强型推理模块。该模块使大型语言模型（LLMs）能够全面理解其角色、分配的任务、推理路径以及仿真任务中的上下文知识（包括检索到的信息），从而在生成仿真代码时增强其推理能力。
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We further propose a feedback-driven, multi-agent framework that integrates
    the enhanced RAG and reasoning modules with an environmental interaction and error-correction
    mechanism. This framework facilitates both action execution and feedback reception,
    providing responsive error signals to initiate adaptive adjustments for the RAG
    and reasoning modules to automatically correct errors, thereby enhancing the reliability
    of simulation outcomes.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们进一步提出了一个反馈驱动的多智能体框架，将增强型RAG和推理模块与环境交互和错误修正机制整合在一起。该框架既促进了行动执行，又支持反馈接收，提供响应性的错误信号，启动适应性调整，使RAG和推理模块能够自动纠正错误，从而提高仿真结果的可靠性。
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Through testing across various strategies, simulation environments, and a diverse
    range of tasks, we reveal that even the latest LLM, o1-preview, struggles with
    power system simulation tasks, including those involving well-established tools
    like MATPOWER, despite prior exposure in the pre-training of the LLM. We further
    reveal that high simulation success rates depend on the cumulative effect of multiple
    strategies. Following this idea, our framework demonstrates high success rates,
    enabling cost-effective, rapid task completion, thereby providing a scalable tool
    for power system researchers.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过在各种策略、仿真环境和多种任务中的测试，我们揭示了即使是最新的LLM（如o1-preview）在处理电力系统仿真任务时也存在困难，包括涉及MATPOWER等成熟工具的任务，尽管这些内容在LLM的预训练中已有涉及。我们进一步揭示，高仿真成功率依赖于多种策略的累积效果。基于这一思路，我们的框架展现了较高的成功率，使得任务能够高效、快速地完成，从而为电力系统研究人员提供了一个可扩展的工具。
- en: 'This paper, as a substantial extension of our preliminary work in [[20](https://arxiv.org/html/2411.16707v1#bib.bib20)],
    is structured as follows: Section II introduces the enhanced RAG module. Section
    III presents the enhanced reasoning module, and Section IV describes the environmental
    acting module with the feedback mechanism. Finally, Section V presents case study
    results, while Section VI concludes the paper with key findings and future outlook.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本文作为我们在[[20](https://arxiv.org/html/2411.16707v1#bib.bib20)]中初步工作的重大扩展，结构安排如下：第二节介绍了增强型RAG模块。第三节展示了增强型推理模块，第四节描述了具有反馈机制的环境交互模块。最后，第五节展示了案例研究结果，第六节总结了本文的关键发现和未来展望。
- en: II Enhanced RAG Module
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 增强型RAG模块
- en: 'As an efficient and scalable approach for integrating external knowledge to
    LLMs, RAG consists of three key steps: external knowledge chunking (splitting
    documents into smaller pieces), text embedding (converting texts into vectors
    using neural networks such as text2vec), and information retrieval (finding information
    in the vector space that aligns with the query) [[6](https://arxiv.org/html/2411.16707v1#bib.bib6)].
    Fig. [3](https://arxiv.org/html/2411.16707v1#S2.F3 "Figure 3 ‣ II Enhanced RAG
    Module ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent
    Framework") illustrates a general RAG diagram. However, for power system simulations,
    critical questions arise: (i) what types of queries should be used for retrieval?
    and (ii) what knowledge base should serve as the retrieval repository? Addressing
    these questions reveals two primary areas for enhancing RAG’s effectiveness in
    simulation tasks.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种高效且可扩展的外部知识整合方法，RAG由三个关键步骤组成：外部知识切块（将文档拆分成更小的片段）、文本嵌入（使用神经网络如text2vec将文本转换为向量）和信息检索（在向量空间中找到与查询相匹配的信息）[[6](https://arxiv.org/html/2411.16707v1#bib.bib6)]。图[3](https://arxiv.org/html/2411.16707v1#S2.F3
    "图3 ‣ II 增强型RAG模块 ‣ 通过反馈驱动的多智能体框架提升LLM在电力系统仿真中的应用")展示了一个通用的RAG图示。然而，对于电力系统仿真，出现了几个关键问题：（i）应使用什么类型的查询进行检索？以及（ii）应使用什么知识库作为检索的存储库？解决这些问题揭示了两个主要领域，以增强RAG在仿真任务中的效果。
- en: 'To this end, we propose an enhanced RAG module. This is specifically designed
    to integrate power system simulation knowledge into LLMs and reduce hallucinations.
    This module emphasizes the identification of essential keywords in simulation
    requests to facilitate more precise knowledge retrieval than the standard RAG.
    It includes two main components: (i) an adaptive query planning strategy, and
    (ii) a triple-based structure design for the knowledge base. Together, these components
    provide an enhanced RAG for complex power system simulation tasks.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们提出了一种增强型RAG模块。该模块专门设计用于将电力系统仿真知识集成到LLM中，并减少幻觉现象。该模块强调在仿真请求中识别关键字，以便比标准RAG实现更精确的知识检索。它包括两个主要组件：（i）自适应查询规划策略，和（ii）基于三元组的知识库结构设计。通过这两个组件，提供了一个增强型RAG，用于处理复杂的电力系统仿真任务。
- en: '![Refer to caption](img/5428c122dfec7fad0398b80219a83a39.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/5428c122dfec7fad0398b80219a83a39.png)'
- en: 'Figure 2: Enhanced RAG module for simulation tasks. (a) The retrieval agent
    decomposes simulation requests into function-related and option-related sub-queries,
    mapped to specific functions and options for precise keyword-based retrieval.
    (b) Structured prompt design detailing keyword extraction steps via few-shot CoT.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：用于仿真任务的增强型RAG模块。（a）检索代理将仿真请求分解为与功能相关和与选项相关的子查询，并映射到特定功能和选项上，以实现基于关键字的精确检索。（b）结构化提示设计，详细说明通过少量示例的链式推理（CoT）提取关键字的步骤。
- en: '![Refer to caption](img/e41ca773459a3fff22b0fda17a7c2658.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/e41ca773459a3fff22b0fda17a7c2658.png)'
- en: 'Figure 3: General RAG diagram, including the process of external knowledge
    chunking, text embedding, and parallel retrieval within a vector database to produce
    relevant retrieval output based on the input queries and the external knowledge
    base. The text embedding model used in this study is from [[here]](https://help.aliyun.com/zh/dashscope/developer-reference/text-embedding-quick-start?spm=a2c4g.11186623.0.0.5695f97eD8MhdE).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：通用RAG图示，包含外部知识块划分、文本嵌入和在向量数据库中并行检索的过程，以根据输入查询和外部知识库生成相关的检索输出。本研究中使用的文本嵌入模型来自[[此处]](https://help.aliyun.com/zh/dashscope/developer-reference/text-embedding-quick-start?spm=a2c4g.11186623.0.0.5695f97eD8MhdE)。
- en: II-A Adaptive Query Planning
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 自适应查询规划
- en: 'This section addresses the question of what types of queries should be used
    for retrieval. In the standard RAG approach, the entire simulation request is
    processed as a single unit, which, as discussed (and will be demonstrated in case
    studies), conflates distinct elements in the request, leading to inefficiencies
    and reduced retrieval accuracy. In fact, simulation requests typically contain
    two critical elements: the functions to be used and the options to be set. Thus,
    we propose using functions and options as distinct retrieval queries. However,
    these elements are rarely stated explicitly in simulation requests; instead, they
    are embedded in natural language descriptions.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论了应使用何种类型的查询进行检索。在标准RAG方法中，整个仿真请求作为一个整体进行处理，这如前所述（并将在案例研究中展示），会将请求中的不同元素混淆，导致低效并降低检索准确性。实际上，仿真请求通常包含两个关键元素：要使用的功能和要设置的选项。因此，我们建议将功能和选项作为独立的检索查询。然而，这些元素在仿真请求中很少明确指出；相反，它们通常嵌入在自然语言描述中。
- en: 'To address this, we develop an agent-driven adaptive query planning strategy,
    as shown in Fig. [2](https://arxiv.org/html/2411.16707v1#S2.F2 "Figure 2 ‣ II
    Enhanced RAG Module ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework")(a), which automatically extracts function-related and
    option-related queries from the broader request to serve as retrieval keywords.
    The strategy operates in two phases: semantic recognition and keyword mapping,
    carried out by a retrieval agent (e.g., a general LLM). In the semantic recognition
    phase, the agent categorizes the request into two query types: function-related
    and option-related. Each function-related query is then decomposed into sub-queries,
    each corresponding to a potential simulation function to be used. Similarly, option-related
    queries are broken down into sub-queries, each linked to a potential option to
    be configured. This systematic separation ensures independent processing of each
    component within the request.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们开发了一种基于代理的自适应查询规划策略，如图[2](https://arxiv.org/html/2411.16707v1#S2.F2
    "图2 ‣ II 增强型RAG模块 ‣ 增强LLM在电力系统仿真中的应用：基于反馈的多代理框架")(a)所示，该策略自动从更广泛的请求中提取与功能和选项相关的查询，作为检索关键词。该策略分为两个阶段：语义识别和关键词映射，由检索代理（例如，一般LLM）执行。在语义识别阶段，代理将请求分类为两种查询类型：与功能相关的查询和与选项相关的查询。每个与功能相关的查询随后被分解为子查询，每个子查询对应一个潜在的仿真功能。类似地，与选项相关的查询被分解为子查询，每个子查询与一个潜在的选项配置相关联。这种系统化的分离确保了请求中每个组件的独立处理。
- en: Following semantic recognition, the keyword mapping phase aligns each identified
    function and option sub-query with its precise keywords. For functions, the keywords
    are the functions’ names. For options, sub-queries are further associated with
    their respective descriptions and values. Ultimately, the extracted functions,
    option descriptions, and values are entered as parallel retrieval queries.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在语义识别之后，关键词映射阶段将每个已识别的功能和选项子查询与其精确的关键词对齐。对于功能，关键词是功能的名称。对于选项，子查询进一步与其相应的描述和值相关联。最终，提取出的功能、选项描述和值作为并行检索查询输入。
- en: 'To enable the retrieval agent to perform both semantic recognition and keyword
    mapping effectively, we design a structured, general action prompt that integrates
    chain-of-thought prompting (CoT) [[21](https://arxiv.org/html/2411.16707v1#bib.bib21)]
    and few-shot prompting [[22](https://arxiv.org/html/2411.16707v1#bib.bib22)] (i.e.,
    few-shot CoT), as depicted in Fig. [2](https://arxiv.org/html/2411.16707v1#S2.F2
    "Figure 2 ‣ II Enhanced RAG Module ‣ Enhancing LLMs for Power System Simulations:
    A Feedback-driven Multi-agent Framework")(b). Only the few-shot examples are tool-dependent,
    making them modular and easily adaptable, while the rest of the prompt remains
    general and independent of specific simulation tools.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使检索代理能够有效地执行语义识别和关键词映射，我们设计了一个结构化的通用行动提示，结合了链式思维提示（CoT）[[21](https://arxiv.org/html/2411.16707v1#bib.bib21)]和少量示例提示[[22](https://arxiv.org/html/2411.16707v1#bib.bib22)]（即少量示例CoT），如图[2](https://arxiv.org/html/2411.16707v1#S2.F2
    "图2 ‣ II 增强型RAG模块 ‣ 增强LLM在电力系统仿真中的应用：基于反馈的多代理框架")(b)所示。只有少量示例依赖于工具，使其具有模块化和易于适配的特点，而其余提示保持通用，独立于具体的仿真工具。
- en: II-B Triple-based Structure Design for Knowledge Base
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 基于三元组的知识库结构设计
- en: 'In this section, we address the question of which knowledge base should serve
    as the retrieval repository. While each power system simulation tool includes
    a user manual with detailed instructions, this manual is not an ideal retrieval
    repository. The reasons are twofold: (i) User manuals are designed for human readability
    rather than automated retrieval; although readable, they are unstructured and
    inefficient for machine-driven queries, especially when manuals primarily consist
    of formulas, tables, and figures. (ii) The main challenge for LLMs in generating
    simulation code is understanding the logical dependencies between options and
    functions, as many options are function-dependent. Using only the user manual
    for retrieval fails to capture these complex relationships effectively.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了应该选择哪个知识库作为检索库。尽管每个电力系统仿真工具都包含带有详细说明的用户手册，但该手册并不是理想的检索库。原因有两个：（i）用户手册是为了便于人类阅读而设计的，而非为了自动化检索；虽然可读性较强，但其结构松散，对于机器驱动的查询效率低下，尤其是当手册主要由公式、表格和图形组成时。（ii）LLM在生成仿真代码时的主要挑战是理解选项和功能之间的逻辑依赖关系，因为许多选项依赖于功能。仅使用用户手册进行检索无法有效捕捉这些复杂关系。
- en: 'To overcome these issues, we propose an additional, easy-to-construct retrieval
    repository: a triple-based structured option document. In this document, each
    line represents an option, providing the following structured information in sequence:
    (i) option name, (ii) default value/format, (iii) function dependencies, and (iv)
    option description. The inclusion of triples in (iii) — linking each option, its
    related functions, and their dependency — enables retrieval for logical relationships.
    As will demonstrated in case studies, this supplementary repository significantly
    enhances retrieval efficiency and improves the accuracy of simulation code generation
    by preserving the logical context.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些问题，我们提出了一种额外的、易于构建的检索库：基于三元组的结构化选项文档。在该文档中，每一行代表一个选项，按顺序提供以下结构化信息：（i）选项名称，（ii）默认值/格式，（iii）功能依赖关系，以及（iv）选项描述。三元组的包含（iii）—将每个选项、相关功能及其依赖关系连接起来—使得逻辑关系的检索成为可能。正如案例研究中所展示的那样，这种补充库显著提高了检索效率，并通过保留逻辑上下文提高了仿真代码生成的准确性。
- en: III Enhanced Reasoning Module
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 增强型推理模块
- en: Even though the enhanced RAG module provides LLMs with retrieval results tailored
    to a simulation request, it still remains essential to strengthen the LLM’s reasoning
    abilities to generate correct simulation codes based on the retrieval results.
    This requires a coding agent (i.e., another LLM) to write codes for simulations
    tasks. This agent needs to fully understand its role, assigned tasks, reasoning
    path, and contextual knowledge, including retrieval results, when handling simulation
    tasks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管增强型RAG模块为大语言模型（LLM）提供了针对仿真请求量身定制的检索结果，但仍然需要强化LLM的推理能力，以便根据检索结果生成正确的仿真代码。这需要一个编码代理（即另一个LLM）来编写仿真任务的代码。该代理需要充分理解自己的角色、分配的任务、推理路径以及处理仿真任务时所需的上下文知识，包括检索结果。
- en: 'To address this, we propose an enhanced reasoning module, as detailed in Fig.
    [4](https://arxiv.org/html/2411.16707v1#S3.F4 "Figure 4 ‣ III Enhanced Reasoning
    Module ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent
    Framework"). It provides structured guidance, sequential reasoning steps, and
    contextual knowledge to support accurate code generation by the coding agent.
    Details are as follows.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决这一问题，我们提出了一个增强型推理模块，如图[4](https://arxiv.org/html/2411.16707v1#S3.F4 "Figure
    4 ‣ III Enhanced Reasoning Module ‣ Enhancing LLMs for Power System Simulations:
    A Feedback-driven Multi-agent Framework")所示。该模块提供结构化指导、顺序推理步骤和上下文知识，以支持编码代理准确生成代码。详细信息如下。'
- en: '![Refer to caption](img/8fdd6651e7a6c611c3629c1546f3b85f.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/8fdd6651e7a6c611c3629c1546f3b85f.png)'
- en: 'Figure 4: Enhanced reasoning module for simulation code generation: (a) Core
    Concept, defining the coding agent’s role, assigned tasks, reasoning path, and
    contextual knowledge. (b) Structured prompt design equipped with few-shot CoT,
    in order to enhance the agent’s reasoning ability for simulation. (c) Coding agent
    workflow integrating the designed prompt and simulation request to produce simulation
    code.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：仿真代码生成的增强型推理模块：（a）核心概念，定义编码代理的角色、分配的任务、推理路径和上下文知识。（b）配备少量样本CoT的结构化提示设计，以增强代理的仿真推理能力。（c）编码代理工作流程，整合设计的提示和仿真请求生成仿真代码。
- en: III-A Role and Functionality Definition
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 角色与功能定义
- en: The agent deployed in this module is designated as a simulation coding agent
    for a specific simulation tool. Its primary function is to generate syntax-compliant
    simulation code that aligns with the specific task requirements, the static provided
    knowledge, and the dynamically retrieved knowledge.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 部署在该模块中的代理被指定为特定仿真工具的仿真编码代理。其主要功能是生成符合语法规范的仿真代码，符合特定任务要求、静态提供的知识和动态检索到的知识。
- en: III-B Reasoning Framework
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 推理框架
- en: 'To enable systematic, tool-independent reasoning, we develop a few-shot CoT
    framework, which breaks down the simulation task into the following universal
    actions:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现系统化、与工具无关的推理，我们开发了一个少量样本CoT框架，将仿真任务分解为以下通用操作：
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Function Identification: Determines the functions relevant to the simulation
    task.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 功能识别：确定与仿真任务相关的功能。
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Function Syntax Learning: Acquires the correct syntax for identified functions
    to ensure compliance with the simulation tool’s requirements.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 功能语法学习：获取已识别功能的正确语法，确保符合仿真工具的要求。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Option Information Extraction: Identifies options and extracts their formats,
    values, and dependencies to maintain coherence with the selected functions.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选项信息提取：识别选项并提取其格式、值和依赖关系，以保持与所选功能的一致性。
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Code Generation: Integrates all extracted information into cohesive simulation
    code that meets task specifications and adheres to syntax requirements.'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码生成：将所有提取的信息整合成符合任务规范并遵守语法要求的连贯仿真代码。
- en: 'Each of these actions is further clarified with tool-specific coding examples
    in the prompt. While the examples are tool-dependent, the rest of the framework
    remains general. Overall, the above reasoning framework highlights again that
    the key to handling simulation tasks: correctly identifying and combining functions
    and options.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 每一个这些操作都通过提示中的工具特定编码示例进一步说明。虽然这些示例依赖于工具，但其余框架保持通用。总体而言，上述推理框架再次强调了处理仿真任务的关键：正确识别和结合功能与选项。
- en: III-C Knowledge Integration
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 知识整合
- en: 'The above reasoning actions heavily rely on information drawn from both the
    simulation request and supplementary knowledge, comprising:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上述推理操作在很大程度上依赖于来自仿真请求和补充知识的信息，这些信息包括：
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Static Basic Knowledge: Supplies the agent with foundational information on
    essential functions and syntax rules pertinent to the simulation tool. This static
    knowledge serves as a base reference and reminder for the agent to consult when
    generating code. Note that such knowledge is tool-dependent.'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 静态基础知识：为代理提供有关仿真工具相关的基本功能和语法规则的基础信息。这些静态知识作为基础参考，供代理在生成代码时查阅。请注意，这些知识是工具特定的。
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dynamic Retrieval Knowledge: The prompt includes placeholders for dynamic retrieval
    results from the enhanced RAG module, allowing the agent to incorporate request-specific
    knowledge into its reasoning. This knowledge provides detailed information on
    function dependencies, option formats, and other contextual elements needed for
    accurate code generation.'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 动态检索知识：提示中包含了用于动态检索增强型 RAG 模块结果的占位符，允许代理将请求特定的知识融入推理中。这些知识提供了有关功能依赖关系、选项格式以及生成准确代码所需的其他上下文元素的详细信息。
- en: Eventually, by integrating both static and dynamic knowledge, as well as the
    above structured reasoning framework, the agent is expected to generate accurate
    code to address the simulation request.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，通过整合静态和动态知识，以及上述结构化推理框架，代理预期能够生成准确的代码来处理仿真请求。
- en: IV Environmental Acting Module with Feedback
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 环境作用模块与反馈
- en: 'Despite the reinforcement brought by the enhanced RAG and reasoning modules,
    the coding agent may still encounter errors during simulation code generation.
    To address this, it is essential to enable direct interaction between the LLM
    and the simulation environment, allowing the agent to receive execution feedback
    and iteratively refine its code. To this end, we propose an environmental acting
    module with an error feedback mechanism that integrates with both the RAG and
    reasoning modules, as illustrated in Fig. [5](https://arxiv.org/html/2411.16707v1#S4.F5
    "Figure 5 ‣ IV-B Error Handling and Feedback Loop ‣ IV Environmental Acting Module
    with Feedback ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework"). The components of this module are described in the following.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管增强型 RAG 和推理模块带来了强化，编码代理在仿真代码生成过程中仍可能遇到错误。为了解决这一问题，必须启用 LLM 与仿真环境之间的直接互动，允许代理接收执行反馈并迭代地改进其代码。为此，我们提出了一种带有错误反馈机制的环境作用模块，该模块与
    RAG 和推理模块集成，如图 [5](https://arxiv.org/html/2411.16707v1#S4.F5 "Figure 5 ‣ IV-B
    Error Handling and Feedback Loop ‣ IV Environmental Acting Module with Feedback
    ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework")
    所示。该模块的组件将在以下部分进行描述。'
- en: IV-A Code Execution and Detection
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 代码执行与检测
- en: 'The simulation code, generated by the coding agent from the enhanced reasoning
    module, is executed using the simulation environment API connected to a specific
    power systems simulation tool. Following execution, the simulation environment
    produces results, which are then checked for error signals. Specifically:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由增强推理模块中的编码代理生成的仿真代码，通过连接到特定电力系统仿真工具的仿真环境 API 执行。执行后，仿真环境生成结果，接着检查是否存在错误信号。具体来说：
- en: •
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If an error is detected, the code advances to a stopping criterion check. If
    the stopping criterion is met, the process is terminated; if not, the module triggers
    a feedback loop with detailed error reporting.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果检测到错误，代码将进入停止标准检查。如果停止标准被满足，则终止过程；如果未满足，模块将触发带有详细错误报告的反馈循环。
- en: •
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If no errors are detected, the process completes.
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果未检测到错误，过程完成。
- en: IV-B Error Handling and Feedback Loop
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 错误处理与反馈循环
- en: 'Upon detecting an error in the simulation results, an error report is automatically
    generated, containing:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到模拟结果中的错误时，自动生成错误报告，其中包含：
- en: •
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Problematic Code: The code segment that caused the error.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题代码：引发错误的代码段。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Error Message: A detailed description of the error.'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 错误信息：错误的详细描述。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'General Hints: Additional guidance on common issues.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般提示：关于常见问题的额外指导。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Request: Specific corrections needed to address the error.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请求：为解决错误所需的具体修正。
- en: •
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reminders: Additional constraints or requirements, if any.'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示：如有其他约束或要求，请注明。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Chat History: A log of previous interactions and iterations.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 聊天历史：之前交互和迭代的日志记录。
- en: '![Refer to caption](img/14850d104ff8cb7649afd0bc88e03fce.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/14850d104ff8cb7649afd0bc88e03fce.png)'
- en: 'Figure 5: Environmental acting module with an error feedback mechanism that
    integrates with both the RAG and reasoning modules.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：带有错误反馈机制的环境作用模块，集成了RAG和推理模块。
- en: 'TABLE I: Evaluated Schemes by Distinct Combinations of the Proposed Strategies
    within the Framework'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表I：通过框架内提出的策略的不同组合评估的方案
- en: '(GPT4o: API of gpt-4o-2024-05-13; CGPT4o: ChatGPT4o Web Interface; o1p: O1-preview
    Web Interface)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: （GPT4o：gpt-4o-2024-05-13的API；CGPT4o：ChatGPT4o Web界面；o1p：O1-preview Web界面）
- en: '|  | GPT4o Full | GPT4o PR | GPT4o RSR | GPT4o SR | GPT4o Sole | GPT4o NC |
    GPT4o NP | GPT4o NS | GPT4o NR | GPT4o NCS | GPT4o RSRNW | CGPT4o R | o1p Sole
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT4o 完整版 | GPT4o PR | GPT4o RSR | GPT4o SR | GPT4o Sole | GPT4o NC |
    GPT4o NP | GPT4o NS | GPT4o NR | GPT4o NCS | GPT4o RSRNW | CGPT4o R | o1p Sole
    |'
- en: '| Query Planning | ✓ | ✓ |  |  |  | ✓ | ✓ | ✓ |  | ✓ | ✓ |  |  |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 查询规划 | ✓ | ✓ |  |  |  | ✓ | ✓ | ✓ |  | ✓ | ✓ |  |  |'
- en: '| Triple-based Structured Option Document | ✓ | ✓ | ✓ | ✓ |  | ✓ |  | ✓ |  |
    ✓ | ✓ | ✓ |  |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 基于三元组的结构化选项文档 | ✓ | ✓ | ✓ | ✓ |  | ✓ |  | ✓ |  | ✓ | ✓ | ✓ |  |'
- en: '| Chain of Thought Prompting | ✓ |  | ✓ |  |  |  | ✓ | ✓ | ✓ |  | ✓ |  |  |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 思维链提示 | ✓ |  | ✓ |  |  |  | ✓ | ✓ | ✓ |  | ✓ |  |  |'
- en: '| Few-Shot Prompting | ✓ |  | ✓ |  |  | ✓ | ✓ |  | ✓ |  | ✓ |  |  |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 少量示例提示 | ✓ |  | ✓ |  |  | ✓ | ✓ |  | ✓ |  | ✓ |  |  |'
- en: '| Static Basic Knowledge | ✓ |  | ✓ |  |  | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  |  |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 静态基础知识 | ✓ |  | ✓ |  |  | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  |  |'
- en: '| Environmental Acting and Feedback | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓
    | ✓ | ✓ | ✓ |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 环境作用与反馈 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '| Proposed RAG | ✓ | ✓ |  |  |  | ✓ | ✓ | ✓ |  | ✓ | ✓ |  |  |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 提出的RAG | ✓ | ✓ |  |  |  | ✓ | ✓ | ✓ |  | ✓ | ✓ |  |  |'
- en: '| Standard RAG |  |  | ✓ | ✓ |  |  |  |  |  |  |  |  |  |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 标准RAG |  |  | ✓ | ✓ |  |  |  |  |  |  |  |  |  |'
- en: '| OpenAI’s Built-in RAG |  |  |  |  |  |  |  |  |  |  |  | ✓ |  |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| OpenAI内置RAG |  |  |  |  |  |  |  |  |  |  |  | ✓ |  |'
- en: '| Well-developed Error-reporting System | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓
    | ✓ |  | ✓ | ✓ |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 完善的错误报告系统 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |  | ✓ | ✓ |'
- en: IV-C Enhanced RAG and Reasoning Module Interplay
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 增强型RAG与推理模块的相互作用
- en: The error report and feedback are then processed as a new request by the retrieval
    agent in the enhanced RAG module. This agent retrieves relevant information based
    on the error report (the query planning can also be applied to error reporting
    by simply replacing the identification of function/option keywords with the identification
    of error-related keywords). The retrieved information is then passed to the enhanced
    reasoning module, where the coding agent incorporates both the retrieval results
    and the correction request to revise the simulation code. The loop proceeds until
    the code meets both requirements, or until the stopping criterion is satisfied.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 错误报告和反馈随后由增强型RAG模块中的检索代理作为新的请求进行处理。该代理根据错误报告检索相关信息（查询规划也可以通过简单地将功能/选项关键字的识别替换为错误相关关键字的识别来应用于错误报告）。然后，检索到的信息被传递到增强推理模块，在那里编码代理将检索结果和修正请求结合起来，修正模拟代码。循环继续，直到代码满足两个要求，或直到满足停止标准为止。
- en: V Case Study
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 案例研究
- en: 'To comprehensively validate the proposed framework, we carry out a range of
    tests differing in three key dimensions: (i) distinct combinations of the proposed
    strategies within the framework to evaluate each strategy’s independent effectiveness;
    (ii) different simulation environments, specifically Daline [[23](https://arxiv.org/html/2411.16707v1#bib.bib23)]
    and MATPOWER [[24](https://arxiv.org/html/2411.16707v1#bib.bib24)], which include
    tools both familiar and unfamiliar to LLMs¹¹1Daline is available [[here]](https://www.shuo.science/daline)
    with a user manual in [[25](https://arxiv.org/html/2411.16707v1#bib.bib25)]. MATPOWER
    is available [[here]](https://matpower.org/) with a user manual in [[26](https://arxiv.org/html/2411.16707v1#bib.bib26)].,
    to demonstrate the framework’s versatility across various applications; and (iii)
    a wide array of simulation tasks, spanning normal to complex scenarios, to assess
    the framework’s performance across various simulation demands.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面验证所提出的框架，我们进行了一系列测试，涵盖三个关键维度：（i）框架内提出的策略的不同组合，以评估每个策略的独立有效性；（ii）不同的仿真环境，特别是Daline
    [[23](https://arxiv.org/html/2411.16707v1#bib.bib23)]和MATPOWER [[24](https://arxiv.org/html/2411.16707v1#bib.bib24)]，这些工具既有LLMs¹¹1Daline可在[[此处]](https://www.shuo.science/daline)获得，用户手册见[[25](https://arxiv.org/html/2411.16707v1#bib.bib25)]。MATPOWER可在[[此处]](https://matpower.org/)获得，用户手册见[[26](https://arxiv.org/html/2411.16707v1#bib.bib26)]，用以展示框架在不同应用中的多样性；（iii）一系列不同的仿真任务，涵盖从普通到复杂的场景，评估框架在各种仿真需求下的表现。
- en: The following sections detail the case study configurations, followed by an
    analysis of the simulation outcomes for Daline and MATPOWER. Eventually, the cost
    of using LLMs to perform power system simulations is discussed.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分详细介绍了案例研究配置，接着分析了Daline和MATPOWER的仿真结果。最终，讨论了使用LLMs进行电力系统仿真的成本。
- en: V-A Settings
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 设置
- en: 'Firstly, Table [I](https://arxiv.org/html/2411.16707v1#S4.T1 "TABLE I ‣ IV-B
    Error Handling and Feedback Loop ‣ IV Environmental Acting Module with Feedback
    ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework")
    presents the distinct combinations of the proposed strategies within the framework
    employed in the evaluation, with the proposed strategies shaded in gray.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，表[I](https://arxiv.org/html/2411.16707v1#S4.T1 "TABLE I ‣ IV-B Error Handling
    and Feedback Loop ‣ IV Environmental Acting Module with Feedback ‣ Enhancing LLMs
    for Power System Simulations: A Feedback-driven Multi-agent Framework")展示了在评估中使用的框架内提出的不同策略组合，所提策略以灰色标示。'
- en: Secondly, this paper selects Daline [[23](https://arxiv.org/html/2411.16707v1#bib.bib23)]
    and MATPOWER [[24](https://arxiv.org/html/2411.16707v1#bib.bib24)] as the simulation
    environments. It is important to note that Daline was released after the latest
    updates of the LLMs used in the evaluation, while the well-established tool MATPOWER
    was already included in the training dataset of the LLMs. Consequently, these
    two environments encompass both seen and unseen scenarios for the LLMs, allowing
    us to demonstrate the framework’s versatility.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，本文选择Daline [[23](https://arxiv.org/html/2411.16707v1#bib.bib23)]和MATPOWER
    [[24](https://arxiv.org/html/2411.16707v1#bib.bib24)]作为仿真环境。需要注意的是，Daline是在用于评估的LLMs的最新更新之后发布的，而已建立的工具MATPOWER已被包含在LLMs的训练数据集中。因此，这两个环境涵盖了LLMs既见过又未见过的场景，允许我们展示框架的多样性。
- en: 'Thirdly, 34 simulation tasks have been used to test the framework with Daline,
    comprising 7 complex tasks and 27 standard tasks. Similarly, for MATPOWER, 35
    simulation tasks have been defined, including 8 complex tasks and 27 standard
    tasks. These tasks comprehensively cover the functionalities of both simulation
    tools, aiming to include the majority of available options. A selection of representative
    tasks is given in Fig. [6](https://arxiv.org/html/2411.16707v1#S5.F6 "Figure 6
    ‣ V-A Settings ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations: A
    Feedback-driven Multi-agent Framework"), intended as an exemplary overview.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '第三，使用了34个仿真任务对框架进行测试，其中Daline包含7个复杂任务和27个标准任务。类似地，对于MATPOWER，定义了35个仿真任务，其中包括8个复杂任务和27个标准任务。这些任务全面覆盖了两个仿真工具的功能，旨在包括大部分可用选项。图[6](https://arxiv.org/html/2411.16707v1#S5.F6
    "Figure 6 ‣ V-A Settings ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations:
    A Feedback-driven Multi-agent Framework")中给出了部分代表性任务，作为示范性概览。'
- en: '![Refer to caption](img/824e01b1c3c7bac51fee42a92cda09de.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![请参考说明](img/824e01b1c3c7bac51fee42a92cda09de.png)'
- en: 'Figure 6: Representative examples of simulation tasks for Daline and MATPOWER.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：Daline和MATPOWER的仿真任务代表性示例。
- en: Finally, for the performance evaluation, each scheme is allowed up to $N_{max}$
    attempts of addressing a simulation task (with $N_{max}=3$ for Daline and $N_{max}=5$
    for MATPOWER, as the latter is relatively more complex). A scheme earns 100 points
    per attempt for exactly correct simulation results without irrelevant settings
    in the code, 50 points for correct simulation results but with irrelevant settings
    in the code, and 0 points for any incorrect simulation outcomes. Subsequent attempts
    are only made if the previous attempt encounters execution errors, and any unused
    attempts receive the same score as the last attempt. The success rate for each
    scheme is defined as the total points earned divided by the maximum possible score,
    resulting in a success rate between 0% and 100%.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于性能评估，每个方案最多允许进行$N_{max}$次模拟任务尝试（Daline的$N_{max}=3$，MATPOWER的$N_{max}=5$，因为后者相对更复杂）。每次尝试如果能获得完全正确的模拟结果且代码中没有不相关的设置，则获得100分；如果模拟结果正确但代码中有不相关的设置，则获得50分；若模拟结果错误，则得0分。如果前一次尝试发生执行错误，则才会进行后续尝试，且未使用的尝试与最后一次尝试的得分相同。每个方案的成功率定义为获得的总分除以最大可能得分，得出的成功率介于0%和100%之间。
- en: V-B Evaluation on Daline
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 评估：Daline
- en: 'The evaluation results on Daline are illustrated in Fig. [7](https://arxiv.org/html/2411.16707v1#S5.F7
    "Figure 7 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework") and Fig. [8](https://arxiv.org/html/2411.16707v1#S5.F8
    "Figure 8 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework"). Fig. [7](https://arxiv.org/html/2411.16707v1#S5.F7
    "Figure 7 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework") depicts the distribution
    of scores achieved across attempts for each evaluated scheme, differentiating
    between complex and standard tasks. Fig. [8](https://arxiv.org/html/2411.16707v1#S5.F8
    "Figure 8 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework") presents the success
    rates for each scheme, itemized by “all tasks combined”, “complex tasks only”,
    “standard tasks only”, as well as for the “first attempt success rate” and the
    “final attempt success rate”. In the following, these evaluation results are analyzed
    from multiple perspectives.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '对Daline的评估结果如图[7](https://arxiv.org/html/2411.16707v1#S5.F7 "Figure 7 ‣ V-B
    Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations:
    A Feedback-driven Multi-agent Framework")和图[8](https://arxiv.org/html/2411.16707v1#S5.F8
    "Figure 8 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework")所示。图[7](https://arxiv.org/html/2411.16707v1#S5.F7
    "Figure 7 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework")展示了每个评估方案在不同尝试中的得分分布，区分了复杂任务和标准任务。图[8](https://arxiv.org/html/2411.16707v1#S5.F8
    "Figure 8 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework")展示了每个方案的成功率，按“所有任务合并”、“仅复杂任务”、“仅标准任务”以及“第一次尝试成功率”和“最后一次尝试成功率”列出。以下将从多个角度对这些评估结果进行分析。'
- en: '![Refer to caption](img/be6d906a53c13be14992ee2fd35d7935.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/be6d906a53c13be14992ee2fd35d7935.png)'
- en: 'Figure 7: Distribution of scores achieved across attempts for each evaluated
    scheme, separated by complex and standard tasks (Simulation Environment: Daline).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：每个评估方案在不同尝试中的得分分布，按复杂任务和标准任务分开（模拟环境：Daline）。
- en: '![Refer to caption](img/b61b4d11f46059cc67b0df934a51fa7a.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/b61b4d11f46059cc67b0df934a51fa7a.png)'
- en: 'Figure 8: Success rates for each scheme, itemized by all tasks combined, complex
    tasks only, standard tasks only, as well as for the first attempt success rate
    and the final attempt success rate (Simulation Environment: Daline).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：每个方案的成功率，按所有任务合并、仅复杂任务、仅标准任务以及第一次尝试成功率和最后一次尝试成功率列出（模拟环境：Daline）。
- en: V-B1 Original Capability vs. Enhanced Capability
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B1 原始能力与增强能力
- en: While equipped with environmental interaction and feedback mechanisms, GPT4o-Sole
    still demonstrates a 0% success rate for both complex and standard tasks, indicating
    that GPT4o has not previously encountered Daline. Even with a complete knowledge
    base supported by RAG — either through the standard RAG or OpenAI’s official RAG
    — the resulting schemes, GPT4o-SR and CGPT4o-R, achieve success rates of only
    31.37% and 33.82% across all tasks, respectively. This suggests that, even with
    RAG support, the latest language model, GPT4o, still lacks reliable performance
    in simulations. In contrast, the scheme equipped with our proposed full framework,
    GPT4o-Full, achieves a success rate of 93.13% across all tasks — a significant
    improvement that highlights the effectiveness of the proposed framework.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GPT4o-Sole配备了环境互动和反馈机制，但它在复杂任务和标准任务中的成功率仍为0%，这表明GPT4o以前未曾遇到过Daline。即使有了通过标准RAG或OpenAI官方RAG支持的完整知识库，所产生的方案GPT4o-SR和CGPT4o-R在所有任务中的成功率也仅为31.37%和33.82%。这表明，即使有RAG支持，最新的语言模型GPT4o在模拟中的表现仍不可靠。相比之下，配备我们提议的完整框架的方案GPT4o-Full在所有任务中的成功率达到了93.13%——这一显著的改进突显了所提框架的有效性。
- en: V-B2 Fully Equipped vs. Less Equipped
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B2 完全装备与较少装备
- en: The high success rate of 93.13% over all taks for GPT4o-Full is due to the cumulative
    effects of using the complete proposed framework. Comparing other schemes with
    GPT4o-Full gives an indication of the impact of omitted strategies. For instance,
    although GPT4o-NP includes most reasoning enhancement strategies, it lacks the
    triple-based structured option document, resulting in a reduced success rate of
    81.37%. On the other hand, omitting the few-shot CoT for reasoning, as in GPT4o-NCS,
    lowers success to 65.19%. When few-shot CoT is employed, but the proposed query
    planning is omitted, as in GPT4o-RSR, the success rate for complex tasks drops
    to 66.67%, particularly due to the deteriorated performance for the complex tasks.
    While similar comparisons can be drawn across all schemes, our goal here is not
    to argue which strategy provides the highest improvement, but to emphasize that
    high success relies on the combined effect of multiple strategies.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: GPT4o-Full在所有任务中的高成功率93.13%是由于采用了完整的提议框架的累积效应。将其他方案与GPT4o-Full进行比较，可以揭示省略策略的影响。例如，尽管GPT4o-NP包含了大多数推理增强策略，但它缺少基于三元组的结构化选项文档，导致成功率降至81.37%。另一方面，省略少量示例的链式思维（CoT）推理，如GPT4o-NCS所示，成功率降至65.19%。当采用少量示例的链式思维推理，但省略了我们提议的查询规划，如GPT4o-RSR所示，复杂任务的成功率降至66.67%，尤其是在复杂任务的性能下降的情况下。虽然在所有方案中都可以做类似的比较，但我们在此的目标不是争论哪种策略提供了最高的改进，而是强调高成功率依赖于多种策略的组合效果。
- en: V-B3 Complex Tasks vs. Normal Tasks
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B3 复杂任务与普通任务
- en: 'In general, more complex tasks — those with multiple sub-requests — tend to
    increase the likelihood of errors in LLMs, resulting in lower success rates compared
    to standard tasks, as observed across most schemes. However, with our proposed
    full framework, GPT4o-Full, the performance gap between complex and standard tasks
    narrows significantly, as shown in both the score distributions in Fig. [7](https://arxiv.org/html/2411.16707v1#S5.F7
    "Figure 7 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework") and the success
    rates in Fig. [8](https://arxiv.org/html/2411.16707v1#S5.F8 "Figure 8 ‣ V-B Evaluation
    on Daline ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework"). This suggests that, with enhanced reasoning capabilities
    and the more effective RAG design, GPT4o-Full effectively identifies and addresses
    the sub-requests within complex tasks, similar to how it handles standard tasks.
    This enables LLMs to better manage complex tasks.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '一般来说，更复杂的任务——即包含多个子请求的任务——往往会增加大型语言模型（LLMs）出错的可能性，导致其成功率低于标准任务，这一点在大多数方案中都有观察到。然而，通过我们提出的完整框架GPT4o-Full，复杂任务与标准任务之间的性能差距显著缩小，正如图[7](https://arxiv.org/html/2411.16707v1#S5.F7
    "Figure 7 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework")中的得分分布和图[8](https://arxiv.org/html/2411.16707v1#S5.F8
    "Figure 8 ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing LLMs for Power
    System Simulations: A Feedback-driven Multi-agent Framework")中的成功率所示。这表明，凭借增强的推理能力和更有效的RAG设计，GPT4o-Full能够有效识别并解决复杂任务中的子请求，类似于它处理标准任务的方式。这使得LLMs能够更好地管理复杂任务。'
- en: V-B4 First Attempt vs. Final Attempt
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B4 初次尝试与最终尝试
- en: 'The comparison between the first-attempt and final-attempt success rates demonstrates
    the effectiveness of environmental interaction and feedback mechanisms. As shown
    in Fig. [8](https://arxiv.org/html/2411.16707v1#S5.F8 "Figure 8 ‣ V-B Evaluation
    on Daline ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework"), the final-attempt success rate is always higher than
    the first-attempt rate, particularly for schemes that incorporate fewer strategies
    from our framework. These schemes typically have either reduced reasoning capability
    or limited retrieval information, making environmental interaction and feedback
    crucial for error correction. However, for GPT4o-Full, the difference between
    first-attempt and final-attempt success rates is relatively small, as GPT4o-Full
    often completes the Daline simulation task successfully on the first attempt.
    This further highlights the effectiveness of the proposed framework. One noteworthy
    point is that the effectiveness of automatic error correction is partly influenced
    by the quality of the simulation tool’s error-reporting system — whether it provides
    clear, code-specific error messages. This feature affects the LLM’s capability
    to interpret and resolve issues in the generated code. In the absence of such
    a feature, as with GPT4o-RSRNW, the success rate drops to 78.43%, with negligible
    improvement between the first and final attempts. This underscores that without
    a well-developed error-reporting system, iterative refinement may yield limited
    benefit. Although tools like Daline and MATPOWER include well-developed error
    reporting (thereby achieving high correction accuracy), for other simulation tools
    where such systems are less developed, reinforcing them is recommended. In fact,
    our framework also enables LLMs to detect vulnerabilities within a simulation
    tool’s error-reporting system, particularly when mistakes occur. These errors
    may not stem from limitations of the LLMs or the framework itself but rather from
    inherent design issues within the tools.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 首次尝试和最终尝试的成功率比较，展示了环境交互和反馈机制的有效性。如图[8](https://arxiv.org/html/2411.16707v1#S5.F8
    "图8 ‣ V-B 评估 ‣ V 案例研究 ‣ 提升大语言模型在电力系统仿真中的表现：基于反馈的多代理框架")所示，最终尝试的成功率总是高于首次尝试的成功率，特别是对于那些采用我们框架中较少策略的方案。这些方案通常要么推理能力较弱，要么检索信息有限，因此环境交互和反馈对错误修正至关重要。然而，对于GPT4o-Full，首次尝试和最终尝试之间的成功率差异相对较小，因为GPT4o-Full通常在首次尝试时就能成功完成Daline仿真任务。这进一步突显了我们提出的框架的有效性。有一点值得注意的是，自动错误修正的效果在一定程度上受到仿真工具错误报告系统质量的影响——即它是否提供清晰、代码特定的错误信息。这个特性会影响大语言模型（LLM）解析和解决生成代码问题的能力。如果没有这样的功能，如GPT4o-RSRNW所示，成功率下降到78.43%，且首次和最终尝试之间的改进微乎其微。这突显出在没有良好开发的错误报告系统的情况下，迭代改进可能带来有限的效果。虽然Daline和MATPOWER等工具具备完善的错误报告系统（从而实现较高的修正准确率），但对于其他错误报告系统不完善的仿真工具，建议加强此类系统的开发。事实上，我们的框架还使得LLM能够检测仿真工具错误报告系统中的漏洞，特别是在出现错误时。这些错误可能并非源于LLM或框架本身的局限性，而是工具设计中固有的问题。
- en: '![Refer to caption](img/810caef34f9eff1c0439d6ddec865aaa.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/810caef34f9eff1c0439d6ddec865aaa.png)'
- en: 'Figure 9: Scores achieved by each evaluated scheme in individual attempts when
    handling complex tasks. The automatic error correction mechanism aids schemes
    equipped with our framework, such as GPT4o-PR, in correcting their behavior when
    encountering errors in initial attempts.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：每个评估方案在处理复杂任务时，各次尝试中的得分。在初次尝试遇到错误时，自动错误修正机制有助于配备我们框架的方案（如GPT4o-PR）修正其行为。
- en: '![Refer to caption](img/0d37e33f80db733c58436f82c4549f3c.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0d37e33f80db733c58436f82c4549f3c.png)'
- en: 'Figure 10: Distribution of scores achieved across attempts for each evaluated
    scheme, separated by complex and standard tasks (Simulation Environment: MATPOWER).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：针对每个评估方案，在各次尝试中的得分分布，按复杂任务和标准任务分开（仿真环境：MATPOWER）。
- en: '![Refer to caption](img/f3edfe9a582658ca8f693c439629d5b6.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f3edfe9a582658ca8f693c439629d5b6.png)'
- en: 'Figure 11: Success rates for each scheme, broken down by all tasks combined,
    complex tasks only, standard tasks only, as well as for the first attempt success
    rate and the final attempt success rate (Simulation Environment: MATPOWER; o1p-Sole
    is only tested by complex tasks).'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：各方案的成功率，按所有任务组合、仅复杂任务、仅标准任务，以及首次尝试成功率和最终尝试成功率分类（仿真环境：MATPOWER；o1p-Sole仅通过复杂任务进行测试）。
- en: V-C Evaluation on MATPOWER
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 在MATPOWER上的评估
- en: 'The evaluation results on MATPOWER are illustrated in Figs. [9](https://arxiv.org/html/2411.16707v1#S5.F9
    "Figure 9 ‣ V-B4 First Attempt vs. Final Attempt ‣ V-B Evaluation on Daline ‣
    V Case Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework"), [10](https://arxiv.org/html/2411.16707v1#S5.F10 "Figure
    10 ‣ V-B4 First Attempt vs. Final Attempt ‣ V-B Evaluation on Daline ‣ V Case
    Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent
    Framework"), and [11](https://arxiv.org/html/2411.16707v1#S5.F11 "Figure 11 ‣
    V-B4 First Attempt vs. Final Attempt ‣ V-B Evaluation on Daline ‣ V Case Study
    ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework").
    Specifically, Fig. [9](https://arxiv.org/html/2411.16707v1#S5.F9 "Figure 9 ‣ V-B4
    First Attempt vs. Final Attempt ‣ V-B Evaluation on Daline ‣ V Case Study ‣ Enhancing
    LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework") presents
    the scores achieved by each evaluated scheme in individual attempts when managing
    complex tasks. Fig. [10](https://arxiv.org/html/2411.16707v1#S5.F10 "Figure 10
    ‣ V-B4 First Attempt vs. Final Attempt ‣ V-B Evaluation on Daline ‣ V Case Study
    ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework")
    shows the distribution of scores across attempts for each scheme, and Fig. [11](https://arxiv.org/html/2411.16707v1#S5.F11
    "Figure 11 ‣ V-B4 First Attempt vs. Final Attempt ‣ V-B Evaluation on Daline ‣
    V Case Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework") depicts the success rates of each scheme. The outcomes
    observed here align closely with the results on Daline, enabling us to only focus
    primarily on comparative analyses across schemes in the subsequent discussion.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: MATPOWER上的评估结果如图[9](https://arxiv.org/html/2411.16707v1#S5.F9 "图9 ‣ V-B4 初次尝试与最终尝试
    ‣ V-B 在Daline上的评估 ‣ V 案例研究 ‣ 通过反馈驱动的多智能体框架增强LLMs用于电力系统仿真")、[10](https://arxiv.org/html/2411.16707v1#S5.F10
    "图10 ‣ V-B4 初次尝试与最终尝试 ‣ V-B 在Daline上的评估 ‣ V 案例研究 ‣ 通过反馈驱动的多智能体框架增强LLMs用于电力系统仿真")和[11](https://arxiv.org/html/2411.16707v1#S5.F11
    "图11 ‣ V-B4 初次尝试与最终尝试 ‣ V-B 在Daline上的评估 ‣ V 案例研究 ‣ 通过反馈驱动的多智能体框架增强LLMs用于电力系统仿真")展示。具体来说，图[9](https://arxiv.org/html/2411.16707v1#S5.F9
    "图9 ‣ V-B4 初次尝试与最终尝试 ‣ V-B 在Daline上的评估 ‣ V 案例研究 ‣ 通过反馈驱动的多智能体框架增强LLMs用于电力系统仿真")呈现了每个评估方案在管理复杂任务时的单独尝试得分。图[10](https://arxiv.org/html/2411.16707v1#S5.F10
    "图10 ‣ V-B4 初次尝试与最终尝试 ‣ V-B 在Daline上的评估 ‣ V 案例研究 ‣ 通过反馈驱动的多智能体框架增强LLMs用于电力系统仿真")展示了各方案在不同尝试中的得分分布，图[11](https://arxiv.org/html/2411.16707v1#S5.F11
    "图11 ‣ V-B4 初次尝试与最终尝试 ‣ V-B 在Daline上的评估 ‣ V 案例研究 ‣ 通过反馈驱动的多智能体框架增强LLMs用于电力系统仿真")则描绘了各方案的成功率。这里观察到的结果与在Daline上的结果非常一致，使得我们在接下来的讨论中主要聚焦于不同方案之间的比较分析。
- en: V-C1 Original Capability vs. Enhanced Capability
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-C1 原始能力与增强能力
- en: Despite MATPOWER being a widely-used and well-documented tool with extensive
    resources available online, the latest high-performance LLMs, such as GPT4o and
    o1-preview (renowned for its reasoning capability), struggle to perform simulations
    reliably. For instance, both GPT4o-Sole and o1p-Sole show a 0% success rate on
    complex tasks, and GPT4o-Sole achieves only 27.77% success on standard tasks.
    Even with RAG and the whole knowledge base, GPT4o-SR reaches a success rate of
    only 13.75% for complex tasks and 52.96% for standard tasks. In contrast, the
    fully equipped framework, GPT4o-Full, achieves a remarkable 96.85% success rate
    across all tasks, with a breakdown of 93.75% on complex tasks and 97.77% on standard
    tasks, underscoring the framework’s effectiveness.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管MATPOWER是一个广泛使用并且文档完备的工具，且在网上有大量的资源可供查阅，最新的高性能LLMs，如GPT4o和o1-preview（以推理能力著称），在执行仿真时仍难以可靠地表现。例如，GPT4o-Sole和o1p-Sole在复杂任务上的成功率为0%，而GPT4o-Sole在标准任务上仅取得27.77%的成功率。即使使用了RAG和完整的知识库，GPT4o-SR在复杂任务上的成功率也仅为13.75%，在标准任务上为52.96%。相比之下，完全装备的框架GPT4o-Full在所有任务上的成功率达到了惊人的96.85%，其中复杂任务的成功率为93.75%，标准任务的成功率为97.77%，这突显了该框架的高效性。
- en: V-C2 Fully Equipped vs. Less Equipped
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-C2 完全装备与较少装备
- en: Consistent with the findings on Daline, the results on MATPOWER indicate that
    high success rates depend on the synergistic effect of multiple strategies. For
    example, excluding the enhanced reasoning module, as in GPT4o-PR, results in an
    overall success rate decrease to 89.71%, with complex tasks dropping further to
    70.00%. Similarly, omitting the proposed query planning strategy, as in GPT4o-RSR,
    reduces the overall success rate to 63.42% and complex tasks to 37.50%. These
    outcomes are substantially lower than those achieved by GPT4o-Full, which maintains
    a 93.75% success rate on complex tasks and 97.77% on standard tasks, demonstrating
    the critical role of each component within the proposed framework.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 与Daline的结果一致，MATPOWER的结果表明，高成功率依赖于多种策略的协同效应。例如，排除增强推理模块（如GPT4o-PR中所做的）会导致整体成功率下降至89.71%，复杂任务的成功率进一步下降至70.00%。类似地，省略提出的查询规划策略（如GPT4o-RSR中所做的）会使整体成功率降至63.42%，复杂任务的成功率降至37.50%。这些结果明显低于GPT4o-Full的表现，后者在复杂任务中的成功率为93.75%，在标准任务中的成功率为97.77%，这表明框架中每个组件的关键作用。
- en: 'TABLE II: Average Cost Analysis of GPT4o-Full Per Task'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表II：GPT4o-Full每个任务的平均成本分析
- en: '| Environment | Time (sec.) | Input Token | Output Token | Expense (USD) |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 环境 | 时间（秒） | 输入代币 | 输出代币 | 费用（美元） |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Daline | 29.446 | 7882.294 | 168.353 | 0.014 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Daline | 29.446 | 7882.294 | 168.353 | 0.014 |'
- en: '| MATPOWER | 32.703 | 5338.514 | 274.371 | 0.013 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| MATPOWER | 32.703 | 5338.514 | 274.371 | 0.013 |'
- en: V-D Cost Analysis
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D 成本分析
- en: 'The cost analysis of GPT4o-Full for executing simulation tasks in Daline and
    MATPOWER is presented in Table [II](https://arxiv.org/html/2411.16707v1#S5.T2
    "TABLE II ‣ V-C2 Fully Equipped vs. Less Equipped ‣ V-C Evaluation on MATPOWER
    ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework"), with average values across all tasks shown. The reported
    time covers the entire process, including retrieval, reasoning, code generation,
    simulation execution, result aggregation, and, where necessary, code correction.
    Remarkably, GPT4o-Full completes each task in approximately half a minute. Additionally,
    the token expense per task is roughly 0.014 USD.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 'GPT4o-Full在Daline和MATPOWER中执行仿真任务的成本分析见表[II](https://arxiv.org/html/2411.16707v1#S5.T2
    "TABLE II ‣ V-C2 Fully Equipped vs. Less Equipped ‣ V-C Evaluation on MATPOWER
    ‣ V Case Study ‣ Enhancing LLMs for Power System Simulations: A Feedback-driven
    Multi-agent Framework")，表中显示了所有任务的平均值。报告的时间涵盖了整个过程，包括检索、推理、代码生成、仿真执行、结果汇总以及在必要时进行的代码修正。值得注意的是，GPT4o-Full完成每个任务的时间大约为半分钟。此外，每个任务的代币费用大约为0.014美元。'
- en: It is noteworthy that aside from parallel retrieval, no specialized acceleration
    techniques were employed in this framework. Thus, despite its already satisfactory
    performance, there is considerable potential for speed enhancements. Even in the
    current state, without any specific acceleration strategies, GPT4o-Full can execute
    approximately 120 simulation tasks per hour in Daline and MATPOWER, with a total
    token cost of around 1.68 USD. Given this high efficiency and cost-effectiveness,
    our framework presents a promising pathway to improve researcher productivity.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，除了并行检索外，本框架未使用任何专门的加速技术。因此，尽管性能已经令人满意，但仍然有很大的速度提升潜力。即便在当前状态下，未采用任何特定的加速策略，GPT4o-Full也可以在Daline和MATPOWER中每小时执行大约120个仿真任务，总代币费用约为1.68美元。鉴于这种高效性和成本效益，我们的框架为提高研究人员的生产力提供了一个有前景的路径。
- en: VI Conclusion
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 结论
- en: 'This paper addresses the research gap in enhancing LLMs for power system simulations
    by proposing a feedback-driven, multi-agent framework, representing the first
    systematic approach to significantly improve LLMs’ simulation capabilities across
    both familiar and new tools. Validated on 69 diverse simulation tasks from Daline
    and MATPOWER, our framework achieved substantial performance improvements, with
    success rates of 93.13% and 96.85%, respectively, far surpassing those of baseline
    schemes, including the latest LLM, o1-preview. Key findings include: (i) The original
    simulation capability of LLMs is limited, as evidenced by GPT4o and o1-preview
    achieving success rates no higher than 27.77%. (ii) Even with the standard RAG
    module and a comprehensive knowledge base, LLMs achieve overall success rates
    below 45%, highlighting the need for a more comprehensive approach. (iii) Our
    framework’s high success rate stems from a synergistic integration of enhanced
    RAG, enhanced reasoning, as well as environmental acting and feedback mechanisms.
    Removing any of these elements results in a significant performance decline. (iv)
    Our framework enables LLMs to execute tasks efficiently, with each task completed
    in approximately 30 seconds at a token cost of only 0.014 USD, offering a scalable,
    cost-effective solution that enhances productivity of human scientists in power
    systems.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本文通过提出一个基于反馈驱动的多智能体框架，解决了增强LLM在电力系统仿真中的研究空白，代表了第一个系统性的方法，显著提高了LLM在常用工具和新工具中的仿真能力。通过在来自Daline和MATPOWER的69个不同仿真任务中验证，我们的框架实现了显著的性能提升，成功率分别为93.13%和96.85%，远远超出了基准方案的表现，包括最新的LLM，o1-preview。主要发现包括：（i）LLM的原始仿真能力有限，GPT4o和o1-preview的成功率最高也仅为27.77%。（ii）即使采用标准的RAG模块和综合知识库，LLM的整体成功率仍低于45%，这凸显了需要更为全面的方法。（iii）我们的框架高成功率的来源于增强的RAG、增强的推理能力、环境行为和反馈机制的协同整合。去除其中任何一个元素都会导致性能大幅下降。（iv）我们的框架使LLM能够高效执行任务，每个任务约30秒完成，令令牌成本仅为0.014美元，提供了一个可扩展、具成本效益的解决方案，提升了电力系统中人类科学家的生产力。
- en: 'However, several critical future challenges still remain: (i) Developing automatic
    evaluation methods for unbenchmarked results to improve reliability and autonomy.
    (ii) Expanding the framework to synchronize multiple simulation tools to tackle
    more challenging tasks. (iii) Since 100% accuracy remains unachieved, integrating
    error-detection mechanisms to flag uncertainties and inform researchers of potential
    inaccuracies. Overall, our work is an initial step in the long journey toward
    realizing intelligent LLM-based research assistants, with potential ahead.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仍然存在一些关键的未来挑战：（i）开发自动评估未标定结果的方法，以提高可靠性和自主性。（ii）扩展框架以同步多个仿真工具，解决更具挑战性的任务。（iii）由于100%的准确率尚未实现，因此需要集成错误检测机制，标记不确定性并告知研究人员潜在的不准确性。总的来说，我们的工作是实现基于智能LLM的研究助手这一长期目标的初步步骤，前景广阔。
- en: Acknowledgement
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to acknowledge the assistance of ChatGPT-4o [[27](https://arxiv.org/html/2411.16707v1#bib.bib27)]
    for language polishing of this paper.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢ChatGPT-4o [[27](https://arxiv.org/html/2411.16707v1#bib.bib27)] 对本文的语言润色提供的帮助。
- en: References
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] D. A. Boiko, R. MacKnight, B. Kline, and G. Gomes, “Autonomous chemical
    research with large language models,” *Nature*, vol. 624, no. 7992, pp. 570–578,
    2023.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] D. A. Boiko, R. MacKnight, B. Kline, 和 G. Gomes, “利用大型语言模型进行自主化学研究，” *自然*，第624卷，第7992期，页码570–578，2023年。'
- en: '[2] B. Romera-Paredes, M. Barekatain, A. Novikov, M. Balog, M. P. Kumar, E. Dupont,
    F. J. Ruiz, J. S. Ellenberg, P. Wang, O. Fawzi *et al.*, “Mathematical discoveries
    from program search with large language models,” *Nature*, vol. 625, no. 7995,
    pp. 468–475, 2024.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] B. Romera-Paredes, M. Barekatain, A. Novikov, M. Balog, M. P. Kumar, E.
    Dupont, F. J. Ruiz, J. S. Ellenberg, P. Wang, O. Fawzi *等*， “通过大型语言模型的程序搜索发现数学定理，”
    *自然*，第625卷，第7995期，页码468–475，2024年。'
- en: '[3] T. H. Trinh, Y. Wu, Q. V. Le, H. He, and T. Luong, “Solving olympiad geometry
    without human demonstrations,” *Nature*, vol. 625, no. 7995, pp. 476–482, 2024.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] T. H. Trinh, Y. Wu, Q. V. Le, H. He, 和 T. Luong, “无需人工演示即可解决奥林匹克几何问题，”
    *自然*，第625卷，第7995期，页码476–482，2024年。'
- en: '[4] S. Tayebi Arasteh, T. Han, M. Lotfinia, C. Kuhl, J. N. Kather, D. Truhn,
    and S. Nebelung, “Large language models streamline automated machine learning
    for clinical studies,” *Nature Communications*, vol. 15, no. 1, p. 1603, 2024.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S. Tayebi Arasteh, T. Han, M. Lotfinia, C. Kuhl, J. N. Kather, D. Truhn,
    和 S. Nebelung, “大型语言模型简化了临床研究中的自动化机器学习，” *自然通讯*，第15卷，第1期，页码1603，2024年。'
- en: '[5] R. S. Bonadia, F. C. Trindade, W. Freitas, and B. Venkatesh, “On the potential
    of chatgpt to generate distribution systems for load flow studies using opendss,”
    *IEEE Transactions on Power Systems*, 2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] R. S. Bonadia, F. C. Trindade, W. Freitas, 和 B. Venkatesh, “ChatGPT在使用OpenDSS进行负荷流研究时生成配电系统的潜力，”
    *IEEE 电力系统学报*，2023年。'
- en: '[6] L. Dong, S. Majumder, F. Doudi, Y. Cai, C. Tian, D. Kalathi, K. Ding, A. A.
    Thatte, and L. Xie, “Exploring the capabilities and limitations of large language
    models in the electric energy sector,” *arXiv preprint arXiv:2403.09125*, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] L. Dong, S. Majumder, F. Doudi, Y. Cai, C. Tian, D. Kalathi, K. Ding, A.
    A. Thatte, 和 L. Xie, “探索大型语言模型在电力能源领域的能力与局限性，” *arXiv 预印本 arXiv:2403.09125*，2024年。'
- en: '[7] H. Chang, J. Park, S. Ye, S. Yang, Y. Seo, D.-S. Chang, and M. Seo, “How
    do large language models acquire factual knowledge during pretraining?” *arXiv
    preprint arXiv:2406.11813*, 2024.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] H. Chang, J. Park, S. Ye, S. Yang, Y. Seo, D.-S. Chang, 和 M. Seo, “大型语言模型在预训练过程中如何获取事实性知识？”
    *arXiv 预印本 arXiv:2406.11813*，2024年。'
- en: '[8] Z. Yan and Y. Xu, “Real-time optimal power flow with linguistic stipulations:
    integrating gpt-agent and deep reinforcement learning,” *IEEE Transactions on
    Power Systems*, 2023.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Z. Yan 和 Y. Xu, “带语言约束的实时最优潮流：集成GPT代理与深度强化学习，” *IEEE 电力系统学报*，2023年。'
- en: '[9] B. Zhang, C. Li, G. Chen, and Z. Dong, “Large language model assisted optimal
    bidding of bess in fcas market: An ai-agent based approach,” *arXiv preprint arXiv:2406.00974*,
    2024.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] B. Zhang, C. Li, G. Chen, 和 Z. Dong, “基于大型语言模型的电池储能系统在频率控制辅助服务市场的最优竞价：一种基于AI代理的方法，”
    *arXiv 预印本 arXiv:2406.00974*，2024年。'
- en: '[10] C. Huang, S. Li, R. Liu, H. Wang, and Y. Chen, “Large foundation models
    for power systems,” in *2024 IEEE Power & Energy Society General Meeting (PESGM)*.   IEEE,
    2024, pp. 1–5.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] C. Huang, S. Li, R. Liu, H. Wang, 和 Y. Chen, “电力系统的大型基础模型，” 载于 *2024 IEEE
    电力与能源学会年会 (PESGM)*。 IEEE，2024年，第1–5页。'
- en: '[11] H. Wang, Z. Chen, N. Shang, S. Yao, Z. Pan, F. Wen, and J. Zhao, “Carbon
    footprint accounting driven by large language models and retrieval-augmented generation,”
    *arXiv preprint arXiv:2408.09713*, 2024.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] H. Wang, Z. Chen, N. Shang, S. Yao, Z. Pan, F. Wen, 和 J. Zhao, “由大型语言模型与检索增强生成驱动的碳足迹核算，”
    *arXiv 预印本 arXiv:2408.09713*，2024年。'
- en: '[12] A. Zaboli, S. L. Choi, T.-J. Song, and J. Hong, “Chatgpt and other large
    language models for cybersecurity of smart grid applications,” in *2024 IEEE Power
    & Energy Society General Meeting (PESGM)*.   IEEE, 2024, pp. 1–5.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] A. Zaboli, S. L. Choi, T.-J. Song, 和 J. Hong, “ChatGPT及其他大型语言模型在智能电网应用中的网络安全，”
    载于 *2024 IEEE 电力与能源学会年会 (PESGM)*。 IEEE，2024年，第1–5页。'
- en: '[13] X. Wang, M. Feng, J. Qiu, J. Gu, and J. Zhao, “From news to forecast:
    Integrating event analysis in llm-based time series forecasting with reflection,”
    *arXiv preprint arXiv:2409.17515*, 2024.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] X. Wang, M. Feng, J. Qiu, J. Gu, 和 J. Zhao, “从新闻到预测：将事件分析整合到基于大型语言模型的时间序列预测中与反思，”
    *arXiv 预印本 arXiv:2409.17515*，2024年。'
- en: '[14] K. Nuortimo, J. Harkonen, and K. Breznik, “Global, regional, and local
    acceptance of solar power,” *Renewable and Sustainable Energy Reviews*, vol. 193,
    p. 114296, 2024.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] K. Nuortimo, J. Harkonen, 和 K. Breznik, “太阳能电力的全球、区域和地方接受度，” *可再生与可持续能源评论*，第193卷，页码114296，2024年。'
- en: '[15] X. Zhou, H. Zhao, Y. Cheng, Y. Cao, G. Liang, G. Liu, and J. Zhao, “Elecbench:
    a power dispatch evaluation benchmark for large language models,” *arXiv preprint
    arXiv:2407.05365*, 2024.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] X. Zhou, H. Zhao, Y. Cheng, Y. Cao, G. Liang, G. Liu, 和 J. Zhao, “Elecbench：一种用于大型语言模型的电力调度评估基准，”
    *arXiv 预印本 arXiv:2407.05365*，2024年。'
- en: '[16] J. Ruan, G. Liang, H. Zhao, G. Liu, X. Sun, J. Qiu, Z. Xu, F. Wen, and
    Z. Y. Dong, “Applying large language models to power systems: Potential security
    threats,” *IEEE Transactions on Smart Grid*, 2024.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Ruan, G. Liang, H. Zhao, G. Liu, X. Sun, J. Qiu, Z. Xu, F. Wen, 和 Z.
    Y. Dong, “将大型语言模型应用于电力系统：潜在的安全威胁，” *IEEE 智能电网学报*，2024年。'
- en: '[17] D. Lifu, C. Ying, X. Tannan, H. Shaowei, and S. Chen, “Exploration of
    generative intelligent application mode for new power systems based on large language
    models,” *Automation of Electric Power Systems*, 2024\. [Online]. Available: [https://github.com/xxh0523/llm4power](https://github.com/xxh0523/llm4power)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] D. Lifu, C. Ying, X. Tannan, H. Shaowei, 和 S. Chen, “基于大型语言模型的新能源系统生成智能应用模式探索，”
    *电力系统自动化*，2024年。 [在线]。 可用链接：[https://github.com/xxh0523/llm4power](https://github.com/xxh0523/llm4power)'
- en: '[18] C. Huang, S. Li, R. Liu, H. Wang, and Y. Chen, “Large foundation models
    for power systems,” *arXiv preprint arXiv:2312.07044*, 2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] C. Huang, S. Li, R. Liu, H. Wang, 和 Y. Chen, “电力系统的大型基础模型，” *arXiv 预印本
    arXiv:2312.07044*，2023年。'
- en: '[19] P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,
    H. Küttler, M. Lewis, W. Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-augmented
    generation for knowledge-intensive NLP tasks,” in *Advances in Neural Information
    Processing Systems*, 2020.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,
    H. Küttler, M. Lewis, W. Yih, T. Rocktäschel, S. Riedel, 和 D. Kiela，“用于知识密集型NLP任务的检索增强生成，”*神经信息处理系统进展*，2020年。'
- en: '[20] M. Jia, Z. Cui, and G. Hug, “Enabling large language models to perform
    power system simulations with previously unseen tools: A case of daline,” *arXiv
    preprint arXiv:2406.17215*, 2024.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] M. Jia, Z. Cui, 和 G. Hug，“使大语言模型能够使用以前未见过的工具进行电力系统仿真：以 Daline 为例，”*arXiv
    预印本 arXiv:2406.17215*，2024年。'
- en: '[21] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou
    *et al.*, “Chain-of-thought prompting elicits reasoning in large language models,”
    *Advances in neural information processing systems*, vol. 35, pp. 24 824–24 837,
    2022.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D.
    Zhou *等*，“链式思维提示引发大语言模型推理，”*神经信息处理系统进展*，第35卷，第24,824–24,837页，2022年。'
- en: '[22] B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, S. Agarwal *et al.*, “Language models are few-shot
    learners,” *arXiv preprint arXiv:2005.14165*, 2020.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, S. Agarwal *等*，“语言模型是少样本学习者，”*arXiv 预印本 arXiv:2005.14165*，2020年。'
- en: '[23] M. Jia, W. Y. Chan, and G. Hug, “Daline: A data-driven power flow linearization
    toolbox for power systems research and education,” 2024\. [Online]. Available:
    [https://doi.org/10.3929/ethz-b-000681867](https://doi.org/10.3929/ethz-b-000681867)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. Jia, W. Y. Chan, 和 G. Hug，“Daline：一个数据驱动的电力流线性化工具箱，用于电力系统研究和教育，”2024年。[在线].
    可用链接：[https://doi.org/10.3929/ethz-b-000681867](https://doi.org/10.3929/ethz-b-000681867)'
- en: '[24] R. D. Zimmerman, C. E. Murillo-Sánchez, and R. J. Thomas, “Matpower: Steady-state
    operations, planning, and analysis tools for power systems research and education,”
    *IEEE Transactions on power systems*, vol. 26, no. 1, pp. 12–19, 2010.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] R. D. Zimmerman, C. E. Murillo-Sánchez, 和 R. J. Thomas，“Matpower：用于电力系统研究和教育的稳态操作、规划和分析工具，”*IEEE
    电力系统学报*，第26卷，第1期，第12–19页，2010年。'
- en: '[25] M. Jia, W. Y. Chan, and G. Hug, “User manual for daline 1.1.5,” 2024\.
    [Online]. Available: [https://doi.org/10.3929/ethz-b-000680438](https://doi.org/10.3929/ethz-b-000680438)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] M. Jia, W. Y. Chan, 和 G. Hug，“Daline 1.1.5 用户手册，”2024年。[在线]. 可用链接：[https://doi.org/10.3929/ethz-b-000680438](https://doi.org/10.3929/ethz-b-000680438)'
- en: '[26] R. D. Zimmerman and C. E. Murillo-Sánchez, “Matpower 8.0 user’s manual,”
    2024\. [Online]. Available: [https://matpower.org/docs/MATPOWER-manual-8.0.pdf](https://matpower.org/docs/MATPOWER-manual-8.0.pdf)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] R. D. Zimmerman 和 C. E. Murillo-Sánchez，“Matpower 8.0 用户手册，”2024年。[在线].
    可用链接：[https://matpower.org/docs/MATPOWER-manual-8.0.pdf](https://matpower.org/docs/MATPOWER-manual-8.0.pdf)'
- en: '[27] OpenAI, “Chatgpt-4o,” 2024, language model used for language polishing
    in this manuscript. [Online]. Available: [https://openai.com/](https://openai.com/)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] OpenAI，“Chatgpt-4o，”2024年，用于本文档语言润色的语言模型。[在线]. 可用链接：[https://openai.com/](https://openai.com/)'
