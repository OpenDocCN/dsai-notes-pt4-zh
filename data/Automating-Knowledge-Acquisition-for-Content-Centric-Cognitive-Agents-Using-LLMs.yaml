- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 12:59:12'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 12:59:12'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Automating Knowledge Acquisition for Content-Centric Cognitive Agents Using
    LLMs
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用大型语言模型（LLMs）自动化内容中心认知代理的知识获取
- en: 来源：[https://arxiv.org/html/2312.16378/](https://arxiv.org/html/2312.16378/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2312.16378/](https://arxiv.org/html/2312.16378/)
- en: Sanjay Oruganti, Sergei Nirenburg\equalcontrib, Jesse English\equalcontrib,
    Marjorie McShane\equalcontrib
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Sanjay Oruganti, Sergei Nirenburg\equalcontrib, Jesse English\equalcontrib,
    Marjorie McShane\equalcontrib
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The paper describes a system that uses large language model (LLM) technology
    to support automatic learning of new entries in an intelligent agent’s semantic
    lexicon. The process is bootstrapped by an existing non-toy lexicon and a natural
    language generator that converts formal, ontologically-grounded representations
    of meaning into natural language sentences. The learning method involves a sequence
    of LLM requests and includes an automatic quality control step. To date, this
    learning method has been applied to learning multiword expressions whose meanings
    are equivalent to those of transitive verbs in the agent’s lexicon. The experiment
    demonstrates the benefits of a hybrid learning architecture that integrates knowledge-based
    methods and resources with both traditional data analytics and LLMs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文描述了一种使用大型语言模型（LLM）技术来支持智能代理语义词汇中新条目自动学习的系统。该过程由现有的非玩具型词汇和自然语言生成器启动，后者将基于本体的正式意义表示转换为自然语言句子。学习方法包括一系列LLM请求，并包含自动质量控制步骤。迄今为止，这种学习方法已应用于学习多词表达式，其意义等同于代理词汇中及物动词的意义。实验展示了将基于知识的方法和资源与传统数据分析方法和LLMs结合的混合学习架构的好处。
- en: Introduction and Motivation
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言与动机
- en: Content-centric computational cognitive modeling Nirenburg, McShane, and English
    ([2020](#bib.bib4)) stresses the importance of static knowledge resources as core
    components of cognitive architectures. To make cognitive agent systems deployable
    in real-world applications, they must be supported on vast amounts of knowledge
    about the world, about language, about themselves, and about other agents. It
    is notoriously difficult to acquire such knowledge in amounts – and at the quality
    level – necessary to deploy AI members of human-AI teams performing real-world
    tasks. As the development of such agents is the main goal of our R&D team, knowledge
    acquisition has been a central concern for a long time Monarch and Nirenburg ([1988](#bib.bib2));
    Viegas and Nirenburg ([1995](#bib.bib10), [1996](#bib.bib11)); McShane and Nirenburg
    ([2021](#bib.bib1)); Nirenburg, Krishnaswamy, and McShane ([2023](#bib.bib3)).
    The general goal is to make knowledge acquisition less expensive over time by
    progressively automating it using any method or combination of methods that look
    promising. Our early efforts concentrated on data analytics support ergonomics
    of manual acquisition Wilks and Nirenburg ([1995](#bib.bib13)) . Once our team
    developed a reliable system for semantic and pragmatic analysis of text and acquired
    a non-toy set of knowledge resources to support it, we started experimenting with
    using the system itself to bootstrap an automatic learning process through learning
    by reading Nirenburg, Oates, and English ([2007](#bib.bib5)) and dialog with a
    human Nirenburg and Wood ([2017](#bib.bib6)) . This paper reports on one of our
    first experiments on using large language models (LLMs) to support the next step
    in automating knowledge acquisition for cognitive agents.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 内容中心的计算认知建模Nirenburg、McShane 和 English（[2020](#bib.bib4)）强调了将静态知识资源作为认知架构核心组件的重要性。为了使认知代理系统能够在现实世界应用中部署，它们必须基于大量的关于世界、语言、自己以及其他代理的知识来进行支持。获取如此数量和质量的知识，尤其是为了部署能在现实世界任务中执行的人工智能（AI）成员，通常是非常困难的。由于开发这类代理是我们研发团队的主要目标，因此知识获取长期以来一直是我们关注的核心问题，Monarch
    和 Nirenburg（[1988](#bib.bib2)）；Viegas 和 Nirenburg（[1995](#bib.bib10)，[1996](#bib.bib11)）；McShane
    和 Nirenburg（[2021](#bib.bib1)）；Nirenburg、Krishnaswamy 和 McShane（[2023](#bib.bib3)）。我们的总体目标是通过逐步自动化知识获取，利用任何看似有效的方法或方法组合，使知识获取变得更加经济。我们最初的努力集中在数据分析支持的手动获取的人机工程学上，Wilks
    和 Nirenburg（[1995](#bib.bib13)）。一旦我们的团队开发出了可靠的语义和语用分析系统，并获得了一套非玩具型的知识资源以支持该系统，我们便开始尝试利用该系统本身通过阅读学习Nirenburg、Oates
    和 English（[2007](#bib.bib5)）以及与人类对话Nirenburg 和 Wood（[2017](#bib.bib6)）来启动自动学习过程。本文报告了我们首次使用大型语言模型（LLMs）支持认知代理知识获取自动化下一步的实验之一。
- en: Large Language Models (LLMs), based on the transformer architecture Vaswani
    et al. ([2017](#bib.bib9)), are crafted to emulate human-like responses by computing
    the best continuations (similar to dialog turns) for textual prompts provided
    by humans on the basis of training on vast amounts of stored text. LLMs excel
    in generating the next word in a sentence, and they neither understand what they
    are doing nor why. As a result, there are issues with deploying them in applications
    requiring trust based on explainability. Nevertheless, while LLM-oriented AI researchers
    are addressing this issue, LLMs can already be made useful as a tool, and the
    experiment we are describing is an example of such use.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基于变压器架构的**大型语言模型**（LLMs）（Vaswani等，[2017](#bib.bib9)）被设计用来模拟类似人类的回应，通过计算文本提示的最佳延续（类似对话轮次），基于大量存储文本的训练来提供人类输入的响应。LLMs擅长生成句子中的下一个单词，但它们并不理解自己在做什么，也不知道为什么要这样做。因此，在需要基于可解释性的信任的应用程序中部署LLMs时存在问题。然而，尽管LLM领域的AI研究人员正在解决这一问题，LLMs已经可以作为工具发挥作用，我们所描述的实验就是这种用途的一个例子。
- en: '![Refer to caption](img/2cf244162fa838d30d6aa87c982279ef.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题说明](img/2cf244162fa838d30d6aa87c982279ef.png)'
- en: 'Figure 1: A sample lexicon entry and ontological concept'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个典型的词汇条目和本体概念示例
- en: The experiment targets the automatic expansion of our architecture’s semantic
    lexicon that links words and constructions in natural language with their semantic
    and pragmatic meanings represented as elements of a formal ontology McShane and
    Nirenburg ([2021](#bib.bib1)).¹¹1In reality, lexicon entries contain more information,
    including a variety of dynamic meaning procedures that must be run to determine
    meanings of particular lexical units in context. Our current English lexicon contains
    about 30,000 words and construction senses that are interpreted using an ontology
    of about 9,000 concepts. Each concept is characterized by an average of 16 properties.
    The present ontology uses about 350 of these properties that have the status of
    axioms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 实验的目标是自动扩展我们架构的语义词汇，这个词汇将自然语言中的单词和结构与其语义和语用意义相连接，并将这些意义表示为形式化本体的元素（McShane和Nirenburg，[2021](#bib.bib1)）。¹¹1实际上，词汇条目包含更多信息，包括一系列动态意义处理程序，必须运行这些程序以确定特定词汇单元在上下文中的含义。我们当前的英语词汇包含大约30,000个单词和结构意义，这些意义通过约9,000个概念的本体来进行解释。每个概念平均具有16个属性。目前的本体使用了大约350个具有公理性质的属性。
- en: The experiment was devoted to learning the senses of verbs. A typical lexicon
    entry for a verb is illustrated in Figure [1](#Sx1.F1 "Figure 1 ‣ Introduction
    and Motivation ‣ Automating Knowledge Acquisition for Content-Centric Cognitive
    Agents Using LLMs"). The sem-struc zone of the entry refers to the underlying
    ontological concept and provides constraints on the verb’s case roles – it’s agent,
    theme, beneficiary, etc., as appropriate. Additionally, Figure [1](#Sx1.F1 "Figure
    1 ‣ Introduction and Motivation ‣ Automating Knowledge Acquisition for Content-Centric
    Cognitive Agents Using LLMs") also presents the ontological entry for hire, the
    concept supplying the basic meaning of employ-v3.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该实验专注于学习动词的意义。图[1](#Sx1.F1 "图1 ‣ 引言与动机 ‣ 使用LLMs自动化内容中心认知代理的知识获取")展示了一个动词的典型词汇条目。条目的**sem-struc**区段指示底层本体概念，并对动词的格角色提供约束——例如它的施事、主题、受益人等，视情况而定。此外，图[1](#Sx1.F1
    "图1 ‣ 引言与动机 ‣ 使用LLMs自动化内容中心认知代理的知识获取")还展示了"hire"（雇佣）的本体条目，这一概念提供了“employ-v3”的基本含义。
- en: '![Refer to caption](img/2d57315bdac706b830b82b0c32c0a03c.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题说明](img/2d57315bdac706b830b82b0c32c0a03c.png)'
- en: 'Figure 2: An MWE (phrasal verb) entry.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：一个多词单位（短语动词）条目。
- en: The goal of our experimental set-up is to expand the system’s static knowledge
    resources by automatically learning other ways of expressing in English the meanings
    of verbal senses, such as employ-v3. This task cannot be carried out with confidence
    by using thesauri or WordNets because their offerings are too imprecise and do
    not conform to the ”seed” word either semantically or (especially for verbs) syntactically.
    ²²2For a detailed discussion of why existing dictionaries, thesauri and wordnets
    cannot be used as resources for automating knowledge acquisition, see Chapter
    3 of McShane et al. forthcoming. The general LLM-supported learning procedure
    we used in this experiment consists of five steps described below.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实验设置的目标是通过自动学习其他表达动词意义的英语方式，扩展系统的静态知识资源，例如 employ-v3。此任务无法仅依靠同义词词典或 WordNet
    自信地完成，因为它们提供的内容过于模糊，不符合“种子”词的语义或（特别是对于动词）句法约束。²²2有关为何现有词典、同义词词典和词网无法作为自动化知识获取资源的详细讨论，参见
    McShane 等人即将出版的《第3章》。我们在本实验中使用的通用 LLM 支持学习过程包括以下五个步骤。
- en: 'Step 1:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '步骤 1:'
- en: Select a seed verb sense from the lexicon. Using the sem-struc zone of this
    sense, construct a semantically correct statement in the ontological metalanguage
    using ontological constraints on the verb sense’s case roles listed in the entry
    or in the ontology. For example, the agent of hire (which is the ontological concept
    expressing the meaning of employ-v3) is constrained to managerial-role, while
    its theme is constrained to human³³3This is a simplification, as the lexicon and
    ontology feature multiple layers of constraints. We use the grain size of description
    sufficient to explain the experimental procedure.. So, the resulting general template
    will be hire (managerial-role, human).
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从词汇表中选择一个种子动词意义。使用该意义的 sem-struc 区域，在本体元语言中根据动词意义的案例角色约束，构建一个语义正确的陈述，这些角色在条目或本体中有列出。例如，hire
    的施事（它是表示 employ-v3 含义的本体概念）被约束为管理角色，而其主题被约束为人类³³3这是一个简化，因为词汇表和本体包含多个约束层次。我们使用足够的描述粒度来解释实验过程。所以，最终得到的一般模板将是
    hire（管理角色，人类）。
- en: 'Step 2:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '步骤 2:'
- en: Use the above template to automatically construct a set of sample generation-oriented
    meaning representations (GMRs) that substitute lexicon entries whose meanings
    directly reference the constraints in the template. An example of such a GMR would
    be employ-v3 (manager-1, actor-1). It conforms to the semantic constraints on
    hire because the meaning of manager-1 is managerial-role, and that of actor-1
    is human. In our experiment, these GMR sets were constrained in size to reduce
    the compute requirements.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用上述模板自动构造一组生成导向的意义表示（GMRs），替代那些直接引用模板约束条件的词汇条目。这样的 GMR 示例可能是 employ-v3（manager-1，actor-1）。它符合
    hire 的语义约束，因为 manager-1 的含义是管理角色，而 actor-1 的含义是人类。在我们的实验中，这些 GMR 集合的大小被限制，以减少计算需求。
- en: 'Step 3:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '步骤 3:'
- en: Use the text generator module of our agent system to generate English sentences
    from the above GMRs. The resulting set of sentences is our best bet to convey
    the meaning of the seed verb to an analogical reasoning engine such as an LLM
    (without much additional training LLMs will not be able to operate over formal
    meaning representations such as the GMRs). This method of explaining lexical meaning
    is what people usually use, though people, of course, can both use analogical
    reasoning and invoke world knowledge in interpreting novel lexical material.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用我们代理系统的文本生成模块，根据上述的 GMR（语义表示）生成英文句子。得到的句子集合是我们最有可能传达种子动词含义的一种方式，适用于类比推理引擎，如大型语言模型（LLM）。由于没有经过额外训练，LLM
    通常无法处理像 GMR 这样的形式化意义表示。这种解释词汇意义的方法是人们通常使用的方式，当然，人们也可以在解释新颖词汇材料时同时运用类比推理和调动世界知识。
- en: 'Step 4:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '步骤 4:'
- en: Use an LLM to generate a list of multiword expressions (MWEs – typically, verbs
    with postpositions, e.g., bring in) semantically equivalent to the seed verb sense
    whose contextual meaning is illustrated by the set of sentences generated in step
    3\. Details of this process form the core of this paper’s content and are detailed
    in Section [Adapting LLMs for Conceptual Learning](#Sx2 "Adapting LLMs for Conceptual
    Learning ‣ Automating Knowledge Acquisition for Content-Centric Cognitive Agents
    Using LLMs") below.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用LLM生成一个多词表达（MWEs）的列表（通常是带有后置词的动词，例如：bring in），这些表达语义上等同于种子动词意义，并且其上下文意义通过步骤3中生成的句子集来说明。本过程的详细信息是本文内容的核心，并在下面的[适应LLM进行概念学习](#Sx2
    "Adapting LLMs for Conceptual Learning ‣ Automating Knowledge Acquisition for
    Content-Centric Cognitive Agents Using LLMs")章节中详细介绍。
- en: 'Step 5:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 步骤5：
- en: Construct a new lexical sense for each of the MWEs output from Step 4\. This
    is done by ”cloning” the sense of the seed verb (see Figure LABEL:fig:phrasal-verb-entry
    for an example), adding the requirement for the presence of the lexical material
    other than the main verb to the syn-struc zone of the newly learned entry (the
    postposition after in the example) and modifying the sem-struc zone of the entry
    by including the instruction that this ”extra” lexical material does not carry
    any semantic weight when appearing in this MWE (marked as null-sem+). A sampling
    of sentences generated for validation purposes in Step 4 is listed in the EXAMPLE
    zone of the new entry. (As a side effect, a sample of the sentences generated
    in Step 3 is added to the EXAMPLE zone of the entry of the seed verb sense.) The
    new lexical senses are marked as ”learned”. The agent is still free to use them
    but may consider them less reliable when scoring TMR candidates during future
    agent processing. The intention is for a knowledge engineer at some point to inspect
    – and possibly edit – these learned senses before removing the ”learned”. marking.
    The level of human involvement in this kind of validation incurs significantly
    lower cognitive loads than manual lexicon acquisition, thus making the entire
    process less expensive and much more efficient.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为步骤4输出的每个多词表达（MWEs）构建一个新的词汇意义。这是通过“克隆”种子动词的意义来完成的（参见图示 LABEL:fig:phrasal-verb-entry
    获取示例），将除了主要动词之外的其他词汇材料的要求添加到新学习条目的语法结构区（例如示例中的后置词“in”），并通过包含指令修改该条目的语义结构区，指示这些“额外”的词汇材料在该多词表达中出现时不携带任何语义分量（标记为null-sem+）。为验证目的在步骤4中生成的句子示例列在新条目的EXAMPLE区。（作为副作用，步骤3中生成的句子示例也会被添加到种子动词意义条目的EXAMPLE区。）新的词汇意义被标记为“已学习”。代理仍然可以使用这些词汇，但在未来的代理处理过程中，在对TMR候选项进行评分时，可能会认为它们不那么可靠。目的是让知识工程师在某个时刻检查——并可能编辑——这些已学习的意义，之后再去掉“已学习”的标记。此类验证中的人类参与程度相比手动词汇获取，认知负担显著较低，因此使整个过程更加高效且成本更低。
- en: Adapting LLMs for Conceptual Learning
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 适应LLM进行概念学习
- en: The first issue in adapting LLMs for use in conceptual learning for cognitive
    agents is devising the most appropriate prompting architecture. Prompts serve
    as adjustable parameters that fine-tune the language models to yield desired outputs
    for specific tasks. In plain words, it is not enough to supply the LLMs with the
    output of the previous stage of the learning process, even if measures are taken
    to represent that output in natural language rather than a formal metalanguage
    that LLMs will not be able to interpret. We need to tell the LLMs what we want
    them to do. Many strategies have been proposed for designing LLM prompts and prompting
    architectures Zhou et al. ([2022](#bib.bib15)). It has been shown that composing
    a single optimal prompt can be both challenging and ineffective, especially considering
    that LLM behavior is unpredictable. One proposed improvement is the “chain of
    thought” prompting approach Wei et al. ([2022](#bib.bib12)), which involves simplifying
    complex prompts by breaking them down into a series of manageable intermediate
    steps. This technique also allows for dynamic adaptation of process flows based
    on the outputs at intermediate stages Yao et al. ([2022](#bib.bib14)) and risk
    mitigation through validation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将LLM应用于认知智能体的概念学习中的第一个问题是设计最合适的提示架构。提示作为可调节参数，用于微调语言模型，从而为特定任务生成期望的输出。通俗来说，仅仅将前一个学习阶段的输出提供给LLM是远远不够的，即使我们采取措施以自然语言而非LLM无法解读的正式元语言来表示该输出。我们需要明确告诉LLM我们希望它做什么。许多策略已经提出用于设计LLM的提示和提示架构，Zhou等人（[2022](#bib.bib15)）对此进行了研究。研究表明，组合一个最优的单一提示既具挑战性又可能无效，特别是考虑到LLM的行为具有不可预测性。一个提出的改进是“思维链”提示方法，Wei等人（[2022](#bib.bib12)）提出了这一方法，该方法通过将复杂的提示分解为一系列可管理的中间步骤来简化提示。此技术还允许基于中间阶段的输出动态调整过程流程，并通过验证实现风险缓解，Yao等人（[2022](#bib.bib14)）也对此进行了研究。
- en: 'Constructing single monolithic prompts with placeholders for the seed verb
    sense and sentences generated in step 3 might seem to offer a simpler approach
    to prompting the LLM. For example, a prompt could be as simple as “In the context
    of the text, generate phrasal verbs that could replace the seed. Also, provide
    a contextually accurate example for the substituted phrasal verb.” However, when
    tested using both GPT-3.5 and GPT-4 Radford et al. ([2019](#bib.bib7)), this approach
    proved ineffective: LLMs returned inadequate results. This prompt template proved
    too complex, as it contained multiple instructions and potential ambiguity due
    to insufficient detail. To improve the quality of LLM output, we enhanced the
    prompting architecture with “prompt catalysts” (see Figure [3](#Sx2.F3 "Figure
    3 ‣ Adapting LLMs for Conceptual Learning ‣ Automating Knowledge Acquisition for
    Content-Centric Cognitive Agents Using LLMs")): a) using prompt template sequences
    and b) embedding analytics obtained from reliable data sources Santu and Feng
    ([2023](#bib.bib8)).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 构建单一的整体提示，其中包含种子动词含义和步骤3中生成的句子的占位符，可能看起来是一种更简单的提示LLM的方法。例如，提示可以简单到像“在文本的上下文中，生成可以替换种子的短语动词，并为替换的短语动词提供一个上下文准确的例子。”然而，在使用GPT-3.5和GPT-4进行测试时，Radford等人（[2019](#bib.bib7)）发现这种方法无效：LLM返回的结果不充分。这种提示模板过于复杂，因为它包含多个指令，并且由于细节不足而可能产生歧义。为了提高LLM输出的质量，我们通过“提示催化剂”来增强提示架构（参见图[3](#Sx2.F3
    "图3 ‣ 将LLM应用于概念学习 ‣ 使用LLM自动化内容中心认知智能体的知识获取")）：a）使用提示模板序列，b）嵌入来自可靠数据源的分析结果，Santu和Feng（[2023](#bib.bib8)）对此进行了研究。
- en: '![Refer to caption](img/b08a7cc400cf70b6b2f8368e0fd815c2.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b08a7cc400cf70b6b2f8368e0fd815c2.png)'
- en: 'Figure 3: A schematic view of the LLM-Supported knowledge acquisition framework
    for language-endowed cognitive agents. The process is “seeded” with a word sense
    as input. Next, the knowledge-based language processor generates a set of semantically
    correct seed sentences containing that word sense. The seeds are incorporated
    into a chain of prompts to an LLM whose responses (in this experiment, MWEs and
    sample sentences containing them) are validated by asking the LLM itself to assess
    whether the semantics of the results it produces correspond to that of the seed
    word in the sense illustrated by the seed sentences. An alternative validation
    method substitutes sentences attested in the COCA corpus for sample sentences
    generated by LLMs.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：一种LLM支持的语言赋能认知体的知识获取框架示意图。该过程以一个词义作为输入进行“初始化”。接下来，基于知识的语言处理器生成一组包含该词义的语义正确的种子句子。这些种子被整合成一链条，作为提示输入LLM，LLM的响应（在本实验中，是包含多词表达（MWEs）和示例句子的响应）通过要求LLM自身评估它产生的结果的语义是否与种子句子所示的种子词的语义相对应来进行验证。另一种验证方法是用COCA语料库中的句子替代LLM生成的示例句子。
- en: 'Our approach to prompt engineering facilitates conveying the semantics of the
    seed verb sense to an analogical reasoning engine, such as an LLM, as precisely
    as possible without the use of formal metalanguage. For the experiment we describe,
    we designed a prompt template chain (Figure [3](#Sx2.F3 "Figure 3 ‣ Adapting LLMs
    for Conceptual Learning ‣ Automating Knowledge Acquisition for Content-Centric
    Cognitive Agents Using LLMs")) consisting of a base generic prompt template followed
    by three templates with placeholders for specific input data to support to support
    three substeps of Step 4 in the overall learning process: 1) a template for generating
    synonymous MWEs, 2) a template for generating sentences with these MWEs needed
    for validation and 3) a template for validation proper. The template chain we
    constructed effectively follows the chain of thought prompting approach (Wei 2022).
    Each prompt in the chain is sent as input to the LLM (we used the GPT-3.5 APIs
    from Open AI for this experiment). The LLM response to each prompt is then embedded
    in the subsequent prompts in the chain, which is necessary because LLMs lack memory
    of their prior processing.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的提示工程方法旨在尽可能精确地将种子动词意义的语义传达给类比推理引擎（如LLM），而不使用正式的元语言。对于我们描述的实验，我们设计了一个提示模板链（图
    [3](#Sx2.F3 "图 3 ‣ 为概念学习调整LLM ‣ 使用LLM自动化内容中心认知体的知识获取")），该链包括一个基本的通用提示模板，后跟三个具有特定输入数据占位符的模板，支持整体学习过程中的步骤
    4 的三个子步骤：1）生成同义多词表达（MWE）的模板，2）生成用于验证的包含这些MWE的句子的模板，3）用于验证的正确模板。我们构建的模板链有效地遵循了链式思维提示方法（Wei
    2022）。链中的每个提示都会作为输入发送给LLM（我们在本实验中使用了Open AI的GPT-3.5 API）。LLM对每个提示的响应随后会嵌入到链中后续的提示中，因为LLM缺乏对其先前处理的记忆。
- en: The primary function of the base prompt is to present a particular task to the
    LLM and explain its role in completing that task. The base prompt does not include
    any placeholders for data. For instance, in the current experiment, the base prompt
    involves a simple role assignment, as illustrated in Figure [4](#Sx2.F4 "Figure
    4 ‣ Adapting LLMs for Conceptual Learning ‣ Automating Knowledge Acquisition for
    Content-Centric Cognitive Agents Using LLMs").
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本提示的主要功能是向LLM展示一个特定任务，并解释其在完成该任务中的角色。基本提示不包含任何数据占位符。例如，在当前实验中，基本提示涉及一个简单的角色分配，如图
    [4](#Sx2.F4 "图 4 ‣ 为概念学习调整LLM ‣ 使用LLM自动化内容中心认知体的知识获取")所示。
- en: '![Refer to caption](img/053fdcaf55f5b98ac02c407e9d906617.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/053fdcaf55f5b98ac02c407e9d906617.png)'
- en: 'Figure 4: An example of the learner operation illustrating the generation of
    MWEs synonymous with the seed verb and two methods of generating sample sentences
    for use in the validation step: Path 1 illustrates the use of LLMs while Path
    2 illustrates the use of the COCA corpus for this purpose. In every iteration
    of the experiment, only one of the two paths is selected for sentence generation,
    with its results then forwarded to the validation step. A different LLM may be
    used for each of the three applications of LLMs in this process, should this option
    prove beneficial.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：学习者操作示例，说明了与种子动词同义的多词表达（MWE）的生成，以及两种生成样本句子的验证方法：路径1展示了使用大语言模型（LLMs），而路径2则展示了使用COCA语料库的方式。在实验的每一轮中，只选择这两条路径中的一条来生成句子，并将其结果转发至验证步骤。如果此选项证明有效，可以为该过程中大语言模型的三次应用使用不同的大语言模型。
- en: The MWE generation substep of Step 4 of the learning process requires the seed
    verb and the set of sentences (the output of Stage 3 of the learning process)
    as placeholders for the prompt template. At the validation substep, the LLM is
    asked to assess the quality of its own results from the generation substep. LLMs
    do this essentially by comparing the “gold standard” sentences generated in Step
    3 of the learning process to illustrate the meaning of the seed verb sense against
    sentences containing the MWEs it generated at the previous substep. So, following
    the chain of thought method, the prompt for the validation substep incorporates
    a) the content of all the upstream prompts, b) the content of the response from
    the MWE generation substep, and c) a set of sentences containing each of the MWEs
    in this response. So, before validation can be triggered, an intermediate substep
    devoted to deriving the set of sentences in c) above is required.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 学习过程中的步骤4的MWE生成子步骤需要种子动词和句子集（即学习过程阶段3的输出）作为提示模板的占位符。在验证子步骤中，大语言模型被要求评估其在生成子步骤中的结果质量。大语言模型通过将学习过程步骤3中生成的“金标准”句子进行比较，来评估其自身结果的质量，这些金标准句子用于阐明种子动词的意义，并与包含其在上一个子步骤中生成的MWE的句子进行比较。因此，遵循思维链方法，验证子步骤的提示包括：a)
    所有上游提示的内容，b) 来自MWE生成子步骤的响应内容，以及c) 包含该响应中每个MWE的句子集。因此，在触发验证之前，需要一个中间子步骤来推导上述c)中的句子集。
- en: 'How should we go about generating this set of sentences? We implemented two
    approaches (labeled as “paths” in Figure [4](#Sx2.F4 "Figure 4 ‣ Adapting LLMs
    for Conceptual Learning ‣ Automating Knowledge Acquisition for Content-Centric
    Cognitive Agents Using LLMs")): a) using the LLM itself to generate the set and
    or b) using data analytics to conduct a search in a text corpus for sentences
    containing the MWEs suggested by the LLM at the MWE generation substep. The LLM
    approach, as always, involved prompting the model with the cumulative prompt incorporating
    the latest response and the upstream prompts. The analytics approach used the
    COCA corpus (Davies 2008) and seeded the search with the set of all the morphological
    forms of the main verb in the MWE. In our experimentation, results from one or
    the other of the methods were used intermittently as inputs to the downstream
    validation step.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该如何生成这一组句子呢？我们实现了两种方法（在图[4](#Sx2.F4 "图4 ‣ 适应大语言模型进行概念学习 ‣ 使用大语言模型自动获取面向内容的认知代理的知识")中标记为“路径”）：a)
    使用大语言模型本身生成句子集；b) 使用数据分析方法在文本语料库中进行搜索，查找包含在MWE生成子步骤中由大语言模型建议的MWE的句子。大语言模型方法，像往常一样，通过将累积的提示（包括最新的响应和上游的提示）提供给模型来执行。数据分析方法则使用了COCA语料库（Davies
    2008），并通过将主要动词的所有形态形式作为种子，来启动对句子的搜索。在我们的实验中，时断时续地使用这两种方法的结果作为输入，供下游验证步骤使用。
- en: In the LLM path (Path 1), additional filtering proved to be necessary to filter
    out irrelevant sentences from LLM-generated responses, specifically, sentences
    the LLM generated to shape its response as a dialog turn, as it was trained to
    simulate a behavior of a conversational companion. Figure [4](#Sx2.F4 "Figure
    4 ‣ Adapting LLMs for Conceptual Learning ‣ Automating Knowledge Acquisition for
    Content-Centric Cognitive Agents Using LLMs") provides an illustration. For our
    purposes, the LLM response should ideally consist exclusively of sample sentence
    candidates separated by the ’$||$’ tag. However, LLMs (GPTs 3.5 in this case)
    generates extraneous material. To filter out such material, our system looks for
    the content separated by a specific tag (‘$||$’). In most cases, the elements
    of the response that do not begin with a tag carry extraneous material.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 路径（路径 1）中，额外的过滤步骤被证明是必要的，以从 LLM 生成的响应中过滤掉无关的句子，特别是那些 LLM 生成的句子，这些句子是为了将响应塑造成对话轮次，因为它被训练成模拟对话伙伴的行为。图[4](#Sx2.F4
    "图 4 ‣ 为概念学习调整 LLM ‣ 使用 LLM 为内容中心认知代理自动化知识获取")提供了一个示例。就我们而言，LLM 响应理想情况下应该完全由通过‘$||$’标签分隔的样本句子候选项组成。然而，LLM（此处是
    GPT-3.5）会生成多余的内容。为了过滤掉这些内容，我们的系统会查找通过特定标签（‘$||$’）分隔的内容。在大多数情况下，响应中那些没有以标签开始的元素携带着多余的内容。
- en: 'WORD: measure'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 单词：衡量
- en: 'TEXT: An actor measured a matter.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 文本：一个演员衡量了一个问题。
- en: 'LLM RESPONSE:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 响应：
- en: '”I apologize for the confusion. Here are several example sentences illustrating
    the use of the phrasal verb ‘take stock’: $||$ Let’s take stock of our inventory
    before placing the order. $||$ After a long day at work, I like to take stock
    of my accomplishments$||$”'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: “对于混淆，我深感抱歉。以下是几个示例句子，展示了短语动词‘take stock’的用法：$||$ 在下订单之前，让我们先清点一下库存。$||$ 工作了一整天后，我喜欢清点一下我的成就$||$”
- en: 'FILTERED RESPONSE (candidates):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤后的响应（候选项）：
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Let’s take stock of our inventory before placing the order.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在下订单之前，让我们先清点一下库存。
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: After a long day at work, I like to take stock of my accomplishments.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 工作了一整天后，我喜欢清点一下我的成就。
- en: 'Figure 5: An example showing filtering applied to LLM response in path 1\.
    Here the excessive text that is in red was removed and the sentences delimited
    by ‘$||$’'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：一个示例，展示了在路径 1 中对 LLM 响应应用过滤。在这里，红色部分的多余文本被删除，句子通过‘$||$’符号进行分隔
- en: In the analytics path (Path 2), the COCA search is preceded by using the NLTK
    libraries to generate all morphological forms of the main verb in the MWEs – e.g.,
    look up, looks up, looking up, looked up. Note that for both of the above methods,
    we have the ability to generate or select sentences where the MWE components are
    discontinuous. So, for example, the sentence ”The puppy managed to run, suddenly,
    off towards the park could” be found for the MWE ”run off.”
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析路径（路径 2）中，COCA 搜索前会使用 NLTK 库生成 MWEs 中主要动词的所有形态变化形式——例如：查找，查找，正在查找，查找过。请注意，对于上述两种方法，我们可以生成或选择
    MWE 组件不连续的句子。例如，句子“这只小狗突然跑向公园”可以找到 MWE “run off”。
- en: INITIAL PROMPT PARAMETERS
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 初始提示参数
- en: '$\rightarrow$WORD: guess'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: $\rightarrow$单词：猜测
- en: '$\rightarrow$TEXT: A human being guessed a factor.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: $\rightarrow$文本：一个人猜测了一个因素。
- en: RESPONSE-1
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 响应-1
- en: '$\rightarrow$MWEs:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: $\rightarrow$多词表达：
- en: '.......[figure out, take a shot, take a stab, work out]'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '.......[想出，尝试，试一试，解决]'
- en: PATH 1 RESPONSE
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 路径 1 响应
- en: '.... FILTERED CANDIDATE SENTENCES'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 过滤后的候选句子'
- en: (Subset for take a shot )
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: （“试一试”子集）
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The detective took a shot at who might be the main suspect based on the available
    clues.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 侦探根据可用的线索猜测了谁可能是主要嫌疑人。
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: She took a shot at persuading her parents to let her go on the trip with her
    friends.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 她尝试说服父母让她和朋友一起去旅行。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Despite having no experience in cooking, he took a shot at preparing a gourmet
    meal for his guests.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尽管没有烹饪经验，他还是尝试为他的客人准备了一顿美味的晚餐。
- en: '.... VALIDATION RESPONSE'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 有效性验证响应'
- en: The detective took a shot at who
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 侦探根据可用线索猜测了谁
- en: might be the main suspect based on the
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 可能是基于
- en: available clues.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 可用线索。
- en: PATH 2 RESPONSE
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 路径 2 响应
- en: '.... FILTERED CANDIDATE SENTENCES'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 过滤后的候选句子'
- en: (Subset for take a shot )
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: （“试一试”子集）
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: I took a camera , I took a shot
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我拿了一个相机，我拍了一张照片
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Somewhere in there , he took a shot at the Olympics.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在某个地方，他在奥运会上尝试了一下。
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: So I took a shot, got lucky.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所以我试了一下，运气不错。
- en: '.... VALIDATION RESPONSE'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 有效性验证响应'
- en: So I took a shot, got lucky.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我试了一下，运气不错。
- en: 'Figure 6: Example 1 showing MWEs generated for the seed word guess and the
    context text input from step 3\. The example shows candidate sentences for the
    take a shot MWE obtained from paths 1 and 2 and their corresponding validation
    responses.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：示例 1 展示了为种子词“猜测”生成的多词表达（MWEs）及来自步骤 3 的上下文文本输入。该示例展示了从路径 1 和路径 2 获得的“采取尝试”MWEs的候选句子及其对应的验证响应。
- en: INITIAL PROMPT PARAMETERS
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 初始提示参数
- en: '$\rightarrow$WORD: employ'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: $\rightarrow$单词：雇佣
- en: '$\rightarrow$TEXT: A leader employed a human.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: $\rightarrow$文本：一位领导雇佣了一名人类。
- en: RESPONSE-1
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 响应-1
- en: '$\rightarrow$MWEs:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '$\rightarrow$MWEs:'
- en: '.......[bring in, hire on, take on]'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '.......[带进，雇佣，承担]'
- en: PATH 1 RESPONSE
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 路径 1 响应
- en: '.... FILTERED CANDIDATE SENTENCES'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 过滤后的候选句子'
- en: (Subset for bring in )
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: （带进的子集）
- en: •
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The zoo plans to bring in a pair of rare pandas to attract more visitors.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 动物园计划引进一对稀有的大熊猫以吸引更多游客。
- en: •
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The school decided to bring in a motivational speaker to inspire the students.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学校决定引进一位激励演讲者来鼓舞学生。
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The government is looking to bring in stricter regulations to protect the environment.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 政府计划引入更严格的规定以保护环境。
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A leader brought in a new employee.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一位领导带来了一位新员工。
- en: '.... VALIDATION RESPONSE'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 验证响应'
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The school decided to bring in a motivational speaker to inspire the students.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学校决定引进一位激励演讲者来鼓舞学生。
- en: •
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A leader brought in a new employee
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一位领导带来了一位新员工。
- en: PATH 2 RESPONSE
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 路径 2 响应
- en: '.... FILTERED CANDIDATE SENTENCES'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 过滤后的候选句子'
- en: (Subset for bring in )
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: （带进的子集）
- en: •
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Bring in an expert.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 引进一位专家。
- en: •
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Mason fiddled with the dial, trying to bring in the station.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 梅森摆弄着旋钮，试图调入该电台。
- en: •
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Amy gets up to help her and the two of them bring in the salad plates.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 艾米站起来帮助她，两人一起端来了沙拉盘。
- en: '.... VALIDATION RESPONSE'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '.... 验证响应'
- en: Bring in an expert.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 引进一位专家。
- en: 'Figure 7: Example 2 showing MWEs generated for the seed word employ and the
    context text input from step 3\. The example shows candidate sentences for the
    bring in MWE obtained from paths 1 and 2 and their corresponding validation responses.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：示例 2 展示了为种子词“雇佣”生成的多词表达（MWEs）及来自步骤 3 的上下文文本输入。该示例展示了从路径 1 和路径 2 获得的“带进”MWEs的候选句子及其对应的验证响应。
- en: 'The filtering process described above is part of the sentence generation substep
    of Step 4 of the overall process and differs from the validation substep. The
    former targets irrelevant sentences while the latter carries out a more semantically
    meaningful task: it filters out sentences that contain the MWEs used in a sense
    different from that of the seed verb sense. Figures [6](#Sx2.F6 "Figure 6 ‣ Adapting
    LLMs for Conceptual Learning ‣ Automating Knowledge Acquisition for Content-Centric
    Cognitive Agents Using LLMs") and [7](#Sx2.F7 "Figure 7 ‣ Adapting LLMs for Conceptual
    Learning ‣ Automating Knowledge Acquisition for Content-Centric Cognitive Agents
    Using LLMs") illustrate some results of validating the results of the operation
    of each of the two sentence generation methods (Path 1 and Path 2). Thus, in Figure
    [7](#Sx2.F7 "Figure 7 ‣ Adapting LLMs for Conceptual Learning ‣ Automating Knowledge
    Acquisition for Content-Centric Cognitive Agents Using LLMs") the MWE bring in
    in the sense illustrated by the sentence ”The government is looking to bring in
    stricter regulations to protect the environment” was not validated as carrying
    the same meaning as the seed verb sense (employ-v3) whose meaning is illustrated
    by the seed text A leader employed a human generated at Step 3 of the overall
    learning process. As a result, the MWE bring in was eliminated from the list of
    candidates.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的过滤过程是整体过程步骤 4 的句子生成子步骤的一部分，区别于验证子步骤。前者主要剔除不相关的句子，而后者则执行一个更具语义意义的任务：它过滤掉那些含有多词表达（MWEs）且意义与种子动词含义不同的句子。图
    [6](#Sx2.F6 "图 6 ‣ 适应大语言模型进行概念学习 ‣ 使用大语言模型自动化内容为中心的认知代理的知识获取") 和 [7](#Sx2.F7 "图
    7 ‣ 适应大语言模型进行概念学习 ‣ 使用大语言模型自动化内容为中心的认知代理的知识获取") 说明了验证每种句子生成方法（路径 1 和路径 2）操作结果的一些结果。因此，在图
    [7](#Sx2.F7 "图 7 ‣ 适应大语言模型进行概念学习 ‣ 使用大语言模型自动化内容为中心的认知代理的知识获取") 中，句子“政府计划引入更严格的规定以保护环境”中的“带进”MWEs并未被验证为与种子动词含义（雇佣-v3）相同，种子文本“A
    leader employed a human”生成于整体学习过程的步骤 3。因此，“带进”MWEs被从候选列表中删除。
- en: Once the automatic validation of the newly learned set of MWEs is completed,
    the learning process advances to Step 5 of the overall learning algorithm, as
    depicted in Figure [3](#Sx2.F3 "Figure 3 ‣ Adapting LLMs for Conceptual Learning
    ‣ Automating Knowledge Acquisition for Content-Centric Cognitive Agents Using
    LLMs").
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦新学习的多词表达（MWE）集合的自动验证完成，学习过程将进入整体学习算法的第5步，如图[3](#Sx2.F3 "图3 ‣ 为概念学习适配LLM ‣
    使用LLM自动化知识获取为内容中心的认知代理")所示。
- en: Discussion
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: We view the experiment described in this paper as an early step in a multifaceted
    R&D effort on using LLMs to support automatic learning by language-endowed AI
    agents. We intend this learning environment to integrate all and all and any methods
    and resources that can be shown to contribute to the task. The experiment reported
    here demonstrates a method that integrates LLMs and data analytics with knowledge-oriented
    methods and resources in a truly hybrid architecture.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将本文描述的实验视为在使用LLM支持语言赋能的AI代理进行自动学习的多方面研发工作中的初步步骤。我们计划将这个学习环境整合所有可以证明对任务有所贡献的方法和资源。这里报告的实验展示了一种将LLM和数据分析与以知识为导向的方法和资源融合在一个真正的混合架构中的方法。
- en: The system developed for the experiment we describe does not yet make use of
    an important capability our agent systems possess – the ability to extract and
    represent in an ontologically-motivated metalanguage the set of semantic and discourse/pragmatic
    meanings of a text. We have experimented with using this capability for learning
    in the past (e.g., English and Nirenburg 2010), and we intend to incorporate it
    in the learning environment described here. This program of work may seem to aim
    at autonomous learning. But in fact we view our learning environment as an orthotic
    system (Nirenburg 2017) that expects human participation in several roles, notably
    as an instructor in a dialog set-up and as a knowledge engineer responsible for
    tuning up and maintaining the system. Indeed, when our system is deployed and
    starts regular operation, the MWE (and, later, other) lexical senses added to
    the lexicon as a result of the learning process we describe here can – and will
    – be vetted by knowledge engineers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为所描述的实验开发的系统尚未利用我们代理系统所具备的一项重要能力——即能够提取和以本体驱动的元语言表示文本的语义和话语/语用意义集合的能力。我们过去曾尝试过使用这一能力进行学习（例如，English和Nirenburg
    2010），并计划将其纳入此处描述的学习环境中。这个工作计划看似旨在实现自主学习，但事实上我们将我们的学习环境视为一个矫形系统（Nirenburg 2017），该系统期望人在多个角色中参与，尤其是在对话设置中的讲师角色以及作为知识工程师负责调优和维护系统的角色。事实上，当我们的系统投入使用并开始常规操作时，通过我们在此描述的学习过程添加到词汇表中的MWE（以及稍后其他）词汇意义，能够——并且将会——经过知识工程师的验证。
- en: Our team’s experimentation on the integration of knowledge-based methods with
    LLMs is not restricted to learning applications. Our agents use LLMs, for example,
    at a final step of text generation to select the most contextually appropriate
    of the candidate English sentences generated by the agent’s text generator from
    formal representations of the meaning of the message that must be conveyed. While
    all of the options from which the LLM is asked to choose are semantically and
    syntactically correct, the LLM has been shown to select the most appropriate one
    stylistically and contextually, thus obviating the need to develop a conceptual
    system module for this purpose.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们团队关于知识驱动方法与LLM集成的实验不仅仅局限于学习应用。我们的代理使用LLM，例如，在文本生成的最后一步，选择由代理的文本生成器从表达必须传达的消息意义的正式表示中生成的候选英语句子中，最符合上下文的一个。尽管LLM被要求从多个语义和句法正确的选项中选择，但研究表明，LLM能够从风格和上下文角度选择最合适的选项，从而无需为此开发一个概念性系统模块。
- en: Future Work
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未来工作
- en: At the time of writing, we are testing the learning process we described on
    the content of our agent’s lexicon. At the symposium, we will present the results
    of an evaluation of the utility of this method when applied to all 1,153 senses
    of transitive verbs in the our system’s current lexicon. We are also planning
    to extend the learning environment to address other types of lexical material,
    such as learning single-word (not MWE) true synonyms for transitive verbs, intransitive
    verbs and other parts of speech. Learning new and improving existing ontological
    concepts will be tackled next.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，我们正在测试我们所描述的学习过程，内容来自我们代理的词汇表。在研讨会上，我们将展示这一方法在应用于我们系统当前词汇表中1,153个及物动词词义时的评估结果。我们还计划扩展学习环境，以应对其他类型的词汇材料，例如学习及物动词、不及物动词和其他词类的单词（非多词表达）的真实同义词。接下来，我们将处理学习新的本体概念和改进现有的本体概念。
- en: The overall learning process will itself be enhanced and improved. For example,
    in creating GMRs in Step 2 of the process we have not yet used ontological descendants
    of the concepts constraining the meanings of the seed verb sense’s subject and
    direct object. We intend to experiment with this option in the immediate future.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 整个学习过程本身将得到增强和改进。例如，在过程的第2步中创建GMRs时，我们尚未使用约束种子动词意义主语和直接宾语含义的本体后代概念。我们计划在近期内进行这方面的实验。
- en: 'Other planned extensions include using the learning environment to carry out
    “inverted” on-the-fly learning as an approach to treating unexpected input during
    the agent’s regular operation: semantically true paraphrases for an unknown verb
    in a textual input can be generated using the method presented in this paper,
    in hopes that at least some of the paraphrases the system will find are already
    attested in the lexicon. For example, if the word buff is not in the system’s
    lexicon, but our LLM-supported learning process suggests an existing sense of
    polish as having the same meaning, this will yield a double bonus of a) the system
    succeeding in generating a meaning representation for the sentence containing
    buff using the content of the lexicon entry for polish and b) the side effect
    of creating a lexicon entry for buff on the fly. This kind of learning is known
    as opportunistic (e.g., McShane et al., forthcoming, Chapter 6) .'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其他计划中的扩展包括使用学习环境来进行“反向”的即时学习，作为处理代理常规操作过程中意外输入的一种方法：对于文本输入中一个未知动词的语义上真实的同义句，可以使用本文中提出的方法生成，期望系统找到的至少部分同义句已经在词汇表中有记录。例如，如果词汇表中没有单词buff，但我们的LLM支持的学习过程认为已有的“polish”意义相同，这将带来双重好处：a)
    系统成功使用“polish”词条的内容生成包含buff的句子的意义表示；b) 意外地为buff创建一个词汇条目。这种学习方式被称为机会主义学习（例如，McShane等人，敬请期待，第6章）。
- en: The same operation can also be implemented as part of deliberate learning, a
    mode in which the agent does not carry out any other tasks. This requires a preliminary
    step of detecting lexicon units not present in the lexicon that are candidates
    for learning. Finally, we intend to investigate how to go beyond synonymy in this
    approach to learning and learn near-synonyms (plesionyms) as well as hypo- and
    hypernyms and other lexical units related to a seed lexicon sense.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的操作也可以作为刻意学习的一部分来实现，在这种模式下，代理不会执行任何其他任务。这需要一个初步步骤，即检测词汇表中不存在的词汇单元，这些单元是潜在的学习候选项。最后，我们打算研究如何在这种学习方法中超越同义词，学习近义词（plesionyms）、上下义词及与种子词汇意义相关的其他词汇单元。
- en: In our current implementation, we used pre-trained LLMs. Training LLMs for specific
    tasks related to learning by cognitive agents is an additional avenue for future
    development. The LLMs we use are trained on text. We intend to experiment with
    training them on a mixture of text and text meaning representations (TMRs) generated
    and used by our agent systems. The prerequisite for this is generating large stores
    of TMRs. This effort is at already underway in our research team.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们当前的实现中，我们使用了预训练的大型语言模型（LLMs）。为与认知代理学习相关的特定任务训练LLMs是未来发展的一个额外方向。我们使用的LLMs是在文本上训练的。我们计划实验将它们训练在由我们代理系统生成和使用的文本及其语义表示（TMRs）的混合体上。实现这一目标的前提是生成大量的TMRs。这项工作已经在我们的研究团队中开展。
- en: Acknowledgments
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'This research is supported in part by the Office of the Director of National
    Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA),
    via the HIATUS Program contract # 2022-22072200001.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分由国家情报总监办公室（ODNI）、情报高级研究项目活动（IARPA）通过HIATUS项目合同#2022-22072200001资助。
- en: The views and conclusions contained herein are those of the authors and should
    not be interpreted as necessarily representing the official policies, either expressed
    or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized
    to reproduce and distribute reprints for governmental purposes, notwithstanding
    any copyright annotation therein.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中的观点和结论仅代表作者个人观点，不应被解读为国家情报总监办公室（ODNI）、情报高级研究项目活动（IARPA）或美国政府的官方政策，亦不应被视为明示或暗示的政府立场。美国政府有权复制并分发该文献以供政府用途，尽管文献中有版权声明。
- en: References
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: McShane and Nirenburg (2021) McShane, M.; and Nirenburg, S. 2021. *Linguistics
    for the Age of AI*. Mit Press.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McShane 和 Nirenburg（2021）McShane, M.; 和 Nirenburg, S. 2021. *人工智能时代的语言学*。麻省理工学院出版社。
- en: 'Monarch and Nirenburg (1988) Monarch, I.; and Nirenburg, S. 1988. ONTOS: An
    Ontology-Based Knowledge Acquisition and Maintenance System. In *Proceedings of
    the Second Workshop on Knowledge Acquisition. Banff, Canada. August*.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Monarch 和 Nirenburg（1988）Monarch, I.; 和 Nirenburg, S. 1988. ONTOS：基于本体的知识获取与维护系统。发表于
    *第二届知识获取研讨会会议录。加拿大班夫。8月*。
- en: Nirenburg, Krishnaswamy, and McShane (2023) Nirenburg, S.; Krishnaswamy, N.;
    and McShane, M. 2023. Hybrid ML/KB Systems Learning through NL Dialog with DL
    Models. In *AAAI-Make Workshop on Challenges Requiring the Combination of Machine
    Learning and Knowledge Engineering*.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nirenburg, Krishnaswamy, 和 McShane（2023）Nirenburg, S.; Krishnaswamy, N.; 和 McShane,
    M. 2023. 通过与深度学习模型的自然语言对话进行混合机器学习/知识库系统学习。发表于 *AAAI-Make 研讨会：需要结合机器学习与知识工程的挑战*。
- en: Nirenburg, McShane, and English (2020) Nirenburg, S.; McShane, M.; and English,
    J. 2020. Content-centric computational cognitive modeling. *Advances in Cognitive
    Systems*.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nirenburg, McShane 和 English（2020）Nirenburg, S.; McShane, M.; 和 English, J.
    2020. 以内容为中心的计算认知建模。 *认知系统进展*。
- en: Nirenburg, Oates, and English (2007) Nirenburg, S.; Oates, T.; and English,
    J. 2007. Learning by reading by learning to read. In *International Conference
    on Semantic Computing (ICSC 2007)*, 694–701\. IEEE.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nirenburg, Oates 和 English（2007）Nirenburg, S.; Oates, T.; 和 English, J. 2007.
    通过阅读学习来学习阅读。发表于 *国际语义计算会议（ICSC 2007）*，694–701，IEEE。
- en: Nirenburg and Wood (2017) Nirenburg, S.; and Wood, P. 2017. Toward human-style
    learning in robots. In *AAAI Fall Symposium on Natural Communication with Robots*.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nirenburg 和 Wood（2017）Nirenburg, S.; 和 Wood, P. 2017. 朝着类人学习的机器人研究迈进。发表于 *AAAI
    秋季研讨会：与机器人进行自然沟通*。
- en: 'Radford et al. (2019) Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.;
    Sutskever, I.; et al. 2019. Language models are unsupervised multitask learners.
    *OpenAI blog*, 1(8): 9.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Radford 等（2019）Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; Sutskever,
    I.; 等. 2019. 语言模型是无监督的多任务学习者。 *OpenAI 博客*，1(8): 9。'
- en: 'Santu and Feng (2023) Santu, S. K. K.; and Feng, D. 2023. TELeR: A General
    Taxonomy of LLM Prompts for Benchmarking Complex Tasks. *arXiv preprint arXiv:2305.11430*.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Santu 和 Feng（2023）Santu, S. K. K.; 和 Feng, D. 2023. TELeR：用于基准复杂任务的大型语言模型提示的一般分类法。
    *arXiv 预印本 arXiv:2305.11430*。
- en: Vaswani et al. (2017) Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
    L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention is all you need.
    *Advances in neural information processing systems*, 30.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等（2017）Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.;
    Gomez, A. N.; Kaiser, Ł.; 和 Polosukhin, I. 2017. 注意力机制是你所需要的一切。 *神经信息处理系统进展*，30。
- en: Viegas and Nirenburg (1995) Viegas, E.; and Nirenburg, S. 1995. Acquisition
    semi-automatique du lexique. *Proceedings of$\backslash$Quatri emes Journ ees
    scientifiques de Lyon”, Lexicologie Langage Terminologie, Lyon*, 95.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viegas 和 Nirenburg（1995）Viegas, E.; 和 Nirenburg, S. 1995. 词汇的半自动获取。 *“里昂四届科学日”会议录，词汇学语言学术语学，里昂*，95。
- en: 'Viegas and Nirenburg (1996) Viegas, E.; and Nirenburg, S. 1996. The ecology
    of lexical acquisition: Computational lexicon making process. In *Proceedings
    of Euralex*, volume 96.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viegas 和 Nirenburg（1996）Viegas, E.; 和 Nirenburg, S. 1996. 词汇习得的生态学：计算词汇表制作过程。发表于
    *Euralex 会议录*，第96卷。
- en: 'Wei et al. (2022) Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi,
    E.; Le, Q. V.; Zhou, D.; et al. 2022. Chain-of-thought prompting elicits reasoning
    in large language models. *Advances in Neural Information Processing Systems*,
    35: 24824–24837.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wei 等（2022）Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi, E.;
    Le, Q. V.; Zhou, D.; 等. 2022. 思维链提示在大型语言模型中引发推理。 *神经信息处理系统进展*，35: 24824–24837。'
- en: 'Wilks and Nirenburg (1995) Wilks, Y.; and Nirenburg, S. 1995. Steps Towards
    Automated Knowledge Acquisition. *Towards Very Large Knowledge Bases: Knowledge
    Building & Knowledge Sharing (KB&KS’95)*, 97–102.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wilks 和 Nirenburg (1995) Wilks, Y.; 和 Nirenburg, S. 1995. 自动化知识获取的步骤。*面向超大规模知识库：知识构建与知识共享
    (KB&KS’95)*, 97–102。
- en: 'Yao et al. (2022) Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan,
    K.; and Cao, Y. 2022. React: Synergizing reasoning and acting in language models.
    *arXiv preprint arXiv:2210.03629*.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等人 (2022) Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.;
    和 Cao, Y. 2022. React: 在语言模型中协同推理与行动。*arXiv 预印本 arXiv:2210.03629*。'
- en: Zhou et al. (2022) Zhou, Y.; Muresanu, A. I.; Han, Z.; Paster, K.; Pitis, S.;
    Chan, H.; and Ba, J. 2022. Large language models are human-level prompt engineers.
    *arXiv preprint arXiv:2211.01910*.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 (2022) Zhou, Y.; Muresanu, A. I.; Han, Z.; Paster, K.; Pitis, S.; Chan,
    H.; 和 Ba, J. 2022. 大型语言模型是人类级别的提示工程师。*arXiv 预印本 arXiv:2211.01910*。
