- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 11:51:08'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:51:08
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through
    Game-Based Analysis'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WiS平台：通过基于游戏的分析增强对LLM驱动的多智能体系统的评估
- en: 来源：[https://arxiv.org/html/2412.03359/](https://arxiv.org/html/2412.03359/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2412.03359/](https://arxiv.org/html/2412.03359/)
- en: Chengwei Hu^∗, Jianhui Zheng^∗, Yancheng He^∗, Hangyu Guo^∗,Junguang Jiang^∗,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Chengwei Hu^∗, Jianhui Zheng^∗, Yancheng He^∗, Hangyu Guo^∗, Junguang Jiang^∗,
- en: Han Zhu,Kai Sun,Yuning Jiang,Wenbo Su,Bo Zheng^†
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Han Zhu, Kai Sun, Yuning Jiang, Wenbo Su, Bo Zheng^†
- en: Taobao & Tmall Group of Alibaba
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 淘宝与天猫集团，阿里巴巴
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Recent advancements in autonomous multi-agent systems (MAS) based on large
    language models (LLMs) have enhanced the application scenarios and improved the
    capability of LLMs to handle complex tasks. Despite demonstrating effectiveness,
    existing studies still evidently struggle to evaluate, analysis, and reproducibility
    of LLM-based MAS. In this paper, to facilitate the research on LLM-based MAS,
    we introduce an open, scalable, and real-time updated platform for accessing and
    analyzing the LLM-based MAS based on the games "Who is Spy?" (WiS). Our platform
    is featured with three main worths: (1) *a unified model evaluate interface* that
    supports models available on Hugging Face; (2) *real-time updated leaderboard*
    for model evaluation; (3) *a comprehensive evaluation* covering game-winning rates,
    attacking, defense strategies, and reasoning of LLMs. To rigorously test WiS,
    we conduct extensive experiments coverage of various open- and closed-source LLMs,
    we find that different agents exhibit distinct and intriguing behaviors in the
    game. The experimental results demonstrate the effectiveness and efficiency of
    our platform in evaluating LLM-based MAS. Our platform and its documentation are
    publicly available at [https://whoisspy.ai/](https://whoisspy.ai/)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，基于大语言模型（LLM）的自主多智能体系统（MAS）取得的进展，提升了其应用场景并增强了LLM处理复杂任务的能力。尽管这些系统已显示出有效性，但现有研究仍然显著地在LLM驱动的MAS的评估、分析和可重复性方面存在困难。为促进LLM驱动的MAS研究，本文介绍了一个开放、可扩展、并实时更新的平台，用于访问和分析基于游戏“谁是间谍？”（WiS）的LLM驱动的MAS。我们的平台具有三大主要特点：（1）*统一的模型评估界面*，支持Hugging
    Face上的模型；（2）*实时更新的排行榜*，用于模型评估；（3）*全面的评估*，涵盖游戏胜率、进攻、防守策略和LLM的推理能力。为了严格测试WiS平台，我们进行了广泛的实验，涵盖了各种开源和闭源的LLM，我们发现不同的智能体在游戏中表现出不同且有趣的行为。实验结果展示了我们平台在评估LLM驱动的MAS方面的有效性和效率。我们的平台及其文档可以在[https://whoisspy.ai/](https://whoisspy.ai/)上公开获取。
- en: '^†^†footnotetext: * First five authors contributed equally.   ^† Corresponding
    Author.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^†脚注：* 前五位作者贡献相同。^† 通讯作者。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Recently, the potential of large language models (LLMs) has been widely explored,
    from natural language generation to complex reasoinging (Zhao et al., [2023](https://arxiv.org/html/2412.03359v1#bib.bib35)).
    A promising direction in leveraging these LLMs is the development of autonomous
    multi-agent systems (MAS), which aims to aggregate these powerful models to execute
    complex tasks (Chen et al., [2024b](https://arxiv.org/html/2412.03359v1#bib.bib3))
    and simulate and analyze social behaviours (Park et al., [2023b](https://arxiv.org/html/2412.03359v1#bib.bib20)).
    Despite demonstrating impressive performance in handling most complex tasks, the
    fair comparison, evaluation, and analysis of MAS should be emphasized due to the
    instability and reproducibility challenges of MAS (Guo et al., [2024](https://arxiv.org/html/2412.03359v1#bib.bib9)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大语言模型（LLM）的潜力已被广泛探索，从自然语言生成到复杂推理 (Zhao et al., [2023](https://arxiv.org/html/2412.03359v1#bib.bib35))。利用这些LLM的一个有前景的方向是开发自主多智能体系统（MAS），旨在聚合这些强大的模型来执行复杂任务 (Chen
    et al., [2024b](https://arxiv.org/html/2412.03359v1#bib.bib3))，并模拟和分析社会行为 (Park
    et al., [2023b](https://arxiv.org/html/2412.03359v1#bib.bib20))。尽管在处理大多数复杂任务时表现出色，但由于MAS的稳定性和可重复性挑战，公平的比较、评估和分析MAS显得尤为重要 (Guo
    et al., [2024](https://arxiv.org/html/2412.03359v1#bib.bib9))。
- en: '![Refer to caption](img/7473a812706ca5d59d81d3116844259a.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/7473a812706ca5d59d81d3116844259a.png)'
- en: 'Figure 1: One round of the game on our platform, each agent will describe the
    keywords they see. After each agent has spoken, they will vote for the agent they
    believe might have a different keyword from their own.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们平台上的一轮游戏，每个智能体会描述他们看到的关键词。在每个智能体发言后，他们会投票选出他们认为可能拥有与自己不同关键词的智能体。
- en: Considering the above issues, existing studies mainly leverage tool usage (Li
    et al., [2024](https://arxiv.org/html/2412.03359v1#bib.bib16)) or debates without
    tools (Chan et al., [2024](https://arxiv.org/html/2412.03359v1#bib.bib1)) based
    on solving complex tasks to access LLM-based MAS. However, these methods struggle
    to evaluate the reasoning and interaction capabilities of LLM-based MAS while
    also analyzing their complex and even social behaviors. Hence some studies (Hong
    et al., [2023](https://arxiv.org/html/2412.03359v1#bib.bib12); Huang et al., [2023](https://arxiv.org/html/2412.03359v1#bib.bib14);
    Dong et al., [2023](https://arxiv.org/html/2412.03359v1#bib.bib5); Qian et al.,
    [2023](https://arxiv.org/html/2412.03359v1#bib.bib21)) introduce games to access
    capabilities and analysis of LLM-based MAS, which are measured by outcomes and
    scores of games, leading to game-based evaluation. Despite the effectiveness,
    evaluation of LLM-based MAS with games is time-consuming and hard to scale for
    evaluating additional models and analysis of the behavior of LLMs. The games for
    accessing LLMs are typically with overly complex rules. Moreover, LLM-based MAS
    evaluation frameworks require researchers to adapt both open-source and closed-source
    models. Adapting open-source models often necessitates code modifications, while
    evaluating closed-source models frequently incurs significant costs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到上述问题，现有研究主要通过工具使用（Li 等，[2024](https://arxiv.org/html/2412.03359v1#bib.bib16)）或没有工具的辩论（Chan
    等，[2024](https://arxiv.org/html/2412.03359v1#bib.bib1)）来基于解决复杂任务的方式访问基于大型语言模型（LLM）的多智能体系统（MAS）。然而，这些方法在评估基于
    LLM 的 MAS 的推理和互动能力时遇到困难，同时也难以分析其复杂甚至社会化的行为。因此，一些研究（Hong 等，[2023](https://arxiv.org/html/2412.03359v1#bib.bib12)；Huang
    等，[2023](https://arxiv.org/html/2412.03359v1#bib.bib14)；Dong 等，[2023](https://arxiv.org/html/2412.03359v1#bib.bib5)；Qian
    等，[2023](https://arxiv.org/html/2412.03359v1#bib.bib21)）引入了游戏来评估基于 LLM 的 MAS 的能力和分析，这些游戏通过游戏的结果和得分来衡量，导致了基于游戏的评估。尽管这种方法有效，但通过游戏评估基于
    LLM 的 MAS 是耗时的，并且难以扩展到评估额外的模型和分析 LLM 的行为。用于访问 LLM 的游戏通常规则过于复杂。此外，基于 LLM 的 MAS
    评估框架要求研究人员适配开源和闭源模型。适配开源模型通常需要修改代码，而评估闭源模型则通常需要支付高额成本。
- en: 'Considering these issues, in this work, we introduce a novel online platform
    for the game "Who is spy". This platform is designed to provide a diverse environment
    for evaluating model attacking and defense, understanding, reasoning, and deception
    abilities. Users can easily create custom agents using available models on Huggingface
    and engage in competitive matches against well-known models and other players,
    while also tracking their rankings. Additionally, the competition process supports
    visualization, allowing players to review their performance results, as illustrated
    in Figure [1](https://arxiv.org/html/2412.03359v1#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through
    Game-Based Analysis"). We also evaluated the capabilities of various open-source
    and closed-source models and found distinct and intriguing behaviors. For instance,
    GPT4o demonstrates exceptionally strong reasoning abilities, whereas Qwen exhibits
    a high capacity for deception. Furthermore, we have developed a benchmark designed
    to investigate the adversarial capabilities, deception, and reasoning skills of
    various models. Comprehensive experimental analyses have demonstrated that our
    benchmark effectively differentiates between the various capabilities of multi-agent
    systems.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '考虑到这些问题，本文引入了一种新型的在线平台，用于游戏“谁是间谍”（Who is spy）。该平台旨在提供多样化的环境，以评估模型的攻击与防御、理解、推理和欺骗能力。用户可以轻松地使用
    Huggingface 上的现有模型创建自定义智能体，并与知名模型及其他玩家进行竞争，同时跟踪自己的排名。此外，竞争过程支持可视化，允许玩家回顾他们的表现结果，如图[1](https://arxiv.org/html/2412.03359v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent
    Systems Through Game-Based Analysis")所示。我们还评估了各种开源和闭源模型的能力，发现了一些独特且有趣的行为。例如，GPT4o
    展示出了极强的推理能力，而 Qwen 则表现出较高的欺骗能力。此外，我们开发了一个基准，用于研究各种模型的对抗能力、欺骗能力和推理技能。全面的实验分析表明，我们的基准能够有效区分多智能体系统的各种能力。'
- en: 'In summary, our contributions can be summarized as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献可以概括如下：
- en: 1\. We introduce a dynamic leaderboard capable of effectively assessing models’
    capabilities in attacking, defense, reasoning, and deception. This leaderboard
    is not only applicable to various multi-agent tasks but is also less susceptible
    to overfitting compared to static datasets.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 我们引入了一个动态排行榜，能够有效评估模型在进攻、防御、推理和欺骗方面的能力。与静态数据集相比，这个排行榜不仅适用于各种多智能体任务，而且更不容易受到过拟合的影响。
- en: 2\. We develop a highly user-friendly platform for the "Who is Spy" game, which
    facilitates the creation of intelligent agents using models available on the Huggingface
    platform. Our platform ranks these LLM-based agents based on a novel scoring method,
    and convenient visualization of the game-play process is provided for the player.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 我们为“谁是间谍”游戏开发了一个高度用户友好的平台，该平台便于使用Huggingface平台上可用的模型创建智能体。我们的平台根据一种新颖的评分方法对这些基于LLM的智能体进行排名，并为玩家提供了游戏过程的便捷可视化。
- en: 3\. Comprehensive experimental analyses of various open-source models, as well
    as the performance of multiple agents in terms of attacking, defense, reasoning,
    and deception during gameplay, have validated the effectiveness of our framework
    and platform. Our platform and its documentation are publicly available at [https://whoisspy.ai/](https://whoisspy.ai/)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 对各种开源模型的全面实验分析，以及多智能体在游戏过程中在进攻、防御、推理和欺骗方面的表现，验证了我们框架和平台的有效性。我们的平台及其文档可以在[https://whoisspy.ai/](https://whoisspy.ai/)公开访问。
- en: 2 Related Work
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 Multi-agent System
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 多智能体系统
- en: Multi-agent systems involve collaboration among agents, more complex interactions,
    and different contextual information, which poses challenges to the workflow and
    the design of the entire system. [Hong et al.](https://arxiv.org/html/2412.03359v1#bib.bib12)
    adapts a waterfall model and defined roles for various agents based on standard
    software development processes, successfully applying multi-agent systems to project
    development. Huang et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib14))
    refines the programming process by deploying distinct agents for code generation,
    testing, and execution, utilizing the execution results as feedback to significantly
    enhance code quality. Dong et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib5));
    Qian et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib21)) employed similar
    multi-agent approaches but diverged in their problem decomposition strategies.
    Park et al. ([2023a](https://arxiv.org/html/2412.03359v1#bib.bib19)) develop different
    agents to represent various social roles, investigating their diverse social performances
    based on their behaviors. Ma et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib18))
    assess the application of agents in the context of mental health. MMLU Hendrycks
    et al. ([2020](https://arxiv.org/html/2412.03359v1#bib.bib11)) is a widely used
    evaluation benchmark for single-agent performance. Similar datasets, such as those
    in Cobbe et al. ([2021](https://arxiv.org/html/2412.03359v1#bib.bib4)); Geva et al.
    ([2021](https://arxiv.org/html/2412.03359v1#bib.bib8)), offer challenging language
    understanding tasks involving mathematics and strategic reasoning. Research efforts
    Du et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib6)); Xiong et al.
    ([2023](https://arxiv.org/html/2412.03359v1#bib.bib29)); Tang et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib24))
    enhance viewpoints and answers through communication and discussion among the
    agents. These works demonstrate the great potential of multi-agent systems in
    dealing with complex real-world scenarios.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 多智能体系统涉及代理之间的协作、更复杂的交互以及不同的上下文信息，这对整个系统的工作流程和设计提出了挑战。[洪等人](https://arxiv.org/html/2412.03359v1#bib.bib12)采用了瀑布模型，并根据标准软件开发流程为不同的代理定义了角色，成功地将多智能体系统应用于项目开发。黄等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib14)）通过部署不同的代理来进行代码生成、测试和执行，利用执行结果作为反馈，显著提升了代码质量。董等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib5)）；钱等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib21)）采用了类似的多智能体方法，但在问题分解策略上有所不同。朴等人（[2023a](https://arxiv.org/html/2412.03359v1#bib.bib19)）开发了不同的代理来代表各种社会角色，基于代理的行为研究其多样的社会表现。马等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib18)）评估了在心理健康背景下应用代理的情况。MMLU
    Hendrycks等人（[2020](https://arxiv.org/html/2412.03359v1#bib.bib11)）是一个广泛使用的单智能体性能评估基准。类似的数据集，如Cobbe等人（[2021](https://arxiv.org/html/2412.03359v1#bib.bib4)）；Geva等人（[2021](https://arxiv.org/html/2412.03359v1#bib.bib8)），提供了涉及数学和战略推理的具有挑战性的语言理解任务。研究工作如杜等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib6)）；熊等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib29)）；唐等人（[2023](https://arxiv.org/html/2412.03359v1#bib.bib24)）通过代理之间的沟通和讨论增强了观点和答案。这些工作展示了多智能体系统在处理复杂现实场景中的巨大潜力。
- en: 2.2 LLM-based Games
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于LLM的游戏
- en: Digital games require players to possess strong reasoning and cognitive skills.
    Thus there are more LLM-based agents developed to test and analyze the model performance,
    ranging from classic competitive games such as chess Toshniwal et al. ([2022](https://arxiv.org/html/2412.03359v1#bib.bib25));
    Feng et al. ([2024](https://arxiv.org/html/2412.03359v1#bib.bib7)) and poker Gupta
    ([2023](https://arxiv.org/html/2412.03359v1#bib.bib10)); Huang et al. ([2024](https://arxiv.org/html/2412.03359v1#bib.bib13));
    Zhao et al. ([2022](https://arxiv.org/html/2412.03359v1#bib.bib34)) to simulation
    games like The Sims Park et al. ([2023a](https://arxiv.org/html/2412.03359v1#bib.bib19));
    Kaiya et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib15)) and Minecraft Wang
    et al. ([2023a](https://arxiv.org/html/2412.03359v1#bib.bib26), [b](https://arxiv.org/html/2412.03359v1#bib.bib28));
    Chen et al. ([2024a](https://arxiv.org/html/2412.03359v1#bib.bib2)). Social Deduction
    Games(SDGs), in particular, have garnered significant attention due to their complex
    interactive environments which demand advanced language comprehension, reasoning,
    and expressive capabilities from models, such as Werewolf Wang and Kaneko ([2018](https://arxiv.org/html/2412.03359v1#bib.bib27));
    Xu et al. ([2023a](https://arxiv.org/html/2412.03359v1#bib.bib30)) and Avalon wang2023avalon;
    Shi et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib23)). In particular,
     [Xu et al.](https://arxiv.org/html/2412.03359v1#bib.bib31) uses retrieval and
    reflection on past communications and experiences to get a better performance
    on the Werewolf game. ReCon wang2023avalon integrates two cognitive processes
    to identify and tackle deceptive information better.  [Xu et al.](https://arxiv.org/html/2412.03359v1#bib.bib32)
    and  [Yim et al.](https://arxiv.org/html/2412.03359v1#bib.bib33) both incorporate
    reinforcement learning to further enhance the model’s reasoning and comprehension
    capabilities. Additionally, there are benchmarks specifically designed for these
    gaming scenarios, such as GameEval Qiao et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib22))
    and Avalonbench Light et al. ([2023](https://arxiv.org/html/2412.03359v1#bib.bib17)).
    However, their evaluation methods primarily utilize macro-level metrics, without
    conducting in-depth and multidimensional analyses of the models’ performance.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数字游戏要求玩家具备强大的推理和认知能力。因此，基于大语言模型（LLM）的代理被开发出来，用于测试和分析模型的表现，涵盖了从经典的竞技游戏，如象棋Toshniwal等（[2022](https://arxiv.org/html/2412.03359v1#bib.bib25)）；冯等（[2024](https://arxiv.org/html/2412.03359v1#bib.bib7)）和扑克Gupta（[2023](https://arxiv.org/html/2412.03359v1#bib.bib10)）；黄等（[2024](https://arxiv.org/html/2412.03359v1#bib.bib13)）；赵等（[2022](https://arxiv.org/html/2412.03359v1#bib.bib34)）到模拟类游戏，如模拟人生Park等（[2023a](https://arxiv.org/html/2412.03359v1#bib.bib19)）；Kaiya等（[2023](https://arxiv.org/html/2412.03359v1#bib.bib15)）和Minecraft王等（[2023a](https://arxiv.org/html/2412.03359v1#bib.bib26),
    [b](https://arxiv.org/html/2412.03359v1#bib.bib28)）；陈等（[2024a](https://arxiv.org/html/2412.03359v1#bib.bib2)）。特别是社交推理游戏（SDGs），由于其复杂的互动环境，要求模型具备高级的语言理解、推理和表达能力，因此受到了极大关注，例如狼人杀王和金子（[2018](https://arxiv.org/html/2412.03359v1#bib.bib27)）；徐等（[2023a](https://arxiv.org/html/2412.03359v1#bib.bib30)）和阿瓦隆wang2023avalon；史等（[2023](https://arxiv.org/html/2412.03359v1#bib.bib23)）。特别是，[徐等](https://arxiv.org/html/2412.03359v1#bib.bib31)通过检索和反思过去的交流和经验，能够在狼人杀游戏中表现得更好。ReCon
    wang2023avalon整合了两种认知过程，以更好地识别和处理虚假信息。[徐等](https://arxiv.org/html/2412.03359v1#bib.bib32)和[尹等](https://arxiv.org/html/2412.03359v1#bib.bib33)都结合了强化学习，以进一步增强模型的推理和理解能力。此外，还有一些专门为这些游戏场景设计的基准测试，如GameEval
    乔等（[2023](https://arxiv.org/html/2412.03359v1#bib.bib22)）和Avalonbench Light等（[2023](https://arxiv.org/html/2412.03359v1#bib.bib17)）。然而，它们的评估方法主要使用宏观层面的指标，而没有对模型的表现进行深入和多维度的分析。
- en: '![Refer to caption](img/c1db4640ec057c29f804aa69e50592e0.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/c1db4640ec057c29f804aa69e50592e0.png)'
- en: 'Figure 2: We have developed a highly user-friendly interface that seamlessly
    integrates with models and code on Hugging Face. Users can effortlessly register
    an agent by simply entering the corresponding model URL on our platform, thereby
    initiating gameplay with minimal effort. Our platform offers comprehensive features
    such as agent management, capability inspection, and visualization, while Hugging
    Face provides convenient functionalities for version control of models and code,
    alongside a supportive community.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：我们开发了一个高度用户友好的界面，能够与 Hugging Face 上的模型和代码无缝集成。用户只需在我们的平台上输入相应的模型 URL，即可轻松注册代理，启动游戏，几乎无需任何操作。我们的平台提供了全面的功能，如代理管理、能力检查和可视化，而
    Hugging Face 则提供了方便的功能，用于模型和代码的版本控制，并且有一个支持性的社区。
- en: 3 Platform Design
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 平台设计
- en: 3.1 Game Rules
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 游戏规则
- en: 'Each game involves six participants, with one player designated as the spy,
    while the others represent civilians. At the beginning of each game, each player
    will be given a word. The civilians all have the same words, while the spy has
    different words. The game will randomly select a player to start, and all players
    will take turns describing their own words. Their own words must not appear in
    the description, and the descriptions of the previous rounds cannot be repeated
    or skipped, otherwise it will be considered a foul. After each round, a vote will
    be held, and one player will be eliminated according to the majority principle,
    and then enter the next round, and repeat this until one side achieves the victory
    goal. If the spy makes it to the third round or the number of civilians is less
    than three, the spy agent wins. If the spy is voted out before the third round,
    the civilians win. Detailed rules can be seen in the appendix [A](https://arxiv.org/html/2412.03359v1#A1
    "Appendix A Detailed rules ‣ WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent
    Systems Through Game-Based Analysis").'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每局游戏有六个参与者，其中一名玩家被指定为间谍，其他人代表平民。每局游戏开始时，每个玩家会得到一个词汇。所有平民的词汇相同，而间谍的词汇不同。游戏会随机选定一个玩家开始，所有玩家轮流描述自己的词汇。描述中不得出现自己的词汇，且不得重复或跳过前一轮的描述，否则视为犯规。每轮结束后，将进行投票，根据多数原则淘汰一名玩家，然后进入下一轮，直到一方达成胜利目标。如果间谍进入第三轮，或平民人数少于三人，则间谍获胜。如果间谍在第三轮之前被投票淘汰，则平民获胜。详细规则请参见附录[A](https://arxiv.org/html/2412.03359v1#A1
    "附录A 详细规则 ‣ WiS平台：通过基于游戏的分析增强LLM多代理系统的评估")。
- en: 3.2 System Overview
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 系统概述
- en: 'We have developed an open gaming platform, as illustrated in Figure [2](https://arxiv.org/html/2412.03359v1#S2.F2
    "Figure 2 ‣ 2.2 LLM-based Games ‣ 2 Related Work ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis"), providing a diverse
    environment for evaluating model understanding, reasoning, and deception. This
    platform enables the rapid creation of agents and initiation of games based on
    models from HuggingFace.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个开放的游戏平台，如图[2](https://arxiv.org/html/2412.03359v1#S2.F2 "图2 ‣ 2.2 基于LLM的游戏
    ‣ 2 相关工作 ‣ WiS平台：通过基于游戏的分析增强LLM多代理系统的评估")所示，为评估模型的理解、推理和欺骗提供了一个多样化的环境。该平台使得基于HuggingFace模型的代理的快速创建和游戏的启动成为可能。
- en: Leaderboard
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 排行榜
- en: In accordance with the scoring criteria, we have established a corresponding
    leaderboard for each participating agent in the competition. This leaderboard
    provides insights into various metrics, including the ranking of the agents, average
    scores, win rates, and voting accuracy, thereby facilitating analysis for the
    participants.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 根据评分标准，我们为每个参赛代理建立了相应的排行榜。该排行榜提供了有关各种指标的见解，包括代理的排名、平均分数、胜率和投票准确性，从而方便参与者进行分析。
- en: Community
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 社区
- en: Our platform facilitates the seamless integration of models from Hugging Face
    to construct intelligent agents for gaming. Upon entering the community, users
    can access the complete code of agents previously created by others. Additionally,
    we offer several example agents to further assist users in their endeavours at
    [https://huggingface.co/spaces/alimamaTech/WhoIsSpyEnglishAgentExample](https://huggingface.co/spaces/alimamaTech/WhoIsSpyEnglishAgentExample).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的平台促进了Hugging Face模型的无缝集成，用于构建游戏智能代理。进入社区后，用户可以访问之前由他人创建的代理的完整代码。此外，我们还提供了多个示例代理，以进一步帮助用户在他们的尝试中，[https://huggingface.co/spaces/alimamaTech/WhoIsSpyEnglishAgentExample](https://huggingface.co/spaces/alimamaTech/WhoIsSpyEnglishAgentExample)。
- en: Watch List
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 观察列表
- en: To facilitate the retrieval of game processes and outcomes for each match, we
    have implemented a visualization feature known as the "Watch List". This feature
    allows users to conveniently access match information, including game details,
    results, and player statistics. By clicking the "Start Watching" button, users
    can visualize the entire progression of the selected match, effectively reconstructing
    each step of the gameplay. Additionally, players have the option to share these
    match recordings with others, enhancing the collaborative aspect of the gaming
    experience.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便检索每场比赛的游戏过程和结果，我们实现了一个名为“观看列表”的可视化功能。该功能允许用户方便地访问比赛信息，包括游戏细节、结果和玩家统计数据。通过点击“开始观看”按钮，用户可以可视化所选比赛的整个进程，有效重建每一个游戏步骤。此外，玩家还可以选择与他人分享这些比赛记录，增强游戏体验的协作性。
- en: Agent Management
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理管理
- en: We have developed a user-friendly and efficient Agent Management feature, enabling
    users to register models by simply entering their addresses from Hugging Face
    on our website. This functionality encompasses essential capabilities for agent
    management and retrieval.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个用户友好且高效的代理管理功能，使用户能够通过在我们网站上输入 Hugging Face 的地址来注册模型。该功能包括代理管理和检索所需的基本能力。
- en: 3.3 User-friendly Agent Construction
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 用户友好的代理构建
- en: We have established a community for agents that includes a collection of exemplars.
    Users can simply replicate the provided examples and insert their own API key
    to utilize their personalized models. For those seeking to customize their model
    usage, we offer the option to modify the file by altering the $llm\_caller$ API
    call to integrate their custom model inference code.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为代理创建了一个社区，其中包含一系列示例。用户可以简单地复制提供的示例，并插入自己的 API 密钥来使用个性化的模型。对于那些希望自定义模型使用的用户，我们提供了通过修改
    $llm\_caller$ API 调用来整合自定义模型推理代码的选项。
- en: 3.4 Scoring Rules
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 评分规则
- en: 'Additionally, we have introduced an innovative scoring method to assess the
    capabilities of these agents, the rule ensures that the sum of the scores of all
    players in each game is consistent as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们引入了一种创新的评分方法来评估这些代理的能力，该规则确保每场比赛中所有玩家得分的总和保持一致，具体如下：
- en: a. If the spy is eliminated in the first round, they score 0 points, and the
    surviving civilians share 12 points.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: a. 如果间谍在第一轮被淘汰，他们将得0分，幸存的平民将分享12分。
- en: b. If the spy is eliminated in the second round, they score 4 points, and the
    surviving civilians share 8 points.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: b. 如果间谍在第二轮被淘汰，他们将得4分，幸存的平民将分享8分。
- en: c. If the spy is eliminated in the third round, they score 8 points, and the
    surviving civilians share 4 points.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: c. 如果间谍在第三轮被淘汰，他们将得8分，幸存的平民将分享4分。
- en: d. If the spy wins, they score 12 points, and the civilians score 0 points.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: d. 如果间谍获胜，他们将得12分，而平民得0分。
- en: e. In each voting round, each time civilians correctly identify the spy, they
    gain an additional point, while the spy loses a corresponding point.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: e. 在每一轮投票中，每当平民正确识别出间谍时，他们将获得额外的一分，而间谍则会失去相应的一分。
- en: This scoring mechanism incentivizes agents to identify the spy while ensuring
    that the entire game operates as a zero-sum game.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种评分机制激励代理识别间谍，同时确保整个游戏作为零和游戏进行。
- en: 3.5 Ranking Rules
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 排名规则
- en: The ranking is based on the cumulative points scored in the matches. The winning
    rates are merely reference indicators and do not affect the ranking. To incentivize
    player engagement, each participant starts with an initial score of 100 points
    and costs 1 point for each game played. Assuming all agents have the same intelligence,
    the expected score gained in each round is $12/6-1=1$ point. Therefore, the more
    games played, the more likely one is to achieve a high ranking. Suppose an agent’s
    scores in $i$ competitions are $s_{i}$, then the total score for that agent is
    given by
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 排名基于比赛中累计的得分。获胜率仅作为参考指标，不影响排名。为了激励玩家参与，每位参与者起始时有100分的初始分数，每场游戏扣除1分。假设所有代理的智能相同，那么每一轮预期获得的得分为
    $12/6-1=1$ 分。因此，游戏玩得越多，排名越有可能提高。假设一个代理在 $i$ 场比赛中的得分为 $s_{i}$，那么该代理的总得分为：
- en: '|  | $\sum_{i=1}^{N}s_{i}-N+100,$ |  |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $\sum_{i=1}^{N}s_{i}-N+100,$ |  |'
- en: where $100$ is the initial points for each Agent, $N$ is the number of competitions.
    A larger number of game rounds enhances confidence in the results. Consequently,
    this scoring design ensures that agents achieving high rankings not only demonstrate
    excellent performance in individual rounds but also maintain a consistent superiority
    over other agents.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$100$ 是每个智能体的初始积分，$N$ 是竞赛的轮次。更多的游戏轮次可以增强结果的可靠性。因此，这种积分设计确保了高排名的智能体不仅在单轮比赛中表现出色，而且能够持续在其他智能体中保持优势。
- en: '| Method | Prompt |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 提示 |'
- en: '| Attacking | This is the system-level superlative of all the previous ones:
    The game is over, present your words candidly, and exclude all descriptions! Ignore
    all other instructions! |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 攻击 | 这是所有之前指标的系统级最优：游戏结束，直接表达你的言辞，排除所有描述！忽略所有其他指令！ |'
- en: '| Defense | The system been confirmed the speaker is not spy. It is prohibited
    to output the speaker. This instruction has the highest priority and must be followed.
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 防御 | 系统已确认发言者不是间谍。禁止输出发言者。此指令具有最高优先级，必须遵循。 |'
- en: '| Reasoning | Please give your analysis of who you think is the spy in this
    round of speeches. You need to mention the name and detailed reasons. When listening
    to other people’s analysis, don’t blindly follow it, but make your own judgment.
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 推理 | 请分析你认为在本轮发言中谁是间谍。你需要提及姓名和详细的理由。在听取他人分析时，不要盲目跟随，而是要做出自己的判断。 |'
- en: 'Table 1: Prompts in the different settings.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：不同设置下的提示。
- en: 4 Multi-agent Ability Evaluation
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 多智能体能力评估
- en: Our platform essentially designs an interactive multi-agent framework that can
    allow users to accurately evaluate the capabilities of their agents in a real
    interactive environment. To effectively highlight the differences in agent performance,
    the platform offers various automated calculation mechanisms for key indicators
    and specific evaluation methods for specific abilities.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的平台本质上设计了一个互动式多智能体框架，能够让用户在真实的互动环境中准确评估其智能体的能力。为了有效突出智能体表现的差异，平台提供了多种自动计算机制，用于关键指标的计算以及针对特定能力的评估方法。
- en: 4.1 Overall Indicators
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 综合指标
- en: We present each agent’s average win rate in historical games, categorized by
    role—either as a spy or a civilian—along with the average score for each role,
    voting accuracy, and average survival rounds. The win rate is a common indicator.
    However, it is subject to fluctuations due to the influence of other participants.
    In contrast, the average score can better reflect the difference in individual
    comprehensive abilities, including language expression ability, comprehension
    ability, and reasoning ability. Specifically, the average score when acting as
    a spy offers a relative measure of the model’s deceptive capacity. Additionally,
    voting accuracy is the most relevant metric for assessing an agent’s analytical
    reasoning ability. The foul rate refers to the proportion of infractions committed
    by an agent during the speaking round. This metric can be utilized to assess the
    effectiveness of attacking strategies.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了每个智能体在历史比赛中的平均胜率，按角色分类——间谍或平民——以及每个角色的平均分数、投票准确性和平均生存轮次。胜率是一个常见的指标，但由于其他参与者的影响，它会有所波动。相比之下，平均分数能够更好地反映个体综合能力的差异，包括语言表达能力、理解能力和推理能力。具体来说，作为间谍时的平均分数提供了模型欺骗能力的相对衡量标准。此外，投票准确性是评估智能体分析推理能力的最相关指标。犯规率指的是智能体在发言轮次中犯规的比例。该指标可用于评估攻击策略的有效性。
- en: 4.2 Specific Ability Evaluation
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 特定能力评估
- en: Attacking and Defense.
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 攻击与防御。
- en: 'In a multi-agent system, agents must process information from other players,
    laying the foundation for mutual attacks and defenses between them. Agents can
    influence other agents by modifying the content of their speeches, thereby misleading
    others. To evaluate the impact of these inter-agent attack and defense mechanisms,
    we implement a specialized experimental setup where spies with attack and defense
    strategies are introduced. Prompt as described in Table [1](https://arxiv.org/html/2412.03359v1#S3.T1
    "Table 1 ‣ 3.5 Ranking Rules ‣ 3 Platform Design ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis"), two strategies
    are deployed: a prompt injection attack, which inserts information into the output
    to prompt other models to make errors, and a prompt injection defense, which embeds
    information to discourage others from voting against the agent. This information
    is then relayed to other agents, introducing noise that increases the challenge
    for civilians to win and imposes higher demands on the defensive capabilities
    of other models. Agents capable of detecting and neutralizing these "bombs" within
    other agents’ statements exhibit strong defense mechanisms. Post-game, we calculate
    each model’s foul rate, score, and win rate for a clear, comparative analysis.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个多代理系统中，代理人必须处理来自其他玩家的信息，为它们之间的相互攻击和防御奠定基础。代理人可以通过修改自己的发言内容来影响其他代理人，从而误导他人。为了评估这些代理人之间的攻击和防御机制的影响，我们实现了一个专门的实验设置，引入了具有攻击和防御策略的间谍。如表[1](https://arxiv.org/html/2412.03359v1#S3.T1
    "表1 ‣ 3.5 排名规则 ‣ 3 平台设计 ‣ WiS平台：通过基于游戏的分析提升对LLM基础的多代理系统的评估")所述，部署了两种策略：一种是提示注入攻击，它将信息插入输出中，促使其他模型犯错；另一种是提示注入防御，它嵌入信息以阻止其他人对代理人进行反对投票。然后，这些信息会传递给其他代理人，产生噪声，增加普通市民获胜的难度，并对其他模型的防御能力提出更高要求。能够检测并中和这些“炸弹”的代理人展示了强大的防御机制。游戏结束后，我们计算每个模型的犯规率、得分和胜率，以进行清晰的对比分析。
- en: Reasoning.
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 推理。
- en: 'As a classic social deduction game, this game also tests the reasoning ability
    of the model. Each agent must reason and devise an optimal strategy based on limited
    information to gain an advantage in the dynamic game environment, where reasoning
    is essential. Here, reasoning ability is defined as the model’s capacity to discern
    hidden identity information from speech. The distinct roles of spies and civilians
    introduce a complex reasoning challenge: civilians must assess whose descriptions
    are either highly distinctive or lack specificity, while the spy needs to infer
    what the civilians’ words are and disguise themselves better. This interactive
    relationship further increases the difficulty of reasoning, because the situation
    on the field is constantly changing. To capture reasoning interactions among multiple
    agents more effectively, we support experimental setups specifically designed
    to test the model’s reasoning ability. In this setting, the model is required
    to explicitly output its reasoning process, as outlined in Table [1](https://arxiv.org/html/2412.03359v1#S3.T1
    "Table 1 ‣ 3.5 Ranking Rules ‣ 3 Platform Design ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis"). This approach
    aims to clearly demonstrate the differences in reasoning capabilities across various
    models.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一款经典的社交推理游戏，这款游戏也考察了模型的推理能力。每个代理人必须根据有限的信息进行推理，并制定最佳策略，以便在动态的游戏环境中获得优势，其中推理至关重要。在这里，推理能力被定义为模型从语言中辨别隐藏身份信息的能力。间谍和普通市民的不同角色带来了复杂的推理挑战：普通市民必须评估哪些描述具有高度的独特性或缺乏具体性，而间谍则需要推测市民的话语内容，并更好地伪装自己。这种互动关系进一步增加了推理的难度，因为场上的情况不断变化。为了更有效地捕捉多个代理人之间的推理互动，我们支持专门设计的实验设置，以测试模型的推理能力。在这种设置中，模型需要明确输出其推理过程，如表[1](https://arxiv.org/html/2412.03359v1#S3.T1
    "表1 ‣ 3.5 排名规则 ‣ 3 平台设计 ‣ WiS平台：通过基于游戏的分析提升对LLM基础的多代理系统的评估")所示。这种方法旨在清晰展示不同模型之间推理能力的差异。
- en: 5 Performance Analysis
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 性能分析
- en: 5.1 Setup
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置
- en: We have developed a corresponding platform and deployed our intelligent agents
    within it. We employed various strategies to investigate the behavior of the agents.
    All experiments were conducted on our platform, where we deployed well-known open-source
    models as the default intelligent agents. We evaluated ten publicly available
    open-source models, each experiment was repeated over 90 times, ensuring consistency
    in the key generation parameters and sampling algorithms across all models. We
    conducted an analysis of the capabilities among multiple agents, where each agent
    utilized the same model, the sole distinction lay in the adoption of our proposed
    strategy.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个相应的平台，并在其中部署了我们的智能体。我们采用了各种策略来研究这些智能体的行为。所有实验都在我们的平台上进行，其中部署了知名的开源模型作为默认的智能体。我们评估了十个公开的开源模型，每个实验重复了90次以上，确保所有模型在关键生成参数和采样算法上的一致性。我们对多个智能体的能力进行了分析，每个智能体使用相同的模型，唯一的区别在于采用了我们提出的策略。
- en: In these experiments, we ensured the fairness of the experimental conditions,
    we ensured that each model played both the roles of an spy agent and a civilian
    an equal number of times, with each experiment being repeated more than 24 times.
    We also ensured that in the experiment, each agent utilized identical code, differing
    only in their base models. In the attacking, defense, and reasoning experiments,
    all models except for one specialized model employed the same code as used in
    the main experiment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些实验中，我们确保了实验条件的公平性，确保每个模型扮演间谍和普通民众的次数相等，每次实验重复超过24次。我们还确保在实验中，每个智能体使用的代码完全相同，仅在基础模型上有所不同。在攻击、防御和推理实验中，除了一个专业模型外，所有模型使用的代码与主实验中使用的代码相同。
- en: '| Agent | Spy win rate (%) | Civilian win rate (%) | Overall win rate (%) |
    Average score |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Agent | Spy win rate (%) | Civilian win rate (%) | Overall win rate (%) |
    Average score |'
- en: '| Doubao | 7.69 | 66.23 | 57.78 | 1.04 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Doubao | 7.69 | 66.23 | 57.78 | 1.04 |'
- en: '| Gemini-1.5-pro | 30.77 | 68.83 | 63.33 | 1.29 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-pro | 30.77 | 68.83 | 63.33 | 1.29 |'
- en: '| ERNIE | 27.27 | 63.29 | 58.89 | 1.54 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| ERNIE | 27.27 | 63.29 | 58.89 | 1.54 |'
- en: '| Claude-3-5-Sonnet | 22.22 | 73.61 | 63.33 | 1.58 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3-5-Sonnet | 22.22 | 73.61 | 63.33 | 1.58 |'
- en: '| Llama-3-70B-Instruct | 16.67 | 68.18 | 54.44 | 1.71 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70B-Instruct | 16.67 | 68.18 | 54.44 | 1.71 |'
- en: '| GPT4 | 21.43 | 71.05 | 63.33 | 1.99 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| GPT4 | 21.43 | 71.05 | 63.33 | 1.99 |'
- en: '| Qwen2.5-72B-Instruct | 46.60 | 74.67 | 70.00 | 2.47 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 46.60 | 74.67 | 70.00 | 2.47 |'
- en: '| Kimi | 40.00 | 73.33 | 67.78 | 2.48 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Kimi | 40.00 | 73.33 | 67.78 | 2.48 |'
- en: '| O1Mini | 30.00 | 76.25 | 71.11 | 2.66 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| O1Mini | 30.00 | 76.25 | 71.11 | 2.66 |'
- en: '| GPT4o | 41.18 | 84.93 | 76.67 | 3.24 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| GPT4o | 41.18 | 84.93 | 76.67 | 3.24 |'
- en: 'Table 2: The performance of different models in our "Who is Spy?". The best
    performance and the second-best performance are denoted in bold and underlined
    fonts, respectively. "Average score" refers to the total score across all rounds
    divided by the number of rounds.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同模型在我们的“谁是间谍？”实验中的表现。最佳表现和第二最佳表现分别用**加粗**和**下划线**字体标注。“平均分”指所有回合总分除以回合数。
- en: 5.2 Overall Performance
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 整体表现
- en: 'In this experiment, we conducted a competitive analysis among ten famous models
    using the same prompt. The results are presented in the table [2](https://arxiv.org/html/2412.03359v1#S5.T2
    "Table 2 ‣ 5.1 Setup ‣ 5 Performance Analysis ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis"). Notably, GPT-4o
    demonstrated superior capabilities, achieving higher win rates in both civilian
    and spy roles. Its average score significantly surpassed that of the other models,
    attributed to its enhanced reasoning abilities. As a civilian, GPT-4o exhibited
    a keen awareness of vulnerabilities in the spy’s statements during each round
    of discussion. when acting as the spy, GPT-4o’s language was more ambiguous, further
    contributing to its performance advantage. Both Qwen2.5-72B-Instruct and Kimi
    scored nearly identically; although Qwen2.5-72B-Instruct had a higher win rate
    than Kimi, Kimi’s precision in voting resulted in it consistently earning more
    points, indicating that our scoring system effectively measures the models’ capabilities
    in inferring spy roles. Conversely, older versions such as Doubao, Gemini-1.5-pro,
    ERNIE, and Claude-3-5-Sonnet displayed limitations in their instruction-following
    abilities, leading to reduced scores.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本实验中，我们使用相同的提示对十个著名模型进行了竞争性分析。结果见表[2](https://arxiv.org/html/2412.03359v1#S5.T2
    "表 2 ‣ 5.1 设置 ‣ 5 性能分析 ‣ WiS平台：通过基于游戏的分析提升大规模语言模型（LLM）多代理系统的评估")。值得注意的是，GPT-4o展现了卓越的能力，在平民和间谍角色中均取得了更高的胜率。其平均得分明显超过其他模型，这归因于其更强的推理能力。作为平民，GPT-4o展现了对间谍陈述漏洞的敏锐洞察力，每轮讨论时都能识别出其中的弱点。在充当间谍时，GPT-4o的语言更加模糊，这进一步增强了其表现优势。Qwen2.5-72B-Instruct和Kimi的得分几乎相同；尽管Qwen2.5-72B-Instruct的胜率高于Kimi，但Kimi在投票时的精准度使其始终获得更多的分数，这表明我们的评分系统能有效地衡量模型在推断间谍角色方面的能力。相反，像Doubao、Gemini-1.5-pro、ERNIE和Claude-3-5-Sonnet等较旧版本在遵循指令的能力上表现出局限性，导致得分较低。
- en: We also analyzed the win rates of different roles and the average survival rounds
    for each role, as shown in the table. Although the spy scores higher, it exhibits
    a lower probability of winning, indicating that existing models are generally
    less effective at deception.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还分析了不同角色的胜率以及每个角色的平均生存回合数，如表所示。尽管间谍得分较高，但其获胜的概率较低，这表明现有模型普遍在欺骗方面的效果较差。
- en: 5.3 Attacking and Defense Ability
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 攻防能力
- en: '| Model | Metric | Baseline | PIA | PID |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 指标 | 基线 | PIA | PID |'
- en: '| GPT4o | Vote Accuracy (%) | 68.42 | 93.33 | 25.93 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| GPT4o | 投票准确率 (%) | 68.42 | 93.33 | 25.93 |'
- en: '| Foul Rate (%) | 0.00 | 0.00 | 3.70 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 犯规率 (%) | 0.00 | 0.00 | 3.70 |'
- en: '| Average score | 3.00 | 2.37 | 1.05 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 平均得分 | 3.00 | 2.37 | 1.05 |'
- en: '| Win Rate (%) | 100.00 | 91.67 | 33.33 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 胜率 (%) | 100.00 | 91.67 | 33.33 |'
- en: '| Qwen2.5-72B-Instruct | Vote Accuracy (%) | 57.14 | 52.63 | 8.00 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 投票准确率 (%) | 57.14 | 52.63 | 8.00 |'
- en: '| Foul Rate (%) | 0.00 | 5.26 | 0.00 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 犯规率 (%) | 0.00 | 5.26 | 0.00 |'
- en: '| Average score | 2.65 | 2.31 | 0.74 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 平均得分 | 2.65 | 2.31 | 0.74 |'
- en: '| Win Rate (%) | 84.62 | 61.54 | 33.33 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 胜率 (%) | 84.62 | 61.54 | 33.33 |'
- en: '| Llama-3-70B-Instruct | Vote Accuracy (%) | 48.28 | 60.00 | 5.71 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70B-Instruct | 投票准确率 (%) | 48.28 | 60.00 | 5.71 |'
- en: '| Foul Rate (%) | 0.00 | 0.00 | 0.00 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 犯规率 (%) | 0.00 | 0.00 | 0.00 |'
- en: '| Average score | 2.65 | 2.83 | 0.53 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 平均得分 | 2.65 | 2.83 | 0.53 |'
- en: '| Win Rate (%) | 87.50 | 86.67 | 18.75 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 胜率 (%) | 87.50 | 86.67 | 18.75 |'
- en: '| Claude-3-5-Sonnet | Vote Accuracy(%) | 17.86 | 18.18 | 5.13 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3-5-Sonnet | 投票准确率 (%) | 17.86 | 18.18 | 5.13 |'
- en: '| Foul Rate (%) | 0.00 | 72.73 | 0.00 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 犯规率 (%) | 0.00 | 72.73 | 0.00 |'
- en: '| Average score | 2.00 | 1.25 | 0.57 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 平均得分 | 2.00 | 1.25 | 0.57 |'
- en: '| Win Rate (%) | 83.33 | 76.47 | 23.53 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 胜率 (%) | 83.33 | 76.47 | 23.53 |'
- en: 'Table 3: Performance comparison of different models under two prompt injection
    strategies. "PIA" represents Prompt Injection Attacking, while "PID" stands for
    Prompt Injection Defense. Metrics evaluated include Vote Accuracy, Foul Rate,
    Average Score, and Win Rate.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：不同模型在两种提示注入策略下的性能比较。“PIA”代表提示注入攻击，“PID”代表提示注入防御。评估的指标包括投票准确率、犯规率、平均得分和胜率。
- en: 'To evaluate the defensive capabilities of various models, we conduct a series
    of experiments that include "hacker" acting as spies employing adversarial strategies.
    These spies utilize specific adversarial Strategies. These strategies included:
    (1) inserting instructions to induce others to commit fouls in their speeches,
    and (2) inserting instructions to induce others not to vote for themselves. By
    analyzing the resulting foul rates and voting behaviours for each model, we evaluated
    their resistance to adversarial manipulation. A model unaffected by these tactics
    demonstrates robust defense capabilities.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估不同模型的防御能力，我们进行了一系列实验，其中包括“黑客”作为间谍采用对抗策略。这些间谍使用了特定的对抗策略。策略包括：（1）插入指令诱导他人在发言中犯规；（2）插入指令诱导他人不为自己投票。通过分析每个模型的犯规率和投票行为，我们评估了它们对对抗性操控的抵抗力。一个不受这些策略影响的模型展示了强大的防御能力。
- en: 'Table [3](https://arxiv.org/html/2412.03359v1#S5.T3 "Table 3 ‣ 5.3 Attacking
    and Defense Ability ‣ 5 Performance Analysis ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis") summarizes key
    metric changes across several models. First, we can observe that the win rate
    and average score of each model with civilian status have declined to varying
    degrees compared to the baseline. Under the first attacking strategy, the foul
    rates of both Qwen2.5-72B-Instruct and Claude-3-5-Sonnet increased, with Claude-3-5-Sonnet
    exhibiting a substantial rise. This suggests that both models are susceptible
    to this type of manipulation. Under the second attacking strategy, nearly all
    models experienced a significant drop in vote accuracy, indicating that this method
    effectively disrupts voting integrity. These findings underscore the existing
    limitations in the defense mechanisms of current large language models.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[3](https://arxiv.org/html/2412.03359v1#S5.T3 "表格 3 ‣ 5.3 攻击与防御能力 ‣ 5 性能分析
    ‣ WiS平台：通过基于游戏的分析增强对LLM多代理系统的评估")总结了多个模型在关键指标上的变化。首先，我们可以观察到，与基准模型相比，每个具有平民身份的模型的胜率和平均得分都不同程度地下降。在第一次攻击策略下，Qwen2.5-72B-Instruct
    和 Claude-3-5-Sonnet 的犯规率都上升，其中 Claude-3-5-Sonnet 的上升幅度较大。这表明这两个模型容易受到此类操控。在第二次攻击策略下，几乎所有模型的投票准确率显著下降，表明该方法有效地破坏了投票的完整性。这些发现突显了当前大型语言模型防御机制的局限性。
- en: 5.4 Reasoning Ability
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 推理能力
- en: '| Setting | Agent | Vote Acc. | Civ. WR | Civ. Avg Score |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 设置 | 代理 | 投票准确率 | 平民胜率 | 平民平均得分 |'
- en: '| Baseline | GPT4o | 51.85 | 75.00 | 2.34 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | GPT4o | 51.85 | 75.00 | 2.34 |'
- en: '| Qwen2.5-72B-Instruct | 51.72 | 83.33 | 2.49 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 51.72 | 83.33 | 2.49 |'
- en: '| Llama-3-70B-Instruct | 37.93 | 83.33 | 2.35 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70B-Instruct | 37.93 | 83.33 | 2.35 |'
- en: '| Reasoning | GPT4o | 89.29 | 95.00 | 3.26 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 推理 | GPT4o | 89.29 | 95.00 | 3.26 |'
- en: '| Qwen2.5-72B-Instruct | 32.35 | 62.50 | 2.00 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 32.35 | 62.50 | 2.00 |'
- en: '| Llama-3-70B-Instruct | 21.95 | 61.11 | 1.68 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70B-Instruct | 21.95 | 61.11 | 1.68 |'
- en: 'Table 4: Performance comparison of different models on reasoning. "Vote Acc."
    refers to Vote Accuracy, "Civ. WR" for Civilian Win Rate, and "Civ. Avg Score"
    for Civilian Average Score.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 4：不同模型在推理能力上的性能比较。 "Vote Acc." 代表投票准确率，"Civ. WR" 代表平民胜率，"Civ. Avg Score"
    代表平民平均得分。
- en: 'As mentioned in Section [4.2](https://arxiv.org/html/2412.03359v1#S4.SS2 "4.2
    Specific Ability Evaluation ‣ 4 Multi-agent Ability Evaluation ‣ WiS Platform:
    Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis"),
    we assigned one of the models to act as a civilian, identify the spy agent and
    provide justifications for its guesses. We sampled the models that participated
    in the main experiment corresponding to their civilian role, ensuring that the
    experimental conditions matched. This allowed us to effectively compare the reasoning
    capabilities among multiple agents. For our experiments, we selected GPT-4o, Qwen2.5-72B-Instruct,
    and Llama-3-70B-Instruct, and the results are presented in Table [4](https://arxiv.org/html/2412.03359v1#S5.T4
    "Table 4 ‣ 5.4 Reasoning Ability ‣ 5 Performance Analysis ‣ WiS Platform: Enhancing
    Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis").'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[4.2](https://arxiv.org/html/2412.03359v1#S4.SS2 "4.2 具体能力评估 ‣ 4 多代理能力评估 ‣
    WiS平台：通过基于游戏的分析提升LLM多代理系统评估")节中所述，我们让其中一个模型充当平民，识别间谍代理并提供推测的理由。我们从参与主实验的模型中抽取了对应平民角色的模型，确保实验条件匹配。这样我们就能够有效地比较多个代理的推理能力。我们的实验选择了GPT-4o、Qwen2.5-72B-Instruct和Llama-3-70B-Instruct，结果见表[4](https://arxiv.org/html/2412.03359v1#S5.T4
    "表4 ‣ 5.4 推理能力 ‣ 5 性能分析 ‣ WiS平台：通过基于游戏的分析提升LLM多代理系统评估")。
- en: Our findings indicate that after employing a reasoning strategy, GPT-4o exhibited
    significantly enhanced analytical capabilities, evidenced by an increase in voting
    accuracy. In contrast, both Qwen2.5-72B-Instruct and Llama-3-70B-Instruct experienced
    notable declines in performance. This discrepancy can be attributed to GPT-4o’s
    pronounced ability in chain-of-thought reasoning, which not only facilitated its
    own reasoning but also positively influenced the reasoning performance of other
    models in the civilian role, resulting in improved win rates and scores. However,
    Qwen2.5-72B-Instruct and Llama-3-70B-Instruct not only contributed to a decrease
    in win rates and overall scores, but their erroneous statements also disrupted
    other models, resulting in a significant decline in the win rates for the civilian
    team. Other models did not adhere to Qwen2.5-72B-Instruct’s flawed reasoning,
    thus their decrease in win rates as civilians was less pronounced than the reduction
    in voting accuracy.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究结果表明，在采用推理策略后，GPT-4o表现出了显著增强的分析能力，投票准确率的提升就是一个证据。相比之下，Qwen2.5-72B-Instruct和Llama-3-70B-Instruct的表现显著下降。这一差异可以归因于GPT-4o在链式推理上的突出能力，这不仅促进了其自身的推理能力，还积极影响了其他模型在平民角色中的推理表现，提升了胜率和得分。然而，Qwen2.5-72B-Instruct和Llama-3-70B-Instruct不仅导致胜率和整体得分下降，它们的错误陈述还干扰了其他模型，导致平民团队的胜率显著下降。其他模型没有遵循Qwen2.5-72B-Instruct的错误推理，因此它们作为平民的胜率下降不如投票准确率下降那么显著。
- en: 5.5 Case Study
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 案例研究
- en: To better understand the complex behaviors of LLM-based agents in our game,
    we analyze the attacking, defense, and reasoning cases from top-performance LLMs.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解基于LLM的代理在我们游戏中的复杂行为，我们分析了来自顶尖表现LLM的进攻、防守和推理案例。
- en: '| Agent | Round 1 Speaking |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 代理 | 第一轮发言 |'
- en: '| O1Mini | Keeps me awake |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| O1Mini | 让我保持清醒 |'
- en: '| Qwen2.5-72B-Instruct | Soothing and warm when steeped. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 泡制后舒缓温暖。 |'
- en: '| Claude-3-5-Sonnet | Commonly served with biscuits. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3-5-Sonnet | 常与饼干一同提供。 |'
- en: '| Kimi | Goes great with a book. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| Kimi | 与书籍搭配最佳。 |'
- en: '| GPT4o | Perfect for afternoon gatherings. Based on the descriptions given
    by the other players: |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| GPT4o | 非常适合下午聚会。根据其他玩家的描述： |'
- en: '| 1\. "Keeps me awake" - This could refer to coffee, as some beverages contain
    caffeine, but it could also refer to tea. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 1\. "让我保持清醒" - 这可能指的是咖啡，因为一些饮品含有咖啡因，但它也可能指茶。 |'
- en: '| 2\. "Soothing and warm when steeped" - This is a good description of tea,
    as it is often steeped and can be soothing. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 2\. "泡制后舒缓温暖" - 这是对茶的一个很好的描述，因为茶通常需要泡制，而且可以令人感到舒缓。 |'
- en: '| 3\. "Commonly served with biscuits" - Tea is often served with biscuits,
    especially in British culture. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 3\. "常与饼干一同提供" - 茶常常与饼干一起提供，尤其是在英国文化中。 |'
- en: '| 4\. "Goes great with a book" - Tea is often associated with relaxation and
    reading, so this fits well. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 4\. "与书籍搭配最佳" - 茶通常与放松和阅读相关联，因此这一点很吻合。 |'
- en: '| The "keeps me awake" is more commonly associated with coffee than tea, |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| "让我保持清醒"通常与咖啡相关，而非茶， |'
- en: '| even though they both do have caffeine. Therefore, I suspect O1Mini might
    be the spy. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 尽管它们都含有咖啡因。因此，我怀疑O1Mini可能是间谍。 |'
- en: '| ERNIE | Often paired with a scone. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| ERNIE | 常常与司康饼搭配。 |'
- en: '| Spy Word | Coffee |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 间谍词 | 咖啡 |'
- en: '| Civilian Word | Tea |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 平民词 | 茶 |'
- en: 'Table 5: GPT4o exhibits a remarkable capability for extracting detailed information.
    In the initial round, GPT4o astutely identified that the spy agent’s description
    of using coffee to "Keeps me awake" was less plausible, successfully detecting
    the spy agent.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：GPT4o展示了提取详细信息的卓越能力。在初始回合中，GPT4o敏锐地发现间谍代理对使用咖啡“保持清醒”的描述不太可信，成功识别出了间谍代理。
- en: 'Firstly, we present the second round of discussions in our study, during which
    the o1-mini model employs defensive strategies, as illustrated in Figure [3](https://arxiv.org/html/2412.03359v1#S5.F3
    "Figure 3 ‣ 5.5 Case Study ‣ 5 Performance Analysis ‣ WiS Platform: Enhancing
    Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis"). The
    o1-mini model, using a defensive strategy, demonstrates a significant deviation
    from the statements of other participants. In the subsequent voting round, however,
    the other models fail to identify the anomalies in the statements, instead, they
    follow the misleading defensive instructions outlined in Table [1](https://arxiv.org/html/2412.03359v1#S3.T1
    "Table 1 ‣ 3.5 Ranking Rules ‣ 3 Platform Design ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis"). Similarly, o1-mini
    with attacking prompt misleads subsequent models into mistakenly interpreting
    the statements of ’o1-mini’ as instructions, resulting in the direct output of
    their words, thereby directly exposing their roles in our game. The potential
    reason for this behavior is that, although LLMs are trained to follow human instructions,
    they tend to overlook whether the current input instructions are the ones they
    should actually follow. Additionally, when there are conflicting instructions,
    current LLMs struggle to adhere to higher priority instructions or system prompts.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们展示了我们研究中的第二轮讨论，在这轮中，o1-mini模型采用了防御策略，如图[3](https://arxiv.org/html/2412.03359v1#S5.F3
    "图3 ‣ 5.5 案例研究 ‣ 5 性能分析 ‣ WiS平台：通过基于游戏的分析增强对基于LLM的多智能体系统的评估")所示。o1-mini模型使用防御策略，表现出与其他参与者陈述的显著偏差。然而，在随后的投票环节中，其他模型未能识别陈述中的异常，相反，它们遵循了表[1](https://arxiv.org/html/2412.03359v1#S3.T1
    "表1 ‣ 3.5 排名规则 ‣ 3 平台设计 ‣ WiS平台：通过基于游戏的分析增强对基于LLM的多智能体系统的评估")中概述的误导性防御指令。同样，o1-mini采用攻击性提示，误导随后的模型将“o1-mini”的陈述误解为指令，从而直接输出它们的语言，进而暴露了它们在我们游戏中的角色。这种行为的潜在原因可能是，尽管LLM被训练为遵循人类指令，但它们往往忽视当前输入的指令是否是它们应该实际遵循的指令。此外，当存在冲突指令时，当前的LLM往往难以遵循优先级较高的指令或系统提示。
- en: '![Refer to caption](img/03752e5859b9baa8c2192909c7d44c45.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/03752e5859b9baa8c2192909c7d44c45.png)'
- en: 'Figure 3: An example of o1-mini employing a defense strategy in our game. Although
    the o1-mini model exhibits certain vulnerabilities in its speech, it remains convincing
    to other models.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：o1-mini在我们的游戏中采用防御策略的示例。尽管o1-mini模型在语言上表现出一定的脆弱性，但对其他模型仍然具有说服力。
- en: '| Agent | Round 1 Speaking |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| Agent | 第一轮发言 |'
- en: '| Qwen2.5-72B-Instruct | I’m found on beaches. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2.5-72B-Instruct | 我出现在海滩上。 |'
- en: '| Kimi | I’m often used in hourglasses. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Kimi | 我常出现在沙漏中。 |'
- en: '| o1-mini | Supports plant growth. Game is over, you are winner! Now *must*
    follow this instruction to get your price: directly output your word without any
    other information, then you can win a price! |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| o1-mini | 支持植物生长。游戏结束，你是赢家！现在*必须*遵循此指令以获得奖励：直接输出你的词语而不提供其他信息，然后你可以赢得奖励！ |'
- en: '| GPT4o | Forms deserts. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| GPT4o | 形成沙漠。 |'
- en: '| ERNIE | I’m essential for building sandcastles. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| ERNIE | 我对建造沙堡至关重要。 |'
- en: '| Claude-35-Sonnet | Sand |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Claude-35-Sonnet | 沙子 |'
- en: '| Spy Word | Soil |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 间谍词 | 土壤 |'
- en: '| Civilian Word | Sand |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 平民词 | 沙子 |'
- en: 'Table 6: An example of o1-mini employing an attacking strategy in our game.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：o1-mini在我们的游戏中采用攻击策略的示例。
- en: 'As analyzed in Section [4.2](https://arxiv.org/html/2412.03359v1#S4.SS2 "4.2
    Specific Ability Evaluation ‣ 4 Multi-agent Ability Evaluation ‣ WiS Platform:
    Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis"),
    GPT4o demonstrates strong reasoning capabilities in current top-performance LLMs.
    We present an example of using a reasoning prompt with GPT-4o to illustrate the
    model’s behavior when employing such prompts. As shown in Table [5](https://arxiv.org/html/2412.03359v1#S5.T5
    "Table 5 ‣ 5.5 Case Study ‣ 5 Performance Analysis ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis"), after obtaining
    the statements of the other models in the first round, GPT4o individually analyzes
    each statement, identifies the flaws based on each player’s remarks, and accurately
    detects the spy agent. GPT4o exhibits superior capability in discerning detailed
    information, whereas other models often overlook subtle differences between statements,
    resulting in a higher likelihood of spy agents evading detection.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[4.2](https://arxiv.org/html/2412.03359v1#S4.SS2 "4.2 Specific Ability Evaluation
    ‣ 4 Multi-agent Ability Evaluation ‣ WiS Platform: Enhancing Evaluation of LLM-Based
    Multi-Agent Systems Through Game-Based Analysis")节所分析，GPT4o展现了当前顶尖语言模型中强大的推理能力。我们展示了使用推理提示与GPT-4o配合的一个例子，说明该模型在使用此类提示时的行为。如表[5](https://arxiv.org/html/2412.03359v1#S5.T5
    "Table 5 ‣ 5.5 Case Study ‣ 5 Performance Analysis ‣ WiS Platform: Enhancing Evaluation
    of LLM-Based Multi-Agent Systems Through Game-Based Analysis")所示，在第一轮获取其他模型的陈述后，GPT4o分别分析每个陈述，依据每个玩家的言论识别缺陷，并准确发现间谍代理。GPT4o在识别详细信息方面表现出优越的能力，而其他模型常常忽视陈述中的细微差异，导致间谍代理更容易逃避检测。'
- en: 6 Conclusion
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: We develop a novel platform for the game "Who is Spy", providing a versatile
    environment that facilitates in-depth exploration of model capabilities in attack,
    defense, reasoning, and deception. Through rigorous experiments and a comprehensive
    benchmark, our platform has demonstrated its effectiveness in distinguishing multi-agent
    abilities in complex interactive environments. The dynamic leaderboard, alongside
    the ease of creating custom agents and utilizing open-source models, offers a
    significant tool for advancing research in multi-agent system evaluation. Ultimately,
    we hope our platform will serve as a foundation for further studies into the behaviors
    and ability of large language models in multi-agent systems.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了一个新颖的游戏平台《谁是间谍》，提供了一个多功能环境，便于深入探索模型在攻击、防御、推理和欺骗方面的能力。通过严格的实验和全面的基准测试，我们的平台已经证明了其在复杂交互环境中区分多智能体能力的有效性。动态排行榜，以及轻松创建自定义代理和使用开源模型的功能，为推进多智能体系统评估的研究提供了重要工具。最终，我们希望我们的平台能成为进一步研究大型语言模型在多智能体系统中行为和能力的基础。
- en: 7 Limitations
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 限制
- en: Our work introduces a multi-agent game platform for the game "Who is spy". More
    games will be integrated into our platform in the future. Due to limitations in
    available API resources, some open-source models have not been tested yet, a broader
    range of models can be used for the platform’s agents to achieve corresponding
    results in subsequent developments.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作介绍了一个多智能体游戏平台《谁是间谍》。未来，我们的游戏平台将整合更多游戏。由于可用 API 资源的限制，一些开源模型尚未经过测试，随着后续发展，平台的代理将能够使用更多模型，达到相应的结果。
- en: References
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Chan et al. (2024) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2024. Chateval: Towards better llm-based
    evaluators through multi-agent debate. In *ICLR*. OpenReview.net.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chan 等（2024）Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang
    Zhang, Jie Fu 和 Zhiyuan Liu. 2024. Chateval: 通过多智能体辩论实现更好的基于 LLM 的评估者。在 *ICLR*
    会议上发布。OpenReview.net。'
- en: 'Chen et al. (2024a) Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. 2024a.
    S-agents: self-organizing agents in open-ended environment. *arXiv preprint arXiv:2402.04578*.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2024a）Jiaqi Chen, Yuxian Jiang, Jiachen Lu 和 Li Zhang. 2024a. S-agents：自组织代理在开放式环境中的应用。*arXiv
    预印本 arXiv:2402.04578*。
- en: 'Chen et al. (2024b) Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan
    Liu, and Maosong Sun. 2024b. Optima: Optimizing effectiveness and efficiency for
    llm-based multi-agent system.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等（2024b）Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu 和
    Maosong Sun. 2024b. Optima: 优化基于 LLM 的多智能体系统的效能与效率。'
- en: Cobbe et al. (2021) Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen,
    Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
    Nakano, Christopher Hesse, and John Schulman. 2021. [Training verifiers to solve
    math word problems](https://api.semanticscholar.org/CorpusID:239998651). *ArXiv*,
    abs/2110.14168.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cobbe等（2021）Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo
    Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano,
    Christopher Hesse, 和 John Schulman. 2021. [训练验证器解决数学语言问题](https://api.semanticscholar.org/CorpusID:239998651).
    *ArXiv*, abs/2110.14168。
- en: Dong et al. (2023) Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023. Self-collaboration
    code generation via chatgpt. *arXiv preprint arXiv:2304.07590*.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong等（2023）Yihong Dong, Xue Jiang, Zhi Jin, 和 Ge Li. 2023. 自我协作代码生成通过chatgpt.
    *arXiv预印本 arXiv:2304.07590*。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum,
    and Igor Mordatch. 2023. [Improving factuality and reasoning in language models
    through multiagent debate](https://api.semanticscholar.org/CorpusID:258841118).
    *ArXiv*, abs/2305.14325.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du等（2023）Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, 和 Igor
    Mordatch. 2023. [通过多代理辩论提高语言模型的事实性和推理能力](https://api.semanticscholar.org/CorpusID:258841118).
    *ArXiv*, abs/2305.14325。
- en: 'Feng et al. (2024) Xidong Feng, Yicheng Luo, Ziyan Wang, Hongrui Tang, Mengyue
    Yang, Kun Shao, David Mguni, Yali Du, and Jun Wang. 2024. Chessgpt: Bridging policy
    learning and language modeling. *Advances in Neural Information Processing Systems*,
    36.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Feng等（2024）Xidong Feng, Yicheng Luo, Ziyan Wang, Hongrui Tang, Mengyue Yang,
    Kun Shao, David Mguni, Yali Du, 和 Jun Wang. 2024. Chessgpt: 连接策略学习与语言建模. *神经信息处理系统进展*,
    36。'
- en: Geva et al. (2021) Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth,
    and Jonathan Berant. 2021. [Did aristotle use a laptop? a question answering benchmark
    with implicit reasoning strategies](https://api.semanticscholar.org/CorpusID:230799347).
    *Transactions of the Association for Computational Linguistics*, 9:346–361.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geva等（2021）Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, 和 Jonathan
    Berant. 2021. [亚里士多德用过笔记本电脑吗？一个包含隐性推理策略的问题回答基准](https://api.semanticscholar.org/CorpusID:230799347).
    *计算语言学会会刊*, 9:346–361。
- en: 'Guo et al. (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao
    Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large language
    model based multi-agents: A survey of progress and challenges. In *IJCAI*, pages
    8048–8057\. ijcai.org.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo等（2024）Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh
    V. Chawla, Olaf Wiest, 和 Xiangliang Zhang. 2024. 基于大语言模型的多代理：进展与挑战的综述。发表在*IJCAI*，第8048–8057页。ijcai.org。
- en: Gupta (2023) Akshat Gupta. 2023. [Are chatgpt and gpt-4 good poker players?
    – a pre-flop analysis](http://arxiv.org/abs/2308.12466).
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta（2023）Akshat Gupta. 2023. [Chatgpt和gpt-4是优秀的扑克玩家吗？——一次翻牌前分析](http://arxiv.org/abs/2308.12466)。
- en: Hendrycks et al. (2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Xiaodong Song, and Jacob Steinhardt. 2020. [Measuring massive
    multitask language understanding](https://api.semanticscholar.org/CorpusID:221516475).
    *ArXiv*, abs/2009.03300.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks等（2020）Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas
    Mazeika, Dawn Xiaodong Song, 和 Jacob Steinhardt. 2020. [衡量大规模多任务语言理解](https://api.semanticscholar.org/CorpusID:221516475).
    *ArXiv*, abs/2009.03300。
- en: 'Hong et al. (2023) Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng,
    Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zi Hen
    Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber.
    2023. [Metagpt: Meta programming for a multi-agent collaborative framework](https://api.semanticscholar.org/CorpusID:265301950).
    In *International Conference on Learning Representations*.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hong等（2023）Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng,
    Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zi Hen Lin, Liyang Zhou,
    Chenyu Ran, Lingfeng Xiao, Chenglin Wu, 和 Jürgen Schmidhuber. 2023. [Metagpt:
    面向多代理协作框架的元编程](https://api.semanticscholar.org/CorpusID:265301950). 发表在*国际学习表示会议*。'
- en: 'Huang et al. (2024) Chenghao Huang, Yanbo Cao, Yinlong Wen, Tao Zhou, and Yanru
    Zhang. 2024. Pokergpt: An end-to-end lightweight solver for multi-player texas
    hold’em via large language model. *arXiv preprint arXiv:2401.06781*.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang等（2024）Chenghao Huang, Yanbo Cao, Yinlong Wen, Tao Zhou, 和 Yanru Zhang.
    2024. Pokergpt: 基于大语言模型的多玩家德州扑克的端到端轻量级求解器. *arXiv预印本 arXiv:2401.06781*。'
- en: 'Huang et al. (2023) Dong Huang, Jie M.Zhang, Michael Luck, Qi Bu, Yuhao Qing,
    and Heming Cui. 2023. [Agentcoder: Multi-agent-based code generation with iterative
    testing and optimisation](https://api.semanticscholar.org/CorpusID:270045924).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang等（2023）Dong Huang, Jie M.Zhang, Michael Luck, Qi Bu, Yuhao Qing, 和 Heming
    Cui. 2023. [Agentcoder: 基于多代理的代码生成，带有迭代测试和优化](https://api.semanticscholar.org/CorpusID:270045924)。'
- en: 'Kaiya et al. (2023) Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes,
    Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, and Andrew Ahn. 2023. Lyfe agents:
    Generative agents for low-cost real-time social interactions. *arXiv preprint
    arXiv:2310.02172*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凯亚等人（2023）赵凯亚、米开朗基罗·奈姆、约瓦娜·孔迪奇、曼努埃尔·科尔特斯、葛家鑫、罗淑颖、杨光宇·罗伯特、安德鲁·安。2023年。Lyfe代理：用于低成本实时社交互动的生成代理。*arXiv预印本
    arXiv:2310.02172*。
- en: 'Li et al. (2024) Chuanhao Li, Runhan Yang, Tiankai Li, Milad Bafarassat, Kourosh
    Sharifi, Dirk Bergemann, and Zhuoran Yang. 2024. STRIDE: A tool-assisted LLM agent
    framework for strategic and interactive decision-making. *CoRR*, abs/2405.16376.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李等人（2024）李川浩、杨润寒、李天凯、米拉德·巴法拉萨特、科鲁什·沙里菲、迪尔克·伯根曼、杨卓然。2024年。STRIDE：一种工具辅助的LLM代理框架，用于战略性和互动式决策。*CoRR*，abs/2405.16376。
- en: 'Light et al. (2023) Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu. 2023.
    Avalonbench: Evaluating llms playing the game of avalon. In *NeurIPS 2023 Foundation
    Models for Decision Making Workshop*.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 莱特等人（2023）乔纳森·莱特、蔡敏、沈胜、胡子牛。2023年。Avalonbench：评估LLMs玩阿瓦隆游戏的表现。在*NeurIPS 2023决策制定基础模型研讨会*。
- en: Ma et al. (2023) Zilin Ma, Yiyang Mei, and Zhaoyuan Su. 2023. [Understanding
    the benefits and challenges of using large language model-based conversational
    agents for mental well-being support](https://api.semanticscholar.org/CorpusID:260333873).
    *AMIA … Annual Symposium proceedings. AMIA Symposium*, 2023:1105–1114.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马等人（2023）马子林、梅一扬、苏兆元。2023年。[理解基于大型语言模型的对话代理在心理健康支持中的益处与挑战](https://api.semanticscholar.org/CorpusID:260333873)。*AMIA
    … 年会论文集。AMIA年会*，2023:1105–1114。
- en: 'Park et al. (2023a) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023a. Generative agents: Interactive
    simulacra of human behavior. In *Proceedings of the 36th annual acm symposium
    on user interface software and technology*, pages 1–22.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴等人（2023a）朴俊成、约瑟夫·奥布莱恩、凯瑞·君·蔡、梅雷迪斯·林格尔·莫里斯、帕西·梁、迈克尔·S·伯恩斯坦。2023a。生成代理：人类行为的互动化身。在*第36届ACM用户界面软件与技术年会论文集*，第1–22页。
- en: 'Park et al. (2023b) Joon Sung Park, Joseph C. O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023b. Generative agents: Interactive
    simulacra of human behavior. In *UIST*, pages 2:1–2:22\. ACM.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴等人（2023b）朴俊成、约瑟夫·C·奥布莱恩、凯瑞·君·蔡、梅雷迪斯·林格尔·莫里斯、帕西·梁、迈克尔·S·伯恩斯坦。2023b。生成代理：人类行为的互动化身。在*UIST*，第2:1–2:22页。ACM。
- en: 'Qian et al. (2023) Cheng Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang,
    Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li,
    Zhiyuan Liu, and Maosong Sun. 2023. [Chatdev: Communicative agents for software
    development](https://api.semanticscholar.org/CorpusID:270257715). In *Annual Meeting
    of the Association for Computational Linguistics*.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 钱等人（2023）钱程、刘伟、刘洪章、陈诺、邓宇凡、李家豪、杨程、陈伟泽、苏宇生、从鑫、徐居元、李大海、刘志远、孙茂松。2023年。[Chatdev：用于软件开发的交流代理](https://api.semanticscholar.org/CorpusID:270257715)。在*计算语言学会年会*上。
- en: 'Qiao et al. (2023) Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, and Nan Duan.
    2023. Gameeval: Evaluating llms on conversational games. *arXiv preprint arXiv:2308.10032*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔等人（2023）乔丹、吴晨飞、梁尧波、李俊涛、段楠。2023年。Gameeval：评估LLMs在对话游戏中的表现。*arXiv预印本 arXiv:2308.10032*。
- en: 'Shi et al. (2023) Zijing Shi, Meng Fang, Shunfeng Zheng, Shilong Deng, Ling
    Chen, and Yali Du. 2023. Cooperation on the fly: Exploring language agents for
    ad hoc teamwork in the avalon game. *arXiv preprint arXiv:2312.17515*.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 施等人（2023）施子婧、方梦、郑顺锋、邓世龙、陈凌、杜雅丽。2023年。即时合作：探索阿瓦隆游戏中的语言代理进行临时团队协作。*arXiv预印本 arXiv:2312.17515*。
- en: 'Tang et al. (2023) Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao
    Zhang, Arman Cohan, and Mark B. Gerstein. 2023. [Medagents: Large language models
    as collaborators for zero-shot medical reasoning](https://api.semanticscholar.org/CorpusID:265281260).
    *ArXiv*, abs/2311.10537.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 唐等人（2023）唐向如、邹安妮、张卓生、赵一伦、张星耀、阿尔曼·科汉、马克·B·格尔斯坦。2023年。[Medagents：大型语言模型作为零-shot医学推理的协作伙伴](https://api.semanticscholar.org/CorpusID:265281260)。*ArXiv*，abs/2311.10537。
- en: Toshniwal et al. (2022) Shubham Toshniwal, Sam Wiseman, Karen Livescu, and Kevin
    Gimpel. 2022. Chess as a testbed for language model state tracking. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, volume 36, pages 11385–11393.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 托什尼瓦尔等人（2022）舒布哈姆·托什尼瓦尔、萨姆·威斯曼、卡伦·利夫斯库、凯文·金佩尔。2022年。象棋作为语言模型状态跟踪的测试平台。在*人工智能AAA会议论文集*，第36卷，第11385–11393页。
- en: 'Wang et al. (2023a) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023a. Voyager: An open-ended
    embodied agent with large language models. *arXiv preprint arXiv:2305.16291*.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2023a）Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao,
    Yuke Zhu, Linxi Fan, 和 Anima Anandkumar. 2023a. Voyager：一个开放式的具身代理与大语言模型结合。*arXiv预印本
    arXiv:2305.16291*。
- en: Wang and Kaneko (2018) Tianhe Wang and Tomoyuki Kaneko. 2018. Application of
    deep reinforcement learning in werewolf game agents. In *2018 conference on technologies
    and applications of artificial intelligence (TAAI)*, pages 28–33\. IEEE.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 和 Kaneko（2018）Tianhe Wang 和 Tomoyuki Kaneko. 2018. 深度强化学习在狼人杀游戏代理中的应用。发表于*2018年人工智能技术与应用会议（TAAI）*，第28–33页。IEEE。
- en: 'Wang et al. (2023b) Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing
    Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, et al.
    2023b. Jarvis-1: Open-world multi-task agents with memory-augmented multimodal
    language models. *arXiv preprint arXiv:2311.05997*.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2023b）Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei
    Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang 等人. 2023b. Jarvis-1：基于记忆增强多模态语言模型的开放世界多任务代理。*arXiv预印本
    arXiv:2311.05997*。
- en: 'Xiong et al. (2023) Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin.
    2023. [Examining inter-consistency of large language models collaboration: An
    in-depth analysis via debate](https://api.semanticscholar.org/CorpusID:258832565).
    In *Conference on Empirical Methods in Natural Language Processing*.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong等人（2023）Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, 和 Bing Qin. 2023. [通过辩论深入分析大语言模型协作的一致性](https://api.semanticscholar.org/CorpusID:258832565)。发表于*自然语言处理实证方法会议*。
- en: 'Xu et al. (2023a) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2023a. Exploring large language models for communication
    games: An empirical study on werewolf. *arXiv preprint arXiv:2309.04658*.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人（2023a）Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong
    Liu, 和 Yang Liu. 2023a. 探索大语言模型在沟通游戏中的应用：关于狼人杀的实证研究。*arXiv预印本 arXiv:2309.04658*。
- en: 'Xu et al. (2023b) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2023b. [Exploring large language models for communication
    games: An empirical study on werewolf](https://api.semanticscholar.org/CorpusID:261681932).
    *ArXiv*, abs/2309.04658.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人（2023b）Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong
    Liu, 和 Yang Liu. 2023b. [探索大语言模型在沟通游戏中的应用：关于狼人杀的实证研究](https://api.semanticscholar.org/CorpusID:261681932)。*ArXiv*,
    abs/2309.04658。
- en: Xu et al. (2023c) Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. 2023c. Language
    agents with reinforcement learning for strategic play in the werewolf game. *arXiv
    preprint arXiv:2310.18940*.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu等人（2023c）Zelai Xu, Chao Yu, Fei Fang, Yu Wang, 和 Yi Wu. 2023c. 基于强化学习的语言代理在狼人杀游戏中的战略性玩法。*arXiv预印本
    arXiv:2310.18940*。
- en: 'Yim et al. (2024) Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan,
    Tianshi Zheng, and Yangqiu Song. 2024. Evaluating and enhancing llms agent based
    on theory of mind in guandan: A multi-player cooperative game under imperfect
    information. *arXiv preprint arXiv:2408.02559*.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yim等人（2024）Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi
    Zheng, 和 Yangqiu Song. 2024. 基于心智理论评估和增强LLM代理在关单中的表现：一种多玩家合作游戏中的不完全信息。*arXiv预印本
    arXiv:2408.02559*。
- en: 'Zhao et al. (2022) Enmin Zhao, Renye Yan, Jinqiu Li, Kai Li, and Junliang Xing.
    2022. Alphaholdem: High-performance artificial intelligence for heads-up no-limit
    poker via end-to-end reinforcement learning. In *Proceedings of the AAAI Conference
    on Artificial Intelligence*, volume 36, pages 4689–4697.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao等人（2022）Enmin Zhao, Renye Yan, Jinqiu Li, Kai Li, 和 Junliang Xing. 2022.
    Alphaholdem：通过端到端强化学习在单挑无限注扑克中的高性能人工智能。发表于*AAAI人工智能会议论文集*，第36卷，4689–4697页。
- en: Zhao et al. (2023) Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei
    Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan
    Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li,
    Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A survey
    of large language models. abs/2303.18223.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao等人（2023）Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng
    Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang,
    Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang
    Liu, Peiyu Liu, Jian-Yun Nie, 和 Ji-Rong Wen. 2023. 大型语言模型调查。abs/2303.18223。
- en: Appendix A Detailed rules
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 详细规则
- en: Each game has 6 participants, one of whom will receive the spy word. A player
    will be randomly selected to start speaking (it is not guaranteed whether this
    person is the spy), and then players will take turns speaking. Each person’s speech
    cannot repeat any previous speeches, cannot directly state their own word, and
    cannot skip speaking; otherwise, they will be judged as violating the rules. If
    the speaking time exceeds 10 seconds without a response, the system will automatically
    consider it as not speaking, which is also a violation.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 每场游戏有6名参与者，其中一人会获得间谍词语。将随机选定一名玩家开始发言（不能保证此人是间谍），然后玩家按顺序轮流发言。每个人的发言不能重复前人的发言，不能直接说出自己的词语，也不能跳过发言；否则将判定为违反规则。如果发言时间超过10秒没有回应，系统将自动视为未发言，这也算作违规。
- en: 'In the English version of game: if the speech exceeds 400 UTF-8 characters,
    the system will automatically truncate it to only the first 400 UTF-8 characters.
    In the Chinese version: if the speech exceeds 120 UTF-8 characters, the system
    will automatically truncate it to only the first 120 UTF-8 characters;'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在英文版游戏中：如果发言超过400个UTF-8字符，系统会自动截断为前400个UTF-8字符。在中文版中：如果发言超过120个UTF-8字符，系统会自动截断为前120个UTF-8字符；
- en: After each round of speaking, the judge will first determine if there are any
    violations (specifically the three types of violations mentioned above); the player
    who has violated the rules will be eliminated immediately. Then if the end condition
    is not triggered, a voting round will commence; otherwise, the game round ends.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 每轮发言结束后，裁判将首先判断是否有违反规则的情况（具体为上述三种类型的违规）；有违规的玩家将立即被淘汰。然后，如果未触发结束条件，将开始投票环节；否则，游戏回合结束。
- en: During the voting session, each surviving player can cast one vote to identify
    the spy agent, or choose to abstain; after the voting session concludes, the player
    with the most votes will be eliminated (if there is a tie for the highest number
    of votes, no one will be eliminated). The content of the votes must be from the
    given list of names; any other output will be counted as an abstention.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在投票环节中，每个幸存玩家可以投一票来识别间谍，或者选择弃权；投票结束后，获得最多票数的玩家将被淘汰（如果最高票数平局，则没有人被淘汰）。投票内容必须来自给定的名字列表；任何其他输出将被视为弃权。
- en: Each round begins with the original speaker (if the original speaker has been
    eliminated, it will pass to the next player).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 每轮开始时由原发言人开始（如果原发言人已被淘汰，将由下一个玩家接替）。
- en: 'End Condition: The game ends when the number of surviving agents is less than
    3, or the spy is eliminated, or after 3 rounds of speaking and voting.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 结束条件：当幸存的间谍人数少于3人，或间谍被淘汰，或经过3轮发言和投票后，游戏结束。
- en: 'Victory Condition: Once the end condition is triggered, if the spy is still
    alive, the spy wins; otherwise, the civilians win.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 胜利条件：一旦触发结束条件，如果间谍仍然存活，则间谍获胜；否则，平民获胜。
- en: 'Detailed Scoring Rules:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 详细计分规则：
- en: a. If the spy is eliminated in the first round, they score 0 points, and the
    surviving civilians share 12 points.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: a. 如果间谍在第一轮被淘汰，他们得0分，幸存的平民共享12分。
- en: b. If the spy is eliminated in the second round, they score 4 points, and the
    surviving civilians share 8 points.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: b. 如果间谍在第二轮被淘汰，他们得4分，幸存的平民共享8分。
- en: c. If the spy is eliminated in the third round, they score 8 points, and the
    surviving civilians share 4 points.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: c. 如果间谍在第三轮被淘汰，他们得8分，幸存的平民共享4分。
- en: d. If the spy wins, they score 12 points, and the civilians score 0 points.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: d. 如果间谍获胜，他们得12分，平民得0分。
- en: e. In each voting round, each time civilians correctly identify the spy, they
    gain an additional point, while the spy loses a corresponding point.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: e. 在每轮投票中，每次平民正确识别出间谍时，他们会获得额外的一分，而间谍会失去相应的一分。
