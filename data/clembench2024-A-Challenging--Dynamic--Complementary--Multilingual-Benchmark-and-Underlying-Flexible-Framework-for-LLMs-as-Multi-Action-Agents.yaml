- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:35:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:35:17
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: clembench2024 A Challenging, Dynamic, Complementary, Multilingual Benchmark
    and Underlying Flexible Framework for LLMs as Multi-Action Agents
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: clembench2024 一项具有挑战性、动态的、互补的多语种基准及其基础灵活框架，适用于将LLM作为多动作代理
- en: 来源：[https://arxiv.org/html/2405.20859/](https://arxiv.org/html/2405.20859/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2405.20859/](https://arxiv.org/html/2405.20859/)
- en: Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov
- en: Brielen Madureira, Philipp Sadler, David Schlangen¹
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Brielen Madureira, Philipp Sadler, David Schlangen¹
- en: Computational Linguistics, Department of Linguistics
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 计算语言学，语言学系
- en: University of Potsdam, Germany
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 波茨坦大学，德国
- en: ¹German Research Center for Artificial Intelligence (DFKI), Berlin, Germany
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ¹德国人工智能研究中心（DFKI），柏林，德国
- en: 'first.last@uni-potsdam.de   Contributions: AB designed and ran the multilingual
    experiments. KC updated the wordle games; BM did so for private/shared; SH did
    so for drawing and reference, managed the leaderboard and co-managed the project.
    PS maintained the main framework and the server infrastructure. DS co-designed
    the experiments, co-managed the project, and edited the document. All authors
    discussed all content.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: first.last@uni-potsdam.de   贡献：AB设计并运行了多语种实验。KC更新了Wordle游戏；BM为私人/共享版本做了更新；SH为绘图和参考做了更新，管理了排行榜并共同管理了项目。PS维护了主要框架和服务器基础设施。DS共同设计了实验，协同管理了项目，并编辑了文档。所有作者讨论了所有内容。
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'It has been established in recent work that Large Language Models (LLMs) can
    be prompted to “self-play” conversational games that probe certain capabilities
    (general instruction following, strategic goal orientation, language understanding
    abilities), where the resulting interactive game play can be automatically scored.
    In this paper, we take one of the proposed frameworks for setting up such game-play
    environments, and further test its usefulness as an evaluation instrument, along
    a number of dimensions: We show that it can easily keep up with new developments
    while avoiding data contamination, we show that the tests implemented within it
    are not yet saturated (human performance is substantially higher than that of
    even the best models), and we show that it lends itself to investigating additional
    questions, such as the impact of the prompting language on performance. We believe
    that the approach forms a good basis for making decisions on model choice for
    building applied interactive systems, and perhaps ultimately setting up a closed-loop
    development environment of system and simulated evaluator.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，大型语言模型（LLM）可以通过提示“自我游戏”对话式游戏，从而探测某些能力（如一般指令执行、战略目标导向、语言理解能力），并且通过自动评分的互动游戏玩法来评估这些能力。在本文中，我们采用了一个提出的框架来搭建这种游戏环境，并进一步测试其作为评估工具的有效性，从多个维度进行验证：我们展示了它能够轻松跟上新的发展，并避免数据污染；我们证明了其中实施的测试尚未饱和（人类表现远高于即便是最好的模型）；我们还展示了该框架能够用于探讨其他问题，比如提示语言对表现的影响。我们认为这一方法为在构建应用交互系统时做出模型选择提供了良好的基础，并且或许最终可以建立一个系统和模拟评估者的闭环开发环境。
- en: clembench[2024] A Challenging, Dynamic, Complementary, Multilingual Benchmark
    and Underlying Flexible Framework for LLMs as Multi-Action Agents
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: clembench[2024] 一项具有挑战性、动态的、互补的多语种基准及其基础灵活框架，适用于将LLM作为多动作代理
- en: 'Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov Brielen Madureira, Philipp
    Sadler, David Schlangen¹ ^†^†thanks:   Contributions: AB designed and ran the
    multilingual experiments. KC updated the wordle games; BM did so for private/shared;
    SH did so for drawing and reference, managed the leaderboard and co-managed the
    project. PS maintained the main framework and the server infrastructure. DS co-designed
    the experiments, co-managed the project, and edited the document. All authors
    discussed all content. Computational Linguistics, Department of Linguistics University
    of Potsdam, Germany ¹German Research Center for Artificial Intelligence (DFKI),
    Berlin, Germany first.last@uni-potsdam.de'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Anne Beyer, Kranti Chalamalasetti, Sherzod Hakimov Brielen Madureira, Philipp
    Sadler, David Schlangen¹ ^†^†致谢：  贡献：AB设计并运行了多语种实验。KC更新了Wordle游戏；BM为私人/共享版本做了更新；SH为绘图和参考做了更新，管理了排行榜并共同管理了项目。PS维护了主要框架和服务器基础设施。DS共同设计了实验，协同管理了项目，并编辑了文档。所有作者讨论了所有内容。计算语言学，语言学系，波茨坦大学，德国
    ¹德国人工智能研究中心（DFKI），柏林，德国 first.last@uni-potsdam.de
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The possibility of coaxing agentive behaviour out of large language models (LLMs)
    makes a vision seem to come into reach of setting up a closed-loop development
    cycle where the dialogue system is formulated through a description of the task
    that is to be reached, and evaluated through specifying a simulated user. While
    there is active work on both sides of this (realising task-oriented systems with
    LLMs, see e.g. Hudeček and Dusek ([2023](https://arxiv.org/html/2405.20859v1#bib.bib7)),
    and evaluating with LLM-simulated users, see e.g. Sekulic et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib14))),
    an important foundational step is to establish the validity and limitations of
    the LLMs-as-agents view. In 2023, a number of frameworks appeared that tackled
    this task through setting up dialogue “self-play” of LLMs on more abstract tasks
    with fully specifiable goals (then often called “dialogue games” (Schlangen, [2023](https://arxiv.org/html/2405.20859v1#bib.bib13))).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从大型语言模型（LLMs）中诱导出智能行为的可能性，似乎为实现一个封闭循环的开发周期提供了可行的设想，其中对话系统是通过描述要达成的任务来构建的，并通过指定一个模拟用户来进行评估。尽管目前在这两个方面都有活跃的研究（实现任务导向的系统与
    LLMs，参见例如 Hudeček 和 Dusek（[2023](https://arxiv.org/html/2405.20859v1#bib.bib7)）的工作，以及与
    LLM 模拟用户的评估，参见例如 Sekulic 等人（[2024](https://arxiv.org/html/2405.20859v1#bib.bib14)）的研究），但一个重要的基础性步骤是确立
    LLM 作为智能体这一观点的有效性和局限性。2023年，出现了多个框架，通过在更抽象的任务上设置 LLM 的对话“自我对弈”并设定完全可指定的目标来处理这一任务（这些任务通常被称为“对话游戏”（Schlangen，[2023](https://arxiv.org/html/2405.20859v1#bib.bib13)））。
- en: For this paper, we continued our work with the clemgame framework (Chalamalasetti
    et al., [2023](https://arxiv.org/html/2405.20859v1#bib.bib2)), and validated some
    of the claims that were left for future work in the original release. Specifically,
    we show that a) this approach can be extended to be a dynamic benchmark, in the
    sense that what is being evaluated are indeed the games themselves and not specific
    game instances; b) it is still a challenging benchmark, given that the scores
    of even the best models are considerably below human performance, which we establish
    for this paper for the first time; c) it is complementary to other benchmarks,
    both reference-based ones (HELM by Liang et al. ([2022](https://arxiv.org/html/2405.20859v1#bib.bib9)))
    and preference-based ones (Chatbot arena by Chiang et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib3)));
    d) the underlying abstractions are flexible, so that new models can be integrated
    easily, making it possible, as we do here, to track the rise of open-weight models
    since the first release of the benchmark; and, last but not least, e) the framework
    makes evaluation of multilingual capabilities of models easily possible, as we
    exemplify here for one of the dialogue games.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们继续使用 clemgame 框架（Chalamalasetti 等人，[2023](https://arxiv.org/html/2405.20859v1#bib.bib2)），并验证了原始发布版本中一些留待未来工作的主张。具体而言，我们展示了：a)
    这种方法可以扩展为一个动态基准测试，意味着所评估的确实是游戏本身，而不是特定的游戏实例；b) 它仍然是一个具有挑战性的基准测试，因为即使是最好的模型，其得分也明显低于人类表现，这一点我们在本文中首次确立；c)
    它与其他基准测试互补，既包括基于参考的基准（Liang 等人提出的 HELM（[2022](https://arxiv.org/html/2405.20859v1#bib.bib9)）），也包括基于偏好的基准（Chiang
    等人提出的 Chatbot arena（[2024](https://arxiv.org/html/2405.20859v1#bib.bib3)））；d)
    基础抽象是灵活的，因此可以轻松集成新模型，使得我们能够像在本文中所做的那样，追踪开放权重模型自基准首次发布以来的发展；最后但同样重要的是，e) 该框架使得模型的多语言能力评估变得轻松可行，正如我们在这里为其中一个对话游戏所举的例子。
- en: Altogether, we draw from this the conclusion that clembench constitutes a valuable
    tool for the community for testing chat-optimised LLMs (and basing decisions on
    the outcome), but also as an instrument for detailed studies of specific aspects
    of LLM behaviour. We end by speculating on possible future uses, for example as
    a learning environment specifically for interaction, and as something that brings
    us closer to the vision from the opening paragraph, as a build/test framework
    for designing improved agents.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们得出的结论是，clembench 是一个对社区非常有价值的工具，不仅可以测试针对对话优化的 LLM（并基于结果做出决策），还可以作为深入研究
    LLM 行为特定方面的工具。最后，我们对可能的未来应用进行了猜测，例如作为一个专门用于交互的学习环境，以及作为一个让我们更接近开篇段落所述愿景的工具，作为设计改进智能体的构建/测试框架。
- en: 2 Dialogue Games and Agent Capabilities
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 对话游戏与智能体能力
- en: From the realisation in 2022 that LLMs could be seen as generalist “dialogue
    models” (see e.g. Andreas ([2022](https://arxiv.org/html/2405.20859v1#bib.bib1))),
    the idea suggested itself that they could be made to simulate all sides in a conversation,
    and that this could be used to evaluate certain capabilities better than dataset-based
    evaluations. Qiao et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib12))
    implement a small number of games (20 questions-like, social deduction game) and
    test them on a small number of models. Li et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib8))
    also emphasise the need to go “beyond static datasets” and implement some interactive
    tasks, which however rely on scoring through a referee-model. Gong et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib5))
    integrate LLMs in more clearly situated environments such as Minecraft, augmenting
    the models into agents with purpose-built modules. Wu et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib16))
    also implement a variety of games and test a few models. Zhou et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib17))
    focus specifically on “social” skills and use a game-like setting to study free-form
    interactions between LLM-realised agents. Duan et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib4))
    finally set up a number of zero-shot games for self-play of LLMs, comparing the
    apparent strategies with those known to be game-theory optimal. What these works
    have in common (with the exception of Duan et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib4)))
    is a focus on face validity, in that the implemented games are simply postulated
    as being challenging, and no attempt is made at elucidating which aspect of the
    underlying construct they target.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从2022年认识到LLM（大规模语言模型）可以被视为通用的“对话模型”（例如，参见Andreas ([2022](https://arxiv.org/html/2405.20859v1#bib.bib1)))开始，便出现了一个想法，即它们可以被用来模拟对话中的各方，而这可以用来评估某些能力，比基于数据集的评估方法更有效。Qiao等人([2023](https://arxiv.org/html/2405.20859v1#bib.bib12))实现了一小部分游戏（类似20个问题，社交推理游戏），并在少量模型上进行了测试。Li等人([2023](https://arxiv.org/html/2405.20859v1#bib.bib8))也强调了需要“超越静态数据集”，并实现了一些互动任务，然而这些任务依赖于通过裁判模型进行评分。Gong等人([2023](https://arxiv.org/html/2405.20859v1#bib.bib5))将LLM集成到更明确的环境中，如Minecraft，通过增补专门设计的模块，将模型转化为具有特定目的的代理。Wu等人([2024](https://arxiv.org/html/2405.20859v1#bib.bib16))也实现了各种游戏并测试了少数几个模型。Zhou等人([2024](https://arxiv.org/html/2405.20859v1#bib.bib17))特别专注于“社交”技能，并使用类似游戏的设置来研究LLM实现的代理之间的自由互动。Duan等人([2024](https://arxiv.org/html/2405.20859v1#bib.bib4))最终设立了一些零-shot自我博弈游戏，用来比较明显的策略与已知的博弈论最优策略。除Duan等人([2024](https://arxiv.org/html/2405.20859v1#bib.bib4))外，这些工作的共同点是关注表面有效性，即所实现的游戏被简单地假定为具有挑战性，但并未尝试阐明它们针对的潜在构造的哪一方面。
- en: For the current work, we continue our work on one of the frameworks that was
    among the first to realise this idea of “self-play for evaluation” (preceding
    the work cited above), and which also specifically focussed on construct validity,
    the clemgame/clembench framework Chalamalasetti et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib2)).
    We do not repeat these validity arguments here and just point the interested reader
    to the original publication; what we do here is to introduce the basic components
    insofar as they are relevant for the work presented here.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于当前的工作，我们继续在“自我博弈评估”这一思想的框架下开展研究，这一思想最早被实现（早于上述引用的工作），并且特别关注构造效度，即clemgame/clembench框架
    Chalamalasetti等人([2023](https://arxiv.org/html/2405.20859v1#bib.bib2))。我们在这里不重复这些效度论证，只是将有兴趣的读者引导至原始出版物；我们在这里所做的，是介绍其中与本工作相关的基本组件。
- en: The main idea of this framework is that games are specified through prompt templates,
    which explain the game goals to the players in natural language, through response
    parsing rules that define what counts as a well-formed response, and through a
    game-specific game flow that defines what counts as a terminal state. A programmatic
    GameMaster then realises game play through the instantiation of the templates
    with specific game instances (e.g., in a guessing game, the word to guess in this
    round), and the turn-by-turn prompting of players (which can be LLMs, or human
    players). The resulting episodes are then scored through game specific scoring
    rules. For each game, one scoring metric is determined as the main metric (always
    ranging from 0 (worst) to 100 (best)). An overall score is computed by averaging
    this metric by game and then over games. Games where a player violates the parsing
    rules count as not played (to end). We track the percentage of games played to
    end; this allows us to separate formatting rule following capabilities (which
    are important for any use of LLMs as internal components where the output needs
    to be of a pre-specified form) from the strategic game play quality. The overall
    score is the product of the two scores. In the following, we will denote the benchmark
    (set of games) as clembench.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架的主要思想是，通过提示模板来指定游戏，这些模板用自然语言向玩家解释游戏目标，通过响应解析规则来定义什么是有效的响应，并通过特定于游戏的游戏流程来定义什么是终局状态。一个程序化的GameMaster通过将模板实例化为特定的游戏实例（例如，在猜词游戏中，本轮要猜的词）并逐回合地提示玩家（玩家可以是LLMs，也可以是人类玩家）来实现游戏的进行。随后，结果回合通过特定的游戏评分规则进行评分。对于每个游戏，都会确定一个评分指标作为主要指标（始终从0（最差）到100（最好））。通过计算每个游戏的这个指标的平均值，然后再计算所有游戏的平均值，从而得出一个总体评分。违反解析规则的游戏计为未完成（结束）。我们追踪完成的游戏百分比；这使得我们能够区分格式规则遵守能力（这对任何将LLMs作为内部组件使用，其中输出需要是预设格式的应用非常重要）与战略游戏质量。总体评分是这两个评分的乘积。以下，我们将该基准（游戏集）称为clembench。
- en: 'For the experiments reported here, we introduced a generalisation layer for
    accessing LLMs via various routes (e.g., locally via huggingface transformers
    Wolf et al. ([2020](https://arxiv.org/html/2405.20859v1#bib.bib15)) or via llama.cpp¹¹1[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)
    , or via various proprietor-specific APIs). This gives us the flexibility to benchmark
    a large selection of models, as discussed below in Section [3](https://arxiv.org/html/2405.20859v1#S3
    "3 Flexible: Performance over Time ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents"), and easily integrate new ones. We also carefully went through all components
    described above, and in particular corrected some parsing rules and scoring rules
    for some games.²²2A detailed list of changes is available in the project repositories
    at [https://github.com/clembench/.](https://github.com/clembench/.) Note that
    this makes the scores that we report not directly comparable with those previously
    reported. For the subset of models that was scored both in the previously reported
    run and in our latest one (19 models), we calculated a rank correlation (Kendall’s
    tau, $r_{\tau}$) of 0.71 ($p<.05$), i.e., a strong to very strong correlation.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里报告的实验中，我们引入了一个通用化层，用于通过各种途径访问大型语言模型（LLMs）（例如，通过本地的huggingface transformers（Wolf等人，[2020](https://arxiv.org/html/2405.20859v1#bib.bib15)），或者通过llama.cpp¹¹1[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)，或者通过各种特定厂商的API）。这为我们提供了灵活性，能够基准测试大量模型，正如下面[3](https://arxiv.org/html/2405.20859v1#S3
    "3 Flexible: Performance over Time ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents")节中讨论的那样，并且可以轻松地集成新的模型。我们还仔细检查了上面描述的所有组件，特别是修正了一些游戏的解析规则和评分规则。²²2详细的变更列表可以在项目仓库中找到：[https://github.com/clembench/.](https://github.com/clembench/.)
    请注意，这使得我们报告的得分与之前报告的得分不可直接比较。对于在之前报告的运行和我们最新运行中都进行评分的模型子集（19个模型），我们计算了一个排名相关性（Kendall的tau，$r_{\tau}$）为0.71（$p<.05$），即，强到非常强的相关性。'
- en: '| models | sc | o/g |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | o/g |'
- en: '| --- | --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-4 | 59.49 | $$ |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4 | 59.49 | $$ |'
- en: '| claude-v1.3 | 37.07 | $$ |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.07 | $$ |'
- en: '| gpt-3.5-turbo | 37.02 | $$ |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo | 37.02 | $$ |'
- en: '| text-davinci-003 | 15.78 | $$ |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| text-davinci-003 | 15.78 | $$ |'
- en: '| vicuna-13b | 4.24 | ow |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b | 4.24 | ow |'
- en: '| oasst-12b | 1.74 | ow |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| oasst-12b | 1.74 | ow |'
- en: '| koala-13b | 1.48 | ow |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| koala-13b | 1.48 | ow |'
- en: '| falcon-40b | 0.71 | ow |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| falcon-40b | 0.71 | ow |'
- en: '| luminous-supreme | 0.00 | $$ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| luminous-supreme | 0.00 | $$ |'
- en: '| models | sc | o/g |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | o/g |'
- en: '| --- | --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-4-0613 | 60.90 | $$ |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 60.90 | $$ |'
- en: '| gpt-4-1106-preview | 60.33 | $$ |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 60.33 | $$ |'
- en: '| gpt-4-0314 | 58.81 | $$ |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0314 | 58.81 | $$ |'
- en: '| claude-v1.3 | 37.64 | $$ |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.64 | $$ |'
- en: '| claude-2.1 | 36.38 | $$ |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 36.38 | $$ |'
- en: '| claude-2 | 33.71 | $$ |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| claude-2 | 33.71 | $$ |'
- en: '| gpt-3.5-turbo-0613 | 32.53 | $$ |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0613 | 32.53 | $$ |'
- en: '| gpt-3.5-turbo-1106 | 30.45 | $$ |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-1106 | 30.45 | $$ |'
- en: '| openchat_3.5 | 19.72 | ow |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 19.72 | ow |'
- en: '| mistral-medium | 17.99 | ow |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium | 17.99 | ow |'
- en: '| mixtral-8x7b-instruct-v0.1 | 17.81 | ow |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x7b-instruct-v0.1 | 17.81 | ow |'
- en: '| openchat-3.5-1210 | 17.61 | ow |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 17.61 | ow |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | ow |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | ow |'
- en: '| yi-34b-chat | 16.77 | ow |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| yi-34b-chat | 16.77 | ow |'
- en: '| wizardlm-70b-v1.0 | 16.70 | ow |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 16.70 | ow |'
- en: '| tulu-2-dpo-70b | 15.90 | ow |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-70b | 15.90 | ow |'
- en: '| sus-chat-34b | 15.64 | ow |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| sus-chat-34b | 15.64 | ow |'
- en: '| claude-instant-1.2 | 15.44 | $$ |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| claude-instant-1.2 | 15.44 | $$ |'
- en: '| models | sc | o/g |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| models | sc | o/g |'
- en: '| --- | --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-4-turbo-2024-04-09 | 58.30 | $$ |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-turbo-2024-04-09 | 58.30 | $$ |'
- en: '| gpt-4-0125-preview | 52.50 | $$ |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0125-preview | 52.50 | $$ |'
- en: '| gpt-4-1106-preview | 51.99 | $$ |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 51.99 | $$ |'
- en: '| gpt-4-0613 | 51.09 | $$ |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 51.09 | $$ |'
- en: '| gpt-4o-2024-05-13 | 48.34 | $$ |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o-2024-05-13 | 48.34 | $$ |'
- en: '| claude-3-opus-20240229 | 42.42 | $$ |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-opus-20240229 | 42.42 | $$ |'
- en: '| gemini-1.5-pro-latest | 41.72 | $$ |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-pro-latest | 41.72 | $$ |'
- en: '| llama-3-70b-instruct | 35.11 | ow |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-70b-instruct | 35.11 | ow |'
- en: '| claude-2.1 | 32.50 | $$ |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 32.50 | $$ |'
- en: '| gemini-1.5-flash-latest | 32.00 | $$ |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-flash-latest | 32.00 | $$ |'
- en: '| claude-3-sonnet-20240229 | 30.53 | $$ |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-sonnet-20240229 | 30.53 | $$ |'
- en: '| qwen1.5-72b-chat | 30.37 | ow |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-72b-chat | 30.37 | ow |'
- en: '| mistral-large-2402 | 28.17 | $$ |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| mistral-large-2402 | 28.17 | $$ |'
- en: '| gpt-3.5-turbo-0125 | 27.22 | $$ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0125 | 27.22 | $$ |'
- en: '| gemini-1.0-pro | 26.95 | $$ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.0-pro | 26.95 | $$ |'
- en: '| command-r-plus | 24.94 | ow |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| command-r-plus | 24.94 | ow |'
- en: '| openchat_3.5 | 23.64 | ow |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 23.64 | ow |'
- en: '| claude-3-haiku-20240307 | 22.49 | $$ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-haiku-20240307 | 22.49 | $$ |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | ow |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | ow |'
- en: '| llama-3-8b-instruct | 19.99 | ow |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-8b-instruct | 19.99 | ow |'
- en: '| openchat-3.5-1210 | 18.22 | ow |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 18.22 | ow |'
- en: '| wizardlm-70b-v1.0 | 17.40 | ow |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 17.40 | ow |'
- en: '| openchat-3.5-0106 | 17.10 | ow |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-0106 | 17.10 | ow |'
- en: '| qwen1.5-14b-chat | 16.80 | ow |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-14b-chat | 16.80 | ow |'
- en: '| mistral-medium-2312 | 16.43 | $$ |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium-2312 | 16.43 | $$ |'
- en: 'Table 1: From left to right, results on the English clembench from June 2023,
    November 2023, May 2024\. “ow”: open weight models, “$$”: gated models. The best
    gated model stayed constant (modulo fixes to scoring code, see text), open weight
    models gained substantially.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 表格1：从左到右，展示了2023年6月、2023年11月、2024年5月的英文clembench结果。“ow”：开放权重模型，“$$”：加密模型。最佳加密模型保持不变（排除评分代码修复，见正文），开放权重模型有了显著提升。
- en: '3 Flexible: Performance over Time'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 灵活性：随时间变化的表现
- en: Table [1](https://arxiv.org/html/2405.20859v1#S2.T1 "Table 1 ‣ 2 Dialogue Games
    and Agent Capabilities ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents") shows the clembench results over various timepoints, from the results
    of the initial publication, over an intermediate point (November 2023), to current
    results.³³3The current leaderboard and all previous versions can always be found
    at [https://clembench.github.io/leaderboard.html](https://clembench.github.io/leaderboard.html),
    with detailed result logs at [https://github.com/clembench/clembench-runs](https://github.com/clembench/clembench-runs).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[1](https://arxiv.org/html/2405.20859v1#S2.T1 "Table 1 ‣ 2 Dialogue Games
    and Agent Capabilities ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents")展示了不同时间点的clembench结果，从初始发布结果、2023年11月的中间结果，到当前的结果。³³3当前的排行榜和所有以前的版本可以随时在[https://clembench.github.io/leaderboard.html](https://clembench.github.io/leaderboard.html)找到，详细结果日志可以在[https://github.com/clembench/clembench-runs](https://github.com/clembench/clembench-runs)查看。
- en: 'Several things are notable. First, the changes described above allowed us to
    keep track of the rapidly evolving field. Whereas Chalamalasetti et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib2))
    only reported results for 9 models, the current version now tracks 53 models.
    (The figure is capped at scores below 16, to save space.) Secondly, two interesting
    trends are observable:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 有几点值得注意。首先，上述变化使我们能够跟踪这一快速发展的领域。与Chalamalasetti等人（[2023](https://arxiv.org/html/2405.20859v1#bib.bib2)）仅报告了9个模型的结果不同，当前版本现在跟踪53个模型。（为了节省空间，数据以低于16的分数进行限制。）其次，可以观察到两个有趣的趋势：
- en: $\bullet$ While there is more competition in the field of closed weight models,
    as a whole, this field has not moved up. The top position is still held by a variant
    of GPT-4, and the top score has also not improved (insofar as the numbers are
    directly comparable; see discussion above). This indicates a certain saturation
    in achievable performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 尽管在闭源权重模型领域竞争激烈，但总体而言，该领域并未取得显著进展。榜首位置仍然由GPT-4的一个变种占据，且最高得分也未提升（前提是这些数字可以直接比较；见上文讨论）。这表明在可实现的性能上已存在一定的饱和。
- en: $\bullet$ Open weight models, on the other hand, have improved dramatically
    over this time span. While the distance between the best open and the best gated
    model was 55.25 points in June 2023, it was reduced to 41.18 five months later
    (November 2023), and now (May 2024) stands at 24.94, thanks to the singular performance
    of llama3-70b-ins. (As the full tables in the Appendix [A](https://arxiv.org/html/2405.20859v1#A1
    "Appendix A Full Results ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents") show, this is partially due to the much improved formatting rule following
    capabilities of these models.)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: $\bullet$ 另一方面，开放权重模型在这段时间内取得了显著进展。虽然2023年6月最佳开放模型与最佳闭源模型之间的差距为55.25分，但五个月后的2023年11月，这一差距缩小到了41.18分，而到2024年5月，这一差距已缩小至24.94分，这要归功于llama3-70b-ins的卓越表现。（如附录[A](https://arxiv.org/html/2405.20859v1#A1
    "附录A 完整结果 ‣ clembench2024 一个具有挑战性、动态、互补、多语言的基准和背后的灵活框架")中完整的表格所示，这部分是由于这些模型在格式规则遵循能力上的大幅改进。）
- en: This indicates, we believe, the usefulness of clembench as an instrument for
    tracking developments in the field, in particular with respect to the suitability
    of a model to be directed to enter into goal-oriented interactions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们认为，clembench作为一个跟踪领域发展的工具，尤其是在模型是否适合进入目标导向交互方面，具有重要价值。
- en: '4 Dynamic: Games, not Instances'
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 动态：游戏，而非实例
- en: As remarked already by Chalamalasetti et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib2)),
    but not followed up on, the separation between game specification (through templates)
    and game instances makes it possible to treat the games as generative devices
    creating a dynamic benchmark that can more easily evade “data contamination” Magar
    and Schwartz ([2022](https://arxiv.org/html/2405.20859v1#bib.bib10)). For the
    run reported above, we created new instances for all of the games contained in
    clembench. For some games, this just required sampling from an already existing
    pool (e.g., new target words for the wordle game), for others, this required light
    manual work (e.g., selecting new target words for the taboo game following the
    methodology described in the original paper; creating new target images for the
    image game). As reported above, the ranking correlation between the previous run
    and ours is high (0.71), which we take as indication that we are indeed evaluating
    the game, and not the instances.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Chalamalasetti等人（[2023](https://arxiv.org/html/2405.20859v1#bib.bib2)）已经提到的，但没有进一步跟进，游戏规范（通过模板）与游戏实例的分离使得可以将游戏视为生成性设备，从而创建一个动态基准，更容易避免“数据污染”（Magar和Schwartz，[2022](https://arxiv.org/html/2405.20859v1#bib.bib10)）。对于上述报告的运行，我们为clembench中包含的所有游戏创建了新实例。对于某些游戏，这仅仅需要从现有池中抽样（例如，为Wordle游戏选择新的目标词），对于其他游戏，则需要一些轻微的手动工作（例如，按照原文中描述的方法为禁忌游戏选择新的目标词；为图像游戏创建新的目标图像）。如上所述，我们的排名与之前的运行的相关性较高（0.71），这表明我们确实是在评估游戏，而不是评估实例。
- en: '| % played | de | en | it | ja | pt | te | tk | tr | zh |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| % played | de | en | it | ja | pt | te | tk | tr | zh |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-4 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 99.44 (-0.56) | 98.33 (-1.67) | 100.0 (0.00) | 72.78 (-27.22) |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 99.44 (-0.56) | 98.33 (-1.67) | 100.0 (0.00) | 72.78 (-27.22) |'
- en: '| Claude-3 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3 | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0
    (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
- en: '| Llama-3-70b | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |
    100.0 (0.00) | 99.44 (-0.56) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70b | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |
    100.0 (0.00) | 99.44 (-0.56) | 100.0 (0.00) | 100.0 (0.00) | 100.0 (0.00) |'
- en: '| Llama-3-8b | 98.33 (-1.67) | 100.0 (0.00) | 100.0 (0.00) | 98.89 (-1.11)
    | 100.0 (0.00) | 87.78 (-12.22) | 28.89 (-71.11) | 0.0 (-100.00) | 100.0 (0.00)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-8b | 98.33 (-1.67) | 100.0 (0.00) | 100.0 (0.00) | 98.89 (-1.11)
    | 100.0 (0.00) | 87.78 (-12.22) | 28.89 (-71.11) | 0.0 (-100.00) | 100.0 (0.00)
    |'
- en: '| Command-R+ | 100.0 (0.56) | 99.44 (0.00) | 100.0 (0.56) | 100.0 (0.56) |
    100.0 (0.56) | 83.89 (-15.55) | 67.78 (-31.66) | 100.0 (0.56) | 99.44 (0.00) |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Command-R+ | 100.0 (0.56) | 99.44 (0.00) | 100.0 (0.56) | 100.0 (0.56) |
    100.0 (0.56) | 83.89 (-15.55) | 67.78 (-31.66) | 100.0 (0.56) | 99.44 (0.00) |'
- en: '| Openchat | 98.33 (-1.67) | 100.0 (0.00) | 46.67 (-53.33) | 100.0 (0.00) |
    50.0 (-50.00) | 0.0 (-100.00) | 0.0 (-100.00) | 0.0 (-100.00) | 46.67 (-53.33)
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Openchat | 98.33 (-1.67) | 100.0 (0.00) | 46.67 (-53.33) | 100.0 (0.00) |
    50.0 (-50.00) | 0.0 (-100.00) | 0.0 (-100.00) | 0.0 (-100.00) | 46.67 (-53.33)
    |'
- en: '| quality score | de | en | it | ja | pt | te | tk | tr | zh |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 质量评分 | de | en | it | ja | pt | te | tk | tr | zh |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| GPT-4 | 85.56 (-1.66) | 87.22 (0.00) | 89.44 (2.22) | 85.56 (-1.66) | 81.11
    (-6.11) | 35.2 (-52.02) | 75.14 (-12.08) | 50.0 (-37.22) | 88.55 (1.33) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 85.56 (-1.66) | 87.22 (0.00) | 89.44 (2.22) | 85.56 (-1.66) | 81.11
    (-6.11) | 35.2 (-52.02) | 75.14 (-12.08) | 50.0 (-37.22) | 88.55 (1.33) |'
- en: '| Claude-3 | 71.11 (-6.11) | 77.22 (0.00) | 72.22 (-5.00) | 68.89 (-8.33) |
    73.33 (-3.89) | 52.22 (-25.00) | 61.11 (-16.11) | 58.89 (-18.33) | 68.89 (-8.33)
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3 | 71.11 (-6.11) | 77.22 (0.00) | 72.22 (-5.00) | 68.89 (-8.33) |
    73.33 (-3.89) | 52.22 (-25.00) | 61.11 (-16.11) | 58.89 (-18.33) | 68.89 (-8.33)
    |'
- en: '| Llama-3-70b | 58.33 (-4.45) | 62.78 (0.00) | 66.67 (3.89) | 56.11 (-6.67)
    | 60.56 (-2.22) | 45.25 (-17.53) | 36.11 (-26.67) | 45.0 (-17.78) | 68.89 (6.11)
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-70b | 58.33 (-4.45) | 62.78 (0.00) | 66.67 (3.89) | 56.11 (-6.67)
    | 60.56 (-2.22) | 45.25 (-17.53) | 36.11 (-26.67) | 45.0 (-17.78) | 68.89 (6.11)
    |'
- en: '| Llama-3-8b | 43.5 (-4.28) | 47.78 (0.00) | 37.78 (-10.00) | 39.33 (-8.45)
    | 46.11 (-1.67) | 34.18 (-13.60) | 34.62 (-13.16) | nan (nan) | 35.0 (-12.78)
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Llama-3-8b | 43.5 (-4.28) | 47.78 (0.00) | 37.78 (-10.00) | 39.33 (-8.45)
    | 46.11 (-1.67) | 34.18 (-13.60) | 34.62 (-13.16) | nan (nan) | 35.0 (-12.78)
    |'
- en: '| Command-R+ | 37.22 (-1.33) | 38.55 (0.00) | 38.33 (-0.22) | 36.11 (-2.44)
    | 37.22 (-1.33) | 29.8 (-8.75) | 31.15 (-7.40) | 35.56 (-2.99) | 38.55 (0.00)
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Command-R+ | 37.22 (-1.33) | 38.55 (0.00) | 38.33 (-0.22) | 36.11 (-2.44)
    | 37.22 (-1.33) | 29.8 (-8.75) | 31.15 (-7.40) | 35.56 (-2.99) | 38.55 (0.00)
    |'
- en: '| Openchat | 35.59 (0.03) | 35.56 (0.00) | 54.76 (19.20) | 36.11 (0.55) | 56.67
    (21.11) | nan (nan) | nan (nan) | nan (nan) | 40.48 (4.92) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Openchat | 35.59 (0.03) | 35.56 (0.00) | 54.76 (19.20) | 36.11 (0.55) | 56.67
    (21.11) | nan (nan) | nan (nan) | nan (nan) | 40.48 (4.92) |'
- en: 'Table 2: The reference game in different languages. Top, “% played”, measuring
    formatting rule following, bottom, “quality score”, measuring quality of the well-formed
    games. In brackets the delta compared to the original English version. GPT-4:
    gpt-4-turbo-2024-04-09, Claude-3: claude-3-opus-20240229, Openchat: openchat-3.5-0106'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同语言的参考游戏。顶部，“% 完成”，衡量格式规则的遵循程度，底部，“质量评分”，衡量格式良好的游戏质量。括号中是与原始英文版本的差值。GPT-4：gpt-4-turbo-2024-04-09，Claude-3：claude-3-opus-20240229，Openchat：openchat-3.5-0106
- en: '5 Challenging: Room to Grow'
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 挑战性：有成长空间
- en: 'Chalamalasetti et al. ([2023](https://arxiv.org/html/2405.20859v1#bib.bib2))
    “suspect” that human performance on clembench would be “near the ceiling”. We
    tested this assumption. Among the authors of this paper, we created pairings so
    as to ensure that no player played a game where they were involved in the creation
    of instances. Since during the work on this paper all players developed a good
    understanding of all games, we consider the resulting scores to represent not
    average human performance, but rather human expert performance. We played between
    10 and 15 episodes per game (leaving out wordle-clue and wordle-critic, as these
    are only variants of the main wordle game). All games were played to end, hence
    ‘% played’ is, unsurprisingly, 100 for the human players. The resultant quality
    scores were: wordle: 72, taboo: 80.5; drawing: 95.2; reference: 100; leading to
    an average of 86.93 – indeed considerably higher than the best result reported
    in Table [1](https://arxiv.org/html/2405.20859v1#S2.T1 "Table 1 ‣ 2 Dialogue Games
    and Agent Capabilities ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents").'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Chalamalasetti 等人（[2023](https://arxiv.org/html/2405.20859v1#bib.bib2)）“怀疑”人在
    clembench 上的表现“接近上限”。我们对此假设进行了测试。在本文的作者中，我们进行了配对，以确保没有玩家参与了生成实例的游戏。由于在本文的工作中，所有玩家对所有游戏都有了充分的理解，我们认为结果得分代表的并不是平均人类表现，而是人类专家表现。我们在每个游戏中玩了
    10 到 15 局（排除了 wordle-clue 和 wordle-critic，因为这些只是主 wordle 游戏的变种）。所有游戏都进行了到底，因此‘%
    played’ 对于人类玩家来说，毫不意外地是 100。结果的质量得分为：wordle：72，taboo：80.5；drawing：95.2；reference：100；从而平均得分为
    86.93 —— 确实明显高于表 [1](https://arxiv.org/html/2405.20859v1#S2.T1 "Table 1 ‣ 2 Dialogue
    Games and Agent Capabilities ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents") 中报告的最佳结果。
- en: '6 Complementary: Correlations'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 互补性：相关性
- en: To investigate how the clembench measures relate to what is measured via reference-based
    evaluation on the one hand, and preference-based evaluation on the other, we computed
    rank correlation with HELM (v1.3.0, 2024-05-07; Liang et al. ([2022](https://arxiv.org/html/2405.20859v1#bib.bib9)))
    and Chatbot Arena (CA; retrieved 2024-05-16; Chiang et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib3))),
    respectively. With CA, clembench shares 30 models. The rankings correlate highly,
    with Kendall’s tau at 0.65 ($r_{\tau}$, $p<0.05$). With HELM, it shares 18 models.
    The correlation is drastically lower, at 0.39 ($r_{\tau}$, $p<0.05$). This very
    interesting result shows that clembench correlates more closely to results achieved
    through interaction (Chatbot Arena) — while not actually requiring human interaction
    and running fully offline. (For a graphical view of the ranking relations, see
    the Appendix [B](https://arxiv.org/html/2405.20859v1#A2 "Appendix B Across-Benchmark
    Correlations ‣ clembench2024 A Challenging, Dynamic, Complementary, Multilingual
    Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents").)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究 clembench 测量值如何与基于参考的评估和基于偏好的评估之间的关系，我们分别计算了与 HELM（v1.3.0，2024-05-07；Liang
    等人（[2022](https://arxiv.org/html/2405.20859v1#bib.bib9)））和 Chatbot Arena（CA；检索于
    2024-05-16；Chiang 等人（[2024](https://arxiv.org/html/2405.20859v1#bib.bib3)））的排名相关性。与
    CA，clembench 共享 30 个模型。排名高度相关，Kendall’s tau 为 0.65（$r_{\tau}$，$p<0.05$）。与 HELM，clembench
    共享 18 个模型。相关性显著较低，为 0.39（$r_{\tau}$，$p<0.05$）。这个非常有趣的结果表明，clembench 与通过互动（Chatbot
    Arena）获得的结果更为相关 —— 而且实际上不需要人类互动，且完全离线运行。（有关排名关系的图形视图，请参见附录 [B](https://arxiv.org/html/2405.20859v1#A2
    "Appendix B Across-Benchmark Correlations ‣ clembench2024 A Challenging, Dynamic,
    Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs
    as Multi-Action Agents")。）
- en: '7 Multilingual: A Case Study'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 多语言：案例研究
- en: 'The separation in the clemgame framework of game specification and game logic
    makes it possible to realise the same game in different languages, simply through
    translating the game templates and game parsing rules. We make use of this to
    probe the multilingual capabilities of a subset of the models tested above, using
    the reference game as a case study. (In this game, player A is presented with
    three, unicode character-based, 5x5 pixel images, and tasked to describe the first
    one. Player B is presented with the same images, potentially in a different order,
    and is tasked to identify the described one. Random performance would lead to
    a quality score of 33.) We selected a set of typologically diverse languages (see
    Appendix [C](https://arxiv.org/html/2405.20859v1#A3 "Appendix C Language Tested
    in the Case Study ‣ clembench2024 A Challenging, Dynamic, Complementary, Multilingual
    Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents"))
    and asked native speakers to translate the prompts and target expressions. Table [2](https://arxiv.org/html/2405.20859v1#S4.T2
    "Table 2 ‣ 4 Dynamic: Games, not Instances ‣ clembench2024 A Challenging, Dynamic,
    Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs
    as Multi-Action Agents") shows the impact of playing in languages other than English.
    The large commercial languages hold up well when it comes to following the formatting
    instructions (top part of the Table), as does llama3-70b. All models are mostly
    impacted by the quality of the game play.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 'clemgame框架中游戏规格与游戏逻辑的分离使得通过翻译游戏模板和游戏解析规则，能够轻松实现相同游戏的多语言版本。我们利用这一点来探讨上述测试模型子集的多语言能力，以参考游戏作为案例研究。（在这个游戏中，玩家A看到三个基于Unicode字符的5x5像素图像，并任务是描述第一个图像。玩家B看到相同的图像，可能顺序不同，并任务是识别被描述的图像。随机表现将导致33的质量评分。）我们选择了一组类型学上具有多样性的语言（参见附录[C](https://arxiv.org/html/2405.20859v1#A3
    "Appendix C Language Tested in the Case Study ‣ clembench2024 A Challenging, Dynamic,
    Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs
    as Multi-Action Agents")），并请母语者翻译提示语和目标表达式。表[2](https://arxiv.org/html/2405.20859v1#S4.T2
    "Table 2 ‣ 4 Dynamic: Games, not Instances ‣ clembench2024 A Challenging, Dynamic,
    Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs
    as Multi-Action Agents")展示了在非英语语言中进行游戏的影响。大型商业语言在遵循格式说明时表现良好（表格的顶部部分），llama3-70b也是如此。所有模型大多受到游戏玩法质量的影响。'
- en: We leave a more detailed analysis of these results to future work, only making
    the point here that this case study shows the value of clembench as a promising
    instrument for investigating multilingual interaction instruction following capabilities.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些结果的更详细分析留待未来的工作中，这里仅指出，案例研究展示了clembench作为一个有前景的工具，能够研究多语言互动指令跟随能力的价值。
- en: 8 Conclusions
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: 'In this short paper, we have assessed a recently proposed evaluation approach
    for LLMs that complements existing reference-based and preference-based approaches.
    We have shown that it possesses certain desirable properties, which promise to
    let it keep its relevance (because it is flexible to be adapted to new models,
    and its dynamic nature counteracts the danger of data contamination). The games
    implemented in the framework appear to sit at an interesting level: They are not
    particularly challenging for human players, and yet they are and remain so even
    for the best-performing models. In a case study, we have shown that the approach
    can also serve to investigate multilingual capabilities. Future work may show
    even further use cases, for example as a learning environment in a reinforcement
    learning setting, or as a development environment for more applied goal-directed
    dialogue systems.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇简短的论文中，我们评估了一种最近提出的评估方法，该方法补充了现有的基于参考和偏好的方法。我们展示了它具有某些理想的特性，这些特性有望保持其相关性（因为它可以灵活适应新模型，并且其动态特性能有效抵抗数据污染的风险）。在框架中实现的游戏似乎处于一个有趣的水平：这些游戏对人类玩家来说并不特别具有挑战性，但即使是最优秀的模型，仍然保持挑战性。在一个案例研究中，我们展示了该方法也可以用来调查多语言能力。未来的工作可能会展示更多的应用场景，例如作为强化学习环境中的学习平台，或作为更多应用目标导向对话系统的开发环境。
- en: References
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Andreas (2022) Jacob Andreas. 2022. [Language models as agent models](https://doi.org/10.18653/v1/2022.findings-emnlp.423).
    In *Findings of the Association for Computational Linguistics: EMNLP 2022*, pages
    5769–5779, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andreas（2022）Jacob Andreas。2022年。[语言模型作为代理模型](https://doi.org/10.18653/v1/2022.findings-emnlp.423)。载于*计算语言学协会的研究成果：EMNLP
    2022*，第5769-5779页，阿布扎比，阿联酋。计算语言学协会。
- en: 'Chalamalasetti et al. (2023) Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov,
    Brielen Madureira, Philipp Sadler, and David Schlangen. 2023. [clembench: Using
    game play to evaluate chat-optimized language models as conversational agents](https://doi.org/10.18653/v1/2023.emnlp-main.689).
    In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language
    Processing*, pages 11174–11219, Singapore. Association for Computational Linguistics.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chalamalasetti等人（2023）Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov, Brielen
    Madureira, Philipp Sadler, 和 David Schlangen。2023年。[clembench：使用游戏玩法评估优化对话的语言模型作为对话代理](https://doi.org/10.18653/v1/2023.emnlp-main.689)。载于*2023年自然语言处理实证方法会议论文集*，第11174-11219页，新加坡。计算语言学协会。
- en: 'Chiang et al. (2024) Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas
    Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael I. Jordan,
    Joseph E. Gonzalez, and Ion Stoica. 2024. [Chatbot arena: An open platform for
    evaluating llms by human preference](https://doi.org/10.48550/ARXIV.2403.04132).
    *CoRR*, abs/2403.04132.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang等人（2024）Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas
    Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael I. Jordan,
    Joseph E. Gonzalez, 和 Ion Stoica。2024年。[聊天机器人竞技场：通过人类偏好评估大语言模型的开放平台](https://doi.org/10.48550/ARXIV.2403.04132)。*CoRR*，abs/2403.04132。
- en: 'Duan et al. (2024) Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura,
    Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, and Kaidi Xu. 2024.
    [Gtbench: Uncovering the strategic reasoning limitations of llms via game-theoretic
    evaluations](https://arxiv.org/abs/2402.12348). *Preprint*, arXiv:2402.12348.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duan等人（2024）Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura,
    Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, 和Kaidi Xu。2024年。[Gtbench：通过博弈论评估揭示大语言模型的战略推理局限性](https://arxiv.org/abs/2402.12348)。*预印本*，arXiv:2402.12348。
- en: 'Gong et al. (2023) Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante,
    Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, and
    Jianfeng Gao. 2023. [Mindagent: Emergent gaming interaction](https://arxiv.org/abs/2309.09971).
    *Preprint*, arXiv:2309.09971.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gong等人（2023）Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke
    Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, 和 Jianfeng
    Gao。2023年。[Mindagent：新兴的游戏互动](https://arxiv.org/abs/2309.09971)。*预印本*，arXiv:2309.09971。
- en: Hendrycks et al. (2021) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
    Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. [Measuring Massive Multitask
    Language Understanding](http://arxiv.org/abs/2009.03300). In *Proceedings of the
    International Conference on Learning Representations (ICLR)ICLR*. ArXiv:2009.03300
    [cs].
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hendrycks等人（2021）Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas
    Mazeika, Dawn Song, 和 Jacob Steinhardt。2021年。[衡量大规模多任务语言理解](http://arxiv.org/abs/2009.03300)。载于*国际学习表征会议（ICLR）*论文集。ArXiv:2009.03300
    [cs]。
- en: Hudeček and Dusek (2023) Vojtěch Hudeček and Ondrej Dusek. 2023. [Are large
    language models all you need for task-oriented dialogue?](https://doi.org/10.18653/v1/2023.sigdial-1.21)
    In *Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse
    and Dialogue*, pages 216–228, Prague, Czechia. Association for Computational Linguistics.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hudeček 和 Dusek（2023）Vojtěch Hudeček 和 Ondrej Dusek。2023年。[大语言模型是否能满足任务导向对话的所有需求？](https://doi.org/10.18653/v1/2023.sigdial-1.21)
    载于*第24届语篇与对话特别兴趣小组年会论文集*，第216-228页，布拉格，捷克。计算语言学协会。
- en: 'Li et al. (2023) Jiatong Li, Rui Li, and Qi Liu. 2023. [Beyond static datasets:
    A deep interaction approach to llm evaluation](https://arxiv.org/abs/2309.04369).
    *Preprint*, arXiv:2309.04369.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人（2023）Jiatong Li, Rui Li, 和 Qi Liu。2023年。[超越静态数据集：一种深度交互方法评估大语言模型](https://arxiv.org/abs/2309.04369)。*预印本*，arXiv:2309.04369。
- en: Liang et al. (2022) Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras,
    Dilara Soylu, Michihiro Yasunaga, and alia. 2022. [Holistic evaluation of language
    models](https://doi.org/10.48550/arXiv.2211.09110). *CoRR*, abs/2211.09110.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang等人（2022）Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara
    Soylu, Michihiro Yasunaga等。2022年。[语言模型的整体评估](https://doi.org/10.48550/arXiv.2211.09110)。*CoRR*，abs/2211.09110。
- en: 'Magar and Schwartz (2022) Inbal Magar and Roy Schwartz. 2022. [Data contamination:
    From memorization to exploitation](https://doi.org/10.18653/v1/2022.acl-short.18).
    In *Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers)*, pages 157–165, Dublin, Ireland. Association
    for Computational Linguistics.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magar 和 Schwartz (2022) Inbal Magar 和 Roy Schwartz. 2022. [数据污染：从记忆到利用](https://doi.org/10.18653/v1/2022.acl-short.18).
    收录于 *第60届计算语言学协会年会论文集（第2卷：短篇论文）*，第157–165页，爱尔兰都柏林。计算语言学协会。
- en: OpenAI et al. (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
    Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello,
    and alia. 2024. [Gpt-4 technical report](https://arxiv.org/abs/2303.08774). *Preprint*,
    arXiv:2303.08774.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 等人 (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad,
    Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
    Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul
    Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, 等. 2024. [Gpt-4
    技术报告](https://arxiv.org/abs/2303.08774). *预印本*，arXiv:2303.08774。
- en: 'Qiao et al. (2023) Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, and Nan Duan.
    2023. [Gameeval: Evaluating llms on conversational games](https://arxiv.org/abs/2308.10032).
    *Preprint*, arXiv:2308.10032.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qiao 等人 (2023) Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, 和 Nan Duan. 2023.
    [Gameeval: 在对话游戏中评估LLM](https://arxiv.org/abs/2308.10032). *预印本*，arXiv:2308.10032。'
- en: 'Schlangen (2023) David Schlangen. 2023. [Dialogue games for benchmarking language
    understanding: Motivation, taxonomy, strategy](https://doi.org/10.48550/arXiv.2304.07007).
    *CoRR*, abs/2304.07007.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schlangen (2023) David Schlangen. 2023. [对话游戏用于语言理解基准测试：动机、分类和策略](https://doi.org/10.48550/arXiv.2304.07007).
    *CoRR*，abs/2304.07007。
- en: Sekulic et al. (2024) Ivan Sekulic, Silvia Terragni, Victor Guimarães, Nghia
    Khau, Bruna Guedes, Modestas Filipavicius, Andre Ferreira Manso, and Roland Mathis.
    2024. [Reliable LLM-based user simulator for task-oriented dialogue systems](https://aclanthology.org/2024.scichat-1.3).
    In *Proceedings of the 1st Workshop on Simulating Conversational Intelligence
    in Chat (SCI-CHAT 2024)*, pages 19–35, St. Julians, Malta. Association for Computational
    Linguistics.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sekulic 等人 (2024) Ivan Sekulic, Silvia Terragni, Victor Guimarães, Nghia Khau,
    Bruna Guedes, Modestas Filipavicius, Andre Ferreira Manso, 和 Roland Mathis. 2024.
    [基于LLM的可靠用户模拟器，用于任务导向对话系统](https://aclanthology.org/2024.scichat-1.3). 收录于 *第1届模拟聊天智能对话工作坊
    (SCI-CHAT 2024)*，第19–35页，马耳他圣朱利安。计算语言学协会。
- en: 'Wolf et al. (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond,
    Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    and Alexander Rush. 2020. [Transformers: State-of-the-art natural language processing](https://doi.org/10.18653/v1/2020.emnlp-demos.6).
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations*, pages 38–45, Online. Association for Computational
    Linguistics.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wolf 等人 (2020) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement
    Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz,
    Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
    Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
    和 Alexander Rush. 2020. [Transformers: 先进的自然语言处理](https://doi.org/10.18653/v1/2020.emnlp-demos.6).
    收录于 *2020年自然语言处理实证方法会议：系统演示*，第38–45页，在线。计算语言学协会。'
- en: 'Wu et al. (2024) Yue Wu, Xuan Tang, Tom M. Mitchell, and Yuanzhi Li. 2024.
    [Smartplay: A benchmark for llms as intelligent agents](https://arxiv.org/abs/2310.01557).
    *Preprint*, arXiv:2310.01557.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人 (2024) Yue Wu, Xuan Tang, Tom M. Mitchell, 和 Yuanzhi Li. 2024. [Smartplay:
    作为智能体的LLM基准测试](https://arxiv.org/abs/2310.01557). *预印本*，arXiv:2310.01557。'
- en: 'Zhou et al. (2024) Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei
    Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig,
    and Maarten Sap. 2024. [SOTOPIA: Interactive Evaluation for Social Intelligence
    in Language Agents](https://arxiv.org/abs/2310.11667). In *Proceedings of ICLR
    2024*, pages 1–45.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou 等人 (2024) Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu,
    Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig,
    和 Maarten Sap. 2024. [SOTOPIA: 语言代理中的社交智能互动评估](https://arxiv.org/abs/2310.11667).
    收录于 *ICLR 2024会议论文集*，第1–45页。'
- en: Appendix A Full Results
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 完整结果
- en: '| models | sc | %pl | qs | o/g |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | sc | %pl | qs | o/g |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| gpt-4 | 59.49 | 96.06 | 61.93 | $$ |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4 | 59.49 | 96.06 | 61.93 | $$ |'
- en: '| claude-v1.3 | 37.07 | 74.76 | 49.58 | $$ |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.07 | 74.76 | 49.58 | $$ |'
- en: '| gpt-3.5-turbo | 37.02 | 85.86 | 43.12 | $$ |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo | 37.02 | 85.86 | 43.12 | $$ |'
- en: '| text-davinci-003 | 15.78 | 44.50 | 35.46 | $$ |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| text-davinci-003 | 15.78 | 44.50 | 35.46 | $$ |'
- en: '| vicuna-13b | 4.24 | 13.58 | 31.25 | ow |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b | 4.24 | 13.58 | 31.25 | ow |'
- en: '| oasst-12b | 1.74 | 20.85 | 8.33 | ow |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| oasst-12b | 1.74 | 20.85 | 8.33 | ow |'
- en: '| koala-13b | 1.48 | 14.76 | 10.00 | ow |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| koala-13b | 1.48 | 14.76 | 10.00 | ow |'
- en: '| falcon-40b | 0.71 | 0.95 | 75.00 | ow |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| falcon-40b | 0.71 | 0.95 | 75.00 | ow |'
- en: '| luminous-supreme | 0.00 | 16.24 | 0.00 | $$ |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| luminous-supreme | 0.00 | 16.24 | 0.00 | $$ |'
- en: '| models | sc | %pl | qs | o/g |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | sc | %pl | qs | o/g |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| gpt-4-0613 | 60.90 | 97.22 | 62.64 | $$ |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 60.90 | 97.22 | 62.64 | $$ |'
- en: '| gpt-4-1106-preview | 60.33 | 97.95 | 61.59 | $$ |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 60.33 | 97.95 | 61.59 | $$ |'
- en: '| gpt-4-0314 | 58.81 | 93.79 | 62.70 | $$ |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0314 | 58.81 | 93.79 | 62.70 | $$ |'
- en: '| claude-v1.3 | 37.64 | 74.24 | 50.70 | $$ |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| claude-v1.3 | 37.64 | 74.24 | 50.70 | $$ |'
- en: '| claude-2.1 | 36.38 | 83.08 | 43.79 | $$ |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 36.38 | 83.08 | 43.79 | $$ |'
- en: '| claude-2 | 33.71 | 82.12 | 41.05 | $$ |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| claude-2 | 33.71 | 82.12 | 41.05 | $$ |'
- en: '| gpt-3.5-turbo-0613 | 32.53 | 91.96 | 35.37 | $$ |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0613 | 32.53 | 91.96 | 35.37 | $$ |'
- en: '| gpt-3.5-turbo-1106 | 30.45 | 77.12 | 39.49 | $$ |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-1106 | 30.45 | 77.12 | 39.49 | $$ |'
- en: '| openchat_3.5 | 19.72 | 57.57 | 34.26 | ow |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 19.72 | 57.57 | 34.26 | ow |'
- en: '| mistral-medium | 17.99 | 51.11 | 35.20 | ow |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium | 17.99 | 51.11 | 35.20 | ow |'
- en: '| mixtral-8x7b-instruct-v0.1 | 17.81 | 60.49 | 29.44 | ow |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x7b-instruct-v0.1 | 17.81 | 60.49 | 29.44 | ow |'
- en: '| openchat-3.5-1210 | 17.61 | 53.18 | 33.11 | ow |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 17.61 | 53.18 | 33.11 | ow |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | 40.82 | 41.93 | ow |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 17.12 | 40.82 | 41.93 | ow |'
- en: '| yi-34b-chat | 16.77 | 63.76 | 26.30 | ow |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| yi-34b-chat | 16.77 | 63.76 | 26.30 | ow |'
- en: '| wizardlm-70b-v1.0 | 16.70 | 51.65 | 32.34 | ow |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 16.70 | 51.65 | 32.34 | ow |'
- en: '| tulu-2-dpo-70b | 15.90 | 54.49 | 29.18 | ow |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-70b | 15.90 | 54.49 | 29.18 | ow |'
- en: '| sus-chat-34b | 15.64 | 49.75 | 31.44 | ow |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| sus-chat-34b | 15.64 | 49.75 | 31.44 | ow |'
- en: '| claude-instant-1.2 | 15.44 | 59.61 | 25.91 | $$ |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| claude-instant-1.2 | 15.44 | 59.61 | 25.91 | $$ |'
- en: '| openchat-3.5-0106 | 14.33 | 48.86 | 29.33 | ow |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-0106 | 14.33 | 48.86 | 29.33 | ow |'
- en: '| nous-hermes-2-mixtral-8x7b-dpo | 12.69 | 57.47 | 22.08 | ow |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| nous-hermes-2-mixtral-8x7b-dpo | 12.69 | 57.47 | 22.08 | ow |'
- en: '| codellama-34b-instruct-hf | 10.34 | 23.96 | 43.15 | ow |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| codellama-34b-instruct-hf | 10.34 | 23.96 | 43.15 | ow |'
- en: '| vicuna-33b-v1.3 | 9.15 | 17.47 | 52.36 | ow |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-33b-v1.3 | 9.15 | 17.47 | 52.36 | ow |'
- en: '| wizardlm-13b-v1.2 | 7.82 | 40.49 | 19.31 | ow |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-13b-v1.2 | 7.82 | 40.49 | 19.31 | ow |'
- en: '| vicuna-13b-v1.5 | 7.21 | 34.74 | 20.74 | ow |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b-v1.5 | 7.21 | 34.74 | 20.74 | ow |'
- en: '| sheep-duck-llama-2-13b | 6.74 | 34.86 | 19.34 | ow |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-13b | 6.74 | 34.86 | 19.34 | ow |'
- en: '| vicuna-7b-v1.5 | 3.46 | 12.86 | 26.91 | ow |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-7b-v1.5 | 3.46 | 12.86 | 26.91 | ow |'
- en: '| tulu-2-dpo-7b | 3.27 | 36.29 | 9.02 | ow |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-7b | 3.27 | 36.29 | 9.02 | ow |'
- en: '| command | 3.12 | 10.01 | 31.13 | $$ |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| command | 3.12 | 10.01 | 31.13 | $$ |'
- en: '| wizard-vicuna-13b-uncensored-hf | 2.06 | 9.49 | 21.71 | ow |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| wizard-vicuna-13b-uncensored-hf | 2.06 | 9.49 | 21.71 | ow |'
- en: '| llama-2-13b-chat-hf | 1.89 | 3.43 | 55.09 | ow |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-13b-chat-hf | 1.89 | 3.43 | 55.09 | ow |'
- en: '| mistral-7b-instruct-v0.1 | 1.50 | 12.86 | 11.67 | ow |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| mistral-7b-instruct-v0.1 | 1.50 | 12.86 | 11.67 | ow |'
- en: '| llama-2-70b-chat-hf | 1.39 | 3.79 | 36.74 | ow |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-70b-chat-hf | 1.39 | 3.79 | 36.74 | ow |'
- en: '| koala-13b-hf | 1.25 | 23.22 | 5.38 | ow |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| koala-13b-hf | 1.25 | 23.22 | 5.38 | ow |'
- en: '| zephyr-7b-beta | 1.23 | 3.95 | 31.25 | ow |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| zephyr-7b-beta | 1.23 | 3.95 | 31.25 | ow |'
- en: '| deepseek-llm-67b-chat | 0.77 | 2.64 | 29.17 | ow |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| deepseek-llm-67b-chat | 0.77 | 2.64 | 29.17 | ow |'
- en: '| zephyr-7b-alpha | 0.75 | 7.51 | 10.00 | ow |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| zephyr-7b-alpha | 0.75 | 7.51 | 10.00 | ow |'
- en: '| llama-2-7b-chat-hf | 0.24 | 6.05 | 4.00 | ow |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-7b-chat-hf | 0.24 | 6.05 | 4.00 | ow |'
- en: '| gpt4all-13b-snoozy | 0.00 | 2.92 | 0.00 | $$ |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| gpt4all-13b-snoozy | 0.00 | 2.92 | 0.00 | $$ |'
- en: '| deepseek-llm-7b-chat | 0.00 | 7.44 | 0.00 | ow |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| deepseek-llm-7b-chat | 0.00 | 7.44 | 0.00 | ow |'
- en: '| oasst-sft-4-pythia-12b-epoch-3.5 | 0.00 | 14.76 | 0.00 | ow |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| oasst-sft-4-pythia-12b-epoch-3.5 | 0.00 | 14.76 | 0.00 | ow |'
- en: '| falcon-7b-instruct | 0.00 | 14.29 | 0.00 | ow |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| falcon-7b-instruct | 0.00 | 14.29 | 0.00 | ow |'
- en: '| models | sc | %pl | qs | o/g |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | sc | %pl | qs | o/g |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| gpt-4-turbo-2024-04-09 | 58.30 | 94.88 | 61.45 | $$ |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-turbo-2024-04-09 | 58.30 | 94.88 | 61.45 | $$ |'
- en: '| gpt-4-0125-preview | 52.50 | 94.92 | 55.31 | $$ |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0125-preview | 52.50 | 94.92 | 55.31 | $$ |'
- en: '| gpt-4-1106-preview | 51.99 | 98.10 | 53.00 | $$ |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-1106-preview | 51.99 | 98.10 | 53.00 | $$ |'
- en: '| gpt-4-0613 | 51.09 | 94.88 | 53.85 | $$ |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4-0613 | 51.09 | 94.88 | 53.85 | $$ |'
- en: '| gpt-4o-2024-05-13 | 48.34 | 85.71 | 56.40 | $$ |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4o-2024-05-13 | 48.34 | 85.71 | 56.40 | $$ |'
- en: '| claude-3-opus-20240229 | 42.42 | 83.10 | 51.05 | $$ |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-opus-20240229 | 42.42 | 83.10 | 51.05 | $$ |'
- en: '| gemini-1.5-pro-latest | 41.72 | 82.14 | 50.79 | $$ |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-pro-latest | 41.72 | 82.14 | 50.79 | $$ |'
- en: '| llama-3-70b-instruct | 35.11 | 80.72 | 43.50 | ow |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-70b-instruct | 35.11 | 80.72 | 43.50 | ow |'
- en: '| claude-2.1 | 32.50 | 82.14 | 39.57 | $$ |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| claude-2.1 | 32.50 | 82.14 | 39.57 | $$ |'
- en: '| gemini-1.5-flash-latest | 32.00 | 76.14 | 42.03 | $$ |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.5-flash-latest | 32.00 | 76.14 | 42.03 | $$ |'
- en: '| claude-3-sonnet-20240229 | 30.53 | 85.24 | 35.82 | $$ |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-sonnet-20240229 | 30.53 | 85.24 | 35.82 | $$ |'
- en: '| qwen1.5-72b-chat | 30.37 | 80.05 | 37.94 | ow |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-72b-chat | 30.37 | 80.05 | 37.94 | ow |'
- en: '| mistral-large-2402 | 28.17 | 66.86 | 42.14 | $$ |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| mistral-large-2402 | 28.17 | 66.86 | 42.14 | $$ |'
- en: '| gpt-3.5-turbo-0125 | 27.22 | 89.67 | 30.36 | $$ |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| gpt-3.5-turbo-0125 | 27.22 | 89.67 | 30.36 | $$ |'
- en: '| gemini-1.0-pro | 26.95 | 80.14 | 33.63 | $$ |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| gemini-1.0-pro | 26.95 | 80.14 | 33.63 | $$ |'
- en: '| command-r-plus | 24.94 | 74.90 | 33.30 | ow |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| command-r-plus | 24.94 | 74.90 | 33.30 | ow |'
- en: '| openchat_3.5 | 23.64 | 63.52 | 37.22 | ow |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| openchat_3.5 | 23.64 | 63.52 | 37.22 | ow |'
- en: '| claude-3-haiku-20240307 | 22.49 | 79.52 | 28.28 | $$ |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| claude-3-haiku-20240307 | 22.49 | 79.52 | 28.28 | $$ |'
- en: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | 41.19 | 52.20 | ow |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-70b-v1.1 | 21.50 | 41.19 | 52.20 | ow |'
- en: '| llama-3-8b-instruct | 19.99 | 76.10 | 26.27 | ow |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| llama-3-8b-instruct | 19.99 | 76.10 | 26.27 | ow |'
- en: '| openchat-3.5-1210 | 18.22 | 51.19 | 35.60 | ow |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-1210 | 18.22 | 51.19 | 35.60 | ow |'
- en: '| wizardlm-70b-v1.0 | 17.40 | 46.19 | 37.66 | ow |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-70b-v1.0 | 17.40 | 46.19 | 37.66 | ow |'
- en: '| openchat-3.5-0106 | 17.10 | 52.57 | 32.52 | ow |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| openchat-3.5-0106 | 17.10 | 52.57 | 32.52 | ow |'
- en: '| qwen1.5-14b-chat | 16.80 | 40.95 | 41.02 | ow |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-14b-chat | 16.80 | 40.95 | 41.02 | ow |'
- en: '| mistral-medium-2312 | 16.43 | 49.25 | 33.36 | $$ |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| mistral-medium-2312 | 16.43 | 49.25 | 33.36 | $$ |'
- en: '| qwen1.5-32b-chat | 15.41 | 63.69 | 24.19 | ow |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-32b-chat | 15.41 | 63.69 | 24.19 | ow |'
- en: '| codegemma-7b-it | 15.30 | 51.95 | 29.45 | ow |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| codegemma-7b-it | 15.30 | 51.95 | 29.45 | ow |'
- en: '| dolphin-2.5-mixtral-8x7b | 15.10 | 46.38 | 32.55 | ow |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| dolphin-2.5-mixtral-8x7b | 15.10 | 46.38 | 32.55 | ow |'
- en: '| codellama-34b-instruct | 14.35 | 33.57 | 42.76 | ow |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| codellama-34b-instruct | 14.35 | 33.57 | 42.76 | ow |'
- en: '| command-r | 14.15 | 61.67 | 22.95 | ow |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| command-r | 14.15 | 61.67 | 22.95 | ow |'
- en: '| gemma-1.1-7b-it | 14.14 | 49.67 | 28.46 | ow |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| gemma-1.1-7b-it | 14.14 | 49.67 | 28.46 | ow |'
- en: '| sus-chat-34b | 14.11 | 54.40 | 25.93 | ow |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| sus-chat-34b | 14.11 | 54.40 | 25.93 | ow |'
- en: '| mixtral-8x22b-instruct-v0.1 | 12.69 | 52.14 | 24.33 | ow |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x22b-instruct-v0.1 | 12.69 | 52.14 | 24.33 | ow |'
- en: '| tulu-2-dpo-70b | 12.62 | 49.76 | 25.37 | ow |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| tulu-2-dpo-70b | 12.62 | 49.76 | 25.37 | ow |'
- en: '| nous-hermes-2-mixtral-8x7b-sft | 11.95 | 39.68 | 30.12 | ow |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| nous-hermes-2-mixtral-8x7b-sft | 11.95 | 39.68 | 30.12 | ow |'
- en: '| wizardlm-13b-v1.2 | 11.48 | 39.57 | 29.00 | ow |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| wizardlm-13b-v1.2 | 11.48 | 39.57 | 29.00 | ow |'
- en: '| vicuna-33b-v1.3 | 11.27 | 23.81 | 47.32 | ow |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-33b-v1.3 | 11.27 | 23.81 | 47.32 | ow |'
- en: '| mistral-7b-instruct-v0.2 | 9.75 | 36.91 | 26.42 | ow |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| mistral-7b-instruct-v0.2 | 9.75 | 36.91 | 26.42 | ow |'
- en: '| yi-34b-chat | 8.27 | 40.86 | 20.25 | ow |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| yi-34b-chat | 8.27 | 40.86 | 20.25 | ow |'
- en: '| mixtral-8x7b-instruct-v0.1 | 8.17 | 47.62 | 17.15 | ow |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| mixtral-8x7b-instruct-v0.1 | 8.17 | 47.62 | 17.15 | ow |'
- en: '| mistral-7b-instruct-v0.1 | 8.01 | 37.14 | 21.58 | ow |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| mistral-7b-instruct-v0.1 | 8.01 | 37.14 | 21.58 | ow |'
- en: '| yi-1.5-34b-chat | 7.67 | 52.38 | 14.65 | ow |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| yi-1.5-34b-chat | 7.67 | 52.38 | 14.65 | ow |'
- en: '| vicuna-13b-v1.5 | 7.01 | 39.52 | 17.73 | ow |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| vicuna-13b-v1.5 | 7.01 | 39.52 | 17.73 | ow |'
- en: '| yi-1.5-6b-chat | 6.73 | 41.43 | 16.25 | ow |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| yi-1.5-6b-chat | 6.73 | 41.43 | 16.25 | ow |'
- en: '| starling-lm-7b-beta | 6.56 | 30.89 | 21.25 | ow |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| starling-lm-7b-beta | 6.56 | 30.89 | 21.25 | ow |'
- en: '| sheep-duck-llama-2-13b | 5.39 | 31.90 | 16.90 | ow |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| sheep-duck-llama-2-13b | 5.39 | 31.90 | 16.90 | ow |'
- en: '| yi-1.5-9b-chat | 4.37 | 38.10 | 11.48 | ow |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| yi-1.5-9b-chat | 4.37 | 38.10 | 11.48 | ow |'
- en: '| gemma-1.1-2b-it | 2.91 | 22.62 | 12.87 | ow |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| gemma-1.1-2b-it | 2.91 | 22.62 | 12.87 | ow |'
- en: '| qwen1.5-7b-chat | 2.58 | 30.24 | 8.53 | ow |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-7b-chat | 2.58 | 30.24 | 8.53 | ow |'
- en: '| gemma-7b-it | 1.82 | 17.78 | 10.23 | ow |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| gemma-7b-it | 1.82 | 17.78 | 10.23 | ow |'
- en: '| llama-2-70b-chat | 0.81 | 7.14 | 11.31 | ow |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| llama-2-70b-chat | 0.81 | 7.14 | 11.31 | ow |'
- en: '| qwen1.5-0.5b-chat | 0.12 | 25.72 | 0.48 | ow |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-0.5b-chat | 0.12 | 25.72 | 0.48 | ow |'
- en: '| qwen1.5-1.8b-chat | 0.00 | 15.24 | 0.00 | ow |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| qwen1.5-1.8b-chat | 0.00 | 15.24 | 0.00 | ow |'
- en: 'Table 3: In order, results on the English clembench from June 2023, November
    2023, May 2024\. “sc” is the clemscore, “%pl” is the percentage of games played
    formally correctly, “qs” is the quality of the game play of those games; “ow”:
    open weight models, “$$”: gated models.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：按顺序列出 2023 年 6 月、2023 年 11 月、2024 年 5 月在英语 clembench 上的结果。 “sc” 是 clemscore，
    “%pl” 是正式正确游戏的百分比， “qs” 是这些游戏的游戏质量；“ow”：开放权重模型，“$$”：有门控模型。
- en: See Table [3](https://arxiv.org/html/2405.20859v1#A1.T3 "Table 3 ‣ Appendix
    A Full Results ‣ clembench2024 A Challenging, Dynamic, Complementary, Multilingual
    Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents").
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 查看表[3](https://arxiv.org/html/2405.20859v1#A1.T3 "表 3 ‣ 附录 A 完整结果 ‣ clembench2024
    一个具有挑战性、动态、互补、多语言的基准测试和适用于大语言模型的灵活框架")。
- en: Appendix B Across-Benchmark Correlations
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 跨基准相关性
- en: See Figure [1](https://arxiv.org/html/2405.20859v1#A2.F1 "Figure 1 ‣ Appendix
    B Across-Benchmark Correlations ‣ clembench2024 A Challenging, Dynamic, Complementary,
    Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action
    Agents").
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见图[1](https://arxiv.org/html/2405.20859v1#A2.F1 "图 1 ‣ 附录 B 跨基准相关性 ‣ clembench2024
    一个具有挑战性、动态、互补的多语言基准及其灵活框架，适用于作为多行动体的LLMs")。
- en: '![Refer to caption](img/89c7cb132b34f7344d6917aef9d36e5d.png)![Refer to caption](img/5b3484a2c44842baa407570e600dcaf8.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅图注](img/89c7cb132b34f7344d6917aef9d36e5d.png)![请参阅图注](img/5b3484a2c44842baa407570e600dcaf8.png)'
- en: 'Figure 1: Top: Bump chart showing ranking differences between clembench (left)
    and Chatbot Arena (2024-05-16; right); Bottom: Ranking differences between clembench (left)
    and HELM (v1.3.0; right)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：上方：展示 clembench（左）与 Chatbot Arena（2024-05-16；右）之间排名差异的凸形图；下方：展示 clembench（左）与
    HELM（v1.3.0；右）之间的排名差异
- en: Appendix C Language Tested in the Case Study
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 案例研究中测试的语言
- en: 'While there is no explicit information available on the amount of training
    data and optimisation for different languages for the commercial models, the model
    card for Command-R+ gives an overview of the supported languages on different
    levels.⁴⁴4[https://huggingface.co/CohereForAI/c4ai-command-r-plus](https://huggingface.co/CohereForAI/c4ai-command-r-plus)
    We select a subset of eight languages from different language families, five for
    which the model is explicitly optimised: German (de), Italian (it), Brazilian
    Portuguese (pt), Japanese (ja) and Simplified Chinese (zh), one for which the
    training data is reported to contain resources: Turkish (tr), and two which are
    not supported explicitly: Telugu (te) and Turkmen (tk).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关于商业模型在不同语言上所使用的训练数据量和优化情况并没有明确的信息，但Command-R+的模型卡提供了不同层次上支持语言的概览。⁴⁴4[https://huggingface.co/CohereForAI/c4ai-command-r-plus](https://huggingface.co/CohereForAI/c4ai-command-r-plus)我们从不同语言家族中选择了八种语言，其中五种是模型明确优化的：德语（de）、意大利语（it）、巴西葡萄牙语（pt）、日语（ja）和简体中文（zh）；一种训练数据中报告包含资源的语言：土耳其语（tr）；还有两种没有明确支持的语言：泰卢固语（te）和土库曼语（tk）。
- en: The Technical Report on GPT-4 OpenAI et al. ([2024](https://arxiv.org/html/2405.20859v1#bib.bib11))
    does not contain any information on the languages supported in the training data,
    but their evaluation contains a ranking of the model’s performance in different
    languages on an automatically translated version of multiple choice questions
    (Hendrycks et al., [2021](https://arxiv.org/html/2405.20859v1#bib.bib6)). Among
    others, our selected languages include the best and worst performing languages
    from their evaluation (Italian and Telugu, respectively). Similarly, the Claude-3
    Model Card (available at [https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf))
    does not contain information on multilingual training data, but the languages
    we select also cover a broad range of the ones this model was evaluated on (and
    more).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPT-4技术报告（OpenAI等，([2024](https://arxiv.org/html/2405.20859v1#bib.bib11))）并未包含有关训练数据中支持的语言的任何信息，但其评估中包含了模型在不同语言上的表现排名，这些评估基于对多项选择题的自动翻译版本（Hendrycks等，[2021](https://arxiv.org/html/2405.20859v1#bib.bib6)）。其中，我们选择的语言包括了他们评估中表现最好和最差的语言（分别是意大利语和泰卢固语）。同样，Claude-3模型卡（可在[https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)上获取）也没有包含多语言训练数据的相关信息，但我们选择的语言同样涵盖了该模型评估的广泛语言（及更多）。
