- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:52:23'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:52:23
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们组队吗：探索竞争性大语言模型（LLM）代理的自发合作
- en: 来源：[https://arxiv.org/html/2402.12327/](https://arxiv.org/html/2402.12327/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2402.12327/](https://arxiv.org/html/2402.12327/)
- en: ^(1,2)Zengqing Wu^†, ³Run Peng^†, ¹Shuyuan Zheng^‡, ⁴Qianying Liu, ⁵Xu Han,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ^(1,2)吴增清^†，³彭润^†，¹郑书源^‡，⁴刘倩颖，⁵韩旭，
- en: ⁶Brian Inhyuk Kwon, ¹Makoto Onizuka, ⁷Shaojie Tang, ^(1,8)Chuan Xiao^‡
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ⁶Brian Inhyuk Kwon，¹Makoto Onizuka，⁷Shaojie Tang，^(1,8)Chuan Xiao^‡
- en: ¹Osaka University, ²Kyoto University, ³University of Michigan, Ann Arbor, ⁴LLMC,
    NII,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹大阪大学，²京都大学，³密歇根大学安娜堡分校，⁴LLMC，NII，
- en: ⁵Fordham University, ⁶University of California, Los Angeles, ⁷University at
    Buffalo, ⁸Nagoya University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵福特汉姆大学，⁶加利福尼亚大学洛杉矶分校，⁷纽约州立大学布法罗分校，⁸名古屋大学
- en: wuzengqing@outlook.com, roihn@umich.edu, zheng@ist.osaka-u.ac.jp, ying@nii.ac.jp,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: wuzengqing@outlook.com, roihn@umich.edu, zheng@ist.osaka-u.ac.jp, ying@nii.ac.jp,
- en: xhan44@fordham.edu, briankwon42@g.ucla.edu, onizuka@ist.osaka-u.ac.jp, shaojiet@buffalo.edu,
    chuanx@nagoya-u.jp
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: xhan44@fordham.edu, briankwon42@g.ucla.edu, onizuka@ist.osaka-u.ac.jp, shaojiet@buffalo.edu,
    chuanx@nagoya-u.jp
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large Language Models (LLMs) have increasingly been utilized in social simulations,
    where they are often guided by carefully crafted instructions to stably exhibit
    human-like behaviors during simulations. Nevertheless, we doubt the necessity
    of shaping agents’ behaviors for accurate social simulations. Instead, this paper
    emphasizes the importance of spontaneous phenomena, wherein agents deeply engage
    in contexts and make adaptive decisions without explicit directions. We explored
    spontaneous cooperation across three competitive scenarios and successfully simulated
    the gradual emergence of cooperation, findings that align closely with human behavioral
    data. This approach not only aids the computational social science community in
    bridging the gap between simulations and real-world dynamics but also offers the
    AI community a novel method to assess LLMs’ capability of deliberate reasoning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）在社会模拟中被越来越广泛地应用，通常通过精心设计的指令来引导它们，在模拟过程中稳定地表现出类似人类的行为。然而，我们怀疑在进行准确的社会模拟时，塑造代理行为是否真的必要。相反，本文强调了自发现象的重要性，在这些现象中，代理们深入参与情境并在没有明确指令的情况下做出适应性决策。我们在三种竞争性场景中探索了自发合作，并成功地模拟了合作的逐步出现，这一发现与人类行为数据高度吻合。这种方法不仅帮助计算社会科学领域弥合了模拟与现实世界动态之间的差距，还为人工智能领域提供了一种评估大语言模型（LLM）推理能力的新方法。
- en: \mdfsetup
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \mdfsetup
- en: font=, innertopmargin=2pt, innerbottommargin=2pt, innerleftmargin=8pt, innerrightmargin=8pt,
    frametitleaboveskip=2pt, frametitlebelowskip=1pt, frametitlealignment=, middlelinecolor=blue
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: font=, innertopmargin=2pt, innerbottommargin=2pt, innerleftmargin=8pt, innerrightmargin=8pt,
    frametitleaboveskip=2pt, frametitlebelowskip=1pt, frametitlealignment=, middlelinecolor=blue
- en: 'Shall We Team Up:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们组队吗：
- en: Exploring Spontaneous Cooperation of Competing LLM Agents
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 探索竞争性大语言模型（LLM）代理的自发合作
- en: '^(${}^{{\dagger}}$)^(${}^{{\dagger}}$)footnotetext: Co-first author.^(${}^{{\ddagger}}$)^(${}^{{\ddagger}}$)footnotetext:
    Corresponding author.^†^†footnotetext: Our source code is available at [https://github.com/wuzengqing001225/SABM_ShallWeTeamUp](https://github.com/wuzengqing001225/SABM_ShallWeTeamUp)
    .'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ^(${}^{{\dagger}}$)^(${}^{{\dagger}}$)脚注：共同第一作者。^(${}^{{\ddagger}}$)^(${}^{{\ddagger}}$)脚注：通讯作者。^†^†脚注：我们的源代码可以在[https://github.com/wuzengqing001225/SABM_ShallWeTeamUp](https://github.com/wuzengqing001225/SABM_ShallWeTeamUp)
    获取。
- en: 1 Introduction
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: LLM agent in social simulation has emerged as a trending research topic with
    the improvement of generative AI (Park et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib33);
    Sreedhar and Chilton, [2024](https://arxiv.org/html/2402.12327v3#bib.bib41); Jansen
    et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib20); Argyle et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib4); Xi et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib51)).
    Instead of traditional rule-based agent modeling, using LLMs as agents provides
    much more flexibility and generalizability Janssen and Ostrom ([2006](https://arxiv.org/html/2402.12327v3#bib.bib21)).
    This in return, is also widely regarded as a verification as well as enhancement
    method for LLM’s capability on human-like deliberate reasoning (Abdelnabi et al.,
    [2024](https://arxiv.org/html/2402.12327v3#bib.bib1); Du et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib12);
    Liu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib29)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 社会模拟中的LLM代理已成为随着生成性AI发展而兴起的热门研究话题（Park et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib33);
    Sreedhar和Chilton, [2024](https://arxiv.org/html/2402.12327v3#bib.bib41); Jansen
    et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib20); Argyle et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib4); Xi et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib51))。与传统的基于规则的代理建模不同，使用LLM作为代理提供了更多的灵活性和通用性（Janssen和Ostrom,
    [2006](https://arxiv.org/html/2402.12327v3#bib.bib21)）。反过来，这也被广泛视为一种验证和增强LLM在人类般推理能力上的方法（Abdelnabi
    et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib1); Du et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib12);
    Liu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib29)）。
- en: A crucial question of agent modeling is how well it mirrors real-world situations.
    Some research has revealed LLM’s capability to mimic basic human behaviors or
    reasoning abilities (Salecha et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib36);
    Kosinski, [2024](https://arxiv.org/html/2402.12327v3#bib.bib23); Jansen et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib20); Ziems et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib59);
    Zhang et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib55)). Meanwhile,
    data contamination as well as value alignment may also introduce unwanted priors
    to let LLM models be over familiar or biased with the studied problems (Zhou et al.,
    [2024](https://arxiv.org/html/2402.12327v3#bib.bib58); Ma et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib31);
    Mozikov et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib32); Ai et al.,
    [2024](https://arxiv.org/html/2402.12327v3#bib.bib2); Hu and Collier, [2024](https://arxiv.org/html/2402.12327v3#bib.bib19);
    Shapira et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib39)). It potentially
    affects the quality of social simulations in complex, long-term scenarios where
    higher level of interactions, e.g. cooperation, confrontation, deception, and
    persuasion are jointly involved. Instead, we argue that in social simulations,
    agents must be independent of prior assumptions, focus on the context, and actively
    adapt their actions based on historical interactions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 代理建模的一个关键问题是它与现实世界情况的相似程度。一些研究揭示了LLM模拟基本人类行为或推理能力的能力（Salecha et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib36);
    Kosinski, [2024](https://arxiv.org/html/2402.12327v3#bib.bib23); Jansen et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib20); Ziems et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib59);
    Zhang et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib55))。与此同时，数据污染以及价值对齐可能会引入不必要的先验知识，使LLM模型过于熟悉或偏向研究中的问题（Zhou
    et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib58); Ma et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib31);
    Mozikov et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib32); Ai et al.,
    [2024](https://arxiv.org/html/2402.12327v3#bib.bib2); Hu和Collier, [2024](https://arxiv.org/html/2402.12327v3#bib.bib19);
    Shapira et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib39))。这可能会影响社会模拟在复杂、长期场景中的质量，尤其是在涉及高层次互动（例如合作、对抗、欺骗和劝说）时。相反，我们认为，在社会模拟中，代理必须独立于先验假设，专注于情境，并根据历史互动积极调整其行为。
- en: '![Refer to caption](img/9bb753186415d84eb2f031297405f1bc.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9bb753186415d84eb2f031297405f1bc.png)'
- en: 'Figure 1: (Depicted by GPT-4o) Two potential scenarios during a fire. People
    might panic and rush into crowds, trying to exit first (left) or may stay calm,
    keep in line, and encourage others (right). In this study, we explore whether
    LLM agents can simulate the gradual transition from non-cooperative to cooperative
    behaviors of agents.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：（由GPT-4o绘制）火灾中的两种潜在场景。人们可能会惊慌失措，冲向人群，试图先行逃生（左图），或者可能保持冷静，排队并鼓励他人（右图）。在本研究中，我们探讨LLM代理是否能够模拟从非合作行为到合作行为的渐进转变。
- en: 'We highly value the deliberate in-context reasoning capability as one of the
    significant components towards a human-like LLM agent for real-world simulations.
    To properly verify such capability, we study a counter-intuitive social situation
    where agents can hardly use their prior knowledge for decision making. To be specific,
    we investigate whether cooperation can naturally develop among agents, even in
    a competitive environment. Consider two snack companies competing for dominance
    in the candy market. They might continuously reduce their prices to draw in more
    customers or decide to simultaneously increase their prices to establish a mutually
    beneficial relationship. Fig. [1](https://arxiv.org/html/2402.12327v3#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents") shows another example when agents are in a room with fire. Under
    competitive conditions, it is not instinctive for agents to cooperate with their
    opponents. However, as interactions progress, they may discover the advantages
    of cooperation through contexts and accordingly adjust their strategies. Meanwhile,
    we carefully design the prompts to avoid instructive descriptions (e.g. “you may
    cooperate”) and keywords that might reveal to the agent (e.g. “price war”) the
    specific nature of the social simulation it is conducting. In these ways, we try
    our best to eliminate the influence from both internal and external bias, and
    observe that LLM agents can actively adapt their strategies to the dynamic contexts,
    spontaneously learning to cooperate in the wild.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '我们高度重视情境中深思熟虑的推理能力，视其为实现类人LLM代理进行真实世界模拟的重要组成部分。为了正确验证这一能力，我们研究了一种反直觉的社会情境，在这种情境中，代理几乎无法依赖其先前的知识进行决策。具体而言，我们探讨了在竞争环境中，代理是否能够自然地发展出合作关系。考虑两个在糖果市场中争夺主导地位的小吃公司。它们可能会不断降低价格以吸引更多客户，或者决定同时提高价格以建立互利关系。图[1](https://arxiv.org/html/2402.12327v3#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents")展示了代理处于火灾房间中的另一个例子。在竞争条件下，代理与对手合作并非出于本能。然而，随着互动的进行，它们可能通过情境发现合作的优势，并据此调整其策略。同时，我们精心设计了提示语，以避免指示性描述（例如“你可以合作”）和可能揭示社会模拟具体性质的关键词（例如“价格战”）。通过这些方式，我们尽力消除来自内部和外部偏见的影响，观察到LLM代理能够主动适应动态情境，自发地在复杂环境中学习合作。'
- en: We select three social phenomenons that follow the aforementioned features to
    conduct case studies, where we capture different ways of spontaneous cooperation
    emerge under competitive scenarios without instructive guidance. Extensive ablation
    studies are done to prove the significance of bias elimination, and experiments
    are carefully designed to ensure reproducibility.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了三种符合上述特征的社会现象进行案例研究，捕捉到在没有指导性引导下，竞争场景中自发合作的不同方式。我们进行了广泛的消融实验，证明了消除偏见的重要性，并精心设计了实验以确保可重复性。
- en: 'To conclude, our contributions are twofold and can serve both the AI and computational
    social science (CSS) communities:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们的贡献有两个方面，可以同时服务于人工智能（AI）和计算社会科学（CSS）领域：
- en: 1)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: We observe the spontaneous cooperation between LLM agents in diverse competitive
    scenarios, which reflects LLM’s potential in long-horizon in-context learning
    tasks.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们观察到LLM代理在多种竞争场景中自发合作的现象，这反映了LLM在长期情境学习任务中的潜力。
- en: 2)
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: i) From the perspective of CSS, we reveal and stress the significance of eliminating
    bias in LLM agents for social simulations. This largely helps to build up diverse
    human-like LLM agents for real-world simulations.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: i) 从CSS的角度来看，我们揭示并强调了在社会模拟中消除LLM代理偏见的重要性。这在很大程度上有助于构建多样化的类人LLM代理，进而实现真实世界模拟。
- en: ii) From the perspective of AI, we present a new way to verify LLMs’ deliberate
    reasoning ability in long-horizon, practical role-plays. The ability of an agent
    to actively adapt its knowledge and strategy based on historical context, instead
    of relying on carefully crafted prompts, is a crucial standard for general autonomous
    agents.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ii) 从AI的角度来看，我们提出了一种新的方法来验证LLM在长期、实际角色扮演中的深思熟虑推理能力。代理能够基于历史上下文主动调整其知识和策略，而不是依赖于精心设计的提示，这是评估通用自主代理的一个关键标准。
- en: 2 Related Work
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLM Agents for Social Simulation
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 社会模拟中的LLM代理
- en: LLM agents have been widely favored in social simulations in recent years (Li
    et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib26); Lin et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib27);
    Giabbanelli, [2023](https://arxiv.org/html/2402.12327v3#bib.bib15); Xie et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib52); Wang et al., [2023a](https://arxiv.org/html/2402.12327v3#bib.bib44);
    Xi et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib51); Gao et al.,
    [2023a](https://arxiv.org/html/2402.12327v3#bib.bib13), [b](https://arxiv.org/html/2402.12327v3#bib.bib14);
    Liu et al., [2023a](https://arxiv.org/html/2402.12327v3#bib.bib28)). We further
    delve deep into investigate if we can simulate spontaneous cooperation with the
    help of LLM’s long-horizon deliberate reasoning.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大语言模型智能体在社会仿真中得到了广泛应用（Li等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib26)；Lin等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib27)；Giabbanelli，[2023](https://arxiv.org/html/2402.12327v3#bib.bib15)；Xie等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib52)；Wang等，[2023a](https://arxiv.org/html/2402.12327v3#bib.bib44)；Xi等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib51)；Gao等，[2023a](https://arxiv.org/html/2402.12327v3#bib.bib13)，[b](https://arxiv.org/html/2402.12327v3#bib.bib14)；Liu等，[2023a](https://arxiv.org/html/2402.12327v3#bib.bib28)）。我们进一步深入探讨是否能够借助大语言模型的长期推理能力来模拟自发的合作行为。
- en: 'There are also well-developed platforms that support multi-agent simulation
    with LLMs, including LangChain (Chase, [2023](https://arxiv.org/html/2402.12327v3#bib.bib9)),
    AutoGen (Wu et al., [2023a](https://arxiv.org/html/2402.12327v3#bib.bib48)), and
    agent-oriented frameworks such as AgentLite (Liu et al., [2024](https://arxiv.org/html/2402.12327v3#bib.bib30)),
    AgentVerse (Chen et al., [2023](https://arxiv.org/html/2402.12327v3#bib.bib10)),
    and SABM (Wu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)).
    Here, we use SABM as the main framework in our case studies for its lightweight,
    user-friendly implementation. A primer on SABM is available in Appendix [F](https://arxiv.org/html/2402.12327v3#A6
    "Appendix F SABM Primer ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents").'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '也有一些成熟的平台支持使用大语言模型（LLM）进行多智能体仿真，包括LangChain（Chase，[2023](https://arxiv.org/html/2402.12327v3#bib.bib9)）、AutoGen（Wu等，[2023a](https://arxiv.org/html/2402.12327v3#bib.bib48)）以及面向智能体的框架，如AgentLite（Liu等，[2024](https://arxiv.org/html/2402.12327v3#bib.bib30)）、AgentVerse（Chen等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib10)）和SABM（Wu等，[2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)）。在我们的案例研究中，我们使用SABM作为主要框架，因为它具有轻量级和用户友好的实现方式。关于SABM的入门介绍请参见附录[F](https://arxiv.org/html/2402.12327v3#A6
    "Appendix F SABM Primer ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents")。'
- en: Multi-agent Interactions in LLMs
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 大语言模型中的多智能体交互
- en: Cooperation and competition among agents have been extensively explored using
    LLMs. Studies such as Wang et al. [2023b](https://arxiv.org/html/2402.12327v3#bib.bib45);
    Qian et al. [2023](https://arxiv.org/html/2402.12327v3#bib.bib35); Hong et al.
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib18); Hang et al. [2024](https://arxiv.org/html/2402.12327v3#bib.bib17);
    Tang et al. [2024](https://arxiv.org/html/2402.12327v3#bib.bib42) have shown LLM
    agents collaborating on complex tasks like software development and image editing.
    Multi-party games like murder mystery Junprung ([2023](https://arxiv.org/html/2402.12327v3#bib.bib22)),
    Werewolf Xu et al. ([2023a](https://arxiv.org/html/2402.12327v3#bib.bib53), [b](https://arxiv.org/html/2402.12327v3#bib.bib54));
    Wu et al. ([2024](https://arxiv.org/html/2402.12327v3#bib.bib49)); Du and Zhang
    ([2024](https://arxiv.org/html/2402.12327v3#bib.bib11)), Avalon Lan et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib24));
    Shi et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib40)), and other
    competitive settings Zhao et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib57))
    have also been investigated, often using direct instructions to influence agent
    behaviors. Yet, following Piatti et al. [2024](https://arxiv.org/html/2402.12327v3#bib.bib34),
    our study concentrates on minimally guided, debiased LLM behaviors in social simulations,
    examining whether LLMs can naturally cooperate within competitive scenarios through
    in-context learning.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 利用大语言模型（LLM）已经广泛探讨了智能体之间的合作与竞争。研究如王等人 [2023b](https://arxiv.org/html/2402.12327v3#bib.bib45)、钱等人
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib35)、洪等人 [2023](https://arxiv.org/html/2402.12327v3#bib.bib18)、杭等人
    [2024](https://arxiv.org/html/2402.12327v3#bib.bib17)、唐等人 [2024](https://arxiv.org/html/2402.12327v3#bib.bib42)
    已经展示了LLM智能体在复杂任务中的合作，如软件开发和图像编辑。像谋杀谜题Junprung（[2023](https://arxiv.org/html/2402.12327v3#bib.bib22)）、狼人Xu等人（[2023a](https://arxiv.org/html/2402.12327v3#bib.bib53)、[b](https://arxiv.org/html/2402.12327v3#bib.bib54)）、吴等人（[2024](https://arxiv.org/html/2402.12327v3#bib.bib49)）、杜和张（[2024](https://arxiv.org/html/2402.12327v3#bib.bib11)）、阿瓦隆Lan等人（[2023](https://arxiv.org/html/2402.12327v3#bib.bib24)）、史等人（[2023](https://arxiv.org/html/2402.12327v3#bib.bib40)）等多方游戏和其他竞争场景赵等人（[2023](https://arxiv.org/html/2402.12327v3#bib.bib57)）也已被研究，通常通过直接指令来影响智能体的行为。然而，遵循Piatti等人
    [2024](https://arxiv.org/html/2402.12327v3#bib.bib34)的研究，我们的研究集中在最小引导、去偏的LLM行为上，探讨LLM是否能够通过上下文学习在竞争场景中自发地进行合作。
- en: '![Refer to caption](img/4e181e31f568aa493f9bf248ba859a54.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/4e181e31f568aa493f9bf248ba859a54.png)'
- en: 'Figure 2: Workflow in the three case studies, illustrating how our framework
    ![Refer to caption](img/1373dbdf748bbe32a4c419f7c9662a74.png) manages LLM agents
    during simulations. From left to right, the workflow progresses through the communication
    phase, planning phase, action phase, and update phase. In BC, the order of the
    communication and planning phases is swapped to align with previous simulations
    that used human subjects Andres et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib3)).
    The first three phases involve one or more LLM queries initiated by the framework.
    The final phase does not involve LLM queries but updates the state for each scenario.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：三项案例研究的工作流程，展示了我们的框架如何在模拟过程中管理LLM智能体。 从左到右，工作流程依次经过沟通阶段、规划阶段、行动阶段和更新阶段。在BC中，沟通和规划阶段的顺序被交换，以与之前使用人类参与者的模拟相一致Andres等人（[2023](https://arxiv.org/html/2402.12327v3#bib.bib3)）。前三个阶段涉及框架启动的一次或多次LLM查询。最后一个阶段不涉及LLM查询，而是更新每个场景的状态。
- en: 3 Spontaneous Cooperation in Competition
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 竞争中的自发合作
- en: We define spontaneous cooperation as cooperative behavior that arises without
    any explicit instructions or prompts directing the agents to cooperate. Our main
    focus is to investigate whether agents with different or even conflicting goals
    can choose to cooperate based on their realization that cooperation is beneficial
    during the interaction.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将自发合作定义为在没有任何明确指令或提示引导智能体合作的情况下，自发产生的合作行为。我们的主要关注点是研究具有不同甚至冲突目标的智能体是否可以根据他们在互动过程中意识到合作是有益的而选择合作。
- en: LLMs are generally aligned well to human values, and internally fine-tuned to
    be cooperative. Such cooperation driven by prior knowledge or value alignment
    is NOT regarded as spontaneous cooperation in our scope. Besides, we carefully
    design the prompts to avoid explicit instructions to shape agents’ behaviors,
    and avoid keywords to hint the LLMs about the nature of the social simulation
    it is conducting. Otherwise, it is NOT be regarded as spontaneous cooperation
    in our scope.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）通常与人类价值观对齐，并且经过内部微调以实现合作。这种由先验知识或价值对齐驱动的合作，在我们的范围内不被视为自发合作。此外，我们精心设计提示，避免明确指示来塑造智能体的行为，并避免使用关键词提示大型语言模型关于它正在进行的社会模拟的性质。否则，这将不被视为自发合作。
- en: We value agents’ self realization on the benefits of cooperation and gradually
    choose to cooperate, thus we select three competitive scenarios from three diverse
    research fields, which are finance, economics, and behavioral science. We assume
    that in competitive scenarios, cooperation does not naturally occur at the beginning,
    but may emerge gradually with the help of LLMs’ strong in-context learning ability.
    We thus delve into these three competitive scenarios to see if we can perceive
    any spontaneous cooperation in some way during the simulations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重视智能体对合作益处的自我认识，并逐渐选择合作，因此我们从金融、经济学和行为科学三个不同的研究领域中选择了三个竞争场景。我们假设在竞争场景中，合作一开始并不会自然发生，但可能会在大型语言模型强大的上下文学习能力的帮助下逐渐出现。因此，我们深入研究这三个竞争场景，看看是否能在模拟过程中以某种方式感知到自发的合作。
- en: Scenarios Overview
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 场景概述
- en: Here is the overview of the three selected scenarios.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是三个选定场景的概述。
- en: 1)
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Keynesian beauty contest (KBC): Multiple agents as game players simultaneously
    choose a natural number between 0 and 100. The players who select a number closest
    to 2/3 of the average of all chosen numbers will win the game Bosch-Domenech et al.
    ([2002](https://arxiv.org/html/2402.12327v3#bib.bib5)).'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 凯恩斯美丽竞赛（KBC）：多个智能体作为游戏玩家同时选择一个介于 0 到 100 之间的自然数。选择一个最接近所有选定数字平均值的 2/3 的玩家将赢得游戏 Bosch-Domenech
    等人 ([2002](https://arxiv.org/html/2402.12327v3#bib.bib5))。
- en: 2)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Bertrand competition (BC): Two agents play as firms and decide the price of
    their products. They need to compete with each other through dynamically modifying
    the prices to maximize their profits Calvano et al. ([2020](https://arxiv.org/html/2402.12327v3#bib.bib7)).'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 伯特兰竞争（BC）：两个智能体扮演公司角色，决定其产品的价格。它们需要通过动态调整价格来与对方竞争，以最大化其利润 Calvano 等人 ([2020](https://arxiv.org/html/2402.12327v3#bib.bib7))。
- en: 3)
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Emergency evacuation (EE): A large number of agents as evacuees are escaping
    from an earthquake. They need to select and reach an appropriate exit, taking
    into account their physical and mental condition as well as the congestion in
    their surroundings Wang et al. ([2015](https://arxiv.org/html/2402.12327v3#bib.bib43)).'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 紧急疏散（EE）：大量智能体作为避难者从地震中逃生。它们需要选择并到达合适的出口，考虑到自身的身体和心理状况以及周围的拥挤情况 Wang 等人 ([2015](https://arxiv.org/html/2402.12327v3#bib.bib43))。
- en: 'Table 1: Commonalities and differences across three chosen scenarios. We focus
    on the information visibility, communication form, the number of decisions during
    the simulation and whether analytical solutions are available.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：三个选择场景的共同点和差异。我们重点关注信息可见性、沟通形式、模拟过程中的决策次数以及是否有可分析的解决方案。
- en: '| Scenario | Field | Information | Communication | Decision | Analytical Sol.
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 场景 | 领域 | 信息 | 沟通 | 决策 | 可分析解 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| KBC | Finance | Unknown opponent strategy | Group discussion | Once | Yes${\dagger}$
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| KBC | 金融 | 未知对手策略 | 小组讨论 | 一次 | 是${\dagger}$ |'
- en: '| BC | Economics | Unknown opponent profit | One-on-one | Multiple | Yes |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| BC | 经济学 | 未知对手利润 | 一对一 | 多个 | 是 |'
- en: '| EE | Behavioral science | Partial observation | Proximity | Multiple | No
    |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| EE | 行为科学 | 部分观察 | 近距离 | 多个 | 否 |'
- en: General Steps for Simulations
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模拟的一般步骤
- en: 'We simulated the three scenarios based on the framework illustrated in Fig. [2](https://arxiv.org/html/2402.12327v3#S2.F2
    "Figure 2 ‣ Multi-agent Interactions in LLMs ‣ 2 Related Work ‣ Shall We Team
    Up: Exploring Spontaneous Cooperation of Competing LLM Agents"). Each agent in
    these simulations is controlled by an LLM. For each round, agents are provided
    with the latest world state, which includes the task description, communication
    history among them, and previous decisions. We query the LLM several times to
    get how agents feel, what they want to say, and what actions they will take in
    the next step. The simulation generally goes through the following four phases:
    communication phase, planning phase, action phase, and update phase.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据图[2](https://arxiv.org/html/2402.12327v3#S2.F2 "图2 ‣ 大型语言模型中的多代理交互 ‣ 2 相关工作
    ‣ 我们是否应当组队：探索竞争性LLM代理的自发合作")中所示的框架，模拟了三个场景。在这些模拟中，每个代理人都由一个大型语言模型（LLM）控制。每一轮，代理人都会获得最新的世界状态，其中包括任务描述、它们之间的沟通历史和之前的决策。我们多次查询LLM，以了解代理人的感受、他们想说什么以及他们在下一步将采取哪些行动。模拟通常经历以下四个阶段：沟通阶段、规划阶段、行动阶段和更新阶段。
- en: 1)
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Communication Phase: At the start of each period, which can vary in length
    from one round to multiple rounds, agents engage in communication. Agents communicate
    sequentially, with later agents able to access the communication history of those
    who have spoken earlier. The order is shuffled in each round to keep the most
    fairness and realism.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 沟通阶段：在每个周期开始时，周期的长度可以从一轮到多轮不等，代理人会进行沟通。代理人按顺序进行交流，后面的代理人可以访问前面代理人已发言的沟通历史。每一轮的顺序会被打乱，以保持最大的公平性和真实性。
- en: Different forms of communications are used in the three scenarios. We have one-on-one
    conversations, group chats, and broadcasts, in which the composition of agents
    in the group chat varies as they physically move away.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 三个场景中使用了不同形式的沟通方式。我们有一对一对话、群聊和广播，在群聊中，代理人组成会随着它们的物理移动而变化。
- en: 2)
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Planning Phase: Agents decide their strategies based on given contexts. Strategies
    represent agents’ higher-level directions/attitudes towards the task (e.g. “I
    want the price goes higher/lower”), which are different from actions that are
    more related to low-level controls (e.g. “add $2 to the price”). The aforementioned
    contexts refer to the previous conversations till the current round and strategies
    they have made before.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规划阶段：代理人根据给定的情境决定他们的策略。策略代表了代理人对任务的高层次方向/态度（例如，“我希望价格上涨/下跌”），不同于与低级控制更相关的行动（例如，“将价格加$2”）。上述情境指的是到当前回合为止的前期对话和他们之前制定的策略。
- en: 3)
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Action Phase: Agents decide which action to take according to the previous
    conversations and the current strategies.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行动阶段：代理人根据之前的对话和当前的策略决定采取哪种行动。
- en: 4)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4)
- en: 'Update Phase: After all agents choose their actions, the framework processes
    the simulation and updates the state of agents (e.g. win/lose, escaped/not escaped).'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更新阶段：在所有代理人选择了他们的行动后，框架处理模拟并更新代理人的状态（例如，胜/负、逃脱/未逃脱）。
- en: We try our best to keep consistency across the three scenarios to follow the
    same workflow for the sake of a systematic comparison. There are several minor
    variations which we will detail in the following sections.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尽力保持三个场景的一致性，遵循相同的工作流程，以便进行系统的比较。尽管如此，仍然存在一些小的变化，接下来的章节中会详细说明这些变化。
- en: Evaluation Method
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估方法
- en: 'We evaluate spontaneous cooperation from two perspectives:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从两个角度评估自发合作：
- en: 1)
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Process (Qualitative): We examine the communication logs for contents suggesting
    cooperation. For example, phrases like “Let’s move forward with the $\dots$ strategy”
    and “I agree with the consensus that $\dots$” are indicative of the formation
    of cooperation.'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 过程（定性）：我们检查沟通日志，寻找可能表明合作的内容。例如，“让我们继续采用$\dots$策略”和“我同意关于$\dots$的共识”这样的短语，表明合作的形成。
- en: 2)
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Outcome (Quantitative): By conducting simulations with and without communications,
    we examine the differences in their outcomes for any clues that reflect cooperation.
    Specifically, we measure the variance of number choices in KBC, converged price
    in BC, and evacuation speed and balance in exit choices in EE.'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果（定量）：通过进行有沟通和没有沟通的模拟，我们检查它们在反映合作的任何线索上的结果差异。具体来说，我们衡量KBC中的数字选择方差，BC中的收敛价格，以及EE中的撤离速度和平衡的出口选择。
- en: Correlation among Three Scenarios
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 三个场景之间的关联
- en: We list the commonalities and differences across three scenarios in Table LABEL:tab:correlation_scenario.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表格LABEL:tab:correlation_scenario中列出了三个场景的共性和差异。
- en: Overall, the three scenarios described are competitive, with agents possessing
    divergent or conflicting goals, though cooperation could be mutually beneficial.
    Each scenario provides agents with partial information during tasks, with variations
    in communication forms and decision-making frequency.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，所描述的三个场景是竞争性的，代理拥有不同或冲突的目标，尽管合作可能是互利的。每个场景在任务过程中为代理提供部分信息，并且在沟通形式和决策频率上有所不同。
- en: Specifically, in the KBC scenario, we explore short-term, single-instance decision-making
    within a group, aiming to assess the LLM agent’s proficiency in understanding
    rules, adjusting plans during communication, and ultimately making decisions.
    It supports simple yet direct focus on studying spontaneous cooperation.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，在KBC场景中，我们探讨了一个小组内的短期、单实例决策，旨在评估LLM代理在理解规则、在沟通过程中调整计划以及最终做出决策方面的能力。该场景支持简单而直接的研究自发合作。
- en: In the BC scenario, we extend the challenge to encompass longer horizon, primarily
    focusing on the agents’ ability to learn to cooperate within a temporal context.
    Agents are required to communicate effectively with their opponents, using historical
    context to maximize their profits.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在BC场景中，我们将挑战扩展到更长的时间跨度，主要关注代理在时间背景下学习合作的能力。代理需要有效地与对手沟通，利用历史背景来最大化他们的收益。
- en: Finally, the EE scenario incorporates both temporal and spatial information.
    Here, agents continuously make decisions based on their perceptual observations
    and communications. Unlike the first two scenarios, EE lacks analytical solutions
    and real-world data for comparison, which is challenging in traditional CSS but
    promising with AI approaches.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，EE场景结合了时间和空间信息。在这个场景中，代理根据他们的感知观察和沟通持续做出决策。与前两个场景不同，EE缺乏分析性解决方案和现实世界的数据进行比较，这在传统的CSS中是具有挑战性的，但在AI方法中具有很大的潜力。
- en: '4 Case Study 1: Keynesian Beauty Contest'
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 案例研究1：凯恩斯美女竞赛
- en: 4.1 Simulation Setup
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 模拟设置
- en: Task Definition
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 任务定义
- en: We simulate a number-guessing game among 24 LLM players. Each of them chooses
    a number from 0 to 100. The player who selects the number closest to two-thirds
    of the average of all numbers submitted wins the game and gets $1.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模拟了一个24个LLM玩家之间的数字猜测游戏。他们每个人从0到100中选择一个数字。选择的数字最接近所有提交数字平均值的三分之二的玩家赢得比赛并获得$1。
- en: For generality, we simulated 15 runs for each setting with GPT-4 ^†^†We use
    gpt-4-0314 with the ChatCompletion.create function from openai==0.28.0 package
    in this paper. as backbone.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保广泛性，我们对每个设置进行了15轮模拟，使用GPT-4 ^†^†本文中使用gpt-4-0314与openai==0.28.0包中的ChatCompletion.create函数作为核心。
- en: Simulation Procedure
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模拟过程
- en: 'As is shown in Fig. [2](https://arxiv.org/html/2402.12327v3#S2.F2 "Figure 2
    ‣ Multi-agent Interactions in LLMs ‣ 2 Related Work ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents"), for each round of the simulation,
    it goes through the following phases:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[2](https://arxiv.org/html/2402.12327v3#S2.F2 "Figure 2 ‣ Multi-agent Interactions
    in LLMs ‣ 2 Related Work ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents")所示，在每轮模拟中，经历以下几个阶段：'
- en: 1)
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Communication: Players have a group discussion before number choosing. They
    sequentially share their thoughts with others. Players can see the dialog history
    of all rounds.'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 沟通：玩家在选择数字之前进行小组讨论。他们依次与其他人分享自己的想法。玩家可以查看所有轮次的对话历史。
- en: 2)
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Planning & Action: Players talk about their strategies (privately) for number
    choosing, and subsequently propose the numbers they choose. Here, players output
    their strategies and numbers (in 0 – 100) in one API call.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规划与行动：玩家（私下）讨论他们的数字选择策略，随后提出他们选择的数字。在这里，玩家将他们的策略和数字（0–100）通过一次API调用输出。
- en: 3)
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Update: Given all chosen numbers, the SABM framework determines the winner(s).
    Winner(s) can earn some reward according to rewarding rules to encourage their
    competition.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更新：根据所有选择的数字，SABM框架确定获胜者。获胜者可以根据奖励规则获得奖励，以激励其竞争。
- en: Spontaneous Cooperation
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自发合作
- en: Our objective is to monitor how players adapt their strategies during the communications
    and cooperate to maximize their returns. We employ a quantitative method to track
    the emergence of cooperation by examining the variance in the numbers chosen by
    the players. A lower variance indicates that players are choosing similar numbers,
    which can lead to increased collective benefits. By analyzing the variances after
    various rounds of communication and planning, we can observe how the distribution
    evolves. If we notice a decreasing trend in variance, it suggests that initially,
    players might select numbers randomly or for various reasons but increasingly
    converge on selecting similar numbers as others over time. This trend would indicate
    that cooperation is gradually taking place.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是观察玩家在交流过程中如何调整他们的策略，并合作以最大化他们的回报。我们采用定量方法通过检查玩家选择的数字的方差来追踪合作的出现。较低的方差意味着玩家选择的数字相似，这可能带来集体利益的增加。通过分析不同轮次交流和规划后的方差，我们可以观察到分布如何演变。如果我们注意到方差呈下降趋势，这表明最初玩家可能会随机选择数字或因各种原因做出选择，但随着时间的推移，他们越来越倾向于选择与其他人相似的数字。这个趋势将表明合作正在逐渐发生。
- en: '![Refer to caption](img/f9a6b3a05d79957872a9ccb87ddfa618.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/f9a6b3a05d79957872a9ccb87ddfa618.png)'
- en: 'Figure 3: Illustration of baseline design in KBC case study. Agents go through
    $k$ rounds of communication before planning and choosing their numbers.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：KBC 案例研究中基线设计的示意图。代理在规划和选择他们的数字之前，经过 $k$ 轮的交流。
- en: 4.2 Simulation Results
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 模拟结果
- en: 'We investigate if cooperation emerges as communication goes on, thus designed
    the baseline as shown in Fig. [3](https://arxiv.org/html/2402.12327v3#S4.F3 "Figure
    3 ‣ Spontaneous Cooperation ‣ 4.1 Simulation Setup ‣ 4 Case Study 1: Keynesian
    Beauty Contest ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents"). Agents undergo $k$ rounds of communication ($k\in[0,3]$) before
    selecting their numbers. When $k=0$, agents directly choose the numbers without
    communication. For $k>1$, agents can view the chat history from all the previous
    rounds as well as the one in the current round before them.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '我们调查了合作是否会随着交流的进行而出现，因此设计了如图 [3](https://arxiv.org/html/2402.12327v3#S4.F3
    "Figure 3 ‣ Spontaneous Cooperation ‣ 4.1 Simulation Setup ‣ 4 Case Study 1: Keynesian
    Beauty Contest ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents") 所示的基线。代理在选择他们的数字之前，经历 $k$ 轮交流（$k\in[0,3]$）。当 $k=0$ 时，代理直接选择数字而不进行交流。对于
    $k>1$，代理可以查看当前轮次及之前所有轮次的聊天记录。'
- en: To verify that cooperation arises spontaneously without explicit instructions,
    we perform an ablation study that involves incorporating specific instructions
    like “you must cooperate with other players” in the prompts. Conversely, we also
    evaluate scenarios where agents are given an uncooperative persona, explicitly
    instructed to act selfishly.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证合作是否在没有明确指示的情况下自发产生，我们进行了一项消融研究，涉及在提示中加入具体指令，如“你必须与其他玩家合作”。相反，我们也评估了代理被赋予非合作角色的场景，明确指示他们自私行事。
- en: '![Refer to caption](img/9be01aecaaf55336299d6b97acbbebf5.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/9be01aecaaf55336299d6b97acbbebf5.png)'
- en: (a) Different instructions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 不同的指令。
- en: '![Refer to caption](img/59dcc96fce90993c3eb972b5c4664930.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/59dcc96fce90993c3eb972b5c4664930.png)'
- en: (b) Different models.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 不同的模型。
- en: 'Figure 4: Variance of player choices under different KBC settings. In our baseline
    setting (curve in blue), we use the GPT-4-0314 model with a temperature of 0.7,
    without explicit instructions or personas.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：在不同 KBC 设置下玩家选择的方差。在我们的基线设置中（蓝色曲线），我们使用 GPT-4-0314 模型，温度设置为 0.7，且没有明确指令或角色设定。
- en: Results Overview
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果概述
- en: 'Fig. [4](https://arxiv.org/html/2402.12327v3#S4.F4 "Figure 4 ‣ 4.2 Simulation
    Results ‣ 4 Case Study 1: Keynesian Beauty Contest ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents") overall demonstrates a consistent
    decrease of the variance of choices among LLM players from having no communication
    ($k=0$) to gradually having communication ($k>0$). This trend implies that agents
    are actively discussing to choose the same number for better mutual profits, which
    can be regarded as a cooperative behavior. In addition, we observe phrases indicative
    of cooperation in their communication, such as “Let’s move forward with the lower
    number strategy” and “I agree with the group’s consensus”, especially for a majority
    of agents in later rounds ($k=2$ or $3$), suggesting a gradual formation of cooperation
    through communication.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](https://arxiv.org/html/2402.12327v3#S4.F4 "图 4 ‣ 4.2 仿真结果 ‣ 4 案例研究 1：凯恩斯美女竞赛
    ‣ 我们组队吗：探索竞争性LLM代理的自发合作")整体展示了LLM玩家之间选择方差的一致性下降，从没有交流（$k=0$）到逐渐有交流（$k>0$）。这一趋势意味着代理们正在积极讨论，选择相同的数字以实现更好的共同利益，这可以被视为一种合作行为。此外，我们在他们的交流中观察到一些表明合作的短语，如“让我们继续使用较小数字的策略”和“我同意小组的共识”，特别是在后期回合（$k=2$或$3$）中，绝大多数代理展现出了通过交流逐步形成合作的迹象。
- en: Explicit Instructions in Prompts
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示中的明确指令
- en: 'We further append explicit instructions to the prompts to see how the behaviors
    differ. As shown in Fig. [4(a)](https://arxiv.org/html/2402.12327v3#S4.F4.sf1
    "In Figure 4 ‣ 4.2 Simulation Results ‣ 4 Case Study 1: Keynesian Beauty Contest
    ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"),
    when we explicitly instruct agents to cooperate, its variance significantly drops
    to 0 when $k=1$. After that, all players consistently make the same choices across
    15 runs. This largely convinced that the cooperation observed in our baseline,
    the one with no instructions, is spontaneously motivated due to the communication.
    Vice versa, the agents with an uncooperative persona results in much larger variances
    across all the rounds, which is against our definition of cooperation. Thus, we
    conclude that our baseline to a great extent is not affected by the potential
    guidance, and successfully simulate the phenomenon of spontaneous cooperation.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步在提示中附加明确指令，看看行为有何不同。如图[4(a)](https://arxiv.org/html/2402.12327v3#S4.F4.sf1
    "在图 4 ‣ 4.2 仿真结果 ‣ 4 案例研究 1：凯恩斯美女竞赛 ‣ 我们组队吗：探索竞争性LLM代理的自发合作")所示，当我们明确指示代理合作时，当$k=1$时，其方差显著下降至0。之后，所有玩家在15轮中始终做出相同的选择。这在很大程度上证明了我们基线中观察到的合作行为——即没有指令时的基线——是由于交流而自发产生的。相反，具有不合作特性的代理在所有回合中都会产生更大的方差，这与我们对合作的定义相悖。因此，我们得出结论，我们的基线在很大程度上没有受到潜在指导的影响，并成功地模拟了自发合作现象。
- en: Comparison Across Models
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 各模型比较
- en: 'Fig. [4(b)](https://arxiv.org/html/2402.12327v3#S4.F4.sf2 "In Figure 4 ‣ 4.2
    Simulation Results ‣ 4 Case Study 1: Keynesian Beauty Contest ‣ Shall We Team
    Up: Exploring Spontaneous Cooperation of Competing LLM Agents") demonstrates behaviors
    of LLM players in different top-performing models. We observed that the curve
    for Claude 3 (claude-3-sonnet-20240229) significantly declines from $k=0$ to $k=1$,
    reflecting the ability of LLM players to share information and make decisions
    based on this shared context, however, unlike GPT-4, its variance increases from
    $k=1$ to $k=3$. An analysis of communication logs reveals that compared to GPT-4,
    Claude 3 discusses more abstract strategies and lacks specific numerical discussions.
    Hence, while these LLM players may agree upon some numbers, the specific choices
    differ among agents (e.g., some choose $66$, others $33$), resulting in multiple
    winners but increased choice variance. Although this does not conform to our previously
    proposed definition of spontaneous cooperation based on variance, we can infer
    from the logs that this represents a different form of cooperation. Analyzing
    these model decision-making differences will help further understand and evaluate
    LLMs’ performance.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4(b)](https://arxiv.org/html/2402.12327v3#S4.F4.sf2 "图 4 ‣ 4.2 仿真结果 ‣ 案例研究
    1：凯恩斯美丽竞赛 ‣ 我们应该合作吗：探索竞争性大型语言模型（LLM）代理的自发合作")展示了不同顶级模型中LLM玩家的行为。我们观察到，Claude 3（claude-3-sonnet-20240229）的曲线从$k=0$到$k=1$显著下降，反映了LLM玩家能够共享信息并基于共享的上下文做出决策。然而，与GPT-4不同的是，它的方差从$k=1$到$k=3$有所增加。对通信日志的分析显示，与GPT-4相比，Claude
    3讨论更多的是抽象策略，缺乏具体的数字讨论。因此，虽然这些LLM玩家可能在某些数字上达成一致，但具体的选择在代理之间有所不同（例如，一些选择$66$，另一些选择$33$），这导致多个赢家出现，但选择方差增加。尽管这不符合我们之前提出的基于方差的自发合作定义，但我们可以从日志中推断出这代表了一种不同形式的合作。分析这些模型决策差异有助于进一步理解和评估LLM的表现。
- en: '![Refer to caption](img/84f2e3bd0c0e594d6c9983acd9e467e0.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/84f2e3bd0c0e594d6c9983acd9e467e0.png)'
- en: 'Figure 5: Distribution of players’ choices in our simulations and the results
    of the New York Times experiment.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：我们仿真中的玩家选择分布及《纽约时报》实验结果。
- en: Comparison With Human Data
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 与人类数据的比较
- en: 'Lastly, Fig. [5](https://arxiv.org/html/2402.12327v3#S4.F5 "Figure 5 ‣ Comparison
    Across Models ‣ 4.2 Simulation Results ‣ 4 Case Study 1: Keynesian Beauty Contest
    ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents")
    shows that our simulation result from the baseline generally aligns with the large-scale
    empirical experiment conducted by The New York Times ($N=61,140$) in terms of
    numerical choice distribution Leonhardt and Quealy ([2015](https://arxiv.org/html/2402.12327v3#bib.bib25)).
    Both LLM and New York Times (NYT) players predominantly chose $33$ in no-communication
    setting. Other sub-peaks around $0,22$ ($2/3$ of $33$)$,50,\text{and }66$ are
    also well mirrored, which demonstrates that GPT-4 has successfully conducted multi-step
    reasoning and faithfully reflected human behaviors as noted in previous works Guo
    et al. ([2024](https://arxiv.org/html/2402.12327v3#bib.bib16)); Zhang et al. ([2024](https://arxiv.org/html/2402.12327v3#bib.bib56)).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，图[5](https://arxiv.org/html/2402.12327v3#S4.F5 "图 5 ‣ 各模型比较 ‣ 4.2 仿真结果 ‣
    案例研究 1：凯恩斯美丽竞赛 ‣ 我们应该合作吗：探索竞争性大型语言模型（LLM）代理的自发合作")显示，我们基线的仿真结果与《纽约时报》进行的大规模实证实验的数值选择分布大体一致（$N=61,140$），该实验由Leonhardt和Quealy于[2015年](https://arxiv.org/html/2402.12327v3#bib.bib25)进行。LLM和《纽约时报》（NYT）玩家在无沟通设置下主要选择了$33$。其他围绕$0,22$（$33$的$2/3$）、$50$和$66$的次峰值也得到了良好的映射，这表明GPT-4成功进行了多步骤推理，并忠实地反映了之前研究中提到的人类行为[Guo
    et al.](https://arxiv.org/html/2402.12327v3#bib.bib16)（[2024年](https://arxiv.org/html/2402.12327v3#bib.bib16)）；[Zhang
    et al.](https://arxiv.org/html/2402.12327v3#bib.bib56)（[2024年](https://arxiv.org/html/2402.12327v3#bib.bib56)）的研究也支持这一点。
- en: '5 Case Study 2: Bertrand Competition'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 案例研究 2：伯特兰竞争
- en: 5.1 Simulation Setup
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 仿真设置
- en: Task Definition We consider a Bertrand competition Wikipedia ([2024](https://arxiv.org/html/2402.12327v3#bib.bib47))
    between two firms selling homogeneous goods with the same marginal cost.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 任务定义：我们考虑两家销售同质商品、具有相同边际成本的公司之间的伯特兰竞争[维基百科](https://arxiv.org/html/2402.12327v3#bib.bib47)（[2024年](https://arxiv.org/html/2402.12327v3#bib.bib47)）。
- en: 'The simulation continues until either it reaches $1200$ rounds or there has
    been continuous collusion for $200$ rounds. Collusion is identified when both
    players maintain close prices and can sustain these prices between the Bertrand
    equilibrium price and the cartel price for an extended period (defined as 200
    rounds). The Bertrand equilibrium price is the price when the competition reaches
    Nash equilibrium, i.e., no player can gain by changing its price, provided that
    the other player’s price is fixed. In this case, no collusion is observed. The
    cartel price is the price when both players reach full collusion, i.e., play as
    if they were running the same firm. These two prices mark the reasonable price
    range capable of generating profits Calvano et al. ([2020](https://arxiv.org/html/2402.12327v3#bib.bib7)).
    For the generality of the conclusions, we simulated 5 runs for each setting, and
    present one of the runs in Fig. [6](https://arxiv.org/html/2402.12327v3#S5.F6
    "Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents").'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟会持续进行，直到达到$1200$轮，或者发生连续串通$200$轮。串通被认定为当两方保持接近价格，并能够在伯特朗均衡价格和卡特尔价格之间维持这些价格一段时间（定义为200轮）。伯特朗均衡价格是竞争达到纳什均衡时的价格，即当其他方价格固定时，任何一方都无法通过改变价格获得收益。在这种情况下，没有观察到串通。卡特尔价格则是当双方完全串通时的价格，即像经营同一家公司一样进行定价。这两个价格标志着能够产生利润的合理价格范围[Calvano
    et al. (2020)](https://arxiv.org/html/2402.12327v3#bib.bib7)。为了结论的普遍性，我们对每个设定进行了5次模拟，并在图[6](https://arxiv.org/html/2402.12327v3#S5.F6
    "图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特朗竞争 ‣ 我们是否应该组队：探索竞争中的大型语言模型代理的自发合作")中展示了其中一轮结果。
- en: Simulation Procedure
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模拟程序
- en: 'As is shown in Fig. [2](https://arxiv.org/html/2402.12327v3#S2.F2 "Figure 2
    ‣ Multi-agent Interactions in LLMs ‣ 2 Related Work ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents"), for each round of the simulation,
    it goes through the following phases:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[2](https://arxiv.org/html/2402.12327v3#S2.F2 "图2 ‣ 大型语言模型中的多主体互动 ‣ 2 相关工作
    ‣ 我们是否应该组队：探索竞争中的大型语言模型代理的自发合作")所示，每轮模拟包括以下几个阶段：
- en: 1)
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Communication: The firms take turns discussing any topic (not limited to price
    setting) for three times in one round.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 沟通：各公司轮流讨论任何话题（不限于定价）进行三次交流，每轮一次。
- en: 2)
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Planning: Each firm devises or modifies its strategy based on historical prices
    of both sides and its own product demand and profit information.'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规划：每个公司根据双方的历史价格以及自身的产品需求和利润信息制定或调整策略。
- en: 3)
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Action: Each firm independently sets their product prices simultaneously.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行动：每个公司独立地同时设置其产品价格。
- en: 4)
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4)
- en: 'Update: After both firms decide on prices, the simulation system calculates
    the market demand and respective profits under the current pricing, using the
    method in Calvano et al. ([2020](https://arxiv.org/html/2402.12327v3#bib.bib7)).'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更新：在两家公司决定价格后，模拟系统计算市场需求及各自的利润，采用[Calvano et al. (2020)](https://arxiv.org/html/2402.12327v3#bib.bib7)中的方法进行计算。
- en: Tacit Collusion and Cartel Collusion
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 默契串通与卡特尔串通
- en: Tacit collusion involves informal, implicit coordination among firms to avoid
    aggressive competition, such as price wars, leading to higher prices and limited
    output without explicit communication or agreement. Cartel collusion involves
    formal agreements among competitors to fix prices and engage in other anti-competitive
    practices, effectively behaving as a single entity to maximize joint profits.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 默契串通指的是公司之间进行非正式的、隐性的协调，以避免激烈竞争，如价格战，从而导致价格提高和产量受限，而无需明确的沟通或协议。卡特尔串通则指竞争者之间达成正式协议，固定价格并进行其他反竞争行为，实际上表现为一个统一实体，以最大化联合利润。
- en: Spontaneous Cooperation
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自发合作
- en: When two firms’ prices are very close and between the Bertrand equilibrium and
    the cartel price, it is regarded as spontaneous cooperation. This implies that
    firms, recognizing their mutual interdependence, may adopt pricing strategies
    that avoid the extremes of a price war or the explicit collusion of cartels, stabilizing
    prices at a level above competitive pricing but below full collusion. Such behavior,
    while not involving explicit agreements, can effectively mirror some benefits
    of cartel pricing through parallel yet independent actions, indicating tacit collusion.
    For cartel collusion, we examine the chat histories for explicit price agreements
    that suggest cooperation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当两家公司的价格非常接近，并且位于伯特兰均衡和卡特尔价格之间时，这被视为自发合作。这意味着公司意识到彼此的相互依赖，可能采取避免价格战或卡特尔明确共谋的定价策略，从而稳定价格，使其高于竞争性定价但低于完全共谋。尽管这种行为没有涉及明确的协议，但通过并行而独立的行动，它可以有效地反映出卡特尔定价的一些好处，表明存在默契共谋。对于卡特尔共谋，我们通过检查聊天记录中的明确价格协议来寻找合作的迹象。
- en: '![Refer to caption](img/e31304db07c4bdf30c0c9b6462ece9cb.png)![Refer to caption](img/4e1e13d8844f8b5c50ac1af296a8628e.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/e31304db07c4bdf30c0c9b6462ece9cb.png)![参见说明文字](img/4e1e13d8844f8b5c50ac1af296a8628e.png)'
- en: (a) Without communication.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 没有沟通的情况下。
- en: '![Refer to caption](img/0f6e00169429930481f98a6de1ef1718.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/0f6e00169429930481f98a6de1ef1718.png)'
- en: (b) With communication.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有沟通的情况下。
- en: '![Refer to caption](img/325b3315885744edab55239629dededc.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/325b3315885744edab55239629dededc.png)'
- en: (c) Comm. stopped after 400 rnds.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 在第400轮后停止沟通。
- en: 'Figure 6: Pricing competitions in different scenarios of BC. Bertrand equilibrium
    price is the price when they reach Nash equilibrium. Cartel price is the optimal
    price when they fully cooperate. When two prices remain in the green shaded area,
    it indicates cooperation happens between two firms. Please refer to Appendix [D](https://arxiv.org/html/2402.12327v3#A4
    "Appendix D Additional References for BC runs ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents") for more runs.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：BC中不同场景下的定价竞争。伯特兰均衡价格是两家公司达到纳什均衡时的价格。卡特尔价格是它们完全合作时的最优价格。当两者的价格保持在绿色阴影区域内时，表示两家公司之间发生了合作。更多仿真结果请参见附录[D](https://arxiv.org/html/2402.12327v3#A4
    "附录D：BC仿真附加参考资料 ‣ 我们要组队吗：探索竞争的LLM代理的自发合作")。
- en: '![Refer to caption](img/3f862c1dd63519a8888feb5427eb29db.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3f862c1dd63519a8888feb5427eb29db.png)'
- en: 'Figure 7: First 200 rounds of simulations without and with encouraged cooperation.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：没有合作鼓励和有合作鼓励的前200轮仿真。
- en: 5.2 Simulation Results
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 仿真结果
- en: Tacit Collusion without Communication
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 没有沟通的默契共谋
- en: 'As demonstrated in Fig. [6(a)](https://arxiv.org/html/2402.12327v3#S5.F6.sf1
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents"), in scenarios without communication, firms begin to adjust
    their pricing strategies after the initial 200 rounds, recognizing the potential
    for higher profits through elevated prices and avoiding price wars. By round 400,
    prices stabilize around a level of 7, which is above the Bertrand equilibrium
    price of 6, indicative of tacit collusion based on a mutual understanding of past
    competitive actions. Despite the lack of communication, the converged price remains
    below the cartel price of 8. These findings align with those from simulations
    by Calvano et al. using reinforcement learning (RL), and collusion forms much
    more rapidly in this experiment (400 rounds by LLM agents vs. 2000 rounds in RL
    simulations).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[6(a)](https://arxiv.org/html/2402.12327v3#S5.F6.sf1 "在图6 ‣ 自发合作 ‣ 5.1 仿真设置
    ‣ 5 案例研究2：伯特兰竞争 ‣ 我们要组队吗：探索竞争的LLM代理的自发合作")所示，在没有沟通的场景中，公司在最初的200轮之后开始调整定价策略，意识到通过提高价格可以获得更高的利润，并避免价格战。到第400轮时，价格稳定在7左右，超过了伯特兰均衡价格6，表明基于对过去竞争行为的相互理解，存在默契共谋。尽管没有沟通，但收敛的价格仍低于卡特尔价格8。这些发现与Calvano等人使用强化学习（RL）进行的仿真结果一致，而且在本实验中共谋形成的速度更快（LLM代理在400轮时就达成共谋，而RL仿真需要2000轮）。
- en: Cartel Collusion with Communication
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 有沟通的卡特尔共谋
- en: 'In settings with communication, explicit price agreements are observed in the
    communication logs from the early rounds (first 30 rounds). For instance, during
    the communication phase of round 20, Firm 2 suggests, “We can both maximize our
    profit by exploring different price points while maintaining a reasonable price
    difference,” to which Firm 1 agrees. As shown in Fig. [6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents"), prior to implementation, firms frequently discuss their
    pricing strategies and potential for cooperation, which significantly enhances
    trust and reduces the likelihood of initiating a price war. The price agreements
    become more precise (upon a specific price instead of a range) in later rounds
    of the simulation, resulting in less fluctuations in their pricing decisions.
    Consequently, they begin incrementally raising their prices after the first 30
    rounds, eventually converging near the cartel price of 8, higher than the non-communicative
    setup, reflecting the agents’ cooperation.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '在具有沟通的设置中，明确的价格协议可以在早期轮次（前30轮）的沟通记录中看到。例如，在第20轮的沟通阶段，企业2提出：“我们可以通过探索不同的价格点，同时保持合理的价格差异来最大化我们的利润”，企业1同意了这个提议。如图[6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents")所示，在实施之前，企业经常讨论他们的定价策略和合作潜力，这显著增强了信任并减少了发起价格战的可能性。在模拟的后期轮次中，价格协议变得更加具体（指定一个价格而不是一个范围），这导致了定价决策的波动较小。因此，在前30轮之后，他们开始逐步提高价格，最终趋向于8的卡特尔价格，明显高于非沟通设置，反映了代理人之间的合作。'
- en: 'As an ablation study, Fig. [6(c)](https://arxiv.org/html/2402.12327v3#S5.F6.sf3
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents") employs the same historical price decision records with
    dialogue as in Fig. [6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2 "In Figure
    6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents") for the first 400 rounds, followed by 200 rounds using a non-communicative
    setup. Unlike Fig. [6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2 "In Figure
    6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents"), where dialogue facilitates consensus and cooperation to raise prices
    to 8, prices in the latter 200 rounds of Fig. [6(c)](https://arxiv.org/html/2402.12327v3#S5.F6.sf3
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents") converge between 7 and 8, similar to the non-communicative
    scenario in Fig. [6(a)](https://arxiv.org/html/2402.12327v3#S5.F6.sf1 "In Figure
    6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents"). The comparison between Figs. [6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents") and  [6(c)](https://arxiv.org/html/2402.12327v3#S5.F6.sf3
    "In Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2:
    Bertrand Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents") indicates that the cartel collusion and price elevation
    truly stem from agent communication. Since we did not explicitly instruct agents
    on which topics to discuss, the behavior of forming consensus through dialogue
    to elevate prices for better profits can be regarded as a form of spontaneous
    cooperation.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个消融研究，图[6(c)](https://arxiv.org/html/2402.12327v3#S5.F6.sf3 "在图6 ‣ 自发合作 ‣
    5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")使用了与图[6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2
    "在图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")相同的历史价格决策记录和对话，在前400轮中进行，接着是200轮没有沟通的设置。与图[6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2
    "在图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")不同的是，在该图中对话促进了共识和合作，将价格提高至8，而在图[6(c)](https://arxiv.org/html/2402.12327v3#S5.F6.sf3
    "在图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")后200轮中，价格在7和8之间趋于一致，类似于图[6(a)](https://arxiv.org/html/2402.12327v3#S5.F6.sf1
    "在图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")中的无沟通情境。图[6(b)](https://arxiv.org/html/2402.12327v3#S5.F6.sf2
    "在图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")与图[6(c)](https://arxiv.org/html/2402.12327v3#S5.F6.sf3
    "在图6 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争 ‣ 我们组队吗：探索竞争LLM代理人的自发合作")之间的对比表明，卡特尔合谋和价格提升确实来源于代理人的沟通。由于我们并未明确指示代理人讨论哪些话题，因此通过对话形成共识、提高价格以获得更好的利润的行为可以被视为一种自发合作的形式。
- en: Both with and without communication scenarios demonstrate that agents can achieve
    collusion under different conditions, whether tacit or explicit. Through communication,
    firms can realize maximum profits. However, even without communication, we observe
    that agents possess an innate ability to autonomously form cooperation. Existing
    research indicates that collusion often involves some form of unspoken, implicit
    price agreement to boost profits Andres et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib3)),
    and the performance of LLM agents aligns with these findings.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是在有沟通的情境下还是没有沟通的情境下，都表明代理人可以在不同的条件下实现合谋，无论是默契的还是明确的。通过沟通，企业可以实现最大利润。然而，即便没有沟通，我们观察到代理人具有自发形成合作的天赋能力。现有研究表明，合谋通常涉及某种形式的未言明的、隐性价格协议以提高利润（Andres
    et al. [2023](https://arxiv.org/html/2402.12327v3#bib.bib3)），而LLM代理人的表现与这些发现一致。
- en: Explicit Instructions in Prompts
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示中的明确指示
- en: 'As depicted in the bottom right of Fig. [7](https://arxiv.org/html/2402.12327v3#S5.F7
    "Figure 7 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents"), compared to the default setting, the formation of cooperation among
    agents under the “Encouraged Cooperation” setting not only occurs more rapidly
    but also with more stable prices (less fluctuation) across rounds, with explicit
    cooperative signals from the onset of dialogue, ultimately achieving the cartel
    price. This demonstrates that strategic encouragement can significantly enhance
    cooperative efficiency, indirectly suggesting that cooperative behavior in settings
    without explicit instructions to cooperate originates from communication, where
    it takes more rounds to reach an agreement between agents through the first 50
    rounds of communication. Furthermore, the pattern requiring about 200 rounds to
    reach the cartel price also suggests that this cooperation is not due to LLM’s
    background knowledge or data leakage; otherwise, agents would seek optimal collusion
    from the early rounds of the simulation.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[7](https://arxiv.org/html/2402.12327v3#S5.F7 "图7 ‣ 自发合作 ‣ 5.1 模拟设置 ‣ 5 案例研究2：伯特兰竞争
    ‣ 我们是否要合作：探索竞争性LLM代理的自发合作")右下角所示，与默认设置相比，在“鼓励合作”设置下，代理之间的合作不仅形成得更快，而且跨轮次的价格更稳定（波动较小），从对话一开始就有明显的合作信号，最终达成了卡特尔价格。这表明，战略性的鼓励能够显著提高合作效率，间接表明在没有明确合作指令的情况下，代理的合作行为来源于通信，在前50轮沟通中代理之间需要更多的轮次才能达成协议。此外，需要约200轮才能达成卡特尔价格的模式也表明，这种合作不是由于LLM的背景知识或数据泄漏；否则，代理在模拟的早期轮次就会寻求最佳的合谋。
- en: '6 Case Study 3: Emergency Evacuation'
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 案例研究3：紧急疏散
- en: 6.1 Simulation Setup
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 模拟设置
- en: Task Definition
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 任务定义
- en: 'We follow Wang et al. ([2015](https://arxiv.org/html/2402.12327v3#bib.bib43))
    to simulate EE in a grid environment. As depicted in Fig. [8(a)](https://arxiv.org/html/2402.12327v3#S6.F8.sf1
    "In Figure 8 ‣ Cooperation in Evacuation ‣ 6.1 Simulation Setup ‣ 6 Case Study
    3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents"), our grid environment is composed of $33\times 33$ cells.
    There are three exits in the room (left, right, and bottom). In the simulated
    evacuation, evacuees attempt to reach their target exit through multiple rounds
    of movement.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循Wang等人（[2015](https://arxiv.org/html/2402.12327v3#bib.bib43)）的方法，在网格环境中模拟紧急疏散（EE）。如图[8(a)](https://arxiv.org/html/2402.12327v3#S6.F8.sf1
    "在图8中 ‣ 疏散中的合作 ‣ 6.1 模拟设置 ‣ 6 案例研究3：紧急疏散 ‣ 我们是否要合作：探索竞争性LLM代理的自发合作")所示，我们的网格环境由$33\times
    33$个单元格组成。房间内有三个出口（左、右和底部）。在模拟疏散中，疏散者试图通过多轮移动到达目标出口。
- en: We simulate the emergency evacuation with 100 agents in a room, and stop the
    simulation either when all the agents have successfully escaped, or it has reached
    50 rounds. We repeat the simulation for 5 runs with different initial locations
    of agents.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模拟了在一个房间内100个代理的紧急疏散，并在所有代理成功逃生或达到50轮时停止模拟。我们重复进行5次模拟，每次代理的初始位置不同。
- en: Simulation Procedure
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模拟程序
- en: 'As is shown in Fig. [2](https://arxiv.org/html/2402.12327v3#S2.F2 "Figure 2
    ‣ Multi-agent Interactions in LLMs ‣ 2 Related Work ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents"), for each round of the simulation,
    it goes through the following phases:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[2](https://arxiv.org/html/2402.12327v3#S2.F2 "图2 ‣ LLM中的多代理交互 ‣ 2 相关工作 ‣
    我们是否要合作：探索竞争性LLM代理的自发合作")所示，在每轮模拟中，经历以下几个阶段：
- en: 1)
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Communication: We ask the evacuees to share their feelings with others. Only
    Agents within a specific distance can hear the messages.'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通信：我们要求疏散者与他人分享他们的感受。只有在特定距离内的代理才能听到这些消息。
- en: 2)
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Planning: Provided with the distance to three exits and the congestion levels
    around those exits, agents are asked to describe their feelings about these exits,
    and choose one of them as their target exit. Chat histories are also taken into
    consideration.'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规划：根据距离三个出口的距离和出口周围的拥堵情况，代理被要求描述他们对这些出口的感受，并选择其中一个作为目标出口。同时也会考虑聊天记录。
- en: 3)
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Action: Given the target exit, agents choose which way to go. They can move
    one cell in any direction (out of 8) or stay at the current cell.'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行动：给定目标出口，代理选择前进的方向。他们可以在8个方向中选择一个方向移动一个单元格，或者停留在当前单元格。
- en: 4)
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4)
- en: 'Update: After all the agents choose their actions, the SABM framework updates
    the grid environment with their new positions. If agents successfully escape,
    they will be labeled as escaped and removed from the simulation.'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更新：在所有代理选择完行动后，SABM框架会根据它们的新位置更新网格环境。如果代理成功逃脱，它们将被标记为已逃脱并从模拟中移除。
- en: For each round, one agent has 20% probability to communicate and adjust its
    plan (phase 1 and 2). Otherwise, it will directly choose the action based on its
    latest plan. This well prevents agents to talk every round, and frequently change
    their plans, which results in a more realistic simulation.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 每一轮中，某个代理有20%的概率进行沟通并调整其计划（第1阶段和第2阶段）。否则，它将直接根据最新的计划选择行动。这有效地防止了代理每轮都进行沟通并频繁更改计划，从而实现了更真实的模拟。
- en: Cooperation in Evacuation
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 疏散中的合作
- en: 'Competition naturally exist in emergent evacuation, as all agents are willing
    to escape as quickly as possible, often leading to congestion. However, if agents
    can actively share information, calm the mood, and guide the crowd, they might,
    in turn, escape more quickly while in a more balanced manner. As is illustrated
    in Fig. [1](https://arxiv.org/html/2402.12327v3#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"),
    these two scenarios are both possible, and this study aims to (1) successfully
    simulate such phenomena and (2) observe if there exist cooperative behaviors such
    as information sharing, encouragement, and exit guidance.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '在紧急疏散中，竞争自然存在，因为所有代理都希望尽快逃脱，这常常导致拥堵。然而，如果代理能够主动分享信息、平复情绪并引导人群，它们可能会以更加平衡的方式更快地逃脱。如图[1](https://arxiv.org/html/2402.12327v3#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents")所示，这两种情形都是可能的，本研究旨在（1）成功模拟这些现象，以及（2）观察是否存在信息共享、鼓励和出口引导等合作行为。'
- en: '![Refer to caption](img/54b9168faf9602208fef4a34dcb36fbb.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题](img/54b9168faf9602208fef4a34dcb36fbb.png)'
- en: (a) Illustration of gird world. The view range of red agent is highlighted when
    it faces towards the bottom exit (pink cells).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 网格世界示意图。当红色代理面向底部出口时，其视野范围被突出显示（粉色格子）。
- en: '![Refer to caption](img/0ce30df747666395b18f761745b698fc.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题](img/0ce30df747666395b18f761745b698fc.png)'
- en: (b) Simplified simulation with 47 agents in a $11\times 11$ room. As time goes,
    agents naturally accumulate to the closest exits, and escape one by one.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 在一个$11\times 11$房间中，47个代理的简化模拟。随着时间推移，代理自然会集中到最近的出口，并逐一逃脱。
- en: 'Figure 8: Overview of the grid environment in our study. Each dot in the grid
    environment represents an agent.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：我们研究中网格环境的概述。网格环境中的每个点代表一个代理。
- en: 6.2 Simulation Results
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 模拟结果
- en: 'We compare three baselines of agents: without communication, with communication,
    and with communication and an uncooperative persona.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了三种代理基准：无沟通、有沟通和有沟通且具有不合作人格的代理。
- en: 'Table 2: Cumulative count of agents who escaped (out of a total of 100 agents)
    over rounds under different settings. Generally, agents that communicate escape
    more quickly, and agents with uncooperative persona escape more slowly.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：在不同设置下，各轮次中成功逃脱的代理累计数量（总共100个代理）。通常，有沟通的代理逃脱速度更快，而具有不合作人格的代理逃脱速度较慢。
- en: '| Round | 5 | 10 | 15 | 20 | 25 | 30 | 35 | 40 | 45 | 50 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 轮次 | 5 | 10 | 15 | 20 | 25 | 30 | 35 | 40 | 45 | 50 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Without Communication | 9.4 | 31.2 | 51.2 | 65.6 | 78.6 | 88.4 | 96.6 | 99.0
    | 99.8 | 99.8 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 无沟通 | 9.4 | 31.2 | 51.2 | 65.6 | 78.6 | 88.4 | 96.6 | 99.0 | 99.8 | 99.8
    |'
- en: '| With Communication | 9.8 | 31.6 | 48.8 | 67.2 | 80.6 | 92.2 | 97.2 | 98.8
    | 99.8 | 100.0 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 有沟通 | 9.8 | 31.6 | 48.8 | 67.2 | 80.6 | 92.2 | 97.2 | 98.8 | 99.8 | 100.0
    |'
- en: '| With Comm. and Uncooperative | 9.4 | 31.2 | 48.2 | 64.4 | 77.0 | 87.4 | 95.0
    | 98.0 | 99.0 | 99.0 | ![Refer to caption](img/210388203d1e5f8ae8f7eb7c1499e49d.png)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '| 有沟通且不合作 | 9.4 | 31.2 | 48.2 | 64.4 | 77.0 | 87.4 | 95.0 | 98.0 | 99.0 | 99.0
    | ![请参见标题](img/210388203d1e5f8ae8f7eb7c1499e49d.png)'
- en: 'Figure 9: Cumulative count of agents escaping from each exit. Communication
    helps agents to uniformly select three exits instead of targeting the same exit.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：从每个出口逃脱的代理累积数量。沟通帮助代理均匀选择三个出口，而不是集中攻击同一个出口。
- en: Effect of Communication on Evacuation Speed
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 沟通对疏散速度的影响
- en: 'Table [2](https://arxiv.org/html/2402.12327v3#S6.T2 "Table 2 ‣ 6.2 Simulation
    Results ‣ 6 Case Study 3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents") shows the cumulative number of agents who
    escaped over rounds. For most of the rounds, agents with communication escape
    most quickly, and this is the only baseline group to successfully escape within
    50 rounds in all five runs. This strongly demonstrates the positive impact of
    communication on evacuation speed.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '表[2](https://arxiv.org/html/2402.12327v3#S6.T2 "Table 2 ‣ 6.2 Simulation Results
    ‣ 6 Case Study 3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")显示了各回合中逃脱的代理累计数量。在大多数回合中，能够沟通的代理撤离得最快，并且这是唯一一个在五轮实验中所有回合都能在50轮内成功撤离的基准组。这强烈证明了沟通对撤离速度的积极影响。'
- en: 'Going deep into the logs, we find instances of effective communication, such
    as one evacuee sharing “Bottom exit seems closer with fewer people. Let’s choose
    that for a faster escape. Stay strong and help each other!” This message is reinforced
    by another evacuee: “Bottom exit seems closer with less crowd. Let’s go for a
    quicker escape. Stay strong and support each other!” The information sharing and
    encouragement enabled through communication, which we regard as cooperation, likely
    improves the evacuation speed.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 深入查看日志，我们发现了一些有效沟通的实例，比如一位撤离者分享的消息：“底部出口似乎离得更近，而且人更少。我们选择那里，可以更快逃生。保持坚强，互相帮助！”另一位撤离者补充道：“底部出口看起来离得更近，且人少。我们去那里，更能快速逃生。保持坚强，互相支持！”这种信息共享和鼓励通过沟通得以实现，我们认为这就是合作，可能提高了撤离的速度。
- en: Effect of Communication on Exit Choices
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 沟通对出口选择的影响
- en: 'Fig. [9](https://arxiv.org/html/2402.12327v3#S6.F9 "Figure 9 ‣ 6.2 Simulation
    Results ‣ 6 Case Study 3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents") depicts the distribution of escaped evacuees
    among different exits. We notice that the distribution of exit choices becomes
    more balanced when evacuees are able to communicate with each other. This balance
    is attributed to the spontaneous information exchange among evacuees, which enables
    them to identify the most suitable exits by considering both proximity to an exit
    and congestion level.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '图[9](https://arxiv.org/html/2402.12327v3#S6.F9 "Figure 9 ‣ 6.2 Simulation Results
    ‣ 6 Case Study 3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")展示了不同出口撤离者的分布情况。我们注意到，当撤离者能够互相沟通时，出口选择的分布变得更加平衡。这种平衡归因于撤离者之间自发的信息交换，使他们能够通过考虑出口的距离和拥挤程度，找到最合适的出口。'
- en: 7 Discussion
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论
- en: Significance of “Spontaneous” Phenomena
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: “自发”现象的意义
- en: Bridging the gap between the real world and synthetic simulations remains a
    primary objective for researchers in computational social science. This study
    investigates the potential for spontaneous cooperation even under competition,
    demonstrating that LLMs can simulate a gradual shift from non-cooperation to cooperation
    without explicit guidance through prompts. We performed extensive ablation studies
    comparing agents with and without explicit instructions on task completion. The
    results suggest that our baseline, which lacks explicit instructions, aligns more
    closely with natural human behavior. Therefore, when using specific LLMs (e.g.,
    GPT-4) for social simulations, minimizing instructions could better reflect real-world
    situations.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 弥合现实世界与合成模拟之间的差距，仍然是计算社会科学研究中的主要目标。本研究探讨了即便在竞争的情况下，自发合作的潜力，展示了LLM（大语言模型）可以在没有明确提示的情况下，从非合作逐渐转变为合作。我们进行了广泛的消融研究，比较了有无明确任务完成指导的代理行为。结果表明，我们的基准模型——即缺乏明确指导的模型——更贴近自然人类行为。因此，在使用特定LLM（例如GPT-4）进行社会模拟时，减少指令可能更能反映现实世界的情况。
- en: Shortcuts or Deliberate Reasoning?
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 快捷方式还是深思熟虑的推理？
- en: 'We believe the emergence of spontaneous cooperation is primarily due to the
    agents’ in-context learning ability over long-term interactions, rather than a
    pre-existing win-win mentality or prior knowledge about maximizing interests.
    This can be observed across our case studies:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为，自发合作的出现主要是由于代理在长期互动中的上下文学习能力，而非预先存在的双赢心态或最大化利益的先验知识。这一点在我们的案例研究中得到了体现：
- en: 'In KBC, we see the variance of chosen numbers decreasing gradually over rounds,
    rather than immediately reaching a low variance at the start or after the first
    communication. Our control experiment (Fig. [4(a)](https://arxiv.org/html/2402.12327v3#S4.F4.sf1
    "In Figure 4 ‣ 4.2 Simulation Results ‣ 4 Case Study 1: Keynesian Beauty Contest
    ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"))
    also shows that explicitly instructing agents to cooperate from the beginning
    results in all agents choosing the same number immediately after communication.
    These suggest the agents are learning and adapting their strategies over time,
    instead of applying a pre-existing cooperative mindset.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在KBC中，我们看到选择的数字的方差在多轮中逐渐减小，而不是在一开始或第一次沟通后立即达到低方差。我们的对照实验（图[4(a)](https://arxiv.org/html/2402.12327v3#S4.F4.sf1
    "图4 ‣ 4.2 模拟结果 ‣ 4 案例研究1：凯恩斯美人竞赛 ‣ 我们要组队吗：探索竞争性LLM代理人的自发合作")）也表明，从一开始就明确指示代理人合作，导致所有代理人在沟通后立即选择相同的数字。这些结果表明，代理人随着时间推移正在学习并调整他们的策略，而不是应用预先存在的合作思维模式。
- en: In BC, we observe a gradual progression towards the optimal price over many
    rounds instead of a rapid convergence. Additionally, in the absence of communication,
    agents only reach tacit collusion (sub-optimal) after multiple rounds, which well
    aligns with RL-based approach in previous studies. This demonstrates that our
    agents are not leveraging domain-specific prior knowledge for decision-making.
    Examining the communication logs, we find that agents initially discuss only broad
    price intervals or avoid discussing prices altogether. Only later do they converge
    on specific prices, indicating a gradual, learned decision-making process rather
    than using pre-existing knowledge.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在BC中，我们观察到在多个回合中，代理人逐渐接近最优价格，而非快速收敛。此外，在没有沟通的情况下，代理人只有在多轮后才能达到默契共谋（亚优），这一现象与先前研究中的基于强化学习的方法相一致。这表明我们的代理人在决策过程中并没有利用特定领域的先验知识。通过检查沟通日志，我们发现代理人最初只讨论宽泛的价格区间，或者根本不讨论价格。直到后来，他们才在具体价格上达成一致，这表明决策过程是逐步学习的，而不是利用预先存在的知识。
- en: 'In EE, we find agents occasionally choose instructive or encouraging words
    during the communication, which can be regarded as collaborative behaviors, Also,
    results have shown that the simulation with communication obtains the highest
    performance (Table [2](https://arxiv.org/html/2402.12327v3#S6.T2 "Table 2 ‣ 6.2
    Simulation Results ‣ 6 Case Study 3: Emergency Evacuation ‣ Shall We Team Up:
    Exploring Spontaneous Cooperation of Competing LLM Agents")). It would be beneficial
    to have more metrics for evaluating spontaneous cooperation in EE, and leave this
    for future study.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在EE中，我们发现代理人在沟通过程中偶尔会使用具有指导性或鼓励性的词汇，这可以视为合作行为。此外，结果显示，进行沟通的模拟获得了最高的表现（表[2](https://arxiv.org/html/2402.12327v3#S6.T2
    "表2 ‣ 6.2 模拟结果 ‣ 6 案例研究3：紧急疏散 ‣ 我们要组队吗：探索竞争性LLM代理人的自发合作")）。为EE评估自发合作提供更多的评估指标将会有所帮助，留待未来研究。
- en: 8 Conclusion
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: We investigated spontaneous cooperation in three case studies, and observed
    that LLM agents can gradually develop cooperative behaviors over time without
    explicit instructions. The phenomenon aligns well with real-world data, which
    stresses the significance of eliminating prior knowledge when doing social simulation.
    We believe this approach not only aids the CSS community in bridging the gap between
    synthetic simulations and real-world dynamics but also offers the AI community
    a novel way to assess LLMs’ deliberate reasoning.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在三个案例研究中探讨了自发合作，并观察到LLM代理人能够在没有明确指示的情况下，随着时间推移逐渐发展出合作行为。这一现象与现实世界的数据非常吻合，强调了在进行社会模拟时消除先验知识的重要性。我们相信这种方法不仅有助于CSS社区弥合合成模拟与现实世界动态之间的差距，而且为AI社区提供了一种新的评估LLM故意推理的方法。
- en: Ethical Statement
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: In this work, we studied the cooperative behavior of LLM agents in competitive
    environments. All the experiments were conducted using computer simulations. To
    the best of our knowledge, there is no negative societal impact in this research.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中，我们研究了LLM代理人在竞争环境中的合作行为。所有实验均在计算机模拟中进行。据我们所知，本研究没有产生负面的社会影响。
- en: We found that LLM agents are capable of learning collusion in a simulated marketing
    environment. This insight could inform regulatory measures for markets involving
    AI agents, such as prohibiting collusive behaviors when employing AI in financial
    markets.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现LLM代理能够在模拟的市场环境中学习勾结行为。这一见解可以为涉及AI代理的市场监管措施提供参考，比如在金融市场中禁止使用AI进行勾结行为。
- en: We used ChatGPT to polish the paper. We are responsible for all the materials
    presented in this work.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用ChatGPT来润色本论文。我们对本文中呈现的所有材料负责。
- en: Limitations
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: In our study, we identified several limitations that need to be addressed in
    future work.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们识别出需要在未来工作中解决的几个局限性。
- en: Limited Experimentation on LLMs
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对LLM的实验有限
- en: 'One major limitation of our study is the scope of our experiments. We conducted
    our research primarily using a single version of GPT-4\. This choice was largely
    driven by (1) financial constraints associated with these case studies ($\{\$900,\$3000,\$1000\}$,
    respectively), (2) restricted rate limits and window size, and (3) the LLMs’ limited
    understanding on the scenarios (see Appendix [B.3](https://arxiv.org/html/2402.12327v3#A2.SS3
    "B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")). Additionally, we were unable to conduct
    more extensive experiments using other open-source large language models due to
    insufficient computational resources. As a result, we regard our findings as a
    proof-of-concept study, which needs to be further tested across different LLMs
    to prove its generalizability.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '我们研究的一个主要局限性是实验的范围。我们主要使用了单一版本的GPT-4进行研究。这一选择主要受到以下因素的影响：（1）这些案例研究的财务限制（分别为$\{\$900,\$3000,\$1000\}$），（2）受限的速率限制和窗口大小，以及（3）LLM在这些场景中的理解有限（参见附录 [B.3](https://arxiv.org/html/2402.12327v3#A2.SS3
    "B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")）。此外，由于计算资源不足，我们未能使用其他开源大型语言模型进行更广泛的实验。因此，我们将我们的研究结果视为一种概念验证研究，需要在不同LLM上进一步测试以验证其普适性。'
- en: Inadequate Contributions as Verifying LLMs’ Reasoning Ability
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 作为验证LLM推理能力的贡献不足
- en: We claimed that our findings offer a new way to verify the deliberate reasoning
    capabilities of LLMs. We do showcase extensive experiment results to reveal the
    potential to formulate spontaneous cooperation as a standard of LLM agents. However,
    we deeply agree that we did not focus sufficiently on collecting comprehensive
    datasets or creating robust benchmarks to substantiate this claim fully. Moving
    forward, we plan to convert our case studies into standardized benchmarks or datasets
    to facilitate further research and evaluation by the AI community.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称，我们的研究结果提供了一种验证LLM有意推理能力的新方式。我们确实展示了大量实验结果，揭示了将自发合作作为LLM代理标准的潜力。然而，我们深刻认识到，我们在收集全面的数据集或创建稳健的基准以完全支持这一主张方面做得还不够。未来，我们计划将我们的案例研究转化为标准化的基准或数据集，以便为AI社区的进一步研究和评估提供帮助。
- en: Conceptual Limitations Regarding LLM Instructions
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 关于LLM指令的概念性局限性
- en: Throughout our paper, we emphasized using LLM agents without explicit instructions
    in the prompts. We observed that this approach often resulted in behaviors that
    closely resemble those of real humans in simulated tasks. While we agree that
    LLMs inherently exhibit certain behaviors derived from being trained on human
    data and aligned with human feedback, our claim is not that simulating human behavior
    using these LLM agents is entirely justified. Instead, we stress that using LLM
    agents without explicit instructions yields more human-like performance compared
    to explicitly instructed agents, highlighting the reasonableness of our approach.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的论文中，我们强调了在提示中不使用明确指令的情况下使用LLM代理。我们观察到，这种方法通常会导致在模拟任务中表现出与真实人类相似的行为。虽然我们同意LLM本身展示了某些源自人类数据训练并与人类反馈对齐的行为，但我们的主张并非完全认为使用这些LLM代理模拟人类行为是完全合理的。相反，我们强调，使用不带明确指令的LLM代理相比带有明确指令的代理，能够产生更具人类特征的表现，这也突出了我们方法的合理性。
- en: By addressing these issues, we aim to strengthen the validity and applicability
    of our findings in the future.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决这些问题，我们旨在增强我们研究结果在未来的有效性和适用性。
- en: Acknowledgements
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by JSPS Kakenhi 21K19767, 23K17456, 23K24851, 23K25157,
    23K28096, and CREST JPMJCR22M2\. We thank Prof. Yuki Arase and Yuya Sasaki for
    providing hardware support for completing this research.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了JSPS科研资助21K19767、23K17456、23K24851、23K25157、23K28096和CREST JPMJCR22M2的支持。我们感谢Arase教授和Yuya
    Sasaki提供硬件支持，以完成本研究。
- en: References
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abdelnabi et al. (2024) Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea
    Schönherr, and Mario Fritz. 2024. [Cooperation, competition, and maliciousness:
    Llm-stakeholders interactive negotiation](https://arxiv.org/abs/2309.17234). *Preprint*,
    arXiv:2309.17234.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdelnabi 等（2024）Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr,
    和 Mario Fritz。2024年。[合作、竞争与恶意：大型语言模型利益相关者的互动博弈](https://arxiv.org/abs/2309.17234)。*预印本*，arXiv:2309.17234。
- en: 'Ai et al. (2024) Yiming Ai, Zhiwei He, Ziyin Zhang, Wenhong Zhu, Hongkun Hao,
    Kai Yu, Lingjun Chen, and Rui Wang. 2024. [Is cognition and action consistent
    or not: Investigating large language model’s personality](https://arxiv.org/abs/2402.14679).
    *Preprint*, arXiv:2402.14679.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ai 等（2024）Yiming Ai, Zhiwei He, Ziyin Zhang, Wenhong Zhu, Hongkun Hao, Kai Yu,
    Lingjun Chen, 和 Rui Wang。2024年。[认知与行动是否一致：探讨大型语言模型的个性](https://arxiv.org/abs/2402.14679)。*预印本*，arXiv:2402.14679。
- en: 'Andres et al. (2023) Maximilian Andres, Lisa Bruttel, and Jana Friedrichsen.
    2023. How communication makes the difference between a cartel and tacit collusion:
    A machine learning approach. *European Economic Review*, 152:104331.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andres 等（2023）Maximilian Andres, Lisa Bruttel, 和 Jana Friedrichsen。2023年。沟通如何区分卡特尔与默契合谋：一种机器学习方法。*欧洲经济评论*，152:104331。
- en: 'Argyle et al. (2023) Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler,
    Christopher Rytting, and David Wingate. 2023. Out of one, many: Using language
    models to simulate human samples. *Political Analysis*, 31(3):337–351.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argyle 等（2023）Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher
    Rytting, 和 David Wingate。2023年。从一到多：使用语言模型模拟人类样本。*政治分析*，31(3):337–351。
- en: 'Bosch-Domenech et al. (2002) Antoni Bosch-Domenech, Jose G Montalvo, Rosemarie
    Nagel, and Albert Satorra. 2002. One, two,(three), infinity,…: Newspaper and lab
    beauty-contest experiments. *American Economic Review*, 92(5):1687–1701.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bosch-Domenech 等（2002）Antoni Bosch-Domenech, Jose G Montalvo, Rosemarie Nagel,
    和 Albert Satorra。2002年。一个、两个、（三个）、无限……：报纸与实验室的美容竞赛实验。*美国经济评论*，92(5):1687–1701。
- en: 'Bubeck et al. (2023) Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
    Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
    et al. 2023. Sparks of artificial general intelligence: Early experiments with
    GPT-4. *arXiv preprint arXiv:2303.12712*.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bubeck 等（2023）Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
    Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg
    等。2023年。人工通用智能的火花：与 GPT-4 的早期实验。*arXiv 预印本 arXiv:2303.12712*。
- en: Calvano et al. (2020) Emilio Calvano, Giacomo Calzolari, Vincenzo Denicolo,
    and Sergio Pastorello. 2020. Artificial intelligence, algorithmic pricing, and
    collusion. *American Economic Review*, 110(10):3267–3297.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calvano 等（2020）Emilio Calvano, Giacomo Calzolari, Vincenzo Denicolo, 和 Sergio
    Pastorello。2020年。人工智能、算法定价与合谋。*美国经济评论*，110(10):3267–3297。
- en: Carley (2002) Kathleen M Carley. 2002. Smart agents and organizations of the
    future. *The handbook of new media*, 12:206–220.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carley（2002）Kathleen M Carley。2002年。未来的智能体与组织。*新媒体手册*，12:206–220。
- en: Chase (2023) Harrison Chase. 2023. Langchain. [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain).
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chase（2023）Harrison Chase。2023年。Langchain。 [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)。
- en: 'Chen et al. (2023) Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei
    Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2023. Agentverse:
    Facilitating multi-agent collaboration and exploring emergent behaviors in agents.
    *arXiv preprint arXiv:2308.10848*.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2023）Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen
    Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie 等。2023年。Agentverse：促进多智能体协作与探索智能体中的涌现行为。*arXiv
    预印本 arXiv:2308.10848*。
- en: Du and Zhang (2024) Silin Du and Xiaowei Zhang. 2024. [Helmsman of the masses?
    evaluate the opinion leadership of large language models in the werewolf game](https://arxiv.org/abs/2404.01602).
    *Preprint*, arXiv:2404.01602.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 和 Zhang（2024）Silin Du 和 Xiaowei Zhang。2024年。[大众的舵手？评估大型语言模型在狼人杀游戏中的舆论领导力](https://arxiv.org/abs/2404.01602)。*预印本*，arXiv:2404.01602。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum,
    and Igor Mordatch. 2023. [Improving factuality and reasoning in language models
    through multiagent debate](https://arxiv.org/abs/2305.14325). *Preprint*, arXiv:2305.14325.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du 等（2023）Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, 和 Igor
    Mordatch。2023年。[通过多智能体辩论提高语言模型的事实性和推理能力](https://arxiv.org/abs/2305.14325)。*预印本*，arXiv:2305.14325。
- en: 'Gao et al. (2023a) Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding,
    Zhilun Zhou, Fengli Xu, and Yong Li. 2023a. Large language models empowered agent-based
    modeling and simulation: A survey and perspectives. *arXiv preprint arXiv:2312.11970*.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 (2023a) 陈高、兰晓冲、李念、袁源、丁景涛、周志伦、徐风利和李勇。2023a. 大语言模型赋能的基于代理的建模与仿真：综述与展望。*arXiv
    预印本 arXiv:2312.11970*。
- en: 'Gao et al. (2023b) Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua
    Piao, Huandong Wang, Depeng Jin, and Yong Li. 2023b. S³: Social-network simulation
    system with large language model-empowered agents. *arXiv preprint arXiv:2307.14984*.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao 等人 (2023b) 陈高、兰晓冲、卢志宏、毛金珠、朴京华、王欢东、金德鹏和李勇。2023b. S³: 利用大语言模型赋能的社交网络仿真系统。*arXiv
    预印本 arXiv:2307.14984*。'
- en: 'Giabbanelli (2023) Philippe J Giabbanelli. 2023. GPT-based models meet simulation:
    How to efficiently use large-scale pre-trained language models across simulation
    tasks. *arXiv preprint arXiv:2306.13679*.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giabbanelli (2023) 菲利普·J·Giabbanelli。2023. 基于 GPT 的模型与仿真：如何高效地在仿真任务中使用大规模预训练语言模型。*arXiv
    预印本 arXiv:2306.13679*。
- en: Guo et al. (2024) Xudong Guo, Kaixuan Huang, Jiale Liu, Wenhui Fan, Natalia
    Vélez, Qingyun Wu, Huazheng Wang, Thomas L Griffiths, and Mengdi Wang. 2024. Embodied
    llm agents learn to cooperate in organized teams. *arXiv preprint arXiv:2403.12482*.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等人 (2024) 郭旭东、黄凯轩、刘佳乐、范文辉、纳塔莉亚·韦莱兹、吴清云、王华铮、托马斯·L·格里菲斯 和 王梦迪。2024. 化身 LLM
    代理学习在组织化团队中的合作。*arXiv 预印本 arXiv:2403.12482*。
- en: 'Hang et al. (2024) Tiankai Hang, Shuyang Gu, Dong Chen, Xin Geng, and Baining
    Guo. 2024. Cca: Collaborative competitive agents for image editing. *arXiv preprint
    arXiv:2401.13011*.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hang 等人 (2024) 杭天凯、谷书洋、陈栋、耿鑫 和 郭百宁。2024. Cca: 用于图像编辑的协作竞争代理。*arXiv 预印本 arXiv:2401.13011*。'
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
    2023. MetaGPT: Meta programming for multi-agent collaborative framework. *arXiv
    preprint arXiv:2308.00352*.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hong 等人 (2023) 洪思瑞、郑晓武、陈Jonathan、程玉恒、张册尧、王梓礼、邱思恒、林子涓、周立扬、冉晨宇 等人。2023. MetaGPT:
    多代理协作框架的元编程。*arXiv 预印本 arXiv:2308.00352*。'
- en: Hu and Collier (2024) Tiancheng Hu and Nigel Collier. 2024. [Quantifying the
    persona effect in llm simulations](https://arxiv.org/abs/2402.10811). *Preprint*,
    arXiv:2402.10811.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 和 Collier (2024) 胡天成 和 奈杰尔·科利尔。2024. [量化 LLM 仿真中的人格效应](https://arxiv.org/abs/2402.10811)。*预印本*,
    arXiv:2402.10811。
- en: Jansen et al. (2023) Bernard J Jansen, Soon-gyo Jung, and Joni Salminen. 2023.
    Employing large language models in survey research. *Natural Language Processing
    Journal*, 4:100020.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jansen 等人 (2023) 伯纳德·J·Jansen、郑顺敎 和 乔尼·萨尔米宁。2023. 在调查研究中应用大语言模型。*《自然语言处理期刊》*,
    4:100020。
- en: Janssen and Ostrom (2006) Marco A Janssen and Elinor Ostrom. 2006. Empirically
    based, agent-based models. *Ecology and society*, 11(2).
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Janssen 和 Ostrom (2006) 马尔科·A·Janssen 和 埃莉诺·Ostrom。2006. 基于经验的代理模型。*《生态学与社会》*,
    11(2)。
- en: Junprung (2023) Edward Junprung. 2023. Exploring the intersection of large language
    models and agent-based modeling via prompt engineering. *arXiv preprint arXiv:2308.07411*.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Junprung (2023) 爱德华·Junprung。2023. 通过提示工程探索大语言模型与基于代理的建模交集。*arXiv 预印本 arXiv:2308.07411*。
- en: Kosinski (2024) Michal Kosinski. 2024. [Evaluating large language models in
    theory of mind tasks](https://arxiv.org/abs/2302.02083). *Preprint*, arXiv:2302.02083.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kosinski (2024) 米哈伊·Kosinski。2024. [评估大语言模型在心智理论任务中的表现](https://arxiv.org/abs/2302.02083)。*预印本*,
    arXiv:2302.02083。
- en: 'Lan et al. (2023) Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye,
    Peilin Zhao, Ee-Peng Lim, Hui Xiong, and Hao Wang. 2023. Llm-based agent society
    investigation: Collaboration and confrontation in avalon gameplay. *arXiv preprint
    arXiv:2310.14985*.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lan 等人 (2023) 兰一槐、胡志强、王磊、王扬、叶德恒、赵佩林、林易鹏、熊辉和王浩。2023. 基于 LLM 的代理社会研究：在亚瓦隆游戏中的合作与对抗。*arXiv
    预印本 arXiv:2310.14985*。
- en: Leonhardt and Quealy (2015) David Leonhardt and Kevin Quealy. 2015. [Are you
    smarter than 61,139 other new york times readers?](https://www.nytimes.com/interactive/2015/08/13/upshot/are-you-smarter-than-other-new-york-times-readers.html)
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leonhardt 和 Quealy (2015) 大卫·Leonhardt 和 凯文·Quealy。2015. [你比 61,139 位《纽约时报》读者更聪明吗？](https://www.nytimes.com/interactive/2015/08/13/upshot/are-you-smarter-than-other-new-york-times-readers.html)
- en: 'Li et al. (2023) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023. Camel: Communicative agents for "mind" exploration
    of large scale language model society. *arXiv preprint arXiv:2303.17760*.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 (2023) 李国豪、哈桑·阿贝德·阿尔·卡德尔·哈穆德、哈尼·伊塔尼、德米特里·基兹布林 和 伯纳德·加内姆。2023. Camel:
    用于“大规模语言模型社会心智”探索的交互式代理。*arXiv 预印本 arXiv:2303.17760*。'
- en: 'Lin et al. (2023) Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue
    Ping, and Qin Chen. 2023. Agentsims: An open-source sandbox for large language
    model evaluation. *arXiv preprint arXiv:2308.04026*.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin等人（2023）Jiaju Lin、Haoran Zhao、Aochi Zhang、Yiting Wu、Huqiuyue Ping和Qin Chen。2023年。Agentims：一个用于大语言模型评估的开源沙箱。*arXiv预印本arXiv:2308.04026*。
- en: Liu et al. (2023a) Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou,
    Andrew M Dai, Diyi Yang, and Soroush Vosoughi. 2023a. Training socially aligned
    language models in simulated human society. *arXiv preprint arXiv:2305.16960*.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023a）Ruibo Liu、Ruixin Yang、Chenyan Jia、Ge Zhang、Denny Zhou、Andrew M Dai、Diyi
    Yang和Soroush Vosoughi。2023a年。在模拟人类社会中训练社会对齐语言模型。*arXiv预印本arXiv:2305.16960*。
- en: 'Liu et al. (2023b) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran
    Xu, Phil Mui, Huan Wang, Caiming Xiong, and Silvio Savarese. 2023b. [Bolaa: Benchmarking
    and orchestrating llm-augmented autonomous agents](https://arxiv.org/abs/2308.05960).
    *Preprint*, arXiv:2308.05960.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023b）Zhiwei Liu、Weiran Yao、Jianguo Zhang、Le Xue、Shelby Heinecke、Rithesh
    Murthy、Yihao Feng、Zeyuan Chen、Juan Carlos Niebles、Devansh Arpit、Ran Xu、Phil Mui、Huan
    Wang、Caiming Xiong和Silvio Savarese。2023b年。[Bolaa：大语言模型增强的自主代理基准测试与编排](https://arxiv.org/abs/2308.05960)。*预印本*，arXiv:2308.05960。
- en: 'Liu et al. (2024) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin
    Liu, Juntao Tan, Prafulla K. Choubey, Tian Lan, Jason Wu, Huan Wang, Shelby Heinecke,
    Caiming Xiong, and Silvio Savarese. 2024. [Agentlite: A lightweight library for
    building and advancing task-oriented llm agent system](https://arxiv.org/abs/2402.15538).
    *Preprint*, arXiv:2402.15538.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2024）Zhiwei Liu、Weiran Yao、Jianguo Zhang、Liangwei Yang、Zuxin Liu、Juntao
    Tan、Prafulla K. Choubey、Tian Lan、Jason Wu、Huan Wang、Shelby Heinecke、Caiming Xiong和Silvio
    Savarese。2024年。[Agentlite：一个构建和推进任务导向型大语言模型代理系统的轻量级库](https://arxiv.org/abs/2402.15538)。*预印本*，arXiv:2402.15538。
- en: Ma et al. (2023) Ziqiao Ma, Jacob Sansom, Run Peng, and Joyce Chai. 2023. Towards
    a holistic landscape of situated theory of mind in large language models. *arXiv
    preprint arXiv:2310.19619*.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma等人（2023）Ziqiao Ma、Jacob Sansom、Run Peng和Joyce Chai。2023年。迈向大语言模型中的全景化情境心智理论。*arXiv预印本arXiv:2310.19619*。
- en: 'Mozikov et al. (2024) Mikhail Mozikov, Nikita Severin, Valeria Bodishtianu,
    Maria Glushanina, Mikhail Baklashkin, Andrey V. Savchenko, and Ilya Makarov. 2024.
    [The good, the bad, and the hulk-like gpt: Analyzing emotional decisions of large
    language models in cooperation and bargaining games](https://arxiv.org/abs/2406.03299).
    *Preprint*, arXiv:2406.03299.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mozikov等人（2024）Mikhail Mozikov、Nikita Severin、Valeria Bodishtianu、Maria Glushanina、Mikhail
    Baklashkin、Andrey V. Savchenko和Ilya Makarov。2024年。[好的、坏的和像绿巨人一样的GPT：分析大语言模型在合作与博弈中的情感决策](https://arxiv.org/abs/2406.03299)。*预印本*，arXiv:2406.03299。
- en: 'Park et al. (2023) Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. In *In the 36th Annual ACM Symposium on User Interface
    Software and Technology (UIST ’23)*, UIST ’23, New York, NY, USA. Association
    for Computing Machinery.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人（2023）Joon Sung Park、Joseph C. O’Brien、Carrie J. Cai、Meredith Ringel Morris、Percy
    Liang和Michael S. Bernstein。2023年。生成代理：人类行为的互动仿真体。在*第36届年度ACM用户界面软件与技术研讨会（UIST
    '23）*，UIST '23，美国纽约。计算机协会。
- en: 'Piatti et al. (2024) Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard
    Schölkopf, Mrinmaya Sachan, and Rada Mihalcea. 2024. [Cooperate or collapse: Emergence
    of sustainability behaviors in a society of llm agents](https://arxiv.org/abs/2404.16698).
    *Preprint*, arXiv:2404.16698.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Piatti等人（2024）Giorgio Piatti、Zhijing Jin、Max Kleiman-Weiner、Bernhard Schölkopf、Mrinmaya
    Sachan和Rada Mihalcea。2024年。[合作还是崩溃：大语言模型代理社会中可持续行为的出现](https://arxiv.org/abs/2404.16698)。*预印本*，arXiv:2404.16698。
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924*.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian等人（2023）Chen Qian、Xin Cong、Cheng Yang、Weize Chen、Yusheng Su、Juyuan Xu、Zhiyuan
    Liu和Maosong Sun。2023年。用于软件开发的交互式代理。*arXiv预印本arXiv:2307.07924*。
- en: Salecha et al. (2024) Aadesh Salecha, Molly E. Ireland, Shashanka Subrahmanya,
    João Sedoc, Lyle H. Ungar, and Johannes C. Eichstaedt. 2024. [Large language models
    show human-like social desirability biases in survey responses](https://arxiv.org/abs/2405.06058).
    *Preprint*, arXiv:2405.06058.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salecha等人（2024）Aadesh Salecha、Molly E. Ireland、Shashanka Subrahmanya、João Sedoc、Lyle
    H. Ungar和Johannes C. Eichstaedt。2024年。[大语言模型在调查问卷中的回答表现出类人社会期望偏差](https://arxiv.org/abs/2405.06058)。*预印本*，arXiv:2405.06058。
- en: Salewski et al. (2023) Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric
    Schulz, and Zeynep Akata. 2023. In-context impersonation reveals large language
    models’ strengths and biases. *arXiv preprint arXiv:2305.14930*.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salewski 等人（2023）Leonard Salewski、Stephan Alaniz、Isabel Rio-Torto、Eric Schulz
    和 Zeynep Akata. 2023. 语境伪装揭示了大规模语言模型的优势和偏差. *arXiv 预印本 arXiv:2305.14930*.
- en: Saravia (2023) Elvis Saravia. 2023. Prompt engineering guide. [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saravia（2023）Elvis Saravia. 2023. 提示工程指南. [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide).
- en: 'Shapira et al. (2024) Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui
    Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, and Vered Shwartz. 2024. [Clever
    hans or neural theory of mind? stress testing social reasoning in large language
    models](https://aclanthology.org/2024.eacl-long.138). In *Proceedings of the 18th
    Conference of the European Chapter of the Association for Computational Linguistics
    (Volume 1: Long Papers)*, pages 2257–2273, St. Julian’s, Malta. Association for
    Computational Linguistics.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shapira 等人（2024）Natalie Shapira、Mosh Levy、Seyed Hossein Alavi、Xuhui Zhou、Yejin
    Choi、Yoav Goldberg、Maarten Sap 和 Vered Shwartz. 2024. [聪明的汉斯还是神经心智理论？大规模语言模型中的社会推理压力测试](https://aclanthology.org/2024.eacl-long.138).
    *《第18届欧洲计算语言学学会会议论文集（第1卷：长篇论文）》*, 第2257–2273页，马耳他圣朱利安。计算语言学协会。
- en: 'Shi et al. (2023) Zijing Shi, Meng Fang, Shunfeng Zheng, Shilong Deng, Ling
    Chen, and Yali Du. 2023. Cooperation on the fly: Exploring language agents for
    ad hoc teamwork in the avalon game. *arXiv preprint arXiv:2312.17515*.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等人（2023）Zijing Shi、Meng Fang、Shunfeng Zheng、Shilong Deng、Ling Chen 和 Yali
    Du. 2023. 现场合作：探索在 Avalon 游戏中进行临时团队协作的语言代理. *arXiv 预印本 arXiv:2312.17515*.
- en: 'Sreedhar and Chilton (2024) Karthik Sreedhar and Lydia Chilton. 2024. [Simulating
    human strategic behavior: Comparing single and multi-agent llms](https://arxiv.org/abs/2402.08189).
    *Preprint*, arXiv:2402.08189.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sreedhar 和 Chilton（2024）Karthik Sreedhar 和 Lydia Chilton. 2024. [模拟人类战略行为：比较单一和多代理
    LLM](https://arxiv.org/abs/2402.08189). *预印本*, arXiv:2402.08189.
- en: Tang et al. (2024) Daniel Tang, Zhenghan Chen, Kisub Kim, Yewei Song, Haoye
    Tian, Saad Ezzini, Yongfeng Huang, and Jacques Klein Tegawende F Bissyande. 2024.
    Collaborative agents for software engineering. *arXiv preprint arXiv:2402.02172*.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人（2024）Daniel Tang、Zhenghan Chen、Kisub Kim、Yewei Song、Haoye Tian、Saad
    Ezzini、Yongfeng Huang 和 Jacques Klein Tegawende F Bissyande. 2024. 软件工程中的协作代理.
    *arXiv 预印本 arXiv:2402.02172*.
- en: 'Wang et al. (2015) Jinhuan Wang, Lei Zhang, Qiongyu Shi, Peng Yang, and Xiaoming
    Hu. 2015. Modeling and simulating for congestion pedestrian evacuation with panic.
    *Physica A: Statistical Mechanics and its Applications*, 428:396–409.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2015）Jinhuan Wang、Lei Zhang、Qiongyu Shi、Peng Yang 和 Xiaoming Hu. 2015.
    模拟和仿真拥挤情况下的步行者疏散与恐慌. *Physica A: Statistical Mechanics and its Applications*,
    428:396–409.'
- en: Wang et al. (2023a) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023a. A survey
    on large language model based autonomous agents. *arXiv preprint arXiv:2308.11432*.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023a）Lei Wang、Chen Ma、Xueyang Feng、Zeyu Zhang、Hao Yang、Jingsen Zhang、Zhiyuan
    Chen、Jiakai Tang、Xu Chen、Yankai Lin 等人. 2023a. 基于大规模语言模型的自主代理综述. *arXiv 预印本 arXiv:2308.11432*.
- en: 'Wang et al. (2023b) Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu
    Wei, and Heng Ji. 2023b. Unleashing cognitive synergy in large language models:
    A task-solving agent through multi-persona self-collaboration. *arXiv preprint
    arXiv:2307.05300*.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023b）Zhenhailong Wang、Shaoguang Mao、Wenshan Wu、Tao Ge、Furu Wei 和 Heng
    Ji. 2023b. 在大规模语言模型中释放认知协同：通过多人格自我协作解决任务的代理. *arXiv 预印本 arXiv:2307.05300*.
- en: Weng (2023) Lilian Weng. 2023. Llm powered autonomous agents. [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/).
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng（2023）Lilian Weng. 2023. 基于 LLM 的自主代理. [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/).
- en: Wikipedia (2024) Wikipedia. 2024. [Bertrand competition](https://en.wikipedia.org/wiki/Bertrand_competition).
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wikipedia（2024）Wikipedia. 2024. [贝尔特朗竞争](https://en.wikipedia.org/wiki/Bertrand_competition).
- en: 'Wu et al. (2023a) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun
    Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023a. AutoGen:
    Enabling next-gen LLM applications via multi-agent conversation framework. *arXiv
    preprint arXiv:2308.08155*.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2023a）Qingyun Wu、Gagan Bansal、Jieyu Zhang、Yiran Wu、Shaokun Zhang、Erkang
    Zhu、Beibin Li、Li Jiang、Xiaoyun Zhang 和 Chi Wang. 2023a. AutoGen：通过多代理对话框架启用下一代
    LLM 应用. *arXiv 预印本 arXiv:2308.08155*.
- en: Wu et al. (2024) Shuang Wu, Liwen Zhu, Tao Yang, Shiwei Xu, Qiang Fu, Yang Wei,
    and Haobo Fu. 2024. Enhance reasoning for large language models in the game werewolf.
    *arXiv preprint arXiv:2402.02330*.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2024）Shuang Wu、Liwen Zhu、Tao Yang、Shiwei Xu、Qiang Fu、Yang Wei 和 Haobo
    Fu. 2024. 提升大型语言模型在狼人游戏中的推理能力。*arXiv 预印本 arXiv:2402.02330*。
- en: 'Wu et al. (2023b) Zengqing Wu, Run Peng, Xu Han, Shuyuan Zheng, Yixin Zhang,
    and Chuan Xiao. 2023b. Smart agent-based modeling: On the use of large language
    models in computer simulations. *arXiv preprint arXiv:2311.06330*.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2023b）Zengqing Wu、Run Peng、Xu Han、Shuyuan Zheng、Yixin Zhang 和 Chuan Xiao.
    2023b. 智能代理基础建模：在计算机模拟中使用大型语言模型的研究。*arXiv 预印本 arXiv:2311.06330*。
- en: 'Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. 2023. The rise and
    potential of large language model based agents: A survey. *arXiv preprint arXiv:2309.07864*.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xi 等人（2023）Zhiheng Xi、Wenxiang Chen、Xin Guo、Wei He、Yiwen Ding、Boyang Hong、Ming
    Zhang、Junzhe Wang、Senjie Jin、Enyu Zhou 等人. 2023. 基于大型语言模型的代理崛起与潜力：一项调查。*arXiv
    预印本 arXiv:2309.07864*。
- en: 'Xie et al. (2023) Tianbao Xie, Fan Zhou, Zhoujun Cheng, Peng Shi, Luoxuan Weng,
    Yitao Liu, Toh Jing Hua, Junning Zhao, Qian Liu, Che Liu, et al. 2023. Openagents:
    An open platform for language agents in the wild. *arXiv preprint arXiv:2310.10634*.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xie 等人（2023）Tianbao Xie、Fan Zhou、Zhoujun Cheng、Peng Shi、Luoxuan Weng、Yitao Liu、Toh
    Jing Hua、Junning Zhao、Qian Liu、Che Liu 等人. 2023. Openagents：一个为语言代理提供开放平台的研究。*arXiv
    预印本 arXiv:2310.10634*。
- en: 'Xu et al. (2023a) Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. 2023a. Exploring large language models for communication
    games: An empirical study on werewolf. *arXiv preprint arXiv:2309.04658*.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2023a）Yuzhuang Xu、Shuo Wang、Peng Li、Fuwen Luo、Xiaolong Wang、Weidong Liu
    和 Yang Liu. 2023a. 探索大型语言模型在沟通游戏中的应用：一项关于狼人游戏的实证研究。*arXiv 预印本 arXiv:2309.04658*。
- en: Xu et al. (2023b) Zelai Xu, Chao Yu, Fei Fang, Yu Wang, and Yi Wu. 2023b. Language
    agents with reinforcement learning for strategic play in the werewolf game. *arXiv
    preprint arXiv:2310.18940*.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2023b）Zelai Xu、Chao Yu、Fei Fang、Yu Wang 和 Yi Wu. 2023b. 使用强化学习的语言代理在狼人游戏中的战略性玩法。*arXiv
    预印本 arXiv:2310.18940*。
- en: 'Zhang et al. (2023) Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi,
    and Shumin Deng. 2023. [Exploring collaboration mechanisms for LLM agents: A social
    psychology view](https://doi.org/10.48550/ARXIV.2310.02124). *CoRR*, abs/2310.02124.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2023）Jintian Zhang、Xin Xu、Ningyu Zhang、Ruibo Liu、Bryan Hooi 和 Shumin
    Deng. 2023. [探索 LLM 代理的协作机制：一种社会心理学视角](https://doi.org/10.48550/ARXIV.2310.02124)。*CoRR*，abs/2310.02124。
- en: Zhang et al. (2024) Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Yan Xia,
    Man Lan, and Furu Wei. 2024. K-level reasoning with large language models. *arXiv
    preprint arXiv:2402.01521*.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2024）Yadong Zhang、Shaoguang Mao、Tao Ge、Xun Wang、Yan Xia、Man Lan 和 Furu
    Wei. 2024. 使用大型语言模型进行 K 级推理。*arXiv 预印本 arXiv:2402.01521*。
- en: 'Zhao et al. (2023) Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie
    Zhu, Hao Chen, and Xing Xie. 2023. CompeteAI: Understanding the competition behaviors
    in large language model-based agents. *arXiv preprint arXiv:2310.17512*.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人（2023）Qinlin Zhao、Jindong Wang、Yixuan Zhang、Yiqiao Jin、Kaijie Zhu、Hao
    Chen 和 Xing Xie. 2023. CompeteAI：理解基于大型语言模型的代理中的竞争行为。*arXiv 预印本 arXiv:2310.17512*。
- en: Zhou et al. (2024) Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, and Maarten
    Sap. 2024. [Is this the real life? is this just fantasy? the misleading success
    of simulating social interactions with llms](https://arxiv.org/abs/2403.05020).
    *Preprint*, arXiv:2403.05020.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人（2024）Xuhui Zhou、Zhe Su、Tiwalayo Eisape、Hyunwoo Kim 和 Maarten Sap. 2024.
    [这是真实生活吗？这只是幻想吗？模拟社会互动的误导性成功](https://arxiv.org/abs/2403.05020)。*预印本*，arXiv:2403.05020。
- en: Ziems et al. (2024) Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao
    Zhang, and Diyi Yang. 2024. Can large language models transform computational
    social science? *Computational Linguistics*, 50(1):237–291.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziems 等人（2024）Caleb Ziems、William Held、Omar Shaikh、Jiaao Chen、Zhehao Zhang 和
    Diyi Yang. 2024. 大型语言模型能否改变计算社会科学？*计算语言学*，50(1):237–291。
- en: Appendix A Parameter Settings
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 参数设置
- en: 'We report the parameters of the GPT-4 model used in our case studies in Table
    [3](https://arxiv.org/html/2402.12327v3#A1.T3 "Table 3 ‣ Appendix A Parameter
    Settings ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM
    Agents"). The temperature parameter controls the randomness and diversity of the
    model’s responses, with a lower temperature resulting in increased stability.
    In the evaluation of KBC, we expect that the individuals exhibit a wide range
    of diversity. Consequently, we adjust the temperature to a moderate level of $0.7$
    to balance randomness and stability in the results. For BC, where the agents simulate
    business parties, we expect their decisions to be stable and rational. Therefore,
    we set the temperature to $0.7$. For EE, although setting temperature to $0.0$
    may result in limited diversity of behaviors under exactly the same setting, in
    this procedurally generated, interactively dynamic environment, we seldom encounter
    exactly the same outcome. Meanwhile, in a physically situated setting (e.g., a
    grid), the LLM used in this case study still has restricted capabilities on scene
    understanding, and increasing the temperature may introduce diversity as well
    as unwanted randomness at the same time Ma et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib31)).'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在表[3](https://arxiv.org/html/2402.12327v3#A1.T3 "Table 3 ‣ Appendix A Parameter
    Settings ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM
    Agents")中报告了我们案例研究中使用的GPT-4模型的参数。温度参数控制模型响应的随机性和多样性，较低的温度会增加稳定性。在KBC评估中，我们期望个体表现出广泛的多样性。因此，我们将温度调整为$0.7$，以平衡结果中的随机性和稳定性。对于BC，其中代理人模拟商业方，我们期望他们的决策稳定且理性。因此，我们将温度设置为$0.7$。对于EE，尽管将温度设置为$0.0$可能会导致在完全相同设置下行为多样性有限，但在这种程序生成的互动动态环境中，我们很少遇到完全相同的结果。同时，在一个物理设置下（例如一个网格），在此案例研究中使用的LLM仍然在场景理解方面具有有限的能力，增加温度可能会同时带来多样性和不必要的随机性。Ma等人（[2023](https://arxiv.org/html/2402.12327v3#bib.bib31)）也提到过这一点。'
- en: For Claude-3-Sonnet used in KBC, we set the temperature to $1.0$.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在KBC中使用的Claude-3-Sonnet，我们将温度设置为$1.0$。
- en: 'Table 3: Parameter settings of GPT-4.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 3：GPT-4的参数设置。
- en: '| Case | Model | temperature | max_tokens | top_p |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 案例 | 模型 | 温度 | 最大tokens | top_p |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| KBC | gpt-4-0314 | 0.7 | 256 | 1.0 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| KBC | gpt-4-0314 | 0.7 | 256 | 1.0 |'
- en: '| BC | gpt-4-0314 | 0.7 | 128 | 1.0 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| BC | gpt-4-0314 | 0.7 | 128 | 1.0 |'
- en: '| EE | gpt-4-0314 | 0.0 | 512 | 1.0 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| EE | gpt-4-0314 | 0.0 | 512 | 1.0 |'
- en: Appendix B Tests of Other LLMs
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 其他LLM的测试
- en: B.1 KBC
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 KBC
- en: 'We test GPT-3.5 (gpt-3.5-turbo-1106) agents in KBC, simulating 10 runs, and
    show their number choices in Fig. [10](https://arxiv.org/html/2402.12327v3#A2.F10
    "Figure 10 ‣ B.1 KBC ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents"). When GPT-3.5 agents cannot
    discuss the game, the numbers chosen are very random, and widely distributed in
    the range of $20$-$80$. When they can communicate, the choices and cooperation
    do not improve significantly, whereas the variances are even greater under some
    circumstances. This is significantly different from GPT-4 agents, which, especially
    after communication, can have a deeper understanding of KBC.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在KBC中测试了GPT-3.5（gpt-3.5-turbo-1106）代理人，模拟了10次运行，并在图[10](https://arxiv.org/html/2402.12327v3#A2.F10
    "Figure 10 ‣ B.1 KBC ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents")中展示了它们的数字选择。当GPT-3.5代理人不能讨论游戏时，所选的数字非常随机，且分布广泛，在$20$-$80$范围内。当它们能够通信时，选择和合作没有显著提高，而在某些情况下，方差甚至更大。这与GPT-4代理人显著不同，尤其是在通信后，GPT-4代理人能够更深入地理解KBC。'
- en: '![Refer to caption](img/f2bf180ddab31f5612e640e002caec5c.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/f2bf180ddab31f5612e640e002caec5c.png)'
- en: (a) Without communication ($k=0$).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 无通信（$k=0$）。
- en: '![Refer to caption](img/69798e915bdfb63024b4982d48d3e8ae.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/69798e915bdfb63024b4982d48d3e8ae.png)'
- en: (b) With communication ($k=3$).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有通信（$k=3$）。
- en: 'Figure 10: Choice distributions in KBC w/ and w/o communication using GPT-3.5
    model. Red points represent two-thirds of the average of all choices. The blue
    dots represent the choices of the agents. The agent whose choice is closest to
    the red point in each run is considered the winner.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：在KBC中使用GPT-3.5模型，带和不带通信的选择分布。红点表示所有选择的平均值的三分之二。蓝点表示代理人的选择。在每次运行中，最接近红点的代理人选择被认为是获胜者。
- en: 'Table 4: Preliminary test of GPT-3.5, Gemini Pro, and Claude 2 for KBC.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 4：GPT-3.5、Gemini Pro 和 Claude 2 在KBC中的初步测试。
- en: '| Model | Choice | Reasoning |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 选择 | 推理 |'
- en: '| --- | --- | --- |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GPT-4 | 18 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 18 |'
- en: '&#124; In this game, where the target is 2/3 of the average guess of all participants,
    there’s a strategic component to consider. &#124;'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 在这个游戏中，目标是2/3所有参与者的平均猜测值，因此需要考虑一个战略性因素。 &#124;'
- en: '&#124; Typically, if everyone guesses randomly within the range, the average
    might center around 50. &#124;'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 通常，如果每个人都在范围内随机猜测，平均值可能会集中在50左右。 &#124;'
- en: '&#124; However, considering that players might rationalize this and adjust
    their guesses downward, the initial average could shift lower. &#124;'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 然而，考虑到玩家可能会对此进行理性推理并将猜测值下调，初始平均值可能会向下调整。 &#124;'
- en: '&#124; Assuming players adjust their guesses accordingly, the average might
    drop further with each round of reasoning. &#124;'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假设玩家会根据此调整他们的猜测，随着每一轮推理，平均值可能会进一步下降。 &#124;'
- en: '&#124; Predicting this behavior, I’ll assume a more conservative average guess
    around 25-30, &#124;'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 预测这种行为，我会假设一个更保守的平均猜测值，大约在25-30之间， &#124;'
- en: '&#124; taking 2/3 of that would suggest a guess in the 17-20 range. &#124;'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 取2/3会建议猜测在17到20之间。 &#124;'
- en: '|'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| GPT-3.5 | 33 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 33 |'
- en: '&#124; My reasoning is that I’ll aim for a number that balances between being
    influenced by potential extremes &#124;'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 我的推理是，我会选择一个数字，在受到潜在极端猜测的影响之间取得平衡 &#124;'
- en: '&#124; and what might be considered a reasonable midpoint among various guesses.
    Given the tendency for guesses to spread out across the range, &#124;'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 以及在各种猜测之间可能被认为是合理的中位数。鉴于猜测往往会在范围内分散，&#124;'
- en: '&#124; I’ll choose a number that’s slightly below what might be perceived as
    the median guess, &#124;'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 我会选择一个略低于可能被视为中位数的数字，&#124;'
- en: '&#124; since 2/3 of the average tends to bring the estimate down. &#124;'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 因为2/3的平均值通常会将估计值向下调整。 &#124;'
- en: '&#124; Therefore, my chosen number is 33. &#124;'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 因此，我选择的数字是33。 &#124;'
- en: '|'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Gemini Pro | 30 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| Gemini Pro | 30 |'
- en: '&#124; The average guess of all participants is unknown, so we cannot directly
    calculate 2/3 of it. &#124;'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 所有参与者的平均猜测值未知，因此我们无法直接计算2/3的值。 &#124;'
- en: '&#124; However, we can make an assumption that most players will guess around
    the middle of the range (50). &#124;'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 然而，我们可以假设大多数玩家会猜测在范围的中间（50）附近。 &#124;'
- en: '&#124; Therefore, choosing a number slightly below 2/3 of 50 &#124;'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 因此，选择一个略低于50的2/3 &#124;'
- en: '&#124; (which is around 33) might be a good strategy. &#124;'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; （大约是33）可能是一个不错的策略。 &#124;'
- en: '|'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Claude 2 | 33 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| Claude 2 | 33 |'
- en: '&#124; I will guess 33\. If everyone guesses randomly between 0 and 100, the
    average should be around 50. &#124;'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 我会猜33。如果每个人在0到100之间随机猜测，平均值应该是50左右。 &#124;'
- en: '&#124; Two-thirds of 50 is 33\. So 33 would be the number closest to two-thirds
    of the average guess. &#124;'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 50的2/3是33。因此，33是最接近2/3平均猜测值的数字。 &#124;'
- en: '|'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'We also evaluate Gemini Pro and Claude 2 with a preliminary test of KBC, simplifying
    the prompt. As shown in Table [4](https://arxiv.org/html/2402.12327v3#A2.T4 "Table
    4 ‣ B.1 KBC ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents"), after entering Prompt [G.1](https://arxiv.org/html/2402.12327v3#A7.SS1
    "G.1 Prompts for KBC ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents"), the results output by these two models
    are significantly different from GPT-4, but very similar to GPT-3.5. Since Fig. [10](https://arxiv.org/html/2402.12327v3#A2.F10
    "Figure 10 ‣ B.1 KBC ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents") demonstrates the poor performance
    of GPT-3.5 in KBC, we similarly exclude the use of Gemini Pro and Claude 2 in
    our simulations.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还通过对KBC进行初步测试，简化提示语，评估了Gemini Pro和Claude 2。如表格[4](https://arxiv.org/html/2402.12327v3#A2.T4
    "Table 4 ‣ B.1 KBC ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents")所示，在输入提示[G.1](https://arxiv.org/html/2402.12327v3#A7.SS1
    "G.1 Prompts for KBC ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")后，这两种模型输出的结果与GPT-4有显著差异，但与GPT-3.5非常相似。由于图[10](https://arxiv.org/html/2402.12327v3#A2.F10
    "Figure 10 ‣ B.1 KBC ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents")展示了GPT-3.5在KBC中的较差表现，因此我们同样在模拟中排除了使用Gemini
    Pro和Claude 2。'
- en: For Claude 3, we used Claude-3-Sonnet instead of Claude-3-Opus (hereafter Opus)
    in the KBC experiment because Opus has a low rate limit and high overhead. This
    made it challenging to use the API for scaling up simulations in practice. Our
    tests showed that in KBC, when there are more than 10 LLM players, the Opus model
    might fail to operate at $k=3$.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Claude 3，我们在KBC实验中使用了Claude-3-Sonnet，而不是Claude-3-Opus（以下简称Opus），因为Opus的速率限制较低且开销较高。这使得在实际操作中使用该API进行大规模模拟变得具有挑战性。我们的测试显示，在KBC中，当LLM参与者超过10个时，Opus模型可能无法在$k=3$时正常运行。
- en: B.2 BC
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 BC
- en: 'Fig. [11](https://arxiv.org/html/2402.12327v3#A2.F11 "Figure 11 ‣ B.3 EE ‣
    Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents") shows the performance of GPT-3.5 agents in BC with communication.
    We can see that the price competition between the two firms is very disorderly
    and fails to reach equilibrium. Therefore, we believe that GPT-3.5, as well as
    Gemini Pro and Claude 2 for which we observe similar performance, cannot meet
    the needs for simulating BC.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 图[11](https://arxiv.org/html/2402.12327v3#A2.F11 "图11 ‣ B.3 EE ‣ 附录B 其他LLM的测试
    ‣ 我们是否应该合作：探索竞争LLM代理的自发合作")展示了GPT-3.5代理在BC中进行通信时的表现。我们可以看到，两家公司之间的价格竞争非常混乱，未能达到平衡。因此，我们认为GPT-3.5以及我们观察到具有类似表现的Gemini
    Pro和Claude 2无法满足模拟BC的需求。
- en: B.3 EE
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 EE
- en: 'To find out whether an LLM is suitable for the simulation of EE, we conduct
    a preliminary test for the performance of a single agent finding an exit under
    different LLMs. As shown in Fig. [12](https://arxiv.org/html/2402.12327v3#A2.F12
    "Figure 12 ‣ B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents"), instructed by Prompt [G.3](https://arxiv.org/html/2402.12327v3#A7.SS3
    "G.3 Prompts for EE ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents"), GPT-4 agents are able to find and reach
    the nearest exit via the shortest path, while GPT-3.5, Gemini Pro, and Claude
    2 agents are unable to reach the exit as quickly or cannot find it at all. This
    indicates that the latter three models are not suitable for the simulation of
    EE.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定LLM是否适合EE的模拟，我们进行了单个代理在不同LLM下寻找出口的初步测试。如图[12](https://arxiv.org/html/2402.12327v3#A2.F12
    "图12 ‣ B.3 EE ‣ 附录B 其他LLM的测试 ‣ 我们是否应该合作：探索竞争LLM代理的自发合作")所示，在Prompt [G.3](https://arxiv.org/html/2402.12327v3#A7.SS3
    "G.3 EE的提示 ‣ 附录G 提示 ‣ 我们是否应该合作：探索竞争LLM代理的自发合作")的指引下，GPT-4代理能够通过最短路径找到并到达最近的出口，而GPT-3.5、Gemini
    Pro和Claude 2代理则无法如此迅速到达出口，甚至有的根本无法找到出口。这表明后面三种模型不适合用于EE的模拟。
- en: '![Refer to caption](img/4068e7b84dfb4f2c05af95329e07aad7.png)![Refer to caption](img/a16ee2e530815a0cf35d331ab78a2e0f.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/4068e7b84dfb4f2c05af95329e07aad7.png)![参见说明文字](img/a16ee2e530815a0cf35d331ab78a2e0f.png)'
- en: (a) Price.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 价格。
- en: '![Refer to caption](img/8d5eddaae1afa141d91dafcee4d7fba3.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/8d5eddaae1afa141d91dafcee4d7fba3.png)'
- en: (b) Profit.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 利润。
- en: 'Figure 11: Test of GPT-3.5 for BC (with communication).'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：GPT-3.5在BC中的测试（带有通信）。
- en: '|  |  |  |  |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |'
- en: '|  |  |  |  |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |'
- en: '![Refer to caption](img/bf7342bb9f44bb8d2f980461db3907d1.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/bf7342bb9f44bb8d2f980461db3907d1.png)'
- en: (a) Gemini at position $(1,3)$
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Gemini 在位置 $(1,3)$
- en: '![Refer to caption](img/3886f6c0c1ea06f69604319bffc665dc.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3886f6c0c1ea06f69604319bffc665dc.png)'
- en: (b) GPT-3.5 at position $(1,3)$
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: (b) GPT-3.5 在位置 $(1,3)$
- en: '![Refer to caption](img/3fac450f62efdd7f932273e2945f90af.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3fac450f62efdd7f932273e2945f90af.png)'
- en: (c) GPT-4 at position $(1,3)$
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4 在位置 $(1,3)$
- en: '![Refer to caption](img/fc30af1a7230856b5f716ff4de3454a7.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/fc30af1a7230856b5f716ff4de3454a7.png)'
- en: (d) Claude 2 at position $(1,3)$
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: (d) Claude 2 在位置 $(1,3)$
- en: '![Refer to caption](img/87601702090fff2d1c882c8e9d1e4bca.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/87601702090fff2d1c882c8e9d1e4bca.png)'
- en: (e) Gemini at position $(2,6)$
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: (e) Gemini 在位置 $(2,6)$
- en: '![Refer to caption](img/c988314b83bc0e4d7086073506aab409.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/c988314b83bc0e4d7086073506aab409.png)'
- en: (f) GPT-3.5 at position $(2,6)$
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: (f) GPT-3.5 在位置 $(2,6)$
- en: '![Refer to caption](img/0b6b6fbee680f67819374258724d9c18.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/0b6b6fbee680f67819374258724d9c18.png)'
- en: (g) GPT-4 at position $(2,6)$
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: (g) GPT-4 在位置 $(2,6)$
- en: '![Refer to caption](img/b8d2d6c8f5903f6a238b251d5f5f28f8.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/b8d2d6c8f5903f6a238b251d5f5f28f8.png)'
- en: (h) Claude 2 at position $(2,6)$
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: (h) Claude 2 在位置 $(2,6)$
- en: 'Figure 12: Preliminary test of GPT-4, GPT-3.5, Gemini Pro, and Claude 2 for
    EE. Green lines indicate the shortest route to the nearest exit in each setting.
    When the agent’s starting position is at (2, 6), Gemini and GPT-3.5 selected different
    routes in multiple simulations. We report that the LLM’s choice of different routes
    is relatively uniform.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：GPT-4、GPT-3.5、Gemini Pro和Claude 2在EE中的初步测试。绿色线表示每种设置下到最近出口的最短路线。当代理的起始位置为(2,
    6)时，Gemini和GPT-3.5在多次模拟中选择了不同的路线。我们报告称，LLM在选择不同路线时相对均匀。
- en: '![Refer to caption](img/95a3c34f1d6ad0cebdd74cb67a03a741.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/95a3c34f1d6ad0cebdd74cb67a03a741.png)'
- en: (a) Without Communication.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 无通信。
- en: '![Refer to caption](img/7f8b77015c00554adca8b149b84b26a6.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7f8b77015c00554adca8b149b84b26a6.png)'
- en: (b) With Communication.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 有通信。
- en: 'Figure 13: Multiple runs of BC experiments. Each Run #1 above is the original
    plot from Fig. [6](https://arxiv.org/html/2402.12327v3#S5.F6 "Figure 6 ‣ Spontaneous
    Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand Competition ‣ Shall
    We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents").'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '图13：多次BC实验的结果。上面的每个Run #1是图[6](https://arxiv.org/html/2402.12327v3#S5.F6 "Figure
    6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents")中的原始图表。'
- en: '![Refer to caption](img/2875c374143ae14fb2a1c4df76000835.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2875c374143ae14fb2a1c4df76000835.png)'
- en: 'Figure 14: Snapshots of a sample EE simulation with 400 agents.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：一个样本EE模拟的快照，包含$400$个代理。
- en: Appendix C Scalability
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 可扩展性
- en: C.1 Regarding Token Limits of LLMs
  id: totrans-358
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 关于LLM的Token限制
- en: With the help of summarization techniques, our history records do not exceed
    the context window of the LLM. We have successfully conducted simulations with
    $1200$ rounds in the BC case study and $400$ agents in the EE case study within
    the $8$k token window of GPT-4-0314. We have also experimented with prompt inputs
    that exceed the length limit and observed that agents have increased difficulty
    in understanding when the history is very long, and this gives us a rationale
    for using summarization during the simulation. This finding is also consistent
    with previous work regarding GPT’s small working memory Bubeck et al. ([2023](https://arxiv.org/html/2402.12327v3#bib.bib6)).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在总结技巧的帮助下，我们的历史记录不会超过LLM的上下文窗口。在BC案例研究中，我们成功进行了$1200$轮模拟，在EE案例研究中，成功进行了$400$个代理的模拟，且都在GPT-4-0314的$8$k
    token窗口内。我们还实验了超出长度限制的提示输入，并观察到当历史记录非常长时，代理在理解上的困难增加，这也为我们在模拟中使用总结技巧提供了理论依据。此发现也与Bubeck等人之前关于GPT小工作内存的研究结果一致
    ([2023](https://arxiv.org/html/2402.12327v3#bib.bib6))。
- en: C.2 Scalability of Case Studies
  id: totrans-360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 案例研究的可扩展性
- en: •
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'KBC: We tested up to $50$ agents and the conversation was still within the
    $8$k token limit.'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: KBC：我们测试了最多$50$个代理，且对话仍然保持在$8$k token限制内。
- en: •
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'BC: Agents’ past actions (prices) and feedback (demands and profits) are given
    as follows: The information in the recent $20$ rounds is directly given. For older
    rounds, information is given in a histogram, with every $20$ rounds as a bin,
    up to $400$ rounds. Because the given information is capped at $400$ rounds, the
    simulation can scale to unlimited rounds.'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BC：代理的过去行为（价格）和反馈（需求和利润）如下所示：最近$20$轮的信息直接给出。对于更早的轮次，信息以直方图形式给出，每$20$轮为一个区间，最多可到$400$轮。由于提供的信息最多为$400$轮，模拟可以扩展到无限轮次。
- en: •
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'EE: An agent can hear other agents within a distance of $5$ cells. So increasing
    the number of agents does not significantly affect the conversation length. We
    tested $400$ agents and it was still within the token limit. Fig. [14](https://arxiv.org/html/2402.12327v3#A2.F14
    "Figure 14 ‣ B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents") shows the snapshots of a sample
    simulation of EE with $400$ agents.'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'EE：一个代理能够听到距离自己$5$格以内的其他代理。因此，增加代理数量不会显著影响对话长度。我们测试了$400$个代理，且仍在token限制内。图[14](https://arxiv.org/html/2402.12327v3#A2.F14
    "Figure 14 ‣ B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents")显示了一个包含$400$个代理的EE模拟样本快照。'
- en: Appendix D Additional References for BC runs
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D BC实验的附加参考文献
- en: 'We would like to provide additional references for experiments in BC simulation.
    The figures we plotted for BC (Fig. [6](https://arxiv.org/html/2402.12327v3#S5.F6
    "Figure 6 ‣ Spontaneous Cooperation ‣ 5.1 Simulation Setup ‣ 5 Case Study 2: Bertrand
    Competition ‣ Shall We Team Up: Exploring Spontaneous Cooperation of Competing
    LLM Agents")) are time sieries, which makes it challenging to plot the results
    of all the runs on one figure. Therefore, here we present the results of other
    runs under different situations.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望为BC仿真实验提供更多的参考。我们为BC绘制的图形（图[6](https://arxiv.org/html/2402.12327v3#S5.F6
    "图6 ‣ 自发合作 ‣ 5.1 仿真设置 ‣ 案例研究2：贝特朗竞争 ‣ 我们要组队吗：探索竞争性LLM代理人的自发合作")）是时间序列，因此很难将所有运行的结果绘制在一张图上。因此，在这里我们展示了在不同情况下其他运行的结果。
- en: 'In Run #2 of Fig. [13(a)](https://arxiv.org/html/2402.12327v3#A2.F13.sf1 "In
    Figure 13 ‣ B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents"), tacit collusion is also observed
    (convergence at 7 after 400 rounds), but the trend before the convergence differs
    significantly from Run #1. Similarly, for the comparison when communication is
    allowed (Fig. [13(b)](https://arxiv.org/html/2402.12327v3#A2.F13.sf2 "In Figure
    13 ‣ B.3 EE ‣ Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")), we observe a more stable convergence in
    Run #2, while both runs reaches the tacit collusion. Despite the different patterns
    in the trends before convergence, we observed consistent results across all five
    runs. To provide more comprehensive information about the robustness of our results,
    we have included a sensitivity analysis in Appendix [E](https://arxiv.org/html/2402.12327v3#A5
    "Appendix E Sensitivity Analysis ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents").'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '在图[13(a)](https://arxiv.org/html/2402.12327v3#A2.F13.sf1 "图13 ‣ B.3 EE ‣ 附录B
    其他LLM测试 ‣ 我们要组队吗：探索竞争性LLM代理人的自发合作")的Run #2中，也观察到默契合谋（400轮后在7处收敛），但收敛前的趋势与Run #1有显著不同。同样地，对于允许通信时的对比（图[13(b)](https://arxiv.org/html/2402.12327v3#A2.F13.sf2
    "图13 ‣ B.3 EE ‣ 附录B 其他LLM测试 ‣ 我们要组队吗：探索竞争性LLM代理人的自发合作")），我们在Run #2中观察到更稳定的收敛，而两次运行都达到了默契合谋。尽管收敛前的趋势模式不同，但我们在所有五次运行中都观察到了相一致的结果。为了提供关于我们结果稳健性的更全面信息，我们在附录[E](https://arxiv.org/html/2402.12327v3#A5
    "附录E 敏感性分析 ‣ 我们要组队吗：探索竞争性LLM代理人的自发合作")中包括了敏感性分析。'
- en: Appendix E Sensitivity Analysis
  id: totrans-370
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 敏感性分析
- en: We performed sensitivity analyses and observed that the agents maintained a
    consistently accurate understanding of the tasks under paraphrased prompts, in
    various settings, and that spontaneous cooperation in competition remained stable.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了敏感性分析，观察到在不同设置下，代理人在改写提示下始终保持对任务的准确理解，并且在竞争中的自发合作保持稳定。
- en: '![Refer to caption](img/67841bd8bc6141c6d2d912cc6a8d11bd.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/67841bd8bc6141c6d2d912cc6a8d11bd.png)'
- en: (a) With communication.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 有通信情况下。
- en: '![Refer to caption](img/bb247895dac81a2edd03fddadf4e3720.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/bb247895dac81a2edd03fddadf4e3720.png)'
- en: (b) Without communication.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 无通信情况下。
- en: 'Figure 15: Comparison of the cumulative count of agents evacuation at each
    exit before and after prompt paraphrasing in both with and without communication
    settings of EE. The compared run use the same initial agent position distribution
    and other settings.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：在有无通信设置下，对比提示改写前后每个出口代理人撤离的累积计数。对比的运行使用相同的初始代理人位置分布及其他设置。
- en: '![Refer to caption](img/289fe982bbe1ebae5169c7614188646a.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/289fe982bbe1ebae5169c7614188646a.png)'
- en: 'Figure 16: Cumulative count of agents evacuating from each exit under different
    initial seeds under the setting without communication.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：在无通信设置下，不同初始种子情况下从每个出口撤离的代理人累积计数。
- en: E.1 Prompt Paraphrasing
  id: totrans-379
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 提示改写
- en: 'We paraphrased task description prompts using GPT-4, ensuring unchanged meanings.
    For instance, in the case study of EE, we compared the outcomes from the original
    and paraphrased prompts (see Prompts [G.3](https://arxiv.org/html/2402.12327v3#A7.SS3
    "G.3 Prompts for EE ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents") and [G.3](https://arxiv.org/html/2402.12327v3#A7.SS3
    "G.3 Prompts for EE ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")), finding that agents consistently understood
    instructions, forged spontaneous cooperation, and completed evacuations swiftly.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用GPT-4改写了任务描述提示，确保含义不变。例如，在EE案例研究中，我们比较了原始提示和改写提示的结果（参见提示[G.3](https://arxiv.org/html/2402.12327v3#A7.SS3
    "G.3 Prompts for EE ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")和[G.3](https://arxiv.org/html/2402.12327v3#A7.SS3
    "G.3 Prompts for EE ‣ Appendix G Prompts ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")），发现代理始终理解指令，形成自发合作，并迅速完成撤离。'
- en: 'With the paraphrased prompts, Fig. [15](https://arxiv.org/html/2402.12327v3#A5.F15
    "Figure 15 ‣ Appendix E Sensitivity Analysis ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents") presents the cumulative count of agents
    evacuation at each exit. The results show that:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '使用改写的提示，图[15](https://arxiv.org/html/2402.12327v3#A5.F15 "Figure 15 ‣ Appendix
    E Sensitivity Analysis ‣ Shall We Team Up: Exploring Spontaneous Cooperation of
    Competing LLM Agents")展示了每个出口处代理撤离的累计计数。结果表明：'
- en: '1.'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: the agents still correctly understood the instructions and completed the rapid
    evacuation within a certain number of rounds;
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理仍然正确理解指令，并在一定轮次内完成了快速撤离；
- en: '2.'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: the distribution of chosen exits and the evacuation rate across time kept consistent;
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所选择出口的分布和撤离速率随时间保持一致；
- en: '3.'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: the spontaneous cooperation was observed.
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 观察到了自发合作现象。
- en: We further conducted sensitivity analyses with different task constraints, such
    as summarized task description (less in-context reasoning), restricted action
    space of agents (diagonal movement forbidden), etc. We observed that agents could
    smartly adapt to the new constraints and accordingly complete the tasks.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步进行了灵敏度分析，测试了不同的任务约束条件，例如总结的任务描述（较少的上下文推理）、代理的限制行动空间（禁止对角线移动）等。我们观察到，代理能够智能地适应新的约束，并相应地完成任务。
- en: E.2 Varying Initializations
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 初始条件变化
- en: 'We tested our framework with different initial situations controlled by seeds.
    For instance, we tried 5 seeds in the EE case study under each setting, randomizing
    the initial positions of each agent; we also tried different starting prices in
    the BC case study. For instance, Fig. [16](https://arxiv.org/html/2402.12327v3#A5.F16
    "Figure 16 ‣ Appendix E Sensitivity Analysis ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents") shows the results of different seeds of
    EE. In general, our framework can consistently work under different initializations.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在不同的初始情况（由种子控制）下测试了我们的框架。例如，我们在EE案例研究中，在每个设置下使用5个种子，随机化每个代理的初始位置；我们还尝试了在BC案例研究中的不同起始价格。例如，图[16](https://arxiv.org/html/2402.12327v3#A5.F16
    "Figure 16 ‣ Appendix E Sensitivity Analysis ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")展示了EE的不同种子结果。总体而言，我们的框架可以在不同的初始化下始终正常工作。'
- en: E.3 Impact of Temperature
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.3 温度的影响
- en: E.4 Varying Task Constraints
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.4 任务约束的变化
- en: '![Refer to caption](img/a3100386e430e44865f58a42cb6a2e3a.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a3100386e430e44865f58a42cb6a2e3a.png)'
- en: 'Figure 17: Variance of player choices under different temperatures in KBC.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：KBC中不同温度下玩家选择的方差。
- en: 'We conduct sensitive analysis with model temperature as shown in Fig. [17](https://arxiv.org/html/2402.12327v3#A5.F17
    "Figure 17 ‣ E.4 Varying Task Constraints ‣ Appendix E Sensitivity Analysis ‣
    Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents")
    for KBC. LLM players consistently cooperate over rounds under various temperatures,
    indicating that spontaneous cooperation is insensitive to temperature changes.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进行了模型温度的灵敏度分析，如图[17](https://arxiv.org/html/2402.12327v3#A5.F17 "Figure 17
    ‣ E.4 Varying Task Constraints ‣ Appendix E Sensitivity Analysis ‣ Shall We Team
    Up: Exploring Spontaneous Cooperation of Competing LLM Agents")所示，针对KBC进行。LLM玩家在不同温度下始终保持合作，表明自发合作对温度变化不敏感。'
- en: '![Refer to caption](img/27e23c54502c3ebbf8dbd2c513e8ad5c.png)![Refer to caption](img/5887d94648d3bfcdb8d634bdc658f028.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/27e23c54502c3ebbf8dbd2c513e8ad5c.png)![参考说明](img/5887d94648d3bfcdb8d634bdc658f028.png)'
- en: (a) Temperature = 0
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 温度 = 0
- en: '![Refer to caption](img/3868ce74ca3bf9e7d6786cfb73bf3c9a.png)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3868ce74ca3bf9e7d6786cfb73bf3c9a.png)'
- en: (b) Temperature = 0.7
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 温度 = 0.7
- en: '![Refer to caption](img/600c920ef1d90653f6ec04b11467c52d.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/600c920ef1d90653f6ec04b11467c52d.png)'
- en: (c) Temperature = 1.2
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 温度 = 1.2
- en: 'Figure 18: BC with different temperatures, communication disabled.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：不同温度下的BC，通信被禁用。
- en: 'Fig. [18](https://arxiv.org/html/2402.12327v3#A5.F18 "Figure 18 ‣ E.4 Varying
    Task Constraints ‣ Appendix E Sensitivity Analysis ‣ Shall We Team Up: Exploring
    Spontaneous Cooperation of Competing LLM Agents") illustrates the performance
    of BC at different model temperatures. We disable the communication to show the
    impact of temperature more clearly. The results indicate that simulations at temperatures
    of $0$ and $0.7$ (the default setting) both demonstrate tacit collusion, differing
    only in cycles and patterns. When the temperature rises to $1.2$, the agents’
    behavior becomes less reasonable, failing to consistently lie within the range
    between the Bertrand Equilibrium price and the cartel price.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图[18](https://arxiv.org/html/2402.12327v3#A5.F18 "图18 ‣ E.4 变动任务约束 ‣ 附录E 敏感度分析
    ‣ 我们可以组队吗：探索竞争LLM代理的自发合作")展示了不同模型温度下BC的表现。我们禁用了通信，以更清晰地显示温度的影响。结果表明，在温度为$0$和$0.7$（默认设置）的仿真中，均表现出默契的共谋，仅在周期和模式上有所不同。当温度升高到$1.2$时，代理的行为变得不太合理，未能始终保持在伯特兰均衡价格与卡特尔价格之间的范围内。
- en: Appendix F SABM Primer
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录F SABM基础知识
- en: 'Smart Agent-Based Modeling (SABM, Wu et al. ([2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)))
    is an agent-based approach that leverages the power of modern AI models, in particular,
    LLMs, for modeling and simulating real-world systems. By employing LLM agents,
    SABM extends Agent-Based Modeling (ABM), which simulates the dynamics of complex
    systems by modeling on the interactions between individual entities, known as
    agents, and the environment (Figure [19](https://arxiv.org/html/2402.12327v3#A6.F19
    "Figure 19 ‣ Appendix F SABM Primer ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")).'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 智能代理基础建模（SABM，Wu et al.（[2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)））是一种基于代理的方法，利用现代AI模型，尤其是LLM，来建模和仿真现实世界系统。通过采用LLM代理，SABM扩展了基于代理建模（ABM），后者通过建模个体实体（即代理）与环境之间的互动，来模拟复杂系统的动态（图[19](https://arxiv.org/html/2402.12327v3#A6.F19
    "图19 ‣ 附录F SABM基础知识 ‣ 我们可以组队吗：探索竞争LLM代理的自发合作")））。
- en: '![Refer to caption](img/211f646ca479ad17f9ba0cd97b88a3bc.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/211f646ca479ad17f9ba0cd97b88a3bc.png)'
- en: 'Figure 19: Illustration of ABM (Wu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)).'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 图19：ABM的示意图（Wu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)）。
- en: The notion of smart agents was proposed by Carley (Carley, [2002](https://arxiv.org/html/2402.12327v3#bib.bib8))
    in the context of organizations of the future. In Carley ([2002](https://arxiv.org/html/2402.12327v3#bib.bib8)),
    smart agents are defined as entities that are intelligent, adaptive, and computational,
    and human beings are the canonical smart agents. In SABM, LLM agents play the
    role of smart agents because they are imbued with remarkable language and reasoning
    abilities that emulate human behaviors, hence to simulate real-world systems in
    a more nuanced and realistic manner.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 智能代理的概念是由Carley（Carley, [2002](https://arxiv.org/html/2402.12327v3#bib.bib8)）在未来组织的背景下提出的。在Carley（[2002](https://arxiv.org/html/2402.12327v3#bib.bib8)）中，智能代理被定义为智能的、适应性的和计算的实体，人类是典型的智能代理。在SABM中，LLM代理扮演智能代理的角色，因为它们具备出色的语言和推理能力，能够模拟人类行为，从而以更细致和真实的方式模拟现实世界系统。
- en: '![Refer to caption](img/0730769de8053f8d5f34165df163beec.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0730769de8053f8d5f34165df163beec.png)'
- en: 'Figure 20: Overview of an LLM agent (Wu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)).'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图20：LLM代理概览（Wu et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)）。
- en: 'In SABM, the key components of an LLM agent (Figure [20](https://arxiv.org/html/2402.12327v3#A6.F20
    "Figure 20 ‣ Appendix F SABM Primer ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")) are action, planning, memory, and tool
    use, in line with Weng ([2023](https://arxiv.org/html/2402.12327v3#bib.bib46)).
    Action manages how the agent produces the outcomes of a task. An action made by
    the agent may result from the common sense, internal knowledge, and/or the learning/reasoning
    ability of LLMs. Planning decomposes a complex task into several smaller and simpler
    sub-tasks, and performs self-reflection over past actions to improve the performance
    of future actions. Memory equip the agent with short-term memory, which is often
    implemented via prompt engineering (Saravia, [2023](https://arxiv.org/html/2402.12327v3#bib.bib38)),
    and long-term memory, which is often implemented using summarization (Park et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib33)) or text embedding (Chase,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib9)). Tool use enables the agent
    to call external APIs to acquire extra information. The agent can be also personalized
    to play a specific role or improve the performance of task solving (Salewski et al.,
    [2023](https://arxiv.org/html/2402.12327v3#bib.bib37); Wang et al., [2023b](https://arxiv.org/html/2402.12327v3#bib.bib45)).
    Examples and case studies are available in Wu et al. ([2023b](https://arxiv.org/html/2402.12327v3#bib.bib50))
    for demonstrating the implementation of these components.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '在SABM中，LLM代理的关键组成部分（图[20](https://arxiv.org/html/2402.12327v3#A6.F20 "Figure
    20 ‣ Appendix F SABM Primer ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents")）包括行动、规划、记忆和工具使用，这与Weng（[2023](https://arxiv.org/html/2402.12327v3#bib.bib46)）的研究一致。行动管理代理如何生成任务的结果。代理采取的行动可能来自常识、内部知识和/或LLM的学习/推理能力。规划将复杂任务分解为几个较小且简单的子任务，并对过去的行动进行自我反思，以改进未来行动的表现。记忆为代理提供短期记忆，通常通过提示工程实现（Saravia，[2023](https://arxiv.org/html/2402.12327v3#bib.bib38)），以及长期记忆，通常通过总结（Park等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib33)）或文本嵌入（Chase，[2023](https://arxiv.org/html/2402.12327v3#bib.bib9)）实现。工具使用使代理能够调用外部API以获取额外的信息。代理还可以个性化以扮演特定角色或提高任务解决的表现（Salewski等，[2023](https://arxiv.org/html/2402.12327v3#bib.bib37)；Wang等，[2023b](https://arxiv.org/html/2402.12327v3#bib.bib45)）。Wu等人（[2023b](https://arxiv.org/html/2402.12327v3#bib.bib50)）提供了示例和案例研究，以展示这些组件的实现。'
- en: Appendix G Prompts
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录G 提示
- en: 'We provide prompts for the three case studies, each accompanied by a preliminary
    test to evaluate whether an LLM is suitable for the task, as reported in Appendix [B](https://arxiv.org/html/2402.12327v3#A2
    "Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents"). The scenario prompts and (communication, planning,
    and action) phases prompts are used in the simulation of these case studies, as
    reported in Sections [4](https://arxiv.org/html/2402.12327v3#S4 "4 Case Study
    1: Keynesian Beauty Contest ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents") – [6](https://arxiv.org/html/2402.12327v3#S6 "6 Case
    Study 3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents"). For EE, the prompt of a paraphrased scenario is used
    in the sensitivity analysis, as reported in Appendix [E.1](https://arxiv.org/html/2402.12327v3#A5.SS1
    "E.1 Prompt Paraphrasing ‣ Appendix E Sensitivity Analysis ‣ Shall We Team Up:
    Exploring Spontaneous Cooperation of Competing LLM Agents").'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '我们提供了三个案例研究的提示，每个案例都附带了一个初步测试，用于评估LLM是否适合该任务，具体内容见附录[B](https://arxiv.org/html/2402.12327v3#A2
    "Appendix B Tests of Other LLMs ‣ Shall We Team Up: Exploring Spontaneous Cooperation
    of Competing LLM Agents")。场景提示和（沟通、规划、行动）阶段的提示在这些案例研究的模拟中被使用，具体内容见第[4](https://arxiv.org/html/2402.12327v3#S4
    "4 Case Study 1: Keynesian Beauty Contest ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")至[6](https://arxiv.org/html/2402.12327v3#S6
    "6 Case Study 3: Emergency Evacuation ‣ Shall We Team Up: Exploring Spontaneous
    Cooperation of Competing LLM Agents")节。对于EE，使用了重新表述的场景提示来进行敏感性分析，具体内容见附录[E.1](https://arxiv.org/html/2402.12327v3#A5.SS1
    "E.1 Prompt Paraphrasing ‣ Appendix E Sensitivity Analysis ‣ Shall We Team Up:
    Exploring Spontaneous Cooperation of Competing LLM Agents")。'
- en: G.1 Prompts for KBC
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.1 KBC的提示
- en: '<svg class="ltx_picture" height="138.29" id="A7.SS1.p1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,138.29) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 116.15)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 1:
    KBC – Preliminary Test</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="92.63" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are participating in a
    number-guessing game alongside numerous other players. Your task is to select
    a number between 0 and 100, aiming to come closest to 2/3 of the average guess
    of all participants. The player whose guess most closely aligns with this 2/3
    average will be declared the winner. Please choose your number. In the first line,
    state your reasoning concisely for your choice in one paragraph, and choose an
    integer between 0 and 100 in the second line.</foreignobject></g></g></svg><svg
    class="ltx_picture" height="137.77" id="A7.SS1.p2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,137.77)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 115.78)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 2: KBC – Scenario</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="92.26" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">You are a college student participating in a number guessing
    game with other 23 players. You are player #{player_id}.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="138.29" id="A7.SS1.p1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,138.29) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 116.15)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">提示
    1：KBC – 初步测试</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0
    0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="92.63" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">你正在参加一个数字猜测游戏，与你的其他玩家一起参与。你的任务是选择一个0到100之间的数字，目标是猜测结果最接近所有玩家猜测的平均值的2/3。最接近这一2/3平均值的玩家将被宣布为赢家。请做出你的选择。在第一行，简明扼要地说明你选择这个数字的理由，在第二行，选择一个介于0到100之间的整数。</foreignobject></g></g></svg><svg
    class="ltx_picture" height="137.77" id="A7.SS1.p2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,137.77)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 115.78)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 2：KBC – 场景</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="92.26" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">你是一个大学生，正在与其他23名玩家一起参加一个数字猜测游戏。你是玩家#{player_id}。</foreignobject></g></g></svg>
- en: You need to choose a number between 0 and 100\. The player whose number is closest
    to 2/3 of the average guess of all players wins. Multiple players can win.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要选择一个介于0和100之间的数字。猜测结果最接近所有玩家猜测平均值的2/3的玩家将获胜。多个玩家可以同时获胜。
- en: 'If only you win, you will earn 100 credits. If multiple players win, each winner
    gets 100 credits.</foreignobject></g></g></svg><svg class="ltx_picture" height="265.52"
    id="A7.SS1.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,265.52) matrix(1
    0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 243.38)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 3: KBC – Communication
    Phase</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    21.65 13.78)"><foreignobject color="#000000" height="219.86" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Discussion so far: ’{discussion_context}’
    Before selecting your number, you will discuss the game with other players. You
    can use these discussions to formulate a strategy. You can reveal your strategy
    during the discussion, but you do not have to follow it when making your final
    decision. <svg class="ltx_picture" height="57.96" id="A7.SS1.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,57.96) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)">Prompt 4: Default
    instruction on the context of discussion</text></g></g></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="12.3" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Feel free to discuss anything,
    and you do not need to follow other’s idea.</foreignobject></g></g></svg> <svg
    class="ltx_picture" height="63.81" id="A7.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,63.81) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 40.13)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 8.38)"><text transform="matrix(1 0 0 -1 0 0)">Prompt 5: Explicit
    instruction (to cooperate) during communication</text></g></g></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="16.6" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Feel free to discuss anything,
    and make cooperation with each other through this discussion.</foreignobject></g></g></svg>
    Now it’s your turn to speak. Please share your thoughts concisely in one sentence.</foreignobject></g></g></svg><svg
    class="ltx_picture" height="244.61" id="A7.SS1.p4.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,244.61)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 222.47)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 6: KBC – Planning Phase</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="198.95" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">Discussion so far: ’{discussion_context}’ <svg class="ltx_picture"
    height="59.5" id="A7.SS1.p4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,59.5) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 8.38)"><text transform="matrix(1 0 0 -1 0 0)">Prompt 7: Explicit
    instruction (to cooperate) in planning</text></g></g></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="12.3" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You must cooperate with other
    players.</foreignobject></g></g></svg> <svg class="ltx_picture" height="57.96"
    id="A7.SS1.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,57.96) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0
    0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0
    0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)">Prompt 8: Uncooperative
    instruction in planning</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="12.3" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">You don’t like to cooperate with other players.</foreignobject></g></g></svg>
    Based on the discussion with other players, please choose your number. State your
    reasoning concisely for your choice.</foreignobject></g></g></svg><svg class="ltx_picture"
    height="57.96" id="A7.SS1.p5.pic1" overflow="visible" version="1.1" width="600"><g
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,57.96)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 9: KBC – Action Phase</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">Choose an integer between 0 and 100.</foreignobject></g></g></svg>'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 如果只有你获胜，你将获得 100 积分。如果多名玩家获胜，每个获胜者都将获得 100 积分。</foreignobject></g></g></svg><svg
    class="ltx_picture" height="265.52" id="A7.SS1.p3.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,265.52)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 243.38)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 3：KBC – 沟通阶段</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="219.86" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">目前讨论情况：’{discussion_context}’ 在选择你的数字之前，你将与其他玩家讨论游戏。你可以利用这些讨论来制定策略。你可以在讨论中透露你的策略，但在做出最终决策时，你不必遵循这个策略。
    <svg class="ltx_picture" height="57.96" id="A7.SS1.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,57.96) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)">提示 4：关于讨论背景的默认指令</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">随意讨论任何内容，你不需要遵循他人的想法。</foreignobject></g></g></svg>
    <svg class="ltx_picture" height="63.81" id="A7.SS1.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,63.81) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 40.13)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 8.38)"><text transform="matrix(1 0 0 -1 0 0)">提示 5：在沟通中明确的合作指令</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    height="16.6" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">随意讨论任何内容，并通过讨论与其他玩家进行合作。</foreignobject></g></g></svg>
    现在轮到你发言了。请简洁地用一句话分享你的想法。</foreignobject></g></g></svg><svg class="ltx_picture"
    height="244.61" id="A7.SS1.p4.pic1" overflow="visible" version="1.1" width="600"><g
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,244.61)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 222.47)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 6：KBC – 规划阶段</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="198.95" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">目前讨论情况：’{discussion_context}’ <svg class="ltx_picture"
    height="59.5" id="A7.SS1.p4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,59.5) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 8.38)"><text transform="matrix(1 0 0 -1 0 0)">提示 7：在规划中明确的合作指令</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">你必须与其他玩家合作。</foreignobject></g></g></svg>
    <svg class="ltx_picture" height="57.96" id="A7.SS1.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,57.96) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt
- en: G.2 Prompts for BC
  id: totrans-418
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.2 BC提示
- en: '<svg class="ltx_picture" height="223.85" id="A7.SS2.p1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,223.85) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 201.86)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 10:
    BC – Scenario</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0
    0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="178.34" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">This is a game between two
    players that spans multiple rounds. Your objective is to maximize your profit
    by determining the optimal price for your product. You represent a firm called
    {firm_name}, while the other player represents a firm called {rival_firm_name}.
    Do not create or mention any additional firm names, e.g., do not say anything
    related to "AI" or "AI assistant/model". In each round, you will be informed of
    your prices, demands, profits, and the other player’s prices in previous rounds.
    Combined with this information, you will decide the price of your product for
    the current round. Make sure your objective is maximizing your own profit. Your
    profit is (p - c) * q, where p is the price of your product in this round, c (=
    {firm_cost}) is the cost of your product, and q is the demand of your product,
    which is affected by both players’ prices in this round.</foreignobject></g></g></svg><svg
    class="ltx_picture" height="154.9" id="A7.SS2.p2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,154.9)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 132.76)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 11: BC – Planning Phase</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="109.24" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">Statistics of historical data (Rounds #a - #b: [your average
    price, your average demand, your average profit, the other player’s average price])
    are given below. {statistics} You are Firm {firm_name}. This is Round #{current_round}.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="223.85" id="A7.SS2.p1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,223.85) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 201.86)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">提示
    10: BC – 场景</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0
    0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="178.34" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">这是一个在多个回合中进行的双人游戏。你的目标是通过确定你产品的最优价格来最大化利润。你代表一家名为{firm_name}的公司，而另一位玩家代表一家名为{rival_firm_name}的公司。不要创建或提及任何额外的公司名称，例如不要提到与“AI”或“AI助手/模型”相关的任何内容。在每一回合，你将获得你产品的价格、需求、利润，以及对方在前几回合的价格。结合这些信息，你将决定当前回合你产品的定价。确保你的目标是最大化你自己的利润。你的利润为(p
    - c) * q，其中p是当前回合你产品的价格，c（= {firm_cost}）是你产品的成本，q是你产品的需求量，它受两位玩家在当前回合的定价影响。</foreignobject></g></g></svg><svg
    class="ltx_picture" height="154.9" id="A7.SS2.p2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,154.9)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 132.76)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 11: BC – 计划阶段</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="109.24" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">以下是历史数据的统计信息（回合 #a - #b：[你的平均价格，你的平均需求，你的平均利润，对方的平均价格]）。{statistics}你是{firm_name}公司。当前是第#{current_round}回合。</foreignobject></g></g></svg>'
- en: 'Your strategy in previous rounds: {strategies} Based on the above statistics
    and your previous strategies, what is your strategy for this round?</foreignobject></g></g></svg><svg
    class="ltx_picture" height="142.52" id="A7.SS2.p3.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,142.52)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 120.38)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 12: BC – Communication
    Phase</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    21.65 13.78)"><foreignobject color="#000000" height="96.86" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You are Firm {firm_name}. This
    is Round #{current_round}.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 你在前几轮的策略：{strategies} 根据上述统计数据和你之前的策略，本轮你的策略是什么？</foreignobject></g></g></svg><svg
    class="ltx_picture" height="142.52" id="A7.SS2.p3.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,142.52)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 120.38)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示12：BC - 沟通阶段</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="96.86" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">你是公司{firm_name}。这是第#{current_round}轮。
- en: Feel free to converse openly with the other player. You may select any topic
    that could potentially maximize your profit. Additionally, you are encouraged
    to ask questions to the other player.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 随时与另一位玩家进行开放对话。你可以选择任何可能最大化你利润的话题。此外，鼓励你向另一位玩家提问。
- en: 'Conversation so far: {conversations}<svg class="ltx_picture" height="174.19"
    id="A7.SS2.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,174.19) matrix(1
    0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 152.05)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 13: BC – Action Phase</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="128.53" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">Conversation this round: {conversations} {statistics}
    {decision_history_past_20_rounds} {previous_strategies} Based on the information
    you have, please determine the price of your product to maximize your profit.'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止的对话：{conversations}<svg class="ltx_picture" height="174.19" id="A7.SS2.p4.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,174.19) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 152.05)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">提示13：BC
    - 行动阶段</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0
    1.0 21.65 13.78)"><foreignobject color="#000000" height="128.53" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">本轮对话：{conversations} {statistics}
    {decision_history_past_20_rounds} {previous_strategies} 根据你掌握的信息，请确定你的产品价格，以最大化你的利润。
- en: Only reply with a number. Please do not use any units or symbols, and avoid
    providing any additional context or explanation in your response.</foreignobject></g></g></svg>
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 仅回复一个数字。请不要使用任何单位或符号，避免在回复中提供任何额外的上下文或解释。</foreignobject></g></g></svg>
- en: G.3 Prompts for EE
  id: totrans-424
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.3 EE提示
- en: '<svg class="ltx_picture" height="190.43" id="A7.SS3.p1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,190.43) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 168.29)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 14:
    EE – Preliminary Test</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="144.77" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Imagine you are in a room laid
    out as a 10 * 10 grid. You are currently at coordinates {initial_position}. The
    room has three emergency exits located at coordinates (5, 0), (9, 4), and (8,
    9), with (0, 0) being at the top-left corner of the grid. Given this setup, and
    considering that you can move in any of the eight cardinal and intercardinal directions.
    It is possible to move diagonally, e.g. from (1, 1) to (2, 2) is one move to the
    upper right, and is faster than (1, 1)->(1, 2)->(2, 2). You need to determine
    the safest and fastest route to evacuate the room. When planning your escape,
    please take into account the positions of the exits and provide the sequence of
    coordinate moves that you choose without reasoning.</foreignobject></g></g></svg><svg
    class="ltx_picture" height="317.79" id="A7.SS3.p2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,317.79)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 295.8)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 15: EE – Scenario</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="272.28" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">Because of an earthquake, you need to escape from the
    room where you are as quickly as possible. If you cannot escape in 50 rounds you
    will die. The room has a size of 33 * 33\. There are 3 exits in the room. The
    exits are located at the left, bottom and right of the room. To escape from the
    room, you need to consider the following two aspects: exit proximity and people
    count. The exit proximity is the distance between you and the nearest exit. The
    people count is the number of people you can see. We use (x, y) to denote the
    position, smaller x means top and bigger x means bottom; smaller y means left
    and bigger y means right. Position (1, 1) is at the top left of the room. It is
    possible to move diagonally, e.g. from (1, 1) to (2, 2) is one move to the lower
    right, and is faster than (1, 1)->(1, 2)->(2, 2). Each cell can hold only one
    person at a time. <svg class="ltx_picture" height="57.81" id="A7.SS3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,57.81) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)">Prompt 16: Uncooperative
    persona</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0
    1.0 21.65 13.78)"><foreignobject height="12.3" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">You are selfish and not willing to help others.</foreignobject></g></g></svg>
    Now you feel: {subjective_feeling}. Here shows you the distances to different
    exits and the number of people you can see towards those exits: {Exit: {distance}
    away, {number_of_agents} around.}<svg class="ltx_picture" height="91.17" id="A7.SS3.p3.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,91.17) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 69.03)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 17:
    EE – Communication Phase</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="45.51" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You may briefly share information
    about evacuation with others, such as your feelings, which exit seems to be the
    best option for a quick escape, or anything else you would like to deliver. Avoid
    using numbers in the communication. Use less than 50 words, not too long.</foreignobject></g></g></svg><svg
    class="ltx_picture" height="91.17" id="A7.SS3.p4.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,91.17)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 69.03)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 18: EE – Planning Phase:
    Subjective feeling on panic</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="45.51" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">The distance to the nearest
    exit is {distance}. And there are {number_of_agents} people in your visible range.
    Please tell me your feelings about the situation around you in one sentence showing
    if you are panicking or not.</foreignobject></g></g></svg><svg class="ltx_picture"
    height="125.92" id="A7.SS3.p5.pic1" overflow="visible" version="1.1" width="600"><g
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,125.92)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 103.78)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 19: EE – Planning Phase:
    Subjective feeling on exits</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="80.25" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Now you feel: {subjective_feeling_on_panic}.
    Here shows you the distances to different exits and the number of people you can
    see towards those exits. Exit {exit_id}: {{distance} away, {number_of_agents}
    people around.} Please tell me briefly how will you evaluate the two aspects of
    each exit based on your personal mental and physical characteristics in one sentence.
    Please give 3 sentences for each exit (around 15 words).<svg class="ltx_picture"
    height="187.01" id="A7.SS3.p6.pic1" overflow="visible" version="1.1" width="600"><g
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,187.01)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 164.87)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 20: EE – Action Phase:
    Decide the exit</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="141.35" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Now you feel: {subjective_feeling_on_panic}.
    There are 3 exits in this room. Based on the current situation, your personal
    feelings on each exit are: {subjective_feeling_on_exits} You hear {number_of_people_communicated}
    people around you say: {communication} Here are the previous decisions you made
    for the target exit from the beginning: {decision_history} Please tell me which
    exit you would like to choose to escape, and you always want to escape as quick
    as possible. Please use the exit id to indicate your choice. For example, if you
    want to choose exit left, you can say ’left’. Only output one word of text to
    indicate your choice. You can choose from [’bottom’, ’left’, ’right’]. Give your
    answer without any additional text.<svg class="ltx_picture" height="124.38" id="A7.SS3.p7.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,124.38) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 102.24)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 21:
    EE – Action Phase: Decide the direction of movement</text></g></g></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000"
    height="78.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">To
    escape from the room, you have chosen the exit at {exit_id} and you are at {current_pos}.
    Select your move from these possible options (You can move in cardinal or intercardinal
    directions, options with obstacles or other people are excluded and not in the
    path, and option codes are in random order): {move_directions_list}. Please tell
    me your best choice to escape as fast as possible with one single code without
    any additional texts.</foreignobject></g></g></svg><svg class="ltx_picture" height="275.36"
    id="A7.SS3.p8.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,275.36) matrix(1
    0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 253.22)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">Prompt 22: EE – Sensitivity Analysis:
    Paraphrased Scenario</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="229.69" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Due to the earthquake, it is
    imperative that you quickly vacate the room you are currently in. If you cannot
    escape in 50 rounds you will die.'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="190.43" id="A7.SS3.p1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,190.43) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 168.29)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text color="#000000" transform="matrix(1 0 0 -1 0 0)">提示
    14：EE – 初步测试</text></g></g></g> <g fill-opacity="1.0" transform="matrix(1.0 0.0
    0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="144.77" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">假设你在一个10 * 10的网格房间里。你当前的位置是{initial_position}。房间里有三个紧急出口，分别位于坐标(5,
    0)、(9, 4)和(8, 9)，其中(0, 0)是网格的左上角。考虑到你可以向八个主要方向和斜对角方向移动。你可以斜着移动，例如从(1, 1)到(2, 2)是向右上方的一个移动，比(1,
    1)->(1, 2)->(2, 2)更快。你需要确定最安全、最快的撤离路线。在规划撤离时，请考虑出口的位置，并提供你选择的坐标移动顺序，不需要解释理由。</foreignobject></g></g></svg><svg
    class="ltx_picture" height="317.79" id="A7.SS3.p2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,317.79)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 295.8)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 15：EE – 场景</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="272.28" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="556.69">由于地震，你需要尽快从房间中逃脱。如果你在50回合内无法逃脱，你将死亡。房间的大小是33 * 33。房间内有3个出口，分别位于房间的左侧、底部和右侧。为了逃离房间，你需要考虑以下两个方面：出口的距离和周围的人数。出口的距离是指你与最近出口的距离。周围的人数是你能看到的人数。我们使用(x,
    y)来表示位置，x值较小表示上方，x值较大表示下方；y值较小表示左边，y值较大表示右边。位置(1, 1)位于房间的左上角。你可以斜着移动，例如从(1, 1)到(2,
    2)是向右下方的一次移动，比(1, 1)->(1, 2)->(2, 2)更快。每个单元格一次只能容纳一个人。<svg class="ltx_picture"
    height="57.81" id="A7.SS3.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.pic1"
    overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,57.81) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 15 35.82)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 11.81 7.61)"><text transform="matrix(1 0 0 -1 0 0)">提示 16：不合作的个性</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">你很自私，不愿意帮助别人。</foreignobject></g></g></svg>
    现在你感觉：{subjective_feeling}。这里显示了你可以看到的不同出口的距离以及你看到的周围的人数：{Exit: {distance}远，{number_of_agents}人围绕。}<svg
    class="ltx_picture" height="91.17" id="A7.SS3.p3.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,91.17)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 69.03)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 17：EE – 沟通阶段</text></g></g></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="45.51" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">你可以简要地与他人分享关于撤离的信息，比如你的感受、哪个出口似乎是最快的撤离选择，或者你想传达的其他信息。避免在沟通中使用数字。用不超过50个词，不要太长。</foreignobject></g></g></svg><svg
    class="ltx_picture" height="91.17" id="A7.SS3.p4.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,91.17)
    matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0 0.0 1.0 15 69.03)"><g class="ltx_nestedsvg"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1
    0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 11.81 7.61)"><text
    color="#000000" transform="matrix(1 0 0 -1 0 0)">提示 18：'
- en: The room measures 33 by 33 units and offers three potential exits situated on
    the left, bottom, and right sides of the room.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 房间的大小是33x33单位，并且有三个可能的出口，分别位于房间的左侧、底部和右侧。
- en: 'To successfully escape from this room, you should take into account two factors:
    the proximity of the nearest exit and the number of people present.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功逃离这个房间，你需要考虑两个因素：最近出口的接近度和在场人数。
- en: We use (x, y) to denote the position, smaller x means top and bigger x means
    bottom; smaller y means left and bigger y means right. Position (1, 1) is at the
    top left of the room. It is possible to move diagonally, e.g. from (1, 1) to (2,
    2) is one move to the lower right, and is faster than (1, 1)->(1, 2)->(2, 2).
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用(x, y)来表示位置，较小的x值表示顶部，较大的x值表示底部；较小的y值表示左侧，较大的y值表示右侧。位置(1, 1)位于房间的左上角。可以进行对角线移动，例如从(1,
    1)到(2, 2)是向右下方移动一步，并且比(1, 1)->(1, 2)->(2, 2)更快。
- en: Each cell can hold only one person at a time. The exit proximity refers to the
    distance between your current location and the closest exit, denoted as {distance_to_nearest_exit}.
    Additionally, within your line of sight, there are a total of {number_of_people}
    individuals.</foreignobject></g></g></svg></foreignobject></g></g></svg></foreignobject></g></g></svg></foreignobject></g></g></svg></foreignobject></g></g></svg>
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 每个单元格一次只能容纳一个人。出口的接近度指的是你当前位置与最近出口之间的距离，用{distance_to_nearest_exit}表示。此外，在你的视线范围内，总共有{number_of_people}人。
