- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 12:42:04'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:42:04
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AgentCoord：面向LLM基础的多代理协作的协调策略视觉探索
- en: 来源：[https://arxiv.org/html/2404.11943/](https://arxiv.org/html/2404.11943/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2404.11943/](https://arxiv.org/html/2404.11943/)
- en: \onlineid
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \onlineid
- en: '0 \vgtccategoryResearch \vgtcpapertypeApplication/Design Study \authorfooter
    Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, and Wei Chen
    are with the State Key Lab of CAD&CG, Zhejiang University, and Wei Chen is also
    with the Laboratory of Art and Archaeology Image (Zhejiang University), Ministry
    of Education, China. E-mail: {bopan $|$ ljying $|$ sttot$|$ zju_zhengli $|$ wenzhen $|$ fycj $|$ chenvis}@zju.edu.cn.
    Minfeng Zhu is with Zhejiang University. E-mail: minfeng_zhu@zju.edu.cn.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '0 \vgtccategoryResearch \vgtcpapertypeApplication/Design Study \authorfooter
    Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, and Wei Chen
    are with the State Key Lab of CAD&CG, Zhejiang University, and Wei Chen is also
    with the Laboratory of Art and Archaeology Image (Zhejiang University), Ministry
    of Education, China. E-mail: {bopan $|$ ljying $|$ sttot$|$ zju_zhengli $|$ wenzhen $|$ fycj $|$ chenvis}@zju.edu.cn.
    Minfeng Zhu is with Zhejiang University. E-mail: minfeng_zhu@zju.edu.cn.'
- en: Bo Pan    Jiaying Lu    Ke Wang    Li Zheng    Zhen Wen    Yingchaojie Feng
       Minfeng Zhu    and Wei Chen
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Bo Pan    Jiaying Lu    Ke Wang    Li Zheng    Zhen Wen    Yingchaojie Feng
       Minfeng Zhu    and Wei Chen
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The potential of automatic task-solving through Large Language Model (LLM)-based
    multi-agent collaboration has recently garnered widespread attention from both
    the research community and industry. While utilizing natural language to coordinate
    multiple agents presents a promising avenue for democratizing agent technology
    for general users, designing coordination strategies remains challenging with
    existing coordination frameworks. This difficulty stems from the inherent ambiguity
    of natural language for specifying the collaboration process and the significant
    cognitive effort required to extract crucial information (e.g. agent relationship,
    task dependency, result correspondence) from a vast amount of text-form content
    during exploration. In this work, we present a visual exploration framework to
    facilitate the design of coordination strategies in multi-agent collaboration.
    We first establish a structured representation for LLM-based multi-agent coordination
    strategy to regularize the ambiguity of natural language. Based on this structure,
    we devise a three-stage generation method that leverages LLMs to convert a user’s
    general goal into an executable initial coordination strategy. Users can further
    intervene at any stage of the generation process, utilizing LLMs and a set of
    interactions to explore alternative strategies. Whenever a satisfactory strategy
    is identified, users can commence the collaboration and examine the visually enhanced
    execution result. We develop AgentCoord, a prototype interactive system, and conduct
    a formal user study to demonstrate the feasibility and effectiveness of our approach.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大型语言模型（LLM）的多代理协作在自动任务解决中的潜力，近年来受到了学术界和工业界的广泛关注。虽然利用自然语言来协调多个代理为普通用户推广代理技术提供了一个有前景的途径，但在现有的协调框架中，设计协调策略仍然充满挑战。这一困难源于自然语言在指定协作过程中的固有模糊性，以及在探索过程中从大量文本形式内容中提取关键信息（例如代理关系、任务依赖、结果对应）所需的巨大认知努力。在本研究中，我们提出了一个视觉探索框架，旨在促进多代理协作中的协调策略设计。我们首先为基于LLM的多代理协调策略建立了一个结构化表示，以规范自然语言的模糊性。在此基础上，我们设计了一种三阶段生成方法，利用LLM将用户的总体目标转化为可执行的初始协调策略。用户可以在生成过程的任何阶段进行进一步干预，利用LLM和一组交互操作探索替代策略。每当识别出令人满意的策略时，用户即可开始协作并检查经过视觉增强的执行结果。我们开发了AgentCoord，一个原型互动系统，并进行了正式的用户研究，以展示我们方法的可行性和有效性。
- en: 'keywords:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Large language model, LLM-based agent, Multi-agent collaboration, visual exploration,
    natural language interface.\teaser
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）基础的代理、多代理协作、视觉探索、自然语言接口。\teaser
- en: 'Our visual exploration framework for coordination strategy design: The user
    first enters a general goal for agent collaboration (a). The system conducts a
    three-stage generation (i.e., Plan Outline Generation (b), Agent Assignment (c),
    and Task Process Generation (d)) to provide an initial strategy. The user interactively
    explores alternative strategies for each stage with the help of LLMs (e, f, g).
    Once satisfied, the user commences the collaboration and examines the visually
    enhanced execution results (h).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的视觉探索框架用于协调策略设计：用户首先输入一个代理协作的总体目标（a）。系统进行三阶段生成（即计划大纲生成（b）、代理分配（c）和任务过程生成（d））以提供初步策略。用户在LLM的帮助下交互式地探索每个阶段的替代策略（e、f、g）。一旦满意，用户便开始协作并检查视觉增强的执行结果（h）。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Large Language Model (LLM) based agents, which are capable of observing, making
    decisions, and performing actions with the reasoning capabilities of LLM, have
    undergone significant improvements, showing great potential in various areas such
    as programming[[12](https://arxiv.org/html/2404.11943v1#bib.bib12), [25](https://arxiv.org/html/2404.11943v1#bib.bib25)],
    creative writing[[3](https://arxiv.org/html/2404.11943v1#bib.bib3), [33](https://arxiv.org/html/2404.11943v1#bib.bib33),
    [44](https://arxiv.org/html/2404.11943v1#bib.bib44)], and question answering [[39](https://arxiv.org/html/2404.11943v1#bib.bib39),
    [28](https://arxiv.org/html/2404.11943v1#bib.bib28)]. While initial forays into
    the realm of LLM-based agents focused on solitary agent system[[10](https://arxiv.org/html/2404.11943v1#bib.bib10),
    [42](https://arxiv.org/html/2404.11943v1#bib.bib42)], the concept of multi-agent
    collaboration—mirroring the cooperative interactions among humans—has started
    to pique the interest of the AI research community. Drawing inspiration from the
    synergistic outcomes observed in human teamwork[[7](https://arxiv.org/html/2404.11943v1#bib.bib7),
    [37](https://arxiv.org/html/2404.11943v1#bib.bib37), [20](https://arxiv.org/html/2404.11943v1#bib.bib20)],
    a burgeoning body of research has been investigating and validating the benefits
    (e.g. expand expertise[[27](https://arxiv.org/html/2404.11943v1#bib.bib27), [28](https://arxiv.org/html/2404.11943v1#bib.bib28)],
    enhance reliability [[2](https://arxiv.org/html/2404.11943v1#bib.bib2), [6](https://arxiv.org/html/2404.11943v1#bib.bib6),
    [25](https://arxiv.org/html/2404.11943v1#bib.bib25)], encourage divergent thinking[[15](https://arxiv.org/html/2404.11943v1#bib.bib15),
    [45](https://arxiv.org/html/2404.11943v1#bib.bib45)]) brought about by LLM-based
    multi-agent collaboration.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大型语言模型（LLM）的代理，能够观察、决策并执行动作，借助LLM的推理能力，已经取得了显著进展，在编程[[12](https://arxiv.org/html/2404.11943v1#bib.bib12)、[25](https://arxiv.org/html/2404.11943v1#bib.bib25)]、创意写作[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)、[33](https://arxiv.org/html/2404.11943v1#bib.bib33)、[44](https://arxiv.org/html/2404.11943v1#bib.bib44)]以及问答[[39](https://arxiv.org/html/2404.11943v1#bib.bib39)、[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]等多个领域展现出巨大的潜力。尽管最初关于基于LLM的代理的探索主要集中在单一代理系统[[10](https://arxiv.org/html/2404.11943v1#bib.bib10)、[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]，但是多代理协作的概念——模拟人类之间的合作互动——已开始引起AI研究界的兴趣。受到人类团队协作中协同效应的启发[[7](https://arxiv.org/html/2404.11943v1#bib.bib7)、[37](https://arxiv.org/html/2404.11943v1#bib.bib37)、[20](https://arxiv.org/html/2404.11943v1#bib.bib20)]，一系列新兴的研究正在探索并验证基于LLM的多代理协作带来的好处（例如扩展专业知识[[27](https://arxiv.org/html/2404.11943v1#bib.bib27)、[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]，增强可靠性[[2](https://arxiv.org/html/2404.11943v1#bib.bib2)、[6](https://arxiv.org/html/2404.11943v1#bib.bib6)、[25](https://arxiv.org/html/2404.11943v1#bib.bib25)]，鼓励发散性思维[[15](https://arxiv.org/html/2404.11943v1#bib.bib15)、[45](https://arxiv.org/html/2404.11943v1#bib.bib45)])。
- en: 'In order to facilitate the coordination of multi-agent collaboration, the open-source
    community emerges a multitude of frameworks for prototyping LLM-based multi-agent
    systems. Existing multi-agent frameworks can be divided into two categories based
    on how users can specify or intervene in the collaborative process: code-based
    and natural language-based. For code-based frameworks [[12](https://arxiv.org/html/2404.11943v1#bib.bib12),
    [25](https://arxiv.org/html/2404.11943v1#bib.bib25), [38](https://arxiv.org/html/2404.11943v1#bib.bib38),
    [21](https://arxiv.org/html/2404.11943v1#bib.bib21), [29](https://arxiv.org/html/2404.11943v1#bib.bib29),
    [4](https://arxiv.org/html/2404.11943v1#bib.bib4)], users need to hard-code the
    coordination strategies (e.g. the division of tasks, the assignment of agents,
    the flow of massages) directly into the code, which requires code skill and learning
    cost. The natural language-based frameworks[[3](https://arxiv.org/html/2404.11943v1#bib.bib3),
    [38](https://arxiv.org/html/2404.11943v1#bib.bib38)] ¹¹1AutoGen [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]
    supports both code-based and natural language-based paradiam. In its “group chat
    mode”, the coordination strategy can be expressed in free-form natural language
    and coordinated by a chat manager., which directly uses natural languages to specify
    the coordination strategies, could be a promising way to democratize agent technology
    for broader general users. Additionally, given that LLMs inherently possess coordinating
    capabilities and rich domain knowledge across different tasks, the natural language-based
    frameworks can easily leverage LLMs to assist in drafting and refining the coordination
    strategies represented in natural language[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)].'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进多代理协作的协调，开源社区涌现出多种基于大语言模型（LLM）的多代理系统原型框架。现有的多代理框架可以根据用户如何指定或干预协作过程分为两类：基于代码的和基于自然语言的。对于基于代码的框架[[12](https://arxiv.org/html/2404.11943v1#bib.bib12)、[25](https://arxiv.org/html/2404.11943v1#bib.bib25)、[38](https://arxiv.org/html/2404.11943v1#bib.bib38)、[21](https://arxiv.org/html/2404.11943v1#bib.bib21)、[29](https://arxiv.org/html/2404.11943v1#bib.bib29)、[4](https://arxiv.org/html/2404.11943v1#bib.bib4)]，用户需要将协调策略（例如任务分配、代理分配、消息流转）硬编码到代码中，这需要一定的编码技能和学习成本。基于自然语言的框架[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)、[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]¹¹1AutoGen[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]
    支持基于代码和基于自然语言的两种范式。在其“群聊模式”中，协调策略可以通过自由形式的自然语言表达，并由聊天管理器进行协调，这直接使用自然语言来指定协调策略，可能是使代理技术为更广泛的一般用户所普及的有希望的方式。此外，鉴于LLM本身具备协调能力并且在不同任务中拥有丰富的领域知识，基于自然语言的框架可以轻松利用LLM来协助草拟和完善用自然语言表示的协调策略[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]。
- en: 'However, designing coordination strategies remains challenging with existing
    natural language-based frameworks. First, the flexibility of natural language
    could be a double-edged sword: on one hand, it allows users to freely design and
    express their coordination strategies; on the other hand, overly flexible expressions
    can make the devised collaboration strategies ambiguous, often requiring users
    repeatedly engage in remedial specification to ensure the execution of the collaboration
    doesn’t stray from its intended course. Second, representing and exploring coordination
    strategies in pure text format faces challenges as the complexity of the collaboration
    process and team organization rises. Users can easily get lost in the “text jam”
    where important information (e.g. agent relationship, task dependency, result
    correspondence, strategy discrepancy) they care about at certain points during
    exploration is drowned in blocks of text. Therefore, novel approaches are highly
    desirable to enhance the current natural language-based design process.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用现有的基于自然语言的框架设计协调策略仍然具有挑战性。首先，自然语言的灵活性可能是一把双刃剑：一方面，它允许用户自由设计和表达他们的协调策略；另一方面，过于灵活的表达方式可能会使得设计出的协作策略模糊不清，往往需要用户反复进行补充说明，以确保协作的执行不会偏离预定的方向。其次，在纯文本格式中表示和探索协调策略会面临挑战，因为随着协作过程和团队组织复杂性的增加，用户容易在“文本堵塞”中迷失，重要信息（例如代理关系、任务依赖性、结果对应性、策略差异）在探索的某些点上可能被大量文本所淹没。因此，亟需新颖的方法来增强当前基于自然语言的设计过程。
- en: 'This work thus presents a visual exploration framework for efficiently designing
    coordination strategies for LLM-based multi-agent collaboration. To exploit the
    flexibility of natural language while incorporating a level of organization to
    regularize its ambiguity, we analyze the common concepts and structures found
    in the description for coordination strategy in a corpus of 25 LLM-based multi-agent
    collaboration papers and 7 high-star projects ²²2The corpus can be found in our
    project repository., based on which we establish a structured representation for
    LLM-based Multi-agent coordination strategy. This structure lays a foundational
    scaffolding for the entire exploration process. Based on this structure, we design
    a generation method that exploits the coordinating capabilities and domain knowledge
    of LLMs to map the general goal provided by users (AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration <svg class="ltx_picture"
    height="13.7" id="S1.p4.1.pic1" overflow="visible" version="1.1" width="13.7"><g
    transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g
    fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0
    0.0 1.0 -3.46 -2.98)"><foreignobject color="#44AAA8" height="5.96" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="6.92">a</foreignobject></g></g></svg>)
    into an executable initial coordination strategy to help users kick off the exploration.
    To ensure coherence among various parts of the generated strategy, we divide the
    generation process into three stages: Plan Outline Generation (AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration <svg class="ltx_picture"
    height="13.7" id="S1.p4.2.pic2" overflow="visible" version="1.1" width="13.7"><g
    transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g
    fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0
    0.0 1.0 -3.84 -4.8)"><foreignobject color="#44AAA8" height="9.61" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="7.69">b</foreignobject></g></g></svg>)
    for an overall collaboration plan to achieve the goal, Agent Assignment (AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration
    <svg class="ltx_picture" height="13.7" id="S1.p4.3.pic3" overflow="visible" version="1.1"
    width="13.7"><g transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0)
    translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0
    0.0 0.0 1.0 -3.07 -2.98)"><foreignobject color="#44AAA8" height="5.96" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="6.15">c</foreignobject></g></g></svg>)
    for each task in the plan outline, and Task Process Generation (AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration <svg class="ltx_picture"
    height="13.7" id="S1.p4.4.pic4" overflow="visible" version="1.1" width="13.7"><g
    transform="translate(0,13.7) matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g
    fill="#44AAA8" stroke="#44AAA8" stroke-width="0.9pt" transform="matrix(1.0 0.0
    0.0 1.0 -3.84 -4.8)"><foreignobject color="#44AAA8" height="9.61" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="7.69">d</foreignobject></g></g></svg>)
    for specifying how assigned agents collaboratively finish the task. To streamline
    users’ exploration and iterative refinement for alternative strategies, we propose
    a set of interactions (AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration <svg class="ltx_picture" height="13.7" id="S1.p4.5.pic5"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.07 -2.98)"><foreignobject
    color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="6.15">e</foreignobject></g></g></svg> <svg class="ltx_picture" height="13.7"
    id="S1.p4.6.pic6" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -2.11 -4.8)"><foreignobject
    color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="4.23">f</foreignobject></g></g></svg> <svg class="ltx_picture" height="13.7"
    id="S1.p4.7.pic7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -1.63)"><foreignobject
    color="#44AAA8" height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="6.92">g</foreignobject></g></g></svg>) to help users visually explore
    the design space for each generation stage with the help of LLMs. Whenever users
    are satisfied with a certain strategy, they can initiate the collaboration and
    examine the execution result which is visually enhanced and linked with previous
    stages for efficient verification (AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration <svg class="ltx_picture" height="13.7"
    id="S1.p4.8.1.pic1" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject
    color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="7.69">h</foreignobject></g></g></svg>).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '本文提出了一个视觉探索框架，用于高效设计基于大型语言模型（LLM）的多智能体协作的协调策略。为了在利用自然语言的灵活性的同时，加入一定的组织结构来规范其模糊性，我们分析了在25篇基于LLM的多智能体协作论文和7个高评分项目的语料库中常见的协调策略描述中的概念和结构²²2该语料库可以在我们的项目仓库中找到。，基于这些分析，我们建立了一个基于LLM的多智能体协调策略的结构化表示。这一结构为整个探索过程奠定了基础框架。基于该结构，我们设计了一种生成方法，利用LLM的协调能力和领域知识，将用户提供的一般目标（AgentCoord:
    视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.1.pic1"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -2.98)"><foreignobject
    color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="6.92">a</foreignobject></g></g></svg>)转化为可执行的初步协调策略，帮助用户启动探索过程。为了确保生成策略各部分之间的一致性，我们将生成过程分为三个阶段：计划大纲生成（AgentCoord:
    视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.2.pic2"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject
    color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="7.69">b</foreignobject></g></g></svg>)，用于制定实现目标的整体协作计划；任务分配（AgentCoord:
    视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.3.pic3"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.07 -2.98)"><foreignobject
    color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="6.15">c</foreignobject></g></g></svg>)，用于给计划大纲中的每个任务分配智能体；以及任务过程生成（AgentCoord:
    视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.4.pic4"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject
    color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="7.69">d</foreignobject></g></g></svg>)，用于指定已分配的智能体如何协作完成任务。为了简化用户在替代策略之间的探索与迭代优化，我们提出了一组交互方法（AgentCoord:
    视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.5.pic5"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.07 -2.98)"><foreignobject
    color="#44AAA8" height="5.96" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="6.15">e</foreignobject></g></g></svg> <svg class="ltx_picture" height="13.7"
    id="S1.p4.6.pic6" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -2.11 -4.8)"><foreignobject
    color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="4.23">f</foreignobject></g></g></svg> <svg class="ltx_picture" height="13.7"
    id="S1.p4.7.pic7" overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -1.63)"><foreignobject
    color="#44AAA8" height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="6.92">g</foreignobject></g></g></svg>)，帮助用户在每个生成阶段借助LLM视觉探索设计空间。每当用户对某一策略感到满意时，他们可以启动协作并检查执行结果，该结果通过视觉增强并与之前的阶段链接，以便于高效验证（AgentCoord:
    视觉探索LLM基础的多智能体协作协调策略 <svg class="ltx_picture" height="13.7" id="S1.p4.8.1.pic1"
    overflow="visible" version="1.1" width="13.7"><g transform="translate(0,13.7)
    matrix(1 0 0 -1 0 0) translate(6.85,0) translate(0,6.85)"><g fill="#44AAA8" stroke="#44AAA8"
    stroke-width="0.9pt" transform="matrix(1.0 0.0 0.0 1.0 -3.84 -4.8)"><foreignobject
    color="#44AAA8" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="7.69">h</foreignobject></g></g></svg>)。'
- en: 'To validate the feasibility and effectiveness of this framework, we developed
    an interactive system called AgentCoord that enables users to visually explore
    coordination strategies for LLM-based multi-agent collaboration, effectively integrating
    the prior of LLMs and users during design. Our user study, involving 12 users
    with a general interest in LLM-based multi-agent collaboration, suggests that
    our approach can effectively facilitate the design process for LLM-based multi-agent
    coordination strategies and has the potential to democratize agent coordination
    for broader users. In summary, our contributions include:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证该框架的可行性和有效性，我们开发了一个名为AgentCoord的互动系统，允许用户直观地探索基于LLM的多智能体协作的协调策略，有效地在设计过程中整合了LLM和用户的先验知识。我们的用户研究涉及12名对基于LLM的多智能体协作感兴趣的用户，研究结果表明，我们的方法能够有效地促进LLM-based多智能体协调策略的设计过程，并且具有使更广泛用户群体能够平等参与智能体协调的潜力。总之，我们的贡献包括：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A visual exploration framework that enables general users to efficiently design
    coordination strategy for LLM-based multi-agent collaboration.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个可视化探索框架，使普通用户能够高效设计基于LLM的多智能体协作的协调策略。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'AgentCoord ³³3Project Repository: https://github.com/AgentCoord/AgentCoord,
    an open-source interactive system that instantiates our framework with a set of
    interactions and visual designs to facilitate coordination strategy exploration.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AgentCoord ³³3项目仓库： [https://github.com/AgentCoord/AgentCoord](https://github.com/AgentCoord/AgentCoord)，一个开源互动系统，通过一系列交互和视觉设计实现我们的框架，帮助促进协调策略的探索。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A formal user study that demonstrates the feasibility and effectiveness of our
    approach.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一项正式的用户研究，展示了我们方法的可行性和有效性。
- en: 2 Related Work
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM-Based Multi-Agent Collaboration
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 基于LLM的多智能体协作
- en: Large language models (LLMs) have recently demonstrated impressive capabilities
    as versatile task-solving agents, attracting substantial interest in both industry
    and academia [[32](https://arxiv.org/html/2404.11943v1#bib.bib32), [41](https://arxiv.org/html/2404.11943v1#bib.bib41)].
    Since LLMs are trained on natural language corpus that is biased toward human
    thinking [[45](https://arxiv.org/html/2404.11943v1#bib.bib45)] and optimized for
    conversation [[23](https://arxiv.org/html/2404.11943v1#bib.bib23)], LLM-based
    agents can collaborate through natural language in a human-like manner and harness
    a range of benefits that come with collaboration.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）最近展现了作为多功能任务解决代理的令人印象深刻的能力，吸引了业界和学术界的广泛关注[[32](https://arxiv.org/html/2404.11943v1#bib.bib32)、[41](https://arxiv.org/html/2404.11943v1#bib.bib41)]。由于LLM是基于自然语言语料库训练的，这些语料库偏向于人类思维[[45](https://arxiv.org/html/2404.11943v1#bib.bib45)]，并且经过优化以进行对话[[23](https://arxiv.org/html/2404.11943v1#bib.bib23)]，因此基于LLM的智能体能够通过自然语言以类似人类的方式进行协作，并充分利用协作所带来的各种好处。
- en: Recent works have initiated attempts to coordinate agents with varied expertise
    in order to improve outcomes on a wide spectrum of tasks that benefit from a diversity
    of knowledge. Medagent [[28](https://arxiv.org/html/2404.11943v1#bib.bib28)] collects
    medical agents with different specialties to provide a comprehensive analysis
    of patient’s conditions and treatment options. MetaGPT [[12](https://arxiv.org/html/2404.11943v1#bib.bib12)]
    and ChatDev [[25](https://arxiv.org/html/2404.11943v1#bib.bib25)] enable agents
    with different roles such as product managers, designers, and programmers to collaborate
    in software development, thereby improving the quality of the software produced.
    MARG[[5](https://arxiv.org/html/2404.11943v1#bib.bib5)] develops a framework for
    integrating the proficiency of multiple expert agents to review scientific papers.
    AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)] and OKR-Agent[[44](https://arxiv.org/html/2404.11943v1#bib.bib44)]
    demonstrate how creative content tasks, such as creative writing and storyboard
    generation, can benefit from the collaboration of agents with diverse domain backgrounds.
    AgentVerse[[4](https://arxiv.org/html/2404.11943v1#bib.bib4)] showcases a scenario
    in which multiple experts with different backgrounds collaborate to deliver a
    hydrogen storage station siting solution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究开始尝试协调具有不同专业领域的智能体，以提高在各类任务中的表现，这些任务能够从多样化的知识中受益。Medagent [[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]
    汇集了不同专科的医疗智能体，提供对患者状况和治疗方案的全面分析。MetaGPT [[12](https://arxiv.org/html/2404.11943v1#bib.bib12)]
    和ChatDev [[25](https://arxiv.org/html/2404.11943v1#bib.bib25)] 使得具有不同角色的智能体，如产品经理、设计师和程序员，能够在软件开发中协作，从而提高软件的质量。MARG[[5](https://arxiv.org/html/2404.11943v1#bib.bib5)]
    开发了一个框架，整合多个专家智能体的能力来审阅科学论文。AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]
    和OKR-Agent[[44](https://arxiv.org/html/2404.11943v1#bib.bib44)] 展示了创意内容任务，如创意写作和故事板生成，如何从具有多元领域背景的智能体协作中受益。AgentVerse[[4](https://arxiv.org/html/2404.11943v1#bib.bib4)]
    展示了多个具有不同背景的专家如何协作，提供氢气储存站选址解决方案的场景。
- en: Additionally, recent studies have discovered that multiple agents can work together
    to foster cognitive synergy [[20](https://arxiv.org/html/2404.11943v1#bib.bib20)]
    similar to humans. Chan et al. request multiple agents to delve into the discussion
    from diverse perspectives to catalyze a comprehensive assessment that is greater
    than the sum of their separate assessments. Liang et al.[[15](https://arxiv.org/html/2404.11943v1#bib.bib15)]
    and Du et al.[[6](https://arxiv.org/html/2404.11943v1#bib.bib6)] let multiple
    agents to debate with each other to encourage deeper levels of contemplation.
    Zhuge et al.[[45](https://arxiv.org/html/2404.11943v1#bib.bib45)] propose the
    concept of “mindstorm” to describe how multiple agents take multiple rounds of
    communication to iterate the ideas to find a solution that is often superior to
    any individual solution.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，最近的研究发现，多个智能体可以协同工作，促进类似人类的认知协同[[20](https://arxiv.org/html/2404.11943v1#bib.bib20)]。Chan等人要求多个智能体从不同角度进行深入讨论，以促进一种比单独评估更为全面的评估。Liang等人[[15](https://arxiv.org/html/2404.11943v1#bib.bib15)]
    和Du等人[[6](https://arxiv.org/html/2404.11943v1#bib.bib6)] 让多个智能体互相辩论，鼓励更深层次的思考。Zhuge等人[[45](https://arxiv.org/html/2404.11943v1#bib.bib45)]
    提出了“头脑风暴”的概念，描述了多个智能体通过多轮交流来迭代想法，从而找到一个通常优于任何单一解决方案的答案。
- en: Despite the potential of multi-agent collaboration shown in various fields,
    most works require coding to design coordination strategies for agents, limiting
    accessibility for broader general users. While AutoGen [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]
    and AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)] support representing
    coordination strategies in pure natural language, users still encounter a series
    of issues when using natural language to explore and design coordination strategies.
    Our work attempts to address these issues with structured generation of coordination
    strategies and a set of visualization approaches to facilitate users’ understanding
    and exploration of the coordination strategies.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在各个领域中多智能体协作展现出了巨大的潜力，但大多数工作仍然需要编写代码来设计智能体的协调策略，这限制了普通用户的使用。虽然AutoGen [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]
    和AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)] 支持用纯自然语言表示协调策略，但用户在使用自然语言探索和设计协调策略时仍然会遇到一系列问题。我们的工作尝试通过结构化生成协调策略和一套可视化方法，解决这些问题，以帮助用户理解和探索协调策略。
- en: 2.2 Generating Coordination Strategy using LLMs
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 使用大型语言模型生成协调策略
- en: Although LLM-based agents have shown tremendous potential in collaboratively
    completing tasks, manually designing coordination strategies is often challenging,
    time-consuming, and sometimes requires expertise in specific domain knowledge
    [[14](https://arxiv.org/html/2404.11943v1#bib.bib14)]. Thus, it is highly desirable
    to leverage LLM’s inherent coordinating capabilities and prior knowledge across
    different tasks to aid in designing coordination strategies for agent collaboration.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于LLM的智能体在协作完成任务方面展现出了巨大的潜力，但手动设计协作策略往往具有挑战性，耗时且有时需要特定领域的专业知识[[14](https://arxiv.org/html/2404.11943v1#bib.bib14)]。因此，非常有必要利用LLM固有的协作能力和跨任务的先验知识，来帮助设计智能体协作的协调策略。
- en: Many works on multi-agent collaboration leverage the prior knowledge of LLMs
    for the formation and adjustment of agent teams. Wang et al. [[33](https://arxiv.org/html/2404.11943v1#bib.bib33)]
    prompt LLM to dynamically identify a set of agent roles in response to a task
    query. Medagent [[28](https://arxiv.org/html/2404.11943v1#bib.bib28)] prompts
    LLM to work as a medical expert who specializes in categorizing a specific medical
    scenario into specific areas of medicine and gathering corresponding expert agents.
    DyLAN [[18](https://arxiv.org/html/2404.11943v1#bib.bib18)] leverages LLM to score
    the performance of agents and dynamically optimize the team organization during
    collaboration. The AgentBuilder module of Autogen [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]
    prompts LLM to generate system prompts for multiple agents based on the current
    task and add them to a group chat for collaboration. AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]
    designs an LLM-based Agent Observer to check the compliance of the agent with
    the requirements and make suggestions for adjustments.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 许多关于多智能体协作的研究利用了大语言模型（LLM）的先验知识来形成和调整智能体团队。王等人[[33](https://arxiv.org/html/2404.11943v1#bib.bib33)]提示LLM根据任务查询动态识别一组智能体角色。Medagent
    [[28](https://arxiv.org/html/2404.11943v1#bib.bib28)]提示LLM作为医学专家，专注于将特定的医学场景分类到特定的医学领域，并召集相应的专家智能体。DyLAN
    [[18](https://arxiv.org/html/2404.11943v1#bib.bib18)]利用LLM对智能体的表现进行评分，并在协作过程中动态优化团队组织。Autogen的AgentBuilder模块[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]提示LLM根据当前任务生成多个智能体的系统提示，并将它们添加到群聊中进行协作。AutoAgents
    [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]设计了一个基于LLM的智能体观察器，用于检查智能体是否符合要求并提出调整建议。
- en: LLMs are also widely utilized to aid in planning the collaboration process of
    multiple agents. For example, AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]
    prompt LLMs to draft a collaboration plan that specifies the agents involved in
    each step and the expected outputs. In Autogen’s group chat mode [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)],
    the user can play the role of an Admin agent to draft and refine the collaboration
    plan together with an LLM-based Planner agent. OKR-agent [[44](https://arxiv.org/html/2404.11943v1#bib.bib44)]
    leverage LLMs to recursively decompose the tasks for teams of agents. Further,
    AgentVerse [[4](https://arxiv.org/html/2404.11943v1#bib.bib4)] designs a collaborative
    decision-making stage for multiple LLM-based agents to make short-term planning.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM也被广泛应用于帮助规划多个智能体的协作过程。例如，AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]提示LLM草拟一份协作计划，指定每个步骤中涉及的智能体及其预期输出。在Autogen的群聊模式[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]中，用户可以扮演管理员智能体的角色，与基于LLM的规划智能体一起草拟和完善协作计划。OKR-agent
    [[44](https://arxiv.org/html/2404.11943v1#bib.bib44)]利用LLM递归地分解团队智能体的任务。此外，AgentVerse
    [[4](https://arxiv.org/html/2404.11943v1#bib.bib4)]设计了一个协作决策阶段，供多个基于LLM的智能体进行短期规划。
- en: Our work focuses more on how to leverage LLM to facilitate general users in
    designing their own multi-agent coordination strategy. To achieve this, we propose
    an LLM-based three-stage generation method to generate a structured coordination
    strategy based on the user’s goal. Additionally, we propose a set of interactions
    to assist users in flexibly exploiting the coordination ability of LLMs during
    exploration.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作更加关注如何利用LLM帮助普通用户设计自己的多智能体协作策略。为此，我们提出了一种基于LLM的三阶段生成方法，根据用户的目标生成结构化的协作策略。此外，我们还提出了一组交互方式，帮助用户在探索过程中灵活利用LLM的协作能力。
- en: 2.3 Interface for LLM-based Agents
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 基于LLM的智能体接口
- en: During the execution of LLM-based agents, a multitude of intricate information
    is involved, which is hard to digest with a plain text terminal [[35](https://arxiv.org/html/2404.11943v1#bib.bib35),
    [19](https://arxiv.org/html/2404.11943v1#bib.bib19)]. Therefore, it is highly
    desirable to have some interfaces to assist in understanding and intervening in
    the execution process. Early interfaces [[26](https://arxiv.org/html/2404.11943v1#bib.bib26),
    [40](https://arxiv.org/html/2404.11943v1#bib.bib40), [30](https://arxiv.org/html/2404.11943v1#bib.bib30)]
    for monitoring single LLM-based agents typically feature an outline view that
    maps out the overall execution process, complemented by detailed text blocks enhanced
    with highlighting and icons. For systems[[24](https://arxiv.org/html/2404.11943v1#bib.bib24),
    [16](https://arxiv.org/html/2404.11943v1#bib.bib16), [43](https://arxiv.org/html/2404.11943v1#bib.bib43),
    [25](https://arxiv.org/html/2404.11943v1#bib.bib25)] that deploys multiple agents
    in a virtual sandbox environment, a panoramic view is usually provided to transform
    text-form information into concrete visual elements (e.g. moving agent avatars,
    expressive emojis) for easier comprehension of the overall process. Topological
    structures such as trees and graphs are also utilized to visualize and manage
    the execution processes of agents. SPROUT[[17](https://arxiv.org/html/2404.11943v1#bib.bib17)]
    employs a tree structure to assist users in visualizing and controlling the process
    of an agent composing code tutorials. Hong et al. [[11](https://arxiv.org/html/2404.11943v1#bib.bib11)]
    use a hierarchical graph structure to manage the execution process of a data science
    agent and allow users to interactively edit the graph during execution. AutoGen
    [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)] introduces a transition
    graph to allow users to constrain agent transition to mitigate the risk of sub-optimal
    agent transitions during multi-agent collaboration in Group Chat mode. Recently,
    AgentLens [[19](https://arxiv.org/html/2404.11943v1#bib.bib19)] initiated the
    first attempt to design a visual analysis system to assist users in analyzing
    the agent behaviors in LLM-based multi-agent systems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行基于LLM的智能体时，涉及大量复杂的信息，这些信息在纯文本终端中很难消化[[35](https://arxiv.org/html/2404.11943v1#bib.bib35)，[19](https://arxiv.org/html/2404.11943v1#bib.bib19)]。因此，非常需要一些界面来帮助理解和干预执行过程。早期用于监控单个LLM智能体的界面[[26](https://arxiv.org/html/2404.11943v1#bib.bib26)，[40](https://arxiv.org/html/2404.11943v1#bib.bib40)，[30](https://arxiv.org/html/2404.11943v1#bib.bib30)]通常采用大纲视图来展示整体执行过程，并通过突出显示和图标增强详细文本块。对于在虚拟沙箱环境中部署多个智能体的系统[[24](https://arxiv.org/html/2404.11943v1#bib.bib24)，[16](https://arxiv.org/html/2404.11943v1#bib.bib16)，[43](https://arxiv.org/html/2404.11943v1#bib.bib43)，[25](https://arxiv.org/html/2404.11943v1#bib.bib25)]，通常会提供全景视图，将文本形式的信息转化为具体的视觉元素（例如移动的智能体头像、富有表现力的表情符号），以便更容易理解整体过程。拓扑结构如树形图和图形也被用来可视化和管理智能体的执行过程。SPROUT[[17](https://arxiv.org/html/2404.11943v1#bib.bib17)]采用树形结构来帮助用户可视化和控制智能体编写代码教程的过程。Hong等人[[11](https://arxiv.org/html/2404.11943v1#bib.bib11)]使用分层图形结构来管理数据科学智能体的执行过程，并允许用户在执行过程中交互式地编辑图形。AutoGen
    [[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]引入了转移图，允许用户限制智能体转移，以减少多智能体协作中群聊模式下智能体转移时的次优风险。最近，AgentLens[[19](https://arxiv.org/html/2404.11943v1#bib.bib19)]首次尝试设计一种可视化分析系统，帮助用户分析LLM基础的多智能体系统中的智能体行为。
- en: Extending this line of work, our work enables general users to visually explore
    coordination strategies for LLM-based multi-agent collaboration.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在此研究的基础上，我们的工作使普通用户能够直观地探索基于大型语言模型（LLM）的多智能体协作中的协调策略。
- en: 3 Formative Study
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 形成性研究
- en: To gain insight into how users use current natural language-based frameworks
    to coordinate multiple LLM-based agents and identify the challenges that exist
    during the exploration process for coordination strategy, we carried out a formative
    study. Based on the findings in the formative study, we formulated four design
    requirements to enhance the process of designing coordination strategies for LLM-based
    multi-agent collaboration.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入了解用户如何使用当前基于自然语言的框架来协调多个基于LLM的智能体，并识别在协调策略探索过程中存在的挑战，我们进行了形成性研究。根据形成性研究的结果，我们制定了四个设计要求，以增强为LLM基础的多智能体协作设计协调策略的过程。
- en: 3.1 Participants and Procedure
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 参与者和程序
- en: We recruited 8 participants who have experience or general interest in LLM-based
    multi-agent collaboration from the local university and online discussion platforms
    for open-source multi-agent frameworks. Four of them are experienced experts in
    LLM-based multi-agent systems (E1 and E2 are NLP researchers familiar with LLM-based
    multi-agent collaboration, while E3 and E4 are developers having experience in
    constructing multi-agent systems). Another four of them (G1-4) are general users
    who have a basic understanding of LLM-based agents and are interested in building
    their own LLM-based multi-agent collaboration strategy.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了8名具有LLM-based多智能体协作经验或对其有兴趣的参与者，来自当地大学和开放源代码多智能体框架的在线讨论平台。四名是有经验的LLM-based多智能体系统专家（E1和E2是熟悉LLM-based多智能体协作的NLP研究人员，而E3和E4是有构建多智能体系统经验的开发者）。另外四名（G1-4）是对LLM-based智能体有基本了解并有兴趣构建自己的LLM-based多智能体协作策略的普通用户。
- en: 'Procedure: In our formative interviews, we initially asked the participants
    about their prior experience with any LLM-based multi-agent framework or system.
    Afterward, we show participants how to use natural language to specify the coordination
    strategy for multi-agent collaboration using AutoAgents [[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]
    alongside a text editor and the “group chat mode” of AutoGen[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)].
    After the participants got familiar with the usage, they were asked to choose
    a task that could benefit from collaboration among multiple LLM-based agents and
    construct their own coordination strategy with both systems separately. The participants
    can also use ChatGPT to assist them in designing coordination strategies during
    the process. Finally, we gathered feedback on participants’ experience during
    the construction of the coordination strategy and inquiry about the challenges
    they faced during the process. For participants who reported prior experience
    with any LLM-based multi-agent framework at the start of the interview, we also
    asked them to compare the strengths and weaknesses of natural language-based methods
    with previous frameworks they have used.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 程序：在我们的初步访谈中，我们首先询问参与者是否有使用过任何基于LLM的多智能体框架或系统的经验。之后，我们展示了如何使用自然语言指定多智能体协作的协调策略，使用AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]与文本编辑器以及AutoGen的“群聊模式”[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]。在参与者熟悉使用方法后，他们被要求选择一个能够通过多LLM智能体协作获益的任务，并分别使用这两个系统构建自己的协调策略。参与者还可以在此过程中使用ChatGPT来帮助设计协调策略。最后，我们收集了参与者在构建协调策略过程中的反馈，并询问他们在此过程中遇到的挑战。对于在访谈开始时报告有过使用基于LLM的多智能体框架经验的参与者，我们还要求他们将基于自然语言的方法与他们之前使用过的框架进行对比，分析其优缺点。
- en: 3.2 Findings
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 发现
- en: All participants find using natural language to design coordination strategies
    is intuitive and could be a promising approach to democratizing agent coordination
    for a wider general audience. However, several challenges are also identified,
    which hinder the participants’ current exploration process to design coordination
    strategies at their will.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者都认为使用自然语言设计协调策略是直观的，并且这种方法有可能成为使更广泛的公众能够民主化智能体协调的有前景的方式。然而，也发现了一些挑战，阻碍了参与者在设计协调策略时的自由探索过程。
- en: 'Lack of structure to regularize the ambiguity of natural language. Although
    natural language is easy to understand and highly expressive, it is prone to ambiguity.
    For example, for a high-level cooperation strategy description “Pharmaceutical
    Chemist, Patent Agent, and Clinical Research Scientist collaboratively drafting
    a patent application”, there could be many ambiguous aspects: “Who takes the main
    responsibility for drafting?”, “How are opinions integrated?”… During the formative
    study, we notice that users often start with a generated collaborative strategy
    and then, upon observing the unexpected outcomes, identify areas that were not
    articulated and make remedial enhancements to the original cooperation strategy.
    After several rounds, the collaborative strategy specification “could be lengthy
    and messy to read” (G4), and “sometimes even contain self-conflicts” (G3). Both
    E1 and E4 suggest that “some structures should be provided to regularize the design
    process” (E1, E4), which can “draw on designs from current code-based frameworks”
    (E1).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏结构来规范自然语言的模糊性。尽管自然语言易于理解且表达力强，但它容易产生歧义。例如，对于一个高层次的合作策略描述“药物化学家、专利代理人和临床研究科学家共同起草专利申请”，可能会有许多模糊的方面：“谁负责主要的起草工作？”，“意见如何整合？”……在形成性研究过程中，我们注意到用户通常先从生成的合作策略开始，然后在观察到意外结果时，识别出未明确表达的领域，并对原始合作策略进行补充完善。经过几轮后，合作策略规范“可能会变得冗长且难以阅读”（G4），并且“有时甚至会包含自相矛盾的内容”（G3）。E1和E4都建议“应该提供一些结构来规范设计过程”（E1，E4），这可以“借鉴当前基于代码的框架设计”（E1）。
- en: Lost in the vast amount of intricate text. During the process of designing collaborative
    strategies, users need to refer to a substantial amount of text information (e.g.,
    previously designed collaborative strategies, descriptions of different agents,
    input/output of agents, intermediate objects). The vast amount of intricate text
    poses significant cognitive overhead on users during the design process. Many
    participants express the feeling that the quantity of text is “overwhelming” (E3,
    E4, G1-G4). They usually needed to “manually switch back and forth between different
    parts of the texts” (G2) and “sometimes forget where to find” (G3). E3 mentioned
    that “as the complexity of my strategy rises, maintain a clear connection between
    specific execution result and the corresponding part of my strategy become challenging”
    (E3). The Participants also express the need to “have a visual interface that
    helps organize information” (G2, E3).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在大量复杂的文本中迷失。在设计合作策略的过程中，用户需要参考大量的文本信息（例如，之前设计的合作策略、不同代理人的描述、代理人的输入/输出、中间对象）。大量复杂的文本在设计过程中给用户带来了显著的认知负担。许多参与者表示，文本数量“压倒性”（E3，E4，G1-G4）。他们通常需要“手动在不同的文本部分之间来回切换”（G2）并且“有时会忘记在哪里查找”（G3）。E3提到，“随着策略复杂性的增加，保持特定执行结果与相应策略部分的清晰联系变得具有挑战性”（E3）。参与者还表示需要“有一个可视化界面来帮助组织信息”（G2，E3）。
- en: Lack of interactions support to facilitate exploration. To leverage the powerful
    coordination capabilities of LLMs and deal with “writer’s block”, participants
    often chat with LLMs (e.g. using ChatGPT) to aid them in drafting and exploring
    coordination strategies. However, the linear non-reversible conversation interface
    for chatting is not designed for iterative multi-thread exploration. E2 mentioned
    that “managing exploration history and toggling between different possibilities
    with manual copy & paste is cumbersome” (E2). Additionally, participants also
    mentioned concerns over the fluidity of exploration due to the need for “manually
    craft auxiliary prompts for different exploration purposes” (G2). Moreover, due
    to the stochastic nature of LLM outputs (which is also greatly affected by prompts)
    and diverse possibilities for strategy design, participants express the need for
    “an interface to help systematically explore and compare different outputs by
    LLM” (G1).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏交互支持来促进探索。为了利用LLM强大的协调能力并应对“写作障碍”，参与者通常会与LLM（例如使用ChatGPT）进行聊天，以帮助他们起草和探索协调策略。然而，线性的、不可逆的聊天界面并未针对迭代的多线程探索进行设计。E2提到，“管理探索历史并在不同的可能性之间切换，通过手动复制和粘贴是很繁琐的”（E2）。此外，参与者还提到，由于需要“手动制作辅助提示来进行不同的探索目的”，探索的流畅性也成为了问题（G2）。此外，由于LLM输出的随机性（这也受到提示的重大影响）以及策略设计的多样性，参与者表示需要“一种界面来帮助系统性地探索和比较LLM的不同输出”（G1）。
- en: 3.3 Design Requirement
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 设计需求
- en: 'In response to the problems identified in the formative study, our goal is
    to develop an interactive system to help general users smoothly explore and design
    coordination strategies for LLM-based Multi-agent collaboration. The design requirements
    are summarized as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 针对初步研究中发现的问题，我们的目标是开发一个互动系统，帮助普通用户顺利地探索和设计基于LLM的多智能体协作的协调策略。设计需求总结如下：
- en: 'R1: Generate a structured coordination strategy for the user’s goal. Although
    using natural language to describe a coordination strategy lowers the barrier
    for users and brings a high level of flexibility, users often lack an effective
    way to deal with its ambiguity. Therefore, the system should provide a structure
    of coordination strategy to help regularize the ambiguity inherent in natural
    language and serve as a scaffolding for downstream exploration. Moreover, to help
    the user kick off, the system should be able to generate an initial coordination
    strategy based on the user’s goal leveraging the coordination capability of LLMs.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: R1：为用户的目标生成结构化的协调策略。尽管使用自然语言描述协调策略降低了用户的门槛并带来了高度的灵活性，但用户往往缺乏有效的方式来处理其模糊性。因此，系统应提供协调策略的结构，帮助规范自然语言中固有的模糊性，并作为下游探索的支撑架构。此外，为了帮助用户入门，系统应能够根据用户的目标生成初步的协调策略，利用LLMs的协调能力。
- en: 'R2: Provide an effective visual organization for the strategy. When users are
    devising a coordination strategy, they need to refer to various types of relevant
    information represented in the text. However, at present, users have to flip back
    and forth through a vast amount of plain text to search for target information
    and do verification, which creates a significant cognitive load. Therefore, the
    system should effectively visually organize and enhance the various pieces of
    information involved in the coordination strategy design process to help users
    quickly locate the information they need and provide the relevant context.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: R2：为策略提供有效的视觉组织。当用户制定协调策略时，他们需要参考以文本形式呈现的各种相关信息。然而，目前，用户必须在大量纯文本中来回翻阅，寻找目标信息并进行验证，这带来了显著的认知负担。因此，系统应有效地视觉组织并增强协调策略设计过程中涉及的各种信息，帮助用户快速定位所需信息并提供相关上下文。
- en: 'R3: Support flexible interactions to facilitate strategy exploration. Users
    often need to explore various possible options at different stages of the coordination
    strategy design with the help of LLMs; however, iterative exploration based on
    a linear chat interface with LLMs is cumbersome and unintuitive. Therefore, the
    system should support flexible and intuitive interactions to help users conduct
    multi-thread iterative exploration. Moreover, the system needs to offer assistance
    to help systematically explore and compare different design choices for coordination
    strategies.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: R3：支持灵活的交互方式，以促进策略探索。用户通常需要在协调策略设计的不同阶段，借助大型语言模型（LLMs）探索各种可能的选项；然而，基于线性聊天界面的迭代探索既繁琐又不直观。因此，系统应支持灵活且直观的交互方式，帮助用户进行多线程迭代探索。此外，系统还需要提供帮助，以帮助用户系统地探索和比较不同的协调策略设计选择。
- en: 'R4: Provide visual enhancement for the execution result. During the execution
    of collaborative tasks, agents generate a substantial amount of textual information.
    However, at present, both code-based and natural language-based agent coordination
    frameworks only output results through a plain text terminal. Users often have
    to manually switch back and forth between different parts of the coordination
    strategy and the execution results to establish connections, which increases cognitive
    load and decreases analytical efficiency. Therefore, the system needs to provide
    visual enhancements to help users examine execution results.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: R4：为执行结果提供视觉增强。在协作任务执行过程中，智能体会生成大量的文本信息。然而，目前基于代码和基于自然语言的智能体协调框架仅通过纯文本终端输出结果。用户往往需要手动在协调策略的不同部分和执行结果之间来回切换，以建立连接，这增加了认知负担并降低了分析效率。因此，系统需要提供视觉增强功能，帮助用户检查执行结果。
- en: 4 Structured Coordination Strategy Generation
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结构化协调策略生成
- en: 'In this section, we abstract a structured representation for coordination strategy
    design (Section [4.1](https://arxiv.org/html/2404.11943v1#S4.SS1 "4.1 Structured
    Representation for Coordination Strategy ‣ 4 Structured Coordination Strategy
    Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration")) to regularize the ambiguity of natural language (R1).
    Based on this structure, a three-stage generation method (Section [4.2](https://arxiv.org/html/2404.11943v1#S4.SS2
    "4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration")) has been designed to automatically generate an initial coordination
    strategy based on the user’s goal (R1).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们为协调策略设计抽象了一个结构化表示（第[4.1](https://arxiv.org/html/2404.11943v1#S4.SS1 "4.1
    协调策略的结构化表示 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于 LLM 的多智能体协作的协调策略可视化探索")节），以规范自然语言的模糊性（R1）。基于这个结构，我们设计了一个三阶段生成方法（第[4.2](https://arxiv.org/html/2404.11943v1#S4.SS2
    "4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于 LLM 的多智能体协作的协调策略可视化探索")节），自动生成基于用户目标的初步协调策略（R1）。
- en: 4.1 Structured Representation for Coordination Strategy
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 协调策略的结构化表示
- en: To maximize the expressiveness of the structure defined for coordination strategy,
    E1-4 and we collaboratively survey a corpus of 25 LLM-based Multi-agent collaboration
    papers and 7 high star open source frameworks [[12](https://arxiv.org/html/2404.11943v1#bib.bib12),
    [14](https://arxiv.org/html/2404.11943v1#bib.bib14), [38](https://arxiv.org/html/2404.11943v1#bib.bib38),
    [21](https://arxiv.org/html/2404.11943v1#bib.bib21), [3](https://arxiv.org/html/2404.11943v1#bib.bib3),
    [25](https://arxiv.org/html/2404.11943v1#bib.bib25), [4](https://arxiv.org/html/2404.11943v1#bib.bib4)]
    for Multi-agent coordination. We analyze the common concepts and structures found
    in the description for coordination strategy in those papers and projects, based
    on which we establish a common structure for LLM-based Multi-agent coordination
    strategy.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化协调策略结构的表现力，E1-4 和我们共同调查了 25 篇基于 LLM 的多智能体协作论文和 7 个高星开源框架 [[12](https://arxiv.org/html/2404.11943v1#bib.bib12),
    [14](https://arxiv.org/html/2404.11943v1#bib.bib14), [38](https://arxiv.org/html/2404.11943v1#bib.bib38),
    [21](https://arxiv.org/html/2404.11943v1#bib.bib21), [3](https://arxiv.org/html/2404.11943v1#bib.bib3),
    [25](https://arxiv.org/html/2404.11943v1#bib.bib25), [4](https://arxiv.org/html/2404.11943v1#bib.bib4)]，以用于多智能体协调。我们分析了这些论文和项目中协调策略描述中常见的概念和结构，基于此，我们为基于
    LLM 的多智能体协调策略建立了一个通用结构。
- en: 'We depict the relationship between key concepts involved in the coordination
    strategy structure as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们描述了协调策略结构中涉及的关键概念之间的关系，如下所示：
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Plan Outline: Provides a blueprint for the overall collaboration, typically
    breaking the objectives down into a sequence of Tasks to be carried out one after
    the other.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计划大纲：为整体协作提供蓝图，通常将目标分解为一个接一个执行的任务序列。
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task: Takes Key Objects as input and output its target Key Object. The task
    process specifies how Agents collaboratively finished the task.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务：以关键对象为输入，并输出其目标关键对象。任务过程指定了智能体如何协作完成任务。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Key Object: Important intermediate objects during collaboration.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关键对象：协作过程中重要的中介对象。
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Agent: Intelligent entity that can perform Action according to its observation
    and Instruction.'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 智能体：能够根据其观察和指令执行动作的智能实体。
- en: •
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Action: The smallest unit of agent behavior observable.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 动作：智能体行为的最小观察单元。
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Instruction: Natural language-based specification that tells agent what/how
    to do.'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指令：基于自然语言的规范，告知智能体做什么/如何做。
- en: 4.2 Three-stage Strategy Generation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 三阶段策略生成
- en: To help users kick off the exploration, we design a three-stage generation method
    to provide an initial coordination strategy based on the goal of the user, leveraging
    the coordination capability of LLM. Details of all the prompts used can be found
    in our project repository.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助用户启动探索，我们设计了一个三阶段生成方法，基于用户的目标提供初步的协调策略，利用 LLM 的协调能力。所有使用的提示的详细信息可以在我们的项目仓库中找到。
- en: '4.2.1 Stage1: Plan Outline Generation'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 阶段 1：计划大纲生成
- en: 'Given a general description of the goal $g$ provided by the user and a set
    of initial key objects $\mathcal{I}=\{ko_{1},ko_{2},...,ko_{n}\}$, the goal of
    the Plan Outline Generation stage is to draft a plan outline that decomposes the
    final goal into a sequence of step tasks $\mathcal{P}=\{t_{1},t_{2},...,t_{n}\}=\{t_{i}\}|_{i=0}^{n}$.
    Here each task $t_{i}$ contains the following attributes:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 给定用户提供的目标$g$的总体描述和一组初始关键对象$\mathcal{I}=\{ko_{1},ko_{2},...,ko_{n}\}$，计划大纲生成阶段的目标是草拟一个计划大纲，将最终目标分解为一系列步骤任务$\mathcal{P}=\{t_{1},t_{2},...,t_{n}\}=\{t_{i}\}|_{i=0}^{n}$。这里，每个任务$t_{i}$包含以下属性：
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Step Name: A clear and concise name summarizing the step.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 步骤名称：总结该步骤的清晰简明名称。
- en: •
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task Content: Task description of the current step.'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务内容：当前步骤的任务描述。
- en: •
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Input Object List: The input key objects that will be used in the current step.'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入对象列表：当前步骤将使用的输入关键对象。
- en: •
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Output Object: The output key object of the current step.'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出对象：当前步骤的输出关键对象。
- en: 'To achieve this, we prompt the LLM to serve as an expert plan outline designer
    to carefully analyze and decompose the goal provided by the user and output the
    plan outline $\mathcal{P}$:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，我们提示LLM充当专家计划大纲设计师，仔细分析并分解用户提供的目标，输出计划大纲$\mathcal{P}$：
- en: '|  | $\mathcal{P}=\text{LLM}(g,\mathcal{I},\texttt{prompt}_{\texttt{stage1}})$
    |  | (1) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{P}=\text{LLM}(g,\mathcal{I},\texttt{prompt}_{\texttt{stage1}})$
    |  | (1) |'
- en: '4.2.2 Stage2: Agent Assignment'
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 阶段2：代理分配
- en: After the plan outline is generated, a team of agents $\mathcal{A}_{i}=\{agent_{1},agent_{2},...,agent_{n\}}$
    should be assigned for each task $t_{i}$. Those agents are selected from a board
    of agent candidates $\mathcal{AB}=\{agent_{1},agent_{2},...agent_{m}\}(\mathcal{A}_{i}\subseteq%
    \mathcal{AB})$ provided by user. The agents in agent board $\mathcal{AB}$ can
    be obtained through role prompting[[42](https://arxiv.org/html/2404.11943v1#bib.bib42)],
    LLM fine-tuning[[34](https://arxiv.org/html/2404.11943v1#bib.bib34)], retrieval-augmented
    generation (RAG) [[13](https://arxiv.org/html/2404.11943v1#bib.bib13)], or even
    recruitment from an agent store[[1](https://arxiv.org/html/2404.11943v1#bib.bib1),
    [22](https://arxiv.org/html/2404.11943v1#bib.bib22), [31](https://arxiv.org/html/2404.11943v1#bib.bib31)].
    Each agent should have a profile to describe its expertise for the coordinator’s
    reference.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成计划大纲后，应为每个任务$t_{i}$分配一组代理$\mathcal{A}_{i}=\{agent_{1},agent_{2},...,agent_{n}\}$。这些代理是从用户提供的代理候选人名单$\mathcal{AB}=\{agent_{1},agent_{2},...agent_{m}\}(\mathcal{A}_{i}\subseteq
    \mathcal{AB})$中选择的。代理候选人名单$\mathcal{AB}$中的代理可以通过角色提示[[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]、LLM微调[[34](https://arxiv.org/html/2404.11943v1#bib.bib34)]、检索增强生成（RAG）[[13](https://arxiv.org/html/2404.11943v1#bib.bib13)]，甚至从代理商店招募[[1](https://arxiv.org/html/2404.11943v1#bib.bib1),
    [22](https://arxiv.org/html/2404.11943v1#bib.bib22), [31](https://arxiv.org/html/2404.11943v1#bib.bib31)]。每个代理应有一个个人资料，描述其专长，以供协调员参考。
- en: 'To make suitable agent assignment for each task $t_{i}$, we prompt the LLM
    to serve as an expert manager that analyzes the aspects of ability needed for
    $t_{i}$ and read the profile for each candidate agent in agent board $\mathcal{AB}$
    to output $\mathcal{A}_{i}$:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为每个任务$t_{i}$进行适当的代理分配，我们提示LLM充当专家经理，分析任务$t_{i}$所需的能力方面，并读取代理候选人名单$\mathcal{AB}$中每个代理的个人资料，以输出$\mathcal{A}_{i}$：
- en: '|  | $\mathcal{A}_{i}=\text{LLM}(g,t_{i},\mathcal{AB},\texttt{prompt}_{\texttt{stage%
    2}})$ |  | (2) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{A}_{i}=\text{LLM}(g,t_{i},\mathcal{AB},\texttt{prompt}_{\texttt{stage\%2}})$
    |  | (2) |'
- en: 'Figure 1: System interface of AgentCoord. The first three views (Plan Outline
    View, Agent Assignment View, Task Process View) correspond to the three-stage
    coordination strategy generation process while the last view presents the execution
    result.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：AgentCoord系统界面。前三个视图（计划大纲视图、代理分配视图、任务过程视图）对应于三阶段的协调策略生成过程，而最后一个视图展示了执行结果。
- en: '4.2.3 Stage3: Task Process Generation'
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3 阶段3：任务过程生成
- en: 'Once the team of agents $\mathcal{A}_{i}$ are assigned to task $t_{i}$, we
    can finally specify the task process $\mathcal{S}_{i}=\{action_{1},action_{2},...,action_{n}\}$
    for task $t_{i}$, which describes how agents conduct actions to collaboratively
    finish task $t_{i}$. Here each action contains the following attributes:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦代理团队$\mathcal{A}_{i}$被分配到任务$t_{i}$，我们最终可以指定任务过程$\mathcal{S}_{i}=\{action_{1},action_{2},...,action_{n}\}$，描述代理如何协作完成任务$t_{i}$。这里，每个行动包含以下属性：
- en: •
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Agent Name: The name of the agent to conduct this action.'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代理名称：执行此操作的代理名称。
- en: •
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Instruction: The instruction for this action, tells the agent what/how to do.'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指令：执行该操作的指令，告诉代理应该如何做。
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interaction Type: Classify the action based on cooperative interaction type,
    which can be one of “propose” (propose something that may contribute to the current
    task), “critique” (provide feedback to the action result of other agents), “improve”
    (improve the result of a previous action), and “finalize” (deliver the final result
    for current task based on previous actions).'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 交互类型：根据合作交互类型分类动作，可以是以下之一：“提议”（提出可能有助于当前任务的内容）、“批评”（对其他代理的行动结果提供反馈）、“改进”（改进先前行动的结果）和“最终确定”（基于先前的行动交付当前任务的最终结果）。
- en: •
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Important Input: Previous information that is important for performing current
    action, which can be certain action results of other agents or previous key objects.'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要输入：执行当前动作时重要的先前信息，可能是其他代理的某些行动结果或先前的关键对象。
- en: Note that although it is enough to use “Agent Name” and “Description” to define
    an action for execution, here we propose two auxiliary attributes (“Interaction
    Type” and “Important Input”) to help articulate its relationship with other actions
    in the context of collaboration.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然仅使用“代理名称”和“描述”来定义执行动作就足够了，但在此我们提出了两个辅助属性（“交互类型”和“重要输入”）来帮助阐明它在协作背景下与其他动作的关系。
- en: 'To generate the specification for the task process $t_{i}$, we prompt the LLM
    to serve as an expert collaboration coordinator to carefully read the profile
    of each agent assigned to the current task $t_{i}$ and output the task process
    specification ${S}_{i}$:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成任务过程 $t_{i}$ 的规范，我们提示 LLM 作为专家协作协调员，仔细阅读分配给当前任务 $t_{i}$ 的每个代理的资料，并输出任务过程规范
    ${S}_{i}$：
- en: '|  | $\mathcal{S}_{i}=\text{LLM}(g,t_{i},\mathcal{A}_{i},\texttt{prompt}_{\texttt{%
    stage3}})$ |  | (3) |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{S}_{i}=\text{LLM}(g,t_{i},\mathcal{A}_{i},\texttt{prompt}_{\texttt{%
    stage3}})$ |  | (3) |'
- en: 5 AgentCoord System
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 AgentCoord 系统
- en: 'In this section, we elaborate on how AgentCoord System visually organizes the
    coordination strategy (Section [5.1](https://arxiv.org/html/2404.11943v1#S5.SS1
    "5.1 Visual Organization for Coordination Strategy ‣ 5 AgentCoord System ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration"))
    to facilitate user’s comprehension (R2), provides interactions to assist alternative
    strategy exploration (R3) (Section [5.2](https://arxiv.org/html/2404.11943v1#S5.SS2
    "5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣
    AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration")), and visually enhances the text form execution result to aid
    examination (R4) (Section [5.3](https://arxiv.org/html/2404.11943v1#S5.SS3 "5.3
    Execution Result Examination ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration")). To facilitate
    understanding of the system usage, we illustrate it through an example that coordinates
    multiple LLM-based agents in writing a novel.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们详细阐述了 AgentCoord 系统如何通过可视化方式组织协调策略（第 [5.1](https://arxiv.org/html/2404.11943v1#S5.SS1
    "5.1 Visual Organization for Coordination Strategy ‣ 5 AgentCoord System ‣ AgentCoord:
    Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")
    节）以便用户理解（R2），提供交互来帮助探索替代策略（R3）（第 [5.2](https://arxiv.org/html/2404.11943v1#S5.SS2
    "5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣
    AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") 节），并通过可视化增强文本形式的执行结果以辅助审查（R4）（第 [5.3](https://arxiv.org/html/2404.11943v1#S5.SS3
    "5.3 Execution Result Examination ‣ 5 AgentCoord System ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration") 节）。为了便于理解系统的使用，我们通过一个示例来说明它如何协调多个基于
    LLM 的代理进行写作小说。'
- en: 5.1 Visual Organization for Coordination Strategy
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 协调策略的可视化组织
- en: 'To first obtain an initial coordination strategy to kick off the exploration,
    the user clicks the  icon in agent board ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ) to add a pool of candidate
    agents, and enters “Write a novel about the awakening of artificial intelligence”
    as the general goal for the collaboration. After a while, the system returns an
    initial coordination strategy that specifies how several agents selected from
    the agent board collaboratively reach the given goal.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了首先获得一个初步的协调策略以启动探索，用户点击代理面板中的图标 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索"))
    来添加一个候选代理池，并输入“写一篇关于人工智能觉醒的小说”作为协作的总体目标。过一会儿，系统返回一个初步的协调策略，指定从代理面板中选择的若干代理如何协作以实现给定目标。
- en: 'As illustrated in [Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2
    Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration"), the generated coordination
    strategy is visually organized into four sub-views. In particular, the first three
    sub-views— Plan Outline View ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ), Agent Board View ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ), and Task Process View ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") )—correspond to the three-stage
    coordination strategy generation process described in Section [4.2](https://arxiv.org/html/2404.11943v1#S4.SS2
    "4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration"). The user can scroll vertically within each view to review the
    respective aspects. Furthermore, when the user gets interested in information
    about a specific task, clicking on it will reveal details and visually connect
    its relevant information across the other views.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成
    ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索")所示，生成的协调策略被可视化地组织成四个子视图。特别地，前三个子视图——计划大纲视图
    ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成
    ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索"))、代理面板视图 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索"))
    和任务流程视图 ([图 1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2
    三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索"))——对应于第[4.2节](https://arxiv.org/html/2404.11943v1#S4.SS2
    "4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作的协调策略可视化探索")中描述的三阶段协调策略生成过程。用户可以在每个视图内垂直滚动，查看各自的方面。此外，当用户对某个特定任务的信息感兴趣时，点击该任务将显示详细信息，并在其他视图中可视化地连接其相关信息。
- en: 'Plan Outline View illustrates how the general goal input by the user is decomposed
    into a series of step tasks. To elucidate the dependencies between different tasks,
    we use a bipartite graph to represent the relationship between the set of key
    objects ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2 Stage2:
    Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination
    Strategy Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration") ) and task sequence of the whole process
    ( [Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2 Stage2: Agent Assignment
    ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy Generation
    ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") ). A key object node can be the output of a task node or provided
    by the user by clicking the  button in [Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") . A task node is connected
    with its input key objects with edge colored in green, and connected with its
    output key object with edge colored in orange. Furthermore, by clicking on a task
    node ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2 Stage2: Agent
    Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy
    Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration") ), the user can manually adjust the task content and
    the dependence it has on other key objects. If the user wants to explore alternative
    plan outlines, they can click on the  button to invoke Plan Outline Exploration
    View (detailed in Section [5.2.1](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS1
    "5.2.1 Plan Outline Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration")).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 计划大纲视图展示了用户输入的整体目标如何被分解为一系列步骤任务。为了阐明不同任务之间的依赖关系，我们使用二分图来表示关键对象集（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）与整个过程的任务顺序（[图
    1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣
    4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）之间的关系。关键对象节点可以是任务节点的输出，也可以通过用户点击[图
    1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣
    4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")中的按钮由用户提供。任务节点通过绿色边与其输入关键对象连接，通过橙色边与其输出关键对象连接。此外，用户可以通过点击任务节点（[图
    1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣
    4 结构化协调策略生成 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）手动调整任务内容及其与其他关键对象的依赖关系。如果用户想要探索替代的计划大纲，可以点击按钮调用计划大纲探索视图（详见第[5.2.1节](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS1
    "5.2.1 计划大纲探索 ‣ 5.2 替代策略的交互式探索 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多代理协作策略可视化探索")）。
- en: 'Agent Board View exhibits all agents the user can assign during the coordination
    strategy design process. By default, each agent card ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ) presents the agent’s name,
    avatar, and profile for the user’s reference. If the user is currently focused
    on a specific task, the agents assigned to that task will be automatically elevated
    to the top of the agent board. Additionally, the actions planned to be executed
    by an agent in the current task are aggregated and showcased within its agent
    card ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2 Stage2: Agent
    Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy
    Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration") ), helping user better understand the role it plays
    in the current task. If the user wants to explore alternative agent assignments
    for the current task, they can click on the  button to invoke Agent Assignment
    Exploration View (detailed in Section [5.2.2](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS2
    "5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration")).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 代理板视图展示了用户在协调策略设计过程中可以分配的所有代理。默认情况下，每个代理卡片（[图1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在4.2.2阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")）展示了代理的名称、头像和简介，供用户参考。如果用户当前专注于特定任务，则分配给该任务的代理将自动提升到代理板的顶部。此外，计划在当前任务中由代理执行的操作会被汇总并展示在其代理卡片内（[图1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在4.2.2阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")），帮助用户更好地理解其在当前任务中所扮演的角色。如果用户希望探索当前任务的替代代理分配方案，可以点击按钮调用代理分配探索视图（详见第[5.2.2](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS2
    "5.2.2 代理分配探索 ‣ 5.2 替代策略的互动探索 ‣ 5 AgentCoord系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")节）。
- en: 'Task Process View provides a natural language description of how the task processes
    are conducted. To enhance the user’s comprehension of the descriptions, we offer
    a template-based summary ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In
    4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ) for each task, in which crucial
    elements are visually accentuated—input key objects are highlighted in green,
    output key objects in orange, and both agent names and task content are set against
    a grey background. The user can click the template-based summary for a task to
    unveil detailed specifications for the task process ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ). The task process specification
    is composed of a sequence of descriptions about how each agent performs its action
    to contribute to the task. To facilitate the user’s understanding of this process
    in terms of cooperative interaction, we use different colors to highlight the
    interaction type for each action according to the “interaction type” classification
    criteria explained in Section [4.2.3](https://arxiv.org/html/2404.11943v1#S4.SS2.SSS3
    "4.2.3 Stage3: Task Process Generation ‣ 4.2 Three-stage Strategy Generation ‣
    4 Structured Coordination Strategy Generation ‣ AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration"). Moreover, the
    user is able to manually adjust the instruction for each action. If the user wants
    to explore alternative task process specifications, they can click on the  button
    to invoke Task Process Exploration View (detailed in Section [5.2.3](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS3
    "5.2.3 Task Process Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration")).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 任务流程视图提供了任务流程如何进行的自然语言描述。为了增强用户对描述的理解，我们为每个任务提供了基于模板的摘要（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索")
    ），其中关键元素得到了视觉突显——输入关键对象以绿色突出显示，输出关键对象以橙色突出显示，代理名称和任务内容则设置在灰色背景上。用户可以点击任务的基于模板的摘要，展开任务流程的详细规格说明（[图
    1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣
    4 结构化协调策略生成 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索") ）。任务流程规范由一系列描述组成，阐述每个代理如何执行其操作以推动任务的完成。为了帮助用户从合作互动的角度理解这一过程，我们根据[4.2.3](https://arxiv.org/html/2404.11943v1#S4.SS2.SSS3
    "4.2.3 阶段3：任务流程生成 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索")节中解释的“互动类型”分类标准，使用不同的颜色突出显示每个操作的互动类型。此外，用户还可以手动调整每个操作的指令。如果用户想探索替代的任务流程规范，可以点击按钮调用任务流程探索视图（详见[5.2.3](https://arxiv.org/html/2404.11943v1#S5.SS2.SSS3
    "5.2.3 任务流程探索 ‣ 5.2 替代策略的交互式探索 ‣ 5 AgentCoord 系统 ‣ AgentCoord：面向基于大语言模型的多代理协作的协调策略可视化探索")）。
- en: 5.2 Interactive Exploration for Alternative Strategy
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 替代策略的交互式探索
- en: 'Upon understanding the current coordination strategy, users can interactively
    explore its alternatives across three specific aspects: Plan Outline (Section
    [5.1](https://arxiv.org/html/2404.11943v1#S5.SS1 "5.1 Visual Organization for
    Coordination Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration")), Agent Assignment (Section
    [5.2](https://arxiv.org/html/2404.11943v1#S5.SS2 "5.2 Interactive Exploration
    for Alternative Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring
    Coordination Strategy for LLM-based Multi-Agent Collaboration")), and Task Process
    (Section [5.3](https://arxiv.org/html/2404.11943v1#S5.SS3 "5.3 Execution Result
    Examination ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration")). For each aspect, we provide
    an illustrative exploration example of the user to showcase the supported interactions.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解当前的协调策略后，用户可以在三个特定方面互动式地探索其替代方案：计划概述（第[5.1节](https://arxiv.org/html/2404.11943v1#S5.SS1
    "5.1 视觉化组织协调策略 ‣ 5 AgentCoord系统 ‣ AgentCoord：视觉化探索基于LLM的多智能体协作的协调策略")）、代理分配（第[5.2节](https://arxiv.org/html/2404.11943v1#S5.SS2
    "5.2 替代策略的互动探索 ‣ 5 AgentCoord系统 ‣ AgentCoord：视觉化探索基于LLM的多智能体协作的协调策略")）和任务过程（第[5.3节](https://arxiv.org/html/2404.11943v1#S5.SS3
    "5.3 执行结果检查 ‣ 5 AgentCoord系统 ‣ AgentCoord：视觉化探索基于LLM的多智能体协作的协调策略")）。对于每个方面，我们提供了一个示例，展示用户如何进行互动式探索。
- en: 5.2.1 Plan Outline Exploration
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 计划概述探索
- en: 'Figure 2: An illustrative example of plan outline exploration.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：计划概述探索的示例。
- en: 'Looking at the plan outline shown in [Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "In 4.2.2 Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration"), the user finds most key elements
    (e.g. “Main Theme”, “Character List”) for the novel are determined before the
    “Plot Development” task while the last two tasks (“Writing Draft”, “Review and
    Editing”) are less interesting common routines. Therefore, the user decides to
    merge the last two tasks into one step and explore more possibilities for the
    tasks before “Plot Development”. To achieve this, the user opens the Plan Outline
    Exploration View ([Fig. 2](https://arxiv.org/html/2404.11943v1#S5.F2 "In 5.2.1
    Plan Outline Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy
    ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration")). The user first clicks the bottom of the
    “Plot Development” task node to create a branch from this task and enters “add
    a step to finalize” ([Fig. 2](https://arxiv.org/html/2404.11943v1#S5.F2 "In 5.2.1
    Plan Outline Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy
    ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration") A). Behind the scenes, an LLM is prompted
    to complete this branch based on the requirement entered by the user. After the
    new branch is completed, the user clicks the starting point of the branch and
    further enters “adjust steps before Plot Development, everything else same as
    baseline” ([Fig. 2](https://arxiv.org/html/2404.11943v1#S5.F2 "In 5.2.1 Plan Outline
    Exploration ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord
    System ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") B). Note that this time the user also selects a branch (highlighted
    with green color) to tell the LLM which branch is the “baseline” referred to in
    the entered requirement and sets the number of created new branches as three to
    explore more possibilities. The system then returns three branches with variation
    before the “Plot Development” step ([Fig. 2](https://arxiv.org/html/2404.11943v1#S5.F2
    "In 5.2.1 Plan Outline Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration") C). Comparing these three choices, the
    user finally selects the middle one as the new plan outline for collaboration.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从[图1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成
    ‣ 4 结构化协调策略生成 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")中展示的计划大纲来看，用户发现小说的多数关键元素（例如“主要主题”，“角色列表”）在“情节发展”任务之前就已确定，而最后两个任务（“写作草稿”，“审查和编辑”）则是比较常见的常规步骤，因此用户决定将这两个任务合并为一步，并探索“情节发展”之前任务的更多可能性。为此，用户打开了计划大纲探索视图（[图2](https://arxiv.org/html/2404.11943v1#S5.F2
    "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")）。用户首先点击“情节发展”任务节点的底部，从该任务创建一个分支，并进入“添加一个步骤以最终确定”([图2](https://arxiv.org/html/2404.11943v1#S5.F2
    "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")
    A)。在后台，LLM根据用户输入的需求提示完成此分支。新分支完成后，用户点击分支的起始点，进一步进入“调整情节发展之前的步骤，其他部分与基准相同”([图2](https://arxiv.org/html/2404.11943v1#S5.F2
    "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")
    B)。请注意，这次用户还选择了一个分支（用绿色突出显示），以告诉LLM哪个分支是所输入需求中提到的“基准”，并设置新创建分支的数量为三个，以探索更多的可能性。系统随后返回三个在“情节发展”步骤之前有变动的分支([图2](https://arxiv.org/html/2404.11943v1#S5.F2
    "在 5.2.1 计划大纲探索 ‣ 5.2 互动探索替代策略 ‣ 5 AgentCoord 系统 ‣ AgentCoord：基于LLM的多代理协作的协调策略可视化探索")
    C)。对比这三个选择后，用户最终选择中间的一个作为新的协作计划大纲。
- en: 5.2.2 Agent Assignment Exploration
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 代理分配探索
- en: 'Figure 3: An illustrative example of agent assignment exploration.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：代理分配探索的示例说明。
- en: 'The user finds that the “theme selection” step task only involves two agents
    (“Futurist” and “Science Fiction Writer"). However, the user hopes that more agents
    with diverse backgrounds can participate in the brainstorming for themes. For
    instance, the user wishes for someone to inject romantic elements into the stories,
    and someone with a solid tech background to ensure the technical plausibility
    of the themes. To achieve this, the user opens the Agent Assignment Exploration
    View. The exploration view displays the scores for each agent on the agent board
    with a heatmap, based on the LLM’s assessment of three capabilities it deems important
    for completing the current task ([Fig. 3](https://arxiv.org/html/2404.11943v1#S5.F3
    "In 5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration") A). To help the user focus on agents
    more likely to be suitable for the current task, the system sorts assigned and
    unassigned agents separately in descending order based on their current average
    scores. The user then further enters two aspects (“AI Tech Understanding”, “Love
    Element Understanding”), and selects four aspects they deem important (“Creative
    Thinking”, “Knowledge of AI Ethics”, “AI Tech Understanding”, “Love Element Understanding”)
    as the new ranking criteria ([Fig. 3](https://arxiv.org/html/2404.11943v1#S5.F3
    "In 5.2.2 Agent Assignment Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration") B). Now the user finds two candidates
    (“AI Scientist” and “AI Engineer”) with strong AI Tech backgrounds. Although both
    candidates scored 5 for AI Tech Understanding, the user finds that the AI scientist
    overall has higher scores in the likelihood of possessing “Creative Thinking”
    and “Knowledge of AI Ethics”. Therefore, the user decides to add the AI scientist
    to the team. The user also finds that the LLM considers the “Poet” and “Cognitive
    Physiologist” likely to have a deeper understanding of the love element. Therefore,
    the user moves the mouse over the corresponding score block to view the reasons
    for the LLM’s scoring. After incorporating the user’s own analysis (believing
    that understanding love from a poetic rather than a psychological perspective
    is more fitting for creative scenarios), the user decides to add the poet to the
    team for the current task and click  to confirm the new agent assignment.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '用户发现“主题选择”步骤的任务仅涉及两个角色（“未来学家”和“科幻作家”）。然而，用户希望更多具有多样背景的角色能参与到主题的头脑风暴中。例如，用户希望有人能为故事注入浪漫元素，另外也希望有技术背景的人能确保主题的技术可行性。为了实现这一点，用户打开了角色分配探索视图。该视图通过热力图展示了每个角色在角色板上的得分，这些得分是基于LLM对完成当前任务所需的三项能力评估得出的（[图
    3](https://arxiv.org/html/2404.11943v1#S5.F3 "In 5.2.2 Agent Assignment Exploration
    ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣
    AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") A）。为了帮助用户更好地关注那些可能更适合当前任务的角色，系统根据角色的当前平均得分，将已分配和未分配的角色按降序分别排序。用户随后进一步选择了两个方面（“AI技术理解”、“爱情元素理解”），并选择了他们认为重要的四个方面（“创造性思维”、“AI伦理知识”、“AI技术理解”、“爱情元素理解”）作为新的排序标准（[图
    3](https://arxiv.org/html/2404.11943v1#S5.F3 "In 5.2.2 Agent Assignment Exploration
    ‣ 5.2 Interactive Exploration for Alternative Strategy ‣ 5 AgentCoord System ‣
    AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent
    Collaboration") B）。现在，用户发现有两个候选人（“AI科学家”和“AI工程师”）具有较强的AI技术背景。虽然两位候选人在AI技术理解方面都得了5分，但用户发现AI科学家在“创造性思维”和“AI伦理知识”的得分普遍较高。因此，用户决定将AI科学家加入团队。用户还发现，LLM认为“诗人”和“认知生理学家”可能对爱情元素有更深的理解。因此，用户将鼠标移动到相应的得分块上，以查看LLM评分的原因。在结合了用户自己的分析后（认为从诗意而非心理学的角度理解爱情更适合创意场景），用户决定将诗人加入当前任务团队，并点击确认新的角色分配。'
- en: 5.2.3 Task Process Exploration
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3 任务流程探索
- en: 'Figure 4: An illustrative example of task process exploration.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：任务流程探索的示例。
- en: 'Since the final story-writing task has a direct impact on the output of the
    novel, the user decides to intervene at a finer granularity in the task process
    of this step. Particularly, the user wants Isabella (the “Science Fiction Writer”)
    to lead the writing of the final draft and focus on the vividness of the final
    story. To achieve this, the user opens the Task Process Exploration View. The
    user first clicks the starting point of the branch and enters “Isabella takes
    the lead in writing novel while Carlos helps review” ([Fig. 4](https://arxiv.org/html/2404.11943v1#S5.F4
    "In 5.2.3 Task Process Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration") A). Behind the scenes, an LLM is prompted
    to generate a new task process based on this requirement. However, the user finds
    that although Isabella indeed takes on most of the writing in the new task process,
    the iterative process did not give sufficient attention to the vividness of the
    story. Therefore, the user selects the current branch as the baseline and creates
    another three branches with the requirement “the improvements for each draft should
    focus on enhancing the vividness of the story” ([Fig. 4](https://arxiv.org/html/2404.11943v1#S5.F4
    "In 5.2.3 Task Process Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration") B). The system returns with three variations
    of the task process that meet the requirement ([Fig. 4](https://arxiv.org/html/2404.11943v1#S5.F4
    "In 5.2.3 Task Process Exploration ‣ 5.2 Interactive Exploration for Alternative
    Strategy ‣ 5 AgentCoord System ‣ AgentCoord: Visually Exploring Coordination Strategy
    for LLM-based Multi-Agent Collaboration") C). The user then chooses the favorite
    one among the three and further iterates on it.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最终的故事写作任务直接影响小说的输出，用户决定在该步骤的任务过程中以更精细的粒度进行干预。特别是，用户希望伊莎贝拉（“科幻小说作家”）主导最终稿的写作，并关注故事的生动性。为此，用户打开了任务过程探索视图。用户首先点击分支的起点，输入“伊莎贝拉主导小说写作，而卡洛斯协助审阅”([图
    4](https://arxiv.org/html/2404.11943v1#S5.F4 "在 5.2.3 任务过程探索 ‣ 5.2 交互式探索替代策略 ‣
    5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多智能体协作视觉化协调策略") A)。在后台，LLM被提示根据这一需求生成新的任务过程。然而，用户发现，尽管伊莎贝拉确实承担了大部分写作工作，但迭代过程并未充分关注故事的生动性。因此，用户选择当前分支作为基准，并创建了另外三个分支，要求“每个草稿的改进应着重提升故事的生动性”([图
    4](https://arxiv.org/html/2404.11943v1#S5.F4 "在 5.2.3 任务过程探索 ‣ 5.2 交互式探索替代策略 ‣
    5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多智能体协作视觉化协调策略") B)。系统返回了符合该要求的三种任务过程变体([图
    4](https://arxiv.org/html/2404.11943v1#S5.F4 "在 5.2.3 任务过程探索 ‣ 5.2 交互式探索替代策略 ‣
    5 AgentCoord 系统 ‣ AgentCoord：基于大语言模型的多智能体协作视觉化协调策略") C)。然后，用户从三者中选择最喜欢的一种并进一步进行迭代。
- en: 5.3 Execution Result Examination
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 执行结果检查
- en: 'Once the user has completed the design of the coordination strategy, they can
    execute it and examine the outcomes by clicking the  button in the Execution Result
    View ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2 Stage2: Agent
    Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination Strategy
    Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for LLM-based
    Multi-Agent Collaboration") ). Instead of presenting the execution result in pure
    text forms like AuoGen[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)] and
    AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)], AgentCoord enhances
    the result with visual designs consistent with the previous design stages and
    explicit visual linkages to help users establish connections between the execution
    result and the strategy design. To prevent users from being overwhelmed by excessive
    textual information, we provide the option to selectively expand relevant results
    with a mouse click ([Fig. 1](https://arxiv.org/html/2404.11943v1#S4.F1 "In 4.2.2
    Stage2: Agent Assignment ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured
    Coordination Strategy Generation ‣ AgentCoord: Visually Exploring Coordination
    Strategy for LLM-based Multi-Agent Collaboration") ). Furthermore, to reduce the
    cognitive load of analyzing and help reveal connections between different execution
    results, when the user focuses on a particular execution result, other results
    with potential important dependencies (based on the Important Input field described
    in [Section 4.2.3](https://arxiv.org/html/2404.11943v1#S4.SS2.SSS3 "4.2.3 Stage3:
    Task Process Generation ‣ 4.2 Three-stage Strategy Generation ‣ 4 Structured Coordination
    Strategy Generation ‣ AgentCoord: Visually Exploring Coordination Strategy for
    LLM-based Multi-Agent Collaboration")) will be visually linked to it.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户完成了协调策略的设计，他们可以通过点击执行结果视图中的按钮来执行策略并检查结果（[图 1](https://arxiv.org/html/2404.11943v1#S4.F1
    "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：视觉探索基于LLM的多代理协作的协调策略")）。与像AuoGen[[38](https://arxiv.org/html/2404.11943v1#bib.bib38)]和AutoAgents[[3](https://arxiv.org/html/2404.11943v1#bib.bib3)]等系统仅以纯文本形式呈现执行结果不同，AgentCoord通过与先前设计阶段一致的视觉设计和显式的视觉链接增强结果，帮助用户建立执行结果与策略设计之间的联系。为了防止用户被过多的文本信息所淹没，我们提供了通过鼠标点击选择性展开相关结果的选项（[图
    1](https://arxiv.org/html/2404.11943v1#S4.F1 "在 4.2.2 阶段2：代理分配 ‣ 4.2 三阶段策略生成 ‣
    4 结构化协调策略生成 ‣ AgentCoord：视觉探索基于LLM的多代理协作的协调策略")）。此外，为了减少分析的认知负担，并帮助揭示不同执行结果之间的联系，当用户聚焦于特定的执行结果时，其他具有潜在重要依赖关系的结果（基于[第
    4.2.3 节](https://arxiv.org/html/2404.11943v1#S4.SS2.SSS3 "4.2.3 阶段3：任务流程生成 ‣ 4.2
    三阶段策略生成 ‣ 4 结构化协调策略生成 ‣ AgentCoord：视觉探索基于LLM的多代理协作的协调策略") 中描述的重要输入字段）将以视觉方式与其相连。
- en: 6 User Study
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 用户研究
- en: We conduct a user study to evaluate the feasibility and effectiveness of our
    approach in facilitating coordination strategy design for agent collaboration.
    Our evaluation focuses on (1) The effectiveness of the structured coordination
    strategy generation approach. (2) The overall effectiveness and usability of the
    interactive system. (3) the support for coordination strategy design compared
    with two baseline systems based on existing LLM-based multi-agent coordination
    frameworks.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项用户研究，以评估我们的方法在促进代理协作的协调策略设计中的可行性和有效性。我们的评估重点包括：(1) 结构化协调策略生成方法的有效性。(2)
    互动系统的整体有效性和可用性。(3) 与基于现有LLM的多代理协调框架的两个基线系统相比，支持协调策略设计的能力。
- en: 6.1 Methodology
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 方法论
- en: 6.1.1 Participants
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1 参与者
- en: We recruited 12 participants (P1-P12) with a general interest in LLM-based multi-agent
    collaboration for our experiment, 3 females and 9 males, aged 23-28 from the local
    university. To mitigate evaluation bias, all participants had not been involved
    in our formative study or the approach design process. All of the participants
    have ever used ChatGPT in the past. Seven have heard about at least one LLM-based
    multi-agent system or framework. Four have first-hand touch with at least one
    LLM-based multi-agent system or framework.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了12名参与者（P1-P12），他们对基于LLM的多代理协作有一般兴趣，来自本地大学，其中3名女性和9名男性，年龄在23至28岁之间。为了减轻评估偏差，所有参与者未曾参与我们的形成性研究或方法设计过程。所有参与者都曾使用过ChatGPT。七名参与者听说过至少一个基于LLM的多代理系统或框架，四名参与者曾亲身接触过至少一个基于LLM的多代理系统或框架。
- en: 6.1.2 Experiment Setup
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2 实验设置
- en: We set up two additional baseline systems for comparative study [[36](https://arxiv.org/html/2404.11943v1#bib.bib36),
    [9](https://arxiv.org/html/2404.11943v1#bib.bib9), [8](https://arxiv.org/html/2404.11943v1#bib.bib8)]
    alongside our system. All three systems utilize GPT4 as the default LLM model.
    The users can also use ChatGPT at their will during experiments. During the strategy
    design phase in AgentCoord, we allow users to switch to a fast mode that uses
    Mistral 8$\times$7B model with hardware acceleration⁵⁵5https://groq.com/ for the
    first time of generation to strike a balance of response quality and efficiency.
    The agents used in the experiments are generated through role prompting [[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]
    and then converted to the corresponding format required for the three systems.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为比较研究设置了两个额外的基准系统[[36](https://arxiv.org/html/2404.11943v1#bib.bib36)、[9](https://arxiv.org/html/2404.11943v1#bib.bib9)、[8](https://arxiv.org/html/2404.11943v1#bib.bib8)]，与我们的系统一起进行比较。所有三个系统都使用
    GPT4 作为默认的 LLM 模型。用户在实验过程中也可以随时使用 ChatGPT。在 AgentCoord 的策略设计阶段，我们允许用户切换到快速模式，该模式使用带有硬件加速的
    Mistral 8$\times$7B 模型⁵⁵5https://groq.com/进行第一次生成，以平衡响应质量和效率。实验中使用的代理是通过角色提示生成的[[42](https://arxiv.org/html/2404.11943v1#bib.bib42)]，然后转换为三个系统所需的相应格式。
- en: 'Baseline A (AutoAgents with simple UI): provides a set of carefully designed
    prompts to let the LLM generate a step-by-step coordination strategy for collaboration
    based on the goal provided by the user. Each step starts with a list “[name1,
    name2, ..]” to specify the agents involved and uses natural language to specify
    how agents will collaborate. A simple text editor is provided for further editing
    the strategy. Once the user is satisfied, they can click the “execute” button
    to start collaboration. The output of the execution result is shown in the text
    terminal.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 基准 A（具有简单 UI 的自动代理）：提供一组精心设计的提示，允许大语言模型（LLM）根据用户提供的目标生成逐步协调策略以进行合作。每个步骤以列表“[name1,
    name2, ..]”开头，指定参与的代理，并使用自然语言说明代理如何协作。提供一个简单的文本编辑器以进一步编辑策略。一旦用户满意，可以点击“执行”按钮开始合作。执行结果的输出显示在文本终端中。
- en: 'Baseline B (AutoGen in Group Chat Mode): allows adding multiple LLM-based agents
    in a group chat and coordinating them using natural language. During the coordination
    strategy design, a planner agent first drafts an initial coordination strategy
    based on the general goal provided by the user and the profile of available agents.
    The user plays the role of an admin agent and refines the coordination strategy
    collaboratively with the planner agent by chatting. Once the user is satisfied
    with the coordination strategy, they can start the collaboration. The output of
    the execution result is shown in the text terminal.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 基准 B（群聊模式下的 AutoGen）：允许在群聊中添加多个基于 LLM 的代理，并使用自然语言进行协调。在协调策略设计过程中，规划代理首先根据用户提供的总体目标和可用代理的资料草拟初步协调策略。用户扮演管理员代理的角色，通过与规划代理聊天，协作完善协调策略。一旦用户对协调策略满意，可以开始合作。执行结果的输出显示在文本终端中。
- en: 6.1.3 Procedure
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.3 程序
- en: 'Introduction and Training: We initially briefed the users on the objective
    and relevant context of the experiment. Following that, we gathered basic information
    from the users, along with their exposure to LLM-based multi-agent systems or
    frameworks. Afterward, we demonstrated to the participants how to design coordination
    strategies for agents using the three systems. We allowed the participants adequate
    time to experiment with and familiarize themselves with the systems. During this
    process, they were free to ask questions at any point.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍与培训：我们首先简要向用户介绍实验的目标和相关背景。接着，我们收集了用户的基本信息，以及他们对基于 LLM 的多代理系统或框架的了解。随后，我们向参与者演示了如何使用这三个系统设计代理的协调策略。我们为参与者提供了足够的时间进行实验，并熟悉系统。在此过程中，他们可以随时提问。
- en: 'Task Process: For each system, participants are required to select a general
    goal (e.g. “write an engaging tutorial about bubble sort for kids”, “make a content
    strategy for a local weekend event”) for agent collaboration and design coordination
    strategy for it with the given system. During the design process, the participants
    are required to finish four sub-tasks: 1\. Comprehend and judge the coordination
    strategy generated by the system. 2\. Explore and improve at least three different
    aspects of the generated collaborative strategy. 3\. Execute the collaborative
    strategy at least once and analyze the results. 4\. Improve at least one area
    of the original collaborative strategy based on the execution results. After the
    user meets the requirements for the sub-tasks, they can continue open-ended exploration
    with the system freely without time constraints. The order of the systems was
    counterbalanced.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 任务流程：对于每个系统，参与者需要选择一个通用目标（例如，“为孩子们编写一个关于冒泡排序的有趣教程”，“为当地周末活动制定内容策略”）进行智能体协作，并使用给定的系统设计协调策略。在设计过程中，参与者需要完成四个子任务：1.
    理解并判断系统生成的协调策略。2. 探索并改进生成的协作策略的至少三个不同方面。3. 至少执行一次协作策略并分析结果。4. 根据执行结果改进原始协作策略的至少一个领域。在用户完成子任务要求后，可以在没有时间限制的情况下自由进行开放式探索。系统的顺序是平衡的。
- en: 'Semi-structured interview: We ask participants to fill out a five-point Likert-scale
    questionnaire designed to assess our system’s effectiveness and usability ([Fig. 5](https://arxiv.org/html/2404.11943v1#S6.F5
    "In 6.2.3 Usability ‣ 6.2 Results Analysis ‣ 6 User Study ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")), and
    coordination support comparison for all systems ([Fig. 6](https://arxiv.org/html/2404.11943v1#S6.F6
    "In 6.2.3 Usability ‣ 6.2 Results Analysis ‣ 6 User Study ‣ AgentCoord: Visually
    Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration")). For
    each question, we encourage participants to explain the reasoning for their ratings
    and provide any opinion. In the end, we collect overall feedback about our system
    from users.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '半结构化访谈：我们要求参与者填写一份五点Likert量表问卷，旨在评估我们系统的有效性和可用性（[图 5](https://arxiv.org/html/2404.11943v1#S6.F5
    "在6.2.3 可用性 ‣ 6.2 结果分析 ‣ 6 用户研究 ‣ AgentCoord: 可视化探索基于LLM的多智能体协作策略")），以及所有系统的协调支持比较（[图
    6](https://arxiv.org/html/2404.11943v1#S6.F6 "在6.2.3 可用性 ‣ 6.2 结果分析 ‣ 6 用户研究 ‣
    AgentCoord: 可视化探索基于LLM的多智能体协作策略")）。对于每个问题，我们鼓励参与者解释他们评分的理由并提供任何意见。最后，我们收集用户对我们系统的总体反馈。'
- en: 6.2 Results Analysis
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 结果分析
- en: 6.2.1 Effectiveness of Structured Strategy Generation
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1 结构化策略生成的有效性
- en: Most of the participants agreed that the structure for coordination strategy
    is expressive and easy to understand (Q1). Users praised that the structure is
    “clear” (P5) and “intuitive” (P2). P5 commented, “it goes from high level to low
    level, which makes sense. The connections between each part are really clear.”
    P7 told us that “the proposed classification for interaction type is very helpful”
    and “hope the later versions of the system support customizing and managing different
    levels of classification granularity”. Most of the participants agreed that the
    structure for coordination strategy facilitates the design process (Q2). The users
    appreciated the structure “provide a clear map for what have been explored and
    what could be explored next” (P11) and “make the exploration process more systematic
    and confident” (P8). P10 told us that “the structure helps increase the predictability
    and my confidence when prompting LLM during exploration”. Most of the participants
    agree that the generated initial strategy is helpful as a starting strategy (Q3).
    The users found the baseline strategy always at least serves a “fair starting
    point” (P6) and sometimes “unexpectedly good” (P3). Some users express the demand
    to “have someplace to enter user’s preference or prior knowledge to affect the
    starting generation” (P5).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数参与者一致认为，协调策略的结构具有表现力且易于理解（Q1）。用户称赞该结构“清晰”（P5）且“直观”（P2）。P5评论道，“它从高层次到低层次，逻辑清晰。各部分之间的连接非常明确。”P7告诉我们，“提议的互动类型分类非常有帮助”，并且“希望系统的后续版本支持自定义和管理不同层级的分类粒度”。大多数参与者一致认为，协调策略的结构有助于设计过程（Q2）。用户赞赏该结构“提供了一个清晰的地图，展示了已探索的内容和接下来可能探索的内容”（P11）并且“使探索过程更加系统化且充满信心”（P8）。P10告诉我们，“该结构有助于增加预测性，并在探索过程中提升我提示LLM时的信心”。大多数参与者认为，生成的初始策略作为起始策略非常有帮助（Q3）。用户发现基准策略总是至少提供了一个“公平的起点”（P6），有时则“意外地好”（P3）。一些用户表达了需求，希望“有地方可以输入用户的偏好或先前的知识，以影响起始生成”（P5）。
- en: 6.2.2 Effectiveness of Interactive System
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2 互动系统的有效性
- en: Visual Organization for Strategy. Most of the participants agreed that the visual
    organization for coordination strategy facilitates comprehension (Q4). The Plan
    Outline View is regarded helpful for “quickly get an understanding of the overall
    strategy” (P2) and “convenient for navigation” (P9). P11 commented, “I like the
    ‘parallel line design’, the relationship between tasks is clearly illustrated”.
    Users appreciated “the adaptive informative reviling” (P6) in Agent Board View
    while wishing for allowing to “show an agent’s historical performance on need”
    (P5). The text highlighting in Task Process View is widely praised by users for
    aiding fast comprehension. However, some users still found the quantity of text
    to read for task process specification is large and wish to “have a summary for
    each action instruction” (P3). The overall layout is also praised by some users
    in terms of aesthetics and consistency.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 策略的视觉组织。大多数参与者一致认为，协调策略的视觉组织有助于理解（Q4）。计划大纲视图被认为有助于“快速了解整体策略”（P2）并且“方便导航”（P9）。P11评论道，“我喜欢‘平行线设计’，任务之间的关系非常清晰地展示出来。”用户赞赏代理板视图中的“自适应信息展示”（P6），并希望能够“根据需要展示代理的历史表现”（P5）。任务过程视图中的文本高亮被用户广泛赞誉，帮助快速理解。然而，一些用户仍然觉得任务过程规范中需要阅读的文本量较大，希望“每个操作指令都有一个总结”（P3）。整体布局也因其美学性和一致性受到一些用户的赞赏。
- en: 'Interactive Exploration for Alternative Strategy. Users generally appreciate
    the exploration interactions supported by our system. Meanwhile, users find the
    organization for exploration histories to be ‘extremely convenient’ (P7) and ‘helpful
    in focusing on exploration’ (P10). Nevertheless, we noted variations in how often
    and how favorably users engaged with the three exploration views (Q5,6,7). While
    both the Plan Outline Exploration View and the Process Exploration View are for
    sequential structure exploration and share a similar design, we find generally
    participants tend to do more exploration in the Plan Outline Exploration View.
    P5 explained: “when deciding the outline for the overall collaboration, I am not
    sure how to do and want to see more possibilities, branching with high-level natural
    language requirement is extremely useful at that phase. On the other hand, the
    task process is for a more detailed level, which I usually do not want to spend
    too much time exploring and just want to directly modify” (P5). The Agent Assignment
    Exploration View is the most popular view for exploration. Most users find using
    head-map to visualize LLM’s prior knowledge for agent assignment “is comprehensive
    and insightful” (P4) and the interactions “flexible and engaging for exploration”
    (P10).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 替代策略的互动探索。用户普遍赞赏我们系统支持的探索交互。与此同时，用户认为探索历史的组织“极为方便”（P7）且“有助于专注于探索”（P10）。然而，我们注意到用户在使用三个探索视图时的频率和评价存在差异（Q5,6,7）。尽管计划大纲探索视图和过程探索视图都用于顺序结构的探索并且设计相似，我们发现参与者通常更倾向于在计划大纲探索视图中进行更多的探索。P5
    解释道：“在决定整体协作的大纲时，我不确定该怎么做，想看到更多的可能性，高级自然语言需求的分支在这个阶段非常有用。另一方面，任务过程更注重更详细的层面，我通常不想花太多时间在探索上，只想直接修改”（P5）。代理分配探索视图是最受欢迎的探索视图。大多数用户发现使用热图可视化LLM的先验知识来进行代理分配“全面且富有洞察力”（P4），而交互方式“灵活且吸引人，适合探索”（P10）。
- en: 'Execution Result Examination. Most of the participants agreed that the Execution
    Result View facilitates the analysis of the execution result (Q8). The participants
    confirmed that when examining the result, it is easy to connect any part of the
    result with its corresponding strategy design. P7 commented: “when I want to a
    analyze certain result, I just click it, the other views automatically show relevant
    strategy information, reminding me of my previous design process, that’s cool.”
    The trace lines for important action inputs were also found helpful. P9 mentioned
    that he likes starting with the final result of a certain task and leveraging
    the trace lines to help trace back to see how this final result is formed along
    the way to identify possible points for improvement.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 执行结果检查。大多数参与者一致认为执行结果视图有助于分析执行结果（Q8）。参与者确认，在检查结果时，容易将结果的任何部分与相应的策略设计连接起来。P7
    评论道：“当我想分析某个结果时，我只需点击它，其他视图会自动显示相关的策略信息，提醒我之前的设计过程，真酷。”重要操作输入的追踪线也被认为是有帮助的。P9
    提到他喜欢从某个任务的最终结果开始，并利用追踪线帮助回溯，查看最终结果是如何在过程中形成的，从而识别可能的改进点。
- en: 6.2.3 Usability
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3 可用性
- en: Most of the participants agreed that our system was easy to learn (Q9) and easy
    to use (Q10). Participants commented that the interface of our system was “intuitive”
    (P2) and “clear” (P5). Several users reported although each feature of the system
    is each to understand, it still requires some time to fully master the system
    in order to use it fluently. All of the participants express their willingness
    to use our system again (Q11). P5 told us that he wish to “use this system to
    coordinate some agents to help maintain my blog in the future” (P5). P1 expressed
    the willingness to use our system to fast prototype some coordination strategies
    for research purposes, indicating its potential to contribute to the research
    community for LLM-based multi-agent systems.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数参与者一致认为我们的系统易于学习（Q9）和易于使用（Q10）。参与者评论称我们系统的界面“直观”（P2）且“清晰”（P5）。几位用户报告称，尽管系统的每个功能都容易理解，但仍然需要一些时间才能完全掌握系统，流畅使用。所有参与者表示愿意再次使用我们的系统（Q11）。P5
    告诉我们，他希望“将来能够使用这个系统协调一些代理来帮助维护我的博客”（P5）。P1 表示愿意使用我们的系统快速原型化一些协调策略用于研究，表明该系统在基于LLM的多智能体系统的研究领域中具有潜力。
- en: 'Figure 5: The results of the questionnaire regarding our system’s effectiveness
    and usability.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：关于我们系统的有效性和可用性问卷结果。
- en: 'Figure 6: The results of the questionnaire comparing the support for coordination
    strategy design across the three systems.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：比较三种系统在协调策略设计支持方面的问卷结果。
- en: 6.2.4 Coordination Support Comparison
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.4 协调支持比较
- en: 'To compare our system against two baselines in aiding the design process for
    coordination strategy, we requested participants to rate three systems across
    three facets (i.e. strategy comprehension, strategy exploration, and result analysis)
    of the design process and their satisfaction with the final result. Overall, our
    system outperforms the baselines for all four aspects. We summarize the user’s
    feedback as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的系统与两个基准进行比较，评估其在协助协调策略设计过程中的表现，我们要求参与者对三个系统在设计过程中的三个方面（即策略理解、策略探索和结果分析）以及他们对最终结果的满意度进行评分。总体而言，我们的系统在所有四个方面都优于基准。我们总结了用户的反馈如下：
- en: 'Strategy Comprehension: In Baseline B, the baseline coordination strategy is
    generated and refined by a planner agent without any structure constraints. Therefore,
    during the iteration for strategies, “the format of strategy could fluctuate frequently,
    which makes me inconfident” (P3). In Baseline A, the strategy is generated with
    carefully designed prompts that enforce some formats (e.g. divide into steps,
    and assign agents for each step). However, reading and comparing strategies repented
    in the pure text still makes users “feeling stressed” (P11) and “less confident
    for comprehension” (P8). In contrast, our system makes sure the coordination strategy
    has a consistent structure during the whole design process and provides visual
    organization and enhancement to facilitate comprehension.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 策略理解：在基准 B 中，基准协调策略由规划代理生成并进行改进，但没有任何结构约束。因此，在策略迭代过程中，“策略的格式可能会频繁波动，这让我感到不自信”（P3）。在基准
    A 中，策略是通过精心设计的提示生成的，这些提示强制执行某些格式（例如，分步骤，并为每个步骤分配代理）。然而，纯文本中重复阅读和比较策略仍然让用户“感到压力”（P11）并且“对理解缺乏信心”（P8）。相比之下，我们的系统确保协调策略在整个设计过程中具有一致的结构，并提供视觉化的组织和增强功能，以促进理解。
- en: 'Strategy Exploration: In baseline A, no direct support for strategy exploration
    is provided, users can only use ChatGPT to aid their exploration. However, transferring
    strategies between interfaces and making manual modifications for format and logic
    consistency can be “tedious and error-prone” (P7). Baseline B allows users to
    explore alternative strategies by chatting with the planner agent. However, there
    lack of support for users to flexibly explore different aspects of the strategy
    on need. Moreover, the quantity of texts can be quickly overwhelming for both
    the planner agent and users as the process of exploration gets complicated. Our
    system empowers users with a set of interactions to flexibly explore different
    aspects of the strategies with the help of LLM and helps visually organize the
    exploration history.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 策略探索：在基准 A 中，没有直接支持策略探索的功能，用户只能使用 ChatGPT 来辅助探索。然而，在界面之间转移策略并手动修改格式和逻辑一致性可能“繁琐且容易出错”（P7）。基准
    B 允许用户通过与规划代理聊天来探索替代策略。然而，它缺乏支持用户根据需求灵活探索策略不同方面的功能。此外，随着探索过程的复杂化，文本量可能迅速让规划代理和用户感到不堪重负。我们的系统赋能用户，通过一系列交互灵活地探索策略的不同方面，并借助大语言模型（LLM）帮助用户可视化地组织探索历史。
- en: 'Result Analysis: Our system is overall deemed more helpful for execution result
    analysis. In both baseline A and baseline B, the execution result is directly
    output to the text terminal. P9 told us that she has to “sift through the text
    myself repeatedly to trace the dependencies between execution results and previous
    operations” (P9). Instead, in our system, users can easily trace each result back
    to its important influencing precursors and corresponding coordination strategies.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 结果分析：我们的系统总体上被认为在执行结果分析方面更加有帮助。在基准 A 和基准 B 中，执行结果直接输出到文本终端。P9 告诉我们，她必须“反复筛查文本，以追溯执行结果与之前操作之间的依赖关系”（P9）。相反，在我们的系统中，用户可以轻松地追溯每个结果到其重要的影响前因和相应的协调策略。
- en: 'Result Satisfaction: Compared to Baseline A and Baseline B, users are overall
    more satisfied with the results of our system. In Baseline B, due to the ambiguity
    frequently existing in the free-form coordination strategy, the execution process
    often deviates from the user’s expectations midway and strays further and further
    away, sometimes even falling into an infinite loop. In Baseline A, thanks to the
    enforced step-by-step strategy format, there is no infinite loop issue. However,
    the result usually misses some important parts that should appear according to
    the coordination strategy (e.g. the main characters decided in character design
    stages are not shown in the final story). While such problems also exist in the
    result of our system, users usually can successfully trace the cause by analyzing
    the result with our system, and quickly adjust the corresponding part of the strategy
    to fix it.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 结果满意度：与基线A和基线B相比，用户对我们系统的结果总体上更为满意。在基线B中，由于自由形式的协调策略中经常存在模糊性，执行过程往往会偏离用户的预期，并且逐渐偏离，有时甚至会陷入无限循环。在基线A中，得益于强制性的逐步策略格式，避免了无限循环的问题。然而，结果通常会错过根据协调策略应该出现的一些重要部分（例如，在角色设计阶段决定的主要角色在最终故事中未能出现）。虽然我们的系统结果中也存在类似问题，但用户通常能够通过分析结果成功追溯问题的原因，并快速调整策略的相关部分加以修正。
- en: 7 Discussion
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论
- en: In this section, we reflect on our research, discuss lessons learned and the
    system’s generalizability, followed by limitations and future work.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了我们的研究，讨论了经验教训和系统的可推广性，并接着讨论了局限性和未来的工作。
- en: 7.1 Lessons Learned
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 经验教训
- en: Benefits of structured strategy representation for human-LLMs co-design process.
    Our evaluation results indicate that having a structured representation for coordination
    strategy is essential for the experience of the design process. The structure
    helps align human and LLMs’ intentions, enforcing both sides to think and communicate
    based on the same set of concepts and abstraction levels, which effectively reduces
    mutual misunderstandings caused by the ambiguity of natural language. Moreover,
    a fixed structure enables the specialized design of visual organization and enhancement,
    facilitating strategy comprehension for humans, allowing them to efficiently explore
    more strategy possibilities generated by LLMs. Additionally, structured representation
    fosters a structured exploration process, making users inclined towards a more
    systematic design process for coordination strategies.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 有结构的策略表示对人类与大型语言模型（LLMs）共同设计过程的好处。我们的评估结果表明，拥有结构化的协调策略表示对设计过程的体验至关重要。这种结构有助于对齐人类与LLMs的意图，迫使双方基于相同的概念和抽象层次进行思考和沟通，从而有效减少由自然语言模糊性引起的相互误解。此外，固定的结构使得可视化组织和增强的设计成为可能，促进人类对策略的理解，使他们能够高效地探索LLMs生成的更多策略可能性。另外，结构化的表示促进了结构化的探索过程，使用户倾向于采用更加系统化的协调策略设计过程。
- en: Visualizing LLMs’ prior knowledge for agent coordination. While many works directly
    leverage LLMs’ prior knowledge to generate coordination strategy, how to effectively
    extract and visualize this prior knowledge to aid strategy design has not been
    explored. We find that compared to just getting a single answer from LLMs, users
    prefer to have a more panoramic understanding of LLM’s prior knowledge when they
    want to optimize a certain part of the strategy. For example, instead of just
    letting LLM select some agents that might contribute the a certain task, visualizing
    how each agent scores for the capabilities LLMs deem important using an interactive
    heat map would be more insightful and systematic for strategy design.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化LLMs的先验知识以促进代理协调。尽管许多研究直接利用LLMs的先验知识生成协调策略，但如何有效提取并可视化这些先验知识以辅助策略设计尚未得到充分探索。我们发现，与仅仅从LLMs获取一个单一答案相比，当用户想要优化策略的某一部分时，他们更倾向于对LLMs的先验知识有一个更全局的理解。例如，与其仅仅让LLM选择可能为某一任务做出贡献的代理，利用交互式热力图可视化每个代理在LLMs认为重要的能力方面的评分，将更加有洞察力和系统化，便于策略设计。
- en: 7.2 System Generalizability
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 系统可推广性
- en: Besides coordinating agents to collaboratively solve goal-oriented tasks, our
    system has the potential to be generalized to various applications. For example,
    users can use our system to coordinate agents to simulate and analyze human activities
    (e.g. playing Werewolf games, competing in debate tournaments, conducting multi-party
    negotiations) that involve multiple people. Those simulations are not only interesting
    for entertainment but also valuable resources for studying human/AI society and
    evaluating specific capabilities of LLMs. In the future, we plan to extend the
    structure representation of AgentCoord to support more social interaction types
    for more flexible simulation purposes. We also plan to allow users to upload their
    customized interaction types.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 除了协调代理协作解决以目标为导向的任务外，我们的系统还具有扩展到各种应用的潜力。例如，用户可以使用我们的系统协调代理模拟和分析涉及多人的人类活动（如玩狼人杀游戏、参加辩论比赛、进行多方谈判等）。这些模拟不仅富有娱乐性，而且是研究人类/AI社会以及评估LLM特定能力的宝贵资源。未来，我们计划扩展AgentCoord的结构表示，以支持更多社会交互类型，以实现更灵活的模拟目的。我们还计划允许用户上传自定义的交互类型。
- en: 7.3 Limitations and Future Work
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 限制与未来工作
- en: AgentCoord currently only supports coordinating agents to collaborate in a plain
    text environment, which contains text-form key objects. An interesting future
    work is to support multi-modal key objects in the environment and allow agents
    with multi-model capabilities to collaborate. For example, a writer agent generates
    a story, and an illustrator agent creates corresponding visuals.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: AgentCoord 当前仅支持在纯文本环境中协调代理进行协作，该环境包含文本形式的关键对象。一项有趣的未来工作是支持环境中的多模态关键对象，并允许具有多模态能力的代理进行协作。例如，写作代理生成故事，插画代理创作相应的视觉效果。
- en: 'AgentCoord currently only supports static coordination strategy design. In
    some scenarios, users may want to dynamically adjust the strategy during collaboration
    execution to adapt to circumstances. For example, the user may coordinate multiple
    agents to help conduct literature research: when an agent finds a paper that interests
    the user, the user may want to adjust the plan to allocate a group of agents to
    read and discuss it, and allocate another group of agents to investigate the background
    of its authors. Future research can be conducted to help users conduct dynamic
    coordination strategy design.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: AgentCoord 当前仅支持静态协调策略设计。在某些场景中，用户可能希望在协作执行过程中动态调整策略，以适应实际情况。例如，用户可能协调多个代理来帮助进行文献研究：当某个代理找到一篇用户感兴趣的论文时，用户可能希望调整计划，将一组代理分配去阅读和讨论这篇论文，另外一组代理去调查该论文作者的背景。未来的研究可以帮助用户进行动态协调策略设计。
- en: 8 Conclusion
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: This study presents a visual exploration framework to aid in the design of coordination
    strategies for LLM-based multi-agent collaboration, addressing the challenges
    posed by natural language ambiguity and the cognitive effort required for comprehending
    the vast amount of texts during strategy design. We propose a structured representation
    for coordination strategy and a three-stage generation method to transform the
    general goal provided by the user into executable strategies. We visually organize
    the generated strategy to facilitate user comprehension and provide a set of interactions
    to support alternative strategies exploration with LLMs. We also provide visual
    enhancement to help users analyze the execution results. Finally, we conduct a
    formal user study to validate the feasibility and effectiveness of our approach.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究提出了一种可视化探索框架，旨在帮助设计基于LLM的多代理协作中的协调策略，解决了自然语言歧义和在策略设计过程中理解大量文本所需的认知努力等挑战。我们提出了一种协调策略的结构化表示，并采用三阶段生成方法，将用户提供的一般目标转化为可执行策略。我们以可视化方式组织生成的策略，便于用户理解，并提供一套交互方式，支持与LLM进行替代策略的探索。我们还提供了可视化增强功能，帮助用户分析执行结果。最后，我们进行了正式的用户研究，以验证我们方法的可行性和有效性。
- en: References
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Assem. NexusGPT Marketplace. [https://app.gpt.nexus/App/Marketplace/agents](https://app.gpt.nexus/App/Marketplace/agents),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Assem. NexusGPT Marketplace. [https://app.gpt.nexus/App/Marketplace/agents](https://app.gpt.nexus/App/Marketplace/agents),
    2023. 访问时间：2024年3月1日。'
- en: '[2] C.-M. Chan, W. Chen, Y. Su, J. Yu, W. Xue, S. Zhang, J. Fu, and Z. Liu.
    ChatEval: Towards better llm-based evaluators through multi-agent debate. In The
    Twelfth International Conference on Learning Representations, 2024\. [doi: 10 . 48550/arXiv . 2308 . 07201](https://doi.org/10.48550/arXiv.2308.07201)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] C.-M. Chan, W. Chen, Y. Su, J. Yu, W. Xue, S. Zhang, J. Fu, 和 Z. Liu. ChatEval：通过多智能体辩论改进基于LLM的评估器。在第十二届国际学习表示大会，2024年。[doi:
    10.48550/arXiv.2308.07201](https://doi.org/10.48550/arXiv.2308.07201)'
- en: '[3] G. Chen, S. Dong, Y. Shu, G. Zhang, S. Jaward, K. Börje, J. Fu, and Y. Shi.
    AutoAgents: A framework for automatic agent generation. CoRR, abs/2309.17288,
    Sept. 2023\. [doi: 10 . 48550/arXiv . 2309 . 17288](https://doi.org/10.48550/arXiv.2309.17288)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] G. Chen, S. Dong, Y. Shu, G. Zhang, S. Jaward, K. Börje, J. Fu, 和 Y. Shi.
    AutoAgents：自动智能体生成框架。CoRR，abs/2309.17288，2023年9月。[doi: 10.48550/arXiv.2309.17288](https://doi.org/10.48550/arXiv.2309.17288)'
- en: '[4] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin,
    Y. Lu, R. Xie, et al. AgentVerse: Facilitating multi-agent collaboration and exploring
    emergent behaviors in agents. CoRR, abs/2308.10848, Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 10848](https://doi.org/10.48550/arXiv.2308.10848)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin,
    Y. Lu, R. Xie 等人。AgentVerse：促进多智能体协作并探索智能体中的涌现行为。CoRR，abs/2308.10848，2023年8月。[doi:
    10.48550/arXiv.2308.10848](https://doi.org/10.48550/arXiv.2308.10848)'
- en: '[5] M. D’Arcy, T. Hope, L. Birnbaum, and D. Downey. MARG: Multi-agent review
    generation for scientific papers. CoRR, abs/2401.04259, Jan. 2024\. [doi: 10 . 48550/arXiv . 2401 . 04259](https://doi.org/10.48550/arXiv.2401.04259)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] M. D’Arcy, T. Hope, L. Birnbaum, 和 D. Downey. MARG：用于科学论文的多智能体审查生成。CoRR，abs/2401.04259，2024年1月。[doi:
    10.48550/arXiv.2401.04259](https://doi.org/10.48550/arXiv.2401.04259)'
- en: '[6] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch. Improving
    factuality and reasoning in language models through multiagent debate. CoRR, abs/2305.14325,
    May 2023\. [doi: 10 . 48550/arXiv . 2305 . 14325](https://doi.org/10.48550/arXiv.2305.14325)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, 和 I. Mordatch. 通过多智能体辩论改进语言模型的事实性与推理能力。CoRR，abs/2305.14325，2023年5月。[doi:
    10.48550/arXiv.2305.14325](https://doi.org/10.48550/arXiv.2305.14325)'
- en: '[7] D. C. Engelbart. Augmenting human intellect: A conceptual framework. Routledge,
    New York, 1^(st) ed., 2023\. [doi: 10 . 4324/9781003230762](https://doi.org/10.4324/9781003230762)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] D. C. Engelbart. 增强人类智慧：一个概念框架。Routledge出版社，纽约，第1版，2023年。[doi: 10.4324/9781003230762](https://doi.org/10.4324/9781003230762)'
- en: '[8] Y. Feng, X. Wang, B. Pan, K. K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H. Qu,
    and W. Chen. Xnli: Explaining and diagnosing nli-based visual data analysis. IEEE
    Transactions on Visualization and Computer Graphics, pp. 1–14, 2023\. [doi: 10 . 1109/TVCG . 2023 . 3240003](https://doi.org/10.1109/TVCG.2023.3240003)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Y. Feng, X. Wang, B. Pan, K. K. Wong, Y. Ren, S. Liu, Z. Yan, Y. Ma, H.
    Qu, 和 W. Chen. Xnli：基于NLI的视觉数据分析的解释与诊断。IEEE《可视化与计算机图形学学报》，第1–14页，2023年。[doi: 10.1109/TVCG.2023.3240003](https://doi.org/10.1109/TVCG.2023.3240003)'
- en: '[9] Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, and W. Chen.
    Promptmagician: Interactive prompt engineering for text-to-image creation. IEEE
    Transactions on Visualization and Computer Graphics, 30(1):295–305, 2023\. [doi:
    10 . 1109/TVCG . 2023 . 3327168](https://doi.org/10.1109/TVCG.2023.3327168)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Y. Feng, X. Wang, K. K. Wong, S. Wang, Y. Lu, M. Zhu, B. Wang, 和 W. Chen.
    Promptmagician：面向文本到图像创作的交互式提示工程。IEEE《可视化与计算机图形学学报》，30(1)：295–305，2023年。[doi:
    10.1109/TVCG.2023.3327168](https://doi.org/10.1109/TVCG.2023.3327168)'
- en: '[10] Gravitas. AutoGPT. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Gravitas. AutoGPT。[https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)，2023年。访问时间：2024年3月1日。'
- en: '[11] S. Hong, Y. Lin, B. Liu, B. Wu, D. Li, J. Chen, J. Zhang, J. Wang, L. Zhang,
    M. Zhuge, et al. Data Interpreter: An llm agent for data science. CoRR, abs/2402.18679,
    Feb. 2024\. [doi: 10 . 48550/arXiv . 2402 . 18679](https://doi.org/10.48550/arXiv.2402.18679)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] S. Hong, Y. Lin, B. Liu, B. Wu, D. Li, J. Chen, J. Zhang, J. Wang, L.
    Zhang, M. Zhuge 等人。数据解释器：一个面向数据科学的LLM智能体。CoRR，abs/2402.18679，2024年2月。[doi: 10.48550/arXiv.2402.18679](https://doi.org/10.48550/arXiv.2402.18679)'
- en: '[12] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S.
    Yau, Z. Lin, L. Zhou, et al. MetaGpt: Meta programming for multi-agent collaborative
    framework. In The Twelfth International Conference on Learning Representations,
    2024\. [doi: 10 . 48550/arXiv . 2308 . 00352](https://doi.org/10.48550/arXiv.2308.00352)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K.
    S. Yau, Z. Lin, L. Zhou 等人。MetaGpt：多智能体协作框架的元编程。在第十二届国际学习表示大会，2024年。[doi: 10.48550/arXiv.2308.00352](https://doi.org/10.48550/arXiv.2308.00352)'
- en: '[13] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler,
    M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, and D. Kiela. Retrieval-augmented
    generation for knowledge-intensive nlp tasks. In Advances in Neural Information
    Processing Systems, pp. 9459–9474, 2020\. [doi: 10 . 48550/arXiv . 2005 . 11401](https://doi.org/10.48550/arXiv.2005.11401)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H.
    Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, 和 D. Kiela. 基于检索增强生成的知识密集型
    NLP 任务。载于《神经信息处理系统进展》，第9459–9474页，2020年。[doi: 10.48550/arXiv.2005.11401](https://doi.org/10.48550/arXiv.2005.11401)'
- en: '[14] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem. CAMEL:
    Communicative agents for “mind” exploration of large language model society. In
    Thirty-seventh Conference on Neural Information Processing Systems, 2023\. [doi:
    10 . 48550/arXiv . 2303 . 17760](https://doi.org/10.48550/arXiv.2303.17760)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] G. Li, H. A. A. K. Hammoud, H. Itani, D. Khizbullin, 和 B. Ghanem. CAMEL：用于“大脑”探索的大语言模型社会中的交互式代理。载于《第三十七届神经信息处理系统大会》，2023年。[doi:
    10.48550/arXiv.2303.17760](https://doi.org/10.48550/arXiv.2303.17760)'
- en: '[15] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, and
    S. Shi. Encouraging divergent thinking in large language models through multi-agent
    debate. CoRR, abs/2305.19118, May 2023\. [doi: 10 . 48550/arXiv . 2305 . 19118](https://doi.org/10.48550/arXiv.2305.19118)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] T. Liang, Z. He, W. Jiao, X. Wang, Y. Wang, R. Wang, Y. Yang, Z. Tu, 和
    S. Shi. 通过多代理辩论鼓励大语言模型的发散思维。CoRR, abs/2305.19118, 2023年5月。[doi: 10.48550/arXiv.2305.19118](https://doi.org/10.48550/arXiv.2305.19118)'
- en: '[16] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, and Q. Chen. AgentSims: An
    open-source sandbox for large language model evaluation. CoRR, abs/2308.04026,
    Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 04026](https://doi.org/10.48550/arXiv.2308.04026)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Lin, H. Zhao, A. Zhang, Y. Wu, H. Ping, 和 Q. Chen. AgentSims：一个开源沙盒，用于大语言模型评估。CoRR,
    abs/2308.04026, 2023年8月。[doi: 10.48550/arXiv.2308.04026](https://doi.org/10.48550/arXiv.2308.04026)'
- en: '[17] Y. Liu, Z. Wen, L. Weng, O. Woodman, Y. Yang, and W. Chen. SPROUT: Authoring
    programming tutorials with interactive visualization of large language model generation
    process. CoRR, abs/2312.01801, Dec. 2023\. [doi: 10 . 48550/arXiv . 2312 . 01801](https://doi.org/10.48550/arXiv.2312.01801)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Y. Liu, Z. Wen, L. Weng, O. Woodman, Y. Yang, 和 W. Chen. SPROUT：通过大语言模型生成过程的交互式可视化编写编程教程。CoRR,
    abs/2312.01801, 2023年12月。[doi: 10.48550/arXiv.2312.01801](https://doi.org/10.48550/arXiv.2312.01801)'
- en: '[18] Z. Liu, Y. Zhang, P. Li, Y. Liu, and D. Yang. Dynamic llm-agent network:
    An llm-agent collaboration framework with agent team optimization. CoRR, abs/2310.02170,
    Oct. 2023\. [doi: 10 . 48550/arXiv . 2310 . 02170](https://doi.org/10.48550/arXiv.2310.02170)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Z. Liu, Y. Zhang, P. Li, Y. Liu, 和 D. Yang. 动态 LLM-代理网络：一种基于 LLM 的代理团队优化协作框架。CoRR,
    abs/2310.02170, 2023年10月。[doi: 10.48550/arXiv.2310.02170](https://doi.org/10.48550/arXiv.2310.02170)'
- en: '[19] J. Lu, B. Pan, J. Chen, Y. Feng, J. Hu, Y. Peng, and W. Chen. AgentLens:
    Visual analysis for agent behaviors in llm-based autonomous systems. CoRR, abs/2402.08995,
    Feb. 2024\. [doi: 10 . 48550/arXiv . 2402 . 08995](https://doi.org/10.48550/arXiv.2402.08995)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] J. Lu, B. Pan, J. Chen, Y. Feng, J. Hu, Y. Peng, 和 W. Chen. AgentLens：基于
    LLM 的自主系统中代理行为的视觉分析。CoRR, abs/2402.08995, 2024年2月。[doi: 10.48550/arXiv.2402.08995](https://doi.org/10.48550/arXiv.2402.08995)'
- en: '[20] A. I. Luppi, P. A. Mediano, F. E. Rosas, N. Holland, T. D. Fryer, J. T.
    O’Brien, J. B. Rowe, D. K. Menon, D. Bor, and E. A. Stamatakis. A synergistic
    core for human brain evolution and cognition. Nature Neuroscience, 25(6):771–782,
    May 2022\. [doi: 10 . 1038/s41593-022-01070-0](https://doi.org/10.1038/s41593-022-01070-0)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] A. I. Luppi, P. A. Mediano, F. E. Rosas, N. Holland, T. D. Fryer, J. T.
    O’Brien, J. B. Rowe, D. K. Menon, D. Bor, 和 E. A. Stamatakis. 人类大脑进化和认知的协同核心。*《自然神经科学》*，第25卷，第6期：771–782，2022年5月。[doi:
    10.1038/s41593-022-01070-0](https://doi.org/10.1038/s41593-022-01070-0)'
- en: '[21] J. MouraAbout. CrewAI. [https://github.com/joaomdmoura/crewAI](https://github.com/joaomdmoura/crewAI),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. MouraAbout. CrewAI. [https://github.com/joaomdmoura/crewAI](https://github.com/joaomdmoura/crewAI),
    2023年。访问日期：2024年3月1日。'
- en: '[22] OpenAI. OpenAI GPT Store. [https://openai.com/blog/introducing-the-gpt-store](https://openai.com/blog/introducing-the-gpt-store),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] OpenAI. OpenAI GPT Store. [https://openai.com/blog/introducing-the-gpt-store](https://openai.com/blog/introducing-the-gpt-store),
    2023年。访问日期：2024年3月1日。'
- en: '[23] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens,
    A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe. Training language
    models to follow instructions with human feedback. In Advances in Neural Information
    Processing Systems, pp. 27730–27744, 2022\. [doi: 10 . 48550/arXiv . 2203 . 02155](https://doi.org/10.48550/arXiv.2203.02155)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C.
    Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller,
    M. Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, 和 R. Lowe. 训练语言模型以通过人类反馈遵循指令。在神经信息处理系统进展（Advances
    in Neural Information Processing Systems），第27730-27744页，2022年。[doi: 10.48550/arXiv.2203.02155](https://doi.org/10.48550/arXiv.2203.02155)'
- en: '[24] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein.
    Generative agents: Interactive simulacra of human behavior. In Proceedings of
    the 36th Annual ACM Symposium on User Interface Software and Technology, pp. 1–22,
    2023\. [doi: 10 . 1145/3586183 . 3606763](https://doi.org/10.1145/3586183.3606763)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] J. S. Park, J. O’Brien, C. J. Cai, M. R. Morris, P. Liang, 和 M. S. Bernstein.
    生成代理：人类行为的交互式模拟。在第36届年度ACM用户界面软件与技术研讨会（Symposium on User Interface Software and
    Technology）论文集，第1-22页，2023年。[doi: 10.1145/3586183.3606763](https://doi.org/10.1145/3586183.3606763)'
- en: '[25] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, and M. Sun.
    Communicative agents for software development. CoRR, abs/2307.07924, July 2023\.
    [doi: 10 . 48550/arXiv . 2307 . 07924](https://doi.org/10.48550/arXiv.2307.07924)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] C. Qian, X. Cong, C. Yang, W. Chen, Y. Su, J. Xu, Z. Liu, 和 M. Sun. 用于软件开发的通信代理。CoRR，abs/2307.07924，2023年7月。[doi:
    10.48550/arXiv.2307.07924](https://doi.org/10.48550/arXiv.2307.07924)'
- en: '[26] ReWorkd. AgentGPT. [https://github.com/reworkd/AgentGPT](https://github.com/reworkd/AgentGPT),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] ReWorkd. AgentGPT。 [https://github.com/reworkd/AgentGPT](https://github.com/reworkd/AgentGPT)，2023年。访问日期：2024年3月1日。'
- en: '[27] L. Salewski, S. Alaniz, I. Rio-Torto, E. Schulz, and Z. Akata. In-context
    impersonation reveals large language models’ strengths and biases. In Thirty-seventh
    Conference on Neural Information Processing Systems, 2023\. [doi: 10 . 48550/arXiv . 2305 . 14930](https://doi.org/10.48550/arXiv.2305.14930)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] L. Salewski, S. Alaniz, I. Rio-Torto, E. Schulz, 和 Z. Akata. 上下文模仿揭示大型语言模型的优势与偏见。在第三十七届神经信息处理系统会议（Neural
    Information Processing Systems），2023年。[doi: 10.48550/arXiv.2305.14930](https://doi.org/10.48550/arXiv.2305.14930)'
- en: '[28] X. Tang, A. Zou, Z. Zhang, Y. Zhao, X. Zhang, A. Cohan, and M. Gerstein.
    MedAgents: Large language models as collaborators for zero-shot medical reasoning.
    CoRR, abs/2311.10537, Nov. 2023\. [doi: 10 . 48550/arXiv . 2311 . 10537](https://doi.org/10.48550/arXiv.2311.10537)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] X. Tang, A. Zou, Z. Zhang, Y. Zhao, X. Zhang, A. Cohan, 和 M. Gerstein.
    MedAgents：大型语言模型作为零样本医学推理的协作者。CoRR，abs/2311.10537，2023年11月。[doi: 10.48550/arXiv.2311.10537](https://doi.org/10.48550/arXiv.2311.10537)'
- en: '[29] L. Team. Langroid: Harness llms with multi-agent programming. [https://github.com/langroid/langroid](https://github.com/langroid/langroid),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] L. Team. Langroid: 利用多代理编程发挥大型语言模型的优势。 [https://github.com/langroid/langroid](https://github.com/langroid/langroid)，2023年。访问日期：2024年3月1日。'
- en: '[30] S. Team. SuperAGI. [https://github.com/TransformerOptimus/SuperAGI](https://github.com/TransformerOptimus/SuperAGI),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] S. Team. SuperAGI。 [https://github.com/TransformerOptimus/SuperAGI](https://github.com/TransformerOptimus/SuperAGI)，2023年。访问日期：2024年3月1日。'
- en: '[31] S. Team. SuperAGI Marketplace. [https://marketplace.superagi.com/](https://marketplace.superagi.com/),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] S. Team. SuperAGI Marketplace。 [https://marketplace.superagi.com/](https://marketplace.superagi.com/)，2023年。访问日期：2024年3月1日。'
- en: '[32] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,
    X. Chen, Y. Lin, et al. A survey on large language model based autonomous agents.
    CoRR, abs/2308.11432, Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 11432](https://doi.org/10.48550/arXiv.2308.11432)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang,
    X. Chen, Y. Lin 等。基于大型语言模型的自主代理调查。CoRR，abs/2308.11432，2023年8月。[doi: 10.48550/arXiv.2308.11432](https://doi.org/10.48550/arXiv.2308.11432)'
- en: '[33] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, and H. Ji. Unleashing the emergent
    cognitive synergy in large language models: A task-solving agent through multi-persona
    self-collaboration. CoRR, abs/2307.05300, July 2023\. [doi: 10 . 48550/arXiv . 2307 . 05300](https://doi.org/10.48550/arXiv.2307.05300)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, 和 H. Ji. 释放大型语言模型中的涌现认知协同：通过多重人格自我协作解决任务的代理。CoRR，abs/2307.05300，2023年7月。[doi:
    10.48550/arXiv.2307.05300](https://doi.org/10.48550/arXiv.2307.05300)'
- en: '[34] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M.
    Dai, and Q. V. Le. Finetuned language models are zero-shot learners. In The Tenth
    International Conference on Learning Representations, 2022\. [doi: 10 . 48550/arXiv . 2109 . 01652](https://doi.org/10.48550/arXiv.2109.01652)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M.
    Dai, 和 Q. V. Le. 微调语言模型是零-shot学习者. 在第十届国际学习表征大会（The Tenth International Conference
    on Learning Representations），2022年。[doi: 10 . 48550/arXiv . 2109 . 01652](https://doi.org/10.48550/arXiv.2109.01652)'
- en: '[35] L. Weng, X. Wang, J. Lu, Y. Feng, Y. Liu, and W. Chen. Insightlens: Discovering
    and exploring insights from conversational contexts in large-language-model-powered
    data analysis. arXiv, 2024\. [doi: 10 . 48550/ARXIV . 2404 . 01644](https://doi.org/10.48550/ARXIV.2404.01644)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] L. Weng, X. Wang, J. Lu, Y. Feng, Y. Liu, 和 W. Chen. Insightlens: 在大型语言模型驱动的数据分析中发现和探索对话背景中的洞察.
    arXiv, 2024年。[doi: 10 . 48550/ARXIV . 2404 . 01644](https://doi.org/10.48550/ARXIV.2404.01644)'
- en: '[36] K. K. Wong, X. Wang, Y. Wang, J. He, R. Zhang, and H. Qu. Anchorage: Visual
    analysis of satisfaction in customer service videos via anchor events. IEEE Transactions
    on Visualization and Computer Graphics, 2023\. [doi: 10 . 48550/ARXIV . 2302 . 06806](https://doi.org/10.48550/ARXIV.2302.06806)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] K. K. Wong, X. Wang, Y. Wang, J. He, R. Zhang, 和 H. Qu. Anchorage: 通过锚事件可视化分析客户服务视频中的满意度.
    IEEE Transactions on Visualization and Computer Graphics, 2023年。[doi: 10 . 48550/ARXIV . 2302 . 06806](https://doi.org/10.48550/ARXIV.2302.06806)'
- en: '[37] A. W. Woolley, C. F. Chabris, A. Pentland, N. Hashmi, and T. W. Malone.
    Evidence for a collective intelligence factor in the performance of human groups.
    science, 330(6004):686–688, Sept. 2010\. [doi: 10 . 1126/science . 1193147](https://doi.org/10.1126/science.1193147)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] A. W. Woolley, C. F. Chabris, A. Pentland, N. Hashmi, 和 T. W. Malone.
    证明了人类群体在表现中的集体智慧因素. Science, 330(6004):686–688, 2010年9月。[doi: 10 . 1126/science . 1193147](https://doi.org/10.1126/science.1193147)'
- en: '[38] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, and C. Wang. AutoGen: Enabling next-gen llm applications via multi-agent
    conversation framework. CoRR, abs/2308.08155, Aug. 2023\. [doi: 10 . 48550/arXiv . 2308 . 08155](https://doi.org/10.48550/arXiv.2308.08155)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Q. Wu, G. Bansal, J. Zhang, Y. Wu, S. Zhang, E. Zhu, B. Li, L. Jiang,
    X. Zhang, 和 C. Wang. AutoGen: 通过多代理对话框架实现下一代LLM应用. CoRR, abs/2308.08155, 2023年8月。[doi:
    10 . 48550/arXiv . 2308 . 08155](https://doi.org/10.48550/arXiv.2308.08155)'
- en: '[39] Y. Wu, F. Jia, S. Zhang, Q. Wu, H. Li, E. Zhu, Y. Wang, Y. T. Lee, R. Peng,
    and C. Wang. An empirical study on challenging math problem solving with gpt-4.
    CoRR, abs/2306.01337, June 2023\. [doi: 10 . 48550/arXiv . 2306 . 01337](https://doi.org/10.48550/arXiv.2306.01337)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Y. Wu, F. Jia, S. Zhang, Q. Wu, H. Li, E. Zhu, Y. Wang, Y. T. Lee, R.
    Peng, 和 C. Wang. 关于利用GPT-4求解挑战性数学问题的实证研究. CoRR, abs/2306.01337, 2023年6月。[doi:
    10 . 48550/arXiv . 2306 . 01337](https://doi.org/10.48550/arXiv.2306.01337)'
- en: '[40] XAgent Team. XAgent: An autonomous agent for complex task solving. [https://github.com/OpenBMB/XAgent](https://github.com/OpenBMB/XAgent),
    2023. Accessed on: Mar 01, 2024.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] XAgent Team. XAgent: 一个用于复杂任务求解的自主代理。[https://github.com/OpenBMB/XAgent](https://github.com/OpenBMB/XAgent)，2023年。访问时间：2024年3月1日。'
- en: '[41] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin,
    E. Zhou, et al. The rise and potential of large language model based agents: A
    survey. CoRR, abs/2309.07864, Sept. 2023\. [doi: 10 . 48550/arXiv . 2309 . 07864](https://doi.org/10.48550/arXiv.2309.07864)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S.
    Jin, E. Zhou 等. 基于大型语言模型的代理的崛起与潜力：一项调查. CoRR, abs/2309.07864, 2023年9月。[doi: 10 . 48550/arXiv . 2309 . 07864](https://doi.org/10.48550/arXiv.2309.07864)'
- en: '[42] B. Xu, A. Yang, J. Lin, Q. Wang, C. Zhou, Y. Zhang, and Z. Mao. ExpertPrompting:
    Instructing large language models to be distinguished experts. CoRR, abs/2305.14688,
    May 2023\. [doi: 10 . 48550/arXiv . 2305 . 14688](https://doi.org/10.48550/arXiv.2305.14688)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] B. Xu, A. Yang, J. Lin, Q. Wang, C. Zhou, Y. Zhang, 和 Z. Mao. ExpertPrompting:
    指导大型语言模型成为卓越专家. CoRR, abs/2305.14688, 2023年5月。[doi: 10 . 48550/arXiv . 2305 . 14688](https://doi.org/10.48550/arXiv.2305.14688)'
- en: '[43] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu, and
    C. Gan. Building cooperative embodied agents modularly with large language models.
    In The Twelfth International Conference on Learning Representations, 2024\. [doi:
    10 . 48550/arXiv . 2307 . 02485](https://doi.org/10.48550/arXiv.2307.02485)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu, 和 C.
    Gan. 使用大型语言模型模块化构建合作型具身代理. 在第十二届国际学习表征大会（The Twelfth International Conference
    on Learning Representations），2024年。[doi: 10 . 48550/arXiv . 2307 . 02485](https://doi.org/10.48550/arXiv.2307.02485)'
- en: '[44] Y. Zheng, C. Ma, K. Shi, and H. Huang. Agents meet OKR: an object and
    key results driven agent system with hierarchical self-collaboration and self-evaluation.
    CoRR, abs/2311.16542, Nov. 2023\. [doi: 10 . 48550/arXiv . 2311 . 16542](https://doi.org/10.48550/arXiv.2311.16542)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Y. Zheng, C. Ma, K. Shi 和 H. Huang. 代理与OKR相遇：一个基于目标与关键结果驱动的代理系统，具备分层自我协作和自我评估功能。CoRR,
    abs/2311.16542, 2023年11月。[doi: 10 . 48550/arXiv . 2311 . 16542](https://doi.org/10.48550/arXiv.2311.16542)'
- en: '[45] M. Zhuge, H. Liu, F. Faccio, D. R. Ashley, R. Csordás, A. Gopalakrishnan,
    A. Hamdi, H. A. A. K. Hammoud, V. Herrmann, K. Irie, et al. Mindstorms in natural
    language-based societies of mind. CoRR, abs/2305.17066, May 2023\. [doi: 10 . 48550/arXiv . 2305 . 17066](https://doi.org/10.48550/arXiv.2305.17066)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] M. Zhuge, H. Liu, F. Faccio, D. R. Ashley, R. Csordás, A. Gopalakrishnan,
    A. Hamdi, H. A. A. K. Hammoud, V. Herrmann, K. Irie 等人. 基于自然语言的心智社会中的思维风暴。CoRR,
    abs/2305.17066, 2023年5月。[doi: 10 . 48550/arXiv . 2305 . 17066](https://doi.org/10.48550/arXiv.2305.17066)'
