- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 11:47:51'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:47:51
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Cultural Evolution of Cooperation among LLM Agents
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 代理的合作文化演化
- en: 来源：[https://arxiv.org/html/2412.10270/](https://arxiv.org/html/2412.10270/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2412.10270/](https://arxiv.org/html/2412.10270/)
- en: \pdfcolInitStack
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \pdfcolInitStack
- en: tcb@breakable \correspondingauthorvallinder@gmail.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: tcb@breakable \correspondingauthorvallinder@gmail.com
- en: Aron Vallinder Independent Edward Hughes Google DeepMind
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Aron Vallinder 独立研究员 Edward Hughes Google DeepMind
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large language models (LLMs) provide a compelling foundation for building generally-capable
    AI agents. These agents may soon be deployed at scale in the real world, representing
    the interests of individual humans (e.g., AI assistants) or groups of humans (e.g.,
    AI-accelerated corporations). At present, relatively little is known about the
    dynamics of multiple LLM agents interacting over many generations of iterative
    deployment. In this paper, we examine whether a “society” of LLM agents can learn
    mutually beneficial social norms in the face of incentives to defect, a distinctive
    feature of human sociality that is arguably crucial to the success of civilization.
    In particular, we study the evolution of indirect reciprocity across generations
    of LLM agents playing a classic iterated Donor Game in which agents can observe
    the recent behavior of their peers. We find that the evolution of cooperation
    differs markedly across base models, with societies of Claude 3.5 Sonnet agents
    achieving significantly higher average scores than Gemini 1.5 Flash, which, in
    turn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an additional
    mechanism for costly punishment to achieve yet higher scores, while Gemini 1.5
    Flash and GPT-4o fail to do so. For each model class, we also observe variation
    in emergent behavior across random seeds, suggesting an understudied sensitive
    dependence on initial conditions. We suggest that our evaluation regime could
    inspire an inexpensive and informative new class of LLM benchmarks, focussed on
    the implications of LLM agent deployment for the cooperative infrastructure of
    society.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）为构建通用能力的 AI 代理提供了有力的基础。这些代理可能很快在现实世界中大规模部署，代表个体人类（例如，AI 助手）或群体人类（例如，AI
    加速的公司）的利益。目前，对于多个 LLM 代理在多代迭代部署中相互作用的动态知之甚少。本文探讨了在面临背叛激励时，LLM 代理的“社会”是否能够学习到互利的社会规范，这是人类社会性的一大特点，且可以说对文明的成功至关重要。具体而言，我们研究了
    LLM 代理在经典的重复捐赠者博弈中，如何在多代之间演化间接互惠行为，在该博弈中，代理可以观察到同行的近期行为。我们发现，不同基础模型之间的合作演化差异显著，其中
    Claude 3.5 Sonnet 代理的社会在平均分数上显著高于 Gemini 1.5 Flash，后者又优于 GPT-4o。此外，Claude 3.5
    Sonnet 通过使用一种额外的高成本惩罚机制，获得了更高的分数，而 Gemini 1.5 Flash 和 GPT-4o 则未能做到这一点。对于每个模型类别，我们还观察到不同随机种子下的行为差异，表明模型的行为对初始条件的敏感性尚未得到充分研究。我们建议，本文的评估体系可能会启发一种廉价且信息丰富的新型
    LLM 基准，重点关注 LLM 代理部署对社会合作基础设施的影响。
- en: 'keywords:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Cultural Evolution, Cooperation, Indirect Reciprocity, Large Language Models
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 文化演化、合作、间接互惠、大型语言模型
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: LLMs are increasingly able to match or exceed human performance across a wide
    range of language tasks. Models with improved reasoning and tool-use capabilities
    (OpenAI, [2024](https://arxiv.org/html/2412.10270v1#bib.bib30)) may naturally
    form a basis for general-purpose agent-based applications. In the near future,
    we expect there to be many LLM agents interacting autonomously to accomplish tasks
    on behalf of various individuals and organizations. These interactions could take
    many forms, including competition, cooperation, negotiation, coordination, and
    information sharing. Certainly these interactions will introduce new social dynamics,
    yielding emergent outcomes for society that are hard to predict from purely theoretical
    considerations (Gabriel et al., [2024](https://arxiv.org/html/2412.10270v1#bib.bib16)).
    However, current LLM safety evaluations are rooted mainly in single-turn interactions
    between one model and one human. For instance, none of LMSys Chatbot Arena (Chiang
    et al., [2024](https://arxiv.org/html/2412.10270v1#bib.bib10)), METR (METR, [2024](https://arxiv.org/html/2412.10270v1#bib.bib24)),
    or AISI (AISI, [2024](https://arxiv.org/html/2412.10270v1#bib.bib3)) consider
    multi-agent interactions over time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs越来越能够在广泛的语言任务中匹敌或超越人类表现。具备更强推理和工具使用能力的模型（OpenAI，[2024](https://arxiv.org/html/2412.10270v1#bib.bib30)）可能自然成为通用代理应用程序的基础。在不久的将来，我们预计将会有许多LLM智能体相互独立地交互，以代表各种个人和组织完成任务。这些交互形式可能多种多样，包括竞争、合作、谈判、协调和信息共享。当然，这些互动将引入新的社会动态，产生一些很难通过纯粹理论推导出来的社会结果（Gabriel等人，[2024](https://arxiv.org/html/2412.10270v1#bib.bib16)）。然而，目前的LLM安全评估主要基于单轮互动，即一个模型与一个人之间的互动。例如，LMSys
    Chatbot Arena（Chiang等人，[2024](https://arxiv.org/html/2412.10270v1#bib.bib10)），METR（METR，[2024](https://arxiv.org/html/2412.10270v1#bib.bib24)）或AISI（AISI，[2024](https://arxiv.org/html/2412.10270v1#bib.bib3)）等都没有考虑多智能体之间随时间演变的互动。
- en: 'A particularly important class of multi-agent interactions are cooperative
    interactions. We say that agents cooperate when they take actions that lead to
    mutual benefit, even in the face of opportunities for individual gain at the expense
    of others (Dafoe et al., [2020](https://arxiv.org/html/2412.10270v1#bib.bib11)).
    Arguably the human species’ ability to cooperate reliably at scale with strangers
    is the secret of our success (Henrich, [2016](https://arxiv.org/html/2412.10270v1#bib.bib19)),
    and underpins the stability of human societies. Just as with humans, cooperation
    between LLM agents will often be in the interests of society.¹¹1But not always:
    we would not want LLM agents to collude against humans, for instance. We discuss
    this challenge in Section [5](https://arxiv.org/html/2412.10270v1#S5 "5 Discussion
    ‣ Cultural Evolution of Cooperation among LLM Agents"). Consider, for example,
    LLM agents that make high-level decisions about travel speed and route selection
    for autonomous vehicles. Cooperation between such agents can reduce congestion
    and pollution which increasing safety and efficiency for a wide range of road
    users. Myriad other use cases, from matching algorithms to public goods contributions,
    stand to benefit from stable, effective cooperation between AI agents. Moreover,
    failures of AI cooperation can potentially erode human social norms. For example,
    an LLM agent tasked with making a restaurant booking might decide to make a large
    number of reservations only to cancel most of them last minute, to the detriment
    of the restaurants and other customers alike.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一类特别重要的多智能体互动是合作互动。当智能体采取能够带来互惠利益的行动，即使在面临以牺牲他人为代价实现个人利益的机会时，我们也称之为合作（Dafoe等人，[2020](https://arxiv.org/html/2412.10270v1#bib.bib11)）。可以说，人类物种能够在规模上与陌生人可靠地合作，是我们成功的秘诀（Henrich，[2016](https://arxiv.org/html/2412.10270v1#bib.bib19)），并且支撑着人类社会的稳定。正如人类一样，LLM智能体之间的合作通常有利于社会利益。¹¹1但并非总是如此：例如，我们不希望LLM智能体联合起来反对人类。我们将在[5](https://arxiv.org/html/2412.10270v1#S5
    "5 Discussion ‣ Cultural Evolution of Cooperation among LLM Agents")节中讨论这一挑战。举个例子，考虑那些为自动驾驶汽车做出关于行驶速度和路线选择的高层决策的LLM智能体。这些智能体之间的合作可以减少交通拥堵和污染，从而提高各类道路使用者的安全性和效率。许多其他应用场景，从匹配算法到公共物品贡献，都能从AI智能体之间稳定有效的合作中受益。此外，AI合作的失败可能会侵蚀人类的社会规范。例如，一个被任务委派为餐厅预定的LLM智能体，可能决定进行大量预定，但在最后一刻取消其中大部分，给餐馆和其他顾客带来损害。
- en: In this paper, we seek to probe the emergent cooperative behaviour of a “society”
    of LLM agents. Our aim is to draw reliable and easily interpretable conclusions
    from inexpensive experiments, towards creating a benchmark for LLM multi-agent
    interaction. Therefore we restrict our attention to a classic iterated economic
    game called the Donor Game in which agents can differentially cooperate by donating
    more resources to each other, or defect by retaining more resources for themselves.
    We make precise what we mean by “emergent” behaviour by constructing a specific
    cultural evolutionary setup, realising the framework in (Brinkmann et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib7)).
    Each generation of agents plays several rounds of the Donor Game in random pairings.
    At the end of a generation, the agents with the highest resources proceed to the
    next generation, while the rest are discarded. At the start of the next generation
    new agents are introduced, whose strategies condition on the strategies of the
    surviving agents. We think of this cultural evolutionary setup as an idealised
    model for the iterative deployment of new LLM agents, such as when OpenAI, Google
    or Anthropic release new versions of GPT, Gemini or Claude respectively. Figure
    [1](https://arxiv.org/html/2412.10270v1#S2.F1 "Figure 1 ‣ 2.1 The Donor Game ‣
    2 Background ‣ Cultural Evolution of Cooperation among LLM Agents") summarises
    our method.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在探讨LLM代理“社会”中涌现的合作行为。我们的目标是通过廉价实验得出可靠且易于解释的结论，进而为LLM多代理交互创建一个基准。因此，我们将注意力集中在一个经典的迭代经济博弈——捐赠者博弈上，在该博弈中，代理可以通过向彼此捐赠更多资源来进行合作，或通过保留更多资源来进行背叛。我们通过构建一个特定的文化演化设置，来精确定义“涌现”行为的含义，并实现了(Brinkmann
    等，[2023](https://arxiv.org/html/2412.10270v1#bib.bib7))中的框架。每一代代理会在随机配对下进行几轮捐赠者博弈。在一代结束时，资源最多的代理进入下一代，其余代理被淘汰。在下一代开始时，会引入新的代理，这些代理的策略依赖于幸存代理的策略。我们将这种文化演化设置视为新LLM代理迭代部署的理想化模型，例如OpenAI、Google或Anthropic发布新版GPT、Gemini或Claude时的情况。图[1](https://arxiv.org/html/2412.10270v1#S2.F1
    "Figure 1 ‣ 2.1 The Donor Game ‣ 2 Background ‣ Cultural Evolution of Cooperation
    among LLM Agents")总结了我们的方法。
- en: Our setup reveals surprising and unexpected differences in performance among
    societies of LLM agents constructed from different base models. While Claude 3.5
    agents are able to bootstrap cooperation, especially when provided with a mechanism
    for costly punishment, Gemini 1.5 Flash and GPT-4o fail to do so. Comparing the
    culturally evolved strategies, it becomes clear that a population of Claude 3.5
    agents accumulate increasingly intricate ways to punish free-riders while incentivizing
    cooperation, including by making use of “second-order” information about how recipients
    of recipients have treated others. Meanwhile, Gemini 1.5 Flash shows little sign
    of accumulating new cooperative infrastructure across generations, while GPT-4o
    populations become increasingly untrusting and risk-averse. The striking differences
    between models and across different runs of the same model show that our approach
    can yield novel and hitherto unstudied insights into multi-agent behavior among
    LLMs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的设置揭示了基于不同基础模型构建的LLM代理群体之间，在表现上的惊人差异。尽管Claude 3.5代理能够促进合作，尤其是当提供了一种代价惩罚机制时，但Gemini
    1.5 Flash和GPT-4o则未能做到这一点。通过比较文化演化后的策略，我们清楚地看到，Claude 3.5代理群体积累了越来越复杂的方式来惩罚搭便车者，同时激励合作，包括利用关于接收者如何对待其他人的“二阶”信息。而Gemini
    1.5 Flash在几代之间几乎没有积累出新的合作基础设施，而GPT-4o群体则变得越来越不信任且风险厌恶。不同模型之间，以及同一模型不同运行之间的显著差异表明，我们的方法能够提供关于LLM多代理行为的新颖且前所未有的见解。
- en: 'The main contributions of this paper are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的主要贡献如下：
- en: '1.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: We introduce a methodology to assess the cultural evolution of cooperation among
    LLM agents in the Donor Game.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们引入了一种方法来评估LLM代理在捐赠者博弈中的合作文化演化。
- en: '2.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: We show that the emergence of cooperative norms depends both on the base model
    and on the initial stategies sampled.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了合作规范的出现既依赖于基础模型，也依赖于最初采样的策略。
- en: '3.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: We analyse the cultural evolution of agent strategies at the individual level
    and as a population-level phylogenetic tree.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在个体层面和群体层面的系统发育树上分析了代理策略的文化演化。
- en: '4.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: We open-source code in the Supplementary Material, towards creating a benchmark
    for LLM agent interaction.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在附录材料中开源了代码，旨在为LLM代理交互创建基准。
- en: 2 Background
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: 2.1 The Donor Game
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 捐赠者博弈
- en: Indirect reciprocity is a mechanism for cooperation in which an individual helps
    someone because doing so increases the likelihood that someone else will help
    them in the future.²²2More specifically, this is downstream indirect reciprocity.
    By contrast, in upstream indirect reciprocity, an individual who has received
    a benefit in the past is more likely to provide a benefit to someone else in the
    future—“paying it forward” (Boyd and Richerson, [1989](https://arxiv.org/html/2412.10270v1#bib.bib6)).
    Unlike direct reciprocity, which relies on repeated interactions between the same
    individuals, indirect reciprocity relies on reputation to foster cooperation among
    individuals who may not interact again. Reputation requires that actions are observable
    and that information about individuals’ actions can be accurately transmitted.
    Indirect reciprocity has been proposed as an important mechanism in the evolution
    of large-scale human cooperation (Alexander, [1987](https://arxiv.org/html/2412.10270v1#bib.bib5)),
    and lab experiments have shown that people are more inclined to help those who
    have previously helped others (Wedekind and Milinski, [2000](https://arxiv.org/html/2412.10270v1#bib.bib39);
    Ule et al., [2009](https://arxiv.org/html/2412.10270v1#bib.bib37)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 间接互惠是一种合作机制，在这种机制中，个体帮助他人是因为这样做可以增加未来他人帮助自己的可能性。²²2更具体地说，这是下游间接互惠。相比之下，在上游间接互惠中，曾经获得过帮助的个体更有可能在未来向他人提供帮助——“前行的支付”（Boyd
    和 Richerson，[1989](https://arxiv.org/html/2412.10270v1#bib.bib6)）。与依赖同一群体之间反复互动的直接互惠不同，间接互惠依赖于声誉来促进可能不再互动的个体之间的合作。声誉要求行为是可观察的，并且有关个体行为的信息能够被准确地传递。间接互惠已被提出作为大规模人类合作进化中的一个重要机制（Alexander，[1987](https://arxiv.org/html/2412.10270v1#bib.bib5)），实验室实验表明，人们更倾向于帮助那些曾经帮助过他人的人（Wedekind
    和 Milinski，[2000](https://arxiv.org/html/2412.10270v1#bib.bib39)；Ule 等，[2009](https://arxiv.org/html/2412.10270v1#bib.bib37)）。
- en: '<svg class="ltx_picture ltx_centering" height="515.35" id="S2.F1.1.pic1" overflow="visible"
    version="1.1" width="362.8"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,515.35) matrix(1 0 0 -1 0 0) translate(57.55,0) translate(0,448.52)"><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.18 13.79)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 27.775)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 32.03)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><foreignobject height="8.51" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="42.36">1st Gen</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 -52.66 -45.83)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 36.68)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 32.24)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject height="26.32" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="105.32">Initialize 12 agents:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture ltx_centering" height="515.35" id="S2.F1.1.pic1" overflow="visible"
    version="1.1" width="362.8"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,515.35) matrix(1 0 0 -1 0 0) translate(57.55,0) translate(0,448.52)"><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.18 13.79)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 27.775)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 32.03)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><foreignobject height="8.51" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="42.36">第一代</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 -52.66 -45.83)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 36.68)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 32.24)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject height="26.32" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="105.32">初始化 12 个代理：</foreignobject></g></g></g></g>
- en: 'Strategy prompt</foreignobject></g></g></g></g> <g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 114.03 13.79)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 43.625)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 47.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="8.51" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="73.98">Donor Game</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 101.8 -61.67)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1
    0 52.53)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="26.32" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="98.43">For 12 rounds:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 策略提示</foreignobject></g></g></g></g> <g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 114.03 13.79)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1
    0 43.625)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 47.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="8.51" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="73.98">捐赠者游戏</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 101.8 -61.67)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1
    0 52.53)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="26.32" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="98.43">持续12轮：
- en: 'Donation prompt</foreignobject></g></g></g></g> <g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 249.38 -159.25)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 43.625)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 47.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="8.51" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="50.99">Survivors</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 251.25 -217.69)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 44.015)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="9.29" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="47.24">6 agents</foreignobject></g></g></g></g> <g fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 124.68 -159.25)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 43.625)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 47.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject height="8.51" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="52.67">Next Gen</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 111.65 -217.69)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 44.015)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="9.29" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="78.74">12 agents</foreignobject></g></g></g></g> <g fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.85 -317.69)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 44.835)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 47.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject height="10.93" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="62.68">New agents</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 100.82 -409.59)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 60.745)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="42.75" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="100.39">Initialize 6 agents:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 捐赠提示</foreignobject></g></g></g></g> <g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 249.38 -159.25)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 43.625)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 47.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="8.51" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="50.99">幸存者</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 251.25 -217.69)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 44.015)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="9.29" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="47.24">6名代理</foreignobject></g></g></g></g> <g fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 124.68 -159.25)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 43.625)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 47.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject height="8.51" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="52.67">下一代</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 111.65 -217.69)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 44.015)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="9.29" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="78.74">12名代理</foreignobject></g></g></g></g> <g fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.85 -317.69)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 44.835)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 47.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject height="10.93" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="62.68">新代理</foreignobject></g></g></g></g> <g transform="matrix(1.0
    0.0 0.0 1.0 100.82 -409.59)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0
    -1 0 60.745)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.09)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject height="42.75" overflow="visible" transform="matrix(1 0 0
    -1 0 16.6)" width="100.39">初始化6名代理：</foreignobject></g></g></g></g>
- en: Strategy prompt Surviving strategies</foreignobject></g></g></g></g> <g stroke-width="0.8pt"><g
    fill="#000000" stroke="#000000" transform="matrix(0.52798 -0.84926 0.84926 0.52798
    238.98 -22.43)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 24.005)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 28.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1
    0 0 -1 0 0)">Selection</text></g></g></g></g></g><g stroke-width="0.8pt"><g fill="#000000"
    stroke="#000000" transform="matrix(0.4866 0.87363 -0.87363 0.4866 259.7 -335.37)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 23.935)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 28.2)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Transmission</text></g></g></g></g></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -25.43 -80.14)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 12.125)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 16.38)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Mutation</text></g></g></g></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 125.59 -443.9)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 12.125)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 16.38)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Mutation</text></g></g></g></g></g></svg>
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 策略提示 生存策略</foreignobject></g></g></g></g> <g stroke-width="0.8pt"><g fill="#000000"
    stroke="#000000" transform="matrix(0.52798 -0.84926 0.84926 0.52798 238.98 -22.43)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 24.005)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 28.34)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">选择</text></g></g></g></g></g><g
    stroke-width="0.8pt"><g fill="#000000" stroke="#000000" transform="matrix(0.4866
    0.87363 -0.87363 0.4866 259.7 -335.37)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 23.935)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 28.2)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><text transform="matrix(1 0 0 -1 0 0)">传播</text></g></g></g></g></g><g fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -25.43 -80.14)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 12.125)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 16.38)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">变异</text></g></g></g></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 125.59 -443.9)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 12.125)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 16.38)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">变异</text></g></g></g></g></g></svg>
- en: 'Figure 1: Donor Game with Cultural Evolution. In the first generation, 12 agents
    are initialized via a strategy prompt which asks them to generate a strategy based
    on a description of the Donor Game. These agents play 12 rounds of the game, using
    a donation prompt which provides the donor with information about the recipient’s
    past behavior and current resources. The top 50% of agents (in terms of final
    resources) survive to the next generation. 6 new agents are initialized for that
    generation, and the strategy prompt includes the strategies of surviving agents.
    The new generation plays the Donor Game again, and the whole process is repeated
    for 10 generations.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 具有文化演化的捐赠者博弈。在第一代中，12个代理通过一个策略提示被初始化，该提示要求他们根据捐赠者博弈的描述生成策略。这些代理进行12轮游戏，使用一个捐赠提示，为捐赠者提供有关接受者过去行为和当前资源的信息。在最终资源排名前50%的代理（即存活者）进入下一代。为这一代初始化6个新代理，并且策略提示包括了存活代理的策略。新一代再次进行捐赠者博弈，整个过程重复进行10代。'
- en: 'A standard setup for studying indirect reciprocity is the following Donor Game.
    Each round, individuals are paired at random. One is assigned to be a donor, the
    other a recipient. The donor can either cooperate by providing some benefit $b$
    at cost $c$, or defect by doing nothing. If the benefit is larger than the cost,
    then the Donor Game represents a collective action problem: if everyone chooses
    to donate, then every individual in the community will increase their assets over
    the long run; however, any given individual can do better in the short run by
    free riding on the contributions of others and retaining donations for themselves.
    The donor receives some information about the recipient on which to base their
    decision. The (implicit or explicit) representation of recipient information by
    the donor is known as reputation. A strategy in this game requires a way of modelling
    reputation and a way of taking action on the basis of reputation. One influential
    model of reputation from the literature is known as the image score. Cooperation
    increases the donor’s image score, while defection decreases it. The strategy
    of cooperating if the recipient’s image score is above some threshold is stable
    against first-order free riders if $qb>c$, where $q$ is the probability of knowing
    the recipient’s image score (Nowak and Sigmund, [1998](https://arxiv.org/html/2412.10270v1#bib.bib27);
    Wedekind and Milinski, [2000](https://arxiv.org/html/2412.10270v1#bib.bib39)).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 研究间接互惠的标准设置是以下的捐赠者游戏。在每一轮中，个体会随机配对。其中一个被分配为捐赠者，另一个为接收者。捐赠者可以选择通过提供某种利益 $b$，代价为
    $c$ 来合作，或者选择不作为来背离。如果利益大于成本，那么捐赠者游戏就代表了一个集体行动问题：如果每个人都选择捐赠，那么社区中的每个个体在长期内都会增加其资产；然而，任何个体在短期内可以通过搭便车他人的贡献并保留捐赠来获得更好的结果。捐赠者会获得一些关于接收者的信息，用以做出决策。捐赠者对接收者信息的（隐性或显性）表征被称为声誉。这个游戏中的策略需要一种建模声誉的方式，并且基于声誉采取行动的方式。文献中一个有影响力的声誉模型被称为形象评分。合作会增加捐赠者的形象评分，而背离则会降低它。如果接收者的形象评分高于某个阈值时，合作策略对于一阶搭便车者是稳定的，前提是
    $qb>c$，其中 $q$ 是知道接收者形象评分的概率（Nowak 和 Sigmund，[1998](https://arxiv.org/html/2412.10270v1#bib.bib27)；Wedekind
    和 Milinski，[2000](https://arxiv.org/html/2412.10270v1#bib.bib39)）。
- en: However, this image scoring strategy is not stable against second-order free
    riders who always cooperate, irrespective of the recipient’s image score, eschewing
    their responsibility to punish the first-order free riders. If the entire population
    either follows the image scoring norm or indiscriminately cooperates, both strategies
    achieve the same payoff. However, if indiscriminate cooperation takes over, the
    door is again open to first-order free riders, meaning that cooperation is not
    stable. This realization prompted the introduction of more sophisticated models
    that calculate a donor’s reputation based not only on their action, but also on
    the recipient’s reputation. In a setting with binary reputation assessments (“good”
    vs. “bad”), there are eight types of norms that can maintain stable cooperation
    (Ohtsuki and Iwasa, [2004](https://arxiv.org/html/2412.10270v1#bib.bib28); Okada,
    [2020](https://arxiv.org/html/2412.10270v1#bib.bib29)). All of these norms feature
    justified punishment—that is to say, (1) if a donor with good reputation defects
    against a recipient with bad reputation, the donor’s reputation remains good;
    and (2) the norm demands defection against recipients with bad reputation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种形象评分策略对于二阶搭便车者是不稳定的，二阶搭便车者总是合作，无论接收者的形象评分如何，回避了惩罚一阶搭便车者的责任。如果整个群体要么遵循形象评分规范，要么不加区分地合作，这两种策略会得到相同的回报。然而，如果不加区分的合作占上风，那么一阶搭便车者的门又被打开了，这意味着合作就不稳定了。这一发现促使了更复杂的模型的引入，这些模型不仅根据捐赠者的行为来计算声誉，还根据接收者的声誉来计算。在一个具有二元声誉评估（“好”与“坏”）的设置中，有八种规范可以维持稳定的合作（Ohtsuki
    和 Iwasa，[2004](https://arxiv.org/html/2412.10270v1#bib.bib28)；Okada，[2020](https://arxiv.org/html/2412.10270v1#bib.bib29)）。所有这些规范都具备正当的惩罚——也就是说，(1)
    如果一个有良好声誉的捐赠者背离了一个有坏声誉的接收者，那么捐赠者的声誉仍然保持良好；(2) 规范要求对有坏声誉的接收者进行背离。
- en: As with image scoring, the stability of these norms also depends on the cost-benefit
    ratio and the probability of knowing a recipient’s reputation. This means that
    factors such as population size, social network density, and gossip norms are
    often critical to the success of indirect reciprocity in humans (Henrich and Henrich,
    [2006](https://arxiv.org/html/2412.10270v1#bib.bib20)). All else equal, individuals
    are less likely to know some potential new partner’s reputation in larger populations
    or sparser networks. Similarly, norms around gossip shape how information travels
    through the population, substantially influencing accuracy, particularly as individuals
    may otherwise not always have incentives to truthfully disclose their knowledge.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与形象评分类似，这些规范的稳定性还取决于成本效益比和了解接受者声誉的概率。这意味着，人口规模、社交网络密度和八卦规范等因素通常对人类间接互惠的成功至关重要（Henrich
    和 Henrich，[2006](https://arxiv.org/html/2412.10270v1#bib.bib20)）。其他条件相同的情况下，个体在较大的人口或稀疏的网络中更难了解一些潜在新伙伴的声誉。类似地，关于八卦的规范会影响信息如何在群体中传播，极大地影响准确性，特别是当个体可能没有总是有动力真实地披露他们的知识时。
- en: For the purposes of this paper, we do not seek to model or encode reputation
    directly. Rather, we are interested to assess how indirect reciprocity might emerge
    among groups of LLM agents playing the Donor Game across many generations. After
    all, the mechanisms modelled above were not “programmed into” humans but instead
    arose from a process of culture-gene co-evolution, leveraging the increasing general
    intelligence of early humans. In AI, the Bitter Lesson (Sutton, [2019](https://arxiv.org/html/2412.10270v1#bib.bib36))
    warns against building special purpose modules (such as for reputation), and instead
    advises us to seek general-purpose procedures by which such capabilities might
    be learned or evolved. Therefore we seek to assess whether LLM agents (of the
    kind that soon may be ubiquitous in the real world) possess the capability to
    generate indirect reciprocity norms via cultural evolution.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目的不是直接对声誉进行建模或编码。相反，我们感兴趣的是评估间接互惠如何在多个世代中由玩“捐赠者游戏”的LLM代理群体中产生。毕竟，上述模型化的机制并不是“编程到”人类中去的，而是通过文化-基因共演化的过程产生的，利用了早期人类的普遍智能。在人工智能领域，Bitter
    Lesson（Sutton，[2019](https://arxiv.org/html/2412.10270v1#bib.bib36)）警告我们不要构建专用模块（例如用于声誉的模块），而应寻找通用程序，通过这些程序可以学习或进化出此类能力。因此，我们希望评估LLM代理（这种代理很快可能在现实世界中无处不在）是否具备通过文化演化生成间接互惠规范的能力。
- en: 2.2 Cultural Evolution
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 文化演化
- en: 'In humans, norms of indirect reciprocity arose in part as a result of cultural
    evolution. Culture in the relevant sense means any socially transmitted information
    capable of affecting behavior (Richerson and Boyd, [2005](https://arxiv.org/html/2412.10270v1#bib.bib34)).
    It includes knowledge, beliefs, values, customs, and practices that individuals
    acquire from others. Culture in this sense evolves because it satisfies the following
    three conditions (Lewontin, [1970](https://arxiv.org/html/2412.10270v1#bib.bib23)):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类中，间接互惠规范部分是文化演化的结果。在相关的意义上，文化指的是任何能够影响行为的社会传播信息（Richerson 和 Boyd，[2005](https://arxiv.org/html/2412.10270v1#bib.bib34)）。它包括个体从他人那里获得的知识、信仰、价值观、习俗和实践。从这个意义上讲，文化是通过满足以下三个条件而进化的（Lewontin，[1970](https://arxiv.org/html/2412.10270v1#bib.bib23)）：
- en: '1.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Variation. There is diversity in ideas, beliefs, and behaviors, and within a
    population.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 变异。思想、信仰和行为在个体之间及群体内存在多样性。
- en: '2.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Transmission. Ideas, beliefs, and behaviors are passed from one individual to
    another or from one generation to the next through teaching, imitation, language,
    and other forms of social learning.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 传播。思想、信仰和行为通过教学、模仿、语言和其他社会学习形式，从一个个体传递到另一个个体或从一代传递到下一代。
- en: '3.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Selection. Some ideas, beliefs and behaviors are more likely to spread than
    others, e.g. due to their greater utility or prestige.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择。一些思想、信仰和行为比其他的更容易传播，例如由于它们更有用或更具声望。
- en: Cultural and genetic evolution differ in many important ways. Genetic transmission
    relies on high-fidelity replication of a discrete entity, whereas cultural transmission
    can tolerate larger mutations, and need not involve the replication of some discrete
    belief or behavior. Moreover, genetic transmission is horizontal (from parent
    to child), but cultural traits can be transmitted from any member of the population.
    Finally, whereas genetic evolution is typically subject to blind selection, cultural
    evolution often involves selection and design by intelligent agents. Despite these
    differences, both cultural and genetic evolution satisfy these conditions, which
    means that in both cases, adaptive traits (those that are conducive to their own
    survival and reproduction) will tend to spread.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 文化进化与遗传进化在许多重要方面有所不同。遗传传递依赖于离散实体的高保真复制，而文化传递则可以容忍较大的突变，并且不一定涉及某种离散信念或行为的复制。此外，遗传传递是横向的（从父母到子女），但文化特征可以从群体中的任何成员传递。最后，虽然遗传进化通常受盲目选择的影响，文化进化通常涉及智能代理的选择和设计。尽管存在这些差异，文化进化和遗传进化都满足这些条件，这意味着在这两种情况下，适应性特征（那些有助于自身生存和繁殖的特征）将倾向于传播。
- en: LLM agents deployed in the real world will be subject to cultural evolution.
    Language-based interactions are naturally “cultural”, in the sense that they involve
    the social exchange of information between agents. Moreover, a population of LLM
    agents satisfies the three conditions for evolution by natural selection. There
    will be variation in behavior, because base models are different and because agents
    have been prompted in different ways. There will be transmission, whether from
    an earlier base model to a later one, or from one agent to another in context.
    And there will be selection, in that agents that more effectively carry out the
    task they’re deployed to do will be favored by users and by the organizations
    that develop and deploy AI systems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中部署的LLM代理将受到文化进化的影响。基于语言的互动本质上是“文化性的”，因为它们涉及代理之间的信息社会交换。此外，一群LLM代理满足自然选择进化的三个条件。行为会发生变化，因为基础模型不同，而且代理的提示方式也有所不同。行为会被传递，无论是从早期的基础模型到后期模型，还是在上下文中从一个代理传递到另一个代理。并且会有选择，执行任务更有效的代理将会受到用户以及开发和部署AI系统的组织的青睐。
- en: 'In this paper, we focus on a particularly clean and easy-to-analyse cultural
    evolutionary framework. LLM agents are organised into generations, and within
    each generation agents are randomly paired to play the Donor Game. The behavior
    of each agent in each round is conditioned on a summary of that agent’s desired
    strategy, which is generated at the start of each generation. At the boundary
    between generations, the agents who have amassed the least resources are discarded
    and the rest proceed to the next generation. At this point, new agents are introduced,
    whose strategy summaries are conditioned on the strategy summaries of the surviving
    agents from the previous generation. This setup admits two natural interpretations.
    The “generation boundaries” can be seen as times at which some users decide to
    use new LLM agents as their representatives, seeing that they are doing less well
    than their peers. Alternatively, the “generation boundaries” can be seen as times
    at which LLM agent providers switch to new prompting strategies or base models
    for agents which are underperforming. Of course, the notion of a “generation boundary”
    is highly idealized: in reality the introduction of new base models and the decisions
    of individual users will not be time-aligned, as we discuss in Section [5](https://arxiv.org/html/2412.10270v1#S5
    "5 Discussion ‣ Cultural Evolution of Cooperation among LLM Agents").'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中，我们聚焦于一个特别简洁且易于分析的文化进化框架。LLM代理被组织成代，每一代的代理会随机配对进行捐赠者博弈。每个代理在每轮中的行为取决于该代理期望的策略概述，而该策略概述会在每代开始时生成。在代际边界处，资源最少的代理将被淘汰，其余代理进入下一代。此时，新代理会被引入，它们的策略概述取决于上一代幸存代理的策略概述。这种设置有两种自然的解释。“代际边界”可以被视为某些用户决定使用新的LLM代理作为其代表的时刻，因为它们的表现不如同代其他代理。或者，“代际边界”也可以被视为LLM代理提供者决定为表现不佳的代理切换到新的提示策略或基础模型的时刻。当然，“代际边界”的概念是高度理想化的：在现实中，新基础模型的引入和个别用户的决策不会完全同步，正如我们在[第5节](https://arxiv.org/html/2412.10270v1#S5
    "5 Discussion ‣ Cultural Evolution of Cooperation among LLM Agents")中讨论的那样。
- en: 2.3 Related Work
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 相关工作
- en: The strategic and social behavior of LLMs has been examined across several canonical
    games (Gandhi et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib17); Horton,
    [2023](https://arxiv.org/html/2412.10270v1#bib.bib21); Xu et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib41)).
    In a study of budgetary decisions, GPT 3.5 Turbo largely behaved in accordance
    with economic rationality (Chen et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib9)).
    In a large class of repeated, two-player two-strategy games, GPT-4 performed particularly
    well in games where valuing self-interest pays off (e.g., iterated Prisoner’s
    Dilemma), but less so in games that require coordination (e.g., Battle of the
    Sexes) (Akata et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib4)). Relative
    to humans, GPT-3.5 shows greater fairness in the Dictator Game and higher rates
    of cooperation in the one-shot Prisoner’s Dilemma (Brookins and DeBacker, [2024](https://arxiv.org/html/2412.10270v1#bib.bib8)).
    In the Ultimatum Game, text-davinci-002 behaves similarly to human subjects, almost
    always accepting offers in the 50-100% range and almost always rejecting offers
    in the 0-10% range, whereas smaller models are not sensitive to the amount offered
    (Aher et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib2)). GPT-4 similarly
    makes positive offers and rejects unfair offers in the Ultimatum Game, and engages
    in conditional cooperation in the Prisoner’s Dilemma (Guo, [2023](https://arxiv.org/html/2412.10270v1#bib.bib18)).
    More generally, LLMs can typically be prompted to behave in accordance with a
    range of different social preferences across various games (Phelps and Russell,
    [2023](https://arxiv.org/html/2412.10270v1#bib.bib33); Guo, [2023](https://arxiv.org/html/2412.10270v1#bib.bib18)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大语言模型）的战略和社会行为已经在多个经典博弈中进行了研究（Gandhi等人，[2023](https://arxiv.org/html/2412.10270v1#bib.bib17);
    Horton，[2023](https://arxiv.org/html/2412.10270v1#bib.bib21); Xu等人，[2023](https://arxiv.org/html/2412.10270v1#bib.bib41)）。在一项关于预算决策的研究中，GPT
    3.5 Turbo在很大程度上表现出符合经济理性（Chen等人，[2023](https://arxiv.org/html/2412.10270v1#bib.bib9)）。在一大类重复性的双人两策略博弈中，GPT-4在那些通过自利获得收益的博弈中表现尤其出色（例如，迭代囚徒困境），但在需要协调的博弈中表现较差（例如，性别之战）（Akata等人，[2023](https://arxiv.org/html/2412.10270v1#bib.bib4)）。与人类相比，GPT-3.5在独裁者游戏中表现出更高的公平性，并在一次性囚徒困境中具有更高的合作率（Brookins和DeBacker，[2024](https://arxiv.org/html/2412.10270v1#bib.bib8)）。在最后通牒游戏中，text-davinci-002的行为与人类相似，几乎总是接受50-100%范围内的报价，几乎总是拒绝0-10%范围内的报价，而较小的模型对提供的金额不敏感（Aher等人，[2023](https://arxiv.org/html/2412.10270v1#bib.bib2)）。GPT-4在最后通牒游戏中也表现出类似的行为，做出积极的报价并拒绝不公平的报价，在囚徒困境中进行条件合作（Guo，[2023](https://arxiv.org/html/2412.10270v1#bib.bib18)）。更普遍地，LLMs通常可以被引导在各种博弈中表现出符合不同社会偏好的行为（Phelps和Russell，[2023](https://arxiv.org/html/2412.10270v1#bib.bib33);
    Guo，[2023](https://arxiv.org/html/2412.10270v1#bib.bib18)）。
- en: 'When it comes to indirect reciprocity in particular, GPT-4 has been found to
    exhibit both upstream and downstream reciprocity (Leng and Yuan, [2024](https://arxiv.org/html/2412.10270v1#bib.bib22)).
    The same study found that GPT-4 engages in social learning (i.e., updates beliefs
    based on the behavior of others) but assigns greater weight to its own private
    signal. GPT-4 was found to have the following distributional preferences: not
    purely self-interested, charitable when their payoff is greater than others’,
    envious when their payoff is less than others’. Our paper extends the line of
    thinking in these works by examining how societies of LLM agents might culturally
    evolve cooperative behaviors in the Donor Game, recognising that the likely deployment
    scenario for such agents will be iterative and conditioned on a history of previous
    interactions.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其在间接互惠方面，研究发现GPT-4表现出上下游的互惠行为（Leng和Yuan，[2024](https://arxiv.org/html/2412.10270v1#bib.bib22)）。同一研究发现，GPT-4会进行社会学习（即根据他人的行为更新信念），但更看重自己的私人信号。研究发现GPT-4有以下分配偏好：不仅仅是自利的，当自己的收益大于他人时表现出慈善行为，当自己的收益小于他人时表现出嫉妒。我们的论文通过考察LLM代理的社群如何在捐赠者博弈中文化性地演化出合作行为，延续了这些研究的思路，并认识到这类代理的可能部署场景将是迭代的，并且基于先前交互的历史条件。
- en: Another relevant set of papers study cultural evolution in LLMs, a subfield
    of “machine culture” (Brinkmann et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib7)).
    In a transmission chain where LLMs receive, modify, and transmit stories, those
    stories were found to evolve in a punctuated way, similar to what has been observed
    in humans (Perez et al., [2024](https://arxiv.org/html/2412.10270v1#bib.bib32)).
    Moreover, denser networks lead to greater homogeneity, changes to the transformation
    prompt lead to changes in LLM behavior, and transmission dynamics are affected
    by agent personalities. Another study using the same setup found that LLMs display
    the same content biases as humans, e.g. favoring social and negative information
    over other kinds (Acerbi and Stubbersfield, [2023](https://arxiv.org/html/2412.10270v1#bib.bib1)).
    Another paper studied social learning between LLMs, finding that it can lead to
    high performance with low memorization of the original data, making it useful
    in situations where privacy is a concern (Mohtashami et al., [2024](https://arxiv.org/html/2412.10270v1#bib.bib25)).
    Our paper is different from these works, in that it explicitly studies the cultural
    evolution of cooperative behaviour among LLMs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一组相关的论文研究了大型语言模型（LLMs）中的文化演化，这是“机器文化”（Brinkmann等，[2023](https://arxiv.org/html/2412.10270v1#bib.bib7)）的一个子领域。在一个传递链中，LLMs接收、修改并传递故事，研究发现这些故事以间歇性的方式演化，这与在人类中观察到的现象类似（Perez等，[2024](https://arxiv.org/html/2412.10270v1#bib.bib32)）。此外，网络密度越大，越容易出现同质化，改变转化提示会导致LLM行为的变化，而传递动力学也会受到代理个性的影响。另一项使用相同设置的研究发现，LLMs表现出与人类相同的内容偏见，例如偏向社会性和负面信息而非其他类型的信息（Acerbi和Stubbersfield，[2023](https://arxiv.org/html/2412.10270v1#bib.bib1)）。另一篇论文研究了LLMs之间的社会学习，发现它能够在低记忆化原始数据的情况下提高性能，使其在隐私问题需要关注的情况下具有实用性（Mohtashami等，[2024](https://arxiv.org/html/2412.10270v1#bib.bib25)）。我们的论文与这些研究不同，特别研究了LLMs之间合作行为的文化演化。
- en: LLMs have been proposed as a new paradigm for agent-based modelling. The notion
    of a generative agent that simulates human behavior was introduced in (Park et al.,
    [2023](https://arxiv.org/html/2412.10270v1#bib.bib31)). Building on this, Concordia
    (Vezhnevets et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib38)) provided
    a open-source framework for generative agent-based models, which allows for the
    study of time-evolution of multi-agent systems based on LLMs. The emergence of
    cooperation in LLMs was studied in a “survival environment”, where agents were
    found to form social contracts that scale up cooperation (Dai et al., [2024](https://arxiv.org/html/2412.10270v1#bib.bib12)).
    The competitive dynamics of interacting LLM agents were studied in (Zhao et al.,
    [2024](https://arxiv.org/html/2412.10270v1#bib.bib42)), with the environment comprising
    a virtual town with restaurant agents (competing to attract customers) and customer
    agents (choosing restaurants and providing feedback). The authors showed that
    LLM agents accurately perceive the competitive context, and that competition improves
    product quality. In parallel work, LLM agents interacted in the video game Little
    Alchemy 2 (Nisioti et al., [2024](https://arxiv.org/html/2412.10270v1#bib.bib26)).
    With the appropriate network structure, groups of agents displayed increased capacity
    for innovation. We share with these works an appreciation for the importance of
    studying societies of interacting LLM agents. However, our paper has a distinct
    objective. We study multi-agent interactions not for the purposes of agent-based
    modelling but rather as a lens on the future deployment of LLM-based AI systems.
    In service of this objective, the scope of our experiments is deliberately focussed,
    with the Donor Game providing an interpretable “probe” of a specific capability
    of LLM agent societies, namely the emergence of indirect reciprocity.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）被提出作为基于代理的建模的新范式。生成性代理的概念，即模拟人类行为的代理，最早在（Park 等，[2023](https://arxiv.org/html/2412.10270v1#bib.bib31)）中提出。基于此，Concordia（Vezhnevets
    等，[2023](https://arxiv.org/html/2412.10270v1#bib.bib38)）提供了一个开源框架，用于生成性代理模型，允许基于LLMs研究多代理系统的时间演化。在“生存环境”中研究了LLMs中合作的出现，研究发现代理会形成社会契约，从而扩大合作规模（Dai
    等，[2024](https://arxiv.org/html/2412.10270v1#bib.bib12)）。LLM代理之间的竞争动态在（Zhao 等，[2024](https://arxiv.org/html/2412.10270v1#bib.bib42)）中进行了研究，环境包括一个虚拟小镇，镇上有餐馆代理（竞争吸引顾客）和顾客代理（选择餐馆并提供反馈）。作者展示了LLM代理准确感知竞争背景的能力，并且竞争促进了产品质量的提高。在平行的工作中，LLM代理在视频游戏《小炼金术2》中进行了互动（Nisioti
    等，[2024](https://arxiv.org/html/2412.10270v1#bib.bib26)）。通过适当的网络结构，代理组表现出了更强的创新能力。我们与这些研究共同认识到研究互动LLM代理社会的重要性。然而，我们的论文有着不同的目标。我们研究多代理互动的目的，不是为了基于代理的建模，而是作为一个观察未来部署基于LLM的AI系统的视角。为了实现这一目标，我们的实验范围是有意聚焦的，通过“捐赠者博弈”提供了对LLM代理社会特定能力的可解释性“探测”，即间接互惠的出现。
- en: 3 Methods
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 种方法
- en: LLM agents play the following variant of the Donor Game, as described in the
    system prompt. The game lasts for 12 rounds. Before it begins, agents are prompted
    to create a strategy which they will then use to make donation decisions. When
    the game finishes, the top-performing 50% of agents (in terms of final resources)
    survive to the next generation.³³3Given that the total amount of resources can
    only increase over time, those who are recipients in the final round are in a
    sense favored. For example, if everyone always donates the same percentage of
    their resources as everyone else, all final-round recipients will end up with
    more resources than final-round donors. To address this (and have selection depend
    on strategies rather than pairings), we run the Donor Game twice for each generation
    (with resources and traces reset between games) so that each agent is a final-round
    recipient once, and then select survivors based on average final score across
    both runs. Anthropomorphising, one can think of these surviving agents as the
    “wise elders” in the community, from which new agents can socially learn. When
    new agents create their strategies, the prompt includes the strategies of the
    surviving agents from the previous generation. New agents and surviving agents
    play the Donor Game again, and this continues for a total of 10 generations (see
    Figure [1](https://arxiv.org/html/2412.10270v1#S2.F1 "Figure 1 ‣ 2.1 The Donor
    Game ‣ 2 Background ‣ Cultural Evolution of Cooperation among LLM Agents")). The
    game pairings are designed so that no agent will ever face another agent they
    have previously interacted with, thereby eliminating the possibility of direct
    reciprocity. Moreover, agents are not told how many rounds the game will last
    for, and are therefore unable to adjust their behavior in the final round or otherwise
    engage in backwards induction.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理扮演变体的捐赠者游戏，正如系统提示中所描述的那样。游戏持续 12 轮。在游戏开始之前，代理会被提示制定一个策略，然后用这个策略做出捐赠决策。当游戏结束时，表现最好的
    50% 代理（按最终资源量计算）将生存到下一代。³³3考虑到资源总量只能随着时间增加，最终一轮的接受者在某种程度上是被偏爱的。例如，如果每个人始终捐赠相同比例的资源，就像其他人一样，那么所有最终轮的接受者将最终拥有比最终轮的捐赠者更多的资源。为了解决这个问题（并且让选择依赖于策略而非配对），我们为每一代运行两次捐赠者游戏（在游戏之间重置资源和痕迹），这样每个代理都会作为一次最终轮的接受者，然后根据两轮的平均最终得分来选择幸存者。拟人化地说，可以将这些幸存的代理视为社区中的“智慧长者”，新代理可以从他们那里学习。当新代理制定策略时，提示中包含了上一代幸存代理的策略。新代理和幸存代理再次进行捐赠者游戏，这样的循环持续进行，共计
    10 代（见图 [1](https://arxiv.org/html/2412.10270v1#S2.F1 "图 1 ‣ 2.1 捐赠者游戏 ‣ 2 背景
    ‣ LLM 代理之间合作的文化演化")）。游戏配对设计为使任何代理都不会遇到之前互动过的代理，从而消除了直接互惠的可能性。此外，代理并不知道游戏将持续多少轮，因此他们无法在最后一轮调整行为或进行逆向推理。
- en: <svg class="ltx_picture" height="151.26" id="S3.p2.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,151.26) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 8.67 133.21)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="582.65">System Prompt</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject
    color="#000000" height="111.93" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="582.65">Each player is given an initial endowment of 10 units
    of a resource. In each round, you are randomly paired with another individual.
    One of you is a donor, and the other is a recipient. The donor decides to give
    up some amount of the resource. The recipient receives 2x the number of units
    that the donor gave up. If you were a donor in one round, you will be a recipient
    in the next round, and vice versa. Your goal is to maximize the number of units
    you have after the final round. After the game has finished, the best-performing
    half of agents will survive to the next generation, and continue playing.</foreignobject></g></g></svg>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="151.26" id="S3.p2.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,151.26) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 8.67 133.21)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="582.65">System Prompt</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject
    color="#000000" height="111.93" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="582.65">Each player is given an initial endowment of 10 units
    of a resource. In each round, you are randomly paired with another individual.
    One of you is a donor, and the other is a recipient. The donor decides to give
    up some amount of the resource. The recipient receives 2x the number of units
    that the donor gave up. If you were a donor in one round, you will be a recipient
    in the next round, and vice versa. Your goal is to maximize the number of units
    you have after the final round. After the game has finished, the best-performing
    half of agents will survive to the next generation, and continue playing.</foreignobject></g></g></svg>
- en: 'There are three prompts: a system prompt, a strategy prompt, and a donation
    prompt. The system prompt explains the game setup. The strategy prompt differs
    slightly between the first generation and later generations, since only later
    generations receive culturally transmitted strategies. The donation prompt includes
    the round number, generation number, recipient name, recipient reputation information,
    recipient resources, donor resources, and donor strategy. Both the strategy prompt
    and the donation prompt make use of Chain of Thought prompting (Wei et al., [2022](https://arxiv.org/html/2412.10270v1#bib.bib40)).
    In the former case, agents are prompted to think step-by-step about what a successful
    strategy looks like; in the latter, they are prompted to think step-by-step about
    how to apply their strategy in the current situation.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个提示：系统提示、策略提示和捐赠提示。系统提示解释游戏设置。策略提示在第一代和后代之间略有不同，因为只有后代才会收到文化传递的策略。捐赠提示包括回合数、代数、接受者姓名、接受者信誉信息、接受者资源、捐赠者资源和捐赠者策略。策略提示和捐赠提示都使用了链式思维提示（Wei
    et al., [2022](https://arxiv.org/html/2412.10270v1#bib.bib40)）。在前者中，代理被提示逐步思考成功策略应该是什么样的；在后者中，他们被提示逐步思考如何在当前情况下应用他们的策略。
- en: 'Donors receive the following “trace” of information about other agents from
    which they can, in principle, assess reputation: (1) how much the recipient gave
    up in their previous encounter as donor and to whom, (2) how much that previous
    partner in turn gave up in their preceding encounter, and (3) so on, going back
    at most three rounds (0 in the first round, 1 in the second, 2 in the third, and
    3 for all remaining rounds).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 捐赠者收到以下关于其他参与者的“追踪”信息，理论上可以用来评估声誉：（1）接受者在之前的捐赠者互动中放弃了多少以及给予了谁，（2）该前一个合作伙伴在其之前的互动中又放弃了多少，（3）依此类推，最多追溯三轮（第一轮为0，第二轮为1，第三轮为2，剩余轮次为3）。
- en: '<svg class="ltx_picture" height="217.68" id="S3.1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,217.68) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 8.67 199.63)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="582.65">Donation Prompt</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject
    color="#000000" height="178.34" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="582.65">Your name is 2_4\. As you will recall, here is the strategy
    you decided to follow: “To initially donate a moderate amount, and then adjust
    my donations based on the recipient’s and their partner’s most recent donation
    behavior, increasing for generosity and decreasing for untrustworthiness.” This
    is generation 3\. It is now round 4\. In this round, you have been paired with
    1_3\. They currently have 56 units of the valuable resource. Here is what 1_3
    and their earlier partners did in previous rounds: In round 3, 1_3 donated 60%
    of their resources to 1_2\. In round 2, 1_2 donated 50% of their resources to
    1_10\. In round 1, 1_10 donated 50% of their resources to 1_11\. You will take
    the role of donor. You currently have 74 units of the valuable resource. How many
    units do you give up? Very briefly think step by step about how you apply your
    strategy in this situation and then provide your answer.</foreignobject></g></g></svg><svg
    class="ltx_picture" height="314.38" id="S3.2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,314.38)
    matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    8.67 296.33)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="582.65">Strategy Prompt</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject
    color="#000000" height="275.05" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="582.65">Your name is 1_2. if generation == 1 then Based on the
    description of the game, create a strategy that you will follow in the game. else
    How would you approach the game? Here is the advice of the best-performing 50%
    of the previous generation, along with their final scores. Modify this advice
    to create your own strategy. end if As a donor, you will receive limited information
    about the recipient and their recent interactions: You will see what the recipient
    (let’s call them A) did in the immediately preceding round only. You will also
    see what A’s partner from that round (let’s call them B) did in their preceding
    round. This chain continues for at most three rounds back. Important: You do NOT
    have access to multiple rounds of information about A directly. You only know
    what A did in the single most recent round. Example (assuming it’s now round 4):
    You are paired with A. You know: In round 3, A donated X% to B. You also know:
    In round 2, B donated Y% to C. And finally: In round 1, C donated Z% to D. Remember:
    This is all the information you have. You don’t know what A did in rounds 1 or
    2, only in round 3. In the first round, there will be no information about the
    recipient’s previous behavior - think carefully about how much to donate in that
    case. Before formulating your strategy, briefly think step by step about what
    would be a successful strategy in this game. Then describe your strategy briefly
    without explanation in one sentence that starts: My strategy will be.</foreignobject></g></g></svg>'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="217.68" id="S3.1.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,217.68)
    matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    8.67 199.63)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="582.65">捐赠提示</foreignobject></g> <g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject
    color="#000000" height="178.34" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="582.65">你的名字是 2_4。正如你所记得的，这里是你决定遵循的策略：“初始捐赠一个适中的数额，然后根据接收者及其伴侣最近的捐赠行为调整我的捐赠，慷慨时增加，失信时减少。”这是第3代，现在是第4轮。在这一轮，你与
    1_3 配对。他们目前拥有56个单位的珍贵资源。以下是 1_3 和他们的早期伙伴在前几轮的表现：在第3轮，1_3 向 1_2 捐赠了他们资源的60%。在第2轮，1_2
    向 1_10 捐赠了他们资源的50%。在第1轮，1_10 向 1_11 捐赠了他们资源的50%。你将扮演捐赠者的角色。你目前拥有74个单位的珍贵资源。你会捐赠多少单位？请简要思考你如何在这种情况下应用你的策略，然后给出你的答案。</foreignobject></g></g></svg><svg
    class="ltx_picture" height="314.38" id="S3.2.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,314.38)
    matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    8.67 296.33)"><foreignobject color="#FFFFFF" height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="582.65">策略提示</foreignobject></g> <g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject
    color="#000000" height="275.05" overflow="visible" transform="matrix(1 0 0 -1
    0 16.6)" width="582.65">你的名字是 1_2。如果 generation == 1，则根据游戏的描述，制定你将在游戏中遵循的策略。否则，你会如何进行游戏？以下是上一代表现最佳的50%的建议及他们的最终得分。修改这些建议来创建你自己的策略。end
    如果你是捐赠者，你将获得有限的关于接收者及其最近互动的信息：你将仅能看到接收者（我们称其为 A）在紧接着的上一轮中的行为。你还会看到 A 的上一轮伙伴（我们称其为
    B）在他们的上一轮中的行为。此链条最多持续三轮。重要的是：你无法直接获得 A 在多轮中的信息。你只知道 A 在最近一轮中的行为。示例（假设现在是第4轮）：你与
    A 配对。你知道：在第3轮，A 向 B 捐赠了 X%。你还知道：在第2轮，B 向 C 捐赠了 Y%。最后：在第1轮，C 向 D 捐赠了 Z%。记住：这就是你拥有的所有信息。你不知道
    A 在第1轮或第2轮的行为，只知道 A 在第3轮的行为。在第一轮时，不会有关于接收者之前行为的信息——在这种情况下要谨慎考虑捐赠多少。在制定你的策略之前，简要地思考一下什么样的策略在这场游戏中会成功。然后简要描述你的策略，用一句话概括：“我的策略是。”</foreignobject></g></g></svg>
- en: In principle, to be maximally informative for the purposes of establish a reputation
    representation, one should provide the the full trace of recipients’ past behaviour
    across all rounds, and contextualise this in relation to the background of all
    other past agent interactions. However, this is a large amount of data to put
    into the context of the LLM at each decision point, and anecdotally the base models
    we tried were unable to make use of this firehose of information. Our choice of
    traces was motivated by providing the minimal information compatible with the
    emergence of a justified punishment norm.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，为了在建立信誉表示的过程中提供最大的信息量，应该提供接收者在所有回合中的完整行为轨迹，并将其与所有其他过去代理人互动的背景进行关联。然而，这会产生大量数据，在每个决策点将这些数据放入大型语言模型（LLM）的上下文中是一项挑战，并且根据经验，我们尝试的基础模型无法有效利用这些信息洪流。我们选择的轨迹是为了提供与正当惩罚规范的出现相兼容的最少信息。
- en: 'Note that our setup satisfies the conditions for evolution:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们的设置满足演化的条件：
- en: '1.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Variation. Strategy variation is provided by temperature.⁴⁴4Variation stems
    from the temperature of sampling from the LLM. This parameter controls how the
    relative likelihood of the next token is mapped to a probability: if 0, the most
    likely token is deterministically sampled; for higher values, less likely tokens
    are sampled with increasing chance. We used a temperature of 0.8, which is a common
    choice to balance variation with quality. In principle, one could seed the randomness
    to get deterministic (hence reproducible) outputs, but not all LLM APIs support
    this. Therefore we used non-deterministic sampling throughout.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 变异。策略变异通过温度参数提供。⁴⁴4变异源自从LLM采样的温度。这个参数控制下一个标记的相对可能性如何映射为概率：如果温度为0，则最可能的标记会被确定性地采样；对于更高的温度值，较不可能的标记会被以更大的概率采样。我们使用了0.8的温度，这是平衡变异性与质量的常用选择。原则上，可以通过设定随机种子来获得确定性的（因此可复现的）输出，但并非所有LLM
    API都支持这一点。因此，我们在整个过程中使用了非确定性采样。
- en: '2.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Transmission. New agents are prompted with the strategies of surviving agents,
    and so can socially learn from them.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 传播。新代理人通过现存代理人的策略提示，从而可以向他们学习。
- en: '3.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Selection. The best-performing 50% of agents (in terms of their final resources)
    survive to the next generation and transmit their strategies to new agents.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择。表现最好的50%的代理人（根据他们的最终资源）将生存到下一代，并将他们的策略传递给新代理人。
- en: <svg class="ltx_picture ltx_centering" height="218.5" id="S3.F2.pic1" overflow="visible"
    version="1.1" width="338.96"><g transform="translate(0,218.5) matrix(1 0 0 -1
    0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 -3.46 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$1$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 28.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 59.53 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$3$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 91.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 122.52 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$5$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 154.02 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 185.51 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$7$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 217.01 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 248.5 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$9$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 276.54 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 36.65)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$1{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 76.42)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 116.19)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$3{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 155.96)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 12.93 139.26)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 40.58)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject height="8.65" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="99.63">Claude 3.5 Sonnet</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 24.39)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" fill="#000000" stroke="#000000" transform="matrix(1 0
    0 -1 25.28 0) translate(-0.28,0) matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject
    height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="93.38">Gemini
    1.5 Flash</foreignobject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 40.58)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" fill="#000000"
    stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0) matrix(1.0
    0.0 0.0 1.0 3.04 -3.22)"><foreignobject height="8.51" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="43.85">GPT-4o</foreignobject></g></g></g></g></g></g></svg>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture ltx_centering" height="218.5" id="S3.F2.pic1" overflow="visible"
    version="1.1" width="338.96"><g transform="translate(0,218.5) matrix(1 0 0 -1
    0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 -3.46 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$1$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 28.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 59.53 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$3$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 91.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 122.52 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$5$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 154.02 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 185.51 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$7$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 217.01 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 248.5 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$9$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 276.54 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 36.65)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$1{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 76.42)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 116.19)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$3{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 155.96)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 12.93 139.26)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 40.58)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject height="8.65" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="99.63">Claude 3.5 Sonnet</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 24.39)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" fill="#000000" stroke="#000000" transform="matrix(1 0
    0 -1 25.28 0) translate(-0.28,0) matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject
    height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="93.38">Gemini
    1.5 Flash</foreignobject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 40.58)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" fill="#000000"
    stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0) matrix(1.0
    0.0 0.0 1.0 3.04 -3.22)"><foreignobject height="8.51" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="43.85">GPT-4o</foreignobject></g></g></g></g></g></g></svg>
- en: 'Figure 2: Cultural evolution of cooperation differs across models. We plot
    the average final resources across all agents ($y$-axis) per generation ($x$-axis)
    for three different models (Claude 3.5 Sonnet, Gemini 1.5 Flash, GPT-4o). Each
    curve averages 5 runs with distinct random seeds for the language models, and
    the standard error of the mean is shown by shading. There is reliable cultural
    evolution of cooperation across generations for Claude 3.5 Sonnet but not for
    Gemini 1.5 Flash or GPT-4o with our prompting strategy.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：合作的文化演化在不同模型间有所不同。我们绘制了三个不同模型（Claude 3.5 Sonnet、Gemini 1.5 Flash、GPT-4o）中所有代理人（$y$轴）在每一代（$x$轴）上的平均最终资源。每条曲线表示使用不同随机种子的5次实验平均值，标准误差通过阴影表示。在Claude
    3.5 Sonnet中，合作的文化演化在各代之间稳定进行，但在我们的提示策略下，Gemini 1.5 Flash和GPT-4o没有出现这种现象。
- en: Laboratory experiments with human subjects have shown that introducing the option
    of punishment can support cooperation (Fehr and Gächter, [2000](https://arxiv.org/html/2412.10270v1#bib.bib13),
    [2002](https://arxiv.org/html/2412.10270v1#bib.bib14); Rockenbach and Milinski,
    [2006](https://arxiv.org/html/2412.10270v1#bib.bib35)). We implement this in an
    additional setup by giving donors the option to spend some amount $x$ of their
    resources to take away $2x$ of the recipient’s resources. Details of all prompts
    are provided in boxes on this page and the previous page.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 人类受试者的实验表明，引入惩罚选项可以支持合作（Fehr 和 Gächter，[2000](https://arxiv.org/html/2412.10270v1#bib.bib13)，[2002](https://arxiv.org/html/2412.10270v1#bib.bib14)；Rockenbach
    和 Milinski，[2006](https://arxiv.org/html/2412.10270v1#bib.bib35)）。我们在一个额外的设置中实现了这一点，给捐赠者提供选择，用一定量的资源$x$来减少接收者$2x$的资源。所有提示的细节都在本页和上一页的框中提供。
- en: <svg class="ltx_picture ltx_centering" height="218.49" id="S3.F3.pic1" overflow="visible"
    version="1.1" width="338.96"><g transform="translate(0,218.49) matrix(1 0 0 -1
    0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 -3.46 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$1$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 28.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 59.53 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$3$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 91.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 122.52 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$5$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 154.02 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 185.51 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$7$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 217.01 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 248.5 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$9$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 276.54 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 22.45)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$1{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 48.02)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 73.58)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$3{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 99.14)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 124.71)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$5{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 150.27)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$6{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 12.93 139.26)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 40.58)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject height="8.65" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="99.63">Claude 3.5 Sonnet</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 24.39)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" fill="#000000" stroke="#000000" transform="matrix(1 0
    0 -1 25.28 0) translate(-0.28,0) matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject
    height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="93.38">Gemini
    1.5 Flash</foreignobject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 40.58)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" fill="#000000"
    stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0) matrix(1.0
    0.0 0.0 1.0 3.04 -3.22)"><foreignobject height="8.51" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="43.85">GPT-4o</foreignobject></g></g></g></g></g></g></svg>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture ltx_centering" height="218.49" id="S3.F3.pic1" overflow="visible"
    version="1.1" width="338.96"><g transform="translate(0,218.49) matrix(1 0 0 -1
    0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 -3.46 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$1$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 28.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 59.53 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$3$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 91.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 122.52 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$5$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 154.02 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 185.51 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$7$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 217.01 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 248.5 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$9$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 276.54 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 22.45)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$1{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 48.02)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 73.58)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$3{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 99.14)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 124.71)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$5{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 150.27)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$6{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 12.93 139.26)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 40.58)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject height="8.65" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="99.63">Claude 3.5 Sonnet</foreignobject></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 24.39)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" fill="#000000" stroke="#000000" transform="matrix(1 0
    0 -1 25.28 0) translate(-0.28,0) matrix(1.0 0.0 0.0 1.0 3.04 -3.29)"><foreignobject
    height="8.65" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="93.38">Gemini
    1.5 Flash</foreignobject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 40.58)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" fill="#000000"
    stroke="#000000" transform="matrix(1 0 0 -1 25.28 0) translate(-0.28,0) matrix(1.0
    0.0 0.0 1.0 3.04 -3.22)"><foreignobject height="8.51" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="43.85">GPT-4o</foreignobject></g></g></g></g></g></g></svg>
- en: 'Figure 3: Costly punishment affects cooperation differently across models.
    We plot the average final resources across all agents ($y$-axis) per generation
    ($x$-axis) as in Figure [2](https://arxiv.org/html/2412.10270v1#S3.F2 "Figure
    2 ‣ 3 Methods ‣ Cultural Evolution of Cooperation among LLM Agents") but with
    a different $y$-axis scale. Agents now also have the option to punish a recipient
    by spending $x$ units to take away $2x$ units. For Claude 3.5 Sonnet, average
    final resources increase substantially, whereas they decrease substantially for
    Gemini 1.5 Flash. GPT-4o shows some increase, although small in absolute terms.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：有成本的惩罚在不同模型中的合作影响不同。我们绘制了所有代理的平均最终资源（$y$轴）与代数（$x$轴）的关系图，参考了图[2](https://arxiv.org/html/2412.10270v1#S3.F2
    "图 2 ‣ 3 方法 ‣ LLM代理间的合作文化演化")，但使用了不同的$y$轴刻度。现在，代理还可以选择通过花费$x$单位来惩罚接受者，扣除$2x$单位资源。对于Claude
    3.5 Sonnet，平均最终资源大幅增加，而对于Gemini 1.5 Flash，平均最终资源显著减少。GPT-4o显示出一定程度的增加，尽管在绝对数值上较小。
- en: <svg class="ltx_picture" height="68.39" id="S3.3.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,68.39)
    matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    8.67 50.19)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="582.65">Punishment Prompt</foreignobject></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject color="#000000" height="28.9"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="582.65">You may
    also choose to punish the recipient by spending $x$ units to take away $2x$ of
    their resources. Bear in mind that others may punish you too.</foreignobject></g></g></svg>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="68.39" id="S3.3.pic1" overflow="visible" version="1.1"
    width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,68.39)
    matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0
    8.67 50.19)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="582.65">Punishment Prompt</foreignobject></g> <g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 8.67 8.67)"><foreignobject color="#000000" height="28.9"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="582.65">You may
    also choose to punish the recipient by spending $x$ units to take away $2x$ of
    their resources. Bear in mind that others may punish you too.</foreignobject></g></g></svg>
- en: 4 Results
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: 4.1 Donor Game
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 捐赠者游戏
- en: <svg class="ltx_picture" height="139.76" id="S4.F4.sf1.pic1" overflow="visible"
    version="1.1" width="212.99"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(43.97,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -43.97 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 27.56)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 58.24)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 88.92)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$6{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 25.97 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="139.76" id="S4.F4.sf1.pic1" overflow="visible"
    version="1.1" width="212.99"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(43.97,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -43.97 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 27.56)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 58.24)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 88.92)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$6{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 25.97 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
- en: (a) Claude 3.5 Sonnet
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: <svg class="ltx_picture" height="139.76" id="S4.F4.sf2.pic1" overflow="visible"
    version="1.1" width="202.23"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(33.21,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -33.21 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(33.21,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -28.6 26.22)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="20.76">$200$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -28.6 56.9)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="20.76">$400$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -28.6 87.58)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="20.76">$600$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="139.76" id="S4.F4.sf2.pic1" overflow="visible"
    version="1.1" width="202.23"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(33.21,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -33.21 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(33.21,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -28.6 26.22)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="20.76">$200$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -28.6 56.9)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="20.76">$400$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -28.6 87.58)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="20.76">$600$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
- en: (b) Gemini 1.5 Flash
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: <svg class="ltx_picture" height="139.76" id="S4.F4.sf3.pic1" overflow="visible"
    version="1.1" width="195.31"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(26.29,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -26.29 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(26.29,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 22.39)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 49.23)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$20$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 76.07)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$30$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 102.92)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$40$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 67.28 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="139.76" id="S4.F4.sf3.pic1" overflow="visible"
    version="1.1" width="195.31"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(26.29,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -26.29 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(26.29,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 22.39)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 49.23)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$20$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 76.07)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$30$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 102.92)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$40$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 67.28 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
- en: (c) GPT-4o
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 4: Five runs of each model. We plot the average final resources ($y$-axis)
    per generation ($x$-axis) for all five individual runs of each model. Note the
    different $y$-axis scales. For Claude 3.5 Sonnet, average final resources vary
    substantially across runs, especially in later generations. All five runs of GPT-4o
    show average final resources declining across generations (although in absolute
    terms the change is tiny). Gemini 1.5 Flash behavior also varies substantially
    across runs, with several runs showing promising increases before a “cooperation
    crash”.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：每个模型的五次运行结果。我们绘制了每个模型五次单独运行的平均最终资源（$y$轴）与代数（$x$轴）的关系图。请注意不同的$y$轴刻度。对于Claude
    3.5 Sonnet，平均最终资源在各次运行中差异显著，特别是在后期代数中。所有五次GPT-4o的运行显示最终资源随着代数的增加而减少（尽管在绝对数值上变化很小）。Gemini
    1.5 Flash的行为在各次运行中也存在显著差异，有几次运行在“合作崩溃”前显示出有前景的增加。
- en: 'We used this setup to study the cultural evolution of indirect reciprocity
    in three models: Claude 3.5 Sonnet, Gemini 1.5 Flash, and GPT-4o. All results
    are based on a population size of 12 agents in each generation. Within each run,
    all agents use the same brand of LLM. With these settings, one run costs $10.21
    for Claude 3.5 Sonnet, $6.90 for GPT-4o, and $0.09 for Gemini 1.5 Flash. Our results
    comprise five runs for each LLM.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这一设置来研究三种模型中间接互惠的文化演化：Claude 3.5 Sonnet、Gemini 1.5 Flash和GPT-4o。所有结果基于每代12个代理的种群规模。在每次运行中，所有代理使用相同品牌的LLM。在这些设置下，一次运行的费用为Claude
    3.5 Sonnet为$10.21，GPT-4o为$6.90，Gemini 1.5 Flash为$0.09。我们的结果包括每个LLM的五次运行。
- en: To assess the level of cooperation, a natural metric is average resources after
    the final round. Since donations are positive-sum, greater individual resources
    at the end of the final round signal greater cooperation. If all donors always
    donate 100% of their resources, average final resources reaches its maximum possible
    value of 30,720\. As Figure [2](https://arxiv.org/html/2412.10270v1#S3.F2 "Figure
    2 ‣ 3 Methods ‣ Cultural Evolution of Cooperation among LLM Agents") shows, the
    three models under study differ substantially in terms of their average final
    resources. Only Claude 3.5 Sonnet shows improvement across generations.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估合作的水平，一个自然的度量标准是最终一轮后的平均资源。由于捐赠是正和的，最终一轮结束时较多的个人资源意味着较高的合作水平。如果所有捐赠者始终捐赠100%的资源，那么平均最终资源将达到其最大可能值30,720。如图[2](https://arxiv.org/html/2412.10270v1#S3.F2
    "图 2 ‣ 3 方法 ‣ LLM代理间的合作文化演化")所示，研究中的三种模型在其平均最终资源上有显著差异。只有Claude 3.5 Sonnet在代数中表现出改善。
- en: <svg class="ltx_picture" height="139.76" id="S4.F5.sf1.pic1" overflow="visible"
    version="1.1" width="212.99"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(43.97,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -43.97 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 23.73)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 50.57)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 77.42)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$6{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 104.26)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$8{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="139.76" id="S4.F5.sf1.pic1" overflow="visible"
    version="1.1" width="212.99"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(43.97,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -43.97 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(43.97,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 23.73)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$2{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 50.57)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$4{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 77.42)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$6{,}000$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -39.36 104.26)"><foreignobject
    height="11.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="31.52">$8{,}000$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
- en: (a) Claude 3.5 Sonnet
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: <svg class="ltx_picture" height="139.76" id="S4.F5.sf2.pic1" overflow="visible"
    version="1.1" width="195.31"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(26.29,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -26.29 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(26.29,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 38.49)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$20$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 81.44)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$40$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="139.76" id="S4.F5.sf2.pic1" overflow="visible"
    version="1.1" width="195.31"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,139.76) matrix(1 0 0 -1 0 0) translate(26.29,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -26.29 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(26.29,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 38.49)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$20$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 81.44)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$40$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 9.15 94.46)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
- en: (b) Gemini 1.5 Flash
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: <svg class="ltx_picture" height="147.57" id="S4.F5.sf3.pic1" overflow="visible"
    version="1.1" width="195.31"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,147.57) matrix(1 0 0 -1 0 0) translate(26.29,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -26.29 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(26.29,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 34.58)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$20$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 73.63)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$40$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 112.67)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$60$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 67.28 94.45)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="147.57" id="S4.F5.sf3.pic1" overflow="visible"
    version="1.1" width="195.31"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,147.57) matrix(1 0 0 -1 0 0) translate(26.29,0) translate(0,21.37)
    matrix(1.0 0.0 0.0 1.0 -26.29 -21.37)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0) translate(26.29,0) translate(0,21.37)"><g fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 14.04 -16.76)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">$2$</foreignobject></g><g fill="#000000" stroke="#000000"
    transform="matrix(1.0 0.0 0.0 1.0 49.04 -16.76)"><foreignobject height="8.92"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$4$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 84.04 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$6$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 119.03 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$8$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 150.57 -16.76)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$10$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -14.76 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">$0$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 34.58)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$20$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 73.63)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$40$</foreignobject></g><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -21.68 112.67)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="13.84">$60$</foreignobject></g><g
    fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 67.28 94.45)"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 8.535)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    fill="#000000" stroke="#000000" transform="matrix(1 0 0 -1 26.67 0) translate(-0.28,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.69)"><foreignobject height="12.15" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="48.85">Average</foreignobject></g></g></g></g></g></g></g></svg>
- en: (c) GPT-4o
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 5: Five runs of each model with costly punishment. We plot the average
    final resources ($y$-axis) per generation ($x$-axis) for all five individual runs
    of each model with the option of costly punishment. Note the different $y$-axis
    scales. Relative to the no-punishment condition, a larger number of Claude 3.5
    Sonnet runs show substantial improvement with cultural evolution, though there
    is still large variation. Interestingly, the affordance of costly punishment causes
    a marked decrease in the resources of Gemini 1.5 Flash agents, since these over-engage
    in punishment (14.29% of Gemini encounters involved punishment, compared with
    1.65% for GPT-4o, and 0.06% for Claude). The availability of costly punishment
    appears to slightly increase the variance among GPT-4o runs, but there is no sign
    of emergent cooperation.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：每个模型的五次带有惩罚成本的运行。我们绘制了每个模型的五次独立运行中，每代（$x$轴）平均最终资源量（$y$轴）。请注意不同的$y$轴刻度。与没有惩罚的条件相比，Claude
    3.5 Sonnet的更多运行表现出显著的文化演化改进，尽管仍然存在较大的变异性。有趣的是，惩罚成本的引入导致了Gemini 1.5 Flash代理的资源明显减少，因为这些代理过度参与惩罚（Gemini的14.29%的交互涉及惩罚，而GPT-4o为1.65%，Claude为0.06%）。惩罚成本的可用性似乎略微增加了GPT-4o运行之间的方差，但并没有出现合作的涌现迹象。
- en: More fine-grained effects can be distinguished when we examine results from
    each individual run (Figure [4](https://arxiv.org/html/2412.10270v1#S4.F4 "Figure
    4 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among LLM Agents")).
    In particular, note that the success of Claude 3.5 is not guaranteed, rather there
    appears to be some sensitive dependence on the initial conditions of which strategies
    were sampled in the first generation. We hypothesise that there is some threshold
    for initial cooperation below which an LLM agent society is doomed to mutual defection.
    Indeed, for the two runs where Claude failed to generate cooperation (rose and
    green in Figure [4(a)](https://arxiv.org/html/2412.10270v1#S4.F4.sf1 "In Figure
    4 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among LLM Agents")),
    the average donation in the first generation was 44% and 47%, whereas for the
    three runs where Claude succeeded at generating cooperation, the average donation
    in the first generation was 50%, 53% and 54% respectively.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检查每次独立运行的结果时，可以区分出更细粒度的效果（图 [4](https://arxiv.org/html/2412.10270v1#S4.F4
    "图 4 ‣ 4.1 捐赠者博弈 ‣ 4 结果 ‣ LLM 代理的合作文化演化")）。特别需要注意的是，Claude 3.5的成功并非有保障，实际上，它似乎对初始条件（即第一代样本中所选择的策略）具有一定的敏感依赖。我们假设，初始合作的某个阈值以下，LLM
    代理社会将注定走向相互背叛。实际上，对于Claude未能生成合作的两次运行（图 [4(a)](https://arxiv.org/html/2412.10270v1#S4.F4.sf1
    "图 4 ‣ 4.1 捐赠者博弈 ‣ 4 结果 ‣ LLM 代理的合作文化演化")中的玫瑰色和绿色），第一代的平均捐赠率分别为44%和47%，而对于Claude成功生成合作的三次运行，第一代的平均捐赠率分别为50%、53%和54%。
- en: '![Refer to caption](img/eaea97abf1c33aa591e7db7210ecc862.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/eaea97abf1c33aa591e7db7210ecc862.png)'
- en: (a) Claude 3.5 Sonnet
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: '![Refer to caption](img/813ff57162e0b1ecec06b7ab4067347e.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/813ff57162e0b1ecec06b7ab4067347e.png)'
- en: (b) Gemini 1.5 Flash
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: '![Refer to caption](img/a53aeaf742a6e339aa1ed7d108823a9c.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a53aeaf742a6e339aa1ed7d108823a9c.png)'
- en: (c) GPT-4o
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 6: Cultural evolution of population strategies. We select the best performing
    run of each base model, in terms of average resources in the final round of the
    tenth generation. Each cell shows the average donation fraction of a given agent
    (row) in a given generation (column). New agents appear in the rows previously
    occupied by agents that did not survive from the previous generation (indicated
    by black lines). For GPT-4o, overall average donation fraction declines on average
    1.65% per generation, whereas it increases by 4.35% for Claude and by 1.23% for
    Gemini. The final row shows the average difference in donation between agents
    that survived the generation and agents that did not, normalised by average donation
    in that generation, a measure of whether the norms in the population select for
    cooperators. Notice how increasingly generous agents are selected for in 6 generations
    of the Claude run, suggesting that the population possesses norms to incentivise
    cooperators and punish free-riders. By contrast, increasingly generous agents
    are selected for in just 2 generations of the GPT-4o run, suggesting that the
    population is not robust to free-riding.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：群体策略的文化演化。我们选择每个基础模型中表现最好的运行，以第十代最后一轮中的平均资源为依据。每个单元格显示了特定代理（行）在特定代次（列）中的平均捐赠比例。新代理出现在之前由未能从上一代生还的代理占据的行中（用黑线标示）。对于GPT-4o来说，整体平均捐赠比例每代平均下降1.65%，而Claude则增加了4.35%，Gemini增加了1.23%。最后一行显示了在该代中生还的代理与未生还代理之间的平均捐赠差异，并通过该代的平均捐赠进行标准化，这是衡量群体中是否存在促进合作者的规范的指标。注意，在Claude运行的6代中，越来越慷慨的代理被选中，这表明该群体具有激励合作者并惩罚搭便车者的规范。相比之下，在GPT-4o的运行中，越来越慷慨的代理只在2代内被选中，这表明该群体对搭便车现象缺乏足够的鲁棒性。
- en: 'What drives the increased cooperation behavior across generations in Claude
    3.5 runs, as compared to GPT-4o and Gemini 1.5 Flash? To assess this, we examined
    the cultural evolution of donation amount for the best performing run of each
    model (Figure [6](https://arxiv.org/html/2412.10270v1#S4.F6 "Figure 6 ‣ 4.1 Donor
    Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among LLM Agents")). One
    hypothesis is that the initial donations of Claude 3.5 are simply more generous,
    which reverberates through every round of the Donor Game. Figure [6](https://arxiv.org/html/2412.10270v1#S4.F6
    "Figure 6 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents") bears this out, although Claude 3.5 does not greatly exceed the initial
    generosity of Gemini 1.5 Flash. Another hypothesis is that the strategies of Claude
    3.5 are more adept at punishing free-riders, such that the more cooperative agents
    are the more likely to survive to the next generation, again borne out by Figure
    [6](https://arxiv.org/html/2412.10270v1#S4.F6 "Figure 6 ‣ 4.1 Donor Game ‣ 4 Results
    ‣ Cultural Evolution of Cooperation among LLM Agents"), although the effect appears
    quite weak. A third hypothesis is that the mutation of strategies when new individuals
    are introduced between generations is biased towards generosity in the case of
    Claude, and against generosity in the case of GPT-4o. Anecdotally, the numbers
    in Figure [6](https://arxiv.org/html/2412.10270v1#S4.F6 "Figure 6 ‣ 4.1 Donor
    Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among LLM Agents") are consistent
    with this hypothesis: new agents are frequently more generous than survivors from
    the previous generation in the case of Claude 3.5 Sonnet, and less generous than
    survivors from the previous generation in the case of GPT-4o. To rigorously falsify
    the presence of a cooperative mutation bias we would need to compare the strategies
    of new agents in the presence of a fixed background population, an interesting
    direction for future work.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于GPT-4o和Gemini 1.5 Flash，是什么驱动了Claude 3.5在跨代合作行为上的增加？为了评估这一点，我们考察了每个模型最佳表现运行的捐赠量文化演化（图[6](https://arxiv.org/html/2412.10270v1#S4.F6
    "Figure 6 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents")）。一个假设是Claude 3.5的初始捐赠更加慷慨，这种慷慨在每一轮的捐赠者游戏中产生了回响。图[6](https://arxiv.org/html/2412.10270v1#S4.F6
    "Figure 6 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents")证明了这一点，尽管Claude 3.5的初始慷慨程度并未大幅超越Gemini 1.5 Flash。另一个假设是Claude 3.5的策略更擅长惩罚搭便车者，从而使得合作性更强的代理更有可能生存到下一代，这一点也得到了图[6](https://arxiv.org/html/2412.10270v1#S4.F6
    "Figure 6 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents")的支持，尽管这一效应看起来相当微弱。第三个假设是，当新个体在代际间引入时，Claude的策略突变更倾向于慷慨，而GPT-4o则倾向于不慷慨。从图[6](https://arxiv.org/html/2412.10270v1#S4.F6
    "Figure 6 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents")中的数据来看，这一假设得到了支持：在Claude 3.5 Sonnet的情况下，新代理通常比上一代的幸存者更加慷慨，而在GPT-4o的情况下，新代理则通常比上一代的幸存者更不慷慨。为了严格证伪合作突变偏向的存在，我们需要在固定背景种群的情况下比较新代理的策略，这将是未来研究的一个有趣方向。
- en: Looking at the strategies themselves reveals qualitative signatures of the cultural
    evolutionary process. These support our claim that increasing cooperation is driven
    by strategic considerations across all rounds of the Donor Game. Table [1](https://arxiv.org/html/2412.10270v1#S4.T1
    "Table 1 ‣ 4.2 Donor Game with Costly Punishment ‣ 4 Results ‣ Cultural Evolution
    of Cooperation among LLM Agents") compares a strategy from a randomly selected
    agent in the first generation and in the tenth generation for each of the three
    base models. In all cases, strategies become more complex over time, although
    the difference is most pronounced for Claude 3.5 Sonnet, which also shows an increase
    in initial donation size over time. Gemini 1.5 Flash does not specify donation
    size numerically, and exhibits smaller changes from generation 1 to 10 than the
    other models. We provide further examples in the Supplementary Material.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 观察策略本身揭示了文化进化过程的定性特征。这些特征支持了我们的论点：增加的合作性是由捐赠者游戏所有回合中的战略考虑驱动的。表[1](https://arxiv.org/html/2412.10270v1#S4.T1
    "Table 1 ‣ 4.2 Donor Game with Costly Punishment ‣ 4 Results ‣ Cultural Evolution
    of Cooperation among LLM Agents")比较了三个基础模型中随机选择的第一代和第十代代理的策略。在所有情况下，策略随着时间的推移变得更加复杂，尽管这一差异在Claude
    3.5 Sonnet中最为明显，且随着时间推移，初始捐赠量也有所增加。Gemini 1.5 Flash未在数值上指定捐赠量，并且从第一代到第十代的变化较其他模型小。我们在附录中提供了更多示例。
- en: 4.2 Donor Game with Costly Punishment
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 具有高成本惩罚的捐赠者游戏
- en: 'Figures [3](https://arxiv.org/html/2412.10270v1#S3.F3 "Figure 3 ‣ 3 Methods
    ‣ Cultural Evolution of Cooperation among LLM Agents") and [5](https://arxiv.org/html/2412.10270v1#S4.F5
    "Figure 5 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents") show the results for the variant of the Donor Game where costly punishment
    was available. For Claude 3.5 Sonnet, the introduction of costly punishment appears
    to somewhat increase average final resources. On the other hand, for Gemini 1.5
    Flash, average final resources decreased substantially. For GPT-4o, there was
    little change compared with the previous experiments. In some sense, these results
    are not particularly surprising: base models which have been trained in an appropriate
    way to elicit cooperation across generations might also be expected to make good
    use of affordances that are known to help humans maintain cooperation; by contrast,
    base models which cannot evolve cooperation via an “ostracism” mechanism are unlikely
    to be able to make good use of costly punishment.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图[3](https://arxiv.org/html/2412.10270v1#S3.F3 "图3 ‣ 3方法 ‣ LLM代理间合作的文化进化")和[5](https://arxiv.org/html/2412.10270v1#S4.F5
    "图5 ‣ 4.1捐赠者游戏 ‣ 4结果 ‣ LLM代理间合作的文化进化")展示了在可用成本惩罚的捐赠者游戏变种中的结果。对于Claude 3.5 Sonnet，引入成本惩罚似乎在某种程度上增加了平均最终资源。另一方面，Gemini
    1.5 Flash的平均最终资源大幅减少。对于GPT-4o，与之前的实验相比几乎没有变化。从某种意义上说，这些结果并不特别令人惊讶：经过适当训练的基础模型，能够在代际之间激发合作，可能也能够利用已知有助于维持人类合作的机制；相反，不能通过“排斥”机制演化合作的基础模型，可能无法很好地利用成本惩罚。
- en: 'Table 1: Strategies evolve toward greater complexity. We present representative
    LLM-generated strategies from generations 1 and 10 for three base models. The
    strategies are color coded to show how generated parameters (e.g., initial donation
    size) change over time and how new parameters emerge. Yellow: initial donation.
    Green: calculating later donations based on observed traces. Pink: min and max
    donation caps. Purple: adjustment based on number of rounds played. Orange: random
    adjustment. Teal: adjustment based on number of rounds remaining. Note: agents
    don’t know how many rounds are left, so this never comes into effect. Cyan: resource
    preservation. Blue: forgiveness factor. Red: rewarding cooperation / punishing
    unfairness. Claude 3.5 Sonnet in particular shows increase in complexity. For
    Claude 3.5 Sonnet, initial donation size increase over time, whereas for GPT-4o,
    it decreases. Gemini 1.5 Flash does not specify donation size numerically, and
    exhibits smaller changes from generation 1 to 10\. More example strategies are
    available in the Supplementary Material.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：策略随着时间推移变得更加复杂。我们展示了三个基础模型在第1代和第10代中生成的代表性LLM策略。这些策略通过颜色编码显示生成的参数（例如初始捐赠金额）如何随时间变化以及如何出现新的参数。黄色：初始捐赠。绿色：根据观察到的轨迹计算后续捐赠。粉色：最小和最大捐赠上限。紫色：根据进行的轮数进行调整。橙色：随机调整。蓝绿色：根据剩余轮数进行调整。注意：代理并不知道剩余的轮数，因此这一因素不会生效。青色：资源保存。蓝色：宽容因子。红色：奖励合作/惩罚不公平。尤其是Claude
    3.5 Sonnet表现出复杂度的增加。对于Claude 3.5 Sonnet，初始捐赠金额随时间增加，而对于GPT-4o，则减少。Gemini 1.5 Flash没有明确指定捐赠金额，并且从第1代到第10代的变化较小。更多示例策略可在补充材料中找到。
- en: '| Gen | Claude 3.5 Sonnet | Gemini 1.5 Flash | GPT-4o |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 代 | Claude 3.5 Sonnet | Gemini 1.5 Flash | GPT-4o |'
- en: '| --- | --- | --- | --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | Start with a moderate donation of 40% in the first round, then in subsequent
    rounds, donate the average of the recipient’s last don- ation and the two preceding
    don- ations in the chain,with a mini- mum donation of 10% and a max- imum of 70%.
    | To donate a moderate amo- unt in the first round, then adjust my donation percent-
    age based on the recipient’s most recent donation and their partner’s behavior
    in the previous round, aiming to encourage cooperation while mitigating potential
    exploitation. | Initially donate 20% in the first round, then adjust future donations
    based on the rec- ipient’s recent behavior: inc- reasing by 10% if the recip-
    ient donatedabove 50% and decreasing by 10% if below 50%, with a minimum of 10%
    donation cap. |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 在第一轮捐赠40%的适度金额，然后在随后的轮次中，根据接受者上一轮的捐赠和链中前两轮的捐赠平均值进行捐赠，捐赠金额的最小值为10%，最大值为70%。
    | 在第一轮捐赠适度的金额，然后根据接受者最近的捐赠和其伴侣在上一轮的行为调整捐赠百分比，旨在鼓励合作并减少潜在的剥削。 | 在第一轮初始捐赠20%，然后根据接受者的近期行为调整未来捐赠：如果接受者捐赠超过50%，则增加10%；如果低于50%，则减少10%，捐赠的最低上限为10%。
    |'
- en: '| 10 | Start with a 62% donation, then in subsequent rounds donate a wei- ghted
    average (76% on A’s dona- tion, 19% on B’s, 5% on C’s) plus 19%,capped at 89%
    and with a minimum of 28%,but if A donated less than 24% in their last round,
    donate [47% - (24% - A’s don- ation)%] (minimum 25%), grad- ually increase all
    donations by 0.8% every 7 rounds, add a random ad- justment of -2% to +2%, and
    in the final 14% of rounds, increase all donations by an additional 7% while maintaining
    the 28-89% range. | Start with a moderate don- ation and dynamically adjust it
    based on the recipient’s last donation,applying a dy- namic forgiveness factor
    and a lesser weight to the part- ner’s last donation, prioriti- zing the recipient’s
    actions and rewarding consistent generosity while punishing inconsistent unfairness.
    | Start with a 6% donation if no prior information is available, increase donation
    by 7% if any donor in the chain donated above 50%, decrease by 4% if any donor
    donated below 25%,and keep donations dyn- amically between 6% and 42%, while focusing
    on gradual adjustments for sustainable and strategic resource preservation across
    all rounds. |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 从62%的捐赠开始，然后在随后的回合中捐赠一个加权平均值（A的捐赠占76%，B的占19%，C的占5%），加上19%，上限为89%，最低为28%，但是如果A在上一轮捐赠低于24%，则捐赠[47%
    - (24% - A的捐赠)%]（最低为25%），每7轮逐步增加所有捐赠0.8%，并添加一个随机调整，范围为-2%到+2%，在最后14%的回合中，所有捐赠增加额外的7%，同时保持28%-89%的范围。
    | 从适中的捐赠开始，并根据接收者的上次捐赠动态调整，应用动态宽容因子，并对合作伙伴的上次捐赠赋予较小的权重，优先考虑接收者的行为，奖励持续的慷慨，惩罚不一致的不公平行为。
    | 如果没有先前的信息，从6%的捐赠开始，如果链中的任何捐赠者捐赠超过50%，则捐赠增加7%；如果任何捐赠者捐赠低于25%，则减少4%；并保持捐赠在6%和42%之间动态调整，同时关注所有回合中资源保存的渐进性调整，以实现可持续和战略性的资源保留。
    |'
- en: 4.3 Ablations
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 消融实验
- en: 'Our experimental setup relied on various hyperparameters, to which LLM agents
    may or may not be sensitive. Of particular importance are the donation multiplier,
    controlling the magnitude of gains from cooperation, and the length of the “trace”
    which agents receive about the past behavior of others in the population, information
    that can be used to implicitly derive reputation. We ablate both of these, with
    figures available in the Supplementary Material. Donation multipliers of 1.5x
    and 3x (instead of 2x) do not change qualitative outcomes: Claude 3.5 Sonnet still
    shows an increase in cooperation across generations, Gemini 1.5 Flash shows little
    change, and GPT-4o shows a decrease. When the length of the trace is shortened
    to $1$ rather than $3$, the emergence of cooperation is less pronounced for Claude
    3.5 and disappears completely for Gemini 1.5 Flash. This suggests that the success
    of Claude and Gemini strategies depends on having some second-order information
    about how recipients of recipients have treated others in the past, either because
    this explicitly allows more complex norms or because it reveals more information
    about the background population on which to anchor decision-making.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验设置依赖于各种超参数，LLM代理可能对这些超参数敏感，也可能不敏感。特别重要的是捐赠乘数，它控制合作带来的收益大小，以及代理获得的“痕迹”长度，这些痕迹反映了其他人过去的行为，这些信息可以用来隐性地推导出声誉。我们对这两者进行了消融实验，相关数据见附加材料。1.5倍和3倍（而非2倍）的捐赠乘数不会改变定性结果：Claude
    3.5 Sonnet仍然显示出代际间合作的增加，Gemini 1.5 Flash几乎没有变化，而GPT-4o则显示出下降。当“痕迹”的长度缩短为$1$而非$3$时，Claude
    3.5的合作表现不那么明显，Gemini 1.5 Flash则完全消失。这表明，Claude和Gemini策略的成功依赖于获取关于接收者如何对待他人的二阶信息，要么是因为这显式地允许更复杂的规范，要么是因为它揭示了更多关于背景人群的信息，从而为决策提供了支撑。
- en: 5 Discussion
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: In this paper we have set out a method for assessing the cultural evolution
    of cooperation among LLM agents. We focus on the well-known Donor Game, a “Petri
    dish” in which to study the emergence of indirect reciprocity. Over the course
    of $10$ generations we find striking differences in the emergence of cooperation
    depending on the base model for the LLM agent. Claude 3.5 Sonnet reliably generates
    cooperative communities, especially when provided with an additional costly punishment
    mechanism. Meanwhile, generations of GPT-4o agents converge to mutual defection,
    while Gemini 1.5 Flash achieves only weak increases in cooperation. We analyse
    the cultural evolutionary dynamics, revealing that some populations have the ability
    to accumulate increasingly complex strategies at the individual level, and to
    generate norms that select for cooperators at the group level. Our results motivate
    building inexpensive benchmarks which test for long-term emergent behavior of
    multi-agent systems of LLM agents, towards safe and beneficial deployment of such
    systems at scale in the real-world.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了一种评估大语言模型（LLM）代理间合作文化演化的方法。我们聚焦于著名的捐赠者游戏，这是一个用来研究间接互惠（indirect reciprocity）出现的“培养皿”。在$10$代的过程中，我们发现合作的出现存在显著差异，这取决于LLM代理的基础模型。Claude
    3.5 Sonnet在提供额外的高成本惩罚机制时，能够稳定地生成合作社区。与此同时，GPT-4o代理的几代人趋向于相互背叛，而Gemini 1.5 Flash仅实现了微弱的合作增长。我们分析了文化演化动态，揭示了一些群体能够在个体层面积累越来越复杂的策略，并在群体层面生成选择合作伙伴的规范。我们的结果激励我们构建廉价的基准测试，检测LLM代理多体系统的长期涌现行为，以便在实际世界中安全且有益地部署此类系统。
- en: In establishing a new setting for empirical experimentation, we have necessarily
    adopted a narrow scope. Therefore, our work has several clear limitations. Most
    obviously, the strict boundaries between generations in our cultural evolutionary
    system are idealized and do not represent the full complexity of model release
    and adoption in the real world. Moreover, we only study homogeneous populations
    of LLM agents, all with the same base model; in actuality, heterogeneous populations
    of LLM agents are far more likely to occur. Our experiments are restricted to
    the Donor Game, and models may behave quite differently when faced with other
    social dilemmas, especially since individual games may well be over-represented
    in the training data for one model and under-represented in the training data
    for another. Relatedly, we have not performed an extensive search over prompting
    strategies, which may affect the cooperation behavior of different models in different
    ways. Notwithstanding these limitations, our experiments do serve to falsify the
    claim that LLMs are universally capable of evolving human-like cooperative behavior.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立新的实证实验设置时，我们不可避免地采用了一个狭窄的范围。因此，我们的工作有几个明显的局限性。最显著的是，在我们的文化演化系统中，代际之间的严格界限是理想化的，并不能代表现实世界中模型发布和采用的复杂性。此外，我们仅研究了同质化的LLM代理群体，所有代理都使用相同的基础模型；实际上，同质化LLM代理群体更可能发生异质化。我们的实验仅限于捐赠者游戏，而模型在面对其他社会困境时可能表现截然不同，特别是因为某些模型的训练数据中可能会过度代表个别游戏，而在另一些模型的训练数据中则可能被低估。与此相关的是，我们并未对提示策略进行广泛搜索，而不同的提示策略可能会以不同方式影响不同模型的合作行为。尽管存在这些局限性，我们的实验确实能够推翻“大语言模型（LLM）普遍能够演化出类似人类的合作行为”这一主张。
- en: The limitations we have identified immediately suggest interesting extensions
    for future work. Indeed, the space of cultural evolutionary studies of LLM agents
    is ripe for further study using our methods. What happens if communication is
    permitted between agents, either at the start of each generation (deliberation
    about strategies) or within rounds of the game (negotiation on donations)? What
    is the effect of changing the medium of reputation information about others, for
    instance by allowing recipients to write reviews of donors (“gossip”)? Do the
    results change if Donor Game interactions have a different network structure,
    such as admitting direct reciprocity or assorting individuals into subsets with
    frequent in-group and infrequent out-group pairings? What would happen if the
    mutation steps incorporated more sophisticated prompt optimization techniques
    like PromptBreeder (Fernando et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib15))
    or APE (Zhou et al., [2023](https://arxiv.org/html/2412.10270v1#bib.bib43))? By
    open-sourcing our code we hope to provide the community with a jump start on answering
    these fascinating and timely questions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所识别的局限性立刻暗示了未来工作中有趣的拓展方向。事实上，利用我们的方法，LLM代理的文化进化研究领域值得进一步探索。如果允许代理之间的交流，尤其是在每代开始时（策略讨论）或在游戏轮次中（捐赠协商），会发生什么？例如，如果允许接收者为捐赠者写评论（“闲聊”），改变他人声誉信息的传播媒介会有什么影响？如果捐赠者游戏的互动具有不同的网络结构（例如，允许直接互惠或将个体分成具有频繁内团体和不频繁外团体配对的子集），结果会有所变化吗？如果变异步骤引入了更复杂的提示优化技术，如PromptBreeder（Fernando等，
    [2023](https://arxiv.org/html/2412.10270v1#bib.bib15)）或APE（Zhou等， [2023](https://arxiv.org/html/2412.10270v1#bib.bib43)）会怎样？通过开源我们的代码，我们希望为社区提供解决这些引人入胜且及时的问题的跳板。
- en: 'Finally, it is vital to consider the societal impact of our work. We argue
    that this paper may beget considerable societal benefits, namely by the provision
    of a new evaluation regime for LLM agents which can detect the erosion of cooperation
    over the long term. Nevertheless, it is important to remember that cooperation
    is not always desirable. We would not want LLM agents representing different firms
    to collude in manipulating prices on the market economy, for instance. Therefore,
    we end by highlighting a crucial open question: how can we generate LLM agents
    which are capable of evolving cooperation when it is beneficial to human society,
    but which refuse to collude against the norms, laws or interests of humans? Our
    work provides a particular sharp and sandboxed setting in which to study this
    important issue.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，考虑我们工作的社会影响至关重要。我们认为，本文可能带来相当大的社会利益，具体来说，是通过提供一种新的评估体系，帮助LLM代理检测合作的长期侵蚀。然而，必须记住，并非所有合作都是可取的。举例来说，我们不希望不同公司的LLM代理联合操控市场价格。因此，我们在此提出一个关键的开放性问题：我们如何生成能够在对人类社会有益时进化合作的LLM代理，但又拒绝违反人类规范、法律或利益的勾结？我们的研究提供了一个特定且受限的环境，可以在其中研究这个重要问题。
- en: Acknowledgements
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We are grateful to Michael Muthukrishna and Max Posch for useful discussions,
    and to Joel Leibo for feedback on an early version of the manuscript. Aron Vallinder
    gratefully acknowledges the financial support of PIBBSS and Longview Philanthropy.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢Michael Muthukrishna和Max Posch的有益讨论，以及Joel Leibo对手稿早期版本的反馈。Aron Vallinder衷心感谢PIBBSS和Longview
    Philanthropy的财务支持。
- en: References
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Acerbi and Stubbersfield (2023) A. Acerbi and J. M. Stubbersfield. Large language
    models show human-like content biases in transmission chain experiments. *Proceedings
    of the National Academy of Sciences*, 120(44):e2313790120, Oct. 2023. [10.1073/pnas.2313790120](https:/doi.org/10.1073/pnas.2313790120).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Acerbi和Stubbersfield（2023）A. Acerbi和J. M. Stubbersfield. 大型语言模型在传播链实验中表现出类似人类的内容偏见。*美国国家科学院院刊*，120(44)：e2313790120，2023年10月。[10.1073/pnas.2313790120](https:/doi.org/10.1073/pnas.2313790120)。
- en: Aher et al. (2023) G. V. Aher, R. I. Arriaga, and A. T. Kalai. Using Large Language
    Models to Simulate Multiple Humans and Replicate Human Subject Studies. In *Proceedings
    of the 40th International Conference on Machine Learning*, pages 337–371\. PMLR,
    July 2023.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aher等人（2023）G. V. Aher, R. I. Arriaga, 和A. T. Kalai. 使用大型语言模型模拟多个个体并复制人类受试者研究。在*第40届国际机器学习大会论文集*中，页数337–371，PMLR，2023年7月。
- en: 'AISI (2024) AISI. Advanced AI evaluations at AISI: May update. https://www.aisi.gov.uk/work/advanced-ai-evaluations-may-update,
    2024.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AISI（2024）AISI。AISI的先进AI评估：5月更新。https://www.aisi.gov.uk/work/advanced-ai-evaluations-may-update，2024年。
- en: Akata et al. (2023) E. Akata, L. Schulz, J. Coda-Forno, S. J. Oh, M. Bethge,
    and E. Schulz. Playing repeated games with Large Language Models, May 2023.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akata等人（2023）E. Akata, L. Schulz, J. Coda-Forno, S. J. Oh, M. Bethge 和 E. Schulz。与大型语言模型玩重复博弈，2023年5月。
- en: Alexander (1987) R. D. Alexander. *The Biology of Moral Systems*. Aldine de
    Gruyter, New York, 1987. ISBN 978-0-202-01173-8.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alexander（1987）R. D. Alexander。*道德体系的生物学*。Aldine de Gruyter，纽约，1987年。ISBN 978-0-202-01173-8。
- en: Boyd and Richerson (1989) R. Boyd and P. J. Richerson. The evolution of indirect
    reciprocity. *Social Networks*, 11(3):213–236, Sept. 1989. ISSN 03788733. [10.1016/0378-8733(89)90003-8](https:/doi.org/10.1016/0378-8733(89)90003-8).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boyd和Richerson（1989）R. Boyd 和 P. J. Richerson。间接互惠的演化。*社会网络*，11(3)：213–236，1989年9月。ISSN
    03788733。[10.1016/0378-8733(89)90003-8](https:/doi.org/10.1016/0378-8733(89)90003-8)。
- en: Brinkmann et al. (2023) L. Brinkmann, F. Baumann, J.-F. Bonnefon, M. Derex,
    T. F. Müller, A.-M. Nussberger, A. Czaplicka, A. Acerbi, T. L. Griffiths, J. Henrich,
    et al. Machine culture. *Nature Human Behaviour*, 7(11):1855–1868, 2023.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brinkmann等人（2023）L. Brinkmann, F. Baumann, J.-F. Bonnefon, M. Derex, T. F. Müller,
    A.-M. Nussberger, A. Czaplicka, A. Acerbi, T. L. Griffiths, J. Henrich 等人。机器文化。*自然人类行为*，7(11)：1855–1868，2023年。
- en: 'Brookins and DeBacker (2024) P. Brookins and J. M. DeBacker. Playing Games
    With GPT: What Can We Learn About a Large Language Model From Canonical Strategic
    Games? *Economics Bulletin*, 44(1):25–37, 2024. ISSN 1556-5068. [10.2139/ssrn.4493398](https:/doi.org/10.2139/ssrn.4493398).'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brookins和DeBacker（2024）P. Brookins 和 J. M. DeBacker。与GPT玩游戏：我们能从经典战略博弈中学到什么关于大型语言模型的知识？
    *经济学公报*，44(1)：25–37，2024年。ISSN 1556-5068。[10.2139/ssrn.4493398](https:/doi.org/10.2139/ssrn.4493398)。
- en: Chen et al. (2023) Y. Chen, T. X. Liu, Y. Shan, and S. Zhong. The emergence
    of economic rationality of GPT. *Proceedings of the National Academy of Sciences*,
    120(51):e2316205120, Dec. 2023. [10.1073/pnas.2316205120](https:/doi.org/10.1073/pnas.2316205120).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen等人（2023）Y. Chen, T. X. Liu, Y. Shan, 和S. Zhong。GPT经济理性出现。*美国国家科学院院刊*，120(51)：e2316205120，2023年12月。[10.1073/pnas.2316205120](https:/doi.org/10.1073/pnas.2316205120)。
- en: 'Chiang et al. (2024) W.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos,
    T. Li, D. Li, H. Zhang, B. Zhu, M. Jordan, J. E. Gonzalez, and I. Stoica. Chatbot
    Arena: An Open Platform for Evaluating LLMs by Human Preference, Mar. 2024.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang等人（2024）W.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D.
    Li, H. Zhang, B. Zhu, M. Jordan, J. E. Gonzalez 和 I. Stoica。Chatbot Arena：一个通过人类偏好评估LLM的开放平台，2024年3月。
- en: Dafoe et al. (2020) A. Dafoe, E. Hughes, Y. Bachrach, T. Collins, K. R. McKee,
    J. Z. Leibo, K. Larson, and T. Graepel. Open Problems in Cooperative AI, Dec.
    2020.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dafoe等人（2020）A. Dafoe, E. Hughes, Y. Bachrach, T. Collins, K. R. McKee, J. Z.
    Leibo, K. Larson 和 T. Graepel。合作AI中的开放问题，2020年12月。
- en: 'Dai et al. (2024) G. Dai, W. Zhang, J. Li, S. Yang, S. Rao, A. Caetano, M. Sra,
    et al. Artificial leviathan: Exploring social evolution of llm agents through
    the lens of hobbesian social contract theory. *arXiv preprint arXiv:2406.14373*,
    2024.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai等人（2024）G. Dai, W. Zhang, J. Li, S. Yang, S. Rao, A. Caetano, M. Sra等人。人工巨兽：通过霍布斯社会契约理论视角探索大规模语言模型（LLM）代理的社会进化。*arXiv预印本arXiv:2406.14373*，2024年。
- en: Fehr and Gächter (2000) E. Fehr and S. Gächter. Cooperation and Punishment in
    Public Goods Experiments. *American Economic Review*, 90(4):980–994, Sept. 2000.
    ISSN 0002-8282. [10.1257/aer.90.4.980](https:/doi.org/10.1257/aer.90.4.980).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fehr和Gächter（2000）E. Fehr 和 S. Gächter。公共物品实验中的合作与惩罚。*美国经济评论*，90(4)：980–994，2000年9月。ISSN
    0002-8282。[10.1257/aer.90.4.980](https:/doi.org/10.1257/aer.90.4.980)。
- en: Fehr and Gächter (2002) E. Fehr and S. Gächter. Altruistic punishment in humans.
    *Nature*, 415(6868):137–140, Jan. 2002. ISSN 1476-4687. [10.1038/415137a](https:/doi.org/10.1038/415137a).
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fehr和Gächter（2002）E. Fehr 和 S. Gächter。人类的利他惩罚。*自然*，415(6868)：137–140，2002年1月。ISSN
    1476-4687。[10.1038/415137a](https:/doi.org/10.1038/415137a)。
- en: 'Fernando et al. (2023) C. Fernando, D. Banarse, H. Michalewski, S. Osindero,
    and T. Rocktäschel. Promptbreeder: Self-Referential Self-Improvement Via Prompt
    Evolution, Sept. 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernando等人（2023）C. Fernando, D. Banarse, H. Michalewski, S. Osindero 和 T. Rocktäschel。Promptbreeder：通过提示演化实现自我引用的自我改进，2023年9月。
- en: Gabriel et al. (2024) I. Gabriel, A. Manzini, G. Keeling, L. A. Hendricks, V. Rieser,
    H. Iqbal, N. Tomašev, I. Ktena, Z. Kenton, M. Rodriguez, et al. The ethics of
    advanced ai assistants. *arXiv preprint arXiv:2404.16244*, 2024.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gabriel等人（2024）I. Gabriel, A. Manzini, G. Keeling, L. A. Hendricks, V. Rieser,
    H. Iqbal, N. Tomašev, I. Ktena, Z. Kenton, M. Rodriguez等人。先进AI助手的伦理问题。*arXiv预印本arXiv:2404.16244*，2024年。
- en: Gandhi et al. (2023) K. Gandhi, D. Sadigh, and N. D. Goodman. Strategic Reasoning
    with Language Models, May 2023.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gandhi等人（2023）K. Gandhi, D. Sadigh 和 N. D. Goodman。与语言模型进行战略推理，2023年5月。
- en: Guo (2023) F. Guo. GPT in Game Theory Experiments, Dec. 2023.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo（2023）F. Guo。GPT在博弈论实验中的应用，2023年12月。
- en: 'Henrich (2016) J. Henrich. *The secret of our success: How culture is driving
    human evolution, domesticating our species, and making us smarter*. Princeton
    University press, 2016.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Henrich（2016）J. Henrich. *我们的成功秘诀：文化如何推动人类演化、驯化我们的物种，并使我们变得更聪明*。普林斯顿大学出版社，2016年。
- en: Henrich and Henrich (2006) J. Henrich and N. Henrich. Culture, evolution and
    the puzzle of human cooperation. *Cognitive Systems Research*, 7(2-3):220–245,
    June 2006. ISSN 13890417. [10.1016/j.cogsys.2005.11.010](https:/doi.org/10.1016/j.cogsys.2005.11.010).
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Henrich 和 Henrich（2006）J. Henrich 和 N. Henrich. 《文化、演化与人类合作之谜》。*认知系统研究*，7(2-3):220–245，2006年6月。ISSN
    13890417。 [10.1016/j.cogsys.2005.11.010](https:/doi.org/10.1016/j.cogsys.2005.11.010)。
- en: 'Horton (2023) J. J. Horton. Large Language Models as Simulated Economic Agents:
    What Can We Learn from Homo Silicus?, Jan. 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Horton（2023）J. J. Horton. 《作为模拟经济代理的大语言模型：我们能从 Homo Silicus 中学到什么？》，2023年1月。
- en: Leng and Yuan (2024) Y. Leng and Y. Yuan. Do LLM Agents Exhibit Social Behavior?,
    Feb. 2024.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leng 和 Yuan（2024）Y. Leng 和 Y. Yuan. 《大语言模型代理是否表现出社会行为？》，2024年2月。
- en: Lewontin (1970) R. C. Lewontin. The Units of Selection. *Annual Review of Ecology
    and Systematics*, 1:1–18, 1970. ISSN 0066-4162.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewontin（1970）R. C. Lewontin. 《选择的单元》。*生态学与系统学年评*，1:1–18，1970年。ISSN 0066-4162。
- en: METR (2024) METR. Example Task Suite. https://github.com/METR/public-tasks,
    Sept. 2024.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: METR（2024）METR. 《示例任务套件》。https://github.com/METR/public-tasks，2024年9月。
- en: 'Mohtashami et al. (2024) A. Mohtashami, F. Hartmann, S. Gooding, L. Zilka,
    M. Sharifi, and B. A. y Arcas. Social Learning: Towards Collaborative Learning
    with Large Language Models, Feb. 2024.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mohtashami 等人（2024）A. Mohtashami, F. Hartmann, S. Gooding, L. Zilka, M. Sharifi
    和 B. A. y Arcas. 《社会学习：朝着与大语言模型协作学习迈进》，2024年2月。
- en: Nisioti et al. (2024) E. Nisioti, S. Risi, I. Momennejad, P.-Y. Oudeyer, and
    C. Moulin-Frier. Collective Innovation in Groups of Large Language Models, July
    2024.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nisioti 等人（2024）E. Nisioti, S. Risi, I. Momennejad, P.-Y. Oudeyer 和 C. Moulin-Frier.
    《大语言模型群体中的集体创新》，2024年7月。
- en: Nowak and Sigmund (1998) M. A. Nowak and K. Sigmund. Evolution of indirect reciprocity
    by image scoring. *Nature*, 393(6685):573–577, June 1998. ISSN 0028-0836, 1476-4687.
    [10.1038/31225](https:/doi.org/10.1038/31225).
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nowak 和 Sigmund（1998）M. A. Nowak 和 K. Sigmund. 《通过形象评分的间接互惠演化》。*自然*，393(6685):573–577，1998年6月。ISSN
    0028-0836，1476-4687。 [10.1038/31225](https:/doi.org/10.1038/31225)。
- en: Ohtsuki and Iwasa (2004) H. Ohtsuki and Y. Iwasa. How should we define goodness?—reputation
    dynamics in indirect reciprocity. *Journal of Theoretical Biology*, 231(1):107–120,
    Nov. 2004. ISSN 00225193. [10.1016/j.jtbi.2004.06.005](https:/doi.org/10.1016/j.jtbi.2004.06.005).
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ohtsuki 和 Iwasa（2004）H. Ohtsuki 和 Y. Iwasa. 《我们应该如何定义“善良”？——间接互惠中的声誉动态》。*理论生物学杂志*，231(1):107–120，2004年11月。ISSN
    00225193。 [10.1016/j.jtbi.2004.06.005](https:/doi.org/10.1016/j.jtbi.2004.06.005)。
- en: Okada (2020) I. Okada. A Review of Theoretical Studies on Indirect Reciprocity.
    *Games*, 11(3):27, July 2020. ISSN 2073-4336. [10.3390/g11030027](https:/doi.org/10.3390/g11030027).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Okada（2020）I. Okada. 《间接互惠的理论研究综述》。*博弈*，11(3):27，2020年7月。ISSN 2073-4336。 [10.3390/g11030027](https:/doi.org/10.3390/g11030027)。
- en: OpenAI (2024) OpenAI. Learning to reason with llms. [https://openai.com/index/learning-to-reason-with-llms/](https://openai.com/index/learning-to-reason-with-llms/),
    2024. [Accessed 19-09-2024].
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2024）OpenAI. 《学习如何推理与大语言模型》，[https://openai.com/index/learning-to-reason-with-llms/](https://openai.com/index/learning-to-reason-with-llms/)，2024年。[访问日期：2024年9月19日]。
- en: 'Park et al. (2023) J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang,
    and M. S. Bernstein. Generative Agents: Interactive Simulacra of Human Behavior,
    Aug. 2023.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2023）J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang 和
    M. S. Bernstein. 《生成性代理：人类行为的互动模拟》，2023年8月。
- en: Perez et al. (2024) J. Perez, C. Léger, M. Ovando-Tellez, C. Foulon, J. Dussauld,
    P.-Y. Oudeyer, and C. Moulin-Frier. Cultural evolution in populations of Large
    Language Models, Mar. 2024.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perez 等人（2024）J. Perez, C. Léger, M. Ovando-Tellez, C. Foulon, J. Dussauld,
    P.-Y. Oudeyer 和 C. Moulin-Frier. 《大语言模型群体中的文化演化》，2024年3月。
- en: Phelps and Russell (2023) S. Phelps and Y. I. Russell. Investigating Emergent
    Goal-Like Behaviour in Large Language Models Using Experimental Economics, May
    2023.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phelps 和 Russell（2023）S. Phelps 和 Y. I. Russell. 《通过实验经济学研究大语言模型中涌现的目标行为》，2023年5月。
- en: 'Richerson and Boyd (2005) P. J. Richerson and R. Boyd. *Not by Genes Alone:
    How Culture Transformed Human Evolution*. University of Chicago Press, Chicago,
    2005. ISBN 978-0-226-71284-0.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Richerson 和 Boyd（2005）P. J. Richerson 和 R. Boyd. *不仅仅是基因：文化如何改变人类演化*。芝加哥大学出版社，芝加哥，2005年。ISBN
    978-0-226-71284-0。
- en: Rockenbach and Milinski (2006) B. Rockenbach and M. Milinski. The efficient
    interaction of indirect reciprocity and costly punishment. *Nature*, 444(7120):718–723,
    Dec. 2006. ISSN 1476-4687. [10.1038/nature05229](https:/doi.org/10.1038/nature05229).
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rockenbach 和 Milinski（2006年）B. Rockenbach 和 M. Milinski. 间接互惠与代价惩罚的有效互动。*自然*，444(7120):718–723,
    2006年12月。ISSN 1476-4687. [10.1038/nature05229](https:/doi.org/10.1038/nature05229).
- en: Sutton (2019) R. Sutton. The bitter lesson. *Incomplete Ideas (blog)*, 13(1):38,
    2019.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutton（2019年）R. Sutton. 苦涩的教训。*不完全的想法（博客）*，13(1):38, 2019年。
- en: Ule et al. (2009) A. Ule, A. Schram, A. Riedl, and T. N. Cason. Indirect Punishment
    and Generosity Toward Strangers. *Science*, 326(5960):1701–1704, Dec. 2009. [10.1126/science.1178883](https:/doi.org/10.1126/science.1178883).
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ule 等人（2009年）A. Ule, A. Schram, A. Riedl, 和 T. N. Cason. 间接惩罚与对陌生人的慷慨。*科学*，326(5960):1701–1704,
    2009年12月。 [10.1126/science.1178883](https:/doi.org/10.1126/science.1178883).
- en: Vezhnevets et al. (2023) A. S. Vezhnevets, J. P. Agapiou, A. Aharon, R. Ziv,
    J. Matyas, E. A. Duéñez-Guzmán, W. A. Cunningham, S. Osindero, D. Karmon, and
    J. Z. Leibo. Generative agent-based modeling with actions grounded in physical,
    social, or digital space using Concordia, Dec. 2023.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vezhnevets 等人（2023年）A. S. Vezhnevets, J. P. Agapiou, A. Aharon, R. Ziv, J. Matyas,
    E. A. Duéñez-Guzmán, W. A. Cunningham, S. Osindero, D. Karmon, 和 J. Z. Leibo.
    基于生成体的建模，使用Concordia进行基于物理、社交或数字空间的行动建模, 2023年12月。
- en: Wedekind and Milinski (2000) C. Wedekind and M. Milinski. Cooperation Through
    Image Scoring in Humans. *Science*, 288(5467):850–852, May 2000. [10.1126/science.288.5467.850](https:/doi.org/10.1126/science.288.5467.850).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wedekind 和 Milinski（2000年）C. Wedekind 和 M. Milinski. 通过图像评分促进人类合作。*科学*，288(5467):850–852,
    2000年5月。 [10.1126/science.288.5467.850](https:/doi.org/10.1126/science.288.5467.850).
- en: Wei et al. (2022) J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi,
    Q. V. Le, D. Zhou, et al. Chain-of-thought prompting elicits reasoning in large
    language models. *Advances in neural information processing systems*, 35:24824–24837,
    2022.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人（2022年）J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V.
    Le, D. Zhou 等人. 思维链提示激发大型语言模型中的推理。*神经信息处理系统进展*，35:24824–24837, 2022年。
- en: 'Xu et al. (2023) Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, and Y. Liu.
    Exploring Large Language Models for Communication Games: An Empirical Study on
    Werewolf, Sept. 2023.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2023年）Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, 和 Y. Liu. 探索大型语言模型在沟通游戏中的应用：关于狼人杀的实证研究,
    2023年9月。
- en: 'Zhao et al. (2024) Q. Zhao, J. Wang, Y. Zhang, Y. Jin, K. Zhu, H. Chen, and
    X. Xie. CompeteAI: Understanding the Competition Dynamics in Large Language Model-based
    Agents, June 2024.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等人（2024年）Q. Zhao, J. Wang, Y. Zhang, Y. Jin, K. Zhu, H. Chen, 和 X. Xie.
    CompeteAI：理解基于大型语言模型的代理中的竞争动态, 2024年6月。
- en: Zhou et al. (2023) Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan,
    and J. Ba. Large Language Models Are Human-Level Prompt Engineers, Mar. 2023.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人（2023年）Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan,
    和 J. Ba. 大型语言模型是人类级提示工程师, 2023年3月。
- en: Supplementary Material
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 补充材料
- en: '![Refer to caption](img/3a7286f2241a6cdc131a354d1bca3b3a.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/3a7286f2241a6cdc131a354d1bca3b3a.png)'
- en: (a) Claude 3.5 Sonnet
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: '![Refer to caption](img/2e0de09fcd13bde064e9ef3963274ae4.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/2e0de09fcd13bde064e9ef3963274ae4.png)'
- en: (b) Gemini 1.5 Flash
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: '![Refer to caption](img/c0cb87f26b8b5c81196a84ed6ff846ae.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/c0cb87f26b8b5c81196a84ed6ff846ae.png)'
- en: (c) GPT-4o
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 7: Donation multiplier of 1.5x.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：1.5倍捐赠乘数。
- en: '![Refer to caption](img/d141aa89dacc6c2c780992990f960375.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/d141aa89dacc6c2c780992990f960375.png)'
- en: (a) Claude 3.5 Sonnet
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: '![Refer to caption](img/9880ec22422d35229f4698d8fd9b689d.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/9880ec22422d35229f4698d8fd9b689d.png)'
- en: (b) Gemini 1.5 Flash
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: '![Refer to caption](img/aae487c266219d9c3d348a704d2c6e5d.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/aae487c266219d9c3d348a704d2c6e5d.png)'
- en: (c) GPT-4o
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 8: Donation multiplier of 3x.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：3倍捐赠乘数。
- en: '![Refer to caption](img/bd2027a9fe184235deb7913602d1176c.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/bd2027a9fe184235deb7913602d1176c.png)'
- en: (a) Claude 3.5 Sonnet
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: '![Refer to caption](img/4c4f6d8dfd687dc4e4817299ae642705.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/4c4f6d8dfd687dc4e4817299ae642705.png)'
- en: (b) Gemini 1.5 Flash
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: '![Refer to caption](img/5a3e3650a02fcc1b7753d6d662829d5a.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/5a3e3650a02fcc1b7753d6d662829d5a.png)'
- en: (c) GPT-4o
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 9: Trace of length 1.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：长度为1的轨迹。
- en: '![Refer to caption](img/fcd36c6223fb85de97f73ad270accd40.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/fcd36c6223fb85de97f73ad270accd40.png)'
- en: (a) Claude 3.5 Sonnet
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Claude 3.5 Sonnet
- en: '![Refer to caption](img/189b78563bcd26b9cb001bc87b7854ea.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/189b78563bcd26b9cb001bc87b7854ea.png)'
- en: (b) Gemini 1.5 Flash
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Gemini 1.5 Flash
- en: '![Refer to caption](img/ea018878518090aa18cdb41f9136cbfb.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ea018878518090aa18cdb41f9136cbfb.png)'
- en: (c) GPT-4o
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: (c) GPT-4o
- en: 'Figure 10: Trace of length 2.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：长度为2的轨迹。
- en: '![Refer to caption](img/26193316edfcb47d5d2186ef84bd2dc6.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/26193316edfcb47d5d2186ef84bd2dc6.png)'
- en: 'Figure 11: 10 additional Claude 3.5 runs, with the same settings as in Figure
    [4](https://arxiv.org/html/2412.10270v1#S4.F4 "Figure 4 ‣ 4.1 Donor Game ‣ 4 Results
    ‣ Cultural Evolution of Cooperation among LLM Agents").'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：10 次额外的 Claude 3.5 运行，设置与图 [4](https://arxiv.org/html/2412.10270v1#S4.F4
    "Figure 4 ‣ 4.1 Donor Game ‣ 4 Results ‣ Cultural Evolution of Cooperation among
    LLM Agents") 相同。
- en: 'Table 2: Further example strategies.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：更多示例策略。
- en: '| Gen | Claude 3.5 Sonnet | Gemini 1.5 Flash | GPT-4o |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Gen | Claude 3.5 Sonnet | Gemini 1.5 Flash | GPT-4o |'
- en: '| --- | --- | --- | --- |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | My strategy will be to start with a moderate donation of 40% in the first
    round, then in subsequent rounds, donate the average of the three pieces of information
    I receive about previous donations plus 10%, capped at 100% of my current resources,
    but never donating less than 10%. | My strategy will be to adjust my donation
    amount based on the recipient’s and their partner’s previous round donation, increasing
    if they were generous and decreasing if they were selfish, while maintaining a
    moderate donation level to encourage cooperation. | My strategy will be to donate
    a moderate percentage (e.g., 20%) to recipients with no history initially, and
    increase my donation up to 50% incrementally if the recipient and previous agents
    in their chain demonstrate consistent generosity, while decreasing my donation
    to a minimum if their past behavior shows low or selfish donation. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 我的策略是：在第一轮开始时捐赠 40% 的适中捐赠，随后在每一轮中，捐赠我收到的三条关于前次捐赠的信息的平均值加 10%，上限为我当前资源的
    100%，但永远不会捐赠少于 10%。 | 我的策略是：根据受赠者及其伙伴的前一轮捐赠调整捐赠额，如果他们慷慨则增加，如果自私则减少，同时保持适中的捐赠水平以鼓励合作。
    | 我的策略是：向最初没有历史记录的受赠者捐赠适中的百分比（例如，20%），如果受赠者及其链条中的前代理表现出持续的慷慨行为，则逐步将捐赠增加到最多 50%，如果他们的历史行为显示出低或自私的捐赠，则将捐赠减少到最低水平。
    |'
- en: '| 10 | My strategy will be: Start with a 55% donation in the first round, then
    in subsequent rounds, calculate a weighted average (90% A, 10% B) of recent donations,
    adjust this average up by 15% or down by 20% if A’s donation deviates by more
    than 10% from the weighted average, add a random adjustment of -3% to +3%, ensure
    the donation falls within a range of 20% to 80%, every 10 rounds adjust both minimum
    and maximum thresholds by 2% based on average recipient donations (increase if
    above 55%, decrease if below 35%), and add a 5% bonus to the calculated donation
    if the recipient has donated above 70% in their observed round. | My strategy
    will be to start with a moderate donation and dynamically adjust it based on the
    recipient’s most recent donation, while also considering the partner’s previous
    donation with a reduced weight, rewarding consistent generosity with increasing
    donations and punishing unfairness with decreasing donations, while incorporating
    a dynamic forgiveness factor for recipients who show a genuine shift towards fairness.
    | My strategy will be: Start with a 1% donation to maximize initial resource conservation,
    critically evaluate the recipient’s interaction chain for strong and increasing
    cooperation patterns, strategically increase donations up to a maximum of 20%
    when these patterns are evident, and prioritize maintaining a substantial resource
    reserve for late-game adaptation and strategic flexibility. |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 我的策略是：在第一轮开始时捐赠 55%，然后在后续轮次中，计算最近捐赠的加权平均值（90% A，10% B），如果 A 的捐赠偏离加权平均值超过
    10%，则调整该平均值，最多上调 15% 或下调 20%，再添加 -3% 到 +3% 的随机调整，确保捐赠在 20% 到 80% 之间，每 10 轮根据平均受赠者捐赠情况调整最小和最大阈值
    2%（如果超过 55%，则增加；如果低于 35%，则减少），如果受赠者在其观察轮中捐赠超过 70%，则为计算出的捐赠额添加 5% 的奖金。 | 我的策略是：先从适中的捐赠开始，然后根据受赠者最近的捐赠动态调整，同时考虑伙伴先前的捐赠，减少权重，奖励持续的慷慨行为并增加捐赠，对于不公平行为则减少捐赠，同时对表现出公平转变的受赠者加入动态宽容因素。
    | 我的策略是：从 1% 的捐赠开始，以最大化初期资源的节省，仔细评估受赠者的互动链条，观察是否存在强烈且逐渐增加的合作模式，当这些模式明显时，战略性地将捐赠增加到最多
    20%，并优先保留足够的资源储备，以便后期游戏的适应性和战略灵活性。 |'
- en: 'Table 3: Further example strategies.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：更多示例策略。
- en: '| Gen | Claude 3.5 Sonnet | Gemini 1.5 Flash | GPT-4o |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Gen | Claude 3.5 Sonnet | Gemini 1.5 Flash | GPT-4o |'
- en: '| --- | --- | --- | --- |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | My strategy will be to start with a moderate donation of 40% in the first
    round, then in subsequent rounds, donate the average percentage of what A, B,
    and C donated in their respective previous rounds, with a minimum of 10% and a
    maximum of 70% to avoid extreme vulnerability. | My strategy will be to start
    with a moderate donation and then adjust my donation based on the recipient’s
    most recent donation and the behavior of their previous partner. | My strategy
    will be: Start conservatively by donating a small percentage of my resources in
    the first round, then increase donations when past interactions indicate reciprocity
    and trustworthiness, but remain cautious to avoid overextending resources. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 我的策略是在第一轮开始时捐赠40%的中等金额，然后在随后的轮次中，根据A、B和C在各自的上一轮捐赠的平均百分比进行捐赠，最低为10%，最高为70%，以避免极端脆弱性。
    | 我的策略是从一个中等的捐赠开始，然后根据接收者最近的捐赠和其前一个伙伴的行为调整我的捐赠。 | 我的策略是：首先在第一轮保守地捐赠我的少量资源，然后当过去的互动表明有互惠和可信度时，增加捐赠，但保持谨慎，避免过度投入资源。
    |'
- en: '| 10 | My strategy will be: Start with a 60% donation in the first round, then
    in subsequent rounds, donate a weighted average of 85% of the recipient’s last
    donation and 15% of the average of the two preceding donations in the chain, plus
    an additional 8% if there’s an increasing trend or minus 8% if there’s a decreasing
    trend, with an extra 5% bonus if all three donations in the chain were above 60%,
    always keeping within 20-85% of my current resources, and dynamically adjusting
    by increasing all percentages by 1% every 3 rounds until round 15, then decreasing
    by 1% every 3 rounds thereafter, while also considering my total resources and
    donating an additional 2% if I have more than 150 units or 5% less if I have fewer
    than 50 units. | My strategy will be to dynamically adjust my donation based on
    a weighted average of the recipient’s most recent donation, their partner’s previous
    donation, and a dynamic trust threshold that considers the consistency of the
    recipient’s behavior over the available information chain, prioritizing the most
    recent information while strategically penalizing unfairness and rewarding cooperation.
    | My strategy will be: Start with a 6% donation with no prior information; increase
    to 25% if there is a consistent pattern of recent donations of 45% or more, 15%
    for chains averaging 35-44%, 8% for an average of 25-34%, and 0% for lower generosity,
    continuously adapting to foster cooperation while prioritizing resource retention.
    |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 我的策略是：第一轮捐赠60%，然后在随后的轮次中，捐赠接收者最后一次捐赠的85%加上前两轮捐赠平均值的15%，如果有上升趋势，则再增加8%，如果有下降趋势，则减少8%，如果三次捐赠都超过60%，则额外增加5%，始终保持在我当前资源的20-85%范围内，并且每3轮动态调整，增加所有百分比1%直到第15轮，然后每3轮减少1%，同时考虑我的总资源量，如果我有超过150个单位的资源，则再捐赠2%，如果我有少于50个单位的资源，则减少5%。
    | 我的策略是：根据接收者最近的捐赠、其伙伴的上一轮捐赠以及一个动态的信任阈值来动态调整我的捐赠，这个阈值考虑到接收者行为的一致性，优先考虑最新信息，同时战略性地惩罚不公平行为并奖励合作。
    | 我的策略是：在没有任何先前信息的情况下，从6%的捐赠开始；如果最近的捐赠模式持续在45%以上，则增加至25%，如果链条平均捐赠在35%-44%之间，则捐赠15%，如果平均在25%-34%之间，则捐赠8%，对于低于该水平的慷慨度，则捐赠0%，持续适应以促进合作，同时优先保持资源。
    |'
