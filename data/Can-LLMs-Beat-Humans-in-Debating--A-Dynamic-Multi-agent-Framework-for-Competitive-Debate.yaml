- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2025-01-11 12:19:53'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:19:53
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM能在辩论中击败人类吗？一种动态多代理框架用于竞争性辩论
- en: 来源：[https://arxiv.org/html/2408.04472/](https://arxiv.org/html/2408.04472/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2408.04472/](https://arxiv.org/html/2408.04472/)
- en: Yiqun Zhang¹, Xiaocui Yang¹, Shi Feng¹, Daling Wang¹, Yifei Zhang¹, Kaisong Song²
    Corresponding author.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 张一群¹，杨晓翠¹，石峰¹，王大岭¹，张一飞¹，宋凯松² 通讯作者。
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Competitive debate is a complex task of computational argumentation. Large Language
    Models (LLMs) suffer from hallucinations and lack competitiveness in this field.
    To address these challenges, we introduce Agent for Debate (Agent4Debate), a dynamic
    multi-agent framework based on LLMs designed to enhance their capabilities in
    competitive debate. Drawing inspiration from human behavior in debate preparation
    and execution, Agent4Debate employs a collaborative architecture where four specialized
    agents, involving Searcher, Analyzer, Writer, and Reviewer, dynamically interact
    and cooperate. These agents work throughout the debate process, covering multiple
    stages from initial research and argument formulation to rebuttal and summary.
    To comprehensively evaluate framework performance, we construct the Competitive
    Debate Arena, comprising 66 carefully selected Chinese debate motions. We recruit
    ten experienced human debaters and collect records of 200 debates involving Agent4Debate,
    baseline models, and humans. The evaluation employs the Debatrix automatic scoring
    system and professional human reviewers based on the established Debatrix-Elo
    and Human-Elo ranking. Experimental results indicate that the state-of-the-art
    Agent4Debate exhibits capabilities comparable to those of humans. Furthermore,
    ablation studies demonstrate the effectiveness of each component in the agent
    structure.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争性辩论是一个复杂的计算性论证任务。大型语言模型（LLMs）在这个领域存在幻觉问题，且缺乏竞争力。为了解决这些挑战，我们介绍了“辩论代理”（Agent
    for Debate，Agent4Debate），这是一种基于LLM的动态多代理框架，旨在提升其在竞争性辩论中的能力。Agent4Debate的设计灵感来源于人类在辩论准备和执行过程中的行为，采用协作架构，由四个专业代理组成，分别是搜索者（Searcher）、分析者（Analyzer）、写作者（Writer）和审阅者（Reviewer），这些代理在辩论过程中动态互动与合作。它们覆盖了从初步研究和论点制定到反驳和总结等多个阶段。在全面评估框架性能时，我们构建了“竞争性辩论场”，其中包含66个精心挑选的中文辩题。我们招募了10名经验丰富的辩手，并收集了200场包含Agent4Debate、基线模型和人类的辩论记录。评估采用Debatrix自动评分系统以及基于已建立的Debatrix-Elo和Human-Elo排名的专业人类评审。实验结果表明，最先进的Agent4Debate展现了与人类相当的能力。此外，消融研究展示了代理结构中各个组件的有效性。
- en: Code — https://github.com/ZhangYiqun018/agent-for-debate
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 — https://github.com/ZhangYiqun018/agent-for-debate
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Competitive debate, as a structured and competitive form of communication (Nichols
    [1936](https://arxiv.org/html/2408.04472v2#bib.bib21); Thueblood [1926](https://arxiv.org/html/2408.04472v2#bib.bib30)),
    plays a crucial role in fields such as education, law, and politics. It challenges
    the comprehensive ability of participants, including logical thinking, expression
    skills, rapid analysis, argument construction, and rebuttal techniques, ultimately
    aiming to persuade a third party. With the advancement of artificial intelligence
    technologies, computational argumentation has emerged, and it is dedicated to
    simulating and understanding human argumentation processes through computational
    methods (Atkinson et al. [2017](https://arxiv.org/html/2408.04472v2#bib.bib3);
    Eger, Daxenberger, and Gurevych [2017](https://arxiv.org/html/2408.04472v2#bib.bib10)).
    However, existing research is largely confined to specific tasks on particular
    datasets, such as argument mining (Lawrence and Reed [2019](https://arxiv.org/html/2408.04472v2#bib.bib16)),
    argument quality assessment (Wachsmuth et al. [2017a](https://arxiv.org/html/2408.04472v2#bib.bib35)),
    and argument generation (Li, Ji, and Han [2021](https://arxiv.org/html/2408.04472v2#bib.bib18)).
    While these methods excel at specific tasks, they struggle to handle the complexity
    of competitive debate characterized by its openness, intense competition, and
    the need for decision-making and comprehensive skills.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争性辩论作为一种结构化和竞争性的沟通形式（Nichols [1936](https://arxiv.org/html/2408.04472v2#bib.bib21);
    Thueblood [1926](https://arxiv.org/html/2408.04472v2#bib.bib30)），在教育、法律和政治等领域中发挥着至关重要的作用。它挑战参与者的综合能力，包括逻辑思维、表达技巧、快速分析、论证构建和反驳技巧，最终目标是说服第三方。随着人工智能技术的进步，计算论证学应运而生，致力于通过计算方法模拟和理解人类的论证过程（Atkinson
    et al. [2017](https://arxiv.org/html/2408.04472v2#bib.bib3); Eger, Daxenberger,
    and Gurevych [2017](https://arxiv.org/html/2408.04472v2#bib.bib10)）。然而，现有研究大多局限于特定任务和特定数据集，如论证挖掘（Lawrence
    and Reed [2019](https://arxiv.org/html/2408.04472v2#bib.bib16)）、论证质量评估（Wachsmuth
    et al. [2017a](https://arxiv.org/html/2408.04472v2#bib.bib35)）和论证生成（Li, Ji, and
    Han [2021](https://arxiv.org/html/2408.04472v2#bib.bib18)）。尽管这些方法在特定任务上表现优异，但它们在应对以开放性、激烈竞争和决策及综合能力需求为特征的竞争性辩论的复杂性时存在困难。
- en: In recent years, Large Language Models (LLMs) (OpenAI [2023](https://arxiv.org/html/2408.04472v2#bib.bib22);
    Touvron et al. [2023b](https://arxiv.org/html/2408.04472v2#bib.bib32)) have demonstrated
    remarkable capabilities in various natural language processing tasks, offering
    new possibilities for constructing high-performance debate systems. Competitive
    debate, characterized by multi-turn document-level text generation with inter-turn
    logical dependencies, presents a unique challenge for LLMs, particularly in two
    significant areas. First, LLMs often face hallucination problems (Ji et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib14)),
    where models may generate plausible information that is inaccurate or fabricated.
    Second, due to limitations in safety alignment during training (Ouyang et al.
    [2022](https://arxiv.org/html/2408.04472v2#bib.bib23)) and constraints in handling
    long contexts (Liu et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib20)),
    models often need to improve in adversarial and sustained debate scenarios (shown
    in Figure [1](https://arxiv.org/html/2408.04472v2#Sx1.F1 "Figure 1 ‣ Introduction
    ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate")), struggling to maintain competitiveness and argumentative consistency.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大语言模型（LLMs）（OpenAI [2023](https://arxiv.org/html/2408.04472v2#bib.bib22);
    Touvron et al. [2023b](https://arxiv.org/html/2408.04472v2#bib.bib32)）在多种自然语言处理任务中展现出了卓越的能力，为构建高性能辩论系统提供了新的可能性。竞争性辩论的特点是多轮次的文档级文本生成，且各轮次之间存在逻辑依赖，这给LLMs带来了独特的挑战，特别是在两个重要领域。首先，LLMs常常面临幻觉问题（Ji
    et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib14)），即模型可能生成看似合理但不准确或虚构的信息。其次，由于训练过程中的安全对齐限制（Ouyang
    et al. [2022](https://arxiv.org/html/2408.04472v2#bib.bib23)）和处理长上下文的局限性（Liu et
    al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib20)），模型在对抗性和持续性辩论场景中往往表现不佳（如图[1](https://arxiv.org/html/2408.04472v2#Sx1.F1
    "图 1 ‣ 引言 ‣ 大语言模型能否击败人类进行辩论？一个动态的多代理框架")所示），难以维持竞争力和论证一致性。
- en: '![Refer to caption](img/43497dc20ba71e19777ac0afe3474e5b.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/43497dc20ba71e19777ac0afe3474e5b.png)'
- en: 'Figure 1: Before and After: Agent4Debate’s impact on LLMs competitive debating
    skills.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：前后对比：Agent4Debate 对大语言模型（LLMs）竞争性辩论技能的影响。
- en: To address these challenges, we propose a multi-agent framework based on LLMs,
    Agent for Debate (Agent4Debate). Agent4Debate features a dynamic, multi-agent
    collaborative architecture, leveraging the cooperation of multiple specialized
    LLMs to enable the framework to participate in multi-stage competitive debates.
    Inspired by human debate preparation processes, our framework incorporates four
    key agents, including Searcher, Analyzer, Writer, and Reviewer. To comprehensively
    evaluate the competitive debate capabilities of Agent4Debate, we establish the
    Competitive Debate Arena, employing an Elo ranking system widely used in competitive
    sports, ensuring fairness and scalability. This arena comprises 66 carefully selected
    Chinese debate motions, covering three categories (Abell [2018](https://arxiv.org/html/2408.04472v2#bib.bib1)),
    such as Policy, Value, and Fact, thoroughly testing the performance of participants
    across different types of debates. Participants include Agent4Debate with different
    foundation models, two baselines, and ten experienced human debaters. All participants
    engage in pairwise matches, with each debate assessed through two independent
    evaluation methods, including an automatic debate judging system based on the
    Debatrix (Liang et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib19))
    metrics, and an expert judging system consisting of three professional human reviewers.
    Based on these two sets of independent evaluation results, we construct two separate
    Elo (Elo [1967](https://arxiv.org/html/2408.04472v2#bib.bib11); Zheng et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib44))
    ranking lists, providing a multi-faceted quantitative assessment of participants’
    performance across various debate motions. The experimental results from the arena
    demonstrate that Agent4Debate can achieve human-level performance in various types
    of competitive debates.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，我们提出了基于LLMs的多智能体框架——Agent for Debate（Agent4Debate）。Agent4Debate具有动态的多智能体协作架构，通过多个专业化LLMs的合作，使框架能够参与多阶段的竞争性辩论。受到人类辩论准备过程的启发，我们的框架包含四个关键智能体，包括信息收集者（Searcher）、战略评估者（Analyzer）、论证构建者（Writer）和批评评估者（Reviewer）。为了全面评估Agent4Debate的竞争性辩论能力，我们建立了竞争性辩论竞技场，采用了广泛应用于竞技体育中的Elo排名系统，确保了公正性和可扩展性。该竞技场包含66个精心挑选的中文辩论议题，涵盖政策、价值和事实三大类别（Abell
    [2018](https://arxiv.org/html/2408.04472v2#bib.bib1)），全面测试参与者在不同类型辩论中的表现。参与者包括采用不同基础模型的Agent4Debate、两个基准系统以及十位经验丰富的人工辩手。所有参与者将进行一对一的比赛，每场辩论都通过两种独立的评估方法进行评分，包括基于Debatrix（Liang
    et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib19)）指标的自动辩论评分系统，以及由三位专业人工评审组成的专家评分系统。基于这两组独立的评估结果，我们构建了两个单独的Elo（Elo
    [1967](https://arxiv.org/html/2408.04472v2#bib.bib11); Zheng et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib44)）排名列表，提供了对参与者在各种辩论议题中的表现的多维度定量评估。来自竞技场的实验结果表明，Agent4Debate能够在各种类型的竞争性辩论中达到人类水平的表现。
- en: 'In conclusion, the main contributions of this work are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本研究的主要贡献如下：
- en: •
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose the Agent4Debate, which enhances the performance of LLMs in competitive
    debates through dynamic multi-agent collaboration. This framework mimics human
    debate team interactions, with agents adapting roles and strategies. Specifically,
    it employs the Searcher for information gathering, the Analyzer for strategic
    assessment, the Writer for argument formulation, and the Reviewer for critical
    evaluation.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了Agent4Debate，旨在通过动态的多智能体协作提升大型语言模型（LLMs）在竞争性辩论中的表现。该框架模拟了人类辩论团队的互动，智能体根据角色和策略进行适应。具体而言，它采用了信息收集者（Searcher）、战略评估者（Analyzer）、论证构建者（Writer）和批评评估者（Reviewer）四个智能体。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We construct the Competitive Debate Arena, a public resource comprising 66 Chinese
    debate motions and 200 debate matches across Policy, Value, and Fact categories.
    Human debaters are incorporated, and we establish Debatrix-Elo and Human-Elo rankings
    using Debatrix metrics and professional human judges, respectively.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们构建了竞争性辩论竞技场，这是一个公共资源，包含66个中文辩论议题和200场跨政策、价值和事实类别的辩论比赛。我们将人类辩手纳入其中，并通过Debatrix指标和专业人类评委分别建立了Debatrix-Elo和Human-Elo排名。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Our experimental results indicate that Agent4Debate’s performance in competitive
    debates is comparable to that of humans. Ablation studies validate the effectiveness
    of each component.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们的实验结果表明，Agent4Debate在竞争性辩论中的表现与人类相当。消融研究验证了各个组件的有效性。
- en: Related Work
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作
- en: Computational Argumentation
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算论证
- en: Argumentation research has deep historical roots (Walton, Reed, and Macagno
    [2008](https://arxiv.org/html/2408.04472v2#bib.bib37)), with its core objective
    being to achieve persuasion through logical reasoning and promote consensus among
    parties. In recent years, computational argumentation has emerged as an increasingly
    important field in natural language processing, with its main research directions
    encompassing argument mining (Lawrence and Reed [2019](https://arxiv.org/html/2408.04472v2#bib.bib16);
    Chen et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib8)), argument generation
    (Hua, Hu, and Wang [2019](https://arxiv.org/html/2408.04472v2#bib.bib12)), argument
    persuasiveness (Carlile et al. [2018](https://arxiv.org/html/2408.04472v2#bib.bib6)),
    and argument quality assessment (Wachsmuth et al. [2017b](https://arxiv.org/html/2408.04472v2#bib.bib36);
    Liang et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib19); Wachsmuth
    et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib34)). Project Debater
    (Slonim et al. [2021](https://arxiv.org/html/2408.04472v2#bib.bib29)), a debate
    system that integrates multiple modules, relies on retrieval-based methods rather
    than generative approaches for its argumentation. With the rise of Large Language
    Models research utilizing adversarial methods such as debate to enhance model
    capabilities (Du et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib9);
    Chang [2024](https://arxiv.org/html/2408.04472v2#bib.bib7)) has gradually attracted
    academic attention. Against this backdrop, our study focuses on competitive debate,
    a complex computational argumentation task that integrates multiple sub-tasks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 论证研究具有深厚的历史根基（Walton, Reed, 和 Macagno [2008](https://arxiv.org/html/2408.04472v2#bib.bib37)），其核心目标是通过逻辑推理实现说服，并促进各方之间的共识。近年来，计算论证作为自然语言处理领域一个日益重要的方向崭露头角，其主要研究方向包括论证挖掘（Lawrence
    和 Reed [2019](https://arxiv.org/html/2408.04472v2#bib.bib16)；Chen 等 [2024](https://arxiv.org/html/2408.04472v2#bib.bib8)）、论证生成（Hua,
    Hu, 和 Wang [2019](https://arxiv.org/html/2408.04472v2#bib.bib12)）、论证说服力（Carlile
    等 [2018](https://arxiv.org/html/2408.04472v2#bib.bib6)）以及论证质量评估（Wachsmuth 等 [2017b](https://arxiv.org/html/2408.04472v2#bib.bib36)；Liang
    等 [2024](https://arxiv.org/html/2408.04472v2#bib.bib19)；Wachsmuth 等 [2024](https://arxiv.org/html/2408.04472v2#bib.bib34)）。Project
    Debater（Slonim 等 [2021](https://arxiv.org/html/2408.04472v2#bib.bib29)），一个集成多个模块的辩论系统，依赖于基于检索的方法，而非生成方法进行论证。随着利用对抗性方法（如辩论）增强模型能力的大型语言模型研究的兴起（Du
    等 [2023](https://arxiv.org/html/2408.04472v2#bib.bib9)；Chang [2024](https://arxiv.org/html/2408.04472v2#bib.bib7)），逐渐吸引了学术界的关注。在此背景下，我们的研究聚焦于竞争性辩论，这是一个复杂的计算论证任务，集成了多个子任务。
- en: LLM-based Agents
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于LLM的代理
- en: LLMs, such as ChatGPT (OpenAI [2023](https://arxiv.org/html/2408.04472v2#bib.bib22)),
    LLaMA (Touvron et al. [2023b](https://arxiv.org/html/2408.04472v2#bib.bib32),
    [a](https://arxiv.org/html/2408.04472v2#bib.bib31)), demonstrate powerful capabilities
    in instruction following and reasoning tasks. Harnessing these advanced capabilities,
    researchers have developed LLM-based agents, which mark a significant step forward
    in the field. These agents leverage the language understanding and generation
    abilities of models for more sophisticated tasks like multi-step reasoning and
    interactive problem-solving, as shown in recent studies (Wang et al. [2023b](https://arxiv.org/html/2408.04472v2#bib.bib39);
    Li et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib17)). They have various
    uses across different domains, such as software engineering (Qian et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib25))
    and scientific inquiry (Boiko, MacKnight, and Gomes [2023](https://arxiv.org/html/2408.04472v2#bib.bib5)),
    highlighting their versatility. These agents can imitate complex human actions,
    partake in social interactions (Park et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib24);
    Tu et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib33)), and replicate
    intricate scenarios like elections (Argyle et al. [2022](https://arxiv.org/html/2408.04472v2#bib.bib2)),
    debates (Wang et al. [2023a](https://arxiv.org/html/2408.04472v2#bib.bib38); Du
    et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib9)), and consumer patterns
    (Wang et al. [2023c](https://arxiv.org/html/2408.04472v2#bib.bib40)), illustrating
    their capacity to emulate human social dynamics. While these agents demonstrate
    impressive capabilities in emulating human social dynamics, current research predominantly
    explores collaborative scenarios. However, competitive settings, though equally
    crucial in human interactions, remain comparatively underexplored.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs），例如ChatGPT（OpenAI [2023](https://arxiv.org/html/2408.04472v2#bib.bib22)）、LLaMA（Touvron
    et al. [2023b](https://arxiv.org/html/2408.04472v2#bib.bib32)，[a](https://arxiv.org/html/2408.04472v2#bib.bib31)），在任务执行和推理任务中展现出了强大的能力。利用这些先进能力，研究人员开发了基于LLM的智能体，标志着该领域的一个重要进展。这些智能体利用模型的语言理解和生成能力，执行更加复杂的任务，如多步推理和交互式问题解决，正如近期的研究所展示的（Wang
    et al. [2023b](https://arxiv.org/html/2408.04472v2#bib.bib39)；Li et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib17)）。它们在多个领域中都有广泛的应用，如软件工程（Qian
    et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib25)）和科学研究（Boiko, MacKnight,
    和 Gomes [2023](https://arxiv.org/html/2408.04472v2#bib.bib5)），突出展示了它们的多功能性。这些智能体能够模仿复杂的人类行为，参与社会互动（Park
    et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib24)；Tu et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib33)），并重现复杂的场景，如选举（Argyle
    et al. [2022](https://arxiv.org/html/2408.04472v2#bib.bib2)）、辩论（Wang et al. [2023a](https://arxiv.org/html/2408.04472v2#bib.bib38)；Du
    et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib9)）和消费模式（Wang et al.
    [2023c](https://arxiv.org/html/2408.04472v2#bib.bib40)），这展示了它们模拟人类社会动态的能力。尽管这些智能体在模仿人类社会动态方面表现出令人印象深刻的能力，目前的研究主要集中在协作场景。然而，竞争性场景，尽管在人类互动中同样至关重要，却相对较少被探索。
- en: Task Definition
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务定义
- en: 'Competitive debate is a structured multi-turn interactive task. Each turn of
    statement can be regarded as a document-level text generation task, with a temporal
    and logical progression relationship between multiple turns. A typical debate
    has two opposing sides: the Pro side and the Con side. We represent the competitive
    debate as a sequence:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争性辩论是一个结构化的多轮交互任务。每一轮陈述可以视为一个文档级文本生成任务，且不同轮次之间存在时间和逻辑的进展关系。典型的辩论有两个对立方：支持方（Pro）和反对方（Con）。我们将竞争性辩论表示为一个序列：
- en: '|  | $D=\{(s_{1},r_{1}),(s_{2},r_{2}),\cdots,(s_{n},r_{n})\}$ |  | (1) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  | $D=\{(s_{1},r_{1}),(s_{2},r_{2}),\cdots,(s_{n},r_{n})\}$ |  | (1) |'
- en: 'where $(s_{i},r_{i})$ denotes the $i$-th statement and its corresponding role,
    $s_{i}$ is the statement, and $r_{i}\in\{\textit{Pro},\textit{Con}\}$ represents
    the role of speaker. Each statement can be defined as:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$(s_{i},r_{i})$表示第$i$条陈述及其对应的角色，$s_{i}$是陈述，$r_{i} \in \{\textit{Pro}, \textit{Con}\}$表示发言者的角色。每个陈述可以定义为：
- en: '|  | $s_{i}=\mathcal{G}(m,r_{i},D_{i-1})$ |  | (2) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $s_{i}=\mathcal{G}(m,r_{i},D_{i-1})$ |  | (2) |'
- en: where $m$ is the motion of debate, $D_{i-1}$ represents the history of the first
    $i-1$ statements, and $\mathcal{G}(\cdot)$ is the generation function that produces
    each statement.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$m$是辩论的议题，$D_{i-1}$表示前$i-1$条陈述的历史，$\mathcal{G}(\cdot)$是生成函数，用于生成每条陈述。
- en: 'Typical competitive debate structure usually comprises three distinct stages,
    namely constructive arguments, rebuttals, and summary statements. To ensure fairness
    and simulate actual competitive debate conditions (Whitman [2005](https://arxiv.org/html/2408.04472v2#bib.bib41)),
    we establish specific rules for each stage:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的竞争性辩论结构通常包括三个不同的阶段，即建构性论点、反驳和总结陈述。为了确保公平并模拟实际的竞争性辩论环境（Whitman [2005](https://arxiv.org/html/2408.04472v2#bib.bib41)），我们为每个阶段设定了具体规则：
- en: '![Refer to caption](img/d23698c30494fff47ec908f96eae1780.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/d23698c30494fff47ec908f96eae1780.png)'
- en: 'Figure 2: Agent for Debate (Agent4Debate) Workflow: A dynamic framework simulating
    human debate team collaboration. From searching to reviewing, it showcases how
    four key roles (Searcher, Analyzer, Writer, Reviewer) interact and work iteratively.
    The right side illustrates the cyclical process from information gathering to
    argument formation using Stage 1 as an example, highlighting the framework’s multi-steps
    progression and recursive refinement.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：辩论智能体（Agent4Debate）工作流程：一个动态框架，模拟人类辩论团队的协作。从搜索到回顾，它展示了四个关键角色（搜索者、分析者、写作者、审阅者）如何互动并进行迭代工作。右侧展示了从信息收集到论点形成的循环过程，以阶段1为例，突出了框架的多步骤进程和递归完善。
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 1 (Constructive Arguments), both sides work independently, with the
    Con side unable to view the Pro’s constructive argument, ensuring initial viewpoints
    are uninfluenced.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在阶段1（建构性论点）中，双方独立工作，反对方无法看到支持方的建构性论点，确保初步观点不受影响。
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Stages 2 and 3 (Rebuttal and Summary) employ a progressive disclosure mechanism,
    where participants access all previous content to construct targeted statements.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段2和阶段3（反驳和总结）采用渐进式披露机制，参与者可以访问所有之前的内容，以构建有针对性的陈述。
- en: •
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We alternate the sequence across stages to balance the advantages of speaking
    order. The Pro side speaks first in Stage 2, while the Con side leads in Stage
    3.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在各个阶段之间交替顺序，以平衡发言顺序的优势。在阶段2中，支持方先发言，而反对方在阶段3中先发言。
- en: Agent for Debate
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 辩论智能体
- en: To address the challenges of hallucination and the difficulties in maintaining
    competitiveness and argumentative consistency in sustained debate scenarios, we
    propose the Agent for Debate (Agent4Debate) framework to enable LLMs to participate
    in competitive debates, as shown in Figure [2](https://arxiv.org/html/2408.04472v2#Sx3.F2
    "Figure 2 ‣ Task Definition ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate"). This framework dynamically simulates human
    debate preparation through dialogue-based collaboration (Wu et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib42))
    among four LLM-based agents, each mirroring key roles in a human debate team.
    The Searcher acts as a research assistant, gathering relevant information, while
    the Analyzer functions like an executive coach, strategizing and analyzing arguments.
    The Writer performs as a debater, crafting and articulating arguments, and the
    Reviewer serves as a debate coach, providing feedback and quality control. These
    agents interact flexibly throughout the debate process, adapting their roles and
    contributions based on the current stage and needs, much like a well-coordinated
    human debate team.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决幻觉问题以及在持续的辩论场景中保持竞争性和论证一致性所面临的挑战，我们提出了辩论智能体（Agent4Debate）框架，使得LLM能够参与竞争性辩论，如图[2](https://arxiv.org/html/2408.04472v2#Sx3.F2
    "Figure 2 ‣ Task Definition ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate")所示。该框架通过基于对话的协作动态模拟人类辩论准备（Wu et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib42)），其中四个基于LLM的智能体分别扮演人类辩论团队中的关键角色。搜索者作为研究助手，收集相关信息；分析者充当执行教练，制定策略并分析论点；写作者充当辩手，构建并阐述论点；审阅者则作为辩论教练，提供反馈并进行质量控制。这些智能体在整个辩论过程中灵活互动，根据当前阶段和需求调整各自的角色和贡献，类似于一个协调良好的人类辩论团队。
- en: The collaboration in Agent4Debate is not just a simple sequence of steps, but
    rather a dynamic interaction between multiple agents, based on the debate stage
    and context. All the agents are equipped with customized prompts for different
    debate stages, enabling them to better adapt to and execute the specific tasks
    of the current stage. In the following sections, we introduce the functions of
    each agent in detail.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Agent4Debate中的协作不仅仅是一个简单的步骤顺序，而是基于辩论阶段和背景的多个智能体之间的动态互动。所有的智能体都配备了针对不同辩论阶段的定制化提示，帮助它们更好地适应并执行当前阶段的具体任务。在接下来的章节中，我们将详细介绍每个智能体的功能。
- en: Searcher Agent
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索者智能体
- en: The Searcher is a tool agent in the Agent4Debate framework, designed to effectively
    mitigate hallucination issues and address information timeliness problems that
    LLMs may encounter during debates. It achieves this by accessing and organizing
    information from external knowledge bases. The workflow of Searcher primarily
    involves decomposing search questions into more refined queries, then utilizing
    external tools (such as search engines or specialized knowledge bases) to retrieve
    relevant information, and finally systematically compiling and organizing the
    obtained answers. The information compiled by the Searcher forms a motion knowledge
    base, which is fixed and accessible to all agents for reference throughout the
    entire debate process. This approach ensures consistency and reliability of the
    information used in the debate. Note that, the Searcher plays different roles
    at various stages of the debate. In Stage 1, the Searcher uses the motion as the
    search question for information gathering. However, in Stage 2 and Stage 3, the
    Searcher switches to a passive mode, waiting for specific instructions from the
    Writer before conducting targeted searches.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索器（Searcher）是Agent4Debate框架中的一个工具代理，旨在有效地缓解幻觉问题，并解决大型语言模型（LLM）在辩论过程中可能遇到的信息时效性问题。它通过访问和组织外部知识库中的信息来实现这一目标。搜索器的工作流程主要包括将搜索问题分解为更精细的查询，然后利用外部工具（如搜索引擎或专门的知识库）来检索相关信息，最后系统地汇编和整理获得的答案。搜索器编制的信息形成了一个固定的、供所有代理在整个辩论过程中参考的议题知识库。这种方法确保了辩论中使用信息的一致性和可靠性。需要注意的是，搜索器在辩论的不同阶段扮演不同的角色。在第一阶段，搜索器将议题作为搜索问题进行信息收集。然而，在第二阶段和第三阶段，搜索器切换到被动模式，等待来自写作代理的具体指令后再进行有针对性的搜索。
- en: Analyzer Agent
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析器代理（Analyzer Agent）
- en: 'The Analyzer is a core agent in the Agent4Debate framework, integrating real-time
    information from the debate and providing structured guidance for subsequent content
    output. Its primary function is to systematically analyze and plan the debate
    content based on the given motion, current stage, and historical context, thus
    bridging different phases of the debate. The workflow of Analyzer primarily involves
    breaking down the debate content step-by-step, drafting detailed outlines, and
    providing targeted strategic advice to other agents. This approach ensures coherence
    in debate reasoning and comprehensiveness in argumentation. Notably, the Analyzer
    plays different roles at various stages:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 分析器是Agent4Debate框架中的核心代理，集成了辩论中的实时信息，并为后续内容输出提供结构化的指导。它的主要功能是根据给定的议题、当前阶段和历史背景，系统地分析和规划辩论内容，从而连接辩论的不同阶段。分析器的工作流程主要包括逐步拆解辩论内容，起草详细的提纲，并为其他代理提供有针对性的战略建议。这种方法确保了辩论推理的连贯性和论证的全面性。值得注意的是，分析器在不同阶段扮演不同的角色：
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 1, the Analyzer receives the debate topic and compiled materials from
    the Searcher. It then summarizes the motion and formulates definitions, judgment
    criteria, main arguments, and supporting evidence from its own perspective.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第一阶段，分析器从搜索器接收辩论主题和整理的材料。接着，它会总结议题，并从自身角度形成定义、判断标准、主要论点和支持证据。
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 2, the Analyzer analyzes all content from previous phases, summarizing
    the differences in viewpoints between both sides, such as the opponent’s definitions
    and judgment criteria. It then suggests rebuttal techniques that can be used to
    address these differences.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第二阶段，分析器分析前阶段的所有内容，总结双方观点的差异，例如对方的定义和判断标准。然后，它会建议可以用来应对这些差异的反驳技巧。
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 3, in addition to continuing to summarize points of disagreement and
    provide rebuttal techniques, the Analyzer also offers suggestions from a value-based
    perspective, further enhancing the depth and persuasiveness of the debate.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第三阶段，除了继续总结分歧点并提供反驳技巧外，分析器还会从价值观角度提出建议，进一步增强辩论的深度和说服力。
- en: Writer Agent
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 写作代理（Writer Agent）
- en: 'The Writer is the executive agent in the Agent4Debate framework, responsible
    for transforming analysis and planning into actual debate content. Its primary
    function is to compose complete debate drafts based on the instructions and outlines
    provided by the Analyzer and to revise these drafts according to feedback from
    the Reviewer, ensuring the quality and persuasiveness of the debate. Workflow
    of the Writer primarily encompasses the following aspects:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 撰写者是Agent4Debate框架中的执行代理，负责将分析和规划转化为实际的辩论内容。其主要职能是根据分析员提供的指令和大纲撰写完整的辩论草稿，并根据评审员的反馈对草稿进行修改，确保辩论的质量和说服力。撰写者的工作流程主要包括以下几个方面：
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Content Creation: Based on the outline provided by the Analyzer, the Writer
    expands it into a detailed debate script, ensuring the logic of arguments and
    the sufficiency of supporting evidence.'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内容创作：根据分析员提供的大纲，撰写者将其扩展为详细的辩论脚本，确保论证逻辑严谨，支持证据充分。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Revision and Refinement: Upon receiving modification suggestions from the Reviewer,
    the Writer makes corresponding adjustments and optimizations to the script to
    enhance its overall quality.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 修订和优化：在收到评审员的修改建议后，撰写者根据建议对脚本进行相应的调整和优化，以提升整体质量。
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Resource Assessment: The Writer evaluates whether the information in the current
    knowledge base is sufficient to support the requirements of the outline and script
    revisions. If information is found to need to be improved, the Writer proactively
    initiates requests to the Searcher, clearly specifying the additional materials
    needed.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 资源评估：撰写者评估当前知识库中的信息是否足以支持大纲和脚本修订的要求。如果发现信息需要改进，撰写者会主动向搜索员发起请求，明确说明需要补充的材料。
- en: Reviewer Agent
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评审员代理
- en: 'The Reviewer is the quality control agent in the Agent4Debate framework, responsible
    for reviewing and evaluating debate scripts generated by the Writer. Its primary
    function is to provide targeted modification suggestions based on the current
    debate stage and historical context, ensuring the debate content’s quality, logic,
    and persuasiveness. The Reviewer’s workflow focuses on different aspects at various
    stages of the debate:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 评审员是Agent4Debate框架中的质量控制者，负责审查和评估撰写者生成的辩论脚本。其主要职能是根据当前的辩论阶段和历史背景，提供有针对性的修改建议，确保辩论内容的质量、逻辑性和说服力。评审员的工作流程关注辩论各个阶段的不同方面：
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 1, the Reviewer primarily concentrates on the completeness of the argument
    structure, the comprehensiveness of content (including definitions, criteria,
    and main points), the sufficiency of supporting evidence, and the fluency of expression.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第一阶段，评审员主要关注论证结构的完整性、内容的全面性（包括定义、标准和要点）、支持证据的充分性以及表达的流畅性。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 2, building upon the previous stage, the Reviewer additionally focuses
    on the appropriate application of rebuttal techniques and ensures that rebuttals
    to the opponent’s arguments do not lead to self-contradiction in one’s stance.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第二阶段，基于上一阶段的工作，评审员还特别关注反驳技巧的恰当应用，并确保对对方论点的反驳不会导致自己立场的自相矛盾。
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: In Stage 3, besides addressing the content from the previous two stages, the
    Reviewer also assesses the depth of the debate content and makes a judgment based
    on the context, providing detailed reasons for this assessment.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第三阶段，除了处理前两阶段的内容外，评审员还会评估辩论内容的深度，并根据上下文作出判断，提供详细的评估理由。
- en: The Reviewer maintains argumentative coherence by continuously assessing consistency
    with previously presented information across all debate stages. This process involves
    providing feedback and modification suggestions to the Writer, and facilitating
    targeted revisions. The review-revision cycle persists iteratively until the script
    meets the Reviewer’s quality standards.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 评审员通过持续评估所有辩论阶段中与先前信息的一致性，保持论证的连贯性。这个过程包括向撰写者提供反馈和修改建议，并促进有针对性的修订。评审-修订循环会持续进行，直到脚本符合评审员的质量标准。
- en: Experimental Setup
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验设置
- en: Experimental Subjects
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验对象
- en: Our experimental design involves three types of participants, including the
    baseline framework, Agent4Debate based on different LLMs, and human participants.
    For all models, we set temperature to 0.2 and Top P to 0.75, with no other parameters
    adjusted.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验设计包括三种类型的参与者，分别是基准框架、基于不同大语言模型（LLM）的Agent4Debate和人类参与者。对于所有模型，我们将温度（temperature）设置为0.2，Top
    P设置为0.75，其他参数未做调整。
- en: Baseline
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准
- en: We adopt the benchmark framework of AI-Debater 2024 competition¹¹1http://www.fudan-disc.com/sharedtask/AIDebater24,
    incorporating Tavily²²2https://tavily.com as the search engine and stage-specific
    prompts. We uses Claude-3.5-sonnet and Deepseek-Chat (Bi et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib4))
    as the foundation models.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了AI-Debater 2024比赛的基准框架¹¹1http://www.fudan-disc.com/sharedtask/AIDebater24，结合Tavily²²2https://tavily.com作为搜索引擎和阶段特定提示。我们使用Claude-3.5-sonnet和Deepseek-Chat（Bi等人，[2024](https://arxiv.org/html/2408.04472v2#bib.bib4)）作为基础模型。
- en: Agent4Debate
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Agent4Debate
- en: To comprehensively evaluate the generalization capability of Agent4Debate and
    conduct more in-depth comparative experiments, we select a variety of advanced
    LLMs as the foundation for Agent4Debate. These models include Claude-3.5-sonnet,
    GPT-4o (OpenAI [2023](https://arxiv.org/html/2408.04472v2#bib.bib22)), and Gemini-1.5-Pro/Flash
    (Reid et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib28)), all of which
    have demonstrated excellent performance in various evaluations (Zheng et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib44)).
    Considering that our study focuses on Chinese competitive debate, we specifically
    incorporate several LLMs that excel in Chinese language processing, including
    Qwen2-72b-Instruct (Yang et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib43)),
    Deepseek-Chat , and GLM-4-Air. Switching models in Agent4Debate experiments updates
    all components accordingly. In all experiments, the Searcher used Tavily as the
    search engine.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估Agent4Debate的泛化能力并进行更深入的对比实验，我们选择了多种先进的大语言模型作为Agent4Debate的基础模型。这些模型包括Claude-3.5-sonnet、GPT-4o（OpenAI
    [2023](https://arxiv.org/html/2408.04472v2#bib.bib22)）和Gemini-1.5-Pro/Flash（Reid等人，[2024](https://arxiv.org/html/2408.04472v2#bib.bib28)），这些模型在各种评估中表现出色（Zheng等人，[2023](https://arxiv.org/html/2408.04472v2#bib.bib44)）。考虑到我们的研究聚焦于中文竞争性辩论，我们特别选用了几种在中文处理上表现优秀的大语言模型，包括Qwen2-72b-Instruct（Yang等人，[2024](https://arxiv.org/html/2408.04472v2#bib.bib43)）、Deepseek-Chat和GLM-4-Air。在Agent4Debate实验中切换模型时，所有组件都会相应更新。在所有实验中，Searcher使用Tavily作为搜索引擎。
- en: Humans
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人类
- en: We recruit ten experienced debaters for our experiment to validate the performance
    of Agent4Debate against humans in competitive debate. Each debater has with 2-4
    years of debate team training and at least one year of Chinese competitive debate
    experience. They are informed that they will be debating against artificial intelligence
    and are given 2 days of preparation time for each motion. To ensure effective
    communication, we use the Whisper model (Radford et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib26))
    to transcribe human speeches into text while the human debaters read the model’s
    output directly. This design ensures accurate information transfer and provides
    human debaters ample time for reflection and response. These debaters participate
    only in the debates, not in other research activities.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为实验招募了十名经验丰富的辩手，以验证Agent4Debate在竞争性辩论中与人类的表现对比。每位辩手都有2-4年的辩论队训练经验，并且至少有一年的中文竞争性辩论经验。他们被告知将与人工智能进行辩论，并且每个辩题有2天的准备时间。为了确保有效的沟通，我们使用Whisper模型（Radford等人，[2023](https://arxiv.org/html/2408.04472v2#bib.bib26)）将人类辩手的演讲转录为文本，而人类辩手则直接阅读模型的输出。此设计确保了信息传递的准确性，并为人类辩手提供了充分的反思和回应时间。这些辩手仅参与辩论，不参与其他研究活动。
- en: Metrics
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 度量标准
- en: Debatrix
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Debatrix
- en: 'Debatrix (Liang et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib19))
    is a multi-turn debate evaluation method based on LLMs. It comprehensively assesses
    debates by considering the chronological order of statements and evaluating them
    along three dimensions, each described in natural language: Argument (A), Source
    (S), and Language (L). These natural language evaluations are then integrated
    to form an Overall (O) assessment, ultimately determining the winner. In our implementation,
    we convert each dimension’s descriptive result into a ternary outcome (win, lose,
    or tie). This evaluation approach is particularly well-suited for our multi-turn,
    document-level competitive debate scenarios. In our experiments, we employ GPT-4o-mini
    as the foundational model for Debatrix. To ensure the reliability of the assessment,
    we conduct three independent evaluations using Debatrix for each debate, ultimately
    deriving the final scores.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Debatrix（梁等人 [2024](https://arxiv.org/html/2408.04472v2#bib.bib19)）是一种基于大语言模型（LLMs）的多回合辩论评估方法。它通过考虑陈述的时间顺序，并沿着三个维度进行评估，全面评估辩论，每个维度都用自然语言描述：论点（A）、来源（S）和语言（L）。这些自然语言评估结果随后被整合为一个总体（O）评估，最终决定胜者。在我们的实现中，我们将每个维度的描述性结果转化为三元结果（胜、负或平）。这种评估方法特别适合我们的多回合、文档级竞争性辩论场景。在实验中，我们采用GPT-4o-mini作为Debatrix的基础模型。为了确保评估的可靠性，我们对每场辩论进行三次独立评估，最终得出最终得分。
- en: Human
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人类
- en: We invite three experienced Chinese competitive debate judges to participate
    in this study. Each judge possesses 3-5 years of experience in Chinese competitive
    debates and has coached university debate teams. The judges independently assess
    each debate, casting a vote for win, lose, or tie, with the outcome determined
    by majority rule. To maintain impartiality, judges are only informed that both
    sides have an equal burden of proof without receiving any additional context.
    It is important to note that all judges are external to the research development
    process and do not have backgrounds in computer science, thereby minimizing potential
    biases.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们邀请了三位经验丰富的中国竞争性辩论裁判参与本研究。每位裁判均拥有3到5年的中国竞争性辩论经验，并曾指导过大学辩论队。裁判独立评估每场辩论，并投票决定胜负或平局，最终结果由多数裁定。为了保持公正，裁判仅被告知双方在举证方面有相等的责任，而不会获得其他任何背景信息。值得注意的是，所有裁判均与研究开发过程无关，并且没有计算机科学背景，从而最大限度地减少了潜在的偏见。
- en: Competitive Debate Arena
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 竞争辩论场
- en: To comprehensively assess the abilities of Agent4Debate, Baseline, and Humans
    in competitive debate, we establish the Competitive Debate Arena. This arena is
    designed to provide a fair and extensible evaluation environment, covering various
    types of debate motions and assessment methods. We carefully select 66 debate
    motions from major Chinese debate competitions over the past decade, including
    Chinese Debate World Cup, The World Mandarin Debating Championship, and International
    Chinese Debating Competition. These motions cover three main categories (Abell
    [2018](https://arxiv.org/html/2408.04472v2#bib.bib1)), including Value, Fact,
    and Policy. Fact makes statements or comparisons about testable aspects of the
    natural world, Value assigns value or judgment to certain things or concepts,
    while Policy typically suggests action plans through proposed changes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估Agent4Debate、基准模型和人类在竞争性辩论中的能力，我们建立了竞争辩论场。这个场地旨在提供一个公平且具有可扩展性的评估环境，涵盖各种类型的辩论议题和评估方法。我们从过去十年间的主要中国辩论比赛中精心挑选了66个辩论议题，包括中国辩论世界杯、世界普通话辩论锦标赛和国际中文辩论比赛。这些议题涵盖了三个主要类别（Abell
    [2018](https://arxiv.org/html/2408.04472v2#bib.bib1)），包括价值、事实和政策。事实是关于自然界中可测试方面的陈述或比较，价值是对某些事物或概念进行价值或判断，政策则通常通过建议变更来提出行动计划。
- en: 'In terms of evaluation methods, we adopt two independent review approaches,
    where one uses the Debatrix based on LLMs for assessment, and the other involves
    judgments by experienced human reviewers. These review methods are completely
    independent, each producing separate results. Based on these review methods, we
    construct two ranking systems, including Debatrix-Elo and Human-Elo. To build
    these ranking systems, we draw inspiration from the Chatbot Arena (Zheng et al.
    [2023](https://arxiv.org/html/2408.04472v2#bib.bib44)) approach and adopt an improved
    version of the Bradley-Terry (BT) model (Hunter [2004](https://arxiv.org/html/2408.04472v2#bib.bib13);
    Rafailov et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib27)) to calculate
    Elo scores. The traditional BT model uses the following formula to calculate the
    probability of Participant A winning over Participant B:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估方法方面，我们采用了两种独立的评审方式，其中一种使用基于 LLM 的 Debatrix 进行评估，另一种则是由经验丰富的人工评审员进行判断。这些评审方法是完全独立的，每种方法都会产生单独的结果。基于这些评审方法，我们构建了两个排名系统，包括
    Debatrix-Elo 和 Human-Elo。为了构建这些排名系统，我们借鉴了 Chatbot Arena (Zheng et al. [2023](https://arxiv.org/html/2408.04472v2#bib.bib44))
    方法，并采用了改进版的 Bradley-Terry (BT) 模型 (Hunter [2004](https://arxiv.org/html/2408.04472v2#bib.bib13);
    Rafailov et al. [2024](https://arxiv.org/html/2408.04472v2#bib.bib27)) 来计算 Elo
    分数。传统的 BT 模型使用以下公式来计算参与者 A 战胜参与者 B 的概率：
- en: '|  | $P(A>B)=\frac{e^{\gamma_{A}}}{e^{\gamma_{A}}+e^{\gamma_{B}}}$ |  | (3)
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | $P(A>B)=\frac{e^{\gamma_{A}}}{e^{\gamma_{A}}+e^{\gamma_{B}}}$ |  | (3)
    |'
- en: where $\gamma_{A}$ and $\gamma_{B}$ represent the ability parameters of A and
    B, respectively.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\gamma_{A}$ 和 $\gamma_{B}$ 分别表示 A 和 B 的能力参数。
- en: 'However, considering that our review system (whether Debatrix or human reviewers)
    independently provides three scores, we improve the traditional model by introducing
    a weight function based on score differences:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到我们的评审系统（无论是 Debatrix 还是人工评审员）会独立提供三项分数，我们通过引入一个基于分数差异的权重函数，改进了传统模型：
- en: '|  | $w_{i}=\frac{1}{1+e^{-&#124;\text{score}_{A_{i}}-\text{score}_{B_{i}}&#124;}}$
    |  | (4) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | $w_{i}=\frac{1}{1+e^{-&#124;\text{score}_{A_{i}}-\text{score}_{B_{i}}&#124;}}$
    |  | (4) |'
- en: 'where $\text{score}\in[0,3]$. This weight function adjusts the importance of
    each match in the final ranking, making the ranking calculation more precise.
    Based on this weight function, our likelihood function becomes:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\text{score}\in[0,3]$。该权重函数调整了每场比赛在最终排名中的重要性，使排名计算更加精确。基于这个权重函数，我们的似然函数变为：
- en: '|  | $\mathcal{L}=\prod_{i=1}^{n}P(A_{i}>B_{i})^{w_{i}}$ |  | (5) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}=\prod_{i=1}^{n}P(A_{i}>B_{i})^{w_{i}}$ |  | (5) |'
- en: By maximizing this likelihood function, we can obtain more accurate ability
    parameter estimates, thus constructing a more precise ranking system.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过最大化这个似然函数，我们可以获得更准确的能力参数估计，从而构建一个更精确的排名系统。
- en: Our improved Elo system not only effectively reflects participants’ overall
    performance in multiple matchups but also allows for more nuanced adjustments
    based on the specifics of each match. Using two independent review methods and
    ranking systems, we can better understand the performance of participants and
    compare potential differences between Debatrix and human reviews. Furthermore,
    this Elo system is scalable, efficiently incorporating new frameworks or models
    for ongoing comparative analysis.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们改进后的 Elo 系统不仅有效地反映了参与者在多个对局中的整体表现，还允许根据每场比赛的具体情况进行更为细致的调整。通过使用两种独立的评审方法和排名系统，我们可以更好地理解参与者的表现，并比较
    Debatrix 和人工评审之间的潜在差异。此外，该 Elo 系统具有可扩展性，能够高效地融入新的框架或模型以进行持续的比较分析。
- en: Experimental Results
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验结果
- en: Agent4Debate vs. Baseline
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Agent4Debate 与基准对比
- en: We conduct a comparative performance evaluation of Agent4Debate against the
    baselines. Each framework participates in 20 debate matches, including five different
    motions. To ensure fairness, the number of times each framework argued for the
    Pro and Con sides is balanced. Debatrix is employed as the evaluation criteria.
    Debatrix scoring is applied three times for each debate, with 1 point awarded
    for each win in the dimensions of Argument (A), Language (L), Source (S), and
    Overall (O) performance. In the case of a tie, both sides are awarded 0.5 points.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对 Agent4Debate 与基准进行比较性能评估。每个框架参加了 20 场辩论比赛，包括五个不同的辩题。为了确保公平，每个框架在支持正方和反方的次数是平衡的。Debatrix
    被用作评估标准。每场辩论应用 Debatrix 评分三次，在论点（A）、语言（L）、来源（S）和整体（O）四个维度上，每次胜利获得 1 分。如果平局，双方各得
    0.5 分。
- en: '| Model | Framework | Debatrix |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 框架 | Debatrix |'
- en: '| --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S | L | A | O |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| S | L | A | O |'
- en: '| --- | --- | --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Claude-3.5-sonnet | Agent4Debate | 2.83 | 1.76 | 2.52 | 2.62 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | Agent4Debate | 2.83 | 1.76 | 2.52 | 2.62 |'
- en: '| Baseline | 0.17 | 1.24 | 0.48 | 0.38 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 0.17 | 1.24 | 0.48 | 0.38 |'
- en: '| Deepseek-Chat | Agent4Debate | 2.73 | 1.88 | 2.31 | 2.77 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-Chat | Agent4Debate | 2.73 | 1.88 | 2.31 | 2.77 |'
- en: '| Baseline | 0.27 | 1.12 | 0.69 | 0.23 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 0.27 | 1.12 | 0.69 | 0.23 |'
- en: 'Table 1: Comparison of Agent4Debate and Baseline.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：Agent4Debate 与基准的比较。
- en: As shown in Table [1](https://arxiv.org/html/2408.04472v2#Sx6.T1 "Table 1 ‣
    Agent4Debate vs. Baseline ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate"), Agent4Debate enhances
    the competitive debating performance across both models. For Claude-3.5-sonnet,
    the Overall score improves from 0.38 to 2.62, while for Deepseek-Chat, it increases
    from 0.23 to 2.77\. These results demonstrate that the Agent4Debate framework
    effectively enhances the performance of language models of varying scales and
    types in competitive debate tasks. Among all metrics, Source shows improvement.
    This can be attributed to the Searcher Agent and Analyzer Agent within Agent4Debate,
    which conducts an in-depth analysis of debate motions and systematic organization
    of materials, utilizing external knowledge more effectively than the simple search
    approach from baseline. The Language shows relatively modest improvement, reflecting
    robust generation capabilities of LLMs, leaving limited room for enhancement.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[1](https://arxiv.org/html/2408.04472v2#Sx6.T1 "Table 1 ‣ Agent4Debate vs.
    Baseline ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating? A Dynamic
    Multi-agent Framework for Competitive Debate")所示，Agent4Debate 提升了两种模型在竞争性辩论中的表现。对于
    Claude-3.5-sonnet，整体得分从 0.38 提升到 2.62；而对于 Deepseek-Chat，得分从 0.23 提升到 2.77。这些结果表明，Agent4Debate
    框架有效提升了不同规模和类型语言模型在竞争性辩论任务中的表现。在所有指标中，Source 显示出了改善。这归因于 Agent4Debate 中的搜索器和分析器代理，它们对辩论议题进行深入分析，并系统化地组织材料，利用外部知识的效率远高于基准模型的简单搜索方法。Language
    显示出相对较小的改善，反映了 LLMs 强大的生成能力，增强的空间有限。
- en: Comparing the results between Claude-3.5-sonnet and Deepseek-Chat, it is observed
    that Agent4Debate yields more pronounced performance improvements for the more
    powerful model, particularly in the Argument and Overall metrics. This may be
    due to more advanced models possessing stronger reasoning abilities and better
    instruction-following capabilities (Kaplan et al. [2020](https://arxiv.org/html/2408.04472v2#bib.bib15)),
    thus exhibiting superior adaptability to complex frameworks.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Claude-3.5-sonnet 和 Deepseek-Chat 之间的结果对比中，可以观察到，Agent4Debate 对更强大的模型带来了更加显著的性能提升，尤其是在
    Argument 和 Overall 指标上。这可能是因为更先进的模型具有更强的推理能力和更好的指令跟随能力（Kaplan 等人，[2020](https://arxiv.org/html/2408.04472v2#bib.bib15)），因此在复杂框架下表现出更好的适应性。
- en: Ablation Study
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消融研究
- en: To evaluate the contribution of each agent within Agent4Debate, we conduct a
    series of ablation studies. The experimental setup remains consistent with the
    previous comparative experiments. Each ablation configuration engages in 20 debates
    across five motions, with a balanced distribution of the Pro and Con sides. The
    evaluation continues to employ Debatrix, with the scoring method identical to
    that of the comparative experiments. We do not perform an ablation experiment
    on the Writer Agent, as it is responsible for the text generation at every stage.
    The foundation model for the ablation study is Claude-3.5-sonnet.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 Agent4Debate 中每个代理的贡献，我们进行了一系列消融研究。实验设置与之前的对比实验一致。每个消融配置会进行 20 次辩论，涵盖五个议题，并在支持方和反对方之间进行平衡分配。评估仍然采用
    Debatrix，并且评分方法与对比实验相同。我们没有对 Writer Agent 进行消融实验，因为它负责每个阶段的文本生成。消融研究的基础模型为 Claude-3.5-sonnet。
- en: '| Framework | Debatrix |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 框架 | Debatrix |'
- en: '| --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| S | L | A | O |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| S | L | A | O |'
- en: '| --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Agent4Debate | 2.79 | 1.54 | 2.01 | 2.12 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 2.79 | 1.54 | 2.01 | 2.12 |'
- en: '| w/o Searcher | 0.21 | 1.46 | 0.99 | 0.88 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 无搜索器 | 0.21 | 1.46 | 0.99 | 0.88 |'
- en: '| Agent4Debate | 1.83 | 1.50 | 1.79 | 1.76 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 1.83 | 1.50 | 1.79 | 1.76 |'
- en: '| w/o Analyzer | 1.17 | 1.50 | 1.21 | 1.24 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 无分析器 | 1.17 | 1.50 | 1.21 | 1.24 |'
- en: '| Agent4Debate | 1.74 | 1.67 | 2.13 | 1.93 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 1.74 | 1.67 | 2.13 | 1.93 |'
- en: '| w/o Reviewer | 1.26 | 1.33 | 0.87 | 1.07 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 无审阅者 | 1.26 | 1.33 | 0.87 | 1.07 |'
- en: 'Table 2: The results of ablation study. The foundation model for the ablation
    study is Claude-3.5-sonnet.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：消融研究的结果。消融研究的基础模型为 Claude-3.5-sonnet。
- en: Table [2](https://arxiv.org/html/2408.04472v2#Sx6.T2 "Table 2 ‣ Ablation Study
    ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") presents the detailed results of our ablation
    study, clearly illustrating the impact of removing each agent. The experimental
    results demonstrate that each agent in the Agent4Debate framework contributes
    to the overall performance. When we remove any agent, the Overall score decreases,
    confirming the necessity of each component. Specifically, removing the Analyzer
    reduces the Overall score from 2.12 to 1.76\. Its impact on the Source and Argument
    metrics is particularly notable, with the Source score dropping from 2.79 to 1.83
    and the Argument score from 2.01 to 1.79\. This indicates the Analyzer’s crucial
    role in the formulation of material analysis, argument refinement, and rebuttal
    strategy. The absence of the Searcher results in a dramatic drop in the Source
    score from 2.79 to 0.21, while the Overall score falls from 2.12 to 0.88\. This
    highlights the importance of appropriately searching and organizing external knowledge
    to enhance debate performance. The removal of the Reviewer has a smaller impact
    on overall performance (Overall score decreases from 2.12 to 1.93). However, its
    primary function of reviewing drafts, suggesting revisions, and improving the
    output quality of Agent4Debate aligns with the framework’s design expectations.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [2](https://arxiv.org/html/2408.04472v2#Sx6.T2 "Table 2 ‣ Ablation Study
    ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") 展示了我们消融研究的详细结果，清晰地说明了去除每个代理人的影响。实验结果表明，Agent4Debate框架中的每个代理人都对整体表现做出了贡献。当去除任何一个代理人时，整体得分都会下降，这确认了每个组件的必要性。具体来说，去除分析器将整体得分从
    2.12 降低到 1.76。其对来源和论点指标的影响尤为显著，来源得分从 2.79 降至 1.83，论点得分从 2.01 降至 1.79。这表明分析器在材料分析、论证细化和反驳策略的制定中起着至关重要的作用。去除搜索器导致来源得分从
    2.79 降至 0.21，整体得分从 2.12 降至 0.88，突显了适当搜索和组织外部知识以提升辩论表现的重要性。去除审阅者对整体表现的影响较小（整体得分从
    2.12 降至 1.93）。然而，审阅者的主要功能是审查草稿、提出修改建议并提升 Agent4Debate 的输出质量，这与框架的设计预期相符。
- en: Results of Competitive Debate Arena
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 竞争辩论场的结果
- en: We collect records of 200 debate matches (excluding those from comparison experiments
    and ablation studies), covering 66 debate motions across three categories, including
    Fact, Value, and Policy. Participants included in Agent4Debate using different
    foundation models, two baselines, and ten human debaters, all of which are engaged
    in randomly paired competitions. Each debate is independently assessed using both
    the Debatrix and human judges. Utilizing the improved BT model in Eq. [5](https://arxiv.org/html/2408.04472v2#Sx5.E5
    "In Competitive Debate Arena ‣ Experimental Setup ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate"), we calculate Elo scores
    for all 200 matches and sub-Elo scores for each of the three debate categories.
    The experimental results are presented in two independent ranking systems, consisting
    of Debatrix-Elo (Table [3](https://arxiv.org/html/2408.04472v2#Sx6.T3 "Table 3
    ‣ Results of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs Beat Humans
    in Debating? A Dynamic Multi-agent Framework for Competitive Debate")) and Human-Elo
    (Table [4](https://arxiv.org/html/2408.04472v2#Sx6.T4 "Table 4 ‣ Results of Competitive
    Debate Arena ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating? A Dynamic
    Multi-agent Framework for Competitive Debate")).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了 200 场辩论比赛的记录（不包括比较实验和消融研究中的比赛），涵盖了 66 个辩题，分为事实、价值和政策三类。参与者包括使用不同基础模型的
    Agent4Debate、两个基线模型和十名人类辩手，所有参与者都参与了随机配对的比赛。每场辩论都由 Debatrix 和人类评审独立评估。我们利用改进后的
    BT 模型（见公式 [5](https://arxiv.org/html/2408.04472v2#Sx5.E5 "In Competitive Debate
    Arena ‣ Experimental Setup ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate")），计算了所有 200 场比赛的 Elo 得分，以及每三类辩论类别的子 Elo 得分。实验结果以两个独立的排名系统呈现，包括
    Debatrix-Elo（表格 [3](https://arxiv.org/html/2408.04472v2#Sx6.T3 "Table 3 ‣ Results
    of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate")）和 Human-Elo（表格 [4](https://arxiv.org/html/2408.04472v2#Sx6.T4
    "Table 4 ‣ Results of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs
    Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate")）。
- en: '| Model | Full | Fact | Policy | Value |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 全部 | 事实 | 政策 | 价值 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Gemini-1.5-Pro | 1034.15 | 1154.93 | 1231.98 | 1075.30 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Pro | 1034.15 | 1154.93 | 1231.98 | 1075.30 |'
- en: '| Claude-3.5-sonnet | 1032.51 | 1159.18 | 1224.19 | 1074.33 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | 1032.51 | 1159.18 | 1224.19 | 1074.33 |'
- en: '| Qwen2-72b-Instruct | 1023.31 | 1130.83 | 1179.62 | 1081.75 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72b-Instruct | 1023.31 | 1130.83 | 1179.62 | 1081.75 |'
- en: '| GPT-4o | 1022.21 | 1150.14 | 1137.49 | 1069.55 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 1022.21 | 1150.14 | 1137.49 | 1069.55 |'
- en: '| Gemini-1.5-Flash | 1012.45 | 1136.21 | 1156.50 | 1057.73 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Flash | 1012.45 | 1136.21 | 1156.50 | 1057.73 |'
- en: '| GLM-4-Air | 1011.72 | 1155.07 | 1148.53 | 1048.42 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4-Air | 1011.72 | 1155.07 | 1148.53 | 1048.42 |'
- en: '| Deepseek-chat | 1004.00 | 1118.98 | 1131.16 | 1054.89 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-chat | 1004.00 | 1118.98 | 1131.16 | 1054.89 |'
- en: '| Claude-3.5-sonnet^∗ | 982.07 | 479.50 | 956.21 | 1021.44 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet^∗ | 982.07 | 479.50 | 956.21 | 1021.44 |'
- en: '| Human | 978.35 | 1109.73 | 515.57 | 953.05 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | 978.35 | 1109.73 | 515.57 | 953.05 |'
- en: '| Deepseek-Chat^∗ | 954.34 | 491.13 | 478.78 | 983.99 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-Chat^∗ | 954.34 | 491.13 | 478.78 | 983.99 |'
- en: 'Table 3: Debatrix-Elo Ranking. ^∗ denotes baseline models, unmarked models
    are Agent4Debate foundation models.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：Debatrix-Elo 排名。^∗ 表示基准模型，未标记的模型为 Agent4Debate 基础模型。
- en: '| Model | Full | Fact | Policy | Value |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 完整 | 事实 | 政策 | 价值 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Gemini-1.5-Pro | 1040.64 | 1110.23 | 1104.79 | 1048.10 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Pro | 1040.64 | 1110.23 | 1104.79 | 1048.10 |'
- en: '| Claude-3.5-sonnet | 1031.15 | 1093.87 | 1104.44 | 1020.05 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | 1031.15 | 1093.87 | 1104.44 | 1020.05 |'
- en: '| GPT-4o | 1028.84 | 1086.78 | 1099.63 | 1033.09 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | 1028.84 | 1086.78 | 1099.63 | 1033.09 |'
- en: '| Human | 1006.46 | 1055.82 | 1030.32 | 1006.57 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | 1006.46 | 1055.82 | 1030.32 | 1006.57 |'
- en: '| Gemini-1.5-Flash | 1000.00 | 1037.45 | 997.66 | 1003.29 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Flash | 1000.00 | 1037.45 | 997.66 | 1003.29 |'
- en: '| Qwen2-72b-Instruct | 999.70 | 1041.10 | 976.16 | 1005.56 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72b-Instruct | 999.70 | 1041.10 | 976.16 | 1005.56 |'
- en: '| Claude-3.5-sonnet^∗ | 991.38 | 1023.29 | 968.34 | 997.47 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet^∗ | 991.38 | 1023.29 | 968.34 | 997.47 |'
- en: '| GLM-4-Air | 972.48 | 940.00 | 948.31 | 996.67 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4-Air | 972.48 | 940.00 | 948.31 | 996.67 |'
- en: '| Deepseek-chat | 971.94 | 963.05 | 946.30 | 986.79 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-chat | 971.94 | 963.05 | 946.30 | 986.79 |'
- en: '| Deepseek-Chat^∗ | 962.61 | 786.44 | 911.33 | 979.29 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-Chat^∗ | 962.61 | 786.44 | 911.33 | 979.29 |'
- en: 'Table 4: Human-Elo Ranking. ^∗ denotes baseline models, unmarked models are
    Agent4Debate foundation models.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：Human-Elo 排名。^∗ 表示基准模型，未标记的模型为 Agent4Debate 基础模型。
- en: 'Drawing from the experimental results presented in Tables [3](https://arxiv.org/html/2408.04472v2#Sx6.T3
    "Table 3 ‣ Results of Competitive Debate Arena ‣ Experimental Results ‣ Can LLMs
    Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate")
    and [4](https://arxiv.org/html/2408.04472v2#Sx6.T4 "Table 4 ‣ Results of Competitive
    Debate Arena ‣ Experimental Results ‣ Can LLMs Beat Humans in Debating? A Dynamic
    Multi-agent Framework for Competitive Debate"), we can derive the following insights.
    (1) Agent4Debate, especially those using advanced foundation models such as Gemini-1.5-Pro
    and Claude-3.5-sonnet, demonstrate performance comparable to or surpassing human
    debaters in Debatrix-Elo and Human-Elo rankings. The top-performing Agent4Debate
    (Gemini-1.5-Pro) consistently ranks first, scoring 1044.18 in Debatrix-Elo and
    1040.64 in Human-Elo. Experimental results indicate that models with more robust
    reasoning and instruction-following capabilities perform better within the Agent4Debate
    framework. (2) In Debatrix-Elo, most models show score variations across the Fact,
    Policy, and Value categories. In contrast, Human-Elo displays more consistent
    scores for each model across categories. This disparity may arise because Debatrix
    considers Source, Language, and Argument dimensions, while human judges likely
    focus more on logic and rebuttal techniques. Debatrix-Elo and Human-Elo show high
    consistency in model rankings, particularly for top-performing models. However,
    human performance is ranked differently in the two rankings. In Debatrix-Elo,
    humans rank 8th with a score of 978.35, while in Human-Elo, they rank 4th with
    a score of 1006.46\. This suggests that Debatrix-Elo may underestimate human performance.
    This underestimation is partly due to the different evaluation tendencies between
    Debatrix and human judges, and partly because human speech quality deteriorates
    when transcribed to text. (3) In Debatrix-Elo, certain models excel in specific
    categories. This is due to differences in the argumentation processes for the
    three types of debate motions: Policy debates typically require extensive evidence
    to demonstrate policy necessity and effectiveness; Value debates often demand
    more substantial logical reasoning and expressive skills; Fact debates combine
    characteristics of both. These distinctions, reflected in Debatrix’s multi-dimensional
    evaluation, yield varying results.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表格[3](https://arxiv.org/html/2408.04472v2#Sx6.T3 "表 3 ‣ 竞争辩论平台 ‣ 实验结果 ‣ 大型语言模型能否在辩论中超越人类？动态多智能体框架")和[4](https://arxiv.org/html/2408.04472v2#Sx6.T4
    "表 4 ‣ 竞争辩论平台 ‣ 实验结果 ‣ 大型语言模型能否在辩论中超越人类？动态多智能体框架")中展示的实验结果，我们可以得出以下见解。（1）Agent4Debate，尤其是那些使用先进基础模型（如
    Gemini-1.5-Pro 和 Claude-3.5-sonnet）的模型，在 Debatrix-Elo 和 Human-Elo 排名中表现出与人类辩手相当或超越的水平。表现最好的
    Agent4Debate（Gemini-1.5-Pro）始终排名第一，在 Debatrix-Elo 中得分为 1044.18，在 Human-Elo 中得分为
    1040.64。实验结果表明，具备更强推理和遵循指令能力的模型在 Agent4Debate 框架中表现更佳。（2）在 Debatrix-Elo 中，大多数模型在事实、政策和价值三类中得分有较大波动。相比之下，Human-Elo
    中每个模型在各类别中的得分更加一致。这种差异可能是因为 Debatrix 考虑了来源、语言和论证维度，而人类评审更侧重于逻辑性和反驳技巧。Debatrix-Elo
    和 Human-Elo 在模型排名上表现出高度一致性，特别是在表现最好的模型上。然而，人类在这两个排名中的表现有所不同。在 Debatrix-Elo 中，人类排名第八，得分为
    978.35，而在 Human-Elo 中排名第四，得分为 1006.46。这表明 Debatrix-Elo 可能低估了人类的表现。这种低估部分源于 Debatrix
    和人类评审的评估倾向差异，部分原因是人类的口语质量在转录为文本时有所下降。（3）在 Debatrix-Elo 中，某些模型在特定类别中表现优异。这是因为在三种类型的辩论议题中，论证过程存在差异：政策辩论通常需要大量证据来证明政策的必要性和有效性；价值辩论则更注重逻辑推理和表达技巧；事实辩论则结合了两者的特点。这些差异反映在
    Debatrix 的多维度评估中，导致了不同的结果。
- en: Agent4Debate vs. Humans
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Agent4Debate 与人类对比
- en: '| Model | Debatrix | Human |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Debatrix | 人类 |'
- en: '| --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| S | L | A | O |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| S | L | A | O |'
- en: '| --- | --- | --- | --- |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Human | 0.52 | 0.30 | 0.6 | 0.42 | 1.22 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | 0.52 | 0.30 | 0.6 | 0.42 | 1.22 |'
- en: '| Agent4Debate | 2.48 | 2.70 | 2.40 | 2.58 | 1.78 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Agent4Debate | 2.48 | 2.70 | 2.40 | 2.58 | 1.78 |'
- en: 'Table 5: Comparison of Human and Agent4Debate'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：人类与 Agent4Debate 的对比
- en: We conduct a separate analysis of 30 debates between Agent4Debate and human
    debaters. In these debates, to ensure comprehensive experimentation, all foundation
    models of Agent4Debate participate. The scoring results from the Debatrix system
    and human judges are presented in Table [5](https://arxiv.org/html/2408.04472v2#Sx6.T5
    "Table 5 ‣ Agent4Debate vs. Humans ‣ Results of Competitive Debate Arena ‣ Experimental
    Results ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for
    Competitive Debate").
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对Agent4Debate与人类辩手之间的30场辩论进行了单独分析。在这些辩论中，为确保实验的全面性，Agent4Debate的所有基础模型都参与了其中。Debatrix系统和人类评审者的评分结果见表[5](https://arxiv.org/html/2408.04472v2#Sx6.T5
    "表5 ‣ Agent4Debate与人类 ‣ 竞技辩论场 ‣ 实验结果 ‣ 大型语言模型能否在辩论中胜过人类？一个动态的多代理框架用于竞技辩论")。
- en: Debatrix for human performance is lower than human judges across three dimensions.
    This discrepancy may stem from several factors. Regarding Source, human debaters
    use voice input, which is then transcribed into text. People typically do not
    directly cite references in oral debates, leading to lower scores. The Language
    score is the lowest, possibly due to oral expressions often containing verbal
    tics and informal language, coupled with imperfect voice-to-text transcription
    accuracy, affecting language quality assessment. The low Argument score may be
    a cascading effect of the previous two low scores, thus impacting Debatrix’s overall
    understanding and evaluation of human input. In contrast, human judges employ
    different criteria when evaluating competitive debates. They usually prioritize
    core factors such as logical reasoning and debating skills, only considering other
    aspects when these primary elements are challenging to distinguish. This approach
    to judgment differs from the Debatrix.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Debatrix在人类表现的评估上低于人类评审者，在三个维度上存在差异。这种差异可能源于多个因素。关于来源，人类辩手使用语音输入，然后将其转录为文本。在口头辩论中，人们通常不会直接引用参考资料，从而导致得分较低。语言得分是最低的，可能是因为口头表达常常包含口头禅和非正式语言，再加上语音转文本的准确性不完美，影响了语言质量的评估。较低的论点得分可能是前两个低分的连锁反应，从而影响了Debatrix对人类输入的整体理解和评估。相比之下，人类评审者在评估竞技辩论时采用了不同的标准。他们通常优先考虑逻辑推理和辩论技巧等核心因素，只有在这些主要因素难以区分时，才会考虑其他方面。这种评判方法与Debatrix不同。
- en: Consistency
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一致性
- en: To analyze the differences between Debatrix and human evaluations, we conduct
    a consistency analysis. Consistency is calculated by comparing the result between
    human and Debatrix, with tie considered consistent outcomes. Table [6](https://arxiv.org/html/2408.04472v2#Sx6.T6
    "Table 6 ‣ Consistency ‣ Results of Competitive Debate Arena ‣ Experimental Results
    ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive
    Debate") presents the results, showing that internal consistency among human reviewers
    remains stable across all matches, while the consistency between Debatrix and
    human reviewers varies when including or excluding human debaters. These findings
    further corroborate the above observations. These findings suggest that while
    Debatrix shows differences from human reviewers in evaluating debates between
    humans and models, it still provides valuable insights, particularly in assessing
    model-to-model debates. In these cases, Debatrix offers multi-faceted analytical
    results that contribute to our understanding of models’ comprehensive capabilities
    in competitive debates.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析Debatrix与人类评估之间的差异，我们进行了一个一致性分析。一致性通过比较人类与Debatrix的结果来计算，相同的结果被视为一致的结论。表[6](https://arxiv.org/html/2408.04472v2#Sx6.T6
    "表6 ‣ 一致性 ‣ 竞技辩论场 ‣ 实验结果 ‣ 大型语言模型能否在辩论中胜过人类？一个动态的多代理框架用于竞技辩论")展示了结果，表明人类评审者之间的内部一致性在所有比赛中保持稳定，而在包括或排除人类辩手时，Debatrix与人类评审者之间的一致性则有所变化。这些发现进一步验证了上述观察结果。这些发现表明，尽管Debatrix在评估人类与模型之间的辩论时与人类评审者存在差异，但它仍然提供了有价值的见解，尤其是在评估模型对模型的辩论时。在这些情况下，Debatrix提供了多方面的分析结果，有助于我们理解模型在竞技辩论中的综合能力。
- en: '| Consistency | Excluding Human Debates | All Debates |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | 排除人类辩论 | 所有辩论 |'
- en: '| --- | --- | --- |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Debatrix vs. Human | 0.66 | 0.56 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| Debatrix与人类 | 0.66 | 0.56 |'
- en: '| Among Human | 0.74 | 0.73 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 人类之间 | 0.74 | 0.73 |'
- en: 'Table 6: Consistency between Debatrix and Human Judges'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：Debatrix与人类评审者的一致性
- en: We further analyze the Elo rankings and Agent4Debate in the Appendix.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在附录中进一步分析了Elo排名和Agent4Debate。
- en: Conclusion
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: We propose a dynamic multi-agent framework, Agent for Debate (Agent4Debate),
    to enable LLMs to participate in competitive debates. To evaluate the performance
    of Agent4Debate, we construct the Competitive Debate Arena, comprising 66 classic
    Chinese debate motions. We recruit ten human debaters and collect 200 debate matches
    involving Agent4Debate, baselines, and human debaters. Using the Debatrix and
    human judges for evaluation, we propose Debatrix-Elo and Human-Elo rankings. Experimental
    results show that our state-of-the-art Agent4Debate exhibits capabilities comparable
    to those of humans in competitive debates. Ablation studies prove the effectiveness
    of each component in the agent structure.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一个动态多代理框架——辩论代理（Agent4Debate），以使LLM参与竞争性辩论。为了评估Agent4Debate的表现，我们构建了一个竞争性辩论场，包含66个经典的中文辩题。我们招募了十名人类辩手，并收集了200场包含Agent4Debate、基线模型和人类辩手的辩论比赛。使用Debatrix和人类评委进行评估，我们提出了Debatrix-Elo和Human-Elo排名。实验结果表明，我们最先进的Agent4Debate展现出与人类在竞争性辩论中相当的能力。消融研究证明了代理结构中各个组件的有效性。
- en: References
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abell (2018) Abell, J. 2018. Value, Fact, and Policy Resolutions.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abell (2018) Abell, J. 2018. 价值、事实与政策决策。
- en: 'Argyle et al. (2022) Argyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J.; Rytting,
    C.; and Wingate, D. 2022. Out of One, Many: Using Language Models to Simulate
    Human Samples. In *Proceedings of the 60th Annual Meeting of the Association for
    Computational Linguistics (Volume 1: Long Papers)*, 819–862.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argyle et al. (2022) Argyle, L. P.; Busby, E. C.; Fulda, N.; Gubler, J.; Rytting,
    C.; 和 Wingate, D. 2022. 从一到多：使用语言模型模拟人类样本。发表于 *第60届计算语言学协会年会论文集（第一卷：长篇论文）*，819–862。
- en: 'Atkinson et al. (2017) Atkinson, K.; Baroni, P.; Giacomin, M.; Hunter, A.;
    Prakken, H.; Reed, C.; Simari, G. R.; Thimm, M.; and Villata, S. 2017. Towards
    Artificial Argumentation. *AI Mag.*, 38: 25–36.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atkinson et al. (2017) Atkinson, K.; Baroni, P.; Giacomin, M.; Hunter, A.; Prakken,
    H.; Reed, C.; Simari, G. R.; Thimm, M.; 和 Villata, S. 2017. 朝着人工论证迈进。*AI Mag.*，38：25–36。
- en: 'Bi et al. (2024) Bi, X.; Chen, D.; Chen, G.; Chen, S.; Dai, D.; Deng, C.; Ding,
    H.; Dong, K.; Du, Q.; Fu, Z.; et al. 2024. Deepseek llm: Scaling open-source language
    models with longtermism. *arXiv preprint arXiv:2401.02954*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bi et al. (2024) Bi, X.; Chen, D.; Chen, G.; Chen, S.; Dai, D.; Deng, C.; Ding,
    H.; Dong, K.; Du, Q.; Fu, Z.; 等人 2024. Deepseek llm：通过长远主义扩展开源语言模型。*arXiv预印本 arXiv:2401.02954*。
- en: Boiko, MacKnight, and Gomes (2023) Boiko, D. A.; MacKnight, R.; and Gomes, G.
    2023. Emergent Autonomous Scientific Research Capabilities of Large Language Models.
    *arXiv preprint arXiv:2304.05332*.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko, MacKnight, 和 Gomes (2023) Boiko, D. A.; MacKnight, R.; 和 Gomes, G. 2023.
    大型语言模型的突现自主科研能力。*arXiv预印本 arXiv:2304.05332*。
- en: 'Carlile et al. (2018) Carlile, W.; Gurrapadi, N.; Ke, Z.; and Ng, V. 2018.
    Give Me More Feedback: Annotating Argument Persuasiveness and Related Attributes
    in Student Essays. In Gurevych, I.; and Miyao, Y., eds., *Proceedings of the 56th
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers)*, 621–631\. Melbourne, Australia: Association for Computational Linguistics.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carlile et al. (2018) Carlile, W.; Gurrapadi, N.; Ke, Z.; 和 Ng, V. 2018. 给我更多反馈：对学生论文中的论证说服力及相关属性进行注释。发表于
    Gurevych, I.; 和 Miyao, Y., 主编， *第56届计算语言学协会年会论文集（第一卷：长篇论文）*，621–631。澳大利亚墨尔本：计算语言学协会。
- en: 'Chang (2024) Chang, E. Y. 2024. SocraSynth: Multi-LLM Reasoning with Conditional
    Statistics. arXiv:2402.06634.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chang (2024) Chang, E. Y. 2024. SocraSynth: 使用条件统计进行多LLM推理。arXiv:2402.06634。'
- en: Chen et al. (2024) Chen, G.; Cheng, L.; Tuan, L. A.; and Bing, L. 2024. Exploring
    the Potential of Large Language Models in Computational Argumentation. arXiv:2311.09022.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2024) Chen, G.; Cheng, L.; Tuan, L. A.; 和 Bing, L. 2024. 探索大型语言模型在计算论证中的潜力。arXiv:2311.09022。
- en: Du et al. (2023) Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; and Mordatch,
    I. 2023. Improving Factuality and Reasoning in Language Models through Multiagent
    Debate. arXiv:2305.14325.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du et al. (2023) Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; 和 Mordatch,
    I. 2023. 通过多代理辩论提升语言模型的事实性和推理能力。arXiv:2305.14325。
- en: Eger, Daxenberger, and Gurevych (2017) Eger, S.; Daxenberger, J.; and Gurevych,
    I. 2017. Neural end-to-end learning for computational argumentation mining. *arXiv
    preprint arXiv:1704.06104*.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eger, Daxenberger, 和 Gurevych (2017) Eger, S.; Daxenberger, J.; 和 Gurevych,
    I. 2017. 用于计算论证挖掘的神经端到端学习。*arXiv预印本 arXiv:1704.06104*。
- en: 'Elo (1967) Elo, A. E. 1967. The proposed uscf rating system, its development,
    theory, and applications. *Chess life*, 22(8): 242–247.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elo (1967) Elo, A. E. 1967. 提议的USCF评级系统，其发展、理论和应用。*Chess life*，22(8)：242–247。
- en: Hua, Hu, and Wang (2019) Hua, X.; Hu, Z.; and Wang, L. 2019. Argument Generation
    with Retrieval, Planning, and Realization. arXiv:1906.03717.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hua, Hu, 和 Wang (2019) Hua, X.; Hu, Z.; 和 Wang, L. 2019. 使用检索、规划和实现生成论证。arXiv:1906.03717。
- en: 'Hunter (2004) Hunter, D. R. 2004. MM algorithms for generalized Bradley-Terry
    models. *The annals of statistics*, 32(1): 384–406.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hunter (2004) Hunter, D. R. 2004. 用于广义Bradley-Terry模型的MM算法。*统计年鉴*，32(1): 384–406。'
- en: 'Ji et al. (2023) Ji, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii,
    E.; Bang, Y. J.; Madotto, A.; and Fung, P. 2023. Survey of hallucination in natural
    language generation. *ACM Computing Surveys*, 55(12): 1–38.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ji 等 (2023) Ji, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii, E.;
    Bang, Y. J.; Madotto, A.; 和 Fung, P. 2023. 语言生成中的幻觉调查。*ACM计算调查*，55(12): 1–38。'
- en: Kaplan et al. (2020) Kaplan, J.; McCandlish, S.; Henighan, T.; Brown, T. B.;
    Chess, B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; and Amodei, D. 2020. Scaling
    Laws for Neural Language Models. arXiv:2001.08361.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaplan 等 (2020) Kaplan, J.; McCandlish, S.; Henighan, T.; Brown, T. B.; Chess,
    B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; 和 Amodei, D. 2020. 神经语言模型的扩展规律。arXiv:2001.08361。
- en: 'Lawrence and Reed (2019) Lawrence, J.; and Reed, C. 2019. Argument Mining:
    A Survey. *Computational Linguistics*, 45(4): 765–818.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lawrence 和 Reed (2019) Lawrence, J.; 和 Reed, C. 2019. 论证挖掘：一项调查。*计算语言学*，45(4):
    765–818。'
- en: 'Li et al. (2023) Li, G.; Hammoud, H. A. A. K.; Itani, H.; Khizbullin, D.; and
    Ghanem, B. 2023. CAMEL: Communicative Agents for ”Mind” Exploration of Large Scale
    Language Model Society. *arXiv preprint arXiv:2303.17760*.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2023) Li, G.; Hammoud, H. A. A. K.; Itani, H.; Khizbullin, D.; 和 Ghanem,
    B. 2023. CAMEL：用于“大规模语言模型社会”心智探索的交互式代理。*arXiv预印本 arXiv:2303.17760*。
- en: Li, Ji, and Han (2021) Li, S.; Ji, H.; and Han, J. 2021. Document-level event
    argument extraction by conditional generation. *arXiv preprint arXiv:2104.05919*.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li, Ji 和 Han (2021) Li, S.; Ji, H.; 和 Han, J. 2021. 通过条件生成进行文档级事件论证抽取。*arXiv预印本
    arXiv:2104.05919*。
- en: 'Liang et al. (2024) Liang, J.; Ye, R.; Han, M.; Lai, R.; Zhang, X.; Huang,
    X.; and Wei, Z. 2024. Debatrix: Multi-dimensinal Debate Judge with Iterative Chronological
    Analysis Based on LLM. *arXiv preprint arXiv:2403.08010*.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang 等 (2024) Liang, J.; Ye, R.; Han, M.; Lai, R.; Zhang, X.; Huang, X.; 和
    Wei, Z. 2024. Debatrix：基于LLM的多维辩论裁判与迭代时间分析。*arXiv预印本 arXiv:2403.08010*。
- en: 'Liu et al. (2024) Liu, N. F.; Lin, K.; Hewitt, J.; Paranjape, A.; Bevilacqua,
    M.; Petroni, F.; and Liang, P. 2024. Lost in the middle: How language models use
    long contexts. *Transactions of the Association for Computational Linguistics*,
    12: 157–173.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等 (2024) Liu, N. F.; Lin, K.; Hewitt, J.; Paranjape, A.; Bevilacqua, M.;
    Petroni, F.; 和 Liang, P. 2024. 迷失在其中：语言模型如何使用长上下文。*计算语言学会会刊*，12: 157–173。'
- en: 'Nichols (1936) Nichols, E. R. 1936. A historical sketch of intercollegiate
    debating: I. *Quarterly Journal of Speech*, 22(2): 213–220.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nichols (1936) Nichols, E. R. 1936. 大学间辩论的历史概述：I。*言论季刊*，22(2): 213–220。'
- en: OpenAI (2023) OpenAI, R. 2023. GPT-4 technical report. *arXiv*, arXiv preprint
    arXiv:2303.08774.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI, R. 2023. GPT-4技术报告。*arXiv*，arXiv预印本 arXiv:2303.08774。
- en: 'Ouyang et al. (2022) Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright,
    C.; Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.; et al. 2022. Training
    language models to follow instructions with human feedback. *Advances in neural
    information processing systems*, 35: 27730–27744.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ouyang 等 (2022) Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;
    Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.; 等. 2022. 训练语言模型按照指令执行并结合人类反馈。*神经信息处理系统进展*，35:
    27730–27744。'
- en: 'Park et al. (2023) Park, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.;
    Liang, P.; and Bernstein, M. S. 2023. Generative Agents: Interactive Simulacra
    of Human Behavior. *arXiv preprint arXiv:2304.03442*.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等 (2023) Park, J. S.; O’Brien, J. C.; Cai, C. J.; Morris, M. R.; Liang,
    P.; 和 Bernstein, M. S. 2023. 生成代理：人类行为的互动模拟。*arXiv预印本 arXiv:2304.03442*。
- en: Qian et al. (2023) Qian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y.; Xu, J.; Liu,
    Z.; and Sun, M. 2023. Communicative Agents for Software Development. *arXiv preprint
    arXiv:2207.07924*.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等 (2023) Qian, C.; Cong, X.; Yang, C.; Chen, W.; Su, Y.; Xu, J.; Liu, Z.;
    和 Sun, M. 2023. 软件开发中的交互式代理。*arXiv预印本 arXiv:2207.07924*。
- en: Radford et al. (2023) Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey,
    C.; and Sutskever, I. 2023. Robust speech recognition via large-scale weak supervision.
    In *International conference on machine learning*, 28492–28518\. PMLR.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford 等 (2023) Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.;
    和 Sutskever, I. 2023. 通过大规模弱监督实现鲁棒的语音识别。在*国际机器学习会议*，28492–28518。PMLR。
- en: 'Rafailov et al. (2024) Rafailov, R.; Sharma, A.; Mitchell, E.; Ermon, S.; Manning,
    C. D.; and Finn, C. 2024. Direct Preference Optimization: Your Language Model
    is Secretly a Reward Model. arXiv:2305.18290.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rafailov 等人（2024）Rafailov, R.; Sharma, A.; Mitchell, E.; Ermon, S.; Manning,
    C. D.; 和 Finn, C. 2024. 直接偏好优化：你的语言模型秘密地是一个奖励模型。arXiv:2305.18290。
- en: 'Reid et al. (2024) Reid, M.; Savinov, N.; Teplyashin, D.; Lepikhin, D.; Lillicrap,
    T.; Alayrac, J.-b.; Soricut, R.; Lazaridou, A.; Firat, O.; Schrittwieser, J.;
    et al. 2024. Gemini 1.5: Unlocking multimodal understanding across millions of
    tokens of context. *arXiv preprint arXiv:2403.05530*.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reid 等人（2024）Reid, M.; Savinov, N.; Teplyashin, D.; Lepikhin, D.; Lillicrap,
    T.; Alayrac, J.-b.; Soricut, R.; Lazaridou, A.; Firat, O.; Schrittwieser, J.;
    等人. 2024. Gemini 1.5：解锁跨越百万标记的多模态理解。*arXiv 预印本 arXiv:2403.05530*。
- en: 'Slonim et al. (2021) Slonim, N.; Bilu, Y.; Alzate, C.; Bar-Haim, R.; Bogin,
    B.; Bonin, F.; Choshen, L.; Cohen-Karlik, E.; Dankin, L.; Edelstein, L.; et al.
    2021. An autonomous debating system. *Nature*, 591(7850): 379–384.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Slonim 等人（2021）Slonim, N.; Bilu, Y.; Alzate, C.; Bar-Haim, R.; Bogin, B.; Bonin,
    F.; Choshen, L.; Cohen-Karlik, E.; Dankin, L.; Edelstein, L.; 等人. 2021. 一个自主辩论系统。*自然*,
    591(7850): 379–384。'
- en: 'Thueblood (1926) Thueblood, T. C. 1926. A chapter on the organization of college
    courses in public speaking. *Quarterly Journal of Speech*, 12(1): 1–11.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thueblood（1926）Thueblood, T. C. 1926. 一章关于大学公开演讲课程的组织。*演讲季刊*, 12(1): 1–11。'
- en: 'Touvron et al. (2023a) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.;
    Blecher, L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.;
    Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
    S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev,
    A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.;
    Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton,
    A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E. M.;
    Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J. X.;
    Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.; Rodriguez,
    A.; Stojnic, R.; Edunov, S.; and Scialom, T. 2023a. Llama 2: Open Foundation and
    Fine-Tuned Chat Models. arXiv:2307.09288.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等人（2023a）Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; Bikel, D.;
    Blecher, L.; Ferrer, C. C.; Chen, M.; Cucurull, G.; Esiobu, D.; Fernandes, J.;
    Fu, J.; Fu, W.; Fuller, B.; Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
    S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; Kloumann, I.; Korenev,
    A.; Koura, P. S.; Lachaux, M.-A.; Lavril, T.; Lee, J.; Liskovich, D.; Lu, Y.;
    Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poulton,
    A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, A.; Silva, R.; Smith, E.
    M.; Subramanian, R.; Tan, X. E.; Tang, B.; Taylor, R.; Williams, A.; Kuan, J.
    X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, S.;
    Rodriguez, A.; Stojnic, R.; Edunov, S.; 和 Scialom, T. 2023a. Llama 2：开放基础和微调聊天模型。arXiv:2307.09288。
- en: 'Touvron et al. (2023b) Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; et al. 2023b.
    Llama 2: Open foundation and fine-tuned chat models. *arXiv preprint arXiv:2307.09288*.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等人（2023b）Touvron, H.; Martin, L.; Stone, K.; Albert, P.; Almahairi,
    A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava, P.; Bhosale, S.; 等人. 2023b.
    Llama 2：开放基础和微调聊天模型。*arXiv 预印本 arXiv:2307.09288*。
- en: 'Tu et al. (2023) Tu, Q.; Chen, C.; Li, J.; Li, Y.; Shang, S.; Zhao, D.; Wang,
    R.; and Yan, R. 2023. CharacterChat: Learning towards Conversational AI with Personalized
    Social Support. *arXiv preprint arXiv:2308.10278*.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tu 等人（2023）Tu, Q.; Chen, C.; Li, J.; Li, Y.; Shang, S.; Zhao, D.; Wang, R.;
    和 Yan, R. 2023. CharacterChat：朝着个性化社会支持的对话式人工智能学习。*arXiv 预印本 arXiv:2308.10278*。
- en: Wachsmuth et al. (2024) Wachsmuth, H.; Lapesa, G.; Cabrio, E.; Lauscher, A.;
    Park, J.; Vecchi, E. M.; Villata, S.; and Ziegenbein, T. 2024. Argument Quality
    Assessment in the Age of Instruction-Following Large Language Models. arXiv:2403.16084.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wachsmuth 等人（2024）Wachsmuth, H.; Lapesa, G.; Cabrio, E.; Lauscher, A.; Park,
    J.; Vecchi, E. M.; Villata, S.; 和 Ziegenbein, T. 2024. 在指令跟随大型语言模型的时代，论证质量评估。arXiv:2403.16084。
- en: 'Wachsmuth et al. (2017a) Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; and Stein, B. 2017a. Computational argumentation
    quality assessment in natural language. In *Proceedings of the 15th Conference
    of the European Chapter of the Association for Computational Linguistics: Volume
    1, Long Papers*, 176–187.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wachsmuth 等人（2017a）Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; 和 Stein, B. 2017a. 自然语言中的计算论证质量评估。载于 *第15届欧洲计算语言学会会议论文集：第一卷，长篇论文*，176–187。
- en: 'Wachsmuth et al. (2017b) Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; and Stein, B. 2017b. Computational Argumentation
    Quality Assessment in Natural Language. In Lapata, M.; Blunsom, P.; and Koller,
    A., eds., *Proceedings of the 15th Conference of the European Chapter of the Association
    for Computational Linguistics: Volume 1, Long Papers*, 176–187\. Valencia, Spain:
    Association for Computational Linguistics.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wachsmuth 等人（2017b）Wachsmuth, H.; Naderi, N.; Hou, Y.; Bilu, Y.; Prabhakaran,
    V.; Thijm, T. A.; Hirst, G.; 和 Stein, B. 2017b. 自然语言中的计算论证质量评估。见 Lapata, M.; Blunsom,
    P.; 和 Koller, A.（编），*第十五届欧洲计算语言学会分会会议论文集：第一卷，长篇论文*，176–187。西班牙瓦伦西亚：计算语言学会。
- en: Walton, Reed, and Macagno (2008) Walton, D.; Reed, C.; and Macagno, F. 2008.
    Argumentation Schemes. In *Computer Science, Psychology*.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Walton, Reed 和 Macagno（2008）Walton, D.; Reed, C.; 和 Macagno, F. 2008. 论证模式。见
    *计算机科学，心理学*。
- en: 'Wang et al. (2023a) Wang, H.; Du, X.; Yu, W.; Chen, Q.; Zhu, K.; Chu, Z.; Yan,
    L.; and Guan, Y. 2023a. Apollo’s Oracle: Retrieval-Augmented Reasoning in Multi-Agent
    Debates. *arXiv preprint arXiv:2312.04854*.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023a）Wang, H.; Du, X.; Yu, W.; Chen, Q.; Zhu, K.; Chu, Z.; Yan, L.;
    和 Guan, Y. 2023a. Apollo’s Oracle：在多代理辩论中的检索增强推理。*arXiv 预印本 arXiv:2312.04854*。
- en: Wang et al. (2023b) Wang, L.; Ma, C.; Feng, X.; Zhang, Z.; Yang, H.; Zhang,
    J.; Chen, Z.; Tang, J.; Chen, X.; Lin, Y.; Zhao, W. X.; Wei, Z.; and Wen, J.-R.
    2023b. A Survey on Large Language Model Based Autonomous Agents. *arXiv preprint
    arXiv:2308.11432*.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023b）Wang, L.; Ma, C.; Feng, X.; Zhang, Z.; Yang, H.; Zhang, J.; Chen,
    Z.; Tang, J.; Chen, X.; Lin, Y.; Zhao, W. X.; Wei, Z.; 和 Wen, J.-R. 2023b. 基于大型语言模型的自主代理调查。*arXiv
    预印本 arXiv:2308.11432*。
- en: 'Wang et al. (2023c) Wang, L.; Zhang, J.; Yang, H.; Chen, Z.; Tang, J.; Zhang,
    Z.; Chen, X.; Lin, Y.; Song, R.; Zhao, W. X.; Xu, J.; Dou, Z.; Wang, J.; and Wen,
    J.-R. 2023c. When Large Language Model Based Agent Meets User Behavior Analysis:
    A Novel User Simulation Paradigm. *arXiv preprint arXiv:2306.02552*.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023c）Wang, L.; Zhang, J.; Yang, H.; Chen, Z.; Tang, J.; Zhang, Z.;
    Chen, X.; Lin, Y.; Song, R.; Zhao, W. X.; Xu, J.; Dou, Z.; Wang, J.; 和 Wen, J.-R.
    2023c. 当基于大型语言模型的代理遇到用户行为分析：一种新颖的用户模拟范式。*arXiv 预印本 arXiv:2306.02552*。
- en: Whitman (2005) Whitman, G. 2005. Formats of Debate. https://www.csun.edu/~dgw61315/debformats.html.
    Accessed on August 04, 2024.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whitman（2005）Whitman, G. 2005. 辩论格式。https://www.csun.edu/~dgw61315/debformats.html。访问于2024年8月4日。
- en: 'Wu et al. (2023) Wu, Q.; Bansal, G.; Zhang, J.; Wu, Y.; Li, B.; Zhu, E.; Jiang,
    L.; Zhang, X.; Zhang, S.; Liu, J.; Awadallah, A. H.; White, R. W.; Burger, D.;
    and Wang, C. 2023. AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent
    Conversation. arXiv:2308.08155.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2023）Wu, Q.; Bansal, G.; Zhang, J.; Wu, Y.; Li, B.; Zhu, E.; Jiang, L.;
    Zhang, X.; Zhang, S.; Liu, J.; Awadallah, A. H.; White, R. W.; Burger, D.; 和 Wang,
    C. 2023. AutoGen：通过多代理对话实现下一代大型语言模型应用。arXiv:2308.08155。
- en: Yang et al. (2024) Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.;
    Li, C.; Li, C.; Liu, D.; Huang, F.; et al. 2024. Qwen2 technical report. *arXiv
    preprint arXiv:2407.10671*.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2024）Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.; Li, C.;
    Li, C.; Liu, D.; Huang, F.; 等人. 2024. Qwen2 技术报告。*arXiv 预印本 arXiv:2407.10671*。
- en: Zheng et al. (2023) Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.;
    Zhuang, Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez, J. E.;
    and Stoica, I. 2023. Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv:2306.05685.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人（2023）Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.; Zhuang,
    Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez, J. E.; 和 Stoica,
    I. 2023. 使用 MT-Bench 和 Chatbot Arena 判断大型语言模型作为裁判的表现。arXiv:2306.05685。
- en: Appendix
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: Further Analysis of Elo Rankings
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步分析 Elo 排名
- en: Competitive Debate Arena currently includes only Chinese debate records. This
    choice is based on the availability of professional Chinese debate judges, ensuring
    the reliability of our Elo ranking system. However, Agent4Debate is designed to
    support competitive debates in other languages, including English, using the same
    structural framework. Expanding to multilingual debates would require only minor
    adjustments to the language constraints in the prompts. Future research may explore
    the implementation of debates in various languages.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争辩论平台目前仅包含中文辩论记录。此选择基于专业中文辩论裁判的可用性，确保了我们的 Elo 排名系统的可靠性。然而，Agent4Debate 设计上支持使用相同的结构框架进行其他语言（包括英语）的竞争性辩论。扩展到多语言辩论只需对提示中的语言约束做些微调。未来的研究可能会探索实现多种语言辩论的可行性。
- en: '| Model | Debatrix-CI | Human-CI |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Debatrix-CI | Human-CI |'
- en: '| --- | --- | --- |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Gemini-1.5-Pro | + 69/- 18 | + 57/- 14 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-Pro | + 69/- 18 | + 57/- 14 |'
- en: '| Claude-3.5-sonnet | + 67/- 18 | + 54/- 14 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5-sonnet | + 67/- 18 | + 54/- 14 |'
- en: '| Qwen2-72b-instruct | + 66/- 20 | + 54/- 15 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| Qwen2-72b-instruct | + 66/- 20 | + 54/- 15 |'
- en: '| GPT-4o | + 66/- 20 | + 58/- 14 |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | + 66/- 20 | + 58/- 14 |'
- en: '| Gemini-1.5-flash | + 66/- 18 | + 53/- 15 |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5-flash | + 66/- 18 | + 53/- 15 |'
- en: '| GLM-4-Air | + 67/- 16 | + 48/- 19 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| GLM-4-Air | + 67/- 16 | + 48/- 19 |'
- en: '| Deepseek-chat | + 64/- 22 | + 44/- 19 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| Deepseek-chat | + 64/- 22 | + 44/- 19 |'
- en: '| baseline (Claude-3.5-sonnet) | + 69/- 36 | + 51/- 31 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 基准（Claude-3.5-sonnet） | + 69/- 36 | + 51/- 31 |'
- en: '| Human | + 64/- 550 | + 50/- 22 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | + 64/- 550 | + 50/- 22 |'
- en: '| baseline (Deepseek-chat) | + 62/- 530 | + 32/- 520 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 基准（Deepseek-chat） | + 62/- 530 | + 32/- 520 |'
- en: 'Table 7: 95% Confidence Intervals'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：95% 置信区间
- en: Table [7](https://arxiv.org/html/2408.04472v2#Ax1.T7 "Table 7 ‣ Further Analysis
    of Elo Rankings ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") presents the 95% confidence intervals (CI)
    for various models and human performance, as evaluated by both the Debatrix-Elo
    and Human-Elo rankings. The CIs are expressed as upper and lower bounds relative
    to the median scores. Based on experimental results, we estimate that new debate
    models or frameworks can achieve a relatively stable ranking after about 15 debates.
    This allows for quick assessment of their competitive debate performance. Models
    with lower win rates show wider CIs (like baseline (Deepseek-Chat)), especially
    in the lower bound. However, this does not significantly affect the evaluation
    of their debate performance. The wider CIs mainly reflect the increased uncertainty
    in precise ranking for these models.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [7](https://arxiv.org/html/2408.04472v2#Ax1.T7 "Table 7 ‣ Further Analysis
    of Elo Rankings ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") 展示了各种模型和人类表现的 95% 置信区间（CI），该评估是基于 Debatrix-Elo
    和 Human-Elo 排名的。置信区间以相对于中位数分数的上下限形式表示。根据实验结果，我们估计新的辩论模型或框架在约 15 场辩论后能够达到相对稳定的排名。这使得对其竞争性辩论表现的评估变得更加快捷。胜率较低的模型展示了较宽的置信区间（如基准（Deepseek-Chat）），特别是在下限部分。然而，这并不会显著影响对其辩论表现的评估。较宽的置信区间主要反映了这些模型精确排名的不确定性增加。
- en: The Elo system can be used to estimate the winning rate of competitive debates
    between models. Figure [3](https://arxiv.org/html/2408.04472v2#Ax1.F3 "Figure
    3 ‣ Further Analysis of Elo Rankings ‣ Appendix ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate") presents the win rate
    calculated using the Debatrix-elo and Human-elo rankings, respectively.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Elo 系统可以用来估算模型之间竞争性辩论的胜率。图 [3](https://arxiv.org/html/2408.04472v2#Ax1.F3 "Figure
    3 ‣ Further Analysis of Elo Rankings ‣ Appendix ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate") 展示了分别使用 Debatrix-elo
    和 Human-elo 排名计算的胜率。
- en: '![Refer to caption](img/98f6f6c353c88ffc52e513779289f268.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/98f6f6c353c88ffc52e513779289f268.png)'
- en: 'Figure 3: Predicted Win Rates Using Elo Rankings for Model A in A vs. B Battles.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：使用 Elo 排名预测的 Model A 在 A 对 B 战斗中的胜率。
- en: Further Analysis of Agent4Debate
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Agent4Debate 的进一步分析
- en: As shown in Table [8](https://arxiv.org/html/2408.04472v2#Ax1.T8 "Table 8 ‣
    Further Analysis of Agent4Debate ‣ Appendix ‣ Can LLMs Beat Humans in Debating?
    A Dynamic Multi-agent Framework for Competitive Debate"), the interaction frequency
    data reveals distinct patterns across debate stages. The Searcher role shows peak
    activity during the Argument stage (3.4431), while the Writer’s interactions are
    highest in the Summary stage (3.0932). The Reviewer maintains consistently high
    engagement throughout all stages. In contrast, the Analyzer exhibits a stable,
    low interaction frequency (approximately 1.0) across all phases. Notably, the
    Searcher’s high activity in the Stage 1 is due to its proactive information-seeking
    role, whereas in subsequent stages (Rebuttal and Summary), it assumes a more passive
    stance, resulting in lower interaction frequencies. These patterns suggest varied
    role importance and engagement levels at different debate stages, with the Analyzer
    serving as an efficient, low-interaction information processor throughout the
    process.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 [8](https://arxiv.org/html/2408.04472v2#Ax1.T8 "Table 8 ‣ Further Analysis
    of Agent4Debate ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") 所示，互动频率数据揭示了不同辩论阶段的不同模式。Searcher 角色在 Argument
    阶段（3.4431）表现出最高的活动量，而 Writer 的互动在 Summary 阶段（3.0932）最为频繁。Reviewer 在所有阶段中始终保持较高的参与度。相比之下，Analyzer
    在各个阶段的互动频率较低（约为 1.0）。值得注意的是，Searcher 在 Stage 1 的高活动量源于其主动的信息搜寻角色，而在后续阶段（Rebuttal
    和 Summary）中，它采取了较为被动的立场，导致互动频率较低。这些模式表明了不同角色在不同辩论阶段的重要性和参与度的差异，Analyzer 在整个过程中作为一个高效的、低互动的信息处理者。
- en: '| Stage | Searcher | Analyzer | Writer | Reviewer |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | Searcher | Analyzer | Writer | Reviewer |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Overall | 2.1862 | 1.0015 | 2.7243 | 2.4888 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 总体 | 2.1862 | 1.0015 | 2.7243 | 2.4888 |'
- en: '| Stage 1 | 3.4431 | 1.0036 | 2.4313 | 2.1682 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 1 | 3.4431 | 1.0036 | 2.4313 | 2.1682 |'
- en: '| Stage 2 | 1.3435 | 1.0000 | 2.7939 | 2.5817 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 2 | 1.3435 | 1.0000 | 2.7939 | 2.5817 |'
- en: '| Stage 3 | 1.2559 | 1.0000 | 3.0932 | 2.8720 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 3 | 1.2559 | 1.0000 | 3.0932 | 2.8720 |'
- en: 'Table 8: Interaction Frequencies of Roles Across Debate Stages in the Agent4Debate'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 8：Agent4Debate 中不同角色在辩论各阶段的交互频率
- en: Table [9](https://arxiv.org/html/2408.04472v2#Ax1.T9 "Table 9 ‣ Further Analysis
    of Agent4Debate ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") illustrates the average token usage (only calculated
    completion token) per utterance for each agent. The Searcher, responsible for
    collecting and organizing information, shows the highest token consumption (2182.90).
    The Analyzer and Writer exhibit similar token usage (795.06 and 811.94 respectively).
    The Reviewer, tasked with providing feedback, has the lowest token consumption
    (415.57), consistent with its role in offering concise critiques. These token
    consumption patterns align well with the intended functions of each role in our
    multi-agent framework design, with the Searcher’s high token usage emphasizing
    its critical role in information processing.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [9](https://arxiv.org/html/2408.04472v2#Ax1.T9 "表格 9 ‣ Agent4Debate 的进一步分析
    ‣ 附录 ‣ LLM 是否能击败人类辩论？一个用于竞争辩论的动态多智能体框架") 显示了每个智能体每次发言的平均 token 使用量（仅计算完成的 token）。负责收集和整理信息的搜索者消耗了最多的
    token（2182.90）。分析者和写作人表现出相似的 token 使用量（分别为 795.06 和 811.94）。审阅者负责提供反馈，消耗的 token
    最少（415.57），这与其提供简洁评价的角色一致。这些 token 消耗模式与我们多智能体框架设计中每个角色的预期功能非常吻合，搜索者的高 token 使用强调了其在信息处理中的关键角色。
- en: '| Token | Searcher | Analyzer | Writer | Reviewer |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| Token | 搜索者 | 分析者 | 写作人 | 审阅者 |'
- en: '| Completion | 2182.90 | 795.06 | 811.94 | 415.57 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 完成度 | 2182.90 | 795.06 | 811.94 | 415.57 |'
- en: 'Table 9: Token completion counts for different agents'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 9：不同智能体的 token 完成计数
- en: Prompts
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: This section outlines the prompt design principles for Agent4Debate. Due to
    space constraints, we provide only key examples here, with the complete set of
    prompts available in the Github Repository³³3https://github.com/ZhangYiqun018/agent-for-debate.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述了 Agent4Debate 的提示设计原则。由于空间限制，我们这里只提供了关键示例，完整的提示集可在 Github 仓库中找到³³3https://github.com/ZhangYiqun018/agent-for-debate。
- en: 'Agent4Debate employs a conversational multi-agent collaborative structure without
    implicit long-term memory. All information is stored within the dialogue context,
    accessible to each agent during their turn. The prompt design for each agent consists
    of five components: profile, knowledge, workflow, rules, and output format.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Agent4Debate 采用一种对话式的多智能体协作结构，没有隐含的长期记忆。所有信息都存储在对话上下文中，每个智能体在轮到自己时可以访问这些信息。每个智能体的提示设计包含五个组件：个人简介、知识、工作流、规则和输出格式。
- en: 'The profile contains basic agent information. For instance, the Analyzer’s
    profile might state: ”You are an experienced debate coach tasked with analyzing
    debate motions, stances, and relevant materials.” The knowledge component stores
    debate-related information and techniques specific to the task of agent. For example,
    the Writer agent for the constructive argument (Stage 1) would have prompts on
    proof techniques, while Stage 2 Writer would have prompts on logical fallacies
    and rebuttal strategies. The workflow component outlines the specific steps for
    task completion, ensuring each agent follows a chain-of-thought (CoT) process.
    The rules component lists guidelines to prevent low-quality responses. Finally,
    the output format defines the structure of the response of agent.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 个人简介包含基本的智能体信息。例如，分析者的简介可能会写道：“你是一个经验丰富的辩论教练，负责分析辩论议题、立场和相关材料。”知识组件存储与任务相关的辩论信息和技巧。举例来说，阶段
    1 的写作人会有关于证明技巧的提示，而阶段 2 的写作人则会有关于逻辑谬误和反驳策略的提示。工作流组件概述了任务完成的具体步骤，确保每个智能体都遵循一个思维链（CoT）过程。规则组件列出了防止低质量回应的指南。最后，输出格式定义了智能体回应的结构。
- en: Each agent is guided by prompts with similar structures but varying content
    across different debate stages, ensuring task completion at each stage.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 每个智能体都通过具有相似结构的提示进行指导，但不同辩论阶段的内容各不相同，以确保每个阶段的任务完成。
- en: Case Study
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究
- en: 'Figures [4](https://arxiv.org/html/2408.04472v2#Ax1.F4 "Figure 4 ‣ Case Study
    ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework
    for Competitive Debate") to [7](https://arxiv.org/html/2408.04472v2#Ax1.F7 "Figure
    7 ‣ Case Study ‣ Appendix ‣ Can LLMs Beat Humans in Debating? A Dynamic Multi-agent
    Framework for Competitive Debate") show case studies of two debate motions: one
    on the correlation between justice and interest and another on implementing a
    fat tax in developed countries. Each motion is shown in English and Chinese, with
    the English versions translated from Chinese using Claude-3.5-sonnet. These case
    studies demonstrate the application of Agent4Debate using different foundation
    models, including GPT-4o, Claude-3.5-sonnet, and Gemini-1.5-Pro. Due to space
    limitations, references for the case studies have been omitted.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4](https://arxiv.org/html/2408.04472v2#Ax1.F4 "图 4 ‣ 案例分析 ‣ 附录 ‣ 大型语言模型能否击败人类辩论？一个动态多智能体框架用于竞争性辩论")
    至 [7](https://arxiv.org/html/2408.04472v2#Ax1.F7 "图 7 ‣ 案例分析 ‣ 附录 ‣ 大型语言模型能否击败人类辩论？一个动态多智能体框架用于竞争性辩论")
    展示了两场辩论的案例分析：一场关于正义与利益之间的关联，另一场关于在发达国家实施肥胖税。每个辩题分别以英语和中文展示，英语版本由Claude-3.5-sonnet从中文翻译。这些案例分析展示了Agent4Debate应用不同基础模型的情况，包括GPT-4o、Claude-3.5-sonnet和Gemini-1.5-Pro。由于篇幅限制，案例分析的参考文献被省略。
- en: '![Refer to caption](img/a4be78e77ddc8b7cf84e1f2ad70e97ad.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a4be78e77ddc8b7cf84e1f2ad70e97ad.png)'
- en: 'Figure 4: English (translated by Claude-3.5-sonnet from Chinese) case study
    of the debate motion ”Justice is nothing but interest. (Pro side) / Justice is
    nothing more than interest (Con side)”. Pro side is Agent4Debate (GPT-4o), Con
    side is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：英语版（由Claude-3.5-sonnet从中文翻译）关于辩题“正义不过是利益。（正方）/ 正义不过是利益（反方）”的案例分析。正方是Agent4Debate（GPT-4o），反方是Agent4Debate（Claude-3.5-sonnet）。
- en: '![Refer to caption](img/d3eed3d6f53d4630c05431943cceffb2.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d3eed3d6f53d4630c05431943cceffb2.png)'
- en: 'Figure 5: Chinese case study of the debate motion ”Justice is nothing but interest.
    (Pro side) / Justice is nothing more than interest (Con side)”. Pro side is Agent4Debate
    (GPT-4o), Con side is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：中文版本关于辩题“正义不过是利益。（正方）/ 正义不过是利益（反方）”的案例分析。正方是Agent4Debate（GPT-4o），反方是Agent4Debate（Claude-3.5-sonnet）。
- en: '![Refer to caption](img/5287f57d844534bc164e163d73b74e80.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5287f57d844534bc164e163d73b74e80.png)'
- en: 'Figure 6: English (translated by Claude-3.5-sonnet from Chinese) case study
    of the debate motion ”Developed countries should (Pro side) / should not (Con
    side) impose a fat tax.”. Pro side is Agent4Debate (Gemini-1.5-Pro), Con side
    is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：英语版（由Claude-3.5-sonnet从中文翻译）关于辩题“发达国家应当（正方）/ 不应当（反方）征收肥胖税”的案例分析。正方是Agent4Debate（Gemini-1.5-Pro），反方是Agent4Debate（Claude-3.5-sonnet）。
- en: '![Refer to caption](img/bd7d990e2b3aaa12f6f02b620b14c831.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bd7d990e2b3aaa12f6f02b620b14c831.png)'
- en: 'Figure 7: Chinese case study of the debate motion ”Developed countries should
    (Pro side) / should not (Con side) impose a fat tax.”. Pro side is Agent4Debate
    (Gemini-1.5-Pro), Con side is Agent4Debate (Claude-3.5-sonnet).'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：中文版本关于辩题“发达国家应当（正方）/ 不应当（反方）征收肥胖税”的案例分析。正方是Agent4Debate（Gemini-1.5-Pro），反方是Agent4Debate（Claude-3.5-sonnet）。
