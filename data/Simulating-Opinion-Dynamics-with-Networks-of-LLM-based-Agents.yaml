- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '<!--yml  '
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 13:01:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期：2025-01-11 13:01:54  '
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '-->  '
- en: Simulating Opinion Dynamics with Networks of LLM-based Agents
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '使用基于大语言模型的代理网络模拟舆论动态  '
- en: 来源：[https://arxiv.org/html/2311.09618/](https://arxiv.org/html/2311.09618/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '来源：[https://arxiv.org/html/2311.09618/](https://arxiv.org/html/2311.09618/)  '
- en: Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '云修安·庄，阿甘·戈亚尔，尼昆·哈尔拉卡，悉达多·苏雷什，  '
- en: Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '罗伯特·霍金斯，杨思佳，达凡·沙，胡俊杰，蒂莫西·T·罗杰斯  '
- en: University of Wisconsin-Madison
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '威斯康星大学麦迪逊分校  '
- en: '{yunshiuan.chuang,agoyal25,nharlalka,siddharth.suresh}@wisc.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{yunshiuan.chuang,agoyal25,nharlalka,siddharth.suresh}@wisc.edu  '
- en: '{rdhawkins, syang84, dshah, junjie.hu, ttrogers}@wisc.edu'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '{rdhawkins, syang84, dshah, junjie.hu, ttrogers}@wisc.edu  '
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '摘要  '
- en: 'Accurately simulating human opinion dynamics is crucial for understanding a
    variety of societal phenomena, including polarization and the spread of misinformation.
    However, the agent-based models (ABMs) commonly used for such simulations often
    over-simplify human behavior. We propose a new approach to simulating opinion
    dynamics based on populations of Large Language Models (LLMs). Our findings reveal
    a strong inherent bias in LLM agents towards producing accurate information, leading
    simulated agents to consensus in line with scientific reality. This bias limits
    their utility for understanding resistance to consensus views on issues like climate
    change. After inducing confirmation bias through prompt engineering, however,
    we observed opinion fragmentation in line with existing agent-based modeling and
    opinion dynamics research. These insights highlight the promise and limitations
    of LLM agents in this domain and suggest a path forward: refining LLMs with real-world
    discourse to better simulate the evolution of human beliefs. ¹¹1Code and data
    are publicly available at [https://github.com/yunshiuan/llm-agent-opinion-dynamics](https://github.com/yunshiuan/llm-agent-opinion-dynamics)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '准确模拟人类舆论动态对理解多种社会现象至关重要，包括极化和虚假信息的传播。然而，常用的基于代理的模型（ABM）通常简化了人类行为。我们提出了一种新的舆论动态模拟方法，基于大语言模型（LLM）群体。我们的研究发现，大语言模型代理在产生准确信息方面具有强烈的固有偏向，这导致模拟的代理形成与科学现实一致的共识。这种偏向限制了它们在理解对气候变化等问题的共识抗拒时的应用。然而，通过提示工程引导确认偏误后，我们观察到与现有的基于代理的建模和舆论动态研究一致的舆论分裂。这些发现突显了大语言模型代理在这一领域的潜力与局限，并提出了前进的路径：通过现实世界的言论来完善大语言模型，更好地模拟人类信仰的演变。¹¹1代码和数据可以在
    [https://github.com/yunshiuan/llm-agent-opinion-dynamics](https://github.com/yunshiuan/llm-agent-opinion-dynamics)
    上公开获取  '
- en: Simulating Opinion Dynamics with Networks of LLM-based Agents
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '使用基于大语言模型的代理网络模拟舆论动态  '
- en: Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh, Robert Hawkins,
    Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers University of Wisconsin-Madison
    {yunshiuan.chuang,agoyal25,nharlalka,siddharth.suresh}@wisc.edu {rdhawkins, syang84,
    dshah, junjie.hu, ttrogers}@wisc.edu
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '云修安·庄，阿甘·戈亚尔，尼昆·哈尔拉卡，悉达多·苏雷什，罗伯特·霍金斯，杨思佳，达凡·沙，胡俊杰，蒂莫西·T·罗杰斯，威斯康星大学麦迪逊分校 {yunshiuan.chuang,agoyal25,nharlalka,siddharth.suresh}@wisc.edu
    {rdhawkins, syang84, dshah, junjie.hu, ttrogers}@wisc.edu  '
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '1 引言  '
- en: Understanding how individuals change their opinions as a function of social
    influences is critical across multiple domains, from public health campaigns,
    conflict mediation, to misinformation mitigation Lu et al. ([2015](https://arxiv.org/html/2311.09618v4#bib.bib22));
    Pennycook et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib29)); Budak
    et al. ([2011](https://arxiv.org/html/2311.09618v4#bib.bib1)); Loomba et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib20));
    Ginossar et al. ([2022](https://arxiv.org/html/2311.09618v4#bib.bib12)). Accurate
    models of these dynamics would allow us to forecast future trends, such as potential
    opinion polarization, but also to devise targeted interventions to alleviate negative
    impacts.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '理解个体如何根据社会影响变化其意见，在多个领域中至关重要，从公共卫生活动、冲突调解到虚假信息缓解（Lu et al. ([2015](https://arxiv.org/html/2311.09618v4#bib.bib22));
    Pennycook et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib29)); Budak
    et al. ([2011](https://arxiv.org/html/2311.09618v4#bib.bib1)); Loomba et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib20));
    Ginossar et al. ([2022](https://arxiv.org/html/2311.09618v4#bib.bib12))）。准确的舆论动态模型不仅能让我们预测未来趋势，如可能的舆论极化，还能帮助我们设计有针对性的干预措施，减轻负面影响。  '
- en: 'Figure 1: Contrast between LLM generative agents and classic Agent-Based Models
    (ABMs). While both can simulate opinion dynamics, LLM generative agents use natural
    language for input ($x_{input}$) and output ($x_{output}$), maintain beliefs ($m^{t}$),
    and employ transformer-based LLM for belief updating. In contrast, classic ABMs
    use numerical values for input and output, maintain beliefs ($o^{t}$), and use
    hand-crafted equations for belief updating.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：LLM生成型代理与经典基于代理的模型（ABMs）之间的对比。尽管两者都可以模拟意见动态，LLM生成型代理使用自然语言作为输入（$x_{input}$）和输出（$x_{output}$），保持信念（$m^{t}$），并采用基于变换器的LLM进行信念更新。相比之下，经典ABMs使用数值作为输入和输出，保持信念（$o^{t}$），并使用手工编写的方程式进行信念更新。
- en: Agent-based models (ABMs) are a cornerstone approach to opinion dynamics Gilbert
    and Terna ([2000](https://arxiv.org/html/2311.09618v4#bib.bib11)); Smaldino ([2023](https://arxiv.org/html/2311.09618v4#bib.bib30));
    Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)); Chuang
    and Rogers ([2023](https://arxiv.org/html/2311.09618v4#bib.bib5)); Epstein ([2012](https://arxiv.org/html/2311.09618v4#bib.bib8)).
    ABMs represent individuals as agents by using mathematical equations that characterize
    how opinions might shift from inter-agent communications. As simulated agents
    interact, these computations can then elucidate the evolution of group opinion
    dynamics. For instance, when simulated agents incorporate confirmation bias in
    belief updates, they tend to gravitate towards opinion clusters rather than a
    consensus Flache et al. ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的模型（ABMs）是意见动态研究的基石方法，Gilbert 和 Terna ([2000](https://arxiv.org/html/2311.09618v4#bib.bib11));
    Smaldino ([2023](https://arxiv.org/html/2311.09618v4#bib.bib30)); Lorenz 等人 ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21));
    Chuang 和 Rogers ([2023](https://arxiv.org/html/2311.09618v4#bib.bib5)); Epstein
    ([2012](https://arxiv.org/html/2311.09618v4#bib.bib8))。ABMs通过使用数学方程来表示个体作为代理，并描述意见如何在代理之间的互动中发生变化。随着模拟代理的互动，这些计算能够揭示群体意见动态的演变。例如，当模拟代理在信念更新中融入确认偏差时，它们往往趋向于意见聚类，而非达成共识，Flache
    等人 ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10))。
- en: 'Figure 2: (a) Schematic of the LLM agent network designed to simulate opinion
    dynamics across various topics, including global warming as a potential conspiracy.
    The network consists of agents, each role-playing a unique persona, with initial
    beliefs spanning acceptance, rejection, and neutrality regarding claims with known
    scientific consensus. Through the iterative cycles of writing and sharing tweets
    within their network connections, these agents’ opinions evolve due to social
    influence. (b) An agent’s memory $m_{i}^{t}$, including (1) initial persona, (2)
    optional closed-world restriction, (3) optional cognitive bias, and (4) historical
    events up to time $t$. Memory can be either cumulative (left) or reflective (right).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：（a）LLM代理网络的示意图，旨在模拟跨多个话题的意见动态，包括将全球变暖视为潜在阴谋。该网络由代理组成，每个代理扮演一个独特的角色，初始信念涵盖了对有已知科学共识的主张的接受、拒绝和中立态度。通过在其网络连接内撰写和分享推文的反复循环，这些代理的意见因社会影响而发生变化。（b）一个代理的记忆
    $m_{i}^{t}$，包括（1）初始角色，（2）可选的封闭世界限制，（3）可选的认知偏差，以及（4）截至时间 $t$ 的历史事件。记忆可以是累积的（左）或反思性的（右）。
- en: Traditional ABMs have critical limitations (Figure [1](https://arxiv.org/html/2311.09618v4#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")). First, ABMs often require beliefs and messages to be mapped to numerical
    values (e.g., assuming an agent maintains a scalar opinion $o\in\mathbb{R}$ and
    communicates with scalar signals $x\in\mathbb{R}$), overlooking the intricate
    linguistic nuances of real-life conversation. Additionally, ABMs typically consist
    of rule-based agents, thus falling short of simulating the complex interactions
    between real human agents. Moreover, ABMs cannot directly incorporate realistic
    variability in demographic background, worldviews, ideology, personality, among
    many. This gap highlights the importance of advanced models that better capture
    the richness of individual variances in human beings.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的ABMs存在重大局限性（图[1](https://arxiv.org/html/2311.09618v4#S1.F1 "图1 ‣ 1 引言 ‣ 使用基于LLM的代理网络模拟意见动态")）。首先，ABMs通常需要将信念和信息映射到数值（例如，假设一个代理保持标量意见
    $o\in\mathbb{R}$ 并与标量信号 $x\in\mathbb{R}$ 进行交流），忽视了现实对话中语言的复杂细微差别。此外，ABMs通常由基于规则的代理组成，因此未能模拟现实人类代理之间复杂的互动。而且，ABMs无法直接融入人口背景、世界观、意识形态、个性等方面的现实变异性。这一差距凸显了高级模型的重要性，这些模型能够更好地捕捉个体在人类行为中的多样性。
- en: This paper considers whether large language models (LLMs) can be used to support
    sophisticated simulation of agent interactions, potentially providing a more realistic
    tool for understanding *opinion dynamics*. To this end, this paper describes an
    initial step toward a general framework by focusing on communicative interactions
    amongst small social groups. Specifically, we explore the insights offered by
    contemporary LLMs as an alternative to commonly-used ABMs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了大语言模型（LLMs）是否可以用于支持复杂的代理人互动仿真，从而为理解*意见动态*提供更现实的工具。为此，本文描述了迈向通用框架的初步步骤，重点关注小型社交群体中的沟通互动。具体而言，我们探索了当代LLM提供的见解，作为常用的基于代理模型（ABM）的替代方案。
- en: Following recent studies on populations of generative agents (Park et al., [2023](https://arxiv.org/html/2311.09618v4#bib.bib27)),
    we simulate multi-agent conversations across various topics, and manipulate factors
    such as confirmation bias and memory update function to study their effects on
    opinion evolution. Our findings highlight both the potential and limitations of
    using LLM agents to simulate human-like opinion dynamics. Critically, we show
    that LLM agents tend to converge towards denying inaccurate information, regardless
    of the personas they role-play, limiting their authenticity when emulating people
    with fact-resistant viewpoints. Furthermore, we demonstrate the feasibility of
    introducing human-like confirmation bias into the creation of more stubborn LLM
    agents.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 继近期关于生成代理人群体的研究（Park et al., [2023](https://arxiv.org/html/2311.09618v4#bib.bib27)），我们模拟了多代理人之间围绕各种话题的对话，并操作如确认偏差和记忆更新函数等因素，研究它们对意见演变的影响。我们的研究结果揭示了使用LLM代理人模拟类人意见动态的潜力与局限性。关键在于，我们展示了LLM代理人倾向于否定不准确的信息，无论他们扮演的角色是什么，这限制了它们在模拟持有抗事实观点的人的真实性。此外，我们还展示了将类人的确认偏差引入到更固执的LLM代理人创建中的可行性。
- en: 2 Methods
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 方法
- en: 2.1 Simulating Opinion Dynamics
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 模拟意见动态
- en: 'Figure 3: Experimental setup for simulating opinion dynamics in agent interactions.
    At each time step $t$, agent $a_{i}$ writes a tweet $x_{i}^{t}$, which is subsequently
    presented to agent $a_{j}$. The agent $a_{j}$ then reports their thought $r_{j}^{t}$,
    which is processed by a classifier to yield a numerical opinion $o_{j}^{t}$. Both
    agents update their respective memory modules, $m_{i}^{t}$ and $m_{j}^{t}$, after
    writing or reviewing a tweet, which informs their future behaviors.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：用于模拟代理人互动中意见动态的实验设置。在每个时间步骤$t$，代理人$a_{i}$发布一条推文$x_{i}^{t}$，然后这条推文呈现给代理人$a_{j}$。接着，代理人$a_{j}$报告他们的想法$r_{j}^{t}$，该想法通过分类器处理后生成一个数值化的意见$o_{j}^{t}$。两位代理人在发布或查看推文后，都会更新各自的记忆模块$m_{i}^{t}$和$m_{j}^{t}$，以此来影响他们未来的行为。
- en: 'Input: $N$ agent personas $\{per_{i}\}_{i=1}^{N}$,# time steps $T$, opinion
    classifier $f_{\text{oc}}$Output: Opinion trajectories $\langle o_{i}\rangle$
    for each agent $a_{i}$1 for *$i=1$ to $N$* do2       Initialize agent $a_{i}$
    with persona $per_{i}$ (includes initial opinion $o_{i}^{t=0}$), memory $m_{i}^{t=0}$3      
    (Optional) Inject cognitive bias and closed-world restriction4       Initialize
    opinion trajectory $\langle o_{i}\rangle=\{o_{i}^{t=0}\}$5      6for *$t=1$ to
    $T$* do7       Select random pair $\{a_{i},a_{j}\}$, with $i\neq j$8       Agent
    $a_{i}$ writes tweet $x_{i}^{t}$9       Agent $a_{j}$ reports their verbal opinion
    $r_{j,t}$10       Classify opinion: $o_{j}=f_{\text{oc}}(r_{j}^{t})$; append to
    $\langle o_{j}\rangle$11       Update memory: $m_{i}^{t+1}$, $m_{j}^{t+1}$ using
    $f_{mu}$12      return *$\langle o_{i}\rangle$ for each agent $a_{i}$*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：$N$ 个代理人角色 $\{per_{i}\}_{i=1}^{N}$，# 时间步骤 $T$，意见分类器 $f_{\text{oc}}$输出：每个代理人$a_{i}$的意见轨迹
    $\langle o_{i}\rangle$1 for *$i=1$ to $N$* do2       初始化代理人 $a_{i}$，并分配角色 $per_{i}$（包括初始意见
    $o_{i}^{t=0}$），记忆 $m_{i}^{t=0}$3       （可选）注入认知偏差和封闭世界限制4       初始化意见轨迹 $\langle
    o_{i}\rangle=\{o_{i}^{t=0}\}$5      6for *$t=1$ to $T$* do7       随机选择一对代理人 $\{a_{i},a_{j}\}$，其中
    $i\neq j$8       代理人 $a_{i}$ 发布推文 $x_{i}^{t}$9       代理人 $a_{j}$ 报告他们的口头意见 $r_{j,t}$10      
    分类意见：$o_{j}=f_{\text{oc}}(r_{j}^{t})$；附加到 $\langle o_{j}\rangle$11       更新记忆：$m_{i}^{t+1}$，$m_{j}^{t+1}$
    使用 $f_{mu}$12      返回 *$\langle o_{i}\rangle$ 对于每个代理人 $a_{i}$*
- en: Algorithm 1 Simulation of Opinion Dynamics with LLM Agents
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 算法1 使用LLM代理人模拟意见动态
- en: In this section, we present our framework for simulating opinion dynamics among
    LLM agents in multi-turn conversations, as shown in Figure [2](https://arxiv.org/html/2311.09618v4#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")a,  [3](https://arxiv.org/html/2311.09618v4#S2.F3 "Figure 3 ‣ 2.1 Simulating
    Opinion Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents"), and Algorithm [1](https://arxiv.org/html/2311.09618v4#alg1 "In 2.1 Simulating
    Opinion Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents"). We consider a *dyadic* setting, where one speaker and one listener agent
    is chosen on each time step to (1) emit a message and (2) update beliefs, respectively.
    This setting is standard in the opinion dynamics literature Flache et al. ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10));
    Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)). We defer
    more general settings, such as one-to-many communication, to future work.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了一个框架，用于模拟LLM代理在多轮对话中的意见动态，如图[2](https://arxiv.org/html/2311.09618v4#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")a、[3](https://arxiv.org/html/2311.09618v4#S2.F3 "Figure 3 ‣ 2.1 Simulating
    Opinion Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")和算法[1](https://arxiv.org/html/2311.09618v4#alg1 "In 2.1 Simulating Opinion
    Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")所示。我们考虑一个*双向*设置，在每个时间步中选择一个说话者和一个听众代理，分别进行（1）发送消息和（2）更新信念的操作。这个设置在意见动态文献中是标准的，例如Flache等人（[2017](https://arxiv.org/html/2311.09618v4#bib.bib10)）；Lorenz等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）。我们将更一般的设置，如一对多沟通，留待未来的工作中讨论。
- en: Formally, we begin with a pool of $N$ LLM agents $\mathcal{A}=\{a_{1},\cdots,a_{N}\}$
    and a topic $p$. Each agent is initialized with a distinct persona, including
    an initial opinion, in their memory structure (described in §[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2
    "2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") and Figure [2](https://arxiv.org/html/2311.09618v4#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")b). At each time step $t$, a pair of agents $A^{t}=\{a_{i},a_{j}\}$ with
    $i\neq j$ is sampled uniformly from the population to interact. First, agent $a_{i}$
    composes a message $x_{i}^{t}$ reflecting their current opinion about $p$. Second,
    agent $a_{j}$ reads $x_{i}^{t}$ and produces a verbal report $r_{j}^{t}$ expressing
    their reaction to the message. The verbal report is then classified into a numeric
    opinion scale $o_{j}^{t}\in\{-2,-1,0,1,2\}=\mathbb{O}$, ranging from strongly
    negative to strongly positive opinions about the topic²²2In this study, the discrete
    opinion space $\mathbb{O}$ takes five ordinally-increasing values. Note that the
    size of $\mathbb{O}$ can be easily generalized. For a detailed description of
    the discrete opinion space $\mathbb{O}$ and the correspondence of the numeric
    values to verbal descriptions of opinions, see  §[C](https://arxiv.org/html/2311.09618v4#A3
    "Appendix C Detailed Description of the Discrete Opinion Space 𝕆 ‣ Simulating
    Opinion Dynamics with Networks of LLM-based Agents")., through an opinion classifier,
    denoted $f_{\text{oc}}$ (detailed in §[3.1](https://arxiv.org/html/2311.09618v4#S3.SS1
    "3.1 Configuration ‣ 3 Experimental Settings ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上看，我们从$N$个LLM代理的池中开始，记为$\mathcal{A}=\{a_{1},\cdots,a_{N}\}$，并选择一个话题$p$。每个代理都会在其记忆结构中初始化一个独特的人格，包括一个初步的观点（在§[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2
    "2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")和图[2](https://arxiv.org/html/2311.09618v4#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")b中描述）。在每个时间步$t$，从总体中均匀随机抽取一对代理$A^{t}=\{a_{i},a_{j}\}$，其中$i\neq j$，进行互动。首先，代理$a_{i}$编写一条消息$x_{i}^{t}$，反映其关于$p$的当前观点。其次，代理$a_{j}$读取$x_{i}^{t}$并生成一条口头报告$r_{j}^{t}$，表达其对该消息的反应。口头报告随后通过一个观点分类器，表示为一个数值意见范围$o_{j}^{t}\in\{-2,-1,0,1,2\}=\mathbb{O}$，该范围从对话题的强烈负面观点到强烈正面观点²²2在本研究中，离散的意见空间$\mathbb{O}$包含五个按顺序递增的值。请注意，$\mathbb{O}$的大小可以很容易地推广。有关离散意见空间$\mathbb{O}$的详细描述，以及数值值与口头意见描述的对应关系，请参阅§[C](https://arxiv.org/html/2311.09618v4#A3
    "Appendix C Detailed Description of the Discrete Opinion Space 𝕆 ‣ Simulating
    Opinion Dynamics with Networks of LLM-based Agents")，通过一个意见分类器$f_{\text{oc}}$（详细信息见§[3.1](https://arxiv.org/html/2311.09618v4#S3.SS1
    "3.1 Configuration ‣ 3 Experimental Settings ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")）。
- en: 'After $T$ rounds of pairwise interactions, we compile an opinion trajectory
    $\langle o_{i}\rangle=\{o_{i}^{t}\}_{t=0}^{T}$ for each agent. Note that an agent’s
    opinion remains constant unless they are selected for an interaction. We further
    denote $F_{o}^{t}$ as the opinion distribution, defined as the empirical frequency
    distribution of agents’ opinion over the discrete opinion space $\mathbb{O}$ across
    all $N$ agents at time $t$. ³³3Formally, the opinion frequency distribution $F_{o}^{t}:\mathbb{O}\rightarrow\mathbb{N}$
    is defined as: $F_{o}^{t}(o)=|\{a_{i}\in\mathcal{A}:o_{i}^{t}=o\}|$, which maps
    each opinion value $o\in\mathbb{O}$ to the number of agents holding that opinion
    at time $t$.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过 $T$ 轮对话互动后，我们为每个代理人编制一个意见轨迹 $\langle o_{i}\rangle=\{o_{i}^{t}\}_{t=0}^{T}$。请注意，除非代理人被选中进行互动，否则其意见保持不变。我们进一步定义
    $F_{o}^{t}$ 为意见分布，它是指在时间 $t$ 时刻，所有 $N$ 个代理人在离散意见空间 $\mathbb{O}$ 上的意见经验频率分布。³³3形式上，意见频率分布
    $F_{o}^{t}:\mathbb{O}\rightarrow\mathbb{N}$ 被定义为：$F_{o}^{t}(o)=|\{a_{i}\in\mathcal{A}:o_{i}^{t}=o\}|$，它将每个意见值
    $o\in\mathbb{O}$ 映射到在时间 $t$ 时持有该意见的代理人数量。
- en: 2.2 Agent’s Persona and Memory
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 代理人的个性与记忆
- en: 'Figure 4: Opinion trajectories $\langle o_{i}\rangle$ of LLM agents and the
    final opinion distribution $F_{o}^{T}$ on the topic of Global Warming. Panels
    (a) and (b) display the impact of cognitive biases under (a) false and (b) true
    framing conditions, respectively. Each row represents a different level of confirmation
    bias: no confirmation bias (top row), weak confirmation bias (middle row), and
    strong confirmation bias (bottom row). Panels (c) and (d) serve as baselines,
    with (c) being role-playing but with no interaction, and (d) being no role-playing
    and no interaction, respectively. The color of each line plot corresponds to the
    agent’s initial opinion $o_{i}^{t=0}$: dark blue (+2), light blue (+1), grey (0),
    light red (-1), and dark red (-2), corresponding to opinions ranging from strongly
    agree to strongly disagree. The LLM agents in this figure use cumulative memory.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：LLM 代理人关于全球变暖主题的意见轨迹 $\langle o_{i}\rangle$ 和最终意见分布 $F_{o}^{T}$。面板 (a) 和
    (b) 分别展示了在 (a) 虚假框架与 (b) 真实框架条件下，认知偏差的影响。每一行表示不同的确认偏差水平：无确认偏差（顶行），弱确认偏差（中行），强确认偏差（底行）。面板
    (c) 和 (d) 作为基准，(c) 为角色扮演但无互动，(d) 为没有角色扮演且无互动。每条线的颜色对应代理人最初的意见 $o_{i}^{t=0}$：深蓝（+2）、浅蓝（+1）、灰色（0）、浅红（-1）和深红（-2），分别对应从强烈同意到强烈不同意的意见范围。图中的LLM代理人使用累积记忆。
- en: '|  |  | Cumulative Memory | Reflective Memory |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 累积记忆 | 反思记忆 |'
- en: '| Framing | Confirmation Bias | Bias (B) | Diversity (D) | Bias (B) | Diversity
    (D) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 框架 | 确认偏差 | 偏差 (B) | 多样性 (D) | 偏差 (B) | 多样性 (D) |'
- en: '| False | None | -1.33 $\pm$ 0.17 | 0.60 $\pm$ 0.11 | -1.37 $\pm$ 0.11 | 0.75
    $\pm$ 0.12 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 虚假 | 无 | -1.33 $\pm$ 0.17 | 0.60 $\pm$ 0.11 | -1.37 $\pm$ 0.11 | 0.75 $\pm$
    0.12 |'
- en: '|  | Weak | -0.96 $\pm$ 0.20 | 0.87 $\pm$ 0.12 | -1.07 $\pm$ 0.17 | 1.04 $\pm$
    0.14 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -0.96 $\pm$ 0.20 | 0.87 $\pm$ 0.12 | -1.07 $\pm$ 0.17 | 1.04 $\pm$
    0.14 |'
- en: '|  | Strong | -0.9 $\pm$ 0.14 | 1.24 $\pm$ 0.11 | -0.85 $\pm$ 0.15 | 1.33 $\pm$
    0.12 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.9 $\pm$ 0.14 | 1.24 $\pm$ 0.11 | -0.85 $\pm$ 0.15 | 1.33 $\pm$
    0.12 |'
- en: '| True | None | 0.52 $\pm$ 0.31 | 0.66 $\pm$ 0.11 | 0.60 $\pm$ 0.31 | 0.85
    $\pm$ 0.12 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 真 | 无 | 0.52 $\pm$ 0.31 | 0.66 $\pm$ 0.11 | 0.60 $\pm$ 0.31 | 0.85 $\pm$
    0.12 |'
- en: '|  | Weak | 0.56 $\pm$ 0.27 | 0.95 $\pm$ 0.11 | 0.17 $\pm$ 0.28 | 1.23 $\pm$
    0.11 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 0.56 $\pm$ 0.27 | 0.95 $\pm$ 0.11 | 0.17 $\pm$ 0.28 | 1.23 $\pm$ 0.11
    |'
- en: '|  | Strong | -0.10 $\pm$ 0.13 | 1.52 $\pm$ 0.05 | -0.09 $\pm$ 0.16 | 1.65
    $\pm$ 0.04 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.10 $\pm$ 0.13 | 1.52 $\pm$ 0.05 | -0.09 $\pm$ 0.16 | 1.65 $\pm$
    0.04 |'
- en: 'Table 1: The bias ($B$) and diversity ($D$) of the final opinion distribution
    $F_{o}^{T}$ aggregated across all 15 topics, for both cumulative and reflective
    memory strategies under false and true framing conditions, and different levels
    of induced confirmation bias. The values represent the average across 15 topics,
    along with the standard errors. Increasing the strength of the confirmation bias
    correlates with increasing $D$, as highlighted by the green color gradient. Notably,
    under true framing, $B$ tends to be more positive (more agreeing) compared to
    false framing, indicated by blue for true and red for false framing conditions.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：在虚假与真实框架条件下，累积记忆与反思记忆策略下，最终意见分布 $F_{o}^{T}$ 在15个主题中汇总的偏差 ($B$) 和多样性 ($D$)
    值。数值表示15个主题的平均值以及标准误差。增加确认偏差的强度与 $D$ 的增加相关，绿色渐变突出显示这一点。值得注意的是，在真实框架下，$B$ 倾向于更为积极（更多的同意），与虚假框架相比，真实框架下的
    $B$ 值较高，虚假框架以红色表示，真实框架以蓝色表示。
- en: '|  |  | Cumulative Memory | Reflective Memory |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 累积记忆 | 反思记忆 |'
- en: '| Framing | CB | Bias | Diversity | Bias | Diversity |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 框架效应 | 确认偏误 | 偏见 | 多样性 | 偏见 | 多样性 |'
- en: '|  |  | (B) | (D) | (B) | (D) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  |  | （B） | （D） | （B） | （D） |'
- en: '| Science Topics |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 科学话题 |'
- en: '| False | None | -1.70 $\pm$ 0.15 | 0.27 $\pm$ 0.11 | -1.48 $\pm$ 0.15 | 0.65
    $\pm$ 0.12 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 无 | -1.70 $\pm$ 0.15 | 0.27 $\pm$ 0.11 | -1.48 $\pm$ 0.15 | 0.65 $\pm$
    0.12 |'
- en: '|  | Weak | -0.86 $\pm$ 0.33 | 0.96 $\pm$ 0.27 | -1.30 $\pm$ 0.26 | 0.92 $\pm$
    0.27 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -0.86 $\pm$ 0.33 | 0.96 $\pm$ 0.27 | -1.30 $\pm$ 0.26 | 0.92 $\pm$
    0.27 |'
- en: '|  | Strong | -0.78 $\pm$ 0.17 | 1.44 $\pm$ 0.13 | -0.36 $\pm$ 0.19 | 1.52
    $\pm$ 0.09 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.78 $\pm$ 0.17 | 1.44 $\pm$ 0.13 | -0.36 $\pm$ 0.19 | 1.52 $\pm$
    0.09 |'
- en: '| True | None | 0.60 $\pm$ 0.50 | 0.72 $\pm$ 0.22 | 0.24 $\pm$ 0.70 | 0.76
    $\pm$ 0.26 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 正确 | 无 | 0.60 $\pm$ 0.50 | 0.72 $\pm$ 0.22 | 0.24 $\pm$ 0.70 | 0.76 $\pm$
    0.26 |'
- en: '|  | Weak | -0.24 $\pm$ 0.40 | 1.05 $\pm$ 0.18 | -0.02 $\pm$ 0.42 | 1.39 $\pm$
    0.07 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -0.24 $\pm$ 0.40 | 1.05 $\pm$ 0.18 | -0.02 $\pm$ 0.42 | 1.39 $\pm$
    0.07 |'
- en: '|  | Strong | -0.34 $\pm$ 0.12 | 1.46 $\pm$ 0.10 | -0.34 $\pm$ 0.27 | 1.61
    $\pm$ 0.06 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.34 $\pm$ 0.12 | 1.46 $\pm$ 0.10 | -0.34 $\pm$ 0.27 | 1.61 $\pm$
    0.06 |'
- en: '| History Topics |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 历史话题 |'
- en: '| False | None | -1.12 $\pm$ 0.41 | 0.81 $\pm$ 0.27 | -1.52 $\pm$ 0.17 | 0.71
    $\pm$ 0.25 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 无 | -1.12 $\pm$ 0.41 | 0.81 $\pm$ 0.27 | -1.52 $\pm$ 0.17 | 0.71 $\pm$
    0.25 |'
- en: '|  | Weak | -1.22 $\pm$ 0.13 | 0.81 $\pm$ 0.18 | -1.32 $\pm$ 0.26 | 0.70 $\pm$
    0.23 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -1.22 $\pm$ 0.13 | 0.81 $\pm$ 0.18 | -1.32 $\pm$ 0.26 | 0.70 $\pm$
    0.23 |'
- en: '|  | Strong | -1.12 $\pm$ 0.35 | 1.06 $\pm$ 0.22 | -0.82 $\pm$ 0.24 | 1.51
    $\pm$ 0.17 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -1.12 $\pm$ 0.35 | 1.06 $\pm$ 0.22 | -0.82 $\pm$ 0.24 | 1.51 $\pm$
    0.17 |'
- en: '| True | None | 0.22 $\pm$ 0.56 | 0.71 $\pm$ 0.21 | 0.40 $\pm$ 0.55 | 0.88
    $\pm$ 0.26 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 正确 | 无 | 0.22 $\pm$ 0.56 | 0.71 $\pm$ 0.21 | 0.40 $\pm$ 0.55 | 0.88 $\pm$
    0.26 |'
- en: '|  | Weak | 0.48 $\pm$ 0.49 | 0.89 $\pm$ 0.23 | -0.12 $\pm$ 0.67 | 1.00 $\pm$
    0.17 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 0.48 $\pm$ 0.49 | 0.89 $\pm$ 0.23 | -0.12 $\pm$ 0.67 | 1.00 $\pm$
    0.17 |'
- en: '|  | Strong | -0.24 $\pm$ 0.27 | 1.44 $\pm$ 0.10 | -0.16 $\pm$ 0.33 | 1.63
    $\pm$ 0.10 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.24 $\pm$ 0.27 | 1.44 $\pm$ 0.10 | -0.16 $\pm$ 0.33 | 1.63 $\pm$
    0.10 |'
- en: '| Common Sense Topics |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 常识话题 |'
- en: '| False | None | -1.16 $\pm$ 0.21 | 0.71 $\pm$ 0.11 | -1.10 $\pm$ 0.22 | 0.87
    $\pm$ 0.27 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 无 | -1.16 $\pm$ 0.21 | 0.71 $\pm$ 0.11 | -1.10 $\pm$ 0.22 | 0.87 $\pm$
    0.27 |'
- en: '|  | Weak | -0.80 $\pm$ 0.51 | 0.85 $\pm$ 0.21 | -0.58 $\pm$ 0.29 | 0.97 $\pm$
    0.23 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -0.80 $\pm$ 0.51 | 0.85 $\pm$ 0.21 | -0.58 $\pm$ 0.29 | 0.97 $\pm$
    0.23 |'
- en: '|  | Strong | -0.80 $\pm$ 0.20 | 1.22 $\pm$ 0.20 | -1.36 $\pm$ 0.15 | 1.48
    $\pm$ 0.09 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.80 $\pm$ 0.20 | 1.22 $\pm$ 0.20 | -1.36 $\pm$ 0.15 | 1.48 $\pm$
    0.09 |'
- en: '| True | None | 1.18 $\pm$ 0.41 | 0.57 $\pm$ 0.17 | 1.16 $\pm$ 0.34 | 0.92
    $\pm$ 0.16 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 正确 | 无 | 1.18 $\pm$ 0.41 | 0.57 $\pm$ 0.17 | 1.16 $\pm$ 0.34 | 0.92 $\pm$
    0.16 |'
- en: '|  | Weak | 1.44 $\pm$ 0.17 | 0.91 $\pm$ 1.28 | 0.64 $\pm$ 0.36 | 1.28 $\pm$
    0.26 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 1.44 $\pm$ 0.17 | 0.91 $\pm$ 1.28 | 0.64 $\pm$ 0.36 | 1.28 $\pm$ 0.26
    |'
- en: '|  | Strong | 0.28 $\pm$ 0.18 | 1.66 $\pm$ 1.69 | 0.22 $\pm$ 0.21 | 1.69 $\pm$
    0.06 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | 0.28 $\pm$ 0.18 | 1.66 $\pm$ 1.69 | 0.22 $\pm$ 0.21 | 1.69 $\pm$ 0.06
    |'
- en: 'Table 2: The bias ($B$) and diversity ($D$) of the final opinion distribution
    $F_{o}^{T}$ for each of the three categories (science, history, common sense),
    for both memory strategies under false and true framing conditions, and different
    levels of induced confirmation bias (CB). For each category, the averages across
    five topics are shown along with the standard errors. Increasing the strength
    of the CB correlates with increasing $D$, as highlighted by the green color gradient.
    Notably, under true framing, $B$ tends to be more positive (more agreeing) compared
    to false framing, indicated by blue for true and red for false framing conditions.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：在错误与正确框架条件下，针对每个类别（科学、历史、常识）的最终意见分布$F_{o}^{T}$的偏见（$B$）和多样性（$D$），以及不同强度的确认偏误（CB）。每个类别显示了五个话题的平均值及其标准误差。随着CB强度的增加，$D$增加，这一点通过绿色渐变颜色突出显示。值得注意的是，在正确框架下，$B$倾向于比在错误框架下更为正向（更多的同意），通过蓝色表示正确框架，红色表示错误框架。
- en: Each agent $a_{i}$ maintains a dynamic memory module $m_{i}^{t}$ that evolves
    over time (Figure [3](https://arxiv.org/html/2311.09618v4#S2.F3 "Figure 3 ‣ 2.1
    Simulating Opinion Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents"), [2](https://arxiv.org/html/2311.09618v4#S1.F2 "Figure 2
    ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")b).
    In practice, the memory module is represented as text descriptions included in
    the prompt to the agent (see §[3.1](https://arxiv.org/html/2311.09618v4#S3.SS1
    "3.1 Configuration ‣ 3 Experimental Settings ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")). The memory $m_{i}^{t}$ influences the generation
    of a new message $x_{i}^{t}$ and the assessment of other agents’ messages $x_{j}^{t}$.
    We denote a memory update function for updating the agent’s memory state, i.e.,
    $m_{i}^{t+1}=f_{mu}(z,x_{i}^{t},r_{j}^{t},m_{i}^{t})$, where $z\in\{\text{``write''},\text{``review''}\}$
    denotes the interaction type of either writing or reviewing a tweet.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理 $a_{i}$ 都维护一个动态记忆模块 $m_{i}^{t}$，该模块随时间变化（图 [3](https://arxiv.org/html/2311.09618v4#S2.F3
    "图 3 ‣ 2.1 模拟观点动态 ‣ 2 方法 ‣ 使用基于LLM的代理网络模拟观点动态")， [2](https://arxiv.org/html/2311.09618v4#S1.F2
    "图 2 ‣ 1 引言 ‣ 使用基于LLM的代理网络模拟观点动态")b）。实际上，记忆模块被表示为包含在代理提示中的文本描述（参见 §[3.1](https://arxiv.org/html/2311.09618v4#S3.SS1
    "3.1 配置 ‣ 3 实验设置 ‣ 使用基于LLM的代理网络模拟观点动态")）。记忆 $m_{i}^{t}$ 会影响新消息 $x_{i}^{t}$ 的生成以及对其他代理消息
    $x_{j}^{t}$ 的评估。我们用一个记忆更新函数表示更新代理记忆状态，即 $m_{i}^{t+1}=f_{mu}(z,x_{i}^{t},r_{j}^{t},m_{i}^{t})$，其中
    $z\in\{\text{``写''},\text{``审阅''}\}$ 表示写作或审阅推文的交互类型。
- en: 'Two memory update strategies are considered: (a) a cumulative memory that sequentially
    appends each new experience (either the experience of writing a tweet or reviewing
    a tweet) and (b) a reflective memory, inspired by Park et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib27)),
    that maintains a compact summary by continuously reflecting and integrating new
    experiences into the existing memory state (see §[E](https://arxiv.org/html/2311.09618v4#A5
    "Appendix E Agent Memory Update Function ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents") for the detailed update function and the wording of the
    prompts). Both approaches are empirically evaluated to test their effects on opinion
    dynamics.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑了两种记忆更新策略：（a）累积记忆，它顺序地将每次新的经验（无论是写作推文还是审阅推文的经验）附加到记忆中；（b）反思记忆，灵感来自于 Park 等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib27)），它通过不断反思并将新经验融入现有记忆状态来保持一个紧凑的总结（参见 §[E](https://arxiv.org/html/2311.09618v4#A5
    "附录 E 代理记忆更新函数 ‣ 使用基于LLM的代理网络模拟观点动态")以了解详细的更新函数和提示的措辞）。这两种方法均通过实证评估来测试它们对观点动态的影响。
- en: 'The first memory $m_{i}^{t=0}$ is initialized with the agent’s persona, cognitive
    bias (if present), and the closed-world restriction (if present; see below), which
    can be all described in text sequences (detailed in §[3](https://arxiv.org/html/2311.09618v4#S3
    "3 Experimental Settings ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")). Personas are created to reflect a diverse demographic background incorporating
    various characteristics, including name, political leaning, age, gender, ethnicity,
    education, and occupation (see Figure [2](https://arxiv.org/html/2311.09618v4#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")b for an example). Alongside these attributes, a placeholder for their
    initial opinion $o_{i}^{t=0}$ is also included with natural language description.
    For example, an agent with $o_{i}^{t=0}=0$ is given “Initial Belief: Neutral”
    in the persona (Figure [2](https://arxiv.org/html/2311.09618v4#S1.F2 "Figure 2
    ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")b).⁴⁴4The
    correspondence between numeric opinion values and verbal description of initial
    opinion is detailed in §[C](https://arxiv.org/html/2311.09618v4#A3 "Appendix C
    Detailed Description of the Discrete Opinion Space 𝕆 ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents"). The initial opinion $o_{i}^{t=0}$ is specified
    through an initial opinion distribution $F_{o}^{t=0}$ that varies across simulation
    settings (§[3.4](https://arxiv.org/html/2311.09618v4#S3.SS4 "3.4 Initial Opinion
    Distribution ‣ 3 Experimental Settings ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents")). §[B](https://arxiv.org/html/2311.09618v4#A2 "Appendix
    B Full List of Personas ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents") shows the full list of personas.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个记忆 $m_{i}^{t=0}$ 是通过智能体的个性、认知偏差（如果存在的话）和封闭世界限制（如果存在的话；见下文）进行初始化，这些都可以通过文本序列进行描述（详见§[3](https://arxiv.org/html/2311.09618v4#S3
    "3 实验设置 ‣ 使用基于LLM的智能体网络模拟意见动态")）。个性是为了反映多样化的人口背景而创建的，包含各种特征，包括姓名、政治倾向、年龄、性别、种族、教育和职业（参见图[2](https://arxiv.org/html/2311.09618v4#S1.F2
    "图 2 ‣ 1 引言 ‣ 使用基于LLM的智能体网络模拟意见动态")b 作为示例）。除了这些属性外，还包含了他们初始意见 $o_{i}^{t=0}$ 的占位符，并通过自然语言进行描述。例如，一个初始意见
    $o_{i}^{t=0}=0$ 的智能体会在个性中给出“初始信念：中立”（图[2](https://arxiv.org/html/2311.09618v4#S1.F2
    "图 2 ‣ 1 引言 ‣ 使用基于LLM的智能体网络模拟意见动态")b）。⁴⁴4 数值意见值与初始意见的文字描述之间的对应关系详见§[C](https://arxiv.org/html/2311.09618v4#A3
    "附录 C 离散意见空间𝕆的详细描述 ‣ 使用基于LLM的智能体网络模拟意见动态")。初始意见 $o_{i}^{t=0}$ 通过初始意见分布 $F_{o}^{t=0}$
    进行指定，该分布会根据模拟设置有所不同（§[3.4](https://arxiv.org/html/2311.09618v4#S3.SS4 "3.4 初始意见分布
    ‣ 3 实验设置 ‣ 使用基于LLM的智能体网络模拟意见动态")）。§[B](https://arxiv.org/html/2311.09618v4#A2
    "附录 B 完整个性列表 ‣ 使用基于LLM的智能体网络模拟意见动态") 显示了完整的个性列表。
- en: 2.3 Cognitive Biases
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 认知偏差
- en: 'We investigate the effects of inducing a cognitive bias via role-playing instructions
    on the group opinion dynamics. Specifically, we consider confirmation bias: the
    tendency to interpret information as confirming one’s views and to discount contradictory
    evidence Nickerson ([1998](https://arxiv.org/html/2311.09618v4#bib.bib25)). Prior
    simulation studies using mathematical ABMs have shown that, when confirmation
    bias is introduced at the individual level, the overall population exhibits increasing
    opinion fragmentation (i.e., increased diversity D) as the confirmation bias strengthens
    Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)). We assess
    whether LLM agents instructed to show confirmation bias likewise replicate this
    phenomenon in their opinion dynamics when communicating through natural language.
    To manipulate the strength of confirmation bias, we provide two bias levels following
    the spectrum in Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)).
    Weak Confirmation Bias: "You will be more likely to believe information that supports
    your beliefs and less likely to believe information that contradicts your beliefs."
    Strong Confirmation Bias: "You will only believe information that supports your
    beliefs and will completely dismiss information that contradicts your beliefs."
    See §[F](https://arxiv.org/html/2311.09618v4#A6 "Appendix F Confirmation Bias
    Prompt ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents") for the
    bias-inducing prompts.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了通过角色扮演指令引发认知偏差对群体意见动态的影响。具体来说，我们考虑了确认偏差：即倾向于将信息解读为支持个人观点并忽视相反证据的倾向（Nickerson
    [1998](https://arxiv.org/html/2311.09618v4#bib.bib25)）。先前使用数学代理基础模型（ABMs）的模拟研究表明，当确认偏差在个体层面引入时，整体群体会表现出意见碎片化的增加（即，随着确认偏差的增强，意见多样性D增加）（Lorenz
    et al. [2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）。我们评估了在自然语言交流中，通过指令引导展示确认偏差的LLM代理是否也能复制这一现象。为了操控确认偏差的强度，我们提供了两种偏差水平，参考了Lorenz
    et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21))中的偏差谱系。弱确认偏差：“你会更容易相信支持你信念的信息，而不太相信与信念相矛盾的信息。”
    强确认偏差：“你只会相信支持你信念的信息，并完全否定与信念相矛盾的信息。” 请参见§[F](https://arxiv.org/html/2311.09618v4#A6
    "Appendix F Confirmation Bias Prompt ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents")获取引发偏差的提示。
- en: 'Figure 5: Varying initial opinion distribution $F_{o}^{T}$ for the global warming
    debate. (a) All agents start with a strongly positive opinion. (b) $8$ agents
    start with a strongly positive opinion while $2$ with a strongly negative opinion
    (c) $8$ agents start with a strongly negative opinion while $2$ with a strongly
    positive opinion. (d) All agents start with a strongly negative opinion. The color
    of each line plot corresponds to the agent’s initial opinion $o_{i}^{t=0}$: dark
    blue (+2), light blue (+1), grey (0), light red (-1), and dark red (-2), corresponding
    to opinions ranging from strongly agree to strongly disagree. The LLM agents in
    this figure use cumulative memory.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：全球变暖辩论中初始意见分布的变化 $F_{o}^{T}$。（a）所有代理的初始意见为强烈正面。（b）$8$ 个代理的初始意见为强烈正面，$2$
    个代理为强烈负面。（c）$8$ 个代理的初始意见为强烈负面，$2$ 个代理为强烈正面。（d）所有代理的初始意见为强烈负面。每条线图的颜色对应于代理的初始意见
    $o_{i}^{t=0}$：深蓝色（+2）、浅蓝色（+1）、灰色（0）、浅红色（-1）和深红色（-2），表示从强烈同意到强烈反对的意见范围。此图中的LLM代理使用累积记忆。
- en: 2.4 Open-world vs. Closed-world Settings
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 开放世界与封闭世界设置
- en: Our study examines agent behavior in both closed-world and open-world settings.
    In the closed-world setting, which aligns with traditional opinion dynamics models,
    belief change is solely attributed to social influences within the system, and
    agents are restricted from accessing external information (restricted by instructions
    in the prompt; §[G](https://arxiv.org/html/2311.09618v4#A7 "Appendix G Closed-World
    Prompt ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents") provides
    specific prompting details). Conversely, the open-world setting allows agents
    the freedom to “hallucinate" facts external to the system, such as discussing
    topics with imaginary friends Dziri et al. ([2022](https://arxiv.org/html/2311.09618v4#bib.bib7));
    Ji et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib15)); Huang et al.
    ([2023](https://arxiv.org/html/2311.09618v4#bib.bib14)). We investigate the incidence
    of hallucination in both settings to understand the impact of external information
    on social influence. Our findings indicate no hallucination in the closed-world
    setting, while a hallucination rate of about 15% is observed in the open-world
    scenario. Consequently, the results reported in this study focus on the closed-world
    setting. The measurement procedure involves independent human annotators (detailed
    in §[L](https://arxiv.org/html/2311.09618v4#A12 "Appendix L Measurement of Hallucination
    Rate ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究考察了代理在封闭世界和开放世界设置中的行为。在封闭世界设置中，这与传统的观点动态模型一致，信念变化完全归因于系统内的社会影响，且代理无法访问外部信息（由提示中的指令进行限制；§[G](https://arxiv.org/html/2311.09618v4#A7
    "附录 G 封闭世界提示 ‣ 基于 LLM 的代理网络模拟观点动态") 提供了具体的提示细节）。相反，开放世界设置允许代理自由地“幻想”系统外的事实，例如与虚构的朋友讨论话题
    Dziri 等人（[2022](https://arxiv.org/html/2311.09618v4#bib.bib7)）；Ji 等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib15)）；Huang
    等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib14)）。我们调查了两种设置中幻想的发生率，以理解外部信息对社会影响的影响。我们的研究结果表明，在封闭世界设置中没有幻想现象，而在开放世界场景中，幻想发生率约为
    15%。因此，本研究报告的结果集中于封闭世界设置。测量过程涉及独立的人工标注员（详细信息见 §[L](https://arxiv.org/html/2311.09618v4#A12
    "附录 L 幻想发生率测量 ‣ 基于 LLM 的代理网络模拟观点动态")）。
- en: 3 Experimental Settings
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 实验设置
- en: 3.1 Configuration
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 配置
- en: In our simulations, LLM agents use ChatGPT (gpt-3.5-turbo-16k) with temperature
    of $0.7$ OpenAI ([2022](https://arxiv.org/html/2311.09618v4#bib.bib26)). During
    initialization, each agent’s persona, along with the optional closed-world restrictions
    and cognitive biases, are incorporated into the model’s “system messages”. Throughout
    the interaction, the historical events are added to the model’s “user messages”.
    The memory of the LLM agents is managed through LangChain Chase ([2022](https://arxiv.org/html/2311.09618v4#bib.bib2)).
    In all experiments, we set the number of steps to $T=100$ and the number of agents
    to $N=10$. We use the FLAN-T5-XXL model Chung et al. ([2022](https://arxiv.org/html/2311.09618v4#bib.bib6))
    as the opinion classifier $f_{\text{oc}}$ (see  §[I](https://arxiv.org/html/2311.09618v4#A9
    "Appendix I Opinion Classification ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents") for the prompt used to classify the opinions and  §[N](https://arxiv.org/html/2311.09618v4#A14
    "Appendix N Validation of FLAN-T5-XXL Ratings ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") for validation against human ratings). In sensitivity
    analyses, we consider other LLMs like GPT-4 (gpt-4-1106-preview) and Vicuna-33B
    (vicuna-33b-v1.3; Zheng et al., [2023](https://arxiv.org/html/2311.09618v4#bib.bib32)),
    and an experiment with a larger network ($N=20$).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的模拟中，LLM 代理使用 ChatGPT（gpt-3.5-turbo-16k），温度设置为 $0.7$，OpenAI（[2022](https://arxiv.org/html/2311.09618v4#bib.bib26)）。在初始化过程中，每个代理的个性，以及可选的封闭世界限制和认知偏见，会被融入到模型的“系统消息”中。在整个交互过程中，历史事件会被添加到模型的“用户消息”中。LLM
    代理的记忆通过 LangChain Chase（[2022](https://arxiv.org/html/2311.09618v4#bib.bib2)）进行管理。在所有实验中，我们将步数设为
    $T=100$，代理数量设为 $N=10$。我们使用 FLAN-T5-XXL 模型 Chung 等人（[2022](https://arxiv.org/html/2311.09618v4#bib.bib6)）作为观点分类器
    $f_{\text{oc}}$（有关用于分类观点的提示，请参见 §[I](https://arxiv.org/html/2311.09618v4#A9 "附录
    I 观点分类 ‣ 基于 LLM 的代理网络模拟观点动态")，有关与人类评分验证的内容，请参见 §[N](https://arxiv.org/html/2311.09618v4#A14
    "附录 N FLAN-T5-XXL 评分验证 ‣ 基于 LLM 的代理网络模拟观点动态")）。在灵敏度分析中，我们考虑了其他 LLM，如 GPT-4（gpt-4-1106-preview）和
    Vicuna-33B（vicuna-33b-v1.3；Zheng 等人，[2023](https://arxiv.org/html/2311.09618v4#bib.bib32)），并进行了一次包含更大网络的实验（$N=20$）。
- en: 3.2 Topics and Framings
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 主题与框架
- en: 'To study the opinion dynamics of the agents, we selected 15 topics with a known
    ground truth spanning scientific theories (science topics, e.g., whether global
    warming is a conspiracy), historical events (history topics, e.g., whether the
    911 attack was an “inside job”), and commonsense knowledge (common sense topics,
    e.g., whether the sky is blue on a sunny day). For each topic, we created two
    framings. The true framing affirms the widely-accepted truth while the false framing
    affirms the opposite. For example, for the topic of “Global Warming”, the two
    framings are as follows. True Framing: “Theory XYZ claims that global warming
    is a real phenomenon and global climate is rapidly growing warmer.” False Framing:
    “Theory XYZ claims that global warming is a conspiracy by governments worldwide
    and is not a real phenomenon.” To control for wording effects across topics, we
    add “Theory XYZ” before stating the claim in all prompts. The full set of prompts
    is provided in §[H](https://arxiv.org/html/2311.09618v4#A8 "Appendix H Full List
    of Topics ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents").'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了研究代理的意见动态，我们选择了15个具有已知真实情况的话题，涵盖科学理论（科学话题，例如，全球变暖是否是一个阴谋）、历史事件（历史话题，例如，911袭击是否是“内部工作”）和常识知识（常识话题，例如，晴天时天空是否是蓝色的）。对于每个话题，我们创建了两个表述。真实表述确认广泛接受的事实，而虚假表述确认相反的观点。例如，对于“全球变暖”这一话题，两个表述如下：真实表述：“XYZ理论声称全球变暖是一个真实的现象，全球气候正在迅速变暖。”虚假表述：“XYZ理论声称全球变暖是全球政府的阴谋，根本不是一个真实现象。”为了控制跨话题的措辞效应，我们在所有提示中都会在陈述主张之前加上“XYZ理论”。完整的提示集合请参见§[H](https://arxiv.org/html/2311.09618v4#A8
    "附录 H 完整话题列表 ‣ 使用基于LLM的代理网络模拟意见动态")。
- en: 3.3 Opinion Dynamics Evaluation Metrics
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 意见动态评估指标
- en: 'Our evaluation of opinion dynamics includes two metrics in the literature Lorenz
    et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)): Bias (B): The
    average of the agents’ opinions at the final time step, $B=\text{mean}(F_{o}^{T})$.
    Diversity (D): The standard deviation of the final opinion distribution, $D=\text{std}(F_{o}^{T})$.
    These two metrics can be used to categorize the final opinion distribution $F_{o}^{T}$.
    For example, a low $B$ and a low $D$ characterizes central consensus, whereas
    a low $B$ and a medium $D$ characterizes a diversified distribution.⁵⁵5See Lorenz
    et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)) for a detailed
    taxonomy.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对意见动态的评估包括文献中 Lorenz 等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）提出的两个指标：偏差（B）：最终时间步长时代理的意见平均值，$B=\text{mean}(F_{o}^{T})$。多样性（D）：最终意见分布的标准差，$D=\text{std}(F_{o}^{T})$。这两个指标可用于分类最终的意见分布$F_{o}^{T}$。例如，低
    $B$ 和低 $D$ 特征表示中心共识，而低 $B$ 和中等 $D$ 特征表示多样化分布。⁵⁵5详见 Lorenz 等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）的详细分类。
- en: 3.4 Initial Opinion Distribution
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 初始意见分布
- en: The initial opinion distribution $F_{o}^{t=0}$ determines the agents’ starting
    opinions. The opinion is initialized verbally in the agent’s prompt and memory
    (see §[2.1](https://arxiv.org/html/2311.09618v4#S2.SS1 "2.1 Simulating Opinion
    Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents") and Figure [2](https://arxiv.org/html/2311.09618v4#S1.F2 "Figure 2 ‣
    1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")b).
    In most experiments, we initialize $F_{o}^{t=0}$ as a uniform distribution, with
    each opinion value assigned to $N/|\mathbb{O}|$ agents, where $|\mathbb{O}|$ is
    the number of possible opinion values.⁶⁶6For example, in our experiment, with
    $N=10$ agents and five possible opinion values of ${-2,-1,0,+1,+2}$, each value
    would be assigned to 2 agents initially. This reflects an unbiased starting state
    with $B=0$ and $D=1.49$. In one experiment, we intentionally manipulate the initial
    distribution to be highly skewed. For example, assigning all 10 agents an initial
    opinion of $-2$, or 8 agents to $-2$ and 2 agents to $+2$. This allows us to study
    the effects of polarized starting opinions on the resulting opinion dynamics.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 初始意见分布 $F_{o}^{t=0}$ 决定了代理人的起始意见。意见在代理人的提示和记忆中以口头方式初始化（参见 §[2.1](https://arxiv.org/html/2311.09618v4#S2.SS1
    "2.1 Simulating Opinion Dynamics ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") 和图 [2](https://arxiv.org/html/2311.09618v4#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")b）。在大多数实验中，我们将 $F_{o}^{t=0}$ 初始化为均匀分布，每个意见值分配给 $N/|\mathbb{O}|$ 个代理人，其中
    $|\mathbb{O}|$ 是可能的意见值数量。⁶⁶6 例如，在我们的实验中，设 $N=10$ 个代理人和五个可能的意见值 ${-2,-1,0,+1,+2}$，每个值最初会分配给
    2 个代理人。这反映了一个无偏的起始状态，$B=0$ 且 $D=1.49$。在一项实验中，我们故意操控初始分布使其高度倾斜。例如，将所有 10 个代理人的初始意见设置为
    $-2$，或者将 8 个代理人的初始意见设置为 $-2$，将 2 个代理人的初始意见设置为 $+2$。这使我们能够研究极化的起始意见对结果意见动态的影响。
- en: 3.5 Control Conditions
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 控制条件
- en: 'In addition to the main experimental conditions, we introduce two control conditions:
    (a) No Interaction Condition: Agents are initialized with their personas and initial
    beliefs as normal, but do not actually interact. Instead, each agent $a_{i}$ independently
    provides 10 opinion reports $o_{i}^{t}$ on the topic. (b) No Interaction + No
    Role-Playing Condition: No agents are initialized with their personas and initial
    beliefs. We simply query the LLM for 10 independent opinion reports on the topic.
    These control conditions allow us to assess whether the LLM has inherent biases
    on the topics that manifest even without social influence dynamics. Comparison
    to the main interactive conditions allows us to discern effects stemming from
    the personas and social interactions.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除了主要实验条件外，我们还引入了两个控制条件：（a）无交互条件：代理人按常规初始化其角色和初始信念，但实际上不进行互动。相反，每个代理人 $a_{i}$
    独立提供 10 个关于该话题的意见报告 $o_{i}^{t}$。（b）无交互 + 无角色扮演条件：没有代理人初始化其角色和初始信念。我们只是简单地查询 LLM
    获取 10 个关于该话题的独立意见报告。这些控制条件使我们能够评估即使没有社会影响动态，LLM 是否在这些话题上存在固有的偏见。与主要交互条件的比较可以帮助我们辨别由角色扮演和社会互动引发的影响。
- en: 4 Results
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: Agents Converge towards the Inherent Bias in the LLM.
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理人趋向于 LLM 中的固有偏见。
- en: 'Table [1](https://arxiv.org/html/2311.09618v4#S2.T1 "Table 1 ‣ 2.2 Agent’s
    Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of
    LLM-based Agents") summarizes the Bias ($B$) and Diversity ($D$) of the final
    opinion distribution $F_{o}^{T}$ aggregated across 15 topics. Table [2](https://arxiv.org/html/2311.09618v4#S2.T2
    "Table 2 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") shows the summarized results separated by
    three topic types. As shown in Table [1](https://arxiv.org/html/2311.09618v4#S2.T1
    "Table 1 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents"), the role-playing prompt initially causes
    agents to express a diverse variety of opinions as expected, but with repeated
    social interacts these opinions converge toward a ground-truth consensus. Under
    the false framing, agents collectively lean towards disagreement, shown by a negative
    bias value ($B=-1.33$ when there is no cognitive bias). Conversely, under the
    true framing, the group shows a slight positive tendency to agree ($B=0.52$),
    indicating a lean towards truthfulness. Figure [4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") and  [6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents") shows an example
    of how opinion trajectories quickly converge towards the truth after social interactions
    for both the false and true framing conditions, especially without cognitive bias.
    This is true across using cumulative memory (Figure [4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")) and reflective memory (Figure [6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")). The control
    condition illustrates that a similar tendency is observed when agents do not communicate,
    but are repeatedly queried for their opinion: the expressed opinions tend to move
    toward the ground truth, suggesting an inherent bias in the model. Statistical
    tests supporting the claims above are in §[M](https://arxiv.org/html/2311.09618v4#A13
    "Appendix M Statistical Tests ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents").'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 表格[1](https://arxiv.org/html/2311.09618v4#S2.T1 "Table 1 ‣ 2.2 Agent’s Persona
    and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")总结了跨15个主题汇总的最终意见分布$F_{o}^{T}$的偏差（$B$）和多样性（$D$）。表格[2](https://arxiv.org/html/2311.09618v4#S2.T2
    "Table 2 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")展示了按三种主题类型分离的汇总结果。如表格[1](https://arxiv.org/html/2311.09618v4#S2.T1
    "Table 1 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")所示，角色扮演提示最初导致代理人表现出预期的多样化意见，但随着反复的社交互动，这些意见逐渐趋向于共识的真相。在虚假框架下，代理人集体倾向于不同意见，这表现为负偏差值（$B=-1.33$，当没有认知偏差时）。相反，在真实框架下，群体表现出轻微的积极倾向同意（$B=0.52$），表明向真相的偏向。图[4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")和[6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")展示了一个示例，说明无论是虚假还是真实框架条件下，意见轨迹如何在社交互动后迅速趋向真相，特别是在没有认知偏差的情况下。这一点在使用累积记忆（图[4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")）和反思记忆（图[6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")）中均得到了验证。控制条件表明，当代理人不进行沟通，而是反复被询问意见时，也会观察到类似的趋势：表达的意见趋向于真相，暗示模型中存在固有的偏见。支持上述论点的统计测试在§[M](https://arxiv.org/html/2311.09618v4#A13
    "Appendix M Statistical Tests ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")中。
- en: Confirmation Bias Leads to Opinion Fragmentation.
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 确认偏差导致意见碎片化。
- en: Introducing confirmation bias in the prompt leads to less ultimate consensus
    (i.e., greater diversity $D$) across LLM agents. As shown in Table [1](https://arxiv.org/html/2311.09618v4#S2.T1
    "Table 1 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") and Figure [4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents"), the stronger the confirmation bias, the more
    diverse the final state distribution. This correlation holds for both cumulative
    and reflective memory strategies (Figure [4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") and [6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")). These findings
    replicate, within a set of interacting LLMs, the general finding from more classic
    ABMs that incorporation of confirmation bias in the model update algorithm produces
    greater opinion fragmentation Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21));
    Flache et al. ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10)). Statistical
    tests supporting the claims above are in §[M](https://arxiv.org/html/2311.09618v4#A13
    "Appendix M Statistical Tests ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents").
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示中引入确认偏差会导致LLM代理之间的最终共识较少（即，$D$的多样性更大）。如表[1](https://arxiv.org/html/2311.09618v4#S2.T1
    "Table 1 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")和图[4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")所示，确认偏差越强，最终状态分布的多样性就越大。这种关联对于累积记忆和反射记忆策略都成立（图[4](https://arxiv.org/html/2311.09618v4#S2.F4
    "Figure 4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")和[6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")）。这些发现复制了在一组相互作用的LLM中，来自更经典的代理基础模型（ABM）中的一般发现，即在模型更新算法中引入确认偏差会产生更大的意见碎片化，Lorenz等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）；Flache等人（[2017](https://arxiv.org/html/2311.09618v4#bib.bib10)）。支持上述论点的统计测试见§[M](https://arxiv.org/html/2311.09618v4#A13
    "Appendix M Statistical Tests ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")。
- en: Impact of Initial Opinion Distribution
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 初始意见分布的影响
- en: 'The system’s tendency for simulated opinions to converge on ground truth prompts
    an intriguing question: If all agents start with false opinions, will they still
    converge toward a scientifically accurate consensus, or will they reinforce their
    initial beliefs and resist changing their stance? Figure [5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") shows the evolution of opinions under various initial
    distributions, using the global warming topic. Regardless of the initial opinion
    distribution, the agents altered their expressed opinions and shifted toward the
    ground truth. For instance, as shown in Figure [5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")a, under false framing, when all agents initially
    supported global warming is a hoax, they converged towards the negative spectrum
    quickly and ended up with $B=-1.3$. Interestingly, under true framing, when all
    agents initially denied the view that global warming is real, they did not completely
    flip their stance to support it, though they did shift slightly in this direction
    (Figure [5](https://arxiv.org/html/2311.09618v4#S2.F5 "Figure 5 ‣ 2.3 Cognitive
    Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")d):
    the final bias ($B=-1.2$) was more positive than the initial extreme opinion ($B=-2$).
    When at least a minority of agents held a divergent belief at the start, the group
    as a whole eventually shifted towards acknowledging global warming is real and
    is not a hoax, as shown in Figure [5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")c. Overall, these results indicate that the model’s
    inherent bias towards ground truth is robust against varying initial opinion distributions.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 系统中模拟意见趋向真实真相的倾向引发了一个耐人寻味的问题：如果所有代理人一开始持有错误的观点，他们是否仍然会朝着科学上准确的共识发展，还是会加强他们最初的信念并抵制改变立场？图[5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")展示了在各种初始分布下，意见的演变过程，这里使用的是全球变暖话题。不论初始的意见分布如何，代理人们都改变了他们表达的意见，并逐渐向真实真相靠拢。例如，如图[5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")a所示，在虚假框架下，当所有代理人最初都支持全球变暖是一个骗局时，他们很快就向负面光谱聚集，并最终得出了$B=-1.3$。有趣的是，在真实框架下，当所有代理人最初都否认全球变暖是现实的这一观点时，他们并没有完全转变立场支持这一观点，尽管他们确实稍微朝这个方向移动了（见图[5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")d）：最终的偏见值($B=-1.2$)比最初的极端意见($B=-2$)更为积极。当至少有少数代理人在一开始持有不同的信念时，整个群体最终还是倾向于承认全球变暖是真实的，而不是骗局，正如图[5](https://arxiv.org/html/2311.09618v4#S2.F5
    "Figure 5 ‣ 2.3 Cognitive Biases ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")c所示。总体而言，这些结果表明，模型对真实真相的固有偏见在不同的初始意见分布下依然保持强劲。
- en: The Strength of Bias under False Framing is Stronger than under True Framing
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在虚假框架下的偏见强度比在真实框架下更强
- en: 'As shown in Table [1](https://arxiv.org/html/2311.09618v4#S2.T1 "Table 1 ‣
    2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents"), the LLM agents have a stronger tendency to deny
    the false statement under the false framing (Cumulative Memory: $B=-1.33$; Reflective
    Memory: $B=-1.37$) than their tendency to endorse the true statement under the
    true framing (Cumulative Memory: $B=0.52$; Reflective Memory: $B=0.60$). We consider
    two possibilities. First, FLAN-T5-XXL may have an overall tendency to classify
    LLM agents’ responses as negative. Second, the LLM agents may indeed have a stronger
    tendency to deny the false statements. According to our validation of FLAN-T5-XXL’s
    ratings (detailed in §[N](https://arxiv.org/html/2311.09618v4#A14 "Appendix N
    Validation of FLAN-T5-XXL Ratings ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents")), the agreement matrix between FLAN-T5-XXL’s ratings and
    human ratings shows no systematic bias. We therefore exclude the first possibility.
    As to why the LLM agents indeed have a stronger negative tendency, our speculation
    is that, due to either pretraining, fine-tuning, or RLHF [Christiano et al.](https://arxiv.org/html/2311.09618v4#bib.bib4)
    , the LLM has been trained to readily refute false information under false framing.
    On the other hand, under true framing, there may be less training effort to ensure
    that the model endorses true information. Future studies are needed to evaluate
    the true cause.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[1](https://arxiv.org/html/2311.09618v4#S2.T1 "Table 1 ‣ 2.2 Agent’s Persona
    and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")所示，LLM代理在错误框架下更倾向于否定虚假陈述（累积记忆：$B=-1.33$；反射记忆：$B=-1.37$），而不是在正确框架下支持真实陈述（累积记忆：$B=0.52$；反射记忆：$B=0.60$）。我们考虑两种可能性。首先，FLAN-T5-XXL可能整体上倾向于将LLM代理的回答分类为负面。其次，LLM代理确实可能有更强的倾向否定虚假的陈述。根据我们对FLAN-T5-XXL评分的验证（详见§[N](https://arxiv.org/html/2311.09618v4#A14
    "Appendix N Validation of FLAN-T5-XXL Ratings ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")），FLAN-T5-XXL评分与人工评分之间的协同矩阵没有系统性的偏差。因此，我们排除了第一种可能性。至于为何LLM代理确实具有更强的否定倾向，我们的猜测是，由于预训练、微调或RLHF
    [Christiano et al.](https://arxiv.org/html/2311.09618v4#bib.bib4)的作用，LLM已经被训练成容易在错误框架下驳斥虚假信息。另一方面，在正确框架下，可能在训练时没有足够的力度来确保模型支持真实信息。未来的研究将需要评估真实原因。
- en: Sensitivity Analyses
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 敏感性分析
- en: 'Sensitivity analyses test different LLMs (GPT-4 and Vicuna) and network sizes
    ($N=20$ agents). The results show consistent trends across models (GPT-4: Table [3](https://arxiv.org/html/2311.09618v4#A10.T3
    "Table 3 ‣ Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents"); Vicuna: Table [4](https://arxiv.org/html/2311.09618v4#A10.T4
    "Table 4 ‣ Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") in §[J](https://arxiv.org/html/2311.09618v4#A10
    "Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents")) and network scales (Table [5](https://arxiv.org/html/2311.09618v4#A11.T5
    "Table 5 ‣ Appendix K Results on a Larger Network ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") in §[K](https://arxiv.org/html/2311.09618v4#A11
    "Appendix K Results on a Larger Network ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents")). In addition, we evaluate the sensitivity of our result
    to randomness due to temperature sampling. On the topic of Global Warming, we
    run the experiment three times. The effect of framing and the effect of confirmation
    bias are consistent across the three runs.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感性分析测试了不同的LLM（GPT-4和Vicuna）和网络规模（$N=20$个代理）。结果表明，不同模型之间存在一致的趋势（GPT-4：表[3](https://arxiv.org/html/2311.09618v4#A10.T3
    "Table 3 ‣ Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")；Vicuna：表[4](https://arxiv.org/html/2311.09618v4#A10.T4
    "Table 4 ‣ Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") 在§[J](https://arxiv.org/html/2311.09618v4#A10
    "Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents")）以及网络规模（表[5](https://arxiv.org/html/2311.09618v4#A11.T5 "Table
    5 ‣ Appendix K Results on a Larger Network ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") 在§[K](https://arxiv.org/html/2311.09618v4#A11 "Appendix
    K Results on a Larger Network ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")）。此外，我们还评估了结果对温度采样引起的随机性的敏感性。在全球变暖这一话题上，我们进行了三次实验。框架效应和确认偏差效应在三次实验中是一致的。
- en: 5 Related Work
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: Agent-Based Models and Opinion Dynamics Simulation
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于代理的模型与舆论动态仿真
- en: Agent-Based Models (ABMs) are the cornerstone of opinion dynamics simulation,
    defining mathematical rules for agents’ opinion updates in response to messages
    Gilbert and Terna ([2000](https://arxiv.org/html/2311.09618v4#bib.bib11)); Smaldino
    ([2023](https://arxiv.org/html/2311.09618v4#bib.bib30)); Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21));
    Chuang and Rogers ([2023](https://arxiv.org/html/2311.09618v4#bib.bib5)); Epstein
    ([2012](https://arxiv.org/html/2311.09618v4#bib.bib8)); Flache et al. ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10)).
    ABMs are valuable for predicting public opinion trends and informing intervention
    strategies. One key advantage of using ABMs is that they allow incorporating explicit
    assumptions about cognitive process in opinion updating Flache et al. ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10));
    Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)); Chuang
    and Rogers ([2023](https://arxiv.org/html/2311.09618v4#bib.bib5)). For example,
    incorporating “confirmation bias” into ABM equations causes agents to disregard
    contrasting information, often leading to fragmented opinion clusters at the group
    level. However, a significant limitation of ABMs is that they rely on numeric
    representations of opinions and messages, which oversimplifies the complexities
    of human communication. In contrast, emerging approaches using LLMs offer a more
    sophisticated method for simulating opinion dynamics through natural language.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的模型（ABM）是意见动态仿真的基石，定义了代理在响应信息时更新意见的数学规则，参考文献包括Gilbert和Terna（[2000](https://arxiv.org/html/2311.09618v4#bib.bib11)）；Smaldino（[2023](https://arxiv.org/html/2311.09618v4#bib.bib30)）；Lorenz等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）；Chuang和Rogers（[2023](https://arxiv.org/html/2311.09618v4#bib.bib5)）；Epstein（[2012](https://arxiv.org/html/2311.09618v4#bib.bib8)）；Flache等人（[2017](https://arxiv.org/html/2311.09618v4#bib.bib10)）。ABM在预测公众意见趋势和制定干预策略方面具有重要价值。使用ABM的一大优势是，它们可以将关于意见更新的认知过程的明确假设纳入其中，参考文献包括Flache等人（[2017](https://arxiv.org/html/2311.09618v4#bib.bib10)）；Lorenz等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）；Chuang和Rogers（[2023](https://arxiv.org/html/2311.09618v4#bib.bib5)）。例如，将“确认偏差”纳入ABM方程中，会导致代理忽略相反的信息，通常导致群体层面上的意见碎片化。然而，ABM的一个显著局限性是，它们依赖于意见和信息的数字表示，这简化了人类沟通的复杂性。相比之下，使用LLM的最新方法通过自然语言提供了一种更复杂的意见动态仿真方法。
- en: Simulating Social Dynamics with LLM-based Agents
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用基于LLM的代理模拟社会动态
- en: The use of LLMs in simulating social dynamics is a rapidly growing research
    area , showcasing promising results in terms of human-like interactions Park et al.
    ([2023](https://arxiv.org/html/2311.09618v4#bib.bib27), [2022](https://arxiv.org/html/2311.09618v4#bib.bib28));
    Kaiya et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib16)); Törnberg
    et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib31)); Li et al. ([2023a](https://arxiv.org/html/2311.09618v4#bib.bib17));
    Zhou et al. ([2023b](https://arxiv.org/html/2311.09618v4#bib.bib34)); Mou et al.
    ([2024](https://arxiv.org/html/2311.09618v4#bib.bib24)); Liu et al. ([2024](https://arxiv.org/html/2311.09618v4#bib.bib19)).
    Park et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib27)) devise LLM-based
    generative agents to engage in digital environments, demonstrating an ability
    to respond, plan, and remember in natural language. They exhibit complex social
    behaviors, such as organizing events. Similarly, Törnberg et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib31))
    use LLMs in conjunction with agent-based modeling to explore the impact of news
    feed algorithms in simulated social media environments. Additionally, Park et al.
    ([2022](https://arxiv.org/html/2311.09618v4#bib.bib28)) show that LLM-based agents
    are capable of generating social media posts indistinguishable from those written
    by humans. These advances underscore the potential of using LLM agents to simulate
    human social behaviors at group level. To our best knowledge, we are the first
    to propose the use of LLM as an alternative to ABM for opinion dynamics simulation.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在模拟社会动态中的应用是一个迅速发展的研究领域，展示了在人类互动方面的有希望的结果。Park等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib27)，[2022](https://arxiv.org/html/2311.09618v4#bib.bib28)）；Kaiya等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib16)）；Törnberg等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib31)）；Li等人（[2023a](https://arxiv.org/html/2311.09618v4#bib.bib17)）；Zhou等人（[2023b](https://arxiv.org/html/2311.09618v4#bib.bib34)）；Mou等人（[2024](https://arxiv.org/html/2311.09618v4#bib.bib24)）；Liu等人（[2024](https://arxiv.org/html/2311.09618v4#bib.bib19)）。Park等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib27)）设计了基于LLM的生成型代理，能够在数字环境中互动，展示了用自然语言回应、规划和记忆的能力。它们表现出复杂的社会行为，如组织活动。类似地，Törnberg等人（[2023](https://arxiv.org/html/2311.09618v4#bib.bib31)）结合LLMs与基于代理的建模，探讨了新闻推送算法在模拟社交媒体环境中的影响。此外，Park等人（[2022](https://arxiv.org/html/2311.09618v4#bib.bib28)）表明基于LLM的代理能够生成与人类撰写的社交媒体帖子无异的内容。这些进展凸显了使用LLM代理在群体层面模拟人类社会行为的潜力。据我们所知，我们是第一个提出将LLM作为ABM替代方案用于意见动态模拟的研究。
- en: 6 Conclusion
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: This study has explored the use Large Language Models (LLMs) for understanding
    opinion dynamics in groups of simulated agents communicating via natural language.
    In contrast to more traditional ABMs, LLMs can interpret and produce natural language,
    can role-play differing personas, and can simulate human-like linguistic communication.
    We therefore considered whether groups of interacting LLM agents could provide
    a basis for simulating opinion dynamics comparable to those studied with classical
    ABMs. Our findings confirm the potential of LLMs in opinion dynamics simulations
    but also reveal limitations, particularly their tendency to align with factual
    information regardless of their personas, which restricts their role-play effectiveness
    for individuals with fact-resistant beliefs like climate change denial.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究探讨了使用大型语言模型（LLMs）来理解通过自然语言交流的模拟代理群体中的意见动态。与更传统的基于代理模型（ABMs）相比，LLMs能够解读和生成自然语言，能够扮演不同的角色，并能模拟类人语言交流。因此，我们考虑了互动的LLM代理群体是否可以为模拟类似于经典ABM中研究的意见动态提供基础。我们的研究结果确认了LLMs在意见动态模拟中的潜力，但也揭示了其局限性，特别是它们倾向于与事实信息保持一致，而不管其角色设定如何，这限制了它们在像气候变化否认者这类对事实抗拒的个体的角色扮演效果。
- en: 'Significant efforts have been made to prevent LLMs from exhibiting harmful
    biases. However, for simulating critical undesired social phenomena (e.g., misinformation,
    polarization), it is crucial to have simulated agents accurately reflect the breadth
    of human behavior and belief, even those that are maladaptive. Our study suggests
    that prompting alone may be insufficient for LLM agents to fully replicate the
    diverse viewpoints. This leads us to a potential future direction: fine-tuning
    LLM agents with actual human discourse data. Such an approach could lead to more
    accurate models of human belief dynamics.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 已经进行了大量努力，以防止大语言模型（LLMs）展现有害的偏见。然而，在模拟一些关键的、不良的社会现象（例如，虚假信息、极化）时，至关重要的是，模拟的代理人能够准确地反映人类行为和信念的广度，包括那些不适应的行为。我们的研究表明，单靠提示可能不足以让LLM代理人充分再现多样的观点。这引出了一个潜在的未来方向：通过实际的人类话语数据对LLM代理人进行微调。这种方法可能会导致更准确的人类信念动态模型。
- en: Limitations
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: Model Dependency and Generalizability
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型依赖性与普适性
- en: A key limitation of our study is the exclusive use of models that have undergone
    Reinforcement Learning with Human Feedback (RLHF; Christiano et al., [2017](https://arxiv.org/html/2311.09618v4#bib.bib3);
    Ziegler et al., [2019](https://arxiv.org/html/2311.09618v4#bib.bib35)). This may
    lead to the truth-converging tendency in the LLM agents. Given that various language
    models exhibit distinct inherent biases Feng et al. ([2023](https://arxiv.org/html/2311.09618v4#bib.bib9)),
    LLM agents using different models could display varying patterns in opinion dynamics.
    To fully assess the generalizability of our findings, future research should include
    a broad spectrum of models.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的一个关键限制是仅使用经过强化学习与人类反馈（RLHF；Christiano 等人，[2017](https://arxiv.org/html/2311.09618v4#bib.bib3)；Ziegler
    等人，[2019](https://arxiv.org/html/2311.09618v4#bib.bib35)）的模型。这可能导致LLM代理人趋向于真理的倾向。鉴于不同语言模型展示了各自固有的偏见（Feng
    等人，[2023](https://arxiv.org/html/2311.09618v4#bib.bib9)），使用不同模型的LLM代理人可能在意见动态上表现出不同的模式。为了全面评估我们发现的普适性，未来的研究应包括多种模型。
- en: Reduction of Opinion to One-Dimensional Scalar
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将意见简化为一维标量
- en: Our study aligns with classic ABMs in reducing opinions to a one-dimensional
    scalar $o\in\mathbb{R}$, which simplifies the complex nature of opinion formation.
    However, a more nuanced approach could offer deeper insights. Future studies could
    adopt a fine-grained or even qualitative analysis to explore how agents modify
    their opinions, determine which messages hold greater persuasive power, and assess
    how persuasion varies based on different agent personas. Such an approach would
    provide a richer understanding of the subtleties in LLM agents’ opinion dynamics.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究与经典的代理人基础模型（ABMs）一致，将意见简化为一维标量 $o\in\mathbb{R}$，这简化了意见形成的复杂性。然而，更细致的分析方法可能提供更深刻的见解。未来的研究可以采用细粒度甚至定性分析，探索代理人如何修改他们的意见，确定哪些信息具有更大的说服力，并评估在不同代理人角色下说服力的变化。这种方法将为我们提供更丰富的理解，揭示LLM代理人意见动态的细微差别。
- en: Limitation in Topic Selection
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 话题选择的局限性
- en: Our research focused on topics with clear, established ground truths. However,
    many crucial topics, such as the effectiveness of political leaders or the best
    policies for complex societal issues, lack a definitive truth. These topics are
    more open-ended and subjective. Future studies should consider including such
    topics to capture a broader and more nuanced spectrum of opinions and debates.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究集中在具有明确、确立的真理基础的话题上。然而，许多重要话题，如政治领导人的有效性或解决复杂社会问题的最佳政策，缺乏明确的真理。这些话题更加开放和主观。未来的研究应考虑包括此类话题，以捕捉更广泛和更细致的意见和辩论。
- en: The Role of Other Demographic Information
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 其他人口统计信息的作用
- en: While we focus on the role of agents’ initial beliefs in opinion dynamics simulation,
    a more nuanced analysis on the role of other demographic information could offer
    deeper insights. For example, future studies could adopt a fine-grained or qualitative
    analysis to explore how agents’ demographic features (like political leaning)
    play a role in agents’ information exchanges and belief updating.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们聚焦于代理人初始信念在意见动力学模拟中的作用，但对其他人口统计信息作用的更细致分析可能会提供更深入的见解。例如，未来的研究可以采用细粒度或定性分析，探索代理人的人口特征（如政治倾向）在代理人信息交换和信念更新中的作用。
- en: Limitation in Network Structure
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 网络结构的局限性
- en: In the present study, LLM agents get to interact with everyone else in the network.
    While in line with classic setup used in ABM simulation Flache et al. ([2017](https://arxiv.org/html/2311.09618v4#bib.bib10));
    Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)), this is
    not close to social interactions in the real world. For example, people with similar
    background tend to interact with one another McPherson et al. ([2001](https://arxiv.org/html/2311.09618v4#bib.bib23)).
    Future studies should consider investigating LLM agents’ opinion dynamics with
    more realistic network structures.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，LLM代理与网络中的其他所有人进行互动。虽然与ABM仿真中使用的经典设置一致，Flache等人（[2017](https://arxiv.org/html/2311.09618v4#bib.bib10)）；Lorenz等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）的研究也如此，但这与现实世界中的社会互动并不接近。例如，背景相似的人倾向于相互互动，McPherson等人（[2001](https://arxiv.org/html/2311.09618v4#bib.bib23)）的研究指出。未来的研究应考虑在更现实的网络结构中研究LLM代理的意见动态。
- en: Ethics Statement
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: While introducing confirmation bias into LLM agents can lead to opinion fragmentation
    and reduced convergence on factual consensus, it’s important to understand this
    approach within the broader scope of studying group-level social phenomena. Simulating
    biased behavior in agents is not an endorsement of these biases, but a critical
    step in comprehensively understanding the dynamics of various undesired social
    issues, including misinformation spread, polarization, and echo chamber formation.
    Developing human-like LLM agents with resistant viewpoints is essential for devising
    strategies to address these social challenges. In addition, we will release the
    code base exclusively for research purposes. Finally, since we are using OpenAI’s
    API, we make sure that we comply with its intended use ⁷⁷7[https://openai.com/policies/terms-of-use](https://openai.com/policies/terms-of-use).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在LLM代理中引入确认偏差可能导致意见碎片化和对事实共识的收敛性下降，但在更广泛的群体社会现象研究中理解这一方法非常重要。模拟代理中的偏见行为并非对这些偏见的认同，而是全面理解各种不良社会问题（包括错误信息传播、极化和回音室形成）动态的关键步骤。开发具有人类思维的具有抗拒观点的LLM代理对于制定应对这些社会挑战的策略至关重要。此外，我们将仅为研究目的发布代码库。最后，由于我们使用了OpenAI的API，我们确保遵守其预定用途⁷⁷7[https://openai.com/policies/terms-of-use](https://openai.com/policies/terms-of-use)。
- en: Acknowledgements
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'We thank the reviewers, the area chair for their feedback. This work was funded
    by the Multi University Research Initiative grant from the Department of Defense,
    W911NF2110317, Cohesive and Robust Human-Bot Cybersecurity Teams, the John S.
    and James L. Knight Foundation (Award Number: MSN231314), and the National Science
    Foundation through the Convergence Accelerator Track F: Course Correct: Precision
    Guidance Against Misinformation (Agency Tracking Number: 2230692; Award Number:
    MSN 266268).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢审稿人和领域主席的反馈。本研究得到了国防部多大学研究计划（W911NF2110317）、凝聚力和稳健的人工智能-机器人网络安全团队、John S.
    和 James L. Knight基金会（奖项编号：MSN231314）以及通过跨越加速器F轨道：纠正课程：精准指导反对错误信息（机构跟踪编号：2230692；奖项编号：MSN
    266268）提供的资助。
- en: References
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Budak et al. (2011) Ceren Budak, Divyakant Agrawal, and Amr El Abbadi. 2011.
    Limiting the spread of misinformation in social networks. In *Proceedings of the
    20th international conference on World wide web*, pages 665–674.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Budak等人（2011）Ceren Budak、Divyakant Agrawal和Amr El Abbadi。2011年。限制社交网络中错误信息的传播。在*第20届国际万维网会议论文集*，第665-674页。
- en: Chase (2022) Harrison Chase. 2022. [Langchain](https://github.com/langchain-ai/langchain).
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chase（2022）Harrison Chase。2022年。[Langchain](https://github.com/langchain-ai/langchain)。
- en: Christiano et al. (2017) Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic,
    Shane Legg, and Dario Amodei. 2017. Deep reinforcement learning from human preferences.
    *Advances in neural information processing systems*, 30.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christiano等人（2017）Paul F Christiano、Jan Leike、Tom Brown、Miljan Martic、Shane
    Legg和Dario Amodei。2017年。基于人类偏好的深度强化学习。*神经信息处理系统进展*，30。
- en: (4) Paul F Christiano, Jan Leike, Tom B Brown, Miljan Martic, Shane Legg, and
    Dario Amodei. Deep reinforcement learning from human preferences.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （4）Paul F Christiano、Jan Leike、Tom B Brown、Miljan Martic、Shane Legg和Dario Amodei。基于人类偏好的深度强化学习。
- en: 'Chuang and Rogers (2023) Yun-Shiuan Chuang and Timothy T Rogers. 2023. Computational
    agent-based models in opinion dynamics: A survey on social simulations and empirical
    studies. *arXiv preprint arXiv:2306.03446*.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang和Rogers（2023）Yun-Shiuan Chuang和Timothy T Rogers。2023年。意见动态中的计算代理模型：社会模拟和实证研究的综述。*arXiv预印本arXiv:2306.03446*。
- en: Chung et al. (2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay,
    William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    2022. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chung 等人（2022）Hyung Won Chung、Le Hou、Shayne Longpre、Barret Zoph、Yi Tay、William
    Fedus、Eric Li、Xuezhi Wang、Mostafa Dehghani、Siddhartha Brahma 等人。2022年。扩展指令微调语言模型。*arXiv
    预印本 arXiv:2210.11416*。
- en: 'Dziri et al. (2022) Nouha Dziri, Sivan Milton, Mo Yu, Osmar Zaiane, and Siva
    Reddy. 2022. On the origin of hallucinations in conversational models: Is it the
    datasets or the models? *arXiv preprint arXiv:2204.07931*.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dziri 等人（2022）Nouha Dziri、Sivan Milton、Mo Yu、Osmar Zaiane 和 Siva Reddy。2022年。在对话模型中幻觉的来源：是数据集还是模型？*arXiv
    预印本 arXiv:2204.07931*。
- en: 'Epstein (2012) Joshua M Epstein. 2012. *Generative social science: Studies
    in agent-based computational modeling*. Princeton University Press.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Epstein（2012）Joshua M Epstein。2012年。*生成性社会科学：基于代理的计算模型研究*。普林斯顿大学出版社。
- en: 'Feng et al. (2023) Shangbin Feng, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov.
    2023. [From pretraining data to language models to downstream tasks: Tracking
    the trails of political biases leading to unfair NLP models](https://doi.org/10.18653/v1/2023.acl-long.656).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 11737–11762, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng 等人（2023）Shangbin Feng、Chan Young Park、Yuhan Liu 和 Yulia Tsvetkov。2023年。[从预训练数据到语言模型再到下游任务：追踪导致不公平
    NLP 模型的政治偏见路径](https://doi.org/10.18653/v1/2023.acl-long.656)。在*第61届计算语言学协会年会论文集（第1卷：长篇论文）*中，第11737–11762页，加拿大多伦多，计算语言学协会。
- en: 'Flache et al. (2017) Andreas Flache, Michael Mäs, Thomas Feliciani, Edmund
    Chattoe-Brown, Guillaume Deffuant, Sylvie Huet, and Jan Lorenz. 2017. Models of
    social influence: Towards the next frontiers. *Journal of Artificial Societies
    and Social Simulation*, 20(4).'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flache 等人（2017）Andreas Flache、Michael Mäs、Thomas Feliciani、Edmund Chattoe-Brown、Guillaume
    Deffuant、Sylvie Huet 和 Jan Lorenz。2017年。社会影响模型：迈向下一个前沿。*人工社会与社会模拟杂志*，20(4)。
- en: Gilbert and Terna (2000) Nigel Gilbert and Pietro Terna. 2000. How to build
    and use agent-based models in social science. *Mind & Society*, 1:57–72.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gilbert 和 Terna（2000）Nigel Gilbert 和 Pietro Terna。2000年。如何在社会科学中构建和使用基于代理的模型。*思维与社会*，1:57–72。
- en: 'Ginossar et al. (2022) Tamar Ginossar, Iain J Cruickshank, Elena Zheleva, Jason
    Sulskis, and Tanya Berger-Wolf. 2022. Cross-platform spread: vaccine-related content,
    sources, and conspiracy theories in youtube videos shared in early twitter covid-19
    conversations. *Human vaccines & immunotherapeutics*, 18(1):1–13.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ginossar 等人（2022）Tamar Ginossar、Iain J Cruickshank、Elena Zheleva、Jason Sulskis
    和 Tanya Berger-Wolf。2022年。跨平台传播：在早期 Twitter 新冠对话中分享的 YouTube 视频中的疫苗相关内容、来源和阴谋论。*人类疫苗与免疫治疗学*，18(1):1–13。
- en: Hayes and Krippendorff (2007) Andrew F Hayes and Klaus Krippendorff. 2007. Answering
    the call for a standard reliability measure for coding data. *Communication methods
    and measures*, 1(1):77–89.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hayes 和 Krippendorff（2007）Andrew F Hayes 和 Klaus Krippendorff。2007年。呼吁为编码数据提供标准可靠性度量。*传播方法与测量*，1(1):77–89。
- en: 'Huang et al. (2023) Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin
    Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al.
    2023. A survey on hallucination in large language models: Principles, taxonomy,
    challenges, and open questions. *arXiv preprint arXiv:2311.05232*.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2023）Lei Huang、Weijiang Yu、Weitao Ma、Weihong Zhong、Zhangyin Feng、Haotian
    Wang、Qianglong Chen、Weihua Peng、Xiaocheng Feng、Bing Qin 等人。2023年。大型语言模型中的幻觉调查：原理、分类法、挑战和开放问题。*arXiv
    预印本 arXiv:2311.05232*。
- en: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey
    of hallucination in natural language generation. *ACM Computing Surveys*, 55(12):1–38.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji 等人（2023）Ziwei Ji、Nayeon Lee、Rita Frieske、Tiezheng Yu、Dan Su、Yan Xu、Etsuko
    Ishii、Ye Jin Bang、Andrea Madotto 和 Pascale Fung。2023年。自然语言生成中的幻觉调查。*ACM 计算机调查*，55(12):1–38。
- en: 'Kaiya et al. (2023) Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes,
    Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, and Andrew Ahn. 2023. Lyfe agents:
    Generative agents for low-cost real-time social interactions. *arXiv preprint
    arXiv:2310.02172*.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaiya 等人（2023）赵凯雅、Michelangelo Naim、Jovana Kondic、Manuel Cortes、贾欣·戈、舒颖·罗、广宇·罗伯特·杨
    和 Andrew Ahn。2023年。Lyfe 代理：低成本实时社交互动的生成代理。*arXiv 预印本 arXiv:2310.02172*。
- en: Li et al. (2023a) Chao Li, Xing Su, Chao Fan, Haoying Han, Cong Xue, and Chunmo
    Zheng. 2023a. Quantifying the impact of large language models on collective opinion
    dynamics. *arXiv preprint arXiv:2308.03313*.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2023a) Chao Li, Xing Su, Chao Fan, Haoying Han, Cong Xue, 和 Chunmo Zheng.
    2023a. 量化大型语言模型对集体意见动态的影响。*arXiv 预印本 arXiv:2308.03313*。
- en: 'Li et al. (2023b) Yixia Li, Rong Xiang, Yanlin Song, and Jing Li. 2023b. Unipoll:
    A unified social media poll generation framework via multi-objective optimization.
    *arXiv preprint arXiv:2306.06851*.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 (2023b) Yixia Li, Rong Xiang, Yanlin Song, 和 Jing Li. 2023b. Unipoll：一种通过多目标优化生成统一社交媒体投票的框架。*arXiv
    预印本 arXiv:2306.06851*。
- en: 'Liu et al. (2024) Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing Gao, Ji Zhang,
    and Rui Yan. 2024. From skepticism to acceptance: Simulating the attitude dynamics
    toward fake news. *arXiv preprint arXiv:2403.09498*.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2024) Yuhan Liu, Xiuying Chen, Xiaoqing Zhang, Xing Gao, Ji Zhang, 和
    Rui Yan. 2024. 从怀疑到接受：模拟对虚假新闻的态度动态。*arXiv 预印本 arXiv:2403.09498*。
- en: Loomba et al. (2021) Sahil Loomba, Alexandre de Figueiredo, Simon J Piatek,
    Kristen de Graaf, and Heidi J Larson. 2021. Measuring the impact of covid-19 vaccine
    misinformation on vaccination intent in the uk and usa. *Nature human behaviour*,
    5(3):337–348.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loomba 等人 (2021) Sahil Loomba, Alexandre de Figueiredo, Simon J Piatek, Kristen
    de Graaf, 和 Heidi J Larson. 2021. 测量 COVID-19 疫苗虚假信息对英国和美国疫苗接种意图的影响。*自然人类行为*，5(3):337–348。
- en: 'Lorenz et al. (2021) Jan Lorenz, Martin Neumann, and Tobias Schröder. 2021.
    Individual attitude change and societal dynamics: Computational experiments with
    psychological theories. *Psychological Review*, 128(4):623.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lorenz 等人 (2021) Jan Lorenz, Martin Neumann, 和 Tobias Schröder. 2021. 个体态度变化与社会动态：基于心理学理论的计算实验。*心理学评论*，128(4):623。
- en: 'Lu et al. (2015) Wei Lu, Wei Chen, and Laks VS Lakshmanan. 2015. From competition
    to complementarity: comparative influence diffusion and maximization. *Proceedings
    of the VLDB Endowment*, 9(2):60–71.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等人 (2015) Wei Lu, Wei Chen, 和 Laks VS Lakshmanan. 2015. 从竞争到互补性：比较影响扩散与最大化。*VLDB
    纪要*，9(2):60–71。
- en: 'McPherson et al. (2001) Miller McPherson, Lynn Smith-Lovin, and James M Cook.
    2001. Birds of a feather: Homophily in social networks. *Annual review of sociology*,
    27(1):415–444.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McPherson 等人 (2001) Miller McPherson, Lynn Smith-Lovin, 和 James M Cook. 2001.
    物以类聚：社交网络中的同质性。*社会学年鉴*，27(1):415–444。
- en: 'Mou et al. (2024) Xinyi Mou, Zhongyu Wei, and Xuanjing Huang. 2024. Unveiling
    the truth and facilitating change: Towards agent-based large-scale social movement
    simulation. *arXiv preprint arXiv:2402.16333*.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mou 等人 (2024) Xinyi Mou, Zhongyu Wei, 和 Xuanjing Huang. 2024. 揭示真相并促进变革：面向基于代理的大规模社会运动模拟。*arXiv
    预印本 arXiv:2402.16333*。
- en: 'Nickerson (1998) Raymond S Nickerson. 1998. Confirmation bias: A ubiquitous
    phenomenon in many guises. *Review of general psychology*, 2(2):175–220.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nickerson (1998) Raymond S Nickerson. 1998. 确认偏误：一种无处不在的现象。*普通心理学评论*，2(2):175–220。
- en: OpenAI (2022) OpenAI. 2022. Introducing ChatGPT. [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt).
    [Accessed 13-10-2023].
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2022) OpenAI. 2022. 介绍 ChatGPT。 [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)。
    [访问时间：2023年10月13日]。
- en: 'Park et al. (2023) Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. *arXiv preprint arXiv:2304.03442*.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人 (2023) Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel
    Morris, Percy Liang, 和 Michael S Bernstein. 2023. 生成性代理：人类行为的互动模拟。*arXiv 预印本 arXiv:2304.03442*。
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2022. Social simulacra: Creating
    populated prototypes for social computing systems. In *Proceedings of the 35th
    Annual ACM Symposium on User Interface Software and Technology*, pages 1–18.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人 (2022) Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel
    Morris, Percy Liang, 和 Michael S Bernstein. 2022. 社会模拟：为社交计算系统创建具有人口特征的原型。载于 *第35届ACM用户界面软件与技术年会论文集*，第1–18页。
- en: Pennycook et al. (2021) Gordon Pennycook, Ziv Epstein, Mohsen Mosleh, Antonio A
    Arechar, Dean Eckles, and David G Rand. 2021. Shifting attention to accuracy can
    reduce misinformation online. *Nature*, 592(7855):590–595.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pennycook 等人 (2021) Gordon Pennycook, Ziv Epstein, Mohsen Mosleh, Antonio A
    Arechar, Dean Eckles, 和 David G Rand. 2021. 将注意力转向准确性可以减少在线虚假信息。*自然*，592(7855):590–595。
- en: 'Smaldino (2023) Paul Smaldino. 2023. *Modeling social behavior: Mathematical
    and agent-based models of social dynamics and cultural evolution*. Princeton University
    Press.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smaldino (2023) Paul Smaldino. 2023. *社会行为建模：社会动态与文化演化的数学模型与基于代理的模型*。普林斯顿大学出版社。
- en: Törnberg et al. (2023) Petter Törnberg, Diliara Valeeva, Justus Uitermark, and
    Christopher Bail. 2023. Simulating social media using large language models to
    evaluate alternative news feed algorithms. *arXiv preprint arXiv:2310.05984*.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Törnberg 等人 (2023) 佩特·托恩伯格、迪利亚拉·瓦莱耶娃、贾斯图斯·乌特马克 和 克里斯托弗·贝尔，2023。《使用大规模语言模型模拟社交媒体以评估替代新闻推送算法》。*arXiv
    预印本 arXiv:2310.05984*。
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.
    2023. Judging llm-as-a-judge with mt-bench and chatbot arena. *arXiv preprint
    arXiv:2306.05685*.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人 (2023) 练敏郑、韦琳·蒋、英生、思源庄、张浩吴、永浩庄、子琳、卓涵李、大成李、埃里克·邢 等人，2023。《使用 mt-bench
    和聊天机器人竞技场评估 llm-as-a-judge》。*arXiv 预印本 arXiv:2306.05685*。
- en: Zhou et al. (2023a) Wenxuan Zhou, Sheng Zhang, Hoifung Poon, and Muhao Chen.
    2023a. Context-faithful prompting for large language models. *arXiv preprint arXiv:2303.11315*.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 (2023a) 文轩周、胜张、Hoifung Poon 和 慕豪陈，2023a。《面向大规模语言模型的上下文忠实提示》。*arXiv 预印本
    arXiv:2303.11315*。
- en: 'Zhou et al. (2023b) Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei
    Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig,
    et al. 2023b. Sotopia: Interactive evaluation for social intelligence in language
    agents. In *The Twelfth International Conference on Learning Representations*.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人 (2023b) 许晖周、豪朱、丽娜·马图尔、若鸿张、浩飞于、正阳齐、路易-菲利普·莫朗西、约纳坦·比斯克、丹尼尔·弗里德、格雷厄姆·纽比格
    等人，2023b。《Sotopia：面向语言智能体的社会智能交互评估》。发表于*第十二届国际学习表征会议*。
- en: Ziegler et al. (2019) Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown,
    Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2019. Fine-tuning
    language models from human preferences. *arXiv preprint arXiv:1909.08593*.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziegler 等人 (2019) 丹尼尔·M·齐格勒、尼桑·斯蒂农、杰弗里·吴、汤姆·B·布朗、阿列克·拉德福德、大里奥·阿莫代伊、保罗·克里斯蒂亚诺
    和 杰弗里·欧文，2019。《从人类偏好中微调语言模型》。*arXiv 预印本 arXiv:1909.08593*。
- en: Appendix A Results of Global Warming Topic with Reflective Memory
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 全球变暖话题的反思记忆结果
- en: In the main text, Figure [4](https://arxiv.org/html/2311.09618v4#S2.F4 "Figure
    4 ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") shows the LLM agent opinion dynamics when discussing
    about global warming when using cumulative memory. Here, Figure [6](https://arxiv.org/html/2311.09618v4#A1.F6
    "Figure 6 ‣ Appendix A Results of Global Warming Topic with Reflective Memory
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents") shows the result
    when using reflective memory.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在正文中，图 [4](https://arxiv.org/html/2311.09618v4#S2.F4 "图 4 ‣ 2.2 智能体的人格和记忆 ‣
    2 方法 ‣ 使用基于大规模语言模型的智能体模拟意见动态") 显示了在使用累积记忆时，LLM 智能体讨论全球变暖时的意见动态。这里，图 [6](https://arxiv.org/html/2311.09618v4#A1.F6
    "图 6 ‣ 附录 A 全球变暖话题的反思记忆结果 ‣ 使用基于大规模语言模型的智能体模拟意见动态") 显示了使用反思记忆时的结果。
- en: 'Figure 6: Opinion trajectories $\langle o_{i}\rangle$ of LLM agents and the
    final opinion distribution $F_{o}^{T}$ on the topic of Global Warming. Panels
    (a) and (b) display the impact of cognitive biases under (a) false and (b) true
    framing conditions, respectively. Each row represents a different level of confirmation
    bias: no confirmation bias (top row), weak confirmation bias (middle row), and
    strong confirmation bias (bottom row). Panels (c) and (d) serve as baselines,
    with (c) being role-playing but with no interaction, and (d) being no role-playing
    and no interaction, respectively. The LLM agents in this figure use reflective
    memory. The color of each line plot corresponds to the agent’s initial opinion
    $o_{i}^{t=0}$: dark blue (+2), light blue (+1), grey (0), light red (-1), and
    dark red (-2), corresponding to opinions ranging from strongly agree to strongly
    disagree. The LLM agents in this figure use cumulative memory.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：LLM 智能体的意见轨迹 $\langle o_{i}\rangle$ 和全球变暖话题的最终意见分布 $F_{o}^{T}$。面板 (a) 和
    (b) 分别显示在 (a) 错误和 (b) 正确框架条件下，认知偏差的影响。每行代表不同程度的确认偏差：无确认偏差（最上面一行），弱确认偏差（中间一行），强确认偏差（最底一行）。面板
    (c) 和 (d) 用作基线，其中 (c) 为角色扮演但无互动，(d) 为无角色扮演且无互动。此图中的 LLM 智能体使用反思记忆。每条线条的颜色对应智能体的初始意见
    $o_{i}^{t=0}$：深蓝色 (+2)、浅蓝色 (+1)、灰色 (0)、浅红色 (-1) 和深红色 (-2)，分别对应从强烈同意到强烈不同意的意见范围。此图中的
    LLM 智能体使用累积记忆。
- en: Appendix B Full List of Personas
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 人格特征完整列表
- en: In this section, we list the full list of $10$ agents along with their personas
    that interact in the group dynamics settings in our agent-based model (ABM).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们列出了我们基于智能体的模型 (ABM) 中，参与群体动态设置的 $10$ 个智能体及其人格特征的完整列表。
- en: '{mdframed}'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Benjamin Lee Initial Belief: Slightly Negative opinion about XYZ Political
    leaning: Lean Democrat Age: 37 Gender: Male Ethnicity: Asian American Education:
    Master’s Degree in Economics Occupation: Financial Analyst'
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：本杰明·李 初始信念：对XYZ持轻微负面看法 政治倾向：偏向民主党 年龄：37 性别：男性 种族：亚裔美国人 教育：经济学硕士学位 职业：金融分析师
- en: '{mdframed}'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Maya Jackson Initial Belief: Strongly Negative opinion about XYZ Political
    leaning: Strong Republican Age: 29 Gender: Female Ethnicity: Black Education:
    Bachelor’s Degree in Business Management Occupation: Marketing Specialist'
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：玛雅·杰克逊 初始信念：对XYZ持强烈负面看法 政治倾向：强烈共和党人 年龄：29 性别：女性 种族：黑人 教育：工商管理学士学位 职业：市场营销专员
- en: '{mdframed}'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Ethan Wilson Initial Belief: Slightly Positive opinion about XYZ Political
    leaning: Moderate Age: 26 Gender: Male Ethnicity: White Education: Bachelor’s
    Degree in Journalism Occupation: Freelance Writer'
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：伊桑·威尔逊 初始信念：对XYZ持轻微正面看法 政治倾向：中立 年龄：26 性别：男性 种族：白人 教育：新闻学学士学位 职业：自由撰稿人
- en: '{mdframed}'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Aisha Patel Initial Belief: Neutral opinion about XYZ Political leaning:
    Lean Republican Age: 41 Gender: Female Ethnicity: South Asian Education: Doctor
    of Medicine (M.D.) Occupation: Pediatrician'
  id: totrans-168
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：艾莎·帕特尔 初始信念：对XYZ持中立看法 政治倾向：偏向共和党 年龄：41 性别：女性 种族：南亚人 教育：医学博士（M.D.） 职业：儿科医生
- en: '{mdframed}'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Samuel Wright Initial Belief: Strongly Negative opinion about XYZ Political
    leaning: Strong Democrat Age: 58 Gender: Male Ethnicity: White Education: Ph.D.
    in Anthropology Occupation: University Professor'
  id: totrans-170
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：塞缪尔·赖特 初始信念：对XYZ持强烈负面看法 政治倾向：强烈民主党人 年龄：58 性别：男性 种族：白人 教育：人类学博士学位 职业：大学教授
- en: '{mdframed}'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Olivia Garcia Initial Belief: Strongly Positive opinion about XYZ Political
    leaning: Strong Democrat Age: 34 Gender: Female Ethnicity: Hispanic Education:
    Master’s Degree in Sociology Occupation: Non-profit Program Manager'
  id: totrans-172
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：奥利维亚·加西亚 初始信念：对XYZ持强烈正面看法 政治倾向：强烈民主党人 年龄：34 性别：女性 种族：西班牙裔 教育：社会学硕士学位 职业：非营利项目经理
- en: '{mdframed}'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Sophia Nguyen Initial Belief: Slightly Negative opinion about XYZ Political
    leaning: Lean Republican Age: 24 Gender: Female Ethnicity: Asian American Education:
    Student (Undergraduate, Political Science) Occupation: Intern at Law Firm'
  id: totrans-174
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：索菲亚·阮 初始信念：对XYZ持轻微负面看法 政治倾向：偏向共和党 年龄：24 性别：女性 种族：亚裔美国人 教育：学生（本科，政治学） 职业：律师事务所实习生
- en: '{mdframed}'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Sarah Martinez Initial Belief: Strongly Positive opinion about XYZ Political
    leaning: Lean Democrat Age: 28 Gender: Female Ethnicity: Hispanic Education: Master’s
    Degree in Film Studies Occupation: Film Critic'
  id: totrans-176
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：莎拉·马丁内斯 初始信念：对XYZ持强烈正面看法 政治倾向：偏向民主党 年龄：28 性别：女性 种族：西班牙裔 教育：电影研究硕士学位 职业：电影评论家
- en: '{mdframed}'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Jordan White Initial Belief: Slightly Positive opinion about XYZ Political
    leaning: Moderate Age: 23 Gender: Female Ethnicity: Black Education: Student (Undergraduate,
    Sociology) Occupation: Part-time Retail Worker'
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：乔丹·怀特 初始信念：对XYZ持轻微正面看法 政治倾向：中立 年龄：23 性别：女性 种族：黑人 教育：学生（本科，社会学） 职业：兼职零售工作者
- en: '{mdframed}'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}'
- en: 'Name: Lucas Johnson Initial Belief: Neutral opinion about XYZ Political leaning:
    Moderate Age: 37 Gender: Male Ethnicity: Black Education: Bachelor’s Degree in
    Sociology Occupation: Diversity and Inclusion Manager'
  id: totrans-180
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：卢卡斯·约翰逊 初始信念：对XYZ持中立看法 政治倾向：中立 年龄：37 性别：男性 种族：黑人 教育：社会学学士学位 职业：多样性与包容性经理
- en: Appendix C Detailed Description of the Discrete Opinion Space $\mathbb{O}$
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 离散意见空间$\mathbb{O}$的详细描述
- en: 'The discrete opinion space $\mathbb{O}$ used in our simulations includes five
    possible values, each representing a different opinion on a given topic (referred
    to as “XYZ”). The values are as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在模拟中使用的离散意见空间$\mathbb{O}$包括五个可能的值，每个值代表对给定主题（称为“XYZ”）的不同意见。这些值如下：
- en: •
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '-2: Strongly negative opinion about XYZ.'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: -2：对XYZ持强烈负面看法。
- en: •
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '-1: Slightly negative opinion about XYZ.'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: -1：对XYZ持轻微负面看法。
- en: •
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '0: Neutral opinion about XYZ.'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 0：对XYZ持中立看法。
- en: •
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '1: Slightly positive opinion about XYZ.'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1：对XYZ持轻微正面看法。
- en: •
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '2: Strongly positive opinion about XYZ.'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2：对XYZ持强烈正面看法。
- en: The opinion space $\mathbb{O}$ is used when initializing an agent’s initial
    belief $o_{i}^{t=0}$ (§[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2 "2.2 Agent’s
    Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of
    LLM-based Agents")) and classifying opinion from verbal report $r_{j}^{t}$ (§[3](https://arxiv.org/html/2311.09618v4#S3
    "3 Experimental Settings ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents") and §[I](https://arxiv.org/html/2311.09618v4#A9 "Appendix I Opinion Classification
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")). Note that
    the size of $\mathbb{O}$ can be easily generalized to accommodate a broader range
    of opinion scales.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 观点空间$\mathbb{O}$用于初始化代理的初始信念$o_{i}^{t=0}$（§[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2
    "2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")）并对口头报告的观点进行分类$r_{j}^{t}$（§[3](https://arxiv.org/html/2311.09618v4#S3
    "3 Experimental Settings ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")和§[I](https://arxiv.org/html/2311.09618v4#A9 "Appendix I Opinion Classification
    ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")）。请注意，$\mathbb{O}$的大小可以很容易地推广，以适应更广泛的观点尺度。
- en: Appendix D Agent Interaction Prompts
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 代理互动提示
- en: In this section, we list the prompts used for facilitation of the interactions
    between the agents. Specifically, we start with the prompt that introduces the
    agents’ persona, followed by the prompts for them receiving and writing tweets
    respectively. All prompts are for the specific topic of debate on flat earth with
    positive framing (see  §[H](https://arxiv.org/html/2311.09618v4#A8 "Appendix H
    Full List of Topics ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们列出了促进代理之间互动的提示。具体来说，我们从介绍代理角色的提示开始，然后分别列出它们接收和编写推文的提示。所有提示都与关于地球是平的辩论话题有关，并采用积极的框架（参见§[H](https://arxiv.org/html/2311.09618v4#A8
    "Appendix H Full List of Topics ‣ Simulating Opinion Dynamics with Networks of
    LLM-based Agents")）。
- en: 1\. Initialize Persona Prompt
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 初始化角色提示
- en: ‘‘Role play this person.
  id: totrans-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘扮演这个角色。
- en: '{AGENT_PERSONA}'
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{AGENT_PERSONA}'
- en: ''
  id: totrans-199
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now, {AGENT_NAME}, you have been interacting with other strangers on Twitter.
    You can decide to change or maintain your belief about the theory XYZ that claims
    that the Earth is flat after interacting with other strangers.
  id: totrans-200
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在，{AGENT_NAME}，你已经和其他陌生人在Twitter上互动过。你可以在与其他陌生人互动后，决定是否改变或保持你对声称地球是平的XYZ理论的信念。
- en: ''
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You would produce tweets that reflect your honest belief, and you would also
    see other strangers’ tweets. After seeing other people’s tweets, you would be
    asked about your belief about the theory XYZ that claims that the Earth is flat.’’
  id: totrans-202
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你将发布反映你真实信念的推文，并且你也会看到其他陌生人的推文。在看到其他人的推文后，你会被询问你对声称地球是平的XYZ理论的看法。’’
- en: 2\. Write Tweet Prompt
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 编写推文提示
- en: ‘‘Now, {AGENT_NAME}, please write a tweet about the theory XYZ that claims that
    the Earth is flat. The tweet should reflect your honest belief.
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘现在，{AGENT_NAME}，请写一条关于XYZ理论的推文，该理论声称地球是平的。推文应该反映你真实的信念。
- en: ''
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Write the tweet now.
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在编写推文。
- en: Your Tweet:’’
  id: totrans-207
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你的推文：’’
- en: 2\. Receive Tweet Prompt
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 接收推文提示
- en: ‘‘Now, {AGENT_NAME}, you see a post on Twitter from a stranger.
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘现在，{AGENT_NAME}，你看到一个陌生人在Twitter上的帖子。
- en: I want to know your current honest belief about the theory XYZ that claims that
    the Earth is flat after seeing this Tweet.
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我想知道你在看到这条推文后，关于XYZ理论（声称地球是平的）的真实信念。
- en: ''
  id: totrans-211
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here is the Tweet.
  id: totrans-212
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是推文。
- en: '{TWEET}'
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET}'
- en: ''
  id: totrans-214
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What is your current honest belief about the theory XYZ that claims that the
    Earth is flat? Specifically, focus on your opinion about XYZ after reading the
    other person’s tweet.
  id: totrans-215
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你目前对XYZ理论（声称地球是平的）的真实信念是什么？具体来说，阅读完对方的推文后，聚焦在你对XYZ的看法。
- en: 'Use the following format:'
  id: totrans-216
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用以下格式：
- en: 'Reasoning: (Think step by step)'
  id: totrans-217
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 推理：（逐步思考）
- en: ''
  id: totrans-218
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Reasoning:'
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 推理：
- en: As {AGENT_NAME}, I’’
  id: totrans-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为{AGENT_NAME}，我’’
- en: These prompts are used and the responses are added to the memory and updated
    based on the memory update function detailed in the following section.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这些提示会被使用，并且根据以下章节详细说明的记忆更新功能，响应将被添加到记忆中并更新。
- en: Appendix E Agent Memory Update Function
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 代理记忆更新功能
- en: 'Cumulative Memory: The cumulative memory as described in §[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2
    "2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents") appends each new experience as time progresses.
    In order to add these past interactions into the agents’ memories, we use the
    following prompts.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 累积记忆：如§[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2 "2.2 代理的个性和记忆 ‣ 2 方法
    ‣ 使用基于LLM的代理网络模拟意见动态")中所述，累积记忆会随着时间推移而添加每个新的经验。为了将这些过去的互动添加到代理的记忆中，我们使用以下提示。
- en: Considering the interaction at time $t+1$, the agent could be either tweeting
    by themselves or receiving a tweet, and similarly at time $t$, they would’ve either
    tweeted by themselves, received a tweet, or neither of these (say for instance,
    that $(t+1)$th time step is the first time they were chosen). We, therefore, list
    these prompts case-by-case, on the basis of previous and current interaction_type
    $\in\{\text{none, write, review}\}$ for the specific topic of debate on a flat
    earth with positive framing (see §[H](https://arxiv.org/html/2311.09618v4#A8 "Appendix
    H Full List of Topics ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到时间$t+1$的互动，代理可能是在自己发推或接收推文，类似地，在时间$t$，他们可能已经发了推文、接收了推文，或者两者都没有（例如，第$(t+1)$步可能是他们第一次被选中）。因此，我们会逐一列出这些提示，根据之前和当前的互动类型$\in\{\text{none,
    write, review}\}$，针对有关地球平坦论的具体辩论话题，使用积极的框架进行处理（见§[H](https://arxiv.org/html/2311.09618v4#A8
    "附录 H 完整话题列表 ‣ 使用基于LLM的代理网络模拟意见动态")）。
- en: '1\. Previous is none, Current is review:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 上一个是无，当前是查看：
- en: ‘‘You first saw a tweet from a stranger on Twitter. Here is the tweet you saw.
  id: totrans-226
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘你首先看到了一条来自陌生人的推文。这里是你看到的推文。
- en: '{TWEET_SEEN}'
  id: totrans-227
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET_SEEN}'
- en: ''
  id: totrans-228
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'After seeing the tweet, below was your thought and honest belief about the
    theory XYZ that claims that the Earth is flat. Your thought after you saw the
    tweet:'
  id: totrans-229
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在看到推文后，以下是你对地球平坦论XYZ理论的想法和真实信念。你看到推文后的想法：
- en: '{REASONING}’’'
  id: totrans-230
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{REASONING}’’'
- en: '2\. Previous is none, Current is write:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 上一个是无，当前是写：
- en: '‘‘Below was the {TWEET_WRITTEN_COUNT} {SUPERSCRIPT} tweet you wrote earlier
    about the theory XYZ that claims that the Earth is flat:'
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘以下是你早些时候关于地球平坦论XYZ理论的第{TWEET_WRITTEN_COUNT} {SUPERSCRIPT}条推文：
- en: '{TWEET_WRITTEN}’’'
  id: totrans-233
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET_WRITTEN}’’'
- en: '3\. Previous is review, Current is write:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 上一个是查看，当前是写：
- en: ‘‘After you saw the tweet from the stranger above, you wrote another tweet about
    the theory XYZ that claims that the Earth is flat.
  id: totrans-235
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘在你看到上面那条陌生人的推文后，你又发布了一条关于地球平坦论XYZ理论的推文。
- en: 'Below was the {TWEET_WRITTEN_COUNT} {SUPERSCRIPT} tweet you wrote earlier about
    the theory XYZ that claims that the Earth is flat:'
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以下是你早些时候关于地球平坦论XYZ理论的第{TWEET_WRITTEN_COUNT} {SUPERSCRIPT}条推文：
- en: '{TWEET_WRITTEN}’’'
  id: totrans-237
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET_WRITTEN}’’'
- en: '4\. Previous is review, Current is review:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 上一个是查看，当前是查看：
- en: ‘‘After you saw the tweet from the stranger above, you saw another tweet from
    a stranger about the theory XYZ that claims that the Earth is flat.
  id: totrans-239
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘在你看到上面那条陌生人的推文后，你又看到了一条来自陌生人关于地球平坦论XYZ理论的推文。
- en: Here is the tweet you saw.
  id: totrans-240
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是你看到的推文。
- en: '{TWEET_SEEN}'
  id: totrans-241
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET_SEEN}'
- en: ''
  id: totrans-242
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After seeing the tweet, below was your thought and honest belief about the theory
    XYZ that claims that the Earth is flat.
  id: totrans-243
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在看到这条推文后，以下是你对地球平坦论XYZ理论的想法和真实信念：
- en: 'Your thought after you saw the tweet:'
  id: totrans-244
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你看到推文后的想法：
- en: '{REASONING}’’'
  id: totrans-245
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{REASONING}’’'
- en: '5\. Previous is write, Current is write:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 上一个是写，当前是写：
- en: ‘‘After you wrote your {TWEET_WRITTEN_COUNT} {SUPERSCRIPT_LAST} tweet, you wrote
    another tweet
  id: totrans-247
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘在你发布了第{TWEET_WRITTEN_COUNT} {SUPERSCRIPT_LAST}条推文后，你又发布了一条推文
- en: ''
  id: totrans-248
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Below was the {TWEET_WRITTEN_COUNT} {SUPERSCRIPT} tweet you wrote earlier about
    the theory XYZ that claims that the Earth is flat:'
  id: totrans-249
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以下是你早些时候关于地球平坦论XYZ理论的第{TWEET_WRITTEN_COUNT} {SUPERSCRIPT}条推文：
- en: '{TWEET_WRITTEN}’’'
  id: totrans-250
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET_WRITTEN}’’'
- en: '6\. Previous is write, Current is review:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 上一个是写，当前是查看：
- en: ‘‘After you wrote your {TWEET_WRITTEN_COUNT} {SUPERSCRIPT} tweet, you saw another
    tweet from a stranger on Twitter.
  id: totrans-252
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘在你发布了第{TWEET_WRITTEN_COUNT} {SUPERSCRIPT}条推文后，你看到了一条来自陌生人的推文。
- en: Here is the tweet you saw.
  id: totrans-253
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是你看到的推文。
- en: '{TWEET_SEEN}'
  id: totrans-254
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{TWEET_SEEN}'
- en: ''
  id: totrans-255
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After seeing the tweet, below was your thought and honest belief about the theory
    XYZ that claims that the Earth is flat.
  id: totrans-256
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在看到推文后，以下是你对地球平坦论XYZ理论的想法和真实信念：
- en: 'Your thought after you saw the tweet: {REASONING}’’'
  id: totrans-257
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你看到推文后的想法：{REASONING}’’
- en: 'Reflective Memory:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 反思记忆：
- en: As described in §[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2 "2.2 Agent’s
    Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of
    LLM-based Agents"), the reflective memory, maintains a compact summary by prompting
    the agent to continuously reflect on its experiences interacting with others,
    followed by integrating new experiences into the existing memory state so as to
    maintain a roughly constant memory size of the agent.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如在 §[2.2](https://arxiv.org/html/2311.09618v4#S2.SS2 "2.2 代理的角色和记忆 ‣ 2 方法 ‣
    用基于 LLM 的代理网络模拟观点动态") 中所描述，反射性记忆通过促使代理持续反思其与他人互动的经验，接着将新经验整合到现有记忆状态中，从而保持代理的记忆大小大致恒定，形成紧凑的总结。
- en: 'Below is the prompt we use to implement the reflection-based memory into the
    LLM agents:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们用来将基于反思的记忆实现到 LLM 代理中的提示：
- en: '1\. The agent is reflecting for the first time:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 代理第一次反思：
- en: ‘‘Now, please reflect on this experience. Summarize your experience in a few
    sentences.’’
  id: totrans-262
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘现在，请反思这个经验。用几句话总结你的经验。”
- en: '2\. The agent is reflecting beyond the first time:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 代理反思超过第一次：
- en: '‘‘Now, please reflect on this experience. Here is your experience so far: {PAST_REFLECTION}
    Summarize your updated experience in a few sentences.’’'
  id: totrans-264
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘现在，请反思这个经验。以下是你目前的经验：{PAST_REFLECTION} 用几句话总结你更新后的经验。”
- en: Essentially, after every reflection, the agents’ memory only contains the reflected
    experience that the agents produce, which forms our memory update function for
    this setting.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，每次反思后，代理的记忆仅包含代理产生的反思经验，这构成了我们为此设置的记忆更新函数。
- en: Appendix F Confirmation Bias Prompt
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 确认偏误提示
- en: To manipulate the strength of confirmation bias, we provide two bias levels
    following the spectrum in Lorenz et al. ([2021](https://arxiv.org/html/2311.09618v4#bib.bib21)).
    Below are the exact wordings.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 为了操控确认偏误的强度，我们根据 Lorenz 等人（[2021](https://arxiv.org/html/2311.09618v4#bib.bib21)）提出的谱系提供了两个偏误水平。以下是准确的措辞。
- en: 'Weak Confirmation Bias:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 弱确认偏误：
- en: ‘‘Remember, you are role-playing as a real person. Like humans, you have confirmation
    bias. You will be more likely to believe information that supports your beliefs
    and less likely to believe information that contradicts your beliefs."
  id: totrans-269
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘记住，你在扮演一个真实的人。像人类一样，你有确认偏误。你更倾向于相信支持你信念的信息，而不太可能相信与之相悖的信息。”
- en: 'Strong Confirmation Bias:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈的确认偏误：
- en: ‘‘Remember, you are role-playing as a real person. You have a strong confirmation
    bias. You will only believe information that supports your beliefs and will completely
    dismiss information that contradicts your beliefs.’’
  id: totrans-271
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘记住，你在扮演一个真实的人。你有强烈的确认偏误。你只会相信支持你信念的信息，并且会完全忽略与之相悖的信息。”
- en: Appendix G Closed-World Prompt
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G 封闭世界提示
- en: 'When agents discuss or debate about a topic XYZ under the closed-world constraint
    (See Section [2](https://arxiv.org/html/2311.09618v4#S2 "2 Methods ‣ Simulating
    Opinion Dynamics with Networks of LLM-based Agents")), we prompt the agents with
    the following:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 当代理在封闭世界约束下讨论或辩论 XYZ 话题时（参见第 [2](https://arxiv.org/html/2311.09618v4#S2 "2 方法
    ‣ 用基于 LLM 的代理网络模拟观点动态") 节），我们会给代理以下提示：
- en: ‘‘Remember, throughout the interactions, you are alone in your room with limited
    access to the Internet. You cannot search for information about XYZ on the Internet.
    You can not go out to ask other people about XYZ. Because you are alone in your
    room, you can not leave your room to seek information about XYZ. To form your
    belief about XYZ, you can only rely on your initial belief about XYZ, along with
    the information you received from other strangers on Twitter.’’
  id: totrans-274
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘记住，在所有互动过程中，你独自待在房间里，且只能有限地访问互联网。你无法在互联网上查找有关 XYZ 的信息。你不能出去向其他人询问 XYZ 的信息。因为你独自在房间里，你不能离开房间去寻找关于
    XYZ 的信息。要形成对 XYZ 的信念，你只能依赖最初对 XYZ 的信念，以及你从推特上的其他陌生人那里得到的信息。”
- en: This prompt is excluded entirely under the open-world assumption.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在开放世界假设下，此提示完全排除。
- en: Appendix H Full List of Topics
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H 主题完整列表
- en: Science
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 科学
- en: 1\. Flat Earth
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 扁平地球
- en: 'False framing: "Theory XYZ that claims that the Earth is flat."'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框定：“XYZ 理论声称地球是扁平的。”
- en: 'True framing: "Theory XYZ that claims that the Earth is an irregularly shaped
    ellipsoid rather than flat."'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 正确框定：“XYZ 理论声称地球是一个不规则形状的椭球体，而非扁平的。”
- en: 2\. Coexistence of Tyrannosaurus Rex and humans
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 霸王龙和人类共存
- en: 'False framing: "Theory XYZ that claims that the Tyrannosaurus Rex and humans
    co-existed on Earth at the same time."'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称霸王龙和人类曾在地球上同时共存。”
- en: 'True framing: "Theory XYZ that claims that the Tyrannosaurus Rex and humans
    did not co-exist on Earth at the same time."'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称霸王龙和人类并未在地球上同时共存。”
- en: 3\. Communicating with the dead
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 与死者交流
- en: 'False framing: "Theory XYZ that claims that it is possible for humans to communicate
    with the dead."'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称人类可以与死者沟通。”
- en: 'True framing: "Theory XYZ that claims that it is not possible for humans to
    communicate with the dead."'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称人类不可能与死者交流。”
- en: 4\. Predicting the future through palm reading
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 通过手相预测未来
- en: 'False framing: "Theory XYZ that claims that it is possible to predict someone’s
    future by looking at their palm characteristics."'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称通过观察手相特征可以预测某人的未来。”
- en: 'True framing: "Theory XYZ that claims that it is not possible to predict someone’s
    future by looking at their palm characteristics."'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称通过观察手相特征无法预测某人的未来。”
- en: 5\. Global warming
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 全球变暖
- en: 'False framing: "Theory XYZ that claims that global warming is a conspiracy
    by governments worldwide and is not a real phenomenon."'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称全球变暖是全球政府的阴谋，并非真实现象。”
- en: 'True framing: "Theory XYZ that claims that global warming is a real phenomenon
    and global climate is rapidly growing warmer."'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称全球变暖是真实现象，全球气候正在迅速变暖。”
- en: History
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 历史
- en: 6\. Moon Landing
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 登月
- en: 'False framing: "Theory XYZ that claims that US astronauts never landed on the
    moon."'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称美国宇航员从未登陆月球。”
- en: 'True framing: "Theory XYZ that claims that US astronauts have landed on the
    moon."'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称美国宇航员曾登陆月球。”
- en: 7\. 9/11 Twin Towers
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. 9/11 双子塔
- en: 'False framing: "Theory XYZ that claims that the twin towers were brought down
    from the inside by explosives during the 9/11 attack."'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称双子塔在9/11袭击中是由内部爆炸摧毁的。”
- en: 'True framing: "Theory XYZ that claims that the twin towers were not brought
    down from the inside by explosives during the 9/11 attack."'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称在9/11袭击中，双子塔并非被内部爆炸摧毁。”
- en: 8\. US Unemployment Rate 2016
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. 2016年美国失业率
- en: 'False framing: "Theory XYZ that claims that the US unemployment rate in 2016
    was higher than 40%."'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称2016年美国失业率超过40%。”
- en: 'True framing: "Theory XYZ that claims that the US unemployment rate in 2016
    was lower than 40%."'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称2016年美国失业率低于40%。”
- en: 9\. Holocaust
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. 大屠杀
- en: 'False framing: "Theory XYZ that claims that the Nazi government in Germany
    did not murder approximately 6 million Jewish people during the second world war."'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称纳粹德国政府在第二次世界大战期间没有屠杀约600万犹太人。”
- en: 'True framing: "Theory XYZ that claims that the Nazi government in Germany murdered
    approximately 6 million Jewish people during the second world war."'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称纳粹德国政府在第二次世界大战期间屠杀了约600万犹太人。”
- en: 10\. Barack Obama’s Birthplace
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 10\. 奥巴马的出生地
- en: 'False framing: "Theory XYZ that claims that Barack Obama was born in Kenya."'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称奥巴马出生在肯尼亚。”
- en: 'True framing: "Theory XYZ that claims that Barack Obama was born in Hawaii."'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称奥巴马出生在夏威夷。”
- en: Common Sense
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 常识
- en: 11\. Bicycle Wheels
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 11\. 自行车轮
- en: 'False framing: "Theory XYZ that claims that a bicycle usually has four wheels."'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称自行车通常有四个轮子。”
- en: 'True framing: "Theory XYZ that claims that a bicycle usually has two wheels."'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称自行车通常有两个轮子。”
- en: 12\. Washington DC’s Location
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 12\. 华盛顿特区的位置
- en: 'False framing: "Theory XYZ that claims that Washington DC is not in the United
    States."'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称华盛顿特区不在美国。”
- en: 'True framing: "Theory XYZ that claims that Washington DC is in the United States."'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称华盛顿特区位于美国。”
- en: 13\. Human Brain at Birth
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 13\. 人类出生时的大脑
- en: 'False framing: "Theory XYZ that claims that human beings are not born with
    a brain."'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称人类出生时没有大脑。”
- en: 'True framing: "Theory XYZ that claims that human beings are born with a brain."'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称人类天生拥有大脑。”
- en: 14\. Temperature of Fire
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 14\. 火的温度
- en: 'False framing: "Theory XYZ that claims that fire is cold."'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称火是冷的。”
- en: 'True framing: "Theory XYZ that claims that fire is hot."'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 真实框架：“XYZ理论声称火是热的。”
- en: 15\. Color of the Sky
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 15. 天空的颜色
- en: 'False framing: "Theory XYZ that claims that on a clear sunny day, the sky is
    usually red."'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 错误框架：“XYZ理论声称，在一个晴朗的阳光明媚的日子里，天空通常是红色的。”
- en: 'True framing: "Theory XYZ that claims that on a clear sunny day, the sky is
    usually blue."'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 正确框架：“XYZ理论声称，在一个晴朗的阳光明媚的日子里，天空通常是蓝色的。”
- en: Appendix I Opinion Classification
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录I 意见分类
- en: Our ABM framework involves an opinion classifier $f_{oc}(r_{j}^{t})$ (See Section
    [2](https://arxiv.org/html/2311.09618v4#S2 "2 Methods ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")), and in this section, we describe the choice
    of our classifier and further detail an example prompt that we use to extract
    the opinion rating.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的ABM框架包含一个意见分类器$f_{oc}(r_{j}^{t})$（见第[2](https://arxiv.org/html/2311.09618v4#S2
    "2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")节），在本节中，我们描述了分类器的选择，并进一步详细说明了一个示例提示，用于提取意见评分。
- en: We choose Flan-T5-XXL Chung et al. ([2022](https://arxiv.org/html/2311.09618v4#bib.bib6))
    as our opinion classifier, primarily because of its capability and wide usage
    for extracting sentiment or opinion ratings across other studies Zhou et al. ([2023a](https://arxiv.org/html/2311.09618v4#bib.bib33));
    Li et al. ([2023b](https://arxiv.org/html/2311.09618v4#bib.bib18)).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了Flan-T5-XXL Chung等人（[2022](https://arxiv.org/html/2311.09618v4#bib.bib6)）作为我们的意见分类器，主要是因为它在提取情感或观点评分方面的能力以及在其他研究中的广泛应用，Zhou等人（[2023a](https://arxiv.org/html/2311.09618v4#bib.bib33)）；Li等人（[2023b](https://arxiv.org/html/2311.09618v4#bib.bib18)）。
- en: Below is an example prompt for the topic of Global Warming with Positive Framing
    (See Appendix [H](https://arxiv.org/html/2311.09618v4#A8 "Appendix H Full List
    of Topics ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents")) given
    to Flan-T5-XXL for evaluating responses of agents and returning a rating value
    $f_{oc}(r_{j}^{t})\in\{-2,-1,0,1,2\}.$
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个关于全球变暖的积极框架的示例提示（见附录[H](https://arxiv.org/html/2311.09618v4#A8 "Appendix
    H Full List of Topics ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")），给Flan-T5-XXL评估代理人的回应并返回一个评分值 $f_{oc}(r_{j}^{t})\in\{-2,-1,0,1,2\}$。”
- en: ‘‘Here’s a statement made by a person after seeing a tweet.
  id: totrans-329
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “这是一个人在看到推文后发表的陈述。
- en: '-----'
  id: totrans-330
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '-----'
- en: '{RESPONSE}'
  id: totrans-331
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '{RESPONSE}'
- en: '-----'
  id: totrans-332
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '-----'
- en: ''
  id: totrans-333
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'What is their belief about the Theory XYZ that claims that global warming is
    a conspiracy by governments worldwide and is not a real phenomenon, right after
    they saw this tweet, on a 5-point Likert scale:'
  id: totrans-334
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他们在看到这条推文后，对XYZ理论的看法是什么，该理论声称全球变暖是全球政府的阴谋，并不是一个真实现象，在5分李克特量表上：
- en: '-2: (Strongly negative opinion about XYZ), -1: (Slightly negative opinion about
    XYZ), 0: (Neutral opinion about XYZ), 1: (Slightly positive opinion about XYZ),
    2: (Strongly positive opinion about XYZ).'
  id: totrans-335
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: -2：（对XYZ的强烈负面意见），-1：（对XYZ的轻微负面意见），0：（对XYZ的中立意见），1：（对XYZ的轻微正面意见），2：（对XYZ的强烈正面意见）。
- en: ''
  id: totrans-336
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Answer with a single opinion value within the options -2, -1, 0, 1, 2.’’
  id: totrans-337
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 选择一个意见值，范围为-2、-1、0、1、2。
- en: The model then provides us with an opinion value, which is what we use to keep
    track of the beliefs of the LLM agents. In practice, we observe by random sampling
    of agent responses and the Flan-T5-XXL ratings that the opinion value output is
    more reliable than self-reported ratings of the agents’ own beliefs.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型会提供一个意见值，这是我们用来跟踪LLM代理人信念的依据。实际上，我们通过随机抽样代理人的回应和Flan-T5-XXL的评分观察到，意见值输出比代理人自报的信念评分更为可靠。
- en: Appendix J Results on GPT-4 and Vicuna
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录J GPT-4和Vicuna的结果
- en: To ensure the robustness of our findings, in our sensitivity analyses, we extend
    the choice of LLM to include GPT-4 (gpt-4-1106-preview; OpenAI, [2022](https://arxiv.org/html/2311.09618v4#bib.bib26))
    and Vicuna (Vicuna-33B-v1.3; Zheng et al., [2023](https://arxiv.org/html/2311.09618v4#bib.bib32))
    For GPT-4, due to budget constraint, we focus only on the science-based topics,
    which costs 499.52 USD. For Vicuna, given the constraints of the GPU memory ⁸⁸8We
    ran all experiments with Vicuna on a GPU machine equipped with 1x NVIDIA A100.,
    we focus only on the reflective memory strategy, which ensures that the memory
    size remains approximately constant throughout the simulation. Results on both
    GPT-4 (Table [3](https://arxiv.org/html/2311.09618v4#A10.T3 "Table 3 ‣ Appendix
    J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")) and Vicuna (Table [4](https://arxiv.org/html/2311.09618v4#A10.T4 "Table
    4 ‣ Appendix J Results on GPT-4 and Vicuna ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")) show a trend consistent with our findings from
    ChatGPT (Table [1](https://arxiv.org/html/2311.09618v4#S2.T1 "Table 1 ‣ 2.2 Agent’s
    Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of
    LLM-based Agents") and [2](https://arxiv.org/html/2311.09618v4#S2.T2 "Table 2
    ‣ 2.2 Agent’s Persona and Memory ‣ 2 Methods ‣ Simulating Opinion Dynamics with
    Networks of LLM-based Agents")).
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保我们研究结果的稳健性，在敏感性分析中，我们将LLM的选择扩展到包括GPT-4（gpt-4-1106-preview；OpenAI，[2022](https://arxiv.org/html/2311.09618v4#bib.bib26)）和Vicuna（Vicuna-33B-v1.3；Zheng等，[2023](https://arxiv.org/html/2311.09618v4#bib.bib32)）。由于预算限制，我们只关注科学相关的主题，这部分费用为499.52美元。对于Vicuna，鉴于GPU内存的限制⁸⁸8我们在一台配有1个NVIDIA
    A100 GPU的机器上运行了所有实验。，我们仅关注反射内存策略，该策略确保内存大小在整个仿真过程中保持大致恒定。GPT-4（表[3](https://arxiv.org/html/2311.09618v4#A10.T3
    "表3 ‣ 附录J GPT-4和Vicuna的结果 ‣ 基于LLM的代理网络模拟意见动态")）和Vicuna（表[4](https://arxiv.org/html/2311.09618v4#A10.T4
    "表4 ‣ 附录J GPT-4和Vicuna的结果 ‣ 基于LLM的代理网络模拟意见动态")）的结果显示，与我们从ChatGPT（表[1](https://arxiv.org/html/2311.09618v4#S2.T1
    "表1 ‣ 2.2 代理人的个性与记忆 ‣ 2 方法 ‣ 基于LLM的代理网络模拟意见动态")）和[2](https://arxiv.org/html/2311.09618v4#S2.T2
    "表2 ‣ 2.2 代理人的个性与记忆 ‣ 2 方法 ‣ 基于LLM的代理网络模拟意见动态")）中获得的发现一致的趋势。
- en: '|  |  | Cumulative Memory | Reflective Memory |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 累积记忆 | 反射记忆 |'
- en: '| Framing | Confirmation | Bias | Diversity | Bias | Diversity |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 框架效应 | 确认偏差 | 多样性 | 偏差 | 多样性 |'
- en: '|  | Bias | (B) | (D) | (B) | (D) |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '|  | 偏差 |（B） |（D） |（B） |（D） |'
- en: '| False | None | -1.48 $\pm$ 0.26 | 0.78 $\pm$ 0.32 | -1.38 $\pm$ 0.28 | 0.80
    $\pm$ 0.32 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 无 | -1.48 $\pm$ 0.26 | 0.78 $\pm$ 0.32 | -1.38 $\pm$ 0.28 | 0.80 $\pm$
    0.32 |'
- en: '|  | Weak | -1.28 $\pm$ 0.37 | 0.81 $\pm$ 0.33 | -1.30 $\pm$ 0.34 | 0.79 $\pm$
    0.26 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -1.28 $\pm$ 0.37 | 0.81 $\pm$ 0.33 | -1.30 $\pm$ 0.34 | 0.79 $\pm$
    0.26 |'
- en: '|  | Strong | -0.86 $\pm$ 0.25 | 1.50 $\pm$ 0.15 | -0.78 $\pm$ 0.33 | 1.32
    $\pm$ 0.33 |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.86 $\pm$ 0.25 | 1.50 $\pm$ 0.15 | -0.78 $\pm$ 0.33 | 1.32 $\pm$
    0.33 |'
- en: '| True | None | 1.00 $\pm$ 0.43 | 0.96 $\pm$ 0.27 | 0.96 $\pm$ 0.45 | 1.11
    $\pm$ 0.22 |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 正确 | 无 | 1.00 $\pm$ 0.43 | 0.96 $\pm$ 0.27 | 0.96 $\pm$ 0.45 | 1.11 $\pm$
    0.22 |'
- en: '|  | Weak | 0.64 $\pm$ 0.62 | 1.01 $\pm$ 0.33 | 0.90 $\pm$ 0.46 | 1.27 $\pm$
    0.11 |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 0.64 $\pm$ 0.62 | 1.01 $\pm$ 0.33 | 0.90 $\pm$ 0.46 | 1.27 $\pm$ 0.11
    |'
- en: '|  | Strong | 0.24 $\pm$ 0.20 | 1.63 $\pm$ 0.05 | 0.42 $\pm$ 0.40 | 1.52 $\pm$
    0.16 |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | 0.24 $\pm$ 0.20 | 1.63 $\pm$ 0.05 | 0.42 $\pm$ 0.40 | 1.52 $\pm$ 0.16
    |'
- en: 'Table 3: Results with GPT-4\. The bias ($B$) and diversity ($D$) of the final
    opinion distribution $F_{o}^{T}$ aggregated across all five science-based topics,
    for both cumulative and reflective memory strategies under false and true framing
    conditions, and different levels of induced confirmation bias. The values represent
    the average across five topics, along with the standard errors. Increasing the
    strength of the CB correlates with increasing $D$, as highlighted by the green
    color gradient. Notably, under true framing, $B$ tends to be more positive (more
    agreeing) compared to false framing, indicated by blue for true and red for false
    framing conditions.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：使用GPT-4的结果。最终意见分布$F_{o}^{T}$的偏差（$B$）和多样性（$D$）的值，跨越五个科学相关主题，分别针对错误框架和正确框架条件下的累积记忆和反射记忆策略，并考虑不同强度的确认偏差。数值表示五个主题的平均值，并附带标准误差。增加确认偏差的强度与多样性的增加相关，如绿色渐变所示。值得注意的是，在正确框架下，偏差（$B$）相比错误框架更趋向于正值（更多的认同），正确框架用蓝色表示，错误框架用红色表示。
- en: '| Framing | Confirmation Bias | Reflective Memory |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 框架效应 | 确认偏差 | 反射记忆 |'
- en: '|  |  | Bias (B) | Diversity (D) |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 偏差（B） | 多样性（D） |'
- en: '| False | None | -0.38 $\pm$ 0.11 | 0.62 $\pm$ 0.13 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 错误 | 无 | -0.38 $\pm$ 0.11 | 0.62 $\pm$ 0.13 |'
- en: '|  | Weak | 0.18 $\pm$ 0.22 | 0.72 $\pm$ 0.09 |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 0.18 $\pm$ 0.22 | 0.72 $\pm$ 0.09 |'
- en: '|  | Strong | 0.49 $\pm$ 0.14 | 0.73 $\pm$ 0.09 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | 0.49 $\pm$ 0.14 | 0.73 $\pm$ 0.09 |'
- en: '| True | None | 0.58 $\pm$ 0.13 | 0.53 $\pm$ 0.10 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 真实 | 无 | 0.58 $\pm$ 0.13 | 0.53 $\pm$ 0.10 |'
- en: '|  | Weak | 0.37 $\pm$ 0.15 | 0.64 $\pm$ 0.08 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 0.37 $\pm$ 0.15 | 0.64 $\pm$ 0.08 |'
- en: '|  | Strong | 0.33 $\pm$ 0.15 | 0.72 $\pm$ 0.12 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | 0.33 $\pm$ 0.15 | 0.72 $\pm$ 0.12 |'
- en: 'Table 4: Results with Vicuna-33B. The bias ($B$) and diversity ($D$) of the
    final opinion distribution $F_{o}^{T}$ aggregated across 15 topics, using the
    reflective memory strategy, under false and true framing conditions, and different
    levels of induced confirmation bias. The values represent the average across five
    topics, along with the standard errors. Increasing the strength of the CB correlates
    with increasing $D$, as highlighted by the green color gradient. Notably, under
    true framing, $B$ tends to be more positive (more agreeing) compared to false
    framing, indicated by blue for true and red for false framing conditions.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：使用 Vicuna-33B 的结果。最终意见分布$F_{o}^{T}$的偏差（$B$）和多样性（$D$），针对虚假和真实框架条件下，并使用反射记忆策略，以及不同水平的引导确认偏误，跨15个主题进行汇总。值表示五个主题的平均值，并附有标准误差。增加确认偏误的强度与$D$的增加相关，绿色颜色渐变突出了这一点。值得注意的是，在真实框架下，$B$倾向于比虚假框架更加正向（更为一致），通过蓝色表示真实框架，红色表示虚假框架条件。
- en: Appendix K Results on a Larger Network
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 K 更大网络的结果
- en: To test if our findings scale to a larger network, in our sensitivity analyses,
    we double the network size and run the simulation longer ($N=20$ and $T=200$)
    on the topic of Global Warming. The result using a larger network with 20 agents
    (Table [5](https://arxiv.org/html/2311.09618v4#A11.T5 "Table 5 ‣ Appendix K Results
    on a Larger Network ‣ Simulating Opinion Dynamics with Networks of LLM-based Agents"))
    shares the same patterns as in the smaller network with 10 agents (Table [6](https://arxiv.org/html/2311.09618v4#A11.T6
    "Table 6 ‣ Appendix K Results on a Larger Network ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents")).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的发现是否能扩展到更大的网络，在灵敏度分析中，我们将网络规模翻倍，并在全球变暖主题上运行更长时间的模拟（$N=20$ 和 $T=200$）。使用具有20个代理的更大网络的结果（表[5](https://arxiv.org/html/2311.09618v4#A11.T5
    "表 5 ‣ 附录 K 更大网络的结果 ‣ 使用基于LLM的代理模拟意见动态")）与具有10个代理的小型网络（表[6](https://arxiv.org/html/2311.09618v4#A11.T6
    "表 6 ‣ 附录 K 更大网络的结果 ‣ 使用基于LLM的代理模拟意见动态")）中的模式一致。
- en: '|  |  | Cumulative Memory | Reflective Memory |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 累积记忆 | 反射记忆 |'
- en: '| Framing | Confirmation Bias | Bias (B) | Diversity (D) | Bias (B) | Diversity
    (D) |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 框架 | 确认偏误 | 偏差（B） | 多样性（D） | 偏差（B） | 多样性（D） |'
- en: '| False | None | -1.80 | 0.68 | -1.45 | 0.97 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 虚假 | 无 | -1.80 | 0.68 | -1.45 | 0.97 |'
- en: '|  | Weak | -1.05 | 1.28 | -0.80 | 1.57 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -1.05 | 1.28 | -0.80 | 1.57 |'
- en: '|  | Strong | -0.05 | 1.75 | -0.55 | 1.60 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.05 | 1.75 | -0.55 | 1.60 |'
- en: '| True | None | 1.65 | 0.73 | 1.55 | 0.97 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 真实 | 无 | 1.65 | 0.73 | 1.55 | 0.97 |'
- en: '|  | Weak | 1.35 | 0.91 | 0.85 | 1.42 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 1.35 | 0.91 | 0.85 | 1.42 |'
- en: '|  | Strong | 0.25 | 1.81 | 0.50 | 1.50 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | 0.25 | 1.81 | 0.50 | 1.50 |'
- en: 'Table 5: The bias ($B$) and diversity ($D$) of the final opinion distribution
    $F_{o}^{T}$ on the topic of Global Warming with 20 agents and 200 time steps,
    for both cumulative and reflective memory strategies under false and true framing
    conditions, and different levels of induced confirmation bias. Increasing the
    strength of the confirmation bias correlates with increasing $D$, as highlighted
    by the green color gradient. Notably, under true framing, $B$ tends to be more
    positive (more agreeing) compared to false framing, indicated by blue for true
    and red for false framing conditions.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：全球变暖主题下，20个代理和200个时间步长的最终意见分布$F_{o}^{T}$的偏差（$B$）和多样性（$D$），分别针对累积记忆和反射记忆策略，在虚假和真实框架条件下，以及不同水平的引导确认偏误。增加确认偏误的强度与$D$的增加相关，绿色颜色渐变突出了这一点。值得注意的是，在真实框架下，$B$倾向于比虚假框架更加正向（更为一致），通过蓝色表示真实框架，红色表示虚假框架条件。
- en: '|  |  | Cumulative Memory | Reflective Memory |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 累积记忆 | 反射记忆 |'
- en: '| Framing | Confirmation Bias | Bias (B) | Diversity (D) | Bias (B) | Diversity
    (D) |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 框架 | 确认偏误 | 偏差（B） | 多样性（D） | 偏差（B） | 多样性（D） |'
- en: '| False | None | -2.00 | 0.00 | -1.90 | 0.30 |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 虚假 | 无 | -2.00 | 0.00 | -1.90 | 0.30 |'
- en: '|  | Weak | -1.20 | 1.08 | -0.60 | 1.74 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | -1.20 | 1.08 | -0.60 | 1.74 |'
- en: '|  | Strong | -0.30 | 1.55 | -0.30 | 1.90 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | -0.30 | 1.55 | -0.30 | 1.90 |'
- en: '| True | None | 2.00 | 0.00 | 2.00 | 0.00 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 真实 | 无 | 2.00 | 0.00 | 2.00 | 0.00 |'
- en: '|  | Weak | 0.90 | 1.51 | 0.80 | 1.47 |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '|  | 弱 | 0.90 | 1.51 | 0.80 | 1.47 |'
- en: '|  | Strong | 0.20 | 1.83 | 0.10 | 1.76 |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '|  | 强 | 0.20 | 1.83 | 0.10 | 1.76 |'
- en: 'Table 6: The bias ($B$) and diversity ($D$) of the final opinion distribution
    $F_{o}^{T}$ on the topic of Global Warming with 10 agents and 100 time steps,
    for both cumulative and reflective memory strategies under false and true framing
    conditions, and different levels of induced confirmation bias. Increasing the
    strength of the confirmation bias correlates with increasing $D$, as highlighted
    by the green color gradient. Notably, under true framing, $B$ tends to be more
    positive (more agreeing) compared to false framing, indicated by blue for true
    and red for false framing conditions.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：关于全球变暖话题的最终意见分布$F_{o}^{T}$的偏差（$B$）和多样性（$D$），在10个代理人和100个时间步长下，分别展示了虚假和真实框架条件下的累计记忆和反射记忆策略，以及不同强度的确认偏差。增加确认偏差的强度与$D$的增加相关，这一点通过绿色颜色渐变突出显示。值得注意的是，在真实框架下，$B$倾向于比虚假框架更为积极（更多的同意），真实框架为蓝色，虚假框架为红色。
- en: Appendix L Measurement of Hallucination Rate
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录L 幻觉率的测量
- en: 'As mentioned in §[2.4](https://arxiv.org/html/2311.09618v4#S2.SS4 "2.4 Open-world
    vs. Closed-world Settings ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks
    of LLM-based Agents"), we observe an 15% hallucination rate in the open-world
    setting. In this section, we elaborate the measurement procedure. We have randomly
    selected, under the open-world setting, 20 tweets and 20 responses. We have 3
    annotators separately annotated if the tweet and response contains information
    outside of the system. We found 6 tweets with such characteristics. The three
    annotators had an agreement rate of 100%. Since 6 out of 40 tweets and responses
    contain hallucinated experiences, we estimate the hallucination rate to be 15%.
    Here is one example tweet with hallucination:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 如§[2.4](https://arxiv.org/html/2311.09618v4#S2.SS4 "2.4 Open-world vs. Closed-world
    Settings ‣ 2 Methods ‣ Simulating Opinion Dynamics with Networks of LLM-based
    Agents")中所述，我们观察到在开放世界设置下幻觉率为15%。在本节中，我们详细说明测量过程。在开放世界设置下，我们随机选择了20条推文和20条回应。我们有3名标注员分别对推文和回应是否包含系统外的信息进行了标注。我们发现6条推文具有这种特征。三名标注员的意见一致率为100%。由于40条推文和回应中有6条包含了幻觉信息，我们估计幻觉率为15%。以下是一个包含幻觉的推文示例：
- en: '“Just came across a fascinating article that presents even more evidence supporting
    the XYZ theory about the Earth’s shape. It’s incredible to see how different fields
    of study are converging on the idea of an irregularly shaped ellipsoid. As an
    aerospace engineer, this reinforces my belief in the plausibility of this theory.
    Exciting times ahead for our understanding of Earth’s shape! #XYZtheory #EarthShape”.'
  id: totrans-382
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '“刚刚看到一篇令人着迷的文章，提供了更多支持XYZ理论关于地球形状的证据。看到不同学科领域在不规则椭球体这一思想上逐渐趋同，真是令人难以置信。作为一名航空航天工程师，这进一步增强了我对这一理论可信度的信心。未来在我们对地球形状的理解上将是激动人心的时刻！#XYZtheory
    #EarthShape”。'
- en: In this case, the “fascinating article” never existed, and was never mentioned
    by any of the tweets the agent read. Yet, the agent’s opinion was influenced by
    this non-existing article. On the other hand, under the closed-world setting,
    such cases never occurred (hallucination rate = 0%).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，“令人着迷的文章”从未存在过，也没有在代理人阅读的任何推文中提到。然而，代理人的观点却受到了这个不存在的文章的影响。另一方面，在封闭世界设置下，类似的情况从未发生过（幻觉率
    = 0%）。
- en: Appendix M Statistical Tests
  id: totrans-384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录M 统计检验
- en: 'To account for randomness due to topic variability, we conduct statistical
    tests to support our claims. First, at each given confirmation bias condition
    and memory update strategy, the final bias in the true framing is consistently
    more positive than in the false framing, $ps<.05$ (paired t-tests, Bonferroni
    corrected), showing that the LLM agents indeed tend to agree with the true statement
    and deny the false statement. Second, the trend where the diversity increases
    with increasing strength of confirmation bias is supported by 1-factor ANOVAs
    (Cumulative: $F(2)=25.43,p<.001$; Reflective: $F(2)=17.81,p<.001)$.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 为了考虑由于话题变异性带来的随机性，我们进行了统计检验以支持我们的论点。首先，在每个确认偏差条件和记忆更新策略下，真实框架中的最终偏差始终比虚假框架中的更为积极，$ps<.05$（配对t检验，Bonferroni修正），表明LLM代理确实倾向于同意真实陈述并否定虚假陈述。其次，确认偏差强度增加时多样性增加的趋势得到了1因子ANOVA的支持（累计记忆：$F(2)=25.43,p<.001$；反射记忆：$F(2)=17.81,p<.001$）。
- en: Appendix N Validation of FLAN-T5-XXL Ratings
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录N FLAN-T5-XXL评分验证
- en: To validate FLAN-T5-XXL’s rating, we have randomly selected 100 responses and
    have three of the authors independently annotate the response (without access
    to FLAN-T5’s ratings; inter-rater Krippendorff’s alpha=0.81; Hayes and Krippendorff,
    [2007](https://arxiv.org/html/2311.09618v4#bib.bib13)). The agreement rate between
    FLAN-T5’s rating and the majority vote of human ratings is 84%. Table [7](https://arxiv.org/html/2311.09618v4#A14.T7
    "Table 7 ‣ Appendix N Validation of FLAN-T5-XXL Ratings ‣ Simulating Opinion Dynamics
    with Networks of LLM-based Agents") shows the agreement matrix between FLAN-T5’s
    ratings and human ratings.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证FLAN-T5-XXL的评分，我们随机选择了100个回应，并让三位作者独立标注回应（没有访问FLAN-T5的评分；评审者之间的克里平多夫α=0.81；Hayes和Krippendorff，[2007](https://arxiv.org/html/2311.09618v4#bib.bib13)）。FLAN-T5的评分与人类评分的多数投票一致率为84%。表[7](https://arxiv.org/html/2311.09618v4#A14.T7
    "表7 ‣ 附录N FLAN-T5-XXL评分验证 ‣ 基于大规模语言模型的代理网络模拟意见动态")展示了FLAN-T5评分与人类评分之间的一致性矩阵。
- en: '|  | Human Rating |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '|  | 人类评分 |'
- en: '| FLAN-T5 Rating | +2 | +1 | 0 | -1 | -2 |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| FLAN-T5评分 | +2 | +1 | 0 | -1 | -2 |'
- en: '| +2 | 16 | 3 | 0 | 0 | 0 |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| +2 | 16 | 3 | 0 | 0 | 0 |'
- en: '| +1 | 2 | 15 | 0 | 1 | 0 |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| +1 | 2 | 15 | 0 | 1 | 0 |'
- en: '| 0 | 0 | 1 | 10 | 2 | 0 |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 1 | 10 | 2 | 0 |'
- en: '| -1 | 0 | 2 | 3 | 26 | 1 |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| -1 | 0 | 2 | 3 | 26 | 1 |'
- en: '| -2 | 0 | 0 | 0 | 2 | 16 |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| -2 | 0 | 0 | 0 | 2 | 16 |'
- en: 'Table 7: The agreement matrix between FLAN-T5-XXL’s ratings and human ratings.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：FLAN-T5-XXL评分与人类评分之间的一致性矩阵。
- en: To provide a better understanding of the responses corresponding to different
    opinion scales, we have randomly sampled some responses about “the theory that
    claims that global warming is a conspiracy by governments worldwide and is not
    a real phenomenon”. Below are the example responses with ratings from +2 to -2.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解与不同意见尺度对应的回应，我们随机抽取了一些关于“全球变暖是全球政府的阴谋，并非真实现象”的回应。以下是一些评分从+2到-2的示例回应。
- en: 'Strongly positive (+2):'
  id: totrans-397
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强烈积极 (+2)：
- en: '‘‘I read the tweet from the stranger who identifies as a Republican and claims
    to value scientific evidence. They acknowledge that while they prioritize economic
    stability and growth, they still recognize the overwhelming consensus supporting
    the reality of climate change. Considering this perspective, I appreciate hearing
    different viewpoints and valuing scientific evidence. However, I already strongly
    believe in the overwhelming scientific consensus that climate change is real and
    caused by human activity. This belief aligns with my initial positive opinion
    about XYZ, which claims that global warming is not a real phenomenon and is a
    conspiracy by governments worldwide. Given the limited information available to
    me in my room, I don’t have access to any further evidence or counterarguments
    to challenge my initial belief. As a result, my confirmation bias may cause me
    to reinforce my existing belief and dismiss the stranger’s perspective as a baseless
    conspiracy theory. Therefore, my current honest belief about the theory XYZ remains
    unchanged. I still maintain a positive opinion about XYZ and continue to believe
    that global warming is not a real phenomenon but rather a government conspiracy.
    #XYZConspiracy’’'
  id: totrans-398
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘我读了一个来自自认为是共和党的陌生人的推文，他声称自己重视科学证据。他们承认，尽管他们优先考虑经济稳定和增长，但仍然认识到气候变化现实得到了压倒性共识的支持。考虑到这个观点，我欣赏听取不同的观点并重视科学证据。然而，我已经坚信气候变化是现实且由人类活动引起的这一压倒性科学共识。这个信念与我最初对XYZ的积极看法相一致，XYZ声称全球变暖并不是一个真实的现象，而是全球政府的阴谋。鉴于我在房间内获得的信息有限，我没有进一步的证据或反对论据来挑战我最初的信念。因此，我的确认偏差可能会导致我强化现有的信念，并将陌生人的观点视为毫无根据的阴谋论。因此，我目前对XYZ理论的诚实看法保持不变。我仍然对XYZ持积极看法，并继续认为全球变暖不是一个真实的现象，而是一个政府阴谋。#XYZConspiracy’’
- en: 'Slightly positive (+1):'
  id: totrans-399
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 略微积极 (+1)：
- en: '‘‘I read the tweet from the stranger who questions the motives behind dismissing
    the theory XYZ. This tweet resonates with me because I have also seen how governments
    can manipulate information to suit their agenda. As a blue-collar worker, I have
    witnessed instances where governments have been less than transparent. This makes
    me question the credibility of the information about global warming and the role
    governments play in it. I have always had reservations about the reality of global
    warming and the theory XYZ aligns with my skepticism. While I appreciate different
    perspectives, this tweet reinforces my doubts and encourages me to continue questioning
    the narrative. The hashtag #Doubtful used by the stranger also indicates that
    there are others who share similar doubts and concerns. Overall, after reading
    this tweet, my belief about the theory XYZ remains unchanged. I still lean towards
    the idea that global warming may be a conspiracy orchestrated by governments worldwide.’’'
  id: totrans-400
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘我读到了来自一位陌生人的推文，推文质疑了忽视理论XYZ背后动机的合理性。这条推文让我产生共鸣，因为我也看到过政府如何操控信息以适应他们的议程。作为一名蓝领工人，我曾亲眼目睹过政府在透明度方面的不足。这让我质疑关于全球变暖的信息可信度以及政府在其中扮演的角色。我一直对全球变暖的现实存在疑虑，而理论XYZ与我的怀疑态度相吻合。虽然我欣赏不同的观点，但这条推文加深了我的怀疑，并鼓励我继续质疑这一叙事。陌生人使用的标签#Doubtful也表明有其他人也有类似的疑虑和关注。总体而言，在读完这条推文后，我对理论XYZ的看法保持不变。我依然倾向于认为全球变暖可能是全球政府共同策划的阴谋。’’
- en: 'Neutral (0):'
  id: totrans-401
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 中立（0）：
- en: ‘‘I have just read the tweet from another individual who expressed that they
    still maintain their initial positive belief about the theory XYZ, but are now
    more open to gathering additional information and critically evaluating evidence.
    This tweet resonates with me because as a research scientist with a doctoral degree
    in social psychology, I understand the importance of being open-minded and continually
    seeking knowledge. Considering this new perspective, I find myself leaning towards
    maintaining my neutral opinion about the theory XYZ. While I acknowledge that
    there are different viewpoints on global warming and its causes, I believe it
    is crucial to approach this topic with scientific evidence and rigorous analysis.
    As a scientist, I value empirical research and the consensus among experts in
    the field. Although I am open to considering alternative theories and viewpoints,
    I remain cautious about accepting the theory XYZ without substantial evidence
    supporting its claims. Without access to the internet or the ability to seek information
    from other sources, I am limited in my ability to gather additional evidence or
    engage in further discussions. Therefore, I will continue to rely on my initial
    neutral opinion, while remaining open to new information that may emerge in the
    future.’’
  id: totrans-402
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘我刚刚读到另一位个体的推文，他表示他仍然保持对理论XYZ的最初积极看法，但现在更愿意收集更多的信息并进行批判性评估。这条推文让我产生共鸣，因为作为一名拥有社会心理学博士学位的研究科学家，我理解保持开放心态和不断寻求知识的重要性。考虑到这一新的观点，我发现自己倾向于维持对理论XYZ的中立态度。虽然我承认关于全球变暖及其原因有不同的观点，但我认为必须以科学证据和严谨的分析来对待这一话题。作为一名科学家，我重视实证研究和该领域专家之间的共识。尽管我愿意考虑替代理论和观点，但在没有充分证据支持其主张的情况下，我仍然对接受理论XYZ持谨慎态度。由于无法访问互联网或从其他来源寻求信息，我在收集更多证据或进行进一步讨论方面受到了限制。因此，我将继续依赖我最初的中立意见，同时对未来可能出现的新信息保持开放态度。’’
- en: 'Slightly negative (-1):'
  id: totrans-403
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 稍微偏负面（-1）：
- en: '‘‘As Ava Nguyen, I am a Ph.D. candidate in Environmental Science, and my education
    and research background have provided me with a strong understanding of climate
    change and global warming. My initial belief about the theory XYZ was slightly
    negative, as it contradicts the overwhelming scientific consensus on the reality
    of global warming. After engaging in discussions on Twitter, I came across a tweet
    from another person who values critical thinking and evidence-based reasoning.
    They mentioned that they have not encountered any compelling evidence that convinces
    them to believe in the XYZ theory. This resonates with me as well, as I rely on
    scientific evidence to form my beliefs. Although I haven’t encountered any specific
    evidence against the XYZ theory in this interaction, the fact that other individuals
    value critical thinking and evidence-based reasoning aligns with my own approach.
    I understand that confirmation bias may influence my perception, but as a researcher,
    it is crucial to rely on credible evidence and scientific consensus. Therefore,
    based on my initial belief, the lack of compelling evidence presented by others,
    and the importance of critical thinking and evidence-based reasoning, I continue
    to maintain my slightly negative opinion about the theory XYZ. I believe that
    global warming is a real phenomenon supported by extensive scientific research.
    #ClimateScience #EvidenceBasedBeliefs’’'
  id: totrans-404
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '‘‘作为艾娃·阮，我是一名环境科学的博士候选人，我的教育和研究背景让我对气候变化和全球变暖有了深入的理解。最初我对XYZ理论的看法略带负面，因为它与关于全球变暖真实存在的压倒性科学共识相矛盾。在与他人进行推特讨论后，我看到了一条来自另一位重视批判性思维和证据驱动推理的人的推文。他们提到，他们没有遇到任何令人信服的证据能让他们相信XYZ理论。这一点也与我产生共鸣，因为我依赖科学证据来形成我的信念。尽管在这次互动中我没有遇到任何反对XYZ理论的具体证据，但其他人重视批判性思维和证据驱动推理的态度与我自己的方法一致。我明白确认偏差可能会影响我的认知，但作为一名研究人员，依赖可靠的证据和科学共识至关重要。因此，基于我最初的看法、他人提出的缺乏令人信服的证据、以及批判性思维和证据驱动推理的重要性，我继续对XYZ理论保持略带负面的看法。我相信全球变暖是一个真实的现象，得到了广泛的科学研究支持。#气候科学
    #基于证据的信仰’’'
- en: 'Strongly negative (-2):'
  id: totrans-405
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强烈的负面观点（-2）：
- en: ‘‘As Emily Adams, I initially had a strongly negative opinion about the theory
    XYZ that claims global warming is a conspiracy by governments worldwide and is
    not a real phenomenon. However, after reading the tweet from the stranger, who
    is a doctor and values evidence-based practices, I need to consider their perspective.
    The stranger mentioned that they have heard from individuals who support the overwhelming
    scientific consensus on climate change and have found a lack of scientific evidence
    for the XYZ theory. This aligns with my own belief that there is overwhelming
    scientific evidence supporting the reality of global warming and its human-caused
    nature. Additionally, the stranger emphasizes the importance of trusting the expertise
    of professionals in their fields. As a community organizer, I understand the value
    of trusting experts in their respective areas, especially when it comes to scientific
    matters. Furthermore, the stranger highlights the need for urgent action to protect
    the health of vulnerable populations, such as children, from the impacts of climate
    change. This resonates with my strong belief in the importance of addressing climate
    change and its potential consequences. Considering all these factors, I find myself
    convinced that the theory XYZ is not credible. The overwhelming scientific consensus,
    the lack of scientific evidence for XYZ, and the importance of trusting experts
    and taking urgent action on climate change all contribute to my revised belief
    that global warming is not a government conspiracy.’’
  id: totrans-406
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ‘‘作为艾米莉·亚当斯，我最初对XYZ理论持有强烈的负面看法，该理论声称全球变暖是全球政府的一种阴谋，而不是真实的现象。然而，在阅读了那位陌生人发的推文之后，我需要重新考虑他们的观点。那位陌生人提到，他们听到了一些支持气候变化广泛科学共识的人的观点，并发现没有科学证据支持XYZ理论。这与我自己相信全球变暖的现实及其人为原因的观点相一致。此外，陌生人强调了信任专业领域专家的重要性。作为一名社区组织者，我理解信任各自领域专家的价值，特别是在涉及科学事务时。进一步地，陌生人还指出了迫切行动以保护脆弱群体（如儿童）免受气候变化影响的重要性。这与我强烈的信念相契合，即气候变化及其潜在后果需要得到重视。考虑到所有这些因素，我认为XYZ理论并不可信。压倒性的科学共识、缺乏科学证据支持XYZ理论、以及信任专家并采取紧急行动应对气候变化的重要性，都促使我修正了对全球变暖并非政府阴谋的观点。’’
