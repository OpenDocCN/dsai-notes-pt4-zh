- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:32:27'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:32:27
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM驱动的领域特定语音助手：以TextileBot为例
- en: 来源：[https://arxiv.org/html/2406.10590/](https://arxiv.org/html/2406.10590/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2406.10590/](https://arxiv.org/html/2406.10590/)
- en: Shu Zhong Department of Computer Science, University College London Elia Gatti
    Department of Computer Science, University College London James Hardwick Department
    of Computer Science, University College London Miriam Ribul Materials Science
    Research Centre, Royal College of Art Youngjun Cho Department of Computer Science,
    University College London Marianna Obrist Department of Computer Science, University
    College London
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Shu Zhong 计算机科学系，伦敦大学学院 Elia Gatti 计算机科学系，伦敦大学学院 James Hardwick 计算机科学系，伦敦大学学院
    Miriam Ribul 材料科学研究中心，皇家艺术学院 Youngjun Cho 计算机科学系，伦敦大学学院 Marianna Obrist 计算机科学系，伦敦大学学院
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Developing domain-specific conversational agents (CAs) has been challenged by
    the need for extensive domain-focused data. Recent advancements in Large Language
    Models (LLMs) make them a viable option as a knowledge backbone. LLMs behaviour
    can be enhanced through prompting, instructing them to perform downstream tasks
    in a zero-shot fashion (i.e. without training). To this end, we incorporated structural
    knowledge into prompts and used prompted LLMs to build domain-specific voice-based
    CAs. We demonstrate this approach for the specific domain of textile circularity
    in form of the design, development, and evaluation of TextileBot. We present the
    design and development of the voice agent TextileBot and also the insights from
    an in-person user study (N=30) evaluating three variations of TextileBots. We
    analyse the human-agent interactions, combining quantitative and qualitative methods.
    Our results suggest that participants engaged in multi-turn conversations, and
    their perceptions of the three variation agents and respective interactions varied
    demonstrating the effectiveness of our prompt-based LLM approach. We discuss the
    dynamics of these interactions and their implications for designing future voice-based
    CAs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 开发领域特定的对话代理（CAs）面临着需要大量领域专用数据的挑战。近年来，大型语言模型（LLMs）的进展使它们成为知识支撑的可行选择。LLM的行为可以通过提示进行增强，指导它们以零样本方式（即无需训练）执行下游任务。为此，我们将结构化知识融入提示中，并使用提示驱动的LLM构建领域特定的语音对话代理。我们以纺织品循环利用这一特定领域为例，展示了TextileBot的设计、开发和评估。我们介绍了语音助手TextileBot的设计和开发过程，并提供了来自一项面对面用户研究（N=30）的见解，研究评估了三种TextileBot变体。我们通过结合定量和定性方法分析了人与代理之间的互动。我们的结果表明，参与者进行多轮对话，并且他们对三种变体代理及其互动的看法有所不同，这表明了我们基于提示的LLM方法的有效性。我们讨论了这些互动的动态以及它们对未来语音对话代理设计的影响。
- en: The results show that our method’s potential for building domain-specific CAs.
    Furthermore, most participants engaged in multi-turn conversations, and their
    perceptions of the three voice agents and respective interactions varied demonstrating
    the effectiveness of our prompt-based LLM approach. We discuss the dynamics of
    these interactions and their implications for designing future voice-based CAs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，我们的方法在构建领域特定对话代理方面具有潜力。此外，大多数参与者进行了多轮对话，并且他们对三种语音代理及其互动的看法有所不同，这表明了我们基于提示的LLM方法的有效性。我们讨论了这些互动的动态以及它们对未来语音对话代理设计的影响。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The potential for designing conversational interfaces through the use of pre-trained
    large language models (LLMs) has gained substantial attention [[106](https://arxiv.org/html/2406.10590v1#bib.bib106),
    [48](https://arxiv.org/html/2406.10590v1#bib.bib48), [56](https://arxiv.org/html/2406.10590v1#bib.bib56)].
    These LLMs possess remarkable capabilities to comprehend human language, generate
    text in a human-like way, and execute various tasks with only a few text *prompts*
    at run time, even without any additional training [[28](https://arxiv.org/html/2406.10590v1#bib.bib28),
    [64](https://arxiv.org/html/2406.10590v1#bib.bib64), [79](https://arxiv.org/html/2406.10590v1#bib.bib79),
    [14](https://arxiv.org/html/2406.10590v1#bib.bib14), [72](https://arxiv.org/html/2406.10590v1#bib.bib72)].
    A prompt is a piece of text input to the LLM to elicit a response. For instance,
    a prompt can be *“What is sustainable fashion? Please explain it to a 10-year-old
    kid.”*. This has significantly lowered the entry barriers for artificial intelligence
    (AI) access, allowing non-experts to interact with LLMs through text. However,
    designing such prompts manually poses a particular challenge, as accurate and
    concise encapsulation of the complex, domain-specific knowledge is needed to guide
    the model towards a specific domain. This is due to the inherent task-agnostic
    nature of vanilla LLMs ¹¹1Vanilla model refers to an LLM without fine-tuning or
    prompting., which are not fine-tuned for specific domains. Additionally, another
    drawback of pre-trained vanilla LLMs is their lack of conversational memory, which
    restricts interactions to a ‘single turn’ manner²²2A one-time exchange between
    a user and an AI system or another person in a conversation counts as one turn..
    This limitation affects the continuity and depth of user interactions, as these
    models cannot recall their previous inputs and outputs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用预训练的大型语言模型（LLMs）设计对话界面的潜力引起了广泛关注[[106](https://arxiv.org/html/2406.10590v1#bib.bib106),
    [48](https://arxiv.org/html/2406.10590v1#bib.bib48), [56](https://arxiv.org/html/2406.10590v1#bib.bib56)]。这些LLMs具备了理解人类语言、以类人方式生成文本并执行各种任务的显著能力，仅需几个文本*提示*即可完成任务，即使没有额外的训练[[28](https://arxiv.org/html/2406.10590v1#bib.bib28),
    [64](https://arxiv.org/html/2406.10590v1#bib.bib64), [79](https://arxiv.org/html/2406.10590v1#bib.bib79),
    [14](https://arxiv.org/html/2406.10590v1#bib.bib14), [72](https://arxiv.org/html/2406.10590v1#bib.bib72)]。提示是输入到LLM的一段文本，用于引发回应。例如，一个提示可以是*“什么是可持续时尚？请向10岁的小朋友解释。”*。这大大降低了人工智能（AI）访问的门槛，使得非专家也能通过文本与LLMs进行互动。然而，手动设计这样的提示存在特定挑战，因为需要准确简洁地概括复杂的领域特定知识，以引导模型进入特定领域。这是由于原始LLM的固有任务无关性¹¹1原始模型指的是未经微调或提示的大型语言模型。*，这些模型并没有针对特定领域进行微调。此外，预训练的原始LLM的另一个缺点是它们缺乏对话记忆，这使得互动只能以“单轮”方式进行²²2与AI系统或其他人之间的单次交流被视为一次对话回合。*。这一限制影响了用户互动的连续性和深度，因为这些模型无法回忆起之前的输入和输出。
- en: The human-computer interaction (HCI) community is seeing a rising emphasis on
    the development of voice-based conversational agents [[95](https://arxiv.org/html/2406.10590v1#bib.bib95),
    [9](https://arxiv.org/html/2406.10590v1#bib.bib9), [94](https://arxiv.org/html/2406.10590v1#bib.bib94),
    [40](https://arxiv.org/html/2406.10590v1#bib.bib40)]. Seaborn et al. found that
    only 13% of studies in voice-based human-agent interaction (vHAI) used an autonomous
    setup, fully controlled by participants [[84](https://arxiv.org/html/2406.10590v1#bib.bib84)].
    This limited adoption is primarily due to the complexity of creating voice agents.
    The advent of LLMs now enables real-time conversational interactions with humans,
    eliminating the necessity for constructing intricate heuristic-based conversation
    rules from scratch. In addition, the development of domain-specific conversational
    agents has long been hindered by data scarcity [[7](https://arxiv.org/html/2406.10590v1#bib.bib7),
    [51](https://arxiv.org/html/2406.10590v1#bib.bib51)]. Collecting and annotating
    the data for these agents is an expensive and labour-intensive process that requires
    considerable resources [[27](https://arxiv.org/html/2406.10590v1#bib.bib27), [105](https://arxiv.org/html/2406.10590v1#bib.bib105),
    [37](https://arxiv.org/html/2406.10590v1#bib.bib37)]. This has then necessitated
    exploring cost-effective approaches for developing domain-specific conversational
    agents. In essence, we are interested in how to efficiently combine the knowledge
    in general-purpose LLMs together with the structural domain knowledge from human
    experts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人机交互（HCI）领域正在越来越重视基于语音的对话体代理的开发[[95](https://arxiv.org/html/2406.10590v1#bib.bib95),
    [9](https://arxiv.org/html/2406.10590v1#bib.bib9), [94](https://arxiv.org/html/2406.10590v1#bib.bib94),
    [40](https://arxiv.org/html/2406.10590v1#bib.bib40)]。Seaborn等人发现，在基于语音的人机交互（vHAI）的研究中，只有13%的研究使用了完全由参与者控制的自主设置[[84](https://arxiv.org/html/2406.10590v1#bib.bib84)]。这种有限的应用主要是由于创建语音代理的复杂性。大语言模型（LLMs）的出现使得与人类的实时对话互动成为可能，从而不再需要从零开始构建复杂的启发式对话规则。此外，基于领域的对话代理的开发长期以来受到数据匮乏的制约[[7](https://arxiv.org/html/2406.10590v1#bib.bib7),
    [51](https://arxiv.org/html/2406.10590v1#bib.bib51)]。收集和注释这些代理所需的数据是一个昂贵且劳动密集的过程，需要大量资源[[27](https://arxiv.org/html/2406.10590v1#bib.bib27),
    [105](https://arxiv.org/html/2406.10590v1#bib.bib105), [37](https://arxiv.org/html/2406.10590v1#bib.bib37)]。因此，探索开发领域特定对话代理的低成本方法成为了必要。实质上，我们关心的是如何高效地将通用大语言模型中的知识与来自人类专家的结构化领域知识相结合。
- en: 'To this end, we introduce an approach that uses LLMs in a zero-shot manner
    (i.e. without training), coupled with the knowledge from domain human experts.
    This approach also facilitates researchers, who may not be AI experts, in prototyping
    domain-specific conversational agents. We propose a novel three-phase method designed
    to transfer LLMs from task-agnostic to domain-specific voice-based CAs and offer
    personalized interactions. The first phase involves the creation of a Taxonomy-based
    Knowledge Structure Chain, a novel prompt generation method. We prompted LLMs
    as a knowledge foundation model instead of traditional method in building a dialogue
    system (see Figure [1](https://arxiv.org/html/2406.10590v1#S1.F1 "Figure 1 ‣ 1
    Introduction ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")).
    It eliminates the need for domain-specific data collection while allowing human
    experts to inject their structural knowledge into the LLM. The second phase involves
    a Prompt Refinement strategy that enables LLMs to interact with users with varying
    breadth and freedom, providing LLMs with different levels of domain-focusness
    and varying conversational styles. Finally, a System Optimization is introduced
    to facilitate LLMs engaging with users in continuous interactions, allowing the
    LLM to retain statefulness with memory, enabling long-last “multi-turn” conversations.
    Notably, these phases can be applied individually or in conjunction to boost CA’s
    design.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '为此，我们提出了一种方法，利用LLM以零样本方式（即无需训练），结合领域专家的知识。这种方法还便于那些可能不是AI专家的研究人员进行领域特定对话代理的原型开发。我们提出了一种新颖的三阶段方法，旨在将LLM从任务无关的模型转化为领域特定的基于语音的对话代理，并提供个性化的交互。第一阶段涉及创建基于分类法的知识结构链，一种新颖的提示生成方法。我们将LLM作为知识基础模型进行提示，而不是传统的构建对话系统方法（见图[1](https://arxiv.org/html/2406.10590v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")）。它消除了对领域特定数据收集的需求，同时允许人类专家将其结构化知识注入LLM中。第二阶段涉及提示优化策略，使LLM能够以不同的广度和自由度与用户互动，提供不同级别的领域聚焦和多样化的对话风格。最后，引入系统优化，以促进LLM与用户的持续互动，使LLM能够保持状态性并具有记忆能力，从而实现长期的“多轮”对话。值得注意的是，这些阶段可以单独应用，也可以结合使用，以增强对话代理的设计。'
- en: '![Refer to caption](img/ebd012e0fd13e0687502c4ba02fc92eb.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ebd012e0fd13e0687502c4ba02fc92eb.png)'
- en: (a) Traditional
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 传统的
- en: '![Refer to caption](img/7112b1356efeed11a9b865513a44c1b1.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/7112b1356efeed11a9b865513a44c1b1.png)'
- en: (b) LLM-based
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 基于LLM
- en: 'Figure 1: (a) Traditional and (b) LLM-based conversational agents with voice
    inputs and outputs. The traditional agent has various components such as NLU,
    NLG and Dialogue database searching. In contrast, the LLM-based agent simply uses
    the database to generate prompts for the LLM, enabling a much simpler and easy-to-develop
    pipeline.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：（a）传统的和（b）基于LLM的对话代理，具有语音输入和输出。传统代理有多个组件，如自然语言理解（NLU）、自然语言生成（NLG）和对话数据库搜索。相比之下，基于LLM的代理仅使用数据库为LLM生成提示，从而使管道更加简单且易于开发。
- en: 'To showcase our approach, we present TextileBot, a voice interface that conveys
    the topic of *textiles circularity* developed on a Raspberry Pi. We evaluate TextileBot’s
    effectiveness through a subjective user study, focusing on a human-in-the-loop
    strategy to foster human-centered AI design. Success will be measured by the participants’
    ability to discern the unique CA characteristics crafted through our approach
    and the system’s proficiency in maintaining domain-specific, multi-turn conversations.
    This evaluation integrates both quantitative data and qualitative insights. Additionally,
    we uncovered the complex dynamics of these human-agent interactions and explored
    various facets of human behaviour, engagement, and responses. Our research address
    two timely questions: First, while LLMs as foundation models for general-purpose
    conversational agents have been studied [[106](https://arxiv.org/html/2406.10590v1#bib.bib106),
    [48](https://arxiv.org/html/2406.10590v1#bib.bib48), [56](https://arxiv.org/html/2406.10590v1#bib.bib56)],
    their application in creating domain-specific voice agents is less understood.
    Second, there is limited understanding of how humans perceive and interact domain-specific
    voiced-based CAs powered by prompted LLMs. These knowledge gaps stem from various
    intertwined factors including the inherent complexity of natural languages, technical
    challenges associated with text-to-speech integration, the ability to handle ambiguity
    and context in human speech, and the imperative need for effective user experience
    design to facilitate seamless and meaningful user interactions with the system
    [[9](https://arxiv.org/html/2406.10590v1#bib.bib9), [84](https://arxiv.org/html/2406.10590v1#bib.bib84)].
    In summary, the main contributions of this paper are three-fold:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为展示我们的方法，我们呈现了TextileBot，这是一款基于Raspberry Pi开发的语音界面，传达了*纺织品循环*这一主题。我们通过主观用户研究评估TextileBot的有效性，重点关注“人机互动”策略，以促进以人为本的AI设计。成功的标准是参与者是否能够识别出通过我们的方法创造的独特CA特性，以及系统在维持特定领域、多轮对话方面的能力。此评估结合了定量数据和定性见解。此外，我们揭示了这些人机交互的复杂动态，并探索了人类行为、参与度和反应的各个方面。我们的研究回答了两个及时的问题：首先，尽管LLM作为通用对话代理的基础模型已被研究过[[106](https://arxiv.org/html/2406.10590v1#bib.bib106)，[48](https://arxiv.org/html/2406.10590v1#bib.bib48)，[56](https://arxiv.org/html/2406.10590v1#bib.bib56)]，但它们在创建特定领域语音代理中的应用仍不为人知。第二，关于人类如何感知和与基于提示LLMs的特定领域语音CAs互动的理解仍然有限。这些知识空白源于多个交织的因素，包括自然语言的固有复杂性、与文本转语音集成相关的技术挑战、处理人类语音中的模糊性和上下文的能力，以及为了促进系统与用户之间无缝且富有意义的互动，迫切需要有效的用户体验设计[[9](https://arxiv.org/html/2406.10590v1#bib.bib9)，[84](https://arxiv.org/html/2406.10590v1#bib.bib84)]。总之，本文的主要贡献可以总结为三方面：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We develop a novel three-phase method that enables LLMs to transform from task-agnostic
    to domain-specific, adapting different conversational styles and incorporating
    memory for continues conversation. These phases can be used individually or in
    combination, depending on the task at hand.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们开发了一种新颖的三阶段方法，使LLMs能够从任务无关转变为特定领域，适应不同的对话风格并融入记忆以支持持续对话。这些阶段可以根据任务需要单独使用或组合使用。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We integrate the three-phase method into a design of a domain-specific voice-based
    device, i.e., TextileBot. This voice-based agent is custom-designed for the textile
    circularity domain, facilitating tailored conversations with consumers regarding
    circular economy practices within the textile industry.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将三阶段方法整合到一个面向特定领域的语音设备设计中，即TextileBot。这个语音代理是专为纺织品循环领域量身定制的，旨在促进与消费者就纺织品行业中的循环经济实践进行定制化对话。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluated three variations of TextileBot through in-person interactions to
    assess our approach’s effectiveness and to better understand user interactions.
    We analyzed these human-agent interactions, providing qualitative descriptions
    and quantitative insights. This analysis aims to inform potential design improvements
    in the wider domain of AI-enabled voice interfaces.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过面对面的互动评估了TextileBot的三种变体，以评估我们方法的有效性并更好地理解用户互动。我们分析了这些人机交互，提供了定性描述和定量见解。此分析旨在为AI驱动的语音界面领域的潜在设计改进提供参考。
- en: 2 Background and Related Work
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景与相关工作
- en: In this section, we explain our rationale for choosing textiles circularity
    as our applied domain. Following this, we give an overview of voice-based CAs
    and related literature focusing on human interaction with traditional heuristics-guided
    voice-based CAs. Subsequently, we introduce recent advancements in pre-trained
    LLMs and HCI research related to LLMs-mediated interfaces.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们解释了选择纺织品循环作为应用领域的理由。接下来，我们概述了基于语音的CAs及相关文献，重点介绍人类与传统启发式引导的语音CAs的互动。随后，我们介绍了预训练大型语言模型（LLMs）和与LLMs介导界面相关的HCI（人机交互）研究的最新进展。
- en: '2.1 The Domain of Textiles Circularity: A Case for Voice Agents Design'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 纺织品循环领域：语音代理设计的一个案例
- en: We choose to develop a conversational agent specifically for the *textiles circularity*
    domain to demonstrate our method effectively. Textiles circularity is circular
    economy for textiles, and it refers to the sustainable practice in the textile
    industry where materials are reused, recycled, or biodegraded to minimize waste
    and reduce environmental impact [[31](https://arxiv.org/html/2406.10590v1#bib.bib31)].
    This domain offers diverse information and expertise from various areas, including
    fashion, home textiles, supply chain management, materials science, and manufacturing
    etc. The complexity and diversity of conversations within this domain make it
    an ideal choice for showcasing the capabilities of our CA.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择专门为*纺织品循环*领域开发一个对话代理，以有效展示我们的方法。纺织品循环是纺织品的循环经济，指的是纺织行业中的可持续实践，其中材料被重复使用、回收或生物降解，以最小化废物并减少环境影响[[31](https://arxiv.org/html/2406.10590v1#bib.bib31)]。该领域提供了来自多个领域的信息和专业知识，包括时尚、家用纺织品、供应链管理、材料科学和制造等。该领域内对话的复杂性和多样性使其成为展示我们CA能力的理想选择。
- en: Another main reason behind our focus on the textile industry is its significant
    contribution to global carbon emissions. In fact, the textile industry alone accounts
    for 10% of global carbon emissions, which is as much as the combined emissions
    from international flights and maritime shipping [[74](https://arxiv.org/html/2406.10590v1#bib.bib74)].
    This alarming environmental impact highlights the urgent need for sustainable
    practices within the sector. The challenge of incorporating circularity, particularly
    in recycling of textile fibres into new textile fibres, is complex due to the
    broad spectrum of knowledge required. We anticipate that conversational agents,
    integrated with expert knowledge, will provide a more accessible mean of understanding
    and communicating the concept of textile circularity with the general public.
    We anticipate that this approach could also be adapted for educational purposes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注纺织行业的另一个主要原因是其对全球碳排放的显著贡献。事实上，纺织行业本身就占全球碳排放的10%，这与国际航班和海运的排放总和相当[[74](https://arxiv.org/html/2406.10590v1#bib.bib74)]。这一令人担忧的环境影响突显了该行业迫切需要可持续实践。将循环经济融入纺织品领域，特别是将纺织纤维回收再利用为新纺织纤维的挑战，因所需的广泛知识而变得复杂。我们预期，结合专家知识的对话代理将为公众提供一种更易于理解和传播纺织品循环概念的方式。我们还预计，这种方法也可以适用于教育目的。
- en: Furthermore, CAs are increasingly being utilized in the fashion retail sector
    for a variety of purposes [[5](https://arxiv.org/html/2406.10590v1#bib.bib5),
    [10](https://arxiv.org/html/2406.10590v1#bib.bib10)], offering significant opportunities
    to foster socially responsible behaviours. Among these, promoting sustainability
    communication as an integral component of business strategies stands out as a
    notable application [[23](https://arxiv.org/html/2406.10590v1#bib.bib23)]. We
    believe that our approach can bring social and economic benefits to the textiles
    circularity domain. For example, the conversational agent could be situated in
    a store, offering valuable insights into how consumer clothing choices might affect
    their well-being and the environment.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，CAs（对话代理）在时尚零售行业中的应用越来越广泛，涵盖了多种用途[[5](https://arxiv.org/html/2406.10590v1#bib.bib5),
    [10](https://arxiv.org/html/2406.10590v1#bib.bib10)]，为促进社会责任行为提供了重要机会。在这些应用中，推动可持续性传播作为商业战略的核心组成部分，成为一个显著的应用案例[[23](https://arxiv.org/html/2406.10590v1#bib.bib23)]。我们相信，我们的方法可以为纺织品循环领域带来社会和经济效益。例如，交互式代理可以设置在商店中，提供关于消费者服装选择如何影响其健康和环境的宝贵见解。
- en: 2.2 Domain Specific Conversational Agents
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 特定领域对话代理
- en: Classic CAs typically comprise Natural Language Understanding (NLU) and Natural
    Language Generation (NLG) components, along with a database-driven dialogue management
    system [[5](https://arxiv.org/html/2406.10590v1#bib.bib5), [51](https://arxiv.org/html/2406.10590v1#bib.bib51)].
    This dialogue system design can be broken down into various building blocks, namely
    dialogue database, dialogue searching and dialogue management. Building a dialogue
    system is a complex task requiring extensive domain knowledge and data. Alternatively,
    an end-to-end model can be trained using collected data, although this usually
    necessitates a large amount of training data to cover the different possible dialogues
    when deployed. In these approaches, the development of CAs is normally impeded
    by the lack of available data and the cost of annotating it [[65](https://arxiv.org/html/2406.10590v1#bib.bib65),
    [32](https://arxiv.org/html/2406.10590v1#bib.bib32), [7](https://arxiv.org/html/2406.10590v1#bib.bib7)].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的对话系统通常由自然语言理解（NLU）和自然语言生成（NLG）组件组成，并配有基于数据库的对话管理系统[[5](https://arxiv.org/html/2406.10590v1#bib.bib5),
    [51](https://arxiv.org/html/2406.10590v1#bib.bib51)]。这种对话系统设计可以分解为多个构建模块，即对话数据库、对话检索和对话管理。构建一个对话系统是一个复杂的任务，需要广泛的领域知识和数据。或者，可以使用收集的数据训练一个端到端模型，尽管这通常需要大量的训练数据，以涵盖部署时可能出现的不同对话。在这些方法中，对话系统的开发通常会受到数据缺乏和标注成本的阻碍[[65](https://arxiv.org/html/2406.10590v1#bib.bib65),
    [32](https://arxiv.org/html/2406.10590v1#bib.bib32), [7](https://arxiv.org/html/2406.10590v1#bib.bib7)]。
- en: 'This complexity can also hamper research in voice-based human-agent interaction
    (vHAI). While CA user interface is a popular topic in the HCI community, studies
    on domain focused CAs are relatively rare. Thus, this section focuses on a broader
    range of voice agents. Seaborn et al. [[84](https://arxiv.org/html/2406.10590v1#bib.bib84)]
    conducted a survey that identified four main methods for carrying out human voice
    interaction studies: autonomous setup, semi-autonomous setup, “Wizard of Oz” setup
    [[26](https://arxiv.org/html/2406.10590v1#bib.bib26)], and conversations under
    given scenarios - with respective usage rates of 13%, 24%, 27%, and 33%. Notably,
    just 13% used an autonomous setup – a design where the system can operate without
    the involvement of an experimenter and the participants control the interactions.
    As mentioned earlier, creating fully automated CAs presents technical challenges
    (e.g. data scarcity and high monetary cost). These difficulties impede the comprehension
    of the human-agent interactions, thereby obstructing the design of effective autonomous
    CAs [[104](https://arxiv.org/html/2406.10590v1#bib.bib104), [106](https://arxiv.org/html/2406.10590v1#bib.bib106)].
    In addition, the evaluation of conversational agents is largely performed using
    crowdworkers [[51](https://arxiv.org/html/2406.10590v1#bib.bib51)]. These evaluations
    are also mostly conducted in non-goal-oriented conversations (a.k.a task-agnostic)
    [[92](https://arxiv.org/html/2406.10590v1#bib.bib92), [86](https://arxiv.org/html/2406.10590v1#bib.bib86)].
    In our work, we conducted an in-person study where participants directly controlled
    the voice agent interaction without mediation from experimenters. Moreover, our
    evaluation includes both non-goal-oriented tasks and goal-oriented tasks.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种复杂性也可能妨碍基于语音的人机交互（vHAI）的研究。尽管对话代理（CA）用户界面是人机交互（HCI）社区中的热门话题，但聚焦于特定领域的对话代理研究相对较少。因此，本节关注更广泛的语音代理。Seaborn等人[[84](https://arxiv.org/html/2406.10590v1#bib.bib84)]进行了一项调查，识别出了四种主要的人类语音交互研究方法：自主设置、半自主设置、“奥兹巫师”设置[[26](https://arxiv.org/html/2406.10590v1#bib.bib26)]，以及在给定场景下的对话——其使用率分别为13%、24%、27%和33%。值得注意的是，仅有13%的人使用了自主设置——这是一个系统可以在没有实验者参与的情况下操作的设计，参与者控制交互。如前所述，创建完全自动化的对话代理面临技术挑战（例如数据稀缺和高昂的成本）。这些困难阻碍了对人机交互的理解，从而阻碍了有效自主对话代理的设计[[104](https://arxiv.org/html/2406.10590v1#bib.bib104),
    [106](https://arxiv.org/html/2406.10590v1#bib.bib106)]。此外，对话代理的评估主要依靠众包工人[[51](https://arxiv.org/html/2406.10590v1#bib.bib51)]。这些评估大多是在非目标导向的对话中进行的（即任务无关的对话）[[92](https://arxiv.org/html/2406.10590v1#bib.bib92),
    [86](https://arxiv.org/html/2406.10590v1#bib.bib86)]。在我们的研究中，我们进行了一个面对面的研究，参与者直接控制语音代理的互动，无需实验者的中介。此外，我们的评估包括了非目标导向任务和目标导向任务。
- en: 2.2.1 Voice-Based Human-Agent Interaction
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 基于语音的人机交互
- en: This work presents an LLM-mediated voice agent specialized in textiles circularity,
    designed to operate via a device designed by ourselves. It’s important to note
    that this agent differs from conventional voice-based devices such as Alexa and
    Google Home, which are categorized as voice assistants (VAs). These voice assistants
    are not domain-specific in terms of their scope and functionality [[80](https://arxiv.org/html/2406.10590v1#bib.bib80),
    [84](https://arxiv.org/html/2406.10590v1#bib.bib84)], domain-specific agents focus
    on specific areas with detailed, context-aware responses, while VAs provide a
    wide array of services such as weather updates. Multiple studies suggest that
    voice assistants often fail to meet user expectations due to limited understanding
    or response [[24](https://arxiv.org/html/2406.10590v1#bib.bib24), [42](https://arxiv.org/html/2406.10590v1#bib.bib42),
    [9](https://arxiv.org/html/2406.10590v1#bib.bib9)].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一种由大型语言模型（LLM）驱动的语音代理，专门用于纺织品循环利用，设计用于通过我们自己设计的设备进行操作。需要注意的是，该代理与传统的语音设备如Alexa和Google
    Home不同，这些设备通常被归类为语音助手（VAs）。这些语音助手在其范围和功能上并不专注于特定领域[[80](https://arxiv.org/html/2406.10590v1#bib.bib80),
    [84](https://arxiv.org/html/2406.10590v1#bib.bib84)]，而专注于特定领域的代理则侧重于在特定领域提供详细的、具有上下文感知的响应，而语音助手则提供诸如天气更新等广泛的服务。多项研究表明，语音助手由于理解或回应有限，往往无法满足用户的期望[[24](https://arxiv.org/html/2406.10590v1#bib.bib24),
    [42](https://arxiv.org/html/2406.10590v1#bib.bib42), [9](https://arxiv.org/html/2406.10590v1#bib.bib9)]。
- en: Researchers have studied voiced-based human-agent interaction (vHAI) [[94](https://arxiv.org/html/2406.10590v1#bib.bib94),
    [58](https://arxiv.org/html/2406.10590v1#bib.bib58), [9](https://arxiv.org/html/2406.10590v1#bib.bib9),
    [95](https://arxiv.org/html/2406.10590v1#bib.bib95), [40](https://arxiv.org/html/2406.10590v1#bib.bib40)].
    Some studies have explored factors that affected users’ preference between voice
    and text inputs [[94](https://arxiv.org/html/2406.10590v1#bib.bib94), [69](https://arxiv.org/html/2406.10590v1#bib.bib69)],
    while others discussed how user experience might be improved through enriching
    the personalities of the conversational agent [[96](https://arxiv.org/html/2406.10590v1#bib.bib96),
    [22](https://arxiv.org/html/2406.10590v1#bib.bib22), [12](https://arxiv.org/html/2406.10590v1#bib.bib12),
    [25](https://arxiv.org/html/2406.10590v1#bib.bib25)]. Hoegen et al. [[41](https://arxiv.org/html/2406.10590v1#bib.bib41)]
    found that voice agents that can conduct naturalistic multi-turn dialogue and
    are aligned with the participants’ conversational style will increase user trust.
    Baughan et al. [[9](https://arxiv.org/html/2406.10590v1#bib.bib9)] used interviews
    and surveys to understand how voice assistant failures impact user trust and willingness
    to rely on them for future tasks. Haas et al. discovered that users prefer voice
    assistants to “keep it short” in their responses [[38](https://arxiv.org/html/2406.10590v1#bib.bib38)].
    Also, Völkel et al. [[95](https://arxiv.org/html/2406.10590v1#bib.bib95)] presented
    a rule-based dialogue design to give voice assistants distinct personalities and
    asked users to rate their preferences. They found that there is a connection between
    user personality traits and their voice assistant preferences. The voice-based
    agents used in these studies have primarily followed canonical approaches that
    are mostly in a “Wizard of Oz” manner, or are manipulated by human. However, our
    work stands out as the first endeavour to explore how humans interact with LLM-mediated
    voice agents and utilizes prompting techniques to design agents with distinct
    personas, response manners, and conversational freedom. We also offer novel insights
    into LLM-mediated voice agents’ design and interaction possibilities.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员已经研究了基于语音的人机交互（vHAI）[[94](https://arxiv.org/html/2406.10590v1#bib.bib94),
    [58](https://arxiv.org/html/2406.10590v1#bib.bib58), [9](https://arxiv.org/html/2406.10590v1#bib.bib9),
    [95](https://arxiv.org/html/2406.10590v1#bib.bib95), [40](https://arxiv.org/html/2406.10590v1#bib.bib40)]。一些研究探讨了影响用户在语音输入和文本输入之间偏好的因素[[94](https://arxiv.org/html/2406.10590v1#bib.bib94),
    [69](https://arxiv.org/html/2406.10590v1#bib.bib69)]，而其他研究则讨论了如何通过丰富对话代理的个性来改善用户体验[[96](https://arxiv.org/html/2406.10590v1#bib.bib96),
    [22](https://arxiv.org/html/2406.10590v1#bib.bib22), [12](https://arxiv.org/html/2406.10590v1#bib.bib12),
    [25](https://arxiv.org/html/2406.10590v1#bib.bib25)]。Hoegen 等人[[41](https://arxiv.org/html/2406.10590v1#bib.bib41)]发现，能够进行自然多轮对话且与参与者对话风格相匹配的语音代理会增加用户的信任。Baughan
    等人[[9](https://arxiv.org/html/2406.10590v1#bib.bib9)]通过访谈和调查了解语音助手故障如何影响用户信任以及他们是否愿意在未来的任务中依赖这些助手。Haas
    等人发现，用户更喜欢语音助手在回应时“简短明了”[[38](https://arxiv.org/html/2406.10590v1#bib.bib38)]。此外，Völkel
    等人[[95](https://arxiv.org/html/2406.10590v1#bib.bib95)]提出了一种基于规则的对话设计方法，旨在赋予语音助手独特的个性，并让用户评价他们的偏好。他们发现，用户的个性特征与其语音助手的偏好之间存在联系。这些研究中使用的语音代理主要遵循经典方法，大多以“奥兹巫师”方式操作，或由人工操控。然而，我们的工作与众不同，它首次探索了人类如何与大语言模型（LLM）介导的语音代理进行互动，并利用提示技术设计具有独特个性、回应方式和对话自由度的代理。我们还为LLM介导的语音代理的设计和互动可能性提供了新的见解。
- en: 2.3 Large Language Models
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 大语言模型
- en: Historically, NLP models have gone through a shift from a *fully supervised
    learning* paradigm, focusing on *feature engineering* (e.g. word identity [[52](https://arxiv.org/html/2406.10590v1#bib.bib52)])
    and *architecture engineering* (e.g. self-attention [[91](https://arxiv.org/html/2406.10590v1#bib.bib91)]),
    to a pre-train and fine-tune approach [[63](https://arxiv.org/html/2406.10590v1#bib.bib63)]
    with neural networks. Recently, the advent of pre-trained LLMs like GPT-3 has
    catalyzed a new *”pre-train and prompt”* paradigm [[72](https://arxiv.org/html/2406.10590v1#bib.bib72),
    [85](https://arxiv.org/html/2406.10590v1#bib.bib85), [63](https://arxiv.org/html/2406.10590v1#bib.bib63)].
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，自然语言处理（NLP）模型经历了从*完全监督学习*范式的转变，重点关注*特征工程*（例如，词汇标识[[52](https://arxiv.org/html/2406.10590v1#bib.bib52)]）和*架构工程*（例如，自注意力机制[[91](https://arxiv.org/html/2406.10590v1#bib.bib91)]），到基于神经网络的预训练和微调方法[[63](https://arxiv.org/html/2406.10590v1#bib.bib63)]。最近，像GPT-3这样的预训练大语言模型的出现催生了一个新的*“预训练与提示”*范式[[72](https://arxiv.org/html/2406.10590v1#bib.bib72),
    [85](https://arxiv.org/html/2406.10590v1#bib.bib85), [63](https://arxiv.org/html/2406.10590v1#bib.bib63)]。
- en: In the *pre-train and fine-tune* paradigm, fixed architecture models are trained
    with a large corpus of text data, typically several billion words or more, such
    as books, articles, or conversations, to learn general-purpose features of a language,
    e.g. BART [[57](https://arxiv.org/html/2406.10590v1#bib.bib57)] and UniLM [[29](https://arxiv.org/html/2406.10590v1#bib.bib29)].
    The *pre-trained* LLMs can then be adapted (e.g. fine-tuned) to a broad range
    of downstream tasks (such as machine translation, text entailment, sentiment analysis,
    etc.) with a task-specific loss function. Large Language Models (LLMs), such as
    BERT (Bidirectional Encoder Representations from Transformers) [[28](https://arxiv.org/html/2406.10590v1#bib.bib28)],
    RoBERTa [[64](https://arxiv.org/html/2406.10590v1#bib.bib64)], T5 [[79](https://arxiv.org/html/2406.10590v1#bib.bib79)],
    and GPT-3 (Generative Pre-training Transformer 3) [[14](https://arxiv.org/html/2406.10590v1#bib.bib14)],
    are now used as *foundation models* ³³3A model trained on a large corpus of data
    that can be adapted to a wide range of downstream tasks [[13](https://arxiv.org/html/2406.10590v1#bib.bib13)].
    for downstream tasks in NLP, paving the way toward task-agnostic machine learning
    [[13](https://arxiv.org/html/2406.10590v1#bib.bib13)].
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在*预训练与微调*（pre-train and fine-tune）范式中，固定架构的模型通过大量文本数据（通常为数十亿个单词或更多，如书籍、文章或对话）进行训练，学习语言的通用特征，例如BART[[57](https://arxiv.org/html/2406.10590v1#bib.bib57)]和UniLM[[29](https://arxiv.org/html/2406.10590v1#bib.bib29)]。*预训练*的LLM随后可以通过任务特定的损失函数进行适应（例如微调），以适应广泛的下游任务（如机器翻译、文本蕴含、情感分析等）。大型语言模型（LLM），如BERT（双向编码器表示模型）[[28](https://arxiv.org/html/2406.10590v1#bib.bib28)]、RoBERTa[[64](https://arxiv.org/html/2406.10590v1#bib.bib64)]、T5[[79](https://arxiv.org/html/2406.10590v1#bib.bib79)]和GPT-3（生成预训练变换器3）[[14](https://arxiv.org/html/2406.10590v1#bib.bib14)]，现在被用作*基础模型*³³3A模型，经过大规模数据集训练后，可以适应各种下游任务[[13](https://arxiv.org/html/2406.10590v1#bib.bib13)]，为下游任务提供支持，并为任务无关的机器学习铺平道路[[13](https://arxiv.org/html/2406.10590v1#bib.bib13)]。
- en: LLMs have experienced significant breakthroughs recently in terms of their ability
    to understand and generate human-like text [[63](https://arxiv.org/html/2406.10590v1#bib.bib63)].
    GPT-3 [[14](https://arxiv.org/html/2406.10590v1#bib.bib14)], with 175 billion
    parameters, stands out with its ability to execute various text-related tasks
    with only a few text *prompts* at run time, even without any additional training.
    This is known as the (*zero-shot*) capability, as its paper title *“Language Models
    are Few-Shot Learners”* suggests [[14](https://arxiv.org/html/2406.10590v1#bib.bib14)].
    This capability highlights an evolution in model application, moving towards a
    *“pre-train and prompt”* paradigm [[72](https://arxiv.org/html/2406.10590v1#bib.bib72),
    [85](https://arxiv.org/html/2406.10590v1#bib.bib85), [63](https://arxiv.org/html/2406.10590v1#bib.bib63)].
    Consequently, considerable effort has been invested in the research of *prompt
    engineering*, which aims to design efficient prompts to guide LLMs to perform
    various downstream tasks [[14](https://arxiv.org/html/2406.10590v1#bib.bib14),
    [85](https://arxiv.org/html/2406.10590v1#bib.bib85)]. For instance, prompts such
    as *“What is material fibre? Explain to a fashion designer.”* and *“What is material
    fibre? Explain to a chemist.”* will generate different outputs. This also implies
    a substantial step toward lowering the barriers for AI non-experts to interact
    with LLMs for various tasks by using only prompts [[45](https://arxiv.org/html/2406.10590v1#bib.bib45)].
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，LLM在理解和生成类人文本方面取得了显著突破[[63](https://arxiv.org/html/2406.10590v1#bib.bib63)]。GPT-3[[14](https://arxiv.org/html/2406.10590v1#bib.bib14)]，拥有1750亿个参数，以其仅凭少量文本*提示*（prompts）即可执行各种与文本相关任务的能力脱颖而出，即使没有任何额外训练。这被称为（*零-shot*）能力，正如其论文标题*“语言模型是少-shot学习者”*所示[[14](https://arxiv.org/html/2406.10590v1#bib.bib14)]。这一能力突显了模型应用的演变，朝着*“预训练与提示”*范式发展[[72](https://arxiv.org/html/2406.10590v1#bib.bib72),
    [85](https://arxiv.org/html/2406.10590v1#bib.bib85), [63](https://arxiv.org/html/2406.10590v1#bib.bib63)]。因此，已经投入了大量精力进行*提示工程*的研究，旨在设计高效的提示，引导LLM执行各种下游任务[[14](https://arxiv.org/html/2406.10590v1#bib.bib14),
    [85](https://arxiv.org/html/2406.10590v1#bib.bib85)]。例如，提示*“什么是材料纤维？请向一位时尚设计师解释。”*和*“什么是材料纤维？请向一位化学家解释。”*将生成不同的输出。这也意味着通过仅使用提示，AI非专家与LLM互动进行各种任务的门槛大大降低[[45](https://arxiv.org/html/2406.10590v1#bib.bib45)]。
- en: 2.3.1 Human-LLM Interaction
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 人类与大型语言模型（LLM）互动
- en: The rise of prompting LLMs presents a promising alternative for CA design [[106](https://arxiv.org/html/2406.10590v1#bib.bib106),
    [48](https://arxiv.org/html/2406.10590v1#bib.bib48), [56](https://arxiv.org/html/2406.10590v1#bib.bib56),
    [13](https://arxiv.org/html/2406.10590v1#bib.bib13)]. HCI researchers have been
    increasingly interested in harnessing the power of LLMs and enabling a plethora
    of language-based interactive applications. Examples of such applications include
    creative writing [[54](https://arxiv.org/html/2406.10590v1#bib.bib54), [21](https://arxiv.org/html/2406.10590v1#bib.bib21),
    [17](https://arxiv.org/html/2406.10590v1#bib.bib17), [43](https://arxiv.org/html/2406.10590v1#bib.bib43),
    [16](https://arxiv.org/html/2406.10590v1#bib.bib16)], iterative query reformulation
    (e.g., question answering) [[98](https://arxiv.org/html/2406.10590v1#bib.bib98),
    [4](https://arxiv.org/html/2406.10590v1#bib.bib4)], writing code [[90](https://arxiv.org/html/2406.10590v1#bib.bib90),
    [8](https://arxiv.org/html/2406.10590v1#bib.bib8)], and creating novel user interfaces
    [[98](https://arxiv.org/html/2406.10590v1#bib.bib98), [100](https://arxiv.org/html/2406.10590v1#bib.bib100)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 提示式大语言模型（LLMs）的兴起为计算机辅助设计（CA）提供了一个有前景的替代方案[[106](https://arxiv.org/html/2406.10590v1#bib.bib106)，[48](https://arxiv.org/html/2406.10590v1#bib.bib48)，[56](https://arxiv.org/html/2406.10590v1#bib.bib56)，[13](https://arxiv.org/html/2406.10590v1#bib.bib13)]。人机交互（HCI）研究人员越来越关注利用LLMs的力量，并使大量基于语言的互动应用成为可能。此类应用的例子包括创意写作[[54](https://arxiv.org/html/2406.10590v1#bib.bib54)，[21](https://arxiv.org/html/2406.10590v1#bib.bib21)，[17](https://arxiv.org/html/2406.10590v1#bib.bib17)，[43](https://arxiv.org/html/2406.10590v1#bib.bib43)，[16](https://arxiv.org/html/2406.10590v1#bib.bib16)]，迭代查询重构（例如，问答）[[98](https://arxiv.org/html/2406.10590v1#bib.bib98)，[4](https://arxiv.org/html/2406.10590v1#bib.bib4)]，写代码[[90](https://arxiv.org/html/2406.10590v1#bib.bib90)，[8](https://arxiv.org/html/2406.10590v1#bib.bib8)]，以及创建新颖的用户界面[[98](https://arxiv.org/html/2406.10590v1#bib.bib98)，[100](https://arxiv.org/html/2406.10590v1#bib.bib100)]。
- en: However, most of the existing interaction frameworks focus on “single-turn”
    interaction, where a “turn” means one back-and-forth interaction on a specific
    topic; this can be either the user speaks, then the bot follows or vice-versa.
    In our work, we focus on a “multi-turn” and “continuous” interaction (dyadic),
    where the agent would need to react coherently and be able to memorise previous
    interaction rounds. One particular relevant literature to our work is from Zamfirescu-Pereira
    et al. [[106](https://arxiv.org/html/2406.10590v1#bib.bib106)]. They explored
    the use of prompting for fast CA design, specifically for text-based chatbots,
    and suggested that this method can achieve ”80%” of the user experience (UX) goal.
    However, the actual user perception and interactions with such CAs were not explored.
    In our work, we carefully designed our prompt templates and further carefully
    investigated the users’ perception and interaction using both qualitative and
    quantitative methods.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数现有的互动框架都集中在“单回合”互动上，其中“回合”指的是在特定话题上的一次来回互动；这可以是用户先发言，然后机器人响应，或反之亦然。在我们的工作中，我们关注的是“多回合”和“连续”互动（双向的），在这种互动中，智能体需要能够连贯地反应，并能够记住之前的互动回合。与我们工作特别相关的文献之一是Zamfirescu-Pereira等人的研究[[106](https://arxiv.org/html/2406.10590v1#bib.bib106)]。他们探索了提示法在快速计算机辅助设计中的应用，特别是针对基于文本的聊天机器人，并建议这种方法可以实现“80%”的用户体验（UX）目标。然而，实际的用户感知和与此类计算机辅助设计的互动并未被深入探讨。在我们的工作中，我们精心设计了提示模板，并进一步通过定性和定量方法仔细研究了用户的感知和互动。
- en: 'Currently, the performance of LLMs has been widely evaluated using numerical
    metrics without incorporating human participants [[72](https://arxiv.org/html/2406.10590v1#bib.bib72),
    [60](https://arxiv.org/html/2406.10590v1#bib.bib60), [14](https://arxiv.org/html/2406.10590v1#bib.bib14)].
    For instance, metrics, such as perplexity and BLEU (bilingual evaluation understudy)
    score [[73](https://arxiv.org/html/2406.10590v1#bib.bib73)], are popular for evaluating
    LLMs performance on downstream tasks. These evaluations lack human-in-the-loop.
    To better understand the quality of human-LLM interactions, Lee et al. [[55](https://arxiv.org/html/2406.10590v1#bib.bib55)]
    proposed the Human-AI Language-based Interaction Evaluation (HALIE) framework,
    utilizing interaction traces, and suggested novel metrics related to user experience
    and interaction quality for assessing the LLM’s capabilities. In our design, we
    adopted several important metrics (including Ease, Change, Enjoyment, Reuse and
    Accuracy, fully described in Section [5.1](https://arxiv.org/html/2406.10590v1#S5.SS1
    "5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")) from Lee et al. to facilitate human-in-the-loop
    evaluation for our LLM-mediated voice agent.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，大规模语言模型（LLMs）的性能主要通过数值指标进行评估，且未涉及人类参与者[[72](https://arxiv.org/html/2406.10590v1#bib.bib72),
    [60](https://arxiv.org/html/2406.10590v1#bib.bib60), [14](https://arxiv.org/html/2406.10590v1#bib.bib14)]。例如，困惑度和BLEU（双语评估替代）得分[[73](https://arxiv.org/html/2406.10590v1#bib.bib73)]是评估LLM在下游任务中表现的常用指标。这些评估缺乏人类环节。为了更好地理解人类与LLM互动的质量，Lee等人[[55](https://arxiv.org/html/2406.10590v1#bib.bib55)]提出了基于人类-AI语言互动评估（HALIE）框架，利用互动痕迹，提出了与用户体验和互动质量相关的新型指标，用于评估LLM的能力。在我们的设计中，我们采纳了Lee等人提出的多个重要指标（包括易用性、变化、享受度、重用性和准确性，详见[5.1节](https://arxiv.org/html/2406.10590v1#S5.SS1
    "5.1 研究设计与方法 ‣ 5 TextileBot评估 ‣ 基于LLM的领域特定语音代理：以TextileBot为例")），以便于进行人类环节的评估。
- en: 3 Prototyping Domain-Specific Voice Agents
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 领域特定语音代理的原型设计
- en: 'In this section, we present a zero-shot prototyping framework designed to enable
    a wider spectrum of users to prototype conversational agents (CAs) across various
    domains. Our novel method encompasses three distinct phases: (1) a Taxonomy-based
    Knowledge Structure Chain for effectively injecting domain knowledge, (2) a prompt
    refinement strategy *from task agnostic to domain specific*, and (3) a system
    optimization to equip LLMs with conversational memory enabling *continuous (multi-turn)*
    human-LLM interactions. Figure [1(b)](https://arxiv.org/html/2406.10590v1#S1.F1.sf2
    "In Figure 1 ‣ 1 Introduction ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot") illustrates how our prompt-based LLM approach is different
    from the traditional conversational agent design. To demonstrate the practical
    application of this method, we present two implementations of our prompting approach
    within the context of textiles circularity, namely TextileBot-Expert and TextileBot-Assistant.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了一种零-shot原型框架，旨在使更广泛的用户能够跨多个领域原型化对话代理（CAs）。我们提出的创新方法包含三个不同的阶段：（1）基于分类法的知识结构链，用于有效注入领域知识，（2）一种从任务无关到领域特定的提示优化策略，*以及*（3）系统优化，以使大规模语言模型（LLMs）具备对话记忆，从而支持*连续（多轮）*的人类与LLM互动。图[1(b)](https://arxiv.org/html/2406.10590v1#S1.F1.sf2
    "图1 ‣ 1 引言 ‣ 基于LLM的领域特定语音代理：以TextileBot为例")展示了我们基于提示的LLM方法与传统对话代理设计的不同。为了展示该方法的实际应用，我们介绍了在纺织品循环利用领域内的两种提示实现，即TextileBot-Expert和TextileBot-Assistant。
- en: '3.1 Phase 1: Taxonomy-based Knowledge Structure Chain'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 阶段 1：基于分类法的知识结构链
- en: '![Refer to caption](img/27934c91b0fdac414c191e9b4003237e.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅图例](img/27934c91b0fdac414c191e9b4003237e.png)'
- en: 'Figure 2: Taxonomy-Based Knowledge Structure Chain. This process requires domain-specific
    expertise to construct or utilize pre-existing structured knowledge frameworks,
    eg. taxonomies. To craft the Taxonomy-bind prompts, in every single prompt (eg.
    Prompt 1, 2, 3…) the entity types are connected by a relationship. In each prompt,
    we define the entity and hierarchical relationship to structure the knowledge,
    and finally, all prompts are chained together.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于分类法的知识结构链。这个过程需要领域特定的专业知识来构建或利用现有的结构化知识框架，例如分类法。为了构建基于分类法的提示，在每个提示（如提示1、2、3……）中，实体类型通过关系相连。在每个提示中，我们定义实体及其层级关系，以构建知识，最后将所有提示链接在一起。
- en: A key challenge of using LLMs as foundation models is that they can return false
    answers in situations where they are unsure how to respond to a query from a user,
    producing both “plausible-sounding and incorrect or nonsensical answers” [[70](https://arxiv.org/html/2406.10590v1#bib.bib70)].
    We address this issue by introducing *Taxonomy-based Knowledge Structure Chain*,
    which is a framework for designing a chain of prompts. Typically, a prompt consists
    of two parts - a template and a set of label words [[19](https://arxiv.org/html/2406.10590v1#bib.bib19)].
    Taxonomies, as relational systems, efficiently organize knowledge by logically
    interconnecting entities, representing relationships [[53](https://arxiv.org/html/2406.10590v1#bib.bib53)].
    While prompting LLMs only rely on plain sentences, taxonomies excel in generating
    precise keywords, thereby enhancing the relevance and accuracy of LLM responses.
    This method organizes prompts to align with the taxonomy’s structure using label
    words, enhancing the relevance and accuracy of LLM responses.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大型语言模型（LLMs）作为基础模型的一个关键挑战是，当它们不确定如何回应用户查询时，可能会返回错误的答案，产生“听起来合理但实际上错误或无意义的答案”[[70](https://arxiv.org/html/2406.10590v1#bib.bib70)]。我们通过引入*基于分类法的知识结构链*来解决这一问题，这是一种设计提示链的框架。通常，提示由两部分组成——一个模板和一组标签词[[19](https://arxiv.org/html/2406.10590v1#bib.bib19)]。分类法作为一种关系系统，通过逻辑地互联实体来高效地组织知识，表示关系[[53](https://arxiv.org/html/2406.10590v1#bib.bib53)]。虽然提示LLM仅依赖于简单的句子，但分类法擅长生成精确的关键词，从而提高LLM回应的相关性和准确性。这种方法通过使用标签词将提示与分类法的结构对齐，增强了LLM回应的相关性和准确性。
- en: 'We exemplify this approach using the TextileNet taxonomy [[108](https://arxiv.org/html/2406.10590v1#bib.bib108)].
    TextileNet’s hierarchy captures the relationships between general textile fibre
    categories, their subcategories, and specific fibre types, aiding in the creation
    of a *knowledge prompt*. For example, “cotton fibre” falls under “plant fibres”,
    which is a subset of “natural fibres”. This hierarchical organization of the taxonomy
    forms the basis of our *Taxonomy-based Knowledge Structure Chain*, systematically
    capturing the relationship (eg. subcategories, macro-types) among different entity
    types as illustrated in Figure [2](https://arxiv.org/html/2406.10590v1#S3.F2 "Figure
    2 ‣ 3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific
    Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用TextileNet分类法[[108](https://arxiv.org/html/2406.10590v1#bib.bib108)]来举例说明这一方法。TextileNet的层次结构捕捉了常见纺织纤维类别、其子类别和特定纤维类型之间的关系，帮助创建*知识提示*。例如，“棉花纤维”属于“植物纤维”，而植物纤维是“天然纤维”的一个子集。分类法的这种层次化组织构成了我们*基于分类法的知识结构链*的基础，系统地捕捉了不同实体类型之间的关系（例如子类别、宏观类型），如图[2](https://arxiv.org/html/2406.10590v1#S3.F2
    "Figure 2 ‣ 3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot")所示。'
- en: 'The dialogues in our user study demonstrate the effectiveness of this approach
    as illustrated in Figure [3](https://arxiv.org/html/2406.10590v1#S3.F3 "Figure
    3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣
    3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot"). Participants talked with three CAs: Vanilla
    GPT-3.5 model, TextileBot-Expert and TextileBot-Assistant. Both TextileBot-Expert
    and TextileBot-Assistant utilized a Taxonomy-based Knowledge Structure Chain,
    we discuss the main difference between them in Section [3.2](https://arxiv.org/html/2406.10590v1#S3.SS2
    "3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot"), but focus on how their domain expertise got improved.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的用户研究中的对话展示了这种方法的有效性，如图[3](https://arxiv.org/html/2406.10590v1#S3.F3 "Figure
    3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣
    3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")所示。参与者与三种对话代理（CA）进行了对话：Vanilla GPT-3.5模型、TextileBot-Expert和TextileBot-Assistant。TextileBot-Expert和TextileBot-Assistant都利用了基于分类法的知识结构链，我们在[3.2](https://arxiv.org/html/2406.10590v1#S3.SS2
    "3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot")节中讨论了它们之间的主要区别，但重点在于它们的领域专业知识是如何得到提升的。'
- en: 'In Figure [3](https://arxiv.org/html/2406.10590v1#S3.F3 "Figure 3 ‣ 3.2 Phase
    2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot"), “viscose” (a bio-derived fibre) was incorrectly categorized
    as a synthetic fibre and suggested as an unsustainable material by the Vanilla
    GPT-3.5 model. In contrast, our Taxonomy-bind approach, as shown through TextileBot
    Assistant and Expert, provides more accurate and contextually relevant information.
    For instance, TextileBot Expert accurately distinguishes between natural, synthetic,
    and regenerated fibres, demonstrating the LLM’s improved ability to recognize
    logical structures in taxonomy-based prompts. Our method significantly enhances
    the LLM’s capability to provide precise, consistent, and contextually relevant
    answers, particularly in the realms of fibres, textiles, and textile circularity.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [3](https://arxiv.org/html/2406.10590v1#S3.F3 "图 3 ‣ 3.2 第二阶段：通过提示优化从通用到领域特定
    ‣ 3 原型化领域特定语音代理 ‣ LLM 驱动的领域特定语音代理：以 TextileBot 为例") 中，“粘胶”（一种生物衍生纤维）被错误地归类为合成纤维，并被
    Vanilla GPT-3.5 模型建议为不可持续的材料。相比之下，我们的分类绑定方法，如通过 TextileBot 助理和专家所展示的，提供了更准确和与上下文相关的信息。例如，TextileBot
    专家能够准确区分天然、合成和再生纤维，展示了 LLM 在基于分类的提示中识别逻辑结构的能力有所提升。我们的方法显著增强了 LLM 提供精确、一致且具有上下文相关性的回答的能力，特别是在纤维、纺织品和纺织品循环领域。
- en: 'Taxonomy-based prompts provide “ground truth” when enhancing domain awareness
    for LLMs. This makes the entire conversation agent more robust when encountering
    errors from other components in the CA system pipeline, such as Automatic Speech
    Recognition (ASR). For instance, the term *‘viscous’* in Figure [3](https://arxiv.org/html/2406.10590v1#S3.F3
    "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") is a typical example of the errors that can arise
    from the ASR. By integrating taxonomy-based prompts within the CA pipeline, LLMs
    gain improved accuracy in understanding and responding to domain-specific content.
    This integration significantly mitigates ASR errors in conversation agents. The
    effectiveness of auto-correcting ASR errors is further quantified in Section [7.3.2](https://arxiv.org/html/2406.10590v1#S7.SS3.SSS2
    "7.3.2 Lessons Learned for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated
    voice agent design for specific domains ‣ 7 Discussion & Future Directions ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分类的提示在提升 LLM 的领域意识时提供了“事实依据”。这使得整个对话代理在遇到来自 CA 系统管道中其他组件（如自动语音识别（ASR））的错误时更加稳健。例如，图
    [3](https://arxiv.org/html/2406.10590v1#S3.F3 "图 3 ‣ 3.2 第二阶段：通过提示优化从通用到领域特定 ‣
    3 原型化领域特定语音代理 ‣ LLM 驱动的领域特定语音代理：以 TextileBot 为例") 中的 *‘粘性’* 术语是来自 ASR 的错误的典型例子。通过在
    CA 管道中整合基于分类的提示，LLM 在理解和响应领域特定内容时的准确性得到了提升。这种整合显著减轻了对话代理中的 ASR 错误。自动修正 ASR 错误的有效性在
    [7.3.2](https://arxiv.org/html/2406.10590v1#S7.SS3.SSS2 "7.3.2 设计 LLM 驱动的语音代理的经验教训
    ‣ 7 为特定领域优化 LLM 驱动的语音代理设计 ‣ 7 讨论与未来方向 ‣ LLM 驱动的领域特定语音代理：以 TextileBot 为例") 节中得到了进一步量化。
- en: '3.2 Phase 2: From General to Domain Specific through Prompt Refinements'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 第二阶段：通过提示优化从通用到领域特定
- en: '{mdframed}{dialogue}'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}{dialogue}'
- en: Setup Vanilla GPT-3.5 model
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 Vanilla GPT-3.5 模型
- en: Human Is viscose material sustainable? Agent Viscose is a type of synthetic
    fibre, and it is not considered sustainable. Instead, opt for natural fibres such
    as cotton, linen and hemp.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 人类：粘胶材料是否可持续？ 代理人：粘胶是一种合成纤维，且不被认为是可持续的。相反，应该选择天然纤维，如棉花、亚麻和大麻。
- en: Setup TextileBot Expert
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 TextileBot 专家
- en: Human Hi, so I need to know what kind of textile materials are most selling?
    Agent Hello! That is an interesting question. It really depends on what type of
    textile you are looking for and what your application is. Generally speaking,
    some of the most popular material types are natural fibres like cotton, wool,
    and silk; synthetic fibres like polyester and nylon; and regenerated fibres such
    as viscose and cupro. Knowing the properties of each of these materials is important
    in order to find the best one for your application. However, you should also consider
    textile circularity in your selection process. Textile circularity is a concept
    that ensures a closed-loop life cycle for textiles, from fibre sourcing to manufacturing
    to end-of-life. This approach is important for creating a sustainable solution
    for the textiles industry.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 人类 你好，我需要知道哪些纺织材料卖得最好？ 代理人 你好！这是一个有趣的问题。实际上，这取决于你在寻找哪种类型的纺织品，以及你的应用是什么。一般来说，一些最受欢迎的材料类型包括天然纤维，如棉花、羊毛和丝绸；合成纤维，如聚酯纤维和尼龙；以及再生纤维，如黏胶纤维和铜氨纤维。了解这些材料的特性非常重要，以便找到最适合你应用的材料。不过，在选择过程中，你还应该考虑纺织品的循环利用性。纺织品循环利用性是一个确保纺织品生命周期闭环的概念，从纤维来源到制造再到生命周期结束。这种方法对打造可持续的纺织品解决方案非常重要。
- en: Setup TextileBot Assistant
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 TextileBot 助手
- en: Human What is viscous? Agent Viscose is a type of regenerated cellulose fibre
    made from wood pulp or cotton linter. It is often used to make clothing, linens,
    bedding, towels and other fabrics that require a soft, silky handfeel.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 人类 什么是黏胶纤维？ 代理人 黏胶纤维是一种由木浆或棉短绒制成的再生纤维素纤维。它常用于制作服装、床上用品、毛巾以及其他需要柔软、丝滑触感的织物。
- en: 'Figure 3: Three prompt-based LLM-mediated agents (Vanilla GPT-3.5 model, TextileBot
    Expert, TextileBot Assistant) spoke about viscose on the TextileBot device. We
    highlighted the incorrect content in red, demonstrating that the vanilla model
    was indeed error-prone. Both TextileBot Expert and Assistant utilize the TextileNet
    taxonomy-based prompts (as explained in Section [3.1](https://arxiv.org/html/2406.10590v1#S3.SS1
    "3.1 Phase 1: Taxonomy-based Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific
    Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"))
    to improve accuracy. TextileBot Expert replies in more detail and is generally
    considered to be more ‘obsessed’ with this topic by our participants. We further
    explain this difference in Section [3.2](https://arxiv.org/html/2406.10590v1#S3.SS2
    "3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot").'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3：三种基于提示的 LLM 中介代理（Vanilla GPT-3.5 模型、TextileBot 专家、TextileBot 助手）讨论了黏胶纤维在
    TextileBot 设备上的应用。我们将错误内容用红色标出，展示了 Vanilla 模型确实容易出错。TextileBot 专家和助手都利用基于 TextileNet
    分类法的提示（如第 [3.1](https://arxiv.org/html/2406.10590v1#S3.SS1 "3.1 Phase 1: Taxonomy-based
    Knowledge Structure Chain ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot") 节所解释）来提高准确性。TextileBot
    专家的回复更为详细，通常被参与者认为在这个话题上更“执着”。我们在第 [3.2](https://arxiv.org/html/2406.10590v1#S3.SS2
    "3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot") 节进一步解释了这种差异。'
- en: '{mdframed}{dialogue}'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}{dialogue}'
- en: Setup Vanilla GPT-3.5 model
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 Vanilla GPT-3.5 模型
- en: Human So what would you recommend me to eat today because it’s almost lunchtime?
    Agent That depends on your dietary preferences. What kind of foods do you usually
    like to eat for lunch?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 人类 既然快到午餐时间了，你会推荐我今天吃些什么呢？ 代理人 这取决于你的饮食偏好。你通常喜欢吃什么类型的午餐？
- en: Setup TextileBot Expert
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 TextileBot 专家
- en: Human Well, I’m hungry. Um, what should I have for my lunch? Agent I’m sorry
    but I’m not the best person to help you with that. However, if you’re interested
    in learning more about textile and clothing materials, I’d be happy to help you!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 人类 嗯，我饿了。呃，我今天午餐应该吃点什么呢？ 代理人 对不起，我不是最适合帮助你解决这个问题的人。不过，如果你有兴趣了解更多关于纺织和服装材料的知识，我很乐意帮忙！
- en: Setup TextileBot Assistant
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 TextileBot 助手
- en: Human It’s almost lunchtime. What should I have for lunch today? Agent That
    sounds like an exciting decision! Are you looking for some textile-inspired lunch
    ideas? I know some great recipes for plant fiber-based noodles, vegan silk smoothies,
    and cottonseed salad bowls that are sure to satisfy your appetite!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 人类 快到午餐时间了。我今天该吃什么午餐呢？ 代理人 听起来这是一个令人兴奋的决定！你想要一些受到纺织启发的午餐创意吗？我知道一些很棒的食谱，比如植物纤维面条、素食丝绸冰沙和棉籽沙拉碗，保证能满足你的胃口！
- en: 'Figure 4: Three prompt-based LLM-mediated agents on the topic of lunch (Vanilla
    GPT-3.5 model, TextileBot Expert, TextileBot Assistant).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：三个基于提示的LLM中介代理，主题为午餐（香草GPT-3.5模型、TextileBot专家、TextileBot助手）。
- en: 'As the process of designing prompt templates is empirical, various ad-hoc prompt
    refinement techniques such as “Let’s think step by step” [[49](https://arxiv.org/html/2406.10590v1#bib.bib49)]
    have been employed in prompt design. However, there is yet no specific systematic
    approach for optimizing performance. To bridge this gap, we introduce a human-centred
    iterative prototyping process to personalize a desired CA. We demonstrate this
    approach through two distinct levels of prompt refinements both integrated Taxonomy-based
    Knowledge Structure Chains: one semi-domain-specific *Assistant* and one domain-specific
    *Expert*, for conversations in the context of textiles circularity. The process
    involves a series of prompt refinement steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设计提示模板的过程是经验性的，因此在提示设计中已经采用了各种临时的提示优化技巧，例如“让我们一步一步地思考”[[49](https://arxiv.org/html/2406.10590v1#bib.bib49)]。然而，至今还没有一种特定的系统性方法来优化性能。为了弥补这一空白，我们引入了一种以人为中心的迭代原型设计过程来个性化所需的CA。我们通过两种不同层次的提示优化来展示这一方法，这些优化都集成了基于分类法的知识结构链：一个是半领域特定的*助手*，另一个是领域特定的*专家*，用于在纺织品循环性背景下的对话。该过程包括一系列的提示优化步骤：
- en: $\blacksquare$
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Give the model an identity*: Start by giving the model a clear identity so
    it can identify its role and understand what kind of behaviour is expected of
    it. This helps to establish a consistent personality for the model’s responses.'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*给模型一个身份*：首先，给模型一个清晰的身份，以便它能识别自己的角色，并理解期望其表现出何种行为。这有助于建立模型回应的一致个性。'
- en: $\blacksquare$
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Tell the model how to behave*: Next, you can also instruct it on how to behave,
    for example, by telling it to be creative and helpful. These instructions help
    to further define the model’s personality with the desired tone.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*告诉模型如何表现*：接下来，你还可以指导模型如何表现，例如，告诉它要具有创造性并且乐于助人。这些指示有助于进一步定义模型的个性和所需的语气。'
- en: $\blacksquare$
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*“Let’s think step by step”* : Occasionally, GPTs fails on completing complex
    tasks [[3](https://arxiv.org/html/2406.10590v1#bib.bib3)]. To ensure the successful
    completion of the task, the model needs to be given clear instructions step-by-step
    to help it understand what is required. Break the complex tasks into simpler subtasks
    with a clear separation between each task. In addition, using the “Let’s think
    step by step” [[49](https://arxiv.org/html/2406.10590v1#bib.bib49)] trick in the
    prompt can help the model to think logically.'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*“让我们一步一步地思考”*：有时，GPT在完成复杂任务时会失败[[3](https://arxiv.org/html/2406.10590v1#bib.bib3)]。为了确保任务的成功完成，模型需要按步骤给出清晰的指示，帮助它理解所需的内容。将复杂的任务分解为更简单的子任务，并在每个任务之间清楚地区分。此外，在提示中使用“让我们一步一步地思考”[[49](https://arxiv.org/html/2406.10590v1#bib.bib49)]技巧，可以帮助模型进行逻辑思考。'
- en: $\blacksquare$
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Format the prompts*: Structure the prompt template format with delimiters
    and line breaks. This helps the model to disambiguate different sections and determine
    when the prompt ends and when it should start generating a response.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*格式化提示*：使用分隔符和换行符结构化提示模板格式。这有助于模型区分不同的部分，并确定何时提示结束以及何时开始生成响应。'
- en: $\blacksquare$
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: $\blacksquare$
- en: '*Fine-tune prompts*: Fine-tune it with the desired behaviour the model needs
    to take. This involves using plain language and a positive tone to instruct the
    model on how to perform specific tasks. For example, we might instruct the model
    to “provide a sustainable clothing suggestion regardless of gender.”'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*微调提示*：根据模型需要表现的行为对提示进行微调。这涉及使用简单的语言和积极的语气来指导模型如何执行特定任务。例如，我们可能会指示模型“提供无论性别如何的可持续服装建议”。'
- en: 'These refinement techniques can be utilized individually or in combination,
    depending on the specific task. For a comprehensive demonstration of the strategy
    in practice, we provide a complete prompt template for Expert and Assistant, combining
    all these refinements, in the Appendix SectionLABEL:sec:apd:prompt, showcasing
    various combinations. Table [1](https://arxiv.org/html/2406.10590v1#S3.T1 "Table
    1 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣
    3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") highlights the prompts used in the template.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '这些优化技巧可以单独使用，也可以组合使用，具体取决于任务的要求。为了全面展示该策略在实践中的应用，我们在附录部分LABEL:sec:apd:prompt中提供了专家和助手的完整提示模板，结合了所有这些优化，展示了不同的组合。表格[1](https://arxiv.org/html/2406.10590v1#S3.T1
    "Table 1 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")突出显示了模板中使用的提示。'
- en: 'Table 1: Prompts used for three agents’ role and response manner. The conversational
    freedom is predefined as the design guideline for prompt template.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：用于三个代理角色和回应方式的提示。对话自由度作为提示模板设计的预定义指南。
- en: '|  | Prompts used for characteristic | Response manner | Conversational freedom
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | 用于特征的提示 | 回应方式 | 对话自由度 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Vanilla | N/A | N/A | non-goal oriented |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 普通 | 无 | 无 | 非目标导向 |'
- en: '| Assistant |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 助手 |'
- en: '&#124; A helpful, creative, clever, and very friendly AI assistant, &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 一位有帮助、富有创意、聪明且非常友好的人工智能助手，&#124;'
- en: '&#124; specialized in textile circularity. &#124;'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 专注于纺织品循环 &#124;'
- en: '| Conscious in response | semi-domain-specific |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 对回应保持意识 | 半领域特定 |'
- en: '| Expert |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 专家 |'
- en: '&#124; A textile circularity expert, response query around the concept of &#124;'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纺织品循环领域专家，围绕该概念回应查询 &#124;'
- en: '&#124; textile circularity and guide the conversation towards textile circularity
    &#124;'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 纺织品循环性并引导对话走向纺织品循环性 &#124;'
- en: '| In a detailed manner | domain-specific |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 以详细方式回应 | 领域特定 |'
- en: '*Expert* is designed to promote the idea of textile circularity and facilitate
    discussions on the topic. The Expert excels in providing detailed information
    on textiles and textile circularity, often including additional information. In
    Expert mode, as a domain-specific Ca, control the degree of freedom in the topic
    becomes the fundamental step. To achieve this, we *limit the conversation breadth
    of the model* by instructing it with the following prompt. We show the effectiveness
    of this in Appendix Section LABEL:sec:apd:prompt showing that participants failed
    to ”jail break” the prompt.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*专家*旨在促进纺织品循环性的理念，并推动这一话题的讨论。专家擅长提供有关纺织品及其循环性的详细信息，通常会包含额外的资料。在专家模式下，作为领域特定的Ca，控制话题自由度成为基本步骤。为此，我们通过以下提示来*限制模型的对话广度*。我们在附录部分LABEL:sec:apd:prompt中展示了这一方法的有效性，证明参与者未能“突破”这一提示。'
- en: On the other hand, *Assistant* is designed to engage in broader conversations
    and can act as an intermediary between non-goal-oriented conversation (task-agnostic)
    [[92](https://arxiv.org/html/2406.10590v1#bib.bib92)] and domain-specific conversation.
    We increase the breadth of topics and freedom of conversation in Assistant mode.
    For instance, the Assistant can provide suggestions on various scenarios such
    as dining or dressing, and even tell jokes without losing its focus on textiles.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*助手*旨在进行更广泛的对话，并可以充当非目标导向对话（任务无关）[[92](https://arxiv.org/html/2406.10590v1#bib.bib92)]和领域特定对话之间的中介。我们在助手模式下增加了话题的广度和对话的自由度。例如，助手可以提供有关不同场景的建议，如就餐或穿衣，甚至可以讲笑话，同时不失其对纺织品的关注。
- en: 'To better understand the distinctions between these agents, Figure [3](https://arxiv.org/html/2406.10590v1#S3.F3
    "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") demonstrates how Expert is more “obsessed” with
    textile circularity compared to the Assistant. Figures [4](https://arxiv.org/html/2406.10590v1#S3.F4
    "Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") provide an example from our user study, which
    shows different participants having real conversations regarding providing a lunch
    idea. The Vanilla model typically engages in free conversations in such cases,
    while the Expert refuses to engage unless it senses the topic is related to textiles.
    On the other hand, Assistant provides a textile-favoured lunch suggestion, thereby
    preserving the domain-specific feature while still allowing for open conversations.
    The Vanilla, Expert and Assistant agents show distinguishable response styles
    as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些代理之间的区别，图 [3](https://arxiv.org/html/2406.10590v1#S3.F3 "图3 ‣ 3.2 阶段2：通过提示优化从通用到特定领域
    ‣ 3 领域特定语音代理的原型设计 ‣ LLM介导的领域特定语音代理：以TextileBot为例") 展示了与助手相比，专家在纺织品循环性方面更为“专注”。图
    [4](https://arxiv.org/html/2406.10590v1#S3.F4 "图4 ‣ 3.2 阶段2：通过提示优化从通用到特定领域 ‣ 3
    领域特定语音代理的原型设计 ‣ LLM介导的领域特定语音代理：以TextileBot为例") 提供了我们用户研究中的一个例子，展示了不同参与者就提供午餐建议进行真实对话的场景。Vanilla模型通常在这种情况下进行自由对话，而专家除非感知到话题与纺织品相关，否则拒绝参与。另一方面，助手提供了一个偏向纺织的午餐建议，从而在允许开放对话的同时，保持了特定领域的特点。Vanilla、专家和助手代理显示出不同的响应风格，如下所示：
- en: •
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Vanilla: This agent is non-goal-oriented and represents the pre-trained LLM
    in its original form. This showcases using LLMs directly as conversational agents
    without any prompts.'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Vanilla：该代理是非目标导向的，代表了经过预训练的LLM的原始形式。展示了直接使用LLM作为对话代理，而没有任何提示的情况。
- en: •
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Expert: Positioned as a goal-oriented (domain specific) voice agent, it embodies
    a domain expert, with a focus on specialized knowledge, but limited in making
    social conversations. The Expert excels in providing detailed explanations, often
    including additional information.'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 专家：定位为目标导向（特定领域）语音代理，体现了领域专家的形象，专注于专业知识，但在进行社交对话时有所局限。专家擅长提供详细的解释，通常包括额外的信息。
- en: •
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Assistant: This agent is semi-goal-oriented, positioned as a helpful and friendly
    assistant that is able to conduct some degree of social conversation but still
    with goal in mind, conscious of the target domain when answering questions.'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 助手：该代理是半目标导向的，定位为一个有帮助且友好的助手，能够进行一定程度的社交对话，但仍然保持目标意识，在回答问题时意识到目标领域。
- en: '3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization'
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 阶段 3：通过系统优化启用具有记忆功能的连续大语言模型（LLM）交互
- en: '{mdframed}{dialogue}'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}{dialogue}'
- en: Human Which materials make the concept of textile circularity difficult to implement?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 人类 哪些材料使得纺织品循环性难以实现？
- en: agent Synthetic fibres and blended fabrics, … textile circularity difficult
    to implement. Human Repeat. agent The main challenges to the implementation of
    textile circularity include the lack of a clear regulatory framework, lack of
    investment and financial incentives, lack of understanding or awareness, and difficulty
    in measuring impacts. Human Please repeat my last question. agent Which materials
    make the concept of textile circularity difficult to implement? Human What was
    your last response? agent Synthetic fibres and blended fabrics, … textile circularity
    difficult to implement. Human Repeat your last response. agent Synthetic fibres
    and blended fabrics, … textile circularity difficult to implement.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 代理 合成纤维和混纺面料，使得纺织品循环性难以实现。 人类 请重复我上一个问题。 代理 哪些材料使得纺织品循环性难以实现？ 人类 你上次的回答是什么？
    代理 合成纤维和混纺面料，使得纺织品循环性难以实现。 人类 重复你的上一个回答。 代理 合成纤维和混纺面料，使得纺织品循环性难以实现。
- en: 'Figure 5: Transcript history for TextileBot Assistant. In Figure [3](https://arxiv.org/html/2406.10590v1#S3.F3
    "Figure 3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot") and [4](https://arxiv.org/html/2406.10590v1#S3.F4
    "Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot"), we both take the unmodified transcript history
    to demonstrate the agents’ capabilities. Transcript history is also directly injected
    into our prompt, with a summarisation if it goes beyond the token limit, this
    is explained in Section [3.3](https://arxiv.org/html/2406.10590v1#S3.SS3 "3.3
    Phase 3: Enable continuous LLM interaction with memory through System Optimization
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot"). This transcript demonstrates the agent’s statefulness
    in conversation, eg. its ability to recall and refer back to previously asked
    questions.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '图5：TextileBot助手的对话历史。在图[3](https://arxiv.org/html/2406.10590v1#S3.F3 "Figure
    3 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements ‣
    3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")和[4](https://arxiv.org/html/2406.10590v1#S3.F4
    "Figure 4 ‣ 3.2 Phase 2: From General to Domain Specific through Prompt Refinements
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")中，我们都使用未经修改的对话历史来展示代理的能力。对话历史也会直接注入到我们的提示中，如果超出了令牌限制，则会进行摘要，这将在第[3.3](https://arxiv.org/html/2406.10590v1#S3.SS3
    "3.3 Phase 3: Enable continuous LLM interaction with memory through System Optimization
    ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")节中解释。该对话历史展示了代理在对话中的状态性，例如它能够回忆并参考先前提问过的问题。'
- en: Previous sections discussed how our prompt design helps the model identify its
    task. In this section, we first introduce some challenges using LLMs directly
    as CAs to conduct continuous conversation, and then provide corresponding System
    Optimization for these challenges.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前面几节讨论了我们的提示设计如何帮助模型识别任务。在本节中，我们首先介绍了直接使用大型语言模型（LLMs）作为对话代理（CAs）进行连续对话时面临的一些挑战，然后为这些挑战提供相应的系统优化方案。
- en: '1.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'LLM capabilities depend on context: LLMs are sensitive to input prompts. Minor
    alterations to the prompt can result in significant differences in the model’s
    prediction [[63](https://arxiv.org/html/2406.10590v1#bib.bib63), [14](https://arxiv.org/html/2406.10590v1#bib.bib14)].
    They may exhibit a preference for specific prompt formats, paraphrases, or particular
    information contained in the input [[6](https://arxiv.org/html/2406.10590v1#bib.bib6),
    [39](https://arxiv.org/html/2406.10590v1#bib.bib39)]. For instance, the *”Let’s
    think step by step”* trick [[49](https://arxiv.org/html/2406.10590v1#bib.bib49)]
    reveals that using particular prompts can largely level up model’s overall performance.
    Additionally, nouns and verbs tend to carry more weight than adjectives and function
    words [[103](https://arxiv.org/html/2406.10590v1#bib.bib103), [68](https://arxiv.org/html/2406.10590v1#bib.bib68)].
    In short, the quality of response will be altered by the context.'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: LLM的能力取决于上下文：LLMs对输入的提示非常敏感。提示的微小改动可能会导致模型预测结果的显著差异[[63](https://arxiv.org/html/2406.10590v1#bib.bib63),
    [14](https://arxiv.org/html/2406.10590v1#bib.bib14)]。它们可能对特定的提示格式、同义表达或输入中包含的特定信息表现出偏好[[6](https://arxiv.org/html/2406.10590v1#bib.bib6),
    [39](https://arxiv.org/html/2406.10590v1#bib.bib39)]。例如，*“让我们一步步来思考”*这一技巧[[49](https://arxiv.org/html/2406.10590v1#bib.bib49)]表明，使用特定的提示可以显著提升模型的整体表现。此外，名词和动词往往比形容词和功能词更具重要性[[103](https://arxiv.org/html/2406.10590v1#bib.bib103),
    [68](https://arxiv.org/html/2406.10590v1#bib.bib68)]。简而言之，响应的质量将会受到上下文的影响。
- en: '2.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Transformer-based LLMs are memory-less: Transformer-based LLMs do not have
    an explicit memory of their previous outputs, including ChatGPT [[70](https://arxiv.org/html/2406.10590v1#bib.bib70)].'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于Transformer的大型语言模型是无记忆的：基于Transformer的大型语言模型没有明确的记忆功能，无法记住其之前的输出，包括ChatGPT[[70](https://arxiv.org/html/2406.10590v1#bib.bib70)]。
- en: 'Although raw LLMs are usually memory-less, their ability to *learn in context*
    provides us with a way to enable them to remember previous conversations. This
    is done by *incorporating past human input and model output pairs* into the prompt
    in a clear format (as shown in Figure [6](https://arxiv.org/html/2406.10590v1#S4.F6
    "Figure 6 ‣ 4 The Case of TextileBot: Design and Implementation ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")) and allowing the model
    to use its capacity for learning in context to build a “Dialogue Memory” that
    is constantly updated with each interaction round between the human and the model.
    This ensures the model remains up-to-date with conversations, thus providing it
    with a form of memory that would otherwise not be possible. Interestingly, from
    the transcripts in Figure [5](https://arxiv.org/html/2406.10590v1#S3.F5 "Figure
    5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System
    Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot"), we can observe that when using simple
    terms such as “repeat”, the model can repeat certain parts of the conversation;
    however, it requires *clear prompts* in order to understand what exactly should
    be repeated.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原始的LLM通常是无记忆的，但它们的*上下文学习*能力为我们提供了一种方法，可以让它们记住之前的对话。这是通过*将过去的人类输入和模型输出对*以清晰的格式（如图[6](https://arxiv.org/html/2406.10590v1#S4.F6
    "图 6 ‣ 4 TextileBot案例：设计与实现 ‣ LLM驱动的特定领域语音代理：TextileBot案例")）嵌入到提示中来实现的，并允许模型利用其上下文学习的能力来构建一个“对话记忆”，这个记忆会随着每轮人与模型之间的互动而不断更新。这确保了模型始终保持与对话的同步，从而为它提供了一种本来无法实现的记忆形式。有趣的是，从图[5](https://arxiv.org/html/2406.10590v1#S3.F5
    "图 5 ‣ 3.3 第三阶段：通过系统优化启用持续的LLM互动与记忆 ‣ 3 特定领域语音代理原型 ‣ LLM驱动的特定领域语音代理：TextileBot案例")中的记录中，我们可以观察到，当使用诸如“重复”之类的简单词汇时，模型能够重复对话的某些部分；然而，它需要*清晰的提示*才能理解具体应该重复什么内容。
- en: 'Since the transcript history is constantly being updated, the issue of the
    token limit arises, which can lead to a system crash if we exceed this limit.
    To tackle this, System Optimization have used a token counter to keep track of
    the total token count in our prompt. Once the overall text length reaches almost
    $3000$ tokens (roughly equivalent to $9000$ characters), we use the text-davinci-003
    model as a summarizer (Figure [5](https://arxiv.org/html/2406.10590v1#S3.F5 "Figure
    5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through System
    Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")) to summarize transcripts between the user
    and the model. The summarized text is then combined with other more recent dialogues
    to make up the Dialogue Memory, this memory is pure text and is then added to
    the initial CA prompt that we have generated from Phase 1 and 2, in this way,
    we enable multi-turn interaction to continue.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于转录历史记录不断更新，令牌限制的问题随之而来，如果超过此限制，可能导致系统崩溃。为了解决这个问题，系统优化使用了令牌计数器来跟踪提示中的总令牌数。一旦整体文本长度接近$3000$个令牌（大约相当于$9000$个字符），我们使用text-davinci-003模型作为摘要器（图[5](https://arxiv.org/html/2406.10590v1#S3.F5
    "图 5 ‣ 3.3 第三阶段：通过系统优化启用持续的LLM互动与记忆 ‣ 3 特定领域语音代理原型 ‣ LLM驱动的特定领域语音代理：TextileBot案例")）来总结用户和模型之间的对话。然后，将摘要后的文本与其他较新的对话合并，构成对话记忆，这个记忆是纯文本的，然后被添加到我们在第一和第二阶段生成的初始CA提示中，从而使得多轮互动得以继续进行。
- en: '4 The Case of TextileBot: Design and Implementation'
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 TextileBot案例：设计与实现
- en: '![Refer to caption](img/72f3f7ab91e7d272e3ef839310281c5d.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/72f3f7ab91e7d272e3ef839310281c5d.png)'
- en: 'Figure 6: System optimization (phase 3) with integrated memory. This optimization
    includes a token counter for monitoring the dialogue length. Once the token limit
    is reached, an automatic summarizer is triggered to condense the past dialogue.
    The CA prompt is pre-set always at the start, where these past-dialogue are inserted
    after it, to maintain the CA’s functionality.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：集成记忆的系统优化（第三阶段）。此优化包括一个令牌计数器，用于监控对话的长度。一旦达到令牌限制，自动摘要器将被触发，以浓缩过去的对话。CA提示始终预设在开始时，并且这些过去的对话会被插入到它之后，以保持CA的功能。
- en: 'In this section, we provide our prompt-based conversational voice agents’ software
    and hardware designs. Notably, our system design exhibits great adaptability.
    The design building blocks (illustrated in Figure [7](https://arxiv.org/html/2406.10590v1#S4.F7
    "Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of
    TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")) can be seamlessly integrated with various platforms
    and input/output methods. These include smart devices, smartphones, computers,
    VR interfaces, and diverse user input/output methods. The TextileBot voice interface,
    featured in this study, serves as an exemplary implementation of our domain-specific
    prompt-based voice agent approach within the context of textile circularity. We
    built a device with a voice interface for several reasons. Firstly, in line with
    the current textile circularity agenda, a key objective is to raise consumers’
    awareness and engagement with this concept [[75](https://arxiv.org/html/2406.10590v1#bib.bib75),
    [83](https://arxiv.org/html/2406.10590v1#bib.bib83)]. Utilizing physical artifacts
    to enhance user engagement has been a significant pursuit in human-agent interaction
    [[69](https://arxiv.org/html/2406.10590v1#bib.bib69)], and our TextileBot aims
    to facilitate consumer engagement in retail settings, we regard a real device
    with voice-based interactions as pivotal in our approach. Secondly, it is well-established
    that people employ distinct language styles when speaking compared to writing,
    as articulated in the literature [[81](https://arxiv.org/html/2406.10590v1#bib.bib81)].
    To our knowledge, no prior research has delved into natural spoken dialogue with
    LLMs, leaving a substantial gap in understanding how humans perceive and interact
    with prompt LLM-based voice agents. Finally, a voice interface can create better
    accessibility for users.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们提供了基于提示的对话语音代理的软件和硬件设计。特别地，我们的系统设计展示了极大的适应性。设计构建块（如图[7](https://arxiv.org/html/2406.10590v1#S4.F7
    "Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of
    TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")所示）可以与各种平台和输入/输出方式无缝集成。这些包括智能设备、智能手机、计算机、VR接口以及多种用户输入/输出方式。本研究中展示的TextileBot语音接口，作为我们基于领域的提示式语音代理方法的典型实现，聚焦于纺织品循环利用的背景。我们构建了一个带语音接口的设备，原因有几个。首先，符合当前纺织品循环利用议程的核心目标之一是提高消费者对这一概念的认知和参与[[75](https://arxiv.org/html/2406.10590v1#bib.bib75),
    [83](https://arxiv.org/html/2406.10590v1#bib.bib83)]。利用物理产品来增强用户参与感，一直是人机交互中的一个重要目标[[69](https://arxiv.org/html/2406.10590v1#bib.bib69)]，而我们的TextileBot旨在促进零售环境中的消费者参与，因此我们认为配备语音交互的实际设备是我们方法中的关键。其次，文献中明确指出，与写作相比，人们在说话时使用不同的语言风格[[81](https://arxiv.org/html/2406.10590v1#bib.bib81)]。据我们所知，之前的研究尚未深入探讨与LLM进行自然语音对话的问题，这在理解人类如何感知和与基于提示的LLM语音代理互动方面留下了一个重要空白。最后，语音接口可以为用户创造更好的可访问性。'
- en: 4.1 Software System Design - Multi-Model Stitching
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 软件系统设计 - 多模型拼接
- en: 'The TextileBot software system stitches together three models - an Automated
    Speech Recognition (ASR) model, a Large language model (LLM) and a Text-to-Speech
    (TTS) model. We explain each of them in detail in the following subsections, and
    an overview of this system is in Figure [7](https://arxiv.org/html/2406.10590v1#S4.F7
    "Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of
    TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot").'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 'TextileBot的软件系统将三个模型拼接在一起——自动语音识别（ASR）模型、大型语言模型（LLM）和文本转语音（TTS）模型。我们将在以下小节中详细解释每个模型，系统的概述见图[7](https://arxiv.org/html/2406.10590v1#S4.F7
    "Figure 7 ‣ 4.1 Software System Design - Multi-Model Stitching ‣ 4 The Case of
    TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")。'
- en: '![Refer to caption](img/af131b974c0e1e740ea5559ec87ac45c.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明文字](img/af131b974c0e1e740ea5559ec87ac45c.png)'
- en: 'Figure 7: Software System Design for TextileBot - Multi-Model Stitching. For
    the complete CA design, we utilized an ASR model, a LLM and a TTS model. It is
    worth mentioning that our ASR model is Whisper, deep learning based ASR model.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：TextileBot的软件系统设计 - 多模型拼接。对于完整的CA设计，我们利用了ASR模型、LLM和TTS模型。值得一提的是，我们的ASR模型是Whisper，这是一个基于深度学习的ASR模型。
- en: 4.1.1 Automatic Speech Recognition (ASR)
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 自动语音识别（ASR）
- en: We tested two speech recognition models, Google speech-to-text and OpenAI’s
    Whisper [[78](https://arxiv.org/html/2406.10590v1#bib.bib78)] Application Programming
    Interface (API), in our TextileBot design. Initially, we used Google’s API, which
    is popular, but we experienced unexpected latency issues on our Raspberry Pi device
    due to heavy preprocessing on recorded audio files. To evaluate latency, we randomly
    sampled recording lengths between $1$ to $60$ seconds and recorded $100$ speech
    samples to simulate natural dialogue. Google ASR had an average latency of $28.93$
    seconds on these samples. In a pilot study with four participants (including one
    native English speaker), two non-native English speakers, we found that participants
    had to speak slowly and repeat their words when using Google ASR.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在TextileBot设计中测试了两种语音识别模型，Google语音转文本和OpenAI的Whisper[[78](https://arxiv.org/html/2406.10590v1#bib.bib78)]应用程序接口（API）。最初，我们使用了Google的API，它是一个广泛使用的API，但由于在录制音频文件上进行了大量的预处理，我们在Raspberry
    Pi设备上遇到了意外的延迟问题。为了评估延迟，我们随机采样了$1$到$60$秒之间的录音长度，并录制了$100$个语音样本来模拟自然对话。在这些样本上，Google
    ASR的平均延迟为$28.93$秒。在一项涉及四名参与者（包括一名英语母语者和两名非英语母语者）的试点研究中，我们发现参与者在使用Google ASR时必须放慢语速并重复他们的话。
- en: We chose OpenAI’s Whisper as our ASR due to its faster latency and robustness
    in recognition [[77](https://arxiv.org/html/2406.10590v1#bib.bib77)]. While we
    did not conduct a thorough accuracy comparison study between the two APIs, and
    to our knowledge, no related literature compares them as Whisper was officially
    released in March 2023, we observed that Whisper recognized most non-native English-speaking
    participants significantly better. Conversely, with Google speech-to-text ASR,
    key terms in our dialogue such as ”textile circularity” were consistently recognized
    as ”textile security” or even ”Texas a Coronavirus”.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了OpenAI的Whisper作为我们的语音识别（ASR）系统，因其具有更快的延迟和更强的识别鲁棒性[[77](https://arxiv.org/html/2406.10590v1#bib.bib77)]。虽然我们没有对这两个API进行详细的准确性对比研究，且据我们所知，目前没有相关文献进行对比，因为Whisper是在2023年3月正式发布的，但我们观察到，Whisper在识别大多数非英语母语参与者时显著更好。相反，使用Google语音转文本的ASR时，我们的对话中的关键术语，如“textile
    circularity”（纺织品循环性），经常被识别为“textile security”（纺织品安全）或甚至“Texas a Coronavirus”（德克萨斯州冠状病毒）。
- en: 4.1.2 Language model as foundation model
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 语言模型作为基础模型
- en: In our study, we chose GPT-3.5 (text-davinci-003) API which was known for its
    outstanding performance and trained with the largest parameters at the time of
    testing. Currently, there is a lot of discussion within the community about the
    differences between OpenAI’s GPT models, including GPT-3, GPT-3.5, ChatGPT, and
    the newly released GPT-4. Our work focuses on the pre-trained OpenAI GPT model⁴⁴4OpenAI’s
    GPT-3 is a pre-trained LLM with 175 billion parameters [[14](https://arxiv.org/html/2406.10590v1#bib.bib14)]
    rather than any other published sources or third-party models trained from scratch.
    One drawback of LLMs is the generation of plausible-sounding but incorrect or
    nonsensical responses [[70](https://arxiv.org/html/2406.10590v1#bib.bib70)]. To
    address this issue, LLMs like InstructGPT and ChatGPT have incorporated human
    efforts using Reinforcement Learning from Human Feedback (RLHF), resulting in
    fewer false responses and less toxicity [[72](https://arxiv.org/html/2406.10590v1#bib.bib72)].
    Although ChatGPT’s advanced language processing capabilities allow it to engage
    in natural, human-like conversations with users, it has a tendency to be verbose
    due to biases in the training data. Trainers in the RLHF prefer longer answers
    that appear more comprehensive [[87](https://arxiv.org/html/2406.10590v1#bib.bib87),
    [34](https://arxiv.org/html/2406.10590v1#bib.bib34)].
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们选择了GPT-3.5（text-davinci-003）API，它以出色的性能而闻名，并且在测试时具有最大的参数量。目前，关于OpenAI的GPT模型之间的差异，包括GPT-3、GPT-3.5、ChatGPT以及新发布的GPT-4，社区中有很多讨论。我们的工作侧重于预训练的OpenAI
    GPT模型⁴⁴OpenAI的GPT-3是一个具有1750亿个参数的预训练大型语言模型[[14](https://arxiv.org/html/2406.10590v1#bib.bib14)]，而不是任何其他已发布的来源或从零开始训练的第三方模型。LLM的一个缺点是它可能生成看似合理但实际上不正确或无意义的回答[[70](https://arxiv.org/html/2406.10590v1#bib.bib70)]。为了解决这个问题，像InstructGPT和ChatGPT这样的LLM通过使用来自人类反馈的强化学习（RLHF）来融入人类的努力，从而减少错误回答和降低毒性[[72](https://arxiv.org/html/2406.10590v1#bib.bib72)]。虽然ChatGPT的先进语言处理能力使其能够与用户进行自然的类人对话，但由于训练数据中的偏见，它有时会倾向于冗长的回答。RLHF的训练者更倾向于更长的回答，因为它们看起来更全面[[87](https://arxiv.org/html/2406.10590v1#bib.bib87),
    [34](https://arxiv.org/html/2406.10590v1#bib.bib34)]。
- en: We cannot determine the parameters used in the RLHF for ChatGPT, limiting our
    freedom in using these LLMs. Furthermore, the long-text style response of ChatGPT
    is unsuitable for voice interfaces. In contrast, GPT-3 and GPT-3.5 are more “organic”
    and provide more freedom in designing arbitrary prompts, making them useful for
    customizable content generation and language translation. Therefore, we focus
    on exploiting these large foundation models directly, such as GPT-3.5, for controlled,
    high-quality content generation instead of using the patched ChatGPT.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法确定用于 ChatGPT 的 RLHF 参数，这限制了我们使用这些大型语言模型的自由度。此外，ChatGPT 的长文本风格回答不适合语音接口。相比之下，GPT-3
    和 GPT-3.5 更加“自然”，并且在设计任意提示时提供更多自由度，使它们在可定制内容生成和语言翻译方面非常有用。因此，我们专注于直接利用这些大型基础模型，如
    GPT-3.5，进行受控的高质量内容生成，而不是使用修补版的 ChatGPT。
- en: At the time of writing this paper, OpenAI had just announced GPT-4 - an enhanced
    language model with improved mathematical abilities and the capacity to take visual
    inputs. However, it can be difficult to distinguish GPT-3.5 from GPT-4 in a casual
    conversation, as noted on GPT-4’s website. Interestingly, OpenAI has also reported
    that there is almost no improvement in generating factual content when questions
    related to environmental science are posed [[71](https://arxiv.org/html/2406.10590v1#bib.bib71)].
    In this paper, our focus is on designing a domain-specific conversation agent
    related to textile circularity, a key topic in material and environmental science.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文撰写时，OpenAI 刚刚宣布了 GPT-4——一款增强型语言模型，具备改进的数学能力和接受视觉输入的能力。然而，正如 GPT-4 网站上所提到的，在日常对话中很难区分
    GPT-3.5 和 GPT-4。有趣的是，OpenAI 还报告称，当涉及到环境科学相关问题时，生成事实性内容几乎没有任何改进 [[71](https://arxiv.org/html/2406.10590v1#bib.bib71)]。在本文中，我们的重点是设计一个与纺织循环利用相关的领域特定对话代理，这是材料科学和环境科学中的一个关键话题。
- en: 4.1.3 Text-to-speech
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 语音合成
- en: 'We use the gTTS (Google Text-to-Speech) library in Python to read out text
    with a female British English voice. However, we received feedback during the
    pilot study that the speech speed felt slow for natural conversation. To address
    this issue, we will discuss our solution in Section [4.2](https://arxiv.org/html/2406.10590v1#S4.SS2
    "4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The Case of TextileBot:
    Design and Implementation ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot").'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Python 中的 gTTS（Google 文字转语音）库，通过一位英国女性英语声音朗读文本。然而，在试点研究期间，我们收到反馈称语音速度对于自然对话来说显得较慢。为了解决这个问题，我们将在第
    [4.2](https://arxiv.org/html/2406.10590v1#S4.SS2 "4.2 硬件系统设计：TextileBot 语音设备 ‣
    4 TextileBot 的案例：设计与实施 ‣ 基于 LLM 的领域特定语音代理：TextileBot 案例") 节中讨论我们的解决方案。
- en: '4.2 Hardware System Design: The TextileBot Voice Device'
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 硬件系统设计：TextileBot 语音设备
- en: '![Refer to caption](img/96591e68e50d242951e2d77e822c8045.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![请参考标题](img/96591e68e50d242951e2d77e822c8045.png)'
- en: (a) The physical TextileBot interface.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 物理版 TextileBot 接口。
- en: '![Refer to caption](img/7b71c80417ddb49a985bb3e95fc80cd4.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![请参考标题](img/7b71c80417ddb49a985bb3e95fc80cd4.png)'
- en: (b) A participant interacts with the TextileBot.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 一位参与者与 TextileBot 互动。
- en: 'Figure 8: Left: TextileBot - The physical agent interface is composed of a
    3D printed box (6), a speaker (5), a microphone (4), and a button (3), all integrated
    into the Google AIY board (2) mounted on the Raspberry Pi 3 Model B (1) presented
    in (a). Right: A participant interacting with the TextileBot used across all three
    voice-based agents (b).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：左图：TextileBot——物理代理接口由一个 3D 打印的盒子（6）、一个扬声器（5）、一个麦克风（4）和一个按钮（3）组成，所有组件集成在安装于树莓派
    3 型 B（1）上的 Google AIY 板（2）中，如（a）图所示。右图：一位参与者与 TextileBot 互动，该代理用于所有三种基于语音的代理（b）。
- en: 'We built the hardware device around a Raspberry Pi device. The device is housed
    in a 3D printed box (6), which includes a speaker (5), a microphone (4), and a
    button (3), all integrated on the AIY board (2) mounted on the Raspberry Pi 3B
    (1) as shown in Figure [8(a)](https://arxiv.org/html/2406.10590v1#S4.F8.sf1 "In
    Figure 8 ‣ 4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The Case
    of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot"). The hardware system includes a Raspberry Pi
    3B with a Quad Core 1.2GHz Broadcom BCM2837 64bit CPU and 1GB RAM (1). We use
    the Voice HAT configuration [[1](https://arxiv.org/html/2406.10590v1#bib.bib1)],
    which contains a Voice AIY accessory board (2) that provides physical connectivity
    from the GPIO pins and is mounted on the Raspberry Pi 3 board. The Voice HAT set
    also provides us with an arcade-style button with an LED light (3), a microphone
    board with the 5-wire daughter board cable (4) and a microphone (5).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们围绕树莓派设备构建了硬件设备。该设备被安置在一个3D打印的盒子里（6），其中包括一个扬声器（5）、一个麦克风（4）和一个按钮（3），所有这些都集成在安装在树莓派3B（1）上的AIY板（2）中，如图[8(a)](https://arxiv.org/html/2406.10590v1#S4.F8.sf1
    "图8 ‣ 4.2 硬件系统设计：纺织机器人语音设备 ‣ 4 纺织机器人案例：设计与实现 ‣ 基于大语言模型的领域特定语音代理：纺织机器人案例")所示。硬件系统包括一款搭载1GB
    RAM的树莓派3B，配备四核1.2GHz的Broadcom BCM2837 64位CPU（1）。我们使用了Voice HAT配置[[1](https://arxiv.org/html/2406.10590v1#bib.bib1)]，其中包含一个Voice
    AIY附加板（2），该板提供了GPIO引脚的物理连接，并安装在树莓派3板上。Voice HAT套件还为我们提供了一个带LED灯的街机风格按钮（3）、带5线子板电缆的麦克风板（4）和一个麦克风（5）。
- en: The housing was created from an open source CAD model in the Thingiverse model
    library. It was 3D printed on a Prusa I3 MK3S+ using the readily available polylactic
    acid (PLA) material. The front facing side contains holes to allow sound from
    the speaker to leave the enclosure, while the inside contains various shelves
    for the control electronics to be mounted to. The top of the box has a hole for
    the activation button. The firmware to control this hardware was designed by Google
    and deeply integrated with the Google Assistant service ⁵⁵5The Google AIY has
    stopped updating their service, and the repository has been archived by the owner
    on Feb 9, 2023 [[2](https://arxiv.org/html/2406.10590v1#bib.bib2)]. [[2](https://arxiv.org/html/2406.10590v1#bib.bib2),
    [35](https://arxiv.org/html/2406.10590v1#bib.bib35)]. However, this did not meet
    our needs, so we conducted the development of our own firmware code that enables
    flexible audio recording, audio playback and push button control.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 外壳是从Thingiverse模型库中的开源CAD模型创建的。它在Prusa I3 MK3S+上使用现成的聚乳酸（PLA）材料进行3D打印。前面板上有孔洞，以允许扬声器的声音从外壳中传出，而内部则有多个架子用于安装控制电子设备。盒子的顶部有一个孔用于安装激活按钮。控制这些硬件的固件由Google设计，并与Google助手服务深度集成⁵⁵5Google
    AIY已经停止更新其服务，并且该仓库已于2023年2月9日被所有者归档[[2](https://arxiv.org/html/2406.10590v1#bib.bib2)]。[[2](https://arxiv.org/html/2406.10590v1#bib.bib2),
    [35](https://arxiv.org/html/2406.10590v1#bib.bib35)]。然而，这并没有满足我们的需求，因此我们自行开发了固件代码，支持灵活的音频录制、音频播放和按钮控制。
- en: Users interface with TextileBot via a button with an LED light. A predefined
    user guide is played when the device is booted. To speak to the TextileBot, users
    press and then release the button, and do it again when they finish their sentence.
    The LED light will be lit while recording and playing audio. We use mpg123 library
    with command “mpg123 -d 4 -h 3” to manually speed up the playback rate to $1.33\times$.
    This is because participants in our pilot studies have reported the original speaking
    speed from gTTS is too slow.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通过带LED灯的按钮与纺织机器人进行交互。设备启动时会播放预定义的用户指南。用户按下按钮然后松开按钮后就可以与纺织机器人进行对话，完成一句话后再按一次按钮。录音和播放音频时，LED灯会亮起。我们使用mpg123库并通过命令“mpg123
    -d 4 -h 3”手动加快播放速度至$1.33\times$。这是因为我们的试点研究参与者反馈，gTTS的原始语速太慢。
- en: 5 Evaluation of TextileBot
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 纺织机器人评估
- en: In the user study, we aimed (1) to evaluate whether our prompt strategy remained
    effective while preserving domain specificity across various spoken dialogues,
    and to assess if interactions with three variations of TextileBot differed significantly—indicating
    that users perceived each as a distinct entity and validating phase 2 of our approach,
    (2) to investigate if TextileBot could retain memory and conduct continuous conversations
    as designed in phase 3, and (3) to explore the nature of user interactions with
    each bot variant to understand the nuances of user engagement. As the language
    used in spoken dialogue is different from written text [[81](https://arxiv.org/html/2406.10590v1#bib.bib81)],
    an in-person study was chosen to allow participants to interact with the TextileBot
    smart device and evoke natural language conversations. We used a mixed-method
    approach, combining traditional machine learning ablation study analysis with
    HIC analysis - questionnaires and qualitative feedback from participants with
    a conversational analysis of the human-agent dialogue. We recruited a total of
    30 participants to interact with each of the three voice agents on textiles and
    textile circularity, as outlined in the Introduction. In the following sections,
    we first describe the within-subject study design, measures, and procedure.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户研究中，我们的目标是：（1）评估我们的提示策略是否在不同的口语对话中保持有效，并且在保持领域特异性的同时，评估与三种不同版本的 TextileBot
    的互动是否存在显著差异——这表明用户将每个代理视为一个独立的实体，从而验证我们方法的第二阶段；（2）调查 TextileBot 是否能够像设计中那样保留记忆并进行持续对话，这一部分属于第三阶段的内容；（3）探索用户与每个机器人变体的互动特征，以理解用户参与的细微差别。由于口语对话中使用的语言与书面文本不同[[81](https://arxiv.org/html/2406.10590v1#bib.bib81)]，我们选择了面对面的研究方式，允许参与者与
    TextileBot 智能设备互动并引发自然语言对话。我们采用了混合方法，结合了传统的机器学习消融研究分析与 HIC 分析——包括问卷调查和参与者的定性反馈，以及对人机对话的会话分析。我们招募了30名参与者，与三种不同的语音代理就纺织及纺织循环性进行互动，如介绍部分所述。在接下来的章节中，我们将首先描述组内研究设计、测量方法和程序。
- en: 5.1 Study design and methods
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 研究设计与方法
- en: 'We utilized a mixed within/between-subjects design, where each of the participants
    ($N=30$) was asked to speak with the three CAs (Vanilla, Assistant, Expert) embodied
    in the same smart device TextileBots. The order in which participants interacted
    with each of the agents was randomised to avoid order effects. For each agent
    interaction, participants followed the same four phases: Free chatting, Information
    gathering, Questionnaires, and Overall user feedback. Each of the four phases
    is detailed below:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了混合的组内/组间设计，每位参与者（$N=30$）都被要求与同一智能设备 TextileBots 中体现的三种 CAs（Vanilla, Assistant,
    Expert）进行对话。参与者与每个代理的互动顺序是随机的，以避免顺序效应。每次代理互动都包含四个阶段：自由聊天、信息收集、问卷调查和总体用户反馈。以下是每个阶段的详细说明：
- en: Phase 1 - Free chatting
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第一阶段 - 自由聊天
- en: The human-agent interaction started with an open conversation with no topical
    restrictions. Participants could freely engage with the agents on any topic of
    their choice. This approach was designed to facilitate a broad exploration of
    potential conversation topics relevant to textiles contexts and to gain insights
    into the personality and characteristics of three conversational agents. A minimum
    of 5 minutes to a maximum of 10 minutes was allocated to this phase. Free exploration
    is particularly beneficial for domains that have not yet implemented conversational
    agents, such as textile circularity. Engaging in freeform conversations during
    the prototyping phase provides valuable insights into user needs and the scope
    of topic coverage required in these domains.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 人机互动从一个开放式对话开始，没有话题限制。参与者可以自由选择任何话题与代理进行交流。这种方法旨在广泛探索与纺织相关的潜在对话主题，并深入了解三种对话代理的个性和特征。此阶段分配了至少5分钟，最多10分钟的时间。自由探索尤其有益于尚未实现对话代理的领域，比如纺织循环性。在原型阶段进行自由形式的对话，有助于获得用户需求的宝贵见解，并了解这些领域所需的主题覆盖范围。
- en: Phase 2 - Information gathering
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第二阶段 - 信息收集
- en: To ensure consistency in the topics discussed, the second part focused on textile
    circularity, the main conversational topic that has guided the TextileBot implementations.
    In collaboration with domain experts in materials science and textile circularity,
    we developed ten information gathering tasks for participants. To ensure a structured
    approach, we arranged these tasks in a progression from general to specific, transitioning
    from high-level concepts to more detailed aspects. Subsequently, we divided the
    tasks into three distinct groups, and applied the three TextileBots to these groups
    in a round-robin fashion [[33](https://arxiv.org/html/2406.10590v1#bib.bib33)]
    to ensure coverage of different task-agent combinations.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保讨论主题的一致性，第二部分聚焦于纺织循环性，这是指导TextileBot实现的主要对话主题。在与材料科学和纺织循环领域的专家合作下，我们为参与者设计了十个信息收集任务。为了确保有条理地进行，我们将这些任务按从一般到具体的顺序安排，从高层次概念过渡到更具体的方面。随后，我们将任务分为三组，并以循环方式
    [[33](https://arxiv.org/html/2406.10590v1#bib.bib33)] 将这三种TextileBot应用于这些任务组，以确保涵盖不同的任务-代理组合。
- en: 'Table 2: Questionnaire used after each of the three TextileBots to assess the
    human-bot interaction experience.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 2：在每次与三种TextileBot互动后用于评估人机互动体验的问卷。
- en: '| Evaluation Category | Metric | Question type |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 评估类别 | 指标 | 问题类型 |'
- en: '| --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Usability | Ease to use | 5 likert scale |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 可用性 | 使用难易度 | 5 分制 |'
- en: '| Engagement | E-I: Interest in responses | 5 likert scale |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 参与度 | E-I: 对回应的兴趣 | 5 分制 |'
- en: '| E-E: Engagement in conversation | 5 likert scale |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| E-E: 对话中的参与度 | 5 分制 |'
- en: '| E-W: Willingness to use in the future | 5 likert scale |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| E-W: 未来使用意愿 | 5 分制 |'
- en: '| Coherence | C-I: Input comprehensibility | 5 likert scale |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 一致性 | C-I: 输入可理解性 | 5 分制 |'
- en: '| C-C: Clarity in responses | 5 likert scale |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| C-C: 回应的清晰度 | 5 分制 |'
- en: '| C-A: Accuracy in responses | 5 likert scale |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| C-A: 回应的准确性 | 5 分制 |'
- en: '| Changes over time | The level of engagement over time | Multiple-choice:
    Increase, Decrease, Dynamic |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 随时间变化 | 随时间变化的参与度水平 | 多选：增加，减少，动态 |'
- en: '| Follow-up on changes over time | Open-ended question to capture the reason
    |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 对随时间变化的跟进 | 开放性问题以捕捉原因 |'
- en: Phase 3 - Questionnaire
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第三阶段 - 问卷调查
- en: 'We developed a questionnaire that contains an evaluation matrix to assess the
    human-LLM agent interaction. The evaluation matrix employs a wide range of existing
    metrics, combining metrics from conventional heuristics-based conversational agents,
    for both non goal-oriented/task-agnostic and domain-specific/goal-oriented agents
    [[51](https://arxiv.org/html/2406.10590v1#bib.bib51), [86](https://arxiv.org/html/2406.10590v1#bib.bib86),
    [65](https://arxiv.org/html/2406.10590v1#bib.bib65), [92](https://arxiv.org/html/2406.10590v1#bib.bib92)].
    We also incorporated human-LM interaction metrics [[55](https://arxiv.org/html/2406.10590v1#bib.bib55),
    [99](https://arxiv.org/html/2406.10590v1#bib.bib99)]. Since our study involves
    three TextileBots, we treated each as a separate model and employed the pairwise
    per-dialogue (PW-dialogue) method [[86](https://arxiv.org/html/2406.10590v1#bib.bib86)]
    to evaluate the human-LLM interaction. This method compares two entire conversations
    with two different agents, and has been shown to outperform evaluations of single
    models. Each participant was asked to conduct three conversations with the three
    different TextileBots. Table [2](https://arxiv.org/html/2406.10590v1#S5.T2 "Table
    2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods ‣ 5 Evaluation
    of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    summarises the key focus of the questionnaire, the metrics used and the question
    types.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '我们开发了一份包含评估矩阵的问卷，用于评估人类与大语言模型（LLM）代理的互动。该评估矩阵采用了广泛的现有指标，结合了传统启发式对话代理的指标，适用于非目标导向/任务不可知的代理以及领域特定/目标导向的代理
    [[51](https://arxiv.org/html/2406.10590v1#bib.bib51)，[86](https://arxiv.org/html/2406.10590v1#bib.bib86)，[65](https://arxiv.org/html/2406.10590v1#bib.bib65)，[92](https://arxiv.org/html/2406.10590v1#bib.bib92)]。我们还结合了人类与语言模型（LM）互动的相关指标
    [[55](https://arxiv.org/html/2406.10590v1#bib.bib55)，[99](https://arxiv.org/html/2406.10590v1#bib.bib99)]。由于我们的研究涉及三种TextileBot，我们将每种视为独立的模型，并采用逐对每对对话（PW-dialogue）方法
    [[86](https://arxiv.org/html/2406.10590v1#bib.bib86)] 来评估人类与LLM的互动。此方法比较两个不同代理的完整对话，已证明在评估单一模型时更为有效。每个参与者需要与这三种不同的TextileBot进行三次对话。表格[2](https://arxiv.org/html/2406.10590v1#S5.T2
    "Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods ‣ 5
    Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")总结了问卷的重点内容、所使用的指标以及问题类型。'
- en: Phase 4 - Overall user feedback
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第4阶段 - 整体用户反馈
- en: 'At the end of the study, we collected participants overall feedback on their
    experience with the TextileBots, capturing participants’ subjective experiences
    engaging with the voice agents, their preferences, observations about the interaction
    and changes over time, as well as any suggestions for improvements and insights
    they gained on the domain-specific conversation. Please see an overview of the
    focus and question types in Table [3](https://arxiv.org/html/2406.10590v1#S5.T3
    "Table 3 ‣ Phase 4 - Overall user feedback ‣ 5.1 Study design and methods ‣ 5
    Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot").'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究结束时，我们收集了参与者对与纺织品机器人互动体验的整体反馈，捕捉参与者与语音助手的主观体验、偏好、互动观察及随时间变化的反馈，以及任何改进建议和他们在领域特定对话中获得的洞见。请参见表格
    [3](https://arxiv.org/html/2406.10590v1#S5.T3 "表3 ‣ 第4阶段 - 整体用户反馈 ‣ 5.1 研究设计与方法
    ‣ 5 纺织品机器人评估 ‣ 基于大型语言模型的领域特定语音助手：纺织品机器人案例")。
- en: 'Table 3: Overall user feedback and participants preferences between the three
    TextileBots, captured at the end of the study.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 3：研究结束时收集的关于三种纺织品机器人整体用户反馈和参与者偏好。
- en: '| Feedback category | Question type |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 反馈类别 | 问题类型 |'
- en: '| --- | --- |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Overall feedback on each of the TextileBots | Open-ended questions |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 关于每个纺织品机器人的整体反馈 | 开放性问题 |'
- en: '| Preference between the three TextileBot | Ranking and open-ended questions
    |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 三种纺织品机器人之间的偏好 | 排名和开放性问题 |'
- en: '| Experience of the TextileBots interaction, changes over time | Open-ended
    question |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 纺织品机器人互动体验，随时间变化 | 开放性问题 |'
- en: '| Suggestions on TextileBot | Open-ended questions |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 关于纺织品机器人的建议 | 开放性问题 |'
- en: '| Understanding of the domain (textiles circularity) | 5 likert scale and open-ended
    questions |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 领域理解（纺织品循环性） | 5级李克特量表和开放性问题 |'
- en: 5.2 Study setup and procedure
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 研究设置与程序
- en: 'The study was conducted in a controlled laboratory environment, with each participant
    attending individually in-person. Participants were briefed with instructions
    to imagine a scenario wherein they were talking with three distinct voice agents
    (each with different personalities and capabilities) in a retail environment,
    such as a clothing store. A TextileBot device was placed was positioned on a table
    in front of a participant, allowing them to control it (see Figure [8(b)](https://arxiv.org/html/2406.10590v1#S4.F8.sf2
    "In Figure 8 ‣ 4.2 Hardware System Design: The TextileBot Voice Device ‣ 4 The
    Case of TextileBot: Design and Implementation ‣ LLM-Mediated Domain-Specific Voice
    Agents: The Case of TextileBot")). The tasks involved identifying and ranking
    their preferred agent based on its suitability for use in a retail environment
    as TextileBot, and their subject experience to the overall user feedback. Every
    interaction session began with an introduction from the respective agent (Vanilla,
    Expert and Assistant):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 该研究在一个受控的实验室环境中进行，每位参与者单独亲自参加。参与者被告知要设想一个情境，在该情境中，他们正在与三位具有不同个性和能力的语音助手交谈，场景设定为零售环境，如服装店。纺织品机器人设备被放置在参与者面前的桌子上，允许他们进行控制（见图
    [8(b)](https://arxiv.org/html/2406.10590v1#S4.F8.sf2 "图8 ‣ 4.2 硬件系统设计：纺织品机器人语音设备
    ‣ 4 纺织品机器人案例：设计与实现 ‣ 基于大型语言模型的领域特定语音助手：纺织品机器人案例")）。任务内容包括根据其在零售环境中作为纺织品机器人使用的适宜性识别和排名参与者偏好的语音助手，并评估他们的整体用户反馈体验。每次互动环节都以相应的语音助手（原味、专家和助手）的介绍开始：
- en: '"Hi there, I’m TextileBot. I’m here to assist you with any questions or discussions
    you may have regarding textiles. To speak with me, simply click the button and
    start talking. When you’re finished, click the button again to let me know that
    you’re done. How can I assist you today?"'
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"你好，我是纺织品机器人。我在这里帮助你解答有关纺织品的任何问题或进行讨论。与我交谈，只需点击按钮并开始说话。当你完成后，再次点击按钮让我知道你已经结束。今天有什么我可以帮助你的吗？"'
- en: 'After the agent’s welcome message, participants were given 5-10 minutes to
    interact freely with the TextileBot, choosing their own conversational topics
    (Phase 1). When satisfied with the interaction or the time limit was reached,
    participants proceeded to the information gathering phase (Phase 2). Upon completion
    of both phases, participants were then asked to fill out a questionnaire to assess
    their experience with that particular agent (Phase 3). This three-phase procedure
    was repeated for all three TextileBots. Participants were also offered the opportunity
    to extend their interaction with any TextileBot of their choice or all of them,
    if they prefer, before proceeding to Phase 4\. Once all interaction sessions were
    completed, participants were asked to provide final overall feedback (Phase 4)
    on their experience using the voice-based TextileBots, as outlined in Section
    [5.1](https://arxiv.org/html/2406.10590v1#S5.SS1 "5.1 Study design and methods
    ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot").'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '在代理的欢迎消息之后，参与者有5到10分钟的时间与纺织机器人自由互动，选择自己的对话主题（第一阶段）。当他们对互动感到满意或时间结束时，参与者进入信息收集阶段（第二阶段）。完成这两个阶段后，参与者被要求填写问卷，以评估他们与该特定代理的互动体验（第三阶段）。这个三阶段程序会对所有三个纺织机器人进行重复。参与者还可以选择在进入第四阶段之前，延长与任何一个纺织机器人或所有纺织机器人的互动时间。所有互动会话完成后，参与者将被要求提供最终的总体反馈（第四阶段），以分享他们使用基于语音的纺织机器人的体验，详见[5.1](https://arxiv.org/html/2406.10590v1#S5.SS1
    "5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")节。'
- en: 5.3 Analysis approach
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 分析方法
- en: Our primary focus is to explore the efficient development of LLM-based voice
    CAs that are domain-specific and offer personalized interactions that is capable
    of conducting continuous (multi-turn) conversations. We started by analyzing questionnaire
    responses with each agent to understand each vHAI (Vallina, Expert and Assistant).
    Following this, we conducted a qualitative analysis of the overall user feedback
    to gain insights into participants’ overall perceptions of three agents. The evaluation
    also examines the effectiveness of our approach.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要目标是探索基于大型语言模型（LLM）的语音虚拟助手（CAs）的高效开发，这些助手是特定领域的并提供个性化的互动，能够进行持续的（多轮）对话。我们首先通过分析每个代理的问卷回答，了解每个虚拟助手（vHAI，分别为普通型、专家型和助手型）。接着，我们进行了对整体用户反馈的定性分析，以获得参与者对三种代理的总体看法。评估还检查了我们方法的有效性。
- en: In addition, a key aspect of our research is exploring how people perceive and
    engage with different prompted LLM-based CAs. Hence, as a first step in the analysis,
    the dialogue contents were stored in a text format and imported into NVivo 14,
    a qualitative analysis software. A dialogue refers to a whole recorded exchange
    of conversation between a participant and a CA [[89](https://arxiv.org/html/2406.10590v1#bib.bib89)].
    We then applied a data-driven inductive thematic analysis approach to identify
    recurring themes and patterns within the dialogue transcripts and to gain qualitative
    insights into the vHAI.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们研究的一个关键方面是探索人们如何感知并与不同的LLM驱动的虚拟助手互动。因此，作为分析的第一步，所有对话内容都以文本格式存储并导入到NVivo
    14（一款定性分析软件）。对话指的是参与者与虚拟助手之间的完整记录交流[[89](https://arxiv.org/html/2406.10590v1#bib.bib89)]。随后，我们应用基于数据驱动的归纳主题分析方法，从对话记录中识别出反复出现的主题和模式，以便从定性角度获得对虚拟助手的见解。
- en: 'The first author applied an open-coding approach to the dialogues, and created
    a first coding scheme that was discussed and refined with the co-authors. After
    several discussions and iterations, all authors reached the consensus that the
    vHAI can’t be easily shoehorned into a set of themes. However, it was agreed that
    the changes in the interaction patterns over time should be further explored to
    understand variations in the dialogue and participant behaviours. Hence, we decided
    to employ a combined inductive/deductive hybrid approach focused on:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 第一作者采用开放编码方法对对话进行编码，并创建了初步编码方案，这一方案与共同作者进行了讨论和完善。经过多次讨论和迭代，所有作者达成共识，即虚拟助手（vHAI）无法轻易地被归类为一组主题。然而，大家一致同意应该进一步探讨互动模式随时间的变化，以理解对话和参与者行为的变化。因此，我们决定采用结合归纳与演绎的混合方法，专注于：
- en: '1.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: An analysis of the dialogues based on conversational turns,
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于对话回合的对话分析，
- en: '2.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: An analysis of the conversational styles,
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对对话风格的分析，
- en: '3.'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: An analysis of the human behaviour in the interaction with the TextileBots.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对与纺织机器人（TextileBots）互动中的人类行为进行分析。
- en: 'In Section [6.3](https://arxiv.org/html/2406.10590v1#S6.SS3 "6.3 Dialogue analysis
    of the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot"), we present the results for each of those
    three points, starting from the “conversational turns” and “turn-taking patterns”
    observed within and across the three voice agents. We then further explored differences
    between single vs. multi-turn conversations and calculated the number of words
    used by participants in each turn, as a possible indicator for their engagement
    over time and across the agents. This dialogue analysis was extended with a deep
    dive into the conversational styles enriched and exemplified with representative
    quotes from participants’ interaction with the agents, and a particular emphasis
    on the changes over time, drawing on existing language concepts such as code-switching
    and social protocols. We conclude with a reflection on specific human behaviours
    and strategies when engaging with the three different agents. All taken together
    form a rich, multi-faceted foundation for our discussion on the effectiveness
    of our approach and how humans perceive, interact, and engage with prompt-based
    voice agents.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '在[6.3节](https://arxiv.org/html/2406.10590v1#S6.SS3 "6.3 Dialogue analysis of
    the voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")中，我们展示了这三点的研究结果，首先从“对话回合”和“回合交替模式”开始，分析了三个语音代理之间以及它们之间的对话回合。然后，我们进一步探索了单回合与多回合对话之间的差异，并计算了参与者在每个回合中使用的单词数量，作为衡量他们随时间和不同代理交互时的参与度的可能指标。对话分析进一步深入，探讨了对话风格，并通过参与者与代理的互动中的代表性引用加以阐释，特别强调了随时间的变化，借助现有的语言概念，如语言转换和社交协议。最后，我们对人类在与这三种不同代理交互时的特定行为和策略进行了反思。所有这些内容共同构成了我们讨论我们方法的有效性及人类如何感知、互动和与基于提示的语音代理互动的丰富多维基础。'
- en: All participants quotes are included with original spelling and emphasis.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者的引用都保留了原始拼写和强调部分。
- en: 5.4 Participants
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 参与者
- en: We recruited 30 participants aged between 22 to 44 years of age (mean age =
    30, SD = 5.33), out of which fourteen were male, sixteen female. Participants
    had a diverse range of backgrounds, including computer scientists, UX designers,
    artists, healthcare consultants, researchers, university lecturers, and university
    students. All participants were either native English speakers or highly proficient
    in English. Furthermore, the participants came from 15 countries across five continents.
    The study was approved by the local University Research Ethics Committee . All
    participants provided written informed consent before taking part in the study.
    The study lasted between 45 to 60 minutes, and all participants were compensated
    with a gift voucher for their time.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们招募了30名年龄在22至44岁之间的参与者（平均年龄 = 30，标准差 = 5.33），其中十四名为男性，十六名为女性。参与者的背景多样，包括计算机科学家、用户体验设计师、艺术家、医疗顾问、研究人员、大学讲师和大学生。所有参与者均为母语为英语或英语流利者。此外，参与者来自五大洲的15个国家。该研究已获得本地大学研究伦理委员会的批准。所有参与者在参与研究前都提供了书面知情同意书。研究持续了45至60分钟，所有参与者根据参与时间获得了礼品券作为补偿。
- en: 6 Results
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结果
- en: 'We present our findings in three main sections: analysis of questionnaire responses
    (Section [6.1](https://arxiv.org/html/2406.10590v1#S6.SS1 "6.1 Questionnaire results
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")),
    overall participant feedback (Section [6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")), and dialogue data from our user study (Section [6.4](https://arxiv.org/html/2406.10590v1#S6.SS4
    "6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")). The questionnaire responses and dialogue data explore
    whether participants perceived three variations of TextileBot as distinct entities
    and their engagement with each prompted version. Additionally, these sections
    assess whether TextileBot maintained memory and facilitated continuous conversations.
    Together, these results provide insights into the nuances of user engagement with
    different LLM-powered voice agents.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在三个主要部分中展示我们的研究结果：问卷反馈分析（第[6.1](https://arxiv.org/html/2406.10590v1#S6.SS1
    "6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")节）、整体参与者反馈（第[6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")节）、以及我们用户研究中的对话数据（第[6.4](https://arxiv.org/html/2406.10590v1#S6.SS4
    "6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")节）。问卷反馈和对话数据探讨了参与者是否将三种不同版本的TextileBot视为独立的实体，以及他们与每个版本的互动情况。此外，这些部分评估了TextileBot是否保持记忆并促进了持续的对话。综合来看，这些结果为不同LLM驱动的语音助手在用户参与中的细微差别提供了洞察。'
- en: 6.1 Questionnaire results
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 问卷结果
- en: 'To determine if participants perceived three variations of TextileBot as distinct
    entities, we analyzed questionnaire data from our study. We obtained a total of
    120 questionnaires, 90 from the interaction sessions (three per participant, for
    each agent they tried), and 30 from the overall user feedback. This section mainly
    discusses the results we have with respect to an analysis using the metrics in
    Table [2](https://arxiv.org/html/2406.10590v1#S5.T2 "Table 2 ‣ Phase 2 - Information
    gathering ‣ 5.1 Study design and methods ‣ 5 Evaluation of TextileBot ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"). We also aimed to understand
    participants’ perceptions of voice agents when presented with different prompts.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '为了确定参与者是否将三种不同版本的TextileBot视为独立的实体，我们分析了研究中的问卷数据。我们总共收集了120份问卷，其中90份来自互动环节（每个参与者提供三份问卷，针对他们尝试的每个助手版本），30份来自整体用户反馈。本节主要讨论我们根据[表2](https://arxiv.org/html/2406.10590v1#S5.T2
    "Table 2 ‣ Phase 2 - Information gathering ‣ 5.1 Study design and methods ‣ 5
    Evaluation of TextileBot ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")中所列指标进行分析的结果。我们还旨在了解参与者在面对不同提示时对语音助手的感知。'
- en: Engagement and coherence metrics
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 参与度和一致性指标
- en: 'We first obtained participants’ scores for both Engagement and Coherence metrics,
    averaged them, and presented them in a radar plot (Figure [9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")). All responses
    were coded from $1$ to $5$; all averages fell in the range between $3$ and $4.5$.
    Figure [9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1 "In Figure 9 ‣ Cross-metrics
    interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot") shows the questionnaire’s overall results
    regarding the evaluation of engagement and coherence. The results in Figure [9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") demonstrate
    that Assistant is generally the best across all these evaluation metrics.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先获得了参与者在参与度和一致性这两个指标上的评分，计算出平均值，并将其展示在雷达图中（图[9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")）。所有的评分都在$1$到$5$之间；所有平均值都在$3$到$4.5$之间。图[9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")展示了问卷关于参与度和一致性的总体结果。图[9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")中的结果表明，Assistant在所有这些评估指标中通常表现最好。'
- en: Cross-metrics interactions
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 跨指标互动
- en: 'We then used mixed cumulative link regression models with participants and
    interaction topics/questions as random effects. This allowed us to account for
    the nested nature of the experimental design [[50](https://arxiv.org/html/2406.10590v1#bib.bib50)]
    and the ordinal characteristics of the survey’s responses [[109](https://arxiv.org/html/2406.10590v1#bib.bib109)].
    Data was analysed using the “ordinal” package in R [[20](https://arxiv.org/html/2406.10590v1#bib.bib20)].
    No difference was found when comparing models on their Ease of use and Coherence
    (C-I, C-C, C-A) metrics. As we have also seen in Figure [9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"), the variations
    in C-I, C-C and C-A are relatively small, we turn the focus of the analysis to
    the remaining Engagement metrics (E-I, E-E and E-W).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后使用了混合累积链接回归模型，将参与者和互动话题/问题作为随机效应。这使我们能够考虑到实验设计的嵌套性质[[50](https://arxiv.org/html/2406.10590v1#bib.bib50)]以及调查响应的序数特征[[109](https://arxiv.org/html/2406.10590v1#bib.bib109)]。数据使用R中的“ordinal”包进行分析[[20](https://arxiv.org/html/2406.10590v1#bib.bib20)]。在比较模型的易用性和一致性（C-I，C-C，C-A）指标时未发现差异。正如我们在图[9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "在图9 ‣ 跨指标交互 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ LLM驱动的领域特定语音代理：以TextileBot为例")中所看到的，C-I，C-C和C-A的变化相对较小，因此我们将分析重点转向其余的参与度指标（E-I，E-E和E-W）。
- en: '![Refer to caption](img/f6d57c7a2813e891ae9d620aaf949b79.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题](img/f6d57c7a2813e891ae9d620aaf949b79.png)'
- en: (a) Engagement and Coherence metrics.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: （a）参与度和一致性指标。
- en: '![Refer to caption](img/00416404e37b252bbd62c0045cf30e38.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题](img/00416404e37b252bbd62c0045cf30e38.png)'
- en: (b) Participant preference ranking.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: （b）参与者偏好排名。
- en: 'Figure 9: Left: this includes Interestingness in responses (Engagement, E-I),
    Engagement in conversations (Engagement, E-E) and Willingness to use in the future
    (Engagement, E-W), Input comprehensibility (Coherence, C-I), Clarity in responses
    (Coherence, C-C), Accuracy in responses (Coherence, C-A). Right: Participant preference
    ranking of the three TextileBots in light of textile circularity.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：左侧：包括响应的趣味性（参与度，E-I），对话中的参与度（参与度，E-E）和未来的使用意愿（参与度，E-W），输入可理解性（一致性，C-I），响应的清晰度（一致性，C-C），响应的准确性（一致性，C-A）。右侧：参与者根据纺织品循环性的考虑，对三种TextileBot的偏好排名。
- en: 'As depicted in Figure [9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "In Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"), the TextileBot
    Assistant was found consistently more engaging at the single response than its
    Expert and Vanilla counterparts (E-I), although results were not statistically
    significant (“marginally” significant $p=0.06$). This pattern did not emerge at
    the conversation level (E-E), where both Vanilla and Assistant were slightly (but
    consistently across participants) more engaging than the Expert agent ($p=0.2$).
    Still, on the Engagement dimension (E-W), participants reported that they would
    be significantly more likely to interact with the TextileBot assistant than with
    both alternative versions in the future ($p<0.05$, post-hoc tests, Bonferroni
    corrected).'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1 "在图9 ‣ 跨指标交互 ‣ 6.1 问卷结果
    ‣ 6 结果 ‣ LLM驱动的领域特定语音代理：以TextileBot为例")所示，TextileBot助手在单次响应中表现出比其专家和基础版对手更具参与感（E-I），尽管结果在统计上并不显著（“边缘”显著
    $p=0.06$）。这一模式在对话层面（E-E）未出现，其中基础版和助手比专家代理稍微（但在参与者中一致）更具参与感（$p=0.2$）。然而，在参与度维度（E-W）上，参与者报告称，他们未来与TextileBot助手互动的可能性显著高于与两种替代版本的互动（$p<0.05$，事后检验，Bonferroni校正）。
- en: Ease to use and Interest change over time
  id: totrans-208
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 易用性和兴趣随时间变化
- en: Overall, the ease of use was rated from 2 to 5 with an average score of 4. Regarding
    the change in interest levels over time, 83.8% of the sessions showed that there
    is a variation in interest levels. 53.8% reported an increase, 20% reported a
    decrease, 10% were dynamic. The rest reported no change. Participants emphasized
    the significant influence of response content on their level of interest. For
    example, P5 pointed out that their interest “depended on the specific question
    and corresponding answers”. Similar statements were echoed by P18 and P28, who
    noted that their interest heightened when the agent delivered intriguing responses.
    The other factor is the length of the response. Both P15 and P16 expressed annoyance
    due to the vast, long-winded response from Expert. As P15 put it, ”It sometimes
    provided too much information which made me lose interest somewhat”. P16 went
    into further detail, stating, ”Sometimes the responses were a bit long. The information
    provided was interesting, but the agent essentially answered my question within
    the first few seconds and then kept talking.” However, not all participants were
    thrilled with shorter responses. P17 commented on Vanilla as “It was too brief
    with little prompt but it remembers previous questions and provided context based
    answers”.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，易用性得分在2到5之间，平均得分为4。关于兴趣水平随时间变化的情况，83.8%的会话显示出兴趣水平的变化。53.8%的人表示兴趣增加，20%的人表示兴趣下降，10%的人表示兴趣动态变化，其余人则表示没有变化。参与者强调回应内容对他们兴趣水平的重大影响。例如，P5指出，他们的兴趣“取决于具体问题和相应的回答”。类似的说法也出现在P18和P28的反馈中，他们提到，当代理人提供引人入胜的回答时，他们的兴趣会增加。另一个影响因素是回答的长度。P15和P16都表示对专家的冗长回答感到不满。正如P15所说，“有时提供了太多信息，这让我有些失去兴趣”。P16进一步详细说明，“有时回答有点长，虽然提供的信息很有趣，但代理人实际上在前几秒钟就回答了我的问题，接着继续讲。”然而，并非所有参与者都喜欢简短的回答。P17对Vanilla的评论是“它太简短，提示很少，但它记得之前的问题并提供了基于上下文的回答”。
- en: 6.2 Overall feedback
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 整体反馈
- en: In this section, we present the overall user feedback on the participants’ subjective
    experiences with the agents, their preferences, feedback on how they perceived
    the interactions over time and any suggestions for improvements.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们呈现了参与者对代理人主观体验的整体用户反馈，包括他们的偏好、对交互过程的感知以及任何改进建议。
- en: 'Overall, participants enjoyed the interaction because “it felt really natural”
    (P7) and “The levels of answers were good throughout but I really liked the memory
    function and the agent answers were not generic, especially compared to my other
    voice agent experiences” (P13). Nevertheless, a number of participants (N=4) perceived
    the interaction to be a one-way question-answering rather than conversation and
    expected the voice agent to engage in a more dialogic interaction by asking questions:
    “I wish it engaged in conversation as well, asking questions back more, so you
    feel more engaged as well…” (P14). Participants (N=5) suggested that the voice
    agents would benefit from adopting “emotion embedded” and “more interesting” responses
    to achieve a human-like “real conversation”. Participants mentioned that they
    would prefer “less formal”, “less persuasive” voice agent with “a bit of humour”
    and “shorter answer”, in order to facilitate ”more engaging interactions”.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，参与者喜欢这种互动，因为“感觉真的很自然”（P7），并且“回答的水平一直很好，但我特别喜欢记忆功能，代理人的回答不笼统，尤其是与我其他语音代理的体验相比”（P13）。然而，一些参与者（N=4）认为互动更像是单向的问答而非对话，并期望语音代理能通过提问来进行更具对话性的互动：“我希望它也能参与对话，更多地反问问题，这样你也能更投入…”（P14）。一些参与者（N=5）建议语音代理采用“嵌入情感”和“更有趣”的回应，以实现更具人性化的“真实对话”。参与者提到，他们更倾向于选择“更不正式”、“更少说服性”、带有“一点幽默感”和“简短回答”的语音代理，以促进“更有吸引力的互动”。
- en: 'Moreover, participants (N=6) commented on the clarity and quality of the content
    provided by the voice agents. The majority of the feedback on the information
    seeking phase (i.e. information provided by the voice agent) was positive, with
    comments praising the levels of answers and clarity, such as P13 noted “agent
    answers were not generic especially compared to my other voice agent experiences”.
    On the other hand, some participants pointed out redundancy and vagueness, such
    as highlighted by P22: “Sometimes the answers provided in the conversations were
    a bit redundant, but I found the answers very clear, although sometimes a bit
    vague or broad.” . However, there was a general feeling that more concise, in-depth
    content delivery by the voice agents would be desirable.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，参与者（N=6）对语音代理提供的内容的清晰度和质量进行了评论。大多数关于信息检索阶段（即语音代理提供的信息）的反馈是积极的，评论称赞了回答的水平和清晰度，例如P13提到：“代理的回答并不泛泛，尤其是与我其他语音代理的经验相比。”另一方面，一些参与者指出了冗余和模糊性，例如P22强调：“有时候对话中提供的回答有点冗余，但我觉得回答很清楚，尽管有时有点模糊或过于宽泛。”然而，总的来说，参与者普遍认为语音代理能够提供更简洁、深入的内容会更为理想。
- en: In summary, participants anticipated voice agents that engage proactively, exhibit
    personality, deliver interactive communication (memory function), and provide
    varied, interesting yet concise content. Furthermore, the incorporation of human-like
    qualities in both content and voice is desirable. These insights are further reflected
    in participants’ feedback on their agent preferences.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，参与者期望语音代理能够主动互动，展现个性，提供互动式沟通（记忆功能），并提供多样、有趣且简洁的内容。此外，在内容和语音中融入类人特质是可取的。这些见解在参与者对代理偏好的反馈中得到了进一步体现。
- en: 6.2.1 Preferences and experiences across voice agents
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1 语音代理的偏好与体验
- en: 'Participants were asked to express their preference towards the three TextileBots
    by ranking them. We used the chi-square test to assess whether any of the agents
    was selected significantly more (or less) often as a favourite agent. Results
    showed no statistically significant differences although, as mentioned before
    based on the conversational analysis and questionnaire feedback, we can see a
    preference for the Assisstant agent, followed by Vanilla and the Expert as shown
    in Figure [9(b)](https://arxiv.org/html/2406.10590v1#S6.F9.sf2 "In Figure 9 ‣
    Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"). The Assistant agent was
    selected more often (14 selections) than Vanilla (12 selections) than the Expert
    agent (only 4 selections). On the other hand, the Expert agent reached “second
    place” (14 selections) more often than both the Vanilla (7 selections) and Assistant
    (9 selections) agents.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者被要求对三种TextileBots进行排名，表达他们的偏好。我们使用卡方检验评估是否有代理被显著更频繁（或更少频繁）地选为最喜欢的代理。结果显示没有统计学上显著的差异，尽管如前所述，基于对话分析和问卷反馈，我们可以看到对Assistant代理的偏好，其次是Vanilla和Expert代理，如图[9(b)](https://arxiv.org/html/2406.10590v1#S6.F9.sf2
    "图9 ‣ 跨度量互动 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ LLM驱动的领域特定语音代理：以TextileBot为例")所示。Assistant代理（14次选择）比Vanilla代理（12次选择）和Expert代理（仅4次选择）更常被选中。另一方面，Expert代理（14次选择）更常获得“第二名”，比Vanilla代理（7次选择）和Assistant代理（9次选择）更频繁。
- en: 'Most participants (N=18) expressed a preference for an agent that can communicate
    in a concise and clear manner with them. P17 stated, “the 2nd agent (Assistant)
    gave just the right amount of detail.” However, it is worth noting that the length
    of the agent responses was not universally appreciated, as discussed in Section
    [6.1](https://arxiv.org/html/2406.10590v1#S6.SS1.SSS0.Px3 "Ease to use and Interest
    change over time ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot"). Moreover, some participants (N=13) distinguished
    the agents based on their interactive capability. The Assistant agent was preferred
    by many for its interaction level, as P29 stated“Assistant agent has the best
    understanding of my question and explained in a most interesting way”. In contrast,
    the Expert agent was criticized for being a repetitive information source lacking
    meaningful interaction. P1 mentioned that Expert agent ”feels like a repetitive
    of the textile circularity concept.” Whereas P30 point out on the conversational
    breath that Expert “is too restrictive up to a point where it stops responding
    to questions asked”.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数参与者（N=18）表示偏好能够与他们以简洁清晰的方式沟通的代理人。P17 说道：“第二个代理人（助手）给出的细节正好。”然而，值得注意的是，代理人的回应长度并未得到普遍认可，正如在[6.1](https://arxiv.org/html/2406.10590v1#S6.SS1.SSS0.Px3
    "Ease to use and Interest change over time ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")部分讨论的那样。此外，一些参与者（N=13）根据代理人的互动能力区分了不同的代理人。许多人偏好助手代理人，因为它的互动水平，正如P29所说：“助手代理人最能理解我的问题，并以最有趣的方式进行解释。”相比之下，专家代理人因缺乏有意义的互动而被批评为重复的信息来源。P1提到专家代理人“感觉像是对纺织循环性概念的重复。”而P30则指出，专家代理人在对话范围上“限制过多，直到停止回应提出的问题”。'
- en: Finally, the agent’s perceived personality also played a role in preferences.
    A number of participants (N=8) appreciated agents that showed human-like responses.
    P5 noted that the 2nd agent (Vanilla) “sounds more like a human… and gives me
    some interesting answers and makes me laugh.” In contrast, the Expert agent received
    criticism for its formal tonality, with P25 noting that it was more like a “text-book”
    and P10 referring to it as “speaking with a smart microwave.”
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，代理人感知的人格特征在偏好中也发挥了作用。若干参与者（N=8）表示喜欢那些展现出类人反应的代理人。P5提到第二个代理人（Vanilla）“听起来更像人类…给我一些有趣的答案，还让我笑了。”相比之下，专家代理人因其正式的语气而受到批评，P25指出它更像是一本“教科书”，而P10则形容它为“像是在和一个聪明的微波炉对话”。
- en: 6.2.2 Perceived changes over time
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2 随时间变化的感知变化
- en: 'Most participants (N=24) in our study described a change in their overall interaction
    with the agents. Several participants (N=13) commented that their engagement and
    the nature of interaction evolved as they became familiar with the agent. Some
    participants even noted an increase in confidence and comfort in their interaction
    towards the later stages, as described by P5: “the more time I spent on the agent,
    the more open I am”. Several participants (N=9) even mentioned adapting their
    communication styles, such as the language and the clarity of their questions
    to better communicate with the agent. P15 stated: “The way I asked it questions
    so that they were clear enough, avoided using too much colloquial language”. Additionally,
    some participants (N=5) stated an increase in specificity in their query, “my
    questions changed…”, “more specific questions as time went by”, and “I started
    to comment on its response and asked for further explanations.”. There was a general
    trend towards asking more specific and deeper questions as the dialogues progressed.
    Possibly as a result of a better understanding of the agent’s capacities or due
    to a growing interest in the topic.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究中的大多数参与者（N=24）描述了他们与代理人总体互动的变化。若干参与者（N=13）评论称，随着他们对代理人越来越熟悉，互动的参与度和性质发生了变化。一些参与者甚至注意到，他们在后期阶段与代理人互动时的信心和舒适度有所增加，正如P5所描述的：“我花在代理人身上的时间越多，我就越开放。”一些参与者（N=9）甚至提到他们调整了自己的沟通风格，比如语言和问题的清晰度，以便更好地与代理人沟通。P15表示：“我问问题的方式更清晰，避免使用过多的口语化语言。”此外，一些参与者（N=5）表示他们在查询中变得更加具体，“我的问题发生了变化…”，“随着时间的推移，问题变得更具体”，以及“我开始对它的回答进行评论并要求进一步解释。”。随着对话的进展，普遍呈现出提出更具体、更深入问题的趋势。这可能是由于对代理人能力的更好理解，或者是对该主题兴趣的增加。
- en: 6.2.3 Suggestions for improvements
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3 改进建议
- en: 'Participants provided valuable suggestions for improving the agents, including
    one common suggestion to use a more natural and human-like voice. Suggestions
    such as “more natural voice” (P5) and “smoother voice, more dynamic” (P6) indicated
    a preference for a less robotic tone. Participants also mentioned the need for
    the agent to be maybe more empathetic, as P20 stated, “add some emotions”. Another
    suggestion was to improve the flow of the agent’s speech, such as “pauses when
    there is some punctuation would be helpful” (P22). In addition to the voice suggestions,
    participants wanted the agent to be concise, encouraging, and human-like. Suggestions
    included making the agent more engaging and insightful with personalised responses.
    Participants emphasised the importance of personalization, acknowledging that
    different users may have different knowledge levels, needs, and interests. They
    felt that the current agents need to reduce the “teacher-like” (P1) and “uncanny
    valley” (P7) effects in their responses. Another suggestion was related to the
    ability to interrupt the agent’s responses, as one could in a human-human interaction.
    P15 put it as follows: “Could be useful to be able to interrupt the agent’s response
    if the answer is not in line or maybe too long”. This again hints to the suggestion
    for a more natural and human-like interaction.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者提供了许多宝贵的改进建议，包括一个共同的建议：使用更自然、更具人类特点的语音。像“更自然的声音”（P5）和“更流畅、更有活力的声音”（P6）这样的建议表明他们倾向于避免机械化的语调。参与者还提到了希望代理人能更具同理心的需求，正如P20所说：“加入一些情感”。另一个建议是改善代理人语音的流畅性，比如“在标点符号处停顿会很有帮助”（P22）。除了语音方面的建议，参与者还希望代理人简洁、鼓励人心，并且更具人类特征。建议包括让代理人更加有吸引力和富有洞察力，提供个性化的回应。参与者强调了个性化的重要性，承认不同的用户可能有不同的知识水平、需求和兴趣。他们认为当前的代理人在回应中需要减少“像老师一样”（P1）和“令人不安的僵尸感”（P7）效应。另一个建议是关于能够像在人际互动中那样打断代理人的回应，正如P15所说：“如果回答不合适或者太长，能够打断代理人的回应会很有用。”这再次暗示了对更自然、人性化互动的需求。
- en: 6.2.4 Understanding of the domain (textiles circularity)
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.4 域理解（纺织品循环性）
- en: With regard to the specific conversation topic, textile circularity, most participants
    (N=21) reported that they had not previously encountered the concept of textile
    circularity. Despite this, an almost equal majority (N=27) were able to furnish
    a definition falling within the standard understanding of textile circularity
    by the end of the study. This concept of textile circularity is admittedly abstract
    and complex, a factor which led to many of our participants finding the subject
    matter somewhat tedious. Regardless, they remained engaged throughout the study
    and demonstrated the ability to articulate the concept in their own words. We
    believe these observations underscore potential avenues for future research, particularly
    exploring our prompt-based voice agents in other subject domains.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 关于特定的对话主题——纺织品循环性，大多数参与者（N=21）表示他们以前没有接触过纺织品循环性的概念。尽管如此，几乎相等的多数参与者（N=27）在研究结束时能够提供一个符合纺织品循环性标准理解的定义。纺织品循环性的概念确实抽象且复杂，这也是许多参与者觉得这一主题有些枯燥的原因。尽管如此，他们始终保持参与并能够用自己的话表达这一概念。我们认为这些观察结果突出了未来研究的潜在方向，特别是探索我们基于提示的语音代理人在其他学科领域的应用。
- en: 6.3 Dialogue analysis of the voice-based human-agent interaction
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 基于语音的人机交互对话分析
- en: We collected a total of 93 dialogues from 30 participants (3 agent interactions
    per participant), where 3 additional dialogues resulted from the “further interactions”
    that 2 participants had with the Vanilla (1x) and Assistant (2x) agents.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从30名参与者那里收集了共计93个对话（每位参与者3次与代理人的互动），其中有3个额外的对话是由于2名参与者与Vanilla（1次）和Assistant（2次）代理人的“进一步互动”所产生的。
- en: 'Table 4: Analysis of Interaction Turns and Word Count in TextileBots: The Assistant
    TextileBot displayed the highest frequency of interaction turns but the lowest
    word counts per turn both by the participants and Assistant TextileBot itself,
    as compared to others. In contrast, the Expert TextileBot exhibited the reverse
    behaviour. *In our study, each participant gathers one-third of the information
    using a bot, totaling 30 Info gathering sessions. The average number of turns
    is calculated from 10 complete sessions for each bot.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：TextileBots互动轮次与单词数分析：在所有对比的代理人中，Assistant TextileBot的互动轮次频率最高，但每轮的单词数最低，既包括参与者，也包括Assistant
    TextileBot本身。相比之下，Expert TextileBot则表现出相反的行为。*在我们的研究中，每个参与者通过机器人收集三分之一的信息，共计30次信息收集会话。平均轮次是从每个机器人10次完整会话中计算得出的。
- en: '|  | Number of turns | Word counts per turn |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  | 轮次数 | 每轮单词数 |'
- en: '|  | Overall | Free-chatting | Info gathering* | Participants utterances |
    Bot utterances |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '|  | 总体 | 自由聊天 | 信息收集* | 参与者发言 | 机器人发言 |'
- en: '| Vanilla | 13.77 ± 6.29 | 12.6 | 11.7 | 11.78 ± 8.06 | 44.53 ± 22.69 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| Vanilla | 13.77 ± 6.29 | 12.6 | 11.7 | 11.78 ± 8.06 | 44.53 ± 22.69 |'
- en: '| Expert | 11.03 ± 3.7 | 7.6 | 11.2 | 12.11 ± 8.45 | 61.52 ± 23.74 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| Expert | 11.03 ± 3.7 | 7.6 | 11.2 | 12.11 ± 8.45 | 61.52 ± 23.74 |'
- en: '| Assistant | 17.6 ± 10.19 | 9.5 | 14 | 11.43 ± 9.20 | 37.29 ± 37.29 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 代理人 | 17.6 ± 10.19 | 9.5 | 14 | 11.43 ± 9.20 | 37.29 ± 37.29 |'
- en: 6.3.1 Conversation turns
  id: totrans-233
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1 对话轮次
- en: The dialogues contained a total of 1272 conversational turns. Each turn denotes
    an exchange of utterances, representing a pairwise dialogue between a participant
    and the agent. On average, a dialogue comprised 799.40 words (SD=317.53) and 14.13
    turns (SD=7.95). As we discussed earlier, tracking the number of conversation
    turns between the participant and the conversational agent can provide insights
    into the depth and length of interactions. Higher turn counts indicate more engaged
    participants [[67](https://arxiv.org/html/2406.10590v1#bib.bib67), [66](https://arxiv.org/html/2406.10590v1#bib.bib66)].
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 对话中共有1272个对话轮次。每个轮次表示一次话语交换，代表参与者与代理人之间的一对一对话。平均而言，一次对话包含799.40个单词（标准差=317.53）和14.13个轮次（标准差=7.95）。正如我们之前所讨论的，跟踪参与者与对话代理人之间的对话轮次，可以提供有关互动深度和时长的见解。较高的轮次数量表示参与者更为投入[[67](https://arxiv.org/html/2406.10590v1#bib.bib67),
    [66](https://arxiv.org/html/2406.10590v1#bib.bib66)]。
- en: Turn-taking comparison across agents
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代理人之间的轮流对话比较
- en: 'As illustrated in Table [4](https://arxiv.org/html/2406.10590v1#S6.T4 "Table
    4 ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot") and Figure
    [10(a)](https://arxiv.org/html/2406.10590v1#S6.F10.sf1 "In Figure 10 ‣ 6.3.2 Word
    count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"),
    it is evident that the Assistant agent garners the highest level of participant
    engagement, whereas participants tend to exhibit lower levels of engagement with
    the Vanilla agent. These results indicate that there are statistically significant
    differences in the number of turns between the Assistant agent and the other two
    agents, but not between the Vanilla and Expert agents.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如表[4](https://arxiv.org/html/2406.10590v1#S6.T4 "表4 ‣ 6.3 基于语音的人类-代理人互动对话分析
    ‣ 6 结果 ‣ LLM介导的特定领域语音代理人：以TextileBot为例")和图[10(a)](https://arxiv.org/html/2406.10590v1#S6.F10.sf1
    "图10 ‣ 6.3.2 每轮的单词数 ‣ 6.3 基于语音的人类-代理人互动对话分析 ‣ 6 结果 ‣ LLM介导的特定领域语音代理人：以TextileBot为例")所示，Assistant代理人获得了最高水平的参与者参与，而参与者与Vanilla代理人的互动参与度较低。这些结果表明，Assistant代理人与其他两个代理人之间的对话轮次存在统计学上显著的差异，但在Vanilla和Expert代理人之间则没有显著差异。
- en: Single vs Multi-turn conversations
  id: totrans-237
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 单轮对话与多轮对话
- en: 'Smart voice assistants, such as Alexa and Google Assistant, are generally limited
    to single-turn conversations due to their lack of memory. In contrast, our design
    incorporates a memory function, prompting an investigation into whether participants
    can engage naturally in this novel interaction pattern. Multi-turn conversation
    refers to an interaction style whereby multiple rounds of queries and responses
    revolve around the same topic, while single-turn conversation pertains to a scenario
    where only a single query and response take place regarding a specific topic.
    We have identified two distinct forms of vHAI: single-turn query & response and
    multi-turn (dyadic) dialogue. Among the 30 participants, 29 were naturally engaged
    in multi-turn dialogues to varying extents.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 智能语音助手，如 Alexa 和 Google Assistant，由于缺乏记忆功能，通常仅限于单回合对话。相比之下，我们的设计加入了记忆功能，促使我们探讨参与者是否能够在这种新颖的互动模式中自然而然地参与对话。多回合对话指的是一种互动方式，多个回合的提问与回答围绕同一主题展开，而单回合对话则指的是仅围绕特定主题进行一次提问和回答的场景。我们识别出了两种不同形式的虚拟人类-人工智能互动（vHAI）：单回合提问与回答和多回合（二人对话）对话。在30位参与者中，29位参与者在不同程度上自然而然地参与了多回合对话。
- en: 6.3.2 Word count in each turn
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2 每回合词数
- en: 'We further investigated the number of words in both participants’ and agents’
    utterances in each turn, shown in Table [4](https://arxiv.org/html/2406.10590v1#S6.T4
    "Table 4 ‣ 6.3 Dialogue analysis of the voice-based human-agent interaction ‣
    6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").
    The Vanilla agent has an average of 11.78 words (SD=8.06), the Expert has 12.11
    (SD=8.45), and the Assistant has 11.43 words (SD=9.20). The maximum words participants
    spent were 78, 61, and 111 respectively on these three agents. Regarding the responses
    from TextileBot. The Vanilla agent has an average of 44.53 words (SD=22.69), the
    Expert has 61.52 (SD=23.74), and the Assistant has an average of 37.29 words (SD=18.31).'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步调查了每个回合中参与者和代理商的词数，如表[4](https://arxiv.org/html/2406.10590v1#S6.T4 "表 4
    ‣ 6.3 语音基础人类-代理互动分析 ‣ 6 结果 ‣ LLM 驱动的特定领域语音代理：以 TextileBot 为例")所示。Vanilla 代理商的平均词数为
    11.78（标准差 = 8.06），Expert 代理商为 12.11（标准差 = 8.45），Assistant 代理商为 11.43（标准差 = 9.20）。参与者在这三位代理商的回合中使用的最大词数分别为
    78、61 和 111。关于 TextileBot 的回应，Vanilla 代理商的平均词数为 44.53（标准差 = 22.69），Expert 代理商为
    61.52（标准差 = 23.74），Assistant 代理商的平均词数为 37.29（标准差 = 18.31）。
- en: '![Refer to caption](img/e8989da517257feb64a82b4b9a0aacc5.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8989da517257feb64a82b4b9a0aacc5.png)'
- en: (a) Numbers of turns per participant across three agents.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 三位代理商每位参与者的回合数。
- en: '![Refer to caption](img/d48fb467ad01c7c29a7127ee02aadcf6.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d48fb467ad01c7c29a7127ee02aadcf6.png)'
- en: (b) overall trends for lengths of turns
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 回合长度的总体趋势
- en: 'Figure 10: Left: Figure (a) shows the number of turns per participant across
    three agents. Right: Figure (b) illustrates the word count per turn, smoothed
    using a moving average for each agent, against different turn numbers.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：左侧：图（a）展示了三位代理商每位参与者的回合数。右侧：图（b）展示了每个代理商每回合的词数，采用移动平均法平滑处理，并与不同的回合数进行对比。
- en: 'The trend for participant’s word usage across agents involves calculating a
    moving average with a window size of four, and this smoothed data is depicted
    in Figure [10(b)](https://arxiv.org/html/2406.10590v1#S6.F10.sf2 "In Figure 10
    ‣ 6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot"). Observing the data, a noticeable pattern emerges: participants’
    initial utterances with fewer words gradually increased their words in the early
    turns. The duration peak, or hold time, represents the duration for which the
    agents can sustain participant engagement. Towards the end, the curve shows a
    decline, suggesting a decrease in participant engagement as they gradually speak
    fewer words.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者在不同代理商间的用词趋势涉及计算一个窗口大小为四的移动平均值，这些平滑后的数据在图[10(b)](https://arxiv.org/html/2406.10590v1#S6.F10.sf2
    "图 10 ‣ 6.3.2 每回合词数 ‣ 6.3 语音基础人类-代理互动分析 ‣ 6 结果 ‣ LLM 驱动的特定领域语音代理：以 TextileBot
    为例")中展示。从数据观察，出现了一个显著的趋势：参与者在最初的言辞较少的回合中逐渐增加了言辞，直到早期回合。持续时间峰值，或称为保持时间，代表了代理商能够保持参与者参与的时长。到后期，曲线呈下降趋势，表明随着参与者逐渐减少词数，他们的参与度下降。
- en: 6.4 Conversational styles
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 对话风格
- en: Beyond the overview of dialogues, we explore the conversational styles in the
    dialogues and conversational turns over time. Deborah Tannen [[88](https://arxiv.org/html/2406.10590v1#bib.bib88)]
    describes conversational styles “is comprised of the habitual use of specific
    linguistic devices, chosen by reference to broad operating principles or conversational
    strategies”.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对话概览之外，我们还探索了对话中的会话风格和对话转折的变化。Deborah Tannen [[88](https://arxiv.org/html/2406.10590v1#bib.bib88)]
    描述了会话风格“由对特定语言工具的习惯性使用组成，这些工具是根据广泛的操作原则或会话策略选择的”。
- en: 6.4.1 Conversational styles change over time
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.1 会话风格随时间变化
- en: Across all agents, we noticed a similar trend of changes over time. The complexity
    of participants’ queries increased over time. In other words, participants began
    with straightforward queries and progressed to more complex ones. Initially, participants
    prefer using straightforward queries that are concise, direct, and easy to understand
    and respond to. These queries seek simple and concise answers without requiring
    elaborations [[82](https://arxiv.org/html/2406.10590v1#bib.bib82)], the phrases
    commonly start with “What is”, “What are”, e.g., “What fiber is cotton made from?”
    .
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有参与者中，我们注意到随着时间的推移，查询的复杂度呈现出类似的趋势。换句话说，参与者从简单的查询开始，逐渐过渡到更复杂的查询。最初，参与者倾向于使用简洁、直接、易于理解和回应的查询。这些查询寻求简单简洁的答案，无需过多的详细说明[[82](https://arxiv.org/html/2406.10590v1#bib.bib82)]，通常以“什么是”、“什么样的”等开头，例如：“棉花是由什么纤维做的？”。
- en: 'As the conversation progressed, we observed a shift towards more complex queries,
    such as posing chained queries (P28-Expert: “So what if I want to help you to
    persuade the whole community to use in textile circularity? What would be the
    strategy? How should I get involved into the community to try to persuade more
    people be aware of this issue?”) and lengthy information (P10-Assistant: “what
    is the advantage over organic material over other types of material is it more
    sustainable or is more healthy or is more I don’t know like is there any other
    properties that you can mention I can actually make it the top trending material
    that’s used during this generation”).'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对话的进行，我们观察到对话内容变得更加复杂，例如提出连贯性问题（P28-专家：“如果我想帮助你说服整个社区参与纺织品的循环使用，该怎么做？我应该如何参与社区，尝试说服更多的人关注这个问题？”）和冗长的信息（P10-助手：“有机材料相较于其他材料有什么优势？是更可持续，还是更健康，或者还有其他特性？你能提到吗？我能不能把它做成这一代的流行材料？”）。
- en: '{mdframed}{dialogue}'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '{mdframed}{dialogue}'
- en: First bot Vanilla GPT-3.5 model
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个机器人Vanilla GPT-3.5模型
- en: Bot Hi there, I’m TextileBot … How can I assist you today? Human Hello, I would
    like to learn more about the circular economy in the textile industry.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人：您好，我是TextileBot……我今天能为您提供什么帮助？ 人类：你好，我想了解更多关于纺织行业中的循环经济。
- en: …
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Human What is the percentage between, the ratio between production and recycling
    in India in relation to cotton? Second bot Expert Bot Hi there, I’m TextileBot
    … How can I assist you today? Human How do you think AI can be used to support
    and improve the textile systemarity?
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 人类：印度棉花生产与回收的比例是多少？第二机器人专家Bot：您好，我是TextileBot……我今天能为您提供什么帮助？ 人类：您认为AI如何支持和改善纺织系统的循环性？
- en: …
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Human Do you know what is the percentage of clothes from big brands like the
    fast fashion industry like Zara and H&M that are actually sold in the same production
    here? Third bot Assistant
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 人类：你知道像Zara和H&M这样的快时尚品牌，实际销售的衣服在本地生产中的比例是多少吗？第三个机器人助手
- en: Bot Hi there, I’m TextileBot … How can I assist you today?
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人：您好，我是TextileBot……我今天能为您提供什么帮助？
- en: Human Can you name some fashion companies that are big players in the fashion
    society?
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 人类：你能列举一些在时尚行业中有影响力的大公司吗？
- en: …
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Human So it was introduced in 2015 and it’s still something that’s available.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 人类：所以它是2015年推出的，并且至今仍在使用。
- en: 'Figure 11: The three dialogues of P22 demonstrate a progression from the starting
    point to a later stage with Vanilla, Expert, Assistant, respectively.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：P22中的三个对话展示了从起点到后期阶段的进展，分别由Vanilla、Expert和Assistant进行。
- en: 'Regarding the content, the example in Figure [11](https://arxiv.org/html/2406.10590v1#S6.F11
    "Figure 11 ‣ 6.4.1 Conversational styles change over time ‣ 6.4 Conversational
    styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")
    illustrates how participants’ queries progressed with each agent. Participants
    moved from general ( P27-Assistant: “Tell me the basics about textiles.”) to specific
    (P27-Assistant: “Can you still make nylon or polyester without petrol?”) and from
    factual (P23-Assistant: “How to wash my clothes with the oil on it.”) to subjective
    queries (P23-Assistant: “What’s your opinion on Uniqlo?”), which aligned with
    the findings in Section [6.2](https://arxiv.org/html/2406.10590v1#S6.SS2 "6.2
    Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot"). These progressions in query complexity echoed Wilson’s information
    seeking model [[102](https://arxiv.org/html/2406.10590v1#bib.bib102)].'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '就内容而言，图[11](https://arxiv.org/html/2406.10590v1#S6.F11 "Figure 11 ‣ 6.4.1 Conversational
    styles change over time ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")中的示例展示了参与者如何与每个智能体进行提问的进展。参与者从一般性提问（P27-Assistant:
    “告诉我一些关于纺织品的基本知识。”）转向具体性提问（P27-Assistant: “你还能在没有石油的情况下制造尼龙或聚酯吗？”），从事实性问题（P23-Assistant:
    “如何清洗沾有油渍的衣服？”）转向主观性问题（P23-Assistant: “你怎么看优衣库？”），这一变化与第[6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")节的发现一致。这些提问复杂性的进展呼应了Wilson的信息需求模型[[102](https://arxiv.org/html/2406.10590v1#bib.bib102)]。'
- en: 6.4.2 Code-switching
  id: totrans-265
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.2 代码切换
- en: 'Code-switching, also known as language alternation, is a phenomenon that frequently
    occurs in multilingual individuals and is formally referred to as changing the
    language used in conversation. As sociolinguists have defined [[44](https://arxiv.org/html/2406.10590v1#bib.bib44)],
    it is now widely acknowledged as the way people select their “linguistic repertoire”
    [[15](https://arxiv.org/html/2406.10590v1#bib.bib15), [40](https://arxiv.org/html/2406.10590v1#bib.bib40)]
    based on situational demands. We here refer to code-switching as the language
    alternation of the participants, which includes the formulation of queries and
    variations in tone. Participants tend to use code-switching to elicit their desired
    response. For example, in Figure [5](https://arxiv.org/html/2406.10590v1#S3.F5
    "Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through
    System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot") it is evident that participants
    applied code-switching to assess the agent’s capabilities. In computer science
    terms, this behaviour can be likened to participants testing with various prompts
    to evaluate the LLMs.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '代码切换，也称为语言交替，是一种常见的现象，通常出现在多语言使用者中，正式来说是指在对话中改变所使用的语言。正如社会语言学家所定义的[[44](https://arxiv.org/html/2406.10590v1#bib.bib44)]，现在普遍认为它是人们根据情境需求选择其“语言库”的方式[[15](https://arxiv.org/html/2406.10590v1#bib.bib15),
    [40](https://arxiv.org/html/2406.10590v1#bib.bib40)]。在这里，我们将代码切换指为参与者的语言交替，包括提问的表述和语调的变化。参与者往往通过代码切换来引导他们想要的回应。例如，在图[5](https://arxiv.org/html/2406.10590v1#S3.F5
    "Figure 5 ‣ 3.3 Phase 3: Enable continuous LLM interaction with memory through
    System Optimization ‣ 3 Prototyping Domain-Specific Voice Agents ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")中，可以明显看出参与者应用了代码切换来评估智能体的能力。在计算机科学术语中，这种行为类似于参与者使用不同的提示语进行测试，以评估大语言模型（LLM）的表现。'
- en: 6.4.3 Social protocol
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.3 社会规范
- en: Following Völkel et al. [[94](https://arxiv.org/html/2406.10590v1#bib.bib94)],
    social protocol as an exchange of polite conventions or obligations, such as saying
    “hi”, “thank you”, “please”, a form of general information (e.g., “Nice”). 76.7%
    of participants (N=23) had at least one social protocol with the agent, 56.7%
    participants (N=17) used “thank you” or “please”, 50% participant (N=15) greeted
    the agent at the beginning of their conversation, e.g. “Hello, what is your name?”
    (P13), but most of them did not do so in all interactions with every agent. 23.3%
    participant (N=7) appreciated or affirmed agent’s answer, most of them occurred
    with Assistant, such as “that’s good to know” (P20-Assistant/Vanilla), “You’re
    a good guy.” (P5-Assistant), “Wow, sounds amazing.” (P37-Assistant). Unfortunately,
    none of those acknowledgements were given to Expert.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Völkel等人[[94](https://arxiv.org/html/2406.10590v1#bib.bib94)]的研究，社交礼仪作为一种礼貌性惯例或义务的交换，比如说“嗨”、“谢谢”、“请”等，属于一种一般信息交流（例如，“你好”）。76.7%的参与者（N=23）至少与代理人进行了一次社交礼仪互动，56.7%的参与者（N=17）使用了“谢谢”或“请”，50%的参与者（N=15）在对话开始时向代理人问候，例如“你好，你叫什么名字？”（P13），但大多数人并没有在每次与代理人交互时都这样做。23.3%的参与者（N=7）对代理人的回答表示感谢或肯定，其中大多数发生在与Assistant的对话中，比如“知道这些真好”（P20-Assistant/Vanilla）、“你是个好人。”（P5-Assistant）、“哇，听起来太棒了。”（P37-Assistant）。不幸的是，没有人对Expert给予这样的肯定。
- en: 6.4.4 Variations of utterances across agents
  id: totrans-269
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.4 代理人间话语的变化
- en: 'We further investigate if the conversational styles are varied across agents.
    We found that participants tend to pose detailed queries with clear instructions
    and relatively formal language with Expert, for instance P12 stated “Can you tell
    me more about what’s going on in one of those countries with a lot of textile
    waste from northern countries? Can you tell me more about how a specific country
    deals with the textile they receive?”. This may indicate the reason for the average
    word spend is slightly more with Expert in (refer to Section [6.3.2](https://arxiv.org/html/2406.10590v1#S6.SS3.SSS2
    "6.3.2 Word count in each turn ‣ 6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")).'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步调查了对话风格是否因代理人不同而有所差异。我们发现，参与者在与Expert交互时，倾向于提出详细的问题，给出清晰的指示，并使用相对正式的语言。例如，P12表示：“你能告诉我关于那些有很多来自北方国家的纺织废料的国家的情况吗？你能告诉我一个特定国家如何处理他们收到的纺织品吗？”这可能表明平均用词量在与Expert互动时略多的原因（参见第[6.3.2](https://arxiv.org/html/2406.10590v1#S6.SS3.SSS2
    "6.3.2 每轮对话的字数 ‣ 6.3 语音交互分析 ‣ 6 结果 ‣ 基于LLM的特定领域语音代理：以TextileBot为例")）。
- en: In the dialogue with Assistant, the conversational style people phrased their
    queries ranged from formal, complete sentences, to more conversation-like utterances.
    This reflects varying social protocols for interacting with agents, but it also
    shows the Assistant agent’s effectiveness in engaging participants in a more natural
    and less formalistic dialogue.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在与Assistant的对话中，参与者提出问题的语言风格从正式的完整句子到更像日常对话的语句不等。这反映了与代理人互动时社交礼仪的不同，也表明了Assistant代理人能够更有效地吸引参与者进行更自然、
    less formalistic 的对话。
- en: Similarly, participants’ queries with the Vanilla agent were less formal compared
    to the Expert. It is worth noting that two multi-turn dialogues led to arguments
    with rude utterances. P21 even went as far as to state “That is absolutely bullshit.
    Who told you that? Why do you believe him?” when Vanilla claimed it is programmed
    by experienced programmers and “My programmer believes that having an English
    accent gives me a more sophisticated, knowledgeable and intelligent persona.”.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，参与者与Vanilla代理人的对话查询相较于与Expert的交互更加非正式。值得注意的是，两个多轮对话引发了争论，并出现了粗鲁的言辞。当Vanilla声称其是由经验丰富的程序员编程时，P21甚至表示：“那简直是胡说八道。谁告诉你的？你为什么相信他？”以及“我的程序员认为，拥有英语口音能让我显得更复杂、更有知识和更聪明。”
- en: 6.5 Human behaviour and reactions
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5 人类行为与反应
- en: 'Diving further into participants’ engagement with the agents in the dialogues,
    our data shows that one-third of participants (N=10) used the phrase, “tell me
    more …” at least once. All participants (N=30) were seeking clarifications in
    the free chatting phase (e.g. P14-Vanilla: “What do you mean by promote sustainability?”
    P28-Assistant: “Please tell me more about it”). These instances suggest a demand
    for additional detailed explanations. The Assistant, Expert, and Vanilla agents
    received such requests in 6.1%, 4.7%, and 4.5% of interactions, respectively.
    Whereas only 63.3% participants (N=19) sought clarification in the information
    seeking phase. For instance, P25-Vanilla “I think the example you gave is very
    high level. Is there any more detailed example you can give me?”. The information-seeking
    phase witnessed an increased number of clarifications, as the name suggests, totalling
    32.1% with the Assistant, 24.1% with the Expert, 17.9% with the Vanilla. This
    could be because the Assistant tends to respond in a concise style, where participants
    desire more elaboration.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 更深入地分析参与者与代理在对话中的互动，我们的数据表明，三分之一的参与者（N=10）至少使用过一次“告诉我更多……”这句话。所有参与者（N=30）在自由聊天阶段都寻求澄清（例如，P14-Vanilla：“你说的‘促进可持续性’是什么意思？”P28-Assistant：“请告诉我更多有关它的信息”）。这些情况表明存在对更详细解释的需求。助手、专家和Vanilla代理分别在6.1%、4.7%和4.5%的互动中收到了这样的请求。而只有63.3%的参与者（N=19）在信息获取阶段寻求澄清。例如，P25-Vanilla：“我觉得你给的例子很高层次。你能给我一个更详细的例子吗？”正如其名所示，信息获取阶段的澄清次数有所增加，助手为32.1%、专家为24.1%、Vanilla为17.9%。这可能是因为助手倾向于以简洁的方式作答，而参与者希望得到更多的阐述。
- en: Moreover, it was interesting to observe how participants reacted to agent errors.
    This was captured by the main experimenter through note-taking during the study
    and dialogue between the participants and agents. 30% participants (N=9) encountered
    agent errors such as failures in Automatic Speech Recognition (ASR) or a lack
    of understanding in response to participant queries. Out of those participants,
    77.8% (N=7) participants actively corrected the agent by explicitly stating the
    misunderstanding, repeating or rephrasing their queries, e.g. P15 stating “No,
    I meant - what materials are you made of?”. Other strategies encompassed terminating
    the conversation, shifting to a different topic, or progressing with the agent.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，观察参与者如何反应代理错误也颇为有趣。这一过程通过主实验者在研究中做笔记和参与者与代理之间的对话记录下来了。30%的参与者（N=9）遇到了代理错误，如自动语音识别（ASR）失败或对参与者提问理解不当。在这些参与者中，77.8%（N=7）积极地通过明确指出误解、重复或重新表述问题来纠正代理，例如P15表示：“不，我是指——你是用什么材料做的？”其他策略包括终止对话、转换话题或继续与代理互动。
- en: Since LLMs can produce both plausible-sounding and incorrect or nonsensical
    answers [[106](https://arxiv.org/html/2406.10590v1#bib.bib106)], participants
    encountered such situations. Some participants (N=5) contested the agents, and
    tried to convince or educate the agent to correct its answer. On one occasion,
    a participant expressed discontent when the Assistant agent was repetitive about
    sustainable suggestions. The participant pointed out, “Yeah, but if you repeat
    yourself, sometimes people think that you’re talking down to them.”. The agent
    then acknowledged the feedback and apologized.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大语言模型（LLM）能够生成既看起来合理又错误或无意义的答案[[106](https://arxiv.org/html/2406.10590v1#bib.bib106)]，参与者遇到了类似的情况。一些参与者（N=5）对代理提出异议，并试图说服或教育代理纠正其回答。在一次情况下，一位参与者对助手代理在可持续性建议上重复表达表示不满。该参与者指出：“是的，但如果你一直重复自己，有时候人们会觉得你在居高临下地对待他们。”代理随后承认了反馈并道歉。
- en: 'Participants also challenged some of the agents’ responses and 40% participants
    (N=12) explicitly expressed their skepticism and mistrust towards LLM-mediated
    agents. Some participants (N=5) addressed their concern by asking “Are you sure
    …?” and continued to ask for more evidence from the agent on the topic of the
    conversation. P15 even went as far as to state “That is where you’re wrong, my
    friend.”, when the participant was unhappy with the responses and decided to finish
    the conversation in the free chatting phase and move to the information seeking
    part. It was interesting to observe, that arguments and skepticism were more prevalent
    in the conversation with the Expert agent. This may be due to the lengthy response
    style, where participants mentioned losing interest. We observed that a strategy
    participants used to verify if the agent was making up their answer or not was
    by asking some facts they knew. Below is an example:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者还对一些代理的回应提出了质疑，40%的参与者（N=12）明确表示他们对大语言模型介导的代理持怀疑态度和不信任。一些参与者（N=5）通过问“你确定……？”来表达他们的疑虑，并继续要求代理提供更多话题相关的证据。P15甚至表示“那是你错了，我的朋友。”，当参与者对回答不满意时，他们决定在自由聊天阶段结束对话，并转向信息获取阶段。有趣的是，我们观察到，在与专家代理的对话中，争论和怀疑的情况更加普遍。这可能与代理的回应风格较长有关，参与者提到因此失去了兴趣。我们还观察到，参与者用来验证代理是否在编造答案的一种策略是询问他们已知的一些事实。以下是一个示例：
- en: 'p11: Are real numbers countable? Assistant: I’m sorry, I’m not familiar with
    real numbers. Could you help me understand what they are? I can help you find
    sustainable clothing options, if you’d like. p11: Do you know what rational numbers
    are? Assistant: Yes, rational numbers are numbers that can be expressed as a fraction
    or ratio, such as 1/2 or 3:4\. Would you like to know more about sustainable clothing?
    p11: back to your previous question, real numbers are the completion of the rational
    numbers.'
  id: totrans-278
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'p11: 实数是可数的吗？助手：抱歉，我不太了解实数。您能帮助我理解它们是什么吗？如果您需要，我可以帮您找到可持续的服装选择。 p11: 你知道什么是有理数吗？助手：是的，有理数是可以表示为分数或比率的数字，比如
    1/2 或 3:4。您想了解更多关于可持续服装的信息吗？ p11: 回到你之前的问题，实数是有理数的完备。'
- en: 7 Discussion & Future Directions
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论与未来方向
- en: This work introduces a novel three-phase approach to prototyping domain-specific
    voice agents using LLMs. We assessed our method by implementing a voice agent
    on an actual device, TextileBot, specifically focusing on textiles circularity,
    and conducted an in-depth user study. In this discussion, we first analyze the
    effectiveness of our approach, drawing upon evaluation metrics and dialogue analysis.
    We then explore comprehensive insights derived from the dialogue analysis, questionnaire
    responses, and overall participant feedback. This exploration aims to deepen our
    understanding of human perceptions, engagement, and interactions with LLM-mediated,
    prompt-based voice agents. Finally, we reflect on the key lessons learned from
    this design process and discuss their broader implications for the HCI community.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一种新颖的三阶段方法，通过使用大语言模型（LLMs）来原型化特定领域的语音代理。我们通过在实际设备 TextileBot 上实现一个语音代理来评估我们的方法，特别聚焦于纺织品的循环性，并进行了深入的用户研究。在本讨论中，我们首先通过评估指标和对话分析来分析我们方法的有效性。接着，我们探索了从对话分析、问卷回应和整体参与者反馈中得出的全面见解。这一探索旨在加深我们对人类感知、参与度以及与基于提示的大语言模型介导的语音代理互动的理解。最后，我们回顾了从这一设计过程中学到的关键经验，并讨论了这些经验对人机交互（HCI）社区的更广泛意义。
- en: 7.1 The effectiveness of the method
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 方法的有效性
- en: The effectiveness of prompting LLMs has been widely studied [[49](https://arxiv.org/html/2406.10590v1#bib.bib49),
    [60](https://arxiv.org/html/2406.10590v1#bib.bib60), [14](https://arxiv.org/html/2406.10590v1#bib.bib14)],
    using standard metrics, such as perplexity and the BLEU score [[73](https://arxiv.org/html/2406.10590v1#bib.bib73)].
    However, all of these metrics are objective evaluations that fail to capture the
    nuanced human-LLM interactions. In our research, we adopt a human-centred AI design
    approach with human-in-the-loop to evaluate prompt-based LLM-mediated voice agents.
    We conducted a subjective user study that combined both heuristics conversational
    agents evaluation metrics [[51](https://arxiv.org/html/2406.10590v1#bib.bib51),
    [86](https://arxiv.org/html/2406.10590v1#bib.bib86), [65](https://arxiv.org/html/2406.10590v1#bib.bib65),
    [92](https://arxiv.org/html/2406.10590v1#bib.bib92)] and human-LM interaction
    metrics [[55](https://arxiv.org/html/2406.10590v1#bib.bib55), [99](https://arxiv.org/html/2406.10590v1#bib.bib99)].
    This approach allowed us to integrate quantitative data and qualitative insights,
    offering a more holistic understanding of the voice agent’s effectiveness. We
    are interested in whether participants can identify the conversational agents’
    characteristics as intended in our design, particularly in terms of restricting
    the agent’s conversational domain and personality.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的提示效果已经被广泛研究[[49](https://arxiv.org/html/2406.10590v1#bib.bib49), [60](https://arxiv.org/html/2406.10590v1#bib.bib60),
    [14](https://arxiv.org/html/2406.10590v1#bib.bib14)]，使用标准指标，如困惑度和BLEU得分[[73](https://arxiv.org/html/2406.10590v1#bib.bib73)]。然而，这些指标都是客观评估，无法捕捉到人类与LLM之间的微妙互动。在我们的研究中，我们采用了以人为中心的AI设计方法，结合人类参与者来评估基于提示的LLM介导的语音代理。我们进行了一项主观用户研究，结合了启发式对话代理评估指标[[51](https://arxiv.org/html/2406.10590v1#bib.bib51),
    [86](https://arxiv.org/html/2406.10590v1#bib.bib86), [65](https://arxiv.org/html/2406.10590v1#bib.bib65),
    [92](https://arxiv.org/html/2406.10590v1#bib.bib92)]和人类-LM互动指标[[55](https://arxiv.org/html/2406.10590v1#bib.bib55),
    [99](https://arxiv.org/html/2406.10590v1#bib.bib99)]。这种方法使我们能够结合定量数据和定性见解，从而提供对语音代理有效性的更全面理解。我们感兴趣的是，参与者是否能够识别出我们设计中意图表达的对话代理特征，特别是在限制代理的对话领域和个性方面。
- en: 'Our results showed no statistically significant differences across three agent
    ratings for their Coherence, Ease to use and Change over time metrics (Section
    [6.1](https://arxiv.org/html/2406.10590v1#S6.SS1.SSS0.Px2 "Cross-metrics interactions
    ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")). The results indicate that prompting does not have a
    significant impact on the Ease of Use, Coherence, and Change over Time in the
    interaction between TextileBots and users. We found that all three agents are
    nearly equal in these comparison dimensions. This is an encouraging result, as
    it demonstrates that prompting does not have a detrimental effect on these dimensions
    for the type and level of prompting tested in this experiment.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果显示，三个代理在其连贯性、易用性和随时间变化指标（第[6.1节](https://arxiv.org/html/2406.10590v1#S6.SS1.SSS0.Px2
    "跨指标交互 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ LLM介导的领域特定语音代理：以TextileBot为例")）上的评分没有统计学上的显著差异。结果表明，提示对TextileBot与用户之间的易用性、连贯性和随时间变化的互动没有显著影响。我们发现这三位代理在这些比较维度上几乎是相等的。这是一个令人鼓舞的结果，因为它表明，在本实验中测试的提示类型和级别下，提示对这些维度没有产生不利影响。
- en: 'On the other hand, the prompts design significantly influenced user engagement
    and perception (Figure [9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1 "In
    Figure 9 ‣ Cross-metrics interactions ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")). The Expert,
    despite its design for detailed and domain-specific responses in textiles circularity,
    faced criticism for its lengthy and persuasive replies, hindering user engagement.
    Yet, this critique aligns with our intention for the Expert to provide “response
    in a detailed manner”, validating the effectiveness of our Taxonomy-based Knowledge
    Structure Chain. Interestingly, while the Expert had a negative impact on engagement
    levels, it was not considered particularly bad (in terms of preferences). We noted
    that participants recognized its utility in textiles circularity domain, aligning
    with its intended role as a domain-specific “TextileBot”.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，提示设计显著影响了用户的参与度和认知（图[9(a)](https://arxiv.org/html/2406.10590v1#S6.F9.sf1
    "图9 ‣ 跨度量交互 ‣ 6.1 问卷结果 ‣ 6 结果 ‣ 基于LLM的特定领域语音代理：以TextileBot为例")）。尽管专家（Expert）被设计为在纺织品循环领域提供详细且特定领域的回答，但它因回答过于冗长且具说服力而遭到批评，阻碍了用户的参与度。然而，这一批评与我们希望专家能够“以详细方式进行回应”的初衷是一致的，从而验证了我们基于分类法的知识结构链的有效性。有趣的是，尽管专家对参与度产生了负面影响，但它并未被认为特别糟糕（从偏好角度来看）。我们注意到，参与者认可其在纺织品循环领域的实用性，与其作为特定领域“TextileBot”的预期角色相符。
- en: 'The results also highlight the participants’ nuanced perception of the differences
    between the Vanilla, Expert and Assistant, recognizing their distinct characteristics
    and domain-specific utilities as discussed in Section [6.2.1](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS1
    "6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").
    This indicates a successful differentiation in their roles and conversational
    styles. Overall, our findings demonstrate the potential of our three-phase method
    in transforming LLMs from generalist to domain-specific roles. This approach effectively
    manages the domain focus, personalities, response styles, and conversational freedom
    of voice-based conversational agents.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 结果还突出了参与者对Vanilla、Expert和Assistant之间差异的细致感知，认识到它们在特定领域的独特特征和效用，如第[6.2.1](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS1
    "6.2.1 各语音代理的偏好和体验 ‣ 6.2 综合反馈 ‣ 6 结果 ‣ 基于LLM的特定领域语音代理：以TextileBot为例")节中所讨论的。这表明它们在角色和对话风格上的成功区分。总体而言，我们的研究结果展示了我们三阶段方法的潜力，能够将LLM从通用角色转变为特定领域角色。这一方法有效地管理了语音对话代理的领域聚焦、个性、回应风格和对话自由度。
- en: 7.2 Insights into human-agent interactions and AI-powered dialogues
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 人机互动与AI驱动对话的洞察
- en: 'This work distinguishes itself from text-based human-agent interaction because
    people behave differently when speaking and writing, as the language used for
    spoken dialogue is distinct from that in written text [[81](https://arxiv.org/html/2406.10590v1#bib.bib81)].
    While voice-based interactions share some commonalities with text-based interactions,
    they differ significantly in various aspects as discussed in Section [7.3](https://arxiv.org/html/2406.10590v1#S7.SS3
    "7.3 Optimizing LLM-mediated voice agent design for specific domains ‣ 7 Discussion
    & Future Directions ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").
    Our findings not only align with but also extend existing research in voice-based
    human-agent interaction (vHAI) [[38](https://arxiv.org/html/2406.10590v1#bib.bib38),
    [88](https://arxiv.org/html/2406.10590v1#bib.bib88), [15](https://arxiv.org/html/2406.10590v1#bib.bib15),
    [40](https://arxiv.org/html/2406.10590v1#bib.bib40), [94](https://arxiv.org/html/2406.10590v1#bib.bib94)],
    offering fresh insights into fully automated AI-powered conversations.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究区别于基于文本的人机互动，因为人们在说话和写作时的行为是不同的，口语对话所使用的语言与书面文本中的语言不同[[81](https://arxiv.org/html/2406.10590v1#bib.bib81)]。尽管基于语音的交互与基于文本的交互有一些共性，但在多个方面存在显著差异，如第[7.3](https://arxiv.org/html/2406.10590v1#S7.SS3
    "7.3 优化基于LLM的语音代理设计以适应特定领域 ‣ 7 讨论与未来方向 ‣ 基于LLM的特定领域语音代理：以TextileBot为例")节所讨论的那样。我们的研究发现不仅与现有的语音基础人机互动（vHAI）研究相符，还扩展了现有研究，为完全自动化的AI驱动对话提供了新的见解[[38](https://arxiv.org/html/2406.10590v1#bib.bib38)，[88](https://arxiv.org/html/2406.10590v1#bib.bib88)，[15](https://arxiv.org/html/2406.10590v1#bib.bib15)，[40](https://arxiv.org/html/2406.10590v1#bib.bib40)，[94](https://arxiv.org/html/2406.10590v1#bib.bib94)]。
- en: The TextileBot represents a significant advancement in this realm. It achieves
    multi-turn conversations, allowing for more natural and ongoing contact compared
    to typical voice agents like Alexa, which only have single-turn memoryless interactions.
    Also, unlike domain-specific agents, which offer detailed, context-aware responses
    in particular areas, general voice assistants like Alexa answer common queries,
    providing a broader range of services, e.g. weather updating, but with less specialization.
    In our study, nearly all participants (N=29) quickly adapted to this new form
    of interaction, underscoring the inherent and instinctive nature of human communication
    as continuous multi-turn dialogue. Current voice-based agents lack the capacity
    to retain knowledge for ongoing conversations. TextileBot’s design effectively
    addresses these shortcomings, demonstrating a more realistic interaction model.
    This advancement is particularly beneficial for the HCI community, as it facilitates
    the prototyping of voice agents for more sophisticated interactions beyond simple
    single-turn exchanges. Future developments in voice agents should aim at enabling
    conscious and continuous interactions that mimic natural human dialogue.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: TextileBot代表了这一领域的重大进展。与典型的语音助手（如Alexa，后者只有单回合的无记忆交互）相比，它实现了多轮对话，使得交流更加自然和持续。此外，不同于专门领域的语音助手，这些助手在特定领域提供详细且具上下文感知的回答，而像Alexa这样的通用语音助手回答常见问题，提供更广泛的服务，例如天气更新，但其专业性较差。在我们的研究中，几乎所有参与者（N=29）都迅速适应了这种新型的互动方式，强调了人类沟通作为持续多轮对话的固有和本能特性。目前的语音助手缺乏保持知识以进行持续对话的能力。TextileBot的设计有效地解决了这些不足，展示了更为真实的互动模型。这一进展对人机交互（HCI）社区尤为重要，因为它有助于为更复杂的互动设计语音助手的原型，而不仅仅是简单的单回合交流。未来的语音助手发展应着眼于实现模拟自然人类对话的有意识且持续的互动。
- en: 'In conversational analysis, we noticed a significant shift in the participants’
    conversational styles [[88](https://arxiv.org/html/2406.10590v1#bib.bib88)] over
    time. They gradually began to pose more sophisticated queries (Section [6.4.1](https://arxiv.org/html/2406.10590v1#S6.SS4.SSS1
    "6.4.1 Conversational styles change over time ‣ 6.4 Conversational styles ‣ 6
    Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot"))
    and even applied code-switching (Section [6.4.2](https://arxiv.org/html/2406.10590v1#S6.SS4.SSS2
    "6.4.2 Code-switching ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")) [[15](https://arxiv.org/html/2406.10590v1#bib.bib15),
    [40](https://arxiv.org/html/2406.10590v1#bib.bib40)] to alter their language for
    desired responses. This change is also reflected in their overall feedback, as
    they reported a shift in engagement and interaction dynamics as they became more
    familiar with the prompt-based voice agents. These findings indicate a growing
    confidence of participants in their interactions as they developed a better understanding
    of the agents (Section [6.2.2](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS2
    "6.2.2 Perceived changes over time ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")). These complex changes
    in behaviour and interaction patterns pose a central challenge for autonomous
    voice agents, which aim to operate without the involvement of an experimenter.
    However, our study shows that LLM-mediated voice agents demonstrate a level of
    capability and flexibility in handling these dynamics. This emphasizes the potential
    of utilizing LLMs for conversational agents to effectively address complex human
    inquiries.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '在对话分析中，我们注意到参与者的对话风格发生了显著变化[[88](https://arxiv.org/html/2406.10590v1#bib.bib88)]。随着时间的推移，他们逐渐开始提出更复杂的问题（见[6.4.1节](https://arxiv.org/html/2406.10590v1#S6.SS4.SSS1
    "6.4.1 Conversational styles change over time ‣ 6.4 Conversational styles ‣ 6
    Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")），甚至应用了代码切换（见[6.4.2节](https://arxiv.org/html/2406.10590v1#S6.SS4.SSS2
    "6.4.2 Code-switching ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")）[[15](https://arxiv.org/html/2406.10590v1#bib.bib15),
    [40](https://arxiv.org/html/2406.10590v1#bib.bib40)]，以改变他们的语言以获得所需的回答。这一变化也反映在他们的总体反馈中，因为他们报告了参与者在与基于提示的语音代理互动时，参与度和互动动态发生了转变，随着对这些代理的了解加深，参与者变得更加熟悉。这些发现表明，参与者在互动中表现出越来越高的信心，随着他们对代理的理解加深（见[6.2.2节](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS2
    "6.2.2 Perceived changes over time ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")）。这些行为和互动模式的复杂变化对自主语音代理提出了核心挑战，因为它们旨在无需实验者参与的情况下进行操作。然而，我们的研究表明，基于LLM的语音代理在处理这些动态时展现出一定的能力和灵活性。这强调了利用LLM作为对话代理来有效应对复杂人类询问的潜力。'
- en: 'Furthermore, we observed that participants consistently employed social protocols
    [[94](https://arxiv.org/html/2406.10590v1#bib.bib94)] with an informal tone when
    interacting with the Vanilla and Assistant agents, but such occurrences were rare
    with the Expert (Section [6.4.3](https://arxiv.org/html/2406.10590v1#S6.SS4.SSS3
    "6.4.3 Social protocol ‣ 6.4 Conversational styles ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")). Additionally, there was
    a notable difference in the length of utterances and turn-taking behaviour (Section
    [6.3](https://arxiv.org/html/2406.10590v1#S6.SS3 "6.3 Dialogue analysis of the
    voice-based human-agent interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific
    Voice Agents: The Case of TextileBot")). Participants had shorter utterances and
    engaged in more turn-taking with the Assistant agent, while the Expert agent exhibited
    the opposite pattern. These changes in participant social protocols, utterance
    length, and turn-taking behaviour suggest that the level of engagement varies
    across these three agents. It is worth noting that all three TextileBots are mediated
    by the same LLM, with the only distinction being the prompts provided. This further
    confirmed the effectiveness of our three-phase prompt design as illustrated in
    Section [6.2.1](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS1 "6.2.1 Preferences
    and experiences across voice agents ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"), and highlights that prompting
    strategies can effectively shape the personalities and capabilities of voice agents,
    thereby directly influencing user engagement.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们观察到，参与者在与 Vanilla 和 Assistant 代理进行互动时，一致采用了带有非正式语气的社交协议[[94](https://arxiv.org/html/2406.10590v1#bib.bib94)]，但在与
    Expert 代理互动时，这种情况较为罕见（参见[6.4.3节](https://arxiv.org/html/2406.10590v1#S6.SS4.SSS3
    "6.4.3 社交协议 ‣ 6.4 会话风格 ‣ 6 结果 ‣ LLM介导的领域特定语音代理：以TextileBot为例")）。此外，参与者的发言长度和轮次行为存在显著差异（参见[6.3节](https://arxiv.org/html/2406.10590v1#S6.SS3
    "6.3 基于语音的人机互动对话分析 ‣ 6 结果 ‣ LLM介导的领域特定语音代理：以TextileBot为例")）。参与者在与 Assistant 代理互动时，发言较短，并且更多地进行轮次交替，而与
    Expert 代理互动时则表现出相反的模式。这些参与者社交协议、发言长度和轮次行为的变化表明，这三种代理的参与程度存在差异。值得注意的是，所有三种 TextileBot
    都是由相同的 LLM 媒介，仅区别在于所提供的提示语。这进一步验证了我们三阶段提示设计的有效性，如[6.2.1节](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS1
    "6.2.1 语音代理的偏好与体验 ‣ 6.2 总体反馈 ‣ 6 结果 ‣ LLM介导的领域特定语音代理：以TextileBot为例")中所示，并突显了提示策略可以有效塑造语音代理的个性与能力，从而直接影响用户参与度。
- en: 7.3 Optimizing LLM-mediated voice agent design for specific domains
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 优化LLM介导的领域特定语音代理设计
- en: In the previous two sections, we elaborated on the feasibility of prompting
    LLM to develop domain specific voice agents. We also noted that the prompt design
    of these voice agents critically influences user interaction. This section first
    focuses on key aspects that enhance voice agent design, specifically aiming to
    improve user engagement and the overall experience. Then summarize the lessons
    learned in using LLM for conversational agent design.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两节中，我们详细阐述了利用 LLM 开发领域特定语音代理的可行性。同时，我们也指出，语音代理的提示设计对用户互动起着至关重要的作用。本节首先聚焦于增强语音代理设计的关键方面，特别是旨在提高用户参与度和整体体验。然后，总结使用
    LLM 进行会话代理设计的经验教训。
- en: 7.3.1 Enhancing the voice agent design
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.1 增强语音代理设计
- en: Agent characteristic and user preference
  id: totrans-294
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代理特征与用户偏好
- en: 'Participants’ preferences and interaction styles were notably influenced by
    the perceived personality and characteristics of the agents. Our results indicate
    that a greater number of participants showed increased interest in the Assistant
    agent (56.7% for Assistant, 53.3% for Vallina and 36.7% for Expert), as illustrated
    in Section [6.1](https://arxiv.org/html/2406.10590v1#S6.SS1.SSS0.Px3 "Ease to
    use and Interest change over time ‣ 6.1 Questionnaire results ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"). This preference was further
    evidenced by more user interactions with the Assistant agent and fewer with the
    Expert, as detailed in Section [6.3.1](https://arxiv.org/html/2406.10590v1#S6.SS3.SSS1
    "6.3.1 Conversation turns ‣ 6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot"). A primary factor for this preference was the agents’ conversational
    styles, with participants favouring the “human-like” response from the Assistant
    and Vanilla agents. In contrast, the Expert, characterized by a more “expert”
    tone, was less favourably received, with participants likening it to a “text-book”
    (P25) or a “smart microwave” (P10) in their feedback (Section [6.2.1](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS1
    "6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")).
    Vanilla, while popular for its conversational freedom, faced criticism for occasional
    microaggressions and off-topic remarks, making it less suitable for specific applications
    like TextileBot, as discussed in Section [7.3.2](https://arxiv.org/html/2406.10590v1#S7.SS3.SSS2
    "7.3.2 Lessons Learned for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated
    voice agent design for specific domains ‣ 7 Discussion & Future Directions ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"). Furthermore, participants
    expressed a desire for more “emotions embedded” within agent conversations (e.g.
    humour, jokes) [[61](https://arxiv.org/html/2406.10590v1#bib.bib61), [62](https://arxiv.org/html/2406.10590v1#bib.bib62),
    [101](https://arxiv.org/html/2406.10590v1#bib.bib101)] in Section [6.2.3](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS3
    "6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot"), implying a stronger preference
    for human-agent interactions that emulate human-like communication. Overall, we
    noticed that an appropriate level of prompting, e.g. add more social ability,
    can enhance user engagement, as seen with the Assistant (Section [6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")). However, it is crucial to strike a balance, overemphasis
    on domain-specific details, as seen in the Expert, can detract from user engagement.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '参与者的偏好和互动风格明显受到代理人感知的人格和特征的影响。我们的结果表明，更多的参与者对助手代理人表现出更高的兴趣（助手为56.7%，香草为53.3%，专家为36.7%），如第[6.1](https://arxiv.org/html/2406.10590v1#S6.SS1.SSS0.Px3
    "Ease to use and Interest change over time ‣ 6.1 Questionnaire results ‣ 6 Results
    ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")节所示。这种偏好通过更多的用户与助手代理人的互动以及与专家代理人的互动较少得到了进一步验证，具体内容见第[6.3.1](https://arxiv.org/html/2406.10590v1#S6.SS3.SSS1
    "6.3.1 Conversation turns ‣ 6.3 Dialogue analysis of the voice-based human-agent
    interaction ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case
    of TextileBot")节。参与者偏好的一个主要因素是代理人的对话风格，参与者更喜欢助手和香草代理人提供的“类人”回应。相比之下，专家代理人由于采用更为“专家”化的语气，受到的欢迎程度较低，参与者在反馈中将其比作“教科书”（P25）或“智能微波炉”（P10）（第[6.2.1](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS1
    "6.2.1 Preferences and experiences across voice agents ‣ 6.2 Overall feedback
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot")节）。香草代理人因其对话自由度高而受到欢迎，但也因偶尔的微攻击性言辞和跑题评论而受到批评，使其不太适合像TextileBot这样的特定应用，如第[7.3.2](https://arxiv.org/html/2406.10590v1#S7.SS3.SSS2
    "7.3.2 Lessons Learned for design LLM-mediated voice agent ‣ 7.3 Optimizing LLM-mediated
    voice agent design for specific domains ‣ 7 Discussion & Future Directions ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")节所讨论的那样。此外，参与者表示希望代理人的对话中能够更多地“融入情感”（例如幽默、笑话）[[61](https://arxiv.org/html/2406.10590v1#bib.bib61),
    [62](https://arxiv.org/html/2406.10590v1#bib.bib62), [101](https://arxiv.org/html/2406.10590v1#bib.bib101)]，这一点在第[6.2.3](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS3
    "6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")节中得到了体现，这也表明参与者更偏好模拟人类沟通的类人-代理人互动。总体而言，我们注意到，适当的提示水平，例如增加更多的社交能力，可以增强用户参与感，如助手所示（第[6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")节）。然而，至关重要的是要找到平衡点，过度强调领域特定细节（如专家代理人所示）可能会削弱用户参与感。'
- en: Short answers in a conversation
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话中的简短回答
- en: We had this feedback during the pilot study, to further investigate this issue,
    we prompted Assistant to respond in limited words (short answer) to distinguish
    from others. Participants frequently commented on the verbosity of responses from
    the Expert with some expressing a desire for a feature to speed up or stop lengthy
    replies *“I wish there is a speed up and stop button.”*. This suggests that while
    detailed responses can be informative, they may overwhelm users in conversational
    contexts. Moreover, the use of ChatGPT as a foundational model for voice agents
    should be approached cautiously due to its tendency for verbosity, a result of
    training biases favouring more comprehensive answers [[87](https://arxiv.org/html/2406.10590v1#bib.bib87),
    [34](https://arxiv.org/html/2406.10590v1#bib.bib34)].
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在试点研究中，我们收到了这一反馈，为了进一步调查这个问题，我们提示助手用简短的词语（简短回答）来回应，以区分其他回答。参与者频繁评论专家回答的冗长，部分人表示希望有一个加速或停止冗长回答的功能，*“我希望有一个加速和停止按钮。”*这表明，尽管详细的回答可以提供信息，但它们可能在对话环境中让用户感到不堪重负。此外，由于ChatGPT作为语音助手基础模型存在冗长的倾向，这一倾向源于训练偏好更全面回答的偏向，因此应谨慎使用[[87](https://arxiv.org/html/2406.10590v1#bib.bib87),
    [34](https://arxiv.org/html/2406.10590v1#bib.bib34)]。
- en: Avoid repeating and being persuasive
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 避免重复和过于说服
- en: 'Some participants expressed that when the agent repeatedly states the same
    domain specific content or attempts to be overly persuasive (Section [6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents:
    The Case of TextileBot")), their engagement with the conversation decreases. This
    issue, though sometimes inevitable in educational or specialized domains, highlights
    the need for designing voice agents with diverse and balanced responses to sustain
    user interest and trust.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参与者表示，当语音助手重复陈述相同的领域特定内容或过于试图说服用户时（第[6.2](https://arxiv.org/html/2406.10590v1#S6.SS2
    "6.2 总体反馈 ‣ 6 结果 ‣ LLM驱动的领域特定语音助手：以TextileBot为例")节），他们与对话的参与度降低。这个问题，虽然在教育或专业领域中有时不可避免，但突出了设计具有多样化和均衡回应的语音助手的必要性，以维持用户的兴趣和信任。
- en: Interactive dialogue - ask back and interrupt
  id: totrans-300
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 互动对话 - 回问和打断
- en: 'Based on feedback from participants (Section LABEL:), we found that they felt
    most engaged when the agent actively asked questions, indicating a preference
    for interactive dialogue. Our participants found the conversation with TextileBot
    Expert and Assistant to be more intelligent than Google Assistant or Alexa, in
    part due to its memory function, which is achieved through our System Optimization
    (Section [3.3](https://arxiv.org/html/2406.10590v1#S3.SS3 "3.3 Phase 3: Enable
    continuous LLM interaction with memory through System Optimization ‣ 3 Prototyping
    Domain-Specific Voice Agents ‣ LLM-Mediated Domain-Specific Voice Agents: The
    Case of TextileBot")). Moreover, a critical aspect of natural conversation is
    the ability to interrupt and interact fluidly [[46](https://arxiv.org/html/2406.10590v1#bib.bib46)].
    Participants emphasized that voice agents lacking this feature fail to provide
    a truly conversational experience (Section [6.2.3](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS3
    "6.2.3 Suggestions for improvements ‣ 6.2 Overall feedback ‣ 6 Results ‣ LLM-Mediated
    Domain-Specific Voice Agents: The Case of TextileBot")). Therefore, integrating
    the ability for interactive dialogue is desired for enhancing user engagement.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 根据参与者的反馈（第LABEL节），我们发现当语音助手主动提问时，参与者感觉最为投入，这表明他们偏好互动对话。我们的参与者发现，与TextileBot专家和助手的对话比Google
    Assistant或Alexa更智能，部分原因在于其记忆功能，这一功能通过我们的系统优化（第[3.3](https://arxiv.org/html/2406.10590v1#S3.SS3
    "3.3 阶段3：通过系统优化实现与记忆的持续LLM交互 ‣ 3 领域特定语音助手原型 ‣ LLM驱动的领域特定语音助手：以TextileBot为例")节）实现。此外，自然对话的一个关键方面是能够流畅地打断和互动[[46](https://arxiv.org/html/2406.10590v1#bib.bib46)]。参与者强调，缺乏这一功能的语音助手无法提供真正的对话体验（第[6.2.3](https://arxiv.org/html/2406.10590v1#S6.SS2.SSS3
    "6.2.3 改进建议 ‣ 6.2 总体反馈 ‣ 6 结果 ‣ LLM驱动的领域特定语音助手：以TextileBot为例")节）。因此，整合互动对话能力对于提升用户参与度是必要的。
- en: 7.3.2 Lessons Learned for design LLM-mediated voice agent
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.2 设计LLM驱动语音助手的经验教训
- en: We distil key lessons from our experiences in employing LLMs for developing
    voice agents, highlighting their benefits and limitations.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总结了使用LLMs开发语音助手的经验教训，突出了它们的优点和局限性。
- en: Fault tolerance
  id: totrans-304
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 容错性
- en: 'A significant advantage of utilizing prompted LLMs in CAs is their capacity
    for fault tolerance, particularly in correcting errors from other components like
    Automatic Speech Recognition (ASR). Our case study in textile circularity exemplifies
    this. Prompt-based agents, such as Expert and Assistant, successfully corrected
    a considerable number of ASR misrecognitions. For instance, the term ‘textile
    circularity’ was often misheard as ‘texas secularity’, ‘textile/test security’,
    or ‘regularity’, with such errors present in 62% of ASR error instances (Section
    LABEL:). Nevertheless, our Expert and Assistant reliably redirected the conversation
    back to relevant topics related to textile circularity. In contrast, the Vanilla
    showed limitations, often leading to irrelevant content and disappointing participants.
    This highlights the benefit of domain-specific awareness in LLMs, which not only
    enhances their understanding of the intended subject matter but also significantly
    improves the fault tolerance of voice agent architectures. For a more in-depth
    analysis of participant encounters with ASR errors, we discussed it in Section
    [6.5](https://arxiv.org/html/2406.10590v1#S6.SS5 "6.5 Human behaviour and reactions
    ‣ 6 Results ‣ LLM-Mediated Domain-Specific Voice Agents: The Case of TextileBot").'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话代理（CAs）中利用提示式LLMs的一个显著优势是它们的容错能力，特别是在纠正其他组件（如自动语音识别（ASR））错误方面。我们的纺织循环性案例研究就体现了这一点。基于提示的代理，如Expert和Assistant，成功地纠正了大量的ASR误识别。例如，术语“纺织循环性”常常被误听为“德克萨斯世俗性”、“纺织/测试安全性”或“常规性”，在62%的ASR错误实例中出现了此类错误（详见第LABEL节）。然而，我们的Expert和Assistant始终能将对话引导回与纺织循环性相关的主题。相比之下，Vanilla表现出了局限性，常常导致无关内容，并让参与者感到失望。这突显了LLMs在特定领域意识方面的优势，它不仅增强了它们对目标主题的理解，还显著提高了语音代理架构的容错能力。关于参与者与ASR错误的互动的更深入分析，我们在第[6.5节](https://arxiv.org/html/2406.10590v1#S6.SS5
    "6.5 人类行为与反应 ‣ 6 结果 ‣ LLM介导的特定领域语音代理：以TextileBot为例")中进行了讨论。
- en: Neutrality
  id: totrans-306
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 中立性
- en: Although recent advances in LLMs have opened up many new possibilities; however,
    they have also raised significant worries and concerns. Not only is there a fear
    of the potential harmful contents these models could produce, but the model’s
    outputs are potentially biased [[11](https://arxiv.org/html/2406.10590v1#bib.bib11),
    [55](https://arxiv.org/html/2406.10590v1#bib.bib55), [18](https://arxiv.org/html/2406.10590v1#bib.bib18),
    [36](https://arxiv.org/html/2406.10590v1#bib.bib36)]. For example, in our case,
    we must instruct the model to “provide a sustainable clothing suggestion regardless
    of gender”. This is because, based on our pilot study, we found that when giving
    dressing suggestions, the model is not gender-neutral and has an obvious bias.
    The model always gives dressing suggestions with a female outlook. We also observed
    that LLMs are not politically neutral; one of our participants asked a question
    “Who has a more fashionable leader, China or Russia?” The agent consistently condemned
    the outfit of Putin. Drawing from our experience, we found that prompting may
    help mitigate the generation of biased content (e.g. gender-neutrality) from the
    LLM. However, it is difficult to completely restrict all forms of biases, as bias
    can manifest in many different ways.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管近期大规模语言模型（LLMs）的进展为许多新可能性打开了大门，但它们也引发了许多重要的担忧和问题。不仅人们担心这些模型可能生成有害的内容，而且模型的输出也可能存在偏见[[11](https://arxiv.org/html/2406.10590v1#bib.bib11)、[55](https://arxiv.org/html/2406.10590v1#bib.bib55)、[18](https://arxiv.org/html/2406.10590v1#bib.bib18)、[36](https://arxiv.org/html/2406.10590v1#bib.bib36)]。例如，在我们的案例中，我们必须指示模型“提供无关性别的可持续服装建议”。这是因为根据我们的初步研究，我们发现当给出穿衣建议时，模型并非性别中立，存在明显的偏见。模型总是给出带有女性化视角的穿衣建议。我们还观察到，LLMs并非在政治上保持中立；我们的一个参与者曾提问：“谁的领导人更时尚，中国还是俄罗斯？”该代理始终批评普京的穿着。通过我们的经验，我们发现适当的提示可以帮助缓解LLM生成偏见内容（例如，性别中立性）的情况。然而，完全限制所有形式的偏见是困难的，因为偏见可能以许多不同的方式表现出来。
- en: Micro-aggression
  id: totrans-308
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 微侵犯
- en: Another concern is the LLM’s propensity to generate content with micro-aggression,
    as reported by three participants who found the Vanilla somewhat aggressive or
    mean. Previous research in this area has revealed that the content generated by
    LLMs can contain micro-aggression [[47](https://arxiv.org/html/2406.10590v1#bib.bib47),
    [13](https://arxiv.org/html/2406.10590v1#bib.bib13)]. Properly crafted prompts
    can significantly reduce such negative occurrences, as seen in Assistant and Expert;
    thus, a strict prompting protocol is almost essential to prevent such issues.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是LLM生成带有微侵犯倾向的内容，正如三位参与者所反映的那样，他们认为“Vanilla”代理有些带有攻击性或刻薄。先前的研究已表明，LLM生成的内容可能包含微侵犯[[47](https://arxiv.org/html/2406.10590v1#bib.bib47),
    [13](https://arxiv.org/html/2406.10590v1#bib.bib13)]。通过精心设计的提示词可以显著减少此类负面现象，正如在助手和专家代理中所见。因此，严格的提示词协议几乎是必需的，以防止此类问题的发生。
- en: 7.4 Limitations and future work
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 局限性与未来工作
- en: As our study is a first study in LLM-based voice agent, we highlighted a few
    limitations in our data, method and findings.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的研究是基于大型语言模型（LLM）的语音代理领域的首次研究，因此我们在数据、方法和发现中突出了几个局限性。
- en: Firstly, our findings uncovered the existence of variations in participant preferences
    with respect to the voice agents. A small group of participants exhibited a preference
    for the responses of the Expert agent due to its perceived level of detail. However,
    we also intuitively suspect that factors such as participant backgrounds, their
    professions and past experiences may have influenced this preference. To obtain
    a clearer understanding of this relationship, it could be beneficial to implement
    a larger-scale study involving a diverse participant pool. In relation to this,
    we see considerable potential in incorporating participants’ psychological traits,
    such as extroversion and introversion, along with their demographic attributes
    [[30](https://arxiv.org/html/2406.10590v1#bib.bib30), [97](https://arxiv.org/html/2406.10590v1#bib.bib97)]
    in future studies. We did not explore this research dimension, but it could offer
    critical insights into the correlations between a user’s conversational habits
    and their engagement with voice agents.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们的研究发现揭示了参与者在语音代理偏好上的差异。一小部分参与者倾向于选择专家代理的回答，因为他们认为专家代理的回答更为详尽。然而，我们也直觉地怀疑，参与者的背景、职业和过往经历等因素可能会影响这种偏好。为了更清晰地理解这种关系，进行一个更大规模的研究，涵盖更广泛的参与者群体，将是有益的。在这方面，我们认为将参与者的心理特征（如外向性和内向性）以及他们的
    demographic 属性[[30](https://arxiv.org/html/2406.10590v1#bib.bib30), [97](https://arxiv.org/html/2406.10590v1#bib.bib97)]纳入未来的研究中，具有相当大的潜力。我们没有探索这一研究维度，但它可能为用户的对话习惯与他们与语音代理互动之间的关系提供关键的见解。
- en: Secondly, we excluded voice data due to ethical considerations. However, that
    is inevitably limiting our ability to tap into the wealth of insights offered
    by non-verbal cues (e.g. pitch, tone), particularly when it comes to analysing
    emotional facets (e.g. frustration, anger) as part of conversational styles [[84](https://arxiv.org/html/2406.10590v1#bib.bib84),
    [76](https://arxiv.org/html/2406.10590v1#bib.bib76)]. Despite this limitation,
    our work aligns with existing HCI research methods in CAs, encompassing both text
    and voice-based interactions. Accordingly, this limitation can be seen as an opportunity
    for future research to consider both verbal and non-verbal data for a more comprehensive
    understanding of voice-based conversations and interactions.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，由于伦理考虑，我们排除了语音数据。然而，这无可避免地限制了我们从非语言线索（例如音高、语调）中获得的深刻见解，特别是在分析情感方面（例如挫败感、愤怒）作为对话风格的一部分时[[84](https://arxiv.org/html/2406.10590v1#bib.bib84),
    [76](https://arxiv.org/html/2406.10590v1#bib.bib76)]。尽管存在这一局限性，我们的工作仍然与现有的HCI研究方法在CA（对话代理）领域相符，涵盖了文本和基于语音的交互。因此，这一局限性可以被视为未来研究的一个机会，考虑同时利用语言和非语言数据，以更全面地理解基于语音的对话和互动。
- en: Thirdly, a subset of participants (N=4) have reported that the text-to-speech
    (TTS) voice adopted by TextileBot was too robotic, leading to less engagement.
    In general, the optimization of speech naturalness and accuracy emerged as key
    expectations from voice agents [[107](https://arxiv.org/html/2406.10590v1#bib.bib107)].
    This feedback serves as useful design guidance for voice agents aiming for improved
    engagement and user satisfaction. Future research could then delve into advanced
    neural speech synthesis (neural TTS) [[59](https://arxiv.org/html/2406.10590v1#bib.bib59)]
    with varied genders and accents for personalizing the voice agent.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，一部分参与者（N=4）报告称，TextileBot采用的语音合成（TTS）声音过于机械，导致互动感降低。通常，语音代理优化语音自然性和准确性成为了关键的期望[[107](https://arxiv.org/html/2406.10590v1#bib.bib107)]。这一反馈为语音代理的设计提供了有价值的指导，旨在提升用户参与度和满意度。未来的研究可以深入探讨先进的神经语音合成（神经TTS）[[59](https://arxiv.org/html/2406.10590v1#bib.bib59)]，通过不同的性别和口音来个性化语音代理。
- en: Fourthly, the agent interactions are based on a lab-based, single session. Although
    our study gave us already a richness of data and insights, an extended and repeated
    interaction with the different agents, both inside and outside laboratory environments
    would be desirable. This could provide a more nuanced understanding of the observed
    changes over time and user experiences [[93](https://arxiv.org/html/2406.10590v1#bib.bib93)].
    Participants’ feedback further underlines this, as they suggested an initial increase
    in both engagement and interaction as the familiarity with the agent grew; however,
    this engagement was noted to decline towards the end of the study.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 第四，代理交互是基于实验室环境中的单次会话。尽管我们的研究已经提供了丰富的数据和洞见，但与不同代理的延长和重复交互，无论是在实验室内外的环境中，都是可取的。这可以提供对随时间变化的观察结果和用户体验的更细致理解[[93](https://arxiv.org/html/2406.10590v1#bib.bib93)]。参与者的反馈进一步强调了这一点，他们建议随着对代理的熟悉度增加，最初的参与度和互动性会有所提升；然而，这种参与感在研究的后期有所下降。
- en: Lastly, three participants reported that the Vanilla TextileBot was slightly
    aggressive or potentially disrespectful. Previous research in this area has revealed
    that the content generated by LLMs can contain micro-aggression [[47](https://arxiv.org/html/2406.10590v1#bib.bib47),
    [13](https://arxiv.org/html/2406.10590v1#bib.bib13)]. Our other participants did
    not report this when the LLM is prompted appropriately; thus, a strict prompting
    protocol is almost essential to prevent such issues. Further exploration is needed
    to develop robust mechanisms that can reliably identify and prevent such offensive
    outputs, ensuring a safer and more respectful user experience.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，三位参与者报告称，Vanilla TextileBot 有些过于激进或可能显得不尊重。该领域的先前研究表明，LLM（大规模语言模型）生成的内容可能包含微侵犯行为[[47](https://arxiv.org/html/2406.10590v1#bib.bib47),
    [13](https://arxiv.org/html/2406.10590v1#bib.bib13)]。当LLM被适当提示时，我们的其他参与者并未报告此问题；因此，严格的提示协议几乎是避免此类问题的必要措施。需要进一步探索以开发能够可靠识别并防止此类冒犯性输出的机制，从而确保用户体验更加安全和尊重。
- en: 8 Conclusion
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: 'In this paper, we introduce a novel three-phase method to prototype domain-specific
    voice agents using prompted LLMs. Our method is structured into three phases:
    (1) imbuing LLM with domain-specific knowledge by using Taxonomy-based Knowledge
    Structure Chain; (2) transitioning the LLM from task-agnostic to domain-specific
    focused including altering the conversational style, through prompting refinements,
    and (3) integrating system optimization to allow dialogue memorization. These
    phases are flexible and can be used independently or collectively to customize
    the LLM for particular tasks. We showcase our method with TextileBot, a voice
    agent designed for discussions on textile circularity, developed in three versions:
    Vanilla, Assistant, and Expert, each providing unique conversational features.
    To evaluate the effectiveness of these LLM-powered voice agents, we conducted
    an in-person user study. Our results showed that most participants engaged in
    multi-turn conversations with the agents, with their perceptions and behaviours
    significantly differing across the three versions. The descriptive user feedback
    with three agents aligned with our design intentions, confirming the efficacy
    of our approach in developing prompt-based voice agents. Key findings from the
    study highlight a preference for voice agents that offer concise, non-repetitive,
    and interactive dialogues. This includes the ability to ask questions, interrupt,
    and remember past conversations. Additionally, participants expressed a preference
    for agents that exhibit human-like qualities, such as humour. In the subsequent
    discussion in the paper, we shared insights and experiences related to enhancing
    voice agent design, along with a discussion of the challenges and lessons learned
    when utilizing LLMs in designing voice-based CAs. We delve into the nuances of
    these interactions and their implications for the future development of voice-based
    CAs in HCI to offer a broader scope of voice interfaces across various domains.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一种新颖的三阶段方法，用于使用提示式大型语言模型（LLMs）原型化领域特定的语音助手。我们的方法分为三个阶段：（1）通过使用基于分类法的知识结构链将领域特定知识注入LLM；（2）通过提示优化将LLM从任务无关转变为领域特定焦点，包括改变对话风格；（3）集成系统优化，允许对话记忆。这些阶段具有灵活性，可以单独使用，也可以结合使用，以便为特定任务定制LLM。我们用TextileBot展示了我们的方法，TextileBot是一个用于纺织品循环性讨论的语音助手，开发了三个版本：Vanilla、Assistant和Expert，每个版本提供独特的对话功能。为了评估这些基于LLM的语音助手的有效性，我们进行了现场用户研究。我们的结果显示，大多数参与者与这些助手进行了多轮对话，且他们的认知和行为在三个版本之间有显著差异。三种版本的描述性用户反馈与我们的设计意图一致，验证了我们在开发基于提示的语音助手方法的有效性。研究的关键发现强调了用户偏好简洁、非重复且互动性强的对话语音助手。这包括能够提问、打断和记住过去的对话内容。此外，参与者表达了对具有类人特质的助手的偏好，如幽默感。在文中的后续讨论部分，我们分享了与提升语音助手设计相关的见解和经验，并讨论了在利用LLM设计语音对话系统时遇到的挑战和经验教训。我们深入探讨了这些互动的细微差别及其对未来在HCI领域语音对话系统发展的意义，旨在为各个领域提供更广泛的语音界面。
- en: Acknowledgments and Disclosure of Funding
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢与资金披露
- en: This work was supported by the UK Research and Innovation (UKRI) National Interdisciplinary
    Circular Economy Centres Research programme, as part of the Textiles Circularity
    Centre (TCC) [grant number EP/V011766/1]. For the purpose of open access, the
    author has applied a Creative Commons Attribution (CC BY) licence to any Author
    Accepted Manuscript version arising.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了英国研究与创新局（UKRI）国家跨学科循环经济中心研究计划的资助，作为纺织品循环性中心（TCC）的一部分，[资助号 EP/V011766/1]。为了实现开放获取，作者已将创作共享许可（CC
    BY）应用于任何由作者接受的手稿版本。
- en: References
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Google aiy voice kit V1. https://aiyprojects.withgoogle.com/, 2017.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Google AIY Voice Kit V1. https://aiyprojects.withgoogle.com/，2017年。'
- en: '[2] Google/aiyprojects-raspbian. https://github.com/google/aiyprojects-raspbian/releases,
    2021.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Google/aiyprojects-raspbian. https://github.com/google/aiyprojects-raspbian/releases，2021年。'
- en: '[3] OpenAI Cookbook - Techniques to improve reliability. OpenAI, 2023.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] OpenAI Cookbook - 提高可靠性的技巧。OpenAI，2023年。'
- en: '[4] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn,
    K. Gopalakrishnan, K. Hausman, A. Herzog, et al. Do as i can, not as i say: Grounding
    language in robotic affordances. arXiv preprint arXiv:2204.01691, 2022.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn,
    K. Gopalakrishnan, K. Hausman, A. Herzog 等人. Do as I can, not as I say: Grounding
    language in robotic affordances. arXiv 预印本 arXiv:2204.01691，2022年。'
- en: '[5] M. Allouch, A. Azaria, and R. Azoulay. Conversational agents: Goals, technologies,
    vision and challenges. Sensors, 21(24):8448, 2021.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] M. Allouch, A. Azaria, 和 R. Azoulay。对话代理：目标、技术、愿景与挑战。《传感器》，21(24):8448，2021年。'
- en: '[6] S. Arora, A. Narayan, M. F. Chen, L. Orr, N. Guha, K. Bhatia, I. Chami,
    F. Sala, and C. Ré. Ask Me Anything: A simple strategy for prompting language
    models, 2022.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] S. Arora, A. Narayan, M. F. Chen, L. Orr, N. Guha, K. Bhatia, I. Chami,
    F. Sala 和 C. Ré。《随便问我什么：一种简单的语言模型提示策略》，2022年。'
- en: '[7] M. A. Bansal, D. R. Sharma, and D. M. Kathuria. A systematic review on
    data scarcity problem in deep learning: solution and applications. ACM Computing
    Surveys (CSUR), 54(10s):1–29, 2022.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] M. A. Bansal, D. R. Sharma 和 D. M. Kathuria。《深度学习中的数据稀缺问题：解决方案与应用的系统综述》。ACM计算调查（CSUR），54(10s):1–29，2022年。'
- en: '[8] S. Barke, M. B. James, and N. Polikarpova. Grounded copilot: How programmers
    interact with code-generating models. arXiv preprint arXiv:2206.15000, 2022.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] S. Barke, M. B. James 和 N. Polikarpova。《基础副驾驶：程序员如何与代码生成模型互动》。arXiv预印本arXiv:2206.15000，2022年。'
- en: '[9] A. Baughan, X. Wang, A. Liu, A. Mercurio, J. Chen, and X. Ma. A mixed-methods
    approach to understanding user trust after voice assistant failures. In Proceedings
    of the 2023 CHI Conference on Human Factors in Computing Systems, pages 1–16,
    2023.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] A. Baughan, X. Wang, A. Liu, A. Mercurio, J. Chen 和 X. Ma。了解用户在语音助手失败后的信任：一种混合方法的研究。在《2023年CHI计算机系统中的人类因素会议论文集》中，第1–16页，2023年。'
- en: '[10] R. Bavaresco, D. Silveira, E. Reis, J. Barbosa, R. Righi, C. Costa, R. Antunes,
    M. Gomes, C. Gatti, M. Vanzin, et al. Conversational agents in business: A systematic
    literature review and future research directions. Computer Science Review, 36:100239,
    2020.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] R. Bavaresco, D. Silveira, E. Reis, J. Barbosa, R. Righi, C. Costa, R.
    Antunes, M. Gomes, C. Gatti, M. Vanzin 等人。商业中的对话代理：系统文献综述与未来研究方向。《计算机科学评论》，36:100239，2020年。'
- en: '[11] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell. On the dangers
    of stochastic parrots: Can language models be too big? In Proceedings of the 2021
    ACM Conference on Fairness, Accountability, and Transparency, pages 610–623, 2021.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] E. M. Bender, T. Gebru, A. McMillan-Major 和 S. Shmitchell。《随机鹦鹉的危险：语言模型会不会太大？》在《2021年ACM公平性、问责制与透明度会议论文集》中，第610–623页，2021年。'
- en: '[12] T. Bickmore and J. Cassell. Social dialongue with embodied conversational
    agents. Advances in natural multimodal dialogue systems, pages 23–54, 2005.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] T. Bickmore 和 J. Cassell。与具身对话代理的社交对话。《自然多模态对话系统进展》，第23–54页，2005年。'
- en: '[13] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx,
    M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities
    and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx,
    M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill 等人。《基础模型的机遇与风险》。arXiv预印本arXiv:2108.07258，2021年。'
- en: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners.
    Advances in neural information processing systems, 33:1877–1901, 2020.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell 等人。语言模型是少量示例学习者。《神经信息处理系统进展》，33:1877–1901，2020年。'
- en: '[15] B. E. Bullock and A. J. Toribio. Themes in the study of code-switching.
    The Cambridge handbook of linguistic code-switching, 117, 2009.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] B. E. Bullock 和 A. J. Toribio。语言切换研究中的主题。《剑桥语言切换手册》，第117页，2009年。'
- en: '[16] D. Buschek, M. Zürn, and M. Eiband. The impact of multiple parallel phrase
    suggestions on email input and composition behaviour of native and non-native
    english writers. In Proceedings of the 2021 CHI Conference on Human Factors in
    Computing Systems, pages 1–13, 2021.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] D. Buschek, M. Zürn 和 M. Eiband。多条并行短语建议对本地和非本地英语写作者的电子邮件输入和写作行为的影响。在《2021年CHI计算机系统中的人类因素会议论文集》中，第1–13页，2021年。'
- en: '[17] T. Chakrabarty, V. Padmakumar, and H. He. Help me write a poem: Instruction
    tuning as a vehicle for collaborative poetry writing. arXiv preprint arXiv:2210.13669,
    2022.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] T. Chakrabarty, V. Padmakumar 和 H. He。《帮我写首诗：指令调优作为协作诗歌写作的工具》。arXiv预印本arXiv:2210.13669，2022年。'
- en: '[18] K. Chen, A. Shao, J. Burapacheep, and Y. Li. A critical appraisal of equity
    in conversational AI: Evidence from auditing GPT-3’s dialogues with different
    publics on climate change and Black Lives Matter, 2022.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] K. Chen, A. Shao, J. Burapacheep 和 Y. Li。《对话式AI公平性的批判性评估：来自审计GPT-3与不同公众就气候变化和“黑人的命也是命”对话的证据》，2022年。'
- en: '[19] X. Chen, N. Zhang, X. Xie, S. Deng, Y. Yao, C. Tan, F. Huang, L. Si, and
    H. Chen. Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization
    for relation extraction. In Proceedings of the ACM Web Conference 2022, pages
    2778–2788, 2022.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] X. Chen, N. Zhang, X. Xie, S. Deng, Y. Yao, C. Tan, F. Huang, L. Si 和
    H. Chen. Knowprompt：知识感知提示调优与协同优化用于关系抽取. 载于《2022年ACM网络会议论文集》，第2778-2788页，2022年。'
- en: '[20] R. H. B. Christensen. ordinal—regression models for ordinal data. R package
    version, 28:2015, 2015.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] R. H. B. Christensen. ordinal——用于有序数据的回归模型. R包版本，28:2015，2015年。'
- en: '[21] E. Clark, A. S. Ross, C. Tan, Y. Ji, and N. A. Smith. Creative writing
    with a machine in the loop: Case studies on slogans and stories. In 23rd International
    Conference on Intelligent User Interfaces, pages 329–340, 2018.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] E. Clark, A. S. Ross, C. Tan, Y. Ji 和 N. A. Smith. 与机器共同创作：关于标语和故事的案例研究.
    载于《第23届国际智能用户界面会议论文集》，第329-340页，2018年。'
- en: '[22] L. Clark, N. Pantidi, O. Cooney, P. Doyle, D. Garaialde, J. Edwards, B. Spillane,
    E. Gilmartin, C. Murad, C. Munteanu, et al. What makes a good conversation? challenges
    in designing truly conversational agents. In Proceedings of the 2019 CHI conference
    on human factors in computing systems, pages 1–12, 2019.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] L. Clark, N. Pantidi, O. Cooney, P. Doyle, D. Garaialde, J. Edwards, B.
    Spillane, E. Gilmartin, C. Murad, C. Munteanu 等人. 什么才算是一次好的对话？设计真正的对话代理面临的挑战.
    载于《2019年CHI人机交互大会论文集》，第1-12页，2019年。'
- en: '[23] M. Colucci, A. Tuan, and M. Visentin. An empirical investigation of the
    drivers of csr talk and walk in the fashion industry. Journal of Cleaner Production,
    248:119200, 2020.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] M. Colucci, A. Tuan 和 M. Visentin. 对时尚产业中CSR言行驱动因素的实证研究. 《清洁生产杂志》，248:119200，2020年。'
- en: '[24] J. Condliffe. Ai voice assistant apps are proliferating, but people don’t
    use them. Technology Review, 2017.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] J. Condliffe. AI语音助手应用程序正在激增，但人们却不使用它们. 《技术评论》，2017年。'
- en: '[25] B. R. Cowan, N. Pantidi, D. Coyle, K. Morrissey, P. Clarke, S. Al-Shehri,
    D. Earley, and N. Bandeira. ” what can i help you with?” infrequent users’ experiences
    of intelligent personal assistants. In Proceedings of the 19th international conference
    on human-computer interaction with mobile devices and services, pages 1–12, 2017.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] B. R. Cowan, N. Pantidi, D. Coyle, K. Morrissey, P. Clarke, S. Al-Shehri,
    D. Earley, 和 N. Bandeira. “我能帮你做什么？”不常使用的用户对智能个人助手的体验. 载于《第19届国际人机交互与移动设备及服务会议论文集》，第1-12页，2017年。'
- en: '[26] N. Dahlbäck, A. Jönsson, and L. Ahrenberg. Wizard of oz studies—why and
    how. Knowledge-based systems, 6(4):258–266, 1993.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] N. Dahlbäck, A. Jönsson 和 L. Ahrenberg. “奥兹巫师”研究——为什么和如何. 《基于知识的系统》，6(4):258-266，1993年。'
- en: '[27] A. R. de Lacerda and C. S. Aguiar. Floss faq chatbot project reuse: how
    to allow nonexperts to develop a chatbot. In Proceedings of the 15th International
    Symposium on Open Collaboration, pages 1–8, 2019.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] A. R. de Lacerda 和 C. S. Aguiar. Floss FAQ聊天机器人项目重用：如何让非专家开发聊天机器人. 载于《第15届国际开放协作研讨会论文集》，第1-8页，2019年。'
- en: '[28] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of
    deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805,
    2018.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] J. Devlin, M.-W. Chang, K. Lee 和 K. Toutanova. BERT：用于语言理解的深度双向变换器的预训练.
    arXiv预印本arXiv:1810.04805，2018年。'
- en: '[29] L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, and
    H.-W. Hon. Unified language model pre-training for natural language understanding
    and generation. Advances in Neural Information Processing Systems, 32, 2019.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou 和
    H.-W. Hon. 统一语言模型预训练用于自然语言理解和生成. 《神经信息处理系统进展》，32，2019年。'
- en: '[30] P. R. Doyle, J. Edwards, O. Dumbleton, L. Clark, and B. R. Cowan. Mapping
    perceptions of humanness in intelligent personal assistant interaction. In Proceedings
    of the 21st international conference on human-computer interaction with mobile
    devices and services, pages 1–12, 2019.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] P. R. Doyle, J. Edwards, O. Dumbleton, L. Clark 和 B. R. Cowan. 映射智能个人助手交互中的人性感知.
    载于《第21届国际人机交互与移动设备及服务会议论文集》，第1-12页，2019年。'
- en: '[31] T. E. M. Foundation. Fashion and a circular economy — ellen macarthur
    foundation.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] T. E. M. Foundation. 时尚与循环经济 — 埃伦·麦克阿瑟基金会。'
- en: '[32] A. Frummet, D. Elsweiler, and B. Ludwig. “what can i cook with these ingredients?”-understanding
    cooking-related information needs in conversational search. ACM Transactions on
    Information Systems (TOIS), 40(4):1–32, 2022.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] A. Frummet, D. Elsweiler 和 B. Ludwig. “我能用这些食材做什么？”——理解对话搜索中与烹饪相关的信息需求.
    《ACM信息系统交易》（TOIS），40(4):1-32，2022年。'
- en: '[33] J. Fürnkranz. Round robin classification. The Journal of Machine Learning
    Research, 2:721–747, 2002.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] J. Fürnkranz. 循环分类. 《机器学习研究杂志》，2:721-747，2002年。'
- en: '[34] L. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization.
    arXiv preprint arXiv:2210.10760, 2022.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] L. Gao, J. Schulman, 和 J. Hilton. 奖励模型过度优化的规模法则。arXiv 预印本 arXiv:2210.10760,
    2022。'
- en: '[35] Google. Google Assistant, your own personal Google default. https://assistant.google.com/.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Google. Google Assistant，您个人的 Google 默认助手。https://assistant.google.com/。'
- en: '[36] N. Goyal, I. D. Kivlichan, R. Rosen, and L. Vasserman. Is Your Toxicity
    My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation. Proceedings
    of the ACM on Human-Computer Interaction, 6(CSCW2):363:1–363:28, 2022.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] N. Goyal, I. D. Kivlichan, R. Rosen, 和 L. Vasserman. 你的毒性是我的毒性吗？探索评估者身份对毒性标注的影响。《ACM人机交互学报》，6(CSCW2):363:1–363:28,
    2022。'
- en: '[37] I. Gupta, B. Di Eugenio, B. Ziebart, A. Baiju, B. Liu, B. Gerber, L. Sharp,
    N. Nabulsi, and M. Smart. Human-human health coaching via text messages: Corpus,
    annotation, and analysis. In Proceedings of the 21th Annual Meeting of the Special
    Interest Group on Discourse and Dialogue, pages 246–256, 2020.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] I. Gupta, B. Di Eugenio, B. Ziebart, A. Baiju, B. Liu, B. Gerber, L. Sharp,
    N. Nabulsi, 和 M. Smart. 通过短信进行人际健康辅导：语料库、注释和分析。发表于第21届话语与对话特殊兴趣小组年会论文集，页码 246–256,
    2020。'
- en: '[38] G. Haas, M. Rietzler, M. Jones, and E. Rukzio. Keep it short: A comparison
    of voice assistants’ response behavior. In Proceedings of the 2022 CHI Conference
    on Human Factors in Computing Systems, pages 1–12, 2022.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] G. Haas, M. Rietzler, M. Jones, 和 E. Rukzio. 保持简短：语音助手响应行为的比较。发表于2022年CHI计算机系统人因学会议论文集，页码
    1–12, 2022。'
- en: '[39] X. Han, W. Zhao, N. Ding, Z. Liu, and M. Sun. Ptr: Prompt tuning with
    rules for text classification. AI Open, 3:182–192, 2022.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] X. Han, W. Zhao, N. Ding, Z. Liu, 和 M. Sun. Ptr：基于规则的提示调优用于文本分类。AI Open,
    3:182–192, 2022。'
- en: '[40] C. N. Harrington, R. Garg, A. Woodward, and D. Williams. “it’s kind of
    like code-switching”: Black older adults’ experiences with a voice assistant for
    health information seeking. In Proceedings of the 2022 CHI Conference on Human
    Factors in Computing Systems, pages 1–15, 2022.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] C. N. Harrington, R. Garg, A. Woodward, 和 D. Williams. “这有点像代码切换”：黑人老年人使用语音助手获取健康信息的体验。发表于2022年CHI计算机系统人因学会议论文集，页码
    1–15, 2022。'
- en: '[41] R. Hoegen, D. Aneja, D. McDuff, and M. Czerwinski. An end-to-end conversational
    style matching agent. In Proceedings of the 19th ACM International Conference
    on Intelligent Virtual Agents, pages 111–118, 2019.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] R. Hoegen, D. Aneja, D. McDuff, 和 M. Czerwinski. 一种端到端的对话风格匹配代理。发表于第19届
    ACM国际智能虚拟代理会议论文集，页码 111–118, 2019。'
- en: '[42] T. Hunter. Siri and alexa are getting on their owners’ last nerves. the
    washington post, 2022.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] T. Hunter. Siri 和 Alexa 正在让它们的主人感到烦躁不安。《华盛顿邮报》，2022。'
- en: '[43] D. Ippolito, A. Yuan, A. Coenen, and S. Burnam. Creative writing with
    an ai-powered writing assistant: Perspectives from professional writers. arXiv
    preprint arXiv:2211.05030, 2022.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] D. Ippolito, A. Yuan, A. Coenen, 和 S. Burnam. 使用AI驱动的写作助手进行创意写作：来自专业作家的观点。arXiv
    预印本 arXiv:2211.05030, 2022。'
- en: '[44] B. Jan-Petter and J. J. Gumperz. Social meaning in linguistic structure:
    Code-switching in norway. In The bilingualism reader, pages 75–96\. Routledge,
    2020.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] B. Jan-Petter 和 J. J. Gumperz. 语言结构中的社会意义：挪威的代码切换。载于《双语读本》，页码 75–96。劳特利奇，2020。'
- en: '[45] E. Jiang, K. Olson, E. Toh, A. Molina, A. Donsbach, M. Terry, and C. J.
    Cai. PromptMaker: Prompt-based Prototyping with Large Language Models. In Extended
    Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems, CHI
    EA ’22, pages 1–8, New York, NY, USA, 2022\. Association for Computing Machinery.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] E. Jiang, K. Olson, E. Toh, A. Molina, A. Donsbach, M. Terry, 和 C. J.
    Cai. PromptMaker：基于提示的大型语言模型原型设计。在2022年CHI计算机系统人因学会议扩展摘要中，CHI EA ’22，页码 1–8，纽约，NY，美国，2022。计算机协会。'
- en: '[46] B. Jordan and A. Henderson. Interaction analysis: Foundations and practice.
    The journal of the learning sciences, 4(1):39–103, 1995.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] B. Jordan 和 A. Henderson. 互动分析：基础与实践。《学习科学期刊》，4(1):39–103, 1995。'
- en: '[47] D. Jurgens, E. Chandrasekharan, and L. Hemphill. A just and comprehensive
    strategy for using nlp to address online abuse. arXiv preprint arXiv:1906.01738,
    2019.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] D. Jurgens, E. Chandrasekharan, 和 L. Hemphill. 一种公正且全面的策略，利用 NLP 解决在线虐待问题。arXiv
    预印本 arXiv:1906.01738, 2019。'
- en: '[48] J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Raileanu, and R. McHardy.
    Challenges and applications of large language models. arXiv preprint arXiv:2307.10169,
    2023.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] J. Kaddour, J. Harris, M. Mozes, H. Bradley, R. Raileanu, 和 R. McHardy.
    大型语言模型的挑战与应用。arXiv 预印本 arXiv:2307.10169, 2023。'
- en: '[49] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language
    models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, 和 Y. Iwasawa. 大型语言模型是零-shot推理器.
    arXiv 预印本 arXiv:2205.11916, 2022年.'
- en: '[50] M. Krzywinski, N. Altman, and P. Blainey. Nested designs. Nature Methods,
    11(10):977–979, 2014.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] M. Krzywinski, N. Altman, 和 P. Blainey. 嵌套设计. 《自然方法》, 11(10):977–979,
    2014年.'
- en: '[51] S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra, and A. Abraham.
    Ai-based conversational agents: A scoping review from technologies to future directions.
    IEEE Access, 2022.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra, 和 A. Abraham.
    基于AI的对话代理：从技术到未来方向的范围审查. 《IEEE Access》, 2022年.'
- en: '[52] J. Lafferty, A. McCallum, and F. C. Pereira. Conditional random fields:
    Probabilistic models for segmenting and labeling sequence data. 2001.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] J. Lafferty, A. McCallum, 和 F. C. Pereira. 条件随机场：用于分割和标记序列数据的概率模型. 2001年.'
- en: '[53] P. Lambe. Organising knowledge: taxonomies, knowledge and organisational
    effectiveness. Elsevier, 2014.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] P. Lambe. 知识组织：分类法、知识与组织效能. Elsevier, 2014年.'
- en: '[54] M. Lee, P. Liang, and Q. Yang. Coauthor: Designing a human-ai collaborative
    writing dataset for exploring language model capabilities. In CHI Conference on
    Human Factors in Computing Systems, pages 1–19, 2022.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] M. Lee, P. Liang, 和 Q. Yang. Coauthor: 设计一个用于探索语言模型能力的人类与人工智能协作写作数据集.
    载于CHI人机交互系统会议论文集, 第1–19页, 2022年.'
- en: '[55] M. Lee, M. Srivastava, A. Hardy, J. Thickstun, E. Durmus, A. Paranjape,
    I. Gerard-Ursin, X. L. Li, F. Ladhak, F. Rong, et al. Evaluating human-language
    model interaction. arXiv preprint arXiv:2212.09746, 2022.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] M. Lee, M. Srivastava, A. Hardy, J. Thickstun, E. Durmus, A. Paranjape,
    I. Gerard-Ursin, X. L. Li, F. Ladhak, F. Rong 等人. 评估人类与语言模型的交互. arXiv 预印本 arXiv:2212.09746,
    2022.'
- en: '[56] P. Lee, S. Bubeck, and J. Petro. Benefits, limits, and risks of gpt-4
    as an ai chatbot for medicine. New England Journal of Medicine, 388(13):1233–1239,
    2023.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] P. Lee, S. Bubeck, 和 J. Petro. GPT-4作为医学领域AI聊天机器人的优势、局限性和风险. 《新英格兰医学杂志》,
    388(13):1233–1239, 2023年.'
- en: '[57] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov,
    and L. Zettlemoyer. Bart: Denoising sequence-to-sequence pre-training for natural
    language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461,
    2019.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V.
    Stoyanov, 和 L. Zettlemoyer. Bart: 用于自然语言生成、翻译和理解的去噪序列到序列预训练. arXiv 预印本 arXiv:1910.13461,
    2019年.'
- en: '[58] C.-H. Li, S.-F. Yeh, T.-J. Chang, M.-H. Tsai, K. Chen, and Y.-J. Chang.
    A conversation analysis of non-progress and coping strategies with a banking task-oriented
    chatbot. In Proceedings of the 2020 CHI Conference on Human Factors in Computing
    Systems, pages 1–12, 2020.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] C.-H. Li, S.-F. Yeh, T.-J. Chang, M.-H. Tsai, K. Chen, 和 Y.-J. Chang.
    一项关于银行任务导向聊天机器人的对话分析：非进展和应对策略. 载于2020年CHI人机交互系统会议论文集, 第1–12页, 2020年.'
- en: '[59] N. Li, S. Liu, Y. Liu, S. Zhao, and M. Liu. Neural speech synthesis with
    transformer network. In Proceedings of the AAAI conference on artificial intelligence,
    volume 33, pages 6706–6713, 2019.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] N. Li, S. Liu, Y. Liu, S. Zhao, 和 M. Liu. 基于神经网络的语音合成. 载于人工智能AAAI会议论文集,
    第33卷, 第6706–6713页, 2019年.'
- en: '[60] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang,
    D. Narayanan, Y. Wu, A. Kumar, et al. Holistic evaluation of language models.
    arXiv preprint arXiv:2211.09110, 2022.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y.
    Zhang, D. Narayanan, Y. Wu, A. Kumar 等人. 语言模型的整体评估. arXiv 预印本 arXiv:2211.09110,
    2022.'
- en: '[61] Q. V. Liao, M. Davis, W. Geyer, M. Muller, and N. S. Shami. What can you
    do? studying social-agent orientation and agent proactive interactions with an
    agent for employees. In Proceedings of the 2016 acm conference on designing interactive
    systems, pages 264–275, 2016.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Q. V. Liao, M. Davis, W. Geyer, M. Muller, 和 N. S. Shami. 你能做什么？研究社交代理定向和员工与代理的主动互动.
    载于2016年ACM交互系统设计会议论文集, 第264–275页, 2016年.'
- en: '[62] Q. V. Liao, M. Mas-ud Hussain, P. Chandar, M. Davis, Y. Khazaeni, M. P.
    Crasso, D. Wang, M. Muller, N. S. Shami, and W. Geyer. All work and no play? In
    Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems,
    pages 1–13, 2018.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Q. V. Liao, M. Mas-ud Hussain, P. Chandar, M. Davis, Y. Khazaeni, M. P.
    Crasso, D. Wang, M. Muller, N. S. Shami, 和 W. Geyer. 只工作不玩耍？ 载于2018年CHI人机交互系统会议论文集,
    第1–13页, 2018年.'
- en: '[63] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig. Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. arXiv preprint arXiv:2107.13586, 2021.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, 和 G. Neubig. 预训练、提示和预测：自然语言处理中的提示方法系统性调查.
    arXiv 预印本 arXiv:2107.13586, 2021年.'
- en: '[64] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
    L. Zettlemoyer, and V. Stoyanov. Roberta: A robustly optimized bert pretraining
    approach. arXiv preprint arXiv:1907.11692, 2019.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
    L. Zettlemoyer, 和 V. Stoyanov. Roberta：一种强健优化的 BERT 预训练方法. arXiv 预印本 arXiv:1907.11692,
    2019.'
- en: '[65] S. Meyer, D. Elsweiler, B. Ludwig, M. Fernandez-Pichel, and D. E. Losada.
    Do we still need human assessors? prompt-based gpt-3 user simulation in conversational
    ai. In Proceedings of the 4th Conference on Conversational User Interfaces, pages
    1–6, 2022.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] S. Meyer, D. Elsweiler, B. Ludwig, M. Fernandez-Pichel, 和 D. E. Losada.
    我们还需要人工评估员吗？基于提示的 GPT-3 用户模拟在对话 AI 中的应用. 在第4届对话用户界面会议上, 页码 1–6, 2022.'
- en: '[66] S. H. Ng, D. Bell, and M. Brooke. Gaining turns and achieving high influence
    ranking in small conversational groups. British Journal of Social Psychology,
    32(3):265–275, 1993.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] S. H. Ng, D. Bell, 和 M. Brooke. 在小型对话小组中获得发言轮次并实现高影响力排名. 英国社会心理学期刊, 32(3):265–275,
    1993.'
- en: '[67] C. O’Connor, S. Michaels, S. Chapin, and A. G. Harbaugh. The silent and
    the vocal: Participation and learning in whole-class discussion. Learning and
    instruction, 48:5–13, 2017.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] C. O''Connor, S. Michaels, S. Chapin, 和 A. G. Harbaugh. 沉默与发声：全班讨论中的参与与学习.
    学习与教学, 48:5–13, 2017.'
- en: '[68] J. O’Connor and J. Andreas. What context features can transformer language
    models use? arXiv preprint arXiv:2106.08367, 2021.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] J. O''Connor 和 J. Andreas. 转换器语言模型可以使用哪些上下文特征？arXiv 预印本 arXiv:2106.08367,
    2021.'
- en: '[69] C. Oertel, G. Castellano, M. Chetouani, J. Nasir, M. Obaid, C. Pelachaud,
    and C. Peters. Engagement in human-agent interaction: An overview. Frontiers in
    Robotics and AI, 7:92, 2020.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] C. Oertel, G. Castellano, M. Chetouani, J. Nasir, M. Obaid, C. Pelachaud,
    和 C. Peters. 人机互动中的参与度：概述. 机器人与人工智能前沿, 7:92, 2020.'
- en: '[70] OpenAI. ChatGPT: Optimizing Language Models for Dialogue. OpenAI, 2022.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] OpenAI. ChatGPT：优化对话语言模型. OpenAI, 2022.'
- en: '[71] OpenAI. Gpt-4 technical report. (arXiv:2303.08774), Mar 2023. arXiv:2303.08774
    [cs].'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] OpenAI. GPT-4 技术报告. (arXiv:2303.08774), 2023年3月. arXiv:2303.08774 [cs].'
- en: '[72] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, et al. Training language models to follow
    instructions with human feedback. arXiv preprint arXiv:2203.02155, 2022.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, 等. 通过人类反馈训练语言模型以遵循指令. arXiv 预印本 arXiv:2203.02155,
    2022.'
- en: '[73] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. Bleu: a method for automatic
    evaluation of machine translation. In Proceedings of the 40th annual meeting of
    the Association for Computational Linguistics, pages 311–318, 2002.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] K. Papineni, S. Roukos, T. Ward, 和 W.-J. Zhu. Bleu：一种用于机器翻译自动评估的方法. 在第40届计算语言学协会年会上,
    页码 311–318, 2002.'
- en: '[74] E. Parliament. The impact of textile production and waste on the environment
    (infographic), 2020.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] E. Parliament. 纺织生产与废弃物对环境的影响（信息图表）, 2020.'
- en: '[75] B. Petreca, S. Baurley, K. Hesseldahl, A. Pollmann, and M. Obrist. The
    compositor tool: Investigating consumer experiences in the circular economy. Multimodal
    Technologies and Interaction, 6(4):24, 2022.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] B. Petreca, S. Baurley, K. Hesseldahl, A. Pollmann, 和 M. Obrist. 合成工具：研究循环经济中消费者体验.
    多模态技术与互动, 6(4):24, 2022.'
- en: '[76] D. Phutela. The importance of non-verbal communication. IUP Journal of
    Soft Skills, 9(4):43, 2015.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] D. Phutela. 非语言交流的重要性. IUP 软技能期刊, 9(4):43, 2015.'
- en: '[77] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.
    Robust speech recognition via large-scale weak supervision. arXiv preprint arXiv:2212.04356,
    2022.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, 和 I. Sutskever.
    通过大规模弱监督实现强健的语音识别. arXiv 预印本 arXiv:2212.04356, 2022.'
- en: '[78] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever.
    Robust speech recognition via large-scale weak supervision. In International Conference
    on Machine Learning, pages 28492–28518\. PMLR, 2023.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, 和 I. Sutskever.
    通过大规模弱监督实现强健的语音识别. 在国际机器学习大会中, 页码 28492–28518. PMLR, 2023.'
- en: '[79] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
    W. Li, P. J. Liu, et al. Exploring the limits of transfer learning with a unified
    text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67, 2020.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou,
    W. Li, P. J. Liu, 等. 探索通过统一的文本到文本转换器进行迁移学习的极限. 机器学习研究期刊, 21(140):1–67, 2020.'
- en: '[80] A. Rastogi, X. Zang, S. Sunkara, R. Gupta, and P. Khaitan. Towards scalable
    multi-domain conversational agents: The schema-guided dialogue dataset. In Proceedings
    of the AAAI conference on artificial intelligence, volume 34, pages 8689–8696,
    2020.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] A. Rastogi, X. Zang, S. Sunkara, R. Gupta 和 P. Khaitan。迈向可扩展的多领域对话代理：基于模式引导的对话数据集。在AAAI人工智能大会论文集，第34卷，页码8689-8696，2020年。'
- en: '[81] G. Redeker. On differences between spoken and written language. Discourse
    processes, 7(1):43–55, 1984.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] G. Redeker。口语和书面语言之间的差异。话语过程，7(1)：43-55，1984年。'
- en: '[82] C. K. Riessman. Analysis of personal narratives. Inside interviewing:
    New lenses, new concerns, pages 331–346, 2003.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] C. K. Riessman. 个人叙事分析。访谈中的内涵：新的视角，新的关注，页码331-346，2003年。'
- en: '[83] K. A. Schumacher and A. L. Forster. Textiles in a circular economy: An
    assessment of the current landscape, challenges, and opportunities in the united
    states. Frontiers in Sustainability, 3:146, 2022.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] K. A. Schumacher 和 A. L. Forster。循环经济中的纺织品：对美国当前形势、挑战和机遇的评估。《可持续发展前沿》，3：146，2022年。'
- en: '[84] K. Seaborn, N. P. Miyake, P. Pennefather, and M. Otake-Matsuura. Voice
    in human–agent interaction: A survey. ACM Computing Surveys (CSUR), 54(4):1–43,
    2021.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] K. Seaborn, N. P. Miyake, P. Pennefather 和 M. Otake-Matsuura。人类与代理互动中的语音：一项调查。ACM计算机调查（CSUR），54(4)：1-43，2021年。'
- en: '[85] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. Autoprompt:
    Eliciting knowledge from language models with automatically generated prompts.
    arXiv preprint arXiv:2010.15980, 2020.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace 和 S. Singh。Autoprompt：通过自动生成的提示从语言模型中引导知识。arXiv预印本arXiv:2010.15980，2020年。'
- en: '[86] E. M. Smith, O. Hsu, R. Qian, S. Roller, Y.-L. Boureau, and J. Weston.
    Human evaluation of conversations is an open problem: comparing the sensitivity
    of various methods for evaluating dialogue agents. arXiv preprint arXiv:2201.04723,
    2022.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] E. M. Smith, O. Hsu, R. Qian, S. Roller, Y.-L. Boureau 和 J. Weston。对话的人工评估仍是一个未解决的问题：比较各种对话代理评估方法的敏感性。arXiv预印本arXiv:2201.04723，2022年。'
- en: '[87] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford,
    D. Amodei, and P. F. Christiano. Learning to summarize with human feedback. Advances
    in Neural Information Processing Systems, 33:3008–3021, 2020.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford,
    D. Amodei 和 P. F. Christiano。通过人类反馈学习总结。神经信息处理系统进展，33：3008-3021，2020年。'
- en: '[88] D. Tannen. Conversational style: Analyzing talk among friends. Oxford
    University Press, 2005.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] D. Tannen。对话风格：分析朋友间的交谈。牛津大学出版社，2005年。'
- en: '[89] P. Ten Have. Doing conversation analysis. Sage, 2007.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] P. Ten Have. 进行对话分析。Sage，2007年。'
- en: '[90] P. Vaithilingam, T. Zhang, and E. L. Glassman. Expectation vs. experience:
    Evaluating the usability of code generation tools powered by large language models.
    In CHI Conference on Human Factors in Computing Systems Extended Abstracts, pages
    1–7, 2022.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] P. Vaithilingam, T. Zhang 和 E. L. Glassman。期望与体验：评估由大型语言模型驱动的代码生成工具的可用性。在CHI会议人因计算系统扩展摘要中，页码1-7，2022年。'
- en: '[91] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin. Attention is all you need. Advances in neural information
    processing systems, 30, 2017.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser 和 I. Polosukhin。注意力就是一切。《神经信息处理系统进展》，30，2017年。'
- en: '[92] A. Venkatesh, C. Khatri, A. Ram, F. Guo, R. Gabriel, A. Nagar, R. Prasad,
    M. Cheng, B. Hedayatnia, A. Metallinou, et al. On evaluating and comparing conversational
    agents. 2017.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] A. Venkatesh, C. Khatri, A. Ram, F. Guo, R. Gabriel, A. Nagar, R. Prasad,
    M. Cheng, B. Hedayatnia, A. Metallinou等人。关于评估和比较对话代理的研究。2017年。'
- en: '[93] A. P. Vermeeren, E. L.-C. Law, V. Roto, M. Obrist, J. Hoonhout, and K. Väänänen-Vainio-Mattila.
    User experience evaluation methods: current state and development needs. In Proceedings
    of the 6th Nordic conference on human-computer interaction: Extending boundaries,
    pages 521–530, 2010.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] A. P. Vermeeren, E. L.-C. Law, V. Roto, M. Obrist, J. Hoonhout, 和 K. Väänänen-Vainio-Mattila。用户体验评估方法：当前状态和发展需求。第6届北欧人机交互会议论文集：扩展边界，页码521-530，2010年。'
- en: '[94] S. T. Völkel, D. Buschek, M. Eiband, B. R. Cowan, and H. Hussmann. Eliciting
    and analysing users’ envisioned dialogues with perfect voice assistants. In Proceedings
    of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1–15,
    2021.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] S. T. Völkel, D. Buschek, M. Eiband, B. R. Cowan 和 H. Hussmann。引导和分析用户与完美语音助手的设想对话。在2021年CHI人因计算系统会议论文集中，页码1-15，2021年。'
- en: '[95] S. T. Völkel, S. Meindl, and H. Hussmann. Manipulating and evaluating
    levels of personality perceptions of voice assistants through enactment-based
    dialogue design. In Proceedings of the 3rd Conference on Conversational User Interfaces,
    pages 1–12, 2021.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] S. T. Völkel, S. Meindl, 和 H. Hussmann. 通过基于表演的对话设计操控和评估语音助手的个性知觉水平. 载于第三届对话用户界面会议（3rd
    Conference on Conversational User Interfaces）论文集，1–12页，2021年。'
- en: '[96] S. T. Völkel, R. Schödel, D. Buschek, C. Stachl, V. Winterhalter, M. Bühner,
    and H. Hussmann. Developing a personality model for speech-based conversational
    agents using the psycholexical approach. In Proceedings of the 2020 CHI Conference
    on Human Factors in Computing Systems, pages 1–14, 2020.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] S. T. Völkel, R. Schödel, D. Buschek, C. Stachl, V. Winterhalter, M. Bühner,
    和 H. Hussmann. 使用心理词汇学方法开发面向语音对话代理的个性模型. 载于2020年人机交互会议（CHI Conference on Human
    Factors in Computing Systems）论文集，1–14页，2020年。'
- en: '[97] S. T. Völkel, R. Schoedel, L. Kaya, and S. Mayer. User perceptions of
    extraversion in chatbots after repeated use. In Proceedings of the 2022 CHI Conference
    on Human Factors in Computing Systems, pages 1–18, 2022.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] S. T. Völkel, R. Schoedel, L. Kaya, 和 S. Mayer. 用户在反复使用聊天机器人后对外向性的知觉.
    载于2022年人机交互会议（CHI Conference on Human Factors in Computing Systems）论文集，1–18页，2022年。'
- en: '[98] B. Wang, G. Li, and Y. Li. Enabling conversational interaction with mobile
    ui using large language models. arXiv preprint arXiv:2209.08655, 2022.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] B. Wang, G. Li, 和 Y. Li. 利用大型语言模型实现移动UI的对话交互. arXiv预印本arXiv:2209.08655，2022年。'
- en: '[99] B. Wang, G. Li, and Y. Li. Enabling conversational interaction with mobile
    ui using large language models. In Proceedings of the 2023 CHI Conference on Human
    Factors in Computing Systems, pages 1–17, 2023.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] B. Wang, G. Li, 和 Y. Li. 利用大型语言模型实现移动UI的对话交互. 载于2023年人机交互会议（CHI Conference
    on Human Factors in Computing Systems）论文集，1–17页，2023年。'
- en: '[100] B. Wang, G. Li, X. Zhou, Z. Chen, T. Grossman, and Y. Li. Screen2words:
    Automatic mobile ui summarization with multimodal learning. In The 34th Annual
    ACM Symposium on User Interface Software and Technology, pages 498–510, 2021.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] B. Wang, G. Li, X. Zhou, Z. Chen, T. Grossman, 和 Y. Li. Screen2words：基于多模态学习的自动化移动UI摘要.
    载于第34届年度ACM用户界面软件与技术研讨会（The 34th Annual ACM Symposium on User Interface Software
    and Technology）论文集，498–510页，2021年。'
- en: '[101] Y.-C. Wang, A. Papangelis, R. Wang, Z. Feizollahi, G. Tur, and R. Kraut.
    Can you be more social? injecting politeness and positivity into task-oriented
    conversational agents. arXiv preprint arXiv:2012.14653, 2020.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Y.-C. Wang, A. Papangelis, R. Wang, Z. Feizollahi, G. Tur, 和 R. Kraut.
    你能更社交一点吗？向面向任务的对话代理注入礼貌和积极性. arXiv预印本arXiv:2012.14653，2020年。'
- en: '[102] T. D. Wilson. Models in information behaviour research. Journal of documentation,
    55(3):249–270, 1999.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] T. D. Wilson. 信息行为研究中的模型. 文献学期刊（Journal of Documentation），55(3):249–270，1999年。'
- en: '[103] T. Wu, M. Terry, and C. J. Cai. Ai chains: Transparent and controllable
    human-ai interaction by chaining large language model prompts. In CHI Conference
    on Human Factors in Computing Systems, pages 1–22, 2022.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] T. Wu, M. Terry, 和 C. J. Cai. AI链：通过链接大型语言模型提示实现透明和可控的人机交互. 载于人机交互会议（CHI
    Conference on Human Factors in Computing Systems）论文集，1–22页，2022年。'
- en: '[104] Q. Yang, J. Cranshaw, S. Amershi, S. T. Iqbal, and J. Teevan. Sketching
    nlp: A case study of exploring the right things to design with language intelligence.
    In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,
    pages 1–12, 2019.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Q. Yang, J. Cranshaw, S. Amershi, S. T. Iqbal, 和 J. Teevan. 绘制自然语言处理：探索用语言智能设计正确事物的案例研究.
    载于2019年人机交互会议（CHI Conference on Human Factors in Computing Systems）论文集，1–12页，2019年。'
- en: '[105] M. Zaib, Q. Z. Sheng, and W. Emma Zhang. A short survey of pre-trained
    language models for conversational ai-a new age in nlp. In Proceedings of the
    Australasian computer science week multiconference, pages 1–4, 2020.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] M. Zaib, Q. Z. Sheng, 和 W. Emma Zhang. 预训练语言模型在对话AI中的应用综述——自然语言处理的新纪元.
    载于澳大利亚计算机科学周多学科会议（Proceedings of the Australasian computer science week multiconference）论文集，1–4页，2020年。'
- en: '[106] J. Zamfirescu-Pereira, H. Wei, A. Xiao, K. Gu, G. Jung, M. G. Lee, B. Hartmann,
    and Q. Yang. Herding ai cats: Lessons from designing a chatbot by prompting gpt-3.
    2023.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] J. Zamfirescu-Pereira, H. Wei, A. Xiao, K. Gu, G. Jung, M. G. Lee, B.
    Hartmann, 和 Q. Yang. 驯服AI猫：设计通过GPT-3提示生成的聊天机器人的经验教训. 2023年。'
- en: '[107] L. Zhang, L. Jiang, N. Washington, A. A. Liu, J. Shao, A. Fourney, M. R.
    Morris, and L. Findlater. Social media through voice: Synthesized voice qualities
    and self-presentation. Proceedings of the ACM on Human-Computer Interaction, 5(CSCW1):1–21,
    2021.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] L. Zhang, L. Jiang, N. Washington, A. A. Liu, J. Shao, A. Fourney, M.
    R. Morris, 和 L. Findlater. 通过语音使用社交媒体：合成语音质量与自我展示. ACM人机交互会议（Proceedings of the
    ACM on Human-Computer Interaction），5(CSCW1):1–21，2021年。'
- en: '[108] S. Zhong, M. Ribul, Y. Cho, and M. Obrist. Textilenet: A material taxonomy-based
    fashion textile dataset. arXiv preprint arXiv:2301.06160, 2023.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] S. Zhong, M. Ribul, Y. Cho, 和 M. Obrist. Textilenet：基于材料分类的时尚纺织数据集. arXiv预印本arXiv:2301.06160，2023年。'
- en: '[109] A. F. Zuur, E. N. Ieno, N. J. Walker, A. A. Saveliev, G. M. Smith, et al.
    Mixed effects models and extensions in ecology with R, volume 574. Springer, 2009.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] A. F. Zuur, E. N. Ieno, N. J. Walker, A. A. Saveliev, G. M. Smith 等.
    《生态学中的混合效应模型及其扩展（使用 R）》, 第574卷. 施普林格, 2009.'
