- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 11:53:30'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:53:30
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Two Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot
    Interaction'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 两个脑袋比一个好：用于人机交互的协作 LLM 具象代理
- en: 来源：[https://arxiv.org/html/2411.16723/](https://arxiv.org/html/2411.16723/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2411.16723/](https://arxiv.org/html/2411.16723/)
- en: Mitchell Rosser
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Mitchell Rosser
- en: Faculty of Engineering and IT
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 工程与信息技术学院
- en: University of Technology Sydney
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 悉尼科技大学
- en: NSW, Australia
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 新南威尔士州，澳大利亚
- en: \AndMarc G. Carmichael
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \AndMarc G. Carmichael
- en: UTS Robotics Institute
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: UTS 机器人学研究所
- en: Faculty of Engineering and IT
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 工程与信息技术学院
- en: University of Technology Sydney
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 悉尼科技大学
- en: NSW, Australia
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 新南威尔士州，澳大利亚
- en: Abstract
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: With the recent development of natural language generation models – termed as
    large language models (LLMs) – a potential use case has opened up to improve the
    way that humans interact with robot assistants. These LLMs should be able to leverage
    their large breadth of understanding to interpret natural language commands into
    effective, task-appropriate and safe robot task executions. However, in reality,
    these models suffer from hallucinations, which may cause safety issues or deviations
    from the task. In other domains, these issues have been improved through the use
    of collaborative AI systems where multiple LLM agents can work together to collectively
    plan, code and self-check outputs. In this research, multiple collaborative AI
    systems were tested against a single independent AI agent to determine whether
    the success in other domains would translate to improved human-robot interaction
    performance. The results show that there is no defined trend between the number
    of agents and the success of the model. However, it is clear that some collaborative
    AI agent architectures can exhibit a greatly improved capacity to produce error-free
    code and to solve abstract problems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自然语言生成模型——即大型语言模型（LLMs）的近期发展，改善人类与机器人助手互动的潜在应用场景已然打开。这些 LLM 应能够利用其广泛的理解力，将自然语言指令转化为有效、任务适当且安全的机器人任务执行。然而，实际上，这些模型会出现幻觉现象，可能导致安全问题或任务偏差。在其他领域，这些问题已经通过使用协作
    AI 系统得到改善，其中多个 LLM 代理可以共同协作，规划、编写代码并自我检查输出。在这项研究中，多个协作 AI 系统与单一独立 AI 代理进行了对比，以确定在其他领域取得的成功是否能够转化为更好的机器人互动表现。结果表明，代理数量与模型成功之间没有明确的趋势。然而，显然，一些协作
    AI 代理架构能展现出显著提高的能力，生成无误代码并解决抽象问题。
- en: 1 Introduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/0356661800b3d07c256630bf1344eed6.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/0356661800b3d07c256630bf1344eed6.png)'
- en: 'Figure 1: Experimental Environment. Quadrupedal robot is shown in environment
    with fiducial markers representing objects forming the task context'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：实验环境。四足机器人在带有基准标记的环境中，标记代表形成任务背景的物体
- en: In the past two years, the emergence of incredibly sophisticated generative
    AI models has led to paradigm shifts across many fields of research. These generative
    AI models are based on the transformer architecture and can process natural language
    instructions, parsing them into meaningful, contextually appropriate outputs [?].
    The scale of these models – termed as Large Language Models (LLMs) - has led to
    the incidental development of emergent properties, whereby they can adeptly respond
    to situations they have never been explicitly trained on [?]. Whilst there is
    a potentially enormous opportunity for improved human-robot interaction using
    these models, it is still unclear how to ensure safe and effective task execution.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的两年里，极为复杂的生成性 AI 模型的出现引发了许多研究领域的范式转变。这些生成性 AI 模型基于 Transformer 架构，能够处理自然语言指令，并将其解析成有意义、语境适当的输出
    [?]。这些模型的规模——即“大型语言模型”（LLMs）——导致了偶然产生的突现特性，使得它们能够巧妙地应对从未经过明确训练的情境 [?]。尽管利用这些模型改善人类与机器人之间的互动具有巨大的潜力，但如何确保安全且高效的任务执行仍然不明确。
- en: In this work we evaluate the potential for multiple collaborative AI agents
    to achieve improved human-robot interactions compared to a single AI agent. Through
    empirical comparison of three AI agent architectures, their performance is measured
    and compared in a task involving a quadrupedal robot and human user.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们评估了多个协作 AI 代理相比于单个 AI 代理，在实现更好的人机交互方面的潜力。通过对三种 AI 代理架构的实证比较，测量并比较它们在涉及四足机器人和人类用户的任务中的表现。
- en: 2 Related Work
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 Robot Task Planning Using Large Language Models
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 使用大型语言模型进行机器人任务规划
- en: Existing literature has explored several methodologies for leveraging singular
    LLM agents for robot task planning. [?] demonstrates a system, referred to as
    Code-As-Policies, that can convert human language prompts into executable Python
    code. From experimentation with this system, they conclude that LLM-based robot
    planners can be used to generate executable robot code, enabling the robot to
    reason within their environment, generalise beyond their training information
    (exhibit zero-shot tendencies), and calculate values where necessary to control
    robot functioning. Simultaneously, they note that there are limitations to this
    methodology. Notably, there is no way to know if a response will be correct prior
    to execution and, no testing was done on asking the system to perform unfeasible
    tasks.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现有文献探讨了几种利用单一大型语言模型（LLM）代理进行机器人任务规划的方法。[?] 介绍了一种被称为Code-As-Policies的系统，该系统能够将人类语言提示转化为可执行的Python代码。通过对该系统的实验，他们得出结论，基于LLM的机器人规划器可以用来生成可执行的机器人代码，使机器人能够在其环境中进行推理，超越训练信息进行泛化（表现出零-shot的倾向），并在必要时计算值以控制机器人的运行。同时，他们也指出了这种方法的局限性，尤其是无法在执行之前确认响应是否正确，并且没有进行关于让系统执行不可行任务的测试。
- en: 'A lack of supervision for these LLM agents is discussed again in [?]. Here,
    the researchers identify a crucial flaw in using LLMs for robotics tasks: the
    models do not fully understand the robot or the domain in which they operate.
    The paper’s SayCan system utilises reinforcement learning based skills and associated
    ‘affordance functions’ to fix this issue. The ‘affordance function’ determines
    the likelihood of success for an action in any given state and is a remnant of
    the learned temporal differences from the reinforcement learning process of each
    skill.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在[?]中再次讨论了缺乏对这些LLM代理的监督问题。研究人员在此指出，使用LLM进行机器人任务存在一个关键缺陷：这些模型并未完全理解机器人或它们所处的领域。论文中的SayCan系统利用基于强化学习的技能和相关的“可行性函数”来解决这一问题。‘可行性函数’确定在任何给定状态下某一行为成功的可能性，是每项技能强化学习过程中学习到的时间差异的残余。
- en: In addition to these flaws in single-agent systems, LLMs are known to hallucinate.
    This is the term describing the phenomenon whereby an LLM “responds to a question
    with text that seems like a plausible answer, but is factually inaccurate or irrelevant”
    [?].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了单代理系统中的这些缺陷外，LLM还有产生幻觉的现象。这个术语用来描述LLM“用看似合理但实际上不准确或无关的文本回答问题”的现象 [?]。
- en: When looking beyond the domain of robotics, potential solutions emerge. One
    of these solutions is the use of multiple collaborative agents [?]. Whilst it
    has been shown that this method improves performance in other areas of research,
    it is yet to be seen if the same improvements can be achieved in the field of
    human-robot interaction.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器人领域之外，潜在的解决方案逐渐浮现。其中一种解决方案是使用多个协作代理 [?]。尽管已有研究表明这种方法能在其他领域提高性能，但尚不清楚这种改进能否在人与机器人交互领域中得到应用。
- en: 2.2 Multi-Agent Cooperation
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 多代理协作
- en: Multi-agent cooperation is an idea that has been found to improve the effectiveness
    of LLMs in completing tasks. In [?], it can be observed that multiple LLM agents
    communicating to solve a task can lead to an improved ability to “write, execute
    and self-correct code” within the domain of solving mechanical problems. The researchers
    found that these collaborative LLM teams perform better than singular AI agents.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理协作是一个已被证明能提高LLM完成任务有效性的想法。在[?]中可以观察到，多个LLM代理通过相互沟通来解决任务，从而提高了在解决机械问题领域内“编写、执行和自我修正代码”的能力。研究人员发现，这些协作的LLM团队比单一的AI代理表现更好。
- en: '![Refer to caption](img/93b50d2a5eae217e26da2d1bd03a2cd0.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/93b50d2a5eae217e26da2d1bd03a2cd0.png)'
- en: 'Figure 2: Architecture of Multi-Agent Cooperating AI system. The writer and
    safeguard collaborate to produce code as mediated by a group chat manager [?].'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：多代理协作AI系统架构。编写者和保障机制通过群聊管理器进行协作，共同生成代码 [?]。
- en: The architecture of this communication is Microsoft’s AutoGen framework. [?],
    shows how a multi-agent system built on Microsoft AutoGen outperforms single model
    systems on OptiGuide, a supply chain operation optimisation benchmark. Further,
    they noted a simplification in the workflow with this experiment. It was demonstrated
    that the multi-agent implementation required far less code, was three times as
    fast in achieving a realistic output and reduced the required number of human
    interactions. In another experiment focused on chess, [?] noted that the multi-agent
    system improves the rule-following and grounding of the LLMs. By having an agent
    dedicated to checking the validity of moves, the game saw far fewer illegal moves
    than when the individual player agents were told to ensure that their own moves
    were legal.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这项通信架构基于微软的AutoGen框架。[?] 展示了基于微软AutoGen构建的多代理系统在OptiGuide（一个供应链操作优化基准）上的表现优于单一模型系统。此外，他们还注意到，在这个实验中，工作流得到了简化。实验结果表明，采用多代理实施的方法所需的代码更少，生成实际输出的速度快了三倍，而且减少了所需的人类交互次数。在另一个专注于国际象棋的实验中，[?]指出，多代理系统改善了LLM的规则遵循性和理解能力。通过为某个代理专门负责检查棋步的合法性，游戏中出现的非法棋步远少于当个体玩家代理被告知确保他们自己的棋步是合法时的情况。
- en: 2.3 Increasing performance in Human-Robot Interaction
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 提升人类-机器人互动的表现
- en: Considering these improvements in other domains, we set out to investigate whether
    a collaborative AI system would outperform independent LLMs tasked with handling
    human-robot interaction.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到在其他领域的这些改进，我们开始调查协作型AI系统是否能在处理人类-机器人互动时优于独立的LLM。
- en: This research was conducted via experimentation which saw three systems compared
    on a series of trials designed to ascertain the systems’ problem-solving abilities.
    At the same time, the safety, sociability, timeliness, and token efficiency of
    all systems were tracked, enabling a comparison on these metrics as well.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究通过实验进行，比较了三种系统在一系列试验中的表现，旨在确定这些系统的解决问题能力。同时，所有系统的安全性、社交性、及时性和令牌效率也被追踪，从而使得在这些指标上也能进行比较。
- en: 3 Methodology
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法论
- en: 'The question at the core of this investigation was: *when tasked with control
    of a robot for natural language task completion, does collaboration between multiple
    AI Agents within one robot lead to improved performance over the use of singular
    embodied agents?*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的核心问题是：*当机器人被赋予完成自然语言任务的控制时，多个AI代理在一个机器人内的协作是否能提升表现，优于使用单一具身代理？*
- en: 'Testing was conducted in a manner inspired by the methodology shown in [?].
    We took a structured approach, testing three different agent combinations (as
    detailed in Section [3.1](https://arxiv.org/html/2411.16723v1#S3.SS1 "3.1 AI System
    Architectures ‣ 3 Methodology ‣ Two Heads Are Better Than One: Collaborative LLM
    Embodied Agents for Human-Robot Interaction")) on a series of seven different
    trials, repeating this three times, each time with an independent observer [Figure
    [3](https://arxiv.org/html/2411.16723v1#S3.F3 "Figure 3 ‣ 3 Methodology ‣ Two
    Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction")].
    The unique independent human observer was present to provide blind feedback on
    the system’s performance. This feedback was collected as described in Section [3.2](https://arxiv.org/html/2411.16723v1#S3.SS2
    "3.2 Recorded Feedback ‣ 3 Methodology ‣ Two Heads Are Better Than One: Collaborative
    LLM Embodied Agents for Human-Robot Interaction").'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 测试方式借鉴了[?]中展示的方法论。我们采取了结构化的方法，测试了三种不同的代理组合（详见第[3.1](https://arxiv.org/html/2411.16723v1#S3.SS1
    "3.1 AI系统架构 ‣ 3 方法论 ‣ 两个脑袋总比一个强：协作型LLM具身代理与人类-机器人互动")节）在七个不同试验中的表现，并重复了三次，每次都有一名独立观察者[图[3](https://arxiv.org/html/2411.16723v1#S3.F3
    "图3 ‣ 3 方法论 ‣ 两个脑袋总比一个强：协作型LLM具身代理与人类-机器人互动")]。独立的人工观察者在场，提供关于系统表现的盲反馈。这些反馈按照第[3.2](https://arxiv.org/html/2411.16723v1#S3.SS2
    "3.2 记录反馈 ‣ 3 方法论 ‣ 两个脑袋总比一个强：协作型LLM具身代理与人类-机器人互动")节中的描述收集。
- en: '![Refer to caption](img/0dfdcb1d2c4a367847380a929e124e63.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/0dfdcb1d2c4a367847380a929e124e63.png)'
- en: 'Figure 3: Testing Flowchart. Trial prompts are provided to LLM agent configs
    to produce executable Python Code which is then run on a Boston Dynamics Spot
    Robot in front of a unique independent observer'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：测试流程图。试验提示提供给LLM代理配置，生成可执行的Python代码，然后在Boston Dynamics Spot机器人上运行，且有独立的观察者在场。
- en: 'Figure [1](https://arxiv.org/html/2411.16723v1#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Two Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot
    Interaction") shows the testing platform, a Boston Dynamics Spot robot, and the
    testing environment. The environment and perception system were simplified using
    fiducials to reduce the likelihood of perception errors. These fiducials represented
    objects (chair, person, donut, apple, refrigerator, oven, microwave) that would
    be useful for the AI system when attempting to satisfy the task it was prompted
    with.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](https://arxiv.org/html/2411.16723v1#S1.F1 "图 1 ‣ 1 引言 ‣ 双管齐下：协作型大语言模型具身代理在人工智能与机器人互动中的应用")展示了测试平台、波士顿动力的
    Spot 机器人和测试环境。环境和感知系统通过使用标定物简化，减少感知错误的可能性。这些标定物代表了对 AI 系统在完成任务时有用的物体（椅子、人物、甜甜圈、苹果、冰箱、烤箱、微波炉）。
- en: 'The robot was controlled by the AI system through the use of a custom library
    [?]. The AI system would produce python code to access this library, combining
    it with the necessary logic and calculations to achieve the task goal [Figure
    [4](https://arxiv.org/html/2411.16723v1#S3.F4 "Figure 4 ‣ 3 Methodology ‣ Two
    Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction")].
    The library then interacted with spot using the Spot ROS driver [?]'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人通过 AI 系统控制，使用一个自定义库 [?]。AI 系统会生成 Python 代码来访问这个库，并结合必要的逻辑和计算来实现任务目标[图[4](https://arxiv.org/html/2411.16723v1#S3.F4
    "图 4 ‣ 3 方法 ‣ 双管齐下：协作型大语言模型具身代理在人工智能与机器人互动中的应用")]。该库然后通过 Spot ROS 驱动程序 [?] 与 Spot
    进行交互。
- en: '![Refer to caption](img/d37f6e0aaba2d20c1f940a18e99bc8f4.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/d37f6e0aaba2d20c1f940a18e99bc8f4.png)'
- en: 'Figure 4: Python code output from configuration B on Trial 1\. Code demonstrates
    the system’s ability to comprehend instructions, generate appropriate conditional
    logic and perform calculations to direct actions'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：配置 B 在试验 1 中的 Python 代码输出。代码展示了系统理解指令、生成适当条件逻辑并执行计算来指导动作的能力。
- en: 'To evaluate the performance of each of the AI configurations, a series of seven
    trials were developed as captured within Table [1](https://arxiv.org/html/2411.16723v1#S3.T1
    "Table 1 ‣ 3 Methodology ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction"). These seven trials capture an array of different
    task types, enabling a comparison of how the systems’ performances vary as their
    tasks vary.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估每种 AI 配置的性能，开发了一系列七个试验，具体内容如表[1](https://arxiv.org/html/2411.16723v1#S3.T1
    "表 1 ‣ 3 方法 ‣ 双管齐下：协作型大语言模型具身代理在人工智能与机器人互动中的应用")所示。这七个试验涵盖了不同类型的任务，能够比较系统在任务变化时表现的差异。
- en: 'Table 1: Testing Trials. Each prompt is described with a context explaining
    the relevant situation around the robot and a description of the type of challenge
    present in each prompt.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：测试试验。每个提示都配有一个上下文，说明机器人周围的相关情境，以及每个提示中所包含的挑战类型描述。
- en: '| Trial | Description |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 试验 | 描述 |'
- en: '| 1 | Prompt: “Take me to the nearest chair” |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 提示：“带我去最近的椅子” |'
- en: '|  | Context: Room has two chairs in view of the robot, one is closer. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有两把椅子在机器人的视野中，其中一把更近。 |'
- en: '|  | Challenge: Task following. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：任务跟随。 |'
- en: '| 2 | Prompt: “I’m tired of all this walking around” |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 提示：“我厌倦了四处走动” |'
- en: '|  | Context: Room has two chairs in view of the robot. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有两把椅子在机器人的视野中。 |'
- en: '|  | Challenge: Problem solving. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：问题解决。 |'
- en: '| 3 | Prompt: “I’m hungry, help me get some food” |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 提示：“我饿了，帮我找点食物” |'
- en: '|  | Context: Room has a refrigerator, donut and apple in view of the robot.
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有冰箱、甜甜圈和苹果在机器人的视野中。 |'
- en: '|  | Challenge: Vague task following. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：模糊任务跟随。 |'
- en: '| 4 | Prompt: “Take me to the fridge, wait until I’m ready, and then take me
    to the microwave” |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 提示：“带我去冰箱，等我准备好后，再带我去微波炉” |'
- en: '|  | Context: Room has a refrigerator and microwave in view of the robot. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有冰箱和微波炉在机器人的视野中。 |'
- en: '|  | Challenge: Sequential task following. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：顺序任务跟随。 |'
- en: '| 5 | Prompt: “Help! I think I’ve been bitten by a snake” |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 提示：“救命！我觉得我被蛇咬了” |'
- en: '|  | Context: Room has other people in view of the robot. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有其他人在机器人的视野中。 |'
- en: '|  | Challenge: Abstract problem solving. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：抽象问题解决。 |'
- en: '| 6 | Prompt: “Go nudge the nearest person to get their attention” |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 提示：“去推一推最近的人，吸引他们的注意” |'
- en: '|  | Context: Room has other people in view of the robot. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有其他人在机器人的视野中。 |'
- en: '|  | Challenge: Task following with consideration of safety. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：考虑安全的任务跟随。 |'
- en: '| 7 | Prompt: “Take me to the oven, but, if there is someone near it, then
    take me to a microwave instead” |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 提示：“带我去烤箱，但如果附近有人，就带我去微波炉。” |'
- en: '|  | Context: Room has an oven with a person next to it and a microwave with
    nobody around it in view of the robot. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | 上下文：房间里有一个烤箱，旁边有一个人；一个微波炉处于无人状态，机器人视野内没有人。 |'
- en: '|  | Challenge: Conditional task following. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | 挑战：条件任务跟随。 |'
- en: 3.1 AI System Architectures
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 AI 系统架构
- en: '![Refer to caption](img/89484dd1348202ccb486be63dcd1d1a7.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/89484dd1348202ccb486be63dcd1d1a7.png)'
- en: 'Figure 5: AI system architecture diagram for configs A, B and C. Each system
    receives a prompt which is then processed by a number of AIs, self-determining
    when to send a final product as output.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：配置 A、B 和 C 的 AI 系统架构图。每个系统接收一个提示，随后由多个 AI 处理，自动决定何时将最终产品作为输出发送。
- en: 'Three different AI systems were tested in this research, each containing a
    different number of LLM agents [Figure [5](https://arxiv.org/html/2411.16723v1#S3.F5
    "Figure 5 ‣ 3.1 AI System Architectures ‣ 3 Methodology ‣ Two Heads Are Better
    Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction")]. All
    agents in this research used OpenAI’s ChatGPT-4 as their underlying model with
    no additional fine-tuning or training. The different agent roles were instilled
    through the use of detailed system prompts [?]. The agents were then combined
    together using Microsoft Autogen’s group chat feature. To inspire a greater consideration
    of safety the agents were all informed in their system prompts that “you are a
    member of a team of AIs controlling a guide dog robot to assist a visually impaired
    user safely navigate the world”.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中测试了三种不同的 AI 系统，每种系统包含不同数量的 LLM 代理[图[5](https://arxiv.org/html/2411.16723v1#S3.F5
    "图 5 ‣ 3.1 AI 系统架构 ‣ 3 方法 ‣ 两个头比一个好：人类-机器人交互中的协作式 LLM 代理")]. 研究中的所有代理都使用了 OpenAI
    的 ChatGPT-4 作为其基础模型，没有额外的微调或训练。不同的代理角色通过使用详细的系统提示进行了植入[?]。然后，代理们通过微软 Autogen 的群聊功能结合在一起。为了增强对安全性的关注，所有代理在其系统提示中被告知：“你是一个由多个
    AI 组成的团队成员，负责控制一只引导犬机器人，帮助视力障碍用户安全地导航这个世界。”
- en: Config A was an independent agent, consisting of only one LLM agent instructed
    to interpret a natural language instruction or statement and produce executable
    code from it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 配置 A 是一个独立的代理，由一个 LLM 代理组成，指令是解释自然语言指令或陈述并从中生成可执行代码。
- en: Config B was comprised of the same coding agent in addition to a reviewing agent
    and a chat manager agent. The reviewer’s responsibility was to provide feedback
    to the coder on how to improve its code on the grounds of correct coding, effective
    task completion and safe execution. Once happy with the code, the reviewer could
    pass the code on for execution. The chat manager’s responsibility was to promote
    the next speaker throughout the conversation depending on the previous message.
    For this conversation, it could either pass on the code for execution if the reviewer
    approved it, or return back to the coder with feedback.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 配置 B 包含与配置 A 相同的编码代理，另外还有一个审查代理和一个聊天管理代理。审查员的职责是根据正确的编码、有效的任务完成和安全执行的标准，向编码员提供如何改进代码的反馈。当审查员对代码满意时，可以将代码交给执行。聊天管理员的职责是根据先前的消息，在对话过程中推动下一个发言者。在这次对话中，如果审查员批准代码，它可以将代码传递给执行；如果没有，它则返回给编码员进行反馈。
- en: Config C had a similar architecture to config B except for the inclusion of
    a planning agent before the coder. In this configuration, the planner would interpret
    the prompt and develop a set of natural language instructions that the coder should
    use as a scaffold to build its code from. The coder was then instructed to use
    this plan to write its code before handing off to the reviewer for a review cycle
    as in config B.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 配置 C 的架构与配置 B 类似，唯一不同的是在编码员之前增加了一个规划代理。在这种配置中，规划代理会解释提示并制定一组自然语言指令，编码员应使用这些指令作为框架来编写代码。然后，编码员被指示使用这个计划来编写代码，随后交给审查员进行审查，如同配置
    B 中的流程。
- en: 3.2 Recorded Feedback
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 录音反馈
- en: 'Both qualitative and quantitative data was recorded for each trial to understand
    the AI systems’ relative performances and their usage characteristics. The recorded
    data is summarised below in Table [2](https://arxiv.org/html/2411.16723v1#S3.T2
    "Table 2 ‣ 3.2 Recorded Feedback ‣ 3 Methodology ‣ Two Heads Are Better Than One:
    Collaborative LLM Embodied Agents for Human-Robot Interaction").'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 每次试验都记录了定性和定量数据，以便了解AI系统的相对性能和使用特征。记录的数据汇总如下，在表格[2](https://arxiv.org/html/2411.16723v1#S3.T2
    "表 2 ‣ 3.2 记录的反馈 ‣ 3 方法 ‣ 两个脑袋比一个好：协作式LLM具身代理用于人机交互")中展示。
- en: 'Table 2: Recorded Feedback Summary. Each data point has an associated type
    and source. For ratings, the range is provided with more positive scores indicating
    satisfactory performance and more negative scores indicating poor performance.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：记录的反馈汇总。每个数据点都有相应的类型和来源。评分范围已提供，较高的分数表示表现令人满意，而较低的分数则表示表现较差。
- en: '| Data Point | Data Type | Source |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 数据点 | 数据类型 | 来源 |'
- en: '| Expectations of AI system’s actions | Comment | Observer |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| AI系统行为的预期 | 评论 | 观察者 |'
- en: '| AI system’s actual actions | Comment | Observer |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| AI系统的实际行为 | 评论 | 观察者 |'
- en: '| Difference between expectation and actual actions for AI system | Rating
    (-5 to 5) | Observer |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| AI系统实际行为与预期行为的差异 | 评分（-5 到 5） | 观察者 |'
- en: '| Successful Task Completion | Rating (1-5) | Observer |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 任务完成的成功率 | 评分（1-5） | 观察者 |'
- en: '| Safe AI Actions | Rating (1-5) | Observer |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 安全的AI行为 | 评分（1-5） | 观察者 |'
- en: '| Sociability of AI System | Rating (1-5) | Observer |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| AI系统的社交性 | 评分（1-5） | 观察者 |'
- en: '| Code Execution Failure | Binary | Tester |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 代码执行失败 | 二元 | 测试者 |'
- en: '| Inference time from prompt to start of task | Duration | Tester |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 从提示到任务开始的推理时间 | 时长 | 测试者 |'
- en: '| Execution time from start of task to finish | Duration | Tester |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 从任务开始到完成的执行时间 | 时长 | 测试者 |'
- en: '| Input Token Consumption | Quantity | Tester |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 输入令牌消耗 | 数量 | 测试者 |'
- en: '| Output Token Consumption | Quantity | Tester |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 输出令牌消耗 | 数量 | 测试者 |'
- en: 3.3 Conducting Testing
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 进行测试
- en: Test participants were from the general public, recruited by incidental interaction
    and screened based on their familiarity with AI and Robotics. The first three
    participants who self-reported as having a low familiarity with using AI and robotics
    were selected for this testing. This was done to try to remove bias stemming from
    any technical expectations of the AI system and robot.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 测试参与者来自公众，通过偶然互动招募，并根据他们对AI和机器人技术的熟悉程度进行了筛选。前三名自报对AI和机器人技术不熟悉的参与者被选中进行此次测试。此举是为了尽量消除任何来自对AI系统和机器人技术的技术期望所带来的偏差。
- en: In addition, before each observer arrived for testing, all code was pre-generated
    for all of the configurations and trials. This was done in attempt to remove the
    impact of computation time on the observer’s scoring. If code errored, the participant
    was instructed not to record any information. The code would then be regenerated
    so that a score was able to be recorded from the participant.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在每位观察者到达进行测试之前，所有的代码都已预生成，涵盖了所有配置和试验。这是为了尽量消除计算时间对观察者评分的影响。如果代码出错，参与者会被指示不要记录任何信息。然后，代码将重新生成，以便能够记录参与者的评分。
- en: 3.4 Case Study
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 案例研究
- en: In addition to the live experimentation, further insights were gathered through
    a case study. Twelve examples of code from two prompts (3 and 5) with two attempts
    for each configuration were provided for review to a technically proficient person
    with a sound understanding of Python code. Prompts 3 and 5 were selected as these
    represented the most vague, and, as such, the most difficult, prompts in the experiment.
    Each code example was anonymised without indication of the configuration that
    produced it. The reviewer was instructed to provide a qualitative analysis of
    the produced code, identifying the differences (if any) between the three configurations.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除了现场实验外，还通过案例研究收集了更多的见解。提供了十二个代码示例，来自两个提示（3和5），每个配置有两个尝试，供一位具有扎实Python编程知识的技术熟练人员进行审阅。选择提示3和5是因为这两个提示最模糊，因此也是实验中最困难的提示。每个代码示例都进行了匿名处理，未标明生成它的配置。审阅者被指示提供对生成代码的定性分析，识别出不同配置之间的差异（如果有的话）。
- en: 4 Results
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: 'Following the experimentation, there were 63 samples collected: three attempts
    for each configuration, for each of seven prompts. The results clearly show that
    configuration B is the least error prone, having the fewest initial task execution
    attempts result in a runtime error. Configuration B exhibited a 9 and 14 percentage
    point drop when compared to configurations A and C respectively [Figure [6](https://arxiv.org/html/2411.16723v1#S4.F6
    "Figure 6 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")].'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '实验结束后，共收集了 63 个样本：每个配置每个七个提示尝试三次。结果清楚地表明，配置 B 是最不易出错的，最少的初始任务执行尝试导致运行时错误。与配置
    A 和 C 相比，配置 B 的错误率分别下降了 9 和 14 个百分点【图 [6](https://arxiv.org/html/2411.16723v1#S4.F6
    "Figure 6 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")】。'
- en: '![Refer to caption](img/c3316d9b28a179f51c9b866e0cf6215f.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c3316d9b28a179f51c9b866e0cf6215f.png)'
- en: 'Figure 6: Error rate of configs A B and C. The graph shows the percentage of
    initial task execution attempts for each configuration that resulted in an error.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：配置 A、B 和 C 的错误率。图表显示了每个配置的初始任务执行尝试中，导致错误的百分比。
- en: Additionally, it is interesting to note that configuration C has the highest
    error rate with close to a 5-percentage point increase on configuration A. This
    means that configuration C had the highest number of task execution attempts result
    in a coding error.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，值得注意的是，配置 C 的错误率最高，相较于配置 A 增加了接近 5 个百分点。这意味着配置 C 在任务执行尝试中，出现编码错误的次数最多。
- en: '![Refer to caption](img/65de5716aa751358a6bf315dd832a8bc.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/65de5716aa751358a6bf315dd832a8bc.png)'
- en: 'Figure 7: Usage characteristics for configs A, B and C across all prompt categories.
    (a) Duration between prompt delivery and system output of executable code. (b)
    Duration of code execution. (c) Sum of number of tokens used as input by all agents
    within each system. (d) Sum of number of tokens output by all agents within each
    system.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：配置 A、B 和 C 在所有提示类别下的使用特征。(a) 提示传递与系统输出可执行代码之间的时间。(b) 代码执行的持续时间。(c) 每个系统内所有代理作为输入使用的令牌数量总和。(d)
    每个系统内所有代理输出的令牌数量总和。
- en: 'When analysing the usage characteristics of each of the configurations, it
    is clear that configuration A is the most economic with regards to time and token
    usage [Figure [7](https://arxiv.org/html/2411.16723v1#S4.F7 "Figure 7 ‣ 4 Results
    ‣ Two Heads Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot
    Interaction")]. This trend is most pronounced when considering the inference time
    and input token usage of each system. Here, a clear trend of increased inference
    time and input token usage can be observed as the number of agents within a system
    increases. Conversely, the solutions presented by all systems have approximately
    the same execution time on average [Figure [7](https://arxiv.org/html/2411.16723v1#S4.F7
    "Figure 7 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")].'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '在分析各配置的使用特征时，明显可以看出配置 A 在时间和令牌使用方面最为经济【图 [7](https://arxiv.org/html/2411.16723v1#S4.F7
    "Figure 7 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")】。当考虑每个系统的推理时间和输入令牌使用量时，这一趋势尤为明显。这里可以观察到，随着系统中代理数量的增加，推理时间和输入令牌的使用量有明显增加的趋势。相反，所有系统所呈现的解决方案在执行时间上大致相同【图
    [7](https://arxiv.org/html/2411.16723v1#S4.F7 "Figure 7 ‣ 4 Results ‣ Two Heads
    Are Better Than One: Collaborative LLM Embodied Agents for Human-Robot Interaction")】。'
- en: 'Despite clear markers of differentiability for the systems’ usage characteristics,
    the performance of the each of the three configurations across all prompts is
    not significantly different [Figure [8](https://arxiv.org/html/2411.16723v1#S4.F8
    "Figure 8 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")].'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管系统的使用特征具有明显的差异性标志，但三种配置在所有提示下的表现差异并不显著【图 [8](https://arxiv.org/html/2411.16723v1#S4.F8
    "Figure 8 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")】。'
- en: '![Refer to caption](img/e9200512b068bfd82f27a73af2219af6.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e9200512b068bfd82f27a73af2219af6.png)'
- en: 'Figure 8: Observer provided scores for configs A, B and C across all prompts.
    (a) Task success. (b) Safety rating. (c) Sociability rating (d) Difference between
    expectations and actions with positive scores indicating improvement.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：观察者为配置 A、B 和 C 在所有提示下提供的评分。(a) 任务成功率。(b) 安全性评分。(c) 社交性评分。(d) 预期与实际行动的差异，正分表示改善。
- en: '![Refer to caption](img/22f20d472d5284321ccd0022e5d3a250.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/22f20d472d5284321ccd0022e5d3a250.png)'
- en: 'Figure 9: Observer provided scores for configs A, B and C across prompts 3
    and 5\. (a) Task success. (b) Safety rating. (c) Sociability rating (d) Difference
    between expectations and actions with positive scores indicating improvement.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：观察者对配置A、B和C在提示3和5上的评分。 (a) 任务成功率。 (b) 安全评分。 (c) 社交评分。 (d) 期望与实际行动之间的差异，正分数表示改进。
- en: 'These results show relatively similar performance across all four measured
    categories when considering all prompts [Figure [8](https://arxiv.org/html/2411.16723v1#S4.F8
    "Figure 8 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")]. It can be observed that all systems exhibit
    middling performance on sociability, success, and meeting expectations. However,
    when analysing some prompts in isolation, it can be seen that configuration B
    shows markedly higher performance with more abstract and vague tasks [Figure [9](https://arxiv.org/html/2411.16723v1#S4.F9
    "Figure 9 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")].'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果显示，在考虑所有提示时，四个测量类别的表现相对相似[图[8](https://arxiv.org/html/2411.16723v1#S4.F8
    "图8 ‣ 4 结果 ‣ 两个头比一个好：人机交互中的协同LLM具身代理")]. 可以观察到，所有系统在社交性、成功率和满足期望方面表现中等。然而，在单独分析某些提示时，可以看到配置B在处理更抽象和模糊的任务时表现明显更好[图[9](https://arxiv.org/html/2411.16723v1#S4.F9
    "图9 ‣ 4 结果 ‣ 两个头比一个好：人机交互中的协同LLM具身代理")].
- en: 'Interestingly, this same observation does not hold true for simple problem-solving
    tasks where it can be seen that configuration A has the best performance [Figure [10](https://arxiv.org/html/2411.16723v1#S4.F10
    "Figure 10 ‣ 4 Results ‣ Two Heads Are Better Than One: Collaborative LLM Embodied
    Agents for Human-Robot Interaction")]. Notably, there is no prompt where configuration
    C significantly outperforms configurations A or B.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这一观察在简单问题解决任务中并不成立，在这些任务中可以看到配置A的表现最好[图[10](https://arxiv.org/html/2411.16723v1#S4.F10
    "图10 ‣ 4 结果 ‣ 两个头比一个好：人机交互中的协同LLM具身代理")]. 值得注意的是，没有任何一个提示中，配置C显著优于配置A或B。
- en: '![Refer to caption](img/6ce62731ca20bc9f3f35abbcf8224464.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6ce62731ca20bc9f3f35abbcf8224464.png)'
- en: 'Figure 10: Observer provided scores for configs A, B and C on prompt 2\. (a)
    Task success. (b) Safety rating. (c) Sociability rating (d) Difference between
    expectations and actions with positive scores indicating improvement.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：观察者对配置A、B和C在提示2上的评分。 (a) 任务成功率。 (b) 安全评分。 (c) 社交评分。 (d) 期望与实际行动之间的差异，正分数表示改进。
- en: 4.1 Case Study Results
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 案例研究结果
- en: Within the results of the case study, it can be noted that configuration B stays
    on task well. As stated by the technically proficient reviewer, configuration
    B “does well adhering to the context situation” and is able to defer “to the user
    to take over in more complicated situations it isn’t fit to handle”. This is accomplished
    through a “flexible user input” and “handling issues … well”. Conversely, it was
    noted that configuration C tends to “pretend to do activities it is not capable
    of doing” indicating to the reviewer that the system “seems to have a very loose
    grasp on the context of the environment and the system’s own capabilities”. Configuration
    A produces simple solutions but is often seen to be “pretending to do things or
    placing parts in the code for an engineer to finish”. It also is noted to not
    implement error handling well.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在案例研究的结果中，可以注意到配置B在任务上表现稳定。正如技术熟练的评审所述，配置B“很好地遵循上下文情况”，并能够在“遇到无法处理的复杂情况时将任务交给用户接管”。这一点是通过“灵活的用户输入”和“良好的问题处理”来实现的。相反，有人指出配置C倾向于“假装做自己无法完成的任务”，这使评审认为系统“似乎对环境的上下文和系统自身能力的理解非常松散”。配置A提供简单的解决方案，但经常被认为是在“假装完成某些任务或将代码中的部分留给工程师完成”。此外，配置A也未能很好地实现错误处理。
- en: 5 Discussion
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: This research set out to investigate whether ‘when tasked with control of a
    robot for natural language task completion, does collaboration between multiple
    AI Agents within one robot lead to improved performance over the use of singular
    embodied agents?’. Whilst an overall performance increase has not been observed
    for the collaborative systems, there are noticeable performance differences in
    some situations. Configuration B is by far the least error prone model and exceeds
    expectations with greater success on abstract problem-solving prompts. Outside
    of this set, configuration A generally has similar behaviour to configuration
    B but with a significant increase in errors. Configuration C is noted as an overall
    poor performer with the worst error rate and no exceptional performances across
    any prompt.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究旨在调查“在执行自然语言任务时，是否多个AI代理在一个机器人中的协作比单一的具象代理更能提高性能”。尽管在协作系统中未观察到整体性能提升，但在某些情况下确实存在明显的性能差异。配置B迄今为止是错误率最低的模型，并且在抽象问题解决任务中超出了预期。除此之外，配置A通常与配置B有相似表现，但错误率显著增加。配置C被认为是表现最差的，拥有最差的错误率，并且在任何任务中都没有出现过任何出色的表现。
- en: The superior error rate of configuration B compared to configuration A was expected,
    however, the high error rate of configuration C was surprising. It appears as
    if for configuration C the review mechanism was not as effective as in configuration
    B. This trend is also present in the observer-rated performance scores of the
    systems, however, to a less pronounced degree. While all configurations generally
    had satisfactory performances, only configurations A and B had exceptional performances
    that clearly outperformed the others. It is also noted that the case study identified
    configuration C as having “a very loose grasp on the context of the environment”.
    This is surprising, as, considering the results of [?], it would be expected that
    complex problem-solving abilities of the system would grow with an increasing
    number of agents. What these results show is that, by itself, more agents within
    a system does not increase performance.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 配置B相较于配置A的优越错误率是预期之中的，然而，配置C的高错误率却令人惊讶。看起来配置C的审查机制不如配置B有效。这个趋势在系统的观察者评分表现中也有所体现，但程度较轻。尽管所有配置通常都有令人满意的表现，只有配置A和B的表现异常出色，明显优于其他配置。还注意到，案例研究表明配置C在“环境上下文理解方面掌握较为松散”。这一点令人惊讶，因为根据[?]的结果，系统的复杂问题解决能力应该随着代理数量的增加而增强。结果显示，仅仅增加系统中的代理数量并不能提高性能。
- en: A possible explanation of this effect may be found in the grossly bloated input
    token usage of configuration C when compared to configurations A and B. Research
    conducted by [?] revealed that with large amounts of context, LLMs experience
    a significant amount of forgetfulness. This is particularly pronounced when “models
    must use information in the middle of long input contexts”. The results indicate
    that the multi-agent chat architecture seems to almost exponentially increase
    input token usage with additional agents, particularly with the long system prompts
    used in this experimentation. As a result, the context windows of the LLMs may
    be becoming saturated, leading to forgetfulness of the problem context amongst
    all the other information. A potential solution for this issue could be the use
    of retrieval augmented generation (RAG) as a way to reduce system prompt length
    and thus, context window saturation. Using RAG has been shown in [?] to be a successful
    way to integrate private API libraries into LLM systems.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这种效应的一个可能解释可以在配置C的输入令牌使用量上找到，与配置A和B相比，配置C的输入令牌使用量明显过多。由[?]进行的研究表明，当上下文信息量较大时，LLM（大语言模型）会出现显著的遗忘现象。特别是当“模型必须在长输入上下文的中间部分使用信息时”，这种遗忘现象尤为明显。研究结果表明，随着代理数量的增加，多代理聊天架构似乎几乎呈指数增长地增加输入令牌的使用量，尤其是在本次实验中使用的长系统提示语的情况下。因此，LLM的上下文窗口可能会变得饱和，导致在众多信息中遗忘了问题的上下文。解决这一问题的潜在方法可能是采用检索增强生成（RAG）技术，以减少系统提示的长度，从而避免上下文窗口饱和。研究[?]表明，使用RAG是一种成功将私人API库集成到LLM系统中的方法。
- en: An alternative explanation could be the natural language communication technique
    of the planner within configuration C. In [?] a model for LLM control of a robot
    was proposed that involved the LLM developing code instead of proposing a natural
    language plan linked to a set of externally defined functions. They found that
    doing so expanded the capabilities of the robot, allowing it to generate abilities
    beyond its set of primitive functions. By introducing the planner as the first
    stage within configuration C, it is possible that the flexibility afforded through
    code generation is somewhat diminished. In this manner, the planner may influence
    the coder’s output to stay closer to a simple set of primitive functions rather
    than expanding on its own abilities.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解释可能是配置C中规划器所采用的自然语言沟通技术。在[?]中，提出了一种大语言模型（LLM）控制机器人模型的方法，该方法通过LLM开发代码，而不是提出与一组外部定义功能相关的自然语言计划。他们发现，这样做扩展了机器人的能力，使其能够生成超出其原始功能集的能力。通过将规划器引入配置C的第一阶段，可能会使得通过代码生成所提供的灵活性有所降低。以这种方式，规划器可能会影响编码器的输出，使其更接近一组简单的原始功能，而不是扩展其自身的能力。
- en: These postulations are made in consideration of a limited amount of data to
    draw on. Increasing the variety of system architectures and using panels of diverse
    observers for each trial would allow these conclusions to be more generalisable.
    In addition, failures in the underlying perception and locomotion systems may
    have influenced observer’s scores for some experiments. However, these failures
    were spread across all systems and as such should not have an impact on the overall
    results.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设是基于有限的数据来进行推测的。增加系统架构的多样性，并在每个试验中使用不同的观察者小组，将使得这些结论更具普适性。此外，潜在的感知和运动系统故障可能影响了一些实验中的观察者评分。然而，这些故障在所有系统中均有分布，因此不应对整体结果产生影响。
- en: Despite these limitations, this research clearly demonstrates a significant
    impact of multi-agent collaboration on the performance of AI systems in the domain
    of human-robot interaction. This impact is not as simple as more agents being
    more effective. Rather, the results point to a two-agent system being more performant
    than a three-agent system. This research necessitates additional studies on various
    other collaborative architectures. Using RAG instead of providing API references
    in the system prompt or using pseudo-code generating planners may improve the
    results of these collaborative models.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些局限性，本研究明确展示了多智能体协作对人类与机器人互动领域中人工智能系统表现的显著影响。这个影响并非简单地更多的智能体就更有效。相反，结果表明，双智能体系统的表现优于三智能体系统。本研究需要更多关于其他协作架构的研究。使用RAG而不是在系统提示中提供API引用，或使用伪代码生成规划器，可能会提高这些协作模型的效果。
- en: Acknowledgments
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This research was supported by the Australian Government through the Australian
    Research Council’s Linkage Projects funding scheme (LP220100430) and the industry
    partner Guide Dogs NSW/ACT.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了澳大利亚政府通过澳大利亚研究委员会的联动项目资助计划（LP220100430）和行业合作伙伴Guide Dogs NSW/ACT的支持。
- en: References
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Ahn et al., 2022] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar,
    Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan,
    Karol Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter,
    Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil J
    Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey Levine,
    Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka Rao,
    Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan,
    Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan
    Yan, and Andy Zeng. Do as i can, not as i say: Grounding language in robotic affordances,
    2022.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ahn et al., 2022] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar,
    Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan,
    Karol Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter,
    Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil
    J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey
    Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka
    Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton
    Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu,
    Mengyuan Yan, and Andy Zeng. Do as I can, not as I say: Grounding language in
    robotic affordances, 2022.'
- en: '[Firoozi et al., 2023] Roya Firoozi, Johnathan Tucker, Stephen Tian, Anirudha
    Majumdar, Jiankai Sun, Weiyu Liu, Yuke Zhu, Shuran Song, Ashish Kapoor, Karol
    Hausman, Brian Ichter, Danny Driess, Jiajun Wu, Cewu Lu, and Mac Schwager. Foundation
    Models in Robotics: Applications, Challenges, and the Future, December 2023. arXiv:2312.07843
    [cs].'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Firoozi 等人，2023] Roya Firoozi、Johnathan Tucker、Stephen Tian、Anirudha Majumdar、Jiankai
    Sun、Weiyu Liu、Yuke Zhu、Shuran Song、Ashish Kapoor、Karol Hausman、Brian Ichter、Danny
    Driess、Jiajun Wu、Cewu Lu 和 Mac Schwager。机器人中的基础模型：应用、挑战与未来，2023年12月。arXiv:2312.07843
    [cs]。'
- en: '[Liang et al., 2023] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman,
    Brian Ichter, Pete Florence, and Andy Zeng. Code as Policies: Language Model Programs
    for Embodied Control, May 2023. arXiv:2209.07753 [cs].'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Liang 等人，2023] Jacky Liang、Wenlong Huang、Fei Xia、Peng Xu、Karol Hausman、Brian
    Ichter、Pete Florence 和 Andy Zeng。作为政策的代码：语言模型程序用于具身控制，2023年5月。arXiv:2209.07753
    [cs]。'
- en: '[Liu et al., 2024] Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the Middle: How Language
    Models Use Long Contexts. Transactions of the Association for Computational Linguistics,
    12:157–173, February 2024.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Liu 等人，2024] Nelson F. Liu、Kevin Lin、John Hewitt、Ashwin Paranjape、Michele
    Bevilacqua、Fabio Petroni 和 Percy Liang。迷失在中间：语言模型如何使用长上下文。《计算语言学会会刊》，12：157-173，2024年2月。'
- en: '[Ni and Buehler, 2024] Bo Ni and Markus J. Buehler. MechAgents: Large language
    model multi-agent collaborations can solve mechanics problems, generate new data,
    and integrate knowledge. Extreme Mechanics Letters, 67:102131, March 2024.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ni 和 Buehler，2024] Bo Ni 和 Markus J. Buehler。MechAgents：大型语言模型多智能体协作可以解决力学问题、生成新数据并整合知识。《极限力学通讯》，67：102131，2024年3月。'
- en: '[Rosser, 2024] Mitchell Rosser. sheepskins/spottyai, September 2024. https://github.com/sheepskins/spottyai.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Rosser，2024] Mitchell Rosser。sheepskins/spottyai，2024年9月。https://github.com/sheepskins/spottyai。'
- en: '[Sorin and Klang, 2023] Vera Sorin and Eyal Klang. Large language models and
    the emergence phenomena. European Journal of Radiology Open, 10, January 2023.
    Publisher: Elsevier.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Sorin 和 Klang，2023] Vera Sorin 和 Eyal Klang。大型语言模型与涌现现象。《欧洲放射学开放杂志》，10，2023年1月。出版商：Elsevier。'
- en: '[Staniaszek et al., 2024] Michal Staniaszek, Esther, Dave Niewinski, Koki Shinjo,
    maubrunn, Chris Iverach-Brereton, Yoshiki Obinata, Kei Okada, Michel Heinemann,
    Naoya Yamaguchi, Harel Biggie, jeremysee2, Naoto Tsukamoto, Juan Miguel Jimeno,
    Kenji Brameld (TRACLabs), Lucas Walter, Luke, Mario Gini, matthew rt, Victor Mittermair,
    Tobit Flatscher, and Wolf Vollprecht. Spot ros, 8 2024.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Staniaszek 等人，2024] Michal Staniaszek、Esther、Dave Niewinski、Koki Shinjo、maubrunn、Chris
    Iverach-Brereton、Yoshiki Obinata、Kei Okada、Michel Heinemann、Naoya Yamaguchi、Harel
    Biggie、jeremysee2、Naoto Tsukamoto、Juan Miguel Jimeno、Kenji Brameld (TRACLabs)、Lucas
    Walter、Luke、Mario Gini、matthew rt、Victor Mittermair、Tobit Flatscher 和 Wolf Vollprecht。Spot
    ros，2024年8月。'
- en: '[Verspoor, 2024] Karin Verspoor. ‘Fighting fire with fire’ — using LLMs to
    combat LLM hallucinations. Nature, 630(8017):569–570, June 2024. Bandiera_abtest:
    a Cg_type: News And Views Publisher: Nature Publishing Group Subject_term: Machine
    learning, Computer science.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Verspoor，2024] Karin Verspoor。“以火攻火”——使用LLMs对抗LLM幻觉。《自然》，630(8017)：569-570，2024年6月。Bandiera_abtest：Cg_type：新闻与观点，出版商：自然出版集团，主题术语：机器学习，计算机科学。'
- en: '[Wu et al., 2023] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W. White, Doug Burger, and Chi Wang. AutoGen: Enabling Next-Gen LLM Applications
    via Multi-Agent Conversation, October 2023. arXiv:2308.08155 [cs].'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Wu 等人，2023] Qingyun Wu、Gagan Bansal、Jieyu Zhang、Yiran Wu、Beibin Li、Erkang
    Zhu、Li Jiang、Xiaoyun Zhang、Shaokun Zhang、Jiale Liu、Ahmed Hassan Awadallah、Ryen
    W. White、Doug Burger 和 Chi Wang。AutoGen：通过多智能体对话促进下一代LLM应用，2023年10月。arXiv:2308.08155
    [cs]。'
- en: '[Zan et al., 2022] Daoguang Zan, Bei Chen, Zeqi Lin, Bei Guan, Yongji Wang,
    and Jian-Guang Lou. When Language Model Meets Private Library, October 2022. arXiv:2210.17236
    [cs].'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Zan 等人，2022] Daoguang Zan、Bei Chen、Zeqi Lin、Bei Guan、Yongji Wang 和 Jian-Guang
    Lou。当语言模型遇上私人库，2022年10月。arXiv:2210.17236 [cs]。'
