- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 11:54:26'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 11:54:26'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Star-Agents: 基于LLM代理的指令调优自动数据优化'
- en: 来源：[https://arxiv.org/html/2411.14497/](https://arxiv.org/html/2411.14497/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2411.14497/](https://arxiv.org/html/2411.14497/)
- en: \floatsetup
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \floatsetup
- en: '[table]capposition=top \newfloatcommandcapbtabboxtable[][\FBwidth]'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[table]capposition=top \newfloatcommandcapbtabboxtable[][\FBwidth]'
- en: Hang Zhou^(1,2), Yehui Tang², Haochen Qin², Yujie Yang², Renren Jin¹,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 杭周^(1,2)，唐业辉²，秦浩辰²，杨宇杰²，金仁仁¹，
- en: Deyi Xiong¹^∗, Kai Han²^∗, Yunhe Wang²
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 熊德毅¹^∗，韩凯²^∗，王云鹤²
- en: ¹College of Intelligence and Computing, Tianjin University, Tianjin, China.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ¹天津大学智能与计算学院，天津，中国。
- en: ²Huawei Noah’s Ark Lab.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ²华为诺亚方舟实验室。
- en: '{zhouhang25, yehui.tang, qinhaochen1, yangyujie26}@huawei.com,'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '{zhouhang25, yehui.tang, qinhaochen1, yangyujie26}@huawei.com，'
- en: '{rrjin, dyxiong}@tju.edu.cn, {kai.han, yunhe.wang}@huawei.com Corresponding
    authors.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '{rrjin, dyxiong}@tju.edu.cn, {kai.han, yunhe.wang}@huawei.com 通讯作者。'
- en: Abstract
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The efficacy of large language models (LLMs) on downstream tasks usually hinges
    on instruction tuning, which relies critically on the quality of training data.
    Unfortunately, collecting high-quality and diverse data is both expensive and
    time-consuming. To mitigate this issue, we propose a novel Star-Agents framework,
    which automates the enhancement of data quality across datasets through multi-agent
    collaboration and assessment. The framework adopts a three-pronged strategy. It
    initially generates diverse instruction data with multiple LLM agents through
    a bespoke sampling method. Subsequently, the generated data undergo a rigorous
    evaluation using a dual-model method that assesses both difficulty and quality.
    Finaly, the above process evolves in a dynamic refinement phase, where more effective
    LLMs are prioritized, enhancing the overall data quality. Our empirical studies,
    including instruction tuning experiments with models such as Pythia and LLaMA,
    demonstrate the effectiveness of the proposed framework. Optimized datasets have
    achieved substantial improvements, with an average increase of 12% and notable
    gains in specific metrics, such as a 40% improvement in Fermi, as evidenced by
    benchmarks like MT-bench, Vicuna bench, and WizardLM testset. Codes will be released
    soon¹¹1https://github.com/CANGLETIAN/Star-Agents.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）在下游任务中的效能通常依赖于指令调优，而这高度依赖于训练数据的质量。不幸的是，收集高质量和多样化的数据既昂贵又耗时。为了解决这个问题，我们提出了一种新颖的Star-Agents框架，它通过多代理协作和评估自动增强数据集的质量。该框架采用三管齐下的策略。首先，它通过定制的采样方法，利用多个LLM代理生成多样化的指令数据。随后，生成的数据经过双模型方法的严格评估，评估内容包括难度和质量。最后，以上过程进入动态优化阶段，在该阶段中，更有效的LLM模型被优先使用，从而提升整体数据质量。我们的实证研究，包括使用Pythia和LLaMA等模型进行的指令调优实验，验证了该框架的有效性。优化后的数据集在多个指标上取得了显著的提升，平均提高了12%，并在特定指标上有显著进步，如Fermi的提升高达40%，这一点在MT-bench、Vicuna
    bench和WizardLM测试集中得到了验证。代码将很快发布¹¹1https://github.com/CANGLETIAN/Star-Agents。
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The research and development of natural language understanding and generation
    have been dramatically accelerated with the emergence and prevalence of LLMs  [[39](https://arxiv.org/html/2411.14497v1#bib.bib39),
    [31](https://arxiv.org/html/2411.14497v1#bib.bib31), [30](https://arxiv.org/html/2411.14497v1#bib.bib30)].
    These models have been extensively applied in a wide range of scenarios, e.g.,
    question answering and text generation, significantly enhancing downstream task
    performance due to their exceptional ability to follow instructions [[3](https://arxiv.org/html/2411.14497v1#bib.bib3),
    [53](https://arxiv.org/html/2411.14497v1#bib.bib53), [49](https://arxiv.org/html/2411.14497v1#bib.bib49),
    [10](https://arxiv.org/html/2411.14497v1#bib.bib10), [28](https://arxiv.org/html/2411.14497v1#bib.bib28)].
    Such an instruction-following capability is primarily acquired through a process
    known as instruction tuning [[40](https://arxiv.org/html/2411.14497v1#bib.bib40),
    [23](https://arxiv.org/html/2411.14497v1#bib.bib23), [5](https://arxiv.org/html/2411.14497v1#bib.bib5)],
    where LLMs are fine-tuned on instruction data. It is hence widely acknowledged
    that the quality of instructions plays a pivotal role [[5](https://arxiv.org/html/2411.14497v1#bib.bib5),
    [20](https://arxiv.org/html/2411.14497v1#bib.bib20), [48](https://arxiv.org/html/2411.14497v1#bib.bib48),
    [29](https://arxiv.org/html/2411.14497v1#bib.bib29)].
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自从LLMs的出现和普及以来，自然语言理解和生成的研究与开发得到了显著加速[[39](https://arxiv.org/html/2411.14497v1#bib.bib39)、[31](https://arxiv.org/html/2411.14497v1#bib.bib31)、[30](https://arxiv.org/html/2411.14497v1#bib.bib30)]。这些模型已广泛应用于多种场景，例如问答和文本生成，由于其出色的指令遵循能力，显著提升了下游任务的表现[[3](https://arxiv.org/html/2411.14497v1#bib.bib3)、[53](https://arxiv.org/html/2411.14497v1#bib.bib53)、[49](https://arxiv.org/html/2411.14497v1#bib.bib49)、[10](https://arxiv.org/html/2411.14497v1#bib.bib10)、[28](https://arxiv.org/html/2411.14497v1#bib.bib28)]。这种指令遵循能力主要通过一种被称为“指令调优”的过程获得[[40](https://arxiv.org/html/2411.14497v1#bib.bib40)、[23](https://arxiv.org/html/2411.14497v1#bib.bib23)、[5](https://arxiv.org/html/2411.14497v1#bib.bib5)]，在该过程中，LLMs会根据指令数据进行微调。因此，普遍认为，指令的质量在其中起着至关重要的作用[[5](https://arxiv.org/html/2411.14497v1#bib.bib5)、[20](https://arxiv.org/html/2411.14497v1#bib.bib20)、[48](https://arxiv.org/html/2411.14497v1#bib.bib48)、[29](https://arxiv.org/html/2411.14497v1#bib.bib29)]。
- en: Historically, the creation of instruction data for training LLMs has heavily
    relied on the expertise of human annotators, as evidenced by substantial scholarly
    contributions [[14](https://arxiv.org/html/2411.14497v1#bib.bib14), [50](https://arxiv.org/html/2411.14497v1#bib.bib50),
    [41](https://arxiv.org/html/2411.14497v1#bib.bib41), [38](https://arxiv.org/html/2411.14497v1#bib.bib38),
    [9](https://arxiv.org/html/2411.14497v1#bib.bib9), [27](https://arxiv.org/html/2411.14497v1#bib.bib27),
    [21](https://arxiv.org/html/2411.14497v1#bib.bib21)].While expert-driven data
    generation assures the production of high-quality instructions, the enormous volume
    of data necessary for effective training renders this method economically untenable.
    In response, recent efforts have shifted towards the utilization of LLMs to automatically
    generate instructions, thereby mitigating the reliance on costly human annotation
    [[37](https://arxiv.org/html/2411.14497v1#bib.bib37), [32](https://arxiv.org/html/2411.14497v1#bib.bib32),
    [44](https://arxiv.org/html/2411.14497v1#bib.bib44), [18](https://arxiv.org/html/2411.14497v1#bib.bib18)].
    Concurrently, there is a growing emphasis on the generation and selection of challenging
    examples, grounded in the belief that more complex and difficult instructions
    can substantially elevate model capabilities [[22](https://arxiv.org/html/2411.14497v1#bib.bib22),
    [17](https://arxiv.org/html/2411.14497v1#bib.bib17)].
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，训练大型语言模型（LLMs）的指令数据创建在很大程度上依赖于人工标注者的专业知识，这一点可以从大量学术贡献中得到验证[[14](https://arxiv.org/html/2411.14497v1#bib.bib14)、[50](https://arxiv.org/html/2411.14497v1#bib.bib50)、[41](https://arxiv.org/html/2411.14497v1#bib.bib41)、[38](https://arxiv.org/html/2411.14497v1#bib.bib38)、[9](https://arxiv.org/html/2411.14497v1#bib.bib9)、[27](https://arxiv.org/html/2411.14497v1#bib.bib27)、[21](https://arxiv.org/html/2411.14497v1#bib.bib21)]。尽管专家驱动的数据生成确保了高质量指令的产生，但为有效训练所需的大量数据使得这种方法在经济上难以持续。因此，最近的努力已经转向利用LLMs自动生成指令，从而减轻了对昂贵人工标注的依赖[[37](https://arxiv.org/html/2411.14497v1#bib.bib37)、[32](https://arxiv.org/html/2411.14497v1#bib.bib32)、[44](https://arxiv.org/html/2411.14497v1#bib.bib44)、[18](https://arxiv.org/html/2411.14497v1#bib.bib18)]。与此同时，越来越多的关注也集中在生成和选择具有挑战性的示例上，基于这样的信念：更复杂、更困难的指令可以显著提升模型的能力[[22](https://arxiv.org/html/2411.14497v1#bib.bib22)、[17](https://arxiv.org/html/2411.14497v1#bib.bib17)]。
- en: Despite the clear advantages of using LLMs for data generation, several challenges
    persist in this strategy. Primarily, previous efforts often depend on a single
    LLM, resulting in data that may lack stylistic variety [[4](https://arxiv.org/html/2411.14497v1#bib.bib4)]
    and encompass a limited range of difficulty levels , which may not be ideal for
    all models. Additionally, there is a trend towards the creation of exceedingly
    complex instructions [[19](https://arxiv.org/html/2411.14497v1#bib.bib19), [44](https://arxiv.org/html/2411.14497v1#bib.bib44),
    [18](https://arxiv.org/html/2411.14497v1#bib.bib18)], which may surpass the operational
    capabilities of models with small parameter scale, thereby hindering their ability
    to fully capitalize on the data’s potential for performance enhancement.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用LLM生成数据具有明显的优势，但这种策略仍然存在一些挑战。首先，以前的努力通常依赖于单一的LLM，导致生成的数据可能缺乏风格多样性 [[4](https://arxiv.org/html/2411.14497v1#bib.bib4)]，并且涵盖的难度范围有限，这可能并不适合所有模型。此外，生成过于复杂的指令
    [[19](https://arxiv.org/html/2411.14497v1#bib.bib19), [44](https://arxiv.org/html/2411.14497v1#bib.bib44),
    [18](https://arxiv.org/html/2411.14497v1#bib.bib18)] 的趋势也日益明显，这可能超过了参数规模较小的模型的操作能力，从而阻碍了它们充分利用数据在性能提升方面的潜力。
- en: To address the aforementioned challenges, we propose the Star-Agents framework,
    an advanced automatic data optimization system specifically designed to learn
    and refine instruction samples with suitable complexity and diversity for target
    LLMs. The framework consists of three main components. First, to increase the
    diversity of generated data, an instruction data rewriting process involving multiple
    advanced LLM agents is proposed. This process samples different LLM agents for
    rewriting instructions and responses separately (referred to as agent-pairs).
    Next, to select high-quality samples, the generated data undergo a dual-model
    evaluation function with appropriate complexity as the selection metric. Finally,
    to balance data diversity and quality, the sampling probability of agent-pairs
    is adjusted and evolved based on the composite scores of the selected data, identifying
    agent-pairs that generate high-quality data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述挑战，我们提出了Star-Agents框架，这是一个先进的自动化数据优化系统，专门设计用于学习和优化具有适当复杂度和多样性的指令样本，以适应目标LLM。该框架由三个主要部分组成。首先，为了增加生成数据的多样性，提出了一种涉及多个高级LLM代理的指令数据重写过程。该过程通过采样不同的LLM代理分别重写指令和响应（称为代理对）。接下来，为了选择高质量样本，生成的数据将通过一个双模型评估函数，以适当的复杂度作为选择标准。最后，为了平衡数据的多样性和质量，代理对的采样概率会根据所选数据的综合得分进行调整和演化，从而识别出能够生成高质量数据的代理对。
- en: Extensive experiments are conducted to evaluate instruction-following capabilities
    of LLMs on a variety of benchmark datasets, including MT-bench [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)],
    Vicuna-bench [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)], and the WizardLM
    testset [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]. Instruction tuning
    experiments with LLMs such as Pythia and LLaMA, demonstrate the effectiveness
    of the Star-Agents framework. LLMs trained on data generated by Star-Agent outperform
    those (the same LLMs) trained on the Evol-Instruct dataset [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]
    or data selected according to the Instruction-Following Difficulty (IFD) metric
    [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)]. Significantly, the optimized
    datasets have resulted in an average performance improvement of 12%, with some
    metrics such as Fermi demonstrating gains of over 40%.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了广泛的实验，评估了LLM在各种基准数据集上的指令跟随能力，包括MT-bench [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)]、Vicuna-bench
    [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)]以及WizardLM测试集 [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]。在Pythia和LLaMA等LLM上的指令微调实验，展示了Star-Agents框架的有效性。基于Star-Agent生成的数据训练的LLM在表现上优于那些（相同的LLM）基于Evol-Instruct数据集
    [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]或根据指令跟随难度（IFD）度量 [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)]选择的数据训练的LLM。显著的是，经过优化的数据集在平均性能上提高了12%，其中一些指标，如Fermi，表现出超过40%的增益。
- en: 2 Related Work
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Our work is related to both instruction data generation and selection. We briefly
    review these topics within the constraint of space.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作涉及指令数据生成和选择。由于篇幅限制，我们简要回顾了这些主题。
- en: Instruction Data Generation
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指令数据生成
- en: Datasets like Dolly [[7](https://arxiv.org/html/2411.14497v1#bib.bib7)] and
    OpenAssistant [[15](https://arxiv.org/html/2411.14497v1#bib.bib15)] are built
    from human-generated instruction data. The ShareGPT dataset, built from conversations
    between humans and ChatGPT, has been effectively used to improve the instruction-following
    performance of fine-tuned models [[6](https://arxiv.org/html/2411.14497v1#bib.bib6)].
    Both Self-Instruct [[36](https://arxiv.org/html/2411.14497v1#bib.bib36)] and Alpaca
    [[33](https://arxiv.org/html/2411.14497v1#bib.bib33)] leverage the generation
    capabilities of GPT-3 to expand seed instructions. The generated instructions
    undergo filtering to eliminate low-quality instructions while the kept instructions
    are used to fine-tune the model to enhance the model’s ability to respond to instructions.
    Baize [[45](https://arxiv.org/html/2411.14497v1#bib.bib45)] proposes a self-dialogue
    framework, using questions from popular Q&A websites as starting topics, then
    having LLMs converse with themselves. CAMEL [[16](https://arxiv.org/html/2411.14497v1#bib.bib16)]
    introduces a role-playing framework where LLMs discuss a given topic when playing
    a role as either “user” or “assistant”. UltraChat [[8](https://arxiv.org/html/2411.14497v1#bib.bib8)]
    uses real-world named entities combined with various text-writing tasks to generate
    diverse and high-quality multi-turn dialogues for LLMs. Lion [[13](https://arxiv.org/html/2411.14497v1#bib.bib13)]
    introduces the concept of adversarial distillation, using the Imitation-Discrimination-Generation
    stages to iteratively generate data, refine existing instructions, and produces
    more complex and diverse instructions to expand the capabilities of the student
    model. Evol-Instruct [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)] uses
    five manually designed prompts to explicitly guide LLM in rewriting existing simple
    instructions into more complex ones. The WizardLM model, trained with Evol-Instuct,
    ranks highly on MT-Bench [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)],
    highlighting the importance of data quality in training effective LLMs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 像Dolly [[7](https://arxiv.org/html/2411.14497v1#bib.bib7)] 和 OpenAssistant [[15](https://arxiv.org/html/2411.14497v1#bib.bib15)]
    这样的数据集是由人工生成的指令数据构建的。由人类与ChatGPT之间的对话构建的ShareGPT数据集，已被有效地用于提高微调模型的指令跟随性能 [[6](https://arxiv.org/html/2411.14497v1#bib.bib6)]。Self-Instruct
    [[36](https://arxiv.org/html/2411.14497v1#bib.bib36)] 和Alpaca [[33](https://arxiv.org/html/2411.14497v1#bib.bib33)]
    利用GPT-3的生成能力扩展种子指令。生成的指令经过筛选，淘汰低质量指令，保留下来的指令用于微调模型，以增强模型响应指令的能力。Baize [[45](https://arxiv.org/html/2411.14497v1#bib.bib45)]
    提出了一个自对话框架，使用来自流行问答网站的问题作为起始话题，然后让LLM与自己对话。CAMEL [[16](https://arxiv.org/html/2411.14497v1#bib.bib16)]
    引入了一个角色扮演框架，在这个框架中，LLM在扮演“用户”或“助手”角色时讨论给定话题。UltraChat [[8](https://arxiv.org/html/2411.14497v1#bib.bib8)]
    结合现实世界的命名实体与各种文本写作任务，生成多样且高质量的多轮对话供LLM使用。Lion [[13](https://arxiv.org/html/2411.14497v1#bib.bib13)]
    引入了对抗蒸馏的概念，通过模仿-判别-生成阶段迭代生成数据，细化现有指令，并生成更复杂、更多样化的指令，扩展学生模型的能力。Evol-Instruct [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]
    使用五个手动设计的提示，明确指导LLM将现有简单指令改写为更复杂的指令。使用Evol-Instruct训练的WizardLM模型，在MT-Bench [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)]上排名靠前，凸显了数据质量在训练有效LLM中的重要性。
- en: Instruction Data Selection
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指令数据选择
- en: With the aforementioned methods, it is not difficult to use LLMs to generate
    large instruction tuning datasets at low cost. However, for instruction-tuned
    language models, data quality is more crucial than quantity. In this aspect, ALPAGASUS
    [[5](https://arxiv.org/html/2411.14497v1#bib.bib5)] evaluates the effectiveness
    of instruction data by leveraging ChatGPT. INSTAG [[24](https://arxiv.org/html/2411.14497v1#bib.bib24)]
    automatically generates tags for instruction samples with ChatGPT and keeps diversity
    by selecting subsets with more tags.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过上述方法，使用LLM生成大规模指令微调数据集的成本不高。然而，对于指令微调语言模型而言，数据质量比数量更为关键。在这方面，ALPAGASUS [[5](https://arxiv.org/html/2411.14497v1#bib.bib5)]
    通过利用ChatGPT评估指令数据的有效性。INSTAG [[24](https://arxiv.org/html/2411.14497v1#bib.bib24)]
    自动为指令样本生成标签，并通过选择具有更多标签的子集来保持多样性。
- en: '![Refer to caption](img/635bb25c642d6761c56edaabeb3e7b26.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![请参考说明文字](img/635bb25c642d6761c56edaabeb3e7b26.png)'
- en: 'Figure 1: The diagram of the Star-Agents Framework. Step 1 is designed to gather
    diverse instructions and responses as shown in Appendix [A.3](https://arxiv.org/html/2411.14497v1#A1.SS3
    "A.3 Data Examples ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"). Step 2 focuses on selecting high-quality,
    tailored data from the data collected in Step 1\. Finally, Step 3 aims to enhance
    the effectiveness and efficiency of the data generation process by evolving the
    Star-Agents framework.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1：Star-Agents 框架的示意图。步骤 1 旨在收集多样化的指令和响应，如附录[A.3](https://arxiv.org/html/2411.14497v1#A1.SS3
    "A.3 Data Examples ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning")所示。步骤 2 专注于从步骤 1 中收集的数据中选择高质量的定制数据。最后，步骤
    3 旨在通过优化 Star-Agents 框架来提高数据生成过程的有效性和效率。'
- en: Cherry LLM [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)] pioneers the
    self-guided approach, using the IFD metric to measure the difficulty for an LLM
    to learn an instruction sample. This allows to select instruction samples that
    significantly enhance training efficiency without resorting to an external model.
    DEITA [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)] first uses ChatGPT
    to evaluate the complexity and quality of samples, then assesses the diversity
    of samples based on the distance between model embeddings, thereby guaranteeing
    complexity, quality, and diversity in the subset. LIFT [[46](https://arxiv.org/html/2411.14497v1#bib.bib46)]
    first guides GPT-4 to generate challenging instructions to expand the data distribution
    and then uses dimensionality reduction and row variance analysis to select representative
    high-quality data, where GPT-4 generates a quality score for each instruction.
    LESS [[43](https://arxiv.org/html/2411.14497v1#bib.bib43)] first stores the gradient
    features of samples in the dataset, then calculates the similarity between a small
    number of samples from the target task and the training data samples. Based on
    the calculated similarity scores, it selects the training samples whose gradient
    features are most similar to those of the target task samples as the fine-tuning
    instances. Data selection not only improves training efficiency but also prevents
    low-quality or poison data from undermining model performance by filtering them
    out [[47](https://arxiv.org/html/2411.14497v1#bib.bib47)].
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Cherry LLM [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)] 首创了自我引导的方法，使用
    IFD 指标来衡量 LLM 学习指令样本的难度。这使得可以选择那些显著提高训练效率的指令样本，而无需依赖外部模型。DEITA [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)]
    首先使用 ChatGPT 来评估样本的复杂性和质量，然后基于模型嵌入之间的距离评估样本的多样性，从而保证子集中的复杂性、质量和多样性。LIFT [[46](https://arxiv.org/html/2411.14497v1#bib.bib46)]
    首先引导 GPT-4 生成具有挑战性的指令，以扩展数据分布，然后使用降维和行方差分析来选择具有代表性的高质量数据，其中 GPT-4 为每个指令生成质量评分。LESS
    [[43](https://arxiv.org/html/2411.14497v1#bib.bib43)] 首先存储数据集中样本的梯度特征，然后计算目标任务的少量样本与训练数据样本之间的相似度。根据计算得出的相似度评分，它选择那些梯度特征与目标任务样本最相似的训练样本作为微调实例。数据选择不仅提高了训练效率，还通过过滤低质量或有害数据，防止它们破坏模型性能
    [[47](https://arxiv.org/html/2411.14497v1#bib.bib47)]。
- en: 3 Star-Agents
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 星级代理
- en: The aim of our research is to construct a high-quality dataset $T$ of tailored
    complexity for the target LLM through the enhancement of an initial seed dataset
    $S=(I_{i},R_{i})_{i=1}^{N}$, consisting of instruction-response pairs $(I,R)$.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的目标是通过增强初始种子数据集 $S=(I_{i},R_{i})_{i=1}^{N}$，构建一个适合目标 LLM 的高质量定制复杂度数据集 $T$，该数据集由指令-响应对
    $(I,R)$ 组成。
- en: 'To this end, we introduce the Star-Agents Framework, depicted in Figure [1](https://arxiv.org/html/2411.14497v1#S2.F1
    "Figure 1 ‣ Instruction Data Selection ‣ 2 Related Work ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning"), which is segmented
    into three steps. The first step leverages a spectrum of advanced LLMs, each trained
    independently. These models are engaged in a dynamic interaction to generate a
    diverse data candidate set $D(S_{i})$ by sampling agent-pair derived from $S_{i}$
    as detailed in Section [3.1](https://arxiv.org/html/2411.14497v1#S3.SS1 "3.1 Generating
    Diverse Data ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization with LLM
    Agents for Instruction Tuning"). Following this, we apply a dual-model evaluation
    strategy $\pi(\cdot)$ to meticulously extract the most suitable data from $D(S_{i})$,
    aiming to substantially elevate the target model’s performance. This process is
    elaborated in Section [3.2](https://arxiv.org/html/2411.14497v1#S3.SS2 "3.2 Evaluating
    Tailored Data via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning"). To enhance the effectiveness
    and efficiency of the Star-Agents framework in generating tailored data, we have
    developed an evolutionary strategy for the Star-Agents, as discussed in Section [3.3](https://arxiv.org/html/2411.14497v1#S3.SS3
    "3.3 Evolving Star Agents ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"). After these three steps, a tailored
    high-quality dataset $T$ is obtained from the seed dataset, which is formulated
    as:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们引入了星代理框架，框架结构如图[1](https://arxiv.org/html/2411.14497v1#S2.F1 "图 1 ‣ 指令数据选择
    ‣ 2 相关工作 ‣ 星代理：通过LLM代理进行指令调优的自动数据优化")所示，该框架分为三步。第一步利用一系列独立训练的先进LLM，这些模型通过动态交互生成一个多样化的数据候选集$D(S_{i})$，通过从$S_{i}$中派生的代理对进行采样，如第[3.1](https://arxiv.org/html/2411.14497v1#S3.SS1
    "3.1 生成多样化数据 ‣ 3 星代理 ‣ 星代理：通过LLM代理进行指令调优的自动数据优化")节所述。随后，我们应用双模型评估策略$\pi(\cdot)$，从$D(S_{i})$中精确提取最合适的数据，以显著提升目标模型的表现。此过程在第[3.2](https://arxiv.org/html/2411.14497v1#S3.SS2
    "3.2 通过双模型策略评估定制数据 ‣ 3 星代理 ‣ 星代理：通过LLM代理进行指令调优的自动数据优化")节中有详细描述。为了提高星代理框架在生成定制数据时的效果和效率，我们开发了一种星代理的进化策略，如第[3.3](https://arxiv.org/html/2411.14497v1#S3.SS3
    "3.3 进化星代理 ‣ 3 星代理 ‣ 星代理：通过LLM代理进行指令调优的自动数据优化")节中所讨论的那样。在这三步之后，从种子数据集获得一个定制的高质量数据集$T$，该数据集的公式为：
- en: '|  | $T=\{\mathop{\arg\max_{d\in D(S_{i})}}\pi\left(D(S_{i})\right)~{}&#124;~{}i=1,2,%
    \cdots,N\}.$ |  | (1) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | $T=\{\mathop{\arg\max_{d\in D(S_{i})}}\pi\left(D(S_{i})\right)~{}&#124;~{}i=1,2,%
    \cdots,N\}.$ |  | (1) |'
- en: 3.1 Generating Diverse Data
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 生成多样化数据
- en: To improve the instruction-tuned model, it is crucial to assemble a high-quality
    and diverse instruction dataset [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)].
    Traditional methods often use a single LLM, such as ChatGPT, for data enrichment.
    In contrast, our approach employs multiple LLMs to avoid monotonous data distribution.
    This multifaceted strategy also addresses the limitations and risks of quality
    degradation on domain-specific tasks associated with using a single model. To
    counter these challenges, we propose to use an Agent-Pair strategy.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进指令微调模型，组建一个高质量且多样化的指令数据集是至关重要的[[22](https://arxiv.org/html/2411.14497v1#bib.bib22)]。传统方法通常使用单一的大型语言模型（LLM），例如ChatGPT，进行数据增强。相比之下，我们的方法采用多个LLM，以避免单一数据分布的单调性。这种多面策略还解决了使用单一模型在特定领域任务中质量下降的局限性和风险。为了解决这些挑战，我们提出使用Agent-Pair策略。
- en: Agent-Pair.
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理对（Agent-Pair）。
- en: Utilizing a spectrum of LLMs, each trained with discrepant setting, facilitates
    the generation of varied responses to given instructions. This diversity is crucial
    for synthesizing a dataset characterized by high richness [[24](https://arxiv.org/html/2411.14497v1#bib.bib24)].
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 利用一系列不同设置训练的大型语言模型（LLMs），可以促进生成多样化的响应。这种多样性对于合成一个高丰富度的数据集至关重要[[24](https://arxiv.org/html/2411.14497v1#bib.bib24)]。
- en: 'The Star-Agents framework strategically pairs different LLMs to rewrite the
    instructions in the seed dataset and generate new responses to increase the diversity.
    With agent-pair $(A^{I}_{j},A^{R}_{k})$, a new instruction data can be generated
    as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 星代理框架（Star-Agents framework）战略性地将不同的LLM配对，用以重写种子数据集中的指令，并生成新的响应以增加多样性。通过代理对$(A^{I}_{j},A^{R}_{k})$，可以生成新的指令数据，具体如下：
- en: '|  | $f_{j,k}\left(I_{i},R_{i}\right)=(A^{I}_{j}(I_{i}),A^{R}_{k}(R_{i})),$
    |  | (2) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{j,k}\left(I_{i},R_{i}\right)=(A^{I}_{j}(I_{i}),A^{R}_{k}(R_{i})),$
    |  | (2) |'
- en: where $A^{I}$ and $A^{R}$ represent the agents that rewrites the instruction
    and response to the instruction, respectively.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$A^{I}$和$A^{R}$分别表示重写指令和响应指令的代理。
- en: 'Given the high cost of deploying all agent-pairs, a feasible solution to balance
    cost and agent diversity is to sample a subset of agent-pairs from the Star-Agents
    for data generation. Equation [3](https://arxiv.org/html/2411.14497v1#S3.E3 "In
    Agent-Pair. ‣ 3.1 Generating Diverse Data ‣ 3 Star-Agents ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning") formulates this process,
    where $D$ is collected dataset generated by performing $f$ over all sampled pairs
    $(A^{I}_{j},A^{R}_{k})$ of instruction agents $A^{I}_{j}$ and response agent $A^{R}_{k}$
    with sampling probabilities $p_{jk}$:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '鉴于部署所有代理对的高成本，平衡成本和代理多样性的可行方案是从Star-Agents中采样一个代理对子集用于数据生成。公式[3](https://arxiv.org/html/2411.14497v1#S3.E3
    "In Agent-Pair. ‣ 3.1 Generating Diverse Data ‣ 3 Star-Agents ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning")公式化了这个过程，其中$D$是通过对所有采样对$(A^{I}_{j},A^{R}_{k})$（指令代理$A^{I}_{j}$和响应代理$A^{R}_{k}$）执行$f$操作生成的收集数据集，采样概率为$p_{jk}$：'
- en: '|  | $\displaystyle D\left(S_{i}\right)=\{f_{j_{1},k_{1}}\left(S_{i}\right),\cdots,f%
    _{j_{M},k_{M}}\left(S_{i}\right)~{}&#124;~{}(j_{m},k_{m})\sim p_{jk},m=1,2,\cdots,M\},$
    |  | (3) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle D\left(S_{i}\right)=\{f_{j_{1},k_{1}}\left(S_{i}\right),\cdots,f_{j_{M},k_{M}}\left(S_{i}\right)~{}&#124;~{}(j_{m},k_{m})\sim
    p_{jk},m=1,2,\cdots,M\},$ |  | (3) |'
- en: '$M$ is number of agent-pairs sampled for a single seed sample. The sampling
    probability $p_{jk}$ is initialized as a uniform distribution and will be updated
    using the method described in Subsection [3.3](https://arxiv.org/html/2411.14497v1#S3.SS3
    "3.3 Evolving Star Agents ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning") during data generation. Meanwhile, an
    Instruction Memory Bank that stores high-quality instructions will be updated.
    To ensure the lower bound of data quality, each iteration will consistently call
    a fixed set of agent-pairs, referred to as base agent-pairs.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '$M$是为单一种子样本采样的代理对数。采样概率$p_{jk}$初始化为均匀分布，并将在数据生成过程中使用[3.3](https://arxiv.org/html/2411.14497v1#S3.SS3
    "3.3 Evolving Star Agents ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning")小节中描述的方法更新。同时，一个存储高质量指令的指令记忆库也将进行更新。为了确保数据质量的下限，每次迭代将始终调用一组固定的代理对，称为基础代理对。'
- en: 3.2 Evaluating Tailored Data via a Dual-model Strategy
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 通过双模型策略评估定制数据
- en: Identifying and selecting tailored data from a diverse dataset is crucial for
    enhancing model performance, especially since the presence of low-quality data
    can impede model functionality. It is acknowledged that data samples that are
    lengthy, complex, and challenging significantly benefit the instruction tuning
    process [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)].
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从多样化的数据集中识别并选择量身定制的数据对于提升模型性能至关重要，特别是因为低质量数据的存在会妨碍模型的功能。已经承认，长且复杂的、高难度的数据样本对指令调优过程有显著益处[[22](https://arxiv.org/html/2411.14497v1#bib.bib22)]。
- en: 'Nevertheless, too complex instruction data may be not necessarily benefit model
    performance. We have observed that for models with 14M and 70M parameters as illustrated
    in Figure [2](https://arxiv.org/html/2411.14497v1#S3.F2 "Figure 2 ‣ 3.2 Evaluating
    Tailored Data via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning"), the Evol-Instruct
    dataset, though more challenging than the Alpaca dataset, results in diminished
    model performance. This suggests that intricate examples may surpass the capabilities
    of small models and be harmful for model performance, despite the advantages of
    using complex data for large models.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，过于复杂的指令数据不一定能有助于模型性能。我们观察到，对于如图[2](https://arxiv.org/html/2411.14497v1#S3.F2
    "Figure 2 ‣ 3.2 Evaluating Tailored Data via a Dual-model Strategy ‣ 3 Star-Agents
    ‣ Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning")所示的14M和70M参数的模型，尽管Evol-Instruct数据集比Alpaca数据集更具挑战性，但其结果却导致了模型性能的下降。这表明，复杂的示例可能会超出小型模型的能力，并且尽管对大模型使用复杂数据具有优势，但对小型模型来说，复杂数据可能会对性能造成负面影响。'
- en: '![[Uncaptioned image]](img/d7109f17c26338dc8573c7db2010a069.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![[无标题图像]](img/d7109f17c26338dc8573c7db2010a069.png)'
- en: 'Figure 2: Performance comparison of varied-scale models on the Alpaca and Evol-Instruct
    datasets. The tasks from the Evol-Instruct dataset are more complex than those
    from Alpaca.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：不同规模模型在Alpaca和Evol-Instruct数据集上的性能比较。Evol-Instruct数据集的任务比Alpaca数据集的任务更为复杂。
- en: '![[Uncaptioned image]](img/097918b2bd407337b5d61185aa702024.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![[无标题图像]](img/097918b2bd407337b5d61185aa702024.png)'
- en: 'Figure 3: Illustration of dual-model evaluation. Data with a significant gap
    between the IFD scores of the small and large models will be prioritised.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：双模型评估的示意图。小模型和大模型的IFD分数差距显著的数据将优先考虑。
- en: Dual-model Evaluation.
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 双模型评估。
- en: To address the issue mentioned above, we propose to use a larger model to evaluate
    the difficulty of data instances together with the evaluation from a smaller model
    (target LLM), hence termed as dual-model evaluation. Inspired by Cherry LLM [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)],
    we employ the IFD metric to measure the degree of difficulty a data sample presents
    to the target model, which is calcuated as
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，我们提出使用更大的模型来评估数据实例的难度，同时结合来自较小模型（目标LLM）的评估，因此称为双模型评估。受到Cherry LLM [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)]的启发，我们使用IFD度量来衡量数据样本对目标模型所呈现的难度，计算公式如下
- en: '|  | $\mathrm{IFD}(I_{i},R_{i})=\frac{\exp\left(-\frac{1}{&#124;R_{i}&#124;}\sum_{w\in
    R_{i}}% \log P(w&#124;I_{i})\right)}{\exp\left(-\frac{1}{&#124;R_{i}&#124;}\sum_{w\in
    R_{i}}\log P(w)% \right)}.$ |  | (4) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathrm{IFD}(I_{i},R_{i})=\frac{\exp\left(-\frac{1}{|R_{i}|}\sum_{w\in
    R_{i}}% \log P(w|I_{i})\right)}{\exp\left(-\frac{1}{|R_{i}|}\sum_{w\in R_{i}}\log
    P(w)% \right)}.$ |  | (4) |'
- en: 'We assume that for the same sample, stronger model yields a smaller IFD score.
    When the IFD scores of the two models are close to each other, it indicates that
    the sample is either too simple or too complex, which is not contributive to effective
    learning. However, when their IFD scores differ significantly, it indicates that
    the data is sufficiently complex for the smaller model but still within the capability
    range of the stronger model. This is a tailored complexity for facilitating learning.
    The above data assessment method is illustrated at Figure [3](https://arxiv.org/html/2411.14497v1#S3.F3
    "Figure 3 ‣ 3.2 Evaluating Tailored Data via a Dual-model Strategy ‣ 3 Star-Agents
    ‣ Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning")
    and formulated as'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设对于同一样本，较强的模型会产生较小的IFD分数。当两个模型的IFD分数接近时，表示该样本要么过于简单，要么过于复杂，这对有效学习没有贡献。然而，当它们的IFD分数差异显著时，表明该数据对较小的模型来说足够复杂，但仍在较强模型的能力范围内。这是一种量身定制的复杂度，旨在促进学习。上述数据评估方法在图[3](https://arxiv.org/html/2411.14497v1#S3.F3
    "图3 ‣ 3.2 通过双模型策略评估定制数据 ‣ 3 星级代理 ‣ 星级代理：通过LLM代理进行指令调优的自动数据优化")中进行了说明，并公式化为
- en: '|  | $\pi_{\mathrm{dual}}^{i}=\frac{\mathrm{IFD}_{\mathrm{small}}(I_{i},R_{i})-%
    \mathrm{IFD}_{\mathrm{large}}(I_{i},R_{i})}{\max\limits_{1\leq i\leq m}(% \mathrm{IFD}_{\mathrm{small}}(I_{i},R_{i})-\mathrm{IFD}_{\mathrm{large}}(I_{i}%
    ,R_{i}))}.$ |  | (5) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | $\pi_{\mathrm{dual}}^{i}=\frac{\mathrm{IFD}_{\mathrm{small}}(I_{i},R_{i})-%
    \mathrm{IFD}_{\mathrm{large}}(I_{i},R_{i})}{\max\limits_{1\leq i\leq m}(% \mathrm{IFD}_{\mathrm{small}}(I_{i},R_{i})-\mathrm{IFD}_{\mathrm{large}}(I_{i}%
    ,R_{i}))}.$ |  | (5) |'
- en: 'Noising data can be endowed with high score since the dual-model metric considers
    only the relative complexity with the neglect of generation quality. To address
    this issue, we utilize an LLM as referee for data sample scoring. This involves
    comparing each data sample in the same batch of diverse data samples generated
    by selected agent-pairs against a base data sample generated by base agent-pairs.
    There are three potential outcomes: the base data sample is better, the diverse
    data sample is better, or a tie, as shown in Appendix [A.1](https://arxiv.org/html/2411.14497v1#A1.SS1
    "A.1 Prompt Examples ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"). These outcomes are quantitatively assigned
    as quality scores, thereby avoiding collecting noising instruction samples:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声数据可能会被赋予较高的分数，因为双模型度量仅考虑相对复杂度，而忽略了生成质量。为了解决这个问题，我们使用LLM作为数据样本评分的裁判。这涉及将同一批次中由选定的代理对生成的多样化数据样本与由基础代理对生成的基础数据样本进行比较。可能的三种结果是：基础数据样本更好、多样化数据样本更好或平局，如附录[A.1](https://arxiv.org/html/2411.14497v1#A1.SS1
    "A.1 提示示例 ‣ 附录 A 附录 ‣ 星级代理：通过LLM代理进行指令调优的自动数据优化")所示。这些结果会被定量地分配为质量分数，从而避免收集噪声指令样本：
- en: '|  | $\pi_{\mathrm{llm}}=\begin{cases}0,&\text{if the base data sample is better},\\
    1,&\text{if the generated data sample is better},\\ 0.5,&\text{if tie}.\\ \end{cases}$
    |  | (6) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '|  | $\pi_{\mathrm{llm}}=\begin{cases}0,&\text{如果基础数据样本更好},\\ 1,&\text{如果生成的数据样本更好},\\
    0.5,&\text{如果平局}.\\ \end{cases}$ |  | (6) |'
- en: 'Finally, the evaluation scores from both the LLM and the dual-model evaluation
    are combined to compute a final composite score:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，来自LLM和双模型评估的评估分数会被结合起来，计算出最终的综合分数：
- en: '|  | $\pi=\pi_{\mathrm{llm}}\cdot\pi_{\mathrm{dual}}.$ |  | (7) |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|  | $\pi=\pi_{\mathrm{llm}}\cdot\pi_{\mathrm{dual}}.$ |  | (7) |'
- en: 'This score determines the overall quality and suitability of data for enhancing
    the model’s capabilities. The highest scoring data sample is then selected into
    dataset $T$ and Instruction Memory Bank as detailed in Section [3.3](https://arxiv.org/html/2411.14497v1#S3.SS3
    "3.3 Evolving Star Agents ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"), ensuring that the chosen dataset maximizes
    potential improvements in model performance.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '该分数决定了数据的整体质量和适用性，用于增强模型的能力。最高得分的数据样本将被选入数据集$T$和指令记忆库，如[3.3节](https://arxiv.org/html/2411.14497v1#S3.SS3
    "3.3 Evolving Star Agents ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning")所述，确保选择的数据集最大限度地提高模型性能的潜力。'
- en: 3.3 Evolving Star Agents
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 演化星级代理
- en: 'As mentioned in Section [3.1](https://arxiv.org/html/2411.14497v1#S3.SS1 "3.1
    Generating Diverse Data ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"), we use the joint probability of instruction
    agents and response agents to regulate the invocation of each agent-pair. Considering
    the abilities and specialities of each LLM vary, however, sampling each agent-pair
    with the same probability is not optimal. We hence use the score from Section
    [3.2](https://arxiv.org/html/2411.14497v1#S3.SS2 "3.2 Evaluating Tailored Data
    via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning") to dynamically evolve the sampling probability.
    Additionally, since the generation performance of agent-pairs is task-dependent,
    we also propose an Instruction Memory Bank to select the most suitable agent-pair
    for particular tasks.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '如[3.1节](https://arxiv.org/html/2411.14497v1#S3.SS1 "3.1 Generating Diverse
    Data ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization with LLM Agents
    for Instruction Tuning")所述，我们使用指令代理和响应代理的联合概率来调节每个代理对的调用。然而，由于每个LLM的能力和特长不同，用相同的概率对每个代理对进行采样并非最优。因此，我们使用[3.2节](https://arxiv.org/html/2411.14497v1#S3.SS2
    "3.2 Evaluating Tailored Data via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning")中的分数来动态演化采样概率。此外，由于代理对的生成性能与任务相关，我们还提出了一个指令记忆库，以选择最适合特定任务的代理对。'
- en: Agent-Pair Sampling Evolution.
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理对采样演化。
- en: 'Section [3.2](https://arxiv.org/html/2411.14497v1#S3.SS2 "3.2 Evaluating Tailored
    Data via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning") has introduced the score $\pi$, which
    effectively estimates the quality of generated samples. During each iteration,
    if the generated samples are of high quality, we will increase the sampling probability
    of the selected agent-pair, which is updated as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[3.2节](https://arxiv.org/html/2411.14497v1#S3.SS2 "3.2 Evaluating Tailored
    Data via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning")介绍了分数$\pi$，该分数有效地估算了生成样本的质量。在每次迭代中，如果生成的样本质量较高，我们将增加所选代理对的采样概率，更新公式如下：'
- en: '|  | $\displaystyle\begin{split}\tilde{p}_{jk}&=p_{jk}+\beta\cdot\pi(I_{i},R_{i}),\\
    p_{jk}&\leftarrow\frac{\tilde{p}_{jk}}{\sum_{j,k}\tilde{p}_{jk}}.\end{split}$
    |  | (8) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\begin{split}\tilde{p}_{jk}&=p_{jk}+\beta\cdot\pi(I_{i},R_{i}),\\
    p_{jk}&\leftarrow\frac{\tilde{p}_{jk}}{\sum_{j,k}\tilde{p}_{jk}}.\end{split}$
    |  | (8) |'
- en: The updated sampling probability for the agent-pair of the $j$-th instruction
    agent and $k$-th response agent that successfully process the $i$-th data sample
    will be used in the next iteration, where $\beta$ denotes the evolution rate.This
    formula adjusts the sampling probabilities based on the effectiveness demonstrated
    by agent-pairs in generating relevant data. Iterative updates ensure that as the
    synthesis process advances, the probability of selecting more effective agent-pairs
    increases, while less effective pairs are gradually phased out.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第$j$个指令代理和第$k$个响应代理成功处理第$i$个数据样本后的更新采样概率，将在下一次迭代中使用，其中$\beta$表示演化速率。此公式根据代理对生成相关数据的效果调整采样概率。迭代更新确保随着合成过程的推进，选择更有效代理对的概率增加，而较低效的代理对则逐渐被淘汰。
- en: Instruction Memory Bank Evolution.
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指令记忆库演化。
- en: 'We establish an Instruction Memory Bank storing high-quality instructions aiming
    to accelerate sampling and relate the evolution with task data. When processing
    a data sample $(I_{i},R_{i})$, we perform a query in the Instruction Memory Bank
    for $I_{i}$, retrieving the top $n$ closest matches according to embedding similarity.
    The associated agent-pairs, identified as highly proficient for tasks similar
    to $I_{i}$, are then sampled. We sample $l$ agent-pairs from this pool using normalized
    probabilities to generate diverse data. Moreover, to foster the creation of a
    diverse dataset, additional $M-l$ agent-pairs are sampled from the remaining pool
    using their respective probabilities to assist in data synthesis. As a result,
    $M$ new samples are generated and then feed for data assessment. Subsequently,
    the Instruction Memory Bank will continuously evolve by incorporating tailored
    high-quality data, which get high socres as introduced in Section [3.2](https://arxiv.org/html/2411.14497v1#S3.SS2
    "3.2 Evaluating Tailored Data via a Dual-model Strategy ‣ 3 Star-Agents ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning").'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '我们建立了一个指令记忆库，用于存储高质量的指令，旨在加速采样并将演化与任务数据相关联。在处理数据样本$(I_{i},R_{i})$时，我们在指令记忆库中查询$I_{i}$，根据嵌入相似性检索出前$n$个最接近的匹配项。与之关联的任务能力强的代理对被识别为与$I_{i}$相似的任务高度熟练，然后进行采样。我们从这个池中使用归一化概率采样$l$个代理对，以生成多样化的数据。此外，为了促进多样化数据集的创建，我们还将从剩余池中使用各自的概率额外采样$M-l$个代理对来协助数据合成。因此，生成了$M$个新样本，然后进行数据评估。随后，指令记忆库将通过融入定制的高质量数据持续演化，这些数据在第[3.2](https://arxiv.org/html/2411.14497v1#S3.SS2
    "3.2 通过双模型策略评估定制数据 ‣ 3 Star-Agents ‣ Star-Agents: 使用LLM代理进行指令调优的自动数据优化")节中介绍的高分数中得到体现。'
- en: 4 Experiments
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: We conducted extensive experiments to evaluate the proposed Star-Agents framework.
    A wide range of LLMs, benchmark datasets were used in our experiments to guarantee
    the robustness of our evaluation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了广泛的实验，以评估所提出的Star-Agents框架。在我们的实验中，使用了多种LLM和基准数据集，以确保评估的稳健性。
- en: 4.1 Setups
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 设置
- en: Datasets.
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集。
- en: In alignment with the WizardLM [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)],
    we adopted the Supervised Fine-Tuning (SFT) dataset, designated as the Evol-Instruct
    dataset, which consists of 70,000 instruction-response pairs. The instructions
    in this dataset were refined using “In-Depth Evolving” and “In-Breadth Evolving”
    methods, which were tailored to enhance the base instructions by adding intricate
    details or expanding the overall scope, respectively. To guarantee the fidelity
    of the data, ChatGPT was also integrated as generator into the refinement process.
    The quality of the instruction data from the Evol-Instruct dataset has been validated
    as superior [[44](https://arxiv.org/html/2411.14497v1#bib.bib44), [25](https://arxiv.org/html/2411.14497v1#bib.bib25)];
    hence, our research continues to leverage these refined instructions. Employing
    the Star-Agents framework, our study invokes multiple LLMs to generate diverse
    and high-quality responses for these instructions. For further enriching our comparative
    analysis, we employed the Alpaca dataset [[32](https://arxiv.org/html/2411.14497v1#bib.bib32)],
    comprising 52,000 instruction-following samples. This dataset, developed under
    the self-instruct paradigm, utilizes the ChatGPT¹¹1https://chatgpt.com/ instead
    of text-davinci-003 for a fair comparison  [[44](https://arxiv.org/html/2411.14497v1#bib.bib44)].
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与WizardLM[[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]保持一致，我们采用了监督微调（SFT）数据集，该数据集被指定为Evol-Instruct数据集，包含70,000对指令-响应对。该数据集中的指令通过“深度演化”和“广度演化”方法进行了精细化，这些方法分别通过添加复杂细节或扩展整体范围来增强基本指令。为了确保数据的准确性，ChatGPT也作为生成器集成到精细化过程中。Evol-Instruct数据集中的指令数据质量已被验证为优越[[44](https://arxiv.org/html/2411.14497v1#bib.bib44),
    [25](https://arxiv.org/html/2411.14497v1#bib.bib25)]；因此，我们的研究继续利用这些精细化的指令。通过使用Star-Agents框架，我们的研究调用多个LLM生成多样化且高质量的响应。为了进一步丰富我们的对比分析，我们使用了Alpaca数据集[[32](https://arxiv.org/html/2411.14497v1#bib.bib32)]，该数据集包含52,000个遵循指令的样本。该数据集在自指令范式下开发，使用ChatGPT¹¹1https://chatgpt.com/而非text-davinci-003进行公平比较[[44](https://arxiv.org/html/2411.14497v1#bib.bib44)]。
- en: 'Table 1: Typical LLMs utilized in Star-Agents.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：在Star-Agents中使用的典型LLM。
- en: '| Model Famliy | Model Size | Data Size | Method | Source |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 模型系列 | 模型大小 | 数据大小 | 方法 | 来源 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Phi [[11](https://arxiv.org/html/2411.14497v1#bib.bib11)] | 2.7B | 1.4T |
    Pretrain | Microsoft |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Phi [[11](https://arxiv.org/html/2411.14497v1#bib.bib11)] | 2.7B | 1.4T |
    预训练 | 微软 |'
- en: '| ChatGLM [[51](https://arxiv.org/html/2411.14497v1#bib.bib51)] | 6B | 1T+
    | SFT & RLHF | Zhipu AI |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| ChatGLM [[51](https://arxiv.org/html/2411.14497v1#bib.bib51)] | 6B | 1T+
    | SFT & RLHF | 智谱AI |'
- en: '| Gemma [[34](https://arxiv.org/html/2411.14497v1#bib.bib34)] | 7B | 6T | SFT
    & RLHF | Google |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Gemma [[34](https://arxiv.org/html/2411.14497v1#bib.bib34)] | 7B | 6T | SFT
    & RLHF | 谷歌 |'
- en: '| Mistral [[12](https://arxiv.org/html/2411.14497v1#bib.bib12)] | 7B | - |
    SFT | Mistral |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Mistral [[12](https://arxiv.org/html/2411.14497v1#bib.bib12)] | 7B | - |
    SFT | Mistral |'
- en: '| Qwen [[1](https://arxiv.org/html/2411.14497v1#bib.bib1)] | 14B | - | SFT
    & RLHF | Alibaba |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Qwen [[1](https://arxiv.org/html/2411.14497v1#bib.bib1)] | 14B | - | SFT
    & RLHF | 阿里巴巴 |'
- en: '| ChatGPT | - | - | SFT & RLHF | OpenAI |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | - | - | SFT & RLHF | OpenAI |'
- en: Models.
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型。
- en: In response to the growing need for cost-effective inference of LLMs at the
    edge, our study explores the capabilities of target models scaled at 1B and 7B
    parameters. The 1B models, specifically the Pythia-1B [[2](https://arxiv.org/html/2411.14497v1#bib.bib2)],
    were trained on roughly 300 billion tokens derived from the Pile dataset. The
    7B models, represented by the Llama-2-7B [[35](https://arxiv.org/html/2411.14497v1#bib.bib35)],
    were trained on an extensive corpus of 2 trillion tokens.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 针对在边缘设备上进行低成本推理的日益增长需求，我们的研究探索了规模为1B和7B参数的目标模型的能力。1B模型，特别是Pythia-1B [[2](https://arxiv.org/html/2411.14497v1#bib.bib2)]，是基于约3000亿个标记从Pile数据集派生而来进行训练的。7B模型，由Llama-2-7B
    [[35](https://arxiv.org/html/2411.14497v1#bib.bib35)]表示，经过2万亿个标记的广泛语料库训练。
- en: 'During our experiments, we integrated as generator a diverse array of LLMs,
    as detailed in Table [1](https://arxiv.org/html/2411.14497v1#S4.T1 "Table 1 ‣
    Datasets. ‣ 4.1 Setups ‣ 4 Experiments ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"). Our hypothesis posits that models from
    different development teams possess unique capabilities, yielding rich responses
    to identical prompts due to the diversity in their training data and strategies.
    For instance, the Phi2 [[11](https://arxiv.org/html/2411.14497v1#bib.bib11)] employed
    1.4T tokens of meticulously curated textbook-like data without undergoing Reinforcement
    Learning with Human Feedback (RLHF) while the Gemma [[34](https://arxiv.org/html/2411.14497v1#bib.bib34)]
    was trained on 6T tokens primarily sourced from English web documents, mathematical
    content, and code, with subsequent fine-tuning through SFT and RLHF. To ensure
    the diversity and quality of generated data, we assembled LLMs trained by different
    teams, widely regarded for their exceptional performance. In pursuit of fostering
    the generation of data across varying levels of difficulty, the utilized LLMs
    range from 2.7B to 14B parameters, including even larger models via API access.
    For a fair comparison with the Evol-Instruct dataset, the most capable model employed
    was the ChatGPT, which was also used for generating responses within the Evol-Instruct
    dataset. Notably, the ChatGPT was also served as evaluator to compute the comparison
    score $\pi_{\mathrm{llm}}$.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '在我们的实验中，我们集成了多种LLM模型作为生成器，具体细节见表[1](https://arxiv.org/html/2411.14497v1#S4.T1
    "Table 1 ‣ Datasets. ‣ 4.1 Setups ‣ 4 Experiments ‣ Star-Agents: Automatic Data
    Optimization with LLM Agents for Instruction Tuning")。我们的假设是，不同开发团队的模型具有独特的能力，因其训练数据和策略的多样性，对相同提示产生丰富的响应。例如，Phi2
    [[11](https://arxiv.org/html/2411.14497v1#bib.bib11)]使用了1.4万亿个精心策划的教材数据进行训练，且未经过人类反馈强化学习（RLHF），而Gemma
    [[34](https://arxiv.org/html/2411.14497v1#bib.bib34)]则使用了6万亿个主要来自英文网络文档、数学内容和代码的数据进行训练，之后通过SFT和RLHF进行微调。为了确保生成数据的多样性和质量，我们集合了不同团队训练的LLM模型，这些团队因其卓越表现而广受认可。为了促进生成不同难度层次的数据，我们使用的LLM模型参数范围从2.7B到14B，包括通过API访问的更大模型。为了与Evol-Instruct数据集进行公平比较，使用的最强模型是ChatGPT，它也被用于生成Evol-Instruct数据集中的响应。值得注意的是，ChatGPT还作为评估者来计算比较得分$\pi_{\mathrm{llm}}$。'
- en: Benchmarks.
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准测试。
- en: 'To rigorously evaluate the instruction-following capabilities of AI models,
    we utilized three widely used benchmarks: MT-bench, Vicuna-bench, and the WizardLM
    testset. Specifically, MT-bench and Vicuna-bench are designed to test the models’
    competencies in various complex cognitive tasks, including mathematics, reasoning,
    complex format handling, and writing through both multi-turn and single-turn dialogues.
    The WizardLM testset, conversely, extends the evaluation to encompass diverse
    fields such as technology, biology, and law. It also features varied difficulty
    levels to facilitate a more nuanced comparison of models’ performance disparities.
    Following established protocols, we employed the Fast-Chat [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)]
    to assess model performances, with GPT-4 acting as the judge model.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了严格评估 AI 模型的指令跟随能力，我们使用了三个广泛使用的基准测试：MT-bench、Vicuna-bench 和 WizardLM 测试集。具体来说，MT-bench
    和 Vicuna-bench 旨在测试模型在各种复杂认知任务中的能力，包括数学、推理、复杂格式处理以及通过多轮和单轮对话进行写作。相反，WizardLM 测试集扩展了评估范围，涵盖了技术、生物学和法律等多个领域。它还具有不同的难度级别，以便更细致地比较模型的性能差异。按照既定协议，我们使用了
    Fast-Chat [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)] 来评估模型性能，以 GPT-4
    作为评判模型。
- en: Baselines.
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准线。
- en: For baseline comparisons, we employed the Pythia-1B and Llama-2-7B, both trained
    using the Evol-Instruct datasets. The Alpaca datasets were also referenced for
    comparative analysis, alongside IFD [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)]
    and Random select as an additional comparsion for data selection methods.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行基准线比较，我们使用了 Pythia-1B 和 Llama-2-7B 两个模型，它们都是使用 Evol-Instruct 数据集进行训练的。此外，还参考了
    Alpaca 数据集进行比较分析，同时将 IFD [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)]
    和随机选择作为数据选择方法的附加比较。
- en: Implementation Details.
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实施细节。
- en: We fine-tuned our models (Pythia-1B and Llama-2-7B) over three epochs using
    the Adam optimizer, with an initial learning rate of $2\times 10^{-5}$, a maximum
    token count of 2048, and a batch size of 64\. For the Star-Agents, 10 agent-pairs
    were employed.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Adam 优化器对我们的模型（Pythia-1B 和 Llama-2-7B）进行了三轮微调，初始学习率为 $2\times 10^{-5}$，最大
    token 数为 2048，批次大小为 64。对于 Star-Agents，我们使用了 10 对代理进行训练。
- en: 4.2 Main Results
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 主要结果
- en: 'Table 2: Results of different models on Vicuna-bench, WizardLM testset and
    MT-Bench.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同模型在 Vicuna-bench、WizardLM 测试集和 MT-Bench 上的结果。
- en: '| Model | Vicuna-Bench | WizardLM testset | MT-Bench | Average |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | Vicuna-Bench | WizardLM 测试集 | MT-Bench | 平均值 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1B Models |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 1B 模型 |'
- en: '| --- |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Pythia-1B [[2](https://arxiv.org/html/2411.14497v1#bib.bib2)] | 1.68 | 1.34
    | 1.17 | 1.40 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B [[2](https://arxiv.org/html/2411.14497v1#bib.bib2)] | 1.68 | 1.34
    | 1.17 | 1.40 |'
- en: '| OPT-1.3B [[52](https://arxiv.org/html/2411.14497v1#bib.bib52)] | 2.49 | 1.64
    | 1.12 | 1.75 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| OPT-1.3B [[52](https://arxiv.org/html/2411.14497v1#bib.bib52)] | 2.49 | 1.64
    | 1.12 | 1.75 |'
- en: '| Sheared-LLaMA-1.3B [[42](https://arxiv.org/html/2411.14497v1#bib.bib42)]
    | 2.73 | 1.86 | 1.59 | 2.06 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Sheared-LLaMA-1.3B [[42](https://arxiv.org/html/2411.14497v1#bib.bib42)]
    | 2.73 | 1.86 | 1.59 | 2.06 |'
- en: '| Pythia-1B-alpaca | 4.14 | 2.97 | 2.20 | 3.10 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-alpaca | 4.14 | 2.97 | 2.20 | 3.10 |'
- en: '| Pythia-1B-evol_instruct | 5.07 | 3.55 | 2.56 | 3.73 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-evol_instruct | 5.07 | 3.55 | 2.56 | 3.73 |'
- en: '| Pythia-1B-IFD [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)] | 4.60
    | 3.21 | 1.98 | 3.26 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-IFD [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)] | 4.60
    | 3.21 | 1.98 | 3.26 |'
- en: '| Pythia-1B-Random | 5.13 | 3.39 | 2.35 | 3.62 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-Random | 5.13 | 3.39 | 2.35 | 3.62 |'
- en: '| Pythia-1B-star_instruct | 5.93 | 3.90 | 2.69 | 4.17 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-star_instruct | 5.93 | 3.90 | 2.69 | 4.17 |'
- en: '| 7B Models |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 7B 模型 |'
- en: '| Llama-2-7B [[35](https://arxiv.org/html/2411.14497v1#bib.bib35)] | - | -
    | 3.95 | - |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B [[35](https://arxiv.org/html/2411.14497v1#bib.bib35)] | - | -
    | 3.95 | - |'
- en: '| zephyr-beta-sft [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)] | -
    | - | 5.32 | - |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| zephyr-beta-sft [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)] | -
    | - | 5.32 | - |'
- en: '| mpt-7B-chat [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)] | - | -
    | 5.45 | - |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| mpt-7B-chat [[22](https://arxiv.org/html/2411.14497v1#bib.bib22)] | - | -
    | 5.45 | - |'
- en: '| XGen-7B-8k-Inst [[26](https://arxiv.org/html/2411.14497v1#bib.bib26)] | -
    | - | 5.55 | - |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| XGen-7B-8k-Inst [[26](https://arxiv.org/html/2411.14497v1#bib.bib26)] | -
    | - | 5.55 | - |'
- en: '| sRecycled-Wiz-7B-v2 [[17](https://arxiv.org/html/2411.14497v1#bib.bib17)]
    | - | - | 5.56 | - |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| sRecycled-Wiz-7B-v2 [[17](https://arxiv.org/html/2411.14497v1#bib.bib17)]
    | - | - | 5.56 | - |'
- en: '| Llama-2-7B-alpaca | 6.33 | 5.08 | 3.63 | 5.01 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-alpaca | 6.33 | 5.08 | 3.63 | 5.01 |'
- en: '| Llama-2-7B-evol_instruct | 7.27 | 6.57 | 5.21 | 6.35 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-evol_instruct | 7.27 | 6.57 | 5.21 | 6.35 |'
- en: '| Llama-2-7B-star_instruct | 8.24 | 6.87 | 5.74 | 6.95 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-star_instruct | 8.24 | 6.87 | 5.74 | 6.95 |'
- en: GPT-4 Automatic Evaluation
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GPT-4 自动评估
- en: 'Based on the findings summarized in Table [2](https://arxiv.org/html/2411.14497v1#S4.T2
    "Table 2 ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning"), comprehensive training sessions were
    conducted for the Pythia-1B and Llama-2-7B models utilizing three distinct datasets:
    Alpaca, Evol-Instruct, and the optimally refined Star Instruct datasets. The latter
    was developed through the application of Star-Agents, which are derivatives of
    the Evol-Instruct datasets. Through comparative analyses with other contemporary
    state-of-the-art models, we observe that the SFT-aligned models employing the
    Star Instruct datasets consistently outperform nearly all aligned counterparts,
    across all evaluated model families.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '根据表[2](https://arxiv.org/html/2411.14497v1#S4.T2 "Table 2 ‣ 4.2 Main Results
    ‣ 4 Experiments ‣ Star-Agents: Automatic Data Optimization with LLM Agents for
    Instruction Tuning")中总结的研究结果，针对Pythia-1B和Llama-2-7B模型进行了全面的训练，使用了三种不同的数据集：Alpaca、Evol-Instruct以及优化过的Star
    Instruct数据集。后者是通过应用Star-Agents开发的，Star-Agents是Evol-Instruct数据集的衍生物。通过与其他当代最先进模型的对比分析，我们发现，采用Star
    Instruct数据集的SFT对齐模型在所有评估的模型系列中，一直优于几乎所有对齐的同行模型。'
- en: '![Refer to caption](img/dcc4e176b75b2d092248745a2b8ca5e9.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/dcc4e176b75b2d092248745a2b8ca5e9.png)'
- en: (a) Vicuna-bench
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Vicuna-bench
- en: '![Refer to caption](img/a85052a14d49a189f806f368343b258f.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/a85052a14d49a189f806f368343b258f.png)'
- en: (b) MT-bench
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: (b) MT-bench
- en: 'Figure 4: Radar plot of detailed scores for Llama-2-7B-star_instrcut against
    the major baseline on different subtasks of (a) Vicuna-Bench and (b) MT-Bench.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：Llama-2-7B-star_instrcut在不同子任务上的详细得分雷达图，比较了主要基线（a）Vicuna-Bench和（b）MT-Bench。
- en: 'Notably, at the 1B scale, models trained with the Star Instruct dataset demonstrate
    significant superiority, surpassing baselines across diverse evaluation datasets.
    Remarkably, in comparison to models trained with the Evol-Instruct dataset, those
    utilizing Star Instruct achieve an average absolute improvement of approximately
    0.45, which is corresponding to a performance enhancement of about 12%. Additionally,
    when compared to models trained with the Alpaca dataset, our framework achieves
    an absolute improvement of 1 point, thereby affirming that the Star Instruct dataset
    is particularly well-suited for the Pythia-1B model, significantly boosting its
    operational efficacy. Additionally, within the 7b model category, the Llama-2-7B-star_instruct
    outperforms the sRecycled-Wiz-7B-v2 [[17](https://arxiv.org/html/2411.14497v1#bib.bib17)],
    which is trained on the Evol-Instruct dataset enhanced by Selective Reflection-Tuning.
    Figure [4(a)](https://arxiv.org/html/2411.14497v1#S4.F4.sf1 "In Figure 4 ‣ GPT-4
    Automatic Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning") illustrates the Llama-2-7B-star_instruct’s
    performance enhancements across nine metrics, with notable substantial improvements
    in math, coding and fermi problem-solving, where improvements surge up to 40%.
    A similar phenomenon can be observed in Figure [4(b)](https://arxiv.org/html/2411.14497v1#S4.F4.sf2
    "In Figure 4 ‣ GPT-4 Automatic Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣
    Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning").
    Additionally, comparative examples of single-turn and multi-turn dialogues are
    provided in Appendix  [A.2](https://arxiv.org/html/2411.14497v1#A1.SS2 "A.2 Case
    Study ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data Optimization with LLM
    Agents for Instruction Tuning"), and the performance on the Open LLM Leaderboards
    of LLMs can be found in Appendix [A.4](https://arxiv.org/html/2411.14497v1#A1.SS4
    "A.4 Performance on Open LLM Leaderboards ‣ Appendix A Appendix ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning").'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，在1B规模下，使用Star Instruct数据集训练的模型表现出了显著的优势，超越了各种评估数据集的基线。特别是，与使用Evol-Instruct数据集训练的模型相比，采用Star
    Instruct数据集的模型在平均绝对提升约0.45，相当于性能提升约12%。此外，与使用Alpaca数据集训练的模型相比，我们的框架实现了1分的绝对提升，进一步验证了Star
    Instruct数据集特别适合Pythia-1B模型，显著提高了其操作效率。此外，在7B模型类别中，Llama-2-7B-star_instruct的表现优于在Evol-Instruct数据集上使用选择性反射调优训练的sRecycled-Wiz-7B-v2
    [[17](https://arxiv.org/html/2411.14497v1#bib.bib17)]。图[4(a)](https://arxiv.org/html/2411.14497v1#S4.F4.sf1
    "在图4 ‣ GPT-4自动评估 ‣ 4.2主要结果 ‣ 4实验 ‣ Star-Agents：使用LLM代理进行指令调优的自动数据优化")展示了Llama-2-7B-star_instruct在九项指标上的性能提升，特别是在数学、编程和费米问题解决中的显著进展，提升幅度可达40%。类似现象可以在图[4(b)](https://arxiv.org/html/2411.14497v1#S4.F4.sf2
    "在图4 ‣ GPT-4自动评估 ‣ 4.2主要结果 ‣ 4实验 ‣ Star-Agents：使用LLM代理进行指令调优的自动数据优化")中观察到。此外，单轮和多轮对话的对比示例可以在附录[A.2](https://arxiv.org/html/2411.14497v1#A1.SS2
    "A.2案例研究 ‣ 附录A 附录 ‣ Star-Agents：使用LLM代理进行指令调优的自动数据优化")中找到，LLMs在Open LLM排行榜上的表现可参见附录[A.4](https://arxiv.org/html/2411.14497v1#A1.SS4
    "A.4 在Open LLM排行榜上的表现 ‣ 附录A 附录 ‣ Star-Agents：使用LLM代理进行指令调优的自动数据优化")。
- en: 'Table 3: Impact of different components.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：不同组件的影响。
- en: '| Components | Average Score |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 组件 | 平均得分 |'
- en: '| Diversity | Data selection | Evolutiuon |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 多样性 | 数据选择 | 演变 |'
- en: '| ✓ | ✓ | ✓ | 4.17 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | 4.17 |'
- en: '| ✓ | ✓ | ✕ | 3.97 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✕ | 3.97 |'
- en: '| ✓ | ✕ | ✕ | 3.62 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✕ | ✕ | 3.62 |'
- en: '| ✕ | ✕ | ✕ | 3.73 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| ✕ | ✕ | ✕ | 3.73 |'
- en: 'Table 4: Imapct of the selection method.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：选择方法的影响。
- en: '| Model | Average Score |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 平均得分 |'
- en: '| --- | --- |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Pythia-1B-evol_instruct | 3.73 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-evol_instruct | 3.73 |'
- en: '| Pythia-1B-IFD [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)] | 3.26
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-IFD [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)] | 3.26
    |'
- en: '| Pythia-1B-Random | 3.62 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| Pythia-1B-Random | 3.62 |'
- en: '| Pythia-1B-star_instruct | 4.17 | ![Refer to caption](img/1a61b0a0090243fe9f1236e9b120fab4.png)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '| Pythia-1B-star_instruct | 4.17 | ![参见说明](img/1a61b0a0090243fe9f1236e9b120fab4.png)'
- en: 'Figure 5: Evolution of the typical Agent-Pairs.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：典型代理对的演变。
- en: 4.3 Ablation Study
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 消融研究
- en: Main Components.
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 主要组件。
- en: 'As illustrated in Table [3](https://arxiv.org/html/2411.14497v1#S4.T3 "Table
    3 ‣ GPT-4 Automatic Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning"), we conducted
    ablation experiments on the three principal components within the Star-Agents
    framework. Results indicate that models using solely diversified datasets with
    random sampling yield a bit lower performance than the baseline. This occurs because
    the baseline employs data generated by ChatGPT, which is of high quality. In contrast,
    the diversified datasets draw from a variety of sources, making it challenging
    to ensure uniformly high quality. Thus, random sampling may introduce low-quality
    data, leading to diminished model performance. The inclusion of a data selection
    module subsequently leads to a recovery in model performance, suggesting that
    this module effectively selects high-quality data suitable for the model. Integration
    of the evolution strategy also provides a significant improvement, demonstrating
    that the evolution module can effectively select the most appropriate data generation
    agent-pairs from a complex array of candidate agent-pairs.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[3](https://arxiv.org/html/2411.14497v1#S4.T3 "Table 3 ‣ GPT-4 Automatic
    Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning")所示，我们对Star-Agents框架中的三个主要组件进行了消融实验。结果表明，单独使用多样化数据集和随机采样的模型性能略低于基线。这是因为基线使用了由ChatGPT生成的数据，质量较高。而多样化数据集则来自多个不同来源，难以确保质量均匀。因此，随机采样可能引入低质量数据，导致模型性能下降。引入数据选择模块后，模型性能得到了恢复，这表明该模块能够有效选择适合模型的高质量数据。结合进化策略后，性能也得到了显著提升，证明了进化模块能够有效地从复杂的候选代理对中选择最合适的数据生成代理对。'
- en: Selection Method.
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择方法。
- en: 'As demonstrated in Table [4](https://arxiv.org/html/2411.14497v1#S4.T4 "Table
    4 ‣ GPT-4 Automatic Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning"), we evaluated
    a range of conventional selection methods, including both random selection and
    strategies informed by the IFD  [[20](https://arxiv.org/html/2411.14497v1#bib.bib20)].
    Our dual-model selection strategy significantly outperforms these approaches.
    Compared to random selection, our method achieves a significant improvement, registering
    an improvement exceeding 0.5 points on average across a variety of test sets.
    When compared with the IFD approach, our enhancement approaches a 0.9 point. These
    findings robustly validate the effectiveness of our dual-model selection strategy,
    illustrating its superior performance in refining model selection precision using
    diverse evaluation metrics.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[4](https://arxiv.org/html/2411.14497v1#S4.T4 "Table 4 ‣ GPT-4 Automatic
    Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents: Automatic Data Optimization
    with LLM Agents for Instruction Tuning")所示，我们评估了一系列传统选择方法，包括随机选择和基于IFD[[20](https://arxiv.org/html/2411.14497v1#bib.bib20)]的策略。我们的双模型选择策略显著优于这些方法。与随机选择相比，我们的方法取得了显著的改进，在多种测试集上平均提高了超过0.5分。与IFD方法相比，我们的提升接近0.9分。这些结果有力地验证了我们的双模型选择策略的有效性，展示了它在使用多样化评估指标细化模型选择精度方面的优越性能。'
- en: Evolution.
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 进化。
- en: 'As depicted in Figure [5](https://arxiv.org/html/2411.14497v1#S4.F5 "Figure
    5 ‣ GPT-4 Automatic Evaluation ‣ 4.2 Main Results ‣ 4 Experiments ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning"), we analyzed
    the sampling probability curves of typical agent-pairs throughout an iterative
    evolutionary process. Initially, each agent-pair began with a sampling probability
    of approximately 10%. Due to its robust performance, the Mistral-ChatGPT receives
    consistent rewards, which leads to a gradual increase in its sampling probability.
    By the completion of about 70,000 iterations, this probability has escalated to
    30%. In stark contrast, the Phi2-ChatGPT undergoes a steady decline over the same
    period, with its sampling probability ultimately plummeting to near zero as it
    is progressively phased out. Concurrently, the ChatGLM3-ChatGPT exhibits a relatively
    stable trajectory, albeit with a slight downward trend. Evolutionary trajectories
    present significant discrepancy indicating different generation suitability of
    different generators on different tasks, where all the differences are captured
    by our evolution mechanism.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[5](https://arxiv.org/html/2411.14497v1#S4.F5 "图5 ‣ GPT-4自动评估 ‣ 4.2 主要结果 ‣
    4 实验 ‣ Star-Agents：用于指令微调的LLM代理自动数据优化")所示，我们分析了典型代理对在迭代进化过程中的采样概率曲线。最初，每对代理的采样概率约为10%。由于其强大的表现，Mistral-ChatGPT获得了持续的奖励，从而使得其采样概率逐渐增加。在大约70,000次迭代完成时，这一概率已经上升至30%。相比之下，Phi2-ChatGPT在同一时期内呈稳定下降趋势，其采样概率最终降至接近零，因为它逐步被淘汰。与此同时，ChatGLM3-ChatGPT则呈现出相对稳定的轨迹，尽管有轻微的下降趋势。进化轨迹的显著差异表明，不同生成器在不同任务上的适用性差异，这些差异都被我们的进化机制捕捉到。
- en: 5 Conclusion
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: 'In this paper, we have presented the Star-Agents framework, an automated system
    for optimizing data to be optimally challenging for target LLMs. This framework
    has been applied to the open-source SFT datasets, and we conduct training sessions
    on a variety of model families, adjusting the data to enhance its efficacy. Our
    empirical investigations include a series of instruction tuning experiments that
    utilize both multiple baselines and specially optimized datasets on well-known
    models such as Pythia and LLaMA. Extensive experiments confirm the substantial
    impact of our method: the optimized tailored datasets result in an average performance
    enhancement of approximately 12%, with certain metrics, especially those involved
    in Fermi problem tasks exhibiting increases exceeding 40%, as substantiated by
    results on benchmarks such as MT-bench, Vicuna bench, and the WizardLM testset.
    These findings underscore the premise that strategically diverse and tailored
    data can profoundly improve model alignment and performance. In conclusion, our
    research details a highly effective automated framework that significantly augments
    dataset functionality, thus fostering more efficient model alignment.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了Star-Agents框架，这是一种用于优化数据，使其对目标LLM（大语言模型）具有最佳挑战性的自动化系统。该框架已应用于开源的SFT数据集，并在多种模型系列上进行了训练，调整数据以提高其效能。我们的实证研究包括一系列指令微调实验，利用多个基准模型和特别优化的数据集，应用于像Pythia和LLaMA等知名模型。大量实验验证了我们方法的显著影响：优化后的定制数据集平均性能提高约12%，某些指标，尤其是与Fermi问题任务相关的，性能提升超过40%，这一结果得到了MT-bench、Vicuna
    bench和WizardLM测试集等基准的验证。这些发现强调了战略性多样化和定制化数据能够显著改善模型对齐和性能的前提。总之，我们的研究详细介绍了一种高度有效的自动化框架，显著增强了数据集的功能性，从而促进了更高效的模型对齐。
- en: Limitations.
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 局限性。
- en: Our approach achieves remarkable performance improvements on single-turn instruction
    datasets. However, it has not yet been evaluated on multi-turn conversations.
    We hence leave the evaluation on multi-turn instruction datasets and validation
    on datasets with domain-specific instructions to our future work.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法在单轮指令数据集上取得了显著的性能提升。然而，它尚未在多轮对话中进行评估。因此，我们将多轮指令数据集的评估和领域特定指令数据集的验证留待未来的工作。
- en: Acknowledgements
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: The present research was partially supported by the National Key Research and
    Development Program of China (Grant No. 2023YFE0116400). We would like to thank
    the anonymous reviewers for their insightful comments.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分得到了中国国家重点研发计划（资助编号：2023YFE0116400）的支持。我们感谢匿名审稿人提出的宝贵意见。
- en: References
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang
    Fan, Wenbin Ge, Yu Han, Fei Huang, et al. Qwen technical report. arXiv preprint
    arXiv:2309.16609, 2023.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang
    Fan, Wenbin Ge, Yu Han, Fei Huang 等人。Qwen 技术报告。arXiv 预印本 arXiv:2309.16609, 2023。'
- en: '[2] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley,
    Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai
    Prashanth, Edward Raff, et al. Pythia: A suite for analyzing large language models
    across training and scaling. In International Conference on Machine Learning,
    pages 2397–2430\. PMLR, 2023.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley,
    Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai
    Prashanth, Edward Raff 等人。Pythia：一个用于分析大语言模型的工具集，涵盖训练和扩展。在国际机器学习大会，页码 2397–2430。PMLR,
    2023。'
- en: '[3] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao
    Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S.
    Yu, Qiang Yang, and Xing Xie. A survey on evaluation of large language models,
    2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao
    Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip
    S. Yu, Qiang Yang 和 Xing Xie。关于大语言模型评估的调查，2023年。'
- en: '[4] Justin Chih-Yao Chen, Swarnadeep Saha, Elias Stengel-Eskin, and Mohit Bansal.
    Magdi: Structured distillation of multi-agent interaction graphs improves reasoning
    in smaller language models. arXiv preprint arXiv:2402.01620, 2024.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Justin Chih-Yao Chen, Swarnadeep Saha, Elias Stengel-Eskin 和 Mohit Bansal。Magdi：结构化蒸馏多智能体交互图改善小型语言模型的推理能力。arXiv
    预印本 arXiv:2402.01620, 2024。'
- en: '[5] Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav,
    Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al. Alpagasus: Training
    a better alpaca with fewer data. arXiv preprint arXiv:2307.08701, 2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav,
    Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang 等人。Alpagasus：用更少的数据训练更好的
    alpaca。arXiv 预印本 arXiv:2307.08701, 2023。'
- en: '[6] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang,
    Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. Vicuna:
    An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. See https://vicuna.
    lmsys. org (accessed 14 April 2023), 2(3):6, 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang,
    Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez 等人。Vicuna：一个开源聊天机器人，以
    90%* ChatGPT 质量给 GPT-4 留下深刻印象。见 https://vicuna.lmsys.org（访问日期：2023年4月14日），2(3):6，2023年。'
- en: '[7] Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah,
    Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. Free dolly: Introducing
    the world’s first truly open instruction-tuned llm. Company Blog of Databricks,
    2023.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah,
    Ali Ghodsi, Patrick Wendell, Matei Zaharia 和 Reynold Xin。Free dolly：介绍世界上首个真正开源的指令调优
    LLM。Databricks 公司博客，2023年。'
- en: '[8] Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan
    Liu, Maosong Sun, and Bowen Zhou. Enhancing chat language models by scaling high-quality
    instructional conversations. arXiv preprint arXiv:2305.14233, 2023.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan
    Liu, Maosong Sun 和 Bowen Zhou。通过扩展高质量教学对话增强聊天语言模型。arXiv 预印本 arXiv:2305.14233,
    2023。'
- en: '[9] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang,
    and Jie Tang. GLM: General language model pretraining with autoregressive blank
    infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), pages 320–335, Dublin, Ireland, May 2022\.
    Association for Computational Linguistics.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang
    和 Jie Tang。GLM：具有自回归空白填充的通用语言模型预训练。在第60届计算语言学协会年会会议论文集（卷1：长篇论文），页码 320–335，爱尔兰都柏林，2022年5月。计算语言学协会。'
- en: '[10] Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao Yu, Yan
    Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong, et al. Evaluating large language models:
    A comprehensive survey. arXiv preprint arXiv:2310.19736, 2023.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao Yu, Yan
    Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong 等人。评估大语言模型：一项全面的调查。arXiv 预印本 arXiv:2310.19736,
    2023。'
- en: '[11] Mojan Javaheripi, Sébastien Bubeck, Marah Abdin, Jyoti Aneja, Sebastien
    Bubeck, Caio César Teodoro Mendes, Weizhu Chen, Allie Del Giorno, Ronen Eldan,
    Sivakanth Gopi, et al. Phi-2: The surprising power of small language models. Microsoft
    Research Blog, 2023.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Mojan Javaheripi, Sébastien Bubeck, Marah Abdin, Jyoti Aneja, Sebastien
    Bubeck, Caio César Teodoro Mendes, Weizhu Chen, Allie Del Giorno, Ronen Eldan,
    Sivakanth Gopi 等人。Phi-2：小型语言模型的惊人威力。微软研究博客，2023年。'
- en: '[12] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825,
    2023.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, 等. Mistral 7b. arXiv预印本 arXiv:2310.06825, 2023.'
- en: '[13] Yuxin Jiang, Chunkit Chan, Mingyang Chen, and Wei Wang. Lion: Adversarial
    distillation of closed-source large language model. arXiv preprint arXiv:2305.12870,
    2023.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Yuxin Jiang, Chunkit Chan, Mingyang Chen, 和 Wei Wang. Lion：封闭源大型语言模型的对抗性蒸馏.
    arXiv预印本 arXiv:2305.12870, 2023.'
- en: '[14] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,
    Peter Clark, and Hannaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with
    a single QA system. In Findings of the Association for Computational Linguistics:
    EMNLP 2020, pages 1896–1907, Online, November 2020\. Association for Computational
    Linguistics.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,
    Peter Clark, 和 Hannaneh Hajishirzi. UNIFIEDQA：使用单一QA系统跨越格式边界. 在《计算语言学协会发现会议：EMNLP
    2020》中，第1896-1907页，在线，2020年11月。计算语言学协会。'
- en: '[15] Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis,
    Zhi Rui Tam, Keith Stevens, Abdullah Barhoum, Duc Nguyen, Oliver Stanley, Richárd
    Nagyfi, et al. Openassistant conversations-democratizing large language model
    alignment. Advances in Neural Information Processing Systems, 36, 2024.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis,
    Zhi Rui Tam, Keith Stevens, Abdullah Barhoum, Duc Nguyen, Oliver Stanley, Richárd
    Nagyfi, 等. 开放对话——民主化大规模语言模型对齐. 神经信息处理系统进展, 36, 2024.'
- en: '[16] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,
    and Bernard Ghanem. Camel: Communicative agents for" mind" exploration of large
    scale language model society. 2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,
    和 Bernard Ghanem. Camel：用于“大规模语言模型社会”的交流代理. 2023.'
- en: '[17] Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, and Tianyi
    Zhou. Selective reflection-tuning: Student-selected data recycling for llm instruction-tuning.
    arXiv preprint arXiv:2402.10110, 2024.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Jiuxiang Gu, 和 Tianyi Zhou.
    选择性反射调优：学生选择数据回收用于LLM指令调优. arXiv预印本 arXiv:2402.10110, 2024.'
- en: '[18] Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Heng Huang, Jiuxiang Gu,
    and Tianyi Zhou. Reflection-tuning: Data recycling improves llm instruction-tuning.
    ArXiv, abs/2310.11716, 2023.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Heng Huang, Jiuxiang Gu,
    和 Tianyi Zhou. 反射调优：数据回收提升LLM指令调优. ArXiv, abs/2310.11716, 2023.'
- en: '[19] Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang,
    Ning Cheng, and Tianyi Zhou. Superfiltering: Weak-to-strong data filtering for
    fast instruction-tuning, 2024.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang,
    Ning Cheng, 和 Tianyi Zhou. 超过滤：用于快速指令调优的弱到强数据过滤, 2024.'
- en: '[20] Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng,
    Jianzong Wang, Tianyi Zhou, and Jing Xiao. From quantity to quality: Boosting
    llm performance with self-guided data selection for instruction tuning. arXiv
    preprint arXiv:2308.12032, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng,
    Jianzong Wang, Tianyi Zhou, 和 Jing Xiao. 从数量到质量：通过自引导数据选择提升LLM性能进行指令调优. arXiv预印本
    arXiv:2308.12032, 2023.'
- en: '[21] Chuang Liu, Linhao Yu, Jiaxuan Li, Renren Jin, Yufei Huang, Ling Shi,
    Junhui Zhang, Xinmeng Ji, Tingting Cui, Tao Liu, et al. Openeval: Benchmarking
    chinese llms across capability, alignment and safety. arXiv preprint arXiv:2403.12316,
    2024.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Chuang Liu, Linhao Yu, Jiaxuan Li, Renren Jin, Yufei Huang, Ling Shi,
    Junhui Zhang, Xinmeng Ji, Tingting Cui, Tao Liu, 等. Openeval：基准测试中文LLM的能力、对齐性和安全性.
    arXiv预印本 arXiv:2403.12316, 2024.'
- en: '[22] Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He. What makes
    good data for alignment? a comprehensive study of automatic data selection in
    instruction tuning. arXiv preprint arXiv:2312.15685, 2023.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, 和 Junxian He. 什么样的数据适合对齐？指令调优中自动数据选择的全面研究.
    arXiv预印本 arXiv:2312.15685, 2023.'
- en: '[23] S. Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny
    Zhou, Quoc V. Le, Barret Zoph, Jason Wei, and Adam Roberts. The flan collection:
    Designing data and methods for effective instruction tuning. ArXiv, abs/2301.13688,
    2023.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] S. Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny
    Zhou, Quoc V. Le, Barret Zoph, Jason Wei, 和 Adam Roberts. Flan集合：为有效的指令调优设计数据和方法.
    ArXiv, abs/2301.13688, 2023.'
- en: '[24] Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan,
    Chang Zhou, and Jingren Zhou. # instag: Instruction tagging for analyzing supervised
    fine-tuning of large language models. In The Twelfth International Conference
    on Learning Representations, 2023.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] 盧克明、袁洪毅、袁政、林潤基、林俊揚、譚傳琪、周暢、周景仁。# instag: 用于分析大型语言模型监督微调的指令标记。载于《第十二届国际学习表征大会》，2023年。'
- en: '[25] Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad
    Usman, Nick Barnes, and Ajmal Mian. A comprehensive overview of large language
    models. arXiv preprint arXiv:2307.06435, 2023.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] 胡姆扎·纳维德、阿萨德·乌拉·汗、邱石、穆罕默德·萨基卜、赛义德·安瓦尔、穆罕默德·乌斯曼、尼克·巴恩斯、阿吉马尔·米安。大型语言模型的综合概述。arXiv预印本arXiv:2307.06435，2023年。'
- en: '[26] Erik Nijkamp, Tian Xie, Hiroaki Hayashi, Bo Pang, Congying Xia, Chen Xing,
    Jesse Vig, Semih Yavuz, Philippe Laban, Ben Krause, et al. Xgen-7b technical report.
    arXiv preprint arXiv:2309.03450, 2023.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] 埃里克·奈坎普、谢天、林浩明、龚邦、谢聪颖、陈兴、杰西·维格、塞米·雅武兹、菲利普·拉班、本·克劳斯等。Xgen-7b技术报告。arXiv预印本arXiv:2309.03450，2023年。'
- en: '[27] Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan
    Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. Large language model alignment: A survey.
    arXiv preprint arXiv:2309.15025, 2023.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] 沈天浩、金仁仁、黄玉飞、刘闯、董伟龙、郭子山、吴新伟、刘燕、熊德毅。大型语言模型对齐：一项调查。arXiv预印本arXiv:2309.15025，2023年。'
- en: '[28] Tianhao Shen, Sun Li, Quan Tu, and Deyi Xiong. Roleeval: A bilingual role
    evaluation benchmark for large language models. arXiv preprint arXiv:2312.16132,
    2023.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] 沈天浩、李顺、屠全、熊德毅。Roleeval：一个针对大型语言模型的双语角色评估基准。arXiv预印本arXiv:2312.16132，2023年。'
- en: '[29] Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao, and
    Tom Goldstein. On the exploitability of instruction tuning, 2023.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] 舒曼丽、王炯霄、朱晨、乔纳斯·盖平、肖超伟、汤姆·戈尔德斯坦。关于指令调优的可利用性，2023年。'
- en: '[30] Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Menglong Cui, Jiangcun
    Dui, Yikun Lei, Lei Yang, Ling Shi, Juesi Xiao, et al. Fuxitranyu: A multilingual
    large language model trained with balanced data. arXiv preprint arXiv:2408.06273,
    2024.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] 孙浩然、金仁仁、徐少扬、潘磊宇、崔孟龙、段江存、雷一坤、杨磊、施凌、肖爵思等。Fuxitranyu：一个使用平衡数据训练的多语言大型语言模型。arXiv预印本arXiv:2408.06273，2024年。'
- en: '[31] Yehui Tang, Fangcheng Liu, Yunsheng Ni, Yuchuan Tian, Zheyuan Bai, Yi-Qi
    Hu, Sichao Liu, Shangling Jui, Kai Han, and Yunhe Wang. Rethinking optimization
    and architecture for tiny language models. arXiv preprint arXiv:2402.02791, 2024.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] 唐业辉、刘方程、倪云生、田玉川、白哲元、胡一琪、刘思超、瑞尚岭、韩凯、王云赫。重新思考微型语言模型的优化和架构。arXiv预印本arXiv:2402.02791，2024年。'
- en: '[32] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li,
    Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An
    instruction-following llama model. [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca),
    2023.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] 罗汉·塔奥里、伊沙恩·古尔贾尼、张天意、杨·杜布瓦、李学辰、卡洛斯·格斯特林、皮尔西·梁、田住典·B·哈希莫托。斯坦福Alpaca：一个指令跟随型的Llama模型。[https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)，2023年。'
- en: '[33] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li,
    Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Stanford alpaca: An instruction-following
    llama model, 2023.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] 罗汉·塔奥里、伊沙恩·古尔贾尼、张天意、杨·杜布瓦、李学辰、卡洛斯·格斯特林、皮尔西·梁、田住典·B·哈希莫托。斯坦福Alpaca：一个指令跟随型的Llama模型，2023年。'
- en: '[34] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju,
    Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love,
    et al. Gemma: Open models based on gemini research and technology. arXiv preprint
    arXiv:2403.08295, 2024.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Gemma团队、托马斯·梅斯纳、卡西迪·哈丁、罗伯特·达达希、苏里亚·布帕塔贾鲁、什雷亚·帕塔克、洛朗·西弗、莫甘·里维耶、米赫尔·桑贾伊·凯尔、朱丽叶·洛夫等。Gemma：基于双子座研究与技术的开放模型。arXiv预印本arXiv:2403.08295，2024年。'
- en: '[35] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
    Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
    et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288,
    2023.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] 雨果·图弗龙、路易斯·马丁、凯文·斯通、彼得·阿尔伯特、阿姆贾德·阿尔梅哈伊里、雅斯敏·巴巴伊、尼古拉·巴什利科夫、苏米娅·巴特拉、普拉吉瓦尔·巴尔加瓦、什鲁蒂·博萨尔等。Llama
    2：开放基础和微调的聊天模型。arXiv预印本arXiv:2307.09288，2023年。'
- en: '[36] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith,
    Daniel Khashabi, and Hannaneh Hajishirzi. Self-instruct: Aligning language models
    with self-generated instructions. arXiv preprint arXiv:2212.10560, 2022.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] 王怡中、叶干赫·科尔迪、斯瓦鲁普·米什拉、阿丽莎·刘、诺亚·A·史密斯、丹尼尔·哈沙比、汉纳赫·哈吉什尔兹。Self-instruct：通过自生成指令对齐语言模型。arXiv预印本arXiv:2212.10560，2022年。'
- en: '[37] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith,
    Daniel Khashabi, and Hannaneh Hajishirzi. Self-instruct: Aligning language models
    with self-generated instructions. In Proceedings of the 61st Annual Meeting of
    the Association for Computational Linguistics (Volume 1: Long Papers), pages 13484–13508,
    Toronto, Canada, July 2023\. Association for Computational Linguistics.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] 王一中，Kordi Yeganeh，Swaroop Mishra，Alisa Liu，Noah A. Smith，Daniel Khashabi，和Hannaneh
    Hajishirzi。Self-instruct：将语言模型与自生成的指令对齐。在第61届计算语言学协会年会（第一卷：长篇论文）上发表，页面13484–13508，加拿大多伦多，2023年7月。计算语言学协会。'
- en: '[38] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza
    Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar,
    David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani
    Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya
    Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha
    Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur
    Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit, and Xudong
    Shen. Super-NaturalInstructions: Generalization via declarative instructions on
    1600+ NLP tasks. In Proceedings of the 2022 Conference on Empirical Methods in
    Natural Language Processing, pages 5085–5109, Abu Dhabi, United Arab Emirates,
    December 2022\. Association for Computational Linguistics.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] 王一中，Swaroop Mishra，Pegah Alipoormolabashi，Yeganeh Kordi，Amirreza Mirzaei，Atharva
    Naik，Arjun Ashok，Arut Selvan Dhanasekaran，Anjana Arunkumar，David Stap，Eshaan Pathak，Giannis
    Karamanolakis，Haizhi Lai，Ishan Purohit，Ishani Mondal，Jacob Anderson，Kirby Kuznia，Krima
    Doshi，Kuntal Kumar Pal，Maitreya Patel，Mehrad Moradshahi，Mihir Parmar，Mirali Purohit，Neeraj
    Varshney，Phani Rohitha Kaza，Pulkit Verma，Ravsehaj Singh Puri，Rushang Karia，Savan
    Doshi，Shailaja Keyur Sampat，Siddhartha Mishra，Sujan Reddy A，Sumanta Patro，Tanay
    Dixit，和Xudong Shen。超自然指令：通过声明性指令对1600多个NLP任务进行泛化。在2022年阿布扎比自然语言处理实证方法会议（EMNLP）上发表，页面5085–5109，阿联酋阿布扎比，2022年12月。计算语言学协会。'
- en: '[39] Yunhe Wang, Hanting Chen, Yehui Tang, Tianyu Guo, Kai Han, Ying Nie, Xutao
    Wang, Hailin Hu, Zheyuan Bai, Yun Wang, et al. Pangu-$pi$: Enhancing language
    model architectures via nonlinearity compensation. arXiv preprint arXiv:2312.17276,
    2023.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] 王云鹤，陈汉廷，唐烨辉，郭天宇，韩凯，聂颖，王旭涛，胡海林，白哲远，王云等人。Pangu-$pi$：通过非线性补偿增强语言模型架构。arXiv预印本arXiv:2312.17276，2023年。'
- en: '[40] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian
    Lester, Nan Du, Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot
    learners. In International Conference on Learning Representations, 2022.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Jason Wei，Maarten Bosma，Vincent Zhao，Kelvin Guu，Adams Wei Yu，Brian Lester，Nan
    Du，Andrew M. Dai，和Quoc V Le。微调语言模型是零样本学习者。在2022年学习表征国际会议（ICLR）上发表。'
- en: '[41] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian
    Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot
    learners. arXiv preprint arXiv:2109.01652, 2021.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Jason Wei，Maarten Bosma，Vincent Y Zhao，Kelvin Guu，Adams Wei Yu，Brian Lester，Nan
    Du，Andrew M Dai，和Quoc V Le。微调语言模型是零样本学习者。arXiv预印本arXiv:2109.01652，2021年。'
- en: '[42] Mengzhou Xia, Tianyu Gao, Zhiyuan Zeng, and Danqi Chen. Sheared llama:
    Accelerating language model pre-training via structured pruning. arXiv preprint
    arXiv:2310.06694, 2023.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] 夏孟洲，高天宇，曾志远，和Danqi Chen。Sheared llama：通过结构化剪枝加速语言模型预训练。arXiv预印本arXiv:2310.06694，2023年。'
- en: '[43] Mengzhou Xia, Sadhika Malladi, Suchin Gururangan, Sanjeev Arora, and Danqi
    Chen. Less: Selecting influential data for targeted instruction tuning. arXiv
    preprint arXiv:2402.04333, 2024.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] 夏孟洲，Sadhika Malladi，Suchin Gururangan，Sanjeev Arora，和Danqi Chen。Less：为目标指令调优选择有影响的数据。arXiv预印本arXiv:2402.04333，2024年。'
- en: '[44] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang
    Tao, and Daxin Jiang. Wizardlm: Empowering large language models to follow complex
    instructions. arXiv preprint arXiv:2304.12244, 2023.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] 徐灿，孙清峰，郑凯，耿修博，赵蒲，冯家湛，陶崇扬，和蒋大欣。Wizardlm：赋能大型语言模型执行复杂指令。arXiv预印本arXiv:2304.12244，2023年。'
- en: '[45] Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. Baize: An open-source
    chat model with parameter-efficient tuning on self-chat data. arXiv preprint arXiv:2304.01196,
    2023.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] 徐灿文，郭大亚，段楠，和Julian McAuley。Baize：一个开源的聊天模型，基于自聊天数据进行参数高效调优。arXiv预印本arXiv:2304.01196，2023年。'
- en: '[46] Yang Xu, Yongqiang Yao, Yufan Huang, Mengnan Qi, Maoquan Wang, Bin Gu,
    and Neel Sundaresan. Rethinking the instruction quality: Lift is what you need,
    2023.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] 许扬，姚永强，黄玉凡，齐孟南，王茂全，顾斌，和Neel Sundaresan。重新思考指令质量：Lift是你所需要的，2023年。'
- en: '[47] Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang,
    Vijay Srinivasan, Xiang Ren, and Hongxia Jin. Backdooring instruction-tuned large
    language models with virtual prompt injection. In NeurIPS 2023 Workshop on Backdoors
    in Deep Learning-The Good, the Bad, and the Ugly, 2023.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] 闫俊, 维卡斯·亚达夫, 李世阳, 陈立昌, 唐正, 王海, 维贾伊·斯里尼瓦桑, 任翔, 金洪霞. 利用虚拟提示注入对指令调优的大型语言模型进行后门攻击.
    载于《NeurIPS 2023年深度学习后门攻击研讨会——好的、坏的与丑陋的》，2023年。'
- en: '[48] Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang,
    Vijay Srinivasan, Xiang Ren, and Hongxia Jin. Virtual prompt injection for instruction-tuned
    large language models, 2023.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] 闫俊, 维卡斯·亚达夫, 李世阳, 陈立昌, 唐正, 王海, 维贾伊·斯里尼瓦桑, 任翔, 金洪霞. 对指令调优的大型语言模型进行虚拟提示注入，2023年。'
- en: '[49] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng,
    Haoming Jiang, Bing Yin, and Xia Hu. Harnessing the power of llms in practice:
    A survey on chatgpt and beyond, 2023.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] 杨晶峰, 金鸿烨, 唐瑞翔, 韩晓天, 冯启章, 姜浩明, 殷冰, 胡霞. 实践中利用LLM的力量: 关于ChatGPT及其延伸的调查，2023年。'
- en: '[50] Qinyuan Ye, Bill Yuchen Lin, and Xiang Ren. CrossFit: A few-shot learning
    challenge for cross-task generalization in NLP. In Proceedings of the 2021 Conference
    on Empirical Methods in Natural Language Processing, pages 7163–7189, Online and
    Punta Cana, Dominican Republic, November 2021\. Association for Computational
    Linguistics.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] 叶勤远, 林钰晨, 任翔. CrossFit: 一项针对自然语言处理任务跨任务泛化的少样本学习挑战. 载于《2021年自然语言处理实证方法会议论文集》，第7163–7189页，在线与多米尼加共和国蓬塔卡纳，2021年11月。计算语言学协会出版。'
- en: '[51] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding,
    Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. Glm-130b: An open bilingual
    pre-trained model. arXiv preprint arXiv:2210.02414, 2022.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] 曾奕翰, 刘晓, 杜郑晓, 王子翰, 赖涵宇, 丁铭, 杨卓依, 许一凡, 郑文迪, 夏晓, 等. Glm-130b: 一种开放的双语预训练模型.
    arXiv预印本 arXiv:2210.02414, 2022年。'
- en: '[52] Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
    Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Open
    pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] 张苏珊, 斯蒂芬·罗勒, 纳曼·戈亚尔, 米凯尔·阿尔特谢, 陈墨雅, 陈烁慧, 克里斯托弗·德万, 莫娜·迪亚布, 李献, 林晓维, 等.
    Opt: 开放预训练的变换器语言模型. arXiv预印本 arXiv:2205.01068, 2022年。'
- en: '[53] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng
    Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang,
    Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang
    Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models,
    2023.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] 赵昕, 周昆, 李俊毅, 唐天一, 王晓磊, 侯宇鹏, 闵英乾, 张贝晨, 张俊杰, 董子灿, 杜一凡, 杨辰, 陈宇硕, 陈志鹏, 姜金浩,
    任瑞扬, 李一帆, 唐欣瑜, 刘紫康, 刘佩宇, 聂剑云, 温基荣. 大型语言模型调查, 2023年。'
- en: '[54] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu,
    Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge
    with mt-bench and chatbot arena. Advances in Neural Information Processing Systems,
    36, 2024.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] 郑连敏, 姜伟林, 盛颖, 庄思源, 吴张浩, 庄永浩, 林子, 李卓涵, 李大成, 辛埃里克, 等. 使用mt-bench和聊天机器人竞技场评估LLM作为法官的表现.
    《神经信息处理系统进展》，第36期，2024年。'
- en: Appendix A Appendix
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 附录
- en: A.1 Prompt Examples
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 提示示例
- en: 'Following the Fast-Chat [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)],
    the prompts used in the data selection process are as listed in Table [5](https://arxiv.org/html/2411.14497v1#A1.T5
    "Table 5 ‣ A.1 Prompt Examples ‣ Appendix A Appendix ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning").'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '根据Fast-Chat [[54](https://arxiv.org/html/2411.14497v1#bib.bib54)]，数据选择过程中使用的提示如表[5](https://arxiv.org/html/2411.14497v1#A1.T5
    "表5 ‣ A.1 提示示例 ‣ 附录A ‣ Star-Agents: 使用LLM代理自动优化数据以进行指令调优")所列。'
- en: 'Table 5: Prompts of data selection for LLMs.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '表5: LLM数据选择的提示。'
- en: '| System Prompt: Please act as an impartial judge and evaluate the quality
    of the responses provided by three AI assistants to the user question displayed
    below. You should choose the assistant that follows the user’s instructions and
    answers the user’s question best. Your evaluation should consider factors such
    as the helpfulness, relevance, accuracy, depth, creativity, and level of detail
    of their responses. Begin your evaluation by comparing the two responses and provide
    a short explanation. Avoid any position biases and ensure that the order in which
    the responses were presented does not influence your decision. Do not allow the
    length of the responses to influence your evaluation. Do not favor certain names
    of the assistants. Be as objective as possible. After providing your explanation,
    output your final verdict by strictly following this format: “[[A]]” if assistant
    A is the bset, “[[B]]” if assistant B is the bset, and “[[C]]” for a tie. |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 系统提示：请充当一名公正的评委，评估三位AI助手对以下用户问题的回答质量。你应该选择那位最能遵循用户指令并最好回答用户问题的助手。你的评估应考虑其回答的有用性、相关性、准确性、深度、创造性以及细节水平。在开始评估之前，先比较两份回答并提供简短的解释。避免偏袒任何一方，确保呈现的顺序不影响你的判断。不要让回答的长度影响你的评估，也不要偏爱某些助手的名字。尽量做到客观。在提供解释后，按照严格的格式输出最终裁定：“[[A]]”如果助手A最佳，“[[B]]”如果助手B最佳，“[[C]]”表示平局。
    |'
- en: '| Prompt Template: [User Question]'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '| 提示模板：[用户问题]'
- en: <question>
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: <question>
- en: '[The Start of Assistant A’s Answer]'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[助手A回答的开始]'
- en: <answer_a>
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: <answer_a>
- en: '[The End of Assistant A’s Answer]'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[助手A回答的结束]'
- en: '[The Start of Assistant B’s Answer]'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[助手B回答的开始]'
- en: <answer_b>
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: <answer_b>
- en: '[The End of Assistant B’s Answer]'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[助手B回答的结束]'
- en: '[Final Verdict]: |'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[最终裁定]：'
- en: A.2 Case Study
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 案例研究
- en: 'Examples of the single-turn dialogue and multi-turn dialogue are presented
    in Table [6](https://arxiv.org/html/2411.14497v1#A1.T6 "Table 6 ‣ A.2 Case Study
    ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data Optimization with LLM Agents
    for Instruction Tuning") and Table [7](https://arxiv.org/html/2411.14497v1#A1.T7
    "Table 7 ‣ A.2 Case Study ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data
    Optimization with LLM Agents for Instruction Tuning").'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 单轮对话和多轮对话的示例见表[6](https://arxiv.org/html/2411.14497v1#A1.T6 "表6 ‣ A.2 案例研究 ‣
    附录A 附录 ‣ Star-Agents：使用LLM代理进行指令调优的自动数据优化")和表[7](https://arxiv.org/html/2411.14497v1#A1.T7
    "表7 ‣ A.2 案例研究 ‣ 附录A 附录 ‣ Star-Agents：使用LLM代理进行指令调优的自动数据优化")。
- en: 'Table 6: Single-turn dialogue example.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：单轮对话示例。
- en: '| Instruction: A tech startup invests $8000 in software development in the
    first year, and then invests half of that amount in software development in the
    second year. What’s the total amount the startup invested in software development
    over the two years? |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 指令：一间技术初创公司在第一年投入$8000进行软件开发，在第二年再投入其一半的金额进行软件开发。那么，该公司在两年内软件开发的总投资额是多少？
    |'
- en: '| --- |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Llama-2-7B-evol_instruct: The total amount the startup invested in software
    development over the two years is $12,000. | Llama-2-7B-star_instruct: To calculate
    the total amount the startup invested in software development over the two years,
    we need to find the total investment in software development for each year and
    then add them together. In the first year, the startup invested $8000 in software
    development. In the second year, the startup invested half of that amount, which
    is $4000. So, the total investment in software development for the two years is:
    $8000 (first year) + $4000 (second year) = $12000 Therefore, the total amount
    the startup invested in software development over the two years is $12000. |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-evol_instruct：该初创公司在两年内投入的软件开发总额为$12,000。 | Llama-2-7B-star_instruct：为了计算该初创公司在两年内投入的软件开发总额，我们需要先计算每年的软件开发投资总额，然后将它们加在一起。在第一年，该初创公司在软件开发上投入了$8000。在第二年，该公司投入了一半的金额，即$4000。因此，两年内软件开发的总投资为：$8000（第一年）+
    $4000（第二年）= $12000。所以，该初创公司在两年内投入的软件开发总额是$12000。 |'
- en: 'Table 7: Multi-turn dialogue examples.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：多轮对话示例。
- en: '| Instruction: Act as a math teacher. I will provide some mathematical equations
    or concepts, and it will be your job to explain them in easy-to-understand terms.
    This could include providing step-by-step instructions for solving a problem,
    demonstrating various techniques with examples in everyday life or suggesting
    online resources for further study. My first request is "I need help understanding
    how probability works." |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| Instruction：作为一名数学老师，我将提供一些数学方程或概念，你的任务是用通俗易懂的语言来解释它们。这可以包括提供逐步解决问题的指南、用日常生活中的例子展示各种技巧或建议进一步学习的在线资源。我的第一个问题是“我需要帮助理解概率是如何工作的”。
    |'
- en: '| --- |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Llama-2-7B-evol_instruct: Sure, I’d be happy to help! Probability is the
    likelihood of something happening, and it’s a fundamental concept in math and
    science. To explain it simply, probability is the chance of something happening
    out of all possible outcomes. For example, if you flip a coin, the probability
    of getting heads is 1 out of 2, or 50%. Probability can be used to make predictions
    and calculate risks, and it’s important in fields like finance, statistics, and
    data analysis. To calculate probability, you can use different formulas depending
    on the type of problem you’re solving. One common method is to use a formula called
    the probability mass function, which tells you the likelihood of getting a certain
    outcome. Another method is to use the probability density function, which tells
    you the likelihood of getting a certain range of outcomes. There are many resources
    available online to help you learn more about probability, including video tutorials,
    interactive simulations, and practice problems. Some popular websites for learning
    probability include Khan Academy, Mathway, and Coursera. I hope this helps! |
    Llama-2-7B-star_instruct: Sure, I’d be happy to help explain probability! Probability
    is a measure of how likely an event is to occur. It’s often expressed as a number
    between 0 and 1, where 0 represents a very unlikely event and 1 represents a very
    likely event. To calculate probability, you need to know the total number of possible
    outcomes and the number of favorable outcomes for the event you’re interested
    in. For example, if you’re flipping a fair coin, there are two possible outcomes
    (heads or tails), and the probability of getting heads is 1/2 or 0.5, because
    there’s only one way to get heads out of two possible outcomes. In everyday life,
    probability can be used to calculate the likelihood of certain events, such as
    the chance of rain on a particular day or the probability of getting a certain
    grade on a test. It’s also used in decision-making situations, like calculating
    the risk of a particular investment or the likelihood of success in a business
    venture. There are many resources available online to help you learn more about
    probability, such as video tutorials, practice problems, and interactive simulations.
    Some popular websites include Khan Academy, Coursera, and edX, which offer free
    courses and resources on probability and other mathematical concepts. |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-evol_instruct：当然，我很乐意帮助你！概率是某个事件发生的可能性，它是数学和科学中的一个基本概念。简单来说，概率是某个事件在所有可能结果中发生的机会。例如，如果你抛一枚硬币，得到正面的概率是2分之一，也就是50%。概率可以用来进行预测和计算风险，在金融、统计学和数据分析等领域非常重要。计算概率时，你可以根据所解决问题的类型使用不同的公式。一种常见的方法是使用称为概率质量函数的公式，它告诉你某个结果发生的可能性。另一种方法是使用概率密度函数，它告诉你某个结果范围内的发生可能性。网上有许多资源可以帮助你了解更多关于概率的知识，包括视频教程、互动模拟和练习题。一些受欢迎的学习概率的网站包括可汗学院、Mathway和Coursera。希望这些对你有帮助！
    | Llama-2-7B-star_instruct：当然，我很乐意帮助你理解概率！概率是衡量事件发生的可能性的指标。它通常表示为介于0和1之间的一个数字，其中0表示事件非常不可能发生，1表示事件非常可能发生。计算概率时，你需要知道所有可能结果的总数以及你感兴趣的事件的有利结果的数量。例如，如果你抛一枚公平的硬币，可能的结果有两个（正面或反面），得到正面的概率是1/2或0.5，因为在两个可能的结果中，只有一种方式可以得到正面。在日常生活中，概率可以用来计算某些事件发生的可能性，比如某一天下雨的几率或在考试中得到某个成绩的概率。它也用于决策情境中，比如计算某项投资的风险或商业投资成功的可能性。网上有很多资源可以帮助你学习更多关于概率的知识，比如视频教程、练习题和互动模拟。一些受欢迎的网站包括可汗学院、Coursera和edX，它们提供关于概率和其他数学概念的免费课程和资源。
    |'
- en: '| Instruction: What are the differences between Riemannian geometry and euclidean
    geometry? |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| Instruction：黎曼几何和欧几里得几何有什么区别？ |'
- en: '| Llama-2-7B-evol_instruct:Riemannian geometry and Euclidean geometry are two
    different types of geometries. In Euclidean geometry, the distance between two
    points is always a straight line, and the angles of a triangle always add up to
    180 degrees. In Riemannian geometry, the distance between two points is not always
    a straight line, and the angles of a triangle can add up to more than 180 degrees.
    Another key difference between the two geometries is the way they handle curved
    surfaces. In Euclidean geometry, a flat surface is a rectangle with parallel sides,
    while in Riemannian geometry, a surface can be curved in any way. This means that
    Riemannian geometry is better suited for describing the geometry of the universe,
    as it can handle the curvature of space-time. Overall, Riemannian geometry is
    a more complex and advanced form of geometry, and it has many practical applications
    in fields such as physics and engineering. | Llama-2-7B-star_instruct: Great question!
    Riemannian geometry and Euclidean geometry are two different types of geometry
    that are used to describe and analyze the properties of spaces. The main differences
    between the two are as follows: 1\. Metric: In Euclidean geometry, the distance
    between two points is defined by the Pythagorean theorem, which states that the
    sum of the squares of the two sides of a right triangle is equal to the square
    of the length of the hypotenuse. In Riemannian geometry, the distance between
    two points is defined by a metric, which is a function that describes how much
    the shortest path between two points is curved. 2\. Curvature: Euclidean geometry
    deals with flat spaces where the curvature of the Earth’s surface is negligible.
    In contrast, Riemannian geometry deals with curved spaces, such as the surface
    of the Earth, where the curvature plays a significant role in determining the
    properties of the space. 3\. Geodesics: In Euclidean geometry, the shortest path
    between two points is a straight line. In Riemannian geometry, the shortest path
    between two points is called a geodesic, which can be curved and depends on the
    metric. 4\. Tensor Fields: Riemannian geometry involves the use of tensor fields,
    which are mathematical objects that describe the geometry of a space. These fields
    are used to calculate the curvature of the space and the behavior of objects moving
    through it. Overall, Riemannian geometry and Euclidean geometry are two different
    approaches to understanding the properties of spaces, with Riemannian geometry
    being more applicable to curved spaces and Euclidean geometry being more applicable
    to flat spaces. |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-evol_instruct:黎曼几何和欧几里得几何是两种不同类型的几何学。在欧几里得几何中，两点之间的距离总是直线，三角形的角度总和为180度。而在黎曼几何中，两点之间的距离不一定是直线，三角形的角度总和可能大于180度。两者之间的另一个关键区别是它们处理曲面的方法。在欧几里得几何中，平面是一个具有平行边的矩形，而在黎曼几何中，表面可以是任何形式的曲面。这意味着黎曼几何更适合描述宇宙的几何，因为它能够处理时空的弯曲。总体而言，黎曼几何是一种更复杂、更高级的几何形式，并且在物理学和工程学等领域有许多实际应用。
    | Llama-2-7B-star_instruct: 很好的问题！黎曼几何和欧几里得几何是两种不同类型的几何学，用于描述和分析空间的性质。它们之间的主要区别如下：1\.
    度量：在欧几里得几何中，两点之间的距离由毕达哥拉斯定理定义，该定理指出，直角三角形两边的平方和等于斜边的平方。在黎曼几何中，两点之间的距离由度量定义，度量是一个描述两点之间最短路径弯曲程度的函数。2\.
    曲率：欧几里得几何处理的是平面空间，其中地球表面的曲率可以忽略不计。相反，黎曼几何处理的是弯曲空间，如地球表面，其中曲率在确定空间性质中起着重要作用。3\.
    大地线：在欧几里得几何中，两点之间的最短路径是直线。在黎曼几何中，两点之间的最短路径称为大地线，它可能是弯曲的，并依赖于度量。4\. 张量场：黎曼几何涉及使用张量场，张量场是描述空间几何的数学对象。这些场用于计算空间的曲率以及物体在其中运动的行为。总体而言，黎曼几何和欧几里得几何是理解空间性质的两种不同方法，其中黎曼几何更适用于弯曲空间，而欧几里得几何更适用于平面空间。
    |'
- en: A.3 Data Examples
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 数据示例
- en: 'Data examples are shown in Table [8](https://arxiv.org/html/2411.14497v1#A1.T8
    "Table 8 ‣ A.3 Data Examples ‣ Appendix A Appendix ‣ Star-Agents: Automatic Data
    Optimization with LLM Agents for Instruction Tuning").'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '数据示例见表格[8](https://arxiv.org/html/2411.14497v1#A1.T8 "表格 8 ‣ A.3 数据示例 ‣ 附录
    A 附录 ‣ Star-Agents: 使用LLM代理进行指令调整的自动数据优化")。'
- en: 'Table 8: Diverse Data Examples.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 8：多样化数据示例。
- en: '| Instruction: Given some binary classification data, identify a suitable machine
    learning model that can be applied to this task. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 说明：给定一些二分类数据，确定一个适合此任务的机器学习模型。 |'
- en: '| --- |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Evol Instruct: The suitable machine learning models for binary classification
    tasks include: 1) Logistic regression: It is a statistical method that uses a
    logistic function to model a binary dependent variable. It is a relatively simple
    and interpretable model that works well with linearly separable datasets.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '| 演示说明：适用于二分类任务的机器学习模型包括：1) 逻辑回归：这是一种统计方法，使用逻辑函数来建模二分类的因变量。它是一个相对简单且易于解释的模型，适用于线性可分的数据集。'
- en: '2) Support Vector Machines (SVMs): It is a popular classifier that is used
    for binary classification tasks. SVMs can handle high-dimensional data and work
    well with datasets that are not linearly separable.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 支持向量机（SVM）：它是一个常用的分类器，用于二分类任务。SVM能够处理高维数据，并且在数据集不是线性可分的情况下也能表现良好。
- en: '3) Random Forests: It is an ensemble learning method that works by constructing
    a multitude of decision trees at training time and outputs the class that is the
    mode of the classes output by the individual trees.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 随机森林：这是一种集成学习方法，通过在训练时构建大量的决策树，并输出各个树输出类别的众数来进行工作。
- en: '4) Neural networks: It is a type of machine learning model that is widely used
    for binary classification tasks. Neural networks can handle non-linear relationships
    between variables and are capable of learning complex patterns in the data.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 4) 神经网络：它是一种广泛用于二分类任务的机器学习模型。神经网络能够处理变量之间的非线性关系，并且能够学习数据中的复杂模式。
- en: The choice of the model depends on the particular characteristics of the data
    and the specific requirements of the project." |
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的选择取决于数据的具体特征和项目的具体要求。 |
- en: '| Agent-Pair A: There are several machine learning models that can be applied
    to binary classification tasks, depending on the nature of the data and the problem
    at hand. Here are a few popular ones: 1\. Logistic Regression: This is a simple
    and effective model that can be used for binary classification problems. It works
    by estimating the probability of the positive class and using it to make predictions.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '| Agent-Pair A：有多种机器学习模型可以应用于二分类任务，具体选择哪种模型取决于数据的性质和任务的要求。以下是一些常见的模型：1. 逻辑回归：这是一种简单且有效的模型，适用于二分类问题。它通过估计正类的概率并使用该概率进行预测来工作。'
- en: '2\. Decision Trees: Decision Trees are a popular machine learning model that
    can handle both categorical and numerical features. They work by recursively splitting
    the data into subsets based on the values of the input features.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 决策树：决策树是一个流行的机器学习模型，可以处理类别特征和数值特征。它通过递归地根据输入特征的值将数据划分为子集来进行工作。
- en: '3\. Random Forest: Random Forest is an ensemble learning method that combines
    multiple decision trees to improve the accuracy of the model. It works by creating
    a set of decision trees and then averaging their predictions.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 随机森林：随机森林是一种集成学习方法，通过结合多个决策树来提高模型的准确性。它通过创建一组决策树，并对它们的预测结果取平均来进行工作。
- en: '4\. Support Vector Machines (SVM): SVM is a powerful model that can handle
    high-dimensional data. It works by finding the hyperplane that maximally separates
    the classes in the feature space.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 支持向量机（SVM）：SVM是一个强大的模型，可以处理高维数据。它通过在特征空间中找到最大分离类的超平面来进行工作。
- en: '5\. Neural Networks: Neural Networks are a set of algorithms that can learn
    and classify from data. They can handle complex and nonlinear relationships between
    the input features and the output labels.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 神经网络：神经网络是一组可以从数据中学习和分类的算法。它们能够处理输入特征与输出标签之间复杂且非线性的关系。
- en: 1The choice of the model depends on various factors such as the size and complexity
    of the dataset, the type of features, the computing resources, and the desired
    level of accuracy. |
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 1模型的选择取决于数据集的大小和复杂度、特征类型、计算资源以及所需的准确性等多种因素。 |
- en: '| Agent-Pair B: For binary classification tasks, several machine learning models
    are suitable, depending on the size of the dataset, complexity of the problem,
    and the availability of features. Here are some popular models that can be applied:
    1\. Logistic Regression: A simple and interpretable model that works well for
    small to medium-sized datasets. It’s linear and can handle both categorical and
    continuous features.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '| Agent-Pair B：对于二分类任务，根据数据集的大小、问题的复杂性和特征的可用性，有多种机器学习模型适用。以下是一些可以应用的流行模型：1\.
    逻辑回归：一种简单且易于解释的模型，适用于中小型数据集。它是线性的，并且能够处理分类和连续特征。|'
- en: '2\. Decision Trees and Random Forest: These are easy to interpret and can handle
    both numerical and categorical data. Random Forest is an ensemble method that
    combines multiple decision trees, reducing overfitting.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 决策树和随机森林：这些模型易于解释，能够处理数值型和分类数据。随机森林是一种集成方法，它结合了多个决策树，从而减少了过拟合。
- en: '3\. Support Vector Machines (SVM): Effective for high-dimensional data and
    can handle non-linear relationships through kernel functions. SVMs are robust
    to outliers and can be used for both linear and non-linear classification.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 支持向量机（SVM）：对于高维数据有效，并且可以通过核函数处理非线性关系。SVM对异常值具有鲁棒性，既可以用于线性分类，也可以用于非线性分类。
- en: '4\. Naive Bayes: A probabilistic model that assumes features are independent.
    It’s fast, easy to implement, and works well for text classification or when features
    are not highly correlated.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 朴素贝叶斯：一种假设特征之间相互独立的概率模型。它速度快，易于实现，适用于文本分类或特征不高度相关的情况。
- en: '5\. K-Nearest Neighbors (KNN): A simple model that classifies based on the
    majority class of its nearest neighbors. It’s non-parametric and can be useful
    for small datasets.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. K近邻（KNN）：一种简单的模型，通过最近邻居的多数类别来进行分类。它是非参数的，适用于小型数据集。
- en: '6\. Neural Networks (e.g., Feedforward, Convolutional, or Recurrent Neural
    Networks): Deep learning models that can capture complex patterns in large datasets.
    They are powerful but require more data and computational resources.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. 神经网络（例如前馈神经网络、卷积神经网络或递归神经网络）：深度学习模型，能够捕捉大数据集中的复杂模式。它们非常强大，但需要更多的数据和计算资源。
- en: '7\. Gradient Boosting Machines (GBM) or XGBoost: Ensemble methods that iteratively
    build weak learners (e.g., decision trees) to create a strong classifier. They
    are often used for structured data and can handle high dimensionality.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. 梯度提升机（GBM）或XGBoost：集成方法，通过迭代构建弱学习器（例如决策树）来创建强分类器。它们通常用于结构化数据，并能够处理高维度。
- en: '8\. AdaBoost: Another boosting algorithm that combines weak learners to create
    a strong classifier. It’s particularly useful when dealing with imbalanced datasets.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. AdaBoost：另一种增强算法，通过结合弱学习器来创建强分类器。在处理不平衡数据集时特别有用。
- en: '9\. Neural Network Ensembles (e.g., stacking, blending): Combining predictions
    from multiple models can improve performance and robustness.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 9\. 神经网络集成（例如，堆叠、混合）：结合多个模型的预测可以提高性能和鲁棒性。
- en: To choose the best model, it’s essential to perform exploratory data analysis,
    split the data into training and testing sets, and evaluate the models using appropriate
    metrics (e.g., accuracy, precision, recall, F1-score, or AUC-ROC for imbalanced
    datasets). Cross-validation can help in selecting the optimal model and hyperparameters
    |
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳模型时，进行探索性数据分析、将数据划分为训练集和测试集，并使用适当的指标（例如准确率、精确率、召回率、F1分数或不平衡数据集的AUC-ROC）评估模型是至关重要的。交叉验证可以帮助选择最佳模型和超参数。
- en: '| Agent-Pair C: A suitable machine learning model for this task would be a
    Random Forest Classifier. This model is effective in handling both categorical
    and numerical data, and can handle large datasets with high dimensionality. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| Agent-Pair C：适用于此任务的机器学习模型是随机森林分类器。该模型在处理分类数据和数值数据时效果良好，并且能够处理高维度的大数据集。|'
- en: '| Agent-Pair D: One suitable machine learning model for binary classification
    tasks is the Logistic Regression model. Logistic Regression is commonly used for
    binary classification as it provides the probability of an instance belonging
    to a particular class. It is a simple and efficient algorithm that works well
    with linearly separable data. Other popular machine learning models for binary
    classification tasks include Support Vector Machines (SVM), Decision Trees, Random
    Forest, Gradient Boosting Machines (GBM), and Neural Networks. The choice of the
    model depends on the complexity of the data, size of the dataset, interpretability
    requirements, and computational resources available. |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| Agent-Pair D：一种适用于二分类任务的机器学习模型是逻辑回归模型。逻辑回归常用于二分类任务，因为它提供了一个实例属于特定类别的概率。这是一种简单而高效的算法，适用于线性可分的数据。其他常用的二分类机器学习模型包括支持向量机（SVM）、决策树、随机森林、梯度提升机（GBM）和神经网络。模型的选择取决于数据的复杂性、数据集的大小、可解释性要求以及可用的计算资源。
    |'
- en: A.4 Performance on Open LLM Leaderboards
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 在公开LLM排行榜上的表现
- en: 'The performance on Open LLM Leaderboards is shown in Table [9](https://arxiv.org/html/2411.14497v1#A1.T9
    "Table 9 ‣ A.4 Performance on Open LLM Leaderboards ‣ Appendix A Appendix ‣ Star-Agents:
    Automatic Data Optimization with LLM Agents for Instruction Tuning").'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '公开LLM排行榜上的表现如表[9](https://arxiv.org/html/2411.14497v1#A1.T9 "Table 9 ‣ A.4
    Performance on Open LLM Leaderboards ‣ Appendix A Appendix ‣ Star-Agents: Automatic
    Data Optimization with LLM Agents for Instruction Tuning")所示。'
- en: '| Model | ARC | HellaSwag | MMLU | TruthfulQA | Average |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | ARC | HellaSwag | MMLU | TruthfulQA | 平均值 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Wizardlm | 51.60 | 77.74 | 42.74 | 45.75 | 54.18 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| Wizardlm | 51.60 | 77.74 | 42.74 | 45.75 | 54.18 |'
- en: '| Llama-2-7B-evol_instruct | 51.88 | 76.70 | 45.76 | 46.10 | 55.11 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-evol_instruct | 51.88 | 76.70 | 45.76 | 46.10 | 55.11 |'
- en: '| Llama-2-7B-star_instruct | 54.44 | 77.64 | 46.94 | 46.13 | 56.29 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| Llama-2-7B-star_instruct | 54.44 | 77.64 | 46.94 | 46.13 | 56.29 |'
- en: 'Table 9: Performance on Open LLM Leaderboards.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：公开LLM排行榜上的表现。
- en: A.5 Computational Cost.
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.5 计算成本。
- en: 'The computational overhead of our proposed method primarily depends on the
    inference computational load of the various LLMs used:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的方法的计算开销主要取决于所使用的各个LLM的推理计算负载：
- en: •
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Qwen-14B: During inference with a sequence length of 256 tokens, the computational
    load is approximately $4\times 10^{12}$ Multiply-Add cumulations (MACs).'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Qwen-14B：在推理过程中，序列长度为256个token时，计算负载大约是$4\times 10^{12}$次乘加运算（MACs）。
- en: •
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phi-2-2.7B: For the same sequence length, the inference computational load
    is around $7\times 10^{11}$ MACs.'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Phi-2-2.7B：对于相同的序列长度，推理计算负载大约是$7\times 10^{11}$ MACs。
- en: •
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'ChatGPT: Given that ChatGPT is a proprietary model, we don’t have details on
    its computational requirements.'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChatGPT：由于ChatGPT是一个专有模型，我们没有其计算需求的详细信息。
- en: 'Nonetheless, for estimation purpose, we can approximate the overall computational
    cost. Assuming an iterative process involving multiple LLMs (e.g., 10 LLMs) and
    a large dataset (e.g., 70,000 samples), the total computation without using our
    framework can be roughly estimated as:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，为了估算总的计算成本，我们可以大致估算整体计算成本。假设一个涉及多个LLM（例如10个LLM）和一个大型数据集（例如70,000个样本）的迭代过程，那么在不使用我们的框架的情况下，总的计算量可以粗略估算为：
- en: •
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $4\times 10^{12}$ FLOPs (Qwen-14B) $\times$ 10 LLMs $\times$ 70,000 samples
    = $2.8\times 10^{18}$ MACs
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $4\times 10^{12}$ FLOPs (Qwen-14B) $\times$ 10 LLMs $\times$ 70,000 samples
    = $2.8\times 10^{18}$ MACs
- en: 'While, when the Agent-Pairs Sampling and Instruction Memory Bank are employed,
    5 of 10 LLMs are used to generate data , therefore, total computation can be significantly
    reduced and roughly estimated as:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 而当使用Agent-Pairs采样和指令记忆库时，10个LLM中有5个LLM用于生成数据，因此，总的计算量可以显著减少，并且大致估算为：
- en: •
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: $4\times 10^{12}$ FLOPs (Qwen-14B) $\times$ 5 LLMs $\times$ 70,000 samples =
    $1.4\times 10^{18}$ MACs
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $4\times 10^{12}$ FLOPs (Qwen-14B) $\times$ 5 LLMs $\times$ 70,000 samples =
    $1.4\times 10^{18}$ MACs
