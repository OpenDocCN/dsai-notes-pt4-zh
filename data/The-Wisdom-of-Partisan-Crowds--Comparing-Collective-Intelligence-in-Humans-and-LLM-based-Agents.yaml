- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2025-01-11 13:01:48'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 13:01:48
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans
    and LLM-based Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 党派群体的智慧：比较人类与基于LLM的代理的集体智能
- en: 来源：[https://arxiv.org/html/2311.09665/](https://arxiv.org/html/2311.09665/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2311.09665/](https://arxiv.org/html/2311.09665/)
- en: Yun-Shiuan Chuang, Siddharth Suresh${}^{\dagger}$, Nikunj Harlalka${}^{\dagger}$,
    Agam Goyal
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yun-Shiuan Chuang, Siddharth Suresh${}^{\dagger}$, Nikunj Harlalka${}^{\dagger}$,
    Agam Goyal
- en: Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, Timothy T. Rogers
- en: University of Wisconsin-Madison
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 威斯康星大学麦迪逊分校
- en: '{yunshiuan.chuang,siddharth.suresh,nharlalka,agoyal25}@wisc.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '{yunshiuan.chuang,siddharth.suresh,nharlalka,agoyal25}@wisc.edu'
- en: '{rdhawkins, syang84, dshah, junjie.hu, ttrogers}@wisc.edu'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '{rdhawkins, syang84, dshah, junjie.hu, ttrogers}@wisc.edu'
- en: ${}^{\dagger}$ joint second author
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ${}^{\dagger}$ 联合第二作者
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Human groups are able to converge on more accurate beliefs through deliberation,
    even in the presence of polarization and partisan bias — a phenomenon known as
    the “wisdom of partisan crowds.” Generated agents powered by Large Language Models
    (LLMs) are increasingly used to simulate human collective behavior, yet few benchmarks
    exist for evaluating their dynamics against the behavior of human groups. In this
    paper, we examine the extent to which the wisdom of partisan crowds emerges in
    groups of LLM-based agents that are prompted to role-play as partisan personas
    (e.g., Democrat or Republican). We find that they not only display human-like
    partisan biases, but also converge to more accurate beliefs through deliberation
    as humans do. We then identify several factors that interfere with convergence,
    including the use of chain-of-thought prompt and lack of details in personas.
    Conversely, fine-tuning on human data appears to enhance convergence. These findings
    show the potential and limitations of LLM-based agents as a model of human collective
    intelligence.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人类群体能够通过审议趋向于更准确的信念，即使在极端分裂和党派偏见存在的情况下——这一现象被称为“党派群体的智慧”。由大型语言模型（LLMs）驱动的生成代理越来越多地被用于模拟人类的集体行为，然而，评估这些代理行为与人类群体行为对比的基准却很少。在本文中，我们探讨了党派群体的智慧在扮演党派角色（如民主党或共和党）的LLM代理群体中是否会出现。我们发现，这些代理不仅展示了类人化的党派偏见，而且通过审议趋向于更准确的信念，正如人类所做的那样。接着，我们识别了几个干扰收敛的因素，包括使用链式思维提示和角色缺乏细节。相反，在人类数据上进行微调似乎能增强收敛性。这些发现展示了基于LLM的代理作为人类集体智能模型的潜力和局限性。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'As Large Language Models (LLMs) have grown more human-like in the behaviors
    they produce (Park et al., [2022](https://arxiv.org/html/2311.09665v2#bib.bib17)),
    there has been increasing interest in investigating whether they can be used to
    better understand emulate human communication in social groups (Törnberg et al.,
    [2023](https://arxiv.org/html/2311.09665v2#bib.bib20); Kaiya et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib12);
    Li et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib14); Chuang et al.,
    [2023](https://arxiv.org/html/2311.09665v2#bib.bib7)). As one example, Park et al.
    ([2023](https://arxiv.org/html/2311.09665v2#bib.bib18)) used LLMs to construct
    generative agents that interact with each other in a simulated environment: initiating
    conversations, spreading information, remembering past events, and planning future
    actions. The resulting vignettes can show remarkably convincing interactions in
    which information about novel events, such as the planning of a birthday party,
    diffuses throughout the community of simulated agents. Yet it is difficult to
    understand how human-like such patterns really are, and consequently how useful
    such simulated systems are for understanding human communicative phenomena, without
    replicable empirical benchmarks of human behavior for comparison.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）在它们所产生的行为中变得越来越像人类（Park 等，[2022](https://arxiv.org/html/2311.09665v2#bib.bib17)），研究人员越来越关注是否可以利用这些模型更好地理解和模仿人类在社会群体中的沟通（Törnberg
    等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib20)；Kaiya 等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib12)；Li
    等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib14)；Chuang 等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib7)）。举个例子，Park
    等人（[2023](https://arxiv.org/html/2311.09665v2#bib.bib18)）使用LLMs构建了生成型代理，这些代理在模拟环境中彼此互动：启动对话、传播信息、记住过去的事件并规划未来的行动。最终生成的情境展示了相当令人信服的互动，其中关于新事件的信息（例如，生日派对的筹划）在模拟代理的群体中扩散。然而，如果没有可以复制的人类行为的实证基准进行比较，就很难理解这些模式在人类行为上究竟有多像，因此也很难判断这些模拟系统在理解人类沟通现象方面有多有用。
- en: '![Refer to caption](img/c2177ac67eb26a170781f874e32fa315.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c2177ac67eb26a170781f874e32fa315.png)'
- en: 'Figure 1: Experimental design comparing social feedback effects on LLM agents’
    estimations of partisan-biased factual questions. LLM agents role-playing Democrat
    and Republican update their estimates after considering their peers’ average responses
    (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：实验设计，比较社交反馈对大语言模型（LLM）代理在党派偏见事实问题上的估计影响。扮演民主党和共和党的LLM代理在考虑了同伴的平均回应后更新他们的估计（Becker
    等，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）。
- en: The current paper develops one such benchmark deriving from a phenomenon in
    the study of human collective intelligence, the wisdom of (partisan) crowds. The
    phenomenon reflects two interesting characteristics of human cognition. First,
    when estimating real-world quantities related to a politically polarized issue,
    self-identified Republicans and Democrats often generate systematically different
    guesses that reflect their political leanings. For example, when asked to estimate
    the US employment rate during Barack Obama’s administration, both groups overestimate
    relative to the ground truth, but Republicans produce reliably higher over-estimates,
    presumably remembering unemployment as worse than it actually was under the Democratic
    regime.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文发展了一个基准，源自人类集体智慧研究中的一个现象——（党派）群体的智慧。这个现象反映了人类认知的两个有趣特征。首先，当估计与政治极化议题相关的现实世界数据时，自认是共和党人和民主党人的个体常常会产生系统性不同的猜测，这些猜测反映了他们的政治倾向。例如，当被要求估算奥巴马政府时期的美国就业率时，两组人都相对真实值进行了高估，但共和党人产生的高估值始终较高，可能是因为他们记得在民主党政府下的失业情况比实际情况更糟。
- en: Second, when shown the mean guess from other members of their preferred party,
    both groups adjust their estimates in ways that move the group mean systematically
    closer to the ground truth. This phenomenon, known as the *wisdom of crowds*,
    is a paradigmatic example of how groups pool individual knowledge through aggregation
    and deliberation (Kameda et al., [2022](https://arxiv.org/html/2311.09665v2#bib.bib13);
    Yi et al., [2012](https://arxiv.org/html/2311.09665v2#bib.bib23)). Moreover, when
    individuals are shown the average estimate of their group and allowed to adjust
    their own, the group’s average becomes more accurate (Becker et al., [2017](https://arxiv.org/html/2311.09665v2#bib.bib1)),
    even for biased groups (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).
    The wisdom of crowds effect where social influence improves collective estimates,
    extends across different cultures (Jayles et al., [2017](https://arxiv.org/html/2311.09665v2#bib.bib11)),
    and finds application in practical domains such as clinical decision-making (Centola
    et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib4)) and science communication
    (Guilbeault et al., [2018](https://arxiv.org/html/2311.09665v2#bib.bib10)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，当看到其偏好党派其他成员的平均猜测时，两个群体都会调整他们的估计值，使得群体的均值系统性地更接近真实值。这个现象被称为*群体智慧*，它是群体通过聚合和讨论汇集个体知识的典型示例（Kameda
    等，[2022](https://arxiv.org/html/2311.09665v2#bib.bib13)；Yi 等，[2012](https://arxiv.org/html/2311.09665v2#bib.bib23)）。此外，当个体看到其群体的平均估计并允许调整自己的估计时，群体的平均值变得更加准确（Becker
    等，[2017](https://arxiv.org/html/2311.09665v2#bib.bib1)），即便是存在偏见的群体也是如此（Becker
    等，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）。群体智慧效应，即社会影响提升集体估计，跨越不同文化（Jayles
    等，[2017](https://arxiv.org/html/2311.09665v2#bib.bib11)），并应用于实际领域，如临床决策（Centola
    等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib4)）和科学传播（Guilbeault 等，[2018](https://arxiv.org/html/2311.09665v2#bib.bib10)）。
- en: In a seminal study, Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2))
    collected data from 1120 participants identifying as either Republican or Democrat.
    Each was asked factual questions known to elicit partisan bias, and after responding,
    was shown the average belief of others in their same partisan group (i.e. other
    Democrats or Republicans). Participants were then permitted to adjust their estimate,
    and the same procedure was repeated, yielding a series of three estimates for
    each respondent. The authors observed that, after each round of feedback, the
    mean estimate for both groups moved closer to the ground truth.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在一项开创性的研究中，Becker 等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）收集了1120名参与者的数据，这些参与者自认是共和党或民主党成员。每个人都被问到一些已知会引发党派偏见的事实性问题，回答后，参与者会看到同一党派群体中其他成员的平均信念（即其他民主党或共和党成员）。然后，参与者可以调整他们的估计，接着重复相同的程序，最终每个参与者会得到三次估计结果。作者观察到，在每轮反馈后，两个党派组的平均估计值都逐渐接近实际真相。
- en: This wisdom of partisan crowd phenomenon is useful for assessing LLM simulation
    of human communication for three reasons. First, all questions have a ground-truth
    value, providing a means of quantifying how accurate the actual LLM estimates
    are. Second, humans typically show partisan lean in their estimates. This provides
    an opportunity to evaluate whether role-playing LLMs show human-like patterns
    of partisan bias in their responses. Third, the social exchange of information
    within human partisan groups increased mean accuracy for each while also reducing
    polarization between groups, providing a reliable dynamic phenomenon in human
    communication that can be assessed in LLM agents.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这一党派群众智慧现象对于评估大规模语言模型（LLM）模拟人类沟通有三点重要作用。首先，所有问题都有一个真实的值，这为量化LLM估计的准确性提供了一种方式。其次，人类在估计时通常表现出党派倾向。这为评估角色扮演的LLM是否在人类反应中表现出类似的党派偏见提供了机会。第三，党派群体内部的信息社会交换提高了每个群体的平均准确性，同时也减少了群体间的极化，这为评估LLM代理中可靠的社会动态现象提供了依据。
- en: For these reasons, we replicated the experimental design of Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)),
    applying it to groups of interacting, role-playing LLM agents in a simulated environment,
    and assessing whether the resulting system replicated the key phenomena in human
    behavior. We found that LLM agents, when operating without Chain-of-Thought (CoT)
    reasoning, exhibit a substantial Wisdom of Partisan Crowds (WOC) effect, closely
    paralleling human patterns of error reduction in group settings. However, the
    use of CoT reasoning reduced this effect. We also show that the “depth of persona”
    created in the role-playing prompt critically influences whether LLM agents exhibit
    human-like partisanship bias in their estimates. Finally, fine-tuning LLMs with
    human data enhances human-like group dynamics in held-out data, though such training
    also risks overfitting. Together the work suggests a promising approach toward
    using established behavioral phenomena from human participants to evaluate and
    shape the use of LLMs for understanding dynamics of social communication.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这些原因，我们复制了Becker 等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）的实验设计，并将其应用于模拟环境中的互动角色扮演LLM代理组，评估结果系统是否复现了人类行为中的关键现象。我们发现，当LLM代理在没有链式思维（CoT）推理的情况下运行时，表现出了显著的党派群众智慧（WOC）效应，这与人类在群体环境中减少错误的模式高度相似。然而，使用CoT推理减少了这一效应。我们还发现，角色扮演提示中创造的“人格深度”对LLM代理是否在估计中表现出类似人类的党派偏见具有决定性影响。最后，用人类数据对LLM进行微调可以增强LLM在保留数据中的类人群体动态，尽管这种训练也有过拟合的风险。综合来看，这项工作为利用人类参与者的既有行为现象来评估和塑造LLM在社会沟通动态中的应用提供了一个有前景的方法。
- en: 'Table 1: Evaluation of resemblance between LLM agent and human in social interaction
    setting. The three main human-LLM alignment metrics are, $HLI$ (the more positive,
    the more human-like, $\overline{\Delta\varepsilon}$ (the more negative, the stronger
    the WOC effect) and $\overline{\beta_{\text{PB}}}$ (the more positive, the more
    aligned with human). The black boldface highlights the condition with the highest
    $HLI$. The metrics are shown with the standard errors. Notably, when there is
    no CoT reasoning, $\overline{\Delta\varepsilon}$ is always more negative than
    using CoT reasoning. In addition, using a detailed persona always leads to a more
    positive $\overline{\beta_{\text{PB}}}$ than using a simple persona.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：评估LLM代理与人类在社交互动设置中的相似性。三个人类-LLM对齐的主要指标是，$HLI$（越积极，越像人类），$\overline{\Delta\varepsilon}$（越消极，WOC效应越强）和$\overline{\beta_{\text{PB}}}$（越积极，与人类越对齐）。黑色粗体突出显示具有最高$HLI$的条件。指标以标准误差的形式显示。值得注意的是，当没有CoT推理时，$\overline{\Delta\varepsilon}$总是比使用CoT推理时更消极。此外，使用详细人物设定总是比使用简单人物设定导致更积极的$\overline{\beta_{\text{PB}}}$。
- en: '| Model | Persona | CoT | $HLI\uparrow$ | $\overline{\Delta\varepsilon}\downarrow$
    | $\overline{\beta_{\text{PB}}}\uparrow$ | Ext.% |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 人物设定 | CoT | $HLI\uparrow$ | $\overline{\Delta\varepsilon}\downarrow$
    | $\overline{\beta_{\text{PB}}}\uparrow$ | 扩展百分比 |'
- en: '| ChatGPT | Detailed | CoT | 4.45 ± 0.8 | -1.08 ± 0.76 | 3.37 ± 0.25 | 0.00
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | 详细 | CoT | 4.45 ± 0.8 | -1.08 ± 0.76 | 3.37 ± 0.25 | 0.00 |'
- en: '|  |  | No CoT | 12.82 ± 1.89 | -7.59 ± 1.87 | 5.23 ± 0.28 | 0.00 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 无CoT | 12.82 ± 1.89 | -7.59 ± 1.87 | 5.23 ± 0.28 | 0.00 |'
- en: '|  | Simple | CoT | -20.13 ± 1.1 | -2.07 ± 0.87 | -22.2 ± 0.67 | 0.00 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '|  | 简单 | CoT | -20.13 ± 1.1 | -2.07 ± 0.87 | -22.2 ± 0.67 | 0.00 |'
- en: '|  |  | No CoT | -21.8 ± 1.77 | -3.11 ± 1.47 | -24.91 ± 0.98 | 0.00 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 无CoT | -21.8 ± 1.77 | -3.11 ± 1.47 | -24.91 ± 0.98 | 0.00 |'
- en: '| Vicuna-33B | Detailed | CoT | 2.81 ± 1.36 | 2.87 ± 1.27 | 5.68 ± 0.49 | 1.31
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna-33B | 详细 | CoT | 2.81 ± 1.36 | 2.87 ± 1.27 | 5.68 ± 0.49 | 1.31 |'
- en: '|  |  | No CoT | 4.35 ± 2.64 | -0.68 ± 2.51 | 4.36 ± 0.80 | 1.38 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 无CoT | 4.35 ± 2.64 | -0.68 ± 2.51 | 4.36 ± 0.80 | 1.38 |'
- en: '|  | Simple | CoT | 3.36 ± 1.25 | 0.59 ± 1.18 | 3.94 ± 0.41 | 0.98 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '|  | 简单 | CoT | 3.36 ± 1.25 | 0.59 ± 1.18 | 3.94 ± 0.41 | 0.98 |'
- en: '|  |  | No CoT | -0.63 ± 2.63 | 0.49 ± 2.47 | -0.14 ± 0.91 | 5.60 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 无CoT | -0.63 ± 2.63 | 0.49 ± 2.47 | -0.14 ± 0.91 | 5.60 |'
- en: '| Human | - | - | 66.5 ± 6.79 | -33.16 ± 6.74 | 33.35 ± 0.83 | 8.37 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 人类 | - | - | 66.5 ± 6.79 | -33.16 ± 6.74 | 33.35 ± 0.83 | 8.37 |'
- en: 2 Methods
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2种方法
- en: 2.1 Experimental Procedure
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 实验过程
- en: 'We followed the experimental design from Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)),
    using LLMs to role-play Democrat and Republican personas. Each LLM agent is embedded
    in a network structure that governs interactions, connecting to four others sharing
    the same political leaning (all agents have node degree $k=4$; see Figure [1](https://arxiv.org/html/2311.09665v2#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")) and thus reflecting the homogeneous
    group structures in human studies. Each LLM agent, powered by LangChain (Chase,
    [2022](https://arxiv.org/html/2311.09665v2#bib.bib5)) with OpenAI’s ChatGPT (gpt-3.5-turbo;
    OpenAI, [2022](https://arxiv.org/html/2311.09665v2#bib.bib16)) and the open-source
    LLM Vicuna (vicuna-33B-v1.3; Zheng et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib24)),
    maintains the continuity of each persona’s memory throughout the experiment. Over
    three rounds, these agents were prompted to answer the same eight fact-based questions
    with known partisan biases as shown in Figure [1](https://arxiv.org/html/2311.09665v2#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents"). After each round, agents were given
    the average estimates of their connected peers and were asked to provide their
    estimates again. Thus at the end of the three rounds, each agent had produced
    three estimates for each of the eight questions. ¹¹1The original study by Becker
    et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)) divided these questions
    into two separate experiments, with the first four questions belonging to the
    first experiment and the last four to the second. However, as both sets of questions
    follow the same experimental procedure, we have merged them into a single analysis
    in our study. The full list of questions is provided in [D](https://arxiv.org/html/2311.09665v2#A4
    "Appendix D Full List of Questions ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents"). The full procedure was
    conducted 12 times for each group to mirror the 12 groups of human participants
    in the social conditions in Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).
    Temperate sampling (temperature = 0.7) was used to allow variability in responses.
    [F](https://arxiv.org/html/2311.09665v2#A6 "Appendix F Full list of Prompts ‣
    The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents") shows the actual prompts. The compute resource for using Vicuna
    is in [I](https://arxiv.org/html/2311.09665v2#A9 "Appendix I Compute Resources
    ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents").'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '我们遵循了Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）的实验设计，使用大型语言模型（LLMs）扮演民主党和共和党的角色。每个LLM代理被嵌入在一个网络结构中，网络结构管理交互，连接到四个与其政治倾向相同的其他代理（所有代理的节点度为$k=4$；参见图[1](https://arxiv.org/html/2311.09665v2#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")），从而反映了人类研究中的同质化群体结构。每个LLM代理由LangChain（Chase,
    [2022](https://arxiv.org/html/2311.09665v2#bib.bib5)）和OpenAI的ChatGPT（gpt-3.5-turbo；OpenAI，[2022](https://arxiv.org/html/2311.09665v2#bib.bib16)）以及开源LLM
    Vicuna（vicuna-33B-v1.3；Zheng等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib24)）提供支持，在实验过程中保持每个角色的记忆连续性。在三轮实验中，这些代理被提示回答相同的八个具有已知党派偏见的事实性问题，如图[1](https://arxiv.org/html/2311.09665v2#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")所示。每轮结束后，代理会收到其连接同伴的平均估计值，并要求再次提供其估计。因此，在三轮实验结束时，每个代理为每个问题提供了三次估计。¹¹1Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）的原始研究将这些问题分为两个独立的实验，前四个问题属于第一个实验，最后四个问题属于第二个实验。然而，由于两组问题遵循相同的实验程序，我们在本研究中将它们合并为单一分析。问题的完整列表请参见[D](https://arxiv.org/html/2311.09665v2#A4
    "Appendix D Full List of Questions ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents")。整个过程每组执行了12次，以模拟Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）研究中的12组人类参与者的社会条件。使用了温和抽样（温度=0.7）以允许响应的变异性。[F](https://arxiv.org/html/2311.09665v2#A6
    "Appendix F Full list of Prompts ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")展示了实际的提示。使用Vicuna的计算资源在[I](https://arxiv.org/html/2311.09665v2#A9
    "Appendix I Compute Resources ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")中列出。'
- en: Formal notation
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 正式符号
- en: We denote each agent in the experiment as $a_{i,p,r}$, where $1\leq i\leq 35$
    indexes the agent within a specific run, $p$ denotes political leaning (Democrat
    or Republican; abbreviated as Dem and Rep hereafter), and $r$ specifies the run
    index with $1\leq r\leq 12$. When the context is clear, we drop the subscript
    $p$ and $r$. For each political leaning, during each run, the agents answer eight
    questions over three time steps, generating a series of estimates $x_{i,q}^{t}$
    for question $q$ at time $t$. Since all eight questions are fact-based, each has
    a ground truth value, denoted as $x^{*}_{q}$. Starting at $t\geq 2$, agents are
    shown $m^{t}_{i,q}$, the average estimate of their four politically homogeneous
    neighbors, before making their own estimates. ²²2Formally, the average estimate
    from neighbors for agent $a_{i,p,r}$ at time $t$ for question $q$ is $m_{i,p,r,q}^{t}=\frac{1}{K}\sum_{j\in\mathcal{N}(i,p,r)}x_{j,p,r,q}^{t-1}$,
    where $\mathcal{N}(i,p,r)$ is the set of indices for the agents’ neighbors who
    share the same political leaning $p$. The number of neighbors $K=4$.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在实验中将每个代理表示为 $a_{i,p,r}$，其中 $1\leq i\leq 35$ 是特定运行中代理的索引，$p$ 表示政治倾向（民主党或共和党；以下简称
    Dem 和 Rep），$r$ 表示运行的索引，$1\leq r\leq 12$。当上下文明确时，我们会省略下标 $p$ 和 $r$。对于每种政治倾向，在每轮实验中，代理会在三个时间步骤内回答八个问题，生成一系列估算值
    $x_{i,q}^{t}$，其中 $q$ 是问题编号，$t$ 是时间步骤。由于所有八个问题都是基于事实的，因此每个问题都有一个真实值，记作 $x^{*}_{q}$。从
    $t\geq 2$ 开始，代理会看到 $m^{t}_{i,q}$，即他们四个政治上相似邻居的平均估算值，然后再做出自己的估算。²²2形式上，代理 $a_{i,p,r}$
    在时间 $t$ 针对问题 $q$ 的邻居平均估算值为 $m_{i,p,r,q}^{t}=\frac{1}{K}\sum_{j\in\mathcal{N}(i,p,r)}x_{j,p,r,q}^{t-1}$，其中
    $\mathcal{N}(i,p,r)$ 是与代理 $a_{i,p,r}$ 具有相同政治倾向 $p$ 的邻居集合。邻居的数量为 $K=4$。
- en: 2.2 Personas and Agent Specification
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 角色和代理规格
- en: Personas and agent specification
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 角色和代理规格
- en: We prompted the LLMs to role-play as different personas created with varying
    levels of background detail. Simple Personas are specified as “a typical Democrat/Republican,”
    relying on temperature sampling to elicit slightly different biased views. Detailed
    Personas are provided with comprehensive backstories, including demographics and
    personal background information, to introduce individual differences based on
    such factors. This persona is retained in memory across the three rounds of adjustment
    for all questions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让大型语言模型（LLMs）扮演不同角色，这些角色是根据不同的背景细节设定的。简单的角色被定义为“典型的民主党人/共和党人”，通过温度采样来引导出略有不同的偏见观点。详细的角色则提供了完整的背景故事，包括人口统计信息和个人背景，基于这些因素引入个体差异。这个角色在三轮调整中会被记住，并用于所有问题的回答。
- en: '[C](https://arxiv.org/html/2311.09665v2#A3 "Appendix C List of Personas ‣ The
    Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based
    Agents") shows the full list of both detailed and simple personas. A diverse set
    of detailed personas was generated by GPT-4.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[C](https://arxiv.org/html/2311.09665v2#A3 "附录 C 角色列表 ‣ 党派群体的智慧：比较人类与基于LLM的代理的集体智能")
    显示了详细和简单角色的完整列表。通过 GPT-4 生成了一套多样化的详细角色。'
- en: For example,
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，
- en: 'Name: Isabella Johnson; Political leaning: Strong Democrat; Age: 67; Gender:
    Female; Ethnicity: White; Education: Bachelor’s Degree in Education; Occupation:
    Retired Teacher; Background: Isabella is from Portland, Oregon, and spent her
    career advocating for public education and teachers’ rights. She is passionate
    about social justice, healthcare, and environmental issues. Isabella is widowed
    with two grown children and enjoys birdwatching and painting in her free time.'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 姓名：伊莎贝拉·约翰逊；政治倾向：强烈的民主党人；年龄：67岁；性别：女性；种族：白人；教育背景：教育学学士学位；职业：退休教师；背景：伊莎贝拉来自俄勒冈州波特兰市，职业生涯中致力于倡导公共教育和教师权益。她热衷于社会正义、医疗保健和环境问题。伊莎贝拉是寡妇，育有两个成年的孩子，空闲时喜欢鸟类观察和绘画。
- en: Chain-of-thought reasoning (CoT)
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 思维链推理（CoT）
- en: 'We manipulated whether the agents used chain-of-thought (CoT) reasoning Wei
    et al. ([2022b](https://arxiv.org/html/2311.09665v2#bib.bib22); [a](https://arxiv.org/html/2311.09665v2#bib.bib21)).
    CoT has demonstrated success as a prompting strategy in solving complex reasoning
    tasks, such as arithmetic problems. However, recent work also indicates that CoT
    reasoning may lead to stereotypes and biases Shaikh et al. ([2022](https://arxiv.org/html/2311.09665v2#bib.bib19)).
    This leads us to explore how CoT reasoning influences an LLM agent’s ability to
    assume human-like behaviors in a social interaction setting. To elicit CoT reasoning,
    we append the prompt with the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们操控了代理是否使用链式推理（CoT）Wei等人（[2022b](https://arxiv.org/html/2311.09665v2#bib.bib22);
    [a](https://arxiv.org/html/2311.09665v2#bib.bib21)）。CoT在解决复杂推理任务（如算术问题）中作为提示策略已取得成功。然而，近期的研究也表明，CoT推理可能导致刻板印象和偏见Shaikh等人（[2022](https://arxiv.org/html/2311.09665v2#bib.bib19)）。这促使我们探索CoT推理如何影响LLM代理在社交互动环境中展现类似人类行为的能力。为了引发CoT推理，我们在提示中附加以下内容：
- en: “Please provide your step-by-step reasoning and then give your estimate as a
    real number.”
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “请提供您的逐步推理过程，然后给出您的实数估计。”
- en: In contrast, in the condition without CoT reasoning, we end the prompt with
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在没有CoT推理的条件下，我们在提示的结尾加上
- en: “Please provide your estimate in a real number.”
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “请提供您的实数估计。”
- en: 2.3 Fine-Tuning the LLMs with Human Data
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 使用人类数据对LLM进行微调
- en: 'In addition to in-context learning through prompting, we also perform supervised
    fine-tuning using human response data from the experiment in Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2))
    to enhance the resemblance of human behaviors in LLM agents. Our fine-tuning methodology
    is inspired by Binz & Schulz ([2023](https://arxiv.org/html/2311.09665v2#bib.bib3)),
    showing that through supervised learning, LLMs can be adapted to modeling human
    decision-making behavior in an unseen task. We aim to investigate whether fine-tuning
    also improves the resemblance of human-like behavior in group interaction settings.
    We fine-tune two separate LLMs: one for Democrats and another one for Republicans.
    The training data consists of responses to questions $5\leq q\leq 8$, while using
    questions $1\leq q\leq 4$ as the testing set. The fine-tuned model is then evaluated
    separately on the train set and the test set. When fine-tuning, no persona is
    provided. Details on how we fine-tuned the LLM (ChatGPT in specific) are in the
    [H](https://arxiv.org/html/2311.09665v2#A8 "Appendix H Fine-tuning Details ‣ The
    Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based
    Agents").'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过提示进行上下文学习外，我们还使用来自Becker等人实验中的人类回应数据进行监督微调（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)），以增强LLM代理中人类行为的相似性。我们的微调方法灵感来自Binz
    & Schulz（[2023](https://arxiv.org/html/2311.09665v2#bib.bib3)），他们展示了通过监督学习，LLM可以被调整为在未见任务中模拟人类决策行为。我们旨在研究微调是否也能提高群体互动设置中人类行为的相似性。我们对两个单独的LLM进行微调：一个针对民主党，一个针对共和党。训练数据包括对问题$5\leq
    q\leq 8$的回答，同时使用问题$1\leq q\leq 4$作为测试集。微调后的模型分别在训练集和测试集上进行评估。在微调时，不提供人物设定。关于我们如何微调LLM（特别是ChatGPT）的详细信息，请参见[H](https://arxiv.org/html/2311.09665v2#A8
    "附录H 微调细节 ‣ 党派人群的智慧：比较人类与LLM代理的集体智能")。
- en: 2.4 Evaluation Metrics
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 评估指标
- en: Wisdom of Partisan Crowds Effect (WOC)
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 党派人群智慧效应（WOC）
- en: 'The Wisdom of Crowds effect quantifies the improvement in LLM agent estimates
    through social interaction, similar to that of human groups Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).
    Within each political leaning and run, we compute the group mean for each question
    $q$ and time step $t$, $\bar{x}_{q}^{t}=\frac{1}{N}\sum_{i=1}^{N}x_{i,q}^{t}$
    (with $N=35$ per group), and the normalized group mean $\eta_{q}^{t}=100\times(\bar{x}_{q}^{t}-x^{*}_{q})/{x^{*}_{q}}$.
    The normalized group error $\varepsilon_{q}^{t}=|\eta_{q}^{t}|$ shows the percentage
    deviation from the ground truth $|x^{*}|$. We measure the reduction in group error
    per question as $\Delta\varepsilon_{q}=\varepsilon_{q}^{t=3}-\varepsilon_{q}^{t=1}$,
    and average these across all questions, both political leanings, and all runs
    to obtain the average reduction in group error $\overline{\Delta\varepsilon}$.
    A more negative $\overline{\Delta\varepsilon}$ indicates a stronger wisdom of
    crowd effect, with $\overline{\Delta\varepsilon}$ representing the percentage
    of ground truth size $|x^{*}|$ by which estimates move toward truth. For detailed
    derivation, see [J.1](https://arxiv.org/html/2311.09665v2#A10.SS1 "J.1 Reduction
    in Group Error Through Social Interaction ‣ Appendix J Detailed Definition of
    Notations ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in
    Humans and LLM-based Agents").'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 群体智慧效应量化了通过社会互动改善大语言模型（LLM）代理估计值的效果，这与人类群体的行为相似（Becker等人，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）。在每个政治倾向和每次实验中，我们计算每个问题$q$和时间步$t$的组平均值$\bar{x}_{q}^{t}=\frac{1}{N}\sum_{i=1}^{N}x_{i,q}^{t}$（每组$N=35$），以及归一化的组平均值$\eta_{q}^{t}=100\times(\bar{x}_{q}^{t}-x^{*}_{q})/{x^{*}_{q}}$。归一化的组误差$\varepsilon_{q}^{t}=|\eta_{q}^{t}|$表示与真实值$|x^{*}|$的百分比偏差。我们通过$\Delta\varepsilon_{q}=\varepsilon_{q}^{t=3}-\varepsilon_{q}^{t=1}$来衡量每个问题的组误差减少，并对所有问题、所有政治倾向和所有实验进行平均，得到组误差的平均减少$\overline{\Delta\varepsilon}$。更负的$\overline{\Delta\varepsilon}$表示更强的群体智慧效应，$\overline{\Delta\varepsilon}$表示估计值向真实值靠拢的真实值百分比$|x^{*}|$。详细推导请见[J.1](https://arxiv.org/html/2311.09665v2#A10.SS1
    "J.1 通过社会互动减少组误差 ‣ 附录J 符号详细定义 ‣ 政党群体智慧：比较人类与基于LLM的代理的集体智慧")。
- en: Partisan Bias
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 政党偏见
- en: '![Refer to caption](img/a9ba207070bf89d38bb2722500be90f1.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/a9ba207070bf89d38bb2722500be90f1.png)'
- en: 'Figure 2: Average Normalized Group Error ($\overline{\varepsilon}_{t}$) for
    (a) human crowds and (b) LLM agents (ChatGPT) across the experimental settings.
    Error bars indicating standard errors.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：在不同实验设置下，（a）人类群体和（b）LLM代理（ChatGPT）的平均归一化组误差（$\overline{\varepsilon}_{t}$）。误差条表示标准误差。
- en: 'To evaluate human-like partisan biases in LLM agents, we define Partisan Bias
    as the average difference in normalized group mean $\eta_{q}^{t}$ between the
    Democratic and Republican groups, in line with the expected directions of human
    partisan bias. Formally, for each questions $q$, let $\overline{D}_{q}$ be the
    normalized group mean $\eta_{q}^{t}$ averaged across Democrats’ runs and time
    steps, and let $\overline{R}_{q}$ be the average for Republicans’. The partisan
    bias for question $q$ is defined as $\beta_{\text{PB}_{q}}=(\overline{R}_{q}-\overline{D}_{q})\times\text{sign}(h_{%
    q})$, where $\text{sign}(h_{q})$ indicates the human partisan bias direction as
    per human data Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)),
    with $+1$ if Republicans typically have greater $\eta_{p,r,q}^{t}$ than Democrats
    (i.e., a more positive $\overline{x}_{q}^{t}$ if $x^{*}_{q}>0$), $-1$ if the other
    way around, and $0$ if there is no expected difference. ³³3$\text{sign}(h_{q})$:
    $+1$ in questions 3 (unemployment rate), 4 (taxes); $-1$ in questions 5 (military),
    6 (immigration change), 7 (unemployment change); and $0$ in questions 1 (election),
    2 (California), 8 (Soldiers). In addition, we denote overall partisan bias $\overline{\beta_{\text{PB}}}$
    as the partisan bias averaged across all questions’ $\beta_{\text{PB}_{q}}$. A
    positive $\overline{\beta_{\text{PB}}}$ indicates a overall similarity to the
    direction of human bias, and vice versa⁴⁴4Because $\eta_{q}^{t}$ is scaled by
    a factor of 100, $\overline{\beta_{\text{PB}}}$ can be interpreted as the partisan
    bias expressed in percentage of the size of ground truth $|x^{*}|$.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估LLM代理中的人类党派偏见，我们将党派偏见定义为在民主党和共和党之间的标准化组均值$\eta_{q}^{t}$的平均差异，这与人类党派偏见的预期方向一致。形式上，对于每个问题$q$，设$\overline{D}_{q}$为在民主党成员的运行和时间步长中平均的标准化组均值$\eta_{q}^{t}$，设$\overline{R}_{q}$为共和党成员的平均值。问题$q$的党派偏见定义为$\beta_{\text{PB}_{q}}=(\overline{R}_{q}-\overline{D}_{q})\times\text{sign}(h_{%
    q})$，其中$\text{sign}(h_{q})$表示人类党派偏见的方向，依据Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）的研究数据，$+1$表示共和党通常具有比民主党更大的$\eta_{p,r,q}^{t}$（即，如果$x^{*}_{q}>0$，则$\overline{x}_{q}^{t}$为正），$-1$表示反之，$0$表示没有预期的差异。³³3$\text{sign}(h_{q})$:
    在问题3（失业率）、4（税收）中为$+1$；在问题5（军事）、6（移民变动）、7（失业变化）中为$-1$；在问题1（选举）、2（加利福尼亚）、8（士兵）中为$0$。此外，我们将整体党派偏见$\overline{\beta_{\text{PB}}}$定义为所有问题的$\beta_{\text{PB}_{q}}$的平均值。正的$\overline{\beta_{\text{PB}}}$表示整体与人类偏见方向相似，反之亦然⁴⁴4由于$\eta_{q}^{t}$被缩放了100倍，$\overline{\beta_{\text{PB}}}$可以解释为表示党派偏见的百分比，基于真实值$|x^{*}|$的大小。'
- en: Human Likeness Index
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人类相似度指数
- en: We introduce the Human Likeness Index (HLI) to assess the extent of LLM agents’
    resemblance to human behaviors. To aggregate the wisdom of crowd effect ($\overline{\Delta\varepsilon}$)
    and the partisan bias ($\overline{\beta_{\text{PB}}}$), we define $HLI=\overline{\beta_{\text{PB}}}+(-\overline{\Delta\varepsilon})$.
    A higher HLI score⁵⁵5A linear addition makes sense because both $\overline{\beta_{\text{PB}}}$
    and $\overline{\Delta\varepsilon}$ are on the same scale. Both can be expressed
    as a percentage of the size of the ground truth value $|x^{*}|$. indicates a stronger
    overall human-like behavior in the LLM agents within this group experiment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了人类相似度指数（HLI）来评估大型语言模型（LLM）代理与人类行为的相似程度。为了聚合群体智慧效应（$\overline{\Delta\varepsilon}$）和党派偏见（$\overline{\beta_{\text{PB}}}$），我们定义$HLI=\overline{\beta_{\text{PB}}}+(-\overline{\Delta\varepsilon})$。更高的HLI得分⁵⁵5A
    线性加和是合理的，因为$\overline{\beta_{\text{PB}}}$和$\overline{\Delta\varepsilon}$处于相同的量级。两者均可以表示为相对于真实值大小$|x^{*}|$的百分比，表示该组实验中LLM代理的整体人类相似行为更强。
- en: Extreme Values (Ext.%)
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 极端值（Ext.%）
- en: 'The Ext.% metric evaluates the proportion of LLM agent responses that are unrealistic,
    based on established criteria Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).
    For a fair comparison with human data, the same criteria are applied to identify
    extreme values, for example, marking any response to the unemployment rate above
    47% as extreme. These criteria are detailed in [G](https://arxiv.org/html/2311.09665v2#A7
    "Appendix G Criteria for Extreme Values ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents"). Extreme values are excluded
    from calculations of Average Group Error Reduction ($\overline{\Delta\varepsilon}$)
    and Partisan Bias ($\overline{\beta_{\text{PB}}}$). The Ext.% thereby serves as
    a measure of the tendency of the LLM agents to generate unrealistic responses.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 'Ext.%指标评估LLM代理生成的不现实回答的比例，依据已有标准Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）提出的标准。为了与人类数据进行公平比较，同样的标准被应用于识别极端值，例如将任何高于47%的失业率回答标记为极端值。这些标准的详细信息请参见[G](https://arxiv.org/html/2311.09665v2#A7
    "Appendix G Criteria for Extreme Values ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents")。极端值会被排除在平均群体误差减少（$\overline{\Delta\varepsilon}$）和偏见（$\overline{\beta_{\text{PB}}}$）计算之外。因此，Ext.%作为衡量LLM代理生成不现实回答倾向的指标。'
- en: Revision Coefficient
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 修正系数
- en: 'In human crowds, the mechanism for why the group mean converges towards the
    truth through social interaction is that those who are more accurate at their
    initial estimate tend to be influenced less by the information they received,
    and thus pull the group distribution towards the truth (Becker et al., [2017](https://arxiv.org/html/2311.09665v2#bib.bib1)).
    Following Becker et al. ([2017](https://arxiv.org/html/2311.09665v2#bib.bib1))’s
    methodology, for each question $q$, we calculate the revision coefficient ($r_{\text{adj},q}$),
    defined as the partial correlation between individual revision ($\Delta x_{i,q}=|x_{i,q}^{t=3}-x_{i,q}^{t=1}|$)
    and individual initial error ($e_{i,q}=|x_{i,q}^{t=1}-x_{q}^{*}|$), adjusted for
    the social signal ($s_{i,q}=|x_{i,q}^{t=1}-m_{i,q}^{t=2}|$) that each individual
    receives. Adjusting for the social signal is important as individuals with higher
    initial errors often receive stronger social feedback as they deviate from the
    rest. Formally, $r_{\text{adj},q}=\text{corr}(\widetilde{\Delta x}_{i,q},\widetilde{e}_{i,q})$,
    where $\widetilde{\Delta x}_{i,q}$ and $\widetilde{e}_{i,q}$ are ${\Delta x}_{i,q}$
    and ${e}_{i,q}$ adjusted by social signal. Please refer to [J.2](https://arxiv.org/html/2311.09665v2#A10.SS2
    "J.2 Deriving the Revision Coefficient ‣ Appendix J Detailed Definition of Notations
    ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents") for detailed derivation.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '在人类群体中，群体均值通过社会互动趋向真实的机制是，初步估计更准确的人往往不太受他们所接收到的信息的影响，因此将群体分布拉向真实（Becker等人，[2017](https://arxiv.org/html/2311.09665v2#bib.bib1)）。根据Becker等人（[2017](https://arxiv.org/html/2311.09665v2#bib.bib1)）的方法论，对于每个问题$q$，我们计算修正系数（$r_{\text{adj},q}$），其定义为个体修正（$\Delta
    x_{i,q}=|x_{i,q}^{t=3}-x_{i,q}^{t=1}|$）与个体初始误差（$e_{i,q}=|x_{i,q}^{t=1}-x_{q}^{*}|$）之间的部分相关系数，并调整每个个体收到的社会信号（$s_{i,q}=|x_{i,q}^{t=1}-m_{i,q}^{t=2}|$）。调整社会信号非常重要，因为初始误差较大的个体通常会受到更强烈的社会反馈，因为他们与其他人的偏差较大。形式上，$r_{\text{adj},q}=\text{corr}(\widetilde{\Delta
    x}_{i,q},\widetilde{e}_{i,q})$，其中$\widetilde{\Delta x}_{i,q}$和$\widetilde{e}_{i,q}$是通过社会信号调整后的${\Delta
    x}_{i,q}$和${e}_{i,q}$。详细推导请参见[J.2](https://arxiv.org/html/2311.09665v2#A10.SS2
    "J.2 Deriving the Revision Coefficient ‣ Appendix J Detailed Definition of Notations
    ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents")。'
- en: 3 Results and Discussion
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 结果与讨论
- en: '![Refer to caption](img/2232e7c205c3d4a5a1e4ae7052dd995b.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/2232e7c205c3d4a5a1e4ae7052dd995b.png)'
- en: 'Figure 3: Normalized group mean $\eta_{p,t}$ over three rounds, averaged across
    12 group experiments (red for Republicans, blue for Democrats), with error bars
    for standard errors. Each panel consists of four columns representing different
    data sets: Column 1 shows human data. Columns 2 to 4 shows LLM (ChatGPT) agents’
    data. Column 2 depicts LLM role-playing detailed personas and without CoT reasoning
    (the configuration with the highest $HLI$); Column 3 presents LLM results before
    fine-tuning; and Column 4 illustrates LLM after fine-tuning. Panel (a) includes
    questions from the training set ($5\leq q\leq 8$) used for fine-tuning the LLM
    agents, while Panel (b) displays questions from the hold-out test set ($1\leq
    q\leq 4$). Question-specific WOC effects ($\Delta\varepsilon_{q}$) and partisan
    biases ($\beta_{\text{PB}_{q}}$, if expected) are overlaid for comparison.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：三轮实验中的标准化组均值$\eta_{p,t}$，在12个小组实验中取平均值（红色为共和党，蓝色为民主党），并附有标准误差的误差条。每个面板由四列数据组成，分别代表不同的数据集：第一列展示了人类数据。第二至第四列展示了LLM（ChatGPT）代理的数据。第二列展示了LLM角色扮演详细人物设定且没有链式推理的配置（即具有最高$HLI$的配置）；第三列展示了LLM未进行微调前的结果；第四列展示了微调后的LLM结果。面板（a）包括用于微调LLM代理的训练集问题（$5\leq
    q\leq 8$），而面板（b）展示了来自保留测试集的问题（$1\leq q\leq 4$）。每个问题特定的WOC效应（$\Delta\varepsilon_{q}$）和党派偏见（$\beta_{\text{PB}_{q}}$，如果有的话）已重叠显示，以便进行比较。
- en: 3.1 Effect of Persona Detail, CoT Reasoning
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 人物设定细节与链式推理的效果
- en: Detailed Persona and without CoT Reasoning Elicits Wisdom of Crowds Effect
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 详细人物设定且无链式推理激发群体智慧效应
- en: 'LLM agents with detailed personas, but without CoT reasoning, demonstrate the
    closest resemblance to human group dynamics. They demonstrate the highest human
    likeness, $HLI=12.82$ (ChatGPT) and $3.67$ (Vicuna) among the six experimental
    settings (Table [1](https://arxiv.org/html/2311.09665v2#S1.T1 "Table 1 ‣ 1 Introduction
    ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents")). Figure [2](https://arxiv.org/html/2311.09665v2#S2.F2 "Figure
    2 ‣ Partisan Bias ‣ 2.4 Evaluation Metrics ‣ 2 Methods ‣ The Wisdom of Partisan
    Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents") visualizes
    the wisdom of partisan crowd results of LLM agents (ChatGPT). These agents converge
    significantly towards the ground truth after social interaction, quantified by
    a significant WOC effect, $\overline{\Delta\varepsilon}=-7.59$, $CI_{95\%}=[-11.08,-4.10]$,
    $p<.001$. It also shows a significant human-like partisan bias, $\overline{\beta_{\text{PB}}}=5.23,CI_{95\%}=[4.66,5.81]$,
    $p<.001$. ⁶⁶6The p-values and 95% Confidence Intervals ($CI_{95\%}$) are derived
    from bootstrapping with 1000 resamplings (Efron, [1992](https://arxiv.org/html/2311.09665v2#bib.bib8)).
    Figure [3](https://arxiv.org/html/2311.09665v2#S3.F3 "Figure 3 ‣ 3 Results and
    Discussion ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence
    in Humans and LLM-based Agents") shows the detailed result for each question.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '拥有详细人物设定但没有链式推理（CoT）的LLM代理表现出最接近人类群体动态的特征。它们在六种实验设置中展示了最高的人类相似度，$HLI=12.82$（ChatGPT）和$3.67$（Vicuna）（表格[1](https://arxiv.org/html/2311.09665v2#S1.T1
    "Table 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")）。图[2](https://arxiv.org/html/2311.09665v2#S2.F2
    "Figure 2 ‣ Partisan Bias ‣ 2.4 Evaluation Metrics ‣ 2 Methods ‣ The Wisdom of
    Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents")展示了LLM代理（ChatGPT）偏向的群体智慧结果。这些代理在社交互动后显著趋近于真实情况，这一效果通过显著的WOC效应量化，$\overline{\Delta\varepsilon}=-7.59$，$CI_{95\%}=[-11.08,-4.10]$，$p<.001$。同时，结果还显示出显著的人类偏见，$\overline{\beta_{\text{PB}}}=5.23,CI_{95\%}=[4.66,5.81]$，$p<.001$。⁶⁶6这些p值和95%的置信区间（$CI_{95\%}$）来自于1000次重采样的自助法（Efron，[1992](https://arxiv.org/html/2311.09665v2#bib.bib8)）。图[3](https://arxiv.org/html/2311.09665v2#S3.F3
    "Figure 3 ‣ 3 Results and Discussion ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents")展示了每个问题的详细结果。'
- en: 'Next, we look into the role of persona detail and CoT reasoning, respectively.
    The result with Vicuna is shown in Figure [6](https://arxiv.org/html/2311.09665v2#A2.F6
    "Figure 6 ‣ Appendix B Vicuna Results ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents") in [B](https://arxiv.org/html/2311.09665v2#A2
    "Appendix B Vicuna Results ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents"). As shown in Table [1](https://arxiv.org/html/2311.09665v2#S1.T1
    "Table 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents"), without CoT reasoning, the agents’
    error reduction through social interaction is consistently greater than with CoT
    reasoning, $\overline{\Delta\varepsilon}$ (without CoT) $<$ $\overline{\Delta\varepsilon}$
    (with CoT), difference $=4.63$, $CI_{95\%}=[2.10,7,20]$, $p<.001$. For example,
    when role-playing detailed persona, the LLM agents (ChatGPT)’ error reduction
    $\overline{\Delta\varepsilon}=-7.59$ when there is no CoT reasoning, as opposed
    to $\overline{\Delta\varepsilon}=-1.08$ with CoT reasoning, difference $=6.52$,
    $CI_{95\%}=[2.59,10.72]$, $p<.001$. In addition, as shown in Figure [2](https://arxiv.org/html/2311.09665v2#S2.F2
    "Figure 2 ‣ Partisan Bias ‣ 2.4 Evaluation Metrics ‣ 2 Methods ‣ The Wisdom of
    Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents")b,
    without CoT reasoning always yield a smaller averaged normalized group error $\overline{\varepsilon}_{t}$
    than the counterpart without CoT reasoning. The result with Vicuna shows similar
    patterns.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '接下来，我们分别探讨角色细节和CoT推理的作用。与Vicuna的结果如图[6](https://arxiv.org/html/2311.09665v2#A2.F6
    "Figure 6 ‣ Appendix B Vicuna Results ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents")所示，在[B](https://arxiv.org/html/2311.09665v2#A2
    "Appendix B Vicuna Results ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")中。正如表[1](https://arxiv.org/html/2311.09665v2#S1.T1
    "Table 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")所示，没有CoT推理时，代理通过社交互动减少的错误量始终大于有CoT推理时的减少量，$\overline{\Delta\varepsilon}$（没有CoT）$<$
    $\overline{\Delta\varepsilon}$（有CoT），差异$=4.63$，$CI_{95\%}=[2.10,7,20]$，$p<.001$。例如，当进行详细角色扮演时，LLM代理（ChatGPT）在没有CoT推理时的错误减少量为$\overline{\Delta\varepsilon}=-7.59$，而有CoT推理时的错误减少量为$\overline{\Delta\varepsilon}=-1.08$，差异$=6.52$，$CI_{95\%}=[2.59,10.72]$，$p<.001$。此外，如图[2](https://arxiv.org/html/2311.09665v2#S2.F2
    "Figure 2 ‣ Partisan Bias ‣ 2.4 Evaluation Metrics ‣ 2 Methods ‣ The Wisdom of
    Partisan Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents")b所示，没有CoT推理时，平均归一化群体错误$\overline{\varepsilon}_{t}$始终小于没有CoT推理时的结果。Vicuna的结果显示出相似的模式。'
- en: Detailed Persona and CoT Reasoning Encourages Human-like Partisan Bias
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 详细的角色设定和CoT推理促进了类人偏袒性别。
- en: 'The depth of persona detail and the use of CoT reasoning significantly increase
    the LLM agents’ resemblance of human-like partisan bias $\overline{\beta_{\text{PB}}}$
    (Table [1](https://arxiv.org/html/2311.09665v2#S1.T1 "Table 1 ‣ 1 Introduction
    ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents")). Detailed personas enables a more human-like partisan bias
    across the two LLMs and across the two CoT reasoning conditions, $\overline{\beta_{\text{PB}}}$
    (detailed persona) $>$ $\overline{\beta_{\text{PB}}}$ (simple persona), difference
    = $15.48$, $CI_{95\%}=[14.63,16.36]$, $p<.001$. On the other hand, the use of
    CoT reasoning also enables a more human-like partisan bias across the two LLMs
    and across all conditions, $\overline{\beta_{\text{PB}}}$ (CoT) $>$ $\overline{\beta_{\text{PB}}}$
    (no CoT), difference = $13.64$, $CI_{95\%}=[12.48,14.78]$, $p<.001$.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '角色细节的深度和CoT推理的使用显著增加了LLM代理在偏袒性别方面与人类的相似度$\overline{\beta_{\text{PB}}}$（表[1](https://arxiv.org/html/2311.09665v2#S1.T1
    "Table 1 ‣ 1 Introduction ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents")）。详细的角色设定使两种LLM在两种CoT推理条件下都呈现出更具人类特色的偏袒性别，$\overline{\beta_{\text{PB}}}$（详细角色）$>$
    $\overline{\beta_{\text{PB}}}$（简单角色），差异 = $15.48$，$CI_{95\%}=[14.63,16.36]$，$p<.001$。另一方面，使用CoT推理也使两种LLM在所有条件下都呈现出更具人类特色的偏袒性别，$\overline{\beta_{\text{PB}}}$（CoT）$>$
    $\overline{\beta_{\text{PB}}}$（没有CoT），差异 = $13.64$，$CI_{95\%}=[12.48,14.78]$，$p<.001$。'
- en: This example illustrates how, in role-playing scenarios, LLM agents’ CoT reasoning
    is more influenced by their personas than factual accuracy.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了在角色扮演场景中，LLM代理的CoT推理受到其角色设定的影响大于事实准确性。
- en: 3.2 Impact of Fine-Tuning on Enhancing Human-Like Dynamics
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 微调对增强类人动态的影响
- en: 'As shown in Table [2](https://arxiv.org/html/2311.09665v2#S3.T2 "Table 2 ‣
    3.2 Impact of Fine-Tuning on Enhancing Human-Like Dynamics ‣ 3 Results and Discussion
    ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence in Humans and
    LLM-based Agents") and Figure [3](https://arxiv.org/html/2311.09665v2#S3.F3 "Figure
    3 ‣ 3 Results and Discussion ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents"), in the training set (questions
    $5\leq q\leq 8$), the human likeness index ($HLI$) increases to $50.11$ (from
    $-33.95$ before fine-tuning), partisan bias $\overline{\beta_{\text{PB}}}$ increases
    to $28.53$ from $-26.68$, difference $=55.20,CI_{95\%}=[52.55,58.00],p<.001$,
    and the wisdom of crowds effect $\overline{\Delta\varepsilon}$ changes to $-21.59$
    from $7.27$, difference $=28.86,CI_{95\%}=[-41.52,-18.44],p<.001$. However, in
    the test set (questions $1\leq q\leq 4$), there is an increase in extreme values
    ($\textit{Ext.\%}=29.94\%$), indicating a risk of overfitting. For example, the
    fine-tuned LLM agents tend to provide a negative estimate (up to $84.52\%$) for
    unemployment rate estimation ($q=3$), which is not valid and deemed as extreme
    values, presumably because there is a similarly worded question about the change
    in unemployment rate where many humans provide negative estimates ($46.90\%$ of
    responses). Nonetheless, after filtering out extreme responses, the fine-tuned
    models continue to show strong human-like behavior, with an enhanced $HLI$ of
    $31.97$ (increased from $0.11$ before tuning), and $\overline{\beta_{\text{PB}}}=-14.1$
    (increased from $2.31$, difference$=16.42,CI_{95\%}=[-22.10,-10.17],p<.001$) and
    $\overline{\Delta\varepsilon}=-14.1$ (changed from $2.31$, difference$=15.67,CI_{95\%}=[11.37,20.47],p<.001$).
    These findings suggest that fine-tuning can greatly enhance the human-like qualities
    of LLM agents, and even generalize well to unseen question if proper application
    of filtering criteria is applied.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如表格[2](https://arxiv.org/html/2311.09665v2#S3.T2 "表格 2 ‣ 3.2 微调对增强类人动态的影响 ‣
    3 结果与讨论 ‣ 党派人群的智慧：比较人类与基于LLM的代理的集体智慧")和图表[3](https://arxiv.org/html/2311.09665v2#S3.F3
    "图 3 ‣ 3 结果与讨论 ‣ 党派人群的智慧：比较人类与基于LLM的代理的集体智慧")所示，在训练集（问题 $5\leq q\leq 8$）中，类人指数（$HLI$）从微调前的
    $-33.95$ 提升至 $50.11$，党派偏差 $\overline{\beta_{\text{PB}}}$ 从 $-26.68$ 增加至 $28.53$，差异
    = 55.20，置信区间 $CI_{95\%}=[52.55,58.00]$，$p<.001$，集体智慧效应 $\overline{\Delta\varepsilon}$
    从 $7.27$ 变化为 $-21.59$，差异 = 28.86，置信区间 $CI_{95\%}=[-41.52,-18.44]$，$p<.001$。然而，在测试集（问题
    $1\leq q\leq 4$）中，极值增加（$\textit{Ext.\%}=29.94\%$），这表明存在过拟合的风险。例如，经过微调的LLM代理倾向于对失业率估算（$q=3$）给出负估计（最高可达
    $84.52\%$），这种估计被认为无效并被视为极值，推测是因为存在一个关于失业率变化的相似措辞问题，其中许多人类给出了负面的估计（$46.90\%$ 的回答）。尽管如此，经过筛选极值响应后，微调模型仍然显示出强烈的类人行为，$HLI$
    增强至 $31.97$（从微调前的 $0.11$ 增加），而 $\overline{\beta_{\text{PB}}}=-14.1$（从 $2.31$ 增加，差异
    = 16.42，置信区间 $CI_{95\%}=[-22.10,-10.17]$，$p<.001$）和 $\overline{\Delta\varepsilon}=-14.1$（从
    $2.31$ 变化，差异 = 15.67，置信区间 $CI_{95\%}=[11.37,20.47]$，$p<.001$）。这些发现表明，微调可以大大增强LLM代理的类人特质，并且如果正确应用筛选标准，甚至能够很好地推广到未见过的问题。
- en: 'Table 2: Evaluation of fine-tuned LLM alignment with human group dynamics on
    the train set ($5\leq q\leq 8$) and the test set ($1\leq q\leq 4]$). The boldface
    highlights the consequences of fine-tuning.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：评估微调后的LLM与人类群体动态的对齐情况，在训练集（$5\leq q\leq 8$）和测试集（$1\leq q\leq 4$）中的表现。粗体部分突出显示了微调的结果。
- en: '| Method | $HLI\uparrow$ | $\overline{\Delta\varepsilon}\downarrow$ | $\overline{\beta_{\text{PB}}}\uparrow$
    | Ext.% |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | $HLI\uparrow$ | $\overline{\Delta\varepsilon}\downarrow$ | $\overline{\beta_{\text{PB}}}\uparrow$
    | Ext.% |'
- en: '| Before Fine-tuning |  |  |  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 微调前 |  |  |  |'
- en: '|    Train | -33.95 ± 1.58 | 7.27 ± 1.18 | -26.68 ± 1.04 | 0.00 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|    训练 | -33.95 ± 1.58 | 7.27 ± 1.18 | -26.68 ± 1.04 | 0.00 |'
- en: '|    Test | -0.11 ± 0.75 | 2.31 ± 0.73 | 2.2 ± 0.14 | 0.00 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|    测试 | -0.11 ± 0.75 | 2.31 ± 0.73 | 2.2 ± 0.14 | 0.00 |'
- en: '| After Fine-tuning |  |  |  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 微调后 |  |  |  |'
- en: '|    Train | 50.11 ± 6.18 | -21.59 ± 6.12 | 28.53 ± 0.89 | 0.09 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|    训练 | 50.11 ± 6.18 | -21.59 ± 6.12 | 28.53 ± 0.89 | 0.09 |'
- en: '|    Test | 31.97 ± 3.77 | -14.1 ± 3.02 | 17.87 ± 2.26 | 29.94 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|    测试 | 31.97 ± 3.77 | -14.1 ± 3.02 | 17.87 ± 2.26 | 29.94 |'
- en: '| Human |  |  |  |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 人类 |  |  |  |  |'
- en: '|    Train | 97.95 ± 13.02 | -54.15 ± 12.97 | 43.8 ± 1.20 | 8.11 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|    训练 | 97.95 ± 13.02 | -54.15 ± 12.97 | 43.8 ± 1.20 | 8.11 |'
- en: '|    Test | 29.83 ± 2.21 | -12.16 ± 2.07 | 17.67 ± 0.78 | 8.64 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|    测试 | 29.83 ± 2.21 | -12.16 ± 2.07 | 17.67 ± 0.78 | 8.64 |'
- en: '![Refer to caption](img/2777ca3770bab2d7da2b663d64dfa8cf.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/2777ca3770bab2d7da2b663d64dfa8cf.png)'
- en: 'Figure 4: Mechanism of why the WOC effect emerges from crowds of Human crowds
    and LLM agents. Panel (a) and (b) shows the examples where both humans and LLM
    agents show the WOC effect through social interaction (i.e., the question-specific
    WOC effect $\Delta\varepsilon_{q}<0$). In contrast, in panel (c), LLM agents do
    not converge towards the ground truth while humans do. In each panel, the line
    plot shows the normalized group mean $\eta_{p,t}$ trajectory over three rounds,
    averaged across 12 runs (red for Republicans, blue for Democrats), with error
    bars indicating standard errors. The $r$ in each panel demonstrate the revision
    coefficient - the correlation $r_{\text{adj}}$ between the adjusted initial individual
    error $\widetilde{e}_{i,p,r,q}$ and adjusted estimate revisions $\widetilde{\Delta
    x}_{i,p,r,q}$ ([2.4](https://arxiv.org/html/2311.09665v2#S2.SS4 "2.4 Evaluation
    Metrics ‣ 2 Methods ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence
    in Humans and LLM-based Agents")). Similar to human crowds, the LLM agents show
    the WOC effect only when $r_{\text{adj}}>0$. The results of the full set of questions
    are shown in Figure [5](https://arxiv.org/html/2311.09665v2#A1.F5 "Figure 5 ‣
    Appendix A Results of Revision Coefficient ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents") ([A](https://arxiv.org/html/2311.09665v2#A1
    "Appendix A Results of Revision Coefficient ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents")). ${}^{*}$: $p<.01$ (Bonferroni
    corrected for all questions); ${}^{\textit{ns}}$: not significant.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '图4：为什么群体和大型语言模型（LLM）代理的群体智慧效应（WOC效应）会出现的机制。面板（a）和（b）展示了在人类和LLM代理通过社交互动（即，特定问题的WOC效应$\Delta\varepsilon_{q}<0$）下，二者都展示了WOC效应的例子。相比之下，在面板（c）中，LLM代理并未朝向真实答案收敛，而人类则有此表现。在每个面板中，线形图展示了经过标准化的群体均值$\eta_{p,t}$在三轮中的变化轨迹，平均值基于12次实验（红色代表共和党，蓝色代表民主党），误差条表示标准误差。每个面板中的$r$展示了修正系数——调整后的初始个体误差$\widetilde{e}_{i,p,r,q}$与调整后的估计修正$\widetilde{\Delta
    x}_{i,p,r,q}$之间的相关性$r_{\text{adj}}$（[2.4](https://arxiv.org/html/2311.09665v2#S2.SS4
    "2.4 评估指标 ‣ 2 方法 ‣ 党派群体的智慧：比较人类与基于LLM的代理的集体智慧")）。与人类群体类似，LLM代理仅当$r_{\text{adj}}>0$时才展示WOC效应。所有问题的结果展示在图[5](https://arxiv.org/html/2311.09665v2#A1.F5
    "图5 ‣ 附录A 修正系数的结果 ‣ 党派群体的智慧：比较人类与基于LLM的代理的集体智慧")（[A](https://arxiv.org/html/2311.09665v2#A1
    "附录A 修正系数的结果 ‣ 党派群体的智慧：比较人类与基于LLM的代理的集体智慧")）。${}^{*}$: $p<.01$（针对所有问题的Bonferroni校正）；${}^{\textit{ns}}$:
    无显著性。'
- en: 3.3 Mechanism of the Wisdom of Crowds Effect
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 群体智慧效应的机制
- en: 'In human group dynamics, the wisdom of crowds (WOC) effect arises when individuals
    with initially accurate estimates are less influenced by others, as indicated
    by a positive revision correlation coefficient (Becker et al., [2017](https://arxiv.org/html/2311.09665v2#bib.bib1)).
    This mechanism is distinct from situations where error reduction is uniform across
    the group. Our analysis, detailed in Figure [4](https://arxiv.org/html/2311.09665v2#S3.F4
    "Figure 4 ‣ 3.2 Impact of Fine-Tuning on Enhancing Human-Like Dynamics ‣ 3 Results
    and Discussion ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence
    in Humans and LLM-based Agents") and [5](https://arxiv.org/html/2311.09665v2#A1.F5
    "Figure 5 ‣ Appendix A Results of Revision Coefficient ‣ The Wisdom of Partisan
    Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents") reveals
    that LLM agents exhibit a similar pattern: the WOC effect occurs ($\Delta\varepsilon_{q}<0,ps<.001$⁷⁷7Bonferroni
    corrected for both the p values for both $\Delta\varepsilon_{q}<0$ and $r_{adj}>0$)
    only when the revision coefficient is significantly positive ($r_{adj}>0$, $ps<.001$).
    In contrast, when the revision coefficient is not positive, the WOC effect never
    emerges. In sum, LLM agents’ WOC effect emerges through the same mechanism as
    human crowds, where those with more precise initial estimates exert greater influence
    on the group’s final consensus.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '在人类群体动力学中，群体智慧（WOC）效应出现在那些最初估计准确的个体较少受到他人影响的情况，这一点通过正向修正相关系数来体现（Becker 等，[2017](https://arxiv.org/html/2311.09665v2#bib.bib1)）。这一机制不同于群体内错误减少均匀分布的情形。我们的分析（详见图[4](https://arxiv.org/html/2311.09665v2#S3.F4
    "Figure 4 ‣ 3.2 Impact of Fine-Tuning on Enhancing Human-Like Dynamics ‣ 3 Results
    and Discussion ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence
    in Humans and LLM-based Agents") 和 [5](https://arxiv.org/html/2311.09665v2#A1.F5
    "Figure 5 ‣ Appendix A Results of Revision Coefficient ‣ The Wisdom of Partisan
    Crowds: Comparing Collective Intelligence in Humans and LLM-based Agents")）表明，LLM代理表现出相似的模式：当修正系数显著为正（$r_{adj}>0$，$ps<.001$）时，WOC效应才会出现（$\Delta\varepsilon_{q}<0,
    ps<.001$⁷⁷7经过Bonferroni校正后，对于$\Delta\varepsilon_{q}<0$和$r_{adj}>0$的p值）。相反，当修正系数不是正值时，WOC效应永远不会出现。总之，LLM代理的WOC效应通过与人类群体相同的机制出现，其中最初估计更精确的个体对群体最终共识产生更大的影响。'
- en: 4 Related Work
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 相关工作
- en: Simulating Human-like Group Dynamics with LLM-based Agents
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用基于LLM的代理模拟类人群体动力学
- en: 'Research in applying LLM-based agents for social simulation is expanding (Park
    et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib18); [2022](https://arxiv.org/html/2311.09665v2#bib.bib17);
    Kaiya et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib12); Törnberg
    et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib20); Li et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib14)).
    However, these behaviors are not evaluated against actual human data and thus
    how human-like they are remains unclear. Similarly, Törnberg et al. ([2023](https://arxiv.org/html/2311.09665v2#bib.bib20))
    simulate social media platforms using LLMs and agent-based modeling to evaluate
    the effect of different news feed algorithms, yet the comparison with human interactions
    is also absent. Park et al. ([2022](https://arxiv.org/html/2311.09665v2#bib.bib17))
    demonstrates that LLM-driven agents can produce human-like posts on platforms
    like Reddit that. However, their work doesn’t test the agents’ ability to represent
    demographic-specific behaviors such as political leanings. This highlights a critical
    gap in the field: evaluate the human likeness of demographic-based LLM agents
    in social interaction setting.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的代理在社交模拟中的应用研究正在扩展（Park 等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib18);
    [2022](https://arxiv.org/html/2311.09665v2#bib.bib17); Kaiya 等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib12);
    Törnberg 等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib20); Li 等，[2023](https://arxiv.org/html/2311.09665v2#bib.bib14)
    )。然而，这些行为尚未与实际的人类数据进行评估，因此它们与人类行为的相似程度仍不明确。同样，Törnberg 等人（[2023](https://arxiv.org/html/2311.09665v2#bib.bib20)）使用LLM和基于代理的建模来模拟社交媒体平台，评估不同新闻推送算法的效果，但也没有与人类互动进行对比。Park
    等人（[2022](https://arxiv.org/html/2311.09665v2#bib.bib17)）展示了LLM驱动的代理能够在Reddit等平台上发布类人内容。然而，他们的研究并未测试这些代理是否能代表特定人群的行为，如政治倾向。这突出表明该领域的一个关键空白：评估基于人口特征的LLM代理在社交互动中的类人程度。
- en: Wisdom of Crowds Through Social Interaction
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过社交互动实现群体智慧
- en: 'Research on the wisdom of crowds (WOC) effect has consistently shown that social
    interaction can refine group estimations in human crowds Becker et al. ([2017](https://arxiv.org/html/2311.09665v2#bib.bib1))
    demonstrate that collective accuracy increases with information exchange in decentralized
    networks, and Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2))
    show that it also manifests in politically homogeneous crowds. In addition, they
    identify the mechanism for why WOC emerges through social interaction: individuals
    with larger initial errors adjust their estimates more, contributing to group
    wisdom. In addition, the effect is robust across cultures (Jayles et al., [2017](https://arxiv.org/html/2311.09665v2#bib.bib11)).
    It has also been applied to real-world application settings, such as clinical
    decision-making (Centola et al., [2023](https://arxiv.org/html/2311.09665v2#bib.bib4))
    and science communication (Guilbeault et al., [2018](https://arxiv.org/html/2311.09665v2#bib.bib10)).
    These studies validate the use of social information to improve collective intelligence
    as a robust benchmark to evaluate human-like behaviors in social interaction context.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对群体智慧效应（WOC）的研究一贯表明，社会互动能够优化人类群体的集体估计。Becker等人（[2017](https://arxiv.org/html/2311.09665v2#bib.bib1)）证明，在去中心化网络中，信息交换能够提高集体准确性，Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）则表明，这种效应也会出现在政治上同质化的群体中。此外，他们还找到了WOC通过社会互动产生的机制：初始错误较大的个体会更多地调整自己的估计，从而促成集体智慧的形成。此外，这一效应在不同文化中都具有稳健性（Jayles等人，[2017](https://arxiv.org/html/2311.09665v2#bib.bib11)）。这一效应还被应用于现实世界的场景，例如临床决策（Centola等人，[2023](https://arxiv.org/html/2311.09665v2#bib.bib4)）和科学传播（Guilbeault等人，[2018](https://arxiv.org/html/2311.09665v2#bib.bib10)）。这些研究验证了在集体智能中使用社会信息作为一种稳健的基准，以评估人类社交互动中的类人行为。
- en: 5 Conclusion
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: Our study utalize Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2))’s
    experimental design to evaluate Large Language Models (LLMs)-based agents in a
    simulated environment. The findings shed light on their potential in emulating
    human group dynamics. We discover that LLM agents, when role-playing detailed
    personas, demonstrate a wisdom of partisan crowds effect, mirroring the error
    reduction seen in human groups. However, incorporating CoT reasoning or a lack
    of detailed persona tends to diminish this effect. Additionally, the level of
    detail in agents’ personas significantly influences their display of human-like
    partisan biases. The fine-tuning of LLMs with human data further enhances their
    ability to replicate human-like group dynamics to unseen questions. This study
    highlights the potential of LLM-based agents in producing human-like group dynamics
    when grounded with empirical human data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究利用Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）的实验设计，在模拟环境中评估基于大型语言模型（LLM）的智能体。研究结果揭示了它们在模拟人类群体动态方面的潜力。我们发现，当LLM智能体扮演详细的角色时，展现出“党派人群效应”的智慧，类似于人类群体中减少错误的现象。然而，结合连贯推理（CoT）或缺乏详细角色设定，往往会削弱这一效应。此外，智能体角色的细节程度显著影响其展现人类党派偏见的方式。通过使用人类数据对LLM进行微调，进一步增强了它们在应对未见问题时复制人类群体动态的能力。本研究强调了基于LLM的智能体在通过经验性人类数据支撑时，能够产生类人群体动态的潜力。
- en: Despite the artificial experimental setting (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)),
    our study point to a promising direction in using established behavioral phenomena
    of human participants to evaluate and shape LLMs for simulating human social communication
    dynamics. Looking forward, we envision that, by incorporating human social interaction
    data into LLM agent development, future studies can develop human-emulating LLM
    agents for broader social simulations that have been traditionally tackled with
    agent-based models (Lorenz et al., [2021](https://arxiv.org/html/2311.09665v2#bib.bib15);
    Flache et al., [2017](https://arxiv.org/html/2311.09665v2#bib.bib9); Chuang &
    Rogers, [2023](https://arxiv.org/html/2311.09665v2#bib.bib6)).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在人工实验设置（Becker等人，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)），我们的研究指向了一个有前景的方向，即利用人类参与者的已知行为现象来评估和塑造LLM，以模拟人类社会交流动态。展望未来，我们设想，通过将人类社会互动数据融入LLM智能体的开发中，未来的研究可以开发出能够模拟人类行为的LLM智能体，用于更广泛的社会模拟，这些模拟通常使用基于智能体的模型来解决（Lorenz等人，[2021](https://arxiv.org/html/2311.09665v2#bib.bib15)；Flache等人，[2017](https://arxiv.org/html/2311.09665v2#bib.bib9)；Chuang
    & Rogers，[2023](https://arxiv.org/html/2311.09665v2#bib.bib6)）。
- en: References
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Becker et al. (2017) Joshua Becker, Devon Brackbill, and Damon Centola. Network
    dynamics of social influence in the wisdom of crowds. *Proceedings of the National
    Academy of Sciences of the United States of America*, 114(26):E5070, 2017.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Becker 等 (2017) Joshua Becker, Devon Brackbill 和 Damon Centola. 群体智慧中的社会影响网络动态。*美国国家科学院院刊*，114(26):E5070,
    2017。
- en: Becker et al. (2019) Joshua Becker, Ethan Porter, and Damon Centola. The wisdom
    of partisan crowds. *Proceedings of the National Academy of Sciences of the United
    States of America*, 116(22):10717–10722, 2019.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Becker 等 (2019) Joshua Becker, Ethan Porter 和 Damon Centola. 党派群体的智慧。*美国国家科学院院刊*，116(22):10717–10722,
    2019年。
- en: Binz & Schulz (2023) Marcel Binz and Eric Schulz. Turning large language models
    into cognitive models. *arXiv preprint arXiv:2306.03917*, 2023.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Binz & Schulz (2023) Marcel Binz 和 Eric Schulz. 将大型语言模型转化为认知模型。*arXiv 预印本 arXiv:2306.03917*，2023年。
- en: Centola et al. (2023) Damon Centola, Joshua Becker, Jingwen Zhang, Jaya Aysola,
    Douglas Guilbeault, and Elaine Khoong. Experimental evidence for structured information–sharing
    networks reducing medical errors. *Proceedings of the National Academy of Sciences*,
    120(31):e2108290120, 2023.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Centola 等 (2023) Damon Centola, Joshua Becker, Jingwen Zhang, Jaya Aysola, Douglas
    Guilbeault 和 Elaine Khoong. 实验证据表明结构化信息共享网络可以减少医疗错误。*美国国家科学院院刊*，120(31):e2108290120，2023年。
- en: Chase (2022) Harrison Chase. Langchain, 10 2022. URL [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chase (2022) Harrison Chase. Langchain, 2022年10月。网址 [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)。
- en: 'Chuang & Rogers (2023) Yun-Shiuan Chuang and Timothy T Rogers. Computational
    agent-based models in opinion dynamics: A survey on social simulations and empirical
    studies. *arXiv preprint arXiv:2306.03446*, 2023.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang & Rogers (2023) Yun-Shiuan Chuang 和 Timothy T Rogers. 基于计算代理的意见动态模型：关于社会模拟与实证研究的综述。*arXiv
    预印本 arXiv:2306.03446*，2023年。
- en: Chuang et al. (2023) Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth
    Suresh, Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu, and Timothy T Rogers.
    Simulating opinion dynamics with networks of llm-based agents. *arXiv preprint
    arXiv:2311.09618*, 2023.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang 等 (2023) Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka, Siddharth Suresh,
    Robert Hawkins, Sijia Yang, Dhavan Shah, Junjie Hu 和 Timothy T Rogers. 使用基于大型语言模型（LLM）代理的网络模拟意见动态。*arXiv
    预印本 arXiv:2311.09618*，2023年。
- en: 'Efron (1992) Bradley Efron. Bootstrap methods: another look at the jackknife.
    In *Breakthroughs in statistics: Methodology and distribution*, pp.  569–593\.
    Springer, 1992.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Efron (1992) Bradley Efron. 自助法：另一种对jackknife方法的考察。收录于 *统计学突破：方法学与分布*，第569–593页，Springer，1992年。
- en: 'Flache et al. (2017) Andreas Flache, Michael Mäs, Thomas Feliciani, Edmund
    Chattoe-Brown, Guillaume Deffuant, Sylvie Huet, and Jan Lorenz. Models of social
    influence: Towards the next frontiers. *Journal of Artificial Societies and Social
    Simulation*, 20(4), 2017.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flache 等 (2017) Andreas Flache, Michael Mäs, Thomas Feliciani, Edmund Chattoe-Brown,
    Guillaume Deffuant, Sylvie Huet 和 Jan Lorenz. 社会影响模型：走向下一个前沿。*人工社会与社会模拟期刊*，20(4)，2017年。
- en: Guilbeault et al. (2018) Douglas Guilbeault, Joshua Becker, and Damon Centola.
    Social learning and partisan bias in the interpretation of climate trends. *Proceedings
    of the National Academy of Sciences*, 115(39):9714–9719, 2018.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guilbeault 等 (2018) Douglas Guilbeault, Joshua Becker 和 Damon Centola. 社会学习与党派偏见对气候趋势解读的影响。*美国国家科学院院刊*，115(39):9714–9719,
    2018。
- en: Jayles et al. (2017) Bertrand Jayles, Hye-rin Kim, Ramón Escobedo, Stéphane
    Cezera, Adrien Blanchet, Tatsuya Kameda, Clément Sire, and Guy Theraulaz. How
    social information can improve estimation accuracy in human groups. *Proceedings
    of the National Academy of Sciences*, 114(47):12620–12625, 2017.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jayles 等 (2017) Bertrand Jayles, Hye-rin Kim, Ramón Escobedo, Stéphane Cezera,
    Adrien Blanchet, Tatsuya Kameda, Clément Sire 和 Guy Theraulaz. 社会信息如何改善人类群体中的估计准确性。*美国国家科学院院刊*，114(47):12620–12625,
    2017。
- en: 'Kaiya et al. (2023) Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes,
    Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, and Andrew Ahn. Lyfe agents: Generative
    agents for low-cost real-time social interactions. *arXiv preprint arXiv:2310.02172*,
    2023.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaiya 等 (2023) Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes,
    Jiaxin Ge, Shuying Luo, Guangyu Robert Yang 和 Andrew Ahn. Lyfe代理：用于低成本实时社交互动的生成代理。*arXiv
    预印本 arXiv:2310.02172*，2023年。
- en: Kameda et al. (2022) Tatsuya Kameda, Wataru Toyokawa, and R Scott Tindale. Information
    aggregation and collective intelligence beyond the wisdom of crowds. *Nature Reviews
    Psychology*, 1(6):345–357, 2022.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kameda 等 (2022) Tatsuya Kameda, Wataru Toyokawa 和 R Scott Tindale. 信息汇总与集体智慧超越群体智慧。*自然评论心理学*，1(6):345–357,
    2022年。
- en: Li et al. (2023) Chao Li, Xing Su, Chao Fan, Haoying Han, Cong Xue, and Chunmo
    Zheng. Quantifying the impact of large language models on collective opinion dynamics.
    *arXiv preprint arXiv:2308.03313*, 2023.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李等人（2023）超·李，星·苏，超·范，昊颖·韩，聪·薛，春默·郑。量化大型语言模型对集体意见动态的影响。*arXiv预印本arXiv:2308.03313*，2023年。
- en: 'Lorenz et al. (2021) Jan Lorenz, Martin Neumann, and Tobias Schröder. Individual
    attitude change and societal dynamics: Computational experiments with psychological
    theories. *Psychological Review*, 128(4):623, 2021.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 洛伦茨等人（2021）简·洛伦茨，马丁·诺伊曼，托比亚斯·施罗德。个体态度变化与社会动态：基于心理学理论的计算实验。*心理学评论*，128(4):623，2021年。
- en: OpenAI (2022) OpenAI. Introducing ChatGPT. [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt),
    2022. [Accessed 13-10-2023].
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2022）OpenAI。介绍ChatGPT。[https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)，2022年。[访问日期：2023年10月13日]。
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. Social simulacra: Creating populated
    prototypes for social computing systems. In *Proceedings of the 35th Annual ACM
    Symposium on User Interface Software and Technology*, pp.  1–18, 2022.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人（2022）俊昇·朴，林赛·波波夫斯基，凯莉·蔡，梅雷迪思·林戈尔·莫里斯，珀西·梁，迈克尔·S·伯恩斯坦。社交模拟：为社交计算系统创建人口原型。在*第35届ACM用户界面软件与技术年会论文集*，第1-18页，2022年。
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. In *Proceedings of the 36th Annual ACM Symposium on User Interface
    Software and Technology*, pp.  1–22, 2023.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人（2023）俊昇·朴，约瑟夫·奥布莱恩，凯莉·君·蔡，梅雷迪思·林戈尔·莫里斯，珀西·梁，迈克尔·S·伯恩斯坦。生成代理：人类行为的互动模拟。在*第36届ACM用户界面软件与技术年会论文集*，第1-22页，2023年。
- en: Shaikh et al. (2022) Omar Shaikh, Hongxin Zhang, William Held, Michael Bernstein,
    and Diyi Yang. On second thought, let’s not think step by step! bias and toxicity
    in zero-shot reasoning. *arXiv preprint arXiv:2212.08061*, 2022.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沙伊赫等人（2022）奥马尔·沙伊赫，洪鑫·张，威廉·赫尔德，迈克尔·伯恩斯坦，狄伊·杨。再三思考，还是不要一步一步思考！零-shot推理中的偏见和毒性。*arXiv预印本arXiv:2212.08061*，2022年。
- en: Törnberg et al. (2023) Petter Törnberg, Diliara Valeeva, Justus Uitermark, and
    Christopher Bail. Simulating social media using large language models to evaluate
    alternative news feed algorithms. *arXiv preprint arXiv:2310.05984*, 2023.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 托恩伯格等人（2023）佩特·托恩伯格，迪利阿拉·瓦莱娃，贾斯图斯·乌特马克，克里斯托弗·贝尔。使用大型语言模型模拟社交媒体，评估替代新闻推送算法。*arXiv预印本arXiv:2310.05984*，2023年。
- en: Wei et al. (2022a) Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret
    Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,
    Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William
    Fedus. Emergent abilities of large language models. *Transactions on Machine Learning
    Research*, 2022a. ISSN 2835-8856. URL [https://openreview.net/forum?id=yzkSU5zdwD](https://openreview.net/forum?id=yzkSU5zdwD).
    Survey Certification.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等人（2022a）杰森·魏，易·泰，瑞希·博马萨尼，科林·拉费尔，巴雷特·佐夫，塞巴斯蒂安·博尔乔，丹尼·尤加塔玛，马尔滕·博斯玛，邓尼·周，唐纳德·梅茨勒，艾德·H·池，田统·桥本，奥里奥尔·维尼亚尔斯，珀西·梁，杰夫·迪恩，威廉·费杜斯。大型语言模型的涌现能力。*机器学习研究学报*，2022a年。ISSN
    2835-8856。网址[https://openreview.net/forum?id=yzkSU5zdwD](https://openreview.net/forum?id=yzkSU5zdwD)。调查认证。
- en: Wei et al. (2022b) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed H Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. In *Advances in Neural Information Processing
    Systems*, 2022b.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等人（2022b）杰森·魏，薛志·王，戴尔·舒尔曼，马尔滕·博斯玛，费伊·夏，艾德·H·池，阔·V·黎，邓尼·周，等人。链式思维提示引发大型语言模型的推理。在*神经信息处理系统进展*，2022b年。
- en: Yi et al. (2012) Sheng Kung Michael Yi, Mark Steyvers, Michael D Lee, and Matthew J
    Dry. The wisdom of the crowd in combinatorial problems. *Cognitive science*, 36(3):452–470,
    2012.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易等人（2012）圣·孔·迈克尔·易，马克·斯泰弗斯，迈克尔·D·李，马修·J·德赖。组合问题中的群体智慧。*认知科学*，36(3):452–470，2012年。
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al.
    Judging llm-as-a-judge with mt-bench and chatbot arena. *arXiv preprint arXiv:2306.05685*,
    2023.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郑等人（2023）廉敏·郑，魏林·姜，英·盛，思远·庄，张昊·吴，永浩·庄，子林·朱，浩然·李，大成·李，埃里克·邢，等人。使用mt-bench和chatbot
    arena评判llm-as-a-judge。*arXiv预印本arXiv:2306.05685*，2023年。
- en: Appendix A Results of Revision Coefficient
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 修订系数的结果
- en: '![Refer to caption](img/02faf8008e4a8fc559349e6e8a405444.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/02faf8008e4a8fc559349e6e8a405444.png)'
- en: 'Figure 5: Analysis of the mechanism of LLM agents’ wisdom of crowds (WOC) effect
    at the individual level. Panel (a) shows the questions where LLM agents exhibit
    the WOC effect ($\Delta\varepsilon_{q}<0)$. Panel (b) shows the questions where
    LLM agents do not show the WOC effect. Within each panel, the questions are ordered
    by their revision correlation $r_{\text{adj}}$. In each panel, the line plot shows
    the normalized group mean $\eta_{p,t}$ trajectory over three rounds, averaged
    across 12 runs (red for Republicans, blue for Democrats), with error bars indicating
    standard errors. The in each panel demonstrate the revision coefficient, the correlation
    $r_{\text{adj}}$ between the adjusted initial individual error $\widetilde{e}_{i,p,r,q}$
    and adjusted estimate revisions $\widetilde{\Delta x}_{i,p,r,q}$ ([2.4](https://arxiv.org/html/2311.09665v2#S2.SS4
    "2.4 Evaluation Metrics ‣ 2 Methods ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents")). The LLM agents show
    the WOC effect only when $r_{\text{adj}}>0$ (panel a). ${}^{*}$: $p<.01$ (Bonferroni
    corrected for all questions); ${}^{\textit{ns}}$: not significant.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：分析LLM代理在个体层面上展现的群体智慧效应（WOC）机制。面板（a）显示LLM代理表现出WOC效应的问题（$\Delta\varepsilon_{q}<0$）。面板（b）显示LLM代理没有表现出WOC效应的问题。在每个面板中，问题按修正相关性$r_{\text{adj}}$排序。在每个面板中，折线图展示了标准化的群体均值$\eta_{p,t}$在三轮中的轨迹，平均值来自12次实验（红色为共和党，蓝色为民主党），误差条表示标准误差。每个面板中的图示展示了修正系数，调整后的初始个体误差$\widetilde{e}_{i,p,r,q}$与调整后的估计修正$\widetilde{\Delta
    x}_{i,p,r,q}$之间的相关性$r_{\text{adj}}$（[2.4](https://arxiv.org/html/2311.09665v2#S2.SS4
    "2.4 评估指标 ‣ 2 方法 ‣ 党派群体智慧：比较人类与基于LLM的代理的集体智能")）。LLM代理只有在$r_{\text{adj}}>0$时才表现出WOC效应（面板a）。${}^{*}$：$p<.01$（针对所有问题的Bonferroni校正）；${}^{\textit{ns}}$：无显著性。
- en: 'Figure [5](https://arxiv.org/html/2311.09665v2#A1.F5 "Figure 5 ‣ Appendix A
    Results of Revision Coefficient ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents") detailed in the analysis of revision
    coefficients. Specifically, the wisdom of crowds effect emerges only when the
    revision coefficient is positive, mirroring human behavior. Like human crowds,
    LLM agents enhanced collective accuracy when individuals with initially more accurate
    estimates are less influenced by peer opinions, thereby steering the group toward
    more accurate collective estimates.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图[5](https://arxiv.org/html/2311.09665v2#A1.F5 "图 5 ‣ 附录 A 修正系数结果 ‣ 党派群体智慧：比较人类与基于LLM的代理的集体智能")详细描述了修正系数的分析。具体来说，群体智慧效应只有在修正系数为正时才会出现，反映了人类行为的相似性。像人类群体一样，当初步估计更为准确的个体不太受同侪意见的影响时，LLM代理能够增强集体的准确性，从而引导群体朝向更为准确的集体估计。
- en: Appendix B Vicuna Results
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B Vicuna 结果
- en: '![Refer to caption](img/09d435bf11b18cb601778fa43543cd2a.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/09d435bf11b18cb601778fa43543cd2a.png)'
- en: 'Figure 6: Trajectories of normalized group mean $\eta_{p,t}$ over three rounds,
    averaged across 12 group experiments (red for Republicans, blue for Democrats),
    with error bars for standard errors. Each panel consists of two columns representing
    different data sets: Column 1 shows human data. Columns 2 shows LLM (Vicuna) agents’
    data. We separate questions into two panels to facilitate comparison with Figure [3](https://arxiv.org/html/2311.09665v2#S3.F3
    "Figure 3 ‣ 3 Results and Discussion ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents"), where panel (a) includes
    questions $5\leq q\leq 8$, and (b) displays questions $1\leq q\leq 4$. Question-specific
    WOC effects ($\Delta\varepsilon_{q}$) and partisan biases ($\beta_{\text{PB}_{q}}$,
    if expected) are overlaid for comparison.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：标准化群体均值$\eta_{p,t}$在三轮中的轨迹，平均值来自12次小组实验（红色为共和党，蓝色为民主党），误差条表示标准误差。每个面板由两列数据组成，分别表示不同的数据集：第1列显示人类数据，第2列显示LLM（Vicuna）代理的数据。我们将问题分为两个面板，以便与图[3](https://arxiv.org/html/2311.09665v2#S3.F3
    "图 3 ‣ 结果与讨论 ‣ 党派群体智慧：比较人类与基于LLM的代理的集体智能")进行比较，其中面板（a）包含问题$5\leq q\leq 8$，面板（b）展示问题$1\leq
    q\leq 4$。每个问题的WOC效应（$\Delta\varepsilon_{q}$）和党派偏差（$\beta_{\text{PB}_{q}}$，如果预期存在）被重叠显示以便比较。
- en: 'Figure [3](https://arxiv.org/html/2311.09665v2#S3.F3 "Figure 3 ‣ 3 Results
    and Discussion ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence
    in Humans and LLM-based Agents") shows the result for human versus ChatGPT-based
    LLM agents. Here, we shows the results for human versus Vicuna-based LLM agents
    in Figure [6](https://arxiv.org/html/2311.09665v2#A2.F6 "Figure 6 ‣ Appendix B
    Vicuna Results ‣ The Wisdom of Partisan Crowds: Comparing Collective Intelligence
    in Humans and LLM-based Agents"). As shown, Vicuna-based LLM agents show the WOC
    effect ($\overline{\Delta\varepsilon}<0$) for all questions except the question
    $q=6$, $p<.001$ (Bonferroni corrected).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图[3](https://arxiv.org/html/2311.09665v2#S3.F3 "图 3 ‣ 3 结果与讨论 ‣ 党派人群的智慧：比较人类与基于LLM的代理的集体智慧")展示了人类与基于ChatGPT的LLM代理的结果。在这里，我们展示了人类与基于Vicuna的LLM代理的结果，如图[6](https://arxiv.org/html/2311.09665v2#A2.F6
    "图 6 ‣ 附录B Vicuna结果 ‣ 党派人群的智慧：比较人类与基于LLM的代理的集体智慧")所示。如图所示，基于Vicuna的LLM代理在除了问题$q=6$外，所有问题都表现出了WOC效应（$\overline{\Delta\varepsilon}<0$），$p<.001$（经过Bonferroni校正）。
- en: Appendix C List of Personas
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 人物角色列表
- en: C.1 Detailed Persona Condition
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 详细人物角色条件
- en: 'In this section, we list the personas of the agents interacting in our experiment.
    35 personas were used in the experiment for both Democrats and Republicans. For
    brevity purposes, a subset of them is included here. The full set of personas
    will be released along with the codebase at the time of publication. The list
    of personas is generated using this prompt (PARTY is either Republican or Democrat)
    with GPT4 (OpenAI, [2022](https://arxiv.org/html/2311.09665v2#bib.bib16)):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们列出了在实验中与我们互动的代理人物角色。实验中使用了35个民主党和共和党人物角色。为简洁起见，这里仅包含其中的一个子集。完整的人物角色集将在发布时与代码库一起发布。人物角色列表是使用以下提示生成的（PARTY可以是共和党或民主党），并由GPT4（OpenAI,
    [2022](https://arxiv.org/html/2311.09665v2#bib.bib16)）生成：
- en: 'Create detailed descriptions for 35 individuals who identify as PARTY and are
    above the age of 18, with varying degrees of political leaning (from Lean PARTY
    to Strong PARTY). Ensure that their demographics are diverse and reflective of
    the actual distribution of the US population, including factors such as age, gender,
    ethnicity, education level, and occupation. Provide comprehensive background information
    for each person. Use the format below. Name:[] Political leaning: [] Age: [] Gender:
    [] Ethnicity: [] Education: [] Occupation: [] Background: []'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为35个自认为是PARTY且年龄超过18岁的个体创建详细描述，涵盖不同的政治倾向（从倾向PARTY到坚定PARTY）。确保他们的人口统计信息多样化，并且反映美国人口的实际分布，包括年龄、性别、种族、教育程度和职业等因素。为每个人提供全面的背景信息。使用以下格式：姓名：[]
    政治倾向：[] 年龄：[] 性别：[] 种族：[] 教育：[] 职业：[] 背景：[]
- en: Democrats
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 民主党
- en: 'Name: Isabella Johnson Political leaning: Strong Democrat Age: 67 Gender: Female
    Ethnicity: White Education: Bachelor’s Degree in Education Occupation: Retired
    Teacher Background: Isabella is from Portland, Oregon, and spent her career advocating
    for public education and teachers’ rights. She is passionate about social justice,
    healthcare, and environmental issues. Isabella is widowed with two grown children
    and enjoys birdwatching and painting in her free time.Name: Jamal Brown Political
    leaning: Lean Democrat Age: 51 Gender: Male Ethnicity: African American Education:
    Bachelor’s Degree in Finance Occupation: Financial Analyst Background: Jamal grew
    up in Detroit, Michigan, and became politically active during the 2008 recession.
    He supports policies promoting economic fairness and equal opportunities. Jamal
    is divorced with one child and enjoys playing golf and attending jazz concerts.Name:
    Karen Patel Political leaning: Moderate Democrat Age: 34 Gender: Female Ethnicity:
    Indian American Education: Master’s Degree in Computer Science Occupation: Software
    Engineer Background: Karen was born in San Jose, California, and is a strong advocate
    for affordable housing and tech industry regulations. She also supports women’s
    rights and STEM education. Karen is married with two young children and enjoys
    hiking and coding projects in her free time.Name: Larry Jackson Political leaning:
    Strong Democrat Age: 42 Gender: Male Ethnicity: White Education: Bachelor’s Degree
    in Sociology Occupation: Nonprofit Fundraiser Background: Larry hails from Madison,
    Wisconsin, and is deeply involved in local politics. He is passionate about income
    inequality, racial justice, and LGBTQ+ rights. Larry is married with no children
    and enjoys traveling and volunteering for progressive causes.Name: Monica Rodriguez
    Political leaning: Lean Democrat Age: 48 Gender: Female Ethnicity: Puerto Rican
    Education: Associate Degree in Nursing Occupation: Registered Nurse Background:
    Monica grew up in New York City, New York, and supports policies that improve
    healthcare access and quality. She is also concerned about affordable housing
    and education reform. Monica is a single mother of two and enjoys salsa dancing
    and cooking.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 姓名：伊莎贝拉·约翰逊 政治倾向：强烈支持民主党 年龄：67 性别：女性 民族：白人 教育背景：教育学学士 学历 职业：退休教师 背景：伊莎贝拉来自俄勒冈州波特兰市，整个职业生涯致力于倡导公共教育和教师权益。她对社会正义、医疗保健和环境问题充满热情。伊莎贝拉是寡妇，有两个成年的孩子，空闲时喜欢观鸟和绘画。姓名：贾马尔·布朗
    政治倾向：倾向支持民主党 年龄：51 性别：男性 民族：非裔美国人 教育背景：金融学学士 学历 职业：金融分析师 背景：贾马尔在密歇根州底特律长大，并在2008年经济衰退期间开始参与政治。他支持促进经济公平和机会平等的政策。贾马尔离异，有一个孩子，空闲时喜欢打高尔夫和参加爵士乐会。姓名：凯伦·帕特尔
    政治倾向：温和派民主党 年龄：34 性别：女性 民族：印度裔美国人 教育背景：计算机科学硕士 学历 职业：软件工程师 背景：凯伦出生在加利福尼亚州圣荷西市，强烈支持可负担住房和科技行业监管政策。她还支持女性权益和STEM教育。凯伦已婚，育有两个年幼的孩子，空闲时喜欢远足和进行编码项目。姓名：拉里·杰克逊
    政治倾向：强烈支持民主党 年龄：42 性别：男性 民族：白人 教育背景：社会学学士 学历 职业：非营利组织筹款人 背景：拉里来自威斯康星州麦迪逊市，积极参与当地政治。他热衷于收入不平等、种族正义和LGBTQ+权益。拉里已婚，无子女，空闲时喜欢旅行和为进步事业做志愿工作。姓名：莫妮卡·罗德里格斯
    政治倾向：倾向支持民主党 年龄：48 性别：女性 民族：波多黎各人 教育背景：护理学副学士 学历 职业：注册护士 背景：莫妮卡在纽约市长大，支持改善医疗保健的可及性和质量的政策。她还关心可负担住房和教育改革。莫妮卡是两个孩子的单亲母亲，空闲时喜欢萨尔萨舞和烹饪。
- en: Republicans
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 共和党人
- en: 'Name: Charles Matthews Political leaning: Lean Republican Age: 38 Gender: Male
    Ethnicity: African American Education: Bachelor’s degree in Business Administration
    Occupation: Small business owner Background: Charles was born and raised in Atlanta,
    Georgia, where he attended a public university before starting his own business.
    He has a wife and two children. Charles supports limited government intervention
    and lower taxes, and he values entrepreneurship and self-reliance.Name: Alice
    Thompson Political leaning: Moderate Republican Age: 29 Gender: Female Ethnicity:
    Caucasian Education: Master’s degree in Public Health Occupation: Epidemiologist
    Background: Alice grew up in a small town in Ohio before moving to Philadelphia
    for her studies. She is passionate about public health and believes in data-driven
    policies. She leans Republican due to her fiscal conservatism and support for
    individual rights.Name: Juan Rodriguez Political leaning: Strong Republican Age:
    45 Gender: Male Ethnicity: Hispanic Education: High school diploma Occupation:
    Construction worker Background: Juan, originally from Mexico, migrated to Texas
    with his family when he was a child. A father of three, he believes in traditional
    family values, hard work, and limited government. He is a staunch advocate for
    securing the nation’s borders.Name: Sarah Chang Political leaning: Lean Republican
    Age: 23 Gender: Female Ethnicity: Asian American Education: Bachelor’s degree
    in Environmental Science Occupation: Environmental Consultant Background: Sarah
    was born and raised in California. She supports free-market solutions to environmental
    issues and believes in responsible resource management. Sarah leans Republican
    due to her fiscally conservative views and her opposition to excessive government
    regulation.Name: Robert Klein Political leaning: Moderate Republican Age: 64 Gender:
    Male Ethnicity: Caucasian Education: Bachelor’s degree in Engineering Occupation:
    Retired engineer Background: Robert, a native of Pennsylvania, worked for a major
    manufacturing company for over 30 years. He is a Vietnam War veteran and a strong
    supporter of the Second Amendment. Robert believes in fiscal responsibility, limited
    government, and a strong national defense.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 姓名：查尔斯·马修斯 政治倾向：倾向共和党 年龄：38 性别：男 民族：非洲裔美国人 教育：工商管理学士学位 职业：小企业主 背景：查尔斯出生并成长于乔治亚州的亚特兰大，他在一所公立大学学习后开始了自己的生意。他有一个妻子和两个孩子。查尔斯支持有限的政府干预和较低的税收，他重视创业精神和自力更生。姓名：爱丽丝·汤普森
    政治倾向：温和共和党 年龄：29 性别：女 民族：白人 教育：公共卫生硕士学位 职业：流行病学家 背景：爱丽丝在俄亥俄州的一个小镇长大，后来搬到费城继续学业。她热衷于公共卫生，认为政策应基于数据。由于其财政保守主义和支持个人权利，她倾向于共和党。姓名：胡安·罗德里格斯
    政治倾向：强烈共和党 年龄：45 性别：男 民族：西班牙裔 教育：高中毕业 职业：建筑工人 背景：胡安来自墨西哥，在他还是孩子时与家人一起移居到德克萨斯州。他是三个孩子的父亲，坚信传统家庭价值观、辛勤工作和有限政府。他是坚决支持保护国家边界的倡导者。姓名：莎拉·张
    政治倾向：倾向共和党 年龄：23 性别：女 民族：亚裔美国人 教育：环境科学学士学位 职业：环境顾问 背景：莎拉在加利福尼亚州出生并长大。她支持自由市场解决环境问题，认为资源管理应负责任。由于她在财政上的保守观点以及反对过度政府监管，莎拉倾向于共和党。姓名：罗伯特·克莱因
    政治倾向：温和共和党 年龄：64 性别：男 民族：白人 教育：工程学士学位 职业：退休工程师 背景：罗伯特是宾夕法尼亚州人，在一家大型制造公司工作了30多年。他是越战老兵，坚决支持第二修正案。罗伯特相信财政责任、有限政府和强大的国家防御。
- en: C.2 Simple Persona Condition
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 简单角色条件
- en: Democrats
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 民主党人
- en: A typical Democrat in the USA.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 美国典型的民主党人。
- en: Republicans
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 共和党人
- en: A typical Republican in the USA.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 美国典型的共和党人。
- en: Appendix D Full List of Questions
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 问题完整列表
- en: Below is the full list of questions ($q\in[1,8]$) in the experiment, along with
    the ground truth $x^{*}_{q}$ and the sign of human partisan bias direction $\text{sign}(h_{q})$
    observed in human data (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是实验中所有问题（$q\in[1,8]$）的完整列表，包含了每个问题的真实答案 $x^{*}_{q}$ 和在人的数据中观察到的人类偏向方向的符号 $\text{sign}(h_{q})$（见Becker等人，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）。
- en: '1.'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: In the 2004 election, individuals gave $269.8 million to Republican candidate
    George W. Bush. How much did they give to Democratic candidate John Kerry? (Answer
    in millions of dollars—e.g., 1 for $1 million.) [$x_{1}^{*}=224.6$, $\text{sign}(h_{1})=0$]
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在2004年选举中，个人捐赠了2.698亿美元给共和党候选人乔治·W·布什。他们捐赠给民主党候选人约翰·凯瑞多少钱？（答案以百万美元为单位，例如，1表示100万美元。）[$x_{1}^{*}=224.6$，$\text{sign}(h_{1})=0$]
- en: '2.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: According to 2010 estimates, what percentage of people in the state of California
    identify as Black/African-American, Hispanic, or Asian? (Give a number from 0
    to 100.) [$x_{2}^{*}=60.2$, $\text{sign}(h_{2})=0$]
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据2010年的估计，加利福尼亚州有多少百分比的人认同自己是黑人/非洲裔美国人、西班牙裔或亚洲人？（请给出一个从0到100的数字。）[$x_{2}^{*}=60.2$,
    $\text{sign}(h_{2})=0$]
- en: '3.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: What was the US unemployment rate at the end of Barack Obama’s presidential
    administration—i.e., what percentage of people were unemployed in December 2016?
    (Give a number from 0 to 100.) [$x_{3}^{*}=4.9$, $\text{sign}(h_{3})=1$]
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 巴拉克·奥巴马总统任期结束时，美国的失业率是多少——也就是说，2016年12月有多少人处于失业状态？（请给出一个从0到100的数字。）[$x_{3}^{*}=4.9$,
    $\text{sign}(h_{3})=1$]
- en: '4.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: In 1980, tax revenue was 18.5% of the economy (as a proportion of GDP). What
    was tax revenue as a percentage of the economy in 2010? (Give a number from 0
    to 100.) [$x_{4}^{*}:14.6$, $\text{sign}(h_{4})=1$]
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1980年，税收占经济总量（国内生产总值的比例）为18.5%。2010年税收占经济总量的百分比是多少？（请给出一个从0到100的数字。）[$x_{4}^{*}:14.6$,
    $\text{sign}(h_{4})=1$]
- en: '5.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: For every dollar the federal government spent in fiscal year 2016, about how
    much went to the Department of Defense (US Military)? Answer with a number between
    0 and 100\. [$x_{5}^{*}=15$, $\text{sign}(h_{5})=-1$]
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2016财政年度，联邦政府每花费一美元，大约有多少用于国防部（美国军队）？请用一个0到100之间的数字回答。[$x_{5}^{*}=15$, $\text{sign}(h_{5})=-1$]
- en: '6.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: In 2007, it was estimated that 6.9 million unauthorized immigrants from Mexico
    lived in the United States. How much did this number change by 2016, before President
    Trump was elected? Express your answer as a percentage of change. [$x_{6}^{*}=-27.8$,
    $\text{sign}(h_{6})=-1$]
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2007年，估计有690万来自墨西哥的非法移民生活在美国。到2016年，在特朗普总统当选之前，这一数字发生了多少变化？请以变化百分比的形式表达你的答案。[$x_{6}^{*}=-27.8$,
    $\text{sign}(h_{6})=-1$]
- en: '7.'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: How much did the unemployment rate in the United States change from the beginning
    to the end of Democratic President Barack Obama’s term in office? Express your
    answer as a percentage of change. [$x_{7}^{*}=-46$, $\text{sign}(h_{7})=-1$]
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从民主党总统巴拉克·奥巴马上任到任期结束，美国失业率变化了多少？请以变化百分比的形式表达你的答案。[$x_{7}^{*}=-46$, $\text{sign}(h_{7})=-1$]
- en: '8.'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: About how many US soldiers were killed in Iraq between the invasion in 2003
    and the withdrawal of troops in December 2011? [$x_{7}8*=4486$, $\text{sign}(h_{8})=0$]
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从2003年入侵到2011年12月撤军，美国在伊拉克阵亡的士兵大约有多少？[$x_{7}8*=4486$, $\text{sign}(h_{8})=0$]
- en: Appendix E List of Induced Partisanship
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 列出引发的党派偏见
- en: Below is the full list of induced partisanship corresponding to the questions
    in the experiment ($q\in[1,8]$). We did not induce a bias for certain questions
    because (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2))
    found that there is no significant human partisan bias for those questions.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是与实验中的问题（$q\in[1,8]$）对应的引发党派偏见的完整列表。我们没有对某些问题引入偏见，因为（Becker等人，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）发现这些问题没有显著的人类党派偏见。
- en: '1.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Did not induce a bias for this question.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对这个问题没有引入偏见。
- en: '2.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Did not induce a bias for this question.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对这个问题没有引入偏见。
- en: '3.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Republicans tend to estimate a higher unemployment rate than democrats.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人倾向于估计失业率高于民主党人。
- en: (a)
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Democrats: ”You believe that Barack Obama did a good job in reducing the US
    unemployment rate.”'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 民主党人：“你认为巴拉克·奥巴马在降低美国失业率方面做得很好。”
- en: (b)
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Republicans: ”You believe that Barack Obama did a poor job in reducing the
    US unemployment rate.”'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人：“你认为巴拉克·奥巴马在降低美国失业率方面做得很差。”
- en: '4.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Republicans tend to estimate higher tax revenue than democrats.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人倾向于估计税收收入高于民主党人。
- en: (a)
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Democrats: ”You believe that tax rates are not as high as they should be in
    general.”'
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 民主党人：“你认为税率通常没有达到应该有的高水平。”
- en: (b)
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Republicans: ”You believe that tax rates are too high in general.”'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人：“你认为税率普遍过高。”
- en: '5.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Democrats tend to estimate a higher military budget than Republicans.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 民主党人倾向于估计美国军费开支高于共和党人。
- en: (a)
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Democrats: ”You believe that the US federal budget spent on the US military
    is too high in general.”'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 民主党人：“你认为美国联邦预算中用于美国军队的支出普遍过高。”
- en: (b)
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Republicans: ”You believe that the US federal budget spent on the US military
    is not as high as it should be in general.”'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人：“你认为美国联邦预算中用于美国军队的支出没有达到应该有的水平。”
- en: '6.'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: Republicans tend to estimate higher number of immigrants than democrats
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人倾向于估计移民数量高于民主党人。
- en: (a)
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Democrats: ”You believe that the unauthorized immigrants from Mexico were not
    a major national crisis before President Trump was elected.”'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 民主党人：“你认为在特朗普总统当选之前，来自墨西哥的非法移民并不是一个重大的国家危机。”
- en: (b)
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Republicans: ”You believe that the US federal budget spent on the US military
    is not as high as it should be in general.”'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人：“你认为美国联邦政府在美国军队上的预算总体上没有达到应有的水平。”
- en: '7.'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: Republicans tend to estimate a higher unemployment rate than democrats.
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人通常估计的失业率比民主党人高。
- en: (a)
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: 'Democrats: ”You believe that Barack Obama did a good job in reducing the US
    unemployment rate.”'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 民主党人：“你认为巴拉克·奥巴马在降低美国失业率方面做得很好。”
- en: (b)
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: 'Republicans: ”You believe that Barack Obama did a poor job in reducing the
    US unemployment rate.”'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共和党人：“你认为巴拉克·奥巴马在降低美国失业率方面做得很差。”
- en: '8.'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: Did not induce a bias for this question.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 没有为此问题引入偏见。
- en: Appendix F Full list of Prompts
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录F 完整的提示列表
- en: In this section, we detail the prompts we use at each time step in the experiments.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们详细介绍了在每个时间步骤中实验中使用的提示。
- en: 'Round 1: Role play this person. {AGENT_PERSONA}'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 第一轮：扮演这个角色。{AGENT_PERSONA}
- en: '{INDUCED_BIAS}'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '{INDUCED_BIAS}'
- en: Let’s play a game where you’ll be asked a single question, and you must provide
    an answer. This game has 3 trials, allowing you 2 chances to revise your response.
    Keep in mind that it’s a group game, played concurrently with other participants.
    After you submit your first answer, you’ll be given the average of other players’
    initial responses. Following your second submission, you’ll receive the average
    of their second-round responses. At the end of the game, the more accurate your
    final answer is compared to the actual truth, the more money you will earn.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来玩一个游戏，你将被问一个问题，并且你必须提供答案。这个游戏有3轮，允许你有2次修改回答的机会。请记住，这是一个小组游戏，其他参与者与您同时进行。在你提交第一次回答后，你将获得其他玩家初始回答的平均值。提交第二次答案后，你将获得他们第二轮回答的平均值。游戏结束时，你的最终答案与实际真相的差距越小，你将赚到的奖金就越多。
- en: Now, {AGENT_NAME}, in this first round of the game, you are asked to answer
    the following question.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，{AGENT_NAME}，在游戏的第一轮中，你被要求回答以下问题。
- en: '{QUESTION_CONTENT}'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '{QUESTION_CONTENT}'
- en: You must give an answer even if you are not sure.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不确定，也必须给出答案。
- en: 'Use the following format:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下格式：
- en: 'My Reasoning: [YOUR ({AGENT_NAME}’s) STEP-BY-STEP REASONING]'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我的推理：[你的（{AGENT_NAME}的）逐步推理]
- en: 'My Final Answer: [YOUR ({AGENT_NAME}’s) ESTIMATE (A REAL NUMBER)]Round 2: Now,
    {AGENT_NAME}, in this second round of the game, you are asked again to answer
    the following question.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我的最终答案：[你的（{AGENT_NAME}的）估算（一个真实的数字）]第二轮：现在，{AGENT_NAME}，在游戏的第二轮中，你再次被要求回答以下问题。
- en: '{QUESTION_CONTENT}'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '{QUESTION_CONTENT}'
- en: You must give an answer even if you are not sure.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不确定，也必须给出答案。
- en: 'This time, you are provided with other players in the first round of the game,
    who are all {AGENT_PARTY}. Their average answer: {FEEDBACK}'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，你将与其他玩家一起参加游戏的第一轮，他们都是{AGENT_PARTY}。他们的平均回答：{FEEDBACK}
- en: 'Use the following format:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下格式：
- en: 'My Reasoning: [YOUR ({AGENT_NAME}’s) STEP-BY-STEP REASONING]'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我的推理：[你的（{AGENT_NAME}的）逐步推理]
- en: 'My Final Answer: [YOUR ({AGENT_NAME}’s) ESTIMATE (A REAL NUMBER)]Round 3: Now,
    {AGENT_NAME}, in this third round of the game, you are asked again to answer the
    following question.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我的最终答案：[你的（{AGENT_NAME}的）估算（一个真实的数字）]第三轮：现在，{AGENT_NAME}，在游戏的第三轮中，你再次被要求回答以下问题。
- en: '{QUESTION_CONTENT}'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '{QUESTION_CONTENT}'
- en: You must give an answer even if you are not sure.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不确定，也必须给出答案。
- en: 'This time, you are provided with other players in the first round of the game,
    who are all {AGENT_PARTY}. Their average answer: {FEEDBACK}'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，你将与其他玩家一起参加游戏的第一轮，他们都是{AGENT_PARTY}。他们的平均回答：{FEEDBACK}
- en: 'Use the following format:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下格式：
- en: 'My Reasoning: [YOUR ({AGENT_NAME}’s) STEP-BY-STEP REASONING]'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我的推理：[你的（{AGENT_NAME}的）逐步推理]
- en: 'My Final Answer: [YOUR ({AGENT_NAME}’s) ESTIMATE (A REAL NUMBER)]'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我的最终答案：[你的（{AGENT_NAME}的）估算（一个真实的数字）]
- en: 'In the prompt outline above, the highlighted sections are subject to change
    based on the configuration of the prompt:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述提示大纲中，突出显示的部分会根据提示的配置而有所变化：
- en: 'AGENT_PERSONA:'
  id: totrans-226
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理人物（AGENT_PERSONA）：
- en: 'If we are using the detailed personas condition for a prompt, this placeholder
    is replaced with one of the descriptions from [C](https://arxiv.org/html/2311.09665v2#A3
    "Appendix C List of Personas ‣ The Wisdom of Partisan Crowds: Comparing Collective
    Intelligence in Humans and LLM-based Agents").'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在提示中使用详细的角色设定条件，这个占位符将被替换为来自[C](https://arxiv.org/html/2311.09665v2#A3 "附录
    C 角色列表 ‣ 党派群体智慧：比较人类与基于大型语言模型的代理的集体智能")中的其中一个描述。
- en: 'INDUCED_BIAS:'
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 引导的偏见：
- en: 'This placeholder is replaced with a bias corresponding to the party of the
    agent and the question. A list of these biases can be found in [E](https://arxiv.org/html/2311.09665v2#A5
    "Appendix E List of Induced Partisanship ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents").'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这个占位符将被替换为与代理和问题相关的党派偏见。关于这些偏见的列表可以在[E](https://arxiv.org/html/2311.09665v2#A5
    "附录 E 引导的党派偏见列表 ‣ 党派群体智慧：比较人类与基于大型语言模型的代理的集体智能")中找到。
- en: 'AGENT_NAME:'
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理名称：
- en: For the detailed persona condition, this placeholder is derived from the agent
    persona. For the simple persona condition, this is replaced with a generic name
    such as ”r_1” for republicans and ”d_1” for democrats.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 对于详细角色设定条件，此占位符来源于代理的角色设定。对于简单角色设定条件，此占位符会被替换为通用名称，如共和党用“r_1”，民主党用“d_1”。
- en: 'My Reasoning [YOUR (AGENT_NAME’s) STEP-BY-STEP REASONING]:'
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 我的推理 [你的（代理名称）逐步推理]：
- en: If the agent do not use chain-of-thought (CoT) reasoning in its responses, this
    section is excluded from the prompt at each time step. otherwise, it is included.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果代理在其回答中没有使用链式思维（CoT）推理，则每个步骤时此部分会从提示中排除。否则，它会被包括在内。
- en: 'AGENT_PARTY:'
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理党派：
- en: This placeholder is replaced with either ”democrats” or ”republicans” depending
    on the agent’s party affiliation.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个占位符将被替换为“民主党”或“共和党”，具体取决于代理的党派归属。
- en: 'FEEDBACK:'
  id: totrans-236
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 反馈：
- en: For the second and third round prompts, this placeholder is replaced with the
    mean response of the agent’s neighbours for the previous round.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二轮和第三轮的提示，此占位符将被替换为代理邻居在上一轮的平均回答。
- en: 'QUESTION_CONTENT:'
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 问题内容：
- en: 'This placeholder is replaced with one of the question from [D](https://arxiv.org/html/2311.09665v2#A4
    "Appendix D Full List of Questions ‣ The Wisdom of Partisan Crowds: Comparing
    Collective Intelligence in Humans and LLM-based Agents").'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这个占位符将被替换为来自[D](https://arxiv.org/html/2311.09665v2#A4 "附录 D 完整问题列表 ‣ 党派群体智慧：比较人类与基于大型语言模型的代理的集体智能")中的一个问题。
- en: Appendix G Criteria for Extreme Values
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录G 极端值标准
- en: 'For all questions in the experiment ($q\in[1,8]$), we use the same criteria
    as in the human study (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2))⁸⁸8Becker
    et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)) use a log function
    to normalize the responses for $q\in[1,4]$ without removing extreme values. In
    our study, we do not do this since LLM agents may occasionally return negative
    values. Instead, we follow their “alternative normalization procedire” outlined
    in their supplementary materials. They show that different normalization procedures
    do not yield significant differences.. The criteria are as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实验中的所有问题（$q\in[1,8]$），我们使用与人类研究（Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）相同的标准。Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）使用对数函数来标准化$q\in[1,4]$的问题，而不移除极端值。在我们的研究中，我们没有这么做，因为大型语言模型代理有时可能返回负值。相反，我们遵循他们在补充材料中概述的“替代标准化程序”。他们表明，不同的标准化程序不会产生显著差异。标准如下：
- en: '1.'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Election donations for John Kerry in 2004: Answers above $2246 million ($10\times
    x^{*}$) or below 0 are considered extreme.'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2004年约翰·克里选举捐款：答案高于2246百万美元（$10\times x^{*}$）或低于0的视为极端值。
- en: '2.'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'California demographics: Answers above 602% ($10\times x^{*})$ or below 0%
    are considered extreme.'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 加利福尼亚州人口统计：答案高于602%（$10\times x^{*}$）或低于0%的视为极端值。
- en: '3.'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Unemployment rate at the end of Obama’s presidency: Answers above 49% ($10\times
    x^{*}$) or below 0% are considered extreme.'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 奥巴马总统任期结束时的失业率：答案高于49%（$10\times x^{*}$）或低于0%的视为极端值。
- en: '4.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Tax revenue as a percentage of GDP in 2010: Answers above 146% ($10\times x^{*}$)
    or below 0% are considered extreme.'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2010年税收占GDP的百分比：答案高于146%（$10\times x^{*}$）或低于0%的视为极端值。
- en: '5.'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: 'Military spending: Answers above 100% or below 0% are considered extreme.'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 军事开支：答案高于100%或低于0%的视为极端值。
- en: '6.'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: 'Immigration rate changes: Answers above 1000% or below -1000% are extreme.'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 移民率变化：答案高于1000%或低于-1000%的视为极端值。
- en: '7.'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: 'Unemployment rate changes: Answers above 1000% or below -1000% are extreme.'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 失业率变化：超过1000%或低于-1000%的回答为极端值。
- en: '8.'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: 'Soldier deaths: Answers above 1 million and answers below 0 are extreme.'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 士兵死亡：超过100万或低于0的回答为极端值。
- en: These criteria are based on the realistic ranges expected for these measures,
    as per the guidelines in Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标准是基于Becker等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）中对于这些度量的现实范围的指导准则。
- en: Appendix H Fine-tuning Details
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H 微调详情
- en: 'OpenAI’s ChatGPT (gpt-3.5-turbo-0613) was fine-tuned using the human data from
    (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)) to investigate
    the change in human-AI alignment in a group interaction setting. Two separate
    models were fine-tuned: one for Democrats and another one for Republicans.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的ChatGPT（gpt-3.5-turbo-0613）使用（Becker等，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）中的人类数据进行了微调，以研究小组互动环境中人类与AI的对齐变化。分别对民主党和共和党的两个模型进行了微调。
- en: 'These were the hyper-parameters used in the fine-tuning:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是用于微调的超参数：
- en: •
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Training Set Size: 2747'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练集大小：2747
- en: •
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Validation Set Size: 381'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证集大小：381
- en: •
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Epochs: 4'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练轮数：4
- en: •
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Batch Size: 5'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批次大小：5
- en: •
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Learning Rate Decay Factor: 0.05'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习率衰减因子：0.05
- en: Human data was collected for 12 groups. For each agent $a_{i,p,r}$, a list of
    4 neighbours $\mathcal{N}(i,p,r)$ was provided. We recreated the feedback provided
    to agents in rounds 2 and 3 by taking the average of their neighbours’ estimates
    in the previous round, given by $m_{i,p,r,q}^{t}=\frac{1}{4}\sum_{j\in\mathcal{N}(i,p,r)}x_{j,p,r,q}^{t-1}$.
    The data for each agent was separated into 3 prompt-response pairs, corresponding
    to a specific round in the experiment. Each pair included the prompt and its corresponding
    response from the respective round, as well as those from earlier rounds. These
    pairs were passed into OpenAI’s fine-tuning API and the experiment was run on
    the resulting models.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 对12个小组收集了人类数据。对于每个代理 $a_{i,p,r}$，提供了4个邻居 $\mathcal{N}(i,p,r)$ 的列表。我们通过取他们在上一轮中邻居估计值的平均值，重建了在第2轮和第3轮提供给代理的反馈，该平均值由
    $m_{i,p,r,q}^{t}=\frac{1}{4}\sum_{j\in\mathcal{N}(i,p,r)}x_{j,p,r,q}^{t-1}$ 给出。每个代理的数据被分成3个提示-回应对，分别对应实验中的特定轮次。每一对包括该轮的提示及其相应的回应，以及早期轮次的内容。这些对被输入到OpenAI的微调API中，并在生成的模型上运行实验。
- en: Appendix I Compute Resources
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 I 计算资源
- en: For running the Vicuna-33B model, we use a Linux server with 1 GPU card (A100-SXM4-80GB),
    taking about 12 hours to run the full experiment.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 Vicuna-33B 模型时，我们使用了一台配有1张GPU卡（A100-SXM4-80GB）的Linux服务器，整个实验大约需要12小时。
- en: Appendix J Detailed Definition of Notations
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 J 符号的详细定义
- en: This appendix section elaborates on the specific definitions and the derivation
    process of key metrics and terms used throughout our study.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录部分详细阐述了在本研究中使用的关键度量和术语的具体定义和推导过程。
- en: J.1 Reduction in Group Error Through Social Interaction
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: J.1 通过社交互动减少小组误差
- en: 'The primary indicator of human-like performance in this group experiment setting
    is the ability to improve estimates over time through social interaction, as per
    (Becker et al., [2019](https://arxiv.org/html/2311.09665v2#bib.bib2)). To quantify
    this effect, we define several key terms:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在此小组实验设置中，人类表现的主要指标是通过社交互动随时间改进估计值的能力，参见（Becker等，[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）。为了量化这一效应，我们定义了几个关键术语：
- en: 'Group Mean ($\bar{x}_{p,r,q}^{t}$):'
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 组均值 ($\bar{x}_{p,r,q}^{t}$)：
- en: For each run $r$ and each political leaning $p$, the group mean at each time
    step $t$ for question $q$ is denoted as $\bar{x}_{p,r,q}^{t}$. It represents the
    average of the estimates provided by all agents in the group at that time step
    and is expressed as $\bar{x}_{p,r,q}^{t}=\frac{1}{N}\sum_{i=1}^{N}x_{i,p,r,q}^{t}$,
    where $N=35$ is the total number of agents in the group.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每次运行 $r$ 和每种政治倾向 $p$，每个时间步 $t$ 对于问题 $q$ 的组均值记作 $\bar{x}_{p,r,q}^{t}$。它表示在该时间步所有组员提供的估计值的平均值，表示为
    $\bar{x}_{p,r,q}^{t}=\frac{1}{N}\sum_{i=1}^{N}x_{i,p,r,q}^{t}$，其中 $N=35$ 是组内总的代理人数。
- en: 'Group Error ($\delta_{p,r,q}^{t}$):'
  id: totrans-281
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 小组误差 ($\delta_{p,r,q}^{t}$)：
- en: 'The group error for each run $r$, political leaning $p$, and time step $t$
    for question $q$ is denoted as $\delta_{p,r,q}^{t}$. This metric is calculated
    as the difference between the group mean and the ground truth value: $\delta_{p,r,q}^{t}=|\bar{x}_{p,r,q}^{t}-x^{*}_{q}|$.
    It represents the raw error of the group’s collective estimate in comparison to
    the actual value for each question.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行 $r$、政治倾向 $p$ 和时间步长 $t$ 对于问题 $q$ 的群体误差表示为 $\delta_{p,r,q}^{t}$。该度量通过群体均值与真实值之间的差异计算：$\delta_{p,r,q}^{t}=|\bar{x}_{p,r,q}^{t}-x^{*}_{q}|$。它表示群体在每个问题上的集体估计与实际值之间的原始误差。
- en: 'Normalized Group Mean ($\eta_{p,r,q}^{t}$):'
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 归一化群体均值（$\eta_{p,r,q}^{t}$）：
- en: The normalized group mean is defined as $\eta_{p,r,q}^{t}=100\times(\bar{x}_{p,r,q}^{t}-x^{*}_{q})/(x^{*}_{q})$,
    where $x^{*}_{q}$ is the ground truth value for question $q$. This metric provides
    a relative measure of the group’s average estimate compared to the ground truth,
    normalized by the scale of each question. We further scale by 100 to express the
    group mean as the percentage of ground truth $x^{*}$; $+100$ means overestimating
    by one unit of $x^{*}$, and $-100$ means underestimating by one unit of $x^{*}$.
    Note that, unlike Becker et al. ([2019](https://arxiv.org/html/2311.09665v2#bib.bib2)),
    who use log functions for normalization for some questions, we adopt their “alternative
    normalization procedure” due to occasional negative values from LLM agents, as
    outlined in their supplementary materials. They demonstrate that various normalization
    methods yield similar results.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化群体均值定义为 $\eta_{p,r,q}^{t}=100\times(\bar{x}_{p,r,q}^{t}-x^{*}_{q})/(x^{*}_{q})$，其中
    $x^{*}_{q}$ 是问题 $q$ 的真实值。该度量提供了群体平均估计值与真实值之间的相对度量，且按每个问题的规模进行了归一化。我们进一步通过 100
    进行缩放，将群体均值表示为真实值 $x^{*}$ 的百分比；$+100$ 表示高估了 $x^{*}$ 的一个单位，$-100$ 表示低估了 $x^{*}$
    的一个单位。请注意，与 Becker 等人（[2019](https://arxiv.org/html/2311.09665v2#bib.bib2)）不同，他们在某些问题上使用对数函数进行归一化，我们采用了他们的“替代归一化程序”，这是因为来自
    LLM 代理的偶尔负值，具体细节见他们的补充材料。他们证明了各种归一化方法产生类似的结果。
- en: 'Normalized Group Error ($\varepsilon_{p,r,q}^{t}$):'
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 归一化群体误差（$\varepsilon_{p,r,q}^{t}$）：
- en: The normalized group error, $\varepsilon_{p,r,q}^{t}$, measures the absolute
    deviation of the normalized group mean from the ground truth value and is defined
    as $\varepsilon_{p,r,q}^{t}=|\eta_{p,r,q}^{t}|=100\times|(\bar{x}_{p,r,q}^{t}-x^{*%
    }_{q})/x^{*}_{q}|$. Note that we also scale by 100, so $\varepsilon_{p,r,q}^{t}$
    can be interpreted as the error in terms of the percentage of the ground truth
    value $x^{*}$. For example, $\varepsilon_{p,r,q}^{t}=50$ means that the group
    mean is deviating from the ground truth $x^{*}$ by $50\%$ of $|x^{*}|$.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化群体误差 $\varepsilon_{p,r,q}^{t}$ 衡量归一化群体均值与真实值之间的绝对偏差，其定义为 $\varepsilon_{p,r,q}^{t}=|\eta_{p,r,q}^{t}|=100\times|(\bar{x}_{p,r,q}^{t}-x^{*}_{q})/x^{*}_{q}|$。请注意，我们也通过
    100 进行缩放，因此 $\varepsilon_{p,r,q}^{t}$ 可以解释为相对于真实值 $x^{*}$ 的百分比误差。例如，$\varepsilon_{p,r,q}^{t}=50$
    表示群体均值偏离真实值 $x^{*}$ 达到了 $|x^{*}|$ 的 $50\%$。
- en: 'Average Normalized Group Error ($\overline{\varepsilon_{t}}$):'
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 平均归一化群体误差（$\overline{\varepsilon_{t}}$）：
- en: To evaluate group performance across political leanings, runs, and questions,
    we calculate the average normalized group error, denoted as $\overline{\varepsilon_{t}}$.
    This metric represents the average normalized group error at a specific time step
    $t$. Formally, $\overline{\varepsilon_{t}}=\frac{1}{P\cdot R\cdot Q}\sum_{p}\sum_{r=1}^{R}\sum%
    _{q=1}^{Q}\varepsilon_{p,r,q}^{t}$, where $P=2$ represents the number of political
    leanings, $R$ is the total number of runs, and $Q=8$ is the number of questions.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估群体在政治倾向、运行次数和问题上的表现，我们计算平均归一化群体误差，表示为 $\overline{\varepsilon_{t}}$。该度量表示特定时间步长
    $t$ 上的平均归一化群体误差。形式上，$\overline{\varepsilon_{t}}=\frac{1}{P\cdot R\cdot Q}\sum_{p}\sum_{r=1}^{R}\sum_{q=1}^{Q}\varepsilon_{p,r,q}^{t}$，其中
    $P=2$ 表示政治倾向的数量，$R$ 是运行次数的总数，$Q=8$ 是问题的数量。
- en: 'Group Error Reduction ($\Delta\varepsilon_{p,r,q}$):'
  id: totrans-289
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 群体误差减少（$\Delta\varepsilon_{p,r,q}$）：
- en: The change in normalized group error from the initial to the final estimate
    is quantified as $\Delta\varepsilon_{p,r,q}=(\varepsilon_{p,r,q}^{t=3}-\varepsilon_{p,r,q}^{t=1})$,
    indicating error reduction for each run. Note that because $\varepsilon_{p,r,q}^{t}$
    is already scaled by 100, $\Delta\varepsilon_{p,r,q}$ can be interpreted as the
    error reduction in terms of the percentage of the ground truth value $x^{*}$.
    For example, $\Delta\varepsilon_{p,r,q}=-50$ means that the group error $\delta_{p,r,q}^{t}$
    reduces by $50\%$ of the size of the ground truth $|x^{*}|$. In other words, the
    group mean $x_{p,r,q}^{t}$ moves towards the ground truth $x^{*}$ by $50\%$ of
    the size of the ground truth $|x^{*}|$)
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 从初始估计到最终估计的标准化组误差变化量为 $\Delta\varepsilon_{p,r,q}=(\varepsilon_{p,r,q}^{t=3}-\varepsilon_{p,r,q}^{t=1})$，表示每次运行的误差减少。注意，由于
    $\varepsilon_{p,r,q}^{t}$ 已经按 100 进行缩放，$\Delta\varepsilon_{p,r,q}$ 可以解释为以真实值 $x^{*}$
    的百分比表示的误差减少。例如，$\Delta\varepsilon_{p,r,q}=-50$ 表示组误差 $\delta_{p,r,q}^{t}$ 减少了
    $50\%$ 的真实值 $|x^{*}|$ 的大小。换句话说，组均值 $x_{p,r,q}^{t}$ 向真实值 $x^{*}$ 移动了 $50\%$ 的真实值
    $|x^{*}|$ 的大小。
- en: 'Average Group Error Reduction ($\overline{\Delta\varepsilon}$):'
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 平均组误差减少（$\overline{\Delta\varepsilon}$）：
- en: To quantify the change in group error over the course of the experiment, we
    calculate the average group error reduction, denoted as $\overline{\Delta\varepsilon}$.
    This is calculated by averaging $\Delta\varepsilon_{p,r,q}$ across all political
    leanings, runs, and questions. Formally, $\overline{\Delta\varepsilon}=\frac{1}{P\cdot
    R\cdot Q}\sum_{p}\sum_{r=1}^{R}% \sum_{q=1}^{Q}\Delta\varepsilon_{p,r,q}$, where
    $P=2$ represents the number of political leanings, $R=12$ the total number of
    runs, and $Q=8$ the number of questions. $\overline{\Delta\varepsilon}$ reflects
    the wisdom of partisan crowds effect in LLM agents. A more negative value of $\overline{\Delta\varepsilon}$
    indicates a stronger wisdom of partisan crowds effect.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 为了量化实验过程中组误差的变化，我们计算平均组误差减少，记作 $\overline{\Delta\varepsilon}$。它是通过对所有政治倾向、运行和问题的
    $\Delta\varepsilon_{p,r,q}$ 进行平均来计算的。形式上，$\overline{\Delta\varepsilon}=\frac{1}{P\cdot
    R\cdot Q}\sum_{p}\sum_{r=1}^{R}% \sum_{q=1}^{Q}\Delta\varepsilon_{p,r,q}$，其中 $P=2$
    表示政治倾向的数量，$R=12$ 是总运行次数，$Q=8$ 是问题的数量。$\overline{\Delta\varepsilon}$ 反映了党派人群智慧效应在大型语言模型（LLM）中的表现。$\overline{\Delta\varepsilon}$
    值越负，表示党派人群智慧效应越强。
- en: J.2 Deriving the Revision Coefficient
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: J.2 推导修正系数
- en: 'To compute the revision coefficient, we follow the methodology outlined by
    Becker et al. ([2017](https://arxiv.org/html/2311.09665v2#bib.bib1)), focusing
    on the relationship between individual revisions, initial errors, and the social
    signal. The process involves two main steps: regression to obtain residuals and
    computing the partial correlation.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算修正系数，我们遵循Becker等人（[2017](https://arxiv.org/html/2311.09665v2#bib.bib1)）提出的方法，重点研究个体修正、初始误差与社会信号之间的关系。该过程包括两个主要步骤：回归分析以获得残差，并计算部分相关性。
- en: 'Obtaining Residuals:'
  id: totrans-295
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 获取残差：
- en: The first step involves using Ordinary Least Squares (OLS) regression to adjust
    individual revisions and errors based on the social signal. This is done to isolate
    the effect of an individual’s initial accuracy on their subsequent revision, independent
    of the strength of the social influence they experience.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步涉及使用普通最小二乘（OLS）回归来调整个体修正和误差，基于社会信号进行调整。这是为了孤立个体初始准确度对其后续修正的影响，而不考虑他们所经历的社会影响的强度。
- en: '1.'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Adjusting Individual Revisions: For each question $q$, across all individual
    $i$, political leaning $p$, and run $r$, we perform a regression of their individual
    revision $\Delta x_{i,p,r,q}$ against the social signal $s_{i,p,r,q}$. For a given
    question $q$, the regression equation is:'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调整个体修正：对于每个问题 $q$，遍及所有个体 $i$、政治倾向 $p$ 和运行 $r$，我们将他们的个体修正 $\Delta x_{i,p,r,q}$
    与社会信号 $s_{i,p,r,q}$ 进行回归分析。对于给定的问题 $q$，回归方程为：
- en: '|  | $\displaystyle\Delta x_{i,p,r,q}=a_{1,q}\cdot s_{i,p,r,q}+b_{1,q}+\epsilon_{1,i%
    ,p,r,q}$ |  |'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle\Delta x_{i,p,r,q}=a_{1,q}\cdot s_{i,p,r,q}+b_{1,q}+\epsilon_{1,i%
    ,p,r,q}$ |  |'
- en: where $a_{1,q}$ and $b_{1,q}$ are regression coefficients, and $\epsilon_{1,i,p,r,q}$
    is the residual. The residual $\epsilon_{1,i,p,r,q}$ represents the adjusted individual
    revision $\widetilde{\Delta x}_{i,p,r,q}=\epsilon_{1,i,p,r,q}$.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中 $a_{1,q}$ 和 $b_{1,q}$ 是回归系数，$\epsilon_{1,i,p,r,q}$ 是残差。残差 $\epsilon_{1,i,p,r,q}$
    代表调整后的个体修正 $\widetilde{\Delta x}_{i,p,r,q}=\epsilon_{1,i,p,r,q}$。
- en: '2.'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Adjusting Initial Errors: Similarly, we regress the individual initial error
    $e_{i,p,r,q}$ against the same social signal:'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调整初始误差：类似地，我们将个体初始误差 $e_{i,p,r,q}$ 与相同的社会信号进行回归：
- en: '|  | $\displaystyle e_{i,p,r,q}=a_{2,q}\cdot s_{i,p,r,q}+b_{2,q}+\epsilon_{2,i,p,r,q}$
    |  |'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '|  | $\displaystyle e_{i,p,r,q}=a_{2,q}\cdot s_{i,p,r,q}+b_{2,q}+\epsilon_{2,i,p,r,q}$
    |  |'
- en: where $a_{2,q}$ and $b_{2,q}$ are coefficients, and $\epsilon_{2,i,p,r,q}$ is
    the residual. The residual $\epsilon_{2,i,p,r,q}$ becomes the adjusted initial
    error $\widetilde{e}_{i,p,r,q}=\epsilon_{2,i,p,r,q}$.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中$a_{2,q}$和$b_{2,q}$是系数，$\epsilon_{2,i,p,r,q}$是残差。残差$\epsilon_{2,i,p,r,q}$变为调整后的初始误差$\widetilde{e}_{i,p,r,q}=\epsilon_{2,i,p,r,q}$。
- en: 'Computing the Partial Correlation:'
  id: totrans-305
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算偏相关：
- en: 'With the residuals obtained, the revision coefficient ($r_{\text{adj},q}$)
    is computed as the Pearson correlation between the adjusted individual revisions
    and adjusted initial errors:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 获得残差后，修正系数($r_{\text{adj},q}$)被计算为调整后的个体修正与调整后的初始误差之间的皮尔逊相关：
- en: '|  | $\displaystyle r_{\text{adj},q}$ | $\displaystyle=\text{corr}(\Delta\widetilde{x}_{i,p,r,q},\widetilde{e}_{i,p,r,q})$
    |  |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle r_{\text{adj},q}$ | $\displaystyle=\text{corr}(\Delta\widetilde{x}_{i,p,r,q},\widetilde{e}_{i,p,r,q})$
    |  |'
- en: '|  |  | $\displaystyle=\text{corr}(\epsilon_{1,i,p,r,q},\epsilon_{2,i,p,r,q})$
    |  |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\text{corr}(\epsilon_{1,i,p,r,q},\epsilon_{2,i,p,r,q})$
    |  |'
- en: This partial correlation reflects the extent to which individuals with higher
    initial accuracy are less influenced by social signals in revising their estimates,
    after controlling for the strength of the social signal itself.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这个偏相关反映了在控制社会信号强度之后，初始精度较高的个体在修正估计时受到社会信号影响的程度。
