- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:15:57'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:15:57
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从宣传到仇恨：基于多代理大语言模型的阿拉伯表情包的多模态分析
- en: 来源：[https://arxiv.org/html/2409.07246/](https://arxiv.org/html/2409.07246/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2409.07246/](https://arxiv.org/html/2409.07246/)
- en: '¹¹institutetext: ¹Qatar Computing Research Institute, Qatar, ²Hamad bin Khalifa
    University, Qatar,'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹机构文本：¹卡塔尔计算研究所，卡塔尔，²哈马德·本·哈利法大学，卡塔尔，
- en: ³Northwestern University in Qatar, Qatar
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ³卡塔尔的西北大学，卡塔尔
- en: fialam@hbku.edu.qa
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: fialam@hbku.edu.qa
- en: ^((✉))Corresponding authorFiroj Alam^✉ 11 [0000-0001-7172-1997](https://orcid.org/0000-0001-7172-1997
    "ORCID identifier")    Md. Rafiul Biswas 22 [0000-0002-5145-1990](https://orcid.org/0000-0002-5145-1990
    "ORCID identifier")    Uzair Shah 22 [0000-0002-6729-5654](https://orcid.org/0000-0002-6729-5654
    "ORCID identifier")    Wajdi Zaghouani 33 [0000-0003-1521-5568](https://orcid.org/0000-0003-1521-5568
    "ORCID identifier")    Georgios Mikros 22 [0000-0002-4093-5973](https://orcid.org/0000-0002-4093-5973
    "ORCID identifier")
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ^((✉))通讯作者Firoj Alam^✉ 11 [0000-0001-7172-1997](https://orcid.org/0000-0001-7172-1997
    "ORCID 标识符")    Md. Rafiul Biswas 22 [0000-0002-5145-1990](https://orcid.org/0000-0002-5145-1990
    "ORCID 标识符")    Uzair Shah 22 [0000-0002-6729-5654](https://orcid.org/0000-0002-6729-5654
    "ORCID 标识符")    Wajdi Zaghouani 33 [0000-0003-1521-5568](https://orcid.org/0000-0003-1521-5568
    "ORCID 标识符")    Georgios Mikros 22 [0000-0002-4093-5973](https://orcid.org/0000-0002-4093-5973
    "ORCID 标识符")
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: In the past decade, social media platforms have been used for information dissemination
    and consumption. While a major portion of the content is posted to promote citizen
    journalism and public awareness, some content is posted to mislead users. Among
    different content types such as text, images, and videos, memes (text overlaid
    on images) are particularly prevalent and can serve as powerful vehicles for propaganda,
    hate, and humor. In the current literature, there have been efforts to individually
    detect such content in memes. However, the study of their intersection is very
    limited. In this study, we explore the intersection between propaganda and hate
    in memes using a multi-agent LLM-based approach. We extend the propagandistic
    meme dataset with coarse and fine-grained hate labels. Our finding suggests that
    there is an association between propaganda and hate in memes. We provide detailed
    experimental results that can serve as a baseline for future studies. We will
    make the experimental resources publicly available to the community.¹¹1[https://github.com/firojalam/propaganda-and-hateful-memes.git](https://github.com/firojalam/propaganda-and-hateful-memes.git)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的十年里，社交媒体平台被广泛用于信息传播和消费。虽然大部分内容是发布来促进公民新闻和公众意识的，但也有部分内容被发布以误导用户。在文本、图像和视频等不同类型的内容中，表情包（在图像上叠加文本）尤为流行，且能够成为宣传、仇恨和幽默的强大载体。在现有文献中，已经有研究尝试单独检测表情包中的此类内容。然而，对于这些内容交集的研究非常有限。在本研究中，我们通过基于多代理大语言模型的方法，探索表情包中宣传与仇恨之间的交集。我们通过粗粒度和细粒度的仇恨标签扩展了宣传表情包数据集。我们的发现表明，表情包中的宣传与仇恨之间存在关联。我们提供了详细的实验结果，这些结果可以作为未来研究的基准。我们将公开实验资源，供社区使用。¹¹1[https://github.com/firojalam/propaganda-and-hateful-memes.git](https://github.com/firojalam/propaganda-and-hateful-memes.git)
- en: 'Keywords:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: PropagandaHateful MemeMultimodalityLLMs
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 宣传仇恨表情包多模态大语言模型
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Social media has emerged as a primary channel for freely sharing content online.
    Its exponential growth has significantly transformed the landscape of information
    dissemination. However, misuse of these platforms has made them fertile grounds
    for the spread of inappropriate content, misinformation, and disinformation [[2](https://arxiv.org/html/2409.07246v2#bib.bib2)].
    While interactions on social media facilitate public discussions on a range of
    topics, from local issues to politics, they also harbor and propagate hate speech
    and offensive content through various content types, text, images, and videos
    [[26](https://arxiv.org/html/2409.07246v2#bib.bib26), [16](https://arxiv.org/html/2409.07246v2#bib.bib16),
    [31](https://arxiv.org/html/2409.07246v2#bib.bib31), [2](https://arxiv.org/html/2409.07246v2#bib.bib2)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体已成为一个主要的在线内容分享渠道。它的指数增长显著改变了信息传播的格局。然而，这些平台的滥用使其成为传播不当内容、虚假信息和误导性信息的温床[[2](https://arxiv.org/html/2409.07246v2#bib.bib2)]。社交媒体上的互动促进了关于从地方问题到政治等一系列话题的公共讨论，但它们也通过各种内容类型——文本、图像和视频——滋生和传播仇恨言论和攻击性内容[[26](https://arxiv.org/html/2409.07246v2#bib.bib26),
    [16](https://arxiv.org/html/2409.07246v2#bib.bib16), [31](https://arxiv.org/html/2409.07246v2#bib.bib31),
    [2](https://arxiv.org/html/2409.07246v2#bib.bib2)]。
- en: To address such problems across different modalities, there have been efforts
    to automatically detect them using both mono- and multimodal modeling approaches
    [[9](https://arxiv.org/html/2409.07246v2#bib.bib9)]. For propagandistic content
    detection, research efforts have specifically focused on defining techniques and
    tackling the issue across various types of content, including news articles, tweets,
    memes, and textual content in multiple languages [[13](https://arxiv.org/html/2409.07246v2#bib.bib13),
    [4](https://arxiv.org/html/2409.07246v2#bib.bib4), [28](https://arxiv.org/html/2409.07246v2#bib.bib28)].
    Similarly, significant efforts have been made in hate-speech detection [[29](https://arxiv.org/html/2409.07246v2#bib.bib29),
    [10](https://arxiv.org/html/2409.07246v2#bib.bib10)]. A notable initiative in
    meme research is the Hateful Memes Challenge [[23](https://arxiv.org/html/2409.07246v2#bib.bib23)],
    which has inspired many subsequent studies.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决不同模态中的此类问题，已有许多努力尝试使用单模态和多模态建模方法自动检测它们[[9](https://arxiv.org/html/2409.07246v2#bib.bib9)]。在宣传内容检测方面，研究主要集中在定义技术并解决各种内容类型（包括新闻文章、推文、表情包和多种语言的文本内容）中的问题[[13](https://arxiv.org/html/2409.07246v2#bib.bib13),
    [4](https://arxiv.org/html/2409.07246v2#bib.bib4), [28](https://arxiv.org/html/2409.07246v2#bib.bib28)]。类似地，在仇恨言论检测方面也进行了大量的努力[[29](https://arxiv.org/html/2409.07246v2#bib.bib29),
    [10](https://arxiv.org/html/2409.07246v2#bib.bib10)]。表情包研究中的一个重要举措是仇恨表情包挑战赛[[23](https://arxiv.org/html/2409.07246v2#bib.bib23)]，它激发了许多后续研究。
- en: Our research lies at the intersection of multimodal content analysis, propaganda
    detection, and hate speech identification. While progress has been made in these
    fields for English and other high-resource languages, the research for Arabic
    remains underexplored. Building on the work of [[5](https://arxiv.org/html/2409.07246v2#bib.bib5)]
    and [[18](https://arxiv.org/html/2409.07246v2#bib.bib18)] in Arabic propaganda
    detection, our study analyzes Arabic memes, addressing a gap in the literature.
    The findings can assist social media platforms, policymakers, and civil society
    organizations in combating harmful online content.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究位于多模态内容分析、宣传检测和仇恨言论识别的交叉领域。尽管在英语及其他高资源语言领域已取得了一定进展，但对于阿拉伯语的研究仍然较为缺乏。在参考了[[5](https://arxiv.org/html/2409.07246v2#bib.bib5)]和[[18](https://arxiv.org/html/2409.07246v2#bib.bib18)]在阿拉伯语宣传检测方面的工作基础上，我们的研究分析了阿拉伯语表情包，填补了文献中的空白。研究结果可以帮助社交媒体平台、政策制定者和民间组织应对有害的网络内容。
- en: 'The key aspects of our work are as follows: (i) we present a novel multi-agent
    LLM-based approach to analyze the association between propaganda and hateful memes
    in Arabic social media content; (ii) we demonstrate the application of multi-agent
    LLM systems for automated annotation of complex, multimodal data, offering a scalable
    solution for processing large volumes of data in low-resource settings; (iii)
    in addition to coarse-grained hateful categories, we also explore fine-grained
    categorization of hateful and non-hateful memes; (iv) we provide experimental
    results on both coarse and fine-grained categories; (v) finally, we will make
    the dataset of hateful memes available to the community.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工作的关键方面如下：（i）我们提出了一种新颖的基于多智能体大型语言模型（LLM）的方法，用于分析阿拉伯语社交媒体内容中宣传和仇恨表情包之间的关联；（ii）我们展示了多智能体LLM系统在复杂、多模态数据自动标注中的应用，提供了一种在资源匮乏环境下处理大量数据的可扩展解决方案；（iii）除了粗粒度的仇恨类别外，我们还探索了仇恨和非仇恨表情包的细粒度分类；（iv）我们提供了粗粒度和细粒度分类的实验结果；（v）最后，我们将把仇恨表情包数据集提供给社区。
- en: 2 Related Work
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 Propagandistic Content
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 宣传内容
- en: 'Textual Content: The study of propagandistic content has attracted significant
    attention in recent years. Da et al. (2020) introduced a large-scale dataset for
    fine-grained propaganda detection in news articles, presenting a corpus of 350K
    sentences annotated with 18 propaganda techniques [[8](https://arxiv.org/html/2409.07246v2#bib.bib8)].
    The annotation schema has been extended to include 23 techniques and a multilingual
    corpus has been proposed in [[28](https://arxiv.org/html/2409.07246v2#bib.bib28)].
    Following the same annotation schema, datasets have been developed for Arabic
    and shared tasks has been organized [[4](https://arxiv.org/html/2409.07246v2#bib.bib4),
    [20](https://arxiv.org/html/2409.07246v2#bib.bib20), [19](https://arxiv.org/html/2409.07246v2#bib.bib19)].'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 文本内容：近年来，宣传内容的研究引起了广泛关注。Da 等人（2020）引入了一个大规模数据集，用于新闻文章中的细粒度宣传检测，呈现了一个包含350K句子、标注了18种宣传技巧的语料库[[8](https://arxiv.org/html/2409.07246v2#bib.bib8)]。该标注方案已扩展为包含23种技巧，并在[[28](https://arxiv.org/html/2409.07246v2#bib.bib28)]中提出了多语言语料库。遵循相同的标注方案，已经为阿拉伯语开发了数据集，并组织了共享任务[[4](https://arxiv.org/html/2409.07246v2#bib.bib4),
    [20](https://arxiv.org/html/2409.07246v2#bib.bib20), [19](https://arxiv.org/html/2409.07246v2#bib.bib19)]。
- en: 'Multimodal Content: Building on previous research in textual content, Dimitrov
    et al. (2021) introduced SemEval-2021 Task 6, which focuses on detecting persuasion
    techniques in texts and images within memes [[14](https://arxiv.org/html/2409.07246v2#bib.bib14)].
    Subsequently, the focus has expanded to include the detection of multilingual
    and multimodal propagandistic memes [[12](https://arxiv.org/html/2409.07246v2#bib.bib12)].
    Similarly, related work on Arabic involves the development of datasets and a shared
    task for propaganda detection [[3](https://arxiv.org/html/2409.07246v2#bib.bib3),
    [21](https://arxiv.org/html/2409.07246v2#bib.bib21)]. Fang et al. (2022) used
    separate networks to embed text and images, fusing these multi-modal embeddings.
    A split-and-share module with multi-level representations was employed to improve
    persuasive technique detection [[15](https://arxiv.org/html/2409.07246v2#bib.bib15)].'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态内容：在文本内容的先前研究基础上，Dimitrov 等人（2021）引入了SemEval-2021任务6，该任务聚焦于检测表情包中文本和图像中的劝说技巧[[14](https://arxiv.org/html/2409.07246v2#bib.bib14)]。随后，研究重点扩展到了包括检测多语言和多模态宣传表情包[[12](https://arxiv.org/html/2409.07246v2#bib.bib12)]。类似地，阿拉伯语相关研究涉及到数据集的开发和宣传检测的共享任务[[3](https://arxiv.org/html/2409.07246v2#bib.bib3),
    [21](https://arxiv.org/html/2409.07246v2#bib.bib21)]。Fang 等人（2022）使用独立的网络来嵌入文本和图像，将这些多模态嵌入进行融合。采用带有多级表示的拆分共享模块，以改善劝说技巧检测[[15](https://arxiv.org/html/2409.07246v2#bib.bib15)]。
- en: 2.2 Hateful Memes
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 仇恨表情包
- en: The study of hateful memes presents unique challenges due to their multimodal
    nature. Kiela et al. (2020) introduced the Hateful Memes Challenge, a large-scale
    dataset and benchmark for multimodal hate detection. This work highlighted the
    importance of integrating both textual and visual elements to identify hate speech
    in memes [[23](https://arxiv.org/html/2409.07246v2#bib.bib23)]. Addressing the
    challenge of low-resource languages, datasets have also been developed in various
    languages [[22](https://arxiv.org/html/2409.07246v2#bib.bib22)]. In [[31](https://arxiv.org/html/2409.07246v2#bib.bib31)],
    the authors provide a detailed survey of multimodal and harmful memes, highlighting
    the significance of the problem and proposing future research avenues.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 仇恨表情包的研究面临独特的挑战，因为它们具有多模态特性。Kiela 等人（2020）引入了仇恨表情包挑战，这是一个用于多模态仇恨检测的大规模数据集和基准。这项工作强调了整合文本和视觉元素的重要性，以便识别表情包中的仇恨言论[[23](https://arxiv.org/html/2409.07246v2#bib.bib23)]。为了解决低资源语言的问题，也已经开发了多种语言的数据集[[22](https://arxiv.org/html/2409.07246v2#bib.bib22)]。在[[31](https://arxiv.org/html/2409.07246v2#bib.bib31)]中，作者提供了有关多模态和有害表情包的详细调查，强调了该问题的重要性，并提出了未来的研究方向。
- en: 2.3 Multi-Agent Systems in Content Analysis
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 内容分析中的多智能体系统
- en: The application of multi-agent systems to content analysis is an emerging field,
    which could be an effective approach in analyzing complex narratives across various
    media [[17](https://arxiv.org/html/2409.07246v2#bib.bib17)]. Chen et al. (2021)
    introduced a dynamic content moderation system using multi-agent reinforcement
    learning, which adapts based on user interactions and content patterns for improved
    detection of harmful content [[7](https://arxiv.org/html/2409.07246v2#bib.bib7)].
    These studies emphasize the value of multi-agent systems in analyzing complex,
    often propagandistic or hateful content in memes. Building on this, our work focuses
    on Arabic memes, employing a multi-agent LLM approach. We explore the association
    between propaganda and hateful memes in low-resource settings. We employ LLMs
    as multiple agents to automate the data annotation process, demonstrating the
    utility of LLMs as data annotators in detecting hateful memes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 多代理系统在内容分析中的应用是一个新兴领域，这可能是分析各种媒体中复杂叙事的有效方法[[17](https://arxiv.org/html/2409.07246v2#bib.bib17)]。Chen等人（2021）提出了一种基于多代理强化学习的动态内容审核系统，该系统根据用户交互和内容模式进行自适应调整，以提高有害内容的检测[[7](https://arxiv.org/html/2409.07246v2#bib.bib7)]。这些研究强调了多代理系统在分析复杂的、往往带有宣传性或仇恨内容的表情包中的价值。在此基础上，我们的研究聚焦于阿拉伯语表情包，采用多代理LLM方法。我们探索了宣传与仇恨表情包之间的关联，尤其是在低资源环境下。我们使用LLM作为多个代理来自动化数据标注过程，展示了LLM作为数据标注员在检测仇恨表情包中的应用价值。
- en: 3 Dataset
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 数据集
- en: 3.1 Propagandistic Memes
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 宣传表情包
- en: For this study, we used ArAIEval-2024 dataset [[21](https://arxiv.org/html/2409.07246v2#bib.bib21)],
    which consists of approximately $\sim$3k memes, each annotated with labels as
    either propagandistic or not-propagandistic. These memes were collected from various
    social media platforms, including Facebook, Twitter, Instagram, and Pinterest.
    We have annotated each meme by three annotators, with the final label determined
    by majority vote. The text from the memes was extracted using an off-the-shelf
    OCR tool²²2[https://github.com/JaidedAI/EasyOCR](https://github.com/JaidedAI/EasyOCR),
    followed by manual corrections for propagandistic memes. The distribution of propagandistic
    and not-propagandistic labels is 40% and 60%, respectively. Further details about
    this dataset are available in [[21](https://arxiv.org/html/2409.07246v2#bib.bib21)],
    and the comprehensive annotation guidelines are provided in [[3](https://arxiv.org/html/2409.07246v2#bib.bib3)].
    For the experiments, the dataset is split into 70%, 10%, and 20% for training,
    development, and testing, respectively.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们使用了ArAIEval-2024数据集[[21](https://arxiv.org/html/2409.07246v2#bib.bib21)]，该数据集包含约$\sim$3k个表情包，每个表情包都标注为宣传性或非宣传性。这些表情包收集自各种社交媒体平台，包括Facebook、Twitter、Instagram和Pinterest。我们由三名标注员对每个表情包进行标注，最终标签由多数票决定。表情包中的文本通过一款现成的OCR工具提取²²2[https://github.com/JaidedAI/EasyOCR](https://github.com/JaidedAI/EasyOCR)，并对宣传性表情包进行了人工修正。宣传性和非宣传性标签的分布分别为40%和60%。该数据集的更多详细信息请参见[[21](https://arxiv.org/html/2409.07246v2#bib.bib21)]，而全面的标注指南见[[3](https://arxiv.org/html/2409.07246v2#bib.bib3)]。在实验中，数据集按70%、10%和20%的比例划分为训练集、开发集和测试集。
- en: '![Refer to caption](img/4a8672b0864cbf61b2a543884d9accc6.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4a8672b0864cbf61b2a543884d9accc6.png)'
- en: 'Figure 1: Experimental pipeline with LLM agents as annotators and consolidator.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：使用LLM代理作为标注员和汇总员的实验流程。
- en: 3.2 Hatefulness and Fine-grained Categories
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 仇恨内容及细粒度分类
- en: 'For the hatefulness and their fine-grained categorization we used ArAIEval-2024
    dataset, mentioned earlier. Our motivation to use ArAIEval-2024 dataset is that
    this is the only meme dataset currently available for Arabic, which has already
    been annotated for propagandistic content. Another motivation was to understand
    the association between propagandistic and hateful memes. In Figure [1](https://arxiv.org/html/2409.07246v2#S3.F1
    "Figure 1 ‣ 3.1 Propagandistic Memes ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal
    Analysis of Arabic Memes with Multi-Agent LLMs"), we provide full pipeline for
    the data preparation to classification experiments.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于仇恨内容及其细粒度分类，我们使用了前面提到的ArAIEval-2024数据集。我们选择使用ArAIEval-2024数据集的原因是，这是目前唯一可用的阿拉伯语表情包数据集，且已对其进行过宣传内容的标注。另一个动机是理解宣传内容与仇恨表情包之间的关联。在图[1](https://arxiv.org/html/2409.07246v2#S3.F1
    "图 1 ‣ 3.1 宣传表情包 ‣ 3 数据集 ‣ 从宣传到仇恨：基于多代理LLM的阿拉伯语表情包多模态分析")中，我们提供了从数据准备到分类实验的完整流程。
- en: 3.2.1 LLM Agents as Annotators
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 LLM代理作为标注员
- en: 'To employ LLM agents as annotators, we selected three well-known and top-performing
    commercial models: OpenAI’s GPT-4o [[27](https://arxiv.org/html/2409.07246v2#bib.bib27)],
    Google’s Gemini Pro (version 1.5) [[32](https://arxiv.org/html/2409.07246v2#bib.bib32)],
    and Claude 3.5 (Sonnet).³³3[https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet).
    For the annotation process, we use the same manual procedure discussed in [[18](https://arxiv.org/html/2409.07246v2#bib.bib18)],
    which involves a two-phase approach. In the first phase, known as the annotation
    phase, three annotators independently annotate memes following the guidelines
    outlined in [3.2.2](https://arxiv.org/html/2409.07246v2#S3.SS2.SSS2 "3.2.2 Manual
    Annotation ‣ 3.2 Hatefulness and Fine-grained Categories ‣ 3 Dataset ‣ Propaganda
    to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs"). In the
    second phase, known as the consolidation phase, we review and resolve any disagreements
    from the annotations received during the first phase. As illustrated in the figure,
    highlighted in dark red, we employ LLM agents as annotators in the first phase
    and as a consolidator in the second phase. For each phase, we use a specific prompt
    in a zero-shot setup for the LLM agent. Following the annotation guidelines discussed
    below, we ask an LLM agent to perform two tasks: (Task 1) label each meme as hateful
    or not-hateful, and (Task 2) based on the label from Task 1, provide a fine-grained
    categorization. For example, if a meme is categorized as hateful in Task 1, it
    should then provide a fine-grained label from one of the eight categories mentioned
    below. The prompt in the second phase is slightly different. Here, the task also
    involves considering the labels obtained from the first phase to make a final
    decision. For this phase, we have experimented with using GPT-4o as the consolidator.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '为了使用LLM代理作为标注员，我们选择了三种知名且表现优异的商业模型：OpenAI的GPT-4o [[27](https://arxiv.org/html/2409.07246v2#bib.bib27)]，Google的Gemini
    Pro（版本1.5）[[32](https://arxiv.org/html/2409.07246v2#bib.bib32)]，以及Claude 3.5（Sonnet）。³³3[https://www.anthropic.com/news/claude-3-5-sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)。在标注过程中，我们使用与[[18](https://arxiv.org/html/2409.07246v2#bib.bib18)]中讨论的相同手动程序，该程序采用了两阶段的方法。在第一阶段，称为标注阶段，三名标注员独立地根据[3.2.2](https://arxiv.org/html/2409.07246v2#S3.SS2.SSS2
    "3.2.2 Manual Annotation ‣ 3.2 Hatefulness and Fine-grained Categories ‣ 3 Dataset
    ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs")中列出的指南标注表情包。在第二阶段，称为合并阶段，我们审核并解决在第一阶段标注过程中出现的任何分歧。如图所示，图中的深红色部分突出显示了我们在第一阶段使用LLM代理作为标注员，在第二阶段则使用LLM代理作为合并员。在每个阶段，我们为LLM代理提供了一个零样本设置的特定提示。根据下面讨论的标注指南，我们要求LLM代理执行两项任务：（任务1）标注每个表情包为“仇恨”或“非仇恨”；（任务2）根据任务1中的标签，提供细粒度的分类。例如，如果任务1中标注为“仇恨”，则应根据下面提到的八个类别之一提供细粒度标签。第二阶段的提示略有不同。这里的任务还涉及考虑第一阶段获得的标签以做出最终决策。在这一阶段，我们尝试使用GPT-4o作为合并员。'
- en: We used this LLM-based multi-agent approach for the training and development
    (dev) sets. To validate the quality of the multi-agent approach, we quantified
    the labels provided by each LLM agent by comparing them with human-annotated labels
    on the test dataset.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这种基于LLM的多代理方法来处理训练集和开发集（dev）。为了验证多代理方法的质量，我们通过将每个LLM代理提供的标签与测试数据集上的人工标注标签进行比较，量化了这些标签的质量。
- en: 3.2.2 Manual Annotation
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 手动标注
- en: 'To verify the LLM-based multi-agent approach, we manually annotated a test
    set from the ArAIEval-2024 dataset, as shown in Figure [1](https://arxiv.org/html/2409.07246v2#S3.F1
    "Figure 1 ‣ 3.1 Propagandistic Memes ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal
    Analysis of Arabic Memes with Multi-Agent LLMs"). For the annotation process,
    we developed a set of instructions, which are discussed below. The typical approach
    to annotation involves two to three annotators. However, for this study, we relied
    on a single annotator who had prior experience with similar annotation tasks.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '为了验证基于LLM的多代理方法，我们手动标注了来自ArAIEval-2024数据集的一个测试集，如图[1](https://arxiv.org/html/2409.07246v2#S3.F1
    "Figure 1 ‣ 3.1 Propagandistic Memes ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal
    Analysis of Arabic Memes with Multi-Agent LLMs")所示。为了标注过程，我们制定了一套说明，下面将讨论这些说明。典型的标注方法通常涉及两到三名标注员。然而，对于本研究，我们依赖于一名具有类似标注经验的标注员。'
- en: 3.2.3 Annotation Instructions
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 标注说明
- en: 'The purpose of this annotation is to identify whether a meme is hateful or
    not-hateful. A hateful meme can attack different individuals, organizations or
    entities. Therefore, another task is identifying the attack types. A non-hateful
    meme can be humorous or sarcastic. Therefore, the idea to also identify the sub-categories
    within non-hateful memes. We adopted the annotation definition and instructions
    from prior work [[23](https://arxiv.org/html/2409.07246v2#bib.bib23), [25](https://arxiv.org/html/2409.07246v2#bib.bib25)].
    Below we provide the definitions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该注释的目的是识别一个表情包是仇恨的还是非仇恨的。仇恨表情包可能会攻击不同的个人、组织或实体。因此，另一个任务是识别攻击类型。非仇恨表情包可能具有幽默或讽刺的性质。因此，目的是识别非仇恨表情包中的子类别。我们采用了先前工作中的注释定义和说明
    [[23](https://arxiv.org/html/2409.07246v2#bib.bib23), [25](https://arxiv.org/html/2409.07246v2#bib.bib25)]。以下是我们的定义：
- en: 'Hateful:'
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 仇恨：
- en: A direct or indirect attack on individuals based on characteristics such as
    ethnicity, race, nationality, immigration status, religion, caste, sex, gender
    identity, sexual orientation, disability, or disease. We define an attack as hate-speech
    that is violent, dehumanizing (such as comparing individuals to non-human entities
    like animals), involves statements of inferiority, or calls for exclusion or segregation.
    Mocking hate crimes is also classified as hate speech. However, attacks directed
    at groups that perpetuate hate (e.g., terrorist organizations) are not considered
    hate speech.⁴⁴4[https://transparency.meta.com/en-gb/policies/community-standards/hate-speech/](https://transparency.meta.com/en-gb/policies/community-standards/hate-speech/)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 针对个人进行的直接或间接攻击，通常基于种族、民族、国籍、移民身份、宗教、种姓、性别、性别认同、性取向、残疾或疾病等特征。我们将攻击定义为仇恨言论，表现为暴力、去人性化（如将个体与非人类实体如动物进行比较）、贬低或提倡排斥或隔离的言论。嘲笑仇恨犯罪也被归类为仇恨言论。然而，针对那些传播仇恨的群体（例如恐怖组织）的攻击不被视为仇恨言论。⁴⁴4[https://transparency.meta.com/en-gb/policies/community-standards/hate-speech/](https://transparency.meta.com/en-gb/policies/community-standards/hate-speech/)
- en: 'Fine-grained categories hatefulness:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 细粒度类别的仇恨性：
- en: •
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dehumanizing: Explicitly or implicitly portraying or describing a group as
    subhuman.'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 去人性化：明确或隐含地将某个群体描述为非人类。
- en: •
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Inferiority: Asserting that a group is inferior, less worthy, or less important
    than society as a whole or compared to another group.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 劣等：宣称某个群体低人一等、价值较低或不如整个社会或其他群体。
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Inciting violence: Explicitly or implicitly advocating for harm to be inflicted
    on a group, including physical violence.'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 煽动暴力：明确或隐含地提倡对某个群体实施伤害，包括身体暴力。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Mocking: Joking about, ridiculing, demeaning, or disparaging a group.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 嘲笑：开玩笑、讽刺、贬低或轻视某个群体。
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Contempt: Expressing strong negative emotions or feelings toward a group.'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 蔑视：对某个群体表达强烈的负面情绪或感觉。
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Slurs: Using biased or derogatory terms to refer to, describe, or characterize
    a group.'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 辱骂：使用带有偏见或贬义的词语来指代、描述或刻画某个群体。
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Exclusion: Advocating for, planning, or justifying the exclusion or segregation
    of a group from society as a whole or from specific areas.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 排斥：提倡、计划或为某个群体在整个社会或特定领域内的排斥或隔离辩护。
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Other: None of the above.'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其他：以上都不适用。
- en: 'Not-Hateful:'
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 非仇恨：
- en: The content is humorous, neutral, or positive, without targeting or harming
    specific individuals or groups. It is light-hearted and intended for entertainment
    without being offensive. Additionally, the content does not promote or incite
    violence, hatred, or discrimination.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 内容具有幽默感、中立或积极，且没有针对或伤害特定的个人或群体。它是轻松愉快的，旨在娱乐而不冒犯人。此外，内容不宣传或煽动暴力、仇恨或歧视。
- en: 'Fine-grained not-hateful categories:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 细粒度的非仇恨类别：
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Humor: The purpose of humor is to entertain, amuse, or bring joy to the audience.
    Often characterized by jokes, puns, or playful language. Humor can vary widely
    in style, including wit, slapstick, parody, and satire.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 幽默：幽默的目的是为了娱乐、逗乐或给观众带来欢乐。通常以笑话、双关语或俏皮的语言为特征。幽默的风格差异很大，可以包括机智、滑稽、模仿和讽刺等。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sarcasm: Typically involves saying the opposite of what one means. Sarcasm
    is a form of irony that always occurs with a deliberate mismatch between what
    is said and what is meant, intentionally to ridicule or mock a specific target.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 讽刺：通常是指说出与自己真正意思相反的话。讽刺是一种具有讽刺意味的表达形式，总是通过言语与意思之间故意的不匹配来进行，目的是嘲笑或讽刺特定的对象。
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Other: None of the above'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其他：以上都不适用
- en: 3.2.4 Annotated Dataset
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.4 注释数据集
- en: 'As discussed in Section [3.2.1](https://arxiv.org/html/2409.07246v2#S3.SS2.SSS1
    "3.2.1 LLM Agents as Annotators ‣ 3.2 Hatefulness and Fine-grained Categories
    ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs"), we annotated the test data into ‘Hateful’ and ‘Not-Hateful’ categories
    using GPT-4o, Sonnet (Claude 3.5), and Gemini (Vertex). We then provided the three
    annotated labels (obtained from GPT-4o, Sonnet, and Gemini) as prompts to GPT-4o
    and asked it to choose the best label that matches the data. The generated output
    label is termed GPT-4o consolidation. Table [1](https://arxiv.org/html/2409.07246v2#S3.T1
    "Table 1 ‣ 3.2.4 Annotated Dataset ‣ 3.2 Hatefulness and Fine-grained Categories
    ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs") shows the inter-annotator agreement (IAA) among the annotators. We computed
    the annotation agreement using pairwise Cohen’s kappa score in different setups:
    (i) LLMs as annotators vs. an LLM as a consolidator, (ii) LLMs as annotators vs.
    human annotation, and (iii) pairwise between LLMs as annotators.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '如第[3.2.1节](https://arxiv.org/html/2409.07246v2#S3.SS2.SSS1 "3.2.1 LLM Agents
    as Annotators ‣ 3.2 Hatefulness and Fine-grained Categories ‣ 3 Dataset ‣ Propaganda
    to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs")所讨论，我们使用GPT-4o、Sonnet（Claude
    3.5）和Gemini（Vertex）将测试数据注释为“仇恨”和“非仇恨”类别。然后，我们将三个注释标签（从GPT-4o、Sonnet和Gemini获得）作为提示提供给GPT-4o，并要求它选择最匹配数据的标签。生成的输出标签被称为GPT-4o汇总。表格[1](https://arxiv.org/html/2409.07246v2#S3.T1
    "Table 1 ‣ 3.2.4 Annotated Dataset ‣ 3.2 Hatefulness and Fine-grained Categories
    ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs")显示了注释者之间的一致性（IAA）。我们通过不同的设置计算了注释一致性，使用的是成对Cohen’s kappa得分：（i）LLMs作为注释者与LLM作为汇总者，（ii）LLMs作为注释者与人工注释，（iii）LLMs作为注释者之间的成对一致性。'
- en: It shows that the IAA between GPT-4o and GPT-4o consolidation is high (0.786),
    representing substantial agreement. It is reasonable because the GPT-4o consolidation
    is derived from the GPT-4o, which means that the consolidated label inherently
    aligns closely with the labels initially provided by GPT-4o. Interestingly, we
    observe that the IAA between Sonnet and GPT-4o consolidation is significant and
    high (0.701), which denotes Sonnet’s capability to understand hateful content
    and memes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示了GPT-4o和GPT-4o汇总之间的IAA很高（0.786），表明有显著的一致性。这是合理的，因为GPT-4o汇总是从GPT-4o派生出来的，这意味着汇总标签本质上与GPT-4o最初提供的标签紧密对齐。有趣的是，我们观察到Sonnet和GPT-4o汇总之间的IAA显著且很高（0.701），这表明Sonnet能够理解仇恨内容和表情包。
- en: 'Table [1](https://arxiv.org/html/2409.07246v2#S3.T1 "Table 1 ‣ 3.2.4 Annotated
    Dataset ‣ 3.2 Hatefulness and Fine-grained Categories ‣ 3 Dataset ‣ Propaganda
    to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs") shows that
    the IAA between Sonnet and the human annotator achieved a higher score (0.405)
    compared to other annotation labels. We also performed pairwise agreements among
    LLM annotators and found that the agreement between Sonnet and GPT-4o is higher
    (0.528). Finally, we measured the annotation agreement among all three annotators
    and obtained a score of 0.369.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '表[1](https://arxiv.org/html/2409.07246v2#S3.T1 "Table 1 ‣ 3.2.4 Annotated Dataset
    ‣ 3.2 Hatefulness and Fine-grained Categories ‣ 3 Dataset ‣ Propaganda to Hate:
    A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs")显示，Sonnet与人工注释者之间的IAA得分（0.405）高于其他注释标签。我们还进行了LLM注释者之间的成对一致性测量，发现Sonnet与GPT-4o之间的一致性较高（0.528）。最后，我们测量了所有三个注释者之间的注释一致性，得到了0.369的得分。'
- en: The annotation agreements between the three different LLMs and the human annotator
    suggest that Sonnet has a fair capability of understanding ‘Hateful’ content compared
    to a human annotator. Therefore, we used Sonnet to annotate the training and development
    datasets.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 三个不同的LLM和人工注释者之间的注释一致性表明，Sonnet在理解“仇恨”内容方面与人工注释者相比具有一定的能力。因此，我们使用Sonnet来注释训练和开发数据集。
- en: 'Table 1: Annotation agreement for different setups.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：不同设置下的注释一致性。
- en: '| Anno. 1 | Anno. 2 | Kappa | Anno. 1 | Anno. 2 | Kappa |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 注释者1 | 注释者2 | Kappa | 注释者1 | 注释者2 | Kappa |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Agreement: LLMs vs. LLM as a Consolidator | Agreement: LLMs vs Human |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 一致性：LLMs与LLM作为汇总者 | 一致性：LLMs与人工 |'
- en: '| --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| GPT-4o | GPT-4o | 0.786 | GPT-4o | Human | 0.233 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | GPT-4o | 0.786 | GPT-4o | Human | 0.233 |'
- en: '| Sonnet (Claude) | GPT-4o | 0.701 | Claude-3.5 (Sonnet) | Human | 0.405 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Sonnet (Claude) | GPT-4o | 0.701 | Claude-3.5 (Sonnet) | Human | 0.405 |'
- en: '| Gemini-1.5 (Vertex) | GPT-4o | 0.236 | Gemini-1.5 (Vertex) | Human | 0.300
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5 (Vertex) | GPT-4o | 0.236 | Gemini-1.5 (Vertex) | Human | 0.300
    |'
- en: '| Agreement: LLMs (Pairwise) | GPO-4o Consolidation | Human | 0.300 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 一致性：大语言模型（成对） | GPO-4o 合并 | 人类 | 0.300 |'
- en: '| Gemini-1.5 (Vertex) | Claude-3.5 (Sonnet) | 0.266 |  |  |  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Gemini-1.5 (Vertex) | Claude-3.5 (Sonnet) | 0.266 |  |  |  |'
- en: '| GPT-4o | Gemini-1.5 (Vertex) | 0.142 |  |  |  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | Gemini-1.5 (Vertex) | 0.142 |  |  |  |'
- en: '| Claude-3.5 (Sonnet) | GPT-4o | 0.528 |  |  |  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Claude-3.5 (Sonnet) | GPT-4o | 0.528 |  |  |  |'
- en: 'Data Stat: Hateful Meme Table [2](https://arxiv.org/html/2409.07246v2#S3.T2
    "Table 2 ‣ 3.2.4 Annotated Dataset ‣ 3.2 Hatefulness and Fine-grained Categories
    ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs") presents the distribution of class labels for training, development, and
    testing datasets, categorized into “Hate/Not-hate” and further labeled into fine-grained
    categories. There is a significantly larger number of “Not-Hateful” (N=1931) category
    instances compared to the “Hateful” (N=212) category. In the fine-grained label,
    “Mocking” has a notable presence (N=133) in the ‘Hateful’ category. Similarly,
    in the fine-grained “Not-Hateful” categories, “Humor” (N=1815) overwhelmingly
    dominates, followed by “Sarcasm”. This distribution highlights the imbalance in
    the data.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 数据统计：仇恨表情包表 [2](https://arxiv.org/html/2409.07246v2#S3.T2 "表 2 ‣ 3.2.4 标注数据集
    ‣ 3.2 仇恨与细粒度类别 ‣ 3 数据集 ‣ 从宣传到仇恨：使用多代理大语言模型对阿拉伯表情包进行的多模态分析") 提供了训练、开发和测试数据集的类别标签分布，分为“仇恨/非仇恨”并进一步标注为细粒度类别。与“仇恨”（N=212）类别相比，“非仇恨”（N=1931）类别的实例数量显著更多。在细粒度标签中，“嘲笑”在“仇恨”类别中占有显著份额（N=133）。类似地，在细粒度“非仇恨”类别中，“幽默”（N=1815）占主导地位，其次是“讽刺”。这一分布突显了数据的不平衡性。
- en: 'Table 2: Distribution of annotated data: The training and development sets
    were labeled using Sonnet, while the test set was labeled by a human.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：标注数据的分布：训练和开发集使用 Sonnet 标注，而测试集由人工标注。
- en: '| Hate/Not-hate | Hate: Fine-grained categories |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 仇恨/非仇恨 | 仇恨：细粒度类别 |'
- en: '| Label | Train | Dev | Test | Label | Train | Dev | Test |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 训练 | 开发 | 测试 | 标签 | 训练 | 开发 | 测试 |'
- en: '| Hateful | 212 | 32 | 154 | Contempt | 38 | 7 | 25 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 仇恨 | 212 | 32 | 154 | 蔑视 | 38 | 7 | 25 |'
- en: '| Not-Hateful | 1,931 | 280 | 452 | Dehumanizing | 12 | 3 | 2 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 非仇恨 | 1,931 | 280 | 452 | 去人性化 | 12 | 3 | 2 |'
- en: '| Total | 2,143 | 312 | 606 | Mocking | 133 | 19 | 49 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 2,143 | 312 | 606 | 嘲笑 | 133 | 19 | 49 |'
- en: '| Non-Hate: Fine-grained categories | Inferiority | 5 | 1 | 14 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 非仇恨：细粒度类别 | 自卑 | 5 | 1 | 14 |'
- en: '| Label | Train | Dev | Test | Exclusion | 6 | 7 | 3 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 训练 | 开发 | 测试 | 排除 | 6 | 7 | 3 |'
- en: '| Sarcasm | 105 | 19 | 118 | Inciting violence | 13 | 2 | 12 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 讽刺 | 105 | 19 | 118 | 煽动暴力 | 13 | 2 | 12 |'
- en: '| Humor | 1,815 | 260 | 334 | Slurs | 6 | 1 | 29 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 幽默 | 1,815 | 260 | 334 | 侮辱 | 6 | 1 | 29 |'
- en: '| Total | 1,920 | 279 | 452 | Other | 10 | 1 | 20 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 1,920 | 279 | 452 | 其他 | 10 | 1 | 20 |'
- en: '|  |  |  |  | Total | 223 | 41 | 154 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 总计 | 223 | 41 | 154 |'
- en: 'Propaganda and Hateful Meme: To understand the correlation between propaganda
    and hateful memes, we observe that out of 171 propagandistic memes in the test
    set, 56 memes are hateful (30%) and 70% are not hateful. This is possible because
    propagandistic memes may not always instigate hate or harm.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 宣传和仇恨表情包：为了理解宣传与仇恨表情包之间的关联，我们观察到，在测试集中有 171 个宣传表情包，其中 56 个是仇恨的（30%），70% 不是仇恨的。这是因为宣传表情包不一定总是煽动仇恨或伤害。
- en: 4 Experiments
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 'Our experiments consist of three setups: (i) hate vs. not-hate, (ii) fine-grained
    categories for hateful memes, and (iii) fine-grained categories for non-hateful
    memes. These classification experiments involve unimodal (text and image) and
    multimodal classifications.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验包括三个设置：(i) 仇恨与非仇恨，(ii) 仇恨表情包的细粒度类别，以及 (iii) 非仇恨表情包的细粒度类别。这些分类实验涉及单模态（文本和图像）和多模态分类。
- en: 'Text classification: We extracted text from propagandistic memes and applied
    various text classification techniques such as AraBERT, mBERT, CAMelBERT, and
    Qarib-BERT ([[6](https://arxiv.org/html/2409.07246v2#bib.bib6), [11](https://arxiv.org/html/2409.07246v2#bib.bib11),
    [1](https://arxiv.org/html/2409.07246v2#bib.bib1)]). The original dataset is imbalanced,
    and so we implemented a class weighting scheme during the fine-tuning process.
    Moreover, we optimized the model by adjusting the dropout rate. This approach
    led to significant improvements over using the original dataset alone. We embedded
    the LoRa to fine-tune the model in an efficient way that does not require fine-tuning
    all the parameters of the model. However, embedding LoRA did not improve the performance.
    We then fine-tuned AraBERT model.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类：我们从宣传性迷因中提取了文本，并应用了多种文本分类技术，如AraBERT、mBERT、CAMelBERT和Qarib-BERT（[[6](https://arxiv.org/html/2409.07246v2#bib.bib6),
    [11](https://arxiv.org/html/2409.07246v2#bib.bib11), [1](https://arxiv.org/html/2409.07246v2#bib.bib1)]）。原始数据集存在不平衡问题，因此在微调过程中我们实施了类别加权方案。此外，我们通过调整丢弃率优化了模型。与仅使用原始数据集相比，这种方法显著提高了性能。我们嵌入了LoRa，以一种不需要微调所有模型参数的高效方式微调模型。然而，嵌入LoRA并未提升性能。接着，我们对AraBERT模型进行了微调。
- en: 'Image classification: We fine-tuned ResNet50 and ConvNeXt-tiny [[24](https://arxiv.org/html/2409.07246v2#bib.bib24)].
    To ensure stable weight adjustments, we froze the feature extraction layers and
    fine-tuned the classification layer. We also adjusted the dropout rate during
    the model training.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类：我们对ResNet50和ConvNeXt-tiny进行了微调[[24](https://arxiv.org/html/2409.07246v2#bib.bib24)]。为了确保稳定的权重调整，我们冻结了特征提取层，并对分类层进行了微调。我们还在模型训练过程中调整了丢弃率。
- en: 'Multimodal classification: To extract visual and text features, we applied
    ConvNext tiny and AraBERT models respectively. We combine the features using a
    fusion layer. We froze the visual models and trained the classification layer
    with textual data. We also used a dropout rate to improve the performance.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态分类：为了提取视觉和文本特征，我们分别应用了ConvNext tiny和AraBERT模型。我们通过融合层将特征进行结合。我们冻结了视觉模型，只用文本数据训练分类层。我们还使用了丢弃率来提高性能。
- en: 'Experimental Setup: We performed all of our experiments and trained our models
    on an Nvidia-RTX 2080 GPU. We employed the Adam optimizer with an initial learning
    rate of 1e-5 and 1e-4 for text and image, respectively. We used a batch size of
    32, a sequence length of 128\. We set the dropout rate to 0.25 for text data and
    trained for 50 epochs. For image data, we set a dropout rate of 0.5 and trained
    for 30 epochs. For multimodal data, we trained the model for 100 epochs with a
    stochastic drop rate of 0.2\. Note that our choice of the models and parameters
    was inspired by prior studies [[3](https://arxiv.org/html/2409.07246v2#bib.bib3),
    [30](https://arxiv.org/html/2409.07246v2#bib.bib30)].'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置：我们在Nvidia-RTX 2080 GPU上执行了所有实验，并训练了我们的模型。我们使用了Adam优化器，文本和图像的初始学习率分别为1e-5和1e-4。我们使用了批量大小为32，序列长度为128。我们将文本数据的丢弃率设置为0.25，训练了50个周期。对于图像数据，我们将丢弃率设置为0.5，并训练了30个周期。对于多模态数据，我们使用0.2的随机丢弃率训练了100个周期。请注意，我们选择的模型和参数受到先前研究的启发[[3](https://arxiv.org/html/2409.07246v2#bib.bib3),
    [30](https://arxiv.org/html/2409.07246v2#bib.bib30)]。
- en: 'Table 3: Classification results on the test set for coarse and fine-grained
    hate labels across different modality setups.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：不同模态设置下粗粒度和细粒度仇恨标签在测试集上的分类结果。
- en: '| Modality | Model | Acc | M-F1 | Modality | Model | Acc | M-F1 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 模态 | 模型 | 准确率 | M-F1 | 模态 | 模型 | 准确率 | M-F1 |'
- en: '| Hate vs. Not-hate | Balanced dataset: Hate vs. Not-hate |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 仇恨与非仇恨 | 平衡数据集：仇恨与非仇恨 |'
- en: '| Text | AraBERT | 0.819 | 0.705 | Balanced | Fusion | 0.817 | 0.709 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | AraBERT | 0.819 | 0.705 | 平衡 | 融合 | 0.817 | 0.709 |'
- en: '| Image | ConvNxT | 0.779 | 0.669 | Fine-grained label |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | ConvNxT | 0.779 | 0.669 | 细粒度标签 |'
- en: '| Text+Image | Fusion | 0.764 | 0.709 | Hateful | Fusion | 0.224 | 0.166 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 文本+图像 | 融合 | 0.764 | 0.709 | 仇恨 | 融合 | 0.224 | 0.166 |'
- en: '|  |  |  |  | Not-Hateful | Fusion | 0.622 | 0.537 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 非仇恨 | 融合 | 0.622 | 0.537 |'
- en: 5 Results and Discussion
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结果与讨论
- en: 'In Table [3](https://arxiv.org/html/2409.07246v2#S4.T3 "Table 3 ‣ 4 Experiments
    ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs"),
    we present the results for different classification setups. For hate vs. not-hate
    classification across different modalities, considering macro-F1, the text and
    multimodal models exhibit similar performance. For the multimodal model, we obtained
    model with a macro-F1 of 0.709 and an accuracy of 0.764\. For the text modality,
    we obtained a macro-F1 of 0.705 and an accuracy of 0.818\. For the image modality,
    we obtained a macro-F1 of 0.669 and an accuracy of 0.775.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '在表格[3](https://arxiv.org/html/2409.07246v2#S4.T3 "Table 3 ‣ 4 Experiments ‣
    Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs")中，我们展示了不同分类设置的结果。对于跨多种模态的仇恨与非仇恨分类，考虑到宏观F1分数，文本和多模态模型表现相似。对于多模态模型，我们获得了宏观F1分数为0.709，准确率为0.764。对于文本模态，我们获得了宏观F1分数为0.705，准确率为0.818。对于图像模态，我们获得了宏观F1分数为0.669，准确率为0.775。'
- en: 'To understand the class imbalance issue, we selected 500 propaganda labels
    and 500 non-propaganda labels from the dataset and applied the fusion model. This
    yielded a macro-F1 of 0.709 and an accuracy of 0.818\. The hateful memes were
    further fine-grained into eight labels, while the non-hateful memes were fine-grained
    into two labels, as shown in Table [2](https://arxiv.org/html/2409.07246v2#S3.T2
    "Table 2 ‣ 3.2.4 Annotated Dataset ‣ 3.2 Hatefulness and Fine-grained Categories
    ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs"). We applied the fusion model individually to the hateful and non-hateful
    fine-grained labels. The F1-score for the hateful fine-grained memes is 0.224,
    with an accuracy of 0.166, which is very low. This occurs because there are multiple
    labels within the hateful category, and the dataset is imbalanced for fine-grained
    hateful memes. In contrast, with only two labels in the non-hateful memes, the
    model performs better in classification, achieving a macro-F1 of 0.537 and an
    accuracy of 0.622.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '为了理解类别不平衡问题，我们从数据集中选择了500个宣传标签和500个非宣传标签，并应用了融合模型。此模型得到了宏观F1分数为0.709，准确率为0.818。仇恨表情包进一步细分为八个标签，而非仇恨表情包则细分为两个标签，如表格[2](https://arxiv.org/html/2409.07246v2#S3.T2
    "Table 2 ‣ 3.2.4 Annotated Dataset ‣ 3.2 Hatefulness and Fine-grained Categories
    ‣ 3 Dataset ‣ Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent
    LLMs")所示。我们分别对仇恨和非仇恨细粒度标签应用了融合模型。仇恨细粒度表情包的F1分数为0.224，准确率为0.166，表现较差。这是因为仇恨类别中包含多个标签，且数据集在细粒度仇恨表情包方面不平衡。相比之下，由于非仇恨表情包只有两个标签，模型在分类上表现更好，达到了宏观F1分数0.537，准确率0.622。'
- en: 6 Conclusion and Future Work
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论与未来工作
- en: In this study, we investigate whether the content in propagandistic memes may
    contain hate. To do so, we used a multi-agent LLM-based approach to label propagandistic
    memes with coarse and fine-grained hate categories. We observed that there is
    a moderate agreement between an LLM agent (Claude 3.5 Sonnet) and human annotation.
    This led us to label propagandistic memes with coarse and fine-grained hate categories.
    We further used the dataset to train the model and evaluate its performance on
    the test set. The developed dataset is skewed in nature, which also reflects its
    classification performance. It is important to note that this attempt can enable
    the development of a large-scale dataset in a cost-effective manner. The issue
    of label imbalance can be resolved with an increase in data size. Future study
    will investigate this direction further by increasing data size and exploring
    open-sourced LLMs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们调查了宣传性表情包中的内容是否可能包含仇恨。为此，我们使用基于多代理LLM的方法，对宣传性表情包进行了粗略和细粒度的仇恨类别标签。我们观察到LLM代理（Claude
    3.5 Sonnet）与人工标注之间存在中等程度的一致性。这促使我们对宣传性表情包进行了粗略和细粒度的仇恨类别标签。随后，我们使用该数据集训练模型，并在测试集上评估其性能。开发的数据集本身具有偏斜性，这也反映了其分类性能。值得注意的是，这一尝试可以以成本效益高的方式促使大规模数据集的开发。标签不平衡问题可以通过增加数据量来解决。未来的研究将通过增加数据量并探索开源LLM，进一步探讨这一方向。
- en: 7 Acknowledgments
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 致谢
- en: The work of F. Alam, M. R. Biswas, U. Shah, W. Zaghouani and G. Mikros is partially
    supported by NPRP 14C-0916-210015 from the Qatar National Research Fund, part
    of Qatar Research Development and Innovation Council (QRDI).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: F. Alam、M. R. Biswas、U. Shah、W. Zaghouani和G. Mikros的研究部分得到了卡塔尔国家研究基金（NPRP 14C-0916-210015）的资助，该基金是卡塔尔研究发展与创新委员会（QRDI）的一部分。
- en: References
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Abdelali, A., Hassan, S., Mubarak, H., Darwish, K., Samih, Y.: Pre-Training
    BERT on Arabic tweets: Practical considerations (2021)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Abdelali, A., Hassan, S., Mubarak, H., Darwish, K., Samih, Y.: 在阿拉伯语推特上预训练BERT：实践考虑（2021年）'
- en: '[2] Alam, F., Cresci, S., Chakraborty, T., Silvestri, F., Dimitrov, D., Martino,
    G.D.S., Shaar, S., Firooz, H., Nakov, P.: A survey on multimodal disinformation
    detection. In: Proceedings of the 29th International Conference on Computational
    Linguistics. pp. 6625–6643 (Oct 2022)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Alam, F., Cresci, S., Chakraborty, T., Silvestri, F., Dimitrov, D., Martino,
    G.D.S., Shaar, S., Firooz, H., Nakov, P.: 多模态虚假信息检测调查。载于：第29届国际计算语言学大会论文集，pp.
    6625–6643（2022年10月）'
- en: '[3] Alam, F., Hasnat, A., Ahmed, F., Hasan, M.A., Hasanain, M.: ArMeme: Propagandistic
    content in arabic memes. In: Proceedings of the 2024 Conference on Empirical Methods
    in Natural Language Processing (Dec 2024)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Alam, F., Hasnat, A., Ahmed, F., Hasan, M.A., Hasanain, M.: ArMeme：阿拉伯语迷因中的宣传内容。载于：2024年自然语言处理经验方法会议论文集（2024年12月）'
- en: '[4] Alam, F., Mubarak, H., Zaghouani, W., Da San Martino, G., Nakov, P.: Overview
    of the WANLP 2022 shared task on propaganda detection in Arabic. In: Proceedings
    of the Seventh Arabic Natural Language Processing Workshop (Dec 2022)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Alam, F., Mubarak, H., Zaghouani, W., Da San Martino, G., Nakov, P.: WANLP
    2022共享任务：阿拉伯语宣传检测概述。载于：第七届阿拉伯语自然语言处理研讨会论文集（2022年12月）'
- en: '[5] Alam, F., Mubarak, H., Zaghouani, W., Da San Martino, G., Nakov, P.: Overview
    of the wanlp 2022 shared task on propaganda detection in arabic. In: Proceedings
    of the Seventh Arabic Natural Language Processing Workshop. pp. 108–115 (2022)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Alam, F., Mubarak, H., Zaghouani, W., Da San Martino, G., Nakov, P.: WANLP
    2022共享任务：阿拉伯语宣传检测概述。载于：第七届阿拉伯语自然语言处理研讨会论文集，pp. 108–115（2022年）'
- en: '[6] Antoun, W., Baly, F., Hajj, H.: AraBERT: Transformer-based model for Arabic
    language understanding. In: Proceedings of the 4th Workshop on Open-Source Arabic
    Corpora and Processing Tools. OSAC ’20, Marseille, France (2020)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Antoun, W., Baly, F., Hajj, H.: AraBERT：基于变换器的阿拉伯语言理解模型。载于：第四届开源阿拉伯语语料库与处理工具研讨会论文集。OSAC
    ’20，法国马赛（2020年）'
- en: '[7] Chen, J., Wu, Y., Yang, X., Liu, J., Yang, H., Wang, Z.: Multi-agent reinforcement
    learning for dynamic content moderation. In: Proceedings of the AAAI Conference
    on Artificial Intelligence. vol. 35, pp. 4536–4544 (2021)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Chen, J., Wu, Y., Yang, X., Liu, J., Yang, H., Wang, Z.: 动态内容审查的多代理强化学习。载于：AAAI人工智能会议论文集，第35卷，pp.
    4536–4544（2021年）'
- en: '[8] Da San Martino, G., Barrón-Cedeño, A., Wachsmuth, H., Petrov, R., Nakov,
    P.: Semeval-2020 task 11: Detection of propaganda techniques in news articles.
    In: Proceedings of the 14th International Workshop on Semantic Evaluation. pp.
    1377–1414 (2020)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Da San Martino, G., Barrón-Cedeño, A., Wachsmuth, H., Petrov, R., Nakov,
    P.: Semeval-2020任务11：新闻文章中的宣传技巧检测。载于：第14届国际语义评估研讨会论文集，pp. 1377–1414（2020年）'
- en: '[9] Da San Martino, G., Yu, S., Barrón-Cedeño, A., Petrov, R., Nakov, P.: Fine-grained
    analysis of propaganda in news article. In: Proceedings of the 2019 Conference
    on Empirical Methods in Natural Language Processing and the 9th International
    Joint Conference on Natural Language Processing. pp. 5636–5646\. ACL (Nov 2019)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Da San Martino, G., Yu, S., Barrón-Cedeño, A., Petrov, R., Nakov, P.: 新闻文章中宣传的精细分析。载于：2019年自然语言处理经验方法会议与第9届国际自然语言处理联合会议论文集，pp.
    5636–5646，ACL（2019年11月）'
- en: '[10] Davidson, T., Warmsley, D., Macy, M., Weber, I.: Automated hate speech
    detection and the problem of offensive language. In: Proceedings of the International
    AAAI Conference on Web and Social Media. AAAI ’17, vol. 11 (2017)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Davidson, T., Warmsley, D., Macy, M., Weber, I.: 自动化仇恨言论检测与攻击性语言问题。载于：国际AAAI网络与社交媒体会议论文集，AAAI
    ’17，第11卷（2017年）'
- en: '[11] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of
    deep bidirectional transformers for language understanding. In: Proceedings of
    the 2019 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies. pp. 4171–4186\. ACL (Jun 2019)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT：用于语言理解的深度双向变换器的预训练。载于：2019年北美计算语言学协会年会：人类语言技术会议论文集，pp.
    4171–4186，ACL（2019年6月）'
- en: '[12] Dimitrov, D., Alam, F., Hasanain, M., Hasnat, A., Silvestri, F., Nakov,
    P., Da San Martino, G.: SemEval-2024 task 4: Multilingual detection of persuasion
    techniques in memes. In: Proceedings of the 18th International Workshop on Semantic
    Evaluation. pp. 2009–2026\. ACL, Mexico City, Mexico (Jun 2024)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Dimitrov, D., Alam, F., Hasanain, M., Hasnat, A., Silvestri, F., Nakov,
    P., Da San Martino, G.: SemEval-2024任务4：在迷因中多语言识别说服技巧。载于：第18届国际语义评估研讨会论文集，pp.
    2009–2026，ACL，墨西哥城，墨西哥（2024年6月）'
- en: '[13] Dimitrov, D., Ali, B.B., Shaar, S., Alam, F., Silvestri, F., Firooz, H.,
    Nakov, P., Da San Martino, G.: Detecting propaganda techniques in memes. In: Proceedings
    of the Joint Conference of the 59th Annual Meeting of the Association for Computational
    Linguistics and the 11th International Joint Conference on Natural Language Processing.
    pp. 6603–6617\. ACL-IJCNLP ’21 (2021)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Dimitrov, D., Ali, B.B., Shaar, S., Alam, F., Silvestri, F., Firooz, H.,
    Nakov, P., Da San Martino, G.：在表情包中检测宣传技巧。载于：第59届计算语言学协会年会与第11届国际联合自然语言处理会议联合会议论文集。第6603–6617页。ACL-IJCNLP
    ’21（2021）'
- en: '[14] Dimitrov, D., Bin Ali, B., Shaar, S., Alam, F., Silvestri, F., Firooz,
    H., Nakov, P., Da San Martino, G.: Semeval-2021 task 6: Detection of persuasion
    techniques in texts and images. In: Proceedings of the 15th International Workshop
    on Semantic Evaluation (SemEval-2021). pp. 70–98 (2021)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Dimitrov, D., Bin Ali, B., Shaar, S., Alam, F., Silvestri, F., Firooz,
    H., Nakov, P., Da San Martino, G.：Semeval-2021任务6：文本和图像中说服技巧的检测。载于：第15届语义评估国际研讨会（SemEval-2021）论文集。第70–98页（2021）'
- en: '[15] Fang, T., Xu, B., Zong, L.: Emotion-enhanced multi-modal persuasive techniques
    detection using split features. In: Fuzzy Systems and Data Mining VIII, pp. 172–180\.
    IOS Press (2022)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Fang, T., Xu, B., Zong, L.：情感增强的多模态说服技巧检测，使用分裂特征。载于：模糊系统与数据挖掘第八卷，第172–180页。IOS出版社（2022）'
- en: '[16] Fortuna, P., Nunes, S.: A survey on automatic detection of hate speech
    in text. ACM Computing Surveys (CSUR) 51(4), 1–30 (2018)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Fortuna, P., Nunes, S.：关于自动检测文本中仇恨言论的调查。ACM计算调查（CSUR）51(4)，第1-30页（2018）'
- en: '[17] Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N.V., Wiest,
    O., Zhang, X.: Large language model based multi-agents: A survey of progress and
    challenges. arXiv preprint arXiv:2402.01680 (2024)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Guo, T., Chen, X., Wang, Y., Chang, R., Pei, S., Chawla, N.V., Wiest,
    O., Zhang, X.：基于大语言模型的多代理：进展与挑战的调查。arXiv预印本arXiv:2402.01680（2024）'
- en: '[18] Hasanain, M., Ahmed, F., Alam, F.: Large language models for propaganda
    span annotation. In: Proceedings of the 2024 Conference on Empirical Methods in
    Natural Language Processing (Dec 2024)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Hasanain, M., Ahmed, F., Alam, F.：大语言模型在宣传片段标注中的应用。载于：2024年自然语言处理实证方法会议论文集（2024年12月）'
- en: '[19] Hasanain, M., Ahmed, F., Alam, F.: Can GPT-4 identify propaganda? annotation
    and detection of propaganda spans in news articles. In: Proceedings of the 2024
    Joint International Conference On Computational Linguistics, Language Resources
    And Evaluation. LREC-COLING 2024, Torino, Italy (2024)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Hasanain, M., Ahmed, F., Alam, F.：GPT-4能否识别宣传？新闻文章中的宣传片段标注与检测。载于：2024年计算语言学联合国际会议、语言资源与评估会议论文集。LREC-COLING
    2024，意大利都灵（2024）'
- en: '[20] Hasanain, M., Alam, F., Mubarak, H., Abdaljalil, S., Zaghouani, W., Nakov,
    P., Da San Martino, G., Freihat, A.: ArAIEval shared task: Persuasion techniques
    and disinformation detection in Arabic text. In: Sawaf, H., El-Beltagy, S., Zaghouani,
    W., Magdy, W., Abdelali, A., Tomeh, N., Abu Farha, I., Habash, N., Khalifa, S.,
    Keleg, A., Haddad, H., Zitouni, I., Mrini, K., Almatham, R. (eds.) Proceedings
    of ArabicNLP 2023\. pp. 483–493\. ACL, Singapore (Hybrid) (Dec 2023)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Hasanain, M., Alam, F., Mubarak, H., Abdaljalil, S., Zaghouani, W., Nakov,
    P., Da San Martino, G., Freihat, A.：ArAIEval共享任务：阿拉伯语文本中的说服技巧与虚假信息检测。载于：Sawaf,
    H., El-Beltagy, S., Zaghouani, W., Magdy, W., Abdelali, A., Tomeh, N., Abu Farha,
    I., Habash, N., Khalifa, S., Keleg, A., Haddad, H., Zitouni, I., Mrini, K., Almatham,
    R.（编辑）《ArabicNLP 2023论文集》。第483–493页。ACL，新加坡（混合会议）（2023年12月）'
- en: '[21] Hasanain, M., Hasan, M.A., Ahmed, F., Suwaileh, R., Biswas, M.R., Zaghouani,
    W., Alam, F.: ArAIEval Shared Task: Propagandistic techniques detection in unimodal
    and multimodal arabic content. In: Proceedings of the Second Arabic Natural Language
    Processing Conference. ACL, Bangkok (Aug 2024)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Hasanain, M., Hasan, M.A., Ahmed, F., Suwaileh, R., Biswas, M.R., Zaghouani,
    W., Alam, F.：ArAIEval共享任务：单模态和多模态阿拉伯语内容中的宣传技巧检测。载于：第二届阿拉伯自然语言处理会议论文集。ACL，泰国曼谷（2024年8月）'
- en: '[22] Hossain, E., Sharif, O., Hoque, M.M., Preum, S.M.: Deciphering hate: Identifying
    hateful memes and their targets. arXiv preprint arXiv:2403.10829 (2024)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Hossain, E., Sharif, O., Hoque, M.M., Preum, S.M.：解密仇恨：识别仇恨表情包及其目标。arXiv预印本arXiv:2403.10829（2024）'
- en: '[23] Kiela, D., Firooz, H., Mohan, A., Goswami, V., Singh, A., Ringshia, P.,
    Testuggine, D.: The hateful memes challenge: Detecting hate speech in multimodal
    memes. In: Advances in Neural Information Processing Systems. vol. 33, pp. 2611–2624
    (2020)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Kiela, D., Firooz, H., Mohan, A., Goswami, V., Singh, A., Ringshia, P.,
    Testuggine, D.：仇恨表情包挑战：在多模态表情包中检测仇恨言论。载于：神经信息处理系统进展，第33卷，第2611–2624页（2020）'
- en: '[24] Liu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell, T., Xie, S.: A
    convnet for the 2020s. In: Proceedings of the IEEE/CVF conference on computer
    vision and pattern recognition. pp. 11976–11986 (2022)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Liu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell, T., Xie, S.: 面向2020年代的卷积网络。在：IEEE/CVF计算机视觉与模式识别会议论文集。第11976–11986页
    (2022)'
- en: '[25] Mathias, L., Nie, S., Mostafazadeh Davani, A., Kiela, D., Prabhakaran,
    V., Vidgen, B., Waseem, Z.: Findings of the WOAH 5 shared task on fine grained
    hateful memes detection. In: Mostafazadeh Davani, A., Kiela, D., Lambert, M.,
    Vidgen, B., Prabhakaran, V., Waseem, Z. (eds.) Proceedings of the 5th Workshop
    on Online Abuse and Harms (WOAH 2021). pp. 201–206\. ACL, Online (Aug 2021)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Mathias, L., Nie, S., Mostafazadeh Davani, A., Kiela, D., Prabhakaran,
    V., Vidgen, B., Waseem, Z.: WOAH 5共享任务的有害迷因细粒度检测研究结果。在：Mostafazadeh Davani, A.,
    Kiela, D., Lambert, M., Vidgen, B., Prabhakaran, V., Waseem, Z. (编)《第五届在线滥用与危害研讨会论文集》（WOAH
    2021）。第201–206页，ACL，在线 (2021年8月)'
- en: '[26] Mubarak, H., Abdaljalil, S., Nassar, A., Alam, F.: Detecting and identifying
    the reasons for deleted tweets before they are posted. Frontiers in Artificial
    Intelligence 6, 1219767 (2023)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Mubarak, H., Abdaljalil, S., Nassar, A., Alam, F.: 在推文发布前检测并识别被删除推文的原因。《人工智能前沿》6,
    1219767 (2023)'
- en: '[27] OpenAI, R.: GPT-4 technical report. arXiv pp. 2303–08774 (2023)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] OpenAI, R.: GPT-4技术报告。arXiv，第2303–08774页 (2023)'
- en: '[28] Piskorski, J., Stefanovitch, N., Da San Martino, G., Nakov, P.: SemEval-2023
    task 3: Detecting the category, the framing, and the persuasion techniques in
    online news in a multi-lingual setup. In: Proceedings of the 17th International
    Workshop on Semantic Evaluation. pp. 2343–2361\. ACL, Toronto, Canada (Jul 2023)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Piskorski, J., Stefanovitch, N., Da San Martino, G., Nakov, P.: SemEval-2023任务3：在多语言环境中检测在线新闻中的类别、框架和说服技巧。在：第17届国际语义评估研讨会论文集。第2343–2361页，ACL，多伦多，加拿大
    (2023年7月)'
- en: '[29] Schmidt, A., Wiegand, M.: A survey on hate speech detection using natural
    language processing. In: Proceedings of the Fifth International Workshop on Natural
    Language Processing for Social Media. pp. 1–10\. ACL, Valencia, Spain (Apr 2017)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Schmidt, A., Wiegand, M.: 使用自然语言处理检测仇恨言论的调查。在：第五届社交媒体自然语言处理国际研讨会论文集。第1–10页，ACL，西班牙瓦伦西亚
    (2017年4月)'
- en: '[30] Shah, U., Biswas, M.R., Agus, M., Househ, M., Zaghouani, W.: MemeMind
    at ArAIEval shared task: Generative augmentation and feature fusion for multimodal
    propaganda detection in Arabic memes through advanced language and vision models.
    In: Proceedings of The Second Arabic Natural Language Processing Conference. pp.
    467–472 (Aug 2024)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Shah, U., Biswas, M.R., Agus, M., Househ, M., Zaghouani, W.: MemeMind在ArAIEval共享任务中的表现：通过先进的语言与视觉模型进行生成性增强和特征融合，检测阿拉伯语迷因中的宣传手段。在：第二届阿拉伯自然语言处理会议论文集。第467–472页
    (2024年8月)'
- en: '[31] Sharma, S., Alam, F., Akhtar, M.S., Dimitrov, D., Da San Martino, G.,
    Firooz, H., Halevy, A., Silvestri, F., Nakov, P., Chakraborty, T.: Detecting and
    understanding harmful memes: A survey. In: Proceedings of the Thirty-First International
    Joint Conference on Artificial Intelligence. pp. 5597–5606\. IJCAI (7 2022)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Sharma, S., Alam, F., Akhtar, M.S., Dimitrov, D., Da San Martino, G.,
    Firooz, H., Halevy, A., Silvestri, F., Nakov, P., Chakraborty, T.: 检测和理解有害迷因：一项调查。在：第31届国际人工智能联合会议论文集。第5597–5606页，IJCAI
    (2022年7月)'
- en: '[32] Team, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.B., Yu, J., Soricut,
    R., Schalkwyk, J., Dai, A.M., Hauth, A., et al.: Gemini: a family of highly capable
    multimodal models. arXiv preprint arXiv:2312.11805 (2023)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Team, G., Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.B., Yu, J., Soricut,
    R., Schalkwyk, J., Dai, A.M., Hauth, A., 等：Gemini：一系列功能强大的多模态模型。arXiv预印本 arXiv:2312.11805
    (2023)'
