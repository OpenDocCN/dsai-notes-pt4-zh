- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 13:00:26'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 13:00:26
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM作为操作系统，代理作为应用程序：设想AIOS、代理与AIOS-Agent生态系统
- en: 来源：[https://arxiv.org/html/2312.03815/](https://arxiv.org/html/2312.03815/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2312.03815/](https://arxiv.org/html/2312.03815/)
- en: Yingqiang Ge
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 颜强葛
- en: Rutgers University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Yujie Ren
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 任宇杰
- en: Rutgers University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Wenyue Hua
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 华文越
- en: Rutgers University
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Shuyuan Xu
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 许书源
- en: Rutgers University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Juntao Tan
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 谭俊涛
- en: Rutgers University
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学
- en: Yongfeng Zhang
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 张永锋
- en: 'Rutgers University Author Affiliation: Department of Computer Science, Rutgers
    University, New Brunswick, NJ, 08854, US; Author Emails: {yingqiang.ge,yujie.ren,wenyue.hua,shuyuan.xu,juntao.tan,yongfeng.zhang}@rutgers.edu'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 罗格斯大学 作者隶属：罗格斯大学计算机科学系，新布伦瑞克，NJ，08854，美国；作者邮箱：{yingqiang.ge,yujie.ren,wenyue.hua,shuyuan.xu,juntao.tan,yongfeng.zhang}@rutgers.edu
- en: Abstract
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This paper envisions a revolutionary AIOS-Agent ecosystem, where Large Language
    Model (LLM) serves as the (Artificial) Intelligent Operating System (IOS, or AIOS)–an
    operating system “with soul”. Upon this foundation, a diverse range of LLM-based
    AI Agent Applications (Agents, or AAPs) are developed, enriching the AIOS-Agent
    ecosystem and signaling a paradigm shift from the traditional OS-APP ecosystem.
    We envision that LLM’s impact will not be limited to the AI application level,
    instead, it will in turn revolutionize the design and implementation of computer
    system, architecture, software, and programming language, featured by several
    main concepts: LLM as OS (system-level), Agents as Applications (application-level),
    Natural Language as Programming Interface (user-level), and Tools as Devices/Libraries
    (hardware/middleware-level).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本文设想了一个革命性的AIOS-Agent生态系统，其中大型语言模型（LLM）作为（人工）智能操作系统（IOS或AIOS）——一个“有灵魂”的操作系统。在此基础上，开发了一系列基于LLM的AI代理应用（Agents或AAPs），丰富了AIOS-Agent生态系统，并标志着传统操作系统-应用程序生态系统的范式转变。我们设想LLM的影响力不仅限于AI应用层，而是将反过来革新计算机系统、架构、软件和编程语言的设计与实现，特点是几个主要概念：LLM作为操作系统（系统级），代理作为应用程序（应用级），自然语言作为编程接口（用户级），工具作为设备/库（硬件/中间件级）。
- en: 'In this paper, we begin by introducing the architecture and historical evolution
    of traditional Operating Systems (OS). Then we formalize a conceptual framework
    for AIOS through “LLM as OS (LLMOS),”¹¹1For convenience, LLMOS may be pronounced
    as “el-mos”. drawing analogies between AIOS components and traditional OS elements:
    LLM is likened to OS kernel, context window to memory, external storage to file
    system, hardware tools to peripheral devices, software tools to programming libraries,
    and user prompts to user commands. Subsequently, we introduce the new AIOS-Agent
    Ecosystem, where users and developers can easily program Agent Applications (AAPs)
    using natural language, democratizing the development of and the access to computer
    software, which is different from the traditional OS-APP ecosystem, where desktop
    or mobile applications (APPs) have to be programmed by well-trained software developers
    using professional programming languages. Following this, we explore the diverse
    scope of Agent Applications. These agents can autonomously perform diverse tasks,
    showcasing intelligent task-solving ability in various scenarios. We delve into
    both single agent systems and multi-agent systems, as well as human-agent interaction.
    Lastly, we posit that the AIOS-Agent ecosystem can gain invaluable insights from
    the development trajectory of the traditional OS-APP ecosystem. Drawing on these
    insights, we propose a strategic roadmap for the evolution of the AIOS-Agent ecosystem.
    This roadmap is designed to guide the future research and development, suggesting
    systematic progresses of AIOS and its Agent applications.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们首先介绍传统操作系统（OS）的架构和历史演变。然后，我们通过“LLM作为操作系统（LLMOS）”¹¹1为方便起见，LLMOS可以读作“el-mos”，为AIOS建立一个概念框架，类比AIOS组件与传统操作系统元素：LLM类似于操作系统内核，上下文窗口类似于内存，外部存储类似于文件系统，硬件工具类似于外设，软件工具类似于编程库，用户提示类似于用户命令。接着，我们介绍了新的AIOS-代理生态系统，用户和开发者可以通过自然语言轻松编写代理应用程序（AAPs），这使得计算机软件的开发和访问民主化，与传统的操作系统-应用程序生态系统不同，后者要求桌面或移动应用程序（APPs）由经过良好培训的软件开发人员使用专业编程语言编写。随后，我们探讨了代理应用程序的多样化范围。这些代理可以自主执行各种任务，展示了在不同场景下的智能任务解决能力。我们深入分析了单代理系统和多代理系统，以及人类与代理的互动。最后，我们认为，AIOS-代理生态系统可以从传统操作系统-应用程序生态系统的发展轨迹中获得宝贵的见解。基于这些见解，我们提出了一条AIOS-代理生态系统发展的战略路线图。该路线图旨在指导未来的研究和开发，提出了AIOS及其代理应用程序的系统化进展建议。
- en: '![Refer to caption](img/366eaf8fce0fa0b3402154c505411e1c.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![请参见图注](img/366eaf8fce0fa0b3402154c505411e1c.png)'
- en: 'Figure 1: OS-APP ecosystem vs. AIOS-Agent ecosystem.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：操作系统-应用程序生态系统与AIOS-代理生态系统的对比。
- en: Contents
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 目录
- en: '[1 Introduction](#S1 "1 Introduction ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1 引言](#S1 "1 Introduction ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理和AIOS-代理生态系统")'
- en: '[2 Aligning LLM and OS](#S2 "2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps:
    Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2 调整LLM与操作系统的关系](#S2 "2 Aligning LLM and OS ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理和AIOS-代理生态系统")'
- en: '[2.1 OS and Connections with LLM](#S2.SS1 "2.1 OS and Connections with LLM
    ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem")'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1 操作系统与LLM的关系](#S2.SS1 "2.1 OS and Connections with LLM ‣ 2 调整LLM与操作系统的关系
    ‣ 将LLM视为操作系统，代理视为应用程序：展望AIOS、代理和AIOS-代理生态系统")'
- en: '[2.1.1 Kernel](#S2.SS1.SSS1 "2.1.1 Kernel ‣ 2.1 OS and Connections with LLM
    ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem")'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1.1 内核](#S2.SS1.SSS1 "2.1.1 Kernel ‣ 2.1 操作系统与LLM的关系 ‣ 2 调整LLM与操作系统的关系 ‣
    将LLM视为操作系统，代理视为应用程序：展望AIOS、代理和AIOS-代理生态系统")'
- en: '[2.1.2 User Interface](#S2.SS1.SSS2 "2.1.2 User Interface ‣ 2.1 OS and Connections
    with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS,
    Agents and the AIOS-Agent Ecosystem")'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1.2 用户界面](#S2.SS1.SSS2 "2.1.2 User Interface ‣ 2.1 操作系统与LLM的关系 ‣ 2 调整LLM与操作系统的关系
    ‣ 将LLM视为操作系统，代理视为应用程序：展望AIOS、代理和AIOS-代理生态系统")'
- en: '[2.1.3 Operating System Ecosystem](#S2.SS1.SSS3 "2.1.3 Operating System Ecosystem
    ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1.3 操作系统生态系统](#S2.SS1.SSS3 "2.1.3 Operating System Ecosystem ‣ 2.1 操作系统与LLM的关系
    ‣ 2 调整LLM与操作系统的关系 ‣ 将LLM视为操作系统，代理视为应用程序：展望AIOS、代理和AIOS-代理生态系统")'
- en: '[2.1.4 Evolution History of Operating Systems](#S2.SS1.SSS4 "2.1.4 Evolution
    History of Operating Systems ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM
    and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem")'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1.4 操作系统的演变历史](#S2.SS1.SSS4 "2.1.4 操作系统的演变历史 ‣ 2.1 操作系统与LLM的联系 ‣ 2 对齐LLM和操作系统
    ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[2.2 AIOS, LLMOS and AI Agents](#S2.SS2 "2.2 AIOS, LLMOS and AI Agents ‣ 2
    Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem")'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2 AIOS、LLMOS和AI代理](#S2.SS2 "2.2 AIOS、LLMOS和AI代理 ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[2.2.1 LLM as OS (system-level)](#S2.SS2.SSS1 "2.2.1 LLM as OS (system-level)
    ‣ 2.2 AIOS, LLMOS and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as
    Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2.1 LLM作为操作系统（系统层）](#S2.SS2.SSS1 "2.2.1 LLM作为操作系统（系统层） ‣ 2.2 AIOS、LLMOS和AI代理
    ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[2.2.2 Agents as Applications (application-level)](#S2.SS2.SSS2 "2.2.2 Agents
    as Applications (application-level) ‣ 2.2 AIOS, LLMOS and AI Agents ‣ 2 Aligning
    LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem")'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2.2 代理作为应用程序（应用层）](#S2.SS2.SSS2 "2.2.2 代理作为应用程序（应用层） ‣ 2.2 AIOS、LLMOS和AI代理
    ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[2.2.3 Natural Language as Programming Interface (user-level)](#S2.SS2.SSS3
    "2.2.3 Natural Language as Programming Interface (user-level) ‣ 2.2 AIOS, LLMOS
    and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2.3 自然语言作为编程接口（用户层）](#S2.SS2.SSS3 "2.2.3 自然语言作为编程接口（用户层） ‣ 2.2 AIOS、LLMOS和AI代理
    ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[2.2.4 Tools as Devices/Libraries (hardware/middleware-level)](#S2.SS2.SSS4
    "2.2.4 Tools as Devices/Libraries (hardware/middleware-level) ‣ 2.2 AIOS, LLMOS
    and AI Agents ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2.4 工具作为设备/库（硬件/中间件层）](#S2.SS2.SSS4 "2.2.4 工具作为设备/库（硬件/中间件层） ‣ 2.2 AIOS、LLMOS和AI代理
    ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[2.3 Development of OS and AIOS Aligned](#S2.SS3 "2.3 Development of OS and
    AIOS Aligned ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.3 操作系统和AIOS的发展](#S2.SS3 "2.3 操作系统和AIOS的发展 ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3 Architecture of AIOS](#S3 "3 Architecture of AIOS ‣ LLM as OS, Agents as
    Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3 AIOS架构](#S3 "3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.1 LLM (as AIOS Kernel)](#S3.SS1 "3.1 LLM (as AIOS Kernel) ‣ 3 Architecture
    of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem")'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1 LLM（作为AIOS内核）](#S3.SS1 "3.1 LLM（作为AIOS内核） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.1.1 Reasoning and Planning](#S3.SS1.SSS1 "3.1.1 Reasoning and Planning ‣
    3.1 LLM (as AIOS Kernel) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps:
    Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.1 推理和规划](#S3.SS1.SSS1 "3.1.1 推理和规划 ‣ 3.1 LLM（作为AIOS内核） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.1.2 Self-Improving](#S3.SS1.SSS2 "3.1.2 Self-Improving ‣ 3.1 LLM (as AIOS
    Kernel) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS,
    Agents and the AIOS-Agent Ecosystem")'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1.2 自我改进](#S3.SS1.SSS2 "3.1.2 自我改进 ‣ 3.1 LLM（作为AIOS内核） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.2 Context Window (as Memory)](#S3.SS2 "3.2 Context Window (as Memory) ‣
    3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem")'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2 上下文窗口（作为内存）](#S3.SS2 "3.2 上下文窗口（作为内存） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.3 External Storage (as Files)](#S3.SS3 "3.3 External Storage (as Files)
    ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem")'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.3 外部存储（作为文件）](#S3.SS3 "3.3 外部存储（作为文件） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.3.1 Data Formats](#S3.SS3.SSS1 "3.3.1 Data Formats ‣ 3.3 External Storage
    (as Files) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS,
    Agents and the AIOS-Agent Ecosystem")'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.3.1 数据格式](#S3.SS3.SSS1 "3.3.1 数据格式 ‣ 3.3 外部存储（作为文件） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：构想AIOS、代理和AIOS-代理生态系统")'
- en: '[3.3.2 Data Retrieval Methods](#S3.SS3.SSS2 "3.3.2 Data Retrieval Methods ‣
    3.3 External Storage (as Files) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as
    Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.3.2 数据检索方法](#S3.SS3.SSS2 "3.3.2 数据检索方法 ‣ 3.3 外部存储（作为文件） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[3.4 Tools (as Devices/Libraries)](#S3.SS4 "3.4 Tools (as Devices/Libraries)
    ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem")'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.4 工具（作为设备/库）](#S3.SS4 "3.4 工具（作为设备/库） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[3.4.1 Tool Categories](#S3.SS4.SSS1 "3.4.1 Tool Categories ‣ 3.4 Tools (as
    Devices/Libraries) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.4.1 工具类别](#S3.SS4.SSS1 "3.4.1 工具类别 ‣ 3.4 工具（作为设备/库） ‣ 3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[3.4.2 Tool-Driver and Tool-API](#S3.SS4.SSS2 "3.4.2 Tool-Driver and Tool-API
    ‣ 3.4 Tools (as Devices/Libraries) ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.4.2 工具驱动程序和工具API](#S3.SS4.SSS2 "3.4.2 工具驱动程序和工具API ‣ 3.4 工具（作为设备/库） ‣ 3
    AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[4 AIOS-Agent Ecosystem](#S4 "4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as
    Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4 AIOS-代理生态系统](#S4 "4 AIOS-代理生态系统 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[4.1 Agents as Applications](#S4.SS1 "4.1 Agents as Applications ‣ 4 AIOS-Agent
    Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem")'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.1 代理作为应用程序](#S4.SS1 "4.1 代理作为应用程序 ‣ 4 AIOS-代理生态系统 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[4.2 Natural Language Programming for Agents](#S4.SS2 "4.2 Natural Language
    Programming for Agents ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.2 代理的自然语言编程](#S4.SS2 "4.2 代理的自然语言编程 ‣ 4 AIOS-代理生态系统 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[4.3 The Ecosystem](#S4.SS3 "4.3 The Ecosystem ‣ 4 AIOS-Agent Ecosystem ‣ LLM
    as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.3 生态系统](#S4.SS3 "4.3 生态系统 ‣ 4 AIOS-代理生态系统 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5 LLMOS in Practice: AI Agents](#S5 "5 LLMOS in Practice: AI Agents ‣ LLM
    as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5 LLMOS在实践中的应用：AI代理](#S5 "5 LLMOS在实践中的应用：AI代理 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.1 Single Agent Applications](#S5.SS1 "5.1 Single Agent Applications ‣ 5
    LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem")'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.1 单一代理应用程序](#S5.SS1 "5.1 单一代理应用程序 ‣ 5 LLMOS在实践中的应用：AI代理 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.1.1 Physical Environment](#S5.SS1.SSS1 "5.1.1 Physical Environment ‣ 5.1
    Single Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.1.1 物理环境](#S5.SS1.SSS1 "5.1.1 物理环境 ‣ 5.1 单一代理应用程序 ‣ 5 LLMOS在实践中的应用：AI代理
    ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.1.2 Virtual/Digital Environment](#S5.SS1.SSS2 "5.1.2 Virtual/Digital Environment
    ‣ 5.1 Single Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS,
    Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.1.2 虚拟/数字环境](#S5.SS1.SSS2 "5.1.2 虚拟/数字环境 ‣ 5.1 单一代理应用程序 ‣ 5 LLMOS在实践中的应用：AI代理
    ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.2 Multi-Agent Applications](#S5.SS2 "5.2 Multi-Agent Applications ‣ 5 LLMOS
    in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem")'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.2 多代理应用程序](#S5.SS2 "5.2 多代理应用程序 ‣ 5 LLMOS在实践中的应用：AI代理 ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.2.1 Collaborative Interaction](#S5.SS2.SSS1 "5.2.1 Collaborative Interaction
    ‣ 5.2 Multi-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.2.1 协作互动](#S5.SS2.SSS1 "5.2.1 协作互动 ‣ 5.2 多代理应用程序 ‣ 5 LLMOS在实践中的应用：AI代理 ‣
    LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.2.2 Adversarial Interaction](#S5.SS2.SSS2 "5.2.2 Adversarial Interaction
    ‣ 5.2 Multi-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.2.2 对抗性互动](#S5.SS2.SSS2 "5.2.2 对抗性互动 ‣ 5.2 多代理应用程序 ‣ 5 LLMOS在实践中的应用：AI代理
    ‣ LLM作为操作系统，代理作为应用程序：展望AIOS、代理及AIOS-代理生态系统")'
- en: '[5.3 Human-Agent Applications](#S5.SS3 "5.3 Human-Agent Applications ‣ 5 LLMOS
    in Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem")'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.3 人机智能体应用](#S5.SS3 "5.3 人机智能体应用 ‣ 5 LLMOS实践：AI智能体 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[6 OS-inspired Future Directions](#S6 "6 OS-inspired Future Directions ‣ LLM
    as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6 操作系统启发的未来方向](#S6 "6 操作系统启发的未来方向 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[6.1 Resource Management](#S6.SS1 "6.1 Resource Management ‣ 6 OS-inspired
    Future Directions ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the
    AIOS-Agent Ecosystem")'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6.1 资源管理](#S6.SS1 "6.1 资源管理 ‣ 6 操作系统启发的未来方向 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[6.1.1 Memory Management](#S6.SS1.SSS1 "6.1.1 Memory Management ‣ 6.1 Resource
    Management ‣ 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6.1.1 内存管理](#S6.SS1.SSS1 "6.1.1 内存管理 ‣ 6.1 资源管理 ‣ 6 操作系统启发的未来方向 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[6.1.2 Tool Management](#S6.SS1.SSS2 "6.1.2 Tool Management ‣ 6.1 Resource
    Management ‣ 6 OS-inspired Future Directions ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6.1.2 工具管理](#S6.SS1.SSS2 "6.1.2 工具管理 ‣ 6.1 资源管理 ‣ 6 操作系统启发的未来方向 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[6.2 Communication](#S6.SS2 "6.2 Communication ‣ 6 OS-inspired Future Directions
    ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6.2 通信](#S6.SS2 "6.2 通信 ‣ 6 操作系统启发的未来方向 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[6.3 Security](#S6.SS3 "6.3 Security ‣ 6 OS-inspired Future Directions ‣ LLM
    as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6.3 安全性](#S6.SS3 "6.3 安全性 ‣ 6 操作系统启发的未来方向 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: '[7 Conclusions](#S7 "7 Conclusions ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem")'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[7 结论](#S7 "7 结论 ‣ LLM作为操作系统，智能体作为应用程序：构想AIOS，智能体与AIOS-智能体生态系统")'
- en: 1 Introduction
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In the evolving landscape of information technology, Operating Systems (OS)
    such as Windows²²2[https://www.microsoft.com/en-us/windows/](https://www.microsoft.com/en-us/windows/),
    MacOS³³3[https://www.apple.com/macos/](https://www.apple.com/macos/), iOS⁴⁴4[https://www.apple.com/ios/](https://www.apple.com/ios/),
    and Android⁵⁵5[https://www.android.com/](https://www.android.com/) have become
    cornerstones of our digital lives. On top of the operating systems, a diverse
    range of applications (APPs) are developed, helping with users’ diverse tasks
    and enriching the OS-APP ecosystem. For example, Microsoft Word⁶⁶6[https://www.microsoft.com/en-us/microsoft-365/word/](https://www.microsoft.com/en-us/microsoft-365/word/)
    and Google Docs⁷⁷7[https://www.google.com/docs/about/](https://www.google.com/docs/about/)
    excel in drafting documents, while Microsoft Outlook⁸⁸8[https://www.microsoft.com/en-us/microsoft-365/outlook/](https://www.microsoft.com/en-us/microsoft-365/outlook/)
    and Gmail⁹⁹9[https://www.google.com/gmail/about/](https://www.google.com/gmail/about/)
    offer efficient email management.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息技术不断发展的环境中，操作系统（OS）如Windows²²2[https://www.microsoft.com/en-us/windows/](https://www.microsoft.com/en-us/windows/)、MacOS³³3[https://www.apple.com/macos/](https://www.apple.com/macos/)、iOS⁴⁴4[https://www.apple.com/ios/](https://www.apple.com/ios/)、Android⁵⁵5[https://www.android.com/](https://www.android.com/)已成为我们数字生活的基石。在操作系统之上，开发了各种各样的应用程序（APP），帮助用户完成各种任务，丰富了操作系统与应用程序的生态系统。例如，Microsoft
    Word⁶⁶6[https://www.microsoft.com/en-us/microsoft-365/word/](https://www.microsoft.com/en-us/microsoft-365/word/)和Google
    Docs⁷⁷7[https://www.google.com/docs/about/](https://www.google.com/docs/about/)在文档起草方面表现卓越，而Microsoft
    Outlook⁸⁸8[https://www.microsoft.com/en-us/microsoft-365/outlook/](https://www.microsoft.com/en-us/microsoft-365/outlook/)和Gmail⁹⁹9[https://www.google.com/gmail/about/](https://www.google.com/gmail/about/)则提供高效的电子邮件管理。
- en: Operating systems have advanced significantly, becoming more intuitive and user-friendly,
    yet their core remains rooted in static rules and predefined logic flows, without
    the intelligent, creative, and emergent task-solving abilities. The applications
    built on top of such OS, on the other hand, are also limited to their designed
    purposes, unable to transcend beyond their individual scopes. Whenever individual
    applications need to incorporate intelligent abilities, they have to implement
    their own AI methods or functionalities, sometimes based on third-party libraries.
    This isolated framework underscores a significant shortfall in the current OS-APP
    ecosystem and highlights the pressing need of infusing (artificial) intelligence
    into operating systems, so that intelligence can be natively distributed to the
    various applications built on top of it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统已经取得了显著进展，变得更加直观和用户友好，但其核心仍然根植于静态规则和预定义的逻辑流程中，缺乏智能、创造性和自发的任务解决能力。与此不同，建立在这些操作系统之上的应用程序也仅限于其设计的目的，无法超越各自的范围。每当个别应用程序需要融入智能能力时，它们必须实现自己的人工智能方法或功能，有时还依赖于第三方库。这种孤立的框架突显了当前操作系统-应用程序生态系统中的一个重大缺陷，并强调了将（人工）智能融入操作系统的迫切需求，以便智能能够原生地分发到其上构建的各种应用程序中。
- en: 'As a result, this paper envisions (Artificial) Intelligent Operating System
    (IOS, or AIOS), an operating system “with soul”. Furthermore, a diverse scope
    of intelligent Agent applications are built on top of the AIOS, leading to the
    new AIOS-Agent ecosystem, in comparison to the traditional OS-APP ecosystem, as
    shown in Figure [1](#S0.F1 "Figure 1 ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem"). Due to the versatile and remarkable
    capabilities they demonstrate, Large Language Models (LLMs) (Radford et al., [2019](#bib.bib84);
    Brown et al., [2020](#bib.bib12); Touvron et al., [2023](#bib.bib107); Taori et al.,
    [2023](#bib.bib106)) are regarded as potential sparks for Artificial General Intelligence
    (AGI) (Bubeck et al., [2023](#bib.bib13); Morris et al., [2023](#bib.bib67); Ge
    et al., [2023](#bib.bib35)), offering hope as foundational elements for the development
    of AIOS. There are several reasons confirming LLMs’ general capability and feasibility
    for building AIOS:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本文设想了一个“有灵魂”的操作系统——（人工）智能操作系统（IOS，或AIOS）。此外，构建在AIOS之上的多样化智能代理应用程序形成了全新的AIOS-代理生态系统，相较于传统的操作系统-应用程序生态系统，如图[1](#S0.F1
    "图1 ‣ LLM作为操作系统，代理作为应用：设想AIOS、代理及AIOS-代理生态系统")所示。由于它们展示出的多功能性和显著能力，大语言模型（LLMs）（Radford等，
    [2019](#bib.bib84)；Brown等， [2020](#bib.bib12)；Touvron等， [2023](#bib.bib107)；Taori等，
    [2023](#bib.bib106)）被认为是人工通用智能（AGI）（Bubeck等， [2023](#bib.bib13)；Morris等， [2023](#bib.bib67)；Ge等，
    [2023](#bib.bib35)）的潜在火花，并且为AIOS的发展提供了作为基础元素的希望。以下几点确认了LLM在构建AIOS方面的通用能力和可行性：
- en: •
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: First, LLMs have demonstrated exceptional language understanding abilities as
    well as reasoning/planning abilities to solve complex tasks, which can divide
    the tasks into several sub-tasks and conquer them one-by-one, sometimes with the
    assistance of external tools (Ge et al., [2023](#bib.bib35); Wei et al., [2022](#bib.bib121);
    Huang and Chang, [2022](#bib.bib45)).
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一，LLM已经展示了卓越的语言理解能力以及解决复杂任务的推理/规划能力，它们能够将任务分解为若干子任务，并逐一解决，有时还借助外部工具的协助（Ge等，
    [2023](#bib.bib35)；Wei等， [2022](#bib.bib121)；Huang和Chang， [2022](#bib.bib45)）。
- en: •
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Second, LLMs offer a highly flexible platform to process virtually any prompt,
    instruction, or query expressed in natural language, making it possible for a
    diverse range of Software Development Kits (SDKs) and/or applications to be built
    on top of them.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二，LLM提供了一个高度灵活的平台，可以处理几乎任何以自然语言表达的提示、指令或查询，从而使各种软件开发工具包（SDK）和/或应用程序能够建立在其基础之上。
- en: •
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Third, LLMs offer a more intuitive and user-friendly interface, since they can
    understand and respond to user prompts or instructions in natural language (Brown
    et al., [2020](#bib.bib12); Touvron et al., [2023](#bib.bib107)). This sheds light
    on the future where natural language serves as the programming language, making
    technology more accessible, especially for those who may not be familiar with
    traditional computer interfaces and programming languages.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第三，LLM（大语言模型）提供了更直观和用户友好的界面，因为它们能够理解并响应用户的自然语言提示或指令（Brown等， [2020](#bib.bib12)；Touvron等，
    [2023](#bib.bib107)）。这为未来的前景提供了启示，即自然语言将成为编程语言，使技术变得更加易于接触，尤其是对于那些不熟悉传统计算机界面和编程语言的人来说。
- en: •
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Fourth, LLMs can be programmed to learn from interactions and customize their
    responses based on user preferences and past interactions, providing a more personalized
    experience (Safdari et al., [2023](#bib.bib91); Durmus et al., [2023](#bib.bib28)).
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第四，LLM可以被编程为从互动中学习，并根据用户偏好和过去的互动定制其响应，从而提供更加个性化的体验（Safdari等人，[2023](#bib.bib91)；Durmus等人，[2023](#bib.bib28)）。
- en: As a result, infusing intelligence into the OS-level through LLM makes it possible
    for easily distributing intelligent abilities into the application-level, providing
    a promising way to democratize intelligence across various applications.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过LLM将智能注入到操作系统层级，使得将智能能力轻松分发到应用程序层级成为可能，提供了一种有前景的方式来在各种应用中实现智能的民主化。
- en: '![Refer to caption](img/54fc84789cab7262498e03c2befa2cf5.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/54fc84789cab7262498e03c2befa2cf5.png)'
- en: (a) Architecture of Operating System (OS).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 操作系统（OS）的架构。
- en: '![Refer to caption](img/8417f007e113ec1f9d9e120fb5b1c8e8.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8417f007e113ec1f9d9e120fb5b1c8e8.png)'
- en: (b) Architecture of Large Language Model as OS (LLMOS) for AIOS.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 作为AIOS操作系统的大型语言模型架构（LLMOS）。
- en: 'Figure 2: Illustrations of the architectures of OS and AIOS (LLMOS).'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：操作系统（OS）和AIOS（LLMOS）架构的示意图。
- en: 'Inspired by the architecture of traditional OS (as shown in Figure. [1(a)](#S1.F1.sf1
    "1(a) ‣ Figure 2 ‣ 1 Introduction ‣ LLM as OS, Agents as Apps: Envisioning AIOS,
    Agents and the AIOS-Agent Ecosystem")), we present a general framework for LLM
    as OS (LLMOS) with several key components in Section [3](#S3 "3 Architecture of
    AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem") (as shown in Figure. [1(b)](#S1.F1.sf2 "1(b) ‣ Figure 2 ‣ 1 Introduction
    ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")):
    LLM as Kernel, Context Window as Memory, External Storage as File, Tools as Devices/Libraries,
    User Prompt/Instruction as User Interface (UI), and Agents as Applications. The
    conceptual framework presented draws an analogy between an LLM as OS (LLMOS) and
    a traditional Operating System (OS), mapping various components of the LLMOS to
    elements of an OS. The LLM itself is likened to the kernel, the central part managing
    the system’s core functions. The LLM’s context window is compared to the memory
    of an OS, handling immediate context selection and data processing (Shi et al.,
    [2023](#bib.bib96)). External storage for the LLM is analogous to the files of
    an OS, allowing for long-term data storage. Meanwhile, there are corresponding
    data retrieval methods to enable retrieval-augmented LLMs (Guu et al., [2020](#bib.bib39)),
    which serve as the file system of OS to manage and find relevant files. Besides,
    LLM can make use of various tools for task solving (Ge et al., [2023](#bib.bib35)),
    including both hardware tools and software tools. Hardware tools in the LLMOS
    framework are equated to peripheral devices in a traditional OS, each offering
    specific functionalities to help interact with the physical world, while software
    tools in the LLMOS framework serve as the programming libraries in traditional
    OS, enabling Agent applications to interact with the virtual/digital world. User
    prompts or instructions for the LLM are akin to the user interface (UI) in a traditional
    OS, facilitating interaction between the user and the system. The user prompts
    or instructions can be direct natural language instructions provided by the user,
    and they may also be (sometimes semi-structured) natural language instructions
    converted from users’ non-natural language instructions such as clicking on icons.
    This mapping provides a systematic way to understand the operational similarities
    between LLMOS-based AIOS and traditional OS.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 受传统操作系统架构的启发（如图[1(a)](#S1.F1.sf1 "1(a) ‣ 图2 ‣ 1 引言 ‣ LLM作为操作系统，代理作为应用程序：设想AIOS、代理和AIOS-代理生态系统")所示），我们在第[3](#S3
    "3 AIOS架构 ‣ LLM作为操作系统，代理作为应用程序：设想AIOS、代理和AIOS-代理生态系统")节中提出了一个LLM作为操作系统（LLMOS）的一般框架，并列出了几个关键组件（如图[1(b)](#S1.F1.sf2
    "1(b) ‣ 图2 ‣ 1 引言 ‣ LLM作为操作系统，代理作为应用程序：设想AIOS、代理和AIOS-代理生态系统")所示）：LLM作为内核，上下文窗口作为内存，外部存储作为文件，工具作为设备/库，用户提示/指令作为用户界面（UI），以及代理作为应用程序。所提出的概念框架将LLM作为操作系统（LLMOS）与传统操作系统（OS）进行类比，将LLMOS的各个组件映射到操作系统的元素。LLM本身类似于内核，是管理系统核心功能的中央部分。LLM的上下文窗口与操作系统的内存相似，处理即时的上下文选择和数据处理（Shi等人，[2023](#bib.bib96)）。LLM的外部存储类似于操作系统的文件，用于长期数据存储。与此同时，有相应的数据检索方法以支持检索增强型LLM（Guu等人，[2020](#bib.bib39)），它们作为操作系统的文件系统，帮助管理和查找相关文件。此外，LLM可以利用各种工具来解决任务（Ge等人，[2023](#bib.bib35)），包括硬件工具和软件工具。LLMOS框架中的硬件工具相当于传统操作系统中的外设，每个硬件工具提供特定功能，帮助与物理世界交互，而LLMOS框架中的软件工具则相当于传统操作系统中的编程库，帮助代理应用程序与虚拟/数字世界互动。LLM的用户提示或指令类似于传统操作系统中的用户界面（UI），促进用户与系统之间的交互。用户提示或指令可以是用户提供的直接自然语言指令，也可以是（有时是半结构化的）从用户非自然语言指令（如点击图标）转换过来的自然语言指令。这一映射为理解基于LLMOS的AIOS和传统操作系统之间的操作相似性提供了一个系统化的方式。
- en: 'Upon establishing a robust conceptual framework for LLMOS-based AIOS, we introduce
    the AIOS-Agent Ecosystem, akin to the traditional OS-APP Ecosystem, in Section
    [4](#S4 "4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS,
    Agents and the AIOS-Agent Ecosystem"). We begin by introducing the concept of
    Agent Applications (AAPs) within LLMOS, analogous to traditional applications
    (APPs) based on an operating system. These AAPs represent a diverse scope of specialized
    tasks for users to execute based on LLMOS. As illustrated in Figure [4](#S4.F4
    "Figure 4 ‣ 4.1 Agents as Applications ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"), by integrating
    the LLMOS layer with the OS layer, Hardware layer, and the Agent Application layer,
    we can construct an autonomous AI Agent system. Such AI Agent system responds
    to user prompts or instructions in natural language and is capable of performing
    a multitude of tasks based on its interaction with the physical or digital environment.
    Since a diverse scope of Agents can be developed on top of the shared AIOS foundation,
    this eventually leads to an AIOS-Agent ecosystem. Moreover, in the new AIOS-Agent
    Ecosystem, the users and developers can easily program Agent Applications (AAPs)
    using natural language, democratizing the development of and the access to computer
    software, which is different from the traditional OS-APP ecosystem, where desktop
    or mobile applications (APPs) have to be programmed by well-trained software developers
    using professional programming languages.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '在为基于LLMOS的AIOS建立一个稳固的概念框架后，我们在第[4](#S4 "4 AIOS-Agent Ecosystem ‣ LLM作为操作系统，Agent作为应用程序：构想AIOS、Agent和AIOS-Agent生态系统")节中介绍了AIOS-Agent生态系统，这一生态系统类似于传统的OS-APP生态系统。我们首先介绍了LLMOS中Agent应用程序（AAPs）的概念，它类似于基于操作系统的传统应用程序（APPs）。这些AAPs代表了用户可以根据LLMOS执行的一系列专门任务。正如图[4](#S4.F4
    "Figure 4 ‣ 4.1 Agents as Applications ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")所示，通过将LLMOS层与操作系统层、硬件层以及Agent应用程序层相结合，我们可以构建一个自主的AI
    Agent系统。这样的AI Agent系统能够响应用户的自然语言提示或指令，并且能够根据与物理或数字环境的互动执行多种任务。由于可以在共享的AIOS基础上开发各种Agent，这最终导致了AIOS-Agent生态系统的形成。此外，在新的AIOS-Agent生态系统中，用户和开发者可以轻松地使用自然语言编程Agent应用程序（AAPs），从而实现计算机软件开发和访问的民主化，这与传统的OS-APP生态系统不同，在传统生态系统中，桌面或移动应用程序（APPs）必须由经过专业训练的软件开发者使用专业编程语言编写。'
- en: 'Following this, we further delve into the practical LLMOS-based Agent Applications
    in Section [5](#S5 "5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents as Apps:
    Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"). This section explores
    the potential of enhancing LLMOS’s functionality by developing various agents
    in the real world, and further investigates the dynamic interactions between multiple
    agents and humans. LLMOS-based agents are characterized by their creative autonomy,
    enabling them to generate novel ideas, narratives, or solutions not pre-programmed
    into them (Chase, [2022](#bib.bib15); Gravitas, [2023](#bib.bib37); Ge et al.,
    [2023](#bib.bib35); Li et al., [2023](#bib.bib58); Yao et al., [2022b](#bib.bib132),
    [a](#bib.bib129)), which is indicative of an advanced level of creative intelligence
    (Yuan et al., [2022](#bib.bib134); Franceschelli and Musolesi, [2023](#bib.bib32)).
    Specifically, Section [5.1](#S5.SS1 "5.1 Single Agent Applications ‣ 5 LLMOS in
    Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem") discusses applications of single agents, Section [5.2](#S5.SS2
    "5.2 Multi-Agent Applications ‣ 5 LLMOS in Practice: AI Agents ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem") explores multi-agent
    systems, and Section [5.3](#S5.SS3 "5.3 Human-Agent Applications ‣ 5 LLMOS in
    Practice: AI Agents ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem") focuses on human-agent interactions.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在第[5](#S5 "5 LLMOS实践：AI代理 ‣ LLM作为操作系统，代理作为应用：构想AIOS、代理和AIOS-代理生态系统")节中进一步探讨基于LLMOS的代理应用。该节探讨了通过在现实世界中开发各种代理来增强LLMOS功能的潜力，并进一步研究多个代理与人类之间的动态互动。基于LLMOS的代理具有创造性自主性，使其能够生成未被预先编程的新的想法、叙事或解决方案（Chase,
    [2022](#bib.bib15); Gravitas, [2023](#bib.bib37); Ge等, [2023](#bib.bib35); Li等,
    [2023](#bib.bib58); Yao等, [2022b](#bib.bib132), [a](#bib.bib129)），这表明了高级创造性智能的水平（Yuan等,
    [2022](#bib.bib134); Franceschelli和Musolesi, [2023](#bib.bib32)）。具体来说，第[5.1](#S5.SS1
    "5.1 单代理应用 ‣ 5 LLMOS实践：AI代理 ‣ LLM作为操作系统，代理作为应用：构想AIOS、代理和AIOS-代理生态系统")节讨论了单个代理的应用，第[5.2](#S5.SS2
    "5.2 多代理应用 ‣ 5 LLMOS实践：AI代理 ‣ LLM作为操作系统，代理作为应用：构想AIOS、代理和AIOS-代理生态系统")节探讨了多代理系统，第[5.3](#S5.SS3
    "5.3 人类与代理的应用 ‣ 5 LLMOS实践：AI代理 ‣ LLM作为操作系统，代理作为应用：构想AIOS、代理和AIOS-代理生态系统")节专注于人类与代理的互动。
- en: 'Finally, in Section [6](#S6 "6 OS-inspired Future Directions ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"), we explore several
    crucial future research directions for LLMOS and AIOS in general, drawing parallels
    and learning from the evolution of traditional operating systems. These directions
    span a wide array of areas, aiming to enhance the capabilities and applications
    of LLMOS: 1) Resource Management. For example, OS employs virtual and shared memories
    to address the issue of limited physical memory. LLMOS can inspire from these
    ideas to mitigate its own problem of limited context window challenges; 2) Communication.
    Different OSes and applications communicate using standardized protocols (such
    as Domain-Specific Languages); LLMOSes and Agents can build and use similar standard
    protocols for exchanging data and instructions with various systems, ensuring
    compatibility and smooth interaction across diverse platforms; 3) Security. Security
    vulnerabilities in OS are important issues. State-of-the-art approaches aim to
    detect and capture malware and viruses at various levels. Similarly, LLMOS can
    implement detection and intervention mechanisms to regulate and monitor the implementation
    of third-party tools and Agent Applications.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第[6](#S6 "6 操作系统启发的未来方向 ‣ LLM作为操作系统，代理作为应用：构想AIOS、代理和AIOS-代理生态系统")节中，我们探讨了LLMOS和AIOS的若干关键未来研究方向，总结并借鉴了传统操作系统的演化。这些方向涵盖了多个领域，旨在增强LLMOS的功能和应用：1)
    资源管理。例如，操作系统使用虚拟和共享内存来解决物理内存有限的问题。LLMOS可以从这些思路中获得启发，缓解自身面临的上下文窗口限制挑战；2) 通信。不同的操作系统和应用程序使用标准化协议进行通信（如领域特定语言）；LLMOS和代理可以建立并使用类似的标准协议，以便与各种系统交换数据和指令，确保在不同平台之间的兼容性和顺畅互动；3)
    安全性。操作系统中的安全漏洞是一个重要问题。最先进的方法旨在各个层面上检测和捕获恶意软件和病毒。同样，LLMOS可以实施检测和干预机制，以规范和监控第三方工具和代理应用程序的执行。
- en: 2 Aligning LLM and OS
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 LLM与操作系统的对齐
- en: 2.1 OS and Connections with LLM
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 操作系统与LLM的关联
- en: The von Neaumann architecture, laying the foundation of modern computer hardware
    system, manipulate electrons and gates in the binary world, whereas human beings
    communicate with natural languages. Such gigantic semantic gaps between human
    users and computer hardware motivates an intermediary software layer interacting
    with users with a protected and abstracted view of underlying hardware resources
    such as CPU (Central Processing Unit), GPU (Graphics Processing Unit), RAM (Random
    Access Memory), storage and various other devices, which is called the Operating
    System (OS). The modern operating systems, over the past few decades, have evolved
    in a multi-layered architecture with modular components in each layer. This design
    not only enhances the efficiency and functionality of the systems but also facilitates
    easier management, scalability, and integration of diverse hardware and software
    elements.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 冯·诺依曼架构奠定了现代计算机硬件系统的基础，它在二进制世界中操作电子和逻辑门，而人类则使用自然语言进行交流。人类用户与计算机硬件之间如此巨大的语义差异，促使了中介软件层的出现，借助该层，用户能够以受保护且抽象的方式与底层硬件资源（如中央处理单元（CPU）、图形处理单元（GPU）、随机存取内存（RAM）、存储设备及其他各类设备）进行交互，这就是操作系统（OS）。在过去几十年里，现代操作系统已发展成具有多层架构的系统，每一层都有模块化的组件。这种设计不仅提高了系统的效率和功能，还便于管理、扩展及整合不同的硬件和软件元素。
- en: 2.1.1 Kernel
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 内核
- en: The kernel, as its name suggests, encapsulates a set of core functionalities
    of managing hardware resources (e.g., CPU, GPU, DRAM, storage, and devices) as
    a nutshell.^(10)^(10)10We limit our scope to traditional monolithic kernel design.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 内核，顾名思义，封装了一套管理硬件资源（如 CPU、GPU、DRAM、存储设备及其他设备）核心功能的“核心”。^(10)^(10)10我们将范围限制在传统的单体内核设计上。
- en: •
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: CPU Management (Process/Thread, scheduling). To manage the CPU resources, modern
    operating systems abstract the execution of user programs or applications on a
    physical CPU as processes or threads. When the user launches an application, the
    operating system kernel loads the executable binary files of this application
    or program into DRAM, create the necessary data structures to book-keep any running
    states for this program, and allocate necessary resources.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CPU 管理（进程/线程，调度）。为了管理 CPU 资源，现代操作系统将用户程序或应用程序在物理 CPU 上的执行抽象为进程或线程。当用户启动一个应用程序时，操作系统内核会将该应用程序或程序的可执行二进制文件加载到
    DRAM 中，创建必要的数据结构来记录该程序的运行状态，并分配所需资源。
- en: However, the power wall (Agarwal et al., [2006](#bib.bib2)) limits the number
    of physical CPUs to be integrated into a single chip. To provide users with the
    illusion that they possess physical CPUs without sharing with others, modern operating
    systems multiplex the running processes or threads with limited number of CPUs
    with time-sharing (Ritchie and Thompson, [1974](#bib.bib85)) and more dedicated
    policies (Molnár, [2007](#bib.bib66); Stoica and Abdel-Wahab, [1995](#bib.bib100)),
    much like multiple users share the same LLM backbone when processing their prompts
    or instructions. In such cases, if the inputs from multiple users are beyond the
    capacity of the resources, such as the tools, then the LLM may perform scheduling
    of the user prompts.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，功率墙（Agarwal 等，[2006](#bib.bib2)）限制了单一芯片中可集成的物理 CPU 数量。为了向用户提供拥有物理 CPU 的错觉而不与其他用户共享，现代操作系统通过时间共享（Ritchie
    和 Thompson，[1974](#bib.bib85)）和更多专用策略（Molnár，[2007](#bib.bib66); Stoica 和 Abdel-Wahab，[1995](#bib.bib100)）将有限数量的
    CPU 与正在运行的进程或线程进行复用，这有点像多个用户在处理他们的提示或指令时共享同一个大型语言模型（LLM）后台。在这种情况下，如果来自多个用户的输入超出了资源的处理能力，例如工具的限制，那么
    LLM 可能会对用户的提示进行调度。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Memory Management. The physical memory in a computer, also known as DRAM (Dynamic
    Random Access Memory), is the key component to store the instructions and data
    of both the OS and applications. The OS is responsible for managing and allocating
    free space in the physical memory from application’s requests.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内存管理。计算机中的物理内存，也称为动态随机存取内存（DRAM），是存储操作系统和应用程序指令及数据的关键组件。操作系统负责管理和分配物理内存中的空闲空间，以满足应用程序的请求。
- en: As described above, the physical memory, depicted as “dynamic,” cannot store
    data persistently when power is off, as it needs to refresh periodically to prevent
    the loss of data. In addition to its volatile nature, the evolution of memory
    falls behind the CPU for a long time, which is known for “The memory wall”. This
    fact lays in two orthogonal aspects. First, the data transfer rate between DRAM
    and CPU can no longer catch up with the speed that CPU processes data. Second,
    the memory capacity on a single node stops scaling. Although the emergence of
    Compute eXpress Link (CXL, [2023](#bib.bib24)) alleviates the memory capacity
    wall, it still cannot keep the rapid pace of data growth at the artificial intelligence
    era.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如上所述，物理内存被描述为“动态”的，当电源关闭时无法持久存储数据，因为它需要定期刷新以防止数据丢失。除了其易失性特征外，内存的发展远远落后于 CPU，这被称为“内存墙”。这一事实存在于两个正交的方面。首先，DRAM
    和 CPU 之间的数据传输速度已经无法跟上 CPU 处理数据的速度。其次，单个节点的内存容量停止扩展。尽管计算快速链接（CXL， [2023](#bib.bib24)）的出现缓解了内存容量壁垒，但它仍然无法跟上人工智能时代数据增长的快速步伐。
- en: This is much like the context window of LLMs, which is usually limited by the
    maximum number of tokens that the LLM can handle. Besides, LLM usually needs to
    select the relevant information from the input context, since not all contexts
    are relevant for the current task and LLM may be easily distracted by irrelevant
    contexts (Shi et al., [2023](#bib.bib96)). Context selection can be either implicitly
    realized through attention mechanisms, or be explicitly implemented by selecting
    relevant segments from the input context, much like the memory management process
    by traditional OS.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这与 LLM 的上下文窗口非常相似，通常受限于 LLM 能处理的最大标记数。此外，LLM 通常需要从输入的上下文中选择相关信息，因为并非所有上下文对于当前任务都是相关的，LLM
    可能会被无关的上下文轻易分散注意力（Shi 等， [2023](#bib.bib96)）。上下文选择可以通过注意力机制隐式实现，也可以通过从输入上下文中选择相关片段显式实现，这与传统操作系统的内存管理过程类似。
- en: •
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Storage Management. Storage devices, which store data persistently, provide
    much more density than memory with fewer cost, but much slower. The operating
    systems abstract the storage as file, and organize files in a systematic way with
    a component called the “file system”. The file system contains the meta-data to
    index the actual data stored on the storage media.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 存储管理。存储设备能够持久地存储数据，提供比内存更高的密度，并且成本较低，但速度要慢得多。操作系统将存储抽象为文件，并通过名为“文件系统”的组件以系统化的方式组织文件。文件系统包含元数据，用于索引存储介质上实际存储的数据。
- en: In addition to the file abstract, modern operating systems reserve a small portion
    of storage as an extension of memory, which is called the “swap area”. It is the
    operating system that tracks the hotness and coldness of the data from user applications,
    and swaps code data from physical memory to the swap area on the storage devices.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了文件抽象外，现代操作系统还会保留一小部分存储作为内存的扩展，称为“交换区”。操作系统跟踪来自用户应用程序的数据的热度和冷度，并将代码数据从物理内存交换到存储设备上的交换区。
- en: Similarly, LLM often has access to external data storage for retrieval-augmented
    language modeling (Guu et al., [2020](#bib.bib39)). These external data can be
    free text data, structured tabular data, semi-structured graph data, or others.
    Furthermore, the external data are usually properly indexed for efficient and
    accurate retrieval, much like the storage management process of traditional operating
    systems.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类似地，LLM 通常可以访问外部数据存储，用于检索增强的语言建模（Guu 等， [2020](#bib.bib39)）。这些外部数据可以是自由文本数据、结构化的表格数据、半结构化的图形数据或其他类型的数据。此外，外部数据通常会被适当索引，以实现高效且准确的检索，这与传统操作系统的存储管理过程非常相似。
- en: •
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Device Management. Peripheral devices, often excluded from the core computing
    system of CPU and DRAM, form an important set of functionalities for user input
    and output. Those devices range from mouse, keyboard, to GPU and network interface
    cards (NIC). The operating systems take the responsibility to manage those devices
    to orchestrate with other core components in the OS kernel.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设备管理。外设设备，通常不包括在 CPU 和 DRAM 的核心计算系统中，构成了用户输入和输出的重要功能集合。这些设备包括鼠标、键盘、GPU 和网络接口卡（NIC）。操作系统负责管理这些设备，使它们能够与操作系统内核中的其他核心组件协调工作。
- en: There are thousands of different devices for different purposes and from different
    vendors all around the world. Hence, it is not possible to implement the driver
    program for all of those devices. Instead, modern operating systems expose a generic
    interface as device driver APIs for device vendors, and thus shifts the responsibility
    of developing device driver programs from OS maintainers to vendors of those devices.
    To provide a ’plug-and-play’ feature, modern operating systems such as Linux include
    some universal and necessary device drivers for some common devices; for example,
    the drivers for GPU and USB devices (Corbet et al., [2005](#bib.bib21)).
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 全世界有成千上万种不同用途和来自不同厂商的设备。因此，不可能为所有这些设备实现驱动程序。相反，现代操作系统提供了通用接口作为设备驱动程序 API 供设备厂商使用，从而将开发设备驱动程序的责任从操作系统维护者转移到设备厂商。为了提供即插即用功能，像
    Linux 这样的现代操作系统包含了一些通用且必要的设备驱动程序，支持一些常见设备，例如 GPU 和 USB 设备（Corbet 等， [2005](#bib.bib21)）。
- en: Similarly, large language models are not only text-in-text-out models, instead,
    they have the ability of leveraging various tools for solving complex tasks (Schick
    et al., [2023](#bib.bib93); Ge et al., [2023](#bib.bib35)). There can be two types
    of tools, hardware tools and software tools, which help the LLM to interact with
    the physical world and the digital world, respectively. In this context, the hardware
    tools for LLM are similar to the devices for traditional OS. Furthermore, just
    like driver programs connect devices with OS, Tool-Drivers can be developed to
    connect LLM and hardware tools, so that LLM can easily leverage the tools for
    task-solving. We will discuss software tools in the following.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类似地，大型语言模型不仅仅是文本输入-文本输出的模型，相反，它们具有利用各种工具解决复杂任务的能力（Schick 等， [2023](#bib.bib93);
    Ge 等， [2023](#bib.bib35)）。这些工具可以分为硬件工具和软件工具，分别帮助 LLM 与物理世界和数字世界进行交互。在这种背景下，LLM
    的硬件工具类似于传统操作系统中的设备。此外，就像驱动程序将设备与操作系统连接一样，可以开发工具驱动程序将 LLM 与硬件工具连接，以便 LLM 可以轻松利用这些工具来解决任务。我们将在接下来的部分讨论软件工具。
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: SDK and Programming Libraries. The SDK (Software Development Kit) and programming
    libraries of an operating system are crucial tools that enable developers to easily
    create applications. They serve as the backbone of application development for
    operating systems, not only enabling and simplifying the creation of applications,
    but also ensuring that these applications are secure, efficient and compatible
    with the OS, which significantly contribute to the vitality and growth of the
    OS-APP ecosystem.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SDK 和编程库。操作系统的 SDK（软件开发工具包）和编程库是至关重要的工具，它们使开发者能够轻松创建应用程序。它们是操作系统应用程序开发的基础，不仅能够简化应用程序的创建，还能确保这些应用程序安全、高效，并与操作系统兼容，这对操作系统-应用程序生态系统的活力和增长做出了重要贡献。
- en: Similarly, LLM and the various AI Agents built on top of it can make use of
    various software tools such as searching on the web, checking for weather conditions,
    and booking for flight tickets (Ge et al., [2023](#bib.bib35)). These software
    tools serve as reusable functionalities that can be leveraged by LLM and Agents
    for complex task-solving, and they can be provided as SDK or programming libraries
    so that users or developers can easily use them.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同样，LLM 及其上构建的各种 AI 代理可以利用各种软件工具，例如在网络上搜索、检查天气情况和预订机票（Ge 等， [2023](#bib.bib35)）。这些软件工具作为可重用的功能，LLM
    和代理可以利用它们来解决复杂任务，并且可以作为 SDK 或编程库提供，使用户或开发者可以轻松使用。
- en: 2.1.2 User Interface
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 用户界面
- en: As detailed previously, the kernel manages the hardware resources with proper
    abstraction for user to utilize. In order to enhance the accessibility of virtualized
    hardware resources, it is crucial to establish an interface between user and OS.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，内核通过适当的抽象管理硬件资源，以便用户使用。为了增强虚拟化硬件资源的可访问性，建立用户与操作系统之间的接口至关重要。
- en: •
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: System Call. The system call, as the channel between OS kernel and users, defines
    a set of core functions to allocate and use the virtualized hardware resources.
    For instance, in a POSIX-compliant operating system (IEEE and Group, [2018](#bib.bib47)),
    the mmap system call allocates and manipulates memory resources. The fork and
    exec system call family deals with process and thread creation. The read and write
    system call are used to interact with storage devices. In terms of LLMs, the system
    calls can be formulated as natural language prompts into instruct the LLM for
    task execution.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 系统调用。系统调用作为操作系统内核与用户之间的通道，定义了一组核心功能，用于分配和使用虚拟化硬件资源。例如，在一个符合POSIX标准的操作系统中（IEEE和Group，[2018](#bib.bib47)），mmap系统调用用于分配和操作内存资源。fork和exec系统调用系列用于进程和线程的创建。read和write系统调用用于与存储设备交互。在LLM的语境下，系统调用可以被制定为自然语言提示，以指令形式让LLM执行任务。
- en: •
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Command-line Interface (CLI). The command-line interface defines a set of utility
    programs built on top of system calls to facilitate users to operate on the computer
    hardware in an interactive manner. Users interact with the OS in those utility
    programs as commands. For instance, the cd and ls commands implement the action
    of entering a directory and list all the files and folders in a directory. In
    the context of LLM, natural language prompts naturally serve as the interface
    for users to interact with LLMs. Furthermore, the LLM may also pre-define some
    foundational and commonly used functionalities as standard prompt templates for
    users to use, similar to the standard commands as in traditional OS.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 命令行界面（CLI）。命令行界面定义了一组基于系统调用构建的实用程序，以便用户通过交互方式操作计算机硬件。用户通过这些实用程序与操作系统交互，命令行即为操作命令。例如，cd和ls命令实现进入目录和列出目录中所有文件和文件夹的功能。在LLM的语境中，自然语言提示自然地成为用户与LLM交互的界面。此外，LLM也可以预定义一些基础和常用功能，作为标准提示模板供用户使用，类似于传统操作系统中的标准命令。
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Graphic User Interface (GUI). The graphic user interface is a visual way for
    users to interact with computers and electronic devices using graphical elements
    such as icons, buttons, windows, and menus, as opposed to a text-based interface
    such as a command-line interface. GUIs make it easier for users to interact with
    complex systems by representing actions through visual elements and providing
    a more intuitive user experience, especially with the increasing demand and use
    of mobile devices such as smart phones discussed in [section 2.1.4](#S2.SS1.SSS4
    "2.1.4 Evolution History of Operating Systems ‣ 2.1 OS and Connections with LLM
    ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem"). In terms of LLMs, graphic user interfaces can
    also be developed for LLM and Agents so that users can more conveniently interact
    with them without the need to writing long prompts. Instead, these GUIs will convert
    user’s non-language instructions (such as clicking on icons) into (sometimes semi-structured)
    natural language prompts based on pre-defined prompt templates, and these converted
    natural language prompts will be sent to LLM for executing the user instruction.'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图形用户界面（GUI）。图形用户界面是用户通过图形元素（如图标、按钮、窗口和菜单）与计算机和电子设备交互的一种可视化方式，与基于文本的界面（如命令行界面）不同。图形用户界面通过以可视化元素呈现操作，并提供更加直观的用户体验，尤其是在智能手机等移动设备使用日益增加的情况下，能够帮助用户更轻松地与复杂系统交互，这一点在[2.1.4节](#S2.SS1.SSS4
    "2.1.4 操作系统演变历史 ‣ 2.1 操作系统与LLM的联系 ‣ 2 对齐LLM与操作系统 ‣ LLM作为操作系统，Agent作为应用：构想AIOS，Agent与AIOS-Agent生态系统")中有所讨论。就LLM而言，也可以为LLM和Agent开发图形用户界面，以便用户更方便地与它们交互，而无需编写长篇提示。相反，这些GUI将把用户的非语言指令（如点击图标）转化为基于预定义提示模板的（有时是半结构化的）自然语言提示，并将这些转换后的自然语言提示发送给LLM以执行用户指令。
- en: 2.1.3 Operating System Ecosystem
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.3 操作系统生态系统
- en: 'The operating system ecosystem functions as an extension of the operating system,
    providing a comprehensive set of developer tool-kits (OS SDK) and runtime libraries,
    shown in Figure [1](#S0.F1 "Figure 1 ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem"). These tools empower application developers
    to efficiently design, implement, and run their applications within the operating
    system environment. For instance, the well-known iOS ecosystem includes a dedicated
    application development toolkit known as Xcode^(11)^(11)11[https://developer.apple.com/xcode/](https://developer.apple.com/xcode/),
    alongside an application publishing platform called the AppStore^(12)^(12)12[https://www.apple.com/app-store/](https://www.apple.com/app-store/),
    complementing the core iOS ecosystem. In this ecosystem, the OS provides a bunch
    of resources to support APP development and also services as the platform for
    deploying and hosting these APPs, which eventually leads to a prospering OS-APP
    ecosystem.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '操作系统生态系统作为操作系统的扩展，提供了一整套开发工具包（OS SDK）和运行时库，如图[1](#S0.F1 "Figure 1 ‣ LLM as
    OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")所示。这些工具使应用程序开发人员能够高效地设计、实现和运行他们的应用程序。例如，著名的iOS生态系统包括一个专门的应用开发工具包Xcode^(11)^(11)11[https://developer.apple.com/xcode/](https://developer.apple.com/xcode/)，以及一个名为AppStore^(12)^(12)12[https://www.apple.com/app-store/](https://www.apple.com/app-store/)的应用发布平台，完善了核心的iOS生态系统。在这个生态系统中，操作系统提供了一系列资源来支持应用开发，并且作为部署和托管这些应用程序的平台，最终形成了繁荣的操作系统-应用生态系统。'
- en: 'Similarly, we envision an AIOS-Agent ecosystem, where LLM serves as the operating
    system and hosts a diverse range of AI Agent applications, as shown in Figure
    [1](#S0.F1 "Figure 1 ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and
    the AIOS-Agent Ecosystem"). The LLM as OS (LLMOS) environment shall also provide
    a comprehensive set of AIOS SDKs and/or libraries, predominately supporting programming
    in natural language, to help developers or even average users without any knowledge
    on professional programming languages, to easily develop and deploy Agent applications
    in the LLMOS-based AIOS-Agent ecosystem.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '类似地，我们设想了一个AIOS-Agent生态系统，其中LLM作为操作系统，并托管多种AI Agent应用程序，如图[1](#S0.F1 "Figure
    1 ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")所示。LLM作为操作系统（LLMOS）环境还将提供一整套AIOS
    SDK和/或库，主要支持自然语言编程，以帮助开发人员或甚至没有任何专业编程语言知识的普通用户，在LLMOS基础的AIOS-Agent生态系统中轻松开发和部署Agent应用程序。'
- en: 2.1.4 Evolution History of Operating Systems
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.4 操作系统的演变历史
- en: •
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Batch Processing System. Early batch processing systems were a fundamental aspect
    of the early days of computing, dating back to 1950s (UW:CSE451, [2023](#bib.bib108)).
    These systems were characterized by a sequential execution of tasks, where jobs
    were submitted in batches for processing. Early batch processing systems laid
    the groundwork for subsequent developments in operating systems. While lacking
    the interactivity and responsiveness of modern systems, they played a crucial
    role in advancing computing capabilities and setting the stage for more interactive
    and user-friendly computing environments in the years to come.
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批处理系统。早期的批处理系统是计算机早期发展中的一个基本组成部分，可以追溯到1950年代（UW:CSE451, [2023](#bib.bib108)）。这些系统的特点是任务的顺序执行，作业以批次的形式提交进行处理。早期的批处理系统为后续的操作系统发展奠定了基础。尽管它们缺乏现代系统的交互性和响应性，但它们在推动计算能力的发展以及为未来更具互动性和用户友好的计算环境奠定基础方面发挥了重要作用。
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Time Sharing. Time-sharing systems (UW:CSE451, [2023](#bib.bib108)), as proposed
    in Multics (Corbató et al., [1971](#bib.bib20)) represent a significant advancement
    in the history of operating systems, providing a departure from traditional batch
    processing systems and introducing the concept of shared, interactive computing.
    Many concepts introduced in time-sharing systems, such as multitasking, interactive
    interfaces, and dynamic resource allocation, have become integral parts of modern
    operating systems, which laid the groundwork for user-friendly computing environments,
    enabling efficient resource utilization and interactive computing.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 时间共享。时间共享系统（UW:CSE451, [2023](#bib.bib108)），如在Multics中提出（Corbató等， [1971](#bib.bib20)），代表了操作系统历史上的一次重大进步，它提供了与传统批处理系统的区别，并引入了共享互动计算的概念。时间共享系统中引入的许多概念，如多任务处理、交互式接口和动态资源分配，已成为现代操作系统的核心部分，为用户友好的计算环境奠定了基础，使得资源利用更加高效，并促进了互动计算的发展。
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Multitasking. As the hardware evolved to multiple cores, planning user tasks
    on available multi-core CPU is critical to maximize the CPU utiliztion. Multitasking
    involves scheduling processes to run on the CPU in a way that gives the appearance
    of concurrent execution. Process scheduling algorithms determine the order in
    which processes are executed. The UNIX operating system (Ritchie and Thompson,
    [1974](#bib.bib85)), developed in the late 1960s and early 1970s at Bell Labs,
    introduced the concept of processes, each with its own address space, and implemented
    a simple and efficient multitasking model.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多任务处理。随着硬件向多核发展，合理规划用户任务在可用多核CPU上的分配对于最大化CPU利用率至关重要。多任务处理涉及调度进程在CPU上运行，以呈现出并发执行的效果。进程调度算法决定了进程执行的顺序。1970年代末至1980年代初，由贝尔实验室开发的UNIX操作系统（Ritchie和Thompson，[1974](#bib.bib85)）引入了进程的概念，每个进程拥有自己的地址空间，并实现了简单而高效的多任务处理模型。
- en: •
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Visualization (GUI). As described previously in [section 2.1.2](#S2.SS1.SSS2
    "2.1.2 User Interface ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS
    ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"),
    the command-line interface used to be the narrow bridge between users to interact
    with OS. Since command lines are highly professional, it prevented broader groups
    of users from easily and efficiently operating the computers. From Xerox Alto
    introduced by Palo Alto Research Center (PARC) in 1973^(13)^(13)13[https://spectrum.ieee.org/xerox-alto](https://spectrum.ieee.org/xerox-alto),
    to Apple Macintosh introduced in 1984^(14)^(14)14[http://apple-history.com/128k](http://apple-history.com/128k),
    to Microsoft Windows^(15)^(15)15[https://winworldpc.com/product/windows-3/31](https://winworldpc.com/product/windows-3/31)
    introduced in the early 1990s, and to a wide range of open-source GUIs for Linux
    such as GNOME^(16)^(16)16[https://www.gnome.org/](https://www.gnome.org/), KDE^(17)^(17)17[https://www.kde.org/](https://www.kde.org/)
    and UNITY^(18)^(18)18[https://unityd.org/](https://unityd.org/), the development
    of GUIs has significantly influenced the accessibility and usability of computers,
    making computing more intuitive and user-friendly.'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化（GUI）。正如在[第2.1.2节](#S2.SS1.SSS2 "2.1.2 用户界面 ‣ 2.1 操作系统与大语言模型的关系 ‣ 2 调整大语言模型与操作系统的对接
    ‣ 大语言模型作为操作系统，代理作为应用：构想AI操作系统、代理与AIOS-代理生态系统")中所描述的，命令行界面曾是用户与操作系统之间的狭窄桥梁。由于命令行非常专业，这使得更广泛的用户群体难以轻松且高效地操作计算机。从1973年由帕洛阿尔托研究中心（PARC）推出的Xerox
    Alto^(13)^(13)13[https://spectrum.ieee.org/xerox-alto](https://spectrum.ieee.org/xerox-alto)开始，到1984年推出的Apple
    Macintosh^(14)^(14)14[http://apple-history.com/128k](http://apple-history.com/128k)，再到1990年代初推出的Microsoft
    Windows^(15)^(15)15[https://winworldpc.com/product/windows-3/31](https://winworldpc.com/product/windows-3/31)，以及为Linux开发的多种开源GUI，如GNOME^(16)^(16)16[https://www.gnome.org/](https://www.gnome.org/)、KDE^(17)^(17)17[https://www.kde.org/](https://www.kde.org/)和UNITY^(18)^(18)18[https://unityd.org/](https://unityd.org/)，GUI的发展显著影响了计算机的可访问性和可用性，使得计算机操作更加直观和用户友好。
- en: •
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Cloud Computing. Performing data computing and storage on a single computing
    node was no longer sufficient as the data scale grew significantly in the early
    2010s. The development of client-server architecture in the early 1990s, where
    multiple clients connect to centralized servers, laid the foundation for distributed
    computing with the support of networked environments and the communication between
    clients and servers that emerged as OS core functionalities. More technologies
    such as virtualization and resource disaggregation empower the modern cloud computing
    community and market. Though cloud computing is not directly tied to the history
    of operating systems, the evolution of cloud computing has had a profound impact
    on how operating systems are designed, deployed, and utilized.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 云计算。随着数据规模在2010年代初期显著增长，单一计算节点进行数据计算和存储已不再足够。1990年代初期的客户端-服务器架构发展，使得多个客户端连接到集中的服务器，为分布式计算奠定了基础，得益于网络环境的支持以及客户端与服务器之间的通信，这些都成为了操作系统核心功能之一。更多的技术，如虚拟化和资源解耦，推动了现代云计算社区和市场的发展。尽管云计算与操作系统的历史并没有直接关联，但云计算的演进对操作系统的设计、部署和使用产生了深远的影响。
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Mobile and Embedded Systems. Aligning with the Moore’s law, the size and the
    computing power of a general-purpose CPU redefines the capability of modern embedded
    devices. Tailored for operating on a relatively constrained computing resource,
    modern mobile OS are specifically focused on power efficiency, network efficiency,
    optimized graphics for touch screen, and the prospering application ecosystem
    (detailed in [section 2.1.3](#S2.SS1.SSS3 "2.1.3 Operating System Ecosystem ‣
    2.1 OS and Connections with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as
    Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem")). Similarly, embedded
    devices ranging from IoT to robotics pose the aspect of real-time responses and
    more strict resource management in OS, which has been reflected in many successful
    embedded OSes such as VxWorks^(19)^(19)19[https://www.windriver.com/products/vxworks](https://www.windriver.com/products/vxworks)
    and QNX^(20)^(20)20[https://blackberry.qnx.com/en](https://blackberry.qnx.com/en).'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '移动与嵌入式系统。与摩尔定律一致，通用CPU的大小和计算能力重新定义了现代嵌入式设备的能力。现代移动操作系统针对在相对受限的计算资源下运行进行优化，特别关注电源效率、网络效率、触摸屏优化图形和蓬勃发展的应用生态系统（详见[第2.1.3节](#S2.SS1.SSS3
    "2.1.3 Operating System Ecosystem ‣ 2.1 OS and Connections with LLM ‣ 2 Aligning
    LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem")）。同样，从物联网到机器人技术的嵌入式设备也面临着操作系统中的实时响应和更加严格的资源管理要求，这一点在许多成功的嵌入式操作系统中得到了体现，例如VxWorks^(19)^(19)19[https://www.windriver.com/products/vxworks](https://www.windriver.com/products/vxworks)和QNX^(20)^(20)20[https://blackberry.qnx.com/en](https://blackberry.qnx.com/en)。'
- en: •
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: AI-powered Features. In the past decade, artificial intelligence (AI) technologies
    have experienced explosive growth. Specifically, breakthroughs in several areas
    of AI, such as natural language processing, computer vision, and speech recognition,
    are extending the interactive interface between users and OS to a new level. As
    examples of early implementations, Siri^(21)^(21)21[https://www.apple.com/siri/](https://www.apple.com/siri/)
    from Apple and Cortana^(22)^(22)22[https://www.microsoft.com/en-us/cortana](https://www.microsoft.com/en-us/cortana)
    from Microsoft, the AI-powered virtual assistants provide a rich set of capabilities
    to understand the requests from the users, such as message sending, call making,
    question answering, web search, recommendation, and controlling smart home devices.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AI驱动的功能。在过去的十年里，人工智能（AI）技术经历了爆炸式的增长。具体来说，AI多个领域的突破，例如自然语言处理、计算机视觉和语音识别，正在将用户与操作系统之间的互动界面提升到一个新层次。作为早期应用的例子，苹果公司的Siri^(21)^(21)21[https://www.apple.com/siri/](https://www.apple.com/siri/)和微软的Cortana^(22)^(22)22[https://www.microsoft.com/en-us/cortana](https://www.microsoft.com/en-us/cortana)，这些AI驱动的虚拟助手提供了丰富的功能，能够理解用户的请求，如发送信息、拨打电话、回答问题、网络搜索、推荐和控制智能家居设备。
- en: 2.2 AIOS, LLMOS and AI Agents
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 AIOS、LLMOS与AI代理
- en: Recent advances in foundation models, such as Large Language Models (LLMs),
    have significantly changed how AI applications are designed, trained, and used,
    including but not limited to NLP, CV, Search, RecSys, Multimedia, and Game applications.
    We envision that the influence of LLMs will not be limited to the application
    level, instead, it will in turn revolutionize the design and implementation of
    computer system, architecture, software, and the system-application ecosystem.
    This is realized through the following key concepts.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在基础模型方面的进展，如大规模语言模型（LLMs），显著改变了AI应用的设计、训练和使用方式，包括但不限于自然语言处理、计算机视觉、搜索、推荐系统、多媒体和游戏应用。我们预测，LLM的影响将不仅限于应用层面，而是将彻底革新计算机系统、架构、软件及系统应用生态系统的设计与实现。这是通过以下关键概念实现的。
- en: 2.2.1 LLM as OS (system-level)
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 LLM作为操作系统（系统级）
- en: LLM serves as the foundation AIOS platform that provides intelligent computing,
    APIs, and services that support various applications and manage various computing
    resources; Different from traditional OS, which aims at precision and efficiency,
    AIOS is characterized by its “intelligence,” which enables its intelligent and
    creative interaction with various applications and computing resources for task
    solving, leading to an operating system “with soul”.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: LLM作为基础AIOS平台，提供智能计算、API和服务，支持各种应用并管理各种计算资源；与传统操作系统旨在精度和效率不同，AIOS的特点在于其“智能”，使其能够与各种应用和计算资源进行智能和创造性的交互，以解决任务，从而实现一个“有灵魂”的操作系统。
- en: 2.2.2 Agents as Applications (application-level)
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 代理作为应用程序（应用级）
- en: 'Based on the LLM-driven AIOS, various AI Agents can be developed as AIOS-native
    applications, such as trip planning agent, medical consulting agent, financial
    management agent, etc.; these agents make use of the intelligent computing power
    of the LLM and the various tools provided by the AIOS SDK to solve various tasks;
    except for single-agent applications, agents may also communicate and interact
    with each other, enabling multi-agent applications; agent can even be created
    when needed and released after use, enabling on-the-fly creation of agents. There
    are several reasons that many specialized agents will be developed instead of
    integrating all of the functionality into one LLM: 1) the tasks that may be initiated
    by users are diverse, unbounded and unable to predetermine, 2) tasks may require
    specialized tools, reasoning and planning abilities, accessing the external physical
    or digital world, or domain-specific knowledge to complete, which the LLM-based
    AIOS platform may not support and need to be developed at the agent-level, 3)
    though language is a very powerful medium for describing tasks, objects, information
    or ideas, it may not be able to describe everything, and the completion of certain
    tasks may need creative forms of interaction beyond the “language input, language
    output” paradigm, such as the processing of vision, sound, touch, smell, and the
    diverse types of signals from various sensors. The processing of these unbounded
    and unpredictable types of information needs to be handled at the agent-level
    instead of the AIOS-level.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM驱动的AIOS，可以开发各种AI代理作为AIOS原生应用，例如旅行规划代理、医疗咨询代理、财务管理代理等；这些代理利用LLM的智能计算能力和AIOS
    SDK提供的各种工具来解决各种任务；除了单一代理应用，代理还可以相互通信和互动，支持多代理应用；代理甚至可以在需要时创建，使用后释放，支持按需创建代理。这其中有多个原因说明为什么会开发多个专业化代理，而不是将所有功能集成到一个LLM中：1）用户发起的任务是多样的、无边界的，且无法预先确定，2）任务可能需要专门的工具、推理和规划能力、访问外部物理或数字世界，或领域特定知识来完成，而基于LLM的AIOS平台可能无法支持，需要在代理层面开发，3）尽管语言是描述任务、对象、信息或想法的非常强大的媒介，但它可能无法描述一切，某些任务的完成可能需要超出“语言输入，语言输出”范式的创意互动形式，比如处理视觉、声音、触觉、嗅觉以及来自各种传感器的多种信号。这些无边界和不可预测的信息处理需要在代理层面而非AIOS层面进行。
- en: 2.2.3 Natural Language as Programming Interface (user-level)
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3 作为编程接口的自然语言（用户层级）
- en: In the AIOS-Agent ecosystem, average users can easily program Agent Applications
    (AAPs) using natural language, democratizing the development of and the access
    to computer software, which is very different from traditional OS-APP ecosystem,
    where desktop or mobile applications (APPs) have to be programmed by well-trained
    software developers using professional programming languages. This trend is consistent
    with the evolving history of programming languages, which are becoming more and
    more user-friendly, beginning from binary codes to assembly language to various
    high-level languages such as C, C++, Java and Python; Natural Language as Programming
    Language is a natural extension of this evolving history, making it possible for
    average users to program agent applications and interact with computers without
    special training on professional programming languages.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在AIOS-Agent生态系统中，普通用户可以轻松使用自然语言编程代理应用（AAPs），使计算机软件的开发和访问民主化，这与传统的操作系统-应用程序（OS-APP）生态系统有很大不同，在传统生态系统中，桌面或移动应用（APPs）必须由经过专业培训的软件开发人员使用专业编程语言编写。这一趋势与编程语言的发展历史相一致，编程语言变得越来越用户友好，从二进制代码到汇编语言，再到C、C++、Java和Python等各种高级语言；自然语言作为编程语言是这一发展历史的自然延伸，使得普通用户可以编写代理应用程序，并且无需专门的编程语言训练即可与计算机互动。
- en: 2.2.4 Tools as Devices/Libraries (hardware/middleware-level)
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4 作为设备/库的工具（硬件/中间件层级）
- en: Just like traditional OS can take advantage of various input and output devices
    such as keyboards and printers to support various APPs for task fulfillment, AIOS
    can also provide various tools as services to support the agents’ task fulfillment.
    Such tools include both hardware tools such as devices and software tools such
    as plugins or libraries; the tools also include both input tools such as collecting
    signals from a sensor and output tools such as sending messages to other agents;
    the AIOS shall include the basic and foundational tools that are frequently used
    by many agents as part of the platform, and provide Tool-Drivers (for hardware
    tools) and tool-APIs (for software tools) to enable easy calling of such tools
    by agents; Besides, each agent may also include its own specialized tools used
    for its own tasks.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 就像传统操作系统可以利用各种输入输出设备，如键盘和打印机，来支持各种应用程序（APP）完成任务一样，AIOS也可以提供各种工具作为服务，以支持代理（agent）完成任务。这些工具包括硬件工具，如设备，也包括软件工具，如插件或库；这些工具还包括输入工具，如从传感器收集信号，以及输出工具，如向其他代理发送消息；AIOS应包括平台中许多代理常用的基本和基础工具，并提供工具驱动程序（用于硬件工具）和工具API（用于软件工具），以便代理能够轻松调用这些工具；此外，每个代理还可以包括其自己专用的工具，用于执行特定任务。
- en: 2.3 Development of OS and AIOS Aligned
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 操作系统与AIOS的同步发展
- en: '![Refer to caption](img/ac52fdba572570c5c8a7bb04d36a8e46.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/ac52fdba572570c5c8a7bb04d36a8e46.png)'
- en: 'Figure 3: Parallel Development of OS and AIOS/LLMOS.^(24)^(24)24Image Sources:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：操作系统和AIOS/LLMOS的并行发展。^(24)^(24)24 图像来源：
- en: '[https://history-computer.com/atlas-computer/](https://history-computer.com/atlas-computer/),'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://history-computer.com/atlas-computer/](https://history-computer.com/atlas-computer/),'
- en: '[https://en.wikipedia.org/wiki/History_of_Unix](https://en.wikipedia.org/wiki/History_of_Unix),'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/History_of_Unix](https://en.wikipedia.org/wiki/History_of_Unix),'
- en: '[https://www.magzter.com/stories/technology/Gadgets-Philippines/ARPANET](https://www.magzter.com/stories/technology/Gadgets-Philippines/ARPANET),'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.magzter.com/stories/technology/Gadgets-Philippines/ARPANET](https://www.magzter.com/stories/technology/Gadgets-Philippines/ARPANET),'
- en: '[https://en.wikipedia.org/wiki/Windows_1.0x](https://en.wikipedia.org/wiki/Windows_1.0x),'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/Windows_1.0x](https://en.wikipedia.org/wiki/Windows_1.0x),'
- en: '[https://www.brookings.edu/articles/chatgpt-educational-friend-or-foe/](https://www.brookings.edu/articles/chatgpt-educational-friend-or-foe/),'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.brookings.edu/articles/chatgpt-educational-friend-or-foe/](https://www.brookings.edu/articles/chatgpt-educational-friend-or-foe/),'
- en: '[https://github.com/agiresearch/OpenAGI](https://github.com/agiresearch/OpenAGI),'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/agiresearch/OpenAGI](https://github.com/agiresearch/OpenAGI),'
- en: '[https://github.com/joonspk-research/generative_agents](https://github.com/joonspk-research/generative_agents),'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/joonspk-research/generative_agents](https://github.com/joonspk-research/generative_agents),'
- en: '[https://openai.com/research/gpt-4v-system-card](https://openai.com/research/gpt-4v-system-card)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://openai.com/research/gpt-4v-system-card](https://openai.com/research/gpt-4v-system-card)'
- en: 'Figure [24](#footnote24 "footnote 24 ‣ Figure 3 ‣ 2.3 Development of OS and
    AIOS Aligned ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning
    AIOS, Agents and the AIOS-Agent Ecosystem") draws a parallel between the evolution
    of Operating Systems (OS) and LLM as OS (LLMOS). This comparison highlights their
    parallel progression in terms of enhanced functionality and user interaction.
    Initially, operating systems such as Atlas Supervisor were designed to manage
    basic computer resources such as CPU and DRAM. This evolved into more sophisticated
    version, exemplified by UNIX which can manage various peripheral devices. In a
    similar vein, LLMs have progressed from text-in-text-out chatbots to intricate
    LLM-based agents capable of managing various tools for complex task solving, as
    seen in OpenAGI (Ge et al., [2023](#bib.bib35)). The figure also emphasizes the
    pivotal role of ARPANET in the development of TCP/IP protocols, which laid the
    foundation for today’s Internet and connects multiple computers for communicating
    with each other. This is paralleled by the advancement of LLM-based multi-agent
    systems where agents can communicate with each other, signifying a trend towards
    more interconnected and collaborative LLM-based computing environments (Park et al.,
    [2023](#bib.bib75)). Additionally, the evolution of operating systems is marked
    by the development of sophisticated graphical user interfaces (GUIs), such as
    those in Windows and Apple Macintosh. Similarly, LLM is evolving to include multi-modal
    interfaces, as demonstrated by GPT-4V(ision) (OpenAI, [2023](#bib.bib69)). This
    comparison underscores the role of both OS and LLM in revolutionizing user interaction
    with technology, transitioning from managing fundamental components to facilitating
    more intuitive, user-centric experiences.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '图[24](#footnote24 "脚注24 ‣ 图3 ‣ 2.3 操作系统与AIOS的同步发展 ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用：设想AIOS、代理与AIOS-代理生态系统")将操作系统（OS）和LLM作为操作系统（LLMOS）的发展进行了类比。这一比较突出了它们在功能增强和用户交互方面的同步发展。最初，像Atlas
    Supervisor这样的操作系统被设计用于管理基本的计算机资源，如CPU和DRAM。随着技术进步，操作系统逐步发展出更加复杂的版本，例如UNIX，能够管理各种外部设备。类似地，LLM也从基于文本的聊天机器人发展为能够管理各种工具的复杂LLM代理，解决复杂任务，如OpenAGI所示（Ge等，[2023](#bib.bib35)）。图中还强调了ARPANET在TCP/IP协议开发中的关键作用，为今天的互联网奠定了基础，连接多个计算机进行互相通信。这与基于LLM的多代理系统的进展相类比，在这种系统中，代理可以彼此通信，标志着LLM计算环境趋向更加互联和协作（Park等，[2023](#bib.bib75)）。此外，操作系统的发展还标志着图形用户界面（GUI）的出现，如Windows和苹果Macintosh中的界面。类似地，LLM正在发展出多模态接口，如GPT-4V(ision)所示（OpenAI，[2023](#bib.bib69)）。这种比较突出了操作系统和LLM在革新用户与技术交互方式中的作用，从管理基本组件转变为促进更加直观、以用户为中心的体验。  '
- en: 3 Architecture of AIOS
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '3 AIOS架构  '
- en: 'In this section, we establish the conceptual framework of “LLM as OS (LLMOS),”
    creating parallels between LLMOS components and traditional OS elements, as is
    shown in Table [1](#S3.T1 "Table 1 ‣ 3 Architecture of AIOS ‣ LLM as OS, Agents
    as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"). In this analogy,
    the LLM is compared to the OS kernel, the context window to memory, and external
    storage to the file system. Tools and user prompts are equated with devices/libraries
    and the user interface, respectively. We will delve into the specifics of this
    correlation in the following discussion.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们建立了“LLM作为操作系统（LLMOS）”的概念框架，将LLMOS组件与传统操作系统元素进行类比，如表[1](#S3.T1 "表1 ‣
    3 AIOS架构 ‣ LLM作为操作系统，代理作为应用：设想AIOS、代理与AIOS-代理生态系统")所示。在这个类比中，LLM被比作操作系统内核，上下文窗口比作内存，外部存储比作文件系统。工具和用户提示分别等同于设备/库和用户界面。我们将在以下讨论中深入探讨这种关联的具体内容。  '
- en: '| OS-APP Ecosystem | AIOS-Agent Ecosystem | Explanation |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| OS-应用生态系统 | AIOS-代理生态系统 | 说明 |  '
- en: '| --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Kernel | LLM | The core of AIOS, providing supportive services for Agent
    Applications (AAPs). |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 内核 | LLM | AIOS的核心，为代理应用程序（AAPs）提供支持服务。 |'
- en: '| Memory | Context Window | Short-term memory of the current session, such
    as the prompt-response history of this session. |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 内存 | 上下文窗口 | 当前会话的短期记忆，如本会话的提示-响应历史。 |  '
- en: '| Memory Management | Context Selection and Management | Select relevant context
    for the session, and manage the context such as adding, deleting and changing
    context information. |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 内存管理 | 上下文选择与管理 | 为会话选择相关的上下文，并管理上下文，如添加、删除和更改上下文信息。 |'
- en: '| File | External Storage | Long-term storage of the AIOS’s history sessions,
    user profiles, factual knowledge, etc. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 文件 | 外部存储 | 用于AIOS历史会话、用户配置文件、事实知识等的长期存储。 |'
- en: '| File System | Retrieval-augmentation | Retrieve relevant information from
    long-term storage. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 文件系统 | 检索增强 | 从长期存储中检索相关信息。 |'
- en: '| Devices/Libraries | Hardware/Software Tools | Help systems interact with
    the external world (both physical and virtual/digital world). |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 设备/库 | 硬件/软件工具 | 帮助系统与外部世界（包括物理和虚拟/数字世界）进行交互。 |'
- en: '| Driver/API | Tool-Driver/Tool-API | Serves as the interface for LLM/Agents
    to access and use the tools, usually in the form of prompts. |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 驱动/API | 工具驱动/工具API | 作为LLM/代理访问和使用工具的接口，通常以提示的形式呈现。 |'
- en: '| OS SDK | AIOS SDK | Assist users in developing Agent Applications. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 操作系统 SDK | AIOS SDK | 帮助用户开发代理应用程序。 |'
- en: '| User Interface (UI) | User Prompt/Instruction | Instruction(s) given by user
    to the system in (sometimes semi-structured) natural language (NL) to perform
    specific tasks. The NL instruction may be converted from users’ non-NL instructions
    such as clicks. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 用户界面 (UI) | 用户提示/指令 | 用户以（有时是半结构化的）自然语言（NL）给系统的指令，用以执行特定任务。自然语言指令可能是从用户的非自然语言指令（如点击）转换而来。
    |'
- en: '| Application (APP) | Agent Application (AAP) | A diverse world of AI Agents.
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 应用程序 (APP) | 代理应用程序 (AAP) | 一个多样化的AI代理世界。 |'
- en: 'Table 1: Comparison of OS-APP Ecosystem and AIOS-Agent Ecosystem'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：操作系统-应用程序生态系统与AIOS-代理生态系统比较
- en: 3.1 LLM (as AIOS Kernel)
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 LLM（作为AIOS内核）
- en: The kernel is a set of computer programs at the core of a computer’s operating
    system and generally has complete control over everything in the system. When
    a user command is issued, the OS parses the command and translates it into one
    or more system calls to enter the kernel, which are precise requests for the kernel
    to perform tasks such as process creation, memory allocation, and file manipulation.
    It then manages these tasks by scheduling the processes, allocating the necessary
    resources, interacting with device drivers for hardware access, and enforcing
    security measures. Throughout this process, the kernel also handles error checking
    and provides appropriate feedback. Upon completion, the kernel ensures that outputs
    are directed back to the user and that all resources are cleaned up to maintain
    system stability, effectively abstracting the intricate hardware details from
    the user.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 内核是计算机操作系统核心的一组计算机程序，通常对系统中的一切具有完全控制权。当用户发出命令时，操作系统解析该命令，并将其转换为一个或多个系统调用进入内核，这些是内核执行任务（如进程创建、内存分配和文件操作）的精确请求。然后，内核通过调度进程、分配必要的资源、与设备驱动程序交互以访问硬件，并执行安全措施来管理这些任务。在整个过程中，内核还处理错误检查并提供适当的反馈。完成后，内核确保将输出返回给用户，并清理所有资源以保持系统的稳定性，从而有效地将复杂的硬件细节抽象化，用户无需关心。
- en: Similarly, LLM acts as the operational core, akin to an OS kernel, responsible
    for planning and decomposing user requests, selectively calling tools, performing
    retrieval, and integrating all the information from previous steps to generate
    the final response. An LLM handles a complex prompt or instruction by first interpreting
    the input to understand its context and intent, and then uses its internal parameters
    to process the information, decomposing the instruction into manageable sub-tasks.
    The LLM generates responses for these sub-tasks, ensuring coherence and relevance
    to the original instruction. Finally, it synthesizes these into a cohesive output
    delivered to the user.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，LLM充当操作核心，类似于操作系统内核，负责规划和分解用户请求，选择性调用工具、执行检索，并整合前一步骤中的所有信息以生成最终响应。LLM通过首先解释输入内容来理解其上下文和意图，然后利用其内部参数处理信息，将指令分解为可管理的子任务。LLM为这些子任务生成响应，确保与原始指令的一致性和相关性。最后，它将这些子任务的响应整合成一个连贯的输出，提供给用户。
- en: 3.1.1 Reasoning and Planning
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 推理与规划
- en: In LLMOS, the role of LLM as the kernel subtly echoes the dynamics illustrated
    in the Dining Philosophers problem from computer science, a scenario that highlights
    the challenges of resource allocation and synchronization. In this problem, philosophers
    seated around a table must navigate shared resource usage–forks–in a way that
    avoids deadlock, a situation where no progress is made due to mutual blocking.
    Reflecting these challenges, the kernel in an operating system is adept at managing
    and scheduling resources to avert system deadlocks, ensuring smooth and conflict-free
    operations. This essential function of the kernel in maintaining system stability
    and efficiency finds a parallel in the role of the LLM within the AIOS framework.
    Here, the LLM is responsible for navigating complex informational environments
    and managing external resources. Crucial to the LLM’s role is its planning ability,
    which involves generating a series of actions to achieve a specific goal (Ge et al.,
    [2023](#bib.bib35)). Central to the planning ability is the capability of reasoning
    (Bratman et al., [1988](#bib.bib11); Russell and Norvig, [1995](#bib.bib90); Fainstein
    and DeFilippis, [2015](#bib.bib29); Huang and Chang, [2022](#bib.bib45)). Through
    reasoning, LLMOS deconstructs complex tasks from user instructions into more manageable
    sub-tasks, devising appropriate plans for each. Next, we will explore several
    representative planning strategies that illustrate this capability.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMOS中，LLM作为核心的角色巧妙地呼应了计算机科学中“餐桌哲学家”问题所阐述的动态，这一情境突出了资源分配和同步的挑战。在这个问题中，围坐在桌子周围的哲学家必须以一种避免死锁的方式使用共享资源——餐叉——死锁是指由于互相阻塞而无法取得进展的情况。反映这些挑战，操作系统中的内核擅长管理和调度资源，防止系统死锁，确保系统平稳且无冲突地运行。内核在维护系统稳定性和效率中的这一基本功能，与LLM在AIOS框架中的角色相平行。在这里，LLM负责在复杂的信息环境中进行导航并管理外部资源。LLM角色的关键在于其规划能力，即生成一系列行动以实现特定目标（Ge
    et al., [2023](#bib.bib35)）。规划能力的核心是推理能力（Bratman et al., [1988](#bib.bib11); Russell
    and Norvig, [1995](#bib.bib90); Fainstein and DeFilippis, [2015](#bib.bib29);
    Huang and Chang, [2022](#bib.bib45)）。通过推理，LLMOS将用户指令中的复杂任务拆解为更易管理的子任务，为每个子任务制定合适的计划。接下来，我们将探讨几种具有代表性的规划策略，以展示这一能力。
- en: •
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Single-path Planning. In this strategy, the final task is decomposed into several
    intermediate steps, which are connected in a cascading manner, with each step
    leading to only one subsequent step. For example, CoT (Chain of Thoughts) prompting
    (Wei et al., [2022](#bib.bib121)), as one of the celebrated capabilities of recent
    LLMs, is a pivotal breakthrough for performing complex multi-step reasoning when
    provided with limited examples. For example, by providing the models with “chain
    of thoughts”, i.e., reasoning exemplars, or a simple prompt “Let’s think step
    by step”, these models are able to answer questions with explicit reasoning steps
    (Kojima et al., [2022](#bib.bib55)). ReAct (Reasoning + Acting) (Yao et al., [2022b](#bib.bib132))
    is a prompt-based paradigm to synergize reasoning and acting in language models.
    It enriches the action space with self-thinking (or thoughts), which compose useful
    information by reasoning over the current context to support future reasoning
    or acting. RAFA (Reason for Future, Act for Now) (Liu et al., [2023a](#bib.bib63))
    studies how to complete a given task provably within a minimum number of interactions
    with the external environment.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 单路径规划。在这种策略中，最终任务被分解成几个中间步骤，这些步骤按级联方式连接，每个步骤只引导到一个后续步骤。例如，CoT（思维链）提示（Wei et
    al., [2022](#bib.bib121)）作为最近大型语言模型（LLM）备受关注的能力之一，是在提供有限示例的情况下执行复杂多步骤推理的关键突破。例如，通过为模型提供“思维链”，即推理示例，或者简单的提示“让我们一步一步地思考”，这些模型能够以明确的推理步骤回答问题（Kojima
    et al., [2022](#bib.bib55)）。ReAct（推理+行动）（Yao et al., [2022b](#bib.bib132)）是一种基于提示的范式，旨在协调语言模型中的推理与行动。它通过自我思考（或思维）丰富了行动空间，这些思维通过推理当前上下文，构建有用的信息来支持未来的推理或行动。RAFA（为未来推理，为现在行动）（Liu
    et al., [2023a](#bib.bib63)）研究如何在与外部环境的最少交互中，证明性地完成给定任务。
- en: •
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Multi-path Planning. In this strategy, the reasoning steps for generating the
    final plans are organized into a tree-like or graph-like structure. This mirrors
    the nature of human decision-making, where individuals often encounter a range
    of choices at each step of their reasoning process. For example, CoT-SC (Self-consistent
    CoT) (Wang et al., [2022](#bib.bib115)) uses the CoT approach to produce multiple
    reasoning paths and answers for a complex problem, selecting the most frequently
    occurring answer as the final output. Tree of Thoughts (ToT) (Yao et al., [2023](#bib.bib131))
    assumes that humans tend to think in a tree-like structure when making decisions
    on complex problems for planning purposes, where each tree node is a thinking
    state. It uses LLM to generate evaluations or votes of thoughts, which can be
    searched using breadth first search (BFS) or depth first search (DFS). These methods
    improve the performance of LLMs on complex reasoning tasks. DFSDT (Depth-first
    search-based decision tree) (Qin et al., [2023b](#bib.bib83)) employs a tree structure
    with each node representing a state that includes instruction context, prior API
    calls, and observations. The model not only reasons and moves to child nodes based
    on API calls but can also backtrack to explore alternative paths, ensuring a more
    diversified search and preventing cumulative errors. Graph of Thoughts (GoT) (Besta
    et al., [2023](#bib.bib7)) further extends the reasoning paths from tree-structure
    to graph-structure, representing data produced by an LLM in the form of a flexible
    graph with individual units of information as nodes.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多路径规划。在这一策略中，生成最终计划的推理步骤被组织成树状或图状结构。这与人类决策的本质相似，人们在推理过程中常常会在每一步遇到一系列的选择。例如，CoT-SC（自洽链式推理）（Wang
    et al., [2022](#bib.bib115)）使用CoT方法为复杂问题生成多个推理路径和答案，选择出现频率最高的答案作为最终输出。思想树（ToT）（Yao
    et al., [2023](#bib.bib131)）假设人类在做复杂问题的决策时倾向于以树状结构进行思考，树的每个节点代表一个思维状态。它使用大语言模型（LLM）生成思维的评估或投票，并可以使用广度优先搜索（BFS）或深度优先搜索（DFS）进行搜索。这些方法提高了大语言模型在复杂推理任务中的表现。DFSDT（基于深度优先搜索的决策树）（Qin
    et al., [2023b](#bib.bib83)）采用树状结构，每个节点代表一个状态，包括指令上下文、先前的API调用和观察结果。该模型不仅通过API调用进行推理并移动到子节点，还可以回溯以探索替代路径，从而确保更加多样化的搜索，并防止累积错误。思想图（GoT）（Besta
    et al., [2023](#bib.bib7)）进一步将推理路径从树状结构扩展到图状结构，表示由大语言模型生成的数据，采用灵活的图形形式，信息单元作为节点。
- en: Valmeekam et al. ([2022](#bib.bib109)) concluded that “LLMs are still far from
    achieving acceptable performance on common planning/reasoning tasks which pose
    no issues for humans to do.” Similarly, Wei et al. ([2022](#bib.bib121)) also
    acknowledged this limitation, noting that “we qualify that although chain of thought
    emulates the thought processes of human reasoners, this does not answer whether
    the neural network is actually reasoning.” As a result, extensive efforts are
    still needed from the community to enhance the reasoning and planning ability
    of large language models.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Valmeekam et al. ([2022](#bib.bib109)) 认为“当前大语言模型在常见的规划/推理任务上仍远未达到人类的表现水平，这些任务对于人类而言并不构成问题。”类似地，Wei
    et al. ([2022](#bib.bib121)) 也承认了这一局限性，指出“我们认为，尽管链式思维模拟了人类推理者的思维过程，但这并不能回答神经网络是否真正进行推理的问题。”因此，社区仍需付出大量努力，以提升大语言模型的推理和规划能力。
- en: 3.1.2 Self-Improving
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 自我改进
- en: Just as kernel updates are driven by human feedback, focusing on bug reports
    and performance issues, leading to improvements in functionality, security, and
    stability, LLMOS also requires continuous enhancement to elevate its performance.
    This process involves the LLMs learning from interactions, refining their algorithms
    based on user experiences and feedback. By doing so, LLMs can develop new capabilities
    and skills, adapting to changing requirements and expectations. This iterative
    process of improvement ensures that LLMs remain effective, relevant, and efficient
    in handling diverse tasks and queries, mirroring the evolving nature of technology
    and user needs. After the LLM has been pre-trained, the learning strategies of
    LLM can be broadly categorized into two main types, as summarized and exemplified
    in the following.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 就像内核更新是通过人工反馈推动的，关注漏洞报告和性能问题，从而改善功能、安全性和稳定性，LLMOS 也需要不断增强以提升其性能。这个过程涉及 LLMs
    从交互中学习，根据用户的经验和反馈完善其算法。通过这样做，LLMs 可以开发新的能力和技能，适应不断变化的需求和期望。这个迭代的改进过程确保了 LLMs 在处理各种任务和查询时，始终保持有效、相关和高效，反映了技术和用户需求的不断发展。在
    LLM 经过预训练后，LLM 的学习策略大致可以分为两种类型，如下所述并举例说明。
- en: •
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Learning from Feedback. LLMs can learn from feedback about the consequences
    of its actions to the environment. For example, Reflexion, as proposed by Shinn
    et al. ([2023](#bib.bib97)), is a framework to reinforce language agents through
    linguistic task feedback rather than update weights, enabling them to learn from
    prior failings. Similarly, Recursively Criticize and Improve (RCI) (Kim et al.,
    [2023](#bib.bib53)) is a prompting approach, which involves prompting the LLMs
    to identify issues in their output and subsequently enhance it based on the identified
    problems. Furthermore, these learning processes can be framed within the paradigm
    of Reinforcement Learning (RL). In this context, the LLM is trained to select
    actions that maximize a reward signal, aligning with the principles of RL. For
    example, Ouyang et al. ([2022](#bib.bib71)) presents Reinforcement Learning from
    Human Feedback (RLHF) to align LLMs with the feedback from human users; OpenAGI
    (Ge et al., [2023](#bib.bib35)) presents Reinforcement Learning from Task Feedback
    (RLTF), which learns from the performance of executing the LLM-generated task
    solution to fine-tune the planning strategy of the LLM.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从反馈中学习。LLMs 可以从其行为对环境的影响反馈中学习。例如，Shinn 等人提出的 Reflexion（[2023](#bib.bib97)）是一种通过语言任务反馈强化语言代理的框架，而不是更新权重，使其能够从之前的失败中学习。类似地，Recursively
    Criticize and Improve（RCI）（Kim 等人，[2023](#bib.bib53)）是一种提示方法，要求 LLMs 识别其输出中的问题，并根据识别到的问题进行改进。此外，这些学习过程可以框架化为强化学习（RL）的范式。在这个框架下，LLM
    被训练选择最大化奖励信号的动作，符合 RL 的原则。例如，Ouyang 等人（[2022](#bib.bib71)）提出了通过人类反馈进行的强化学习（RLHF），以将
    LLM 与人类用户的反馈对齐；OpenAGI（Ge 等人，[2023](#bib.bib35)）提出了基于任务反馈的强化学习（RLTF），它从执行 LLM
    生成的任务解决方案的表现中学习，以微调 LLM 的规划策略。
- en: •
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Learning from Examples. Recently, there has been a surge of interest in fine-tuning
    LLMs to perform tasks in a supervised way. For example, ToolLLaMA (Qin et al.,
    [2023b](#bib.bib83)) is created by collecting various real-world APIs and generating
    instructions for their practical use, with solutions annotated using a language
    model such as ChatGPT and an efficient Depth-First Search Decision Tree. This
    process results in a dataset of instruction-solution pairs, on which a large language
    model such as LLaMA is fine-tuned to execute APIs according to instructions. Moreover,
    Gorilla (Patil et al., [2023](#bib.bib76)) is trained by extracting key fields
    from API documentation and using GPT-4 to create instruction-API pairs, which
    are then used in a conversational format to fine-tune a model such as LLaMA, incorporating
    both retriever-aware and non-retriever training methods.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从示例中学习。最近，越来越多的人开始关注通过监督方式对 LLM 进行微调以执行任务。例如，ToolLLaMA（Qin 等人，[2023b](#bib.bib83)）是通过收集各种现实世界的
    API 并生成它们的实际使用说明创建的，解决方案使用如 ChatGPT 等语言模型以及高效的深度优先搜索决策树进行注释。这个过程产生了一个由指令-解决方案对组成的数据集，基于这些数据集，像
    LLaMA 这样的语言模型被微调以根据指令执行 API。此外，Gorilla（Patil 等人，[2023](#bib.bib76)）通过从 API 文档中提取关键字段，并使用
    GPT-4 创建指令-API 对，这些对随后以对话的形式用于微调如 LLaMA 这样的模型，结合了检索感知和非检索训练方法。
- en: 3.2 Context Window (as Memory)
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 上下文窗口（作为记忆）
- en: In LLMOS, memory functions similarly to the context window in an LLM, defining
    the scope of information that the LLM can utilize and learn from while producing
    outputs. Increasing the amount of memory is desirable but always at a high cost.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMOS中，内存的功能类似于LLM中的上下文窗口，定义了LLM在生成输出时可以利用和学习的信息范围。增加内存量是可取的，但总是伴随着高昂的成本。
- en: 'Within the framework of an LLM, an expansion of the context window precipitates
    increased computational demands. This escalation is attributed to the quadratic
    computational complexity that is a characteristic of the attention mechanism employed
    in these models (Vaswani et al., [2017](#bib.bib110)). During the training phase,
    one widely adopted strategy to avoid the exorbitant costs associated with lengthy
    context is to conduct an initial pre-training phase using a relatively limited
    context window, and subsequently followed by a fine-tuning stage employing an
    expanded context window (Chen et al., [2023b](#bib.bib18)). Consequently, two
    primary challenges emerge: 1) the reduction of computational costs associated
    with processing long contexts, and 2) the development of a flexible position encoding
    mechanism suitable for extended contexts.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM框架内，扩展上下文窗口会导致计算需求的增加。这一增加归因于这些模型中使用的注意力机制所具有的二次计算复杂度（Vaswani等人，[2017](#bib.bib110)）。在训练阶段，避免因长上下文带来的高昂成本的一个广泛采用的策略是，首先使用相对有限的上下文窗口进行预训练阶段，然后再使用扩展的上下文窗口进行微调阶段（Chen等人，[2023b](#bib.bib18)）。因此，出现了两个主要挑战：1）减少处理长上下文所需的计算成本，2）开发适用于扩展上下文的灵活位置编码机制。
- en: •
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Efficient attention: Various methods have been proposed to reduce the complexity
    of the multi-head attention mechanism, which can be categorized into three primary
    types: 1) Sparse attention mechanism (Zaheer et al., [2020](#bib.bib135); Gray
    et al., [2017](#bib.bib38); Kitaev et al., [2020](#bib.bib54); Beltagy et al.,
    [2020](#bib.bib6); Ainslie et al., [2020](#bib.bib5); Wang et al., [2020](#bib.bib114))
    redefines the traditional computation of attention weights. In this approach,
    each query tensor is limited to engaging with only a subset of key tensors, as
    opposed to the entire set. This method effectively zeroes out other attention
    weights, thereby diluting the computation and reducing the overall computational
    burden; 2) Linear attention mechanism (Katharopoulos et al., [2020](#bib.bib52)),
    which modifies the tensor multiplication process to be linear with respect to
    the sequence length without reducing the interaction between query tensors and
    key tensors; 3) Traditional multi-head attention uses multiple heads to split
    the query, key, and value tensor. Another method of reducing complexity aims at
    sharing heads for keys and values to optimize memory usage. By sharing heads between
    the keys and values in the multi-head attention setup (Shazeer, [2019](#bib.bib95);
    Ainslie et al., [2023](#bib.bib4)), it reduces the storage requirements for the
    key-value (KV) cache and improves efficiency.'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高效的注意力机制：为减少多头注意力机制的复杂性，已经提出了各种方法，这些方法可以分为三种主要类型：1）稀疏注意力机制（Zaheer等人，[2020](#bib.bib135)；Gray等人，[2017](#bib.bib38)；Kitaev等人，[2020](#bib.bib54)；Beltagy等人，[2020](#bib.bib6)；Ainslie等人，[2020](#bib.bib5)；Wang等人，[2020](#bib.bib114)）重新定义了传统的注意力权重计算方法。在这种方法中，每个查询张量仅与部分关键张量进行交互，而不是与整个集合进行交互。这种方法有效地将其他注意力权重置为零，从而稀释了计算并减少了整体计算负担；2）线性注意力机制（Katharopoulos等人，[2020](#bib.bib52)），它修改了张量乘法过程，使其在序列长度上线性，而不会减少查询张量与关键张量之间的交互；3）传统的多头注意力机制使用多个头来拆分查询、关键和数值张量。另一种减少复杂度的方法是共享关键和值的头，以优化内存使用。通过在多头注意力结构中共享关键和值的头（Shazeer，[2019](#bib.bib95)；Ainslie等人，[2023](#bib.bib4)），可以减少关键-值（KV）缓存的存储需求并提高效率。
- en: •
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Position encoding: Position encoding can be classified into absolute position
    encoding and relative position encoding. The original Transformers paper (Vaswani
    et al., [2017](#bib.bib110)) utilizes absolute position encoding, in which information
    is encoded in a combination of sin/cos functions whose wavelength increases from
    low- to higher-order dimensions of the embedding. Various methods, such as RoPE
    (Su et al., [2021](#bib.bib101)), are proposed later to emphasize the relative
    position information between tokens. To extend the context window size, Alibi
    (Sun et al., [2022](#bib.bib103)), LeX (Sun et al., [2022](#bib.bib103)), and
    XPos (Press et al., [2021](#bib.bib77)) are proposed to enable length extrapolation
    so that a model can conduct inference on long context while being trained only
    on short context. To increase context length, methods such as position interpolation
    (Chen et al., [2023b](#bib.bib18)) and NTK-aware (Rozière et al., [2023](#bib.bib87))
    position interpolation based on RoPE can be used.'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 位置编码：位置编码可以分为绝对位置编码和相对位置编码。原始的Transformers论文（Vaswani等，[2017](#bib.bib110)）采用了绝对位置编码，其中信息通过正弦/余弦函数的组合进行编码，这些函数的波长从低维到高维逐渐增加。之后提出了多种方法，例如RoPE（Su等，[2021](#bib.bib101)），强调了标记之间的相对位置信息。为了扩展上下文窗口大小，提出了Alibi（Sun等，[2022](#bib.bib103)）、LeX（Sun等，[2022](#bib.bib103)）和XPos（Press等，[2021](#bib.bib77)）等方法，这些方法支持长度外推，使得模型即便仅在短上下文上进行训练，也能在长上下文中进行推理。为了增加上下文长度，可以使用基于RoPE的位置信息插值（Chen等，[2023b](#bib.bib18)）和NTK感知（Rozière等，[2023](#bib.bib87)）位置插值方法。
- en: Even though technically, the long context can be processed, there is no guarantee
    that the information in the long context can be correctly used and learned by
    LLM. Recent research has found that LLM does not robustly make use of information
    in long input contexts (Liu et al., [2023b](#bib.bib62); Shi et al., [2023](#bib.bib96)).
    In particular, performance is often highest when relevant information occurs at
    the beginning or end of the input context and significantly degrades when models
    must access relevant information in the middle of long contexts. Similar findings
    are also found in chat-based LLM (Yang and Ettinger, [2023](#bib.bib125)), where
    model’s ability to track and enumerate environment states is unsatisfying. Given
    long documents, various prompt compression methods, such as LLMLingua (Jiang et al.,
    [2023](#bib.bib49)), have been proposed to reduce context length by removing unimportant
    tokens from the text.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 即使从技术上讲，长上下文是可以处理的，但并不能保证LLM能够正确使用和学习长上下文中的信息。最近的研究发现，LLM并不能稳健地利用长输入上下文中的信息（Liu等，[2023b](#bib.bib62)；Shi等，[2023](#bib.bib96)）。特别是，当相关信息出现在输入上下文的开始或结束时，模型的表现通常最佳；而当模型必须访问长上下文中间的相关信息时，表现显著下降。类似的发现也出现在基于聊天的LLM中（Yang和Ettinger，[2023](#bib.bib125)），其中模型跟踪和列举环境状态的能力令人不满意。对于长文档，提出了各种提示压缩方法，如LLMLingua（Jiang等，[2023](#bib.bib49)），通过移除文本中不重要的标记来缩短上下文长度。
- en: 3.3 External Storage (as Files)
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 外部存储（作为文件）
- en: In addition to generating content based on knowledge acquired during pre-training,
    LLMs also utilize externally stored information for several purposes. These include
    enhancing predictions in domain-specific areas, generating more current information
    based on recent updates, and improving long-term memory retention. The external
    storage functions similarly to a file system within an operating system and supports
    various data formats. Certain formats enable the LLMs to swiftly query data as
    required, while others act as auxiliary knowledge bases. These knowledge are accessible
    for instant access to provide information in response to queries requiring high
    precision or expert knowledge. This section will commence with an explanation
    of how data is stored, followed by a discussion on the methodologies employed
    to retrieve pertinent information from the data storage.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基于预训练期间获得的知识生成内容外，LLM还利用外部存储的信息来实现多个目的。这些目的包括增强特定领域的预测、基于最近更新生成更为当前的信息以及改善长期记忆保持。外部存储类似于操作系统中的文件系统，并支持多种数据格式。某些格式使LLM能够根据需要快速查询数据，而其他格式则充当辅助知识库。这些知识可以即时访问，以便为需要高精度或专家知识的查询提供信息。本节将首先解释数据是如何存储的，然后讨论用于从数据存储中检索相关信息的方法。
- en: 3.3.1 Data Formats
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 数据格式
- en: 'A file system in OS stores, organizes, and retrieves information in different
    modalities, including but not limited to plain text, images, audios, or videos.
    Similarly, LLM stores and retrieves data in different formats, such as natural
    language, embedding vectors, or graphs. It should be emphasized that these formats
    are not mutually exclusive, and many models incorporate multiple formats to concurrently
    harness their respective benefits. In the following, we introduce several representative
    data formats, each with its distinct features and applications:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统中的文件系统存储、组织和检索信息，涵盖多种形式，包括但不限于纯文本、图像、音频或视频。同样，LLM（大型语言模型）也以不同格式存储和检索数据，如自然语言、嵌入向量或图表。需要强调的是，这些格式并非相互排斥，许多模型结合了多种格式，以同时发挥各自的优势。接下来，我们将介绍几种具有代表性的数据格式，每种格式都有其独特的特点和应用：
- en: •
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Embedding Vectors. Embedding vectors represent words, phrases, or even entire
    documents as dense vectors in high-dimensional spaces. This format is crucial
    for processing information in machine-readable forms, such as natural language
    and images, enabling LLMs to efficiently and accurately retrieve necessary information
    for content generation. We note that dense vector retrieval, as exemplified by
    Karpukhin et al. ([2020](#bib.bib51)), generally serves as a necessary intermediate
    step for various data formats. Many different data formats are represented as
    dense vectors during this retrieval process. Specifically, when introducing embedding
    vector-based data formats, we refer to methods that explicitly store information
    in vector format. This approach is commonly used in conversational agents to maintain
    long-term memories. For example, Zhong et al. ([2023](#bib.bib139)) identified
    the lack of long-term memory as a significant limitation in current LLM-based
    applications such as ChatGPT. This issue is particularly noticeable in scenarios
    that require sustained interactions, such as personal companionship, psychological
    counseling, and secretarial tasks. To equip LLMs with the ability to effectively
    access long-term memory, Zhong et al. ([2023](#bib.bib139)) proposed “MemoryBank,”
    a novel vector-retrieval mechanism designed specifically for LLM-based applications.
    MemoryBank stores user-system past interactions, such as dialogues, as time-aware
    dense vectors known as memory pieces, with a dual-tower dense retriever and a
    memory updater inspired by Ebbinghaus’ Forgetting Curve theory. A chatbot powered
    by MemoryBank demonstrates the effectiveness of this mechanism in long-term conversation.
    Similarly, Zhao et al. ([2023](#bib.bib138)) stores long-term conversational data
    as vectors for open-domain dialogue applications, where each piece of dialogue
    or summarized memory is transformed into a high-dimensional vector that captures
    its semantic meaning. Contrastive representation learning is used to increase
    the accuracy of memory retrieval. Lee et al. ([2023](#bib.bib56)) proposed a memory-enhanced
    chatbot to achieve long-term consistency and flexibility in open-domain conversations.
    It uses a summarizer model to summarize dialogues and store them as dense vectors
    in a memory pool after a certain number of rounds. Then, the relevant memory is
    retrieved to help generate responses. Later, Lu et al. ([2023](#bib.bib65)) introduced
    “Memochat,” which proposed an iterative “memorization-retrieval-response” cycle
    to maintain consistency in long conversations covering multiple topics. In this
    cycle, LLMs are trained to create structured memos, which help to keep track of
    the conversation context and topics.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 嵌入向量。嵌入向量将单词、短语，甚至整个文档表示为高维空间中的密集向量。这种格式对于以机器可读形式处理信息至关重要，如自然语言和图像，能够使大型语言模型（LLMs）高效且准确地检索生成内容所需的信息。我们注意到，正如Karpukhin等人（[2020](#bib.bib51)）所示，密集向量检索通常作为处理各种数据格式的必要中间步骤。在这个检索过程中，许多不同的数据格式被表示为密集向量。具体来说，当介绍基于嵌入向量的数据格式时，我们指的是那些明确将信息以向量格式存储的方法。这种方法在对话代理中广泛使用，用于维持长期记忆。例如，Zhong等人（[2023](#bib.bib139)）指出，缺乏长期记忆是当前基于LLM的应用（如ChatGPT）中的一个重要限制。这个问题在需要持续互动的场景中尤为明显，比如个人陪伴、心理咨询和秘书工作等。为了使LLMs能够有效访问长期记忆，Zhong等人（[2023](#bib.bib139)）提出了“MemoryBank”，一种专为LLM应用设计的新型向量检索机制。MemoryBank将用户和系统的历史互动，如对话，存储为时间感知的密集向量，这些向量被称为记忆片段，并使用双塔密集检索器和基于艾宾浩斯遗忘曲线理论的记忆更新器。由MemoryBank支持的聊天机器人展示了这种机制在长期对话中的有效性。类似地，Zhao等人（[2023](#bib.bib138)）将长期对话数据存储为向量，用于开放领域对话应用，其中每一段对话或总结的记忆都会被转化为高维向量，以捕捉其语义含义。对比表示学习被用来提高记忆检索的准确性。Lee等人（[2023](#bib.bib56)）提出了一种增强记忆的聊天机器人，旨在实现开放领域对话中的长期一致性和灵活性。该系统使用一个总结器模型来总结对话，并在一定轮次后将其存储为密集向量，存入记忆池中。然后，相关的记忆会被检索，以帮助生成回应。后来，Lu等人（[2023](#bib.bib65)）提出了“Memochat”，该系统提出了一种迭代的“记忆-检索-回应”循环，以在涵盖多个主题的长期对话中保持一致性。在这一循环中，LLMs被训练以创建结构化的备忘录，帮助跟踪对话的上下文和主题。
- en: •
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Plain-Text Documents. Language models that generate responses by retrieving
    external plain-text documents can greatly improve the quality of responses. This
    is especially true for tasks that demand domain-specific knowledge or up-to-date
    information, such as question answering (Guu et al., [2020](#bib.bib39); Borgeaud
    et al., [2022](#bib.bib9)) and fact verification (Lewis et al., [2020](#bib.bib57);
    Izacard et al., [2022](#bib.bib48)). Plain-text documents, which consist of unstructured
    text data, are often vast in size and contain a wealth of information. Examples
    of such retrieval include Wikipedia articles (Guu et al., [2020](#bib.bib39)),
    textbooks (Wang et al., [2023d](#bib.bib117)), and programming code (Zhou et al.,
    [2022](#bib.bib140)). Retrieving information from these documents poses a challenge
    due to their dense and extensive nature. Therefore, advanced retrieval methods
    such as Dense Passage Retrieval (DPR) (Karpukhin et al., [2020](#bib.bib51)) are
    frequently utilized in the retrieval process. Retrieval-augmented LLM based on
    external document collections is an important extension of LLMs, where the system
    is not just reliant on pre-trained knowledge but also actively retrieves external
    knowledge for better response generation. The augmentation allows for more accurate,
    up-to-date, and context-relevant responses, particularly crucial for tasks involving
    real-time data or specialized knowledge. Research in this field is often referred
    to as Retrieval-Augmented Generation (RAG), focusing on critical issues such as
    pre-training language models in retrieval contexts and fine-tuning them for downstream
    tasks.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 纯文本文档。通过检索外部纯文本文档生成回应的语言模型可以显著提高回应的质量。对于那些需要领域特定知识或最新信息的任务，这一点尤其重要，例如问答（Guu等，[2020](#bib.bib39)；Borgeaud等，[2022](#bib.bib9)）和事实核查（Lewis等，[2020](#bib.bib57)；Izacard等，[2022](#bib.bib48)）。纯文本文档由非结构化文本数据组成，通常规模庞大，包含丰富的信息。这类检索的例子包括维基百科文章（Guu等，[2020](#bib.bib39)）、教科书（Wang等，[2023d](#bib.bib117)）和编程代码（Zhou等，[2022](#bib.bib140)）。从这些文档中检索信息具有挑战性，因为它们既密集又庞大。因此，像密集段落检索（DPR）（Karpukhin等，[2020](#bib.bib51)）这样的高级检索方法通常在检索过程中被广泛使用。基于外部文档集合的检索增强型大语言模型（LLM）是大语言模型的重要扩展，其中系统不仅依赖于预训练知识，还主动检索外部知识，以生成更好的回应。这种增强使得回应更加准确、及时且与上下文相关，特别适用于涉及实时数据或专业知识的任务。该领域的研究通常被称为检索增强生成（RAG），重点研究在检索上下文中预训练语言模型以及为下游任务进行微调等关键问题。
- en: •
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Structured Data. Structured data is a commonly used format for storing external,
    useful knowledge for LLMs. Since much information naturally exists in structural
    formats, this enables models to access a wide range of information within complex
    knowledge structures. The sources of structured data are diverse, with knowledge
    graphs being one of the most pertinent formats for augmenting LLMs’ generative
    abilities: Pan et al. ([2023](#bib.bib73)) explicitly discuss the use of knowledge
    graphs to address the hallucination issues in LLMs and enhance their interpretability.
    Furthermore, several popular LLM tools, such as LlamaIndex (Liu, [2022](#bib.bib61)),
    offer options to leverage existing knowledge graphs to improve knowledge generation.
    Another potentially valuable data format is tabular data. As introduced in Sundar
    and Heck ([2023](#bib.bib104)), a novel concept of Conversational Tables (cTBLS)
    is designed to enhance the capabilities of conversational AI by integrating tabular
    data. This work utilizes a dense table retrieval method to rank relevant table
    cells. Subsequently, the responses of LLMs are grounded in the tabular information
    and the conversational context.'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结构化数据。结构化数据是存储外部有用知识以供大语言模型（LLM）使用的常见格式。由于许多信息自然存在于结构化格式中，这使得模型能够在复杂的知识结构中访问广泛的信息。结构化数据的来源多种多样，其中知识图谱是增强LLM生成能力的最相关格式之一：Pan等人（[2023](#bib.bib73)）明确讨论了使用知识图谱来解决LLM中的幻觉问题并增强其可解释性。此外，一些流行的LLM工具，如LlamaIndex（Liu，[2022](#bib.bib61)），提供了利用现有知识图谱来改善知识生成的选项。另一个潜在有价值的数据格式是表格数据。正如Sundar和Heck（[2023](#bib.bib104)）介绍的那样，一种新概念——对话表格（cTBLS）旨在通过整合表格数据来增强对话AI的能力。该工作使用密集表格检索方法对相关的表格单元进行排序。随后，LLM的回应将基于表格信息和对话上下文。
- en: 3.3.2 Data Retrieval Methods
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 数据检索方法
- en: The ability to access relevant and accurate information from external storage
    through sophisticated data retrieval methods is crucial for LLMOS’s execution
    of targeted actions. A primary challenge in this process is selecting the most
    appropriate data file from an extensive repository of information. These data
    retrieval methods operate automatically, leveraging advanced algorithms and machine
    learning techniques.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 通过复杂的数据检索方法从外部存储中访问相关和准确的信息的能力，对于 LLMOS 执行目标行动至关重要。这个过程中的一个主要挑战是从庞大的信息库中选择最合适的数据文件。这些数据检索方法自动运行，利用先进的算法和机器学习技术。
- en: For instance, Zhu et al. ([2023](#bib.bib142)) show that LLM can store past
    accomplished sub-goals of video games using a dictionary, where the sub-goals
    are keys, and the corresponding action sequences are values. When encountering
    familiar objectives, the first action is easily retrieved using the name of the
    goal. Conversely, Park et al. ([2023](#bib.bib75)) propose a more sophisticated
    “memory stream” to record agents’ past experiences in a list, labeled with text
    descriptions and timestamps of creation or last interaction. This data storage
    strategy enables agents to effectively retrieve useful experiences based on their
    current situation, using scores of Recency, Importance, and Relevance. Similarly,
    Zhong et al. ([2023](#bib.bib139)) discuss storing detailed records of daily conversations,
    summaries of past events, and assessments of user personalities as vector representations
    indexed by FAISS (Johnson et al., [2019](#bib.bib50)), a library used for efficient
    similarity search in stored vectors. Furthermore, Hu et al. ([2023](#bib.bib42))
    highlight the limitations of conventional neural memory mechanisms, which are
    not symbolic and rely on vector similarity calculations, being prone to errors.
    It suggests the use of databases as an external symbolic memory for LLMs. Complex
    problems are decomposed into a series of SQL-based memory operation steps, greatly
    simplifying the retrieval process.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Zhu 等人（[2023](#bib.bib142)）表明，LLM 可以通过字典存储视频游戏中已完成的子目标，其中子目标作为键，对应的动作序列作为值。当遇到熟悉的目标时，可以通过目标名称轻松检索到第一个动作。相反，Park
    等人（[2023](#bib.bib75)）提出了一种更复杂的“记忆流”来记录代理的过去经验，以列表的形式存储，并标注有文本描述以及创建或最后交互的时间戳。这种数据存储策略使得代理能够根据当前情况有效地检索有用的经验，使用近期性、重要性和相关性的评分。类似地，Zhong
    等人（[2023](#bib.bib139)）讨论了将每日对话的详细记录、过去事件的总结以及用户个性评估作为向量表示存储，并通过 FAISS（Johnson
    等人，[2019](#bib.bib50)）索引，该库用于在存储的向量中进行高效的相似性搜索。此外，Hu 等人（[2023](#bib.bib42)）强调了传统神经记忆机制的局限性，这些机制不是符号性的，且依赖于向量相似性计算，容易出错。该研究建议使用数据库作为
    LLM 的外部符号记忆。复杂问题被分解为一系列基于 SQL 的记忆操作步骤，从而大大简化了检索过程。
- en: 'On the other hand, retrieving information from extremely large external documents
    heavily relies on existing methods in Information Retrieval (IR) research (Croft
    et al., [2010](#bib.bib23)). Modern Information Retrieval involves two key stages:
    retrieval and ranking. The retrieval stage focuses on fetching relevant documents
    based on user queries using algorithms such as vector space models (Salton, [1975](#bib.bib92);
    Robertson et al., [2009](#bib.bib86)), or pre-trained models such as BERT (Devlin
    et al., [2018](#bib.bib26); Karpukhin et al., [2020](#bib.bib51)). LLM extensively
    applies these methods for applications that depend on generating comprehensive
    domain knowledge or accurate information. To ensure better accuracy in retrieving
    information from a vast amount of documents, effective index representations are
    usually learned during pre-training or fine-tuning (Guu et al., [2020](#bib.bib39);
    Borgeaud et al., [2022](#bib.bib9); Lewis et al., [2020](#bib.bib57); Izacard
    et al., [2022](#bib.bib48); Hua et al., [2023b](#bib.bib44)).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，从极大外部文档中检索信息在很大程度上依赖于信息检索（IR）研究中的现有方法（Croft 等人，[2010](#bib.bib23)）。现代信息检索涉及两个关键阶段：检索和排序。检索阶段侧重于基于用户查询，通过使用向量空间模型（Salton，[1975](#bib.bib92)；Robertson
    等人，[2009](#bib.bib86)）等算法，或使用预训练模型如 BERT（Devlin 等人，[2018](#bib.bib26)；Karpukhin
    等人，[2020](#bib.bib51)）来获取相关文档。LLM 广泛应用这些方法，用于依赖于生成全面领域知识或准确获取信息的应用程序。为了确保从大量文档中更准确地检索信息，通常会在预训练或微调过程中学习有效的索引表示（Guu
    等人，[2020](#bib.bib39)；Borgeaud 等人，[2022](#bib.bib9)；Lewis 等人，[2020](#bib.bib57)；Izacard
    等人，[2022](#bib.bib48)；Hua 等人，[2023b](#bib.bib44)）。
- en: 3.4 Tools (as Devices/Libraries)
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 工具（作为设备/库）
- en: In a traditional OS, peripheral devices, such as keyboards, mice, and printers,
    extend the system’s capabilities, allowing for diverse forms of input and output
    that enhance the overall functionality of the computer. There are also various
    programming libraries, which include a diverse set of reusable functionalities
    that can be leveraged by applications through API calls. Similarly, in the context
    of AIOS, hardware tools can be seen as analogous to these peripheral devices,
    and software tools can be seen as analogous to these libraries and APIs. These
    tools can range from data analysis modules to interactive interfaces, each adding
    a unique dimension to the LLM’s processing and response abilities. They allow
    the LLM to interact with different data types, environments, and user requirements,
    significantly enriching its functionality. As a result, these hardware and software
    tools help the LLM to interact with the physical and digital worlds, expanding
    LLM’s capabilities, and can be leveraged by agents for complex task solving. In
    the upcoming sections, we will delve into the specifics of these tools, illustrating
    how they enrich the LLM’s capacity within the AIOS.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统操作系统中，外围设备，如键盘、鼠标和打印机，扩展了系统的功能，使得计算机可以进行多样的输入和输出，从而增强了整体功能。此外，还有各种编程库，包含了多样的可重用功能，这些功能可以通过API调用被应用程序利用。类似地，在AIOS的背景下，硬件工具可以类比为这些外围设备，而软件工具则类似于这些库和API。这些工具从数据分析模块到交互界面不等，每种工具都为LLM的处理和响应能力增添了独特的维度。它们使LLM能够与不同类型的数据、环境和用户需求进行交互，显著丰富了其功能。因此，这些硬件和软件工具帮助LLM与物理世界和数字世界进行交互，扩展了LLM的能力，并可以被代理用于复杂任务的解决。在接下来的章节中，我们将深入探讨这些工具的具体内容，展示它们如何在AIOS中丰富LLM的能力。
- en: 3.4.1 Tool Categories
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.1 工具类别
- en: Though LLMs are adept at handling numerous tasks, they encounter limitations
    in complex tasks that require deep domain knowledge or interaction with the external
    world. External tools enable LLMs to harness various resources and specialized
    knowledge, bolstering their capabilities. In the following, we present several
    representative tools for LLMs, as discussed in the existing literature.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM在处理许多任务方面非常熟练，但在需要深厚领域知识或与外部世界互动的复杂任务中，它们会遇到局限性。外部工具使LLM能够利用各种资源和专业知识，增强其能力。以下是我们根据现有文献介绍的几种LLM的代表性工具。
- en: •
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Software Tools are domain expert models or APIs that help LLMs to finish a specialized
    sub-task, such as searching a query on the Web through a search API or checking
    the weather through a third party weather service API. Recent trends show a growing
    integration of APIs with LLMs, serving as interfaces for external programs to
    interact with LLMs, and acting as a bridge between the LLM and other software
    applications, thus extending LLMs’ capabilities across various applications and
    services. For instance, OpenAGI (Ge et al., [2023](#bib.bib35)) trains LLMs to
    use various domain expert models as tools for reasoning, planing, and complex
    task solving based on reinforcement learning from task feedback (RLTF). TPTU (Ruan
    et al., [2023a](#bib.bib88)) interfaces with both Python interpreters and LaTeX
    compilers for mathematical computations. Gorilla (Patil et al., [2023](#bib.bib76)),
    a fine-tuned LLM, is engineered to generate precise API call arguments and prevent
    hallucinations. ToolLLM (Qin et al., [2023b](#bib.bib83)) presents a general framework
    for tool use, including data construction, model training, and evaluation. It
    also provides an instruction-tuning dataset for tools, collected from over 16,000
    real-world APIs. TaskMatrix.AI (Liang et al., [2023b](#bib.bib60)) connects foundational
    models with millions of APIs for diverse task completion, facilitating user interaction
    in an interactive manner. ChemCrow (Bran et al., [2023](#bib.bib10)) integrates
    several expert-designed models to augment LLMs in chemistry-related tasks such
    as organic synthesis, drug discovery, and materials design. MM-REACT (Yang et al.,
    [2023a](#bib.bib128)) combines LLMs with various vision expert models for advanced
    multi-modal reasoning and actions. Using expert models as tools, LLM agents can
    tackle advanced tasks necessitating expert knowledge.
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 软件工具是领域专家模型或 API，帮助大语言模型完成专门的子任务，例如通过搜索 API 在网络上搜索查询，或通过第三方天气服务 API 查询天气。近期趋势显示，API
    与大语言模型的集成日益增加，作为外部程序与大语言模型互动的接口，充当大语言模型与其他软件应用程序之间的桥梁，从而扩展了大语言模型在各种应用和服务中的能力。例如，OpenAGI（Ge
    等人，[2023](#bib.bib35)）训练大语言模型使用各种领域专家模型作为工具进行推理、规划和复杂任务解决，这些工具基于来自任务反馈的强化学习（RLTF）。TPTU（Ruan
    等人，[2023a](#bib.bib88)）与 Python 解释器和 LaTeX 编译器进行接口，进行数学计算。Gorilla（Patil 等人，[2023](#bib.bib76)），一个经过微调的大语言模型，旨在生成精确的
    API 调用参数并防止产生幻觉。ToolLLM（Qin 等人，[2023b](#bib.bib83)）提出了一个通用的工具使用框架，包括数据构建、模型训练和评估。它还提供了一个工具指令调优数据集，收集自超过
    16,000 个真实世界的 API。TaskMatrix.AI（Liang 等人，[2023b](#bib.bib60)）将基础模型与数百万个 API 连接起来，完成多样的任务，便于用户以交互的方式进行互动。ChemCrow（Bran
    等人，[2023](#bib.bib10)）集成了多个专家设计的模型，增强了大语言模型在化学相关任务中的能力，例如有机合成、药物发现和材料设计。MM-REACT（Yang
    等人，[2023a](#bib.bib128)）将大语言模型与各种视觉专家模型结合，用于先进的多模态推理和行动。通过使用专家模型作为工具，大语言模型代理能够处理需要专家知识的高级任务。
- en: •
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Hardware Tools. While the aforementioned tools enhance LLMs in the digital world,
    physical tools such as robotics and embodied AI serve as pivotal means to connect
    LLMs with the physical world. These tools enable LLMs to actively observe, understand,
    and interact with their physical surroundings. Observations allow LLMs to gather
    various inputs from the physical world, converting them into multi-modal signals
    to augment actions such as navigation and manipulation. For example, Soundspace
    (Chen et al., [2020](#bib.bib16)) explores observing physical space geometry using
    reverberating audio sensory inputs. Physical tools enable LLMs to execute user
    commands, transcending the role of merely providing natural language instructions.
    SayCan (Ahn et al., [2022](#bib.bib3)), for instance, incorporates physical tools
    into LLMs for real-world tasks such as cleaning tabletops or retrieving items.
    In essence, physical tools act as the “hands, ears, eyes” etc. of LLMs to interact
    with the physical world, fostering real-world grounding.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 硬件工具。虽然前述的工具在数字世界中增强了大语言模型（LLMs）的功能，但诸如机器人和具身人工智能等物理工具则是将大语言模型与物理世界连接的关键手段。这些工具使大语言模型能够主动观察、理解并与其物理环境进行互动。通过观察，大语言模型可以从物理世界收集各种输入，将其转化为多模态信号，从而增强导航和操作等行为。例如，Soundspace（Chen
    等人，[2020](#bib.bib16)）通过回响音频感知输入探索观察物理空间几何形状。物理工具使大语言模型能够执行用户命令，超越了仅仅提供自然语言指令的角色。例如，SayCan（Ahn
    等人，[2022](#bib.bib3)）将物理工具融入大语言模型，用于现实世界中的任务，如清洁桌面或取回物品。从本质上讲，物理工具充当了大语言模型与物理世界互动的“手、耳、眼”等，促进了现实世界的基础。
- en: •
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Self-made Tools. Current tools are primarily designed by humans. Recently, there
    are increasing interest in the use of LLMs for automated tool making. This involves
    generating executable programs or enhancing existing tools to create more powerful
    solutions, guided by appropriate instructions and demonstrations (Qin et al.,
    [2023a](#bib.bib82); Qian et al., [2023b](#bib.bib81); Chen et al., [2021](#bib.bib17)).
    For example, a large code model, as evaluated in Chen et al. ([2021](#bib.bib17)),
    is capable of generating executable programs based on user-provided instructions.
    These programs can then serve as specialized tools to address particular tasks.
    Furthermore, these LLMs can also acquire the ability to self-debug, which is an
    essential skill for maintaining and improving the tool functionality, as detailed
    in Chen et al. ([2023a](#bib.bib19)).
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自制工具。目前的工具主要由人类设计。最近，越来越多的人开始关注使用LLM（大语言模型）来自动化工具的制作。这涉及生成可执行程序或增强现有工具，以创造更强大的解决方案，并通过适当的指令和示范来引导（Qin等人，[2023a](#bib.bib82)；Qian等人，[2023b](#bib.bib81)；Chen等人，[2021](#bib.bib17)）。例如，Chen等人（[2021](#bib.bib17)）评估的大型代码模型能够根据用户提供的指令生成可执行程序。这些程序随后可以作为专门的工具来解决特定任务。此外，这些LLM还可以获得自我调试的能力，这对于维护和改善工具功能至关重要，具体细节见Chen等人（[2023a](#bib.bib19)）。
- en: 3.4.2 Tool-Driver and Tool-API
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.2 Tool-Driver与Tool-API
- en: In traditional OS, Drivers or APIs play a pivotal role in enabling the system
    to interact with specific Devices or Libraries. The drivers provide interfaces
    to connect the OS with hardware devices, while the APIs provide interfaces to
    connect the OS or application with software libraries. In the context AIOS, where
    hardware tools are viewed as devices and software tools are viewed as libraries,
    Tool-Drivers and Tool-APIs are required, which serve as the interface for AIOS
    or agents to use these hardware and sofware tools, respectively.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的操作系统中，驱动程序或API在使系统与特定设备或库进行交互中起着至关重要的作用。驱动程序提供了连接操作系统与硬件设备的接口，而API则提供了连接操作系统或应用程序与软件库的接口。在AIOS的背景下，硬件工具被视为设备，软件工具被视为库，因此需要Tool-Driver和Tool-API，它们分别作为AIOS或代理使用这些硬件和软件工具的接口。
- en: 'Existing literature usually defines the Tool-Drivers and Tool-APIs in the form
    of prompts. Specifically, these prompts are composed of two essential elements:
    application scenarios and invocation methods. Much like how Drivers or APIs in
    a traditional OS control access to specific Devices or Libraries, commonly used
    prompts in AIOS should equip LLMs with an in-depth understanding of application
    scenarios. This enables LLMs to judiciously determine the appropriateness of a
    particular tool for a given task. Moreover, in parallel to how Drivers or APIs
    facilitate the communication between the OS and devices, tool instruction prompts
    should clearly outline the invocation methods. This is crucial for LLMs to comprehend
    the inputs and outputs of the tools, ensuring their effective execution and integration
    into the system.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现有文献通常以提示（prompts）的形式定义Tool-Driver和Tool-API。具体来说，这些提示由两个关键元素组成：应用场景和调用方法。就像传统操作系统中的驱动程序或API控制对特定设备或库的访问一样，AIOS中常用的提示应当使LLM深入理解应用场景。这使得LLM能够明智地判断特定工具在给定任务中的适用性。此外，类似于驱动程序或API促进操作系统与设备之间的通信，工具指令提示应当清晰地概述调用方法。这对于LLM理解工具的输入输出至关重要，从而确保其有效执行并与系统集成。
- en: Utilizing the inherent zero-shot and few-shot learning capabilities of LLMs
    (Radford et al., [2019](#bib.bib84); Brown et al., [2020](#bib.bib12)), agents
    can gain insights about tools through zero-shot prompts that elucidate tool functionalities
    and parameters, or few-shot prompts offering demonstrations of particular tool
    usage scenarios and methodologies (Schick et al., [2023](#bib.bib93); Parisi et al.,
    [2022](#bib.bib74)). Usually, a single tool is inadequate for complex tasks. Hence,
    agents must adeptly decompose these tasks into manageable subtasks, where their
    understanding of the tools is pivotal. After understanding individual tools, LLMs
    should determine their application in addressing complex tasks. One approach is
    to generate actions by extracting pertinent information from memory relevant to
    the current task. For instance, Generative Agents (Park et al., [2023](#bib.bib75))
    maintain a memory stream, consulting it for recent, pertinent, and crucial information
    before each action to guide their decisions. In GITM (Ghost in the Minecraft)
    (Zhu et al., [2023](#bib.bib142)), to achieve specific sub-goals, the agent probes
    its memory to identify if any similar tasks have been successfully executed before.
    If so, it replicates those successful actions for the current task. In collaborative
    frameworks such as ChatDev (Qian et al., [2023a](#bib.bib80)) and MetaGPT (Hong
    et al., [2023](#bib.bib41)), agents engage in mutual communication, retaining
    the conversation history in their memories. Another strategy involves executing
    a pre-formulated plan. For example, in DEPS (Describe, Explain, Plan and Select)
    (Wang et al., [2023a](#bib.bib118)), given a task, if there are no indicators
    of the plan’s failure, the agent proceeds with actions based on that plan.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 利用大型语言模型（LLMs）（Radford et al., [2019](#bib.bib84); Brown et al., [2020](#bib.bib12)）固有的零-shot和少-shot学习能力，智能体可以通过零-shot提示获得关于工具的洞察，阐明工具的功能和参数，或通过少-shot提示提供特定工具使用场景和方法的演示（Schick
    et al., [2023](#bib.bib93); Parisi et al., [2022](#bib.bib74)）。通常，单一工具不足以完成复杂任务。因此，智能体必须熟练地将这些任务分解为可管理的子任务，其中它们对工具的理解至关重要。在理解单个工具后，LLMs应确定它们在解决复杂任务中的应用。一种方法是通过从记忆中提取与当前任务相关的有用信息来生成动作。例如，生成智能体（Park
    et al., [2023](#bib.bib75)）保持一个记忆流，在每个动作之前咨询它，获取近期、相关且重要的信息，以指导其决策。在GITM（Minecraft中的幽灵）（Zhu
    et al., [2023](#bib.bib142)）中，为了实现特定的子目标，智能体探查其记忆，查看是否以前成功执行过类似的任务。如果有，它会复制这些成功的动作来执行当前任务。在ChatDev（Qian
    et al., [2023a](#bib.bib80)）和MetaGPT（Hong et al., [2023](#bib.bib41)）等协作框架中，智能体进行互相交流，并在其记忆中保留对话历史。另一种策略是执行预先制定的计划。例如，在DEPS（描述、解释、计划和选择）（Wang
    et al., [2023a](#bib.bib118)）中，给定一个任务，如果没有计划失败的迹象，智能体就会根据该计划继续执行相应的动作。
- en: 4 AIOS-Agent Ecosystem
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 AIOS-Agent生态系统
- en: 4.1 Agents as Applications
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 智能体作为应用程序
- en: 'On top of the LLMOS-based AIOS, a diverse scope of AI Agent applications can
    be developed, akin to traditional OS-based applications such as browsers and photo-editing
    softwares. These Agent Applications (AAPs) generally comprise three components:
    the agent profile, an accessible external database, and task-specific tools. On
    one hand, the agent profiles are written into the prompt and used to indicate
    the agent functionality, influencing the LLM behaviors to exhibit certain roles
    such as a coder agent, a teacher agent, or a travel planning agent, as described
    in sources such as Qian et al. ([2023a](#bib.bib80)); Li et al. ([2023](#bib.bib58));
    Ge et al. ([2023](#bib.bib35)). Typical agent profiles may encompass basic information
    such as age, gender, and career (Park et al., [2023](#bib.bib75)), or psychology
    information reflecting the personalities of the agents (Serapio-García et al.,
    [2023](#bib.bib94)), as well as social information detailing the relationships
    between agents (Li et al., [2023](#bib.bib58)). The nature of the agent’s profile
    is tailored to the application’s context; for example, applications focused on
    human cognitive processes will emphasize psychological information. Furthermore,
    the inclusion of an external database and toolset within the prompt enhances the
    LLM’s interaction with the external world, specifying elements such as file locations
    and tool descriptions.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于LLMOS的AIOS之上，可以开发各种AI代理应用，就像传统操作系统上的应用程序一样，例如浏览器和照片编辑软件。这些代理应用（AAPs）通常包含三个组件：代理档案、可访问的外部数据库和特定任务的工具。一方面，代理档案被写入提示中，用于指示代理的功能，影响LLM的行为，使其展现出特定角色，如编码代理、教师代理或旅行规划代理，正如Qian等人（[2023a](#bib.bib80)）、Li等人（[2023](#bib.bib58)）、Ge等人（[2023](#bib.bib35)）等资料中所描述的那样。典型的代理档案可能包含基本信息，如年龄、性别和职业（Park等人，[2023](#bib.bib75)），或反映代理个性的心理学信息（Serapio-García等人，[2023](#bib.bib94)），以及社会信息，详述代理之间的关系（Li等人，[2023](#bib.bib58)）。代理档案的性质根据应用的上下文量身定制；例如，专注于人类认知过程的应用将强调心理学信息。此外，在提示中加入外部数据库和工具集增强了LLM与外部世界的互动，指定了文件位置和工具描述等元素。
- en: 'As illustrated in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Agents as Applications
    ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents
    and the AIOS-Agent Ecosystem"), by merging the LLMOS layer with the OS layer,
    Hardware layer, and the Agent Application layer, we can establish an autonomous
    LLMOS-based Agent system. This system will respond to natural language instructions
    from users, capable of executing a variety of tasks through its interactions with
    the environment and its inherent knowledge.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[4](#S4.F4 "图4 ‣ 4.1 代理作为应用 ‣ 4 AIOS-代理生态系统 ‣ LLM作为操作系统，代理作为应用：展望AIOS、代理和AIOS-代理生态系统")所示，通过将LLMOS层与操作系统层、硬件层和代理应用层相融合，我们可以建立一个基于LLMOS的自主代理系统。该系统将能够响应用户的自然语言指令，能够通过与环境的交互以及其固有知识来执行各种任务。
- en: '![Refer to caption](img/7f48603733583da3f4de18be519a930a.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/7f48603733583da3f4de18be519a930a.png)'
- en: 'Figure 4: An illustration of LLMOS-based AI Agent.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：基于LLMOS的AI代理示意图。
- en: 4.2 Natural Language Programming for Agents
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 面向代理的自然语言编程
- en: Natural Language Programming (NLProg) acts as a crucial intermediary between
    LLMOS and Agents within the AIOS-Agent ecosystem. This innovative approach allows
    average users to easily program Agent Applications (AAPs) using natural language.
    This development democratizes the creation and accessibility of computer software,
    representing a significant shift from the traditional OS-APP ecosystem. Traditionally,
    desktop or mobile applications (APPs) required programming by skilled software
    developers using professional programming languages. In contrast, NLProg empowers
    even those without formal training in these languages to develop applications.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言编程（NLProg）作为AIOS-代理生态系统中LLMOS和代理之间的关键中介。这种创新方法使普通用户能够使用自然语言轻松编程代理应用（AAPs）。这一发展使得计算机软件的创建和可访问性变得更加民主化，代表了从传统的操作系统-应用程序生态系统的重大转变。传统上，桌面或移动应用（APPs）需要通过专业编程语言由技术娴熟的软件开发人员编写。相反，NLProg使得即使没有正规编程语言培训的人也能开发应用程序。
- en: This trend aligns with the historical evolution of programming languages, which
    have progressively become more user-friendly. The journey from binary codes to
    assembly language and then to various high-level languages such as C, C++, Java,
    and Python reflects this trend. The introduction of Natural Language as a Programming
    Interface is a natural progression in this evolution. It simplifies programming
    for the average user, allowing them to program agent applications and interact
    with computers without the need for specialized training in conventional programming
    languages.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这一趋势与编程语言的历史演变相一致，编程语言逐渐变得更加用户友好。从二进制代码到汇编语言，再到C、C++、Java、Python等各种高级语言的发展，反映了这一趋势。将自然语言作为编程接口的引入，是这一演变的自然进程。它简化了普通用户的编程过程，使他们能够编写代理应用程序，并与计算机互动，而无需接受传统编程语言的专门训练。
- en: Moreover, this shift has broader implications for the field of computer science
    and technology. It opens up new possibilities for innovation and creativity, as
    a wider range of individuals can contribute to software development. This inclusivity
    can lead to the development of more diverse and tailored applications, as people
    from different backgrounds and with varying expertise can bring their unique perspectives
    to software design. Additionally, NLProg in the AIOS ecosystem fosters a more
    intuitive interaction between humans and computers, enhancing user experience
    and potentially leading to more efficient and effective use of technology in various
    sectors. As this approach gains traction, it could significantly alter the landscape
    of technology development, making it more accessible and aligned with the natural
    human way of communication and understanding.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这一变化对计算机科学和技术领域具有更广泛的影响。它为创新和创造力开辟了新的可能性，因为更多的人可以参与到软件开发中。这种包容性可能会导致更具多样性和定制化的应用程序的开发，因为来自不同背景和具有不同专业知识的人能够将他们独特的视角带入软件设计中。此外，AIOS生态系统中的NLProg促进了人类与计算机之间更直观的互动，提升了用户体验，并有可能在各个行业中促进技术的更高效、更有效使用。随着这种方法的普及，它可能会显著改变技术发展的格局，使其更加易于访问，并与自然的人类沟通和理解方式相契合。
- en: 4.3 The Ecosystem
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 生态系统
- en: In the AIOS-Agent ecosystem, the potential for collaboration and networking
    among agents heralds a new era of digital assistance and decision-making. These
    agents, with their diverse skill sets and role profiles, can work in tandem to
    address complex challenges, offering a multifaceted approach to problem-solving.
    For instance, an agent with a background in data analysis can collaborate with
    another agent specialized in creative design, leading to innovative solutions
    that a single agent might not conceive.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在AIOS-代理生态系统中，代理之间的协作和联网潜力预示着数字助手和决策制定的新纪元。这些代理具有多样化的技能和角色配置，能够协同工作以解决复杂问题，提供一种多方面的解决问题的方法。例如，一个专注于数据分析的代理可以与另一个擅长创意设计的代理合作，产生单一代理无法想出的创新解决方案。
- en: Moreover, the AIOS ecosystem is designed to be scalable, accommodating an increasing
    number of agents as user needs grow and evolve. This scalability ensures that
    the system remains efficient and effective, even as the complexity of tasks increases.
    The AIOS also emphasizes the importance of learning and adaptation. Agents in
    this ecosystem can learn from their interactions, both with users and other agents,
    continuously evolving and enhancing their capabilities. This feature is crucial
    for keeping up with the rapidly changing landscape of technology and user expectations.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AIOS生态系统设计上具有可扩展性，能够随着用户需求的增长和发展而容纳更多的代理。这样的可扩展性确保了系统即使在任务复杂性增加时，仍能保持高效和有效。AIOS还强调学习和适应的重要性。该生态系统中的代理能够从与用户和其他代理的互动中学习，持续进化并增强其能力。此特性对于跟上技术和用户期望迅速变化的步伐至关重要。
- en: In the broader context, the AIOS-Agent ecosystem can significantly impact various
    industries, from healthcare, where agents can assist in patient care and medical
    research, to education, where agents can offer personalized learning experiences.
    The versatility and adaptability of this ecosystem make it a valuable asset in
    any field where decision making, data analysis, and creative problem solving are
    crucial. As this technology matures, it holds the promise of transforming our
    interaction with the digital world, making it more intuitive, efficient, and responsive
    to our needs.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在更广泛的背景下，AIOS-智能体生态系统可以对各行各业产生深远影响，从医疗保健领域，智能体可以协助患者护理和医学研究，到教育领域，智能体可以提供个性化学习体验。该生态系统的多功能性和适应性使其成为任何需要决策、数据分析和创造性问题解决的领域中的宝贵资产。随着这项技术的成熟，它有望改变我们与数字世界的互动，使其更加直观、高效，并响应我们的需求。
- en: '5 LLMOS in Practice: AI Agents'
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 LLMOS实践：AI智能体
- en: 'In this section, we present a comprehensive overview of the current applications
    of LLMOS-based agents, aiming to provide a wide-ranging perspective on their practical
    deployment scenarios. Specifically, we mainly introduce three scenarios: single
    agent applications, multi-agent applications, and human-agent applications.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将全面概述基于LLMOS的智能体当前应用，旨在提供广泛的视角，展示其实际应用场景。具体来说，我们主要介绍三种场景：单一智能体应用、多智能体应用和人类-智能体应用。
- en: 5.1 Single Agent Applications
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 单一智能体应用
- en: Single agent applications mainly focus on utilizing a single agent to address
    various user tasks. We categorize single agent applications into two distinct
    types based on the external environments they interacted with, i.e., physical
    environment and virtual/digital environment.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 单一智能体应用主要集中在利用单一智能体解决各种用户任务。我们根据智能体与外部环境的交互方式将单一智能体应用分为两种类型：物理环境和虚拟/数字环境。
- en: 5.1.1 Physical Environment
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1 物理环境
- en: Unlike virtual or simulated environments, the physical environment is made up
    of tangible elements that an AI Agent must navigate or manipulate. This concept
    is particularly relevant in the field of robotics and embodied AI, where the agents
    are not just software algorithms but have a physical presence or are integrated
    with physical systems. Following this, we present a range of exemplary scenarios,
    as detailed in existing literature.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 与虚拟或模拟环境不同，物理环境由实际的元素组成，智能体必须在其中导航或操作。这一概念在机器人学和具身人工智能领域尤为重要，在这些领域中，智能体不仅仅是软件算法，而是具有物理存在，或与物理系统集成。接下来，我们将展示一些典型的场景，具体内容可参见现有文献。
- en: •
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Scientific Research. Agents have the capacity to function autonomously, undertaking
    experiments independently, while also serving as invaluable resources for scientists
    engaged in research projects (Boiko et al., [2023](#bib.bib8); Bran et al., [2023](#bib.bib10)).
    For instance, Boiko et al. ([2023](#bib.bib8)) propose an end-to-end platform
    that automates scientific experimentation, integrating AI modules, reasoning capabilities,
    software tools, and laboratory hardware. It autonomously performs tasks ranging
    from online information gathering and experiment design to running protocols and
    controlling robotic equipment, while adapting to errors and refusing unethical
    requests. ChemCrow (Bran et al., [2023](#bib.bib10)) is a suite of 17 specialized
    tools designed to aid chemical research, offering methodological suggestions and
    highlighting safety hazards based on the input objectives. Huang et al. ([2023](#bib.bib46))
    also propose MLAgentBench, a suite of ML tasks for benchmarking AI research agents.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 科学研究。智能体具有自主执行任务的能力，可以独立进行实验，同时也为从事科研项目的科学家提供宝贵的资源（Boiko 等， [2023](#bib.bib8)；Bran
    等， [2023](#bib.bib10)）。例如，Boiko 等（[2023](#bib.bib8)）提出了一种端到端平台，自动化科学实验，集成了人工智能模块、推理能力、软件工具和实验室硬件。它可以自主完成从在线信息收集、实验设计到执行方案和控制机器人设备的任务，同时能够适应错误并拒绝不道德的请求。ChemCrow（Bran
    等， [2023](#bib.bib10)）是一套由17个专门工具组成的工具集，旨在辅助化学研究，基于输入目标提供方法论建议并突出安全隐患。黄等（[2023](#bib.bib46)）还提出了MLAgentBench，一套用于评估AI研究智能体的机器学习任务。
- en: •
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Robotics. Recent studies have employed LLM-based agents in the fields of Robotics.
    For example, ChatGPT for Robotics (Vemprala et al., [2023](#bib.bib111)) employs
    ChatGPT for a wide array of robotics tasks through strategic prompt engineering,
    showing its ability to comprehend and respond to natural language instructions
    in the context of robotics applications. SayCan (Ahn et al., [2022](#bib.bib3))
    comprises two integral components: the “Say” part of the LLM, responsible for
    task-grounding by identifying pertinent actions for a high-level objective, and
    the “Can” part, which encompasses the learned affordance functions that offer
    a world-grounding, thereby determining the feasible actions for the plan’s execution.
    It ensures not only the relevance of the actions chosen for the specified task
    but also their feasibility in the real-world scenario. VOYAGER (Wang et al., [2023e](#bib.bib112))
    presents lifelong learning with prompting mechanisms, skill library, and self-verification,
    which are based on LLM. These three modules aim to enhance the development of
    more complex behaviors of agents.'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 机器人技术。最近的研究将基于大规模语言模型（LLM）的智能体应用于机器人领域。例如，ChatGPT for Robotics（Vemprala et al.,
    [2023](#bib.bib111)）通过战略性的提示工程，广泛应用于各种机器人任务，展示了它在机器人应用中理解并回应自然语言指令的能力。SayCan（Ahn
    et al., [2022](#bib.bib3)）包含两个核心组件：“Say”部分由LLM组成，负责通过识别相关动作来实现任务的基础，以支持高层次目标；“Can”部分则包括学习到的功能函数，提供世界基础，从而确定计划执行的可行动作。它不仅确保所选择的动作与指定任务相关，而且确保这些动作在现实场景中的可行性。VOYAGER（Wang
    et al., [2023e](#bib.bib112)）提出了基于LLM的终身学习、提示机制、技能库和自我验证的模型。这三个模块旨在促进智能体更复杂行为的发展。
- en: •
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Autonomous Driving. Recent studies have harnessed LLMs to enhance self-driving
    car technologies. For example, Fu et al. ([2023a](#bib.bib33)) propose an agent-based
    autonomous driving system, which widely adopts a four-module framework: Environment,
    Agent, Memory, and Expert. Within this framework, the Environment sets the interaction
    stage, the Agent perceives the environment and makes decision, the Memory accumulates
    experience for action, and the Expert provides training advice and inconsistency
    feedback.'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动驾驶。最近的研究利用LLM技术来增强自动驾驶汽车技术。例如，Fu et al. ([2023a](#bib.bib33))提出了一种基于智能体的自动驾驶系统，该系统广泛采用四模块框架：环境、智能体、记忆和专家。在这个框架中，环境设置交互舞台，智能体感知环境并做出决策，记忆积累行动经验，专家提供训练建议和不一致性反馈。
- en: 5.1.2 Virtual/Digital Environment
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2 虚拟/数字环境
- en: Agents in virtual or digital environment mainly includes the manipulation of
    APIs (Schick et al., [2023](#bib.bib93); Yao and Narasimhan, [2023](#bib.bib130);
    Ge et al., [2023](#bib.bib35); Parisi et al., [2022](#bib.bib74); Tang et al.,
    [2023](#bib.bib105)), accessing the Internet and websites (Nakano et al., [2022](#bib.bib68)),
    executing codes (Zhang et al., [2023](#bib.bib137)), and simulation in historical
    settings (Hua et al., [2023a](#bib.bib43)). Such digital grounding is cheaper
    and faster than physical or human interaction. It is thus a convenient test bed
    for language agents and has been studied with increasing intensity in recent years.
    In the following, we present several representative scenarios as studied in the
    existing literature.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟或数字环境中的智能体主要包括API的操作（Schick et al., [2023](#bib.bib93); Yao and Narasimhan,
    [2023](#bib.bib130); Ge et al., [2023](#bib.bib35); Parisi et al., [2022](#bib.bib74);
    Tang et al., [2023](#bib.bib105)）、访问互联网和网站（Nakano et al., [2022](#bib.bib68)）、执行代码（Zhang
    et al., [2023](#bib.bib137)）、以及在历史背景下的仿真（Hua et al., [2023a](#bib.bib43)）。这种数字化基础比物理或人工互动更便宜、更快捷。因此，它是语言智能体的便利测试平台，并且近年来受到越来越多的关注。接下来，我们将介绍现有文献中研究的几种代表性场景。
- en: •
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Coding. This category focuses on leveraging the capabilities of agents to generate
    programs. For example, ToolCoder (Zhang et al., [2023](#bib.bib137)) is a system
    that merges API search tools with existing models to facilitate code generation
    and API selection, using a two-step approach. Initially, an automated data annotation
    technique involving ChatGPT embeds tool usage data into the source code, followed
    by fine-tuning the code generation model; during inference, the API search tool
    is integrated to autonomously suggest API choices, optimizing code generation
    and improving API selection decision-making. Moreover, Lemur-series models (Xu
    et al., [2023](#bib.bib124)) are meticulously pre-trained and instruction fine-tuned
    to demonstrate balanced language and coding capabilities.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编程。这个类别专注于利用代理的能力生成程序。例如，ToolCoder（Zhang 等人，[2023](#bib.bib137)）是一个系统，将API搜索工具与现有模型相结合，使用两步法促进代码生成和API选择。首先，使用ChatGPT的自动数据标注技术将工具使用数据嵌入到源代码中，然后微调代码生成模型；在推理过程中，集成API搜索工具来自主地建议API选择，从而优化代码生成并提高API选择的决策能力。此外，Lemur系列模型（Xu
    等人，[2023](#bib.bib124)）经过精心的预训练和指令微调，展现出平衡的语言和编程能力。
- en: •
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Web Service. This category primarily revolves around utilizing agents to address
    web-based tasks through diverse APIs. For example, Auto-GPT (Gravitas, [2023](#bib.bib37))
    is an automated agent designed to set multiple objectives, break them down into
    relevant tasks, and iterate on these tasks until the objectives are achieved.
    OpenAGI (Ge et al., [2023](#bib.bib35)) is an LLM-based agent designed for reasoning,
    planing, and executing tools to achieve complex tasks, accompanied with a benchmark
    to evalute the agent’s task-solving performance. BMTools (Qin et al., [2023a](#bib.bib82))
    is an open-source repository that extends LLMs with tools and provides a platform
    for community-driven tool building and sharing. It supports various types of tools,
    enables simultaneous task execution using multiple tools, and offers a simple
    interface for loading plugins via URLs, fostering easy development and contribution
    to the BMTools ecosystem. Mind2Web (Deng et al., [2023](#bib.bib25)) provides
    a benchmark for developing and evaluating generalist agents for the Web, which
    are agents that can follow language instructions to complete complex tasks on
    websites. MusicAgent (Yu et al., [2023](#bib.bib133)) integrates numerous music-related
    tools and an autonomous workflow to address user requirements. Auto-UI (Zhan and
    Zhang, [2023](#bib.bib136)) is a multi-modal solution that directly interacts
    with the interface, bypassing the need for environment parsing or the dependence
    on application-dependent APIs.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Web服务。这个类别主要围绕利用代理通过各种API处理基于Web的任务。例如，Auto-GPT（Gravitas，[2023](#bib.bib37)）是一个自动化代理，旨在设定多个目标，将其分解为相关任务，并迭代这些任务，直到目标完成。OpenAGI（Ge
    等人，[2023](#bib.bib35)）是一个基于LLM的代理，旨在进行推理、规划和执行工具以实现复杂任务，并附带一个基准来评估代理的任务解决表现。BMTools（Qin
    等人，[2023a](#bib.bib82)）是一个开源库，通过工具扩展LLMs，并提供一个社区驱动的工具构建和分享平台。它支持各种类型的工具，能够使用多个工具同时执行任务，并提供一个简易接口，通过URL加载插件，促进BMTools生态系统的轻松开发和贡献。Mind2Web（Deng
    等人，[2023](#bib.bib25)）为开发和评估Web通用代理提供了一个基准，这些代理能够根据语言指令在网站上完成复杂任务。MusicAgent（Yu
    等人，[2023](#bib.bib133)）集成了许多与音乐相关的工具和自主工作流，以满足用户需求。Auto-UI（Zhan 和 Zhang，[2023](#bib.bib136)）是一个多模态解决方案，直接与界面交互，跳过环境解析或对应用程序特定API的依赖。
- en: •
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Games. This includes agents interacting in the game environments (Hausknecht
    et al., [2020](#bib.bib40); Côté et al., [2019](#bib.bib22); Shridhar et al.,
    [2020](#bib.bib98)). For example, MineClip, introduced by Fan et al. ([2022](#bib.bib30)),
    is a novel agent learning algorithm that leverages large pre-trained video-language
    models as a learned reward function. Based on it, the authors further proposed
    MineDojo, a framework built on the popular Minecraft game that features a simulation
    suite with thousands of diverse open-ended tasks and an internet-scale knowledge
    base with Minecraft videos, tutorials, wiki pages, and forum discussions.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 游戏。这个类别包括代理在游戏环境中的互动（Hausknecht 等人，[2020](#bib.bib40)；Côté 等人，[2019](#bib.bib22)；Shridhar
    等人，[2020](#bib.bib98)）。例如，Fan 等人（[2022](#bib.bib30)）提出的MineClip，是一种新型的代理学习算法，利用大型预训练的视频语言模型作为学习的奖励函数。在此基础上，作者进一步提出了MineDojo，这是一个基于流行的Minecraft游戏构建的框架，具有一个模拟套件，包含成千上万种多样的开放式任务，并且拥有一个规模庞大的知识库，涵盖了Minecraft视频、教程、维基页面和论坛讨论。
- en: •
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Recommendation. Recent literature demonstrates the efficacy of employing LLM
    and Agents in recommender systems (Geng et al., [2022](#bib.bib36); Wang et al.,
    [2023c](#bib.bib116); Feng et al., [2023](#bib.bib31); Wang et al., [2023f](#bib.bib113)).
    For instance, RecMind (Wang et al., [2023c](#bib.bib116)) develop an LLM-based
    recommender system agent, which provides personalized recommendations based on
    planning, use of tools, obtaining external knowledge, and leveraging individual
    user’s personalized data. LLMCRS Feng et al. ([2023](#bib.bib31)) is a conversational
    recommendation agent that utilizes Large Language Models (LLMs) for efficient
    sub-task management during the recommendation process. It combines LLMs with expert
    models for specific sub-tasks and employs LLMs as a language interface for generating
    improved user responses, thereby enhancing overall performance and response quality
    in conversational recommendation systems.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 推荐系统。近期文献证明了在推荐系统中使用LLM和智能体的有效性（Geng 等，[2022](#bib.bib36)；Wang 等，[2023c](#bib.bib116)；Feng
    等，[2023](#bib.bib31)；Wang 等，[2023f](#bib.bib113)）。例如，RecMind（Wang 等，[2023c](#bib.bib116)）开发了一种基于LLM的推荐系统智能体，该智能体通过规划、使用工具、获取外部知识以及利用个体用户的个性化数据来提供个性化推荐。LLMCRS（Feng
    等，[2023](#bib.bib31)）是一个对话推荐智能体，利用大语言模型（LLMs）在推荐过程中高效地进行子任务管理。它将LLMs与专家模型结合用于特定子任务，并将LLMs作为语言接口生成改进的用户响应，从而提升对话推荐系统的整体表现和响应质量。
- en: 5.2 Multi-Agent Applications
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 多智能体应用
- en: 'Multi-Agent Systems (MAS) (Wooldridge and Jennings, [1995](#bib.bib122)) emphasize
    the coordination and collaboration among a group of agents to effectively solve
    problems. The existing LLM-based MAS landscape is broadly categorized into two
    types: Collaborative Interaction and Adversarial Interaction.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 多智能体系统（MAS）（Wooldridge 和 Jennings，[1995](#bib.bib122)）强调一组智能体之间的协调与合作，以有效解决问题。基于大语言模型（LLM）的现有MAS应用可大致分为两种类型：协作互动和对抗互动。
- en: 5.2.1 Collaborative Interaction
  id: totrans-265
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 协作互动
- en: 'As the scope and complexity of tasks amenable to Large Language Models (LLMs)
    increase, a logical strategy to augment the effectiveness of these agents is to
    employ cooperative multi-agent systems. Such systems, prevalently utilized in
    practical applications, operate on the principle where each agent evaluates and
    understands the requirements and capabilities of its peers, thereby fostering
    a collaborative environment conducive to shared actions and information exchange
    (Li et al., [2023](#bib.bib58)). In the specific area of Non-Player Characters
    (NPCs), the concept of Generative Agents (Park et al., [2023](#bib.bib75)) emerges
    as a compelling simulation of human behavior within interactive applications.
    This approach is exemplified by the deployment of twenty-five agents in a sandbox
    environment akin to The Sims, allowing users to engage with and influence the
    agents as they execute daily routines, interact socially, establish relationships,
    and organize group activities. Furthermore, the Humanoid Agents system (Wang et al.,
    [2023b](#bib.bib119)) enhances the realism of Generative Agents by incorporating
    three fundamental aspects of “System 1” processing: the fulfillment of basic needs
    (such as hunger, health, and energy), emotional responses, and the dynamics of
    interpersonal relationships. In the field of Software Development, the MetaGPT
    system (Hong et al., [2023](#bib.bib41)) represents a specialized LLM application
    that leverages a multi-agent conversational framework. This innovative framework
    facilitates automatic software development by assigning distinct roles to various
    GPT models, enabling them to collaborate effectively in the creation of software
    applications. Additionally, BOLAA (Liu et al., [2023c](#bib.bib64)) introduces
    a controller module that orchestrates the coordination and communication among
    multiple collaborative agents, thereby streamlining the selection and interaction
    processes between different labor agents. CHATDEV (Qian et al., [2023a](#bib.bib80))
    proposes an advanced software development framework that utilizes agents to foster
    enhanced collaboration among the diverse roles integral to the software development
    cycle. In the domain of Conversational AI, research exemplified by Fu et al. ([2023b](#bib.bib34))
    delves into the potential of LLMs to autonomously refine their negotiation skills.
    This is achieved through engaging the models in bargaining games against one another,
    complemented by the integration of natural language feedback from an AI critic.
    This study underscores the evolving capabilities of LLMs in complex, interactive
    settings.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 随着适用于大型语言模型（LLMs）任务的范围和复杂性增加，增强这些代理效果的合理策略是采用协作型多代理系统。这些系统在实际应用中被广泛使用，其运行原理是每个代理评估并理解其同行的需求和能力，从而促进一个有利于共享行动和信息交换的协作环境（Li
    等人，[2023](#bib.bib58)）。在非玩家角色（NPCs）这一特定领域，生成代理（Park 等人，[2023](#bib.bib75)）的概念作为一种引人注目的模拟人类行为的方式出现在互动应用中。这一方法通过在类似《模拟人生》沙盒环境中部署
    25 个代理进行示范，允许用户与这些代理互动并影响其执行日常例程、社交互动、建立关系和组织集体活动。此外，类人代理系统（Wang 等人，[2023b](#bib.bib119)）通过融入“三个基本要素”的“系统
    1”处理，增强了生成代理的真实性：满足基本需求（如饥饿、健康和能量）、情感反应和人际关系的动态。在软件开发领域，MetaGPT 系统（Hong 等人，[2023](#bib.bib41)）代表了一种专门的
    LLM 应用，它利用多代理对话框架来促进自动化软件开发。这个创新框架通过为各种 GPT 模型分配不同的角色，使它们在创建软件应用时能够有效协作。此外，BOLAA（Liu
    等人，[2023c](#bib.bib64)）引入了一个控制模块，协调和沟通多个协作代理之间的工作，从而简化了不同劳动代理之间的选择和互动过程。CHATDEV（Qian
    等人，[2023a](#bib.bib80)）提出了一个先进的软件开发框架，利用代理促进软件开发周期中各种角色之间的协作。在对话式人工智能领域，Fu 等人（[2023b](#bib.bib34)）的研究探讨了
    LLMs 在自主提高谈判技巧方面的潜力。通过让模型之间进行讨价还价游戏，并结合来自 AI 批评者的自然语言反馈，达成这一目标。这项研究突显了 LLMs 在复杂互动环境中不断发展的能力。
- en: 5.2.2 Adversarial Interaction
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 对抗性互动
- en: Traditionally, collaborative methods have been extensively explored in multi-agent
    systems. However, researchers are increasingly recognizing that introducing concepts
    from game theory into systems can lead to more robust and efficient behaviors.
    For example, Du et al. ([2023](#bib.bib27)) introduce the concept of debate, endowing
    agents with responses from fellow peers. When these responses diverge from an
    agent’s own judgments, a “mental” argumentation occurs, leading to refined solutions.
    ChatEval (Chan et al., [2023](#bib.bib14)) establishes a role-playing-based multi-agent
    referee team. Through self-initiated debates, agents evaluate the quality of text
    generated by LLMs, reaching a level of excellence comparable to human evaluators.
    Corex (Sun et al., [2023](#bib.bib102)) is constituted by diverse collaboration
    paradigms including Debate, Review, and Retrieve modes, which collectively work
    towards enhancing the factuality, faithfulness, and reliability of the reasoning
    process. These paradigms foster task-agnostic approaches that enable LLMs to “think
    outside the box,” thereby overcoming hallucinations and providing better solutions.
    MAD (Multi-Agent Debate) (Liang et al., [2023a](#bib.bib59)) is a framework wherein
    several agents engage in a “tit-for-tat” exchange of arguments under the oversight
    of a judge who steers the discussion towards a conclusive solution. Furthermore,
    WarAgent (Hua et al., [2023a](#bib.bib43)) considers each country as an LLM-based
    agent and simulates the international conflicts among the countries using World
    War I, World War II, and the Warring States Period in Ancient China as examples,
    which showcases possible approaches towards LLM multi-agent based policy simulation
    and answering the “what if” questions for historical analysis.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，协作方法在多智能体系统中已被广泛探索。然而，研究人员越来越认识到，将博弈论的概念引入系统可以带来更强大和高效的行为。例如，Du 等人（[2023](#bib.bib27)）引入了辩论的概念，为智能体提供了来自同伴的回应。当这些回应与智能体自身的判断出现分歧时，就会发生一种“心理”辩论，从而产生更加精炼的解决方案。ChatEval（Chan
    等人，[2023](#bib.bib14)）建立了一个基于角色扮演的多智能体裁判团队。通过自发的辩论，智能体评估大型语言模型（LLM）生成文本的质量，达到了与人类评估者相媲美的卓越水平。Corex（Sun
    等人，[2023](#bib.bib102)）由多种协作范式构成，包括辩论、审查和检索模式，这些模式共同作用于提高推理过程的事实性、忠实性和可靠性。这些范式促进了与任务无关的方法，使得LLM能够“跳出框架思考”，从而克服幻觉并提供更好的解决方案。MAD（多智能体辩论）（Liang
    等人，[2023a](#bib.bib59)）是一个框架，其中多个智能体在裁判的监督下进行“以牙还牙”的辩论，裁判引导讨论朝着最终的解决方案发展。除此之外，WarAgent（Hua
    等人，[2023a](#bib.bib43)）将每个国家视为一个基于LLM的智能体，并以第一次世界大战、第二次世界大战和中国古代战国时期为例，模拟各国之间的国际冲突，展示了基于LLM的多智能体政策模拟和解答历史分析中的“假设”问题的可能方法。
- en: 5.3 Human-Agent Applications
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 人类-智能体应用
- en: Most existing agent frameworks often limit themselves to defining and controlling
    agent behavior through system prompts, allowing the agent to independently plan
    and act. A notable shortcoming of this approach is the restricted, and sometimes
    non-existent, capacity for meaningful interaction between human users and agents,
    including multi-agent setups. Addressing this gap, AutoGen (Wu et al., [2023](#bib.bib123))
    offers an open-source solution enabling developers to construct LLM applications
    through multiple agents. Specifically, AutoGen distinguishes itself with agents
    that are not only customizable and conversable, but also versatile in their operational
    modes, which incorporate a blend of LLMs, human inputs, and tools, enhancing the
    interaction capabilities and efficiency of the agents. Furthermore, AGENTS (Zhou
    et al., [2023](#bib.bib141)) introduces a novel approach to creating controllable
    agents. This method involves the use of symbolic plans or standard operating procedures
    (SOPs), which can be generated by an LLM and subsequently modified by the user.
    This feature allows for greater customization and fine-tuning of agents, providing
    a more user-centric and adaptable agent framework. Collectively, these developments
    represent a significant shift in the landscape of agent frameworks, moving towards
    systems that not only automate tasks but also facilitate a more interactive and
    collaborative environment between humans and agents.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的代理框架通常局限于通过系统提示定义和控制代理行为，使代理能够独立规划和执行。然而，这种方法的一个显著缺点是缺乏人类用户与代理之间有意义的互动，尤其是在多代理环境下，这种互动往往非常有限，甚至完全不存在。为了解决这一问题，AutoGen（Wu等，[2023](#bib.bib123)）提供了一个开源解决方案，使开发人员能够通过多个代理构建LLM应用。具体而言，AutoGen通过具备可定制、可对话且多功能的操作模式的代理脱颖而出，这些模式结合了LLM、人类输入和工具，增强了代理的互动能力和效率。此外，AGENTS（Zhou等，[2023](#bib.bib141)）引入了一种创建可控代理的新方法。这种方法涉及使用符号计划或标准操作程序（SOP），这些计划可以由LLM生成，并由用户进行后续修改。这一特点使得代理能够进行更大的定制和微调，提供了一个更以用户为中心且具有适应性的代理框架。这些进展共同标志着代理框架领域的重大转变，推动系统不仅自动化任务，而且促进人类与代理之间更具互动性和协作性的环境。
- en: 6 OS-inspired Future Directions
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 操作系统启发的未来方向
- en: The evolution history of operating system over the past half century has witnessed
    the continuous development of computer hardware and the explosive growth of data,
    which empowers the fast iteration of Artificial Intelligence in the past decade.
    In this section, we enumerate the lessons learned from the history of operating
    systems and provide envisions of the future directions for AIOS.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 过去半个世纪操作系统的演变历史见证了计算机硬件的持续发展和数据的爆炸性增长，这推动了人工智能在过去十年的快速迭代。在本节中，我们列举了从操作系统历史中学到的经验教训，并为AIOS的未来方向提供了展望。
- en: 6.1 Resource Management
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 资源管理
- en: 6.1.1 Memory Management
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1 内存管理
- en: Physical memory (DRAM) has always been an insufficient resource from the beginning
    age of computer systems until now. To reduce the tension between users’ requirements
    and the fact of DRAM resource shortage, several approaches have been proposed
    in modern operating systems.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 物理内存（DRAM）从计算机系统初期至今一直是一个不足的资源。为了解决用户需求与DRAM资源短缺之间的矛盾，现代操作系统提出了几种解决方案。
- en: •
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Swapping to external storage. A dedicated partition in external storage is
    reserved for swapping unused memory regions to external storage in a user-transparent
    way, as detailed in [section 2.1.1](#S2.SS1.SSS1 "2.1.1 Kernel ‣ 2.1 OS and Connections
    with LLM ‣ 2 Aligning LLM and OS ‣ LLM as OS, Agents as Apps: Envisioning AIOS,
    Agents and the AIOS-Agent Ecosystem"). This approach enlarges the available DRAM
    resources in the system.'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 切换到外部存储。外部存储中为交换未使用的内存区域而专门保留了一个分区，以用户透明的方式将未使用的内存交换到外部存储，具体细节见[第2.1.1节](#S2.SS1.SSS1
    "2.1.1 内核 ‣ 2.1 操作系统与LLM的连接 ‣ 2 对齐LLM和操作系统 ‣ LLM作为操作系统，代理作为应用：展望AIOS、代理与AIOS-代理生态系统")。这种方法扩展了系统中可用的DRAM资源。
- en: •
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Memory sharing. To support data sharing across applications, modern operating
    systems provide memory sharing between applications, which provides both sharing
    and also reduces the extra copies of shared data.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内存共享。为了支持应用程序之间的数据共享，现代操作系统提供了应用之间的内存共享，这不仅提供了共享功能，还减少了共享数据的额外副本。
- en: •
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Memory disaggregation. Entering the terabyte scale data, fitting the memory
    requirements for an application in a single operating system on a sole machine
    is becoming challenging. To remedy this, disaggregated memory techniques were
    proposed to allow an application to use memory on another machine via network.
    Moreover, recent Compute eXpress Link (CXL) technique (CXL, [2023](#bib.bib24))
    significantly reduces the software overheads and hardware latency of remote memory
    access.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 内存分离。随着数据进入 TB 级规模，在单台机器的单一操作系统中适配应用程序的内存需求变得越来越具有挑战性。为了解决这个问题，提出了内存分离技术，允许应用程序通过网络使用另一台机器的内存。此外，最近的计算eXpress链接（CXL）技术（CXL,
    [2023](#bib.bib24)）显著减少了远程内存访问的软硬件开销和延迟。
- en: LLMs have revolutionized abilities, but are constrained by limited context windows,
    hindering their utility in tasks such as extended conversations and document analysis.
    To mitigate the limited context window problem in LLMs, approaches inspired by
    the above operating system memory management methods can be developed. A swapping
    mechanism, similar to OS swapping to external storage, can be implemented in LLMs
    to temporarily store inactive parts of their context, effectively enlarging the
    context window. This would require efficient retrieval systems to minimize latency.
    For example, MemGPT (Packer et al., [2023](#bib.bib72)) intelligently manages
    different memory tiers in order to effectively provide extended context within
    the LLM’s limited context window, and utilizes interrupts to manage control flow
    between itself and the user. Additionally, mirroring OS memory sharing, LLMOS
    can share context or learned patterns across different LLMOS-based Agent instances,
    reducing redundancy and allowing access to a larger shared knowledge pool for
    agents. Finally, drawing from memory disaggregation in modern OS, agents can leverage
    networked memory resources, enabling them to access and process data stored across
    multiple LLMOSes, thus expanding their abilities significantly. Each of these
    strategies, while offering potential solutions, also presents unique challenges
    such as managing latency, ensuring consistency in shared contexts, and handling
    the complexities of distributed memory systems.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在能力上带来了革命性的变化，但受限于有限的上下文窗口，限制了它们在诸如长时间对话和文档分析等任务中的应用。为了缓解LLMs中有限上下文窗口的问题，可以开发受到上述操作系统内存管理方法启发的方案。一种类似于操作系统交换到外部存储的交换机制，可以在LLMs中实现，用来暂时存储其上下文中不活跃的部分，从而有效扩大上下文窗口。这将需要高效的检索系统来最小化延迟。例如，MemGPT（Packer
    et al., [2023](#bib.bib72)）智能地管理不同的内存层次，以便在LLM有限的上下文窗口内有效提供扩展的上下文，并利用中断来管理自身与用户之间的控制流。此外，借鉴操作系统内存共享的方式，LLMOS可以在不同的LLMOS代理实例之间共享上下文或学习的模式，从而减少冗余，并允许代理访问更大的共享知识库。最后，借鉴现代操作系统中的内存分离，代理可以利用网络内存资源，使它们能够访问和处理跨多个LLMOS存储的数据，从而显著扩展其能力。尽管这些策略都提供了潜在的解决方案，但也带来了独特的挑战，如管理延迟、确保共享上下文的一致性，以及处理分布式内存系统的复杂性。
- en: 6.1.2 Tool Management
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2 工具管理
- en: 'Serving as external resources outside LLM, the hardware tools (e.g., robotics)
    and software tools (e.g., Web Search API) are the counterpart of devices and libraries
    in modern operating systems as shown in Table [1](#S3.T1 "Table 1 ‣ 3 Architecture
    of AIOS ‣ LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent
    Ecosystem"), respectively. Taking the example of the ecosystem in modern Linux
    operating system–the most widely-used open source operating system community by
    now, here are the successful experiences in its evolving history. Specifically,
    a rich set of built-in and third-party libraries from thousands of experts and
    open-source developers leads to the success of the Linux ecosystem. Managing the
    install/uninstall and dependencies of those libraries, along with the versioning
    for tracking software development, is critical. The Linux ecosystem, over the
    past few decades, provides library management tools such as dpkg^(25)^(25)25[https://man7.org/linux/man-pages/man1/dpkg.1.html](https://man7.org/linux/man-pages/man1/dpkg.1.html)
    in Debian-based Linux distributions, and yum^(26)^(26)26[http://yum.baseurl.org/](http://yum.baseurl.org/)
    in RHEL-based Linux distributions. Git^(27)^(27)27[https://git-scm.com/](https://git-scm.com/),
    a distributed version control system that plays a crucial role in the development
    of the Linux ecosystem, allows collaborative and parallel development, boost the
    speed of development cycles in building the Linux ecosystem.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 作为LLM外部资源，硬件工具（例如机器人）和软件工具（例如Web搜索API）分别是现代操作系统中设备和库的对应物，如表[1](#S3.T1 "表1 ‣
    3 人工智能操作系统架构 ‣ LLM作为操作系统，智能体作为应用：展望AIOS、智能体与AIOS-智能体生态系统")所示。以现代Linux操作系统的生态系统为例——目前最广泛使用的开源操作系统社区，下面是其演变历史中的一些成功经验。具体而言，由成千上万的专家和开源开发者提供的丰富的内置和第三方库促成了Linux生态系统的成功。管理这些库的安装/卸载以及依赖关系，同时进行软件版本管理来追踪软件开发进度，至关重要。过去几十年，Linux生态系统提供了诸如Debian系列Linux发行版中的dpkg^(25)^(25)25[https://man7.org/linux/man-pages/man1/dpkg.1.html](https://man7.org/linux/man-pages/man1/dpkg.1.html)和基于RHEL的Linux发行版中的yum^(26)^(26)26[http://yum.baseurl.org/](http://yum.baseurl.org/)等库管理工具。Git^(27)^(27)27[https://git-scm.com/](https://git-scm.com/)是一个分布式版本控制系统，在Linux生态系统的开发中起着至关重要的作用，允许协作和并行开发，促进了Linux生态系统构建中的开发周期速度。
- en: 'The process of code comparison in Git, particularly during merging and rebasing,
    typically analyzes changes at the line level rather than understanding the semantic
    meaning of the text. However, as discussed in Section [4.2](#S4.SS2 "4.2 Natural
    Language Programming for Agents ‣ 4 AIOS-Agent Ecosystem ‣ LLM as OS, Agents as
    Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem"), the development
    of agents using natural language is increasingly achievable. Adapting existing
    version control software, which is based on the code or texts without knowing
    the semantics and contexts, for use with natural languages poses distinct challenges.
    First, natural languages, while structured by grammars, exhibit a loosely coupled
    relationship with the varied expressions of different users. Second, this loose
    coupling can result in natural language statements that are semantically equivalent
    but differ in their wording. For example, in the context of an AI agent system,
    the instructions “Analyze the latest sales data and generate a report” and “Generate
    a report based on the analysis of the most recent sales data” convey the same
    instruction to the agent but are phrased differently. Incorporating the ability
    to recognize and reconcile these semantic nuances in natural language into version
    control software is essential. This is especially critical in collaborative development
    of complex AI agent systems, where such a feature can greatly streamline development
    cycles by effectively managing and merging diverse natural language inputs.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: Git 中的代码比较过程，特别是在合并和变基时，通常是在行级别分析变化，而不是理解文本的语义含义。然而，如第[4.2节](#S4.SS2 "4.2 自然语言编程为代理
    ‣ 4 AIOS-Agent 生态系统 ‣ LLM作为操作系统，代理作为应用：构想 AIOS、代理和 AIOS-Agent 生态系统")所讨论的，使用自然语言开发代理已经变得越来越可行。将现有的版本控制软件（基于代码或文本，且不理解语义和上下文）改造为支持自然语言，面临着不同的挑战。首先，自然语言虽然由语法结构化，但它与不同用户的多样化表达之间存在松散的耦合关系。其次，这种松散的耦合可能导致语义等价的自然语言陈述在措辞上有所不同。例如，在
    AI 代理系统的上下文中，指令“分析最新的销售数据并生成报告”和“基于对最新销售数据的分析生成报告”传达给代理的是相同的指令，但措辞不同。将识别和调和这些自然语言中的语义细微差别的能力融入版本控制软件中至关重要。这对于复杂
    AI 代理系统的协作开发尤为关键，因为这种功能可以通过有效地管理和合并多样化的自然语言输入，极大地简化开发周期。
- en: 6.2 Communication
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 通信
- en: Domain-Specific Languages (DSLs) are widely used in both native operating systems
    and cloud environments, which address specific requirements or tasks within a
    particular domain. Operating systems are often equipped with scripting languages
    on top of the command-line interfaces that allow users to perform various tasks
    collaboratively. Unix-like operating systems use shell scripting languages such
    as Bash^(28)^(28)28[https://www.gnu.org/software/bash/](https://www.gnu.org/software/bash/),
    which is designed for automating tasks in a command-line environment. In the cloud
    computing, DSLs are commonly used to define infrastructure as code (Sledziewski
    et al., [2010](#bib.bib99)). It allows users to describe and provision cloud infrastructure
    resources, including virtual machines, networks, and storage; It can also be used
    for scheduling tasks on infrastructure resources. DSLs strike a balance between
    the underlying OSes and users that they are readable for both.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 特定领域语言（DSLs）在本地操作系统和云环境中得到广泛应用，它们解决了特定领域内的需求或任务。操作系统通常配备了基于命令行界面的脚本语言，允许用户协同执行各种任务。类
    Unix 操作系统使用诸如 Bash^(28)^(28)28[https://www.gnu.org/software/bash/](https://www.gnu.org/software/bash/)
    之类的 shell 脚本语言，用于在命令行环境中自动化任务。在云计算中，DSLs 常用于将基础设施定义为代码（Sledziewski 等人，[2010](#bib.bib99)）。它允许用户描述和配置云基础设施资源，包括虚拟机、网络和存储；也可用于调度基础设施资源上的任务。DSLs
    在底层操作系统与用户之间取得了平衡，使其既可读又易于理解。
- en: Leveraging the wisdom gleaned from OSes, multi-AIOS communication can be enhanced
    by adopting structured communication protocols that are analogous to the function
    of DSLs in simplifying complex tasks. Just as DSLs provide a medium for users
    to interact effectively with the operating system and its resources, a similar
    specialized protocol can be established for LLMs to communicate with one another.
    This protocol would standardize interactions, allowing for the clear transmission
    of context, tasks, and goals between LLMs, thus facilitating a more coordinated
    and coherent multi-agent operation. It would ensure that despite the varied functionalities
    and knowledge bases of individual LLMs, there is a common language or method through
    which they can collaborate, share insights, and synchronize their learning processes.
    This approach mirrors the way operating systems manage resources and processes,
    ensuring harmonious and efficient functionality across various components of a
    system.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 利用操作系统的智慧，通过采用结构化通信协议来增强多AIOS通信，这些协议类似于DSL在简化复杂任务中的功能。就像DSL为用户与操作系统及其资源的交互提供了一种媒介，类似的专门协议可以为LLM之间的通信建立。这种协议将标准化交互，使得LLM之间能够清晰地传递上下文、任务和目标，从而促进更加协调和一致的多代理操作。它将确保尽管单个LLM的功能和知识库各不相同，但通过一种共同的语言或方法，它们可以协作、分享见解并同步学习过程。这种方法类似于操作系统如何管理资源和进程，确保系统各个组件之间的和谐与高效运行。
- en: 'In current AI Agents, the task-solving plan is still represented by natural
    language in most cases. However, in the future, we can even develop DSLs or semi-structured
    natural language grammars for representing Agent’s task-solving plans. This involves
    the following breakthroughs:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的AI代理中，任务解决计划大多数情况下仍然是用自然语言表示的。然而，在未来，我们甚至可以开发DSL或半结构化的自然语言语法来表示代理的任务解决计划。这涉及以下突破：
- en: •
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Defining Basic Operations: This would standardize the basic operations, tools,
    or commands that an AI Agent understands and can execute for task-solving.'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定义基本操作：这将标准化AI代理理解和能够执行的基本操作、工具或命令，以便解决任务。
- en: •
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sequence of Operations: Task-solving plans would then be sequences of these
    basic operations, making them more structured and potentially more efficient.'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 操作顺序：任务解决计划将成为这些基本操作的顺序，使得计划更加结构化，并可能更加高效。
- en: 'Using LLM to interpret users’ natural language instructions into a DSL-composed
    plan brings several benefits, including 1) Improved Consistency: Standardized
    operations would lead to more predictable and consistent outcomes; 2) Easier to
    Interpret: A well-defined DSL makes it easier for AI Agents to interpret and execute
    plans; and 3) Scalability: With a standard DSL, it is easier to scale solutions
    across different platforms and applications.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM将用户的自然语言指令转化为DSL组成的计划带来了几个好处，包括：1）提高一致性：标准化的操作会导致更加可预测和一致的结果；2）更易于理解：明确定义的DSL使得AI代理更容易理解和执行计划；3）可扩展性：使用标准的DSL，更容易在不同平台和应用程序之间扩展解决方案。
- en: 'However, achieving this goal also meets some important challenges that need
    future research attention: 1) Complexity of Natural Language: Natural language
    is inherently ambiguous and context-dependent, making it challenging to convert
    instructions into structured plans consistently; 2) Flexibility vs. Standardization:
    Striking a balance between the flexibility of natural language and the rigidity
    of a standardized DSL; 3) Interoperability: Ensuring the DSL works well with a
    wide range of tools and platforms; and 4) Adaptation and Learning: The system
    needs to continuously learn and adapt to new instructions, tools, and tasks.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，达成这一目标也面临一些需要未来研究关注的重要挑战：1）自然语言的复杂性：自然语言本质上是模糊且依赖上下文的，这使得将指令一致地转化为结构化计划变得具有挑战性；2）灵活性与标准化：在自然语言的灵活性与标准DSL的刚性之间找到平衡；3）互操作性：确保DSL能够与各种工具和平台良好兼容；4）适应与学习：系统需要持续学习和适应新的指令、工具和任务。
- en: Overall, the use of a large language model as an interpreter (LLM as Interpreter),
    which can translate natural language described plans to DSL described plans, can
    be an important direction to create task-solving plans, and to bridge LLM as OS
    (LLMOS) and Agent Applications (AAP). The development of a DSL for such plans
    could further streamline and standardize the process, though it would come with
    its own set of challenges. This approach has the potential to make complex task
    execution more accessible and efficient, paving the way for more advanced AI systems
    in the future.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，使用大型语言模型作为解释器（LLM作为解释器），可以将自然语言描述的计划转换为DSL描述的计划，这可以成为创建任务解决计划的重要方向，并且能够架起LLM作为操作系统（LLMOS）与代理应用程序（AAP）之间的桥梁。为此类计划开发DSL可以进一步简化和标准化这一过程，尽管这也会带来一些挑战。这一方法有潜力使复杂的任务执行更加便捷和高效，为未来更先进的AI系统铺平道路。
- en: 6.3 Security
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 安全性
- en: Security has been an important issue as the wide-spread of operating systems
    from labs to our daily life in the 1980s. The consequences of the operating system
    vulnerabilities can be roughly categorized as following.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 随着操作系统从实验室逐渐扩展到我们的日常生活，安全问题在1980年代变得尤为重要。操作系统漏洞的后果大致可以分为以下几类。
- en: •
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Breaking down the system. In its early stages, viruses like the Morris Worm (Orman,
    [2003](#bib.bib70)) were primarily created to compromise operating systems, serving
    as a demonstration of individual programmers’ prowess in hacking. While these
    attacks did not result in direct financial losses, users faced potential harm
    through the compromise of personal data or critical workplace documents.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 拆解系统。在早期阶段，像莫里斯蠕虫（Morris Worm）（Orman, [2003](#bib.bib70)）这样的病毒主要是为了破坏操作系统而创建，旨在展示个别程序员在黑客攻击中的技术水平。尽管这些攻击未导致直接的经济损失，但用户可能因个人数据或重要工作文件的泄露而面临潜在风险。
- en: •
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Racketeering. In later stages, vulnerabilities within operating systems became
    targets for illicit activities, including the exploitation of users for racketeering
    purposes. An example of this is the WannaCry Ransomware^(29)^(29)29[https://nvd.nist.gov/vuln/detail/cve-2017-0143](https://nvd.nist.gov/vuln/detail/cve-2017-0143),
    which encrypts users’ files and demands a ransom for their release. Additionally,
    banking trojans like Zeus^(30)^(30)30[https://nvd.nist.gov/vuln/detail/cve-2010-0188](https://nvd.nist.gov/vuln/detail/cve-2010-0188)
    exploit vulnerabilities by intercepting communication channels between users and
    banking systems, resulting in direct financial losses for the affected users.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 敲诈勒索。随着时间的推移，操作系统中的漏洞成为非法活动的目标，包括利用用户进行敲诈勒索。例如WannaCry勒索病毒^(29)^(29)29[https://nvd.nist.gov/vuln/detail/cve-2017-0143](https://nvd.nist.gov/vuln/detail/cve-2017-0143)就是通过加密用户文件并要求支付赎金来恢复访问。除此之外，像Zeus^(30)^(30)30[https://nvd.nist.gov/vuln/detail/cve-2010-0188](https://nvd.nist.gov/vuln/detail/cve-2010-0188)这样的银行木马通过拦截用户和银行系统之间的通信渠道来利用漏洞，导致受影响用户遭受直接的经济损失。
- en: •
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Stealing Resource. Malicious software, such as Coinhive^(31)^(31)31[https://krebsonsecurity.com/2018/03/who-and-what-is-coinhive/](https://krebsonsecurity.com/2018/03/who-and-what-is-coinhive/),
    is crafted to harness the computing power of other machines for cryptocurrency
    mining, including Bitcoin. While it may not inflict direct harm on operating systems,
    the substantial utilization of CPU and memory resources can significantly impair
    the overall system performance. In cloud environments, this slowdown has the potential
    to translate into financial losses, making it imperative to address such threats
    proactively.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 资源盗窃。恶意软件，例如Coinhive^(31)^(31)31[https://krebsonsecurity.com/2018/03/who-and-what-is-coinhive/](https://krebsonsecurity.com/2018/03/who-and-what-is-coinhive/)，旨在利用其他计算机的计算能力进行加密货币挖矿，包括比特币。尽管它可能不会对操作系统造成直接危害，但对CPU和内存资源的巨大占用可能会显著影响整个系统的性能。在云环境中，这种性能下降可能会转化为财务损失，因此必须积极应对此类威胁。
- en: Security vulnerabilities in operating systems are hard to prevent. The state-of-the-art
    approaches detect and capture those malware and virus at different levels.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统中的安全漏洞难以防范。最先进的方法在不同层级上检测和捕捉这些恶意软件和病毒。
- en: •
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Static Analysis. This approach conducts code-level or binary-level analyses
    by examining the code or binary image of an application or part of the OS. It
    is often performed when a third-party application is published to the cloud, or
    when a file is downloaded to the file system in a user’s operating system.
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 静态分析。此方法通过检查应用程序或操作系统一部分的代码或二进制镜像，进行代码级或二进制级的分析。通常在第三方应用程序发布到云端，或文件被下载到用户操作系统的文件系统时执行此操作。
- en: •
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Fuzzing. Fuzzing (Fuzz Testing) involves the automated generation of a large
    number of random or semi-random inputs to a program to discover vulnerabilities,
    crashes, or unexpected behaviors.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模糊测试。模糊测试（Fuzz Testing）涉及自动生成大量随机或半随机输入以测试程序，从而发现漏洞、崩溃或意外行为。
- en: Similarly, adversarial attacks have been the subject of extensive study in LLM
    research (Wei et al., [2023](#bib.bib120); Zou et al., [2023](#bib.bib143); Qi
    et al., [2023a](#bib.bib78); Yang et al., [2023c](#bib.bib126)), representing
    a significant threat to the security of AIOS. Furthermore, research (Yang et al.,
    [2023b](#bib.bib127); Qi et al., [2023b](#bib.bib79)) has revealed that an aligned
    LLM can be broken using a very small dataset comprising only a few hundred data
    points. This vulnerability is not only a significant concern in terms of system
    integrity but also raises alarming implications for the safety of agents interacting
    with these systems. How to be robust and defend against such attacks has yet to
    be studied in the context of AIOS, LLMOS, and Agents.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对抗性攻击也成为LLM研究中的重要课题（Wei等人，[2023](#bib.bib120)；Zou等人，[2023](#bib.bib143)；Qi等人，[2023a](#bib.bib78)；Yang等人，[2023c](#bib.bib126)），对AIOS的安全构成了重大威胁。此外，研究（Yang等人，[2023b](#bib.bib127)；Qi等人，[2023b](#bib.bib79)）表明，一个对齐的LLM也能被一个仅包含几百个数据点的小数据集攻破。这一漏洞不仅对系统完整性构成重大威胁，还对与这些系统交互的代理的安全性提出了令人担忧的隐患。如何在AIOS、LLMOS和代理的背景下提高防御能力，以应对此类攻击，仍然是一个亟待研究的问题。
- en: Looking into the future, as agent applications in AIOS evolve to be programmed
    by natural language, the intricacy of scanning the code of such applications will
    increase due to the expansive and less structured nature of natural language compared
    to the constrained syntax of programming languages. This necessitates a robust
    and effective scanning tool for AIOS agents. Moreover, fuzzing can be seen as
    an initial step towards creating a Red-teaming dataset for LLMOS-based Agents.
    For instance, Ruan et al. ([2023b](#bib.bib89)) have developed a multi-agent system
    that generates red-teaming scenarios for LLM-based agents, using GPT-4 to simulate
    adversarial environments within textual scenarios. The study provides a rich array
    of scenarios that serve as a valuable resource for future research into the alignment
    of LLM-based Agents.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，随着AIOS中的代理应用程序逐渐通过自然语言编程，其代码扫描的复杂性也将增加，因为与编程语言受限的语法相比，自然语言的表达更为广泛且结构较为松散。这就需要为AIOS代理开发一个强大且有效的扫描工具。此外，模糊测试可以视为为LLMOS代理创建红队数据集的初步步骤。例如，Ruan等人（[2023b](#bib.bib89)）开发了一个多代理系统，该系统使用GPT-4在文本场景中模拟对抗环境，生成适用于LLM代理的红队场景。这项研究提供了丰富的场景，成为未来研究LLM代理对齐的重要资源。
- en: 7 Conclusions
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: This paper presents a novel vision for the future of computing within the AIOS-Agent
    ecosystem, where the LLM functions as the core of AIOS. This innovative approach
    marks a significant departure from the conventional OS-APP ecosystem, heralding
    a new era in technology where AI and traditional computing systems merge seamlessly.
    The AIOS-Agent ecosystem envisaged here is not just an incremental change but
    a fundamental shift in how we interact with technology. By positioning LLM at
    the system level, Agents as applications, Tools as devices/libraries, and Natural
    Language as the Programming Interface, we redefine the interaction between users,
    developers, and the digital world. This paradigm shift promises to democratize
    software development and access, allowing users and developers to program Agent
    Applications (AAPs) using natural language. This accessibility contrasts sharply
    with the traditional ecosystem, where software development is confined to those
    with specialized programming skills. Moreover, the discussion of single and multi-agent
    systems, as well as human-agent interactions, illustrates the potential of AIOS
    in enhancing productivity, creativity, and decision-making processes across various
    domains. Looking ahead, the proposed strategic roadmap, informed by the developmental
    trajectory of the traditional OS-APP ecosystem, offers a pragmatic and systematic
    approach to the evolution of AIOS and its Agent Applications. This roadmap not
    only guides future development and research in this field but also anticipates
    the challenges and opportunities that lie ahead.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了在AIOS-Agent生态系统中计算未来的新视野，其中LLM作为AIOS的核心功能。这一创新方法标志着与传统操作系统-应用程序生态系统的显著分离，开启了一个技术新时代，AI与传统计算系统无缝融合。这里设想的AIOS-Agent生态系统不仅仅是渐进性的变化，而是我们与技术互动方式的根本转变。通过将LLM置于系统级别，代理作为应用程序，工具作为设备/库，自然语言作为编程接口，我们重新定义了用户、开发者与数字世界之间的互动。这一范式转变承诺将使软件开发和访问实现民主化，允许用户和开发者使用自然语言编程代理应用程序（AAPs）。与传统生态系统中软件开发仅限于具备专业编程技能的人群相比，这种可访问性形成了鲜明对比。此外，单一和多代理系统以及人类-代理互动的讨论，展示了AIOS在提升各领域生产力、创造力和决策过程中的潜力。展望未来，所提出的战略路线图，基于传统操作系统-应用程序生态系统的发展轨迹，提供了一种务实且系统化的方法来推动AIOS及其代理应用程序的发展。这一路线图不仅指导未来在该领域的发展和研究，还预见了前方可能面临的挑战和机遇。
- en: References
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Agarwal et al. (2006) Amit Agarwal, Saibal Mukhopadhyay, Arijit Raychowdhury,
    Kaushik Roy, and Chris H Kim. 2006. Leakage power analysis and reduction for nanoscale
    circuits. *IEeE Micro* 26, 2 (2006), 68–80.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 等人（2006）Amit Agarwal、Saibal Mukhopadhyay、Arijit Raychowdhury、Kaushik
    Roy 和 Chris H Kim。2006年。《纳米尺度电路的泄漏功率分析与减少》。*IEEE Micro* 26, 2 (2006)，68–80。
- en: 'Ahn et al. (2022) Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar,
    Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan,
    Karol Hausman, et al. 2022. Do as i can, not as i say: Grounding language in robotic
    affordances. *arXiv preprint arXiv:2204.01691* (2022).'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahn 等人（2022）Michael Ahn、Anthony Brohan、Noah Brown、Yevgen Chebotar、Omar Cortes、Byron
    David、Chelsea Finn、Chuyuan Fu、Keerthana Gopalakrishnan、Karol Hausman 等人。2022年。《做我能做的，而不是我说的：将语言与机器人能力相结合》。*arXiv
    预印本 arXiv:2204.01691* (2022)。
- en: 'Ainslie et al. (2023) Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury
    Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. 2023. GQA: Training Generalized
    Multi-Query Transformer Models from Multi-Head Checkpoints. *arXiv preprint arXiv:2305.13245*
    (2023).'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ainslie 等人（2023）Joshua Ainslie、James Lee-Thorp、Michiel de Jong、Yury Zemlyanskiy、Federico
    Lebrón 和 Sumit Sanghai。2023年。《GQA：从多头检查点训练通用多查询变换器模型》。*arXiv 预印本 arXiv:2305.13245*
    (2023)。
- en: 'Ainslie et al. (2020) Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav
    Cvicek, Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang,
    and Li Yang. 2020. ETC: Encoding long and structured inputs in transformers. *arXiv
    preprint arXiv:2004.08483* (2020).'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ainslie 等人（2020）Joshua Ainslie、Santiago Ontanon、Chris Alberti、Vaclav Cvicek、Zachary
    Fisher、Philip Pham、Anirudh Ravula、Sumit Sanghai、Qifan Wang 和 Li Yang。2020年。《ETC：在变换器中编码长结构化输入》。*arXiv
    预印本 arXiv:2004.08483* (2020)。
- en: 'Beltagy et al. (2020) Iz Beltagy, Matthew E Peters, and Arman Cohan. 2020.
    Longformer: The long-document transformer. *arXiv preprint arXiv:2004.05150* (2020).'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beltagy 等人（2020）Iz Beltagy、Matthew E Peters 和 Arman Cohan。2020年。《Longformer：长文档变换器》。*arXiv
    预印本 arXiv:2004.05150* (2020)。
- en: 'Besta et al. (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk, et al. 2023. Graph of thoughts: Solving elaborate problems with
    large language models. *arXiv preprint arXiv:2308.09687* (2023).'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Besta 等人 (2023) Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,
    Piotr Nyczyk 等人. 2023. 思维图：使用大型语言模型解决复杂问题. *arXiv 预印本 arXiv:2308.09687* (2023).
- en: Boiko et al. (2023) Daniil A Boiko, Robert MacKnight, and Gabe Gomes. 2023.
    Emergent autonomous scientific research capabilities of large language models.
    *arXiv preprint arXiv:2304.05332* (2023).
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko 等人 (2023) Daniil A Boiko, Robert MacKnight, 和 Gabe Gomes. 2023. 大型语言模型的自主科学研究能力的出现.
    *arXiv 预印本 arXiv:2304.05332* (2023).
- en: Borgeaud et al. (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022. Improving language models by
    retrieving from trillions of tokens. In *International conference on machine learning*.
    PMLR, 2206–2240.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borgeaud 等人 (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark 等人. 2022. 通过从万亿标记中检索来改进语言模型. 在 *国际机器学习会议*.
    PMLR, 2206–2240.
- en: 'Bran et al. (2023) Andres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller.
    2023. ChemCrow: Augmenting large-language models with chemistry tools. *arXiv
    preprint arXiv:2304.05376* (2023).'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bran 等人 (2023) Andres M Bran, Sam Cox, Andrew D White, 和 Philippe Schwaller.
    2023. ChemCrow: 用化学工具增强大型语言模型. *arXiv 预印本 arXiv:2304.05376* (2023).'
- en: Bratman et al. (1988) Michael E Bratman, David J Israel, and Martha E Pollack.
    1988. Plans and resource-bounded practical reasoning. *Computational intelligence*
    4, 3 (1988), 349–355.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bratman 等人 (1988) Michael E Bratman, David J Israel, 和 Martha E Pollack. 1988.
    计划与资源受限的实际推理. *计算智能* 4, 3 (1988), 349–355.
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems* 33 (2020), 1877–1901.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人 (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell 等人. 2020. 语言模型是少量样本学习者. *神经信息处理系统的进展* 33 (2020), 1877–1901.
- en: 'Bubeck et al. (2023) Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
    Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
    Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. 2023. Sparks of
    Artificial General Intelligence: Early experiments with GPT-4. arXiv:2303.12712 [cs.CL]'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bubeck 等人 (2023) Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
    Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
    Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, 和 Yi Zhang. 2023. 人工通用智能的火花：与
    GPT-4 的早期实验. arXiv:2303.12712 [cs.CL]
- en: 'Chan et al. (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. ChatEval: Towards Better LLM-based
    Evaluators through Multi-Agent Debate. arXiv:2308.07201 [cs.CL]'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chan 等人 (2023) Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue,
    Shanghang Zhang, Jie Fu, 和 Zhiyuan Liu. 2023. ChatEval: 通过多智能体辩论推动更好的基于 LLM 的评估器.
    arXiv:2308.07201 [cs.CL]'
- en: Chase (2022) Harrison Chase. 2022. *LangChain*. [https://github.com/hwchase17/langchain](https://github.com/hwchase17/langchain)
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chase (2022) Harrison Chase. 2022. *LangChain*. [https://github.com/hwchase17/langchain](https://github.com/hwchase17/langchain)
- en: 'Chen et al. (2020) Changan Chen, Unnat Jain, Carl Schissler, Sebastia Vicenc Amengual
    Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, and Kristen Grauman.
    2020. Soundspaces: Audio-visual navigation in 3d environments. In *Computer Vision–ECCV
    2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings,
    Part VI 16*. Springer, 17–36.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等人 (2020) Changan Chen, Unnat Jain, Carl Schissler, Sebastia Vicenc Amengual
    Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, 和 Kristen Grauman.
    2020. 声音空间：在 3D 环境中的视听导航. 在 *计算机视觉–ECCV 2020: 第16届欧洲会议, 英国格拉斯哥, 2020年8月23日–28日,
    论文集, 第VI部分 16*. Springer, 17–36.'
- en: Chen et al. (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique
    Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
    Greg Brockman, et al. 2021. Evaluating large language models trained on code.
    *arXiv preprint arXiv:2107.03374* (2021).
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2021) Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde
    de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
    Brockman 等人. 2021. 评估在代码上训练的大型语言模型. *arXiv 预印本 arXiv:2107.03374* (2021).
- en: Chen et al. (2023b) Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong
    Tian. 2023b. Extending context window of large language models via positional
    interpolation. *arXiv preprint arXiv:2306.15595* (2023).
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023b) Shouyuan Chen, Sherman Wong, Liangjian Chen, 和 Yuandong
    Tian。2023b年。通过位置插值扩展大型语言模型的上下文窗口。*arXiv预印本 arXiv:2306.15595*（2023年）。
- en: Chen et al. (2023a) Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2023a. Teaching large language models to self-debug. *arXiv preprint arXiv:2304.05128*
    (2023).
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2023a) Xinyun Chen, Maxwell Lin, Nathanael Schärli, 和 Denny Zhou。2023a年。教会大型语言模型自我调试。*arXiv预印本
    arXiv:2304.05128*（2023年）。
- en: 'Corbató et al. (1971) F. J. Corbató, J. H. Saltzer, and C. T. Clingen. 1971.
    Multics: The First Seven Years. In *Proceedings of the May 16-18, 1972, Spring
    Joint Computer Conference* (Atlantic City, New Jersey) *(AFIPS ’72 (Spring))*.
    Association for Computing Machinery, New York, NY, USA, 571–583. [https://doi.org/10.1145/1478873.1478950](https://doi.org/10.1145/1478873.1478950)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Corbató et al. (1971) F. J. Corbató, J. H. Saltzer, 和 C. T. Clingen。1971年。Multics：最初的七年。在*1972年5月16日至18日春季联合计算机会议论文集*（新泽西州大西洋城）（*AFIPS
    ’72（春季）*）。计算机协会，纽约，NY，USA，571–583。[https://doi.org/10.1145/1478873.1478950](https://doi.org/10.1145/1478873.1478950)
- en: Corbet et al. (2005) Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman.
    2005. *Linux Device Drivers, 3rd Edition*. O’Reilly Media, Inc.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Corbet et al. (2005) Jonathan Corbet, Alessandro Rubini, 和 Greg Kroah-Hartman。2005年。*Linux设备驱动程序，第3版*。O’Reilly
    Media, Inc.
- en: 'Côté et al. (2019) Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas,
    Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud
    Adada, et al. 2019. Textworld: A learning environment for text-based games. In
    *Computer Games: 7th Workshop, CGW 2018, Held in Conjunction with the 27th International
    Conference on Artificial Intelligence, IJCAI 2018, Stockholm, Sweden, July 13,
    2018, Revised Selected Papers 7*. Springer, 41–75.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Côté et al. (2019) Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas,
    Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud
    Adada, 等人。2019年。Textworld：一种面向基于文本的游戏的学习环境。在*计算机游戏：第七届研讨会，CGW 2018，联合举办于第27届国际人工智能会议，IJCAI
    2018，瑞典斯德哥尔摩，2018年7月13日，修订精选论文集7*。Springer，41–75。
- en: 'Croft et al. (2010) W Bruce Croft, Donald Metzler, and Trevor Strohman. 2010.
    *Search engines: Information retrieval in practice*. Vol. 520. Addison-Wesley
    Reading.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croft et al. (2010) W Bruce Croft, Donald Metzler, 和 Trevor Strohman。2010年。*搜索引擎：实践中的信息检索*。第520卷。Addison-Wesley
    Reading。
- en: CXL (2023) CXL. 2023. Compute Express Link Specification. [https://www.computeexpresslink.org/](https://www.computeexpresslink.org/).
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CXL (2023) CXL。2023年。计算扩展链接规范。 [https://www.computeexpresslink.org/](https://www.computeexpresslink.org/)。
- en: 'Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens,
    Boshi Wang, Huan Sun, and Yu Su. 2023. Mind2Web: Towards a Generalist Agent for
    the Web. *arXiv preprint arXiv:2306.06070* (2023).'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2023) Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens,
    Boshi Wang, Huan Sun, 和 Yu Su。2023年。Mind2Web：面向通用代理的网络。*arXiv预印本 arXiv:2306.06070*（2023年）。
- en: 'Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language
    understanding. *arXiv preprint arXiv:1810.04805* (2018).'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin et al. (2018) Jacob Devlin, Ming-Wei Chang, Kenton Lee, 和 Kristina Toutanova。2018年。Bert：用于语言理解的深度双向变换器的预训练。*arXiv预印本
    arXiv:1810.04805*（2018年）。
- en: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum,
    and Igor Mordatch. 2023. Improving Factuality and Reasoning in Language Models
    through Multiagent Debate. arXiv:2305.14325 [cs.CL]
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Du et al. (2023) Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum,
    和 Igor Mordatch。2023年。通过多智能体辩论改善语言模型的事实性和推理能力。arXiv:2305.14325 [cs.CL]
- en: Durmus et al. (2023) Esin Durmus, Karina Nyugen, Thomas I Liao, Nicholas Schiefer,
    Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez,
    Nicholas Joseph, et al. 2023. Towards measuring the representation of subjective
    global opinions in language models. *arXiv preprint arXiv:2306.16388* (2023).
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Durmus et al. (2023) Esin Durmus, Karina Nyugen, Thomas I Liao, Nicholas Schiefer,
    Amanda Askell, Anton Bakhtin, Carol Chen, Zac Hatfield-Dodds, Danny Hernandez,
    Nicholas Joseph, 等人。2023年。面向衡量语言模型中主观全球观点的表现。*arXiv预印本 arXiv:2306.16388*（2023年）。
- en: Fainstein and DeFilippis (2015) Susan S Fainstein and James DeFilippis. 2015.
    *Readings in planning theory*. John Wiley & Sons.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fainstein and DeFilippis (2015) Susan S Fainstein 和 James DeFilippis。2015年。*规划理论选读*。John
    Wiley & Sons。
- en: 'Fan et al. (2022) Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong
    Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. 2022.
    Minedojo: Building open-ended embodied agents with internet-scale knowledge. *Advances
    in Neural Information Processing Systems* 35 (2022), 18343–18362.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 范等（2022）范林熙、王冠志、蒋云凡、阿贾伊·曼德尔卡尔、杨云聪、朱浩义、唐安德鲁、黄德安、朱宇科和安妮玛·安南德库马尔。2022年。《Minedojo：构建具有互联网规模知识的开放式具身代理》。*神经信息处理系统进展*，第35卷（2022年），18343–18362页。
- en: Feng et al. (2023) Yue Feng, Shuchang Liu, Zhenghai Xue, Qingpeng Cai, Lantao
    Hu, Peng Jiang, Kun Gai, and Fei Sun. 2023. A Large Language Model Enhanced Conversational
    Recommender System. *arXiv preprint arXiv:2308.06212* (2023).
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冯等（2023）冯岳、刘书畅、薛正海、蔡清鹏、胡兰涛、蒋鹏、盖昆和孙飞。2023年。《大型语言模型增强的对话推荐系统》。*arXiv预印本arXiv:2308.06212*（2023年）。
- en: Franceschelli and Musolesi (2023) Giorgio Franceschelli and Mirco Musolesi.
    2023. On the creativity of large language models. *arXiv preprint arXiv:2304.00008*
    (2023).
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弗朗切斯切利和穆索雷西（2023）乔治·弗朗切斯切利和米尔科·穆索雷西。2023年。《大型语言模型的创造力》。*arXiv预印本arXiv:2304.00008*（2023年）。
- en: 'Fu et al. (2023a) Daocheng Fu, Xin Li, Licheng Wen, Min Dou, Pinlong Cai, Botian
    Shi, and Yu Qiao. 2023a. Drive Like a Human: Rethinking Autonomous Driving with
    Large Language Models. arXiv:2307.07162 [cs.RO]'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 傅等（2023a）傅道成、李鑫、温立成、窦敏、蔡品龙、施博天和乔宇。2023a年。《像人一样驾驶：用大型语言模型重新思考自动驾驶》。arXiv:2307.07162
    [cs.RO]
- en: Fu et al. (2023b) Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. 2023b.
    Improving language model negotiation with self-play and in-context learning from
    ai feedback. *arXiv preprint arXiv:2305.10142* (2023).
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 傅等（2023b）傅尧、彭浩、图沙尔·霍特和米雷拉·拉帕塔。2023b年。《通过自我博弈和上下文学习提高语言模型的谈判能力》。*arXiv预印本arXiv:2305.10142*（2023年）。
- en: 'Ge et al. (2023) Yingqiang Ge, Wenyue Hua, Kai Mei, jianchao ji, Juntao Tan,
    Shuyuan Xu, Zelong Li, and Yongfeng Zhang. 2023. OpenAGI: When LLM Meets Domain
    Experts. In *Thirty-seventh Conference on Neural Information Processing Systems*.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 葛等（2023）葛英强、华文越、梅凯、季建超、谭俊涛、徐书元、李泽龙、张永峰。2023年。《OpenAGI：当大型语言模型遇到领域专家》。发表于*第37届神经信息处理系统会议论文集*。
- en: 'Geng et al. (2022) Shijie Geng, Shuchang Liu, Zuohui Fu, Yingqiang Ge, and
    Yongfeng Zhang. 2022. Recommendation as Language Processing (RLP): A Unified Pretrain,
    Personalized Prompt & Predict Paradigm (P5). In *Proceedings of the 16th ACM Conference
    on Recommender Systems*. 299–315.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 耿等（2022）耿世杰、刘书畅、傅佐辉、葛英强、张永峰。2022年。《推荐作为语言处理（RLP）：一个统一的预训练、个性化提示和预测范式（P5）》。发表于*第16届ACM推荐系统会议论文集*，299–315页。
- en: Gravitas (2023) Significant Gravitas. 2023. *AutoGPT*. [https://news.agpt.co/](https://news.agpt.co/)
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gravitas（2023）重大Gravitas。2023年。*AutoGPT*。[https://news.agpt.co/](https://news.agpt.co/)
- en: Gray et al. (2017) Scott Gray, Alec Radford, and Diederik P Kingma. 2017. Gpu
    kernels for block-sparse weights. *arXiv preprint arXiv:1711.09224* 3, 2 (2017),
    2.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格雷等（2017）斯科特·格雷、阿莱克·拉德福德、迪德里克·P·金马。2017年。《块稀疏权重的GPU内核》。*arXiv预印本arXiv:1711.09224*，3，2（2017），第2页。
- en: Guu et al. (2020) Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei
    Chang. 2020. Retrieval augmented language model pre-training. In *International
    conference on machine learning*. PMLR, 3929–3938.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 古等（2020）凯尔文·古、肯顿·李、佐拉·通、潘普荣·帕苏帕、明伟·张。2020年。《检索增强语言模型的预训练》。发表于*国际机器学习会议论文集*，PMLR，3929–3938页。
- en: 'Hausknecht et al. (2020) Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre
    Côté, and Xingdi Yuan. 2020. Interactive fiction games: A colossal adventure.
    In *Proceedings of the AAAI Conference on Artificial Intelligence*, Vol. 34\.
    7903–7910.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 豪斯内赫特等（2020）马修·豪斯内赫特、普里斯维拉吉·阿曼纳布罗卢、马克-亚历山大·科特和邓迪·袁。2020年。《互动小说游戏：一场宏大的冒险》。发表于*2020年AAAI人工智能会议论文集*，第34卷，7903–7910页。
- en: 'Hong et al. (2023) Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al.
    2023. Metagpt: Meta programming for multi-agent collaborative framework. *arXiv
    preprint arXiv:2308.00352* (2023).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 洪等（2023）洪思睿、郑晓武、陈杰、程宇衡、张策瑶、王子力、邹启星、林子娟、周丽扬、冉晨宇等。2023年。《MetaGPT：用于多智能体协作框架的元编程》。*arXiv预印本arXiv:2308.00352*（2023年）。
- en: 'Hu et al. (2023) Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao,
    and Hang Zhao. 2023. ChatDB: Augmenting LLMs with Databases as Their Symbolic
    Memory. *arXiv preprint arXiv:2306.03901* (2023).'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 胡等（2023）胡晨旭、傅杰、杜晨壮、罗思勉、赵俊博、赵航。2023年。《ChatDB：用数据库增强大型语言模型的符号记忆》。*arXiv预印本arXiv:2306.03901*（2023年）。
- en: 'Hua et al. (2023a) Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji,
    Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. 2023a. War and Peace (WarAgent):
    Large Language Model-based Multi-Agent Simulation of World Wars. *arXiv preprint
    arXiv:2311.17227* (2023).'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hua et al. (2023a) Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji,
    Yingqiang Ge, Libby Hemphill, 和 Yongfeng Zhang. 2023a. 战争与和平（WarAgent）：基于大规模语言模型的世界大战多智能体仿真.
    *arXiv 预印本 arXiv:2311.17227* (2023).
- en: Hua et al. (2023b) Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and Yongfeng Zhang.
    2023b. How to Index Item IDs for Recommendation Foundation Models. In *Proceedings
    of the Annual International ACM SIGIR Conference on Research and Development in
    Information Retrieval in the Asia Pacific Region*. 195–204.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hua et al. (2023b) Wenyue Hua, Shuyuan Xu, Yingqiang Ge, 和 Yongfeng Zhang. 2023b.
    如何为推荐基础模型建立项目 ID 索引. 载于 *亚太地区国际 ACM SIGIR 信息检索研究与发展年会论文集*. 195–204.
- en: 'Huang and Chang (2022) Jie Huang and Kevin Chen-Chuan Chang. 2022. Towards
    reasoning in large language models: A survey. *arXiv preprint arXiv:2212.10403*
    (2022).'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 和 Chang (2022) Jie Huang 和 Kevin Chen-Chuan Chang. 2022. 朝向大规模语言模型的推理：一项综述.
    *arXiv 预印本 arXiv:2212.10403* (2022).
- en: Huang et al. (2023) Qian Huang, Jian Vora, Percy Liang, and Jure Leskovec. 2023.
    Benchmarking Large Language Models As AI Research Agents. *arXiv preprint arXiv:2310.03302*
    (2023).
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. (2023) Qian Huang, Jian Vora, Percy Liang, 和 Jure Leskovec. 2023.
    基准测试大规模语言模型作为人工智能研究代理. *arXiv 预印本 arXiv:2310.03302* (2023).
- en: IEEE and Group (2018) IEEE and The Open Group. 2018. The POSIX standard. [https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/](https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/).
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IEEE 和 Group (2018) IEEE 和 The Open Group. 2018. POSIX 标准. [https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/](https://pubs.opengroup.org/onlinepubs/9699919799.2018edition/).
- en: Izacard et al. (2022) Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini,
    Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel,
    and Edouard Grave. 2022. Few-shot learning with retrieval augmented language models.
    *arXiv preprint arXiv:2208.03299* (2022).
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Izacard et al. (2022) Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini,
    Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel,
    和 Edouard Grave. 2022. 基于检索增强语言模型的少样本学习. *arXiv 预印本 arXiv:2208.03299* (2022).
- en: 'Jiang et al. (2023) Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang,
    and Lili Qiu. 2023. Llmlingua: Compressing prompts for accelerated inference of
    large language models. *arXiv preprint arXiv:2310.05736* (2023).'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiang et al. (2023) Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang,
    和 Lili Qiu. 2023. Llmlingua: 压缩提示词以加速大规模语言模型的推理. *arXiv 预印本 arXiv:2310.05736*
    (2023).'
- en: Johnson et al. (2019) Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale
    similarity search with gpus. *IEEE Transactions on Big Data* 7, 3 (2019), 535–547.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Johnson et al. (2019) Jeff Johnson, Matthijs Douze, 和 Hervé Jégou. 2019. 使用
    GPU 的十亿级相似性搜索. *IEEE 大数据学报* 7, 3 (2019), 535–547.
- en: Karpukhin et al. (2020) Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage
    retrieval for open-domain question answering. *arXiv preprint arXiv:2004.04906*
    (2020).
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpukhin et al. (2020) Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, 和 Wen-tau Yih. 2020. 开放域问答的密集段落检索.
    *arXiv 预印本 arXiv:2004.04906* (2020).
- en: 'Katharopoulos et al. (2020) Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas,
    and François Fleuret. 2020. Transformers are rnns: Fast autoregressive transformers
    with linear attention. In *International conference on machine learning*. PMLR,
    5156–5165.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Katharopoulos et al. (2020) Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas,
    和 François Fleuret. 2020. Transformer 是 RNN：具有线性注意力的快速自回归 Transformer. 载于 *国际机器学习会议*，PMLR,
    5156–5165.
- en: Kim et al. (2023) Geunwoo Kim, Pierre Baldi, and Stephen McAleer. 2023. Language
    Models can Solve Computer Tasks. *arXiv preprint arXiv:2303.17491* (2023).
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim et al. (2023) Geunwoo Kim, Pierre Baldi, 和 Stephen McAleer. 2023. 语言模型可以解决计算机任务.
    *arXiv 预印本 arXiv:2303.17491* (2023).
- en: 'Kitaev et al. (2020) Nikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. 2020.
    Reformer: The efficient transformer. *arXiv preprint arXiv:2001.04451* (2020).'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kitaev et al. (2020) Nikita Kitaev, Łukasz Kaiser, 和 Anselm Levskaya. 2020.
    Reformer: 高效的 Transformer. *arXiv 预印本 arXiv:2001.04451* (2020).'
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners.
    *Advances in neural information processing systems* 35 (2022), 22199–22213.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, 和 Yusuke Iwasawa. 2022. 大规模语言模型是零样本推理器. *神经信息处理系统进展* 35 (2022), 22199–22213.
- en: Lee et al. (2023) Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos,
    and Kangwook Lee. 2023. Prompted LLMs as Chatbot Modules for Long Open-domain
    Conversation. *arXiv preprint arXiv:2305.04533* (2023).
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee等人（2023）Gibbeum Lee、Volker Hartmann、Jongho Park、Dimitris Papailiopoulos和Kangwook
    Lee。2023. **通过聊天机器人模块提示大语言模型进行长时间开放领域对话**。*arXiv预印本 arXiv:2305.04533*（2023）。
- en: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive
    nlp tasks. *Advances in Neural Information Processing Systems* 33 (2020), 9459–9474.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis等人（2020）Patrick Lewis、Ethan Perez、Aleksandra Piktus、Fabio Petroni、Vladimir
    Karpukhin、Naman Goyal、Heinrich Küttler、Mike Lewis、Wen-tau Yih、Tim Rocktäschel等人。2020.
    **检索增强生成用于知识密集型自然语言处理任务**。*神经信息处理系统进展* 33（2020），9459–9474。
- en: 'Li et al. (2023) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023. CAMEL: Communicative Agents for "Mind" Exploration
    of Large Scale Language Model Society. arXiv:2303.17760 [cs.AI]'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等人（2023）Guohao Li、Hasan Abed Al Kader Hammoud、Hani Itani、Dmitrii Khizbullin和Bernard
    Ghanem。2023. CAMEL：用于“大规模语言模型社会”心智探索的交互式代理。arXiv:2303.17760 [cs.AI]
- en: Liang et al. (2023a) Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang,
    Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023a. Encouraging Divergent
    Thinking in Large Language Models through Multi-Agent Debate. arXiv:2305.19118 [cs.CL]
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang等人（2023a）Tian Liang、Zhiwei He、Wenxiang Jiao、Xing Wang、Yan Wang、Rui Wang、Yujiu
    Yang、Zhaopeng Tu和Shuming Shi。2023a. **通过多代理辩论鼓励大语言模型中的发散性思维**。arXiv:2305.19118
    [cs.CL]
- en: 'Liang et al. (2023b) Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia,
    Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, et al. 2023b. Taskmatrix. ai:
    Completing tasks by connecting foundation models with millions of apis. *arXiv
    preprint arXiv:2303.16434* (2023).'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liang等人（2023b）Yaobo Liang、Chenfei Wu、Ting Song、Wenshan Wu、Yan Xia、Yu Liu、Yang
    Ou、Shuai Lu、Lei Ji、Shaoguang Mao等人。2023b. **Taskmatrix.ai：通过连接基础模型与数百万API来完成任务**。*arXiv预印本
    arXiv:2303.16434*（2023）。
- en: Liu (2022) Jerry Liu. 2022. *LlamaIndex*. [https://doi.org/10.5281/zenodo.1234](https://doi.org/10.5281/zenodo.1234)
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu（2022）Jerry Liu。2022. *LlamaIndex*。 [https://doi.org/10.5281/zenodo.1234](https://doi.org/10.5281/zenodo.1234)
- en: 'Liu et al. (2023b) Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023b. Lost in the middle:
    How language models use long contexts. *arXiv preprint arXiv:2307.03172* (2023).'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023b）Nelson F Liu、Kevin Lin、John Hewitt、Ashwin Paranjape、Michele Bevilacqua、Fabio
    Petroni和Percy Liang。2023b. **迷失在中间**：语言模型如何使用长上下文。*arXiv预印本 arXiv:2307.03172*（2023）。
- en: 'Liu et al. (2023a) Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke,
    Boyi Liu, and Zhaoran Wang. 2023a. Reason for Future, Act for Now: A Principled
    Framework for Autonomous LLM Agents with Provable Sample Efficiency. *arXiv preprint
    arXiv:2309.17382* (2023).'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023a）刘志涵、胡浩、张胜昊、郭洪逸、柯书奇、刘博一和王兆然。2023a. **未来的理由，行动的现在**：具有可证明样本效率的自主大语言模型代理的原则性框架。*arXiv预印本
    arXiv:2309.17382*（2023）。
- en: 'Liu et al. (2023c) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al.
    2023c. BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents.
    *arXiv preprint arXiv:2308.05960* (2023).'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023c）Zhiwei Liu、Weiran Yao、Jianguo Zhang、Le Xue、Shelby Heinecke、Rithesh
    Murthy、Yihao Feng、Zeyuan Chen、Juan Carlos Niebles、Devansh Arpit等人。2023c. **BOLAA：基准测试和协调大语言模型增强的自主代理**。*arXiv预印本
    arXiv:2308.05960*（2023）。
- en: 'Lu et al. (2023) Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He,
    Di Yin, Xing Sun, and Yunsheng Wu. 2023. MemoChat: Tuning LLMs to Use Memos for
    Consistent Long-Range Open-Domain Conversation. arXiv:2308.08239 [cs.CL]'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu等人（2023）Junru Lu、Siyu An、Mingbao Lin、Gabriele Pergola、Yulan He、Di Yin、Xing
    Sun和Yunsheng Wu。2023. MemoChat：调整大语言模型使用备忘录进行一致的长程开放领域对话。arXiv:2308.08239 [cs.CL]
- en: Molnár (2007) Ingo Molnár. 2007. Linux CFS Scheduler. [https://docs.kernel.org/scheduler/sched-design-CFS.html](https://docs.kernel.org/scheduler/sched-design-CFS.html).
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Molnár（2007）Ingo Molnár。2007. **Linux CFS调度器**。 [https://docs.kernel.org/scheduler/sched-design-CFS.html](https://docs.kernel.org/scheduler/sched-design-CFS.html)。
- en: 'Morris et al. (2023) Meredith Ringel Morris, Jascha Sohl-dickstein, Noah Fiedel,
    Tris Warkentin, Allan Dafoe, Aleksandra Faust, Clement Farabet, and Shane Legg.
    2023. Levels of AGI: Operationalizing Progress on the Path to AGI. *arXiv preprint
    arXiv:2311.02462* (2023).'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Morris等人（2023）Meredith Ringel Morris、Jascha Sohl-dickstein、Noah Fiedel、Tris
    Warkentin、Allan Dafoe、Aleksandra Faust、Clement Farabet和Shane Legg。2023. **AGI的各个层次：在通往AGI的道路上实现进展**。*arXiv预印本
    arXiv:2311.02462*（2023）。
- en: 'Nakano et al. (2022) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. WebGPT: Browser-assisted
    question-answering with human feedback. arXiv:2112.09332 [cs.CL]'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nakano 等人 (2022) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long
    Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William
    Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button,
    Matthew Knight, Benjamin Chess 和 John Schulman. 2022. WebGPT: 通过浏览器辅助的问答与人类反馈。arXiv:2112.09332
    [cs.CL]'
- en: OpenAI (2023) OpenAI. 2023. GPT-4V(ision) System Card. (2023).
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI (2023) OpenAI. 2023. GPT-4V(ision) 系统卡。 (2023)。
- en: 'Orman (2003) H. Orman. 2003. The Morris worm: a fifteen-year perspective. *IEEE
    Security & Privacy* 1, 5 (2003), 35–43. [https://doi.org/10.1109/MSECP.2003.1236233](https://doi.org/10.1109/MSECP.2003.1236233)'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orman (2003) H. Orman. 2003. 莫里斯蠕虫：十五年的回顾。*IEEE 安全与隐私* 1, 5 (2003), 35–43. [https://doi.org/10.1109/MSECP.2003.1236233](https://doi.org/10.1109/MSECP.2003.1236233)
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems* 35 (2022), 27730–27744.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang 等人 (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright,
    Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray 等人. 2022.
    训练语言模型以遵循带有人类反馈的指令。*神经信息处理系统进展* 35 (2022), 27730–27744。
- en: 'Packer et al. (2023) Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin,
    Sarah Wooders, and Joseph E Gonzalez. 2023. MemGPT: Towards LLMs as Operating
    Systems. *arXiv preprint arXiv:2310.08560* (2023).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Packer 等人 (2023) Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah
    Wooders 和 Joseph E Gonzalez. 2023. MemGPT: 朝着将大型语言模型作为操作系统的方向发展。*arXiv 预印本 arXiv:2310.08560*
    (2023)。'
- en: 'Pan et al. (2023) Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang,
    and Xindong Wu. 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap.
    *arXiv preprint arXiv:2306.08302* (2023).'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan 等人 (2023) Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang 和 Xindong
    Wu. 2023. 统一大型语言模型与知识图谱：一条路线图。*arXiv 预印本 arXiv:2306.08302* (2023)。
- en: 'Parisi et al. (2022) Aaron Parisi, Yao Zhao, and Noah Fiedel. 2022. Talm: Tool
    augmented language models. *arXiv preprint arXiv:2205.12255* (2022).'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Parisi 等人 (2022) Aaron Parisi, Yao Zhao 和 Noah Fiedel. 2022. Talm: 工具增强语言模型。*arXiv
    预印本 arXiv:2205.12255* (2022)。'
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. In *Proceedings of the 36th Annual ACM Symposium
    on User Interface Software and Technology*. 1–22.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人 (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang 和 Michael S Bernstein. 2023. 生成代理：人类行为的互动仿真。收录于 *第36届 ACM
    用户界面软件与技术年会论文集*，1–22。
- en: 'Patil et al. (2023) Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E
    Gonzalez. 2023. Gorilla: Large language model connected with massive apis. *arXiv
    preprint arXiv:2305.15334* (2023).'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Patil 等人 (2023) Shishir G Patil, Tianjun Zhang, Xin Wang 和 Joseph E Gonzalez.
    2023. Gorilla: 连接海量 API 的大型语言模型。*arXiv 预印本 arXiv:2305.15334* (2023)。'
- en: 'Press et al. (2021) Ofir Press, Noah A Smith, and Mike Lewis. 2021. Train short,
    test long: Attention with linear biases enables input length extrapolation. *arXiv
    preprint arXiv:2108.12409* (2021).'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Press 等人 (2021) Ofir Press, Noah A Smith 和 Mike Lewis. 2021. 短期训练，长期测试：具有线性偏差的注意力机制使输入长度外推成为可能。*arXiv
    预印本 arXiv:2108.12409* (2021)。
- en: Qi et al. (2023a) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Peter Henderson,
    Mengdi Wang, and Prateek Mittal. 2023a. Visual Adversarial Examples Jailbreak
    Aligned Large Language Models. arXiv:2306.13213 [cs.CR]
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi 等人 (2023a) Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Peter Henderson, Mengdi
    Wang 和 Prateek Mittal. 2023a. 视觉对抗样本突破对齐的大型语言模型。arXiv:2306.13213 [cs.CR]
- en: Qi et al. (2023b) Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia,
    Prateek Mittal, and Peter Henderson. 2023b. Fine-tuning Aligned Language Models
    Compromises Safety, Even When Users Do Not Intend To! *arXiv preprint arXiv:2310.03693*
    (2023).
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi 等人 (2023b) Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek
    Mittal 和 Peter Henderson. 2023b. 微调对齐语言模型会妥协安全性，即使用户并不打算这样做！*arXiv 预印本 arXiv:2310.03693*
    (2023)。
- en: Qian et al. (2023a) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023a. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924* (2023).
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人 (2023a) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan
    Xu, Zhiyuan Liu 和 Maosong Sun. 2023a. 面向软件开发的交互式智能代理。*arXiv 预印本 arXiv:2307.07924*
    (2023)。
- en: 'Qian et al. (2023b) Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu,
    and Heng Ji. 2023b. CREATOR: Disentangling Abstract and Concrete Reasonings of
    Large Language Models through Tool Creation. *arXiv preprint arXiv:2305.14318*
    (2023).'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qian等人（2023b）Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, 和 Heng
    Ji. 2023b. CREATOR: 通过工具创建解开大语言模型的抽象和具体推理. *arXiv预印本 arXiv:2305.14318*（2023）。'
- en: Qin et al. (2023a) Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding,
    Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al. 2023a. Tool
    learning with foundation models. *arXiv preprint arXiv:2304.08354* (2023).
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin等人（2023a）Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu
    Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han等人. 2023a. 基于基础模型的工具学习. *arXiv预印本
    arXiv:2304.08354*（2023）。
- en: 'Qin et al. (2023b) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. 2023b. Toolllm:
    Facilitating large language models to master 16000+ real-world apis. *arXiv preprint
    arXiv:2307.16789* (2023).'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin等人（2023b）Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu,
    Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian等人. 2023b. Toolllm：帮助大语言模型掌握16000+现实世界API.
    *arXiv预印本 arXiv:2307.16789*（2023）。
- en: Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask
    learners. *OpenAI blog* 1, 8 (2019), 9.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等人（2019）Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei,
    Ilya Sutskever等人. 2019. 语言模型是无监督的多任务学习者. *OpenAI博客* 1, 8（2019），9。
- en: Ritchie and Thompson (1974) Dennis M. Ritchie and Ken Thompson. 1974. The UNIX
    Time-Sharing System. *Commun. ACM* 17, 7 (jul 1974), 365–375. [https://doi.org/10.1145/361011.361061](https://doi.org/10.1145/361011.361061)
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ritchie和Thompson（1974）Dennis M. Ritchie和Ken Thompson. 1974. UNIX时间共享系统. *ACM通讯*
    17, 7（1974年7月），365–375。[https://doi.org/10.1145/361011.361061](https://doi.org/10.1145/361011.361061)
- en: 'Robertson et al. (2009) Stephen Robertson, Hugo Zaragoza, et al. 2009. The
    probabilistic relevance framework: BM25 and beyond. *Foundations and Trends® in
    Information Retrieval* 3, 4 (2009), 333–389.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robertson等人（2009）Stephen Robertson, Hugo Zaragoza等人. 2009. 概率相关框架：BM25及其扩展.
    *信息检索基础与趋势®* 3, 4（2009），333–389。
- en: 'Rozière et al. (2023) Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy
    Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton
    Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal
    Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel
    Synnaeve. 2023. Code Llama: Open Foundation Models for Code. arXiv:2308.12950 [cs.CL]'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rozière等人（2023）Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla,
    Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin,
    Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton
    Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal
    Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, 和 Gabriel
    Synnaeve. 2023. Code Llama：开源基础模型用于代码. arXiv:2308.12950 [cs.CL]
- en: 'Ruan et al. (2023a) Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng
    Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao. 2023a. Tptu:
    Task planning and tool usage of large language model-based ai agents. *arXiv preprint
    arXiv:2308.03427* (2023).'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ruan等人（2023a）Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao,
    Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, 和 Rui Zhao. 2023a. Tptu：基于大语言模型的AI代理的任务规划和工具使用.
    *arXiv预印本 arXiv:2308.03427*（2023）。
- en: Ruan et al. (2023b) Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao
    Zhou, Jimmy Ba, Yann Dubois, Chris J. Maddison, and Tatsunori Hashimoto. 2023b.
    Identifying the Risks of LM Agents with an LM-Emulated Sandbox. arXiv:2309.15817 [cs.AI]
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ruan等人（2023b）Yangjun Ruan, Honghua Dong, Andrew Wang, Silviu Pitis, Yongchao
    Zhou, Jimmy Ba, Yann Dubois, Chris J. Maddison, 和 Tatsunori Hashimoto. 2023b.
    使用LM仿真沙箱识别LM代理的风险. arXiv:2309.15817 [cs.AI]
- en: Russell and Norvig (1995) Stuart Russell and Peter Norvig. 1995. *Prentice Hall
    series in artificial intelligence*. Prentice Hall Englewood Cliffs, NJ:.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russell和Norvig（1995）Stuart Russell和Peter Norvig. 1995. *普伦蒂斯·霍尔人工智能系列*. 普伦蒂斯·霍尔，Englewood
    Cliffs, NJ：。
- en: Safdari et al. (2023) Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen
    Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić.
    2023. Personality traits in large language models. *arXiv preprint arXiv:2307.00184*
    (2023).
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Safdari等人（2023）Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen
    Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, 和 Maja Matarić.
    2023. 大语言模型中的人格特征. *arXiv预印本 arXiv:2307.00184*（2023）。
- en: Salton (1975) Gerard Salton. 1975. A vector space model for information retrieval.
    *Journal of the ASIS* (1975), 613–620.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salton（1975）Gerard Salton. 1975. 用于信息检索的向量空间模型. *美国信息科学学会期刊*（1975），613–620。
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer:
    Language models can teach themselves to use tools. *arXiv preprint arXiv:2302.04761*
    (2023).'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick 等人 (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda 和 Thomas Scialom. 2023. Toolformer:
    语言模型可以自我学习使用工具。*arXiv 预印本 arXiv:2302.04761* (2023)。'
- en: Serapio-García et al. (2023) Greg Serapio-García, Mustafa Safdari, Clément Crepy,
    Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, and
    Maja Matarić. 2023. Personality Traits in Large Language Models. arXiv:2307.00184 [cs.CL]
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Serapio-García 等人 (2023) Greg Serapio-García, Mustafa Safdari, Clément Crepy,
    Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust 和 Maja
    Matarić. 2023. 大型语言模型中的人格特征。arXiv:2307.00184 [cs.CL]
- en: 'Shazeer (2019) Noam Shazeer. 2019. Fast transformer decoding: One write-head
    is all you need. *arXiv preprint arXiv:1911.02150* (2019).'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shazeer (2019) Noam Shazeer. 2019. 快速 transformer 解码：一个写头就足够了。*arXiv 预印本 arXiv:1911.02150*
    (2019)。
- en: Shi et al. (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David
    Dohan, Ed H Chi, Nathanael Schärli, and Denny Zhou. 2023. Large language models
    can be easily distracted by irrelevant context. In *International Conference on
    Machine Learning*. PMLR, 31210–31227.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等人 (2023) Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan,
    Ed H Chi, Nathanael Schärli 和 Denny Zhou. 2023. 大型语言模型容易被无关背景分散注意力。发表于 *国际机器学习大会*。PMLR，31210–31227。
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath,
    Karthik Narasimhan, and Shunyu Yao. 2023. Reflexion: Language agents with verbal
    reinforcement learning. *arXiv preprint arXiv:2303.11366* (2023).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn 等人 (2023) Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath,
    Karthik Narasimhan 和 Shunyu Yao. 2023. Reflexion: 使用语言强化学习的语言代理。*arXiv 预印本 arXiv:2303.11366*
    (2023)。'
- en: 'Shridhar et al. (2020) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan
    Bisk, Adam Trischler, and Matthew Hausknecht. 2020. Alfworld: Aligning text and
    embodied environments for interactive learning. *arXiv preprint arXiv:2010.03768*
    (2020).'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shridhar 等人 (2020) Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan
    Bisk, Adam Trischler 和 Matthew Hausknecht. 2020. Alfworld: 对齐文本与具身环境以进行互动学习。*arXiv
    预印本 arXiv:2010.03768* (2020)。'
- en: Sledziewski et al. (2010) Krzysztof Sledziewski, Behzad Bordbar, and Rachid
    Anane. 2010. A DSL-Based Approach to Software Development and Deployment on Cloud.
    In *2010 24th IEEE International Conference on Advanced Information Networking
    and Applications*. 414–421. [https://doi.org/10.1109/AINA.2010.81](https://doi.org/10.1109/AINA.2010.81)
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sledziewski 等人 (2010) Krzysztof Sledziewski, Behzad Bordbar 和 Rachid Anane.
    2010. 基于 DSL 的云端软件开发与部署方法。在 *2010 年第 24 届 IEEE 国际信息网络与应用大会* 上。414–421。[https://doi.org/10.1109/AINA.2010.81](https://doi.org/10.1109/AINA.2010.81)
- en: 'Stoica and Abdel-Wahab (1995) I. Stoica and H. Abdel-Wahab. 1995. *Earliest
    Eligible Virtual Deadline First: A Flexible and Accurate Mechanism for Proportional
    Share Resource Allocation*. Technical Report. USA.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Stoica 和 Abdel-Wahab (1995) I. Stoica 和 H. Abdel-Wahab. 1995. *Earliest Eligible
    Virtual Deadline First: 一种灵活且精确的按比例分配资源机制*。技术报告。美国。'
- en: 'Su et al. (2021) Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen,
    and Yunfeng Liu. 2021. Roformer: Enhanced transformer with rotary position embedding.
    *arXiv preprint arXiv:2104.09864* (2021).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Su 等人 (2021) Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen 和 Yunfeng
    Liu. 2021. Roformer: 带有旋转位置嵌入的增强型 transformer。*arXiv 预印本 arXiv:2104.09864* (2021)。'
- en: 'Sun et al. (2023) Qiushi Sun, Zhangyue Yin, Xiang Li, Zhiyong Wu, Xipeng Qiu,
    and Lingpeng Kong. 2023. Corex: Pushing the Boundaries of Complex Reasoning through
    Multi-Model Collaboration. arXiv:2310.00280 [cs.AI]'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sun 等人 (2023) Qiushi Sun, Zhangyue Yin, Xiang Li, Zhiyong Wu, Xipeng Qiu 和
    Lingpeng Kong. 2023. Corex: 通过多模型协作推动复杂推理的边界。arXiv:2310.00280 [cs.AI]'
- en: Sun et al. (2022) Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang,
    Alon Benhaim, Vishrav Chaudhary, Xia Song, and Furu Wei. 2022. A length-extrapolatable
    transformer. *arXiv preprint arXiv:2212.10554* (2022).
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等人 (2022) Yutao Sun, Li Dong, Barun Patra, Shuming Ma, Shaohan Huang, Alon
    Benhaim, Vishrav Chaudhary, Xia Song 和 Furu Wei. 2022. 一种长度可外推的 transformer。*arXiv
    预印本 arXiv:2212.10554* (2022)。
- en: 'Sundar and Heck (2023) Anirudh S Sundar and Larry Heck. 2023. cTBL: Augmenting
    Large Language Models for Conversational Tables. *arXiv preprint arXiv:2303.12024*
    (2023).'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sundar 和 Heck (2023) Anirudh S Sundar 和 Larry Heck. 2023. cTBL: 增强大型语言模型的对话表格功能。*arXiv
    预印本 arXiv:2303.12024* (2023)。'
- en: 'Tang et al. (2023) Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao
    Liang, and Le Sun. 2023. ToolAlpaca: Generalized Tool Learning for Language Models
    with 3000 Simulated Cases. *arXiv preprint arXiv:2306.05301* (2023).'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tang 等人 (2023) Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang
    和 Le Sun. 2023. ToolAlpaca: 面向语言模型的广义工具学习，包含 3000 个模拟案例。*arXiv 预印本 arXiv:2306.05301*
    (2023)。'
- en: 'Taori et al. (2023) Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois,
    Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford
    Alpaca: An Instruction-following LLaMA model. [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca).'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Taori 等人（2023）Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen
    Li, Carlos Guestrin, Percy Liang 和 Tatsunori B. Hashimoto. 2023. Stanford Alpaca:
    一种遵循指令的 LLaMA 模型. [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca).'
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288* (2023).'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人（2023）Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad
    Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale 等人. 2023. Llama 2: 开放的基础和微调的聊天模型. *arXiv 预印本 arXiv:2307.09288*
    (2023).'
- en: UW:CSE451 (2023) UW:CSE451. 2023. History of Operating Systems. [https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf](https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf).
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UW:CSE451（2023）UW:CSE451. 2023. 操作系统历史. [https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf](https://courses.cs.washington.edu/courses/cse451/16wi/readings/lecture_readings/LCM_OperatingSystemsTimeline_Color_acd_newsize.pdf).
- en: Valmeekam et al. (2022) Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan,
    and Subbarao Kambhampati. 2022. Large Language Models Still Can’t Plan (A Benchmark
    for LLMs on Planning and Reasoning about Change). In *NeurIPS 2022 Foundation
    Models for Decision Making Workshop*.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Valmeekam 等人（2022）Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan 和 Subbarao
    Kambhampati. 2022. 大型语言模型仍然无法进行规划（LLM 在规划和推理变化方面的基准测试）. 见 *NeurIPS 2022 决策制定基础模型研讨会*.
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. *Advances in neural information processing systems* 30 (2017).
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等人（2017）Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser 和 Illia Polosukhin. 2017. 注意力机制就是你所需要的一切.
    *神经信息处理系统进展* 30 (2017).
- en: 'Vemprala et al. (2023) Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish
    Kapoor. 2023. Chatgpt for robotics: Design principles and model abilities. *Microsoft
    Auton. Syst. Robot. Res* 2 (2023), 20.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vemprala 等人（2023）Sai Vemprala, Rogerio Bonatti, Arthur Bucker 和 Ashish Kapoor.
    2023. 用于机器人技术的 ChatGPT: 设计原则与模型能力. *Microsoft Auton. Syst. Robot. Res* 2 (2023),
    20.'
- en: 'Wang et al. (2023e) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023e. Voyager: An open-ended
    embodied agent with large language models. *arXiv preprint arXiv:2305.16291* (2023).'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2023e）Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan 和 Anima Anandkumar. 2023e. Voyager: 一个基于大语言模型的开放式具身代理.
    *arXiv 预印本 arXiv:2305.16291* (2023).'
- en: 'Wang et al. (2023f) Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song,
    Wayne Xin Zhao, and Ji-Rong Wen. 2023f. RecAgent: A Novel Simulation Paradigm
    for Recommender Systems. *arXiv preprint arXiv:2306.02552* (2023).'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2023f）Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne
    Xin Zhao 和 Ji-Rong Wen. 2023f. RecAgent: 一种新的推荐系统仿真范式. *arXiv 预印本 arXiv:2306.02552*
    (2023).'
- en: 'Wang et al. (2020) Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and
    Hao Ma. 2020. Linformer: Self-attention with linear complexity. *arXiv preprint
    arXiv:2006.04768* (2020).'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2020）Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang 和 Hao Ma. 2020.
    Linformer: 具有线性复杂度的自注意力机制. *arXiv 预印本 arXiv:2006.04768* (2020).'
- en: Wang et al. (2022) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H
    Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-Consistency
    Improves Chain of Thought Reasoning in Language Models. In *The Eleventh International
    Conference on Learning Representations*.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2022）Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan
    Narang, Aakanksha Chowdhery 和 Denny Zhou. 2022. 自一致性提升语言模型的思维链推理. 见 *第十一届国际学习表征会议*.
- en: 'Wang et al. (2023c) Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue
    Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023c.
    RecMind: Large Language Model Powered Agent For Recommendation. *arXiv preprint
    arXiv:2308.14296* (2023).'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人（2023c）Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou,
    Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu 和 Yingzhen Yang. 2023c. RecMind:
    基于大语言模型的推荐代理. *arXiv 预印本 arXiv:2308.14296* (2023).'
- en: Wang et al. (2023d) Yubo Wang, Xueguang Ma, and Wenhu Chen. 2023d. Augmenting
    Black-box LLMs with Medical Textbooks for Clinical Question Answering. *arXiv
    preprint arXiv:2309.02233* (2023).
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023d) Yubo Wang, Xueguang Ma, and Wenhu Chen. 2023d. 通过医学教科书增强黑盒LLM以进行临床问题回答。
    *arXiv预印本 arXiv:2309.02233* (2023)。
- en: 'Wang et al. (2023a) Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao
    Liang. 2023a. Describe, explain, plan and select: Interactive planning with large
    language models enables open-world multi-task agents. *arXiv preprint arXiv:2302.01560*
    (2023).'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023a) Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao
    Liang. 2023a. 描述、解释、规划与选择：使用大语言模型的互动规划使开放世界的多任务智能体成为可能。 *arXiv预印本 arXiv:2302.01560*
    (2023)。
- en: 'Wang et al. (2023b) Zhilin Wang, Yu Ying Chiu, and Yu Cheung Chiu. 2023b. Humanoid
    Agents: Platform for Simulating Human-like Generative Agents. arXiv:2310.05418 [cs.CL]'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2023b) Zhilin Wang, Yu Ying Chiu, and Yu Cheung Chiu. 2023b. 人形智能体：模拟类人生成智能体的平台。
    arXiv:2310.05418 [cs.CL]
- en: 'Wei et al. (2023) Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. 2023.
    Jailbroken: How Does LLM Safety Training Fail? arXiv:2307.02483 [cs.LG]'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2023) Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. 2023.
    被越狱：LLM安全训练失败的原因。 arXiv:2307.02483 [cs.LG]
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems* 35 (2022), 24824–24837.
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. 思维链提示法激发大语言模型的推理能力。 *神经信息处理系统进展*
    35 (2022)，24824–24837。
- en: 'Wooldridge and Jennings (1995) Michael Wooldridge and Nicholas R Jennings.
    1995. Intelligent agents: Theory and practice. *The knowledge engineering review*
    10, 2 (1995), 115–152.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wooldridge and Jennings (1995) Michael Wooldridge and Nicholas R Jennings. 1995.
    智能体：理论与实践。 *知识工程评论* 10, 2 (1995)，115–152。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, and Chi Wang. 2023. AutoGen: Enabling Next-Gen LLM
    Applications via Multi-Agent Conversation. arXiv:2308.08155 [cs.AI]'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, and Chi Wang. 2023. AutoGen：通过多智能体对话启用下一代LLM应用。 arXiv:2308.08155
    [cs.AI]
- en: 'Xu et al. (2023) Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia
    Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, et al. 2023. Lemur: Harmonizing
    Natural Language and Code for Language Agents. *arXiv preprint arXiv:2310.06830*
    (2023).'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2023) Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia
    Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, et al. 2023. Lemur：为语言智能体协调自然语言和代码。
    *arXiv预印本 arXiv:2310.06830* (2023)。
- en: Yang and Ettinger (2023) Chenghao Yang and Allyson Ettinger. 2023. Can You Follow
    Me? Testing Situational Understanding in ChatGPT. *arXiv preprint arXiv:2310.16135*
    (2023).
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang and Ettinger (2023) Chenghao Yang and Allyson Ettinger. 2023. 你能跟上我吗？测试ChatGPT的情境理解能力。
    *arXiv预印本 arXiv:2310.16135* (2023)。
- en: Yang et al. (2023c) Haomiao Yang, Kunlan Xiang, Hongwei Li, and Rongxing Lu.
    2023c. A Comprehensive Overview of Backdoor Attacks in Large Language Models within
    Communication Networks. *arXiv preprint arXiv:2308.14367* (2023).
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2023c) Haomiao Yang, Kunlan Xiang, Hongwei Li, and Rongxing Lu.
    2023c. 大型语言模型在通信网络中的后门攻击综述。 *arXiv预印本 arXiv:2308.14367* (2023)。
- en: 'Yang et al. (2023b) Xianjun Yang, Xiao Wang, Qi Zhang, Linda Petzold, William Yang
    Wang, Xun Zhao, and Dahua Lin. 2023b. Shadow alignment: The ease of subverting
    safely-aligned language models. *arXiv preprint arXiv:2310.02949* (2023).'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2023b) Xianjun Yang, Xiao Wang, Qi Zhang, Linda Petzold, William
    Yang Wang, Xun Zhao, and Dahua Lin. 2023b. 阴影对齐：轻松颠覆安全对齐语言模型的难易程度。 *arXiv预印本 arXiv:2310.02949*
    (2023)。
- en: 'Yang et al. (2023a) Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan
    Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang. 2023a.
    Mm-react: Prompting chatgpt for multimodal reasoning and action. *arXiv preprint
    arXiv:2303.11381* (2023).'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2023a) Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan
    Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, and Lijuan Wang. 2023a.
    Mm-react：通过提示ChatGPT进行多模态推理与行动。 *arXiv预印本 arXiv:2303.11381* (2023)。
- en: 'Yao et al. (2022a) Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan.
    2022a. Webshop: Towards scalable real-world web interaction with grounded language
    agents. *Advances in Neural Information Processing Systems* 35 (2022), 20744–20757.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2022a) Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan.
    2022a. Webshop：面向可扩展的真实世界网页交互，结合基础语言智能体。 *神经信息处理系统进展* 35 (2022)，20744–20757。
- en: 'Yao and Narasimhan (2023) Shunyu Yao and Karthik Narasimhan. 2023. Language
    Agents in the Digital World: Opportunities and Risks. *princeton-nlp.github.io*
    (Jul 2023). [https://princeton-nlp.github.io/language-agent-impact/](https://princeton-nlp.github.io/language-agent-impact/)'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 和 Narasimhan（2023）Shunyu Yao 和 Karthik Narasimhan. 2023. 数字世界中的语言智能体：机会与风险。*princeton-nlp.github.io*（2023年7月）。[https://princeton-nlp.github.io/language-agent-impact/](https://princeton-nlp.github.io/language-agent-impact/)
- en: 'Yao et al. (2023) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts: Deliberate
    problem solving with large language models. *arXiv preprint arXiv:2305.10601*
    (2023).'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等（2023）Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths,
    Yuan Cao 和 Karthik Narasimhan. 2023. 思维树：使用大型语言模型进行深思熟虑的问题解决。*arXiv 预印本 arXiv:2305.10601*（2023年）。
- en: 'Yao et al. (2022b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R Narasimhan, and Yuan Cao. 2022b. ReAct: Synergizing Reasoning and Acting
    in Language Models. In *The Eleventh International Conference on Learning Representations*.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 和 Narasimhan（2022b）Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R Narasimhan 和 Yuan Cao. 2022b. ReAct：在语言模型中协同推理与行动。在*第十一届国际学习表征会议*。
- en: 'Yu et al. (2023) Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, Wei
    Ye, Shikun Zhang, and Jiang Bian. 2023. MusicAgent: An AI Agent for Music Understanding
    and Generation with Large Language Models. arXiv:2310.11954 [cs.CL]'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu 等（2023）Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, Wei Ye, Shikun
    Zhang 和 Jiang Bian. 2023. MusicAgent：一个用于音乐理解和生成的 AI 智能体，使用大型语言模型。arXiv:2310.11954
    [cs.CL]
- en: 'Yuan et al. (2022) Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito.
    2022. Wordcraft: story writing with large language models. In *27th International
    Conference on Intelligent User Interfaces*. 841–852.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan 等（2022）Ann Yuan, Andy Coenen, Emily Reif 和 Daphne Ippolito. 2022. Wordcraft：使用大型语言模型编写故事。在*第27届国际智能用户界面会议*。841–852。
- en: 'Zaheer et al. (2020) Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua
    Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang,
    Li Yang, et al. 2020. Big bird: Transformers for longer sequences. *Advances in
    neural information processing systems* 33 (2020), 17283–17297.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zaheer 等（2020）Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie,
    Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang
    等人. 2020. Big bird：用于更长序列的变压器。*神经信息处理系统进展* 33（2020年），17283–17297。
- en: 'Zhan and Zhang (2023) Zhuosheng Zhan and Aston Zhang. 2023. You Only Look at
    Screens: Multimodal Chain-of-Action Agents. *arXiv preprint arXiv:2309.11436*
    (2023).'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhan 和 Zhang（2023）Zhuosheng Zhan 和 Aston Zhang. 2023. 你只看屏幕：多模态链式动作智能体。*arXiv
    预印本 arXiv:2309.11436*（2023年）。
- en: 'Zhang et al. (2023) Kechi Zhang, Ge Li, Jia Li, Zhuo Li, and Zhi Jin. 2023.
    ToolCoder: Teach Code Generation Models to use APIs with search tools. *arXiv
    preprint arXiv:2305.04032* (2023).'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等（2023）Kechi Zhang, Ge Li, Jia Li, Zhuo Li 和 Zhi Jin. 2023. ToolCoder：教代码生成模型使用带搜索工具的
    API。*arXiv 预印本 arXiv:2305.04032*（2023年）。
- en: 'Zhao et al. (2023) Kang Zhao, Wei Liu, Jian Luan, Minglei Gao, Li Qian, Hanlin
    Teng, and Bin Wang. 2023. UniMC: A Unified Framework for Long-Term Memory Conversation
    via Relevance Representation Learning. *arXiv preprint arXiv:2306.10543* (2023).'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等（2023）Kang Zhao, Wei Liu, Jian Luan, Minglei Gao, Li Qian, Hanlin Teng
    和 Bin Wang. 2023. UniMC：一个用于长期记忆对话的统一框架，通过相关性表示学习。*arXiv 预印本 arXiv:2306.10543*（2023年）。
- en: 'Zhong et al. (2023) Wanjun Zhong, Lianghong Guo, Qiqi Gao, and Yanlin Wang.
    2023. MemoryBank: Enhancing Large Language Models with Long-Term Memory. *arXiv
    preprint arXiv:2305.10250* (2023).'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong 等（2023）Wanjun Zhong, Lianghong Guo, Qiqi Gao 和 Yanlin Wang. 2023. MemoryBank：通过长期记忆增强大型语言模型。*arXiv
    预印本 arXiv:2305.10250*（2023年）。
- en: 'Zhou et al. (2022) Shuyan Zhou, Uri Alon, Frank F Xu, Zhengbao Jiang, and Graham
    Neubig. 2022. Docprompting: Generating code by retrieving the docs. In *The Eleventh
    International Conference on Learning Representations*.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等（2022）Shuyan Zhou, Uri Alon, Frank F Xu, Zhengbao Jiang 和 Graham Neubig.
    2022. Docprompting：通过检索文档生成代码。在*第十一届国际学习表征会议*。
- en: 'Zhou et al. (2023) Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong
    Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding
    Zhu, Jiyu Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui, and Mrinmaya
    Sachan. 2023. Agents: An Open-source Framework for Autonomous Language Agents.
    arXiv:2309.07870 [cs.CL]'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等（2023）Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan
    Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu
    Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui 和 Mrinmaya Sachan. 2023.
    智能体：一个开源框架用于自主语言智能体。arXiv:2309.07870 [cs.CL]
- en: 'Zhu et al. (2023) Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su,
    Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. 2023. Ghost in
    the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language
    Models with Text-based Knowledge and Memory. *arXiv preprint arXiv:2305.17144*
    (2023).'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2023）Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu
    Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang 等人。2023年。《Minecraft中的幽灵：通过大规模语言模型与基于文本的知识和记忆，在开放世界环境中实现普适型智能体》。*arXiv预印本
    arXiv:2305.17144*（2023年）。
- en: Zou et al. (2023) Andy Zou, Zifan Wang, J. Zico Kolter, and Matt Fredrikson.
    2023. Universal and Transferable Adversarial Attacks on Aligned Language Models.
    arXiv:2307.15043 [cs.CL]
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等人（2023）Andy Zou, Zifan Wang, J. Zico Kolter 和 Matt Fredrikson。2023年。《针对对齐语言模型的通用和可转移对抗性攻击》。arXiv:2307.15043
    [cs.CL]
