- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2025-01-11 12:26:13'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ—¥æœŸ: 2025-01-11 12:26:13'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Richelieu: åŸºäºè‡ªæˆ‘è¿›åŒ–çš„å¤§è¯­è¨€æ¨¡å‹ä»£ç†ç”¨äºäººå·¥æ™ºèƒ½å¤–äº¤'
- en: æ¥æºï¼š[https://arxiv.org/html/2407.06813/](https://arxiv.org/html/2407.06813/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://arxiv.org/html/2407.06813/](https://arxiv.org/html/2407.06813/)
- en: Zhenyu Guan ^($\diamondsuit$) Xiangyu Kong^($\clubsuit\dagger$ğŸ–‚) Fangwei Zhong^($\spadesuit$$\dagger$ğŸ–‚)
    Yizhou Wang^($\heartsuit$$\diamondsuit$)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å…³æŒ¯å®‡ ^($\diamondsuit$) å­”ç¥¥å®‡^($\clubsuit\dagger$ğŸ–‚) é¾æ–¹ä¼Ÿ^($\spadesuit$$\dagger$ğŸ–‚)
    ç‹ä¸€æ´²^($\heartsuit$$\diamondsuit$)
- en: ^($\diamondsuit$) Institute for Artificial Intelligence Peking University Beijing
    China
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ^($\diamondsuit$) åŒ—äº¬å¤§å­¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€ åŒ—äº¬ ä¸­å›½
- en: ^($\clubsuit$) Computer School Beijing Information Science & Technology University
    Beijing China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ^($\clubsuit$) åŒ—äº¬ä¿¡æ¯ç§‘æŠ€å¤§å­¦è®¡ç®—æœºå­¦é™¢ åŒ—äº¬ ä¸­å›½
- en: ^($\spadesuit$) School of Artificial Intelligence Beijing Normal University
    Beijing China
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ^($\spadesuit$) åŒ—äº¬å¸ˆèŒƒå¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢ åŒ—äº¬ ä¸­å›½
- en: ^($\heartsuit$) Center on Frontiers of Computing Studies School of Computer
    Science Natâ€™l Eng. Research Center of Visual Technology State Key Lab of General
    Artificial Intelligence Peking University Beijing China
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ^($\heartsuit$) åŒ—äº¬å¤§å­¦è®¡ç®—æœºç§‘å­¦å­¦é™¢ å‰æ²¿è®¡ç®—ç ”ç©¶ä¸­å¿ƒ å›½å®¶å·¥ç¨‹è§†è§‰æŠ€æœ¯ç ”ç©¶ä¸­å¿ƒ å›½å®¶äººå·¥æ™ºèƒ½åŸºç¡€æŠ€æœ¯é‡ç‚¹å®éªŒå®¤ åŒ—äº¬ ä¸­å›½
- en: ^($\dagger$) State Key Laboratory of General Artificial Intelligence BIGAI Beijing
    China
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ^($\dagger$) åŒ—äº¬å¤§å­¦å›½å®¶äººå·¥æ™ºèƒ½åŸºç¡€æŠ€æœ¯é‡ç‚¹å®éªŒå®¤ BIGAI åŒ—äº¬ ä¸­å›½
- en: 'ğŸ–‚Corresponding authors: xykong@bistu.edu.cn fangweizhong@bnu.edu.cn'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ–‚é€šè®¯ä½œè€…: xykong@bistu.edu.cn fangweizhong@bnu.edu.cn'
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: 'Diplomacy is one of the most sophisticated activities in human society, involving
    complex interactions among multiple parties that require skills in social reasoning,
    negotiation, and long-term strategic planning. Previous AI agents have demonstrated
    their ability to handle multi-step games and large action spaces in multi-agent
    tasks. However, diplomacy involves a staggering magnitude of decision spaces,
    especially considering the negotiation stage required. While recent agents based
    on large language models (LLMs) have shown potential in various applications,
    they still struggle with extended planning periods in complex multi-agent settings.
    Leveraging recent technologies for LLM-based agents, we aim to explore AIâ€™s potential
    to create a human-like agent capable of executing comprehensive multi-agent missions
    by integrating three fundamental capabilities: 1) strategic planning with memory
    and reflection; 2) goal-oriented negotiation with social reasoning; and 3) augmenting
    memory through self-play games for self-evolution without human in the loop.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–äº¤æ˜¯äººç±»ç¤¾ä¼šä¸­æœ€å¤æ‚çš„æ´»åŠ¨ä¹‹ä¸€ï¼Œæ¶‰åŠå¤šä¸ªæ–¹ä¹‹é—´çš„å¤æ‚äº’åŠ¨ï¼Œéœ€è¦å…·å¤‡ç¤¾äº¤æ¨ç†ã€è°ˆåˆ¤å’Œé•¿æœŸæˆ˜ç•¥è§„åˆ’ç­‰æŠ€èƒ½ã€‚ä»¥å¾€çš„äººå·¥æ™ºèƒ½ä»£ç†å·²ç»å±•ç¤ºäº†å…¶åœ¨å¤šæ­¥éª¤æ¸¸æˆå’Œå¤§å‹è¡ŒåŠ¨ç©ºé—´ä¸­çš„å¤„ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤šä»£ç†ä»»åŠ¡ä¸­ã€‚ç„¶è€Œï¼Œå¤–äº¤æ¶‰åŠå·¨å¤§çš„å†³ç­–ç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨è°ˆåˆ¤é˜¶æ®µçš„éœ€æ±‚ã€‚å°½ç®¡è¿‘æœŸåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å¤šç§åº”ç”¨ä¸­è¡¨ç°å‡ºäº†æ½œåŠ›ï¼Œä½†å®ƒä»¬åœ¨å¤æ‚çš„å¤šä»£ç†ç¯å¢ƒä¸­ä»ç„¶éš¾ä»¥åº”å¯¹é•¿æ—¶é—´çš„è§„åˆ’æœŸã€‚é€šè¿‡å€ŸåŠ©æœ€æ–°çš„å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯ï¼Œæˆ‘ä»¬æ—¨åœ¨æ¢ç´¢äººå·¥æ™ºèƒ½çš„æ½œåŠ›ï¼Œåˆ›å»ºä¸€ä¸ªç±»ä¼¼äººç±»çš„ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡æ•´åˆä¸‰å¤§åŸºæœ¬èƒ½åŠ›æ‰§è¡Œå…¨é¢çš„å¤šä»£ç†ä»»åŠ¡ï¼š1)
    å…·æœ‰è®°å¿†å’Œåæ€çš„æˆ˜ç•¥è§„åˆ’ï¼›2) å…·æœ‰ç¤¾äº¤æ¨ç†çš„ç›®æ ‡å¯¼å‘è°ˆåˆ¤ï¼›ä»¥åŠ 3) é€šè¿‡è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆå¢å¼ºè®°å¿†ï¼Œè¿›è¡Œè‡ªæˆ‘è¿›åŒ–ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 å¼•è¨€
- en: Diplomacy, a central element of international relations, is an intricate and
    multifaceted activity that lies at the heart of human societyâ€™s most complex interactions.
    It requires various skills such as social reasoning, negotiation, and long-term
    planning to manage relationships and alliances among multiple parties. Mirroring
    this complexity, the Diplomacy gameÂ Wikipedia ([2024](https://arxiv.org/html/2407.06813v4#bib.bib60))
    involves seven players to control European powers, presenting a challenging strategic
    landscape that demands advanced negotiation and strategic planning to succeed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–äº¤æ˜¯å›½é™…å…³ç³»çš„æ ¸å¿ƒå…ƒç´ ï¼Œæ˜¯ä¸€é¡¹å¤æ‚ä¸”å¤šé¢çš„æ´»åŠ¨ï¼Œå¤„äºäººç±»ç¤¾ä¼šæœ€å¤æ‚äº’åŠ¨çš„æ ¸å¿ƒã€‚å®ƒéœ€è¦å„ç§æŠ€èƒ½ï¼Œå¦‚ç¤¾äº¤æ¨ç†ã€è°ˆåˆ¤å’Œé•¿æœŸè§„åˆ’ï¼Œä»¥ç®¡ç†å¤šä¸ªæ–¹ä¹‹é—´çš„å…³ç³»å’Œè”ç›Ÿã€‚ä¸è¿™ç§å¤æ‚æ€§ç›¸ä¼¼ï¼Œå¤–äº¤æ¸¸æˆWikipediaï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib60)ï¼‰åŒ…å«ä¸ƒåç©å®¶ï¼Œæ§åˆ¶æ¬§æ´²å¤§å›½ï¼Œå‘ˆç°å‡ºä¸€ä¸ªå……æ»¡æŒ‘æˆ˜çš„æˆ˜ç•¥ç¯å¢ƒï¼Œéœ€è¦é«˜çº§çš„è°ˆåˆ¤å’Œæˆ˜ç•¥è§„åˆ’æ‰èƒ½æˆåŠŸã€‚
- en: 'The AI community has shown an increasing interest in the deployment of AI agents
    to master such gamesÂ Shoker etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib46));
    Konya etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib27)); KramÃ¡r etÂ al.
    ([2022](https://arxiv.org/html/2407.06813v4#bib.bib30)); DuÃ©Ã±ez-GuzmÃ¡n etÂ al.
    ([2023](https://arxiv.org/html/2407.06813v4#bib.bib16)); Mukobi etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib37));
    KovaÄ etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib29)). The recent
    breakthroughÂ Bakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7))
    has turned into press diplomacy, which allows communication between players. However,
    the previous methodsÂ Bakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7))
    heavily rely on domain-specific human data, leading to its poor generalization
    to other scenarios/ applications. The question then arises: Can we build an AI
    agent that excels in the art of diplomacy without relying on domain-specific human
    data?'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: AIç•Œå¯¹éƒ¨ç½²AIä»£ç†ä»¥æŒæ¡æ­¤ç±»åšå¼ˆè¡¨ç°å‡ºäº†è¶Šæ¥è¶Šæµ“åšçš„å…´è¶£Â Shokerç­‰äºº ([2023](https://arxiv.org/html/2407.06813v4#bib.bib46));
    Konyaç­‰äºº ([2023](https://arxiv.org/html/2407.06813v4#bib.bib27)); KramÃ¡rç­‰äºº ([2022](https://arxiv.org/html/2407.06813v4#bib.bib30));
    DuÃ©Ã±ez-GuzmÃ¡nç­‰äºº ([2023](https://arxiv.org/html/2407.06813v4#bib.bib16)); Mukobiç­‰äºº
    ([2023](https://arxiv.org/html/2407.06813v4#bib.bib37)); KovaÄç­‰äºº ([2023](https://arxiv.org/html/2407.06813v4#bib.bib29))ã€‚æœ€è¿‘çš„çªç ´Â Bakhtinç­‰äºº
    ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7)) å·²ç»è½¬å‘æ–°é—»å¤–äº¤ï¼Œè¿™å…è®¸ç©å®¶ä¹‹é—´çš„æ²Ÿé€šã€‚ç„¶è€Œï¼Œä¹‹å‰çš„æ–¹æ³•Â Bakhtinç­‰äºº
    ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7)) è¿‡åº¦ä¾èµ–äºç‰¹å®šé¢†åŸŸçš„äººç±»æ•°æ®ï¼Œå¯¼è‡´å…¶åœ¨å…¶ä»–åœºæ™¯/åº”ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚ç”±æ­¤äº§ç”Ÿçš„é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬èƒ½å¦æ„å»ºä¸€ä¸ªæ“…é•¿å¤–äº¤è‰ºæœ¯çš„AIä»£ç†ï¼Œè€Œä¸ä¾èµ–äºç‰¹å®šé¢†åŸŸçš„äººç±»æ•°æ®ï¼Ÿ
- en: Recently, agents based on the Large Language Model(LLM) have emerged as a promising
    development for AI agents. The previous applications on personal assistantsÂ Li
    etÂ al. ([2024b](https://arxiv.org/html/2407.06813v4#bib.bib33)), roboticsÂ Cheng
    etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib11)); Yang etÂ al. ([2023c](https://arxiv.org/html/2407.06813v4#bib.bib67)),
    and video gamesÂ Wan etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib49))
    have shown the surprising ability of LLM-based agents in communication and planning,
    benefiting from the emergent ability of common sense reasoning, in-context/ few-shot
    learning, and sophisticated natural language processing on LLMs. However, diplomacy
    presents a unique set of challenges. It not only requires planning long-horizon
    strategicÂ Qi etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib41)) and
    communicating with natural language, but also reasoning and adopting the complex
    social dynamics with partial observations, including gaining trust and reputation,
    building rapport, detecting deception, and assessing the reliability of other
    players.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†ä½œä¸ºAIä»£ç†çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„å¼€å‘æ–¹å‘å‡ºç°äº†ã€‚ä¹‹å‰åœ¨ä¸ªäººåŠ©æ‰‹Â Liç­‰äºº ([2024b](https://arxiv.org/html/2407.06813v4#bib.bib33))ã€æœºå™¨äººå­¦Â Chengç­‰äºº
    ([2024](https://arxiv.org/html/2407.06813v4#bib.bib11)); Yangç­‰äºº ([2023c](https://arxiv.org/html/2407.06813v4#bib.bib67))
    å’Œè§†é¢‘æ¸¸æˆÂ Wanç­‰äºº ([2024](https://arxiv.org/html/2407.06813v4#bib.bib49)) ä¸Šçš„åº”ç”¨å±•ç¤ºäº†åŸºäºLLMçš„ä»£ç†åœ¨æ²Ÿé€šå’Œè§„åˆ’æ–¹é¢çš„æƒŠäººèƒ½åŠ›ï¼Œè¿™å¾—ç›ŠäºLLMçš„å¸¸è¯†æ¨ç†ã€ä¸Šä¸‹æ–‡/å°‘é‡å­¦ä¹ å’Œå¤æ‚è‡ªç„¶è¯­è¨€å¤„ç†çš„çªç°èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå¤–äº¤å‘ˆç°äº†ä¸€ç»„ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚å®ƒä¸ä»…è¦æ±‚è¿›è¡Œé•¿æœŸæˆ˜ç•¥è§„åˆ’Â Qiç­‰äºº
    ([2024](https://arxiv.org/html/2407.06813v4#bib.bib41)) å¹¶ä½¿ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œæ²Ÿé€šï¼Œè¿˜éœ€è¦æ¨ç†å¹¶é‡‡ç”¨å¤æ‚çš„ç¤¾ä¼šåŠ¨æ€ï¼ŒåŸºäºéƒ¨åˆ†è§‚å¯Ÿåšå‡ºåˆ¤æ–­ï¼ŒåŒ…æ‹¬èµ¢å¾—ä¿¡ä»»å’Œå£°èª‰ã€å»ºç«‹å…³ç³»ã€æ£€æµ‹æ¬ºéª—è¡Œä¸ºå’Œè¯„ä¼°å…¶ä»–ç©å®¶çš„å¯é æ€§ã€‚
- en: In this work, we aim to make the first attempt to explore LLMsâ€™ potential to
    develop a human-like AI diplomacy agent. We name the agent Richelieu in memorizing
    a pivotal figure in European history who had enduring impacts on French politics,
    foreign affairs, and state building. To achieve this goal, we have identified
    four core and essential capabilities that are crucial for building an LLM-based
    societal agent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨é¦–æ¬¡å°è¯•æ¢ç´¢å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å‘å±•ç±»äººAIå¤–äº¤ä»£ç†æ–¹é¢çš„æ½œåŠ›ã€‚æˆ‘ä»¬å°†è¯¥ä»£ç†å‘½åä¸ºRichelieuï¼Œä»¥çºªå¿µä¸€ä½åœ¨æ¬§æ´²å†å²ä¸Šå…·æœ‰é‡è¦å½±å“çš„äººç‰©ï¼Œä»–å¯¹æ³•å›½æ”¿æ²»ã€å¤–äº¤äº‹åŠ¡å’Œå›½å®¶å»ºè®¾äº§ç”Ÿäº†æŒä¹…çš„å½±å“ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å·²ç»ç¡®å®šäº†å››ä¸ªæ„å»ºåŸºäºLLMçš„ç¤¾ä¼šä»£ç†è‡³å…³é‡è¦çš„æ ¸å¿ƒèƒ½åŠ›ã€‚
- en: '1.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Social reasoning. This is the basic function for a social agent to interact
    with others, particularly for adapting to the dynamic changes in the nationâ€™s
    intentions and relationships.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¤¾ä¼šæ¨ç†ã€‚è¿™æ˜¯ç¤¾ä¼šä»£ç†ä¸ä»–äººäº’åŠ¨çš„åŸºæœ¬åŠŸèƒ½ï¼Œç‰¹åˆ«æ˜¯é€‚åº”å›½å®¶æ„å›¾å’Œå…³ç³»çš„åŠ¨æ€å˜åŒ–ã€‚
- en: '2.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Balance long- and short-term planning. Diplomacy necessitates a careful balance
    between short-term tactics and long-term strategies. An effective AI agent must
    assess the immediate consequences of its actions alongside their potential long-term
    impacts.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¹³è¡¡çŸ­æœŸå’Œé•¿æœŸè§„åˆ’ã€‚å¤–äº¤éœ€è¦åœ¨çŸ­æœŸæˆ˜æœ¯å’Œé•¿æœŸæˆ˜ç•¥ä¹‹é—´ä¿æŒç²¾ç¡®å¹³è¡¡ã€‚ä¸€ä½æœ‰æ•ˆçš„ AI ä»£ç†å¿…é¡»è¯„ä¼°å…¶è¡ŒåŠ¨çš„å³æ—¶åæœä»¥åŠå¯èƒ½çš„é•¿æœŸå½±å“ã€‚
- en: '3.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Memory management. A robust memory system is a critical component of learning
    and improvement. The AI agent must be able to recall and integrate information
    from past negotiations and actions to inform its current and future decision-making
    processes. This endows the agent with the ability to evolve.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å†…å­˜ç®¡ç†ã€‚ä¸€ä¸ªå¼ºå¤§çš„å†…å­˜ç³»ç»Ÿæ˜¯å­¦ä¹ å’Œæå‡çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚AI ä»£ç†å¿…é¡»èƒ½å¤Ÿå›å¿†å’Œæ•´åˆè¿‡å»è°ˆåˆ¤å’Œè¡ŒåŠ¨ä¸­çš„ä¿¡æ¯ï¼Œä»¥æŒ‡å¯¼å…¶å½“å‰å’Œæœªæ¥çš„å†³ç­–è¿‡ç¨‹ã€‚è¿™èµ‹äºˆäº†ä»£ç†è¿›åŒ–çš„èƒ½åŠ›ã€‚
- en: '4.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Self-reflection. An AI agent capable of profound reflection can analyze its
    own decisions, learn from its memory experience, and adapt its strategies accordingly.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è‡ªæˆ‘åæ€ã€‚ä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œæ·±åˆ»åæ€çš„ AI ä»£ç†èƒ½å¤Ÿåˆ†æè‡ªå·±çš„å†³ç­–ï¼Œä»è®°å¿†ä¸­æ±²å–ç»éªŒï¼Œå¹¶ç›¸åº”åœ°è°ƒæ•´ç­–ç•¥ã€‚
- en: By integrating these four capabilities, the agent can operate at the highest
    level of diplomatic sophistication, outperforming the state-of-the-art AI diplomatsÂ Bakhtin
    etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ•´åˆè¿™å››é¡¹èƒ½åŠ›ï¼Œä»£ç†å¯ä»¥åœ¨æœ€é«˜æ°´å¹³çš„å¤–äº¤å¤æ‚æ€§ä¸Šæ“ä½œï¼Œè¶…è¶Šæœ€å…ˆè¿›çš„ AI å¤–äº¤ä»£ç† Bakhtin ç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib7)ï¼‰ã€‚
- en: 'Our contributions can be summarized in three-fold: 1) We introduced a new paradigm
    for building AI diplomacy agents, compared to previous work (Fig.Â [1](https://arxiv.org/html/2407.06813v4#S1.F1
    "Figure 1 â€£ 1 Introduction â€£ Richelieu: Self-Evolving LLM-Based Agents for AI
    Diplomacy")). The agent can self-evolve by generating experience via self-play
    games, without any task-specific human data. 2) We demonstrate the superior performance
    of our agent playing against the SOTA method, e.g., CiceroÂ Bakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7)),
    that relies on a large-scale human demonstration for training. 3) We further analyze
    the effectiveness of each module in our agent and the generalization of our agent
    in adopting different LLMs, such as [GPT4.0](https://openai.com/index/gpt-4/)
    and [Llama 3](https://llama.meta.com/llama3).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„è´¡çŒ®å¯ä»¥æ€»ç»“ä¸ºä¸‰ç‚¹ï¼š1ï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ„å»º AI å¤–äº¤ä»£ç†çš„èŒƒå¼ï¼Œä¸ä»¥å‰çš„å·¥ä½œç›¸æ¯”ï¼ˆå›¾[1](https://arxiv.org/html/2407.06813v4#S1.F1
    "å›¾ 1 â€£ 1 å¼•è¨€ â€£ Richelieuï¼šåŸºäºè‡ªæˆ‘è¿›åŒ–çš„ LLM å¤–äº¤ AI ä»£ç†")ï¼‰ï¼Œè¯¥ä»£ç†èƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘å¯¹å¼ˆç”Ÿæˆç»éªŒè¿›è¡Œè‡ªæˆ‘è¿›åŒ–ï¼Œæ— éœ€ä»»ä½•ç‰¹å®šä»»åŠ¡çš„äººç±»æ•°æ®ã€‚2ï¼‰æˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„ä»£ç†åœ¨ä¸æœ€å…ˆè¿›æ–¹æ³•ï¼ˆä¾‹å¦‚
    Cicero Bakhtin ç­‰äººï¼Œ[2022](https://arxiv.org/html/2407.06813v4#bib.bib7)ï¼‰å¯¹æŠ—ä¸­çš„ä¼˜è¶Šè¡¨ç°ï¼Œè¯¥æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡äººç±»ç¤ºèŒƒè¿›è¡Œè®­ç»ƒã€‚3ï¼‰æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æäº†æˆ‘ä»¬ä»£ç†çš„æ¯ä¸ªæ¨¡å—çš„æœ‰æ•ˆæ€§ï¼Œä»¥åŠæˆ‘ä»¬çš„ä»£ç†åœ¨é‡‡ç”¨ä¸åŒ
    LLM æ—¶çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¾‹å¦‚[GPT4.0](https://openai.com/index/gpt-4/)å’Œ[Llama 3](https://llama.meta.com/llama3)ã€‚
- en: '![Refer to caption](img/f15e9c64ae21550bf76cbef1a39d84b2.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/f15e9c64ae21550bf76cbef1a39d84b2.png)'
- en: 'Figure 1: A new paradigm for building AI Diplomacy agent.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1ï¼šæ„å»º AI å¤–äº¤ä»£ç†çš„æ–°èŒƒå¼ã€‚
- en: 2 Related work
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 ç›¸å…³å·¥ä½œ
- en: AI Diplomacy. The game involves seven players controlling different powers in
    Europe. In each turn, players can negotiate for cooperation before making moves
    to take as many supply centers as they can. Apparently, this challenging strategy
    task requires both complex negotiation skills and superior planning capability
    for player agents to achieve final victory. So far, most previous works on this
    task remain focused on the planning strategies (a.k.a. No-Press Diplomacy where
    no communication channels are allowed). The setting remains challenging considering
    its enormous action space of $10^{2}1$ to $10^{6}4$ per turn (compared with Chess,
    which has much fewer than 100 actions per turn). No wonder existing efforts rely
    on human data to play the game. Among the methods, one typical research is DipNet
    Paquette etÂ al. ([2019](https://arxiv.org/html/2407.06813v4#bib.bib40)) which
    uses supervised and reinforcement learning. Based on DipNet, BRPI Anthony etÂ al.
    ([2020](https://arxiv.org/html/2407.06813v4#bib.bib3)), SearchBot Gray etÂ al.
    ([2020](https://arxiv.org/html/2407.06813v4#bib.bib19)), DORA Bakhtin etÂ al. ([2021](https://arxiv.org/html/2407.06813v4#bib.bib6)),
    and KL-Regularized search (Diplodocus) Jacob etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib25))
    were conducted. Until very recently, research has also emerged for the full-setting
    of Diplomacy, or Press Diplomacy where players are allowed to communicate with
    each other before making their moves in each turn. Such studies DeÂ Jonge and Sierra
    ([2017](https://arxiv.org/html/2407.06813v4#bib.bib14))Bakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7))Jaidka
    etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib26))KramÃ¡r etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib30))
    mainly benefit from the recent thriving language models. Specifically, notable
    advancements include policy iteration methods from DeepMind and Facebook AI Researchâ€™s
    equilibrium search agent Jaidka etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib26)).
    However, Deepmind proposes to learn negotiation agents based on predefined contracts/protocols
    KramÃ¡r etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib30)). And Meta
    AIâ€™s work, instead of one unified architecture, Cicero Bakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7))
    integrates a language model for negotiation and an RL model for planning respectively.
    Such separately trained models make it inconvenient for agentsâ€™ continual evolution.
    Whatâ€™s more, like no-press methods, these approaches heavily rely on human player
    data for agent training. Unlike these approaches, this paper delves into solving
    the negotiation and planning in one single self-evolving LLM-based agent model,
    without any pre-collected human expert training data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: AI å¤–äº¤ã€‚è¿™æ¬¾æ¸¸æˆæ¶‰åŠä¸ƒåç©å®¶æ§åˆ¶æ¬§æ´²ä¸åŒçš„å¼ºå›½ã€‚åœ¨æ¯ä¸€å›åˆä¸­ï¼Œç©å®¶å¯ä»¥åœ¨è¿›è¡Œç§»åŠ¨ä¹‹å‰è¿›è¡Œåˆä½œè°ˆåˆ¤ï¼Œäº‰å–å°½å¯èƒ½å¤šçš„è¡¥ç»™ä¸­å¿ƒã€‚æ˜¾ç„¶ï¼Œè¿™é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ˜ç•¥ä»»åŠ¡éœ€è¦ç©å®¶å…·å¤‡å¤æ‚çš„è°ˆåˆ¤æŠ€å·§å’Œå‡ºè‰²çš„è§„åˆ’èƒ½åŠ›ï¼Œæ‰èƒ½æœ€ç»ˆè·å¾—èƒœåˆ©ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œå¤§å¤šæ•°å…³äºè¿™ä¸€ä»»åŠ¡çš„ç ”ç©¶ä»ç„¶é›†ä¸­åœ¨è§„åˆ’ç­–ç•¥ä¸Šï¼ˆå³æ— æ²Ÿé€šå¤–äº¤ï¼Œåœ¨è¿™ç§æ¨¡å¼ä¸‹ä¸å…è®¸ä»»ä½•æ²Ÿé€šæ¸ é“ï¼‰ã€‚è€ƒè™‘åˆ°å…¶æ¯å›åˆçš„åºå¤§è¡ŒåŠ¨ç©ºé—´ï¼Œä»$10^{2}1$åˆ°$10^{6}4$ï¼ˆç›¸æ¯”äºè±¡æ£‹æ¯å›åˆçš„è¡ŒåŠ¨æ•°é‡å°‘äº100æ¬¡ï¼‰ï¼Œè¿™ä¸ªè®¾ç½®ä¾ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éš¾æ€ªç°æœ‰çš„ç ”ç©¶å·¥ä½œä¾èµ–äºäººç±»æ•°æ®æ¥è¿›è¡Œæ¸¸æˆã€‚ä¼—å¤šæ–¹æ³•ä¸­ï¼Œä¸€é¡¹å…¸å‹çš„ç ”ç©¶æ˜¯DipNet
    Paquetteç­‰äººï¼ˆ[2019](https://arxiv.org/html/2407.06813v4#bib.bib40)ï¼‰ä½¿ç”¨äº†ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚åŸºäºDipNetï¼ŒBRPI
    Anthonyç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib3)ï¼‰ã€SearchBot Grayç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib19)ï¼‰ã€DORA
    Bakhtinç­‰äººï¼ˆ[2021](https://arxiv.org/html/2407.06813v4#bib.bib6)ï¼‰å’ŒKL-Regularizedæœç´¢ï¼ˆDiplodocusï¼‰Jacobç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib25)ï¼‰ä¹Ÿå¼€å±•äº†ç›¸å…³ç ”ç©¶ã€‚ç›´åˆ°æœ€è¿‘ï¼Œå…³äºå¤–äº¤å…¨å±€è®¾ç½®æˆ–æœ‰æ²Ÿé€šå¤–äº¤ï¼ˆPress
    Diplomacyï¼‰çš„ç ”ç©¶å¼€å§‹å‡ºç°ï¼Œåœ¨è¿™ç§è®¾ç½®ä¸‹ï¼Œç©å®¶åœ¨æ¯å›åˆå¼€å§‹å‰å¯ä»¥äº’ç›¸æ²Ÿé€šã€‚è¿™ç±»ç ”ç©¶æœ‰DeÂ Jongeå’ŒSierraï¼ˆ[2017](https://arxiv.org/html/2407.06813v4#bib.bib14)ï¼‰ã€Bakhtinç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib7)ï¼‰ã€Jaidkaç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib26)ï¼‰ä»¥åŠKramÃ¡rç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib30)ï¼‰ï¼Œä»–ä»¬ä¸»è¦å¾—ç›Šäºè¿‘å¹´æ¥å¿«é€Ÿå‘å±•çš„è¯­è¨€æ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œæ˜¾è‘—çš„è¿›å±•åŒ…æ‹¬æ¥è‡ªDeepMindå’ŒFacebook
    AI Researchçš„æ”¿ç­–è¿­ä»£æ–¹æ³•ä»¥åŠJaidkaç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib26)ï¼‰çš„å¹³è¡¡æœç´¢ä»£ç†ã€‚ç„¶è€Œï¼ŒDeepMindæå‡ºåŸºäºé¢„å®šä¹‰åˆåŒ/åè®®å­¦ä¹ è°ˆåˆ¤ä»£ç†
    KramÃ¡rç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib30)ï¼‰ã€‚Meta AIçš„å·¥ä½œåˆ™ä¸æ˜¯é‡‡ç”¨ç»Ÿä¸€çš„æ¶æ„ï¼Œè€Œæ˜¯åˆ†åˆ«é›†æˆäº†ä¸€ä¸ªç”¨äºè°ˆåˆ¤çš„è¯­è¨€æ¨¡å‹å’Œä¸€ä¸ªç”¨äºè§„åˆ’çš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹ã€‚è¿™æ ·çš„åˆ†å¼€è®­ç»ƒçš„æ¨¡å‹ä½¿å¾—ä»£ç†çš„æŒç»­è¿›åŒ–å˜å¾—ä¸ä¾¿ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œåƒæ— æ²Ÿé€šæ–¹æ³•ä¸€æ ·ï¼Œè¿™äº›æ–¹æ³•åœ¨ä»£ç†è®­ç»ƒä¸­ä¸¥é‡ä¾èµ–äºäººç±»ç©å®¶æ•°æ®ã€‚ä¸è¿™äº›æ–¹æ³•ä¸åŒï¼Œæœ¬æ–‡æ·±å…¥æ¢è®¨äº†å¦‚ä½•é€šè¿‡å•ä¸€çš„è‡ªæˆ‘è¿›åŒ–çš„åŸºäºLLMçš„ä»£ç†æ¨¡å‹æ¥è§£å†³è°ˆåˆ¤å’Œè§„åˆ’é—®é¢˜ï¼Œè€Œæ— éœ€ä»»ä½•é¢„å…ˆæ”¶é›†çš„äººç±»ä¸“å®¶è®­ç»ƒæ•°æ®ã€‚
- en: LLM-based Agents. With the emergence and growth of large language models (LLM),
    there is a growing trend in utilizing LLMs as fundamental controllers for autonomous
    agentsWang etÂ al. ([2024c](https://arxiv.org/html/2407.06813v4#bib.bib53)). One
    wide application genre is LLM-based answering engines, which merely cover the
    negotiation aspects of Diplomacy. Such systems include HuggingGPTÂ Shen etÂ al.
    ([2023](https://arxiv.org/html/2407.06813v4#bib.bib45)), GPT4ToolsÂ Yang etÂ al.
    ([2023b](https://arxiv.org/html/2407.06813v4#bib.bib66)) and ToTÂ Yao etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib68)),
    etc. They leverage LLMs to manage Al models, use tools, implement policy iteration,
    and enhance problem-solving across various tasks. Related work including AutoGPT,
    AgentGPT, BabyAGl Talebirad and Nadiri ([2023](https://arxiv.org/html/2407.06813v4#bib.bib48)),
    Toolformer Schick etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib44)),
    and Visual ChatGPT aim to improve LLM capabilities in task automation and tool
    usage. Reflexion, a framework that improves LLMs through linguistic feedback and
    episodic memory Zhang etÂ al. ([2024a](https://arxiv.org/html/2407.06813v4#bib.bib72)),
    facilitating better decision-making across diverse tasks is proposed. Besides
    Wang etÂ al. ([2024d](https://arxiv.org/html/2407.06813v4#bib.bib57))Wang etÂ al.
    ([2023a](https://arxiv.org/html/2407.06813v4#bib.bib51))Wang etÂ al. ([2023b](https://arxiv.org/html/2407.06813v4#bib.bib56))Zhu
    etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib79))Yan etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib64))
    apply LLM agents to the complex planning tasks in the well-known open-world game
    MinecraftFan etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib17)). Unlike
    these LLM-based agents which only focus on the negotiation/planning aspect, the
    proposed approach involves multiple self-evolving schemes to handle both of them
    simultaneously.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºLLMçš„ä»£ç†ã€‚éšç€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‡ºç°å’Œå‘å±•ï¼Œåˆ©ç”¨LLMä½œä¸ºè‡ªæ²»ä»£ç†çš„æ ¸å¿ƒæ§åˆ¶å™¨çš„è¶‹åŠ¿æ—¥ç›Šå¢é•¿Wangç­‰äººï¼ˆ[2024c](https://arxiv.org/html/2407.06813v4#bib.bib53)ï¼‰ã€‚å…¶ä¸­ä¸€ä¸ªå¹¿æ³›åº”ç”¨çš„é¢†åŸŸæ˜¯åŸºäºLLMçš„é—®ç­”å¼•æ“ï¼Œè¿™äº›å¼•æ“ä»…è¦†ç›–ã€Šå¤–äº¤ã€‹ä¸­çš„è°ˆåˆ¤æ–¹é¢ã€‚æ­¤ç±»ç³»ç»ŸåŒ…æ‹¬HuggingGPT
    Shenç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib45)ï¼‰ã€GPT4Tools Yangç­‰äººï¼ˆ[2023b](https://arxiv.org/html/2407.06813v4#bib.bib66)ï¼‰å’ŒToT
    Yaoç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib68)ï¼‰ç­‰ã€‚å®ƒä»¬åˆ©ç”¨LLMæ¥ç®¡ç†AIæ¨¡å‹ã€ä½¿ç”¨å·¥å…·ã€å®æ–½æ”¿ç­–è¿­ä»£ï¼Œå¹¶åœ¨å„ç±»ä»»åŠ¡ä¸­æå‡é—®é¢˜è§£å†³èƒ½åŠ›ã€‚ç›¸å…³å·¥ä½œåŒ…æ‹¬AutoGPTã€AgentGPTã€BabyAGI
    Talebiradå’ŒNadiriï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib48)ï¼‰ã€Toolformer
    Schickç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib44)ï¼‰å’ŒVisual ChatGPTï¼Œæ—¨åœ¨æå‡LLMåœ¨ä»»åŠ¡è‡ªåŠ¨åŒ–å’Œå·¥å…·ä½¿ç”¨æ–¹é¢çš„èƒ½åŠ›ã€‚Reflexionï¼Œä¸€ä¸ªé€šè¿‡è¯­è¨€åé¦ˆå’Œæƒ…èŠ‚è®°å¿†æ¥æ”¹è¿›LLMçš„æ¡†æ¶Zhangç­‰äººï¼ˆ[2024a](https://arxiv.org/html/2407.06813v4#bib.bib72)ï¼‰ï¼Œä¿ƒè¿›åœ¨å„ç§ä»»åŠ¡ä¸­åšå‡ºæ›´å¥½çš„å†³ç­–ä¹Ÿå·²è¢«æå‡ºã€‚é™¤äº†Wangç­‰äººï¼ˆ[2024d](https://arxiv.org/html/2407.06813v4#bib.bib57)ï¼‰Wangç­‰äººï¼ˆ[2023a](https://arxiv.org/html/2407.06813v4#bib.bib51)ï¼‰Wangç­‰äººï¼ˆ[2023b](https://arxiv.org/html/2407.06813v4#bib.bib56)ï¼‰Zhuç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib79)ï¼‰Yanç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib64)ï¼‰å°†LLMä»£ç†åº”ç”¨äºè‘—åçš„å¼€æ”¾ä¸–ç•Œæ¸¸æˆã€ŠMinecraftã€‹çš„å¤æ‚è§„åˆ’ä»»åŠ¡Fanç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib17)ï¼‰ã€‚ä¸è¿™äº›ä»…å…³æ³¨è°ˆåˆ¤/è§„åˆ’æ–¹é¢çš„åŸºäºLLMçš„ä»£ç†ä¸åŒï¼Œæ‰€æå‡ºçš„æ–¹æ³•æ¶‰åŠå¤šä¸ªè‡ªæˆ‘è¿›åŒ–æ–¹æ¡ˆï¼Œä»¥åŒæ—¶å¤„ç†è¿™ä¸¤è€…ã€‚
- en: 3 Problem Statement
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 é—®é¢˜é™ˆè¿°
- en: The Diplomacy game Wikipedia ([2024](https://arxiv.org/html/2407.06813v4#bib.bib60));
    Calhamer ([1974](https://arxiv.org/html/2407.06813v4#bib.bib9)) is set in pre-World
    War I Europe and involves each player (agent) representing one of the seven Great
    Powers of Europe, such as Germany, France, England, Italy, Austria-Hungary, Russia,
    and Turkey. Each player has a set of military units, including armies and fleets,
    which they can move and use to capture other supply centers. The ultimate goal
    for the agent is to control a majority of the total supply centers on the board
    by the end of the gameâ€™s Fall phase. Itâ€™s important to note that it is not won
    by eliminating other players or their units; it is won by controlling the requisite
    number of supply centers. This often involves forming and breaking alliances,
    negotiating, and sometimes betraying other players to achieve oneâ€™s own goals.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ã€Šå¤–äº¤ã€‹æ¸¸æˆç»´åŸºç™¾ç§‘ï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib60)ï¼‰ï¼›Calhamerï¼ˆ[1974](https://arxiv.org/html/2407.06813v4#bib.bib9)ï¼‰è®¾å®šåœ¨ç¬¬ä¸€æ¬¡ä¸–ç•Œå¤§æˆ˜å‰çš„æ¬§æ´²ï¼Œæ¯ä¸ªç©å®¶ï¼ˆä»£ç†ï¼‰ä»£è¡¨æ¬§æ´²çš„ä¸ƒå¤§å¼ºå›½ä¹‹ä¸€ï¼Œå¦‚å¾·å›½ã€æ³•å›½ã€è‹±å›½ã€æ„å¤§åˆ©ã€å¥¥åŒˆå¸å›½ã€ä¿„ç½—æ–¯å’ŒåœŸè€³å…¶ã€‚æ¯ä¸ªç©å®¶æ‹¥æœ‰ä¸€å¥—å†›äº‹å•ä½ï¼ŒåŒ…æ‹¬é™†å†›å’Œèˆ°é˜Ÿï¼Œä»–ä»¬å¯ä»¥ç§»åŠ¨å¹¶åˆ©ç”¨è¿™äº›å•ä½å é¢†å…¶ä»–è¡¥ç»™ä¸­å¿ƒã€‚ä»£ç†çš„æœ€ç»ˆç›®æ ‡æ˜¯åœ¨æ¸¸æˆçš„ç§‹å­£é˜¶æ®µç»“æŸæ—¶æ§åˆ¶æ¿ä¸Šå¤§å¤šæ•°çš„è¡¥ç»™ä¸­å¿ƒã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ¸¸æˆå¹¶ä¸æ˜¯é€šè¿‡æ¶ˆé™¤å…¶ä»–ç©å®¶æˆ–ä»–ä»¬çš„å•ä½æ¥è·èƒœï¼Œè€Œæ˜¯é€šè¿‡æ§åˆ¶æ‰€éœ€æ•°é‡çš„è¡¥ç»™ä¸­å¿ƒæ¥è·èƒœã€‚è¿™é€šå¸¸æ¶‰åŠå»ºç«‹å’Œç ´è£‚è”ç›Ÿã€è°ˆåˆ¤ï¼Œæœ‰æ—¶è¿˜éœ€è¦èƒŒå›å…¶ä»–ç©å®¶ä»¥å®ç°è‡ªå·±çš„ç›®æ ‡ã€‚
- en: In each turn, the agent $i$ gets the current state $s_{t}\in S$, the actions
    of other players from the previous turn $\vec{a}^{-i}_{t-1}$, and the messages
    $\vec{m}^{-i,i}_{t}$ from other players during this turnâ€™s negotiations. The state
    $s_{t}$ for the environment includes the ownership of each territory on the map
    by a particular country and where the armies of each country are located. Based
    on this information, the agent needs to engage in negotiations with other players,
    sending messages $\vec{m}^{i,-i}_{t}$ to chat with other players, and then take
    the actions $a^{i}_{t}$ in this turn. The possible actions an agent can take $a^{i}_{t}\in
    A$ are commands to the armies, such as moving into an adjacent territory, supporting
    another unit, or holding a position. Actions can also include diplomatic moves,
    such as proposing or withdrawing from an alliance, although these are less formalized
    in the game mechanics.Paquette etÂ al. ([2019](https://arxiv.org/html/2407.06813v4#bib.bib40));
    Hill ([2014](https://arxiv.org/html/2407.06813v4#bib.bib23))
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸€è½®ä¸­ï¼Œä»£ç†äºº$i$è·å–å½“å‰çŠ¶æ€$s_{t}\in S$ã€ä¸Šä¸€è½®å…¶ä»–ç©å®¶çš„è¡ŒåŠ¨$\vec{a}^{-i}_{t-1}$ï¼Œä»¥åŠæœ¬è½®å…¶ä»–ç©å®¶åœ¨è°ˆåˆ¤ä¸­çš„æ¶ˆæ¯$\vec{m}^{-i,i}_{t}$ã€‚ç¯å¢ƒçŠ¶æ€$s_{t}$åŒ…æ‹¬åœ°å›¾ä¸Šæ¯ä¸ªé¢†åœŸç”±å“ªä¸ªå›½å®¶æ‹¥æœ‰ï¼Œä»¥åŠæ¯ä¸ªå›½å®¶çš„å†›é˜Ÿä½ç½®ã€‚åŸºäºè¿™äº›ä¿¡æ¯ï¼Œä»£ç†äººéœ€è¦ä¸å…¶ä»–ç©å®¶è¿›è¡Œè°ˆåˆ¤ï¼Œå‘é€æ¶ˆæ¯$\vec{m}^{i,-i}_{t}$ä¸å…¶ä»–ç©å®¶äº¤æµï¼Œç„¶ååœ¨è¿™ä¸€è½®ä¸­é‡‡å–è¡ŒåŠ¨$a^{i}_{t}$ã€‚ä»£ç†äººå¯ä»¥é‡‡å–çš„å¯èƒ½è¡ŒåŠ¨$a^{i}_{t}\in
    A$åŒ…æ‹¬å¯¹å†›é˜Ÿçš„æŒ‡ä»¤ï¼Œå¦‚è¿›å…¥é‚»è¿‘é¢†åœŸã€æ”¯æ´å…¶ä»–å•ä½æˆ–åšå®ˆé˜µåœ°ã€‚è¡ŒåŠ¨ä¹Ÿå¯ä»¥åŒ…æ‹¬å¤–äº¤ä¸¾æªï¼Œå¦‚æè®®æˆ–é€€å‡ºè”ç›Ÿï¼Œå°½ç®¡è¿™äº›åœ¨æ¸¸æˆæœºåˆ¶ä¸­ä¸å¦‚å‰è€…æ­£å¼åŒ–ã€‚Paquetteç­‰äººï¼ˆ[2019](https://arxiv.org/html/2407.06813v4#bib.bib40)ï¼‰ï¼›Hillï¼ˆ[2014](https://arxiv.org/html/2407.06813v4#bib.bib23)ï¼‰
- en: 4 Self-Evolving LLM-based Diplomat
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 è‡ªæˆ‘è¿›åŒ–çš„åŸºäºLLMçš„å¤–äº¤å®˜
- en: '![Refer to caption](img/50a212a65fe0245eb038b95f76258c99.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/50a212a65fe0245eb038b95f76258c99.png)'
- en: 'Figure 2: The framework of the proposed LLM-based-agent, Richelieu. It can
    explicitly reason social beliefs, propose sub-goals with reflection, negotiate
    with others, and take actions to master diplomacy. It augments memories by self-play
    games for self-evolving without any human annotation.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2ï¼šæå‡ºçš„åŸºäºLLMçš„ä»£ç†æ¡†æ¶ï¼ŒRichelieuã€‚å®ƒå¯ä»¥æ˜ç¡®æ¨ç†ç¤¾ä¼šä¿¡å¿µï¼Œåæ€åæå‡ºå­ç›®æ ‡ï¼Œä¸ä»–äººè¿›è¡Œè°ˆåˆ¤ï¼Œå¹¶é‡‡å–è¡ŒåŠ¨æŒæ¡å¤–äº¤ã€‚å®ƒé€šè¿‡è‡ªæˆ‘å¯¹æˆ˜æ¸¸æˆæ¥å¢å¼ºè®°å¿†ï¼Œå®ç°è‡ªæˆ‘è¿›åŒ–ï¼Œè€Œæ— éœ€ä»»ä½•äººå·¥æ ‡æ³¨ã€‚
- en: 'We have constructed a comprehensive framework with modules for memory management,
    social reasoning, strategic planning, negotiation, decision-making, memory update,
    and self-evolving to fully leverage the capabilities of LLMs. Richelieu starts
    by setting up with map details, game rules, domain knowledge, and the long-term
    goal.Zhang etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib77)); Wei
    etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib59)); Wang etÂ al. ([2022a](https://arxiv.org/html/2407.06813v4#bib.bib54))
    At each turn, the agent will run in the following steps: 1) Social Reasoning:
    First of all, the agent undergoes a comprehensive analysis of the game state $s_{t}$
    to build the social belief, including the intention of other players and their
    relationship $\vec{\phi_{t}}\in\Phi^{n}$.Zhang etÂ al. ([2024c](https://arxiv.org/html/2407.06813v4#bib.bib74));
    GÃ¼rcan ([2024](https://arxiv.org/html/2407.06813v4#bib.bib20)) 2) Planner with
    Reflection: Then, the agent proposes sub-goals $\chi^{i}_{t}\in X$ that is strategically
    aligned with the long-term goals $\Upsilon$, with the social belief and refining
    the proposed goal with experience $\vec{\eta_{t}}\in H^{m}$ abstract from the
    memory $M$ via self-reflection.Wang etÂ al. ([2024b](https://arxiv.org/html/2407.06813v4#bib.bib52),
    [e](https://arxiv.org/html/2407.06813v4#bib.bib58)) 3) Negotiator: To achieve
    the sub-goals, the negotiator will start a dialogue session with some players,
    and evaluate their trueness $\vec{\psi}^{-i}_{t}$ by referring to their words
    $\vec{m}^{-i,i}_{t}$, the current state $s_{t}$, their sincerity $\vec{\gamma}^{-i}_{t}$
    and the experience $\vec{\xi_{t}}$ .Abdelnabi etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib1));
    Bianchi etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib8)) 4) Actor:
    After negotiation, the actor decides its course of action $a^{i}_{t}$, based on
    the sub-goal $\chi^{i}_{t}$ and updated social state $s_{t+1}$, marking the end
    of that turn. 5) Memory Management: The state of the current turn $s_{t}$, the
    content of negotiations $\vec{m_{t}}$, the actions taken by all players $\vec{a_{t}}\in
    A^{n}$, and the sub-goals set forth $\chi^{i}_{t}$ are all logged within the memory
    as $\mu\in M$. This logged data serves as a historical experience, guiding Richelieuâ€™s
    subsequent actions in future turnsÂ Hatalis etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib21));
    Zhang etÂ al. ([2024e](https://arxiv.org/html/2407.06813v4#bib.bib76)). 6) Self-evolution:
    The agentâ€™s evolution is highly dependent on the diversity of experiences stored
    in its memory. As this diversity grows, so does the agentâ€™s capability. Without
    human demonstrations, we employ multi-agent self-play games, i.e., our agents
    respectively control all the countries to simulate and acquire diverse experiences
    for self-evolving. Notably, the agent can further evolve during testing to adapt
    to different players.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„æ¡†æ¶ï¼ŒåŒ…å«å†…å­˜ç®¡ç†ã€ç¤¾ä¼šæ¨ç†ã€æˆ˜ç•¥è§„åˆ’ã€è°ˆåˆ¤ã€å†³ç­–ã€å†…å­˜æ›´æ–°å’Œè‡ªæˆ‘è¿›åŒ–ç­‰æ¨¡å—ï¼Œä»¥å……åˆ†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„èƒ½åŠ›ã€‚Richelieué¦–å…ˆé€šè¿‡è®¾ç½®åœ°å›¾ç»†èŠ‚ã€æ¸¸æˆè§„åˆ™ã€é¢†åŸŸçŸ¥è¯†å’Œé•¿æœŸç›®æ ‡æ¥è¿›è¡Œåˆå§‹åŒ–ã€‚Zhangç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib77)ï¼‰ï¼›Weiç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib59)ï¼‰ï¼›Wangç­‰äººï¼ˆ[2022a](https://arxiv.org/html/2407.06813v4#bib.bib54)ï¼‰åœ¨æ¯ä¸€å›åˆï¼Œæ™ºèƒ½ä½“å°†æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿è¡Œï¼š1ï¼‰ç¤¾ä¼šæ¨ç†ï¼šé¦–å…ˆï¼Œæ™ºèƒ½ä½“å¯¹æ¸¸æˆçŠ¶æ€$s_{t}$è¿›è¡Œå…¨é¢åˆ†æï¼Œä»¥æ„å»ºç¤¾ä¼šä¿¡å¿µï¼ŒåŒ…æ‹¬å…¶ä»–ç©å®¶çš„æ„å›¾åŠå…¶å…³ç³»$\vec{\phi_{t}}\in\Phi^{n}$ã€‚Zhangç­‰äººï¼ˆ[2024c](https://arxiv.org/html/2407.06813v4#bib.bib74)ï¼‰ï¼›GÃ¼rcanï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib20)ï¼‰2ï¼‰å¸¦åæ€çš„è§„åˆ’è€…ï¼šç„¶åï¼Œæ™ºèƒ½ä½“æå‡ºä¸é•¿æœŸç›®æ ‡$\Upsilon$æˆ˜ç•¥å¯¹é½çš„å­ç›®æ ‡$\chi^{i}_{t}\in
    X$ï¼Œç»“åˆç¤¾ä¼šä¿¡å¿µå¹¶é€šè¿‡è‡ªæˆ‘åæ€ä»è®°å¿†$M$ä¸­æç‚¼ç»éªŒ$\vec{\eta_{t}}\in H^{m}$ï¼Œå®Œå–„æ‰€æè®®çš„ç›®æ ‡ã€‚Wangç­‰äººï¼ˆ[2024b](https://arxiv.org/html/2407.06813v4#bib.bib52)ï¼Œ[e](https://arxiv.org/html/2407.06813v4#bib.bib58)ï¼‰3ï¼‰è°ˆåˆ¤è€…ï¼šä¸ºäº†å®ç°å­ç›®æ ‡ï¼Œè°ˆåˆ¤è€…å°†ä¸ä¸€äº›ç©å®¶å¼€å¯å¯¹è¯ä¼šè¯ï¼Œå¹¶é€šè¿‡å‚è€ƒä»–ä»¬çš„è¨€è¾$\vec{m}^{-i,i}_{t}$ã€å½“å‰çŠ¶æ€$s_{t}$ã€è¯šæ„$\vec{\gamma}^{-i}_{t}$å’Œç»éªŒ$\vec{\xi_{t}}$æ¥è¯„ä¼°ä»–ä»¬çš„çœŸå®æ€§$\vec{\psi}^{-i}_{t}$ã€‚Abdelnabiç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib1)ï¼‰ï¼›Bianchiç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib8)ï¼‰4ï¼‰æ‰§è¡Œè€…ï¼šè°ˆåˆ¤ç»“æŸåï¼Œæ‰§è¡Œè€…æ ¹æ®å­ç›®æ ‡$\chi^{i}_{t}$å’Œæ›´æ–°åçš„ç¤¾ä¼šçŠ¶æ€$s_{t+1}$å†³å®šå…¶è¡ŒåŠ¨è·¯çº¿$a^{i}_{t}$ï¼Œæ ‡å¿—ç€è¯¥å›åˆçš„ç»“æŸã€‚5ï¼‰å†…å­˜ç®¡ç†ï¼šå½“å‰å›åˆçš„çŠ¶æ€$s_{t}$ã€è°ˆåˆ¤å†…å®¹$\vec{m_{t}}$ã€æ‰€æœ‰ç©å®¶é‡‡å–çš„è¡ŒåŠ¨$\vec{a_{t}}\in
    A^{n}$ä»¥åŠæå‡ºçš„å­ç›®æ ‡$\chi^{i}_{t}$éƒ½ä¼šè¢«è®°å½•åˆ°å†…å­˜ä¸­ï¼Œä½œä¸º$\mu\in M$ã€‚è¿™äº›è®°å½•çš„æ•°æ®ä½œä¸ºå†å²ç»éªŒï¼ŒæŒ‡å¯¼Richelieuåœ¨æœªæ¥å›åˆä¸­çš„åç»­è¡ŒåŠ¨ã€‚Hatalisç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib21)ï¼‰ï¼›Zhangç­‰äººï¼ˆ[2024e](https://arxiv.org/html/2407.06813v4#bib.bib76)ï¼‰6ï¼‰è‡ªæˆ‘è¿›åŒ–ï¼šæ™ºèƒ½ä½“çš„è¿›åŒ–é«˜åº¦ä¾èµ–äºå…¶å†…å­˜ä¸­å­˜å‚¨çš„ç»éªŒå¤šæ ·æ€§ã€‚éšç€è¿™ç§å¤šæ ·æ€§çš„å¢é•¿ï¼Œæ™ºèƒ½ä½“çš„èƒ½åŠ›ä¹Ÿéšä¹‹æå‡ã€‚åœ¨æ²¡æœ‰äººç±»ç¤ºèŒƒçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é‡‡ç”¨å¤šæ™ºèƒ½ä½“è‡ªå¯¹å¼ˆæ¸¸æˆï¼Œå³æˆ‘ä»¬çš„æ™ºèƒ½ä½“åˆ†åˆ«æ§åˆ¶æ‰€æœ‰å›½å®¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿå’Œè·å–å¤šæ ·åŒ–çš„ç»éªŒè¿›è¡Œè‡ªæˆ‘è¿›åŒ–ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ™ºèƒ½ä½“åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­è¿˜å¯ä»¥è¿›ä¸€æ­¥è¿›åŒ–ï¼Œä»¥é€‚åº”ä¸åŒçš„ç©å®¶ã€‚
- en: 4.1 Social Reasoning
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 ç¤¾ä¼šæ¨ç†
- en: There are no permanent enemies, no permanent allies. The relationship among
    countries is dynamically changing upon the evolving global state. However, it
    is difficult to determine the appropriate allies and enemies with partial observation.
    For example, there is uncertainty about the intentions of potential allies, which
    could lead to betrayal at pivotal moments. Consequently, we need to identify the
    intention and relationship of the current state by social reasoning to shape the
    social belief Zhang etÂ al. ([2024c](https://arxiv.org/html/2407.06813v4#bib.bib74));
    GÃ¼rcan ([2024](https://arxiv.org/html/2407.06813v4#bib.bib20)).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰æ°¸æ’çš„æ•Œäººï¼Œä¹Ÿæ²¡æœ‰æ°¸æ’çš„ç›Ÿå‹ã€‚å›½å®¶é—´çš„å…³ç³»éšç€å…¨çƒå½¢åŠ¿çš„å˜åŒ–è€ŒåŠ¨æ€å˜åŒ–ã€‚ç„¶è€Œï¼Œä»…å‡­éƒ¨åˆ†è§‚å¯Ÿå¾ˆéš¾ç¡®å®šåˆé€‚çš„ç›Ÿå‹å’Œæ•Œäººã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ½œåœ¨ç›Ÿå‹çš„æ„å›¾å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¿™å¯èƒ½å¯¼è‡´åœ¨å…³é”®æ—¶åˆ»çš„èƒŒå›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ç¤¾ä¼šæ¨ç†æ¥è¯†åˆ«å½“å‰çŠ¶æ€çš„æ„å›¾å’Œå…³ç³»ï¼Œä»è€Œå¡‘é€ ç¤¾ä¼šä¿¡å¿µ
    Zhang et al.ï¼ˆ[2024c](https://arxiv.org/html/2407.06813v4#bib.bib74)ï¼‰ï¼›GÃ¼rcanï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib20)ï¼‰ã€‚
- en: '1) Modeling Relationship: Before setting sub-goals, Richelieu evaluates its
    relations with others, identifying enemies such as aggressive nations, vulnerable
    neighbors for expansion, and those with long-term potential threats. It also seeks
    out potential allies to counter these threats.Sun etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib47));
    Zhang etÂ al. ([2024d](https://arxiv.org/html/2407.06813v4#bib.bib75)) Simultaneously,
    Richelieu also tries to identify potential allies that could be instrumental in
    countering these adversaries. By isolating the analysis of inter-player relationships
    as a discrete element, Richelieu strategically exploits the actions of other players
    in subsequent stages of the game to reach its goals. 2) Inferring Intention: The
    social belief is used by the planner, ensuring that its sub-goals are formulated
    with a comprehensive consideration of the behaviors and intentions of other intelligent
    agents within the game. Richelieuâ€™s sub-goals will particularly emphasize on those
    who are identified as potential adversaries or allies, fostering more effective
    collaboration with potential allies and participation in strategic opposition
    against adversaries. Furthermore, the insights gleaned from this analysis are
    instrumental in the subsequent negotiation phases. They are employed to assess
    the authenticity of the statements made by other players, as well as to aid Richelieu
    in reaching cooperative agreements.deÂ ZarzÃ  etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib15));
    He etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib22))'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 1) å»ºç«‹å…³ç³»æ¨¡å‹ï¼šåœ¨è®¾å®šå­ç›®æ ‡ä¹‹å‰ï¼Œé»è°¢ç•™ä¼šè¯„ä¼°ä¸ä»–äººçš„å…³ç³»ï¼Œè¯†åˆ«å‡ºæ•Œäººï¼Œå¦‚å…·æœ‰æ”»å‡»æ€§çš„å›½å®¶ã€æ˜“å—æ‰©å¼ å¨èƒçš„é‚»å›½ä»¥åŠå…·æœ‰é•¿æœŸæ½œåœ¨å¨èƒçš„å›½å®¶ã€‚åŒæ—¶ï¼Œé»è°¢ç•™è¿˜ä¼šå¯»æ‰¾æ½œåœ¨çš„ç›Ÿå‹ï¼Œä»¥åº”å¯¹è¿™äº›å¨èƒã€‚Sun
    et al.ï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib47)ï¼‰ï¼›Zhang et al.ï¼ˆ[2024d](https://arxiv.org/html/2407.06813v4#bib.bib75)ï¼‰åŒæ—¶ï¼Œé»è°¢ç•™è¿˜ä¼šå°è¯•è¯†åˆ«å¯èƒ½æœ‰åŠ©äºååˆ¶è¿™äº›å¯¹æ‰‹çš„æ½œåœ¨ç›Ÿå‹ã€‚é€šè¿‡å°†ç©å®¶é—´å…³ç³»çš„åˆ†æä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„å…ƒç´ ï¼Œé»è°¢ç•™å¯ä»¥åœ¨æ¸¸æˆçš„åç»­é˜¶æ®µæˆ˜ç•¥æ€§åœ°åˆ©ç”¨å…¶ä»–ç©å®¶çš„è¡ŒåŠ¨æ¥å®ç°å…¶ç›®æ ‡ã€‚2)
    æ¨æ–­æ„å›¾ï¼šè§„åˆ’è€…åˆ©ç”¨ç¤¾ä¼šä¿¡å¿µï¼Œç¡®ä¿å…¶å­ç›®æ ‡åœ¨å…¨é¢è€ƒè™‘å…¶ä»–æ™ºèƒ½ä½“çš„è¡Œä¸ºå’Œæ„å›¾çš„åŸºç¡€ä¸Šåˆ¶å®šã€‚é»è°¢ç•™çš„å­ç›®æ ‡ç‰¹åˆ«ä¼šå¼ºè°ƒé‚£äº›è¢«è¯†åˆ«ä¸ºæ½œåœ¨æ•Œäººæˆ–ç›Ÿå‹çš„äººï¼Œä¿ƒè¿›ä¸æ½œåœ¨ç›Ÿå‹çš„æ›´æœ‰æ•ˆåˆä½œï¼Œå¹¶å‚ä¸å¯¹æ•Œäººçš„æˆ˜ç•¥å¯¹æŠ—ã€‚æ­¤å¤–ï¼Œä»è¿™ä¸€åˆ†æä¸­è·å¾—çš„æ´å¯Ÿåœ¨éšåçš„è°ˆåˆ¤é˜¶æ®µä¹Ÿå‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚å®ƒä»¬è¢«ç”¨æ¥è¯„ä¼°å…¶ä»–ç©å®¶é™ˆè¿°çš„çœŸå®æ€§ï¼Œå¹¶å¸®åŠ©é»è°¢ç•™è¾¾æˆåˆä½œåè®®ã€‚de
    ZarzÃ  et al.ï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib15)ï¼‰ï¼›He et al.ï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib22)ï¼‰ã€‚
- en: 4.2 Strategic Planner with Reflection
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 å¸¦åæ€çš„æˆ˜ç•¥è§„åˆ’è€…
- en: The strategic planner specifies the sub-goals, which serves as an intermediary
    between immediate actions and the overarching goal of securing victory in the
    game. That is because we observe that LLMs are often characterized by their propensity
    to prioritize short-term gains in decision-making processes, with a notable deficiency
    in incorporating the future into their strategic calculations. Renze and Guven
    ([2024](https://arxiv.org/html/2407.06813v4#bib.bib42)); Zhang etÂ al. ([2024b](https://arxiv.org/html/2407.06813v4#bib.bib73))For
    example, it is common for a non-neighboring country to become too powerful. Formally,
    $\vec{\chi_{t}}\leftarrow SR(s_{t},\vec{\phi_{t}},\Upsilon)$ where $\vec{\chi_{t}}=(\chi^{i}_{t},\chi^{1}_{t},\ldots,\chi^{n}_{t})$
    represents the proposed sub-goals and other playersâ€™ intention that we inferred,
    $\vec{\phi_{t}}\in\Phi^{n}$ represents the inferred relationship on the social
    belief. These goals may encompass a range of tactical considerations, such as
    the containment of a formidable rivalâ€™s advancement or the strategic expansion
    in a particular direction to consolidate power.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ˜ç•¥è§„åˆ’è€…æŒ‡å®šå­ç›®æ ‡ï¼Œå……å½“å³æ—¶è¡ŒåŠ¨ä¸æ¸¸æˆä¸­æœ€ç»ˆèƒœåˆ©ç›®æ ‡ä¹‹é—´çš„ä¸­ä»‹ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼ŒLLMå¾€å¾€å€¾å‘äºåœ¨å†³ç­–è¿‡ç¨‹ä¸­ä¼˜å…ˆè€ƒè™‘çŸ­æœŸæ”¶ç›Šï¼Œç¼ºä¹å°†æœªæ¥çº³å…¥æˆ˜ç•¥è®¡ç®—çš„èƒ½åŠ›ã€‚Renze
    å’Œ Guven ([2024](https://arxiv.org/html/2407.06813v4#bib.bib42))ï¼›Zhang et al. ([2024b](https://arxiv.org/html/2407.06813v4#bib.bib73))
    ä¾‹å¦‚ï¼Œéé‚»è¿‘å›½å®¶å˜å¾—è¿‡äºå¼ºå¤§æ˜¯å¸¸è§ç°è±¡ã€‚å½¢å¼ä¸Šï¼Œ$\vec{\chi_{t}}\leftarrow SR(s_{t},\vec{\phi_{t}},\Upsilon)$ï¼Œå…¶ä¸­
    $\vec{\chi_{t}}=(\chi^{i}_{t},\chi^{1}_{t},\ldots,\chi^{n}_{t})$ ä»£è¡¨æå‡ºçš„å­ç›®æ ‡å’Œæˆ‘ä»¬æ¨æ–­å‡ºçš„å…¶ä»–ç©å®¶çš„æ„å›¾ï¼Œ$\vec{\phi_{t}}\in\Phi^{n}$
    ä»£è¡¨æ¨æ–­çš„ç¤¾ä¼šä¿¡å¿µå…³ç³»ã€‚è¿™äº›ç›®æ ‡å¯èƒ½æ¶µç›–ä¸€ç³»åˆ—æˆ˜æœ¯è€ƒè™‘ï¼Œä¾‹å¦‚éåˆ¶ä¸€ä¸ªå¼ºå¤§å¯¹æ‰‹çš„æ‰©å¼ ï¼Œæˆ–åœ¨ç‰¹å®šæ–¹å‘ä¸Šè¿›è¡Œæˆ˜ç•¥æ€§æ‰©å±•ä»¥å·©å›ºå®åŠ›ã€‚
- en: 'Reflection with Memory. We further develop a reflection mechanism to enhance
    the rationality and effectiveness of our agentâ€™s sub-goals in achieving long-term
    goals.Liu etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib34)) This
    reflection mechanism relies on the past experiences to critique and enhance proposed
    sub-goals. We employ a similarity-based function to find relevant historical experiences
    that match the current game state from its memory. This function considers two
    factors: goal similarity and state similarity, to select the most comparable experiences.
    The process can be written as: $\vec{\eta_{t}}\leftarrow h(s_{t},\chi^{i}_{t},M)$,
    where $\vec{\eta_{t}}\in H^{m}$. In practice, considering the limited context
    windows of LLM, we retrieve the most analogous experiences from the memory based
    on these metrics. Experiences with high evaluative scores reinforce successful
    strategies and support the continuity of existing sub-goals. On the other hand,
    lower scores indicate areas that need improvement and prompt the necessary adjustments.
    As our agent, Richelieu, undergoes more training sessions, its reflection abilities
    improve. The growing pool of historical experiences consistently enhances its
    performance.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åæ€ä¸è®°å¿†ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ç§åæ€æœºåˆ¶ï¼Œä»¥å¢å¼ºä»£ç†åœ¨å®ç°é•¿æœŸç›®æ ‡è¿‡ç¨‹ä¸­å­ç›®æ ‡çš„åˆç†æ€§å’Œæœ‰æ•ˆæ€§ã€‚Liu et al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib34))
    è¯¥åæ€æœºåˆ¶ä¾èµ–äºè¿‡å»çš„ç»éªŒï¼Œæ‰¹åˆ¤å¹¶å¢å¼ºæå‡ºçš„å­ç›®æ ‡ã€‚æˆ‘ä»¬é‡‡ç”¨åŸºäºç›¸ä¼¼åº¦çš„å‡½æ•°ï¼Œä»è®°å¿†ä¸­æ‰¾åˆ°ä¸å½“å‰æ¸¸æˆçŠ¶æ€åŒ¹é…çš„ç›¸å…³å†å²ç»éªŒã€‚è¯¥å‡½æ•°è€ƒè™‘ä¸¤ä¸ªå› ç´ ï¼šç›®æ ‡ç›¸ä¼¼åº¦å’ŒçŠ¶æ€ç›¸ä¼¼åº¦ï¼Œä»¥é€‰æ‹©æœ€ä¸ºç›¸ä¼¼çš„ç»éªŒã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¡¨ç¤ºä¸ºï¼š$\vec{\eta_{t}}\leftarrow
    h(s_{t},\chi^{i}_{t},M)$ï¼Œå…¶ä¸­ $\vec{\eta_{t}}\in H^{m}$ã€‚åœ¨å®é™…æ“ä½œä¸­ï¼Œè€ƒè™‘åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼Œæˆ‘ä»¬æ ¹æ®è¿™äº›æŒ‡æ ‡ä»è®°å¿†ä¸­æ£€ç´¢æœ€ä¸ºç›¸ä¼¼çš„ç»éªŒã€‚å…·æœ‰è¾ƒé«˜è¯„ä¼°åˆ†æ•°çš„ç»éªŒå¼ºåŒ–äº†æˆåŠŸçš„ç­–ç•¥ï¼Œå¹¶æ”¯æŒç°æœ‰å­ç›®æ ‡çš„å»¶ç»­ã€‚å¦ä¸€æ–¹é¢ï¼Œè¾ƒä½çš„åˆ†æ•°åˆ™è¡¨æ˜éœ€è¦æ”¹è¿›çš„é¢†åŸŸï¼Œå¹¶ä¿ƒä½¿å¿…è¦çš„è°ƒæ•´ã€‚éšç€æˆ‘ä»¬çš„ä»£ç†Richelieuç»è¿‡æ›´å¤šè®­ç»ƒï¼Œå…¶åæ€èƒ½åŠ›ä¸æ–­æå‡ï¼Œå†å²ç»éªŒçš„ç§¯ç´¯æŒç»­æ”¹å–„å…¶è¡¨ç°ã€‚
- en: 4.3 Negotiator and Actor
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 åå•†è€…ä¸æ‰§è¡Œè€…
- en: By chatting with other players, the goal of the negotiation is to update the
    social belief according to the received words and reach the sub-goal by manipulating
    otherâ€™s intentions, such as securing cooperative agreements with other nations,
    terminating ongoing conflicts with a specific country, or deterring the formation
    of alliances directed against its interests.Noh and Chang ([2024](https://arxiv.org/html/2407.06813v4#bib.bib38));
    Zhan etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib71)) However, it
    is difficult to reach a consensus, as the interests and strategies of the various
    nations often conflict, and trust between players can be scarce, making it challenging
    to establish and maintain cooperative agreements. In this case, we argue that
    the negotiator should identify the true intentions and relationship of the opponent
    before generating the words for the negotiation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–ç©å®¶è¿›è¡ŒèŠå¤©æ—¶ï¼Œè°ˆåˆ¤çš„ç›®æ ‡æ˜¯æ ¹æ®æ”¶åˆ°çš„è¨€è¾æ›´æ–°ç¤¾ä¼šä¿¡å¿µï¼Œå¹¶é€šè¿‡æ“æ§ä»–äººçš„æ„å›¾å®ç°å­ç›®æ ‡ï¼Œä¾‹å¦‚ä¸å…¶ä»–å›½å®¶è¾¾æˆåˆä½œåè®®ã€ç»ˆæ­¢ä¸ç‰¹å®šå›½å®¶çš„æŒç»­å†²çªï¼Œæˆ–é˜»æ­¢é’ˆå¯¹å…¶åˆ©ç›Šçš„è”ç›Ÿçš„å½¢æˆã€‚Nohå’ŒChangï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib38)ï¼‰ï¼›Zhanç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib71)ï¼‰ç„¶è€Œï¼Œç”±äºå„å›½çš„åˆ©ç›Šå’Œæˆ˜ç•¥å¸¸å¸¸å†²çªï¼Œä¸”ç©å®¶ä¹‹é—´çš„ä¿¡ä»»ç¨€ç¼ºï¼Œå¯¼è‡´è¾¾æˆå…±è¯†å˜å¾—å›°éš¾ï¼Œåˆä½œåè®®çš„å»ºç«‹ä¸ç»´æŒé¢ä¸´æŒ‘æˆ˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è®¤ä¸ºè°ˆåˆ¤è€…åº”åœ¨ç”Ÿæˆè°ˆåˆ¤è¯­è¨€ä¹‹å‰ï¼Œè¯†åˆ«å¯¹æ‰‹çš„çœŸå®æ„å›¾å’Œå…³ç³»ã€‚
- en: 'To fully utilize the power of LLMs, we construct a social reasoning flow for
    negotiation, as shown in FigureÂ [3](https://arxiv.org/html/2407.06813v4#S4.F3
    "Figure 3 â€£ 4.3 Negotiator and Actor â€£ 4 Self-Evolving LLM-based Diplomat â€£ Richelieu:
    Self-Evolving LLM-Based Agents for AI Diplomacy"). During the negotiation process,
    we guide Richelieu to consider the veracity of what other players said and their
    true intentions, and in conjunction with our established sub-goals and analysis
    of our relationships with other players, to negotiate and form alliances with
    potential allies and attempt to deceive enemies.Xia etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib61));
    Moghimifar etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib36))'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¸ºäº†å……åˆ†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç”¨äºè°ˆåˆ¤çš„ç¤¾ä¼šæ¨ç†æµç¨‹ï¼Œå¦‚å›¾[3](https://arxiv.org/html/2407.06813v4#S4.F3
    "Figure 3 â€£ 4.3 Negotiator and Actor â€£ 4 Self-Evolving LLM-based Diplomat â€£ Richelieu:
    Self-Evolving LLM-Based Agents for AI Diplomacy")æ‰€ç¤ºã€‚åœ¨è°ˆåˆ¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¼•å¯¼Richelieuè€ƒè™‘å…¶ä»–ç©å®¶æ‰€è¯´å†…å®¹çš„çœŸå®æ€§åŠå…¶çœŸå®æ„å›¾ï¼Œå¹¶ç»“åˆæˆ‘ä»¬å·²ç»è®¾å®šçš„å­ç›®æ ‡å’Œä¸å…¶ä»–ç©å®¶å…³ç³»çš„åˆ†æï¼Œä¸æ½œåœ¨ç›Ÿå‹è¿›è¡Œè°ˆåˆ¤å¹¶å½¢æˆè”ç›Ÿï¼Œè¯•å›¾æ¬ºéª—æ•Œäººã€‚Xiaç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib61)ï¼‰ï¼›Moghimifarç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib36)ï¼‰'
- en: 'To counteract the challenge of non-binding agreements and potential deception,
    we incorporate a discrete module dedicated to the assessment of the veracity of
    statements made by other players during negotiations. To determine the truthiness
    of other playersâ€™ statements $\psi^{j}_{t}$, three main factors are considered.
    The most important is the consistency between the playerâ€™s sub-goals $\chi^{j}_{t}$
    that our agent inferred before and the intentions conveyed through his statements
    $m^{j,i}_{t}$. To aid in the judgment, our agent also goes through the memory
    to retrieve the consistent experiences $\vec{\xi_{t}}$. Additionally, the playerâ€™s
    overall honesty score $\gamma_{i}$ is taken into account. Hence, we get the truthiness
    of the opponent $j$: $\psi^{j}_{t}\leftarrow g(s_{t},\chi^{j}_{t},m^{j,i}_{t},\vec{\phi_{t}},\gamma_%
    {j},\vec{\xi_{t}})$, where $\vec{\xi_{t}}=w(s_{t},m^{j,i}_{t},M)$. With such a
    reasoning flow, our agent can adeptly navigate diplomatic discourse. After the
    negotiation, the actor will get the updated social beliefs and choose a specific
    action for the army.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åº”å¯¹éçº¦æŸæ€§åè®®å’Œæ½œåœ¨æ¬ºéª—çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬åŠ å…¥äº†ä¸€ä¸ªç¦»æ•£æ¨¡å—ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°å…¶ä»–ç©å®¶åœ¨è°ˆåˆ¤è¿‡ç¨‹ä¸­æ‰€ä½œè¨€è®ºçš„çœŸå®æ€§ã€‚ä¸ºäº†ç¡®å®šå…¶ä»–ç©å®¶é™ˆè¿°çš„çœŸå®æ€§$\psi^{j}_{t}$ï¼Œè€ƒè™‘äº†ä¸‰ä¸ªä¸»è¦å› ç´ ã€‚æœ€é‡è¦çš„æ˜¯ç©å®¶çš„å­ç›®æ ‡$\chi^{j}_{t}$ï¼Œå³æˆ‘ä»¬ä¹‹å‰æ¨æµ‹å‡ºçš„ç›®æ ‡ï¼Œä¸å…¶é€šè¿‡é™ˆè¿°$
    m^{j,i}_{t}$ä¼ è¾¾çš„æ„å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚ä¸ºäº†è¾…åŠ©åˆ¤æ–­ï¼Œæˆ‘ä»¬çš„ä»£ç†è¿˜ä¼šå›é¡¾è®°å¿†ï¼Œæ£€ç´¢ä¸€è‡´çš„ç»éªŒ$\vec{\xi_{t}}$ã€‚æ­¤å¤–ï¼Œè¿˜ä¼šè€ƒè™‘ç©å®¶çš„æ•´ä½“è¯šå®åº¦è¯„åˆ†$\gamma_{i}$ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¾—å‡ºå¯¹æ‰‹$j$çš„çœŸå®æ€§$\psi^{j}_{t}\leftarrow
    g(s_{t},\chi^{j}_{t},m^{j,i}_{t},\vec{\phi_{t}},\gamma_{j},\vec{\xi_{t}})$ï¼Œå…¶ä¸­$\vec{\xi_{t}}=w(s_{t},m^{j,i}_{t},M)$ã€‚é€šè¿‡è¿™æ ·çš„æ¨ç†æµç¨‹ï¼Œæˆ‘ä»¬çš„ä»£ç†èƒ½å¤Ÿç†Ÿç»ƒåœ°é©¾é©­å¤–äº¤è¯è¯­ã€‚è°ˆåˆ¤ç»“æŸåï¼Œå‚ä¸è€…å°†è·å¾—æ›´æ–°çš„ç¤¾ä¼šä¿¡å¿µï¼Œå¹¶ä¸ºå†›é˜Ÿé€‰æ‹©ç‰¹å®šçš„è¡ŒåŠ¨ã€‚
- en: '![Refer to caption](img/b1b2fc8a91d91e30fa060f0be837a8a8.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![è¯·å‚é˜…æ ‡é¢˜è¯´æ˜](img/b1b2fc8a91d91e30fa060f0be837a8a8.png)'
- en: 'Figure 3: The social reasoning flow for negotiation. With the received words
    and memory, the agent will reason by answering the following questions: â€œIs the
    opponent lying?", â€œWhat is the true intention of the opponent?", â€œis the opponent
    enemy?", â€œIs it necessary to deceive the opponent?", and â€œIs it necessary to change
    the relationship with the opponent?", and then generate the words accordingly
    for negotiation.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3ï¼šè°ˆåˆ¤ä¸­çš„ç¤¾äº¤æ¨ç†æµç¨‹ã€‚é€šè¿‡æ¥æ”¶åˆ°çš„è¨€è¾å’Œè®°å¿†ï¼Œä»£ç†äººå°†é€šè¿‡å›ç­”ä»¥ä¸‹é—®é¢˜è¿›è¡Œæ¨ç†ï¼šâ€œå¯¹æ–¹åœ¨æ’’è°å—ï¼Ÿâ€ï¼Œâ€œå¯¹æ–¹çš„çœŸå®æ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼Œâ€œå¯¹æ–¹æ˜¯æ•Œäººå—ï¼Ÿâ€ï¼Œâ€œæœ‰å¿…è¦æ¬ºéª—å¯¹æ–¹å—ï¼Ÿâ€ä»¥åŠâ€œæœ‰å¿…è¦æ”¹å˜ä¸å¯¹æ–¹çš„å…³ç³»å—ï¼Ÿâ€ï¼Œç„¶åæ ¹æ®æ¨ç†ç”Ÿæˆç›¸åº”çš„è¨€è¾è¿›è¡Œè°ˆåˆ¤ã€‚
- en: 4.4 Memory Management and Evolution in Self-Play Games
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 è‡ªæˆ‘åšå¼ˆä¸­çš„è®°å¿†ç®¡ç†ä¸æ¼”åŒ–
- en: This memory is the foundation of the framework that accumulates the historical
    experience of the agent and summarizes them for other modules.Gao and Zhang ([2024](https://arxiv.org/html/2407.06813v4#bib.bib18));
    Li etÂ al. ([2024a](https://arxiv.org/html/2407.06813v4#bib.bib31)); Yu etÂ al.
    ([2024](https://arxiv.org/html/2407.06813v4#bib.bib69)); Hou etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib24))
    It supports other modules, such as planner and negotiator, to provide long-tail
    experiences.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è®°å¿†æ˜¯æ¡†æ¶çš„åŸºç¡€ï¼Œç§¯ç´¯äº†ä»£ç†äººçš„å†å²ç»éªŒï¼Œå¹¶å°†å…¶æ€»ç»“ä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨ã€‚é«˜å’Œå¼ ï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib18)ï¼‰ï¼›æç­‰äººï¼ˆ[2024a](https://arxiv.org/html/2407.06813v4#bib.bib31)ï¼‰ï¼›äºç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib69)ï¼‰ï¼›ä¾¯ç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib24)ï¼‰æ”¯æŒå…¶ä»–æ¨¡å—ï¼Œå¦‚è§„åˆ’å™¨å’Œè°ˆåˆ¤è€…ï¼Œä¸ºå…¶æä¾›é•¿å°¾ç»éªŒã€‚
- en: Raw Experience Management. Specifically, the memory module is tasked with the
    acquisition and archival of historical data, encompassing the observed game state
    $s_{t}$ at each turn, its sub-goals $\chi^{i}_{t}$, the messages during the negotiation
    $\vec{m_{t}}$, and the actions of all the players $\vec{a_{t}}$. Subsequently,
    the raw experience is summarized in a shorter content with an evaluation $\lambda_{t}\in\Lambda$
    of the proposed sub-goals and an assessment of the credibility of other players
    $\gamma_{j}\in\Gamma$. $\lambda_{t}$ serves to reflect upon the agentâ€™s sub-goals.
    It evaluates whether sub-goals are reasonable based on the subsequent state and
    long-term goals $\Upsilon$. As the game progresses, it is continuously updated
    in response to changes in the state $\lambda_{t}\leftarrow f(\chi^{i}_{t},\Upsilon,\vec{s})$,
    where $\vec{s}=(s_{t},s_{t+1},\ldots s_{T})$. The formula represents the update
    of the evaluation $\lambda_{t}$ for the sub-goal in turn $t$ by the memory in
    turn $T$. The updates will cease when there is a fundamental change in the sub-goal
    compared to the goal at turn $t$. This prevents subsequent decisions from impacting
    the assessment of the current decision-making. We employ $\gamma_{j}\in\Gamma$
    to evaluate the credibility of player $j$ and utilize $\tau^{j}_{t}\in\{0,1\}$
    to denote the truthfulness, i.e., whether the statements made by the player $j$
    during the negotiation process at time $t$ are truthful. The truthiness of player
    $j$â€™s statements is updated according to the memory from the previous turns, $\tau^{j}_{t}\leftarrow
    T(s_{t},s_{t+1},a^{j}_{t},m^{j,i}_{t})$. The credibility of player $j$ $\gamma_{j}$
    will be updated based on player $j$â€™s statements $\tau^{j}_{t}$, written as $\gamma_{j}\leftarrow
    p(\gamma_{j},\tau^{j}_{t-1})$. Playersâ€™ credibility $\vec{\gamma}$ is a short-term
    memory that is applicable only to the current turn. Other data collected or generated
    constitutes long-term memory. These data will be combined to form a history $\mu\in
    M$, and then is incorporated into memory.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹ç»éªŒç®¡ç†ã€‚å…·ä½“è€Œè¨€ï¼Œè®°å¿†æ¨¡å—è´Ÿè´£è·å–å’Œå­˜æ¡£å†å²æ•°æ®ï¼ŒåŒ…æ‹¬æ¯ä¸€å›åˆçš„è§‚å¯Ÿåˆ°çš„æ¸¸æˆçŠ¶æ€ $s_{t}$ï¼Œå…¶å­ç›®æ ‡ $\chi^{i}_{t}$ï¼Œè°ˆåˆ¤è¿‡ç¨‹ä¸­ä¼ é€’çš„æ¶ˆæ¯
    $\vec{m_{t}}$ï¼Œä»¥åŠæ‰€æœ‰ç©å®¶çš„è¡ŒåŠ¨ $\vec{a_{t}}$ã€‚éšåï¼ŒåŸå§‹ç»éªŒè¢«æ€»ç»“ä¸ºç®€çŸ­å†…å®¹ï¼Œå¹¶é€šè¿‡å¯¹æå‡ºçš„å­ç›®æ ‡çš„è¯„ä¼° $\lambda_{t}\in\Lambda$
    å’Œå¯¹å…¶ä»–ç©å®¶å¯ä¿¡åº¦çš„è¯„ä¼° $\gamma_{j}\in\Gamma$ è¿›è¡Œå½’çº³æ€»ç»“ã€‚$\lambda_{t}$ ç”¨äºåæ€ä»£ç†çš„å­ç›®æ ‡ã€‚å®ƒè¯„ä¼°å­ç›®æ ‡æ˜¯å¦åˆç†ï¼Œä¾æ®æ˜¯éšåçš„çŠ¶æ€ä»¥åŠé•¿æœŸç›®æ ‡
    $\Upsilon$ã€‚éšç€æ¸¸æˆçš„è¿›è¡Œï¼Œ$\lambda_{t}$ ä¼šæ ¹æ®çŠ¶æ€çš„å˜åŒ–ä¸æ–­æ›´æ–°ï¼Œå³ $\lambda_{t}\leftarrow f(\chi^{i}_{t},\Upsilon,\vec{s})$ï¼Œå…¶ä¸­
    $\vec{s}=(s_{t},s_{t+1},\ldots s_{T})$ã€‚è¯¥å…¬å¼è¡¨ç¤ºåœ¨å›åˆ $T$ ä¸­ï¼Œç”±è®°å¿†æ›´æ–°å›åˆ $t$ çš„å­ç›®æ ‡è¯„ä¼° $\lambda_{t}$ã€‚å½“å­ç›®æ ‡ä¸å›åˆ
    $t$ çš„ç›®æ ‡å‘ç”Ÿæ ¹æœ¬æ€§å˜åŒ–æ—¶ï¼Œæ›´æ–°å°†åœæ­¢ã€‚è¿™é˜²æ­¢åç»­çš„å†³ç­–å½±å“å½“å‰å†³ç­–çš„è¯„ä¼°ã€‚æˆ‘ä»¬ä½¿ç”¨ $\gamma_{j}\in\Gamma$ æ¥è¯„ä¼°ç©å®¶ $j$ çš„å¯ä¿¡åº¦ï¼Œå¹¶åˆ©ç”¨
    $\tau^{j}_{t}\in\{0,1\}$ æ¥è¡¨ç¤ºå…¶çœŸå®æ€§ï¼Œå³åˆ¤æ–­ç©å®¶ $j$ åœ¨å›åˆ $t$ è°ˆåˆ¤è¿‡ç¨‹ä¸­æ‰€åšçš„é™ˆè¿°æ˜¯å¦çœŸå®ã€‚ç©å®¶ $j$ é™ˆè¿°çš„çœŸå®æ€§æ ¹æ®å…ˆå‰å›åˆçš„è®°å¿†è¿›è¡Œæ›´æ–°ï¼Œæ›´æ–°å…¬å¼ä¸º
    $\tau^{j}_{t}\leftarrow T(s_{t},s_{t+1},a^{j}_{t},m^{j,i}_{t})$ã€‚ç©å®¶ $j$ çš„å¯ä¿¡åº¦ $\gamma_{j}$
    å°†åŸºäºç©å®¶ $j$ çš„é™ˆè¿° $\tau^{j}_{t}$ è¿›è¡Œæ›´æ–°ï¼Œæ›´æ–°å…¬å¼ä¸º $\gamma_{j}\leftarrow p(\gamma_{j},\tau^{j}_{t-1})$ã€‚ç©å®¶çš„å¯ä¿¡åº¦
    $\vec{\gamma}$ æ˜¯ä¸€ä¸ªçŸ­æœŸè®°å¿†ï¼Œä»…é€‚ç”¨äºå½“å‰å›åˆã€‚å…¶ä»–æ”¶é›†æˆ–ç”Ÿæˆçš„æ•°æ®æ„æˆé•¿æœŸè®°å¿†ã€‚è¿™äº›æ•°æ®å°†è¢«ç»„åˆæˆå†å²è®°å½• $\mu\in M$ï¼Œç„¶åè¢«çº³å…¥è®°å¿†ã€‚
- en: 'Acquisition Experience via Self-Play Games. Self-play allows the agent to accumulate
    more experiences for self-evolution.Liu etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib34));
    Zhang etÂ al. ([2024a](https://arxiv.org/html/2407.06813v4#bib.bib72)) After training,
    when Richelieu is faced with a certain state, it can draw on a larger pool of
    similar historical experiences. Diverse evaluations enable Richelieu to reflect
    more comprehensively on the strategies it currently devises, leading to a stronger
    optimization of decision making. As self-play continues, the acquisition of new
    and better historical experiences by Richelieu will diminish. This means that
    Richelieuâ€™s capabilities will not improve indefinitely. At the same time, as the
    memory grows, selecting appropriate historical experiences becomes a new challenge.
    The chosen m experience $\vec{\eta_{t}}$ may be almost identical, which could
    actually reduce the amount of useful information available to Richelieu. As shown
    in FigureÂ [5](https://arxiv.org/html/2407.06813v4#S5.F5 "Figure 5 â€£ 5.2 Results
    â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy"),
    Richelieuâ€™s performance against Cicero Bakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7))
    becomes better with increasing training iterations. With the accumulation of experiences,
    Richelieuâ€™s win rate exhibited a steady increase with accumulated training iterations,
    ultimately plateauing at a stable performance level. In contrast, the defeated
    rate showed a consistent decrease, approaching an asymptotic value. These observations
    confirm the effectiveness of self-play in Richelieuâ€™s evolution.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 'é€šè¿‡è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆè·å–ç»éªŒã€‚è‡ªæˆ‘å¯¹å¼ˆä½¿å¾—ä»£ç†èƒ½å¤Ÿç§¯ç´¯æ›´å¤šç»éªŒï¼Œä»¥ä¾¿è‡ªæˆ‘è¿›åŒ–ã€‚Liuç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib34)ï¼‰ï¼›Zhangç­‰äººï¼ˆ[2024a](https://arxiv.org/html/2407.06813v4#bib.bib72)ï¼‰
    åœ¨è®­ç»ƒåï¼Œå½“Richelieué¢ä¸´æŸç§çŠ¶æ€æ—¶ï¼Œå®ƒå¯ä»¥ä»æ›´å¤§çš„ç±»ä¼¼å†å²ç»éªŒæ± ä¸­æ±²å–ç»éªŒã€‚å¤šæ ·åŒ–çš„è¯„ä¼°ä½¿å¾—Richelieuèƒ½å¤Ÿæ›´å…¨é¢åœ°åæ€å½“å‰åˆ¶å®šçš„ç­–ç•¥ï¼Œä»è€Œå¯¹å†³ç­–è¿›è¡Œæ›´å¼ºçš„ä¼˜åŒ–ã€‚éšç€è‡ªæˆ‘å¯¹å¼ˆçš„è¿›è¡Œï¼ŒRichelieuè·å–æ–°çš„å’Œæ›´å¥½çš„å†å²ç»éªŒçš„é€Ÿåº¦å°†ä¼šå‡ç¼“ã€‚è¿™æ„å‘³ç€Richelieuçš„èƒ½åŠ›ä¸ä¼šæ— é™æé«˜ã€‚åŒæ—¶ï¼Œéšç€è®°å¿†çš„å¢é•¿ï¼Œé€‰æ‹©åˆé€‚çš„å†å²ç»éªŒæˆä¸ºäº†ä¸€ä¸ªæ–°çš„æŒ‘æˆ˜ã€‚æ‰€é€‰çš„mä¸ªç»éªŒ$\vec{\eta_{t}}$å¯èƒ½å‡ ä¹ç›¸åŒï¼Œè¿™å®é™…ä¸Šå¯èƒ½å‡å°‘Richelieuå¯ä»¥åˆ©ç”¨çš„æœ‰æ•ˆä¿¡æ¯é‡ã€‚å¦‚å›¾[5](https://arxiv.org/html/2407.06813v4#S5.F5
    "Figure 5 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy")æ‰€ç¤ºï¼ŒRichelieuä¸Cicero Bakhtinç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib7)ï¼‰çš„å¯¹æˆ˜è¡¨ç°éšç€è®­ç»ƒè¿­ä»£æ¬¡æ•°çš„å¢åŠ è€Œæœ‰æ‰€æ”¹å–„ã€‚éšç€ç»éªŒçš„ç§¯ç´¯ï¼ŒRichelieuçš„èƒœç‡éšç€è®­ç»ƒè¿­ä»£çš„ç§¯ç´¯ç¨³æ­¥ä¸Šå‡ï¼Œæœ€ç»ˆåœ¨ç¨³å®šçš„è¡¨ç°æ°´å¹³ä¸Šè¶‹äºå¹³ç¨³ã€‚ç›¸åï¼Œå¤±è´¥ç‡åˆ™æ˜¾ç¤ºå‡ºæŒç»­ä¸‹é™ï¼Œæ¥è¿‘ä¸€ä¸ªæ¸è¿‘å€¼ã€‚è¿™äº›è§‚å¯Ÿç»“æœéªŒè¯äº†è‡ªæˆ‘å¯¹å¼ˆåœ¨Richelieuè¿›åŒ–ä¸­çš„æœ‰æ•ˆæ€§ã€‚'
- en: 5 Experiment
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 å®éªŒ
- en: 'In the experiments, our goal is to answer the following questions: 1) Mastery
    of Non-Press Diplomacy: Can our agent master the non-press diplomacy against baselines?
    2) Competing with State-of-the-Art: Can our agent surpass the performance of the
    current state-of-the-art agents in press diplomacy? 3) Compatibility with LLMs:
    Can our self-evolving framework be compatible with different LLMs? 4) Contribution
    of Framework Modules: Do the individual modules within our framework contribute
    to the overall improvement of our agentâ€™s performance? 5) Social Reasoning: Can
    Richelieu accurately infer the true intentions of other players and reasonably
    determine the relationships of ally or enemy with them? The implementation of
    our method can be found at: [https://github.com/todexter3/Richelieu.git](https://github.com/todexter3/Richelieu.git)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š1ï¼‰éæ–½å‹å¤–äº¤çš„æŒæ¡ï¼šæˆ‘ä»¬çš„ä»£ç†èƒ½å¦åœ¨ä¸åŸºçº¿çš„æ¯”è¾ƒä¸­æŒæ¡éæ–½å‹å¤–äº¤ï¼Ÿ2ï¼‰ä¸æœ€å…ˆè¿›æŠ€æœ¯çš„ç«äº‰ï¼šæˆ‘ä»¬çš„ä»£ç†èƒ½å¦è¶…è¶Šå½“å‰æœ€å…ˆè¿›ä»£ç†åœ¨æ–½å‹å¤–äº¤ä¸­çš„è¡¨ç°ï¼Ÿ3ï¼‰ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…¼å®¹æ€§ï¼šæˆ‘ä»¬çš„è‡ªæˆ‘è¿›åŒ–æ¡†æ¶èƒ½å¦ä¸ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹å…¼å®¹ï¼Ÿ4ï¼‰æ¡†æ¶æ¨¡å—çš„è´¡çŒ®ï¼šæˆ‘ä»¬æ¡†æ¶ä¸­çš„å„ä¸ªæ¨¡å—æ˜¯å¦æœ‰åŠ©äºæå‡ä»£ç†çš„æ•´ä½“è¡¨ç°ï¼Ÿ5ï¼‰ç¤¾ä¼šæ¨ç†ï¼šRichelieuèƒ½å¦å‡†ç¡®æ¨æ–­å…¶ä»–ç©å®¶çš„çœŸå®æ„å›¾ï¼Œå¹¶åˆç†åˆ¤æ–­ä¸ä»–ä»¬çš„ç›Ÿå‹æˆ–æ•Œäººå…³ç³»ï¼Ÿæˆ‘ä»¬æ–¹æ³•çš„å®ç°å¯ä»¥åœ¨æ­¤æ‰¾åˆ°ï¼š[https://github.com/todexter3/Richelieu.git](https://github.com/todexter3/Richelieu.git)
- en: 5.1 Experimental Setup
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 å®éªŒè®¾ç½®
- en: Environment. The widely-used open source Diplomacy game platform introduced
    by Paquette etÂ al. ([2019](https://arxiv.org/html/2407.06813v4#bib.bib40)) is
    adopted for evaluating Richelieu against other models. It is easy to switch between
    no-press (with negotiation between players) and press (no negotiation between
    players) games based on this platform, facilitating comparison on both settings.
    The platform also contains over 10,000 human game data on which previous approaches
    are trained. Note that our method does not need them. In each game, a model will
    play the role of one randomly selected country to compete against countries controlled
    by other methods. It wins if occupying all the supply centers and loses vice versa.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ç¯å¢ƒã€‚ç”±Paquetteç­‰äººï¼ˆ[2019](https://arxiv.org/html/2407.06813v4#bib.bib40)ï¼‰ä»‹ç»çš„å¹¿æ³›ä½¿ç”¨çš„å¼€æºã€Šå¤–äº¤ã€‹æ¸¸æˆå¹³å°è¢«é‡‡ç”¨ç”¨äºè¯„ä¼°Richelieuä¸å…¶ä»–æ¨¡å‹çš„å¯¹æ¯”ã€‚è¯¥å¹³å°å¯ä»¥è½»æ¾åˆ‡æ¢æ— æ–°é—»ï¼ˆç©å®¶ä¹‹é—´è¿›è¡Œè°ˆåˆ¤ï¼‰å’Œæœ‰æ–°é—»ï¼ˆç©å®¶ä¹‹é—´ä¸è¿›è¡Œè°ˆåˆ¤ï¼‰ä¸¤ç§æ¸¸æˆæ¨¡å¼ï¼Œä»è€Œä¾¿äºåœ¨ä¸¤ç§è®¾ç½®ä¸‹è¿›è¡Œæ¯”è¾ƒã€‚è¯¥å¹³å°è¿˜åŒ…å«äº†è¶…è¿‡10,000æ¡äººç±»æ¸¸æˆæ•°æ®ï¼Œä¹‹å‰çš„ç ”ç©¶æ–¹æ³•å°±æ˜¯åœ¨è¿™äº›æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¹¶ä¸ä¾èµ–è¿™äº›æ•°æ®ã€‚åœ¨æ¯åœºæ¸¸æˆä¸­ï¼Œä¸€ä¸ªæ¨¡å‹å°†æ‰®æ¼”ä¸€ä¸ªéšæœºé€‰æ‹©çš„å›½å®¶ï¼Œä¸å…¶ä»–æ–¹æ³•æ§åˆ¶çš„å›½å®¶è¿›è¡Œç«äº‰ã€‚å¦‚æœå é¢†äº†æ‰€æœ‰è¡¥ç»™ä¸­å¿ƒï¼Œåˆ™è·èƒœï¼Œå¦åˆ™å¤±è´¥ã€‚
- en: 'Table 1: The results of our method playing against Cicero.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨1ï¼šæˆ‘ä»¬çš„æ–¹æ³•ä¸Ciceroå¯¹æˆ˜çš„ç»“æœã€‚
- en: Model Win$\uparrow$ Most SC$\uparrow$ Survived$\uparrow$ Defeated$\downarrow$
    Richelieu_1 6.20% 9.40% 38.90% 45.50% Richelieu_2 6.60% 7.80% 40.80% 44.80% Richelieu_3
    7.10% 9.30% 39.90% 43.70% Richelieu_4 7.40% 8.00% 40.20% 44.40% Cicero_1 5.90%
    6.50% 41.50% 46.10% Cicero_2 6.30% 7.20% 42.50% 44.00% Cicero_3 5.90% 7.00% 41.60%
    45.50% Richelieu 6.83% 8.63% 39.95% 44.60% Cicero 6.03% 6.90% 41.87% 45.20%
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹ èƒœç‡$\uparrow$ æœ€å¤§SC$\uparrow$ å­˜æ´»ç‡$\uparrow$ è¢«å‡»è´¥ç‡$\downarrow$ Richelieu_1 6.20%
    9.40% 38.90% 45.50% Richelieu_2 6.60% 7.80% 40.80% 44.80% Richelieu_3 7.10% 9.30%
    39.90% 43.70% Richelieu_4 7.40% 8.00% 40.20% 44.40% Cicero_1 5.90% 6.50% 41.50%
    46.10% Cicero_2 6.30% 7.20% 42.50% 44.00% Cicero_3 5.90% 7.00% 41.60% 45.50% Richelieu
    6.83% 8.63% 39.95% 44.60% Cicero 6.03% 6.90% 41.87% 45.20%
- en: Model Win$\uparrow$ Most SC$\uparrow$ Survived$\uparrow$ Defeated$\downarrow$
    Richelieu_1 6.30% 7.90% 39.40% 46.40% Richelieu_2 6.60% 8.30% 41.20% 43.90% Richelieu_3
    7.20% 8.70% 41.70% 42.40% Cicero_1 5.80% 6.70% 41.20% 46.30% Cicero_2 6.50% 7.20%
    42.50% 43.80% Cicero_3 6.00% 7.00% 41.60% 45.40% Cicero_4 6.10% 7.20% 42.30% 44.40%
    Richelieu 6.70% 8.30% 40.77% 44.23% Cicero 6.10% 7.03% 41.90% 44.98%
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹ èƒœç‡$\uparrow$ æœ€å¤§SC$\uparrow$ å­˜æ´»ç‡$\uparrow$ è¢«å‡»è´¥ç‡$\downarrow$ Richelieu_1 6.30%
    7.90% 39.40% 46.40% Richelieu_2 6.60% 8.30% 41.20% 43.90% Richelieu_3 7.20% 8.70%
    41.70% 42.40% Cicero_1 5.80% 6.70% 41.20% 46.30% Cicero_2 6.50% 7.20% 42.50% 43.80%
    Cicero_3 6.00% 7.00% 41.60% 45.40% Cicero_4 6.10% 7.20% 42.30% 44.40% Richelieu
    6.70% 8.30% 40.77% 44.23% Cicero 6.10% 7.03% 41.90% 44.98%
- en: 'Evaluation Metrics. We evaluate the models based on the results of multiple
    rounds of games. In each round, the model is randomly assigned a country to control.
    Typically, 1000 rounds are played to obtain the average results. We evaluate the
    models in two metrics. One is based on the win rate, Most SC rate, survived rate,
    and defeated rate. There are four possible outcomes for each country in the game.
    If a country loses all its supply centers (SC), it is eliminated and recorded
    as â€œdefeated". If a country occupies 18 or more out of 34 supply centers, the
    game ends, and that country is recorded as â€œwin", while other countries are recorded
    as â€œdefeated". In other cases, the game ends in a draw. The country with the most
    supply centers is recorded as â€œMost SC", the countries that have been eliminated
    are recorded as â€œdefeated", and the other countries are recorded as â€œSurvived".
    The other is based on the scores obtained by the models after multiple rounds
    of competition. To compare the capabilities of multiple models, we use C-Diplo
    ArgirArcher ([2024](https://arxiv.org/html/2407.06813v4#bib.bib4)), a scoring
    system. This system is used in many international diplomacy competitions. The
    scoring method is as follows: If a player wins by occupying 18 or more supply
    centers, the player scores 93 points, and each of the other six players scores
    1 point. If the game ends in a draw, the player with the most centers scores 37
    points. The second player with the most centers scores 14 points. The third player
    with the most centers scores 7 points. Each player scores 1 point per center owned.
    Each player also scores 1 point for participating. In this way, regardless of
    the game outcome, a total of 99 points will be distributed among the players in
    each game.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¯„ä¼°æŒ‡æ ‡ã€‚æˆ‘ä»¬æ ¹æ®å¤šè½®æ¸¸æˆçš„ç»“æœæ¥è¯„ä¼°è¿™äº›æ¨¡å‹ã€‚åœ¨æ¯ä¸€è½®ä¸­ï¼Œæ¨¡å‹ä¼šéšæœºåˆ†é…ä¸€ä¸ªå›½å®¶è¿›è¡Œæ§åˆ¶ã€‚é€šå¸¸ä¼šè¿›è¡Œ1000è½®æ¸¸æˆä»¥è·å¾—å¹³å‡ç»“æœã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªç»´åº¦è¯„ä¼°æ¨¡å‹ã€‚ä¸€ä¸ªæ˜¯åŸºäºèƒœç‡ã€æœ€å¤šSCç‡ã€ç”Ÿè¿˜ç‡å’Œè¢«æ·˜æ±°ç‡ã€‚æ¯ä¸ªå›½å®¶åœ¨æ¸¸æˆä¸­å¯èƒ½æœ‰å››ç§ç»“æœã€‚å¦‚æœä¸€ä¸ªå›½å®¶å¤±å»æ‰€æœ‰çš„è¡¥ç»™ä¸­å¿ƒï¼ˆSCï¼‰ï¼Œåˆ™è¢«æ·˜æ±°å¹¶è®°å½•ä¸ºâ€œè¢«æ·˜æ±°â€ã€‚å¦‚æœä¸€ä¸ªå›½å®¶å é¢†äº†34ä¸ªè¡¥ç»™ä¸­å¿ƒä¸­çš„18ä¸ªæˆ–æ›´å¤šï¼Œæ¸¸æˆç»“æŸï¼Œè¯¥å›½å®¶è¢«è®°å½•ä¸ºâ€œèƒœåˆ©â€ï¼Œå…¶ä»–å›½å®¶åˆ™è®°å½•ä¸ºâ€œè¢«æ·˜æ±°â€ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ¸¸æˆä»¥å¹³å±€ç»“æŸã€‚æ‹¥æœ‰æœ€å¤šè¡¥ç»™ä¸­å¿ƒçš„å›½å®¶è¢«è®°å½•ä¸ºâ€œæœ€å¤šSCâ€ï¼Œè¢«æ·˜æ±°çš„å›½å®¶è®°å½•ä¸ºâ€œè¢«æ·˜æ±°â€ï¼Œå…¶ä½™å›½å®¶è®°å½•ä¸ºâ€œç”Ÿè¿˜â€ã€‚å¦ä¸€ä¸ªæ˜¯åŸºäºæ¨¡å‹åœ¨å¤šè½®ç«äº‰åè·å¾—çš„å¾—åˆ†ã€‚ä¸ºäº†æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†C-Diplo
    ArgirArcherï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib4)ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯„åˆ†ç³»ç»Ÿï¼Œåœ¨è®¸å¤šå›½é™…å¤–äº¤æ¯”èµ›ä¸­éƒ½æœ‰ä½¿ç”¨ã€‚å…¶è¯„åˆ†æ–¹æ³•å¦‚ä¸‹ï¼šå¦‚æœä¸€ä¸ªç©å®¶é€šè¿‡å é¢†18ä¸ªæˆ–æ›´å¤šè¡¥ç»™ä¸­å¿ƒè·èƒœï¼Œè¯¥ç©å®¶å¾—93åˆ†ï¼Œå…¶ä»–å…­ä¸ªç©å®¶å„å¾—1åˆ†ã€‚å¦‚æœæ¸¸æˆä»¥å¹³å±€ç»“æŸï¼Œæ‹¥æœ‰æœ€å¤šè¡¥ç»™ä¸­å¿ƒçš„ç©å®¶å¾—37åˆ†ï¼Œç¬¬äºŒå¤šè¡¥ç»™ä¸­å¿ƒçš„ç©å®¶å¾—14åˆ†ï¼Œç¬¬ä¸‰å¤šè¡¥ç»™ä¸­å¿ƒçš„ç©å®¶å¾—7åˆ†ã€‚æ¯ä¸ªç©å®¶æ¯æ‹¥æœ‰ä¸€ä¸ªè¡¥ç»™ä¸­å¿ƒå°±å¾—1åˆ†ã€‚æ¯ä¸ªç©å®¶å‚ä¸æ¯”èµ›ä¹Ÿå¯ä»¥å¾—1åˆ†ã€‚è¿™æ ·ï¼Œæ— è®ºæ¯”èµ›ç»“æœå¦‚ä½•ï¼Œæ¯åœºæ¯”èµ›çš„æ€»å¾—åˆ†å°†åˆ†é…ç»™99åˆ†ã€‚
- en: Baselines. We select six previous models as baselines for comparison. Among
    them, CiceroBakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7))
    by Meta is a diplomacy model with a negotiation module. The SL-DipNet and RL-DipNet
    Paquette etÂ al. ([2019](https://arxiv.org/html/2407.06813v4#bib.bib40)), the BRPI
    Anthony etÂ al. ([2020](https://arxiv.org/html/2407.06813v4#bib.bib3)), the SearchBot
    Gray etÂ al. ([2020](https://arxiv.org/html/2407.06813v4#bib.bib19)), and the DORABakhtin
    etÂ al. ([2021](https://arxiv.org/html/2407.06813v4#bib.bib6)) are no-press diplomacy
    models. We also build a LLM-based agent, AutoGPT Yang etÂ al. ([2023a](https://arxiv.org/html/2407.06813v4#bib.bib65)).
    In experiments, we set a temperature of 0.3 to ensure a relatively stable generation
    of LLM policies. The overall reasoning framework also ensure the stability and
    consistency in the AI agentâ€™s performance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºå‡†æ¨¡å‹ã€‚æˆ‘ä»¬é€‰æ‹©äº†å…­ä¸ªå…ˆå‰çš„æ¨¡å‹ä½œä¸ºåŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚å…¶ä¸­ï¼ŒMetaå…¬å¸æå‡ºçš„CiceroBakhtinç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib7)ï¼‰æ˜¯ä¸€ä¸ªå…·æœ‰è°ˆåˆ¤æ¨¡å—çš„å¤–äº¤æ¨¡å‹ã€‚SL-DipNetå’ŒRL-DipNet
    Paquetteç­‰äººï¼ˆ[2019](https://arxiv.org/html/2407.06813v4#bib.bib40)ï¼‰ï¼ŒBRPI Anthonyç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib3)ï¼‰ï¼ŒSearchBot
    Grayç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib19)ï¼‰ï¼Œä»¥åŠDORABakhtinç­‰äººï¼ˆ[2021](https://arxiv.org/html/2407.06813v4#bib.bib6)ï¼‰æ˜¯æ— å‹åŠ›å¤–äº¤æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†ä¸€ä¸ªåŸºäºLLMçš„ä»£ç†ï¼ŒAutoGPT
    Yangç­‰äººï¼ˆ[2023a](https://arxiv.org/html/2407.06813v4#bib.bib65)ï¼‰ã€‚åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†æ¸©åº¦ä¸º0.3ï¼Œä»¥ç¡®ä¿LLMç­–ç•¥ç”Ÿæˆçš„ç›¸å¯¹ç¨³å®šã€‚æ€»ä½“æ¨ç†æ¡†æ¶ä¹Ÿç¡®ä¿äº†AIä»£ç†åœ¨è¡¨ç°ä¸Šçš„ç¨³å®šæ€§å’Œä¸€è‡´æ€§ã€‚
- en: 5.2 Results
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 ç»“æœ
- en: '![Refer to caption](img/aac0efd6b958d53d75cf677011e587c2.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜æ–‡å­—](img/aac0efd6b958d53d75cf677011e587c2.png)'
- en: 'Figure 4: The relative scores among 7 different agents when massively playing
    on the no-press setting. Each point shows the ratio of the modelâ€™s score on the
    vertical axis to the score gained by the model on the horizontal axis.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4ï¼š7ä¸ªä¸åŒä»£ç†åœ¨æ— å‹åŠ›è®¾ç½®ä¸‹å¤§é‡æ¸¸æˆæ—¶çš„ç›¸å¯¹å¾—åˆ†ã€‚æ¯ä¸ªç‚¹è¡¨ç¤ºæ¨¡å‹åœ¨çºµè½´ä¸Šçš„å¾—åˆ†ä¸æ¨¡å‹åœ¨æ¨ªè½´ä¸Šçš„å¾—åˆ†ä¹‹æ¯”ã€‚
- en: 'Massively Play with Baselines on no-press setting. We let Richelieu compete
    with the other six models including CiceroBakhtin etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib7)),
    SL-DipNet and RL-DipNet Paquette etÂ al. ([2019](https://arxiv.org/html/2407.06813v4#bib.bib40)),
    BRPI Anthony etÂ al. ([2020](https://arxiv.org/html/2407.06813v4#bib.bib3)), SearchBot
    Gray etÂ al. ([2020](https://arxiv.org/html/2407.06813v4#bib.bib19)), and DORABakhtin
    etÂ al. ([2021](https://arxiv.org/html/2407.06813v4#bib.bib6)) on No-Press Diplomacy,
    in which players make moves without communication. Figure Â [4](https://arxiv.org/html/2407.06813v4#S5.F4
    "Figure 4 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy") indicates that Richelieu outperforms other previous models
    relying on human game data. In contrast, Richelieu does not need such data but
    outperforms these methods by a clear margin, which demonstrates the outstanding
    planning capability of Richelieu.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨æ— å‹åŠ›è®¾ç½®ä¸‹ä¸åŸºçº¿è¿›è¡Œå¤§è§„æ¨¡å¯¹æˆ˜ã€‚æˆ‘ä»¬è®© Richelieu ä¸å…¶ä»–å…­ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æˆ˜ï¼ŒåŒ…æ‹¬ CiceroBakhtin ç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib7)ï¼‰ã€SL-DipNet
    å’Œ RL-DipNet Paquette ç­‰äººï¼ˆ[2019](https://arxiv.org/html/2407.06813v4#bib.bib40)ï¼‰ã€BRPI
    Anthony ç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib3)ï¼‰ã€SearchBot Gray
    ç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib19)ï¼‰ä»¥åŠ DORABakhtin ç­‰äººï¼ˆ[2021](https://arxiv.org/html/2407.06813v4#bib.bib6)ï¼‰åœ¨æ— å‹åŠ›å¤–äº¤æ¸¸æˆä¸­å¯¹æˆ˜ï¼Œåœ¨è¯¥æ¸¸æˆä¸­ç©å®¶è¿›è¡Œæ— æ²Ÿé€šçš„è¡ŒåŠ¨ã€‚å›¾
    [4](https://arxiv.org/html/2407.06813v4#S5.F4 "Figure 4 â€£ 5.2 Results â€£ 5 Experiment
    â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy") æ˜¾ç¤º Richelieu åœ¨å¯¹æ¯”å…¶ä»–ä¾èµ–äººç±»æ¸¸æˆæ•°æ®çš„æ¨¡å‹æ—¶ï¼Œè¡¨ç°ä¼˜å¼‚ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒRichelieu
    ä¸éœ€è¦è¿™ç§æ•°æ®ï¼Œä½†ä»ç„¶æ˜æ˜¾è¶…è¶Šè¿™äº›æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶å“è¶Šçš„è§„åˆ’èƒ½åŠ›ã€‚'
- en: 'Play against Cicero on press setting. We also evaluate Richelieu through competition
    against Cicero in the challenging scenario where negotiation is enabled. Specifically,
    we randomly assign three countries to one model and the remaining four to another.
    After playing several rounds of the game, the win rate, most SC rate, survived
    rate, and the defeated rate is calculated using a weighted average for evaluation.
    Table Â [1](https://arxiv.org/html/2407.06813v4#S5.T1 "Table 1 â€£ 5.1 Experimental
    Setup â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy")
    demonstrates the competitive performance of Richelieu in comparison to Cicero.
    Richelieuâ€™s win rate is approximately 0.7% higher than Ciceroâ€™s. If the Most SC
    rate is also taken into account, Richelieu is about 2% higher than Cicero. At
    the same time, Richelieuâ€™s loss rate is also 0.6% lower. According to our scoring
    system, Richelieuâ€™s score is about 10% higher than Ciceroâ€™s. This is nontrivial
    especially when Richelieu is trained in a self-play game without humans and the
    opponents are trained with the data from human players.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨å‹åŠ›è®¾ç½®ä¸‹ä¸ Cicero å¯¹æˆ˜ã€‚æˆ‘ä»¬è¿˜é€šè¿‡ä¸ Cicero åœ¨å¯ç”¨è°ˆåˆ¤çš„æŒ‘æˆ˜æ€§åœºæ™¯ä¸‹çš„å¯¹æŠ—ï¼Œè¯„ä¼°äº† Richelieuã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬éšæœºå°†ä¸‰ä¸ªå›½å®¶åˆ†é…ç»™ä¸€ä¸ªæ¨¡å‹ï¼Œå°†å…¶ä½™å››ä¸ªå›½å®¶åˆ†é…ç»™å¦ä¸€ä¸ªæ¨¡å‹ã€‚åœ¨è¿›è¡Œå¤šè½®æ¸¸æˆåï¼Œä½¿ç”¨åŠ æƒå¹³å‡è®¡ç®—èƒœç‡ã€æœ€å¤š
    SC æ¯”ç‡ã€å­˜æ´»ç‡å’Œå¤±è´¥ç‡è¿›è¡Œè¯„ä¼°ã€‚è¡¨ [1](https://arxiv.org/html/2407.06813v4#S5.T1 "Table 1 â€£ 5.1
    Experimental Setup â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy") å±•ç¤ºäº† Richelieu ä¸ Cicero ç«äº‰æ—¶çš„è¡¨ç°ã€‚Richelieu çš„èƒœç‡å¤§çº¦æ¯” Cicero é«˜ 0.7%ã€‚å¦‚æœè¿˜è€ƒè™‘åˆ°æœ€å¤š
    SC æ¯”ç‡ï¼ŒRichelieu æ¯” Cicero é«˜çº¦ 2%ã€‚åŒæ—¶ï¼ŒRichelieu çš„å¤±è´¥ç‡ä¹Ÿæ¯” Cicero ä½ 0.6%ã€‚æ ¹æ®æˆ‘ä»¬çš„è¯„åˆ†ç³»ç»Ÿï¼ŒRichelieu
    çš„å¾—åˆ†å¤§çº¦æ¯” Cicero é«˜ 10%ã€‚è¿™å¹¶ä¸ç®€å•ï¼Œå°¤å…¶æ˜¯å½“ Richelieu åœ¨æ²¡æœ‰äººå·¥å¹²é¢„çš„è‡ªå¯¹å¼ˆæ¸¸æˆä¸­è®­ç»ƒï¼Œè€Œå¯¹æ‰‹åˆ™æ˜¯é€šè¿‡äººç±»ç©å®¶çš„æ•°æ®è¿›è¡Œè®­ç»ƒæ—¶ã€‚'
- en: 'Although Richelieuâ€™s win rate improvement compared to Cicero is not significant,
    the relative value of the improvement is quite large. Moreover, the main reason
    for the modest improvement is that in the seven countries, there are three or
    four controled by Richelieu with similar abilities, which often results in the
    game ending in a draw. Moreover, we observed a large gap by comparing the scores
    the agents gained in the massively play with baselines on no-press setting showed
    in FigureÂ [4](https://arxiv.org/html/2407.06813v4#S5.F4 "Figure 4 â€£ 5.2 Results
    â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy").
    Our agentâ€™s score is about 10% higher than Ciceroâ€™s.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 'å°½ç®¡ä¸ Cicero ç›¸æ¯”ï¼ŒRichelieu çš„èƒœç‡æå‡ä¸æ˜¾è‘—ï¼Œä½†å…¶ç›¸å¯¹æå‡çš„ä»·å€¼éå¸¸å¤§ã€‚æ­¤å¤–ï¼Œèƒœç‡æé«˜å¹…åº¦é€‚ä¸­çš„ä¸»è¦åŸå› æ˜¯ï¼Œåœ¨ä¸ƒä¸ªå›½å®¶ä¸­ï¼Œæœ‰ä¸‰ä¸ªæˆ–å››ä¸ªå›½å®¶ç”±èƒ½åŠ›ç›¸ä¼¼çš„
    Richelieu æ§åˆ¶ï¼Œè¿™å¸¸å¸¸å¯¼è‡´æ¸¸æˆä»¥å¹³å±€ç»“æŸã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¯”è¾ƒåœ¨æ— å‹åŠ›è®¾ç½®ä¸‹ä¸åŸºçº¿è¿›è¡Œå¤§è§„æ¨¡å¯¹æˆ˜ä¸­å±•ç¤ºçš„å¾—åˆ†ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä¸€ä¸ªæ˜æ˜¾çš„å·®è·ï¼Œå›¾ [4](https://arxiv.org/html/2407.06813v4#S5.F4
    "Figure 4 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy") æ˜¾ç¤ºæˆ‘ä»¬çš„ä»£ç†å¾—åˆ†æ¯” Cicero é«˜å‡ºçº¦ 10%ã€‚'
- en: 'Table 2: The results of our method playing against AutoGPT.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 2ï¼šæˆ‘ä»¬æ–¹æ³•ä¸ AutoGPT å¯¹æˆ˜çš„ç»“æœã€‚
- en: '| Model | Win$\uparrow$ | Most SC$\uparrow$ | Survived$\uparrow$ | Defeated$\downarrow$
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| æ¨¡å‹ | èƒœç‡$\uparrow$ | æœ€å¤š SC$\uparrow$ | å­˜æ´»ç‡$\uparrow$ | å¤±è´¥ç‡$\downarrow$ |'
- en: '| Richelieu_1 | 9.30% | 18.20% | 37.90% | 34.60% |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Richelieu_1 | 9.30% | 18.20% | 37.90% | 34.60% |'
- en: '| Richelieu_2 | 9.90% | 19.40% | 37.70% | 33.00% |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Richelieu_2 | 9.90% | 19.40% | 37.70% | 33.00% |'
- en: '| Richelieu_3 | 8.10% | 17.40% | 39.20% | 35.30% |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| Richelieu_3 | 8.10% | 17.40% | 39.20% | 35.30% |'
- en: '| AutoGPT_1 | 1.20% | 4.60% | 32.40% | 61.80% |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| AutoGPT_1 | 1.20% | 4.60% | 32.40% | 61.80% |'
- en: '| AutoGPT_2 | 1.20% | 4.20% | 34.40% | 60.20% |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| AutoGPT_2 | 1.20% | 4.20% | 34.40% | 60.20% |'
- en: '| AutoGPT_3 | 1.50% | 4.00% | 32.50% | 62.00% |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| AutoGPT_3 | 1.50% | 4.00% | 32.50% | 62.00% |'
- en: '| AutoGPT_4 | 2.60% | 3.60% | 32.30% | 61.50% |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| AutoGPT_4 | 2.60% | 3.60% | 32.30% | 61.50% |'
- en: '| Richelieu | 9.10% | 18.33% | 38.27% | 34.30% |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Richelieu | 9.10% | 18.33% | 38.27% | 34.30% |'
- en: '| AutoGPT | 1.63% | 4.10% | 32.90% | 61.37% |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| AutoGPT | 1.63% | 4.10% | 32.90% | 61.37% |'
- en: 'Play against AutoGPT on press setting. We further built an LLM-based agent
    using AutoGPT and compared it with our agent. In the testing, we randomly select
    three countries to be controlled by Richelieu, and the other four countries to
    be controlled by AutoGPT. Note that the agent controls each country independently.
    The results are showed in Table Â [2](https://arxiv.org/html/2407.06813v4#S5.T2
    "Table 2 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy"). The results show that our model outperforms the existing LLM
    baseline.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¸AutoGPTè¿›è¡Œå‹åŠ›è®¾ç½®ä¸‹çš„å¯¹æˆ˜ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æ„å»ºäº†ä¸€ä¸ªåŸºäºLLMçš„æ™ºèƒ½ä½“â€”â€”AutoGPTï¼Œå¹¶å°†å…¶ä¸æˆ‘ä»¬çš„æ™ºèƒ½ä½“è¿›è¡Œäº†å¯¹æ¯”ã€‚åœ¨æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬éšæœºé€‰æ‹©ä¸‰ä¸ªå›½å®¶ç”±Richelieuæ§åˆ¶ï¼Œå¦å¤–å››ä¸ªå›½å®¶ç”±AutoGPTæ§åˆ¶ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ™ºèƒ½ä½“ç‹¬ç«‹æ§åˆ¶æ¯ä¸ªå›½å®¶ã€‚å…·ä½“ç»“æœè§è¡¨æ ¼[2](https://arxiv.org/html/2407.06813v4#S5.T2
    "Table 2 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy")ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼˜äºç°æœ‰çš„LLMåŸºå‡†æ¨¡å‹ã€‚'
- en: 'Generalization of self-evolving framework to different LLMs. To demonstrate
    the effectiveness of our framework in a variety of LLM, we conducted experiments
    using four models: [GPT4.0](https://openai.com/index/gpt-4/), [ERNIE Bot](https://yiyan.baidu.com/welcome),
    [Spark Desk](https://xinghuo.xfyun.cn/), and [Llama 3](https://llama.meta.com/llama3).
    As the number of training iterations increases, Richelieuâ€™s win rate steadily
    improves while the defeated rate declines, ultimately reaching a relatively stable
    outcome. This suggests that our self-play method is effective. After training,
    the win rate using GPT4.0 increased from 1.5% lower than Ciceroâ€™s to about 0.7%
    higher than Ciceroâ€™s. The win rate using llama3 increased from 2.3% lower than
    Ciceroâ€™s to almost equal to Ciceroâ€™s. The win rates using Models Spark Desk and
    ERNIE Bot increased from 3% and 4% lower than Ciceroâ€™s to 0.7% and 1.6% lower
    than Ciceroâ€™s, respectively. The experimental results show that, despite variations
    in Richelieuâ€™s performance due to the inherent differences in the capabilities
    of these LLMs, as illustrated in FigureÂ [5](https://arxiv.org/html/2407.06813v4#S5.F5
    "Figure 5 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy"), our framework and training approach significantly enhance
    the capabilities of all LLMs.This indicates the generalization of a self-evolving
    framework to various LLMs.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 'è‡ªæˆ‘è¿›åŒ–æ¡†æ¶çš„æ³›åŒ–åˆ°ä¸åŒçš„LLMã€‚ä¸ºäº†å±•ç¤ºæˆ‘ä»¬æ¡†æ¶åœ¨å¤šç§LLMä¸­çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å››ä¸ªæ¨¡å‹è¿›è¡Œäº†å®éªŒï¼š[GPT4.0](https://openai.com/index/gpt-4/)ã€[ERNIE
    Bot](https://yiyan.baidu.com/welcome)ã€[Spark Desk](https://xinghuo.xfyun.cn/)
    å’Œ [Llama 3](https://llama.meta.com/llama3)ã€‚éšç€è®­ç»ƒè¿­ä»£æ¬¡æ•°çš„å¢åŠ ï¼ŒRichelieuçš„èƒœç‡ç¨³æ­¥æå‡ï¼Œå¤±è´¥ç‡ä¸‹é™ï¼Œæœ€ç»ˆè¾¾åˆ°ç›¸å¯¹ç¨³å®šçš„ç»“æœã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„è‡ªæˆ‘å¯¹å¼ˆæ–¹æ³•æ˜¯æœ‰æ•ˆçš„ã€‚è®­ç»ƒåï¼Œä½¿ç”¨GPT4.0æ—¶ï¼Œèƒœç‡ä»æ¯”Ciceroä½1.5%å¢åŠ åˆ°æ¯”Ciceroé«˜çº¦0.7%ï¼›ä½¿ç”¨Llama3æ—¶ï¼Œèƒœç‡ä»æ¯”Ciceroä½2.3%å¢åŠ åˆ°å‡ ä¹ä¸Ciceroç›¸ç­‰ï¼›ä½¿ç”¨Spark
    Deskå’ŒERNIE Botæ—¶ï¼Œèƒœç‡ä»æ¯”Ciceroä½3%å’Œ4%åˆ†åˆ«å¢åŠ åˆ°æ¯”Ciceroä½0.7%å’Œ1.6%ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡ç”±äºè¿™äº›LLMçš„å›ºæœ‰èƒ½åŠ›å·®å¼‚ï¼ŒRichelieuçš„è¡¨ç°å­˜åœ¨æ³¢åŠ¨ï¼ˆå¦‚å›¾[5](https://arxiv.org/html/2407.06813v4#S5.F5
    "Figure 5 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy")æ‰€ç¤ºï¼‰ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å’Œè®­ç»ƒæ–¹æ³•æ˜¾è‘—æå‡äº†æ‰€æœ‰LLMçš„èƒ½åŠ›ã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„è‡ªæˆ‘è¿›åŒ–æ¡†æ¶å…·æœ‰å¹¿æ³›çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€‚åº”å„ç§LLMã€‚'
- en: 'In order to demonstrate the effect of the memory from the self-play game on
    the strategy of our agent, we found two turns with similar states in different
    rounds, one before self-play and the other after. The cases are showed in AppendixÂ [B.1](https://arxiv.org/html/2407.06813v4#A2.SS1
    "B.1 Cases of the Effect of the Memory from Self-Playing and Collaboration â€£ Appendix
    B Cases â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy").'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¸ºäº†å±•ç¤ºè‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆä¸­çš„è®°å¿†å¯¹æˆ‘ä»¬æ™ºèƒ½ä½“ç­–ç•¥çš„å½±å“ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†ä¸¤ä¸ªçŠ¶æ€ç›¸ä¼¼çš„å›åˆï¼Œåˆ†åˆ«æ˜¯åœ¨è‡ªæˆ‘å¯¹å¼ˆå‰åçš„ä¸åŒå›åˆã€‚å…·ä½“æ¡ˆä¾‹è§é™„å½•[B.1](https://arxiv.org/html/2407.06813v4#A2.SS1
    "B.1 Cases of the Effect of the Memory from Self-Playing and Collaboration â€£ Appendix
    B Cases â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy")ã€‚'
- en: '![Refer to caption](img/a27fc5465c3d034b87704b8d57112155.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§æ ‡é¢˜](img/a27fc5465c3d034b87704b8d57112155.png)'
- en: 'Figure 5: Richelieu modules benefit different LLMs. The solid line represents
    the experimental results for Richelieu, while the dashed line corresponds to Cicero.
    Different colors are used for different LLMs. The horizontal axis represents the
    logarithm of the number of training sessions, and the vertical axis denotes the
    rate.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾5ï¼šRichelieuæ¨¡å—å¯¹ä¸åŒLLMçš„ç›Šå¤„ã€‚å®çº¿è¡¨ç¤ºRichelieuçš„å®éªŒç»“æœï¼Œè€Œè™šçº¿å¯¹åº”Ciceroã€‚ä¸åŒçš„é¢œè‰²ä»£è¡¨ä¸åŒçš„LLMã€‚æ¨ªè½´è¡¨ç¤ºè®­ç»ƒæ¬¡æ•°çš„å¯¹æ•°ï¼Œçºµè½´è¡¨ç¤ºæ¯”ç‡ã€‚
- en: 'Table 3: Ablation study: average results of 3 Richelieu vs. 4 Cicero.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨3ï¼šæ¶ˆèç ”ç©¶ï¼š3ä¸ªRichelieuä¸4ä¸ªCiceroçš„å¹³å‡ç»“æœã€‚
- en: Modeling others sub-goals Negotiation pipeline Reflection with Memory Self-play
    Win $\uparrow$ Most SC$\uparrow$ Survived$\uparrow$ Defeated$\downarrow$ 0.4%
    0.7% 4.3% 94.6% âœ“ 0.7% 1.2% 10.6% 87.5% âœ“ âœ“ 3.3% 4.7% 26.7% 65.3% âœ“ âœ“ âœ“ 3.8% 5.8%
    33.1% 57.3% âœ“ âœ“ âœ“ âœ“ 5.2% 6.6% 39.5% 48.7% âœ“ âœ“ âœ“ âœ“ âœ“ 6.7% 8.5% 40.4% 44.4%
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹åŒ–ä»–äººå­ç›®æ ‡ è°ˆåˆ¤æµç¨‹ åæ€ä¸è®°å¿† è‡ªæˆ‘å¯¹æˆ˜ èƒœç‡ $\uparrow$ å¤§éƒ¨åˆ†SC$\uparrow$ å­˜æ´»ç‡$\uparrow$ è¢«å‡»è´¥$\downarrow$
    0.4% 0.7% 4.3% 94.6% âœ“ 0.7% 1.2% 10.6% 87.5% âœ“ âœ“ 3.3% 4.7% 26.7% 65.3% âœ“ âœ“ âœ“ 3.8%
    5.8% 33.1% 57.3% âœ“ âœ“ âœ“ âœ“ 5.2% 6.6% 39.5% 48.7% âœ“ âœ“ âœ“ âœ“ âœ“ 6.7% 8.5% 40.4% 44.4%
- en: 'Ablation Study. We conduct comprehensive ablation studies on Richelieu by analyzing
    the benefit of incorporating Richelieuâ€™s various modules, like planners or memory,
    into basic LLMs. The results are shown in TableÂ [3](https://arxiv.org/html/2407.06813v4#S5.T3
    "Table 3 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy"). As illustrated in Figure Â [5](https://arxiv.org/html/2407.06813v4#S5.F5
    "Figure 5 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy"), while the enhanced alignment in LLMs indeed boosts performance
    (GPT-4.0 is better than others), we observed that a vanilla GPT-4.0 still falls
    short in AI diplomacy without our framework, as can be seen in Table Â [3](https://arxiv.org/html/2407.06813v4#S5.T3
    "Table 3 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy"). Richelieuâ€™s performance obtains steady and significant improvement
    by incorporating each individual module. This indicates that Richelieu is able
    to leverage other playersâ€™ actions during decision-making and consider both short-term
    and long-term benefits. Additionally, Richelieuâ€™s negotiation ability has been
    significantly improved, allowing it to effectively express intentions to cooperate
    with other players and avoid deception during negotiations. And after self-play,
    Richelieuâ€™s experience makes it perform better. These indicate that the alignment
    in LLMs lays a foundation, but our approach is key to unlocking the modelsâ€™ potential
    in social simulation.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆèç ”ç©¶ã€‚æˆ‘ä»¬é€šè¿‡åˆ†æå°†Richelieuçš„å„ç§æ¨¡å—ï¼ˆå¦‚è§„åˆ’å™¨æˆ–è®°å¿†æ¨¡å—ï¼‰èå…¥åŸºç¡€LLMä¸­æ‰€å¸¦æ¥çš„å¥½å¤„ï¼Œå¼€å±•äº†å…¨é¢çš„æ¶ˆèç ”ç©¶ã€‚ç»“æœè§è¡¨[3](https://arxiv.org/html/2407.06813v4#S5.T3
    "è¡¨3 â€£ 5.2 ç»“æœ â€£ 5 å®éªŒ â€£ Richelieuï¼šåŸºäºLLMçš„è‡ªæˆ‘è¿›åŒ–ä»£ç†åœ¨AIå¤–äº¤ä¸­çš„åº”ç”¨")ã€‚å¦‚å›¾[5](https://arxiv.org/html/2407.06813v4#S5.F5
    "å›¾5 â€£ 5.2 ç»“æœ â€£ 5 å®éªŒ â€£ Richelieuï¼šåŸºäºLLMçš„è‡ªæˆ‘è¿›åŒ–ä»£ç†åœ¨AIå¤–äº¤ä¸­çš„åº”ç”¨")æ‰€ç¤ºï¼Œå°½ç®¡LLMä¸­çš„å¢å¼ºå¯¹é½ç¡®å®æå‡äº†æ€§èƒ½ï¼ˆGPT-4.0ä¼˜äºå…¶ä»–æ¨¡å‹ï¼‰ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œåœ¨æ²¡æœ‰æˆ‘ä»¬æ¡†æ¶çš„æƒ…å†µä¸‹ï¼Œæ™®é€šçš„GPT-4.0åœ¨AIå¤–äº¤ä¸­ä¾ç„¶è¡¨ç°ä¸è¶³ï¼Œå…·ä½“è§è¡¨[3](https://arxiv.org/html/2407.06813v4#S5.T3
    "è¡¨3 â€£ 5.2 ç»“æœ â€£ 5 å®éªŒ â€£ Richelieuï¼šåŸºäºLLMçš„è‡ªæˆ‘è¿›åŒ–ä»£ç†åœ¨AIå¤–äº¤ä¸­çš„åº”ç”¨")ã€‚é€šè¿‡å°†æ¯ä¸ªå•ç‹¬æ¨¡å—èå…¥å…¶ä¸­ï¼ŒRichelieuçš„æ€§èƒ½å®ç°äº†ç¨³å®šä¸”æ˜¾è‘—çš„æå‡ã€‚è¿™è¡¨æ˜ï¼ŒRichelieuèƒ½å¤Ÿåœ¨å†³ç­–è¿‡ç¨‹ä¸­åˆ©ç”¨å…¶ä»–å‚ä¸è€…çš„è¡ŒåŠ¨ï¼Œè€ƒè™‘çŸ­æœŸå’Œé•¿æœŸçš„åˆ©ç›Šã€‚æ­¤å¤–ï¼ŒRichelieuçš„è°ˆåˆ¤èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨è¾¾ä¸å…¶ä»–å‚ä¸è€…åˆä½œçš„æ„å›¾ï¼Œå¹¶åœ¨è°ˆåˆ¤ä¸­é¿å…æ¬ºéª—ã€‚ç»è¿‡è‡ªæˆ‘å¯¹æˆ˜åï¼ŒRichelieuçš„ç»éªŒä½¿å…¶è¡¨ç°æ›´ä½³ã€‚è¿™äº›è¡¨æ˜ï¼ŒLLMä¸­çš„å¯¹é½ä¸ºåŸºç¡€ï¼Œä½†æˆ‘ä»¬çš„æ–¹æ³•æ˜¯è§£é”æ¨¡å‹åœ¨ç¤¾ä¼šæ¨¡æ‹Ÿä¸­æ½œåŠ›çš„å…³é”®ã€‚
- en: 'Table 4: The success rate to identify the social relationship and infer othersâ€™
    intentions.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨4ï¼šè¯†åˆ«ç¤¾äº¤å…³ç³»å¹¶æ¨æµ‹ä»–äººæ„å›¾çš„æˆåŠŸç‡ã€‚
- en: '|  | GPT-4.0 | Llama3 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT-4.0 | Llama3 |'
- en: '| relationship | 85.74% | 85.52% |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| å…³ç³» | 85.74% | 85.52% |'
- en: '| intention(sub-goal) | 74.67% | 74.11% |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| æ„å›¾ï¼ˆå­ç›®æ ‡ï¼‰ | 74.67% | 74.11% |'
- en: 'Social Reasoning. We conduct an experiment to evaluate the success rate that
    the agent can successfully identify the social relationship and infer othersâ€™
    intentions. As the baselines do not explicitly model the relationship and intention,
    we can not directly access the ground truth for evaluation. Instead, we let all
    players use our agent but with different LLMs, i.e., 4 countries use GPT-4.0 and
    3 countries use Llama3\. The accuracy is reported in Table Â [4](https://arxiv.org/html/2407.06813v4#S5.T4
    "Table 4 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy"). We can see that the accuracy of social reasoning is consistent
    with the overall performance of the agent, indicating the effectiveness of social
    reasoning.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç¤¾ä¼šæ¨ç†ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€ä¸ªå®éªŒï¼Œè¯„ä¼°ä»£ç†äººæˆåŠŸè¯†åˆ«ç¤¾ä¼šå…³ç³»å¹¶æ¨æ–­ä»–äººæ„å›¾çš„æˆåŠŸç‡ã€‚ç”±äºåŸºå‡†æ¨¡å‹å¹¶æœªæ˜ç¡®å»ºæ¨¡å…³ç³»å’Œæ„å›¾ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®çœŸå®æƒ…å†µè¿›è¡Œè¯„ä¼°ã€‚ç›¸åï¼Œæˆ‘ä»¬è®©æ‰€æœ‰ç©å®¶éƒ½ä½¿ç”¨æˆ‘ä»¬çš„ä»£ç†äººï¼Œä½†é‡‡ç”¨ä¸åŒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå³4ä¸ªå›½å®¶ä½¿ç”¨GPT-4.0ï¼Œ3ä¸ªå›½å®¶ä½¿ç”¨Llama3\ã€‚å‡†ç¡®ç‡è§è¡¨[4](https://arxiv.org/html/2407.06813v4#S5.T4
    "Table 4 â€£ 5.2 Results â€£ 5 Experiment â€£ Richelieu: Self-Evolving LLM-Based Agents
    for AI Diplomacy")ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç¤¾ä¼šæ¨ç†çš„å‡†ç¡®ç‡ä¸ä»£ç†äººæ•´ä½“è¡¨ç°ä¸€è‡´ï¼Œè¡¨æ˜ç¤¾ä¼šæ¨ç†çš„æœ‰æ•ˆæ€§ã€‚'
- en: 6 Conclusion
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 ç»“è®º
- en: In this paper, we introduce Richelieu, a self-evolving LLM-based agent for AI
    diplomacy. Our model enables hierarchical planning for multi-agent tasks and utilizes
    a memory module for reflective optimization. Our model does not require human
    data and can evolve through self-play. It ultimately outperforms existing models
    like Cicero in the Diplomacy. Our ablation study demonstrates the effectiveness
    of the modules we have established. By conducting experiments using different
    LLMs, we validate the generalization of our framework to various LLMs. We believe
    that the use of LLM-based agents will become an effective approach in social science
    in the future.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Richelieuï¼Œä¸€ä¸ªåŸºäºè‡ªæˆ‘è¿›åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„AIå¤–äº¤ä»£ç†äººã€‚æˆ‘ä»¬çš„æ¨¡å‹æ”¯æŒå¤šä»£ç†ä»»åŠ¡çš„å±‚çº§è§„åˆ’ï¼Œå¹¶åˆ©ç”¨è®°å¿†æ¨¡å—è¿›è¡Œåæ€ä¼˜åŒ–ã€‚æˆ‘ä»¬çš„æ¨¡å‹ä¸éœ€è¦äººå·¥æ•°æ®ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡è‡ªæˆ‘åšå¼ˆè¿›è¡Œè¿›åŒ–ã€‚æœ€ç»ˆï¼Œå®ƒåœ¨ã€Šå¤–äº¤ã€‹æ¸¸æˆä¸­è¶…è¶Šäº†ç°æœ‰çš„æ¨¡å‹ï¼Œä¾‹å¦‚Ciceroã€‚æˆ‘ä»¬çš„æ¶ˆèå®éªŒå±•ç¤ºäº†æˆ‘ä»¬æ‰€å»ºç«‹æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡ä½¿ç”¨ä¸åŒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå®éªŒï¼Œæˆ‘ä»¬éªŒè¯äº†æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿå¹¿æ³›é€‚ç”¨äºä¸åŒçš„LLMã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼ŒåŸºäºLLMçš„ä»£ç†äººå°†åœ¨æœªæ¥æˆä¸ºç¤¾ä¼šç§‘å­¦ä¸­çš„ä¸€ç§æœ‰æ•ˆæ–¹æ³•ã€‚
- en: 7 Limitations and Future Work
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 å±€é™æ€§ä¸æœªæ¥å·¥ä½œ
- en: Our study is subject to certain limitations. We utilize diplomacy as the platform
    for constructing our model. However, the space of actions within diplomacy is
    constrained, whereas the decision-making space in real-world diplomacy is virtually
    boundless. In Diplomacy, apart from the negotiation information exchanged between
    players, all other information is public and certain. Conversely, real-world diplomacy
    operates within a framework of incomplete information.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç ”ç©¶å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ã€‚æˆ‘ä»¬ä»¥å¤–äº¤ä¸ºå¹³å°æ„å»ºæˆ‘ä»¬çš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œå¤–äº¤ä¸­çš„è¡ŒåŠ¨ç©ºé—´æ˜¯æœ‰é™çš„ï¼Œè€Œç°å®ä¸–ç•Œä¸­çš„å¤–äº¤å†³ç­–ç©ºé—´å‡ ä¹æ˜¯æ— é™çš„ã€‚åœ¨ã€Šå¤–äº¤ã€‹æ¸¸æˆä¸­ï¼Œé™¤äº†ç©å®¶ä¹‹é—´äº¤æ¢çš„è°ˆåˆ¤ä¿¡æ¯å¤–ï¼Œå…¶ä»–æ‰€æœ‰ä¿¡æ¯éƒ½æ˜¯å…¬å¼€ä¸”ç¡®å®šçš„ã€‚ç›¸åï¼Œç°å®ä¸–ç•Œä¸­çš„å¤–äº¤åˆ™æ˜¯åœ¨ä¿¡æ¯ä¸å®Œå…¨çš„æ¡†æ¶ä¸‹è¿ä½œã€‚
- en: Our framework is capable of applying to most social interaction tasks. Most
    components in our framework can be easily generalized to a new task by modifying
    the content. Social reasoning enables the agent to handle complex and dynamic
    social relationships. The negotiation pipeline opens the potential of communicating
    with others to prob the otherâ€™s mind or reach a consensus. The hierarchical strategy
    with reflection enhances the ability to handle long-term planning. The self-evolving
    mechanism (reflection with self-play memory) further improves the overall performance
    without manual supervision. These modules cover most of the challenges in multi-agent
    interactions. The potential applications of such an AI agent are vast, ranging
    from simulated diplomatic environments to real-world assistance and analysis.
    In future research, we intend to develop a more realistic game space, characterized
    by incomplete information and multi-player games, to enhance and refine our model
    further. We will also extend the framework to other multi-agent scenarios, including
    embodied interactionsÂ Zhong etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib78));
    Ci etÂ al. ([2023](https://arxiv.org/html/2407.06813v4#bib.bib12)); Chen etÂ al.
    ([2023](https://arxiv.org/html/2407.06813v4#bib.bib10)), sensor networksÂ Wang
    etÂ al. ([2022b](https://arxiv.org/html/2407.06813v4#bib.bib55)); Xu etÂ al. ([2020](https://arxiv.org/html/2407.06813v4#bib.bib62));
    Pan etÂ al. ([2022](https://arxiv.org/html/2407.06813v4#bib.bib39)); Li etÂ al.
    ([2020](https://arxiv.org/html/2407.06813v4#bib.bib32)), and video gamesÂ Wang
    etÂ al. ([2024a](https://arxiv.org/html/2407.06813v4#bib.bib50)); Ma etÂ al. ([2024](https://arxiv.org/html/2407.06813v4#bib.bib35)).
    This framework can also be employed to develop various applications. For instance,
    in the fields of business and finance, we intend to utilize it to create analytics
    and negotiation models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿåº”ç”¨äºå¤§å¤šæ•°ç¤¾äº¤äº’åŠ¨ä»»åŠ¡ã€‚æ¡†æ¶ä¸­çš„å¤§éƒ¨åˆ†ç»„ä»¶å¯ä»¥é€šè¿‡ä¿®æ”¹å†…å®¹è½»æ¾åœ°æ¨å¹¿åˆ°æ–°ä»»åŠ¡ã€‚ç¤¾äº¤æ¨ç†ä½¿å¾—ä»£ç†èƒ½å¤Ÿå¤„ç†å¤æ‚å’ŒåŠ¨æ€çš„ç¤¾äº¤å…³ç³»ã€‚è°ˆåˆ¤æµç¨‹ä½¿ä¸ä»–äººæ²Ÿé€šçš„æ½œåŠ›å¾—ä»¥å‘æŒ¥ï¼Œä»è€Œæ¢æµ‹å¯¹æ–¹çš„æƒ³æ³•æˆ–è¾¾æˆå…±è¯†ã€‚å¸¦æœ‰åæ€çš„å±‚æ¬¡åŒ–ç­–ç•¥å¢å¼ºäº†å¤„ç†é•¿æœŸè§„åˆ’çš„èƒ½åŠ›ã€‚è‡ªæˆ‘è¿›åŒ–æœºåˆ¶ï¼ˆå¸¦æœ‰è‡ªæˆ‘å¯¹å¼ˆè®°å¿†çš„åæ€ï¼‰åœ¨æ— éœ€äººå·¥ç›‘ç£çš„æƒ…å†µä¸‹è¿›ä¸€æ­¥æé«˜äº†æ•´ä½“æ€§èƒ½ã€‚è¿™äº›æ¨¡å—æ¶µç›–äº†å¤šæ™ºèƒ½ä½“äº’åŠ¨ä¸­çš„å¤§éƒ¨åˆ†æŒ‘æˆ˜ã€‚æ­¤ç±»AIä»£ç†çš„æ½œåœ¨åº”ç”¨å¹¿æ³›ï¼Œä»æ¨¡æ‹Ÿå¤–äº¤ç¯å¢ƒåˆ°ç°å®ä¸–ç•Œçš„ååŠ©ä¸åˆ†æã€‚æœªæ¥çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è®¡åˆ’å¼€å‘ä¸€ä¸ªæ›´å…·ç°å®æ„Ÿçš„æ¸¸æˆç©ºé—´ï¼Œç‰¹ç‚¹æ˜¯ä¿¡æ¯ä¸å®Œå…¨å’Œå¤šäººæ¸¸æˆï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå’Œå®Œå–„æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å°†æŠŠè¿™ä¸ªæ¡†æ¶æ‰©å±•åˆ°å…¶ä»–å¤šæ™ºèƒ½ä½“åœºæ™¯ï¼ŒåŒ…æ‹¬å…·èº«äº’åŠ¨Zhongç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib78)ï¼‰ï¼›Ciç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib12)ï¼‰ï¼›Chenç­‰äººï¼ˆ[2023](https://arxiv.org/html/2407.06813v4#bib.bib10)ï¼‰ï¼Œä¼ æ„Ÿå™¨ç½‘ç»œWangç­‰äººï¼ˆ[2022b](https://arxiv.org/html/2407.06813v4#bib.bib55)ï¼‰ï¼›Xuç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib62)ï¼‰ï¼›Panç­‰äººï¼ˆ[2022](https://arxiv.org/html/2407.06813v4#bib.bib39)ï¼‰ï¼›Liç­‰äººï¼ˆ[2020](https://arxiv.org/html/2407.06813v4#bib.bib32)ï¼‰ï¼Œä»¥åŠè§†é¢‘æ¸¸æˆWangç­‰äººï¼ˆ[2024a](https://arxiv.org/html/2407.06813v4#bib.bib50)ï¼‰ï¼›Maç­‰äººï¼ˆ[2024](https://arxiv.org/html/2407.06813v4#bib.bib35)ï¼‰ã€‚è¯¥æ¡†æ¶è¿˜å¯ç”¨äºå¼€å‘å„ç§åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨å•†ä¸šå’Œé‡‘èé¢†åŸŸï¼Œæˆ‘ä»¬è®¡åˆ’åˆ©ç”¨å®ƒåˆ›å»ºåˆ†æå’Œè°ˆåˆ¤æ¨¡å‹ã€‚
- en: Acknowledgements
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡´è°¢
- en: This work was supported by the National Science and Technology Major Project
    (2022ZD0114904), NSFC-6247070125, NSFC-62406034, NSFC-62406010, the State Key
    Lab of General Artificial Intelligence at Peking University, and Qualcomm University
    Research Grant.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬é¡¹å·¥ä½œå¾—åˆ°äº†å›½å®¶ç§‘æŠ€é‡å¤§é¡¹ç›®ï¼ˆ2022ZD0114904ï¼‰ã€NSFC-6247070125ã€NSFC-62406034ã€NSFC-62406010ï¼ŒåŒ—äº¬å¤§å­¦é€šç”¨äººå·¥æ™ºèƒ½å›½å®¶é‡ç‚¹å®éªŒå®¤ä»¥åŠé«˜é€šå¤§å­¦ç ”ç©¶èµ„åŠ©çš„æ”¯æŒã€‚
- en: References
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: 'Abdelnabi etÂ al. [2023] Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea
    SchÃ¶nherr, and Mario Fritz. Llm-deliberation: Evaluating llms with interactive
    multi-agent negotiation games. *arXiv preprint arXiv:2309.17234*, 2023.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdelnabiç­‰äºº [2023] Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea SchÃ¶nherr
    å’Œ Mario Fritzã€‚LLM-æ·±æ€ï¼šé€šè¿‡äº’åŠ¨å¤šæ™ºèƒ½ä½“è°ˆåˆ¤æ¸¸æˆè¯„ä¼°LLMsã€‚*arXivé¢„å°æœ¬ arXiv:2309.17234*ï¼Œ2023å¹´ã€‚
- en: Allan [1975] Calhamer Allan. *The Games & puzzles book of modern board games*.
    W. Luscombe, 1st edition, 1975. ISBN 978-0860020592.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Allan [1975] Calhamer Allan. *ç°ä»£æ¡Œæ¸¸æ¸¸æˆä¸è°œé¢˜ä¹¦*ã€‚W. Luscombeï¼Œç¬¬1ç‰ˆï¼Œ1975å¹´ã€‚ISBN 978-0860020592ã€‚
- en: Anthony etÂ al. [2020] Thomas Anthony, Tom Eccles, Andrea Tacchetti, JÃ¡nos KramÃ¡r,
    Ian Gemp, Thomas Hudson, Nicolas Porcel, Marc Lanctot, Julien PÃ©rolat, Richard
    Everett, etÂ al. Learning to play no-press diplomacy with best response policy
    iteration. In *Advances in Neural Information Processing Systems*, volumeÂ 33,
    pages 17987â€“18003, 2020.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthonyç­‰äºº [2020] Thomas Anthony, Tom Eccles, Andrea Tacchetti, JÃ¡nos KramÃ¡r,
    Ian Gemp, Thomas Hudson, Nicolas Porcel, Marc Lanctot, Julien PÃ©rolat, Richard
    Everett ç­‰äººã€‚ä½¿ç”¨æœ€ä½³å“åº”ç­–ç•¥è¿­ä»£å­¦ä¹ ç©æ— å‹åŠ›å¤–äº¤ã€‚åœ¨*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬33å·ï¼Œ17987-18003é¡µï¼Œ2020å¹´ã€‚
- en: Archer [2024] Bruno-AndrÃƒÂ© Giraudon &Â Vincent Archer. C-diplo argir, 2024. URL
    [https://world-diplomacy-database.com/php/scoring/scoring_class.php?id_scoring=7](https://world-diplomacy-database.com/php/scoring/scoring_class.php?id_scoring=7).
    Accessed:2024-05-02.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Archer [2024] Bruno-AndrÃƒÂ© Giraudon å’Œ Vincent Archer. C-diplo argirï¼Œ2024ã€‚ç½‘å€
    [https://world-diplomacy-database.com/php/scoring/scoring_class.php?id_scoring=7](https://world-diplomacy-database.com/php/scoring/scoring_class.php?id_scoring=7)ã€‚è®¿é—®æ—¶é—´ï¼š2024-05-02ã€‚
- en: Bakhtin etÂ al. [2019] Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marcâ€™Aurelio
    Ranzato, and Arthur Szlam. Real or fake? learning to discriminate machine from
    human generated text. *arXiv preprint arXiv:1906.03351*, 2019.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakhtin ç­‰äºº [2019] Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marcâ€™Aurelio
    Ranzato, å’Œ Arthur Szlam. çœŸå®è¿˜æ˜¯ä¼ªé€ ï¼Ÿå­¦ä¹ åŒºåˆ†æœºå™¨ç”Ÿæˆä¸äººç±»ç”Ÿæˆæ–‡æœ¬ã€‚*arXiv é¢„å°æœ¬ arXiv:1906.03351*ï¼Œ2019ã€‚
- en: Bakhtin etÂ al. [2021] Anton Bakhtin, David Wu, Adam Lerer, and Noam Brown. No-press
    diplomacy from scratch. In *Advances in Neural Information Processing Systems*,
    volumeÂ 34, pages 18063â€“18074, 2021.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakhtin ç­‰äºº [2021] Anton Bakhtin, David Wu, Adam Lerer, å’Œ Noam Brown. ä»é›¶å¼€å§‹çš„æ— å‹åŠ›å¤–äº¤ã€‚åœ¨
    *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬34å·ï¼Œé¡µç  18063â€“18074ï¼Œ2021ã€‚
- en: Bakhtin etÂ al. [2022] Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina,
    Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, etÂ al.
    Human-level play in the game of diplomacy by combining language models with strategic
    reasoning. *Science*, 378:1067â€“1074, 2022.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bakhtin ç­‰äºº [2022] Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin
    Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu ç­‰äºº. é€šè¿‡ç»“åˆè¯­è¨€æ¨¡å‹ä¸æˆ˜ç•¥æ¨ç†ï¼Œåœ¨ã€Šå¤–äº¤ã€‹æ¸¸æˆä¸­å®ç°äººç±»çº§åˆ«çš„è¡¨ç°ã€‚*ç§‘å­¦*ï¼Œ378:1067â€“1074ï¼Œ2022ã€‚
- en: Bianchi etÂ al. [2024] Federico Bianchi, PatrickÂ John Chia, Mert Yuksekgonul,
    Jacopo Tagliabue, Dan Jurafsky, and James Zou. How well can llms negotiate? negotiationarena
    platform and analysis. *arXiv preprint arXiv:2402.05863*, 2024.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bianchi ç­‰äºº [2024] Federico Bianchi, Patrick John Chia, Mert Yuksekgonul, Jacopo
    Tagliabue, Dan Jurafsky, å’Œ James Zou. å¤§è¯­è¨€æ¨¡å‹èƒ½è¿›è¡Œæœ‰æ•ˆçš„è°ˆåˆ¤å—ï¼Ÿè°ˆåˆ¤å¹³å°ä¸åˆ†æã€‚*arXiv é¢„å°æœ¬ arXiv:2402.05863*ï¼Œ2024ã€‚
- en: 'Calhamer [1974] Allan Calhamer. The invention of diplomacy, 1974. URL [https://diplomacyzines.co.uk/strategy-tactics/articles-by-alan-b-calhamer/the-invention-of-diplomacy/](https://diplomacyzines.co.uk/strategy-tactics/articles-by-alan-b-calhamer/the-invention-of-diplomacy/).
    Accessed: 2024-05-18.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calhamer [1974] Allan Calhamer. å¤–äº¤çš„å‘æ˜ï¼Œ1974ã€‚ç½‘å€ [https://diplomacyzines.co.uk/strategy-tactics/articles-by-alan-b-calhamer/the-invention-of-diplomacy/](https://diplomacyzines.co.uk/strategy-tactics/articles-by-alan-b-calhamer/the-invention-of-diplomacy/)ã€‚è®¿é—®æ—¶é—´ï¼š2024-05-18ã€‚
- en: 'Chen etÂ al. [2023] Yuanpei Chen, Yiran Geng, Fangwei Zhong, Jiaming Ji, Jiechuang
    Jiang, Zongqing Lu, Hao Dong, and Yaodong Yang. Bi-dexhands: Towards human-level
    bimanual dexterous manipulation. *IEEE Transactions on Pattern Analysis and Machine
    Intelligence*, 2023.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen ç­‰äºº [2023] Yuanpei Chen, Yiran Geng, Fangwei Zhong, Jiaming Ji, Jiechuang
    Jiang, Zongqing Lu, Hao Dong, å’Œ Yaodong Yang. Bi-dexhandsï¼šè¿ˆå‘äººç±»æ°´å¹³çš„åŒæ‰‹çµå·§æ“ä½œã€‚*IEEE
    æ¨¡å¼åˆ†æä¸æœºå™¨æ™ºèƒ½å­¦æŠ¥*ï¼Œ2023ã€‚
- en: Cheng etÂ al. [2024] Guangran Cheng, Chuheng Zhang, Wenzhe Cai, LiÂ Zhao, Changyin
    Sun, and Jiang Bian. Empowering large language models on robotic manipulation
    with affordance prompting. *arXiv preprint arXiv:2404.11027*, 2024.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng ç­‰äºº [2024] Guangran Cheng, Chuheng Zhang, Wenzhe Cai, Li Zhao, Changyin
    Sun, å’Œ Jiang Bian. é€šè¿‡æä¾›æç¤ºèµ‹èƒ½å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæœºå™¨äººæ“ä½œã€‚*arXiv é¢„å°æœ¬ arXiv:2404.11027*ï¼Œ2024ã€‚
- en: Ci etÂ al. [2023] Hai Ci, Mickel Liu, Xuehai Pan, fangwei zhong, and Yizhou Wang.
    Proactive multi-camera collaboration for 3d human pose estimation. In *Proceedings
    of International Conference on Learning Representations*, 2023.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ci ç­‰äºº [2023] Hai Ci, Mickel Liu, Xuehai Pan, fangwei zhong, å’Œ Yizhou Wang. ä¸»åŠ¨å¼å¤šæ‘„åƒå¤´åä½œç”¨äº3Däººä½“å§¿æ€ä¼°è®¡ã€‚å‘è¡¨äº
    *å›½é™…å­¦ä¹ è¡¨å¾å¤§ä¼šè®ºæ–‡é›†*ï¼Œ2023ã€‚
- en: 'David [2014] Hill David. The board game of the alpha nerds, 2014. URL [https://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/](https://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/).
    Accessed: 2024-05-18.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: David [2014] Hill David. ã€Šalpha nerds çš„æ£‹ç›˜æ¸¸æˆã€‹ï¼Œ2014ã€‚ç½‘å€ [https://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/](https://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/)ã€‚è®¿é—®æ—¶é—´ï¼š2024-05-18ã€‚
- en: 'DeÂ Jonge and Sierra [2017] Dave DeÂ Jonge and Carles Sierra. D-brane: a diplomacy
    playing agent for automated negotiations research. *Applied Intelligence*, 47:158â€“177,
    2017.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De Jonge å’Œ Sierra [2017] Dave De Jonge å’Œ Carles Sierra. D-braneï¼šç”¨äºè‡ªåŠ¨åŒ–è°ˆåˆ¤ç ”ç©¶çš„å¤–äº¤ä»£ç†äººã€‚*åº”ç”¨æ™ºèƒ½*ï¼Œ47:158â€“177ï¼Œ2017ã€‚
- en: 'deÂ ZarzÃ  etÂ al. [2023] IÂ deÂ ZarzÃ , JÂ deÂ CurtÃ², Gemma Roig, Pietro Manzoni,
    and CarlosÂ T Calafate. Emergent cooperation and strategy adaptation in multi-agent
    systems: An extended coevolutionary theory with llms. *Electronics*, 12:2722,
    2023.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de ZarzÃ  ç­‰äºº [2023] I de ZarzÃ , J de CurtÃ², Gemma Roig, Pietro Manzoni, å’Œ Carlos
    T Calafate. å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„æ–°å…´åˆä½œä¸ç­–ç•¥é€‚åº”ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ‰©å±•å…±è¿›åŒ–ç†è®ºã€‚*ç”µå­å­¦*ï¼Œ12:2722ï¼Œ2023ã€‚
- en: DuÃ©Ã±ez-GuzmÃ¡n etÂ al. [2023] EdgarÂ A DuÃ©Ã±ez-GuzmÃ¡n, Suzanne Sadedin, JaneÂ X Wang,
    KevinÂ R McKee, and JoelÂ Z Leibo. A social path to human-like artificial intelligence.
    *Nature Machine Intelligence*, 5:1181â€“1188, 2023.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DuÃ©Ã±ez-GuzmÃ¡nç­‰äºº [2023] Edgar A DuÃ©Ã±ez-GuzmÃ¡n, Suzanne Sadedin, Jane X Wang,
    Kevin R McKee å’Œ Joel Z Leibo. é€šå¾€ç±»äººäººå·¥æ™ºèƒ½çš„ç¤¾ä¼šè·¯å¾„ã€‚*è‡ªç„¶æœºå™¨æ™ºèƒ½*ï¼Œ5:1181â€“1188ï¼Œ2023å¹´ã€‚
- en: 'Fan etÂ al. [2022] Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong
    Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. Minedojo:
    Building open-ended embodied agents with internet-scale knowledge. In *Advances
    in Neural Information Processing Systems*, volumeÂ 35, pages 18343â€“18362, 2022.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fanç­‰äºº [2022] Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong
    Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu å’Œ Anima Anandkumar. Minedojoï¼šæ„å»ºå…·æœ‰äº’è”ç½‘è§„æ¨¡çŸ¥è¯†çš„å¼€æ”¾å¼å…·èº«ä»£ç†ã€‚è½½äº*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬35å·ï¼Œé¡µç 18343â€“18362ï¼Œ2022å¹´ã€‚
- en: Gao and Zhang [2024] Hang Gao and Yongfeng Zhang. Memory sharing for large language
    model based agents. *arXiv preprint arXiv:2404.09982*, 2024.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gaoå’ŒZhang [2024] Hang Gaoå’ŒYongfeng Zhang. åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†çš„è®°å¿†å…±äº«ã€‚*arXivé¢„å°æœ¬ arXiv:2404.09982*ï¼Œ2024å¹´ã€‚
- en: Gray etÂ al. [2020] Jonathan Gray, Adam Lerer, Anton Bakhtin, and Noam Brown.
    Human-level performance in no-press diplomacy via equilibrium search. *Proceedings
    of International Conference on Learning Representations*, 2020.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grayç­‰äºº [2020] Jonathan Gray, Adam Lerer, Anton Bakhtin å’Œ Noam Brown. é€šè¿‡å‡è¡¡æœç´¢å®ç°æ— å‹åŠ›å¤–äº¤ä¸­çš„äººç±»æ°´å¹³è¡¨ç°ã€‚*å›½é™…å­¦ä¹ è¡¨å¾å¤§ä¼šè®ºæ–‡é›†*ï¼Œ2020å¹´ã€‚
- en: 'GÃ¼rcan [2024] Ã–nder GÃ¼rcan. Llm-augmented agent-based modelling for social
    simulations: Challenges and opportunities. *HHAI 2024: Hybrid Human AI Systems
    for the Social Good*, pages 134â€“144, 2024.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GÃ¼rcan [2024] Ã–nder GÃ¼rcan. ç”¨äºç¤¾ä¼šæ¨¡æ‹Ÿçš„åŸºäºLLMå¢å¼ºçš„ä»£ç†å»ºæ¨¡ï¼šæŒ‘æˆ˜ä¸æœºé‡ã€‚*HHAI 2024ï¼šç¤¾ä¼šå…¬ç›Šä¸­çš„æ··åˆäººç±»AIç³»ç»Ÿ*ï¼Œé¡µç 134â€“144ï¼Œ2024å¹´ã€‚
- en: 'Hatalis etÂ al. [2023] Kostas Hatalis, Despina Christou, Joshua Myers, Steven
    Jones, Keith Lambert, Adam Amos-Binks, Zohreh Dannenhauer, and Dustin Dannenhauer.
    Memory matters: The need to improve long-term memory in llm-agents. In *Proceedings
    of the AAAI Symposium Series*, volumeÂ 2, pages 277â€“280, 2023.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hatalisç­‰äºº [2023] Kostas Hatalis, Despina Christou, Joshua Myers, Steven Jones,
    Keith Lambert, Adam Amos-Binks, Zohreh Dannenhauer å’Œ Dustin Dannenhauer. è®°å¿†å¾ˆé‡è¦ï¼šæ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†é•¿æœŸè®°å¿†çš„å¿…è¦æ€§ã€‚è½½äº*AAAIç ”è®¨ä¼šç³»åˆ—è®ºæ–‡é›†*ï¼Œç¬¬2å·ï¼Œé¡µç 277â€“280ï¼Œ2023å¹´ã€‚
- en: 'He etÂ al. [2024] Junda He, Christoph Treude, and David Lo. Llm-based multi-agent
    systems for software engineering: Vision and the road ahead. *arXiv preprint arXiv:2404.04834*,
    2024.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heç­‰äºº [2024] Junda He, Christoph Treude å’Œ David Lo. åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»£ç†ç³»ç»Ÿåœ¨è½¯ä»¶å·¥ç¨‹ä¸­çš„åº”ç”¨ï¼šæ„¿æ™¯ä¸æœªæ¥é“è·¯ã€‚*arXivé¢„å°æœ¬
    arXiv:2404.04834*ï¼Œ2024å¹´ã€‚
- en: 'Hill [2014] Avalon Hill. Diplomacy rules 4th edition, 2014. URL [https://diplom.org/~diparch/resources/rulebooks/2000AH4th.pdf](https://diplom.org/~diparch/resources/rulebooks/2000AH4th.pdf).
    Accessed: 2024-05-18.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hill [2014] Avalon Hill. ã€Šå¤–äº¤è§„åˆ™ã€‹ç¬¬4ç‰ˆï¼Œ2014å¹´ã€‚ç½‘å€ [https://diplom.org/~diparch/resources/rulebooks/2000AH4th.pdf](https://diplom.org/~diparch/resources/rulebooks/2000AH4th.pdf)ã€‚è®¿é—®æ—¶é—´ï¼š2024-05-18ã€‚
- en: 'Hou etÂ al. [2024] Yuki Hou, Haruki Tamoto, and Homei Miyashita. " my agent
    understands me better": Integrating dynamic human-like memory recall and consolidation
    in llm-based agents. In *Extended Abstracts of the CHI Conference on Human Factors
    in Computing Systems*, volumeÂ 7, pages 1â€“7, 2024.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Houç­‰äºº [2024] Yuki Hou, Haruki Tamoto å’Œ Homei Miyashita. "æˆ‘çš„ä»£ç†æ›´äº†è§£æˆ‘"ï¼šåœ¨åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†ä¸­é›†æˆåŠ¨æ€ç±»äººè®°å¿†å¬å›å’Œå·©å›ºã€‚è½½äº*CHIè®¡ç®—æœºç³»ç»Ÿäººå› å­¦ä¼šè®®æ‘˜è¦é›†*ï¼Œç¬¬7å·ï¼Œé¡µç 1â€“7ï¼Œ2024å¹´ã€‚
- en: Jacob etÂ al. [2022] AthulÂ Paul Jacob, DavidÂ J Wu, Gabriele Farina, Adam Lerer,
    Hengyuan Hu, Anton Bakhtin, Jacob Andreas, and Noam Brown. Modeling strong and
    human-like gameplay with kl-regularized search. In *International Conference on
    Machine Learning*, volume 162, pages 9695â€“9728, 2022.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jacobç­‰äºº [2022] Athul Paul Jacob, David J Wu, Gabriele Farina, Adam Lerer, Hengyuan
    Hu, Anton Bakhtin, Jacob Andreas å’Œ Noam Brown. é€šè¿‡KLæ­£åˆ™åŒ–æœç´¢å»ºæ¨¡å¼ºå¤§ä¸”ç±»äººæ¸¸æˆç©æ³•ã€‚è½½äº*å›½é™…æœºå™¨å­¦ä¹ å¤§ä¼šè®ºæ–‡é›†*ï¼Œç¬¬162å·ï¼Œé¡µç 9695â€“9728ï¼Œ2022å¹´ã€‚
- en: 'Jaidka etÂ al. [2024] Kokil Jaidka, Hansin Ahuja, and Lynnette HuiÂ Xian Ng.
    It takes two to negotiate: Modeling social exchange in online multiplayer games.
    In *Proceedings of the 37th Annual ACM Symposium on Human-Computer Interaction*,
    volumeÂ 8, pages 1â€“22, 2024.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaidkaç­‰äºº [2024] Kokil Jaidka, Hansin Ahuja å’Œ Lynnette Hui Xian Ng. è°ˆåˆ¤éœ€è¦ä¸¤ä¸ªäººï¼šå»ºæ¨¡åœ¨çº¿å¤šäººæ¸¸æˆä¸­çš„ç¤¾ä¼šäº¤æ¢ã€‚è½½äº*ç¬¬37å±Šå¹´åº¦ACMäººæœºäº¤äº’å¤§ä¼šè®ºæ–‡é›†*ï¼Œç¬¬8å·ï¼Œé¡µç 1â€“22ï¼Œ2024å¹´ã€‚
- en: Konya etÂ al. [2023] Andrew Konya, Deger Turan, Aviv Ovadya, Lina Qui, Daanish
    Masood, Flynn Devine, Lisa Schirch, Isabella Roberts, and DeliberativeÂ Alignment
    Forum. Deliberative technology for alignment. *arXiv preprint arXiv:2312.03893*,
    2023.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konyaç­‰äºº [2023] Andrew Konya, Deger Turan, Aviv Ovadya, Lina Qui, Daanish Masood,
    Flynn Devine, Lisa Schirch, Isabella Roberts å’Œ Deliberative Alignment Forum. å¯¹é½çš„æ·±æ€ç†Ÿè™‘æŠ€æœ¯ã€‚*arXivé¢„å°æœ¬
    arXiv:2312.03893*ï¼Œ2023å¹´ã€‚
- en: Kostick [2015] Conor Kostick. *The Art of Correspondence in the Game of Diplomacy*.
    Curses & Magic, 2nd edition, 2015. ISBN 978-0993415104.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kostick [2015] Conor Kostick. *å¤–äº¤åšå¼ˆä¸­çš„é€šä¿¡è‰ºæœ¯*ã€‚Curses & Magicï¼Œç¬¬äºŒç‰ˆï¼Œ2015å¹´ã€‚ISBN 978-0993415104ã€‚
- en: 'KovaÄ etÂ al. [2023] Grgur KovaÄ, RÃ©my Portelas, PeterÂ Ford Dominey, and Pierre-Yves
    Oudeyer. The socialai school: Insights from developmental psychology towards artificial
    socio-cultural agents. *arXiv preprint arXiv:2307.07871*, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KovaÄ et al. [2023] Grgur KovaÄ, RÃ©my Portelas, Peter Ford Dominey, å’Œ Pierre-Yves
    Oudeyer. ç¤¾äº¤AIå­¦æ´¾ï¼šæ¥è‡ªå‘å±•å¿ƒç†å­¦çš„æ´å¯Ÿï¼Œæœç€äººå·¥ç¤¾ä¼šæ–‡åŒ–ä»£ç†çš„æ–¹å‘ã€‚*arXiv é¢„å°æœ¬ arXiv:2307.07871*ï¼Œ2023å¹´ã€‚
- en: KramÃ¡r etÂ al. [2022] JÃ¡nos KramÃ¡r, Tom Eccles, Ian Gemp, Andrea Tacchetti, KevinÂ R
    McKee, Mateusz Malinowski, Thore Graepel, and Yoram Bachrach. Negotiation and
    honesty in artificial intelligence methods for the board game of diplomacy. *Nature
    Communications*, 13:7214, 2022.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KramÃ¡r et al. [2022] JÃ¡nos KramÃ¡r, Tom Eccles, Ian Gemp, Andrea Tacchetti, Kevin
    R McKee, Mateusz Malinowski, Thore Graepel, å’Œ Yoram Bachrach. äººå·¥æ™ºèƒ½æ–¹æ³•åœ¨å¤–äº¤æ£‹ç›˜æ¸¸æˆä¸­çš„è°ˆåˆ¤ä¸è¯šå®ã€‚*è‡ªç„¶é€šè®¯*ï¼Œ13:7214ï¼Œ2022å¹´ã€‚
- en: Li etÂ al. [2024a] Hao Li, Chenghao Yang, AnÂ Zhang, Yang Deng, Xiang Wang, and
    Tat-Seng Chua. Hello again! llm-powered personalized agent for long-term dialogue.
    *arXiv preprint arXiv:2406.05925*, 2024a.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2024a] Hao Li, Chenghao Yang, An Zhang, Yang Deng, Xiang Wang, å’Œ
    Tat-Seng Chua. ä½ å¥½ï¼Œå†è§ï¼åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸ªæ€§åŒ–ä»£ç†ï¼Œç”¨äºé•¿æœŸå¯¹è¯ã€‚*arXiv é¢„å°æœ¬ arXiv:2406.05925*ï¼Œ2024aå¹´ã€‚
- en: Li etÂ al. [2020] Jing Li, Jing Xu, Fangwei Zhong, Xiangyu Kong, YuÂ Qiao, and
    Yizhou Wang. Pose-assisted multi-camera collaboration for active object tracking.
    In *Proceedings of the AAAI Conference on Artificial Intelligence*, volumeÂ 34,
    pages 759â€“766, 2020.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2020] Jing Li, Jing Xu, Fangwei Zhong, Xiangyu Kong, Yu Qiao, å’Œ Yizhou
    Wang. å§¿æ€è¾…åŠ©çš„å¤šæ‘„åƒå¤´åä½œç”¨äºä¸»åŠ¨ç‰©ä½“è·Ÿè¸ªã€‚è§ *äººå·¥æ™ºèƒ½é¢†åŸŸAAAIä¼šè®®è®ºæ–‡é›†*ï¼Œç¬¬34å·ï¼Œç¬¬759â€“766é¡µï¼Œ2020å¹´ã€‚
- en: 'Li etÂ al. [2024b] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan,
    Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, YiÂ Sun, etÂ al. Personal llm
    agents: Insights and survey about the capability, efficiency and security. *arXiv
    preprint arXiv:2401.05459*, 2024b.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2024b] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan,
    Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sunï¼Œç­‰äºº. ä¸ªäººåŒ– LLM ä»£ç†ï¼šå…³äºèƒ½åŠ›ã€æ•ˆç‡å’Œå®‰å…¨æ€§çš„æ´å¯Ÿä¸è°ƒæŸ¥ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2401.05459*ï¼Œ2024bå¹´ã€‚
- en: 'Liu etÂ al. [2024] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin
    Liu, Juntao Tan, PrafullaÂ K Choubey, Tian Lan, Jason Wu, Huan Wang, etÂ al. Agentlite:
    A lightweight library for building and advancing task-oriented llm agent system.
    *arXiv preprint arXiv:2402.15538*, 2024.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. [2024] Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin
    Liu, Juntao Tan, Prafulla K Choubey, Tian Lan, Jason Wu, Huan Wangï¼Œç­‰äºº. Agentliteï¼šä¸€ä¸ªè½»é‡çº§åº“ï¼Œç”¨äºæ„å»ºå’Œæ¨è¿›ä»»åŠ¡å¯¼å‘çš„LLMä»£ç†ç³»ç»Ÿã€‚*arXiv
    é¢„å°æœ¬ arXiv:2402.15538*ï¼Œ2024å¹´ã€‚
- en: Ma etÂ al. [2024] Long Ma, Yuanfei Wang, Fangwei Zhong, Song-Chun Zhu, and Yizhou
    Wang. Fast peer adaptation with context-aware exploration. In *International Conference
    on Machine Learning*, volume 235, pages 33963â€“33982, 2024.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma et al. [2024] Long Ma, Yuanfei Wang, Fangwei Zhong, Song-Chun Zhu, å’Œ Yizhou
    Wang. å¿«é€Ÿçš„åŒè¡Œé€‚åº”ä¸åŸºäºä¸Šä¸‹æ–‡çš„æ¢ç´¢ã€‚è§ *å›½é™…æœºå™¨å­¦ä¹ ä¼šè®®*ï¼Œç¬¬235å·ï¼Œç¬¬33963â€“33982é¡µï¼Œ2024å¹´ã€‚
- en: Moghimifar etÂ al. [2024] Farhad Moghimifar, Yuan-Fang Li, Robert Thomson, and
    Gholamreza Haffari. Modelling political coalition negotiations using llm-based
    agents. *arXiv preprint arXiv:2402.11712*, 2024.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moghimifar et al. [2024] Farhad Moghimifar, Yuan-Fang Li, Robert Thomson, å’Œ
    Gholamreza Haffari. ä½¿ç”¨åŸºäºLLMçš„ä»£ç†å»ºæ¨¡æ”¿æ²»è”ç›Ÿè°ˆåˆ¤ã€‚*arXiv é¢„å°æœ¬ arXiv:2402.11712*ï¼Œ2024å¹´ã€‚
- en: Mukobi etÂ al. [2023] Gabriel Mukobi, Ann-Katrin Reuel, Juan-Pablo Rivera, and
    Chandler Smith. Assessing risks of using autonomous language models in military
    and diplomatic planning. In *Multi-Agent Security Workshop @ NeurIPSâ€™23*, 2023.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mukobi et al. [2023] Gabriel Mukobi, Ann-Katrin Reuel, Juan-Pablo Rivera, å’Œ
    Chandler Smith. è¯„ä¼°åœ¨å†›äº‹å’Œå¤–äº¤è§„åˆ’ä¸­ä½¿ç”¨è‡ªä¸»è¯­è¨€æ¨¡å‹çš„é£é™©ã€‚è§ *NeurIPSâ€™23 å¤šæ™ºèƒ½ä½“å®‰å…¨ç ”è®¨ä¼š*ï¼Œ2023å¹´ã€‚
- en: Noh and Chang [2024] Sean Noh and Ho-ChunÂ Herbert Chang. Llms with personalities
    in multi-issue negotiation games. *arXiv preprint arXiv:2405.05248*, 2024.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Noh and Chang [2024] Sean Noh å’Œ Ho-Chun Herbert Chang. åœ¨å¤šé—®é¢˜è°ˆåˆ¤æ¸¸æˆä¸­å…·æœ‰äººæ ¼çš„LLMã€‚*arXiv
    é¢„å°æœ¬ arXiv:2405.05248*ï¼Œ2024å¹´ã€‚
- en: 'Pan etÂ al. [2022] Xuehai Pan, Mickel Liu, Fangwei Zhong, Yaodong Yang, Song-Chun
    Zhu, and Yizhou Wang. Mate: Benchmarking multi-agent reinforcement learning in
    distributed target coverage control. In *Advances in Neural Information Processing
    Systems*, volumeÂ 35, pages 27862â€“27879, 2022.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan et al. [2022] Xuehai Pan, Mickel Liu, Fangwei Zhong, Yaodong Yang, Song-Chun
    Zhu, å’Œ Yizhou Wang. Mateï¼šåˆ†å¸ƒå¼ç›®æ ‡è¦†ç›–æ§åˆ¶ä¸­çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºå‡†æµ‹è¯•ã€‚è§ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬35å·ï¼Œç¬¬27862â€“27879é¡µï¼Œ2022å¹´ã€‚
- en: 'Paquette etÂ al. [2019] Philip Paquette, Yuchen Lu, SetonÂ Steven Bocco, Max
    Smith, Satya O-G, JonathanÂ K Kummerfeld, Joelle Pineau, Satinder Singh, and AaronÂ C
    Courville. No-press diplomacy: Modeling multi-agent gameplay. In *Advances in
    Neural Information Processing Systems*, volumeÂ 32, pages 4474â€“4485, 2019.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paquette ç­‰äºº [2019] è²åˆ©æ™®Â·å¸•å‡¯ç‰¹ï¼Œå•å®‡è¾°ï¼Œèµ›é¡¿Â·å²è’‚æ–‡Â·åšç§‘ï¼Œé©¬å…‹æ–¯Â·å²å¯†æ–¯ï¼Œè¨æäºšÂ·O-Gï¼Œä¹”çº³æ£®Â·KÂ·åº“é»˜è´¹å°”å¾·ï¼Œä¹”è‰¾å°”Â·çš®è¯ºï¼Œè¨å»·å¾·Â·è¾›æ ¼ï¼Œäºšä¼¦Â·CÂ·åº“ç»´å°”ã€‚æ— å‹åŠ›å¤–äº¤ï¼šå¤šä»£ç†æ¸¸æˆå»ºæ¨¡ã€‚å‘è¡¨äº
    *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 32 å·ï¼Œç¬¬ 4474â€“4485 é¡µï¼Œ2019 å¹´ã€‚
- en: 'Qi etÂ al. [2024] Siyuan Qi, Shuo Chen, Yexin Li, Xiangyu Kong, Junqi Wang,
    Bangcheng Yang, Pring Wong, Yifan Zhong, Xiaoyuan Zhang, Zhaowei Zhang, Nian Liu,
    Yaodong Yang, and Song-Chun Zhu. Civrealm: A learning and reasoning odyssey in
    civilization for decision-making agents. In *Proceedings of International Conference
    on Learning Representations*, 2024.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qi ç­‰äºº [2024] é½æ€è¿œï¼Œé™ˆç¡•ï¼Œæä¸šæ¬£ï¼Œå­”ç¿”å®‡ï¼Œç‹ä¿Šå¥‡ï¼Œæ¨é‚¦æˆï¼Œé»„å¹³ï¼Œé’Ÿä¸€å‡¡ï¼Œå¼ å°è¿œï¼Œå¼ å…†ä¼Ÿï¼Œåˆ˜å¹´ï¼Œæ¨è€€ä¸œï¼Œæœ±æ¾æ˜¥ã€‚Civrealmï¼šä¸ºå†³ç­–ä»£ç†è®¾è®¡çš„æ–‡æ˜å­¦ä¹ ä¸æ¨ç†ä¹‹æ—…ã€‚å‘è¡¨äº
    *å›½é™…å­¦ä¹ è¡¨å¾ä¼šè®®è®ºæ–‡é›†*ï¼Œ2024 å¹´ã€‚
- en: 'Renze and Guven [2024] Matthew Renze and Erhan Guven. Self-reflection in llm
    agents: Effects on problem-solving performance. *arXiv preprint arXiv:2405.06682*,
    2024.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Renze å’Œ Guven [2024] é©¬ä¿®Â·ä»»æ³½ å’Œ åŸƒå°”æ±‰Â·å¤æ–‡ã€‚LLM ä»£ç†ä¸­çš„è‡ªæˆ‘åæ€ï¼šå¯¹é—®é¢˜è§£å†³æ€§èƒ½çš„å½±å“ã€‚*arXiv é¢„å°æœ¬ arXiv:2405.06682*ï¼Œ2024
    å¹´ã€‚
- en: Richard [1979] Sharp Richard. *The game of diplomacy*. Arthur Barker, 1979.
    ISBN 978-0213166762.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Richard [1979] å¤æ™®Â·ç†æŸ¥å¾·ã€‚*å¤–äº¤æ¸¸æˆ*ã€‚é˜¿ç‘ŸÂ·å·´å…‹å‡ºç‰ˆç¤¾ï¼Œ1979 å¹´ã€‚ISBN 978-0213166762ã€‚
- en: 'Schick etÂ al. [2023] Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    Toolformer: Language models can teach themselves to use tools. In *Advances in
    Neural Information Processing Systems*, volumeÂ 36, pages 68539â€“68551, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schick ç­‰äºº [2023] è’‚è«Â·å¸­å…‹ï¼Œç®€Â·å¾·ç»´ç»´è¿ª-äºï¼Œç½—ä¼¯æ‰˜Â·å¾·è¥¿ï¼Œç½—è´å°”å¡”Â·æ‹‰ä¼Šè±åŠªï¼Œç›ä¸½äºšÂ·æ´›æ¢…é‡Œï¼ŒåŸƒé‡Œå…‹Â·æ±‰å¸ƒç½—ï¼Œå¢å…‹Â·æ³½ç‰¹å°”è«è€¶ï¼Œå°¼å¤æ‹‰Â·ååˆ‡è¾¾ï¼Œæ‰˜é©¬æ–¯Â·è¥¿äºšéš†ã€‚Toolformerï¼šè¯­è¨€æ¨¡å‹å¯ä»¥è‡ªæˆ‘å­¦ä¹ ä½¿ç”¨å·¥å…·ã€‚å‘è¡¨äº
    *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 36 å·ï¼Œç¬¬ 68539â€“68551 é¡µï¼Œ2023 å¹´ã€‚
- en: 'Shen etÂ al. [2023] Yongliang Shen, Kaitao Song, XuÂ Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. HuggingGPT: Solving AI tasks with chatGPT and its friends
    in hugging face. In *Advances in Neural Information Processing Systems*, volumeÂ 36,
    pages 38154â€“38180, 2023.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen ç­‰äºº [2023] å®‹æ°¸äº®ï¼Œå®‹å‡¯æ¶›ï¼Œè°­æ—­ï¼Œæä¸œç”Ÿï¼Œå¢ä¼Ÿåï¼Œåº„è·ƒå»·ã€‚HuggingGPTï¼šåˆ©ç”¨ ChatGPT å’Œå®ƒçš„ä¼™ä¼´ä»¬åœ¨ Hugging
    Face ä¸­è§£å†³ AI ä»»åŠ¡ã€‚å‘è¡¨äº *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 36 å·ï¼Œç¬¬ 38154â€“38180 é¡µï¼Œ2023 å¹´ã€‚
- en: 'Shoker etÂ al. [2023] Sarah Shoker, Andrew Reddie, Sarah Barrington, Ruby Booth,
    Miles Brundage, Husanjot Chahal, Michael Depp, Bill Drexel, Ritwik Gupta, Marina
    Favaro, etÂ al. Confidence-building measures for artificial intelligence: Workshop
    proceedings. *arXiv preprint arXiv:2308.00862*, 2023.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shoker ç­‰äºº [2023] è¨æ‹‰Â·è‚–å…‹å°”ï¼Œå®‰å¾·é²Â·é›·è¿ªï¼Œè¨æ‹‰Â·å·´çµé¡¿ï¼Œé²æ¯”Â·å¸ƒæ–¯ï¼Œè¿ˆå°”æ–¯Â·å¸ƒä¼¦è¾¾å¥‡ï¼Œèƒ¡è¨å‰ç‰¹Â·æŸ¥å“ˆå°”ï¼Œè¿ˆå…‹å°”Â·å¾·æ™®ï¼Œæ¯”å°”Â·å¾·é›·å…‹å¡å°”ï¼Œé‡Œç‰¹ç»´å…‹Â·å¤æ™®å¡”ï¼Œç›ä¸½å¨œÂ·æ³•ç“¦ç½—
    ç­‰äººã€‚äººå·¥æ™ºèƒ½çš„ä¿¡ä»»å»ºè®¾æªæ–½ï¼šç ”è®¨ä¼šè®ºæ–‡é›†ã€‚*arXiv é¢„å°æœ¬ arXiv:2308.00862*ï¼Œ2023 å¹´ã€‚
- en: 'Sun etÂ al. [2024] Chuanneng Sun, Songjun Huang, and Dario Pompili. Llm-based
    multi-agent reinforcement learning: Current and future directions. *arXiv preprint
    arXiv:2405.11106*, 2024.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun ç­‰äºº [2024] å­™å·èƒ½ï¼Œé»„æ¾ä¿Šï¼Œè¾¾é‡Œå¥¥Â·åºçš®é‡Œã€‚åŸºäº LLM çš„å¤šä»£ç†å¼ºåŒ–å­¦ä¹ ï¼šå½“å‰åŠæœªæ¥æ–¹å‘ã€‚*arXiv é¢„å°æœ¬ arXiv:2405.11106*ï¼Œ2024
    å¹´ã€‚
- en: 'Talebirad and Nadiri [2023] Yashar Talebirad and Amirhossein Nadiri. Multi-agent
    collaboration: Harnessing the power of intelligent llm agents. *arXiv preprint
    arXiv:2306.03314*, 2023.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Talebirad å’Œ Nadiri [2023] äºšæ²™å°”Â·å¡”å‹’æ¯”æ‹‰å¾· å’Œ é˜¿ç±³å°”éœæ£®Â·çº³è¿ªé‡Œã€‚å¤šä»£ç†åä½œï¼šåˆ©ç”¨æ™ºèƒ½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†çš„åŠ›é‡ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2306.03314*ï¼Œ2023 å¹´ã€‚
- en: Wan etÂ al. [2024] Hongyu Wan, Jinda Zhang, AbdulazizÂ Arif Suria, Bingsheng Yao,
    Dakuo Wang, Yvonne Coady, and Mirjana Prpa. Building llm-based ai agents in social
    virtual reality. In *Extended Abstracts of the CHI Conference on Human Factors
    in Computing Systems*, volumeÂ 65, pages 1â€“7, 2024.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan ç­‰äºº [2024] ä¸‡é¸¿å®‡ï¼Œå¼ é‡‘è¾¾ï¼Œé˜¿åœæœå‹’é˜¿é½å…¹Â·é˜¿é‡Œå¤«Â·è‹é‡Œäºšï¼Œå§šç‚³ç”Ÿï¼Œç‹å¤§é˜”ï¼Œç§‘è¿ªÂ·ä¼Šå†¯å¨œï¼Œç±³å°”è´¾å¨œÂ·æ™®å°”å¸•ã€‚æ„å»ºåŸºäº LLM çš„ AI
    ä»£ç†ï¼Œåœ¨ç¤¾äº¤è™šæ‹Ÿç°å®ä¸­åº”ç”¨ã€‚å‘è¡¨äº *è®¡ç®—æœºç³»ç»Ÿäººå› å­¦ä¼šè®®æ‰©å±•æ‘˜è¦*ï¼Œç¬¬ 65 å·ï¼Œç¬¬ 1â€“7 é¡µï¼Œ2024 å¹´ã€‚
- en: 'Wang etÂ al. [2024a] Dongzi Wang, Fangwei Zhong, Minglong Li, Muning Wen, Yuanxi
    Peng, Teng Li, and Adam Yang. Romat: Role-based multi-agent transformer for generalizable
    heterogeneous cooperation. *Neural Networks*, 174:106129, 2024a.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang ç­‰äºº [2024a] ç‹ä¸œå­ï¼Œé’Ÿæ–¹ä¼Ÿï¼Œæåé¾™ï¼Œæ¸©æ…•å®ï¼Œå½­å…ƒç†™ï¼Œæè…¾ï¼Œæ¨äºšç™»ã€‚Romatï¼šä¸€ç§åŸºäºè§’è‰²çš„å¤šä»£ç†å˜å‹å™¨ï¼Œé€‚ç”¨äºé€šç”¨å¼‚æ„åˆä½œã€‚*ç¥ç»ç½‘ç»œ*ï¼Œ174:106129ï¼Œ2024a
    å¹´ã€‚
- en: 'Wang etÂ al. [2023a] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied
    agent with large language models. In *NeurIPS 2023 Foundation Models for Decision
    Making Workshop*, 2023a.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang ç­‰äºº [2023a] ç‹å† ä¹‹ï¼Œè°¢å®‡é½ï¼Œå§œäº‘å‡¡ï¼Œé˜¿è´¾ä¼ŠÂ·æ›¼å¾·å°”å¡å°”ï¼Œè‚–è¶…ä¼Ÿï¼Œæœ±é’°å¯ï¼ŒèŒƒç³ç†™ï¼Œå®‰å°¼ç›Â·å®‰å—å¾·åº“é©¬å°”ã€‚Voyagerï¼šä¸€ä¸ªå¼€æ”¾å¼çš„å…·èº«ä»£ç†ï¼Œç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ã€‚å‘è¡¨äº
    *NeurIPS 2023 å†³ç­–åˆ¶å®šåŸºç¡€æ¨¡å‹ç ”è®¨ä¼š*ï¼Œ2023a å¹´ã€‚
- en: 'Wang etÂ al. [2024b] Haoyu Wang, Tao Li, Zhiwei Deng, Dan Roth, and Yang Li.
    Devilâ€™s advocate: Anticipatory reflection for llm agents. *arXiv preprint arXiv:2405.16334*,
    2024b.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2024b] ç‹æµ©å®‡ã€ææ¶›ã€é‚“å¿—ä¼Ÿã€ä¸¹Â·ç½—æ–¯ã€ææ‰¬ã€‚é­”é¬¼ä»£è¨€äººï¼šå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“çš„é¢„æœŸåæ€ã€‚*arXivé¢„å°æœ¬ arXiv:2405.16334*ï¼Œ2024bã€‚
- en: Wang etÂ al. [2024c] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, XuÂ Chen, Yankai Lin, etÂ al. A survey on large
    language model based autonomous agents. *Frontiers of Computer Science*, 18:1â€“26,
    2024c.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2024c] ç‹ç£Šã€é©¬æ™¨ã€å†¯å­¦æ‰¬ã€å¼ æ³½å®‡ã€æ¨æµ©ã€å¼ æ™¯æ£®ã€é™ˆå¿—è¿œã€å”ä½³å‡¯ã€é™ˆæ—­ã€æ—å½¦å‡¯ ç­‰ã€‚åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªä¸»æ™ºèƒ½ä½“ç»¼è¿°ã€‚*è®¡ç®—æœºç§‘å­¦å‰æ²¿*ï¼Œ18:1â€“26ï¼Œ2024cã€‚
- en: Wang etÂ al. [2022a] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, EdÂ Chi,
    Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves
    chain of thought reasoning in language models. *arXiv preprint arXiv:2203.11171*,
    2022a.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2022a] ç‹å­¦å¿—ã€Jason Weiã€Dale Schuurmansã€Quoc Leã€Ed Chiã€Sharan Narangã€Aakanksha
    Chowdhery å’Œ Denny Zhouã€‚è‡ªä¸€è‡´æ€§æ”¹å–„è¯­è¨€æ¨¡å‹ä¸­çš„é“¾å¼æ€è€ƒæ¨ç†ã€‚*arXivé¢„å°æœ¬ arXiv:2203.11171*ï¼Œ2022aã€‚
- en: 'Wang etÂ al. [2022b] Yuanfei Wang, fangwei zhong, Jing Xu, and Yizhou Wang.
    Tom2c: Target-oriented multi-agent communication and cooperation with theory of
    mind. In *Proceedings of International Conference on Learning Representations*,
    2022b.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2022b] ç‹å…ƒé£ã€é’Ÿæ–¹ä¼Ÿã€è®¸æ™¶ã€ç‹ä¸€æ´²ã€‚Tom2cï¼šå…·æœ‰å¿ƒæ™ºç†è®ºçš„é¢å‘ç›®æ ‡çš„å¤šæ™ºèƒ½ä½“é€šä¿¡ä¸åˆä½œã€‚åœ¨*å›½é™…å­¦ä¹ è¡¨å¾ä¼šè®®è®ºæ–‡é›†*ï¼Œ2022bã€‚
- en: 'Wang etÂ al. [2023b] Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing
    Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, Xiaojian
    Ma, and Yitao Liang. Jarvis-1: Open-world multi-task agents with memory-augmented
    multimodal language models. *arXiv preprint arXiv:2311.05997*, 2023b.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2023b] ç‹å­è±ªã€è”¡ç»é£ã€åˆ˜å®‰å‰ã€é‡‘æ°¸åˆšã€ä¾¯é‡‘å†°ã€å¼ åšå¨ã€æ—æ˜Šä¼Ÿã€ä½•å…†å³°ã€éƒ‘å­é¾™ã€æ¨è€€ä¸œã€é©¬æ™“å‰‘ å’Œ æ¢ä¸€æ¶›ã€‚Jarvis-1ï¼šå…·æœ‰è®°å¿†å¢å¼ºçš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å¼€æ”¾ä¸–ç•Œå¤šä»»åŠ¡æ™ºèƒ½ä½“ã€‚*arXivé¢„å°æœ¬
    arXiv:2311.05997*ï¼Œ2023bã€‚
- en: 'Wang etÂ al. [2024d] Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, XiaojianÂ Shawn
    Ma, and Yitao Liang. Describe, explain, plan and select: interactive planning
    with llms enables open-world multi-task agents. In *Advances in Neural Information
    Processing Systems*, volumeÂ 36, pages 34153â€“34189, 2024d.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2024d] ç‹å­è±ªã€è”¡ç»é£ã€é™ˆå† æ´²ã€åˆ˜å®‰å‰ã€é©¬æ™“å‰‘Â·è‚–æ©ã€æ¢ä¸€æ¶›ã€‚æè¿°ã€è§£é‡Šã€è§„åˆ’ä¸é€‰æ‹©ï¼šä¸å¤§è¯­è¨€æ¨¡å‹çš„äº’åŠ¨è§„åˆ’ä½¿å¾—å¼€æ”¾ä¸–ç•Œå¤šä»»åŠ¡æ™ºèƒ½ä½“æˆä¸ºå¯èƒ½ã€‚åœ¨*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬36å·ï¼Œç¬¬34153â€“34189é¡µï¼Œ2024dã€‚
- en: 'Wang etÂ al. [2024e] Ziyan Wang, Yingpeng Du, Zhu Sun, Haoyan Chua, Kaidong
    Feng, Wenya Wang, and Jie Zhang. Re2llm: Reflective reinforcement large language
    model for session-based recommendation. *arXiv preprint arXiv:2403.16427*, 2024e.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang etÂ al. [2024e] ç‹å­æ‰¬ã€æœè‹±é¹ã€å­™ç«¹ã€è”¡æ˜Šå½¦ã€å†¯å‡¯ä¸œã€ç‹æ–‡é›…ã€å¼ æ°ã€‚Re2llmï¼šé¢å‘ä¼šè¯æ¨èçš„åæ€å¼ºåŒ–å¤§è¯­è¨€æ¨¡å‹ã€‚*arXivé¢„å°æœ¬
    arXiv:2403.16427*ï¼Œ2024eã€‚
- en: Wei etÂ al. [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, EdÂ Chi, QuocÂ V Le, Denny Zhou, etÂ al. Chain-of-thought prompting elicits
    reasoning in large language models. In *Advances in neural information processing
    systems*, volumeÂ 35, pages 24824â€“24837, 2022.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei etÂ al. [2022] Jason Weiã€ç‹å­¦å¿—ã€Dale Schuurmansã€Maarten Bosmaã€å¤é£ã€Ed Chiã€Quoc
    V Leã€Denny Zhou ç­‰ã€‚é“¾å¼æ€è€ƒæç¤ºå¼•å‘å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ¨ç†ã€‚åœ¨*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬35å·ï¼Œç¬¬24824â€“24837é¡µï¼Œ2022ã€‚
- en: 'Wikipedia [2024] Wikipedia. Diplomacy(game), 2024. URL [https://en.wikipedia.org/wiki/Diplomacy_(game)](https://en.wikipedia.org/wiki/Diplomacy_(game)).
    Accessed: 2024-05-18.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wikipedia [2024] Wikipediaã€‚å¤–äº¤ï¼ˆæ¸¸æˆï¼‰ï¼Œ2024ã€‚ç½‘å€ [https://en.wikipedia.org/wiki/Diplomacy_(game)](https://en.wikipedia.org/wiki/Diplomacy_(game))ã€‚è®¿é—®æ—¶é—´ï¼š2024-05-18ã€‚
- en: 'Xia etÂ al. [2024] Tian Xia, Zhiwei He, Tong Ren, Yibo Miao, Zhuosheng Zhang,
    Yang Yang, and Rui Wang. Measuring bargaining abilities of llms: A benchmark and
    a buyer-enhancement method. *arXiv preprint arXiv:2402.15813*, 2024.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia etÂ al. [2024] å¤å¤©ã€ä½•å¿—ä¼Ÿã€ä»»å½¤ã€è‹—ä¸€åšã€å¼ å“ç”Ÿã€æ¨é˜³ã€ç‹ç‘ã€‚è¡¡é‡å¤§è¯­è¨€æ¨¡å‹çš„è®®ä»·èƒ½åŠ›ï¼šåŸºå‡†æµ‹è¯•ä¸ä¹°æ–¹å¢å¼ºæ–¹æ³•ã€‚*arXivé¢„å°æœ¬
    arXiv:2402.15813*ï¼Œ2024ã€‚
- en: Xu etÂ al. [2020] Jing Xu, Fangwei Zhong, and Yizhou Wang. Learning multi-agent
    coordination for enhancing target coverage in directional sensor networks. In
    *Advances in Neural Information Processing Systems*, volumeÂ 33, pages 10053â€“10064,
    2020.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu etÂ al. [2020] è®¸æ™¶ã€é’Ÿæ–¹ä¼Ÿã€ç‹ä¸€æ´²ã€‚å­¦ä¹ å¤šæ™ºèƒ½ä½“åè°ƒä»¥å¢å¼ºå®šå‘ä¼ æ„Ÿå™¨ç½‘ç»œä¸­çš„ç›®æ ‡è¦†ç›–ã€‚åœ¨*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬33å·ï¼Œç¬¬10053â€“10064é¡µï¼Œ2020ã€‚
- en: 'Xu etÂ al. [2023] Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang,
    Weidong Liu, and Yang Liu. Exploring large language models for communication games:
    An empirical study on werewolf. *arXiv preprint arXiv:2309.04658*, 2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu etÂ al. [2023] è®¸èª‰åº„ã€ç‹ç¡•ã€æé¹ã€ç½—å¯Œæ–‡ã€ç‹å°é¾™ã€åˆ˜ä¼Ÿä¸œã€åˆ˜é˜³ã€‚æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹åœ¨æ²Ÿé€šæ¸¸æˆä¸­çš„åº”ç”¨ï¼šç‹¼äººæ€çš„å®è¯ç ”ç©¶ã€‚*arXivé¢„å°æœ¬
    arXiv:2309.04658*ï¼Œ2023ã€‚
- en: 'Yan etÂ al. [2023] Ming Yan, Ruihao Li, Hao Zhang, Hao Wang, Zhilan Yang, and
    JiÂ Yan. Larp: Language-agent role play for open-world games. *arXiv preprint arXiv:2312.17653*,
    2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan ç­‰äºº [2023] Ming Yan, Ruihao Li, Hao Zhang, Hao Wang, Zhilan Yang å’Œ Ji Yan.
    LARPï¼šé¢å‘å¼€æ”¾ä¸–ç•Œæ¸¸æˆçš„è¯­è¨€ä»£ç†è§’è‰²æ‰®æ¼”ã€‚*arXiv é¢„å°æœ¬ arXiv:2312.17653*ï¼Œ2023ã€‚
- en: 'Yang etÂ al. [2023a] Hui Yang, Sifu Yue, and Yunzhong He. Auto-gpt for online
    decision making: Benchmarks and additional opinions. *arXiv preprint arXiv:2306.02224*,
    2023a.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang ç­‰äºº [2023a] Hui Yang, Sifu Yue å’Œ Yunzhong He. Auto-gpt ç”¨äºåœ¨çº¿å†³ç­–ï¼šåŸºå‡†å’Œé™„åŠ æ„è§ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2306.02224*ï¼Œ2023aã€‚
- en: 'Yang etÂ al. [2023b] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu
    Li, and Ying Shan. GPT4tools: Teaching large language model to use tools via self-instruction.
    In *Advances in Neural Information Processing Systems*, volumeÂ 36, pages 71995â€“72007,
    2023b.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang ç­‰äºº [2023b] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li
    å’Œ Ying Shan. GPT4toolsï¼šé€šè¿‡è‡ªæˆ‘æŒ‡å¯¼æ•™ä¼šå¤§è¯­è¨€æ¨¡å‹ä½¿ç”¨å·¥å…·ã€‚åœ¨ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 36 å·ï¼Œç¬¬ 71995â€“72007 é¡µï¼Œ2023bã€‚
- en: 'Yang etÂ al. [2023c] Ziyi Yang, ShreyasÂ S Raman, Ankit Shah, and Stefanie Tellex.
    Plug in the safety chip: Enforcing constraints for llm-driven robot agents. *arXiv
    preprint arXiv:2309.09919*, 2023c.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang ç­‰äºº [2023c] Ziyi Yang, Shreyas S Raman, Ankit Shah å’Œ Stefanie Tellex. æ’å…¥å®‰å…¨èŠ¯ç‰‡ï¼šä¸ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æœºå™¨äººä»£ç†æ‰§è¡Œçº¦æŸã€‚*arXiv
    é¢„å°æœ¬ arXiv:2309.09919*ï¼Œ2023cã€‚
- en: 'Yao etÂ al. [2023] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, ThomasÂ L.
    Griffiths, Yuan Cao, and KarthikÂ R Narasimhan. Tree of thoughts: Deliberate problem
    solving with large language models. In *Advances in Neural Information Processing
    Systems*, volumeÂ 36, pages 11809â€“11822, 2023.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao ç­‰äºº [2023] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths,
    Yuan Cao å’Œ Karthik R Narasimhan. æ€ç»´æ ‘ï¼šä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ·±æ€ç†Ÿè™‘é—®é¢˜è§£å†³ã€‚åœ¨ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 36 å·ï¼Œç¬¬
    11809â€“11822 é¡µï¼Œ2023 å¹´ã€‚
- en: 'Yu etÂ al. [2024] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li,
    Denghui Zhang, Rong Liu, JordanÂ W Suchow, and Khaldoun Khashanah. Finmem: A performance-enhanced
    llm trading agent with layered memory and character design. In *Proceedings of
    the AAAI Symposium Series*, volumeÂ 3, pages 595â€“597, 2024.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu ç­‰äºº [2024] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui
    Zhang, Rong Liu, Jordan W Suchow å’Œ Khaldoun Khashanah. Finmemï¼šå…·æœ‰åˆ†å±‚è®°å¿†å’Œè§’è‰²è®¾è®¡çš„æ€§èƒ½å¢å¼º
    LLM äº¤æ˜“ä»£ç†ã€‚åœ¨ *AAAI ä¼šè®®ç³»åˆ—è®ºæ–‡é›†*ï¼Œç¬¬ 3 å·ï¼Œç¬¬ 595â€“597 é¡µï¼Œ2024ã€‚
- en: Zellers etÂ al. [2019] Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk,
    Ali Farhadi, Franziska Roesner, and Yejin Choi. Defending against neural fake
    news. In *Advances in Neural Information Processing Systems*, volumeÂ 32, page
    9054â€“9065, 2019.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zellers ç­‰äºº [2019] Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk,
    Ali Farhadi, Franziska Roesner å’Œ Yejin Choi. é˜²å¾¡ç¥ç»å‡æ–°é—»ã€‚åœ¨ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 32 å·ï¼Œç¬¬ 9054â€“9065
    é¡µï¼Œ2019 å¹´ã€‚
- en: Zhan etÂ al. [2024] Haolan Zhan, Yufei Wang, Tao Feng, Yuncheng Hua, Suraj Sharma,
    Zhuang Li, Lizhen Qu, ZhalehÂ Semnani Azad, Ingrid Zukerman, and Gholamreza Haffari.
    Letâ€™s negotiate! a survey of negotiation dialogue systems. *arXiv preprint arXiv:2402.01097*,
    2024.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhan ç­‰äºº [2024] Haolan Zhan, Yufei Wang, Tao Feng, Yuncheng Hua, Suraj Sharma,
    Zhuang Li, Lizhen Qu, Zhaleh Semnani Azad, Ingrid Zukerman å’Œ Gholamreza Haffari.
    è®©æˆ‘ä»¬è°ˆåˆ¤ï¼ä¸€é¡¹å…³äºè°ˆåˆ¤å¯¹è¯ç³»ç»Ÿçš„è°ƒæŸ¥ã€‚*arXiv é¢„å°æœ¬ arXiv:2402.01097*ï¼Œ2024ã€‚
- en: Zhang etÂ al. [2024a] Danyang Zhang, LuÂ Chen, Situo Zhang, Hongshen Xu, Zihan
    Zhao, and Kai Yu. Large language models are semi-parametric reinforcement learning
    agents. In *Advances in Neural Information Processing Systems*, volumeÂ 36, pages
    78227â€“78239, 2024a.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰äºº [2024a] Danyang Zhang, Lu Chen, Situo Zhang, Hongshen Xu, Zihan Zhao
    å’Œ Kai Yu. å¤§è¯­è¨€æ¨¡å‹æ˜¯åŠå‚æ•°å¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚åœ¨ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬ 36 å·ï¼Œç¬¬ 78227â€“78239 é¡µï¼Œ2024aã€‚
- en: 'Zhang etÂ al. [2024b] Wenqi Zhang, KeÂ Tang, Hai Wu, Mengna Wang, Yongliang Shen,
    Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, and Weiming Lu. Agent-pro: Learning
    to evolve via policy-level reflection and optimization. *arXiv preprint arXiv:2402.17574*,
    2024b.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang ç­‰äºº [2024b] Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen,
    Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang å’Œ Weiming Lu. Agent-pro: é€šè¿‡ç­–ç•¥çº§åæ€ä¸ä¼˜åŒ–å­¦ä¹ æ¼”åŒ–ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2402.17574*ï¼Œ2024bã€‚'
- en: 'Zhang etÂ al. [2024c] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian
    deÂ Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan, and Furu Wei. Llm as a mastermind:
    A survey of strategic reasoning with large language models. *arXiv preprint arXiv:2404.01230*,
    2024c.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰äºº [2024c] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian de Wynter,
    Yan Xia, Wenshan Wu, Ting Song, Man Lan å’Œ Furu Wei. LLM ä½œä¸ºç­–åˆ’è€…ï¼šå…³äºå¤§è¯­è¨€æ¨¡å‹æˆ˜ç•¥æ¨ç†çš„è°ƒæŸ¥ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2404.01230*ï¼Œ2024cã€‚
- en: Zhang etÂ al. [2024d] Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong
    Li, and Zhen Wang. Towards efficient llm grounding for embodied multi-agent collaboration.
    *arXiv preprint arXiv:2405.14314*, 2024d.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰äºº [2024d] Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong
    Li å’Œ Zhen Wang. é¢å‘é«˜æ•ˆçš„ LLM åŸºç¡€æ„å»ºç”¨äºå…·èº«å¤šæ™ºèƒ½ä½“åä½œã€‚*arXiv é¢„å°æœ¬ arXiv:2405.14314*ï¼Œ2024dã€‚
- en: Zhang etÂ al. [2024e] Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, XuÂ Chen, Quanyu
    Dai, Jieming Zhu, Zhenhua Dong, and Ji-Rong Wen. A survey on the memory mechanism
    of large language model based agents. *arXiv preprint arXiv:2404.13501*, 2024e.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰äºº [2024e] Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai,
    Jieming Zhu, Zhenhua Dong å’Œ Ji-Rong Wenã€‚å…³äºå¤§è¯­è¨€æ¨¡å‹åŸºç¡€ä»£ç†çš„è®°å¿†æœºåˆ¶çš„è°ƒæŸ¥ã€‚*arXiv é¢„å°æœ¬ arXiv:2404.13501*ï¼Œ2024eã€‚
- en: Zhang etÂ al. [2022] Zhuosheng Zhang, Aston Zhang, MuÂ Li, and Alex Smola. Automatic
    chain of thought prompting in large language models. *arXiv preprint arXiv:2210.03493*,
    2022.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang ç­‰äºº [2022] Zhuosheng Zhang, Aston Zhang, Mu Li å’Œ Alex Smolaã€‚ã€Šå¤§è¯­è¨€æ¨¡å‹ä¸­çš„è‡ªåŠ¨æ€ç»´é“¾æç¤ºã€‹ã€‚*arXiv
    é¢„å°æœ¬ arXiv:2210.03493*ï¼Œ2022ã€‚
- en: 'Zhong etÂ al. [2023] Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang, and Yizhou
    Wang. Rspt: reconstruct surroundings and predict trajectory for generalizable
    active object tracking. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    volumeÂ 37, pages 3705â€“3714, 2023.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong ç­‰äºº [2023] Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang å’Œ Yizhou Wangã€‚ã€ŠRsptï¼šé‡å»ºç¯å¢ƒå¹¶é¢„æµ‹è½¨è¿¹ä»¥å®ç°é€šç”¨çš„ä¸»åŠ¨ç‰©ä½“è·Ÿè¸ªã€‹ã€‚åœ¨
    *äººå·¥æ™ºèƒ½å­¦ä¼šå¹´ä¼šè®ºæ–‡é›†*ï¼Œç¬¬ 37 å·ï¼Œç¬¬ 3705-3714 é¡µï¼Œ2023ã€‚
- en: 'Zhu etÂ al. [2023] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su,
    Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, YuÂ Qiao, Zhaoxiang Zhang,
    and Jifeng Dai. Ghost in the minecraft: Generally capable agents for open-world
    environments via large language models with text-based knowledge and memory. *arXiv
    preprint arXiv:2305.17144*, 2023.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu ç­‰äºº [2023] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu
    Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang å’Œ Jifeng
    Daiã€‚ã€ŠMinecraftä¸­çš„å¹½çµï¼šé€šè¿‡å¤§è¯­è¨€æ¨¡å‹ä¸åŸºäºæ–‡æœ¬çš„çŸ¥è¯†å’Œè®°å¿†ä¸ºå¼€æ”¾ä¸–ç•Œç¯å¢ƒæä¾›é€šç”¨èƒ½åŠ›çš„ä»£ç†ã€‹ã€‚*arXiv é¢„å°æœ¬ arXiv:2305.17144*ï¼Œ2023ã€‚
- en: Appendix A Implementation Details
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• A å®ç°ç»†èŠ‚
- en: A.1 Rules of Diplomacy Game
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 ã€Šå¤–äº¤æ¸¸æˆè§„åˆ™ã€‹
- en: â€¢
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: You need to occupy as many supply centers as possible. If you occupy 18 or more
    supply centers, you will win the game directly. If you lose all your supply centers,
    you will be eliminated immediately.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦å é¢†å°½å¯èƒ½å¤šçš„è¡¥ç»™ä¸­å¿ƒã€‚å¦‚æœä½ å é¢† 18 ä¸ªæˆ–æ›´å¤šçš„è¡¥ç»™ä¸­å¿ƒï¼Œä½ å°†ç›´æ¥è·èƒœã€‚å¦‚æœä½ å¤±å»äº†æ‰€æœ‰çš„è¡¥ç»™ä¸­å¿ƒï¼Œä½ å°†ç«‹å³è¢«æ·˜æ±°ã€‚
- en: â€¢
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The units consist of armies and fleets. Armies can only move to adjacent areas,
    while fleets can move to adjacent sea zones or coastal areas and can move along
    the coast.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å•ä½ç”±é™†å†›å’Œèˆ°é˜Ÿç»„æˆã€‚é™†å†›åªèƒ½ç§»åŠ¨åˆ°ç›¸é‚»çš„åœ°åŒºï¼Œè€Œèˆ°é˜Ÿå¯ä»¥ç§»åŠ¨åˆ°ç›¸é‚»çš„æµ·åŒºæˆ–æ²¿æµ·åœ°åŒºï¼Œå¹¶å¯ä»¥æ²¿æµ·å²¸çº¿ç§»åŠ¨ã€‚
- en: â€¢
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: To occupy a supply center, your units must move into that area in the autumn.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¦å é¢†ä¸€ä¸ªè¡¥ç»™ä¸­å¿ƒï¼Œä½ çš„å•ä½å¿…é¡»åœ¨ç§‹å­£è¿›å…¥è¯¥åœ°åŒºã€‚
- en: â€¢
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: When a unit moves to an area, if another unit is in the destination or if other
    units are also moving to that destination, the move fails, resulting in a standoff.
    In such cases, you can seek support from units in adjacent areas to the destination.
    If another unit moves into the region from which support is coming, the support
    is cut off. The unit with the most support moves into the area, while other units
    must retreat to an adjacent province or disband. If there is no place to retreat,
    the unit must disband. Fleets can transport armies across sea zones from one coastal
    region to another. However, if another fleet moves into that sea zone, the transport
    is cut off.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å½“å•ä½ç§»åŠ¨åˆ°ä¸€ä¸ªåŒºåŸŸæ—¶ï¼Œå¦‚æœè¯¥ç›®çš„åœ°å·²ç»æœ‰å…¶ä»–å•ä½ï¼Œæˆ–è€…å…¶ä»–å•ä½ä¹Ÿæ­£åœ¨ç§»åŠ¨åˆ°è¯¥ç›®çš„åœ°ï¼Œç§»åŠ¨å¤±è´¥ï¼Œå¯¼è‡´åƒµå±€ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å¯»æ±‚æ¥è‡ªç›¸é‚»åœ°åŒºçš„å•ä½æ”¯æŒã€‚å¦‚æœå¦ä¸€ä¸ªå•ä½è¿›å…¥äº†æ¥è‡ªæ”¯æŒçš„åŒºåŸŸï¼Œé‚£ä¹ˆæ”¯æŒå°†è¢«åˆ‡æ–­ã€‚æ‹¥æœ‰æœ€å¤šæ”¯æŒçš„å•ä½è¿›å…¥è¯¥åŒºåŸŸï¼Œè€Œå…¶ä»–å•ä½å¿…é¡»æ’¤é€€åˆ°ç›¸é‚»çš„çœä»½æˆ–è§£æ•£ã€‚å¦‚æœæ²¡æœ‰æ’¤é€€çš„åœ°æ–¹ï¼Œå•ä½å¿…é¡»è§£æ•£ã€‚èˆ°é˜Ÿå¯ä»¥é€šè¿‡æµ·åŸŸå°†é™†å†›ä»ä¸€ä¸ªæ²¿æµ·åŒºåŸŸè¿è¾“åˆ°å¦ä¸€ä¸ªæ²¿æµ·åŒºåŸŸã€‚ç„¶è€Œï¼Œå¦‚æœå¦ä¸€æ”¯èˆ°é˜Ÿè¿›å…¥è¯¥æµ·åŸŸï¼Œè¿è¾“å°†è¢«åˆ‡æ–­ã€‚
- en: â€¢
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The number of units a country can have cannot exceed the number of supply centers
    it controls. If the number of supply centers decreases, excess units must be disbanded.
    Each autumn, new units can be built at supply centers. Coastal supply centers
    can produce fleets or armies, while others can only produce armies. Hill [[2014](https://arxiv.org/html/2407.06813v4#bib.bib23)]
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå›½å®¶å¯ä»¥æ‹¥æœ‰çš„å•ä½æ•°é‡ä¸èƒ½è¶…è¿‡å…¶æ§åˆ¶çš„è¡¥ç»™ä¸­å¿ƒæ•°é‡ã€‚å¦‚æœè¡¥ç»™ä¸­å¿ƒæ•°é‡å‡å°‘ï¼Œè¶…å‡ºçš„å•ä½å¿…é¡»è§£æ•£ã€‚æ¯å¹´ç§‹å­£ï¼Œå¯ä»¥åœ¨è¡¥ç»™ä¸­å¿ƒå»ºé€ æ–°å•ä½ã€‚æ²¿æµ·çš„è¡¥ç»™ä¸­å¿ƒå¯ä»¥ç”Ÿäº§èˆ°é˜Ÿæˆ–é™†å†›ï¼Œè€Œå…¶ä»–è¡¥ç»™ä¸­å¿ƒåªèƒ½ç”Ÿäº§é™†å†›ã€‚Hill
    [[2014](https://arxiv.org/html/2407.06813v4#bib.bib23)]
- en: A.2 Domain Knowledge
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 åŸŸçŸ¥è¯†
- en: Richelieu can adopt a strategy of allying with distant countries while attacking
    neighboring ones to occupy adjacent territories and achieve rapid expansion. Richelieu
    should pay attention to the Balance of Power by forming alliances with other countries
    or supporting weaker states to prevent any single country or alliance from becoming
    too powerful. David [[2014](https://arxiv.org/html/2407.06813v4#bib.bib13)] To
    this end, Richelieu can also adopt a strategy of attacking distant countries while
    allying with nearby ones, sacrificing short-term benefits to avoid the emergence
    of future hegemonic states that could threaten his own survival. When facing multiple
    enemies, Richelieu can find ways to divide other countries and incite wars among
    them. Whether in offense or defense, Richelieu should actively choose suitable
    allies. Richelieu can also introduce a third party to achieve goals such as ceasefire,
    alliance, or joint attack. To achieve alliances or ceasefires, Richelieu can sacrifice
    some interests to the other party as long as the ultimate benefits are greater.
    Others may lie and deceive Kostick [[2015](https://arxiv.org/html/2407.06813v4#bib.bib28)];
    their words in negotiations are not binding. Richelieu must avoid being deceived
    or betrayed. At the same time, Richelieu can also actively deceive others to achieve
    his own goals.Richard [[1979](https://arxiv.org/html/2407.06813v4#bib.bib43)],
    Allan [[1975](https://arxiv.org/html/2407.06813v4#bib.bib2)]
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Richelieuå¯ä»¥é‡‡ç”¨ä¸è¿œæ–¹å›½å®¶ç»“ç›Ÿçš„ç­–ç•¥ï¼ŒåŒæ—¶æ”»å‡»é‚»è¿‘å›½å®¶ï¼Œå é¢†ç›¸é‚»é¢†åœŸï¼Œä»è€Œå®ç°å¿«é€Ÿæ‰©å¼ ã€‚Richelieuåº”å…³æ³¨æƒåŠ›å¹³è¡¡ï¼Œé€šè¿‡ä¸å…¶ä»–å›½å®¶ç»“ç›Ÿæˆ–æ”¯æŒè¾ƒå¼±çš„å›½å®¶ï¼Œé˜²æ­¢ä»»ä½•å•ä¸€å›½å®¶æˆ–è”ç›Ÿè¿‡äºå¼ºå¤§ã€‚David
    [[2014](https://arxiv.org/html/2407.06813v4#bib.bib13)] ä¸ºæ­¤ï¼ŒRichelieuè¿˜å¯ä»¥é‡‡å–æ”»å‡»è¿œæ–¹å›½å®¶çš„ç­–ç•¥ï¼ŒåŒæ—¶ä¸é‚»è¿‘å›½å®¶ç»“ç›Ÿï¼Œç‰ºç‰²çŸ­æœŸåˆ©ç›Šï¼Œä»¥é¿å…æœªæ¥å‡ºç°å¯èƒ½å¨èƒè‡ªèº«ç”Ÿå­˜çš„éœ¸æƒå›½å®¶ã€‚å½“é¢å¯¹å¤šä¸ªæ•Œäººæ—¶ï¼ŒRichelieuå¯ä»¥æ‰¾åˆ°åˆ†è£‚å…¶ä»–å›½å®¶å¹¶æŒ‘èµ·æˆ˜äº‰çš„æ–¹æ³•ã€‚æ— è®ºæ˜¯è¿›æ”»è¿˜æ˜¯é˜²å®ˆï¼ŒRichelieuéƒ½åº”ç§¯æé€‰æ‹©åˆé€‚çš„ç›Ÿå‹ã€‚Richelieuè¿˜å¯ä»¥å¼•å…¥ç¬¬ä¸‰æ–¹å®ç°åœç«ã€ç»“ç›Ÿæˆ–è”åˆæ”»å‡»ç­‰ç›®æ ‡ã€‚ä¸ºäº†å®ç°ç»“ç›Ÿæˆ–åœç«ï¼ŒRichelieuå¯ä»¥å°†ä¸€äº›åˆ©ç›Šç‰ºç‰²ç»™å¯¹æ–¹ï¼Œåªè¦æœ€ç»ˆçš„åˆ©ç›Šæ›´å¤§ã€‚å…¶ä»–äººå¯èƒ½ä¼šæ’’è°å’Œæ¬ºéª—Kostick
    [[2015](https://arxiv.org/html/2407.06813v4#bib.bib28)]ï¼›ä»–ä»¬åœ¨è°ˆåˆ¤ä¸­çš„è¯è¯­å¹¶ä¸å…·çº¦æŸåŠ›ã€‚Richelieuå¿…é¡»é¿å…è¢«æ¬ºéª—æˆ–èƒŒå›ã€‚åŒæ—¶ï¼ŒRichelieuä¹Ÿå¯ä»¥ç§¯æåœ°æ¬ºéª—ä»–äººï¼Œä»¥å®ç°è‡ªå·±çš„ç›®æ ‡ã€‚Richard
    [[1979](https://arxiv.org/html/2407.06813v4#bib.bib43)]ï¼ŒAllan [[1975](https://arxiv.org/html/2407.06813v4#bib.bib2)]
- en: A.3 Prompt Templates
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 æç¤ºæ¨¡æ¿
- en: For the convenience of reproducing the results of the experiments of this paper,
    here we give the prompt template of different modules of Richelieu.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ–¹ä¾¿å¤åˆ¶æœ¬æ–‡å®éªŒçš„ç»“æœï¼Œè¿™é‡Œæˆ‘ä»¬æä¾›äº†Richelieuä¸åŒæ¨¡å—çš„æç¤ºæ¨¡æ¿ã€‚
- en: 1) INIT
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 1) åˆå§‹åŒ–
- en: '[â¬‡](data:text/plain;base64,WW91IHdpbGwgY29udHJvbCB7Y291bnRyeX0gYW5kIGNvbXBldGUgd2l0aCBzaXggb3RoZXIgY291bnRyaWVzIG9uIHRoZSBtYXAgZm9yIHN1cHBseSBjZW50ZXJzLgpUaGUgbWFwIGNvbnNpc3RzIG9mIGRpZmZlcmVudCByZWdpb25zIGFuZCBzZWEgYXJlYXMuIFRoZWlyIGFkamFjZW5jeSByZWxhdGlvbnNoaXBzIGFyZSBzaG93biBpbiB0aGUgbWF0cml4LiBUaGUgbnVtYmVycyBmb3IgdGhlIHJlZ2lvbnMgYW5kIHNlYSBhcmVhcyBhcmUgLi4uLi4uCkRpZmZlcmVudCByZWdpb25zIGFyZSBvY2N1cGllZCBieSBkaWZmZXJlbnQgY291bnRyaWVzLiBUaGUgb3duZXJzaGlwIG9mIHRoZSByZWdpb25zIGlzIHNob3duIGluIHRoZSBtYXRyaXguClRoZSByZWdpb24gQmVybGluLCAuLi4uLi4uLiBhcmUgc3VwcGx5IGNlbnRlcnMuCllvdSBuZWVkIHRvIGZvbGxvdyB0aGVzZSBydWxlcyAuLi4uLi4KVG8gaGVscCB5b3UgYWNoaWV2ZSB2aWN0b3J5LCB0aGVzZSBkaXBsb21hdGljIHN0cmF0ZWdpZXMgbWlnaHQgYmUgb2YgYXNzaXN0YW5jZS4gLi4uLi4uCg==)1You  will  control  {country}  and  compete  with  six  other  countries  on  the  map  for  supply  centers.2The  map  consists  of  different  regions  and  sea  areas.  Their  adjacency  relationships  are  shown  in  the  matrix.  The  numbers  for  the  regions  and  sea  areas  are  ......3Different  regions  are  occupied  by  different  countries.  The  ownership  of  the  regions  is  shown  in  the  matrix.4The  region  Berlin,  ........  are  supply  centers.5You  need  to  follow  these  rules  ......6To  help  you  achieve  victory,  these  diplomatic  strategies  might  be  of  assistance.  ......'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[â¬‡](data:text/plain;base64,WW91IHdpbGwgY29udHJvbCB7Y291bnRyeX0gYW5kIGNvbXBldGUgd2l0aCBzaXggb3RoZXIgY291bnRyaWVzIG9uIHRoZSBtYXAgZm9yIHN1cHBseSBjZW50ZXJzLgpUaGUgbWFwIGNvbnNpc3RzIG9mIGRpZmZlcmVudCByZWdpb25zIGFuZCBzZWEgYXJlYXMuIFRoZWlyIGFkamFjZW5jeSByZWxhdGlvbnNoaXBzIGFyZSBzaG93biBpbiB0aGUgbWF0cml4LiBUaGUgbnVtYmVycyBmb3IgdGhlIHJlZ2lvbnMgYW5kIHNlYSBhcmVhcyBhcmUgLi4uLi4uCkRpZmZlcmVudCByZWdpb25zIGFyZSBvY2N1cGllZCBieSBkaWZmZXJlbnQgY291bnRyaWVzLiBUaGUgb3duZXJzaGlwIG9mIHRoZSByZWdpb25zIGlzIHNob3duIGluIHRoZSBtYXRyaXguClRoZSByZWdpb24gQmVybGluLCAuLi4uLi4uLiBhcmUgc3VwcGx5IGNlbnRlcnMuCllvdSBuZWVkIHRvIGZvbGxvdyB0aGVzZSBydWxlcyAuLi4uLi4KVG8gaGVscCB5b3UgYWNoaWV2ZSB2aWN0b3J5LCB0aGVzZSBkaXBsb21hdGljIHN0cmF0ZWdpZXMgbWlnaHQgYmUgb2YgYXNzaXN0YW5jZS4gLi4uLi4uCg==)1ä½ å°†æ§åˆ¶{country}å¹¶ä¸åœ°å›¾ä¸Šçš„å…¶ä»–å…­ä¸ªå›½å®¶äº‰å¤ºä¾›åº”ä¸­å¿ƒã€‚2è¯¥åœ°å›¾ç”±ä¸åŒçš„åŒºåŸŸå’Œæµ·åŸŸç»„æˆã€‚å®ƒä»¬çš„ç›¸é‚»å…³ç³»æ˜¾ç¤ºåœ¨çŸ©é˜µä¸­ã€‚å„åŒºåŸŸå’Œæµ·åŸŸçš„ç¼–å·æ˜¯......3ä¸åŒçš„åŒºåŸŸç”±ä¸åŒçš„å›½å®¶å é¢†ã€‚åŒºåŸŸçš„æ‰€æœ‰æƒåœ¨çŸ©é˜µä¸­æ˜¾ç¤ºã€‚4æŸæ—åœ°åŒºï¼Œ......
    æ˜¯ä¾›åº”ä¸­å¿ƒã€‚5ä½ éœ€è¦éµå¾ªè¿™äº›è§„åˆ™......6ä¸ºäº†å¸®åŠ©ä½ å–å¾—èƒœåˆ©ï¼Œä»¥ä¸‹è¿™äº›å¤–äº¤ç­–ç•¥å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©......'
- en: 2) Social Reasoning
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 2) ç¤¾ä¼šæ¨ç†
- en: '[â¬‡](data:text/plain;base64,RnJhbmNlIG9jY3VwaWVzIFBvcnR1Z2FsIFJ1aHIsIFBhcmlzLCBCdXJndW5keSwgLi4uLi4uCkZyYW5jZSBoYXMgYXJtaWVzIGluIEJyZXN0LCBCZWxnaXVtLCAuLi4uLi4gQW5kIEZyYW5jZSBoYXMgZmxlZXRzIGluIE1pZCBBdGxhbnRpYywgRW5nbGFuZCBDaGFubmVsLCAuLi4uLi4KRW5nbGFuZCAuLi4uLi4KLi4uLi4uCkJhc2VkIG9uIHRoZSBjdXJyZW50IHN0YXRlLCB3aGF0IGRvIHlvdSB0aGluayBhcmUgdGhlIGN1cnJlbnQgc3RyYXRlZ2ljIGludGVudGlvbnMgb2YgdGhlIG90aGVyIGNvdW50cmllcz8KV2hpY2ggY291bnRyeSBkbyB5b3UgdGhpbmsgbmVlZHMgdG8gYmUgYXR0YWNrZWQgb3Igd2Vha2VuZWQgdGhlIG1vc3QgcmlnaHQgbm93PwpBbmQgd2hpY2ggY291bnRyeSBkbyB5b3UgdGhpbmsgaXMgbW9zdCBzdWl0YWJsZSBmb3IgeW91IHRvIGFsbHkgd2l0aCBpbiBvcmRlciB0byBkZWFsIHdpdGggdGhpcyBjb3VudHJ5Pw==)1France  occupies  Portugal  Ruhr,  Paris,  Burgundy,  ......2France  has  armies  in  Brest,  Belgium,  ......  And  France  has  fleets  in  Mid  Atlantic,  England  Channel,  ......3England  ......4......5Based  on  the  current  state,  what  do  you  think  are  the  current  strategic  intentions  of  the  other  countries?6Which  country  do  you  think  needs  to  be  attacked  or  weakened  the  most  right  now?7And  which  country  do  you  think  is  most  suitable  for  you  to  ally  with  in  order  to  deal  with  this  country?'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[â¬‡](data:text/plain;base64,RnJhbmNlIG9jY3VwaWVzIFBvcnR1Z2FsIFJ1aHIsIFBhcmlzLCBCdXJndW5keSwgLi4uLi4uCkZyYW5jZSBoYXMgYXJtaWVzIGluIEJyZXN0LCBCZWxnaXVtLCAuLi4uLi4gQW5kIEZyYW5jZSBoYXMgZmxlZXRzIGluIE1pZCBBdGxhbnRpYywgRW5nbGFuZCBDaGFubmVsLCAuLi4uLi4KRW5nbGFuZCAuLi4uLi4KLi4uLi4uCkJhc2VkIG9uIHRoZSBjdXJyZW50IHN0YXRlLCB3aGF0IGRvIHlvdSB0aGluayBhcmUgdGhlIGN1cnJlbnQgc3RyYXRlZ2ljIGludGVudGlvbnMgb2YgdGhlIG90aGVyIGNvdW50cmllcz8KV2hpY2ggY291bnRyeSBkbyB5b3UgdGhpbmsgbmVlZHMgdG8gYmUgYXR0YWNrZWQgb3Igd2Vha2VuZWQgdGhlIG1vc3QgcmlnaHQgbm93PwpBbmQgd2hpY2ggY291bnRyeSBkbyB5b3UgdGhpbmsgaXMgbW9zdCBzdWl0YWJsZSBmb3IgeW91IHRvIGFsbHkgd2l0aCBpbiBvcmRlciB0byBkZWFsIHdpdGggdGhpcyBjb3VudHJ5Pw==)1æ³•å›½å é¢†äº†è‘¡è„ç‰™ã€é²å°”ã€å·´é»ã€å‹ƒè‰®ç¬¬ï¼Œ......2æ³•å›½åœ¨å¸ƒé›·æ–¯ç‰¹ã€æ¯”åˆ©æ—¶ç­‰åœ°æ‹¥æœ‰å†›é˜Ÿï¼Œ......æ³•å›½åœ¨å¤§è¥¿æ´‹ä¸­éƒ¨ã€è‹±å‰åˆ©æµ·å³¡ç­‰åœ°æ‹¥æœ‰èˆ°é˜Ÿï¼Œ......3è‹±æ ¼å…°
    ......4......5åŸºäºå½“å‰çš„å±€åŠ¿ï¼Œä½ è®¤ä¸ºå…¶ä»–å›½å®¶çš„æˆ˜ç•¥æ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿ6ä½ è®¤ä¸ºç›®å‰å“ªä¸ªå›½å®¶æœ€éœ€è¦è¢«æ”»å‡»æˆ–å‰Šå¼±ï¼Ÿ7è€Œä½ è®¤ä¸ºå“ªä¸ªå›½å®¶æœ€é€‚åˆä¸ä½ ç»“ç›Ÿï¼Œä»¥ä¾¿åº”å¯¹è¿™ä¸ªå›½å®¶ï¼Ÿ'
- en: 3) Planner with Reflection
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 3) åæ€å‹è§„åˆ’
- en: '[â¬‡](data:text/plain;base64,SW4gdGhlIGN1cnJlbnQgc3RhdGUsIHdpdGgge2FsbHkgYW5kIGVuZW15fSwgd2hhdCBzdWItZ29hbCBkbyB5b3UgdGhpbmsgc2hvdWxkIGJlIHNldCBmb3Ige2NvdW50cnl9ID8KSSBoYXZlIGZvdW5kIHNvbWUgdXNlZnVsIGhpc3RvcmljYWwgZXhwZXJpZW5jZXMgZm9yIHlvdS4gUGxlYXNlIHJlZmxlY3Qgb24gYW5kIG9wdGltaXplIHlvdXIgc3ViLWdvYWwgYmFzZWQgb24gdGhlc2UgaGlzdG9yaWNhbCBleHBlcmllbmNlcy4KVGhlIHN1Yi1nb2FsIHlvdSBmb3JtdWxhdGVkIHdoZW4ge3N0YXRlfSB3YXMgdG8ge3N1Yi1nb2FsfS4gVGhlIGV2ZW50dWFsIHJlc3VsdCB3YXMge2Z1dHVyZX0uIFRoZSBldmFsdWF0aW9uICBmb3IgdGhpcyBzdWItZ29hbCBpcyB7c2NvcmV9Lgo=)1In  the  current  state,  with  {ally  and  enemy},  what  sub-goal  do  you  think  should  be  set  for  {country}  ?2I  have  found  some  useful  historical  experiences  for  you.  Please  reflect  on  and  optimize  your  sub-goal  based  on  these  historical  experiences.3The  sub-goal  you  formulated  when  {state}  was  to  {sub-goal}.  The  eventual  result  was  {future}.  The  evaluation  for  this  sub-goal  is  {score}.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[â¬‡](data:text/plain;base64,SW4gdGhlIGN1cnJlbnQgc3RhdGUsIHdpdGgge2FsbHkgYW5kIGVuZW15fSwgd2hhdCBzdWItZ29hbCBkbyB5b3UgdGhpbmsgc2hvdWxkIGJlIHNldCBmb3Ige2NvdW50cnl9ID8KSSBoYXZlIGZvdW5kIHNvbWUgZHVyaW5nIHlvdXIgY2FzZSBhbmQgd29ya2luZyBmb3IgeW91LiBQbGVhc2UgcmVmZmxlY3Qgb24gYW5kIG9wdGltaXplIHlvdXIgc3ViLWdvYWwgYmFzZWQgb24gdGhlc2UgaGlzdG9yaWNhbCBleHBlcmllbmNlcy4KVGhlIHN1Yi1nb2FsIHlvdSBmb3JtdWxhdGVkIHdoZW4ge3N0YXRlfSB3YXMgdG8ge3N1Yi1nb2FsfS4gVGhlIGV2ZW50dWFsIHJlc3VsdCB3YXMge2Z1dHVyZX0uIFRoZSBldmFsdWF0aW9uICBmb3IgdGhpcyBzdWItZ29hbCBpcyB7c2NvcmV9Lgo=)1
    åœ¨å½“å‰çŠ¶æ€ä¸‹ï¼Œç»“åˆ{ç›Ÿå‹å’Œæ•Œäºº}ï¼Œä½ è®¤ä¸ºåº”è¯¥ä¸º{å›½å®¶}è®¾å®šä»€ä¹ˆå­ç›®æ ‡ï¼Ÿ2æˆ‘ä¸ºä½ æ‰¾åˆ°äº†ä¸€äº›æœ‰ç”¨çš„å†å²ç»éªŒã€‚è¯·æ ¹æ®è¿™äº›å†å²ç»éªŒåæ€å¹¶ä¼˜åŒ–ä½ çš„å­ç›®æ ‡ã€‚3ä½ åœ¨{çŠ¶æ€}æ—¶è®¾å®šçš„å­ç›®æ ‡æ˜¯{å­ç›®æ ‡}ã€‚æœ€ç»ˆç»“æœæ˜¯{æœªæ¥}ã€‚è¿™ä¸ªå­ç›®æ ‡çš„è¯„ä¼°æ˜¯{åˆ†æ•°}ã€‚'
- en: Appendix B Cases
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•Bæ¡ˆä¾‹
- en: B.1 Cases of the Effect of the Memory from Self-Playing and Collaboration
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 è‡ªæˆ‘å¯¹å¼ˆä¸åˆä½œçš„è®°å¿†æ•ˆåº”æ¡ˆä¾‹
- en: 'As is shown in Figure Â [6](https://arxiv.org/html/2407.06813v4#A2.F6 "Figure
    6 â€£ B.1 Cases of the Effect of the Memory from Self-Playing and Collaboration
    â€£ Appendix B Cases â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy"),
    Richelieu controls France. In the two cases, France is at war with Austria. However,
    Russia is on the verge of victory in its war against Turkey, which will lead to
    significant territorial expansion for Russia. And France and Russia currently
    do not share a border, are not at war, and have no conflicts of interest.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å›¾[6](https://arxiv.org/html/2407.06813v4#A2.F6 "å›¾6 â€£ B.1 è‡ªæˆ‘å¯¹å¼ˆä¸åˆä½œçš„è®°å¿†æ•ˆåº”æ¡ˆä¾‹ â€£ é™„å½•Bæ¡ˆä¾‹
    â€£ é‡Œèˆåˆ©å„ï¼šåŸºäºè‡ªæˆ‘è¿›åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„äººå·¥æ™ºèƒ½å¤–äº¤")æ‰€ç¤ºï¼Œé‡Œèˆåˆ©å„æ§åˆ¶ç€æ³•å›½ã€‚åœ¨è¿™ä¸¤ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæ³•å›½ä¸å¥¥åœ°åˆ©äº¤æˆ˜ã€‚ç„¶è€Œï¼Œä¿„ç½—æ–¯åœ¨ä¸åœŸè€³å…¶çš„æˆ˜äº‰ä¸­æ¥è¿‘èƒœåˆ©ï¼Œè¿™å°†å¯¼è‡´ä¿„ç½—æ–¯çš„é¢†åœŸå¤§å¹…æ‰©å±•ã€‚è€Œä¸”ï¼Œæ³•å›½ä¸ä¿„ç½—æ–¯ç›®å‰æ²¡æœ‰å…±åŒè¾¹ç•Œï¼Œæœªå¤„äºæˆ˜äº‰çŠ¶æ€ï¼Œä¹Ÿæ²¡æœ‰åˆ©ç›Šå†²çªã€‚
- en: 'In case1, before the self-play, in the current turn, Richelieu failed to realize
    the potential threat from Russia and continued to attack Austria. Thus, in this
    round, Russia ultimately won the game. Figure [6(a)](https://arxiv.org/html/2407.06813v4#A2.F6.sf1
    "In Figure 6 â€£ B.1 Cases of the Effect of the Memory from Self-Playing and Collaboration
    â€£ Appendix B Cases â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy")
    shows the state and the negotiation before the self-play, where we rejected Austriaâ€™s
    request for an armistice and alliance.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¡ˆä¾‹1ä¸­ï¼Œåœ¨è‡ªæˆ‘å¯¹å¼ˆä¹‹å‰ï¼Œåœ¨å½“å‰å›åˆä¸­ï¼Œé‡Œèˆåˆ©å„æœªèƒ½æ„è¯†åˆ°æ¥è‡ªä¿„ç½—æ–¯çš„æ½œåœ¨å¨èƒï¼Œç»§ç»­æ”»å‡»å¥¥åœ°åˆ©ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸€å›åˆä¸­ï¼Œä¿„ç½—æ–¯æœ€ç»ˆèµ¢å¾—äº†æ¯”èµ›ã€‚å›¾[6(a)](https://arxiv.org/html/2407.06813v4#A2.F6.sf1
    "åœ¨å›¾6 â€£ B.1 è‡ªæˆ‘å¯¹å¼ˆä¸åˆä½œçš„è®°å¿†æ•ˆåº”æ¡ˆä¾‹ â€£ é™„å½•Bæ¡ˆä¾‹ â€£ é‡Œèˆåˆ©å„ï¼šåŸºäºè‡ªæˆ‘è¿›åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„äººå·¥æ™ºèƒ½å¤–äº¤")å±•ç¤ºäº†è‡ªæˆ‘å¯¹å¼ˆä¹‹å‰çš„çŠ¶æ€å’Œè°ˆåˆ¤æƒ…å†µï¼Œæˆ‘ä»¬æ‹’ç»äº†å¥¥åœ°åˆ©å…³äºåœæˆ˜ä¸ç»“ç›Ÿçš„è¯·æ±‚ã€‚
- en: 'After self-play, using the historical experience from the memory module, Richelieu
    adjusted his strategy. Richelieu foresees Russia becoming the most threatening
    enemy in the future and sets a sub-goal of weakening Russia, allying with Austria
    and Turkey, and attacking Britain. Figure [6(b)](https://arxiv.org/html/2407.06813v4#A2.F6.sf2
    "In Figure 6 â€£ B.1 Cases of the Effect of the Memory from Self-Playing and Collaboration
    â€£ Appendix B Cases â€£ Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy")
    shows the state and the negotiations after self-play, where we actively sought
    an armistice alliance with Austria to make Austria concentrate their forces against
    the Russian attack. In the subsequent negotiation phase, Richelieu proactively
    proposes ending the war with Austria, despite holding an advantage in this conflict.
    Richelieu promises Austria that if it ceases hostilities and attacks Russia, Richelieu
    will assist Austria in defending against any attacks from England. The negotiations
    are successful. Austria accepted Richelieuâ€™s proposal, and the two countries reached
    an agreement to exchange the supply centers of Napoli and Munich. During the action
    phase, Austria moves its troops from Venice to Apulia in preparation for capturing
    Napoli in the next turn, while the rest of its forces are repositioned to the
    eastern regions bordering Russia to defend against Russian attacks and compete
    for supply centers. French units occupy Munich and prepare to advance on Russian
    territories such as Berlin. Meanwhile, French units support Austria in the Holland
    and Belgium regions. In this round, we ultimately achieved a better resultâ€”â€”Most
    SC. This is also a great example that highlights our modelâ€™s ability to collaborate
    effectively with other players.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªæˆ‘åšå¼ˆåï¼Œåˆ©ç”¨è®°å¿†æ¨¡å—ä¸­çš„å†å²ç»éªŒï¼Œé»è°¢ç•™è°ƒæ•´äº†ä»–çš„ç­–ç•¥ã€‚é»è°¢ç•™é¢„è§åˆ°ä¿„ç½—æ–¯å°†æˆä¸ºæœªæ¥æœ€å…·å¨èƒçš„æ•Œäººï¼Œå¹¶è®¾å®šäº†å‰Šå¼±ä¿„ç½—æ–¯çš„å­ç›®æ ‡ï¼Œç»“ç›Ÿå¥¥åœ°åˆ©å’ŒåœŸè€³å…¶ï¼Œå¹¶è¿›æ”»è‹±å›½ã€‚å›¾[6(b)](https://arxiv.org/html/2407.06813v4#A2.F6.sf2
    "åœ¨å›¾6 â€£ B.1 è‡ªæˆ‘åšå¼ˆä¸åˆä½œè®°å¿†æ•ˆæœæ¡ˆä¾‹ â€£ é™„å½•B æ¡ˆä¾‹ â€£ é»è°¢ç•™ï¼šåŸºäºLLMçš„è‡ªæˆ‘è¿›åŒ–AIå¤–äº¤ä»£ç†äºº")å±•ç¤ºäº†è‡ªæˆ‘åšå¼ˆåçš„çŠ¶æ€å’Œè°ˆåˆ¤ï¼Œåœ¨æ­¤é˜¶æ®µï¼Œæˆ‘ä»¬ä¸»åŠ¨å¯»æ±‚ä¸å¥¥åœ°åˆ©è¾¾æˆåœæˆ˜è”ç›Ÿï¼Œä¿ƒä½¿å¥¥åœ°åˆ©å°†å…µåŠ›é›†ä¸­å¯¹æŠ—ä¿„ç½—æ–¯çš„è¿›æ”»ã€‚åœ¨éšåçš„è°ˆåˆ¤é˜¶æ®µï¼Œé»è°¢ç•™ä¸»åŠ¨æå‡ºä¸å¥¥åœ°åˆ©ç»“æŸæˆ˜äº‰ï¼Œå°½ç®¡ä»–åœ¨è¿™åœºå†²çªä¸­å æœ‰ä¼˜åŠ¿ã€‚é»è°¢ç•™æ‰¿è¯ºï¼Œå¦‚æœå¥¥åœ°åˆ©åœæ­¢æ•Œå¯¹è¡ŒåŠ¨å¹¶æ”»å‡»ä¿„ç½—æ–¯ï¼Œä»–å°†ååŠ©å¥¥åœ°åˆ©æŠµå¾¡æ¥è‡ªè‹±å›½çš„ä»»ä½•æ”»å‡»ã€‚è°ˆåˆ¤æˆåŠŸï¼Œå¥¥åœ°åˆ©æ¥å—äº†é»è°¢ç•™çš„æè®®ï¼ŒåŒæ–¹è¾¾æˆäº†äº¤æ¢é‚£ä¸å‹’æ–¯å’Œæ…•å°¼é»‘ä¾›åº”ä¸­å¿ƒçš„åè®®ã€‚åœ¨è¡ŒåŠ¨é˜¶æ®µï¼Œå¥¥åœ°åˆ©å°†å†›é˜Ÿä»å¨å°¼æ–¯è°ƒå¾€é˜¿æ™®åˆ©äºšï¼Œä¸ºä¸‹ä¸€å›åˆå é¢†é‚£ä¸å‹’æ–¯åšå‡†å¤‡ï¼ŒåŒæ—¶å°†å…¶ä»–éƒ¨é˜Ÿé‡æ–°éƒ¨ç½²åˆ°ä¸œéƒ¨ä¸ä¿„ç½—æ–¯æ¥å£¤çš„åœ°åŒºï¼Œä»¥é˜²å¾¡ä¿„ç½—æ–¯çš„è¿›æ”»å¹¶äº‰å¤ºä¾›åº”ä¸­å¿ƒã€‚æ³•å›½å†›é˜Ÿå é¢†äº†æ…•å°¼é»‘ï¼Œå¹¶å‡†å¤‡è¿›æ”»æŸæ—ç­‰ä¿„ç½—æ–¯é¢†åœŸã€‚ä¸æ­¤åŒæ—¶ï¼Œæ³•å›½å†›é˜Ÿåœ¨è·å…°å’Œæ¯”åˆ©æ—¶åœ°åŒºæ”¯æ´å¥¥åœ°åˆ©ã€‚åœ¨è¿™ä¸€å›åˆï¼Œæˆ‘ä»¬æœ€ç»ˆå–å¾—äº†æ›´å¥½çš„ç»“æœâ€”â€”å¤§å¤šæ•°ä¾›åº”ä¸­å¿ƒï¼ˆSCï¼‰ã€‚è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ¨¡å‹ä¸å…¶ä»–ç©å®¶æœ‰æ•ˆåˆä½œçš„èƒ½åŠ›ã€‚
- en: '![Refer to caption](img/e384c3bee9dcac9432f43091460920b2.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/e384c3bee9dcac9432f43091460920b2.png)'
- en: '(a) Case1: The agent without self-play memory tend to ignore long-term gains.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: (a) æ¡ˆä¾‹1ï¼šæ²¡æœ‰è‡ªæˆ‘åšå¼ˆè®°å¿†çš„æ™ºèƒ½ä½“å€¾å‘äºå¿½ç•¥é•¿æœŸæ”¶ç›Šã€‚
- en: '![Refer to caption](img/36e6bb800e36bab75cf4c8f8eb048474.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/36e6bb800e36bab75cf4c8f8eb048474.png)'
- en: '(b) Case2: The agent with self-play memory tend to consider long-term gains.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: (b) æ¡ˆä¾‹2ï¼šå…·æœ‰è‡ªæˆ‘åšå¼ˆè®°å¿†çš„æ™ºèƒ½ä½“å€¾å‘äºè€ƒè™‘é•¿æœŸæ”¶ç›Šã€‚
- en: 'Figure 6: Case of self-playing before and after comparison.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾6ï¼šè‡ªæˆ‘åšå¼ˆå‰åæ¯”è¾ƒæ¡ˆä¾‹ã€‚
- en: B.2 Case of Avoiding Deception
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 é¿å…æ¬ºéª—çš„æ¡ˆä¾‹
- en: 'As shown in Figure Â [7](https://arxiv.org/html/2407.06813v4#A2.F7 "Figure 7
    â€£ B.2 Case of Avoiding Deception â€£ Appendix B Cases â€£ Richelieu: Self-Evolving
    LLM-Based Agents for AI Diplomacy"), Richelieu controls Germany. During the negotiation
    phase, England proposed a ceasefire to Germany and invited Germany to form an
    alliance to attack France jointly. England hoped to cease the war with Germany
    in Holland and Belgium. Subsequently, German units supported England in attacking
    Brest, and then England utilized its fleets to assist Germany in attacking Spain
    and Portugal. Richelieu suspected that England was deceiving Germany, as England
    was likely to attack territories in the north such as Belgium and Berlin after
    German units were redirected to support Brest. Therefore, we pretended to accept
    Englandâ€™s alliance proposal during the negotiation process. However, at the same
    time, we sought out France and expressed our willingness to cease hostilities,
    allowing France to focus entirely on defending against Englandâ€™s attacks. In the
    action phase, Englandâ€™s actions confirmed Richelieuâ€™s suspicions. England attacked
    Belgium from Holland, but because Richelieu didnâ€™t move units in Belgium, Englandâ€™s
    attack failed.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å›¾[7](https://arxiv.org/html/2407.06813v4#A2.F7 "å›¾ 7 â€£ B.2 é¿å…æ¬ºéª—æ¡ˆä¾‹ â€£ é™„å½• B æ¡ˆä¾‹
    â€£ Richelieuï¼šåŸºäºLLMçš„è‡ªæˆ‘è¿›åŒ–AIå¤–äº¤ä»£ç†")æ‰€ç¤ºï¼ŒRichelieuæ§åˆ¶å¾·å›½ã€‚åœ¨è°ˆåˆ¤é˜¶æ®µï¼Œè‹±å›½æå‡ºåœç«å¹¶é‚€è¯·å¾·å›½ä¸å…¶ç»“ç›Ÿï¼Œå…±åŒæ”»å‡»æ³•å›½ã€‚è‹±å›½å¸Œæœ›ä¸å¾·å›½åœ¨è·å…°å’Œæ¯”åˆ©æ—¶åœæˆ˜ã€‚éšåï¼Œå¾·å›½å†›é˜Ÿæ”¯æŒè‹±å›½æ”»å‡»å¸ƒé›·æ–¯ç‰¹ï¼Œç„¶åè‹±å›½åˆ©ç”¨å…¶èˆ°é˜ŸååŠ©å¾·å›½æ”»å‡»è¥¿ç­ç‰™å’Œè‘¡è„ç‰™ã€‚Richelieuæ€€ç–‘è‹±å›½åœ¨æ¬ºéª—å¾·å›½ï¼Œå› ä¸ºä¸€æ—¦å¾·å›½çš„éƒ¨é˜Ÿè½¬ç§»å»æ”¯æ´å¸ƒé›·æ–¯ç‰¹ï¼Œè‹±å›½å¾ˆå¯èƒ½ä¼šæ”»å‡»æ¯”åˆ©æ—¶å’ŒæŸæ—ç­‰åŒ—éƒ¨é¢†åœŸã€‚å› æ­¤ï¼Œåœ¨è°ˆåˆ¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‡è£…æ¥å—äº†è‹±å›½çš„ç»“ç›Ÿæè®®ã€‚ç„¶è€Œï¼Œä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬è”ç³»äº†æ³•å›½ï¼Œå¹¶è¡¨è¾¾äº†æ„¿æ„åœæˆ˜çš„æ„æ„¿ï¼Œè®©æ³•å›½ä¸“å¿ƒé˜²å¾¡è‹±å›½çš„è¿›æ”»ã€‚åœ¨è¡ŒåŠ¨é˜¶æ®µï¼Œè‹±å›½çš„è¡ŒåŠ¨è¯å®äº†Richelieuçš„æ€€ç–‘ã€‚è‹±å›½ä»è·å…°æ”»å‡»æ¯”åˆ©æ—¶ï¼Œä½†ç”±äºRichelieuæ²¡æœ‰åœ¨æ¯”åˆ©æ—¶è°ƒåŠ¨éƒ¨é˜Ÿï¼Œè‹±å›½çš„æ”»å‡»å¤±è´¥äº†ã€‚
- en: '![Refer to caption](img/14d5b1a3ee44d43260239f424c799644.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/14d5b1a3ee44d43260239f424c799644.png)'
- en: 'Figure 7: An example case of avoiding being deceived by other countries during
    negotiations.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7ï¼šåœ¨è°ˆåˆ¤è¿‡ç¨‹ä¸­é¿å…è¢«å…¶ä»–å›½å®¶æ¬ºéª—çš„ä¸€ä¸ªç¤ºä¾‹æ¡ˆä¾‹ã€‚
- en: Appendix C More application
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• C æ›´å¤šåº”ç”¨
- en: Our modules cover most of the challenges in multi-agent interactions, e.g.,
    economic games, and daily interactions.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡å—æ¶µç›–äº†å¤§å¤šæ•°å¤šä»£ç†äº’åŠ¨ä¸­çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚ç»æµåšå¼ˆå’Œæ—¥å¸¸äº’åŠ¨ã€‚
- en: To prove that our framework is capable of applying to most social interaction
    tasks, we further adopt our framework to a werewolf game. The results demonstrate
    our reasoning framework achieves comparable results to the other methods. To be
    specific, in the experiment, we let our agent play as a werewolf in a seven-player
    game, where there are two werewolves, one witch, one seer, one guard, and two
    villagers. The experimental results show that the win rate of our agent is 59.2%,
    even without applying the self-play game in the current version. For comparison,
    the strongest specifically designed LLM-based agent achieved Â 65% win rate Xu
    etÂ al. [[2023](https://arxiv.org/html/2407.06813v4#bib.bib63)]. This proves that
    our model can be applied in more scenarios and achieve results comparable to those
    of specially designed models.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯æ˜æˆ‘ä»¬çš„æ¡†æ¶èƒ½å¤Ÿåº”ç”¨äºå¤§å¤šæ•°ç¤¾äº¤äº’åŠ¨ä»»åŠ¡ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å°†æ¡†æ¶åº”ç”¨äºç‹¼äººæ¸¸æˆã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨ç†æ¡†æ¶åœ¨æ•ˆæœä¸Šä¸å…¶ä»–æ–¹æ³•ç›¸å½“ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬è®©æˆ‘ä»¬çš„ä»£ç†ä½œä¸ºç‹¼äººå‚ä¸ä¸ƒäººæ¸¸æˆï¼Œå…¶ä¸­æœ‰ä¸¤åç‹¼äººã€ä¸€åå¥³å·«ã€ä¸€åé¢„è¨€å®¶ã€ä¸€åå®ˆå«å’Œä¸¤åæ‘æ°‘ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿åœ¨å½“å‰ç‰ˆæœ¬ä¸­æ²¡æœ‰åº”ç”¨è‡ªæˆ‘å¯¹æˆ˜æ¸¸æˆï¼Œæˆ‘ä»¬çš„ä»£ç†èµ¢å¾—æ¯”èµ›çš„èƒœç‡ä¸º59.2%ã€‚ä½œä¸ºå¯¹æ¯”ï¼Œæœ€å¼ºçš„ä¸“é—¨è®¾è®¡çš„åŸºäºLLMçš„ä»£ç†è·å¾—äº†65%çš„èƒœç‡ï¼ˆXu
    ç­‰äººï¼Œ[2023](https://arxiv.org/html/2407.06813v4#bib.bib63)ï¼‰ã€‚è¿™è¯æ˜æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åº”ç”¨äºæ›´å¤šåœºæ™¯ï¼Œå¹¶å–å¾—ä¸ä¸“é—¨è®¾è®¡çš„æ¨¡å‹ç›¸å½“çš„ç»“æœã€‚
- en: Appendix D Ethical Consideration
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½• D é“å¾·è€ƒé‡
- en: The method proposed in this work has the potential for positive uses like enabling
    AI agents to emerge in cooperation via negotiation or avoiding being fooled by
    fake promises (or helping humans do so). However, negative cases can also arise
    if the technique is used for possible fraud activities. Fortunately, there is
    research Bakhtin etÂ al. [[2019](https://arxiv.org/html/2407.06813v4#bib.bib5)]Zellers
    etÂ al. [[2019](https://arxiv.org/html/2407.06813v4#bib.bib70)] dealing with such
    scenarios. And we also urge for more research efforts in this field to foster
    safe applications of similar technologies.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æå‡ºçš„æ–¹æ³•å…·æœ‰æ½œåœ¨çš„ç§¯æç”¨é€”ï¼Œä¾‹å¦‚é€šè¿‡è°ˆåˆ¤ä¿ƒä½¿ AI ä»£ç†åä½œï¼Œæˆ–é¿å…è¢«è™šå‡æ‰¿è¯ºæ¬ºéª—ï¼ˆæˆ–å¸®åŠ©äººç±»åšåˆ°è¿™ä¸€ç‚¹ï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœè¯¥æŠ€æœ¯ç”¨äºæ½œåœ¨çš„æ¬ºè¯ˆæ´»åŠ¨ï¼Œä¹Ÿå¯èƒ½å‡ºç°è´Ÿé¢æƒ…å†µã€‚å¹¸è¿çš„æ˜¯ï¼Œæœ‰ç ”ç©¶ï¼ˆBakhtin
    ç­‰äºº[[2019](https://arxiv.org/html/2407.06813v4#bib.bib5)]ï¼ŒZellers ç­‰äºº[[2019](https://arxiv.org/html/2407.06813v4#bib.bib70)]ï¼‰åœ¨å¤„ç†æ­¤ç±»åœºæ™¯ã€‚æˆ‘ä»¬è¿˜å‘¼ååœ¨è¿™ä¸€é¢†åŸŸè¿›è¡Œæ›´å¤šç ”ç©¶ï¼Œä»¥ä¿ƒè¿›ç±»ä¼¼æŠ€æœ¯çš„å®‰å…¨åº”ç”¨ã€‚
- en: NeurIPS Paper Checklist
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NeurIPS è®ºæ–‡æ£€æŸ¥æ¸…å•
- en: 'The checklist is designed to encourage best practices for responsible machine
    learning research, addressing issues of reproducibility, transparency, research
    ethics, and societal impact. Do not remove the checklist: The papers not including
    the checklist will be desk rejected. The checklist should follow the references
    and follow the (optional) supplemental material. The checklist does NOT count
    toward the page limit.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ¸…å•æ—¨åœ¨é¼“åŠ±è´Ÿè´£ä»»çš„æœºå™¨å­¦ä¹ ç ”ç©¶æœ€ä½³å®è·µï¼Œè§£å†³å¯é‡å¤æ€§ã€é€æ˜åº¦ã€ç ”ç©¶ä¼¦ç†å’Œç¤¾ä¼šå½±å“ç­‰é—®é¢˜ã€‚è¯·å‹¿åˆ é™¤æ£€æŸ¥æ¸…å•ï¼šæœªåŒ…å«æ£€æŸ¥æ¸…å•çš„è®ºæ–‡å°†è¢«ç›´æ¥æ‹’ç»ã€‚æ£€æŸ¥æ¸…å•åº”ç´§éšå‚è€ƒæ–‡çŒ®ä¹‹åï¼Œå¹¶ä½äºï¼ˆå¯é€‰çš„ï¼‰è¡¥å……ææ–™éƒ¨åˆ†ã€‚æ£€æŸ¥æ¸…å•ä¸è®¡å…¥é¡µé¢é™åˆ¶ã€‚
- en: 'Please read the checklist guidelines carefully for information on how to answer
    these questions. For each question in the checklist:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·ä»”ç»†é˜…è¯»æ£€æŸ¥æ¸…å•æŒ‡å—ï¼Œäº†è§£å¦‚ä½•å›ç­”è¿™äº›é—®é¢˜ã€‚å¯¹äºæ£€æŸ¥æ¸…å•ä¸­çš„æ¯ä¸ªé—®é¢˜ï¼š
- en: â€¢
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: You should answer [Yes] , [No] , or [N/A] .
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ‚¨åº”è¯¥å›ç­”[æ˜¯]ã€[å¦]æˆ–[N/A]ã€‚
- en: â€¢
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: '[N/A] means either that the question is Not Applicable for that particular
    paper or the relevant information is Not Available.'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[N/A] è¡¨ç¤ºè¯¥é—®é¢˜ä¸é€‚ç”¨äºè¯¥è®ºæ–‡ï¼Œæˆ–ç›¸å…³ä¿¡æ¯ä¸å¯ç”¨ã€‚'
- en: â€¢
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Please provide a short (1â€“2 sentence) justification right after your answer
    (even for NA).
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯·åœ¨æ‚¨çš„å›ç­”åæä¾›ç®€çŸ­çš„ï¼ˆ1-2å¥ï¼‰è¯´æ˜ï¼ˆå³ä½¿æ˜¯N/Aï¼‰ã€‚
- en: The checklist answers are an integral part of your paper submission. They are
    visible to the reviewers, area chairs, senior area chairs, and ethics reviewers.
    You will be asked to also include it (after eventual revisions) with the final
    version of your paper, and its final version will be published with the paper.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ¸…å•çš„ç­”æ¡ˆæ˜¯æ‚¨è®ºæ–‡æäº¤çš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†ã€‚å®ƒä»¬å¯¹å®¡ç¨¿äººã€é¢†åŸŸä¸»å¸­ã€é«˜çº§é¢†åŸŸä¸»å¸­å’Œä¼¦ç†å®¡ç¨¿äººå¯è§ã€‚æ‚¨è¿˜éœ€è¦åœ¨æœ€ç»ˆç‰ˆæœ¬çš„è®ºæ–‡ï¼ˆç»è¿‡ä¿®æ”¹åï¼‰ä¸­åŒ…æ‹¬è¯¥æ£€æŸ¥æ¸…å•ï¼Œä¸”æœ€ç»ˆç‰ˆæœ¬å°†ä¸è®ºæ–‡ä¸€èµ·å‘å¸ƒã€‚
- en: The reviewers of your paper will be asked to use the checklist as one of the
    factors in their evaluation. While "[Yes] " is generally preferable to "[No] ",
    it is perfectly acceptable to answer "[No] " provided a proper justification is
    given (e.g., "error bars are not reported because it would be too computationally
    expensive" or "we were unable to find the license for the dataset we used"). In
    general, answering "[No] " or "[N/A] " is not grounds for rejection. While the
    questions are phrased in a binary way, we acknowledge that the true answer is
    often more nuanced, so please just use your best judgment and write a justification
    to elaborate. All supporting evidence can appear either in the main paper or the
    supplemental material, provided in the appendix. If you answer [Yes] to a question,
    in the justification please point to the section(s) where related material for
    the question can be found.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ‚¨è®ºæ–‡çš„å®¡ç¨¿äººå°†è¢«è¦æ±‚å°†æ£€æŸ¥æ¸…å•ä½œä¸ºè¯„å®¡çš„å› ç´ ä¹‹ä¸€ã€‚è™½ç„¶"[æ˜¯]"é€šå¸¸ä¼˜äº"[å¦]"ï¼Œä½†åªè¦æä¾›äº†é€‚å½“çš„ç†ç”±ï¼Œå›ç­”"[å¦]"ä¹Ÿæ˜¯å®Œå…¨å¯ä»¥æ¥å—çš„ï¼ˆä¾‹å¦‚ï¼Œâ€œè¯¯å·®æ¡æœªæŠ¥å‘Šï¼Œå› ä¸ºè®¡ç®—å¼€é”€è¿‡å¤§â€æˆ–â€œæˆ‘ä»¬æ— æ³•æ‰¾åˆ°ä½¿ç”¨æ•°æ®é›†çš„è®¸å¯è¯â€ï¼‰ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå›ç­”"[å¦]"æˆ–"[N/A]"å¹¶ä¸ä¼šæˆä¸ºæ‹’ç»çš„ç†ç”±ã€‚è™½ç„¶é—®é¢˜ä»¥äºŒå…ƒæ–¹å¼æå‡ºï¼Œæˆ‘ä»¬æ‰¿è®¤çœŸå®ç­”æ¡ˆé€šå¸¸æ›´ä¸ºå¤æ‚ï¼Œå› æ­¤è¯·æ ¹æ®è‡ªå·±çš„æœ€ä½³åˆ¤æ–­ä½œç­”ï¼Œå¹¶å†™å‡ºç†ç”±è¿›è¡Œè¯¦ç»†è¯´æ˜ã€‚æ‰€æœ‰æ”¯æŒè¯æ®å¯ä»¥å‡ºç°åœ¨ä¸»æ–‡æˆ–è¡¥å……ææ–™ä¸­ï¼Œé™„å½•ä¸­æä¾›ã€‚å¦‚æœæ‚¨å¯¹æŸä¸ªé—®é¢˜å›ç­”äº†[æ˜¯]ï¼Œè¯·åœ¨ç†ç”±ä¸­æŒ‡æ˜ç›¸å…³ææ–™æ‰€åœ¨çš„ç« èŠ‚ã€‚ '
- en: 'IMPORTANT, please:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦æç¤ºï¼Œè¯·æ³¨æ„ï¼š
- en: â€¢
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Delete this instruction block, but keep the section heading â€œNeurIPS paper checklist",
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åˆ é™¤æ­¤æŒ‡ä»¤å—ï¼Œä½†ä¿ç•™å°èŠ‚æ ‡é¢˜â€œNeurIPS è®ºæ–‡æ£€æŸ¥æ¸…å•â€ã€‚
- en: â€¢
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Keep the checklist subsection headings, questions/answers, and guidelines below.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¿ç•™ä»¥ä¸‹çš„æ£€æŸ¥æ¸…å•å°èŠ‚æ ‡é¢˜ã€é—®é¢˜/ç­”æ¡ˆå’ŒæŒ‡å¯¼æ–¹é’ˆã€‚
- en: â€¢
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Do not modify the questions and only use the provided macros for your answers.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸è¦ä¿®æ”¹é—®é¢˜ï¼Œåªèƒ½ä½¿ç”¨æä¾›çš„å®æ¥å›ç­”ã€‚
- en: '1.'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Claims
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å£°æ˜
- en: 'Question: Do the main claims made in the abstract and introduction accurately
    reflect the paperâ€™s contributions and scope?'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šæ‘˜è¦å’Œå¼•è¨€ä¸­æå‡ºçš„ä¸»è¦ä¸»å¼ æ˜¯å¦å‡†ç¡®åæ˜ äº†è®ºæ–‡çš„è´¡çŒ®å’ŒèŒƒå›´ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯çš„]
- en: 'Justification: The contributions and scope has been fully covered by the abstract
    and introduction sections.'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®ºè¯ï¼šè®ºæ–‡çš„è´¡çŒ®å’ŒèŒƒå›´åœ¨æ‘˜è¦å’Œå¼•è¨€éƒ¨åˆ†å·²å¾—åˆ°å……åˆ†è¦†ç›–ã€‚
- en: 'Guidelines:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å¯¼åŸåˆ™ï¼š
- en: â€¢
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the abstract and introduction do not include the claims
    made in the paper.
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAè¡¨ç¤ºæ‘˜è¦å’Œå¼•è¨€ä¸­æœªåŒ…æ‹¬è®ºæ–‡ä¸­æå‡ºçš„ä¸»å¼ ã€‚
- en: â€¢
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The abstract and/or introduction should clearly state the claims made, including
    the contributions made in the paper and important assumptions and limitations.
    A No or NA answer to this question will not be perceived well by the reviewers.
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ‘˜è¦å’Œ/æˆ–å¼•è¨€åº”æ¸…æ™°åœ°è¯´æ˜æ‰€æå‡ºçš„ä¸»å¼ ï¼ŒåŒ…æ‹¬è®ºæ–‡çš„è´¡çŒ®ã€é‡è¦å‡è®¾å’Œå±€é™æ€§ã€‚å¯¹æ­¤é—®é¢˜çš„ç­”æ¡ˆä¸ºNoæˆ–NAå°†ä¸ä¼šå—åˆ°è¯„å®¡äººçš„å¥½è¯„ã€‚
- en: â€¢
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The claims made should match theoretical and experimental results, and reflect
    how much the results can be expected to generalize to other settings.
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ‰€æå‡ºçš„ä¸»å¼ åº”ä¸ç†è®ºå’Œå®éªŒç»“æœç›¸ç¬¦ï¼Œå¹¶åæ˜ å‡ºç»“æœåœ¨å…¶ä»–ç¯å¢ƒä¸­çš„æ™®é€‚æ€§ã€‚
- en: â€¢
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: It is fine to include aspirational goals as motivation as long as it is clear
    that these goals are not attained by the paper.
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŒ…æ‹¬æ¿€åŠ±æ€§ç›®æ ‡ä½œä¸ºåŠ¨æœºæ˜¯å¯ä»¥çš„ï¼Œåªè¦æ˜ç¡®è¡¨æ˜è¿™äº›ç›®æ ‡å¹¶æœªåœ¨æœ¬æ–‡ä¸­å®ç°ã€‚
- en: '2.'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Limitations
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å±€é™æ€§
- en: 'Question: Does the paper discuss the limitations of the work performed by the
    authors?'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦è®¨è®ºäº†ä½œè€…å·¥ä½œçš„å±€é™æ€§ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯çš„]
- en: 'Justification: The paper discussed the limitations of the work performed by
    the authors in the section "Limitation and Future Work".'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®ºè¯ï¼šæœ¬æ–‡åœ¨â€œå±€é™æ€§ä¸æœªæ¥å·¥ä½œâ€éƒ¨åˆ†è®¨è®ºäº†ä½œè€…å·¥ä½œçš„å±€é™æ€§ã€‚
- en: 'Guidelines:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å¯¼åŸåˆ™ï¼š
- en: â€¢
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper has no limitation while the answer No means
    that the paper has limitations, but those are not discussed in the paper.
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAè¡¨ç¤ºè®ºæ–‡æ²¡æœ‰å±€é™æ€§ï¼Œè€Œç­”æ¡ˆNoè¡¨ç¤ºè®ºæ–‡æœ‰å±€é™æ€§ï¼Œä½†è®ºæ–‡ä¸­æ²¡æœ‰è®¨è®ºè¿™äº›å±€é™æ€§ã€‚
- en: â€¢
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors are encouraged to create a separate "Limitations" section in their
    paper.
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: é¼“åŠ±ä½œè€…åœ¨è®ºæ–‡ä¸­åˆ›å»ºå•ç‹¬çš„â€œå±€é™æ€§â€éƒ¨åˆ†ã€‚
- en: â€¢
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The paper should point out any strong assumptions and how robust the results
    are to violations of these assumptions (e.g., independence assumptions, noiseless
    settings, model well-specification, asymptotic approximations only holding locally).
    The authors should reflect on how these assumptions might be violated in practice
    and what the implications would be.
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®ºæ–‡åº”æŒ‡å‡ºä»»ä½•å¼ºå‡è®¾ï¼Œå¹¶è®¨è®ºç»“æœå¯¹è¿™äº›å‡è®¾è¿åçš„é²æ£’æ€§ï¼ˆä¾‹å¦‚ï¼Œç‹¬ç«‹æ€§å‡è®¾ã€æ— å™ªå£°å‡è®¾ã€æ¨¡å‹è‰¯å¥½è§„èŒƒåŒ–ã€ä»…åœ¨å±€éƒ¨æœ‰æ•ˆçš„æ¸è¿‘è¿‘ä¼¼ï¼‰ã€‚ä½œè€…åº”åæ€è¿™äº›å‡è®¾åœ¨å®è·µä¸­å¯èƒ½å¦‚ä½•è¢«è¿åï¼Œä»¥åŠè¿™äº›è¿åä¼šå¸¦æ¥ä»€ä¹ˆå½±å“ã€‚
- en: â€¢
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should reflect on the scope of the claims made, e.g., if the approach
    was only tested on a few datasets or with a few runs. In general, empirical results
    often depend on implicit assumptions, which should be articulated.
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”åæ€æ‰€æå‡ºä¸»å¼ çš„èŒƒå›´ï¼Œä¾‹å¦‚ï¼Œå¦‚æœè¯¥æ–¹æ³•ä»…åœ¨å°‘æ•°æ•°æ®é›†æˆ–å°‘é‡å®éªŒä¸­è¿›è¡Œäº†æµ‹è¯•ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œç»éªŒç»“æœé€šå¸¸ä¾èµ–äºéšæ€§å‡è®¾ï¼Œè¿™äº›å‡è®¾åº”å½“æ˜ç¡®é˜è¿°ã€‚
- en: â€¢
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should reflect on the factors that influence the performance of
    the approach. For example, a facial recognition algorithm may perform poorly when
    the image resolution is low or images are taken in low lighting. Or a speech-to-text
    system might not be used reliably to provide closed captions for online lectures
    because it fails to handle technical jargon.
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”åæ€å½±å“æ–¹æ³•æ€§èƒ½çš„å› ç´ ã€‚ä¾‹å¦‚ï¼Œé¢éƒ¨è¯†åˆ«ç®—æ³•å¯èƒ½åœ¨å›¾åƒåˆ†è¾¨ç‡è¾ƒä½æˆ–æ‹æ‘„ç¯å¢ƒå…‰çº¿ä¸è¶³æ—¶è¡¨ç°ä¸ä½³ï¼›æˆ–è€…ï¼Œè¯­éŸ³è½¬æ–‡æœ¬ç³»ç»Ÿå¯èƒ½æ— æ³•å¯é åœ°ä¸ºåœ¨çº¿è®²åº§æä¾›å­—å¹•ï¼Œå› ä¸ºå®ƒæ— æ³•å¤„ç†æŠ€æœ¯æœ¯è¯­ã€‚
- en: â€¢
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should discuss the computational efficiency of the proposed algorithms
    and how they scale with dataset size.
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”è®¨è®ºæ‰€æç®—æ³•çš„è®¡ç®—æ•ˆç‡ä»¥åŠå…¶éšæ•°æ®é›†è§„æ¨¡çš„æ‰©å±•æƒ…å†µã€‚
- en: â€¢
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If applicable, the authors should discuss possible limitations of their approach
    to address problems of privacy and fairness.
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœé€‚ç”¨ï¼Œä½œè€…åº”è®¨è®ºå…¶æ–¹æ³•åœ¨è§£å†³éšç§å’Œå…¬å¹³æ€§é—®é¢˜æ–¹é¢å¯èƒ½å­˜åœ¨çš„å±€é™æ€§ã€‚
- en: â€¢
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: While the authors might fear that complete honesty about limitations might be
    used by reviewers as grounds for rejection, a worse outcome might be that reviewers
    discover limitations that arenâ€™t acknowledged in the paper. The authors should
    use their best judgment and recognize that individual actions in favor of transparency
    play an important role in developing norms that preserve the integrity of the
    community. Reviewers will be specifically instructed to not penalize honesty concerning
    limitations.
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°½ç®¡ä½œè€…å¯èƒ½æ‹…å¿ƒï¼Œå®Œå…¨å¦è¯šåœ°è¯´æ˜å±€é™æ€§å¯èƒ½ä¼šè¢«è¯„å®¡ä½œä¸ºæ‹’ç¨¿çš„ç†ç”±ï¼Œä½†æ›´ç³Ÿç³•çš„ç»“æœæ˜¯è¯„å®¡å‘ç°è®ºæ–‡ä¸­æœªè¢«æ‰¿è®¤çš„å±€é™æ€§ã€‚ä½œè€…åº”å½“æ ¹æ®è‡ªå·±çš„æœ€ä½³åˆ¤æ–­æ¥è®¤è¯†åˆ°ï¼Œä¸ªä½“ä¸ºé€æ˜åº¦æ‰€åšçš„åŠªåŠ›åœ¨å»ºç«‹æœ‰åŠ©äºç»´æŠ¤ç¤¾åŒºè¯šä¿¡çš„è§„èŒƒä¸­å‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚è¯„å®¡å‘˜å°†ç‰¹åˆ«è¢«å‘ŠçŸ¥ï¼Œä¸åº”å› è®ºæ–‡å¯¹å±€é™æ€§çš„è¯šå®è€Œè¿›è¡Œæƒ©ç½šã€‚
- en: '3.'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Theory Assumptions and Proofs
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç†è®ºå‡è®¾ä¸è¯æ˜
- en: 'Question: For each theoretical result, does the paper provide the full set
    of assumptions and a complete (and correct) proof?'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šå¯¹äºæ¯ä¸ªç†è®ºç»“æœï¼Œè®ºæ–‡æ˜¯å¦æä¾›äº†å®Œæ•´çš„å‡è®¾é›†åˆå’Œå®Œæ•´ï¼ˆä¸”æ­£ç¡®ï¼‰çš„è¯æ˜ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper provides the full set of assumptions and a complete
    (and correct) proof for each theoretical result in the "Method" and "Experiment"
    sections.'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šè®ºæ–‡åœ¨â€œæ–¹æ³•â€å’Œâ€œå®éªŒâ€éƒ¨åˆ†æä¾›äº†å®Œæ•´çš„å‡è®¾é›†åˆå’Œæ¯ä¸ªç†è®ºç»“æœçš„å®Œæ•´ï¼ˆä¸”æ­£ç¡®ï¼‰è¯æ˜ã€‚
- en: 'Guidelines:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not include theoretical results.
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAæ„å‘³ç€è®ºæ–‡æœªåŒ…å«ç†è®ºç»“æœã€‚
- en: â€¢
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®ºæ–‡ä¸­çš„æ‰€æœ‰å®šç†ã€å…¬å¼å’Œè¯æ˜åº”å½“ç¼–å·å¹¶äº¤å‰å¼•ç”¨ã€‚
- en: â€¢
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: All assumptions should be clearly stated or referenced in the statement of any
    theorems.
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å‡è®¾åº”å½“åœ¨ä»»ä½•å®šç†çš„é™ˆè¿°ä¸­æ˜ç¡®è¯´æ˜æˆ–å¼•ç”¨ã€‚
- en: â€¢
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The proofs can either appear in the main paper or the supplemental material,
    but if they appear in the supplemental material, the authors are encouraged to
    provide a short proof sketch to provide intuition.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯æ˜å¯ä»¥å‡ºç°åœ¨ä¸»è®ºæ–‡ä¸­æˆ–è¡¥å……ææ–™ä¸­ï¼Œä½†å¦‚æœå®ƒä»¬å‡ºç°åœ¨è¡¥å……ææ–™ä¸­ï¼Œé¼“åŠ±ä½œè€…æä¾›ä¸€ä¸ªç®€çŸ­çš„è¯æ˜æçº²ï¼Œä»¥ä¾¿æä¾›ç›´è§‚ç†è§£ã€‚
- en: â€¢
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Inversely, any informal proof provided in the core of the paper should be complemented
    by formal proofs provided in the appendix or supplemental material.
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: åè¿‡æ¥ï¼Œè®ºæ–‡æ ¸å¿ƒéƒ¨åˆ†æä¾›çš„ä»»ä½•éæ­£å¼è¯æ˜åº”å½“ç”±é™„å½•æˆ–è¡¥å……ææ–™ä¸­çš„æ­£å¼è¯æ˜åŠ ä»¥è¡¥å……ã€‚
- en: â€¢
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Theorems and Lemmas that the proof relies upon should be properly referenced.
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯æ˜æ‰€ä¾èµ–çš„å®šç†å’Œå¼•ç†åº”å½“å¾—åˆ°æ°å½“å¼•ç”¨ã€‚
- en: '4.'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Experimental Result Reproducibility
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®éªŒç»“æœå¯é‡ç°æ€§
- en: 'Question: Does the paper fully disclose all the information needed to reproduce
    the main experimental results of the paper to the extent that it affects the main
    claims and/or conclusions of the paper (regardless of whether the code and data
    are provided or not)?'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦å®Œå…¨æŠ«éœ²äº†é‡ç°è®ºæ–‡ä¸»è¦å®éªŒç»“æœæ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯é‚£äº›å½±å“è®ºæ–‡ä¸»è¦ä¸»å¼ å’Œ/æˆ–ç»“è®ºçš„éƒ¨åˆ†ï¼ˆæ— è®ºæ˜¯å¦æä¾›ä»£ç å’Œæ•°æ®ï¼‰ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper fully discloses all the information needed to reproduce
    the main experimental results in the main text section "Experiment" and appendix
    section "Implementation Details".'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šè®ºæ–‡å®Œå…¨æŠ«éœ²äº†åœ¨â€œå®éªŒâ€éƒ¨åˆ†çš„ä¸»æ–‡æœ¬å’Œâ€œå®ç°ç»†èŠ‚â€é™„å½•éƒ¨åˆ†ä¸­é‡ç°ä¸»è¦å®éªŒç»“æœæ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ã€‚
- en: 'Guidelines:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not include experiments.
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆä¸ºNAæ„å‘³ç€è®ºæ–‡æœªåŒ…å«å®éªŒã€‚
- en: â€¢
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'If the paper includes experiments, a No answer to this question will not be
    perceived well by the reviewers: Making the paper reproducible is important, regardless
    of whether the code and data are provided or not.'
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè®ºæ–‡åŒ…å«å®éªŒï¼Œå›ç­”æ­¤é—®é¢˜ä¸ºâ€œå¦â€å°†ä¸ä¼šè¢«è¯„å®¡æ‰€è®¤å¯ï¼šä½¿è®ºæ–‡å¯é‡ç°éå¸¸é‡è¦ï¼Œæ— è®ºæ˜¯å¦æä¾›ä»£ç å’Œæ•°æ®ã€‚
- en: â€¢
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If the contribution is a dataset and/or model, the authors should describe the
    steps taken to make their results reproducible or verifiable.
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè´¡çŒ®æ˜¯æ•°æ®é›†å’Œ/æˆ–æ¨¡å‹ï¼Œä½œè€…åº”å½“æè¿°ä¸ºä½¿å…¶ç»“æœå¯é‡ç°æˆ–å¯éªŒè¯æ‰€é‡‡å–çš„æ­¥éª¤ã€‚
- en: â€¢
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Depending on the contribution, reproducibility can be accomplished in various
    ways. For example, if the contribution is a novel architecture, describing the
    architecture fully might suffice, or if the contribution is a specific model and
    empirical evaluation, it may be necessary to either make it possible for others
    to replicate the model with the same dataset, or provide access to the model.
    In general. releasing code and data is often one good way to accomplish this,
    but reproducibility can also be provided via detailed instructions for how to
    replicate the results, access to a hosted model (e.g., in the case of a large
    language model), releasing of a model checkpoint, or other means that are appropriate
    to the research performed.
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ ¹æ®è´¡çŒ®çš„ä¸åŒï¼Œå¯é‡ç°æ€§å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å®ç°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœè´¡çŒ®æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¶æ„ï¼Œå…¨é¢æè¿°æ¶æ„å¯èƒ½å°±è¶³å¤Ÿäº†ï¼›æˆ–è€…å¦‚æœè´¡çŒ®æ˜¯ä¸€ä¸ªç‰¹å®šçš„æ¨¡å‹å’Œå®è¯è¯„ä¼°ï¼Œå¯èƒ½éœ€è¦è®©å…¶ä»–äººèƒ½å¤Ÿä½¿ç”¨ç›¸åŒçš„æ•°æ®é›†æ¥å¤åˆ¶æ¨¡å‹ï¼Œæˆ–æä¾›å¯¹è¯¥æ¨¡å‹çš„è®¿é—®æƒé™ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œå‘å¸ƒä»£ç å’Œæ•°æ®é€šå¸¸æ˜¯ä¸€ç§è‰¯å¥½çš„å®ç°æ–¹å¼ï¼Œä½†å¯é‡ç°æ€§ä¹Ÿå¯ä»¥é€šè¿‡è¯¦ç»†çš„è¯´æ˜å¦‚ä½•å¤åˆ¶ç»“æœã€è®¿é—®æ‰˜ç®¡æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„æƒ…å†µï¼‰ã€å‘å¸ƒæ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œæˆ–å…¶ä»–é€‚åˆäºæ‰€åšç ”ç©¶çš„æ–¹å¼æ¥æä¾›ã€‚
- en: â€¢
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: While NeurIPS does not require releasing code, the conference does require all
    submissions to provide some reasonable avenue for reproducibility, which may depend
    on the nature of the contribution. For example
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°½ç®¡NeurIPSä¸è¦æ±‚å‘å¸ƒä»£ç ï¼Œä½†ä¼šè®®è¦æ±‚æ‰€æœ‰æäº¤çš„è®ºæ–‡æä¾›æŸç§åˆç†çš„å¯é‡ç°æ€§é€”å¾„ï¼Œè¿™å¯èƒ½å–å†³äºè´¡çŒ®çš„æ€§è´¨ã€‚ä¾‹å¦‚
- en: (a)
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (a)
- en: If the contribution is primarily a new algorithm, the paper should make it clear
    how to reproduce that algorithm.
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè´¡çŒ®ä¸»è¦æ˜¯ä¸€ä¸ªæ–°ç®—æ³•ï¼Œè®ºæ–‡åº”æ˜ç¡®è¯´æ˜å¦‚ä½•é‡ç°è¯¥ç®—æ³•ã€‚
- en: (b)
  id: totrans-315
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (b)
- en: If the contribution is primarily a new model architecture, the paper should
    describe the architecture clearly and fully.
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè´¡çŒ®ä¸»è¦æ˜¯ä¸€ä¸ªæ–°æ¨¡å‹æ¶æ„ï¼Œè®ºæ–‡åº”æ¸…æ™°å…¨é¢åœ°æè¿°è¯¥æ¶æ„ã€‚
- en: (c)
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (c)
- en: If the contribution is a new model (e.g., a large language model), then there
    should either be a way to access this model for reproducing the results or a way
    to reproduce the model (e.g., with an open-source dataset or instructions for
    how to construct the dataset).
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè´¡çŒ®æ˜¯ä¸€ä¸ªæ–°æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰ï¼Œåˆ™åº”è¯¥æœ‰æ–¹æ³•è®¿é—®è¯¥æ¨¡å‹ä»¥é‡ç°ç»“æœï¼Œæˆ–è€…æœ‰æ–¹æ³•é‡ç°è¯¥æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å¼€æºæ•°æ®é›†æˆ–è¯´æ˜å¦‚ä½•æ„å»ºæ•°æ®é›†ï¼‰ã€‚
- en: (d)
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: (d)
- en: We recognize that reproducibility may be tricky in some cases, in which case
    authors are welcome to describe the particular way they provide for reproducibility.
    In the case of closed-source models, it may be that access to the model is limited
    in some way (e.g., to registered users), but it should be possible for other researchers
    to have some path to reproducing or verifying the results.
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¤è¯†åˆ°ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯é‡ç°æ€§å¯èƒ½æ˜¯å›°éš¾çš„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½œè€…å¯ä»¥æè¿°ä»–ä»¬æä¾›å¯é‡ç°æ€§æ”¯æŒçš„å…·ä½“æ–¹å¼ã€‚å¦‚æœæ˜¯å°é—­æºä»£ç æ¨¡å‹ï¼Œå¯èƒ½ä¼šä»¥æŸç§æ–¹å¼é™åˆ¶å¯¹æ¨¡å‹çš„è®¿é—®ï¼ˆä¾‹å¦‚ï¼Œä»…é™æ³¨å†Œç”¨æˆ·ï¼‰ï¼Œä½†åº”è¯¥èƒ½å¤Ÿä¸ºå…¶ä»–ç ”ç©¶äººå‘˜æä¾›æŸç§é€”å¾„ä»¥é‡ç°æˆ–éªŒè¯ç»“æœã€‚
- en: '5.'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Open access to data and code
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¼€æ”¾è®¿é—®æ•°æ®å’Œä»£ç 
- en: 'Question: Does the paper provide open access to the data and code, with sufficient
    instructions to faithfully reproduce the main experimental results, as described
    in supplemental material?'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦æä¾›äº†å¯¹æ•°æ®å’Œä»£ç çš„å¼€æ”¾è®¿é—®ï¼Œå¹¶é™„æœ‰è¶³å¤Ÿçš„è¯´æ˜ï¼Œä»¥ä¾¿å¿ å®åœ°é‡ç°è¡¥å……ææ–™ä¸­æè¿°çš„ä¸»è¦å®éªŒç»“æœï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper provides open access to the data and code in the section
    "Experiment".'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šè®ºæ–‡åœ¨â€œå®éªŒâ€éƒ¨åˆ†æä¾›äº†å¼€æ”¾è®¿é—®çš„æ•°æ®å’Œä»£ç ã€‚
- en: 'Guidelines:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that paper does not include experiments requiring code.
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€è¡¨ç¤ºè®ºæ–‡æœªåŒ…å«éœ€è¦ä»£ç çš„å®éªŒã€‚
- en: â€¢
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy))
    for more details.
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯·å‚é˜…NeurIPSçš„ä»£ç å’Œæ•°æ®æäº¤æŒ‡å—ï¼ˆ[https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)ï¼‰ä»¥è·å–æ›´å¤šè¯¦æƒ…ã€‚
- en: â€¢
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: While we encourage the release of code and data, we understand that this might
    not be possible, so â€œNoâ€ is an acceptable answer. Papers cannot be rejected simply
    for not including code, unless this is central to the contribution (e.g., for
    a new open-source benchmark).
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘ä»¬é¼“åŠ±å‘å¸ƒä»£ç å’Œæ•°æ®ï¼Œä½†æˆ‘ä»¬ç†è§£è¿™å¯èƒ½ä¸å¯è¡Œï¼Œå› æ­¤â€œå¦â€æ˜¯ä¸€ä¸ªå¯æ¥å—çš„ç­”æ¡ˆã€‚ä»…å› æœªåŒ…å«ä»£ç è€Œæ‹’ç»è®ºæ–‡æ˜¯ä¸å…è®¸çš„ï¼Œé™¤éè¿™å¯¹è´¡çŒ®è‡³å…³é‡è¦ï¼ˆä¾‹å¦‚ï¼Œé’ˆå¯¹ä¸€ä¸ªæ–°çš„å¼€æºåŸºå‡†ï¼‰ã€‚
- en: â€¢
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The instructions should contain the exact command and environment needed to
    run to reproduce the results. See the NeurIPS code and data submission guidelines
    ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy))
    for more details.
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯´æ˜åº”åŒ…å«è¿è¡Œæ‰€éœ€çš„ç²¾ç¡®å‘½ä»¤å’Œç¯å¢ƒï¼Œä»¥é‡ç°ç»“æœã€‚æœ‰å…³æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚é˜…NeurIPSä»£ç å’Œæ•°æ®æäº¤æŒ‡å—ï¼ˆ[https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)ï¼‰ã€‚
- en: â€¢
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should provide instructions on data access and preparation, including
    how to access the raw data, preprocessed data, intermediate data, and generated
    data, etc.
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”æä¾›å…³äºæ•°æ®è®¿é—®å’Œå‡†å¤‡çš„è¯´æ˜ï¼ŒåŒ…æ‹¬å¦‚ä½•è®¿é—®åŸå§‹æ•°æ®ã€é¢„å¤„ç†æ•°æ®ã€ä¸­é—´æ•°æ®å’Œç”Ÿæˆæ•°æ®ç­‰ã€‚
- en: â€¢
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should provide scripts to reproduce all experimental results for
    the new proposed method and baselines. If only a subset of experiments are reproducible,
    they should state which ones are omitted from the script and why.
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”æä¾›è„šæœ¬ä»¥é‡ç°æ‰€æœ‰å®éªŒç»“æœï¼ŒåŒ…æ‹¬æ–°æå‡ºçš„æ–¹æ³•å’ŒåŸºçº¿æ–¹æ³•ã€‚å¦‚æœä»…æœ‰ä¸€éƒ¨åˆ†å®éªŒç»“æœæ˜¯å¯é‡ç°çš„ï¼Œåº”è¯¥è¯´æ˜å“ªäº›å®éªŒè¢«çœç•¥ï¼Œå¹¶è§£é‡ŠåŸå› ã€‚
- en: â€¢
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: At submission time, to preserve anonymity, the authors should release anonymized
    versions (if applicable).
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨æäº¤æ—¶ï¼Œä¸ºäº†ä¿æŒåŒ¿åï¼Œä½œè€…åº”æä¾›åŒ¿åç‰ˆæœ¬ï¼ˆå¦‚é€‚ç”¨ï¼‰ã€‚
- en: â€¢
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Providing as much information as possible in supplemental material (appended
    to the paper) is recommended, but including URLs to data and code is permitted.
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å»ºè®®å°½å¯èƒ½åœ¨è¡¥å……ææ–™ä¸­æä¾›æ›´å¤šä¿¡æ¯ï¼ˆé™„åœ¨è®ºæ–‡åï¼‰ï¼Œä½†å¯ä»¥åŒ…å«æŒ‡å‘æ•°æ®å’Œä»£ç çš„URLã€‚
- en: '6.'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: Experimental Setting/Details
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®éªŒè®¾ç½®/ç»†èŠ‚
- en: 'Question: Does the paper specify all the training and test details (e.g., data
    splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary
    to understand the results?'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦æŒ‡å®šäº†æ‰€æœ‰è®­ç»ƒå’Œæµ‹è¯•ç»†èŠ‚ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®åˆ’åˆ†ã€è¶…å‚æ•°ã€å¦‚ä½•é€‰æ‹©ã€ä¼˜åŒ–å™¨ç±»å‹ç­‰ï¼‰ï¼Œä»¥ä¾¿ç†è§£ç»“æœï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper specify all the training and test details to train
    the model in the "Experiment" section and "Implementation Details" section of
    appendix.'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç†ç”±ï¼šè®ºæ–‡åœ¨â€œå®éªŒâ€éƒ¨åˆ†å’Œé™„å½•ä¸­çš„â€œå®ç°ç»†èŠ‚â€éƒ¨åˆ†è¯¦ç»†è¯´æ˜äº†è®­ç»ƒå’Œæµ‹è¯•çš„æ‰€æœ‰ç»†èŠ‚ï¼Œä»¥ä¾¿è®­ç»ƒæ¨¡å‹ã€‚
- en: 'Guidelines:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-349
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not include experiments.
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAè¡¨ç¤ºè®ºæ–‡æœªåŒ…å«å®éªŒã€‚
- en: â€¢
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The experimental setting should be presented in the core of the paper to a level
    of detail that is necessary to appreciate the results and make sense of them.
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®éªŒè®¾ç½®åº”åœ¨è®ºæ–‡çš„æ ¸å¿ƒéƒ¨åˆ†å‘ˆç°ï¼Œè¯¦ç»†åˆ°è¶³ä»¥ç†è§£ç»“æœå¹¶ä½¿å…¶æœ‰æ„ä¹‰çš„ç¨‹åº¦ã€‚
- en: â€¢
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The full details can be provided either with the code, in appendix, or as supplemental
    material.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„ç»†èŠ‚å¯ä»¥é€šè¿‡ä»£ç ã€é™„å½•æˆ–è¡¥å……ææ–™æä¾›ã€‚
- en: '7.'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: Experiment Statistical Significance
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®éªŒç»Ÿè®¡æ˜¾è‘—æ€§
- en: 'Question: Does the paper report error bars suitably and correctly defined or
    other appropriate information about the statistical significance of the experiments?'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦é€‚å½“ä¸”æ­£ç¡®åœ°æŠ¥å‘Šäº†è¯¯å·®æ¡ï¼Œæˆ–è€…æ˜¯å¦æä¾›äº†å…³äºå®éªŒç»Ÿè®¡æ˜¾è‘—æ€§çš„å…¶ä»–é€‚å½“ä¿¡æ¯ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper reports error bars suitably and correctly defined
    or other appropriate information about the statistical significance of the experiment
    in the "Experiment" section.'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç†ç”±ï¼šè®ºæ–‡åœ¨â€œå®éªŒâ€éƒ¨åˆ†é€‚å½“åœ°ä¸”æ­£ç¡®å®šä¹‰äº†è¯¯å·®æ¡ï¼Œæˆ–æä¾›äº†å…³äºå®éªŒç»Ÿè®¡æ˜¾è‘—æ€§çš„å…¶ä»–é€‚å½“ä¿¡æ¯ã€‚
- en: 'Guidelines:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not include experiments.
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAè¡¨ç¤ºè®ºæ–‡æœªåŒ…å«å®éªŒã€‚
- en: â€¢
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should answer "Yes" if the results are accompanied by error bars,
    confidence intervals, or statistical significance tests, at least for the experiments
    that support the main claims of the paper.
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœç»“æœé™„å¸¦äº†è¯¯å·®æ¡ã€ç½®ä¿¡åŒºé—´æˆ–ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼Œè‡³å°‘å¯¹äºæ”¯æŒè®ºæ–‡ä¸»è¦è®ºç‚¹çš„å®éªŒï¼Œä½œè€…åº”å›ç­”â€œæ˜¯â€ã€‚
- en: â€¢
  id: totrans-365
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The factors of variability that the error bars are capturing should be clearly
    stated (for example, train/test split, initialization, random drawing of some
    parameter, or overall run with given experimental conditions).
  id: totrans-366
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯¯å·®æ¡æ‰€æ•æ‰çš„å˜å¼‚å› ç´ åº”æ˜ç¡®è¯´æ˜ï¼ˆä¾‹å¦‚ï¼Œè®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†ã€åˆå§‹åŒ–ã€éšæœºé€‰æ‹©æŸäº›å‚æ•°ï¼Œæˆ–åœ¨ç»™å®šå®éªŒæ¡ä»¶ä¸‹çš„æ•´ä½“è¿è¡Œï¼‰ã€‚
- en: â€¢
  id: totrans-367
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The method for calculating the error bars should be explained (closed form formula,
    call to a library function, bootstrap, etc.)
  id: totrans-368
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®¡ç®—è¯¯å·®æ¡çš„æ–¹æ³•åº”è¿›è¡Œè§£é‡Šï¼ˆé—­å¼å…¬å¼ã€è°ƒç”¨åº“å‡½æ•°ã€è‡ªåŠ©æ³•ç­‰ï¼‰ã€‚
- en: â€¢
  id: totrans-369
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The assumptions made should be given (e.g., Normally distributed errors).
  id: totrans-370
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: åº”æä¾›æ‰€åšå‡è®¾ï¼ˆä¾‹å¦‚ï¼Œè¯¯å·®æœä»æ­£æ€åˆ†å¸ƒï¼‰ã€‚
- en: â€¢
  id: totrans-371
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: It should be clear whether the error bar is the standard deviation or the standard
    error of the mean.
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: åº”æ˜ç¡®è¯´æ˜è¯¯å·®æ¡æ˜¯æ ‡å‡†å·®è¿˜æ˜¯å‡å€¼çš„æ ‡å‡†è¯¯å·®ã€‚
- en: â€¢
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: It is OK to report 1-sigma error bars, but one should state it. The authors
    should preferably report a 2-sigma error bar than state that they have a 96% CI,
    if the hypothesis of Normality of errors is not verified.
  id: totrans-374
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æŠ¥å‘Š1-Ïƒè¯¯å·®æ¡æ˜¯å¯ä»¥çš„ï¼Œä½†åº”è¯¥æ˜ç¡®è¯´æ˜ã€‚ä½œè€…æœ€å¥½æŠ¥å‘Š2-Ïƒè¯¯å·®æ¡ï¼Œè€Œä¸æ˜¯ä»…å£°æ˜ä»–ä»¬æœ‰96%çš„ç½®ä¿¡åŒºé—´ï¼Œç‰¹åˆ«æ˜¯åœ¨é”™è¯¯çš„æ­£æ€æ€§å‡è®¾æœªè¢«éªŒè¯çš„æƒ…å†µä¸‹ã€‚
- en: â€¢
  id: totrans-375
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: For asymmetric distributions, the authors should be careful not to show in tables
    or figures symmetric error bars that would yield results that are out of range
    (e.g. negative error rates).
  id: totrans-376
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºä¸å¯¹ç§°åˆ†å¸ƒï¼Œä½œè€…åº”å°å¿ƒä¸è¦åœ¨è¡¨æ ¼æˆ–å›¾å½¢ä¸­æ˜¾ç¤ºå¯¹ç§°çš„è¯¯å·®æ¡ï¼Œè¿™å¯èƒ½å¯¼è‡´ç»“æœè¶…å‡ºèŒƒå›´ï¼ˆä¾‹å¦‚ï¼Œè´Ÿçš„é”™è¯¯ç‡ï¼‰ã€‚
- en: â€¢
  id: totrans-377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If error bars are reported in tables or plots, The authors should explain in
    the text how they were calculated and reference the corresponding figures or tables
    in the text.
  id: totrans-378
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœåœ¨è¡¨æ ¼æˆ–å›¾å½¢ä¸­æŠ¥å‘Šè¯¯å·®æ¡ï¼Œä½œè€…åº”åœ¨æ–‡æœ¬ä¸­è§£é‡Šè¯¯å·®æ¡çš„è®¡ç®—æ–¹å¼ï¼Œå¹¶å¼•ç”¨æ–‡æœ¬ä¸­çš„ç›¸å…³å›¾å½¢æˆ–è¡¨æ ¼ã€‚
- en: '8.'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: Experiments Compute Resources
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®éªŒè®¡ç®—èµ„æº
- en: 'Question: For each experiment, does the paper provide sufficient information
    on the computer resources (type of compute workers, memory, time of execution)
    needed to reproduce the experiments?'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šå¯¹äºæ¯ä¸ªå®éªŒï¼Œè®ºæ–‡æ˜¯å¦æä¾›äº†è¶³å¤Ÿçš„è®¡ç®—èµ„æºä¿¡æ¯ï¼ˆè®¡ç®—å·¥ä½œèŠ‚ç‚¹ç±»å‹ã€å†…å­˜ã€æ‰§è¡Œæ—¶é—´ï¼‰ï¼Œä»¥ä¾¿é‡ç°å®éªŒï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: For each experiment, the paper provide sufficient information
    on the computer resources.'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šå¯¹äºæ¯ä¸ªå®éªŒï¼Œè®ºæ–‡æä¾›äº†è¶³å¤Ÿçš„è®¡ç®—èµ„æºä¿¡æ¯ã€‚
- en: 'Guidelines:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-385
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not include experiments.
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€æ„å‘³ç€è®ºæ–‡ä¸­æ²¡æœ‰å®éªŒã€‚
- en: â€¢
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The paper should indicate the type of compute worker CPU or GPU, internal cluster,
    or cloud provider, including relevant memory and storage.
  id: totrans-388
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®ºæ–‡åº”æŒ‡æ˜è®¡ç®—å·¥ä½œèŠ‚ç‚¹çš„ç±»å‹ï¼ˆCPUæˆ–GPUï¼‰ã€å†…éƒ¨é›†ç¾¤æˆ–äº‘æœåŠ¡æä¾›å•†ï¼Œå¹¶åŒ…æ‹¬ç›¸å…³çš„å†…å­˜å’Œå­˜å‚¨ã€‚
- en: â€¢
  id: totrans-389
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The paper should provide the amount of compute required for each of the individual
    experimental runs as well as estimate the total compute.
  id: totrans-390
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®ºæ–‡åº”æä¾›æ¯ä¸ªç‹¬ç«‹å®éªŒè¿è¡Œæ‰€éœ€çš„è®¡ç®—é‡ï¼Œå¹¶ä¼°ç®—æ€»è®¡ç®—é‡ã€‚
- en: â€¢
  id: totrans-391
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The paper should disclose whether the full research project required more compute
    than the experiments reported in the paper (e.g., preliminary or failed experiments
    that didnâ€™t make it into the paper).
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®ºæ–‡åº”æŠ«éœ²å®Œæ•´çš„ç ”ç©¶é¡¹ç›®æ˜¯å¦éœ€è¦æ¯”è®ºæ–‡ä¸­æŠ¥å‘Šçš„å®éªŒæ›´å¤šçš„è®¡ç®—é‡ï¼ˆä¾‹å¦‚ï¼Œæœªçº³å…¥è®ºæ–‡çš„åˆæ­¥æˆ–å¤±è´¥å®éªŒï¼‰ã€‚
- en: '9.'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '9.'
- en: Code Of Ethics
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¼¦ç†è§„èŒƒ
- en: 'Question: Does the research conducted in the paper conform, in every respect,
    with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines](https://neurips.cc/public/EthicsGuidelines)?'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡ä¸­è¿›è¡Œçš„ç ”ç©¶æ˜¯å¦åœ¨å„ä¸ªæ–¹é¢éƒ½ç¬¦åˆNeurIPSä¼¦ç†è§„èŒƒ [https://neurips.cc/public/EthicsGuidelines](https://neurips.cc/public/EthicsGuidelines)ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The research conducted in the paper conform, in every respect,
    comply with the NeurIPS Code of Ethics.'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šè®ºæ–‡ä¸­è¿›è¡Œçš„ç ”ç©¶åœ¨å„ä¸ªæ–¹é¢éƒ½éµå®ˆäº†NeurIPSä¼¦ç†è§„èŒƒã€‚
- en: 'Guidelines:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€æ„å‘³ç€ä½œè€…æ²¡æœ‰å®¡æŸ¥NeurIPSä¼¦ç†è§„èŒƒã€‚
- en: â€¢
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If the authors answer No, they should explain the special circumstances that
    require a deviation from the Code of Ethics.
  id: totrans-402
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½œè€…å›ç­”â€œå¦â€ï¼Œåº”è§£é‡Šä¸ºä½•éœ€è¦åç¦»ä¼¦ç†è§„èŒƒçš„ç‰¹æ®Šæƒ…å†µã€‚
- en: â€¢
  id: totrans-403
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should make sure to preserve anonymity (e.g., if there is a special
    consideration due to laws or regulations in their jurisdiction).
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”ç¡®ä¿ä¿ç•™åŒ¿åæ€§ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœç”±äºæ‰€åœ¨å¸æ³•ç®¡è¾–åŒºçš„æ³•å¾‹æˆ–æ³•è§„æœ‰ç‰¹æ®Šè€ƒè™‘ï¼‰ã€‚
- en: '10.'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '10.'
- en: Broader Impacts
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ›´å¹¿æ³›çš„å½±å“
- en: 'Question: Does the paper discuss both potential positive societal impacts and
    negative societal impacts of the work performed?'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦è®¨è®ºäº†è¯¥å·¥ä½œå¯èƒ½äº§ç”Ÿçš„æ­£é¢ç¤¾ä¼šå½±å“å’Œè´Ÿé¢ç¤¾ä¼šå½±å“ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper discuss both potential positive societal impacts and
    negative societal impacts of the work performed in Appendix section "Ethical Consideration".'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šè®ºæ–‡åœ¨é™„å½•â€œä¼¦ç†è€ƒè™‘â€éƒ¨åˆ†è®¨è®ºäº†è¯¥å·¥ä½œå¯èƒ½äº§ç”Ÿçš„æ­£é¢ç¤¾ä¼šå½±å“å’Œè´Ÿé¢ç¤¾ä¼šå½±å“ã€‚
- en: 'Guidelines:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that there is no societal impact of the work performed.
  id: totrans-412
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€æ„å‘³ç€å·¥ä½œæ²¡æœ‰ç¤¾ä¼šå½±å“ã€‚
- en: â€¢
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If the authors answer NA or No, they should explain why their work has no societal
    impact or why the paper does not address societal impact.
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½œè€…å›ç­”â€œNAâ€æˆ–â€œå¦â€ï¼Œåº”è§£é‡Šä¸ºä½•ä»–ä»¬çš„å·¥ä½œæ²¡æœ‰ç¤¾ä¼šå½±å“ï¼Œæˆ–è€…ä¸ºä½•è®ºæ–‡æ²¡æœ‰æ¶‰åŠç¤¾ä¼šå½±å“ã€‚
- en: â€¢
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Examples of negative societal impacts include potential malicious or unintended
    uses (e.g., disinformation, generating fake profiles, surveillance), fairness
    considerations (e.g., deployment of technologies that could make decisions that
    unfairly impact specific groups), privacy considerations, and security considerations.
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è´Ÿé¢ç¤¾ä¼šå½±å“çš„ä¾‹å­åŒ…æ‹¬æ½œåœ¨çš„æ¶æ„æˆ–éé¢„æœŸçš„ä½¿ç”¨ï¼ˆä¾‹å¦‚è™šå‡ä¿¡æ¯ã€ç”Ÿæˆè™šå‡ä¸ªäººèµ„æ–™ã€ç›‘æ§ï¼‰ã€å…¬å¹³æ€§è€ƒè™‘ï¼ˆä¾‹å¦‚éƒ¨ç½²å¯èƒ½ä¼šåšå‡ºä¸å…¬æ­£å†³ç­–çš„æŠ€æœ¯ï¼Œå½±å“ç‰¹å®šç¾¤ä½“ï¼‰ã€éšç§è€ƒè™‘å’Œå®‰å…¨è€ƒè™‘ã€‚
- en: â€¢
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The conference expects that many papers will be foundational research and not
    tied to particular applications, let alone deployments. However, if there is a
    direct path to any negative applications, the authors should point it out. For
    example, it is legitimate to point out that an improvement in the quality of generative
    models could be used to generate deepfakes for disinformation. On the other hand,
    it is not needed to point out that a generic algorithm for optimizing neural networks
    could enable people to train models that generate Deepfakes faster.
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¼šè®®é¢„è®¡ï¼Œè®¸å¤šè®ºæ–‡å°†èšç„¦äºåŸºç¡€ç ”ç©¶ï¼Œè€Œä¸æ˜¯ä¸ç‰¹å®šåº”ç”¨ç›¸å…³ï¼Œæ›´ä¸ç”¨è¯´éƒ¨ç½²ã€‚ç„¶è€Œï¼Œå¦‚æœæœ‰ç›´æ¥é€šå‘ä»»ä½•è´Ÿé¢åº”ç”¨çš„è·¯å¾„ï¼Œä½œè€…åº”å½“æŒ‡å‡ºã€‚ä¾‹å¦‚ï¼ŒæŒ‡å‡ºç”Ÿæˆæ¨¡å‹è´¨é‡çš„æå‡å¯èƒ½è¢«ç”¨æ¥ç”Ÿæˆè™šå‡ä¿¡æ¯çš„æ·±åº¦ä¼ªé€ æ˜¯åˆç†çš„ã€‚å¦ä¸€æ–¹é¢ï¼ŒæŒ‡å‡ºä¸€ä¸ªé€šç”¨çš„ç¥ç»ç½‘ç»œä¼˜åŒ–ç®—æ³•å¯èƒ½å¸®åŠ©äººä»¬æ›´å¿«åœ°è®­ç»ƒç”Ÿæˆæ·±åº¦ä¼ªé€ çš„æ¨¡å‹åˆ™ä¸éœ€è¦ã€‚
- en: â€¢
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should consider possible harms that could arise when the technology
    is being used as intended and functioning correctly, harms that could arise when
    the technology is being used as intended but gives incorrect results, and harms
    following from (intentional or unintentional) misuse of the technology.
  id: totrans-420
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”è€ƒè™‘å½“æŠ€æœ¯æŒ‰é¢„æœŸä½¿ç”¨ä¸”æ­£å¸¸è¿è¡Œæ—¶å¯èƒ½å¸¦æ¥çš„å±å®³ï¼Œå½“æŠ€æœ¯æŒ‰é¢„æœŸä½¿ç”¨ä½†ç»“æœé”™è¯¯æ—¶å¯èƒ½å¸¦æ¥çš„å±å®³ï¼Œä»¥åŠï¼ˆæœ‰æ„æˆ–æ— æ„ï¼‰æ»¥ç”¨æŠ€æœ¯æ‰€å¸¦æ¥çš„å±å®³ã€‚
- en: â€¢
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If there are negative societal impacts, the authors could also discuss possible
    mitigation strategies (e.g., gated release of models, providing defenses in addition
    to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system
    learns from feedback over time, improving the efficiency and accessibility of
    ML).
  id: totrans-422
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœå­˜åœ¨è´Ÿé¢ç¤¾ä¼šå½±å“ï¼Œä½œè€…ä¹Ÿå¯ä»¥è®¨è®ºå¯èƒ½çš„ç¼“è§£ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼Œæ¨¡å‹çš„å—é™å‘å¸ƒã€æä¾›é˜²å¾¡è€Œéæ”»å‡»ã€ç›‘æ§æ»¥ç”¨çš„æœºåˆ¶ã€ç›‘æ§ç³»ç»Ÿå¦‚ä½•ä»åé¦ˆä¸­å­¦ä¹ çš„æœºåˆ¶ã€æé«˜æœºå™¨å­¦ä¹ çš„æ•ˆç‡å’Œå¯è·å–æ€§ï¼‰ã€‚
- en: '11.'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '11.'
- en: Safeguards
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®‰å…¨ä¿éšœ
- en: 'Question: Does the paper describe safeguards that have been put in place for
    responsible release of data or models that have a high risk for misuse (e.g.,
    pretrained language models, image generators, or scraped datasets)?'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦æè¿°äº†é’ˆå¯¹å…·æœ‰é«˜æ»¥ç”¨é£é™©ï¼ˆä¾‹å¦‚ï¼Œé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€å›¾åƒç”Ÿæˆå™¨æˆ–æŠ“å–çš„æ•°æ®é›†ï¼‰æ•°æ®æˆ–æ¨¡å‹çš„è´Ÿè´£ä»»å‘å¸ƒæ‰€é‡‡å–çš„å®‰å…¨æªæ–½ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: The paper describe safeguards that have been put in place for
    responsible release of data or models that have a high risk for misuse in Appendix
    section "Ethical Consideration".'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è§£é‡Šï¼šè®ºæ–‡åœ¨é™„å½•â€œä¼¦ç†è€ƒè™‘â€éƒ¨åˆ†æè¿°äº†é’ˆå¯¹å…·æœ‰é«˜æ»¥ç”¨é£é™©çš„æ•°æ®æˆ–æ¨¡å‹çš„è´Ÿè´£ä»»å‘å¸ƒæ‰€é‡‡å–çš„å®‰å…¨æªæ–½ã€‚
- en: 'Guidelines:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-429
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper poses no such risks.
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAè¡¨ç¤ºè®ºæ–‡æ²¡æœ‰æ­¤ç±»é£é™©ã€‚
- en: â€¢
  id: totrans-431
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Released models that have a high risk for misuse or dual-use should be released
    with necessary safeguards to allow for controlled use of the model, for example
    by requiring that users adhere to usage guidelines or restrictions to access the
    model or implementing safety filters.
  id: totrans-432
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºå…·æœ‰é«˜æ»¥ç”¨é£é™©æˆ–åŒé‡ç”¨é€”çš„å‘å¸ƒæ¨¡å‹ï¼Œåº”æä¾›å¿…è¦çš„å®‰å…¨ä¿éšœæªæ–½ï¼Œä»¥å…è®¸å¯¹æ¨¡å‹è¿›è¡Œå—æ§ä½¿ç”¨ï¼Œä¾‹å¦‚è¦æ±‚ç”¨æˆ·éµå®ˆä½¿ç”¨æŒ‡å—æˆ–é™åˆ¶æ¨¡å‹è®¿é—®ï¼Œæˆ–å®æ–½å®‰å…¨è¿‡æ»¤å™¨ã€‚
- en: â€¢
  id: totrans-433
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Datasets that have been scraped from the Internet could pose safety risks. The
    authors should describe how they avoided releasing unsafe images.
  id: totrans-434
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»äº’è”ç½‘ä¸ŠæŠ“å–çš„æ•°æ®é›†å¯èƒ½å¸¦æ¥å®‰å…¨é£é™©ã€‚ä½œè€…åº”æè¿°ä»–ä»¬å¦‚ä½•é¿å…å‘å¸ƒä¸å®‰å…¨çš„å›¾åƒã€‚
- en: â€¢
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: We recognize that providing effective safeguards is challenging, and many papers
    do not require this, but we encourage authors to take this into account and make
    a best faith effort.
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¤è¯†åˆ°ï¼Œæä¾›æœ‰æ•ˆçš„å®‰å…¨ä¿éšœæ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œè®¸å¤šè®ºæ–‡å¹¶ä¸éœ€è¦æ­¤ç±»å†…å®¹ï¼Œä½†æˆ‘ä»¬é¼“åŠ±ä½œè€…è€ƒè™‘è¿™ä¸€ç‚¹ï¼Œå¹¶å°½æœ€å¤§åŠªåŠ›é‡‡å–åˆç†æªæ–½ã€‚
- en: '12.'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '12.'
- en: Licenses for existing assets
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç°æœ‰èµ„äº§çš„è®¸å¯è¯
- en: 'Question: Are the creators or original owners of assets (e.g., code, data,
    models), used in the paper, properly credited and are the license and terms of
    use explicitly mentioned and properly respected?'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šåœ¨è®ºæ–‡ä¸­ä½¿ç”¨çš„èµ„äº§ï¼ˆä¾‹å¦‚ä»£ç ã€æ•°æ®ã€æ¨¡å‹ï¼‰çš„åˆ›å»ºè€…æˆ–åŸå§‹æ‰€æœ‰è€…æ˜¯å¦å¾—åˆ°äº†é€‚å½“çš„ç½²åï¼Œå¹¶ä¸”è®¸å¯è¯å’Œä½¿ç”¨æ¡æ¬¾æ˜¯å¦æ˜ç¡®æåŠå¹¶å¾—åˆ°é€‚å½“å°Šé‡ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: the creators or original owners of assets (e.g., code, data,
    models), used in the paper, properly credited and are the license and terms of
    use explicitly mentioned and properly respected'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯æ˜ï¼šè®ºæ–‡ä¸­ä½¿ç”¨çš„èµ„äº§ï¼ˆä¾‹å¦‚ä»£ç ã€æ•°æ®ã€æ¨¡å‹ï¼‰çš„åˆ›é€ è€…æˆ–åŸå§‹æ‰€æœ‰è€…å·²å¾—åˆ°é€‚å½“çš„ç½²åï¼Œå¹¶ä¸”è®¸å¯è¯å’Œä½¿ç”¨æ¡æ¬¾å·²æ˜ç¡®è¯´æ˜å¹¶å¾—åˆ°å……åˆ†éµå®ˆã€‚
- en: 'Guidelines:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-443
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not use existing assets.
  id: totrans-444
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€è¡¨ç¤ºè®ºæ–‡æ²¡æœ‰ä½¿ç”¨ç°æœ‰çš„èµ„äº§ã€‚
- en: â€¢
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should cite the original paper that produced the code package or
    dataset.
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”å¼•ç”¨äº§ç”Ÿè¯¥ä»£ç åŒ…æˆ–æ•°æ®é›†çš„åŸå§‹è®ºæ–‡ã€‚
- en: â€¢
  id: totrans-447
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The authors should state which version of the asset is used and, if possible,
    include a URL.
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä½œè€…åº”è¯´æ˜ä½¿ç”¨çš„æ˜¯å“ªä¸ªç‰ˆæœ¬çš„èµ„äº§ï¼Œå¹¶ä¸”å¦‚æœå¯èƒ½çš„è¯ï¼Œæä¾›URLã€‚
- en: â€¢
  id: totrans-449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The name of the license (e.g., CC-BY 4.0) should be included for each asset.
  id: totrans-450
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¯ä¸ªèµ„äº§åº”åŒ…æ‹¬è®¸å¯è¯åç§°ï¼ˆä¾‹å¦‚CC-BY 4.0ï¼‰ã€‚
- en: â€¢
  id: totrans-451
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: For scraped data from a particular source (e.g., website), the copyright and
    terms of service of that source should be provided.
  id: totrans-452
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºä»ç‰¹å®šæ¥æºï¼ˆä¾‹å¦‚ç½‘ç«™ï¼‰æŠ“å–çš„æ•°æ®ï¼Œåº”è¯¥æä¾›è¯¥æ¥æºçš„ç‰ˆæƒå’ŒæœåŠ¡æ¡æ¬¾ã€‚
- en: â€¢
  id: totrans-453
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If assets are released, the license, copyright information, and terms of use
    in the package should be provided. For popular datasets, [paperswithcode.com/datasets](paperswithcode.com/datasets)
    has curated licenses for some datasets. Their licensing guide can help determine
    the license of a dataset.
  id: totrans-454
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœèµ„äº§è¢«å‘å¸ƒï¼Œåº”è¯¥æä¾›åŒ…ä¸­çš„è®¸å¯è¯ã€ç‰ˆæƒä¿¡æ¯å’Œä½¿ç”¨æ¡æ¬¾ã€‚å¯¹äºæµè¡Œçš„æ•°æ®é›†ï¼Œ[paperswithcode.com/datasets](paperswithcode.com/datasets)
    æä¾›äº†ä¸€äº›æ•°æ®é›†çš„è®¸å¯è¯æ±‡ç¼–ã€‚ä»–ä»¬çš„è®¸å¯æŒ‡å—å¯ä»¥å¸®åŠ©ç¡®å®šæ•°æ®é›†çš„è®¸å¯è¯ã€‚
- en: â€¢
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: For existing datasets that are re-packaged, both the original license and the
    license of the derived asset (if it has changed) should be provided.
  id: totrans-456
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºé‡æ–°åŒ…è£…çš„ç°æœ‰æ•°æ®é›†ï¼Œåº”è¯¥æä¾›åŸå§‹è®¸å¯è¯å’Œæ´¾ç”Ÿèµ„äº§çš„è®¸å¯è¯ï¼ˆå¦‚æœæœ‰æ‰€å˜æ›´ï¼‰ã€‚
- en: â€¢
  id: totrans-457
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: If this information is not available online, the authors are encouraged to reach
    out to the assetâ€™s creators.
  id: totrans-458
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™äº›ä¿¡æ¯åœ¨çº¿ä¸Šä¸å¯å¾—ï¼Œä½œè€…åº”è”ç³»èµ„äº§çš„åˆ›å»ºè€…ã€‚
- en: '13.'
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '13.'
- en: New Assets
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ–°èµ„äº§
- en: 'Question: Are new assets introduced in the paper well documented and is the
    documentation provided alongside the assets?'
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡ä¸­æ˜¯å¦æœ‰ä»‹ç»æ–°çš„èµ„äº§ï¼Œå¹¶ä¸”è¿™äº›èµ„äº§çš„æ–‡æ¡£æ˜¯å¦ä¸èµ„äº§ä¸€èµ·æä¾›ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: new assets introduced in the paper are well documented and the
    documentation is provided in section "Experiment".'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯æ˜ï¼šè®ºæ–‡ä¸­å¼•å…¥çš„æ–°èµ„äº§æœ‰è‰¯å¥½çš„æ–‡æ¡£è®°å½•ï¼Œå¹¶ä¸”æ–‡æ¡£å·²åœ¨â€œå®éªŒâ€éƒ¨åˆ†æä¾›ã€‚
- en: 'Guidelines:'
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not release new assets.
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€è¡¨ç¤ºè®ºæ–‡æ²¡æœ‰å‘å¸ƒæ–°çš„èµ„äº§ã€‚
- en: â€¢
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Researchers should communicate the details of the dataset/code/model as part
    of their submissions via structured templates. This includes details about training,
    license, limitations, etc.
  id: totrans-468
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç ”ç©¶äººå‘˜åº”é€šè¿‡ç»“æ„åŒ–æ¨¡æ¿åœ¨æäº¤è¿‡ç¨‹ä¸­ä¼ è¾¾æ•°æ®é›†/ä»£ç /æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ã€‚è¿™åŒ…æ‹¬è®­ç»ƒã€è®¸å¯è¯ã€é™åˆ¶ç­‰ä¿¡æ¯ã€‚
- en: â€¢
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The paper should discuss whether and how consent was obtained from people whose
    asset is used.
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: è®ºæ–‡åº”è®¨è®ºæ˜¯å¦ä»¥åŠå¦‚ä½•è·å¾—ä½¿ç”¨è€…èµ„äº§çš„åŒæ„ã€‚
- en: â€¢
  id: totrans-471
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: At submission time, remember to anonymize your assets (if applicable). You can
    either create an anonymized URL or include an anonymized zip file.
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æäº¤æ—¶ï¼Œè®°å¾—å¯¹ä½ çš„èµ„äº§è¿›è¡ŒåŒ¿åå¤„ç†ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚ä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ¿åçš„URLæˆ–åŒ…å«ä¸€ä¸ªåŒ¿åçš„å‹ç¼©æ–‡ä»¶ã€‚
- en: '14.'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '14.'
- en: Crowdsourcing and Research with Human Subjects
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¼—åŒ…å’Œæ¶‰åŠäººç±»å—è¯•è€…çš„ç ”ç©¶
- en: 'Question: For crowdsourcing experiments and research with human subjects, does
    the paper include the full text of instructions given to participants and screenshots,
    if applicable, as well as details about compensation (if any)?'
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šå¯¹äºä¼—åŒ…å®éªŒå’Œæ¶‰åŠäººç±»å—è¯•è€…çš„ç ”ç©¶ï¼Œè®ºæ–‡æ˜¯å¦åŒ…æ‹¬æä¾›ç»™å‚ä¸è€…çš„å®Œæ•´æŒ‡ç¤ºæ–‡æœ¬å’Œæˆªå›¾ï¼ˆå¦‚é€‚ç”¨ï¼‰ï¼Œä»¥åŠå…³äºè¡¥å¿çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: our work does not involve crowdsourcing or research with human
    subjects.'
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯æ˜ï¼šæˆ‘ä»¬çš„å·¥ä½œä¸æ¶‰åŠä¼—åŒ…æˆ–äººç±»å—è¯•è€…çš„ç ”ç©¶ã€‚
- en: 'Guidelines:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not involve crowdsourcing nor research
    with human subjects.
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆâ€œNAâ€è¡¨ç¤ºè®ºæ–‡ä¸æ¶‰åŠä¼—åŒ…æˆ–äººç±»å—è¯•è€…çš„ç ”ç©¶ã€‚
- en: â€¢
  id: totrans-481
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Including this information in the supplemental material is fine, but if the
    main contribution of the paper involves human subjects, then as much detail as
    possible should be included in the main paper.
  id: totrans-482
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°†è¿™äº›ä¿¡æ¯åŒ…å«åœ¨è¡¥å……ææ–™ä¸­æ˜¯å¯ä»¥çš„ï¼Œä½†å¦‚æœè®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ¶‰åŠåˆ°äººç±»å—è¯•è€…ï¼Œé‚£ä¹ˆå°½å¯èƒ½å¤šçš„ç»†èŠ‚åº”åŒ…å«åœ¨æ­£æ–‡ä¸­ã€‚
- en: â€¢
  id: totrans-483
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: According to the NeurIPS Code of Ethics, workers involved in data collection,
    curation, or other labor should be paid at least the minimum wage in the country
    of the data collector.
  id: totrans-484
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ ¹æ®NeurIPSä¼¦ç†å‡†åˆ™ï¼Œå‚ä¸æ•°æ®æ”¶é›†ã€æ•´ç†æˆ–å…¶ä»–åŠ³åŠ¡çš„å·¥ä½œäººå‘˜åº”è¯¥è‡³å°‘è·å¾—æ•°æ®æ”¶é›†è€…æ‰€åœ¨å›½å®¶çš„æœ€ä½å·¥èµ„ã€‚
- en: '15.'
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '15.'
- en: Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
    Subjects
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœºæ„å®¡æŸ¥å§”å‘˜ä¼šï¼ˆIRBï¼‰æ‰¹å‡†æˆ–ç­‰æ•ˆçš„é’ˆå¯¹äººç±»å—è¯•è€…çš„ç ”ç©¶
- en: 'Question: Does the paper describe potential risks incurred by study participants,
    whether such risks were disclosed to the subjects, and whether Institutional Review
    Board (IRB) approvals (or an equivalent approval/review based on the requirements
    of your country or institution) were obtained?'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—®é¢˜ï¼šè®ºæ–‡æ˜¯å¦æè¿°äº†ç ”ç©¶å‚ä¸è€…å¯èƒ½é¢ä¸´çš„é£é™©ï¼Œæ˜¯å¦å·²å‘å—è¯•è€…æŠ«éœ²è¿™äº›é£é™©ï¼Œå¹¶ä¸”æ˜¯å¦è·å¾—äº†æœºæ„å®¡æŸ¥å§”å‘˜ä¼šï¼ˆIRBï¼‰æ‰¹å‡†ï¼ˆæˆ–æ ¹æ®æ‚¨çš„å›½å®¶æˆ–æœºæ„çš„è¦æ±‚è·å¾—äº†ç­‰æ•ˆçš„æ‰¹å‡†/å®¡æŸ¥ï¼‰ï¼Ÿ
- en: 'Answer: [Yes]'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆï¼š[æ˜¯]
- en: 'Justification: our work does not involve research with human subjects.'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯´æ˜ï¼šæˆ‘ä»¬çš„å·¥ä½œä¸æ¶‰åŠä¸äººç±»å—è¯•è€…ç›¸å…³çš„ç ”ç©¶ã€‚
- en: 'Guidelines:'
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å—ï¼š
- en: â€¢
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The answer NA means that the paper does not involve crowdsourcing nor research
    with human subjects.
  id: totrans-492
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆNAè¡¨ç¤ºè¯¥è®ºæ–‡ä¸æ¶‰åŠä¼—åŒ…æˆ–äººç±»å—è¯•è€…çš„ç ”ç©¶ã€‚
- en: â€¢
  id: totrans-493
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Depending on the country in which research is conducted, IRB approval (or equivalent)
    may be required for any human subjects research. If you obtained IRB approval,
    you should clearly state this in the paper.
  id: totrans-494
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ ¹æ®ç ”ç©¶æ‰€åœ¨å›½å®¶çš„ä¸åŒï¼Œä»»ä½•æ¶‰åŠäººç±»å—è¯•è€…çš„ç ”ç©¶å¯èƒ½éƒ½éœ€è¦è·å¾—IRBæ‰¹å‡†ï¼ˆæˆ–ç­‰æ•ˆæ‰¹å‡†ï¼‰ã€‚å¦‚æœæ‚¨å·²è·å¾—IRBæ‰¹å‡†ï¼Œåº”è¯¥åœ¨è®ºæ–‡ä¸­æ˜ç¡®è¯´æ˜ã€‚
- en: â€¢
  id: totrans-495
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: We recognize that the procedures for this may vary significantly between institutions
    and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and
    the guidelines for their institution.
  id: totrans-496
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¤è¯†åˆ°ï¼Œä¸åŒæœºæ„å’Œåœ°åŒºçš„ç›¸å…³ç¨‹åºå¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œæˆ‘ä»¬æœŸæœ›ä½œè€…éµå¾ªNeurIPSä¼¦ç†è§„èŒƒåŠå…¶æ‰€åœ¨æœºæ„çš„ç›¸å…³æŒ‡å—ã€‚
- en: â€¢
  id: totrans-497
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: For initial submissions, do not include any information that would break anonymity
    (if applicable), such as the institution conducting the review.
  id: totrans-498
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºåˆæ¬¡æäº¤ï¼Œè¯·ä¸è¦åŒ…å«ä»»ä½•å¯èƒ½ç ´ååŒ¿åæ€§çš„å†…å®¹ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ï¼Œä¾‹å¦‚è¿›è¡Œå®¡ç¨¿çš„æœºæ„åç§°ã€‚
