- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 13:00:16'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 13:00:16
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLM-MARS: Large Language Model for Behavior Tree Generation and NLP-enhanced
    Dialogue in Multi-Agent Robot Systems'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM-MARS：用于行为树生成和自然语言处理增强对话的多智能体机器人系统中的大型语言模型
- en: 来源：[https://arxiv.org/html/2312.09348/](https://arxiv.org/html/2312.09348/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2312.09348/](https://arxiv.org/html/2312.09348/)
- en: Artem Lykov, Maria Dronova, Nikolay Naglov,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Artem Lykov, Maria Dronova, Nikolay Naglov，
- en: Mikhail Litvinov, Sergei Satsevich, Artem Bazhenov,
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Mikhail Litvinov, Sergei Satsevich, Artem Bazhenov，
- en: Vladimir Berman, Aleksei Shcherbak and Dzmitry Tsetserukou ©2023 IEEE. This
    work has been submitted to IEEE for possible publication. Copyright may be transferred
    without notice, after which this version may no longer be accessibleThe authors
    are with the Intelligent Space Robotics Laboratory, Center for Digital Engineering,
    Skolkovo Institute of Science and Technology (Skoltech), 121205 Moscow, Russia.
    {Artem.Lykov, Maria.Dronova, Nikolay.Naglov, Mikhail.Litvinov2, Sergei.Satsevich,
    Artem.Bazhenov, Vladimir.Berman, Aleksei.Shcherbak, D.Tsetserukou}@skoltech.ru
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Vladimir Berman, Aleksei Shcherbak 和 Dzmitry Tsetserukou ©2023 IEEE。该工作已提交给IEEE，等待可能的发表。版权可能会在未通知的情况下转让，转让后该版本可能无法再访问。作者们来自俄罗斯莫斯科的斯科尔科沃科技学院（Skoltech）数字工程中心智能空间机器人实验室，邮政编码121205。
    {Artem.Lykov, Maria.Dronova, Nikolay.Naglov, Mikhail.Litvinov2, Sergei.Satsevich,
    Artem.Bazhenov, Vladimir.Berman, Aleksei.Shcherbak, D.Tsetserukou}@skoltech.ru
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: This paper introduces LLM-MARS, first technology that utilizes a Large Language
    Model based Artificial Intelligence for Multi-Agent Robot Systems. LLM-MARS enables
    dynamic dialogues between humans and robots, allowing the latter to generate behavior
    based on operator commands and provide informative answers to questions about
    their actions. LLM-MARS is built on a transformer-based Large Language Model,
    fine-tuned from the Falcon 7B model. We employ a multimodal approach using LoRa
    adapters for different tasks. The first LoRa adapter was developed by fine-tuning
    the base model on examples of Behavior Trees and their corresponding commands.
    The second LoRa adapter was developed by fine-tuning on question-answering examples.
    Practical trials on a multi-agent system of two robots within the Eurobot 2023
    game rules demonstrate promising results. The robots achieve an average task execution
    accuracy of 79.28% in compound commands. With commands containing up to two tasks
    accuracy exceeded 90%. Evaluation confirms the system’s answers on operators questions
    exhibit high accuracy, relevance, and informativeness. LLM-MARS and similar multi-agent
    robotic systems hold significant potential to revolutionize logistics, enabling
    autonomous exploration missions and advancing Industry 5.0.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了LLM-MARS，这是一项利用基于大型语言模型的人工智能技术，应用于多智能体机器人系统的首个技术。LLM-MARS使人类与机器人之间能够进行动态对话，允许机器人根据操作员的指令生成行为，并为关于其行为的问题提供信息丰富的回答。LLM-MARS建立在基于变换器的大型语言模型上，并对Falcon
    7B模型进行了微调。我们采用了多模态方法，使用LoRa适配器来处理不同的任务。第一个LoRa适配器是通过对行为树及其相应指令的示例进行微调开发的。第二个LoRa适配器则通过对问答示例的微调进行开发。根据2023年Eurobot比赛规则，在一个由两台机器人组成的多智能体系统上进行的实践试验显示出良好的结果。这些机器人在复合命令中的任务执行准确率达到79.28%。对于包含最多两个任务的命令，准确率超过了90%。评估结果表明，该系统对操作员问题的回答在准确性、相关性和信息性方面表现出色。LLM-MARS和类似的多智能体机器人系统具有革命性潜力，能够彻底改变物流领域，支持自主探索任务，并推动工业5.0的发展。
- en: 'Index Terms:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Robotics, artificial intelligence, multi-agent system, large language model,
    human-robot interaction, strategy generation, behaviour tree.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人技术，人工智能，多智能体系统，大型语言模型，人机交互，战略生成，行为树。
- en: I Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: In recent years, remarkable advancements have been made in the realms of robotics
    and artificial intelligence. Various methodologies have emerged to enhance the
    logical capabilities of robotic systems, with a particularly intriguing avenue
    of research involving the integration of large language models (LLMs), like GPT.
    These LLMs possess the exceptional ability to break down complex natural language
    tasks into simpler sub-tasks that can be executed by robots. Additionally, LLMs
    have been leveraged to develop human-robot interaction systems using natural language
    processing (NLP) techniques.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，机器人技术和人工智能领域取得了显著进展。多种方法论已涌现，用以增强机器人系统的逻辑能力，其中一个特别引人注目的研究方向是将大型语言模型（如GPT）与机器人系统的结合。这些大型语言模型具有将复杂的自然语言任务拆解为机器人可以执行的简单子任务的卓越能力。此外，大型语言模型还被用于开发利用自然语言处理（NLP）技术的人机交互系统。
- en: To address a range of challenges, multimodal solutions have also been explored.
    The emergence of open LLMs has marked a turning point in LLM research, as they
    can be openly trained on custom data, making them accessible and capable of performing
    instruction-following tasks. However, only limited research has focused on using
    LLMs to generate entire robot behaviour trees (BTs) that simultaneously consider
    the handling of a large number of possible scenarios. Such models are specifically
    designed to leverage natural language processing techniques to comprehend human
    speech and generate intricate operating sequence for robots based on the acquired
    information. This approach exhibits significant potential in enhancing the adaptability
    and flexibility of artificially intelligent robot systems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对一系列挑战，多模态解决方案也已被探索。开放式LLM的出现标志着LLM研究的一个转折点，因为它们可以在自定义数据上进行开放训练，使其更易获得并能够执行指令跟随任务。然而，针对使用LLM生成完整机器人行为树（BT）的研究仍然有限，这些行为树需要同时考虑大量可能的场景处理。这类模型专为利用自然语言处理技术来理解人类语言，并基于所获得的信息生成复杂的机器人操作序列而设计。这一方法在提升人工智能机器人系统的适应性和灵活性方面展示了巨大潜力。
- en: '![Refer to caption](img/3d614a304f81292c574f89aaf3d0eafe.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3d614a304f81292c574f89aaf3d0eafe.png)'
- en: 'Figure 1: Strategy generation process. User defines the tasks, Large Language
    Model generates a Behavior Tree for robots to autonomously solve the tasks given
    the environment.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：策略生成过程。用户定义任务，大型语言模型根据环境生成机器人自主完成任务的行为树。
- en: In this study, we employ the LLM-based BT generation approach that entails the
    utilization of a fine-tuned variant of the Falcon 7B LLM for BT generation. At
    the time of constructing our system, this model demonstrated exceptional metrics
    as per the LLM ranking [[1](#bib.bib1)]. Employed as a proof of concept, this
    model served its purpose. Nevertheless, the relentless influx of newly released
    models presents an ongoing challenge to keep abreast of the latest developments
    in the field.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们采用了基于LLM的行为树生成方法，利用经过微调的Falcon 7B LLM变体来生成行为树。在构建我们的系统时，该模型在LLM排名中表现出了卓越的指标[[1](#bib.bib1)]。作为概念验证模型，该模型达到了预期效果。然而，新模型的不断涌现带来了持续的挑战，我们需要跟上该领域最新发展的步伐。
- en: The model is fine-tuned using a dataset generated with the text-davinci-003
    model developed by OpenAI. To collect the dataset, pairs of commands for the robot
    and their corresponding BTs were generated using the ChatGPT API, while manually
    written BTs were used as examples for the model. Moreover, as our aim is to evaluate
    the performance of a multi-agent robot system when employing LLM under conditions
    that closely resemble real-world scenarios, experiments involving physical robots
    were conducted.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是通过使用由OpenAI开发的text-davinci-003模型生成的数据集进行微调的。为了收集数据集，使用ChatGPT API生成了机器人指令对及其相应的行为树（BT），同时手工编写的行为树被用作模型的示例。此外，鉴于我们的目标是评估在类似现实世界场景条件下使用大语言模型（LLM）时多智能体机器人系统的性能，因此还进行了涉及物理机器人的实验。
- en: A highly promising and readily apparent domain for the aforementioned application
    of dynamically generated BTs lies within the realm of robotics autonomous competitions.
    One such example is Eurobot, an esteemed international amateur robotics competition,
    hosted by Planète Sciences France. The primary technical challenge presented in
    Eurobot involves the construction of an autonomous robot or a pair of robots functioning
    in tandem. These robots are required to demonstrate reliability while effectively
    responding to actions initiated by their adversaries.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 动态生成行为树的上述应用在机器人自主竞赛领域展现了极大的潜力且明显可见。其中一个例子是Eurobot，这是一项由Planète Sciences France主办的国际著名业余机器人竞赛。Eurobot的主要技术挑战是构建一个自主机器人或一对协同工作的机器人。这些机器人需要在有效应对对手发起的行动的同时，展现出可靠性。
- en: In the context of the 2023 iteration of the competition, the participating robots
    were tasked with executing a specific sequence of actions. These actions encompassed
    the collection and categorization of object sets, referred to as “cakes”, based
    on their respective colors. Additionally, the robots were required to gather and
    tally spherical objects, commonly referred to as “cherries”. Subsequently, the
    acquired objects needed to be transported and placed in designated locations on
    the playing field. Furthermore, the robots had to skillfully navigate the playing
    field to reach their assigned team positions, while simultaneously forecasting
    the accrued points resulting from the collected objects. These intricate conditions
    presented within the competition serve as an exceptional testing ground for the
    real-world evaluation of generating robotic behavior trees.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年版本的比赛中，参赛机器人被要求执行一系列特定的动作。这些动作包括根据物体的颜色收集和分类一组被称为“蛋糕”的物品。此外，机器人还需要收集并统计被称为“樱桃”的球形物体。随后，获得的物体需要被运输并放置在比赛场地的指定位置。此外，机器人还必须巧妙地导航比赛场地，以到达指定的队伍位置，同时预测收集到的物体所带来的积分。这些复杂的条件为生成机器人行为树的现实世界评估提供了一个卓越的测试平台。
- en: 'Thus, in our study we focus on the application of a multimodal LLM to control
    a tandem of mobile robots under conditions that closely emulate real-world scenarios.
    The process of generating strategies is depicted of Fig. [1](#S1.F1 "Figure 1
    ‣ I Introduction ‣ LLM-MARS: Large Language Model for Behavior Tree Generation
    and NLP-enhanced Dialogue in Multi-Agent Robot Systems"). The core modules of
    the model specifically designed for this purpose include a behavior generation
    module in a BT format and a module for discussing task outcomes.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，在我们的研究中，我们专注于应用多模态LLM来控制一对移动机器人，在逼近现实世界场景的条件下执行任务。生成策略的过程如图[1](#S1.F1 "图1
    ‣ I 引言 ‣ LLM-MARS: 用于行为树生成和多智能体机器人系统中的NLP增强对话的大型语言模型")所示。该模型的核心模块专门设计用于此目的，包括BT格式的行为生成模块和用于讨论任务结果的模块。'
- en: II Related Works
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关工作
- en: In recent times, the transformer models have gained significant popularity,
    becoming increasingly prevalent in various domains since the concept was introduced
    in the groundbreaking paper “Attention is all you need” by Vaswani et al. [[2](#bib.bib2)].
    These transformer models have shown remarkable performance in tasks such as language
    modeling, translation, and speech recognition, among others.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，变换器模型（transformer models）获得了极大的关注，自从Vaswani等人在开创性的论文《Attention is all you
    need》中提出该概念以来，这些模型在各个领域变得越来越普及[[2](#bib.bib2)]。这些变换器模型在语言建模、翻译、语音识别等任务中表现出了卓越的性能。
- en: In particular, LLMs, which are based on the transformer architecture, have received
    tremendous attention in recent years. The rise in popularity has been facilitated
    by the emergence of models such as OpenAI’s GPT3.5 and GPT4, whose features are
    discussed by Chen et al. [[3](#bib.bib3)] and Bubeck et al. [[4](#bib.bib4)] respectively.
    The introduction of ChatGPT by OpenAI [[5](#bib.bib5)] has significantly contributed
    to the growing popularity by bringing accessibility to GPT to a broader audience,
    taking the level of popularity to new heights.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是基于变换器架构的LLM近年来受到了极大的关注。随着OpenAI的GPT3.5和GPT4等模型的出现，这种流行趋势得到了促进，相关特性分别由Chen等人[[3](#bib.bib3)]和Bubeck等人[[4](#bib.bib4)]讨论。OpenAI推出的ChatGPT[[5](#bib.bib5)]通过为更广泛的受众提供GPT的可访问性，为这一流行趋势做出了巨大贡献，将其受欢迎程度提升到了一个新的高度。
- en: For a while, only those who collaborated with OpenAI had the opportunity to
    actively participate in the development of GPT models and witness their remarkable
    successes. However, the landscape changed with the advent of GPT-like LLM counterparts
    such as Google T5 described in paper Raffel et al. [[6](#bib.bib6)] and Meta’s
    LLaMa introduced in [[7](#bib.bib7)], which offered alternative options that were
    not restricted to control of a single entity. Such models have gained widespread
    usage across various NLP applications, encompassing language generation, question-answering,
    sentiment analysis, and more.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间以来，只有与OpenAI合作的人才有机会积极参与GPT模型的开发，并见证其卓越的成功。然而，随着GPT类LLM模型的出现，形势发生了变化，如论文Raffel等人描述的Google
    T5[[6](#bib.bib6)]和Meta的LLaMa[[7](#bib.bib7)]，这些模型提供了不局限于单一实体控制的替代选项。这些模型在各种NLP应用中得到了广泛使用，包括语言生成、问答、情感分析等。
- en: Furthermore, the emergence of open LLMs, including Stanford Alpaca [[8](#bib.bib8)]
    model, has marked a turning point in LLM research. Work of E. J. Wang [[9](#bib.bib9)]
    offers a comprehensive resource for individuals seeking to fine-tune Alpaca 7B
    model using the identical methodology employed by Stanford University. It encompasses
    all the necessary components and instructions to facilitate the fine-tuning process.
    Unlike other LLMs, the Stanford Alpaca model not only became accessible to researchers
    worldwide LLM performing close to GPT3, but also possessed characteristics that
    enabled it to run even on average power personal computers. The model’s architecture
    allows for fine-tuning to perform instruction-following tasks, which opens up
    enormous possibilities for researchers in related technical fields. As time went
    on, other, better performing open LLMs with the possibility of additional training,
    such as Falcon7B[[10](#bib.bib10)], which we utilize in our work, began to appear.
    And lately the ranking of the best performing models [[1](#bib.bib1)] is updated
    every month presenting better and better models both for 7B scales such as LLaMa
    2 [[11](#bib.bib11)] and Mistral [[12](#bib.bib12)], as well as more impressive
    ones like Falcon180B [[13](#bib.bib13)]. Such models showcasing competitiveness
    with existing open-source chat models. The embodiment exhibit equivalent competency
    to certain proprietary models on evaluation sets examined, albeit trailing behind
    other advanced models like GPT-4.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，开源LLMs的出现，包括斯坦福大学的Alpaca[[8](#bib.bib8)]模型，标志着LLM研究的一个转折点。E. J. Wang的工作[[9](#bib.bib9)]为那些希望使用斯坦福大学采用的相同方法对Alpaca
    7B模型进行微调的个人提供了全面的资源。该资源涵盖了所有必要的组件和操作说明，旨在促进微调过程。与其他LLMs不同，斯坦福Alpaca模型不仅向全球研究人员开放，且其表现接近GPT-3，还具备能够在普通个人计算机上运行的特点。该模型的架构允许进行微调以执行指令跟随任务，这为相关技术领域的研究人员开辟了巨大的可能性。随着时间的推移，其他性能更好的开源LLMs陆续出现，并且具有进一步训练的可能性，例如我们在工作中使用的Falcon7B[[10](#bib.bib10)]。最近，最优性能模型的排名[[1](#bib.bib1)]每月更新，呈现出越来越出色的模型，不仅有像LLaMa
    2 [[11](#bib.bib11)]和Mistral [[12](#bib.bib12)]这样的7B规模模型，还有像Falcon180B[[13](#bib.bib13)]这样的更为强大的模型。这些模型展现了与现有开源聊天模型的竞争力。在评估集上，它们表现出与某些专有模型相当的能力，尽管在其他先进模型（如GPT-4）的面前稍显逊色。
- en: Another particularly fascinating research direction involves the integration
    of LLMs, such as GPT, for applications in robotics [[14](#bib.bib14)]. These models
    have demonstrated the ability to generate coherent and contextually appropriate
    text, making them well-suited for a wide range of natural NLP tasks. In particular,
    they possess the ability to break down complex natural language tasks into elementary
    sub-tasks that can be executed by a robot [[15](#bib.bib15), [16](#bib.bib16)].
    Furthermore, LLMs have been employed to develop human-robot interaction systems
    leveraging NLP techniques [[17](#bib.bib17), [18](#bib.bib18)]. Notably, the RT2
    model [[19](#bib.bib19)] has been introduced to tackle challenging manipulation
    tasks, while Tesla recently unveiled the Tesla Bot Optimus [[20](#bib.bib20)],
    a humanoid robot equipped with advanced manipulation skills. The fusion of sophisticated
    LLMs with robotic systems represents a promising avenue that holds the potential
    for facilitating more effective collaboration between humans and robots both in
    highly specialized areas and for everyday tasks [[21](#bib.bib21)].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个特别令人着迷的研究方向涉及将大型语言模型（LLMs），如GPT，集成应用于机器人技术[[14](#bib.bib14)]。这些模型已经展示了生成连贯且语境适当文本的能力，使其非常适合广泛的自然语言处理（NLP）任务。特别是，它们具备将复杂的自然语言任务分解成可以由机器人执行的基础子任务的能力[[15](#bib.bib15),
    [16](#bib.bib16)]。此外，LLMs还被应用于开发利用NLP技术的人机交互系统[[17](#bib.bib17), [18](#bib.bib18)]。值得注意的是，RT2模型[[19](#bib.bib19)]已被提出以应对复杂的操作任务，而特斯拉最近发布了特斯拉机器人Optimus[[20](#bib.bib20)]，一款配备先进操作技能的人形机器人。将先进的LLMs与机器人系统结合，代表了一个充满前景的方向，具有促进人类与机器人在高度专业化领域及日常任务中更有效合作的潜力[[21](#bib.bib21)]。
- en: However, only limited research has been conducted on the utilization of LLMs
    for generating robot behavior tree [[22](#bib.bib22), [23](#bib.bib23)]. Previously,
    various approaches such as finite state machines [[24](#bib.bib24), [25](#bib.bib25)],
    Petri nets [[26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29)],
    and BTs [[30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33),
    [34](#bib.bib34)] were commonly employed and still are being actively used to
    delineate the higher-level behavior of robots. Among these, BTs present an advanced
    means of specifying complex robot behavior [[35](#bib.bib35)]. Traditionally,
    the application of such methodologies necessitates the involvement of highly qualified
    specialists with expertise in the specified domains, thereby rendering implementation
    challenging. However, the utilization of LLMs for generating behavior trees could
    be a game changer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关于LLMs在生成机器人行为树中的应用，相关研究仍然有限[[22](#bib.bib22), [23](#bib.bib23)]。此前，各种方法如有限状态机[[24](#bib.bib24),
    [25](#bib.bib25)]、Petri网[[26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28),
    [29](#bib.bib29)]和行为树[[30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33),
    [34](#bib.bib34)]通常被应用并仍在积极使用，用以描述机器人更高层次的行为。在这些方法中，行为树提供了一种指定复杂机器人行为的先进方式[[35](#bib.bib35)]。传统上，应用这些方法通常需要领域专家的参与，因此实施起来具有一定挑战性。然而，利用LLMs生成行为树可能会成为一个颠覆性的变化。
- en: Leveraging natural language processing techniques, LLMs for robot behavior,
    on the other hand, hold the potential to significantly enhance the adaptability
    and flexibility of AI-powered robotic systems. Y. Cao et al.’s work [[22](#bib.bib22)]
    endeavored to create robot behavior through the utilization of LLM. The authors,
    however, employed an OpenAI product to populate BTs with behavior nodes. OpenAI
    products lack embodied experience in generating behavior trees, as they were not
    specifically trained for the purpose. Consequently, researchers imposed a limitation
    by fixing the behavior tree structure, restricting the use to sequence and action
    nodes only. While this approach imposes constraints on the modular structure advantages
    of BTs, the outcomes remain promising. Nevertheless, fine-tuning the LLM specifically
    for the task at hand usually yields much better results. This approach is anticipated
    to produce diverse BTs without any constraints on their structure.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，利用自然语言处理技术，LLMs在机器人行为方面具有显著提高AI驱动机器人系统适应性和灵活性的潜力。Y. Cao等人的工作[[22](#bib.bib22)]尝试通过使用LLM来创建机器人行为。然而，作者们使用了OpenAI的产品来填充行为树（BTs）中的行为节点。由于OpenAI产品没有经过专门的训练来生成行为树，它们缺乏具身经验。因此，研究人员通过固定行为树结构来加以限制，仅使用序列和动作节点。尽管这种方法限制了行为树模块化结构的优势，但结果仍然是有希望的。然而，专门针对任务对LLM进行微调通常能取得更好的效果。预计这种方法能够生成多样化的行为树，并且不会对其结构进行任何限制。
- en: Furthermore, several laboratories and industries with access to LLMs have been
    diligent in developing a methodology for building robot behavior that use, once
    again, GPT or its counterparts. One such work by Driess et al. [[36](#bib.bib36)]
    focuses on the development of PaLM-E, an embodied multimodal language model that
    makes a robot to follow human instructions in natural language while analyzing
    its environment. Another work by Brohan et al. [[37](#bib.bib37)] presents a robotics
    transformer for real-world control at scale. Both of them are large models that
    require significant computational resources and training data. Beyond that, Boston
    Dynamics has also been exploring the potential of GPT for building robot behavior.
    They have successfully trained a robot dog Spot to provide operational reports
    to generate responses to inquiries, analyzing the surroundings [[38](#bib.bib38)].
    However, it is employed only for vocal communication and navigation within the
    building without interactions with physical objects.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些能够使用大型语言模型（LLMs）的实验室和工业界在开发机器人行为构建方法论方面非常勤奋，再次使用GPT或其对应模型。其中一项由Driess等人[[36](#bib.bib36)]完成的工作，聚焦于PaLM-E的开发，这是一种具身的多模态语言模型，使机器人能够在分析其环境的同时，按照人类的自然语言指令行动。另一个由Brohan等人[[37](#bib.bib37)]完成的工作，提出了一种用于大规模现实世界控制的机器人变压器。这两者都是需要大量计算资源和训练数据的大型模型。除此之外，波士顿动力公司也在探索GPT在构建机器人行为方面的潜力。他们成功地训练了机器狗Spot，使其能够提供操作报告并生成回应查询的答案，分析周围环境[[38](#bib.bib38)]。然而，它仅用于建筑内的语音通信和导航，且不与物理物体进行交互。
- en: Nevertheless, the generation of a diverse and extensive dataset with various
    BTs for robots of different structures and applications is necessary for fine-tuning
    LLM to achieve generation of complex BTs. While the approach of using Reinforcement
    Learning of from Human Feedback (RLHF) for LLM, as discussed by Stiennon et al.
    [[40](#bib.bib40)], is widely acknowledged, generating a substantial dataset would
    necessitate employing specialists who possess expertise in constructing BT. This,
    in turn, renders the task highly challenging. In our study, we enhance the methodology
    introduced by Y. Wang et al. [[41](#bib.bib41)] as employed in the research conducted
    by Taori et al. [[8](#bib.bib8)]. This approach involves the utilization of a
    text-davinci-003 model employing a self-instruct style to generate a dataset.
    The resultant model exhibits superior performance in certain tasks compared to
    the model responsible for dataset generation, owing to its fine-tuning tailored
    for these specific challenges.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，生成包含各种行为树（BT）的大型数据集以适应不同结构和应用的机器人，是对LLM进行微调以生成复杂行为树所必需的。尽管使用来自人类反馈的强化学习（RLHF）方法对LLM进行训练，如Stiennon等人所讨论的[[40](#bib.bib40)]，这一方法已被广泛认可，但生成一个庞大的数据集需要聘请具有构建行为树专长的专家，这使得任务变得非常具有挑战性。在我们的研究中，我们改进了Y.
    Wang等人[[41](#bib.bib41)]在Taori等人[[8](#bib.bib8)]研究中采用的方法。该方法利用text-davinci-003模型，通过自我指令风格生成数据集。生成的模型在某些任务上的表现优于生成数据集的模型，这得益于它经过针对这些特定挑战的微调。  '
- en: The integration of LLMs and other transformer-based models in the field of robotics
    holds significant promise for improving human-robot interaction. The utilization
    of transformer-based LLMs enables remarkable advancements in addressing a wide
    range of tasks, including the comprehension of natural language commands and the
    decomposition of complex tasks into manageable subtasks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '在机器人学领域，LLM和其他基于变换器的模型的结合对于改善人机交互具有重要的前景。利用基于变换器的LLM能够显著推动解决广泛任务的进展，包括理解自然语言命令和将复杂任务分解为可管理的子任务。  '
- en: III Advantages of Behavior Trees Approach
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'III 行为树方法的优势  '
- en: III-A Advantages of Using Behavior Trees in Robotics
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'III-A 行为树在机器人学中的优势  '
- en: BT is a hierarchical structure used to represent robot tasks at an abstract
    level, offering an alternative to the state machine paradigm. BT as an approach
    to constructing robot behavior is discussed by Colledanchise and Ögren [[31](#bib.bib31)].
    Formally, a BT is a directed rooted tree with leaf nodes responsible for task
    execution and branch nodes defining the control-flow logic. The leaf nodes are
    either Action or Condition nodes. The former specifies a primitive task and returns
    a Success signal when the task is completed. The latter is used to evaluate a
    Boolean condition, such as the satisfaction of a specific sensor reading. The
    most commonly used branch nodes are the Sequence and Fallback nodes. The Sequence
    node executes its child nodes sequentially until the first Failure signal is received.
    The Fallback node, on the other hand, executes its child nodes sequentially until
    the first Success signal is received. Using these four node types, a BT can achieve
    the same task execution as a state machine. But it has a lot of advantages, as
    modular structure allows to add, remove and replace nodes without having to reconstruct
    all structure.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 行为树（BT）是一种层次化结构，用于在抽象层次表示机器人任务，为状态机范式提供了一种替代方案。Colledanchise和Ögren[[31](#bib.bib31)]讨论了作为构建机器人行为的一种方法的行为树。形式上，行为树是一个有向根树，叶节点负责任务执行，分支节点定义控制流逻辑。叶节点可以是动作节点或条件节点。动作节点指定一个原始任务，任务完成时返回成功信号；条件节点用于评估布尔条件，例如特定传感器读数的满足情况。最常用的分支节点是顺序节点和回退节点。顺序节点按顺序执行其子节点，直到收到第一个失败信号；回退节点则按顺序执行其子节点，直到收到第一个成功信号。通过这四种节点类型，行为树可以实现与状态机相同的任务执行。但它有许多优势，因为模块化结构使得可以在不重建整个结构的情况下添加、移除或替换节点。
- en: BTs have become a widely used approach in robotics due to their intuitive and
    efficient control of robotic systems. They provide a structured way to represent
    and control the behavior of autonomous agents, making them well-suited for a wide
    range of robotic applications. They has been successfully applied in many robotics
    competitions and challenges, including the DARPA Robotics Challenge, RoboCup,
    and Eurobot. For example, in the DARPA Robotics Challenge, teams used BT to control
    their robots in tasks such as driving a car, opening doors, and using power tools,
    which was considered in the paper of Colledanchise and Ögren [[42](#bib.bib42)].
    In RoboCup, BT was used to control multi-robot systems in tasks such as soccer
    playing and search and rescue scenarios discussed by Safronov et al. [[34](#bib.bib34)].
    In Eurobot, it was used to control autonomous robots in tasks such as navigating
    a maze and manipulating objects considered in the paper of Granosik, et al. [[43](#bib.bib43)].
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 行为树（BT）因其直观和高效的机器人系统控制而成为机器人学中广泛使用的方法。它们提供了一种结构化的方式来表示和控制自主智能体的行为，使其非常适用于各种机器人应用。行为树已成功应用于许多机器人竞赛和挑战中，包括达尔帕机器人挑战赛（DARPA
    Robotics Challenge）、机器人世界杯（RoboCup）和欧洲机器人（Eurobot）。例如，在达尔帕机器人挑战赛中，团队使用行为树控制他们的机器人完成任务，如驾驶汽车、开门和使用电动工具，这些内容在Colledanchise和Ögren的论文中有所讨论[[42](#bib.bib42)]。在机器人世界杯中，行为树被用于控制多机器人系统完成诸如踢足球和搜救等任务，这些任务在Safronov等人的论文中有所探讨[[34](#bib.bib34)]。在欧洲机器人比赛中，行为树被用来控制自主机器人执行任务，如迷宫导航和物体操作，这些内容在Granosik等人的论文中讨论过[[43](#bib.bib43)]。
- en: III-B Advantages of Using Behavior Trees as Output of LLM
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 使用行为树作为大型语言模型输出的优势
- en: BTs, a hierarchical and modular structure, offer a promising solution for the
    development of transformer-based LLM. The structure enables the replacement of
    nodes with identical types. Ability to replace tokens make the structure well-suited
    for use as an output of the transformer. Additionally, the modularity and scalability
    of the BT structure allow for the easy addition of new nodes or modification of
    existing ones.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 行为树（BT），作为一种层级化和模块化的结构，为基于变换器的大型语言模型（LLM）的开发提供了有前景的解决方案。该结构支持用相同类型的节点进行替换。替换令牌的能力使得这一结构非常适合作为变换器输出。此外，行为树结构的模块化和可扩展性使得可以轻松添加新节点或修改现有节点。
- en: Another compelling feature of the BT structure is its option to use a subtree
    as part of a main tree. This means that generated BTs can be added to the node
    library and used as a part of more complex behavior. By operating in recursive
    mode, the model can build the BT first at the top level of abstraction and then
    descend to a lower level of abstraction, generating missing nodes from simpler
    components. This method allows for the creation of large and complex behavior
    structures while remaining within token length limitations in the model output.
    This approach positively impacts the model’s performance and removes the limitations
    on the final size of the BT.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 行为树结构的另一个重要特点是可以选择将子树作为主树的一部分。这意味着生成的行为树可以添加到节点库中，并作为更复杂行为的一部分使用。通过递归模式，模型可以首先在最高抽象层构建行为树，然后下降到较低的抽象层，从简单组件生成缺失的节点。这种方法使得在模型输出的令牌长度限制内创建大型和复杂的行为结构成为可能，同时提高了模型的性能，消除了对最终行为树大小的限制。
- en: IV Multimodal LLM to Multiagent Robot Control
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 多模态大型语言模型用于多智能体机器人控制
- en: Current applications of LLM in robotics become strategically advantageous when
    addressing intricate sequences of actions with LLM-based decision making. These
    applications of LLMs lack significance when dealing with complicated systems where
    robots engaged in repetitive and monotonous tasks. As a long-term goal, we praise
    the creation of a universal AI-driven multi-agent robot system capable of understanding
    the goals of the task and solve it using existent agents.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，LLM 在机器人学中的应用，在处理复杂的动作序列和基于LLM的决策时，具有战略性优势。然而，在应对机器人执行重复和单调任务的复杂系统时，这些LLM的应用则缺乏意义。作为长期目标，我们赞扬创建一个通用的人工智能驱动的多智能体机器人系统，能够理解任务目标并利用现有智能体来解决问题。
- en: Our approach differs significantly from traditional methods. We propose a solution
    in which a Language Model-Based Artificial Intelligence system takes control of
    an entire multi-agent system by generating behavior trees for these agents. Our
    system enables user interaction and control of robotic agents through dialogue.
    It comprises robotic agents and a multimodal LLM engaged in task discussions,
    command reception, and query responses. The LLM constructs BTs tailored for distinct
    agent types, thus facilitating the collaborative execution of intricate tasks.
    Agents autonomously execute these generated BTs and periodically update the system
    with information regarding their environment and current results. This BT generation
    approach, developed within our ISR Lab, provides a unique advantage in robot control.
    The system’s ability to work seamlessly with different numbers and types of robots
    renders it highly scalable. In contrast to conventional methods that rely on a
    LLM solely to generate responses to external changes, our approach focuses on
    the generation of complex robot behaviors that consider a wide range of possible
    scenario evolutions. By creating a BT once, it inherently encompasses checks for
    multiple conditions and instructions on how to respond to them. This approach
    significantly reduces the number of requests to the LLM, effectively employing
    a single “brain” and enhancing resource efficiency.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法与传统方法有显著的不同。我们提出了一种解决方案，通过基于语言模型的人工智能系统控制整个多智能体系统，并为这些智能体生成行为树。我们的系统通过对话使用户能够与机器人智能体互动并进行控制。它包括机器人智能体和一个多模态大语言模型（LLM），该模型参与任务讨论、指令接收和查询响应。LLM为不同类型的智能体构建行为树，从而促进复杂任务的协作执行。智能体自主执行这些生成的行为树，并定期更新系统，提供有关其环境和当前结果的信息。这种行为树生成方法是在我们的ISR实验室内开发的，在机器人控制方面具有独特的优势。系统能够与不同数量和类型的机器人无缝协作，使其具有高度的可扩展性。与传统方法仅依赖大语言模型生成响应外部变化不同，我们的方法侧重于生成考虑多种可能场景演变的复杂机器人行为。通过一次创建行为树，它本身就涵盖了多个条件检查和响应指令。这种方法显著减少了对大语言模型的请求次数，有效地利用单一的“大脑”，从而提升了资源效率。
- en: In practical scenarios, a multi-agent approach is often essential. In the field
    of robotics, individual machines perform straightforward tasks within their predefined
    behavior boundaries, while the collective system addresses intricate challenges.
    This phenomenon is readily observable in warehouse robotics, where robots carry
    out basic actions but collaborate to manage complex logistical demands. Similarly,
    in scientific drone exploration, each drone adheres to a simple plan, yet their
    collective endeavors result in detailed maps of remote terrains. Urban delivery
    robots excel in their individual roles of cargo transport, but the system’s complexity
    lies in coordinating city-wide goods delivery. In facility inspection using multi-agent
    systems, robots follow predefined behaviors, while a centralized system ensures
    comprehensive coverage of the entire enterprise. Even in manufacturing, where
    individual robot tasks may involve repetitive manipulations, the entire conveyor
    system efficiently manufactures technological products. Hence, this is the typical
    scenario, with numerous robots contributing their simple components to a broader
    task. Consequently, providing each of these robots with its independent AI is
    an overly ambitious undertaking.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，多智能体方法往往是至关重要的。在机器人领域，单个机器执行预定义行为边界内的简单任务，而集体系统则解决复杂的挑战。这一现象在仓库机器人中非常明显，机器人执行基本的动作，但通过协作来应对复杂的物流需求。同样，在科学无人机探索中，每架无人机遵循简单的计划，但它们的集体努力产生了详细的遥远地形地图。城市配送机器人在货物运输中的个人角色表现出色，但系统的复杂性体现在协调全市范围内的货物配送。在使用多智能体系统进行设施检查时，机器人遵循预定义的行为，而一个集中系统确保全面覆盖整个企业。即使在制造业中，单个机器人的任务可能涉及重复的操作，但整个传送带系统能够高效地制造技术产品。因此，这种情况是典型的，许多机器人通过贡献简单的组成部分来完成更广泛的任务。因此，给每个机器人配备独立的人工智能是一个过于雄心勃勃的任务。
- en: While existing examples of multi-agent systems are already in active use, their
    high-level control typically relies on a group of human operators or predefined
    programs tailored to specific tasks. Consequently, any task modification necessitates
    a team of experts and a significant amount of time to reconfigure the entire system.
    The crux of our proposed method is to delegate this high-level control to artificial
    intelligence. Our approach allows the rapid reorganization of the system to accommodate
    new tasks. To achieve this, it is only necessary to instruct the LLM-based AI
    manager about the tasks to be performed, which it will then execute using the
    available agents.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然现有的多智能体系统已经在积极使用，但它们的高级控制通常依赖于一组人工操作员或预定义的程序，这些程序是针对特定任务量身定制的。因此，任何任务修改都需要一支专家团队和大量时间来重新配置整个系统。我们提出方法的关键是将这种高级控制委托给人工智能。我们的方法使得系统能够快速重组以适应新任务。为此，只需指示基于LLM的AI管理器要执行的任务，它将使用现有的智能体来执行。
- en: IV-A Multimodal LLM to Control Eurobot Robots
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 多模态LLM控制Eurobot机器人
- en: For prototyping the system within the laboratory, we turned to another task
    that has all the necessary qualities to realize the technology. Eurobot serves
    as an appropriate testbed for implementing LLM in a robot. Eurobot is an esteemed
    international robotics competition that provides a perfect platform for testing
    and evaluating robotic capabilities. The competition uses a multi-agent system
    of robots that can autonomously perform a given behavior. There are clear rules
    of the game and the criterion of victory, which is the goal of the system, but
    the changing conditions of the playing field generate thousands of scenarios.
    The competition challenges participants to design and operate autonomous robots
    that demonstrate reliability and responsiveness to adversary actions. In 2023
    year, robots were tasked with collecting and sorting colored object sets known
    as ’cakes’ and tallying spherical objects called ’cherries’. These objects then
    had to be transported and placed accurately within designated areas on the competition
    field. Thus, our robots, Black Samurai and Orange Shogan, were chosen as pioneers
    for LLM integration. Introducing LLM into a robot with initially designed High
    Level, Low Level, and Mechanics for different purposes poses a formidable challenge.
    The fact that the robots were initially created with support for strategies in
    the form of Behavior Trees assisted us in this endeavor. The objective was to
    launch a multimodal model in a manner that allows human interaction, while the
    generated BTs functioned seamlessly, just like those manually scripted before.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在实验室内原型化该系统，我们转向了另一个具有实现该技术所需所有特性的任务。Eurobot作为一个合适的测试平台，用于在机器人中实现LLM。Eurobot是一个备受尊敬的国际机器人竞赛，提供了一个完美的平台来测试和评估机器人能力。该竞赛使用一个多智能体系统的机器人，这些机器人能够自主执行指定的行为。竞赛规则明确，胜利标准是系统的目标，但比赛场地的变化条件会产生成千上万种场景。竞赛挑战参与者设计并操作能够表现出可靠性和响应能力的自主机器人，以应对对手的行动。在2023年，机器人的任务是收集和分类一组被称为“蛋糕”的彩色物体，并统计被称为“樱桃”的球形物体。这些物体随后需要被运输并准确放置在比赛场地上指定的区域。因此，我们的机器人“黑武士”和“橙将军”被选为LLM集成的先锋。将LLM引入一个最初设计了不同目的的高级、低级和机械模块的机器人中，面临着巨大的挑战。机器人最初就支持行为树策略，这在我们这个过程中提供了帮助。我们的目标是以一种允许人类互动的方式启动一个多模态模型，同时生成的行为树能够无缝运行，就像之前手动编写的一样。
- en: The hardware of our robot did not include components capable of supporting the
    autonomous execution of LLM with its 7 billion parameters. LLM was launched on
    a remote server accessible through SSH requests from the robot. To facilitate
    remote LLM execution, a server with Intel Broadwell featuring NVIDIA Tesla V100
    hardware was leased. Natural language queries were sent to the server, and responses
    and strategies were sent back to the robot. Thus the whole system consisting of
    a multi-agent robotics system and a multimodal LLM was put together.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们机器人硬件的配置并不包括能够支持7亿参数LLM自主执行的组件。LLM在一个通过SSH请求从机器人访问的远程服务器上启动。为了便于远程执行LLM，我们租用了一个配备英特尔Broadwell和NVIDIA
    Tesla V100硬件的服务器。自然语言查询被发送到服务器，服务器的响应和策略会返回到机器人。因此，整个由多智能体机器人系统和多模态LLM组成的系统被组建起来。
- en: V System Overview
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 系统概述
- en: In this section, we present an intricate analysis encompassing both the software
    and hardware aspects of the robotic system used for integration of the multi-modal
    LLM.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将对用于集成多模态大语言模型（LLM）的机器人系统进行详细分析，涵盖软件和硬件两个方面。
- en: Through a meticulous exposition of the interplay between all robotic components
    and software parts, this section serves as a comprehensive guide towards not only
    understanding the intricacies of our achievements but also as a practical guide
    to facilitating autonomous replication of our results within the realm of creating
    a LLM-driven Multi-agent Robotic system.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通过详细阐述所有机器人组件与软件部分之间的相互作用，本节不仅为理解我们的成就的复杂性提供了全面的指导，还为在创建基于LLM驱动的多智能体机器人系统的领域中，促进自主复制我们的成果提供了实际指南。
- en: V-A Mechanical Construction Overview
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 机械结构概述
- en: '![Refer to caption](img/005ee4c46d95590a30f818b696696d0d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/005ee4c46d95590a30f818b696696d0d.png)'
- en: (a)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: (a)
- en: '![Refer to caption](img/957e0a7896b8179425e4dd05094c6fd6.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/957e0a7896b8179425e4dd05094c6fd6.png)'
- en: (b)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: (b)
- en: 'Figure 2: 3D CAD models of the robots. (a) Isometric view. (b) Straddling view
    of the frame and grippers.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：机器人的3D CAD模型。(a)等轴测图。(b)框架和抓取器的跨视图。
- en: 'The robots (Fig. [2](#S5.F2 "Figure 2 ‣ V-A Mechanical Construction Overview
    ‣ V System Overview ‣ LLM-MARS: Large Language Model for Behavior Tree Generation
    and NLP-enhanced Dialogue in Multi-Agent Robot Systems")) are specifically crafted
    to adhere to the regulations of the Eurobot competition. The steel frame attaches
    the essential elements of each robot, which moves on a platform featuring omni-wheels
    and a suspension system. Within the mechanical structure, key components include
    grippers, a sorting mechanism, a cherry dispenser, and a cherry collection mechanism.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些机器人（图 [2](#S5.F2 "图 2 ‣ V-A 机械结构概述 ‣ V 系统概述 ‣ LLM-MARS：用于行为树生成和自然语言处理增强对话的多智能体机器人系统中的大语言模型")）专门设计以符合Eurobot竞赛的规则。钢架将每个机器人必需的部件固定在一起，机器人在一个具有全向轮和悬挂系统的平台上移动。在机械结构中，关键组件包括抓取器、分拣机构、樱桃分配器和樱桃收集机制。
- en: 'Each of the three grippers are divided into a lower part (1a) for gripping
    the bottom cake layer and an upper part (1b) for gripping the two upper cake layers.
    All sections of the gripper are controlled by a servomotor and attached to the
    outer gears of a sorting mechanism. The sorting mechanism consists of lifting
    and rotating parts and is raised and lowered on a central rod (2a) by a motor
    through a belt. The rotating part comprises two parts, resembling a planetary
    gear system, with one input gear rotating the outer gear (2b) using a motor. The
    cherry dispenser is composed of a special tube and a dedicated flap controlled
    by a servomotor. The actuation of the flap facilitates the controlled release
    of cherries onto the cake. The cherry collection mechanism comprises distinct
    elements: a specially shaped movable tube (4a) regulated by two servomotors; two
    impellers (4b) designed for the suction of cherries from a designated section
    (4c) within the robot and subsequently expel them into a specialized receptacle;
    and outer and inner flaps (4d) under the control of servomotors.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 三个抓取器的每一个都分为下部（1a），用于抓取底部蛋糕层，以及上部（1b），用于抓取上面两层蛋糕。抓取器的所有部分都由伺服电机控制，并附着在分拣机制的外齿轮上。分拣机制包括升降和旋转部件，通过电机通过皮带将其升降在一个中央杆（2a）上。旋转部分由两部分组成，类似于行星齿轮系统，其中一个输入齿轮通过电机旋转外齿轮（2b）。樱桃分配器由一个特殊管道和一个由伺服电机控制的专用挡板组成。挡板的动作可以控制樱桃的释放，将其精确地放置到蛋糕上。樱桃收集机制包括几个独立的部分：一个特别形状的可动管（4a），由两个伺服电机调节；两个叶轮（4b），用于从机器人指定区域（4c）吸取樱桃，并将其排放到专用容器中；以及由伺服电机控制的外部和内部挡板（4d）。
- en: V-B Embedded Systems Overview
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 嵌入式系统概述
- en: Robotic electronics serve as a crucial intermediary, facilitating seamless interaction
    between the high-level computer and the set of onboard devices, including the
    omni-wheel platform, actuators, switches, and sensors. Its paramount function
    extends to providing the high-level side with abstraction layers and interfaces,
    thereby streamlining the overall interaction process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人电子系统作为关键中介，促进了高层计算机与一系列车载设备之间的无缝互动，这些设备包括全向轮平台、执行器、开关和传感器。其主要功能是为高层系统提供抽象层和接口，从而简化了整体互动过程。
- en: 'Essential time-critical operations and low-level control algorithms are housed
    within the electronic components, further solidifying its role in the system.
    Additionally, the electronics adeptly oversees the management of the onboard battery,
    ensuring its safe and optimal functioning, while effectively distributing power
    to all pertinent robot components. An illustrative representation of the electronics’
    structure is presented on Fig. [3](#S5.F3 "Figure 3 ‣ V-B Embedded Systems Overview
    ‣ V System Overview ‣ LLM-MARS: Large Language Model for Behavior Tree Generation
    and NLP-enhanced Dialogue in Multi-Agent Robot Systems").'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的时间敏感操作和低级控制算法被集成在电子组件中，进一步巩固了其在系统中的作用。此外，电子系统熟练地管理着机载电池，确保其安全和最佳运行，同时有效地向所有相关的机器人组件分配电力。电子系统结构的示意图如图[3](#S5.F3
    "图3 ‣ V-B 嵌入式系统概述 ‣ V 系统概述 ‣ LLM-MARS：用于行为树生成和多智能体机器人系统中NLP增强对话的大型语言模型")所示。
- en: '![Refer to caption](img/dc480e887ed3202a1974831dfd23ce7d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明文字](img/dc480e887ed3202a1974831dfd23ce7d.png)'
- en: 'Figure 3: Block diagram of the robot electronics.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：机器人电子系统的框图。
- en: At the heart of the robot electronics lies the main control board, centered
    around the STM32F407VG Microcontroller Unit (MCU). This pivotal board draws power
    from both the +5V and +12V power lines, while the remaining electronic entities
    are deemed downstream and subservient, operating under the firm control and connection
    of this central board. Furthermore, the high-level computer serves as the upstream
    side, establishing connectivity to the main control board via a USB cable.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人电子系统的核心是主控制板，围绕STM32F407VG微控制单元（MCU）构建。这个关键的板子同时从+5V和+12V电源线路获取电力，而其他电子组件被视为下游的从属部分，依赖于这个中央控制板的严格控制和连接。此外，高级计算机作为上游，通过USB电缆与主控制板建立连接。
- en: V-C High-Level Systems Overview
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 高级系统概述
- en: The high-level system is designed to manage data acquired directly from sensors
    such as LIDAR and cameras, as well as from the embedded system, particularly wheel
    encoders. Furthermore, it facilitates interaction with robot actuators through
    various commands, empowering developers to devise sophisticated strategies. To
    fulfill these requirements, the system is built upon the ROS2 Humble framework
    [[44](#bib.bib44)], which runs on an Intel NUC computer installed with Ubuntu
    22.04\. The computer communicates with STM32 via USART interface. Therefore, this
    module receives commands and sends responses through ROS topics and performs serialization
    or deserialization to match the USART data exchange format. Besides that, the
    module publishes wheel odometry to ROS topics with frequency of 40 Hz.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 高级系统旨在管理直接从传感器（如激光雷达和摄像头）以及嵌入式系统，特别是车轮编码器，获取的数据。此外，它通过各种命令与机器人执行器进行交互，使开发人员能够设计复杂的策略。为满足这些需求，系统基于ROS2
    Humble框架[[44](#bib.bib44)]构建，运行在安装了Ubuntu 22.04的Intel NUC计算机上。计算机通过USART接口与STM32进行通信。因此，该模块通过ROS主题接收命令并发送响应，并执行序列化或反序列化以匹配USART数据交换格式。除此之外，该模块以40Hz的频率将车轮里程信息发布到ROS主题中。
- en: 'The localization module is important in accurately determining a robot’s position
    within a playing field. We employed a particle filter (PF) methodology [[45](#bib.bib45)],
    integrating data from wheel encoders, LiDAR, and the computer vision (CV) system.
    Initially, the module computes odometry measurements from individual sensor data,
    referencing the robot’s previous pose. For the extraction of LiDAR-based odometry,
    we incorporated a laser scan matcher module, which operates on the principles
    of the Canonical Scan Matcher [[46](#bib.bib46)]. These odometry measurements
    are pivotal during the “predict” phase of the particle filter. It is worth noting
    that each sensor possesses a weighted value, determining the proportion of particles
    influenced by their respective measurements. The raw LiDAR point cloud serves
    as the primary source for landmark detection. These landmarks are situated at
    the vertices of a triangle beyond the edges of the playing field and are characterized
    by cylindrical shapes encased in retroreflective material. The detection procedure
    combines a sequence of operations: filtering points based on light intensity return,
    outlier removal, and landmark center identification via optimization techniques.
    Subsequently, data association is executed, correlating the detected centers with
    the global positions of the landmarks. Concluding the process, the pinpointed
    landmark centers become crucial during the “update” phase of the PF. This facilitates
    the synthesis of measurements, resulting in a refined and filtered pose determination
    for the robot.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本地化模块在精确确定机器人在赛场中的位置方面至关重要。我们采用了粒子滤波（PF）方法[[45](#bib.bib45)]，整合了轮编码器、激光雷达（LiDAR）和计算机视觉（CV）系统的数据。最初，模块通过个别传感器数据计算里程测量，参考机器人的先前姿态。为了提取基于激光雷达的里程，我们引入了激光扫描匹配模块，该模块基于经典扫描匹配器（Canonical
    Scan Matcher）原理[[46](#bib.bib46)]。这些里程测量在粒子滤波的“预测”阶段起着关键作用。值得注意的是，每个传感器都有一个加权值，决定了相应测量影响的粒子比例。原始激光雷达点云作为地标检测的主要来源。这些地标位于赛场边缘外的一个三角形的顶点，并具有包裹在反射材料中的圆柱形状。检测过程结合了一系列操作：根据光强返回值滤波点，去除离群点，并通过优化技术识别地标中心。随后，执行数据关联，将检测到的中心与地标的全局位置进行关联。在过程的最后，确定的地标中心在粒子滤波的“更新”阶段变得至关重要。这有助于合成测量，从而为机器人提供精确和过滤后的姿态确定。
- en: 'The CV system is designed to perform two main functions: game object detection
    and robot localization. The system consists of a Jetson Xavier AGX microcomputer
    and an Imagine Source DFK 33UX250 Global Shutter camera equipped with a Computar
    fisheye lens. The camera is mounted on a tower-type tracking device and has an
    overhead view of the playground. The first aspect of the system involves accurate
    detection and identification of game objects, specifically cakes. This is achieved
    using the Hough algorithm [[47](#bib.bib47)] for circle finding, effectively tracking
    all cakes on the field. Additionally, the system can determine the color and number
    of layers of each detected cake. The second functionality excels in precisely
    localizing robots on the field. Robots are equipped with cubes containing AruCo
    markers on their faces, which are designed to be visible from any angle, ensuring
    reliable detection even under varying perspectives. Using a single AruCo marker,
    the system accurately localizes the robot in three-dimensional space. This feature
    is particularly valuable in dynamic scenarios involving multiple robots, where
    LiDAR localization may not provide accurate data. The CV system utilizes the OpenCV
    python library [[48](#bib.bib48)] for the detection and recognition of AruCo markers.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉系统设计了两个主要功能：游戏物体检测和机器人定位。该系统由一台Jetson Xavier AGX微型计算机和一台配备Computar鱼眼镜头的Imagine
    Source DFK 33UX250全局快门摄像机组成。摄像机安装在一个塔式跟踪设备上，俯瞰整个赛场。系统的第一个功能是准确检测和识别游戏物体，特别是蛋糕。该功能使用霍夫算法[[47](#bib.bib47)]进行圆形查找，有效跟踪赛场上的所有蛋糕。此外，系统还能确定每个检测到的蛋糕的颜色和层数。第二个功能擅长精确地定位赛场上的机器人。机器人配备了带有AruCo标记的立方体，这些标记可以从任何角度看到，确保即使在不同视角下也能可靠检测。通过单个AruCo标记，系统可以精确地在三维空间中定位机器人。这个特性在涉及多个机器人的动态场景中尤为重要，因为激光雷达定位可能无法提供准确数据。计算机视觉系统使用OpenCV
    Python库[[48](#bib.bib48)]进行AruCo标记的检测和识别。
- en: 'Navigation module is responsible for creating an environment map, generating
    safe trajectories for robots and controlling their velocities. Initially, the
    module consistently acquires refreshed coordinates of robots, encompassing those
    of opponents, as well as game objects, from the localization and computer vision
    (CV) modules. This data is used to generate an environment map. It is structured
    as a grid consisting of 1x1 cm cells, with each cell assigned values of 0 (indicating
    not occupied) or 1 (indicating occupied). Full map is made by adding occupied
    circles with a certain radius on a static map, which consists of field borders
    and fixed cherry holders. Subsequently, the module receives a target point from
    the BT module and formulates a secure and concise path from the current position
    to the target by employing the RRT* algorithm [[49](#bib.bib49)]. During each
    iteration of progressing towards the goal, the module examines whether opponent
    robots obstruct the established path. In the event of such obstruction, the module
    generates a new path from the current position. If the target proves unreachable,
    a stop command is issued along with feedback to the BT module.Ultimately, once
    the path is established, the module generates a smooth velocity profile using
    the minimum jerk algorithm [[50](#bib.bib50)] and sends velocities commands to
    STM32\. Velocities are limited according to a minimum distance to other robots
    to avoid collisions with them. To hold on a path two PID regulators are used:
    one for trajectory and one for angle.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 导航模块负责创建环境地图、为机器人生成安全的轨迹并控制其速度。最初，该模块持续从定位和计算机视觉（CV）模块获取机器人的更新坐标，包括对手的坐标以及游戏对象的坐标。这些数据用于生成环境地图。地图被结构化为一个由1x1厘米单元格组成的网格，每个单元格被赋予0（表示未占用）或1（表示已占用）的值。完整的地图通过在静态地图上添加具有一定半径的占用圆圈来构建，静态地图包括场地边界和固定的樱桃支架。随后，该模块从行为树（BT）模块接收目标点，并通过采用RRT*算法[[49](#bib.bib49)]制定一条从当前位置到目标的安全简洁路径。在每次向目标推进的迭代过程中，该模块检查是否有对手机器人阻碍了已建立的路径。如果发生阻碍，模块将从当前位置生成一条新路径。如果目标无法到达，系统将发出停止命令并向BT模块反馈。最终，一旦路径确定，模块使用最小抖动算法[[50](#bib.bib50)]生成平滑的速度曲线，并向STM32发送速度命令。速度限制根据与其他机器人的最小距离进行调整，以避免碰撞。为了保持在路径上，使用了两个PID调节器：一个用于轨迹，一个用于角度。
- en: BT module provides interface to create human-readable strategies for robots.
    For this purpose behavior-tree-cpp-v3 library [[51](#bib.bib51)] is used. Each
    command for actuators is wrapped into a certain action with input and output ports.
    Additionally, helpful conditions are provided, such as “If-Then-Else” or bounds
    for execution time for an action. Strategies are written as xml-files.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: BT模块提供了一个接口，用于为机器人创建人类可读的策略。为此，使用了behavior-tree-cpp-v3库[[51](#bib.bib51)]。每个对执行器的命令都封装成一个具有输入和输出端口的特定动作。此外，还提供了有用的条件，例如“如果-则-否则”或执行时间的界限。策略以xml文件的形式编写。
- en: VI LLM Training Methods and Recipes
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI LLM训练方法与策略
- en: The primary objective of our research was to train a model capable of constructing
    BTs for robots in multi-agent system based on natural language commands from operators.
    To achieve this, we fine-tuned the Falcon model containing 7 billion parameters
    using the Low-Rank Adaptation PEFT method [[52](#bib.bib52)] on a dataset generated
    with the text-davinci-003 model. The PEFT methods allows efficiently and productively
    fine-tune the LLM without having to retrain the entire model, as discussed by
    G. Pu et al. [[53](#bib.bib53)]. PEFT methods are particularly useful when tuning
    LLMs is too computationally expensive. Instead of tuning all the model’s parameters,
    PEFT methods adjust only a small number of additional parameters, thus significantly
    reducing computational and storage costs. The PEFT method we employed to fine-tune
    the LLM, is the Low-Rank Adaptation (LoRA) method, which adds low-rank matrices
    to transformer layers and adjusts only those matrices instead of the entire model.
    The application of the LoRA method to the LLM is described by E. J. Hu et al.
    [[52](#bib.bib52)]. The aforementioned Falcon 7B was selected for our study because
    it demonstrated superior performance in terms of open model rating [[1](#bib.bib1)]
    at the time of system development.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的主要目标是训练一个能够基于操作员的自然语言指令，为多智能体系统中的机器人构建行为树（BTs）的模型。为实现这一目标，我们使用低秩适应PEFT方法[[52](#bib.bib52)]对包含70亿参数的Falcon模型进行微调，数据集由text-davinci-003模型生成。PEFT方法使得在不需要重新训练整个模型的情况下，能够高效且富有成效地微调大语言模型（LLM），正如G.
    Pu等人所讨论的[[53](#bib.bib53)]。当微调LLM的计算成本过高时，PEFT方法尤其有用。与调整所有模型参数不同，PEFT方法只调整少量额外参数，从而显著减少计算和存储成本。我们用于微调LLM的PEFT方法是低秩适应（LoRA）方法，该方法在变换器层中添加低秩矩阵，仅调整这些矩阵，而不是整个模型。E.
    J. Hu等人描述了LoRA方法在LLM中的应用[[52](#bib.bib52)]。上述的Falcon 7B被选为我们的研究模型，因为在系统开发时，它在开放模型评分[[1](#bib.bib1)]方面表现优异。
- en: VI-A Behavior Tree Generation Module Fine-tuning Process
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 行为树生成模块微调过程
- en: This subsection delves into the process of structuring a dataset tailored for
    training a LLM for the generation of BT. The LLM sequentially generates words,
    and its training dataset comprises robot’s behavior as prompts and corresponding
    complete answers. Thus, for our purpose each dataset sample consists of an instruction
    for building the robot’s behavior and an output represented as a logically and
    structurally correct BT that allows the robot to execute the task. The instruction
    includes a system prompt that is common to all samples. This part is necessary
    for further work when the LLM will not only build BTs but also perform other tasks.
    After the unchangeable part of the instruction, there is a description of the
    required robot behavior. When generating this part of the samples using the text-davinci-003
    model, special attention was paid to the naturalness of the request. It should
    be a simple and logically understandable command that a human could give, as it
    is the human who will give the command to the robot when using the fine-tuned
    model. The generated BT consist of Action and Condition nodes that the robot can
    perform. In addition to Action and Condition nodes, the BT sometimes contains
    SubTree nodes. These nodes work like Action nodes, but themselves are compiled
    BTs. Adding SubTree nodes allows generating the overall logic of the robot’s behavior
    in several stages by generating missing elements from the available nodes. This
    approach avoids generating large constructions using LLM in one go, which would
    significantly increase the required memory, as the need to store attention between
    all sequence elements leads to a quadratic increase in the required memory with
    the increase in sequence length.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节深入探讨了为训练LLM生成行为树（BT）而定制数据集的构建过程。LLM按顺序生成单词，其训练数据集包括机器人的行为作为提示和相应的完整答案。因此，为了实现我们的目标，每个数据集样本包含构建机器人行为的指令和一个输出，该输出是一个逻辑和结构上正确的BT，允许机器人执行任务。指令包括一个所有样本共享的系统提示。这部分对于后续工作是必要的，因为LLM不仅将构建BT，还将执行其他任务。在指令的不可更改部分之后，描述了所需的机器人行为。在使用text-davinci-003模型生成这些样本的这一部分时，特别关注了请求的自然性。它应该是一个简单且逻辑上易于理解的命令，类似于人类可以给出的指令，因为当使用经过微调的模型时，正是人类将给出指令给机器人。生成的BT由机器人可以执行的Action和Condition节点组成。除了Action和Condition节点外，BT有时还包含SubTree节点。这些节点类似于Action节点，但它们本身是编译后的BT。添加SubTree节点使得可以通过生成缺失的元素来分阶段生成机器人行为的整体逻辑。此方法避免了在一次性使用LLM生成大型结构的情况，因为在所有序列元素之间存储注意力的需求会导致所需内存的平方增长，随着序列长度的增加，内存需求大幅增加。
- en: Furthermore, we proceeded with the dataset generation process. Initially, we
    possessed a list of nodes available for addition to the BT of our robots, and
    we aimed for the model to generate behaviors solely from these predefined nodes.
    To achieve this, we generated diverse samples of Behavior Trees using a Python
    script without resorting to LLM methods. The script produced a varied set of action
    combinations and parameters, along with corresponding descriptions following a
    specific template. While we retained the BTs in the dataset unchanged, we paraphrased
    the descriptions using the ChatGPT API. As a result, our dataset not only encompassed
    comprehensive and strategically valid behaviors but also exhibited request diversity.
    The training dataset comprised 7500 BT samples, each paired with its corresponding
    user command. The fine-tuning process lasted for three epochs on an Nvidia Tesla
    V100, totaling 10 hours.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们继续进行数据集生成过程。最初，我们拥有一个可供添加到机器人BT中的节点列表，并且我们希望模型仅从这些预定义节点生成行为。为此，我们使用Python脚本生成了多种行为树样本，而没有使用LLM方法。该脚本生成了一组多样的动作组合和参数，并根据特定模板生成相应的描述。在数据集中，我们保留了BT的原样，但使用ChatGPT
    API对描述进行了改述。因此，我们的数据集不仅包含了全面且战略上有效的行为，还展示了请求的多样性。训练数据集包括7500个BT样本，每个样本都有对应的用户命令。微调过程持续了三个周期，在Nvidia
    Tesla V100上总计花费了10小时。
- en: VI-B Question Answering Module Fine-tuning Process
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 问答模块微调过程
- en: '![Refer to caption](img/a13ec173a09dffef284cc15e8aa5a7d3.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a13ec173a09dffef284cc15e8aa5a7d3.png)'
- en: 'Figure 4: System architecture of LLM-MARS.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：LLM-MARS的系统架构。
- en: For effective human-robot interaction, it is insufficient for the robot to merely
    receive and execute commands. It must also provide feedback and answer to questions
    regarding its behavior. Considering our overarching goal of achieving autonomous
    AI-powered robots, it would be impractical to develop a separate full-fledged
    model to handle the task of answering questions. Operating two 7B models simultaneously
    on a single robot’s microcomputer significantly elevates its hardware requirements.
    Consequently, we conceived the idea of using a single LLM alongside multiple LoRa
    adapters as a solution. This approach offers advantages in terms of compactness
    and resource efficiency. However, it also has drawbacks, such as the need to switch
    between adapters, taking approximately 40 seconds. We also explored the possibility
    of using one adapter for both tasks; however, this negatively impacted the correctness
    of the structure of the generated BTs, jeopardizing the robot’s functionality.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现有效的人机交互，机器人仅仅接收和执行命令是不够的。它还必须提供反馈并回答有关其行为的问题。考虑到我们实现自主AI驱动机器人这一宏伟目标，开发一个独立的完整模型来处理问答任务是不可行的。在单个机器人的微型计算机上同时运行两个7B模型会显著提高硬件要求。因此，我们提出了使用一个单一的大型语言模型（LLM）和多个LoRa适配器作为解决方案。这种方法在紧凑性和资源效率方面具有优势。然而，它也存在一些缺点，例如需要在适配器之间切换，耗时约40秒。我们还探讨了使用一个适配器同时处理这两个任务的可能性；然而，这会影响生成行为树（BT）结构的正确性，从而危及机器人的功能。
- en: 'To address the generation of answers to questions about the outcome of the
    robot’s behavior, we drew inspiration from the work of Boston Dynamics [[38](#bib.bib38)].
    An XML file containing the context of the behavior’s results is assembled based
    on the BT and data from control sensors. This file is then passed as input to
    the LLM along with the user’s question to the robot. In original project, authors
    employed the ChatGPT API to generate responses for question-answering. In our
    research, we utilize the ChatGPT API to generate 11000 question-answering samples
    based on XML files in our specified format, each with various outcomes. After
    three epochs of training on Nvidia Tesla V100 on this dataset, taking 12 hours,
    we integrated a second LoRa adapter into our model, rendering it multimodal. The
    resulting architecture is presented on Fig. [4](#S6.F4 "Figure 4 ‣ VI-B Question
    Answering Module Fine-tuning Process ‣ VI LLM Training Methods and Recipes ‣ LLM-MARS:
    Large Language Model for Behavior Tree Generation and NLP-enhanced Dialogue in
    Multi-Agent Robot Systems").'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决生成关于机器人行为结果问题的答案，我们借鉴了Boston Dynamics的工作[[38](#bib.bib38)]。根据BT和控制传感器的数据，汇编一个包含行为结果上下文的XML文件。然后，这个文件与用户提出的问题一起作为输入传递给LLM。在原项目中，作者使用了ChatGPT
    API来生成问答回复。在我们的研究中，我们利用ChatGPT API基于我们指定格式的XML文件生成11000个问答样本，每个样本有不同的结果。经过在Nvidia
    Tesla V100上对该数据集进行三轮训练，总耗时12小时后，我们将第二个LoRa适配器集成到模型中，使其变得多模态。最终架构如图[4](#S6.F4 "Figure
    4 ‣ VI-B Question Answering Module Fine-tuning Process ‣ VI LLM Training Methods
    and Recipes ‣ LLM-MARS: Large Language Model for Behavior Tree Generation and
    NLP-enhanced Dialogue in Multi-Agent Robot Systems")所示。'
- en: At the moment we have developed two adapters. During further development, the
    number of adapters, and therefore the capabilities of the multimodal system, can
    be expanded.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们已经开发了两个适配器。在进一步的开发中，适配器的数量以及多模态系统的能力可以得到扩展。
- en: VII Experimental Evaluation
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 实验评估
- en: VII-A Experiment on Human Ability to Recognize Model-Generated Behavior Tree
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-A 人类识别模型生成行为树的实验
- en: To assess the performance of the model, we conducted an evaluation of individuals’
    capacity to differentiate between LLM-generated BTs and manually authored ones.
    A similar investigation was conducted by Brown et al. [[54](#bib.bib54)] but with
    the distinction that in our study, all participants possessed knowledge regarding
    the underlying principles and construction of BTs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型的表现，我们进行了一个评估，测试个体区分LLM生成的BT与人工编写的BT的能力。Brown等人也进行过类似的研究[[54](#bib.bib54)]，但与我们研究的不同之处在于，我们的所有参与者都具备关于BT的基本原理和构建方式的知识。
- en: Participants
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参与者
- en: We recruited a total of 15 participants, comprising both undergraduate and graduate
    students specializing in the Robotics track, to assess the quality of BT generation.
    Among the participants, ten individuals were members of local Eurobot team and
    regularly worked with BT. The remaining five participants had no prior exposure
    to BT and received explicit instructions on the underlying principles and construction
    techniques of BT. Prior to the commencement of the experiment, all participants
    provided their informed consent, thereby confirming their familiarity with the
    operational and structural aspects of robot BTs.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们共招募了15名参与者，包括专攻机器人学方向的本科生和研究生，以评估BT生成的质量。在这些参与者中，十名是当地Eurobot团队的成员，并且经常与BT进行工作。剩余的五名参与者之前没有接触过BT，且接受了有关BT的基本原理和构建技巧的明确指导。在实验开始之前，所有参与者均提供了知情同意书，确认他们已了解机器人BT的操作和结构方面的内容。
- en: Procedure
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 程序
- en: To conduct the experiment, a set of 10 BTs was generated using LLM. These BTs
    were designed to simulate various actions and interactions that a mobile robot
    could perform. Additionally, a separate set of 10 BTs was created manually, aiming
    to achieve similar functionalities and behaviors as the LLM generated BTs. Participants
    were presented with descriptions of the robot’s behavior and pairs of BTs, consisting
    of one LLM-generated BT and one human-created BT. The order of presentation was
    randomized to avoid any bias. Participants were then asked to evaluate the BTs
    and determine which one was created by the LLM and which one was human-created.
    They were instructed to rely on their subjective perception and any distinguishing
    features they could identify.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行实验，使用LLM生成了一组10个BT。这些BT旨在模拟移动机器人可以执行的各种动作和交互。此外，还手动创建了一组10个BT，旨在实现与LLM生成的BT相似的功能和行为。参与者被展示了机器人的行为描述和一对BT，其中包含一个LLM生成的BT和一个人类创建的BT。展示顺序是随机的，以避免任何偏差。随后，参与者被要求评估这些BT，并确定哪一个是由LLM生成，哪一个是由人类创建。他们被指示依赖自己的主观感知以及能够识别的任何区分特征。
- en: Experimental Results
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实验结果
- en: 'After the completion of the assessment phase for all pairs of BTs, the resulting
    data were collected and subjected to analysis. The findings of the experiment
    are visually depicted in Fig. [5](#S7.F5 "Figure 5 ‣ Experimental Results ‣ VII-A
    Experiment on Human Ability to Recognize Model-Generated Behavior Tree ‣ VII Experimental
    Evaluation ‣ LLM-MARS: Large Language Model for Behavior Tree Generation and NLP-enhanced
    Dialogue in Multi-Agent Robot Systems"). The mean score of 4.53 correct answers
    out of a total of 10 suggests that participants’ ability to differentiate between
    BTs generated by the LLM and those created by humans was comparable to random
    chance.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有BT对的评估阶段完成后，收集了相关数据并进行了分析。实验结果如图[5](#S7.F5 "图5 ‣ 实验结果 ‣ VII-A 人类识别模型生成的行为树实验
    ‣ VII 实验评估 ‣ LLM-MARS：用于行为树生成和多智能体机器人系统中的自然语言处理增强对话的大型语言模型")所示。平均得分为4.53分（满分10分），表明参与者区分LLM生成的BT和人类创建的BT的能力与随机猜测相当。
- en: '![Refer to caption](img/889b68d9a05adfbb3bd6d37ab5cbac66.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/889b68d9a05adfbb3bd6d37ab5cbac66.png)'
- en: 'Figure 5: Correct answer distribution for experiment on human ability to recognize
    model-generated behavior tree.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：关于人类识别模型生成的行为树的正确答案分布。
- en: In order to examine potential correlations between survey responses and specific
    questions, a one-way analysis of variance (ANOVA) was conducted with a significance
    level set at 5%. The analysis revealed no statistically significant difference
    in users’ perceptions of different questions (F = 0.75, p = 0.66 $>$ 0.05). This
    suggests that there is no evidence to support the claim that the probability of
    a correct answer depends on the question. To determine whether there exist discernible
    distinctions between human-generated BTs and those generated by the LLM, a t-test
    was conducted with a significance level set at 5% to evaluate the null hypothesis
    that they cannot be distinguished from each other. Under this null hypothesis,
    the average number of correct answers provided by the subjects would be 5 out
    of 10, and the average score would be 0.5\. Based on our results (mean score =
    0.453, t-statistic = -1.2, critical value = 2.145, p $>$ 0.05), we have no reason
    to reject the null hypothesis, which suggests that the mean score is not significantly
    different from 0.5.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查调查回答与特定问题之间的潜在关联，进行了单因素方差分析（ANOVA），显著性水平设定为 5%。分析结果显示，用户对不同问题的感知之间没有统计学显著差异（F
    = 0.75，p = 0.66 $>$ 0.05）。这表明没有证据支持正确答案的概率与问题之间的依赖关系。为了确定人工生成的行为树与LLM生成的行为树是否存在可区分的差异，进行了t检验，显著性水平设定为
    5%，以评估无法区分它们的原假设。在这一原假设下，受试者提供的正确答案平均数量为 10 个中的 5 个，平均得分为 0.5。根据我们的结果（平均得分 = 0.453，t统计量
    = -1.2，临界值 = 2.145，p $>$ 0.05），我们没有理由拒绝原假设，这表明平均得分与 0.5 并无显著差异。
- en: The user study, involving 15 volunteers, yielded no substantive indications
    of subjective disparities between LLM-generated BTs and human-generated BTs. The
    LLM model demonstrates the capability to generate robot behavior with result close
    to human-created BTs, at least in terms of subjective perception within the context
    of our experiment.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 该用户研究涉及15名志愿者，未发现LLM生成的行为树与人工生成的行为树之间在主观感知上有实质性差异。LLM模型展示了生成机器人行为的能力，其结果接近人工创建的行为树，至少在我们实验的主观感知上下文中是如此。
- en: VII-B Behavior Generation Performance Evaluation
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-B 行为生成性能评估
- en: After the experiment demonstrated the ability of LLM to generate BT for given
    tasks, we conducted experiment on a real multi-agent robot system. The experiment
    aimed to evaluate the extent to which the formed BTs reflect the tasks given.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验展示LLM生成给定任务的行为树的能力后，我们在一个真实的多智能体机器人系统上进行了实验。该实验旨在评估形成的行为树在多大程度上反映了给定的任务。
- en: Participants
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参与者
- en: The experiment involved the participation of authors of this work who assessed
    the LLM’s ability to generate BTs for designated tasks.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 实验由本工作的作者参与，评估了LLM生成行为树的能力。
- en: Procedure
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 过程
- en: 'The LLM was presented with sixty commands, each containing one to six tasks.
    For each task variant, ten examples were available, ensuring a comprehensive evaluation
    of task complexities. The primary focus was on analyzing the accuracy of integrating
    robot tasks into the BT. The result of the experiment is presented on Fig. [6](#S7.F6
    "Figure 6 ‣ Procedure ‣ VII-B Behavior Generation Performance Evaluation ‣ VII
    Experimental Evaluation ‣ LLM-MARS: Large Language Model for Behavior Tree Generation
    and NLP-enhanced Dialogue in Multi-Agent Robot Systems").'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大语言模型）接受了六十个命令，每个命令包含一到六个任务。每个任务变体提供了十个示例，确保对任务复杂性的全面评估。主要关注点是分析将机器人任务整合到行为树（BT）中的准确性。实验结果见图
    [6](#S7.F6 "图 6 ‣ 过程 ‣ VII-B 行为生成性能评估 ‣ VII 实验评估 ‣ LLM-MARS：用于多智能体机器人系统中的行为树生成和NLP增强对话的大语言模型")。
- en: '![Refer to caption](img/6a625c394d0b1d8d11495519e3f31aaa.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/6a625c394d0b1d8d11495519e3f31aaa.png)'
- en: 'Figure 6: Task quantity’s impact on Large Language Model’s performance accuracy.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：任务数量对大语言模型性能准确度的影响。
- en: Experimental Results
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实验结果
- en: The results of the experiment showcased the remarkable performance of the LLM
    in generating BTs based on commands. The LLM demonstrated an accuracy of 70.44%
    in integrating provided robot tasks into the BTs. For commands with up to two
    tasks, integration accuracy exceeded 90%. The average percentage of correctly
    added tasks within a command was found to be 79.28%. Notably, task integration
    accuracy in BTs was influenced by the number of tasks in a command.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果展示了大型语言模型（LLM）在根据指令生成行为树（BTs）方面的卓越表现。该LLM在将提供的机器人任务整合到行为树中的准确率达到了70.44%。对于最多包含两个任务的指令，整合准确率超过了90%。在一条指令中正确添加任务的平均百分比为79.28%。值得注意的是，行为树中的任务整合准确率受指令中任务数量的影响。
- en: VII-C Expert Evaluation of Question Responses
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第七章C 专家评估问题回答
- en: Participants
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参与者
- en: 'The following experiment involved the collection of 50 responses from the Language
    Model (LLM) concerning robot behavior. These responses were subject to evaluation
    by ten individual with specialized knowledge and experience in the field related
    to robot behavior based on three criteria: accuracy, relevance, and informativeness.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的实验涉及收集了50个来自大型语言模型（LLM）关于机器人行为的回应。这些回应经过了十位具有机器人行为相关领域的专业知识和经验的个体评估，评估标准包括准确性、相关性和信息性。
- en: '![Refer to caption](img/1698a79db3dfddc42047a4474788209c.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/1698a79db3dfddc42047a4474788209c.png)'
- en: 'Figure 7: Average assessment of Large Language Model parameters.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：大型语言模型参数的平均评估。
- en: Procedure
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 程序
- en: 'The responses from the LLM were evaluated by expert raters based on three criteria.
    Accuracy was scored as 0 for incorrect and 1 for correct responses. Relevance
    was rated on a scale of 1 to 5 (1 = not relevant, 5 = highly relevant), and informativeness
    was assessed on a scale of 1 to 5, with higher scores indicating more relevant
    information. To validate the significance of the data, a Krippendorff’s Alpha
    Reliability test was conducted to assess expert agreement. The corresponding data
    is presented on Fig. [7](#S7.F7 "Figure 7 ‣ Participants ‣ VII-C Expert Evaluation
    of Question Responses ‣ VII Experimental Evaluation ‣ LLM-MARS: Large Language
    Model for Behavior Tree Generation and NLP-enhanced Dialogue in Multi-Agent Robot
    Systems").'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM的回应由专家评分员根据三个标准进行评估。准确性以0表示错误回答，1表示正确回答。相关性按1到5的等级评定（1 = 不相关，5 = 高度相关），信息性则按1到5的等级评估，得分越高表示信息越相关。为了验证数据的显著性，进行了克里平多夫α可靠性测试，以评估专家的一致性。相应的数据见图[7](#S7.F7
    "图7 ‣ 参与者 ‣ 第七章C 专家评估问题回答 ‣ 第七章 实验评估 ‣ LLM-MARS: 大型语言模型在多代理机器人系统中的行为树生成和自然语言处理增强对话应用")。'
- en: Experimental Results
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实验结果
- en: The average accuracy of the LLM was 72.8%, with relevance and informativeness
    scores equaling 4.71 and 4.89, respectively.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的平均准确率为72.8%，相关性和信息性得分分别为4.71和4.89。
- en: 'To validate the significance of the data, a Krippendorff’s Alpha Reliability
    test was conducted to assess expert agreement. The results of Krippendorff’s Alpha
    Reliability test are the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证数据的显著性，进行了克里平多夫α可靠性测试，以评估专家的一致性。克里平多夫α可靠性测试的结果如下：
- en: •
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reliability for Accuracy: The Krippendorff’s alpha equals 0.8239, demonstrating
    a robust agreement among evaluators regarding accuracy.'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确性可靠性：克里平多夫α系数为0.8239，表明评估者在准确性方面有较强的一致性。
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reliability for Relevance: The Krippendorff’s alpha equals 0.7229, indicating
    a moderate level of agreement among evaluators regarding relevance.'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相关性可靠性：克里平多夫α系数为0.7229，表明评估者在相关性方面有中等程度的一致性。
- en: •
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reliability for Informativeness: The Krippendorff’s alpha equals 0.7594, also
    signifying a moderate level of agreement among evaluators regarding informativeness.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息性可靠性：克里平多夫α系数为0.7594，同样表明评估者在信息性方面有中等程度的一致性。
- en: VIII Results and Discussion
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第八章 结果与讨论
- en: 'The results (Fig. [6](#S7.F6 "Figure 6 ‣ Procedure ‣ VII-B Behavior Generation
    Performance Evaluation ‣ VII Experimental Evaluation ‣ LLM-MARS: Large Language
    Model for Behavior Tree Generation and NLP-enhanced Dialogue in Multi-Agent Robot
    Systems")) demonstrated outstanding performance of LLM in generating BT based
    on commands. LLM accurately integrated 70.44% of all provided robot tasks into
    the generated Behavior Trees. For commands with up to two tasks, the integration
    accuracy exceeded 90%. Additionally, the average percentage of correctly added
    tasks within a command equals 79.28%. Moreover, task integration accuracy in BT
    was influenced by the number of tasks in a command. A one-way analysis of variance
    (ANOVA) with a significance level of 0.05 confirmed the statistical significance
    of this relationship (F-statistic = 2.61, p-value = 0.035). Specifically, LLM
    performed better with commands containing fewer tasks. The performance slightly
    improved when dealing with commands with up to 6 tasks, likely due to the fact
    that this amount of tasks make strategy similar to strategies for Eurobot that
    was used to generate the dataset for LLM finetuning.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 结果（图[6](#S7.F6 "图 6 ‣ 程序 ‣ VII-B 行为生成性能评估 ‣ VII 实验评估 ‣ LLM-MARS：用于行为树生成和多智能体机器人系统中NLP增强对话的大型语言模型")）表明LLM在基于指令生成行为树方面表现优异。LLM准确地将70.44%的所有给定机器人任务整合到生成的行为树中。对于最多包含两个任务的指令，整合准确率超过90%。此外，指令中正确添加任务的平均百分比为79.28%。此外，行为树中任务的整合准确率受指令中任务数量的影响。通过显著性水平为0.05的一元方差分析（ANOVA）确认了这一关系的统计显著性（F统计量
    = 2.61，p值 = 0.035）。具体来说，LLM在处理包含较少任务的指令时表现更好。处理最多6个任务的指令时，性能略有提升，这可能是因为这些任务的数量使得策略类似于用于生成LLM微调数据集的Eurobot策略。
- en: 'The results of question response evaluation for each expert (Fig. [7](#S7.F7
    "Figure 7 ‣ Participants ‣ VII-C Expert Evaluation of Question Responses ‣ VII
    Experimental Evaluation ‣ LLM-MARS: Large Language Model for Behavior Tree Generation
    and NLP-enhanced Dialogue in Multi-Agent Robot Systems")) indicated a strong performance
    of the LLM in addressing questions related to robot behavior. The average accuracy
    was 72.8%. The relevance and informativeness score equal 4.71 and 4.89 respectively.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 每位专家的问答评估结果（图[7](#S7.F7 "图 7 ‣ 参与者 ‣ VII-C 专家问答评估 ‣ VII 实验评估 ‣ LLM-MARS：用于行为树生成和多智能体机器人系统中NLP增强对话的大型语言模型")）表明，LLM在处理与机器人行为相关的问题时表现出色。平均准确率为72.8%。相关性和信息量得分分别为4.71和4.89。
- en: The results of Krippendorff’s Alpha Reliability test indicated a strong agreement
    among the expert evaluators for the Accuracy parameter. However, for the Relevance
    and Informativeness parameters, the level of agreement was moderate. This disparity
    can be attributed to the more subjective nature of relevance and informativeness
    compared to the Accuracy.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Krippendorff α可靠性测试的结果表明，专家评估者在准确性参数上的一致性较强。然而，在相关性和信息量参数上，一致性水平较为中等。这一差异可以归因于相关性和信息量相比准确性而言更具主观性。
- en: In our research, we explore the exciting fusion of LLM and robotics. We developed
    first technology to create a multi-agent robotic system capable of engaging in
    dialogue with humans, constructing complex behavioral strategies for its agents
    based on human commands, and providing feedback on task execution. This technology
    has been put into practice in a multi-agent robotic system under near real-world
    conditions. Experimental results show that robots correctly execute given compound
    commands at an average of 79.28%, with higher accuracy (exceeding 90%) observed
    for commands containing one or two tasks. Furthermore, expert evaluation of question
    responses revealed that the answers provided by the system exhibit high accuracy,
    relevance, and informativeness.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们探索了LLM与机器人技术的激动人心的融合。我们开发了第一项技术，能够创建一个多智能体机器人系统，使其能够与人类对话，根据人类指令为其代理构建复杂的行为策略，并提供任务执行反馈。这项技术已经在接近真实世界条件下的多智能体机器人系统中得到了应用。实验结果表明，机器人能够正确执行给定的复合指令，平均准确率为79.28%，对于包含一个或两个任务的指令，准确率超过90%。此外，专家对问答的评估表明，系统提供的答案具有较高的准确性、相关性和信息量。
- en: Although the results obtained during the research fully justified our expectations,
    this technology still offers a vast expanse for further exploration and refinement.
    In future endeavors, our focus will be on enhancing the command processing capabilities
    of the model, particularly for commands comprising a larger number of tasks. This
    improvement can be achieved through a two-step approach involving command decomposition
    into simpler tasks and generating BTs based on these tasks. The decomposition
    stage could be realized by adding a dedicated function to the BT generation adapter
    or training a separate adapter specifically for this purpose.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管研究中获得的结果充分证明了我们的预期，但这一技术仍有广阔的探索和完善空间。在未来的工作中，我们将专注于提升模型的命令处理能力，特别是对于包含更多任务的命令。这一改进可以通过两步法实现，首先将命令分解为更简单的任务，然后基于这些任务生成行为树（BTs）。分解阶段可以通过向行为树生成适配器添加专门功能，或训练一个专门为此目的的适配器来实现。
- en: IX Conclusion
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IX 结论
- en: In conclusion, our development and implementation of LLM-MARS mark a groundbreaking
    advancement in the convergence of artificial intelligence and robotics. This innovative
    approach, utilizing a Large Language Model based on the Falcon 7B, introduces
    a paradigm shift in robot control, enabling the management of multi-agent robotic
    systems through dynamic dialogues.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们开发并实施的LLM-MARS标志着人工智能与机器人技术融合的突破性进展。这一创新方法，基于Falcon 7B的大型语言模型，引入了机器人控制的范式转变，使得通过动态对话管理多智能体机器人系统成为可能。
- en: Our trials within the Eurobot 2023 game rules demonstrate significant success,
    with an impressive average task execution accuracy of 79.28%. Particularly noteworthy
    is the system’s proficiency in integrating tasks into Behavior Trees, showcasing
    the effectiveness of the employed Large Language Model used in such a scenario.
    The observed correlation between task integration accuracy and the number of tasks
    in a command suggests targeted enhancements for command processing.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Eurobot 2023比赛规则下的实验展示了显著的成功，平均任务执行准确率达到了79.28%。特别值得注意的是，系统在将任务整合到行为树（Behavior
    Trees）中的高效性，展示了所采用的大型语言模型在此场景中的有效性。观察到任务整合准确性与命令中任务数量之间的相关性，提示了命令处理的有针对性改进。
- en: Expert evaluations further affirm the reliability and potential of LLM-MARS
    in practical scenarios, emphasizing high accuracy, relevance, and informativeness
    in responses to questions. These findings also illuminate areas for future research,
    particularly in enhancing the system’s handling of more complex commands through
    advanced techniques like command decomposition and specialized adapters.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 专家评估进一步确认了LLM-MARS在实际场景中的可靠性和潜力，强调了其在回答问题时的高准确性、相关性和信息性。这些发现还揭示了未来研究的方向，特别是在通过命令分解和专门适配器等先进技术提高系统处理复杂命令的能力方面。
- en: The core achievement lies in our pioneering approach to robot management, allowing
    a swarm of robots to possess AI capabilities under the control of a single LLM.
    This strategy is especially crucial for scenarios where robot groups collaboratively
    tackle complex tasks, each responding to simple instructions. E.g. mobile robot
    groups could revolutionize logistics by fully replacing human warehouse personnel.
    Additionally, groups of robots or drones could autonomously carry out exploration
    missions, searching for valuable artifacts and conducting terrain research. Furthermore,
    the application of this technology to create a multi-agent system of manipulator
    robots represents a step forward in the direction of the collaboration between
    humans and machines, also knows as Industry 5.0.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的核心成就 lies 在于我们在机器人管理方面的开创性方法，使得一群机器人能够在单一大型语言模型（LLM）的控制下具备人工智能能力。这一策略对于机器人群体共同完成复杂任务尤其重要，每个机器人响应简单指令。例如，移动机器人群体可以彻底取代人类仓库人员，革新物流行业。此外，机器人或无人机群体可以自主执行探索任务，寻找有价值的文物并进行地形研究。此外，将这项技术应用于创建多智能体的机械臂机器人系统，标志着人机协作方向的进一步发展，也即工业5.0。
- en: The primary advantage of our approach is that the LLM configures the system
    for specific tasks, eliminating the need for specialized human programming for
    each robot. This not only streamlines the process but also empowers the AI as
    a system manager, capable of answering inquiries about its performance.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们方法的主要优势在于，LLM为特定任务配置系统，消除了为每个机器人进行专门人类编程的需要。这不仅简化了流程，还赋予了人工智能作为系统管理员的能力，能够回答关于其性能的询问。
- en: References
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] E. Beeching et al. “Open LLM Leaderboard”. Huggingface.co. [https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
    (accessed Nov. 16, 2023).'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] E. Beeching 等人，“开放LLM排行榜”。Huggingface.co. [https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)（访问日期：2023年11月16日）。'
- en: '[2] A. Vaswani et al., “Attention Is All You Need,” 2017, arXiv:1706.03762\.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] A. Vaswani 等人，“注意力机制：你需要的一切，”2017年，arXiv:1706.03762\。'
- en: '[3] X. Chen et al., “How Robust is GPT-3.5 to Predecessors? A Comprehensive
    Study on Language Understanding Tasks,” 2023, arXiv:2303.00293\.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] X. Chen 等人，“GPT-3.5对前代模型的鲁棒性如何？关于语言理解任务的综合研究，”2023年，arXiv:2303.00293\。'
- en: '[4] S. Bubeck et al., “Sparks of Artificial General Intelligence: Early experiments
    with GPT-4,” 2023, arXiv:2303.12712\.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S. Bubeck 等人，“人工通用智能的火花：与GPT-4的早期实验，”2023年，arXiv:2303.12712\。'
- en: '[5] G. Brockman et al., “Introducing ChatGPT,” OpenAI, 2022 [Online] Available:
    [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt).'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] G. Brockman 等人，“介绍ChatGPT，”OpenAI，2022年 [在线] 可用：[https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)。'
- en: '[6] C. Raffel et al., “Exploring the Limits of Transfer Learning with a Unified
    Text-to-Text Transformer,” in Journal of Machine Learning Research, vol. 21, no.140,
    pp. 1-67, 2020\.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] C. Raffel 等人，“探索统一文本到文本变换器的迁移学习极限，”《机器学习研究期刊》，第21卷，第140期，页码：1-67，2020年\。'
- en: '[7] H. Touvron et al., “LLaMA: Open and Efficient Foundation Language Models,”
    2023, arXiv:2302.13971\.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] H. Touvron 等人，“LLaMA：开放高效的基础语言模型，”2023年，arXiv:2302.13971\。'
- en: '[8] R. Taori et al. “Alpaca: A Strong, Replicable Instruction-Following Model”.
    CRFM.Stanford.edu [https://crfm.stanford.edu/2023/03/13/alpaca.html](https://crfm.stanford.edu/2023/03/13/alpaca.html)
    (accessed Sept. 26, 2023).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] R. Taori 等人，“Alpaca：一个强大且可复制的指令跟随模型”。CRFM.Stanford.edu [https://crfm.stanford.edu/2023/03/13/alpaca.html](https://crfm.stanford.edu/2023/03/13/alpaca.html)（访问日期：2023年9月26日）。'
- en: '[9] E. J. Wang. “Flan-Alpaca-LoRA: Instruction Tuning from Humans and Machines
    with Low-Rank Adaptation”. GitHub.com. [https://github.com/Reason-Wang/flan-alpaca-lora](https://github.com/Reason-Wang/flan-alpaca-lora)
    (accessed Sept. 15, 2023).'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] E. J. Wang. “Flan-Alpaca-LoRA: 来自人类和机器的指令调优与低秩自适应”。GitHub.com. [https://github.com/Reason-Wang/flan-alpaca-lora](https://github.com/Reason-Wang/flan-alpaca-lora)（访问日期：2023年9月15日）。'
- en: '[10] G. Penedo et al., “The RefinedWeb Dataset for Falcon LLM: Outperforming
    Curated Corpora with Web Data, and Web Data Only,” 2023, arXiv:2306.01116\.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] G. Penedo 等人，“Falcon LLM的精炼Web数据集：仅凭Web数据超越精心策划的语料库，”2023年，arXiv:2306.01116\。'
- en: '[11] H. Touvron et al., “Llama 2: Open foundation and fine-tuned chat models,”
    2023, arXiv:2307.09288\.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] H. Touvron 等人，“Llama 2：开放的基础模型和微调的聊天模型，”2023年，arXiv:2307.09288\。'
- en: '[12] A. Q. Jiang et al., ”Mistral 7B,” 2023, arXiv:2310.06825\.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] A. Q. Jiang 等人，“Mistral 7B，”2023年，arXiv:2310.06825\。'
- en: '[13] The Refined Web dataset for Falcon LLM: outperforming curated corpora
    with web data, and web data only. (2023) [Online]. Available: [https://huggingface.co/tiiuae/falcon-180B](https://huggingface.co/tiiuae/falcon-180B).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Falcon LLM的精炼Web数据集：超越精心策划的语料库，仅凭Web数据。 (2023) [在线]. 可用：[https://huggingface.co/tiiuae/falcon-180B](https://huggingface.co/tiiuae/falcon-180B)。'
- en: '[14] A. Koubaa, “ROSGPT: Next-Generation Human-Robot Interaction with ChatGPT
    and ROS,” Preprints.org, 2023, doi: 10.20944/preprints202304.0827.v3\.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] A. Koubaa，“ROSGPT：与ChatGPT和ROS的下一代人类机器人互动，”Preprints.org，2023年，doi: 10.20944/preprints202304.0827.v3\。'
- en: '[15] I. Singh et al., “ProgPrompt: Generating Situated Robot Task Plans using
    Large Language Models,” 2023 IEEE International Conference on Robotics and Automation
    (ICRA), London, United Kingdom, 2023, pp. 11523-11530, doi: 10.1109/ICRA48891.2023.10161317\.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] I. Singh 等人，“ProgPrompt：使用大型语言模型生成定位机器人任务计划，”2023年IEEE国际机器人与自动化大会（ICRA），英国伦敦，2023年，页码：11523-11530，doi:
    10.1109/ICRA48891.2023.10161317\。'
- en: '[16] X. Zhao, M. Li, C. Weber, M. B. Hafez, S. Wermter, “Chat with the Environment:
    Interactive Multimodal Perception Using Large Language Models,” 2023, arXiv:2303.08268v2\.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] X. Zhao, M. Li, C. Weber, M. B. Hafez, S. Wermter，“与环境对话：使用大型语言模型进行互动多模态感知，”2023年，arXiv:2303.08268v2\。'
- en: '[17] Y. Ding, X. Zhang, C. Paxton, S. Zhang, “Task and Motion Planning with
    Large Language Models for Object Rearrangement,” 2023, arXiv:2303.06247v3\.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Y. Ding, X. Zhang, C. Paxton, S. Zhang，“基于大型语言模型的物体重新排列任务与运动规划，”2023年，arXiv:2303.06247v3\。'
- en: '[18] W. Huang et al., “Inner Monologue: Embodied Reasoning through Planning
    with Language Models,” 2022, arXiv:2207.05608\.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] W. Huang 等人，“内心独白：通过语言模型的规划实现具身推理，”2022年，arXiv:2207.05608\。'
- en: '[19] B. Zitkovich et al., “Rt-2: Vision-language-action models transfer web
    knowledge to robotic control,” 7th Annual Conference on Robot Learning (CoRL 2023),
    Atlanta, USA, 2023, pp. 1-19\.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] B. Zitkovich 等， “Rt-2：视觉-语言-动作模型将网络知识转移到机器人控制中，”第7届机器人学习年会（CoRL 2023），美国亚特兰大，2023年，第1-19页\.'
- en: '[20] Y. Su, “Artificial Intelligence: The Significance of Tesla Bot,” International
    Conference on Computer, Machine Learning and Artificial Intelligence (CMLAI 2023),
    San Francisco, USA, 2023, pp. 1351-1355, doi: 10.54097/hset.v39i.6767\.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Y. Su, “人工智能：特斯拉机器人之重要性，”国际计算机、机器学习与人工智能会议（CMLAI 2023），美国旧金山，2023年，第1351-1355页，doi:
    10.54097/hset.v39i.6767\.'
- en: '[21] B. Ichter et al., “Do As I Can, Not As I Say: Grounding Language in Robotic
    Affordances,” Conference on Robot Learning, Auckland, New Zealand, 2022, pp. 287-318\.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] B. Ichter 等， “做我能做的，而不是我说的：将语言与机器人能力对接，”机器人学习会议，纽西兰奥克兰，2022年，第287-318页\.'
- en: '[22] Y. Cao, C.S. Lee, “Robot Behavior-Tree-Based Task Generation with Large
    Language Models,” 2023, arXiv:2302.12927\.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Y. Cao, C.S. Lee, “基于机器人行为树的大型语言模型任务生成，”2023年，arXiv:2302.12927\.'
- en: '[23] Z. Wu, Z. Wang, X. Xu, J. Lu, H. Yan, “Embodied Task Planning with Large
    Language Models,” 2023, arXiv:2307.01848\.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Z. Wu, Z. Wang, X. Xu, J. Lu, H. Yan, “具身任务规划与大型语言模型，”2023，arXiv:2307.01848\.'
- en: '[24] R. Balogh, D. Obdržálek, “Using Finite State Machines in Introductory
    Robotics: Methods and Applications for Teaching and Learning,” in Robotics in
    Education (RiE 2018). Advances in Intelligent Systems and Computing, Springer,
    2018, vol. 829., pp. 85-91\.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] R. Balogh, D. Obdržálek, “在入门级机器人学中使用有限状态机：教学与学习的方法与应用，”发表于《教育中的机器人学》（RiE
    2018）。智能系统与计算的进展，Springer出版社，2018年，第829卷，第85-91页\.'
- en: '[25] R. Hussain, T. Zielinska, R. Hexel, “Finite state automaton based control
    system for walking machines,” International Journal of Advanced Robotic Systems,
    vol. 16, May 2019, Art. no. 1729881419853182, doi: 10.1177/1729881419853182\.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] R. Hussain, T. Zielinska, R. Hexel, “基于有限状态自动机的行走机器控制系统，”《先进机器人系统国际期刊》，第16卷，2019年5月，艺术编号1729881419853182，doi:
    10.1177/1729881419853182\.'
- en: '[26] P. Lima, H. Gracio, V. Veiga and A. Karlsson, “Petri nets for modeling
    and coordination of robotic tasks,” in SMC’98 Conference Proceedings. 1998 IEEE
    International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218),
    San Diego, CA, USA, 1998, pp. 190-195 vol.1, doi: 10.1109/ICSMC.1998.725407\.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] P. Lima, H. Gracio, V. Veiga 和 A. Karlsson, “用于建模和协调机器人任务的Petri网，”发表于《SMC''98会议论文集》。1998年IEEE国际系统、人类与控制论会议（Cat.
    No.98CH36218），美国加利福尼亚州圣地亚哥，1998年，第190-195页，第1卷，doi: 10.1109/ICSMC.1998.725407\.'
- en: '[27] V.A. Ziparo, L. Iocchi, P.U. Lima, D. Nardi, P.F. Palamara, “Petri net
    plans: A framework for collaboration and coordination in multi-robot systems,”
    in Autonomous Agents and Multi-Agent Systems, vol. 23, pp. 344-383, 2011, doi:
    10.1007/s10458-010-9146-1\.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] V.A. Ziparo, L. Iocchi, P.U. Lima, D. Nardi, P.F. Palamara, “Petri网规划：多机器人系统中协作与协调的框架，”发表于《自主代理与多智能体系统》，第23卷，第344-383页，2011年，doi:
    10.1007/s10458-010-9146-1\.'
- en: '[28] B. Lacerda, P.U. Lima, “Petri net based multi-robot task coordination
    from temporal logic specification,” in Robotics and Autonomous Systems vol. 122,
    Sep. 2019, Art. no. 103289, doi: 10.1016/j.robot.2019.103289\.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] B. Lacerda, P.U. Lima, “基于Petri网的多机器人任务协调从时序逻辑规范出发，”发表于《机器人与自主系统》 第122卷，2019年9月，艺术编号103289，doi:
    10.1016/j.robot.2019.103289\.'
- en: '[29] P. Lv, G. Luo, X. Yin, Z. Ma, S. Li, “Optimal multi-robot path planning
    for cyclic tasks using Petri nets,” in Control Engineering Practice, vol. 138,
    Sept. 2023, Art. no. 105600, doi: 10.1016/j.conengprac.2023.10560\.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] P. Lv, G. Luo, X. Yin, Z. Ma, S. Li, “基于Petri网的循环任务多机器人路径规划优化，”发表于《控制工程实践》，第138卷，2023年9月，艺术编号105600，doi:
    10.1016/j.conengprac.2023.10560\.'
- en: '[30] M. Colledanchise, “Behavior Trees in Robotics,” Ph.D. dissertation, School
    of Computer Science and Communication (CSC), KTH Royal Institute of Technology,
    Stockholm, Sweden, 2017\.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. Colledanchise, “机器人学中的行为树，”博士论文，计算机科学与通信学院（CSC），瑞典KTH皇家理工学院，斯德哥尔摩，2017年\.'
- en: '[31] M. Colledanchise, P. Ögren, Behavior Trees in Robotics and AI: An Introduction,
    Boca Raton, FL, USA: CRC Press, ed. 1, 2018\.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] M. Colledanchise, P. Ögren, 《机器人学与人工智能中的行为树：入门》，美国佛罗里达州博卡拉顿：CRC出版社，第1版，2018年\.'
- en: '[32] P. Ögren, C.I. Sprague, “Behavior trees in robot control systems,” in
    Annual Review of Control, Robotics, and Autonomous Systems, vol. 5, pp. 81-107,
    May 2022, doi: 10.1146/annurev-control-042920-095314\.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] P. Ögren, C.I. Sprague, “机器人控制系统中的行为树，”发表于《控制、机器人与自主系统年评》，第5卷，第81-107页，2022年5月，doi:
    10.1146/annurev-control-042920-095314\.'
- en: '[33] M. Colledanchise, L. Natale, “On the Implementation of Behavior Trees
    in Robotics,” in IEEE Robotics and Automation Letters vol. 6, no. 3, pp. 5929-5936,
    July 2021, doi: 10.1109/LRA.2021.3087442\.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] M. Colledanchise, L. Natale，“机器人中行为树的实现，”《IEEE机器人与自动化快报》，第 6 卷，第 3 期，第
    5929-5936 页，2021年7月，doi: 10.1109/LRA.2021.3087442。'
- en: '[34] E. Safronov, M. Colledanchise, L. Natale, “Task Planning with Belief Behavior
    Trees,” 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems
    (IROS), Las Vegas, NV, USA, 2020, pp. 6870-6877, doi: 10.1109/IROS45743.2020.9341562\.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] E. Safronov, M. Colledanchise, L. Natale，“使用信念行为树进行任务规划，”2020年IEEE/RSJ国际智能机器人与系统大会（IROS），位于美国内华达州拉斯维加斯，2020年，第
    6870-6877 页，doi: 10.1109/IROS45743.2020.9341562。'
- en: '[35] R. Ghzouli, T. Berger, E.B. Johnsen, A. Wasowski, S. Dragule, “Behavior
    Trees and State Machines in Robotics Applications,” in IEEE Transactions on Software
    Engineering, vol. 49, no. 9, pp. 4243-4267, Sept. 2023, https://doi.org/10.1109/TSE.2023.3269081\.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] R. Ghzouli, T. Berger, E.B. Johnsen, A. Wasowski, S. Dragule，“机器人应用中的行为树与状态机，”《IEEE软件工程学报》，第
    49 卷，第 9 期，第 4243-4267 页，2023年9月，[https://doi.org/10.1109/TSE.2023.3269081](https://doi.org/10.1109/TSE.2023.3269081)。'
- en: '[36] D. Driess et al., “PaLM-E: An Embodied Multimodal Language Model,” 2023,
    arXiv:2303.03378\.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] D. Driess 等人，“PaLM-E：一种具身多模态语言模型，”2023年，arXiv:2303.03378。'
- en: '[37] A. Brohan et al., “Rt-1: Robotics transformer for real-world control at
    scale,” 2022, arXiv:2212.06817\.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] A. Brohan 等人，“Rt-1：大规模现实世界控制的机器人变压器，”2022年，arXiv:2212.06817。'
- en: '[38] M. Klingensmith. “Robots That Can Chat”. Bostondynamics.com. [https://bostondynamics.com/blog/robots-that-can-chat/](https://bostondynamics.com/blog/robots-that-can-chat/)
    (accessed Nov. 11, 2023).'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] M. Klingensmith。“可以聊天的机器人”。Bostondynamics.com。[https://bostondynamics.com/blog/robots-that-can-chat/](https://bostondynamics.com/blog/robots-that-can-chat/)（访问日期：2023年11月11日）。'
- en: '[39] V. Petkauskas. “ChatGPT injected into Boston Dynamics’ Spot”. Cybernews.com.
    [https://cybernews.com/tech/chatgpt-google-boston-dynamics-spot/](https://cybernews.com/tech/chatgpt-google-boston-dynamics-spot/)
    (accessed Nov. 11, 2023).'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] V. Petkauskas。“ChatGPT 注入到 Boston Dynamics 的 Spot 中”。Cybernews.com。[https://cybernews.com/tech/chatgpt-google-boston-dynamics-spot/](https://cybernews.com/tech/chatgpt-google-boston-dynamics-spot/)（访问日期：2023年11月11日）。'
- en: '[40] N. Stiennon et al., “Learning to summarize from human feedback,” 2022,
    arXiv:2009.01325\.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] N. Stiennon 等人，“从人类反馈中学习总结，”2022年，arXiv:2009.01325。'
- en: '[41] Y. Wang et al., “Self-Instruct: Aligning Language Models with Self-Generated
    Instructions,” 2022, arXiv:2212.10560\.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Y. Wang 等人，“Self-Instruct：将语言模型与自生成的指令对齐，”2022年，arXiv:2212.10560。'
- en: '[42] M. Colledanchise, P. Ögren, “How Behavior Trees modularize robustness
    and safety in hybrid systems,” 2014 IEEE/RSJ International Conference on Intelligent
    Robots and Systems, Chicago, IL, USA, 2014, pp. 1482-1488, doi: 10.1109/IROS.2014.6942752\.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] M. Colledanchise, P. Ögren，“行为树如何在混合系统中模块化鲁棒性和安全性，”2014年IEEE/RSJ国际智能机器人与系统大会，位于美国伊利诺伊州芝加哥，2014年，第
    1482-1488 页，doi: 10.1109/IROS.2014.6942752。'
- en: '[43] G. Granosik et al., “Using Robot Operating System for Autonomous Control
    of Robots in Eurobot, ERC and Robotour Competitions,” Acta Polytechnica CTU Proceedings,
    vol. 6, pp. 11-17, 2016, doi:10.14311/APP.2016.6.0011\.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] G. Granosik 等人，“在 Eurobot、ERC 和 Robotour 竞赛中使用机器人操作系统进行自主控制，”《捷克理工大学学报》，第
    6 卷，第 11-17 页，2016年，doi:10.14311/APP.2016.6.0011。'
- en: '[44] S. Macenski, T. Foote, B. Gerkey, C. Lalancette, W. Woodall, “Robot Operating
    System 2: Design, architecture, and uses in the wild,” in Science Robotics, vol.
    7, no. 66, pp. 60-74, 2022, doi: 10.1126/scirobotics.abm6074\.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. Macenski, T. Foote, B. Gerkey, C. Lalancette, W. Woodall，“机器人操作系统 2：设计、架构及其在实际中的应用，”《科学机器人学》，第
    7 卷，第 66 期，第 60-74 页，2022年，doi: 10.1126/scirobotics.abm6074。'
- en: '[45] F. Gustafsson et al., “Particle filters for positioning, navigation, and
    tracking,” in IEEE Transactions on Signal Processing, vol. 50, no. 2, pp. 425-437,
    2002, doi: 10.1109/78.978396\.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] F. Gustafsson 等人，“用于定位、导航和跟踪的粒子滤波器，”《IEEE信号处理学报》，第 50 卷，第 2 期，第 425-437
    页，2002年，doi: 10.1109/78.978396。'
- en: '[46] A. Censi, “An ICP variant using a point-to-line metric,” in 2008 IEEE
    International Conference on Robotics and Automation, Pasadena, CA, USA, 2008,
    pp. 19-25, doi: 10.1109/ROBOT.2008.4543181\.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] A. Censi，“一种使用点到线度量的 ICP 变体，”2008年IEEE国际机器人与自动化大会，位于美国加利福尼亚州帕萨迪纳，2008年，第
    19-25 页，doi: 10.1109/ROBOT.2008.4543181。'
- en: '[47] V. F. Leavers, D. Ben-Tzvi, M. B. Sandier, “A Dynamic Combinatorial Hough
    Transform for Straight Lines and Circles,” in Proceedings of the Alvey Vision
    Conference (AVC 1989), pp 28.1-28.6., 1989\.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] V. F. Leavers, D. Ben-Tzvi, M. B. Sandier，“用于直线和圆的动态组合霍夫变换，”《Alvey视觉会议论文集》（AVC
    1989），第 28.1-28.6 页，1989年。'
- en: '[48] G. Bradski, “The OpenCV Library,” in Dr. Dobb’s Journal of Software Tools,
    vol. 4, Nov. 2000, Art. no. 2236121\.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] G. Bradski，“OpenCV 库，”《Dr. Dobb''s 软件工具杂志》，第 4 卷，2000年11月，文章编号2236121。'
- en: '[49] S. Karaman, M. R. Walter, A. Perez, E. Frazzoli, S. Teller, “Anytime Motion
    Planning using the RRT*,” in IEEE International Conference on Robotics and Automation
    (IEEE, 2011), Shanghai, China, 2011, pp 1478-1483, doi: 10.1109/ICRA.2011.5980479\.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] S. Karaman, M. R. Walter, A. Perez, E. Frazzoli, S. Teller, “使用RRT*进行任意时刻的运动规划”，载于IEEE国际机器人与自动化会议（IEEE，2011），中国上海，2011年，页1478-1483，doi:
    10.1109/ICRA.2011.5980479。'
- en: '[50] C. G. Lo Bianco, “Minimum-Jerk Velocity Planning for Mobile Robot Applications,”
    in IEEE Transactions on Robotics (IEEE, 2013), vol. 29, no. 5, pp. 1317-1326,
    doi: 10.1109/TRO.2013.2262744\.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] C. G. Lo Bianco, “面向移动机器人应用的最小抖动速度规划”，载于《IEEE机器人学报》（IEEE，2013），第29卷，第5期，页1317-1326，doi:
    10.1109/TRO.2013.2262744。'
- en: '[51] D. Faconti, M. Colledanchise. “BehaviorTree.CPP”. GitHub.com. [https://github.com/BehaviorTree/BehaviorTree.CPP](https://github.com/BehaviorTree/BehaviorTree.CPP)
    (accessed Nov. 2, 2023).'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] D. Faconti, M. Colledanchise. “BehaviorTree.CPP”。GitHub.com. [https://github.com/BehaviorTree/BehaviorTree.CPP](https://github.com/BehaviorTree/BehaviorTree.CPP)（访问日期：2023年11月2日）。'
- en: '[52] E. J. Hu et al., “LoRA: Low-Rank Adaptation of Large Language Models,”
    2021, arXiv:2106.09685\.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] E. J. Hu 等，“LoRA：大型语言模型的低秩自适应”，2021年，arXiv:2106.09685。'
- en: '[53] G. Pu, A. Jain, J. Yin, R. Kaplan, “Empirical Analysis of the Strengths
    and Weaknesses of PEFT Techniques for LLMs,” 2023, arXiv:2304.14999\.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] G. Pu, A. Jain, J. Yin, R. Kaplan, “PEFT技术在LLMs中的优缺点的实证分析”，2023年，arXiv:2304.14999。'
- en: '[54] T. Brown, “Language models are few-shot learners,” in Advances in neural
    information processing systems, vol. 33, Dec. 2020, pp. 1877-1901\.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] T. Brown, “语言模型是少量示例学习者”，载于《神经信息处理系统进展》，第33卷，2020年12月，页1877-1901。'
- en: '| ![[Uncaptioned image]](img/21f32cbcf9dbfb6303fdf08550b10b6e.png) | Artem
    Lykov graduated with honors from the Bauman Moscow State Technical University
    in 2022 and received the B.Sc. degree in Robotic Systems and Mechatronics. He
    is currently pursuing his Master’s degree at the Skolkovo Institute of Science
    and Technology, in the Engineering Systems department, Robotics track. He conducts
    research and development in the field of LLM-based robots with AI in the Intelligent
    Space Robotics Laboratory. His research interests include AI, LLM, multi-agent
    robotic systems, autonomous robots, human-robot interaction and haptics. Artem
    received Best Paper Award at Asia Haptics conference in 2022\. As a member of
    the Reset team of the Skolkovo Institute of Science and Technology, in 2023 he
    won the champion title at the national stage of the Eurobot robotics competition.
    |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/21f32cbcf9dbfb6303fdf08550b10b6e.png) | 阿尔忒弥·利科夫（Artem Lykov）于2022年以优异成绩毕业于莫斯科鲍曼国立技术大学，并获得机器人系统与机电一体化专业的学士学位。他目前正在斯科尔科沃科技学院攻读硕士学位，专业方向为工程系统系中的机器人学方向。他在智能空间机器人实验室从事基于大型语言模型（LLM）的AI机器人研究与开发。他的研究兴趣包括人工智能（AI）、大型语言模型（LLM）、多智能体机器人系统、自动化机器人、人机交互和触觉学。阿尔忒弥在2022年亚洲触觉学大会上获得最佳论文奖。作为斯科尔科沃科技学院Reset团队的成员，2023年他在欧洲机器人竞赛（Eurobot）全国赛中获得冠军。'
- en: '| ![[Uncaptioned image]](img/713874ea570071e7ae520a55af4aa9ee.png) | Maria
    Dronova graduated with honors from the Bauman Moscow State Technical University
    in 2022 and received the B.Sc. degree in Rocket and Space Technology. Enrolled
    in 2022 in the Master’s program at the Skolkovo Institute of Science and Technology
    in the Engineering Systems department, Robotics track. Maria, as the member of
    ReSET Skoltech team, became the champion of Eurobot Russia 2023, prestigious autonomous
    robot competition. She is the author of 5 papers, her research interests lay in
    the field of drones, path planning algorithms and deep learning. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注图片]](img/713874ea570071e7ae520a55af4aa9ee.png) | 玛丽亚·德罗诺娃（Maria Dronova）于2022年以优异成绩毕业于莫斯科鲍曼国立技术大学，获得火箭与空间技术专业的学士学位。2022年，她加入斯科尔科沃科技学院，攻读工程系统系机器人学方向的硕士课程。作为ReSET斯科尔科沃团队的成员，玛丽亚在2023年欧洲机器人俄罗斯赛（Eurobot
    Russia）中获得了冠军，她在这项权威的自动化机器人竞赛中表现出色。她是5篇论文的作者，研究兴趣包括无人机、路径规划算法和深度学习。'
- en: '| ![[Uncaptioned image]](img/69973e1d74927ecbe21baf153b6bcb24.png) | Nikolay
    Naglov graduated with honors from the Saratov State Technical University in 2022
    and received the B.Sc. degree in Mechatronics and Robotics. He is currently pursuing
    his Master’s degree at the Skolkovo Institute of Science and Technology, in the
    Engineering Systems department, Robotics track. His research interests include
    navigation of autonomous mobile robots, human-robot interaction, AI and LLM. Nikolay
    is the champion of Eurobot Russia 2023 autonomous mobile robot competition as
    a member of RESET Skoltech team. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/69973e1d74927ecbe21baf153b6bcb24.png) | 尼古拉·纳格洛夫于2022年以优异的成绩毕业于萨拉托夫州立技术大学，获得了机电一体化与机器人学的学士学位。目前，他正在斯科尔科沃科技学院攻读硕士学位，专注于工程系统专业，机器人方向。他的研究兴趣包括自主移动机器人导航、人与机器人互动、人工智能和大型语言模型（LLM）。尼古拉作为RESET
    Skoltech团队的一员，赢得了2023年Eurobot俄罗斯赛自主移动机器人竞赛的冠军。 |'
- en: '| ![[Uncaptioned image]](img/72f59ae552d8ff262c02a4a7c229b8af.png) | Mikhail
    Litvinov received his Bachelor’s degree in Radio Engineering and Computer Technology
    from the Moscow Institute of Physics and Technology. He is currently pursuing
    his Master’s degree at the Skolkovo Institute of Science and Technology, in the
    Intelligent Space Robotics Laboratory. Mikhail was a part of the ReSET team that
    became the champion of Eurobot Russia 2023, respectable autonomous robot competition.
    His research interests include autonomous mobile robotics, human-robot interaction,
    computer vision, and deep learning. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/72f59ae552d8ff262c02a4a7c229b8af.png) | 米哈伊尔·利特维诺夫在莫斯科物理技术学院获得了无线电工程和计算机技术的学士学位。目前，他正在斯科尔科沃科技学院攻读硕士学位，研究方向为智能空间机器人实验室。米哈伊尔曾是ReSET团队的一员，该团队在2023年赢得了Eurobot俄罗斯赛的冠军，这是一个备受尊敬的自动化机器人竞赛。他的研究兴趣包括自主移动机器人、人与机器人互动、计算机视觉和深度学习。
    |'
- en: '| ![[Uncaptioned image]](img/a546df1454c579de06fc855018104601.png) | Sergei
    Satsevich graduated from Bauman Moscow State Technical University in 2019 with
    an M.Sc. degree in Wheeled Vehicles. Subsequently, he worked in the aerospace
    industry as an mechanical engineer. Presently, he is pursuing a Master’s degree
    at the Skolkovo Institute of Science and Technology in the Engineering Systems
    department, specializing in the Robotics track. His research interests encompass
    autonomous robots, legged robots, drones, soft robotics, control engineering,
    and reinforcement learning. Being part of the Reset team at the Skolkovo Institute
    of Science and Technology, he secured the championship title during the national
    round of the Eurobot robotics competition in 2023. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/a546df1454c579de06fc855018104601.png) | 谢尔盖·萨茨维奇于2019年毕业于莫斯科鲍曼国立技术大学，获得了轮式车辆的硕士学位。随后，他在航空航天工业担任机械工程师。现在，他在斯科尔科沃科技学院攻读硕士学位，专注于工程系统专业，机器人方向。他的研究兴趣涵盖了自主机器人、步态机器人、无人机、软体机器人、控制工程和强化学习。作为斯科尔科沃科技学院ReSET团队的一员，他在2023年Eurobot机器人竞赛的全国赛中获得了冠军。
    |'
- en: '| ![[Uncaptioned image]](img/248928fe3d804fd634e7afcb32359e2b.png) | Artem
    Bazhenov graduated from Gubkin University as a mechanical engineer, then gained
    work experience in the oil and gas industry and is now a master’s student at Skoltech.
    He has created several mechanical design for devices, more than 15 different electronic
    devices of high complexity with PCB boards, and has a strong background not only
    in engineering, but also in Deep Learning. His research interests include LLM-based
    robotics control, Reinforcement-Learning, human-robot interaction. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/248928fe3d804fd634e7afcb32359e2b.png) | 阿尔乔姆·巴热诺夫毕业于古比金大学，获得机械工程师学位，随后在石油和天然气行业积累了工作经验，现在是斯科尔科沃科技学院的硕士生。他设计了多种机械设备，创造了超过15种不同的高复杂度电子设备，具备强大的工程背景，同时也在深度学习领域有着扎实的基础。他的研究兴趣包括基于大型语言模型（LLM）的机器人控制、强化学习以及人与机器人互动。
    |'
- en: '| ![[Uncaptioned image]](img/12ba80f1104d9f1081dcdab47984c464.png) | Vladimir
    Berman graduated with honors from Bauman Moscow State Technical University in
    the field of Biomedical Technologies. Currently, he is pursuing a Master’s degree
    in Robotics at the Skolkovo Institute of Science and Technology. His research
    activities encompass Deep Learning, Reinforcement Learning, Natural Language Processing
    and Robotics Transformers in multi-agent systems. Additionally, he has a background
    in electronics and backend development. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/12ba80f1104d9f1081dcdab47984c464.png) | Vladimir Berman毕业于莫斯科鲍曼国立技术大学，获得生物医学技术领域的优等学位。目前，他正在斯科尔科沃科技学院攻读机器人学硕士学位。他的研究方向涵盖深度学习、强化学习、自然语言处理和多智能体系统中的机器人转换器。此外，他还具有电子学和后端开发的背景。
    |'
- en: '| ![[Uncaptioned image]](img/f7a2365e76fd56b5b855d2a991892708.png) | Aleksei
    Shcherbak is a PhD student of Skolkovo Institute of Science and Technology (Skoltech),
    Russia. Aleksei received his MSc degree in Physics at Moscow State University,
    Physics department, Russia, in 2019\. His research interests include wearable
    sensing, robotics, electronics development, firmware development, computationals
    and machine learning in medical related applications. Aleksei is the champion
    of Eurobot Russia 2022 and 2023 autonomous mobile robot competition as a member
    of RESET Skoltech team. |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/f7a2365e76fd56b5b855d2a991892708.png) | Aleksei Shcherbak是俄罗斯斯科尔科沃科技学院（Skoltech）的博士生。Aleksei于2019年在莫斯科国立大学物理系获得物理学硕士学位。他的研究兴趣包括可穿戴传感器、机器人技术、电子开发、固件开发、计算和机器学习在医学相关应用中的应用。Aleksei是2022年和2023年欧洲机器人俄罗斯赛自走式移动机器人竞赛的冠军，代表RESET
    Skoltech团队参加比赛。 |'
- en: '| ![[Uncaptioned image]](img/34cb4bdc203ab662366b110be10e3105.png) | Dzmitry
    Tsetserukou received the Ph.D. degree in Information Science and Technology from
    the University of Tokyo, Japan, in 2007\. From 2007 to 2009, he was a JSPS Post-Doctoral
    Fellow at the University of Tokyo. He worked as Assistant Professor at the Electronics-Inspired
    Interdisciplinary Research Institute, Toyohashi University of Technology from
    2010 to 2014\. From August 2014 he works at Skolkovo Institute of Science and
    Technology as Associate Professor and Head of Intelligent Space Robotics Laboratory.
    Dzmitry is a member of the Institute of Electrical and Electronics Engineers (IEEE)
    since 2006 and the author of 128 scientific papers indexed in Scopus, 10 patents,
    and a book. His research interests include autonomous robots, swarm of drones,
    LLM, AI, human-robot interaction, haptic and tactile displays. In 2023 he was
    awarded by Elsevier (Scopus) the rank of top 2% of the world’s most cited researchers.
    Dzmitry received such prestigious Awards as Best Paper Award (Asia Haptics 2022),
    Finalist of Franklin V. Taylor Memorial Award (IEEE SMC 2021), Best Demonstration
    Award (ACM SIGGRAPH Asia 2019), Best Demonstration Award (Bronze Prize AsiaHaptics
    2018), Laval Virtual Awards (ACM SIGGRAPH 2016), and a Best Paper Award (ACM Augmented
    Human 2010). Team ReSet of Skoltech supervised by Dzmitry became the 7-time Champions
    of Russia in autonomous robot competition Eurobot (2016-2023) and vice-champions
    of the Eurobot World in 2019, France. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| ![[未标注的图片]](img/34cb4bdc203ab662366b110be10e3105.png) | Dzmitry Tsetserukou于2007年获得东京大学信息科学与技术博士学位。2007年至2009年，他在东京大学担任JSPS博士后研究员。2010年至2014年，他在丰桥技术大学电子启发跨学科研究所担任助理教授。从2014年8月起，他在斯科尔科沃科技学院担任副教授，并担任智能空间机器人实验室主任。Dzmitry自2006年起是电气和电子工程师协会（IEEE）会员，已发表128篇被Scopus收录的学术论文，拥有10项专利和一本书。他的研究兴趣包括自主机器人、无人机群体、LLM、人工智能、人机交互、触觉和触觉显示技术。2023年，他被Elsevier（Scopus）授予全球最受引用研究者前2%的荣誉。Dzmitry获得过许多著名奖项，包括最佳论文奖（Asia
    Haptics 2022）、Franklin V. Taylor纪念奖决赛入围者（IEEE SMC 2021）、最佳演示奖（ACM SIGGRAPH Asia
    2019）、最佳演示奖（铜奖AsiaHaptics 2018）、Laval Virtual奖（ACM SIGGRAPH 2016）以及最佳论文奖（ACM Augmented
    Human 2010）。在Dzmitry的指导下，斯科尔科沃科技学院的ReSet团队连续七次获得俄罗斯欧罗巴自走式机器人竞赛冠军（2016-2023），并在2019年法国获得欧罗巴世界赛亚军。'
