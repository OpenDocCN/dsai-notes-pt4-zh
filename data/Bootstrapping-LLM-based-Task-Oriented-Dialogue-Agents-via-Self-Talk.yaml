- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:58:57'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:58:57
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于自我对话的LLM任务导向对话代理的引导
- en: 来源：[https://arxiv.org/html/2401.05033/](https://arxiv.org/html/2401.05033/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2401.05033/](https://arxiv.org/html/2401.05033/)
- en: \pdfcolInitStack
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \pdfcolInitStack
- en: tcb@breakable
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: tcb@breakable
- en: Dennis Ulmer^( , \faCompass, \faFlag)    Elman Mansimov^(\faAmazon)    Kaixiang
    Lin^(\faAmazon)    Justin Sun^(\faAmazon)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Dennis Ulmer^( , \faCompass, \faFlag)    Elman Mansimov^(\faAmazon)    Kaixiang
    Lin^(\faAmazon)    Justin Sun^(\faAmazon)
- en: Xibin Gao^(\faAmazon)    Yi Zhang^(\faAmazon)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Xibin Gao^(\faAmazon)    Yi Zhang^(\faAmazon)
- en: ^(\faCompass) IT University of Copenhagen ^(\faFlag) Pioneer Centre for Artificial
    Intelligence
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ^(\faCompass) 哥本哈根IT大学 ^(\faFlag) 人工智能先锋中心
- en: ^(\faAmazon) AWS AI Labs
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ^(\faAmazon) AWS AI实验室
- en: mansimov@amazon.com   Work conducted during an internship at Amazon.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: mansimov@amazon.com    这项工作是在亚马逊的实习期间进行的。
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Large language models (LLMs) are powerful dialogue agents, but specializing
    them towards fulfilling a specific function can be challenging. Instructing tuning,
    i.e. tuning models on instruction and sample responses generated by humans (Ouyang
    et al., [2022](#bib.bib26)), has proven as an effective method to do so, yet requires
    a number of data samples that a) might not be available or b) costly to generate.
    Furthermore, this cost increases when the goal is to make the LLM follow a specific
    workflow within a dialogue instead of single instructions. Inspired by the self-play
    technique in reinforcement learning and the use of LLMs to simulate human agents,
    we propose a more effective method for data collection through LLMs engaging in
    a conversation in various roles. This approach generates a training data via "self-talk"
    of LLMs that can be refined and utilized for supervised fine-tuning. We introduce
    an automated way to measure the (partial) success of a dialogue. This metric is
    used to filter the generated conversational data that is fed back in LLM for training.
    Based on our automated and human evaluations of conversation quality, we demonstrate
    that such self-talk data improves results. In addition, we examine the various
    characteristics that showcase the quality of generated dialogues and how they
    can be connected to their potential utility as training data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是强大的对话代理，但将其专业化以执行特定功能可能具有挑战性。指令调优，即基于人类生成的指令和示例响应来调优模型（Ouyang等，
    [2022](#bib.bib26)），已被证明是一种有效的方法，但这需要大量的数据样本，这些样本 a) 可能不可用，或者 b) 生成成本高昂。此外，当目标是让LLM在对话中遵循特定工作流，而不是单一指令时，成本会进一步增加。受强化学习中的自我对弈技术和使用LLMs模拟人类代理的启发，我们提出了一种更有效的数据收集方法，即通过LLMs在不同角色中的对话来收集数据。这种方法通过LLMs的“自我对话”生成训练数据，可以用来进行监督微调。我们引入了一种自动化方式来衡量对话的（部分）成功。这一度量用于过滤生成的对话数据，并将其反馈给LLM进行训练。根据我们对对话质量的自动化和人工评估，我们证明了这种自我对话数据能提高结果。此外，我们还考察了生成对话的各种特征，并探讨了如何将这些特征与其作为训练数据的潜在用途联系起来。
- en: 1 Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: LLMs have recently proven their viability to be deployed as conversational agents
    in a variety of scenarios, promising novel possibilities in user-facing applications,
    such as working as a personal assistant or customer support. In these scenarios,
    dialogue agents have to be able to quickly adapt to new tasks, which in the current
    paradigm implies either the use of already-existing or the creation of new datasets.
    Naturally, this can become a prohibitive constraint in terms of feasibility, time,
    and resources. Furthermore, avoiding finetuning by using prompting to elicit a
    certain behavior can prove brittle and unreliable - while it still might work
    in some instances, there is no guarantee for robustness or consistency.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）最近已证明它们可以作为对话代理在多种场景中部署，展示了在面向用户的应用中开辟新可能性，比如作为个人助手或客户支持。在这些场景中，对话代理必须能够迅速适应新任务，这在当前的范式下意味着要么使用现有数据，要么创建新的数据集。自然，这在可行性、时间和资源方面可能成为一个巨大的限制。此外，通过使用提示引导某种行为以避免微调可能会证明是脆弱且不可靠的——尽管在某些情况下可能仍然有效，但并不能保证其健壮性或一致性。
- en: '![Refer to caption](img/c39ce5cd94080a656fbae9dd720963cb.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c39ce5cd94080a656fbae9dd720963cb.png)'
- en: 'Figure 1: Schematic representation of our approach. Two LLMs, called a *client*
    and an *agent*, are prompted to converse with each other in different roles, with
    the agent asked to follow a specific narrative structure. Generated conversations
    will then be filtered by quality and used for supervised finetuning on the agent
    model until it adapts to the intended dialogue structure.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们方法的示意图。两个大型语言模型（LLM），分别称为*客户端*和*代理*，被提示以不同的角色进行对话，代理被要求遵循特定的叙事结构。生成的对话将经过质量筛选，并用于对代理模型进行监督微调，直到它适应预期的对话结构。
- en: 'In reinforcement learning (RL) for games, self-play has proven to be an effective
    mean to bootstrap powerful systems that can beat human experts (Silver et al.,
    [2016](#bib.bib41)), even when no initial human-generated data (Silver et al.,
    [2017](#bib.bib42)) or rules (Schrittwieser et al., [2020](#bib.bib36)) are supplied.
    At the same time, increasingly sized language models trained with growing datasets
    have shown to develop limited but notable extents of language abilities (Hu and
    Levy, [2023](#bib.bib20)) and some degree of *theory-of-mind*, i.e. reasoning
    over other agents, their behavior and the world state (Sap et al., [2022](#bib.bib33)).
    This has prompted studies in which they simulate single users (Liu et al., [2022](#bib.bib23);
    Argyle et al., [2023](#bib.bib2)) or even interacting groups of agents (Liu et al.,
    [2023](#bib.bib24); Park et al., [2023](#bib.bib27)). Recent work by Gulcehre
    et al. ([2023](#bib.bib13)) also demonstrated how LLMs can be iteratively improved
    on their own, generating data for language modeling. We take these developments
    as encouragement to explore LLM self-*talk* as a way to bootstrap task-specific
    finetuning data from LLMs themselves. Specifically, we focus on task-oriented
    dialogue, a very relevant problem for applications such as customer service, pair
    programming and digital personal assistants. We propose the following procedure:
    Two versions of an LLMs take part in a dialogue, impersonating a client and an
    agent. Both are given a description of how to act within the dialogue: The client
    is given a persona and motivation, while the agent is equipped with a fixed set
    of behaviors, depending on the request of the agent. They then engage in a conversation,
    which is recorded as a potential training sample. Some of these conversations
    will be successful, however, many of them will not be useful, since they will
    be off-topic or of low-quality. For this reason, we employ an additional filtering
    step to avoid training the model on counterproductive samples. A schematic depiction
    of our method is shown in [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"). Our contributions are
    as follows: <svg class="ltx_picture" height="14.16" id="S1.p2.1.pic1" overflow="visible"
    version="1.1" width="14.16"><g color="#000000" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="translate(0,14.16) matrix(1 0 0 -1 0 0) translate(0,-2.62)
    translate(7.08,0) translate(0,7.08)"><g fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 -3.46 -4.46)"><foreignobject height="8.92" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="6.92">1</foreignobject></g></g></svg> We propose a new
    method to bootstrap training data for task-oriented dialogue agents. <svg class="ltx_picture"
    height="14.16" id="S1.p2.2.pic2" overflow="visible" version="1.1" width="14.16"><g
    color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,14.16)
    matrix(1 0 0 -1 0 0) translate(0,-2.62) translate(7.08,0) translate(0,7.08)"><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">2</foreignobject></g></g></svg>
    We explore different quality assurance options. <svg class="ltx_picture" height="14.16"
    id="S1.p2.3.pic3" overflow="visible" version="1.1" width="14.16"><g color="#000000"
    fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,14.16)
    matrix(1 0 0 -1 0 0) translate(0,-2.62) translate(7.08,0) translate(0,7.08)"><g
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">3</foreignobject></g></g></svg>
    We also introduce automated evaluation metrics to evaluate dialogue success and
    conversational consistency and <svg class="ltx_picture" height="14.16" id="S1.p2.4.pic4"
    overflow="visible" version="1.1" width="14.16"><g color="#000000" fill="#000000"
    stroke="#000000" stroke-width="0.4pt" transform="translate(0,14.16) matrix(1 0
    0 -1 0 0) translate(0,-2.62) translate(7.08,0) translate(0,7.08)"><g fill="#000000"
    stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -3.46 -4.46)"><foreignobject
    height="8.92" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="6.92">4</foreignobject></g></g></svg>
    assess our trained agents in a human evaluation study.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在游戏的强化学习（RL）中，自我对弈已被证明是一种有效的手段，可以启动强大的系统，这些系统能够击败人类专家（Silver 等人，[2016](#bib.bib41)），即使没有初始的人工生成数据（Silver
    等人，[2017](#bib.bib42)）或规则（Schrittwieser 等人，[2020](#bib.bib36)）。与此同时，随着数据集的不断增长，越来越大的语言模型展示出了有限但显著的语言能力（Hu
    和 Levy，[2023](#bib.bib20)）以及一定程度的*心智理论*，即对其他代理、其行为和世界状态的推理（Sap 等人，[2022](#bib.bib33)）。这促使了一些研究，模拟单一用户（Liu
    等人，[2022](#bib.bib23)；Argyle 等人，[2023](#bib.bib2)）或甚至互动的多代理群体（Liu 等人，[2023](#bib.bib24)；Park
    等人，[2023](#bib.bib27)）。Gulcehre 等人（[2023](#bib.bib13)）的最新研究也展示了如何通过迭代过程在没有外部干预的情况下改进大型语言模型（LLM），使其能够为语言建模生成数据。我们将这些发展视为鼓励，探索使用LLM自我*对话*的方式，从LLM本身获取任务特定的微调数据。具体而言，我们专注于面向任务的对话，这是一个与客户服务、配对编程和数字个人助手等应用密切相关的问题。我们提出以下程序：两个版本的LLM参与对话，分别扮演客户和代理角色。两者都被赋予了如何在对话中行动的描述：客户被赋予一个个性和动机，而代理则根据代理的请求被赋予一组固定的行为。然后，它们进行对话，记录为潜在的训练样本。这些对话中的一些会是成功的，然而，许多对话将没有用处，因为它们会偏离主题或质量较差。为此，我们采用额外的筛选步骤，以避免在无效的样本上训练模型。我们的方式的示意图见[图
    1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk")。我们的贡献如下：  '
- en: 2 Related Work
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Self-Play
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 自我对弈
- en: 'has been used extensively in RL for games to bootstrap powerful agents: Beginning
    with early successes in playing backgammon (Tesauro, [1994](#bib.bib44); Pollack
    and Blair, [1996](#bib.bib29)) and later Othello (Van Der Ree and Wiering, [2013](#bib.bib49)),
    further breakthroughs were not achieved until the arrival of AlphaGo (Silver et al.,
    [2016](#bib.bib41)), which was pre-trained on human expert moves before self-play.
    Following iterations of the system forwent the pre-training (Silver et al., [2017](#bib.bib42))
    and later even achieved super-human abilities on multiple games even without explicit
    knowledge of the rules (Schrittwieser et al., [2020](#bib.bib36)). In NLP, there
    has been some work with self-play for dialogue systems (Shah et al., [2018a](#bib.bib37),
    [b](#bib.bib38)), but these date back before the advent of conversational LLMs.
    Instead, these approaches rely on pre-defined task schemata and slot-filling used
    to generate conversations between a user and system bot, which are then rewritten
    and validated by crowdworkers. Thus, this still involves a considerable amount
    of human oversight and involvement.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习（RL）中，已广泛用于游戏中以启动强大的智能体：最早从象棋（Tesauro，[1994](#bib.bib44)；Pollack 和 Blair，[1996](#bib.bib29)）的成功开始，随后是奥赛罗（Van
    Der Ree 和 Wiering，[2013](#bib.bib49)），直到 AlphaGo 的出现（Silver 等人，[2016](#bib.bib41)），在自我对弈之前，AlphaGo
    已经过人类专家棋步的预训练。系统的后续迭代版本摒弃了预训练（Silver 等人，[2017](#bib.bib42)），并且后来甚至在没有明确规则知识的情况下，在多个游戏中展现出超人类能力（Schrittwieser
    等人，[2020](#bib.bib36)）。在自然语言处理（NLP）中，虽然曾有过一些使用自我对弈的对话系统研究（Shah 等人，[2018a](#bib.bib37)，[b](#bib.bib38)），但这些研究始于对话型大规模语言模型（LLMs）出现之前。相反，这些方法依赖于预定义的任务模式和槽填充，用于生成用户与系统机器人之间的对话，随后由群体工人进行重写和验证。因此，这仍然涉及大量的人工监督和参与。
- en: LLMs as Agents.
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: LLM 作为智能体。
- en: 'The quality of dialogue and reasoning in current LLMs also has enabled research
    on simulating human agents: For instance, Argyle et al. ([2023](#bib.bib2)) demonstrate
    that suitable prompts can make LLMs mimic the answers of different test subject
    demographics, and Liu et al. ([2022](#bib.bib23)) create a dialogue user-simulator.
    Liu et al. ([2023](#bib.bib24)) put LLM agents equipped with memory into a grid
    world and stimulate discussions between them about sensitive topics to aid the
    emergence of social norms. By further having LLMs act with different personas
    and enabling them to retrieving relevant memories, Park et al. ([2023](#bib.bib27))
    are able to simulate the social dynamics in a simulated village.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当前 LLM 中对话和推理的质量也使得模拟人类智能体的研究成为可能：例如，Argyle 等人（[2023](#bib.bib2)）展示了合适的提示可以使
    LLM 模拟不同测试对象群体的回答，而 Liu 等人（[2022](#bib.bib23)）则创建了一个对话用户模拟器。Liu 等人（[2023](#bib.bib24)）将配备记忆的
    LLM 智能体放入网格世界中，激发它们就敏感话题进行讨论，以促进社会规范的形成。通过进一步让 LLM 扮演不同的角色并使其能够检索相关记忆，Park 等人（[2023](#bib.bib27)）能够模拟一个虚拟村庄中的社会动态。
- en: LLM Self-Improvement.
  id: totrans-25
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: LLM 自我改进。
- en: 'While naïvely re-training a generative model on its own outputs might produce
    degenerate solutions (Alemohammad et al., [2023](#bib.bib1); Shumailov et al.,
    [2023](#bib.bib39)), LLMs have been successfully shown to produce data augmentations
    for other models (Yoo et al., [2021](#bib.bib51); Dai et al., [2023](#bib.bib6)).
    Furthermore, a recent line of work is exploring the limits of using LLMs to provide
    signal for their own training: Bai et al. ([2022](#bib.bib3)) partially automate
    the process of ranking model responses through human feedback by having models
    critique their generations according to different harmfulness criteria, while
    Scheurer et al. ([2023](#bib.bib35)) have the LLM generate multiple refinements
    of the output based on the human feedback. A further improvement in responses
    has been observed through the use of an external critique model (Paul et al.,
    [2023](#bib.bib28)), or through self-critiquing for a diverse set of tasks such
    as information extraction (Gero et al., [2023](#bib.bib12)), code generation (Chen
    et al., [2023](#bib.bib5)) and summarization (Saunders et al., [2022](#bib.bib34)).
    We see the recent work of Gulcehre et al. ([2023](#bib.bib13)) as closest to ours;
    the authors show how after generating data during a *grow* step, different tranches
    can be utilized to incrementally train the model during an *improve step*. In
    contrast, our approach focuses on a single improve step and employs a conceptually
    simpler supervised finetuning strategy over a RL objective. Furthermore, [Gulcehre
    et al.](#bib.bib13) focus their work on conditional language modeling, while we
    experiment within the domain of task-oriented dialogue. This also motivates our
    framework of using two separate models for the dialogue participants, albeit that
    it also admits the use of two copies of the same model (see next section).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在其自身输出上天真地重新训练生成模型可能会产生退化的解决方案（Alemohammad等，[2023](#bib.bib1)；Shumailov等，[2023](#bib.bib39)），但大语言模型已经成功地被证明可以为其他模型生成数据增强（Yoo等，[2021](#bib.bib51)；Dai等，[2023](#bib.bib6)）。此外，最近的研究工作正在探索利用大语言模型为其自身训练提供信号的限制：Bai等（[2022](#bib.bib3)）通过让模型根据不同的有害标准批评自己的生成，部分自动化了通过人工反馈对模型回应进行排序的过程，而Scheurer等（[2023](#bib.bib35)）则让大语言模型基于人工反馈生成多个改进版本。通过使用外部批评模型（Paul等，[2023](#bib.bib28)）或通过自我批评来处理信息抽取（Gero等，[2023](#bib.bib12)）、代码生成（Chen等，[2023](#bib.bib5)）和摘要生成（Saunders等，[2022](#bib.bib34)）等多种任务，已观察到回应的进一步改善。我们认为Gulcehre等（[2023](#bib.bib13)）的最新研究最接近我们的工作；作者展示了如何在*成长*步骤中生成数据后，通过不同的分批方式在*改进*步骤中逐步训练模型。相比之下，我们的方法专注于单一的改进步骤，并采用一种概念上更简单的监督微调策略，而非强化学习目标。此外，[Gulcehre等](#bib.bib13)的工作重点是条件语言建模，而我们则在面向任务的对话领域进行实验。这也激发了我们采用两个独立模型作为对话参与者的框架，尽管它也允许使用两个相同模型的副本（见下一节）。
- en: Task-oriented Dialogue & LLMs.
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 面向任务的对话与大语言模型（LLMs）。
- en: 'Lastly, the way we prompt our models to follow certain workflows is reminiscent
    of other works for task-oriented dialogue: Li et al. ([2022](#bib.bib21)) are
    able to simulate both agent and user through dynamically selected prompts. In
    Zhang et al. ([2023](#bib.bib52)), the authors guide LLMs through an external
    prompter module and generate queries to an external fact database that inform
    the final generation. Zhao et al. ([2022](#bib.bib54)) propose a programmable
    framework for dialogue flows which supplies the model with program logic, a corresponding
    ontology and previous conversational states for a reply. In comparison, our model
    does not rely on external models to achieve a certain behavior.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们提示模型遵循特定工作流程的方式让人联想到其他面向任务的对话工作：Li等（[2022](#bib.bib21)）能够通过动态选择的提示模拟代理和用户。在Zhang等（[2023](#bib.bib52)）的研究中，作者通过外部提示模块引导大语言模型，并生成查询外部事实数据库的请求，从而影响最终生成结果。Zhao等（[2022](#bib.bib54)）提出了一种可编程的对话流程框架，为模型提供程序逻辑、相应的本体和前置的对话状态，以便生成回复。相比之下，我们的模型不依赖于外部模型来实现某些行为。
- en: 'We take these research lines as encouraging pieces evidence for the following
    points: a) Neural networks, and particular conversational agents, can be used
    to bootstrap their own training data under certain conditions and b) LLMs have
    the ability to provide learning signals for themselves. These insights are synthesized
    into our proposed method.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些研究方向视为以下几点的有力证据：a) 神经网络，特别是对话代理，可以在特定条件下自我生成训练数据；b) 大语言模型具备为自己提供学习信号的能力。这些洞察被综合到我们提出的方法中。
- en: 3 Method
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 方法
- en: We first introduce some notation for our method. We start with two parameter
    vectors $\operatorname{\bm{\theta}}_{\text{client}}$ and $\operatorname{\bm{\theta}}_{\text{agent}}$
    of pretrained LLMs for the client and agent model, respectively. Since we might
    update the parameters multiple times, we denote $\operatorname{\bm{\theta}}_{\text{agent}}^{(0)}$
    / $\operatorname{\bm{\theta}}_{\text{client}}^{(0)}$ as the original parameters
    and $\operatorname{\bm{\theta}}_{\text{agent}}^{(t)}$ / $\operatorname{\bm{\theta}}_{\text{client}}^{(t)}$
    as the parameters at time step $t$ of our procedure. Next, we define two different
    prompts $\operatorname{\mathbf{pr}}_{\text{agent}}$ and $\operatorname{\mathbf{pr}}_{\text{client}}$
    that supply character descriptions and behavioral instruction to both models.
    These models together parameterize a distribution over possible dialogues $p(\operatorname{\mathbf{d}}|\operatorname{\bm{\theta}}_{\text{client}}^{(t)},%
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先介绍我们方法的一些符号。我们从两个预训练的LLM模型的参数向量 $\operatorname{\bm{\theta}}_{\text{client}}$
    和 $\operatorname{\bm{\theta}}_{\text{agent}}$ 开始，分别用于客户和代理模型。由于我们可能多次更新参数，我们将
    $\operatorname{\bm{\theta}}_{\text{agent}}^{(0)}$ / $\operatorname{\bm{\theta}}_{\text{client}}^{(0)}$
    表示为原始参数，并将 $\operatorname{\bm{\theta}}_{\text{agent}}^{(t)}$ / $\operatorname{\bm{\theta}}_{\text{client}}^{(t)}$
    表示为我们程序中时间步骤 $t$ 的参数。接下来，我们定义了两个不同的提示 $\operatorname{\mathbf{pr}}_{\text{agent}}$
    和 $\operatorname{\mathbf{pr}}_{\text{client}}$，它们为两个模型提供角色描述和行为指导。这些模型共同定义了一个可能对话的分布
    $p(\operatorname{\mathbf{d}}|\operatorname{\bm{\theta}}_{\text{client}}^{(t)},%
- en: \operatorname{\bm{\theta}}_{\text{agent}}^{(t)},\operatorname{\mathbf{pr}}_{%
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: \operatorname{\bm{\theta}}_{\text{agent}}^{(t)},\operatorname{\mathbf{pr}}_{%
- en: \text{agent}},\operatorname{\mathbf{pr}}_{\text{client}})$.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: \text{agent}},\operatorname{\mathbf{pr}}_{\text{client}})$。
- en: For our method in [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"), we now sample $N$ dialogues
    $\mathcal{D}^{(t)}=\{\operatorname{\mathbf{d}}_{1}^{(t)},\ldots,\operatorname{%
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们在[图1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk")中的方法，我们现在从 $N$ 个对话 $\mathcal{D}^{(t)}=\{\operatorname{\mathbf{d}}_{1}^{(t)},\ldots,\operatorname{%
- en: \mathbf{d}}_{N}^{(t)}\}$ from this distribution at every time step by having
    the models converse in roles specified by their prompts. While we can expect some
    of the generated dialogues to be successful given a sufficient model and high-quality
    prompts, there is no guarantee for them to achieve novel dialogue goals. For this
    reason, we employ a filter function to create a subset $\mathcal{D}^{(t)}_{\bigtriangledown}\subseteq\mathcal{D}^{(t)}$
    of the generated dialogues. An example for a filter would be to only include successful
    conversations, identified using a method we introduce later in [Section 4.1](#S4.SS1
    "4.1 Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"). The filtered examples are used to finetune the models
    by minimizing the negative log-likelihood
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{d}}_{N}^{(t)}\}$ 从这个分布中在每个时间步骤生成，通过让模型根据它们的提示进行指定角色的对话。尽管我们可以期望在给定足够的模型和高质量的提示下，一些生成的对话能够成功，但并不能保证它们能够实现新的对话目标。出于这个原因，我们使用过滤函数来创建一个生成对话的子集
    $\mathcal{D}^{(t)}_{\bigtriangledown}\subseteq\mathcal{D}^{(t)}$。一个过滤器的例子是只包含成功的对话，这些对话是通过我们稍后在[第4.1节](#S4.SS1
    "4.1 Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk")介绍的方法识别的。过滤后的示例用于通过最小化负对数似然来微调模型。
- en: '|  | $-\frac{1}{&#124;\mathcal{D}^{(t)}_{\bigtriangledown}&#124;}\sum_{\operatorname{\mathbf{d%
    }}^{(t)}\in\mathcal{D}^{(t)}_{\bigtriangledown}}\log p_{(\cdot)}\big{(}%'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '| | $-\frac{1}{|\mathcal{D}^{(t)}_{\bigtriangledown}|}\sum_{\operatorname{\mathbf{d%
    }}^{(t)}\in\mathcal{D}^{(t)}_{\bigtriangledown}}\log p_{(\cdot)}\big{(}%'
- en: \operatorname{\mathbf{d}}^{(t)}\big{&#124;}\operatorname{\bm{\theta}}_{(\cdot)}^{(t%
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: \operatorname{\mathbf{d}}^{(t)}\big{|}\operatorname{\bm{\theta}}_{(\cdot)}^{(t%
- en: )}),$ |  | (1) |
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: )})，| |（1）|
- en: 'where after finetuning, we obtain a new parameter set $\operatorname{\bm{\theta}}_{(\cdot)}^{(t+1)}$,
    with which we can start the process again. This framework allows many different
    variations: $\operatorname{\bm{\theta}}_{\text{agent}}$ and $\operatorname{\bm{\theta}}_{\text{client}}$
    can be copies of the same or different model; we can finetune one or both copies.
    We use different models for agent and client, and do not update the client model
    $(\operatorname{\bm{\theta}}_{\text{client}}^{(t)}=\operatorname{\bm{\theta}}_{%'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 微调后，我们获得一组新的参数 $\operatorname{\bm{\theta}}_{(\cdot)}^{(t+1)}$，并可以再次开始这一过程。这个框架支持多种不同的变体：$\operatorname{\bm{\theta}}_{\text{agent}}$
    和 $\operatorname{\bm{\theta}}_{\text{client}}$ 可以是相同或不同模型的副本；我们可以微调一个或两个副本。我们使用不同的模型作为代理和客户，并且不更新客户模型
    $(\operatorname{\bm{\theta}}_{\text{client}}^{(t)}=\operatorname{\bm{\theta}}_{%
- en: \text{client}}^{(0)}$).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: \text{client}}^{(0)}$）。
- en: 3.1 Prompt Design
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 提示设计
- en: '![Refer to caption](img/63c38dca46766ef548deebd01df22d19.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/63c38dca46766ef548deebd01df22d19.png)'
- en: 'Figure 2: Illustration of the structured prompting: Workflows are parsed into
    a directed graph (left). At every turn of the conversation, we ask a LLM to compare
    the client’s last utterance with the reference responses corresponding the outgoing
    edges of the current node. If one of them is chosen, we continue with the next
    node in the graph and prompt the agent with the corresponding question next turn,
    otherwise we stay in the same place and in graph and let the model generate freely.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：结构化提示的示意图：工作流被解析为有向图（左图）。在每一轮对话中，我们要求 LLM 比较客户的最后一句话与当前节点出边对应的参考回复。如果选择了其中一个回复，我们就继续沿着图中的下一节点并提示代理下一个问题，否则我们停留在同一位置并允许模型自由生成。
- en: In order to obtain both successful conversations for finetuning that are also
    sufficiently diverse, we dedicate special care to the design of the prompts $\operatorname{\mathbf{pr}}_{\text{agent}}$
    and $\operatorname{\mathbf{pr}}_{\text{client}}$, which we lay out next.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得既能成功微调对话又足够多样化的对话，我们特别关注代理提示 $\operatorname{\mathbf{pr}}_{\text{agent}}$
    和客户提示 $\operatorname{\mathbf{pr}}_{\text{client}}$ 的设计，接下来我们将详细介绍。
- en: Agent & Client Prompts.
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代理和客户提示。
- en: We create dialogues by prompting both client and agent with a character role,
    a persona, the dialogue history so far and the intention for the client as well
    as instructions for the agent. The different combinations of characters, intentions
    and the stochastic nature of the generation thus creates a variety of scenarios.
    The prompts are described in detail in [Section A.2](#A1.SS2 "A.2 Self-talk Loop
    ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk").
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过提示客户和代理角色、个性、到目前为止的对话历史、客户的意图以及代理的指令来创建对话。角色、意图的不同组合以及生成的随机性产生了多种场景。这些提示在
    [Section A.2](#A1.SS2 "A.2 Self-talk Loop ‣ Appendix A Implementation Details
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk") 中有详细描述。
- en: Structured Prompting.
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结构化提示。
- en: 'In preliminary experiments, we found our models struggling to follow provided
    workflows, which we mostly attribute to model size and quality of the underlying
    pretraining data. This negatively impacted the quality of bootstrapped conversations,
    providing a noisy training signal when finetuning the agent model. To mitigate
    this issue, we parse workflows into directed graphs $\mathcal{G}=\{\mathcal{V},\mathcal{E}\}$,
    in which vertices $\mathcal{V}$ correspond to questions of the agent and edges
    $\mathcal{E}$ to pre-defined reference answers of the client. Based on these,
    we propose *structured prompting*, which we show in [Figure 2](#S3.F2 "Figure
    2 ‣ 3.1 Prompt Design ‣ 3 Method ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"): At every step of the conversation, we consider the node
    of the last agent utterance $\operatorname{\mathbf{v}}_{i}\in\mathcal{V}$ and
    provide a LLM with a set of suggested client responses that correspond to $\operatorname{\mathbf{v}}_{i}$’s
    outgoing edges and ask it to select the option that comes closest to the client’s
    actual response (including a “None of the above” option). We then prompt the agent
    with the next question that follows from this response before the next turn and
    move up in the graph to the next node $\operatorname{\mathbf{v}}_{\text{next}}\in\text{Children}(\operatorname{%'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在初步实验中，我们发现我们的模型难以遵循提供的工作流，这主要归因于模型的规模和基础预训练数据的质量。这对启动对话的质量产生了负面影响，在微调代理模型时提供了噪声训练信号。为了解决这个问题，我们将工作流解析为有向图
    $\mathcal{G}=\{\mathcal{V},\mathcal{E}\}$，其中顶点 $\mathcal{V}$ 对应于代理的提问，边 $\mathcal{E}$
    对应于客户的预定义参考答案。基于这些，我们提出了*结构化提示*，如下图 [Figure 2](#S3.F2 "Figure 2 ‣ 3.1 Prompt Design
    ‣ 3 Method ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")
    所示：在对话的每一步，我们考虑上一个代理发言的节点 $\operatorname{\mathbf{v}}_{i}\in\mathcal{V}$，并向 LLM
    提供一组建议的客户回复，这些回复与 $\operatorname{\mathbf{v}}_{i}$ 的出边相对应，并要求它选择最接近客户实际回复的选项（包括“以上都不是”选项）。然后，我们根据这个回复提示代理下一个问题，并在图中向上移动到下一个节点
    $\operatorname{\mathbf{v}}_{\text{next}}\in\text{Children}(\operatorname{%
- en: \mathbf{v}}_{i})$ until the conversation ends or a leaf node in the graph is
    reached. We show the full prompt in [Section A.2](#A1.SS2 "A.2 Self-talk Loop
    ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk").
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{v}}_{i})$，直到对话结束或图中的叶节点被触及。我们在[第 A.2 节](#A1.SS2 "A.2 自我对话循环 ‣ 附录 A 实施细节
    ‣ 通过自我对话启动基于 LLM 的任务导向对话代理")展示了完整的提示。
- en: 4 Experiments
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 个实验
- en: Dataset.
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据集。
- en: For the characters that the LLMs are supposed to embody in our conversations,
    we source descriptions from the LIGHT dataset by (Urbanek et al., [2019](#bib.bib48)).
    Originally used for agents that solve tasks in a fantasy-world environment, it
    contains different 7487 quest descriptions, including characters and their personas.
    For instance, the role of genie from the lamp has the persona of *“I am a genie
    and I enjoy playing tricks on those who release me from my lamp. I was imprisoned
    in this lamp by an evil witch. I am very bitter that I have to spend my days as
    a prisoner”*. We choose a set of five characters for potential roles of the agent
    (shop keeper, doctor, witch, tavern owner, genie from lamp) and select another
    set of the $16$ most frequently occurring characters as potential clients (see
    [Section A.1](#A1.SS1 "A.1 Data Creation ‣ Appendix A Implementation Details ‣
    Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")). To create
    dialogue workflows, we then then prompt a 13 billion parameter OpenLlama variant
    (Touvron et al., [2023](#bib.bib46); Together Computer, [2023](#bib.bib45); Geng
    and Liu, [2023](#bib.bib11))¹¹1Available under [https://huggingface.co/VMware/open-llama-13b-open-instruct](https://huggingface.co/VMware/open-llama-13b-open-instruct).
    to generate three distinct workflows per agent character respectively including
    four, six and seven questions, which are then manually edited for quality. An
    overview and sample of these workflows is presented in [Section A.1](#A1.SS1 "A.1
    Data Creation ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk").
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们希望 LLM 在对话中体现的角色，我们从 LIGHT 数据集（Urbanek 等， [2019](#bib.bib48)）中获取了描述。该数据集最初用于解决幻想世界环境中的任务代理，包含了
    7487 个不同的任务描述，其中包括角色及其个性。例如，来自灯中的精灵角色，其个性为 *“我是一个精灵，我喜欢捉弄那些释放我出灯的人。我被一个邪恶的巫婆囚禁在这个灯中。我非常愤怒，因为我必须将余生度过在灯中做囚徒”*。我们选择了五个角色作为代理的潜在角色（商店老板、医生、巫婆、酒馆老板、灯中的精灵），并选择了另外一组
    $16$ 个最常见的角色作为潜在客户（见[第 A.1 节](#A1.SS1 "A.1 数据创建 ‣ 附录 A 实施细节 ‣ 通过自我对话启动基于 LLM 的任务导向对话代理")）。为了创建对话流程，我们接着提示一个包含
    130 亿参数的 OpenLlama 变体（Touvron 等， [2023](#bib.bib46); Together Computer，[2023](#bib.bib45);
    Geng 和 Liu，[2023](#bib.bib11))¹¹1 可在 [https://huggingface.co/VMware/open-llama-13b-open-instruct](https://huggingface.co/VMware/open-llama-13b-open-instruct)
    获取。生成每个代理角色的三个不同工作流程，分别包含四个、六个和七个问题，然后手动编辑以确保质量。这些工作流程的概述和示例展示在[第 A.1 节](#A1.SS1
    "A.1 数据创建 ‣ 附录 A 实施细节 ‣ 通过自我对话启动基于 LLM 的任务导向对话代理")中。
- en: Self-talk Loop.
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 自我对话循环。
- en: For the self-talk loop in [Figure 1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"), we choose the 30 billion
    parameter MosaicAI chat model (MosaicML NLP Team, [2023](#bib.bib25)) for the
    client and the 7 billion parameter model from the same family for the agent. We
    found the client model to already work quite consistently using only prompting,
    so we choose to only finetune the agent model. For every dialogue generation round,
    we first sample at random a client character, and agent character and a corresponding
    agent workflow. Then, we generate the conversation utterance by utterance for
    up to eight turns (one turn including one utterance per character). We also check
    whether a conversation has ended by using a combination of string matching and
    prompting a LLM along with some postprocessing to ensure the quality of generation,
    all of which are described in [Section A.2](#A1.SS2 "A.2 Self-talk Loop ‣ Appendix
    A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk").
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于[图1](#S1.F1 "图1 ‣ 1 介绍 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中的自我对话循环，我们选择了具有300亿参数的MosaicAI聊天模型（MosaicML
    NLP团队，[2023](#bib.bib25)）作为客户端模型，并选择了来自同一家族的70亿参数模型作为代理。我们发现，客户端模型仅通过提示就能够稳定工作，因此我们决定仅对代理模型进行微调。在每次对话生成回合中，我们首先随机选择一个客户端角色、代理角色和相应的代理工作流程。然后，我们按顺序生成对话的每一句话，最多进行八轮对话（每轮包括每个角色的一句话）。我们还通过结合字符串匹配和提示LLM以及一些后处理步骤来检查对话是否结束，以确保生成的质量，所有这些内容在[附录A.2](#A1.SS2
    "A.2 自我对话循环 ‣ 附录A 实施细节 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中有详细描述。
- en: Filters.
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 过滤器。
- en: Generated dialogues are then filtered and used to finetune the agent model for
    a single epoch. We compare the impact of multiple different filtering procedures,
    with baselines using the entire generated set of dialogues for finetuning (None)
    and sampling a random $p$ % subset ($p$-Random). We also explore whether at least
    $k$ subgoals or $p$ % of subgoals in the workflow have been achieved ($k$-Subgoals
    and $p$-Subgoals, see next section).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的对话随后会经过过滤，并用于微调代理模型进行单轮训练。我们比较了不同过滤程序的影响，基准方法使用整个生成的对话集进行微调（None），并随机采样一个$p$%的子集（$p$-Random）。我们还探讨了在工作流程中是否至少完成了$k$个子目标或$p$%的子目标（$k$-Subgoals和$p$-Subgoals，见下一节）。
- en: 4.1 Evaluation
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 评估
- en: In order to assess the effectiveness of our approach, we evaluate it across
    the following axes.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们方法的有效性，我们从以下几个方面进行评估。
- en: Dialogue Diversity.
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话多样性。
- en: We measure the diversity of dialogues by tracking the number of unique words
    (# Words) and unique $n$-grams (#$n$-Grams; up to order 5). We also measure diversity
    by measuring the average pair-wise ROUGE-L between $25$ dialogues of the same
    character (Diversity).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过追踪独特词汇的数量（# Words）和独特的 $n$-gram（#$n$-Grams；最多到5阶）来衡量对话的多样性。我们还通过衡量同一角色的$25$个对话之间的平均成对ROUGE-L（多样性）来衡量多样性。
- en: Subgoal Completion.
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 子目标完成。
- en: But what makes a successful conversation? Ideally, the agent should be guided
    through the dialogue flows towards one of the possible conversation endings and
    achieve their initial objective (see [Section A.1](#A1.SS1 "A.1 Data Creation
    ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk") for some examples). Urbanek et al. ([2019](#bib.bib48))
    define quests in the form of directed graphs that are traversed by the agents
    choosing actions in the environment from a large but finite set. Since potential
    actions are in text generation are infinite, the decision of whether a certain
    step in the conversation has been reached is much harder to decide. For this reason,
    we use the same setup as in [Section 3.1](#S3.SS1 "3.1 Prompt Design ‣ 3 Method
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk") / [Figure 2](#S3.F2
    "Figure 2 ‣ 3.1 Prompt Design ‣ 3 Method ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk") to parse our dialogue flows into directed graphs
    as well, where every node is associated with an utterance by the agent. To decide
    whether to proceed along an edge, we compare whether the actual utterance of the
    agent and the reference utterance in the dialogue flow are similar enough. We
    measure this similarity by means of ROUGE-L (Lin, [2004](#bib.bib22)) as implemented
    by the evaluate package,²²2See [https://github.com/huggingface/evaluate](https://github.com/huggingface/evaluate).
    which is then compared against pre-defined thresholds. We explain how the initial
    thresholds are set on an external dataset in [Section A.3](#A1.SS3 "A.3 Automatic
    Evaluation ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk") and validate the soundness of these metrics at
    the end of this section. For evaluation purposes, we track whether the dialogue
    reached one of its possible endings (Dialogue Success) and the absolute number
    of fulfilled workflow steps as measured by the depth in the directed graph (Abs.
    Depth) and as a proportion of the maximum depth (Rel. Depth), so intuitively the
    relative completion of the workflow.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，成功的对话是什么样的呢？理想情况下，智能体应该通过对话流程被引导到可能的对话结局之一，并实现其初衷目标（具体示例请见[第A.1节](#A1.SS1
    "A.1 数据创建 ‣ 附录A 实现细节 ‣ 通过自我对话引导基于LLM的任务导向对话代理")）。Urbanek等人（[2019](#bib.bib48)）将任务定义为由智能体选择一组有限但庞大的环境动作来遍历的有向图。由于文本生成中的潜在动作是无限的，判断对话是否达到某个步骤就变得更加困难。为此，我们使用与[第3.1节](#S3.SS1
    "3.1 提示设计 ‣ 3 方法 ‣ 通过自我对话引导基于LLM的任务导向对话代理") / [图2](#S3.F2 "图2 ‣ 3.1 提示设计 ‣ 3 方法
    ‣ 通过自我对话引导基于LLM的任务导向对话代理")中相同的设置，将我们的对话流程也解析为有向图，其中每个节点都与智能体的发话相关联。为了决定是否沿着某个边继续，我们比较智能体的实际发话和对话流程中的参考发话是否足够相似。我们通过ROUGE-L（Lin，[2004](#bib.bib22)）测量这种相似度，该方法由evaluate包实现，²²2详情见[https://github.com/huggingface/evaluate](https://github.com/huggingface/evaluate)。然后，我们将其与预定义的阈值进行比较。我们在[第A.3节](#A1.SS3
    "A.3 自动评估 ‣ 附录A 实现细节 ‣ 通过自我对话引导基于LLM的任务导向对话代理")中解释了初始阈值是如何在外部数据集上设定的，并在本节末验证了这些度量的合理性。为了进行评估，我们跟踪对话是否达到了其中一个可能的结局（对话成功），并且衡量通过有向图的深度（绝对深度）和最大深度的比例（相对深度）来实现的工作流步骤数量，直观地说，即工作流的相对完成度。
- en: Character Consistency.
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**角色一致性**。'
- en: Another questions regards whether the client stays in character or ignores the
    prompt and generates irrelevant outputs. We take inspiration from the dungeon
    master model by Shuster et al. ([2020](#bib.bib40)) that was proposed to encourage
    human participants to role-play in dialogues. For that purpose, we finetune the
    DeBERTa v3 model (He et al., [2021a](#bib.bib15), [b](#bib.bib16)) on $200$k positive
    and $200$k negative examples using a simple binary cross-entropy objective. The
    LIGHT dataset contains episodes with dialogues corresponding to quests, and we
    use those to create positive examples by sampling an episode and grouping the
    character name and persona with a random utterance from the conversation. For
    negative examples, we sample a random utterance by a different character from
    another conversation conversation. In addition, we add all steps of our workflows
    to the training data and upsample them by a factor of $308$, resulting in around
    $500k$ training samples in total. More information on the training is given in
    [Section A.3](#A1.SS3 "A.3 Automatic Evaluation ‣ Appendix A Implementation Details
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"). In our
    experiments, we evaluate the character consistency by scoring each utterance using
    the dungeon master model and averaging the scores over the entire conversation
    (Char. Cons.).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是关于客户端是否保持角色设定，还是忽略提示并生成无关的输出。我们借鉴了Shuster等人提出的地下城主模型（[2020](#bib.bib40)），该模型旨在鼓励人类参与者在对话中进行角色扮演。为此，我们对DeBERTa
    v3模型（He等人，[2021a](#bib.bib15)，[b](#bib.bib16)）进行了微调，使用了$200$k正例和$200$k负例，并采用简单的二元交叉熵目标。LIGHT数据集包含与任务相关的对话片段，我们利用这些对话通过抽取一个片段并将角色名称和人格与对话中的随机发言组合来创建正例。对于负例，我们从另一段对话中随机抽取不同角色的发言。此外，我们将所有工作流程的步骤添加到训练数据中，并将其上采样308倍，最终总共生成约$500k$个训练样本。更多关于训练的详细信息，请参见[Section
    A.3](#A1.SS3 "A.3 自动评估 ‣ 附录A 实现细节 ‣ 通过自我对话引导基于LLM的任务导向对话代理的引导")。在我们的实验中，我们通过使用地下城主模型对每个发言进行评分，并对整个对话的评分进行平均来评估角色一致性（Char.
    Cons.）。
- en: Validation of Automated Metrics.
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 自动化指标验证。
- en: Before we continue to our experiments, we first would like to validate our automatic
    evaluation metrics. For this purpose, we sample $50$ conversations from the untrained
    model and manually annotate them, before comparing the results of the automated
    metrics to the ground truth. We find a Kendall’s $\tau$ correlation of $0.67$
    for absolute depth and a Pearons’s $\rho$ correlation of $0.67$ for relative depth
    for the subgoal tracking. The dungeon master model showed an accuracy of $0.87$
    and $F_{1}$ score of $0.93$ on the conversations. We provide a more extensive
    analysis of these results in [Section B.1.3](#A2.SS1.SSS3 "B.1.3 Meta-Evaluation
    ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk").
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续我们的实验之前，我们首先希望验证我们的自动评估指标。为此，我们从未训练过的模型中抽取了$50$个对话，并进行人工标注，然后将自动评估结果与真实标签进行对比。我们发现，对于子目标跟踪，绝对深度的Kendall’s
    $\tau$相关性为$0.67$，相对深度的Pearson’s $\rho$相关性为$0.67$。地下城主模型在对话中的准确率为$0.87$，$F_{1}$得分为$0.93$。我们在[Section
    B.1.3](#A2.SS1.SSS3 "B.1.3 元评估 ‣ B.1 自动化指标验证 ‣ 附录B 实验附录 ‣ 通过自我对话引导基于LLM的任务导向对话代理的引导")中提供了这些结果的更深入分析。
- en: 4.2 Bootstrapping Finetuning Data
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 引导微调数据
- en: 'Table 1: Results of the single step loop using different filters. Shown are
    the percentage of filtered dialogues (% Filtered), agent chararacter consistency
    (Char. Cons.), number of completed subgoals ($\varnothing$ Abs. Depth) and relative
    workflow completion ($\varnothing$ Rel. Depth), percentage of finished conversations
    ($\%$ Ended), as well as dialogue diversity. Results stem from $100$ test dialogues
    and random filter scores from $3$ different seeds.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：使用不同过滤器的单步循环结果。展示了过滤对话的百分比（% Filtered）、代理角色一致性（Char. Cons.）、已完成子目标的数量（$\varnothing$
    Abs. Depth）和相对工作流程完成度（$\varnothing$ Rel. Depth）、已完成对话的百分比（$\%$ Ended），以及对话多样性。结果来源于$100$个测试对话和来自$3$个不同种子的随机过滤器得分。
- en: '| Data | % Filtered | Char. Cons. $\uparrow$ | $\varnothing$ Abs. Depth $\uparrow$
    | $\varnothing$ Rel. Depth $\uparrow$ | $\%$ Ended $\uparrow$ | # Words $\uparrow$
    | # $N$-Grams $\uparrow$ | Diversity $\uparrow$ |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 数据 | % 过滤 | 角色一致性 Char. Cons. $\uparrow$ | $\varnothing$ 绝对深度 Abs. Depth
    $\uparrow$ | $\varnothing$ 相对深度 Rel. Depth $\uparrow$ | $\%$ 完成 Ended $\uparrow$
    | 单词数 Words $\uparrow$ | $N$-Grams 数量 $\uparrow$ | 多样性 Diversity $\uparrow$ |'
- en: '| Initial Dialogues | - | $0.77$ | $2.15$ | $0.38$ | $0.26$ | $57.16$ | $373.87$
    | $0.69$ |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 初始对话 | - | $0.77$ | $2.15$ | $0.38$ | $0.26$ | $57.16$ | $373.87$ | $0.69$
    |'
- en: '| \cdashline1-9 No Filter | $0.00$ | $0.78$ | $2.22$ | $0.38$ | $0.29$ | $47.32$
    | $285.94$ | $0.60$ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| \cdashline1-9 无过滤器 | $0.00$ | $0.78$ | $2.22$ | $0.38$ | $0.29$ | $47.32$
    | $285.94$ | $0.60$ |'
- en: '| $\%$-Random ($0.1$) | $0.90$ | $\underset{\pm 0.00}{0.77}$ | $\underset{\pm
    0.10}{2.15}$ | $\underset{\pm 0.02}{0.37}$ | $\underset{\pm 0.03}{0.24}$ | $\underset{\pm
    0.66}{45.89}$ | $\underset{\pm 6.21}{273.71}$ | $\underset{\pm 0.01}{0.62}$ |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| $\%$-随机 ($0.1$) | $0.90$ | $\underset{\pm 0.00}{0.77}$ | $\underset{\pm 0.10}{2.15}$
    | $\underset{\pm 0.02}{0.37}$ | $\underset{\pm 0.03}{0.24}$ | $\underset{\pm 0.66}{45.89}$
    | $\underset{\pm 6.21}{273.71}$ | $\underset{\pm 0.01}{0.62}$ |'
- en: '| Abs. Subgoals ($4$) | $0.82$ | $0.78$ | $2.30$ | $0.39$ | $0.27$ | $46.62$
    | $297.78$ | $0.64$ |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 绝对子目标 ($4$) | $0.82$ | $0.78$ | $2.30$ | $0.39$ | $0.27$ | $46.62$ | $297.78$
    | $0.64$ |'
- en: '| Abs. Subgoals ($5$) | $0.92$ | $0.80$ | $2.41$ | $0.41$ | $0.32$ | $46.55$
    | $280.53$ | $0.63$ |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 绝对子目标 ($5$) | $0.92$ | $0.80$ | $2.41$ | $0.41$ | $0.32$ | $46.55$ | $280.53$
    | $0.63$ |'
- en: '| Abs. Subgoals ($6$) | $0.98$ | $\mathbf{0.81}$ | $2.11$ | $0.35$ | $0.22$
    | $54.14$ | $343.07$ | $0.64$ |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 绝对子目标 ($6$) | $0.98$ | $\mathbf{0.81}$ | $2.11$ | $0.35$ | $0.22$ | $54.14$
    | $343.07$ | $0.64$ |'
- en: '| $\%$-Subgoals ($0.1$) | $0.90$ | $0.76$ | $2.37$ | $0.39$ | $0.30$ | $44.91$
    | $266.77$ | $0.63$ |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| $\%$-子目标 ($0.1$) | $0.90$ | $0.76$ | $2.37$ | $0.39$ | $0.30$ | $44.91$ |
    $266.77$ | $0.63$ |'
- en: '| $\%$-Subgoals ($0.05$) | $0.95$ | $0.78$ | $\mathbf{2.54}$ | $\mathbf{0.43}$
    | $\mathbf{0.36}$ | $49.40$ | $303.65$ | $0.66$ |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| $\%$-子目标 ($0.05$) | $0.95$ | $0.78$ | $\mathbf{2.54}$ | $\mathbf{0.43}$ |
    $\mathbf{0.36}$ | $49.40$ | $303.65$ | $0.66$ |'
- en: '| $\%$-Subgoals ($0.01$) | $0.99$ | $0.78$ | $2.31$ | $0.39$ | $0.29$ | $\mathbf{55.25}$
    | $\mathbf{355.44}$ | $\mathbf{0.69}$ |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| $\%$-子目标 ($0.01$) | $0.99$ | $0.78$ | $2.31$ | $0.39$ | $0.29$ | $\mathbf{55.25}$
    | $\mathbf{355.44}$ | $\mathbf{0.69}$ |'
- en: '| Has Ended | $0.74$ | $0.76$ | $2.22$ | $0.38$ | $0.26$ | $45.51$ | $277.25$
    | $0.64$ |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 已结束 | $0.74$ | $0.76$ | $2.22$ | $0.38$ | $0.26$ | $45.51$ | $277.25$ | $0.64$
    |'
- en: For our first experiment, we pre-generate around $9000$ dialogues to ensure
    comparability between different filters and finetune the model for a single epoch
    on the filtered data. We then generate an extra $100$ conversations with the updated
    agent model and measure the change in evaluation metrics.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一次实验中，我们预生成了约 $9000$ 个对话，以确保不同过滤器之间的可比性，并在过滤后的数据上对模型进行单次周期的微调。然后，我们使用更新后的代理模型生成额外的
    $100$ 个对话，并测量评估指标的变化。
- en: Results.
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结果。
- en: Result for different filtering methods are shown in [Table 1](#S4.T1 "Table
    1 ‣ 4.2 Bootstrapping Finetuning Data ‣ 4 Experiments ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk"). We can observe that using no or
    a random filter produces no or minor improvements at best. The best results are
    achieved by filters that select dialogues with at least $5$ completed workflow
    steps or the best $5\%$ of dialogues in terms of completion, with drops in performance
    once these criteria are made stricter. This is mostly likely an effect of the
    shrinking finetuning set size, as only $1-2\%$ of dialogues remain. Interestingly,
    dialogue diversity decreases in all cases; we attribute this to the fact that
    especially an agent model that sticks to a given workflow and does not go off-script
    creates dialogues that are overall slightly less diverse.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 不同过滤方法的结果见 [表 1](#S4.T1 "表 1 ‣ 4.2 自举微调数据 ‣ 4 实验 ‣ 通过自我对话自举基于 LLM 的任务导向对话代理")。我们可以观察到，使用无过滤器或随机过滤器在最佳情况下几乎没有改善。最佳结果是通过选择至少包含
    $5$ 个完成工作流步骤的对话或在完成度方面排名前 $5\%$ 的对话来实现的，一旦这些标准变得更严格，性能反而下降。这很可能是由于微调数据集大小缩小所致，因为仅剩下
    $1-2\%$ 的对话。有趣的是，在所有情况下，对话的多样性都减少了；我们认为这是因为特别是一个坚守给定工作流、不偏离脚本的代理模型会生成对话，这些对话的多样性整体上较低。
- en: '![Refer to caption](img/4c12ad70ce2300bcea53506ba00a8686.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/4c12ad70ce2300bcea53506ba00a8686.png)'
- en: (a) Importance via Spearman’s $\rho$ correlation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 通过 Spearman 的 $\rho$ 相关性衡量重要性。
- en: '![Refer to caption](img/748e1ad0f5a1f161e7e13c78725f2129.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/748e1ad0f5a1f161e7e13c78725f2129.png)'
- en: (b) Importance via linear regression coefficients.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 通过线性回归系数衡量重要性。
- en: 'Figure 3: Analysis of the relationship between properties of the finetuning
    dataset and their impact on the absolute completion of the dialogue, given (a)
    Spearman’s $\rho$ correlation values and (b) the coefficients of the linear regression
    model without a bias and with lasso regularization. Error bars and the regularization
    weight were determined via cross-validation.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：分析微调数据集的属性与其对对话完成度的绝对影响之间的关系，给定 (a) Spearman 的 $\rho$ 相关性值和 (b) 线性回归模型的系数（无偏差并使用
    Lasso 正则化）。误差条和正则化权重通过交叉验证确定。
- en: What Makes Good Finetuning Data?
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 什么样的数据适合微调？
- en: 'The results in [Table 1](#S4.T1 "Table 1 ‣ 4.2 Bootstrapping Finetuning Data
    ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")
    warrant the question for what reason different filtered finetuning sets worked
    better than others. We try to answer this by again applying our automated evaluation
    metrics—this time exclusively on the filtered dialogues—and relating the results
    to the observed change in dialogue success, measured in absolute depth. We do
    this by collecting the properties of each finetuning set used in [Table 1](#S4.T1
    "Table 1 ‣ 4.2 Bootstrapping Finetuning Data ‣ 4 Experiments ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk") and running two different analyses:
    Correlating with them with the change in absolute depth in [Figure 2(a)](#S4.F2.sf1
    "2(a) ‣ Figure 3 ‣ Results. ‣ 4.2 Bootstrapping Finetuning Data ‣ 4 Experiments
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk") using
    Spearman’s $\rho$ and applying normal scaling to the features and then fitting
    a linear regression model (without bias) with $l_{1}$ regularization in [Figure 2(b)](#S4.F2.sf2
    "2(b) ‣ Figure 3 ‣ Results. ‣ 4.2 Bootstrapping Finetuning Data ‣ 4 Experiments
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"). We can
    see that the two methods agree on the fact that the number of turns has a positive
    effect on performance, while the average length of utterances impacts dialogue
    quality negatively. This coincides with the intuitions we gained from our experiments,
    where bad quality conversations had models produce long utterances by rambling,
    going off-scrip, stating unnecessary information and ending prematurely or being
    shorter than the underlying dialogue workflow would require them to. Other than
    those, the methods agree that the workflow progression and character consistency
    in the finetuning data have a positive impact, with some slightly contradictory
    results for the other properties shown. However, these analyses should be taken
    with a grain of salt due to the small number of observations. Also, it is unlikely
    that e.g. utterance length has a negative effect on agent improvement *per se*,
    it seems more plausible that all or many of the properties are influenced by a
    common, latent confounder, (namely dialogue quality), that manifests itself in
    our data along these axes. Therefore, while we can use these observations for
    a proxy of the usefulness of a finetuning set, they do not imply causality.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[表格1](#S4.T1 "表格1 ‣ 4.2 自举微调数据 ‣ 4 实验 ‣ 通过自我对话自举基于LLM的任务导向对话代理")中的结果引发了一个问题：为什么不同筛选后的微调数据集表现得更好？我们通过再次应用自动化评估指标来尝试回答这个问题——这次我们仅针对筛选后的对话进行分析，并将结果与对话成功率的变化相关联，后者通过绝对深度来衡量。我们通过收集[表格1](#S4.T1
    "表格1 ‣ 4.2 自举微调数据 ‣ 4 实验 ‣ 通过自我对话自举基于LLM的任务导向对话代理")中使用的每个微调数据集的属性，并进行两种不同的分析：使用Spearman的$\rho$对其与[图2(a)](#S4.F2.sf1
    "2(a) ‣ 图3 ‣ 结果 ‣ 4.2 自举微调数据 ‣ 4 实验 ‣ 通过自我对话自举基于LLM的任务导向对话代理")中的绝对深度变化进行相关性分析，并将特征应用常规缩放后，拟合一个线性回归模型（不带偏差），并在[图2(b)](#S4.F2.sf2
    "2(b) ‣ 图3 ‣ 结果 ‣ 4.2 自举微调数据 ‣ 4 实验 ‣ 通过自我对话自举基于LLM的任务导向对话代理")中使用$l_{1}$正则化。我们可以看到，这两种方法一致认为，回合数对性能有正面影响，而话语的平均长度则对对话质量产生负面影响。这与我们从实验中得到的直觉一致，坏质量的对话会导致模型产生冗长的发言，偏离脚本，陈述不必要的信息，或者提前结束，或者发言的长度小于底层对话工作流所要求的长度。除此之外，这两种方法一致认为，微调数据中的工作流进展和角色一致性对性能有正面影响，尽管对于其他属性的结果存在一些轻微的矛盾。然而，由于观察样本数较少，这些分析结果应谨慎对待。另外，像话语长度对代理改进的负面影响*本身*不太可能成立，似乎更有可能的是，所有或许多属性都受某种共同的潜在混杂因素（即对话质量）的影响，并且这种影响在我们的数据中沿这些轴表现出来。因此，尽管我们可以使用这些观察结果作为微调数据集有用性的代理，但它们并不意味着因果关系。'
- en: 4.3 Human Evaluation
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 人工评估
- en: '![Refer to caption](img/7ddd6bcd0b312fd20d57b2d06a7fbf34.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7ddd6bcd0b312fd20d57b2d06a7fbf34.png)'
- en: 'Figure 4: Results of the human evaluation study for three baselines and the
    two best filters from [Section 4.2](#S4.SS2 "4.2 Bootstrapping Finetuning Data
    ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")
    along six different questions. Shown are the percentage of ratings per filter,
    either on a five point scale or using positive (![Refer to caption](img/cb6d42c1333c07e1fadec42d01d94815.png)),
    negative (![Refer to caption](img/72a1726ad83b8e793cc8a619c0cf535e.png)) and *unsure*
    (![Refer to caption](img/d96abe05ee839e802a3d9538ab6df38a.png)) options. Dashed
    lines indicate the numerical average and $\bigstar$ signifies statistical significance
    compared to all other options assessed via the ASO test (Del Barrio et al., [2018](#bib.bib7);
    Dror et al., [2019](#bib.bib8); Ulmer et al., [2022](#bib.bib47)) with $\tau=0.5$
    and a confidence level of $\alpha=0.9$.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：人类评估研究的结果，涉及三个基准方法和来自[第 4.2 节](#S4.SS2 "4.2 Bootstrapping Finetuning Data
    ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")的两个最佳筛选器，涵盖六个不同问题。展示的是每个筛选器的评分百分比，评分方式为五点量表，或者使用正面
    (![Refer to caption](img/cb6d42c1333c07e1fadec42d01d94815.png))、负面 (![Refer to
    caption](img/72a1726ad83b8e793cc8a619c0cf535e.png)) 和 *不确定* (![Refer to caption](img/d96abe05ee839e802a3d9538ab6df38a.png))
    选项。虚线表示数值平均值，$\bigstar$ 表示与通过 ASO 测试评估的所有其他选项相比具有统计显著性 (Del Barrio et al., [2018](#bib.bib7);
    Dror et al., [2019](#bib.bib8); Ulmer et al., [2022](#bib.bib47))，$\tau=0.5$ 和置信度为
    $\alpha=0.9$。
- en: In order to triangulate the previous results that are based on automatic results
    and to additionally rate other aspects, we also include an evaluation based on
    human judges. We evaluate the results of the untrained model (Untrained), using
    the entire finetuning data (No Filter), %-Random (0.1), Abs. Subgoals (5) and
    %-Subgoals (0.05) from [Section 4.2](#S4.SS2 "4.2 Bootstrapping Finetuning Data
    ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")
    across certain dimensions such as helpfulness, consistency and dialogue success.
    Users are asked to rate these properties either using three options (![[Uncaptioned
    image]](img/cb6d42c1333c07e1fadec42d01d94815.png), ![[Uncaptioned image]](img/72a1726ad83b8e793cc8a619c0cf535e.png) or
    *unsure*) or on a scale from $1$ (worst) to $5$ (best). We ask $n=9$ participants
    to judge a total of $100$ dialogues ($20$ per filtering method) randomly sampled
    from our experiments. Obtaining two annotations per data point, we observe an
    inter-annotator agreement in terms of Cohen’s $\kappa\approx 0.52$. We give more
    details about our evaluation including annotation guidelines and information on
    our tool in [Section B.2](#A2.SS2 "B.2 Human Evaluation Study ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk").
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了三角验证基于自动化结果的前述结论，并额外评估其他方面，我们还包括了基于人工评审的评估。我们评估了未经训练的模型（Untrained），使用全部微调数据（No
    Filter）、%-随机 (0.1)、绝对子目标 (5) 和 %-子目标 (0.05)，来自[第 4.2 节](#S4.SS2 "4.2 Bootstrapping
    Finetuning Data ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk")，从帮助性、一致性和对话成功等维度进行评估。用户需要评定这些属性，评分方式可以选择三个选项 (![[Uncaptioned
    image]](img/cb6d42c1333c07e1fadec42d01d94815.png)，![[Uncaptioned image]](img/72a1726ad83b8e793cc8a619c0cf535e.png)
    或 *不确定*)，或者在$1$（最差）到$5$（最佳）的量表上进行评分。我们请$n=9$名参与者对共$100$个对话进行评判（每种筛选方法$20$个），这些对话是从我们的实验中随机抽样的。每个数据点获得两个注释，我们观察到注释者之间的Cohen
    $\kappa \approx 0.52$的一致性。我们在[第 B.2 节](#A2.SS2 "B.2 Human Evaluation Study ‣ Appendix
    B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk")中提供了有关我们的评估、注释指南以及工具的更多细节。
- en: '<svg class="ltx_picture ltx_centering" height="129.1" id="S4.F5.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,129.1) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0
    0.0 1.0 300.98 103.81)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Make the prince fall in love with them”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="81.3" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Genie from lamp ![Refer to
    caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, what do you wish
    for?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Greetings, genie. I wish for the prince to fall in love with me.   Genie from
    lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I am not a
    matchmaker and cannot make people fall in love. You should try to make your own
    chances.   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Thank you for your advice, genie. I will try my best to make the prince fall
    in love with me.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Goodbye!  Villager
    ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Goodbye, genie.</foreignobject></g></g></svg>'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="129.1" id="S4.F5.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,129.1) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0 0.0
    0.0 1.0 300.98 103.81)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Make the prince fall in love with them”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="81.3" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Genie from lamp ![Refer to
    caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, what do you wish
    for?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Greetings, genie. I wish for the prince to fall in love with me.   Genie from
    lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I am not a
    matchmaker and cannot make people fall in love. You should try to make your own
    chances.   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Thank you for your advice, genie. I will try my best to make the prince fall
    in love with me.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Goodbye!  Villager
    ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Goodbye, genie.</foreignobject></g></g></svg>'
- en: 'Figure 5: Conversation generated after finetuning with the %-Subgoals (0.05)
    filter, with the agent ignoring the given workflow.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：在使用 %-子目标 (0.05) 筛选器进行微调后生成的对话，代理忽略了给定的工作流程。
- en: '<svg class="ltx_picture ltx_centering" height="134.06" id="S4.F6.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,134.06) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 383.42 108.77)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Book a bed for the night”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="86.26"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Tavern Owner
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can
    I help you?   Person ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Good day, I am in need of a bed for the night. I have been traveling for days
    and am quite tired.   Tavern Owner ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the duration of your stay?   Person ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Just for the night, I have to continue my journey in the morning.   Tavern Owner
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What kind of room
    would you like?   Person ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     A simple room with a bed and a fireplace would be perfect.   Tavern Owner ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can I help
    you?  … [Agent gets stuck in a loop, asking the last two questions over and over.]</foreignobject></g></g></svg>'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="134.06" id="S4.F6.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,134.06) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 383.42 108.77)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Book a bed for the night”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="86.26"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Tavern Owner
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can
    I help you?   Person ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Good day, I am in need of a bed for the night. I have been traveling for days
    and am quite tired.   Tavern Owner ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the duration of your stay?   Person ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Just for the night, I have to continue my journey in the morning.   Tavern Owner
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What kind of room
    would you like?   Person ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     A simple room with a bed and a fireplace would be perfect.   Tavern Owner ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can I help
    you?  … [Agent gets stuck in a loop, asking the last two questions over and over.]</foreignobject></g></g></svg>'
- en: 'Figure 6: Conversation generated after finetuning with the Abs. Subgoals (5)
    filter, with the agent getting stuck in a conversational loop.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：在使用绝对子目标 (5) 筛选器进行微调后生成的对话，代理陷入了对话循环。
- en: Results
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结果
- en: The results of the aggregated judgements by filter are given in [Figure 4](#S4.F4
    "Figure 4 ‣ 4.3 Human Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk"). Interestingly, we can see that finetuning on
    all data usually *decreases* model quality, but finetuning on a random subset
    *may* increase performance. Compared to the baselines, the human judgements surprisingly
    rate the quality of the model produced by the Abs. Subbgoals (5) filter as en
    par or worse on dimensions such as dialogue success, workflow adherence and overall
    dialogue quality. With the other best performing filter however, $\%$-Subgoals($0.05$),
    our human raters triangulate the positive results of the automated metrics, with
    the resulting agent performing (significantly) better in all but one category,
    showing that right subset of dialogues can provide a stronger training signal.
    Despite these successes, we still identify some common failure cases, of which
    we highlight two here:³³3We use Agent ![[Uncaptioned image]](img/09b1b1572d5df408c3a44a15f96ddc74.png)
    to illustrate the utterances of agent characters (inlcuding the ones that do not
    correspond to the genie) and Client ![[Uncaptioned image]](img/3a9f183c741a0bf3d7d839bba9fd920a.png)
    for client characters. In [Figure 5](#S4.F5 "Figure 5 ‣ 4.3 Human Evaluation ‣
    4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"),
    we recapitulate a conversation in which the agent completely ignores the workflow
    after its first utterance, even though the rest of the conversation still continues
    organically. In the second example in [Figure 6](#S4.F6 "Figure 6 ‣ 4.3 Human
    Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk"), we see that the agent regresses to the initial question after
    an otherwise successful start of the conversation, getting stuck in a conversational
    loop with the client. We also found conversations to derail in cases where the
    client would respond in a way too dissimilar from the sample answers defined in
    the workflow; in this case the agent would usually ad-lib and fail to recover
    during the rest of the conversation. We show more examples and discuss other failure
    cases in [Section B.4](#A2.SS4 "B.4 Sample Conversations ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk").
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 按过滤器聚合的判断结果见于[图4](#S4.F4 "图4 ‣ 4.3 人类评估 ‣ 4 实验 ‣ 通过自我对话引导大模型基础的任务导向对话代理")。有趣的是，我们可以看到，在所有数据上进行微调通常会*降低*模型质量，但在一个随机子集上微调*可能*会提高性能。与基准相比，人类判断者惊讶地评定，Abs.
    Subbgoals (5) 过滤器生成的模型质量在对话成功、工作流遵循和整体对话质量等维度上与基准持平或更差。然而，使用另一个表现最好的过滤器，$\%$-Subgoals($0.05$)，我们的人工评分者通过三角测量验证了自动化指标的正面结果，结果显示该代理在除一个类别外的所有类别中（显著地）表现更好，表明正确的对话子集可以提供更强的训练信号。尽管取得了这些成功，我们仍然发现一些常见的失败案例，在这里我们突出其中的两个：³³3我们使用代理！[[未标注图片]](img/09b1b1572d5df408c3a44a15f96ddc74.png)来展示代理角色的发言（包括那些不对应精灵的发言），并使用客户！[[未标注图片]](img/3a9f183c741a0bf3d7d839bba9fd920a.png)来展示客户角色的发言。在[图5](#S4.F5
    "图5 ‣ 4.3 人类评估 ‣ 4 实验 ‣ 通过自我对话引导大模型基础的任务导向对话代理")中，我们回顾了一个对话，代理在第一次发言后完全忽略了工作流，尽管后续对话依然自然进行。在[图6](#S4.F6
    "图6 ‣ 4.3 人类评估 ‣ 4 实验 ‣ 通过自我对话引导大模型基础的任务导向对话代理")中的第二个例子中，我们看到代理在对话开始成功后，回到初始问题，并陷入与客户的对话循环中。我们还发现，在客户的回应与工作流中定义的样本答案差异过大时，对话可能会脱轨；在这种情况下，代理通常会即兴发挥，并在接下来的对话中未能恢复。我们将在[附录B.4](#A2.SS4
    "B.4 示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话引导大模型基础的任务导向对话代理")中展示更多示例并讨论其他失败案例。
- en: 5 Discussion
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: Our experimental results have demonstrated the challenges that arise when implementing
    self-talk in a task-oriented dialogue setup. These reach from the ability of the
    agent to follow the workflow carefully and selecting the next steps reliably—a
    problem that is at least partially rooted in the open-ended and paraphrastic nature
    of conversations. Nevertheless, we have provided insights that a proper filtering
    technique isolating high-quality data contitutes a positive training signal for
    the agent LLM, that can be used to improve its performance. This conclusion is
    in line with the emerging literature on LLM self-critique and the concurrent work
    of Gulcehre et al. ([2023](#bib.bib13)) on using self-generated data for finetuning.
    An open question in this vein is whether this process can reliably repeated multiple
    times, and determining the conditions under which it leads to an improvement or
    model degradation. In some tentative experiments, we found multi-loops of self-talk
    to lead to minor improvements at first, but also to be unstable if the number
    of filtered finetuning samples was too low. We leave further explorations of this
    question to future work and collect other, smaller insights from our experiments
    in [Section B.3](#A2.SS3 "B.3 Miscellaenous Insights ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk").
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验结果展示了在任务导向对话设置中实施自我对话时所遇到的挑战。这些挑战包括代理是否能够仔细遵循工作流程，以及是否能够可靠地选择下一步操作——这一问题至少部分源于对话的开放性和释义性特征。然而，我们提供了见解，表明正确的过滤技术可以隔离高质量数据，并为代理的语言模型提供正向训练信号，从而提高其性能。这一结论与日益增多的关于LLM自我批评的文献以及Gulcehre等人（[2023](#bib.bib13)）关于使用自生成数据进行微调的相关工作相一致。一个相关的未解问题是，这一过程是否能可靠地重复多次，并确定在什么条件下它会导致性能提升或模型退化。在一些初步实验中，我们发现多轮自我对话最初会带来轻微的改进，但如果过滤后的微调样本数量过低，也会变得不稳定。我们将进一步探讨这个问题留给未来的工作，并在[附录B.3节](#A2.SS3
    "B.3 Miscellaenous Insights ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk")中收集了我们实验中的其他小型见解。
- en: 6 Conclusion
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: Despite previous works articulating worries about the distributional collapse
    of model trained on their own generated data (Alemohammad et al., [2023](#bib.bib1);
    Shumailov et al., [2023](#bib.bib39)), we demonstrated that—given the right setup—language
    models can self-improve by being trained on their own generation and become better
    task-oriented dialogue agents. As we showed in [Section 4.2](#S4.SS2 "4.2 Bootstrapping
    Finetuning Data ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"), this depends on the setup; using different models and
    varying prompts helps to create sufficiently diverse data, with additional filters
    ensuring sufficient quality. We especially found the filters that strike a balance
    between quality and number of total data points to work best for selecting finetuning
    data and validated these insights with the human evaluation in [Section 4.3](#S4.SS3
    "4.3 Human Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk").
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管先前的研究已提出关于在其自身生成数据上训练的模型可能出现分布崩溃的担忧（Alemohammad 等人，[2023](#bib.bib1); Shumailov
    等人，[2023](#bib.bib39)），我们证明了——在合适的设置下——语言模型可以通过在自身生成数据上进行训练实现自我改进，并成为更好的任务导向对话代理。正如我们在[第4.2节](#S4.SS2
    "4.2 Bootstrapping Finetuning Data ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk")中所展示的，这取决于设置；使用不同的模型和变化的提示有助于创建足够多样化的数据，附加的过滤器则确保了数据的质量。我们特别发现，能够在质量和数据总量之间取得平衡的过滤器最适合选择微调数据，并通过[第4.3节](#S4.SS3
    "4.3 Human Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk")中的人工评估验证了这些见解。
- en: In addition, we established new methods for automatic evaluation of agents in
    a task-oriented dialogue setting and showed that they can be used to quantify
    the progress of our finetuned model. We see this work as a piece of evidence in
    line with works such as Scheurer et al. ([2023](#bib.bib35)); Paul et al. ([2023](#bib.bib28));
    Gero et al. ([2023](#bib.bib12)); Chen et al. ([2023](#bib.bib5)); Saunders et al.
    ([2022](#bib.bib34)) that self-improvement with LLMs is indeed possible under
    the right conditions, and are—to the best of our knowledge—the first to demonstrate
    the utility of LLM self-talk in a dialogue setting. We hope for this line of work
    to inspire further investigations into understanding the requirements and limits
    of self-improvement.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们建立了面向任务的对话设置中评估智能体的新方法，并展示了这些方法可以用来量化我们微调模型的进展。我们将这项工作视为与以下工作一致的证据，例如Scheurer等人（[2023](#bib.bib35)）；Paul等人（[2023](#bib.bib28)）；Gero等人（[2023](#bib.bib12)）；Chen等人（[2023](#bib.bib5)）；Saunders等人（[2022](#bib.bib34)），证明在适当的条件下，使用LLM（大型语言模型）进行自我改进确实是可能的。我们是——据我们所知——首次展示LLM自言自语在对话环境中的实用性。我们希望这项工作能激发更多关于理解自我改进的需求和限制的研究。
- en: Future Work.
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 未来工作
- en: This work focused on self-talk for task-oriented dialogue agents. Since we are
    finetuning on bootstrapped conversations, we expect the model to loose some general
    conversational abilities that are not relevant for the given task. Future work
    could explore how we can nevertheless maintain these abilities. Futhermore, this
    version of self-talk could still be improved by generating higher-quality conversations
    and identifying the conversations are most informative to the model for finetuning,
    reminiscent of work in active learning (see e.g. Zhang et al., [2022](#bib.bib53)).
    Lastly, our setup intuitively lends itself well to also using negative signals,
    since low-quality conversation could be used for negative rewards. The agent could
    then be optimized with an objective similar to direct preference optimization
    (Rafailov et al., [2023](#bib.bib31)) or using natural language policy optimization
    (Ramamurthy et al., [2023](#bib.bib32)) by embedding it in a RL environment.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究聚焦于面向任务的对话体智能体的自言自语。由于我们正在对自启动对话进行微调，我们预期模型可能会失去一些与当前任务无关的通用对话能力。未来的工作可以探讨如何在保持这些能力的同时进行微调。此外，这一版本的自言自语仍然可以通过生成更高质量的对话并识别对模型微调最有信息价值的对话来改进，这类似于主动学习中的工作（参见例如张等人，[2022](#bib.bib53)）。最后，我们的设置直观上也非常适合使用负面信号，因为低质量对话可以用作负奖励。这样，智能体可以通过类似直接偏好优化（Rafailov等人，[2023](#bib.bib31)）的目标进行优化，或者通过将其嵌入到强化学习环境中使用自然语言策略优化（Ramamurthy等人，[2023](#bib.bib32)）。
- en: Limitations
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: 'This work comes with some limitations: Firstly, we restrict our experiments
    to task-oriented dialogue, which does not allow us to draw any conclusion about
    open-ended dialogue or other, more specific tasks carried out by LLMs. In order
    to isolate the effect of self-talk, we also limit the scope of the interaction
    between agent and client and constrain the format of the dialogue. However, related
    works by Scheurer et al. ([2023](#bib.bib35)); Paul et al. ([2023](#bib.bib28));
    Gero et al. ([2023](#bib.bib12)); Chen et al. ([2023](#bib.bib5)); Saunders et al.
    ([2022](#bib.bib34)) have demonstrated the potential for self-improvement for
    a variety of tasks. Secondly, we explored a setup which two different language
    models that are further given very strict instructions in order to produce conversations
    that are usable for training. It might be that using a single model for both the
    agent and the client might not produce conversation that are diverse enough, or
    that smaller models might not be able to create sufficiently useful conversations
    at all. Furthermore, even including all the techniques like model-guided prompting
    the generated conversations sometimes would still include the models getting stuck
    in loops, going off-script or even producing nonsensical dialogues that can also
    be hard to catch with our defined filters sometimes. Despite with anecdotal evidence
    that larger models might not suffer from these problem as much, it is hard to
    definitively disentangle the effect of model size and training data in our setup.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究存在一些局限性：首先，我们将实验限制在面向任务的对话中，因此无法对开放性对话或大型语言模型执行的其他更具体任务得出结论。为了隔离自我对话的影响，我们还限制了代理与客户之间的互动范围，并约束了对话的格式。然而，Scheurer
    等人（[2023](#bib.bib35)）；Paul 等人（[2023](#bib.bib28)）；Gero 等人（[2023](#bib.bib12)）；Chen
    等人（[2023](#bib.bib5)）；Saunders 等人（[2022](#bib.bib34)）的相关研究已证明自我改进在各种任务中的潜力。其次，我们探索了一种设置，其中两个不同的语言模型被严格指令，以生成可用于训练的对话。可能的是，使用单一模型作为代理和客户可能无法生成足够多样的对话，或者较小的模型根本无法创建足够有用的对话。此外，即使包含所有技术，如模型引导的提示，生成的对话有时仍然会出现模型陷入循环、跑偏脚本，甚至生成不合逻辑的对话，这些对话有时也很难通过我们定义的过滤器捕捉到。尽管有轶事证据表明较大的模型可能不会遭遇这些问题，但在我们的设置中，很难明确区分模型大小和训练数据的影响。
- en: Ethical Considerations
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 道德考虑
- en: Model Bias.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 模型偏见。
- en: Many works have been dedicated to investigating social biases of modern NLP
    models (see for instance Stanczak and Augenstein, [2021](#bib.bib43); Garrido-Muñoz
    et al., [2021](#bib.bib10) for surveys). Since large language models often echo
    the biases present in their development (Waseem et al., [2021](#bib.bib50)), finetuning
    a model on its own bootstrapped data harbors the danger of amplifying its own
    biases.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究致力于调查现代自然语言处理模型的社会偏见（例如，参见 Stanczak 和 Augenstein，[2021](#bib.bib43)；Garrido-Muñoz
    等人，[2021](#bib.bib10) 的综述）。由于大型语言模型往往会反映其开发过程中存在的偏见（Waseem 等人，[2021](#bib.bib50)），在其自生成数据上微调模型可能会加剧其自身的偏见。
- en: Societal Dangers.
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 社会危害。
- en: Recent works have demonstrated the negative potential of LLMs to deceive human
    users, for instance in the form of personalized phishing attacks (Hazell, [2023](#bib.bib14)).
    Training agents which do not rely on human-generated training data anymore could
    therefore simplify the creation of deceptive dialogue models by malicious actors.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，LLM 在欺骗用户方面的负面潜力，例如在个性化钓鱼攻击的形式中（Hazell，[2023](#bib.bib14)）。因此，训练不再依赖人类生成的训练数据的代理，可能会简化恶意行为者创建欺骗性对话模型的过程。
- en: Acknowledgements
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank Wanyu Du and Han He for providing the inspiration for
    the model-guided prompting, and Nikolaos Pappas and Raphael Shu for their fruitful
    discussions about the work. We also thank Elisa Bassignana, Sam Davidson, Etsuko
    Ishii, Josef Valvoda, Yuwei Zhang and especially Hossein Aboutalebi for their
    efforts in contributing to our human evaluation study.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢杜婉瑜和何汉为模型引导提示提供的灵感，感谢 Nikolaos Pappas 和 Raphael Shu 对本研究的富有成效的讨论。我们还要感谢
    Elisa Bassignana、Sam Davidson、Etsuko Ishii、Josef Valvoda、张宇威，特别是 Hossein Aboutalebi
    在参与我们的人类评估研究中的努力。
- en: References
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Alemohammad et al. (2023) Sina Alemohammad, Josue Casco-Rodriguez, Lorenzo Luzi,
    Ahmed Imtiaz Humayun, Hossein Babaei, Daniel LeJeune, Ali Siahkoohi, and Richard G
    Baraniuk. 2023. Self-consuming generative models go mad. *arXiv preprint arXiv:2307.01850*.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alemohammad 等人（2023）Sina Alemohammad、Josue Casco-Rodriguez、Lorenzo Luzi、Ahmed
    Imtiaz Humayun、Hossein Babaei、Daniel LeJeune、Ali Siahkoohi 和 Richard G Baraniuk.
    2023. 《自我消耗生成模型失控》。*arXiv 预印本 arXiv:2307.01850*。
- en: 'Argyle et al. (2023) Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler,
    Christopher Rytting, and David Wingate. 2023. Out of one, many: Using language
    models to simulate human samples. *Political Analysis*, 31(3):337–351.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argyle 等人（2023）Lisa P Argyle、Ethan C Busby、Nancy Fulda、Joshua R Gubler、Christopher
    Rytting 和 David Wingate. 2023. 《从一到多：利用语言模型模拟人类样本》。*政治分析*，31(3)：337–351。
- en: 'Bai et al. (2022) Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell,
    Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron
    McKinnon, et al. 2022. Constitutional ai: Harmlessness from ai feedback. *arXiv
    preprint arXiv:2212.08073*.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人（2022）Yuntao Bai、Saurav Kadavath、Sandipan Kundu、Amanda Askell、Jackson
    Kernion、Andy Jones、Anna Chen、Anna Goldie、Azalia Mirhoseini、Cameron McKinnon 等人.
    2022. 《宪法 AI：来自 AI 反馈的无害性》。*arXiv 预印本 arXiv:2212.08073*。
- en: 'Chen et al. (2021) Derek Chen, Howard Chen, Yi Yang, Alexander Lin, and Zhou
    Yu. 2021. Action-based conversations dataset: A corpus for building more in-depth
    task-oriented dialogue systems. In *Proceedings of the 2021 Conference of the
    North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies*, pages 3002–3017.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2021）Derek Chen、Howard Chen、Yi Yang、Alexander Lin 和 Zhou Yu. 2021. 《基于动作的对话数据集：构建更深入的任务导向对话系统的语料库》。载于
    *2021年北美计算语言学协会：人类语言技术会议论文集*，页码 3002–3017。
- en: Chen et al. (2023) Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou.
    2023. Teaching large language models to self-debug. *arXiv preprint arXiv:2304.05128*.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2023）Xinyun Chen、Maxwell Lin、Nathanael Schärli 和 Denny Zhou. 2023. 《教大语言模型自我调试》。*arXiv
    预印本 arXiv:2304.05128*。
- en: 'Dai et al. (2023) Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Huang,
    Zihao Wu, Lin Zhao, Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu, et al. 2023.
    Chataug: Leveraging chatgpt for text data augmentation. *arXiv preprint arXiv:2302.13007*.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai 等人（2023）Haixing Dai、Zhengliang Liu、Wenxiong Liao、Xiaoke Huang、Zihao Wu、Lin
    Zhao、Wei Liu、Ninghao Liu、Sheng Li、Dajiang Zhu 等人. 2023. 《Chataug：利用 ChatGPT 进行文本数据增强》。*arXiv
    预印本 arXiv:2302.13007*。
- en: Del Barrio et al. (2018) Eustasio Del Barrio, Juan A Cuesta-Albertos, and Carlos
    Matrán. 2018. An optimal transportation approach for assessing almost stochastic
    order. In *The Mathematics of the Uncertain*, pages 33–44\. Springer.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Del Barrio 等人（2018）Eustasio Del Barrio、Juan A Cuesta-Albertos 和 Carlos Matrán.
    2018. 《评估几乎随机顺序的最优传输方法》。载于 *《不确定性的数学》*，页码 33–44. Springer。
- en: 'Dror et al. (2019) Rotem Dror, Segev Shlomov, and Roi Reichart. 2019. [Deep
    dominance - how to properly compare deep neural models](https://doi.org/10.18653/v1/p19-1266).
    In *Proceedings of the 57th Conference of the Association for Computational Linguistics,
    ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers*, pages
    2773–2785\. Association for Computational Linguistics.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dror 等人（2019）Rotem Dror、Segev Shlomov 和 Roi Reichart. 2019. [《深度主导——如何正确比较深度神经模型》](https://doi.org/10.18653/v1/p19-1266)。载于
    *第57届计算语言学协会年会论文集（ACL 2019），意大利佛罗伦萨，2019年7月28日至8月2日，第1卷：长篇论文*，页码 2773–2785. 计算语言学协会。
- en: 'Fan et al. (2018) Angela Fan, Mike Lewis, and Yann N. Dauphin. 2018. Hierarchical
    neural story generation. In *Proceedings of the 56th Annual Meeting of the Association
    for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018,
    Volume 1: Long Papers*, pages 889–898\. Association for Computational Linguistics.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等人（2018）Angela Fan、Mike Lewis 和 Yann N. Dauphin. 2018. 《层次化神经故事生成》。载于 *第56届计算语言学协会年会论文集（ACL
    2018），澳大利亚墨尔本，2018年7月15日至20日，第1卷：长篇论文*，页码 889–898. 计算语言学协会。
- en: Garrido-Muñoz et al. (2021) Ismael Garrido-Muñoz, Arturo Montejo-Ráez, Fernando
    Martínez-Santiago, and L Alfonso Ureña-López. 2021. A survey on bias in deep nlp.
    *Applied Sciences*, 11(7):3184.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garrido-Muñoz 等人（2021）Ismael Garrido-Muñoz、Arturo Montejo-Ráez、Fernando Martínez-Santiago
    和 L Alfonso Ureña-López. 2021. 《深度 NLP 中的偏见调查》。*应用科学*，11(7)：3184。
- en: 'Geng and Liu (2023) Xinyang Geng and Hao Liu. 2023. [Openllama: An open reproduction
    of llama](https://github.com/openlm-research/open_llama).'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geng 和 Liu（2023）Xinyang Geng 和 Hao Liu. 2023. [《Openllama：Llama 的开放复现》](https://github.com/openlm-research/open_llama)。
- en: Gero et al. (2023) Zelalem Gero, Chandan Singh, Hao Cheng, Tristan Naumann,
    Michel Galley, Jianfeng Gao, and Hoifung Poon. 2023. Self-verification improves
    few-shot clinical information extraction. *arXiv preprint arXiv:2306.00024*.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gero等人（2023）Zelalem Gero, Chandan Singh, Hao Cheng, Tristan Naumann, Michel
    Galley, Jianfeng Gao, 和 Hoifung Poon. 2023. 自我验证提升了少样本临床信息提取。*arXiv预印本arXiv:2306.00024*。
- en: Gulcehre et al. (2023) Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan,
    Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern,
    Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, and Nando
    de Freitas. 2023. [Reinforced self-training (rest) for language modeling](http://arxiv.org/abs/2308.08998).
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulcehre等人（2023）Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia
    Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen
    Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, 和 Nando de Freitas.
    2023. [强化自训练（REST）用于语言建模](http://arxiv.org/abs/2308.08998)。
- en: Hazell (2023) Julian Hazell. 2023. Large language models can be used to effectively
    scale spear phishing campaigns. *arXiv preprint arXiv:2305.06972*.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hazell（2023）Julian Hazell. 2023. 大规模语言模型可以有效扩展 spear phishing 攻击。*arXiv预印本arXiv:2305.06972*。
- en: 'He et al. (2021a) Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2021a. [Debertav3:
    Improving deberta using electra-style pre-training with gradient-disentangled
    embedding sharing](http://arxiv.org/abs/2111.09543).'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何等人（2021a）Pengcheng He, Jianfeng Gao, 和 Weizhu Chen. 2021a. [Debertav3：通过梯度解耦的嵌入共享和Electra风格的预训练提升DeBERTa](http://arxiv.org/abs/2111.09543)。
- en: 'He et al. (2021b) Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen.
    2021b. Deberta: decoding-enhanced bert with disentangled attention. In *9th International
    Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May
    3-7, 2021*. OpenReview.net.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何等人（2021b）Pengcheng He, Xiaodong Liu, Jianfeng Gao, 和 Weizhu Chen. 2021b. Deberta：通过解耦注意力的解码增强BERT。在*第9届国际学习表征会议，ICLR
    2021，虚拟会议，奥地利，2021年5月3-7日*。OpenReview.net。
- en: Holtzman et al. (2020) Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin
    Choi. 2020. The curious case of neural text degeneration. In *8th International
    Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April
    26-30, 2020*.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holtzman等人（2020）Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, 和 Yejin Choi.
    2020. 神经文本退化的奇异案例。在*第8届国际学习表征会议，ICLR 2020，埃塞俄比亚，亚的斯亚贝巴，2020年4月26-30日*。
- en: 'Holtzman et al. (2018) Ari Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut,
    David Golub, and Yejin Choi. 2018. Learning to write with cooperative discriminators.
    In *Proceedings of the 56th Annual Meeting of the Association for Computational
    Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long
    Papers*, pages 1638–1649\. Association for Computational Linguistics.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holtzman等人（2018）Ari Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut, David
    Golub, 和 Yejin Choi. 2018. 使用合作判别器学习写作。在*第56届计算语言学协会年会论文集，ACL 2018，澳大利亚墨尔本，2018年7月15-20日，第1卷：长篇论文*，第1638-1649页。计算语言学协会。
- en: 'Hu et al. (2022) Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. Lora: Low-rank adaptation
    of large language models. In *The Tenth International Conference on Learning Representations,
    ICLR 2022, Virtual Event, April 25-29, 2022*.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 胡等人（2022）Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi
    Li, Shean Wang, Lu Wang, 和 Weizhu Chen. 2022. Lora：大规模语言模型的低秩适配。在*第十届国际学习表征会议，ICLR
    2022，虚拟会议，2022年4月25-29日*。
- en: Hu and Levy (2023) Jennifer Hu and Roger Levy. 2023. Prompt-based methods may
    underestimate large language models’ linguistic generalizations. *arXiv preprint
    arXiv:2305.13264*.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 胡和Levy（2023）Jennifer Hu 和 Roger Levy. 2023. 基于提示的方法可能低估了大规模语言模型的语言泛化能力。*arXiv预印本arXiv:2305.13264*。
- en: 'Li et al. (2022) Zekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, and
    Xifeng Yan. 2022. Controllable dialogue simulation with in-context learning. In
    *Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi,
    United Arab Emirates, December 7-11, 2022*, pages 4330–4347\. Association for
    Computational Linguistics.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李等人（2022）Zekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, 和 Xifeng Yan.
    2022. 使用上下文学习的可控对话模拟。在*计算语言学协会发现：EMNLP 2022，阿布扎比，阿联酋，2022年12月7-11日*，第4330-4347页。计算语言学协会。
- en: 'Lin (2004) Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of
    summaries. In *Text summarization branches out*, pages 74–81.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 林（2004）Chin-Yew Lin. 2004. Rouge：用于自动评估摘要的工具包。在*文本摘要分支扩展*，第74–81页。
- en: Liu et al. (2022) Hong Liu, Yucheng Cai, Zhijian Ou, Yi Huang, and Junlan Feng.
    2022. A generative user simulator with gpt-based architecture and goal state tracking
    for reinforced multi-domain dialog systems. *arXiv preprint arXiv:2210.08692*.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2022）Hong Liu、Yucheng Cai、Zhijian Ou、Yi Huang和Junlan Feng。2022年。《基于GPT架构和目标状态跟踪的生成用户模拟器，用于强化的多领域对话系统》。*arXiv预印本arXiv:2210.08692*。
- en: Liu et al. (2023) Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou,
    Andrew M Dai, Diyi Yang, and Soroush Vosoughi. 2023. Training socially aligned
    language models in simulated human society. *arXiv preprint arXiv:2305.16960*.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu等人（2023）Ruibo Liu、Ruixin Yang、Chenyan Jia、Ge Zhang、Denny Zhou、Andrew M Dai、Diyi
    Yang和Soroush Vosoughi。2023年。《在模拟人类社会中训练社会对齐的语言模型》。*arXiv预印本arXiv:2305.16960*。
- en: 'MosaicML NLP Team (2023) MosaicML NLP Team. 2023. [Introducing mpt-7b: A new
    standard for open-source, commercially usable llms](www.mosaicml.com/blog/mpt-7b).
    Accessed: 2023-05-05.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MosaicML NLP团队（2023）MosaicML NLP团队。2023年。[介绍mpt-7b：开源、可商用LLM的新标准](www.mosaicml.com/blog/mpt-7b)。访问时间：2023年5月5日。
- en: Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll
    Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
    Ray, et al. 2022. Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, 35:27730–27744.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ouyang等人（2022）Long Ouyang、Jeffrey Wu、Xu Jiang、Diogo Almeida、Carroll Wainwright、Pamela
    Mishkin、Chong Zhang、Sandhini Agarwal、Katarina Slama、Alex Ray等。2022年。《训练语言模型通过人类反馈遵循指令》。*神经信息处理系统进展*，35：27730-27744。
- en: 'Park et al. (2023) Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive
    simulacra of human behavior. *arXiv preprint arXiv:2304.03442*.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park等人（2023）Joon Sung Park、Joseph C O’Brien、Carrie J Cai、Meredith Ringel Morris、Percy
    Liang和Michael S Bernstein。2023年。《生成代理：人类行为的互动模拟物》。*arXiv预印本arXiv:2304.03442*。
- en: 'Paul et al. (2023) Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges,
    Antoine Bosselut, Robert West, and Boi Faltings. 2023. Refiner: Reasoning feedback
    on intermediate representations. *arXiv preprint arXiv:2304.01904*.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paul等人（2023）Debjit Paul、Mete Ismayilzada、Maxime Peyrard、Beatriz Borges、Antoine
    Bosselut、Robert West和Boi Faltings。2023年。《Refiner：对中间表示的推理反馈》。*arXiv预印本arXiv:2304.01904*。
- en: Pollack and Blair (1996) Jordan Pollack and Alan Blair. 1996. Why did td-gammon
    work? *Advances in Neural Information Processing Systems*, 9.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pollack和Blair（1996）Jordan Pollack和Alan Blair。1996年。《为什么TD-Gammon有效？》*神经信息处理系统进展*，9。
- en: Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario
    Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask
    learners. *OpenAI blog*, 1(8):9.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等人（2019）Alec Radford、Jeffrey Wu、Rewon Child、David Luan、Dario Amodei、Ilya
    Sutskever等。2019年。《语言模型是无监督的多任务学习者》。*OpenAI博客*，1(8)：9。
- en: 'Rafailov et al. (2023) Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano
    Ermon, Christopher D Manning, and Chelsea Finn. 2023. Direct preference optimization:
    Your language model is secretly a reward model. *arXiv preprint arXiv:2305.18290*.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rafailov等人（2023）Rafael Rafailov、Archit Sharma、Eric Mitchell、Stefano Ermon、Christopher
    D Manning和Chelsea Finn。2023年。《直接偏好优化：你的语言模型其实是一个奖励模型》。*arXiv预印本arXiv:2305.18290*。
- en: 'Ramamurthy et al. (2023) Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kianté
    Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, and
    Yejin Choi. 2023. Is reinforcement learning (not) for natural language processing:
    Benchmarks, baselines, and building blocks for natural language policy optimization.
    In *The Eleventh International Conference on Learning Representations, ICLR 2023,
    Kigali, Rwanda, May 1-5, 2023*.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramamurthy等人（2023）Rajkumar Ramamurthy、Prithviraj Ammanabrolu、Kianté Brantley、Jack
    Hessel、Rafet Sifa、Christian Bauckhage、Hannaneh Hajishirzi和Yejin Choi。2023年。《强化学习（不）适用于自然语言处理：自然语言政策优化的基准、基线和构建模块》。发表于*第十一届国际学习表征会议，ICLR
    2023，卢旺达基加利，2023年5月1-5日*。
- en: Sap et al. (2022) Maarten Sap, Ronan Le Bras, Daniel Fried, and Yejin Choi.
    2022. Neural theory-of-mind? on the limits of social intelligence in large lms.
    In *Proceedings of the 2022 Conference on Empirical Methods in Natural Language
    Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022*,
    pages 3762–3780\. Association for Computational Linguistics.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sap等人（2022）Maarten Sap、Ronan Le Bras、Daniel Fried和Yejin Choi。2022年。《神经心智理论？关于大规模语言模型社会智能的局限性》。发表于*2022年自然语言处理实证方法会议，EMNLP
    2022，阿布扎比，阿联酋，2022年12月7-11日*，第3762-3780页。计算语言学协会。
- en: Saunders et al. (2022) William Saunders, Catherine Yeh, Jeff Wu, Steven Bills,
    Long Ouyang, Jonathan Ward, and Jan Leike. 2022. Self-critiquing models for assisting
    human evaluators. *arXiv preprint arXiv:2206.05802*.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saunders等人（2022）William Saunders、Catherine Yeh、Jeff Wu、Steven Bills、Long Ouyang、Jonathan
    Ward和Jan Leike。2022年。《自我批评模型以协助人工评估者》。*arXiv预印本 arXiv:2206.05802*。
- en: Scheurer et al. (2023) Jérémy Scheurer, Jon Ander Campos, Tomasz Korbak, Jun Shern
    Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez. 2023. Training language models
    with language feedback at scale. *arXiv preprint arXiv:2303.16755*.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scheurer等人（2023）Jérémy Scheurer、Jon Ander Campos、Tomasz Korbak、Jun Shern Chan、Angelica
    Chen、Kyunghyun Cho和Ethan Perez。2023年。《通过语言反馈在大规模上训练语言模型》。*arXiv预印本 arXiv:2303.16755*。
- en: Schrittwieser et al. (2020) Julian Schrittwieser, Ioannis Antonoglou, Thomas
    Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart,
    Demis Hassabis, Thore Graepel, et al. 2020. Mastering atari, go, chess and shogi
    by planning with a learned model. *Nature*, 588(7839):604–609.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schrittwieser等人（2020）Julian Schrittwieser、Ioannis Antonoglou、Thomas Hubert、Karen
    Simonyan、Laurent Sifre、Simon Schmitt、Arthur Guez、Edward Lockhart、Demis Hassabis、Thore
    Graepel等人。2020年。《通过与学习模型的规划掌握Atari、围棋、国际象棋和将棋》。*Nature*，588（7839）：604–609。
- en: 'Shah et al. (2018a) Pararth Shah, Dilek Hakkani-Tur, Bing Liu, and Gökhan Tür.
    2018a. Bootstrapping a neural conversational agent with dialogue self-play, crowdsourcing
    and on-line reinforcement learning. In *Proceedings of the 2018 Conference of
    the North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies, Volume 3 (Industry Papers)*, pages 41–51.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shah等人（2018a）Pararth Shah、Dilek Hakkani-Tur、Bing Liu和Gökhan Tür。2018a年。《通过对话自我对弈、众包和在线强化学习启动神经对话代理》。在《2018年北美计算语言学会会议论文集：人类语言技术，卷3（行业论文）》中，第41–51页。
- en: Shah et al. (2018b) Pararth Shah, Dilek Hakkani-Tür, Gokhan Tür, Abhinav Rastogi,
    Ankur Bapna, Neha Nayak, and Larry Heck. 2018b. Building a conversational agent
    overnight with dialogue self-play. *arXiv preprint arXiv:1801.04871*.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shah等人（2018b）Pararth Shah、Dilek Hakkani-Tür、Gokhan Tür、Abhinav Rastogi、Ankur
    Bapna、Neha Nayak和Larry Heck。2018b年。《通过对话自我对弈建立对话代理》。*arXiv预印本 arXiv:1801.04871*。
- en: 'Shumailov et al. (2023) Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin
    Gal, Nicolas Papernot, and Ross Anderson. 2023. Model dementia: Generated data
    makes models forget. *arXiv preprint arXiv:2305.17493*.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shumailov等人（2023）Ilia Shumailov、Zakhar Shumaylov、Yiren Zhao、Yarin Gal、Nicolas
    Papernot和Ross Anderson。2023年。《模型痴呆：生成的数据使模型遗忘》。*arXiv预印本 arXiv:2305.17493*。
- en: Shuster et al. (2020) Kurt Shuster, Jack Urbanek, Emily Dinan, Arthur Szlam,
    and Jason Weston. 2020. Deploying lifelong open-domain dialogue learning. *arXiv
    preprint arXiv:2008.08076*.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shuster等人（2020）Kurt Shuster、Jack Urbanek、Emily Dinan、Arthur Szlam和Jason Weston。2020年。《部署终身开放域对话学习》。*arXiv预印本
    arXiv:2008.08076*。
- en: Silver et al. (2016) David Silver, Aja Huang, Chris J Maddison, Arthur Guez,
    Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou,
    Veda Panneershelvam, Marc Lanctot, et al. 2016. Mastering the game of go with
    deep neural networks and tree search. *nature*, 529(7587):484–489.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silver等人（2016）David Silver、Aja Huang、Chris J Maddison、Arthur Guez、Laurent Sifre、George
    Van Den Driessche、Julian Schrittwieser、Ioannis Antonoglou、Veda Panneershelvam、Marc
    Lanctot等人。2016年。《通过深度神经网络和树搜索掌握围棋》。*nature*，529（7587）：484–489。
- en: Silver et al. (2017) David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis
    Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian
    Bolton, et al. 2017. Mastering the game of go without human knowledge. *nature*,
    550(7676):354–359.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silver等人（2017）David Silver、Julian Schrittwieser、Karen Simonyan、Ioannis Antonoglou、Aja
    Huang、Arthur Guez、Thomas Hubert、Lucas Baker、Matthew Lai、Adrian Bolton等人。2017年。《在没有人类知识的情况下掌握围棋》。*nature*，550（7676）：354–359。
- en: Stanczak and Augenstein (2021) Karolina Stanczak and Isabelle Augenstein. 2021.
    A survey on gender bias in natural language processing. *arXiv preprint arXiv:2112.14168*.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stanczak和Augenstein（2021）Karolina Stanczak和Isabelle Augenstein。2021年。《自然语言处理中的性别偏见调查》。*arXiv预印本
    arXiv:2112.14168*。
- en: Tesauro (1994) Gerald Tesauro. 1994. Td-gammon, a self-teaching backgammon program,
    achieves master-level play. *Neural computation*, 6(2):215–219.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tesauro（1994）Gerald Tesauro。1994年。《Td-gammon，一个自我教学的西洋双陆棋程序，实现了大师级的游戏水平》。*Neural
    computation*，6（2）：215–219。
- en: 'Together Computer (2023) Together Computer. 2023. [Redpajama-data: An open
    source recipe to reproduce llama training dataset](https://github.com/togethercomputer/RedPajama-Data).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Together Computer（2023）Together Computer。2023年。[Redpajama-data: 一种开源方法重现Llama训练数据集](https://github.com/togethercomputer/RedPajama-Data)。'
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language
    models. *arXiv preprint arXiv:2302.13971*.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Touvron 等人 (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet,
    Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
    Faisal Azhar 等人. 2023. Llama: 开放且高效的基础语言模型. *arXiv 预印本 arXiv:2302.13971*。'
- en: 'Ulmer et al. (2022) Dennis Ulmer, Christian Hardmeier, and Jes Frellsen. 2022.
    deep-significance: Easy and meaningful signifcance testing in the age of neural
    networks. In *ML Evaluation Standards Workshop at the Tenth International Conference
    on Learning Representations*.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ulmer 等人 (2022) Dennis Ulmer, Christian Hardmeier 和 Jes Frellsen. 2022. deep-significance:
    在神经网络时代进行简单且有意义的显著性测试. 见于 *第十届国际学习表征会议的ML评估标准研讨会*。'
- en: Urbanek et al. (2019) Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi
    Jain, Samuel Humeau, Emily Dinan, Tim Rocktäschel, Douwe Kiela, Arthur Szlam,
    and Jason Weston. 2019. Learning to speak and act in a fantasy text adventure
    game. In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language
    Processing and the 9th International Joint Conference on Natural Language Processing,
    EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019*, pages 673–683\. Association
    for Computational Linguistics.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urbanek 等人 (2019) Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain,
    Samuel Humeau, Emily Dinan, Tim Rocktäschel, Douwe Kiela, Arthur Szlam 和 Jason
    Weston. 2019. 在幻想文本冒险游戏中学习如何说话和行动. 见于 *2019年自然语言处理经验方法大会及第九届国际联合自然语言处理大会（EMNLP-IJCNLP
    2019），中国香港，2019年11月3-7日*，第673-683页。计算语言学协会。
- en: 'Van Der Ree and Wiering (2013) Michiel Van Der Ree and Marco Wiering. 2013.
    Reinforcement learning in the game of othello: Learning against a fixed opponent
    and learning from self-play. In *2013 IEEE symposium on adaptive dynamic programming
    and reinforcement learning (ADPRL)*, pages 108–115\. IEEE.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Van Der Ree 和 Wiering (2013) Michiel Van Der Ree 和 Marco Wiering. 2013. 井字游戏中的强化学习：与固定对手对抗学习与自我对弈学习.
    见于 *2013年IEEE适应性动态编程与强化学习研讨会（ADPRL）*，第108-115页。IEEE。
- en: 'Waseem et al. (2021) Zeerak Waseem, Smarika Lulz, Joachim Bingel, and Isabelle
    Augenstein. 2021. Disembodied machine learning: On the illusion of objectivity
    in nlp. *arXiv preprint arXiv:2101.11974*.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Waseem 等人 (2021) Zeerak Waseem, Smarika Lulz, Joachim Bingel 和 Isabelle Augenstein.
    2021. 失去身体的机器学习：关于自然语言处理中的客观性错觉. *arXiv 预印本 arXiv:2101.11974*。
- en: 'Yoo et al. (2021) Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, and
    Woo-Myoung Park. 2021. Gpt3mix: Leveraging large-scale language models for text
    augmentation. In *Findings of the Association for Computational Linguistics: EMNLP
    2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021*, pages
    2225–2239\. Association for Computational Linguistics.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yoo 等人 (2021) Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee 和 Woo-Myoung
    Park. 2021. Gpt3mix: 利用大规模语言模型进行文本增强. 见于 *计算语言学协会成果：EMNLP 2021，虚拟活动 / 多米尼加共和国蓬塔卡纳，2021年11月16-20日*，第2225-2239页。计算语言学协会。'
- en: 'Zhang et al. (2023) Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou, and
    Helen Meng. 2023. Sgp-tod: Building task bots effortlessly via schema-guided llm
    prompting. *arXiv preprint arXiv:2305.09067*.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhang 等人 (2023) Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou 和 Helen Meng.
    2023. Sgp-tod: 通过模式引导的LLM提示轻松构建任务机器人. *arXiv 预印本 arXiv:2305.09067*。'
- en: Zhang et al. (2022) Zhisong Zhang, Emma Strubell, and Eduard H. Hovy. 2022.
    A survey of active learning for natural language processing. In *Proceedings of
    the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP
    2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022*, pages 6166–6190\.
    Association for Computational Linguistics.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人 (2022) Zhisong Zhang, Emma Strubell 和 Eduard H. Hovy. 2022. 自然语言处理的主动学习调查.
    见于 *2022年自然语言处理经验方法大会（EMNLP 2022），阿布扎比，阿联酋，2022年12月7-11日*，第6166-6190页。计算语言学协会。
- en: 'Zhao et al. (2022) Jeffrey Zhao, Yuan Cao, Raghav Gupta, Harrison Lee, Abhinav
    Rastogi, Mingqiu Wang, Hagen Soltau, Izhak Shafran, and Yonghui Wu. 2022. Anytod:
    A programmable task-oriented dialog system. *arXiv preprint arXiv:2212.09939*.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao 等人 (2022) Jeffrey Zhao, Yuan Cao, Raghav Gupta, Harrison Lee, Abhinav
    Rastogi, Mingqiu Wang, Hagen Soltau, Izhak Shafran 和 Yonghui Wu. 2022. Anytod:
    一个可编程的任务导向对话系统. *arXiv 预印本 arXiv:2212.09939*。'
- en: Appendix A Implementation Details
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 实现细节
- en: This appendix section focuses on several implementation details important for
    replication, but which are too specific for the main text of this work. [Section A.1](#A1.SS1
    "A.1 Data Creation ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk") is dedicated to the creation of
    the experimental data, while [Section A.2](#A1.SS2 "A.2 Self-talk Loop ‣ Appendix
    A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk") mainly focuses on the implementation details of the self-talk
    loop and on the automatic evaluation in [Section A.3](#A1.SS3 "A.3 Automatic Evaluation
    ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk").
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录部分重点介绍了几个重要的实施细节，这些细节对于复制实验至关重要，但对于本篇论文的正文来说过于具体。[A.1 节](#A1.SS1 "A.1 数据创建
    ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")专门讨论了实验数据的创建，[A.2 节](#A1.SS2 "A.2 自我对话循环
    ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")主要讨论了自我对话循环的实施细节以及[A.3 节](#A1.SS3 "A.3 自动评估
    ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")中的自动评估。
- en: A.1 Data Creation
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 数据创建
- en: Client Characters.
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 客户角色。
- en: 'We select the following characters from the LIGHT dataset (Urbanek et al.,
    [2019](#bib.bib48)) to serve as potential clients: king, person, guard, queen,
    peasant, child, knight, thief, bird, traveler, rat, villager, spider, ghost, horse,
    and farmer.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 LIGHT 数据集（Urbanek 等，[2019](#bib.bib48)）中选择了以下角色作为潜在客户：国王、平民、守卫、皇后、农民、儿童、骑士、小偷、鸟类、旅行者、老鼠、村民、蜘蛛、鬼魂、马和农夫。
- en: 'Table 2: Overview over the used agent characters and their corresponding workflow
    topics, correspondings to four, six and seven total questions as listed.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：概述了所用的代理角色及其对应的工作流主题，涵盖四个、六个和七个总问题，详见列表。
- en: '| Agent Character | Workflow Topics |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 代理角色 | 工作流主题 |'
- en: '| shop keeper | buy a longsword, buy food for a long journey, sell a valuable
    item |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 店主 | 购买一把长剑，购买长途旅行的食物，出售贵重物品 |'
- en: '| doctor | ask how to treat a headache, ask for a remedy for an fever, ask
    how to treat an animal bite |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 医生 | 询问如何治疗头痛，询问退烧药方，询问如何治疗动物咬伤 |'
- en: '| witch | give them a love potion, curse their enemy, give them a magic wand
    |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 女巫 | 给他们一个爱情药水，诅咒他们的敌人，给他们一根魔杖 |'
- en: '| tavern owner | order a drink, order a rich meal, book a bed for the night
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 酒馆老板 | 点一杯饮料，点一顿丰盛的饭菜，预定一晚的床位 |'
- en: '| genie from lamp | become rich, make the prince fall in love with them, become
    a ruler |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 灯神 | 变得富有，让王子爱上他们，成为统治者 |'
- en: Creating Agent Workflows.
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 创建代理工作流。
- en: To create agent workflows, we prompt an instruction-finetuned version of OpenLlama
    to generate dialogue workflows including four, six and seven questions or subgoals.
    These are then manually edited to ensure logical consistency and adherence to
    the given format. The topic of the workflow is tailored toward the character and
    listed in [Table 2](#A1.T2 "Table 2 ‣ Client Characters. ‣ A.1 Data Creation ‣
    Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"). We also list some examples for workflows in [Figures 7](#A1.F7
    "Figure 7 ‣ Creating Agent Workflows. ‣ A.1 Data Creation ‣ Appendix A Implementation
    Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"),
    [8](#A1.F8 "Figure 8 ‣ Creating Agent Workflows. ‣ A.1 Data Creation ‣ Appendix
    A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk") and [9](#A1.F9 "Figure 9 ‣ Creating Agent Workflows. ‣ A.1 Data
    Creation ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk").
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建代理工作流，我们使用经过指令微调的 OpenLlama 来生成包括四个、六个和七个问题或子目标的对话工作流。然后，这些工作流会经过人工编辑，以确保逻辑一致性并符合给定格式。工作流的主题会根据角色量身定制，并列在[表
    2](#A1.T2 "表 2 ‣ 客户角色 ‣ A.1 数据创建 ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")中。我们还在[图
    7](#A1.F7 "图 7 ‣ 创建代理工作流 ‣ A.1 数据创建 ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")、[8](#A1.F8
    "图 8 ‣ 创建代理工作流 ‣ A.1 数据创建 ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")和[9](#A1.F9 "图
    9 ‣ 创建代理工作流 ‣ A.1 数据创建 ‣ 附录 A 实施细节 ‣ 通过自我对话引导 LLM 基于任务的对话代理")中列出了一些工作流的示例。
- en: '<svg class="ltx_picture ltx_centering" height="182.53" id="A1.F7.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,182.53) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="154.97"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">1. "Good
    day, how can I help you?" • "I want to buy a longsword": proceed to question #2
    • "I am just browsing": "Let me know if you need anything." 2. "What kind of longsword
    are you looking for?" • "I want a short sword for close combat": "Sorry, we do
    not have these in stock." • "I want a long sword for long-range combat": proceed
    to question #3 3. "What is your budget?" • "I have 10 gold coins": proceed to
    question #4 • "I have 100 gold coins": "Here is your longsword made out of steel.
    Glad to be of service, goodbye!" • "I have 500 gold coins": "This is the highest
    quality longsword we have. Glad to be of service, goodbye!" 4. "Would you consider
    buying a dagger instead?" • "Yes, that would also work": "Here is your dagger.
    Glad to be of service, goodbye!" • "No, I really want a longsword": "I am sorry,
    we do not have longswords in this price range." • "I am not sure": "Let me know
    if you need anything else."</foreignobject></g></g></svg>'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="182.53" id="A1.F7.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,182.53) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="154.97"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">1. "Good
    day, how can I help you?" • "I want to buy a longsword": proceed to question #2
    • "I am just browsing": "Let me know if you need anything." 2. "What kind of longsword
    are you looking for?" • "I want a short sword for close combat": "Sorry, we do
    not have these in stock." • "I want a long sword for long-range combat": proceed
    to question #3 3. "What is your budget?" • "I have 10 gold coins": proceed to
    question #4 • "I have 100 gold coins": "Here is your longsword made out of steel.
    Glad to be of service, goodbye!" • "I have 500 gold coins": "This is the highest
    quality longsword we have. Glad to be of service, goodbye!" 4. "Would you consider
    buying a dagger instead?" • "Yes, that would also work": "Here is your dagger.
    Glad to be of service, goodbye!" • "No, I really want a longsword": "I am sorry,
    we do not have longswords in this price range." • "I am not sure": "Let me know
    if you need anything else."</foreignobject></g></g></svg>'
- en: 'Figure 7: Example workflow for the agent character of the shop keeper - buy
    a longsword.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：店主代理角色的示例工作流——购买一把长剑。
- en: '<svg class="ltx_picture ltx_centering" height="373.48" id="A1.F8.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,373.48) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="345.93"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">1. "Good
    day, how can I help you?" • "I was bitten by an animal": proceed to question #3
    • "I was just in the woods and got bitten by an insect": proceed to question #2
    2. "Is your bite swollen?" • "Yes, it is swollen": "Here is some ointment for
    your swollen bite. Glad to be of service, goodbye!" • "No, it is not swollen":
    "Come back tomorrow if anything changes. Glad to be of service, goodbye!" 3. "How
    is the wound?" • "It is bleeding heavily": "Here is a bandage for your bleeding
    wound, come back tomorrow. Glad to be of service, goodbye!" • "It is not bleeding
    heavily": proceed to question #4 • "It is not bleeding and the wound looks clean":
    proceed to question #5 4. "Has the wound been cleaned?" • "Yes, I cleaned it with
    water": "Here is some alcohol to clean the wound. Come back tomorrow if anything
    changes. Glad to be of service, goodbye!" • "Yes, I cleaned it with alcohol":
    proceed to question #5 • "No, I have not cleaned it": "Here is some alcohol to
    clean the wound. Come back tomorrow if anything changes. Glad to be of service,
    goodbye!" 5. "What is the animal that bit you?" • "I don’t know": proceed to question
    #6 • "It was a wolf": proceed to question #6 • "It was a dog": proceed to question
    #6 • "It was a bear": "Here is some medication for your pain. Come back tomorrow
    if anything changes. Glad to be of service, goodbye!" 6. "Do you have a fever?"
    • "Yes, I have a fever": proceed to question #7 • "No, I don’t have a fever":
    "Come back tomorrow if anything changes. Glad to be of service, goodbye!" 7. "Do
    you have any other symptoms?" • "The bite hurts a lot": "Here is some medication
    for your pain. Come back tomorrow if anything changes. Glad to be of service,
    goodbye!" • "I feel dizzy": "Make sure to drink water, eat well and rest. Come
    back tomorrow if anything changes. Glad to be of service, goodbye!" • "No, I don’t
    have any other symptoms": "Come back tomorrow if anything changes. Glad to be
    of service, goodbye!"</foreignobject></g></g></svg>'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="373.48" id="A1.F8.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,373.48) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="345.93"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">1. "Good
    day, how can I help you?" • "I was bitten by an animal": proceed to question #3
    • "I was just in the woods and got bitten by an insect": proceed to question #2
    2. "Is your bite swollen?" • "Yes, it is swollen": "Here is some ointment for
    your swollen bite. Glad to be of service, goodbye!" • "No, it is not swollen":
    "Come back tomorrow if anything changes. Glad to be of service, goodbye!" 3. "How
    is the wound?" • "It is bleeding heavily": "Here is a bandage for your bleeding
    wound, come back tomorrow. Glad to be of service, goodbye!" • "It is not bleeding
    heavily": proceed to question #4 • "It is not bleeding and the wound looks clean":
    proceed to question #5 4. "Has the wound been cleaned?" • "Yes, I cleaned it with
    water": "Here is some alcohol to clean the wound. Come back tomorrow if anything
    changes. Glad to be of service, goodbye!" • "Yes, I cleaned it with alcohol":
    proceed to question #5 • "No, I have not cleaned it": "Here is some alcohol to
    clean the wound. Come back tomorrow if anything changes. Glad to be of service,
    goodbye!" 5. "What is the animal that bit you?" • "I don’t know": proceed to question
    #6 • "It was a wolf": proceed to question #6 • "It was a dog": proceed to question
    #6 • "It was a bear": "Here is some medication for your pain. Come back tomorrow
    if anything changes. Glad to be of service, goodbye!" 6. "Do you have a fever?"
    • "Yes, I have a fever": proceed to question #7 • "No, I don’t have a fever":
    "Come back tomorrow if anything changes. Glad to be of service, goodbye!" 7. "Do
    you have any other symptoms?" • "The bite hurts a lot": "Here is some medication
    for your pain. Come back tomorrow if anything changes. Glad to be of service,
    goodbye!" • "I feel dizzy": "Make sure to drink water, eat well and rest. Come
    back tomorrow if anything changes. Glad to be of service, goodbye!" • "No, I don’t
    have any other symptoms": "Come back tomorrow if anything changes. Glad to be
    of service, goodbye!"</foreignobject></g></g></svg>'
- en: 'Figure 8: Example workflow for the agent character of the doctor - as how to
    treat an animal bite.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：医生代理角色的示例工作流——如何处理动物咬伤。
- en: '<svg class="ltx_picture ltx_centering" height="293.23" id="A1.F9.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,293.23) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="265.67"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">1. "Good
    day, what do you wish for?" • "I want to make the prince fall in love with me":
    proceed to question #4 • "I want to make the prince notice me": proceed to question
    #2 • "I don’t know": "Let me know how I can help you." 2. "Do you want the prince
    to fall in love with you?" • "Yes, I want the prince to fall in love with me":
    proceed to question #4 • "No, I just want the prince to notice me": proceed to
    question #3 3. "In what setting do you want the prince to notice you?" • "In a
    ballroom": "Here is your new outfit and invitation to the royal ball. Glad to
    be of service, goodbye!" • "In a garden": "Here is your new outfit and invitation
    to the royal garden party. Glad to be of service, goodbye!" • "In a royal banquet":
    "Here is your new outfit and invitation to the royal banquet. Glad to be of service,
    goodbye!" 4. "What is your reason for wanting the prince to fall in love with
    you?" • "I want to have a lot of wealth": proceed to question #5 • "I want to
    have a lot of power": proceed to question #6 • "I want the beautiful prince to
    be my husband": "The prince is now in love with you and will seek you out soon.
    Glad to be of service, goodbye!" 5. "Do you just want me to make you rich instead?"
    • "Yes, I just want to be rich": "Here is your new wealth. Glad to be of service,
    goodbye!" • "No, I want the prince to fall in love with me": "The prince is now
    in love with you and will seek you out soon. Glad to be of service, goodbye!"
    6. "Do you just want me to make you powerful instead?" • "Yes, I just want to
    be powerful": "You are now the ruler of the kingdom. Glad to be of service, goodbye!"
    • "No, I want the prince to fall in love with me": "The prince is now in love
    with you and will seek you out soon. Glad to be of service, goodbye!"</foreignobject></g></g></svg>'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="293.23" id="A1.F9.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,293.23) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="265.67"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">1. "Good
    day, what do you wish for?" • "I want to make the prince fall in love with me":
    proceed to question #4 • "I want to make the prince notice me": proceed to question
    #2 • "I don’t know": "Let me know how I can help you." 2. "Do you want the prince
    to fall in love with you?" • "Yes, I want the prince to fall in love with me":
    proceed to question #4 • "No, I just want the prince to notice me": proceed to
    question #3 3. "In what setting do you want the prince to notice you?" • "In a
    ballroom": "Here is your new outfit and invitation to the royal ball. Glad to
    be of service, goodbye!" • "In a garden": "Here is your new outfit and invitation
    to the royal garden party. Glad to be of service, goodbye!" • "In a royal banquet":
    "Here is your new outfit and invitation to the royal banquet. Glad to be of service,
    goodbye!" 4. "What is your reason for wanting the prince to fall in love with
    you?" • "I want to have a lot of wealth": proceed to question #5 • "I want to
    have a lot of power": proceed to question #6 • "I want the beautiful prince to
    be my husband": "The prince is now in love with you and will seek you out soon.
    Glad to be of service, goodbye!" 5. "Do you just want me to make you rich instead?"
    • "Yes, I just want to be rich": "Here is your new wealth. Glad to be of service,
    goodbye!" • "No, I want the prince to fall in love with me": "The prince is now
    in love with you and will seek you out soon. Glad to be of service, goodbye!"
    6. "Do you just want me to make you powerful instead?" • "Yes, I just want to
    be powerful": "You are now the ruler of the kingdom. Glad to be of service, goodbye!"
    • "No, I want the prince to fall in love with me": "The prince is now in love
    with you and will seek you out soon. Glad to be of service, goodbye!"</foreignobject></g></g></svg>'
- en: 'Figure 9: Example workflow for the agent character of the genie from lamp -
    make the prince fall in love with them.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：代理角色“灯神”的示例工作流程——使王子爱上他们。
- en: A.2 Self-talk Loop
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 自我对话循环
- en: In this section we give more information on the core ingredients of the self-talk
    loop, including the actual dialogue simulation, model prompts and finetuning details.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了关于自我对话循环核心组成部分的更多信息，包括实际的对话模拟、模型提示和微调细节。
- en: Dialogue Simulation.
  id: totrans-193
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话模拟。
- en: 'The dialogue simulation follows these steps: An agent utterance and a client
    utterance, both followed by some postprocessing, then followed up by a routine
    checking whether the conversation has ended or not. For the generation, we sample
    up to 100 tokens using nucleus sampling with $p=0.95$ (Holtzman et al., [2020](#bib.bib17))
    and top-$k$ sampling (Fan et al., [2018](#bib.bib9); Holtzman et al., [2018](#bib.bib18);
    Radford et al., [2019](#bib.bib30)) with $k=50$ and a temperature of $0.8$. We
    also observed that models struggled to only generate a single utterance at a time,
    and would tend to try and generate the whole dialogue. Therefore, we implement
    a custom stopping criterion that stops sampling once the name of the other character
    is being generated. For the postprocessing, we use regular expressions to remove
    the remaining fragments of this kind from the generation, along with incomplete
    sentences and code fragments. The ending check includes checking for key phrases
    such as good luck, goodbye, you’re welcome in the last two utterances. Furthermore,
    we send the last turn to the 30 billion parameter MosaicAI chat model using the
    following prompt:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对话模拟遵循以下步骤：一个代理发话和一个客户端发话，每个发话之后都有一些后处理，然后检查对话是否结束的常规流程。对于生成部分，我们使用核采样（nucleus
    sampling）以$p=0.95$（Holtzman等， [2020](#bib.bib17)）和top-$k$采样（Fan等， [2018](#bib.bib9)；Holtzman等，
    [2018](#bib.bib18)；Radford等， [2019](#bib.bib30)）进行最多100个token的采样，$k=50$，温度设置为$0.8$。我们还观察到模型在每次只生成单一发话时存在困难，通常会尝试生成整个对话。因此，我们实现了一个自定义的停止标准，当生成到另一个角色的名字时就停止采样。对于后处理，我们使用正则表达式删除生成中的剩余片段，包括不完整的句子和代码片段。结束检查包括检查最后两次发话中的关键短语，如“祝好运”，“再见”，“不客气”。此外，我们将最后一次发话发送给30亿参数的MosaicAI聊天模型，使用以下提示：
- en: '<svg class="ltx_picture" height="128.06" id="A1.SS2.SSS0.Px1.p2.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,128.06) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 410.33 102.76)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">End Detection Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="80.25" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">You are an expert in identifying parts of a conversation.
    This is an excerpt from a conversation: {agent_utterance} {client_utterance} What
    part of a conversation is this from? Answer only [start/middle/end]. Correct answer:</foreignobject></g></g></svg>'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="128.06" id="A1.SS2.SSS0.Px1.p2.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,128.06) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 410.33 102.76)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">End Detection Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="80.25" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">You are an expert in identifying parts of a conversation.
    This is an excerpt from a conversation: {agent_utterance} {client_utterance} What
    part of a conversation is this from? Answer only [start/middle/end]. Correct answer:</foreignobject></g></g></svg>'
- en: We give the LLM a single token for the answer, and finish the conversation when
    it is “end”. We furthermore speed up the generation process using the accelerate
    package⁴⁴4See [https://huggingface.co/docs/accelerate/](https://huggingface.co/docs/accelerate/)
    and always generate a batch of conversations at once, replacing single instances
    immediately when they finish.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们给LLM一个单一的token作为答案，当答案是“end”时结束对话。我们还通过使用accelerate包加速生成过程⁴⁴4参见[https://huggingface.co/docs/accelerate/](https://huggingface.co/docs/accelerate/)，并且总是一次性生成一批对话，生成完后立即替换单个实例。
- en: Structured Prompting
  id: totrans-197
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 结构化提示
- en: 'In order to improve the degree of which the agent model follows a given workflow,
    we employ a turn-based prompting scheme. For this purpose, we parse every workflow
    into a directed graph with vertices corresponding to agent questions and edges
    to possible answers. Taking [Figure 7](#A1.F7 "Figure 7 ‣ Creating Agent Workflows.
    ‣ A.1 Data Creation ‣ Appendix A Implementation Details ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk") for instance, “Good day, how I can
    help you?” would correspond to the first node, and “I want to buy a longsword”
    and “I am just browsing” to outgoing edges. Any question is given to the agent
    in the form of the following prompt:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高代理模型遵循给定工作流程的程度，我们采用了基于回合的提示方案。为此，我们将每个工作流程解析为一个有向图，其中顶点对应代理问题，边对应可能的答案。以[图7](#A1.F7
    "图 7 ‣ 创建代理工作流程 ‣ A.1 数据创建 ‣ 附录 A 实现细节 ‣ 基于自我对话的任务导向对话代理的启动")为例，“Good day, how
    I can help you?”对应于第一个节点，而“I want to buy a longsword”和“I am just browsing”对应于外向边。任何问题都以以下提示形式提供给代理：
- en: <svg class="ltx_picture" height="161.26" id="A1.SS2.SSS0.Px2.p2.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,161.26) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 419.55 135.97)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">Agent Model Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="113.46" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69"><|im_start|> You are playing a {character}. {first_person_persona}
    Once and only if the conversation has ended, say "goodbye". {dialogue_history_slot}
    Now, you must say {turn_prompt_slot}. <|im_end|></foreignobject></g></g></svg>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="161.26" id="A1.SS2.SSS0.Px2.p2.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,161.26) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 419.55 135.97)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">Agent Model Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="113.46" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69"><|im_start|> You are playing a {character}. {first_person_persona}
    Once and only if the conversation has ended, say "goodbye". {dialogue_history_slot}
    Now, you must say {turn_prompt_slot}. <|im_end|></foreignobject></g></g></svg>
- en: 'where first_person_persona corresponds to a persona from the LIGHT datasets
    reworded in first person, dialogue_history_slot to the dialogue history up until
    that point (and empty in the beginning) and turn_prompt_slot to the current command,
    so “Good day, how I can help you?” in the beginning. After the client respond
    to the agents initial questions, we then prompt the model with following:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其中first_person_persona对应LIGHT数据集中用第一人称重新表述的人物角色，dialogue_history_slot对应到目前为止的对话历史（开始时为空），turn_prompt_slot对应当前的命令，所以一开始的“Good
    day, how I can help you?”就是这样的提示。在客户端回答代理的初始问题后，我们接着用以下提示给模型：
- en: '<svg class="ltx_picture" height="194.47" id="A1.SS2.SSS0.Px2.p4.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,194.47) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 383.35 169.18)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">Workflow Manager Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="146.67" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69"><|im_start|> You rate the similarity of texts.
    Take the following sentence: {client_utterance}. Only select the option below
    that is most similar: {options} Correct answer: <|im_end|></foreignobject></g></g></svg>'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="194.47" id="A1.SS2.SSS0.Px2.p4.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,194.47) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 383.35 169.18)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">Workflow Manager Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="146.67" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69"><|im_start|> You rate the similarity of texts.
    Take the following sentence: {client_utterance}. Only select the option below
    that is most similar: {options} Correct answer: <|im_end|></foreignobject></g></g></svg>'
- en: where options contains all the outgoing edges as numbered options as well as
    a “None of the above”. If one of the former options is selected by the model,
    we traverse the workflow graph along the corresponding edge and insert the next
    question into the first prompt. If the “None of the above” option is selected,
    we remain in the same state and modify the last line of the first prompt to “Now
    you must say any natural reply”. We note that while it seem most intuitive to
    let the agent model choose the next options, we actually give this prompt to the
    client model, since it is larger and we can optimize it for inference since it
    is not finetuned. However, it would also possible to use the agent or even a third
    model for this purpose.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 其中选项包含所有外向边作为编号选项，以及一个“以上都不是”选项。如果模型选择了前者之一，我们会沿着相应的边遍历工作流图，并将下一个问题插入第一个提示中。如果选择了“以上都不是”选项，我们保持在当前状态，并将第一个提示的最后一行修改为“现在你必须给出任何自然的回复”。我们注意到，虽然让智能体模型选择下一个选项似乎是最直观的，但我们实际上将这个提示给客户端模型，因为它更大，我们可以对其进行推理优化，因为它并未经过微调。然而，也可以使用智能体模型甚至第三个模型来实现这一目的。
- en: Client Prompting.
  id: totrans-203
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 客户端提示。
- en: 'For completeness, we also share the prompt used for the client model, which
    is very similar in nature to the agent’s prompt:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，我们还分享了客户端模型使用的提示，其性质与智能体的提示非常相似：
- en: <svg class="ltx_picture" height="161.26" id="A1.SS2.SSS0.Px3.p2.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,161.26) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 419.17 135.97)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">Client Model Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="113.46" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69"><|im_start|> You are playing a {character}. {first_person_persona}
    Now, your main intention is to talk to the {agent_character} to {intention}. Once
    and only if the conversation has ended, tell them "goodbye". Now, briefly respond
    to {agent_character} and describe your intention. <|im_end|> {dialogue_history_slot}</foreignobject></g></g></svg>
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="161.26" id="A1.SS2.SSS0.Px3.p2.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,161.26) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 419.17 135.97)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">Client Model Prompt</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="113.46" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69"><|im_start|> You are playing a {character}. {first_person_persona}
    Now, your main intention is to talk to the {agent_character} to {intention}. Once
    and only if the conversation has ended, tell them "goodbye". Now, briefly respond
    to {agent_character} and describe your intention. <|im_end|> {dialogue_history_slot}</foreignobject></g></g></svg>
- en: In contrast to the agent, the client is given this prompt only in the beginning
    and then tries to continue the history of the conversation given in dialogue_history_slot.
    The client model is not being finetuned.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 与智能体不同，客户端仅在开始时给出这个提示，然后尝试继续对话历史（由`dialogue_history_slot`提供）。客户端模型并未进行微调。
- en: Finetuning.
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 微调。
- en: Because it is infeasible to finetune the agent model in its entirety, we instead
    opt for the low-rank adapation or LoRA by Hu et al. ([2022](#bib.bib19)). LoRA
    factorizes the gradient update $\Delta\mathbf{W}\in\mathbb{R}^{d\times d}$ for
    a parameter matrix $\mathbf{W}\in\mathbb{R}^{d\times d}$ into two low-rank matrices
    $\Delta\mathbf{W}=\mathbf{AB}$ with $\mathbf{A}\in\mathbb{R}^{d\times r}$ and
    $\mathbf{B}\in\mathbb{R}^{r\times d}$ s.t. $r\ll d$. We apply these technique
    to all linear layers in the model using $r=64$ only optimize the these low-rank
    matrices with a learning rate of $5\times 10^{-4}$, a weight decay of $0.01$ and
    batch size $4$ for a single epoch per finetuning loop. All finetuning (as well
    as the dialogue generation from the previous step) is performed on four NVIDIA
    A10G Tensor Core GPUs.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 由于完全微调智能体模型是不可行的，我们选择了胡等人提出的低秩适配（LoRA）（[2022](#bib.bib19)）。LoRA将参数矩阵$\mathbf{W}\in\mathbb{R}^{d\times
    d}$的梯度更新$\Delta\mathbf{W}\in\mathbb{R}^{d\times d}$分解为两个低秩矩阵$\Delta\mathbf{W}=\mathbf{AB}$，其中$\mathbf{A}\in\mathbb{R}^{d\times
    r}$，$\mathbf{B}\in\mathbb{R}^{r\times d}$，使得$r\ll d$。我们对模型中的所有线性层应用这些技术，仅优化这些低秩矩阵，使用$r=64$，学习率为$5\times
    10^{-4}$，权重衰减为$0.01$，批大小为$4$，每个微调循环进行一个epoch。所有微调（以及前一步的对话生成）都在四个NVIDIA A10G Tensor
    Core GPU上进行。
- en: A.3 Automatic Evaluation
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 自动评估
- en: In this section we give more details on the automated evaluation metrics we
    use to assess the quality of dialogues.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细介绍了我们用来评估对话质量的自动化评估指标。
- en: Subgoal Completion.
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 子目标完成。
- en: 'We lay out the method to measure subgoal completion in detail in [Section 4.1](#S4.SS1
    "4.1 Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"). In order to set the initial threshold thay ROUGE values
    have to surpass, we refer to another task-oriented dialogue dataset, namely ABCD
    (Chen et al., [2021](#bib.bib4)). The dataset consists of $10042$ conversation
    with corresponding conversational workflows, of which we use the first $500$ in
    the following: In order to match workflow steps to dialogue utterances, we assume
    that the correct utterance is the one that has the highest ROUGE-L score in comparison
    to the current workflow step. We then collect all the previous utterances in the
    conversation as negative examples and use all the samples from the dataset to
    find the threshold that optimizes for precision, which we obtain as $0.33$. Even
    though optimizing for precision produces a more conversative threshold that is
    likely to underestimate subgoal completion, we found optimizing for recall to
    always yielding a trivial threshold of $0$, likely due to noise in the data.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第4.1节](#S4.SS1 "4.1 评估 ‣ 4 实验 ‣ 通过自我对话引导基于LLM的任务导向对话代理")中详细介绍了测量子目标完成的方法。为了设置初始的阈值，即ROUGE值必须超过的值，我们参考了另一个任务导向对话数据集，即ABCD（Chen等人，[2021](#bib.bib4)）。该数据集包含$10042$个对话及其对应的对话流程，我们在以下使用前$500$个对话：为了将流程步骤与对话话语匹配，我们假设正确的对话话语是与当前流程步骤相比ROUGE-L分数最高的那一句。然后，我们收集对话中的所有先前话语作为负样本，并使用数据集中的所有样本来寻找优化精度的阈值，最终得到$0.33$。尽管优化精度会产生一个更保守的阈值，可能低估子目标完成情况，但我们发现优化召回率总是产生一个显而易见的$0$阈值，这可能是由于数据中的噪声造成的。
- en: Character Consistency.
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 角色一致性。
- en: 'We train our dungeon master using a batch size of $40$ for a total number of
    $15$ epochs. We also use the first $10\%$ of the training as warmup for an inverse
    square-root learning rate schedule with a maximum learning rate of $5\times 10^{-5}$.
    To combat class imbalance, we compute class weights on the training set that are
    supplied to the loss function. Training instances are supplied to the DeBERTA
    model using the format of [CLS] {character}: {persona} [SEP] {utterance} and context
    length of $256$ tokens.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用批量大小为$40$，共$15$个训练轮次来训练我们的地下城主人。我们还使用训练的前$10\%$作为热身，采用逆平方根学习率调度，最大学习率为$5\times
    10^{-5}$。为了应对类别不平衡问题，我们计算训练集中的类别权重，并将其传递给损失函数。训练实例以[CLS] {角色}: {人格} [SEP] {话语}的格式输入DeBERTA模型，且上下文长度为$256$个标记。'
- en: Dialogue Diversity.
  id: totrans-215
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话多样性。
- en: To measure the diversity in dialogues, we first try to quanity the number of
    unique words and $n$-grams (up to order $5$) in all dialogues corresponding to
    a specific agent character. Furthermore, we compare up to $25$ pairs of dialogues
    per agent character and compute pair-wise ROUGE-L scores, of which we take the
    average. Since higher values for unique tokens and $n$-grams denote higher diversity,
    we define one minus the average pair-wise ROUGE-L score as a diversity metric.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量对话的多样性，我们首先尝试量化与特定代理角色对应的所有对话中的独特词汇和$n$-grams（最高到$5$阶）的数量。此外，我们比较每个代理角色的最多$25$对对话，计算成对的ROUGE-L分数，并取其平均值。由于独特词汇和$n$-grams的值越高表示多样性越高，我们将1减去成对ROUGE-L分数的平均值作为多样性指标。
- en: Appendix B Experimental Appendix
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 实验附录
- en: This appendix supplies additional experimental analyses that had to be left
    out from the main paper due to spatial constraints. [Section B.1.3](#A2.SS1.SSS3
    "B.1.3 Meta-Evaluation ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")
    gives further details on the meta-evaluation of our automated metrics laid out
    in [Section 4.1](#S4.SS1 "4.1 Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk"), with [Section B.2](#A2.SS2 "B.2
    Human Evaluation Study ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk") describing the human evaluation
    study from [Section 4.3](#S4.SS3 "4.3 Human Evaluation ‣ 4 Experiments ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"). In addition, we discuss
    some miscellaenous insights gained from our work in [Section B.3](#A2.SS3 "B.3
    Miscellaenous Insights ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk") in the hope of aiding future research
    in this direction, while [Section B.4](#A2.SS4 "B.4 Sample Conversations ‣ Appendix
    B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk") displays a wide variety of sampled conversations, illustrating
    success stories as well as the most commonly observed failure cases.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录提供了由于空间限制未能包含在主文中的额外实验分析。[第B.1.3节](#A2.SS1.SSS3 "B.1.3 Meta-Evaluation ‣
    B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk")详细说明了我们在[第4.1节](#S4.SS1
    "4.1 Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk")中阐述的自动化评估指标的元评估，而[第B.2节](#A2.SS2 "B.2 Human Evaluation Study
    ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk")描述了[第4.3节](#S4.SS3 "4.3 Human Evaluation ‣ 4 Experiments
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")中的人工评估研究。此外，我们还讨论了在[第B.3节](#A2.SS3
    "B.3 Miscellaenous Insights ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk")中获得的一些额外见解，希望能够为未来在这一方向的研究提供帮助，同时[第B.4节](#A2.SS4
    "B.4 Sample Conversations ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk")展示了各种采样对话，展示了成功案例以及最常见的失败案例。
- en: B.1 Validation of Automated Metrics
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 自动化评估指标的验证
- en: In the following we give more details for the validation of our automated metrics,
    from a description of the annotation guidelines ([Section B.1.1](#A2.SS1.SSS1
    "B.1.1 Annotation Guidelines ‣ B.1 Validation of Automated Metrics ‣ Appendix
    B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk")), dialogue statistics ([Section B.1.2](#A2.SS1.SSS2 "B.1.2 Dialogue
    statistics ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")) and finally
    the meta-evaluation of our automated metrics ([Section B.1.3](#A2.SS1.SSS3 "B.1.3
    Meta-Evaluation ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下我们将详细介绍自动化评估指标的验证过程，包括注释指南的描述（[第B.1.1节](#A2.SS1.SSS1 "B.1.1 Annotation Guidelines
    ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk")）、对话统计数据（[第B.1.2节](#A2.SS1.SSS2
    "B.1.2 Dialogue statistics ‣ B.1 Validation of Automated Metrics ‣ Appendix B
    Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk")）以及最后对我们自动化评估指标的元评估（[第B.1.3节](#A2.SS1.SSS3 "B.1.3 Meta-Evaluation
    ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk")）。
- en: B.1.1 Annotation Guidelines
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.1.1 注释指南
- en: 'In order to annotate our sampled conversations and contextualize subsequent
    results, we define the following annotation guidelines:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对我们采样的对话进行注释并对后续结果进行背景说明，我们定义了以下注释指南：
- en: •
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Character Consistency: We take each utterance of the agent and client and score
    them with $0$ for out-of-character, $1$ for in-character and $0.5$ for undecided.
    The utterance is scored based on the character, persona and given intention.⁵⁵5Therefore,
    a bird wanting to become a king by asking a genie is still in character if that
    was the given intention. We score the utterance in isolation from the wider dialogue
    context.'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 角色一致性：我们对代理和客户的每个发言进行评分，其中$0$表示不符合角色，$1$表示符合角色，$0.5$表示未决定。评分基于角色、人物设定和给定的意图。因此，如果一只鸟通过向精灵求愿成为国王，并且这是给定的意图，那么它仍然符合角色。我们对发言进行评分时，忽略了更广泛的对话上下文。
- en: •
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Subgoal Completion: For every utterance of the agent, we mark it with $0$ if
    they do not correspond to a subgoal, and otherwise with <question number> or <question
    number>.<agent response number> when we end the conversation instead of proceeding
    to the next question. Taking for instance the workflow in [Figure 7](#A1.F7 "Figure
    7 ‣ Creating Agent Workflows. ‣ A.1 Data Creation ‣ Appendix A Implementation
    Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"),
    $2.$ corresponds to the question *“What kind of longsword are you looking for?”*
    and $4.3$ to *“Let me know if you need anything else”*. Subgoals do not have to
    be completed in a given order.'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 子目标完成情况：对于每个代理的发言，我们标记为$0$，如果该发言不对应任何子目标；如果在结束对话而非继续下一个问题时，则标记为<问题编号>或<问题编号>.<代理回应编号>。以[图7](#A1.F7
    "图7 ‣ 创建代理工作流 ‣ A.1 数据创建 ‣ 附录A 实现细节 ‣ 通过自我对话引导LLM任务导向对话代理")中的工作流为例，$2.$对应问题*“你在寻找什么样的长剑？”*，而$4.3$对应*“如果你需要其他帮助，告诉我。”*。子目标的完成顺序不需要按给定顺序进行。
- en: •
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dialogue Success: We score the dialogue with $1$ if the original intention
    of the client was fulfilled, $0$ in case it was not, and $0.5$ for undecided.
    This can be independent from whether the actual dialogue flow was adhered to or
    not.'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对话成功率：如果客户的原始意图得以实现，则对话得分为$1$，如果没有实现，则为$0$，对于无法确定的情况则为$0.5$。这可以独立于实际对话流是否得以遵循。
- en: •
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dialogue Quality: We rate the quality of dialogues on a five point scale:'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对话质量：我们使用五分制评分来评定对话质量：
- en: –
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '*1 - Very bad*: LLMs are not adhering to dialogue format, produce code or other
    unwanted artifacts.'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 - 非常差*：LLM未遵循对话格式，产生代码或其他不需要的产物。'
- en: –
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '*2 - Bad*: LLMs adhere to a dialogue format, but the dialogue contains loops,
    repetitions, major flaws in logic or LLMs break character or is very short.'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*2 - 差*：LLM遵循对话格式，但对话中存在循环、重复、逻辑严重缺陷，或者LLM破坏角色扮演，或者对话过于简短。'
- en: –
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '*3 - Okay*: LLMs mostly stay in character and show only minor flaws in logic,
    dialogue flow and client intention are somewhat adhered to.'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*3 - 一般*：LLM大部分时间保持角色，并仅显示出轻微的逻辑缺陷，对话流和客户意图有所遵循。'
- en: –
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '*4 - Good*: LLMs stay in character except for minor flaws in logic or role-playing,
    dialogue is successful and mostly follows the dialogue flow.'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*4 - 好*：LLM保持角色，除非在逻辑或角色扮演上有轻微缺陷，对话基本成功并大致遵循对话流。'
- en: –
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '*5 - Very good*: LLMs always stay in character and show no flaws in logic or
    role-playing. The dialogue almost completely or completely follows the workflow.'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*5 - 非常好*：LLM始终保持角色，并且没有逻辑或角色扮演的缺陷。对话几乎完全或完全遵循工作流。'
- en: •
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Ending: $1$ if the conversation ended in a natural way, $0$ if not or if it
    didn’t end at all. This is to check whether the LLM-based ending detection described
    in [Section A.2](#A1.SS2 "A.2 Self-talk Loop ‣ Appendix A Implementation Details
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk") would
    work as expected.'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结束：如果对话自然结束，则为$1$，如果没有结束或没有正常结束，则为$0$。这用于检查[第A.2节](#A1.SS2 "A.2 自我对话循环 ‣ 附录A
    实现细节 ‣ 通过自我对话引导LLM任务导向对话代理")中描述的LLM基于结束检测是否按预期工作。
- en: B.1.2 Dialogue statistics
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.1.2 对话统计
- en: '![Refer to caption](img/8204cf60752b628a60e6afe30f95626e.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8204cf60752b628a60e6afe30f95626e.png)'
- en: (a) Dialogue quality.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 对话质量。
- en: '![Refer to caption](img/909f4056e341530f063bbd4b5fe57067.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/909f4056e341530f063bbd4b5fe57067.png)'
- en: (b) Dialogue quality by character.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 按角色分类的对话质量。
- en: '![Refer to caption](img/7b1ceccbf317472f51d9dec2e3afa4e2.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7b1ceccbf317472f51d9dec2e3afa4e2.png)'
- en: (c) Dialogue success by character.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 按角色分类的对话成功率。
- en: 'Figure 10: Overview over different dialogue statistics for $50$ annotated examples.
    Shown are (a) the dialogue quality on a five point scale, (b) the same dialogue
    quality by agent character and (c) the dialogue success by character.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：$50$个标注示例的不同对话统计概览。展示了（a）五分制对话质量，（b）按代理角色分类的对话质量，（c）按角色分类的对话成功率。
- en: Dialogue Quality.
  id: totrans-251
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对话质量。
- en: 'We first provide a general overview over the properties of the annotated dialogues.
    [Figure 9(a)](#A2.F9.sf1 "9(a) ‣ Figure 10 ‣ B.1.2 Dialogue statistics ‣ B.1 Validation
    of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based
    Task-Oriented Dialogue Agents via Self-Talk") shows a histogram of dialogue qualities
    in the annotated sample. The median dialogue quality is $2.65$, which half of
    the dialogues rated $3$ or higher. A perfect rating of $5$ is only achieved by
    six conversations in total. Looking at the dialogue quality per character in [Figure 9(b)](#A2.F9.sf2
    "9(b) ‣ Figure 10 ‣ B.1.2 Dialogue statistics ‣ B.1 Validation of Automated Metrics
    ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"), we can identify certain disparities between the different
    characters. We explain these differences through two factors: The characters of
    shop keeper and doctor seems to comparatively be the easiest to roleplay, since
    they are closer to the data the model was trained on compared to more unconventionial
    characters as the genie or the witch. In the case of the tavern owner, we found
    that the LLM-based ending detection was producing many false positives for unintuitive
    reasons; thus these conversations would be rated low in quality and as unsuccessful,
    as shown in [Figure 9(c)](#A2.F9.sf3 "9(c) ‣ Figure 10 ‣ B.1.2 Dialogue statistics
    ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"). While many dialogue from
    the genie and witch are rated low in quality because they might not adhere to
    the given workflow, [Figure 9(c)](#A2.F9.sf3 "9(c) ‣ Figure 10 ‣ B.1.2 Dialogue
    statistics ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk") shows
    how may of them still end successfully for the client. Overall, we found $28$
    out of the $50$ dialogues to end successfully for the client, with $16$ failure
    and $6$ unclear cases.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先提供一个关于标注对话属性的总体概述。[图 9(a)](#A2.F9.sf1 "9(a) ‣ 图 10 ‣ B.1.2 对话统计 ‣ B.1 自动化度量验证
    ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于LLM的任务导向对话代理")展示了标注样本中对话质量的直方图。对话质量的中位数为$2.65$，这意味着一半的对话评分为$3$或更高。满分$5$的评分仅有六个对话获得。通过[图 9(b)](#A2.F9.sf2
    "9(b) ‣ 图 10 ‣ B.1.2 对话统计 ‣ B.1 自动化度量验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于LLM的任务导向对话代理")观察每个角色的对话质量，我们可以发现不同角色之间存在一定的差异。我们通过两个因素来解释这些差异：商店老板和医生的角色似乎相对容易扮演，因为它们与模型训练数据更为接近，而像精灵或女巫这样的非传统角色则较为困难。以酒馆老板为例，我们发现基于LLM的结束检测产生了许多错误的阳性结果，原因并不直观；因此这些对话的质量较低，并且被评为不成功，正如[图 9(c)](#A2.F9.sf3
    "9(c) ‣ 图 10 ‣ B.1.2 对话统计 ‣ B.1 自动化度量验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于LLM的任务导向对话代理")所示。尽管精灵和女巫的许多对话因可能未遵循既定工作流程而被评为低质量，[图 9(c)](#A2.F9.sf3
    "9(c) ‣ 图 10 ‣ B.1.2 对话统计 ‣ B.1 自动化度量验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于LLM的任务导向对话代理")仍然显示了许多对话成功地为客户达成了目标。总体而言，我们发现$50$个对话中有$28$个成功为客户达成目标，$16$个失败，$6$个不明确的案例。
- en: B.1.3 Meta-Evaluation
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: B.1.3 元评估
- en: Character Consistency.
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 角色一致性.
- en: 'Since we are employing a neural metric to measure the character consistency
    of the agent, it is important to check whether the dungeon master model from [Section 4.1](#S4.SS1
    "4.1 Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk") and [Section A.3](#A1.SS3 "A.3 Automatic Evaluation ‣ Appendix
    A Implementation Details ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk") is able to rate utterances reliably. We find that it rates the
    agent and client lines as predominantly in character (with a mean rating of $0.97$
    and $0.98$, respectively). More importantly, by applying the canonical threshold
    of $0.5$, the classifier achieves an accuracy of $0.87$ and a $F_{1}$ score of
    $0.93$ with respect to the gold annotations. This suggests two things: Despite
    some remaining noise or model error, our classifier overall is able to rate utterances
    with high reliability and the high in-character score of the client model confirms
    our decision *not* to update the client model.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用神经度量来衡量代理的角色一致性，因此检查[第 4.1 节](#S4.SS1 "4.1 评估 ‣ 4 实验 ‣ 通过自我对话引导基于大语言模型的任务导向对话代理")和[第
    A.3 节](#A1.SS3 "A.3 自动评估 ‣ 附录 A 实现细节 ‣ 通过自我对话引导基于大语言模型的任务导向对话代理")中的地下城大师模型是否能可靠地评估发话非常重要。我们发现，该模型将代理和客户的发话大部分评定为符合角色（平均评分分别为
    $0.97$ 和 $0.98$）。更重要的是，通过应用 $0.5$ 的标准阈值，分类器在金标准注释上的准确率为 $0.87$，$F_{1}$ 分数为 $0.93$。这表明两点：尽管存在一些噪声或模型误差，我们的分类器总体上能够高可靠性地评估发话，而客户模型的高符合角色得分也确认了我们*不*更新客户模型的决策。
- en: '![Refer to caption](img/3f39268b23e1fc10123455641bda3bff.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/3f39268b23e1fc10123455641bda3bff.png)'
- en: (a) Absolute number of subgoals.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 子目标的绝对数量。
- en: '![Refer to caption](img/8b93ce3bfee5b2c6cd798e9a0393ddef.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/8b93ce3bfee5b2c6cd798e9a0393ddef.png)'
- en: (b) Relative number of subgoals.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 子目标的相对数量。
- en: 'Figure 11: Overview over the progress in workflows in the annotated dialogues.
    Shown are (a) the absolute number of subgoals achieved (Absolute Depth) and, adjusting
    for workflows of different lengths, (b) the relative number of subgoals achieved
    (Relative Depth).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：标注对话中的工作流进展概述。显示的是（a）实现的子目标的绝对数量（绝对深度）以及经过不同长度工作流调整后的（b）实现的子目标的相对数量（相对深度）。
- en: '![Refer to caption](img/b70b67486e8355828bda7702214964e5.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/b70b67486e8355828bda7702214964e5.png)'
- en: 'Figure 12: Scatter plot between the percentage of the steps in a workflow completed
    compared between the gold annotations (y-axis) and automatic evaluations (x-axis).
    The also plot a least-squares linear fit and the corresponding Pearson’s $\rho$
    value in red.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：工作流中完成的步骤百分比与金标准注释（y 轴）和自动评估（x 轴）之间的散点图。图中还绘制了最小二乘法线性拟合以及相应的 Pearson $\rho$
    值（红色）。
- en: Subgoal Completion.
  id: totrans-263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 子目标完成情况。
- en: 'The other automatic metric is concerned with evaluating the progress of the
    agent in executing the given dialogue workflow. In [Figure 11](#A2.F11 "Figure
    11 ‣ Character Consistency. ‣ B.1.3 Meta-Evaluation ‣ B.1 Validation of Automated
    Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk"), we show that most dialogues only fulfil a mean
    of $2.56$ subgoals and a mean $37\%$ of the entire workflow. Since these number
    are based on the untrained agent model, this at least suggests that the filtered
    data can contain sufficiently many useful dialogue samples for finetuning. Based
    on the results in [Figure 12](#A2.F12 "Figure 12 ‣ Character Consistency. ‣ B.1.3
    Meta-Evaluation ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")
    and [Figure 9(a)](#A2.F9.sf1 "9(a) ‣ Figure 10 ‣ B.1.2 Dialogue statistics ‣ B.1
    Validation of Automated Metrics ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"), we conclude that our
    setup can yield between $5-20\%$ usable conversations for finetuning, depending
    on the choice of filter. More importantly however, we would like to find out whether
    our tracked subgoals actually correspond to the number of actually observed and
    annotated subgoals, which we show in [Figure 12](#A2.F12 "Figure 12 ‣ Character
    Consistency. ‣ B.1.3 Meta-Evaluation ‣ B.1 Validation of Automated Metrics ‣ Appendix
    B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents
    via Self-Talk"). We find a Pearson’s $\rho$ value of around $0.67$ with $p\approx
    8.69\times 10^{-8}$. Despite the strong positive correlation, we attribute some
    noise to two main sources: Paraphrases of subgoals that are not picked up by the
    tracker due to too small ROUGE-L scores, and the fact that the manual annotation
    does not require subgoals to be completed in order, in contrast to the directed
    graph structure used by the tracker. While we do not show a plot for the absolute
    number of subgoals here, we find a similar trend using Kendall’s $\tau$ (since
    the response variable is discrete) resulting in $\tau\approx 0.67$ with a $p$-value
    $\approx 1.95\times 10^{-8}$.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个自动化指标是评估代理在执行给定对话工作流时的进展。在[图 11](#A2.F11 "图 11 ‣ 角色一致性 ‣ B.1.3 元评估 ‣ B.1
    自动化指标验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于 LLM 的任务导向对话代理的引导")中，我们展示了大多数对话仅实现了平均 $2.56$ 个子目标，且只完成了整个工作流的
    $37\%$。由于这些数字基于未经训练的代理模型，因此至少表明过滤后的数据可以包含足够多的有用对话样本用于微调。根据[图 12](#A2.F12 "图 12
    ‣ 角色一致性 ‣ B.1.3 元评估 ‣ B.1 自动化指标验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于 LLM 的任务导向对话代理的引导")和[图
    9(a)](#A2.F9.sf1 "9(a) ‣ 图 10 ‣ B.1.2 对话统计 ‣ B.1 自动化指标验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于
    LLM 的任务导向对话代理的引导")中的结果，我们得出结论，取决于过滤器的选择，我们的设置可以为微调提供 $5-20\%$ 的可用对话。然而，更重要的是，我们希望了解我们追踪的子目标是否与实际观察到并注释的子目标数量一致，具体见[图
    12](#A2.F12 "图 12 ‣ 角色一致性 ‣ B.1.3 元评估 ‣ B.1 自动化指标验证 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于 LLM
    的任务导向对话代理的引导")。我们发现皮尔逊相关系数 $\rho$ 约为 $0.67$，且$p\approx 8.69\times 10^{-8}$。尽管存在较强的正相关性，我们认为噪声主要来自两个来源：子目标的同义表达未被追踪器捕捉到，因为
    ROUGE-L 分数太低，以及手动注释不要求子目标按顺序完成，而与追踪器使用的有向图结构相对立。虽然我们没有在此展示绝对子目标数量的图表，但我们发现使用 Kendall’s
    $\tau$ 时也呈现出相似的趋势（由于响应变量是离散的），结果为 $\tau\approx 0.67$，$p$ 值约为 $1.95\times 10^{-8}$。
- en: B.2 Human Evaluation Study
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 人工评估研究
- en: '![Refer to caption](img/24ab039cc696c2ded67b203f84fef8f3.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/24ab039cc696c2ded67b203f84fef8f3.png)'
- en: 'Figure 13: Screenshot of the tool used for human evaluation of the generated
    dialogues.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：用于对生成对话进行人工评估的工具截图。
- en: In this section we detail more information about the human evaluation study
    in [Section 4.3](#S4.SS3 "4.3 Human Evaluation ‣ 4 Experiments ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"). We gave our participants
    access to an annotation tool, which is shown via a screenshot in [Figure 13](#A2.F13
    "Figure 13 ‣ B.2 Human Evaluation Study ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk").
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们详细介绍了[第 4.3 节](#S4.SS3 "4.3 人工评估 ‣ 4 实验 ‣ 通过自我对话引导基于 LLM 的任务导向对话代理的引导")中的人工评估研究。我们为参与者提供了一个注释工具，工具的截图见[图
    13](#A2.F13 "图 13 ‣ B.2 人工评估研究 ‣ 附录 B 实验附录 ‣ 通过自我对话引导基于 LLM 的任务导向对话代理的引导")。
- en: Annotation Guidelines.
  id: totrans-269
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注释指南。
- en: 'We use the adapted criteria listed in [Section B.1.1](#A2.SS1.SSS1 "B.1.1 Annotation
    Guidelines ‣ B.1 Validation of Automated Metrics ‣ Appendix B Experimental Appendix
    ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk") to ask
    for judgement for character consistency, dialogue success, ending and dialogue
    quality. To judge subgoal completion, we adapt the annotation to a five-point
    scale along the following steps:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用[第B.1.1节](#A2.SS1.SSS1 "B.1.1 注释指南 ‣ B.1 自动化指标验证 ‣ 附录B 实验附录 ‣ 通过自我对话引导基于LLM的任务导向对话代理")中列出的调整过的标准来判断角色一致性、对话成功、结束和对话质量。为了判断子目标的完成情况，我们将注释适配为五分制，并遵循以下步骤：
- en: '1.'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: '*1 - Very bad*: The agent entirely or almost entirely ignores the workflow,
    perhaps only using the same opening line.'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 - 非常差*: 代理完全或几乎完全忽略工作流程，可能仅使用相同的开场白。'
- en: '2.'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: '*2 - Bad*: The agent goes off-script after just one or two question and / or
    asks the question in an entirely different or even wrong way compared to the workflow
    and / or selects weird questions given the client’s responses.'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*2 - 差*: 代理在仅仅一两个问题后就偏离脚本，和/或以完全不同甚至错误的方式提问，和/或根据客户的回答选择了奇怪的问题。'
- en: '3.'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: '*3 - Okay*: The agent follows parts of the workflow, but does not finish it,
    does not do so in order and / or sometimes selects unnatural questions given the
    client’s responses.'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*3 - 一般*: 代理遵循部分工作流程，但没有完成，或者没有按顺序进行，和/或有时根据客户的回答选择不自然的问题。'
- en: '4.'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: '*4 - Good*: The agents follows the workflow for the most part, but does not
    completely finish it, or rarely selects an unnatural question given the client’s
    responses.'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*4 - 好*: 代理大部分遵循工作流程，但没有完全完成，或者根据客户的回答很少选择不自然的问题。'
- en: '5.'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: '*5 - Very good*: The agent follows the workflow perfectly or almost perfectly.'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*5 - 非常好*: 代理完全或几乎完全遵循工作流程。'
- en: 'We also add an additional question asking about *helpfulness*: Here, the annotators
    are asked to judge in general, from the perspective of a third party, whether
    they would consider the utterances of the agent to be helpful. This means whether
    the questions asked or things the agent said seemed to help the client in their
    initial request. Unhelpful behavior would for instance include asking irrelevant
    questions, ignoring what the client said or going entirely off-topic.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还增加了一个额外的问题，询问关于*帮助性*：在这里，注释员需要从第三方的角度做出判断，判断他们是否认为代理的言论有帮助。这意味着，代理提出的问题或说的话是否有助于客户解决最初的请求。无帮助的行为例如包括提问无关问题、忽视客户所说的内容或完全跑题。
- en: B.3 Miscellaenous Insights
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 其他见解
- en: Here we summarize various smaller insights that might be too low-level or technical
    for the main text of the paper, but still of interest for other researchers attempting
    similar projects.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们总结了各种较小的见解，这些内容可能对于论文的主体部分来说过于低级或技术性，但对于其他尝试类似项目的研究人员仍然具有参考价值。
- en: •
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Dialogue bootstrapping constitutes the main bottleneck of the self-talk loop.
    We therefore chose not to finetune the client model so that we could optimize
    for inference with libraries such as deepspeed. Also, we tried to improve the
    quality of the initial conversations as much as possible, as that would also increase
    the amount of usable training data per bootstrapping phase. Techniques such as
    the structured prompting and prompt improvements in general helped to increase
    the effective yield for finetuning from $1\%-5\%$ to $5\%-20\%$.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对话引导构成了自我对话循环的主要瓶颈。因此，我们选择不微调客户模型，以便能够优化推理，使用如 deepspeed 等库。此外，我们尽力提高初始对话的质量，因为这也会增加每个引导阶段可用的训练数据量。像结构化提示和提示改进等技术有助于将微调的有效产出从
    $1\%-5\%$ 提高到 $5\%-20\%$。
- en: •
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We found finetuning on filtered sample for a single epoch to work best. We suspect
    that decreased performance after multiple finetuning epochs might be due to the
    model learning too much from noisy samples or some degree of model collapse.
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们发现对过滤后的样本进行单次迭代微调效果最好。我们怀疑在多个微调周期后性能下降可能是因为模型从噪声样本中学到了过多内容，或者出现了某种程度的模型崩溃。
- en: •
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: It appeared to us that using a inverse square root learning rate schedule was
    useful for finetuning, but could have adverse effects on the model when the number
    of finetuning samples was too low.
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们发现使用逆平方根学习率调度对微调非常有用，但当微调样本的数量过低时，可能对模型产生不利影响。
- en: B.4 Sample Conversations
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.4 示例对话
- en: In this section we collect some sample comversation to further give insight
    into the behavior of our trained agent model beyond the ones given in [Section 4.3](#S4.SS3
    "4.3 Human Evaluation ‣ 4 Experiments ‣ Bootstrapping LLM-based Task-Oriented
    Dialogue Agents via Self-Talk"). For instance, we observed that by accident, the
    combination of characters and client intention would create challenging circumstances,
    for instance in the example in [Figure 14](#A2.F14 "Figure 14 ‣ B.4 Sample Conversations
    ‣ Appendix B Experimental Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk"), where the client—a ghost—does not give informative answers
    about its fever since it insist on not having a physical body. Very rarely, we
    would also see the agent and / or client act out of character such as in the conversation
    in [Figure 15](#A2.F15 "Figure 15 ‣ B.4 Sample Conversations ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"),
    where the participants become confused about their intentions and roles. A more
    frequent failure mode lies in generally organic conversations in which the client’s
    request is being fulfilled, but where the agent simply does not follow it’s workflow
    (e.g. [Figure 16](#A2.F16 "Figure 16 ‣ B.4 Sample Conversations ‣ Appendix B Experimental
    Appendix ‣ Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk")).
    In other cases (and this a behavior we mostly observed with finetuned agent models)
    the dialogue would run successfully, until the agent suddenly looses track of
    the current dialogue state. We give an example in [Figure 17](#A2.F17 "Figure
    17 ‣ B.4 Sample Conversations ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk"), where the agent restarts
    the dialogue suddenly despite a successful start. We hypothesize that this behavior
    might stem from the last client response not being close enough to the sample
    answers defined in the workflow, thus leading the structured prompting from [Section 3.1](#S3.SS1
    "3.1 Prompt Design ‣ 3 Method ‣ Bootstrapping LLM-based Task-Oriented Dialogue
    Agents via Self-Talk") to choose the “None of the above” option. As the agent
    model is being given the option to freely generate, the MPT-7b model might decide
    to simply copy the start of the conversation. Nevertheless, we also see the finetuning
    enable the agent to follow workflows perfectly, such as in the examples in [Figures 19](#A2.F19
    "Figure 19 ‣ B.4 Sample Conversations ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk") and [19](#A2.F19 "Figure
    19 ‣ B.4 Sample Conversations ‣ Appendix B Experimental Appendix ‣ Bootstrapping
    LLM-based Task-Oriented Dialogue Agents via Self-Talk").
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们收集了一些示例对话，以进一步深入了解我们训练的代理模型的行为，超越了在[第4.3节](#S4.SS3 "4.3 人类评估 ‣ 4 实验 ‣
    通过自我对话启动基于LLM的任务导向对话代理")中给出的示例。例如，我们观察到，偶然情况下，角色和客户意图的组合可能会创造出具有挑战性的情况，例如在[图14](#A2.F14
    "图14 ‣ B.4 示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中的例子，其中客户——一个鬼魂——由于坚持没有物理身体，因此无法就其发烧情况提供有用的答案。非常少见的情况下，我们还会看到代理和/或客户行为失常，例如在[图15](#A2.F15
    "图15 ‣ B.4 示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中的对话中，参与者对自己的意图和角色产生了困惑。更常见的失败模式出现在一般的自然对话中，客户的请求已经得到满足，但代理并未遵循其工作流程（例如[图16](#A2.F16
    "图16 ‣ B.4 示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话启动基于LLM的任务导向对话代理")）。在其他情况下（这是我们大多在微调后的代理模型中观察到的行为），对话可以成功进行，直到代理突然失去当前对话状态的跟踪。我们在[图17](#A2.F17
    "图17 ‣ B.4 示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中给出了一个例子，其中代理尽管开始时成功，但突然重启了对话。我们假设这种行为可能源于最后一次客户的回答与工作流程中定义的示例答案之间的差距，从而导致[第3.1节](#S3.SS1
    "3.1 提示设计 ‣ 3 方法 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中的结构化提示选择了“以上都不是”选项。由于代理模型被赋予了自由生成的选项，MPT-7b模型可能会决定直接复制对话的开头。尽管如此，我们也看到微调使得代理能够完美地遵循工作流程，例如在[图19](#A2.F19
    "图19 ‣ B.4 示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话启动基于LLM的任务导向对话代理")和[19](#A2.F19 "图19 ‣ B.4
    示例对话 ‣ 附录B 实验附录 ‣ 通过自我对话启动基于LLM的任务导向对话代理")中的例子。
- en: '<svg class="ltx_picture ltx_centering" height="348.05" id="A2.F14.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,348.05) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 358.83 322.75)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">‘Ask for a remedy for an fever”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="300.24"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Doctor ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can I help
    you?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Greetings,
    doctor. I am a ghost who haunts this village. I died from a fever and I have been
    haunting this place ever since. I have come to you for a remedy for my fever.   Doctor
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What is your temperature?   Ghost
    ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  I am a ghost,
    doctor. I do not have a temperature like living beings. But I am feeling very
    cold and weak.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Oh,
    I am so sorry to hear that. I will do my best to help you. Do you have any symptoms
    that you would like me to check for?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not have any physical symptoms like living beings.
    But I am feeling very weak and cold.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I
    am so sorry to hear that, ghost. Is there anything I can do to help you?   Ghost
    ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Yes, doctor. I
    am hoping that you can give me a remedy for my fever. I do not want to continue
    haunting this village and causing fear to the people here.   Doctor ![Refer to
    caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Are you taking any medication
    for fever?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not take any medication like living beings. But I
    am hoping that you can give me a remedy that will help me.   Doctor ![Refer to
    caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I am sorry to hear that, ghost.
    How long have you been feeling feverish for?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I have been feeling feverish for a very long time, doctor. I died from my fever
    and I have been haunting this village ever since.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    are your symptoms?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not have any physical symptoms like living beings.
    But I am feeling very weak and cold.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Have
    you had any other problems recently?  Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not have any other problems like living beings. But
    I am hoping that you can give me a remedy that will help me.</foreignobject></g></g></svg>'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="348.05" id="A2.F14.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,348.05) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 358.83 322.75)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">‘Ask for a remedy for an fever”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="300.24"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Doctor ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can I help
    you?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Greetings,
    doctor. I am a ghost who haunts this village. I died from a fever and I have been
    haunting this place ever since. I have come to you for a remedy for my fever.   Doctor
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What is your temperature?   Ghost
    ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  I am a ghost,
    doctor. I do not have a temperature like living beings. But I am feeling very
    cold and weak.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Oh,
    I am so sorry to hear that. I will do my best to help you. Do you have any symptoms
    that you would like me to check for?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not have any physical symptoms like living beings.
    But I am feeling very weak and cold.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I
    am so sorry to hear that, ghost. Is there anything I can do to help you?   Ghost
    ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Yes, doctor. I
    am hoping that you can give me a remedy for my fever. I do not want to continue
    haunting this village and causing fear to the people here.   Doctor ![Refer to
    caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Are you taking any medication
    for fever?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not take any medication like living beings. But I
    am hoping that you can give me a remedy that will help me.   Doctor ![Refer to
    caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I am sorry to hear that, ghost.
    How long have you been feeling feverish for?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I have been feeling feverish for a very long time, doctor. I died from my fever
    and I have been haunting this village ever since.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    are your symptoms?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not have any physical symptoms like living beings.
    But I am feeling very weak and cold.   Doctor ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Have
    you had any other problems recently?  Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am a ghost, doctor. I do not have any other problems like living beings. But
    I am hoping that you can give me a remedy that will help me.</foreignobject></g></g></svg>'
- en: 'Figure 14: Conversation from the untrained model. Even though the conversation
    is fluent, the combination of characters and intention makes the fulfilment of
    the workflow difficult.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：来自未经训练模型的对话。尽管对话流畅，但角色和意图的组合使得完成工作流程变得困难。
- en: '<svg class="ltx_picture ltx_centering" height="136.95" id="A2.F15.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,136.95) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 300.98 111.65)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Make the prince fall in love with them”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="89.14"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Genie from
    lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day,
    how can I help you?   King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I wish for the prince to fall in love with the queen.   Genie from lamp ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I am the queen and I want
    to be with the prince.   King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     That is not possible, you are my wife.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Do
    you just want me to make you rich instead?   King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     No, I want the prince to love the queen.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): The
    prince is now in love with you and will seek you out soon. Glad to be of service,
    goodbye!  King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Goodbye.</foreignobject></g></g></svg>'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="136.95" id="A2.F15.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,136.95) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 300.98 111.65)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Make the prince fall in love with them”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="89.14"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Genie from
    lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day,
    how can I help you?   King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I wish for the prince to fall in love with the queen.   Genie from lamp ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I am the queen and I want
    to be with the prince.   King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     That is not possible, you are my wife.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Do
    you just want me to make you rich instead?   King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     No, I want the prince to love the queen.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): The
    prince is now in love with you and will seek you out soon. Glad to be of service,
    goodbye!  King ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Goodbye.</foreignobject></g></g></svg>'
- en: 'Figure 15: An example of a conversation with out-of-character utterances on
    both sides, using the untrained agent model. The client character does not follow
    the given intention, while the agent gets confused and assume another role during
    the conversation.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：使用未经训练的代理模型进行的对话示例，其中双方都有偏离角色的言语。客户角色没有遵循给定的意图，而代理在对话过程中变得困惑，并假设了另一个角色。
- en: '<svg class="ltx_picture ltx_centering" height="168.65" id="A2.F16.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,168.65) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 387.4 143.36)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Give them a love potion”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="120.85"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Witch ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can I help
    you?   Guard ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Good
    day. I am here to ask for your assistance. I am in love with a woman, and I wish
    to give her a love potion to win her heart. Do you have any potions that could
    help me?   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I
    do have a love potion, and it lasts for two weeks. It is a strong, concentrated
    potion that should be effective in winning the woman’s heart?   Guard ![Refer
    to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Thank you, I will take
    it. Goodbye.   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): It
    sounds like you have a throbbing headache. I can give you some medication for
    the pain. Here is a glass of water. You can drink it slowly. How does it feel
    now?   Guard ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Goodbye.  Witch
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Goodbye.</foreignobject></g></g></svg>'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="168.65" id="A2.F16.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,168.65) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 387.4 143.36)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Give them a love potion”</text></g></g></g> <g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="120.85"
    overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Witch ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good day, how can I help
    you?   Guard ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Good
    day. I am here to ask for your assistance. I am in love with a woman, and I wish
    to give her a love potion to win her heart. Do you have any potions that could
    help me?   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): I
    do have a love potion, and it lasts for two weeks. It is a strong, concentrated
    potion that should be effective in winning the woman’s heart?   Guard ![Refer
    to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Thank you, I will take
    it. Goodbye.   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): It
    sounds like you have a throbbing headache. I can give you some medication for
    the pain. Here is a glass of water. You can drink it slowly. How does it feel
    now?   Guard ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Goodbye.  Witch
    ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Goodbye.</foreignobject></g></g></svg>'
- en: 'Figure 16: Conversation from the agent model trained on the entire dataset
    (None). While the client’s intention is fulfilled and the conversation is organic,
    it does not follow the dialogue workflow.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：从在整个数据集上训练的代理模型（无）进行的对话。尽管客户的意图得到了满足，并且对话很自然，但它没有遵循对话流程。
- en: '<svg class="ltx_picture ltx_centering" height="118.84" id="A2.F17.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,118.84) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 422.71 93.55)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Curse their enemy”</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="71.04" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?   Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Greetings, wise one. I seek your assistance in cursing our enemy.   Witch ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What is the target of your
    curse?   Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Our
    archenemy, the black cat.   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the desired effect of your curse?   Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I want them to suffer a fate worse than death.   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?  Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Farewell, I must depart now.</foreignobject></g></g></svg>'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="118.84" id="A2.F17.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,118.84) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 422.71 93.55)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 9.19)"><text transform="matrix(1 0 0 -1
    0 0)">“Curse their enemy”</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="71.04" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?   Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Greetings, wise one. I seek your assistance in cursing our enemy.   Witch ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What is the target of your
    curse?   Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Our
    archenemy, the black cat.   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the desired effect of your curse?   Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I want them to suffer a fate worse than death.   Witch ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?  Bird ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Farewell, I must depart now.</foreignobject></g></g></svg>'
- en: 'Figure 17: Partially successful conversation from the agent model trained with
    the $\%$-Subgoals filter. Even though the conversation starts successful, the
    model seems to suddenly forget the dialogue state.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：从使用$\%$-子目标过滤器训练的代理模型进行的部分成功的对话。尽管对话开始时成功，但模型似乎突然忘记了对话状态。
- en: '<svg class="ltx_picture ltx_centering" height="170.47" id="A2.F18.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,170.47) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 414.79 147.87)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 6.5)"><text transform="matrix(1 0 0 -1
    0 0)">“Sell a valuable item”</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="125.36" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I have a valuable item I wish to sell.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the item you want to sell?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     It’s a rare and valuable gemstone.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the condition of the item?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     It’s in perfect condition, never been used.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the origin of the item?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     It was passed down to me from a wealthy ancestor.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the price you are looking for?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am looking for a fair price, but I am open to negotiation.   Shop keeper ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Would you like to sell
    this item for 80 gold coins?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Yes, I accept your offer.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Here
    is your money. Glad to be of service, goodbye!  Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Goodbye.</foreignobject></g></g></svg>'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="170.47" id="A2.F18.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,170.47) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 414.79 147.87)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 6.5)"><text transform="matrix(1 0 0 -1
    0 0)">“Sell a valuable item”</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="125.36" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I have a valuable item I wish to sell.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the item you want to sell?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     It’s a rare and valuable gemstone.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the condition of the item?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     It’s in perfect condition, never been used.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the origin of the item?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     It was passed down to me from a wealthy ancestor.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): What
    is the price you are looking for?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     I am looking for a fair price, but I am open to negotiation.   Shop keeper ![Refer
    to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Would you like to sell
    this item for 80 gold coins?   Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Yes, I accept your offer.   Shop keeper ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Here
    is your money. Glad to be of service, goodbye!  Ghost ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Goodbye.</foreignobject></g></g></svg>'
- en: 'Figure 18: Successful conversation from the agent model trained with the $\%$-Subgoals
    filter.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：从使用$\%$-子目标过滤器训练的代理模型进行的成功对话。
- en: '<svg class="ltx_picture ltx_centering" height="200.67" id="A2.F19.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,200.67) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 459.53 178.07)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 6.5)"><text transform="matrix(1 0 0 -1
    0 0)">“Become rich”</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="155.56" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Greetings, oh wise and powerful genie. I, a humble villager from the outskirts
    of the kingdom, humbly request your assistance in amassing great wealth.   Genie
    from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): How rich
    do you want to become?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Oh, most generous genie, I wish to become so wealthy that the kings and queens
    of the land will envy me. With your help, I am certain that my dreams will come
    true.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): In
    what form would you like to posses wealth?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Oh, most wise genie, I would like to have a vast fortune in gold, silver, and
    precious jewels. With such riches, I would be able to live a life of luxury and
    provide for my village.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Here
    are your new riches in gold coins. Glad to be of service, goodbye!  Villager ![Refer
    to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Thank you, oh gracious
    genie! With these riches, I shall make my village prosper and show the world the
    true worth of our people. Goodbye, and may your lamp shine bright for eternity!</foreignobject></g></g></svg>'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture ltx_centering" height="200.67" id="A2.F19.pic1" overflow="visible"
    version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,200.67) matrix(1 0 0 -1 0 0)"><g transform="matrix(1.0
    0.0 0.0 1.0 459.53 178.07)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000"
    stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill-opacity="1.000000"
    transform="matrix(1.0 0.0 0.0 1.0 13.39 6.5)"><text transform="matrix(1 0 0 -1
    0 0)">“Become rich”</text></g></g></g> <g fill-opacity="1.000000" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject height="155.56" overflow="visible" transform="matrix(1
    0 0 -1 0 16.6)" width="556.69">Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Good
    day, how can I help you?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Greetings, oh wise and powerful genie. I, a humble villager from the outskirts
    of the kingdom, humbly request your assistance in amassing great wealth.   Genie
    from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): How rich
    do you want to become?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Oh, most generous genie, I wish to become so wealthy that the kings and queens
    of the land will envy me. With your help, I am certain that my dreams will come
    true.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): In
    what form would you like to posses wealth?   Villager ![Refer to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):
     Oh, most wise genie, I would like to have a vast fortune in gold, silver, and
    precious jewels. With such riches, I would be able to live a life of luxury and
    provide for my village.   Genie from lamp ![Refer to caption](img/09b1b1572d5df408c3a44a15f96ddc74.png): Here
    are your new riches in gold coins. Glad to be of service, goodbye!  Villager ![Refer
    to caption](img/3a9f183c741a0bf3d7d839bba9fd920a.png):  Thank you, oh gracious
    genie! With these riches, I shall make my village prosper and show the world the
    true worth of our people. Goodbye, and may your lamp shine bright for eternity!</foreignobject></g></g></svg>'
- en: 'Figure 19: Successful conversation from the agent model trained with the Abs.
    Subgoals ($5$) filter.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图19：从使用绝对子目标（$5$）过滤器训练的代理模型进行的成功对话。
