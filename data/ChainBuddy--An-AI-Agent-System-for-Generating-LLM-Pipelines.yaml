- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:14:10'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 12:14:10'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ChainBuddy: An AI Agent System for Generating LLM Pipelines'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChainBuddy：一个用于生成 LLM 流水线的 AI 代理系统
- en: 来源：[https://arxiv.org/html/2409.13588/](https://arxiv.org/html/2409.13588/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2409.13588/](https://arxiv.org/html/2409.13588/)
- en: Jingyue Zhang Université de MontréalMontréalQuébecCanada [jingyue.zhang@umontreal.ca](mailto:jingyue.zhang@umontreal.ca)
     and  Ian Arawjo Université de MontréalMontréalQuébecCanada [ian.arawjo@umontreal.ca](mailto:ian.arawjo@umontreal.ca)(2018;
    20 February 2007; 12 March 2009; 5 June 2009)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Jingyue Zhang 蒙特利尔大学 蒙特利尔 魁北克 加拿大 [jingyue.zhang@umontreal.ca](mailto:jingyue.zhang@umontreal.ca)  和  Ian
    Arawjo 蒙特利尔大学 蒙特利尔 魁北克 加拿大 [ian.arawjo@umontreal.ca](mailto:ian.arawjo@umontreal.ca)(2018；2007年2月20日；2009年3月12日；2009年6月5日)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: As large language models (LLMs) advance, their potential applications have grown
    significantly. However, it remains difficult to evaluate LLM behavior on user-specific
    tasks and craft effective pipelines to do so. Many users struggle with where to
    start, often referred to as the ”blank page problem.” ChainBuddy, an AI assistant
    for generating evaluative LLM pipelines built into the ChainForge platform, aims
    to tackle this issue. ChainBuddy offers a straightforward and user-friendly way
    to plan and evaluate LLM behavior, making the process less daunting and more accessible
    across a wide range of possible tasks and use cases. We report a within-subjects
    user study comparing ChainBuddy to the baseline interface. We find that when using
    AI assistance, participants reported a less demanding workload and felt more confident
    setting up evaluation pipelines of LLM behavior. We derive insights for the future
    of interfaces that assist users in the open-ended evaluation of AI.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模语言模型（LLMs）的发展，它们的潜在应用已显著增加。然而，仍然很难评估 LLM 在特定用户任务上的表现，并构建有效的流水线来实现这一目标。许多用户在开始时感到困惑，这通常被称为“空白页问题”。ChainBuddy
    是一个内置于 ChainForge 平台中的 AI 助手，用于生成评估 LLM 流水线，旨在解决这一问题。ChainBuddy 提供了一种简单且用户友好的方式来规划和评估
    LLM 的表现，使得整个过程不再那么令人畏惧，并且更容易适用于各种任务和使用场景。我们报告了一项对比 ChainBuddy 与基准界面的用户研究。我们发现，在使用
    AI 帮助时，参与者报告的工作负载较低，并且在设置 LLM 行为评估流水线时更有信心。我们从中得出了一些对未来界面的洞察，这些界面可以帮助用户进行开放性 AI
    评估。
- en: 'language models, AI agents, prompt engineering, automation, LLM pipelines,
    visual programming environments^†^†copyright: none^†^†journalyear: 2018^†^†doi:
    XXXXXXX.XXXXXXX^†^†conference: Pre-print; June 03–05, 2018; Woodstock, NY^†^†isbn:
    978-1-4503-XXXX-X/18/06^†^†ccs: Human-centered computing Interactive systems and
    tools^†^†ccs: Human-centered computing Empirical studies in HCI![Refer to caption](img/4d89d8f15c5db59dfa3ae7f8f06deb61.png)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '语言模型，AI 代理，提示工程，自动化，LLM 流水线，视觉编程环境^†^†版权：无^†^†期刊年份：2018^†^†doi: XXXXXXX.XXXXXXX^†^†会议：预印本；2018年6月03–05日；纽约州伍德斯托克^†^†isbn:
    978-1-4503-XXXX-X/18/06^†^†ccs: 以人为本的计算 互动系统与工具^†^†ccs: 以人为本的计算 人机交互的实证研究![参见图注](img/4d89d8f15c5db59dfa3ae7f8f06deb61.png)'
- en: Figure 1\. A zero-shot example of a workflow created by ChainBuddy from a single
    user prompt. The user wishes to investigate how different personas can affect
    an LLM’s response to a complex math question. ChainBuddy generates an LLM pipeline
    with example personas, a math problem (the Gaussian integral), templated prompts,
    comparison across four LLMs, and a Python Code Evaluator to check for the solution
    in the LLM’s output ($\sqrt{\pi}$). The user can tweak the output, such as including
    more patterns in the regex.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 一个由 ChainBuddy 从单个用户提示创建的零样本工作流程示例。用户希望调查不同人物角色如何影响 LLM 对复杂数学问题的回答。ChainBuddy
    生成了一个包含示例人物角色、数学问题（高斯积分）、模板化提示、四个 LLM 之间的比较以及 Python 代码评估器的 LLM 流水线，以检查 LLM 输出中的解（$\sqrt{\pi}$）。用户可以调整输出，例如在正则表达式中包含更多模式。
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Over the past two years, the growing interest in AI has spawned a plethora of
    tools, APIs, and best practices for creating applications based on LLMs. These
    advancements include a wide range of techniques, from prompt engineering and LLM
    evaluation platforms to sophisticated AI agent systems equipped with tool use
    capabilities (Shankar et al., [2024b](https://arxiv.org/html/2409.13588v1#bib.bib34);
    Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2); Webster,
    [2023](https://arxiv.org/html/2409.13588v1#bib.bib42); Beasley and Abouzied, [2024](https://arxiv.org/html/2409.13588v1#bib.bib5)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去两年里，对AI的日益关注催生了大量的工具、API和最佳实践，用于基于LLM创建应用程序。这些进展包括广泛的技术，从提示工程和LLM评估平台到配备工具使用功能的复杂AI代理系统（Shankar等，[2024b](https://arxiv.org/html/2409.13588v1#bib.bib34)；Arawjo等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)；Webster，[2023](https://arxiv.org/html/2409.13588v1#bib.bib42)；Beasley和Abouzied，[2024](https://arxiv.org/html/2409.13588v1#bib.bib5)）。
- en: 'Despite these advancements, many users encounter a significant challenge: the
    ”blank page problem.” This problem is characterized by the uncertainty and difficulty
    of knowing where to begin when using platforms like promptfoo (Webster, [2023](https://arxiv.org/html/2409.13588v1#bib.bib42))
    or Flowise (Flowise AI, [2024](https://arxiv.org/html/2409.13588v1#bib.bib13)).
    Some researchers have proposed social solutions to this problem, such as the development
    of prompt repositories and community-sharing mechanisms (Zamfirescu-Pereira et al.,
    [2023](https://arxiv.org/html/2409.13588v1#bib.bib47)). Another proposed solution
    is to create an assistant that helps users get started by providing initial guidance
    and structure (Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些进展，许多用户仍然面临一个重大挑战：“空白页面问题”。这个问题的特点是，当使用像promptfoo（Webster，[2023](https://arxiv.org/html/2409.13588v1#bib.bib42)）或Flowise（Flowise
    AI，[2024](https://arxiv.org/html/2409.13588v1#bib.bib13)）这样的平台时，往往不知道从哪里开始。部分研究人员提出了社交解决方案，例如开发提示库和社区共享机制（Zamfirescu-Pereira等，[2023](https://arxiv.org/html/2409.13588v1#bib.bib47)）。另一种提议的解决方案是创建一个助手，通过提供初步的指导和结构来帮助用户开始（Arawjo等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)）。
- en: 'Taking the latter approach, our solution, ChainBuddy, is an AI-powered assistant
    that automatically generates starter LLM pipelines (“flows”) given an initial
    prompt. ChainBuddy helps users get started with evaluating LLM behavior and setting
    up chains by providing a starter flow, custom-tailored to their use case, that
    they can edit and extend. We built ChainBuddy on top of an existing open-source
    visual environment, ChainForge (Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)),
    which was designed for open-ended prompt engineering, LLM evaluation, and experimentation
    tasks (comparing response quality across prompts and models, setting up data processing
    pipelines, and establish automated evaluation metrics). By building on top of
    this foundation, ChainBuddy offers users structured assistance to help them overcome
    the blank page problem, making it easier to explore, experiment and evaluate the
    behavior of LLMs across a wide range of potential tasks and use cases. We report
    a mixed methods usability study of ChainBuddy, comparing the assistant to the
    baseline interface. We find broad support for ChainBuddy, particularly in its
    reduction of user effort and requirements-gathering intent elicitation feature,
    with the majority of participants expressing surprise at the quality of the assistant’s
    capabilities. Our contributions are:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 采用后者方法，我们的解决方案ChainBuddy是一个由AI驱动的助手，能够根据初始提示自动生成启动的LLM管道（“流”）。ChainBuddy帮助用户开始评估LLM行为和设置链条，通过提供一个定制的启动流，量身定制以满足他们的使用案例，用户可以编辑和扩展该流。我们在现有的开源可视化环境ChainForge（Arawjo等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)）的基础上构建了ChainBuddy，该环境旨在进行开放式提示工程、LLM评估和实验任务（比较不同提示和模型的响应质量、设置数据处理管道、建立自动化评估指标）。通过建立在这一基础上，ChainBuddy为用户提供了结构化的帮助，帮助他们克服空白页面问题，使探索、实验和评估LLM在各种潜在任务和使用案例中的行为变得更加容易。我们报告了ChainBuddy的混合方法可用性研究，将该助手与基准界面进行了比较。我们发现，ChainBuddy获得了广泛的支持，特别是在其减少用户努力和需求收集意图引导功能方面，大多数参与者对该助手的能力表示惊讶。我们的贡献包括：
- en: (1)
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: A chat-like AI assistant and agent architecture, ChainBuddy, that chats with
    the user to understand their requirements and goals, and then generates editable
    and interactive starter LLM pipelines
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个类似聊天的AI助手和代理架构ChainBuddy，它与用户进行对话，理解他们的需求和目标，然后生成可编辑和交互的启动LLM管道
- en: (2)
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: A within-subjects, mixed methods usability study investigating the relative
    advantages and trade-offs of the ChainBuddy assistant versus the baseline interface
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一项在被试内设计的混合方法可用性研究，探讨了ChainBuddy助手与基准界面在相对优势和权衡方面的差异。
- en: (3)
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （3）
- en: Insights for future AI support interfaces and reflections on the risk of user
    over-reliance on AI assistants for LLM pipeline generation
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为未来的AI支持界面提供的见解，并反思用户过度依赖AI助手进行LLM管道生成的风险。
- en: 2\. Related Work
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 相关工作
- en: Since the release of ChatGPT, the LLM landscape has blossomed into a plethora
    of proprietary and open-source models, infrastructure, and tooling to support
    LLM operations (sometimes called “LLMOps”). The unique power of LLMs, alongside
    their stochastic, nondeterministic nature and some high-profile incidents of bias
    (Wolf et al., [2017](https://arxiv.org/html/2409.13588v1#bib.bib43)), have raised
    the question of how best to integrate them into larger software systems in a manner
    that is robust and safe. How to build “LLM-integrated software” is thus emerging
    as a unique subdiscipline within software engineering, and comprises a number
    of operations, from prompt engineering, to systematic evaluations, to chaining
    LLM calls (introduced by Wu et al. in HCI as “AI chains” (Wu et al., [2022b](https://arxiv.org/html/2409.13588v1#bib.bib46)))
    as well as more complex network structures (Wu et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib44)),
    and providing LLMs access to *tools*—the ability to call functions that perform
    actions on the user’s machine. The term “AI agents” has come to be synonymous
    with the latter two architectures.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自从ChatGPT发布以来，LLM（大语言模型）领域已经发展成了一个充满各种专有和开源模型、基础设施以及支持LLM操作的工具的生态系统（有时被称为“LLMOps”）。LLM的独特能力，加上其随机性、非确定性特征以及一些具有影响力的偏见事件（Wolf等人，[2017](https://arxiv.org/html/2409.13588v1#bib.bib43)），引发了如何将LLM最好地集成到更大的软件系统中，以确保系统的鲁棒性和安全性的问题。因此，如何构建“LLM集成软件”逐渐成为软件工程中的一个独特子学科，涉及多个操作，从提示工程、系统评估、到LLM调用链（由Wu等人在HCI中引入为“AI链”（Wu等人，[2022b](https://arxiv.org/html/2409.13588v1#bib.bib46)））以及更复杂的网络结构（Wu等人，[2023](https://arxiv.org/html/2409.13588v1#bib.bib44)），以及为LLM提供访问*工具*的能力——即调用执行用户机器上操作的函数的能力。“AI代理”一词逐渐与后两种架构同义。
- en: To support developers in exploring these new practices, a slew of graphical
    user interfaces and programming libraries have emerged to fill the gap. Coding
    APIs like LangGraph, CrewAI, and AutoGen (CrewAI, [2024](https://arxiv.org/html/2409.13588v1#bib.bib10);
    LangChain AI, [2024](https://arxiv.org/html/2409.13588v1#bib.bib25); Wu et al.,
    [2023](https://arxiv.org/html/2409.13588v1#bib.bib44)) support developers in creating
    flows of AI agents (LLM-integrated submodules) that pass messages to each other
    in asynchronous-style collaborative architectures. Tools like EvalLM, PromptMaker,
    BotDesigner, and promptfoo (Kim et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib22);
    Jiang et al., [2022](https://arxiv.org/html/2409.13588v1#bib.bib19); Zamfirescu-Pereira
    et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib47); Webster, [2023](https://arxiv.org/html/2409.13588v1#bib.bib42))
    support prompt engineering, while LLM Comparator and ChainForge go further, supporting
    cross-model comparison, automated code- and LLM-based evaluations, visualizations,
    and chaining of prompts (Kahng et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib20);
    Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)). Some coding
    APIs serve to guard against the unpredictable nature of LLM outputs, such as Guardrails,
    LangChain, and Instructor (Instructor, [2023](https://arxiv.org/html/2409.13588v1#bib.bib18);
    Guardrails, [2023](https://arxiv.org/html/2409.13588v1#bib.bib15); et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib11)).
    Another pattern is the rise of data flow-based interfaces for LLMOps, such as
    Flowise, LangFlow, ChainForge and PromptChainer, visual programming environments
    usually (though not exclusively) targeting app development (Logspace, [2023](https://arxiv.org/html/2409.13588v1#bib.bib27);
    Flowise AI, [2024](https://arxiv.org/html/2409.13588v1#bib.bib13); Arawjo et al.,
    [2024](https://arxiv.org/html/2409.13588v1#bib.bib2); Wu et al., [2022a](https://arxiv.org/html/2409.13588v1#bib.bib45)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持开发者探索这些新实践，出现了大量的图形用户界面和编程库来填补这一空白。像 LangGraph、CrewAI 和 AutoGen（CrewAI，[2024](https://arxiv.org/html/2409.13588v1#bib.bib10)；LangChain
    AI，[2024](https://arxiv.org/html/2409.13588v1#bib.bib25)；Wu 等，[2023](https://arxiv.org/html/2409.13588v1#bib.bib44)）这样的编码
    API 支持开发者创建 AI 代理流（集成大语言模型的子模块），这些代理在异步协作架构中相互传递信息。像 EvalLM、PromptMaker、BotDesigner
    和 promptfoo（Kim 等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib22)；Jiang
    等，[2022](https://arxiv.org/html/2409.13588v1#bib.bib19)；Zamfirescu-Pereira 等，[2023](https://arxiv.org/html/2409.13588v1#bib.bib47)；Webster，[2023](https://arxiv.org/html/2409.13588v1#bib.bib42)）这样的工具支持提示工程，而
    LLM Comparator 和 ChainForge 则更进一步，支持跨模型比较、自动化的代码和大语言模型评估、可视化以及提示链的创建（Kahng 等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib20)；Arawjo
    等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)）。一些编码 API 旨在防止大语言模型输出的不可预测性，比如
    Guardrails、LangChain 和 Instructor（Instructor，[2023](https://arxiv.org/html/2409.13588v1#bib.bib18)；Guardrails，[2023](https://arxiv.org/html/2409.13588v1#bib.bib15)；et
    al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib11)）。另一种模式是基于数据流的接口在 LLMOps
    中的崛起，比如 Flowise、LangFlow、ChainForge 和 PromptChainer，这些通常（但不限于）面向应用开发的可视化编程环境（Logspace，[2023](https://arxiv.org/html/2409.13588v1#bib.bib27)；Flowise
    AI，[2024](https://arxiv.org/html/2409.13588v1#bib.bib13)；Arawjo 等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)；Wu
    等，[2022a](https://arxiv.org/html/2409.13588v1#bib.bib45)）。
- en: 'The many practices of LLMOps have led to recent proposals to *automate* parts
    of the process—from synthetic input data generation and mining the internet for
    datasets (Boyeau et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib6);
    Gandhi et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib14)), to prompt
    optimization (Khattab et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib21);
    Singhvi et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib35)), to helping
    users generate automated evaluators that align with their preferences (Shankar
    et al., [2024b](https://arxiv.org/html/2409.13588v1#bib.bib34), [a](https://arxiv.org/html/2409.13588v1#bib.bib33);
    Shaikh et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib32)). For instance,
    DSPy and Teola serve as prompt and chain optimization frameworks (Khattab et al.,
    [2023](https://arxiv.org/html/2409.13588v1#bib.bib21); Tan et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib38)).
    However, there remains a problem at a higher level of abstraction: that users,
    even AI/ML experts, struggle to set up pipelines and automated evaluations of
    LLM behavior, with Arawjo et al. concluding that “more work needs to be done on
    [the] conceptualization and planning aspects” of supporting users in LLM pipeline
    creation (Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2);
    Zamfirescu-Pereira et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib47)).
    Part of the issue is certainly the usual difficulty of learning a new interface,
    but the larger issue is conceptual: what is the *“right way”* to prompt engineer?
    To set up a pipeline? To evaluate LLM behavior? We and the community are still
    learning these best practices.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: LLMOps的许多实践促使了最近提出的*自动化*部分流程的建议——从合成输入数据生成和从互联网挖掘数据集（Boyeau等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib6);
    Gandhi等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib14)），到提示优化（Khattab等人，[2023](https://arxiv.org/html/2409.13588v1#bib.bib21);
    Singhvi等人，[2023](https://arxiv.org/html/2409.13588v1#bib.bib35)），再到帮助用户生成与其偏好对齐的自动评估器（Shankar等人，[2024b](https://arxiv.org/html/2409.13588v1#bib.bib34)，[a](https://arxiv.org/html/2409.13588v1#bib.bib33);
    Shaikh等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib32)）。例如，DSPy和Teola作为提示和链优化框架（Khattab等人，[2023](https://arxiv.org/html/2409.13588v1#bib.bib21);
    Tan等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib38)）。然而，在更高层次的抽象中仍然存在一个问题：即使是AI/ML专家，用户在设置LLM行为的管道和自动评估时也感到困难，Arawjo等人总结道，“在[概念化和规划方面]需要更多的工作”来支持用户创建LLM管道（Arawjo等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2);
    Zamfirescu-Pereira等人，[2023](https://arxiv.org/html/2409.13588v1#bib.bib47)）。这个问题的一部分无疑是学习新界面的常见困难，但更大的问题是概念性的：如何*“正确的方式”*进行提示工程？如何设置管道？如何评估LLM行为？我们和社区仍在学习这些最佳实践。
- en: 'The problem of pipeline generation bears a similarity to AutoML, an area of
    research in machine learning that focuses on automatically designing machine learning
    (ML) pipelines to train new ML models, whether in part or in full (Heffetz et al.,
    [2020](https://arxiv.org/html/2409.13588v1#bib.bib17); Barbudo et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib4);
    Feurer et al., [2022](https://arxiv.org/html/2409.13588v1#bib.bib12)). Certainly,
    AutoML faces unique challenges compared to the typical problems in the LLMOps
    space (such as managing very large training datasets, deciding upon hyperparameters
    and weighing trade-offs in terms of expected training cost and performance). Inspired
    by this line of ML research, here we investigate the *end-to-end generation of
    LLM pipelines*, an emerging research area we call AutoLLMOps: from a single user
    prompt, can we generate an *inspectable*, *interactive*, and *editable* pipeline,
    complete with input data, prompt(s) and model(s), and even automated evaluations?
    Could we build such a system for open-ended tasks? What benefits would users derive
    from it? And what dangers are there, if any, to automation? To the best of our
    knowledge, no HCI paper has yet investigated this question. With new LLM agent
    frameworks, emerging research is showing that this kind of end-to-end generation
    of a workflow is possible, albeit for different tasks like descriptive analytics
    given a user-provided dataset (Beasley and Abouzied, [2024](https://arxiv.org/html/2409.13588v1#bib.bib5))
    or for chatbot creation (Sánchez Cuadrado et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib31)).
    Here, we apply this idea to LLM pipelines, specifically focusing on pipelines
    that help users evaluate LLM behavior.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 管道生成问题与AutoML相似，AutoML是机器学习中的一个研究领域，旨在自动设计机器学习（ML）管道，以训练新的ML模型，无论是部分还是全部（Heffetz等，[2020](https://arxiv.org/html/2409.13588v1#bib.bib17)；Barbudo等，[2023](https://arxiv.org/html/2409.13588v1#bib.bib4)；Feurer等，[2022](https://arxiv.org/html/2409.13588v1#bib.bib12)）。与LLMOps领域中的典型问题相比，AutoML面临着独特的挑战（例如，管理非常大的训练数据集、确定超参数并权衡预期训练成本与性能的折衷）。受此类ML研究的启发，我们在此研究*端到端生成LLM管道*，这是一个新兴的研究领域，我们称之为AutoLLMOps：从一个单一用户提示开始，是否可以生成一个*可检查*、*互动*和*可编辑*的管道，完整地包含输入数据、提示(s)、模型(s)，甚至是自动化评估？我们能为开放性任务构建这样的系统吗？用户能从中获得什么好处？如果有的话，自动化会带来哪些风险？据我们所知，目前还没有HCI论文研究过这个问题。随着新的LLM代理框架的出现，新兴研究表明，这种端到端生成工作流的方式是可行的，尽管是在处理不同任务时，如给定用户提供的数据集的描述性分析（Beasley和Abouzied，[2024](https://arxiv.org/html/2409.13588v1#bib.bib5)）或用于聊天机器人的创建（Sánchez
    Cuadrado等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib31)）。在这里，我们将这一思路应用于LLM管道，特别是聚焦于帮助用户评估LLM行为的管道。
- en: 3\. ChainBuddy System Design
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. ChainBuddy系统设计
- en: To automate the creation of LLM pipelines, we focused on creating a flexible,
    user-friendly interface that could support a wide range of use cases beyond just
    prompt engineering. We decided to build a chatbot-style assistant interface, ChainBuddy,
    within the open-source ChainForge platform (Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)).
    This choice was driven by the need for an intuitive and interactive environment
    that can support various users across a range of different pipelines, such as
    data processing, prompt optimization, LLM auditing, and more. Our goal was to
    ensure that ChainBuddy could handle diverse and complex requirements while being
    accessible to users with varying levels of technical expertise and use cases.
    Note that our ultimate goal is to extend ChainBuddy to guide users beyond initial
    generation, i.e., to edit existing flows; however, due to the complexity of the
    agent system and open-ended nature of the problem, we consider here only the ability
    of ChainBuddy to generate flows from scratch.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自动化LLM管道的创建，我们专注于创建一个灵活、用户友好的界面，能够支持广泛的应用场景，而不仅仅是提示工程。我们决定在开源ChainForge平台内构建一个聊天机器人风格的助手界面——ChainBuddy（Arawjo等，
    [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)）。这一选择源于对一个直观且互动的环境的需求，该环境能够支持不同管道中各种用户的需求，例如数据处理、提示优化、LLM审核等。我们的目标是确保ChainBuddy能够处理多样化和复杂的需求，同时对不同技术水平和使用场景的用户都具有可访问性。请注意，我们的最终目标是扩展ChainBuddy，指导用户超越初始生成，即编辑现有流程；然而，由于代理系统的复杂性以及问题的开放性，我们在此仅考虑ChainBuddy从头生成流程的能力。
- en: 3.1\. Interface and Example Usage
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 界面和示例用法
- en: 'The ChainBuddy assistant can be seen in Figure [2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines"). The assistant comprises
    a standard chat interface in the bottom-left hand corner of the ChainForge platform.
    The user starts a chat with the assistant to explain their problem (Fig [2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")a). The assistant
    then holds a Q&A conversation with the user to disambiguate user intent (Ma et al.,
    [2024](https://arxiv.org/html/2409.13588v1#bib.bib29); Vaithilingam et al., [2024a](https://arxiv.org/html/2409.13588v1#bib.bib39))
    (Fig [2](https://arxiv.org/html/2409.13588v1#S3.F2 "Figure 2 ‣ 3.1\. Interface
    and Example Usage ‣ 3\. ChainBuddy System Design ‣ ChainBuddy: An AI Agent System
    for Generating LLM Pipelines")b). This comprises a pass where the assistant asks
    a set of up to three questions, and the user can respond individually to each
    question by filling out a form (Fig. [2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")c). At any time,
    the user may end the disambiguation and trigger the AI to generate a flow by clicking
    the button (Fig. [2](https://arxiv.org/html/2409.13588v1#S3.F2 "Figure 2 ‣ 3.1\.
    Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣ ChainBuddy: An AI
    Agent System for Generating LLM Pipelines")d). The user can then inspect the generated
    flow or request a new generation (Fig. [2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")e). We kept the assistant
    interface simple as the majority of our contribution’s complexity lies in the
    agent architecture and flow generation capabilities.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 'ChainBuddy助手可以在图[2](https://arxiv.org/html/2409.13588v1#S3.F2 "Figure 2 ‣ 3.1\.
    Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣ ChainBuddy: An AI
    Agent System for Generating LLM Pipelines")中看到。该助手包括ChainForge平台左下角的标准聊天界面。用户与助手开始聊天以说明他们的问题（图[2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")a）。然后，助手与用户进行问答对话，以澄清用户的意图（Ma等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib29);
    Vaithilingam等人，[2024a](https://arxiv.org/html/2409.13588v1#bib.bib39)）（图[2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")b）。这包括一个环节，助手会提出最多三个问题，用户可以通过填写表单单独回答每个问题（图[2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")c）。在任何时候，用户都可以结束澄清过程并通过点击按钮触发AI生成流程（图[2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")d）。然后，用户可以检查生成的流程或请求新的生成（图[2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")e）。我们保持助手界面简单，因为我们大多数贡献的复杂性集中在代理架构和流程生成能力上。'
- en: '![Refer to caption](img/344d8eaf115542b94b04bf79469bd8d8.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/344d8eaf115542b94b04bf79469bd8d8.png)'
- en: Figure 2\. ChainBuddy interface and example usage. Users specify requirements
    (A), ChainBuddy replies with a requirements-gathering form (B) that users can
    either fill out and send, or follow up with an open-ended chat (C). User presses
    green button (D) to indicate that they are ready to generate a flow. After a delay
    of 10-20sec, ChainBuddy produces a starter pipeline (E). Here, the starter pipeline
    includes example inputs, multiple prompts to try (prompt templates), two queried
    models, and a Python-based code evaluator.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图2. ChainBuddy界面及示例使用。用户指定需求（A），ChainBuddy回复需求收集表单（B），用户可以填写并发送，或继续进行开放式聊天（C）。用户按下绿色按钮（D）表示他们已准备好生成流程。经过10-20秒的延迟后，ChainBuddy生成一个起始流水线（E）。在这里，起始流水线包括示例输入、多个提示（提示模板）、两个查询模型以及基于Python的代码评估器。
- en: Note that in this paper, we focus on explaining and showing the ChainBuddy interface
    and workflow, rather than the baseline interface’s built-in features like the
    Response Inspector (table of LLM responses) and different nodes. We point readers
    unfamiliar with the ChainForge platform to the public documentation or the paper
    (Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在本文中，我们重点解释和展示ChainBuddy的界面和工作流，而不是基线界面中的内置功能，例如响应检查器（LLM响应表）和不同节点。对于不熟悉ChainForge平台的读者，我们建议参考公开文档或相关论文（Arawjo等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)）。
- en: 3.2\. System Architecture
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 系统架构
- en: '![Refer to caption](img/5c2fcac434acaef5405c5e79a5914130.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/5c2fcac434acaef5405c5e79a5914130.png)'
- en: 'Figure 3\. ChainBuddy system architecture. A front-end requirement agent elicits
    user intent and context (left). When the user presses the generate button (Fig [2](https://arxiv.org/html/2409.13588v1#S3.F2
    "Figure 2 ‣ 3.1\. Interface and Example Usage ‣ 3\. ChainBuddy System Design ‣
    ChainBuddy: An AI Agent System for Generating LLM Pipelines")d), a specification
    of user intent is sent to the Planner in the back-end. The Planner agent breaks
    down the problem into tasks and sends each to a dedicated agent; the outputs are
    combined through layout-providing connection agents, merged and passed to an optional
    Reviewer agent. The final output is passed to the front-end as a complete ChainForge
    flow (JSON).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. ChainBuddy系统架构。前端需求代理引导用户意图和上下文（左侧）。当用户按下生成按钮（图[2](https://arxiv.org/html/2409.13588v1#S3.F2
    "图 2 ‣ 3.1\. 界面和示例使用 ‣ 3\. ChainBuddy系统设计 ‣ ChainBuddy：用于生成LLM管道的AI代理系统")d）时，用户意图的规范会发送到后端的规划器。规划器代理将问题拆解为任务并将每个任务分配给专门的代理；这些输出通过提供布局的连接代理进行合并，并传递给可选的审阅者代理。最终输出作为完整的ChainForge流程（JSON）传递到前端。
- en: ChainBuddy is built on LangGraph (LangChain AI, [2024](https://arxiv.org/html/2409.13588v1#bib.bib25)),
    a library designed for constructing stateful, multi-actor applications with LLMs.
    LangGraph’s core benefits include its ability to handle cycles, provide fine-grained
    controllability, and ensure persistence. These features are essential for creating
    reliable agent-based workflows that can support advanced human-in-the-loop and
    memory functionalities. We use Anthropic’s Claude 3.5 Sonnet for the front-end
    requirements-gathering agent, and OpenAI’s GPT-4o for all agents in the backend.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ChainBuddy基于LangGraph（LangChain AI，[2024](https://arxiv.org/html/2409.13588v1#bib.bib25)）构建，LangGraph是一个用于构建具有状态、支持多个参与者的LLM应用程序的库。LangGraph的核心优势包括处理循环的能力、提供精细化控制以及确保持久性。这些功能对于创建可靠的基于代理的工作流至关重要，能够支持高级的人工参与和记忆功能。我们使用Anthropic的Claude
    3.5 Sonnet作为前端需求收集代理，后端所有代理则使用OpenAI的GPT-4o。
- en: 3.2.1\. Requirement gathering
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 需求收集
- en: 'The design of the requirement gathering agent for the ChainForge platform draws
    inspiration from the Chain of Reasoning (Suzgun and Kalai, [2024](https://arxiv.org/html/2409.13588v1#bib.bib36))
    prompting methodology adapted from the open-source GitHub project Professor Synapse,
    an “AI guide designed to help users achieve their goals” (Synaptic Labs, [2024](https://arxiv.org/html/2409.13588v1#bib.bib37)).
    The structured interface for intent elicitation was inspired by ExploreLLM (Ma
    et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib29)). The agent employs
    a dictionary that updates context about the primary user goal, a list of current
    requirements the solution should address, and other user preferences. This structure
    is updated throughout the agent’s interactions with the user. Overall, the agent
    poses three types of targeted questions to refine understanding:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ChainForge平台的需求收集代理的设计灵感来源于“推理链”（Suzgun和Kalai，[2024](https://arxiv.org/html/2409.13588v1#bib.bib36)）提示方法，该方法是从开源GitHub项目Professor
    Synapse中改编而来，Professor Synapse是一个“旨在帮助用户实现目标的AI指南”（Synaptic Labs，[2024](https://arxiv.org/html/2409.13588v1#bib.bib37)）。用于意图引导的结构化界面灵感来自ExploreLLM（Ma等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib29)）。该代理使用一个字典来更新关于主要用户目标的上下文信息、解决方案应解决的当前需求列表以及其他用户偏好。这个结构会在代理与用户的交互过程中不断更新。总体而言，代理通过三种类型的目标问题来细化理解：
- en: (1)
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Goal Clarification Questions: These questions help to understand the overall
    objectives the user is aiming to achieve, as well as the context around their
    problem.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标澄清问题：这些问题帮助理解用户希望实现的总体目标，以及他们问题的背景。
- en: (2)
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'Requirements Exploration Questions: Designed to uncover specific needs, constraints,
    and fine-grained requirements that align with the user’s goals.'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 需求探索问题：旨在揭示与用户目标一致的具体需求、约束和细化要求。
- en: (3)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: 'Disambiguation Questions: Ask for any clarifications to address ambiguities
    or contradictions between the overall user goal and the requirements.'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 澄清问题：请求任何澄清，以解决整体用户目标和需求之间的歧义或矛盾。
- en: This interactive approach ensures flexibility in accommodating changes as new
    insights or constraints emerge during the iterative dialogue. The requirement
    gathering agent also aims to help users better understand and reflect on their
    needs and goals before precise messages are sent to the back-end workflow-generating
    agents, which are relatively time-consuming and costly compared to the chat.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种互动式方法确保了在迭代对话过程中，随着新见解或约束的出现，能够灵活应对变化。需求收集代理还旨在帮助用户在向后端工作流生成代理发送精确消息之前，更好地理解和反思自己的需求和目标，因为与聊天过程相比，后端工作流生成代理的处理相对更耗时且成本更高。
- en: 3.2.2\. Workflow generation
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 工作流生成
- en: 'Inspired by concepts from Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought
    Reasoning by Large Language Models (Wang et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib41))
    and projects like Baby-AGI (Nakajima, [2024](https://arxiv.org/html/2409.13588v1#bib.bib30)),
    we designed ChainBuddy’s agentic system to generate long-term plans based on user
    requirements (Figure [3](https://arxiv.org/html/2409.13588v1#S3.F3 "Figure 3 ‣
    3.2\. System Architecture ‣ 3\. ChainBuddy System Design ‣ ChainBuddy: An AI Agent
    System for Generating LLM Pipelines")). This approach involves breaking down each
    task into specific, manageable actions that can be executed by individual agents
    which return structured data to upstream agents (i.e., JSON). This design allows
    each agent to focus on a single task, improving efficiency and accuracy. Key architectural
    features include:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '受到《Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning
    by Large Language Models》（王等， [2023](https://arxiv.org/html/2409.13588v1#bib.bib41)）以及像Baby-AGI（中岛，[2024](https://arxiv.org/html/2409.13588v1#bib.bib30)）这样的项目的启发，我们设计了ChainBuddy的代理系统，以根据用户需求生成长期计划（见图[3](https://arxiv.org/html/2409.13588v1#S3.F3
    "Figure 3 ‣ 3.2\. System Architecture ‣ 3\. ChainBuddy System Design ‣ ChainBuddy:
    An AI Agent System for Generating LLM Pipelines")）。这种方法涉及将每个任务分解为可由单个代理执行的具体、可管理的操作，代理将结构化数据返回给上游代理（即JSON）。这种设计使得每个代理可以专注于单一任务，从而提高效率和准确性。关键的架构特点包括：'
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Requirement Gathering Chat Assistant: A chat-focused agent interacts with the
    user to disambiguate user intent and gain context for their problem, before proceeding
    to the generation step.'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 需求收集聊天助手：一个以聊天为主的代理与用户互动，以澄清用户意图并获取问题的上下文，然后再进入生成步骤。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Planner Agent: Takes the specification from the front-end of the user goal,
    and develops a comprehensive plan for implementation. The Planner is passed contextual
    information on all nodes in ChainForge that it has access to, their names and
    descriptions, and how they are allowed to connect.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规划代理：接收来自用户目标前端的规范，并制定全面的实施计划。规划代理会获得它可以访问的所有ChainForge节点的上下文信息，包括节点的名称、描述以及它们允许的连接方式。
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Task-Specific Agents: Each task in the plan is assigned to a specific agent,
    allowing for focused execution. Here, a “task” largely maps to different nodes
    in the ChainForge interface that need to be generated.¹¹1For our usability study,
    we limited the nodes to: TextFields Node, Prompt Node, LLM Scorer Node, and Python
    Code Evaluator Node. This specialization can allow utilizing smaller, less powerful
    models for execution tasks while reserving larger, more capable models for planning.'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务专用代理：计划中的每个任务都分配给特定代理，从而实现集中的执行。在这里，“任务”主要映射到ChainForge界面中需要生成的不同节点。¹¹1在我们的可用性研究中，我们将节点限制为：TextFields节点、Prompt节点、LLM评分节点和Python代码评估节点。这种专业化可以允许使用较小、较不强大的模型来执行任务，而将较大、更强大的模型保留用于规划。
- en: •
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Connection Agents: These agents take the task-specific output (as JSON data
    representing ChainForge nodes to add), create edge specifications to connect them
    and fill in starter x-y positions for nodes.'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 连接代理：这些代理处理任务专用的输出（作为表示要添加的ChainForge节点的JSON数据），创建连接这些节点的边缘规范，并为节点填写初始的x-y位置。
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Post-hoc Reviewer Agent: A final Reviewer agent assesses the generated flow
    against the initial user criteria given to the Planner agent. The Reviewer can
    trigger the Planner to re-plan before presenting the flow to the user, if the
    generated flow falls below expectations. (Note that for our usability study, we
    disabled the Reviewer because it significantly increases generation time.)'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 事后审阅者代理：一个最终的审阅者代理会根据初始用户提供给Planner代理的标准评估生成的流程。如果生成的流程未达到预期，审阅者可以触发Planner重新规划，然后再将流程呈现给用户。（请注意，对于我们的可用性研究，我们禁用了审阅者，因为它显著增加了生成时间。）
- en: 'By leveraging these architectural principles, ChainBuddy aims to provide a
    robust, scalable solution for a wide range of LLM-related tasks. Note finally
    that the system we present here is limited to a few select nodes in ChainForge:
    TextFields Node, for defining input data; Prompt Node, for prompting one or more
    models and prompt templating; Python Code Evaluator and LLM Scorer Nodes for evaluating
    LLM outputs; and the Vis Node. The system also supports template chaining (Arawjo
    et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)) to compare across
    prompts; i.e., putting prompt templates inside TextField inputs and chaining them
    together. Template chaining is primarily useful for comparing across prompts in
    a structured way.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用这些架构原理，ChainBuddy旨在为广泛的LLM相关任务提供一个强大、可扩展的解决方案。最后请注意，我们在此展示的系统仅限于ChainForge中的几个特定节点：TextFields节点，用于定义输入数据；Prompt节点，用于提示一个或多个模型并进行提示模板化；Python代码评估器和LLM评分节点，用于评估LLM输出；以及Vis节点。该系统还支持模板链式（Arawjo等，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)），用于跨提示进行比较；即，将提示模板放入TextField输入并将其链式连接。模板链式主要用于以结构化的方式比较提示。
- en: 3.3\. Early Feedback
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 早期反馈
- en: 'We designed ChainBuddy through an iterative process of testing internally on
    new tasks, from prompt comparison, to model comparison, to evaluating LLMs for
    identity-based bias. In particular, we found that the AI had a tendency to overfit
    to few-shot examples (e.g., always choosing to evaluate two models, or use specific
    input data); based on this, we removed few-shot examples in specific places such
    as the Planner agent prompt. We also conducted informal pilot studies to gather
    early feedback and improve our system. Some early insights we discovered:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在新任务上进行内部测试的迭代过程设计了ChainBuddy，从提示比较，到模型比较，再到评估LLM的身份偏见。特别是，我们发现AI有过度拟合少量示例的倾向（例如，总是选择评估两个模型，或者使用特定的输入数据）；基于此，我们在某些地方（如Planner代理提示）移除了少量示例。我们还进行了非正式的试点研究，以收集早期反馈并改进我们的系统。我们发现的一些早期见解如下：
- en: •
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Intent disambiguation: One prompt entered by users did not usually contain
    enough information to generate a detailed workflow that addresses user’s actual
    needs. Based on this, we opted for a more interactive chat.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 意图歧义消除：用户输入的一个提示通常没有足够的信息来生成详细的工作流程，以满足用户的实际需求。基于此，我们选择了更具互动性的聊天方式。
- en: •
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Structured elicitation: We implemented ChatGPT-like chat where the system asks
    users questions. However, the LLM output was often long or listed several questions,
    and users struggled to reply in a natural way. Based on this, we opted for a structured
    form-filling approach, letting the user clarify only the questions they want to.
    We also limited the number and length of questions.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结构化引导：我们实现了类似于ChatGPT的聊天方式，在这种方式中，系统向用户提问。然而，LLM的输出通常很长，或者列出了多个问题，用户很难以自然的方式作答。基于此，我们选择了一种结构化的表单填写方法，让用户只澄清他们想要的那些问题。我们还限制了问题的数量和长度。
- en: •
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Feedback: Users suggested incorporating features like visualizing the loading
    progress, as well as providing explainable AI elements to help users understand
    how the system arrives at certain visualizations or results.'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 反馈：用户建议加入诸如可视化加载进度、以及提供可解释的AI元素，帮助用户理解系统如何得出某些可视化或结果。
- en: •
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Desire to edit existing flows: Some users wanted to continue the assistant
    chat, asking ChainBuddy to revise or extend the flow. We too wanted this feature,
    but felt it was too complex to address within the limits of a single paper.'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编辑现有流程的需求：一些用户希望继续与助手聊天，要求ChainBuddy修改或扩展流程。我们也希望有这个功能，但认为在一篇论文的限制内很难解决这个问题。
- en: 4\. Usability Study
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 可用性研究
- en: 'To evaluate ChainBuddy, we ran a within-subjects, mixed-methods user study
    against the baseline interface (ChainForge without ChainBuddy), since it was the
    most direct comparison to a “manual” open-ended system for setting up LLM pipelines.
    Our goals were broadly focused on how people would want to use an AI assistant
    for generating evaluations of LLM behavior; specifically, for our qualitative
    evaluation:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估ChainBuddy，我们进行了一个以被试为基础、混合方法的用户研究，针对基准界面（没有ChainBuddy的ChainForge），因为它是与设置LLM管道的“手动”开放式系统最直接的比较。我们的目标主要集中在人们如何希望使用AI助手生成LLM行为的评估；具体来说，对于我们的定性评估：
- en: (1)
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: What aspects of the assistant do they appreciate the most, compared to the baseline?
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相较于基准系统，他们最欣赏助手的哪些方面？
- en: (2)
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Do users find the requirements-gathering interaction helpful or necessary?
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户是否认为需求收集的互动既有帮助又必要？
- en: (3)
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: What kinds of problems do participants want to use ChainBuddy for? (free exploration
    task)
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参与者希望使用ChainBuddy解决哪些问题？（自由探索任务）
- en: (4)
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: Do people feel that their ideas or hypotheses changed after interacting with
    the assistant?
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户在与助手互动后，是否感觉自己的想法或假设发生了变化？
- en: (5)
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5)
- en: How do people edit the generated flows? What kinds of edits do they tend to
    make?
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户如何编辑生成的流程？他们通常会做哪些修改？
- en: (6)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (6)
- en: Do people learn anything from interacting with the assistant (and if so, what)?
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户在与助手互动过程中是否学到了什么？（如果有，学到了什么？）
- en: 'We also sought quantitative, subjective metrics for the following hypotheses
    for the structured tasks measured via self-reported completion times,²²2Specifically,
    the time from when participants first clicked or typed in the interface, to the
    time when they said they were “done” or ran out of time. Participants were given
    12 minutes for all tasks; if they ran out of time, the time was recorded as the
    maximum. NASA TLX cognitive load scale (Hart, [1988](https://arxiv.org/html/2409.13588v1#bib.bib16)),
    and a subset of five system usability Likert questions³³3The five questions, “I
    found the system easy to use,” “I would like to use this system frequently,” “I
    found the system unnecessarily complex,” “I felt confident using the system”,
    and “I needed to learn a lot of things before I could get going with this system”.
    derived from the System Usability Scale (Brooke, [1996](https://arxiv.org/html/2409.13588v1#bib.bib7)):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还寻求了关于以下假设的定量、主观指标，结构化任务通过自报告的完成时间来衡量，²²2具体而言，从参与者首次点击或输入界面开始，到他们表示“完成”或时间用尽为止。所有任务的时间限制为12分钟；如果时间用尽，记录为最大时间。NASA
    TLX认知负荷量表（Hart，[1988](https://arxiv.org/html/2409.13588v1#bib.bib16)），以及五个系统可用性Likert问卷的子集³³3这五个问题是：“我觉得系统易于使用”，“我希望经常使用这个系统”，“我觉得这个系统不必要地复杂”，“我使用系统时感到自信”，以及“我在使用这个系统前需要学很多东西”，这些问题源自系统可用性量表（Brooke，[1996](https://arxiv.org/html/2409.13588v1#bib.bib7)）：
- en: H1.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H1.
- en: Users feel that they complete tasks more quickly when using ChainBuddy, versus
    without.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户认为使用ChainBuddy时，相较于不使用，它能够更快地完成任务。
- en: H2.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2.
- en: Users perceive their workload with ChainBuddy as less demanding than the manual
    baseline interface.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户认为使用ChainBuddy时，工作负担比使用手动基准界面要轻。
- en: H3.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H3.
- en: Users report greater self-satisfaction with ChainBuddy, versus without (i.e.,
    ease of use, confidence, learnability).
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户报告称，相较于不使用时，使用ChainBuddy时的自我满意度更高（即易用性、信心、可学习性）。
- en: H4.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H4.
- en: Users are able to complete tasks more successfully with ChainBuddy, versus without.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户在使用ChainBuddy时，相较于不使用，能够更成功地完成任务。
- en: 4.1\. Recruitment and Participants
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 招募和参与者
- en: We recruited 12 in-lab participants around our North America-based university
    through listservs and Slack channels, mainly in computer science and engineering
    contexts. Participants were between ages 18-34 (seven between 23-27, three from
    28-34 and one 18-22) and balanced across gender (7 female; 6 male). Ten out of
    12 were from computer science or engineering backgrounds (the other two were from
    Neuroscience and Life Sciences, respectively). They reported a relatively high
    past experience with LLMs ($\mu{=}3.83$, $\sigma{=}0.71$ on a scale 1-5, with
    5 highest) as well as Python programming knowledge ($\mu{=}3.83$, $\sigma{=}1.11$;
    only P6, who had a background in Life Sciences, indicated no knowledge). Half
    of the participants self-reported as having “worked on a university study, paper,
    or project involving the evaluation of [LLMs]” and three participants had heard
    of or used ChainForge prior to the study. Each study took 75 minutes, and participants
    were compensated $30 in cash (CAD).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过北美一所大学的邮件列表和Slack频道招募了12名实验室内参与者，主要来自计算机科学和工程学科。参与者的年龄在18到34岁之间（7人年龄在23到27岁之间，3人年龄在28到34岁之间，1人年龄在18到22岁之间），性别平衡（7名女性，6名男性）。12名参与者中有10名来自计算机科学或工程背景（另外两名分别来自神经科学和生命科学）。他们报告了较高的LLM（大型语言模型）使用经验（平均值$\mu{=}3.83$，标准差$\sigma{=}0.71$，量表1-5，5为最高）以及Python编程知识（平均值$\mu{=}3.83$，标准差$\sigma{=}1.11$；只有P6，来自生命科学背景，表示没有相关知识）。一半的参与者自我报告曾参与过“涉及评估[LLMs]的大学研究、论文或项目”，并且有三名参与者在研究前听说或使用过ChainForge。每个研究耗时75分钟，参与者获得30加元（CAD）的现金报酬。
- en: 4.2\. Methodology, Procedure and Tasks
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 方法论、程序与任务
- en: 'We designed a within-subjects study with mixed methods. There were two Conditions:
    Assistant (with ChainBuddy) and Control (the baseline ChainForge interface without
    ChainBuddy). We also devised two tasks of roughly the same style and difficulty,
    and randomly assigned them in a counterbalanced manner to the conditions. The
    tasks were $T_{\texttt{email}}$: “You are a software engineer tasked with designing
    an automated tool to help people professionalize their emails for work contexts”,
    and $T_{\texttt{tweet}}$: “You are working on a tool to help summarize long text
    paragraphs into concise, catchy tweets limited to 144 characters.” In both cases,
    we told users their goal was “to set up a workflow in ChainForge that can help
    you find the ‘best’ prompt” and emphasized that their goal “is not to find the
    best prompt, but rather to set up a flow that can help you find the best prompt
    and compare between prompts.” There were $2\times 2=4$ unique orderings of Condition
    $\times$ Task. With 12 participants, this means that three (3) participants experienced
    each unique ordering, and six (6) experienced the Control first.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个结合多种方法的被试内设计研究。共有两个条件：助手（使用ChainBuddy）和控制组（基线的ChainForge界面，不使用ChainBuddy）。我们还设计了两个大致相同风格和难度的任务，并将它们以平衡的方式随机分配到不同的条件中。任务包括$T_{\texttt{email}}$：“你是一名软件工程师，任务是设计一个自动化工具，帮助人们为工作场景专业化他们的邮件”，以及$T_{\texttt{tweet}}$：“你正在开发一个工具，帮助将长段文本压缩成简洁且引人注目的推文，限制在144个字符以内。”在这两种情况下，我们告诉用户他们的目标是“在ChainForge中设置一个可以帮助你找到‘最佳’提示的工作流程”，并强调他们的目标“不是找到最佳提示，而是设置一个工作流，帮助你找到最佳提示并进行比较。”有$2\times
    2=4$种独特的条件$\times$任务排列方式。在12名参与者中，这意味着每种排列有三（3）名参与者体验，六（6）名参与者先体验控制组。
- en: 'After obtaining informed consent, the study procedure was:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得知情同意后，研究程序如下：
- en: (1)
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: A 5 minute video overview of the ChainForge interface
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一段5分钟的视频概述了ChainForge界面
- en: (2)
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: A tutorial guides users through the process of writing a prompt template that
    takes an ingredient and returns the dishes it can make, comparing prompts using
    template chaining, querying models, and inspecting results. The tutorial gave
    participants everything they needed to succeed, as the solutions to tasks were
    structurally similar to the tutorial flow. (The Tutorial did not introduce the
    Assistant; see below.)
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一段教程引导用户通过编写一个提示模板的过程，该模板接受一个成分并返回可以制作的菜肴，通过模板链式比对、查询模型和检查结果来比较提示。该教程为参与者提供了成功所需的一切，因为任务的解决方案与教程流程在结构上非常相似。（教程没有介绍助手；详见下文。）
- en: (3)
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: The first condition and task, in an order randomly assigned and counter-balanced
    across participants. After the task, the post-task questionnaire.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个条件和任务，以随机分配并在参与者之间进行平衡的方式进行。任务完成后，填写任务后问卷。
- en: (4)
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (4)
- en: The second condition and task, and post-task questionnaire.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二个条件和任务，以及任务后问卷。
- en: (5)
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5)
- en: Unstructured exploration, where participants examined an idea or hypothesis
    they had within the Assistant condition. They were not required to use the assistant.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无结构探索，参与者在助手条件下检查他们拥有的想法或假设。他们不需要使用助手。
- en: (6)
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (6)
- en: Post-interview and compensation
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 后访谈和补偿
- en: There is also one mini-tutorial for the Assistant that occurs directly before
    the Assistant condition, wherever the condition appears. We deliberately avoided
    showing participants the Assistant during the pre-tasks tutorial, because we wanted
    to mitigate the potential for bias from participants “guessing the hypothesis”
    of the study (demand characteristics) when experiencing the Control interface
    first.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 助手条件之前还有一个小型教程，每当条件出现时，都会直接进行。我们故意避免在前置任务教程中向参与者展示助手，因为我们希望减少参与者在首次体验控制界面时“猜测研究假设”（需求特征）可能带来的偏差。
- en: 4.3\. Data Analysis
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 数据分析
- en: Participant interactions were screen and audio recorded. We also captured log
    data for chats with the Assistant and saved flows (files) for all tasks for later
    analysis. We analyzed qualitative data through inductive thematic analysis; specifically,
    the first author iteratively affinity diagrammed all participant remarks during
    the study (including post-interview) to arrive at clusters (codes). These clusters
    and codes were then discussed by both authors until we reached consensus.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者的互动进行了屏幕和音频录制。我们还捕获了与助手的聊天日志数据，并保存了所有任务的流程（文件），以供后续分析。我们通过归纳主题分析处理定性数据；具体而言，第一作者迭代地将研究过程中所有参与者的评论（包括后访谈）进行亲和图分类，以得出聚类（编码）。这些聚类和编码随后由两位作者讨论，直到达成共识。
- en: We analyzed quantitative data using a repeated measures linear mixed effects
    model in R (Luke, [2017](https://arxiv.org/html/2409.13588v1#bib.bib28)), examining
    fixed effects of Condition, Task, and Order and all interaction effects between
    these factors, and controlling for random effect of Participant. P-values for
    main and interaction effects are calculated using Satterthwaite’s method for degrees
    of freedom and reported from ANOVA tables with lmerTest (Kuznetsova et al., [2017](https://arxiv.org/html/2409.13588v1#bib.bib24)).
    Post-hoc tests were done via estimated marginal means (emmeans) with Bonferroni
    correction; when including the estimate ($\beta$) and t-statistic ($t$), reported
    p-values are from emmeans. We visually inspected the normality of model residuals
    (via Q-Q plots) and assumption of homoscedasticity. Our quantitative results are
    meant to complement our qualitative findings.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用R中的重复测量线性混合效应模型（Luke, [2017](https://arxiv.org/html/2409.13588v1#bib.bib28)）分析了定量数据，检查了条件、任务和顺序的固定效应，以及这些因素之间的所有交互效应，并控制了参与者的随机效应。主效应和交互效应的P值是通过Satterthwaite自由度方法计算的，并从ANOVA表中报告，使用lmerTest（Kuznetsova等人，[2017](https://arxiv.org/html/2409.13588v1#bib.bib24)）。事后检验通过估计边际均值（emmeans）和Bonferroni校正进行；在包括估计值（$\beta$）和t统计量（$t$）时，报告的p值来自emmeans。我们通过Q-Q图检查了模型残差的正态性以及同方差性假设。我们的定量结果旨在补充我们的定性发现。
- en: 5\. Findings
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 研究发现
- en: '![Refer to caption](img/fe2a1fb3be82569d494e30421b4dbf04.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![请参见标题](img/fe2a1fb3be82569d494e30421b4dbf04.png)'
- en: Figure 4\. Participant responses to Likert Questions for NASA TLX and system
    usability, grouped by Condition. Asterisk (*) indicates a significant main effect
    of Condition at $p<0.05$; † indicates another main effect, interaction effect
    or outliers.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图4\. 参与者对NASA TLX和系统可用性Likert问卷的回应，按条件分组。星号(*)表示条件的显著主效应，$p<0.05$；† 表示另一个主效应、交互效应或异常值。
- en: 5.1\. Quantitative results
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 定量结果
- en: We summarize major quantitative findings here before delving into specifics.
    Overall, participants perceived the Assistant as significantly *less mentally
    demanding* and *less physically demanding* than the Control. Participants were
    also *more confident* and *more performant* when using the Assistant. Finally,
    participants *created at least one more type of node in the Assistant condition,*
    on average, with a portion of the effect explained by the Assistant generating
    Evaluator nodes (where only one participant created a Python Code Evaluator in
    the Control condition).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里总结了主要的定量发现，然后再深入探讨具体内容。总体而言，参与者认为助手比控制条件显著*更不费脑力*且*更不费体力*。使用助手时，参与者也表现得*更有信心*且*表现更好*。最后，参与者在助手条件下*平均创造了至少一种新的节点类型*，其中部分效应可以通过助手生成的评估节点来解释（在控制条件下，只有一个参与者创建了Python代码评估器）。
- en: There were also two ordering effects by task for perceived Successfulness and
    Ease of Use, both when experiencing the Control condition after the Assistant.
    Though these results are specific, interact with Task (see below) and could be
    considered random fluctuations or demand characteristics given the small study
    size; however, considered together, they might suggest a small “missing the assistant”
    effect—using the Assistant first helped some participants apply their knowledge
    to the next task, but it also may prime them to perceive the baseline interface
    as harder to use.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 任务的顺序效应也影响了感知成功性和易用性，尤其是在控制条件出现在助手之后时。尽管这些结果是特定的，且与任务交互（见下文），并且考虑到研究样本量较小，它们可能被视为随机波动或需求特征；然而，综合考虑，这些结果可能表明一个小的“怀念助手”效应——首先使用助手帮助一些参与者将他们的知识应用到下一个任务中，但也可能让他们认为基础界面更难使用。
- en: 5.1.1\. Time to completion (H1)
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1. 完成时间（H1）
- en: 'We did not find a significant main effect at $p{<}0.05$. We report a borderline
    significant interaction effect for Condition given Order ($\beta{=}-239.5$, $t{=}-2.22$,
    $p{=}0.04$): when people experienced the Assistant after the Control condition,
    they perceived they were finished with the task faster ($\mu{=}357$ secs versus
    $\mu{=}610$; 95% CI [195, 518] versus [445, 771]).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有发现$p{<}0.05$时的显著主效应。我们报告了条件与顺序的交互效应接近显著（$\beta{=}-239.5$，$t{=}-2.22$，$p{=}0.04$）：当人们在控制条件后体验助手时，他们感觉任务完成得更快（$\mu{=}357$秒对$\mu{=}610$秒；95%
    置信区间[195, 518]对[445, 771]）。
- en: 5.1.2\. Workload Demand (NASA TLX) (H2)
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2. 工作负载需求（NASA TLX）（H2）
- en: 'We find main effects of Condition on mental demand and physical demand, with
    participants finding tasks less mentally demanding ($\beta{=}-0.91$, $t{=}-2.66$,
    $p{=}0.01$) and less physically demanding ($\beta{=}-1.08$, $t{=}-3.15$, $p{=}0.01$)
    when using the Assistant (Figure [4](https://arxiv.org/html/2409.13588v1#S5.F4
    "Figure 4 ‣ 5\. Findings ‣ ChainBuddy: An AI Agent System for Generating LLM Pipelines")).
    For perceived successfulness, there is also a significant effect of Task ($\beta{=}0.66$,
    $t{=}2.53$, $p{=}0.02$) and two interaction effects of between Condition and Task
    ($p{=}0.02$), and Task and Order ($p{=}0.006$). Post-hoc emmeans tests suggest
    two sources for the effect: participants report they are more successful at $T_{\texttt{email}}$
    than $T_{\texttt{tweet}}$, but only when $T_{\texttt{email}}$ appeared second,
    possibly indicating a learning effect ($\beta{=}1.5$, $t{=}4.02$, $p{=}0.005$);
    and participants felt they were less successful when solving $T_{\texttt{tweet}}$
    in the Control condition ($\beta{=}1.33$, $t{=}3.57$, $p{=}0.01$). No other questions
    reach significance at $p{<}0.05$.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现条件对心理需求和身体需求有主效应，参与者在使用助手时任务的心理需求较低（$\beta{=}-0.91$，$t{=}-2.66$，$p{=}0.01$）且身体需求较低（$\beta{=}-1.08$，$t{=}-3.15$，$p{=}0.01$）（图[4](https://arxiv.org/html/2409.13588v1#S5.F4
    "图 4 ‣ 5. 发现 ‣ ChainBuddy：用于生成LLM管道的AI代理系统")）。在感知成功性方面，任务也有显著效应（$\beta{=}0.66$，$t{=}$2.53，$p{=}0.02$），并且条件与任务（$p{=}0.02$）以及任务与顺序（$p{=}0.006$）之间有两个交互效应。事后均值检验表明这一效应的两个来源：参与者报告他们在完成$T_{\texttt{email}}$时比完成$T_{\texttt{tweet}}$更成功，但仅当$T_{\texttt{email}}$出现在第二时，可能表明存在学习效应（$\beta{=}1.5$，$t{=}$4.02，$p{=}0.005$）；而在控制条件下，参与者在解决$T_{\texttt{tweet}}$时感觉不太成功（$\beta{=}1.33$，$t{=}$3.57，$p{=}0.01$）。没有其他问题在$p{<}0.05$时达到显著性。
- en: 5.1.3\. Perceived System Usability (H3)
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.3. 感知系统可用性（H3）
- en: 'We find a significant main effect of Condition on Confidence ($\beta{=}0.5$,
    $t{=}2.44$, $p{=}0.04$). Participants felt moderately more confident using the
    Assistant (Fig [4](https://arxiv.org/html/2409.13588v1#S5.F4 "Figure 4 ‣ 5\. Findings
    ‣ ChainBuddy: An AI Agent System for Generating LLM Pipelines")).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现条件对自信心有显著的主效应（$\beta{=}0.5$，$t{=}2.44$，$p{=}0.04$）。参与者在使用助手时感觉更有信心（图[4](https://arxiv.org/html/2409.13588v1#S5.F4
    "图 4 ‣ 5. 发现 ‣ ChainBuddy：用于生成LLM管道的AI代理系统")）。
- en: 'For Ease of Use, we found a three-way interaction between Condition, Task,
    and Order ($p{=}0.003$). Visual inspection of data reveals two outliers as the
    culprit: two participants who received $T_{\texttt{tweet}}$ with the Control condition
    in the second position, who both rated ease of use 1 and 2 (P2 and P7; only one
    other participant, P9, experienced this order). All other participants rated the
    Control condition 4 or above for Ease of Use, with a median of 4.5\. Eleven (out
    of 12) participants gave the Assistant a 5 for ease of use (one 4). One possible
    explanation for the outliers is that these participants “missed” the AI assistant’s
    reduction to their workload during $T_{\texttt{tweet}}$, which asks participants
    to summarize “long paragraphs” into tweets—requiring them to create test data.
    Possibly, knowing that the Assistant could generate long example paragraphs for
    them, these participants were frustrated by having to manually type in input data.
    (Indeed, there is evidence for this: P2 used a lone Prompt Node to generate test
    paragraphs, as a workaround for not having assistant access.)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对于易用性，我们发现条件、任务和顺序之间存在三向交互作用（$p{=}0.003$）。数据的视觉检查揭示了两个异常值是罪魁祸首：两位在第二位置接受了控制条件的$T_{\texttt{tweet}}$的参与者，他们分别给易用性评分为1和2（P2和P7；只有另一位参与者P9经历了这种顺序）。所有其他参与者在易用性上都给控制条件评分为4或更高，中位数为4.5。十一位（共12位）参与者给助手的易用性评分为5（一个评分为4）。异常值的一个可能解释是，这些参与者在$T_{\texttt{tweet}}$任务中“错过”了AI助手减少他们工作量的作用，该任务要求参与者将“长段落”总结为推文——这要求他们创建测试数据。可能是因为知道助手可以为他们生成长示例段落，这些参与者对手动输入数据感到沮丧。（事实上，有证据支持这一点：P2使用了一个独立的提示节点生成测试段落，作为没有助手访问时的解决方法。）
- en: No other questions reached significance, suggesting that participants liked
    the interface equally across conditions, and found it of similar difficulty to
    learn.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 没有其他问题达到显著性，表明参与者在不同条件下对界面的喜好相似，并且觉得学习难度相似。
- en: 5.1.4\. Performance (H4)
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.4. 性能（H4）
- en: 'We estimated user performance on the task with three binary (true-false) measures
    shared across both task descriptions: whether their final flow explicitly compares
    two prompts, whether the flow runs (i.e., the Prompt Node can run), and whether
    the flow uses template chaining to compare prompts (the last is a feature introduced
    in the tutorial and was the expected solution, but is not the only one). Plots
    show strong evidence in favor of the Assistant condition (Figure [5](https://arxiv.org/html/2409.13588v1#S5.F5
    "Figure 5 ‣ 5.1.5\. Number and Types of Created Nodes ‣ 5.1\. Quantitative results
    ‣ 5\. Findings ‣ ChainBuddy: An AI Agent System for Generating LLM Pipelines")),
    indicating that, *despite participants rating themselves of having similar success
    in both interfaces,* two-thirds of participants did not adequately solve the task
    in the Control condition (did not create a workflow helping users to compare prompts),
    compared to eleven (out of 12) participants when using the Assistant.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '我们通过三个二元（真假）度量标准来估计用户在任务中的表现，这些度量标准在两个任务描述中共享：他们的最终流程是否明确比较了两个提示，流程是否能够运行（即提示节点是否可以运行），以及流程是否使用了模板链式结构来比较提示（最后一项是教程中介绍的功能，是预期的解决方案，但不是唯一的）。图表强烈支持助手条件（图[5](https://arxiv.org/html/2409.13588v1#S5.F5
    "图 5 ‣ 5.1.5. 创建节点的数量和类型 ‣ 5.1. 定量结果 ‣ 5. 研究发现 ‣ ChainBuddy: 用于生成LLM管道的AI代理系统")），表明，*尽管参与者自评在两种界面中的成功率相似，*在控制条件下，三分之二的参与者未能充分解决任务（没有创建帮助用户比较提示的工作流），而在使用助手时，十一位（共12位）参与者成功解决了该任务。'
- en: 5.1.5\. Number and Types of Created Nodes
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.5. 创建节点的数量和类型
- en: Finally, we examined the Number of Nodes in participants’ final flows, as well
    as the Number of Node Types (e.g., a flow with two TextFields and one Prompt Node
    has 3 nodes and 2 types of nodes). Participants created a similar number of nodes
    regardless of condition or task—suggesting a similar complexity and size of their
    pipelines. However, for types of nodes, we find main effects of Condition ($\beta{=}0.583$,
    $t{=}4.04$, $p{=}0.003$) and Order ($\beta{=}{-}0.417$, $t{=}{-}2.887$, $p{=}0.02$).
    On average, people created significantly more node types in the Assistant condition
    than the Control; specifically, they created about one more node type (median
    of 2 node types, versus median of 3 for Control). People also created more node
    types during their second task, indicating a learning effect irrespective of Condition
    and Task. Post-hoc analyses show significantly more Evaluator Nodes (either Code-
    or LLM-based) in the Assistant condition ($\beta{=}0.58$, $t{=}3.5$, $p{=}0.008$),
    with no other node type reaching significance. Inspecting the data further, only
    one participant added a Python Code Evaluator when in the Control condition.⁴⁴4One
    explanation is that writing Python code is difficult and time-consuming, and since
    we did not screen participants for programming skill, some may have been unable
    to write said code. Overall, this suggests the Assistant helped participants make
    more Evaluator-type nodes, especially Python Code Evaluators, and that participants
    tried out more interface features over time.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查了参与者最终工作流中的节点数量以及节点类型数量（例如，一个包含两个TextField和一个Prompt Node的工作流有3个节点和2种节点类型）。无论在什么条件下或任务中，参与者创建的节点数量都差不多——这表明他们的工作流的复杂度和规模相似。然而，在节点类型方面，我们发现条件（$\beta{=}0.583$，$t{=}4.04$，$p{=}0.003$）和顺序（$\beta{=}{-}0.417$，$t{=}{-}2.887$，$p{=}0.02$）有主要影响。平均而言，在助手条件下，参与者创建的节点类型显著多于控制组；具体来说，他们创建了大约一个更多的节点类型（控制组的中位数为2种节点类型，而助手组为3种节点类型）。参与者在第二个任务中也创建了更多的节点类型，表明无论条件或任务如何，存在学习效应。事后分析显示，助手条件下显著更多的评估节点（无论是基于代码的还是基于LLM的）（$\beta{=}0.58$，$t{=}3.5$，$p{=}0.008$），其他节点类型没有达到显著性。进一步检查数据时，只有一位参与者在控制条件下添加了一个Python代码评估节点。⁴⁴一个解释是编写Python代码既困难又耗时，且由于我们没有筛选参与者的编程技能，一些人可能无法编写该代码。总体而言，这表明助手帮助参与者创建了更多评估类型的节点，尤其是Python代码评估节点，并且参与者随着时间的推移尝试了更多的界面功能。
- en: '![Refer to caption](img/1d27d91abae310129e978c86a481ef0b.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/1d27d91abae310129e978c86a481ef0b.png)'
- en: 'Figure 5\. Performance metrics comparing expected qualities of correct solutions
    across conditions and tasks: whether the flow explicitly compares two prompts,
    whether the flow runs (i.e., the Prompt Node can run), and whether the flow uses
    template chaining to compare prompts (a feature introduced in the tutorial, and
    the expected solution).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图5\. 性能指标比较不同条件和任务下正确解决方案的预期质量：流程是否明确比较了两个提示，流程是否可以运行（即，提示节点是否可以运行），以及流程是否使用模板链接来比较提示（这是在教程中介绍的功能，也是预期的解决方案）。
- en: 5.2\. Qualitative results
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 定性结果
- en: 'We examined interactions and interview data across the structured tasks and
    unstructured exploration. Overall we found several key insights into participants’
    experiences with ChainBuddy:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对结构化任务和非结构化探索中的互动和访谈数据进行了分析。总体而言，我们发现了几个关于参与者使用ChainBuddy的关键洞察：
- en: •
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: ChainBuddy helps users in overcoming the ”blank page problem,” converting vague
    ideas into concrete workflow drafts.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChainBuddy帮助用户克服了“空白页问题”，将模糊的想法转化为具体的工作流草稿。
- en: •
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: ChainBuddy’s requirement gathering process helped participants elicit user goals
    and criteria, provided a structured way to present requirements, and expanded
    user thinking.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChainBuddy的需求收集过程帮助参与者引导用户目标和标准，提供了一种结构化的方式来呈现需求，并扩展了用户的思维。
- en: •
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Participants perceived that the assistant reduced effort, sped up their workflow
    and alleviated the learning curve of using the baseline interface.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参与者认为助手减少了工作量，加快了工作流，并缓解了使用基线界面的学习曲线。
- en: •
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: ChainBuddy surpassed participants’ expectations, with its capabilities surprising
    users.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChainBuddy超出了参与者的预期，其能力令用户感到惊讶。
- en: •
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Participants with substantial prior experience in prompt engineering perceived
    that ChainBuddy aided their prompt engineering process.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 具有丰富提示工程经验的参与者认为ChainBuddy有助于他们的提示工程过程。
- en: •
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Concerns about potential bias or influence on their problem-solving approach
    after interacting with the assistant.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 参与者在与助手互动后，对可能的偏见或对问题解决方式的影响表示担忧。
- en: We first expand on these findings in the sections below and then discuss the
    interaction patterns identified by the study
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在下面的章节中扩展这些发现，然后讨论研究中识别的互动模式。
- en: 5.2.1\. Assistant as a starting point
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 作为起点的助手
- en: Eight participants found that ChainBuddy provided a good starting point for
    their tasks, helping them overcome the initial challenge of starting from scratch.
    P5 said, ”maybe it’s hard to start with an empty page. It’s better to start with
    a little bit of question and answer here, so you have a base structure.” The assistant
    helped users quickly generate initial workflow drafts, reducing the effort required
    to start from scratch. P1 appreciated that ”the assistant can give me, like a
    first draft. That is pretty good.” Similarly, P9 highlighted the importance of
    having an example to ”put things into context much more easily,” which helped
    them decide whether to proceed with the assistant’s suggestions or refine their
    own approach.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 八位参与者发现，ChainBuddy为他们的任务提供了一个很好的起点，帮助他们克服了从零开始的初步挑战。P5表示：“也许从空白页面开始很难。最好从一些问答开始，这样你就有了一个基础结构。”该助手帮助用户快速生成初步的工作流程草稿，减少了从零开始所需的努力。P1认为，“助手可以给我一个初稿，这很不错。”类似地，P9强调了拥有示例的重要性，“这样可以更容易地将事情放到上下文中”，这帮助他们决定是否继续执行助手的建议，或者优化自己的方法。
- en: 5.2.2\. Requirement gathering process helped refine ideas and elicit requirements
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2\. 需求收集过程帮助完善想法并引出需求
- en: Six participants reflected that the assistant’s structured and iterative approach
    to intent disambiguation made the process more organized and easier to follow
    compared to traditional prompting. Moreover, the iterative questioning made users
    think more deeply about their tasks and specify details they might otherwise overlook,
    which they felt led to more detailed pipelines.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 六位参与者反映，助手在意图消歧过程中采用的结构化和迭代方法使得这一过程比传统的提示更有条理，也更容易跟随。此外，迭代式提问让用户更加深入地思考他们的任务，并明确一些可能会忽视的细节，参与者认为这导致了更详细的工作流程。
- en: 'For instance, P12 remarked that ”sometimes… I know exactly what I want, but
    I’m not necessarily putting it all in the prompt.” P9 found that ”the follow-up
    questions made you create a more comprehensive workflow” and P8 was ”really surprised
    when it asked questions based on what I need.” The form-filling interface helped
    users to provide information in a more manageable and less overwhelming way than
    writing everything at once (e.g. P9: ”I was pleasantly surprised that you can
    type the answers under each question, instead of having just to blurt it all out
    in a long piece of text”). By asking users relevant questions, the assistant could
    also help broaden their thinking and refine their ideas. P1 found that the assistant
    ”asked me other questions, and I think of like, ‘Oh, it’s true, I can do this.’”
    P7 said ”it was impressive, because it’s started to ask me about the design itself,
    it was clear and precise,” and commented that the assistant encouraged him to
    “think more on the abstract side of the idea itself.”'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，P12提到，“有时……我确切知道我想要什么，但我不一定会把所有信息都放进提示里。”P9发现，“后续的问题让你创建了一个更全面的工作流程”，而P8则“非常惊讶它会根据我需要的内容提问。”这种表单填写界面帮助用户以一种更易于管理、不那么压倒性的方式提供信息，而不是一次性写下所有内容（例如P9：“我很惊讶你可以在每个问题下输入答案，而不是必须把所有内容一口气写成一大段文字”）。通过向用户提出相关问题，助手还能够帮助他们拓宽思路并完善他们的想法。P1发现，助手“问了我其他问题，我就会想到，‘哦，确实，我可以这么做。’”P7表示，“这很令人印象深刻，因为它开始问我关于设计本身的问题，很清晰且精准”，并评论说助手鼓励他“更多地从抽象的角度思考想法本身。”
- en: However, participants could also worry that Q&A intent elicitation could become
    excessive, with four suggesting rounds limits or guidance on when sufficient information
    has been provided. P9 worried about getting ”too caught up in the details, which
    is me answering the supplemental questions too much. Like I keep on digging… and
    you end up creating a model that’s just too rigid.” P12 also wondered, ”if you
    keep going and questions keep being asked, that’s where you start contradicting
    yourself.” One suggestion to improve the design was to have the assistant deduce
    when there is enough information to proceed with generation (e.g., P7 said ”I
    do think, if it understand the question, it should know where to stop.”, and P2
    wanted ”an indicator of… [the] level of understanding that the system has achieved
    at that point of time”).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，参与者也担心问答意图引导可能会过度，其中四位建议限制问答轮次或提供有关何时信息足够的指导。P9担心会“过于纠结细节，这就是我回答补充问题太多。就像我不停地挖掘……你最终会创造出一个过于僵化的模型。”P12也表示，“如果你不停地继续，问题一直被问，那时你就开始自相矛盾了。”一个改进设计的建议是让助手判断何时信息足够，可以继续生成（例如，P7说：“我确实认为，如果它理解了问题，它应该知道何时停止。”，P2希望“有一个指示器……[系统在此时]所达到的理解程度”）。
- en: 5.2.3\. Exceeding user expectations
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3\. 超越用户预期
- en: 'Ten participants remarked the assistant not just met, but exceeded their initial
    expectations. Participants consistently expressed surprise by the assistant’s
    capabilities, particularly in its abilities to ask relevant follow-up requirement-gathering
    questions and generate detailed workflows. For instance, P2 remarked, ”I was not
    expecting it to generate even remotely close workflow. But it gave me two additional
    nodes, understood that these are my requirements, so I might use it.” P1 was surprised
    at how well the assistant performed: ”It’s asking really good like, follow up
    questions that made me rethink the problem and generated a good flow for it.”
    Similarly, P8 initially expected a basic chatbot but was impressed when the assistant
    ”asked questions based on what I need,” which helped expand their ideas and improve
    their prompts. P6 was particularly impressed by how ChainBuddy was able to generate
    a workflow for a complex goal, stating, ”I asked it to compare detailed incomes
    for 10 medical specialties, and it did really well, and it also handled a more
    complex task without misunderstanding.”'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 十位参与者表示助手不仅满足了他们的预期，还超出了他们的初步期望。参与者一致表示对助手的能力感到惊讶，特别是在它能够提出相关的后续需求收集问题并生成详细工作流方面。例如，P2表示，“我没想到它能生成如此接近的工作流。但它给了我两个额外的节点，理解了这些是我的需求，所以我可能会使用它。”P1对助手的表现感到惊讶：“它问了非常好的后续问题，让我重新思考问题，并生成了一个很好的流程。”类似地，P8最初期望的是一个基本的聊天机器人，但当助手“根据我的需求提问”时，给他们的思路拓展并改善了他们的提示，他们感到非常印象深刻。P6特别对ChainBuddy能为复杂目标生成工作流感到印象深刻，表示：“我让它比较10个医学专业的详细收入，它做得非常好，而且也处理了更复杂的任务，没有误解。”
- en: When asked to clarify, participants explained that they expected the assistant
    to be a basic Q&A chatbot, but found it more interactive and insightful. For example,
    P10’s ”expectation was something like ChatGPT that actually gives you the final
    output, not asking too many questions, back and forth,” but they appreciated how
    the assistant ”tries to understand what’s your goals, what’s your criteria. So
    I love it better than ChatGPT.”
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当被要求澄清时，参与者解释说他们原本期望助手只是一个基本的问答聊天机器人，但发现它更加互动且富有洞察力。例如，P10的“期望是类似于ChatGPT那样的，它实际上会给你最终的输出，而不是问太多问题，来回反复，”但他们欣赏助手“尝试理解你的目标是什么，你的标准是什么。所以我比更喜欢它，而不是ChatGPT。”
- en: 5.2.4\. Reducing effort
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.4\. 降低努力
- en: Participants felt the assistant reduced their workload and streamlined task
    execution, complementing our quantitative results. P10 said ”the mental demand
    was much less when I used the assistant,” which was particularly beneficial because
    the assistant helped ”translating my inquiries to this platform,” making the experience
    accessible for beginners. Similarly, P8 observed that without the assistant, it
    was “pretty hard to think on my own, like making flows and like arranging it properly,”
    whereas the assistant streamlined the process. Without the assistant, participants
    could find manually setting up flows confusing or inefficient. P6 reflected that
    work without the assistant was “a lot harder than I expected. It seems that the
    task is simple at first, but then when I do it manually, some of the things does
    not fall into the category that I expected.” P4 found the assistant interface
    to be ”very intuitive, it generated and you just drag and drop everything [after].
    So I did not find any frustrations.”
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者认为助手减轻了他们的工作负担并简化了任务执行，这与我们的定量结果相得益彰。P10表示：“当我使用助手时，心理负担小了很多”，这尤其有益，因为助手帮助“将我的询问转化到这个平台上”，使得体验对于初学者更易接受。同样，P8观察到，没有助手时，“自己想的时候挺难的，比如制作流程和正确安排”，而助手简化了这个过程。没有助手，参与者可能会发现手动设置流程既混乱又低效。P6回忆道，没有助手的工作“比我预期的要难得多。任务一开始看起来很简单，但当我手动做时，有些东西并没有落入我预期的类别。”
    P4认为助手界面“非常直观，它生成后，你只需要拖放一切[之后]。所以我没有遇到任何挫折。”
- en: 5.2.5\. Accelerating workflow
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.5\. 加速工作流程
- en: Participants remarked that the assistant significantly accelerated their workflow.
    P11 remarked that ”with the assistant, it’s really quick. It gives you the ideas,
    and it makes all the necessary connections on the platform, so you save up that
    manual time of creating the whole workflow. And on top of that, it also saves
    mental efforts to start with the prompt.” Similarly, P9 felt that while there
    wasn’t a significant difference in their success rate and solution, ”it was just
    faster with ChainBuddy”.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者表示，助手显著加快了他们的工作流程。P11评论道，“有了助手，真的很快。它给了你想法，并在平台上完成了所有必要的连接，所以你节省了手动创建整个工作流程的时间。而且，最重要的是，它还节省了启动时的心理负担。”同样，P9认为，虽然他们的成功率和解决方案没有显著差异，“但使用ChainBuddy时就是更快了。”
- en: 5.2.6\. Helping users learn the platform
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.6\. 帮助用户学习平台
- en: Some participants felt that the assistant helped them learn and adapt to the
    platform, reducing the learning curve and making the tool more accessible for
    first-time users. P7 highlighted that ”usually when you don’t have an assistant
    and have nothing to work with you need, similar to learning new coding languages,”
    but with the assistant, the process was ”very fast.” P3 noted, ”for the first
    exercise, I really didn’t have much ideas of what I should do, after using the
    assistance, it’s just much more clear.” P5 also found the assistant helpful in
    guiding them through tasks, saying that ”it gives a sample that shows how these
    [nodes] could be connected. I just saw that, oh, I can name these [nodes] with
    relevant things [titles of the nodes], it’s good to name relevant [nodes] especially
    for someone using the tool for the first time, it’s very helpful.” P3, who had
    limited experience with AI tools, was impressed by the assistant’s capability,
    saying, ”The assistants just enlightened me,” and found it surprisingly effective
    compared to their prior experiences with AI chatbot from other interfaces.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参与者认为助手帮助他们学习和适应平台，减少了学习曲线，使工具对第一次使用的用户更为友好。P7强调，“通常没有助手且没有任何可以工作的东西时，你需要，类似于学习新的编程语言”，但有了助手，过程“非常快速”。P3指出，“第一次练习时，我真的不知道应该做什么，使用助手后，一切变得更清晰了。”
    P5也发现助手在引导他们完成任务时很有帮助，表示“它给出了一个示例，展示了这些[节点]如何连接。我看到后，哦，我可以用相关的东西[节点标题]来命名这些[节点]，尤其对于第一次使用工具的人来说，命名相关[节点]非常有帮助。”
    P3对AI工具经验有限，但对助手的能力印象深刻，表示“助手真是启发了我”，并且发现它比他们之前在其他界面上使用的AI聊天机器人更有效。
- en: The assistant was especially beneficial for helping participants overcome initial
    obstacles to understanding the interface. P6 shared that without the assistant,
    ”I don’t really know what to do sometimes,” but with the assistant, they ”did
    not need to think [about] anything.” P7 also said that”without the assistant,
    there would be obstacles for first-time users, a lot of people will struggle,”
    like the experience to the challenges of using something unfamiliar. P11 felt
    that the assistant “changed [my approach] to be better”.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 助手对于帮助参与者克服理解界面初步障碍尤其有益。P6 分享说，如果没有助手，“我有时真的不知道该做什么”，但有了助手，他们“什么都不用想”。P7 也说，“没有助手，第一次使用者会遇到障碍，很多人会感到困惑”，就像使用不熟悉的东西时遇到的挑战一样。P11
    觉得助手“改变了[我的方法]，让它变得更好”。
- en: 5.2.7\. Streamlining prompt engineering
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.7\. 精简提示工程
- en: In our study, there were three participants who often did prompt engineering
    in their daily work. P7 explained that in their prompt engineering tasks, they
    often need to ”write a program for each LLM and collect responses,” which is time-consuming.
    The assistant’s ability to handle these tasks with built-in tools meant that ”it
    will do all of that for you, because it already have the model, it has its evaluation
    tool, and you don’t need to do much time in order to experiment [with] multiple
    things.” P4 reflected, ”I think the most difficult part of doing this prompt engineering
    is writing the initial set of prompts. And I think that is where the assistant
    is very helpful, that it gives you an initial set of prompts, then that you can
    start working on… It’s a very, very good product, I would use it a lot.” P12,
    who often needed to duel with variations in data formats in their real work, found
    the assistant helpful in creating a workflow that could compare prompts to standardize
    differently structured information.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，有三位参与者在日常工作中经常进行提示工程。P7 解释说，在他们的提示工程任务中，他们经常需要“为每个大型语言模型（LLM）编写程序并收集响应”，这非常耗时。助手具备处理这些任务的内置工具，因此“它会为你做所有这些事情，因为它已经拥有模型，拥有评估工具，你不需要花很多时间来实验多个内容。”P4
    反思说，“我认为进行提示工程最困难的部分是编写初始提示集。我认为这是助手非常有帮助的地方，它给你提供了一个初始提示集，然后你可以开始工作……这真的是一个非常非常好的产品，我会经常使用它。”P12，通常需要应对实际工作中数据格式变化的参与者，发现助手在创建一个能够比较提示并标准化不同结构化信息的工作流方面非常有帮助。
- en: 5.2.8\. Interaction patterns with the assistant
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.8\. 与助手的互动模式
- en: We identified three patterns in the process of participants’ usage of the assistant,
    derived from qualitative analysis of the screen-capture recordings of the structured
    task and free exploration time. Many participants (8) made only minimal edits
    to assistant’s solution, tweaking input values but keeping its overall structure.
    This approach was observed mainly during the structured task, with seven participants
    reliant during the task, versus only three in free exploration. Second, we saw
    participants heavily revising the assistant’s solution without changing its structure,
    entirely changing prompts in addition to input data. This approach allowed participants
    to tailor the assistant’s suggestions to better fit their needs while still trusting
    the structure of the assistant’s initial solution. Third, participants amended
    or extended the structure of the assistant’s solution, resulting in more complex
    and customized chains (e.g., P1, P2, P9, and P10). This last approach demonstrates
    a collaborative use of the assistant, where its suggestions are seen as a foundation
    upon which users can add their own creativity and complexity. Note that during
    free exploration, participants P3 and P12 did not use the assistant directly,
    but were inspired by its solution to the second task (e.g., “because the structure
    that is in my mind is kind of similar to the last one done by the assistant” and
    “I already had something in my mind, I started building a chain from an existing
    one”).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在参与者使用助手的过程中识别出了三种模式，这些模式来自于对结构化任务和自由探索时间的屏幕录制记录的定性分析。许多参与者（8人）对助手的解决方案进行了最小的编辑，调整输入值，但保持了其整体结构。这种方式主要出现在结构化任务中，七位参与者在任务中依赖助手，而在自由探索中则只有三位参与者采用这种方式。其次，我们看到一些参与者在不改变助手解决方案结构的情况下进行了大量修改，除了修改输入数据外，还完全改变了提示语。这种方式使参与者能够调整助手的建议，以更好地适应自己的需求，同时仍然信任助手初步解决方案的结构。第三，参与者修改或扩展了助手解决方案的结构，形成了更复杂和定制化的链条（例如P1、P2、P9和P10）。最后这种方式展示了助手的协作性使用，其建议被视为一个基础，用户可以在其上添加自己的创造力和复杂性。需要注意的是，在自由探索期间，参与者P3和P12没有直接使用助手，但从助手在第二个任务中的解决方案中得到了启发（例如，“因为我脑海中的结构与助手上次做的结构有些相似”以及“我已经有了一些想法，我从一个现有的链条开始构建”）。
- en: 5.2.9\. Concerns about assistant bias and influence
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.9\. 关于助手偏见和影响的担忧
- en: 'Some participants expressed concerns that using the assistant influences their
    problem-solving approach, potentially biasing their subsequent tasks. P9 reflected
    on this impact: ”The first task I did was with the ChainBuddy. The second one
    was without, [but] I think because I started off with [it], it kind of taught
    me how to do it.” Two participants noticed that their approach to their ideas
    in the free exploration time mirrored the structure introduced by the assistant.
    P3 said, ”I didn’t use the assistant because the structure that is in my mind
    is kind of similar to the last one done by the assistant,” indicating that the
    assistant’s influence persisted even when not directly used. P12 also described
    how she ”started building a chain from an existing one, and that one is created
    from the second task, which is done by the assistant.” This continuity suggests
    that initial interactions with the assistant could set a pattern that users continue
    to follow, even when trying to work independently. We reflect on this risk further
    in Discussion.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参与者表达了对使用助手可能影响他们解决问题方式的担忧，认为这可能会对他们之后的任务产生偏见。P9反思了这一影响：“我做的第一个任务是用ChainBuddy做的，第二个任务没有用[它]，但我觉得因为我一开始用[它]，它就有点像教我怎么做。”两位参与者注意到，他们在自由探索时间对想法的处理方式与助手引入的结构相似。P3说：“我没有使用助手，因为我脑海中的结构与助手做的最后一个任务结构有点类似”，这表明即使没有直接使用助手，其影响仍然存在。P12也描述了她是如何“从一个现有的链条开始构建，而那个链条来自助手做的第二个任务。”这种延续性表明，最初与助手的互动可能会设置一种模式，即使用户试图独立工作时，也会继续遵循这一模式。我们在讨论中进一步反思了这一风险。
- en: 5.2.10\. Use cases in free exploration time
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.10\. 自由探索时间中的使用案例
- en: 'During the free exploration time, participants explored a diverse range of
    ideas, showcasing creative and varied uses in collaborating with the assistant
    to address specific needs and interests. The diverse range of topics reflected
    a similar diverse range in the study of ChainForge (Arawjo et al., [2024](https://arxiv.org/html/2409.13588v1#bib.bib2)),
    the baseline interface. Participant usage fell into three major categories: comparing
    and exploring different prompts, evaluating behavior across different LLMs, and
    testing LLMs for bias and handling of sensitive topics. The full list of participant
    ideas is listed in Appendix [A](https://arxiv.org/html/2409.13588v1#A1 "Appendix
    A Participant Ideas in Free Exploration ‣ ChainBuddy: An AI Agent System for Generating
    LLM Pipelines").'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '在自由探索时间内，参与者探索了多种不同的想法，展示了在与助手合作解决特定需求和兴趣时的创意和多样化应用。话题的多样性反映了与基准界面ChainForge（Arawjo等人，[2024](https://arxiv.org/html/2409.13588v1#bib.bib2)）的研究中类似的多样性。参与者的使用情况可以分为三大类：比较和探索不同的提示，评估不同LLM（大型语言模型）的行为，以及测试LLM的偏见和敏感话题处理能力。参与者的完整创意列表请见附录[A](https://arxiv.org/html/2409.13588v1#A1
    "Appendix A Participant Ideas in Free Exploration ‣ ChainBuddy: An AI Agent System
    for Generating LLM Pipelines")。'
- en: 5.3\. Limitations
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 限制
- en: 'Our within-subjects usability study had a small sample size and compared to
    a single baseline. It could be that for a different LLM pipeline interface, we
    might have seen different results. We did not restrict users by prior knowledge
    of the baseline interface—it could be that expert ChainForge users would feel
    differently about the assistant’s capabilities. For various constraints common
    to usability studies, we also only examined two tasks that both involved comparing
    across prompts, even though ChainBuddy is capable of more types of tasks and LLM
    pipelines, such as comparing responses across models or setting up data processing
    workflows. An alternate study design might explicitly try three or more very different
    tasks with a larger sample size, to better understand when ChainBuddy is and is
    not useful. We also relied on rough indicators of performance; a more robust evaluation
    might have a team of external raters grade the quality of created flows on a scale.
    Finally, our quantitative findings should also be taken with a grain of salt:
    the complex interaction effects we observed for Ease of Use and Successfulness
    in particular may be due to random noise. Nevertheless, we believe that the body
    of evidence is clear, in that all tests of significance leaned in favor of ChainBuddy,
    and qualitative feedback was overwhelmingly positive. We intend to run a follow-up
    study post-deployment, investigating a broader range of tasks and real-world use
    cases.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的内部可用性研究样本量较小，并且只与单一基准进行了比较。可能对于不同的LLM管道界面，我们会看到不同的结果。我们没有限制用户对基准界面的先验知识——可能经验丰富的ChainForge用户会对助手的能力有不同的看法。由于可用性研究中常见的各种限制，我们仅研究了两个任务，且这两个任务都涉及跨提示的比较，尽管ChainBuddy能够处理更多类型的任务和LLM管道，如比较不同模型的回应或设置数据处理工作流。一个替代的研究设计可能会明确尝试三个或更多非常不同的任务，并且有更大的样本量，以更好地理解ChainBuddy在何时有用，何时无用。我们还依赖于粗略的性能指标；更为严谨的评估可能会让外部评审团队在一个量表上对创建的工作流质量进行评分。最后，我们的定量研究结果也应当谨慎看待：我们观察到的“易用性”和“成功度”之间的复杂交互效应可能是随机噪声的结果。尽管如此，我们相信证据是明确的：所有显著性测试都倾向于支持ChainBuddy，而定性反馈则压倒性地积极。我们计划在部署后进行一项后续研究，调查更广泛的任务和现实世界的使用案例。
- en: 6\. Discussion
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 讨论
- en: Our findings provide evidence in favor of AI-assisted interfaces for generating
    LLM pipelines. Participants found their workload less demanding when using an
    AI assistant’s help in an interface for setting up evaluative LLM pipelines, compared
    to without. And, they were more confident, performant, and able to create automated
    evaluations with greater regularity. In post-interviews, participants appreciated
    how the requirements gathering interaction supported refining their ideas, and
    consistently expressed that they were impressed by the assistant’s capabilities.
    We also observed interaction effects that suggest participants can experience
    lower perceived successfulness and interface ease-of-use when AI assistance is
    taken away from them (mediated by task); a generous interpretation is that people
    miss the assistant’s help in reducing their workload.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究结果为支持 AI 辅助界面生成 LLM 流程提供了证据。与没有使用 AI 助手的界面相比，参与者在使用 AI 助手帮助设置评估性 LLM 流程时，发现他们的工作负载较轻。而且，他们的信心更强，表现更好，并且能够更规律地创建自动化评估。在后续访谈中，参与者表示，需求收集互动帮助他们完善了想法，并一致表示他们对助手的能力印象深刻。我们还观察到一些交互效应，表明当
    AI 助手被移除时（通过任务进行调节），参与者可能会感到他们的成功感和界面的易用性下降；一个宽泛的解释是，人们会在减少工作负载方面错失助手的帮助。
- en: One interesting null result is time. We did not find significant *qualitative*
    evidence that ChainBuddy helped people solve the task faster, as might be expected
    (although participants did express this feeling in post-interviews). However,
    three things to note. First, ChainBuddy takes time to generate flows, on the order
    of 10 seconds or greater. Second, our times are subjective, with a participant-reported
    indication of being “done.” Participants using the assistant spent time revising,
    running or inspecting the generated flows, or clarifying their intent with the
    assistant. Third, qualitative data indicates that some participants felt they
    could go further in their analysis with the assistant, compared to without. So,
    though participants spent around the same time per condition, *what* they spent
    that time on differed.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的零结果是时间。我们没有发现显著的*定性*证据表明 ChainBuddy 帮助人们更快地完成任务，尽管参与者在后续访谈中表达了这种感觉。然而，有三点需要注意。首先，ChainBuddy
    生成流程需要一定时间，大约 10 秒或更长时间。其次，我们的时间是主观的，基于参与者报告的“完成”标志。使用助手的参与者花时间修改、运行或检查生成的流程，或与助手澄清他们的意图。第三，定性数据表明，一些参与者认为他们在有助手的情况下能够进行更深入的分析，而没有助手则无法做到。所以，尽管参与者在每个条件下所花的时间大致相同，*他们花时间做的事情*却有所不同。
- en: More broadly than LLM pipelines, our work contributes to a growing body of literature
    on AI agents integrated into software platforms to assist users in implementing
    ideas (e.g., an agent that creates Powerpoint slides, visualizations from datasets,
    or dynamic widgets (Vaithilingam et al., [2024b](https://arxiv.org/html/2409.13588v1#bib.bib40);
    Beasley and Abouzied, [2024](https://arxiv.org/html/2409.13588v1#bib.bib5); Zheng
    et al., [2022](https://arxiv.org/html/2409.13588v1#bib.bib48))). Our study provides
    evidence for the intuitive hypothesis that users perceive that AI agents improve
    workload by reducing the mental and physical burdens placed on them when interacting
    with software—clicking and dragging, planning what to do. However, our quantitative
    findings indicate that for the most part, users perceived they were just as successful
    *without* the assistant—even when performance analysis suggests overall performance
    plummeted without the assistants’ help. This finding resembles the Dunning–Kruger
    effect (Kruger and Dunning, [1999](https://arxiv.org/html/2409.13588v1#bib.bib23))—that
    people who lack the skill to evaluate the quality of their work in a domain may
    over-estimate its quality—and, combined with worries about being biased by the
    assistant (discussed below), contributes to growing concerns about non-experts’
    over-reliance on AI systems (Buçinca et al., [2021](https://arxiv.org/html/2409.13588v1#bib.bib8);
    Bansal et al., [2021](https://arxiv.org/html/2409.13588v1#bib.bib3)). Future studies
    on software-integrated AI assistants should complement subjective measures with
    more objective evaluations of user performance (e.g., by external raters or as
    here, by quantifiable metrics that serve as indicators of performance).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 比起LLM流水线，我们的工作更广泛地贡献于一个不断增长的文献库，探讨了集成到软件平台中的AI助手，帮助用户实现创意（例如，创建PowerPoint幻灯片、从数据集生成可视化图表，或创建动态小部件的助手（Vaithilingam
    et al., [2024b](https://arxiv.org/html/2409.13588v1#bib.bib40); Beasley和Abouzied,
    [2024](https://arxiv.org/html/2409.13588v1#bib.bib5); Zheng et al., [2022](https://arxiv.org/html/2409.13588v1#bib.bib48)））。我们的研究提供了证据，支持这样一个直觉假设：用户认为AI助手通过减少与软件互动时带来的心理和身体负担（如点击、拖拽、规划操作步骤）来改善工作负荷。然而，我们的定量研究结果表明，在大多数情况下，用户认为即使*没有*助手，他们也能同样成功——即使表现分析表明在没有助手的帮助下，整体表现明显下降。这个发现类似于邓宁-克鲁格效应（Kruger
    and Dunning, [1999](https://arxiv.org/html/2409.13588v1#bib.bib23)）——即缺乏评估自己工作质量能力的人可能会高估其工作质量——而且，加上对被助手偏见影响的担忧（下文讨论），进一步加剧了对非专家过度依赖AI系统的担忧（Buçinca
    et al., [2021](https://arxiv.org/html/2409.13588v1#bib.bib8); Bansal et al., [2021](https://arxiv.org/html/2409.13588v1#bib.bib3)）。未来关于软件集成AI助手的研究应通过更多客观的用户表现评估（例如，由外部评审员进行评估，或如本文所示，通过可量化的表现指标）来补充主观衡量。
- en: 6.1\. Risk of over-reliance on AI assistance for LLM pipeline creation
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 对LLM流水线创建中对AI辅助过度依赖的风险
- en: 'The reader might ask whether and to what extent the user over-relies on, or
    is biased by, the assistant’s solutions. Even if the assistant helps the user
    learn the platform (which some participants indicated), is there a risk of it
    proposing solutions that are subpar or misleading in some way, outside of more
    straightforward usability errors? For instance, imagine a user asks ChainBuddy
    to set up a flow to evaluate LLMs for gender bias. In this task, ChainBuddy usually
    sets up a flow that compares whether the presence of a social identity marker
    (male, female, non-binary) changes the LLM success rate on solving a math problem—a
    common “persona” approach used in benchmarking papers (Cheng et al., [2023](https://arxiv.org/html/2409.13588v1#bib.bib9)).
    While one way to evaluate gender bias, it certainly does not exhaust all possibilities,
    nor does the current assistant help the user “scale up” their analysis, choose
    one solution from alternatives and weigh trade-offs (a learning technique from
    variation theory (Ling Lo, [2012](https://arxiv.org/html/2409.13588v1#bib.bib26))),
    or help them hedge against misinterpretation of random noise. In our study, we
    did see one error case (Fig. [5](https://arxiv.org/html/2409.13588v1#S5.F5 "Figure
    5 ‣ 5.1.5\. Number and Types of Created Nodes ‣ 5.1\. Quantitative results ‣ 5\.
    Findings ‣ ChainBuddy: An AI Agent System for Generating LLM Pipelines")) where
    ChainBuddy constructed a wrong solution that did not compare two prompts. The
    participant was evidently not able to identify and fix the AI’s mistakes. This
    raises the question of how future assistants can help the user learn the interface,
    while mitigating the potential for bias.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '读者可能会问，用户是否过度依赖，或者在多大程度上受到助手解决方案的偏见影响。即使助手帮助用户学习平台（正如一些参与者所表明的），是否有风险它提出的解决方案在某种程度上不如预期或具有误导性，超出了更直接的可用性错误？例如，假设用户要求ChainBuddy设置一个评估LLM性别偏见的流程。在这个任务中，ChainBuddy通常会设置一个流程，比较社会身份标志（男性、女性、非二元性别）的存在是否改变了LLM在解决数学问题时的成功率——这是基准测试论文中常用的“人格”方法（Cheng等人，[2023](https://arxiv.org/html/2409.13588v1#bib.bib9)）。虽然这是评估性别偏见的一种方式，但它显然没有涵盖所有可能性，当前的助手也没有帮助用户“扩大”他们的分析，选择一个解决方案并权衡不同的取舍（变异理论中的学习技巧（Ling
    Lo，[2012](https://arxiv.org/html/2409.13588v1#bib.bib26)）），也没有帮助他们规避随机噪音的误解。在我们的研究中，我们确实看到一个错误案例（图[5](https://arxiv.org/html/2409.13588v1#S5.F5
    "Figure 5 ‣ 5.1.5\. Number and Types of Created Nodes ‣ 5.1\. Quantitative results
    ‣ 5\. Findings ‣ ChainBuddy: An AI Agent System for Generating LLM Pipelines")），ChainBuddy构建了一个错误的解决方案，未能比较两个提示。显然，参与者无法识别并修正AI的错误。这提出了一个问题，未来的助手如何帮助用户学习界面，同时减轻潜在的偏见影响。'
- en: 6.2\. Future Work
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2. 未来工作
- en: 'Our work presents only the starting point for the emerging research area of
    AutoLLMOps: AI assistance for designing and implementing LLM pipelines. We summarize
    potential directions for future work (beyond the obvious one of connecting the
    chatbot to interface documentation).'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作仅仅是新兴研究领域AutoLLMOps的起点：设计和实现LLM管道的AI辅助。我们总结了未来工作的潜在方向（除了将聊天机器人连接到界面文档这一显而易见的方向之外）。
- en: Facilitate importing external data within the chat. The process of intent elicitation
    may involve the user referencing data, such as spreadsheets, internal documents
    or online resources. A future system of ChainBuddy could allow users to import
    their own data or other contextual information directly into the system, say using
    a drag-and-drop interface. By supporting data imports, users can leverage existing
    datasets or relevant context that the agent can, for instance, transform and add
    to a Tabular Data Node.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 促进在聊天中导入外部数据。意图引导过程可能涉及用户引用数据，例如电子表格、内部文档或在线资源。未来的ChainBuddy系统可能允许用户直接将自己的数据或其他上下文信息导入系统，比如通过拖放界面实现。通过支持数据导入，用户可以利用现有的数据集或相关的上下文，代理可以例如将这些数据转化并添加到表格数据节点中。
- en: Support Editing of Existing Chains. Another important enhancement is enabling
    users to edit existing chains. Currently, ChainBuddy supports the creation of
    new chains but lacks the functionality to modify them once created. A few participants
    in our study expressed a desire for editing.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 支持编辑现有链条。另一个重要的改进是使用户能够编辑现有链条。目前，ChainBuddy支持创建新的链条，但一旦创建后，缺乏修改功能。我们的研究中有一些参与者表达了对编辑功能的需求。
- en: Provide User Control Over AI Decision-Making. We may consider providing users
    with more fine-grained control over the decision-making process of the AI agents.
    This involves developing features that allow users to influence and guide the
    agents’ decisions more directly, ensuring that the outcomes align closely with
    their expectations and requirements. For instance, if the user’s intent remains
    vague, a downstream agent handling input data generation may wish to ask the user
    a question to clarify the ambiguity. However, given that some participants felt
    the agent should know when to “stop” eliciting their intent, this may trade-off
    some reduction of user effort for more accurate generation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 提供用户对AI决策过程的控制。我们可以考虑为用户提供更精细的控制权，以便更直接地影响和引导AI代理的决策，确保结果与他们的期望和需求高度一致。例如，如果用户的意图仍然模糊，下游代理处理输入数据生成时可能会向用户提问，以澄清模糊之处。然而，鉴于一些参与者认为代理应该知道何时“停止”引导用户表达意图，这可能会在提高生成准确性的同时减少用户的努力。
- en: Offer a Variety of Suggested Chains. Finally, we plan to increase the variety
    of suggested chains and nodes provided by ChainBuddy. Here, we limited ChainBuddy
    to only a few of the most common nodes in ChainForge, missing nodes like Join
    and Split. By offering a broader range of pre-configured chains and templates,
    users will have more options to choose from, catering to diverse use cases and
    preferences. This variety will help users find more relevant and effective starting
    points for their specific needs, further reducing the ”blank page problem.”
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 提供多样化的建议链条。最后，我们计划增加ChainBuddy提供的建议链条和节点的多样性。在此，我们将ChainBuddy限制为仅包含ChainForge中最常见的一些节点，遗漏了如Join和Split等节点。通过提供更广泛的预配置链条和模板，用户将有更多选择，适应不同的使用场景和偏好。这种多样性将帮助用户为其特定需求找到更相关和有效的起点，进一步减少“空白页问题”。
- en: References
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （1）
- en: 'Arawjo et al. (2024) Ian Arawjo, Chelse Swoopes, Priyan Vaithilingam, Martin
    Wattenberg, and Elena L. Glassman. 2024. ChainForge: A Visual Toolkit for Prompt
    Engineering and LLM Hypothesis Testing. In *Proceedings of the CHI Conference
    on Human Factors in Computing Systems* (Honolulu, HI, USA) *(CHI ’24)*. Association
    for Computing Machinery, New York, NY, USA, Article 304, 18 pages. [https://doi.org/10.1145/3613904.3642016](https://doi.org/10.1145/3613904.3642016)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arawjo等人（2024）Ian Arawjo、Chelse Swoopes、Priyan Vaithilingam、Martin Wattenberg和Elena
    L. Glassman。2024年。《ChainForge：用于提示工程和LLM假设测试的可视化工具包》。发表于*CHI计算机系统中的人类因素会议论文集*（美国夏威夷州檀香山，CHI’24）。纽约：计算机协会（ACM），文章304，18页。[https://doi.org/10.1145/3613904.3642016](https://doi.org/10.1145/3613904.3642016)
- en: Bansal et al. (2021) Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira
    Nushi, Ece Kamar, Marco Tulio Ribeiro, and Daniel Weld. 2021. Does the whole exceed
    its parts? the effect of ai explanations on complementary team performance. In
    *Proceedings of the 2021 CHI conference on human factors in computing systems*.
    1–16.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bansal等人（2021）Gagan Bansal、Tongshuang Wu、Joyce Zhou、Raymond Fok、Besmira Nushi、Ece
    Kamar、Marco Tulio Ribeiro和Daniel Weld。2021年。《整体是否超过其部分？AI解释对互补团队表现的影响》。发表于*2021年CHI计算机系统中的人类因素会议论文集*，1–16。
- en: 'Barbudo et al. (2023) Rafael Barbudo, Sebastián Ventura, and José Raúl Romero.
    2023. Eight years of AutoML: categorisation, review and trends. *Knowledge and
    Information Systems* 65, 12 (2023), 5097–5149.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barbudo等人（2023）Rafael Barbudo、Sebastián Ventura和José Raúl Romero。2023年。《AutoML的八年：分类、综述与趋势》。*知识与信息系统*
    65, 12（2023），5097–5149。
- en: 'Beasley and Abouzied (2024) Cole Beasley and Azza Abouzied. 2024. Pipe (line)
    Dreams: Fully Automated End-to-End Analysis and Visualization. In *Proceedings
    of the 2024 Workshop on Human-In-the-Loop Data Analytics*. 1–7.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beasley和Abouzied（2024）Cole Beasley和Azza Abouzied。2024年。《管道（线）梦想：完全自动化的端到端分析与可视化》。发表于*2024年人类参与数据分析研讨会论文集*，1–7。
- en: 'Boyeau et al. (2024) Pierre Boyeau, Anastasios N Angelopoulos, Nir Yosef, Jitendra
    Malik, and Michael I Jordan. 2024. AutoEval Done Right: Using Synthetic Data for
    Model Evaluation. *arXiv preprint arXiv:2403.07008* (2024).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boyeau等人（2024）Pierre Boyeau、Anastasios N Angelopoulos、Nir Yosef、Jitendra Malik和Michael
    I Jordan。2024年。《AutoEval的正确做法：使用合成数据进行模型评估》。*arXiv预印本arXiv:2403.07008*（2024）。
- en: 'Brooke (1996) J Brooke. 1996. SUS: A quick and dirty usability scale. *Usability
    Evaluation in INdustry/Taylor and Francis* (1996).'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brooke（1996）J Brooke。1996年。《SUS：一种快速且简单的可用性量表》。发表于*工业/泰勒与弗朗西斯的可用性评估*（1996）。
- en: 'Buçinca et al. (2021) Zana Buçinca, Maja Barbara Malaya, and Krzysztof Z Gajos.
    2021. To trust or to think: cognitive forcing functions can reduce overreliance
    on AI in AI-assisted decision-making. *Proceedings of the ACM on Human-Computer
    Interaction* 5, CSCW1 (2021), 1–21.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Buçinca et al. (2021) Zana Buçinca, Maja Barbara Malaya, 和 Krzysztof Z Gajos.
    2021. 信任还是思考：认知强制函数可以减少在AI辅助决策中的过度依赖。*ACM人机交互会议论文集* 5, CSCW1 (2021), 1–21。
- en: 'Cheng et al. (2023) Myra Cheng, Esin Durmus, and Dan Jurafsky. 2023. Marked
    Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*. 1504–1532.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. (2023) Myra Cheng, Esin Durmus, 和 Dan Jurafsky. 2023. 标记化人物：使用自然语言提示来衡量语言模型中的刻板印象。In
    *第61届计算语言学协会年会论文集（第一卷：长篇论文）*。1504–1532。
- en: 'CrewAI (2024) CrewAI. 2024. CrewAI: AI Agents for real use cases. [https://www.crewai.com](https://www.crewai.com)
    Accessed: 2024-09-08.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CrewAI (2024) CrewAI. 2024. CrewAI：用于真实用例的AI代理。[https://www.crewai.com](https://www.crewai.com)
    访问时间：2024-09-08。
- en: et al. (2023) Harrison Chase et al. 2023. LangChain. [https://pypi.org/project/langchain/](https://pypi.org/project/langchain/).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: et al. (2023) Harrison Chase 等人。2023. LangChain。[https://pypi.org/project/langchain/](https://pypi.org/project/langchain/)。
- en: 'Feurer et al. (2022) Matthias Feurer, Katharina Eggensperger, Stefan Falkner,
    Marius Lindauer, and Frank Hutter. 2022. Auto-sklearn 2.0: Hands-free automl via
    meta-learning. *Journal of Machine Learning Research* 23, 261 (2022), 1–61.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feurer et al. (2022) Matthias Feurer, Katharina Eggensperger, Stefan Falkner,
    Marius Lindauer, 和 Frank Hutter. 2022. Auto-sklearn 2.0：通过元学习实现免手动Automl。*机器学习研究期刊*
    23, 261 (2022)，1–61。
- en: 'Flowise AI (2024) Flowise AI. 2024. Flowise AI: Visual Toolkit for Prompt Engineering.
    [https://flowiseai.com/](https://flowiseai.com/)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flowise AI (2024) Flowise AI. 2024. Flowise AI：用于提示工程的可视化工具包。[https://flowiseai.com/](https://flowiseai.com/)
- en: Gandhi et al. (2024) Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang
    Wu, and Graham Neubig. 2024. Better Synthetic Data by Retrieving and Transforming
    Existing Datasets. *arXiv preprint arXiv:2404.14361* (2024).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gandhi et al. (2024) Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang
    Wu, 和 Graham Neubig. 2024. 通过检索和转换现有数据集来生成更好的合成数据。*arXiv预印本arXiv:2404.14361*（2024）。
- en: Guardrails (2023) Guardrails 2023. Guardrails AI. https://github.com/guardrails-ai/guardrails.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guardrails (2023) Guardrails 2023. Guardrails AI. https://github.com/guardrails-ai/guardrails。
- en: 'Hart (1988) SG Hart. 1988. Development of NASA-TLX (Task Load Index): Results
    of empirical and theoretical research. *Human mental workload/Elsevier* (1988).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hart (1988) SG Hart. 1988. NASA-TLX（任务负荷指数）的发展：经验和理论研究结果。*人类心理负荷/Elsevier*（1988）。
- en: 'Heffetz et al. (2020) Yuval Heffetz, Roman Vainshtein, Gilad Katz, and Lior
    Rokach. 2020. Deepline: Automl tool for pipelines generation using deep reinforcement
    learning and hierarchical actions filtering. In *Proceedings of the 26th ACM SIGKDD
    international conference on knowledge discovery & data mining*. 2103–2113.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heffetz et al. (2020) Yuval Heffetz, Roman Vainshtein, Gilad Katz, 和 Lior Rokach.
    2020. Deepline：使用深度强化学习和层次化动作过滤生成管道的Automl工具。In *第26届ACM SIGKDD国际知识发现与数据挖掘会议论文集*。2103–2113。
- en: Instructor (2023) Instructor 2023. Instructor, Generating Structure from LLMs.
    https://jxnl.github.io/instructor/.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Instructor (2023) Instructor 2023. Instructor，生成LLM的结构。https://jxnl.github.io/instructor/。
- en: 'Jiang et al. (2022) Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina,
    Aaron Donsbach, Michael Terry, and Carrie J Cai. 2022. PromptMaker: Prompt-based
    Prototyping with Large Language Models. In *Extended Abstracts of the 2022 CHI
    Conference on Human Factors in Computing Systems* (New Orleans, LA, USA) *(CHI
    EA ’22)*. Association for Computing Machinery, New York, NY, USA, Article 35,
    8 pages. [https://doi.org/10.1145/3491101.3503564](https://doi.org/10.1145/3491101.3503564)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiang et al. (2022) Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina,
    Aaron Donsbach, Michael Terry, and Carrie J Cai. 2022. PromptMaker: 基于提示的大型语言模型原型设计。In
    *2022年CHI会议扩展摘要*（美国新奥尔良，路易斯安那州）*(CHI EA ’22)*。计算机协会，纽约，纽约，美国，第35篇，8页。[https://doi.org/10.1145/3491101.3503564](https://doi.org/10.1145/3491101.3503564)'
- en: 'Kahng et al. (2024) Minsuk Kahng, Ian Tenney, Mahima Pushkarna, Michael Xieyang
    Liu, James Wexler, Emily Reif, Krystal Kallarackal, Minsuk Chang, Michael Terry,
    and Lucas Dixon. 2024. LLM comparator: Visual analytics for side-by-side evaluation
    of large language models. In *Extended Abstracts of the CHI Conference on Human
    Factors in Computing Systems*. 1–7.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kahng et al. (2024) Minsuk Kahng, Ian Tenney, Mahima Pushkarna, Michael Xieyang
    Liu, James Wexler, Emily Reif, Krystal Kallarackal, Minsuk Chang, Michael Terry,
    and Lucas Dixon. 2024. LLM comparator: Visual analytics for side-by-side evaluation
    of large language models. In *计算机系统中的人因CHI会议扩展摘要*。1–7。'
- en: 'Khattab et al. (2023) Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan
    Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T
    Joshi, Hanna Moazam, et al. 2023. Dspy: Compiling declarative language model calls
    into self-improving pipelines. *arXiv preprint arXiv:2310.03714* (2023).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khattab 等 (2023) Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang,
    Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T Joshi,
    Hanna Moazam, 等. 2023. 《Dspy：将声明性语言模型调用编译成自我改进的管道》. *arXiv 预印本 arXiv:2310.03714*
    (2023)。
- en: 'Kim et al. (2024) Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, and Juho
    Kim. 2024. Evallm: Interactive evaluation of large language model prompts on user-defined
    criteria. In *Proceedings of the CHI Conference on Human Factors in Computing
    Systems*. 1–21.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 等 (2024) Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, 和 Juho Kim.
    2024. 《Evallm：基于用户定义标准的交互式大语言模型评估》. 在 *CHI 计算机系统中的人类因素会议论文集* 中，1-21 页。
- en: 'Kruger and Dunning (1999) Justin Kruger and David Dunning. 1999. Unskilled
    and unaware of it: how difficulties in recognizing one’s own incompetence lead
    to inflated self-assessments. *Journal of personality and social psychology* 77,
    6 (1999), 1121.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kruger 和 Dunning (1999) Justin Kruger 和 David Dunning. 1999. 《无能却不自知：难以识别自身无能如何导致过度自评》
    *人格与社会心理学期刊* 77, 6 (1999), 1121。
- en: 'Kuznetsova et al. (2017) Alexandra Kuznetsova, Per B Brockhoff, and Rune Haubo Bojesen
    Christensen. 2017. lmerTest package: tests in linear mixed effects models. *Journal
    of statistical software* 82, 13 (2017).'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuznetsova 等 (2017) Alexandra Kuznetsova, Per B Brockhoff, 和 Rune Haubo Bojesen
    Christensen. 2017. 《lmerTest 包：线性混合效应模型的检验》. *统计软件期刊* 82, 13 (2017)。
- en: 'LangChain AI (2024) LangChain AI. 2024. LangGraph: Documentation. [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)
    Accessed: 2024-07-19.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain AI (2024) LangChain AI. 2024. LangGraph：文档. [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)
    访问日期：2024-07-19。
- en: 'Ling Lo (2012) Mun Ling Lo. 2012. *Variation theory and the improvement of
    teaching and learning*. Göteborg: Acta Universitatis Gothoburgensis.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ling Lo (2012) Mun Ling Lo. 2012. *变异理论与教学和学习的改进*。哥德堡：哥德堡大学出版社。
- en: Logspace (2023) Logspace. 2023. LangFlow. [https://www.langflow.org/](https://www.langflow.org/).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Logspace (2023) Logspace. 2023. LangFlow. [https://www.langflow.org/](https://www.langflow.org/)。
- en: Luke (2017) Steven G Luke. 2017. Evaluating significance in linear mixed-effects
    models in R. *Behavior research methods* 49 (2017), 1494–1502.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luke (2017) Steven G Luke. 2017. 《在 R 中评估线性混合效应模型的显著性》. *行为研究方法* 49 (2017),
    1494–1502。
- en: 'Ma et al. (2024) Xiao Ma, Swaroop Mishra, Ariel Liu, Sophie Ying Su, Jilin
    Chen, Chinmay Kulkarni, Heng-Tze Cheng, Quoc Le, and Ed Chi. 2024. Beyond chatbots:
    ExploreLLM for structured thoughts and personalized model responses. In *Extended
    Abstracts of the CHI Conference on Human Factors in Computing Systems*. 1–12.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ma 等 (2024) Xiao Ma, Swaroop Mishra, Ariel Liu, Sophie Ying Su, Jilin Chen,
    Chinmay Kulkarni, Heng-Tze Cheng, Quoc Le, 和 Ed Chi. 2024. 《超越聊天机器人：ExploreLLM
    以结构化思维和个性化模型响应为特色》. 在 *CHI 计算机系统中的人类因素扩展摘要* 中，1-12 页。
- en: 'Nakajima (2024) Yohei Nakajima. 2024. BabyAGI: An AI Agent That Can Achieve
    Goals and Execute Tasks. [https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nakajima (2024) Yohei Nakajima. 2024. 《BabyAGI：一个能够实现目标并执行任务的 AI 代理》. [https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)
- en: Sánchez Cuadrado et al. (2024) Jesús Sánchez Cuadrado, Sara Pérez-Soler, Esther
    Guerra, and Juan De Lara. 2024. Automating the Development of Task-oriented LLM-based
    Chatbots. In *Proceedings of the 6th ACM Conference on Conversational User Interfaces*.
    1–10.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sánchez Cuadrado 等 (2024) Jesús Sánchez Cuadrado, Sara Pérez-Soler, Esther Guerra,
    和 Juan De Lara. 2024. 《自动化开发面向任务的基于大语言模型的聊天机器人》. 在 *第六届 ACM 会话用户界面会议论文集* 中，1-10
    页。
- en: 'Shaikh et al. (2024) Omar Shaikh, Michelle Lam, Joey Hejna, Yijia Shao, Michael
    Bernstein, and Diyi Yang. 2024. Show, Don’t Tell: Aligning Language Models with
    Demonstrated Feedback. *arXiv preprint arXiv:2406.00888* (2024).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shaikh 等 (2024) Omar Shaikh, Michelle Lam, Joey Hejna, Yijia Shao, Michael Bernstein,
    和 Diyi Yang. 2024. 《展示，非告知：将语言模型与演示反馈对齐》. *arXiv 预印本 arXiv:2406.00888* (2024)。
- en: 'Shankar et al. (2024a) Shreya Shankar, Haotian Li, Parth Asawa, Madelon Hulsebos,
    Yiming Lin, JD Zamfirescu-Pereira, Harrison Chase, Will Fu-Hinthorn, Aditya G
    Parameswaran, and Eugene Wu. 2024a. SPADE: Synthesizing Assertions for Large Language
    Model Pipelines. *arXiv preprint arXiv:2401.03038* (2024).'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shankar 等 (2024a) Shreya Shankar, Haotian Li, Parth Asawa, Madelon Hulsebos,
    Yiming Lin, JD Zamfirescu-Pereira, Harrison Chase, Will Fu-Hinthorn, Aditya G
    Parameswaran, 和 Eugene Wu. 2024a. 《SPADE：为大语言模型管道合成断言》. *arXiv 预印本 arXiv:2401.03038*
    (2024)。
- en: Shankar et al. (2024b) Shreya Shankar, JD Zamfirescu-Pereira, Björn Hartmann,
    Aditya G Parameswaran, and Ian Arawjo. 2024b. Who Validates the Validators? Aligning
    LLM-Assisted Evaluation of LLM Outputs with Human Preferences. *arXiv preprint
    arXiv:2404.12272* (2024).
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shankar 等人（2024b）Shreya Shankar, JD Zamfirescu-Pereira, Björn Hartmann, Aditya
    G Parameswaran, 和 Ian Arawjo. 2024b. 谁来验证验证者？将 LLM 辅助评估与人类偏好对齐. *arXiv 预印本 arXiv:2404.12272*（2024）。
- en: 'Singhvi et al. (2023) Arnav Singhvi, Manish Shetty, Shangyin Tan, Christopher
    Potts, Koushik Sen, Matei Zaharia, and Omar Khattab. 2023. DSPy Assertions: Computational
    Constraints for Self-Refining Language Model Pipelines. *arXiv preprint arXiv:2312.13382*
    (2023).'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Singhvi 等人（2023）Arnav Singhvi, Manish Shetty, Shangyin Tan, Christopher Potts,
    Koushik Sen, Matei Zaharia, 和 Omar Khattab. 2023. DSPy Assertions: 自我精炼语言模型管道的计算约束.
    *arXiv 预印本 arXiv:2312.13382*（2023）。'
- en: 'Suzgun and Kalai (2024) Mirac Suzgun and Adam Tauman Kalai. 2024. Meta-prompting:
    Enhancing language models with task-agnostic scaffolding. *arXiv preprint arXiv:2401.12954*
    (2024).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Suzgun 和 Kalai（2024）Mirac Suzgun 和 Adam Tauman Kalai. 2024. Meta-prompting:
    通过任务无关的脚手架增强语言模型. *arXiv 预印本 arXiv:2401.12954*（2024）。'
- en: 'Synaptic Labs (2024) Synaptic Labs. 2024. Professor Synapse. [https://github.com/ProfSynapse/Synapse_CoR](https://github.com/ProfSynapse/Synapse_CoR)
    Accessed: 2024-06-20.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Synaptic Labs（2024）Synaptic Labs. 2024. Professor Synapse. [https://github.com/ProfSynapse/Synapse_CoR](https://github.com/ProfSynapse/Synapse_CoR)
    访问时间：2024-06-20。
- en: 'Tan et al. (2024) Xin Tan, Yimin Jiang, Yitao Yang, and Hong Xu. 2024. Teola:
    Towards End-to-End Optimization of LLM-based Applications. *arXiv preprint arXiv:2407.00326*
    (2024).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tan 等人（2024）Xin Tan, Yimin Jiang, Yitao Yang, 和 Hong Xu. 2024. Teola: 面向 LLM
    基于应用的端到端优化. *arXiv 预印本 arXiv:2407.00326*（2024）。'
- en: 'Vaithilingam et al. (2024a) Priyan Vaithilingam, Ian Arawjo, and Elena L Glassman.
    2024a. Imagining a future of designing with ai: Dynamic grounding, constructive
    negotiation, and sustainable motivation. In *Proceedings of the 2024 ACM Designing
    Interactive Systems Conference*. 289–300.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaithilingam 等人（2024a）Priyan Vaithilingam, Ian Arawjo, 和 Elena L Glassman. 2024a.
    想象未来的 AI 设计：动态扎根、建设性谈判和可持续激励. 载于 *2024 ACM 设计交互系统会议论文集*. 289–300。
- en: 'Vaithilingam et al. (2024b) Priyan Vaithilingam, Elena L Glassman, Jeevana Priya
    Inala, and Chenglong Wang. 2024b. DynaVis: Dynamically Synthesized UI Widgets
    for Visualization Editing. In *Proceedings of the CHI Conference on Human Factors
    in Computing Systems*. 1–17.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaithilingam 等人（2024b）Priyan Vaithilingam, Elena L Glassman, Jeevana Priya Inala,
    和 Chenglong Wang. 2024b. DynaVis：用于可视化编辑的动态合成 UI 小部件. 载于 *CHI 计算机系统人因学会议论文集*.
    1–17。
- en: 'Wang et al. (2023) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. 2023. Plan-and-Solve Prompting: Improving Zero-Shot
    Chain-of-Thought Reasoning by Large Language Models. In *Annual Meeting of the
    Association for Computational Linguistics*. [https://api.semanticscholar.org/CorpusID:258558102](https://api.semanticscholar.org/CorpusID:258558102)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023）Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei
    Lee, 和 Ee-Peng Lim. 2023. Plan-and-Solve 提示：通过大型语言模型改进零-shot 思维链推理. 载于 *计算语言学会年会*。[https://api.semanticscholar.org/CorpusID:258558102](https://api.semanticscholar.org/CorpusID:258558102)
- en: 'Webster (2023) Ian Webster. 2023. promptfoo: Test your prompts. [https://www.promptfoo.dev/](https://www.promptfoo.dev/).'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Webster（2023）Ian Webster. 2023. promptfoo: 测试你的提示. [https://www.promptfoo.dev/](https://www.promptfoo.dev/)。'
- en: 'Wolf et al. (2017) Marty J Wolf, K Miller, and Frances S Grodzinsky. 2017.
    Why we should have seen that coming: comments on Microsoft’s tay” experiment,”
    and wider implications. *Acm Sigcas Computers and Society* 47, 3 (2017), 54–64.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf 等人（2017）Marty J Wolf, K Miller, 和 Frances S Grodzinsky. 2017. 为什么我们应该早就预见到这一点：对微软“tay”实验及其广泛影响的评论.
    *Acm Sigcas 计算机与社会* 47, 3（2017），54–64。
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. *arXiv preprint
    arXiv:2308.08155* (2023).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人（2023）Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang,
    Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, 和 Chi Wang. 2023. Autogen: 通过多代理对话框架支持下一代
    LLM 应用. *arXiv 预印本 arXiv:2308.08155*（2023）。'
- en: 'Wu et al. (2022a) Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra
    Molina, Michael Terry, and Carrie J Cai. 2022a. Promptchainer: Chaining large
    language model prompts through visual programming. In *CHI Conference on Human
    Factors in Computing Systems Extended Abstracts*. 1–10.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人（2022a）Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra
    Molina, Michael Terry, 和 Carrie J Cai. 2022a. Promptchainer: 通过视觉编程链接大型语言模型的提示.
    载于 *CHI 计算机系统人因学会议扩展摘要*. 1–10。'
- en: 'Wu et al. (2022b) Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b.
    AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large
    Language Model Prompts. In *Proceedings of the 2022 CHI Conference on Human Factors
    in Computing Systems* (New Orleans, LA, USA) *(CHI ’22)*. Association for Computing
    Machinery, New York, NY, USA, Article 385, 22 pages. [https://doi.org/10.1145/3491102.3517582](https://doi.org/10.1145/3491102.3517582)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2022b）Tongshuang Wu, Michael Terry 和 Carrie Jun Cai. 2022b. AI链：通过链式大型语言模型提示实现透明且可控的人机交互。在
    *2022年计算机系统人机交互会议论文集*（美国路易斯安那州新奥尔良）（*CHI '22*）。计算机协会，纽约，NY，USA，第385号文章，22页。 [https://doi.org/10.1145/3491102.3517582](https://doi.org/10.1145/3491102.3517582)
- en: 'Zamfirescu-Pereira et al. (2023) J.D. Zamfirescu-Pereira, Richmond Y. Wong,
    Bjoern Hartmann, and Qian Yang. 2023. Why Johnny Can’t Prompt: How Non-AI Experts
    Try (and Fail) to Design LLM Prompts. In *Proceedings of the 2023 CHI Conference
    on Human Factors in Computing Systems* (Hamburg, Germany) *(CHI ’23)*. Association
    for Computing Machinery, New York, NY, USA, Article 437, 21 pages. [https://doi.org/10.1145/3544548.3581388](https://doi.org/10.1145/3544548.3581388)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zamfirescu-Pereira 等人（2023年）J.D. Zamfirescu-Pereira, Richmond Y. Wong, Bjoern
    Hartmann 和 Qian Yang. 2023年. 为什么 Johnny 不能进行提示：非AI专家如何（并且失败）设计LLM提示。在 *2023年计算机系统人机交互会议论文集*（德国汉堡）（*CHI
    '23*）。计算机协会，纽约，NY，USA，第437号文章，21页。 [https://doi.org/10.1145/3544548.3581388](https://doi.org/10.1145/3544548.3581388)
- en: 'Zheng et al. (2022) Chengbo Zheng, Dakuo Wang, April Yi Wang, and Xiaojuan
    Ma. 2022. Telling stories from computational notebooks: AI-assisted presentation
    slides creation for presenting data science work. In *Proceedings of the 2022
    CHI Conference on Human Factors in Computing Systems*. 1–20.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人（2022年）Chengbo Zheng, Dakuo Wang, April Yi Wang 和 Xiaojuan Ma. 2022年.
    从计算笔记本讲故事：AI辅助的数据科学工作展示幻灯片制作。在 *2022年计算机系统人机交互会议论文集*。1–20。
- en: Appendix A Participant Ideas in Free Exploration
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 自由探索中的参与者想法
- en: For the curiosity of readers, here we list the ideas that each participant explored
    using the assistant in free exploration time.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足读者的好奇心，这里列出了每个参与者在自由探索时间内使用助手探索的想法。
- en: P1.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P1.
- en: Compared different LLMs’ abilities to translate JavaScript code into Python
    while ensuring both code validity and functional equivalence.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 比较了不同LLM在确保代码有效性和功能等价的同时，将JavaScript代码转换为Python的能力。
- en: P2.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P2.
- en: Evaluated different LLMs’ reasoning abilities by testing their responses to
    various math questions.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过测试LLM对各种数学问题的回答，评估了不同LLM的推理能力。
- en: P3.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P3.
- en: Explored generating SPARQL queries from natural language inputs related to music
    data.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 探索了如何根据与音乐数据相关的自然语言输入生成SPARQL查询。
- en: P4.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P4.
- en: Tested LLMs’ responses to questions about local dishes served during Konkan
    marriages to see if LLMs’ response in a very specific cultural topics.
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试了LLM对关于Konkan婚礼期间当地菜肴的提问的回应，查看LLM在非常具体的文化话题中的反应。
- en: P5.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P5.
- en: Tested how LLMs respond to sensitive topics like reincarnation through storytelling
    prompts.
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试了LLM如何通过讲故事提示回应关于转世等敏感话题。
- en: P6.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P6.
- en: compared how different LLMs generate the context if asked to compare incomes
    for various doctor specialties, including dentists for 2024.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 比较了不同大型语言模型（LLM）在被要求比较各类医生专业收入时的上下文生成方式，包括2024年的牙医收入。
- en: P7.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P7.
- en: Examined MBTI personality test results from different LLMs.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 检查了不同LLM的MBTI性格测试结果。
- en: P8.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P8.
- en: Compared prompts to assess business risks based on current news events.
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 比较了基于当前新闻事件评估商业风险的提示。
- en: P9.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P9.
- en: Explored prompts of structuring a conference panel discussion.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 探索了结构化会议小组讨论的提示。
- en: P10.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P10.
- en: Compared prompts to create a productive weekly schedule incorporating tasks
    and personal goals.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 比较了创建包含任务和个人目标的高效每周计划的提示。
- en: P11.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P11.
- en: Tested LLMs’ responses to potentially harmful queries, exploring how phrasing
    could bypass content restrictions (jail-breaking).
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试了LLM对潜在有害查询的回应，探索了如何通过措辞绕过内容限制（破解）。
- en: P12.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P12.
- en: Developed a workflow to standardize data entries from a range of inconsistent
    formats into a uniform JSON structure.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开发了一个工作流程，将来自各种不一致格式的数据条目标准化为统一的JSON结构。
