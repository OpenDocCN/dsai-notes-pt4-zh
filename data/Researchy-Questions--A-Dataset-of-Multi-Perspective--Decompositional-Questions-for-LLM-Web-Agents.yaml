- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:49:46'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:49:46
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Researchy Questions：一个面向LLM Web代理的多角度、分解性问题数据集
- en: 来源：[https://arxiv.org/html/2402.17896/](https://arxiv.org/html/2402.17896/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2402.17896/](https://arxiv.org/html/2402.17896/)
- en: Corby Rosset
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Corby Rosset
- en: Microsoft
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft
- en: \AndHo-Lam Chung
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \AndHo-Lam Chung
- en: National Taiwan Univ.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 国立台湾大学
- en: \AndGuanghui Qin
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \AndGuanghui Qin
- en: Johns Hopkins Univ.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰霍普金斯大学
- en: \AndEthan C. Chau
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \AndEthan C. Chau
- en: Microsoft
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft
- en: \ANDZhuo Feng
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \ANDZhuo Feng
- en: Microsoft
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft
- en: \AndAhmed Awadallah
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \AndAhmed Awadallah
- en: Microsoft
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft
- en: \AndJennifer Neville
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: \AndJennifer Neville
- en: Microsoft
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft
- en: \AndNikhil Rao
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \AndNikhil Rao
- en: Microsoft
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft
- en: Abstract
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Existing question answering (QA) datasets are no longer challenging to most
    powerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA,
    NaturalQuestions, ELI5 and HotpotQA mainly study “known unknowns” with clear indications
    of both what information is missing, and how to find it to answer the question.
    Hence, good performance on these benchmarks provides a false sense of security.
    A yet unmet need of the NLP community is a bank of non-factoid, multi-perspective
    questions involving a great deal of unclear information needs, i.e. “unknown uknowns”.
    We claim we can find such questions in search engine logs, which is surprising
    because most question-intent queries are indeed factoid. We present Researchy
    Questions, a dataset of search engine queries tediously filtered to be non-factoid,
    “decompositional” and multi-perspective. We show that users spend a lot of “effort”
    on these questions in terms of signals like clicks and session length, and that
    they are also challenging for GPT-4. We also show that “slow thinking” answering
    techniques, like decomposition into sub-questions shows benefit over answering
    directly. We release¹¹1[https://huggingface.co/datasets/corbyrosset/researchy_questions](https://huggingface.co/datasets/corbyrosset/researchy_questions)
    $\sim$ 100k Researchy Questions, along with the Clueweb22 URLs that were clicked.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的问答（QA）数据集对大多数强大的大型语言模型（LLMs）来说已不再具有挑战性。传统的QA基准，如TriviaQA、NaturalQuestions、ELI5和HotpotQA，主要研究“已知的未知”问题，明确指示了缺失的信息以及如何找到这些信息以回答问题。因此，在这些基准上的良好表现提供了一种虚假的安全感。自然语言处理（NLP）社区目前未被满足的需求是一个包含大量不明确信息需求的非事实性、多角度问题的数据库，即“未知的未知”。我们声称可以在搜索引擎日志中找到这些问题，这一点令人惊讶，因为大多数问题意图查询确实是事实性问题。我们提出了Researchy
    Questions，一个通过繁琐的筛选过程得到的非事实性、”分解性“且多角度的搜索引擎查询数据集。我们展示了用户在这些问题上花费了大量的“精力”，如点击量和会话时长等信号，且这些问题对GPT-4也具有挑战性。我们还展示了“慢思考”回答技术，如分解为子问题，相较于直接回答更具优势。我们发布了约10万个Researchy
    Questions数据集，并附上了用户点击的Clueweb22网址。[https://huggingface.co/datasets/corbyrosset/researchy_questions](https://huggingface.co/datasets/corbyrosset/researchy_questions)
- en: 1 Introduction
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '| Dataset | Num. | Topics | Sub-Ques. | Sub-Query |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 数量 | 话题 | 子问题 | 子查询 |'
- en: '| Hotpot QA | 300 | 2.9 | 3.8 | 3.6 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Hotpot QA | 300 | 2.9 | 3.8 | 3.6 |'
- en: '| OpenBook QA | 300 | 3.8 | 6.3 | 5.9 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| OpenBook QA | 300 | 3.8 | 6.3 | 5.9 |'
- en: '| Strategy QA | 300 | 3.8 | 5.3 | 4.9 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Strategy QA | 300 | 3.8 | 5.3 | 4.9 |'
- en: '| Truthful QA | 300 | 3.8 | 6.4 | 6.0 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Truthful QA | 300 | 3.8 | 6.4 | 6.0 |'
- en: '| Aquamuse | 300 | 3.7 | 5.4 | 5.2 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Aquamuse | 300 | 3.7 | 5.4 | 5.2 |'
- en: '| Reddit/askh | 300 | 4.9 | 9.4 | 8.5 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/askh | 300 | 4.9 | 9.4 | 8.5 |'
- en: '| Reddit/asks | 300 | 5.1 | 9.2 | 8.8 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/asks | 300 | 5.1 | 9.2 | 8.8 |'
- en: '| Reddit/eli5 | 300 | 4.5 | 9.7 | 9.3 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/eli5 | 300 | 4.5 | 9.7 | 9.3 |'
- en: '| Stack Exchange | 300 | 6.1 | 8.4 | 7.6 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Stack Exchange | 300 | 6.1 | 8.4 | 7.6 |'
- en: '| Wikihow | 300 | 4.8 | 11.7 | 11.2 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Wikihow | 300 | 4.8 | 11.7 | 11.2 |'
- en: '| Researchy | 96k | 3.9 | 14.3 | 12.6 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Researchy | 96k | 3.9 | 14.3 | 12.6 |'
- en: 'Table 1: We asked GPT-4 to decompose questions into a natural hierachy of subquestions,
    as well as concrete queries it would issue to a search engine. As expected, HotpotQA
    requires the fewest sub-questions to answer.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：我们要求GPT-4将问题分解成一个自然的子问题层级，并给出它将向搜索引擎发出的具体查询。如预期所示，HotpotQA回答所需的子问题最少。
- en: 'The advent of Large Language Models (LLMs) has ushered in a new era for the
    field natural language processing, with short- and long- form question-answering
    (QA) at the forefront of recent achievements OpenAI et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib39)).
    Historically, QA benchmarks served as the crucible for evaluating a model’s grasp
    of natural language understanding. However, LLMs have nearly perfected many QA
    datasets, particularly those involving answering short, factual questions like
    *“What is the capital of Brunei?"*. The re-emergence of chatbots and “agentic”
    AI assistants, which represent complex systems based on LLMs as a building block,
    have led to new opportunities for users to ask deeper, more nuanced questions
    as shown in Figure [1](https://arxiv.org/html/2402.17896v1#S1.F1 "Figure 1 ‣ 1
    Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents").'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '大型语言模型（LLMs）的出现为自然语言处理领域带来了新时代，其中短期和长期的问答（QA）处于近期成就的前沿，OpenAI等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib39)）也在其中扮演了重要角色。从历史上看，QA基准一直是评估模型理解自然语言能力的熔炉。然而，LLMs几乎已经完美地解决了许多QA数据集，尤其是那些涉及回答简短事实性问题的，如*“文莱的首都是什么？”*。聊天机器人和“代理型”AI助手的重新崛起，代表了基于LLMs构建的复杂系统，已为用户提出更深入、更有层次的问题创造了新机会，如图[1](https://arxiv.org/html/2402.17896v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")所示。'
- en: '![Refer to caption](img/61341f94b3126ceb9f1a9d3626809354.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/61341f94b3126ceb9f1a9d3626809354.png)'
- en: 'Figure 1: Qualitative comparison of how Researchy Questions differs from other
    Question Answering datasets. Researchy Questions involve a greater deal of complexity
    and “unknown unknowns” than other QA datasets.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：Researchy Questions与其他问答数据集的定性比较。Researchy Questions涉及比其他QA数据集更多的复杂性和“未知的未知”。
- en: However, the capabilities of powerful AI-assisted QA tools has outpaced the
    metrics needed to evaluate them. A number of traditional QA benchmarks like Natural
    Questions Kwiatkowski et al. ([2019](https://arxiv.org/html/2402.17896v1#bib.bib31)),
    TriviaQA Joshi et al. ([2017](https://arxiv.org/html/2402.17896v1#bib.bib23)),
    WebQuestions Berant et al. ([2013](https://arxiv.org/html/2402.17896v1#bib.bib4)),
    SearchQA Dunn et al. ([2017](https://arxiv.org/html/2402.17896v1#bib.bib12)) have
    been more or less solved by modern LLMs. These datasets consist primarily of factoid
    questions (from search engine logs, Trivia, Jeopardy!, etc), where answers are
    typically found within a single sentence or paragraph that almost certainly exist
    in standard pre-training web corpora Zhou et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib65)).
    For instance, MS Marco  Campos et al. ([2016](https://arxiv.org/html/2402.17896v1#bib.bib9))
    is up to 55% factoid questions (Bolotova et al., [2022](https://arxiv.org/html/2402.17896v1#bib.bib5)).
    The obvious drawback to these kinds of QA datasets is that the answers can be
    memorized by LLMs or solved with simple pattern-matching or keyword-based search.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，强大的AI辅助问答工具的能力已经超出了评估它们所需的指标。许多传统的QA基准，如Natural Questions Kwiatkowski等人（[2019](https://arxiv.org/html/2402.17896v1#bib.bib31)）、TriviaQA
    Joshi等人（[2017](https://arxiv.org/html/2402.17896v1#bib.bib23)）、WebQuestions Berant等人（[2013](https://arxiv.org/html/2402.17896v1#bib.bib4)）、SearchQA
    Dunn等人（[2017](https://arxiv.org/html/2402.17896v1#bib.bib12)）等，已经或多或少被现代LLMs解决。这些数据集主要由事实性问题（如搜索引擎日志、Trivia、Jeopardy!等）构成，其中答案通常可以在单一的句子或段落中找到，这些句子或段落几乎肯定存在于标准的预训练网络语料库中，Zhou等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib65)）。例如，MS
    Marco Campos等人（[2016](https://arxiv.org/html/2402.17896v1#bib.bib9)）中有多达55%的问题是事实性问题（Bolotova等人，[2022](https://arxiv.org/html/2402.17896v1#bib.bib5)）。这类QA数据集的明显缺点是答案可以被LLMs记住，或者通过简单的模式匹配或基于关键词的搜索解决。
- en: Multi-hop reasoning tasks including HotpotQA Yang et al. ([2018](https://arxiv.org/html/2402.17896v1#bib.bib56)),
    HybridQA Chen et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib10)),
    MuSiQue Trivedi et al. ([2022](https://arxiv.org/html/2402.17896v1#bib.bib49))
    aim to challenge QA systems to logically bridge information across multiple documents
    or paragraphs. While these datasets have made strides in increasing question complexity,
    the answers are still ultimately factoid, and it’s clear what sub-questions ought
    to be asked to recall the missing information. Furthermore, the construction of
    these datasets (e.g. synthetically generated from paths of wikipedia links) leads
    to a distribution mismatch w.r.t questions humans ask.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 包括 HotpotQA Yang 等人（[2018](https://arxiv.org/html/2402.17896v1#bib.bib56)）、HybridQA
    Chen 等人（[2020](https://arxiv.org/html/2402.17896v1#bib.bib10)）、MuSiQue Trivedi
    等人（[2022](https://arxiv.org/html/2402.17896v1#bib.bib49)）在内的多跳推理任务，旨在挑战 QA 系统，通过多个文档或段落之间的逻辑桥接来解决问题。尽管这些数据集在增加问题复杂度方面取得了进展，但答案仍然是事实性问题，而且清楚地知道应该提出哪些子问题来回忆缺失的信息。此外，这些数据集的构建（例如，通过维基百科链接路径合成生成）导致了与人类提问方式之间的分布不匹配。
- en: There exist several sources of long-form, non-factoid QA datasets like ELI5 Fan
    et al. ([2019](https://arxiv.org/html/2402.17896v1#bib.bib14)), Stack Exchange,
    Yahoo Answers Zhang et al. ([2016](https://arxiv.org/html/2402.17896v1#bib.bib61)),
    and WikiHowQA Bolotova-Baranova et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib6)).
    While answers to these questions are more involved than factoid questions, ELI5
    and WikiHowQA elicit more expository answers than analytical ones. The Oxford
    Allsouls dataset Liu et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib35))
    contains 1k college-level essay prompts which are multi-perspective, but are designed
    to evaluate persuasive writing skills and do not have associated documents to
    ground responses. AQuaMuSe Kulkarni et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib30))
    is an excellent attempt at filtering Natural Questions (NQ) for multi-faceted
    queries, but their method was constrained by relying on the relatively short paragraph-length
    answers already present in NQ.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多个长期、非事实性 QA 数据集来源，例如 ELI5 Fan 等人（[2019](https://arxiv.org/html/2402.17896v1#bib.bib14)）、Stack
    Exchange、Yahoo Answers Zhang 等人（[2016](https://arxiv.org/html/2402.17896v1#bib.bib61)）和
    WikiHowQA Bolotova-Baranova 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib6)）。尽管这些问题的答案比事实性问题更为复杂，但
    ELI5 和 WikiHowQA 更倾向于引出叙述性回答，而非分析性回答。牛津大学 Allsouls 数据集 Liu 等人（[2023b](https://arxiv.org/html/2402.17896v1#bib.bib35)）包含
    1000 个大学水平的论文题目，这些题目具有多角度性，但旨在评估说服写作技巧，并且没有关联的文档来支撑回答。AQuaMuSe Kulkarni 等人（[2020](https://arxiv.org/html/2402.17896v1#bib.bib30)）是一个非常优秀的尝试，旨在过滤
    Natural Questions (NQ) 中的多面性查询，但他们的方法受限于依赖 NQ 中已有的相对较短的段落式回答。
- en: '| Researchy Question: how does public transport help the economy |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 研究问题：公共交通如何帮助经济 |'
- en: '| --- |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Hierarchical Decomposition of the Question | Clicked Clueweb22 URLs |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 问题的层次化分解 | 点击的 Clueweb22 URL |'
- en: '| 1. What is public transport? (a) What are the different types of public transport?
    (b) How many people use public transport in different regions or countries? 2.
    What are the direct economic benefits of public transport? (a) How public transport
    reduces costs for users e.g. fuel, parking, maintenance, etc.? (b) How does public
    transport generate revenue… 3. What are the indirect economic benefits of public
    transport? (a) How does public transport reduce congestion… (b) How does public
    transport increase access to education, employment, health, … (c) How does public
    transport enhance productivity and innovation… (d) How does public transport contribute
    to environmental and social goals… 4. How do the economic benefits of public transport
    compare to the costs of providing and maintaining public transport? (a) What are
    the main costs of public transport… (b) How are the costs of public transport
    financed… (c) How are the benefits and costs of public transport measured and
    evaluated… | 1. [infrastructureusa.org](https://infrastructureusa.org/the-economic-impact-of-public-transportation)
    2. [nationalgeographic.org](https://nationalgeographic.org/article/effects-transportation-economy)
    3. [quora.com](https://quora.com/how-does-public-transportation-help-the-economy)
    4. [accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    5. [ced.berkeley.edu](https://frameworks.ced.berkeley.edu/2014/the-economic-benefits-of-transit-service)
    6. [greenertransportsolutions](https://greenertransportsolutions.com/guidance-tool/relationship-between-transport-economy)
    7. [bts.gov](https://bts.gov/topics/transportation-and-economy) 8. [apta.com](https://apta.com/research-technical-resources/economic-impact-of-public-transit)
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 1. 什么是公共交通？（a）公共交通的不同类型有哪些？（b）在不同地区或国家，多少人使用公共交通？ 2. 公共交通的直接经济效益有哪些？（a）公共交通如何减少用户成本，例如燃料、停车、维护等？（b）公共交通如何创造收入…
    3. 公共交通的间接经济效益有哪些？（a）公共交通如何减少拥堵…（b）公共交通如何增加对教育、就业、健康等的接触…（c）公共交通如何提高生产力和创新…（d）公共交通如何为环境和社会目标做出贡献…
    4. 公共交通的经济效益与提供和维护公共交通的成本相比如何？（a）公共交通的主要成本是什么…（b）公共交通的成本如何融资…（c）如何衡量和评估公共交通的效益与成本…
    | 1. [infrastructureusa.org](https://infrastructureusa.org/the-economic-impact-of-public-transportation)
    2. [nationalgeographic.org](https://nationalgeographic.org/article/effects-transportation-economy)
    3. [quora.com](https://quora.com/how-does-public-transportation-help-the-economy)
    4. [accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    5. [ced.berkeley.edu](https://frameworks.ced.berkeley.edu/2014/the-economic-benefits-of-transit-service)
    6. [greenertransportsolutions](https://greenertransportsolutions.com/guidance-tool/relationship-between-transport-economy)
    7. [bts.gov](https://bts.gov/topics/transportation-and-economy) 8. [apta.com](https://apta.com/research-technical-resources/economic-impact-of-public-transit)
    |'
- en: '| Example of a Pivotal Fact from URL: [accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    “…Even in cities with a high concentration of office space in the [central business
    district], we estimate that increasing transit ridership by 10 percent will increase
    office rents by no more than 0.5 percent. For all other cities, we estimate that
    increasing transit ridership will have no effect on office rents…” |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 来自URL的关键事实示例：[accessmagazine.org](https://accessmagazine.org/spring-2012/can-public-transportation-increase-economic-efficiency)
    “…即使在商业区高密度办公空间的城市，我们估计将公交乘客数增加10%，也仅会使办公租金最多增加0.5%。对于所有其他城市，我们估计增加公交乘客数不会对办公租金产生影响…”
    |'
- en: 'Table 2: An example Researchy Question, how GPT-4 decomposed it into sub-questions
    (closed-book), as well the URLs in ClueWeb22 that real users clicked on, and an
    example of a Pivotal Fact from one of those URLs.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：一个研究问题的示例，展示了GPT-4如何将其分解为子问题（闭卷），以及ClueWeb22中真实用户点击的URL，和其中一个URL的关键事实示例。
- en: The rise of “LLM Agents” e.g.  Wu et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib54))
    have opened the door for even deeper collaboration between users, LLMs, and tools.
    In response, more recent datasets have focused on completing challenging tasks
    in open-ended environments with tools like a web browser, file system, database,
    etc.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: “LLM代理”（例如吴等人，[2023b](https://arxiv.org/html/2402.17896v1#bib.bib54)）的兴起为用户、LLM和工具之间更深入的协作打开了大门。对此，近年来的数据集集中在使用像网页浏览器、文件系统、数据库等工具，在开放式环境中完成挑战性任务。
- en: In particular, Gaia Mialon et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib37))
    tests understanding of multi-modal inputs (images and text), as well as complex
    reasoning across levels of difficulty to solve. AgentBench Liu et al. ([2023c](https://arxiv.org/html/2402.17896v1#bib.bib36))
    provides closed environments for an LLM to interact with APIs in various scenarios,
    including coding (interacting with file systems or databases), games/puzzles,
    and web browsing/shopping. While these datasets advance the field of metrics for
    LLM agents, they are small, consisting of only 466 and 1,091 questions respectively
    that were hand-curated by the authors.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，Gaia Mialon et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib37))
    测试了对多模态输入（图像和文本）的理解，以及跨难度层次进行复杂推理来解决问题的能力。AgentBench Liu et al. ([2023c](https://arxiv.org/html/2402.17896v1#bib.bib36))
    提供了一个封闭环境，供 LLM 在各种场景中与 API 互动，包括编码（与文件系统或数据库的交互）、游戏/谜题，以及网页浏览/购物。尽管这些数据集推动了 LLM
    代理的度量领域的发展，但它们很小，分别只有 466 和 1,091 个问题，这些问题是由作者手工策划的。
- en: 'The need for more challenging QA datasets also stems from some alarming trends:
    while there are hundreds of public LLMs, they are pretrained on only a handful
    existing corpora Gao et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib15));
    Raffel et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib44)), or distilled
    from one of a few teacher LLMs Peng et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib41)).
    Furthermore, much more data scraped from the internet for training is itself going
    to be AI-generated content, leading to an echo-chamber effect Dohmatob et al.
    ([2024](https://arxiv.org/html/2402.17896v1#bib.bib11)); Wu et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib53)).
    Hence, the convergent evolution Stayton ([2015](https://arxiv.org/html/2402.17896v1#bib.bib47))
    of LLMs increases the risk that they will not recognize that they don’t know something,
    e.g. see GPT-4 and Mixtral 8x7b in Table [10](https://arxiv.org/html/2402.17896v1#A1.T10
    "Table 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). This is especially true when LLMs act in the capacity
    of LLM-as-a-judge Zheng et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib63));
    Yuan et al. ([2024](https://arxiv.org/html/2402.17896v1#bib.bib59)), or when faced
    with very multi-faceted/multi-perspective questions, where the consequences could
    be that users “miss the whole picture” or worse, are misled Zheng et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib64));
    Liu et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib35)). While retrieval-augmentation Lewis
    et al. ([2021](https://arxiv.org/html/2402.17896v1#bib.bib32)); Borgeaud et al.
    ([2022](https://arxiv.org/html/2402.17896v1#bib.bib7)); Guu et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib17))
    can help complement LLM agents, the risk is merely shifted to whether a sub-system
    retrieves the right information and uses it correctly Liu et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib34)).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '对于更具挑战性的 QA 数据集的需求，也源自一些令人担忧的趋势：虽然有数百种公共的 LLM，它们仅在少数现有语料库上进行了预训练 Gao et al.
    ([2020](https://arxiv.org/html/2402.17896v1#bib.bib15)); Raffel et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib44))，或从少数几个教师
    LLM 中提炼而来 Peng et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib41))。此外，用于训练的更多数据来源于互联网上抓取的内容，而这些内容本身将是
    AI 生成的，导致回音室效应 Dohmatob et al. ([2024](https://arxiv.org/html/2402.17896v1#bib.bib11));
    Wu et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib53))。因此，LLM 的趋同演化 Stayton
    ([2015](https://arxiv.org/html/2402.17896v1#bib.bib47)) 增加了它们无法识别自己不知道某些事情的风险，例如见表[10](https://arxiv.org/html/2402.17896v1#A1.T10
    "Table 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")中的 GPT-4 和 Mixtral 8x7b。当 LLM 扮演 LLM 作为裁判的角色时，尤其如此 Zheng
    et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib63)); Yuan et al. ([2024](https://arxiv.org/html/2402.17896v1#bib.bib59))，或者当面对非常多面/多视角的问题时，其后果可能是用户“错失全貌”或更糟，受到误导 Zheng
    et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib64)); Liu et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib35))。尽管检索增强 Lewis
    et al. ([2021](https://arxiv.org/html/2402.17896v1#bib.bib32)); Borgeaud et al.
    ([2022](https://arxiv.org/html/2402.17896v1#bib.bib7)); Guu et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib17))
    可以帮助补充 LLM 代理，但风险仅仅转移到了子系统是否检索到正确信息并正确使用它的问题上 Liu et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib34))。'
- en: We believe the well-studied phenomenon of “unknown unknowns” United States Congress
    et al. ([1981](https://arxiv.org/html/2402.17896v1#bib.bib51)) applies to LLM
    Agents in scenarios addressing complex questions requiring “slow thinking” Kahneman
    ([2011](https://arxiv.org/html/2402.17896v1#bib.bib24)). Simply put, one strategy
    is to iteratively re-frame or decompose the problem into a set of “known unknowns”
    (which characterize most of the aforementioned QA datasets). For these sub-problems,
    it should be clearer what information is missing, how to find it, and once found,
    how the “known known” contributes to the final answer. Several techniques such
    as chain-of-thought question decomposition Radhakrishnan et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib43))
    and tree-of-thought Yao et al. ([2023a](https://arxiv.org/html/2402.17896v1#bib.bib57))
    prompting take a similar approach to plan long-horizon solutions to complex problems.
    However, those studies still operate over traditional QA benchmarks like HotpotQA,
    or over simple games like crossword puzzles. Hence, the right benchmark of questions
    for these advanced decomposition techniques still does not exist for open-domain
    web scenarios Krishna et al. ([2021](https://arxiv.org/html/2402.17896v1#bib.bib29)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为“未知的未知”这一现象，美国国会等人（[1981](https://arxiv.org/html/2402.17896v1#bib.bib51)）同样适用于在解决复杂问题时需要“慢思考”的LLM代理（Kahneman，
    [2011](https://arxiv.org/html/2402.17896v1#bib.bib24)）。简而言之，一种策略是通过迭代地重新构建或分解问题，将其转化为一组“已知的未知”（这类问题特征正是大多数前述QA数据集的特点）。对于这些子问题，应该能更清楚地了解缺失了哪些信息，如何寻找这些信息，一旦找到，如何利用“已知的已知”来贡献最终答案。一些技术，例如链式思考问题分解（Radhakrishnan等，[2023](https://arxiv.org/html/2402.17896v1#bib.bib43)）和思维树（Yao等，[2023a](https://arxiv.org/html/2402.17896v1#bib.bib57)）提示，采用类似的方法来规划应对复杂问题的长期解决方案。然而，这些研究仍然基于传统的QA基准，例如HotpotQA，或是简单的游戏，比如填字游戏。因此，目前还没有合适的基准问题，用于检验这些先进的分解技术在开放领域网络场景中的应用（Krishna等，[2021](https://arxiv.org/html/2402.17896v1#bib.bib29)）。
- en: 'We present Researchy Questions to study the dynamics of how LLM agents handle
    unclear information needs associated with very complex questions. We define a
    Researchy Question as a *non-factoid* question that expects a *long-form answer*
    (longer than a paragraph!) entailing substantial research or effort to synthesize.
    A Researchy Question can be instantiated as a complex search task Aula and Russell
    ([2008](https://arxiv.org/html/2402.17896v1#bib.bib2)) with unclear information
    needs that requires analyzing *multiple documents* or pieces of evidence. A Researchy
    Question does not have a single correct answer, but rather *multiple perspectives*
    allowing a dense manifold of answers over which varying criteria can determine
    which is better. In practice, the act of answering a Researchy Question probably
    involves *decomposition* into sub-questions that aid the retrieval of comprehensive
    information, reducing the risk of missing unknown unknowns. Lastly, a Researchy
    Question represents a *genuine information need* that real people asked. Figure [1](https://arxiv.org/html/2402.17896v1#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") qualitatively compares other canonical
    QA datasets.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '我们提出了Researchy Questions，旨在研究LLM代理在处理与复杂问题相关的不明确信息需求时的动态。我们将Researchy Question定义为一种*非事实型*问题，期望得到*长篇回答*（超过一段！），需要进行大量研究或努力进行综合。Researchy
    Question可以被看作是一个复杂的搜索任务（Aula和Russell，[2008](https://arxiv.org/html/2402.17896v1#bib.bib2)），其信息需求不明确，且需要分析*多个文档*或证据片段。Researchy
    Question没有单一的正确答案，而是*多个视角*，允许根据不同的标准来判断哪个答案更好。实际上，回答Researchy Question的过程可能涉及*分解*成有助于检索全面信息的子问题，从而减少遗漏未知未知的风险。最后，Researchy
    Question代表了人们真实提出的*真正信息需求*。图[1](https://arxiv.org/html/2402.17896v1#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")定性地比较了其他经典QA数据集。'
- en: Researchy Questions is primarily a QA dataset to evaluate question answering
    systems or LLM Agents with the ultimate goal of achieving ever higher-quality
    answers using any tools necessary. Notwithstanding, it is also a search/retrieval
    dataset in the sense that finding and correctly incorporating the right evidence
    is a critical sub-system to meet expectations of trustworthiness and groundedness Zheng
    et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib64)); Liu et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib35)).
    While we believe that question decomposition is a critical piece of solving Researchy
    Questions , it is unclear how to define or measure the quality of sub-questions.
    To aid this endeavor, we reveal what URLs end users found useful, with the hope
    that good sub-questions will at least lead to the information found in those clicked
    documents.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Researchy Questions主要是一个问答数据集，用于评估问答系统或大语言模型代理，最终目标是利用任何必要的工具实现更高质量的答案。尽管如此，它也是一个搜索/检索数据集，因为找到并正确地结合相关证据是一个关键子系统，能够满足可信度和扎实性的期望（Zheng
    et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib64))；Liu et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib35))）。虽然我们认为问题分解是解决Researchy
    Questions的一个关键部分，但目前尚不清楚如何定义或衡量子问题的质量。为帮助这一努力，我们揭示了终端用户认为有用的网址，期望好的子问题至少能引导到那些被点击的文档中的信息。
- en: 'We release about 96K Researchy Questions consisting of real users’ queries
    to a commercial search engine, and additionally:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发布了大约96K个Researchy Questions，包括真实用户向商业搜索引擎提交的查询，并且还：
- en: '1.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'The decomposition of the question into a 2-level hierarchical plan (See Table [2](https://arxiv.org/html/2402.17896v1#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") Left).'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '将问题分解为一个2级的层级计划（见表[2](https://arxiv.org/html/2402.17896v1#S1.T2 "Table 2 ‣
    1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") 左侧）。'
- en: '2.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: For each question, the user-aggregated click distribution over URLs in a publicly
    available web corpus, ClueWeb22.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于每个问题，用户在一个公开可用的网络语料库ClueWeb22上的点击分布汇总。
- en: '3.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Ordered list of sub-queries corresponding roughly to the sub-questions that
    can be readily issued to a search engine
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对应于可以直接向搜索引擎发出的子问题的有序子查询列表。
- en: 'In Section [2](https://arxiv.org/html/2402.17896v1#S2 "2 Researchy Questions
    Construction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") we describe how Researchy Questions were obtained
    and then characterize them in Section [3](https://arxiv.org/html/2402.17896v1#S3
    "3 Characterizing Researchy Questions ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents"). In Section [4](https://arxiv.org/html/2402.17896v1#S4
    "4 Agreement with User Search Behavior ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") we verify that web users expend
    more effort on Researchy Questions over other queries. In Section [5](https://arxiv.org/html/2402.17896v1#S5
    "5 Evaluating Answer Techniques to Researchy Questions ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    we evaluate and compare decompositional answering techniques from Radhakrishnan
    et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib43)).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '在第[2](https://arxiv.org/html/2402.17896v1#S2 "2 Researchy Questions Construction
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents")节中，我们描述了Researchy Questions的获取方式，并在第[3](https://arxiv.org/html/2402.17896v1#S3
    "3 Characterizing Researchy Questions ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")节中对其进行了特征描述。在第[4](https://arxiv.org/html/2402.17896v1#S4
    "4 Agreement with User Search Behavior ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")节中，我们验证了网络用户在Researchy Questions上投入的精力多于其他查询。在第[5](https://arxiv.org/html/2402.17896v1#S5
    "5 Evaluating Answer Techniques to Researchy Questions ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")节中，我们评估并比较了Radhakrishnan等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib43)）的分解式回答技术。'
- en: 2 Researchy Questions Construction
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 Researchy Questions构建
- en: '| First | MS Marco | QnA | Non-factoid | Researchy ($\downarrow$) |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| First | MS Marco | QnA | 非事实型 | Researchy ($\downarrow$) |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| how | 17.0% | 34.3% | 29.4% | 41.2% |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| how | 17.0% | 34.3% | 29.4% | 41.2% |'
- en: '| why | 1.64% | 6.26% | 33.4% | 22.9% |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| why | 1.64% | 6.26% | 33.4% | 22.9% |'
- en: '| what | 34.9% | 12.2% | 21.3% | 19.1% |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| what | 34.9% | 12.2% | 21.3% | 19.1% |'
- en: '| is/are/do | 5.77% | 15.0% | 6.50% | 9.67% |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| is/are/do | 5.77% | 15.0% | 6.50% | 9.67% |'
- en: '| should | 0.11% | 0.53% | 0.59% | 1.85% |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| should | 0.11% | 0.53% | 0.59% | 1.85% |'
- en: '| can | 1.84% | 4.31% | 1.01% | 0.97% |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| can | 1.84% | 4.31% | 1.01% | 0.97% |'
- en: '| who | 3.27% | 4.77% | 0.90% | 0.47% |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 谁 | 3.27% | 4.77% | 0.90% | 0.47% |'
- en: '| which | 1.78% | 2.78% | 1.87% | 0.46% |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 哪个 | 1.78% | 2.78% | 1.87% | 0.46% |'
- en: '| when | 2.70% | 5.03% | 0.44% | 0.43% |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 何时 | 2.70% | 5.03% | 0.44% | 0.43% |'
- en: '| pros | $<$ 0.01% | 0.03% | 0.45% | 0.28% |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 优势 | $<$ 0.01% | 0.03% | 0.45% | 0.28% |'
- en: '| explain | 0.05% | 0.06% | 0.12% | 0.23% |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 解释 | 0.05% | 0.06% | 0.12% | 0.23% |'
- en: '| where | 3.54% | 4.08% | 0.37% | 0.17% |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 其中 | 3.54% | 4.08% | 0.37% | 0.17% |'
- en: '| factors | $<$ 0.01% | 0.01% | 0.08% | 0.15% |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 因素 | $<$ 0.01% | 0.01% | 0.08% | 0.15% |'
- en: '| will | 0.10% | 0.69% | 0.08% | 0.15% |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 将 | 0.10% | 0.69% | 0.08% | 0.15% |'
- en: '| describe | 0.05% | 0.07% | 0.04% | 0.09% |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 描述 | 0.05% | 0.07% | 0.04% | 0.09% |'
- en: 'Table 3: Top most-prevalent first-words of the three main stages of our question
    filtering funnel (with MS Marco for comparison).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：我们问题过滤漏斗的三个主要阶段中最常见的首词（以 MS Marco 为比较）。
- en: Researchy Questions are real user queries from search logs. While search logs
    have a rich diversity of query types and intents Bolotova et al. ([2022](https://arxiv.org/html/2402.17896v1#bib.bib5));
    Bu et al. ([2010](https://arxiv.org/html/2402.17896v1#bib.bib8)), they mostly
    contain factoid or navigational queries, which need to be filtered.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 研究型问题是来自搜索日志的真实用户查询。虽然搜索日志包含了丰富多样的查询类型和意图 Bolotova 等人 ([2022](https://arxiv.org/html/2402.17896v1#bib.bib5));
    Bu 等人 ([2010](https://arxiv.org/html/2402.17896v1#bib.bib8))，但它们大多包含事实性或导航型查询，需要进行过滤。
- en: '2.1 Stage 1: Mining Search Logs'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 阶段 1：挖掘搜索日志
- en: '| Query Type | Count |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 查询类型 | 数量 |'
- en: '&#124; Avg. unique &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均独特 &#124;'
- en: '&#124; clicked urls &#124;'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击的 URL &#124;'
- en: '|'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Avg. &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均 &#124;'
- en: '&#124; clicks &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击量 &#124;'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Avg. sat. &#124;'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 平均饱和度 &#124;'
- en: '&#124; clicks &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击量 &#124;'
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| General Queries | $\geq 1B$ | 1.88 | 4.83 | 2.54 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 一般查询 | $\geq 1B$ | 1.88 | 4.83 | 2.54 |'
- en: '| QnA Queries | 15.7M | 3.99 | 9.31 | 5.10 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 问答查询 | 15.7M | 3.99 | 9.31 | 5.10 |'
- en: '| Non-factoid QnA | 1.0M | 4.20 | 8.99 | 4.86 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 非事实型问答 | 1.0M | 4.20 | 8.99 | 4.86 |'
- en: '| Researchy Queries | 100k | 6.31 | 15.85 | 8.54 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 研究型查询 | 100k | 6.31 | 15.85 | 8.54 |'
- en: '| Session Type | Count | # Turns |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 会话类型 | 数量 | 回合数 |'
- en: '&#124; # unique. &#124;'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; # 独特 &#124;'
- en: '&#124; queries &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 查询 &#124;'
- en: '|'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; # sat &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; # 饱和度 &#124;'
- en: '&#124; clicks &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 点击量 &#124;'
- en: '|'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| General Sessions | $\geq 10B$ | 2.42 | 2.11 | 0.76 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 一般会话 | $\geq 10B$ | 2.42 | 2.11 | 0.76 |'
- en: '| QnA Sessions | $\geq 100M$ | 6.28 | 5.53 | 1.15 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 问答会话 | $\geq 100M$ | 6.28 | 5.53 | 1.15 |'
- en: '| N.F. QnA Sessions | $\geq 10M$ | 12.89 | 11.33 | 1.91 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 非事实型问答会话 | $\geq 10M$ | 12.89 | 11.33 | 1.91 |'
- en: '| Researchy Sessions | $\geq 1M$ | 13.45 | 11.81 | 2.46 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 研究型会话 | $\geq 1M$ | 13.45 | 11.81 | 2.46 |'
- en: 'Table 4: Our query filtering funnel; each row is a subset from the row above
    it. (Left) Researchy Questions have much more clicks (Sat clicks have longer dwelltime),
    and require more unique documents; the full distribution is in Figure [2](https://arxiv.org/html/2402.17896v1#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    (Right) Search statistics per session in which each type of query appeared, indicating
    that harder questions appear in longer sessions. These behaviors confirm our filtering
    yields more complex questions.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：我们的查询过滤漏斗；每一行都是上一行的一个子集。（左）研究型问题有更多的点击（饱和度点击的停留时间更长），并且需要更多的独特文档；完整的分布见图[2](https://arxiv.org/html/2402.17896v1#A1.F2
    "图 2 ‣ 附录 A 基于 GPT-4 的过滤细节 ‣ 研究型问题：一种多视角、分解性问题的数据集，用于 LLM 网络代理")。（右）每个类型查询出现的会话统计数据，表明更难的问题出现在较长的会话中。这些行为确认了我们的过滤器产生了更复杂的问题。
- en: We obtained a set of query-url click pairs from a commercial search engine that
    were logged between July 2021 and August 2022, which maximally overlaps with the
    creation of the Clueweb22 snapshot of web documents Overwijk et al. ([2022](https://arxiv.org/html/2402.17896v1#bib.bib40)).
    This way, we can simply indicate which Researchy Questions clicked on which documents.
    We began with a large sample of english, non-adult queries that had least one
    click. We denote these as “General Queries”, which were further filtered.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个商业搜索引擎获取了一组查询-URL 点击对，这些记录是在 2021 年 7 月到 2022 年 8 月之间的，最大限度地与 Clueweb22
    网络文档快照的创建重叠 Overwijk 等人 ([2022](https://arxiv.org/html/2402.17896v1#bib.bib40))。通过这种方式，我们可以简单地指明哪些研究型问题点击了哪些文档。我们首先从大量英语、非成人查询中获取，这些查询至少有一次点击。我们将这些称为“一般查询”，并对其进行了进一步过滤。
- en: 'An important filtering criteria is frequency: we kept queries if they were
    issued at least 50 times in the logs. This criteria is simple but powerful: it
    helps denoise the dataset (reduces spelling errors), and also allows us to focus
    on questions that are not “one-offs”. This helps us glean insights into repeated
    user behaviors as they interact with the search engine.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的过滤标准是频率：我们只保留在日志中至少出现过50次的查询。这个标准既简单又强大：它有助于去除数据中的噪音（减少拼写错误），同时让我们专注于那些不是“偶然出现”的问题。这帮助我们获取有关用户与搜索引擎互动时的重复行为的洞察。
- en: 'In order to select queries which are answer-seeking intent (i.e. actual “questions”
    as distinct from navigational queries like “facebook login”, shopping intent like
    “fast running shoes”, or local intent like “best pizza near me”), we used a suite
    of rules and existing production classifiers:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择那些具有寻求答案意图的查询（即实际的“问题”，而非像“facebook 登录”这样的导航查询，“快速跑步鞋”这样的购物意图，或“附近最好披萨”这样的本地意图），我们使用了一套规则和现有的生产分类器：
- en: •
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Query Language: English'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 查询语言：英语
- en: •
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Adult intent: False'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成人意图：假
- en: •
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Distinct Occurrences: $\geq$ 50'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不同出现次数：$\geq$ 50
- en: •
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '3 $\leq$ Number of Query Words: $\leq$ 15'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3 $\leq$ 查询词数：$\leq$ 15
- en: •
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of Distinct URLs Clicked On: $\geq 2$'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击的不同URL数量：$\geq$ 2
- en: •
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Question Intent Classifier: True'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题意图分类器：真
- en: •
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Navigational Intent: False'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导航意图：假
- en: •
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Local / Real Estate / Map Intent: False'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本地/房地产/地图意图：假
- en: •
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Retail/Shopping Intent: False'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 零售/购物意图：假
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Coding/Technical Intent: False'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编程/技术意图：假
- en: •
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Health/Medical Intent: False'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 健康/医疗意图：假
- en: •
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Triggered Possible Answer Cards: $\geq 1$'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 触发的可能答案卡：$\geq$ 1
- en: •
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Triggered lots of Ads: False'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 触发大量广告：假
- en: 'To explain some of the points above: an Answer Card is a high-precision feature
    in a search engine where a paragraph containing the answer is shown at the top
    of the results page, distinct from the “ten blue links”. Because search engines
    are constantly being updated with new features and triggering rules, all the above
    statistics are aggregated and normalized over the full year period. For instance,
    “a lot of Ads” is determined by summing the total number of ads shown for the
    query over the full year and dividing by the number of times the query was issued,
    and then picking a threshold above which queries seemed “shopping intent”. The
    Ads requirement also helped catch any shopping intent queries missed by the Retail
    intent classifier.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 解释以上某些点：答案卡是搜索引擎中的一个高精度特性，其中包含答案的段落显示在结果页面的顶部，区别于“十个蓝色链接”。由于搜索引擎不断更新新功能和触发规则，所有上述统计数据都是在全年的时间段内汇总和标准化的。例如，“大量广告”是通过将查询在整年中显示的广告总数相加，然后除以查询被发出的次数，再选择一个阈值，超过该阈值的查询被认为是“购物意图”。广告要求还帮助捕捉到零售意图分类器未能捕捉到的任何购物意图查询。
- en: We wanted to remove Coding/Technical queries because such questions are often
    motivated by very specific problems that are often solved by one piece of documentation
    after lots of clicking around, which is not the behavior we wish to target in
    this dataset. Health and medical questions are avoided largely because they often
    overlap too much with those that ought to be addressed by a licensed medical professional.
    Many shopping / retail queries could be construed as “researchy” e.g. “what are
    the best headphones”, but we avoid them in this dataset because it is hard to
    distinguish whether a URL was clicked due to aggressive advertising or a real
    information need.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望删除编程/技术类查询，因为这些问题通常是由非常具体的问题驱动的，这些问题通常通过大量点击后的一份文档得到解决，而这不是我们希望在这个数据集中关注的行为。健康和医疗类问题主要被避免，因为它们往往与应由持证医务人员处理的问题重叠过多。许多购物/零售类查询可能被解读为“研究性”问题，例如“最好的耳机是什么”，但我们在这个数据集中避免了这些问题，因为很难区分一个URL点击是由于激进广告的原因还是出于真正的信息需求。
- en: After this stage of filtering, we arrived at 15.7M “QnA Queries” which are largely
    recognizable as natural language questions that deal with open-domain knowledge.
    This size was manageable enough to efficiently run our own bert-large scale classifiers
    we use in the next stage of filtering.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过滤阶段后，我们得到了1570万个“问答查询”，这些查询大多可以识别为处理开放领域知识的自然语言问题。这个数据量足够管理，可以有效地运行我们在下一个过滤阶段使用的自己的bert-large规模分类器。
- en: '2.2 Stage 2: Factoid Classifier'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 第二阶段：事实型分类器
- en: 'We needed a way to distinguish which QnA Queries were factoid vs. non-factoid;
    we trained a binary classifier on auto-labeled data for this purpose. The training
    data was a uniform sample of 200k questions from the 15.7M QnA Queries. Labels
    for the questions were collected from gpt3 (text-davinci-003) prompted with few-shot
    examples as shown in Figure [4](https://arxiv.org/html/2402.17896v1#A1.F4 "Figure
    4 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents"). The labels
    were then used to train a bert-large non-factoid question classifier, which was
    then inferenced on the full set of 15.7M queries. By manual inspection, a threshold
    was chosen above which we were satisfied that the questions were meaningfully
    non-factoid. The resulting 1.0M met the non-factoid threshold of 0.75 as shown
    on the left hand side of Figure [3](https://arxiv.org/html/2402.17896v1#A1.F3
    "Figure 3 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents"),
    which we denote as ”Non-factoid QnA Queries”.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一种方法来区分哪些QnA查询是事实型（factoid）与非事实型（non-factoid）；为此我们训练了一个二分类器，使用自动标注的数据。训练数据是从1570万个QnA查询中均匀抽取的20万个问题样本。问题的标签是通过gpt3（text-davinci-003）在少量示例提示下生成的，如图[4](https://arxiv.org/html/2402.17896v1#A1.F4
    "图4 ‣ 附录A 基于GPT-4的筛选细节 ‣ 研究性问题：多视角、分解式问题的数据集")所示。然后这些标签被用来训练一个bert-large非事实型问题分类器，之后在1570万个查询的完整数据集上进行推断。通过人工检查，选择了一个阈值，超过该阈值的我们认为问题是有意义的非事实型。最终的100万条数据符合图[3](https://arxiv.org/html/2402.17896v1#A1.F3
    "图3 ‣ 附录A 基于GPT-4的筛选细节 ‣ 研究性问题：多视角、分解式问题的数据集")左侧所示的非事实型阈值0.75，我们将其称为“非事实型QnA查询”。
- en: '2.3 Stage 3: Decompositional Classifier'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 阶段3：分解式分类器
- en: 'Not all the resulting non-factoid QnA queries exhibited the “decompositional”
    information needs. Namely, they often looked expository or “how-to” with generally
    one correct answer which did not have many perspectives. We trained a second classifier
    to score the extent to which a question requires asking sub-questions. The specific
    definition of “requiring sub-questions” is described in a prompt in Figure [5](https://arxiv.org/html/2402.17896v1#A1.F5
    "Figure 5 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") given
    to ChatGPT (gpt-35-turbo) to collect labels. We used ChatGPT because we figured
    this was a relatively intense cognitive task. We inferenced ChatGPT on about 40k
    outputs from the non-factoid classifier that met the non-factoid threshold of
    0.75\. We used the labels to train a separate bert-large “decompositional” classifier.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 不是所有结果中的非事实型QnA查询都展现了“分解式”信息需求。具体来说，它们常常表现为解释性或“如何做”的问题，通常只有一个正确答案，且没有太多视角。我们训练了第二个分类器，用于评分一个问题是否需要提出子问题。所谓“需要子问题”的具体定义，见图[5](https://arxiv.org/html/2402.17896v1#A1.F5
    "图5 ‣ 附录A 基于GPT-4的筛选细节 ‣ 研究性问题：多视角、分解式问题的数据集")中的提示，该提示用于让ChatGPT（gpt-35-turbo）收集标签。我们之所以使用ChatGPT，是因为我们认为这是一个相对密集的认知任务。我们对约40k个来自非事实型分类器并满足非事实型阈值0.75的输出进行了推断。然后我们使用这些标签训练了一个单独的bert-large“分解式”分类器。
- en: 'Again, we chose a threshold by manual inspection to indicate which of the 1.0M
    Non-factoid QnA Queries were also decompositional, which happened to be 0.6 as
    shown on the right-hand side of Figure [3](https://arxiv.org/html/2402.17896v1#A1.F3
    "Figure 3 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    Out of the 1.0M queries that met the non-factoid threshold, 146k also met the
    decompositional threshold. These 146k became the Researchy Questions candidates
    before deduplication. This procedure is not perfect; in Table [6](https://arxiv.org/html/2402.17896v1#A1.T6
    "Table 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents") we show examples
    of some non-factoid questions that did not meet the decompositional threshold.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '同样，我们通过手动检查选择了一个阈值，表示哪些1.0M非事实性问答查询也是分解性的，这个阈值恰好是0.6，如图[3](https://arxiv.org/html/2402.17896v1#A1.F3
    "Figure 3 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")右侧所示。在满足非事实性阈值的1.0M查询中，146k也满足分解性阈值。这146k成为去重前的研究性问题候选。在表[6](https://arxiv.org/html/2402.17896v1#A1.T6
    "Table 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents")中，我们展示了没有满足分解性阈值的某些非事实性问题的例子。'
- en: '2.4 Stage 4: Deduplication'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 阶段4：去重
- en: The final step of filtering is deduplication. We take an agglomerative clustering
    approach  Everitt ([1974](https://arxiv.org/html/2402.17896v1#bib.bib13)), where
    the only parameter is a distance threshold $\epsilon$ below which two queries
    are considered “duplicate intent”.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 去重的最后一步是去重。我们采用了聚合聚类方法，Everitt（[1974](https://arxiv.org/html/2402.17896v1#bib.bib13)），其唯一参数是距离阈值$\epsilon$，低于该阈值的两个查询被认为是“重复意图”。
- en: We represent the semantic intent of a query by an ANCE-based Xiong et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib55))
    vector encoder $\overrightarrow{q_{i}}\leftarrow\texttt{encoder}(q_{i})$. We instantiate
    a metric space defined by $1-\texttt{cosine}(\cdot,\cdot)$ of the vector encodings
    using the faiss implementation of an approximate nearest neighbor (ANN) index Johnson
    et al. ([2019](https://arxiv.org/html/2402.17896v1#bib.bib22)). For each question
    in the index, we search for the nearest neighbors $\{q_{j}\sim\texttt{ANN}(q_{i})$
    s.t. 1.0 - $\overrightarrow{q_{i}}\cdot\overrightarrow{q_{j}}<\epsilon\}$. For
    agglomerative clustering, we define a “group” as a set of queries in which all
    pairwise distances are within $\epsilon$. We found that about 63% of queries were
    singletons (did not belong to a group of size greater than one), and the average
    group size was 3.8\. For example, the queries “*what were tanks used for in ww1*”,
    “*how were the tanks used in ww1*” and “*why were tanks needed in ww1*” were all
    part of the same group. For all groups of size greater than one, we selected the
    query that was issued most often in the logs as the representative “head” of the
    group. After combining the heads of groups and singletons, about 70% of queries
    remained, yielding 102k Researchy Questions . Although we did our best to de-duplicate
    question intent, some clusters of topics remain, e.g. a quick keyword count shows
    about 600 contain the string “ww2”, or about 80 for “supreme court”.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过基于ANCE的Xiong等人（[2020](https://arxiv.org/html/2402.17896v1#bib.bib55)）的向量编码器来表示查询的语义意图$\overrightarrow{q_{i}}\leftarrow\texttt{encoder}(q_{i})$。我们实例化了一个度量空间，该空间由$1-\texttt{cosine}(\cdot,\cdot)$的向量编码组成，使用faiss实现的近似最近邻（ANN）索引Johnson等人（[2019](https://arxiv.org/html/2402.17896v1#bib.bib22)）。对于索引中的每个问题，我们搜索最近邻$\{q_{j}\sim\texttt{ANN}(q_{i})$
    使得 1.0 - $\overrightarrow{q_{i}}\cdot\overrightarrow{q_{j}}<\epsilon\}$。对于聚合聚类，我们定义一个“组”作为一组查询，其中所有的成对距离都在$\epsilon$范围内。我们发现大约63%的查询是孤立的（不属于大小大于一的组），而平均组大小为3.8。例如，查询“*what
    were tanks used for in ww1*”，“*how were the tanks used in ww1*”和“*why were tanks
    needed in ww1*”都属于同一组。对于所有大于一的组，我们选择在日志中最常出现的查询作为该组的代表“头”。在组合组头和孤立查询后，大约70%的查询得以保留，共计102k研究性问题。尽管我们尽力去重问题意图，但仍然存在一些话题聚类，例如，快速的关键词统计显示大约600个查询包含“ww2”字符串，约80个查询包含“supreme
    court”。
- en: '2.5 Stage 5: Final GPT-4 Filtering'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 阶段5：最终的GPT-4过滤
- en: 'As a final quality control step after deduplication, we had all 102k questions
    labeled by GPT-4 for intrinsic attributes of the question like how multi-faceted
    it is, how reasoning-intensive it is likely to be, etc. The full set of eight
    attributes is defined in Figure [7](https://arxiv.org/html/2402.17896v1#A1.F7
    "Figure 7 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents"),
    along with histograms of those scores in Figure [6](https://arxiv.org/html/2402.17896v1#A1.F6
    "Figure 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") for
    both Researchy Questions and Natural Questions. All eight are scored on a scale
    of 1-10\. About 3% of 102k questions were removed based on the attributes “ambiguous”
    and “incomplete” which indicate defective questions too difficult to answer; some
    examples are shown in Table [7](https://arxiv.org/html/2402.17896v1#A1.T7 "Table
    7 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents"). Another
    2% were removed for being too “assumptive”, meaning the question was phrased in
    a presumptuous way that was likely to bias the answer as shown in Table  [8](https://arxiv.org/html/2402.17896v1#A1.T8
    "Table 8 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents"). Another
    2% was removed for safety reasons as shown in Table [9](https://arxiv.org/html/2402.17896v1#A1.T9
    "Table 9 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"), where we deem risk of harm too high by attempting
    to answer the question. Not all “assumptive” questions are harmful per se. Finally,
    the remaining 96k queries are what we release.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 作为去重后的最终质量控制步骤，我们让 GPT-4 为所有 102k 个问题标注了内在属性，比如问题的多维性、推理强度等。这些属性的完整集合定义在图 [7](https://arxiv.org/html/2402.17896v1#A1.F7
    "图 7 ‣ 附录 A 基于 GPT-4 的过滤细节 ‣ 研究性问题：多视角、分解性问题数据集")中，并且图 [6](https://arxiv.org/html/2402.17896v1#A1.F6
    "图 6 ‣ 附录 A 基于 GPT-4 的过滤细节 ‣ 研究性问题：多视角、分解性问题数据集") 中包含了这些分数的直方图，涵盖了研究性问题和自然问题。所有八个属性的评分范围为
    1-10。约 3% 的 102k 个问题被移除，原因是它们被标记为“模糊”和“不完整”，这些问题过于难以回答；一些示例如表 [7](https://arxiv.org/html/2402.17896v1#A1.T7
    "表 7 ‣ 附录 A 基于 GPT-4 的过滤细节 ‣ 研究性问题：多视角、分解性问题数据集") 所示。另有 2% 的问题被移除，原因是它们过于“假设性”，即问题的措辞具有假设性，可能会偏向某种回答，如表
    [8](https://arxiv.org/html/2402.17896v1#A1.T8 "表 8 ‣ 附录 A 基于 GPT-4 的过滤细节 ‣ 研究性问题：多视角、分解性问题数据集")
    所示。还有 2% 的问题因安全原因被移除，如表 [9](https://arxiv.org/html/2402.17896v1#A1.T9 "表 9 ‣ A.1
    附加安全过滤 ‣ 附录 A 基于 GPT-4 的过滤细节 ‣ 研究性问题：多视角、分解性问题数据集") 所示，我们认为尝试回答这些问题的风险过高。并非所有“假设性”问题都本质上有害。最终，剩余的
    96k 条查询将被发布。
- en: '| Method | Samples | Direct Answer | CoT decomp. | Factor decomp. | Decomp.
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 样本 | 直接答案 | CoT 分解 | 因素分解 | 分解 |'
- en: '| Acc. | Score | Acc. | Score | Acc. | Score | Score gain |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 准确度 | 分数 | 准确度 | 分数 | 准确度 | 分数 | 分数增益 |'
- en: '| Hotpot QA | 300 | 0.843 | 83.4 | 0.877 | 83.5 | 0.837 | 81.3 | +0.1 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Hotpot QA | 300 | 0.843 | 83.4 | 0.877 | 83.5 | 0.837 | 81.3 | +0.1 |'
- en: '| OpenBook QA | 300 | 0.926 | 86.1 | 0.843 | 83.5 | 0.750 | 80.7 | -2.6 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 开放书籍 QA | 300 | 0.926 | 86.1 | 0.843 | 83.5 | 0.750 | 80.7 | -2.6 |'
- en: '| Strategy QA | 300 | 0.757 | 80.8 | 0.810 | 83.7 | 0.777 | 82.6 | +2.9 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 策略 QA | 300 | 0.757 | 80.8 | 0.810 | 83.7 | 0.777 | 82.6 | +2.9 |'
- en: '| Truthful QA | 300 | 0.703 | 73.7 | 0.789 | 82.4 | 0.739 | 81.5 | +8.7 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Truthful QA | 300 | 0.703 | 73.7 | 0.789 | 82.4 | 0.739 | 81.5 | +8.7 |'
- en: '| Aquamuse | 300 | 0.916 | 83.0 | 0.940 | 84.9 | 0.926 | 85.0 | +2.0 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Aquamuse | 300 | 0.916 | 83.0 | 0.940 | 84.9 | 0.926 | 85.0 | +2.0 |'
- en: '| Reddit/askh | 300 | 0.759 | 79.8 | 0.736 | 77.3 | 0.732 | 79.3 | -0.5 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/askh | 300 | 0.759 | 79.8 | 0.736 | 77.3 | 0.732 | 79.3 | -0.5 |'
- en: '| Reddit/asks | 300 | 0.783 | 81.1 | 0.743 | 79.4 | 0.796 | 82.7 | +1.6 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/asks | 300 | 0.783 | 81.1 | 0.743 | 79.4 | 0.796 | 82.7 | +1.6 |'
- en: '| Reddit/eli5 | 300 | 0.883 | 83.1 | 0.890 | 85.0 | 0.890 | 86.5 | +3.4 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Reddit/eli5 | 300 | 0.883 | 83.1 | 0.890 | 85.0 | 0.890 | 86.5 | +3.4 |'
- en: '| StackExchange | 300 | 0.717 | 78.4 | 0.599 | 70.7 | 0.628 | 73.4 | -5.0 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| StackExchange | 300 | 0.717 | 78.4 | 0.599 | 70.7 | 0.628 | 73.4 | -5.0 |'
- en: '| Wikihow QA | 300 | 0.93 | 82.9 | 0.937 | 84.4 | 0.950 | 88.2 | +5.3 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Wikihow QA | 300 | 0.93 | 82.9 | 0.937 | 84.4 | 0.950 | 88.2 | +5.3 |'
- en: '| Researchy Questions | 1k | N/A | 82.7 | N/A | 84.6 | N/A | 88.3 | +5.6 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 研究性问题 | 1k | 不适用 | 82.7 | 不适用 | 84.6 | 不适用 | 88.3 | +5.6 |'
- en: 'Table 5: Comparison of various question decomposition techniques to prompt
    GPT-4 as an answer module. The top half of the table is short-form questions,
    the bottom half is longform questions.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表格5：各种问题分解技术与GPT-4作为答题模块的对比。表格的上半部分为简短问题，下半部分为长格式问题。
- en: 3 Characterizing Researchy Questions
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 描述Researchy Questions
- en: 'Across the 96k Researchy Questions (split into 90k train, 6.4k test), there
    are in aggregate 350k unique documents clicked, 48% of which can be found in the
    english subset of Clueweb22 Set B Overwijk et al. ([2022](https://arxiv.org/html/2402.17896v1#bib.bib40));
    the rest are in Sets A or L. For each question we release, there are on average
    4.9 +/- 3.5 clicked documents (See Figure [2](https://arxiv.org/html/2402.17896v1#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") Right),
    indicating a good diversity of information needs and much higher than the average
    query overall. Conversely, for each document there is only 1.4 +/- 2.3 associated
    Researchy Questions (See Figure [2](https://arxiv.org/html/2402.17896v1#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") Left)
    indicating good query de-duplication.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '在96k个Researchy Questions（分为90k训练集，6.4k测试集）中，总共有350k个独特的点击文档，其中48%的文档可以在Clueweb22
    Set B的英文子集中过滤到，参见Overwijk等人（[2022](https://arxiv.org/html/2402.17896v1#bib.bib40)）；其余的文档位于A集或L集中。对于我们发布的每个问题，平均有4.9
    +/- 3.5个被点击的文档（见图[2](https://arxiv.org/html/2402.17896v1#A1.F2 "Figure 2 ‣ Appendix
    A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") 右），这表明信息需求的多样性较好，且明显高于总体的平均查询。相反，对于每个文档，只有1.4
    +/- 2.3个相关的Researchy Questions（见图[2](https://arxiv.org/html/2402.17896v1#A1.F2
    "Figure 2 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") 左），这表明查询去重良好。'
- en: 'To get a sense of how intrinsically difficult Researchy Questions are compared
    to other datasets, we asked GPT-4 how many sub-questions or search engine queries
    would be necessary to ask/issue in order to fully answer each question. An example
    decomposition in shown in Table [2](https://arxiv.org/html/2402.17896v1#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents"), and the aggregate results are
    shown in Table [1](https://arxiv.org/html/2402.17896v1#S1.T1 "Table 1 ‣ 1 Introduction
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents"). Clearly, GPT-4 thinks that most factoid QA datasets (top
    of the table) require the fewest sub-questions to answer, whereas Researchy Questions require
    the most even among longer-form QA datasets.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '为了了解与其他数据集相比，Researchy Questions在内在难度上的表现，我们向GPT-4询问了每个问题需要多少个子问题或搜索引擎查询才能完全回答。一个示例分解见于表格[2](https://arxiv.org/html/2402.17896v1#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")，汇总结果见于表格[1](https://arxiv.org/html/2402.17896v1#S1.T1
    "Table 1 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")。显然，GPT-4认为大多数事实型问答数据集（表格顶部）需要最少的子问题，而Researchy
    Questions即使在较长格式的问答数据集中，也需要最多的子问题。'
- en: 'We also compared Researchy Questions to another search-log based QA dataset
    – Natural Questions Kwiatkowski et al. ([2019](https://arxiv.org/html/2402.17896v1#bib.bib31))
    – along the 8 quality dimensions descried in Section [2.5](https://arxiv.org/html/2402.17896v1#S2.SS5
    "2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents"), such as how reasoning- and knowledge-intense they are. The comparative
    histograms are shown in Figure [6](https://arxiv.org/html/2402.17896v1#A1.F6 "Figure
    6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents"), Clearly,
    GPT-4 thinks that Researchy Questions require much more knowledge, reasoning,
    and are inherently more multi-faceted.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还将Researchy Questions与另一个基于搜索日志的问答数据集——Natural Questions  Kwiatkowski et
    al. ([2019](https://arxiv.org/html/2402.17896v1#bib.bib31))进行了比较，比较了在第[2.5节](https://arxiv.org/html/2402.17896v1#S2.SS5
    "2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents")中描述的8个质量维度，比如它们的推理强度和知识强度。比较的直方图显示在图[6](https://arxiv.org/html/2402.17896v1#A1.F6
    "Figure 6 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")中，显然，GPT-4认为Researchy
    Questions需要更多的知识、推理，且本质上更加多面。'
- en: 'Table [3](https://arxiv.org/html/2402.17896v1#S2.T3 "Table 3 ‣ 2 Researchy
    Questions Construction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") shows the distribution of first
    words across Researchy Questions (as well as intermediate datasets used in the
    filtering funnel described in the next section). For comparison, MS Marco queries
    (also from web search logs) are much more factoid – e.g. only 1.64% of them start
    with “why” Bajaj et al. ([2018](https://arxiv.org/html/2402.17896v1#bib.bib3)).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [3](https://arxiv.org/html/2402.17896v1#S2.T3 "Table 3 ‣ 2 Researchy Questions
    Construction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") 显示了Researchy Questions中第一个单词的分布（以及在下一节中描述的过滤漏斗中使用的中间数据集）。为了进行比较，MS
    Marco查询（同样来自网络搜索日志）则更偏向事实类问题——例如，只有1.64%的查询以“why”开头  Bajaj et al. ([2018](https://arxiv.org/html/2402.17896v1#bib.bib3))。'
- en: 'Lastly, an emergent property of Researchy Questions we observed is that some
    information found in the clicked URLs is very surprising, e.g. for the question
    “should the death penalty be legalized”, the fact that in the US, “the cost of
    enforcing the death penalty cost millions more than life imprisonment” ²²2supremecourt.gov/opinions
    would have a large impact on the economic arguments in that answer. We define
    a Pivotal Fact as a piece of information that is so surprising and consequential
    that, once known, drastically changes how an LLM Agent would answer the question
    (and the answer wouldn’t be as good without it); but it wouldn’t know about it
    unless it asked the right sub-question to retrieve it, e.g. “does the death penalty
    cost more than life imprisonment”. Hence, a pivotal fact is the information analogue
    of a black swan, a critical event that is hard to predict but highly impactful Taleb
    ([2008](https://arxiv.org/html/2402.17896v1#bib.bib48)); another example is shown
    in the bottom of Table [2](https://arxiv.org/html/2402.17896v1#S1.T2 "Table 2
    ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Although we don’t have a good way to quantify
    the prevalence of Pivotal Facts, we believe that Researchy Questions is the best
    dataset to study the dynamics of how LLM Agents search for, and respond to, these
    uknown unknowns.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，我们观察到Researchy Questions的一个突现特性是，某些在点击的URL中找到的信息非常令人惊讶，例如，对于“死刑是否应当合法化”的问题，事实上在美国，“执行死刑的成本比终身监禁高出数百万美元”²²2supremecourt.gov/opinions，这会对经济角度的回答产生很大影响。我们将“关键事实”定义为一种信息，它是如此令人惊讶且具有深远影响，以至于一旦知道它，LLM
    Agent的回答将会发生根本性变化（如果没有它，答案将无法达到同样的质量）；但除非它提出正确的子问题来检索该信息，否则它不会知道这件事，例如：“死刑的成本是否比终身监禁更高”。因此，关键事实就像黑天鹅一样，是一种难以预测但具有重大影响的关键事件 Taleb
    ([2008](https://arxiv.org/html/2402.17896v1#bib.bib48))；另一个例子见于表格[2](https://arxiv.org/html/2402.17896v1#S1.T2
    "Table 2 ‣ 1 Introduction ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents")的底部。虽然我们没有一个好的方法来量化关键事实的普遍性，但我们认为Researchy
    Questions是研究LLM Agents如何寻找并回应这些未知未知（unknown unknowns）动态的最佳数据集。'
- en: 4 Agreement with User Search Behavior
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与用户搜索行为的协议
- en: More complicated questions ought to require more effort to answer Kelly et al.
    ([2015](https://arxiv.org/html/2402.17896v1#bib.bib26)). We can approximate the
    amount of effort users expend in terms of behavior signals like clicks and session
    length.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '更复杂的问题应该需要更多的努力来回答，Kelly等人（[2015](https://arxiv.org/html/2402.17896v1#bib.bib26)）提出过这一观点。我们可以通过行为信号，如点击和会话时长，来近似用户花费的努力量。  '
- en: 'In Table [4](https://arxiv.org/html/2402.17896v1#S2.T4 "Table 4 ‣ 2.1 Stage
    1: Mining Search Logs ‣ 2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    (Left) we show aggregate click statistics for each subset of queries. The results
    show that Researchy Questions , which are both non-factoid and decompositional,
    lead to more in-depth consumption (clicks and sat-clicks) of more diverse information
    (unique urls), agreeing with prior work Hassan et al. ([2014](https://arxiv.org/html/2402.17896v1#bib.bib18)).'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[4](https://arxiv.org/html/2402.17896v1#S2.T4 "Table 4 ‣ 2.1 Stage 1: Mining
    Search Logs ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents")（左侧），我们展示了每个查询子集的汇总点击统计数据。结果表明，研究性问题（Researchy
    Questions）既非事实性问题又是可分解的，它们导致了对更多样化信息（独特的网址）的更深入消费（点击和满意点击），这与之前的工作Hassan等人（[2014](https://arxiv.org/html/2402.17896v1#bib.bib18)）一致。  '
- en: 'In Table [4](https://arxiv.org/html/2402.17896v1#S2.T4 "Table 4 ‣ 2.1 Stage
    1: Mining Search Logs ‣ 2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    (Right) we show behavioral signals exhibited by users at the session level rather
    than individual click level. For instance, if a QnA-type query appeared at any
    time in any session in the date range, the whole session is included in the “QnA
    Sessions” row. The results clearly show users were twice as engaged answering
    non-factoid questions than sessions devoted to factoid-y intents, and six times
    longer than the average session overall.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[4](https://arxiv.org/html/2402.17896v1#S2.T4 "Table 4 ‣ 2.1 Stage 1: Mining
    Search Logs ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents")（右侧），我们展示了用户在会话层级上表现出的行为信号，而非单一点击层级。例如，如果在某个日期范围内的任何会话中出现了问答类型的查询，那么该会话将包含在“问答会话”一栏中。结果清楚地显示，用户在回答非事实性问题时的参与度是回答事实性问题会话的两倍，且整体会话时长是平均会话的六倍。  '
- en: 5 Evaluating Answer Techniques to Researchy Questions
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '5 评估回答研究性问题的技巧  '
- en: Since there is no one “correct” answer to a Researchy Question, we contend that
    they ought be evaluated in a relative, side-by-side fashion *a la* Alpaca-Eval
    syle Li et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib33)), with e.g.
    the “closed-book” answer as the reference.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 由于研究性问题没有一个“正确”的答案，我们认为它们应该以相对的、并排的方式进行评估，*类似于* Alpaca-Eval风格，Li等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib33)）指出，例如，将“闭卷”答案作为参考。
- en: Since Researchy Questions are intended to be answered by decomposing them into
    sub-questions, we evaluate two decompositional question answering answer techniques
    – chain-of-thought decomposition, and factored decomposition – against the direct
    answering baseline. Factored decomposition makes a separate call to an LLM for
    each sub-question independently, and then a final “recomposition” call to synthesize
    the main answer (Radhakrishnan et al., [2023](https://arxiv.org/html/2402.17896v1#bib.bib43)).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '由于研究性问题旨在通过将其分解为子问题来进行回答，我们评估了两种分解式问题回答技术——思维链分解和因式分解——与直接回答基线进行对比。因式分解为每个子问题分别调用LLM，然后进行最终的“重组”调用，以综合主答案（Radhakrishnan等人，[2023](https://arxiv.org/html/2402.17896v1#bib.bib43)）。  '
- en: 'Table [5](https://arxiv.org/html/2402.17896v1#S2.T5 "Table 5 ‣ 2.5 Stage 5:
    Final GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    shows the results of a side-by-side auto-eval of the three answering techniques
    across a range of datasets. The LLM providing the answers was GPT-4, and the LLM-as-a-judge
    was also GPT-4, prompted separately using the template in Figure [8](https://arxiv.org/html/2402.17896v1#A1.F8
    "Figure 8 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"). Since the gold correct answers exist for many
    of the datasets we consider, the judge was asked to ascertain “Accuracy” as a
    binary score of whether the candidate answer was consistent with the gold. The
    “Score” is on a scale of 1-100 indicating the overall quality. The top half of
    Table [5](https://arxiv.org/html/2402.17896v1#S2.T5 "Table 5 ‣ 2.5 Stage 5: Final
    GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") corresponds
    to short-answer datasets (where Accuracy is more important), while the bottom
    half is longer answer questions where the overall Score is better suited to evaluate.
    Out of the long-form answer datasets, Researchy Questions benefits the most from
    decomposition techniques.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '表格 [5](https://arxiv.org/html/2402.17896v1#S2.T5 "Table 5 ‣ 2.5 Stage 5: Final
    GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents") 显示了在一系列数据集上，三种回答技术的并行自动评估结果。提供答案的LLM是GPT-4，作为评审的LLM也是GPT-4，分别使用图 [8](https://arxiv.org/html/2402.17896v1#A1.F8
    "Figure 8 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") 中的模板进行提示。由于我们考虑的许多数据集有正确的标准答案，评审被要求判断“准确性”，即候选答案是否与标准答案一致，并给出一个二元评分。“得分”是一个1-100的范围，表示整体质量。表格的上半部分 [5](https://arxiv.org/html/2402.17896v1#S2.T5
    "Table 5 ‣ 2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy Questions Construction
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents") 对应的是短答案数据集（在这里，准确性更为重要），而下半部分是长答案问题，更适合用整体得分来评估。在长答案数据集中，Researchy
    Questions 在分解技术的帮助下受益最多。'
- en: 'We draw several conclusions from Table [5](https://arxiv.org/html/2402.17896v1#S2.T5
    "Table 5 ‣ 2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy Questions Construction
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents"). Firstly, we largely confirm the results of  Radhakrishnan
    et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib43)) that decompositional
    techniques improve the accuracy on short-form multi-hop datasets over zero-shot
    direct answering. Secondly, factored decomposition leads to the highest scores
    for long-form questions, particularly questions involving reasoning about complex
    processes like Wikihow and Researchy Questions . On the other hand, chain-of-thought
    decomposition may be better suited to deduce correct answers to more logic-intensive
    questions. We believe the results for Researchy Questions using factored decomposition
    would be much higher if we incorporated retrieved information.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '我们从表 [5](https://arxiv.org/html/2402.17896v1#S2.T5 "Table 5 ‣ 2.5 Stage 5:
    Final GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    中得出几个结论。首先，我们基本确认了Radhakrishnan等人 ([2023](https://arxiv.org/html/2402.17896v1#bib.bib43))
    的研究结果，即分解技术在短格式多跳数据集上比零-shot直接回答提高了准确性。其次，分解法（factored decomposition）对于长答案问题的得分最高，特别是涉及复杂过程推理的问题，如Wikihow和Researchy
    Questions 。另一方面，思维链（chain-of-thought）分解可能更适合推理逻辑密集型问题的正确答案。我们认为，如果我们引入检索到的信息，使用分解法的Researchy
    Questions的结果会更高。'
- en: 6 Related Work
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: 6.1 Human Behavior in Search Sessions
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 搜索会话中的人类行为
- en: There has been some fundamental research into understanding user behavior in
    search sessions, from user studies Kelly et al. ([2015](https://arxiv.org/html/2402.17896v1#bib.bib26))
    to large scale click log evaluations Hassan et al. ([2014](https://arxiv.org/html/2402.17896v1#bib.bib18)).
    The latter attempt to ascertain signals that could indicate whether a user is
    “struggling” or “exploring” in their search session; we use many of the same signals.
    Namely, they conclude that “exploring” sessions contain more clicks because users
    want to locate information for multiple facets of a topic. We concur with their
    results, e.g. non-factoid questions involve more clicks than factoid ones. Similarly,
    the definition of a “complex search task” is almost congruent to that of a Researchy
    Question in its information seeking behaviors [Aula and Russell](https://arxiv.org/html/2402.17896v1#bib.bib2).
    Other studies try to identify complex search tasks and offer recommended sub-tasks Hassan Awadallah
    et al. ([2014](https://arxiv.org/html/2402.17896v1#bib.bib19)); Zhang et al. ([2021](https://arxiv.org/html/2402.17896v1#bib.bib62)).
    Much of the intuition on how to filter Researchy Questions stems from these and
    similar studies on user search behavior.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些基础研究致力于理解用户在搜索会话中的行为，从用户研究，Kelly 等人（[2015](https://arxiv.org/html/2402.17896v1#bib.bib26)）到大规模点击日志评估，Hassan
    等人（[2014](https://arxiv.org/html/2402.17896v1#bib.bib18)）。后者试图确定是否有信号可以指示用户在搜索会话中是“挣扎”还是“探索”；我们使用了许多相同的信号。即，他们的研究结论是，“探索”会话的点击量更多，因为用户希望为一个话题的多个方面寻找信息。我们同意他们的结果，例如，非事实性问题比事实性问题涉及更多的点击。同样，“复杂搜索任务”的定义几乎与研究性问题在信息需求行为上相吻合，[Aula
    和 Russell](https://arxiv.org/html/2402.17896v1#bib.bib2)的研究也支持这一点。其他研究尝试识别复杂搜索任务并提供推荐的子任务，Hassan
    Awadallah 等人（[2014](https://arxiv.org/html/2402.17896v1#bib.bib19)）；Zhang 等人（[2021](https://arxiv.org/html/2402.17896v1#bib.bib62)）。关于如何筛选研究性问题的直觉，源自这些以及类似的用户搜索行为研究。
- en: 6.2 Iterative Retrieval-Augmented Generation
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 迭代检索增强生成
- en: 'Many papers discuss variants of chain-of-thought Wei et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib52))
    adapted to decomposing multi-faceted questions such as query refinement prompts Amplayo
    et al. ([2022](https://arxiv.org/html/2402.17896v1#bib.bib1)), Decomposed Prompting Khot
    et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib28)) and ReAct Yao et al.
    ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib58)). A step further is to
    marry a generative LLM with a vector-based retrieval system, e.g. Ren et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib45));
    Xiong et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib55)); Karpukhin
    et al. ([2020](https://arxiv.org/html/2402.17896v1#bib.bib25)); Izacard and Grave
    ([2021](https://arxiv.org/html/2402.17896v1#bib.bib20)). Such methods are instantiated
    in many flavors: Self-Ask Press et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib42))
    was one of the first chain-of-thought-like decomposed prompting techniques to
    integrate a search engine, forcing an LLM to iteratively ask and subquestions.
    IRCoT interleaves retrieval with chain-of-thought such that what to retrieve next
    depends on what was previously retrieved Trivedi et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib50))
    Iter-RetGen iteratively retrieves and generates candidate answers to use as inputs
    to the next phase of retrieval Shao et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib46)),
    while Beam Retrieval maintains running hypotheses of the relevant passages at
    every step Zhang et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib60)).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 许多论文讨论了链式思维的变体，Wei 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib52)）对其进行了改编，以解决诸如查询精炼提示等多方面问题，Amplayo
    等人（[2022](https://arxiv.org/html/2402.17896v1#bib.bib1)），分解式提示，Khot 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib28)）和
    ReAct，Yao 等人（[2023b](https://arxiv.org/html/2402.17896v1#bib.bib58)）。进一步的进展是将生成式大型语言模型与基于向量的检索系统结合，例如
    Ren 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib45)）；Xiong 等人（[2020](https://arxiv.org/html/2402.17896v1#bib.bib55)）；Karpukhin
    等人（[2020](https://arxiv.org/html/2402.17896v1#bib.bib25)）；Izacard 和 Grave（[2021](https://arxiv.org/html/2402.17896v1#bib.bib20)）。此类方法有多种实现方式：Self-Ask，Press
    等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib42)）是最早将搜索引擎集成进链式思维式分解提示技术之一，迫使大型语言模型反复提出问题并进行子问题分解。IRCoT
    将检索与链式思维交织在一起，下一步的检索内容取决于先前的检索结果，Trivedi 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib50)）。Iter-RetGen
    反复检索并生成候选答案，作为下一轮检索的输入，Shao 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib46)），而
    Beam Retrieval 在每一步都维护相关段落的当前假设，Zhang 等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib60)）。
- en: 6.3 Agentic Question Answering
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 代理式问答
- en: There are several “agentic” frameworks to facilitate the dynamic interaction
    between tools e.g. retrieval systems and LLMs-as-agents which are adept at iterative
    retrieval-augmented QA tasks. One is Demonstrate-Search-Predict Khattab et al.
    ([2023](https://arxiv.org/html/2402.17896v1#bib.bib27)), another is AutoGen Wu
    et al. ([2023b](https://arxiv.org/html/2402.17896v1#bib.bib54)). Some existing
    Web-based Agents include WebGPT Nakano et al. ([2022](https://arxiv.org/html/2402.17896v1#bib.bib38))
    which imitate how users surf the web and ask queries, others like WebAgent Gur
    et al. ([2023](https://arxiv.org/html/2402.17896v1#bib.bib16)) interact with the
    web programmatically by understanding the raw HTML.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种“代理性”框架可以促进工具之间的动态交互，例如检索系统和作为代理的LLM，它们在迭代检索增强问答任务中表现出色。其中一个是Demonstrate-Search-Predict
    Khattab等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib27)），另一个是AutoGen Wu等人（[2023b](https://arxiv.org/html/2402.17896v1#bib.bib54)）。一些现有的基于网络的代理包括WebGPT
    Nakano等人（[2022](https://arxiv.org/html/2402.17896v1#bib.bib38)），它模拟用户浏览网页和提问的方式；其他代理如WebAgent
    Gur等人（[2023](https://arxiv.org/html/2402.17896v1#bib.bib16)）则通过理解原始HTML与网络进行程序化交互。
- en: 'There are also several consumer-facing products for agentic search assistants
    such as Bing Chat ³³3[https://bing.com/chat](https://bing.com/chat), YouPro ⁴⁴4[https://you.com/search](https://you.com/search)
    (Research Mode) and SciPhi ⁵⁵5[https://search.sciphi.ai/research](https://search.sciphi.ai/research).
    All of these systems clearly decompose queries into sub-questions and then retrieve/crawl
    the necessary pages to synthesize the final outputs. An example of each addressing
    a Researchy Question is shown in Figures [9](https://arxiv.org/html/2402.17896v1#A1.F9
    "Figure 9 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"),  [10](https://arxiv.org/html/2402.17896v1#A1.F10
    "Figure 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"), and  [11](https://arxiv.org/html/2402.17896v1#A1.F11
    "Figure 11 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents"), respectively.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '目前也有一些面向消费者的代理搜索助手产品，如Bing Chat ³³3[https://bing.com/chat](https://bing.com/chat)、YouPro ⁴⁴4[https://you.com/search](https://you.com/search)（研究模式）和SciPhi ⁵⁵5[https://search.sciphi.ai/research](https://search.sciphi.ai/research)。这些系统都能清晰地将查询分解为子问题，然后检索/爬取必要的页面来合成最终结果。每个系统解决研究性问题的示例分别展示在图[9](https://arxiv.org/html/2402.17896v1#A1.F9
    "Figure 9 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")、[10](https://arxiv.org/html/2402.17896v1#A1.F10
    "Figure 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")和[11](https://arxiv.org/html/2402.17896v1#A1.F11
    "Figure 11 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")中有所展示。'
- en: 7 Conclusion
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: For some time now, many QA datasets have been saturated, and many researchers
    have dismissed search logs as sources of complex questions. We present Researchy
    Questions , a large dataset to advance the field of complex question answering
    over multiple documents and perspectives, targeting LLM-assisted web search agents.
    We detail how these complex queries are mined from search logs, and confirm they
    involve significantly more effort than other types of search queries. We also
    provide some preliminary evidence that decompositional answering techniques yield
    stronger results on Researchy Questions than direct answering.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，许多问答数据集已经趋于饱和，许多研究者也已将搜索日志排除为复杂问题的来源。我们提出了Researchy Questions，一个大型数据集，旨在推动多文档、多视角的复杂问题解答领域，目标是LLM辅助的网络搜索代理。我们详细描述了这些复杂查询是如何从搜索日志中挖掘出来的，并确认它们需要比其他类型的搜索查询更多的努力。我们还提供了一些初步证据，表明分解式回答技术在Researchy
    Questions上的表现优于直接回答。
- en: 'By design, these questions don’t have a gold answer, so regrettably, it difficult
    to quantify the “headroom” of existing models, but qualitatively (e.g. Table [10](https://arxiv.org/html/2402.17896v1#A1.T10
    "Table 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")) there seems to be substantial room for improvement.
    There also remains much work surrounding how to measure the quality of sub-questions,
    and studying how LLM agents find and interact with Pivotal Facts. We hope this
    dataset can help aid the development of new metrics and unlock new experiences
    for web users.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '从设计上来看，这些问题没有标准的答案，因此遗憾的是，很难量化现有模型的“提升空间”，但从定性角度来看（例如，表格[10](https://arxiv.org/html/2402.17896v1#A1.T10
    "Table 10 ‣ A.1 Additional Safety Filtering ‣ Appendix A GPT-4-based Filtering
    Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents")），似乎还有很大的改进空间。同时，关于如何衡量子问题的质量，以及研究LLM代理如何发现并与关键事实（Pivotal
    Facts）互动，仍然有很多工作需要做。我们希望这个数据集能够帮助开发新的衡量标准，并为网络用户开启新的体验。'
- en: Limitations
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: One of the primary limitations of this study is that while we argue question
    decomposition is key to solving complex Researchy Questions , we don’t propose
    a good way to measure the quality of a candidate set of sub-questions. Instead,
    we loosely argue that good sub-questions ought to at least lead to the same set
    of information found in the documents users clicked on for the question. We admit
    these two things are not the same, but clicks are a powerful signal. We try to
    make up for this gap by releasing the hierarchical question/query decomposition
    that GPT-4 gives closed-book, but we do not evaluate whether that decomposition
    does indeed lead to the same set of gold documents in a real retrieval system
    e.g. built from the entirety of ClueWeb22.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的主要限制之一是，尽管我们认为问题分解是解决复杂研究性问题的关键，但我们并没有提出一个有效的方式来衡量一组候选子问题的质量。相反，我们松散地认为，好的子问题至少应当能够引导出用户点击的文档中找到的相同信息。我们承认，这两者并不相同，但点击数据是一个强有力的信号。为了弥补这个差距，我们发布了GPT-4在闭卷环境下给出的层次化问题/查询分解，但我们并未评估该分解是否确实能在真实的检索系统中（例如基于ClueWeb22构建的系统）导出相同的标准文档集合。
- en: We also admit that it would potentially be better to produce the question decomposition
    by “working backwards” from the documents that were clicked on – i.e. identify
    key information in the clicked document for a researchy question and then identify
    what sub-question would lead to that information being retrieved. On the other
    hand, one could argue that the “forward” direction is what needs to be implemented
    in practice. While we do not address these points in this study, others in the
    academic community can explore these topics more with the dataset we release.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也承认，从点击的文档“反向推导”问题分解可能会更好——即，首先识别在点击的文档中找到的关键资料，针对研究性问题再确定哪些子问题能帮助提取到这些信息。另一方面，也可以认为“正向”方向才是实际应用中需要实施的方向。虽然我们在这项研究中没有解决这些问题，但学术界的其他人可以利用我们发布的数据集进一步探索这些话题。
- en: Another limitation of this study is that Pivotal Facts are purely an observational
    phenomenon that we have in no way quantified. Future researchers could create
    a LLM-prompt to count the number of such statements in the clicked documents.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的另一个限制是，关键事实（Pivotal Facts）仅仅是我们观察到的现象，尚未进行量化。未来的研究人员可以创建一个LLM提示，用于统计点击的文档中此类陈述的数量。
- en: We regret that this dataset is not multi-lingual. This is due to the large amount
    of uncertainty and trial-and-error in curating this dataset, which meant frequent
    manual inspection of data. We believe the same framework can be used to construct
    a multi-lingual version of Researchy Questions .
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遗憾地表示，这个数据集不是多语言的。这是因为在策划这个数据集时存在大量的不确定性和反复试验，这意味着需要频繁地进行人工数据检查。我们相信，可以使用相同的框架来构建一个多语言版本的研究性问题数据集。
- en: Ethics Statement
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理声明
- en: We obtained approval to release this dataset after thorough IRB proceedings
    to ensure compliance with privacy, safety, and legal guidelines.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在通过全面的IRB（伦理审查委员会）程序后获得了发布这个数据集的批准，以确保符合隐私、安全和法律准则。
- en: 'We would like to make a few notes: while it may appear that we tried to remove
    queries that seemed “controversial”, it is not our intention to act as moral or
    political regulators to decide if user queries are well-meaning. At the scale
    of web search, one will notice that users ask a lot of questions for a lot of
    reasons, and it is beyond the scope of our job to speculate what the motives are
    behind a query. It *is* is our job to assess whether the act of attempting to
    answer a question will lead to a reasonable risk of harm. Also, it is not the
    case that “GPT-4 is our moral authority” on the topic of safety, it is merely
    one of many tools we employ in a stack to ensure our internal requirements are
    being met.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想做几点说明：尽管表面上看起来我们尝试删除了那些看起来“有争议”的查询，但我们并不打算充当道德或政治的监管者，来决定用户查询是否出于善意。在网络搜索的规模下，人们会注意到用户出于各种原因提出了很多问题，而推测查询背后的动机超出了我们的工作范围。我们*确实*的工作是评估尝试回答问题的行为是否会导致合理的伤害风险。此外，并不是说“GPT-4是我们在安全问题上的道德权威”，它只是我们在确保满足内部要求时所使用的一众工具之一。
- en: References
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Amplayo et al. (2022) Reinald Kim Amplayo, Kellie Webster, Michael Collins,
    Dipanjan Das, and Shashi Narayan. 2022. [Query refinement prompts for closed-book
    long-form question answering](http://arxiv.org/abs/2210.17525).
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amplayo et al. (2022) Reinald Kim Amplayo, Kellie Webster, Michael Collins,
    Dipanjan Das, 和 Shashi Narayan. 2022. [用于封闭书籍长篇问答的查询优化提示](http://arxiv.org/abs/2210.17525)。
- en: Aula and Russell (2008) Anne Aula and Daniel Russell. 2008. Complex and exploratory
    web search.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aula 和 Russell (2008) Anne Aula 和 Daniel Russell. 2008. 复杂和探索性的网页搜索。
- en: 'Bajaj et al. (2018) Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng
    Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen,
    Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. 2018. [Ms
    marco: A human generated machine reading comprehension dataset](http://arxiv.org/abs/1611.09268).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bajaj et al. (2018) Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng
    Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen,
    Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, 和 Tong Wang. 2018. [Ms
    marco：一项人类生成的机器阅读理解数据集](http://arxiv.org/abs/1611.09268)。
- en: Berant et al. (2013) Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang.
    2013. [Semantic parsing on Freebase from question-answer pairs](https://www.aclweb.org/anthology/D13-1160).
    In *Proceedings of the 2013 Conference on Empirical Methods in Natural Language
    Processing*, pages 1533–1544, Seattle, Washington, USA. Association for Computational
    Linguistics.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berant et al. (2013) Jonathan Berant, Andrew Chou, Roy Frostig, 和 Percy Liang.
    2013. [基于问答对的Freebase语义解析](https://www.aclweb.org/anthology/D13-1160)。发表于 *2013年自然语言处理实证方法会议论文集*，第1533–1544页，美国华盛顿州西雅图。计算语言学协会。
- en: Bolotova et al. (2022) Valeriia Bolotova, Vladislav Blinov, Falk Scholer, W. Bruce
    Croft, and Mark Sanderson. 2022. [A non-factoid question-answering taxonomy](https://doi.org/10.1145/3477495.3531926).
    In *Proceedings of the 45th International ACM SIGIR Conference on Research and
    Development in Information Retrieval*, SIGIR ’22, page 1196–1207, New York, NY,
    USA. Association for Computing Machinery.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolotova et al. (2022) Valeriia Bolotova, Vladislav Blinov, Falk Scholer, W.
    Bruce Croft, 和 Mark Sanderson. 2022. [非事实性问答分类法](https://doi.org/10.1145/3477495.3531926)。发表于
    *第45届国际ACM SIGIR信息检索研究与开发会议论文集*，SIGIR '22，第1196–1207页，美国纽约。计算机协会。
- en: 'Bolotova-Baranova et al. (2023) Valeriia Bolotova-Baranova, Vladislav Blinov,
    Sofya Filippova, Falk Scholer, and Mark Sanderson. 2023. [WikiHowQA: A comprehensive
    benchmark for multi-document non-factoid question answering](https://doi.org/10.18653/v1/2023.acl-long.290).
    In *Proceedings of the 61st Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers)*, pages 5291–5314, Toronto, Canada. Association
    for Computational Linguistics.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bolotova-Baranova et al. (2023) Valeriia Bolotova-Baranova, Vladislav Blinov,
    Sofya Filippova, Falk Scholer, 和 Mark Sanderson. 2023. [WikiHowQA：一个综合性的多文档非事实性问答基准](https://doi.org/10.18653/v1/2023.acl-long.290)。发表于
    *第61届计算语言学协会年会论文集（第1卷：长篇论文）*，第5291–5314页，加拿大多伦多。计算语言学协会。
- en: Borgeaud et al. (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick,
    Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer,
    Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero,
    Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. 2022. [Improving
    language models by retrieving from trillions of tokens](http://arxiv.org/abs/2112.04426).
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Borgeaud 等人 (2022) Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor
    Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste
    Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick,
    Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer,
    Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero,
    Karen Simonyan, Jack W. Rae, Erich Elsen 和 Laurent Sifre. 2022. [通过从万亿级标记中检索来提升语言模型](http://arxiv.org/abs/2112.04426)。
- en: Bu et al. (2010) Fan Bu, Xingwei Zhu, Yu Hao, and Xiaoyan Zhu. 2010. [Function-based
    question classification for general QA](https://aclanthology.org/D10-1109). In
    *Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing*,
    pages 1119–1128, Cambridge, MA. Association for Computational Linguistics.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bu 等人 (2010) Fan Bu, Xingwei Zhu, Yu Hao 和 Xiaoyan Zhu. 2010. [基于功能的问答分类方法](https://aclanthology.org/D10-1109)。收录于*2010年自然语言处理实证方法会议论文集*，第1119–1128页，剑桥,
    MA。计算语言学学会。
- en: 'Campos et al. (2016) Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia
    Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, and Bhaskar Mitra.
    2016. [Ms marco: A human generated machine reading comprehension dataset](https://api.semanticscholar.org/CorpusID:1289517).
    *ArXiv*, abs/1611.09268.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Campos 等人 (2016) Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia Song,
    Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng 和 Bhaskar Mitra. 2016.
    [Ms marco: 一个人类生成的机器阅读理解数据集](https://api.semanticscholar.org/CorpusID:1289517)。*ArXiv*，abs/1611.09268。'
- en: 'Chen et al. (2020) Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang,
    and William Yang Wang. 2020. [HybridQA: A dataset of multi-hop question answering
    over tabular and textual data](https://doi.org/10.18653/v1/2020.findings-emnlp.91).
    In *Findings of the Association for Computational Linguistics: EMNLP 2020*, pages
    1026–1036, Online. Association for Computational Linguistics.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等人 (2020) Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang
    和 William Yang Wang. 2020. [HybridQA: 一个针对表格和文本数据的多跳问答数据集](https://doi.org/10.18653/v1/2020.findings-emnlp.91)。收录于*计算语言学学会发现:
    EMNLP 2020*，第1026–1036页，线上出版。计算语言学学会。'
- en: 'Dohmatob et al. (2024) Elvis Dohmatob, Yunzhen Feng, Pu Yang, Francois Charton,
    and Julia Kempe. 2024. [A tale of tails: Model collapse as a change of scaling
    laws](http://arxiv.org/abs/2402.07043).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dohmatob 等人 (2024) Elvis Dohmatob, Yunzhen Feng, Pu Yang, Francois Charton 和
    Julia Kempe. 2024. [尾部的故事：模型崩溃作为缩放法则的变化](http://arxiv.org/abs/2402.07043)。
- en: 'Dunn et al. (2017) Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney,
    Volkan Cirik, and Kyunghyun Cho. 2017. [Searchqa: A new q&a dataset augmented
    with context from a search engine](http://arxiv.org/abs/1704.05179).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dunn 等人 (2017) Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan
    Cirik 和 Kyunghyun Cho. 2017. [Searchqa: 一个通过搜索引擎上下文增强的全新问答数据集](http://arxiv.org/abs/1704.05179)。'
- en: Everitt (1974) Brian Everitt. 1974. *Cluster analysis*. Heinemann Educational
    [for] the Social Science Research Council.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Everitt (1974) Brian Everitt. 1974. *聚类分析*。Heinemann 教育出版社 [为] 社会科学研究委员会出版。
- en: 'Fan et al. (2019) Angela Fan, Yacine Jernite, Ethan Perez, David Grangier,
    Jason Weston, and Michael Auli. 2019. [ELI5: long form question answering](https://doi.org/10.18653/v1/p19-1346).
    In *Proceedings of the 57th Conference of the Association for Computational Linguistics,
    ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers*, pages
    3558–3567\. Association for Computational Linguistics.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fan 等人 (2019) Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason
    Weston 和 Michael Auli. 2019. [ELI5: 长篇问答系统](https://doi.org/10.18653/v1/p19-1346)。收录于*第57届计算语言学学会年会论文集,
    ACL 2019, 意大利佛罗伦萨, 2019年7月28日-8月2日, 第1卷: 长篇论文*，第3558–3567页。计算语言学学会。'
- en: 'Gao et al. (2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis
    Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn
    Presser, and Connor Leahy. 2020. [The pile: An 800gb dataset of diverse text for
    language modeling](http://arxiv.org/abs/2101.00027).'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao 等人 (2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis
    Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn
    Presser 和 Connor Leahy. 2020. [The pile: 一个包含800GB多样文本数据的语言建模数据集](http://arxiv.org/abs/2101.00027)。'
- en: Gur et al. (2023) Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari,
    Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. 2023. [A real-world webagent
    with planning, long context understanding, and program synthesis](http://arxiv.org/abs/2307.12856).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gur 等人（2023）Izzeddin Gur、Hiroki Furuta、Austin Huang、Mustafa Safdari、Yutaka Matsuo、Douglas
    Eck 和 Aleksandra Faust。2023年。[A real-world webagent with planning, long context
    understanding, and program synthesis](http://arxiv.org/abs/2307.12856)。
- en: 'Guu et al. (2020) Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and
    Ming-Wei Chang. 2020. [Realm: Retrieval-augmented language model pre-training](http://arxiv.org/abs/2002.08909).'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guu 等人（2020）Kelvin Guu、Kenton Lee、Zora Tung、Panupong Pasupat 和 Ming-Wei Chang。2020年。[Realm:
    Retrieval-augmented language model pre-training](http://arxiv.org/abs/2002.08909)。'
- en: Hassan et al. (2014) Ahmed Hassan, Ryen W. White, Susan T. Dumais, and Yi-Min
    Wang. 2014. [Struggling or exploring? disambiguating long search sessions](https://doi.org/10.1145/2556195.2556221).
    In *Proceedings of the 7th ACM International Conference on Web Search and Data
    Mining*, WSDM ’14, page 53–62, New York, NY, USA. Association for Computing Machinery.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan 等人（2014）Ahmed Hassan、Ryen W. White、Susan T. Dumais 和 Yi-Min Wang。2014年。[Struggling
    or exploring? disambiguating long search sessions](https://doi.org/10.1145/2556195.2556221)。在
    *Proceedings of the 7th ACM International Conference on Web Search and Data Mining*，WSDM
    ’14，页面53–62，纽约，NY，USA。计算机协会。
- en: Hassan Awadallah et al. (2014) Ahmed Hassan Awadallah, Ryen W. White, Patrick
    Pantel, Susan T. Dumais, and Yi-Min Wang. 2014. [Supporting complex search tasks](https://doi.org/10.1145/2661829.2661912).
    In *Proceedings of the 23rd ACM International Conference on Conference on Information
    and Knowledge Management*, CIKM ’14, page 829–838, New York, NY, USA. Association
    for Computing Machinery.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassan Awadallah 等人（2014）Ahmed Hassan Awadallah、Ryen W. White、Patrick Pantel、Susan
    T. Dumais 和 Yi-Min Wang。2014年。[Supporting complex search tasks](https://doi.org/10.1145/2661829.2661912)。在
    *Proceedings of the 23rd ACM International Conference on Conference on Information
    and Knowledge Management*，CIKM ’14，页面829–838，纽约，NY，USA。计算机协会。
- en: 'Izacard and Grave (2021) Gautier Izacard and Edouard Grave. 2021. [Leveraging
    passage retrieval with generative models for open domain question answering](https://doi.org/10.18653/v1/2021.eacl-main.74).
    In *Proceedings of the 16th Conference of the European Chapter of the Association
    for Computational Linguistics: Main Volume*, pages 874–880, Online. Association
    for Computational Linguistics.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Izacard 和 Grave（2021）Gautier Izacard 和 Edouard Grave。2021年。[Leveraging passage
    retrieval with generative models for open domain question answering](https://doi.org/10.18653/v1/2021.eacl-main.74)。在
    *Proceedings of the 16th Conference of the European Chapter of the Association
    for Computational Linguistics: Main Volume*，页面874–880，在线。计算语言学协会。'
- en: Jiang et al. (2024) Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
    Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas,
    Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
    Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep
    Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut
    Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024. [Mixtral of
    experts](http://arxiv.org/abs/2401.04088).
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang 等人（2024）Albert Q. Jiang、Alexandre Sablayrolles、Antoine Roux、Arthur Mensch、Blanche
    Savary、Chris Bamford、Devendra Singh Chaplot、Diego de las Casas、Emma Bou Hanna、Florian
    Bressand、Gianna Lengyel、Guillaume Bour、Guillaume Lample、Lélio Renard Lavaud、Lucile
    Saulnier、Marie-Anne Lachaux、Pierre Stock、Sandeep Subramanian、Sophia Yang、Szymon
    Antoniak、Teven Le Scao、Théophile Gervet、Thibaut Lavril、Thomas Wang、Timothée Lacroix
    和 William El Sayed。2024年。[Mixtral of experts](http://arxiv.org/abs/2401.04088)。
- en: Johnson et al. (2019) Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Billion-scale
    similarity search with GPUs. *IEEE Transactions on Big Data*, 7(3):535–547.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Johnson 等人（2019）Jeff Johnson、Matthijs Douze 和 Hervé Jégou。2019年。亿级相似度搜索与 GPU。*IEEE
    Transactions on Big Data*，7(3):535–547。
- en: 'Joshi et al. (2017) Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer.
    2017. [triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading
    Comprehension](http://arxiv.org/abs/1705.03551). *arXiv e-prints*, page arXiv:1705.03551.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Joshi 等人（2017）Mandar Joshi、Eunsol Choi、Daniel Weld 和 Luke Zettlemoyer。2017年。[triviaqa:
    A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension](http://arxiv.org/abs/1705.03551)。*arXiv
    e-prints*，页面 arXiv:1705.03551。'
- en: Kahneman (2011) Daniel Kahneman. 2011. *Thinking, Fast and Slow*. Farrar, Straus
    and Giroux, New York.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kahneman（2011）Daniel Kahneman。2011年。*Thinking, Fast and Slow*。Farrar, Straus
    and Giroux，纽约。
- en: Karpukhin et al. (2020) Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick
    Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen tau Yih. 2020. [Dense passage
    retrieval for open-domain question answering](http://arxiv.org/abs/2004.04906).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpukhin 等人（2020）Vladimir Karpukhin、Barlas Oğuz、Sewon Min、Patrick Lewis、Ledell
    Wu、Sergey Edunov、Danqi Chen 和 Wen tau Yih。2020年。[Dense passage retrieval for open-domain
    question answering](http://arxiv.org/abs/2004.04906)。
- en: Kelly et al. (2015) Diane Kelly, Jaime Arguello, Ashlee Edwards, and Wan-ching
    Wu. 2015. [Development and evaluation of search tasks for iir experiments using
    a cognitive complexity framework](https://doi.org/10.1145/2808194.2809465). In
    *Proceedings of the 2015 International Conference on The Theory of Information
    Retrieval*, ICTIR ’15, page 101–110, New York, NY, USA. Association for Computing
    Machinery.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kelly 等人（2015）Diane Kelly、Jaime Arguello、Ashlee Edwards 和 Wan-ching Wu。2015年。[基于认知复杂性框架的
    IIR 实验搜索任务的开发与评估](https://doi.org/10.1145/2808194.2809465)。收录于*2015年国际信息检索理论会议论文集*，ICTIR
    '15，第101–110页，美国纽约，计算机学会。
- en: 'Khattab et al. (2023) Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David
    Hall, Percy Liang, Christopher Potts, and Matei Zaharia. 2023. [Demonstrate-search-predict:
    Composing retrieval and language models for knowledge-intensive nlp](http://arxiv.org/abs/2212.14024).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Khattab 等人（2023）Omar Khattab、Keshav Santhanam、Xiang Lisa Li、David Hall、Percy
    Liang、Christopher Potts 和 Matei Zaharia。2023年。[Demonstrate-search-predict: 将检索和语言模型结合用于知识密集型NLP](http://arxiv.org/abs/2212.14024)。'
- en: 'Khot et al. (2023) Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle
    Richardson, Peter Clark, and Ashish Sabharwal. 2023. [Decomposed prompting: A
    modular approach for solving complex tasks](http://arxiv.org/abs/2210.02406).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khot 等人（2023）Tushar Khot、Harsh Trivedi、Matthew Finlayson、Yao Fu、Kyle Richardson、Peter
    Clark 和 Ashish Sabharwal。2023年。[分解式提示：一种解决复杂任务的模块化方法](http://arxiv.org/abs/2210.02406)。
- en: Krishna et al. (2021) Kalpesh Krishna, Aurko Roy, and Mohit Iyyer. 2021. [Hurdles
    to progress in long-form question answering](http://arxiv.org/abs/2103.06332).
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krishna 等人（2021）Kalpesh Krishna、Aurko Roy 和 Mohit Iyyer。2021年。[长文本问答中的进展障碍](http://arxiv.org/abs/2103.06332)。
- en: 'Kulkarni et al. (2020) Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, and
    Eugene Ie. 2020. [Aquamuse: Automatically generating datasets for query-based
    multi-document summarization](http://arxiv.org/abs/2010.12694).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kulkarni 等人（2020）Sayali Kulkarni、Sheide Chammas、Wan Zhu、Fei Sha 和 Eugene Ie。2020年。[Aquamuse:
    自动生成用于查询式多文档摘要的数据集](http://arxiv.org/abs/2010.12694)。'
- en: 'Kwiatkowski et al. (2019) Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield,
    Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin,
    Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones,
    Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural
    questions: a benchmark for question answering research. *Transactions of the Association
    of Computational Linguistics*.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kwiatkowski 等人（2019）Tom Kwiatkowski、Jennimaria Palomaki、Olivia Redfield、Michael
    Collins、Ankur Parikh、Chris Alberti、Danielle Epstein、Illia Polosukhin、Matthew Kelcey、Jacob
    Devlin、Kenton Lee、Kristina N. Toutanova、Llion Jones、Ming-Wei Chang、Andrew Dai、Jakob
    Uszkoreit、Quoc Le 和 Slav Petrov。2019年。Natural questions: 一个用于问答研究的基准。*计算语言学会会刊*。'
- en: Lewis et al. (2021) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim
    Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2021. [Retrieval-augmented generation
    for knowledge-intensive nlp tasks](http://arxiv.org/abs/2005.11401).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 等人（2021）Patrick Lewis、Ethan Perez、Aleksandra Piktus、Fabio Petroni、Vladimir
    Karpukhin、Naman Goyal、Heinrich Küttler、Mike Lewis、Wen tau Yih、Tim Rocktäschel、Sebastian
    Riedel 和 Douwe Kiela。2021年。[增强生成检索用于知识密集型NLP任务](http://arxiv.org/abs/2005.11401)。
- en: 'Li et al. (2023) Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan
    Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Alpacaeval:
    An automatic evaluator of instruction-following models. [https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval).'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人（2023）Xuechen Li、Tianyi Zhang、Yann Dubois、Rohan Taori、Ishaan Gulrajani、Carlos
    Guestrin、Percy Liang 和 Tatsunori B. Hashimoto。2023年。Alpacaeval: 一种自动评估指令跟随模型的工具。[https://github.com/tatsu-lab/alpaca_eval](https://github.com/tatsu-lab/alpaca_eval)。'
- en: 'Liu et al. (2023a) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023a. [Lost in the middle:
    How language models use long contexts](http://arxiv.org/abs/2307.03172).'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023a）Nelson F. Liu、Kevin Lin、John Hewitt、Ashwin Paranjape、Michele Bevilacqua、Fabio
    Petroni 和 Percy Liang。2023a年。[迷失在中间：语言模型如何使用长上下文](http://arxiv.org/abs/2307.03172)。
- en: Liu et al. (2023b) Nelson F. Liu, Tianyi Zhang, and Percy Liang. 2023b. [Evaluating
    verifiability in generative search engines](http://arxiv.org/abs/2304.09848).
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023b）Nelson F. Liu、Tianyi Zhang 和 Percy Liang。2023b年。[评估生成式搜索引擎中的可验证性](http://arxiv.org/abs/2304.09848)。
- en: 'Liu et al. (2023c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023c. [Agentbench: Evaluating llms
    as agents](http://arxiv.org/abs/2308.03688).'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2023c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, 和 Jie Tang. 2023c. [Agentbench: 评估 LLM 作为代理的能力](http://arxiv.org/abs/2308.03688)。'
- en: 'Mialon et al. (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas
    Wolf, Yann LeCun, and Thomas Scialom. 2023. [Gaia: a benchmark for general ai
    assistants](http://arxiv.org/abs/2311.12983).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mialon 等人 (2023) Grégoire Mialon, Clémentine Fourrier, Craig Swift, Thomas
    Wolf, Yann LeCun, 和 Thomas Scialom. 2023. [Gaia: 一个通用 AI 助手的基准测试](http://arxiv.org/abs/2311.12983)。'
- en: 'Nakano et al. (2022) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,
    Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,
    William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
    Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. [Webgpt: Browser-assisted
    question-answering with human feedback](http://arxiv.org/abs/2112.09332).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nakano 等人 (2022) Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long
    Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William
    Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button,
    Matthew Knight, Benjamin Chess, 和 John Schulman. 2022. [Webgpt: 基于浏览器的问答系统，结合人工反馈](http://arxiv.org/abs/2112.09332)。'
- en: OpenAI et al. (2023) OpenAI, :, Josh Achiam, Steven Adler, Sandhini Agarwal,
    Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello, Jake
    Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg
    Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage,
    Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea
    Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen,
    Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu,
    Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux,
    Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling,
    Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus,
    Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie
    Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes,
    Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane
    Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton,
    Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon
    Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn
    Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto,
    Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider,
    Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina
    Kim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,
    Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen
    Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung,
    Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin,
    Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning,
    Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew,
    Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina,
    Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie
    Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David
    Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard
    Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe
    Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita,
    Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres,
    Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass,
    Vitchyr Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul
    Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra
    Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli,
    Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr,
    John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah
    Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin,
    Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher,
    Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak,
    Madeleine Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle,
    Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya,
    Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan
    Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian
    Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong,
    Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo,
    Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang,
    Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2023.
    [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 等人（2023）OpenAI，:，Josh Achiam，Steven Adler，Sandhini Agarwal，Lama Ahmad，Ilge
    Akkaya，Florencia Leoni Aleman，Diogo Almeida，Janko Altenschmidt，Sam Altman，Shyamal
    Anadkat，Red Avila，Igor Babuschkin，Suchir Balaji，Valerie Balcom，Paul Baltescu，Haiming
    Bao，Mo Bavarian，Jeff Belgum，Irwan Bello，Jake Berdine，Gabriel Bernadett-Shapiro，Christopher
    Berner，Lenny Bogdonoff，Oleg Boiko，Madelaine Boyd，Anna-Luisa Brakman，Greg Brockman，Tim
    Brooks，Miles Brundage，Kevin Button，Trevor Cai，Rosie Campbell，Andrew Cann，Brittany
    Carey，Chelsea Carlson，Rory Carmichael，Brooke Chan，Che Chang，Fotis Chantzis，Derek
    Chen，Sully Chen，Ruby Chen，Jason Chen，Mark Chen，Ben Chess，Chester Cho，Casey Chu，Hyung
    Won Chung，Dave Cummings，Jeremiah Currier，Yunxing Dai，Cory Decareaux，Thomas Degry，Noah
    Deutsch，Damien Deville，Arka Dhar，David Dohan，Steve Dowling，Sheila Dunning，Adrien
    Ecoffet，Atty Eleti，Tyna Eloundou，David Farhi，Liam Fedus，Niko Felix，Simón Posada
    Fishman，Juston Forte，Isabella Fulford，Leo Gao，Elie Georges，Christian Gibson，Vik
    Goel，Tarun Gogineni，Gabriel Goh，Rapha Gontijo-Lopes，Jonathan Gordon，Morgan Grafstein，Scott
    Gray，Ryan Greene，Joshua Gross，Shixiang Shane Gu，Yufei Guo，Chris Hallacy，Jesse
    Han，Jeff Harris，Yuchen He，Mike Heaton，Johannes Heidecke，Chris Hesse，Alan Hickey，Wade
    Hickey，Peter Hoeschele，Brandon Houghton，Kenny Hsu，Shengli Hu，Xin Hu，Joost Huizinga，Shantanu
    Jain，Shawn Jain，Joanne Jang，Angela Jiang，Roger Jiang，Haozhun Jin，Denny Jin，Shino
    Jomoto，Billie Jonn，Heewoo Jun，Tomer Kaftan，Łukasz Kaiser，Ali Kamali，Ingmar Kanitscheider，Nitish
    Shirish Keskar，Tabarak Khan，Logan Kilpatrick，Jong Wook Kim，Christina Kim，Yongjik
    Kim，Hendrik Kirchner，Jamie Kiros，Matt Knight，Daniel Kokotajlo，Łukasz Kondraciuk，Andrew
    Kondrich，Aris Konstantinidis，Kyle Kosic，Gretchen Krueger，Vishal Kuo，Michael Lampe，Ikai
    Lan，Teddy Lee，Jan Leike，Jade Leung，Daniel Levy，Chak Ming Li，Rachel Lim，Molly Lin，Stephanie
    Lin，Mateusz Litwin，Theresa Lopez，Ryan Lowe，Patricia Lue，Anna Makanju，Kim Malfacini，Sam
    Manning，Todor Markov，Yaniv Markovski，Bianca Martin，Katie Mayer，Andrew Mayne，Bob
    McGrew，Scott Mayer McKinney，Christine McLeavey，Paul McMillan，Jake McNeil，David
    Medina，Aalok Mehta，Jacob Menick，Luke Metz，Andrey Mishchenko，Pamela Mishkin，Vinnie
    Monaco，Evan Morikawa，Daniel Mossing，Tong Mu，Mira Murati，Oleg Murk，David Mély，Ashvin
    Nair，Reiichiro Nakano，Rajeev Nayak，Arvind Neelakantan，Richard Ngo，Hyeonwoo Noh，Long
    Ouyang，Cullen O’Keefe，Jakub Pachocki，Alex Paino，Joe Palermo，Ashley Pantuliano，Giambattista
    Parascandolo，Joel Parish，Emy Parparita，Alex Passos，Mikhail Pavlov，Andrew Peng，Adam
    Perelman，Filipe de Avila Belbute Peres，Michael Petrov，Henrique Ponde de Oliveira
    Pinto，Michael，Pokorny，Michelle Pokrass，Vitchyr Pong，Tolly Powell，Alethea Power，Boris
    Power，Elizabeth Proehl，Raul Puri，Alec Radford，Jack Rae，Aditya Ramesh，Cameron Raymond，Francis
    Real，Kendra Rimbach，Carl Ross，Bob Rotsted，Henri Roussez，Nick Ryder，Mario Saltarelli，Ted
    Sanders，Shibani Santurkar，Girish Sastry，Heather Schmidt，David Schnurr，John Schulman，Daniel
    Selsam，Kyla Sheppard，Toki Sherbakov，Jessica Shieh，Sarah Shoker，Pranav Shyam，Szymon
    Sidor，Eric Sigler，Maddie Simens，Jordan Sitkin，Katarina Slama，Ian Sohl，Benjamin
    Sokolowsky，Yang Song，Natalie Staudacher，Felipe Petroski Such，Natalie Summers，Ilya
    Sutskever，Jie Tang，Nikolas Tezak，Madeleine Thompson，Phil Tillet，Amin Tootoonchian，Elizabeth
    Tseng，Preston Tuggle，Nick Turley，Jerry Tworek，Juan Felipe Cerón Uribe，Andrea Vallone，Arun
    Vijayvergiya，Chelsea Voss，Carroll Wainwright，Justin Jay Wang，Alvin Wang，Ben Wang，Jonathan
    Ward，Jason Wei，CJ Weinmann，Akila Welihinda，Peter Welinder，Jiayi Weng，Lilian Weng，Matt
    Wiethoff，Dave Willner，Clemens Winter，Samuel Wolrich，Hannah Wong，Lauren Workman，Sherwin
    Wu，Jeff Wu，Michael Wu，Kai Xiao，Tao Xu，Sarah Yoo，Kevin Yu，Qiming Yuan，Wojciech
    Zaremba，Rowan Zellers，Chong Zhang，Marvin Zhang，Shengjia Zhao，Tianhao Zheng，Juntang
    Zhuang，William Zhuk 和 Barret Zoph。2023年。[GPT-4技术报告](http://arxiv.org/abs/2303.08774)。
- en: 'Overwijk et al. (2022) Arnold Overwijk, Chenyan Xiong, Xiao Liu, Cameron VandenBerg,
    and Jamie Callan. 2022. [Clueweb22: 10 billion web documents with visual and semantic
    information](http://arxiv.org/abs/2211.15848).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Overwijk 等人（2022）Arnold Overwijk, Chenyan Xiong, Xiao Liu, Cameron VandenBerg
    和 Jamie Callan. 2022. [Clueweb22：具备视觉和语义信息的100亿网页文档](http://arxiv.org/abs/2211.15848).
- en: Peng et al. (2023) Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and
    Jianfeng Gao. 2023. Instruction tuning with gpt-4. *arXiv preprint arXiv:2304.03277*.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peng 等人（2023）Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley 和 Jianfeng
    Gao. 2023. 基于 GPT-4 的指令调优。*arXiv 预印本 arXiv:2304.03277*.
- en: Press et al. (2023) Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A.
    Smith, and Mike Lewis. 2023. [Measuring and narrowing the compositionality gap
    in language models](http://arxiv.org/abs/2210.03350).
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Press 等人（2023）Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith
    和 Mike Lewis. 2023. [衡量并缩小语言模型中的组合差距](http://arxiv.org/abs/2210.03350).
- en: Radhakrishnan et al. (2023) Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol
    Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion,
    Kamilė Lukošiūtė, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch,
    Sam McCandlish, Sheer El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran,
    Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. Bowman, and Ethan Perez.
    2023. [Question decomposition improves the faithfulness of model-generated reasoning](http://arxiv.org/abs/2307.11768).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radhakrishnan 等人（2023）Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol Chen,
    Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion,
    Kamilė Lukošiūtė, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch,
    Sam McCandlish, Sheer El Showk, Tamera Lanham, Tim Maxwell, Venkatesa Chandrasekaran,
    Zac Hatfield-Dodds, Jared Kaplan, Jan Brauner, Samuel R. Bowman 和 Ethan Perez.
    2023. [问题分解提升模型生成推理的忠实度](http://arxiv.org/abs/2307.11768).
- en: Raffel et al. (2023) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
    Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2023. [Exploring
    the limits of transfer learning with a unified text-to-text transformer](http://arxiv.org/abs/1910.10683).
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel 等人（2023）Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan
    Narang, Michael Matena, Yanqi Zhou, Wei Li 和 Peter J. Liu. 2023. [探索统一文本到文本的转换器在迁移学习中的极限](http://arxiv.org/abs/1910.10683).
- en: 'Ren et al. (2023) Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao
    She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. 2023. [Rocketqav2: A joint training
    method for dense passage retrieval and passage re-ranking](http://arxiv.org/abs/2110.07367).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 等人（2023）Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She,
    Hua Wu, Haifeng Wang 和 Ji-Rong Wen. 2023. [Rocketqav2：一种联合训练密集文档检索和文档重排序的方法](http://arxiv.org/abs/2110.07367).
- en: Shao et al. (2023) Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan
    Duan, and Weizhu Chen. 2023. [Enhancing retrieval-augmented large language models
    with iterative retrieval-generation synergy](http://arxiv.org/abs/2305.15294).
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shao 等人（2023）Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan 和
    Weizhu Chen. 2023. [通过迭代检索-生成协同增强检索增强的大型语言模型](http://arxiv.org/abs/2305.15294).
- en: Stayton (2015) C. T. Stayton. 2015. [What does convergent evolution mean? the
    interpretation of convergence and its implications in the search for limits to
    evolution](https://doi.org/10.1098/rsfs.2015.0039). *Interface Focus*, 5(6):20150039.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stayton（2015）C. T. Stayton. 2015. [收敛进化意味着什么？收敛的解释及其在寻找进化极限中的意义](https://doi.org/10.1098/rsfs.2015.0039).
    *Interface Focus*, 5(6):20150039.
- en: Taleb (2008) Nassim Nicholas Taleb. 2008. *The Black Swan*. Penguin Books, Harlow,
    England.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Taleb（2008）Nassim Nicholas Taleb. 2008. *黑天鹅*。企鹅出版社，哈罗英国。
- en: 'Trivedi et al. (2022) Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
    and Ashish Sabharwal. 2022. MuSiQue: Multihop questions via single-hop question
    composition. *Transactions of the Association for Computational Linguistics*.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trivedi 等人（2022）Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot 和 Ashish
    Sabharwal. 2022. MuSiQue：通过单跳问题组成实现的多跳问题。*计算语言学会会刊*。
- en: Trivedi et al. (2023) Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,
    and Ashish Sabharwal. 2023. [Interleaving retrieval with chain-of-thought reasoning
    for knowledge-intensive multi-step questions](http://arxiv.org/abs/2212.10509).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trivedi 等人（2023）Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot 和 Ashish
    Sabharwal. 2023. [通过链式推理与检索交替进行知识密集型多步问题解答](http://arxiv.org/abs/2212.10509).
- en: 'United States Congress et al. (1981) House Committee on Science United States Congress,
    Subcommittee on Space Science Technology, and Applications. 1981. *NASA Program
    Management and Procurement Procedures and Practices: Hearings Before the Subcommittee
    on Space Science and Applications of the Committee on Science and Technology,
    U.S. House of Representatives, Ninety-seventh Congress, First Session*. U.S. Government
    Printing Office, Washington, D.C.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 美国国会等（1981）美国国会科学委员会，太空科学技术与应用小组委员会. 1981. *NASA项目管理与采购程序和实践：美国众议院科技委员会太空科学与应用小组委员会听证会，九十七届国会第一次会议*.
    美国政府印刷办公室，华盛顿特区.
- en: Wei et al. (2023) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
    Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023. [Chain-of-thought prompting
    elicits reasoning in large language models](http://arxiv.org/abs/2201.11903).
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏等人（2023）魏杰森，王学智，达尔·舒尔曼，马尔滕·博斯马，布赖恩·伊赫特，夏飞，艾德·池，李国，和周丹尼. 2023. [思维链提示在大型语言模型中引发推理](http://arxiv.org/abs/2201.11903).
- en: 'Wu et al. (2023a) Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and
    Hong Lin. 2023a. [Ai-generated content (aigc): A survey](http://arxiv.org/abs/2304.06632).'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人（2023a）吴佳扬，甘文生，陈泽峰，万世程，和林鸿. 2023a. [AI生成内容（AIGC）：一项综述](http://arxiv.org/abs/2304.06632).
- en: 'Wu et al. (2023b) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W White, Doug Burger, and Chi Wang. 2023b. [Autogen: Enabling next-gen llm
    applications via multi-agent conversation](http://arxiv.org/abs/2308.08155).'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人（2023b）吴青云，班吉恩·巴萨尔，张杰宇，吴怡然，李贝宾，朱尔康，江利，张晓云，张少坤，刘嘉乐，艾哈迈德·哈桑·阿瓦达拉，瑞恩·W·怀特，道格·伯格，和王驰.
    2023b. [AutoGen：通过多智能体对话启用下一代大型语言模型应用](http://arxiv.org/abs/2308.08155).
- en: Xiong et al. (2020) Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin
    Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2020. [Approximate nearest
    neighbor negative contrastive learning for dense text retrieval](http://arxiv.org/abs/2007.00808).
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熊等人（2020）熊李，熊陈延，李烨，邝丰唐，刘嘉麟，保罗·本内特，贾奈德·艾哈迈德，和阿诺德·欧威克. 2020. [用于密集文本检索的近似最近邻负对比学习](http://arxiv.org/abs/2007.00808).
- en: 'Yang et al. (2018) Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W.
    Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. [Hotpotqa: A dataset
    for diverse, explainable multi-hop question answering](http://arxiv.org/abs/1809.09600).'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人（2018）杨志霖，齐鹏，张赛正，约书亚·本吉奥，威廉·W·科恩，鲁斯兰·萨拉库丁诺夫，和克里斯托弗·D·曼宁. 2018. [Hotpotqa：一个多样化、可解释的多跳问答数据集](http://arxiv.org/abs/1809.09600).
- en: 'Yao et al. (2023a) Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L.
    Griffiths, Yuan Cao, and Karthik Narasimhan. 2023a. [Tree of thoughts: Deliberate
    problem solving with large language models](http://arxiv.org/abs/2305.10601).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姚等人（2023a）姚顺宇，余典，赵杰弗里，伊扎克·沙弗兰，托马斯·L·格里菲斯，曹元，和卡尔提克·纳拉西曼. 2023a. [思维树：通过大型语言模型进行深思熟虑的问题解决](http://arxiv.org/abs/2305.10601).
- en: 'Yao et al. (2023b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2023b. [React: Synergizing reasoning and acting
    in language models](http://arxiv.org/abs/2210.03629).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姚等人（2023b）姚顺宇，赵杰弗里，余典，杜楠，伊扎克·沙弗兰，卡尔提克·纳拉西曼，和曹元. 2023b. [React：语言模型中的推理与行动协同](http://arxiv.org/abs/2210.03629).
- en: Yuan et al. (2024) Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Xian Li,
    Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. 2024. [Self-rewarding language
    models](http://arxiv.org/abs/2401.10020).
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 袁等人（2024）袁伟哲，庞元哲，赵庆贤，李闲，苏巴尔·苏赫巴托尔，徐静，和杰森·韦斯顿. 2024. [自奖励语言模型](http://arxiv.org/abs/2401.10020).
- en: 'Zhang et al. (2023) Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, and
    Shen Huang. 2023. [Beam retrieval: General end-to-end retrieval for multi-hop
    question answering](http://arxiv.org/abs/2308.08973).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2023）张嘉豪，张海洋，张冬梅，刘勇，和黄申. 2023. [Beam检索：用于多跳问答的通用端到端检索](http://arxiv.org/abs/2308.08973).
- en: Zhang et al. (2016) Xiang Zhang, Junbo Zhao, and Yann LeCun. 2016. [Character-level
    convolutional networks for text classification](http://arxiv.org/abs/1509.01626).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2016）张向，赵俊波，和Yann LeCun. 2016. [字符级卷积网络用于文本分类](http://arxiv.org/abs/1509.01626).
- en: 'Zhang et al. (2021) Yi Zhang, Sujay Kumar Jauhar, Julia Kiseleva, Ryen White,
    and Dan Roth. 2021. [Learning to decompose and organize complex tasks](https://doi.org/10.18653/v1/2021.naacl-main.217).
    In *Proceedings of the 2021 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, pages 2726–2735,
    Online. Association for Computational Linguistics.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2021）张毅、Sujay Kumar Jauhar、Julia Kiseleva、Ryen White 和 Dan Roth。2021。 [学习分解和组织复杂任务](https://doi.org/10.18653/v1/2021.naacl-main.217)。收录于
    *2021年北美计算语言学会年会：人类语言技术会议论文集*，第2726-2735页，在线版。计算语言学协会。
- en: Zheng et al. (2023a) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023a. [Judging llm-as-a-judge with
    mt-bench and chatbot arena](http://arxiv.org/abs/2306.05685).
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郑等人（2023a）郑炼民、蒋威霖、盛颖、庄思源、吴张昊、庄永浩、林子、李卓涵、李大成、Eric P. Xing、张浩、Joseph E. Gonzalez
    和 Ion Stoica。2023a。 [使用 mt-bench 和聊天机器人竞技场评判 LLM 作为评审官](http://arxiv.org/abs/2306.05685)。
- en: Zheng et al. (2023b) Shen Zheng, Jie Huang, and Kevin Chen-Chuan Chang. 2023b.
    [Why does chatgpt fall short in providing truthful answers?](http://arxiv.org/abs/2304.10513)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郑等人（2023b）郑昕、黄杰、Kevin Chen-Chuan Chang。2023b。 [为什么 ChatGPT 在提供真实答案时会失败？](http://arxiv.org/abs/2304.10513)
- en: Zhou et al. (2023) Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen, Wayne Xin
    Zhao, Xu Chen, Yankai Lin, Ji-Rong Wen, and Jiawei Han. 2023. [Don’t make your
    llm an evaluation benchmark cheater](http://arxiv.org/abs/2311.01964).
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周等人（2023）周坤、朱宇涛、陈志鹏、陈文彤、赵晓阳、陈旭、林彦凯、温基荣和韩家威。2023。 [不要让你的LLM成为评估基准作弊者](http://arxiv.org/abs/2311.01964)。
- en: Appendix A GPT-4-based Filtering Details
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A GPT-4基础过滤详情
- en: '![Refer to caption](img/886ecbdfb3e3cbf82b2051e0814b11ff.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/886ecbdfb3e3cbf82b2051e0814b11ff.png)'
- en: 'Figure 2: (Right) Histogram of number of documents clicked per question for
    Researchy Questions which is much higher than for general web search queries.
    (Left) number of queries associated with each document. The fact that not very
    many queries are associated with each document validates the effectiveness of
    our query-deduplication procedure.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：（右）研究性问题每个问题点击的文档数量的直方图，明显高于一般网页搜索查询。（左）与每个文档相关的查询数量。每个文档关联的查询数量并不多，验证了我们的查询去重程序的有效性。
- en: '![Refer to caption](img/ea7d5f5c3d6e2c4e5a4b878eed8de29d.png)![Refer to caption](img/f3c6870d3b31034a803fd7bacd7806a9.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ea7d5f5c3d6e2c4e5a4b878eed8de29d.png)![参考标题](img/f3c6870d3b31034a803fd7bacd7806a9.png)'
- en: 'Figure 3: (Left) Non-factoid scores of the 15.7M QnA Queries. The roughly 1M
    queries whose score exceeded the threshold +0.75 were sent to the Decompositional
    classifier. Note that because this was a binary classifier, 89% of the non-factoid
    scores were less than -0.75, which is cut off from the left-hand histogram to
    make it easier to visualize. (Right) The Decompositional classifier’s scores of
    the roughly 1M Non-factoid queries. Around 146k queries exceeding the 0.6 threshold
    line resulted are considered both Non-factoid and Decompositional, and were then
    de-duplicated to arrive at the final Researchy Questions dataset of around 100k.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：（左）15.7M问答查询的非事实型得分。大约100万个得分超过+0.75的查询被发送到分解分类器。注意，由于这是一个二分类器，89%的非事实型得分小于-0.75，因此左侧的直方图被裁剪，以便更容易可视化。（右）分解分类器对大约100万个非事实型查询的得分。大约146k个超过0.6阈值的查询被认为既是非事实型又是分解型，随后进行了去重，最终得到了约10万个研究性问题数据集。
- en: '| Question | Factoid | Decompositional ($\downarrow$) |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | 事实型 | 分解型（$\downarrow$） |'
- en: '| --- | --- | --- |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Why is it illegal to destroy money | 1.02 | 0.59 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 为什么毁掉钱是非法的 | 1.02 | 0.59 |'
- en: '| Which law firms offer the best opportunities for international work? | 1.07
    | 0.58 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 哪些律师事务所提供最佳的国际工作机会？ | 1.07 | 0.58 |'
- en: '| How should a grad student communicate with faculty | 0.80 | 0.56 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 研究生应该如何与导师沟通 | 0.80 | 0.56 |'
- en: '| How does a short story differ from a novel | 1.07 | 0.54 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 短篇小说与小说有何不同 | 1.07 | 0.54 |'
- en: '| Why is Beowulf an important literary work | 1.10 | 0.51 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 为什么《贝奥武夫》是一部重要的文学作品 | 1.10 | 0.51 |'
- en: '| Why are e scooters illegal | 0.90 | 0.50 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 为什么电动滑板车是非法的 | 0.90 | 0.50 |'
- en: '| Why did the declaration of independence start | 1.12 | 0.49 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 为什么独立宣言开始了 | 1.12 | 0.49 |'
- en: '| How did marsupials evolve | 1.02 | 0.48 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 有袋动物是如何进化的 | 1.02 | 0.48 |'
- en: '| Is turbulence dangerous | 0.97 | 0.47 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 湍流危险吗 | 0.97 | 0.47 |'
- en: '| Why do people cut down the Amazon rainforest | 1.09 | 0.45 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 为什么人们砍伐亚马逊雨林 | 1.09 | 0.45 |'
- en: '| Why are flags at half mast in Indiana today | 1.06 | 0.45 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 为什么今天印第安纳州的旗帜降半旗 | 1.06 | 0.45 |'
- en: '| Why the houses in Rajasthan have thick walls and flat roofs? | 1.06 | 0.43
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 为什么拉贾斯坦的房屋有厚厚的墙壁和平顶？ | 1.06 | 0.43 |'
- en: '| How do forensic pathologists determine cause and manner of death? | 1.02
    | 0.43 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 法医病理学家如何确定死亡的原因和方式？ | 1.02 | 0.43 |'
- en: '| What causes changes in the moon’s appearance | 1.10 | 0.41 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 什么原因导致月亮外观的变化 | 1.10 | 0.41 |'
- en: '| How did Edgar Allan Poe start his writing career | 0.97 | 0.40 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 埃德加·爱伦·坡是如何开始他的写作生涯的 | 0.97 | 0.40 |'
- en: '| How common was vasectomy in the 1950’s | 0.90 | 0.40 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 在1950年代，结扎手术有多普遍 | 0.90 | 0.40 |'
- en: '| Why are behavioral questions important | 0.79 | 0.38 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 为什么行为问题很重要 | 0.79 | 0.38 |'
- en: '| Is pepper spray harmful | 0.93 | 0.37 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 胡椒喷雾有害吗 | 0.93 | 0.37 |'
- en: '| How do fertilizers increase productivity | 1.05 | 0.35 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 肥料如何提高生产力 | 1.05 | 0.35 |'
- en: '| How do we get matter and energy from food | 1.11 | 0.32 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 我们如何从食物中获取物质和能量 | 1.11 | 0.32 |'
- en: '| What type of competition occurs when only a few firms dominate a market?
    | 1.08 | 0.31 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 当只有少数几家公司主导一个市场时，发生什么类型的竞争？ | 1.08 | 0.31 |'
- en: '| Why can’t waves travel through a vacuum? | 1.08 | 0.30 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 为什么波浪无法通过真空传播？ | 1.08 | 0.30 |'
- en: '| What caused the Dixie fire | 0.84 | 0.29 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 是什么导致了迪克西大火 | 0.84 | 0.29 |'
- en: '| Why camels live in desert | 1.02 | 0.29 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 为什么骆驼生活在沙漠中 | 1.02 | 0.29 |'
- en: '| How was COVID-19 discovered | 0.92 | 0.28 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| COVID-19是如何被发现的 | 0.92 | 0.28 |'
- en: '| How are elements organized into groups | 0.96 | 0.27 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 元素是如何组织成组的 | 0.96 | 0.27 |'
- en: '| Why did Montezuma give the Spanish gold? | 1.01 | 0.27 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 为什么蒙特祖玛给西班牙人黄金？ | 1.01 | 0.27 |'
- en: '| Differences between debt and equity financing | 0.98 | 0.27 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 债务和股本融资的区别 | 0.98 | 0.27 |'
- en: '| How are fossils older than 60,000 years dated? | 1.08 | 0.17 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 如何对超过60,000年的化石进行年代测定？ | 1.08 | 0.17 |'
- en: '| What happens when a data collision occurs on an Ethernet bus? | 1.03 | 0.16
    |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 当以太网总线发生数据碰撞时会发生什么？ | 1.03 | 0.16 |'
- en: '| How is gold formed in the earth’s crust | 0.98 | 0.12 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 黄金是如何在地壳中形成的 | 0.98 | 0.12 |'
- en: 'Table 6: Examples of QnA Queries that were non-factoid (had a non-factoid classifier
    score above 0.75), but were not decompositional (had decompositional classifier
    score less than 0.6). Further down this list, more of the examples have a single
    correct answer (even if it is somewhat long-form), but there is obviously a lot
    of gray area, highlighting the challenges of trying to filter large amounts of
    queries by simple thresholds.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：一些非事实性（非事实性分类器得分超过0.75）但非分解性（分解性分类器得分低于0.6）的问答查询示例。在这个列表的下方，更多的示例有一个单一的正确答案（即使它稍显冗长），但显然有许多灰色地带，突显了通过简单阈值筛选大量查询时的挑战。
- en: For the following (Question | score | reason) triples, the score indicates how
    "good" of a non-factoid question they are in the sense that they can lead to interesting
    and in-depth analysis.
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对于以下的（问题 | 分数 | 原因）三元组，分数表示它们作为非事实性问题的“优质”程度，即它们能够引发有趣且深入的分析。
- en: 'Definition: A good non-factoid question is specific, with potential to amount
    to a good research report with a clear and refutable thesis, supported by evidence
    and analysis.'
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义：一个优质的非事实性问题是具体的，具有发展成一份好的研究报告的潜力，报告中有清晰且可反驳的论点，并得到证据和分析的支持。
- en: 'Characteristic formats of good non-factoid questions (not exhaustive):'
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优质非事实性问题的特征格式（并非详尽无遗）：
- en: •
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Good non-factoid questions will often talk about the relationship between two
    things, e.g. "Compare and contrast X and Y", "How/why does X affect/impact Y?",
    "Why X is significant to Y", or "What role does X play in Y?", or "to what extent
    does X lead to Y?", etc.
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 优质的非事实性问题通常会讨论两者之间的关系，例如“比较并对比X与Y”，“X如何/为什么影响/作用于Y？”，“为什么X对Y重要”或“X在Y中的作用是什么？”，或者“X在多大程度上导致Y？”等。
- en: •
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: A good non-factoid question can also ask "Why does X happen", "What factors
    play a role in X?", "How is X significant" or "What is the cause of X", but it
    should be specific about what kind of analysis is expected.
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个优质的非事实性问题还可以问“为什么X会发生”，“哪些因素在X中发挥作用？”，“X的重要性是什么”或“X的原因是什么”，但它应该明确预期什么样的分析。
- en: •
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Other forms of good non-factoid questions can ask about the pros/cons, benefits/detriments
    of something, or compare/contrast two things, etc.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其他优质非事实性问题的形式可以是询问某物的优缺点、益处/害处，或比较/对比两件事物等。
- en: 'Instructions: Rate each question on a scale of 0-10, where 0 is a factoid question
    and 10 is an excellent non-factoid question and then provide a brief reason for
    your rating'
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 说明：根据0-10的评分标准对每个问题进行评分，其中0是事实性问题，10是优秀的非事实性问题，并简要说明你的评分理由。
- en: 'Q: how tall is abraham lincoln | 0 | factoid'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 问：亚伯拉罕·林肯有多高？ | 0 | 小知识
- en: 'Q: can i change the weather | 2 | personal question'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 问：我可以改变天气吗？ | 2 | 个人问题
- en: 'Q: was the civil war fought over slavery | 5 | fair, but could more directly
    ask about other important facets of the causes of the civil war and their role
    in the conflict'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 问：美国内战是为了解决奴隶制问题而爆发的吗？ | 5 | 合理，但可以更直接地询问内战原因的其他重要方面及其在冲突中的作用
- en: 'Q: to what extent was the civil war fought over slavery | 8 | good, will lead
    to in-depth analysis on the causes of the civil war'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 问：内战在多大程度上是为了奴隶制而打的？ | 8 | 很好，将引发对内战原因的深入分析
- en: 'Q: what impact do human activities have on the weather | 10 | excellent, many
    in-depth reports written to answer this question'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 问：人类活动对天气有何影响？ | 10 | 极好，已有许多深入报告回答这个问题
- en: 'Q: should LA invest more in railway or highway infrastructure for public transport
    | 9 | great'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 问：洛杉矶应该在铁路还是公路基础设施上投入更多资金来改善公共交通？ | 9 | 很好
- en: 'Q: what is an example of blackbody radiation? | 0 | asking for an example'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 问：什么是黑体辐射的例子？ | 0 | 请求一个例子
- en: 'Q: could not determine type for | 0 | not a question'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 问：无法确定类型 | 0 | 不是一个问题
- en: 'Q: what typically signals the end of the olympic games | 2 | factoid, olympic
    closing ceremony can be looked up easily'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 问：奥林匹克运动会通常由什么标志性事件结束 | 2 | 小知识，奥林匹克闭幕式可以轻松查找
- en: 'Q: Why were Navajo code talkers used during WW2? | 7 | good, could lead to
    analysis of how culture and language can be used in warfare'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么在第二次世界大战期间使用了纳瓦霍密码讲解员？ | 7 | 很好，可能引发对文化和语言如何在战争中使用的分析
- en: 'Q: When does protein folding begin? | 1 | has a single, known correct answer'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 问：蛋白质折叠从何时开始？ | 1 | 有一个已知的正确答案
- en: 'Q: what is the cost and necessary materials to build a refinery | 5 | fair,
    asks about a complex process but will not likely elicit analysis'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 问：建造炼油厂的成本和必要材料是什么 | 5 | 合理，询问一个复杂的过程，但不太可能引发深度分析
- en: 'Q: What is the Navavidha Bhakti? | 0 | asking for a definition'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 问：什么是Navavidha Bhakti？ | 0 | 请求定义
- en: 'Q: why is technological change bad? | 5 | fair, but could be more specific'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么技术变革是坏事？ | 5 | 合理，但可以更具体
- en: 'Q: analyze how technological changes have historically impacted cultures |
    10 | excellent, very specific'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 问：分析技术变革如何历史性地影响文化 | 10 | 极好，非常具体
- en: 'Q: who owns phone number 280-626-1435 | 0 | personally identifiable information'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 问：谁拥有电话号码280-626-1435 | 0 | 个人可识别信息
- en: 'Q: What are the main differences between regulations of the NFL and the CFL?
    | 4 | has potential for in-depth analysis but doesn’t explicitly ask for it'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 问：NFL和CFL的规章制度有何主要区别？ | 4 | 有潜力进行深入分析，但没有明确要求
- en: 'Q: Why do planes using rivets & not welded construction? | 7 | good, will require
    in-depth analysis on aerospace technology'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 问：为什么飞机使用铆钉而不是焊接结构？ | 7 | 很好，需要对航空技术进行深入分析
- en: 'Q: How did the Catholic Pope manage to become more powerful than Kings in old
    Europe? | 9 | much potential for historical analysis'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 问：天主教教皇是如何在古欧洲成为比国王更有权力的？ | 9 | 有很大的历史分析潜力
- en: 'Q: interesting facts about korea | 0 | not specific'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 问：关于韩国的有趣事实 | 0 | 不具体
- en: 'Q: {Question} |'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 问：{问题} |
- en: 'Figure 4: Prompt given to text-davinci-003 to collect labels of whether a question
    is non-factoid. The current question is substituted at the end. Labels on 1-10
    were binarized based to train the non-factoid classifier.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：给text-davinci-003的提示，用于收集问题是否是非事实性的问题的标签。当前问题在最后替换。1到10的标签基于二元化方法训练非事实性分类器。
- en: 'Question: {Question}'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 问：{问题} |
- en: 'Instructions: how clearly does the above question require sub-questions in
    order to answer it? Think silently about how complex or multi-facted the question
    is. Imagine you are a person trying to answer the question using a search engine
    like Google. Would the person likely have to issue multiple queries to arrive
    at a comprehensive answer? Would they need to exert more effort to fully understand
    the nuances behind the question, or different perspectives surrounding it? etc.
    Or, is the person likely to find the best answer with a single search with low
    effort? Give your rating on 1-100 between <score> and </score> tags, where 1 means
    the question is trivial or common knowledge, while 100 means it likely involves
    effort to break the question down into many sub-questions or facets. <score>'
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指示：上述问题需要多少子问题才能清晰地回答？静下心来思考这个问题有多复杂或多面向。想象一下你是一个试图使用像 Google 这样的搜索引擎来回答这个问题的人。这个人是否可能需要发出多个查询才能得出一个全面的答案？他们是否需要花更多的精力去完全理解问题背后的细微差别或不同的视角？等等。或者，这个人是否可能通过一次低难度的搜索就能找到最好的答案？请在
    `<score>` 和 `</score>` 标签之间给出你的评分，1代表问题是微不足道的或是常识，而100则意味着这个问题可能需要努力将其分解成多个子问题或多个方面。
- en: 'Figure 5: Prompt given to gpt-35-turbo to collect labels of how appropriate
    a question is for “decomposition” into sub-questions. These labels were used to
    train the Decompositional classifier.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：给 gpt-35-turbo 提供的提示，用于收集关于一个问题是否适合“分解”为子问题的标签。这些标签用于训练分解性分类器。
- en: '![Refer to caption](img/96b1417ce8dd5326cfa7913d88b77aa5.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/96b1417ce8dd5326cfa7913d88b77aa5.png)'
- en: 'Figure 6: We had GPT-4 label all 102k Researchy question – and a uniform sample
    of 2k Natural Questions – along 8 dimensions using the prompt in Figure [7](https://arxiv.org/html/2402.17896v1#A1.F7
    "Figure 7 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A
    Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents").
    Each dimension was on a scale of 1-10; we plot their normalized densities. For
    Researchy Questions, these are the scores of the final 96k released questions
    after final filtering described in Section [2.5](https://arxiv.org/html/2402.17896v1#S2.SS5
    "2.5 Stage 5: Final GPT-4 Filtering ‣ 2 Researchy Questions Construction ‣ Researchy
    Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web
    Agents"). Lower scores are better for Ambiguity, Incompleteness, Assumptiveness
    and Harmfulness. We intended Researchy Questions to have higher scores for Knowledge-intensiveness,
    Reasoning-intensiveness and Multi-facetedness.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：我们让 GPT-4 给所有 102k 个 Researchy 问题打标签——以及 2k 个自然问题的统一样本——并使用图[7](https://arxiv.org/html/2402.17896v1#A1.F7
    "图7 ‣ 附录A GPT-4 基于过滤的细节 ‣ Researchy 问题：一个多视角、分解性问题数据集用于 LLM Web 代理")中的提示，沿着8个维度进行标注。每个维度的评分范围是1-10；我们绘制了它们的归一化密度图。对于
    Researchy 问题，这些是经过第[2.5节](https://arxiv.org/html/2402.17896v1#S2.SS5 "2.5 第5阶段：最终
    GPT-4 过滤 ‣ 2 Researchy 问题构建 ‣ Researchy 问题：一个多视角、分解性问题数据集用于 LLM Web 代理")描述的最终过滤后的
    96k 问题的分数。对于歧义性、不完整性、假设性和有害性，较低的分数表示更好。我们希望 Researchy 问题在知识密集性、推理密集性和多面性方面有更高的分数。
- en: 'We had GPT-4 label certain attributes of each Researchy Question using the
    prompt given in Figure [7](https://arxiv.org/html/2402.17896v1#A1.F7 "Figure 7
    ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset of
    Multi-Perspective, Decompositional Questions for LLM Web Agents"). Particularly,
    we focus on removing questions that were too incomplete or underspecified to meaningfully
    answer (shown in Table [7](https://arxiv.org/html/2402.17896v1#A1.T7 "Table 7
    ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset of
    Multi-Perspective, Decompositional Questions for LLM Web Agents")), or those that
    are too presumptuous (shown in Table  [8](https://arxiv.org/html/2402.17896v1#A1.T8
    "Table 8 ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset
    of Multi-Perspective, Decompositional Questions for LLM Web Agents")). Incomplete
    queries could arise when users ask queries that e.g. refer to previous queries
    or subjects in their session.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '我们让 GPT-4 根据图 [7](https://arxiv.org/html/2402.17896v1#A1.F7 "Figure 7 ‣ Appendix
    A GPT-4-based Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective,
    Decompositional Questions for LLM Web Agents") 中给出的提示标签化每个“Researchy Question”的某些属性。特别地，我们重点移除那些过于不完整或不明确、无法有意义地回答的问题（如表
    [7](https://arxiv.org/html/2402.17896v1#A1.T7 "Table 7 ‣ Appendix A GPT-4-based
    Filtering Details ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional
    Questions for LLM Web Agents") 所示），或那些过于假设性的问题（如表 8 所示）。不完整的查询可能出现在用户提问时，比如他们提到之前的查询或会话中的某些主题。'
- en: '| how can climate change | why did the market crash |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 气候变化如何影响我们 | 为什么市场崩溃 |'
- en: '| --- | --- |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| are perspectives that change when presented with fresh experiences | how
    did the war for independence end |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 观点在接触新经验后发生变化 | 独立战争是如何结束的 |'
- en: '| in what ways did native peoples transform | how dangeous can a persona affect
    a person personality |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 土著人民是如何转变的 | 人物塑造如何影响一个人的个性 |'
- en: '| how would the law treat the issues confronting a diverse family? | how did
    president lyndon b. johnson respond to this event? |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 法律将如何处理面临多元家庭问题的情况？ | 林登·B·约翰逊总统如何回应这一事件？ |'
- en: '| compare and contrast social contract | what is the difference in how the
    government reacted in these two situations? |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 比较和对比社会契约 | 政府在这两种情况下的反应有何不同？ |'
- en: '| how were others influenced by miyamoto | explain why summers were difficult
    for europeans. |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 他人是如何受到宫本茂影响的 | 解释为什么欧洲的夏季如此艰难。 |'
- en: '| what effect did the recent looting have on emigration | what is the main
    reason why some teams never reach stage 4 |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 最近的掠夺对移民产生了什么影响 | 为什么一些队伍永远无法进入第四阶段 |'
- en: 'Table 7: Examples of incomplete or ambiguous queries a.k.a too underspecified
    to attempt to answer meaningfully (roughly 3% of queries in the last stage of
    filtering) that were removed from the dataset by additional GPT-4 filtering.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 7：示例——那些不完整或含糊不清的查询，即那些过于不明确，无法尝试有意义地回答的问题（大约占最后筛选阶段查询的 3%），这些问题被通过额外的 GPT-4
    筛选从数据集中移除。
- en: '| how college became a ruthless competition divorced from learning | why is
    airline customer service so bad |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 大学如何变成了一场与学习脱节的无情竞争 | 为什么航空公司客户服务如此差 |'
- en: '| --- | --- |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| why are police departments afraid of change | why immigration is bad for
    the us |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 为什么警察部门害怕变革 | 为什么移民对美国不利 |'
- en: '| why did chinese families not desire to have female children? | why do games
    make people socially disconnected from people |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 为什么中国家庭不愿意有女性孩子？ | 为什么游戏让人们在人际关系上变得疏离？ |'
- en: '| why are catholics democrats | why junior doctors are treated so badly |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 为什么天主教徒是民主党人 | 为什么年轻医生遭遇如此差待遇 |'
- en: '| how casinos have ruined towns | why should zoos be shut down |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 赌场如何毁掉了城镇 | 为什么动物园应该关闭 |'
- en: '| how is the government controlling us | why rehabilitation does not work in
    america |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 政府如何控制我们 | 为什么美国的康复治疗不起作用 |'
- en: '| why veganism is bad for animals | why most clinical research is not useful
    |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 为什么素食主义对动物不好 | 为什么大多数临床研究没什么用 |'
- en: 'Table 8: Examples of “presumptious” queries we removed from the dataset (roughly
    2% of queries in the last stage of filtering), roughly defined as those where
    the question is slanted or biased in some way. Note, not all assumptive queries
    were harmful.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 8：我们从数据集中移除的“过于假设性”的查询示例（大约占最后筛选阶段查询的 2%），粗略定义为那些提问方式存在偏向或倾斜的情况。请注意，并非所有假设性查询都是有害的。
- en: 'Given the question: {Question}'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 给定问题：{Question}
- en: 'Instructions: Please output a python dictionary with fields scoring the question
    on the following criteria:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 说明：请输出一个Python字典，包含根据以下标准对问题评分的字段：
- en: '1.'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: '"ambiguous" : Int 0-10 to what extent is the intent of the question ambiguous
    (has more than one interpretation); 0 means no major ambiguity. Not to be confused
    with subjectiveness or incompleteness.'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"模糊性"：整数0-10，表示问题意图的模糊程度（有多个解释）；0表示没有重大模糊性。不要与主观性或不完整性混淆。'
- en: '2.'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: '"incompleteness" : Int 0-10 indicating how difficult it is to determine the
    intent of the question, whether it is missing crucial context or details that
    ought to be specified in order to answer the question; 0 means the question is
    answerable and self-contained, 10 means the question is un-answerable because
    it is incomplete or under-specified.'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"不完整性"：整数0-10，表示判断问题意图的难度，问题是否缺少关键的背景或细节，这些背景或细节是回答问题时必须明确的；0表示问题是可回答且自足的，10表示问题由于不完整或描述不明确而无法回答。'
- en: '3.'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: '"assumptive" : Int 0-10 the degree to which the question has built-in assumptions
    or biases (that are not offensive, which is point 8 below); 0 means no notable
    or unreasonable assumptions.'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"假设性"：整数0-10，表示问题中内嵌假设或偏见的程度（这些假设或偏见不是冒犯性的，下面第8点会提到）；0表示没有明显或不合理的假设。'
- en: '4.'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: '"multi-faceted" : Int 0-10 the degree to which the question has multiple facets
    or perspectives that need to be considered in order to answer it; 0 means the
    question is straightforward and has a single, undisputed answer.'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"多方面性"：整数0-10，表示问题需要考虑多个方面或视角才能回答的程度；0表示问题直接且有单一、无争议的答案。'
- en: '5.'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: '"knowledge-intensive" : Int 0-10 the degree to which the question would require
    specialized knowledge (like textbooks, scholarly articles, etc) to provide a thorough
    and grounded answer; 0 means the answer is common knowledge or can be looked up
    instantly in common references, 10 means the questions probably entails a lot
    of work to find and analyze specialized knowledge.'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"知识密集型"：整数0-10，表示问题需要专门知识（如教科书、学术文章等）才能提供全面且有根据的答案的程度；0表示答案是常识或可以在常见参考资料中迅速查到，10表示该问题可能需要大量工作来查找和分析专门的知识。'
- en: '6.'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: '"subjective" : Int 0-10 the degree to which the question is subjective, meaning
    an answer(s) exist, but there is no agreed-upon way to determine which one is
    better; 0 means the question is largely objective i.e. the overwhelming majority
    of people would agree on the answer if they knew it.'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"主观性"：整数0-10，表示问题的主观性程度，即问题有答案，但没有公认的方式来确定哪个答案更好；0表示问题大体上是客观的，即如果大多数人知道了问题，他们会达成一致的答案。'
- en: '7.'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: '"reasoning-intensive" : Int 0-10 the degree to which the question requires
    reasoning to synthesize an answer; 0 means the question can be answered trivially
    e.g. by looking up a fact, referencing an encyclopedia or database, or using a
    calculator (once).'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"推理密集型"：整数0-10，表示问题需要推理才能得出答案的程度；0表示问题可以通过简单查找事实、参考百科全书或数据库，或者使用计算器（一次）得到答案。'
- en: '8.'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '8.'
- en: '"harmful" : Int 0-10 to what extent the question could be interpreted as being
    harmful (physically or psychologically to oneself, others, or animals), offensive,
    overly biased, sexually explicit, or otherwise inappropriate for e.g. someone
    of the age of 12 to be exposed to.'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"有害性"：整数0-10，表示问题可能被解读为有害的程度（对自己、他人或动物的身体或心理造成伤害、冒犯性、过度偏见、性暗示或其他不适宜某些年龄段（如12岁）接触的内容）。'
- en: Note that the above criteria are not mutually exclusive, e.g. a question can
    be both subjective and knowledge-intensive, for example "is capitalism better
    than socialism" would be both. Make sure to output only the valid python dictionary
    without comments or other extraneous output.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，以上标准并非互斥的，例如一个问题可以既是主观的，也需要大量的知识。例如，“资本主义是否优于社会主义”就是两者兼有的情况。确保仅输出有效的Python字典，不要包含注释或其他多余的输出。
- en: 'Figure 7: Prompt given to GPT-4 to classify attributes of each of the Researchy
    Questions. The output labels were used to further filter the data for release.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：给GPT-4的提示，要求对每个研究性问题的属性进行分类。输出标签用于进一步筛选数据以供发布。
- en: A.1 Additional Safety Filtering
  id: totrans-384
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 额外的安全过滤
- en: In addition to the official offensiveness/adult query classifiers used in our
    commericial search engine, we also had GPT-4 label on a scale of 1-10 “to what
    extent the question could be interpreted as being harmful (physically or psychologically
    to oneself, others, or animals), offensive, overly biased, sexually explicit,
    or otherwise inappropriate for e.g. someone of the age of 12 to be exposed to.”.
    We found roughly 2% of queries had an unsatisfactory harmfulness score and hence
    were removed from the released dataset.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们商业搜索引擎中使用的官方冒犯/成人查询分类器外，我们还要求GPT-4根据1到10的评分来标记“这个问题在多大程度上可能被解读为对自己、他人或动物造成身体或心理伤害、冒犯、过度偏见、性暗示或其他不适宜例如12岁以下儿童接触的内容”。我们发现大约2%的查询得到了不令人满意的有害评分，因此被从发布的数据集中移除。
- en: 'Table [9](https://arxiv.org/html/2402.17896v1#A1.T9 "Table 9 ‣ A.1 Additional
    Safety Filtering ‣ Appendix A GPT-4-based Filtering Details ‣ Researchy Questions:
    A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents")
    shows some examples of those removed. Real people asked these questions: we acknowledge
    that some of these may be motivated by genuine information-seeking intent, notwithstanding,
    we believe there is too high a risk that the act of answering these questions
    may lead to harm.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 表[9](https://arxiv.org/html/2402.17896v1#A1.T9 "表 9 ‣ A.1 附加安全过滤 ‣ 附录 A 基于GPT-4的过滤详情
    ‣ 研究性问题：LLM Web代理的多视角分解性问题数据集")展示了这些被移除的示例。真实的人提问了这些问题：我们承认其中一些问题可能是出于真正的信息寻求意图，尽管如此，我们认为回答这些问题的行为存在过高的风险，可能会导致伤害。
- en: '| Is it fair to blame younger people for covid spike | How bad is illegal immigration
    |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 归咎于年轻人导致新冠激增是否公平 | 非法移民有多严重 |'
- en: '| --- | --- |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Why do people pretend to be depressed | Why veganism is bad for animals |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 为什么人们假装抑郁 | 为什么素食主义对动物有害 |'
- en: '| what factors affect when deciding to terminate a down sydrome child | Why
    is the business of sex so popular and lucrative? |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 在决定终止唐氏综合症胎儿时，哪些因素会影响决定 | 为什么性交易行业如此受欢迎且有利可图？ |'
- en: '| how people make money illegally | Was the holocaust real? |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 人们如何非法赚钱 | 大屠杀是真的吗？ |'
- en: '| Why was gender queer banned | Which countries persecute christians |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| 为什么性别非二元被禁止 | 哪些国家迫害基督徒 |'
- en: '| Why do so many women get abortions | Was the holocaust worse than slavery
    |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 为什么那么多女性会堕胎 | 大屠杀是否比奴隶制更糟糕 |'
- en: '| Could a small nuclear war reverse global warming | How do holocaust deniers
    try to gain followers? |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 小规模核战争能否逆转全球变暖？ | 大屠杀否认者是如何试图争取追随者的？ |'
- en: '| Is china a threat to world peace | Why christians believe conspiracy theories
    |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 中国是世界和平的威胁吗 | 为什么基督徒相信阴谋论 |'
- en: '| Why do so many incompetent men become leaders | Why did africans sell other
    africans into slavery |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 为什么那么多无能的男人成为领导者 | 为什么非洲人要将其他非洲人卖为奴隶 |'
- en: '| Why is bribery being used to force people to take vaccine | Why were many
    whites scared away from supporting civil rights |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 为什么行贿被用来迫使人们接种疫苗 | 为什么许多白人不愿支持民权 |'
- en: '| What makes a church a cult | Why did poor southerners fight for slavery |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 什么使教堂成为邪教 | 为什么贫困的南方人会为奴隶制而战 |'
- en: '| Are minorities more likely to commit crime | Why isn’t christianity considered
    a cult |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 少数族裔是否更容易犯罪 | 为什么基督教不被视为邪教 |'
- en: '| Why corporal punishment should be legal | Pros and cons of sexism |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 为什么体罚应该合法 | 性别歧视的利与弊 |'
- en: '| Should we stratify people based on intelligence or other specific qualities?
    | Why are we challenged by the arrival of migrants in our country? |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 我们是否应该根据智力或其他特定品质来对人群进行分层？ | 为什么移民的到来会让我们感到挑战？ |'
- en: '| Why are we protecting the unvaccinated | Is the death penalty racially motivated
    |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 我们为何要保护未接种疫苗的人 | 死刑是否具有种族动机 |'
- en: '| Why is bayonetta so sexualized | Why is racial profiling important in society
    |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 为什么贝优妮塔（Bayonetta）被过度性化 | 为什么种族定性在社会中很重要 |'
- en: '| Does islam promote violence | Is affirmative action racism |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 伊斯兰教是否鼓励暴力 | 平权行动是种族主义吗 |'
- en: '| Who is behind mass immigration | Why is the vaccine killing people |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 谁在推动大规模移民 | 为什么疫苗会致人死亡 |'
- en: '| Why is the west so intent in bringing in so many illegal migrants | Why might
    the artist have thought reconstruction was “worse than slavery” for black southerners?
    |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 为什么西方如此执着于引入那么多非法移民 | 为什么艺术家会认为重建对黑人南方人来说“比奴隶制还要糟糕”？ |'
- en: 'Table 9: Here we show some examples of the roughly 2% of queries that were
    removed from the dataset by additional GPT-4 harmfulness filtering.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 表9：这里我们展示了大约2%被额外GPT-4有害性过滤器移除的查询示例。
- en: 'Question: {Question}'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：{问题}
- en: '#####################'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '#####################'
- en: 'Reference Answer (assumed to be true): {ReferenceAnswer}'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 参考答案（假设为真实）：{ReferenceAnswer}
- en: '{CandidateAnswers}'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '{CandidateAnswers}'
- en: '#####################'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '#####################'
- en: 'Keep in mind the following Guidelines when evaluating the Candidate Answers:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估候选答案时，请牢记以下《指南》：
- en: 'Guidelines:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 《指南》：
- en: •
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Usefulness: A useful answer adds value by providing in-depth analysis, actionable
    steps, and relevant information that helps users make informed decisions, complete
    tasks, and understand complex problems in a simpler way. It also considers real-world
    scenarios, cause and effect relationships, and historical context to enhance the
    user’s understanding.'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有用性：一个有用的答案通过提供深入的分析、可操作的步骤和相关信息，帮助用户做出明智的决策、完成任务并以更简单的方式理解复杂问题。它还考虑了现实场景、因果关系和历史背景，以增强用户的理解。
- en: •
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Relevance: A relevant answer directly addresses the question’s intent in a
    sensible and specific manner, without being overly broad, redundant, or distracting.
    It should be clear, on-topic, and provide helpful information tailored to the
    question asked.'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相关性：一个相关的答案直接、具体地回答问题的意图，而不应过于笼统、冗余或分散注意力。它应该简明、紧扣主题，并提供有助于解答问题的相关信息。
- en: •
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Truthfulness in an answer means providing accurate and verifiable information,
    without making false claims, unverifiable statements, or promoting misleading
    information. It should agree with the Reference Answer. Contradicting the Reference
    Answer *must* result in lower score.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 真实性：一个真实的答案应提供准确且可验证的信息，避免做出虚假陈述、无法验证的声明或传播误导性信息。它应该与参考答案一致。如果与参考答案相矛盾，*必须*降低评分。
- en: •
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Groundedness in an answer means providing information supported by reliable
    sources and following a logical chain of reasoning, instilling confidence in its
    accuracy. The answer should be based on credible evidence, address uncertainties,
    and avoid relying on personal opinions, rumors, or hearsay.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 依据性：一个有依据的答案应提供可靠来源支持的信息，并遵循逻辑推理链条，增强其准确性。答案应基于可信证据，处理不确定性，并避免依赖个人意见、谣言或传闻。
- en: •
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Thoroughness involves considering the full scope of a question, addressing multiple
    perspectives, scenarios, and outcomes, and ensuring all important aspects are
    covered without omission. It requires analyzing pros and cons, empathizing with
    various stakeholders, and addressing different interpretations or facets of a
    question.
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完整性：完整性涉及考虑问题的全部范围，涵盖多个视角、场景和结果，并确保没有遗漏任何重要方面。这要求分析优缺点、同情各方利益，并考虑问题的不同解读或方面。
- en: '##################### Instructions: Above are {NumCandidates} Candidate Answers
    to the Question: {Question}. Please read them carefully along with the Guidelines
    for how to evaluate an answer’s quality. Then:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '##################### 说明：上面是针对问题{Question}的{NumCandidates}个候选答案。请仔细阅读它们，并结合《指南》来评估答案的质量。然后：'
- en: '1.'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Briefly critique each Candidate Answer with respect to the Guidelines, formatted
    in *bullet points* between "<CritiqueX>" and "</CritiqueX>" tags where X is the
    Candidate Answer number. Each bullet is between sub-tags of either <strength>,
    <weakness>, or <missinginfo>. A <strength> is where the Answer makes a good point
    that follows the Guidelines and contributes to a helpful response. A <weakness>
    is where the Answer makes an incorrect, irrelevant, unreasonable or overly broad
    claim that fails to address the full scope of the Question, or otherwise falls
    short of the Guidelines. <missinginfo> is when some key event, facts or other
    material information is omitted but should have included to strengthen the Candidate
    Answer.
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 简要地根据《指南》批评每个候选答案，批评内容以*项目符号*形式呈现在"<CritiqueX>"和"</CritiqueX>"标签之间，其中X是候选答案的编号。每个项目符号位于<strength>、<weakness>或<missinginfo>子标签之间。<strength>是指答案提出了一个符合《指南》并有助于产生有用回应的良好观点。<weakness>是指答案提出了一个不正确、无关、无理或过于笼统的观点，未能全面回答问题，或在某些方面未达到《指南》的要求。<missinginfo>是指缺少一些关键事件、事实或其他重要信息，这些信息本应包含在内，以增强候选答案的有效性。
- en: '2.'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Give a binary correctness score indicating whether each Candidate Answer generally
    agrees with the Reference Answer – "<CorrectX>1</CorrectX>" – or contradicts it
    "<CorrectX>0</CorrectX>", where X is the Candidate Answer number.
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 给出一个二进制正确性评分，指示每个候选答案是否总体上与参考答案一致 – "<CorrectX>1</CorrectX>" – 或者与其相矛盾 "<CorrectX>0</CorrectX>"，其中X是候选答案的编号。
- en: '3.'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Explain which Candidate Answer is better and why, i.e. how well it adheres to
    the Guidelines, between "<Explanation>" and "</Explanation>" tags."
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解释哪一个候选答案更好，以及为什么，即它如何符合指导原则，放在"<Explanation>"和"</Explanation>"标签之间。
- en: '4.'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Finally, score each Candidate Answer on 1-100, where 100 is a perfect Answer
    that aligns with the Guidelines. Indicate the score between "<ScoreX>" and "</ScoreX>"
    tags where X is the Candidate Answer number.
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，给每个候选答案打分，满分为100分，100分表示完全符合指导原则的答案。将分数放在"<ScoreX>"和"</ScoreX>"标签之间，其中X是候选答案的编号。
- en: Make sure to address all {NumCandidates} Candidate Answers. When you are finished,
    conclude your response with "=====".
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 确保回答所有{NumCandidates}候选答案。当完成时，用“=====”结束你的回答。
- en: <Critique1>
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: <Critique1>
- en: 'Figure 8: Prompt given to GPT-4 to act as a “critique-then-score” judge of
    candidate answers side-by-side.'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：给GPT-4的提示，要求其作为“批评-再打分”评审员，针对候选答案进行对比评分。
- en: '| Researchy Question: how does public transport help the economy |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 研究问题：公共交通如何帮助经济 |'
- en: '| --- |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| GPT-4 Turbo Closed-book Answer (2023-07-01-preview) |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 Turbo 闭卷答案 (2023-07-01-preview) |'
- en: '| Public transport provides numerous economic benefits to communities and countries
    as a whole. Here are some of the key ways in which public transportation supports
    economic growth and efficiency: 1. Reduced Congestion Costs: Public transport
    can significantly reduce the number of vehicles on the road, which in turn reduces
    traffic congestion. This leads to a more efficient transportation system and increased
    productivity. 2. Cost Savings for Individuals: Public transport can be more cost-effective
    than owning a private vehicle, leading to increased disposable income for individuals.
    3. Job Creation: Public transport systems create jobs for operation, maintenance,
    and construction, contributing to employment opportunities. 4. Increased Property
    Values: Good public transport connectivity often increases property values, leading
    to higher tax revenues. 5. Environmental Benefits: Public transport reduces the
    number of cars on the road, decreasing air pollution and greenhouse gas emissions.
    6. Tourism: Efficient public transport systems enhance tourism by making it easier
    for tourists to navigate and spend in local economies. 7. Business Productivity:
    Reliable public transport reduces employee tardiness and absenteeism, increasing
    business productivity. 8. Social Inclusion: Public transport provides mobility
    for those without access to private vehicles, allowing for greater workforce participation
    and access to services. 9. Urban Development: Public transport encourages efficient
    land use and can be a catalyst for urban revitalization and development. 10. Energy
    Efficiency: Public transport is more energy-efficient per passenger kilometer
    than private vehicles, contributing to energy security. By providing an affordable
    and efficient alternative to private vehicles, public transport systems can enhance
    the overall economic performance of a region and improve the quality of life for
    its residents. |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 公共交通为社区和整个国家带来了许多经济利益。以下是公共交通支持经济增长和效率的几个关键方式：1. 降低拥堵成本：公共交通可以显著减少道路上的车辆数量，从而减少交通拥堵。这导致运输系统更加高效，生产力也得到提高。2.
    个人节省成本：公共交通比拥有私家车更具成本效益，增加了个人的可支配收入。3. 创造就业机会：公共交通系统为运营、维护和建设提供了工作机会，促进了就业。4.
    提高房地产价值：良好的公共交通连接通常会提升房地产价值，带来更高的税收收入。5. 环境效益：公共交通减少了道路上的汽车数量，降低了空气污染和温室气体排放。6.
    旅游业：高效的公共交通系统通过让游客更容易在当地经济中消费，促进了旅游业的发展。7. 商业生产力：可靠的公共交通减少了员工迟到和缺席，提升了商业生产力。8.
    社会包容：公共交通为没有私家车的人提供了流动性，促进了劳动力的参与和对服务的访问。9. 城市发展：公共交通促进了高效的土地使用，能够成为城市复兴和发展的催化剂。10.
    能源效率：公共交通在每位乘客每公里的能源效率上优于私家车，有助于能源安全。通过提供一种负担得起且高效的替代交通方式，公共交通系统可以提高一个地区的整体经济表现，并改善居民的生活质量。
    |'
- en: '| Mixtral 8x7b Closed-book Answer ([https://stablediffusion.fr/mixtral](https://stablediffusion.fr/mixtral))
    |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| Mixtral 8x7b 闭卷答案 ([https://stablediffusion.fr/mixtral](https://stablediffusion.fr/mixtral))
    |'
- en: '| Public transportation can have a positive impact on the economy in several
    ways: 1. Reduced traffic congestion: Public transportation helps to reduce traffic
    congestion by providing an alternative to driving, which can lead to decreased
    travel times and increased productivity. This can also reduce the need for costly
    road expansion projects. 2. Increased economic activity: Public transportation
    can help to stimulate economic activity by making it easier for people to access
    jobs, shops, and other services. This can lead to increased spending and investment
    in local communities. 3. Lower transportation costs: Public transportation can
    provide a more affordable transportation option for many people, especially those
    who cannot afford to own and maintain a car. This can help to reduce household
    transportation costs and free up money for other expenses. 4. Improved air quality:
    Public transportation can help to reduce air pollution by taking cars off the
    road. This can lead to improved public health and reduced healthcare costs. 5.
    Increased property values: Properties located near public transportation hubs,
    such as train stations and bus stops, often have higher property values than those
    located further away. This can lead to increased tax revenues for local governments.
    6. Job creation: Public transportation agencies and companies create jobs for
    drivers, mechanics, engineers, and other professionals. These jobs can provide
    stable employment and contribute to the local economy. 7. Energy efficiency: Public
    transportation is generally more energy-efficient than individual car travel.
    This can help to reduce dependence on fossil fuels and decrease greenhouse gas
    emissions. Overall, public transportation can play an important role in supporting
    a strong and sustainable economy by providing affordable, efficient, and environmentally-friendly
    transportation options. |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 公共交通可以通过多种方式对经济产生积极影响：1. 减少交通拥堵：公共交通通过提供替代驾车的选择，帮助减少交通拥堵，从而减少旅行时间并提高生产力。这还可以减少对昂贵的道路扩建项目的需求。2.
    增加经济活动：公共交通可以通过方便人们访问工作岗位、商店和其他服务来促进经济活动。这可能导致当地社区消费和投资的增加。3. 降低交通成本：公共交通为许多人，尤其是那些无法负担拥有和维护汽车的人，提供了更实惠的交通选择。这有助于降低家庭交通成本，并将资金释放用于其他开支。4.
    改善空气质量：公共交通通过减少道路上的汽车数量，帮助减少空气污染。这有助于改善公共健康并减少医疗费用。5. 提高房产价值：靠近公共交通枢纽（如火车站和公交车站）的物业通常比远离这些地方的物业具有更高的房产价值。这可能导致地方政府的税收收入增加。6.
    创造就业机会：公共交通机构和公司为司机、机械师、工程师和其他专业人士创造就业机会。这些工作可以提供稳定的就业，并促进地方经济发展。7. 能源效率：公共交通通常比个人汽车出行更具能源效率。这有助于减少对化石燃料的依赖并降低温室气体排放。总体而言，公共交通通过提供负担得起、效率高且环保的交通选择，在支持强大且可持续的经济方面发挥着重要作用。|'
- en: 'Table 10: Closed-book direct answers from GPT-4 and Mixtra 8x7b Jiang et al.
    ([2024](https://arxiv.org/html/2402.17896v1#bib.bib21)) to the Researchy Question
    used in Table [2](https://arxiv.org/html/2402.17896v1#S1.T2 "Table 2 ‣ 1 Introduction
    ‣ Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions
    for LLM Web Agents"). We find these two answers to be strikingly similar (suggesting
    convergent evolution of LLMs), and both paint in very broad strokes an answer
    that isn’t “wrong” but rather, superficial.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 表10：GPT-4与Mixtra 8x7b Jiang等人（[2024](https://arxiv.org/html/2402.17896v1#bib.bib21)）针对表[2](https://arxiv.org/html/2402.17896v1#S1.T2
    "表2 ‣ 1 引言 ‣ 研究性问题：面向LLM网页代理的多角度、分解性问题数据集")中使用的研究问题的闭卷直接答案。我们发现这两个答案非常相似（这表明LLM的趋同进化），两者都给出了一个非常宽泛的回答，虽然不是“错误”，但却显得有些肤浅。
- en: 'Public transportation plays a significant role in boosting the economy in several
    ways:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 公共交通在通过多种方式促进经济发展方面发挥着重要作用：
- en: '1.'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Job Creation: Investment in public transportation can create millions of jobs.
    For instance, every $1 billion invested could create 50,000 jobs [1,2].'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创造就业机会：对公共交通的投资可以创造数百万个就业岗位。例如，每投资10亿美元，可以创造50,000个就业机会[1,2]。
- en: '2.'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Economic Returns: Every $1 invested in public transportation could generate
    $5 in economic returns [1].'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经济回报：每投资1美元于公共交通，可能带来5美元的经济回报[1]。
- en: '3.'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Reduced Traffic Congestion: A well-functioning public transit system reduces
    traffic congestion, leading to more efficient travel and productivity [3].'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 减少交通拥堵：一个运作良好的公共交通系统可以减少交通拥堵，从而提高出行效率和生产力[3]。
- en: '4.'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Economic Growth: Public transportation can shape land use and development patterns,
    stimulate commerce, and increase property values [4].'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 经济增长：公共交通能够塑造土地使用和发展模式，刺激商业活动，并提高房地产价值[4]。
- en: '5.'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: 'Supports Vulnerable Populations: It improves equality, particularly for the
    more vulnerable members of society, by providing them with mobility and access
    to jobs [1].'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 支持弱势群体：通过为社会中更脆弱的成员提供流动性和就业机会，公共交通改善了平等性[1]。
- en: '6.'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: 'Environmental Impact: Public transit helps improve air quality and reduce greenhouse
    gas emissions, contributing to a sustainable future [3].'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 环境影响：公共交通有助于改善空气质量并减少温室气体排放，为可持续的未来作出贡献[3]。
- en: In summary, public transportation is more than just a way to move people around.
    It’s a vehicle for opportunity, equity, and a better quality of life.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，公共交通不仅仅是人们出行的一种方式。它是机会、公平和更高生活质量的载体。
- en: References
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: •
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[1] https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/](https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/)'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[1] https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/](https://www.weforum.org/agenda/2021/04/here-s-why-cities-should-invest-in-public-transport/)'
- en: •
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[2] https://infrastructureusa.org/the-economic-impact-of-public-transportation/](https://infrastructureusa.org/the-economic-impact-of-public-transportation/)'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[2] https://infrastructureusa.org/the-economic-impact-of-public-transportation/](https://infrastructureusa.org/the-economic-impact-of-public-transportation/)'
- en: •
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[3] https://www.ncesc.com/is-public-transit-better-for-the-economy/](https://www.ncesc.com/is-public-transit-better-for-the-economy/)'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[3] https://www.ncesc.com/is-public-transit-better-for-the-economy/](https://www.ncesc.com/is-public-transit-better-for-the-economy/)'
- en: •
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[4] https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf](https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf)'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[4] https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf](https://www.apta.com/wp-content/uploads/Resources/resources/reportsandpublications/Documents/Economic-Recovery-APTA-White-Paper.pdf)'
- en: •
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[5] https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/](https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/)'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[5] https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/](https://profound-tips.com/advice/how-does-public-transportation-help-the-economy/)'
- en: 'Figure 9: A “screenshot” of the output from Bing Chat in precise mode (a.k.a.
    Microsoft Copilot) for the question “how does transportation help the economy”.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：Bing Chat在精确模式下（也称为Microsoft Copilot）对“交通如何帮助经济”的问题的输出“截图”。
- en: 'Comprehensive Research Report: The Role of Transportation in Economic Development'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 综合研究报告：交通在经济发展中的作用
- en: Introduction Transportation is a critical factor in the economic development
    of any region or nation. It serves as the backbone of economic growth, facilitating
    the movement of goods, services, and labor, which are essential for the efficient
    functioning of the economy. This report synthesizes key points from various sources
    to illustrate how transportation contributes to economic prosperity.
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言 交通运输是任何地区或国家经济发展的关键因素。它作为经济增长的支柱，促进货物、服务和劳动力的流动，这些对于经济高效运作至关重要。本报告综合了来自不同来源的要点，以说明交通如何促进经济繁荣。
- en: 'Key Contributions of Transportation to the Economy ## Job Creation and Economic
    Growth Investments in transportation infrastructure, such as public transit, are
    directly linked to job creation and economic growth. For every $1 billion invested
    in transit, an estimated 49,700 to 50,731 jobs can be created, offering a significant
    return on investment ranging from 4 to 1 to as high as 5 to 1 . This investment
    not only supports American jobs and industry but also generates income for local
    businesses and their workers . Moreover, spending on transportation programs creates
    jobs in the short term, particularly in construction, and can stimulate the economy
    .'
  id: totrans-472
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '交通对经济的关键贡献 ## 就业创造和经济增长 对交通基础设施（如公共交通）的投资与就业创造和经济增长直接相关。每投入10亿美元用于交通运输，预计可以创造49,700到50,731个就业机会，投资回报率约为4比1至5比1。这项投资不仅支持美国的就业和工业，还为地方企业及其员工创造收入。此外，交通项目的支出在短期内创造了特别是在建筑行业的就业机会，并能够刺激经济。'
- en: Enhancing Business Productivity and Competitiveness Transportation improvements
    lead to reduced travel times and costs, as well as increased network reliability,
    which in turn enhances business productivity and competitiveness . By reducing
    transport costs, businesses can access higher-quality or lower-cost inputs and
    connect with potential suppliers . This connectivity also allows individuals to
    access a wider range of jobs, thereby participating more fully in the labor market
    .
  id: totrans-473
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提升商业生产力和竞争力 交通改善能够减少旅行时间和成本，并提高网络可靠性，从而提升商业生产力和竞争力。通过降低运输成本，企业可以获得更高质量或更低成本的输入，并与潜在供应商建立联系。这种互联互通也使个人能够获得更广泛的就业机会，从而更充分地参与劳动力市场。
- en: Market Accessibility and Economic Activity An efficient transport system provides
    market accessibility by linking producers and consumers, enabling transactions
    to occur . This linkage is crucial for the economy as transportation accounts
    for a significant portion of the GDP, ranging from 6% to 12% . By offering cost,
    time, and reliability advantages, transportation enables goods to be transported
    over longer distances, fostering economic changes, most of which are positive
    .
  id: totrans-474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 市场可达性与经济活动 高效的交通系统通过连接生产者和消费者，提供市场可达性，使交易能够顺利进行。这种连接对经济至关重要，因为交通占GDP的一个重要部分，通常在6%至12%之间。通过提供成本、时间和可靠性上的优势，交通使货物能够运送更远的距离，促进经济变革，其中大多数是积极的。
- en: Induced Investment and Regeneration Impacts Transportation investments can influence
    the level or location of private sector investment due to improved connectivity
    . These investments can also lead to local economic impacts resulting from an
    improved local image and the attraction of land use development, known as regeneration
    impacts .
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 诱发投资与再生影响 交通投资可以通过改善连接性，影响私营部门投资的水平或位置。这些投资还可以通过改善地方形象和吸引土地使用开发而产生地方经济影响，通常被称为再生影响。
- en: Structural and Developmental Transformations Sustained improvements in transportation,
    along with parallel advancements in information and production technologies and
    institutional structures, can lead to structural and developmental transformations
    within the economy . This demonstrates the dynamic nature of transportation’s
    role in economic development.
  id: totrans-476
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构性和发展性转型 交通的持续改善，以及信息技术、生产技术和制度结构的同步进步，可以导致经济内部的结构性和发展性转型。这展示了交通在经济发展中动态的作用。
- en: Economic Efficiency and Scale An efficient transportation system reduces costs
    across many economic sectors, while an inefficient one increases these costs .
    Moreover, more efficient transport costs less, leading to rising productivity
    and economies of scale, which should cause GDP to rise faster than transport activity
    .
  id: totrans-477
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 经济效率与规模 效率高的交通系统能降低多个经济部门的成本，而低效的交通系统则会增加这些成本。此外，效率更高的交通成本较低，从而提高生产力和规模效益，这应当导致国内生产总值（GDP）增长速度超过运输活动的增长速度。
- en: Influence on Economic Development and Military Strength Transportation activities
    contribute to a nation’s total economic product and strengthen the national or
    regional economy . A well-developed transportation network not only makes markets
    more competitive but also adds to a nation’s military strength .
  id: totrans-478
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对经济发展和军事力量的影响 交通活动有助于一个国家的总经济产出，并增强国家或地区的经济实力。一个发达的交通网络不仅能使市场更具竞争力，还能增强国家的军事力量。
- en: Conclusion Transportation plays a pivotal role in the economic development of
    a country. It is essential for job creation, enhancing business productivity,
    providing market accessibility, inducing investment, and contributing to structural
    transformations. Governments recognize the importance of investing in transportation
    infrastructure as a means to stimulate economic growth and maintain a competitive
    edge in the global market. As such, transportation is not just a means of moving
    people and goods; it is a fundamental driver of economic prosperity.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 结论 交通在国家经济发展中起着至关重要的作用。它对于创造就业、提高商业生产力、提供市场可达性、诱发投资以及推动结构性转型至关重要。各国政府认识到投资交通基础设施的重要性，视其为刺激经济增长并保持全球市场竞争力的手段。因此，交通不仅仅是人员和货物流动的方式，它是推动经济繁荣的根本驱动力。
- en: References
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: •
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Economic Impact of Public Transit. (2019, April 22). American Public Transportation
    Association.](https://www.apta.com/research-technical-resources/economic-impact-of-public-transit/)'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[公共交通的经济影响。（2019年4月22日）。美国公共交通协会.](https://www.apta.com/research-technical-resources/economic-impact-of-public-transit/)'
- en: •
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[The relationship between transport and the economy. (2017, February 13). Greener
    Vision.](https://greener-vision.com/guidance-tool/relationship-between-transport-economy/)'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[交通与经济之间的关系。（2017年2月13日）。Greener Vision.](https://greener-vision.com/guidance-tool/relationship-between-transport-economy/)'
- en: •
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Economic Impact Of Public Transportation Investment. (2019, March 27). American
    Public Transportation Association.](https://www.apta.com/research-technical-resources/research-reports/economic-impact-of-public-transportation-investment/)'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[公共交通投资的经济影响。（2019年3月27日）。美国公共交通协会.](https://www.apta.com/research-technical-resources/research-reports/economic-impact-of-public-transportation-investment/)'
- en: •
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[3.1 – Transportation and Economic Development | The Geography of Transport
    Systems. (2017, December 4). Transport Geography.](https://transportgeography.org/contents/chapter3/transportation-and-economic-development/)'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[3.1 – 交通与经济发展 | 交通系统地理学。（2017年12月4日）。交通地理学.](https://transportgeography.org/contents/chapter3/transportation-and-economic-development/)'
- en: •
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Economic Consequences of Transport Improvements. (2022, October 11). ACCESS
    Magazine.](https://www.accessmagazine.org/spring-2005/economic-consequences-transport-improvements/)'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[交通改善的经济后果。（2022年10月11日）。ACCESS Magazine.](https://www.accessmagazine.org/spring-2005/economic-consequences-transport-improvements/)'
- en: •
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Transportation, Jobs, and Economic Growth. (2018, February 14). ACCESS Magazine.](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[交通、就业与经济增长。（2018年2月14日）。ACCESS Magazine.](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
- en: •
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[Transportation economics | Definition, Importance, & Facts. (1998, September
    8). Britannica.](https://www.britannica.com/money/topic/transportation-economics)'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[交通经济学 | 定义、重要性与事实。（1998年9月8日）。大英百科全书.](https://www.britannica.com/money/topic/transportation-economics)'
- en: •
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[The role of transport in economic development. FutureLearn.](https://www.futurelearn.com/info/courses/what-is-economics-in-the-world-of-global-logistics/0/steps/95653)'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[交通在经济发展中的作用。FutureLearn.](https://www.futurelearn.com/info/courses/what-is-economics-in-the-world-of-global-logistics/0/steps/95653)'
- en: 'Figure 10: A “screenshot” of the output from YouPro Research engine for the
    query “how does transportation help the economy”. [https://you.com/search?q=how+does+transportation+help+the+economy](https://you.com/search?q=how+does+transportation+help+the+economy)'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：来自YouPro Research引擎的“截图”，查询为“交通如何帮助经济”。[https://you.com/search?q=how+does+transportation+help+the+economy](https://you.com/search?q=how+does+transportation+help+the+economy)
- en: 'Query #1 - how does transportation help the economy'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #1 - 交通如何帮助经济？'
- en: 'Query #2 - How does transportation infrastructure affect economic growth?'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #2 - 交通基础设施如何影响经济增长？'
- en: 'Query #3 - What are the long-term effects of transportation investments?'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #3 - 交通投资的长期效应是什么？'
- en: 'Query #4 - How does transportation contribute to GDP?'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #4 - 交通如何促进GDP增长？'
- en: 'Query #5 - What are the environmental impacts of transportation?'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #5 - 交通的环境影响是什么？'
- en: 'Query #6 - How does transportation affect urban planning and development?'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #6 - 交通如何影响城市规划和发展？'
- en: 'Query #7 - What are the challenges in financing transportation infrastructure?'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #7 - 融资交通基础设施面临的挑战是什么？'
- en: 'Query #8 - How can transportation policy influence economic productivity?'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '查询 #8 - 交通政策如何影响经济生产力？'
- en: Final Research Result for how does transportation help the economy
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 交通如何帮助经济的最终研究结果
- en: Transportation plays a pivotal role in the economy, contributing to the movement
    of goods, services, labor, and capital, which are essential for the functioning
    of a modern society and the growth of an economy [11]. The ability to transport
    goods and people efficiently is fundamental to economic life, as seen in the early
    United States where a robust transportation network was instrumental in the country’s
    development. In a macroeconomic sense, transportation activities are a part of
    the total economic product, and the demand for transportation services contributes
    to the GDP [2]. The transportation sector not only supports the movement of goods
    and services but also affects employment, wages, and business income, thereby
    contributing to the overall economic growth [3].
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 交通在经济中发挥着关键作用，推动商品、服务、劳动力和资本的流动，这些都是现代社会运作和经济增长所必需的[11]。高效的商品和人员运输能力对经济生活至关重要，正如在早期的美国，强大的交通网络对国家的发展起到了至关重要的作用。从宏观经济角度来看，交通活动是总经济产值的一部分，对交通服务的需求有助于GDP的增长[2]。交通部门不仅支持商品和服务的流动，还影响就业、工资和企业收入，从而有助于整体经济增长[3]。
- en: Investments in transportation infrastructure can lead to job creation and improved
    connectivity, which in turn, promotes economic productivity and well-being [22].
    Furthermore, efficient transportation systems can reduce poverty by increasing
    access to employment, recreational, and other essential life-shaping opportunities
    [20]. The economic importance of transportation is also evident in the fact that
    transportation-related final demand has been increasing since the recession, indicating
    a strong correlation between transportation and economic activity [8]. Additionally,
    the World Bank and ITDP report highlights the importance of active mobility in
    promoting economic productivity and socially inclusive development [21].
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 对交通基础设施的投资可以带来就业机会和改善连通性，从而促进经济生产力和福祉[22]。此外，高效的交通系统可以通过增加就业机会、休闲机会和其他塑造生活的关键机会来减少贫困[20]。交通的经济重要性还体现在交通相关的最终需求自经济衰退以来持续增长，表明交通与经济活动之间有着密切的关联[8]。此外，世界银行和国际交通与发展计划（ITDP）报告强调了积极出行对促进经济生产力和社会包容性发展的重要性[21]。
- en: Transportation is a critical component of a society, reflecting the aspirations
    of a society and influencing the location decisions of people and businesses.
    It is a vital determinant of economic growth, job creation, and improved living
    conditions, and its efficiency can lead to a green future by reducing congestion
    and promoting sustainable development [19].
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 交通是社会的关键组成部分，反映了社会的愿望，并影响人们和企业的选址决策。它是经济增长、创造就业机会和改善生活条件的重要决定因素，其效率可以通过减少拥堵和促进可持续发展来引领绿色未来[19]。
- en: In conclusion, transportation is not only crucial for the movement of goods
    and services but also plays a significant role in the overall economic growth
    of a country. It contributes to the GDP, supports employment, and affects wages
    and business income [2][3]. Investments in transportation infrastructure can lead
    to job creation and improved connectivity, promoting economic productivity and
    well-being [22]. Additionally, transportation plays a vital role in reducing poverty
    by increasing access to essential opportunities [20]. The economic importance
    of transportation is evident in the strong correlation between transportation
    and economic activity [8]. Therefore, transportation is a critical component of
    a society, reflecting its aspirations and influencing the location decisions of
    people and businesses [19].
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，交通不仅对于商品和服务的流动至关重要，还在一个国家的整体经济增长中扮演着重要角色。它为国内生产总值（GDP）做出贡献，支持就业，并影响工资和企业收入[2][3]。对交通基础设施的投资可以带来就业机会和改善连通性，促进经济生产力和福祉[22]。此外，交通通过增加对关键机会的获取，发挥着减少贫困的重要作用[20]。交通的经济重要性体现在交通与经济活动之间的强烈关联[8]。因此，交通是社会的一个关键组成部分，反映了社会的愿望并影响人们和企业的选址决策[19]。
- en: References
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: •
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[2] https://www.britannica.com/money/topic/transportation-economics](https://www.britannica.com/money/topic/transportation-economics)'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[2] https://www.britannica.com/money/topic/transportation-economics](https://www.britannica.com/money/topic/transportation-economics)'
- en: •
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[3] https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/](https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/)'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[3] https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/](https://data.bts.gov/stories/s/Transportation-Economic-Trends-Contribution-of-Tra/smrm-36nv/)'
- en: •
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[8] https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf](https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf)'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[8] https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf](https://www.bts.gov/sites/bts.dot.gov/files/docs/browse-statistical-products-and-data/transportation-economic-trends/215926/transportation-economic-trends-2017-chapter-2.pdf)'
- en: •
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[11] https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/](https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/)'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[11] https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/](https://www.nationalgeographic.org/article/effects-transportation-economy/5th-grade/)'
- en: •
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[19] https://transportgeography.org/contents/chapter3/transportation-and-society/](https://transportgeography.org/contents/chapter3/transportation-and-society/)'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[19] https://transportgeography.org/contents/chapter3/transportation-and-society/](https://transportgeography.org/contents/chapter3/transportation-and-society/)'
- en: •
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[20] https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/](https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/)'
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[20] https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/](https://blogs.iadb.org/transporte/en/how-can-transport-reduce-poverty-and-promote-socially-inclusive-development/)'
- en: •
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[21] https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/](https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/)'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[21] https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/](https://www.usatoday.com/story/special/contributor-content/2024/01/10/itdp-and-world-bank-report-highlights-economic-and-environmental-benefits-of-financing-active-mobili/72177281007/)'
- en: •
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: '[[22] https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[[22] https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/](https://www.accessmagazine.org/spring-2011/transportation-jobs-economic-growth/)'
- en: 'Figure 11: A “screenshot” of the output from SciPhi Research engine for the
    query “how does transportation help the economy”. This research engine also asked
    and separately answered multiple queries before arriving at the final research
    result. [https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy](https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy)'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：来自SciPhi Research引擎的“截图”，查询内容为“交通如何促进经济”。该研究引擎在得出最终研究结果之前，曾分别提出并回答了多个相关问题。[https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy](https://search.sciphi.ai/research?q=how+does+transportation+help+the+economy)
