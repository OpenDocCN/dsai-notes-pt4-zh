- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2025-01-11 12:46:36'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2025-01-11 12:46:36
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Driving Style Alignment for LLM-powered Driver Agent
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŸºäºLLMçš„é©¾é©¶å‘˜ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½
- en: æ¥æºï¼š[https://arxiv.org/html/2403.11368/](https://arxiv.org/html/2403.11368/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://arxiv.org/html/2403.11368/](https://arxiv.org/html/2403.11368/)
- en: 'Ruoxuan Yang, Xinyue Zhang, Anais Fernandez-Laaksonen, Xin Ding and Jiangtao
    Gong^(ğŸ–‚) The authors are with the Institute for AI Industry Research, Tsinghua
    University, Beijing, China. Corresponding Email: gongjiangtao@air.tsinghua.edu.cn'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Ruoxuan Yang, Xinyue Zhang, Anais Fernandez-Laaksonen, Xin Ding å’Œ Jiangtao Gong^(ğŸ–‚)
    ä½œè€…å‡æ¥è‡ªä¸­å›½åŒ—äº¬æ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢ã€‚é€šè®¯é‚®ç®±ï¼šgongjiangtao@air.tsinghua.edu.cn
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: Recently, LLM-powered driver agents have demonstrated considerable potential
    in the field of autonomous driving, showcasing human-like reasoning and decision-making
    abilities. However, current research on aligning driver agent behaviors with human
    driving styles remains limited, partly due to the scarcity of high-quality natural
    language data from human driving behaviors. To address this research gap, we propose
    a multi-alignment framework designed to align driver agents with human driving
    styles through demonstrations and feedback. Notably, we construct a natural language
    dataset of human driver behaviors through naturalistic driving experiments and
    post-driving interviews, offering high-quality human demonstrations for LLM alignment.
    The frameworkâ€™s effectiveness is validated through simulation experiments in the
    CARLA urban traffic simulator and further corroborated by human evaluations. Our
    research offers valuable insights into designing driving agents with diverse driving
    styles. The implementation of [the framework](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)Â¹Â¹1[https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent](https://github.com/AIR-DISCOVER/Multi-alignment-Drivng-Agent)
    and details of [the dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)Â²Â²2[https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)
    can be found at the link.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é©¾é©¶å‘˜ä»£ç†åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸå±•ç¤ºäº†å·¨å¤§çš„æ½œåŠ›ï¼Œå±•ç°äº†ç±»ä¼¼äººç±»çš„æ¨ç†å’Œå†³ç­–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç›®å‰å…³äºå°†é©¾é©¶å‘˜ä»£ç†è¡Œä¸ºä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½çš„ç ”ç©¶ä»ç„¶æœ‰é™ï¼Œéƒ¨åˆ†åŸå› æ˜¯ç¼ºä¹æ¥è‡ªäººç±»é©¾é©¶è¡Œä¸ºçš„é«˜è´¨é‡è‡ªç„¶è¯­è¨€æ•°æ®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç ”ç©¶ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šé‡å¯¹é½æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ¼”ç¤ºå’Œåé¦ˆå°†é©¾é©¶å‘˜ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬é€šè¿‡è‡ªç„¶é©¾é©¶å®éªŒå’Œé©¾é©¶åè®¿è°ˆæ„å»ºäº†ä¸€ä¸ªäººç±»é©¾é©¶è¡Œä¸ºçš„è‡ªç„¶è¯­è¨€æ•°æ®é›†ï¼Œä¸ºLLMå¯¹é½æä¾›äº†é«˜è´¨é‡çš„äººç±»æ¼”ç¤ºã€‚è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§é€šè¿‡åœ¨CARLAåŸå¸‚äº¤é€šæ¨¡æ‹Ÿå™¨ä¸­çš„ä»¿çœŸå®éªŒå¾—åˆ°äº†éªŒè¯ï¼Œå¹¶é€šè¿‡äººç±»è¯„ä¼°è¿›ä¸€æ­¥å¾—åˆ°è¯å®ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºè®¾è®¡å…·æœ‰å¤šæ ·åŒ–é©¾é©¶é£æ ¼çš„é©¾é©¶ä»£ç†æä¾›äº†å®è´µçš„è§è§£ã€‚æ¡†æ¶çš„å®ç°å’Œ[æ•°æ®é›†](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)çš„è¯¦ç»†ä¿¡æ¯å¯ä»¥åœ¨é“¾æ¥ä¸­æ‰¾åˆ°ã€‚
- en: I INTRODUCTION
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I å¼•è¨€
- en: In the burgeoning field of autonomous driving (AV), driver agents powered by
    Large Language Models (LLMs) are demonstrating remarkable promise due to their
    exceptional planning[[1](https://arxiv.org/html/2403.11368v1#bib.bib1)] and reasoning[[2](https://arxiv.org/html/2403.11368v1#bib.bib2),
    [3](https://arxiv.org/html/2403.11368v1#bib.bib3), [4](https://arxiv.org/html/2403.11368v1#bib.bib4)]
    capabilities. Researchers have delved into the development of intricately designed
    driver agents that could perceive environmental stimuli[[5](https://arxiv.org/html/2403.11368v1#bib.bib5),
    [6](https://arxiv.org/html/2403.11368v1#bib.bib6), [7](https://arxiv.org/html/2403.11368v1#bib.bib7)],
    comprehend the situation[[8](https://arxiv.org/html/2403.11368v1#bib.bib8)], fetch
    their memories[[9](https://arxiv.org/html/2403.11368v1#bib.bib9), [10](https://arxiv.org/html/2403.11368v1#bib.bib10)]
    and deduce subsequent driving actions[[11](https://arxiv.org/html/2403.11368v1#bib.bib11)]
    that mirrors human decision-making. Such human-like AVs show promise in navigating
    a diverse range of driving scenariosÂ [[12](https://arxiv.org/html/2403.11368v1#bib.bib12),
    [13](https://arxiv.org/html/2403.11368v1#bib.bib13)], enabling better anticipation
    of AV behavior by other road usersÂ [[14](https://arxiv.org/html/2403.11368v1#bib.bib14)],
    while also enhancing human trust in these systemsÂ [[15](https://arxiv.org/html/2403.11368v1#bib.bib15)].
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è“¬å‹ƒå‘å±•çš„è‡ªåŠ¨é©¾é©¶ï¼ˆAVï¼‰é¢†åŸŸï¼Œç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„é©¾é©¶ä»£ç†å› å…¶å“è¶Šçš„è§„åˆ’[[1](https://arxiv.org/html/2403.11368v1#bib.bib1)]å’Œæ¨ç†[[2](https://arxiv.org/html/2403.11368v1#bib.bib2),
    [3](https://arxiv.org/html/2403.11368v1#bib.bib3), [4](https://arxiv.org/html/2403.11368v1#bib.bib4)]èƒ½åŠ›è€Œå±•ç°å‡ºä»¤äººç©ç›®çš„æ½œåŠ›ã€‚ç ”ç©¶äººå‘˜æ·±å…¥ç ”ç©¶äº†å¤æ‚è®¾è®¡çš„é©¾é©¶ä»£ç†ï¼Œè¿™äº›ä»£ç†èƒ½å¤Ÿæ„ŸçŸ¥ç¯å¢ƒåˆºæ¿€[[5](https://arxiv.org/html/2403.11368v1#bib.bib5),
    [6](https://arxiv.org/html/2403.11368v1#bib.bib6), [7](https://arxiv.org/html/2403.11368v1#bib.bib7)]ï¼Œç†è§£å½“å‰æƒ…å†µ[[8](https://arxiv.org/html/2403.11368v1#bib.bib8)]ï¼Œæå–è®°å¿†[[9](https://arxiv.org/html/2403.11368v1#bib.bib9),
    [10](https://arxiv.org/html/2403.11368v1#bib.bib10)]ï¼Œå¹¶æ¨å¯¼å‡ºåç»­çš„é©¾é©¶è¡Œä¸º[[11](https://arxiv.org/html/2403.11368v1#bib.bib11)]ï¼Œè¿™äº›è¡Œä¸ºç±»ä¼¼äºäººç±»çš„å†³ç­–è¿‡ç¨‹ã€‚è¿™æ ·çš„ç±»äººè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåœ¨åº”å¯¹å„ç§é©¾é©¶åœºæ™¯æ—¶è¡¨ç°å‡ºäº†å·¨å¤§æ½œåŠ›[[12](https://arxiv.org/html/2403.11368v1#bib.bib12),
    [13](https://arxiv.org/html/2403.11368v1#bib.bib13)]ï¼Œèƒ½å¤Ÿå¸®åŠ©å…¶ä»–é“è·¯ä½¿ç”¨è€…æ›´å¥½åœ°é¢„æµ‹è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„è¡Œä¸º[[14](https://arxiv.org/html/2403.11368v1#bib.bib14)]ï¼ŒåŒæ—¶ä¹Ÿå¢å¼ºäº†äººä»¬å¯¹è¿™äº›ç³»ç»Ÿçš„ä¿¡ä»»[[15](https://arxiv.org/html/2403.11368v1#bib.bib15)]ã€‚
- en: However, aligning these driver agents with human driving styles to imbue them
    with more human-like and personalized characteristics remains unexplored. Prevailing
    strategies for aligning LLM-based agents with humans, such as fine-tuning[[5](https://arxiv.org/html/2403.11368v1#bib.bib5),
    [6](https://arxiv.org/html/2403.11368v1#bib.bib6), [16](https://arxiv.org/html/2403.11368v1#bib.bib16)]
    and the integration of expert feedback[[17](https://arxiv.org/html/2403.11368v1#bib.bib17),
    [18](https://arxiv.org/html/2403.11368v1#bib.bib18)], are often hindered by their
    high costs. Recently, some studies have leveraged AI to generate feedback or reflections[[19](https://arxiv.org/html/2403.11368v1#bib.bib19),
    [20](https://arxiv.org/html/2403.11368v1#bib.bib20), [21](https://arxiv.org/html/2403.11368v1#bib.bib21),
    [22](https://arxiv.org/html/2403.11368v1#bib.bib22)], yet they fall short in aligning
    such reflections with human perspectives. On the other hand, despite researches
    focusing on employing AI to generate few-shot demonstrations[[1](https://arxiv.org/html/2403.11368v1#bib.bib1),
    [23](https://arxiv.org/html/2403.11368v1#bib.bib23)] for LLMs, another challenge
    in enhancing agent-human alignment lies in the lack of high-quality human behavior
    data in a form accessible to LLMs, making it difficult for agents to learn from
    human demonstrations. Existing datasets for autonomous driving learning either
    provide only environment data for perception tasks[[24](https://arxiv.org/html/2403.11368v1#bib.bib24),
    [25](https://arxiv.org/html/2403.11368v1#bib.bib25), [26](https://arxiv.org/html/2403.11368v1#bib.bib26)]
    rather than driving behaviors, or present driving behaviors in non-linguistic
    modalities (e.g. trajectories in maps[[27](https://arxiv.org/html/2403.11368v1#bib.bib27)],
    Controller Area Network Bus (CAN-Bus) data[[28](https://arxiv.org/html/2403.11368v1#bib.bib28),
    [29](https://arxiv.org/html/2403.11368v1#bib.bib29)], in-car videos[[30](https://arxiv.org/html/2403.11368v1#bib.bib30)])
    that are indirect for LLMs to learn from. Thus, successful alignment requires
    an approach that efficiently synchronizes LLM-based driver agents with human driving
    styles, as well as a collection of driving demonstrations across different driving
    styles in natural language for LLMsâ€™ comprehension and learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå°†è¿™äº›é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ï¼Œä»¥èµ‹äºˆå®ƒä»¬æ›´å¤šç±»äººåŒ–å’Œä¸ªæ€§åŒ–çš„ç‰¹å¾ä»ç„¶æ˜¯ä¸€ä¸ªæœªè¢«æ¢ç´¢çš„é—®é¢˜ã€‚ç°æœ‰çš„åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é½äººç±»çš„ç­–ç•¥ï¼Œå¦‚å¾®è°ƒ[[5](https://arxiv.org/html/2403.11368v1#bib.bib5),
    [6](https://arxiv.org/html/2403.11368v1#bib.bib6), [16](https://arxiv.org/html/2403.11368v1#bib.bib16)]å’Œä¸“å®¶åé¦ˆçš„æ•´åˆ[[17](https://arxiv.org/html/2403.11368v1#bib.bib17),
    [18](https://arxiv.org/html/2403.11368v1#bib.bib18)]ï¼Œå¾€å¾€å› å…¶é«˜æ˜‚çš„æˆæœ¬è€Œå—åˆ°é™åˆ¶ã€‚æœ€è¿‘ï¼Œä¸€äº›ç ”ç©¶åˆ©ç”¨äººå·¥æ™ºèƒ½ç”Ÿæˆåé¦ˆæˆ–åæ€[[19](https://arxiv.org/html/2403.11368v1#bib.bib19),
    [20](https://arxiv.org/html/2403.11368v1#bib.bib20), [21](https://arxiv.org/html/2403.11368v1#bib.bib21),
    [22](https://arxiv.org/html/2403.11368v1#bib.bib22)]ï¼Œä½†å®ƒä»¬æœªèƒ½å°†è¿™äº›åæ€ä¸äººç±»è§†è§’å¯¹é½ã€‚å¦ä¸€æ–¹é¢ï¼Œå°½ç®¡æœ‰ç ”ç©¶ä¸“æ³¨äºåˆ©ç”¨äººå·¥æ™ºèƒ½ä¸ºLLMsç”Ÿæˆå°‘é‡ç¤ºèŒƒ[[1](https://arxiv.org/html/2403.11368v1#bib.bib1),
    [23](https://arxiv.org/html/2403.11368v1#bib.bib23)]ï¼Œå¢å¼ºä»£ç†ä¸äººç±»å¯¹é½çš„å¦ä¸€ä¸ªæŒ‘æˆ˜åœ¨äºç¼ºä¹å¯ä¾›LLMè®¿é—®çš„é«˜è´¨é‡äººç±»è¡Œä¸ºæ•°æ®ï¼Œè¿™ä½¿å¾—ä»£ç†éš¾ä»¥ä»äººç±»ç¤ºèŒƒä¸­å­¦ä¹ ã€‚ç°æœ‰çš„è‡ªåŠ¨é©¾é©¶å­¦ä¹ æ•°æ®é›†ï¼Œè¦ä¹ˆä»…æä¾›ç”¨äºæ„ŸçŸ¥ä»»åŠ¡çš„ç¯å¢ƒæ•°æ®[[24](https://arxiv.org/html/2403.11368v1#bib.bib24),
    [25](https://arxiv.org/html/2403.11368v1#bib.bib25), [26](https://arxiv.org/html/2403.11368v1#bib.bib26)]ï¼Œè€Œéé©¾é©¶è¡Œä¸ºï¼Œè¦ä¹ˆä»¥éè¯­è¨€åŒ–çš„æ–¹å¼å‘ˆç°é©¾é©¶è¡Œä¸ºï¼ˆä¾‹å¦‚ï¼Œåœ°å›¾ä¸­çš„è½¨è¿¹[[27](https://arxiv.org/html/2403.11368v1#bib.bib27)]ï¼Œæ§åˆ¶å™¨å±€åŸŸç½‘ç»œï¼ˆCAN-Busï¼‰æ•°æ®[[28](https://arxiv.org/html/2403.11368v1#bib.bib28),
    [29](https://arxiv.org/html/2403.11368v1#bib.bib29)]ï¼Œè½¦å†…è§†é¢‘[[30](https://arxiv.org/html/2403.11368v1#bib.bib30)]ï¼‰ï¼Œè¿™äº›æ–¹å¼å¯¹äºLLMæ¥è¯´éƒ½æ˜¯é—´æ¥çš„å­¦ä¹ èµ„æ–™ã€‚å› æ­¤ï¼ŒæˆåŠŸçš„å¯¹é½éœ€è¦ä¸€ç§èƒ½å¤Ÿé«˜æ•ˆåŒæ­¥LLMé©±åŠ¨ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼çš„æ–¹æ³•ï¼ŒåŒæ—¶éœ€è¦é€šè¿‡è‡ªç„¶è¯­è¨€æ”¶é›†ä¸åŒé©¾é©¶é£æ ¼çš„é©¾é©¶ç¤ºèŒƒï¼Œä»¥ä¾¿LLMç†è§£å’Œå­¦ä¹ ã€‚
- en: In this paper, we introduce a novel multi-alignment framework that utilizes
    demonstrations and feedback to align driver agents with human driving styles.
    Diverging from reliance on human expert feedback or reflections from LLMs themselves,
    our approach harnesses the few-shot learning capabilities[[31](https://arxiv.org/html/2403.11368v1#bib.bib31)]
    of LLMs to create a Coach Agent that learns from human demonstrations, evaluates
    past driving behaviors, and formulates driving guidelines. All human demonstrations
    are pre-collected, eliminating the need for additional human effort during alignment
    and substantially reducing costs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šé‡å¯¹é½æ¡†æ¶ï¼Œé€šè¿‡ç¤ºèŒƒå’Œåé¦ˆå°†é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚ä¸ä¾èµ–äººç±»ä¸“å®¶åé¦ˆæˆ–LLMè‡ªæˆ‘åæ€ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨LLMçš„å°‘é‡å­¦ä¹ èƒ½åŠ›[[31](https://arxiv.org/html/2403.11368v1#bib.bib31)]ï¼Œåˆ›å»ºäº†ä¸€ç§æ•™ç»ƒä»£ç†ï¼Œèƒ½å¤Ÿä»äººç±»ç¤ºèŒƒä¸­å­¦ä¹ ï¼Œè¯„ä¼°è¿‡å»çš„é©¾é©¶è¡Œä¸ºï¼Œå¹¶åˆ¶å®šé©¾é©¶æŒ‡å—ã€‚æ‰€æœ‰çš„äººç±»ç¤ºèŒƒéƒ½å·²é¢„å…ˆæ”¶é›†ï¼Œé¿å…äº†åœ¨å¯¹é½è¿‡ç¨‹ä¸­éœ€è¦é¢å¤–çš„äººåŠ›æŠ•å…¥ï¼Œä»è€Œå¤§å¹…é™ä½äº†æˆæœ¬ã€‚
- en: Moreover, to collect high-quality demonstrations for alignment, we compiled
    a dataset that encompasses driving behaviors from drivers with varied driving
    styles. A real-world driving experiment was conducted, followed by a post-driving
    interview, wherein we gathered and structured human driversâ€™ decision-making data.
    This dataset likely represents the first effort to meticulously dissect human
    driving behaviors and articulate the driving decision-making process in a natural
    language format.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä¸ºäº†æ”¶é›†é«˜è´¨é‡çš„å¯¹é½ç¤ºèŒƒæ•°æ®ï¼Œæˆ‘ä»¬ç¼–åˆ¶äº†ä¸€ä¸ªåŒ…å«ä¸åŒé©¾é©¶é£æ ¼é©¾é©¶å‘˜è¡Œä¸ºçš„æ•°æ®é›†ã€‚è¿›è¡Œäº†ä¸€ä¸ªçœŸå®ä¸–ç•Œçš„é©¾é©¶å®éªŒï¼Œéšåè¿›è¡Œäº†é©¾é©¶åçš„è®¿è°ˆï¼Œæ”¶é›†å¹¶æ•´ç†äº†äººç±»é©¾é©¶å‘˜çš„å†³ç­–æ•°æ®ã€‚è¿™ä¸ªæ•°æ®é›†å¯èƒ½æ˜¯é¦–æ¬¡åŠªåŠ›ç»†è‡´åœ°å‰–æäººç±»é©¾é©¶è¡Œä¸ºï¼Œå¹¶ä»¥è‡ªç„¶è¯­è¨€æ ¼å¼é˜è¿°é©¾é©¶å†³ç­–è¿‡ç¨‹çš„å°è¯•ã€‚
- en: We validate our work through both simulation experiments and human evaluation
    surveys, demonstrating that our multi-aligned framework effectively creates driver
    agents with distinct driving styles that are not only statistically sound but
    also distinctly perceptible to humans.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡ä»¿çœŸå®éªŒå’Œäººå·¥è¯„ä¼°è°ƒæŸ¥éªŒè¯äº†æˆ‘ä»¬çš„å·¥ä½œï¼Œè¯æ˜æˆ‘ä»¬çš„å¤šé‡å¯¹é½æ¡†æ¶æœ‰æ•ˆåœ°åˆ›å»ºäº†å…·æœ‰ä¸åŒé©¾é©¶é£æ ¼çš„é©¾é©¶ä»£ç†ï¼Œè¿™äº›ä»£ç†ä¸ä»…åœ¨ç»Ÿè®¡ä¸Šåˆç†ï¼Œè€Œä¸”åœ¨æ„ŸçŸ¥ä¸Šèƒ½è¢«äººç±»æ¸…æ™°åŒºåˆ†ã€‚
- en: 'The contributions of this paper are summarized as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡çš„è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š
- en: â€¢
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: A multi-alignment framework that can align LLM-based driver agents with human
    driving styles.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¤šé‡å¯¹é½æ¡†æ¶ï¼Œå¯ä»¥å°†åŸºäºLLMçš„é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚
- en: â€¢
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: A dataset of human driving behaviors in natural language format.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä»¥è‡ªç„¶è¯­è¨€æ ¼å¼è¡¨ç¤ºçš„äººç±»é©¾é©¶è¡Œä¸ºæ•°æ®é›†ã€‚
- en: â€¢
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Comprehensive validation through both simulation experiments and human evaluations.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»¿çœŸå®éªŒå’Œäººå·¥è¯„ä¼°è¿›è¡Œå…¨é¢éªŒè¯ã€‚
- en: II Multi-alignment Framework
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II å¤šé‡å¯¹é½æ¡†æ¶
- en: '![Refer to caption](img/aad80c2e5382486c4f4eaa004c220f03.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/aad80c2e5382486c4f4eaa004c220f03.png)'
- en: 'Figure 1: The multi-alignment framework'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1ï¼šå¤šé‡å¯¹é½æ¡†æ¶
- en: Fig. [1](https://arxiv.org/html/2403.11368v1#S2.F1 "Figure 1 â€£ II Multi-alignment
    Framework â€£ Driving Style Alignment for LLM-powered Driver Agent") demonstrates
    the comprehensive structure of the multi-alignment framework, consisting of a
    Driver Agent, a Coach Agent, and demonstrations from human drivers. In this section,
    we first introduce the architecture and basic workflow of the Driver Agent. Then
    we show how to achieve multi-alignment through direct demonstration data from
    human drivers and feedback from the Coach Agent with human demonstrations.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[1](https://arxiv.org/html/2403.11368v1#S2.F1 "å›¾1 â€£ II å¤šé‡å¯¹é½æ¡†æ¶ â€£ åŸºäºLLMçš„é©¾é©¶ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½")å±•ç¤ºäº†å¤šé‡å¯¹é½æ¡†æ¶çš„å…¨é¢ç»“æ„ï¼ŒåŒ…æ‹¬é©¾é©¶ä»£ç†ã€æ•™ç»ƒä»£ç†å’Œæ¥è‡ªäººç±»é©¾é©¶å‘˜çš„ç¤ºèŒƒæ•°æ®ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä»‹ç»é©¾é©¶ä»£ç†çš„æ¶æ„å’ŒåŸºæœ¬å·¥ä½œæµç¨‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å±•ç¤ºå¦‚ä½•é€šè¿‡æ¥è‡ªäººç±»é©¾é©¶å‘˜çš„ç›´æ¥ç¤ºèŒƒæ•°æ®å’Œæ•™ç»ƒä»£ç†çš„åé¦ˆå®ç°å¤šé‡å¯¹é½ã€‚
- en: II-A Driver Agent
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A é©¾é©¶ä»£ç†
- en: The Driver Agent acts as entities interacting with the surrounding driving environment
    and making driving decisions. It maintains an iterable, fixed-capacity short-term
    memory, which stores the most recent memory units, promoting the continuity and
    consistency of decision-making.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: é©¾é©¶ä»£ç†ä½œä¸ºä¸å‘¨å›´é©¾é©¶ç¯å¢ƒäº’åŠ¨å¹¶åšå‡ºé©¾é©¶å†³ç­–çš„å®ä½“ã€‚å®ƒä¿æŒä¸€ä¸ªå¯è¿­ä»£çš„å›ºå®šå®¹é‡çŸ­æœŸè®°å¿†ï¼Œå­˜å‚¨æœ€è¿‘çš„è®°å¿†å•å…ƒï¼Œä¿ƒè¿›å†³ç­–çš„è¿è´¯æ€§å’Œä¸€è‡´æ€§ã€‚
- en: 'The workflow begins by capturing the current state and environment information
    for perception, including the speed and direction of the agent vehicle, the speed
    limits and other restrictions of the current road, as well as the status of other
    vehicles and pedestrians nearby. Next, it analyzes the collected information alongside
    its short-term memory to grasp the current situation. Following this analysis,
    along with provided Demonstrations and Guidelines for multi-alignment, the Driver
    Agent deduces the most appropriate driving action at the moment. Here, the Driver
    Agent is prompted to â€™Think Step by Step,â€™ employing a chain-of-thought (CoT)
    reasoning strategy towards the final decision:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å·¥ä½œæµç¨‹ä»æ•æ‰å½“å‰çŠ¶æ€å’Œç¯å¢ƒä¿¡æ¯å¼€å§‹ï¼ŒåŒ…æ‹¬ä»£ç†è½¦è¾†çš„é€Ÿåº¦å’Œæ–¹å‘ã€å½“å‰é“è·¯çš„é™é€ŸåŠå…¶ä»–é™åˆ¶ï¼Œä»¥åŠé™„è¿‘å…¶ä»–è½¦è¾†å’Œè¡Œäººçš„çŠ¶æ€ã€‚æ¥ä¸‹æ¥ï¼Œç³»ç»Ÿåˆ†ææ”¶é›†çš„ä¿¡æ¯ï¼Œå¹¶ç»“åˆå…¶çŸ­æœŸè®°å¿†æ¥æŒæ¡å½“å‰æƒ…å†µã€‚åœ¨æ­¤åˆ†æä¹‹åï¼Œé€šè¿‡æä¾›çš„ç¤ºèŒƒå’Œå¤šé‡å¯¹é½æŒ‡å—ï¼Œé©¾é©¶ä»£ç†æ¨æ–­å‡ºå½“ä¸‹æœ€åˆé€‚çš„é©¾é©¶è¡ŒåŠ¨ã€‚æ­¤æ—¶ï¼Œé©¾é©¶ä»£ç†è¢«æç¤ºâ€œé€æ­¥æ€è€ƒâ€ï¼Œè¿ç”¨è¿é”æ€ç»´ï¼ˆCoTï¼‰æ¨ç†ç­–ç•¥åšå‡ºæœ€ç»ˆå†³ç­–ï¼š
- en: â€œGiven the rather faster speed of the vehicle ahead and inability to change
    lanes, the agent car should match the speed by gentle acceleration.â€
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: â€œé‰´äºå‰æ–¹è½¦è¾†çš„é€Ÿåº¦è¾ƒå¿«ä¸”æ— æ³•å˜é“ï¼Œä»£ç†è½¦åº”é€šè¿‡æ¸©å’ŒåŠ é€Ÿæ¥åŒ¹é…é€Ÿåº¦ã€‚â€
- en: Next, the Driver Agent selects the most matching ones from a set of atomic driving
    operations as the stepâ€™s action and performs. The â€Situation,â€ â€Reasoning,â€ and
    â€Actionâ€ generated are then compiled into a memory unit and incorporated into
    the short-term memory, while the earliest memory unit is popped out. Through the
    consistent repetition of this process, the Driver Agent successfully crafts a
    sequence of fluid and coherent driving maneuvers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œé©¾é©¶ä»£ç†ä»ä¸€ç»„åŸå­é©¾é©¶æ“ä½œä¸­é€‰æ‹©æœ€åŒ¹é…çš„åŠ¨ä½œä½œä¸ºè¯¥æ­¥éª¤çš„æ“ä½œå¹¶æ‰§è¡Œã€‚ç”Ÿæˆçš„â€œæƒ…å¢ƒâ€ï¼ˆSituationï¼‰ã€â€œæ¨ç†â€ï¼ˆReasoningï¼‰å’Œâ€œåŠ¨ä½œâ€ï¼ˆActionï¼‰éšåè¢«ç¼–åˆ¶æˆä¸€ä¸ªè®°å¿†å•å…ƒï¼Œå¹¶èå…¥åˆ°çŸ­æœŸè®°å¿†ä¸­ï¼Œè€Œæœ€æ—©çš„è®°å¿†å•å…ƒåˆ™ä¼šè¢«å¼¹å‡ºã€‚é€šè¿‡è¿™ä¸€è¿‡ç¨‹çš„æŒç»­é‡å¤ï¼Œé©¾é©¶ä»£ç†æˆåŠŸåœ°å½¢æˆäº†ä¸€ç³»åˆ—æµç•…ä¸”è¿è´¯çš„é©¾é©¶åŠ¨ä½œã€‚
- en: II-B Multi-alignment through Demonstrations and Feedback
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B é€šè¿‡ç¤ºèŒƒå’Œåé¦ˆå®ç°å¤šé‡å¯¹é½
- en: We construct a framework that could multi-align the Driver Agent with human
    driving styles by adopting demonstrations and feedback.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ¡†æ¶ï¼Œé€šè¿‡é‡‡ç”¨ç¤ºèŒƒå’Œåé¦ˆï¼Œå¯ä»¥å°†é©¾é©¶ä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼è¿›è¡Œå¤šé‡å¯¹é½ã€‚
- en: Demonstrations encompass representative decision-making processes of human drivers,
    featuring both cautious and risky driving demonstrations. They are collected and
    then organized into the form of the Driver Agentâ€™s memory units (with more details
    in Section [III](https://arxiv.org/html/2403.11368v1#S3 "III Driving Style Data
    Collection â€£ Driving Style Alignment for LLM-powered Driver Agent")). Demonstrations
    serve a dual purpose in alignment, being utilized by both the Driver Agent and
    the Coach Agent. For the Driver Agent, they serve as few-shot prompts, aiming
    to guide it towards making driving decisions similar in style. And for the Coach
    Agent, they are provided as â€™Goodâ€™ examples, prompting it to make evaluations
    with driving style preferences, further generating guidelines that embody driving
    styles.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºèŒƒåŒ…æ‹¬äº†äººç±»å¸æœºå…·æœ‰ä»£è¡¨æ€§çš„å†³ç­–è¿‡ç¨‹ï¼Œæ¶µç›–äº†è°¨æ…å’Œå†’é™©çš„é©¾é©¶ç¤ºèŒƒã€‚è¿™äº›ç¤ºèŒƒè¢«æ”¶é›†å¹¶ç»„ç»‡æˆé©¾é©¶ä»£ç†çš„è®°å¿†å•å…ƒå½¢å¼ï¼ˆæ›´å¤šç»†èŠ‚è§ç¬¬[III](https://arxiv.org/html/2403.11368v1#S3
    "III Driving Style Data Collection â€£ Driving Style Alignment for LLM-powered Driver
    Agent")èŠ‚ï¼‰ã€‚ç¤ºèŒƒåœ¨å¯¹é½ä¸­èµ·åˆ°äº†åŒé‡ä½œç”¨ï¼Œæ—¢è¢«é©¾é©¶ä»£ç†ä½¿ç”¨ï¼Œä¹Ÿè¢«æ•™ç»ƒä»£ç†ä½¿ç”¨ã€‚å¯¹äºé©¾é©¶ä»£ç†ï¼Œç¤ºèŒƒä½œä¸ºå°‘é‡ç¤ºä¾‹ï¼Œæ—¨åœ¨å¼•å¯¼å…¶åšå‡ºé£æ ¼ç›¸ä¼¼çš„é©¾é©¶å†³ç­–ï¼›è€Œå¯¹äºæ•™ç»ƒä»£ç†ï¼Œç¤ºèŒƒåˆ™ä½œä¸ºâ€œä¼˜ç§€â€ç¤ºä¾‹ï¼Œä¿ƒä½¿å…¶ä¾æ®é©¾é©¶é£æ ¼åå¥½è¿›è¡Œè¯„ä¼°ï¼Œå¹¶è¿›ä¸€æ­¥ç”Ÿæˆä½“ç°é©¾é©¶é£æ ¼çš„æŒ‡å—ã€‚
- en: To implement feedback, a Coach Agent was established, outfitted with a Guidelines
    module that compiles driving suggestions gleaned from continuous evaluations.
    It scrutinizes the current short-term memory of the Driver Agent and issues a
    judgment of â€™Goodâ€™ or â€™Badâ€™, along with the reason for this judgement. The criteria
    for evaluation include whether the decisions in the short-memory align with common
    driving sense, conform to the requirements proposed in the Guidelines, and match
    the style of the provided â€™Goodâ€™ examples. Should an evaluation yield a â€™Badâ€™
    rating, the Coach Agent formulates a new guideline addressing the suboptimal driving
    decision. This new guideline is then assimilated into the existing Guidelines
    repository.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®æ–½åé¦ˆï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªæ•™ç»ƒä»£ç†ï¼Œå¹¶é…å¤‡äº†ä¸€ä¸ªæŒ‡å—æ¨¡å—ï¼Œç”¨äºæ±‡æ€»é€šè¿‡æŒç»­è¯„ä¼°è·å¾—çš„é©¾é©¶å»ºè®®ã€‚å®ƒä¼šå®¡æŸ¥é©¾é©¶ä»£ç†å½“å‰çš„çŸ­æœŸè®°å¿†ï¼Œå¹¶å¯¹å…¶è¿›è¡Œâ€œä¼˜ç§€â€æˆ–â€œä¸ä½³â€çš„è¯„åˆ¤ï¼Œå¹¶é™„ä¸Šåˆ¤æ–­ç†ç”±ã€‚è¯„ä¼°æ ‡å‡†åŒ…æ‹¬ï¼šçŸ­æœŸè®°å¿†ä¸­çš„å†³ç­–æ˜¯å¦ç¬¦åˆå¸¸è§„é©¾é©¶å¸¸è¯†ï¼Œæ˜¯å¦ç¬¦åˆæŒ‡å—ä¸­æå‡ºçš„è¦æ±‚ï¼Œå¹¶ä¸æä¾›çš„â€œä¼˜ç§€â€ç¤ºä¾‹é£æ ¼ä¸€è‡´ã€‚å¦‚æœè¯„ä¼°ç»“æœä¸ºâ€œä¸ä½³â€ï¼Œæ•™ç»ƒä»£ç†å°†åˆ¶å®šæ–°çš„æŒ‡å—ï¼Œé’ˆå¯¹ä¸ç†æƒ³çš„é©¾é©¶å†³ç­–è¿›è¡Œä¿®æ­£ã€‚è¿™ä¸ªæ–°æŒ‡å—éšåä¼šè¢«æ•´åˆåˆ°ç°æœ‰çš„æŒ‡å—åº“ä¸­ã€‚
- en: III Driving Style Data Collection
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III é©¾é©¶é£æ ¼æ•°æ®æ”¶é›†
- en: III-A Natural Driving Experiment and Post-driving Interview
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A è‡ªç„¶é©¾é©¶å®éªŒä¸é©¾é©¶åè®¿è°ˆ
- en: To gather authentic human driving behavior data for alignment, we conducted
    a natural driving experiment with human drivers followed by a post-experiment
    interview. A total of 24 drivers were invited to participate in our data collection
    experiment, covering different genders and age groups. Notably, in order to gather
    data on different driving styles, the participants also included both seasoned
    professional drivers and novice drivers with less driving experience.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ”¶é›†ç”¨äºå¯¹é½çš„çœŸå®äººç±»é©¾é©¶è¡Œä¸ºæ•°æ®ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹è‡ªç„¶é©¾é©¶å®éªŒï¼Œå®éªŒåè¿˜è¿›è¡Œäº†è®¿è°ˆã€‚å…±æœ‰24åå¸æœºè¢«é‚€è¯·å‚ä¸æˆ‘ä»¬çš„æ•°æ®æ”¶é›†å®éªŒï¼Œæ¶µç›–äº†ä¸åŒæ€§åˆ«å’Œå¹´é¾„ç¾¤ä½“ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸ºäº†æ”¶é›†ä¸åŒé©¾é©¶é£æ ¼çš„æ•°æ®ï¼Œå‚ä¸è€…ä¸­æ—¢åŒ…æ‹¬äº†ç»éªŒä¸°å¯Œçš„ä¸“ä¸šå¸æœºï¼Œä¹ŸåŒ…æ‹¬äº†é©¾é©¶ç»éªŒè¾ƒå°‘çš„æ–°æ‰‹å¸æœºã€‚
- en: To delve deeply into specific driving behaviors, we initially had each driver
    perform an urban road driving task covering 13 driving conditions, with a total
    length of 5.7 kilometers. To faithfully recreate the entire driving process during
    the following post-experiment interview, we set up a roof-mounted 360-degree panoramic
    camera to record the environment around the vehicle during task execution, an
    in-car motion camera to capture the driverâ€™s actions, as well as an eye tracker
    to record changes in the driverâ€™s gaze. Additionally, real-time CAN-Bus data on
    the vehicleâ€™s status were recorded, including speed, the throttle and brake percentage,
    and the turning of the steering wheel.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ·±å…¥æ¢è®¨å…·ä½“çš„é©¾é©¶è¡Œä¸ºï¼Œæˆ‘ä»¬é¦–å…ˆè®©æ¯ä½é©¾é©¶å‘˜æ‰§è¡Œä¸€é¡¹æ¶µç›–13ç§é©¾é©¶æ¡ä»¶çš„åŸå¸‚é“è·¯é©¾é©¶ä»»åŠ¡ï¼Œæ€»é•¿åº¦ä¸º5.7å…¬é‡Œã€‚ä¸ºäº†åœ¨æ¥ä¸‹æ¥çš„åå®éªŒè®¿è°ˆä¸­å¿ å®å†ç°æ•´ä¸ªé©¾é©¶è¿‡ç¨‹ï¼Œæˆ‘ä»¬è®¾ç½®äº†ä¸€å°è½¦é¡¶360åº¦å…¨æ™¯ç›¸æœºï¼Œç”¨äºè®°å½•ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­è½¦è¾†å‘¨å›´çš„ç¯å¢ƒï¼Œè½¦å†…è¿åŠ¨ç›¸æœºç”¨æ¥æ•æ‰é©¾é©¶å‘˜çš„åŠ¨ä½œï¼Œä»¥åŠçœ¼åŠ¨ä»ªç”¨æ¥è®°å½•é©¾é©¶å‘˜æ³¨è§†ç‚¹çš„å˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å®æ—¶è®°å½•äº†è½¦è¾†çŠ¶æ€çš„CANæ€»çº¿æ•°æ®ï¼ŒåŒ…æ‹¬é€Ÿåº¦ã€æ²¹é—¨ä¸åˆ¹è½¦çš„ç™¾åˆ†æ¯”ï¼Œä»¥åŠæ–¹å‘ç›˜çš„è½¬åŠ¨æƒ…å†µã€‚
- en: For safety reasons, drivers were not requested to verbalize their thought processes
    while performing driving tasks. Right after the natural driving experiment, drivers
    would participate in a detailed post-experiment interview, which typically lasted
    for 1.5-2 hours. During the interview, we used the collected videos to recreate
    the task situation just experienced by the driver. For each driving action (e.g.
    accelerating, lane changing or turning), drivers were asked to recall and describe
    the entire decision-making process, from evaluating the surrounding environment
    to executing the corresponding driving action. These interview data will assist
    in determining the driverâ€™s driving style, and also serve as the source of Demonstrations
    in the Multi-alignment Framework.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œé©¾é©¶å‘˜åœ¨æ‰§è¡Œé©¾é©¶ä»»åŠ¡æ—¶å¹¶æœªè¦æ±‚å£å¤´è¡¨è¾¾å…¶æ€ç»´è¿‡ç¨‹ã€‚åœ¨è‡ªç„¶é©¾é©¶å®éªŒç»“æŸåï¼Œé©¾é©¶å‘˜ä¼šå‚åŠ ä¸€æ¬¡è¯¦ç»†çš„åå®éªŒè®¿è°ˆï¼Œè®¿è°ˆé€šå¸¸æŒç»­1.5åˆ°2å°æ—¶ã€‚åœ¨è®¿è°ˆè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨æ”¶é›†åˆ°çš„è§†é¢‘å›æ”¾é©¾é©¶å‘˜åˆšæ‰ç»å†çš„ä»»åŠ¡æƒ…å¢ƒã€‚å¯¹äºæ¯ä¸€ä¸ªé©¾é©¶åŠ¨ä½œï¼ˆä¾‹å¦‚åŠ é€Ÿã€å˜é“æˆ–è½¬å¼¯ï¼‰ï¼Œé©¾é©¶å‘˜ä¼šè¢«è¦æ±‚å›å¿†å¹¶æè¿°æ•´ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œä»è¯„ä¼°å‘¨å›´ç¯å¢ƒåˆ°æ‰§è¡Œç›¸åº”çš„é©¾é©¶åŠ¨ä½œã€‚è¿™äº›è®¿è°ˆæ•°æ®å°†æœ‰åŠ©äºç¡®å®šé©¾é©¶å‘˜çš„é©¾é©¶é£æ ¼ï¼Œå¹¶ä¸”ä¹Ÿä½œä¸ºå¤šé‡å¯¹é½æ¡†æ¶ä¸­æ¼”ç¤ºæ•°æ®çš„æ¥æºã€‚
- en: III-B Driving Style Selection and Data Organization
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B é©¾é©¶é£æ ¼é€‰æ‹©ä¸æ•°æ®ç»„ç»‡
- en: Having completed driving experiments and post-experiment interviews, our next
    task is to differentiate the driversâ€™ driving styles and organize the think-aloud
    data into demonstrations of different styles.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®Œæˆé©¾é©¶å®éªŒå’Œåå®éªŒè®¿è°ˆåï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€æ­¥ä»»åŠ¡æ˜¯åŒºåˆ†é©¾é©¶å‘˜çš„é©¾é©¶é£æ ¼ï¼Œå¹¶å°†æ€ç»´è¿‡ç¨‹æ•°æ®ç»„ç»‡æˆä¸åŒé£æ ¼çš„æ¼”ç¤ºã€‚
- en: 'The differentiation of driving styles is based on subjective questionnaire
    results and objective driving records in driving tasks. We distributed a MDSI
    questionnaire[[32](https://arxiv.org/html/2403.11368v1#bib.bib32)] to each driver
    invited to participate in the experiment. The results indicated the presence of
    four driving styles among the 24 drivers: risky, high-velocity, patient, and careful.
    Notably, the risky style often coincided with the high-velocity style, while the
    patient style typically appeared alongside the careful style. Further analysis
    of the CAN-Bus data during driving tasks revealed that 3 drivers exhibited speeds
    and throttle percentages significantly above the average â€” specifically, the average
    speed of all drivers was 6.40 m/s and average throttle percentage was 23.09%,
    while average speed of these 3 drivers respectively reached speeds of 7.73 m/s
    (20.78% higher than average), 7.50 m/s (17.19% higher than average) and 7.41 m/s
    (15.78% higher than average), and average throttle percentages reached 29.09%
    (25.99% higher than average), 24.42% (5.76% higher than average) and 24.37% (5.54%
    higher than average) â€” aligning with their self-reported â€™risky and high-velocityâ€™
    driving styles in the questionnaire. Conversely, 2 other drivers had lower metrics
    â€” with speeds of 5.15 m/s (19.53% lower than average) and 5.28 m/s (17.50% lower
    than average) respectively, and throttle percentage of 21.00% (9.05% lower than
    average) and 21.34% (7.58% lower than average) â€” aligning with their self-reported
    â€™patient and carefulâ€™ driving styles in the questionnaire. Additionally, a few
    drivers who reported to have driving styles in the questionnaire did not show
    clear trends in either driving data or interview records.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: é©¾é©¶é£æ ¼çš„åŒºåˆ†åŸºäºé©¾é©¶ä»»åŠ¡ä¸­çš„ä¸»è§‚é—®å·ç»“æœå’Œå®¢è§‚é©¾é©¶è®°å½•ã€‚æˆ‘ä»¬å‘æ¯ä½å—é‚€å‚ä¸å®éªŒçš„é©¾é©¶å‘˜åˆ†å‘äº†MDSIé—®å·[[32](https://arxiv.org/html/2403.11368v1#bib.bib32)]ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨24åé©¾é©¶å‘˜ä¸­ï¼Œå­˜åœ¨å››ç§é©¾é©¶é£æ ¼ï¼šå†’é™©ã€é«˜é€Ÿã€è€å¿ƒå’Œå°å¿ƒã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå†’é™©é£æ ¼é€šå¸¸ä¸é«˜é€Ÿé£æ ¼é‡åˆï¼Œè€Œè€å¿ƒé£æ ¼é€šå¸¸ä¸å°å¿ƒé£æ ¼ä¸€èµ·å‡ºç°ã€‚è¿›ä¸€æ­¥åˆ†æé©¾é©¶ä»»åŠ¡ä¸­çš„CAN-Busæ•°æ®è¡¨æ˜ï¼Œ3åé©¾é©¶å‘˜çš„è½¦é€Ÿå’Œæ²¹é—¨ç™¾åˆ†æ¯”æ˜æ˜¾é«˜äºå¹³å‡æ°´å¹³â€”â€”å…·ä½“æ¥è¯´ï¼Œæ‰€æœ‰é©¾é©¶å‘˜çš„å¹³å‡è½¦é€Ÿä¸º6.40
    m/sï¼Œå¹³å‡æ²¹é—¨ç™¾åˆ†æ¯”ä¸º23.09%ï¼Œè€Œè¿™3åé©¾é©¶å‘˜çš„å¹³å‡è½¦é€Ÿåˆ†åˆ«è¾¾åˆ°äº†7.73 m/sï¼ˆæ¯”å¹³å‡å€¼é«˜20.78%ï¼‰ã€7.50 m/sï¼ˆæ¯”å¹³å‡å€¼é«˜17.19%ï¼‰å’Œ7.41
    m/sï¼ˆæ¯”å¹³å‡å€¼é«˜15.78%ï¼‰ï¼Œæ²¹é—¨ç™¾åˆ†æ¯”åˆ†åˆ«ä¸º29.09%ï¼ˆæ¯”å¹³å‡å€¼é«˜25.99%ï¼‰ã€24.42%ï¼ˆæ¯”å¹³å‡å€¼é«˜5.76%ï¼‰å’Œ24.37%ï¼ˆæ¯”å¹³å‡å€¼é«˜5.54%ï¼‰â€”â€”è¿™äº›æ•°æ®ä¸ä»–ä»¬åœ¨é—®å·ä¸­è‡ªæŠ¥å‘Šçš„'å†’é™©å’Œé«˜é€Ÿ'é©¾é©¶é£æ ¼ç›¸ç¬¦ã€‚ç›¸åï¼Œå¦å¤–2åé©¾é©¶å‘˜çš„æŒ‡æ ‡è¾ƒä½â€”â€”ä»–ä»¬çš„è½¦é€Ÿåˆ†åˆ«ä¸º5.15
    m/sï¼ˆæ¯”å¹³å‡å€¼ä½19.53%ï¼‰å’Œ5.28 m/sï¼ˆæ¯”å¹³å‡å€¼ä½17.50%ï¼‰ï¼Œæ²¹é—¨ç™¾åˆ†æ¯”åˆ†åˆ«ä¸º21.00%ï¼ˆæ¯”å¹³å‡å€¼ä½9.05%ï¼‰å’Œ21.34%ï¼ˆæ¯”å¹³å‡å€¼ä½7.58%ï¼‰â€”â€”è¿™äº›æ•°æ®ä¸ä»–ä»¬åœ¨é—®å·ä¸­è‡ªæŠ¥å‘Šçš„'è€å¿ƒå’Œå°å¿ƒ'é©¾é©¶é£æ ¼ç›¸ç¬¦ã€‚æ­¤å¤–ï¼Œä¸€äº›åœ¨é—®å·ä¸­æŠ¥å‘Šäº†é©¾é©¶é£æ ¼çš„é©¾é©¶å‘˜ï¼Œåœ¨é©¾é©¶æ•°æ®æˆ–è®¿è°ˆè®°å½•ä¸­æœªæ˜¾ç¤ºå‡ºæ˜ç¡®çš„è¶‹åŠ¿ã€‚
- en: 'Therefore, we identified two basic driving styles: â€™riskyâ€™ and â€™high-velocityâ€™
    were merged into â€™risky,â€™ while â€™patientâ€™ and â€™carefulâ€™ were combined into â€™cautious.â€™
    We reviewed the interview data of drivers with risky driving styles and those
    with cautious driving styles, selecting representative decision-making processes
    that exemplify each driving style. Then, we organized each process according to
    the decision sequence into the format of â€™Situationâ€™, â€™Reasoningâ€™ and â€™Actionâ€™,
    forming the final Demonstrations for alignment with humans.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬è¯†åˆ«äº†ä¸¤ç§åŸºæœ¬çš„é©¾é©¶é£æ ¼ï¼š'å†’é™©'å’Œ'é«˜é€Ÿ'åˆå¹¶ä¸º'å†’é™©'ï¼Œè€Œ'è€å¿ƒ'å’Œ'å°å¿ƒ'åˆ™åˆå¹¶ä¸º'è°¨æ…'ã€‚æˆ‘ä»¬å›é¡¾äº†å…·æœ‰å†’é™©é©¾é©¶é£æ ¼å’Œè°¨æ…é©¾é©¶é£æ ¼çš„é©¾é©¶å‘˜çš„è®¿è°ˆæ•°æ®ï¼Œé€‰æ‹©äº†å…·æœ‰ä»£è¡¨æ€§çš„å†³ç­–è¿‡ç¨‹ï¼Œå±•ç¤ºäº†æ¯ç§é©¾é©¶é£æ ¼ã€‚ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®å†³ç­–é¡ºåºå°†æ¯ä¸ªè¿‡ç¨‹ç»„ç»‡æˆ'æƒ…å¢ƒ'ã€'æ¨ç†'å’Œ'è¡ŒåŠ¨'çš„æ ¼å¼ï¼Œå½¢æˆæœ€ç»ˆçš„ç¤ºèŒƒï¼Œä¸äººç±»è¿›è¡Œå¯¹é½ã€‚
- en: IV Experiment
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV å®éªŒ
- en: 'In this section, we validated the proposed Multi-alignment Framework by exploring
    the following questions:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ¢è®¨ä»¥ä¸‹é—®é¢˜æ¥éªŒè¯æ‰€æå‡ºçš„å¤šé‡å¯¹é½æ¡†æ¶ï¼š
- en: â€¢
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Can Driver Agents with different driving styles be constructed using human think-aloud
    data?
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸åŒé©¾é©¶é£æ ¼çš„é©¾é©¶ä»£ç†èƒ½å¦ä½¿ç”¨äººç±»æ€ç»´å¤§å£°æ€è€ƒæ•°æ®æ„å»ºï¼Ÿ
- en: â€¢
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: Which alignment method can efficiently achieve human alignment of driving styles?
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å“ªç§å¯¹é½æ–¹æ³•å¯ä»¥æœ‰æ•ˆå®ç°é©¾é©¶é£æ ¼çš„äººç±»å¯¹é½ï¼Ÿ
- en: To this end, we implemented the Multi-alignment Framework on CARLAâ€”a high-fidelity
    traffic simulator. A simulation experiment was carried out under urban driving
    conditions, upon which we further conducted a user experiment to collect human
    evaluations of its performance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨CARLAâ€”â€”ä¸€ä¸ªé«˜ä¿çœŸåº¦çš„äº¤é€šæ¨¡æ‹Ÿå™¨ä¸Šå®ç°äº†å¤šé‡å¯¹é½æ¡†æ¶ã€‚æˆ‘ä»¬åœ¨åŸå¸‚é©¾é©¶æ¡ä»¶ä¸‹è¿›è¡Œäº†æ¨¡æ‹Ÿå®éªŒï¼Œå¹¶è¿›ä¸€æ­¥è¿›è¡Œäº†ä¸€é¡¹ç”¨æˆ·å®éªŒï¼Œä»¥æ”¶é›†äººç±»å¯¹å…¶æ€§èƒ½çš„è¯„ä»·ã€‚
- en: IV-A Conditions
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A æ¡ä»¶
- en: '![Refer to caption](img/c0babe77d1528b39af2fcafec07e9ea1.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§æ ‡é¢˜](img/c0babe77d1528b39af2fcafec07e9ea1.png)'
- en: 'Figure 2: Experiment conditions'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2ï¼šå®éªŒæ¡ä»¶
- en: 'The experiment adopts an approximate 3 Ã— 3 with-in subject design with two
    main variables: Driving Style [cautiousÂ (C), riskyÂ (R)and not-alignedÂ (N)] and
    Alignment Method [demonstrationsÂ (D), feedbackÂ (F)and multi-alignmentÂ (M)]. Fig.
    [2](https://arxiv.org/html/2403.11368v1#S4.F2 "Figure 2 â€£ IV-A Conditions â€£ IV
    Experiment â€£ Driving Style Alignment for LLM-powered Driver Agent") shows the
    general design of different conditions.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬å®éªŒé‡‡ç”¨äº†ä¸€ä¸ªå¤§çº¦3 Ã— 3çš„è¢«è¯•å†…è®¾è®¡ï¼Œä¸»è¦å˜é‡æœ‰ä¸¤ä¸ªï¼šé©¾é©¶é£æ ¼[è°¨æ…ï¼ˆCï¼‰ã€å†’é™©ï¼ˆRï¼‰å’Œæœªå¯¹é½ï¼ˆNï¼‰]å’Œå¯¹é½æ–¹æ³•[æ¼”ç¤ºï¼ˆDï¼‰ã€åé¦ˆï¼ˆFï¼‰å’Œå¤šé‡å¯¹é½ï¼ˆMï¼‰]ã€‚å›¾[2](https://arxiv.org/html/2403.11368v1#S4.F2
    "Figure 2 â€£ IV-A Conditions â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered
    Driver Agent")å±•ç¤ºäº†ä¸åŒæ¡ä»¶çš„æ•´ä½“è®¾è®¡ã€‚
- en: In terms of Driving Style, we compared the effects of using cautiousÂ driving
    demonstrations, riskyÂ driving demonstrations, and no demonstrations (i.e., not-aligned).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é©¾é©¶é£æ ¼æ–¹é¢ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†ä½¿ç”¨è°¨æ…é©¾é©¶æ¼”ç¤ºã€å†’é™©é©¾é©¶æ¼”ç¤ºå’Œæ— æ¼”ç¤ºï¼ˆå³æœªå¯¹é½ï¼‰ä¸‰ç§æƒ…å†µä¸‹çš„æ•ˆæœã€‚
- en: Alignment Method was organized in an ablation format, with conditions including
    demonstrations, feedback, and multi-alignmentÂ (i.e., the full alignment framework).
    The demonstrationsÂ condition involves Driver Agents provided with demonstrations,
    and the feedbackÂ condition involves Driver Agents without demonstrations and Coach
    Agents that were provided with demonstrations, while in the multi-alignmentÂ condition,
    both Driver Agent and Coach Agent were provided with demonstrations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹é½æ–¹æ³•é‡‡ç”¨äº†æ¶ˆèå®éªŒçš„å½¢å¼ï¼Œå…¶ä¸­åŒ…å«äº†æ¼”ç¤ºã€åé¦ˆå’Œå¤šé‡å¯¹é½ï¼ˆå³å®Œæ•´çš„å¯¹é½æ¡†æ¶ï¼‰ç­‰æ¡ä»¶ã€‚æ¼”ç¤ºæ¡ä»¶æ¶‰åŠä¸ºé©¾é©¶ä»£ç†æä¾›æ¼”ç¤ºï¼Œè€Œåé¦ˆæ¡ä»¶åˆ™æ˜¯æ²¡æœ‰æ¼”ç¤ºçš„é©¾é©¶ä»£ç†å’Œæœ‰æ¼”ç¤ºçš„æ•™ç»ƒä»£ç†ï¼›åœ¨å¤šé‡å¯¹é½æ¡ä»¶ä¸‹ï¼Œé©¾é©¶ä»£ç†å’Œæ•™ç»ƒä»£ç†éƒ½æä¾›äº†æ¼”ç¤ºã€‚
- en: IV-B CARLA Simulation
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B CARLAæ¨¡æ‹Ÿ
- en: IV-B1 Set-up
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 è®¾ç½®
- en: The simulation experiment setup involved a ThundeRobot Zero desktop computer
    as the hardware foundation. The simulation environment was built upon the CARLA
    simulator, specifically, version 0.9.14Â³Â³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)
    and operated on Python 3.7 with Unreal Engine 4â´â´4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/).
    We use the map Town10, a typical urban driving scene, with both the number of
    other vehicles and pedestrians in the scenario set to 60\. And Audi TT was the
    designated vehicle for all experiments, with fixed starting and continuously,
    randomly generated ending points for its path (After a vehicle is generated at
    a predefined fixed point, a random endpoint is generated. Upon reaching the endpoint,
    another endpoint is randomly generated, and so on.).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿå®éªŒçš„ç¡¬ä»¶åŸºç¡€æ˜¯ThundeRobot Zeroå°å¼è®¡ç®—æœºã€‚æ¨¡æ‹Ÿç¯å¢ƒåŸºäºCARLAæ¨¡æ‹Ÿå™¨ï¼Œå…·ä½“ç‰ˆæœ¬ä¸º0.9.14Â³Â³3[http://carla.org/2022/12/23/release-0.9.14/](http://carla.org/2022/12/23/release-0.9.14/)ï¼Œå¹¶åœ¨Python
    3.7å’ŒUnreal Engine 4â´â´4[https://docs.unrealengine.com/4.27/en-US/](https://docs.unrealengine.com/4.27/en-US/)ä¸Šè¿è¡Œã€‚æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯Town10åœ°å›¾ï¼Œä¸€ä¸ªå…¸å‹çš„åŸå¸‚é©¾é©¶åœºæ™¯ï¼Œåœºæ™¯ä¸­å…¶ä»–è½¦è¾†å’Œè¡Œäººçš„æ•°é‡éƒ½è®¾ç½®ä¸º60ã€‚Audi
    TTæ˜¯æ‰€æœ‰å®éªŒçš„æŒ‡å®šè½¦è¾†ï¼Œå…¶è·¯å¾„æœ‰å›ºå®šçš„èµ·ç‚¹å’ŒæŒç»­éšæœºç”Ÿæˆçš„ç»ˆç‚¹ï¼ˆè½¦è¾†åœ¨é¢„å®šä¹‰çš„å›ºå®šç‚¹ç”Ÿæˆåï¼Œä¼šéšæœºç”Ÿæˆä¸€ä¸ªç»ˆç‚¹ï¼Œè¾¾åˆ°ç»ˆç‚¹åä¼šå†éšæœºç”Ÿæˆä¸‹ä¸€ä¸ªç»ˆç‚¹ï¼Œä¾æ­¤ç±»æ¨ï¼‰ã€‚
- en: We leverage OpenAIâ€™s GPT-4âµâµ5[https://openai.com/gpt-4](https://openai.com/gpt-4)
    APIs for constructing both the Driver Agent and the Coach Agent. However, it takes
    several seconds for GPT to generate a response, which is too long in a driving
    context for making immediate decisions. Therefore, we slowed down CARLAâ€™s simulation
    time based on the required token count by setting a fixed time-step of 0.0008-0.0015
    seconds.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ©ç”¨OpenAIçš„GPT-4âµâµ5[https://openai.com/gpt-4](https://openai.com/gpt-4) APIæ„å»ºäº†é©¾é©¶ä»£ç†å’Œæ•™ç»ƒä»£ç†ã€‚ç„¶è€Œï¼Œç”±äºGPTç”Ÿæˆå“åº”éœ€è¦å‡ ç§’é’Ÿçš„æ—¶é—´ï¼Œè¿™åœ¨é©¾é©¶æƒ…å¢ƒä¸­ä½œå‡ºå³æ—¶å†³ç­–æ—¶æ˜¾å¾—è¿‡é•¿ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ ¹æ®æ‰€éœ€çš„tokenæ•°é‡ï¼Œå°†CARLAçš„æ¨¡æ‹Ÿæ—¶é—´å‡æ…¢ï¼Œè®¾ç½®å›ºå®šæ—¶é—´æ­¥é•¿ä¸º0.0008-0.0015ç§’ã€‚
- en: Each simulation process is recorded on video. Additionally, to collect vehicle
    status information during the simulation, we initiated a log-collector thread
    to accumulate log on collisions, speed, throttle percentage, and brake percentage
    from the agent vehicle on a second-by-second basis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¨¡æ‹Ÿè¿‡ç¨‹éƒ½è¿›è¡Œäº†è§†é¢‘å½•åˆ¶ã€‚æ­¤å¤–ï¼Œä¸ºäº†åœ¨æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­æ”¶é›†è½¦è¾†çŠ¶æ€ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯åŠ¨äº†ä¸€ä¸ªæ—¥å¿—æ”¶é›†çº¿ç¨‹ï¼ŒæŒ‰ç§’è®°å½•ä»£ç†è½¦è¾†çš„ç¢°æ’ã€é€Ÿåº¦ã€æ²¹é—¨ç™¾åˆ†æ¯”å’Œåˆ¹è½¦ç™¾åˆ†æ¯”æ—¥å¿—ã€‚
- en: IV-B2 Metrics
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 æŒ‡æ ‡
- en: 'Here, we introduce three metrics to evaluate the driving performance of the
    Driver Agent: collision rate, speed, throttle percentage, and brake percentage.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸‰é¡¹æŒ‡æ ‡æ¥è¯„ä¼°é©¾é©¶ä»£ç†çš„é©¾é©¶è¡¨ç°ï¼šç¢°æ’ç‡ã€é€Ÿåº¦ã€æ²¹é—¨ç™¾åˆ†æ¯”å’Œåˆ¹è½¦ç™¾åˆ†æ¯”ã€‚
- en: â€¢
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Collision rate: The number of collisions can be obtained from the log, with
    distance traveled being cumulative up to the last collision. The calculating formula
    is $Collisions\ per\ Meter=\frac{Number\ of\ Collisions}{Distance\ Traveled\ (m)}$'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç¢°æ’ç‡ï¼šç¢°æ’æ¬¡æ•°å¯ä»¥ä»æ—¥å¿—ä¸­è·å¾—ï¼Œè¡Œé©¶è·ç¦»åˆ™æ˜¯ä»ä¸Šæ¬¡ç¢°æ’èµ·ç´¯è®¡çš„ã€‚è®¡ç®—å…¬å¼ä¸º $Collisions\ per\ Meter=\frac{Number\
    of\ Collisions}{Distance\ Traveled\ (m)}$
- en: â€¢
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Speed: The statistical measures for speed include the average speed of the
    agent vehicle during each simulation and the segmented average speed per minute
    (simulator time). All calculations of average speed exclude zero values to minimize
    the impact of the agent vehicle waiting at traffic signals and in traffic jams.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è½¦é€Ÿï¼šè½¦é€Ÿçš„ç»Ÿè®¡æŒ‡æ ‡åŒ…æ‹¬ä»£ç†è½¦è¾†åœ¨æ¯æ¬¡æ¨¡æ‹Ÿè¿‡ç¨‹ä¸­çš„å¹³å‡è½¦é€Ÿï¼Œä»¥åŠæ¯åˆ†é’Ÿçš„åˆ†æ®µå¹³å‡è½¦é€Ÿï¼ˆæ¨¡æ‹Ÿå™¨æ—¶é—´ï¼‰ã€‚æ‰€æœ‰å¹³å‡è½¦é€Ÿçš„è®¡ç®—éƒ½æ’é™¤äº†é›¶å€¼ï¼Œä»¥å°½é‡å‡å°‘ä»£ç†è½¦è¾†åœ¨äº¤é€šä¿¡å·ç¯å‰ç­‰å¾…æˆ–äº¤é€šå µå¡æ—¶çš„å½±å“ã€‚
- en: â€¢
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Throttle percentage & brake percentage: The statistics for throttle and brake
    percentages are also divided into overall average values and segmented average
    values per minute. Similarly, all calculations exclude data from when the agent
    vehicle is stationary.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ²¹é—¨ç™¾åˆ†æ¯”å’Œåˆ¹è½¦ç™¾åˆ†æ¯”ï¼šæ²¹é—¨å’Œåˆ¹è½¦çš„ç»Ÿè®¡æ•°æ®ä¹Ÿåˆ†ä¸ºæ•´ä½“å¹³å‡å€¼å’Œæ¯åˆ†é’Ÿçš„åˆ†æ®µå¹³å‡å€¼ã€‚åŒæ ·ï¼Œæ‰€æœ‰è®¡ç®—éƒ½æ’é™¤äº†ä»£ç†è½¦è¾†é™æ­¢æ—¶çš„æ•°æ®ã€‚
- en: IV-B3 Results
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B3 ç»“æœ
- en: '![Refer to caption](img/069fc753a0dfd82d24b0e14dd4c6f230.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/069fc753a0dfd82d24b0e14dd4c6f230.png)'
- en: \thesubsubfigure Collision rates per meter (with increased incidences of abrupt
    maneuvers by surrounding vehicles and pedestrians).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: \thesubsubfigure ç¢°æ’ç‡æ¯ç±³ï¼ˆå‘¨å›´è½¦è¾†å’Œè¡Œäººçš„çªç„¶æœºåŠ¨å¢åŠ æ—¶ï¼‰ã€‚
- en: '![Refer to caption](img/39ca1c167646acd545a03e83308356d2.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒè¯´æ˜](img/39ca1c167646acd545a03e83308356d2.png)'
- en: \thesubsubfigure Average throttle percentage (left), brake percentage (middle),
    and speed (right) of the agent vehicle, with all calculations excluding data from
    when the agent vehicle was stationary (the speed limit is km/h).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: \thesubsubfigure ä»£ç†è½¦è¾†çš„å¹³å‡æ²¹é—¨ç™¾åˆ†æ¯”ï¼ˆå·¦ï¼‰ã€åˆ¹è½¦ç™¾åˆ†æ¯”ï¼ˆä¸­ï¼‰å’Œè½¦é€Ÿï¼ˆå³ï¼‰ï¼Œæ‰€æœ‰è®¡ç®—æ’é™¤äº†ä»£ç†è½¦è¾†é™æ­¢æ—¶çš„æ•°æ®ï¼ˆè½¦é€Ÿå•ä½ä¸º km/hï¼‰ã€‚
- en: 'Figure 3: Simulation experiment results for predefined metrics.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3ï¼šé¢„å®šä¹‰æŒ‡æ ‡çš„æ¨¡æ‹Ÿå®éªŒç»“æœã€‚
- en: We conducted approximately 50.3 hours of simulation experiments under various
    conditions, which corresponds to an average of about 6.7 minutes of driving per
    condition for the agent vehicle on the simulation platform. The average distance
    the agent vehicle traveled per condition was approximately 1.5 kilometers. Notably,
    we adjusted the algorithms controlling other vehicles and pedestrians to make
    them more prone to sudden maneuvers (e.g. abrupt lane changes, running red lights).
    These edge cases aim to increase the risk level of the driving environment for
    the agent vehicle, making its driving style more observable.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ä¸åŒæ¡ä»¶ä¸‹è¿›è¡Œäº†çº¦50.3å°æ—¶çš„æ¨¡æ‹Ÿå®éªŒï¼Œç›¸å½“äºæ¯ä¸ªæ¡ä»¶ä¸‹ä»£ç†è½¦è¾†åœ¨æ¨¡æ‹Ÿå¹³å°ä¸Šçš„å¹³å‡é©¾é©¶æ—¶é—´ä¸ºçº¦6.7åˆ†é’Ÿã€‚æ¯ä¸ªæ¡ä»¶ä¸‹ä»£ç†è½¦è¾†è¡Œé©¶çš„å¹³å‡è·ç¦»çº¦ä¸º1.5å…¬é‡Œã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è°ƒæ•´äº†æ§åˆ¶å…¶ä»–è½¦è¾†å’Œè¡Œäººçš„ç®—æ³•ï¼Œä½¿å…¶æ›´å®¹æ˜“è¿›è¡Œçªç„¶çš„æœºåŠ¨ï¼ˆä¾‹å¦‚æ€¥å‰§å˜é“ã€é—¯çº¢ç¯ï¼‰ã€‚è¿™äº›æç«¯æƒ…å†µæ—¨åœ¨å¢åŠ ä»£ç†è½¦è¾†æ‰€å¤„é©¾é©¶ç¯å¢ƒçš„é£é™©çº§åˆ«ï¼Œä»è€Œä½¿å…¶é©¾é©¶é£æ ¼æ›´ä¸ºå¯è§‚å¯Ÿã€‚
- en: Fig. [3](https://arxiv.org/html/2403.11368v1#S4.F3 "Figure 3 â€£ IV-B3 Results
    â€£ IV-B CARLA Simulation â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered
    Driver Agent") displays the collision rates per meter for the agent vehicle calculated
    under different conditions. Agents aligned with the riskyÂ driving style overall
    exhibit higher collision rates, while those aligned with the cautiousÂ driving
    style show lower collision rates overall. Additionally, when aligned with cautiousÂ driving
    style, the multi-alignmentÂ method displayed the lowest collision rate while the
    demonstrationsÂ method displayed the highest, and when aligned with riskyÂ driving
    style, the multi-alignmentÂ method showed the highest collision rate while the
    demonstrationsÂ method displayed the highest. When not-aligned, the collision rate
    for the demonstrationsÂ method is higher than that for the feedbackÂ method.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[3](https://arxiv.org/html/2403.11368v1#S4.F3 "å›¾ 3 â€£ IV-B3 ç»“æœ â€£ IV-B CARLA
    æ¨¡æ‹Ÿ â€£ IV å®éªŒ â€£ åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é©¾é©¶å‘˜ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½")å±•ç¤ºäº†ä»£ç†è½¦è¾†åœ¨ä¸åŒæ¡ä»¶ä¸‹è®¡ç®—çš„æ¯ç±³ç¢°æ’ç‡ã€‚æ•´ä½“è€Œè¨€ï¼Œä¸é£é™©é©¾é©¶é£æ ¼å¯¹é½çš„ä»£ç†è½¦è¾†ç¢°æ’ç‡è¾ƒé«˜ï¼Œè€Œä¸è°¨æ…é©¾é©¶é£æ ¼å¯¹é½çš„è½¦è¾†ç¢°æ’ç‡è¾ƒä½ã€‚æ­¤å¤–ï¼Œå½“ä¸è°¨æ…é©¾é©¶é£æ ¼å¯¹é½æ—¶ï¼Œå¤šé‡å¯¹é½æ–¹æ³•çš„ç¢°æ’ç‡æœ€ä½ï¼Œè€Œç¤ºèŒƒæ–¹æ³•çš„ç¢°æ’ç‡æœ€é«˜ï¼›è€Œå½“ä¸é£é™©é©¾é©¶é£æ ¼å¯¹é½æ—¶ï¼Œå¤šé‡å¯¹é½æ–¹æ³•çš„ç¢°æ’ç‡æœ€é«˜ï¼Œç¤ºèŒƒæ–¹æ³•çš„ç¢°æ’ç‡ä¹Ÿè¾ƒé«˜ã€‚åœ¨æœªå¯¹é½çš„æƒ…å†µä¸‹ï¼Œç¤ºèŒƒæ–¹æ³•çš„ç¢°æ’ç‡é«˜äºåé¦ˆæ–¹æ³•ã€‚
- en: Fig. [3](https://arxiv.org/html/2403.11368v1#S4.F3 "Figure 3 â€£ IV-B3 Results
    â€£ IV-B CARLA Simulation â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered
    Driver Agent") presents the average throttle percentage, brake percentage, and
    speed of the agent vehicle during the driving process under different conditions,
    with all calculations excluding data from when the agent vehicle was stationary.
    When using the same alignment method, agents aligned with the riskyÂ driving style
    had the highest average speed, highest throttle percentage, and lowest brake percentage,
    while agents aligned with the cautiousÂ driving style had the lowest speed, lowest
    throttle percentage, and highest brake percentage. When aligned with the cautiousÂ driving
    style, the average speed and throttle percentage decrease while the average brake
    percentage increases across the demonstrations, feedback, and multi-alignment,
    in that order. The opposite trend is observed when aligning with the riskyÂ driving
    style. When not-aligned, the average speed and throttle percentage for the demonstrationsÂ method
    are higher than those for the feedbackÂ method, while the average brake percentage
    is lower.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[3](https://arxiv.org/html/2403.11368v1#S4.F3 "å›¾ 3 â€£ IV-B3 ç»“æœ â€£ IV-B CARLAæ¨¡æ‹Ÿ
    â€£ IVå®éªŒ â€£ å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é©¾é©¶ä»£ç†çš„é©¾é©¶é£æ ¼å¯¹é½")å±•ç¤ºäº†ä¸åŒæ¡ä»¶ä¸‹ï¼Œä»£ç†è½¦è¾†åœ¨é©¾é©¶è¿‡ç¨‹ä¸­çš„å¹³å‡æ²¹é—¨ç™¾åˆ†æ¯”ã€åˆ¹è½¦ç™¾åˆ†æ¯”å’Œé€Ÿåº¦ï¼Œæ‰€æœ‰è®¡ç®—éƒ½æ’é™¤äº†ä»£ç†è½¦è¾†åœé©¶æ—¶çš„æ•°æ®ã€‚åœ¨ä½¿ç”¨ç›¸åŒå¯¹é½æ–¹æ³•æ—¶ï¼Œä¸å±é™©é©¾é©¶é£æ ¼å¯¹é½çš„ä»£ç†å…·æœ‰æœ€é«˜çš„å¹³å‡é€Ÿåº¦ã€æœ€é«˜çš„æ²¹é—¨ç™¾åˆ†æ¯”å’Œæœ€ä½çš„åˆ¹è½¦ç™¾åˆ†æ¯”ï¼Œè€Œä¸è°¨æ…é©¾é©¶é£æ ¼å¯¹é½çš„ä»£ç†åˆ™å…·æœ‰æœ€ä½çš„é€Ÿåº¦ã€æœ€ä½çš„æ²¹é—¨ç™¾åˆ†æ¯”å’Œæœ€é«˜çš„åˆ¹è½¦ç™¾åˆ†æ¯”ã€‚ä¸è°¨æ…é©¾é©¶é£æ ¼å¯¹é½æ—¶ï¼Œæ¼”ç¤ºã€åé¦ˆå’Œå¤šé‡å¯¹é½é¡ºåºä¸­ï¼Œå¹³å‡é€Ÿåº¦å’Œæ²¹é—¨ç™¾åˆ†æ¯”ä¸‹é™ï¼Œè€Œåˆ¹è½¦ç™¾åˆ†æ¯”ä¸Šå‡ã€‚ä¸å±é™©é©¾é©¶é£æ ¼å¯¹é½æ—¶ï¼Œè§‚å¯Ÿåˆ°ç›¸åçš„è¶‹åŠ¿ã€‚åœ¨æœªå¯¹é½çš„æƒ…å†µä¸‹ï¼Œæ¼”ç¤ºæ³•çš„å¹³å‡é€Ÿåº¦å’Œæ²¹é—¨ç™¾åˆ†æ¯”é«˜äºåé¦ˆæ³•ï¼Œè€Œåˆ¹è½¦ç™¾åˆ†æ¯”åˆ™è¾ƒä½ã€‚
- en: IV-B4 Findings
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B4 å‘ç°
- en: Based on the hypothesis that agents with more cautious driving styles are safer,
    agents can exhibit corresponding driving styles by aligning with different driving
    styles. multi-alignmentÂ was the most effective method, displaying the most significant
    differences in collision rates, average throttle, brake, and speed between cautious
    and risky driving styles, while demonstrationsÂ were less effective.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºä»£ç†å…·æœ‰æ›´è°¨æ…é©¾é©¶é£æ ¼æ›´å®‰å…¨çš„å‡è®¾ï¼Œä»£ç†å¯ä»¥é€šè¿‡ä¸ä¸åŒé©¾é©¶é£æ ¼å¯¹é½æ¥å±•ç¤ºç›¸åº”çš„é©¾é©¶é£æ ¼ã€‚å¤šé‡å¯¹é½æ˜¯æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼Œåœ¨è°¨æ…ä¸å±é™©é©¾é©¶é£æ ¼ä¹‹é—´ï¼Œç¢°æ’ç‡ã€å¹³å‡æ²¹é—¨ã€åˆ¹è½¦å’Œé€Ÿåº¦æ˜¾ç¤ºå‡ºæ˜¾è‘—å·®å¼‚ï¼Œè€Œæ¼”ç¤ºæ³•çš„æ•ˆæœè¾ƒå¼±ã€‚
- en: IV-C Human Evaluation
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C äººç±»è¯„ä¼°
- en: IV-C1 Procedure
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 ç¨‹åº
- en: We designed two survey questionnaires to collect human driversâ€™ evaluations
    of the Driver Agentâ€™s performance, which was presented to participants in the
    questionnaire through video clips of the simulation, with about 30 seconds of
    driving footage captured for each experimental condition.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾è®¡äº†ä¸¤ä»½è°ƒæŸ¥é—®å·ï¼Œæ”¶é›†äººç±»é©¾é©¶å‘˜å¯¹é©¾é©¶ä»£ç†æ€§èƒ½çš„è¯„ä¼°ï¼Œé—®å·é€šè¿‡æ¨¡æ‹Ÿè§†é¢‘ç‰‡æ®µå‘ˆç°ç»™å‚ä¸è€…ï¼Œæ¯ä¸ªå®éªŒæ¡ä»¶ä¸‹éƒ½æœ‰å¤§çº¦30ç§’çš„é©¾é©¶è§†é¢‘ã€‚
- en: In Part I of the first questionnaire, we initially collected basic information
    (e.g. age, gender, whether holding a driving license) from participants. A partial
    MDSI self-assessment was also included, with items covering indicators of risky
    and careful driving styles from the MDSI.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€ä»½é—®å·çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬é¦–å…ˆæ”¶é›†äº†å‚ä¸è€…çš„åŸºæœ¬ä¿¡æ¯ï¼ˆå¦‚å¹´é¾„ã€æ€§åˆ«ã€æ˜¯å¦æŒæœ‰é©¾é©¶æ‰§ç…§ï¼‰ã€‚è¿˜åŒ…æ‹¬äº†éƒ¨åˆ†MDSIè‡ªæˆ‘è¯„ä¼°ï¼Œæ¶µç›–äº†MDSIä¸­å…³äºå±é™©é©¾é©¶å’Œè°¨æ…é©¾é©¶é£æ ¼çš„æŒ‡æ ‡ã€‚
- en: 'In Part II, the video clips are divided into four groups:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬äºŒéƒ¨åˆ†ï¼Œè§†é¢‘ç‰‡æ®µè¢«åˆ†ä¸ºå››ç»„ï¼š
- en: â€¢
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Demonstrations Group: {demonstrationsÂ cautiousÂ (DC), demonstrationsÂ not-alignedÂ (DN),
    demonstrationsÂ riskyÂ (DR)}'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ¼”ç¤ºç»„ï¼š{æ¼”ç¤ºè°¨æ…ï¼ˆDCï¼‰ã€æ¼”ç¤ºæœªå¯¹é½ï¼ˆDNï¼‰ã€æ¼”ç¤ºå±é™©ï¼ˆDRï¼‰}
- en: â€¢
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Feedback Group: {feedbackÂ cautiousÂ (FC), feedbackÂ not-alignedÂ (FN), feedbackÂ riskyÂ (FR),
    demonstrationsÂ not-alignedÂ (DN, serving as baseline in this group)}'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åé¦ˆç»„ï¼š{åé¦ˆè°¨æ…ï¼ˆFCï¼‰ã€åé¦ˆæœªå¯¹é½ï¼ˆFNï¼‰ã€åé¦ˆå±é™©ï¼ˆFRï¼‰ã€æ¼”ç¤ºæœªå¯¹é½ï¼ˆDNï¼Œåœ¨æ­¤ç»„ä¸­ä½œä¸ºåŸºçº¿ï¼‰}
- en: â€¢
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Cautious Group: {demonstrationsÂ cautiousÂ (DC), feedbackÂ cautiousÂ (FC), multi-alignmentÂ cautiousÂ (MC)}'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è°¨æ…ç»„ï¼š{æ¼”ç¤ºè°¨æ…ï¼ˆDCï¼‰ã€åé¦ˆè°¨æ…ï¼ˆFCï¼‰ã€å¤šé‡å¯¹é½è°¨æ…ï¼ˆMCï¼‰}
- en: â€¢
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: 'Risky Group: {demonstrationsÂ riskyÂ (DR), feedbackÂ riskyÂ (FR), multi-alignmentÂ riskyÂ (MR)}'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å±é™©ç»„ï¼š{æ¼”ç¤ºå±é™©ï¼ˆDRï¼‰ã€åé¦ˆå±é™©ï¼ˆFRï¼‰ã€å¤šé‡å¯¹é½å±é™©ï¼ˆMRï¼‰}
- en: Each group of video clips will appear in a random order, accompanied by a ranking
    question requiring participants to rank the driving styles in the videos according
    to their level of riskiness (a smaller number indicates more risky) and a reason
    question for explaining their rankings.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ç»„è§†é¢‘ç‰‡æ®µå°†ä»¥éšæœºé¡ºåºå‡ºç°ï¼Œå¹¶é™„æœ‰ä¸€ä¸ªæ’åé—®é¢˜ï¼Œè¦æ±‚å‚ä¸è€…æ ¹æ®è§†é¢‘ä¸­çš„é£é™©æ€§å¯¹é©¾é©¶é£æ ¼è¿›è¡Œæ’åï¼ˆæ•°å­—è¶Šå°è¡¨ç¤ºè¶Šå†’é™©ï¼‰ï¼Œå¹¶é™„æœ‰ä¸€ä¸ªç†ç”±é—®é¢˜ç”¨äºè§£é‡Šä»–ä»¬çš„æ’åã€‚
- en: Parts I of the second questionnaire are identical to the first questionnaire.
    In Part II, participants were instructed to watch all of the eight videos clips,
    which were also organized in a random order, with three scoring questions respectively
    investigated the intelligence level, riskiness level and human-likeness level
    of the agent vehicle (all from 0 to 10) and a reason question attached below each
    clip.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä»½é—®å·çš„ç¬¬ä¸€éƒ¨åˆ†ä¸ç¬¬ä¸€ä»½é—®å·ç›¸åŒã€‚åœ¨ç¬¬äºŒéƒ¨åˆ†ä¸­ï¼Œå‚ä¸è€…è¢«è¦æ±‚è§‚çœ‹æ‰€æœ‰å…«æ®µè§†é¢‘ç‰‡æ®µï¼Œè§†é¢‘é¡ºåºä¹Ÿæ˜¯éšæœºæ’åˆ—çš„ï¼Œä¸‰ä¸ªè¯„åˆ†é—®é¢˜åˆ†åˆ«è°ƒæŸ¥äº†ä»£ç†è½¦è¾†çš„æ™ºèƒ½æ€§ã€é£é™©æ€§å’Œäººç±»ç›¸ä¼¼åº¦ï¼ˆè¯„åˆ†èŒƒå›´ä¸º0åˆ°10ï¼‰ï¼Œæ¯æ®µè§†é¢‘ä¸‹æ–¹é™„æœ‰ä¸€ä¸ªåŸå› é—®é¢˜ã€‚
- en: Additionally, to filter out carelessly completed questionnaires, we set a minimum
    answering time and included trap questions in the questionnaire, which required
    participants to select a certain option.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä¸ºäº†ç­›é€‰æ‰ä¸è®¤çœŸå¡«å†™çš„é—®å·ï¼Œæˆ‘ä»¬è®¾ç½®äº†æœ€çŸ­ç­”é¢˜æ—¶é—´ï¼Œå¹¶åœ¨é—®å·ä¸­åŠ å…¥äº†é™·é˜±é—®é¢˜ï¼Œè¦æ±‚å‚ä¸è€…é€‰æ‹©æŸä¸€ç‰¹å®šé€‰é¡¹ã€‚
- en: IV-C2 Participants
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 å‚ä¸è€…
- en: We recruited over 200 participants through a third-party recruitment channel
    provided by the survey platform, offering a compensation of approximately $2.08
    per valid questionnaire completed. Additionally, our team of five researchers
    also shared our questionnaires on social media platforms, recruiting over 60 participants.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€šè¿‡è°ƒæŸ¥å¹³å°æä¾›çš„ç¬¬ä¸‰æ–¹æ‹›å‹Ÿæ¸ é“æ‹›å‹Ÿäº†200å¤šåå‚ä¸è€…ï¼Œå®Œæˆæ¯ä»½æœ‰æ•ˆé—®å·çš„è¡¥å¿çº¦ä¸º2.08ç¾å…ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬äº”åç ”ç©¶äººå‘˜è¿˜é€šè¿‡ç¤¾äº¤åª’ä½“å¹³å°åˆ†äº«äº†é—®å·ï¼Œæ‹›å‹Ÿäº†60å¤šåå‚ä¸è€…ã€‚
- en: All 270 participants verified in the questionnaire that they possess a driving
    license. Among them, there were 141 male participants, accounting for 52.22%,
    and 129 female participants, accounting for 47.78%, with ages ranging from 19
    to 54 years old.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰270åå‚ä¸è€…åœ¨é—®å·ä¸­ç¡®è®¤è‡ªå·±æŒæœ‰é©¾é©¶æ‰§ç…§ã€‚å…¶ä¸­ï¼Œ141åä¸ºç”·æ€§ï¼Œå 52.22%ï¼Œ129åä¸ºå¥³æ€§ï¼Œå 47.78%ï¼Œå¹´é¾„èŒƒå›´ä»19å²åˆ°54å²ä¸ç­‰ã€‚
- en: IV-C3 Data Analysis
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C3 æ•°æ®åˆ†æ
- en: For both questionnaires, we first categorized participantsâ€™ driving styles based
    on the results from Section I. The formula for calculating the driving style score
    is $S_{driving\ style}=\Sigma o_{risky}-\Sigma o_{cautious}$, where $o_{risky}$
    represents the option made by participants for each risky indicator, while $o_{cautious}$
    represents the option for each cautious indicator (with two negative indicators
    within, where options are included as negative values). The higher the driving
    style score, the more a participantâ€™s driving style tends towards being risky.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸¤ä»½é—®å·ï¼Œæˆ‘ä»¬é¦–å…ˆæ ¹æ®ç¬¬ä¸€éƒ¨åˆ†çš„ç»“æœå¯¹å‚ä¸è€…çš„é©¾é©¶é£æ ¼è¿›è¡Œäº†åˆ†ç±»ã€‚è®¡ç®—é©¾é©¶é£æ ¼åˆ†æ•°çš„å…¬å¼ä¸º $S_{driving\ style}=\Sigma o_{risky}-\Sigma
    o_{cautious}$ï¼Œå…¶ä¸­ $o_{risky}$ ä»£è¡¨å‚ä¸è€…åœ¨æ¯ä¸ªé£é™©æ€§æŒ‡æ ‡ä¸Šçš„é€‰æ‹©ï¼Œè€Œ $o_{cautious}$ ä»£è¡¨æ¯ä¸ªè°¨æ…æ€§æŒ‡æ ‡çš„é€‰æ‹©ï¼ˆå…¶ä¸­åŒ…å«ä¸¤ä¸ªè´Ÿé¢æŒ‡æ ‡ï¼Œé€‰é¡¹ä¸ºè´Ÿå€¼ï¼‰ã€‚é©¾é©¶é£æ ¼åˆ†æ•°è¶Šé«˜ï¼Œè¯´æ˜å‚ä¸è€…çš„é©¾é©¶é£æ ¼è¶Šå€¾å‘äºå†’é™©ã€‚
- en: For Part II of the first questionnaire, we calculated the rankings obtained
    by different video clips in the ranking question following each group of video
    clips, as well as the statistical significance between their rankings.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬ä¸€ä»½é—®å·çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¡ç®—äº†æ¯ç»„è§†é¢‘ç‰‡æ®µåæ’åé—®é¢˜å¾—åˆ°çš„ä¸åŒè§†é¢‘ç‰‡æ®µæ’åï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´æ’åçš„ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚
- en: For Part II of the second questionnaire, we separately tallied the results of
    the three scoring questions after each video clip, representing the agent vehicleâ€™s
    intelligence, riskiness, and human-likeness.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä»½é—®å·çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬åˆ†åˆ«ç»Ÿè®¡äº†æ¯æ®µè§†é¢‘ç‰‡æ®µåä¸‰ä¸ªè¯„åˆ†é—®é¢˜çš„ç»“æœï¼Œåˆ†åˆ«ä»£è¡¨äº†ä»£ç†è½¦è¾†çš„æ™ºèƒ½æ€§ã€é£é™©æ€§å’Œäººç±»ç›¸ä¼¼åº¦ã€‚
- en: Additionally, we scrutinized all the answers to the reasoning questions in both
    questionnaires, summarizing supports for judging the driving behaviors of the
    agent vehicles.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä»”ç»†å®¡æŸ¥äº†ä¸¤ä»½é—®å·ä¸­çš„æ‰€æœ‰æ¨ç†é—®é¢˜çš„ç­”æ¡ˆï¼Œæ±‡æ€»äº†åˆ¤æ–­ä»£ç†è½¦è¾†é©¾é©¶è¡Œä¸ºçš„æ”¯æŒä¾æ®ã€‚
- en: IV-C4 Results
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C4 ç»“æœ
- en: '![Refer to caption](img/50aec979bcbcdc44c7adade6a67f3ac7.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜æ–‡å­—](img/50aec979bcbcdc44c7adade6a67f3ac7.png)'
- en: '\thesubsubfigure Frequency of riskiness rankings in different groups: demonstrations
    with different driving styles (left), feedback with different driving styles (middle-left),
    cautious driving style under different alignment methods (middle-right), and risky
    driving style under different alignment methods (right). Higher rankings indicate
    higher riskiness.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: \thesubsubfigure ä¸åŒç»„åˆ«ä¸­çš„é£é™©æ’åé¢‘ç‡ï¼šå…·æœ‰ä¸åŒé©¾é©¶é£æ ¼çš„æ¼”ç¤ºï¼ˆå·¦ä¾§ï¼‰ã€å…·æœ‰ä¸åŒé©¾é©¶é£æ ¼çš„åé¦ˆï¼ˆä¸­å·¦ä¾§ï¼‰ã€ä¸åŒå¯¹é½æ–¹æ³•ä¸‹çš„è°¨æ…é©¾é©¶é£æ ¼ï¼ˆä¸­å³ä¾§ï¼‰ã€ä»¥åŠä¸åŒå¯¹é½æ–¹æ³•ä¸‹çš„å†’é™©é©¾é©¶é£æ ¼ï¼ˆå³ä¾§ï¼‰ã€‚æ’åè¶Šé«˜è¡¨ç¤ºé£é™©è¶Šå¤§ã€‚
- en: '![Refer to caption](img/9477057b8d0aad9763dbb74f246b7d93.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§æ ‡é¢˜](img/9477057b8d0aad9763dbb74f246b7d93.png)'
- en: \thesubsubfigure Pearson correlation and significance of scores for agent vehicleâ€™s
    riskiness (R), human-likeness (H), and intelligence (I).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: \thesubsubfigure ä»£ç†è½¦é£é™©æ€§ï¼ˆRï¼‰ã€äººç±»ç›¸ä¼¼åº¦ï¼ˆHï¼‰å’Œæ™ºèƒ½æ€§ï¼ˆIï¼‰è¯„åˆ†çš„çš®å°”é€Šç›¸å…³æ€§åŠæ˜¾è‘—æ€§ã€‚
- en: 'Figure 4: Human evaluation results.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4ï¼šäººç±»è¯„ä¼°ç»“æœã€‚
- en: We distributed two questionnaires for 3 days and received a total of 259 valid
    responses after screening, with 198 for the first questionnaire and 59 for the
    second. The driving style statistics in part I are highly diverse. With an average
    score of 0.61, 34 participants scores below -4 (suggesting a cautious driving
    style), while 37 participants scores over 5 (suggesting a risky driving style),
    indicating good representativeness of our results.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ†å‘äº†ä¸¤ä»½é—®å·ï¼Œå…±è®¡å‘æ”¾3å¤©ï¼Œç»è¿‡ç­›é€‰åæ”¶åˆ°äº†259ä»½æœ‰æ•ˆå›åº”ï¼Œå…¶ä¸­ç¬¬ä¸€ä»½é—®å·198ä»½ï¼Œç¬¬äºŒä»½é—®å·59ä»½ã€‚ç¬¬Iéƒ¨åˆ†çš„é©¾é©¶é£æ ¼ç»Ÿè®¡å…·æœ‰å¾ˆé«˜çš„å¤šæ ·æ€§ã€‚å¹³å‡å¾—åˆ†ä¸º0.61ï¼Œ34åå‚ä¸è€…å¾—åˆ†ä½äº-4ï¼ˆè¡¨æ˜è°¨æ…é©¾é©¶é£æ ¼ï¼‰ï¼Œè€Œ37åå‚ä¸è€…å¾—åˆ†è¶…è¿‡5ï¼ˆè¡¨æ˜å†’é™©é©¾é©¶é£æ ¼ï¼‰ï¼Œè¡¨æ˜æˆ‘ä»¬çš„ç»“æœå…·æœ‰è¾ƒå¥½çš„ä»£è¡¨æ€§ã€‚
- en: Fig. [4](https://arxiv.org/html/2403.11368v1#S4.F4 "Figure 4 â€£ IV-C4 Results
    â€£ IV-C Human Evaluation â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered
    Driver Agent") shows the rankings of riskiness for different video clips in each
    group from the first questionnaire, with higher rankings indicating higher riskiness.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ [4](https://arxiv.org/html/2403.11368v1#S4.F4 "Figure 4 â€£ IV-C4 Results â€£
    IV-C Human Evaluation â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered
    Driver Agent") å±•ç¤ºäº†ç¬¬ä¸€ä»½é—®å·ä¸­å„ç»„åˆ«è§†é¢‘ç‰‡æ®µçš„é£é™©æ€§æ’åï¼Œæ’åè¶Šé«˜è¡¨ç¤ºé£é™©è¶Šå¤§ã€‚
- en: In both the demonstrations and feedback groups, the rankings for DC and FC were
    significantly lower than those for other videos in the same group, indicating
    that they were perceived as the least risky. One participant explained choosing
    DC as the least risky in the Demonstration Group, noting, â€The car ran stably
    without veering left or right.â€ Another participant cited their reasoning for
    deeming FC the least risky in the Feedback Group, stating, â€It waits for the pedestrian
    ahead to pass by.â€
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¼”ç¤ºç»„å’Œåé¦ˆç»„ä¸­ï¼ŒDCå’ŒFCçš„æ’åæ˜¾è‘—ä½äºåŒç»„å…¶ä»–è§†é¢‘ï¼Œè¡¨æ˜å®ƒä»¬è¢«è®¤ä¸ºæ˜¯æœ€ä¸å…·é£é™©çš„ã€‚ä¸€ä½å‚ä¸è€…è§£é‡Šäº†ä¸ºä»€ä¹ˆåœ¨æ¼”ç¤ºç»„ä¸­é€‰æ‹©DCä¸ºæœ€ä¸å…·é£é™©çš„ï¼Œè¡¨ç¤ºï¼šâ€œæ±½è½¦ç¨³å®šè¡Œé©¶ï¼Œæ²¡æœ‰åå·¦æˆ–åå³ã€‚â€å¦ä¸€ä½å‚ä¸è€…åœ¨åé¦ˆç»„ä¸­é€‰æ‹©FCä¸ºæœ€ä¸å…·é£é™©çš„ï¼Œè§£é‡Šé“ï¼šâ€œå®ƒç­‰å¾…å‰æ–¹è¡Œäººé€šè¿‡ã€‚â€
- en: When not-aligned, the riskiness of FN decreases compared to DN, with multiple
    participants noting DNâ€™s â€Decelerate too slowly when approaching a pedestrian
    crossing.â€ However, DN shows no significant difference when compared to either
    DR or FR, because they â€all look very riskyâ€
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœªå¯¹é½çš„æƒ…å†µä¸‹ï¼ŒFNçš„é£é™©æ€§ç›¸æ¯”äºDNæœ‰æ‰€ä¸‹é™ï¼Œå¤šåå‚ä¸è€…æŒ‡å‡ºDNçš„â€œåœ¨æ¥è¿‘äººè¡Œé“æ—¶å‡é€Ÿè¿‡æ…¢ã€‚â€ç„¶è€Œï¼Œä¸DRæˆ–FRç›¸æ¯”ï¼ŒDNå¹¶æ— æ˜¾è‘—å·®å¼‚ï¼Œå› ä¸ºå®ƒä»¬â€œçœ‹èµ·æ¥éƒ½å¾ˆå…·é£é™©â€ã€‚
- en: In the cautious group, the ranking of riskiness goes significantly as DC $>$
    FC $>$ MC, indicating that multi-alignmentÂ has the best alignment effect, with
    demonstrationsÂ being the least effective. The majority of participants attributed
    the rankings to â€Driver x (DC) performs lane changes a bit too quickly, whereas
    driver y (MC) not only waits for pedestrians but also yields to other vehicles.â€
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è°¨æ…ç»„ä¸­ï¼Œé£é™©æ€§æ’åæ˜¾è‘—ä¸ºDC $>$ FC $>$ MCï¼Œè¡¨æ˜å¤šé‡å¯¹é½æ–¹æ³•å…·æœ‰æœ€ä½³å¯¹é½æ•ˆæœï¼Œè€Œæ¼”ç¤ºæ–¹æ³•æ•ˆæœæœ€å·®ã€‚å¤§å¤šæ•°å‚ä¸è€…å°†æ’åå½’å› äºâ€œé©¾é©¶å‘˜xï¼ˆDCï¼‰å˜é“ç¨å¾®å¤ªå¿«ï¼Œè€Œé©¾é©¶å‘˜yï¼ˆMCï¼‰ä¸ä»…ç­‰å€™è¡Œäººï¼Œè¿˜è®©è¡Œå…¶ä»–è½¦è¾†ã€‚â€
- en: Similarly, the demonstrationsÂ method also showed the poorest alignment effect
    in the risky group, with MR slightly better than FR but not significant.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œæ¼”ç¤ºæ–¹æ³•åœ¨å†’é™©ç»„ä¸­ä¹Ÿè¡¨ç°å‡ºæœ€å·®çš„å¯¹é½æ•ˆæœï¼ŒMRç•¥ä¼˜äºFRï¼Œä½†å·®å¼‚ä¸æ˜¾è‘—ã€‚
- en: Fig.Â [4](https://arxiv.org/html/2403.11368v1#S4.F4 "Figure 4 â€£ IV-C4 Results
    â€£ IV-C Human Evaluation â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered
    Driver Agent") presents the results of the correlation analysis among participantsâ€™
    scores for riskiness, human-likeness, and intelligence for the same video clip
    in the second questionnaire. It can be observed that humans tend to associate
    higher riskiness with lower intelligence, and higher intelligence with greater
    human-likeness. Interestingly, despite cautious driving being safer, humans still
    tend to associate higher riskiness with greater human-likeness. One participant
    remarked, â€It (MR) is really like an experienced driver who is showing off his
    driving skills.â€
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾[4](https://arxiv.org/html/2403.11368v1#S4.F4 "Figure 4 â€£ IV-C4 Results â€£ IV-C
    Human Evaluation â€£ IV Experiment â€£ Driving Style Alignment for LLM-powered Driver
    Agent")å±•ç¤ºäº†ç¬¬äºŒä»½é—®å·ä¸­å‚ä¸è€…å¯¹åŒä¸€è§†é¢‘ç‰‡æ®µçš„é£é™©æ€§ã€äººç±»ç›¸ä¼¼æ€§å’Œæ™ºèƒ½æ€§è¯„åˆ†ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æç»“æœã€‚å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œäººç±»å€¾å‘äºå°†æ›´é«˜çš„é£é™©æ€§ä¸è¾ƒä½çš„æ™ºèƒ½æ€§è”ç³»åœ¨ä¸€èµ·ï¼Œå°†æ›´é«˜çš„æ™ºèƒ½æ€§ä¸æ›´å¼ºçš„äººç±»ç›¸ä¼¼æ€§è”ç³»åœ¨ä¸€èµ·ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå°½ç®¡è°¨æ…é©¾é©¶æ›´å®‰å…¨ï¼Œäººç±»ä»ç„¶å€¾å‘äºå°†æ›´é«˜çš„é£é™©æ€§ä¸æ›´å¼ºçš„äººç±»ç›¸ä¼¼æ€§è”ç³»åœ¨ä¸€èµ·ã€‚ä¸€ä½å‚ä¸è€…è¯„è®ºé“ï¼šâ€œå®ƒï¼ˆMRï¼‰çœŸåƒä¸€ä½ç»éªŒä¸°å¯Œçš„å¸æœºåœ¨ç‚«è€€ä»–çš„é©¾é©¶æŠ€æœ¯ã€‚â€
- en: IV-C5 Findings
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C5 å‘ç°
- en: The human evaluation results indicated a clear distinction in perceived riskiness
    between different driving styles. Agents aligned with cautious driving were consistently
    rated as less risky, particularly under the multi-alignment condition, which was
    proven to be the most effective for aligning driving styles. Demonstrations alone
    showed the least effectiveness in both cautious and risky conditions. Additionally,
    there is an interesting psychological insight that despite associating cautious
    driving with safety, participants tended to equate higher cautiousness with less
    human-likeness, reflecting a complex perception of human driving behavior.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: äººç±»è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œä¸åŒé©¾é©¶é£æ ¼ä¹‹é—´çš„æ„ŸçŸ¥é£é™©æ€§å­˜åœ¨æ˜æ˜¾å·®å¼‚ã€‚ä¸è°¨æ…é©¾é©¶å¯¹é½çš„ä»£ç†è¢«ä¸€è‡´è¯„ä¸ºé£é™©è¾ƒä½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šé‡å¯¹é½æ¡ä»¶ä¸‹ï¼Œè¿™ä¸€æ¡ä»¶è¢«è¯æ˜æ˜¯æœ€æœ‰æ•ˆçš„å¯¹é½é©¾é©¶é£æ ¼çš„æ–¹æ³•ã€‚ä»…å‡­æ¼”ç¤ºåœ¨è°¨æ…å’Œå†’é™©æ¡ä»¶ä¸‹çš„æ•ˆæœæœ€å·®ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªæœ‰è¶£çš„å¿ƒç†å­¦æ´å¯Ÿï¼Œå°½ç®¡äººä»¬å°†è°¨æ…é©¾é©¶ä¸å®‰å…¨è”ç³»åœ¨ä¸€èµ·ï¼Œä½†å‚ä¸è€…å€¾å‘äºå°†è¾ƒé«˜çš„è°¨æ…æ€§ä¸è¾ƒä½çš„äººç±»ç›¸ä¼¼æ€§è”ç³»åœ¨ä¸€èµ·ï¼Œåæ˜ äº†äººç±»é©¾é©¶è¡Œä¸ºçš„å¤æ‚æ„ŸçŸ¥ã€‚
- en: V CONCLUSIONS
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V ç»“è®º
- en: This paper presents a novel multi-alignment framework for aligning LLM-powered
    Driver Agents with human driving styles. Through a comprehensive set of experiments
    and evaluations, we successfully demonstrate that Driver Agents can be tailored
    to exhibit distinct driving stylesâ€”risky and cautiousâ€”by leveraging human driving
    data as chain-of-thought prompts. The frameworkâ€™s effectiveness is validated through
    simulation experiments in the CARLA urban traffic simulator and further corroborated
    by human evaluations.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¤šé‡å¯¹é½æ¡†æ¶ï¼Œç”¨äºå°†LLMé©±åŠ¨çš„å¸æœºä»£ç†ä¸äººç±»é©¾é©¶é£æ ¼å¯¹é½ã€‚é€šè¿‡ä¸€ç³»åˆ—å…¨é¢çš„å®éªŒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬æˆåŠŸåœ°å±•ç¤ºäº†é€šè¿‡åˆ©ç”¨äººç±»é©¾é©¶æ•°æ®ä½œä¸ºæ€ç»´é“¾æç¤ºï¼Œå¸æœºä»£ç†å¯ä»¥è¢«å®šåˆ¶ä¸ºå±•ç¤ºä¸åŒçš„é©¾é©¶é£æ ¼â€”â€”å†’é™©ä¸è°¨æ…ã€‚è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§é€šè¿‡åœ¨CARLAåŸå¸‚äº¤é€šæ¨¡æ‹Ÿå™¨ä¸­çš„ä»¿çœŸå®éªŒå¾—åˆ°äº†éªŒè¯ï¼Œå¹¶é€šè¿‡äººç±»è¯„ä¼°è¿›ä¸€æ­¥å¾—åˆ°äº†è¯å®ã€‚
- en: By illustrating the potential of LLMs in achieving nuanced human-agent alignment,
    this work opens new avenues for research into autonomous driving technologies
    that cater to individual preferences. By encoding the intricacies of human driving
    behaviors in a format accessible to language models, this work paves the way for
    more intuitive and effective human-agent alignment across a broad spectrum of
    applications beyond autonomous driving. Additionally, the insights into human
    perceptions of riskiness and human-likeness in driving styles underscore the complexity
    of aligning autonomous agents with human expectations and behaviors, highlighting
    the importance of further interdisciplinary research in this area.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å±•ç¤ºLLMåœ¨å®ç°ç»†è‡´çš„äººç±»-ä»£ç†å¯¹é½æ–¹é¢çš„æ½œåŠ›ï¼Œè¿™é¡¹å·¥ä½œä¸ºç ”ç©¶è¿åˆä¸ªä½“åå¥½çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚é€šè¿‡å°†äººç±»é©¾é©¶è¡Œä¸ºçš„å¤æ‚æ€§ç¼–ç ä¸ºè¯­è¨€æ¨¡å‹å¯æ¥å…¥çš„æ ¼å¼ï¼Œè¿™é¡¹å·¥ä½œä¸ºè·¨è¶Šè‡ªåŠ¨é©¾é©¶ä»¥å¤–æ›´å¹¿æ³›åº”ç”¨åœºæ™¯çš„æ›´ç›´è§‚å’Œæœ‰æ•ˆçš„äººç±»-ä»£ç†å¯¹é½å¥ å®šäº†åŸºç¡€ã€‚æ­¤å¤–ï¼Œå¯¹é©¾é©¶é£æ ¼ä¸­çš„é£é™©æ€§å’Œäººç±»ç›¸ä¼¼æ€§æ„ŸçŸ¥çš„æ´å¯Ÿçªæ˜¾äº†å°†è‡ªåŠ¨ä»£ç†ä¸äººç±»æœŸæœ›å’Œè¡Œä¸ºå¯¹é½çš„å¤æ‚æ€§ï¼Œå¼ºè°ƒäº†åœ¨è¿™ä¸€é¢†åŸŸè¿›ä¸€æ­¥è·¨å­¦ç§‘ç ”ç©¶çš„é‡è¦æ€§ã€‚
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] C.Â H. Song, J.Â Wu, C.Â Washington, B.Â M. Sadler, W.-L. Chao, and Y.Â Su,
    â€œLlm-planner: Few-shot grounded planning for embodied agents with large language
    models,â€ in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998â€“3009.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, å’Œ Y. Su, â€œLlm-planner:
    åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å°‘æ ·æœ¬æœ‰æ ¹è§„åˆ’ç”¨äºå…·èº«ä»£ç†â€ï¼Œè½½äº*IEEE/CVFå›½é™…è®¡ç®—æœºè§†è§‰ä¼šè®®è®ºæ–‡é›†*ï¼Œ2023å¹´ï¼Œç¬¬2998-3009é¡µã€‚'
- en: '[2] J.Â Wei, X.Â Wang, D.Â Schuurmans, M.Â Bosma, F.Â Xia, E.Â Chi, Q.Â V. Le, D.Â Zhou,
    *etÂ al.*, â€œChain-of-thought prompting elicits reasoning in large language models,â€
    *Advances in Neural Information Processing Systems*, vol.Â 35, pp. 24â€‰824â€“24â€‰837,
    2022.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D.
    Zhou, *ç­‰*ï¼Œâ€œæ€ç»´é“¾æç¤ºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¼•å‘æ¨ç†ï¼Œâ€ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬35å·ï¼Œç¬¬24,824â€“24,837é¡µï¼Œ2022ã€‚'
- en: '[3] X.Â Wang, J.Â Wei, D.Â Schuurmans, Q.Â Le, E.Â Chi, S.Â Narang, A.Â Chowdhery,
    and D.Â Zhou, â€œSelf-consistency improves chain of thought reasoning in language
    models,â€ *arXiv preprint arXiv:2203.11171*, 2022.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery,
    å’Œ D. Zhou, â€œè‡ªä¸€è‡´æ€§æ”¹å–„è¯­è¨€æ¨¡å‹ä¸­çš„æ€ç»´é“¾æ¨ç†ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2203.11171*ï¼Œ2022ã€‚'
- en: '[4] S.Â Yao, D.Â Yu, J.Â Zhao, I.Â Shafran, T.Â L. Griffiths, Y.Â Cao, and K.Â Narasimhan,
    â€œTree of thoughts: Deliberate problem solving with large language models,â€ *arXiv
    preprint arXiv:2305.10601*, 2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, å’Œ K. Narasimhan,
    â€œæ€æƒ³æ ‘ï¼šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ·±æ€ç†Ÿè™‘çš„é—®é¢˜è§£å†³ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2305.10601*ï¼Œ2023ã€‚'
- en: '[5] L.Â Chen, O.Â Sinavski, J.Â HÃ¼nermann, A.Â Karnsund, A.Â J. Willmott, D.Â Birch,
    D.Â Maund, and J.Â Shotton, â€œDriving with llms: Fusing object-level vector modality
    for explainable autonomous driving,â€ *arXiv preprint arXiv:2310.01957*, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. Chen, O. Sinavski, J. HÃ¼nermann, A. Karnsund, A. J. Willmott, D. Birch,
    D. Maund, å’Œ J. Shotton, â€œä½¿ç”¨LLMsè¿›è¡Œé©¾é©¶ï¼šèåˆé¢å‘å¯¹è±¡çš„å‘é‡æ¨¡æ€ä»¥å®ç°å¯è§£é‡Šçš„è‡ªåŠ¨é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.01957*ï¼Œ2023ã€‚'
- en: '[6] Z.Â Xu, Y.Â Zhang, E.Â Xie, Z.Â Zhao, Y.Â Guo, K.Â K. Wong, Z.Â Li, and H.Â Zhao,
    â€œDrivegpt4: Interpretable end-to-end autonomous driving via large language model,â€
    *arXiv preprint arXiv:2310.01412*, 2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Z. Xu, Y. Zhang, E. Xie, Z. Zhao, Y. Guo, K. K. Wong, Z. Li, å’Œ H. Zhao,
    â€œDrivegpt4ï¼šé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯è§£é‡Šçš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.01412*ï¼Œ2023ã€‚'
- en: '[7] A.Â Hu, L.Â Russell, H.Â Yeo, Z.Â Murez, G.Â Fedoseev, A.Â Kendall, J.Â Shotton,
    and G.Â Corrado, â€œGaia-1: A generative world model for autonomous driving,â€ *arXiv
    preprint arXiv:2309.17080*, 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] A. Hu, L. Russell, H. Yeo, Z. Murez, G. Fedoseev, A. Kendall, J. Shotton,
    å’Œ G. Corrado, â€œGaia-1ï¼šç”¨äºè‡ªåŠ¨é©¾é©¶çš„ç”Ÿæˆå‹ä¸–ç•Œæ¨¡å‹ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2309.17080*ï¼Œ2023ã€‚'
- en: '[8] H.Â Shao, Y.Â Hu, L.Â Wang, S.Â L. Waslander, Y.Â Liu, and H.Â Li, â€œLmdrive:
    Closed-loop end-to-end driving with large language models,â€ 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] H. Shao, Y. Hu, L. Wang, S. L. Waslander, Y. Liu, å’Œ H. Li, â€œLmdriveï¼šé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé—­ç¯ç«¯åˆ°ç«¯é©¾é©¶ï¼Œâ€
    2023ã€‚'
- en: '[9] C.Â Cui, Y.Â Ma, X.Â Cao, W.Â Ye, and Z.Â Wang, â€œDrive as you speak: Enabling
    human-like interaction with large language models in autonomous vehicles,â€ in
    *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*,
    2024, pp. 902â€“909.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] C. Cui, Y. Ma, X. Cao, W. Ye, å’Œ Z. Wang, â€œæŒ‰è¯´è¯æ–¹å¼é©¾é©¶ï¼šåœ¨è‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­å®ç°ä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„äººç±»åŒ–äº’åŠ¨ï¼Œâ€
    è½½äº *IEEE/CVF è®¡ç®—æœºè§†è§‰åº”ç”¨å†¬å­£ä¼šè®®è®ºæ–‡é›†*ï¼Œ2024ï¼Œç¬¬902â€“909é¡µã€‚'
- en: '[10] L.Â Wen, D.Â Fu, X.Â Li, X.Â Cai, T.Â Ma, P.Â Cai, M.Â Dou, B.Â Shi, L.Â He, and
    Y.Â Qiao, â€œDilu: A knowledge-driven approach to autonomous driving with large language
    models,â€ *arXiv preprint arXiv:2309.16292*, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. Wen, D. Fu, X. Li, X. Cai, T. Ma, P. Cai, M. Dou, B. Shi, L. He, å’Œ
    Y. Qiao, â€œDiluï¼šä¸€ç§åŸºäºçŸ¥è¯†é©±åŠ¨çš„å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨é©¾é©¶æ–¹æ³•ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2309.16292*ï¼Œ2023ã€‚'
- en: '[11] W.Â Wang, J.Â Xie, C.Â Hu, H.Â Zou, J.Â Fan, W.Â Tong, Y.Â Wen, S.Â Wu, H.Â Deng,
    Z.Â Li, H.Â Tian, L.Â Lu, X.Â Zhu, X.Â Wang, Y.Â Qiao, and J.Â Dai, â€œDrivemlm: Aligning
    multi-modal large language models with behavioral planning states for autonomous
    driving,â€ 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Wang, J. Xie, C. Hu, H. Zou, J. Fan, W. Tong, Y. Wen, S. Wu, H. Deng,
    Z. Li, H. Tian, L. Lu, X. Zhu, X. Wang, Y. Qiao, å’Œ J. Dai, â€œDrivemlmï¼šå°†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸è‡ªåŠ¨é©¾é©¶çš„è¡Œä¸ºè§„åˆ’çŠ¶æ€å¯¹é½ï¼Œâ€
    2023ã€‚'
- en: '[12] S.Â Kolekar, J.Â deÂ Winter, and D.Â Abbink, â€œHuman-like driving behaviour
    emerges from a risk-based driver model,â€ *Nature communications*, vol.Â 11, no.Â 1,
    p. 4850, 2020.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S. Kolekar, J. de Winter, å’Œ D. Abbink, â€œåŸºäºé£é™©çš„é©¾é©¶å‘˜æ¨¡å‹ä¸­æ¶Œç°å‡ºç±»äººé©¾é©¶è¡Œä¸ºï¼Œâ€ *Nature
    Communications*ï¼Œç¬¬11å·ï¼Œç¬¬1æœŸï¼Œç¬¬4850é¡µï¼Œ2020ã€‚'
- en: '[13] Y.Â Jin, X.Â Shen, H.Â Peng, X.Â Liu, J.Â Qin, J.Â Li, J.Â Xie, P.Â Gao, G.Â Zhou,
    and J.Â Gong, â€œSurrealdriver: Designing generative driver agent simulation framework
    in urban contexts based on large language model,â€ *arXiv preprint arXiv:2309.13193*,
    2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Jin, X. Shen, H. Peng, X. Liu, J. Qin, J. Li, J. Xie, P. Gao, G. Zhou,
    å’Œ J. Gong, â€œSurrealdriverï¼šåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹è®¾è®¡çš„åŸå¸‚ç¯å¢ƒä¸­ç”Ÿæˆå‹é©¾é©¶å‘˜ä»£ç†æ¨¡æ‹Ÿæ¡†æ¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2309.13193*ï¼Œ2023ã€‚'
- en: '[14] S.Â Hecker, D.Â Dai, and L.Â VanÂ Gool, â€œLearning accurate, comfortable and
    human-like driving,â€ *arXiv preprint arXiv:1903.10995*, 2019.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] S. Hecker, D. Dai, å’Œ L. Van Gool, â€œå­¦ä¹ å‡†ç¡®ã€èˆ’é€‚ä¸”ç±»äººåŒ–çš„é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:1903.10995*ï¼Œ2019ã€‚'
- en: '[15] A.Â Waytz, J.Â Heafner, and N.Â Epley, â€œThe mind in the machine: Anthropomorphism
    increases trust in an autonomous vehicle,â€ *Journal of experimental social psychology*,
    vol.Â 52, pp. 113â€“117, 2014.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] A. Waytz, J. Heafner, å’Œ N. Epley, â€œæœºå™¨ä¸­çš„å¿ƒæ™ºï¼šäººç±»åŒ–å¢åŠ äº†å¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†çš„ä¿¡ä»»ï¼Œâ€ *å®éªŒç¤¾ä¼šå¿ƒç†å­¦æ‚å¿—*ï¼Œç¬¬52å·ï¼Œç¬¬113â€“117é¡µï¼Œ2014ã€‚'
- en: '[16] J.Â Mao, Y.Â Qian, H.Â Zhao, and Y.Â Wang, â€œGpt-driver: Learning to drive
    with gpt,â€ *arXiv preprint arXiv:2310.01415*, 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Mao, Y. Qian, H. Zhao, å’Œ Y. Wang, â€œGpt-driver: ä½¿ç”¨ GPT å­¦ä¹ é©¾é©¶ï¼Œâ€ *arXiv
    é¢„å°æœ¬ arXiv:2310.01415*, 2023.'
- en: '[17] L.Â Ouyang, J.Â Wu, X.Â Jiang, D.Â Almeida, C.Â L. Wainwright, P.Â Mishkin,
    C.Â Zhang, S.Â Agarwal, K.Â Slama, A.Â Ray, *etÂ al.*, â€œTraining language models to
    follow instructions with human feedback, 2022,â€ *URL https://arxiv. org/abs/2203.02155*,
    vol.Â 13, p.Â 1, 2022.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,
    C. Zhang, S. Agarwal, K. Slama, A. Ray, *ç­‰äºº*, â€œè®­ç»ƒè¯­è¨€æ¨¡å‹ä»¥éµå¾ªæŒ‡ä»¤å¹¶é€šè¿‡äººå·¥åé¦ˆè¿›è¡Œè°ƒæ•´ï¼Œ2022ï¼Œâ€ *URL
    https://arxiv.org/abs/2203.02155*, ç¬¬ 13 å·, ç¬¬ 1 é¡µ, 2022.'
- en: '[18] D.Â Fu, X.Â Li, L.Â Wen, M.Â Dou, P.Â Cai, B.Â Shi, and Y.Â Qiao, â€œDrive like
    a human: Rethinking autonomous driving with large language models,â€ in *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2024, pp.
    910â€“919.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] D. Fu, X. Li, L. Wen, M. Dou, P. Cai, B. Shi, å’Œ Y. Qiao, â€œåƒäººç±»ä¸€æ ·é©¾é©¶ï¼šé€šè¿‡å¤§è¯­è¨€æ¨¡å‹é‡æ–°æ€è€ƒè‡ªåŠ¨é©¾é©¶ï¼Œâ€
    è§ *IEEE/CVF å†¬å­£è®¡ç®—æœºè§†è§‰åº”ç”¨ä¼šè®®è®ºæ–‡é›†*, 2024, é¡µ 910â€“919.'
- en: '[19] A.Â Zhao, D.Â Huang, Q.Â Xu, M.Â Lin, Y.-J. Liu, and G.Â Huang, â€œExpel: Llm
    agents are experiential learners,â€ *arXiv preprint arXiv:2308.10144*, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] A. Zhao, D. Huang, Q. Xu, M. Lin, Y.-J. Liu, å’Œ G. Huang, â€œExpel: LLM ä»£ç†æ˜¯ç»éªŒå­¦ä¹ è€…ï¼Œâ€
    *arXiv é¢„å°æœ¬ arXiv:2308.10144*, 2023.'
- en: '[20] N.Â Shinn, F.Â Cassano, A.Â Gopinath, K.Â Narasimhan, and S.Â Yao, â€œReflexion:
    Language agents with verbal reinforcement learning,â€ *Advances in Neural Information
    Processing Systems*, vol.Â 36, 2024.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, å’Œ S. Yao, â€œReflexion:
    å…·æœ‰è¯­è¨€å¼ºåŒ–å­¦ä¹ çš„è¯­è¨€ä»£ç†ï¼Œâ€ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*, ç¬¬ 36 å·, 2024.'
- en: '[21] W.Â Yao, S.Â Heinecke, J.Â C. Niebles, Z.Â Liu, Y.Â Feng, L.Â Xue, R.Â Murthy,
    Z.Â Chen, J.Â Zhang, D.Â Arpit, *etÂ al.*, â€œRetroformer: Retrospective large language
    agents with policy gradient optimization,â€ *arXiv preprint arXiv:2308.02151*,
    2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] W. Yao, S. Heinecke, J. C. Niebles, Z. Liu, Y. Feng, L. Xue, R. Murthy,
    Z. Chen, J. Zhang, D. Arpit, *ç­‰äºº*, â€œRetroformer: å…·æœ‰ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–çš„å›æº¯å¤§è¯­è¨€ä»£ç†ï¼Œâ€ *arXiv é¢„å°æœ¬
    arXiv:2308.02151*, 2023.'
- en: '[22] Z.Â Yang, P.Â Li, and Y.Â Liu, â€œFailures pave the way: Enhancing large language
    models through tuning-free rule accumulation,â€ *arXiv preprint arXiv:2310.15746*,
    2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Z. Yang, P. Li, å’Œ Y. Liu, â€œå¤±è´¥é“ºå°±é“è·¯ï¼šé€šè¿‡æ— è°ƒä¼˜è§„åˆ™ç´¯ç§¯å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.15746*,
    2023.'
- en: '[23] X.Â Wang, W.Â Zhu, M.Â Saxon, M.Â Steyvers, and W.Â Y. Wang, â€œLarge language
    models are implicitly topic models: Explaining and finding good demonstrations
    for in-context learning,â€ in *Workshop on Efficient Systems for Foundation Models@
    ICML2023*, 2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] X. Wang, W. Zhu, M. Saxon, M. Steyvers, å’Œ W. Y. Wang, â€œå¤§è¯­è¨€æ¨¡å‹éšå¼ä½œä¸ºä¸»é¢˜æ¨¡å‹ï¼šè§£é‡Šå’Œå¯»æ‰¾é€‚åˆä¸Šä¸‹æ–‡å­¦ä¹ çš„ä¼˜è´¨ç¤ºä¾‹ï¼Œâ€
    è§ *ICML2023 åŸºç¡€æ¨¡å‹é«˜æ•ˆç³»ç»Ÿç ”è®¨ä¼š*, 2023.'
- en: '[24] H.Â Caesar, V.Â Bankiti, A.Â H. Lang, S.Â Vora, V.Â E. Liong, Q.Â Xu, A.Â Krishnan,
    Y.Â Pan, G.Â Baldan, and O.Â Beijbom, â€œnuscenes: A multimodal dataset for autonomous
    driving,â€ in *Proceedings of the IEEE/CVF conference on computer vision and pattern
    recognition*, 2020, pp. 11â€‰621â€“11â€‰631.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan,
    Y. Pan, G. Baldan, å’Œ O. Beijbom, â€œnuscenes: ä¸€ä¸ªå¤šæ¨¡æ€è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ï¼Œâ€ è§ *IEEE/CVF è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ä¼šè®®è®ºæ–‡é›†*,
    2020, é¡µ 11â€‰621â€“11â€‰631.'
- en: '[25] J.Â Geyer, Y.Â Kassahun, M.Â Mahmudi, X.Â Ricou, R.Â Durgesh, A.Â S. Chung,
    L.Â Hauswald, V.Â H. Pham, M.Â MÃ¼hlegg, S.Â Dorn, *etÂ al.*, â€œA2d2: Audi autonomous
    driving dataset,â€ *arXiv preprint arXiv:2004.06320*, 2020.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] J. Geyer, Y. Kassahun, M. Mahmudi, X. Ricou, R. Durgesh, A. S. Chung,
    L. Hauswald, V. H. Pham, M. MÃ¼hlegg, S. Dorn, *ç­‰äºº*, â€œA2d2: å¥¥è¿ªè‡ªåŠ¨é©¾é©¶æ•°æ®é›†ï¼Œâ€ *arXiv
    é¢„å°æœ¬ arXiv:2004.06320*, 2020.'
- en: '[26] X.Â Huang, X.Â Cheng, Q.Â Geng, B.Â Cao, D.Â Zhou, P.Â Wang, Y.Â Lin, and R.Â Yang,
    â€œThe apolloscape dataset for autonomous driving,â€ in *Proceedings of the IEEE
    conference on computer vision and pattern recognition workshops*, 2018, pp. 954â€“960.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] X. Huang, X. Cheng, Q. Geng, B. Cao, D. Zhou, P. Wang, Y. Lin, å’Œ R. Yang,
    â€œApolloscape è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ï¼Œâ€ è§ *IEEE è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ä¼šè®®ç ”è®¨ä¼šè®ºæ–‡é›†*, 2018, é¡µ 954â€“960.'
- en: '[27] W.Â Zhan, L.Â Sun, D.Â Wang, H.Â Shi, A.Â Clausse, M.Â Naumann, J.Â Kummerle,
    H.Â Konigshof, C.Â Stiller, A.Â deÂ LaÂ Fortelle, *etÂ al.*, â€œInteraction dataset: An
    international, adversarial and cooperative motion dataset in interactive driving
    scenarios with semantic maps,â€ *arXiv preprint arXiv:1910.03088*, 2019.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] W. Zhan, L. Sun, D. Wang, H. Shi, A. Clausse, M. Naumann, J. Kummerle,
    H. KÃ¶nigshof, C. Stiller, A. de La Fortelle, *ç­‰äºº*, â€œäº’åŠ¨æ•°æ®é›†ï¼šåœ¨å…·æœ‰è¯­ä¹‰åœ°å›¾çš„äº’åŠ¨é©¾é©¶åœºæ™¯ä¸­çš„å›½é™…æ€§ã€å¯¹æŠ—æ€§å’Œåˆä½œæ€§è¿åŠ¨æ•°æ®é›†ï¼Œâ€
    *arXiv é¢„å°æœ¬ arXiv:1910.03088*, 2019.'
- en: '[28] T.Â Li, A.Â Alhilal, A.Â Zhang, M.Â A. Hoque, D.Â Chatzopoulos, Z.Â Xiao, Y.Â Li,
    and P.Â Hui, â€œDriving big data: A first look at driving behavior via a large-scale
    private car dataset,â€ in *2019 IEEE 35th International Conference on Data Engineering
    Workshops (ICDEW)*.Â Â Â IEEE, 2019, pp. 61â€“68.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] T. Li, A. Alhilal, A. Zhang, M. A. Hoque, D. Chatzopoulos, Z. Xiao, Y.
    Li, å’Œ P. Hui, â€œé©¾é©¶å¤§æ•°æ®ï¼šé€šè¿‡ä¸€ä¸ªå¤§è§„æ¨¡ç§äººæ±½è½¦æ•°æ®é›†é¦–æ¬¡ç ”ç©¶é©¾é©¶è¡Œä¸ºï¼Œâ€è½½äº *2019 IEEEç¬¬35å±Šå›½é™…æ•°æ®å·¥ç¨‹ç ”è®¨ä¼šï¼ˆICDEWï¼‰*ï¼ŒIEEEï¼Œ2019å¹´ï¼Œç¬¬61â€“68é¡µã€‚'
- en: '[29] X.Â Hu, Z.Â Zheng, D.Â Chen, X.Â Zhang, and J.Â Sun, â€œProcessing, assessing,
    and enhancing the waymo autonomous vehicle open dataset for driving behavior research,â€
    *Transportation Research Part C: Emerging Technologies*, vol. 134, p. 103490,
    2022.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] X. Hu, Z. Zheng, D. Chen, X. Zhang, å’Œ J. Sun, â€œå¤„ç†ã€è¯„ä¼°å¹¶å¢å¼ºWaymoè‡ªåŠ¨é©¾é©¶è½¦è¾†å¼€æ”¾æ•°æ®é›†ä»¥ç”¨äºé©¾é©¶è¡Œä¸ºç ”ç©¶ï¼Œâ€
    *äº¤é€šç ”ç©¶Céƒ¨åˆ†ï¼šæ–°å…´æŠ€æœ¯*ï¼Œç¬¬134å·ï¼Œæ–‡ç« ç¼–å·103490ï¼Œ2022å¹´ã€‚'
- en: '[30] M.Â Martin, A.Â Roitberg, M.Â Haurilet, M.Â Horne, S.Â ReiÃŸ, M.Â Voit, and R.Â Stiefelhagen,
    â€œDrive&act: A multi-modal dataset for fine-grained driver behavior recognition
    in autonomous vehicles,â€ in *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, 2019, pp. 2801â€“2810.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. Martin, A. Roitberg, M. Haurilet, M. Horne, S. ReiÃŸ, M. Voit, å’Œ R.
    Stiefelhagen, â€œDrive&act: ä¸€ç§ç”¨äºè‡ªåŠ¨é©¾é©¶è½¦è¾†ä¸­ç»†ç²’åº¦é©¾é©¶è¡Œä¸ºè¯†åˆ«çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œâ€è½½äº *IEEE/CVFå›½é™…è®¡ç®—æœºè§†è§‰ä¼šè®®è®ºæ–‡é›†*ï¼Œ2019å¹´ï¼Œç¬¬2801â€“2810é¡µã€‚'
- en: '[31] T.Â Brown, B.Â Mann, N.Â Ryder, M.Â Subbiah, J.Â D. Kaplan, P.Â Dhariwal, A.Â Neelakantan,
    P.Â Shyam, G.Â Sastry, A.Â Askell, *etÂ al.*, â€œLanguage models are few-shot learners,â€
    *Advances in neural information processing systems*, vol.Â 33, pp. 1877â€“1901, 2020.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell, *ç­‰äºº*ï¼Œâ€œè¯­è¨€æ¨¡å‹æ˜¯å°‘é‡å­¦ä¹ è€…ï¼Œâ€ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬33å·ï¼Œç¬¬1877â€“1901é¡µï¼Œ2020å¹´ã€‚'
- en: '[32] O.Â Taubman-Ben-Ari, M.Â Mikulincer, and O.Â Gillath, â€œThe multidimensional
    driving style inventoryâ€”scale construct and validation,â€ *Accident Analysis &
    Prevention*, vol.Â 36, no.Â 3, pp. 323â€“332, 2004.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] O. Taubman-Ben-Ari, M. Mikulincer, å’Œ O. Gillath, â€œå¤šç»´é©¾é©¶é£æ ¼é‡è¡¨â€”â€”ç»“æ„æ„å»ºä¸éªŒè¯ï¼Œâ€
    *äº‹æ•…åˆ†æä¸é¢„é˜²*ï¼Œç¬¬36å·ï¼Œç¬¬3æœŸï¼Œç¬¬323â€“332é¡µï¼Œ2004å¹´ã€‚'
