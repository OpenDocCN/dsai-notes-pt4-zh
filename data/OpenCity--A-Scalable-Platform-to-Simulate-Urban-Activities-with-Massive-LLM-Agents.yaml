- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:01:38'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:01:38
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM
    Agents'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCity：一个可扩展平台，用于模拟拥有大量 LLM 代理的城市活动
- en: 来源：[https://arxiv.org/html/2410.21286/](https://arxiv.org/html/2410.21286/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2410.21286/](https://arxiv.org/html/2410.21286/)
- en: Yuwei Yan¹¹15pt Information Hub, The Hong Kong University of Science and Technology
    (GuangZhou) Qingbin Zeng¹¹15pt Department of Electronic Engineering, Tsinghua
    University Zhiheng Zheng Shenzhen International Graduate School, Tsinghua University
    Jingzhe Yuan Department of Electronic Engineering, Tsinghua University Jie Feng
    Department of Electronic Engineering, Tsinghua University Jun Zhang Department
    of Electronic Engineering, Tsinghua University Fengli Xu²²25pt Department of Electronic
    Engineering, Tsinghua University Yong Li²²25pt Department of Electronic Engineering,
    Tsinghua University
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Yuwei Yan¹¹15pt 信息中心，香港科技大学（广州） Qingbin Zeng¹¹15pt 电子工程系，清华大学 Zhiheng Zheng
    深圳国际研究生院，清华大学 Jingzhe Yuan 电子工程系，清华大学 Jie Feng 电子工程系，清华大学 Jun Zhang 电子工程系，清华大学
    Fengli Xu²²25pt 电子工程系，清华大学 Yong Li²²25pt 电子工程系，清华大学
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Agent-based models (ABMs) have long been employed to explore how individual
    behaviors aggregate into complex societal phenomena in urban space. Unlike black-box
    predictive models, ABMs excel at explaining the micro-macro linkages that drive
    such emergent behaviors. The recent rise of Large Language Models (LLMs) has led
    to the development of LLM agents capable of simulating urban activities with unprecedented
    realism. However, the extreme high computational cost of LLMs presents significant
    challenges for scaling up the simulations of LLM agents. To address this problem,
    we propose OpenCity, a scalable simulation platform optimized for both system
    and prompt efficiencies. Specifically, we propose a LLM request scheduler to reduce
    communication overhead by parallelizing requests through IO multiplexing. Besides,
    we deisgn a “group-and-distill” prompt optimization strategy minimizes redundancy
    by clustering agents with similar static attributes. Through experiments on six
    global cities, OpenCity achieves a 600-fold acceleration in simulation time per
    agent, a 70% reduction in LLM requests, and a 50% reduction in token usage. These
    improvements enable the simulation of 10,000 agents’ daily activities in 1 hour
    on commodity hardware. Besides, the substantial speedup of OpenCity allows us
    to establish a urban simulation benchmark for LLM agents for the first time, comparing
    simulated urban activities with real-world data in 6 major cities around the globe.
    We believe our OpenCity platform provides a critical infrastructure to harness
    the power of LLMs for interdisciplinary studies in urban space, fostering the
    collective efforts of broader research communities. Code repo is available at
    https://anonymous.4open.science/r/Anonymous-OpenCity-42BD.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的模型（ABMs）长期以来一直被用来探索个体行为如何汇聚成城市空间中的复杂社会现象。与黑盒预测模型不同，ABMs 擅长解释驱动这些涌现行为的微观-宏观联系。近年来，大型语言模型（LLMs）的崛起催生了能够以空前逼真度模拟城市活动的
    LLM 代理。然而，LLMs 的极高计算成本给 LLM 代理的模拟规模化带来了重大挑战。为了解决这一问题，我们提出了 OpenCity，这是一个针对系统和提示效率进行优化的可扩展模拟平台。具体来说，我们提出了一种
    LLM 请求调度器，通过 IO 多路复用并行化请求，减少通信开销。此外，我们设计了一种“分组与提炼”的提示优化策略，通过将具有相似静态属性的代理进行聚类，最小化冗余。通过对六个全球城市的实验，OpenCity
    实现了每个代理模拟时间的 600 倍加速，LLM 请求减少了 70%，并且令牌使用量减少了 50%。这些改进使得在普通硬件上能够在 1 小时内模拟 10,000
    个代理的日常活动。此外，OpenCity 的显著加速使我们首次建立了 LLM 代理的城市模拟基准，将模拟的城市活动与全球六个主要城市的实际数据进行比较。我们相信，OpenCity
    平台为城市空间中的跨学科研究提供了关键基础设施，促进了更广泛研究社区的集体努力。代码库可在 [https://anonymous.4open.science/r/Anonymous-OpenCity-42BD](https://anonymous.4open.science/r/Anonymous-OpenCity-42BD)
    获得。
- en: '¹¹footnotetext: Equal Contribution.²²footnotetext: Corresponding authors.^†^†footnotetext:
    Preprint. Under review.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ¹¹脚注：同等贡献。²²脚注：通讯作者。^†^†脚注：预印本，正在审稿中。
- en: 1 Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Agent-based models (ABMs) were first introduced to urban studies in the seminal
    work of Thomas Schelling about 50 years ago [[1](https://arxiv.org/html/2410.21286v1#bib.bib1)],
    which ingeniously explained how segregation can emerge as the aggregation of individual
    choices. Compared to black-box predictive models, ABMs offer the unique advantage
    of explaining the underlying mechanisms behind aggregated phenomena [[2](https://arxiv.org/html/2410.21286v1#bib.bib2)],
    *i.e.*, revealing the connections between “micro-motives” and “macro-behaviours.”
    As a result, ABMs play an important role in many research areas [[3](https://arxiv.org/html/2410.21286v1#bib.bib3)],
    including computational social sciences, urban planning and public health. The
    recent advance of Large Language Models (LLMs) have driven the rise of LLM agents [[4](https://arxiv.org/html/2410.21286v1#bib.bib4),
    [5](https://arxiv.org/html/2410.21286v1#bib.bib5)], which leverage LLM’s remarkable
    capabilities of commonsense reasoning and role-playing to simulate human behaviours.
    Unlike previous rule-based agents, these emerging LLM agents generate far more
    realistic human behaviours [[4](https://arxiv.org/html/2410.21286v1#bib.bib4),
    [6](https://arxiv.org/html/2410.21286v1#bib.bib6)], and can also explain their
    inner motives via prompting techniques like chain-of-thoughts [[7](https://arxiv.org/html/2410.21286v1#bib.bib7)].
    Therefore, LLM agents hold great potential to harness the power of language models
    in transforming urban studies.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的模型（ABMs）最早由托马斯·谢林（Thomas Schelling）约50年前引入城市研究[[1](https://arxiv.org/html/2410.21286v1#bib.bib1)]，他巧妙地解释了如何通过个体选择的聚合产生隔离现象。与黑盒预测模型相比，ABMs提供了独特的优势，即能够解释聚合现象背后的基本机制[[2](https://arxiv.org/html/2410.21286v1#bib.bib2)]，*即*揭示“微动机”和“宏行为”之间的联系。因此，ABMs在许多研究领域中扮演着重要角色[[3](https://arxiv.org/html/2410.21286v1#bib.bib3)]，包括计算社会科学、城市规划和公共卫生。最近，**大语言模型**（LLMs）的发展推动了LLM代理的兴起[[4](https://arxiv.org/html/2410.21286v1#bib.bib4),
    [5](https://arxiv.org/html/2410.21286v1#bib.bib5)]，这些代理利用LLM在常识推理和角色扮演方面的卓越能力来模拟人类行为。与以前基于规则的代理不同，这些新兴的LLM代理生成的**人类行为**更加真实[[4](https://arxiv.org/html/2410.21286v1#bib.bib4),
    [6](https://arxiv.org/html/2410.21286v1#bib.bib6)]，并且还能够通过类似链式思维的提示技术解释它们的内在动机[[7](https://arxiv.org/html/2410.21286v1#bib.bib7)]。因此，LLM代理有着巨大的潜力，能够借助语言模型的力量改变城市研究领域。
- en: 'Despite this promising outlook, LLM agents also face severe challenges of scaling
    up due to the high computation time. In the pioneering work of Park et al. [[4](https://arxiv.org/html/2410.21286v1#bib.bib4)]
    only 15 LLM agents were employed to simulate a small village. One main reason
    is the prohibitive simulation time, which can be broken down into two parts: on
    one hand, LLMs are inherently slow due to their enormous model sizes; on the other
    hand, powerful commercial LLMs are only accessible via APIs, which introduces
    significant time delay due to network transmission, further slowing down simulation.
    To make matters worse, the prompt design of urban LLM agents often involve dynamic
    elements, such as the changing memories and perceived environment [[4](https://arxiv.org/html/2410.21286v1#bib.bib4),
    [8](https://arxiv.org/html/2410.21286v1#bib.bib8)]. This important feature prevents
    the straightforward reuse of simulated behaviors from a small sample of the population [[9](https://arxiv.org/html/2410.21286v1#bib.bib9)],
    as LLM agents need to maintain independent memories and experiences, which are
    essential for simulating a vibrant and diverse urban population.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前景看好，LLM代理也面临着由于高计算时间导致的规模化挑战。在Park等人的开创性工作中[[4](https://arxiv.org/html/2410.21286v1#bib.bib4)]，仅使用了15个LLM代理来模拟一个小村庄。一个主要原因是高昂的模拟时间，可以分解为两部分：一方面，由于LLM模型庞大，它们本身的运行速度较慢；另一方面，强大的商业LLM只能通过API访问，这导致由于网络传输产生显著的时间延迟，进一步拖慢了模拟速度。更糟糕的是，城市LLM代理的提示设计通常涉及动态元素，如变化的记忆和感知环境[[4](https://arxiv.org/html/2410.21286v1#bib.bib4),
    [8](https://arxiv.org/html/2410.21286v1#bib.bib8)]。这一重要特性使得无法直接重用小样本群体中的模拟行为[[9](https://arxiv.org/html/2410.21286v1#bib.bib9)]，因为LLM代理需要保持独立的记忆和经验，这对于模拟充满活力和多样化的城市人口至关重要。
- en: In this paper, we present OpenCity, a scalable platform that introduces both
    system-level and prompt-level optimizations to enable efficient LLM agent simulation
    in urban environments. Specifically, we design an LLM request scheduler that leverages
    the scalable I/O event notification mechanism in operating system (*e.g.*, epoll
    in Linux [[10](https://arxiv.org/html/2410.21286v1#bib.bib10)]) to minimize network
    transmission delay. This design is based on our key observation that sending LLM
    requests and receiving generated output account for only a small portion of total
    communication time, while the rest are wasted on waiting for LLM responses and
    the repeatedly establishing TCP connections [[11](https://arxiv.org/html/2410.21286v1#bib.bib11)].
    To address this problem, the LLM request scheduler uses the scalable I/O event
    notification mechanism to parallelize LLM requests by reusing the network I/O
    portal and TCP connections while waiting for responses. Besides, LLM request scheduler
    also analyzes the interdependencies of LLM requests and local computation tasks,
    *e.g.*, updating agent’s memory and retrieving nearby locations, ensuring local
    computation tasks are optimally distributed across multiple CPU cores. These system-level
    optimizations enable large-scale LLM agent simulations to run on commodity hardware.
    As for the prompt-level optimization, OpenCity introduces a novel “group-and-distill”
    prompt strategy to minimize the input token required by LLMs. The key idea is
    to identify the clusters of LLM agents that share semantically similar static
    elements, *e.g.*, age, gender and income level, and use shared context in batch
    prompting [[12](https://arxiv.org/html/2410.21286v1#bib.bib12)] to reduce token
    redundancy. Specifically, our “group-and-distill” strategy leverages the in-context
    learning capabilities of LLMs to implement a prototype learning workflow that
    automatically discovers clusters of LLM agents with semantically similar static
    elements for simulation. Agents within the same clusters are grouped into a batch
    prompt, and we design a “prompt distillation” to extract shared prefix for grouped
    agents. Finally, OpenCity also features an easy-to-use web portal that facilitates
    code-less simulation configuration and result visualization. This design minimizes
    the program requirement for running simulation with LLM agents, ensuring our OpenCity
    platform can benefit researchers from all background.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们提出了OpenCity，一个可扩展的平台，通过引入系统级和提示级优化，实现了在城市环境中高效的LLM代理仿真。具体而言，我们设计了一个LLM请求调度器，利用操作系统中的可扩展I/O事件通知机制（*例如*，Linux中的epoll
    [[10](https://arxiv.org/html/2410.21286v1#bib.bib10)]）来最小化网络传输延迟。该设计基于我们的一个关键观察：发送LLM请求和接收生成的输出仅占总通信时间的一小部分，而其余时间则浪费在等待LLM响应和反复建立TCP连接上[[11](https://arxiv.org/html/2410.21286v1#bib.bib11)]。为了解决这个问题，LLM请求调度器使用可扩展的I/O事件通知机制，通过重用网络I/O端口和TCP连接来并行化LLM请求，同时等待响应。此外，LLM请求调度器还分析LLM请求与本地计算任务之间的相互依赖关系，*例如*，更新代理的内存和检索附近位置，确保本地计算任务在多个CPU核心之间得到最优分配。这些系统级优化使得大规模LLM代理仿真能够在普通硬件上运行。至于提示级优化，OpenCity引入了一种新颖的“分组与蒸馏”提示策略，以最小化LLM所需的输入token。其关键思想是识别共享语义相似静态元素的LLM代理群体，*例如*，年龄、性别和收入水平，并使用共享上下文进行批量提示[[12](https://arxiv.org/html/2410.21286v1#bib.bib12)]，以减少token冗余。具体而言，我们的“分组与蒸馏”策略利用LLM的上下文学习能力，实施一个原型学习工作流，自动发现具有语义相似静态元素的LLM代理群体进行仿真。位于同一群体中的代理被分组成一个批量提示，并且我们设计了一种“提示蒸馏”方法，以提取分组代理的共享前缀。最后，OpenCity还提供了一个易于使用的Web门户，便于无代码的仿真配置和结果可视化。该设计最大限度地减少了运行LLM代理仿真的程序需求，确保我们的OpenCity平台能够惠及各类背景的研究人员。
- en: We evaluate the efficiency and faithfulness of OpenCity in simulating the urban
    activities of 6 cities around the world using the widely adopted Generative Agent
    workflow [[4](https://arxiv.org/html/2410.21286v1#bib.bib4)]. Our experiments
    show OpenCity achieves an average 635x acceleration in simulations with 10,000
    LLM agents. Besides, the number of requests and consumed tokens are reduced by
    73.7% and 45.5%, respectively. OpenCity also shows strong scalability, with the
    simulation time per agent reducing from 36.25 to 0.06 seconds as the simulation
    size increases from 1 to 10,000 agents, demonstrating that larger simulations
    allow for more efficient LLM request scheduling and prompt distillation. More
    importantly, OpenCity also maintains high faithfulness of the simulated behaviour.
    Specifically, the Jensen–Shannon divergence and top-1 hit rates of our method
    are comparable to the standard prompting technique of batch prompting [[12](https://arxiv.org/html/2410.21286v1#bib.bib12)],
    and substantially surpass straightforward reusing strategy [[9](https://arxiv.org/html/2410.21286v1#bib.bib9)].
    Besides, the top-1 hit rate can reaches up to 96% when using powerful LLMs like
    GPT-4o.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们评估了OpenCity在模拟全球6个城市的城市活动时的效率和忠实度，使用了广泛采用的生成式代理工作流[[4](https://arxiv.org/html/2410.21286v1#bib.bib4)]。我们的实验表明，OpenCity在使用10,000个LLM代理时，仿真加速平均为635倍。此外，请求数量和消耗的代币分别减少了73.7%和45.5%。OpenCity还表现出强大的可扩展性，随着仿真规模从1个增加到10,000个代理，每个代理的仿真时间从36.25秒减少到0.06秒，表明更大规模的仿真能够实现更高效的LLM请求调度和提示提炼。更重要的是，OpenCity还保持了较高的仿真行为忠实度。具体而言，我们方法的詹森-香农散度和top-1命中率与批量提示的标准提示技术[[12](https://arxiv.org/html/2410.21286v1#bib.bib12)]相当，且远远超过了直接重用策略[[9](https://arxiv.org/html/2410.21286v1#bib.bib9)]。此外，使用像GPT-4o这样的强大LLM时，top-1命中率可达到96%。
- en: The substantial simulation acceleration allows us to benchmark LLM agents’ ability
    to replicate large-scale urban activities for the first time. We use classic evaluation
    measures such as the radius of gyration [[13](https://arxiv.org/html/2410.21286v1#bib.bib13)],
    origin-destination matrix [[14](https://arxiv.org/html/2410.21286v1#bib.bib14)],
    and segregation index [[15](https://arxiv.org/html/2410.21286v1#bib.bib15)] to
    assess LLM agents’ simulations. These are the most widely adopted metrics that
    characterize urban residents’ activities at both individual and group levels,
    and across physical and social domains. Our experiments show that LLM agents perform
    comparably to, or better than, traditional rule-based agents like EPR [[16](https://arxiv.org/html/2410.21286v1#bib.bib16)].
    Moreover, LLM agents enable counterfactual analyses, such as evaluating experienced
    segregation in cities without residential segregation [[17](https://arxiv.org/html/2410.21286v1#bib.bib17)].
    They also allow researchers to interrogate LLM agents’ motives behind their behaviors,
    offering valuable insights for urban policy-making.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这一显著的仿真加速使我们首次能够对大规模城市活动的复制进行基准测试。我们使用经典的评估指标，如回转半径[[13](https://arxiv.org/html/2410.21286v1#bib.bib13)]、起源-目的地矩阵[[14](https://arxiv.org/html/2410.21286v1#bib.bib14)]和隔离指数[[15](https://arxiv.org/html/2410.21286v1#bib.bib15)]来评估LLM代理的仿真效果。这些是最广泛采用的指标，用于描述城市居民在个体和群体层面、以及在物理和社会领域的活动。我们的实验表明，LLM代理的表现与传统的基于规则的代理（如EPR）[[16](https://arxiv.org/html/2410.21286v1#bib.bib16)]相当，甚至更好。此外，LLM代理还可以进行反事实分析，例如评估在没有居民隔离的城市中的经验性隔离[[17](https://arxiv.org/html/2410.21286v1#bib.bib17)]。它们还允许研究人员探讨LLM代理行为背后的动机，为城市政策制定提供宝贵的见解。
- en: We believe our OpenCity platform can serve as a critical infrastructure to unleash
    the power of LLMs in the interdisciplinary studies in urban space. It not only
    provides high speedup that allows large simulation to run on commodity hardware,
    but also offers a user-friendly web portal that allows researchers with minimum
    programming background to access this technology. It will facilitate a broader
    research community and other stakeholders to use LLM agents to evaluate, analyze
    and inform their projects.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信我们的OpenCity平台可以作为释放LLM在城市空间跨学科研究中潜力的关键基础设施。它不仅提供了高加速，使得大型仿真能够在普通硬件上运行，而且还提供了一个用户友好的网络门户，使得拥有最少编程背景的研究人员也能够访问这一技术。它将促进更广泛的研究社区和其他利益相关者使用LLM代理来评估、分析并为他们的项目提供信息。
- en: 2 Related Works
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: 2.1 LLM Agents
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 LLM代理
- en: 'With the widespread use of large language models (LLMs) in various applications,
    the limitations of LLMs, e.g., unstable reasoning abilities, limited memory capacity,
    and lack of specialized expertise, have been exposed to the public. As one of
    the potential solution, LLM agents are proposed to overcome these limitations
    and promote the practical application of LLMs. AutoGPT [[18](https://arxiv.org/html/2410.21286v1#bib.bib18)]
    as one of the most popular LLM autonomous agent explore the potential of applying
    LLM to enable the autonomous planning and task-solving. After that, LLM agents [[19](https://arxiv.org/html/2410.21286v1#bib.bib19),
    [20](https://arxiv.org/html/2410.21286v1#bib.bib20)] have made significant progress
    in two directions: task-oriented agents and simulation agents. Following the first
    direction, researchers aim to improve LLM agent’s ability to solve complex tasks.
    For example, lots of programming agents, such as ChatDev [[21](https://arxiv.org/html/2410.21286v1#bib.bib21)],
    SWEAgent [[22](https://arxiv.org/html/2410.21286v1#bib.bib22)], and MetaGPT [[23](https://arxiv.org/html/2410.21286v1#bib.bib23)],
    are designed to solve the complex programming tasks. As for the second direction,
    generative agents [[4](https://arxiv.org/html/2410.21286v1#bib.bib4)] have demonstrated
    the potential of large models in simulating human behavior, which has been further
    validated in subsequent research. S3 [[24](https://arxiv.org/html/2410.21286v1#bib.bib24)]
    explores the potential of using LLM agents to simulate the social network. CoPB [[6](https://arxiv.org/html/2410.21286v1#bib.bib6)]
    defines a agentic workflow to simulate the mobility behaviors. RecAgent [[25](https://arxiv.org/html/2410.21286v1#bib.bib25)]
    simulate the user behavior in the recommendation system. While these works demonstrate
    the potential of LLM agents, the large scale efficient simulation of generative
    agents becomes the critical bottleneck of further applications.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLM）在各种应用中的广泛使用，LLM的局限性，例如推理能力不稳定、记忆容量有限以及缺乏专业知识，已被公开揭示。作为其中一个潜在的解决方案，LLM代理被提出用于克服这些局限性并推动LLM的实际应用。AutoGPT [[18](https://arxiv.org/html/2410.21286v1#bib.bib18)]
    作为最流行的LLM自主代理之一，探索了应用LLM实现自主规划和任务解决的潜力。随后，LLM代理[[19](https://arxiv.org/html/2410.21286v1#bib.bib19),
    [20](https://arxiv.org/html/2410.21286v1#bib.bib20)] 在两个方向上取得了显著进展：任务导向代理和模拟代理。沿着第一个方向，研究人员致力于提高LLM代理解决复杂任务的能力。例如，许多编程代理，如ChatDev [[21](https://arxiv.org/html/2410.21286v1#bib.bib21)]、SWEAgent [[22](https://arxiv.org/html/2410.21286v1#bib.bib22)]
    和MetaGPT [[23](https://arxiv.org/html/2410.21286v1#bib.bib23)]，被设计用来解决复杂的编程任务。至于第二个方向，生成性代理[[4](https://arxiv.org/html/2410.21286v1#bib.bib4)]
    已展示出大模型在模拟人类行为方面的潜力，这一点在后续的研究中得到了进一步验证。S3 [[24](https://arxiv.org/html/2410.21286v1#bib.bib24)]
    探索了使用LLM代理模拟社交网络的潜力。CoPB [[6](https://arxiv.org/html/2410.21286v1#bib.bib6)] 定义了一种代理工作流程来模拟移动行为。RecAgent [[25](https://arxiv.org/html/2410.21286v1#bib.bib25)]
    模拟了推荐系统中的用户行为。尽管这些工作展示了LLM代理的潜力，但生成性代理的大规模高效模拟成为进一步应用的关键瓶颈。
- en: 2.2 LLM Deployment Optimization
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 LLM 部署优化
- en: To support the efficient inference of LLMs and LLM agents, enormous works and
    systems [[26](https://arxiv.org/html/2410.21286v1#bib.bib26)] are designed to
    optimize the inference efficiency of LLMs and further accelerate their practical
    applications. For example, Flash-attention [[27](https://arxiv.org/html/2410.21286v1#bib.bib27)]
    is an IO-aware exact attention algorithm which uses tiling to reduce the number
    of memory reads/writes within GPU. AWQ [[28](https://arxiv.org/html/2410.21286v1#bib.bib28)]
    is an activation-aware weight quantization to compress and accelerate the LLM
    inference. vLLM [[29](https://arxiv.org/html/2410.21286v1#bib.bib29)] proposes
    pagedAttention mechanism to enable highly efficient KV cache scheduler during
    the inference and becomes the most population open source LLM inference engine.
    SGLang [[30](https://arxiv.org/html/2410.21286v1#bib.bib30)] provides a flexible
    frontend language to enable the efficient autonomous optimization of LLM inference.
    Synergy-of-thought [[31](https://arxiv.org/html/2410.21286v1#bib.bib31)] proposes
    to exploit the synergy between larger and smaller language models for efficient
    reasoning. While these systems are designed to process the general LLM inference,
    specific characteristics of generative agents especially urban generative agents
    are ignored which can be employed to further accelerate the inference and simulation.
    In this paper, we explore the potential of this direction and design the OpenCity
    platform.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持LLM和LLM代理的高效推理，设计了大量工作和系统[[26](https://arxiv.org/html/2410.21286v1#bib.bib26)]，旨在优化LLM的推理效率并进一步加速其实际应用。例如，Flash-attention
    [[27](https://arxiv.org/html/2410.21286v1#bib.bib27)]是一种IO感知的精确注意力算法，采用平铺技术减少GPU内存读写次数。AWQ
    [[28](https://arxiv.org/html/2410.21286v1#bib.bib28)]是一种激活感知的权重量化方法，用于压缩并加速LLM推理。vLLM
    [[29](https://arxiv.org/html/2410.21286v1#bib.bib29)]提出了pagedAttention机制，旨在推理过程中启用高效的KV缓存调度器，成为最受欢迎的开源LLM推理引擎。SGLang
    [[30](https://arxiv.org/html/2410.21286v1#bib.bib30)]提供了一个灵活的前端语言，以实现LLM推理的高效自主优化。Synergy-of-thought
    [[31](https://arxiv.org/html/2410.21286v1#bib.bib31)]提出利用大语言模型和小语言模型之间的协同效应进行高效推理。虽然这些系统旨在处理一般的LLM推理，但忽视了生成代理，尤其是城市生成代理的特定特征，这些特征可以进一步加速推理和仿真。在本文中，我们探讨了这一方向的潜力，并设计了OpenCity平台。
- en: 3 Preliminaries
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 前言
- en: 3.1 LLM Agents for Urban Activities
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 用于城市活动的LLM代理
- en: 'We focus on using LLM agents to reproduce urban dynamics characterized primarily
    by physical mobility. Consider an urban environment $E$ containing $N$ LLM agents.
    The state of agent $i$ at simulation time $t$, denoted as $S_{i}(t)=\{s_{i},m_{i}(t)\}$,
    consists of both static properties $s_{i}$ and dynamic properties $m_{i}(t)$.
    Static properties, like the agent’s demographics, remain constant throughout the
    simulation, while dynamic properties, such as memory and perceived environment
    information, change frequently and are hard to predict. We can represent the state
    update of agent $i$ using a function $f$:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专注于使用LLM代理来再现主要由物理移动性特征决定的城市动态。考虑一个包含$N$个LLM代理的城市环境$E$。代理$i$在仿真时间$t$的状态记作$S_{i}(t)=\{s_{i},m_{i}(t)\}$，由静态属性$s_{i}$和动态属性$m_{i}(t)$组成。静态属性，如代理的基本信息，在仿真过程中保持不变，而动态属性，如记忆和感知到的环境信息，则频繁变化且难以预测。我们可以使用函数$f$表示代理$i$的状态更新：
- en: '|  | $m_{i}(t+1)=f(s_{i},E,m_{i}(t);S_{i}(t+1)=\{s_{i},m_{i}(t+1)\}$ |  | (1)
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '|  | $m_{i}(t+1)=f(s_{i},E,m_{i}(t);S_{i}(t+1)=\{s_{i},m_{i}(t+1)\}$ |  | (1)
    |'
- en: Here, $m_{i}(t+1)$ is the updated memory of agent $i$ at time $t+1$, and the
    function $f$ models how the agent updates its state by perceiving the urban environment
    $E$, reflecting on its memory $m_{i}(t)$, and interacting with the LLM. The individual
    trajectory of agent $i$, denoted as $T_{i}$, describes the trajectory of the agent
    over time in the urban environment $E$. If the location of agent $i$ at time $t$
    is represented by $L_{i}(t)$, which depends on its state $S_{i}(t)$, then the
    individual trace can be expressed as $T_{i}=\{L_{i}(0),L_{i}(1),L_{i}(2),...,L_{i}(t_{s})\}$,
    where $t_{s}$ is the the total simulation time. Along with individual mobility,
    we also examine the aggregated mobility features $A=\Phi(\sum_{i}{\phi(\sum_{t}S_{i}(t)}))$,
    such as Original-Destination (OD) matrix and income segregation index, which reflects
    the urban dynamics involving states of all agents.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，$m_{i}(t+1)$ 是代理 $i$ 在时间 $t+1$ 时刻更新后的记忆，函数 $f$ 模拟了代理如何通过感知城市环境 $E$、反思其记忆
    $m_{i}(t)$ 并与LLM互动来更新其状态。代理 $i$ 的个体轨迹，记作 $T_{i}$，描述了代理在城市环境 $E$ 中随时间变化的轨迹。如果代理
    $i$ 在时间 $t$ 的位置用 $L_{i}(t)$ 表示，且该位置依赖于其状态 $S_{i}(t)$，则个体轨迹可以表示为 $T_{i}=\{L_{i}(0),L_{i}(1),L_{i}(2),...,L_{i}(t_{s})\}$，其中
    $t_{s}$ 是总的仿真时间。除了个体的流动性，我们还考察了聚合的流动性特征 $A=\Phi(\sum_{i}{\phi(\sum_{t}S_{i}(t)}))$，例如原始-目的地（OD）矩阵和收入隔离指数，这些特征反映了涉及所有代理状态的城市动态。
- en: 'To simulate LLM agents in the urban space, we set the initial state for the
    agents and environment $\{S_{i}(0)|i\in N\}$ and then apply the Equation [1](https://arxiv.org/html/2410.21286v1#S3.E1
    "In 3.1 LLM Agents for Urban Activities ‣ 3 Preliminaries ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents") for each agent
    at every simulation step. When the number of agents increases, challenges arise
    mainly because of the LLM request process. LLMs are inherently slow due to their
    parameter size, and when using commercial LLMs accessed via APIs, response times
    can be further delayed, especially with poor network conditions. Some have proposed
    reusing the LLM response for agents can improve the efficiency [[9](https://arxiv.org/html/2410.21286v1#bib.bib9)],
    but it requires that the agents have the completely same state or have limit kinds
    of state that can be easily predicted. What’s more, simply reusing the response
    would eliminate the independence of agents and reduce the faithfulness of the
    simulation results. Urban agent $i$ has dynamic memory $m_{i}(t)$ that evolves
    during the simulation. This memory $m_{i}(t)$ depends not only on past memory
    $m_{i}(t_{h})$ but also on the current environment. Since decision-making and
    memory updates rely heavily on the LLM, predicting an agent’s future state or
    finding an agent with an identical state to reuse an LLM response is difficult.
    Therefore, to simulate the large-scale and reliable LLM agents for urban dynamics,
    a simple response reuse strategy is insufficient.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '为了在城市空间中模拟LLM代理，我们首先为代理和环境设置初始状态 $\{S_{i}(0)|i\in N\}$，然后在每个仿真步骤中对每个代理应用方程
    [1](https://arxiv.org/html/2410.21286v1#S3.E1 "In 3.1 LLM Agents for Urban Activities
    ‣ 3 Preliminaries ‣ OpenCity: A Scalable Platform to Simulate Urban Activities
    with Massive LLM Agents")。当代理数量增加时，主要的挑战来自于LLM请求过程。由于LLM的参数规模，LLM本身的计算速度较慢，尤其是在通过API访问商业LLM时，响应时间可能会进一步延迟，尤其是在网络条件较差时。有人提出通过重用LLM的响应来提高效率[[9](https://arxiv.org/html/2410.21286v1#bib.bib9)]，但这要求代理必须处于完全相同的状态，或者只具有有限种可以轻松预测的状态。而且，单纯的重用响应会消除代理的独立性，降低仿真结果的真实性。城市代理
    $i$ 拥有动态记忆 $m_{i}(t)$，在仿真过程中不断演变。这个记忆 $m_{i}(t)$ 不仅依赖于过去的记忆 $m_{i}(t_{h})$，还依赖于当前的环境。由于决策和记忆更新在很大程度上依赖于LLM，因此预测一个代理的未来状态或找到一个具有相同状态的代理以重用LLM响应是困难的。因此，想要为城市动态模拟大规模且可靠的LLM代理，单纯的响应重用策略是不足够的。'
- en: 3.2 Time Cost Analysis
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 时间成本分析
- en: 'In light of the prevailing dominance of remote LLM service invocations in the
    current operational landscape of LLM agents simulation, a decomposition of the
    time required for a single LLM request can be undertaken, as illustrated in Fig.[1](https://arxiv.org/html/2410.21286v1#S4.F1
    "Figure 1 ‣ 4.1 LLM Request Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents")(b). The first
    phase is the initialization and reception time for the LLM request, the second
    is the TCP/IP connection and destruction time between the simulation system and
    the LLM service provider, and the third is the data transmission and waiting time.
    For a single LLM request, the overhead of the first and second phases is relatively
    low in comparison to the third, and the core time consumption is derived from
    the data transmission and waiting.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '鉴于当前LLM代理仿真中远程LLM服务调用的主导地位，可以对单个LLM请求所需的时间进行分解，如图[1](https://arxiv.org/html/2410.21286v1#S4.F1
    "Figure 1 ‣ 4.1 LLM Request Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents")(b)所示。第一阶段是LLM请求的初始化和接收时间，第二阶段是仿真系统与LLM服务提供商之间的TCP/IP连接和销毁时间，第三阶段是数据传输和等待时间。对于单个LLM请求，第一和第二阶段的开销相对于第三阶段较低，核心的时间消耗来自数据传输和等待。'
- en: The simulation of large-scale agents necessitates the issuance of a considerable
    number of LLM requests, which, given the presence of waiting periods, impairs
    the overall efficiency of the simulator. Furthermore, the system resources are
    not fully utilized. Consequently, the effective scheduling of LLM requests is
    essential for enhancing the overall utilization of system resources, which in
    turn improves the overall efficiency of the simulation. Furthermore, as the time
    required for LLM inference is directly proportional to the number of tokens contained
    in an LLM request, it is also important to reduce the number of tokens consumed
    per agent while compressing the number of requests.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模代理的仿真需要发出大量的LLM请求，而由于存在等待时间，这会影响仿真器的整体效率。此外，系统资源未能充分利用。因此，有效调度LLM请求对于提高系统资源的整体利用率至关重要，从而提升仿真的整体效率。此外，由于LLM推理所需的时间与LLM请求中包含的令牌数量成正比，因此减少每个代理消耗的令牌数，同时压缩请求的数量，也非常重要。
- en: From this vantage point, the present work puts forth an efficacious LLM request
    scheduler and a prompt distillation method, which can markedly enhance the efficiency
    of large-scale LLM agents simulation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，本研究提出了一种有效的LLM请求调度器和提示蒸馏方法，可以显著提高大规模LLM代理仿真的效率。
- en: 4 OpenCity Platform
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 OpenCity平台
- en: We devise a scalable platform OpenCity to accelerate the simulation of urban
    LLM agents from both system- and prompt-level. The OpenCity platform aims to substantially
    reduce the simulation time per LLM agent while maintaining high simulation fidelity.
    Besides, OpenCity also provides a user-friendly web interface to facilitate the
    easy access of researchers from diverse background. The key designs are introduced
    as follows.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个可扩展的平台OpenCity，从系统级和提示级两个方面加速城市LLM代理的仿真。OpenCity平台旨在显著减少每个LLM代理的仿真时间，同时保持高仿真保真度。此外，OpenCity还提供了一个用户友好的网页界面，便于来自不同背景的研究人员轻松访问。以下介绍了关键设计。
- en: 4.1 LLM Request Scheduler
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 LLM请求调度器
- en: 'As shown in Fig.[1](https://arxiv.org/html/2410.21286v1#S4.F1 "Figure 1 ‣ 4.1
    LLM Request Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable Platform to
    Simulate Urban Activities with Massive LLM Agents")(a), for a LLM agent, the dependency
    between its LLM requests—that is, the necessity for the next LLM request to be
    initiated after the previous one is completed—results in a constant waiting time
    under the condition of a fixed network environment and request content. In contrast,
    for a system comprising multiple agents, there is no dependency between their
    LLM requests. In order to achieve asynchronous processing of multiple LLM requests,
    we have implemented an IO multiplexing scheme (based on epoll in Linux) which
    eliminates waiting time in the simulation system. This allows the operating system
    to manage IO waiting, thereby achieving the desired "zero-awareness" of data transmission
    in the simulation system. Consequently, the average time for a LLM request is
    reduced to the time required for the first and second phases (Time saving#1 in
    Fig.[1](https://arxiv.org/html/2410.21286v1#S4.F1 "Figure 1 ‣ 4.1 LLM Request
    Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable Platform to Simulate Urban
    Activities with Massive LLM Agents")(c)).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[1](https://arxiv.org/html/2410.21286v1#S4.F1 "图 1 ‣ 4.1 LLM 请求调度器 ‣ 4 OpenCity
    平台 ‣ OpenCity: 一个可扩展的平台，用于模拟具有大量 LLM 代理的城市活动")（a）所示，对于一个 LLM 代理，其 LLM 请求之间的依赖性——即，必须在前一个
    LLM 请求完成后才能启动下一个 LLM 请求——会导致在固定网络环境和请求内容下，存在恒定的等待时间。相比之下，对于由多个代理组成的系统，它们的 LLM
    请求之间没有依赖关系。为了实现多条 LLM 请求的异步处理，我们实现了一种基于 Linux 中 epoll 的 IO 多路复用方案，消除了模拟系统中的等待时间。这使得操作系统能够管理
    IO 等待，从而实现模拟系统中数据传输的“零感知”。因此，LLM 请求的平均时间缩短为第一阶段和第二阶段所需的时间（图[1](https://arxiv.org/html/2410.21286v1#S4.F1
    "图 1 ‣ 4.1 LLM 请求调度器 ‣ 4 OpenCity 平台 ‣ OpenCity: 一个可扩展的平台，用于模拟具有大量 LLM 代理的城市活动")（c）中的时间节省#1）。'
- en: '![Refer to caption](img/e97c03da3c42b80c1f25e31b3beaac55.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e97c03da3c42b80c1f25e31b3beaac55.png)'
- en: 'Figure 1: The functionality of the proposed LLM Request Scheduler.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：提出的 LLM 请求调度器的功能。
- en: 'Furthermore, the considerable number of LLM calls necessitates the frequent
    establishment of connections with the service provider, resulting in a considerable
    overhead in the establishment and destruction of each connection. However, given
    that the content of LLM requests is inherently linked to the corresponding agent,
    it is possible to leverage the same connection for multiple agents, thereby reducing
    the overall performance overhead. To address this issue, a pool of reusable connections
    is maintained within the system. Upon initiation of an LLM request by an agent,
    the request content is populated into an available connection, thus avoiding the
    establishment of a new connection. This approach additionally reduces the mean
    time consumption of LLM requests (Time saving#2 in Fig.[1](https://arxiv.org/html/2410.21286v1#S4.F1
    "Figure 1 ‣ 4.1 LLM Request Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents")(c)).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，考虑到大量的 LLM 调用需要频繁与服务提供商建立连接，因此每个连接的建立和销毁都会带来相当大的开销。然而，由于 LLM 请求的内容本质上与相应的代理相关联，可以利用同一个连接为多个代理服务，从而减少整体性能开销。为了解决这个问题，系统内部维护了一个可重用连接池。在代理发起
    LLM 请求时，请求内容会填充到一个可用的连接中，从而避免了新建连接。这种方法还减少了 LLM 请求的平均时间消耗（图[1](https://arxiv.org/html/2410.21286v1#S4.F1
    "图 1 ‣ 4.1 LLM 请求调度器 ‣ 4 OpenCity 平台 ‣ OpenCity: 一个可扩展的平台，用于模拟具有大量 LLM 代理的城市活动")（c）中的时间节省#2）。'
- en: 'For those agents with CPU tasks during the computation process, it is important
    to note that the continued occupation of CPU resources by the computation load
    will inevitably result in a delay in the sending of LLM requests from subsequent
    agents. To mitigate the adverse effects of this issue on the system’s overall
    performance, we categorize the CPU task as "local IO", offload it to available
    cores for computation through a multi-core parallel scheme, and then return the
    result to the designated agent upon completion of the computation. This approach
    further ensures the stable operation of asynchronous LLM requests (Time saving#3
    in Fig.[1](https://arxiv.org/html/2410.21286v1#S4.F1 "Figure 1 ‣ 4.1 LLM Request
    Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable Platform to Simulate Urban
    Activities with Massive LLM Agents")(c)).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '对于在计算过程中执行 CPU 任务的代理，需要注意的是，计算负载持续占用 CPU 资源将不可避免地导致后续代理的 LLM 请求发送延迟。为减轻该问题对系统整体性能的负面影响，我们将
    CPU 任务分类为“本地 IO”，通过多核并行方案将其卸载到可用核心进行计算，并在计算完成后将结果返回到指定代理。这一方法进一步确保了异步 LLM 请求的稳定运行（图[1](https://arxiv.org/html/2410.21286v1#S4.F1
    "Figure 1 ‣ 4.1 LLM Request Scheduler ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents")(c)中的节省时间#3）。'
- en: The proposed LLM request scheduler is designed to reduce the waiting time for
    a significant number of LLM requests during the simulation runtime. Based on the
    supporting auxiliary scheme, it has the potential to significantly enhance the
    efficiency of large-scale LLM agents.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的 LLM 请求调度器旨在减少在模拟运行期间大量 LLM 请求的等待时间。基于支持的辅助方案，它有潜力显著提升大规模 LLM 代理的效率。
- en: 4.2 Group-and-Distill Meta-Prompt Optimizer
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 Group-and-Distill 元提示优化器
- en: 'A further crucial method for enhancing the efficiency of the simulation is
    to reduce the number of LLM requests issued by agents and the quantity of tokens
    consumed by said agents. A conventional approach is to reuse the generated result
    of a single LLM request across multiple agents. However, this approach presents
    two significant drawbacks: 1\. In fine-grained urban LLM agent simulations, each
    agent possesses its own dynamic properties. Consequently, the reuse scheme compromises
    the independence of agents, which is antithetical to the objective of conducting
    urban simulations through large-scale LLM agents. Furthermore, for agents with
    dynamic properties, it is inherently impossible to share the result of a single
    LLM request, as shown in Fig.[2](https://arxiv.org/html/2410.21286v1#S4.F2 "Figure
    2 ‣ 4.2 Group-and-Distill Meta-Prompt Optimizer ‣ 4 OpenCity Platform ‣ OpenCity:
    A Scalable Platform to Simulate Urban Activities with Massive LLM Agents")(a).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '提升模拟效率的另一重要方法是减少代理发出的 LLM 请求数量及这些代理消耗的令牌数量。传统方法是通过在多个代理之间重用单个 LLM 请求的生成结果。然而，这种方法存在两个显著缺点：1.
    在精细化的城市 LLM 代理模拟中，每个代理都拥有自身的动态属性。因此，重用方案会妥协代理的独立性，这与通过大规模 LLM 代理进行城市模拟的目标背道而驰。此外，对于具有动态属性的代理来说，天然无法共享单个
    LLM 请求的结果，如图[2](https://arxiv.org/html/2410.21286v1#S4.F2 "Figure 2 ‣ 4.2 Group-and-Distill
    Meta-Prompt Optimizer ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable Platform to
    Simulate Urban Activities with Massive LLM Agents")（a）所示。'
- en: '![Refer to caption](img/788eff7f8384cb659518f783e0d74ba9.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/788eff7f8384cb659518f783e0d74ba9.png)'
- en: 'Figure 2: Overview of Group-and-Distill Meta-Prompt Optimizer.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：Group-and-Distill 元提示优化器概览。
- en: 'To address this issue, we propose the Group-and-Distill Meta-Prompt Optimizer
    (depicted in Fig.[2](https://arxiv.org/html/2410.21286v1#S4.F2 "Figure 2 ‣ 4.2
    Group-and-Distill Meta-Prompt Optimizer ‣ 4 OpenCity Platform ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents")), which employs
    group information in lieu of the static attributes of the agent. This approach
    aggregates requests from multiple agents at runtime and realizes prompt by sharing
    group information and context information while preserving the agent’s dynamic
    properties. The optimizer is comprised of two distinct components. In-context
    prototype learning (IPL) and distill meta-prompt.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决这个问题，我们提出了 Group-and-Distill 元提示优化器（如图[2](https://arxiv.org/html/2410.21286v1#S4.F2
    "Figure 2 ‣ 4.2 Group-and-Distill Meta-Prompt Optimizer ‣ 4 OpenCity Platform
    ‣ OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM
    Agents")所示），该优化器利用组信息替代代理的静态属性。这种方法在运行时聚合来自多个代理的请求，通过共享组信息和上下文信息来实现提示，同时保留代理的动态属性。优化器由两个不同的组件组成：上下文原型学习（IPL）和元提示蒸馏。'
- en: 'The inputs and outputs of IPL are defined as follow:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: IPL的输入和输出定义如下：
- en: '|  | $IPL(\{s_{i}\},M,T)\rightarrow\textbf{G},\textbf{D}$ |  | (2) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|  | $IPL(\{s_{i}\},M,T)\rightarrow\textbf{G},\textbf{D}$ |  | (2) |'
- en: in which, $\{s_{i}\}$ is the collection of agent’s static properties; $M$ controls
    the number of agents in initial prototype learning; $T$ is the threshold for decision
    making; G is the collection of agent groups; D is the descriptions for each group
    of agents.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\{s_{i}\}$是代理的静态属性集合；$M$控制初始原型学习中代理的数量；$T$是决策的阈值；G是代理组的集合；D是每个代理组的描述信息。
- en: Input the static properties of a set of agents, IPL first groups the first $M$
    agents, providing both group results and the corresponding description information.
    Subsequently, IPL classifies the remaining agents by transmitting the static properties
    of the agent to LLM, which analyzes the likelihood of the agent belonging to each
    group based on the group description and provides the quantization result. By
    comparing the quantization result with $T$, when the result is greater than $T$,
    IPL assigns the agent to the specified group. Otherwise, it constructs a new group
    and describes the characteristics of the group. In comparison to conventional
    prototype learning methods that operate within a fixed parameter space, IPL exhibits
    enhanced generalization capabilities and a particular aptitude for leveraging
    semantic-level knowledge in the prototyping process. The prototype information
    obtained by IPL is employed to efficiently summarize the static attribute characteristics
    of the set of agents within the specified group.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输入一组代理的静态属性后，IPL首先将前$M$个代理分组，提供分组结果及相应的描述信息。随后，IPL通过将代理的静态属性传递给LLM，LLM根据组描述分析代理属于各个组的可能性，并提供量化结果。通过将量化结果与$T$进行比较，当结果大于$T$时，IPL将该代理分配到指定组。否则，IPL构建一个新组并描述该组的特征。与在固定参数空间内操作的传统原型学习方法相比，IPL展示了更强的泛化能力，并且在原型化过程中特别擅长利用语义级别的知识。IPL获得的原型信息用于有效总结指定组内代理的静态属性特征。
- en: 'The distill meta-prompts obtained through a systematic examination of the original
    prompts and the CoT approach is employed to generate the prompts (details can
    be found in Fig.[A1](https://arxiv.org/html/2410.21286v1#A3.F1 "Figure A1 ‣ Appendix
    C Image supplements ‣ OpenCity: A Scalable Platform to Simulate Urban Activities
    with Massive LLM Agents")). To facilitate the generation procedure, we have proposed
    a raw prompt design diagram, which divides the prompt into three sections: the
    function section, the variable section, and the input section. The generation
    process, which is initiated with a given raw prompt, comprises four steps: summarization,
    context extraction, information sharing, and rewriting of the raw prompt into
    the distill meta-prompt. In the operational phase, the requests from the agents
    in a group are aggregated into a single Distill request, which has the effect
    of reducing the number of LLM requests and the consumption of tokens.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '通过对原始提示和CoT方法的系统性检验获得的蒸馏元提示被用来生成提示（详细信息见图[A1](https://arxiv.org/html/2410.21286v1#A3.F1
    "图A1 ‣ 附录C 图像补充 ‣ OpenCity: 一个可扩展的平台，用于模拟城市活动与大规模LLM代理")）。为了简化生成过程，我们提出了一个原始提示设计图，将提示分为三个部分：功能部分、变量部分和输入部分。生成过程从给定的原始提示开始，包括四个步骤：总结、上下文提取、信息共享以及将原始提示重写为蒸馏元提示。在操作阶段，来自一个组的代理请求被汇总为一个单一的蒸馏请求，从而减少了LLM请求的数量和令牌的消耗。'
- en: The proposed prompt optimizer enables further enhancement of simulation efficiency
    and reduction of simulation cost while maintaining agent dynamic properties.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的提示优化器能够进一步提高仿真效率并降低仿真成本，同时保持代理的动态属性。
- en: 4.3 Web Portal
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 网站门户
- en: A web portal has been designed for the utilisation of OpenCity, encompassing
    the frontend, backend, and simulation system. This enables users to rapidly configure
    simulation conditions and visualise simulation results, as well as facilitating
    the storage of simulation data and urban infrastructure information within a database.
    The fundamental concept underlying the design of this portal is user-friendliness,
    particularly given the inherently interdisciplinary nature of urban research.
    We have developed a rapid, code-free configuration approach tailored to the needs
    of researchers, thereby facilitating the seamless engagement of experts from diverse
    fields with our simulation platform.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地利用OpenCity，已设计了一个Web门户，涵盖了前端、后端和模拟系统。该门户使用户能够快速配置模拟条件并可视化模拟结果，同时也方便将模拟数据和城市基础设施信息存储在数据库中。该门户设计的基本理念是用户友好性，特别是考虑到城市研究本身的跨学科特性。我们开发了一种快速、无代码配置方法，专门针对研究人员的需求，从而促进了来自不同领域的专家与我们的模拟平台的无缝对接。
- en: 'User-friendliness: In order to enhance the usability of the OpenCity platform,
    the Web Portal has been augmented with the incorporation of the LLM agent blueprint
    construction function. Users are able to drag and drop each basic function module
    in order to construct complex logic for LLM agents. In order to meet a variety
    of needs, the blueprint function is based on the established LLM agent development
    frameworks, such as Langchain [[32](https://arxiv.org/html/2410.21286v1#bib.bib32)]
    and AutoGPT [[33](https://arxiv.org/html/2410.21286v1#bib.bib33)], and incorporates
    several fundamental modules oriented towards urban simulation, including environmental
    and traffic sensing. The blueprint offers an efficient and agile development solution
    for interdisciplinary researchers, facilitating the rapid iteration of simulation
    methods and theories.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用户友好性：为了提高OpenCity平台的可用性，Web门户已通过引入LLM代理蓝图构建功能进行了增强。用户可以通过拖放每个基本功能模块来构建LLM代理的复杂逻辑。为了满足多样化的需求，蓝图功能基于现有的LLM代理开发框架，如Langchain
    [[32](https://arxiv.org/html/2410.21286v1#bib.bib32)] 和AutoGPT [[33](https://arxiv.org/html/2410.21286v1#bib.bib33)]，并结合了多个面向城市模拟的基础模块，包括环境和交通感知。该蓝图为跨学科研究人员提供了一种高效且灵活的开发解决方案，促进了模拟方法和理论的快速迭代。
- en: 'Basic workflow: The primary process of urban LLM agent simulation on this web
    portal is comprised of three distinct phases: citizen profile configuration, deployment
    and simulation, and results presentation. The configuration of the citizen profile
    is facilitated by the provision of a console hub, which enables users to efficiently
    and transparently administer the simulation tasks they have created on the platform,
    along with the agents within those simulations. The user is able to bind the execution
    logic designed in the blueprint to different agents and to configure their profiles
    with great rapidity via the web interface. This may entail selecting a city, selecting
    an existing profile, or filling out a profile manually. Once the configuration
    process is complete, users can deploy and initiate simulations on the platform
    with a single click, leveraging the backend system and simulation system. The
    web portal also offers a monitor page, which enables users to observe the real-time
    outcomes of ongoing simulations and assess the performance of their agents. Finally,
    after the simulation has concluded, users can access the portal to view macroscopic
    statistical results in a visual format, such as Origin-Destination (OD) maps.
    An exemplar of the proposed web portal in operation can be found in Figure [A2](https://arxiv.org/html/2410.21286v1#A3.F2
    "Figure A2 ‣ Appendix C Image supplements ‣ OpenCity: A Scalable Platform to Simulate
    Urban Activities with Massive LLM Agents").'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '基本工作流程：该网络门户中城市LLM代理仿真的主要过程分为三个不同的阶段：市民个人资料配置、部署与仿真、结果展示。市民个人资料的配置通过提供一个控制台中心来实现，该中心使用户能够高效且透明地管理他们在平台上创建的仿真任务及其仿真中的代理。用户能够将设计蓝图中的执行逻辑绑定到不同的代理，并通过网页界面迅速配置其个人资料。这可能包括选择一个城市、选择一个现有的个人资料，或手动填写个人资料。一旦配置过程完成，用户可以通过单击按钮利用后台系统和仿真系统在平台上部署并启动仿真。该网页门户还提供一个监控页面，允许用户观察正在进行的仿真的实时结果，并评估其代理的表现。最后，仿真完成后，用户可以访问门户，查看以可视化格式呈现的宏观统计结果，如起止点（OD）地图。操作中的网页门户示例如图[A2](https://arxiv.org/html/2410.21286v1#A3.F2
    "Figure A2 ‣ Appendix C Image supplements ‣ OpenCity: A Scalable Platform to Simulate
    Urban Activities with Massive LLM Agents")所示。'
- en: 5 Benchmark
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 基准
- en: 5.1 Dataset and Setup
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 数据集与设置
- en: 'Dataset We collect urban mobility data in 6 major cities around world: Beijing,
    New York, San Francisco, London, Paris, and Sydney. The data sources vary. Beijing’s
    data comes from a related work [[6](https://arxiv.org/html/2410.21286v1#bib.bib6)],
    which collected from social network platform. New York and San Francisco source
    from Safegraph for aggregated population flow data. And the other three cities
    are from Foursquare which consist of thousands of check-ins data. To make better
    use of these data, we have done some preprocess method, such as trajectory filter,
    home extraction and profile sampling. More details can be seen in Appendix [A](https://arxiv.org/html/2410.21286v1#A1
    "Appendix A Urban Mobility Dataset ‣ OpenCity: A Scalable Platform to Simulate
    Urban Activities with Massive LLM Agents").'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '数据集 我们收集了来自世界六个主要城市的城市出行数据：北京、纽约、旧金山、伦敦、巴黎和悉尼。这些数据的来源各不相同。北京的数据来源于一项相关研究[[6](https://arxiv.org/html/2410.21286v1#bib.bib6)]，该研究收集了来自社交网络平台的数据。纽约和旧金山的数据来自Safegraph，提供了聚合的人口流动数据。其余三个城市的数据则来自Foursquare，其中包含了数以千计的签到数据。为了更好地利用这些数据，我们进行了部分预处理方法，如轨迹过滤、家庭提取和个人资料抽样。更多细节可见附录[A](https://arxiv.org/html/2410.21286v1#A1
    "Appendix A Urban Mobility Dataset ‣ OpenCity: A Scalable Platform to Simulate
    Urban Activities with Massive LLM Agents")。'
- en: Architecture of LLM Agent The main agent used in OpenCity platform to simulate
    the urban dynamic is the generative agent [[4](https://arxiv.org/html/2410.21286v1#bib.bib4)].
    Generative agents use a framework that involves perception, planning, and reflection.
    A generative agent first creates a daily plan to ensure the trajectory is reasonable.
    When the agent arrives at a POI, it makes decisions based on current perceptions
    and memory. After taking action, the agent records the action and the POI into
    its memory stream. Once the memory stream reaches a threshold, the agent reflects.
    The results show that the generative agent to function well in the OpenCity platform.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理的架构 OpenCity平台中用于模拟城市动态的主要代理是生成代理[[4](https://arxiv.org/html/2410.21286v1#bib.bib4)]。生成代理使用一个包括感知、规划和反思的框架。生成代理首先制定一个日常计划，以确保轨迹的合理性。当代理到达一个兴趣点（POI）时，它会根据当前的感知和记忆做出决策。采取行动后，代理将该行动和POI记录到它的记忆流中。当记忆流达到某个阈值时，代理会进行反思。结果表明，生成代理在OpenCity平台中能够很好地运作。
- en: 'We also have rule-based agent for comparison, such as the famous Explore and
    Preferential-Return (EPR) model [[16](https://arxiv.org/html/2410.21286v1#bib.bib16)].
    This work make agent choose to explore a new location or return to the visited
    location. Decisions are related to some parameters to compute the probability.
    In this paper, we set the parameters as follows: exploration rate $\rho=0.6$,
    exploration-return trade-off parameter $\gamma=0.21$, waiting time distribution
    parameters $\tau=17,\beta=0.8$.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还进行了基于规则的代理比较，例如著名的探索与优先返回（EPR）模型[[16](https://arxiv.org/html/2410.21286v1#bib.bib16)]。该模型让代理选择探索新地点或返回已访问的地点。决策与一些参数相关，用于计算概率。在本文中，我们设置了以下参数：探索率$\rho=0.6$，探索-返回权衡参数$\gamma=0.21$，等待时间分布参数$\tau=17,\beta=0.8$。
- en: 5.2 Acceleration Performance
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 加速性能
- en: 'This section presents an evaluation of the performance of the OpenCity platform
    in conjunction with the Generative Agent (Tested on Huawei ECS Cloud Server -
    Intel(R) Xeon(R) Platinum 8378C CPU @ 2.80GHz with 64 cores and 256 GB RAM). The
    performance of the platform was evaluated in six major cities with 10,000 agents.
    The results are presented in Table.[1](https://arxiv.org/html/2410.21286v1#S5.T1
    "Table 1 ‣ 5.2 Acceleration Performance ‣ 5 Benchmark ‣ OpenCity: A Scalable Platform
    to Simulate Urban Activities with Massive LLM Agents"), where the following variables
    are defined: $Speedup$ denotes the improvements in simulation time, $Rr$ denotes
    the LLM request number reduction rate, and $Tr$ denotes the token number reduction
    rate.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '本节介绍了在与生成代理结合使用时，OpenCity平台的性能评估（测试环境为华为ECS云服务器——Intel(R) Xeon(R) Platinum
    8378C CPU @ 2.80GHz，64核，256 GB内存）。平台的性能在六个主要城市中进行了评估，涉及10,000个代理。结果见下表[1](https://arxiv.org/html/2410.21286v1#S5.T1
    "Table 1 ‣ 5.2 Acceleration Performance ‣ 5 Benchmark ‣ OpenCity: A Scalable Platform
    to Simulate Urban Activities with Massive LLM Agents")，其中定义了以下变量：$Speedup$表示模拟时间的加速，$Rr$表示LLM请求数量减少率，$Tr$表示token数量减少率。'
- en: The results demonstrate that OpenCity exhibits substantial acceleration in all
    test cities, with an average runtime of 0.058s per LLM agent and an average speedup
    of 635.3x in simulation time. Furthermore, the proposed acceleration scheme is
    capable of markedly reducing the number of LLM requests and token consumption,
    with an average reduction of 73.7% and 45.5%, respectively.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，OpenCity在所有测试城市中都表现出显著的加速，LLM代理的平均运行时间为0.058秒，模拟时间的平均加速为635.3倍。此外，所提出的加速方案能够显著减少LLM请求数量和token消耗，平均减少率分别为73.7%和45.5%。
- en: 'To assess the scalability of OpenCity, we conducted a series of simulations
    to evaluate its acceleration performance under varying orders of magnitude of
    agents. The results of this analysis are presented in Fig.[3](https://arxiv.org/html/2410.21286v1#S5.F3
    "Figure 3 ‣ 5.2 Acceleration Performance ‣ 5 Benchmark ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents"), in which the
    baseline represents the simulation time without optimization. The results demonstrate
    that OpenCity’s acceleration capability is scalable, with a notable enhancement
    in acceleration effect when the number of agents is increased from 10 to 10,000\.
    This is due to the fact that as the number of agents increases, the number of
    groups obtained based on IPL also gradually increases. This, in turn, allows the
    advantages of the LLM request scheduler to be fully realised, thereby ensuring
    a better utilisation of system resources.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估OpenCity的可扩展性，我们进行了一系列模拟，评估了其在不同规模的代理数量下的加速性能。该分析的结果展示在图[3](https://arxiv.org/html/2410.21286v1#S5.F3
    "Figure 3 ‣ 5.2 Acceleration Performance ‣ 5 Benchmark ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents")中，其中基准线表示未优化的模拟时间。结果表明，OpenCity的加速能力是可扩展的，当代理数量从10增加到10,000时，加速效果显著增强。这是因为随着代理数量的增加，基于IPL获得的组数也逐渐增加，从而充分发挥了LLM请求调度器的优势，确保了系统资源的更好利用。'
- en: '| Cities | Time | $Speedup$ | $Rr$ | $Tr$ |  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 城市 | 时间 | $加速$ | $Rr$ | $Tr$ |  |'
- en: '| Beijing | 0.07s | 521.7 | 73.2% | 38.7% |  |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 北京 | 0.07秒 | 521.7 | 73.2% | 38.7% |  |'
- en: '| New York | 0.06s | 624.7 | 67.3% | 37.6% |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 纽约 | 0.06秒 | 624.7 | 67.3% | 37.6% |  |'
- en: '| San Francisco | 0.07s | 588.6 | 80.3% | 51.3% |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 旧金山 | 0.07秒 | 588.6 | 80.3% | 51.3% |  |'
- en: '| London | 0.04s | 792.5 | 74.6% | 49.9% |  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 伦敦 | 0.04秒 | 792.5 | 74.6% | 49.9% |  |'
- en: '| Paris | 0.06s | 640.0 | 76.3% | 48.6% |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 巴黎 | 0.06秒 | 640.0 | 76.3% | 48.6% |  |'
- en: '| Sydney | 0.05s | 644.0 | 70.7% | 46.6% |  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 悉尼 | 0.05秒 | 644.0 | 70.7% | 46.6% |  |'
- en: '| Average | 0.058s | 635.3 | 73.7% | 45.5% |  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 0.058秒 | 635.3 | 73.7% | 45.5% |  |'
- en: 'Table 1: Acceleration experiment results'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：加速实验结果
- en: '![Refer to caption](img/6ea06cb855db921f290eac4fffec3845.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![请参见图注](img/6ea06cb855db921f290eac4fffec3845.png)'
- en: 'Figure 3: Scalability experiments'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：可扩展性实验
- en: 'Furthermore, faithfulness experiments are conducted to demonstrate that the
    Group-and-Distill optimizer can effectively preserve the distinctive personality
    traits of the agents. The testbed for this evaluation is location choice generation,
    which requires the combination of agent properties to select the next location
    to visit. A comparison was conducted between the performance of four distinct
    methods, including raw prompting (without any modification), batch prompting [[12](https://arxiv.org/html/2410.21286v1#bib.bib12)],
    archetype prompting [[9](https://arxiv.org/html/2410.21286v1#bib.bib9)], and the
    proposed method. One hundred agents were randomly selected and location selection
    was performed 100 times for each agent with the same context. The effectiveness
    of the method was evaluated by counting the distribution of selections ($JSD$)
    as well as the top-1 hit rate ($T1$). The results are shown in Table.[2](https://arxiv.org/html/2410.21286v1#S5.T2
    "Table 2 ‣ 5.2 Acceleration Performance ‣ 5 Benchmark ‣ OpenCity: A Scalable Platform
    to Simulate Urban Activities with Massive LLM Agents"), where Inherent denotes
    the bias present in LLM itself (raw prompt method).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，还进行了忠实度实验，以证明Group-and-Distill优化器能够有效地保留代理的独特个性特征。该评估的测试平台是位置选择生成，它要求结合代理属性来选择下一个访问地点。我们对四种不同方法的性能进行了比较，包括原始提示（未做任何修改）、批量提示
    [[12](https://arxiv.org/html/2410.21286v1#bib.bib12)]、原型提示 [[9](https://arxiv.org/html/2410.21286v1#bib.bib9)]
    和提出的方法。随机选择了100个代理，并在相同上下文中对每个代理进行了100次位置选择。方法的有效性通过计算选择的分布（$JSD$）以及Top-1命中率（$T1$）来评估。结果如表所示。[2](https://arxiv.org/html/2410.21286v1#S5.T2
    "Table 2 ‣ 5.2 Acceleration Performance ‣ 5 Benchmark ‣ OpenCity: A Scalable Platform
    to Simulate Urban Activities with Massive LLM Agents")，其中"Inherent"表示LLM本身存在的偏差（原始提示方法）。'
- en: '| Model and Cities |   Inherent |  Batch prompting | Archetype prompting |
    Ours |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 模型与城市 |   固有 |  批量提示 | 原型提示 | 我们的方法 |'
- en: '| $JSD$ | $T1$ | $JSD$ | $T1$ | $JSD$ | $T1$ | $JSD$ | $T1$ |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| $JSD$ | $T1$ | $JSD$ | $T1$ | $JSD$ | $T1$ | $JSD$ | $T1$ |'
- en: '| 4o-mini | BJ | $0.04\pm 0.02$ | 90% | $0.11\pm 0.05$ | 76% | $0.89\pm 0.04$
    | 8% | $0.13\pm 0.02$ | 74% |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 4o-mini | BJ | $0.04\pm 0.02$ | 90% | $0.11\pm 0.05$ | 76% | $0.89\pm 0.04$
    | 8% | $0.13\pm 0.02$ | 74% |'
- en: '| NY | $0.02\pm 0.01$ | 92% | $0.07\pm 0.03$ | 81% | $0.84\pm 0.11$ | 13% |
    $0.06\pm 0.04$ | 86% |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 纽约 | $0.02\pm 0.01$ | 92% | $0.07\pm 0.03$ | 81% | $0.84\pm 0.11$ | 13% |
    $0.06\pm 0.04$ | 86% |'
- en: '| SF | $0.03\pm 0.02$ | 88% | $0.09\pm 0.04$ | 77% | $0.91\pm 0.03$ | 11% |
    $0.10\pm 0.03$ | 85% |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| SF | $0.03\pm 0.02$ | 88% | $0.09\pm 0.04$ | 77% | $0.91\pm 0.03$ | 11% |
    $0.10\pm 0.03$ | 85% |'
- en: '| Lo | $0.06\pm 0.04$ | 89% | $0.12\pm 0.07$ | 79% | $0.86\pm 0.06$ | 9% |
    $0.12\pm 0.04$ | 78% |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| Lo | $0.06\pm 0.04$ | 89% | $0.12\pm 0.07$ | 79% | $0.86\pm 0.06$ | 9% |
    $0.12\pm 0.04$ | 78% |'
- en: '| Pa | $0.05\pm 0.02$ | 86% | $0.17\pm 0.11$ | 69% | $0.94\pm 0.03$ | 4% |
    $0.14\pm 0.04$ | 71% |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| Pa | $0.05\pm 0.02$ | 86% | $0.17\pm 0.11$ | 69% | $0.94\pm 0.03$ | 4% |
    $0.14\pm 0.04$ | 71% |'
- en: '| Sy | $0.04\pm 0.03$ | 85% | $0.08\pm 0.03$ | 75% | $0.88\pm 0.05$ | 5% |
    $0.07\pm 0.04$ | 75% |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Sy | $0.04\pm 0.03$ | 85% | $0.08\pm 0.03$ | 75% | $0.88\pm 0.05$ | 5% |
    $0.07\pm 0.04$ | 75% |'
- en: '| GPT-4o | NY | $0.003\pm 0.002$ | 98% | $0.012\pm 0.007$ | 94% | $0.89\pm
    0.09$ | 10% | $0.009\pm 0.004$ | 97% |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4o | NY | $0.003\pm 0.002$ | 98% | $0.012\pm 0.007$ | 94% | $0.89\pm
    0.09$ | 10% | $0.009\pm 0.004$ | 97% |'
- en: '| Pa | $0.004\pm 0.002$ | 99% | $0.021\pm 0.009$ | 93% | $0.91\pm 0.04$ | 7%
    | $0.010\pm 0.006$ | 96% |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| Pa | $0.004\pm 0.002$ | 99% | $0.021\pm 0.009$ | 93% | $0.91\pm 0.04$ | 7%
    | $0.010\pm 0.006$ | 96% |'
- en: 'Table 2: Faithfulness experiment results'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：忠实度实验结果
- en: As evidenced by the results, our method demonstrates the capacity to maintain
    a comparable level of consistency to that observed in the batch prompting method,
    while exhibiting a reduction in volatility and token consumption. However, the
    archetype prompting method performs poorly in this evaluation, which further demonstrates
    the inability of the reuse-based method to accommodate the dynamic properties
    of agents. Furthermore, given the considerable discrepancies observed in the raw
    prompting method when evaluated using the GPT-4o-mini model, an additional assessment
    was conducted on two cities, New York and Paris, utilising the GPT-4o model. The
    findings indicate that our method is capable of approximating the execution of
    the raw prompting method to a significant degree. Additionally, the results indicate
    that there are notable discrepancies between different models in terms of environmental
    comprehension and the capacity to process lengthy textual content. The consistency
    of LLM outcomes merits further examination.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如实验结果所示，我们的方法展示了能够保持与批量提示方法相当一致性的能力，同时减少了波动性和令牌消耗。然而，原型提示方法在此评估中表现不佳，进一步证明了基于重用的方法无法适应代理的动态特性。此外，鉴于在使用GPT-4o-mini模型评估时原始提示方法存在较大差异，针对纽约和巴黎两个城市使用GPT-4o模型进行了额外评估。结果表明，我们的方法能够在很大程度上接近原始提示方法的执行。此外，结果还表明，不同模型在环境理解和处理长篇文本内容的能力方面存在显著差异。LLM结果的一致性值得进一步研究。
- en: In general, OpenCity is capable of markedly enhancing the efficiency of large-scale
    urban LLM agent simulations while concurrently preserving the distinctive characteristics
    of the agents themselves. This enables the cost of simulating populations exceeding
    10,000 to be maintained at the hourly level.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，OpenCity能够显著提高大规模城市LLM代理模拟的效率，同时保持代理本身的独特特性。这使得模拟超过10,000个个体的成本能够保持在每小时水平。
- en: 5.3 Reproducing Urban Dynamics
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 复制城市动态
- en: 'The significant increase in simulation efficiency enables us to benchmark LLM
    agent’s ability to reproduce large-scale urban dynamics for the first time. We
    use comprehensive metrics in three-levels to evaluate the simulation performance,
    from individual- to group level, and also from physical domain to social domain.
    At the individual level, we calculate the radius of gyration [[13](https://arxiv.org/html/2410.21286v1#bib.bib13)]
    for each user. At the group level, we use the original-destination matrix [[14](https://arxiv.org/html/2410.21286v1#bib.bib14)].
    As for the social domain, we focus on the income segregation index [[15](https://arxiv.org/html/2410.21286v1#bib.bib15)].
    To evaluation the simulation performance, we compute the MSE for these three metrics,
    which are denoted as $R_{MSE}$, $OD_{MSE}$ and $S_{MSE}$. More details can be
    referred to Appendix [B](https://arxiv.org/html/2410.21286v1#A2 "Appendix B Urban
    dynamic metrics ‣ OpenCity: A Scalable Platform to Simulate Urban Activities with
    Massive LLM Agents").'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '模拟效率的显著提高使我们首次能够基准测试LLM代理在再现大规模城市动态方面的能力。我们使用三层次的综合指标来评估模拟性能，从个体层面到群体层面，也从物理领域到社会领域。在个体层面，我们计算每个用户的回转半径[[13](https://arxiv.org/html/2410.21286v1#bib.bib13)]。在群体层面，我们使用原始-目的地矩阵[[14](https://arxiv.org/html/2410.21286v1#bib.bib14)]。至于社会领域，我们关注收入隔离指数[[15](https://arxiv.org/html/2410.21286v1#bib.bib15)]。为了评估模拟性能，我们计算这三个指标的均方误差（MSE），分别记作$R_{MSE}$、$OD_{MSE}$和$S_{MSE}$。更多细节可参见附录[B](https://arxiv.org/html/2410.21286v1#A2
    "附录 B 城市动态指标 ‣ OpenCity: 一个可扩展的城市活动模拟平台，支持大规模LLM代理")。'
- en: 'In this section, we analyze the performance of the Generative Agent and EPR
    Agent in reproducing urban dynamics. We test both agents in 6 major cities using
    1,000 agents. The results are shown in Table [3](https://arxiv.org/html/2410.21286v1#S5.T3
    "Table 3 ‣ 5.3 Reproducing Urban Dynamics ‣ 5 Benchmark ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents"). The results indicate
    that both the Generative Agent and EPR Agent successfully reproduce urban dynamics
    with low MSE values. Additionally, the LLM Agent performs as well as or better
    than the classical rule-based EPR Agent, highlighting the advantage of LLM’s semantic
    understanding ability in urban simulations.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '本节中，我们分析了生成代理和EPR代理在再现城市动态方面的表现。我们在6个主要城市中使用1000个代理测试了这两种代理。结果如表[3](https://arxiv.org/html/2410.21286v1#S5.T3
    "表 3 ‣ 5.3 再现城市动态 ‣ 5 基准 ‣ OpenCity: 一个可扩展的城市活动模拟平台，支持大规模LLM代理")所示。结果表明，生成代理和EPR代理都成功地再现了城市动态，且具有较低的MSE值。此外，LLM代理的表现与经典的基于规则的EPR代理相当或更好，突显了LLM在城市模拟中语义理解能力的优势。'
- en: '| Cities | GenerativeAgent | EPR |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 城市 | 生成代理 | EPR |'
- en: '| --- | --- | --- |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $R_{MSE}$ | $OD_{MSE}$ | $S_{MSE}$ | $R_{MSE}$ | $OD_{MSE}$ | $S_{MSE}$ |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| $R_{MSE}$ | $OD_{MSE}$ | $S_{MSE}$ | $R_{MSE}$ | $OD_{MSE}$ | $S_{MSE}$ |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Beijing | 19.5 | 3.88e-4 | 0.0312 | 29.8 | 4.26e-4 | 0.0630 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 北京 | 19.5 | 3.88e-4 | 0.0312 | 29.8 | 4.26e-4 | 0.0630 |'
- en: '| New York | - | 5.95e-4 | 0.3521 | - | 3.70e-4 | 0.2319 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| New York | - | 5.95e-4 | 0.3521 | - | 3.70e-4 | 0.2319 |'
- en: '| San Francisco | - | 23.6e-4 | 0.1535 | - | 14.0e-4 | 0.0352 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 旧金山 | - | 23.6e-4 | 0.1535 | - | 14.0e-4 | 0.0352 |'
- en: '| Paris | 2.48 | 7.58e-4 | 0.1255 | 4.04 | 6.25e-4 | 0.1240 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 巴黎 | 2.48 | 7.58e-4 | 0.1255 | 4.04 | 6.25e-4 | 0.1240 |'
- en: '| London | 6.24 | 5.22e-4 | 0.1258 | 25.7 | 7.41e-4 | 0.1501 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 伦敦 | 6.24 | 5.22e-4 | 0.1258 | 25.7 | 7.41e-4 | 0.1501 |'
- en: '| Sydney | 15.1 | 4.71e-4 | 0.1118 | 54.2 | 7.63e-4 | 0.1265 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 悉尼 | 15.1 | 4.71e-4 | 0.1118 | 54.2 | 7.63e-4 | 0.1265 |'
- en: 'Table 3: Urban dynamics reproduction results'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：城市动态再现结果
- en: '6 Case Study: Experienced Urban Segregation'
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 案例研究：经验性城市隔离
- en: With the ability to simulate large-scale urban LLM agents, we can conduct counterfactual
    experiments to explore outcomes under different policies and design optimal strategies
    for the future. Conventional rule-based models do not support this capability,
    as they are designed to simulate real-world scenarios. Experienced urban segregation
    is a widely discussed issue with significant impacts on social dynamics and the
    economy. It arises from both demographic differences in residential neighborhoods
    and the mobility patterns of urban residents [[15](https://arxiv.org/html/2410.21286v1#bib.bib15)].
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模拟大规模城市LLM代理的能力，我们可以进行反事实实验，探索不同政策下的结果，并为未来设计最佳策略。传统的基于规则的模型不支持此能力，因为它们是为模拟现实世界场景而设计的。经验性的城市隔离问题是一个广泛讨论的议题，对社会动态和经济有重大影响。它源于住宅区的人口差异以及城市居民的流动模式[[15](https://arxiv.org/html/2410.21286v1#bib.bib15)]。
- en: 'This section provides a case study: a counterfactual simulation is conducted
    in New York and San Francisco, to observe how the simulation results change in
    different configurations, and try to summarize the results with the LLM agents
    themselves.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了一个案例研究：在纽约和旧金山进行反事实仿真，以观察不同配置下仿真结果的变化，并尝试总结LLM代理本身的结果。
- en: 'Specifically, we construct the counterfactual scenario by evenly distributing
    LLM agents with different income levels across the city, that means we almost
    eliminate the residential segregation. The results of the income segregation statistics
    with CBGs as the statistical granularity are shown in Fig.[4](https://arxiv.org/html/2410.21286v1#S6.F4
    "Figure 4 ‣ 6 Case Study: Experienced Urban Segregation ‣ OpenCity: A Scalable
    Platform to Simulate Urban Activities with Massive LLM Agents"), where ‘Original’
    samples the segregation results from the real census data, and ‘Even’ is the result
    after uniform distribution of agents with different incomes.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '具体而言，我们通过将不同收入水平的LLM代理均匀分布到整个城市来构建反事实场景，这意味着我们几乎消除了住宅隔离。以CBG为统计单位的收入隔离统计结果如图[4](https://arxiv.org/html/2410.21286v1#S6.F4
    "图 4 ‣ 6 案例研究：经验性城市隔离 ‣ OpenCity: 一种可扩展的模拟大规模LLM代理城市活动的平台")所示，其中“Original”代表来自真实人口普查数据的隔离结果，而“Even”则是不同收入代理均匀分布后的结果。'
- en: '![Refer to caption](img/9ec05c85dfff1fba19bcc2babb9fa726.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/9ec05c85dfff1fba19bcc2babb9fa726.png)'
- en: 'Figure 4: The distribution of income segregation index for counterfactual experiment.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：反事实实验的收入隔离指数分布。
- en: From the results, it can be seen that the segregation of the two cities changed
    significantly after the different income groups were evenly distributed in the
    cities. In New York City, the mean segregation index decreases from 0.845 to 0.172,
    and in San Francisco, the mean segregation index decreases from 0.665 to 0.232.
    As a result, we believe that differences between regions are the main cause of
    segregation as opposed to segregation by choice of action. To extend, we can know
    that with policies that promote more even income distribution among neighborhoods,
    urban segregation and social inequality can be improved.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果可以看出，当不同收入群体在城市中均匀分布后，两座城市的隔离情况发生了显著变化。在纽约市，平均隔离指数从0.845降至0.172，而在旧金山，平均隔离指数从0.665降至0.232。因此，我们认为区域间的差异是导致隔离的主要原因，而不是由选择行为造成的隔离。进一步推论，我们可以知道，通过推动邻里间收入更均衡分配的政策，城市隔离和社会不平等可以得到改善。
- en: '![Refer to caption](img/943566dcb9fd995dfb2229f55441a824.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/943566dcb9fd995dfb2229f55441a824.png)'
- en: 'Figure 5: A detail case of interpreting simulation results through communication.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：通过沟通解释仿真结果的详细案例。
- en: 'Furthermore, we use natural language to communicate with those involved agents
    to gain deeper insights about urban segregation. One detailed case is shown in
    Fig.[5](https://arxiv.org/html/2410.21286v1#S6.F5 "Figure 5 ‣ 6 Case Study: Experienced
    Urban Segregation ‣ OpenCity: A Scalable Platform to Simulate Urban Activities
    with Massive LLM Agents"). When we ask an agent about its daily journey, it can
    accurately provide the time and locations it visited. This is because the agent
    caches runtime information and uses the LLM’s ability to understand semantic details.
    When asked about the people it met, the agent lists everyone it encountered at
    different locations and provides their information. This is due to vectorized
    storage of the agent’s simulation results and the LLM’s ability to retrieve that
    information. Collecting and observing fine-grained statistical information through
    conversations with agents and even through LLM improves both the interpretability
    of the simulation and our understanding of the simulation goals.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，我们使用自然语言与这些涉及的代理进行沟通，以深入了解城市隔离的情况。图[5](https://arxiv.org/html/2410.21286v1#S6.F5
    "图 5 ‣ 6 案例研究：经验性城市隔离 ‣ OpenCity: 一种可扩展的模拟大规模LLM代理城市活动的平台")展示了一个详细案例。当我们询问一个代理它的日常行程时，它可以准确提供它所访问的时间和地点。这是因为该代理缓存了运行时信息，并利用LLM的语义理解能力。当问及它遇到的人时，代理列出了它在不同地点遇到的所有人，并提供了他们的信息。这是因为代理的仿真结果经过向量化存储，LLM能够检索这些信息。通过与代理的对话，甚至通过LLM收集和观察精细的统计信息，提升了仿真结果的可解释性和我们对仿真目标的理解。'
- en: 7 Conclusion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: In this work, we introduced OpenCity, a scalable platform designed to address
    the computational and communication challenges inherent to the deployment of large-scale
    LLM-based urban agents in city simulations. By incorporating an LLM request scheduler
    and a novel "group-and-distill" prompt optimization strategy, we achieved a notable
    600-fold increase in the efficiency of agent simulations, with a substantial reduction
    in both LLM requests and token usage. The OpenCity platform was evaluated through
    experiments conducted on six global cities. The results demonstrated the platform’s
    capability to simulate the daily activities of 10,000 agents at an hourly level,
    while also establishing a benchmark for generative agent performance in urban
    contexts. The platform’s ability to compare simulated behaviors with real-world
    data highlights its potential for real-world urban-scale applications, offering
    a robust tool for urban planners and researchers to explore and understand complex
    societal phenomena.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我们介绍了OpenCity，一个可扩展的平台，旨在解决大规模基于LLM的城市智能体在城市模拟中部署所固有的计算和通信挑战。通过结合LLM请求调度器和一种新颖的“分组与蒸馏”提示优化策略，我们实现了智能体模拟效率的600倍提升，同时大幅减少了LLM请求和令牌使用。通过在六个全球城市进行实验评估，OpenCity平台展示了其模拟10,000个智能体日常活动的能力，且能够在每小时级别进行模拟，同时为城市背景下的生成智能体性能建立了基准。该平台能够将模拟行为与真实世界数据进行比较，凸显了其在现实世界城市规模应用中的潜力，为城市规划者和研究人员提供了一个强大的工具，用于探索和理解复杂的社会现象。
- en: References
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Thomas C Schelling. Micromotives and macrobehavior. WW Norton & Company,
    2006.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Thomas C Schelling. 《微观动机与宏观行为》。WW Norton & Company，2006年。'
- en: '[2] Fengli Xu, Yong Li, Depeng Jin, Jianhua Lu, and Chaoming Song. Emergence
    of urban growth patterns from human mobility behavior. Nature Computational Science,
    1(12):791–800, 2021.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Fengli Xu, Yong Li, Depeng Jin, Jianhua Lu, 和 Chaoming Song. 人类移动行为中城市增长模式的出现。自然计算科学，1(12)：791–800，2021年。'
- en: '[3] Lin Chen, Fengli Xu, Zhenyu Han, Kun Tang, Pan Hui, James Evans, and Yong
    Li. Strategic covid-19 vaccine distribution can simultaneously elevate social
    utility and equity. Nature Human Behaviour, 6(11):1503–1514, 2022.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Lin Chen, Fengli Xu, Zhenyu Han, Kun Tang, Pan Hui, James Evans, 和 Yong
    Li. 战略性的新冠疫苗分发可以同时提高社会效用和公平性。自然人类行为，6(11)：1503–1514，2022年。'
- en: '[4] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris,
    Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra
    of human behavior. In Proceedings of the 36th annual acm symposium on user interface
    software and technology, pages 1–22, 2023.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris,
    Percy Liang, 和 Michael S Bernstein. 生成智能体：人类行为的交互式模拟。发表于第36届年度ACM用户界面软件与技术研讨会论文集，第1–22页，2023年。'
- en: '[5] Fengli Xu, Jun Zhang, Chen Gao, Jie Feng, and Yong Li. Urban generative
    intelligence (ugi): A foundational platform for agents in embodied city environment.
    arXiv preprint arXiv:2312.11813, 2023.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Fengli Xu, Jun Zhang, Chen Gao, Jie Feng, 和 Yong Li. 城市生成智能（UGI）：为体现城市环境中的智能体提供的基础平台。arXiv预印本arXiv:2312.11813，2023年。'
- en: '[6] Chenyang Shao, Fengli Xu, Bingbing Fan, Jingtao Ding, Yuan Yuan, Meng Wang,
    and Yong Li. Beyond imitation: Generating human mobility from context-aware reasoning
    with large language models. arXiv preprint arXiv:2402.09836, 2024.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Chenyang Shao, Fengli Xu, Bingbing Fan, Jingtao Ding, Yuan Yuan, Meng Wang,
    和 Yong Li. 超越模仿：通过大语言模型的上下文感知推理生成人类移动行为。arXiv预印本arXiv:2402.09836，2024年。'
- en: '[7] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in
    large language models. Advances in neural information processing systems, 35:24824–24837,
    2022.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,
    Quoc V Le, Denny Zhou，等。链式思维提示引发大语言模型中的推理。神经信息处理系统进展，35：24824–24837，2022年。'
- en: '[8] Qingbin Zeng, Qinglong Yang, Shunan Dong, Heming Du, Liang Zheng, Fengli
    Xu, and Yong Li. Perceive, reflect, and plan: Designing llm agent for goal-directed
    city navigation without instructions. arXiv preprint arXiv:2408.04168, 2024.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Qingbin Zeng, Qinglong Yang, Shunan Dong, Heming Du, Liang Zheng, Fengli
    Xu, 和 Yong Li. 感知、反思与规划：为无指令的目标导向城市导航设计LLM智能体。arXiv预印本arXiv:2408.04168，2024年。'
- en: '[9] Ayush Chopra, Shashank Kumar, Nurullah Giray-Kuru, Ramesh Raskar, and Arnau
    Quera-Bofarull. On the limits of agency in agent-based models. arXiv preprint
    arXiv:2409.10568, 2024.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Ayush Chopra, Shashank Kumar, Nurullah Giray-Kuru, Ramesh Raskar, 和 Arnau
    Quera-Bofarull. 智能体模型的能力极限。arXiv预印本arXiv:2409.10568，2024年。'
- en: '[10] Francesc Bruguera i Moriscot. Benchmarking input/output multiplexing facilities
    of the linux kernel. 2019.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Francesc Bruguera i Moriscot. Linux内核输入/输出复用设施基准测试. 2019.'
- en: '[11] Larry L Peterson and Bruce S Davie. Computer networks: a systems approach.
    Morgan Kaufmann, 2007.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Larry L Peterson 和 Bruce S Davie. 《计算机网络：一种系统方法》. Morgan Kaufmann, 2007.'
- en: '[12] Zhoujun Cheng, Jungo Kasai, and Tao Yu. Batch prompting: Efficient inference
    with large language model apis. arXiv preprint arXiv:2301.08721, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Zhoujun Cheng, Jungo Kasai, 和 Tao Yu. 批量提示：使用大型语言模型API进行高效推理. arXiv预印本
    arXiv:2301.08721, 2023.'
- en: '[13] Marta C Gonzalez, Cesar A Hidalgo, and Albert-Laszlo Barabasi. Understanding
    individual human mobility patterns. nature, 453(7196):779–782, 2008.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Marta C Gonzalez, Cesar A Hidalgo, 和 Albert-Laszlo Barabasi. 理解个体人类移动模式.
    《自然》, 453(7196):779–782, 2008.'
- en: '[14] Shan Jiang, Yingxiang Yang, Siddharth Gupta, Daniele Veneziano, Shounak
    Athavale, and Marta C González. The timegeo modeling framework for urban mobility
    without travel surveys. Proceedings of the National Academy of Sciences, 113(37):E5370–E5378,
    2016.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Shan Jiang, Yingxiang Yang, Siddharth Gupta, Daniele Veneziano, Shounak
    Athavale, 和 Marta C González. 基于时间地理建模框架的城市移动性，无需旅行调查. 《美国国家科学院院刊》, 113(37):E5370–E5378,
    2016.'
- en: '[15] Esteban Moro, Dan Calacci, Xiaowen Dong, and Alex Pentland. Mobility patterns
    are associated with experienced income segregation in large us cities. Nature
    communications, 12(1):4633, 2021.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Esteban Moro, Dan Calacci, Xiaowen Dong, 和 Alex Pentland. 移动模式与美国大城市中的收入隔离经验相关.
    《自然通讯》, 12(1):4633, 2021.'
- en: '[16] Chaoming Song, Tal Koren, Pu Wang, and Albert-László Barabási. Modelling
    the scaling properties of human mobility. Nature physics, 6(10):818–823, 2010.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Chaoming Song, Tal Koren, Pu Wang, 和 Albert-László Barabási. 人类移动性的尺度特性建模.
    《自然物理学》, 6(10):818–823, 2010.'
- en: '[17] Douglas S Massey and Nancy A Denton. The dimensions of residential segregation.
    Social forces, 67(2):281–315, 1988.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Douglas S Massey 和 Nancy A Denton. 《住宅隔离的维度》. 《社会力量》, 67(2):281–315, 1988.'
- en: '[18] Significant Gravitas. Autogpt. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT),
    2023. Accessed: 2024-09-01.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Significant Gravitas. AutoGPT. [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT),
    2023. 访问时间：2024-09-01.'
- en: '[19] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,
    Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language
    model based autonomous agents. Frontiers of Computer Science, 18(6):186345, 2024.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,
    Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, 等. 基于大型语言模型的自主代理调查. 《计算机科学前沿》,
    18(6):186345, 2024.'
- en: '[20] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming
    Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large
    language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming
    Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, 等. 基于大型语言模型的代理崛起与潜力：一项调查. arXiv预印本
    arXiv:2309.07864, 2023.'
- en: '[21] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint
    arXiv:2307.07924, 6, 2023.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
    Liu, 和 Maosong Sun. 软件开发的沟通代理. arXiv预印本 arXiv:2307.07924, 6, 2023.'
- en: '[22] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao,
    Karthik Narasimhan, and Ofir Press. Swe-agent: Agent-computer interfaces enable
    automated software engineering. arXiv preprint arXiv:2405.15793, 2024.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao,
    Karthik Narasimhan, 和 Ofir Press. Swe-agent：代理计算机界面实现自动化软件工程. arXiv预印本 arXiv:2405.15793,
    2024.'
- en: '[23] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt:
    Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352,
    2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao
    Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, 等. MetaGPT：多智能体协作框架的元编程.
    arXiv预印本 arXiv:2308.00352, 2023.'
- en: '[24] Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong
    Wang, Depeng Jin, and Yong Li. S3: Social-network simulation system with large
    language model-empowered agents. arXiv preprint arXiv:2307.14984, 2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong
    Wang, Depeng Jin, 和 Yong Li. S3：基于大型语言模型赋能代理的社交网络仿真系统. arXiv预印本 arXiv:2307.14984,
    2023.'
- en: '[25] Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao,
    and Ji-Rong Wen. Recagent: A novel simulation paradigm for recommender systems.
    arXiv preprint arXiv:2306.02552, 2023.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao,
    和 Ji-Rong Wen. RecAgent：一种用于推荐系统的新型仿真范式. arXiv预印本 arXiv:2306.02552, 2023.'
- en: '[26] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin,
    Tianqi Chen, and Zhihao Jia. Towards efficient generative large language model
    serving: A survey from algorithms to systems. arXiv preprint arXiv:2312.15234,
    2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin,
    Tianqi Chen, 和 Zhihao Jia. 朝向高效生成型大语言模型服务：从算法到系统的综述. arXiv 预印本 arXiv:2312.15234，2023年。'
- en: '[27] Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. Flashattention:
    Fast and memory-efficient exact attention with io-awareness. Advances in Neural
    Information Processing Systems, 35:16344–16359, 2022.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, 和 Christopher Ré. FlashAttention：一种快速且内存高效的精确注意力机制，具备
    IO 感知能力. 《神经信息处理系统进展》，35:16344–16359，2022年。'
- en: '[28] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen, Wei-Chen
    Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, and Song Han. Awq: Activation-aware
    weight quantization for on-device llm compression and acceleration. Proceedings
    of Machine Learning and Systems, 6:87–100, 2024.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen, Wei-Chen
    Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, 和 Song Han. Awq：一种激活感知的权重量化方法，用于设备端的
    LLM 压缩与加速. 载于《机器学习与系统会议论文集》，6:87–100，2024年。'
- en: '[29] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao
    Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for
    large language model serving with pagedattention. In Proceedings of the 29th Symposium
    on Operating Systems Principles, pages 611–626, 2023.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody
    Hao Yu, Joseph Gonzalez, Hao Zhang, 和 Ion Stoica. 通过分页注意力机制优化大语言模型服务的高效内存管理. 载于《第29届操作系统原理研讨会论文集》，第611-626页，2023年。'
- en: '[30] Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Jeff Huang, Chuyue Sun, Cody Hao
    Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E Gonzalez, et al. Efficiently
    programming large language models using sglang. arXiv preprint arXiv:2312.07104,
    2023.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Jeff Huang, Chuyue Sun, Cody
    Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E Gonzalez 等. 使用 SGLang
    高效编程大语言模型. arXiv 预印本 arXiv:2312.07104，2023年。'
- en: '[31] Yu Shang, Yu Li, Fengli Xu, and Yong Li. Defint: A default-interventionist
    framework for efficient reasoning with hybrid large language models. arXiv preprint
    arXiv:2402.02563, 2024.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Yu Shang, Yu Li, Fengli Xu, 和 Yong Li. Defint：一个默认干预框架，用于高效推理与混合大语言模型.
    arXiv 预印本 arXiv:2402.02563，2024年。'
- en: '[32] Keivalya Pandya and Mehfuza Holia. Automating customer service using langchain:
    Building custom open-source gpt chatbot for organizations. arXiv preprint arXiv:2310.05421,
    2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Keivalya Pandya 和 Mehfuza Holia. 使用 LangChain 自动化客户服务：为组织构建自定义开源 GPT 聊天机器人.
    arXiv 预印本 arXiv:2310.05421，2023年。'
- en: '[33] Hui Yang, Sifu Yue, and Yunzhong He. Auto-gpt for online decision making:
    Benchmarks and additional opinions. arXiv preprint arXiv:2306.02224, 2023.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Hui Yang, Sifu Yue, 和 Yunzhong He. Auto-GPT 在在线决策中的应用：基准测试和额外意见. arXiv
    预印本 arXiv:2306.02224，2023年。'
- en: Appendix A Urban Mobility Dataset
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 城市流动性数据集
- en: 'As shown in Table [A1](https://arxiv.org/html/2410.21286v1#A1.T1 "Table A1
    ‣ Appendix A Urban Mobility Dataset ‣ OpenCity: A Scalable Platform to Simulate
    Urban Activities with Massive LLM Agents"), we collect urban mobility data of
    6 major cities around the world. The data sources vary. In Beijing, the data is
    from a related work [[6](https://arxiv.org/html/2410.21286v1#bib.bib6)], which
    gathered through a social network platform and tracking users’ mobility trajectories.
    Additionally, users’ profiles, such as income level, gender, occupation, education
    level and age, are collected through digital surveys. In New York and San Francisco,
    the data comes from Safegraph, which provides aggregated population flow among
    Points of Interest(POIs) and Census Block Groups(CBGs). The other three cities—London,
    Paris and Sydney—use data are from Foursquare. Foursquare data consist of thousands
    of check-ins data of users and the corresponding venue position.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 [A1](https://arxiv.org/html/2410.21286v1#A1.T1 "表A1 ‣ 附录A 城市流动性数据集 ‣ OpenCity：一个可扩展的平台，用于通过海量LLM代理模拟城市活动")
    所示，我们收集了来自全球6个主要城市的城市流动性数据。数据来源各不相同。在北京，数据来自相关研究[[6](https://arxiv.org/html/2410.21286v1#bib.bib6)]，通过社交网络平台收集，跟踪用户的流动轨迹。此外，用户的个人资料，如收入水平、性别、职业、教育水平和年龄，通过数字化调查收集。在纽约和旧金山，数据来自
    Safegraph，该公司提供聚合的兴趣点（POIs）和人口普查区块组（CBGs）之间的流动数据。其他三个城市——伦敦、巴黎和悉尼——的数据来自 Foursquare。Foursquare
    数据包含用户的成千上万次签到记录及其对应的场所位置。
- en: To make better use of the datasets, we apply several preprocessing methods.
    We firstly arrange the trajectory points in time sequence, and divide the trajectory
    into units of one day. Then we filter out trajectories with fewer than 4 points
    in a day, as they do not fully capture users’ mobility patterns. For home extraction,
    we identify the most frequently visited location of the useres the home. Since
    only the Tencent dataset includes user profiles, we make profile sampling for
    users of each city based on local census data for the other two datasets. In the
    end, our dataset is optimized for easy use in urban mobility simulations.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地利用这些数据集，我们应用了几种预处理方法。首先，我们按时间顺序排列轨迹点，并将轨迹划分为一天为单位。然后，我们筛选出每天轨迹点少于4个的轨迹，因为这些轨迹不能充分捕捉到用户的移动模式。对于家庭位置提取，我们识别出用户最常访问的位置作为其家庭地址。由于只有腾讯数据集包含用户档案信息，因此对于其他两个数据集，我们基于本地普查数据对每个城市的用户进行档案采样。最终，我们的数据集经过优化，方便用于城市出行模拟。
- en: '| Source | City | Users | Trajectory Points | Duration |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 来源 | 城市 | 用户数 | 轨迹点 | 时长 |'
- en: '| [[6](https://arxiv.org/html/2410.21286v1#bib.bib6)] | Beijing | 100000 |
    297363263 | Oct. 2019 - Dec. 2019 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| [[6](https://arxiv.org/html/2410.21286v1#bib.bib6)] | 北京 | 100000 | 297363263
    | 2019年10月 - 2019年12月 |'
- en: '| Safegraph | New york | Aggregated | 760493 | May 2023 - July 2023 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Safegraph | 纽约 | 聚合 | 760493 | 2023年5月 - 2023年7月 |'
- en: '| San Francisco | Aggregated | 316732 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 旧金山 | 聚合 | 316732 |'
- en: '| Foursquare | London | 9409 | 173268 | Apr. 2012 - Sept. 2013 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Foursquare | 伦敦 | 9409 | 173268 | 2012年4月 - 2013年9月 |'
- en: '| Paris | 5809 | 85679 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 巴黎 | 5809 | 85679 |'
- en: '| Sydney | 1720 | 54170 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 悉尼 | 1720 | 54170 |'
- en: 'Table A1: Basic information about the dataset'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 表A1：数据集基本信息
- en: Appendix B Urban dynamic metrics
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 城市动态指标
- en: We use comprehensive metrics in three-levels to evaluate the simulation performance,
    from individual-level to group level, and also from physical domain to social
    domain. These metrics allows us to gain a full understanding of mobility patterns
    and their implications, and can also help us evaluate the performance of the simulation
    by analysing the generated trajectory.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用三个层次的综合指标来评估模拟性能，从个体层面到群体层面，以及从物理领域到社会领域。这些指标使我们能够全面了解出行模式及其影响，同时也能通过分析生成的轨迹来帮助我们评估模拟的表现。
- en: 'At the individual level, we calculate radius of gyration $r_{g}$ [[13](https://arxiv.org/html/2410.21286v1#bib.bib13)]
    for each user, which is a measure of the spatial extent of their movements. The
    radius of gyration is defined as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在个体层面，我们计算每个用户的回转半径$r_{g}$[[13](https://arxiv.org/html/2410.21286v1#bib.bib13)]，这是衡量其运动空间范围的一个指标。回转半径定义如下：
- en: '|  | $r_{g}^{\alpha}=\sqrt{\frac{1}{N^{\alpha}}\sum_{i=1}^{N^{\alpha}}{(\vec{r}_{i}^%
    {\alpha}-\vec{r}_{cm}^{\alpha})^{2}}}$ |  | (3) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | $r_{g}^{\alpha}=\sqrt{\frac{1}{N^{\alpha}}\sum_{i=1}^{N^{\alpha}}{(\vec{r}_{i}^{\alpha}-\vec{r}_{cm}^{\alpha})^{2}}}$
    |  | (3) |'
- en: where $\vec{r}_{i}^{\alpha}$ represents the $i=1,2,...,N$ positions recorded
    by user $\alpha$, and $r_{cm}^{\alpha}=1/{N^{\alpha}}\sum_{i=1}^{N^{\alpha}}{(\vec{r}_{i}^{\alpha})}$
    is the center of mass of the trajectory. The radius of gyration provides an indication
    of the size of a user’s activity range. To assess the accuracy of our simulation
    data against real-world data for a specific user, we calculate $R_{MSE}$, the
    Mean Squared Error(MSE) of the radius of gyration.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\vec{r}_{i}^{\alpha}$表示用户$\alpha$记录的第$i=1,2,...,N$个位置，$r_{cm}^{\alpha}=1/{N^{\alpha}}\sum_{i=1}^{N^{\alpha}}{(\vec{r}_{i}^{\alpha})}$是轨迹的质心。回转半径提供了用户活动范围大小的指示。为了评估我们模拟数据与现实世界数据在特定用户上的准确性，我们计算$R_{MSE}$，即回转半径的均方误差（MSE）。
- en: To analyze movement patterns and other aggregated features, we define block
    areas as spatial units within the city. For cities with Safegraph data, we use
    existing Census Block Group (CBG) areas. For other cities, we divide the map area
    into evenly spaced grids, with each grid cell representing a block area.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析运动模式和其他聚合特征，我们将城市中的区域定义为空间单元。对于拥有Safegraph数据的城市，我们使用现有的普查街区组（CBG）区域。对于其他城市，我们将地图区域划分为均匀的网格，每个网格单元表示一个街区区域。
- en: At the group level, we count the inflow and outflow of agents between block
    areas, calculate the Origin-Destination (OD) matrix [[14](https://arxiv.org/html/2410.21286v1#bib.bib14)],
    and normalize it. To compare real data with simulation data, we calculate the
    MSE of the normalized OD matrix, denoted as $OD_{MSE}$. A smaller $OD_{MSE}$ value
    indicates greater similarity between the OD matrices, meaning the movement characteristics
    of the simulated data closely match the real data.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在小组层面，我们统计不同区域之间的代理流入流出，计算起点-终点（OD）矩阵[[14](https://arxiv.org/html/2410.21286v1#bib.bib14)]，并进行归一化处理。为了将实际数据与模拟数据进行比较，我们计算归一化
    OD 矩阵的均方误差（MSE），记作 $OD_{MSE}$。较小的 $OD_{MSE}$ 值表明 OD 矩阵之间的相似性更大，意味着模拟数据的移动特征与实际数据非常接近。
- en: At the social domain, we calculate the income segregation index [[15](https://arxiv.org/html/2410.21286v1#bib.bib15)]
    for each block area. The income segregation of a place $\alpha$ is defined as
    $S_{\alpha}=\frac{5}{8}\sum_{q}{|\tau_{q\alpha}-\frac{1}{5}|}$, where $\tau_{q\alpha}$
    is is the proportion of visitors in each income quintile for place $\alpha$. The
    $S_{\alpha}$ ranges from 0 to 1\. A high $S_{\alpha}$ indicates that the place
    $\alpha$ is predominantly visited by a single income group, suggesting a high
    level of income segregation. We denote $S_{MSE}$ as the MSE between the real data
    and simulation data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在社会领域，我们计算每个区域的收入隔离指数[[15](https://arxiv.org/html/2410.21286v1#bib.bib15)]。某地
    $\alpha$ 的收入隔离定义为 $S_{\alpha}=\frac{5}{8}\sum_{q}{|\tau_{q\alpha}-\frac{1}{5}|}$，其中
    $\tau_{q\alpha}$ 是该地 $\alpha$ 中每个收入五分位数的访客比例。$S_{\alpha}$ 的值范围是 0 到 1。较高的 $S_{\alpha}$
    值表示该地区主要被单一收入群体访问，表明收入隔离程度较高。我们用 $S_{MSE}$ 表示实际数据与模拟数据之间的 MSE。
- en: Appendix C Image supplements
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 图像补充
- en: '![Refer to caption](img/0701cc837f41599df0866f2a465512cd.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0701cc837f41599df0866f2a465512cd.png)'
- en: 'Figure A1: Distill meta-prompt generation through CoT inference.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A1：通过 CoT 推理提炼元提示生成。
- en: '![Refer to caption](img/9e819ebe83b22380a7edb67c8f5b4148.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9e819ebe83b22380a7edb67c8f5b4148.png)'
- en: (a) Agent Construction
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 代理构建
- en: '![Refer to caption](img/495a4baeaed67b5a0566d203e575cf95.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/495a4baeaed67b5a0566d203e575cf95.png)'
- en: (b) Profile Configuration
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 配置文件设置
- en: '![Refer to caption](img/b4c526b41a78c86dbd59bf1fc9ff1a2c.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/b4c526b41a78c86dbd59bf1fc9ff1a2c.png)'
- en: (c) Simulation Visualization
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 模拟可视化
- en: '![Refer to caption](img/0ad9b6a7b4f5ac639964c24f7be0a71c.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/0ad9b6a7b4f5ac639964c24f7be0a71c.png)'
- en: (d) Result Visualization
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 结果可视化
- en: 'Figure A2: Overview of OpenCity web portal.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A2：OpenCity 网络门户概览。
