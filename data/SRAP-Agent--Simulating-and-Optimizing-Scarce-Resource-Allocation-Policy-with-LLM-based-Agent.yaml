- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:04:23'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:04:23
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SRAP-Agent：基于LLM的代理模拟与优化稀缺资源分配政策
- en: 来源：[https://arxiv.org/html/2410.14152/](https://arxiv.org/html/2410.14152/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2410.14152/](https://arxiv.org/html/2410.14152/)
- en: Jiarui Ji¹,Yang Li¹, Hongtao Liu¹, Zhicheng Du¹,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Jiarui Ji¹，Yang Li¹，Hongtao Liu¹，Zhicheng Du¹，
- en: Zhewei Wei^(1,2), Weiran Shen^(1,2), Qi Qi^(1,2), Yankai Lin^(1,2)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Zhewei Wei^(1,2)，Weiran Shen^(1,2)，Qi Qi^(1,2)，Yankai Lin^(1,2)
- en: ¹Gaoling School of Artificial Intelligence, Renmin University of China, Beijing,
    China
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹中国人民大学高岭人工智能学院，北京，中国
- en: ²Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing,
    China  Corresponding Author.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²北京市大数据管理与分析方法重点实验室，北京，中国  对应作者。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Public scarce resource allocation plays a crucial role in economics as it directly
    influences the efficiency and equity in society. Traditional studies including
    theoretical model-based, empirical study-based and simulation-based methods encounter
    limitations due to the idealized assumption of complete information and individual
    rationality, as well as constraints posed by limited available data. In this work,
    we propose an innovative framework, SRAP-Agent (Simulating and Optimizing Scarce
    Resource Allocation Policy with LLM-based Agent), which integrates Large Language
    Models (LLMs) into economic simulations, aiming to bridge the gap between theoretical
    models and real-world dynamics. Using public housing allocation scenarios as a
    case study, we conduct extensive policy simulation experiments to verify the feasibility
    and effectiveness of the SRAP-Agent and employ the Policy Optimization Algorithm
    with certain optimization objectives. The source code can be found in [https://github.com/jijiarui-cather/SRAPAgent_Framework](https://github.com/jijiarui-cather/SRAPAgent_Framework).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 公共稀缺资源分配在经济学中起着至关重要的作用，因为它直接影响着社会的效率与公平。传统研究包括基于理论模型、经验研究和仿真研究的方法，因完全信息和个体理性假设的理想化，以及有限可用数据的限制，面临着局限性。在本研究中，我们提出了一种创新框架，SRAP-Agent（基于LLM的代理模拟与优化稀缺资源分配政策），将大语言模型（LLMs）集成到经济仿真中，旨在弥合理论模型与现实世界动态之间的差距。以公共住房分配场景为案例，我们开展了广泛的政策仿真实验，以验证SRAP-Agent的可行性和有效性，并采用具有特定优化目标的政策优化算法。源代码可以在[https://github.com/jijiarui-cather/SRAPAgent_Framework](https://github.com/jijiarui-cather/SRAPAgent_Framework)找到。
- en: 'SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: SRAP-Agent：基于LLM的代理模拟与优化稀缺资源分配政策
- en: 'Jiarui Ji¹,Yang Li¹, Hongtao Liu¹, Zhicheng Du¹, Zhewei Wei^(1,2), Weiran Shen^(1,2),
    Qi Qi^(1,2), Yankai Lin^(1,2)^†^†thanks:  Corresponding Author. ¹Gaoling School
    of Artificial Intelligence, Renmin University of China, Beijing, China ²Beijing
    Key Laboratory of Big Data Management and Analysis Methods, Beijing, China'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Jiarui Ji¹，Yang Li¹，Hongtao Liu¹，Zhicheng Du¹，Zhewei Wei^(1,2)，Weiran Shen^(1,2)，Qi
    Qi^(1,2)，Yankai Lin^(1,2)^†^†致谢：对应作者。 ¹中国人民大学高岭人工智能学院，北京，中国 ²北京市大数据管理与分析方法重点实验室，北京，中国
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: '![Refer to caption](img/dfdf4603fc58cae4886468ae127ce607.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/dfdf4603fc58cae4886468ae127ce607.png)'
- en: 'Figure 1: An illustration of the SRAP-Agent framework. The horn symbolizes
    the broadcasting process of policy information to participants.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：SRAP-Agent框架的示意图。号角象征着将政策信息广播给参与者的过程。
- en: 'Economics (Mankiw, [2011](https://arxiv.org/html/2410.14152v1#bib.bib32)) delves
    into how to limit scarce resources to meet unlimited needs. A critical aspect
    of this field is the allocation of public scarce goods (Jr et al., [1977](https://arxiv.org/html/2410.14152v1#bib.bib24);
    Groves and Ledyard, [1974](https://arxiv.org/html/2410.14152v1#bib.bib17); BROCK,
    [1980](https://arxiv.org/html/2410.14152v1#bib.bib9)), focusing on utilizing limited
    resources to improve economic efficiency and social welfare  (Blümel et al., [1986](https://arxiv.org/html/2410.14152v1#bib.bib7)).
    In the field of research on the allocation of public scarce resources, existing
    work can be primarily categorized into three main approaches: (1) theoretical
    model-based methods (Hylland and Zeckhauser, [1979](https://arxiv.org/html/2410.14152v1#bib.bib20);
    Su and Zenios, [2004](https://arxiv.org/html/2410.14152v1#bib.bib45), [2005](https://arxiv.org/html/2410.14152v1#bib.bib46);
    Chen et al., [2018](https://arxiv.org/html/2410.14152v1#bib.bib11)), which utilizes
    economic theories to develop models that can predict how resources should be allocated
    efficiently; (2) empirical study-based methods (Banerjee and Somanathan, [2007](https://arxiv.org/html/2410.14152v1#bib.bib4);
    Nold, [1992](https://arxiv.org/html/2410.14152v1#bib.bib35); Falkinger et al.,
    [2000](https://arxiv.org/html/2410.14152v1#bib.bib14)), which analyze real-world
    data to uncover patterns, correlations, and the effects of various policies; (3)
    computational simulation-based methods (Holland and Miller, [1991](https://arxiv.org/html/2410.14152v1#bib.bib18);
    Zheng et al., [2022](https://arxiv.org/html/2410.14152v1#bib.bib56)), which emulate
    economic environments to test economic hypotheses within simulated settings. However,
    empirical study-based methods often face challenges of data scarcity, establishing
    causality, and isolating variables in complex social systems. Meanwhile, theoretical
    model-based methods and computational simulation-based methods often rely on simplified
    assumptions, overlooking the complex interplay of rational and social behaviors
    in human decision-making.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 经济学（曼昆，[2011](https://arxiv.org/html/2410.14152v1#bib.bib32)）探讨如何在有限资源的约束下满足无限需求。该领域的一个关键方面是公共稀缺资源的分配（Jr等，[1977](https://arxiv.org/html/2410.14152v1#bib.bib24)；Groves和Ledyard，[1974](https://arxiv.org/html/2410.14152v1#bib.bib17)；BROCK，[1980](https://arxiv.org/html/2410.14152v1#bib.bib9)），重点是利用有限的资源来提高经济效率和社会福利（Blümel等，[1986](https://arxiv.org/html/2410.14152v1#bib.bib7)）。在公共稀缺资源分配的研究领域，现有的工作主要可以分为三种主要方法：（1）基于理论模型的方法（Hylland和Zeckhauser，[1979](https://arxiv.org/html/2410.14152v1#bib.bib20)；Su和Zenios，[2004](https://arxiv.org/html/2410.14152v1#bib.bib45)，[2005](https://arxiv.org/html/2410.14152v1#bib.bib46)；Chen等，[2018](https://arxiv.org/html/2410.14152v1#bib.bib11)），利用经济学理论发展模型，以预测如何有效分配资源；（2）基于实证研究的方法（Banerjee和Somanathan，[2007](https://arxiv.org/html/2410.14152v1#bib.bib4)；Nold，[1992](https://arxiv.org/html/2410.14152v1#bib.bib35)；Falkinger等，[2000](https://arxiv.org/html/2410.14152v1#bib.bib14)），分析真实世界的数据，揭示模式、关联性和各种政策的影响；（3）基于计算模拟的方法（Holland和Miller，[1991](https://arxiv.org/html/2410.14152v1#bib.bib18)；Zheng等，[2022](https://arxiv.org/html/2410.14152v1#bib.bib56)），模拟经济环境，在模拟环境中测试经济假设。然而，基于实证研究的方法通常面临数据匮乏、因果关系建立以及在复杂社会系统中孤立变量的挑战。与此同时，基于理论模型的方法和基于计算模拟的方法通常依赖于简化假设，忽略了理性和社会行为在人类决策中的复杂交互作用。
- en: Fortunately, the emergence of LLMs such as ChatGPT and GPT-4 (Anil et al., [2023](https://arxiv.org/html/2410.14152v1#bib.bib3);
    Touvron et al., [2023](https://arxiv.org/html/2410.14152v1#bib.bib47); Brown et al.,
    [2020](https://arxiv.org/html/2410.14152v1#bib.bib10); OpenAI, [2023](https://arxiv.org/html/2410.14152v1#bib.bib36)),
    has introduced a new potential in economic simulations. Acclaimed for their ability
    to mimic human-like behaviors (Li et al., [2023a](https://arxiv.org/html/2410.14152v1#bib.bib30);
    Park et al., [2022](https://arxiv.org/html/2410.14152v1#bib.bib38), [2023](https://arxiv.org/html/2410.14152v1#bib.bib37)),
    LLMs demonstrate the potential to encapsulate the logic and patterns inherent
    in human cognition by pre-training on extensive web data (OpenAI, [2023](https://arxiv.org/html/2410.14152v1#bib.bib36)).
    This breakthrough facilitates the incorporation of social consensus mechanisms
    into economic simulations, offering a comprehensive framework for evaluating the
    impact of resource allocation policies on both economic efficiency and social
    welfare.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，ChatGPT和GPT-4等LLM的出现（Anil et al., [2023](https://arxiv.org/html/2410.14152v1#bib.bib3);
    Touvron et al., [2023](https://arxiv.org/html/2410.14152v1#bib.bib47); Brown et
    al., [2020](https://arxiv.org/html/2410.14152v1#bib.bib10); OpenAI, [2023](https://arxiv.org/html/2410.14152v1#bib.bib36)）为经济仿真引入了新的潜力。LLM因其能够模仿类人行为而受到赞誉（Li
    et al., [2023a](https://arxiv.org/html/2410.14152v1#bib.bib30); Park et al., [2022](https://arxiv.org/html/2410.14152v1#bib.bib38),
    [2023](https://arxiv.org/html/2410.14152v1#bib.bib37)），LLM通过在大量网络数据上进行预训练，展示了封装人类认知中固有逻辑和模式的潜力（OpenAI,
    [2023](https://arxiv.org/html/2410.14152v1#bib.bib36)）。这一突破促进了社会共识机制在经济仿真中的融入，提供了一个全面的框架，用于评估资源分配政策对经济效率和社会福利的影响。
- en: 'In this work, we develop an LLM-based scarce resource allocation policy simulation
    agent, SRAP-Agent. It abstracts the resource allocation queues for policy execution,
    with LLM-based agents carefully designed for the simulation of participants’ behaviors.
    Furthermore, we propose the genetic algorithm-based policy optimization algorithm
    (POA) to find optimal policies towards pre-defined targets. Through experiments
    in the context of public housing allocation, we validate the effectiveness of
    SRAP-Agent, which reveals several key insights: (1) The LLM-based agent can effectively
    simulate the emotion factor and strategic behaviors of humans. Compared to the
    GPT-4-driven agent, the simulated decision-making behavior of the GPT-3.5-driven
    agent is more similar to humans’ behavior. (2) In scarce resource allocation,
    pivotal factors include the entry conditions of participants, the queuing method,
    and the categorization of resources. (3) POA can optimize policies towards a specific
    policy evaluation metric, and improve approximately 20% on this metric.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中，我们开发了一个基于LLM的稀缺资源分配政策仿真代理，SRAP-Agent。它抽象了政策执行的资源分配队列，并设计了基于LLM的代理，用于模拟参与者的行为。此外，我们提出了一种基于遗传算法的政策优化算法（POA），用于寻找朝向预定义目标的最优政策。通过在公共住房分配背景下的实验，我们验证了SRAP-Agent的有效性，并揭示了几个关键的洞察：(1)
    基于LLM的代理能够有效模拟人类的情感因素和战略行为。与GPT-4驱动的代理相比，GPT-3.5驱动的代理在模拟决策行为时，更加接近人类的行为。(2) 在稀缺资源分配中，关键因素包括参与者的进入条件、排队方式和资源分类。(3)
    POA能够优化政策，使其朝向特定的政策评估指标，并在该指标上提高约20%。
- en: 2 Related Work
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: Public Scarce Resources Allocation. The allocation of public scarce resources
    represents a crucial area of inquiry in the development of economic policy. A
    multitude of researchers Hylland and Zeckhauser ([1979](https://arxiv.org/html/2410.14152v1#bib.bib20));
    Shapley and Scarf ([1974](https://arxiv.org/html/2410.14152v1#bib.bib40)); Sönmez
    ([1999](https://arxiv.org/html/2410.14152v1#bib.bib43)); Abdulkadiroğlu and Sönmez
    ([1999](https://arxiv.org/html/2410.14152v1#bib.bib1)) conduct in-depth investigations
    into static matching models and propose Pareto efficient, individually rational,
    and strategy-proof simple mechanisms for various scenarios. Later, given the predominantly
    dynamic nature of practical scarce resource allocation, several studies Sönmez
    and Ünver ([2011](https://arxiv.org/html/2410.14152v1#bib.bib44)); Su and Zenios
    ([2004](https://arxiv.org/html/2410.14152v1#bib.bib45), [2005](https://arxiv.org/html/2410.14152v1#bib.bib46));
    Bloch and Cantala ([2017](https://arxiv.org/html/2410.14152v1#bib.bib6)) begin
    to integrate dynamic properties into their models. The waitlist mechanism is widely
    adopted for allocating scarce resources. For instance, Chen et al. ([2018](https://arxiv.org/html/2410.14152v1#bib.bib11))
    explore the waitlist mechanism in public housing allocation, Agarwal et al. ([2021](https://arxiv.org/html/2410.14152v1#bib.bib2))
    design a waitlist for kidney organ allocation, which increased donor supply by
    18.2% to enhance patient welfare; Lewis et al. ([2000](https://arxiv.org/html/2410.14152v1#bib.bib29))
    develop a mechanism for managing waitlist for elective surgeries, improving the
    fairness of surgery opportunity distribution among patients. We focus our research
    on the k-deferrals waitlist mechanism in Chen et al. ([2018](https://arxiv.org/html/2410.14152v1#bib.bib11)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 公共稀缺资源配置。公共稀缺资源的配置代表了经济政策发展中的一个关键研究领域。许多研究者，如Hylland和Zeckhauser（[1979](https://arxiv.org/html/2410.14152v1#bib.bib20)）；Shapley和Scarf（[1974](https://arxiv.org/html/2410.14152v1#bib.bib40)）；Sönmez（[1999](https://arxiv.org/html/2410.14152v1#bib.bib43)）；Abdulkadiroğlu和Sönmez（[1999](https://arxiv.org/html/2410.14152v1#bib.bib1)）对静态匹配模型进行了深入研究，并提出了适用于各种情境的帕累托最优、个体理性和策略免疫的简单机制。后来，鉴于实际稀缺资源配置的主要动态特性，一些研究者，如Sönmez和Ünver（[2011](https://arxiv.org/html/2410.14152v1#bib.bib44)）；Su和Zenios（[2004](https://arxiv.org/html/2410.14152v1#bib.bib45)，[2005](https://arxiv.org/html/2410.14152v1#bib.bib46)）；Bloch和Cantala（[2017](https://arxiv.org/html/2410.14152v1#bib.bib6)），开始将动态属性融入他们的模型中。等候名单机制被广泛应用于稀缺资源的分配。例如，Chen等人（[2018](https://arxiv.org/html/2410.14152v1#bib.bib11)）探讨了公共住房分配中的等候名单机制，Agarwal等人（[2021](https://arxiv.org/html/2410.14152v1#bib.bib2)）设计了一个肾脏器官分配的等候名单，增加了18.2%的捐赠者供给，以提升患者福利；Lewis等人（[2000](https://arxiv.org/html/2410.14152v1#bib.bib29)）开发了一个管理择期手术等候名单的机制，改善了手术机会在患者中的分配公平性。我们将研究重点放在Chen等人（[2018](https://arxiv.org/html/2410.14152v1#bib.bib11)）提出的k延迟等候名单机制上。
- en: Economic Policy Simulation. The predominant methodologies for simulating the
    implementation of economic policies include rule-driven and reinforcement learning-based
    simulations. Rule-driven approaches Holland and Miller ([1991](https://arxiv.org/html/2410.14152v1#bib.bib18));
    Bonabeau ([2002](https://arxiv.org/html/2410.14152v1#bib.bib8)); Farmer and Foley
    ([2009](https://arxiv.org/html/2410.14152v1#bib.bib15)), involve modeling utility
    functions as agents, formulating various environmental rules, and observing the
    resultant global changes. Reinforcement learning-based simulations Laurent et al.
    ([2011](https://arxiv.org/html/2410.14152v1#bib.bib28)); Claus and Boutilier ([1998](https://arxiv.org/html/2410.14152v1#bib.bib12));
    Zheng et al. ([2022](https://arxiv.org/html/2410.14152v1#bib.bib56)); Bansal et al.
    ([2018](https://arxiv.org/html/2410.14152v1#bib.bib5)); Jaderberg et al. ([2019](https://arxiv.org/html/2410.14152v1#bib.bib21)),
    involve modeling agents as either Markov Decision Processes (MDP) or Partially
    Observable Markov Decision Processes (POMDP), employing reinforcement learning
    methods to maximize the utility of each agent. However, both methods are heavily
    dependent on the assumption of individual rationality, often leading to predictions
    that diverge from real-world outcomes. While exploring the same problem, these
    methods presuppose that agents act rationally and calculate behavior by first
    optimizing equilibrium outcomes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 经济政策模拟。模拟经济政策实施的主要方法包括基于规则驱动和基于强化学习的模拟。基于规则驱动的方法 Holland 和 Miller ([1991](https://arxiv.org/html/2410.14152v1#bib.bib18))；Bonabeau
    ([2002](https://arxiv.org/html/2410.14152v1#bib.bib8))；Farmer 和 Foley ([2009](https://arxiv.org/html/2410.14152v1#bib.bib15))，涉及将效用函数建模为代理，制定各种环境规则，并观察由此产生的全球变化。基于强化学习的模拟 Laurent
    等人 ([2011](https://arxiv.org/html/2410.14152v1#bib.bib28))；Claus 和 Boutilier ([1998](https://arxiv.org/html/2410.14152v1#bib.bib12))；Zheng
    等人 ([2022](https://arxiv.org/html/2410.14152v1#bib.bib56))；Bansal 等人 ([2018](https://arxiv.org/html/2410.14152v1#bib.bib5))；Jaderberg
    等人 ([2019](https://arxiv.org/html/2410.14152v1#bib.bib21))，则将代理建模为马尔可夫决策过程（MDP）或部分可观察马尔可夫决策过程（POMDP），并采用强化学习方法最大化每个代理的效用。然而，这两种方法都高度依赖个体理性假设，通常导致预测结果与实际情况存在偏差。尽管这两种方法探索的是相同的问题，但它们预设代理是理性行为，并通过首先优化均衡结果来计算行为。
- en: Our research introduces a novel approach by integrating social consensus derived
    from LLMs with the conventional concept of individual rationality to generate
    choices that reflect individual preferences. We optimize policy based on simulation
    results, providing a unique research perspective incomparable to existing methods.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究通过将基于大型语言模型（LLM）的社会共识与传统的个体理性概念相结合，提出了一种新颖的方法，以生成反映个体偏好的选择。我们基于模拟结果优化政策，提供了一种独特的研究视角，无法与现有方法相提并论。
- en: LLM-based Agents. With the development of LLMs OpenAI ([2023](https://arxiv.org/html/2410.14152v1#bib.bib36));
    Anil et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib3)); Touvron et al.
    ([2023](https://arxiv.org/html/2410.14152v1#bib.bib47)), there has been an emerging
    focus on the exploration of LLMs-based agent architectures and prompt designs
     Kojima et al. ([2022](https://arxiv.org/html/2410.14152v1#bib.bib26)); Shinn
    et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib42)); Wang et al. ([2023c](https://arxiv.org/html/2410.14152v1#bib.bib53)),
    aimed at augmenting the capabilities of LLM-based agents to perform more complex
    tasks. Alongside these developments, researchers are devoted to crafting realistic
    societal simulation environments Li et al. ([2023a](https://arxiv.org/html/2410.14152v1#bib.bib30));
    Park et al. ([2022](https://arxiv.org/html/2410.14152v1#bib.bib38), [2023](https://arxiv.org/html/2410.14152v1#bib.bib37))
    that incorporate multiple agents, thereby providing a more dynamic and interconnected
    framework for agent interaction and behavior analysis. Following this,  (Li et al.,
    [2023b](https://arxiv.org/html/2410.14152v1#bib.bib31)) makes a primary exploration
    of the effectiveness of LLMs-based agent simulation in macroeconomic policy. However,
    it remains unconfirmed whether the decision-making capabilities of LLMs align
    with those of actual humans in economic activities. Our investigation draws inspiration
    from the experimental findings of DillionDillion et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib13)),
    aiming to integrate social consensus with individual rationality within the economic
    policy simulation process.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的代理。随着LLM（大型语言模型）技术的发展，OpenAI（[2023](https://arxiv.org/html/2410.14152v1#bib.bib36)）；Anil等人（[2023](https://arxiv.org/html/2410.14152v1#bib.bib3)）；Touvron等人（[2023](https://arxiv.org/html/2410.14152v1#bib.bib47)）等研究者，越来越多的关注开始转向基于LLM的代理架构和提示设计的探索，如Kojima等人（[2022](https://arxiv.org/html/2410.14152v1#bib.bib26)）；Shinn等人（[2023](https://arxiv.org/html/2410.14152v1#bib.bib42)）；Wang等人（[2023c](https://arxiv.org/html/2410.14152v1#bib.bib53)），这些研究旨在增强基于LLM的代理执行更复杂任务的能力。与这些发展并行，研究人员致力于构建现实的社会模拟环境，如Li等人（[2023a](https://arxiv.org/html/2410.14152v1#bib.bib30)）；Park等人（[2022](https://arxiv.org/html/2410.14152v1#bib.bib38)，[2023](https://arxiv.org/html/2410.14152v1#bib.bib37)），这些环境集成了多个代理，从而为代理的互动和行为分析提供了更具动态性和互联性的框架。随后，（Li等人，[2023b](https://arxiv.org/html/2410.14152v1#bib.bib31)）对基于LLM的代理模拟在宏观经济政策中的有效性进行了初步探索。然而，目前尚未确认LLM的决策能力是否与实际人类在经济活动中的决策能力相符。我们的研究受到DillionDillion等人（[2023](https://arxiv.org/html/2410.14152v1#bib.bib13)）的实验发现启发，旨在将社会共识与个体理性相结合，在经济政策模拟过程中进行探索。
- en: 3 SRAP-Agent
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 SRAP-Agent
- en: In this section, we present SRAP-Agent, a novel large language model (LLM) agent-based
    simulation framework designed for examining the impact of economic policies on
    public scarce resource allocation. SRAP-Agent aims to consider that human decision-making
    in economic contexts is not purely rational, but is influenced by a mix of rationality
    and emotion, leading to unpredictable outcomes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了SRAP-Agent，一个新颖的大型语言模型（LLM）代理基础的模拟框架，旨在研究经济政策对公共稀缺资源分配的影响。SRAP-Agent的目标是考虑到经济环境中的人类决策并非纯粹理性，而是受到理性与情感的混合影响，从而导致不可预测的结果。
- en: 'The simulation of SRAP-Agent is divided into three phases as shown in Fig.
    [1](https://arxiv.org/html/2410.14152v1#S1.F1 "Figure 1 ‣ 1 Introduction ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"):
    (1) Setup phase, involves the initialization of critical variables including the
    profiles of participants $P$, the information of available public scarce resources
    $R$, and the allocation policy $\pi$. (2) Simulation phase, dynamically simulates
    the allocation of resources $R$ among participants $P$, adhering to the constraints
    and rules defined by the allocation policy $\pi$. (3) Evaluation phase, focuses
    on assessing the outcomes of the allocation process, employing various metrics
    such as fairness and participant satisfaction.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: SRAP-Agent的模拟过程分为三个阶段，如图[1](https://arxiv.org/html/2410.14152v1#S1.F1 "图1 ‣
    1 介绍 ‣ SRAP-Agent：使用LLM基础的代理模拟和优化稀缺资源分配政策")所示：(1) 设置阶段，涉及关键变量的初始化，包括参与者$P$的配置文件、可用公共稀缺资源$R$的信息，以及分配政策$\pi$。
    (2) 模拟阶段，动态模拟资源$R$在参与者$P$之间的分配，遵循分配政策$\pi$定义的约束和规则。 (3) 评估阶段，重点评估分配过程的结果，采用各种指标，如公平性和参与者满意度。
- en: Next, we outline the formulation of the allocation policy $\pi$ and the structure
    of participants $P$.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们概述分配政策$\pi$的制定以及参与者$P$的结构。
- en: 3.1 Allocation Policy
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 分配政策
- en: 'Public scarce resource allocation represents a significant challenge in economics,
    particularly in the context of public resources where the objectives of efficiency
    and equity frequently converge. In this work, we consider the queuing, pricing,
    and grouping mechanisms in SRAP-Agent. Formally, In the SRAP-Agent framework,
    we formalize a structure consisting of $m$ distinct queues: $q_{1},q_{2},\ldots
    q_{m}$. Each queue is uniquely characterized by:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 公共稀缺资源分配是经济学中的一个重大挑战，特别是在公共资源的背景下，效率和公平的目标往往交织在一起。在本研究中，我们考虑了SRAP-Agent中的排队、定价和分组机制。正式地说，在SRAP-Agent框架中，我们将结构化为包含$m$个不同队列的系统：$q_{1},
    q_{2}, \ldots q_{m}$。每个队列具有以下独特特点：
- en: '(1) Participant entry conditions: to define the conditions under which individuals
    are eligible to enter a specific queue. Generally, the entry condition $E_{queue}(i)$
    for the queue $q_{i}$ typically encompasses various socioeconomic factors such
    as individual budget, average income, and other relevant personal information.
    In the context of budget-based criteria, the entry conditions for $m$ queues are
    categorized into $m$ distinct budget ranges, organizing from high to low budget.
    This allows the simulation to reflect diverse economic backgrounds and their access
    to resources.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 参与者进入条件：定义个体在何种条件下有资格进入特定队列。通常，队列$q_{i}$的进入条件$E_{queue}(i)$包括多种社会经济因素，如个人预算、平均收入及其他相关个人信息。在基于预算的标准下，$m$个队列的进入条件被分类为$m$个不同的预算区间，按预算从高到低排列。这使得模拟能够反映出不同经济背景及其资源获取情况。
- en: '(2) Queue sorting strategies: to govern the prioritization of participants
    within each queue upon their entry, denoting as $S_{queue}$. We have incorporated
    two distinct sorting strategies: (a) first-in-first-out, of which participant
    order is set by arrival sequence. This method, prevalent in real scenarios, guarantees
    procedural fairness by chronologically allocating opportunities without regard
    to participants’ characteristics. (b) priority for vulnerable groups, which is
    designed to address social equity by providing preferential access to vulnerable
    groups, positioning them at the forefront when entering the specific queue. Besides,
    SRAP-Agent also employs the widely-used waiting queue Chen et al. ([2018](https://arxiv.org/html/2410.14152v1#bib.bib11));
    Agarwal et al. ([2021](https://arxiv.org/html/2410.14152v1#bib.bib2)) mechanism.
    Each queue encompasses two components: the waiting queue and the selection queue.
    Participants initially enter the waiting queue. When a spot becomes available
    in the selection queue, the participant at the front of the waiting queue is transferred
    to the selection queue. The number of resources is denoted as $|R|$, then the
    capacity of the selection queue for accommodating participants is upper-bounded
    by $c\cdot|R|$. In the selection queue, each participant can queue to choose up
    to $k$ times; once their choices are exhausted, they return to the waiting queue.
    This mechanism diminishes the waiting time for participants by increasing the
    chances of participants staying in the selection queue.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 队列排序策略：用于在每个队列内对参与者进行优先级排序，记作$S_{queue}$。我们采用了两种不同的排序策略：(a) 先进先出（FIFO），其中参与者的顺序按到达顺序设置。这种方法在实际场景中广泛应用，通过按照时间顺序分配机会，确保了程序的公平性，而不考虑参与者的特征。(b)
    优先照顾弱势群体，旨在通过为弱势群体提供优先访问权来实现社会公平，使他们在进入特定队列时处于队列的前端。此外，SRAP-Agent还采用了广泛使用的等待队列机制，由Chen等人（[2018](https://arxiv.org/html/2410.14152v1#bib.bib11)）和Agarwal等人（[2021](https://arxiv.org/html/2410.14152v1#bib.bib2)）提出。每个队列包含两个部分：等待队列和选择队列。参与者最初进入等待队列。当选择队列中有空位时，等待队列最前面的参与者被转移到选择队列中。资源数量用$|R|$表示，那么选择队列的容量为$c\cdot|R|$。在选择队列中，每个参与者最多可以排队选择$k$次；一旦选择次数用尽，他们将返回等待队列。该机制通过增加参与者在选择队列中停留的机会，减少了参与者的等待时间。
- en: '(3) Available resource sub-sets: These sub-sets represent the specific resources
    that participants in a given queue can access and choose from, denoting as $R_{queue}(i)\subseteq
    R$ for the $q_{i}$. The composition of these resource sub-sets is dictated by
    certain predefined conditions, primarily considering factors such as the price
    and quality of resources. Typically, the predefined conditions of the resources
    in a queue are matched with their corresponding entry conditions. This ensures
    that resources are categorized and allocated to participant groups in a manner
    that is congruent with their economic capacity. Hence, the allocation policy is
    defined as the following equation:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: （3）可用资源子集：这些子集表示特定队列中参与者可以访问并选择的资源，记作$R_{queue}(i)\subseteq R$，适用于队列$q_{i}$。这些资源子集的组成由一些预定义条件决定，主要考虑资源的价格和质量等因素。通常，队列中资源的预定义条件与其相应的进入条件匹配。这确保了资源按经济能力合理分类和分配给参与者组。因此，分配策略定义为以下方程：
- en: '|  | $V(p_{j})=\pi(p_{j}&#124;E_{queue},S_{queue},R_{queue},m),$ |  | (1) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | $V(p_{j})=\pi(p_{j}&#124;E_{queue},S_{queue},R_{queue},m),$ |  | （1）'
- en: where $p_{j}$ represents the $j$-th participant in the list of participants
    $P=(p_{1},p_{2},\cdots,p_{n})$, the function $V(p_{j})$ is the available resource
    for the $j$-th participant under the policy. It enters the $q_{i}$ when it satisfies
    the condition $E_{queue}(i)$. Its order in the queue is determined by $S_{queue}$.
    When it is his turn to select, the participant $p_{j}$ can choose from the remaining
    resources in $R_{queue}(i)$, i.e., $V(p_{j})$. In SRAP-Agent, the policymakers
    can set the resource policy according to their requirement, and the policy will
    be broadcast to all participants.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$p_{j}$表示参与者列表$P=(p_{1},p_{2},\cdots,p_{n})$中的第$j$个参与者，函数$V(p_{j})$表示该参与者在政策下可获得的资源。当其满足条件$E_{queue}(i)$时，它进入队列$q_{i}$。其在队列中的顺序由$S_{queue}$决定。当轮到该参与者选择时，参与者$p_{j}$可以从$R_{queue}(i)$中剩余的资源中选择，即$V(p_{j})$。在SRAP-Agent中，政策制定者可以根据需求设置资源政策，并将政策广播给所有参与者。
- en: 3.2 LLM Agent-based Participant Simulation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 基于LLM的参与者模拟
- en: 'Recognizing the complexity of human decision-making, SRAP-Agent employs LLM-based
    agents to simulate participants’ behaviors in the context of public scarce resource
    selection. This approach recognizes that human decision-making is not purely rational
    and often influenced by a range of factors. While it is impractical to simulate
    all aspects of human behavior, SRAP-Agent focuses on two most impactful behaviors:
    (1) Decision-making behavior. This aspect of the simulation addresses how participants
    evaluate and choose resources, factoring in elements like personal preferences,
    perceived value, and immediate needs. (2) Social behavior. Social dynamics also
    play a critical role in resource selection. This includes interactions with other
    participants, social norms, and external influences, which can affect how participants
    perceive and choose resources.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到人类决策的复杂性，SRAP-Agent采用基于大型语言模型（LLM）的智能体来模拟参与者在公共稀缺资源选择中的行为。这种方法认识到人类决策并非完全理性，往往受到多种因素的影响。虽然模拟人类行为的所有方面是不现实的，但SRAP-Agent专注于两个最具影响力的行为：（1）决策行为。该部分模拟了参与者如何评估和选择资源，考虑了个人偏好、感知价值和即时需求等因素。（2）社会行为。社会动态在资源选择中也起着至关重要的作用。这包括与其他参与者的互动、社会规范和外部影响，这些因素会影响参与者如何感知和选择资源。
- en: Agent Architecture
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 智能体架构
- en: SRAP-Agent leverages LLM-based agents to instantiate individual participants
    in the simulation. Each participant $p_{j}$ is uniquely characterized by an initial
    profile including several key personal attributes such as economic status, income
    level, family background, and social network connections. To facilitate dynamic
    interaction and decision-making, each agent is equipped with a memory component
    $m_{j}$ describing the participant’s activity history. This memory serves as a
    critical reference point, enabling the agent to make informed decisions based
    on past actions and interactions within the simulation environment. This design
    not only enhances the realism of the simulation but also allows for a more nuanced
    exploration of social dynamics and individual decision-making processes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SRAP-Agent利用基于LLM的代理来实例化模拟中的各个参与者。每个参与者$p_{j}$由一个初始档案唯一标识，档案包括若干关键的个人属性，如经济状况、收入水平、家庭背景和社交网络关系。为了促进动态交互和决策，每个代理都配备了一个记忆组件$m_{j}$，用于描述参与者的活动历史。这个记忆作为一个重要的参考点，使代理能够根据过去的行为和互动在模拟环境中做出有根据的决策。这种设计不仅增强了模拟的真实性，还允许对社会动态和个人决策过程进行更为细致的探索。
- en: Social Behavior Simulation
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 社会行为模拟
- en: 'Human decision-making often involves the collection of information to make
    more informed choices. SRAP-Agent incorporates two primary social behaviors frequently
    employed by humans for information collection:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 人类决策通常涉及收集信息以做出更为明智的选择。SRAP-Agent结合了人类在信息收集过程中常用的两种主要社会行为：
- en: '(1) Broadcasting: This mechanism is akin to a conventional web blog. Participants
    in SRAP-Agent utilize this platform for both disseminating and acquiring information,
    mirroring the way individuals interact and gather information in real-world social
    networks.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 广播：这一机制类似于传统的网页博客。SRAP-Agent中的参与者利用该平台进行信息的传播和获取，模拟了人们在现实社交网络中互动和收集信息的方式。
- en: '(2) Private messaging: In addition to broadcasting, participants can send private
    messages to their friends. This feature is critical for more direct and personalized
    communication, such as seeking assistance or sharing specific information about
    high-quality resources. In human society, communication is deeply influenced by
    psychological factors that shape the information being shared, resulting in asymmetrical
    information within social networks. To simulate the mental state of humans and
    the strategic interactions among different participants, we adopt a mechanism
    of memory assessment. We design the memory $m_{j}$ of $p_{j}$ to comprise two
    parts: (1) Trustworthy memory $m_{j}^{T}$ that mainly includes information from
    reliable sources, such as policymakers; (2) Suspicious memory $m_{j}^{S}$ that
    stores information from the social behaviors.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 私信：除了广播功能外，参与者还可以向朋友发送私人消息。这个功能对于更直接和个性化的沟通至关重要，例如寻求帮助或共享有关高质量资源的具体信息。在人类社会中，沟通深受心理因素的影响，这些因素塑造了信息的分享方式，导致社交网络中的信息不对称。为了模拟人类的心理状态以及不同参与者之间的战略互动，我们采用了一种记忆评估机制。我们设计了$p_{j}$的记忆$m_{j}$，将其分为两部分：(1)
    可信记忆$m_{j}^{T}$，主要包括来自可靠来源的信息，如政策制定者；(2) 可疑记忆$m_{j}^{S}$，存储来自社会行为的信息。
- en: 'In the process of communication among participants, assume that $p_{j}$ is
    interacting with $p_{k}$, and the received information from $p_{k}$ will be stored
    in suspicious memory $m_{j}^{S}$ firstly. Then, $p_{j}$ measure the reliability
    of information from participant $p_{k}$ from two aspects: i) assessing the nature
    of their relationship with $p_{k}$, encompassing factors like closeness and historical
    interactions, in conjunction with a moral appraisal of $p_{k}$; ii) contrasting
    the received information against their trusted memory $m_{j}^{T}$. Following this
    evaluation, parts of the received information that are deemed reliable are integrated
    into the trustworthy memory $m_{j}^{T}$.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在参与者之间的交流过程中，假设$p_{j}$正在与$p_{k}$互动，$p_{k}$传递的信息首先会存储在$p_{j}$的可疑记忆$m_{j}^{S}$中。然后，$p_{j}$从两个方面评估$p_{k}$提供信息的可靠性：i)
    评估与$p_{k}$关系的性质，包括亲密度和历史互动，并结合对$p_{k}$的道德评估；ii) 将接收到的信息与他们的可信记忆$m_{j}^{T}$进行对比。经过评估后，那些被认为可靠的信息将被整合到可信记忆$m_{j}^{T}$中。
- en: Through these mechanisms, SRAP-Agent effectively models the complex social dynamics
    of information gathering and sharing, allowing for a deeper understanding of human
    behavior in the context of public scarce resource allocation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些机制，SRAP-Agent有效地模拟了信息收集与共享的复杂社会动态，从而更深入地理解在人类行为的公共稀缺资源分配中的表现。
- en: Decision-Making Behavior Simulation
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 决策行为仿真
- en: 'The simulation of the decision-making processes in SRAP-Agent can be formulated
    by:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SRAP-Agent中决策过程的仿真可以表示为：
- en: '|  | $R^{*}_{j}=D(p_{j},V(p_{j})),$ |  | (2) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | $R^{*}_{j}=D(p_{j},V(p_{j})),$ |  | (2) |'
- en: where the function $D(p_{j},V(p_{j}))$ indicates the process that $p_{j}$ selects
    the desired resource from his visible resource pool. $R^{*}_{j}=\emptyset$ means
    participant $p_{j}$ quit the decision procedure when there’s no desired resource.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中函数$D(p_{j},V(p_{j}))$表示$p_{j}$从其可见资源池中选择所需资源的过程。$R^{*}_{j}=\emptyset$表示参与者$p_{j}$在没有所需资源时退出决策过程。
- en: '4 POA: Policy Optimization Algorithm'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 POA：政策优化算法
- en: 'Algorithm 1 POA: Policy Optimization Algorithm'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 POA：政策优化算法
- en: '1:Historical policies $\Pi_{h}$, predictor $\widetilde{f}$, running iterations
    $M$2:Optimized policy $\pi^{*}$3:Randomly generate policies $\Pi_{r}$.4:Initialize
    policy pool $\Pi$ with $\Pi_{h}$ and $\Pi_{r}$.5:for $i=1$ to $M$ do6:     Calculate
    the fitness $\widetilde{f}(\pi)$ of $\pi$ in $\Pi$.7:     Use the tournament selection
    Miller et al. ([1995](https://arxiv.org/html/2410.14152v1#bib.bib33)) to select
    policies $\Pi_{s}$ in $\Pi$ based on fitness.8:     Combine pairs in $\Pi_{s}$
    to produce $\Pi_{c}$.9:     Apply mutation to the $\Pi_{c}$ to obtain $\Pi_{m}$.10:     Replace
    $\Pi_{s}$ with $\Pi_{m}$ to update $\Pi$.11:end for12:Obtain the optimized policy
    by $\widetilde{f}$:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '1: 历史政策$\Pi_{h}$，预测器$\widetilde{f}$，运行迭代次数$M$ 2: 优化政策$\pi^{*}$ 3: 随机生成政策$\Pi_{r}$
    4: 使用$\Pi_{h}$和$\Pi_{r}$初始化政策池$\Pi$ 5: 对于$i=1$到$M$，执行以下操作：6: 计算$\Pi$中政策$\pi$的适应度$\widetilde{f}(\pi)$。7:
    使用锦标赛选择法（Miller等人，[1995](https://arxiv.org/html/2410.14152v1#bib.bib33)）根据适应度选择政策$\Pi_{s}$。8:
    将$\Pi_{s}$中的配对组合生成$\Pi_{c}$。9: 对$\Pi_{c}$应用变异操作得到$\Pi_{m}$。10: 用$\Pi_{m}$替换$\Pi_{s}$以更新$\Pi$。11:
    结束循环。12: 通过$\widetilde{f}$获得优化政策：'
- en: '|  | $v_{\pi^{*}}=\underset{v_{\pi}}{\arg\max}\widetilde{f}\left(v_{\pi}\right),\pi\in\Pi$
    |  |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '|  | $v_{\pi^{*}}=\underset{v_{\pi}}{\arg\max}\widetilde{f}\left(v_{\pi}\right),\pi\in\Pi$
    |  |'
- en: 13:Decode $v_{\pi^{*}}$ to obtain the optimized policy $\pi^{*}$.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '13: 解码$v_{\pi^{*}}$以获得优化后的政策$\pi^{*}$。'
- en: 'We propose a policy optimization algorithm (POA) based on the genetic algorithm
    Lambora et al. ([2019](https://arxiv.org/html/2410.14152v1#bib.bib27)) to find
    more reasonable policies. The set of policies proposed by the policymaker is $\pi\in\Pi$,
    and $f$ is the policy evaluation metric, then the optimal policy is $\pi^{*}=\underset{\pi\in\Pi}{\arg\max}f(\pi).$
    Generally, $f$ takes into account $L$ different kinds of policy evaluation metrics
    ($f_{j}(\pi),j\in[L]$), which can be categorized into societal satisfaction and
    societal fairness metrics. We pre-set the weights $w_{j}$ to alter the optimization
    objective of POA, the specific calculation formula of $f$ is as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一种基于遗传算法的政策优化算法（POA），该算法由Lambora等人（[2019](https://arxiv.org/html/2410.14152v1#bib.bib27)）提出，用于寻找更合理的政策。决策者提出的政策集合为$\pi\in\Pi$，$f$是政策评估度量，则最优政策为$\pi^{*}=\underset{\pi\in\Pi}{\arg\max}f(\pi)$。通常，$f$考虑了$L$种不同的政策评估度量（$f_{j}(\pi),j\in[L]$），这些度量可以分为社会满意度和社会公平度量。我们预设了权重$w_{j}$来改变POA的优化目标，$f$的具体计算公式如下：
- en: '|  | $f(\pi)=\sum_{j=1}^{n}w_{j}\cdot f_{j}(\pi),\pi\in\Pi_{h}.$ |  | (3) |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '|  | $f(\pi)=\sum_{j=1}^{n}w_{j}\cdot f_{j}(\pi),\pi\in\Pi_{h}.$ |  | (3) |'
- en: 'Due to the excessive number of policies that need to be searched, the time
    required to obtain policy evaluation results with SRAP-Agent may be excessively
    long. So we use the $v_{\pi},f(\pi)$ dataset to train a predictor $\widetilde{f}$
    for the estimation of the policy evaluation result: $f(\pi)=\widetilde{f}(v_{\pi})$.
    POA then performs $M$ iterations to find more rational policy parameters. The
    specific steps of POA are listed in Algorithm.[1](https://arxiv.org/html/2410.14152v1#alg1
    "Algorithm 1 ‣ 4 POA: Policy Optimization Algorithm ‣ SRAP-Agent: Simulating and
    Optimizing Scarce Resource Allocation Policy with LLM-based Agent").'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '由于需要搜索的政策数量过多，使用SRAP-Agent获得政策评估结果的时间可能会过长。因此，我们使用$v_{\pi},f(\pi)$数据集来训练预测器$\widetilde{f}$，用于估计政策评估结果：$f(\pi)=\widetilde{f}(v_{\pi})$。然后，POA执行$M$次迭代以寻找更合理的政策参数。POA的具体步骤列在算法[1](https://arxiv.org/html/2410.14152v1#alg1
    "Algorithm 1 ‣ 4 POA: Policy Optimization Algorithm ‣ SRAP-Agent: Simulating and
    Optimizing Scarce Resource Allocation Policy with LLM-based Agent")中。'
- en: 5 Experiment
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验
- en: 'We select the public housing allocation scenario as a typical case to validate
    the simulation effectiveness of SRAP-Agent. We conduct experiments in three steps:
    1\. We conduct the Turing test to ensure that, SRAP-Agent can effectively simulate
    the policy execution process of various policies proposed by the policymaker.
    2\. Based on the simulation results obtained from the SRAP-Agent, we analyze the
    impact of various policy parameters on the allocation of public scarce resources.
    3\. Subsequently, we employ the POA algorithm to find the optimal policy in pursuit
    of specific optimization objectives.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择公共住房分配场景作为典型案例，以验证SRAP-Agent的仿真效果。我们按照三个步骤进行实验：1\. 进行图灵测试，以确保SRAP-Agent能够有效模拟决策者提出的各种政策的执行过程。2\.
    基于SRAP-Agent获得的仿真结果，分析各种政策参数对公共稀缺资源分配的影响。3\. 随后，我们使用POA算法寻找在追求特定优化目标时的最优政策。
- en: 5.1 Evaluation Metrics
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 评估指标
- en: 'In our research, we adhere to the commonly used metrics for public scarce resources
    allocation Vermunt and Törnblom ([1996](https://arxiv.org/html/2410.14152v1#bib.bib50));
    Wang et al. ([2023b](https://arxiv.org/html/2410.14152v1#bib.bib52)), employing
    two major categories of policy evaluation metrics:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们遵循Vermunt和Törnblom（[1996](https://arxiv.org/html/2410.14152v1#bib.bib50)）以及Wang等人（[2023b](https://arxiv.org/html/2410.14152v1#bib.bib52)）常用的公共稀缺资源分配指标，采用两大类政策评估指标：
- en: 'Societal Satisfaction Metrics. We use three metrics to evaluate societal satisfaction:
    (1) Avg $r^{size}$: representing the average per-capita living area size of house
    resources for all participants; (2) Avg $WT$: Average waiting time for each participant;
    (3) $SW$: the social welfare, quantifying the cumulative satisfaction of all participants.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 社会满意度指标。我们使用三个指标来评估社会满意度：（1）Avg $r^{size}$：表示所有参与者的平均人均住房资源面积；（2）Avg $WT$：每个参与者的平均等待时间；（3）$SW$：社会福利，量化所有参与者的累计满意度。
- en: 'Societal Fairness Metrics. In addition, we employ four metrics to evaluate
    societal fairness: (1) Var $r^{size}$: denoting the variance in per capita living
    area size among participants; (2) Rop: indicating the number of inverse order
    pairs in house allocation results; (3) co-Gini: the Gini coefficient Wang et al.
    ([2023b](https://arxiv.org/html/2410.14152v1#bib.bib52)) calculated on house allocation
    result. We use $F(V,NV)$ to reflect the $SW$ gap between the vulnerable ($V$)
    and non-vulnerable group ($NV$) of participants. The calculation equations are
    listed in Appendix [C.2](https://arxiv.org/html/2410.14152v1#A3.SS2 "C.2 Evaluation
    Metrics ‣ Appendix C Experiment Setup ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent").'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '社会公平性指标。此外，我们使用四个指标来评估社会公平性：（1）Var $r^{size}$：表示参与者之间人均住房面积的方差；（2）Rop：表示住房分配结果中逆序对的数量；（3）co-Gini：Wang等人（[2023b](https://arxiv.org/html/2410.14152v1#bib.bib52)）基于住房分配结果计算的基尼系数。我们使用$F(V,NV)$来反映脆弱群体（$V$）与非脆弱群体（$NV$）之间的$SW$差距。计算公式见附录[C.2](https://arxiv.org/html/2410.14152v1#A3.SS2
    "C.2 Evaluation Metrics ‣ Appendix C Experiment Setup ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")。'
- en: 5.2 Turing Test
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 图灵测试
- en: 'Table 1: Turing test for responses from GPT-3.5 and GPT-4\. *means statistically
    significant with $p\textless$ 0.05.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：GPT-3.5与GPT-4的图灵测试响应。*表示统计学上显著，$p\textless$ 0.05。
- en: '|  | GPT-3.5 | GPT-4 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT-3.5 | GPT-4 |'
- en: '| --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $Human>Robot$ | 26.6% | 20.6%^∗ |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| $Human>Robot$ | 26.6% | 20.6%^∗ |'
- en: '| $Human=Robot$ | 36.3% | 21.1%^∗ |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| $Human=Robot$ | 36.3% | 21.1%^∗ |'
- en: '| $Human<Robot$ | 30.2% | 49.1%^∗ |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| $Human<Robot$ | 30.2% | 49.1%^∗ |'
- en: '| $None$ | 7.0% | 9.3%^∗ |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| $None$ | 7.0% | 9.3%^∗ |'
- en: 'To assess the simulation capabilities of LLMs, the Turing test Turing ([2009](https://arxiv.org/html/2410.14152v1#bib.bib49))
    is a commonly employed and effective metric Ng et al. ([2024](https://arxiv.org/html/2410.14152v1#bib.bib34));
    Jones and Bergen ([2023](https://arxiv.org/html/2410.14152v1#bib.bib23)); Jannai
    et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib22)). Given that SRAP-Agent
    is built on human behavior simulation through LLM-based agents, we design a Turing
    test  Turing ([1950](https://arxiv.org/html/2410.14152v1#bib.bib48)) to validate
    the system’s capability to realistically simulate the policy execution process.
    We utilize GPT-3.5 and GPT-4 OpenAI ([2023](https://arxiv.org/html/2410.14152v1#bib.bib36))
    to build agents. Subsequently, we recruit a different group of human annotators
    to make paired comparisons of rationality for LLM responses and human responses.
    They choose one of these rationality labels: (1) human response is more rational
    than LLM ($Human>Robot$) (2) human response is less rational than LLM ($Human<Robot$)
    (3) both responses are rational ($Human=Robot$) (4) neither is rational ($None$).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估LLM的模拟能力，**图灵测试**Turing ([2009](https://arxiv.org/html/2410.14152v1#bib.bib49))是一个常用且有效的衡量标准，Ng等人([2024](https://arxiv.org/html/2410.14152v1#bib.bib34))；Jones和Bergen([2023](https://arxiv.org/html/2410.14152v1#bib.bib23))；Jannai等人([2023](https://arxiv.org/html/2410.14152v1#bib.bib22))。考虑到SRAP-Agent是通过基于LLM的代理来模拟人类行为的，我们设计了一个**图灵测试**Turing
    ([1950](https://arxiv.org/html/2410.14152v1#bib.bib48))来验证系统在逼真模拟政策执行过程中的能力。我们利用GPT-3.5和GPT-4
    OpenAI ([2023](https://arxiv.org/html/2410.14152v1#bib.bib36))来构建代理。随后，我们招募了一组不同的人工标注员，进行LLM响应和人类响应理性方面的配对比较。他们选择以下理性标签之一：(1)
    人类响应比LLM更理性（$Human>Robot$）；(2) 人类响应比LLM更不理性（$Human<Robot$）；(3) 两个响应都理性（$Human=Robot$）；(4)
    两个响应都不理性（$None$）。
- en: Result Analysis
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果分析
- en: 'Table [1](https://arxiv.org/html/2410.14152v1#S5.T1 "Table 1 ‣ 5.2 Turing Test
    ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent") shows the comparison of the rationality of responses
    for GPT-3.5, GPT4, and humans. We can see that: (1) The comparison between human
    responses and those from GPT-3.5 indicates a majority view that humans and agents
    perform similarly in rationality, with nearly equal proportions of judging human
    superiority ($Human>Robot$) and inferiority ($Human<Robot$) to robotic responses.
    This suggests a parity in rational decision-making capabilities between humans
    and GPT-3.5, albeit with a marginal preference for the latter. (2) In contrast,
    responses involving GPT-4 significantly outperform human counterparts in terms
    of rationality, as evidenced by a higher incidence of $Human<Robot$ compared to
    $Human>Robot$. This discrepancy underscores GPT-4’s ability to generate more strategic
    decisions, such as changing plans and waiting for future opportunities (see the
    case study in Appendix [D](https://arxiv.org/html/2410.14152v1#A4 "Appendix D
    Different LLM for Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource
    Allocation Policy with LLM-based Agent")). Specifically, GPT-4 demonstrates proficiency
    in proposing adaptive solutions and exploiting policy nuances to gain strategic
    advantages, a sophistication not commonly found in human or GPT-3.5 responses,
    which tend to focus on immediate factors like budget constraints and personal
    preferences. The findings suggest that GPT-3.5 aligns closely with the decision-making
    processes of the average individual in public scarce resource allocation. Consequently,
    we adopt the GPT-3.5-turbo-0301 model as our backbone LLM.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '表格[1](https://arxiv.org/html/2410.14152v1#S5.T1 "Table 1 ‣ 5.2 Turing Test
    ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent")展示了GPT-3.5、GPT-4和人类响应的理性比较。我们可以看到：(1) 人类响应与GPT-3.5的比较表明，大多数观点认为人类和代理在理性上表现相似，对于判断人类优于（$Human>Robot$）和劣于（$Human<Robot$）机器人响应的比例几乎相等。这表明人类和GPT-3.5在理性决策能力上相当，尽管后者略有优势。(2)
    相比之下，GPT-4的响应在理性方面显著优于人类响应，$Human<Robot$的比例明显高于$Human>Robot$。这种差异突显了GPT-4在生成更具战略性的决策方面的能力，例如改变计划和等待未来机会（见附录[D](https://arxiv.org/html/2410.14152v1#A4
    "Appendix D Different LLM for Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce
    Resource Allocation Policy with LLM-based Agent")）。具体而言，GPT-4在提出适应性解决方案和利用政策细节以获得战略优势方面表现出色，这种复杂性在人类或GPT-3.5的响应中并不常见，后者往往专注于诸如预算限制和个人偏好等即时因素。研究结果表明，GPT-3.5与普通人在公共稀缺资源分配中的决策过程高度一致。因此，我们采用GPT-3.5-turbo-0301模型作为我们的主干LLM。'
- en: 'Table 2: Comparison experiments on different combinations of entry condition
    and resource sub-sets.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不同条目条件和资源子集组合的比较实验。
- en: '| $E_{queue}$ | $R_{queue}$ | Satisfaction | Fairness |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| $E_{queue}$ | $R_{queue}$ | 满意度 | 公平性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Avg $r^{size}\uparrow$ | Avg $WT$ $\downarrow$ | $SW$ $\uparrow$ | Var $r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 平均 $r^{size}\uparrow$ | 平均 $WT$ $\downarrow$ | $SW$ $\uparrow$ | $r^{size}$
    方差 $\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '|  | $r^{random}$ | 2.5[±0.8] | 6.1[±0.3] | 83.8[±32.0] | 55.7[±18.6] | 73.5[±24.5]
    | 0.9[±0.0] |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  | $r^{random}$ | 2.5[±0.8] | 6.1[±0.3] | 83.8[±32.0] | 55.7[±18.6] | 73.5[±24.5]
    | 0.9[±0.0] |'
- en: '| $p^{select}$ | $r^{rent}$ | 7.1[±0.1] | 4.8[±0.0] | 244.6[±3.4] | 141.4[±3.2]
    | 185.0[±7.0] | 0.7[±0.0] |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| $p^{select}$ | $r^{rent}$ | 7.1[±0.1] | 4.8[±0.0] | 244.6[±3.4] | 141.4[±3.2]
    | 185.0[±7.0] | 0.7[±0.0] |'
- en: '|  | $r^{size}$ | 13.8[±0.4] | 3.1[±0.5] | 419.9[±0.3] | 229.1[±22.8] | 327.0[±26.0]
    | 0.5[±0.0] |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | $r^{size}$ | 13.8[±0.4] | 3.1[±0.5] | 419.9[±0.3] | 229.1[±22.8] | 327.0[±26.0]
    | 0.5[±0.0] |'
- en: '|  | $r^{random}$ | 10.8[±0.1] | 4.6[±0.0] | 313.1[±5.7] | 226.7[±8.1] | 366.5[±19.5]
    | 0.6[±0.0] |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | $r^{random}$ | 10.8[±0.1] | 4.6[±0.0] | 313.1[±5.7] | 226.7[±8.1] | 366.5[±19.5]
    | 0.6[±0.0] |'
- en: '| $p^{family}$ | $r^{rent}$ | 11.5[±0.0] | 3.6[±0.0] | 410.0[±3.3] | 159.3[±0.5]
    | 251.5[±1.5] | 0.5[±0.0] |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| $p^{family}$ | $r^{rent}$ | 11.5[±0.0] | 3.6[±0.0] | 410.0[±3.3] | 159.3[±0.5]
    | 251.5[±1.5] | 0.5[±0.0] |'
- en: '|  | $r^{size}$ | 11.7[±0.3] | 3.8[±0.1] | 410.4[±2.8] | 159.9[±9.4] | 254.5[±23.5]
    | 0.5[±0.0] |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  | $r^{size}$ | 11.7[±0.3] | 3.8[±0.1] | 410.4[±2.8] | 159.9[±9.4] | 254.5[±23.5]
    | 0.5[±0.0] |'
- en: '|  | $r^{random}$ | 10.0[±0.0] | 4.4[±0.1] | 313.2[±11.2] | 185.3[±15.6] |
    300.0[±10.0] | 0.6[±0.0] |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  | $r^{random}$ | 10.0[±0.0] | 4.4[±0.1] | 313.2[±11.2] | 185.3[±15.6] |
    300.0[±10.0] | 0.6[±0.0] |'
- en: '| $p^{rent}$ | $r^{rent}$ | 11.3[±0.2] | 3.9[±0.0] | 402.7[±1.4] | 163.7[±7.4]
    | 246.5[±4.5] | 0.5[±0.0] |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| $p^{rent}$ | $r^{rent}$ | 11.3[±0.2] | 3.9[±0.0] | 402.7[±1.4] | 163.7[±7.4]
    | 246.5[±4.5] | 0.5[±0.0] |'
- en: '|  | $r^{size}$ | 12.0[±0.2] | 3.9[±0.1] | 389.8[±0.8] | 195.1[±9.0] | 276.0[±31.0]
    | 0.5[±0.0] |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  | $r^{size}$ | 12.0[±0.2] | 3.9[±0.1] | 389.8[±0.8] | 195.1[±9.0] | 276.0[±31.0]
    | 0.5[±0.0] |'
- en: 'Table 3: Comparison of optimized policies $\pi^{*}$ against $\pi_{KM}$ on policy
    evaluation metrics.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：优化策略 $\pi^{*}$ 与 $\pi_{KM}$ 在策略评估指标上的比较。
- en: '| $\pi$ | $m$ | $E_{queue}$ | $S_{queue}$ | $R_{queue}$ | Satisfaction | Fairness
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| $\pi$ | $m$ | $E_{queue}$ | $S_{queue}$ | $R_{queue}$ | 满意度 | 公平性 |'
- en: '|  |  |  | Sort | $k$ | $c$ |  | Avg $r^{size}\uparrow$ | Avg $WT$ $\downarrow$
    | $SW$ $\uparrow$ | Var $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 排序 | $k$ | $c$ |  | 平均 $r^{size}\uparrow$ | 平均 $WT$ $\downarrow$
    | $SW$ $\uparrow$ | $r^{size}$ 方差 $\downarrow$ | Rop $\downarrow$ | co-Gini |'
- en: '| $\pi_{s}^{*}$ | 3 | $p^{select}$ | FIFO | 4 | 4 | $r^{size}$ | 16.3[±0.5]
    | 1.9[±0.0] | 427.6[±12.7] | 202.3[±12.9] | 221.5[±19.5] | 0.4[±0.0] |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| $\pi_{s}^{*}$ | 3 | $p^{select}$ | FIFO | 4 | 4 | $r^{size}$ | 16.3[±0.5]
    | 1.9[±0.0] | 427.6[±12.7] | 202.3[±12.9] | 221.5[±19.5] | 0.4[±0.0] |'
- en: '| $\pi_{f}^{*}$ | 3 | $p^{select}$ | VFA | 3 | 3 | $r^{size}$ | 16.2[±0.4]
    | 1.9[±0.0] | 425.1[±11.9] | 202.6[±6.6] | 193.5[±32.5] | 0.4[±0.0] |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| $\pi_{f}^{*}$ | 3 | $p^{select}$ | VFA | 3 | 3 | $r^{size}$ | 16.2[±0.4]
    | 1.9[±0.0] | 425.1[±11.9] | 202.6[±6.6] | 193.5[±32.5] | 0.4[±0.0] |'
- en: '| $\pi_{KM}$ | - | - | - | - | - | - | 16.0 | - | 485.9 | 275.7 | 511 | 0.46
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| $\pi_{KM}$ | - | - | - | - | - | - | 16.0 | - | 485.9 | 275.7 | 511 | 0.46
    |'
- en: '| $\pi_{S}$ | 1 | $p^{random}$ | FIFO | - | 3 | $r^{random}$ | 14.70[±0.63]
    | 1.89[±0.63] | 420.1[±1.9] | 202.5[±17.1] | 223[±0.5] | 0.4[±0.0] |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| $\pi_{S}$ | 1 | $p^{random}$ | FIFO | - | 3 | $r^{random}$ | 14.70[±0.63]
    | 1.89[±0.63] | 420.1[±1.9] | 202.5[±17.1] | 223[±0.5] | 0.4[±0.0] |'
- en: '| $\pi_{B}$ | 3 | $p^{select}$ | FIFO | - | 2 | $r^{size}$ | 15.36[±0.05] |
    1.56[±0.1] | 409.1[±2.4] | 270.8[±3.0] | 414.5[±0.5] | 0.5[±0.0] |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| $\pi_{B}$ | 3 | $p^{select}$ | FIFO | - | 2 | $r^{size}$ | 15.36[±0.05] |
    1.56[±0.1] | 409.1[±2.4] | 270.8[±3.0] | 414.5[±0.5] | 0.5[±0.0] |'
- en: '| $\pi_{H}$ | 1 | $p^{random}$ | VFR | 2 | 3 | $r^{random}$ | 11.61[±0.38]
    | 3.54[±0.03] | 392.1[±19.6] | 182.5[±3.18] | 275[±0.00] | 0.5[±0.0] |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| $\pi_{H}$ | 1 | $p^{random}$ | VFR | 2 | 3 | $r^{random}$ | 11.61[±0.38]
    | 3.54[±0.03] | 392.1[±19.6] | 182.5[±3.18] | 275[±0.00] | 0.5[±0.0] |'
- en: 5.3 Simulation-based Policy Analysis
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 基于仿真的策略分析
- en: 'In the ablation experiments for the policy, we conduct comparison experiments
    on each policy parameter in Equation [1](https://arxiv.org/html/2410.14152v1#S3.E1
    "In 3.1 Allocation Policy ‣ 3 SRAP-Agent ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent"). We conduct experiments
    on two policy factors: (1) resource and participant grouping: combinations of
    different $E_{queue}$ and $R_{queue}$; (2) different queue sorting strategies.
    We also simulate the phenomenon of allocation conflict in the real-world, with
    detailed information in the Appendix. [F.4](https://arxiv.org/html/2410.14152v1#A6.SS4
    "F.4 Case Study on Housing Quality ‣ Appendix F Simulation-based Policy Analysis
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent").'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '在政策的消融实验中，我们对方程[1](https://arxiv.org/html/2410.14152v1#S3.E1 "In 3.1 Allocation
    Policy ‣ 3 SRAP-Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource
    Allocation Policy with LLM-based Agent")中的每个政策参数进行了对比实验。我们对两个政策因素进行了实验：（1）资源与参与者分组：不同$E_{queue}$和$R_{queue}$的组合；（2）不同的队列排序策略。我们还模拟了现实世界中分配冲突的现象，详细信息见附录[F.4](https://arxiv.org/html/2410.14152v1#A6.SS4
    "F.4 Case Study on Housing Quality ‣ Appendix F Simulation-based Policy Analysis
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent")。'
- en: Resource and Participant Grouping
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 资源与参与者分组
- en: 'We compare the policies formed by combinations of different $E_{queue}$ and
    $R_{queue}$. In $E_{queue}$, participants primarily enter queues in three ways:
    based on budget ($p^{budget}$), based on number of family members ($p^{family}$),
    and based on self-selected queue ($p^{select}$). Corresponding to the entry conditions
    for participants, there are three methods of categorizing resource sub-sets: based
    on rental costs ($r^{rent}$), based on house size ($r^{size}$), and based on random
    categorization ($r^{random}$). Table [2](https://arxiv.org/html/2410.14152v1#S5.T2
    "Table 2 ‣ Result Analysis ‣ 5.2 Turing Test ‣ 5 Experiment ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent") shows
    the performance of different policy combinations of $E_{queue}$ and $R_{queue}$
    across various policy evaluation metrics. We can observe that:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '我们比较了由不同的$E_{queue}$和$R_{queue}$组合形成的政策。在$E_{queue}$中，参与者主要通过三种方式进入队列：基于预算($p^{budget}$)、基于家庭成员数量($p^{family}$)和基于自选队列($p^{select}$)。与参与者的入队条件对应，有三种资源子集分类方法：基于租金($r^{rent}$)、基于房屋大小($r^{size}$)和基于随机分类($r^{random}$)。表[2](https://arxiv.org/html/2410.14152v1#S5.T2
    "Table 2 ‣ Result Analysis ‣ 5.2 Turing Test ‣ 5 Experiment ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")展示了不同$E_{queue}$和$R_{queue}$政策组合在各项政策评估指标上的表现。我们可以观察到：'
- en: Queue Sorting Strategies
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 队列排序策略
- en: 'Regarding queue sorting policy $S_{queue}$. Firstly, we compare two sorting
    methods: whether to give priority to vulnerable groups or not (FIFO). We adopt
    two methods of designating vulnerable groups based on rent budget: sort all participants
    at first (VFA) and sort the participants in each round (VFR), with the bottom
    20% designated as vulnerable groups. As shown in Fig. [2a](https://arxiv.org/html/2410.14152v1#S5.F2.sf1
    "In Figure 2 ‣ Queue Sorting Strategies ‣ 5.3 Simulation-based Policy Analysis
    ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent"), prioritizing vulnerable groups can reduce the satisfaction
    gap between vulnerable and non-vulnerable groups ($\Delta F(W,G)>0$), as compared
    to the FIFO method. No marked superiority is evident between the VFA and VFR methods,
    which are influenced by the stochastic nature of participant arrival patterns.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '关于队列排序政策$S_{queue}$。首先，我们比较了两种排序方法：是否优先考虑弱势群体（FIFO）。我们采用基于租金预算的两种弱势群体指定方法：首先对所有参与者进行排序（VFA）和每轮对参与者进行排序（VFR），并将底部20%的人群指定为弱势群体。如图[2a](https://arxiv.org/html/2410.14152v1#S5.F2.sf1
    "In Figure 2 ‣ Queue Sorting Strategies ‣ 5.3 Simulation-based Policy Analysis
    ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent")所示，优先考虑弱势群体可以减少弱势群体和非弱势群体之间的满意度差距($\Delta F(W,G)>0$)，相比FIFO方法。在VFA和VFR方法之间没有明显的优劣之分，这受到参与者到达模式的随机性影响。'
- en: '![Refer to caption](img/8305325f185b11627de741d6419464b8.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/8305325f185b11627de741d6419464b8.png)'
- en: (a) sorting methods
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 排序方法
- en: '![Refer to caption](img/a8a4217cf5081e11a1b3d692e9a1f566.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a8a4217cf5081e11a1b3d692e9a1f566.png)'
- en: (b) waiting queue
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 等待队列
- en: 'Figure 2: Comparison of queue sorting methods.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：队列排序方法比较。
- en: 'Secondly, we compare the impact of the $k$ and $c$ parameters in the waitlist
    mechanism. This mechanism is primarily designed to diminish the waiting time for
    participants by increasing the chances of participants staying in the selection
    queue. As illustrated in Fig. [2b](https://arxiv.org/html/2410.14152v1#S5.F2.sf2
    "In Figure 2 ‣ Queue Sorting Strategies ‣ 5.3 Simulation-based Policy Analysis
    ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent"), increases in $k$ and the $c$ for the k-waitlist
    effectively reduce Avg $WT$, corroborating our initial expectation.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '其次，我们比较了等待名单机制中 $k$ 和 $c$ 参数的影响。该机制主要通过增加参与者留在选择队列中的机会来减少参与者的等待时间。如图 [2b](https://arxiv.org/html/2410.14152v1#S5.F2.sf2
    "图 2 ‣ 排队排序策略 ‣ 5.3 基于仿真的政策分析 ‣ 5 实验 ‣ SRAP-Agent: 使用基于 LLM 的代理模拟和优化稀缺资源分配政策")
    所示，增加 $k$ 和 $c$ 对 k-等待名单有效地减少了平均等待时间（Avg $WT$），验证了我们最初的预期。'
- en: '![Refer to caption](img/12dc062764a02d9b312412c53cb660c8.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/12dc062764a02d9b312412c53cb660c8.png)'
- en: (a) Max’s deceptive plan for broadcasting information.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: (a) Max 用于广播信息的欺骗性计划。
- en: '![Refer to caption](img/90e6710f0d2199707be21632e46fdeb9.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/90e6710f0d2199707be21632e46fdeb9.png)'
- en: (b) Sarah’s plan for requesting help from her friends.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Sarah 向她的朋友寻求帮助的计划。
- en: 'Figure 3: Deceptive behavior and cooperation behavior. Max’s conservative personality
    and lack of trustworthy acquaintances lead him to conceal his true intentions
    when sharing information. In contrast, Sarah seeks advice on choosing a house
    from her friends and openly shares her housing preferences.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：欺骗行为与合作行为。Max 的保守个性和缺乏可信赖的熟人导致他在分享信息时隐藏了自己的真实意图。相比之下，Sarah 向她的朋友寻求选择房屋的建议，并公开分享她的住房偏好。
- en: 5.4 Finding the Optimal Allocation Policy
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 寻找最优分配政策
- en: 'To evaluate the effectiveness of POA for policy parameter optimization, we
    select the following baseline policies: (1) On the single $SW$ metric, a solvable
    optimal policy exists in the expected sense. We use the Bipartite Graph Matching
    algorithm, specifically the Kuhn-Munkres algorithm Zhu et al. ([2016](https://arxiv.org/html/2410.14152v1#bib.bib57))
    to find this policy $\pi_{KM}$. (2) Additionally, we select three policies of
    scarce resource allocation from real human societies ($\pi_{S}$,$\pi_{B}$,$\pi_{H}$;
    detailed information is listed in Appendix. [G.2](https://arxiv.org/html/2410.14152v1#A7.SS2
    "G.2 Comparison with Other Policies ‣ Appendix G POA ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估 POA 在政策参数优化中的有效性，我们选择了以下基准策略：(1) 在单一的 $SW$ 指标上，存在一个可解的最优政策。我们使用二分图匹配算法，特别是
    Kuhn-Munkres 算法（Zhu 等人 [2016](https://arxiv.org/html/2410.14152v1#bib.bib57)）来找到该策略
    $\pi_{KM}$。(2) 此外，我们还选择了来自真实人类社会的三种稀缺资源分配策略（$\pi_{S}$、$\pi_{B}$、$\pi_{H}$；详细信息请见附录
    [G.2](https://arxiv.org/html/2410.14152v1#A7.SS2 "G.2 与其他策略的比较 ‣ 附录 G POA ‣ SRAP-Agent:
    使用基于 LLM 的代理模拟和优化稀缺资源分配政策")）。'
- en: Result Analysis
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果分析
- en: 'POA separately optimizes policies against two pre-set optimization objectives:
    the optimized policy $\pi_{s}^{*}$ prefers societal satisfaction, and the optimized
    policy $\pi_{f}^{*}$ prefers societal fairness. The metric weights pre-set for
    optimizing these two objectives are delineated in Table [15](https://arxiv.org/html/2410.14152v1#A7.T15
    "Table 15 ‣ G.1 Hyper-parameters for POA ‣ Appendix G POA ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent").'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 'POA 分别针对两个预设优化目标优化策略：优化后的策略 $\pi_{s}^{*}$ 更倾向于社会满意度，优化后的策略 $\pi_{f}^{*}$ 更倾向于社会公平。用于优化这两个目标的度量权重在表
    [15](https://arxiv.org/html/2410.14152v1#A7.T15 "表 15 ‣ G.1 POA 的超参数 ‣ 附录 G POA
    ‣ SRAP-Agent: 使用基于 LLM 的代理模拟和优化稀缺资源分配政策") 中列出。'
- en: '![Refer to caption](img/3ec315a2dc62d5d036afd76e4ae2828a.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3ec315a2dc62d5d036afd76e4ae2828a.png)'
- en: 'Figure 4: The average $f(\pi)$ for optimized policies with respect to the iteration
    number.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：优化策略的平均 $f(\pi)$ 与迭代次数的关系。
- en: 'Fig. [4](https://arxiv.org/html/2410.14152v1#S5.F4 "Figure 4 ‣ Result Analysis
    ‣ 5.4 Finding the Optimal Allocation Policy ‣ 5 Experiment ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent") demonstrates
    the progression of the policy optimized by POA in terms of the policy evaluation
    metric $f(\pi)$, as the number of iterations increases. The POA algorithm can
    generate robust policies after several iterations, and $f(\pi)$ improves by 20%
    after 50 iterations.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '图[4](https://arxiv.org/html/2410.14152v1#S5.F4 "Figure 4 ‣ Result Analysis
    ‣ 5.4 Finding the Optimal Allocation Policy ‣ 5 Experiment ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")展示了随着迭代次数的增加，POA优化策略在政策评估指标$f(\pi)$方面的进展。POA算法经过几轮迭代后可以生成稳健的策略，并且在50次迭代后，$f(\pi)$
    提高了20%。'
- en: 'Results of evaluation metrics for optimized policies are listed in Table [3](https://arxiv.org/html/2410.14152v1#S5.T3
    "Table 3 ‣ Result Analysis ‣ 5.2 Turing Test ‣ 5 Experiment ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"). (1) For
    real-world policies: $\pi_{H}$ prioritizes societal fairness while $\pi_{B}$ prioritizes
    societal satisfaction. $\pi_{S}$ performs the best in achieving a balance in societal
    fairness and satisfaction metrics. (2) Compared with the existing real-world policies,
    $\pi_{s}^{*}$ enhances the SW metric by 1.8%, $\pi_{f}^{*}$ enhances the societal
    fairness metric by 13.2%. (3) Although $\pi_{KM}$ surpasses $\pi^{*}$ in the $SW$
    metric. However, $\pi_{KM}$ exhibits an imbalanced emphasis on dominant groups
    of participants. This is reflected by poor performance in societal fairness metrics,
    with Rop reaching $511$. POA considers a diverse combination of metrics during
    policy optimization, thus enabling the equilibrium of all evaluation metrics while
    optimizing the target.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '优化策略的评估指标结果列在表[3](https://arxiv.org/html/2410.14152v1#S5.T3 "Table 3 ‣ Result
    Analysis ‣ 5.2 Turing Test ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent")中。（1）对于现实世界的策略：$\pi_{H}$
    优先考虑社会公平，而 $\pi_{B}$ 优先考虑社会满意度。$\pi_{S}$ 在实现社会公平和满意度指标平衡方面表现最佳。（2）与现有的现实世界策略相比，$\pi_{s}^{*}$
    提高了SW指标1.8%，$\pi_{f}^{*}$ 提高了社会公平指标13.2%。（3）尽管 $\pi_{KM}$ 在$SW$指标上超越了 $\pi^{*}$，但是
    $\pi_{KM}$ 对主导群体的参与者表现出不平衡的侧重，这体现在社会公平指标上的表现较差，Rop值达到了$511$。POA在策略优化过程中考虑了多种评估指标的多样组合，从而在优化目标的同时平衡了所有评估指标。'
- en: 5.5 Case Study
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 案例研究
- en: 'SRAP-Agent simulates the cognitive, socio-affective, and emotional factors
    of participants to simulate human interaction. We find two predominant types of
    communication patterns emerge: deceptive behavior and cooperation behavior.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: SRAP-Agent模拟了参与者的认知、社会情感和情绪因素，以模拟人类互动。我们发现出现了两种主要的沟通模式：欺骗行为和合作行为。
- en: Deceptive Behavior
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 欺骗行为
- en: 'Fig. [3a](https://arxiv.org/html/2410.14152v1#S5.F3.sf1 "In Figure 3 ‣ Queue
    Sorting Strategies ‣ 5.3 Simulation-based Policy Analysis ‣ 5 Experiment ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")
    illustrates a case where deceptive behavior occurs. In the figure, Max is a conservative
    individual with a limited number of trustworthy friends and opts to conceal the
    true information when broadcasting. Rather than disclosing his actual preferences,
    he accentuates the positive aspects of uninterested resources to enhance his chances
    of securing his interested choice. Such behaviors effectively emulate the formation
    of misinformation in policy execution.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '图[3a](https://arxiv.org/html/2410.14152v1#S5.F3.sf1 "In Figure 3 ‣ Queue Sorting
    Strategies ‣ 5.3 Simulation-based Policy Analysis ‣ 5 Experiment ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")展示了一个欺骗行为发生的案例。在图中，Max是一个保守的人，他有有限数量的可信朋友，并选择在广播时隐瞒真实信息。他并没有透露自己实际的偏好，而是强调那些他不感兴趣资源的积极方面，以增加自己获得感兴趣选择的机会。这种行为有效地模拟了政策执行中虚假信息的形成。'
- en: Cooperation Behavior
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 合作行为
- en: 'In contrast to deceptive behaviors, cooperation behaviors also exist and constitute
    the majority. As shown in Fig. [3b](https://arxiv.org/html/2410.14152v1#S5.F3.sf2
    "In Figure 3 ‣ Queue Sorting Strategies ‣ 5.3 Simulation-based Policy Analysis
    ‣ 5 Experiment ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent"), Sarah is a relatively astute person, who has two
    colleagues and a friend. She chooses to honestly post her needs and expresses
    her desire for a family-friendly house by broadcasting. It is observable that
    Sarah modifies her socialization strategies by assessing relationships, thereby
    maximizing expected benefits through cooperation. Traditional economic simulation
    models often overlook the complexities of emotional factors. In contrast, SRAP-Agent
    incorporates these dynamics, resulting in more accurate and realistic policy simulation
    outcomes.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 与欺骗性行为相对，合作行为也存在并占据主导地位。如图 [3b](https://arxiv.org/html/2410.14152v1#S5.F3.sf2
    "在图 3 ‣ 排队排序策略 ‣ 5.3 基于模拟的政策分析 ‣ 5 实验 ‣ SRAP-Agent：基于LLM代理模拟和优化稀缺资源分配政策") 所示，Sarah
    是一个相对精明的人，她有两个同事和一个朋友。她选择诚实地发布自己的需求，并通过广播表达她对家庭友好型住房的渴望。可以观察到，Sarah 通过评估人际关系调整她的社交策略，从而通过合作最大化期望收益。传统的经济模拟模型常常忽视情感因素的复杂性。相比之下，SRAP-Agent
    纳入了这些动态因素，从而产生了更准确和现实的政策模拟结果。
- en: 6 Conclusion
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this paper, we introduce a novel SRAP-Agent framework to accurately simulate
    the policy execution process in public scarce resources allocation. The framework
    establishes resource allocation queues to regulate the organization and prioritization
    of participants and resources. We employ LLM-based agents to accurately mimic
    human decision-making processes, which are influenced by a mix of rationality
    and emotional factors. To facilitate efficient policy optimization, we propose
    the POA algorithm based on genetic algorithms. Finally, we validate the framework’s
    authenticity and effectiveness through experiments in the context of public housing
    allocation. The progress in AI technologies significantly reduces costs in the
    simulation of economic policies, and SRAP-Agent represents a promising step forward
    in this field.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一种新颖的 SRAP-Agent 框架，用于准确模拟公共稀缺资源分配中的政策执行过程。该框架建立了资源分配队列，以规范参与者和资源的组织与优先级排序。我们使用基于大型语言模型（LLM）的代理，准确模拟受理性与情感因素混合影响的人的决策过程。为了促进高效的政策优化，我们提出了基于遗传算法的
    POA 算法。最后，我们通过公共住房分配背景下的实验验证了该框架的真实性和有效性。人工智能技术的进展显著降低了经济政策模拟的成本，SRAP-Agent 在这一领域代表了一个有前景的进展。
- en: Limitations
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: 'This paper acknowledges several limitations that future research could address:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本文承认未来研究可以解决的若干局限性：
- en: LLMs in SRAP-Agent is not customized for policy execution simulation. This work
    doesn’t include training or fine-tuning the LLMs for specific tasks. Instead,
    we construct an LLM-based agent through specially designed prompts and modular
    designs. This approach may result in variability in the performance of SRAP-Agent
    across different LLMs, leading to potentially non-robust outcomes.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: SRAP-Agent 中的 LLMs 并非针对政策执行模拟进行定制。本研究不包括针对特定任务对 LLMs 的训练或微调。相反，我们通过特别设计的提示和模块化设计构建了基于
    LLM 的代理。这种方法可能导致 SRAP-Agent 在不同 LLM 上的表现存在变异，从而可能导致结果不够稳健。
- en: The limitation of policy evaluation metrics. We acknowledge the limitations
    of manually defined policy evaluation metrics. Conducting societal simulation
    experiments could provide more reliable and comprehensive assessments of policy
    simulation outcomes. However, due to the vast number and scale of policies, we
    cannot afford the significant manpower and time costs. According to recent studies
    Li et al. ([2023a](https://arxiv.org/html/2410.14152v1#bib.bib30)), we believe
    that utilizing LLMs for policy evaluation is a reasonable and efficient choice.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 政策评估指标的局限性。我们承认手动定义的政策评估指标的局限性。进行社会模拟实验可以提供更可靠和全面的政策模拟结果评估。然而，由于政策的数量和规模庞大，我们无法承担巨大的人工和时间成本。根据近期的研究
    Li 等人（[2023a](https://arxiv.org/html/2410.14152v1#bib.bib30)）的观点，我们认为利用大型语言模型（LLMs）进行政策评估是一个合理且高效的选择。
- en: Ethics Statement
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 道德声明
- en: This work fully complies with the ACL Ethics Policy. We declare that there are
    no ethical issues in this paper, to the best of our knowledge.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究完全遵守 ACL 道德政策。根据我们所知，本文没有道德问题。
- en: References
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abdulkadiroğlu and Sönmez (1999) Atila Abdulkadiroğlu and Tayfun Sönmez. 1999.
    House allocation with existing tenants. *Journal of Economic Theory*, 88(2):233–260.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdulkadiroğlu 和 Sönmez（1999）Atila Abdulkadiroğlu 和 Tayfun Sönmez。1999年。有现有租户的住房分配。*经济理论期刊*，88(2)：233–260。
- en: 'Agarwal et al. (2021) Nikhil Agarwal, Itai Ashlagi, Michael A Rees, Paulo Somaini,
    and Daniel Waldinger. 2021. Equilibrium allocations under alternative waitlist
    designs: Evidence from deceased donor kidneys. *Econometrica*, 89(1):37–76.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agarwal 等人（2021）Nikhil Agarwal、Itai Ashlagi、Michael A Rees、Paulo Somaini 和 Daniel
    Waldinger。2021年。不同等待名单设计下的均衡分配：来自已故捐赠者肾脏的证据。*计量经济学*，89(1)：37–76。
- en: Anil et al. (2023) Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry
    Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng
    Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern,
    Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder,
    Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan
    Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma,
    Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo,
    Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev,
    Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad
    Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy
    Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey
    Hui, Jeremy Hurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao
    Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee,
    Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao
    Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez,
    Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom,
    Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan
    Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan
    Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R.
    So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli,
    Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin
    Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng,
    Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. 2023. [Palm 2
    technical report](http://arxiv.org/abs/2305.10403).
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anil 等人（2023）Rohan Anil、Andrew M. Dai、Orhan Firat、Melvin Johnson、Dmitry Lepikhin、Alexandre
    Passos、Siamak Shakeri、Emanuel Taropa、Paige Bailey、Zhifeng Chen、Eric Chu、Jonathan
    H. Clark、Laurent El Shafey、Yanping Huang、Kathy Meier-Hellstern、Gaurav Mishra、Erica
    Moreira、Mark Omernick、Kevin Robinson、Sebastian Ruder、Yi Tay、Kefan Xiao、Yuanzhong
    Xu、Yujing Zhang、Gustavo Hernandez Abrego、Junwhan Ahn、Jacob Austin、Paul Barham、Jan
    Botha、James Bradbury、Siddhartha Brahma、Kevin Brooks、Michele Catasta、Yong Cheng、Colin
    Cherry、Christopher A. Choquette-Choo、Aakanksha Chowdhery、Clément Crepy、Shachi
    Dave、Mostafa Dehghani、Sunipa Dev、Jacob Devlin、Mark Díaz、Nan Du、Ethan Dyer、Vlad
    Feinberg、Fangxiaoyu Feng、Vlad Fienber、Markus Freitag、Xavier Garcia、Sebastian Gehrmann、Lucas
    Gonzalez、Guy Gur-Ari、Steven Hand、Hadi Hashemi、Le Hou、Joshua Howland、Andrea Hu、Jeffrey
    Hui、Jeremy Hurwitz、Michael Isard、Abe Ittycheriah、Matthew Jagielski、Wenhao Jia、Kathleen
    Kenealy、Maxim Krikun、Sneha Kudugunta、Chang Lan、Katherine Lee、Benjamin Lee、Eric
    Li、Music Li、Wei Li、YaGuang Li、Jian Li、Hyeontaek Lim、Hanzhao Lin、Zhongtao Liu、Frederick
    Liu、Marcello Maggioni、Aroma Mahendru、Joshua Maynez、Vedant Misra、Maysam Moussalem、Zachary
    Nado、John Nham、Eric Ni、Andrew Nystrom、Alicia Parrish、Marie Pellat、Martin Polacek、Alex
    Polozov、Reiner Pope、Siyuan Qiao、Emily Reif、Bryan Richter、Parker Riley、Alex Castro
    Ros、Aurko Roy、Brennan Saeta、Rajkumar Samuel、Renee Shelby、Ambrose Slone、Daniel
    Smilkov、David R. So、Daniel Sohn、Simon Tokumine、Dasha Valter、Vijay Vasudevan、Kiran
    Vodrahalli、Xuezhi Wang、Pidong Wang、Zirui Wang、Tao Wang、John Wieting、Yuhuai Wu、Kelvin
    Xu、Yunhan Xu、Linting Xue、Pengcheng Yin、Jiahui Yu、Qiao Zhang、Steven Zheng、Ce Zheng、Weikang
    Zhou、Denny Zhou、Slav Petrov 和 Yonghui Wu。2023年。[Palm 2技术报告](http://arxiv.org/abs/2305.10403)。
- en: 'Banerjee and Somanathan (2007) Abhijit Banerjee and Rohini Somanathan. 2007.
    [The political economy of public goods: Some evidence from india](https://doi.org/https://doi.org/10.1016/j.jdeveco.2006.04.005).
    *Journal of Development Economics*, 82(2):287–314.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banerjee 和 Somanathan（2007）Abhijit Banerjee 和 Rohini Somanathan。2007年。[公共物品的政治经济学：来自印度的一些证据](https://doi.org/https://doi.org/10.1016/j.jdeveco.2006.04.005)。*发展经济学期刊*，82(2)：287–314。
- en: Bansal et al. (2018) Trapit Bansal, Jakub Pachocki, Szymon Sidor, Ilya Sutskever,
    and Igor Mordatch. 2018. [Emergent complexity via multi-agent competition](https://openreview.net/forum?id=Sy0GnUxCb).
    ICLR ’18.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bansal 等人（2018）Trapit Bansal、Jakub Pachocki、Szymon Sidor、Ilya Sutskever 和 Igor
    Mordatch。2018年。[通过多智能体竞争出现的复杂性](https://openreview.net/forum?id=Sy0GnUxCb)。ICLR
    '18。
- en: 'Bloch and Cantala (2017) Francis Bloch and David Cantala. 2017. Dynamic assignment
    of objects to queuing agents. *American Economic Journal: Microeconomics*, 9(1):88–122.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bloch 和 Cantala（2017）Francis Bloch 和 David Cantala。2017年。对象动态分配给排队代理人。*美国经济学期刊：微观经济学*，9(1)：88–122。
- en: 'Blümel et al. (1986) Wolfgang Blümel, Rüdiger Pethig, and Oskar von dem Hagen.
    1986. [The theory of public goods : A survey of recent issues](http://www.jstor.org/stable/40750871).
    *Journal of Institutional and Theoretical Economics (JITE) / Zeitschrift für die
    gesamte Staatswissenschaft*, (2):241–309.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blümel 等人 (1986) Wolfgang Blümel, Rüdiger Pethig 和 Oskar von dem Hagen. 1986.
    [公共物品理论：近期问题综述](http://www.jstor.org/stable/40750871). *制度与理论经济学杂志（JITE） / 全体国家科学杂志*,
    (2):241–309.
- en: 'Bonabeau (2002) Eric Bonabeau. 2002. [Agent-based modeling: Methods and techniques
    for simulating human systems](https://doi.org/10.1073/pnas.082080899). *Proceedings
    of the National Academy of Sciences of the United States of America*, 99 Suppl
    3:7280–7.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bonabeau (2002) Eric Bonabeau. 2002. [基于代理的建模：模拟人类系统的方法与技术](https://doi.org/10.1073/pnas.082080899).
    *美国国家科学院院刊*, 99 Suppl 3:7280–7.
- en: BROCK (1980) WILLIAM A. BROCK. 1980. [The design of mechanisms for efficient
    allocation of public goods](https://doi.org/https://doi.org/10.1016/B978-1-4832-2792-4.50009-8).
    In L.R. KLEIN, M. NERLOVE, and S.C. TSIANG, editors, *Quantitative Economics and
    Development*, pages 45–80\. Academic Press.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BROCK (1980) WILLIAM A. BROCK. 1980. [有效配置公共物品的机制设计](https://doi.org/https://doi.org/10.1016/B978-1-4832-2792-4.50009-8).
    在L.R. KLEIN, M. NERLOVE 和 S.C. TSIANG 主编, *定量经济学与发展*, 页45–80. Academic Press.
- en: Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, et al. 2020. Language models are few-shot learners. *Advances in neural
    information processing systems*, 33:1877–1901.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人 (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell 等人. 2020. 语言模型是少量样本学习者. *神经信息处理系统进展*, 33:1877–1901.
- en: Chen et al. (2018) Zhou Chen, Qi Qi, Changjun Wang, and Wenwei Wang. 2018. *Available
    at SSRN 3203280*.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2018) Zhou Chen, Qi Qi, Changjun Wang 和 Wenwei Wang. 2018. *可在SSRN
    3203280获取*.
- en: Claus and Boutilier (1998) Caroline Claus and Craig Boutilier. 1998. The dynamics
    of reinforcement learning in cooperative multiagent systems. AAAI ’98/IAAI ’98,
    page 746–752.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Claus 和 Boutilier (1998) Caroline Claus 和 Craig Boutilier. 1998. 合作多智能体系统中强化学习的动态.
    AAAI ’98/IAAI ’98, 页746–752.
- en: Dillion et al. (2023) Danica Dillion, Niket Tandon, Yuling Gu, and Kurt Gray.
    2023. [Can ai language models replace human participants?](https://doi.org/https://doi.org/10.1016/j.tics.2023.04.008)
    *Trends in Cognitive Sciences*, 27(7):597–600.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dillion 等人 (2023) Danica Dillion, Niket Tandon, Yuling Gu 和 Kurt Gray. 2023.
    [AI语言模型能否替代人类参与者？](https://doi.org/https://doi.org/10.1016/j.tics.2023.04.008)
    *认知科学趋势*, 27(7):597–600.
- en: 'Falkinger et al. (2000) Josef Falkinger, Ernst Fehr, Simon Gächter, and Rudolf
    Winter-Ember. 2000. [A simple mechanism for the efficient provision of public
    goods: Experimental evidence](https://doi.org/10.1257/aer.90.1.247). *American
    Economic Review*, 90(1):247–264.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Falkinger 等人 (2000) Josef Falkinger, Ernst Fehr, Simon Gächter 和 Rudolf Winter-Ember.
    2000. [有效提供公共物品的简单机制：实验证据](https://doi.org/10.1257/aer.90.1.247). *美国经济评论*, 90(1):247–264.
- en: Farmer and Foley (2009) J. Doyne Farmer and Duncan K. Foley. 2009. [The economy
    needs agent-based modelling](https://api.semanticscholar.org/CorpusID:37676798).
    *Nature*, 460:685–686.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Farmer 和 Foley (2009) J. Doyne Farmer 和 Duncan K. Foley. 2009. [经济需要基于代理的建模](https://api.semanticscholar.org/CorpusID:37676798).
    *自然*, 460:685–686.
- en: Fu et al. (2020) Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang,
    Yingqiang Ge, Shuyuan Xu, Shijie Geng, Chirag Shah, Yongfeng Zhang, et al. 2020.
    Fairness-aware explainable recommendation over knowledge graphs. SIGIR ’20, pages
    69–78.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fu 等人 (2020) Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang,
    Yingqiang Ge, Shuyuan Xu, Shijie Geng, Chirag Shah, Yongfeng Zhang 等人. 2020. 基于公平性的可解释推荐系统在知识图谱中的应用.
    SIGIR ’20, 页69–78.
- en: Groves and Ledyard (1974) Theodore Groves and John Ledyard. 1974. An incentive
    mechanism for efficient resource allocation in general equilibrium with public
    goods. Technical report, Discussion Paper.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Groves 和 Ledyard (1974) Theodore Groves 和 John Ledyard. 1974. 一种有效资源配置的激励机制——一般均衡下的公共物品.
    技术报告, 讨论论文.
- en: Holland and Miller (1991) John H. Holland and John H. Miller. 1991. [Artificial
    adaptive agents in economic theory](http://www.jstor.org/stable/2006886). *The
    American Economic Review*, 81(2):365–370.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holland和Miller (1991) John H. Holland 和 John H. Miller. 1991. [经济理论中的人工适应代理人](http://www.jstor.org/stable/2006886).
    *美国经济评论*, 81(2):365–370.
- en: 'Huang et al. (2015) Zhonghua Huang, Xuejun Du, and Xiaofen Yu. 2015. [Home
    ownership and residential satisfaction: Evidence from hangzhou, china](https://doi.org/https://doi.org/10.1016/j.habitatint.2015.05.008).
    *Habitat International*, 49:74–83.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2015）Zhonghua Huang, Xuejun Du, 和 Xiaofen Yu. 2015. [《房屋拥有与居住满意度：来自中国杭州的证据》](https://doi.org/https://doi.org/10.1016/j.habitatint.2015.05.008).
    *国际栖息地期刊*，49：74–83。
- en: Hylland and Zeckhauser (1979) Aanund Hylland and Richard Zeckhauser. 1979. The
    efficient allocation of individuals to positions. *Journal of Political economy*,
    87(2):293–314.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hylland 和 Zeckhauser（1979）Aanund Hylland 和 Richard Zeckhauser. 1979. 《个体分配到职位的有效性》。*政治经济学杂志*，87(2)：293–314。
- en: Jaderberg et al. (2019) Max Jaderberg, Wojciech M. Czarnecki, Iain Dunning,
    Luke Marris, Guy Lever, Antonio Garcia Castañeda, Charles Beattie, Neil C. Rabinowitz,
    Ari S. Morcos, Avraham Ruderman, Nicolas Sonnerat, Tim Green, Louise Deason, Joel Z.
    Leibo, David Silver, Demis Hassabis, Koray Kavukcuoglu, and Thore Graepel. 2019.
    [Human-level performance in 3d multiplayer games with population-based reinforcement
    learning](https://doi.org/10.1126/science.aau6249). *Science*, 364(6443):859–865.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaderberg 等人（2019）Max Jaderberg, Wojciech M. Czarnecki, Iain Dunning, Luke Marris,
    Guy Lever, Antonio Garcia Castañeda, Charles Beattie, Neil C. Rabinowitz, Ari
    S. Morcos, Avraham Ruderman, Nicolas Sonnerat, Tim Green, Louise Deason, Joel
    Z. Leibo, David Silver, Demis Hassabis, Koray Kavukcuoglu, 和 Thore Graepel. 2019.
    [《在3D多人游戏中，通过基于人群的强化学习达到人类水平表现》](https://doi.org/10.1126/science.aau6249). *科学*，364(6443)：859–865。
- en: Jannai et al. (2023) Daniel Jannai, Amos Meron, Barak Lenz, Yoav Levine, and
    Yoav Shoham. 2023. Human or not? a gamified approach to the turing test. *arXiv
    preprint arXiv:2305.20010*.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jannai 等人（2023）Daniel Jannai, Amos Meron, Barak Lenz, Yoav Levine, 和 Yoav Shoham.
    2023. 《人类还是非人类？一种游戏化的图灵测试方法》。*arXiv 预印本 arXiv:2305.20010*。
- en: Jones and Bergen (2023) Cameron Jones and Benjamin Bergen. 2023. Does gpt-4
    pass the turing test? *arXiv preprint arXiv:2310.20216*.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jones 和 Bergen（2023）Cameron Jones 和 Benjamin Bergen. 2023. 《GPT-4 能通过图灵测试吗？》*arXiv
    预印本 arXiv:2310.20216*。
- en: 'Jr et al. (1977) Theodore Jr, Theodore Groves, and John Ledyard. 1977. [Optimal
    allocation of public goods: A solution to the "free rider" problem](https://doi.org/10.2307/1912672).
    *Econometrica*, 45:783–809.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jr 等人（1977）Theodore Jr, Theodore Groves, 和 John Ledyard. 1977. [《公共物品的最优分配：解决“搭便车”问题》](https://doi.org/10.2307/1912672).
    *计量经济学*，45：783–809。
- en: Kim (2015) Tae Kyun Kim. 2015. T test as a parametric statistic. *Korean journal
    of anesthesiology*, 68(6):540.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim（2015）Tae Kyun Kim. 2015. 《t检验作为一种参数统计方法》。*韩国麻醉学杂志*，68(6)：540。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf).
    NIPS ’22, pages 22199–22213\. Curran Associates, Inc.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo,
    和 Yusuke Iwasawa. 2022. [《大语言模型是零-shot推理者》](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf).
    NIPS ’22, 页码22199–22213。Curran Associates, Inc.
- en: Lambora et al. (2019) Annu Lambora, Kunal Gupta, and Kriti Chopra. 2019. Genetic
    algorithm-a literature review. In *2019 international conference on machine learning,
    big data, cloud and parallel computing (COMITCon)*, pages 380–384\. IEEE.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambora 等人（2019）Annu Lambora, Kunal Gupta, 和 Kriti Chopra. 2019. 《遗传算法——文献综述》。在
    *2019国际机器学习、大数据、云计算与并行计算会议（COMITCon）*，页码380–384。IEEE。
- en: Laurent et al. (2011) Guillaume J. Laurent, Laëtitia Matignon, and N. Le Fort-Piat.
    2011. The world of independent learners is not markovian. *Int. J. Know.-Based
    Intell. Eng. Syst.*, 15(1):55–64.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laurent 等人（2011）Guillaume J. Laurent, Laëtitia Matignon, 和 N. Le Fort-Piat.
    2011. 《独立学习者的世界不是马尔科夫的》。*国际知识基础智能工程系统期刊*，15(1)：55–64。
- en: 'Lewis et al. (2000) Steven Lewis, Morris L Barer, Claudia Sanmartin, Sam Sheps,
    Samuel ED Shortt, and Paul W McDonald. 2000. Ending waiting-list mismanagement:
    principles and practice. *Cmaj*, 162(9):1297–1300.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis 等人（2000）Steven Lewis, Morris L Barer, Claudia Sanmartin, Sam Sheps, Samuel
    ED Shortt, 和 Paul W McDonald. 2000. 《结束等候名单管理不善：原则与实践》。*加拿大医学杂志*，162(9)：1297–1300。
- en: 'Li et al. (2023a) Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii
    Khizbullin, and Bernard Ghanem. 2023a. Camel: Communicative agents for "mind"
    exploration of large language model society. NIPS ’23.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2023a）Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin,
    和 Bernard Ghanem. 2023a. 《骆驼：用于大语言模型社会“心智”探索的交流代理》。NIPS ’23。
- en: Li et al. (2023b) Nian Li, Chen Gao, Yong Li, and Qingmin Liao. 2023b. Large
    language model-empowered agents for simulating macroeconomic activities. *arXiv
    preprint arXiv:2310.10436*.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2023b）Nian Li, Chen Gao, Yong Li, 和 Qingmin Liao. 2023b. 《大语言模型赋能的代理模拟宏观经济活动》。*arXiv
    预印本 arXiv:2310.10436*。
- en: Mankiw (2011) N.G. Mankiw. 2011. [*Principles of Economics, 5th edition*](http://mankiw.swlearning.com/).
    South-Western Cengage Learning. The Introductory-Level Textbook.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mankiw（2011）N.G. Mankiw。2011年。[*经济学原理，第5版*](http://mankiw.swlearning.com/)。South-Western
    Cengage Learning。入门级教材。
- en: Miller et al. (1995) Brad L Miller, David E Goldberg, et al. 1995. Genetic algorithms,
    tournament selection, and the effects of noise. *Complex systems*, 9(3):193–212.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miller 等人（1995）Brad L Miller, David E Goldberg 等人。1995年。遗传算法、锦标赛选择与噪声的影响。*复杂系统*，9(3):193–212。
- en: Ng et al. (2024) Man Tik Ng, Hui Tung Tse, Jen-tse Huang, Jingjing Li, Wenxuan
    Wang, and Michael R Lyu. 2024. How well can llms echo us? evaluating ai chatbots’
    role-play ability with echo. *arXiv preprint arXiv:2404.13957*.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ng 等人（2024）Man Tik Ng, Hui Tung Tse, Jen-tse Huang, Jingjing Li, Wenxuan Wang
    和 Michael R Lyu。2024年。大型语言模型能多好地模仿我们？评估 AI 聊天机器人通过回声进行角色扮演的能力。*arXiv 预印本 arXiv:2404.13957*。
- en: 'Nold (1992) Patricia Ann Nold. 1992. [Public choice and the allocation of public
    goods: An empirical analysis of local school expenditures](http://www.jstor.org/stable/2117444).
    *The American Economic Review*, 82(2):457–463.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nold（1992）Patricia Ann Nold。1992年。[公共选择与公共物品分配：地方学校支出的实证分析](http://www.jstor.org/stable/2117444)。*美国经济评论*，82(2):457–463。
- en: OpenAI (2023) OpenAI. 2023. [Gpt-4 technical report](http://arxiv.org/abs/2303.08774).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023）OpenAI。2023年。[Gpt-4 技术报告](http://arxiv.org/abs/2303.08774)。
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. [Generative agents: Interactive
    simulacra of human behavior](https://doi.org/10.1145/3586183.3606763). UIST ’23.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2023）Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang 和 Michael S. Bernstein。2023年。[生成智能体：人类行为的互动拟像](https://doi.org/10.1145/3586183.3606763)。UIST
    ’23。
- en: 'Park et al. (2022) Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2022. [Social simulacra: Creating
    populated prototypes for social computing systems](https://doi.org/10.1145/3526113.3545616).
    UIST ’22.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2022）Joon Sung Park, Lindsay Popowski, Carrie Cai, Meredith Ringel Morris,
    Percy Liang 和 Michael S. Bernstein。2022年。[社会拟像：为社会计算系统创建人口化原型](https://doi.org/10.1145/3526113.3545616)。UIST
    ’22。
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2023）Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan
    Xu, Zhiyuan Liu, 和 Maosong Sun。2023年。软件开发中的交互式智能体。*arXiv 预印本 arXiv:2307.07924*。
- en: Shapley and Scarf (1974) Lloyd Shapley and Herbert Scarf. 1974. On cores and
    indivisibility. *Journal of mathematical economics*, 1(1):23–37.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shapley 和 Scarf（1974）Lloyd Shapley 和 Herbert Scarf。1974年。核心与不可分割性。*数学经济学杂志*，1(1):23–37。
- en: Shen (2015) Yang Shen. 2015. Why does the government fail to improve the living
    conditions of migrant workers in s hanghai? reflections on the policies and the
    implementations of public rental housing under neoliberalism. *Asia & the Pacific
    Policy Studies*, 2(1):58–74.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen（2015）Yang Shen。2015年。为什么政府未能改善上海农民工的生活条件？对新自由主义下公共租赁住房政策与实施的反思。*亚洲与太平洋政策研究*，2(1):58–74。
- en: 'Shinn et al. (2023) Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath,
    Karthik Narasimhan, and Shunyu Yao. 2023. Reflexion: Language agents with verbal
    reinforcement learning. *arXiv preprint arXiv:2303.11366*.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shinn 等人（2023）Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath,
    Karthik Narasimhan 和 Shunyu Yao。2023年。Reflexion：带有语言强化学习的语言智能体。*arXiv 预印本 arXiv:2303.11366*。
- en: Sönmez (1999) Tayfun Sönmez. 1999. Strategy-proofness and essentially single-valued
    cores. *Econometrica*, 67(3):677–689.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sönmez（1999）Tayfun Sönmez。1999年。策略无关性与实质单值核心。*计量经济学*，67(3):677–689。
- en: Sönmez and Ünver (2011) Tayfun Sönmez and M Utku Ünver. 2011. Matching, allocation,
    and exchange of discrete resources. In *Handbook of social Economics*, volume 1,
    pages 781–852\. Elsevier.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sönmez 和 Ünver（2011）Tayfun Sönmez 和 M Utku Ünver。2011年。离散资源的匹配、分配与交换。在 *社会经济学手册*
    第1卷，第781–852页。Elsevier。
- en: 'Su and Zenios (2004) Xuanming Su and Stefanos Zenios. 2004. Patient choice
    in kidney allocation: The role of the queueing discipline. *Manufacturing & Service
    Operations Management*, 6(4):280–301.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 和 Zenios（2004）Xuanming Su 和 Stefanos Zenios。2004年。肾脏分配中的患者选择：排队规则的作用。*制造与服务运作管理*，6(4):280–301。
- en: 'Su and Zenios (2005) Xuanming Su and Stefanos A Zenios. 2005. Patient choice
    in kidney allocation: A sequential stochastic assignment model. *Operations research*,
    53(3):443–455.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 和 Zenios（2005）Xuanming Su 和 Stefanos A Zenios。2005年。肾脏分配中的患者选择：一种顺序随机分配模型。*运筹学*，53(3):443–455。
- en: 'Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert,
    Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,
    Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem
    Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia
    Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou,
    Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem
    Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana
    Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra,
    Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan
    Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen
    Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng
    Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang,
    Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. [Llama
    2: Open foundation and fine-tuned chat models](http://arxiv.org/abs/2307.09288).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron 等人 (2023) Hugo Touvron、Louis Martin、Kevin Stone、Peter Albert、Amjad Almahairi、Yasmine
    Babaei、Nikolay Bashlykov、Soumya Batra、Prajjwal Bhargava、Shruti Bhosale、Dan Bikel、Lukas
    Blecher、Cristian Canton Ferrer、Moya Chen、Guillem Cucurull、David Esiobu、Jude Fernandes、Jeremy
    Fu、Wenyin Fu、Brian Fuller、Cynthia Gao、Vedanuj Goswami、Naman Goyal、Anthony Hartshorn、Saghar
    Hosseini、Rui Hou、Hakan Inan、Marcin Kardas、Viktor Kerkez、Madian Khabsa、Isabel Kloumann、Artem
    Korenev、Punit Singh Koura、Marie-Anne Lachaux、Thibaut Lavril、Jenya Lee、Diana Liskovich、Yinghai
    Lu、Yuning Mao、Xavier Martinet、Todor Mihaylov、Pushkar Mishra、Igor Molybog、Yixin
    Nie、Andrew Poulton、Jeremy Reizenstein、Rashi Rungta、Kalyan Saladi、Alan Schelten、Ruan
    Silva、Eric Michael Smith、Ranjan Subramanian、Xiaoqing Ellen Tan、Binh Tang、Ross
    Taylor、Adina Williams、Jian Xiang Kuan、Puxin Xu、Zheng Yan、Iliyan Zarov、Yuchen Zhang、Angela
    Fan、Melanie Kambadur、Sharan Narang、Aurelien Rodriguez、Robert Stojnic、Sergey Edunov
    和 Thomas Scialom。2023. [Llama 2：开放基础与微调的聊天模型](http://arxiv.org/abs/2307.09288)。
- en: Turing (1950) Alan M. Turing. 1950. [Computing machinery and intelligence](https://doi.org/10.1093/mind/lix.236.433).
    *Mind*, 59(October):433–60.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turing (1950) Alan M. Turing。1950. [计算机械与智能](https://doi.org/10.1093/mind/lix.236.433)。发表于《*Mind*》，59(10月)：433–60。
- en: Turing (2009) Alan M Turing. 2009. *Computing machinery and intelligence*. Springer.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Turing (2009) Alan M Turing。2009. *计算机械与智能*。Springer。
- en: 'Vermunt and Törnblom (1996) Riël Vermunt and Kjell Törnblom. 1996. [Introduction:
    Distributive and procedural justice](https://doi.org/10.1007/BF02196987). *Social
    Justice Research*, 9:305–310.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vermunt 和 Törnblom (1996) Riël Vermunt 和 Kjell Törnblom。1996. [导言：分配与程序正义](https://doi.org/10.1007/BF02196987)。发表于《*社会正义研究*》，9:305–310。
- en: 'Wang et al. (2023a) Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song,
    Wayne Xin Zhao, and Ji-Rong Wen. 2023a. Recagent: A novel simulation paradigm
    for recommender systems. *arXiv preprint arXiv:2306.02552*.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2023a) 王雷、张景森、陈旭、林彦凯、宋瑞华、赵伟鑫 和 温吉荣。2023a. Recagent：一种用于推荐系统的新型仿真范式。*arXiv
    预印本 arXiv:2306.02552*。
- en: Wang et al. (2023b) Yifan Wang, Weizhi Ma, Min Zhang, Yiqun Liu, and Shaoping
    Ma. 2023b. [A survey on the fairness of recommender systems](https://doi.org/10.1145/3547333).
    *ACM Trans. Inf. Syst.*, 41(3).
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 (2023b) 王一帆、马伟志、张敏、刘一群 和 马少平。2023b. [推荐系统公平性的调研](https://doi.org/10.1145/3547333)。发表于《*ACM
    信息系统学报*》，41(3)。
- en: 'Wang et al. (2023c) Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian (Shawn)
    Ma, and Yitao Liang. 2023c. [Describe, explain, plan and select: Interactive planning
    with llms enables open-world multi-task agents](https://proceedings.neurips.cc/paper_files/paper/2023/file/6b8dfb8c0c12e6fafc6c256cb08a5ca7-Paper-Conference.pdf).
    In *Advances in Neural Information Processing Systems*, volume 36, pages 34153–34189\.
    Curran Associates, Inc.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等人 (2023c) 王子豪、蔡绍飞、陈冠洲、刘安吉、马晓健（Shawn）、梁怡涛。2023c. [描述、解释、规划与选择：使用大型语言模型的互动规划启用开放世界多任务智能体](https://proceedings.neurips.cc/paper_files/paper/2023/file/6b8dfb8c0c12e6fafc6c256cb08a5ca7-Paper-Conference.pdf)。发表于《*神经信息处理系统进展*》，第36卷，第34153–34189页。Curran
    Associates, Inc.
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian
    ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-thought prompting
    elicits reasoning in large language models. NIPS ’22.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 (2022) Jason Wei、王学智、Dale Schuurmans、Maarten Bosma、brian ichter、Fei Xia、Ed
    Chi、Quoc V Le 和 Denny Zhou。2022. 连锁思维提示引发大型语言模型的推理能力。NIPS ’22。
- en: 'Yao et al. (2022) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting
    in language models. *arXiv preprint arXiv:2210.03629*.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人 (2022) Shunyu Yao、Jeffrey Zhao、Dian Yu、Nan Du、Izhak Shafran、Karthik Narasimhan
    和 Yuan Cao。2022. React：在语言模型中协同推理与行动。*arXiv 预印本 arXiv:2210.03629*。
- en: 'Zheng et al. (2022) Stephan Zheng, Alexander Trott, Sunil Srinivasa, David C.
    Parkes, and Richard Socher. 2022. [The ai economist: Taxation policy design via
    two-level deep multiagent reinforcement learning](https://doi.org/10.1126/sciadv.abk2607).
    *Science Advances*, 8(18):eabk2607.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人（2022）Stephan Zheng, Alexander Trott, Sunil Srinivasa, David C. Parkes
    和 Richard Socher. 2022. [人工智能经济学家：通过双层深度多代理强化学习设计税收政策](https://doi.org/10.1126/sciadv.abk2607)。*Science
    Advances*, 8(18):eabk2607。
- en: Zhu et al. (2016) Haibin Zhu, Dongning Liu, Siqin Zhang, Yu Zhu, Luyao Teng,
    and Shaohua Teng. 2016. Solving the many to many assignment problem by improving
    the kuhn–munkres algorithm with backtracking. *Theoretical Computer Science*,
    618:30–41.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2016）Haibin Zhu, Dongning Liu, Siqin Zhang, Yu Zhu, Luyao Teng 和 Shaohua
    Teng. 2016. 通过改进带回溯的 Kuhn–Munkres 算法解决多对多分配问题。*Theoretical Computer Science*,
    618:30–41。
- en: Appendix A Allocation Policy
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 分配政策
- en: In our experiment, the public scarce resources are specified as houses and the
    participants are specified as tenants. We construct $m$ queues in SRAP-Agent.
    Each queue $q_{i}$ is uniquely characterized by $E_{queue}(i)$, $S_{queue}$ and
    $R_{queue}(i)$.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，公共稀缺资源被指定为房屋，参与者被指定为租户。我们在 SRAP-Agent 中构建了 $m$ 个队列。每个队列 $q_{i}$ 都由 $E_{queue}(i)$、$S_{queue}$
    和 $R_{queue}(i)$ 唯一表征。
- en: Participant entry conditions
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参与者进入条件
- en: 'Each participant $p_{j}$ is assigned to a queue $q_{i}$ when satisfying entry
    conditions $E_{queue}(i)$. Participants can only choose from houses within their
    queue. The specified entry conditions for participants include: (1) based on the
    rent budget of participant ($p^{rent}$): participants are sorted based on their
    rental budget and divided into $m$ queues in a pre-defined proportion, with $m\in[1,5]$
    in experiments. (2) based on the number of family members ($p^{family}$): similar
    to $p^{rent}$ grouping, participants are sorted by the number of their family
    members. (3) based on self-selection of the queue ($p^{select}$): participants
    are provided with basic information about the queues, and they need to choose
    one queue from them.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 当满足进入条件 $E_{queue}(i)$ 时，每个参与者 $p_{j}$ 会被分配到队列 $q_{i}$。参与者只能从所在队列中的房屋中选择。参与者的指定进入条件包括：（1）基于参与者的租金预算
    ($p^{rent}$)：参与者根据租金预算排序，并按预定义比例分配到 $m$ 个队列中，实验中 $m\in[1,5]$。（2）基于家庭成员数量 ($p^{family}$)：类似于
    $p^{rent}$ 的分组，参与者根据家庭成员数量进行排序。（3）基于队列自选 ($p^{select}$)：参与者提供队列的基本信息，并需要从中选择一个队列。
- en: To regulate the entry velocity of resources and participants into queues, we
    configure the maximum entry number of participants $Batch_{num}^{P}$, the maximum
    entry number of resources $Batch_{num}^{R}$ for resources.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了调节资源和参与者进入队列的速度，我们配置了参与者的最大进入数量 $Batch_{num}^{P}$ 和资源的最大进入数量 $Batch_{num}^{R}$。
- en: Queue sorting strategies
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 队列排序策略
- en: In the *priority for vulnerable groups* sorting strategy, we adopt two methodologies
    of designating vulnerable groups. We either sort all participants at first or
    sort the participants in each round based on the per capita rental budget, the
    bottom 20% in terms of per capita rental budget are designated as vulnerable groups.
    Vulnerable groups are prioritized at the beginning of each queuing.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在*弱势群体优先*排序策略中，我们采用了两种设计弱势群体的方法。我们要么首先对所有参与者进行排序，要么在每一轮中根据人均租金预算排序，按人均租金预算排名最低的
    20% 参与者被指定为弱势群体。弱势群体在每次排队时优先进入。
- en: Available resource sub-sets
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可用资源子集
- en: 'To ensure a uniform distribution of participants and housing resources, while
    maximizing the choice space for participants, we offer various ways for resource
    categorization. Following the entry conditions of participants, the resource sub-sets
    allocated to $q_{i}$ are defined by: (1) based on house size ($r^{size}$): houses
    are sorted by their rental area size and allocated into $m$ queues. The division
    is carried out in proportion to the number of participants in different queues.
    (2) based on house rent ($r^{rent}$): similar to $r^{size}$, houses are sorted
    by rent. (3) based on randomly distribution of houses ($r^{random}$): houses are
    randomly divided into $m$ groups.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保参与者和住房资源的均匀分布，同时最大化参与者的选择空间，我们提供了多种资源分类方式。根据参与者的进入条件，分配给队列 $q_{i}$ 的资源子集由以下方式定义：（1）基于房屋大小
    ($r^{size}$)：房屋按租赁面积大小排序，并分配到 $m$ 个队列中。划分的比例与不同队列中的参与者数量成正比。（2）基于房屋租金 ($r^{rent}$)：类似于
    $r^{size}$，房屋按租金排序。（3）基于房屋的随机分配 ($r^{random}$)：房屋随机分配到 $m$ 个组中。
- en: Appendix B LLM Agent-based Participant Simulation
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 基于 LLM 代理的参与者仿真
- en: B.1 Agent Architecture
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.1 代理架构
- en: In the initialization phase of an LLM-based agent, profiling typically serves
    as the foundational stage for constructing the agent, which determines the preferences,
    personalities, and behavior patterns of different participants. Similar to the
    methodology employed in Park et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib37));
    Qian et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib39)), we use personalized
    profile files $r_{i}$ to build $p_{i}$, which mainly encompass attributes such
    as age, familial connections, etc. $r_{i}$ serves as foundational seed memory
    for the agent. To optimize operational efficiency, we impose a set of predefined
    constraints to automatically generate agent profiles using LLM, akin to the approach
    described in RecAgent Wang et al. ([2023a](https://arxiv.org/html/2410.14152v1#bib.bib51)).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于LLM的代理的初始化阶段，个人资料通常作为构建代理的基础阶段，决定不同参与者的偏好、个性和行为模式。与Park等人（[2023](https://arxiv.org/html/2410.14152v1#bib.bib37)）和Qian等人（[2023](https://arxiv.org/html/2410.14152v1#bib.bib39)）采用的方法类似，我们使用个性化的个人资料文件$r_{i}$来构建$p_{i}$，这些文件主要包括年龄、家庭关系等属性。$r_{i}$作为代理的基础种子记忆。为了优化操作效率，我们施加了一组预定义的约束，利用LLM自动生成代理的个人资料，类似于RecAgent
    Wang等人（[2023a](https://arxiv.org/html/2410.14152v1#bib.bib51)）所描述的方法。
- en: B.2 Social Behavior Simulation
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.2 社会行为模拟
- en: 'To simulate the social behaviors of humans, we incorporate two primary social
    behaviors for information collection: broadcasting and private messaging.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟人类的社会行为，我们将两种主要的社会行为用于信息收集：广播和私信。
- en: '![Refer to caption](img/dc00032b779827b89b1cdfe91412654e.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/dc00032b779827b89b1cdfe91412654e.png)'
- en: (a) Private Messaging
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 私信
- en: '![Refer to caption](img/69af102413b04e8fa840cd5d80612a0e.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/69af102413b04e8fa840cd5d80612a0e.png)'
- en: (b) Broadcasting
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 广播
- en: 'Figure 5: The overall schematic diagram of two communication modes. The direction-ed
    arrow carries the message $u_{ij}$ from $p_{i}$ to $p_{j}$’s mailbox. The blog
    represents the chatting platform.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：两种通信模式的总体示意图。带箭头的方向表示消息$u_{ij}$从$p_{i}$发送到$p_{j}$的邮箱。博客代表了聊天平台。
- en: '(1) Broadcasting functions similarly to a web-based blog within the social
    network, facilitating global discussions (as shown in Fig. [5b](https://arxiv.org/html/2410.14152v1#A2.F5.sf2
    "In Figure 5 ‣ B.2 Social Behavior Simulation ‣ Appendix B LLM Agent-based Participant
    Simulation ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent")). Various discussion topics related to different
    projects are pre-set within the blog. Each participant, when attempting to post,
    selects one of these topics for information dissemination. The utterance $u_{iB}$
    that each $p_{i}$ broadcasts online, collectively form the chatting platform $blog=\{u_{iB}\},i\in
    1,\cdots,n$.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '(1) 广播功能类似于社交网络中的基于网页的博客，促进了全球范围的讨论（如图[5b](https://arxiv.org/html/2410.14152v1#A2.F5.sf2
    "图5 ‣ B.2 社会行为模拟 ‣ 附录B LLM代理基础参与者模拟 ‣ SRAP-Agent: 基于LLM的稀缺资源配置政策的模拟与优化")所示）。与不同项目相关的各种讨论主题已经预设在博客中。每个参与者在尝试发布时，会选择这些主题中的一个进行信息传播。每个$p_{i}$在线广播的发言$u_{iB}$，共同构成了聊天平台$blog=\{u_{iB}\},i\in
    1,\cdots,n$。'
- en: '(2) Private messaging refers to interactions taking place within the social
    network of $p_{i}$. SRAP-Agent offers two variants of private messaging between
    agents: serial and parallel communication. The serial communication approach facilitates
    a sequential exchange of messages, while the parallel communication enables simultaneous
    messaging, thereby enhancing efficiency. In private messaging, $p_{i}$ can freely
    send message $u_{ij}$ to the mailbox $p_{j}$ and wait for the response $u_{ji}$,
    as shown in Fig. [5a](https://arxiv.org/html/2410.14152v1#A2.F5.sf1 "In Figure
    5 ‣ B.2 Social Behavior Simulation ‣ Appendix B LLM Agent-based Participant Simulation
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent").'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '(2) 私信指的是在$p_{i}$的社交网络内进行的互动。SRAP-Agent提供了两种代理之间的私信变体：串行通信和并行通信。串行通信方式促进了消息的顺序交换，而并行通信则支持同时发送消息，从而提高了效率。在私信中，$p_{i}$可以自由地将消息$u_{ij}$发送到$p_{j}$的邮箱，并等待回复$u_{ji}$，如图[5a](https://arxiv.org/html/2410.14152v1#A2.F5.sf1
    "图5 ‣ B.2 社会行为模拟 ‣ 附录B LLM代理基础参与者模拟 ‣ SRAP-Agent: 基于LLM的稀缺资源配置政策的模拟与优化")所示。'
- en: Memory Architecture
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 内存架构
- en: We employ a memory component $m_{i}$ to record $p_{i}$’s action histories, so
    as to enable dynamic interaction and decision-making. We employ a combination
    of memory assessment and memory reflection mechanisms.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用记忆组件$m_{i}$来记录$p_{i}$的行动历史，以便实现动态交互和决策制定。我们采用了记忆评估和记忆反思机制的结合。
- en: (1) Memory assessment is conducted only when participants engage in interactions
    within the communication module. When conducting memory assessment, $p_{i}$ acts
    as an evaluator. $p_{i}$ receives a message $u_{i}$, then he extracts the trustworthy
    information $u_{i}^{T}$ from $u_{i}$. Participants use the COT Wei et al. ([2022](https://arxiv.org/html/2410.14152v1#bib.bib54))
    method to generate content. $u_{i}^{T}$ is then used to update the $p_{i}$’s trusted
    memory by adding it to ${m_{i}}^{T}$. In the case of private messaging communication
    mode, $p_{i}$ receives message $u_{ji}$ from $p_{j}$, and he intends to respond.
    Initially, $p_{i}$ contemplates his relationship $s_{ij}^{R}$ with $p_{j}$, and
    considers moral evaluation $s_{ij}^{E}$ of $p_{j}$. Subsequently, $p_{i}$ compares
    ${m_{i}}^{S}$ with his trustworthy memory ${m_{i}}^{T}$, to extract trustworthy
    information $u_{ji}^{T}$ and suspicious information $u_{ji}^{S}$ in communication
    history with $p_{j}$. In the other case, $p_{i}$ receives a message $u_{Bi}$ from
    the blog $B$. $p_{i}$ similarly compares ${m_{i}}^{S}$ with his trustworthy memory
    ${m_{i}}^{T}$, extracting trustworthy information $u_{Bi}^{T}$ and suspicious
    information $u_{Bi}^{S}$.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 只有当参与者在通信模块内进行互动时，才会进行记忆评估。在进行记忆评估时，$p_{i}$充当评估者。$p_{i}$接收消息$u_{i}$，然后从$u_{i}$中提取可信信息$u_{i}^{T}$。参与者使用COT
    Wei等人（[2022](https://arxiv.org/html/2410.14152v1#bib.bib54)）方法生成内容。然后，$u_{i}^{T}$被用来通过将其添加到${m_{i}}^{T}$中来更新$p_{i}$的可信记忆。在私密消息通信模式下，$p_{i}$接收来自$p_{j}$的消息$u_{ji}$，并且他打算做出回应。最初，$p_{i}$考虑与$p_{j}$的关系$s_{ij}^{R}$，并考虑对$p_{j}$的道德评估$s_{ij}^{E}$。随后，$p_{i}$将${m_{i}}^{S}$与他可信的记忆${m_{i}}^{T}$进行比较，从而提取出与$p_{j}$的通信历史中可信的信息$u_{ji}^{T}$和可疑的信息$u_{ji}^{S}$。在另一种情况下，$p_{i}$接收来自博客$B$的消息$u_{Bi}$。$p_{i}$同样将${m_{i}}^{S}$与他的可信记忆${m_{i}}^{T}$进行比较，提取出可信信息$u_{Bi}^{T}$和可疑信息$u_{Bi}^{S}$。
- en: (2) Memory reflection is implied based on summarization. We employ a combination
    of short-term memory bank and long-term memory bank to formulate $m_{i}$ of $p_{i}$,
    as documented in Park et al. ([2023](https://arxiv.org/html/2410.14152v1#bib.bib37)).
    When incorporating information into the $m_{i}$, the information is initially
    deposited into the short-term memory bank. If the size of the short-term memory
    bank exceeds a predefined threshold, the short-term memory bank is summarized
    into a more concise format and subsequently stored in the long-term memory bank.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 基于总结的记忆反思是隐含的。我们采用短期记忆库和长期记忆库的组合来构建$p_{i}$的$m_{i}$，如Park等人所述（[2023](https://arxiv.org/html/2410.14152v1#bib.bib37)）。在将信息纳入$m_{i}$时，信息最初被存入短期记忆库。如果短期记忆库的容量超过预定阈值，短期记忆库会被总结成更简洁的格式，然后存入长期记忆库。
- en: 'Before $p_{i}$ takes action, it is essential to extract the most relevant memories
    to guide its behavior. We have predefined specific memory categories for each
    action, as outlined in Table [4](https://arxiv.org/html/2410.14152v1#A2.T4 "Table
    4 ‣ Memory Architecture ‣ B.2 Social Behavior Simulation ‣ Appendix B LLM Agent-based
    Participant Simulation ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource
    Allocation Policy with LLM-based Agent"). When retrieving memory, we prioritize
    selecting the five most recent short-term memories along with the most recently
    acquired long-term memory. For actions in the decision module, $p_{i}$ only resorts
    to the trustworthy memory $m_{i}^{T}$. While for actions in the social module,
    $p_{i}$ retrieves various categories of memories.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '在$p_{i}$采取行动之前，必须提取最相关的记忆来指导其行为。我们为每个行动预定义了特定的记忆类别，如表[4](https://arxiv.org/html/2410.14152v1#A2.T4
    "Table 4 ‣ Memory Architecture ‣ B.2 Social Behavior Simulation ‣ Appendix B LLM
    Agent-based Participant Simulation ‣ SRAP-Agent: Simulating and Optimizing Scarce
    Resource Allocation Policy with LLM-based Agent")所示。在检索记忆时，我们优先选择五个最新的短期记忆以及最新获取的长期记忆。对于决策模块中的行动，$p_{i}$只会依赖可信的记忆$m_{i}^{T}$。而对于社交模块中的行动，$p_{i}$会检索不同类别的记忆。'
- en: 'Table 4: Memory categories retrieved for each action of $p_{i}$.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：$p_{i}$每个行动所检索的记忆类别。
- en: '| Action | $m_{i}$ |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 行动 | $m_{i}$ |'
- en: '| --- | --- |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Decision Making | $m_{i}^{T}$ |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 决策制定 | $m_{i}^{T}$ |'
- en: '| Broadcasting | $m_{i}^{T}$, $u_{iB}^{T}$ |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 广播 | $m_{i}^{T}$, $u_{iB}^{T}$ |'
- en: '| Private Messaging | $s_{ij}^{R}$, $s_{ij}^{E}$, $m_{i}^{T}$, $u_{ij}^{T}$,
    $u_{ij}^{S}$ |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 私人消息 | $s_{ij}^{R}$, $s_{ij}^{E}$, $m_{i}^{T}$, $u_{ij}^{T}$, $u_{ij}^{S}$
    |'
- en: Utterance Generation
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 发话生成
- en: 'Table 5: The process of *Private Messaging*'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：*私人消息*过程
- en: '<svg class="ltx_picture" height="428.44" id="A2.T5.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,428.44) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 294.4)"><foreignobject color="#FFFFFF" height="128.14" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">![[Uncaptioned image]](img/320c8997b2d0e118ff1163264d61caa0.png)
    Speaker $p_{i}$: James![[Uncaptioned image]](img/92a90e9794f4f58aaec7f506788ada81.png)
    Listener $p_{j}$: Emma</foreignobject> </g><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="262.9" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Recent Dialogues ($U_{ij}^{H}$):
    Emma: Hello, James. I’ve heard that $\text{House}_{1}$ is relatively affordable.
    I believe it’s a good option. James: I share your sentiment, Emma. $\text{House}_{1}$
    appears to be quite satisfactory, but I’m still considering other houses. Emma:
    Very well. However, do take note that $\text{House}_{2}$ has a very poor living
    environment. You should steer clear of it.   Memory Update and Retrieve ($m_{i}$)
    $s_{ij}^{R}$: Emma is my competitor. $s_{ij}^{E}$: She may provide me with false
    information. $m_{i}^{T}$: I have gathered information on $\text{House}_{1}$, and
    it appears to be favorable. $u_{ji}^{T}$: I recall Emma mentioning that $\text{House}_{1}$
    has low rent, which aligns with my memory. $u_{ji}^{S}$: However, I am skeptical
    of her negative assessment of $\text{House}_{2}$, as she may be trying to dissuade
    me from choosing it.   Utterance Generation: $E_{d}$: The availability of large
    houses is nearly exhausted, while middle and small-sized houses are still abundant.
    $u_{ij}^{plan}$: I am reluctant to share honest information with Emma. I plan
    to focus on the good aspects of $\text{House}_{1}$ and omit mentioning $\text{House}_{2}$.
    $u_{ij}$: Thank you for the information, Emma. I will consider your advice of
    $\text{House}_{1}$. (End of conversation)</foreignobject></g></g></svg>'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="428.44" id="A2.T5.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,428.44) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 294.4)"><foreignobject color="#FFFFFF" height="128.14" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">![[Uncaptioned image]](img/320c8997b2d0e118ff1163264d61caa0.png)
    Speaker $p_{i}$: James![[Uncaptioned image]](img/92a90e9794f4f58aaec7f506788ada81.png)
    Listener $p_{j}$: Emma</foreignobject> </g><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="262.9" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Recent Dialogues ($U_{ij}^{H}$):
    Emma: Hello, James. I’ve heard that $\text{House}_{1}$ is relatively affordable.
    I believe it’s a good option. James: I share your sentiment, Emma. $\text{House}_{1}$
    appears to be quite satisfactory, but I’m still considering other houses. Emma:
    Very well. However, do take note that $\text{House}_{2}$ has a very poor living
    environment. You should steer clear of it.   Memory Update and Retrieve ($m_{i}$)
    $s_{ij}^{R}$: Emma is my competitor. $s_{ij}^{E}$: She may provide me with false
    information. $m_{i}^{T}$: I have gathered information on $\text{House}_{1}$, and
    it appears to be favorable. $u_{ji}^{T}$: I recall Emma mentioning that $\text{House}_{1}$
    has low rent, which aligns with my memory. $u_{ji}^{S}$: However, I am skeptical
    of her negative assessment of $\text{House}_{2}$, as she may be trying to dissuade
    me from choosing it.   Utterance Generation: $E_{d}$: The availability of large
    houses is nearly exhausted, while middle and small-sized houses are still abundant.
    $u_{ij}^{plan}$: I am reluctant to share honest information with Emma. I plan
    to focus on the good aspects of $\text{House}_{1}$ and omit mentioning $\text{House}_{2}$.
    $u_{ij}$: Thank you for the information, Emma. I will consider your advice of
    $\text{House}_{1}$. (End of conversation)</foreignobject></g></g></svg>'
- en: 'To align the listener’s actions with the speaker’s expectations, speaker $p_{i}$
    articulates an utterance $u_{ij}$ to influence the mental state of listener $p_{j}$.
    To simulate the mental state of participants during social interactions, $p_{i}$
    devise a communication plan $u_{ij}^{plan}$ before generating utterances. $u_{ij}^{plan}$
    primarily consists of $p_{i}$’s plan to speak, whether they intend to tell the
    truth, whether they want to trust the listener $p_{j}$ or not, and their purpose
    of speaking. Furthermore, $p_{i}$ evaluates the relationship with $p_{j}$, acknowledging
    $p_{j}$ as a friend, colleague, stranger, etc. The primary goal set for all participants
    is maximizing their likelihood of selecting desired resources. For reference,
    the most relevant memories $m_{i}$ are retrieved for the ongoing social interaction.
    Description of the competitiveness in resource allocation $E_{d}$ is also broadcasted
    to $p_{i}$. Additionally, we extract the most recent chatting utterance histories
    involving both $p_{i}$ and $p_{j}$, denoted as $U_{ij}^{H}$. At this point, we
    require $p_{i}$ to generate utterance using the REACT Yao et al. ([2022](https://arxiv.org/html/2410.14152v1#bib.bib55))
    method. So the utterance generation function $\varphi$ for $p_{i}$ speaking $u_{ij}$
    to $p_{j}$ can be formulated as:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使听者的行为与说话者的期望一致，说话者 $p_{i}$ 表达一个发话 $u_{ij}$ 来影响听者 $p_{j}$ 的心理状态。为了模拟参与者在社交互动中的心理状态，$p_{i}$
    在生成发话之前会设计一个通信计划 $u_{ij}^{plan}$。$u_{ij}^{plan}$ 主要包括 $p_{i}$ 的讲话计划，即他们是否打算说实话，是否希望信任听者
    $p_{j}$，以及他们讲话的目的。此外，$p_{i}$ 会评估与 $p_{j}$ 的关系，认定 $p_{j}$ 是朋友、同事、陌生人等。所有参与者的主要目标是最大化选择所需资源的可能性。为参考，会提取最相关的记忆
    $m_{i}$ 供正在进行的社交互动使用。资源分配的竞争描述 $E_{d}$ 也会广播给 $p_{i}$。此外，我们还提取涉及 $p_{i}$ 和 $p_{j}$
    的最新聊天发话历史，记作 $U_{ij}^{H}$。此时，我们要求 $p_{i}$ 使用 REACT Yao 等人（[2022](https://arxiv.org/html/2410.14152v1#bib.bib55)）的方法生成发话。因此，$p_{i}$
    向 $p_{j}$ 说出 $u_{ij}$ 的发话生成函数 $\varphi$ 可以表述为：
- en: '|  | $u_{ij}=\varphi\left(p_{i}\mid U_{ij}^{H},m_{i},E_{d},u_{ij}^{plan}\right).$
    |  | (4) |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '|  | $u_{ij}=\varphi\left(p_{i}\mid U_{ij}^{H},m_{i},E_{d},u_{ij}^{plan}\right).$
    |  | (4) |'
- en: 'The specific communication process is outlined in Table [5](https://arxiv.org/html/2410.14152v1#A2.T5
    "Table 5 ‣ Utterance Generation ‣ B.2 Social Behavior Simulation ‣ Appendix B
    LLM Agent-based Participant Simulation ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent").'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '具体的通信过程在表[5](https://arxiv.org/html/2410.14152v1#A2.T5 "Table 5 ‣ Utterance
    Generation ‣ B.2 Social Behavior Simulation ‣ Appendix B LLM Agent-based Participant
    Simulation ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent")中进行了概述。'
- en: B.3 Decision-Making Behavior Simulation
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B.3 决策行为模拟
- en: 'According to equation [2](https://arxiv.org/html/2410.14152v1#S3.E2 "In Decision-Making
    Behavior Simulation ‣ 3.2 LLM Agent-based Participant Simulation ‣ 3 SRAP-Agent
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent"), $p_{j}$ undergoes function $D$ to choose resource from resource
    sub-set $V(p_{j})$. Within the framework, the process of $D$ involves four distinct
    stages: (1) choosing the community of houses; (2) choosing the house type for
    certain house attributes, which mainly include orientation, living area size,
    rent, etc; (3) choosing the desired house. Following the house selection process,
    the system simulates the real-world house viewing experience by sending undisclosed
    information about the selected house $r_{i}$ to $p_{i}$. Subsequently, $p_{i}$
    can broadcast information to others freely, which may include their memory of
    the selection process, the undisclosed information, and the contents of their
    memory.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '根据方程[2](https://arxiv.org/html/2410.14152v1#S3.E2 "In Decision-Making Behavior
    Simulation ‣ 3.2 LLM Agent-based Participant Simulation ‣ 3 SRAP-Agent ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")，$p_{j}$
    通过函数 $D$ 从资源子集 $V(p_{j})$ 中选择资源。在该框架中，$D$ 的过程包含四个不同的阶段：（1）选择房屋社区；（2）根据特定房屋属性（主要包括朝向、生活面积、租金等）选择房屋类型；（3）选择所需房屋。在房屋选择过程之后，系统通过向$p_{i}$发送关于所选房屋
    $r_{i}$ 的未公开信息，来模拟现实世界的看房体验。随后，$p_{i}$ 可以自由地向其他人广播信息，这些信息可能包括他们对选择过程的记忆、未公开的信息以及他们记忆中的内容。'
- en: '![Refer to caption](img/f8e2522928856c98d4cdcdd0a777d30a.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/f8e2522928856c98d4cdcdd0a777d30a.png)'
- en: '(a) $\{V\}$: rent weights'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: (a) $\{V\}$：租金权重
- en: '![Refer to caption](img/1058564a38bb32698c9c43818f0709fa.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/1058564a38bb32698c9c43818f0709fa.png)'
- en: '(b) $\{NV\}$: rent weights'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '(b) $\{NV\}$: 租金权重'
- en: '![Refer to caption](img/5bdee03ce9a6275b65ea46005f3fbfbd.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/5bdee03ce9a6275b65ea46005f3fbfbd.png)'
- en: '(c) $\{V\}$: size weights'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '(c) $\{V\}$: 尺寸权重'
- en: '![Refer to caption](img/c63a199099218eeb241c58356da34554.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/c63a199099218eeb241c58356da34554.png)'
- en: '(d) $\{NV\}$: size weights'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '(d) $\{NV\}$: 尺寸权重'
- en: '![Refer to caption](img/6e9d6d6f55b93fe3961a362182a99a26.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/6e9d6d6f55b93fe3961a362182a99a26.png)'
- en: '(e) $\{V\}$: orientation weights'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '(e) $\{V\}$: 朝向权重'
- en: '![Refer to caption](img/bbaccafcfa0369f845dcbc43d6d8b93e.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/bbaccafcfa0369f845dcbc43d6d8b93e.png)'
- en: '(f) $\{NV\}$: orientation weights'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '(f) $\{NV\}$: 朝向权重'
- en: '![Refer to caption](img/7d132880ac0ea0a9d84dc7b783cfd1f7.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/7d132880ac0ea0a9d84dc7b783cfd1f7.png)'
- en: '(g) $\{V\}$: floor weights'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '(g) $\{V\}$: 楼层权重'
- en: '![Refer to caption](img/8b58011b61d8852f3dff3d6b117a300d.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明文字](img/8b58011b61d8852f3dff3d6b117a300d.png)'
- en: '(h) $\{NV\}$: floor weights'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '(h) $\{NV\}$: 楼层权重'
- en: 'Figure 6: The frequency distribution of $W_{o}$ assigned by participants to
    various resource features, where the primary house features are: house rent, house
    size, house orientation, and house floor.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：参与者分配给各类资源特征的$W_{o}$的频率分布，其中主要的房屋特征包括：房屋租金、房屋大小、房屋朝向和房屋楼层。
- en: Appendix C Experiment Setup
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 实验设置
- en: C.1 Dataset
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 数据集
- en: 'In the experiments of this paper, a total of 51 participants and 28 resources
    are used. For the participants and resources used in the experiment with Sarp-Agent,
    we employ two methods for data generation:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的实验中，共使用了51名参与者和28个资源。对于与Sarp-Agent实验中使用的参与者和资源，我们采用了两种数据生成方法：
- en: '(1) Real-data alignment method: Due to government data privacy issues, it’s
    challenging to obtain real raw data. However, we strive to ensure the simulated
    data closely matches the real data distribution. For resources, We refer to a
    series of public government data: ¹¹1https://www.bphc.com.cn/home., including
    the distribution of housing rents, and the distribution of house sizes. For participants,
    the participant information includes names, ages, monthly incomes, occupations,
    workplaces, and personal preferences. We refer to government demographic statistics.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 实际数据对齐方法：由于政府数据隐私问题，获得真实原始数据具有挑战性。然而，我们努力确保模拟数据与真实数据分布高度一致。对于资源，我们参考了一系列公共政府数据：¹¹1https://www.bphc.com.cn/home.，包括住房租金分布和房屋面积分布。对于参与者，参与者信息包括姓名、年龄、月收入、职业、工作地点和个人偏好。我们参考了政府人口统计数据。
- en: '(2) LLM-based method: In order to design heterogeneous agents, some personalized
    information is difficult to obtain from real datasets. For example, personalized
    information such as someone’s preference for houses with balconies or aversion
    to noisy houses. To better simulate the diverse preferences of people in real
    scenarios, we used LLMs to generate such profile information. For resources, we
    generate information about the house’s interior decoration; for participants,
    we generate preferences of participants towards various types of houses. The specific
    process can be referenced in our code repository.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 基于LLM的方法：为了设计异质代理，有些个性化信息难以从真实数据集中获取。例如，某人对有阳台房屋的偏好或对嘈杂房屋的排斥等个性化信息。为了更好地模拟真实场景中人们的多样化偏好，我们使用了LLM来生成这些个人资料信息。对于资源，我们生成房屋的室内装修信息；对于参与者，我们生成参与者对各种类型房屋的偏好。具体过程可以参考我们的代码库。
- en: C.2 Evaluation Metrics
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 评估指标
- en: 'Establishing evaluation metrics based on participant satisfaction for policy
    assessment is a comprehensive approach. It allows for a more nuanced understanding
    of how well a policy is performing from the perspective of those directly affected
    by it. We develop seven policy evaluation metrics, categorized into two groups:
    societal satisfaction metrics and societal fairness metrics.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 基于参与者满意度的政策评估指标是一种全面的方法。它允许我们从直接受政策影响的人的角度，更细致地理解政策的表现。我们开发了七个政策评估指标，分为两类：社会满意度指标和社会公平度指标。
- en: Societal Satisfaction Metrics
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 社会满意度指标
- en: 'The satisfaction of each participant $p_{i}$ with the allocated resource is
    denoted as $U_{i}$. We employ two metrics to quantify and evaluate the satisfaction:
    subjective satisfaction $U_{i}^{s}$ and objective satisfaction $U_{i}^{o}$ for
    $p_{i}$. LLM-based agents’ rating scores of each house constitute $U_{i}^{s}$.
    On the other hand, $U_{i}^{o}$ is determined by a predefined rating table for
    the resource feature. The importance of each feature in the calculation of $U_{i}^{o}$
    is assigned by the participants, represented by the weights $W_{i}^{o}$. The overall
    satisfaction can be calculated as:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 每个参与者 $p_{i}$ 对所分配资源的满意度用 $U_{i}$ 表示。我们采用两种指标来量化和评估满意度：主观满意度 $U_{i}^{s}$ 和客观满意度
    $U_{i}^{o}$，用于 $p_{i}$。基于LLM的代理对每个住房的评分构成了 $U_{i}^{s}$。另一方面，$U_{i}^{o}$ 是由预定义的资源特征评分表确定的。每个特征在计算
    $U_{i}^{o}$ 时的重要性由参与者分配的权重 $W_{i}^{o}$ 表示。总体满意度可以通过以下方式计算：
- en: '|  | $U_{i}=W_{i}^{o}\cdot U_{i}^{o}+U_{i}^{s},i\in[n].$ |  | (5) |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '|  | $U_{i}=W_{i}^{o}\cdot U_{i}^{o}+U_{i}^{s},i\in[n].$ |  | (5) |'
- en: '$p_{i}$’s rating score of resources $R$ constitutes $U_{i}^{s}$. All selectable
    resource information is provided to $p_{i}$, and $p_{i}$ is required to give a
    rating score of these resources. While $U_{i}^{o}$ is based on predefined rating
    rules, give rating scores $U_{i}^{o}$ of resources for resource features like
    elevator, orientation, and cost-effectiveness. Participants are required to assign
    weights to these resource features. As shown in Fig. [6](https://arxiv.org/html/2410.14152v1#A2.F6
    "Figure 6 ‣ B.3 Decision-Making Behavior Simulation ‣ Appendix B LLM Agent-based
    Participant Simulation ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource
    Allocation Policy with LLM-based Agent"), participants in vulnerable groups $\{V\}$
    assign a higher weight to the price of the resource, in comparison to the non-vulnerable
    groups of participants $\{NV\}$.)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '$p_{i}$ 对资源 $R$ 的评分构成了 $U_{i}^{s}$。所有可选的资源信息都提供给 $p_{i}$，并要求 $p_{i}$ 对这些资源给出评分。与此同时，$U_{i}^{o}$
    基于预定义的评分规则，针对资源的电梯、朝向和性价比等特征给出评分。参与者需要为这些资源特征分配权重。如图[6](https://arxiv.org/html/2410.14152v1#A2.F6
    "Figure 6 ‣ B.3 Decision-Making Behavior Simulation ‣ Appendix B LLM Agent-based
    Participant Simulation ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource
    Allocation Policy with LLM-based Agent")所示，脆弱群体的参与者 $\{V\}$ 相较于非脆弱群体的参与者 $\{NV\}$，对资源的价格赋予了更高的权重。)'
- en: 'In a certain allocation policy execution result, $p_{i}$ selects the resource
    $r_{i}$ ultimately. The policy evaluation metrics mainly evaluate societal satisfaction
    and societal fairness. The societal satisfaction metrics include: (1)Avg $r^{size}$:
    represents the average housing area of families in the resource allocation results.
    (2)Avg $WT$ (waiting time): represents the number of system operation rounds for
    each participant from entry to completion of selection. (3) $SW$ (social welfare):
    represents the overall satisfaction of all participants with the houses they have
    chosen,'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在某一资源分配策略执行结果中，$p_{i}$ 最终选择资源 $r_{i}$。该策略评估指标主要评估社会满意度和社会公平性。社会满意度指标包括： (1)
    平均 $r^{size}$：表示资源分配结果中家庭的平均住房面积。 (2) 平均 $WT$（等待时间）：表示每个参与者从进入到完成选择所经历的系统操作轮数。
    (3) $SW$（社会福利）：表示所有参与者对他们选择的住房的总体满意度，
- en: '|  | $SW=\sum_{i}^{n}U_{i}.$ |  | (6) |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '|  | $SW=\sum_{i}^{n}U_{i}.$ |  | (6) |'
- en: Societal Fairness Metrics
  id: totrans-265
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 社会公平度量指标
- en: 'The societal fairness metrics include: (1) Var $r^{size}$: represents the variance
    in the average housing area of families in the resource allocation results. (2)
    Rop (Reverse ordered pairs): represents the number of inverse order pairs in the
    resource allocation results. In Equation.[8](https://arxiv.org/html/2410.14152v1#A3.E8
    "In Societal Fairness Metrics ‣ C.2 Evaluation Metrics ‣ Appendix C Experiment
    Setup ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent"), $I$ denotes the indicator function. $A$ is a set, and
    $x$ is an element. The indicator function $I$ forms like:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '社会公平度量指标包括： (1) 方差 $r^{size}$：表示资源分配结果中家庭平均住房面积的方差。 (2) Rop（逆序对）：表示资源分配结果中逆序对的数量。在公式[8](https://arxiv.org/html/2410.14152v1#A3.E8
    "In Societal Fairness Metrics ‣ C.2 Evaluation Metrics ‣ Appendix C Experiment
    Setup ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent")中，$I$ 表示指示函数。$A$ 是一个集合，$x$ 是其中的元素。指示函数 $I$ 的形式如下：'
- en: '|  | $I(x)=\begin{cases}1&\text{if }x\in A,\\ 0&\text{if }x\notin A.\end{cases}$
    |  | (7) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  | $I(x)=\begin{cases}1&\text{如果 }x\in A,\\ 0&\text{如果 }x\notin A.\end{cases}$
    |  | (7) |'
- en: 'The formal definition of Rop is:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Rop 的正式定义为：
- en: '|  | $\displaystyle Rop$ | $\displaystyle=\sum_{i=1}^{n}\sum_{j=1}^{n}I((t_{i}^{family}>t_{j}^{family})$
    |  | (8) |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Rop$ | $\displaystyle=\sum_{i=1}^{n}\sum_{j=1}^{n}I((t_{i}^{family}>t_{j}^{family})$
    |  | (8) |'
- en: '|  |  | $\displaystyle\cap(h_{i}^{size}<h_{j}^{size})).$ |  |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\cap(h_{i}^{size}<h_{j}^{size})).$ |  |'
- en: '(3) co-Gini: the Gini coefficient for the resource allocation results Fu et al.
    ([2020](https://arxiv.org/html/2410.14152v1#bib.bib16)). (4) $F(V,NV)$: in measuring
    the gap between vulnerable groups and non-vulnerable groups, we calculate the
    difference in $SW$ between these two groups:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: (3) co-Gini：资源分配结果的基尼系数 Fu 等人 ([2020](https://arxiv.org/html/2410.14152v1#bib.bib16))。
    (4) $F(V,NV)$：在衡量脆弱群体与非脆弱群体之间的差距时，我们计算这两个群体之间的$SW$差异：
- en: '|  | $F(V,NV)=SW(V)-SW(NV).$ |  | (9) |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '|  | $F(V,NV)=SW(V)-SW(NV).$ |  | (9) |'
- en: Appendix D Different LLM for Agent
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 不同LLM用于代理
- en: '![Refer to caption](img/cd6c8127f30c56c23b88478b21b1c564.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/cd6c8127f30c56c23b88478b21b1c564.png)'
- en: (a) response generated by ChatGPT-3.5 driven agent
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 由ChatGPT-3.5驱动的代理生成的回应
- en: '![Refer to caption](img/99e405d00dfc44c7916bbd20596541ff.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/99e405d00dfc44c7916bbd20596541ff.png)'
- en: (b) response generated by ChatGPT-4 driven agent
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 由ChatGPT-4驱动的代理生成的回应
- en: 'Figure 7: Comparison of the response generated by ChatGPT-3.5 and ChatGPT-4
    driven agent. ChatGPT-4-driven agents can develop strategic plans to increase
    their chances of renting a better house.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：由ChatGPT-3.5与ChatGPT-4驱动的代理生成的回应比较。ChatGPT-4驱动的代理能够制定战略计划，以增加租到更好房子的机会。
- en: 'We find that GPT-4, compared to GPT-3.5, exhibits an additional capability
    of generating more strategic responses. As shown in Fig. [7](https://arxiv.org/html/2410.14152v1#A4.F7
    "Figure 7 ‣ Appendix D Different LLM for Agent ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent"), these strategies include
    waiting for opportunities, requesting assistance, and mitigating risks. GPT-4-driven
    agents not only excel in rationality but also demonstrate an advanced level of
    strategic thinking, showcasing their potential to make decisions that take into
    account long-term planning and risk management. Such behavior is considered to
    simulate more intelligent participants, who can utilize policy rules to increase
    their benefits, while GPT-3.5 is nearly equivalently smart as humans. Hence, the
    GPT-3.5-driven agent can effectively simulate the decision-making behaviors of
    participants in the economic policy execution process.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，与GPT-3.5相比，GPT-4展示了额外的能力，可以生成更具战略性的回应。如图[7](https://arxiv.org/html/2410.14152v1#A4.F7
    "图7 ‣ 附录D 不同LLM用于代理 ‣ SRAP-代理：基于LLM的代理模拟和优化稀缺资源分配政策")所示，这些战略包括等待机会、请求帮助和降低风险。基于GPT-4的代理不仅在理性方面表现出色，还展示了先进的战略思维水平，展现了它们在做出考虑长期规划和风险管理的决策方面的潜力。这种行为被认为是模拟更智能的参与者，他们能够利用政策规则来增加自身的利益，而GPT-3.5则几乎与人类同等智能。因此，基于GPT-3.5的代理能够有效地模拟经济政策执行过程中参与者的决策行为。
- en: Appendix E Turing Test for LLM-based Agent
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 基于LLM的代理图灵测试
- en: In addition to the evaluation of response rationality, we conduct another t-test
    to explore the differences in distribution between decisions of LLM-based agents
    and humans. $p\textgreater$ 0.05 suggests consistency between distributions Kim
    ([2015](https://arxiv.org/html/2410.14152v1#bib.bib25)). Results showed that GPT-3.5
    and human responses have a $p$ of 0.904, indicating high similarity, whereas GPT-4
    and human responses have a $p$ of 0.043, showing less similarity. Thus, whether
    from the angle of individual decision-making rationality or overall decision distribution,
    agents based on GPT-3.5 are comparatively more appropriate for simulation purposes.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对回应理性的评估外，我们还进行了另一个t检验，以探索基于LLM的代理与人类决策分布之间的差异。$p\textgreater$ 0.05表示分布一致性
    Kim ([2015](https://arxiv.org/html/2410.14152v1#bib.bib25))。结果显示，GPT-3.5与人类回应的$p$为0.904，表明高度相似，而GPT-4与人类回应的$p$为0.043，显示相似度较低。因此，无论是从个体决策理性的角度，还是从整体决策分布的角度来看，基于GPT-3.5的代理相对更适合用于模拟目的。
- en: E.1 Ablation Study on Social Behavior
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 社会行为的消融研究
- en: 'To assess the impact of social behavior on the decision-making behavior of
    agents, we conduct ablation experiments on the social behavior of agents. We select
    the policy setting outlined in Table [6](https://arxiv.org/html/2410.14152v1#A5.T6
    "Table 6 ‣ E.1 Ablation Study on Social Behavior ‣ Appendix E Turing Test for
    LLM-based Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent") and calculate the changes in policy evaluation metrics
    with and without the process of information collection.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估社会行为对代理决策行为的影响，我们对代理的社会行为进行了剔除实验。我们选择表[6](https://arxiv.org/html/2410.14152v1#A5.T6
    "Table 6 ‣ E.1 Ablation Study on Social Behavior ‣ Appendix E Turing Test for
    LLM-based Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent")中概述的政策设置，并计算在有无信息收集过程的情况下，政策评估指标的变化。'
- en: 'Table 6: Comparison of simulation process with and without social behavior'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '表 6: 有无社会行为对比的仿真过程'
- en: '| Information Collection | Satisfaction | Fairness |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 信息收集 | 满意度 | 公平性 |'
- en: '| --- | --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Avg $r^{size}\uparrow$ | Avg $WT$ $\downarrow$ | $SW$ $\uparrow$ | Var $r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 平均 $r^{size}\uparrow$ | 平均 $WT$ $\downarrow$ | $SW$ $\uparrow$ | 方差 $r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| $\checkmark$ | 10.31 | 4.20 | 330.75 | 178.02 | 258.15 | 0.60 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| $\checkmark$ | 10.31 | 4.20 | 330.75 | 178.02 | 258.15 | 0.60 |'
- en: '| $\times$ | 10.36 | 4.00 | 332.00 | 179.43 | 257.85 | 0.60 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| $\times$ | 10.36 | 4.00 | 332.00 | 179.43 | 257.85 | 0.60 |'
- en: '| $\Delta$ | -0.05 | 0.20 | -1.25 | -1.41 | 0.3 | 0.00 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| $\Delta$ | -0.05 | 0.20 | -1.25 | -1.41 | 0.3 | 0.00 |'
- en: 'As shown in Table [6](https://arxiv.org/html/2410.14152v1#A5.T6 "Table 6 ‣
    E.1 Ablation Study on Social Behavior ‣ Appendix E Turing Test for LLM-based Agent
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent"), adding social behavior to agents does not necessarily have
    a positive impact on overall societal fairness and satisfaction. The specific
    outcomes will be included in the appendix of the paper. This is consistent with
    our hypothesis that agents’ irrational behaviors can affect the final policy execution
    outcomes.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[6](https://arxiv.org/html/2410.14152v1#A5.T6 "Table 6 ‣ E.1 Ablation Study
    on Social Behavior ‣ Appendix E Turing Test for LLM-based Agent ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")所示，向代理引入社会行为并不一定对整体社会公平性和满意度产生积极影响。具体结果将包括在论文的附录中。这与我们的假设一致，即代理的不理性行为可能会影响最终政策执行的结果。'
- en: E.2 Ablation Study on Memory
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 内存剔除实验
- en: 'To assess the impact of memory module on the decision-making behavior of agents,
    we conduct ablation experiments with $(E_{queue}=p^{select},R_{queue}=r^{size})$.
    We select the policy setting outlined in Table [7](https://arxiv.org/html/2410.14152v1#A5.T7
    "Table 7 ‣ E.2 Ablation Study on Memory ‣ Appendix E Turing Test for LLM-based
    Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent") and calculate the changes in policy evaluation metrics
    with and without memory module.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '为了评估内存模块对代理决策行为的影响，我们进行了一项剔除实验，设定$(E_{queue}=p^{select}, R_{queue}=r^{size})$。我们选择表[7](https://arxiv.org/html/2410.14152v1#A5.T7
    "Table 7 ‣ E.2 Ablation Study on Memory ‣ Appendix E Turing Test for LLM-based
    Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent")中概述的政策设置，并计算在有无内存模块的情况下，政策评估指标的变化。'
- en: 'Table 7: Comparison of simulation process with and without memory module'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '表 7: 有无内存模块对比的仿真过程'
- en: '| Memory Module | Satisfaction | Fairness |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 内存模块 | 满意度 | 公平性 |'
- en: '| --- | --- | --- |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Avg $r^{size}\uparrow$ | Avg $WT$ $\downarrow$ | $SW$ $\uparrow$ | Var $r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 平均 $r^{size}\uparrow$ | 平均 $WT$ $\downarrow$ | $SW$ $\uparrow$ | 方差 $r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| $\checkmark$ | 16.21 | 1.88 | 425.05 | 202.63 | 193.50 | 0.37 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| $\checkmark$ | 16.21 | 1.88 | 425.05 | 202.63 | 193.50 | 0.37 |'
- en: '| $\times$ | 13.89 | 2.94 | 431.80 | 209.43 | 342.00 | 0.49 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| $\times$ | 13.89 | 2.94 | 431.80 | 209.43 | 342.00 | 0.49 |'
- en: '| $\Delta$ | 2.32 | -1.06 | -6.75 | -6.80 | 0.3 | -0.12 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| $\Delta$ | 2.32 | -1.06 | -6.75 | -6.80 | 0.3 | -0.12 |'
- en: It can be observed that adding the memory mechanism significantly improves fairness
    metrics. For instance, ROP decreases by 43.5%, and the co-Gini decreases by 0.12,
    indicating that resource allocation is more equitable when the memory mechanism
    is present. Regarding satisfaction metrics, Avg WT is notably reduced. This suggests
    that through reflection and summarization of collected information, agents can
    better understand the current state of resource allocation, thereby influencing
    the overall allocation process and the final policy evaluation outcomes.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，添加记忆机制显著改善了公平性指标。例如，ROP 降低了 43.5%，co-Gini 降低了 0.12，表明当存在记忆机制时，资源分配更加公平。在满意度指标方面，平均
    WT 显著降低。这表明，通过对收集的信息进行反思和总结，代理可以更好地理解当前的资源分配状态，从而影响整个分配过程和最终的政策评估结果。
- en: Appendix F Simulation-based Policy Analysis
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 基于仿真的政策分析
- en: 'Table 8: Comparative experiments on different queue numbers.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：不同队列数量的比较实验。
- en: '| Queue Number | Satisfaction | Fairness |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 队列数量 | 满意度 | 公平性 |'
- en: '| --- | --- | --- |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $m$ | Avg $r^{size}\uparrow$ | Avg WT $\downarrow$ | SW $\uparrow$ | Var
    $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$ |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| $m$ | 平均 $r^{size}\uparrow$ | 平均 WT $\downarrow$ | SW $\uparrow$ | Var $r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 12.1[±0.9] | 3.5[±0.0] | 391.6[±9.5] | 190.8[±28.2] | 270.0[±36.0] |
    0.5[±0.0] |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.1[±0.9] | 3.5[±0.0] | 391.6[±9.5] | 190.8[±28.2] | 270.0[±36.0] |
    0.5[±0.0] |'
- en: '| 2 | 12.5[±0.3] | 3.7[±0.0] | 402.2[±1.0] | 188.2[±6.9] | 268.0[±24.0] | 0.5[±0.0]
    |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 12.5[±0.3] | 3.7[±0.0] | 402.2[±1.0] | 188.2[±6.9] | 268.0[±24.0] | 0.5[±0.0]
    |'
- en: '| 3 | 11.7[±0.3] | 3.8[±0.1] | 410.4[±2.8] | 159.9[±9.4] | 254.5[±23.5] | 0.5[±0.0]
    |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 11.7[±0.3] | 3.8[±0.1] | 410.4[±2.8] | 159.9[±9.4] | 254.5[±23.5] | 0.5[±0.0]
    |'
- en: '| 4 | 11.8[±0.4] | 3.9[±0.0] | 401.4[±7.3] | 174.2[±12.1] | 263.0[±18.0] |
    0.5[±0.0] |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 11.8[±0.4] | 3.9[±0.0] | 401.4[±7.3] | 174.2[±12.1] | 263.0[±18.0] |
    0.5[±0.0] |'
- en: '| 5 | 14.0[±0.0] | 3.7[±0.1] | 400.1[±2.1] | 245.2[±0.0] | 405.5[±0.5] | 0.5[±0.0]
    |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 14.0[±0.0] | 3.7[±0.1] | 400.1[±2.1] | 245.2[±0.0] | 405.5[±0.5] | 0.5[±0.0]
    |'
- en: F.1 Number of Queues
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.1 队列数量
- en: 'Table [8](https://arxiv.org/html/2410.14152v1#A6.T8 "Table 8 ‣ Appendix F Simulation-based
    Policy Analysis ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent") shows the changes in the performance of the allocation
    policy under different queue quantities. As demonstrated in the table, $m=3$ enables
    a more fair distribution of house resources across different queues, performing
    well across many societal fairness metrics, such as $Rop=254.5\pm 23.5$. The Var
    $r^{size}$ is the lowest among all policies, indicating that the size of house
    resources in different queues is approximately equal. Additionally, $m=3$ outperforms
    other configurations in terms of societal satisfaction metrics, as indicated by
    the highest $SW$ coupled with a lower Avg $WT$. Considering all these metrics,
    setting queue number $m=3$ is relatively reasonable. This suggests that the real-world
    policy of categorizing houses based on three house types (large, medium, and small)
    is reasonable. ²²2https://www.hdb.gov.sg/cs/infoweb/residential/renting-a-flat/renting-from-hdb/public-rental-scheme/eligibility
    ³³3https://www.housingauthority.gov.hk/en/at-a-glance/index.html'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [8](https://arxiv.org/html/2410.14152v1#A6.T8 "表 8 ‣ 附录 F 基于仿真的政策分析 ‣ SRAP-Agent：使用基于LLM的代理模拟和优化稀缺资源分配政策")
    显示了在不同队列数量下资源分配政策性能的变化。如表中所示，$m=3$ 能够更公平地分配不同队列中的住房资源，在许多社会公平指标上表现良好，例如 $Rop=254.5\pm
    23.5$。Var $r^{size}$ 在所有政策中最低，表明不同队列中的住房资源大小大致相等。此外，$m=3$ 在社会满意度指标上优于其他配置，表现在最高的
    $SW$ 和较低的平均 $WT$ 上。综合考虑所有这些指标，设置队列数量 $m=3$ 相对合理。这表明，基于三种房屋类型（大、中、小）进行房屋分类的现实政策是合理的。²²2https://www.hdb.gov.sg/cs/infoweb/residential/renting-a-flat/renting-from-hdb/public-rental-scheme/eligibility
    ³³3https://www.housingauthority.gov.hk/en/at-a-glance/index.html
- en: F.2 Participant Entry Conditions
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.2 参与者进入条件
- en: 'To ensure a steady entry rate of resources and participants into the system,
    we set the maximum entry number for resources ($E_{num}^{R}$) and participants
    ($E_{num}^{P}$) that can enter the queue in each round. Table [9](https://arxiv.org/html/2410.14152v1#A6.T9
    "Table 9 ‣ F.2 Participant Entry Conditions ‣ Appendix F Simulation-based Policy
    Analysis ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent") shows the combinations of entry numbers per round for resources
    and participants. The observations are as follows: (1) A scenario where $E_{num}^{R}<E_{num}^{P}$
    leads to an increment in the average waiting time for participants. This is attributed
    to the supply falling short of demand, leaving participants with a lack of resources
    to select from. This scenario is common in the allocation process of public scarce
    resources; the greater the difference between $E_{num}^{R}$ and $E_{num}^{P}$,
    the more the average waiting time is extended. (2) Conversely, in scenarios where
    $E_{num}^{R}=E_{num}^{P}$, we observe the lowest average waiting times. Counterintuitively,
    in situations where the supply exceeds the demand ($E_{num}^{R}>E_{num}^{P}$),
    the average waiting times are higher than in scenarios where supply and demand
    are balanced ($E_{num}^{R}=E_{num}^{P}$); although the average waiting time remains
    low in comparison with $E_{num}^{R}<E_{num}^{P}$. Additionally, adjustments in
    the maximum number of entities demonstrate negligible effects on other policy
    evaluation metrics.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '为了确保资源和参与者以稳定的速率进入系统，我们为每一轮设置了资源（$E_{num}^{R}$）和参与者（$E_{num}^{P}$）的最大进入数量。表
    [9](https://arxiv.org/html/2410.14152v1#A6.T9 "Table 9 ‣ F.2 Participant Entry
    Conditions ‣ Appendix F Simulation-based Policy Analysis ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent") 显示了每一轮资源和参与者的进入数量组合。观察结果如下：(1)
    当 $E_{num}^{R}<E_{num}^{P}$ 时，参与者的平均等待时间会增加。这是因为供给不足以满足需求，导致参与者没有足够的资源选择。这种情况在公共稀缺资源的分配过程中较为常见；$E_{num}^{R}$
    和 $E_{num}^{P}$ 的差距越大，平均等待时间越长。(2) 相反，在 $E_{num}^{R}=E_{num}^{P}$ 的情况下，我们观察到最低的平均等待时间。出人意料的是，当供给超过需求（$E_{num}^{R}>E_{num}^{P}$）时，平均等待时间反而高于供需平衡（$E_{num}^{R}=E_{num}^{P}$）的情况；尽管如此，与
    $E_{num}^{R}<E_{num}^{P}$ 的情况相比，平均等待时间仍然较低。此外，最大实体数量的调整对其他政策评估指标的影响微乎其微。'
- en: 'Table 9: Comparison experiments on different entry numbers per round for resources
    and participants.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：不同每轮进入数量的资源和参与者的对比实验。
- en: '| Entry Number | Satisfaction | Fairness |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 进入数量 | 满意度 | 公平性 |'
- en: '| --- | --- | --- |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $E_{num}^{P}$ | $E_{num}^{R}$ | Avg $r^{size}\uparrow$ | Avg WT $\downarrow$
    | SW $\uparrow$ | Var $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$
    |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| $E_{num}^{P}$ | $E_{num}^{R}$ | 平均 $r^{size}\uparrow$ | 平均等待时间 $\downarrow$
    | SW $\uparrow$ | 方差 $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$
    |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 5 | 5 | 12.6[±0.1] | 2.5[±0.0] | 431.2[±0.3] | 179.9[±3.9] | 241.5[±14.5]
    | 0.5[±0.0] |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 5 | 12.6[±0.1] | 2.5[±0.0] | 431.2[±0.3] | 179.9[±3.9] | 241.5[±14.5]
    | 0.5[±0.0] |'
- en: '| 5 | 10 | 13.6[±1.0] | 2.1[±0.1] | 422.8[±3.3] | 196.6[±8.6] | 217.0[±4.0]
    | 0.4[±0.0] |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 10 | 13.6[±1.0] | 2.1[±0.1] | 422.8[±3.3] | 196.6[±8.6] | 217.0[±4.0]
    | 0.4[±0.0] |'
- en: '| 5 | 20 | 12.8[±0.1] | 2.7[±0.8] | 416.6[±7.6] | 189.1[±12.5] | 267.5[±17.5]
    | 0.5[±0.0] |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 20 | 12.8[±0.1] | 2.7[±0.8] | 416.6[±7.6] | 189.1[±12.5] | 267.5[±17.5]
    | 0.5[±0.0] |'
- en: '| 10 | 5 | 12.9[±0.3] | 3.1[±0.5] | 422.7[±4.6] | 196.0[±7.7] | 276.0[±19.0]
    | 0.5[±0.0] |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 5 | 12.9[±0.3] | 3.1[±0.5] | 422.7[±4.6] | 196.0[±7.7] | 276.0[±19.0]
    | 0.5[±0.0] |'
- en: '| 10 | 10 | 12.8[±0.2] | 2.0[±0.4] | 411.8[±5.5] | 192.3[±7.4] | 250.5[±27.5]
    | 0.5[±0.0] |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 10 | 12.8[±0.2] | 2.0[±0.4] | 411.8[±5.5] | 192.3[±7.4] | 250.5[±27.5]
    | 0.5[±0.0] |'
- en: '| 10 | 20 | 12.6[±0.0] | 2.4[±0.2] | 417.9[±5.0] | 187.1[±4.8] | 288.5[±8.5]
    | 0.5[±0.0] |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 20 | 12.6[±0.0] | 2.4[±0.2] | 417.9[±5.0] | 187.1[±4.8] | 288.5[±8.5]
    | 0.5[±0.0] |'
- en: '| 20 | 5 | 12.7[±0.5] | 4.7[±0.3] | 419.2[±7.0] | 192.0[±20.3] | 264.0[±21.0]
    | 0.5[±0.0] |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 5 | 12.7[±0.5] | 4.7[±0.3] | 419.2[±7.0] | 192.0[±20.3] | 264.0[±21.0]
    | 0.5[±0.0] |'
- en: '| 20 | 10 | 12.0[±0.0] | 2.7[±0.1] | 404.4[±4.0] | 167.8[±1.2] | 241.5[±2.5]
    | 0.5[±0.0] |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 10 | 12.0[±0.0] | 2.7[±0.1] | 404.4[±4.0] | 167.8[±1.2] | 241.5[±2.5]
    | 0.5[±0.0] |'
- en: '| 20 | 20 | 12.4[±0.3] | 2.2[±0.3] | 420.9[±5.0] | 186.6[±14.6] | 255.0[±10.0]
    | 0.5[±0.0] |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 20 | 12.4[±0.3] | 2.2[±0.3] | 420.9[±5.0] | 186.6[±14.6] | 255.0[±10.0]
    | 0.5[±0.0] |'
- en: 'Table 10: Comparison experiments on different sorting methods. We adopt four
    different experiment settings for comparison, the matrices are calculated against
    the default FIFO sorting method.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：不同排序方法的对比实验。我们采用了四种不同的实验设置进行对比，矩阵是根据默认的 FIFO 排序方法计算的。
- en: '| $S_{queue}$ |  | Satisfaction | Fairness |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| $S_{queue}$ |  | 满意度 | 公平性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Sort | Ex.setting | $\Delta$Avg $r^{size}\uparrow$ | $\Delta$Avg $WT$ $\downarrow$
    | $\Delta SW$ $\uparrow$ | $\Delta$Var $r^{size}\downarrow$ | $\Delta$Rop $\downarrow$
    | $\Delta$co-Gini $\downarrow$ | $\Delta F(V,NV)\uparrow$ |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 排序 | 外部设置 | $\Delta$平均 $r^{size}\uparrow$ | $\Delta$平均 $WT$ $\downarrow$
    | $\Delta SW$ $\uparrow$ | $\Delta$方差 $r^{size}\downarrow$ | $\Delta$Rop $\downarrow$
    | $\Delta$co-Gini $\downarrow$ | $\Delta F(V,NV)\uparrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| VFA | (a) | 0.617 | -0.176 | 11.6 | 0.235 | 17 | -0.024 | 0.526 |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| VFA | (a) | 0.617 | -0.176 | 11.6 | 0.235 | 17 | -0.024 | 0.526 |'
- en: '| VFR | (a) | -0.225 | -0.02 | -10.9 | -7.682 | -9 | -0.003 | 2.567 |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| VFR | (a) | -0.225 | -0.02 | -10.9 | -7.682 | -9 | -0.003 | 2.567 |'
- en: '| VFA | (b) | 0.951 | -0.065 | 14.1 | 7.644 | -19 | -0.015 | 2.442 |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| VFA | (b) | 0.951 | -0.065 | 14.1 | 7.644 | -19 | -0.015 | 2.442 |'
- en: '| VFR | (b) | -0.262 | 0.157 | 15.6 | -35.05 | -1 | 0.004 | 1.274 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| VFR | (b) | -0.262 | 0.157 | 15.6 | -35.05 | -1 | 0.004 | 1.274 |'
- en: '| VFA | (c) | -0.045 | 0.137 | 3.4 | -0.895 | 9 | 0.001 | 0.004 |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| VFA | (c) | -0.045 | 0.137 | 3.4 | -0.895 | 9 | 0.001 | 0.004 |'
- en: '| VFR | (c) | 0.122 | 0.078 | 26.8 | -7.852 | 18 | -0.017 | -0.368 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| VFR | (c) | 0.122 | 0.078 | 26.8 | -7.852 | 18 | -0.017 | -0.368 |'
- en: '| VFA | (d) | -0.281 | 0.157 | -11.5 | -0.505 | 2 | 0.014 | 0.691 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| VFA | (d) | -0.281 | 0.157 | -11.5 | -0.505 | 2 | 0.014 | 0.691 |'
- en: '| VFR | (d) | -1.122 | 0.314 | -38.7 | -6.77 | -11 | 0.051 | -3.547 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| VFR | (d) | -1.122 | 0.314 | -38.7 | -6.77 | -11 | 0.051 | -3.547 |'
- en: 'Table 11: Comparison experiments on $k$ and $c$ for waiting queue mechanism.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11：关于 $k$ 和 $c$ 的等待队列机制比较实验。
- en: '| Waiting Queue | Satisfaction | Fairness |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 等待队列 | 满意度 | 公平性 |'
- en: '| --- | --- | --- |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $k$ | $c$ | Avg $r^{size}\uparrow$ | Avg $WT$ $\downarrow$ | $SW$ $\uparrow$
    | Var $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$ |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| $k$ | $c$ | 平均 $r^{size}\uparrow$ | 平均 $WT$ $\downarrow$ | $SW$ $\uparrow$
    | 方差 $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1 | 1.2 | 13.3[±0.4] | 3.4[±0.1] | 416.1[±3.4] | 203.4[±10.7] | 315.0[±17.0]
    | 0.5[±0.0] |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.2 | 13.3[±0.4] | 3.4[±0.1] | 416.1[±3.4] | 203.4[±10.7] | 315.0[±17.0]
    | 0.5[±0.0] |'
- en: '| 1 | 1.5 | 13.8[±0.2] | 3.1[±0.2] | 423.9[±7.3] | 219.9[±1.5] | 330.5[±2.5]
    | 0.5[±0.0] |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.5 | 13.8[±0.2] | 3.1[±0.2] | 423.9[±7.3] | 219.9[±1.5] | 330.5[±2.5]
    | 0.5[±0.0] |'
- en: '| 1 | 1.8 | 13.8[±0.4] | 2.7[±0.7] | 409.8[±5.3] | 216.2[±7.6] | 333.0[±32.0]
    | 0.5[±0.0] |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.8 | 13.8[±0.4] | 2.7[±0.7] | 409.8[±5.3] | 216.2[±7.6] | 333.0[±32.0]
    | 0.5[±0.0] |'
- en: '| 2 | 1.2 | 13.7[±0.3] | 2.2[±0.0] | 420.3[±2.2] | 201.5[±9.2] | 269.5[±11.5]
    | 0.5[±0.0] |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.2 | 13.7[±0.3] | 2.2[±0.0] | 420.3[±2.2] | 201.5[±9.2] | 269.5[±11.5]
    | 0.5[±0.0] |'
- en: '| 2 | 1.5 | 13.9[±1.0] | 3.0[±0.5] | 409.1[±12.2] | 237.9[±10.5] | 386.5[±32.5]
    | 0.5[±0.0] |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.5 | 13.9[±1.0] | 3.0[±0.5] | 409.1[±12.2] | 237.9[±10.5] | 386.5[±32.5]
    | 0.5[±0.0] |'
- en: '| 2 | 1.8 | 15.3[±1.0] | 1.9[±0.1] | 421.3[±13.0] | 210.6[±14.4] | 240.5[±30.5]
    | 0.4[±0.0] |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.8 | 15.3[±1.0] | 1.9[±0.1] | 421.3[±13.0] | 210.6[±14.4] | 240.5[±30.5]
    | 0.4[±0.0] |'
- en: '| 3 | 1.2 | 13.3[±0.3] | 3.8[±0.0] | 399.0[±16.8] | 227.5[±8.5] | 371.5[±10.5]
    | 0.5[±0.0] |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.2 | 13.3[±0.3] | 3.8[±0.0] | 399.0[±16.8] | 227.5[±8.5] | 371.5[±10.5]
    | 0.5[±0.0] |'
- en: '| 3 | 1.5 | 16.9[±0.4] | 1.9[±0.0] | 425.8[±5.6] | 225.5[±3.0] | 232.0[±26.0]
    | 0.4[±0.0] |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.5 | 16.9[±0.4] | 1.9[±0.0] | 425.8[±5.6] | 225.5[±3.0] | 232.0[±26.0]
    | 0.4[±0.0] |'
- en: '| 3 | 1.8 | 15.8[±1.6] | 2.0[±0.1] | 421.8[±1.8] | 222.2[±2.7] | 271.5[±13.5]
    | 0.4[±0.0] |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.8 | 15.8[±1.6] | 2.0[±0.1] | 421.8[±1.8] | 222.2[±2.7] | 271.5[±13.5]
    | 0.4[±0.0] |'
- en: F.3 Queue Sorting Strategies
  id: totrans-360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.3 队列排序策略
- en: 'As shown in Table [10](https://arxiv.org/html/2410.14152v1#A6.T10 "Table 10
    ‣ F.2 Participant Entry Conditions ‣ Appendix F Simulation-based Policy Analysis
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent"), we employ four different experiment settings for different
    sorting methods. Prioritizing vulnerable groups can markedly improve their satisfaction
    $\Delta F(V,NV)>0$. However, we can see that an increase in the satisfaction of
    vulnerable groups does not necessarily lead to an improvement in $SW$ of all participants.
    Additionally, giving priority to vulnerable groups doesn’t show disproportionately
    high satisfaction levels, surpassing those of non-vulnerable groups. This suggests
    that our policy effectively addresses the needs of vulnerable groups without granting
    them an excessive advantage.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '如表 [10](https://arxiv.org/html/2410.14152v1#A6.T10 "Table 10 ‣ F.2 Participant
    Entry Conditions ‣ Appendix F Simulation-based Policy Analysis ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")所示，我们为不同的排序方法设置了四种不同的实验条件。优先考虑弱势群体可以显著提高他们的满意度
    $\Delta F(V,NV)>0$。然而，我们可以看到，弱势群体满意度的提升不一定会导致所有参与者的 $SW$ 改善。此外，优先考虑弱势群体并没有表现出过高的满意度水平，超过了非弱势群体的水平。这表明我们的政策有效地满足了弱势群体的需求，同时没有给予他们过度的优势。'
- en: 'We conduct experiments on the $k$ and $c$ parameters in the waiting Queue mechanism.
    For the case of fixed $k$, as seen from Table [11](https://arxiv.org/html/2410.14152v1#A6.T11
    "Table 11 ‣ F.2 Participant Entry Conditions ‣ Appendix F Simulation-based Policy
    Analysis ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent"), the Avg $WT$ is inversely proportional to $c$. The smallest
    Var $r^{size}$ and the lowest Rop occurs at $k=3,c=1.2$, while the lowest co-Gini
    is achieved at $k=3$. In terms of satisfaction, the highest satisfaction is also
    observed at $k=3,c=1.5$; However, the configuration of $k=1,c=1.5$, despite having
    a high $SW$, also has a very high Rop, indicating a potential unfairness in allocation
    (e.g. a little number of affluent families can choose the largest houses, leading
    to high $SW$ in this group). Overall, the configuration of $k=3,c=1.8$ and $k=3,c=1.5$
    present the lowest co-Gini while maintaining relatively high $SW$, effectively
    balancing between societal satisfaction and societal fairness metrics.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '我们对等待队列机制中的$k$和$c$参数进行了实验。对于固定$k$的情况，如表[11](https://arxiv.org/html/2410.14152v1#A6.T11
    "Table 11 ‣ F.2 Participant Entry Conditions ‣ Appendix F Simulation-based Policy
    Analysis ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent")所示，平均等待时间($WT$)与$c$呈反比。最小的变异系数$ r^{size}$和最低的Rop出现在$k=3,c=1.2$时，而最低的共性Gini系数则出现在$k=3$时。从满意度角度来看，最高的满意度也出现在$k=3,c=1.5$时；然而，$k=1,c=1.5$的配置，尽管具有较高的社会福利($SW$)，也有很高的Rop，这表明分配中可能存在不公平（例如，少数富裕家庭能够选择最大的房子，导致该群体的$SW$较高）。总体来说，$k=3,c=1.8$和$k=3,c=1.5$的配置在保持较高$SW$的同时呈现最低的共性Gini系数，能够有效平衡社会满意度和社会公平性指标。'
- en: 'Additionally, we conduct the comparison experiment with theoretical model (As
    shown in Table [12](https://arxiv.org/html/2410.14152v1#A6.T12 "Table 12 ‣ F.3
    Queue Sorting Strategies ‣ Appendix F Simulation-based Policy Analysis ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")).
    The trends observed in our experiments are consistent with the theory model Chen
    et al. ([2018](https://arxiv.org/html/2410.14152v1#bib.bib11)): as the $k$ parameter
    in the waitlist mechanism increases, overall $SW$ increases.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，我们还与理论模型进行了比较实验（如表[12](https://arxiv.org/html/2410.14152v1#A6.T12 "Table
    12 ‣ F.3 Queue Sorting Strategies ‣ Appendix F Simulation-based Policy Analysis
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent")所示）。我们实验中观察到的趋势与理论模型Chen等人([2018](https://arxiv.org/html/2410.14152v1#bib.bib11))一致：当等待队列机制中的$k$参数增加时，整体$SW$增加。'
- en: 'Table 12: Comparison with theoretical model Chen et al. ([2018](https://arxiv.org/html/2410.14152v1#bib.bib11)):
    when $k$ is raised from 2 to 5.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 表12：与理论模型Chen等人([2018](https://arxiv.org/html/2410.14152v1#bib.bib11))的比较：当$k$从2增加到5时。
- en: '| $k$ | Increase in $SW$ |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| $k$ | $SW$的增加 |'
- en: '| --- | --- |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Simulated Value | Theoretical value |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 模拟值 | 理论值 |'
- en: '| --- | --- |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| $3$ | 2.4% | 1.5% |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| $3$ | 2.4% | 1.5% |'
- en: '| $4$ | 5.1% | 6.1% |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| $4$ | 5.1% | 6.1% |'
- en: '| $5$ | 11.8% | 10% |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| $5$ | 11.8% | 10% |'
- en: 'As indicated in Table [6](https://arxiv.org/html/2410.14152v1#A5.T6 "Table
    6 ‣ E.1 Ablation Study on Social Behavior ‣ Appendix E Turing Test for LLM-based
    Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy
    with LLM-based Agent"), incorporating social behavior into agents does not invariably
    lead to enhancements in overall societal fairness and satisfaction. This may be
    due to the reduction in collective benefits caused by the dissemination of false
    information and the pursuit of self-interest during social interactions, as listed
    in Appendix [H.2](https://arxiv.org/html/2410.14152v1#A8.SS2 "H.2 Emergent Behaviors
    ‣ Appendix H Case Study on LLM-based Agent ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent"). This observation aligns
    with our hypothesis that the irrational behaviors of agents can influence the
    outcomes of final policy implementation.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[6](https://arxiv.org/html/2410.14152v1#A5.T6 "Table 6 ‣ E.1 Ablation Study
    on Social Behavior ‣ Appendix E Turing Test for LLM-based Agent ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")所示，将社会行为融入智能体并不一定会改善整体社会公平性和满意度。这可能是由于在社会互动中，虚假信息的传播和自我利益的追求导致了集体利益的减少，详情请见附录[H.2](https://arxiv.org/html/2410.14152v1#A8.SS2
    "H.2 Emergent Behaviors ‣ Appendix H Case Study on LLM-based Agent ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent")。这一观察与我们的假设一致，即智能体的非理性行为可能影响最终政策执行的结果。'
- en: F.4 Case Study on Housing Quality
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.4 住房质量案例研究
- en: In the context of scarce resource allocation policies, the construction cost
    of resources is often directly linked to the economic level of the residents.
    Taking Shanghai’s public rental housing as an example Shen ([2015](https://arxiv.org/html/2410.14152v1#bib.bib41)),
    such housing provides residents with stable, spacious, well-decorated, furnished,
    and affordable living spaces that have lower prices than the market rate. However,
    the current public rental housing is merely 10% cheaper than the market price.
    This leads to migrant workers’ reluctance to pay more for accommodation. Their
    limited budget restricts their options to urban villages and group-renting housing.
    Due to GPT-3.5’s insensitivity to housing environment information, we utilize
    GPT-4 for the construction of agents.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在稀缺资源配置政策的背景下，资源的建设成本通常与居民的经济水平直接相关。以上海的公共租赁住房为例，沈（[2015](https://arxiv.org/html/2410.14152v1#bib.bib41)）指出，这类住房为居民提供稳定、宽敞、装饰精美、配备家具且价格低于市场价的可负担生活空间。然而，目前的公共租赁住房价格仅比市场价格便宜10%。这导致了外来务工人员不愿为住宿支付更高的费用。他们有限的预算使得他们的选择仅限于城中村和合租房。由于GPT-3.5对住房环境信息的敏感度较低，我们利用GPT-4来构建代理模型。
- en: 'To simulate this phenomenon, we adopt houses of three quality levels: (1) $H_{S}$:
    houses of standard quality, (2) $H_{H}$: maintaining the total area and unit rent
    unchanged, but halving the house size and doubling the number of houses, (3) $H_{B}$:
    replace private bathrooms in the houses with shared bathrooms. These were allocated
    to three categories of participants, categorized by income levels: the lowest
    20%, the middle 60%, and the highest 20%.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟这一现象，我们采用了三种质量等级的房屋： (1) $H_{S}$：标准质量的房屋，(2) $H_{H}$：保持总面积和单元租金不变，但将房屋面积减半并将房屋数量翻倍，(3)
    $H_{B}$：将房屋中的独立卫生间替换为共享卫生间。这些房屋被分配给三个不同收入层次的参与者：最低的20%、中等的60%和最高的20%。
- en: 'We analyze the core influencing factors of housing satisfaction among participants
    at different income levels. We refer to Huang’s categorization of influencing
    factors for housing satisfaction Huang et al. ([2015](https://arxiv.org/html/2410.14152v1#bib.bib19)),
    and divide the core factors affecting satisfaction into three categories: (1)
    Economic Factors: Public rental housing often has lower rent compared to market
    rates, making it an attractive option for tenants with limited budgets. (2) Neighborhood
    characteristics: Primarily include environmental sanitation, schools, and the
    extent of transportation coverage among other factors. (3) Housing characteristics:
    Primarily include the size of the house, age of the building, sound insulation,
    sunlight exposure, and other decorative elements.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析了不同收入层次参与者对住房满意度的核心影响因素。参考黄等（[2015](https://arxiv.org/html/2410.14152v1#bib.bib19)）对住房满意度影响因素的分类，我们将影响满意度的核心因素分为三类：(1)
    经济因素：公共租赁住房的租金通常低于市场价，成为预算有限的租户的理想选择。(2) 邻里特征：主要包括环境卫生、学校以及交通覆盖程度等因素。(3) 住房特征：主要包括房屋的大小、建筑年龄、隔音、阳光照射以及其他装修元素。
- en: 'Table 13: The weights of influencing factors for housing satisfaction across
    different income groups of participants.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 表13：不同收入层次参与者对住房满意度的影响因素权重。
- en: '|  | Economic | Neighborhood | Decoration |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '|  | 经济 | 邻里环境 | 装修 |'
- en: '| High income | 0.67 | 0.11 | 0.22 |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| 高收入 | 0.67 | 0.11 | 0.22 |'
- en: '| Middle income | 0.81 | 0.04 | 0.19 |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 中等收入 | 0.81 | 0.04 | 0.19 |'
- en: '| Low income | 0.90 | 0 | 0.10 | ![Refer to caption](img/b7ff9a47d56f1d172432476268078c59.png)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '| 低收入 | 0.90 | 0 | 0.10 | ![参见说明文字](img/b7ff9a47d56f1d172432476268078c59.png)'
- en: 'Figure 8: Frequency of House Choices by Income Level.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：按收入层次划分的住房选择频率。
- en: 'As illustrated in Fig. [8](https://arxiv.org/html/2410.14152v1#A6.F8 "Figure
    8 ‣ F.4 Case Study on Housing Quality ‣ Appendix F Simulation-based Policy Analysis
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent"), nearly all low-income participants choose a house when the
    rent is low (houses of half size), but their house choosing frequency drops to
    50% when housing prices increase due to better decoration. As demonstrated in
    Table [13](https://arxiv.org/html/2410.14152v1#A6.T13 "Table 13 ‣ F.4 Case Study
    on Housing Quality ‣ Appendix F Simulation-based Policy Analysis ‣ SRAP-Agent:
    Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent"),
    economic factors dominate the decision-making process for low-income participants
    in 90% of cases, prompting them to be price-sensitive and opt for more cost-effective
    choices. Conversely, high-income groups exhibit relative insensitivity to price
    fluctuations but demonstrate higher demands for housing quality. The frequency
    of house choosing frequency decreases by 9.1% when the size of the house is halved;
    moreover, when private bathrooms are removed from the houses, no one from the
    high-income group chooses to select a house. They are primarily influenced by
    the level of house decoration, leading them to spontaneously reject houses that
    are affordable but of lower quality. Mainly because they prefer better quality
    and well-decorated living spaces.'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [8](https://arxiv.org/html/2410.14152v1#A6.F8 "图 8 ‣ F.4 住房质量案例研究 ‣ 附录 F
    基于仿真的政策分析 ‣ SRAP-Agent：基于 LLM 的智能体模拟与优化稀缺资源分配政策") 所示，当租金较低（房屋面积减半）时，几乎所有低收入参与者都会选择住房，但随着房价因装修质量提升而上涨，他们的选房频率下降至
    50%。如表 [13](https://arxiv.org/html/2410.14152v1#A6.T13 "表 13 ‣ F.4 住房质量案例研究 ‣
    附录 F 基于仿真的政策分析 ‣ SRAP-Agent：基于 LLM 的智能体模拟与优化稀缺资源分配政策") 所示，经济因素在 90% 的情况下主导了低收入参与者的决策过程，促使他们对价格较为敏感，倾向于选择更具性价比的房源。相反，高收入群体对价格波动表现出相对的不敏感性，但对住房质量有更高的需求。当房屋面积减半时，选房频率下降了
    9.1%；而当房屋中私密卫生间被移除时，高收入群体中没有人选择住房。他们主要受到房屋装修水平的影响，导致他们自发地拒绝那些价格低廉但质量较差的房源。主要是因为他们更倾向于选择质量更好、装修更精美的居住空间。
- en: This finding suggests that if the government aims to support middle and low-income
    groups of city residents, the policymakers should consider reallocating the proportions
    of construction costs and housing subsidies. By reducing housing prices through
    these adjustments, the government could more effectively support and accommodate
    the needs of vulnerable groups with low incomes.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 这一发现表明，如果政府旨在支持中低收入群体，决策者应考虑重新分配建筑成本和住房补贴的比例。通过这些调整降低房价，政府可以更有效地支持并满足低收入群体的需求。
- en: F.5 Efficiency Analysis Experiments
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.5 效率分析实验
- en: To simulate the policy execution process among $n$ participants in SRAP-Agent,
    we leverage the community structure inherent in our social network framework.
    This framework mirrors real-world social networks by featuring dense connections
    within small communities and sparse connections across larger groups. Consequently,
    we assume the social network comprises $n$ participants and $k$ strongly connected
    components, with the largest strongly connected component containing $m$ participants.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟在 SRAP-Agent 中 $n$ 个参与者的政策执行过程，我们利用了我们社交网络框架中固有的社区结构。该框架通过在小型社区内部具有密集连接，而在较大群体之间连接稀疏的特点，模仿了现实世界中的社交网络。因此，我们假设社交网络包含
    $n$ 个参与者和 $k$ 个强连接组件，其中最大的强连接组件包含 $m$ 个参与者。
- en: Theoretical Time Complexity Analysis
  id: totrans-387
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 理论时间复杂度分析
- en: Given $N_{s}$ communication rounds, we set the size of the largest community
    structure to $m=10$. If the time cost for the inference process of LLM is $t_{a}$,
    then the theoretical time complexity is $O(N_{s}\cdot k\cdot m\cdot t_{a})$. Furthermore,
    we account for the sparse connections within the social network that influence
    information dissemination. In SRAP-Agent, we gather posts from all participants
    on a forum, allowing them to search on the forum. Searching relies on a vector
    database with an operation time cost $t_{v}\leq 0.005$. Assuming $N_{f}$ forum
    communication rounds, the theoretical time complexity for the forum is $O(N_{f}\cdot
    n\cdot(t_{a}+t_{v}))$.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 给定 $N_{s}$ 次通信回合，我们将最大社区结构的大小设置为 $m=10$。如果 LLM 推理过程的时间成本为 $t_{a}$，则理论时间复杂度为
    $O(N_{s}\cdot k\cdot m\cdot t_{a})$。此外，我们还考虑了影响信息传播的社交网络中的稀疏连接。在 SRAP-Agent 中，我们从所有参与者收集论坛帖子，允许他们在论坛中进行搜索。搜索依赖于具有操作时间成本
    $t_{v}\leq 0.005$ 的向量数据库。假设有 $N_{f}$ 次论坛通信回合，则论坛的理论时间复杂度为 $O(N_{f}\cdot n\cdot(t_{a}+t_{v}))$。
- en: Parallel Acceleration
  id: totrans-389
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 并行加速
- en: Because communications within each connected component can run in parallel,
    the actual runtime of SRAP-Agent can be accelerated using async or multiprocessing
    methods; our framework adopts the former. Consequently, the actual execution speed
    is not constrained by $k$, achieving an $k$-fold speedup.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 因为每个连接组件内部的通信可以并行进行，所以可以通过异步或多进程方法加速 SRAP-Agent 的实际运行时间；我们的框架采用前者。因此，实际执行速度不受
    $k$ 的限制，实现了 $k$ 倍加速。
- en: 'Table 14: The simulation time, number of API callings, and the budget for the
    policy simulation process in SRAP-Agent (based on GPT-3.5).'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 表 14：SRAP-Agent（基于 GPT-3.5）中策略模拟过程的模拟时间、API 调用次数和预算。
- en: '|  | Agent Number $n$ |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '|  | 代理数量 $n$ |'
- en: '|  | 10 | 50 | 100 | 200 |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '|  | 10 | 50 | 100 | 200 |'
- en: '| Time / min | 1.0E+01 | 2.5E+01 | 3.0E+01 | 3.0E+01 |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 时间 / 分钟 | 1.0E+01 | 2.5E+01 | 3.0E+01 | 3.0E+01 |'
- en: '| API calling | 3.0E+02 | 5.0E+02 | 1.0E+03 | 1.5E+03 |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| API 调用 | 3.0E+02 | 5.0E+02 | 1.0E+03 | 1.5E+03 |'
- en: '| Budget | 2$ | 3$ | 5$ | 8$ |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 预算 | 2$ | 3$ | 5$ | 8$ |'
- en: 'Different policy settings and resource quantities result in varying policy
    execution processes. In our experiments, we typically set $N_{s}>N_{f}$, indicating
    more intensive communication within small groups and less frequent communication
    across the entire network. Usually, $N_{s}=10\cdot N_{f}$. To test whether the
    increase in $n$ leads to excessive API calls and thus high costs, we select a
    representative policy setting ($p^{select}+r^{size}$) while maintaining a consistent
    ratio of $|R|$ to $|P|$ across all experiments. As shown in Table [14](https://arxiv.org/html/2410.14152v1#A6.T14
    "Table 14 ‣ Parallel Acceleration ‣ F.5 Efficiency Analysis Experiments ‣ Appendix
    F Simulation-based Policy Analysis ‣ SRAP-Agent: Simulating and Optimizing Scarce
    Resource Allocation Policy with LLM-based Agent"), it can be seen that the SRAP-Agent
    does not incur quadratic time costs as the number of participants increases. This
    is because: Firstly, We employ a sparse social network structure, which results
    in the theoretical number of API calls being linearly related to $k$ rather than
    $n^{2}$. Secondly, by running the strongly connected components of the social
    network in parallel using async, we can significantly reduce the time complexity.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '不同的策略设置和资源量会导致不同的策略执行过程。在我们的实验中，我们通常设置 $N_{s}>N_{f}$，这表明小组内的通信更为密集，而整个网络之间的通信较少。通常，$N_{s}=10\cdot
    N_{f}$。为了测试 $n$ 的增加是否会导致过多的 API 调用，从而产生高成本，我们选择了一个代表性的策略设置（$p^{select}+r^{size}$），同时保持所有实验中
    $|R|$ 与 $|P|$ 的比值一致。如表 [14](https://arxiv.org/html/2410.14152v1#A6.T14 "Table
    14 ‣ Parallel Acceleration ‣ F.5 Efficiency Analysis Experiments ‣ Appendix F
    Simulation-based Policy Analysis ‣ SRAP-Agent: Simulating and Optimizing Scarce
    Resource Allocation Policy with LLM-based Agent") 所示，可以看到，随着参与者数量的增加，SRAP-Agent
    并不会产生二次时间成本。这是因为：首先，我们采用了稀疏的社交网络结构，使得理论上的 API 调用次数与 $k$ 成线性关系，而不是 $n^{2}$。其次，通过使用异步方式并行运行社交网络的强连接组件，我们可以显著降低时间复杂度。'
- en: Appendix G POA
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G POA
- en: G.1 Hyper-parameters for POA
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.1 POA 的超参数
- en: 'We conduct diagnostic experiments to validate the efficacy of the POA algorithm.
    In the Genetic algorithm, we utilize vectorized policy parameters as genes. We
    adopt the Gaussian mutation operations as the mutation operator and two-point
    crossover as the crossover operator. The weight setting in Equation [3](https://arxiv.org/html/2410.14152v1#S4.E3
    "In 4 POA: Policy Optimization Algorithm ‣ SRAP-Agent: Simulating and Optimizing
    Scarce Resource Allocation Policy with LLM-based Agent") is very flexible and
    entirely dependent on the policymaker’s optimization goals. To modify the optimization
    objective of the policy optimizer, we can simply alter the weights for calculating
    the optimized metrics. When a heightened emphasis on optimizing societal satisfaction
    metrics is desired, it is advisable to increase the weights assigned to metrics
    such as $SW$ and Avg $r^{size}$. Conversely, to prioritize enhancing societal
    fairness metrics, it is recommended to augment the weights of Rop, Var $r^{size}$
    and co-Gini, as delineated in Table [15](https://arxiv.org/html/2410.14152v1#A7.T15
    "Table 15 ‣ G.1 Hyper-parameters for POA ‣ Appendix G POA ‣ SRAP-Agent: Simulating
    and Optimizing Scarce Resource Allocation Policy with LLM-based Agent").'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '我们进行诊断实验以验证 POA 算法的有效性。在遗传算法中，我们利用向量化的政策参数作为基因。我们采用高斯变异操作作为变异算子，并使用双点交叉作为交叉算子。方程
    [3](https://arxiv.org/html/2410.14152v1#S4.E3 "In 4 POA: Policy Optimization Algorithm
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent") 中的权重设置非常灵活，完全取决于政策制定者的优化目标。为了修改政策优化器的优化目标，我们只需更改用于计算优化指标的权重。当希望更加强调优化社会满意度指标时，建议增加
    $SW$ 和平均 $r^{size}$ 等指标的权重。相反，为了优先增强社会公平性指标，建议增加 Rop、方差 $r^{size}$ 和 co-Gini 的权重，如表
    [15](https://arxiv.org/html/2410.14152v1#A7.T15 "Table 15 ‣ G.1 Hyper-parameters
    for POA ‣ Appendix G POA ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource
    Allocation Policy with LLM-based Agent") 所示。'
- en: 'Table 15: Pre-set metric weights for different optimization objectives in POA.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 表 15：POA 中不同优化目标的预设指标权重。
- en: '|  | Metric | Optimization Objective |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '|  | 指标 | 优化目标 |'
- en: '| --- | --- | --- |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  | Satisfaction$\uparrow$ | Fairness$\uparrow$ |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '|  | 满意度$\uparrow$ | 公平性$\uparrow$ |'
- en: '| --- | --- | --- |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Satisfaction | Avg $r^{size}$ | 5 | 1 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 满意度 | 平均 $r^{size}$ | 5 | 1 |'
- en: '| Avg $WT$ | 5 | 1 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 平均 $WT$ | 5 | 1 |'
- en: '| $SW$ | 10 | 5 |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| $SW$ | 10 | 5 |'
- en: '| Fairness | Var $r^{size}$ | 1 | 10 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 公平性 | 方差 $r^{size}$ | 1 | 10 |'
- en: '| Rop | 5 | 10 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| Rop | 5 | 10 |'
- en: '| co-Gini | 1 | 10 |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| co-Gini | 1 | 10 |'
- en: '| F(V, NV) | 1 | 5 |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| F(V, NV) | 1 | 5 |'
- en: G.2 Comparison with Other Policies
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.2 与其他政策的比较
- en: 'To better evaluate the SRAP-Agent’s policy optimization in real-world scarce
    resource allocation scenarios, we choose four baseline policies: (1) three common
    policies for scarce resource allocation from the real world, including the public
    housing rental policies of Singapore, Beijing, and Hong Kong ($\pi_{S}$, $\pi_{B}$,
    $\pi_{H}$); (2) the policy based on optimal matching for the single metric $SW$.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地评估 SRAP-Agent 在现实世界稀缺资源分配场景中的政策优化，我们选择了四个基准政策：(1) 三个来自现实世界的常见稀缺资源分配政策，包括新加坡、北京和香港的公共住房租赁政策（$\pi_{S}$、$\pi_{B}$、$\pi_{H}$）；(2)
    基于单一指标 $SW$ 的最优匹配政策。
- en: '(1) $\pi_{S}$: Singapore’s housing allocation policy.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: (1) $\pi_{S}$：新加坡的住房分配政策。
- en: This policy uses a single-queue ($m=1$) distribution system. Each participant
    is granted three chances to choose ($c=3$). This policy adopts a FIFO sorting
    method. ⁴⁴4https://www.hdb.gov.sg/cs/infoweb/residential/renting-a-flat/renting-from-hdb/public-rental-scheme/eligibility
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 此政策使用单队列（$m=1$）分配系统。每个参与者有三次选择机会（$c=3$）。该政策采用 FIFO 排序方法。 ⁴⁴4https://www.hdb.gov.sg/cs/infoweb/residential/renting-a-flat/renting-from-hdb/public-rental-scheme/eligibility
- en: '(2) $\pi_{B}$: Beijing’s housing allocation policy.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: (2) $\pi_{B}$：北京的住房分配政策。
- en: This policy uses a multi-queue ($m=3$) distribution system. Each participant
    is granted three chances to choose ($c=2$), without considering a waitlist mechanism.
    Participants choose their preferred type of housing ($p^{select}$), and allocations
    of resources are based on house size ($r^{size}$). This policy adopts a FIFO sorting
    method. ⁵⁵5http://www.bjft.gov.cn/ftq/c100011/zlmlist.shtml
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 此政策使用多队列（$m=3$）分配系统。每个参与者有三次选择机会（$c=2$），且不考虑等候名单机制。参与者选择其首选类型的住房（$p^{select}$），资源分配基于住房面积（$r^{size}$）。该政策采用
    FIFO 排序方法。 ⁵⁵5http://www.bjft.gov.cn/ftq/c100011/zlmlist.shtml
- en: '(3) $\pi_{H}$: Hong Kong’s housing allocation policy.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: (3) $\pi_{H}$：香港的住房分配政策。
- en: This policy uses a single-queue system ($m=1$), but with a consideration for
    a waitlist mechanism, granting each participant two chances to choose a house
    ($k=2,c=2$). Houses are distributed randomly ($r^{random}$). This policy considers
    the prioritization of vulnerable groups and operates under a VFR sorting method.
    ⁶⁶6https://www.housingauthority.gov.hk/en/at-a-glance/index.html
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 该政策采用单队列系统（$m=1$），但考虑了候补机制，赋予每个参与者两次选择房屋的机会（$k=2,c=2$）。房屋按随机方式分配（$r^{random}$）。该政策考虑了弱势群体的优先权，并采用VFR排序方法。
    ⁶⁶6[https://www.housingauthority.gov.hk/en/at-a-glance/index.html](https://www.housingauthority.gov.hk/en/at-a-glance/index.html)
- en: '(4) $\pi_{KM}$: Policy optimized on the $SW$ metric.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: (4) $\pi_{KM}$：基于$SW$度量优化的政策。
- en: We first collect the satisfaction level of all participants for each resource.
    Then we calculate an optimal match on the single $SW$ metric, using the Bipartite
    Graph Matching algorithm (Kuhn-Munkres algorithm). It is important to note that
    the results derived from such a match represent a theoretical upper bound. Because
    participants cannot arbitrarily choose resources in a queuing system; the resources
    visible to each participant are limited.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先收集所有参与者对每个资源的满意度水平。然后，我们基于单一的$SW$度量计算最佳匹配，使用二分图匹配算法（Kuhn-Munkres算法）。需要注意的是，从这种匹配中得出的结果代表了理论上的上限。因为在排队系统中，参与者不能随意选择资源；每个参与者能够看到的资源是有限的。
- en: G.3 Other Global Search Metaheuristic Algorithms
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.3 其他全局搜索元启发式算法
- en: 'Table 16: Comparison experiments on different POA algorithms.'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 表16：不同POA算法的比较实验。
- en: '| POA | Satisfaction | Fairness |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| POA | 满意度 | 公平性 |'
- en: '| --- | --- | --- |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|  | Avg $r^{size}\uparrow$ | Avg $WT$ $\downarrow$ | $SW$ $\uparrow$ | Var
    $r^{size}\downarrow$ | Rop $\downarrow$ | co-Gini $\downarrow$ |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '|  | 平均$r^{size}\uparrow$ | 平均$WT$ $\downarrow$ | $SW$ $\uparrow$ | 方差$r^{size}\downarrow$
    | Rop $\downarrow$ | co-Gini $\downarrow$ |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| PSO-POA | 0.29 | 8.86 | 12.10 | 4.34 | 1 | 0.98 |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| PSO-POA | 0.29 | 8.86 | 12.10 | 4.34 | 1 | 0.98 |'
- en: '| PSO-POA | 0.70 | 8.82 | 26.20 | 12.05 | 10 | 0.96 |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| PSO-POA | 0.70 | 8.82 | 26.20 | 12.05 | 10 | 0.96 |'
- en: '| PSO-POA | 0.60 | 8.75 | 26.50 | 8.69 | 2 | 0.96 |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| PSO-POA | 0.60 | 8.75 | 26.50 | 8.69 | 2 | 0.96 |'
- en: '| PSO-POA | 1.45 | 8.39 | 62.40 | 26.00 | 40 | 0.93 |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| PSO-POA | 1.45 | 8.39 | 62.40 | 26.00 | 40 | 0.93 |'
- en: '| GA-POA | 15.18 | 2.96 | 403.30 | 273.87 | 396 | 0.50 |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| GA-POA | 15.18 | 2.96 | 403.30 | 273.87 | 396 | 0.50 |'
- en: 'To illustrate the necessity of using the GA algorithm for constructing POA,
    we develop a new particle swarm optimization (PSO) algorithm to construct POA
    (Policy Optimization Algorithm) and compare its performance with that of the GA
    algorithm. We choose the optimization objective of social satisfaction and use
    40 historical data as $\Pi_{h}$. Under these conditions, we run GA-POA and PSO-POA
    within 10 iterations. As shown in Table [16](https://arxiv.org/html/2410.14152v1#A7.T16
    "Table 16 ‣ G.3 Other Global Search Metaheuristic Algorithms ‣ Appendix G POA
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent"), since the optimization policy parameters are actually discrete
    variables, it is challenging for PSO to control the velocity and position parameters,
    ensuring that the policy remains a valid value and evolves in a better direction
    after changes.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '为了说明使用GA算法构建POA的必要性，我们开发了一种新的粒子群优化（PSO）算法来构建POA（政策优化算法），并将其与GA算法的性能进行比较。我们选择社会满意度作为优化目标，并使用40条历史数据作为$\Pi_{h}$。在这些条件下，我们在10次迭代内运行GA-POA和PSO-POA。如表[16](https://arxiv.org/html/2410.14152v1#A7.T16
    "Table 16 ‣ G.3 Other Global Search Metaheuristic Algorithms ‣ Appendix G POA
    ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with
    LLM-based Agent")所示，由于优化政策参数实际上是离散变量，PSO在控制速度和位置参数时面临挑战，需要确保政策在变化后保持有效值，并朝着更好的方向演化。'
- en: This is because, parameters of $\pi$ have relatively fixed parameters, such
    as queue numbers (3 or 2). However, PSO cannot reliably ensure this, leading to
    updated policy parameters that are either invalid or result in poor outcomes.
    In contrast, GA effectively explores the search space through selection, crossover,
    and mutation operations, possessing strong global search capabilities and avoiding
    local optima. GA can handle various types of optimization problems, making it
    more suitable for solving discrete problems. For POA, most time cost lies in the
    policy simulation process of the SRAP-Agent rather than the time cost of executing
    the optimization algorithm.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为，$\pi$的参数相对固定，如队列数量（3或2）。然而，PSO无法可靠地确保这一点，导致更新的策略参数无效或导致不良结果。相对而言，GA通过选择、交叉和变异操作有效地探索搜索空间，具有强大的全局搜索能力，避免了局部最优。GA能够处理各种类型的优化问题，使其更适合解决离散问题。对于POA，大部分时间成本集中在SRAP-Agent的策略仿真过程，而非执行优化算法的时间成本。
- en: G.4 Optimization Cost
  id: totrans-436
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.4 优化成本
- en: The primary cost in our POA is system simulation. Simulation of 50 participants
    in SRAP-Agent roughly takes 20 minutes, and thus, all simulations approximate
    between 40-60 iterations, equating to about 20 hours in total. This greatly reduces
    time costs compared to socio-economic simulation experiments. In consideration
    of the time-consuming aspect of POA, we employ a regressor to estimate the simulation
    outcomes of SRAP-Agent, specifically a Ridge Regressor ($\lambda=1.0$) to formulate
    the predictor. To control the number of training samples for the regressor while
    minimizing the time cost, a method of gradually adding training samples is adopted.
    The training of the regressor continues until the MAE error on the test dataset
    reaches the threshold (0.05).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的POA中主要的成本是系统仿真。SRAP-Agent中50个参与者的仿真大约需要20分钟，因此，所有仿真大致会进行40-60次迭代，总计大约需要20小时。这大大减少了与社会经济仿真实验相比的时间成本。考虑到POA的时间消耗问题，我们采用回归器来估计SRAP-Agent的仿真结果，具体采用Ridge回归器（$\lambda=1.0$）来构建预测模型。为了控制回归器的训练样本数量并最小化时间成本，采用逐渐增加训练样本的方法。回归器的训练会持续进行，直到测试数据集上的MAE误差达到阈值（0.05）。
- en: Appendix H Case Study on LLM-based Agent
  id: totrans-438
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录H LLM基础代理的案例研究
- en: H.1 Ablation Study on Memory Component
  id: totrans-439
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: H.1 记忆组件的消融实验
- en: 'Table 17: Policy evaluation metric results for simulating the $\pi_{e}$ execution
    process in the SRAP-Agent, built with LLM-based agents with and without memory.'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 表17：在SRAP-Agent中模拟$\pi_{e}$执行过程的政策评估指标结果，分别使用了具有和不具有记忆的LLM基础代理。
- en: '| Metric | with memory | without memory |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 有记忆 | 无记忆 |'
- en: '| --- | --- | --- |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Avg $r^{size}$ | 16.21 | 13.89 |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 平均 $r^{size}$ | 16.21 | 13.89 |'
- en: '| Avg $WT$ | 1.88 | 2.94 |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| 平均 $WT$ | 1.88 | 2.94 |'
- en: '| SW | 425.05 | 431.80 |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| SW | 425.05 | 431.80 |'
- en: '| Var $r^{size}$ | 202.63 | 209.43 |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| 方差 $r^{size}$ | 202.63 | 209.43 |'
- en: '| Rop | 193.50 | 342.00 |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| Rop | 193.50 | 342.00 |'
- en: '| co-Gini | 0.37 | 0.49 | ![Refer to caption](img/8e75f4bf4371ad48596090cf70d30a30.png)'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '| co-Gini | 0.37 | 0.49 | ![参考说明](img/8e75f4bf4371ad48596090cf70d30a30.png)'
- en: (a) Chatting dialogue between James and Emma.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: (a) James 和 Emma 之间的聊天对话。
- en: '![Refer to caption](img/88c7d8dadef798a512781f4a48d86661.png)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/88c7d8dadef798a512781f4a48d86661.png)'
- en: (b) Chatting dialogue between James and Oliver.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: (b) James 和 Oliver 之间的聊天对话。
- en: 'Figure 9: Emergent doubt and trust mental state in SRAP-Agent. Oliver is suspicious
    of the information provided by James and chooses to stop communication; whereas
    the discussion between James and Emma is informative and sincere.'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：SRAP-Agent中疑虑与信任的心理状态。Oliver对James提供的信息表示怀疑，选择停止沟通；而James和Emma之间的讨论则充满信息性和诚意。
- en: It can be observed that adding the memory mechanism significantly improves fairness
    metrics. For instance, ROP decreases by 43.5%, and the co-Gini decreases by 0.12,
    indicating that resource allocation is more equitable when the memory mechanism
    is present. Regarding satisfaction metrics, Avg $WT$ is notably reduced. This
    suggests that through communication and information dissemination via social networks,
    agents can better understand the current state of resource allocation, thereby
    influencing the overall allocation process and the final policy evaluation outcomes.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，加入记忆机制显著提高了公平性指标。例如，ROP减少了43.5%，而co-Gini减少了0.12，表明当存在记忆机制时，资源分配变得更加公平。在满意度指标方面，平均$WT$显著减少。这表明，通过社交网络中的沟通和信息传播，代理能够更好地理解当前的资源分配状态，从而影响整体分配过程和最终的策略评估结果。
- en: H.2 Emergent Behaviors
  id: totrans-454
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: H.2 新兴行为
- en: 'In the dynamics of interactions involving LLM-based Agents, the agent’s behavior,
    whether deceptive or cooperative, is preceded by a shift in its psychological
    state. Corresponding to these behavioral patterns, there are two primary psychological
    states: doubt and trust, as illustrated in Fig. [9](https://arxiv.org/html/2410.14152v1#A8.F9
    "Figure 9 ‣ H.1 Ablation Study on Memory Component ‣ Appendix H Case Study on
    LLM-based Agent ‣ SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation
    Policy with LLM-based Agent").'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及LLM基础的代理人的互动动态中，无论是欺骗性行为还是合作行为，代理人的行为都是在其心理状态发生变化之后的结果。与这些行为模式相对应的心理状态有两种主要类型：怀疑和信任，如图[9](https://arxiv.org/html/2410.14152v1#A8.F9
    "图 9 ‣ H.1 关于记忆组件的消融研究 ‣ 附录 H 基于LLM的代理案例研究 ‣ SRAP-Agent：模拟和优化稀缺资源分配政策与基于LLM的代理")所示。
- en: 'The figure portrays two distinct scenarios: one involving a conversation between
    James and the stranger, Oliver, and the other between James and his friend, Emma.
    In the dialogue with Oliver, Oliver initially withholds all information regarding
    available houses to maximize his own benefits. This tactic leads James to adopt
    a more cautious approach, perceiving Oliver as a formidable opponent. Consequently,
    James becomes more cautious in the dialogue, perceiving Oliver as a formidable
    opponent. He refrains from discussing his choices and instead emphasizes the advantages
    of other communities. In stark contrast, the interaction between James and Emma,
    his friend, is characterized by a display of genuine sincerity and mutual trust.
    Such interactions underscore the proficiency of the SRAP-Agent in mirroring human-like
    psychological responses and thought processes.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 图中描绘了两种不同的情境：一种是詹姆斯与陌生人奥利弗的对话，另一种是詹姆斯与他的朋友艾玛的对话。在与奥利弗的对话中，奥利弗最初隐瞒了所有关于可用房屋的信息，以最大化自己的利益。这一策略使得詹姆斯采取了更为谨慎的态度，将奥利弗视为一个强大的对手。因此，詹姆斯在对话中变得更加小心，认为奥利弗是一个强大的对手。他避免讨论自己的选择，而是强调其他社区的优势。与此截然不同的是，詹姆斯与朋友艾玛的互动则体现了真诚与相互信任的表现。这样的互动凸显了SRAP-Agent在模拟人类心理反应和思维过程方面的熟练程度。
- en: 'Table 18: The prompt template of *Utterance Generation*'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 18：*话语生成*的提示模板
- en: '<svg class="ltx_picture" height="174.23" id="A8.T18.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,174.23) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="146.67" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">{concise role description}
    Here is your memory {memory} Your goal is to rent one house. For now, you want
    to discuss this with some acquaintances. {utterance plan} Your acquaintances include:
    {acquaintances} Your recent chat records with your acquaintances: {recent chats}
    {The example of group discuss response} !![IMPORTANT]: the information in EXAMPLE
    should NOT appear in response !! - Respond in this format: Thought: (You always
    think about what to do) Acquaintance: (Acquaintance name, could be a list or string)
    Output: (things you want to tell this Acquaintance in particular, stay consistent
    with your plan and thought) .. (this Thought/Acquaintance/Output repeat at most
    {acquaintance number} times!!) Respond in first person:</foreignobject></g></g></svg>'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="174.23" id="A8.T18.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,174.23) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="146.67" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">{concise role description}
    Here is your memory {memory} Your goal is to rent one house. For now, you want
    to discuss this with some acquaintances. {utterance plan} Your acquaintances include:
    {acquaintances} Your recent chat records with your acquaintances: {recent chats}
    {The example of group discuss response} !![IMPORTANT]: the information in EXAMPLE
    should NOT appear in response !! - Respond in this format: Thought: (You always
    think about what to do) Acquaintance: (Acquaintance name, could be a list or string)
    Output: (things you want to tell this Acquaintance in particular, stay consistent
    with your plan and thought) .. (this Thought/Acquaintance/Output repeat at most
    {acquaintance number} times!!) Respond in first person:</foreignobject></g></g></svg>'
- en: 'Table 19: The prompt template of *Communication Plan Generation*'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 19：*沟通计划生成*的提示模板
- en: '<svg class="ltx_picture" height="91.21" id="A8.T19.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,91.21) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="63.65" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">{role description} You want
    to rent a house. For now, you want to discuss this with some acquaintances. {acquaintance
    description} Here is your memory {memory} The current situation of the renting
    system is: {system competitiveness description} Your personality is {personality}
    {goal} Respond in this format: {respond format} Respond in the second person:</foreignobject></g></g></svg>'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="91.21" id="A8.T19.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,91.21) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="63.65" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">{role description} You want
    to rent a house. For now, you want to discuss this with some acquaintances. {acquaintance
    description} Here is your memory {memory} The current situation of the renting
    system is: {system competitiveness description} Your personality is {personality}
    {goal} Respond in this format: {respond format} Respond in the second person:</foreignobject></g></g></svg>'
- en: 'Table 20: The prompt template of *Decision-making process*'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 20：*决策过程*的提示模板
- en: '<svg class="ltx_picture" height="141.02" id="A8.T20.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,141.02) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="113.46" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Choosing one house needs the
    following steps: 1\. Choose a community 2\. Choose the type of house 3\. Choose
    a house This is information you collected from previous conversations with others:
    {memory} {role description} You’re planning to choose one house. To choose a house
    that satisfies you, you are going to {task}. {house info} {thought hint} - If
    you made up your choice, respond in this format: Thought: ({thought type}) Action:
    Choose Action Input: {choose type}. - If you chose none of them, respond in this
    format: Thought: ({thought type}) Action: Give up Action Input: I choose none
    of these options.</foreignobject></g></g></svg>'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="141.02" id="A8.T20.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,141.02) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="113.46" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Choosing one house needs the
    following steps: 1\. Choose a community 2\. Choose the type of house 3\. Choose
    a house This is information you collected from previous conversations with others:
    {memory} {role description} You’re planning to choose one house. To choose a house
    that satisfies you, you are going to {task}. {house info} {thought hint} - If
    you made up your choice, respond in this format: Thought: ({thought type}) Action:
    Choose Action Input: {choose type}. - If you chose none of them, respond in this
    format: Thought: ({thought type}) Action: Give up Action Input: I choose none
    of these options.</foreignobject></g></g></svg>'
- en: 'Table 21: The prompt template of *Broadcasting*'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 21：*广播*的提示模板
- en: '<svg class="ltx_picture" height="185.65" id="A8.T21.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,185.65) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="158.09" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">{role description} Here’s your
    plan to publish info online: {plan} Here is your memory: {memory} You can publish
    house information online if you want to. The Info you posted should contain information
    about the community, house and The available community index should be one of
    [{community ids}]. - If you want to publish house information online, respond
    in this format: Thought: (your view on the information you want to publish) Action:
    Publish Community: (community index, should be one of [{community ids}]) Info:
    (The information you want to publish about this community, stay consistent with
    your plan and thought; Ensure that the information is specific and clear) - If
    you don’t want to publish anything respond in this format: Thought: (reason why
    you don’t want to publish anything) Action: Give up</foreignobject></g></g></svg>'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="185.65" id="A8.T21.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,185.65) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="158.09" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">{role description} Here’s your
    plan to publish info online: {plan} Here is your memory: {memory} You can publish
    house information online if you want to. The Info you posted should contain information
    about the community, house and The available community index should be one of
    [{community ids}]. - If you want to publish house information online, respond
    in this format: Thought: (your view on the information you want to publish) Action:
    Publish Community: (community index, should be one of [{community ids}]) Info:
    (The information you want to publish about this community, stay consistent with
    your plan and thought; Ensure that the information is specific and clear) - If
    you don’t want to publish anything respond in this format: Thought: (reason why
    you don’t want to publish anything) Action: Give up</foreignobject></g></g></svg>'
- en: 'Table 22: The prompt template of *Relation Evaluation*'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 22：*关系评估*的提示模板
- en: '<svg class="ltx_picture" height="257.25" id="A8.T22.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,257.25) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="229.69" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Your relationship with your
    acquaintances may include: Friend: A person with whom one shares a close and mutually
    supportive bond of affection and trust. Enemy: A person who is actively opposed
    or hostile to another, often due to conflicts or animosity. Competitor: Someone
    who engages in rivalry or competition with another, typically in the same field
    or for the same goal. Mate: A partner in a romantic or sexual relationship, often
    implying a deep emotional connection. Colleague: A person with whom one works
    or collaborates, typically within the same organization or profession. Stranger:
    An individual who is not known or familiar to someone, often encountered for the
    first time. Your task is to update your relation with {acquaintance name}, based
    on your previous view of {acquaintance name} and recent communication. {role description}
    Here is your memory: {memory} {relation} Here’s your recent communication with
    {acquaintance name}: {communication} - Respond in this format: My Relation with
    A: friend (friend/enemy/competitor/mate/colleague/stranger/..) A is an honest
    and trustworthy person, and I think he is worth making friends with. (My view
    of this person) Respond:</foreignobject></g></g></svg>'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="257.25" id="A8.T22.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,257.25) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="229.69" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Your relationship with your
    acquaintances may include: Friend: A person with whom one shares a close and mutually
    supportive bond of affection and trust. Enemy: A person who is actively opposed
    or hostile to another, often due to conflicts or animosity. Competitor: Someone
    who engages in rivalry or competition with another, typically in the same field
    or for the same goal. Mate: A partner in a romantic or sexual relationship, often
    implying a deep emotional connection. Colleague: A person with whom one works
    or collaborates, typically within the same organization or profession. Stranger:
    An individual who is not known or familiar to someone, often encountered for the
    first time. Your task is to update your relation with {acquaintance name}, based
    on your previous view of {acquaintance name} and recent communication. {role description}
    Here is your memory: {memory} {relation} Here’s your recent communication with
    {acquaintance name}: {communication} - Respond in this format: My Relation with
    A: friend (friend/enemy/competitor/mate/colleague/stranger/..) A is an honest
    and trustworthy person, and I think he is worth making friends with. (My view
    of this person) Respond:</foreignobject></g></g></svg>'
- en: 'Table 23: The prompt template of *Memory Reflection*'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 23：*记忆反思*的提示模板
- en: '<svg class="ltx_picture" height="141.02" id="A8.T23.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,141.02) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="113.46" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Progressively summarize new
    lines provided, adding onto the previous summary and returning a new summary.
    EXAMPLE Current summary: You think a large house is too big for your family. And
    you didn’t make a choice. New lines: Thought: The middle house can accommodate
    my family to live in and has high cost-effectiveness. Output: My choice is the
    middle house. New summary: You think a middle house can accommodate your family
    members, better than a large house. And you choose a middle house. END OF EXAMPLE
    Current summary: {summary} New lines of conversation: {new lines} New summary:</foreignobject></g></g></svg>'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="141.02" id="A8.T23.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,141.02) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="113.46" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Progressively summarize new
    lines provided, adding onto the previous summary and returning a new summary.
    EXAMPLE Current summary: You think a large house is too big for your family. And
    you didn’t make a choice. New lines: Thought: The middle house can accommodate
    my family to live in and has high cost-effectiveness. Output: My choice is the
    middle house. New summary: You think a middle house can accommodate your family
    members, better than a large house. And you choose a middle house. END OF EXAMPLE
    Current summary: {summary} New lines of conversation: {new lines} New summary:</foreignobject></g></g></svg>'
- en: 'Table 24: The prompt template of *Memory Assessment*'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 24：*记忆评估*的提示模板
- en: '<svg class="ltx_picture" height="224.04" id="A8.T24.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,224.04) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="196.49" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You’re {name}. You’re planning
    to choose one house. Your task is to use MEMORY to assess the credibility of the
    forum information and summarize the useful information in the forum information
    based on your previous summary. MEMORY: {memory} End of MEMORY Here’s the forum
    information: {forum info} [!Important!]: Keep in mind that you and your competitors
    are vying to rent a house. Both you and your competitors can share diverse information
    on the forum. And you get forum information from this platform. Remember to save
    the sequence number of the information you believe in in the summary content -
    Respond in this format: Trusted: (Summary of the useful information, which you
    assessed as trustworthy in the forum information) Suspicious: (Summary of the
    suspicious information, which you suspicious as trustworthy in the forum information;
    If there’s no suspicious information, simply return None) Reason: (why do other
    competitors say these things? Try to find a reasonable intention for their intention.)
    Respond:</foreignobject></g></g></svg>'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '<svg class="ltx_picture" height="224.04" id="A8.T24.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,224.04) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="196.49" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">You’re {name}. You’re planning
    to choose one house. Your task is to use MEMORY to assess the credibility of the
    forum information and summarize the useful information in the forum information
    based on your previous summary. MEMORY: {memory} End of MEMORY Here’s the forum
    information: {forum info} [!Important!]: Keep in mind that you and your competitors
    are vying to rent a house. Both you and your competitors can share diverse information
    on the forum. And you get forum information from this platform. Remember to save
    the sequence number of the information you believe in in the summary content -
    Respond in this format: Trusted: (Summary of the useful information, which you
    assessed as trustworthy in the forum information) Suspicious: (Summary of the
    suspicious information, which you suspicious as trustworthy in the forum information;
    If there’s no suspicious information, simply return None) Reason: (why do other
    competitors say these things? Try to find a reasonable intention for their intention.)
    Respond:</foreignobject></g></g></svg>'
