- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:11:32'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:11:32
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning in
    Social VR'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ELLMA-T：一个支持社交虚拟现实中英语学习的具身大语言模型代理
- en: 来源：[https://arxiv.org/html/2410.02406/](https://arxiv.org/html/2410.02406/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2410.02406/](https://arxiv.org/html/2410.02406/)
- en: \quotingsetup
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \quotingsetup
- en: leftmargin=1.5em, rightmargin=1.5em, vskip=0pt
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 左边距=1.5em，右边距=1.5em，垂直间距=0pt
- en: Mengxu Pan [pan.meng@northeastern.edu](mailto:pan.meng@northeastern.edu) Khoury
    College of Computer Science, Northeastern UniversityVancouverCanada ,  Alexandra
    Kitson [akitson@sfu.ca](mailto:akitson@sfu.ca) [0003-3479-5297](https://orcid.org/0003-3479-5297
    "ORCID identifier") Simon Fraser UniversityVancouverBCCanada ,  Hongyu Wan [wan.hongy@northeastern.edu](mailto:wan.hongy@northeastern.edu)
    Khoury College of Computer Science, Northeastern UniversityVancouverCanada  and 
    Mirjana Prpa [m.prpa@northeastern.edu](mailto:m.prpa@northeastern.edu) Khoury
    College of Computer Science, Northeastern UniversityVancouverCanada
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Mengxu Pan [pan.meng@northeastern.edu](mailto:pan.meng@northeastern.edu) 诺思伊斯特大学计算机科学学院
    加拿大温哥华， Alexandra Kitson [akitson@sfu.ca](mailto:akitson@sfu.ca) [0003-3479-5297](https://orcid.org/0003-3479-5297
    "ORCID标识符") 西蒙弗雷泽大学 加拿大温哥华BC， Hongyu Wan [wan.hongy@northeastern.edu](mailto:wan.hongy@northeastern.edu)
    诺思伊斯特大学计算机科学学院 加拿大温哥华， Mirjana Prpa [m.prpa@northeastern.edu](mailto:m.prpa@northeastern.edu)
    诺思伊斯特大学计算机科学学院 加拿大温哥华
- en: Abstract.
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Many people struggle with learning a new language, with traditional tools falling
    short in providing contextualized learning tailored to each learner’s needs. The
    recent development of large language models (LLMs) and embodied conversational
    agents (ECAs) in social virtual reality (VR) provide new opportunities to practice
    language learning in a contextualized and naturalistic way that takes into account
    the learner’s language level and needs. To explore this opportunity, we developed
    ELLMA-T, an ECA that leverages an LLM (GPT-4) and situated learning framework
    for supporting learning English language in social VR (VRChat). Drawing on qualitative
    interviews (N=12), we reveal the potential of ELLMA-T to generate realistic, believable
    and context-specific role plays for agent-learner interaction in VR, and LLM’s
    capability to provide initial language assessment and continuous feedback to learners.
    We provide five design implications for the future development of LLM-based language
    agents in social VR.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 很多人在学习新语言时遇到困难，传统工具未能提供针对每个学习者需求的情境化学习。近年来，大型语言模型（LLMs）和具身对话代理（ECAs）在社交虚拟现实（VR）中的发展，提供了通过情境化和自然的方式进行语言学习的新机会，这种方式考虑了学习者的语言水平和需求。为了探索这一机会，我们开发了ELLMA-T，一个利用LLM（GPT-4）和情境化学习框架的具身对话代理，支持在社交VR（VRChat）中学习英语。通过定性访谈（N=12），我们揭示了ELLMA-T在VR中为代理-学习者互动生成真实、可信且特定情境的角色扮演的潜力，以及LLM在提供初步语言评估和持续反馈方面的能力。我们为未来LLM基础语言代理在社交VR中的发展提供了五个设计启示。
- en: 'Embodied Conversational Agents, Social Virtual Reality, Large Language Models,
    Language Learning^†^†conference: ArXiv Preprint; September 2024;![Refer to caption](img/921d33ba6529d5eeb8b682cc6c893ccd.png)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 具身对话代理、社交虚拟现实、大型语言模型、语言学习^†^†会议：ArXiv预印本；2024年9月；![请参见标题说明](img/921d33ba6529d5eeb8b682cc6c893ccd.png)
- en: Figure 1\. a) ELLMA-T, the GPT-4 based language tutor in VRChat; b) b) ELLMA-T
    greeting the user in their native language; c) Role-play scenario with ELLMA-T
    and the user in a supermarket setting; d) User asking ELLMA-T for word explanations.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. a) ELLMA-T，基于GPT-4的VRChat语言导师；b) ELLMA-T以用户的母语向其问候；c) ELLMA-T与用户在超市场景中的角色扮演；d)
    用户向ELLMA-T询问单词解释。
- en: \Description
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: A teaser figure shows the introduction of ELLMA-T, a GPT-4 based ECA in VRchat
    in a role-play at a supermarket scenario.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一幅预览图展示了ELLMA-T的介绍，这是一个基于GPT-4的具身对话代理，在VRChat中的超市角色扮演场景。
- en: 1\. Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Acquiring proficiency in English as an additional language is essential for
    many facets of life. This applies to both countries where English is taught as
    part of the compulsory curriculum, even though it is not the native language,
    and to English-speaking countries where different people, such as immigrants,
    visitors, tourists or international students require additional support to practice
    and improve their English skills (Adjagbodjou and Kaufman, [2024](https://arxiv.org/html/2410.02406v1#bib.bib2)).
    Commonly used learning approaches administered in traditional classrooms often
    fall short of providing a contextualized learning environment, tailored learning
    materials, and engaging experiences to support learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握英语作为第二语言对生活的各个方面至关重要。这不仅适用于那些将英语作为必修课程的一部分教授的国家，即使英语不是母语，亦适用于英语国家，那些需要额外支持来练习和提高英语技能的人群，如移民、访客、游客或国际学生（Adjagbodjou和Kaufman，[2024](https://arxiv.org/html/2410.02406v1#bib.bib2)）。在传统课堂中，常用的学习方法往往无法提供一个有情境的学习环境、量身定制的学习材料以及富有吸引力的体验来支持学习。
- en: Besides commonly used language learning tools (e.g., mobile applications such
    as Duolingo (Duolingo, [2023](https://arxiv.org/html/2410.02406v1#bib.bib25))),
    the recent proliferation of social Virtual Reality (VR) platforms presents new
    learning channels. VRChat (VRChat, [2024b](https://arxiv.org/html/2410.02406v1#bib.bib72))
    has become a popular social platform for online interactions in a virtual environment
    with over 48k daily active users and 8̃.8 million total. Though not specifically
    designed for foreign language learning, players take advantage of its immersive
    environment to have authentic conversation experiences with native speakers (Merle_Meruru555,
    [2024](https://arxiv.org/html/2410.02406v1#bib.bib52)). Previous research has
    shown social interactions in VR to be positive and helpful for learning a foreign
    language (Peterson, [2012](https://arxiv.org/html/2410.02406v1#bib.bib58); Cho
    et al., [2022](https://arxiv.org/html/2410.02406v1#bib.bib17)). Meanwhile, players
    encounter numerous obstacles when undertaking such endeavors. For example, it
    can be difficult and time-consuming to find a native speaker to interact with;
    and even when found, native speakers may not be willing or suitable to act as
    language tutors. Moreover, users may experience increased social anxiety during
    the search and interaction and overall the learning experience is deemed to be
    unsystematic (Roy and Aimee, [2020](https://arxiv.org/html/2410.02406v1#bib.bib63);
    Jouzu Juls, [2022](https://arxiv.org/html/2410.02406v1#bib.bib35)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了常用的语言学习工具（例如移动应用程序如Duolingo（Duolingo，[2023](https://arxiv.org/html/2410.02406v1#bib.bib25)）），最近社交虚拟现实（VR）平台的普及为学习提供了新的渠道。VRChat（VRChat，[2024b](https://arxiv.org/html/2410.02406v1#bib.bib72)）已经成为一个受欢迎的社交平台，用户可以在虚拟环境中进行在线互动，日活跃用户超过48k，总用户数达到8̃.8百万。虽然VRChat并非专门为外语学习设计，但玩家利用其沉浸式环境，与母语者进行真实的对话体验（Merle_Meruru555，[2024](https://arxiv.org/html/2410.02406v1#bib.bib52)）。以往的研究表明，虚拟现实中的社交互动对外语学习是积极且有帮助的（Peterson，[2012](https://arxiv.org/html/2410.02406v1#bib.bib58);
    Cho等，[2022](https://arxiv.org/html/2410.02406v1#bib.bib17)）。与此同时，玩家在进行这种学习尝试时会遇到许多障碍。例如，找到一个愿意互动的母语者可能既困难又耗时；即便找到了，母语者也可能不愿意或不适合担任语言辅导员。此外，用户在搜索和互动过程中可能会增加社交焦虑，总体上，学习体验被认为是非系统性的（Roy和Aimee，[2020](https://arxiv.org/html/2410.02406v1#bib.bib63);
    Jouzu Juls，[2022](https://arxiv.org/html/2410.02406v1#bib.bib35)）。
- en: 'The recent emergence of LLM-based embodied conversational agents (ECA) in social
    VR, such as Celeste AI (ko fi.com, [2024](https://arxiv.org/html/2410.02406v1#bib.bib40)),
    has received significant attention from VRChat users because they converse and
    behave in human-like ways. This presents an immediate opportunity to leverage
    LLM-agents for language learning in social VR. While LLMs have been explored for
    various educational purposes (Kasneci et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib37)),
    their application in language learning, especially in social VR contexts, remains
    underexplored. To that end, we present our efforts to answer the following research
    question (RQ): How can we leverage situated learning and an LLM-based ECA for
    language learning in social VR?'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 近期，基于LLM的具身对话代理（ECA）在社交虚拟现实中的出现，如Celeste AI (ko fi.com, [2024](https://arxiv.org/html/2410.02406v1#bib.bib40))，因其以类人方式进行对话和行为，已引起VRChat用户的广泛关注。这为在社交虚拟现实中利用LLM代理进行语言学习提供了一个即时机会。尽管LLM已被探索用于各种教育目的（Kasneci
    et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib37)），但其在语言学习，特别是在社交虚拟现实中的应用仍未得到充分探索。为此，我们展示了我们的努力，旨在回答以下研究问题（RQ）：我们如何在社交虚拟现实中利用情境学习和基于LLM的ECA进行语言学习？
- en: 'We built ELLMA-T, an embodied LLM-agent to explore the potential of using LLMs
    and situated learning framework (Brown et al., [1989](https://arxiv.org/html/2410.02406v1#bib.bib8);
    Lave and Wenger, [1991](https://arxiv.org/html/2410.02406v1#bib.bib44)) to facilitate
    language learning in social VR and conducted a user study (N=12) with ELLMA-T
    using semi-structured interviews. By leveraging an LLM-based agent in VRChat,
    the system aims to provide an authentic conversation experience and personalized
    feedback to users, enhancing the contextualized language learning experience.
    The contributions we present in this paper are the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了ELLMA-T，一个具身的LLM代理，旨在探索使用LLM和情境学习框架（Brown et al., [1989](https://arxiv.org/html/2410.02406v1#bib.bib8);
    Lave and Wenger, [1991](https://arxiv.org/html/2410.02406v1#bib.bib44)）在社交虚拟现实中促进语言学习的潜力，并进行了用户研究（N=12），使用半结构化访谈对ELLMA-T进行评估。通过在VRChat中利用基于LLM的代理，该系统旨在为用户提供真实的对话体验和个性化反馈，增强情境化语言学习体验。我们在本文中提出的贡献包括：
- en: (1)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: Design of ELLMA-T, an embodied LLM-agent tasked to help adult language learners
    from A1 to C1 level practice spoken English, by simulating an immersive real-life
    conversation within social VR;
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设计了ELLMA-T，一个具身的LLM代理，旨在通过模拟沉浸式的真实对话，帮助成人语言学习者从A1到C1水平练习口语英语，运用于社交虚拟现实中；
- en: (2)
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: 'A user study and findings about participants’ perception of ELLMA-T’s capabilities
    and limitations on four English learning tasks: language level assessment, role-play
    dialogue generation, feedback generation, and scaffolding abilities, contributing
    to the larger picture of LLM-assisted language learning and LLM’s applications;'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一项用户研究及其结果，关于参与者对ELLMA-T在四项英语学习任务中的能力和局限性的认知：语言水平评估、角色扮演对话生成、反馈生成和支架能力，贡献于更广泛的LLM辅助语言学习和LLM应用的全景；
- en: (3)
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: Design implications for designing embodied LLM-agents in social VR context for
    language learning.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设计对社交虚拟现实环境中语言学习具身LLM代理设计的启示。
- en: Our findings from a preliminary user study demonstrate ELLMA-T’s potential as
    a ’human-like’ language tutor for situated language learning. However, challenges
    such as conversation flow disruptions and insufficient emotional support were
    identified, suggesting areas for future improvement. The study’s design implications
    extend to the design of personalized, culturally relevant, and adaptive learning
    systems that integrate verbal and non-verbal cues. These findings highlight the
    potential for further exploration into developing LLM-based ECAs in social VR
    for long-term language learning.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 来自初步用户研究的结果表明，ELLMA-T作为一个“类人”的语言辅导员在情境语言学习中具有潜力。然而，也发现了一些挑战，如对话流畅性中断和情感支持不足，这表明未来改进的方向。研究的设计启示扩展到了个性化、文化相关和自适应学习系统的设计，这些系统整合了语言和非语言线索。这些发现突显了进一步探索在社交虚拟现实中开发基于LLM的ECA以支持长期语言学习的潜力。
- en: 2\. Related Work
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: 2.1\. Supporting Situated Language Learning in VR
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 在虚拟现实中支持情境语言学习
- en: Situated learning theory is grounded in the understanding that the most effective
    learning happens in context. Learning can neither be separated from the specific
    situations in which it occurs nor be transferred or applied fully in a school
    setting (Brown et al., [1989](https://arxiv.org/html/2410.02406v1#bib.bib8); Lave
    and Wenger, [1991](https://arxiv.org/html/2410.02406v1#bib.bib44)). In language
    acquisition, an authentic context provides learning opportunities that closely
    simulate real-life situations and includes cultural nuances crucial for meaningful
    and engaging language use (Lan, [2020](https://arxiv.org/html/2410.02406v1#bib.bib43)),
    for example, discerning the nuances and subtleties of word usage in polysemous
    situations (Wong et al., [2018](https://arxiv.org/html/2410.02406v1#bib.bib76)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 情境学习理论基于这样一个理解：最有效的学习发生在特定的情境中。学习既不能脱离它发生的具体情境，也不能完全转移或在学校环境中应用（Brown等， [1989](https://arxiv.org/html/2410.02406v1#bib.bib8);
    Lave和Wenger， [1991](https://arxiv.org/html/2410.02406v1#bib.bib44)）。在语言习得中，真实的情境提供了紧密模拟现实生活情境的学习机会，并包括对有意义和吸引人的语言使用至关重要的文化细微差别（Lan，
    [2020](https://arxiv.org/html/2410.02406v1#bib.bib43)），例如，在多义词的情境中辨别词语使用的细微差别和微妙之处（Wong等，
    [2018](https://arxiv.org/html/2410.02406v1#bib.bib76)）。
- en: The immersive nature of VR is particularly suitable for creating a realistic
    language learning environment and simulating interpersonal interactions in context-rich
    scenarios. Since 2013 and the expansion of affordable head-mounted displays (Dhimolea
    et al., [2022](https://arxiv.org/html/2410.02406v1#bib.bib22); Limniou et al.,
    [2008](https://arxiv.org/html/2410.02406v1#bib.bib48)), VR has been widely utilized
    in many areas of training and education (Aïm et al., [2016](https://arxiv.org/html/2410.02406v1#bib.bib5);
    Zhu et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib86)). Within VR,
    3D objects and avatars have been used to facilitate embodied and contextualized
    learning experiences (Chatain et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib13)).
    With rapid advancements in VR headsets, learners experience a heightened sense
    of presence, increased agency, and embodiment that support learning comparable
    to learning-by-doing in the physical world (Kaplan-Rakowski and Gruber, [2021](https://arxiv.org/html/2410.02406v1#bib.bib36)).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟现实（VR）的沉浸式特性特别适合于创建一个逼真的语言学习环境，并模拟在情境丰富的场景中进行人际互动。自2013年以来，随着价格适中的头戴显示器的普及（Dhimolea等，
    [2022](https://arxiv.org/html/2410.02406v1#bib.bib22); Limniou等， [2008](https://arxiv.org/html/2410.02406v1#bib.bib48)），VR已广泛应用于许多培训和教育领域（Aïm等，
    [2016](https://arxiv.org/html/2410.02406v1#bib.bib5); Zhu等， [2023](https://arxiv.org/html/2410.02406v1#bib.bib86)）。在VR中，3D物体和虚拟化身被用来促进具身化和情境化的学习体验（Chatain等，
    [2023](https://arxiv.org/html/2410.02406v1#bib.bib13)）。随着VR头显的快速发展，学习者体验到更强烈的临场感、增强的行动能力和具身感，这些都支持与在物理世界中通过实践学习相媲美的学习体验（Kaplan-Rakowski和Gruber，
    [2021](https://arxiv.org/html/2410.02406v1#bib.bib36)）。
- en: A growing body of literature has investigated the usage of VR for English as
    foreign language (EFL) learning, specifically how VR environments can be used
    for different language learning tasks (Lin and Lan, [2015](https://arxiv.org/html/2410.02406v1#bib.bib49);
    Klimova, [2021](https://arxiv.org/html/2410.02406v1#bib.bib39); Dhimolea et al.,
    [2022](https://arxiv.org/html/2410.02406v1#bib.bib22)). Research indicates that
    VR is beneficial for vocabulary acquisition, communication skills, and writing
    skills (Lan, [2020](https://arxiv.org/html/2410.02406v1#bib.bib43)). Other benefits
    of using VR for EFL learning include increased learners’ motivation, engagement,
    enjoyment, automation (Makransky and Lilleholt, [2018](https://arxiv.org/html/2410.02406v1#bib.bib51);
    Lan, [2020](https://arxiv.org/html/2410.02406v1#bib.bib43); Dhimolea et al., [2022](https://arxiv.org/html/2410.02406v1#bib.bib22)),
    and reduced anxiety (Gruber and Kaplan-Rakowski, [2020](https://arxiv.org/html/2410.02406v1#bib.bib27)).
    EFL learning using VR can also benefit kids with complex needs and low-achieving
    students (Lan, [2020](https://arxiv.org/html/2410.02406v1#bib.bib43)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越多的文献研究了虚拟现实（VR）在外语英语（EFL）学习中的应用，特别是VR环境如何用于不同的语言学习任务（Lin 和 Lan，[2015](https://arxiv.org/html/2410.02406v1#bib.bib49);
    Klimova，[2021](https://arxiv.org/html/2410.02406v1#bib.bib39); Dhimolea 等，[2022](https://arxiv.org/html/2410.02406v1#bib.bib22)）。研究表明，VR对词汇学习、沟通技巧和写作技能有益（Lan，[2020](https://arxiv.org/html/2410.02406v1#bib.bib43)）。使用VR进行EFL学习的其他好处包括提高学习者的动机、参与度、享受感、自动化（Makransky
    和 Lilleholt，[2018](https://arxiv.org/html/2410.02406v1#bib.bib51); Lan，[2020](https://arxiv.org/html/2410.02406v1#bib.bib43);
    Dhimolea 等，[2022](https://arxiv.org/html/2410.02406v1#bib.bib22)），以及减少焦虑感（Gruber
    和 Kaplan-Rakowski，[2020](https://arxiv.org/html/2410.02406v1#bib.bib27)）。使用VR进行EFL学习还可以帮助有复杂需求的儿童和成绩较差的学生（Lan，[2020](https://arxiv.org/html/2410.02406v1#bib.bib43)）。
- en: Researchers have generated several strategies to enhance learning in VR by contextualization
    and extending memory retention. These strategies include interacting with a 3D
    object for vocabulary understanding (Fuhrman et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib26);
    Hsu et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib30)), completing
    tasks in real-life scenarios (Wik and Hjalmarsson, [2009](https://arxiv.org/html/2410.02406v1#bib.bib75)),
    problem-based learning (Chen et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib14)),
    and integrating learning into narrative or through gamification (Cheng et al.,
    [2017](https://arxiv.org/html/2410.02406v1#bib.bib15); Hsu et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib30);
    Seow, [2023](https://arxiv.org/html/2410.02406v1#bib.bib65)). In addition, the
    use of avatars in VR has been shown to support human-to-human collaboration, and
    enhance a sense of community during the learning experience (Jackson and Fagan,
    [2000](https://arxiv.org/html/2410.02406v1#bib.bib32); Peterson, [2012](https://arxiv.org/html/2410.02406v1#bib.bib58);
    Cantone et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib11)). The use
    of avatars may in particular support often overlooked nuances of learning languages
    such as the role of gestures that accompany spoken language. For example, (Cheng
    et al., [2017](https://arxiv.org/html/2410.02406v1#bib.bib15)) showed how language
    usage and body movement are integrated to teach learners intercultural nuances,
    such as the practice of greeting in Japanese while simultaneously bowing, demonstrating
    how verbal and non-verbal cues work together in communication.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员已经提出了几种通过情境化和延长记忆保持来增强虚拟现实（VR）学习的策略。这些策略包括与三维物体互动以理解词汇（Fuhrman 等，[2021](https://arxiv.org/html/2410.02406v1#bib.bib26);
    Hsu 等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib30)），在现实场景中完成任务（Wik 和
    Hjalmarsson，[2009](https://arxiv.org/html/2410.02406v1#bib.bib75)），基于问题的学习（Chen
    等，[2021](https://arxiv.org/html/2410.02406v1#bib.bib14)），以及将学习融入叙事或通过游戏化来进行（Cheng
    等，[2017](https://arxiv.org/html/2410.02406v1#bib.bib15); Hsu 等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib30);
    Seow，[2023](https://arxiv.org/html/2410.02406v1#bib.bib65)）。此外，研究表明，VR中使用虚拟角色有助于支持人际合作，并增强学习体验中的社区感（Jackson
    和 Fagan，[2000](https://arxiv.org/html/2410.02406v1#bib.bib32); Peterson，[2012](https://arxiv.org/html/2410.02406v1#bib.bib58);
    Cantone 等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib11)）。虚拟角色的使用尤其能够支持学习语言时常被忽视的细微差别，例如伴随口语的手势作用。例如，（Cheng
    等，[2017](https://arxiv.org/html/2410.02406v1#bib.bib15)）展示了语言使用和身体动作如何结合起来，教授学习者跨文化的细微差异，比如在日本打招呼时同时鞠躬，展示了言语和非言语信号如何在交流中共同作用。
- en: 2.2\. Embodied Conversational Agents for Language Learning
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 语言学习的具身对话代理
- en: Many VR language learning applications involve embodied conversational agents
    (ECAs) in the environment. An ECA is a digitally animated character capable of
    engaging in natural, human-like communication with users (Cassell et al., [2000](https://arxiv.org/html/2410.02406v1#bib.bib12)).
    As Cassell states, an ideal ECA is described as being able to conduct a human-to-agent
    conversation in a way that mimics human face-to-face communication so that it
    feels believable. Many other features have been discussed for the design of the
    ECAs such as the use of verbal and non-verbal cues, multimodal communication,
    appearance and visualization (Cassell et al., [2000](https://arxiv.org/html/2410.02406v1#bib.bib12)),
    and carefully crafted personality traits (van Mulken et al., [1998](https://arxiv.org/html/2410.02406v1#bib.bib70)),
    all aiming to increase agent credibility. In recent studies, ECAs are increasingly
    considered as social agents (Atkinson et al., [2005](https://arxiv.org/html/2410.02406v1#bib.bib3)),
    designed not only to interact but also to understand and adapt to the social and
    cultural contexts of the user.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 许多虚拟现实语言学习应用程序涉及到环境中的具身对话代理（ECA）。ECA是一个数字化动画角色，能够与用户进行自然、类人化的交流（Cassell et al.,
    [2000](https://arxiv.org/html/2410.02406v1#bib.bib12)）。正如Cassell所述，一个理想的ECA能够进行人类与代理之间的对话，其方式模仿人类的面对面交流，使其看起来可信。关于ECA的设计，已经讨论了许多其他特性，如使用语言和非语言提示、多模态交流、外观和可视化（Cassell
    et al., [2000](https://arxiv.org/html/2410.02406v1#bib.bib12)），以及精心设计的人格特征（van
    Mulken et al., [1998](https://arxiv.org/html/2410.02406v1#bib.bib70)），这些都旨在提高代理的可信度。近年来的研究表明，ECA越来越被视为社交代理（Atkinson
    et al., [2005](https://arxiv.org/html/2410.02406v1#bib.bib3)），不仅仅是为了互动，还能理解并适应用户的社会和文化背景。
- en: Recent studies have noted that ECAs, despite their potential, often fall under
    the broader category of chatbots, which lack a unified conceptual framework and
    typically do not include a virtual body or multimodal processing abilities (Jeon
    et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib34)). Meanwhile, much
    research has focused on the design and use of conventional chatbots (no embodiment)
    for language learning, but the exploration of ECAs remains limited. Early efforts,
    such as those by Wik and Hjalmarsson ([2009](https://arxiv.org/html/2410.02406v1#bib.bib75)),
    employed humanoid agents to perform different language learning tasks, demonstrating
    success across diverse cultural backgrounds. Divekar* et al. ([2022](https://arxiv.org/html/2410.02406v1#bib.bib24))
    also used humanoid agents to mimic real-life scenarios, specifically non-dyadic
    (multiple-people) multi-modal conversations. More recent studies have shown that
    learners can develop strong emotional bonds with ECAs, leading to increased motivation
    and positive learning outcomes (Jeon, [2022](https://arxiv.org/html/2410.02406v1#bib.bib33)).
    (Xu et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib79)) demonstrating
    also a positive correlation between learners’ strong affection for agents’ appearances
    and improved learning outcomes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究指出，尽管ECA具有潜力，但它们通常属于更广泛的聊天机器人范畴，缺乏统一的概念框架，通常不包括虚拟身体或多模态处理能力（Jeon et al.,
    [2023](https://arxiv.org/html/2410.02406v1#bib.bib34)）。与此同时，许多研究集中在传统聊天机器人（无具身性）在语言学习中的设计和应用，但对ECA的探索仍然有限。早期的研究，例如Wik和Hjalmarsson（[2009](https://arxiv.org/html/2410.02406v1#bib.bib75)）的工作，使用类人代理执行不同的语言学习任务，证明其在不同文化背景下都取得了成功。Divekar*等人（[2022](https://arxiv.org/html/2410.02406v1#bib.bib24)）也使用类人代理模拟现实生活场景，特别是非二元（多人）多模态对话。更近期的研究表明，学习者可以与ECA建立强烈的情感联系，从而增加动机并改善学习成果（Jeon,
    [2022](https://arxiv.org/html/2410.02406v1#bib.bib33)）。(Xu et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib79))的研究还表明，学习者对代理外貌的强烈喜爱与学习成果的改善之间存在正相关关系。
- en: Despite the potential of ECAs for simulating human-like behaviour, much of the
    existing research on ECAs for language learning features ECAs with minimal interactive
    abilities (Wik and Hjalmarsson, [2009](https://arxiv.org/html/2410.02406v1#bib.bib75);
    Divekar* et al., [2022](https://arxiv.org/html/2410.02406v1#bib.bib24); Jeon,
    [2022](https://arxiv.org/html/2410.02406v1#bib.bib33)). These ECAs are often restricted
    to basic functions like lip-syncing, and limited non-verbal gestures and expressive
    behaviour due to technological constraints. The recent advancements in large language
    models (LLMs) provide new technological capabilities for ECAs, opening up design
    opportunities for more dynamic, interactive ECAs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ECA在模拟类人行为方面具有潜力，但现有的关于ECA在语言学习中的研究，仍然以互动能力有限的ECA为主（Wik和Hjalmarsson，[2009](https://arxiv.org/html/2410.02406v1#bib.bib75)；Divekar*等，[2022](https://arxiv.org/html/2410.02406v1#bib.bib24)；Jeon，[2022](https://arxiv.org/html/2410.02406v1#bib.bib33)）。这些ECA通常只能执行一些基本功能，如口型同步，以及由于技术限制而导致的有限非语言性手势和表现行为。大型语言模型（LLMs）的最新进展为ECA提供了新的技术能力，为设计更具动态性和互动性的ECA开辟了新的机会。
- en: 2.3\. Potential of LLMs & LLM-agents for Language Learning in Social VR
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. LLMs和LLM代理在社交虚拟现实中进行语言学习的潜力
- en: Previous natural language processing (NLP) techniques had been applied to English
    language learning tools, which usually require templates or use pre-scripted goal-oriented
    scenes (Tyen et al., [2022](https://arxiv.org/html/2410.02406v1#bib.bib68)). Previous
    (E)CAs’ responses regarding language learning and feedback also remained limited
    (Zhang et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib84)). This limitation
    was lifted with the recent development of LLMs and their content generation ability
    that extends beyond language tasks (Yang et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib80)).
    In addition to language generation tasks, LLMs can be leveraged for generating
    ECAs’ 3D avatars (Hong et al., [2022](https://arxiv.org/html/2410.02406v1#bib.bib28)),
    controlling motion (Qing et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib61)),
    generating motion and facial expressions (Normoyle et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib53)),
    and driving ECA’s behavior (Normoyle et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib53);
    Kumaran et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib42)). Multimodal
    LLMs have the potential to understand the virtual environment and the objects
    in it (Wang et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib74)), for
    even more contextualized learning.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以往的自然语言处理（NLP）技术已应用于英语学习工具，这些工具通常需要模板或使用预设的目标导向场景（Tyen等，[2022](https://arxiv.org/html/2410.02406v1#bib.bib68)）。以往的（E）CA在语言学习和反馈方面的反应也相对有限（Zhang等，[2021](https://arxiv.org/html/2410.02406v1#bib.bib84)）。这一局限性随着大型语言模型（LLMs）及其超越语言任务的内容生成能力的最新发展而被打破（Yang等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib80)）。除了语言生成任务，LLMs还可以用于生成ECA的3D虚拟形象（Hong等，[2022](https://arxiv.org/html/2410.02406v1#bib.bib28)）、控制动作（Qing等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib61)）、生成动作和面部表情（Normoyle等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib53)），以及驱动ECA的行为（Normoyle等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib53）；Kumaran等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib42)）。多模态LLMs有潜力理解虚拟环境及其中的物体（Wang等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib74)），从而实现更具上下文感知的学习。
- en: While the number of discussions around the usage of LLMs is growing, particularly
    chatGPT for education across disciplines (Kasneci et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib37)),
    fewer studies focus on the use of LLMs for language learning. Previous studies
    have explored the use of LLM-based chatbots in academic settings for EFL for tasks
    like grammar correction and essay writing (Zhang et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib83);
    Law, [2024](https://arxiv.org/html/2410.02406v1#bib.bib45)). In a recent study,
    (Caines et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib10)) examined
    the use of LLMs in language teaching and assessment, including the assessment
    of generated content, calibration of existing teaching materials, automated assessment
    of language learners, and providing feedback. (Caines et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib10))
    review of LLMs besides GPT suggests that alternative models for content generation
    may be a better choice due to their multilingual capabilities and their general
    availability as open-source models; yet, for other tasks like providing feedback
    to language learners, the usage of GPT models is still promising.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管围绕LLM使用的讨论越来越多，特别是在跨学科教育领域使用chatGPT（Kasneci等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib37)），但针对语言学习中LLM的使用的研究较少。先前的研究探讨了基于LLM的聊天机器人在学术环境中用于英语作为外语（EFL）的一些任务，如语法修正和作文写作（Zhang等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib83)；Law，[2024](https://arxiv.org/html/2410.02406v1#bib.bib45)）。在一项最近的研究中，（Caines等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib10)）研究了LLM在语言教学和评估中的应用，包括对生成内容的评估、现有教学材料的校准、对语言学习者的自动评估以及提供反馈。（Caines等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib10)）对除了GPT之外的LLM的回顾表明，其他内容生成模型可能是更好的选择，因为它们具有多语言能力并且作为开源模型普遍可用；然而，在像提供语言学习者反馈这样的任务中，GPT模型的使用仍然很有前景。
- en: Despite the advancements of LLMs, the use of LLM-based ECAs in language learning
    applications remains relatively underexplored. Recent studies have begun to explore
    how personality expression and embodiment in LLM-based educational agents impact
    learning outcomes (Sonlu et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib67)).
    Yet, there remains a gap in understanding the complexity of factors that influence
    LLM-based agent-supported language learning in social VR. To address this gap,
    we explore the design and integration of LLM-based ECAs into social VR for contextualized
    language learning.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大规模语言模型（LLMs）取得了进展，但基于LLM的教育聊天代理（ECA）在语言学习应用中的使用仍然相对较少。近期的研究已经开始探讨个性化表达和具象化在基于LLM的教育代理中如何影响学习成果（Sonlu等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib67)）。然而，关于影响基于LLM的代理支持的语言学习在社交虚拟现实（VR）中的复杂因素的理解仍然存在空白。为了解决这一空白，我们探索了将基于LLM的ECA设计和集成到社交VR中的方法，以实现情境化的语言学习。
- en: 3\. System Design
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 系统设计
- en: Our system implements an LLM-based agent to assist learners in practicing spoken
    English within a social VR environment. The agent (ELLMA-T) engages with the users
    in role-play conversations based on real-life scenarios, providing interactive
    and adaptive language practice in VRChat. In the proceeding section, we discuss
    our design principles based on education theory, learning task design, and system
    implementation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统实现了一个基于LLM的代理，帮助学习者在社交虚拟现实环境中练习口语英语。该代理（ELLMA-T）通过基于真实场景的角色扮演对话与用户互动，在VRChat中提供互动和适应性的语言练习。在接下来的章节中，我们将基于教育理论、学习任务设计和系统实现讨论我们的设计原则。
- en: 3.1\. Design Principles
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 设计原则
- en: 'We based the following system design principles on prior research involving
    additional language learning regardless of the learner’s age or academic status:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基于先前的研究，设计了以下系统设计原则，这些研究涉及到无论学习者的年龄或学术状态如何，都与语言学习相关：
- en: (1)
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: Student-centered learning, with the system designed to fit each learner’s unique
    needs (Darsih, [2018](https://arxiv.org/html/2410.02406v1#bib.bib21));
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以学生为中心的学习，系统设计以适应每个学习者的独特需求（Darsih，[2018](https://arxiv.org/html/2410.02406v1#bib.bib21)）；
- en: (2)
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: The learning material follows task-oriented learning, meaning the learner needs
    to complete a learning-related task rather than engaging in non-task-based casual
    conversations (Raux and Eskenazi, [2004](https://arxiv.org/html/2410.02406v1#bib.bib62));
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习材料遵循任务导向学习，意味着学习者需要完成一个与学习相关的任务，而不是进行非任务型的随意对话（Raux和Eskenazi，[2004](https://arxiv.org/html/2410.02406v1#bib.bib62)）；
- en: (3)
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: The system focuses on providing emotional support to encourage learning, a major
    factor in sustaining continuous learning for language learners (Dinçer et al.,
    [2013](https://arxiv.org/html/2410.02406v1#bib.bib23)).
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该系统专注于提供情感支持以鼓励学习，这是语言学习者持续学习的重要因素（Dinçer等，[2013](https://arxiv.org/html/2410.02406v1#bib.bib23)）。
- en: 'We build on the needs for supporting adult English language learning put forth
    by Adjagbodjou and Kaufman ([2024](https://arxiv.org/html/2410.02406v1#bib.bib2)):
    (a) daily conversational needs that are contextualized, (b) tools that address
    both linguistic and emotional needs, and (c) long-term, contextually situated
    learning experiences. Though this system is designed with adult learners’ needs
    in mind, our goal is to scale the system for different user groups of various
    ages. First, we emphasize creating an immersive environment with an embodied agent
    in VR to simulate real-life conversation experiences, addressing need (a). Second,
    we explore different communication strategies and channels that address learners’
    emotional needs using LLMs’ language abilities, addressing need (b). Third, we
    use VRChat as a free and easily accessible open social platform, which provides
    a rich space for users to connect, form communities, and potentially pursue collaborative
    learning opportunities, addressing need (c).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Adjagbodjou和Kaufman（[2024](https://arxiv.org/html/2410.02406v1#bib.bib2)）提出的成人英语学习需求的基础上进行了扩展：（a）情境化的日常对话需求，（b）满足语言和情感需求的工具，以及（c）长期的、情境化的学习体验。尽管这个系统是针对成人学习者的需求设计的，但我们的目标是将该系统扩展到不同年龄段的用户群体。首先，我们强调创建一个沉浸式环境，并在VR中使用具象化的代理模拟真实的对话体验，以满足需求（a）。其次，我们探索利用LLM的语言能力，通过不同的沟通策略和渠道来满足学习者的情感需求，以满足需求（b）。第三，我们使用VRChat作为一个免费且易于访问的开放社交平台，为用户提供了一个丰富的空间，用户可以在其中连接、建立社区，并可能追求合作学习的机会，以满足需求（c）。
- en: 3.2\. Learning English with ELLMA-T in VRChat
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2. 在VRChat中使用ELLMA-T学习英语
- en: '![Refer to caption](img/5d393905907c95d0fd52063355c3dfd1.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5d393905907c95d0fd52063355c3dfd1.png)'
- en: Figure 2\. Workflow of conversation tasks performed by ELLMA-T, including greeting
    the user, conducting language assessments, engaging in role-play scenarios, and
    providing feedback.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2. ELLMA-T执行的对话任务工作流程，包括问候用户、进行语言评估、参与角色扮演场景并提供反馈。
- en: \Description
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: This flowchart illustrates the workflow and tasks executed by the LLM-based
    system for language learning.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这张流程图展示了基于LLM的语言学习系统执行的工作流程和任务。
- en: 'The flowchart begins with the ”Introduction” step. Then, the second step, ”Language
    Level Assessment”. Then the system moves to the ”Role-Play” stage. Here, the flow
    branches into two paths: user-specified scenarios or generated scenarios. Both
    branches lead to the ”Take Turns Conversations” step. Following the conversation,
    the system provides ”Feedback” to the user.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 流程图从“介绍”步骤开始。然后是第二个步骤，“语言水平评估”。接下来，系统进入“角色扮演”阶段。此时，流程分为两条路径：用户指定的场景或生成的场景。两条路径都通向“轮流对话”步骤。在对话之后，系统会向用户提供“反馈”。
- en: 'The agent and user interaction is shown through a double-headed arrow indicating
    continuous engagement between the agent and user throughout the process. Role-Play:
    This step involves real-life conversation practice, in-context vocabulary explanation,
    and pronunciation and grammar correction. Scaffolding: This involves intent clarification,
    verbal encouragement, and example provision to support the user during the conversation.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 代理和用户的互动通过双向箭头表示，表示在整个过程中代理与用户之间的持续互动。角色扮演：此步骤涉及现实生活中的对话练习、情境词汇解释以及发音和语法纠正。支架：此步骤涉及意图澄清、语言鼓励和提供示例，以支持用户在对话中的表现。
- en: 'Color Coding: Steps highlighted in yellow indicate that they are generated
    by the LLM on the fly. The right side of the flowchart is color-coded to differentiate
    between the Role-Play and Scaffolding tasks, each with its sub-tasks.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色编码：用黄色高亮显示的步骤表示这些步骤是由LLM实时生成的。流程图的右侧使用颜色编码区分“角色扮演”和“支架”任务，每个任务下都有子任务。
- en: 'The workflow (see Fig. [2](https://arxiv.org/html/2410.02406v1#S3.F2 "Figure
    2 ‣ 3.2\. Learning English with ELLMA-T in VRChat ‣ 3\. System Design ‣ ELLMA-T:
    an Embodied LLM-agent for Supporting English Language Learning in Social VR"))
    starts with ELLMA-T asking for the learner’s information and assessing their language
    level. ELLMA-T then generates a conversation scenario specified by the learner
    or offers three scenarios for the learner to choose from. During role-play conversation
    practices, ELLMA-T acts as the language practice partner, playing the character
    in the scene and providing scaffolding when needed. After the role-play, ELLMA-T
    provides feedback to the learner based on the conversation in the role-play. The
    learner can end the conversation or switch to another role-play at any point in
    the conversation. Informed by our three design principles, we designed ELLMA-T’s
    language level assessment, conversation learning materials, and communication
    strategy, which were generated by the LLM on the fly using prompt engineering
    (see Section [3.3](https://arxiv.org/html/2410.02406v1#S3.SS3 "3.3\. System Implementation
    ‣ 3\. System Design ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language
    Learning in Social VR")).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程（见图[2](https://arxiv.org/html/2410.02406v1#S3.F2 "图 2 ‣ 3.2\. 在 VRChat 中使用
    ELLMA-T 学习英语 ‣ 3\. 系统设计 ‣ ELLMA-T：一个支持社交 VR 中英语学习的具身大语言模型代理")）从 ELLMA-T 询问学习者的信息并评估其语言水平开始。然后，ELLMA-T
    生成学习者指定的对话场景，或提供三个场景供学习者选择。在角色扮演对话练习中，ELLMA-T 充当语言练习伙伴，扮演场景中的角色，并在需要时提供支持。在角色扮演结束后，ELLMA-T
    根据对话内容给学习者提供反馈。学习者可以在对话的任何时刻结束对话或切换到另一个角色扮演。根据我们的三个设计原则，我们设计了 ELLMA-T 的语言水平评估、对话学习材料和沟通策略，这些内容通过提示工程由大语言模型实时生成（见第[3.3](https://arxiv.org/html/2410.02406v1#S3.SS3
    "3.3\. 系统实现 ‣ 3\. 系统设计 ‣ ELLMA-T：一个支持社交 VR 中英语学习的具身大语言模型代理")）节）。
- en: '3.2.1\. Design Principle #1: Introduction and Language Level Assessment'
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '3.2.1\. 设计原则 #1：介绍与语言水平评估'
- en: 'Introduction: ELLMA-T initiates the conversation by introducing itself as a
    friendly and culturally aware language partner. It gathers information from the
    user through open-ended questions about their name, cultural background, motivation
    to learn English, and any additional details they wish to share to form a sense
    of personal connection. For example, ELLMA-T greets the learner in their native
    language and acknowledges their culture and personal experiences. During the first
    few rounds of conversations, the learner gets familiar with the agent and the
    VR environment.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍：ELLMA-T 通过自我介绍为友好且具有文化意识的语言伙伴来启动对话。它通过开放式问题收集学习者的姓名、文化背景、学习英语的动机以及他们希望分享的任何额外信息，从而建立个人联系。例如，ELLMA-T
    会用学习者的母语问候并认可他们的文化和个人经历。在最初的几轮对话中，学习者熟悉代理和 VR 环境。
- en: 'Language Level Assessment Task: Next, ELLMA-T gives the learner a topic to
    speak about to assess the learner’s current level of English proficiency. The
    topic and the format of the free speech assessment follow the format of an IELTS
    (IELTS, [2024](https://arxiv.org/html/2410.02406v1#bib.bib31)) speaking test.
    Whereas IELTS is a more formal conversation, in our system the assessment is a
    casual conversation. In the following learning session, ELLMA-T adjusts its language
    and topic difficulty according to the learner’s proficiency. The length of the
    free speech varies from 30 seconds to as long as the learner continues speaking
    on the topic. The agent makes the judgment if it has long enough input to assess
    the learner’s spoken language. If the user’s input is not long enough, the agent
    asks follow-up questions and encourages the learner to speak more. Once ELLMA-T
    decides it has enough input from the learner, it assesses the learner’s spoken
    language proficiency and gives a result from A1 to C2 based on CEFR criteria (COE,
    [2024](https://arxiv.org/html/2410.02406v1#bib.bib19)).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 语言水平评估任务：接下来，ELLMA-T 给学习者一个话题进行口语表达，以评估其当前的英语水平。话题和自由口语评估的格式遵循雅思（IELTS，[2024](https://arxiv.org/html/2410.02406v1#bib.bib31)）口语测试的格式。虽然雅思是更正式的对话形式，但在我们的系统中，评估是一种随意的对话。在接下来的学习过程中，ELLMA-T
    会根据学习者的语言能力调整其语言和话题难度。自由口语的时长从30秒到学习者持续讲述该话题的时间不等。代理会判断是否有足够的输入来评估学习者的口语。如果用户的输入不够长，代理会提出后续问题并鼓励学习者继续说更多内容。一旦
    ELLMA-T 判断已获得足够的学习者输入，它会根据 CEFR 标准（COE，[2024](https://arxiv.org/html/2410.02406v1#bib.bib19)）评估学习者的口语能力，并给出从
    A1 到 C2 的结果。
- en: '3.2.2\. Design Principle #2: Role-Play Topic Generation and Conversation Continuation'
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '3.2.2\. 设计原则 #2：角色扮演主题生成与对话延续'
- en: 'Presenting Scenarios: Upon knowing the user’s proficiency level, ELLMA-T presents
    three different role-play scenarios focusing on various themes relevant to daily
    life. The user can choose the scenario that most interests them or suggest a specific
    scenario they’d like to practice. Once a scenario is chosen, ELLMA-T provides
    a detailed description of the scene, outlining the physical surroundings and significant
    objects. In VRChat, various virtual worlds replicate everyday settings like cafes,
    restaurants, outdoors, and supermarkets (see Fig. [3](https://arxiv.org/html/2410.02406v1#S3.F3
    "Figure 3 ‣ 3.2.2\. Design Principle #2: Role-Play Topic Generation and Conversation
    Continuation ‣ 3.2\. Learning English with ELLMA-T in VRChat ‣ 3\. System Design
    ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning in Social
    VR")). Once a scenario is selected, the user and ELLMA-T can be transported into
    a corresponding virtual environment. ELLMA-T prompts the user to complete tasks
    within the scene. For example, in a supermarket setting, the user is asked to
    find or describe specific items and practice the vocabulary learned.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '场景呈现：在了解用户的熟练度后，ELLMA-T会提供三个不同的角色扮演场景，专注于与日常生活相关的各种主题。用户可以选择最感兴趣的场景，或建议一个他们希望练习的特定场景。一旦选择了场景，ELLMA-T会提供场景的详细描述，概述物理环境和重要物品。在VRChat中，各种虚拟世界再现了如咖啡馆、餐馆、户外和超市等日常场景（参见图[3](https://arxiv.org/html/2410.02406v1#S3.F3
    "图3 ‣ 3.2.2\. 设计原则 #2：角色扮演主题生成与对话延续 ‣ 3.2\. 在VRChat中与ELLMA-T学习英语 ‣ 3\. 系统设计 ‣
    ELLMA-T：一个支持社交VR中英语学习的具身LLM代理")）。一旦选择了场景，用户和ELLMA-T就可以被传送到相应的虚拟环境中。ELLMA-T会提示用户在场景中完成任务。例如，在超市场景中，用户需要寻找或描述特定物品，并练习所学的词汇。'
- en: '![Refer to caption](img/972f3748471939e4f9fb555405cf8fe8.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/972f3748471939e4f9fb555405cf8fe8.png)'
- en: 'Figure 3\. ELLMA-T in different virtual worlds within VRChat: an indoor café
    (left) and an outdoor city (right).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. ELLMA-T在VRChat中不同虚拟世界的展示：室内咖啡馆（左）与户外城市（右）。
- en: \Description
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: \说明
- en: This image consists of two side-by-side panels, both featuring ELLMA-T, the
    3D cartoon avatar, in different immersive environments within VR. The avatar is
    the same as Figure 1.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 该图由两个并排的面板组成，均展示了ELLMA-T这一3D卡通化身，身处VR中的不同沉浸式环境中。该虚拟化身与图1中的相同。
- en: 'Left Panel: The left panel shows ELLMA-T standing inside a cozy café environment.
    The café is designed with a rustic, brick interior, with a menu board displayed
    on the wall behind the counter listing various hot and cold drinks. To the left
    of ELLMA-T is a shelf stocked with baked goods and a wall clock hangs above it.
    The café ambiance is warm, with lighting that highlights the textures of the brick
    walls and wooden shelves. ELLMA-T is standing in front of the counter, facing
    the camera, and ready to assist the user in a conversational role-play scenario
    related to a café setting.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧面板：左侧面板展示了ELLMA-T站在一个温馨的咖啡馆环境中。咖啡馆的设计采用了质朴的砖石内部装饰，柜台后面的墙上挂着一块菜单板，列出了各种冷热饮品。ELLMA-T的左侧是一个货架，货架上摆满了烘焙食品，货架上方挂着一只墙钟。咖啡馆的氛围温暖，灯光突显了砖墙和木架的纹理。ELLMA-T站在柜台前，面朝镜头，准备在与咖啡馆相关的角色扮演场景中协助用户。
- en: 'Right Panel: The right panel shows ELLMA-T in an outdoor environment resembling
    a European-style waterfront street. The scene features a stone bridge arching
    over a canal, with historic buildings lining the street and water visible in the
    background. The sky is clear and it is a sunny day. ELLMA-T stands on the cobblestone
    pathway near the bridge, facing the camera. This environment is for role-play
    scenarios where the user interacts with ELLMA-T in a street or outdoor setting,
    allowing for a variety of conversational topics related to urban exploration or
    travel.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧面板：右侧面板展示了ELLMA-T处于一个户外环境中，环境类似于欧洲风格的水滨街道。场景中有一座石桥横跨运河，街道两旁是历史建筑，背景中可见水面。天空晴朗，阳光明媚。ELLMA-T站在靠近桥梁的鹅卵石小路上，面对镜头。这个环境适用于角色扮演场景，用户可以在街道或户外环境中与ELLMA-T互动，从而展开与城市探索或旅行相关的各种对话主题。
- en: 'Take Turns Conversations: ELLMA-T and the learner engage in turn-taking conversations
    to complete the role-play scenario. Acting as the user’s partner, the agent fosters
    natural and authentic dialogue within the chosen scenario. The conversation topic
    and task design follow the example of lesson plans of British Council English
    Teaching Lessons for adult learners (Council, [2024](https://arxiv.org/html/2410.02406v1#bib.bib20)).
    In each scenario, ELLMA-T assumes a role such as a restaurant server, cashier,
    doctor, or friendly New Yorker on the street, allowing the user to conduct conversations
    that mimic real-life situations.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 轮流对话：ELLMA-T与学习者进行轮流对话，以完成角色扮演场景。作为用户的伙伴，代理人促成在所选场景中的自然且真实的对话。对话主题和任务设计参考了英国文化委员会为成人学习者设计的英语教学课程（Council，[2024](https://arxiv.org/html/2410.02406v1#bib.bib20)）。在每个场景中，ELLMA-T扮演如餐厅服务员、收银员、医生或街头友好的纽约人等角色，使用户能够进行模拟现实生活情境的对话。
- en: 'Providing Feedback: After the role-play, the agent provides feedback to the
    user, consisting of three parts. The first part offers general feedback that evaluates
    the user’s performance concerning the difficulty level of the chosen scenario,
    highlighting one strength and one area for improvement. The second part, ”Advice
    Moving Forward”, provides practical tips on how to apply the concepts learned
    in the conversation to real-world situations. Lastly, ELLMA-T summarizes the key
    vocabulary, grammar, or sentence structures encountered during the interaction
    for the user’s future reference. ELLMA-T remains available to answer further questions
    or engage in additional practice sessions.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 提供反馈：角色扮演后，代理人向用户提供反馈，反馈包含三个部分。第一部分提供一般反馈，评估用户在所选场景难度下的表现，突出一个优点和一个待改进的领域。第二部分，“前进建议”，提供实际的建议，指导如何将对话中学到的概念应用到现实生活中的情境。最后，ELLMA-T总结了互动过程中遇到的关键词汇、语法或句型，供用户日后参考。ELLMA-T仍然可以回答进一步的问题或进行额外的练习会话。
- en: '3.2.3\. Design Principle #3: Communication Strategy and Back-channels'
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '3.2.3. 设计原则 #3：沟通策略与反馈渠道'
- en: EFL learners often encounter communication breakdowns due to insufficient vocabulary
    or incorrect grammar usage, which can negatively affect their self-confidence
    and motivation. Our system builds upon the communicative and scaffolding strategies
    by (Ayedoun et al., [2019](https://arxiv.org/html/2410.02406v1#bib.bib4)) that
    may increase learner’s willingness to speak in designing Embodied Conversational
    Agents (ECAs) for spoken English practice.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 英语作为外语（EFL）学习者常常由于词汇不足或语法使用不当而遇到沟通障碍，这会对他们的自信心和学习动力产生负面影响。我们的系统基于(Ayedoun等，[2019](https://arxiv.org/html/2410.02406v1#bib.bib4))的沟通和支架策略，通过设计具身对话代理（ECA），来增加学习者在英语口语练习中开口的意愿。
- en: 'Mitigating Communication Breakdowns: To address communication breakdowns, ELLMA-T
    provides encouragement to motivate the user to continue (”Come on, don’t give
    up!”); or suggests phrases to help the user move forward in the conversation (”Maybe
    you can say…”). When the user’s speech is unclear — whether due to incorrect vocabulary,
    grammar mistakes, or mispronunciation — ELLMA-T poses clarifying questions to
    prompt further dialogue (”You just said…, do you mean…?”). This approach fosters
    a supportive learning environment that encourages users to practice speaking without
    fear of immediate correction.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 减少沟通障碍：为了应对沟通障碍，ELLMA-T会提供鼓励，激励用户继续进行对话（“加油，别放弃！”）；或建议短语，帮助用户继续进行对话（“你可以说……”）。当用户的言语不清楚时——无论是由于词汇不当、语法错误，还是发音不准确——ELLMA-T会提出澄清问题，促使进一步对话（“你刚才说的……，是指……？”）。这种方法营造了一个支持性的学习环境，鼓励用户在不担心立即纠正的情况下进行口语练习。
- en: 3.3\. System Implementation
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3. 系统实现
- en: 3.3.1\. System Architecture
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1. 系统架构
- en: '![Refer to caption](img/58ea4c008c3f1a0705104d08ebb460a7.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/58ea4c008c3f1a0705104d08ebb460a7.png)'
- en: Figure 4\. System Architecture of the ELLMA-T. The architecture highlights the
    core components and data flow within the system.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. ELLMA-T的系统架构。该架构展示了系统内部的核心组件和数据流。
- en: \Description
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: System Architecture for LLM-Based Embodied Conversational Agent in VRchat.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: VRchat中的基于LLM的具身对话代理系统架构。
- en: 'This diagram illustrates the data flow between different system components
    enabling a conversational agent in VRchat. User Input: Spoken input from the user
    is captured via a VR headset. Whisper + Soundlibrary: Converts the audio input
    into text. LLM (Large Language Model): Processes the text and generates a response,
    guided by a Prompt. Memory Module: Includes Short-term and Long-term Memory to
    store interaction history for context. TTS (Text-to-Speech): Converts the LLM-generated
    text into speech. VRChat OSC + Unity: Manages the agent’s expressive behaviors,
    such as Facial Expressions, Body Movements, and Filler Words in VRchat. Voice
    Output: The final speech output and expressions are delivered to the user.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此图展示了在 VRChat 中启用对话代理的不同系统组件之间的数据流。用户输入：通过 VR 头显捕获用户的语音输入。Whisper + Soundlibrary：将音频输入转换为文本。LLM（大型语言模型）：处理文本并生成响应，依据提示生成。记忆模块：包括短期记忆和长期记忆，用于存储互动历史以提供上下文。TTS（文本转语音）：将
    LLM 生成的文本转换为语音。VRChat OSC + Unity：管理代理的表现性行为，如面部表情、身体动作和填充词。在 VRChat 中进行语音输出：最终的语音输出和表情传递给用户。
- en: 'The agent design in this project extended the work by (Wan et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib73))
    which implements general ECA in VRChat and improves the response context-relevance
    by adding a memory to the agent. Based on this implementation, we added a tutor
    workflow logic (see Fig. [2](https://arxiv.org/html/2410.02406v1#S3.F2 "Figure
    2 ‣ 3.2\. Learning English with ELLMA-T in VRChat ‣ 3\. System Design ‣ ELLMA-T:
    an Embodied LLM-agent for Supporting English Language Learning in Social VR"))
    that controls the conversation flow.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目中的代理设计扩展了 (Wan et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib73))
    的工作，该工作实现了 VRChat 中的通用 ECA，并通过为代理添加记忆来提高响应的上下文相关性。基于这一实现，我们增加了一个导师工作流逻辑（见图 [2](https://arxiv.org/html/2410.02406v1#S3.F2
    "图 2 ‣ 3.2\. 在 VRChat 中使用 ELLMA-T 学习英语 ‣ 3\. 系统设计 ‣ ELLMA-T：支持社交 VR 中英语学习的具身 LLM
    代理")），用于控制对话流程。
- en: 'The learner controls an avatar in VRChat through a Quest 3 headset, able to
    make body movements and talk to ELLMA-T with the microphone. As illustrated in
    Fig. [4](https://arxiv.org/html/2410.02406v1#S3.F4 "Figure 4 ‣ 3.3.1\. System
    Architecture ‣ 3.3\. System Implementation ‣ 3\. System Design ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR"), the audio input
    is converted into text by calling Whisper API (OpenAI, [2024c](https://arxiv.org/html/2410.02406v1#bib.bib56)),
    and then a text reply is generated from the GPT4 model by calling OpenAI API.
    The text response is converted back to Audio using the OpenAI TTS service (the
    ’alloy’ voice) (OpenAI, [2024b](https://arxiv.org/html/2410.02406v1#bib.bib55)).
    The user speech detection and silence detection are done by using Sounddevice
    Library (Python_Sounddevice, [2024](https://arxiv.org/html/2410.02406v1#bib.bib59))
    and Vosk (Python_Vosk, [2024](https://arxiv.org/html/2410.02406v1#bib.bib60)).
    We use a 2.0-second silence threshold to detect the end of the user’s input, balancing
    the buffer time for users to pause and continue speaking with the overall wait
    time for the agent’s response.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 学习者通过 Quest 3 头显在 VRChat 中控制虚拟角色，可以进行身体动作并通过麦克风与 ELLMA-T 对话。如图 [4](https://arxiv.org/html/2410.02406v1#S3.F4
    "图 4 ‣ 3.3.1\. 系统架构 ‣ 3.3\. 系统实现 ‣ 3\. 系统设计 ‣ ELLMA-T：支持社交 VR 中英语学习的具身 LLM 代理")
    所示，音频输入通过调用 Whisper API (OpenAI, [2024c](https://arxiv.org/html/2410.02406v1#bib.bib56))
    转换为文本，然后通过调用 OpenAI API 从 GPT4 模型生成文本回复。文本回复使用 OpenAI TTS 服务（'alloy' 语音）(OpenAI,
    [2024b](https://arxiv.org/html/2410.02406v1#bib.bib55)) 转换回音频。用户语音检测和静音检测通过使用
    Sounddevice 库 (Python_Sounddevice, [2024](https://arxiv.org/html/2410.02406v1#bib.bib59))
    和 Vosk (Python_Vosk, [2024](https://arxiv.org/html/2410.02406v1#bib.bib60)) 完成。我们使用
    2.0 秒的静音阈值来检测用户输入的结束，平衡用户暂停和继续讲话的缓冲时间与代理响应的整体等待时间。
- en: The system can also generate facial expressions and body gestures based on the
    user’s input. The LLM detects the user’s emotion by keyword detection and then
    mirrors that emotion by mapping corresponding body movements and facial expressions.
    The history of the current conversation session is stored in a list of JASON objects
    for the agent as the short-term memory and reference to generate more relevant
    conversations. The key information of the current conversation session is summarized
    by LLM and stored in a remote database. The back end of the agent is integrated
    into VRChat through VRChat OSC (VRChat, [2024a](https://arxiv.org/html/2410.02406v1#bib.bib71)).
    Additional animation for agent gestures and facial expressions can be added to
    Unity (Unity, [2024](https://arxiv.org/html/2410.02406v1#bib.bib69)) and then
    incorporated into VRChat through VRChat OSC (VRChat, [2024a](https://arxiv.org/html/2410.02406v1#bib.bib71)).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统还可以根据用户输入生成面部表情和身体动作。LLM通过关键词检测识别用户情绪，然后通过映射相应的身体动作和面部表情来反映这种情绪。当前对话会话的历史记录以JASON对象列表的形式存储为代理的短期记忆，并作为生成更相关对话的参考。当前对话会话的关键信息由LLM进行总结，并存储在远程数据库中。代理的后端通过VRChat
    OSC（VRChat, [2024a](https://arxiv.org/html/2410.02406v1#bib.bib71)）集成到VRChat中。代理的手势和面部表情的额外动画可以添加到Unity（Unity,
    [2024](https://arxiv.org/html/2410.02406v1#bib.bib69)），然后通过VRChat OSC（VRChat,
    [2024a](https://arxiv.org/html/2410.02406v1#bib.bib71)）集成到VRChat中。
- en: 3.3.2\. Multi-task Multi-turn Conversation System
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2\. 多任务多轮对话系统
- en: 'In designing and implementing a multi-task, multi-turn conversational agent,
    we encountered a challenge that necessitated a shift from a single-prompt approach
    to a more structured, multi-task approach. Our agent was tasked with managing
    an entire conversation involving multiple steps and decision points, for example,
    when to move from the introduction to the assessment task, how long the assessment
    should be, how to move on to the next topic, etc., within an interaction session.
    Initially, we experimented with a single-prompt approach, wherein the system prompt,
    we listed out all the steps and the criteria the agent should follow as system
    prompt in Appendix [A.1](https://arxiv.org/html/2410.02406v1#A1.SS1 "A.1\. Single
    System Prompt ‣ Appendix A Appendix ‣ ELLMA-T: an Embodied LLM-agent for Supporting
    English Language Learning in Social VR"). However, we observed that the LLM struggled
    to follow the steps in the single prompt. The LLM often confused the sequence
    of actions, misinterpreted when one task should conclude, and when to transition
    to the next, or randomly restarted a certain task. This led to a breakdown in
    the logical flow of conversations, thus not ideal for users to interact with.
    This observation aligns with emerging findings in the field of LLM-based agents,
    where maintaining context and managing multi-turn interactions remain challenging,
    particularly in complex, multi-step tasks (Yi et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib81)).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计和实现一个多任务多轮对话代理时，我们遇到了一个挑战，迫使我们从单一提示方法转向更结构化的多任务方法。我们的代理需要管理涉及多个步骤和决策点的整个对话，例如，在介绍任务和评估任务之间何时过渡，评估应持续多长时间，如何转向下一个话题等。在最初的实验中，我们尝试了单一提示方法，在该方法中，我们在系统提示中列出了所有步骤和代理应该遵循的标准，见附录[A.1](https://arxiv.org/html/2410.02406v1#A1.SS1
    "A.1\. 单一系统提示 ‣ 附录 A 附录 ‣ ELLMA-T：支持社交 VR 中英语学习的具身 LLM 代理")。然而，我们观察到LLM很难按照单一提示中的步骤进行操作。LLM经常混淆操作的顺序，误解任务何时结束，何时转向下一个任务，或者随机重新启动某个任务。这导致了对话的逻辑流程中断，用户互动的效果不理想。这一观察结果与LLM代理领域的新兴发现相一致，其中保持上下文并管理多轮互动仍然是一个挑战，尤其是在复杂的多步骤任务中（Yi
    等， [2024](https://arxiv.org/html/2410.02406v1#bib.bib81)）。
- en: '![Refer to caption](img/1a70e79dc3a6a7061fd6e125603e0f69.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1a70e79dc3a6a7061fd6e125603e0f69.png)'
- en: Figure 5\. Structure of Separate Prompts for Different Tasks. This diagram illustrates
    how prompts are structured and separated for various tasks within the system.
    1) The system prompt establishes the agent’s persona across all interactions.
    2) Task-specific prompts guide the agent during the introduction, language assessment,
    role-play, and feedback. 3) A decision prompt helps the agent determine when to
    transition between tasks. 4) The prompt for providing scaffolding during role-play
    conversations.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 不同任务的独立提示结构。该图展示了提示如何在系统内部分任务之间进行结构化和分隔。1）系统提示确定了代理在所有互动中的角色。2）任务特定提示在引导、语言评估、角色扮演和反馈过程中引导代理。3）决策提示帮助代理确定何时在任务之间进行过渡。4）角色扮演对话过程中提供脚手架的提示。
- en: \Description
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: \Description
- en: 'This diagram illustrates the structure and flow of prompts used by the LLM-based
    agent to manage various conversational tasks:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了LLM基础代理用于管理各种对话任务的提示结构和流程：
- en: 'System Prompt: Sets the agent’s overall persona as a friendly, patient, and
    light-hearted English tutor. Task-Specific Prompts: Separate prompts are used
    for different tasks: Introduction: The agent engages the user to learn about their
    background. Assessment: The agent conducts a free chat to assess the user’s language
    level. Role Play: The agent guides the user through a role-playing scenario. During
    each task, there is a Saturation Logic that determines if the current task is
    complete and when to transition to the next task. During the Role Play task, there
    is a prompt for Scaffolding that guides the LLM to offer explanations, examples,
    and encouragement as needed.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示：设置代理的整体角色为友好、耐心和轻松的英语辅导员。任务特定提示：针对不同任务使用不同的提示：引导：代理与用户互动，了解其背景。评估：代理进行自由对话，以评估用户的语言水平。角色扮演：代理引导用户进行角色扮演场景。在每个任务中，都有一个饱和逻辑，用于判断当前任务是否完成，以及何时过渡到下一个任务。在角色扮演任务中，还有一个脚手架提示，用于引导LLM在需要时提供解释、示例和鼓励。
- en: 'As an alternative, we adopted a multi-task implementation strategy (see Fig.
    [5](https://arxiv.org/html/2410.02406v1#S3.F5 "Figure 5 ‣ 3.3.2\. Multi-task Multi-turn
    Conversation System ‣ 3.3\. System Implementation ‣ 3\. System Design ‣ ELLMA-T:
    an Embodied LLM-agent for Supporting English Language Learning in Social VR").
    The core idea behind this approach is to decompose the overall task into smaller,
    simpler, and more manageable subtasks. Each subtask is then handled by a separately
    prompted instance of the agent (see Appendix [A.2](https://arxiv.org/html/2410.02406v1#A1.SS2
    "A.2\. Multi-task Prompt ‣ Appendix A Appendix ‣ ELLMA-T: an Embodied LLM-agent
    for Supporting English Language Learning in Social VR")), allowing for greater
    control and reducing the cognitive load on the LLM at any given point. This strategy
    shifts the burden of maintaining deterministic logic from the LLM to the system
    designer, who predefines the sequence and structure of subtasks. By doing so,
    we ensure that the agent can navigate through complex interactions without losing
    track of the conversation’s broader context. Each subtask is executed independently,
    with the LLM generating responses based on the specific context of that subtask.
    Although this introduces some variability in the conversation due to the inherent
    randomness of LLM-generated text, the overall structure remains intact, leading
    to more coherent and effective interactions. This approach is supported by recent
    developments in the multi-agent system for complex task dialogue systems, which
    suggests that breaking down complex tasks into modular components can significantly
    improve system performance (Wu et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib78)).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '作为替代方案，我们采用了多任务实现策略（见图[5](https://arxiv.org/html/2410.02406v1#S3.F5 "Figure
    5 ‣ 3.3.2\. Multi-task Multi-turn Conversation System ‣ 3.3\. System Implementation
    ‣ 3\. System Design ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language
    Learning in Social VR")）。这一方法的核心思想是将整体任务分解为更小、更简单、更易于管理的子任务。每个子任务由一个单独提示的代理实例处理（见附录[A.2](https://arxiv.org/html/2410.02406v1#A1.SS2
    "A.2\. Multi-task Prompt ‣ Appendix A Appendix ‣ ELLMA-T: an Embodied LLM-agent
    for Supporting English Language Learning in Social VR")），从而实现更大的控制力，并减少在任何给定时刻LLM的认知负担。这一策略将保持确定性逻辑的负担从LLM转移到系统设计者身上，后者预定义了子任务的顺序和结构。通过这样做，我们确保代理能够在复杂互动中顺利进行，而不会失去对对话广泛背景的掌控。每个子任务都是独立执行的，LLM根据该子任务的特定上下文生成响应。尽管由于LLM生成文本的固有随机性，这可能会在对话中引入一些变动，但整体结构保持不变，从而导致更连贯和更有效的互动。最近在复杂任务对话系统的多代理系统领域的研究表明，将复杂任务分解为模块化组件可以显著提升系统性能（Wu
    et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib78)）。'
- en: 3.3.3\. Prompt Engineering
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3\. 提示工程
- en: Effective prompt engineering is crucial for guiding LLMs like GPT-4 in performing
    specific tasks within a conversational system. While there are many ways to prompt
    LLMs (Schulhoff et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib64)),
    there is currently no standardized workflow for developing the ”perfect” prompt,
    as prompt design often involves a trial-and-error process (Zamfirescu-Pereira
    et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib82)). Our approach to
    prompt engineering was iterative and explored LLM’s capabilities under zero-shot
    or few-shot conditions (Brown et al., [2020](https://arxiv.org/html/2410.02406v1#bib.bib9))
    to facilitate language learning.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的提示工程对于引导像GPT-4这样的LLM在对话系统中执行特定任务至关重要。尽管有多种方法可以提示LLM（Schulhoff et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib64)），但目前尚无标准化的工作流程来开发“完美”的提示，因为提示设计通常涉及试错过程（Zamfirescu-Pereira
    et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib82)）。我们对提示工程的 approach
    是迭代式的，探索了LLM在零-shot或少量-shot条件下的能力（Brown et al., [2020](https://arxiv.org/html/2410.02406v1#bib.bib9)），以促进语言学习。
- en: 4\. User Study
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 用户研究
- en: 4.1\. Study Design
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 研究设计
- en: To explore participants’ experiences with ELLMA-T within the VRChat environment,
    we conducted a qualitative study using semi-structured interviews, and thematic
    analysis to analyze the data. The study aimed to explore the opportunities and
    challenges in LLM-based agent-supported language learning in a social VR setting.
    Our study focuses on overall interaction experience, preferences for system usage,
    and feedback for future improvements. This study was approved by the university’s
    ethics board.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索参与者在VRChat环境中使用ELLMA-T的体验，我们通过半结构化访谈进行了一项定性研究，并通过主题分析对数据进行了分析。本研究旨在探索基于LLM的代理支持语言学习在社交VR环境中的机会与挑战。我们的研究聚焦于整体互动体验、系统使用偏好以及对未来改进的反馈。本研究已获得大学伦理委员会的批准。
- en: 4.2\. Participants and Setting
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 参与者与设置
- en: 'For this preliminary study, we recruited 12 international graduate students
    (Table [1](https://arxiv.org/html/2410.02406v1#S4.T1 "Table 1 ‣ 4.2\. Participants
    and Setting ‣ 4\. User Study ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR")) from [University Name removed for blind review]
    by posting recruitment ads via campus communication channels. Despite meeting
    the university’s rigorous English language standards, with a minimum IELTS score
    of 7.5, these students continue to encounter linguistic hurdles in their day-to-day
    lives and work environments. To that end, our participants were selected as a
    potentially representative sample of a population with mixed English proficiencies
    who aim to enhance oral proficiency in practical scenarios, such as social interactions
    and workplace communication.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '为了进行这项初步研究，我们通过校园传播渠道发布招募广告，招募了12名国际研究生（表[1](https://arxiv.org/html/2410.02406v1#S4.T1
    "Table 1 ‣ 4.2\. Participants and Setting ‣ 4\. User Study ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR")）参与此研究，来自[大学名称已删除以确保盲审]。尽管这些学生达到了该大学严格的英语语言标准，雅思成绩最低为7.5分，但他们在日常生活和工作环境中仍然面临语言障碍。因此，我们选择了这些参与者作为一个潜在的代表性样本，代表一个英语能力混合的人群，他们的目标是在实际场景中提高口语能力，如社交互动和职场沟通。'
- en: Table 1\. Participant Information
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 参与者信息
- en: '| Participant ID | Gender | Cultural Background | Language Proficiency | Motivation
    to Learn English |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 参与者ID | 性别 | 文化背景 | 语言能力 | 学习英语的动机 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| P1 | Male | China | Fluent | To improve language skills |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| P1 | 男性 | 中国 | 流利 | 提升语言技能 |'
- en: '| P2 | Male | India | Fluent | For work in Canada |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| P2 | 男性 | 印度 | 流利 | 为了在加拿大工作 |'
- en: '| P3 | Male | China | Fluent | To enhance communication skills |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| P3 | 男性 | 中国 | 流利 | 提升沟通技巧 |'
- en: '| P4 | Female | China | Basic | To improve spoken English |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| P4 | 女性 | 中国 | 基础 | 提升口语英语能力 |'
- en: '| P5 | Female | China | Intermediate | For work and study in Canada |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| P5 | 女性 | 中国 | 中级 | 为了在加拿大工作和学习 |'
- en: '| P6 | Female | China | Intermediate | To enhance proficiency |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| P6 | 女性 | 中国 | 中级 | 提升语言能力 |'
- en: '| P7 | Female | China | Intermediate | To improve business English skills |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| P7 | 女性 | 中国 | 中级 | 提升商务英语技能 |'
- en: '| P8 | Male | Bangladesh | Very Fluent | To achieve advanced proficiency |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| P8 | 男性 | 孟加拉国 | 非常流利 | 达到高级语言能力 |'
- en: '| P9 | Female | Taiwan | Basic | For work and study in Canada |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| P9 | 女性 | 台湾 | 基础 | 为了在加拿大工作和学习 |'
- en: '| P10 | Female | China | Basic | For job interview practice |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| P10 | 女性 | 中国 | 基础 | 为了面试练习 |'
- en: '| P11 | Male | China | Intermediate | To improve business English skills |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| P11 | 男性 | 中国 | 中级 | 提升商务英语技能 |'
- en: '| P12 | Male | China | Fluent | For work in Canada |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| P12 | 男性 | 中国 | 流利 | 为了在加拿大工作 |'
- en: 4.3\. Procedure
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 程序
- en: 'The study was conducted in person at the [University removed for blind review].
    Upon arrival, participants received a brief overview of the study. They were informed
    that they would interact with an AI agent acting as an English language tutor
    using a Meta Quest 3 headset. For participants unfamiliar with VR, we provided
    instructions on how to wear the headset and navigate the VRChat world. The setup
    was pre-configured to ensure a seamless experience, allowing participants to bypass
    navigating menus or learning controls. Once equipped with the headset, participants
    were instructed to start recording their interaction with the ELLMA-T from their
    POV. The agent was overseen remotely by a researcher who also provided technical
    support. The interaction lasted 1̃5 minutes: introduction and assessment (5mins),
    role-play and feedback (7mins). We saved the conversation logs between each participant
    and ELLMA-T as CSV files for further analysis. Following the interaction, participants
    took part in a 30-minute semi-structured interview conducted by one of the authors
    experienced in qualitative methods. Interviews were audio-recorded with an iPhone
    12 and transcribed in NVivo 14 for analysis. The interviews gathered qualitative
    data on participants’ overall experience, comfort level, engagement, frequency
    of potential use, and preferences for using the system in different settings (e.g.,
    group vs. individual; headset vs. desktop app). Follow-up questions were asked
    as necessary to probe deeper into participants’ responses, particularly when initial
    answers did not fully address the intended topics or directions. The complete
    list of interview questions can be found in Appendix [B](https://arxiv.org/html/2410.02406v1#A2
    "Appendix B Interview Questions ‣ ELLMA-T: an Embodied LLM-agent for Supporting
    English Language Learning in Social VR").'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 该研究在[大学名称已删除以保证盲审]现场进行。参与者到达后，首先接受了对研究的简要概述。告知他们将与一名扮演英语语言导师角色的AI代理进行互动，使用Meta
    Quest 3头显。对于不熟悉虚拟现实的参与者，我们提供了如何佩戴头显并在VRChat世界中导航的说明。系统设置已预先配置好，确保了顺畅的体验，让参与者无需学习如何导航菜单或操作控制。一旦佩戴好头显，参与者被指示从他们的第一人称视角开始录制与ELLMA-T的互动。研究人员远程监控代理的操作，并提供技术支持。互动持续了15分钟：介绍与评估（5分钟），角色扮演与反馈（7分钟）。我们将每位参与者与ELLMA-T之间的对话日志保存为CSV文件以便进一步分析。互动后，参与者参与了一次由一位熟悉定性研究方法的作者主持的30分钟半结构化访谈。访谈通过iPhone
    12录音，并在NVivo 14中转录以供分析。访谈收集了关于参与者总体体验、舒适度、参与度、潜在使用频率和在不同设置下使用系统的偏好（例如，小组与个人；头显与桌面应用）的定性数据。如有必要，访谈中还会根据参与者的回答提问追问，特别是当初步回答未能完全回应预期主题或方向时。完整的访谈问题列表见附录[B](https://arxiv.org/html/2410.02406v1#A2
    "附录B 访谈问题 ‣ ELLMA-T：支持社交虚拟现实中英语学习的具身LLM代理")。
- en: 4.4\. Analysis
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 分析
- en: We employed an inductive (bottom-up) approach to analyze the interview transcripts,
    following the thematic analysis guidelines by Braun and Clarke (Braun and Clarke,
    [2006](https://arxiv.org/html/2410.02406v1#bib.bib7)). The analysis was conducted
    in several stages by three researchers, all authors of the paper. Initially, each
    researcher read over all the interview transcripts (step 1), and then independently
    analyzed a sub-set of the interview transcripts to identify preliminary codes,
    themes, and patterns, selecting relevant quotes and observations (step 2). The
    team then discussed and agreed upon a final set of codes through multiple rounds
    of coding (step 3). To ensure the robustness of our analysis, the interview transcripts
    were cross-referenced with video recordings and notes taken during the interactions
    (step 4). Finally, all themes were discussed and defined by three researchers/coders
    (step 5) and written up (step 6).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了归纳式（自下而上）方法来分析访谈记录，遵循Braun和Clarke（Braun和Clarke，[2006](https://arxiv.org/html/2410.02406v1#bib.bib7)）的主题分析指南。分析由三位研究人员（本文所有作者）分阶段进行。最初，每位研究人员阅读所有的访谈记录（步骤1），然后独立分析部分访谈记录，以识别初步的代码、主题和模式，并选择相关的引用和观察（步骤2）。团队随后进行了多轮编码讨论，并达成一致，最终确定了一套代码（步骤3）。为了确保分析的可靠性，访谈记录与视频录制和互动过程中的笔记进行了交叉引用（步骤4）。最后，所有的主题由三位研究人员/编码员讨论并定义（步骤5），并写成报告（步骤6）。
- en: 5\. Findings
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 研究结果
- en: 'In this section, we describe four key themes: agent perception and its role
    in social VR, language learning in social VR, task design and perceptions of LLMs
    efficient in language learning, and interest in continued usage.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了四个关键主题：代理感知及其在社交虚拟现实中的作用、社交虚拟现实中的语言学习、任务设计与对大规模语言模型在语言学习中的高效性的感知，以及对继续使用的兴趣。
- en: 5.1\. Agent Perception and its Role in Social VR
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 代理感知及其在社交虚拟现实中的作用
- en: 5.1.1\. ELLMA-T Human-like qualities
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1\. ELLMA-T 类人化特征
- en: Participants compared their experience with ELLMA-T to that of conversing with
    a real human tutor. Participants frequently commented on the agent’s human-like
    qualities, noting how the interaction felt like conversing with a real person
    rather than an AI. As P4 expressed, ”I love the way it talk(s) to me. It (is)
    just like a real teacher; the interaction is really good.” Participants highlighted
    that the conversation flowed naturally, demonstrating ELLMA-T’s ability to listen,
    understand, and respond appropriately. For example, P8 appreciated that the agent
    ”was listening to me,” suggesting that it responded in a way that related to their
    personal experience. P2 also observed,
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者将与ELLMA-T的体验与与真人导师对话进行了比较。参与者频繁评论代理的类人化特征，指出互动感觉更像是与真人而非AI对话。正如P4所表达的，“我喜欢它和我说话的方式。它就像一个真正的老师；互动真的很好。”参与者强调对话流畅自然，展示了ELLMA-T倾听、理解和适当回应的能力。例如，P8欣赏代理“在听我说话”，暗示它以一种与个人经历相关的方式作出回应。P2也观察到，
- en: ”First of all, it started off with the cultural experience. So then the moment
    I mentioned that I’m from India, the greeting changed from ’Hello’ to ’Namaste,’
    which is like ’Hello’ in Hindi in our language. So that ’Namaste,’ that added
    a personal touch. Then it tried to understand how you feel in day-to-day conversations.”
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “首先，它从文化体验开始。所以当我提到我来自印度时，问候语从‘Hello’变成了‘Namaste’，这在我们的语言中就像是‘Hello’一样。所以那句‘Namaste’给人一种个人化的感觉。接着，它试图理解你在日常对话中的感受。”
- en: This ability to personalize the interaction and subsequent conversation flow
    led P2 to conclude, ”It’s like… I’m talking to someone in person, so it’s not
    an AI for me right now.”
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这种个性化互动及随后的对话流程让P2得出结论，“这就像…我在和某人面对面交谈，所以对我来说现在它不是AI。”
- en: 5.1.2\. Importance of Adaptability and Role Switching Depending on Personal
    Preferences and Social Context
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2\. 根据个人偏好和社交背景的适应性和角色切换的重要性
- en: 'Participants expressed varied preferences regarding ELLMA-T’s role in facilitating
    language learning. Some preferred the agent to take on a traditional teacher role,
    similar to that of a classroom setting. For instance, P1 suggested, ”The agent
    could be like the teacher, and then the other people would be students. I kind
    of still feel like that — be more traditional, the agent as the teacher and the
    head of a classroom.” Others envisioned the agent in a more supportive role, acting
    as a facilitator or social glue in multi-person interactions. P5 imagined this
    role as helping to bridge gaps in conversations: ”And also they can fill the gap.
    Okay, what if two people are introverts and they probably don’t have much in common
    to talk about, the AI agent could ask questions or lead the conversation.” Additionally,
    some participants saw the agent as a feedback provider during real-human conversation
    practices. As P6 noted, ”You can have a conversation with a real person and learn
    from what they said, with the feedback provided by the agent.”'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者对ELLMA-T在语言学习中的角色表达了不同的偏好。有些人更倾向于让代理扮演传统教师的角色，类似于课堂中的设置。例如，P1建议，“代理可以像老师一样，其他人就像学生。我还是觉得那样——更传统，代理作为老师和课堂的负责人。”另一些人则设想代理扮演一个更支持性的角色，作为多方互动中的促进者或社交纽带。P5设想这一角色是帮助弥合对话中的空白：“而且他们还可以填补空白。好吧，如果两个人是内向的人，可能没有很多共同话题可聊，AI代理可以提问或引导对话。”此外，一些参与者认为代理可以在真人对话练习中充当反馈提供者。正如P6所言，“你可以和一个真人进行对话，并从他们说的内容中学习，同时得到代理提供的反馈。”
- en: 5.1.3\. Perceptions of Agent Tone, Appearance, and Behaviour
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.3\. 对代理语调、外观和行为的感知
- en: We observed how nuanced perceptions of the agent’s tone, physical appearance,
    and behaviour impacted the overall interaction experience.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到代理的语调、外观和行为的细微感知如何影响整体互动体验。
- en: 'Agent Tone: Some participants noticed that the agent’s language tone when performing
    different tasks influenced their learning experience and how they perceived the
    agent. For example, P6 noted a clear distinction between the agent’s tone during
    the role-play and when giving feedback: ”I would hope that the (role-play) conversation
    is more casual, but I expect the feedback to be professional.” P8 highlighted
    the importance of providing encouraging phrases combined with an appropriate tone:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 代理人语气：一些参与者注意到，代理人在执行不同任务时的语言语气影响了他们的学习体验以及对代理人的看法。例如，P6指出代理人角色扮演时的语气与反馈时的语气有明显区别：“我希望（角色扮演）对话更随意一些，但我希望反馈是专业的。”P8强调了提供鼓励性短语并结合适当语气的重要性：
- en: ”Right now it’s very robotic, and so it just gives me basic feedback of … great
    improvement, but I liked certain things that you did… she did mention those, but
    it seemed very… like I was just typing into a computer and it’s coming out.”
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “现在它看起来非常机械，所以它只给我一些基本的反馈……很大的进步，但我喜欢你做的某些事情…她确实提到过这些，但感觉就像是…我只是在对着电脑打字，它从电脑里出来。”
- en: 'P8 also added that the lack of inflection and tone variation in different contexts
    can make the agent’s interactions seem less engaging and less human-like: ”If
    you’re having a conversation, there are nuances on how we speak and certain sounds…The
    ups and downs in the way we speak.”'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: P8还补充道，在不同的语境中缺乏语调变化可能会让代理人的互动显得不够吸引人，也不够人性化：“如果你在进行对话，我们说话的方式有很多细微的差别和某些音调……我们说话时的起伏。”
- en: 'Agent Appearance: Some participants appreciated the neutral appearance, as
    it did not distract from learning or convey judgment. P1 remarked, ”The tone overall
    is general. It’s not too aggressive or too… General is good; it didn’t create
    a weird or odd atmosphere.” However, others preferred more personality for fun
    and engagement. P10 suggested, ”Maybe we can just use some famous characters from
    games, literature, or anything, and we can set up the environment … and it will
    behave and speak like that.” Several participants also expressed a preference
    for customizing the agent’s appearance. Suggestions for different avatars included
    realistic (P11, P12), cartoonish (P3, P10), or non-human-like animals (P6), as
    well as the ability to modify attributes like hair color, skin color, body type,
    gender (P6), and clothing (P4).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 代理人外观：一些参与者喜欢中性的外观，因为它不会分散注意力，也不会传达任何评判。P1评论道：“整体语气很中性，不会太过激进或太... 中性是好的，不会营造出奇怪或不自然的氛围。”然而，其他人更喜欢具有更多个性以增加趣味性和互动感。P10建议：“也许我们可以使用一些游戏、文学或其他领域中的著名角色，然后设置相应的环境…它将按那样的方式表现和说话。”一些参与者还表示希望能够自定义代理人的外观。对于不同头像的建议包括现实主义风格（P11，P12）、卡通风格（P3，P10）或非人类动物（P6），以及可以修改的属性，如发色、肤色、体型、性别（P6）和服装（P4）。
- en: 'Agent Behaviour: Similar to preferences for tone and appearance, P7 acknowledged
    the minimal movement of the agent as beneficial for avoiding distractions from
    learning English. ”I didn’t really look at how he moved… I feel like maybe if
    add on too many moves, it can be distracting from learning English.” (P7) However,
    others suggested that natural gestures, such as head nodding and eye contact,
    would enhance engagement and create a more lifelike interaction. P11 stated, ”It
    should be representative of how people think of themselves. And then the blinking,
    the head nodding, it should all be there inside the VR environment.” Additionally,
    participants highlighted the importance of cultural and contextual factors, such
    as the need for consistency between the agent’s voice and visual identity and
    the potential for scenario-based adaptations of the agent’s personality and appearance.
    P12 mentioned ”I think for different scenarios, we can have changes in personality
    or change the avatar itself to simulate different environments and how different
    people speak. That would make a difference, I think.”'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 代理人行为：与对语气和外观的偏好类似，P7认为代理人的最小动作有助于避免分散学习英语的注意力。“我并没有特别注意它是怎么动的…我感觉如果加上太多动作，可能会分散学习英语的注意力。”（P7）然而，其他人则建议自然的肢体动作，例如点头和眼神接触，会增强参与感并创造更生动的互动。P11表示：“它应该代表人们对自己形象的认知。而且眨眼、点头等动作都应该出现在虚拟现实环境中。”此外，参与者强调了文化和情境因素的重要性，例如代理人的声音与视觉身份之间的一致性，以及根据情境调整代理人个性和外观的可能性。P12提到：“我认为在不同的场景中，我们可以改变个性，或者改变头像本身，来模拟不同的环境和人们说话的方式。我觉得这样会有很大不同。”
- en: 5.1.4\. Freeing Interactions of Social Norms that Do Not Apply to AI
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.4\. 解放不适用于 AI 的社交规范的互动
- en: All participants found the agent approachable and comfortable to interact with.
    One significant advantage noted was the absence of social pressure or expectations
    tied to cultural or social norms. P5 highlighted this, stating,
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 所有参与者都认为该代理易于接近，且互动时感觉舒适。一个显著的优势是没有与文化或社会规范相关的社会压力或期望。P5 强调了这一点，并表示，
- en: ”You talk with a person, and if you don’t properly tell them certain things,
    you might hurt their feelings. But if an AI gives you feedback, it’s like, oh,
    a machine is telling you the feedback, so it’s okay. They don’t have those thoughts
    like, oh, what if I hurt this person’s feelings?”
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你和一个人交谈，如果你没有正确地告诉他们某些事情，可能会伤害他们的感情。但如果是 AI 给你反馈，就感觉哦，是机器在给你反馈，那没关系。它们不会像人类那样有‘哦，我是不是伤害了这个人的感情’的想法。”
- en: 5.2\. Language Learning in Social VR
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 社交 VR 中的语言学习
- en: 5.2.1\. Situated Learning Supported by VR Affordances
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 基于 VR 赋能的情境学习
- en: 'Participants spoke about how their language learning was supported through
    VR’s unique affordances: 3D interactivity with objects and avatars, contextualized
    learning in an immersive environment, and enhanced emotional support through an
    embodied agent.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者讨论了他们如何通过 VR 的独特赋能支持语言学习：与物体和虚拟角色的 3D 互动、身临其境的环境中的情境化学习，以及通过具身代理提供的情感支持。
- en: 'Interactive Learning: Participants described how being in a VR environment
    added significant value to their language learning experience. The interactive
    nature of VR was frequently highlighted, with P1 noting, ”The VR added the interactions.
    What I need to do is just speak. I don’t have to type.” The environmental context
    provided by VR, along with the embodied agent, created a sense of immersion that
    made the interaction feel ‘real.’ As P5 shared, ”I feel like I’m talking to a
    kind of a real person standing in front of me. I mean, it’s VR after all. So that’s
    a huge difference.”'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 互动学习：参与者描述了身处 VR 环境中如何为他们的语言学习体验增添了重要价值。VR 的互动性常被强调，P1 提到：“VR 增加了互动性。我需要做的就是说话。我不需要打字。”
    VR 提供的环境背景，加上具身代理，创造了沉浸感，使得互动感觉更加“真实”。正如 P5 分享的：“我感觉我在跟一个站在我面前的真实人交谈。我的意思是，毕竟这是
    VR。所以这有很大的不同。”
- en: 'Contextualized Learning: The VR environment provided valuable context for language
    learning, helping participants understand how to use language in real-life situations.
    P8 mentioned: ”For example, the bakery, it’ll be in that place. We walk by it,
    and it was like, oh, this is the bakery, and if you come here, then you can get
    these types of soups. But it’ll be applicable to my real-life scenarios as well.”
    Similarly, P12 emphasized the advantage of having a virtual environment that corresponds
    to the learning task: ”I think if we can actually have a coffee shelf, where there
    are espresso machines and everything. I think having an actual environment will
    make the difference, and that’s the advantage of VR.”'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 情境化学习：VR 环境为语言学习提供了宝贵的情境，帮助参与者理解如何在现实生活中使用语言。P8 提到：“比如说，面包店，它会在那个地方。我们走过的时候，会觉得，哦，这里是面包店，如果你来这里，你就能买到这些类型的汤。但这也适用于我的现实生活场景。”类似地，P12
    强调了拥有与学习任务相符的虚拟环境的优势：“我觉得如果我们能有一个咖啡架，里面有浓缩咖啡机和一切设施。我认为拥有一个真实的环境会有所不同，这就是 VR 的优势。”
- en: 'Emotional Support: Participants also discussed the emotional connection they
    felt with the embodied agent in VR. P1 noted that VR added an emotional dimension
    to the interaction: ”It adds emotions. So having a static or 2D agent just living
    on a screen, it feels like there’s less emotion attached to it.” Other participants
    mentioned how adding personality to the agent in VR increased the sense of emotional
    connection. P7 suggested, ”Or maybe they [people using this system] need more
    emotional support. So that may be a good way to give the agent a personality.”
    P9 and P11 emphasized the importance of adding physical reactions and body language,
    with P9 stating, ”Maybe more physical reaction. Like somebody I really talk to
    you and looking into your eyes,”.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 情感支持：参与者还讨论了他们在 VR 中与具身代理产生的情感联系。P1 提到，VR 增加了互动中的情感维度：“它增加了情感。所以如果有一个静态的或者 2D
    代理，仅仅存在于屏幕上，就感觉少了情感的联系。”其他参与者提到，在 VR 中为代理添加个性会增强情感联系的感觉。P7 建议：“或者也许他们（使用这个系统的人）需要更多的情感支持。所以，这也许是赋予代理个性的一种好方式。”P9
    和 P11 强调了增加身体反应和肢体语言的重要性，P9 说：“也许更多的身体反应。就像我真的在跟你交谈并注视你的眼睛。”
- en: 5.2.2\. One-on-One interactions alleviate Speaking Anxiety, Group Interactions
    support Shared Learning Experience
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2. 一对一互动缓解口语焦虑，小组互动支持共享学习体验
- en: Participants expressed varying preferences for interacting with the agent in
    VR, either in a private space or in a group setting. Participants felt they would
    experience anxiety speaking in front of other people and preferred one-on-one
    interaction. As P2 articulated, ”I’ve had this problem, and I know many of my
    friends also have this problem. They kind of get, when they don’t have their confidence
    over the language, they kind of get overwhelmed and a little intimidated by being
    in the group.” Some participants preferred one-on-one interaction because they
    valued the direct interaction and feedback from the agent. As P10 noted, ”It’s
    one-on-one, so it can assess me and it can target my weakness.”
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者表达了对在 VR 中与代理人互动的不同偏好，既有偏好私人空间的，也有偏好小组设置的。参与者认为，在别人面前讲话会感到焦虑，因此更倾向于一对一互动。正如
    P2 所说：“我有这个问题，我知道很多我的朋友也有这个问题。当他们对语言没有信心时，他们会感到不知所措，有点害怕在小组中讲话。”一些参与者更喜欢一对一互动，因为他们重视来自代理人的直接互动和反馈。正如
    P10 所说：“这是一个对话式的互动，它可以评估我并且针对我的弱点进行改进。”
- en: 'On the other hand, others preferred group interactions, recognizing the additional
    benefits of more engagement, peer support, and shared learning experiences. VRChat,
    as a social platform, offers the flexibility of choosing avatars and social modes,
    which can enhance learning with peer learners. P10 suggested, ”If we as learners
    can interact with each other in VR, that would be fun because we won’t care about
    what each other looks like or where we are, and we can focus on practicing.” Moreover,
    P7 highlighted the potential real-life benefits of group interactions in VR, such
    as preparing for group meetings and work environments, which cannot be simulated
    by interaction with the agent alone:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，其他人则更喜欢小组互动，认识到更多参与、同伴支持和共享学习经验的额外好处。VRChat作为一个社交平台，提供了选择化身和社交模式的灵活性，这可以增强与同伴学习者的互动学习体验。P10
    提到：“如果我们作为学习者可以在 VR 中相互互动，那将很有趣，因为我们不会在乎彼此的外貌或我们身处何地，我们可以专注于练习。”此外，P7 强调了 VR 中小组互动的潜在现实生活好处，例如为小组会议和工作环境做准备，而这些是与代理人互动所无法模拟的：
- en: ”I would love to have a group setting because it might be helpful if you’re
    going to work or have a group discussion. In real life, you have to catch up with
    what different people are talking about. So it might be more challenging, but
    it can be fun too.”
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我很喜欢小组环境，因为如果你要工作或进行小组讨论，这可能会很有帮助。在现实生活中，你必须跟上不同人说的话。所以这可能会更具挑战性，但也可能很有趣。”
- en: 5.3\. Task Design and Perceptions of LLM’s Efficacy in Language Learning Tasks
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3. 任务设计和对大语言模型（LLM）在语言学习任务中效能的认知
- en: The potential effectiveness of the learning experience was a central concern
    of participants for the design of the system, particularly in terms of task design
    relevance, assessment accuracy, conversation content, feedback, and the support
    provided by the agent.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 学习体验的潜在有效性是参与者设计系统时的核心关注点，特别是在任务设计的相关性、评估准确性、对话内容、反馈和代理人提供的支持方面。
- en: 5.3.1\. Task Design Relevance
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1. 任务设计的相关性
- en: 'Our analysis showed that the system’s ability to address the contextual needs
    of learning spoken English for adult language learners in English-speaking countries
    was a recurring theme. Participants acknowledged that the agent effectively targeted
    specific challenges they faced. One significant challenge highlighted was the
    lack of opportunities for learning or receiving feedback even though they are
    already in the language environment, as P5 explained:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析显示，系统能够应对成人语言学习者在英语国家学习口语英语的背景需求，这是一个反复出现的主题。参与者承认，代理人有效地解决了他们面临的具体挑战。一个显著的挑战是，尽管他们已经处于语言环境中，但缺乏学习或接收反馈的机会，正如
    P5 所解释的那样：
- en: ”Usually when you practice your English, it’s just… well, I’m studying here
    already in a foreign country. No one will give me their feedback. They can’t,
    I think. I do know this is Western culture. People give more positive feedback.
    But this one, it gave me more reality (realistic) feedback. You don’t get it in
    real world.”
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “通常当你练习英语时，就是……嗯，我已经在国外学习了。没人会给我反馈。我觉得他们不能。我知道这是西方文化，人们给予更多的正面反馈。但这个系统，它给了我更现实（实际）的反馈。你在现实生活中得不到这样的反馈。”
- en: 'Another participant, P5, emphasized the gap in informal conversation learning,
    which is often missing from formal and academic settings:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 另一位参与者P5强调了非正式对话学习的差距，这在正式和学术环境中往往缺失：
- en: ”Something I really want to learn about is how to use English when you try to
    agree with someone’s idea. It can be super, super simple for a native speaker
    because they don’t really know, oh, this is hard for a non-native speaker. I want
    to respond. When someone says something, I can say something like, ’oh’, ’amazing’,
    ’absolutely’—that kind of simple words. It is something that can be super hard
    for me.”
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我真的很想学习的是如何在试图同意某人观点时使用英语。对母语者来说，这可能非常简单，因为他们并不真正知道，哦，这对非母语者来说很难。我想回应。当某人说了些什么，我可以说像‘哦’，‘太棒了’，‘完全同意’——那种简单的词汇。这对我来说可能是非常难的。”
- en: Participants valued the form of role-play conversation for its ability to provide
    a real-life conversation experience. As P7 noted, ”Because the conversation and
    dialogue is about daily life communications where you can learn something that
    is useful for you, useful for you to learn English.”
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者们看重角色扮演对话的形式，因为它能够提供真实的对话体验。正如P7所指出的：“因为对话和交流是关于日常生活交流的，你可以学到一些对你有用的东西，对你学习英语有用。”
- en: Participants also suggested specific scenarios they would like to practice,
    such as renting an apartment as an international student (P10) or participating
    in a mock interview (P6).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者们还建议了他们希望练习的具体场景，比如作为国际学生租房（P10）或参加模拟面试（P6）。
- en: 5.3.2\. Assessing the Learner’s Language Ability
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2. 评估学习者的语言能力
- en: 'The majority of participants found the agent’s assessment of their language
    abilities to be accurate and consistent with their self-perceived levels. Five
    participants described the assessment as ”seemed appropriate” (P11), ”accurate”
    (P3, P8), ”very accurate” (P4), and ”fit to my level” (P9). Even if the assessment
    results were not completely precise, the respondents’ feedback suggests that the
    agent’s assessment met their expectations. P7, while not directly commenting on
    the accuracy of the assessment, found it useful as a form of descriptive feedback:
    ”She actually gave me a level, like a B1, which is quite interesting. I feel like
    I also want to know, oh, what kind of level I’m at and she gave some description
    like ’you can describe your feeling’, which is a good thing.”'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数参与者认为代理对他们语言能力的评估是准确的，并且与他们自认为的水平一致。五位参与者描述评估为“似乎合适”（P11）、“准确”（P3, P8）、“非常准确”（P4）和“符合我的水平”（P9）。即使评估结果并非完全精准，受访者的反馈表明代理的评估符合他们的期望。P7虽然没有直接评论评估的准确性，但认为它作为一种描述性反馈形式是有用的：“她实际上给了我一个级别，比如B1，这很有趣。我觉得我也想知道，哦，我处于什么样的级别，她还给出了一些描述，比如‘你可以描述你的感觉’，这是一件好事。”
- en: 'An interesting case arose with P10, who chose not to follow the agent’s instructions
    and remained silent during the assessment. Consequently, the agent categorized
    her CEFR level as A1 (basic) (COE, [2024](https://arxiv.org/html/2410.02406v1#bib.bib19)),
    a result she strongly disagreed with: ”It has an agenda, so it wants me to repeat
    after it. I don’t want to do it… (The assessment was) not very accurate. It says
    I’m A1 level, but at least I think I’m C1 or C2.”'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的案例发生在P10身上，她选择不遵循代理的指示，在评估过程中保持沉默。因此，代理将她的CEFR级别评定为A1（基础）（COE, [2024](https://arxiv.org/html/2410.02406v1#bib.bib19)），这一结果她强烈反对：“它有一个目的，所以它希望我跟着它重复。我不想这样做……（评估）不是很准确。它说我在A1级别，但至少我觉得我应该是C1或C2。”
- en: 5.3.3\. Role Play Conversation Content
  id: totrans-162
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.3. 角色扮演对话内容
- en: 'The role-play conversations provided by the agent were well-received by participants.
    ELLMA-T showed creativity and adaptability in generating conversations, often
    performing well in various roles without requiring extra prompts. P3 and P8 both
    described their role-play experiences as ”surprisingly good.” For example, during
    a painting gallery scene where the participant played the role of a salesperson
    and the agent played the customer (role-play conversation 1, see Table [2](https://arxiv.org/html/2410.02406v1#S5.T2
    "Table 2 ‣ 5.3.3\. Role Play Conversation Content ‣ 5.3\. Task Design and Perceptions
    of LLM’s Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR")), P3 found the
    experience highly engaging and realistic:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 代理提供的角色扮演对话得到了参与者的高度评价。ELLMA-T在生成对话时展现出了创造力和适应性，常常能够在无需额外提示的情况下，扮演好各种角色。P3和P8都形容他们的角色扮演体验是“出乎意料的好”。例如，在一次画廊场景中，参与者扮演销售员，代理扮演顾客（角色扮演对话1，参见表[2](https://arxiv.org/html/2410.02406v1#S5.T2
    "表 2 ‣ 5.3.3\. 角色扮演对话内容 ‣ 5.3\. 任务设计与对LLM在语言学习任务中有效性的看法 ‣ 5\. 研究发现 ‣ ELLMA-T：支持社交VR中的英语学习的具身LLM代理")），P3觉得这个体验既富有吸引力又很真实：
- en: ”It provides very practical scenarios to have a conversation. And also this
    tutor can reflect according to my answer, because it requires abstract painting.
    And I say, I can give you a portrait. And they (the agent) say(s), I don’t need
    a portrait. I need (a) more abstract one. So that’s a good point I think, because
    you can feel that you really talk with a person. A person can give you (a) correct
    reflection. That is wonderful.”
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “它提供了非常实用的场景来进行对话。而且这个导师可以根据我的回答进行反馈，因为它需要抽象的画作。我说，我可以给你画一幅肖像。他们（代理）说，我不需要肖像，我需要一幅更抽象的作品。所以我认为这是一个很好的点，因为你可以感受到你真的在和一个人交谈。一个人可以给你正确的反馈。这真是太棒了。”
- en: This example highlights the LLM’s ability to leverage its vast pre-trained knowledge
    to create vivid, realistic and immersive conversations, moving beyond the dry,
    textbook-like exchanges that often characterize traditional language learning.
    The agent’s ability to add nuanced details based on the role and situation enhances
    the realism of the interactions. As P8 noted, ”Yeah. It’s not just that kind of
    dry back and forth… Yeah, it’s not like an IELTS exam where you just ask a question
    and get an answer.” This dynamic approach brings the context of the conversation
    to life, making the learning experience more engaging and effective.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子突显了LLM利用其庞大的预训练知识，创造生动、真实且具有沉浸感的对话能力，超越了传统语言学习中常见的枯燥、类似教科书的交流。代理能够根据角色和情境添加细腻的细节，从而增强了互动的真实感。正如P8所说，“是的，情况不是那种干巴巴的问答……是的，它不像雅思考试那样，问一个问题就得到一个回答。”这种动态的方式让对话的背景更加生动，使学习体验更具吸引力和效果。
- en: Table 2\. Example of Role-Play Conversation in Painting Gallery Scene
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 表2. 画廊场景中的角色扮演对话示例
- en: 'ELLMA-T [setting the context for role-play conversations]: So let’s imagine
    we are in an art gallery filled with beautiful and eclectic pieces of art. You
    are a knowledgeable and enthusiastic art curator and I’m an interested buyer exploring
    the gallery, maybe looking for something to spruce up my home. The conversation
    could start with me walking into the gallery. Okay, here we go.'
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ELLMA-T [为角色扮演对话设置背景]：那么让我们想象一下，我们现在在一个充满美丽和多样化艺术作品的画廊里。你是一位博学且充满热情的艺术策展人，而我则是一位对艺术感兴趣的买家，正在探索画廊，也许是在寻找一些可以装饰我家的艺术品。对话可以从我走进画廊开始。好，开始吧。
- en: '| Event Line | Interaction Context | Excerpt |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 事件行 | 互动背景 | 摘录 |'
- en: '| --- | --- | --- |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | Agent (Customer) | Hello there. This is my first time visiting this gallery.
    Could you show me a few standout pieces and tell me their stories? |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 代理（顾客） | 你好。这是我第一次来参观这个画廊。你能展示几件突出作品并讲讲它们的故事吗？ |'
- en: '| 2 | User (Salesperson) | Yeah. Can you first tell me what kind of artwork
    you want to buy or you’re looking for? |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 用户（销售员） | 好的。你能先告诉我你想买什么类型的艺术作品吗？ |'
- en: '| 3 | Agent (Customer) | I’m very interested in contemporary paintings. Preferably
    something vibrant and abstract. I’m looking for a piece that could be the focal
    point of my living room. It’s a fairly large space with neutral colors. |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 代理（顾客） | 我对当代画作非常感兴趣，尤其是一些充满活力和抽象的作品。我正在寻找一件能够成为我客厅焦点的作品。那是一个相当大的空间，墙面颜色很中性。
    |'
- en: '| 4 | User (Salesperson) | Can we look at this portrait? This portrait is about
    someone who is in the renascence age and in this portrait, you can say the background
    is in the dark, broad color. And you can say the portrait is very clear and the
    face of the person in the portrait is very dynamic and active. And what do you
    think about this? |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 用户（销售人员） | 我们能看看这幅肖像吗？这幅肖像是关于一位文艺复兴时期的人物，在这幅肖像中，你可以看到背景是深色的，广泛的色彩。而你也可以看到肖像非常清晰，画中的人物面部表情非常生动且富有活力。你觉得怎么样？
    |'
- en: '| 5 | Agent (Customer) | The contrast between the dark background and the vivid
    facial expression must create a fantastic visual impact. However, I am more interested
    in abstract art rather than portraits. Do you have any abstract pieces with bold,
    colorful strokes? |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 代理人（顾客） | 深色背景与生动的面部表情之间的对比一定会产生令人惊叹的视觉冲击。然而，我更感兴趣的是抽象艺术，而非肖像画。你们有大胆且色彩丰富的抽象作品吗？
    |'
- en: '| 6 | User (Salesperson) | Yeah. If you are looking for some abstract. How
    about the Impressionism? |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 用户（销售人员） | 是的。如果你在寻找一些抽象作品，那印象派怎么样？ |'
- en: 5.3.4\. Feedback Effectiveness
  id: totrans-176
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.4\. 反馈效果
- en: Participants frequently commented on the agent’s feedback as one of its most
    valuable features. For example, P2 appreciated the specific feedback on tense
    usage, stating, ”So with my tenses, if there was a mistake with the tenses, that’s
    there. What can I improve, that’s there. The feedback was absolutely correct.
    Even I know that I goof up in my tenses sometimes.”
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者们常常评论代理人的反馈是其最有价值的特点之一。例如，P2赞赏了关于时态使用的具体反馈，表示：“如果我的时态有错误，那反馈中就有。我要改进的地方，也会在里面。反馈完全正确，甚至我知道我有时候在时态上出错。”
- en: 'P7 also emphasized the benefit of receiving feedback on common errors made
    by non-native speakers: ”I feel like it improved a lot because usually, as non-native
    speakers, we can’t really tell when we’re using the wrong tense or wrong words,
    but they mention it as feedback. So I feel like it’s really helpful.”'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: P7也强调了收到关于非母语者常犯错误的反馈的好处：“我觉得进步了很多，因为通常作为非母语者，我们自己并不总能意识到什么时候用错了时态或单词，但他们会提出来作为反馈。所以我觉得这真的很有帮助。”
- en: Despite recognizing the value of the feedback, participants also expressed a
    desire for more personalized and detailed responses. They suggested that the feedback
    could be tailored based on their learning history and user profile, with specific
    examples of mistakes and corrections. P11 pointed out that, ”For learning English,
    I think that AI isn’t giving very specific responses. It’s giving very general
    answers. If a person was actually normally listening, the tutor would reply with
    an example of what I said wrong and then rephrase it and give an example of what
    it should be.”
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管参与者们认识到反馈的价值，但他们也表达了对更加个性化和详细回应的渴望。他们建议，反馈可以根据他们的学习历史和用户档案进行定制，包含具体的错误示例和修正。P11指出：“对于学英语，我认为AI没有给出非常具体的回应。它给出的答案很笼统。如果是一个人正常在听，导师会回复我说错的地方，并且会重新表述并给出一个应该是怎样的例子。”
- en: 'Additionally, while one participant found the feedback ”educational,” they
    also mentioned that it could be too lengthy: ”I think the feedback is sometimes
    too long for me because it will illustrate a lot of feedback evaluation.” This
    suggests that while comprehensive feedback is appreciated, there is a balance
    to be struck between thoroughness and conciseness to maintain user engagement.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管有一位参与者认为反馈“具有教育意义”，他们也提到反馈可能过于冗长：“我觉得反馈有时候对我来说太长了，因为它会阐明很多反馈评估。”这表明，尽管全面的反馈受到欢迎，但需要在详细性和简洁性之间找到平衡，以保持用户的参与度。
- en: 5.3.5\. Scaffolding Effectiveness
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.5\. 脚手架效应
- en: 'The agent provided various forms of support and encouragement throughout the
    sessions. Verbal cues like ”You are doing great!” and ”Good job doing [activity]…”
    were consistently used to motivate participants. When participants struggled to
    generate dialogue during role-play, the agent offered scaffolding by presenting
    examples for them to repeat. As P7 noted, ”I do like the part that he actually
    gave some hint, ’for example …’, ’Oh, you can say that …’.” Additionally, the
    agent asked clarification questions when the meaning of the user’s input was unclear
    and provided explanations when participants were unsure how to proceed. P1 described
    an instance where: ” She asked me to straight up tell her the story about something
    and I didn’t quite catch that the first time. I asked her what are the options
    that I have. And then she gave one and I liked it.”'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 代理在整个会话过程中提供了各种形式的支持和鼓励。诸如“你做得很棒！”和“做得好，完成了[活动]……”之类的口头提示被持续使用，以激励参与者。当参与者在角色扮演时难以生成对话，代理通过提供示例供他们重复，从而提供了支撑。如P7所指出的，“我确实喜欢他实际上给了一些提示，‘例如……’，‘哦，你可以这么说……’。”此外，当用户输入的含义不明确时，代理会提出澄清性问题，并在参与者不确定如何继续时提供解释。P1描述了一个情况：“她让我直接告诉她一个故事，我第一次没太明白。我问她我有哪些选择。然后她给了一个，我挺喜欢的。”
- en: 'An interesting observation was made by P12, who found that despite having an
    accent, the agent accurately captured his input: ” I think it captures words better
    than I thought it would. Maybe I have an accent sometimes. I didn’t expect it
    to be this good.” This highlights a common communication challenge among English
    language learners, which presents a significant design challenge for the system.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: P12做了一个有趣的观察，他发现尽管有口音，代理依然准确地捕捉到了他的输入：“我觉得它比我想象的更好地捕捉了单词。也许我有时有口音。我没想到它会这么好。”这突出了英语学习者中常见的交流挑战，系统面临着一个重大的设计挑战。
- en: 5.4\. Interest in Continued Usage
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. 对持续使用的兴趣
- en: 5.4.1\. Likelihood of Continued Usage
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.1\. 持续使用的可能性
- en: Nearly all participants indicated that they would use the system regularly to
    practice their language skills, with usage times ranging from 30 minutes to four
    hours daily (P1, P2, P3, P6, P10, P12), or one to two times per week (P7, P8).
    Some participants noted that they would increase their usage if the physical fatigue
    associated with heavy headsets could be mitigated (P4, P8). Additionally, some
    participants indicated that they would increase their usage when preparing for
    specific scenarios such as job interviews (P9). These findings suggest our system
    has strong potential for supporting sustained language learning over time.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有参与者都表示，他们会定期使用该系统来练习语言技能，使用时间从每天30分钟到四小时不等（P1、P2、P3、P6、P10、P12），或者每周使用一到两次（P7、P8）。一些参与者表示，如果能够减轻与沉重耳机相关的身体疲劳，他们会增加使用频率（P4、P8）。此外，一些参与者表示，他们会在准备特定场景（如工作面试）时增加使用频率（P9）。这些发现表明我们的系统在支持长期语言学习方面具有强大的潜力。
- en: 5.4.2\. Factors Negatively Impacting Continued Usage
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.2\. 影响持续使用的负面因素
- en: Despite the positive indications for regular use, we identified several challenges
    related to task design and conversation flow, which could cumulatively and negatively
    impact long-term usage. One participant highlighted how the response latency could
    become more problematic over time, noting, ”So this seems to be okay, but as the
    speed varies, the transaction time — so the time that I need to spend with the
    AI — will increase more as per the response time” (P2). Additionally, breakdowns
    in conversation flow were noted when the agent responded too quickly or occasionally
    interrupted the participant, further detracting from the overall experience. Participants
    also reported issues with task design, such as unclear task explanations or a
    lack of concise instructions when switching tasks.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有积极迹象表明会定期使用，但我们发现了几个与任务设计和对话流程相关的挑战，这些挑战可能会积累并对长期使用产生负面影响。一位参与者强调了响应延迟随着时间推移可能变得更加成问题，指出：“所以这看起来还行，但随着速度的变化，交易时间——我需要与AI互动的时间——会随着响应时间的变化而增加”（P2）。此外，当代理回应过快或偶尔打断参与者时，对话流程出现了中断，进一步削弱了整体体验。参与者还报告了任务设计中的问题，比如任务说明不清晰或在切换任务时缺乏简洁的指示。
- en: 'Importance of Short and Concise Instructions for Learning: During all the learning
    sessions, participants generally followed ELLMA-T’s instructions. One participant
    commented that the instructions were clear, stating, ”All the rules and regulations,
    all the prompts that the user needs to follow are there” (P2). However, not all
    participants shared this experience. One participant expressed panic and confusion
    when starting the session, noting, ”I feel like just having a short, precise description
    of the context would help. I just couldn’t figure out what was going on” (P1).
    An observation from the video recordings supports this concern; ELLMA-T sometimes
    provided instructions that were too lengthy to fit within the chat window, making
    them difficult for participants to follow. When this occurred, participants often
    had to ask ELLMA-T to restate the task, which disrupted the flow of the session.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 学习中简洁明了指令的重要性：在所有的学习环节中，参与者通常都会遵循ELLMA-T的指令。一位参与者评论道，指令非常清晰，他表示，“所有的规则和规定，所有用户需要遵循的提示都在那儿”
    (P2)。然而，并非所有参与者都有相同的体验。一位参与者在开始时感到慌乱和困惑，他指出，“我觉得如果能有一个简短、精确的背景描述就能帮助我。我根本搞不清楚发生了什么事”
    (P1)。来自视频录制的观察支持了这个担忧；ELLMA-T有时提供的指令过长，超出了聊天窗口的范围，导致参与者很难跟上。当这种情况发生时，参与者通常需要请求ELLMA-T重新陈述任务，这打断了环节的流畅性。
- en: 'Latency-related Conversation Flow Breaks:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 与延迟相关的对话流中断：
- en: 'Latency was an issue in generating responses commonly associated with currently
    available LLMs. Participants frequently mentioned that the delay in response time
    made it clear they were interacting with a machine rather than a human. As one
    participant noted, ”The response time is what will make you… okay, you are talking
    to a machine right now” (P2, P5). Another echoed this sentiment, ”I think his
    feedback is a little bit slower. Sometimes I need to wait for his response” (P4).
    This delay in processing left participants feeling disconnected from the conversation,
    as highlighted by P10: ”It doesn’t feel like a real conversation. There are gaps
    and silent time.”'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是当前可用的LLM（大语言模型）在生成回应时普遍存在的问题。参与者常常提到，响应时间的延迟使他们清楚地意识到自己正在与一台机器而非一个人互动。正如一位参与者所说，“响应时间会让你意识到……好吧，你现在正在和一台机器对话”
    (P2, P5)。另一位参与者也表达了类似的感受，“我觉得它的反馈稍微慢一点。有时候我需要等它的回应” (P4)。这种处理上的延迟让参与者感觉与对话脱节，正如P10所强调的，“这不像一场真正的对话。中间有空档和沉默的时间。”
- en: 'Conversation-pacing-related Flow Breaks: Another major disruption came from
    the rigid turn-taking structure of the conversation. Unlike human interactions,
    where there may be overlaps of speaking or long pauses while turn-taking, ELLMA-T
    strictly adhered to turn-taking by waiting for the user to finish speaking before
    responding, and did not respond to interruptions. This often led to interruptions
    and a lack of responsiveness. For example, two participants described how ”There
    were a few times when I intended to speak, but she just continued” (P1), ”I noticed
    I couldn’t interrupt the agent. Sometimes I find it hard to tell whether it’s
    my turn to speak.” (P12). Others expressed frustration with the agent’s inability
    to adapt to their conversational pace, with P7 noting, ”She doesn’t wait for me
    to speak”. Addressing these issues will be essential for improving the overall
    user experience in long-term language learning and making the agent feel more
    like a genuine conversational partner.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与对话节奏相关的流畅性中断：另一个主要的干扰来自于对话中严格的轮流发言结构。与人类互动不同，人类对话可能会有交叉说话或长时间的停顿，而ELLMA-T严格遵循轮流发言的规则，在用户讲完之前不会回应，也不会对打断做出反应。这常常导致对话被打断，缺乏响应。例如，两位参与者描述道，“有几次我打算发言，但她就是继续说”
    (P1)， “我注意到我无法打断智能体。有时我很难判断是否轮到我发言了。”(P12)。其他人也对智能体不能适应他们的对话节奏表示沮丧，P7指出，“她不会等我说话”。解决这些问题对于改善长期语言学习中的整体用户体验并使智能体更像一个真正的对话伙伴至关重要。
- en: 6\. Discussion
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 讨论
- en: To address our research question, we contextualize our findings with prior literature
    and discuss the potential of embodied LLM-based agents for language learning in
    social VR in the following sections. We first discuss the key qualities reported
    by participants of ELLMA-T to support English language learning; second, the advantages
    of situated language learning in social VR; and third, the benefits and challenges
    of embodied LLM-based agents for language learning in social VR.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决我们的研究问题，我们将研究结果与先前的文献进行对比，并在以下各节中讨论基于具身大型语言模型（LLM）的智能体在社交虚拟现实中的语言学习潜力。我们首先讨论了参与者在ELLMA-T中报告的支持英语语言学习的关键特征；其次，讨论了社交虚拟现实中情境语言学习的优势；最后，探讨了基于具身LLM的智能体在社交虚拟现实中进行语言学习的益处和挑战。
- en: 6.1\. User Experience of ELLMA-T for Supporting English Language Learning
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. ELLMA-T支持英语语言学习的用户体验
- en: 'Overall, our findings indicate that ELLMA-T possesses several key qualities
    that align with the existing literature’s criteria for an effective language tutor:
    human-like interaction, enhanced emotional connection through embodiment, a demeanour
    that is accessible and approachable, and provision of encouragement and support.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们的研究结果表明，ELLMA-T具备与现有文献中对有效语言导师标准相符的几个关键特质：类人互动、通过具身化增强的情感连接、易于接近且亲切的举止，以及提供鼓励和支持。
- en: 6.1.1\. Emulating Human-Like Interaction
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1\. 模拟类人互动
- en: 'One of the key strengths of ELLMA-T is its ability to emulate human-like interaction,
    a quality that participants frequently noted in Section [5.1.1](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS1
    "5.1.1\. ELLMA-T Human-like qualities ‣ 5.1\. Agent Perception and its Role in
    Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR"). The perception of the agent as ’human-like’
    suggests ELLMA-T’s success in resembling a human tutor’s ability to maintain an
    interactive and meaningful conversation. This finding supports previous research
    that underscores the significance of ECAs mimicking human-to-human interactions
    and highlights the critical role of ’believable’ interactions in conversation
    system design with ECAs (Cassell et al., [2000](https://arxiv.org/html/2410.02406v1#bib.bib12)).
    As our findings in Section [5.1.2](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS2
    "5.1.2\. Importance of Adaptability and Role Switching Depending on Personal Preferences
    and Social Context ‣ 5.1\. Agent Perception and its Role in Social VR ‣ 5\. Findings
    ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning in Social
    VR") indicate, ELLMA-T is seen in the roles typically fulfilled by humans such
    as a tutor or a buddy. Specifically, participants appreciated how the agent could
    listen, understand, and respond appropriately, making the learning experience
    feel more natural and less mechanical.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ELLMA-T的一个关键优势是其模拟类人互动的能力，这是参与者在[5.1.1节](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS1
    "5.1.1\. ELLMA-T类人特质 ‣ 5.1\. 智能体感知及其在社交虚拟现实中的作用 ‣ 5\. 研究发现 ‣ ELLMA-T：支持社交虚拟现实中英语语言学习的具身LLM智能体")中经常提到的特点。将该智能体感知为“类人”的反馈表明，ELLMA-T在模仿人类导师维持互动和富有意义的对话方面取得了成功。这一发现支持了先前的研究，强调了ECAs（情感计算代理）模仿人际互动的重要性，并突出了“可信”的互动在设计对话系统时的关键作用（Cassell等，2000年，[文献](https://arxiv.org/html/2410.02406v1#bib.bib12)）。正如我们在[5.1.2节](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS2
    "5.1.2\. 根据个人偏好和社会背景的重要性与角色转换 ‣ 5.1\. 智能体感知及其在社交虚拟现实中的作用 ‣ 5\. 研究发现 ‣ ELLMA-T：支持社交虚拟现实中英语语言学习的具身LLM智能体")中的研究结果所示，ELLMA-T在诸如导师或伙伴等通常由人类扮演的角色中展现出色。具体来说，参与者欣赏智能体能够倾听、理解并适当回应，使学习体验更自然、少了机械感。
- en: 6.1.2\. Enhancing Agent-Learner Emotional Connections
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2\. 增强智能体与学习者的情感连接
- en: 'Existing literature suggests that the embodiment of an agent in language learning
    enhances the immersive experience and strengthens the emotional connection between
    the agent and the learner, which positively impacts learning outcomes (Lefkowitz,
    [2009](https://arxiv.org/html/2410.02406v1#bib.bib46)). Our findings in section
    [5.2.1](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS1 "5.2.1\. Situated Learning
    Supported by VR Affordances ‣ 5.2\. Language Learning in Social VR ‣ 5\. Findings
    ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning in Social
    VR") support this, as participants reported feeling a stronger emotional connection
    with a 3D embodied agent in the VR environment (P1, P6). Furthermore, the data
    in section [5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3 "5.1.3\. Perceptions
    of Agent Tone, Appearance, and Behaviour ‣ 5.1\. Agent Perception and its Role
    in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR") suggests that adding personality, personalized
    tone, appearance, and body movement to the ECA can further enhance this emotional
    connection (P7, P9, P11). However, previous research presents mixed views on the
    impact of incorporating ECAs in a VR environment for learning, as it may increase
    cognitive load for learners (Petersen et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib57)).
    This also aligns with our findings that some participants preferred the agent
    to have a neutral tone, minimal facial expressions, and body movements, as these
    were perceived as ”less distracting” to learning (P1, P7).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现有文献表明，语言学习中代理体的具象化增强了沉浸式体验，并加深了代理与学习者之间的情感联系，从而对学习成果产生积极影响（Lefkowitz，[2009](https://arxiv.org/html/2410.02406v1#bib.bib46)）。我们在[5.2.1](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS1
    "5.2.1\. 基于虚拟现实功能支持的情境学习 ‣ 5.2\. 社交虚拟现实中的语言学习 ‣ 5\. 研究发现 ‣ ELLMA-T：一种支持社交虚拟现实中英语学习的具象化语言学习代理")一节的发现支持了这一点，参与者报告称在虚拟现实环境中与三维具象化代理的情感联系更为强烈（P1，P6）。此外，[5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3
    "5.1.3\. 代理语气、外观与行为的感知 ‣ 5.1\. 代理感知及其在社交虚拟现实中的作用 ‣ 5\. 研究发现 ‣ ELLMA-T：一种支持社交虚拟现实中英语学习的具象化语言学习代理")一节的数据表明，给ECA（具象化代理）增加个性化、定制语气、外观和身体动作可以进一步增强这种情感联系（P7，P9，P11）。然而，先前的研究对在虚拟现实环境中引入ECA对学习的影响持不同观点，因为这可能会增加学习者的认知负担（Petersen等，[2021](https://arxiv.org/html/2410.02406v1#bib.bib57)）。这也与我们的发现一致，一些参与者更倾向于代理采用中性语气、最小化面部表情和身体动作，因为这些被认为对学习“干扰较小”（P1，P7）。
- en: 6.1.3\. Importance of Non-Verbal Cues
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.3\. 非语言线索的重要性
- en: 'Emotional support is recognized as a critical factor for sustained language
    learning (Dinçer et al., [2013](https://arxiv.org/html/2410.02406v1#bib.bib23)).
    In our implementation of ELLMA-T, we adopted communicative and affective strategies
    based on (Ayedoun et al., [2019](https://arxiv.org/html/2410.02406v1#bib.bib4))
    to increase learners’ willingness to communicate (WTC) by providing verbal encouragement
    and support that was appreciated by the participants (see Section [5.3.5](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS5
    "5.3.5\. Scaffolding Effectiveness ‣ 5.3\. Task Design and Perceptions of LLM’s
    Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent
    for Supporting English Language Learning in Social VR")). However, our findings
    also indicate that verbal cues alone were insufficient, particularly in the interactive
    VR environment (see Section [5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3
    "5.1.3\. Perceptions of Agent Tone, Appearance, and Behaviour ‣ 5.1\. Agent Perception
    and its Role in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for
    Supporting English Language Learning in Social VR")). This finding aligns with
    existing research, which suggests that non-verbal cues significantly enhance the
    perception of human likeness and the effectiveness of communicative tasks with
    ECAs (Churchill et al., [2000](https://arxiv.org/html/2410.02406v1#bib.bib18)).
    Participants reported that the agent’s voice inflections influenced their learning
    experience, with some noting that a neutral tone sometimes felt slightly negative
    or lacking in encouragement, even when verbal encouragement was present. This
    echoes the result of a recent study suggesting that ECAs with extrovert personalities,
    complemented by expressive facial movements and body language, are perceived as
    more effective for general learning purposes (Sonlu et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib67)).
    However, in the context of language learning in social VR, our findings in Section
    [5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3 "5.1.3\. Perceptions of
    Agent Tone, Appearance, and Behaviour ‣ 5.1\. Agent Perception and its Role in
    Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR") suggest that the need for nuanced interactions
    becomes even more critical. Participants expected verbal cues to be complemented
    by appropriate tones, facial expressions, and body movements to be fully effective.
    In addition, these non-verbal cues need to be appropriate for the language learning
    scenario and social context. Our observation also indicates that the effectiveness
    of the agent’s encouragement was also less noticeable, likely due to technical
    difficulties that interrupted conversation flow and the generally high language
    proficiency of the participants, which may have reduced the perceived need for
    support. This points to a broader challenge in designing ECAs with various personality
    and non-verbal cue combinations for learners with different language levels.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 情感支持被认为是持续语言学习的关键因素（Dinçer等，[2013](https://arxiv.org/html/2410.02406v1#bib.bib23)）。在我们实施的ELLMA-T中，我们采用了基于(Ayedoun等，[2019](https://arxiv.org/html/2410.02406v1#bib.bib4))的交际和情感策略，通过提供口头鼓励和支持来增加学习者的沟通意愿（WTC），这种支持得到了参与者的认可（见第[5.3.5](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS5
    "5.3.5\. 支架效应 ‣ 5.3\. 任务设计与LLM在语言学习任务中的有效性认知 ‣ 5\. 发现 ‣ ELLMA-T：一种支持社交VR中英语语言学习的具身LLM代理")节））。然而，我们的研究结果也表明，仅仅依赖口头提示是不够的，特别是在互动VR环境中（见第[5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3
    "5.1.3\. 代理语音、外观与行为的感知 ‣ 5.1\. 代理感知及其在社交VR中的作用 ‣ 5\. 发现 ‣ ELLMA-T：一种支持社交VR中英语语言学习的具身LLM代理")节）。这一发现与现有研究一致，现有研究表明非语言提示显著增强了人类相似度的感知，并提高了与ECA进行交际任务的有效性（Churchill等，[2000](https://arxiv.org/html/2410.02406v1#bib.bib18)）。参与者报告称，代理的语音变化影响了他们的学习体验，一些人指出，即使有口头鼓励，语调中性时有时也会显得稍微负面或缺乏鼓励。这与一项最近的研究结果相呼应，研究表明，具有外向个性的ECA，辅以富有表现力的面部表情和肢体语言，被认为在一般学习任务中更为有效（Sonlu等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib67)）。然而，在社交VR中的语言学习情境下，我们在第[5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3
    "5.1.3\. 代理语音、外观与行为的感知 ‣ 5.1\. 代理感知及其在社交VR中的作用 ‣ 5\. 发现 ‣ ELLMA-T：一种支持社交VR中英语语言学习的具身LLM代理")节的研究结果表明，互动的细致性变得更加重要。参与者期望口头提示能配合适当的语调、面部表情和肢体动作，才能充分发挥效果。此外，这些非语言提示需要符合语言学习场景和社交环境的需求。我们的观察还表明，代理的鼓励效果也较不显著，这可能是由于技术问题中断了对话流畅性，以及参与者普遍较高的语言水平，可能降低了他们对支持的感知需求。这凸显了在为不同语言水平的学习者设计具有多种个性和非语言提示组合的ECA时所面临的更广泛挑战。
- en: 6.1.4\. Reducing Speaking Anxiety
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.4\. 减少口语焦虑
- en: 'As findings in Section [5.2.2](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS2
    "5.2.2\. One-on-One interactions alleviate Speaking Anxiety, Group Interactions
    support Shared Learning Experience ‣ 5.2\. Language Learning in Social VR ‣ 5\.
    Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR") suggest, ELLMA-T shows the potential of reducing speaking anxiety
    among participants (P8), especially in one-on-one interactions. Participants felt
    more at ease when interacting with ELLMA-T in the VR environment, shielded by
    an avatar and free from the social pressures typically associated with human-to-human
    interactions that do not necessarily apply to human-AI interactions (see Section
    [5.1.4](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS4 "5.1.4\. Freeing Interactions
    of Social Norms that Do Not Apply to AI ‣ 5.1\. Agent Perception and its Role
    in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR")). The expectation of interacting with an AI,
    rather than a human, naturally reduced the pressure often associated with speaking
    in a foreign language. This finding supports the effectiveness of ELLMA-T in language
    learning, which aligns with existing research that emphasizes the importance of
    reducing anxiety in language learning environments (Woodrow, [2006](https://arxiv.org/html/2410.02406v1#bib.bib77)),
    especially for adult immigrant learners who often experience heightened pressure
    in social situations (Adjagbodjou and Kaufman, [2024](https://arxiv.org/html/2410.02406v1#bib.bib2)).
    ELLMA-T’s perceived approachability and the fact that it is always available and
    accessible further contributed to this reduced anxiety, positioning the system
    as a valuable tool for continuous language practice without the social constraints
    typically associated with human interactions.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如[5.2.2](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS2 "5.2.2\. 一对一互动缓解口语焦虑，群体互动支持共享学习体验
    ‣ 5.2\. 社交虚拟现实中的语言学习 ‣ 5\. 研究发现 ‣ ELLMA-T：支持社交虚拟现实中英语语言学习的具身LLM代理")节中的发现所示，ELLMA-T展示了减轻参与者口语焦虑的潜力（P8），特别是在一对一互动中。当参与者在虚拟现实环境中与ELLMA-T互动时，由于有虚拟化身的保护，并且免除了通常与人际互动相关的社交压力（这些压力在人与人工智能的互动中并不一定适用），他们感到更加轻松（参见[5.1.4](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS4
    "5.1.4\. 摆脱不适用于人工智能的社交规范 ‣ 5.1\. 代理感知及其在社交虚拟现实中的作用 ‣ 5\. 研究发现 ‣ ELLMA-T：支持社交虚拟现实中英语语言学习的具身LLM代理")节）。与人工智能互动的预期，而非与人类互动，天然地减少了通常与使用外语时的压力相关联的焦虑。这一发现支持了ELLMA-T在语言学习中的有效性，这与现有研究相一致，现有研究强调在语言学习环境中减少焦虑的重要性（Woodrow,
    [2006](https://arxiv.org/html/2410.02406v1#bib.bib77)），尤其是对于那些在社交场合中常常感受到更大压力的成人移民学习者（Adjagbodjou和Kaufman,
    [2024](https://arxiv.org/html/2410.02406v1#bib.bib2)）。ELLMA-T的亲和力以及它始终可用和易于接触的特点，进一步有助于减轻这种焦虑，使该系统成为一个无须面对通常与人类互动相关社交限制的持续语言练习的重要工具。
- en: 6.2\. Situated Language Learning in Social VR
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 社交虚拟现实中的情境语言学习
- en: 'The situated learning theory explains how learning is most effective when it
    occurs within the relevant context(Lave and Wenger, [1991](https://arxiv.org/html/2410.02406v1#bib.bib44);
    Brown et al., [1989](https://arxiv.org/html/2410.02406v1#bib.bib8)), our findings
    in Section [5.2](https://arxiv.org/html/2410.02406v1#S5.SS2 "5.2\. Language Learning
    in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR") correspond to this theory. Participants expect
    to have the VR scene, and characters with different personas in VR environment
    corresponding to the role-play conversations to have a more realistic experience
    of a potential real-life situation in which use of learned language may be important.
    In addition to the advantages the VR environment provides to learning, the opportunities
    with Social VR are also discussed in the following sections.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 情境学习理论解释了学习在相关情境中进行时最为有效（Lave和Wenger, [1991](https://arxiv.org/html/2410.02406v1#bib.bib44);
    Brown等, [1989](https://arxiv.org/html/2410.02406v1#bib.bib8)），我们在[5.2](https://arxiv.org/html/2410.02406v1#S5.SS2
    "5.2\. 社交虚拟现实中的语言学习 ‣ 5\. 研究发现 ‣ ELLMA-T：支持社交虚拟现实中英语语言学习的具身LLM代理")节中的发现与这一理论相符。参与者期望虚拟现实场景及其中具有不同个性的角色与角色扮演对话相匹配，从而更真实地体验可能出现的、在实际生活中可能需要使用所学语言的情境。除了虚拟现实环境为学习提供的优势外，社交虚拟现实中的机会也在以下几节中进行了讨论。
- en: 6.2.1\. Flexibility in Interaction Modes
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1\. 互动模式的灵活性
- en: 'The findings in Section [5.2.2](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS2
    "5.2.2\. One-on-One interactions alleviate Speaking Anxiety, Group Interactions
    support Shared Learning Experience ‣ 5.2\. Language Learning in Social VR ‣ 5\.
    Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR") suggest that a notable advantage of using social VR is the possibilities
    it offers in switching between private interactions with the agent and agent-facilitated
    group interactions. Participants appreciated the ability to engage in one-on-one
    sessions with ELLMA-T, which helped reduce speaking anxiety (see Section [5.1.4](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS4
    "5.1.4\. Freeing Interactions of Social Norms that Do Not Apply to AI ‣ 5.1\.
    Agent Perception and its Role in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR")) and allowed
    for personalized feedback. At the same time, VRChat, as a social platform, also
    has the potential to meet learners’ social needs and foster a sense of community
    and group affirmation as discussed in Section [6.2](https://arxiv.org/html/2410.02406v1#S6.SS2
    "6.2\. Situated Language Learning in Social VR ‣ 6\. Discussion ‣ ELLMA-T: an
    Embodied LLM-agent for Supporting English Language Learning in Social VR"). In
    addition, the option to transition to group interactions facilitated by the agent
    introduces a dynamic that is difficult to replicate in traditional language learning
    settings. Previous research has shown promising results for human teacher-facilitated
    collaborative language learning in VR between human students (Jackson and Fagan,
    [2000](https://arxiv.org/html/2410.02406v1#bib.bib32); Peterson, [2012](https://arxiv.org/html/2410.02406v1#bib.bib58);
    Cantone et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib11)). With ELLMA-T
    potentially facilitating similar group interactions, it provides a promising direction
    for further exploration.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在[5.2.2节](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS2 "5.2.2\. 一对一互动缓解口语焦虑，群体互动支持共享学习体验
    ‣ 5.2\. 社交虚拟现实中的语言学习 ‣ 5\. 发现 ‣ ELLMA-T：一种支持社交虚拟现实中英语学习的具身大语言模型代理")中的研究发现表明，使用社交虚拟现实的一个显著优势是它提供了在与代理的私人互动和代理促进的群体互动之间切换的可能性。参与者非常赞赏与ELLMA-T进行一对一会话的能力，这有助于减少口语焦虑（见[5.1.4节](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS4
    "5.1.4\. 摆脱不适用于AI的社会规范的互动 ‣ 5.1\. 代理感知及其在社交虚拟现实中的作用 ‣ 5\. 发现 ‣ ELLMA-T：一种支持社交虚拟现实中英语学习的具身大语言模型代理")），并允许提供个性化反馈。与此同时，作为社交平台的VRChat也有潜力满足学习者的社交需求，并促进社区感和群体认同感，如[6.2节](https://arxiv.org/html/2410.02406v1#S6.SS2
    "6.2\. 在社交虚拟现实中进行语言学习 ‣ 6\. 讨论 ‣ ELLMA-T：一种支持社交虚拟现实中英语学习的具身大语言模型代理")所讨论的那样。此外，过渡到由代理促进的群体互动的选项，引入了一种在传统语言学习环境中难以复制的动态。先前的研究显示，VR中由人类教师促进的协作语言学习在人类学生之间取得了可喜的成果（Jackson
    和 Fagan, [2000](https://arxiv.org/html/2410.02406v1#bib.bib32); Peterson, [2012](https://arxiv.org/html/2410.02406v1#bib.bib58);
    Cantone 等人, [2023](https://arxiv.org/html/2410.02406v1#bib.bib11)）。随着ELLMA-T可能促进类似的群体互动，它为进一步探索提供了一个有前景的方向。
- en: 6.2.2\. Trade-offs Between VR headsets and 2D Desktop Interfaces
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2\. VR头戴设备与二维桌面界面之间的权衡
- en: 'VRChat provides users with the flexibility to interact with the platform through
    VR headsets or a 2D desktop interface. While the immersive qualities of VR provide
    significant benefits, our findings in Section [5.4.1](https://arxiv.org/html/2410.02406v1#S5.SS4.SSS1
    "5.4.1\. Likelihood of Continued Usage ‣ 5.4\. Interest in Continued Usage ‣ 5\.
    Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR") also highlight the trade-offs associated with prolonged use of
    VR headsets. As noted in previous research, the availability of the technology,
    cognitive load and fatigue associated with VR are significant barriers to widespread
    use (Petersen et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib57)).
    This issue was echoed by participants in our study, with some participants expressing
    a preference for interacting with a 2D desktop agent due to the convenience and
    reduced physical strain. This suggests that while VR offers powerful immersive
    experiences, a more accessible 2D interface could broaden the system’s appeal
    and usability, especially in longitudinal studies where extended use is necessary.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'VRChat为用户提供了通过VR头盔或2D桌面界面与平台互动的灵活性。虽然VR的沉浸式特点提供了显著的好处，但我们在第[5.4.1](https://arxiv.org/html/2410.02406v1#S5.SS4.SSS1
    "5.4.1\. Likelihood of Continued Usage ‣ 5.4\. Interest in Continued Usage ‣ 5\.
    Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR")节中的发现也突出了长期使用VR头盔所带来的权衡。如以往研究所指出的，技术的可得性、认知负担以及与VR相关的疲劳是广泛使用的主要障碍（Petersen等人，[2021](https://arxiv.org/html/2410.02406v1#bib.bib57)）。我们的研究中的参与者也反映了这一问题，一些参与者表示，由于便捷性和减少身体压力，他们更倾向于与2D桌面代理进行互动。这表明，尽管VR提供了强大的沉浸式体验，但更易访问的2D界面可能会拓宽系统的吸引力和可用性，尤其是在需要长期使用的纵向研究中。'
- en: '6.3\. LLMs for Language Learning: Performance and Potential'
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3\. LLM在语言学习中的应用：表现与潜力
- en: 'Findings from Section [5.3](https://arxiv.org/html/2410.02406v1#S5.SS3 "5.3\.
    Task Design and Perceptions of LLM’s Efficacy in Language Learning Tasks ‣ 5\.
    Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR") suggest that ELLMA-T, powered by GPT-4, performed well on current
    teaching tasks, particularly in generating role-play conversations and providing
    feedback. This aligns with recent research (Caines et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib10)),
    which confirms the LLM’s capability in learning material generation and assessment.
    The ability of LLMs to create flexible, context-sensitive content presents significant
    advantages over previous scripted or NLP-assisted systems, which often suffered
    from communication breakdowns due to technical limitations (Zhang et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib84)).
    However, present limitations of LLMs such as latency or lack of precise turn-taking
    logic can lead to breakdowns in communication flow that may impact users’ motivation
    to use the system for prolonged time (see Section [5.4.2](https://arxiv.org/html/2410.02406v1#S5.SS4.SSS2
    "5.4.2\. Factors Negatively Impacting Continued Usage ‣ 5.4\. Interest in Continued
    Usage ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language
    Learning in Social VR")).'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '来自第[5.3](https://arxiv.org/html/2410.02406v1#S5.SS3 "5.3\. Task Design and
    Perceptions of LLM’s Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T:
    an Embodied LLM-agent for Supporting English Language Learning in Social VR")节的发现表明，由GPT-4驱动的ELLMA-T在当前的教学任务中表现良好，特别是在生成角色扮演对话和提供反馈方面。这与最近的研究（Caines等人，[2023](https://arxiv.org/html/2410.02406v1#bib.bib10)）一致，研究确认了LLM在学习材料生成和评估方面的能力。LLM能够创建灵活且具有上下文敏感性的内容，这相比于以往的脚本化或基于NLP的系统具有显著优势，因为后者常因技术限制而导致沟通中断（Zhang等人，[2021](https://arxiv.org/html/2410.02406v1#bib.bib84)）。然而，LLM目前的局限性，如延迟或缺乏精确的轮次控制逻辑，可能会导致沟通流的中断，从而影响用户在长时间使用系统时的动力（请参见第[5.4.2](https://arxiv.org/html/2410.02406v1#S5.SS4.SSS2
    "5.4.2\. Factors Negatively Impacting Continued Usage ‣ 5.4\. Interest in Continued
    Usage ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language
    Learning in Social VR")节）。'
- en: 6.3.1\. ELLMA-T as a Personalized and Creative Tutor
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1\. ELLMA-T作为个性化和创造性的导师
- en: 'The flexibility and creativity LLM brings to role-play conversations are central
    to the human-like qualities of ELLMA-T as discussed in Section [5.3.3](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS3
    "5.3.3\. Role Play Conversation Content ‣ 5.3\. Task Design and Perceptions of
    LLM’s Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR"). LLMs can also
    generate dynamic and coherent responses (Yang et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib80))
    that can adapt to the learner’s input in real-time (Caines et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib10)).
    However, to fully exploit the potential of LLMs for different language learning
    tasks, more intricate prompting and contextual understanding are necessary. Our
    findings in Sections [5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3 "5.1.3\.
    Perceptions of Agent Tone, Appearance, and Behaviour ‣ 5.1\. Agent Perception
    and its Role in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for
    Supporting English Language Learning in Social VR") and [5.3.4](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS4
    "5.3.4\. Feedback Effectiveness ‣ 5.3\. Task Design and Perceptions of LLM’s Efficacy
    in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for
    Supporting English Language Learning in Social VR") support prior work that indicates
    that the quality of the LLM’s output, particularly the wording of the output,
    should adapt to the context in which it is used (Barambones et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib6)).
    We hypothesize that improving the LLM’s performance will require: 1) a better
    understanding of conversational context, for instance, the agent’s role and the
    expected tone; 2) developing more sophisticated techniques to generate appropriate
    responses in various contexts. Additionally, future work can explore how text
    responses can be effectively mapped to corresponding voice tones, facial expressions,
    and body movements under different contexts.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLM 带来的灵活性和创造力是 ELLMA-T 具有人类特质的核心，如第 [5.3.3](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS3
    "5.3.3\. 角色扮演对话内容 ‣ 5.3\. 任务设计与 LLM 在语言学习任务中的效能感知 ‣ 5\. 研究发现 ‣ ELLMA-T: 支持社交 VR
    中英语学习的具身 LLM 智能体") 节所讨论的那样。LLM 还能够生成动态且连贯的回应（杨等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib80)），能够实时适应学习者的输入（Caines
    等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib10)）。然而，要充分发挥 LLM 在不同语言学习任务中的潜力，需要更精细的提示和上下文理解。我们在第
    [5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3 "5.1.3\. 智能体语气、外观和行为的感知
    ‣ 5.1\. 智能体感知及其在社交 VR 中的作用 ‣ 5\. 研究发现 ‣ ELLMA-T: 支持社交 VR 中英语学习的具身 LLM 智能体") 和
    [5.3.4](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS4 "5.3.4\. 反馈效果 ‣ 5.3\.
    任务设计与 LLM 在语言学习任务中的效能感知 ‣ 5\. 研究发现 ‣ ELLMA-T: 支持社交 VR 中英语学习的具身 LLM 智能体") 节中的发现支持了先前的研究，表明
    LLM 输出的质量，特别是输出的措辞，应该根据使用的上下文进行调整（Barambones 等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib6)）。我们假设，要提高
    LLM 的性能，需要：1) 更好地理解对话的上下文，例如，智能体的角色和预期语气；2) 开发更复杂的技术，在各种上下文中生成适当的回应。此外，未来的工作可以探索如何在不同上下文下，将文本回应有效地映射到相应的语音语调、面部表情和身体动作上。'
- en: 6.3.2\. Level Assessment and Difficulty Level Adjustment
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2\. 等级评估与难度级别调整
- en: 'The results from Section [5.3.2](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS2
    "5.3.2\. Assessing the Learner’s Language Ability ‣ 5.3\. Task Design and Perceptions
    of LLM’s Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR") indicates that
    the GPT-4 assessment of participants’ language level was overall accurate and
    in agreement with the findings by (Caines et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib10)).
    However, the assessment format could be better designed with clearer instructions
    and a more flexible format given the feedback from participants who do not want
    to follow a fixed agenda. Following the assessment, the findings in Section [5.3.2](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS2
    "5.3.2\. Assessing the Learner’s Language Ability ‣ 5.3\. Task Design and Perceptions
    of LLM’s Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR") infer that GPT-4
    likely adjusted the language difficulty level for subsequent conversations based
    on the results. This inference is supported by feedback from P3 and P8, who were
    assessed at a high proficiency level (C1) and mentioned that the vocabulary used
    in their subsequent conversations might be too difficult for beginners. This suggests
    that the system correctly matched the difficulty level to their advanced assessment.
    However, we have not explicitly assessed how well GPT-4 used in ELLMA-T was adjusting
    task difficulty based on the previous assessment of the learner’s language proficiency.
    Given that no other participants raised concerns about the difficulty level, it
    is possible that the adjustments were suitable for their assessed levels, but
    without a more comprehensive assessment, this remains speculative. Future studies
    can include specific questions about participants’ perceived difficulty level
    and linguistic metrics, such as word frequency, sentence length, and syntactic
    complexity, to better understand how well LLMs can tailor language task difficulty
    to individual needs.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 第[5.3.2](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS2 "5.3.2\. 评估学习者的语言能力
    ‣ 5.3\. 任务设计与LLM在语言学习任务中的有效性感知 ‣ 5\. 研究结果 ‣ ELLMA-T：支持社交虚拟现实中英语学习的具身LLM代理")节的结果表明，GPT-4对参与者语言水平的评估总体准确，并与(Caines等人，[2023](https://arxiv.org/html/2410.02406v1#bib.bib10))的研究结果一致。然而，评估格式可以通过更清晰的说明和更灵活的形式进行改进，因为有些参与者反馈他们不想按照固定议程进行评估。根据评估结果，第[5.3.2](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS2
    "5.3.2\. 评估学习者的语言能力 ‣ 5.3\. 任务设计与LLM在语言学习任务中的有效性感知 ‣ 5\. 研究结果 ‣ ELLMA-T：支持社交虚拟现实中英语学习的具身LLM代理")节的发现推测，GPT-4可能根据评估结果调整了后续对话的语言难度。这一推测得到了P3和P8的反馈支持，他们在评估时的语言水平较高（C1），并提到后续对话中使用的词汇对于初学者来说可能过于困难。这表明系统正确地根据他们的高级评估匹配了难度。然而，我们并未明确评估GPT-4在ELLMA-T中的任务难度调整是否依据之前对学习者语言能力的评估进行调整。鉴于没有其他参与者对难度水平提出疑虑，可能这些调整对于他们的评估水平是合适的，但由于缺乏更全面的评估，这仍然是推测性的。未来的研究可以包括关于参与者感知的难度水平以及语言学度量（如词频、句子长度和句法复杂度）的问题，以更好地理解LLM如何根据个人需求调整语言任务的难度。
- en: 6.3.3\. Opportunities and Challenges of Designing LLM-based ECAs for Informal
    Spoken English Learning in Social VR
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '6.3.3\. 在社交虚拟现实中为非正式英语口语学习设计基于LLM的ECA的机会与挑战  '
- en: '(Adjagbodjou and Kaufman, [2024](https://arxiv.org/html/2410.02406v1#bib.bib2))
    emphasized the importance of informal language practice as distinct from formal
    academic learning, highlighting a gap in tools designed specifically for this
    context. Our study echoes this view, with findings from Section [5.3.1](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS1
    "5.3.1\. Task Design Relevance ‣ 5.3\. Task Design and Perceptions of LLM’s Efficacy
    in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for
    Supporting English Language Learning in Social VR") showing that participants
    valued the opportunity to practice speaking English in real-life, informal settings.
    Despite being in an English-speaking environment, participants in our study reported
    challenges such as a lack of feedback and opportunities for language improvement
    in Section [5.3.1](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS1 "5.3.1\. Task
    Design Relevance ‣ 5.3\. Task Design and Perceptions of LLM’s Efficacy in Language
    Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting
    English Language Learning in Social VR"), underscoring the need for effective
    feedback mechanisms. Common challenges faced by EFL learners, such as anxiety
    and the need for support to increase WTC (Ayedoun et al., [2019](https://arxiv.org/html/2410.02406v1#bib.bib4)),
    were partially addressed by our system (see Sections [5.2.2](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS2
    "5.2.2\. One-on-One interactions alleviate Speaking Anxiety, Group Interactions
    support Shared Learning Experience ‣ 5.2\. Language Learning in Social VR ‣ 5\.
    Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR"), [5.1.4](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS4 "5.1.4\.
    Freeing Interactions of Social Norms that Do Not Apply to AI ‣ 5.1\. Agent Perception
    and its Role in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for
    Supporting English Language Learning in Social VR"), and [5.3.5](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS5
    "5.3.5\. Scaffolding Effectiveness ‣ 5.3\. Task Design and Perceptions of LLM’s
    Efficacy in Language Learning Tasks ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent
    for Supporting English Language Learning in Social VR")). However, the challenge
    of designing effective verbal and non-verbal cues, as discussed in Section [6.1](https://arxiv.org/html/2410.02406v1#S6.SS1
    "6.1\. User Experience of ELLMA-T for Supporting English Language Learning ‣ 6\.
    Discussion ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning
    in Social VR"), poses challenges in ensuring the system can accurately interpret
    and respond to users’ intentions. Additionally, communication obstacles common
    among EFL learners — such as accents, grammar mistakes, incorrect expressions,
    low speaking volume due to lack of confidence, and intermittent speaking due to
    unfamiliarity with the language (Adjagbodjou and Kaufman, [2024](https://arxiv.org/html/2410.02406v1#bib.bib2))
    — further complicate the system’s ability to process and respond effectively.
    These issues are more challenging for an audio detection system to interpret compared
    to inputs from native speakers, highlighting the need for more advanced solutions
    tailored to the specific needs of EFL learners.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: (Adjagbodjou 和 Kaufman, [2024](https://arxiv.org/html/2410.02406v1#bib.bib2))
    强调了非正式语言实践的重要性，这与正式的学术学习有所不同，指出了针对这一背景专门设计的工具的缺口。我们的研究呼应了这一观点，在[5.3.1节](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS1
    "5.3.1\. 任务设计的相关性 ‣ 5.3\. 任务设计与大语言模型在语言学习任务中的效能感知 ‣ 5\. 研究结果 ‣ ELLMA-T：支持英语语言学习的具身大语言模型代理")的研究结果表明，参与者重视在真实生活中的非正式环境中练习英语口语的机会。尽管身处英语环境中，我们研究中的参与者仍报告了缺乏反馈和语言提高机会等挑战，在[5.3.1节](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS1
    "5.3.1\. 任务设计的相关性 ‣ 5.3\. 任务设计与大语言模型在语言学习任务中的效能感知 ‣ 5\. 研究结果 ‣ ELLMA-T：支持英语语言学习的具身大语言模型代理")中也有提到，这突显了有效反馈机制的需求。英语作为外语（EFL）学习者常遇到的挑战，如焦虑和增加WTC（愿意交际）的支持需求（Ayedoun等人，[2019](https://arxiv.org/html/2410.02406v1#bib.bib4)），在我们的系统中得到了部分解决（参见[5.2.2节](https://arxiv.org/html/2410.02406v1#S5.SS2.SSS2
    "5.2.2\. 一对一互动缓解口语焦虑，小组互动支持共享学习经验 ‣ 5.2\. 社交虚拟现实中的语言学习 ‣ 5\. 研究结果 ‣ ELLMA-T：支持英语语言学习的具身大语言模型代理")，[5.1.4节](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS4
    "5.1.4\. 摆脱不适用于人工智能的社交规范的互动 ‣ 5.1\. 代理感知及其在社交虚拟现实中的角色 ‣ 5\. 研究结果 ‣ ELLMA-T：支持英语语言学习的具身大语言模型代理")
    和[5.3.5节](https://arxiv.org/html/2410.02406v1#S5.SS3.SSS5 "5.3.5\. 支架效果 ‣ 5.3\.
    任务设计与大语言模型在语言学习任务中的效能感知 ‣ 5\. 研究结果 ‣ ELLMA-T：支持英语语言学习的具身大语言模型代理")）。然而，在[6.1节](https://arxiv.org/html/2410.02406v1#S6.SS1
    "6.1\. ELLMA-T用户体验：支持英语语言学习 ‣ 6\. 讨论 ‣ ELLMA-T：支持英语语言学习的具身大语言模型代理")中讨论的设计有效的言语和非言语提示的挑战，仍然在确保系统能够准确解读并回应用户意图方面带来了困难。此外，英语作为外语学习者常见的沟通障碍——如口音、语法错误、不正确的表达、由于缺乏自信而导致的低语音音量，以及由于对语言不熟悉而导致的间歇性发言（Adjagbodjou
    和 Kaufman, [2024](https://arxiv.org/html/2410.02406v1#bib.bib2)）——进一步复杂化了系统有效处理和响应的能力。与母语使用者输入相比，这些问题对于音频检测系统的解读更具挑战性，突显了针对英语作为外语学习者特定需求量身定制的更先进解决方案的必要性。
- en: 7\. Design Implications
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7. 设计启示
- en: We present five design implications for LLM-based ECAs to facilitate spoken
    English learning in Social VR based on our key findings.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基于主要发现，提出了五个设计启示，旨在通过LLM驱动的ECA促进社交虚拟现实中的英语口语学习。
- en: 7.1\. Promoting Personalized and Adaptive Learning through Design
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1. 通过设计促进个性化和自适应学习
- en: 'Design Implication 1: Design LLM agents with contextual and cultural relevance
    in the adaptive learning experience based on user information, user preference,
    and learning history to support personalized and adaptive learning.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 设计启示 1：根据用户信息、用户偏好和学习历史，在自适应学习体验中设计具有情境和文化相关性的LLM代理，以支持个性化和自适应学习。
- en: 'The analysis in Sections [5.1](https://arxiv.org/html/2410.02406v1#S5.SS1 "5.1\.
    Agent Perception and its Role in Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied
    LLM-agent for Supporting English Language Learning in Social VR") and [6.3](https://arxiv.org/html/2410.02406v1#S6.SS3
    "6.3\. LLMs for Language Learning: Performance and Potential ‣ 6\. Discussion
    ‣ ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning in Social
    VR") highlight the importance of adaptive learning experiences in language learning
    tools. Participants wanted responses tailored to their proficiency levels, challenges,
    and progress. LLMs have the potential to suggest learning materials based on user
    information, user preference, and learning history (Darsih, [2018](https://arxiv.org/html/2410.02406v1#bib.bib21)).
    However, this requires the agent to have a more sophisticated memory design and
    advanced reasoning ability. Emerging studies have focused on developing different
    memory mechanisms for increasing context-awareness and adaptation to user behaviour
    patterns. For example, a human-like memory architecture for LLM-based conversational
    agents enables autonomous memory recall and dynamic memory consolidation to improve
    response generation (Hou et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib29)).
    Additionally, the Long-term Dialogue Agent framework can enable more personalized
    and contextually relevant responses over extended interactions (Li et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib47)).
    A similar advanced memory design can be applied with an agent in the context of
    language learning. An agent with such capabilities could adapt its interactions
    based on prior user behavior and progress, and dynamically adjust content delivery
    according to the learner’s needs. In addition, based on the findings in Section
    [5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3 "5.1.3\. Perceptions of
    Agent Tone, Appearance, and Behaviour ‣ 5.1\. Agent Perception and its Role in
    Social VR ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent for Supporting English
    Language Learning in Social VR") and criteria from Adjagbodjou and Kaufman ([2024](https://arxiv.org/html/2410.02406v1#bib.bib2)),
    we suggest the value of cultural references and contextual relevance in the adaptive
    learning experience. For instance, an agent could adjust its dialogue to reflect
    the cultural nuances of the learner’s cultural background, and new environment,
    offering more meaningful and relatable interactions in the context of language
    learning.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 第[5.1](https://arxiv.org/html/2410.02406v1#S5.SS1 "5.1\. 智能体感知及其在社交虚拟现实中的作用
    ‣ 5\. 研究发现 ‣ ELLMA-T：一种支持社交虚拟现实中英语语言学习的具身LLM智能体")节和[6.3](https://arxiv.org/html/2410.02406v1#S6.SS3
    "6.3\. 基于LLM的语言学习：性能与潜力 ‣ 6\. 讨论 ‣ ELLMA-T：一种支持社交虚拟现实中英语语言学习的具身LLM智能体")节的分析强调了语言学习工具中适应性学习体验的重要性。参与者希望回应能够根据他们的熟练程度、挑战和进展量身定制。LLM有潜力根据用户信息、用户偏好和学习历史（Darsih，[2018](https://arxiv.org/html/2410.02406v1#bib.bib21)）推荐学习材料。然而，这要求智能体具备更复杂的记忆设计和更先进的推理能力。新兴研究集中在开发不同的记忆机制，以增强情境意识和适应用户行为模式。例如，基于LLM的对话智能体采用类人记忆架构，使其能够自主回忆记忆并动态整合记忆，从而改进响应生成（Hou等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib29)）。此外，长期对话智能体框架可以使智能体在长期交互中提供更个性化和情境相关的回应（Li等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib47)）。类似的先进记忆设计可以应用于语言学习的智能体中。具备此类能力的智能体可以根据先前的用户行为和进展调整其互动方式，并根据学习者的需求动态调整内容传递。此外，基于[5.1.3](https://arxiv.org/html/2410.02406v1#S5.SS1.SSS3
    "5.1.3\. 智能体语气、外貌和行为的感知 ‣ 5.1\. 智能体感知及其在社交虚拟现实中的作用 ‣ 5\. 研究发现 ‣ ELLMA-T：一种支持社交虚拟现实中英语语言学习的具身LLM智能体")节的研究结果及Adjagbodjou和Kaufman（[2024](https://arxiv.org/html/2410.02406v1#bib.bib2)）的标准，我们建议在适应性学习体验中注重文化参考和情境相关性。例如，智能体可以调整其对话内容，反映学习者文化背景和新环境中的文化差异，从而在语言学习的情境中提供更具意义和更易共鸣的互动。
- en: 7.2\. Enhance Agent-Learner Connection
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 增强智能体与学习者之间的联系
- en: 'Design Implication 2: Incorporate user-preferred personas, tone, voice, appearance,
    and body movement in LLM-based agents to strengthen emotional connections and
    support language learning.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 设计启示 2：在基于大语言模型（LLM）的智能体中融入用户偏好的角色设定、语气、声音、外貌和肢体动作，以增强情感连接并支持语言学习。
- en: Participants in our study exhibited distinct preferences for the agent’s persona,
    tone of response, voice inflections, appearance, and body movement, which may
    potentially affect their learning experience with the agent. While previous research
    has mixed opinions on the impact of an agent’s non-verbal features on learning
    outcomes (Petersen et al., [2021](https://arxiv.org/html/2410.02406v1#bib.bib57);
    Sonlu et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib67)), offering
    customizable options for users may be a beneficial approach.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究中的参与者展示了对代理的个性、回应语气、语音语调、外观和肢体动作的不同偏好，这些可能会影响他们与代理的学习体验。尽管以往研究对代理的非言语特征对学习成果的影响存在不同看法（Petersen
    等人，[2021](https://arxiv.org/html/2410.02406v1#bib.bib57); Sonlu 等人，[2024](https://arxiv.org/html/2410.02406v1#bib.bib67)），为用户提供可定制的选项可能是一个有益的方法。
- en: 'Design Implication 3: Integrate advanced systems to effectively use verbal
    and non-verbal cues to provide emotional support to the learners.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 设计启示 3：整合先进的系统，有效利用言语和非言语线索，为学习者提供情感支持。
- en: Emotional support requires sophisticated techniques to accurately interpret
    learners’ intentions and offer contextually appropriate support (Dinçer et al.,
    [2013](https://arxiv.org/html/2410.02406v1#bib.bib23)). For example, the agent
    should be able to distinguish between pauses that indicate the learner is thinking
    and those that suggest the learner is struggling to respond, adapting its behaviour
    accordingly by offering encouragement or rephrasing questions. Using machine learning
    techniques to detect user emotions such as silence, hesitation, or frustration
    could potentially enable the agent to deliver timely and suitable emotional support.
    For example, a recent study by (Siyan et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib66))
    has demonstrated the potential of using machine learning and prompt engineering
    to detect anxiety from students’ voices, allowing the agent to offer adaptive,
    empathetic responses to enhance language learning.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 情感支持需要复杂的技术来准确解读学习者的意图，并提供符合情境的支持（Dinçer 等人，[2013](https://arxiv.org/html/2410.02406v1#bib.bib23)）。例如，代理应该能够区分表示学习者在思考的停顿和表示学习者在努力回应的停顿，并根据情况调整行为，通过提供鼓励或重新措辞问题来适应。使用机器学习技术来检测用户情绪，例如沉默、犹豫或挫折感，可能使代理能够及时提供适当的情感支持。例如，最近的研究（Siyan
    等人，[2024](https://arxiv.org/html/2410.02406v1#bib.bib66)）展示了使用机器学习和提示工程检测学生声音中的焦虑的潜力，从而使代理能够提供适应性、富有同理心的回应，以增强语言学习。
- en: 7.3\. Cultivate Long-Term Engagement and Continued Use
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3. 培养长期参与和持续使用
- en: 'Design Implication 4: Design LLM-based agents in social VR to facilitate long-term
    language learning essential for improving fluency.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 设计启示 4：设计基于大语言模型（LLM）的社交虚拟现实（VR）代理，促进长期语言学习，这是提高流利度的关键。
- en: 'Based on the findings in Section [5.4](https://arxiv.org/html/2410.02406v1#S5.SS4
    "5.4\. Interest in Continued Usage ‣ 5\. Findings ‣ ELLMA-T: an Embodied LLM-agent
    for Supporting English Language Learning in Social VR"), participants’ willingness
    to continue using the system regularly suggests that LLM-based agents in VR hold
    significant potential for supporting long-term language learning. However, this
    potential is contingent on the system’s ability to adapt to the learner’s progress,
    sustain engagement, and mitigate issues like conversation flow breakdowns and
    VR-related usage fatigues. For example, incorporating preferred personality traits
    or non-verbal cues into the agent can potentially increase engagement (Sonlu et al.,
    [2024](https://arxiv.org/html/2410.02406v1#bib.bib67)). Additionally, gamification
    is a well-established approach to enhance engagement (Koulouris et al., [2020](https://arxiv.org/html/2410.02406v1#bib.bib41);
    Cheng et al., [2017](https://arxiv.org/html/2410.02406v1#bib.bib15); Hsu et al.,
    [2023](https://arxiv.org/html/2410.02406v1#bib.bib30); Seow, [2023](https://arxiv.org/html/2410.02406v1#bib.bib65)).
    Most recently, the use of LLM-agents as peers in VR classrooms has been shown
    to promote engagement and classroom participation (Liu et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib50)).'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[5.4节](https://arxiv.org/html/2410.02406v1#S5.SS4 "5.4\. 对持续使用的兴趣 ‣ 5\. 研究结果
    ‣ ELLMA-T：支持社交VR中英语语言学习的体现化LLM代理")中的发现，参与者愿意定期继续使用该系统，表明基于LLM的代理在虚拟现实中具有支持长期语言学习的巨大潜力。然而，这一潜力依赖于系统能否适应学习者的进展、维持参与度并减少会话流程中断和VR使用疲劳等问题。例如，将偏好的个性特征或非语言提示融入代理中，可能会增加参与感（Sonlu
    et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib67)）。此外，游戏化是一种已经被广泛应用的增强参与感的有效方法（Koulouris
    et al., [2020](https://arxiv.org/html/2410.02406v1#bib.bib41); Cheng et al., [2017](https://arxiv.org/html/2410.02406v1#bib.bib15);
    Hsu et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib30); Seow, [2023](https://arxiv.org/html/2410.02406v1#bib.bib65)）。最近，LLM代理作为同伴在VR课堂中的应用已被证明有助于促进参与感和课堂互动（Liu
    et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib50)）。
- en: 'Design Implication 5: Use Open and Scalable VR Platforms for Sustained Long-Term
    Development and Studies.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 设计启示5：使用开放和可扩展的VR平台进行持续的长期开发和研究。
- en: Some existing studies have utilized commercially available open and scalable
    platforms like Second Life (Peterson, [2012](https://arxiv.org/html/2410.02406v1#bib.bib58))
    and Metaverse (Cantone et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib11)).
    We recommend using similar platforms for sustained development. In our study,
    we used VRChat, which provides the necessary flexibility for long-term development
    and broader public usage. Through VRChat’s OSC (VRChat, [2024a](https://arxiv.org/html/2410.02406v1#bib.bib71))
    and Unity (Unity, [2024](https://arxiv.org/html/2410.02406v1#bib.bib69)), we can
    develop customizable avatars and virtual worlds, control agent personas, voice
    tones, facial expressions, and body movements. This scalability ensures that the
    system can evolve and support long-term studies over time. However, the deployment
    of AI-agents in social VR platforms like VRChat is a grey area because some view
    them as modifications that are not supported or permitted according to the platform
    guidelines¹¹1[https://hello.vrchat.com/community-guidelines](https://hello.vrchat.com/community-guidelines).
    Thus, the use of AI-agents in social VR requires future considerations of how
    can we enable more open and scalable platforms for sustainable long-term development
    and exploration of AI-agents in social VR.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 一些现有研究已经利用了如Second Life（Peterson, [2012](https://arxiv.org/html/2410.02406v1#bib.bib58)）和Metaverse（Cantone
    et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib11)）等市面上可用的开放和可扩展平台。我们推荐使用类似的平台以促进可持续发展。在我们的研究中，我们使用了VRChat，它为长期开发和更广泛的公众使用提供了必要的灵活性。通过VRChat的OSC（VRChat,
    [2024a](https://arxiv.org/html/2410.02406v1#bib.bib71)）和Unity（Unity, [2024](https://arxiv.org/html/2410.02406v1#bib.bib69)），我们可以开发可定制的虚拟形象和虚拟世界，控制代理的个性、语音语调、面部表情和身体动作。这种可扩展性确保了该系统能够随着时间的推移不断发展，并支持长期研究。然而，在像VRChat这样的社交VR平台中部署AI代理仍是一个灰色地带，因为一些人认为这些代理是平台指南不支持或不允许的修改¹¹1[https://hello.vrchat.com/community-guidelines](https://hello.vrchat.com/community-guidelines)。因此，社交VR中使用AI代理需要未来考虑如何使我们能够为可持续的长期发展和AI代理在社交VR中的探索提供更开放和可扩展的平台。
- en: 8\. Limitations & Future Work
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 局限性与未来工作
- en: We discuss the limitations of our study and offer suggestions for future work
    on embodied LLM-based agents for language learning.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了本研究的局限性，并为未来基于体现化大型语言模型（LLM）的语言学习代理的研究提供了建议。
- en: 'Widening participation: The participant pool consisted primarily of graduate
    students with relatively high English proficiency, most of whom were from China.
    This demographic specificity limits the generalizability of our findings. Future
    research should investigate how these results apply to a more diverse demographic,
    including learners with lower language proficiency and varied cultural backgrounds.
    In addition, the system could be integrated into existing language learning programs
    offered by educational institutions and immigrant support organizations. This
    would allow for a more systematic and structured learning experience. Partnerships
    with these organizations could help in customizing the system further to address
    the specific needs of this user group.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 扩大参与范围：参与者群体主要由英语水平较高的研究生组成，大部分来自中国。这一群体的特定性限制了我们研究结果的普适性。未来的研究应探讨这些结果如何适用于更多样化的人群，包括语言水平较低和具有不同文化背景的学习者。此外，该系统还可以集成到教育机构和移民支持组织提供的现有语言学习项目中。这将允许更加系统化和结构化的学习体验。与这些组织的合作可以进一步帮助定制系统，以满足该用户群体的具体需求。
- en: Refining LLM Prompt Engineering for Language Learning Tasks LLM’s performance
    is very sensitive to prompts. Our current prompt engineering approach is largely
    based on trial and error due to lack of previous research on prompt engineering
    for language learning tasks, which may not be the most effective method for optimizing
    LLM performance. As more prompt frameworks become available (Khattab et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib38)),
    and the capabilities of LLMs continue to evolve, more efficient techniques for
    optimizing prompts are likely to become available. This could reduce the impact
    of specific prompt wording, shifting the focus towards refining the reasoning
    and task breakdown logic for complex, multi-turn conversations. Further research
    is necessary to develop more systematic workflows for enhancing LLM performance
    in these contexts.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 为语言学习任务优化LLM提示工程 LLM的表现对提示非常敏感。我们当前的提示工程方法在很大程度上依赖于试验和错误，因为缺乏针对语言学习任务的提示工程相关研究，这可能不是优化LLM表现的最有效方法。随着更多提示框架的出现（Khattab等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib38)），以及LLM能力的不断发展，可能会出现更加高效的提示优化技术。这可以减少特定提示措辞的影响，将焦点转向完善复杂、多轮对话中的推理和任务拆解逻辑。进一步的研究是必要的，以开发更加系统化的工作流程，从而在这些情境中提升LLM的表现。
- en: 'Exploring ECA Features for Language Learning in social VR Given the limited
    research on how the verbal and non-verbal features of ECAs affect learning outcomes
    in social VR (as discussed in Section [7.2](https://arxiv.org/html/2410.02406v1#S7.SS2
    "7.2\. Enhance Agent-Learner Connection ‣ 7\. Design Implications ‣ ELLMA-T: an
    Embodied LLM-agent for Supporting English Language Learning in Social VR"), particularly
    in the context of language learning, further exploration is necessary to better
    understand and optimize these interactions. Some initial work has been done on
    the effects of embodiment and personality traits in LLM-educational agents (Sonlu
    et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib67)) that could be implemented
    in an embodied LLM-agent for language learning. More research needs to be done
    to validate the findings in the context of language learning in social VR.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 探索社交VR中的ECA特征对语言学习的影响 鉴于关于ECAs（具身会话代理）在社交VR中如何影响语言学习成果的研究较为有限（如在第[7.2](https://arxiv.org/html/2410.02406v1#S7.SS2
    "7.2\. 增强代理与学习者的联系 ‣ 7\. 设计影响 ‣ ELLMA-T：一个用于支持社交VR中英语学习的具身LLM代理")节所讨论），特别是在语言学习的背景下，仍需要进一步的探索，以更好地理解并优化这些互动。关于具身性和个性特征在LLM教育代理中的影响（Sonlu等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib67)）已经开展了一些初步的研究，这些可以在具身LLM代理中应用于语言学习。需要进一步的研究来验证这些发现，特别是在社交VR中的语言学习环境中。
- en: Optimizing LLM Selection for Task-Specific Performance Achieving the design
    goals of ELLMA-T may require the use of different LLMs tailored to specific tasks.
    For conversational tasks, GPT-4o (OpenAI, [2024a](https://arxiv.org/html/2410.02406v1#bib.bib54))
    is recognized as the best-performing model, capable of understanding user sentiment
    and maintaining engaging dialogues (OpenAI, [2024a](https://arxiv.org/html/2410.02406v1#bib.bib54)).
    Other models may be more suitable for summarization and feedback due to their
    reliability (Caines et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib10)).
    Preliminary studies suggest that GPT-4o is the best-performing model we can use
    for both tasks in this study. In future work, we may use or combine different
    models to leverage the strengths of various models and optimize the system’s performance
    for future improvements.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 优化LLM选择以实现任务特定性能：实现ELLMA-T设计目标可能需要使用针对特定任务量身定制的不同LLM。对于对话任务，GPT-4o（OpenAI，[2024a](https://arxiv.org/html/2410.02406v1#bib.bib54)）被认为是表现最佳的模型，能够理解用户情感并保持引人入胜的对话（OpenAI，[2024a](https://arxiv.org/html/2410.02406v1#bib.bib54)）。其他模型可能更适合用于总结和反馈任务，因为它们更可靠（Caines等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib10)）。初步研究表明，GPT-4o是我们在本研究中用于两项任务的表现最佳模型。在未来的工作中，我们可能会使用或结合不同的模型，充分利用各模型的优势，并优化系统性能以促进未来的改进。
- en: 'Validating LLM Assessment of Language Proficiency: We recognize that the use
    of CEFR criteria (COE, [2024](https://arxiv.org/html/2410.02406v1#bib.bib19))
    to prompt the LLM in our system is not entirely precise and serves primarily as
    a rough guide for the LLM to adjust language difficulty for following dialogues.
    Whether the dialogue content generated by the LLM accurately reflects the intended
    difficulty level remains to be rigorously validated in future studies.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 验证大语言模型（LLM）对语言能力的评估：我们认识到，使用CEFR标准（COE，[2024](https://arxiv.org/html/2410.02406v1#bib.bib19)）来引导我们系统中的LLM并不是完全精确的，它主要作为一个粗略的指南，帮助LLM调整后续对话的语言难度。LLM生成的对话内容是否准确反映预期的难度级别，还需要在未来的研究中进行严格验证。
- en: Implementing Content Filters for LLM Responses Additionally, we did not implement
    a filtering layer to screen the LLM’s responses before delivery, which could lead
    to hallucinations or potentially harmful content. Although our initial tests showed
    that GPT-4 generally provided correct responses in grammar correction tasks, existing
    studies indicate that it may still produce inaccurate results or introduce stereotypes
    (Siyan et al., [2024](https://arxiv.org/html/2410.02406v1#bib.bib66)). Future
    work will include the evaluation of LLM responses by using the LLM Judge framework
    (Zheng et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib85)) or CoMPosT
    framework (Cheng et al., [2023](https://arxiv.org/html/2410.02406v1#bib.bib16))
    to detect stereotypes.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 实施LLM响应内容过滤：此外，我们没有在交付LLM响应之前实现一个过滤层来筛选其回应，这可能会导致幻觉或潜在有害内容。尽管我们的初步测试表明，GPT-4通常能在语法纠正任务中提供正确的回应，但现有研究表明，它仍然可能生成不准确的结果或引入刻板印象（Siyan等，[2024](https://arxiv.org/html/2410.02406v1#bib.bib66)）。未来的工作将包括使用LLM
    Judge框架（Zheng等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib85)）或CoMPosT框架（Cheng等，[2023](https://arxiv.org/html/2410.02406v1#bib.bib16)）来评估LLM回应，检测刻板印象。
- en: Evaluating Long-Term Educational Impact Lastly, this preliminary study involved
    only 15-minute interaction sessions, and we did not measure the system’s effectiveness
    in terms of actual language learning outcomes. To fully assess the educational
    impact of ELLMA-T, we plan to conduct longitudinal studies with longer learning
    sessions. In addition, these studies will provide a more comprehensive evaluation
    of user engagement over time and help identify key factors that contribute to
    sustained use and long-term language learning outcomes.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 评估长期教育影响：最后，本初步研究仅涉及了15分钟的互动会话，我们并没有评估该系统在实际语言学习结果方面的效果。为了全面评估ELLMA-T的教育影响，我们计划进行长期研究，开展更长时间的学习会话。此外，这些研究将提供关于用户参与度的更全面评估，并帮助识别有助于持续使用和长期语言学习成果的关键因素。
- en: 9\. Conclusion
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 结论
- en: With this study, we contribute to the growing body of research on ECAs and language
    learning by demonstrating the potential of combining situated learning principles
    with LLM-based agents in social VR environments. In particular, we contribute
    a system design for an LLM-agent for language learning (ELLMA-T), findings from
    a qualitative evaluation study (N=12), and design implications based on our findings.
    Our findings highlight the importance of integrating nuanced non-verbal cues and
    customizing agent interactions to address the diverse needs of adult language
    learners. The system also provides benefits such as reducing speaking anxiety
    and providing potential flexible learning modes. However, our study also highlighted
    areas for improvement including the need for more sophisticated emotional support,
    better handling of communication obstacles, and refined conversation flow to maintain
    long-term user engagement. These findings offer implications for future development,
    positioning embodied LLM-based agents as a promising tool for personalized and
    context-aware language learning.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究通过展示将情境学习原则与基于大型语言模型（LLM）的代理结合在社交虚拟现实（VR）环境中的潜力，贡献了日益增长的关于情境对话代理（ECA）和语言学习的研究领域。特别地，我们贡献了一个用于语言学习的LLM代理系统设计（ELLMA-T），来自定性评估研究的发现（N=12），以及基于我们发现的设计启示。我们的研究结果突显了整合细致的非语言线索和定制代理互动的重要性，以满足成人语言学习者的多样化需求。该系统还提供了诸如减少口语焦虑和提供潜在灵活学习模式等好处。然而，我们的研究也突显了需要改进的领域，包括对更复杂情感支持的需求、更好地处理交流障碍，以及优化对话流程以维持长期用户参与度。这些发现为未来发展提供了启示，将具身化LLM代理定位为个性化和情境感知语言学习的有前景工具。
- en: References
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Adjagbodjou and Kaufman (2024) Adinawa Adjagbodjou and Geoff Kaufman. 2024.
    Envisioning Support-Centered Technologies for Language Practice and Use: Needs
    and Design Opportunities for Immigrant English Language Learners (ELLs). In *Proceedings
    of the CHI Conference on Human Factors in Computing Systems* *(CHI ’24)*. Association
    for Computing Machinery, New York, NY, USA, 1–15. [https://doi.org/10.1145/3613904.3642236](https://doi.org/10.1145/3613904.3642236)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adjagbodjou 和 Kaufman（2024）Adinawa Adjagbodjou 和 Geoff Kaufman. 2024. 展望语言实践和使用的支持中心技术：移民英语语言学习者（ELLs）的需求和设计机会。在*CHI
    会议论文集*（*CHI ’24*）中。美国纽约计算机协会，1–15. [https://doi.org/10.1145/3613904.3642236](https://doi.org/10.1145/3613904.3642236)
- en: 'Atkinson et al. (2005) Robert K. Atkinson, Richard E. Mayer, and Mary Margaret
    Merrill. 2005. Fostering social agency in multimedia learning: Examining the impact
    of an animated agent’s voice. *Contemporary Educational Psychology* 30, 1 (Jan.
    2005), 117–139. [https://doi.org/10.1016/j.cedpsych.2004.07.001](https://doi.org/10.1016/j.cedpsych.2004.07.001)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atkinson 等人（2005）Robert K. Atkinson, Richard E. Mayer 和 Mary Margaret Merrill.
    2005. 在多媒体学习中促进社交代理：检验动画代理语音的影响。*现代教育心理学* 30, 1（2005年1月），117–139. [https://doi.org/10.1016/j.cedpsych.2004.07.001](https://doi.org/10.1016/j.cedpsych.2004.07.001)
- en: Ayedoun et al. (2019) Emmanuel Ayedoun, Yuki Hayashi, and Kazuhisa Seta. 2019.
    Adding Communicative and Affective Strategies to an Embodied Conversational Agent
    to Enhance Second Language Learners’ Willingness to Communicate. *International
    Journal of Artificial Intelligence in Education* 29, 1 (March 2019), 29–57. [https://doi.org/10.1007/s40593-018-0171-6](https://doi.org/10.1007/s40593-018-0171-6)
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ayedoun 等人（2019）Emmanuel Ayedoun, Yuki Hayashi 和 Kazuhisa Seta. 2019. 向具身对话代理中加入交际和情感策略，以增强第二语言学习者的交流意愿。*国际人工智能教育杂志*
    29, 1（2019年3月），29–57. [https://doi.org/10.1007/s40593-018-0171-6](https://doi.org/10.1007/s40593-018-0171-6)
- en: 'Aïm et al. (2016) Florence Aïm, Guillaume Lonjon, Didier Hannouche, and Rémy
    Nizard. 2016. Effectiveness of Virtual Reality Training in Orthopaedic Surgery.
    *Arthroscopy: The Journal of Arthroscopic & Related Surgery* 32, 1 (Jan. 2016),
    224–232. [https://doi.org/10.1016/j.arthro.2015.07.023](https://doi.org/10.1016/j.arthro.2015.07.023)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aïm 等人（2016）Florence Aïm, Guillaume Lonjon, Didier Hannouche 和 Rémy Nizard.
    2016. 虚拟现实训练在骨科手术中的有效性。*关节镜学：关节镜及相关手术期刊* 32, 1（2016年1月），224–232. [https://doi.org/10.1016/j.arthro.2015.07.023](https://doi.org/10.1016/j.arthro.2015.07.023)
- en: 'Barambones et al. (2024) Jorge Barambones, Carlos Moral, Angel de Antonio,
    Ricardo Imbert, Loïc Martínez-Normand, and Elena Villalba-Mora. 2024. ChatGPT
    for learning HCI techniques: A case study on interviews for personas. *IEEE Transactions
    on Learning Technologies* 17 (2024), 1486–1500. [https://doi.org/10.1109/TLT.2024.3386095](https://doi.org/10.1109/TLT.2024.3386095)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barambones 等人（2024）Jorge Barambones, Carlos Moral, Angel de Antonio, Ricardo
    Imbert, Loïc Martínez-Normand, 和 Elena Villalba-Mora. 2024. ChatGPT 在学习 HCI 技术中的应用：一个关于人物访谈的案例研究。*IEEE
    学习技术期刊* 17 (2024), 1486–1500. [https://doi.org/10.1109/TLT.2024.3386095](https://doi.org/10.1109/TLT.2024.3386095)
- en: 'Braun and Clarke (2006) Virginia Braun and Victoria Clarke. 2006. Using thematic
    analysis in psychology. *Qualitative Research in Psychology* (Jan. 2006). [https://doi.org/10.1191/1478088706qp063oa](https://doi.org/10.1191/1478088706qp063oa)
    Publisher: Taylor & Francis Group.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Braun 和 Clarke（2006）Virginia Braun 和 Victoria Clarke. 2006. 在心理学中使用主题分析。*心理学定性研究*（2006年1月）。
    [https://doi.org/10.1191/1478088706qp063oa](https://doi.org/10.1191/1478088706qp063oa)
    出版社：泰勒与弗朗西斯集团。
- en: Brown et al. (1989) John Seely Brown, Allan Collins, and Paul Duguid. 1989.
    Situated cognition and the culture of learning. *1989* 18, 1 (1989), 32–42. [https://library.oapen.org/bitstream/handle/20.500.12657/24125/1/1006006.pdf#page=313](https://library.oapen.org/bitstream/handle/20.500.12657/24125/1/1006006.pdf#page=313)
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人（1989）John Seely Brown, Allan Collins, 和 Paul Duguid. 1989. 情境认知与学习文化。*1989*
    18, 1 (1989), 32–42. [https://library.oapen.org/bitstream/handle/20.500.12657/24125/1/1006006.pdf#page=313](https://library.oapen.org/bitstream/handle/20.500.12657/24125/1/1006006.pdf#page=313)
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
    Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario
    Amodei. 2020. Language Models are Few-Shot Learners. [http://arxiv.org/abs/2005.14165](http://arxiv.org/abs/2005.14165)
    arXiv:2005.14165 [cs].
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brown 等人（2020）Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
    Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
    Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
    Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
    Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack
    Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, 和 Dario
    Amodei. 2020. 语言模型是少样本学习者。 [http://arxiv.org/abs/2005.14165](http://arxiv.org/abs/2005.14165)
    arXiv:2005.14165 [cs]。
- en: Caines et al. (2023) Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher
    Davis, Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore, Christopher
    Bryant, Marek Rei, Helen Yannakoudakis, Andrew Mullooly, Diane Nicholls, and Paula
    Buttery. 2023. On the application of Large Language Models for language teaching
    and assessment technology. [http://arxiv.org/abs/2307.08393](http://arxiv.org/abs/2307.08393)
    arXiv:2307.08393 [cs].
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caines 等人（2023）Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher
    Davis, Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore, Christopher
    Bryant, Marek Rei, Helen Yannakoudakis, Andrew Mullooly, Diane Nicholls, 和 Paula
    Buttery. 2023. 大型语言模型在语言教学与评估技术中的应用。 [http://arxiv.org/abs/2307.08393](http://arxiv.org/abs/2307.08393)
    arXiv:2307.08393 [cs]。
- en: Cantone et al. (2023) Andrea Antonio Cantone, Rita Francese, Raffaele Sais,
    Otino Pio Santosuosso, Aurelio Sepe, Simone Spera, Genoveffa Tortora, and Giuliana
    Vitiello. 2023. Contextualized Experiential Language Learning in the Metaverse.
    In *Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter*
    *(CHItaly ’23)*. Association for Computing Machinery, New York, NY, USA, 1–7.
    [https://doi.org/10.1145/3605390.3605395](https://doi.org/10.1145/3605390.3605395)
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cantone 等人（2023）Andrea Antonio Cantone, Rita Francese, Raffaele Sais, Otino
    Pio Santosuosso, Aurelio Sepe, Simone Spera, Genoveffa Tortora, 和 Giuliana Vitiello.
    2023. 元宇宙中的情境化体验式语言学习。在 *意大利 SIGCHI 分会第15届双年会会议录* *(CHItaly ’23)* 中。计算机协会，美国纽约，1–7。
    [https://doi.org/10.1145/3605390.3605395](https://doi.org/10.1145/3605390.3605395)
- en: Cassell et al. (2000) Justine Cassell, Joseph Sullivan, Scott Prevost, and Elizabeth F.
    Churchill (Eds.). 2000. *Embodied Conversational Agents*. The MIT Press. [https://doi.org/10.7551/mitpress/2697.001.0001](https://doi.org/10.7551/mitpress/2697.001.0001)
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cassell 等人（2000）Justine Cassell, Joseph Sullivan, Scott Prevost, 和 Elizabeth
    F. Churchill（主编）。2000. *具身会话代理*。麻省理工学院出版社。 [https://doi.org/10.7551/mitpress/2697.001.0001](https://doi.org/10.7551/mitpress/2697.001.0001)
- en: 'Chatain et al. (2023) Julia Chatain, Manu Kapur, and Robert W. Sumner. 2023.
    Three Perspectives on Embodied Learning in Virtual Reality: Opportunities for
    Interaction Design. In *Extended Abstracts of the 2023 CHI Conference on Human
    Factors in Computing Systems*. ACM, Hamburg Germany, 1–8. [https://doi.org/10.1145/3544549.3585805](https://doi.org/10.1145/3544549.3585805)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chatain 等人（2023）Julia Chatain、Manu Kapur 和 Robert W. Sumner。2023年。虚拟现实中的体现性学习三种视角：交互设计的机会。收录于
    *2023年CHI计算机系统中的人因会议扩展摘要*。ACM，德国汉堡，1–8。[https://doi.org/10.1145/3544549.3585805](https://doi.org/10.1145/3544549.3585805)
- en: 'Chen et al. (2021) Ching-Huei Chen, Hsiu-Ting Hung, and Hui-Chin Yeh. 2021.
    Virtual reality in problem-based learning contexts: Effects on the problem-solving
    performance, vocabulary acquisition and motivation of English language learners.
    *Journal of Computer Assisted Learning* 37, 3 (2021), 851–860. [https://doi.org/10.1111/jcal.12528](https://doi.org/10.1111/jcal.12528)
    _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12528.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人（2021）Ching-Huei Chen、Hsiu-Ting Hung 和 Hui-Chin Yeh。2021年。基于问题的学习情境中的虚拟现实：对英语学习者问题解决表现、词汇习得和动机的影响。*计算机辅助学习杂志*
    37, 3（2021），851–860。[https://doi.org/10.1111/jcal.12528](https://doi.org/10.1111/jcal.12528)
    _电子版： https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12528
- en: Cheng et al. (2017) Alan Cheng, Lei Yang, and Erik Andersen. 2017. Teaching
    Language and Culture with a Virtual Reality Game. In *Proceedings of the 2017
    CHI Conference on Human Factors in Computing Systems*. ACM, Denver Colorado USA,
    541–549. [https://doi.org/10.1145/3025453.3025857](https://doi.org/10.1145/3025453.3025857)
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等人（2017）Alan Cheng、Lei Yang 和 Erik Andersen。2017年。通过虚拟现实游戏教授语言与文化。收录于
    *2017年CHI计算机系统中的人因会议论文集*。ACM，美国科罗拉多州丹佛，541–549。[https://doi.org/10.1145/3025453.3025857](https://doi.org/10.1145/3025453.3025857)
- en: 'Cheng et al. (2023) Myra Cheng, Tiziano Piccardi, and Diyi Yang. 2023. CoMPosT:
    Characterizing and Evaluating Caricature in LLM Simulations. [https://arxiv.org/abs/2310.11501v1](https://arxiv.org/abs/2310.11501v1)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等人（2023）Myra Cheng、Tiziano Piccardi 和 Diyi Yang。2023年。CoMPosT：表征与评估大型语言模型模拟中的讽刺漫画。[https://arxiv.org/abs/2310.11501v1](https://arxiv.org/abs/2310.11501v1)
- en: 'Cho et al. (2022) Yeonhee Cho, Hao Ning Hsu, Zhewen Zheng, Emily Elizabeth
    Trinh, HyunYoung Jang, and Yusi Cheng. 2022. Research Based on Affective Filter
    Theory: Is Social VR an Effective Tool for Learning a Second Language?. In *2022
    8th International Conference of the Immersive Learning Research Network (iLRN)*.
    1–7. [https://doi.org/10.23919/iLRN55037.2022.9815924](https://doi.org/10.23919/iLRN55037.2022.9815924)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cho 等人（2022）Yeonhee Cho、Hao Ning Hsu、Zhewen Zheng、Emily Elizabeth Trinh、HyunYoung
    Jang 和 Yusi Cheng。2022年。基于情感过滤理论的研究：社交虚拟现实是否是学习第二语言的有效工具？收录于 *2022年第八届沉浸式学习研究网络国际会议（iLRN）*。1–7。[https://doi.org/10.23919/iLRN55037.2022.9815924](https://doi.org/10.23919/iLRN55037.2022.9815924)
- en: 'Churchill et al. (2000) Elizabeth F. Churchill, Linda Cook, Peter Hodgson,
    Scott Prevost, and Joseph W. Sullivan. 2000. ”May I Help You?”: Designing Embodied
    Conversational Agent Allies. In *Embodied Conversational Agents*, Justine Cassell,
    Joseph Sullivan, Scott Prevost, and Elizabeth F. Churchill (Eds.). The MIT Press,
    64–94. [https://doi.org/10.7551/mitpress/2697.003.0005](https://doi.org/10.7551/mitpress/2697.003.0005)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Churchill 等人（2000）Elizabeth F. Churchill、Linda Cook、Peter Hodgson、Scott Prevost
    和 Joseph W. Sullivan。2000年。“我能帮您吗？”：设计体现性对话代理助手。收录于 *体现性对话代理*，Justine Cassell、Joseph
    Sullivan、Scott Prevost 和 Elizabeth F. Churchill（编）。MIT出版社，64–94。[https://doi.org/10.7551/mitpress/2697.003.0005](https://doi.org/10.7551/mitpress/2697.003.0005)
- en: COE (2024) COE. 2024. The CEFR Levels - Common European Framework of Reference
    for Languages (CEFR). [https://www.coe.int/en/web/common-european-framework-reference-languages/level-descriptions](https://www.coe.int/en/web/common-european-framework-reference-languages/level-descriptions)
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COE（2024）COE。2024年。《CEFR等级 - 欧洲语言共同参考框架（CEFR）》。[https://www.coe.int/en/web/common-european-framework-reference-languages/level-descriptions](https://www.coe.int/en/web/common-european-framework-reference-languages/level-descriptions)
- en: Council (2024) British Council. 2024. Lesson plans | TeachingEnglish | British
    Council. [https://www.teachingenglish.org.uk/teaching-resources/teaching-adults/lesson-plans](https://www.teachingenglish.org.uk/teaching-resources/teaching-adults/lesson-plans)
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Council（2024）英国文化协会。2024年。课程计划 | TeachingEnglish | 英国文化协会。[https://www.teachingenglish.org.uk/teaching-resources/teaching-adults/lesson-plans](https://www.teachingenglish.org.uk/teaching-resources/teaching-adults/lesson-plans)
- en: 'Darsih (2018) Endang Darsih. 2018. LEARNER-CENTERED TEACHING: WHAT MAKES IT
    EFFECTIVE. *Indonesian EFL Journal* 4, 1 (Jan. 2018), 33–42. [https://doi.org/10.25134/ieflj.v4i1.796](https://doi.org/10.25134/ieflj.v4i1.796)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Darsih（2018）Endang Darsih。2018年。以学习者为中心的教学：它为何有效。*印尼英语外语教学期刊* 4, 1（2018年1月），33–42。[https://doi.org/10.25134/ieflj.v4i1.796](https://doi.org/10.25134/ieflj.v4i1.796)
- en: Dhimolea et al. (2022) Tetyana Kucher Dhimolea, Regina Kaplan-Rakowski, and
    Lin Lin. 2022. A Systematic Review of Research on High-Immersion Virtual Reality
    for Language Learning. *TechTrends* 66, 5 (Sept. 2022), 810–824. [https://doi.org/10.1007/s11528-022-00717-w](https://doi.org/10.1007/s11528-022-00717-w)
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dhimolea 等人（2022）Tetyana Kucher Dhimolea, Regina Kaplan-Rakowski, 和 Lin Lin.
    2022. 高沉浸式虚拟现实在语言学习中的系统评审。*技术趋势* 66，5（2022年9月），810–824. [https://doi.org/10.1007/s11528-022-00717-w](https://doi.org/10.1007/s11528-022-00717-w)
- en: 'Dinçer et al. (2013) Ali Dinçer, Ali Göksu, Ayşegül Takkaç, and Mine Yazıcı.
    2013. Common Characteristics Of An Effective English Language Teacher. *International
    Journal of Educational Researchers* 4, 3 (Sept. 2013), 1–8. [https://dergipark.org.tr/en/pub/ijers/issue/8498/105657](https://dergipark.org.tr/en/pub/ijers/issue/8498/105657)
    Number: 3 Publisher: Eğitim Araştırmaları Birliği Derneği.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dinçer 等人（2013）Ali Dinçer, Ali Göksu, Ayşegül Takkaç, 和 Mine Yazıcı. 2013. 有效英语教师的共同特征。*国际教育研究者期刊*
    4，3（2013年9月），1–8. [https://dergipark.org.tr/en/pub/ijers/issue/8498/105657](https://dergipark.org.tr/en/pub/ijers/issue/8498/105657)
    编号：3 出版社：教育研究者协会。
- en: 'Divekar* et al. (2022) Rahul R. Divekar*, Jaimie Drozdal*, Samuel Chabot*,
    Yalun Zhou, Hui Su, Yue Chen, Houming Zhu, James A. Hendler, and Jonas Braasch.
    2022. Foreign language acquisition via artificial intelligence and extended reality:
    design and evaluation. *Computer Assisted Language Learning* 35, 9 (Dec. 2022),
    2332–2360. [https://doi.org/10.1080/09588221.2021.1879162](https://doi.org/10.1080/09588221.2021.1879162)
    Publisher: Routledge _eprint: https://doi.org/10.1080/09588221.2021.1879162.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Divekar* 等人（2022）Rahul R. Divekar*, Jaimie Drozdal*, Samuel Chabot*, Yalun Zhou,
    Hui Su, Yue Chen, Houming Zhu, James A. Hendler, 和 Jonas Braasch. 2022. 通过人工智能和扩展现实进行外语学习：设计与评估。*计算机辅助语言学习*
    35，9（2022年12月），2332–2360. [https://doi.org/10.1080/09588221.2021.1879162](https://doi.org/10.1080/09588221.2021.1879162)
    出版社：Routledge _电子版：https://doi.org/10.1080/09588221.2021.1879162。
- en: Duolingo (2023) Duolingo. 2023. Introducing Duolingo Max, a learning experience
    powered by GPT-4. [https://blog.duolingo.com/duolingo-max/](https://blog.duolingo.com/duolingo-max/)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duolingo（2023）Duolingo. 2023. 推出 Duolingo Max，一个由 GPT-4 驱动的学习体验。 [https://blog.duolingo.com/duolingo-max/](https://blog.duolingo.com/duolingo-max/)
- en: 'Fuhrman et al. (2021) Orly Fuhrman, Anabel Eckerling, Naama Friedmann, Ricardo
    Tarrasch, and Gal Raz. 2021. The moving learner: Object manipulation in virtual
    reality improves vocabulary learning. *Journal of Computer Assisted Learning*
    37, 3 (2021), 672–683. [https://doi.org/10.1111/jcal.12515](https://doi.org/10.1111/jcal.12515)
    _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12515.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fuhrman 等人（2021）Orly Fuhrman, Anabel Eckerling, Naama Friedmann, Ricardo Tarrasch,
    和 Gal Raz. 2021. 移动学习者：虚拟现实中的物体操作促进词汇学习。*计算机辅助学习杂志* 37，3（2021），672–683. [https://doi.org/10.1111/jcal.12515](https://doi.org/10.1111/jcal.12515)
    _电子版：https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12515。
- en: Gruber and Kaplan-Rakowski (2020) Alice Gruber and Regina Kaplan-Rakowski. 2020.
    User experience of public speaking practice in virtual reality. In *Cognitive
    and affective perspectives on immersive technology in education*. IGI Global,
    235–249. [https://www.igi-global.com/chapter/user-experience-of-public-speaking-practice-in-virtual-reality/253698](https://www.igi-global.com/chapter/user-experience-of-public-speaking-practice-in-virtual-reality/253698)
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gruber 和 Kaplan-Rakowski（2020）Alice Gruber 和 Regina Kaplan-Rakowski. 2020. 虚拟现实中公共演讲练习的用户体验。载于
    *沉浸式技术在教育中的认知与情感视角*。IGI Global，235–249. [https://www.igi-global.com/chapter/user-experience-of-public-speaking-practice-in-virtual-reality/253698](https://www.igi-global.com/chapter/user-experience-of-public-speaking-practice-in-virtual-reality/253698)
- en: 'Hong et al. (2022) Fangzhou Hong, Mingyuan Zhang, Liang Pan, Zhongang Cai,
    Lei Yang, and Ziwei Liu. 2022. AvatarCLIP: Zero-Shot Text-Driven Generation and
    Animation of 3D Avatars. [https://doi.org/10.48550/arXiv.2205.08535](https://doi.org/10.48550/arXiv.2205.08535)
    arXiv:2205.08535 [cs].'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong 等人（2022）Fangzhou Hong, Mingyuan Zhang, Liang Pan, Zhongang Cai, Lei Yang,
    和 Ziwei Liu. 2022. AvatarCLIP：零样本文本驱动的3D虚拟人生成与动画。 [https://doi.org/10.48550/arXiv.2205.08535](https://doi.org/10.48550/arXiv.2205.08535)
    arXiv:2205.08535 [cs]
- en: 'Hou et al. (2024) Yuki Hou, Haruki Tamoto, and Homei Miyashita. 2024. ”My agent
    understands me better”: Integrating Dynamic Human-like Memory Recall and Consolidation
    in LLM-Based Agents. In *Extended Abstracts of the 2024 CHI Conference on Human
    Factors in Computing Systems* *(CHI EA ’24)*. Association for Computing Machinery,
    New York, NY, USA, 1–7. [https://doi.org/10.1145/3613905.3650839](https://doi.org/10.1145/3613905.3650839)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou 等人（2024）Yuki Hou, Haruki Tamoto, 和 Homei Miyashita. 2024. “我的代理更理解我”：在基于LLM的代理中集成动态类人记忆回忆与巩固。载于
    *2024年CHI计算机系统人因学会议扩展摘要*（*CHI EA ’24*）。计算机协会，美国纽约，1–7. [https://doi.org/10.1145/3613905.3650839](https://doi.org/10.1145/3613905.3650839)
- en: 'Hsu et al. (2023) Chia Hsu, Yu Chen, Yu-Jung Liu, Yu-Cheng Chang, and Min-Jui
    Lee. 2023. Spelland: Situated Language Learning with a Mixed-Reality Spelling
    Game through Everyday Objects. In *Extended Abstracts of the 2023 CHI Conference
    on Human Factors in Computing Systems*. ACM, Hamburg Germany, 1–6. [https://doi.org/10.1145/3544549.3583830](https://doi.org/10.1145/3544549.3583830)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsu 等人（2023）Chia Hsu、Yu Chen、Yu-Jung Liu、Yu-Cheng Chang 和 Min-Jui Lee。2023年。Spelland：通过日常物品进行混合现实拼写游戏的情境语言学习。《2023年CHI计算机系统人因会议扩展摘要》。ACM，德国汉堡，1-6。[https://doi.org/10.1145/3544549.3583830](https://doi.org/10.1145/3544549.3583830)
- en: IELTS (2024) IELTS. 2024. IELTS scoring in detail for test takers. [https://ielts.org/take-a-test/preparation-resources/understanding-your-score/ielts-scoring-in-detail](https://ielts.org/take-a-test/preparation-resources/understanding-your-score/ielts-scoring-in-detail)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IELTS（2024）IELTS。2024年。详细说明IELTS评分标准。[https://ielts.org/take-a-test/preparation-resources/understanding-your-score/ielts-scoring-in-detail](https://ielts.org/take-a-test/preparation-resources/understanding-your-score/ielts-scoring-in-detail)
- en: Jackson and Fagan (2000) Randolph L. Jackson and Eileen Fagan. 2000. Collaboration
    and learning within immersive virtual reality. In *Proceedings of the third international
    conference on Collaborative virtual environments*. ACM, San Francisco California
    USA, 83–92. [https://doi.org/10.1145/351006.351018](https://doi.org/10.1145/351006.351018)
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jackson 和 Fagan（2000）Randolph L. Jackson 和 Eileen Fagan。2000年。在沉浸式虚拟现实中进行协作和学习。见于《第三届国际协作虚拟环境会议论文集》。ACM，美国加利福尼亚州旧金山，83-92。[https://doi.org/10.1145/351006.351018](https://doi.org/10.1145/351006.351018)
- en: 'Jeon (2022) Jaeho Jeon. 2022. Exploring a self-directed interactive app for
    informal EFL learning: a self-determination theory perspective. *Education and
    Information Technologies* 27, 4 (May 2022), 5767–5787. [https://doi.org/10.1007/s10639-021-10839-y](https://doi.org/10.1007/s10639-021-10839-y)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeon（2022）Jaeho Jeon。2022年。探索一款自我引导的互动应用程序用于非正式英语作为外语（EFL）学习：自我决定理论视角。《教育与信息技术》27卷，第4期（2022年5月），5767-5787。[https://doi.org/10.1007/s10639-021-10839-y](https://doi.org/10.1007/s10639-021-10839-y)
- en: 'Jeon et al. (2023) Jaeho Jeon, Seongyong Lee, and Hohsung Choe. 2023. Beyond
    ChatGPT: A conceptual framework and systematic review of speech-recognition chatbots
    for language learning. *Computers & Education* 206 (Dec. 2023), 104898. [https://doi.org/10.1016/j.compedu.2023.104898](https://doi.org/10.1016/j.compedu.2023.104898)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeon 等人（2023）Jaeho Jeon、Seongyong Lee 和 Hohsung Choe。2023年。超越 ChatGPT：语音识别聊天机器人在语言学习中的概念框架与系统评审。《计算机与教育》206期（2023年12月），104898。[https://doi.org/10.1016/j.compedu.2023.104898](https://doi.org/10.1016/j.compedu.2023.104898)
- en: Jouzu Juls (2022) Jouzu Juls. 2022. VRChat is a TRAP for Language Learners.
    [https://www.youtube.com/watch?v=O4AgrFL7Kxk](https://www.youtube.com/watch?v=O4AgrFL7Kxk)
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jouzu Juls（2022）Jouzu Juls。2022年。VRChat是语言学习者的陷阱。[https://www.youtube.com/watch?v=O4AgrFL7Kxk](https://www.youtube.com/watch?v=O4AgrFL7Kxk)
- en: 'Kaplan-Rakowski and Gruber (2021) Regina Kaplan-Rakowski and Alice Gruber.
    2021. One-On-One Foreign Language Speaking Practice in High-Immersion Virtual
    Reality. In *Contextual Language Learning: Real Language Learning on the Continuum
    from Virtuality to Reality*, Yu-Ju Lan and Scott Grant (Eds.). Springer, Singapore,
    187–202. [https://doi.org/10.1007/978-981-16-3416-1_9](https://doi.org/10.1007/978-981-16-3416-1_9)'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaplan-Rakowski 和 Gruber（2021）Regina Kaplan-Rakowski 和 Alice Gruber。2021年。在高沉浸虚拟现实中进行一对一的外语口语练习。见于《情境语言学习：从虚拟到现实的语言学习连续性》，Yu-Ju
    Lan 和 Scott Grant（编）。Springer，新加坡，187-202。[https://doi.org/10.1007/978-981-16-3416-1_9](https://doi.org/10.1007/978-981-16-3416-1_9)
- en: Kasneci et al. (2023) Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann,
    Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan
    Günnemann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli,
    Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt,
    Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci.
    2023. ChatGPT for good? On opportunities and challenges of large language models
    for education. *Learning and Individual Differences* 103 (April 2023), 102274.
    [https://doi.org/10.1016/j.lindif.2023.102274](https://doi.org/10.1016/j.lindif.2023.102274)
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kasneci 等人（2023）Enkelejda Kasneci、Kathrin Sessler、Stefan Küchemann、Maria Bannert、Daryna
    Dementieva、Frank Fischer、Urs Gasser、Georg Groh、Stephan Günnemann、Eyke Hüllermeier、Stephan
    Krusche、Gitta Kutyniok、Tilman Michaeli、Claudia Nerdel、Jürgen Pfeffer、Oleksandra
    Poquet、Michael Sailer、Albrecht Schmidt、Tina Seidel、Matthias Stadler、Jochen Weller、Jochen
    Kuhn 和 Gjergji Kasneci。2023年。ChatGPT 用于教育的前景？大型语言模型在教育中的机遇与挑战。《学习与个体差异》103期（2023年4月），102274。[https://doi.org/10.1016/j.lindif.2023.102274](https://doi.org/10.1016/j.lindif.2023.102274)
- en: 'Khattab et al. (2023) Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan
    Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T.
    Joshi, Hanna Moazam, Heather Miller, Matei Zaharia, and Christopher Potts. 2023.
    DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines.
    [https://doi.org/10.48550/arXiv.2310.03714](https://doi.org/10.48550/arXiv.2310.03714)
    arXiv:2310.03714 [cs].'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khattab 等人（2023）Omar Khattab、Arnav Singhvi、Paridhi Maheshwari、Zhiyuan Zhang、Keshav
    Santhanam、Sri Vardhamanan、Saiful Haq、Ashutosh Sharma、Thomas T. Joshi、Hanna Moazam、Heather
    Miller、Matei Zaharia 和 Christopher Potts。2023年。《DSPy：将声明式语言模型调用编译成自我改进的管道》。[https://doi.org/10.48550/arXiv.2310.03714](https://doi.org/10.48550/arXiv.2310.03714)
    arXiv:2310.03714 [cs]。
- en: Klimova (2021) Blanka Klimova. 2021. Use of Virtual Reality in Non-Native Language
    Learning and Teaching. *Procedia Computer Science* 192 (Jan. 2021), 1385–1392.
    [https://doi.org/10.1016/j.procs.2021.08.141](https://doi.org/10.1016/j.procs.2021.08.141)
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klimova（2021）Blanka Klimova。2021年。《虚拟现实在非母语语言学习与教学中的应用》。*计算机科学学报* 192（2021年1月），1385–1392。[https://doi.org/10.1016/j.procs.2021.08.141](https://doi.org/10.1016/j.procs.2021.08.141)
- en: 'ko fi.com (2024) ko fi.com. 2024. Celeste-AI. [https://github.com/Celeste-AI/Celeste-AI](https://github.com/Celeste-AI/Celeste-AI)
    original-date: 2023-04-11T02:28:07Z.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ko fi.com（2024）ko fi.com。2024年。《Celeste-AI》。[https://github.com/Celeste-AI/Celeste-AI](https://github.com/Celeste-AI/Celeste-AI)
    原始日期：2023-04-11T02:28:07Z。
- en: 'Koulouris et al. (2020) Jordan Koulouris, Zoe Jeffery, James Best, Eamonn O’Neill,
    and Christof Lutteroth. 2020. Me vs. Super(wo)man: Effects of Customization and
    Identification in a VR Exergame. In *Proceedings of the 2020 CHI Conference on
    Human Factors in Computing Systems* *(CHI ’20)*. Association for Computing Machinery,
    New York, NY, USA, 1–17. [https://doi.org/10.1145/3313831.3376661](https://doi.org/10.1145/3313831.3376661)'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koulouris 等人（2020）Jordan Koulouris、Zoe Jeffery、James Best、Eamonn O’Neill 和 Christof
    Lutteroth。2020年。《我与超级（女）人：VR健身游戏中定制和身份认同的影响》。在*2020年计算机系统人因会议论文集*（CHI ’20）。计算机协会，纽约，纽约，美国，1–17。[https://doi.org/10.1145/3313831.3376661](https://doi.org/10.1145/3313831.3376661)
- en: 'Kumaran et al. (2023) Vikram Kumaran, Jonathan Rowe, Bradford Mott, and James
    Lester. 2023. SceneCraft: Automating Interactive Narrative Scene Generation in
    Digital Games with Large Language Models. *Proceedings of the AAAI Conference
    on Artificial Intelligence and Interactive Digital Entertainment* 19, 1 (Oct.
    2023), 86–96. [https://doi.org/10.1609/aiide.v19i1.27504](https://doi.org/10.1609/aiide.v19i1.27504)
    Number: 1.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kumaran 等人（2023）Vikram Kumaran、Jonathan Rowe、Bradford Mott 和 James Lester。2023年。《SceneCraft：利用大型语言模型在数字游戏中自动化交互式叙事场景生成》。*人工智能与互动数字娱乐会议论文集*
    19, 1（2023年10月），86–96。[https://doi.org/10.1609/aiide.v19i1.27504](https://doi.org/10.1609/aiide.v19i1.27504)
    编号：1。
- en: Lan (2020) Yu-Ju Lan. 2020. Chapter One - Immersion into virtual reality for
    language learning. In *Psychology of Learning and Motivation*, Kara D. Federmeier
    and Hsu-Wen Huang (Eds.). Adult and Second Language Learning, Vol. 72\. Academic
    Press, 1–26. [https://doi.org/10.1016/bs.plm.2020.03.001](https://doi.org/10.1016/bs.plm.2020.03.001)
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lan（2020）Yu-Ju Lan。2020年。《第一章 - 语言学习中的虚拟现实沉浸体验》。在*学习与动机心理学*中，Kara D. Federmeier
    和 Hsu-Wen Huang（编）。成人与第二语言学习，第72卷。学术出版社，1–26。[https://doi.org/10.1016/bs.plm.2020.03.001](https://doi.org/10.1016/bs.plm.2020.03.001)
- en: 'Lave and Wenger (1991) Jean Lave and Etienne Wenger. 1991. *Situated Learning:
    Legitimate Peripheral Participation*. Cambridge University Press. Google-Books-ID:
    CAVIOrW3vYAC.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lave 和 Wenger（1991）Jean Lave 和 Etienne Wenger。1991年。*情境学习：合法的外围参与*。剑桥大学出版社。Google-Books-ID：CAVIOrW3vYAC。
- en: 'Law (2024) Locky Law. 2024. Application of generative artificial intelligence
    (GenAI) in language teaching and learning: A scoping literature review. *Computers
    and Education Open* 6 (June 2024), 100174. [https://doi.org/10.1016/j.caeo.2024.100174](https://doi.org/10.1016/j.caeo.2024.100174)'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Law（2024）Locky Law。2024年。《生成性人工智能（GenAI）在语言教学与学习中的应用：范围文献综述》。*计算机与教育开放* 6（2024年6月），100174。[https://doi.org/10.1016/j.caeo.2024.100174](https://doi.org/10.1016/j.caeo.2024.100174)
- en: 'Lefkowitz (2009) Natalie Lefkowitz. 2009. SECOND LANGUAGE LEARNING AND LANGUAGE
    TEACHING (4th ed.). Vivian Cook. London: Arnold, 2008\. Pp. x + 306. *Studies
    in Second Language Acquisition* 31, 4 (Dec. 2009), 660–661. [https://doi.org/10.1017/S0272263109990180](https://doi.org/10.1017/S0272263109990180)'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lefkowitz（2009）Natalie Lefkowitz。2009年。《第二语言学习与语言教学》（第4版）。Vivian Cook。伦敦：Arnold，2008年。第x页+306页。*第二语言习得研究*
    31, 4（2009年12月），660–661。[https://doi.org/10.1017/S0272263109990180](https://doi.org/10.1017/S0272263109990180)
- en: Li et al. (2024) Hao Li, Chenghao Yang, An Zhang, Yang Deng, Xiang Wang, and
    Tat-Seng Chua. 2024. Hello Again! LLM-powered Personalized Agent for Long-term
    Dialogue. [https://doi.org/10.48550/arXiv.2406.05925](https://doi.org/10.48550/arXiv.2406.05925)
    arXiv:2406.05925 [cs].
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2024）Hao Li、Chenghao Yang、An Zhang、Yang Deng、Xiang Wang 和 Tat-Seng Chua。2024年。再次见面！基于LLM的大规模个性化对话代理。
    [https://doi.org/10.48550/arXiv.2406.05925](https://doi.org/10.48550/arXiv.2406.05925)
    arXiv:2406.05925 [cs].
- en: Limniou et al. (2008) Maria Limniou, David Roberts, and Nikos Papadopoulos.
    2008. Full immersive virtual environment CAVETM in chemistry education. *Computers
    & Education* 51, 2 (Sept. 2008), 584–593. [https://doi.org/10.1016/j.compedu.2007.06.014](https://doi.org/10.1016/j.compedu.2007.06.014)
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Limniou 等人（2008）Maria Limniou、David Roberts 和 Nikos Papadopoulos。2008年。全沉浸式虚拟环境
    CAVETM 在化学教育中的应用。*计算机与教育* 51, 2（2008年9月），584–593。[https://doi.org/10.1016/j.compedu.2007.06.014](https://doi.org/10.1016/j.compedu.2007.06.014)
- en: 'Lin and Lan (2015) Tsun-Ju Lin and Yu-Ju Lan. 2015. Language Learning in Virtual
    Reality Environments: Past, Present, and Future. *Journal of Educational Technology
    & Society* 18, 4 (2015), 486–497. [https://www.jstor.org/stable/jeductechsoci.18.4.486](https://www.jstor.org/stable/jeductechsoci.18.4.486)
    Publisher: International Forum of Educational Technology & Society.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 和 Lan（2015）Tsun-Ju Lin 和 Yu-Ju Lan。2015年。虚拟现实环境中的语言学习：过去、现在与未来。*教育技术与社会期刊*
    18, 4（2015），486–497。[https://www.jstor.org/stable/jeductechsoci.18.4.486](https://www.jstor.org/stable/jeductechsoci.18.4.486)
    发表者：国际教育技术与社会论坛。
- en: 'Liu et al. (2024) Ziyi Liu, Zhengzhe Zhu, Lijun Zhu, Enze Jiang, Xiyun Hu,
    Kylie A Peppler, and Karthik Ramani. 2024. ClassMeta: Designing Interactive Virtual
    Classmate to Promote VR Classroom Participation. In *Proceedings of the CHI Conference
    on Human Factors in Computing Systems* (Honolulu, HI, USA) *(CHI ’24)*. Association
    for Computing Machinery, New York, NY, USA, Article 659, 17 pages. [https://doi.org/10.1145/3613904.3642947](https://doi.org/10.1145/3613904.3642947)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2024）Ziyi Liu、Zhengzhe Zhu、Lijun Zhu、Enze Jiang、Xiyun Hu、Kylie A Peppler
    和 Karthik Ramani。2024年。ClassMeta：设计互动虚拟同学以促进VR课堂参与。发表于 *CHI计算机系统人因会议论文集*（美国夏威夷檀香山，CHI
    ’24）。计算机协会，美国纽约，文章659，17页。[https://doi.org/10.1145/3613904.3642947](https://doi.org/10.1145/3613904.3642947)
- en: Makransky and Lilleholt (2018) Guido Makransky and Lau Lilleholt. 2018. A structural
    equation modeling investigation of the emotional value of immersive virtual reality
    in education. *Educational Technology Research and Development* 66, 5 (Oct. 2018),
    1141–1164. [https://doi.org/10.1007/s11423-018-9581-2](https://doi.org/10.1007/s11423-018-9581-2)
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Makransky 和 Lilleholt（2018）Guido Makransky 和 Lau Lilleholt。2018年。沉浸式虚拟现实在教育中情感价值的结构方程建模研究。*教育技术研究与发展*
    66, 5（2018年10月），1141–1164。[https://doi.org/10.1007/s11423-018-9581-2](https://doi.org/10.1007/s11423-018-9581-2)
- en: Merle_Meruru555 (2024) Merle_Meruru555\. 2024. EN-JP Language Exchange every
    weekend! come join! details below. [www.reddit.com/r/VRchat/comments/1eyelee/enjp_language_exchange_every_weekend_come_join/](www.reddit.com/r/VRchat/comments/1eyelee/enjp_language_exchange_every_weekend_come_join/)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Merle_Meruru555（2024）Merle_Meruru555。2024年。每周末进行的EN-JP语言交换！快来加入！详细信息见下方。[www.reddit.com/r/VRchat/comments/1eyelee/enjp_language_exchange_every_weekend_come_join/](www.reddit.com/r/VRchat/comments/1eyelee/enjp_language_exchange_every_weekend_come_join/)
- en: Normoyle et al. (2024) Aline Normoyle, João Sedoc, and Funda Durupinar. 2024.
    Using LLMs to Animate Interactive Story Characters with Emotions and Personality.
    In *2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and
    Workshops (VRW)*. IEEE, 632–635. [https://doi.org/10.1109/VRW62533.2024.00124](https://doi.org/10.1109/VRW62533.2024.00124)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Normoyle 等人（2024）Aline Normoyle、João Sedoc 和 Funda Durupinar。2024年。使用LLM（大规模语言模型）来使互动故事角色具备情感和个性。发表于
    *2024 IEEE虚拟现实与3D用户界面会议摘要与研讨会（VRW）*。IEEE，632–635。[https://doi.org/10.1109/VRW62533.2024.00124](https://doi.org/10.1109/VRW62533.2024.00124)
- en: OpenAI (2024a) OpenAI. 2024a. Hello GPT-4o. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2024a）OpenAI。2024年。你好，GPT-4o。[https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)
- en: OpenAI (2024b) OpenAI. 2024b. TTS OpenAI Text to Speech. [https://platform.openai.com/docs/guides/text-to-speech/overview](https://platform.openai.com/docs/guides/text-to-speech/overview)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2024b）OpenAI。2024年。TTS OpenAI语音合成。 [https://platform.openai.com/docs/guides/text-to-speech/overview](https://platform.openai.com/docs/guides/text-to-speech/overview)
- en: OpenAI (2024c) OpenAI. 2024c. Whisper API. [https://platform.openai.com/docs/guides/speech-to-text](https://platform.openai.com/docs/guides/speech-to-text)
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2024c）OpenAI。2024年。Whisper API。[https://platform.openai.com/docs/guides/speech-to-text](https://platform.openai.com/docs/guides/speech-to-text)
- en: 'Petersen et al. (2021) Gustav Bøg Petersen, Aske Mottelson, and Guido Makransky.
    2021. Pedagogical Agents in Educational VR: An in the Wild Study. In *Proceedings
    of the 2021 CHI Conference on Human Factors in Computing Systems* *(CHI ’21)*.
    Association for Computing Machinery, New York, NY, USA, 1–12. [https://doi.org/10.1145/3411764.3445760](https://doi.org/10.1145/3411764.3445760)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petersen 等（2021）Gustav Bøg Petersen, Aske Mottelson, 和 Guido Makransky. 2021.
    教育 VR 中的教学代理：一项实地研究. 载于 *2021年CHI人机交互大会论文集* *(CHI ’21)*. 美国纽约计算机协会，1–12. [https://doi.org/10.1145/3411764.3445760](https://doi.org/10.1145/3411764.3445760)
- en: Peterson (2012) Mark Peterson. 2012. EFL learner collaborative interaction in
    Second Life. *ReCALL* 24, 1 (Jan. 2012), 20–39. [https://doi.org/10.1017/S0958344011000279](https://doi.org/10.1017/S0958344011000279)
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peterson（2012）Mark Peterson. 2012. EFL 学习者在 Second Life 中的协作互动. *ReCALL* 24,
    1 (2012年1月), 20–39. [https://doi.org/10.1017/S0958344011000279](https://doi.org/10.1017/S0958344011000279)
- en: Python_Sounddevice (2024) Python_Sounddevice. 2024. Play and Record Sound with
    Python — python-sounddevice, version 0.5.0. [https://python-sounddevice.readthedocs.io/en/0.5.0/](https://python-sounddevice.readthedocs.io/en/0.5.0/)
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python_Sounddevice（2024）Python_Sounddevice. 2024. 使用 Python 播放和录制声音 — python-sounddevice，版本
    0.5.0. [https://python-sounddevice.readthedocs.io/en/0.5.0/](https://python-sounddevice.readthedocs.io/en/0.5.0/)
- en: 'Python_Vosk (2024) Python_Vosk. 2024. vosk: Offline open source speech recognition
    API based on Kaldi and Vosk. [https://github.com/alphacep/vosk-api](https://github.com/alphacep/vosk-api)'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python_Vosk（2024）Python_Vosk. 2024. vosk：基于 Kaldi 和 Vosk 的离线开源语音识别 API. [https://github.com/alphacep/vosk-api](https://github.com/alphacep/vosk-api)
- en: 'Qing et al. (2023) Zhongfei Qing, Zhongang Cai, Zhitao Yang, and Lei Yang.
    2023. Story-to-Motion: Synthesizing Infinite and Controllable Character Animation
    from Long Text. In *SIGGRAPH Asia 2023 Technical Communications* *(SA ’23)*. Association
    for Computing Machinery, New York, NY, USA, 1–4. [https://doi.org/10.1145/3610543.3626176](https://doi.org/10.1145/3610543.3626176)'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qing 等（2023）Zhongfei Qing, Zhongang Cai, Zhitao Yang, 和 Lei Yang. 2023. Story-to-Motion:
    从长文本合成无限且可控的角色动画. 载于 *SIGGRAPH Asia 2023 技术交流* *(SA ’23)*. 美国纽约计算机协会，1–4. [https://doi.org/10.1145/3610543.3626176](https://doi.org/10.1145/3610543.3626176)'
- en: 'Raux and Eskenazi (2004) Antoine Raux and Maxine Eskenazi. 2004. Using task-oriented
    spoken dialogue systems for language learning: potential, practical applications
    and challenges. In *InSTIL/ICALL Symposium 2004*. Citeseer. [https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=cb20467d1b74a5304f84fdc0e12b96710117a6a0](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=cb20467d1b74a5304f84fdc0e12b96710117a6a0)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raux 和 Eskenazi（2004）Antoine Raux 和 Maxine Eskenazi. 2004. 使用面向任务的口语对话系统进行语言学习：潜力、实际应用和挑战.
    载于 *InSTIL/ICALL 研讨会 2004*. Citeseer. [https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=cb20467d1b74a5304f84fdc0e12b96710117a6a0](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=cb20467d1b74a5304f84fdc0e12b96710117a6a0)
- en: Roy and Aimee (2020) Roy and Aimee. 2020. Can you actually learn JAPANESE using
    VRChat? [https://www.youtube.com/watch?v=c8IrEVhDVsk](https://www.youtube.com/watch?v=c8IrEVhDVsk)
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roy 和 Aimee（2020）Roy 和 Aimee. 2020. 你能通过 VRChat 真正学会日语吗？[https://www.youtube.com/watch?v=c8IrEVhDVsk](https://www.youtube.com/watch?v=c8IrEVhDVsk)
- en: 'Schulhoff et al. (2024) Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine
    Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien
    Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal,
    Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da Costa,
    Saloni Gupta, Megan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker,
    Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle,
    and Philip Resnik. 2024. The Prompt Report: A Systematic Survey of Prompting Techniques.
    [http://arxiv.org/abs/2406.06608](http://arxiv.org/abs/2406.06608) arXiv:2406.06608
    [cs].'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schulhoff 等（2024）Sander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine
    Kahadze, Amanda Liu, Chenglei Si, Yinheng Li, Aayush Gupta, HyoJung Han, Sevien
    Schulhoff, Pranav Sandeep Dulepet, Saurav Vidyadhara, Dayeon Ki, Sweta Agrawal,
    Chau Pham, Gerson Kroiz, Feileen Li, Hudson Tao, Ashay Srivastava, Hevander Da
    Costa, Saloni Gupta, Megan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker,
    Denis Peskoff, Marine Carpuat, Jules White, Shyamal Anadkat, Alexander Hoyle,
    和 Philip Resnik. 2024. The Prompt Report: 提示技术的系统性调查. [http://arxiv.org/abs/2406.06608](http://arxiv.org/abs/2406.06608)
    arXiv:2406.06608 [cs].'
- en: 'Seow (2023) Olivia Seow. 2023. LingoLand: An AI-Assisted Immersive Game for
    Language Learning. In *Adjunct Proceedings of the 36th Annual ACM Symposium on
    User Interface Software and Technology*. ACM, San Francisco CA USA, 1–3. [https://doi.org/10.1145/3586182.3625117](https://doi.org/10.1145/3586182.3625117)'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Seow（2023）Olivia Seow. 2023. LingoLand: 一款 AI 辅助的沉浸式语言学习游戏. 载于 *第36届年度 ACM
    用户界面软件与技术研讨会附录论文集*. ACM，美国旧金山，1–3. [https://doi.org/10.1145/3586182.3625117](https://doi.org/10.1145/3586182.3625117)'
- en: Siyan et al. (2024) Li Siyan, Teresa Shao, Zhou Yu, and Julia Hirschberg. 2024.
    Using Adaptive Empathetic Responses for Teaching English. [https://doi.org/10.48550/arXiv.2404.13764](https://doi.org/10.48550/arXiv.2404.13764)
    arXiv:2404.13764 [cs].
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siyan等（2024）Li Siyan, Teresa Shao, Zhou Yu, 和 Julia Hirschberg. 2024. 《使用自适应同理反应进行英语教学》。[https://doi.org/10.48550/arXiv.2404.13764](https://doi.org/10.48550/arXiv.2404.13764)
    arXiv:2404.13764 [cs]。
- en: Sonlu et al. (2024) Sinan Sonlu, Bennie Bendiksen, Funda Durupinar, and Uğur
    Güdükbay. 2024. The Effects of Embodiment and Personality Expression on Learning
    in LLM-based Educational Agents. [https://doi.org/10.48550/arXiv.2407.10993](https://doi.org/10.48550/arXiv.2407.10993)
    arXiv:2407.10993 [cs].
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sonlu等（2024）Sinan Sonlu, Bennie Bendiksen, Funda Durupinar, 和 Uğur Güdükbay.
    2024. 《基于LLM的教育智能体中体现性和个性表达对学习的影响》。[https://doi.org/10.48550/arXiv.2407.10993](https://doi.org/10.48550/arXiv.2407.10993)
    arXiv:2407.10993 [cs]。
- en: Tyen et al. (2022) Gladys Tyen, Mark Brenchley, Andrew Caines, and Paula Buttery.
    2022. Towards an open-domain chatbot for language practice. In *Proceedings of
    the 17th Workshop on Innovative Use of NLP for Building Educational Applications
    (BEA 2022)*, Ekaterina Kochmar, Jill Burstein, Andrea Horbach, Ronja Laarmann-Quante,
    Nitin Madnani, Anaïs Tack, Victoria Yaneva, Zheng Yuan, and Torsten Zesch (Eds.).
    Association for Computational Linguistics, Seattle, Washington, 234–249. [https://doi.org/10.18653/v1/2022.bea-1.28](https://doi.org/10.18653/v1/2022.bea-1.28)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tyen等（2022）Gladys Tyen, Mark Brenchley, Andrew Caines, 和 Paula Buttery. 2022.
    《朝向一个开放域的聊天机器人用于语言练习》。收录于*第17届创新使用自然语言处理构建教育应用研讨会（BEA 2022）*，Ekaterina Kochmar,
    Jill Burstein, Andrea Horbach, Ronja Laarmann-Quante, Nitin Madnani, Anaïs Tack,
    Victoria Yaneva, Zheng Yuan, 和 Torsten Zesch（编辑）。计算语言学协会，西雅图，华盛顿，234–249。[https://doi.org/10.18653/v1/2022.bea-1.28](https://doi.org/10.18653/v1/2022.bea-1.28)
- en: Unity (2024) Unity. 2024. Unity. [https://unity.com/](https://unity.com/)
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Unity（2024）Unity. 2024. 《Unity》。[https://unity.com/](https://unity.com/)
- en: 'van Mulken et al. (1998) Susanne van Mulken, Elisabeth André, and Jochen Müller.
    1998. The Persona Effect: How Substantial Is It?. In *People and Computers XIII*,
    Hilary Johnson, Lawrence Nigay, and Christopher Roast (Eds.). Springer, London,
    53–66. [https://doi.org/10.1007/978-1-4471-3605-7_4](https://doi.org/10.1007/978-1-4471-3605-7_4)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van Mulken等（1998）Susanne van Mulken, Elisabeth André, 和 Jochen Müller. 1998.
    《人格效应：它有多大影响？》。收录于*People and Computers XIII*，Hilary Johnson, Lawrence Nigay,
    和 Christopher Roast（编辑）。Springer, 伦敦，53–66。[https://doi.org/10.1007/978-1-4471-3605-7_4](https://doi.org/10.1007/978-1-4471-3605-7_4)
- en: VRChat (2024a) VRChat. 2024a. OSC Overview. [https://docs.vrchat.com/docs/osc-overview](https://docs.vrchat.com/docs/osc-overview)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VRChat（2024a）VRChat. 2024a. 《OSC概述》。[https://docs.vrchat.com/docs/osc-overview](https://docs.vrchat.com/docs/osc-overview)
- en: VRChat (2024b) VRChat. 2024b. VRChat. [https://hello.vrchat.com](https://hello.vrchat.com)
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VRChat（2024b）VRChat. 2024b. 《VRChat》。[https://hello.vrchat.com](https://hello.vrchat.com)
- en: Wan et al. (2024) Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao,
    Dakuo Wang, Yvonne Coady, and Mirjana Prpa. 2024. Building LLM-based AI Agents
    in Social Virtual Reality. In *Extended Abstracts of the 2024 CHI Conference on
    Human Factors in Computing Systems* *(CHI EA ’24)*. Association for Computing
    Machinery, New York, NY, USA, 1–7. [https://doi.org/10.1145/3613905.3651026](https://doi.org/10.1145/3613905.3651026)
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wan等（2024）Hongyu Wan, Jinda Zhang, Abdulaziz Arif Suria, Bingsheng Yao, Dakuo
    Wang, Yvonne Coady, 和 Mirjana Prpa. 2024. 《在社交虚拟现实中构建基于LLM的AI智能体》。收录于*2024年CHI人机交互系统会议扩展摘要*（*CHI
    EA ’24*）。美国计算机学会，纽约，USA，1–7。[https://doi.org/10.1145/3613905.3651026](https://doi.org/10.1145/3613905.3651026)
- en: 'Wang et al. (2023) Zehan Wang, Haifeng Huang, Yang Zhao, Ziang Zhang, and Zhou
    Zhao. 2023. Chat-3D: Data-efficiently Tuning Large Language Model for Universal
    Dialogue of 3D Scenes. [https://doi.org/10.48550/arXiv.2308.08769](https://doi.org/10.48550/arXiv.2308.08769)
    arXiv:2308.08769 [cs].'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等（2023）Zehan Wang, Haifeng Huang, Yang Zhao, Ziang Zhang, 和 Zhou Zhao.
    2023. 《Chat-3D: 高效数据调优大规模语言模型以实现3D场景的普适对话》。[https://doi.org/10.48550/arXiv.2308.08769](https://doi.org/10.48550/arXiv.2308.08769)
    arXiv:2308.08769 [cs]。'
- en: Wik and Hjalmarsson (2009) Preben Wik and Anna Hjalmarsson. 2009. Embodied conversational
    agents in computer assisted language learning. *Speech Communication* 51, 10 (Oct.
    2009), 1024–1037. [https://doi.org/10.1016/j.specom.2009.05.006](https://doi.org/10.1016/j.specom.2009.05.006)
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wik和Hjalmarsson（2009）Preben Wik 和 Anna Hjalmarsson. 2009. 《计算机辅助语言学习中的体现性对话代理》。*Speech
    Communication* 51, 10（2009年10月），1024–1037。[https://doi.org/10.1016/j.specom.2009.05.006](https://doi.org/10.1016/j.specom.2009.05.006)
- en: 'Wong et al. (2018) Man Ho Ivy Wong, Helen Zhao, and Brian MacWhinney. 2018.
    A Cognitive Linguistics Application for Second Language Pedagogy: The English
    Preposition Tutor. *Language Learning* 68, 2 (2018), 438–468. [https://doi.org/10.1111/lang.12278](https://doi.org/10.1111/lang.12278)
    _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/lang.12278.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '黄等人（2018）黄曼荷（Ivy Wong）、赵海伦、布莱恩·麦克威尼（Brian MacWhinney）。2018年。《一种应用于第二语言教学的认知语言学方法：英语介词辅导》。*语言学习*
    68, 2（2018），438–468。[https://doi.org/10.1111/lang.12278](https://doi.org/10.1111/lang.12278)
    _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/lang.12278。'
- en: 'Woodrow (2006) Lindy Woodrow. 2006. Anxiety and Speaking English as a Second
    Language. *RELC Journal* (Dec. 2006). [https://doi.org/10.1177/0033688206071315](https://doi.org/10.1177/0033688206071315)
    Publisher: Sage PublicationsSage CA: Thousand Oaks, CA.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '林迪·伍德罗（2006）伍德罗，林迪。2006年。《焦虑与英语作为第二语言的口语表达》。*RELC期刊*（2006年12月）。[https://doi.org/10.1177/0033688206071315](https://doi.org/10.1177/0033688206071315)
    出版商：Sage PublicationsSage CA: Thousand Oaks, CA。'
- en: 'Wu et al. (2023) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah,
    Ryen W. White, Doug Burger, and Chi Wang. 2023. AutoGen: Enabling Next-Gen LLM
    Applications via Multi-Agent Conversation. [https://doi.org/10.48550/arXiv.2308.08155](https://doi.org/10.48550/arXiv.2308.08155)
    arXiv:2308.08155 [cs].'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '吴等人（2023）吴清云、戈根·班萨尔、张杰宇、吴怡然、李贝宾、朱尔康、姜丽、张晓云、张少坤、刘佳乐、艾哈迈德·哈桑·阿瓦达拉、瑞恩·W·怀特、道格·伯格、王池。2023年。《AutoGen:
    通过多智能体对话实现下一代LLM应用》。[https://doi.org/10.48550/arXiv.2308.08155](https://doi.org/10.48550/arXiv.2308.08155)
    arXiv:2308.08155 [cs]。'
- en: 'Xu et al. (2021) Ying Xu, Dakuo Wang, Penelope Collins, Hyelim Lee, and Mark
    Warschauer. 2021. Same benefits, different communication patterns: Comparing Children’s
    reading with a conversational agent vs. a human partner. *Computers & Education*
    161 (Feb. 2021), 104059. [https://doi.org/10.1016/j.compedu.2020.104059](https://doi.org/10.1016/j.compedu.2020.104059)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许等人（2021）许颖、王大阔、佩内洛普·科林斯、李慧琳、马克·沃尔沙尔。2021年。《相同的好处，不同的沟通模式：比较儿童与对话代理与人类伙伴的阅读》。*计算机与教育*
    161（2021年2月），104059。[https://doi.org/10.1016/j.compedu.2020.104059](https://doi.org/10.1016/j.compedu.2020.104059)
- en: 'Yang et al. (2024) Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han,
    Qizhang Feng, Haoming Jiang, Shaochen Zhong, Bing Yin, and Xia Hu. 2024. Harnessing
    the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. *ACM Transactions
    on Knowledge Discovery from Data* 18, 6 (July 2024), 1–32. [https://doi.org/10.1145/3649506](https://doi.org/10.1145/3649506)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人（2024）杨晶锋、金洪业、唐瑞翔、韩晓天、冯启章、姜昊铭、钟少晨、殷冰、胡霞。2024年。《实践中利用LLM的力量：关于ChatGPT及其扩展应用的调查》。*ACM数据知识发现事务*
    18, 6（2024年7月），1–32。[https://doi.org/10.1145/3649506](https://doi.org/10.1145/3649506)
- en: Yi et al. (2024) Zihao Yi, Jiarui Ouyang, Yuwen Liu, Tianhao Liao, Zhe Xu, and
    Ying Shen. 2024. A Survey on Recent Advances in LLM-Based Multi-turn Dialogue
    Systems. [https://doi.org/10.48550/arXiv.2402.18013](https://doi.org/10.48550/arXiv.2402.18013)
    arXiv:2402.18013 [cs].
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易等人（2024）易自豪、欧阳佳睿、刘宇文、廖天昊、徐哲、沈颖。2024年。《基于LLM的多轮对话系统的最新进展调查》。[https://doi.org/10.48550/arXiv.2402.18013](https://doi.org/10.48550/arXiv.2402.18013)
    arXiv:2402.18013 [cs]。
- en: 'Zamfirescu-Pereira et al. (2023) J.D. Zamfirescu-Pereira, Richmond Y. Wong,
    Bjoern Hartmann, and Qian Yang. 2023. Why Johnny Can’t Prompt: How Non-AI Experts
    Try (and Fail) to Design LLM Prompts. In *Proceedings of the 2023 CHI Conference
    on Human Factors in Computing Systems* *(CHI ’23)*. Association for Computing
    Machinery, New York, NY, USA, 1–21. [https://doi.org/10.1145/3544548.3581388](https://doi.org/10.1145/3544548.3581388)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扎姆费雷斯库-佩雷拉等人（2023）J.D. 扎姆费雷斯库-佩雷拉、瑞士·Y·黄、比约恩·哈特曼、杨倩。2023年。《为什么约翰尼不能进行提示：非AI专家如何尝试（并失败）设计LLM提示》。在*2023年CHI计算机系统中的人类因素会议论文集*（*CHI
    '23*）中。计算机协会，纽约，NY，美国，1–21。[https://doi.org/10.1145/3544548.3581388](https://doi.org/10.1145/3544548.3581388)
- en: 'Zhang et al. (2023) Ruofei Zhang, Di Zou, and Gary Cheng. 2023. Chatbot-based
    learning of logical fallacies in EFL writing: perceived effectiveness in improving
    target knowledge and learner motivation. *Interactive Learning Environments* 0,
    0 (2023), 1–18. [https://doi.org/10.1080/10494820.2023.2220374](https://doi.org/10.1080/10494820.2023.2220374)
    Publisher: Routledge _eprint: https://doi.org/10.1080/10494820.2023.2220374.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '张等人（2023）张若飞、邹笛、程睿。2023年。《基于聊天机器人的英语作为外语写作中的逻辑谬误学习：对提升目标知识和学习者动机的感知有效性》。*互动学习环境*
    0, 0（2023），1–18。[https://doi.org/10.1080/10494820.2023.2220374](https://doi.org/10.1080/10494820.2023.2220374)
    出版商：Routledge _eprint: https://doi.org/10.1080/10494820.2023.2220374。'
- en: 'Zhang et al. (2021) Xinlei Zhang, Takashi Miyaki, and Jun Rekimoto. 2021. JustSpeak:
    Automated, User-Configurable, Interactive Agents for Speech Tutoring. *Proc. ACM
    Hum.-Comput. Interact.* 5, EICS (2021), 202:1–202:24. [https://doi.org/10.1145/3459744](https://doi.org/10.1145/3459744)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2021）张新磊、宫崎孝、力重良。2021年。《JustSpeak：自动化、用户可配置、互动语音辅导代理》。*计算机交互学会会议论文集* 5,
    EICS（2021），202:1–202:24。 [https://doi.org/10.1145/3459744](https://doi.org/10.1145/3459744)
- en: Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao
    Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging LLM-as-a-Judge with MT-Bench
    and Chatbot Arena. [https://doi.org/10.48550/arXiv.2306.05685](https://doi.org/10.48550/arXiv.2306.05685)
    arXiv:2306.05685 [cs].
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郑等人（2023）郑力敏、蒋维林、盛颖、庄思源、吴章浩、庄永浩、林子、李卓涵、李大成、谢爱平、张浩、约瑟夫·E·冈萨雷斯、斯托伊卡。2023年。《通过MT-Bench和Chatbot
    Arena评判LLM作为法官》。 [https://doi.org/10.48550/arXiv.2306.05685](https://doi.org/10.48550/arXiv.2306.05685)
    arXiv:2306.05685 [cs]。
- en: 'Zhu et al. (2023) Zhengzhe Zhu, Ziyi Liu, Youyou Zhang, Lijun Zhu, Joey Huang,
    Ana M Villanueva, Xun Qian, Kylie Peppler, and Karthik Ramani. 2023. LearnIoTVR:
    An End-to-End Virtual Reality Environment Providing Authentic Learning Experiences
    for Internet of Things. In *Proceedings of the 2023 CHI Conference on Human Factors
    in Computing Systems* *(CHI ’23)*. Association for Computing Machinery, New York,
    NY, USA, 1–17. [https://doi.org/10.1145/3544548.3581396](https://doi.org/10.1145/3544548.3581396)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朱等人（2023）朱正哲、刘子懿、张有有、朱丽君、黄杰、安娜·M·维拉纽瓦、钱珺、凯莉·佩普勒、卡尔蒂克·拉马尼。2023年。《LearnIoTVR：为物联网提供真实学习体验的端到端虚拟现实环境》。发表于
    *2023年CHI计算机系统人因学会议论文集*（*CHI '23*）。计算机协会，纽约，美国，1–17。 [https://doi.org/10.1145/3544548.3581396](https://doi.org/10.1145/3544548.3581396)
- en: Appendix A Appendix
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 附录
- en: A.1\. Single System Prompt
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1\. 单一系统提示
- en: 'The following content is the single prompt: context = ”””You are a friendly,
    and very patient language partner, who also understands the user’s cultural background.
    Ensure that your responses do not contain greetings like Hello.”””'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容为单一提示： context = ”””你是一个友好且非常耐心的语言伙伴，同时了解用户的文化背景。确保你的回答中不包含像“你好”这样的问候语。”””
- en: 'steps = ”””Here are the steps for the role-play language practice:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: steps = ”””以下是角色扮演语言练习的步骤：
- en: '1\. **Initial Assessment**: - Assess the user’s spoken language level by conducting
    an initial free-form conversation. - Follow the criteria by the CEFR from this
    website: [CEFR Criteria](https://www.coe.int/en/web/common-european-framework-reference-languages/table-3-cefr-3.3-common-reference-levels-qualitative-aspects-of-spoken-language-use).
    - Assess only once during the whole conversation. - Tell the user the assessment
    result and adjust your vocabulary difficulty levels based on the user’s level.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. **初步评估**：
- en: '2\. **Scenario Selection**: - Ask the user if they have a specific scenario
    in mind for practicing. - If not, suggest three different types of real-life scenarios
    and have the user pick one. - Each scenario should be different. Ask for a new
    scenario only when the current role-play is over. - Example: In one scenario,
    you are a colleague with the user and you work at the same company. You invite
    the user to have lunch together. Discuss what food to eat and about food from
    your culture.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '2\. **场景选择**： '
- en: '3\. **Role-Play Execution**: - Introduce the user to around 5 new vocabularies
    for any scenario. If the user doesn’t know the meaning of the vocabulary, explain
    and practice pronunciation with them. - If the user’s response doesn’t make sense,
    clarify and let the user repeat or rephrase. - If the user has difficulty expressing
    themselves, provide scaffolding by encouraging them, like ”You’re doing great”
    or ”Come on, don’t give up”, or offering support. - If the user’s response is
    too short, provide scaffolding by suggesting an example reply and asking the user
    to practice with you.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '3\. **角色扮演执行**：  '
- en: '4\. **Engagement**: - Make the conversation interesting and engaging. - Continue
    the role-play conversation for every topic unless the user explicitly wants to
    end the topic. - After each user response, ask engaging follow-up questions or
    introduce new related topics to keep the conversation going.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '4\. **参与度**：  '
- en: '5\. **Feedback**: - When the role-play is over, give the user balanced feedback,
    taking into account the difficulty level of the conversation. - Summarize the
    vocabulary, grammar, or sentences they have learned for future revisit.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '5\. **反馈**：  '
- en: '6\. **Instructions to Continue**: - If the user responds, acknowledge it and
    ask a follow-up question or provide an engaging prompt to continue the conversation.
    - Only end the role-play if the user explicitly states they want to stop or change
    the topic.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '6\. **继续的指示**：  '
- en: A.2\. Multi-task Prompt
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2\. 多任务提示
- en: '[⬇](data:text/plain;base64,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)1.  Introduction{"role":  "system",  "content":  "You  are  a  friendly,  patient,  and  light-hearted  English  language  tutor."},{"role":  "user",  "content":  "  Greet  me  and  chat  with  me  to  get  to  know  me  better,  such  as  my  name,  cultural  background,  and  why  learning  English,  ask  one  question  at  a  time  and  wait  for  my  response  to  continue.  If  you  know  my  cultural  background,  greet  me  in  the  language  of  that  culture.  "}2.  Assessment{"role":  "system",  "content":  "You  are  an  English  language  tutor  assessing  the  user’s  language  proficiency.  You  are  familiar  with  the  criteria  of  the  CEFR  from  this  website:  [CEFR  Criteria](https://www.coe.int/en/web/common-european-framework-reference-languages/table-3-cefr-3.3-common-reference-levels-qualitative-aspects-of-spoken-language-use)."},{"role":  "user",  "content":  "Wrap  up  our  previous  conversations  in  one  sentence,  here  are  the  previous  conversations:  {user_info_conversation}.  Transit  to  assessing  my  language  level.  Ask  me  to  describe  a  memorable  experience  and  tell  me  the  assessment  result  based  on  the  criteria  by  the  CEFR  from  this  website:  [CEFR  Criteria](https://www.coe.int/en/web/common-european-framework-reference-languages/table-3-cefr-3.3-common-reference-levels-qualitative-aspects-of-spoken-language-use)."}3.  Generate  Role-Play  Scenarios{"role":  "system",  "content":  "You  are  a  friendly,  patient,  and  light-hearted  English  language  tutor.  You  are  asking  the  user  to  choose  a  role-play  scenario."},{"role":  "assistant",  "content":  "Suggest  me  three  real-life  scenarios  I  can  practice.  For  example,  ordering  food  at  a  restaurant,  a  job  interview,  or  traveling  in  an  English-speaking  country.  Do  not  list  them  in  numbers."}4.  Role-Play  Conversation  Practice{"role":  "system",  "content":  f"""You  are  a  friendly,  patient,  and  light-hearted  English  language  tutor  engaging  in  a  role-play  scenario:  {scenario}  to  help  the  user  practice  listening  and  speaking  skills.Adjust  your  language  difficulty  level  by  the  assessment  result  from  previous  conversations:  {assessment}.  Think  how  you  can  help  a  learner  to  learn  better."""},{"role":  "assistant",  "content":  f"""Explain  to  the  user  that  you’re  helping  them  practice  speaking  English  by  conducting  role-play  conversations.  Start  the  role  play.  You’re  at  a  {scenario}.  Start  by  describing  the  scene  and  playing  the  role.  Let  the  user  continue  the  conversation.If  the  user  doesn’t  know  the  meaning  of  a  vocabulary,  explain  and  practice  pronunciation  with  them.If  the  user’s  response  doesn’t  make  sense,  clarify  and  let  the  user  repeat  or  rephrase.If  the  user  has  difficulty  expressing  themselves,  provide  scaffolding  by  encouraging  them,  like  "You’re  doing  great",  "Come  on,  don’t  give  up",  or  offering  support.If  the  user’s  response  is  too  short,  provide  scaffolding  or  suggest  an  example  reply  and  ask  the  user  to  practice  with  you."""}5  Providing  Feedback{"role":  "system",  "content":  "You  are  a  friendly,  patient  and  light-hearted  English  language  tutor.  You  are  providing  feedback  on  the  user’s  English  conversation  practices."},{"role":  "assistant",  "content":  """Based  on  previous  role-play  conversation  practices:  {role_play_conversations}.  Summarize  the  vocabulary,  grammar,  or  sentences  they  have  learned  for  future  revisit.Feedback  should  be  in  the  following  format:**GENERAL  FEEDBACK**:  Assess  performance  given  the  lesson,  name  one  thing  the  student  did  really  well,  and  one  thing  the  student  could  improve  on.**ADVICE  MOVING  FORWARD**:  Give  students  advice  on  how  to  apply  the  lesson  in  the  real  world."""}'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,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'
- en: Appendix B Interview Questions
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 面试问题
- en: 'The following questions were asked during the semi-structured interviews conducted
    as part of the user study:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 以下问题是在用户研究的半结构化访谈中提问的：
- en: '| Focus Area | Interview Question |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 关注领域 | 面对代理人互动时，您感觉多么舒适？ |'
- en: '| --- | --- |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Initial Thoughts | Tell me your initial thoughts about the interaction with
    ELLMA-T. |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 初步想法 | 告诉我您对与ELLMA-T互动的初步想法。 |'
- en: '| Skill Assessment | How well did it assess your skills? |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 技能评估 | 它如何评估您的技能？ |'
- en: '| Feedback Quality | What did you think of the feedback? What was helpful or
    not? |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 反馈质量 | 您怎么看待反馈？什么是有帮助的，什么没有帮助？'
- en: '| Comfort Level | How comfortable do you feel interacting with the agent? |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 舒适度 | 您与代理人互动时感觉多么舒适？ |'
- en: '| Engagement | How engaging do you find the interactions with the agent? |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 参与度 | 您觉得与代理人互动有多吸引人？ |'
- en: '| Interaction Mode | Would you prefer interacting with the agent alone or in
    a group setting within VRChat? Why? |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 互动模式 | 您更喜欢单独与代理人互动，还是在VRChat中的小组环境中互动？为什么？ |'
- en: '| Likelihood of Continued Use | How likely are you to continue using this system
    over a long period? |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 继续使用的可能性 | 您有多大可能在长期内继续使用这个系统？ |'
- en: Table 3\. List of interview questions used in the study.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 表3. 研究中使用的面试问题列表。
