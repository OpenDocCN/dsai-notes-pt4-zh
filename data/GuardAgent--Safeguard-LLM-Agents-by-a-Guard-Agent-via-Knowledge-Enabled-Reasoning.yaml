- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: '<!--yml  '
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类  '
- en: 'date: 2025-01-11 12:33:43'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 12:33:43  '
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '-->  '
- en: 'GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'GuardAgent：通过知识驱动推理保护LLM智能体  '
- en: 来源：[https://arxiv.org/html/2406.09187/](https://arxiv.org/html/2406.09187/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '来源：[https://arxiv.org/html/2406.09187/](https://arxiv.org/html/2406.09187/)  '
- en: Zhen Xiang^(1∗)  Linzhi Zheng²  Yanjie Li³  Junyuan Hong⁴  Qinbin Li⁵  Han Xie⁶
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 'Zhen Xiang^(1∗)  Linzhi Zheng²  Yanjie Li³  Junyuan Hong⁴  Qinbin Li⁵  Han
    Xie⁶  '
- en: Jiawei Zhang¹  Zidi Xiong¹  Chulin Xie¹  Carl Yang⁶  Dawn Song⁵  Bo Li^(17)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jiawei Zhang¹  Zidi Xiong¹  Chulin Xie¹  Carl Yang⁶  Dawn Song⁵  Bo Li^(17)
- en: ¹UIUC  ²Tsinghua University  ³Hong Kong Polytechnic University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '¹UIUC  ²清华大学  ³香港理工大学  '
- en: ⁴UT Austin  ⁵UC Berkeley  ⁶Emory University  ⁷ University of Chicago Correspondence
    to Zhen Xiang ⟨zhen.xiang.lance@gmail.com⟩and Bo Li ⟨bol@uchicago.edu⟩.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '⁴德州大学奥斯汀分校  ⁵加利福尼亚大学伯克利分校  ⁶埃默里大学  ⁷芝加哥大学 通信作者：Zhen Xiang ⟨zhen.xiang.lance@gmail.com⟩和Bo
    Li ⟨bol@uchicago.edu⟩。  '
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '摘要  '
- en: 'The rapid advancement of large language models (LLMs) has catalyzed the deployment
    of LLM-powered agents across numerous applications, raising new concerns regarding
    their safety and trustworthiness. In addition, existing methods for enhancing
    the safety of LLMs are not directly transferable to LLM-powered agents due to
    their diverse objectives and output modalities. In this paper, we propose GuardAgent,
    the first LLM agent as a guardrail to other LLM agents. Specifically, GuardAgent
    oversees a target LLM agent by checking whether its inputs/outputs satisfy a set
    of given guard requests (e.g., safety rules or privacy policies) defined by the
    users. GuardAgent comprises two steps: 1) creating a task plan by analyzing the
    provided guard requests, and 2) generating guardrail code based on the task plan
    and executing the code by calling APIs or using external engines. In both steps,
    an LLM is utilized as the core reasoning component, supplemented by in-context
    demonstrations retrieved from a memory module. Such knowledge-enabled reasoning
    allows GuardAgent to understand various textual guard requests and accurately
    “translate” them into executable code that provides reliable guardrails. Furthermore,
    GuardAgent is equipped with an extendable toolbox containing functions and APIs
    and requires no additional LLM training, which underscores its generalization
    capabilities and low operational overhead. In addition to GuardAgent , we propose
    two novel benchmarks: an EICU-AC benchmark for assessing privacy-related access
    control for healthcare agents and a Mind2Web-SC benchmark for safety evaluation
    for web agents. We show the effectiveness of GuardAgent on these two benchmarks
    with 98.7% and 90.0% guarding accuracy in moderating invalid inputs and outputs
    for the two types of agents, respectively. We also show that GuardAgent is able
    to define novel functions in adaption to emergent LLM agents and guard requests,
    which underscores its strong generalization capabilities.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '大型语言模型（LLMs）的快速发展促进了LLM驱动的智能体在众多应用中的部署，同时也引发了有关其安全性和可信度的新问题。此外，现有的增强LLM安全性的方法由于目标和输出模式的多样性，无法直接应用于LLM驱动的智能体。在本文中，我们提出了GuardAgent，这是第一个作为其他LLM智能体保护屏障的LLM智能体。具体而言，GuardAgent通过检查目标LLM智能体的输入/输出是否满足用户定义的一系列保护请求（例如安全规则或隐私政策），来监督目标LLM智能体。GuardAgent包括两个步骤：1）通过分析提供的保护请求创建任务计划，2）根据任务计划生成保护屏障代码，并通过调用API或使用外部引擎执行该代码。在这两个步骤中，LLM作为核心推理组件，辅以从内存模块中检索的上下文示范。这样的知识驱动推理使得GuardAgent能够理解各种文本保护请求，并准确地将其“翻译”成可执行的代码，从而提供可靠的保护屏障。此外，GuardAgent配备了一个可扩展的工具箱，包含各种功能和API，并且不需要额外的LLM训练，这突显了其强大的泛化能力和低运行开销。除了GuardAgent，我们还提出了两个新基准：EICU-AC基准，用于评估面向医疗保健智能体的隐私相关访问控制，和Mind2Web-SC基准，用于评估Web智能体的安全性。我们展示了GuardAgent在这两个基准上的有效性，分别在两类智能体的无效输入和输出调节中，达到了98.7%和90.0%的保护准确率。我们还展示了GuardAgent能够根据新兴的LLM智能体和保护请求定义新的功能，这突显了其强大的泛化能力。  '
- en: '![Refer to caption](img/39812941eca41c307acaff83c117efdf.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![Refer to caption](img/39812941eca41c307acaff83c117efdf.png)  '
- en: 'Figure 1: Illustration of GuardAgent as a guardrail to a target LLM agent.
    The inputs to GuardAgent include a) a set of guard requests informed by a specification
    of the target agent and b) the test-time inputs and outputs of the target agent.
    GuardAgent first generates an action plan following a few shots of demonstrations
    retrieved from the memory. Then, a guardrail code is generated following the action
    plan based on both demonstrations and a list of callable functions. The outputs/actions
    of the target agent will be denied if GuardAgent detects a violation of the guard
    requests.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GuardAgent作为目标LLM代理的保护栏的示意图。GuardAgent的输入包括：a) 由目标代理规范提供的信息集的保护请求，b) 目标代理的测试时输入和输出。GuardAgent首先根据从记忆中检索到的几次示范生成一个行动计划。然后，基于示范和可调用函数列表，按照行动计划生成一个保护栏代码。如果GuardAgent检测到违反保护请求的行为，则目标代理的输出/行动将被拒绝。
- en: 1 Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: AI agents empowered by large language models (LLMs) have showcased remarkable
    performance across diverse application domains, including finance [[24](https://arxiv.org/html/2406.09187v1#bib.bib24)],
    healthcare [[2](https://arxiv.org/html/2406.09187v1#bib.bib2), [17](https://arxiv.org/html/2406.09187v1#bib.bib17),
    [22](https://arxiv.org/html/2406.09187v1#bib.bib22), [18](https://arxiv.org/html/2406.09187v1#bib.bib18),
    [11](https://arxiv.org/html/2406.09187v1#bib.bib11)], daily work [[4](https://arxiv.org/html/2406.09187v1#bib.bib4),
    [5](https://arxiv.org/html/2406.09187v1#bib.bib5), [28](https://arxiv.org/html/2406.09187v1#bib.bib28),
    [27](https://arxiv.org/html/2406.09187v1#bib.bib27)], and autonomous driving [[3](https://arxiv.org/html/2406.09187v1#bib.bib3),
    [8](https://arxiv.org/html/2406.09187v1#bib.bib8), [12](https://arxiv.org/html/2406.09187v1#bib.bib12)].
    For each user query, these agents typically employ an LLM for task planning, leveraging
    the reasoning capability of the LLM with the optional support of long-term memory
    from previous use cases [[10](https://arxiv.org/html/2406.09187v1#bib.bib10)].
    The proposed plan is then executed by calling external tools (e.g., through APIs)
    with potential interaction with the environment [[23](https://arxiv.org/html/2406.09187v1#bib.bib23)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由大语言模型（LLMs）赋能的AI代理在多个应用领域展现出了卓越的表现，包括金融[[24](https://arxiv.org/html/2406.09187v1#bib.bib24)]、医疗[[2](https://arxiv.org/html/2406.09187v1#bib.bib2),
    [17](https://arxiv.org/html/2406.09187v1#bib.bib17), [22](https://arxiv.org/html/2406.09187v1#bib.bib22),
    [18](https://arxiv.org/html/2406.09187v1#bib.bib18), [11](https://arxiv.org/html/2406.09187v1#bib.bib11)]、日常工作[[4](https://arxiv.org/html/2406.09187v1#bib.bib4),
    [5](https://arxiv.org/html/2406.09187v1#bib.bib5), [28](https://arxiv.org/html/2406.09187v1#bib.bib28),
    [27](https://arxiv.org/html/2406.09187v1#bib.bib27)]，以及自动驾驶[[3](https://arxiv.org/html/2406.09187v1#bib.bib3),
    [8](https://arxiv.org/html/2406.09187v1#bib.bib8), [12](https://arxiv.org/html/2406.09187v1#bib.bib12)]。对于每个用户查询，这些代理通常使用LLM进行任务规划，利用LLM的推理能力，并通过可选的长期记忆支持（来自先前的使用案例）[[10](https://arxiv.org/html/2406.09187v1#bib.bib10)]。然后，通过调用外部工具（例如，通过API）并可能与环境进行交互[[23](https://arxiv.org/html/2406.09187v1#bib.bib23)]来执行提出的计划。
- en: Unfortunately, the current development of LLM agents primarily focuses on their
    effectiveness in solving complex tasks while significantly overlooking their potential
    for misuse, which can lead to harmful consequences. For example, if misused by
    unauthorized personnel, a healthcare LLM agent could easily expose confidential
    patient information [[25](https://arxiv.org/html/2406.09187v1#bib.bib25)]. Indeed,
    some LLM agents, particularly those used in high-stakes applications like autonomous
    driving, are equipped with safety controls to prevent the execution of undesired
    dangerous actions [[12](https://arxiv.org/html/2406.09187v1#bib.bib12), [6](https://arxiv.org/html/2406.09187v1#bib.bib6)].
    However, these task-specific guardrails are hardwired into the LLM agent and,
    therefore, cannot be generalized to other agents (e.g., for healthcare) with different
    guard requests (e.g., for privacy instead of safety).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，目前LLM代理的发展主要集中在它们在解决复杂任务方面的有效性，而在很大程度上忽视了它们被滥用的潜力，这可能导致有害的后果。例如，如果被未经授权的人员滥用，医疗LLM代理可能会轻易泄露患者的机密信息[[25](https://arxiv.org/html/2406.09187v1#bib.bib25)]。实际上，一些LLM代理，特别是在自动驾驶等高风险应用中使用的代理，配备了安全控制，以防止执行不期望的危险行为[[12](https://arxiv.org/html/2406.09187v1#bib.bib12),
    [6](https://arxiv.org/html/2406.09187v1#bib.bib6)]。然而，这些特定任务的保护栏是硬编码到LLM代理中的，因此无法推广到具有不同保护请求（例如，针对隐私而非安全的医疗代理）其他代理上。
- en: On the other hand, guardrails for LLMs provide input and output moderation to
    detect and mitigate a wide range of potential harms [[13](https://arxiv.org/html/2406.09187v1#bib.bib13),
    [9](https://arxiv.org/html/2406.09187v1#bib.bib9), [16](https://arxiv.org/html/2406.09187v1#bib.bib16),
    [7](https://arxiv.org/html/2406.09187v1#bib.bib7), [26](https://arxiv.org/html/2406.09187v1#bib.bib26)].
    This is typically achieved by building the guardrail upon another pre-trained
    LLM to contextually understand the input and output of the target LLM. More importantly,
    the ‘non-invasiveness’ of guardrails, achieved through their parallel deployment
    alongside the target LLM, allows for their application to new models and harmfulness
    taxonomies with only minor modifications. However, LLM agents are significantly
    different from LLMs, as they involve a much broader range of output modalities
    and highly specific guard requests. For instance, a web agent empowered by LLM
    might generate actions like clicking a designated button on a webpage [[27](https://arxiv.org/html/2406.09187v1#bib.bib27)].
    The guard requests here could involve safety rules that prohibit certain users
    (e.g., those under a certain age) from purchasing specific items (e.g., alcoholic
    beverages). Clearly, existing guardrails designed solely to moderate the textual
    inputs and outputs of LLMs cannot address such intricate guard requests.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，LLM 的护栏提供了输入和输出的审查，以检测和减轻广泛的潜在危害[[13](https://arxiv.org/html/2406.09187v1#bib.bib13),
    [9](https://arxiv.org/html/2406.09187v1#bib.bib9), [16](https://arxiv.org/html/2406.09187v1#bib.bib16),
    [7](https://arxiv.org/html/2406.09187v1#bib.bib7), [26](https://arxiv.org/html/2406.09187v1#bib.bib26)]。这通常是通过在另一个预训练的
    LLM 上建立护栏来实现的，从而能够在上下文中理解目标 LLM 的输入和输出。更重要的是，护栏的“非侵入性”特性，通过与目标 LLM 并行部署，允许它们仅通过少量修改就能够应用于新模型和有害性分类。然而，LLM
    代理与 LLM 有显著区别，因为它们涉及更广泛的输出方式和高度特定的护栏请求。例如，一个由 LLM 驱动的网页代理可能会生成诸如点击网页上指定按钮的动作[[27](https://arxiv.org/html/2406.09187v1#bib.bib27)]。在这里，护栏请求可能涉及安全规则，禁止某些用户（例如，未满特定年龄的用户）购买特定物品（例如，酒精饮料）。显然，现有仅用于审查
    LLM 文本输入和输出的护栏无法处理如此复杂的护栏请求。
- en: In this paper, we present the first study on guardrails for LLM agents. We propose
    GuardAgent, the first generalizable framework that uses an LLM agent to safeguard
    other LLM agents (referred to as ‘target agents’ henceforth) by adhering to diverse
    real-world guard requests from users, such as safety rules or privacy policies.
    The deployment of GuardAgent requires the prescription of a set of textural guard
    requests informed by a specification of the target agent (e.g., the format of
    agent output and logs). During the inference, user inputs to the target agent,
    along with associated outputs and logs, will be provided to GuardAgent for examination
    to determine whether the guard requests are satisfied or not. Specifically, GuardAgent
    first uses an LLM to generate an action plan based on the guard requests and the
    inputs and outputs of the target agent. Subsequently, the LLM transforms the action
    plan into a guardrail code, which is then executed by calling an external engine.
    For both the action plan and the guardrail code generation, the LLM is provided
    with related demonstrations retrieved from a memory module, which archives inputs
    and outputs from prior use cases. Such knowledge-enabled reasoning is the foundation
    for GuardAgent to understand diverse guard requests for different types of LLM
    agents. The design of our GuardAgent offers three key advantages. Firstly, GuardAgent
    can be easily generalized to safeguard new target agents by simply uploading new
    functions to its toolbox. Secondly, GuardAgent provides guardrails by code generation
    and execution, which is more reliable than guardrails solely based on natural
    language. Thirdly, GuardAgent employs LLMs by in-context learning, enabling direct
    utilization of off-the-shelf LLMs without the need for additional training.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们首次研究了针对LLM代理的防护措施。我们提出了GuardAgent，这是第一个可泛化的框架，利用LLM代理通过遵循用户的多种现实世界防护请求（如安全规则或隐私政策）来保障其他LLM代理（以下简称“目标代理”）。部署GuardAgent需要规定一组基于目标代理规范的文本防护请求（例如，代理输出和日志的格式）。在推理过程中，目标代理的用户输入以及相关的输出和日志将被提供给GuardAgent进行检查，以确定防护请求是否满足。具体来说，GuardAgent首先利用LLM根据防护请求和目标代理的输入输出生成行动计划。随后，LLM将行动计划转化为防护代码，并通过调用外部引擎来执行该代码。对于行动计划和防护代码的生成，LLM会通过内存模块获取相关示范，内存模块保存了之前使用案例的输入和输出。这种基于知识的推理是GuardAgent理解不同类型LLM代理的多种防护请求的基础。我们的GuardAgent设计有三个主要优点。首先，GuardAgent可以通过简单地向其工具箱上传新功能，轻松泛化以保障新的目标代理。其次，GuardAgent通过代码生成和执行提供防护措施，这比仅基于自然语言的防护措施更可靠。第三，GuardAgent通过上下文学习使用LLM，能够直接利用现成的LLM，无需额外训练。
- en: 'Before introducing GuardAgent in Sec. [4](https://arxiv.org/html/2406.09187v1#S4
    "4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning"), we investigate diverse guard requests for different
    types of LLM agents and propose two novel benchmarks in Sec. [3](https://arxiv.org/html/2406.09187v1#S3
    "3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by
    a Guard Agent via Knowledge-Enabled Reasoning"). The first benchmark, EICU-AC,
    is designed to assess the effectiveness of access control for LLM agents for healthcare.
    The second benchmark, Mind2Web-SC, evaluates safety control for LLM-powered web
    agents. These two benchmarks are used to evaluate our GuardAgent in our experiments
    in Sec. [5](https://arxiv.org/html/2406.09187v1#S5 "5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"). Note
    that the two types of guard requests considered here – access control and safety
    control – are closely related to privacy and safety, respectively, which are critical
    perspectives of AI trustworthiness [[19](https://arxiv.org/html/2406.09187v1#bib.bib19)].
    Our technical contributions are summarized as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '在介绍《GuardAgent》框架之前（见第[4节](https://arxiv.org/html/2406.09187v1#S4 "4 GuardAgent
    Framework ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")），我们研究了针对不同类型LLM代理的多样化保护请求，并在第[3节](https://arxiv.org/html/2406.09187v1#S3
    "3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by
    a Guard Agent via Knowledge-Enabled Reasoning")提出了两个新的基准。第一个基准，EICU-AC，旨在评估医疗领域LLM代理的访问控制效果。第二个基准，Mind2Web-SC，用于评估LLM驱动的网页代理的安全控制。这两个基准被用于在第[5节](https://arxiv.org/html/2406.09187v1#S5
    "5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")的实验中评估我们的GuardAgent。请注意，本文所考虑的两类保护请求——访问控制和安全控制——分别与隐私和安全密切相关，而这两者是AI可信度的关键视角[[19](https://arxiv.org/html/2406.09187v1#bib.bib19)]。我们的技术贡献总结如下：'
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose GuardAgent, the first LLM agent framework providing guardrails to
    other LLM agents via knowledge-enabled reasoning in order to address diverse user
    guard requests.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了GuardAgent，这是第一个通过知识启用推理为其他LLM代理提供保护的LLM代理框架，旨在处理各种用户的保护请求。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a novel design for GuardAgent, which comprises knowledge-enabled
    task planning using in-context demonstrations, followed by guardrail code generation
    involving an extendable array of functions. Such design endows GuardAgent with
    strong generalization capabilities, reliable guardrail generation, and no need
    for additional training.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新的GuardAgent设计，包含通过上下文演示启用的知识任务规划，随后是涉及可扩展功能数组的保护代码生成。这样的设计赋予了GuardAgent强大的泛化能力、可靠的保护代码生成，并且无需额外训练。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We create two benchmarks, EICU-AC and Mind2Web-SC, for evaluating privacy-related
    access control for healthcare agents and safety control for web agents, respectively.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们创建了两个基准，EICU-AC和Mind2Web-SC，分别用于评估医疗代理的隐私相关访问控制和网页代理的安全控制。
- en: •
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We show that GuardAgent effectively provides guardrails to 1) an EHRAgent for
    healthcare with a 98.7% guarding accuracy in access control and 2) a SeeAct web
    agent with a 90.0% guarding accuracy in safety control. We also demonstrate the
    capabilities of GuardAgent in defining new functions during guardrail code generation
    and execution.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了GuardAgent有效地为1）医疗领域的EHRAgent提供了98.7%的访问控制保护精度，以及2）为SeeAct网页代理提供了90.0%的安全控制保护精度。我们还展示了GuardAgent在保护代码生成和执行过程中定义新功能的能力。
- en: 2 Related Work
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 相关工作
- en: LLM agents refer to AI agents that use LLMs as their central engine for task
    understanding and planning and then execute the plan by interacting with the environment
    (e.g., by calling third-party APIs) [[21](https://arxiv.org/html/2406.09187v1#bib.bib21)].
    Such fundamental difference from LLMs (with purely textual outputs) enables LLM
    agents to be deployed in diverse applications, including finance [[24](https://arxiv.org/html/2406.09187v1#bib.bib24)],
    healthcare [[2](https://arxiv.org/html/2406.09187v1#bib.bib2), [17](https://arxiv.org/html/2406.09187v1#bib.bib17),
    [22](https://arxiv.org/html/2406.09187v1#bib.bib22), [18](https://arxiv.org/html/2406.09187v1#bib.bib18),
    [11](https://arxiv.org/html/2406.09187v1#bib.bib11)], daily work [[4](https://arxiv.org/html/2406.09187v1#bib.bib4),
    [5](https://arxiv.org/html/2406.09187v1#bib.bib5), [28](https://arxiv.org/html/2406.09187v1#bib.bib28),
    [27](https://arxiv.org/html/2406.09187v1#bib.bib27)], and autonomous driving [[3](https://arxiv.org/html/2406.09187v1#bib.bib3),
    [8](https://arxiv.org/html/2406.09187v1#bib.bib8), [12](https://arxiv.org/html/2406.09187v1#bib.bib12)].
    LLM agents are also commonly equipped with a retrievable memory module, allowing
    them to perform knowledge-enabled reasoning to handle different tasks within its
    application domain [[10](https://arxiv.org/html/2406.09187v1#bib.bib10)]. Our
    GuardAgent is a typical LLM agent, but with different objectives from existing
    agents, as it is the first one to safeguard other LLM agents.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理指的是将LLM作为其任务理解和规划的核心引擎，并通过与环境交互（例如，通过调用第三方API）执行计划的AI代理[[21](https://arxiv.org/html/2406.09187v1#bib.bib21)]。与LLM（仅输出文本）存在的根本区别使得LLM代理可以部署在多个应用领域，包括金融[[24](https://arxiv.org/html/2406.09187v1#bib.bib24)]、医疗保健[[2](https://arxiv.org/html/2406.09187v1#bib.bib2)、[17](https://arxiv.org/html/2406.09187v1#bib.bib17)、[22](https://arxiv.org/html/2406.09187v1#bib.bib22)、[18](https://arxiv.org/html/2406.09187v1#bib.bib18)、[11](https://arxiv.org/html/2406.09187v1#bib.bib11)]、日常工作[[4](https://arxiv.org/html/2406.09187v1#bib.bib4)、[5](https://arxiv.org/html/2406.09187v1#bib.bib5)、[28](https://arxiv.org/html/2406.09187v1#bib.bib28)、[27](https://arxiv.org/html/2406.09187v1#bib.bib27)]和自动驾驶[[3](https://arxiv.org/html/2406.09187v1#bib.bib3)、[8](https://arxiv.org/html/2406.09187v1#bib.bib8)、[12](https://arxiv.org/html/2406.09187v1#bib.bib12)]。LLM代理通常还配备了可检索的记忆模块，使它们能够执行知识驱动的推理，从而处理其应用领域中的不同任务[[10](https://arxiv.org/html/2406.09187v1#bib.bib10)]。我们的GuardAgent是一个典型的LLM代理，但与现有代理的目标不同，因为它是第一个用来保护其他LLM代理的系统。
- en: LLM-based guardrails belong to a family of moderation approaches for harmfulness
    mitigation [[25](https://arxiv.org/html/2406.09187v1#bib.bib25), [15](https://arxiv.org/html/2406.09187v1#bib.bib15)].
    Traditional guardrails were operated as classifiers trained on categorically labeled
    content [[13](https://arxiv.org/html/2406.09187v1#bib.bib13), [9](https://arxiv.org/html/2406.09187v1#bib.bib9)],
    while recently, guardrails based on LLMs with broader contextual understanding
    have been developed and shown strong generalization capabilities. However, existing
    guardrails for LLMs, either ‘model guarding models’ ([[16](https://arxiv.org/html/2406.09187v1#bib.bib16),
    [7](https://arxiv.org/html/2406.09187v1#bib.bib7), [26](https://arxiv.org/html/2406.09187v1#bib.bib26)])
    or ‘agent guarding models’ ([[1](https://arxiv.org/html/2406.09187v1#bib.bib1)]),
    are designed for harmfulness defined on natural language. They cannot be directly
    used to safeguard LLM agents with diverse output modalities. In this paper, we
    propose GuardAgent, the first ‘agent guarding agents’ framework, and show its
    advantage over ‘model guarding agents’ approaches in our experiments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的防护措施属于一种有害性减轻的审查方法[[25](https://arxiv.org/html/2406.09187v1#bib.bib25)、[15](https://arxiv.org/html/2406.09187v1#bib.bib15)]。传统的防护措施作为分类器，训练于分类标记的内容[[13](https://arxiv.org/html/2406.09187v1#bib.bib13)、[9](https://arxiv.org/html/2406.09187v1#bib.bib9)]，而最近，基于LLM且具有更广泛上下文理解的防护措施已经被开发，并展现出强大的泛化能力。然而，现有的LLM防护措施，无论是‘模型防护模型’([[16](https://arxiv.org/html/2406.09187v1#bib.bib16)、[7](https://arxiv.org/html/2406.09187v1#bib.bib7)、[26](https://arxiv.org/html/2406.09187v1#bib.bib26)])还是‘代理防护模型’([[1](https://arxiv.org/html/2406.09187v1#bib.bib1)]），都是为了应对自然语言中的有害性定义的。它们不能直接用于保护具有多样化输出方式的LLM代理。在本文中，我们提出了GuardAgent，首个‘代理防护代理’框架，并通过实验展示了其相较于‘模型防护代理’方法的优势。
- en: 3 Safety Requests for Diverse LLM Agents
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 针对多样化LLM代理的安全请求
- en: 'Before introducing our GuardAgent, we investigate safety requests for different
    types of LLM agents in this section. We focus on two representative LLM agents:
    an EHRAgent for healthcare and a web agent SeeAct. In particular, EHRAgent represents
    LLM agents for high-stake tasks, while SeeAct represents generalist LLM agents
    for diverse tasks. We briefly review these two agents, their designated tasks,
    and their original evaluation benchmarks. More importantly, we propose two novel
    benchmarks for different safety requests: 1) EICU-AC, which assesses access control
    for healthcare agents like EHRAgent, and 2) Mind2Web-SC, which evaluates safety
    control for web agents like SeeAct. Then, we conduct a preliminary study to test
    ‘invasive’ approaches for access control and safety control, which are based on
    naive instructions injected into the system prompts of EHRAgent and SeeAct, respectively;
    their ineffectiveness and poor generalization motivate the need for our GuardAgent.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍我们的 GuardAgent 之前，我们将在本节中调查不同类型的 LLM 代理的安全请求。我们重点关注两个具有代表性的 LLM 代理：一个用于医疗保健的
    EHRAgent 和一个名为 SeeAct 的网页代理。特别地，EHRAgent 代表了用于高风险任务的 LLM 代理，而 SeeAct 代表了用于多任务的通用
    LLM 代理。我们简要回顾这两个代理，它们的指定任务以及原始的评估基准。更重要的是，我们提出了两个新颖的基准，用于不同的安全请求：1）EICU-AC，用于评估像
    EHRAgent 这样的医疗保健代理的访问控制；2）Mind2Web-SC，用于评估像 SeeAct 这样的网页代理的安全控制。然后，我们进行了一项初步研究，测试了基于注入到
    EHRAgent 和 SeeAct 系统提示中的简单指令的“侵入性”方法用于访问控制和安全控制；它们的低效性和差的泛化能力促使我们提出了 GuardAgent。
- en: '![Refer to caption](img/8c0c8ac5489b1f1a1460c78ba2c1f6da.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8c0c8ac5489b1f1a1460c78ba2c1f6da.png)'
- en: 'Figure 2: An example from EICU-AC (left) and an example from Mind2Web-SC (right).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：EICU-AC 的一个示例（左）和 Mind2Web-SC 的一个示例（右）。
- en: 3.1 EHRAgent and EICU-AC Benchmark
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 EHRAgent 和 EICU-AC 基准
- en: EHRAgent
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: EHRAgent
- en: 'EHRAgent is designed to respond to healthcare-related queries by generating
    code to retrieve and analyze data from provided databases [[17](https://arxiv.org/html/2406.09187v1#bib.bib17)].
    EHRAgent has been evaluated and shown decent performance on several benchmarks,
    including an EICU dataset containing questions regarding the clinical care of
    ICU patients (see Fig. [2](https://arxiv.org/html/2406.09187v1#S3.F2 "Figure 2
    ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") for example) and 10 relevant
    databases [[14](https://arxiv.org/html/2406.09187v1#bib.bib14)]. Each database
    contains several types of patient information stored in different columns. In
    practical healthcare systems, it is crucial to restrict access to specific databases
    based on user identities. For example, personnel in general administration should
    not have access to patient diagnosis details. Thus, LLM agents for healthcare,
    such as EHRAgent, should be able to deny requests for information from the patient
    diagnosis database when the user is from the general administration. In essence,
    these LLM agents should incorporate access controls to safeguard patient privacy.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 'EHRAgent 设计用于通过生成代码从提供的数据库中检索和分析数据，以响应与医疗保健相关的查询 [[17](https://arxiv.org/html/2406.09187v1#bib.bib17)]。EHRAgent
    已在多个基准上进行评估，并表现出良好的性能，包括一个包含 ICU 患者临床护理问题的 EICU 数据集（例如，见图 [2](https://arxiv.org/html/2406.09187v1#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")）以及 10 个相关的数据库 [[14](https://arxiv.org/html/2406.09187v1#bib.bib14)]。每个数据库包含多种类型的患者信息，这些信息存储在不同的列中。在实际的医疗保健系统中，基于用户身份限制对特定数据库的访问至关重要。例如，行政人员不应访问患者诊断详情。因此，像
    EHRAgent 这样的医疗保健 LLM 代理应该能够在用户属于一般行政部门时，拒绝对患者诊断数据库的信息请求。本质上，这些 LLM 代理应该具备访问控制功能，以保护患者隐私。'
- en: Proposed EICU-AC benchmark
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提议的 EICU-AC 基准
- en: 'In this paper, we create an EICU-AC benchmark from EICU to evaluate Access
    Control approaches for EHRAgent (and potentially other healthcare agents that
    require database retrieval). We define three roles for the user of EHRAgent (and
    other similar target agents): ‘physician’, ‘nursing’, and ‘general administration’.
    The access control being evaluated is supposed to ensure that each identity has
    access to only a subset of databases and columns of the EICU benchmark. We generate
    the ground truth access permission for each role by querying ChatGPT (see App.
    [A.1](https://arxiv.org/html/2406.09187v1#A1.SS1 "A.1 Role-Based Access Permission
    ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") for more details). While generic
    access control approaches should be invariant to the specific roles and their
    access permissions, we have made these choices to simulate practical healthcare
    scenarios. Then, each example in EICU-AC is designed to include the following
    information: 1) a healthcare-related question and the correct answer, 2) the databases
    and the columns required to answer the question, 3) a user identity/role, 4) a
    binary label ‘0’ if all required databases and columns are accessible to the given
    identity or ‘1’ otherwise, and 5) the required databases and columns inaccessible
    to the identity if the label is ‘1’. An illustration of a generated EICU-AC example
    is shown in Fig. [2](https://arxiv.org/html/2406.09187v1#S3.F2 "Figure 2 ‣ 3 Safety
    Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning").'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '本文中，我们从EICU创建了一个EICU-AC基准，用于评估EHRAgent的访问控制方法（以及可能需要数据库检索的其他医疗代理）。我们为EHRAgent（以及其他类似的目标代理）的用户定义了三个角色：“医生”，“护士”和“一般管理”。所评估的访问控制应确保每个身份仅能访问EICU基准的部分数据库和列。我们通过查询ChatGPT生成每个角色的真实访问权限（更多细节请参见附录[A.1](https://arxiv.org/html/2406.09187v1#A1.SS1
    "A.1 Role-Based Access Permission ‣ Appendix A Details About the EICU-AC Benchmark
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")）。虽然通用的访问控制方法应对特定角色及其访问权限保持不变，但我们做出这些选择是为了模拟实际的医疗场景。然后，EICU-AC中的每个示例设计包括以下信息：1）一个与医疗相关的问题及其正确答案，2）回答该问题所需的数据库和列，3）一个用户身份/角色，4）一个二进制标签“0”，如果给定身份可以访问所有所需的数据库和列，或者“1”表示不能访问，5）如果标签为“1”，则给定身份无法访问的数据库和列。生成的EICU-AC示例的插图见图[2](https://arxiv.org/html/2406.09187v1#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")。'
- en: 'In particular, all questions in EICU-AC are sampled or adapted from the EICU
    dataset. We keep questions from EICU that are correctly answered by EHRAgent using
    GPT-4 (at temperature zero) as the core LLM so that the evaluation using our benchmark
    will mainly focus on access control without much influence from the task performance.
    Initially, we generate three EICU-AC examples from each of these questions by
    assigning them the three roles respectively. After labeling each example based
    on the ground truth accessibility of its assigned role, we find for all three
    identities that the two labels are highly imbalanced. Thus, for each identity,
    we remove some of the generated examples while adding new ones to achieve a relative
    balance between the two labels (see more details in App. [A.2](https://arxiv.org/html/2406.09187v1#A1.SS2
    "A.2 Sampling from EICU ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")). Ultimately,
    our EICU-AC contains 52, 57, and 45 examples labeled to ‘0’ for ‘physician’, ‘nursing’,
    and ‘general administration’, respectively, and 46, 55, and 61 examples labeled
    to ‘1’ for the three roles, respectively. Moreover, among these 316 examples,
    there are 226 unique questions spanning 51 different ICU information categories,
    which underscores the diversity of our EICU-AC.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '具体而言，EICU-AC 中的所有问题都来自 EICU 数据集或经过调整。我们保留那些由 EHRAgent 使用 GPT-4（在零温度下）作为核心 LLM
    正确回答的 EICU 问题，以便通过我们的基准进行评估时，主要聚焦于访问控制，而不受任务表现的太大影响。最初，我们通过分别为每个问题分配三个角色，生成三个
    EICU-AC 示例。然后，我们根据每个示例所分配角色的实际访问权限进行标注，发现所有三个身份的标签非常不平衡。因此，对于每个身份，我们删除一些生成的示例，同时添加新的示例，以实现两个标签之间的相对平衡（更多细节见附录[A.2](https://arxiv.org/html/2406.09187v1#A1.SS2
    "A.2 Sampling from EICU ‣ Appendix A Details About the EICU-AC Benchmark ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")）。最终，我们的
    EICU-AC 包含分别标注为‘0’的52个、57个和45个示例，分别对应‘医生’、‘护理’和‘普通行政’，以及分别标注为‘1’的46个、55个和61个示例。此外，在这些316个示例中，共有226个独特的问题，涵盖了51个不同的
    ICU 信息类别，这凸显了我们 EICU-AC 的多样性。  '
- en: 3.2 SeeAct and Mind2Web-SC Benchmark
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 SeeAct 和 Mind2Web-SC 基准
- en: SeeAct
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 'SeeAct  '
- en: 'SeeAct is a generalist web agent that follows natural language instructions
    to complete tasks on any given website by sequentially generating actions, including
    clicking on a button, typing specific texts, etc. (see Fig. [2](https://arxiv.org/html/2406.09187v1#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning") for example) [[27](https://arxiv.org/html/2406.09187v1#bib.bib27)].
    In the original paper, SeeAct is evaluated on the Mind2Web benchmark containing
    over 2,000 complex web tasks spanning 137 websites across 31 domains (e.g., car
    rental, shopping, entertainment, etc.) [[4](https://arxiv.org/html/2406.09187v1#bib.bib4)].
    However, it is essential for practical web agents like SeeAct to integrate safety
    controls that restrict certain actions for specific users. For example, in most
    regions of the world, a driver’s license is required for car rental.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'SeeAct 是一个通用的网络代理，通过自然语言指令在任何给定的网站上执行任务，任务通过连续生成的操作完成，包括点击按钮、输入特定文本等（例如，见图[2](https://arxiv.org/html/2406.09187v1#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")）[[27](https://arxiv.org/html/2406.09187v1#bib.bib27)]。在原始论文中，SeeAct
    在 Mind2Web 基准测试上进行了评估，该基准包含超过2,000个复杂的网络任务，跨越31个领域的137个网站（例如，汽车租赁、购物、娱乐等）[[4](https://arxiv.org/html/2406.09187v1#bib.bib4)]。然而，对于像
    SeeAct 这样的实际网络代理来说，集成安全控制至关重要，这些控制限制特定用户的某些操作。例如，在世界大多数地区，租车需要持有驾驶执照。  '
- en: Proposed Mind2Web-SC benchmark
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '提出的 Mind2Web-SC 基准  '
- en: 'We create a Mind2Web-SC benchmark to evaluate Safety Control applicable to
    SeeAct and other web agents that operate based on action generation. The objective
    of safety control is to ensure that the agent obeys six rules we created based
    on common web regulations and regional conventions: 1) user must be a member to
    shop, 2) unvaccinated user cannot book a flight, 3) user without a driver’s license
    cannot buy or rent a car, 4) user aged under 18 cannot book a hotel, 5) user must
    be in certain countries to search movies/music/video, 6) user under 15 cannot
    apply for jobs. Again, these rules are proposed solely for evaluation purposes
    and do not reflect the personal views or attitudes of the authors.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个Mind2Web-SC基准，用于评估适用于SeeAct和其他基于动作生成的网页代理的安全控制。安全控制的目标是确保代理遵守我们基于常见网络法规和地区惯例制定的六条规则：1）用户必须是会员才能购物，2）未接种疫苗的用户不能预订航班，3）没有驾驶执照的用户不能购买或租赁汽车，4）未满18岁的用户不能预订酒店，5）用户必须在特定国家才能搜索电影/音乐/视频，6）15岁以下的用户不能申请工作。再次声明，这些规则仅为评估目的而提出，不代表作者的个人观点或态度。
- en: 'The examples in Mind2Web-SC are created by the following steps. First, we obtain
    all tasks with correct action prediction by SeeAct (using LLaVA-1.5 as the core
    LLM) from the travel, shop, and entertainment domains of the test set of Mind2Web.
    Second, for each task, we randomly create a user profile containing ‘age’ in integer
    and ‘domestic’, ‘dr_license’, ‘vaccine’, and ‘membership’, all boolean (see the
    right of Fig. [2](https://arxiv.org/html/2406.09187v1#S3.F2 "Figure 2 ‣ 3 Safety
    Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning")). Note that each of these six user information
    categories is non-trivial, as it is related to at least one of the six safety
    rules we created. Third, we manually label each example based on the task and
    the user information. If the task itself is not related to any of the six rules,
    the example will be labeled to ‘0’ for ‘action permitted’. If the task is related
    to at least one of the rules (e.g. the one for car rental), we check the user
    information and will label the example to ‘1’ for ‘action denied’ if the rule
    is violated (e.g. ‘dr_license’ is ‘false’) and ‘0’ otherwise. For each example
    labeled to ‘1’, the violated rules are also included in our benchmark. Finally,
    we balance the two classes by creating additional examples (based on existing
    tasks but with different user information) while removing some examples with tasks
    irrelevant to any of the rules (see details in App. [B](https://arxiv.org/html/2406.09187v1#A2
    "Appendix B Details About the Mind2Web-SC Benchmark ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")). The created Mind2Web-SC
    benchmark contains 100 examples in each class with only unique tasks within the
    class.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'Mind2Web-SC中的示例是通过以下步骤创建的。首先，我们从Mind2Web测试集的旅行、购物和娱乐领域获取SeeAct（使用LLaVA-1.5作为核心LLM）正确动作预测的所有任务。其次，对于每个任务，我们随机创建一个用户档案，包含整数型的‘年龄’以及布尔型的‘国内’、‘驾驶执照’、‘疫苗’和‘会员资格’（参见图[2](https://arxiv.org/html/2406.09187v1#S3.F2
    "Figure 2 ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")右侧）。请注意，这六个用户信息类别中的每一项都不是琐碎的，因为它至少与我们制定的六条安全规则中的一条相关。第三，我们根据任务和用户信息手动标注每个示例。如果任务本身与任何规则无关，则该示例将标注为‘0’，表示‘允许操作’。如果任务与至少一条规则相关（例如与租车相关的规则），我们检查用户信息，如果规则被违反（例如‘dr_license’为‘false’），则将示例标注为‘1’，表示‘拒绝操作’，否则标注为‘0’。对于每个标注为‘1’的示例，违反的规则也将包含在我们的基准中。最后，我们通过创建额外的示例（基于现有任务，但用户信息不同）来平衡这两个类别，同时删除一些任务与任何规则无关的示例（详细信息请见附录[B](https://arxiv.org/html/2406.09187v1#A2
    "Appendix B Details About the Mind2Web-SC Benchmark ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")）。创建的Mind2Web-SC基准每个类别包含100个示例，且每个类别中的任务都是唯一的。'
- en: 'Table 1: Access control on EHRAgent and safety control on SeeAct based on system
    instructions are ineffective on EICU-AC and Mind2Web-SC; therefore, a new guardrail
    method is needed.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：基于系统指令对EHRAgent的访问控制和对SeeAct的安全控制在EICU-AC和Mind2Web-SC上无效；因此，需要一种新的防护方法。
- en: '|  | LPP $\uparrow$ | LPR $\uparrow$ | CCA $\uparrow$ | FRA $\uparrow$ |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | LPP $\uparrow$ | LPR $\uparrow$ | CCA $\uparrow$ | FRA $\uparrow$ |'
- en: '| EHRAgent + EICU-AC | 76.6 | 90.7 | 50.0 | 3.2 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| EHRAgent + EICU-AC | 76.6 | 90.7 | 50.0 | 3.2 |'
- en: '| SeeAct + Mind2Web-SC | 95.1 | 58.0 | 58.0 | 71.0 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| SeeAct + Mind2Web-SC | 95.1 | 58.0 | 58.0 | 71.0 |'
- en: 3.3 Preliminary Guardrails on the Two Benchmarks
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 两个基准的初步防护措施
- en: Naive ‘invasive’ baselines
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 天真“入侵性”基线
- en: 'We use the EICU-AC benchmark to evaluate a naive approach that hardwires the
    access control into the system prompt of EHRAgent by specifying the three roles
    with their accessible databases and columns. During the evaluation, this modified
    EHRAgent will be provided with both the role and the query of the EICU-AC examples.
    Its system prompt will include instructions to display a ‘denial message’ along
    with the inaccessible databases and columns for the given role, if there are any.
    Similarly, we incorporate textual instructions for safety checks into the system
    prompt of SeeAct and evaluate it on Mind2Web-SC. If any of the rules are violated
    for the given user profile, the safety-enforced SeeAct is supposed to print a
    ‘denial message’ with the violated rules. Details about the system prompts for
    the two agents equipped with the naive ‘invasive’ guardrails are deferred to App.
    [C](https://arxiv.org/html/2406.09187v1#A3 "Appendix C Detailed System Prompts
    for Naive Access Control and Safety Control Based on Instructions ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 EICU-AC 基准来评估一种朴素的方法，该方法通过指定三种角色及其可访问的数据库和列，将访问控制硬编码到 EHRAgent 的系统提示中。在评估过程中，修改后的
    EHRAgent 将同时获得 EICU-AC 示例的角色和查询。它的系统提示将包括指示，如果给定角色有任何不可访问的数据库和列，则显示“拒绝消息”，并列出这些不可访问的数据库和列。同样，我们将安全检查的文本指令融入
    SeeAct 的系统提示中，并在 Mind2Web-SC 上对其进行评估。如果给定用户配置文件违反了任何规则，强制安全的 SeeAct 应该打印出包含违规规则的“拒绝消息”。关于这两种配备朴素“入侵式”保护措施的代理系统提示的详细信息，请参见
    App. [C](https://arxiv.org/html/2406.09187v1#A3 "附录 C：基于指令的朴素访问控制和安全控制的详细系统提示
    ‣ GuardAgent：通过知识驱动推理保护 LLM 代理的保护代理")。
- en: Metrics
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指标
- en: 'We consider four evaluation metrics shared by both benchmarks: label prediction
    precision (LPP), label prediction recall (LPR), comprehensive control accuracy
    (CCA), and final response accuracy (FRA), all in percentage. Both LPP and LPR
    are calculated over all examples in each dataset to measure the overall label
    prediction efficacy, where a prediction of label ‘1’ is counted only if the ‘denial
    message’ appears. CCA considers all examples with ground truth labeled ‘1’. It
    is defined as the percentage of these examples being correctly predicted to ‘1’
    and with all inaccessible databases and columns (for EICU-AC) or all violated
    rules (for Mind2Web-SC) successfully detected. In contrast, FRA considers all
    examples with ground truth labeled ‘0’. It is defined as the percentage of these
    examples being correctly predicted to ‘0’ and with the agent responses correctly.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑了两个基准共享的四个评估指标：标签预测精度（LPP）、标签预测召回率（LPR）、综合控制准确度（CCA）和最终响应准确度（FRA），所有指标均以百分比表示。LPP
    和 LPR 都是在每个数据集的所有示例上计算的，用于衡量整体标签预测效果，其中只有在“拒绝消息”出现时，标签‘1’的预测才会被计入。CCA 考虑所有标记为‘1’的真实例子。它被定义为这些例子中正确预测为‘1’并成功检测到所有不可访问的数据库和列（对于
    EICU-AC）或所有违规规则（对于 Mind2Web-SC）的百分比。相比之下，FRA 考虑所有标记为‘0’的真实例子。它被定义为这些例子中正确预测为‘0’并且代理的响应正确的百分比。
- en: Results
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果
- en: 'As shown in Tab. [1](https://arxiv.org/html/2406.09187v1#S3.T1 "Table 1 ‣ Proposed
    Mind2Web-SC benchmark ‣ 3.2 SeeAct and Mind2Web-SC Benchmark ‣ 3 Safety Requests
    for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning"), the two naive baselines fail in their designated
    tasks, exhibiting either low precision or recall in label prediction. Specifically,
    the naive access control for EHRAgent is overly strict, resulting in an excessive
    number of false positives. Conversely, the naive safety control for SeeAct fails
    to reject many unsafe actions, leading to numerous false negatives. Moreover,
    the ‘invasion’ that introduces additional tasks imposes heavy burdens on both
    agents, significantly degrading the performance on their designated tasks, particularly
    for EHRAgent (which achieves only 3.2% end-to-end accuracy on negative examples
    as measured by FRA). Finally, despite their poor performance, both naive guardrail
    approaches are hardwired to the agent, making them non-transferable to other LLM
    agents with different designs. These shortcomings highlight the need for our GuardAgent,
    which is both effective and generalizable in safeguarding diverse LLM agents.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '如表[1](https://arxiv.org/html/2406.09187v1#S3.T1 "Table 1 ‣ Proposed Mind2Web-SC
    benchmark ‣ 3.2 SeeAct and Mind2Web-SC Benchmark ‣ 3 Safety Requests for Diverse
    LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")所示，两个简单的基线方法未能完成其指定任务，表现出标签预测的低精度或低召回率。具体而言，EHRAgent的简单访问控制过于严格，导致大量假阳性；相反，SeeAct的简单安全控制未能拒绝许多不安全的操作，导致大量假阴性。此外，引入额外任务的“入侵”对两个代理都造成了沉重的负担，显著降低了它们在指定任务上的表现，特别是对于EHRAgent（其在负面示例上通过FRA测量的端到端准确率仅为3.2%）。最后，尽管表现不佳，但这两种简单的守护方法是与代理硬编码的，无法转移到具有不同设计的其他LLM代理上。这些缺点突显了我们GuardAgent的必要性，它在保障各种LLM代理的安全方面既有效又具有可扩展性。'
- en: 4 GuardAgent Framework
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 GuardAgent框架
- en: 'In this section, we introduce GuardAgent with three key features: 1) generalizable
    – the memory and toolbox of GuardAgent can be easily extended to address new target
    agents with new guard requests; 2) reliable – outputs of GuardAgent are obtained
    by successful code execution; 3) training-free – GuardAgent is in-context-learning-based
    and does not need any LLM training.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了GuardAgent的三个关键特点：1）可扩展性——GuardAgent的记忆和工具箱可以轻松扩展，以处理具有新守护请求的新目标代理；2）可靠性——GuardAgent的输出通过成功的代码执行获得；3）免训练——GuardAgent基于上下文学习，无需任何大语言模型（LLM）训练。
- en: 4.1 Overview of GuardAgent
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 GuardAgent概述
- en: The intended user of GuardAgent is the developer or administrator of a target
    LLM agent who seeks to implement guardrails on it. The mandatory inputs to GuardAgent
    are all textual, including a set of guard requests $I_{r}$, a specification $I_{s}$
    of the target agent, inputs $I_{i}$ to the target agent, and the output logs $I_{o}$
    of the target agent corresponding to $I_{i}$. Here, $I_{r}$ is informed by $I_{s}$,
    which includes the functionality of the target agent, the content of the inputs
    and output logs, their formats, etc. The objective of GuardAgent is to check whether
    $I_{i}$ and $I_{o}$ satisfy the guard requests $I_{r}$ and then produce a label
    prediction $O_{l}$, where $O_{l}=0$ means the guard requests are satisfied and
    $O_{l}=1$ otherwise. The outputs or actions proposed by the target agent will
    be admitted by GuardAgent if $O_{l}=0$ or denied if $O_{l}=1$. If $O_{l}=1$, GuardAgent
    should also output the detailed reasons $O_{d}$ (e.g., by printing out the inaccessible
    databases and columns for EICU-AC) for potential further actions. For example,
    severe rule violations for some use cases may require judicial intervention.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: GuardAgent的预期用户是目标LLM代理的开发者或管理员，旨在为其实施守护措施。GuardAgent的强制输入均为文本形式，包括一组守护请求$I_{r}$、目标代理的规格$I_{s}$、目标代理的输入$I_{i}$和目标代理对应于$I_{i}$的输出日志$I_{o}$。其中，$I_{r}$由$I_{s}$提供，$I_{s}$包含目标代理的功能、输入和输出日志的内容、它们的格式等。GuardAgent的目标是检查$I_{i}$和$I_{o}$是否满足守护请求$I_{r}$，然后生成标签预测$O_{l}$，其中$O_{l}=0$表示守护请求已满足，$O_{l}=1$则表示未满足。如果$O_{l}=0$，目标代理提出的输出或操作将被GuardAgent接受；如果$O_{l}=1$，则被拒绝。如果$O_{l}=1$，GuardAgent还应输出详细的原因$O_{d}$（例如，通过打印出EICU-AC不可访问的数据库和列）以供进一步处理。例如，某些用例的严重规则违规可能需要司法干预。
- en: 'The key idea of GuardAgent is to leverage the logical reasoning capabilities
    of LLMs with knowledge retrieval to accurately ‘translate’ textual guard requests
    into executable code. Correspondingly, the pipeline of GuardAgent comprises two
    major steps (see Fig. [1](https://arxiv.org/html/2406.09187v1#S0.F1 "Figure 1
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")).
    In the first step (Sec. [4.2](https://arxiv.org/html/2406.09187v1#S4.SS2 "4.2
    Task Planning ‣ 4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning")), a step-by-step action plan is
    generated by prompting an LLM with the above-mentioned inputs to GuardAgent. In
    the second step [4.3](https://arxiv.org/html/2406.09187v1#S4.SS3 "4.3 Guardrail
    Code Generation and Execution ‣ 4 GuardAgent Framework ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")), we prompt the
    LLM with the action plan and a set of callable functions to get a guardrail code,
    which is then executed by calling an external engine. A memory module is available
    in both steps to retrieve in-context demonstrations.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: GuardAgent的核心理念是利用大型语言模型（LLM）的逻辑推理能力和知识检索，准确地将文本形式的守护请求“翻译”成可执行的代码。因此，GuardAgent的流程包含两个主要步骤（见图
    [1](https://arxiv.org/html/2406.09187v1#S0.F1 "图 1 ‣ GuardAgent：通过知识驱动推理保护LLM代理")）。在第一步（第
    [4.2](https://arxiv.org/html/2406.09187v1#S4.SS2 "4.2 任务规划 ‣ 4 GuardAgent框架 ‣
    GuardAgent：通过知识驱动推理保护LLM代理") 节）中，系统通过向LLM提供上述输入来生成逐步的行动计划。在第二步 [4.3](https://arxiv.org/html/2406.09187v1#S4.SS3
    "4.3 防护代码生成与执行 ‣ 4 GuardAgent框架 ‣ GuardAgent：通过知识驱动推理保护LLM代理") 中，我们用行动计划和一组可调用的函数来提示LLM，从而获取防护代码，随后通过调用外部引擎执行该代码。在这两个步骤中，都提供了一个内存模块用于检索上下文中的示范。
- en: 4.2 Task Planning
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 任务规划
- en: 'The objective for task planning is to generate a step-by-step action plan $P$
    from the inputs to GuardAgent. A naive design is to prompt a foundation LLM with
    $[I_{p},I_{s},I_{r},I_{i},I_{o}]$, where $I_{p}$ contains carefully designed planning
    instructions that 1) define each input to GuardAgent , 2) state the guardrail
    task (i.e., checking if $I_{r}$ is satisfied by $I_{i}$ and $I_{o}$), and 3) guide
    the generation of action steps (see Fig. [8](https://arxiv.org/html/2406.09187v1#A4.F8
    "Figure 8 ‣ Complete Inputs to GuardAgent ‣ Appendix D Complete Inputs and Output
    of GuardAgent ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning") in App. [D](https://arxiv.org/html/2406.09187v1#A4 "Appendix D Complete
    Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning") for a concrete example). However, understanding
    the complex guard requests and incorporating them with the target agent remains
    a challenging task for existing LLMs.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 任务规划的目标是根据输入生成一个逐步的行动计划$P$。一种简单的设计是，通过向基础LLM提供$[I_{p},I_{s},I_{r},I_{i},I_{o}]$来提示，其中$I_{p}$包含精心设计的规划指令，这些指令
    1) 定义了GuardAgent的每个输入，2) 说明了防护任务（即检查$I_{r}$是否由$I_{i}$和$I_{o}$满足），并且 3) 指导行动步骤的生成（见附录[D](https://arxiv.org/html/2406.09187v1#A4
    "附录D GuardAgent的完整输入与输出 ‣ GuardAgent：通过知识驱动推理保护LLM代理")中的图 [8](https://arxiv.org/html/2406.09187v1#A4.F8
    "图 8 ‣ GuardAgent的完整输入 ‣ 附录D GuardAgent的完整输入与输出") ）。然而，理解复杂的防护请求并将其与目标代理结合起来，仍然是现有LLM面临的一项挑战。
- en: We address this challenge by allowing GuardAgent to retrieve demonstrations
    from a memory module that archives target agent inputs and outputs from past use
    cases. Here, an element $D$ in the memory module is denoted by $D=[I_{i,D},I_{o,D},P_{D},C_{D}]$,
    where $I_{i,D}$ and $I_{o,D}$ are the target agent inputs and outputs respectively,
    $P_{D}$ contains the action steps, and $C_{D}$ contains the guardrail code. Retrieval
    is based on the similarity between the current target agent inputs and outputs
    and those from the memory. Specifically, we retrieve $k$ demonstrations by selecting
    $k$ elements from the memory with the smallest Levenshtein distance $L([I_{i,D},I_{o,D}],[I_{i},I_{o}])$.
    Then the action plan is obtained by $P={\rm LLM}([I_{p},I_{s},I_{r},[I_{i,D_{1}},I_{o,D_{1}},P_{D_{1}}],\cdots,[I_{%
    i,D_{k}},I_{o,D_{k}},P_{D_{k}}],I_{i},I_{o}])$. Note that the guardrail code in
    each demonstration has been removed for the brevity of the prompt.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过允许GuardAgent从记忆模块中检索示范来解决这一挑战，该模块存档了过去使用案例中目标代理的输入和输出。这里，记忆模块中的一个元素$D$表示为$D=[I_{i,D},I_{o,D},P_{D},C_{D}]$，其中$I_{i,D}$和$I_{o,D}$分别表示目标代理的输入和输出，$P_{D}$包含行动步骤，$C_{D}$包含防护代码。检索是基于当前目标代理输入和输出与记忆中记录的输入和输出之间的相似性。具体来说，我们通过选择与当前目标代理输入和输出的Levenshtein距离$L([I_{i,D},I_{o,D}],[I_{i},I_{o}])$最小的$k$个元素来检索$k$个示范。然后，行动计划通过$P={\rm
    LLM}([I_{p},I_{s},I_{r},[I_{i,D_{1}},I_{o,D_{1}},P_{D_{1}}],\cdots,[I_{i,D_{k}},I_{o,D_{k}},P_{D_{k}}],I_{i},I_{o}])$获得。请注意，为了简洁起见，已移除每个示范中的防护代码。
- en: 'In the cases where GuardAgent is applied to a new LLM agent for some specific
    guard requests, we also allow the user of GuardAgent to manually inject demonstrations
    into the memory module. In particular, we request the action plan in each demonstration
    provided by the user to contain four mandatory steps, denoted by $P_{D}=[p_{1,D},p_{2,D},p_{3,D},p_{4,D}]$,
    where the four steps form a chain-of-thought [[20](https://arxiv.org/html/2406.09187v1#bib.bib20)].
    In general, $p_{1,D}$ summarizes guard requests to identify the keywords, such
    as ‘access control’ with three roles, ‘physician’, ‘nursing’, and ‘general administration’
    for EICU-AC. Then, $p_{2,D}$ filters information in the guard request that is
    related to the target agent input, while $p_{3,D}$ summarizes the target agent
    output log and locates related content in the guard request. Finally, $p_{4,D}$
    instructs guardrail code generation to compare the information obtained in $p_{2,D}$
    and $p_{3,D}$, as well as the supposed execution engine. Example action plans
    are shown in Fig. [13](https://arxiv.org/html/2406.09187v1#A7.F13 "Figure 13 ‣
    Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") of App. [G](https://arxiv.org/html/2406.09187v1#A7
    "Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '在将GuardAgent应用于新的LLM代理以处理特定的防护请求的情况下，我们还允许GuardAgent的用户手动将示范注入到记忆模块中。特别地，我们要求用户提供的每个示范中的行动计划包含四个强制步骤，表示为$P_{D}=[p_{1,D},p_{2,D},p_{3,D},p_{4,D}]$，这四个步骤形成一个思维链[[20](https://arxiv.org/html/2406.09187v1#bib.bib20)]。一般而言，$p_{1,D}$总结防护请求，以识别关键词，例如‘访问控制’，其中包括三个角色：‘医生’、‘护理’和‘普通管理’，用于EICU-AC。然后，$p_{2,D}$过滤与目标代理输入相关的防护请求中的信息，而$p_{3,D}$总结目标代理的输出日志，并定位防护请求中相关的内容。最后，$p_{4,D}$指导防护代码生成，比较在$p_{2,D}$和$p_{3,D}$中获得的信息，以及假设的执行引擎。示范行动计划的示例见附录[13](https://arxiv.org/html/2406.09187v1#A7.F13
    "图13 ‣ 附录G 手动创建的示范 ‣ GuardAgent: 通过知识驱动推理保护LLM代理")。'
- en: 4.3 Guardrail Code Generation and Execution
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 防护代码生成与执行
- en: The goal of this step is to generate a guardrail code $C$ based on the action
    plan $P$. Once generated, $C$ is executed through the external engine $E$ specified
    in the action plan. However, guardrail code generated by directly prompting an
    LLM with the action plan $P$ and straightforward instructions may not be reliably
    executable. One of our key designs to address this issue is to adopt more comprehensive
    instructions that include a list $\mathcal{F}$ of callable functions with specification
    of their input arguments. The definitions of these functions are stored in the
    toolbox of GuardAgent, which can be easily extended by users through code uploading
    to address new guard requests and target agents. The LLM is instructed to use
    only the provided functions for code generation; otherwise, it easily makes up
    non-existent functions during code generation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本步骤的目标是基于行动计划 $P$ 生成一个护栏代码 $C$。一旦生成，$C$ 将通过行动计划中指定的外部引擎 $E$ 执行。然而，直接通过向大型语言模型（LLM）提供行动计划
    $P$ 和简单指令生成的护栏代码可能无法可靠执行。为了解决这个问题，我们的一个关键设计是采用更全面的指令，其中包括一个可调用函数列表 $\mathcal{F}$，并指定它们的输入参数。这些函数的定义存储在
    GuardAgent 的工具箱中，用户可以通过上传代码轻松扩展以应对新的护栏请求和目标代理。LLM 被指示仅使用提供的函数来生成代码；否则，它在生成代码时很容易编造不存在的函数。
- en: Furthermore, we utilize past examples retrieved from memory, employing the same
    approach used in task planning, to serve as demonstrations for code generation.
    Thus, we have $C={\rm LLM}(I_{c}(\mathcal{F}),D_{1},\cdots,D_{k},I_{i},I_{o},P)$,
    where $I_{c}(\mathcal{F})$ are the instructions based on the callable functions
    in $\mathcal{F}$ and $D_{1},\cdots,D_{k}$ are the retrieved demonstrations. The
    outputs of GuardAgent are obtained by executing the generated code, i.e., $(O_{l},O_{d})=E(C,\mathcal{F})$.
    Finally, we adopt the debugging mechanism proposed by Shi et al. [[17](https://arxiv.org/html/2406.09187v1#bib.bib17)],
    which invokes an LLM to analyze any error messages that may arise during execution
    to enhance the reliability of the generated code.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还利用从记忆中检索的过去示例，采用与任务规划中相同的方法，将其作为代码生成的示范。因此，我们有 $C={\rm LLM}(I_{c}(\mathcal{F}),D_{1},\cdots,D_{k},I_{i},I_{o},P)$，其中
    $I_{c}(\mathcal{F})$ 是基于可调用函数 $\mathcal{F}$ 的指令，$D_{1},\cdots,D_{k}$ 是检索到的示范。GuardAgent
    的输出通过执行生成的代码获得，即 $(O_{l},O_{d})=E(C,\mathcal{F})$。最后，我们采用 Shi 等人提出的调试机制 [[17](https://arxiv.org/html/2406.09187v1#bib.bib17)]，该机制调用
    LLM 分析执行过程中可能出现的任何错误信息，从而提高生成代码的可靠性。
- en: 5 Experiments
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 个实验
- en: 'In Sec. [5.2](https://arxiv.org/html/2406.09187v1#S5.SS2 "5.2 Guardrail Performance
    ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), we show the effectiveness of GuardAgent in safeguarding EHRAgent
    on EICU-AC and SeeAct on Mind2Web-SC with 98.7% and 90.0% label prediction accuracies,
    respectively. We illustrate through a case study that the advantage of GuardAgent
    over ‘model guarding agents’ approaches is attributed to the more reliable guardrail
    by code generation and execution. In Sec. [5.3](https://arxiv.org/html/2406.09187v1#S5.SS3
    "5.3 Ablation Studies ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning"), we conduct ablation studies to
    show 1) GuardAgent performs similarly well for most of the roles in EICU-AC and
    rules in Mind2Web-SC, allowing it to handle guard requests with high complexity,
    and 2) GuardAgent requires only a few shots of demonstrations. In Sec. [5.4](https://arxiv.org/html/2406.09187v1#S5.SS4
    "5.4 Code-Based Guardrail is the Natural Preference of LLMs, but Tools are Needed
    ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), we demonstrate that GuardAgent may define necessary functions based
    on guard requests, highlighting its ability to generalize to new guard requests.
    Additionally, we find that LLMs, such as GPT-4, tend to generate code-based guardrails
    (albeit mostly inexecutable) even when not provided with specific instructions
    for code generation and execution.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '在第[5.2节](https://arxiv.org/html/2406.09187v1#S5.SS2 "5.2 Guardrail Performance
    ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")中，我们展示了GuardAgent在保护EHRAgent（在EICU-AC上的表现）和SeeAct（在Mind2Web-SC上的表现）方面的有效性，分别达到了98.7%和90.0%的标签预测准确率。通过一个案例研究，我们说明了GuardAgent相对于“模型守护代理”方法的优势，归因于通过代码生成和执行实现的更可靠的防护。
    在第[5.3节](https://arxiv.org/html/2406.09187v1#S5.SS3 "5.3 Ablation Studies ‣ 5
    Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")中，我们进行消融研究，显示出1）GuardAgent对EICU-AC中的大多数角色和Mind2Web-SC中的规则表现相似良好，使其能够处理高复杂度的守护请求，2）GuardAgent仅需要少量示范来执行任务。
    在第[5.4节](https://arxiv.org/html/2406.09187v1#S5.SS4 "5.4 Code-Based Guardrail
    is the Natural Preference of LLMs, but Tools are Needed ‣ 5 Experiments ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中，我们展示了GuardAgent可以根据守护请求定义必要的功能，突出了其在处理新守护请求时的泛化能力。此外，我们还发现，LLM（如GPT-4）倾向于生成基于代码的防护（尽管大多数是无法执行的），即使没有为代码生成和执行提供具体的指示。'
- en: 5.1 Setup
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 设置
- en: Datasets and agents
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集和代理
- en: 'We test GuardAgent on EICU-AC and Mind2Web-SC with EHRAgent and SeeAct (using
    their original settings) as the target agents, respectively. The role and question
    from each EICU-AC example are inputs to EHRAgent, and the output logs include
    the reasoning steps, the generated code, and the final answer produced by EHRAgent.
    The inputs to SeeAct contain the task and user information from each example in
    Mind2Web-SC, and the output logs include the predicted action and the reasoning
    by SeeAct. Example inputs ($I_{i}$) and output logs ($I_{o}$) of the two target
    agents (which are the inputs to GuardAgent) are shown in App. [D](https://arxiv.org/html/2406.09187v1#A4
    "Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning"). Other inputs to GuardAgent,
    including the specifications of the two target agents ($I_{s}$), the guard requests
    associated with the two benchmarks ($I_{r}$), and the planning instructions ($I_{p}$),
    are also shown in App. [D](https://arxiv.org/html/2406.09187v1#A4 "Appendix D
    Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM Agents by
    a Guard Agent via Knowledge-Enabled Reasoning") due to space limitations.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '我们分别在EICU-AC和Mind2Web-SC上测试了GuardAgent，目标代理分别是EHRAgent和SeeAct（使用它们的原始设置）。每个EICU-AC示例中的角色和问题是EHRAgent的输入，输出日志包括推理步骤、生成的代码和EHRAgent生成的最终答案。SeeAct的输入包含来自Mind2Web-SC中每个示例的任务和用户信息，输出日志包括SeeAct预测的动作和推理过程。两个目标代理的示例输入（$I_{i}$）和输出日志（$I_{o}$）（即GuardAgent的输入）显示在附录[D](https://arxiv.org/html/2406.09187v1#A4
    "Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")中。由于篇幅限制，GuardAgent的其他输入，包括两个目标代理的规格（$I_{s}$）、与两个基准相关的守护请求（$I_{r}$）以及规划指令（$I_{p}$），也显示在附录[D](https://arxiv.org/html/2406.09187v1#A4
    "Appendix D Complete Inputs and Output of GuardAgent ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning")中。'
- en: Settings of GuardAgent
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GuardAgent的设置
- en: 'In the main experiments, we set the number of demonstrations to $k=1$ and $k=3$
    for EICU-AC and Mind2Web-SC, respectively. Other choices will be considered in
    our ablation study in Sec. [5.3](https://arxiv.org/html/2406.09187v1#S5.SS3 "5.3
    Ablation Studies ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning"). For each benchmark, we initialize the
    memory of GuardAgent by $k$ manually created demonstrations (see App. [G](https://arxiv.org/html/2406.09187v1#A7
    "Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") for example). We use GPT-4
    version 2024-02-01 with temperature zero as the core LLM of GuardAgent. We use
    Python as the default code execution engine, with two initial functions in the
    toolbox, ‘CheckAccess’ and ‘CheckRules’, which are defined in App. [E](https://arxiv.org/html/2406.09187v1#A5
    "Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning"). Note that users of GuardAgent can easily upload
    new functions or engines into the toolbox. Finally, we allow three debugging iterations,
    though in most cases, the guardrail code generated by GuardAgent is directly executable.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '在主要实验中，我们将演示数量设置为$k=1$和$k=3$，分别用于EICU-AC和Mind2Web-SC。其他选择将在我们的消融研究中考虑，见第[5.3节](https://arxiv.org/html/2406.09187v1#S5.SS3
    "5.3 Ablation Studies ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning")。对于每个基准，我们通过$k$个手动创建的演示初始化GuardAgent的记忆（例如见附录[G](https://arxiv.org/html/2406.09187v1#A7
    "Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning")）。我们使用GPT-4版本2024-02-01，并设置温度为零，作为GuardAgent的核心LLM。我们使用Python作为默认的代码执行引擎，工具箱中包含两个初始函数，‘CheckAccess’和‘CheckRules’，这些函数在附录[E](https://arxiv.org/html/2406.09187v1#A5
    "Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning")中定义。请注意，GuardAgent的用户可以轻松地将新函数或引擎上传到工具箱中。最后，我们允许进行三次调试迭代，尽管在大多数情况下，GuardAgent生成的保护代码是可以直接执行的。'
- en: Baselines
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准
- en: 'Since GuardAgent is the first LLM agent designed to safeguard other agents,
    we compare it with baselines using models to safeguard agents. Here, we consider
    GPT-4 version 2024-02-01 and Llama3-70B as the guardrail models¹¹1Approaches for
    ‘model guarding models’, such as LlamaGuard designed to detect predefined unsafe
    categories [[7](https://arxiv.org/html/2406.09187v1#bib.bib7)], are not considered
    here due to their completely different objectives.. We create comprehensive prompts
    containing high-level instructions $I^{\prime}_{p}$ adapted from the one for GuardAgent,
    the same number of demonstrations as for GuardAgent but without guardrail code
    generation, denoted by $D^{\prime}_{1},\cdots,D^{\prime}_{k}$, and the same set
    of inputs as for GuardAgent. However, neither baselines involve the memory module
    as our GuardAgent does; they use a fixed set of demonstrations during the evaluation.
    Example prompts for both benchmarks are shown in App. [H](https://arxiv.org/html/2406.09187v1#A8
    "Appendix H Function Defined by GuardAgent in Zero-Shot Setting ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"). Then
    the outputs of the guardrail models for the baselines are obtained by $(O_{l},O_{d})={\rm
    LLM}(I^{\prime}_{p},I_{s},I_{r},D^{\prime}_{1},\cdots,D^{% \prime}_{k},I_{i},I_{o})$.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '由于GuardAgent是第一个旨在保护其他代理的LLM代理，因此我们将其与使用模型保护代理的基准进行比较。在这里，我们考虑使用GPT-4版本2024-02-01和Llama3-70B作为保护模型¹¹1“模型保护模型”的方法，例如LlamaGuard，它设计用于检测预定义的不安全类别[[7](https://arxiv.org/html/2406.09187v1#bib.bib7)]，由于目标完全不同，因此不在此讨论。我们创建了包含高级指令的综合性提示，$I^{\prime}_{p}$，它是从GuardAgent的提示中改编而来的，演示数量与GuardAgent相同，但不包括保护代码生成，记作$D^{\prime}_{1},\cdots,D^{\prime}_{k}$，并且使用与GuardAgent相同的输入集。然而，这些基准模型没有像GuardAgent那样涉及记忆模块；它们在评估过程中使用固定的演示集。两个基准的示例提示见附录[H](https://arxiv.org/html/2406.09187v1#A8
    "Appendix H Function Defined by GuardAgent in Zero-Shot Setting ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")。然后，基准的保护模型输出通过$(O_{l},O_{d})={\rm
    LLM}(I^{\prime}_{p},I_{s},I_{r},D^{\prime}_{1},\cdots,D^{\prime}_{k},I_{i},I_{o})$获得。'
- en: Evaluation metrics
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'We use the two label prediction metrics, LPP and LPR, and the CCA metric, all
    defined in Sec. [3.3](https://arxiv.org/html/2406.09187v1#S3.SS3 "3.3 Preliminary
    Guardrails on the Two Benchmarks ‣ 3 Safety Requests for Diverse LLM Agents ‣
    GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning").
    The FRA metric is not considered here since all guardrails being evaluated will
    not affect the normal operation of the target agent when the alarm is not triggered.
    In addition, we report the label prediction accuracy (LPA, a.k.a. guarding accuracy),
    defined over all examples in each dataset, as the overall metric for the guardrail
    performance.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用了两个标签预测指标，LPP和LPR，以及CCA指标，所有这些都在第[3.3节](https://arxiv.org/html/2406.09187v1#S3.SS3
    "3.3 Preliminary Guardrails on the Two Benchmarks ‣ 3 Safety Requests for Diverse
    LLM Agents ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")中定义。由于所有被评估的防护措施在警报未触发时不会影响目标代理的正常操作，因此此处不考虑FRA指标。此外，我们报告了标签预测准确率（LPA，也叫做防护准确率），该指标在每个数据集的所有示例上定义，作为防护措施性能的整体指标。'
- en: 'Table 2: Performance of GuardAgent in safeguarding EHRAgent on EICU-AC and
    SeeAct on Mind2Web-SC, compared with two model-based baselines with GPT-4 and
    Llama3, respectively.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：GuardAgent在保障EICU-AC上的EHRAgent和Mind2Web-SC上的SeeAct性能，与基于模型的两个基线（分别为GPT-4和Llama3）进行比较。
- en: '|  | EHRAgent on EICU-AC | SeeAct on Mind2Web-SC |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | EHRAgent on EICU-AC | SeeAct on Mind2Web-SC |'
- en: '|  | LPA $\uparrow$ | LPP $\uparrow$ | LPR $\uparrow$ | CCA $\uparrow$ | LPA
    $\uparrow$ | LPP $\uparrow$ | LPR $\uparrow$ | CCA $\uparrow$ |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | LPA $\uparrow$ | LPP $\uparrow$ | LPR $\uparrow$ | CCA $\uparrow$ | LPA
    $\uparrow$ | LPP $\uparrow$ | LPR $\uparrow$ | CCA $\uparrow$ |'
- en: '| Llama3 | 92.1 | 95.4 | 88.9 | 41.4 | 76.5 | 93.4 | 57.0 | 57.0 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| Llama3 | 92.1 | 95.4 | 88.9 | 41.4 | 76.5 | 93.4 | 57.0 | 57.0 |'
- en: '| GPT-4 | 97.5 | 95.3 | 100.0 | 67.9 | 82.5 | 100.0 | 65.0 | 65.0 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 97.5 | 95.3 | 100.0 | 67.9 | 82.5 | 100.0 | 65.0 | 65.0 |'
- en: '| GuardAgent | 98.7 | 100.0 | 97.5 | 97.5 | 90.0 | 100.0 | 80.0 | 80.0 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| GuardAgent | 98.7 | 100.0 | 97.5 | 97.5 | 90.0 | 100.0 | 80.0 | 80.0 |'
- en: '![Refer to caption](img/956ee81b74a876080c8d7e5586c00868.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅标题](img/956ee81b74a876080c8d7e5586c00868.png)'
- en: 'Figure 3: Left: A failure case of the GPT-4 baseline where the same column
    name (‘patientunitstayid’) shared by different databases cannot be effectively
    distinguished. Right: A failure case of GuardAgent where a rule violation is not
    detected due to the overwhelming details in the query.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：左：GPT-4基线的失败案例，其中不同数据库共享相同的列名（‘patientunitstayid’），无法有效区分。右：GuardAgent的失败案例，由于查询中细节过多，未能检测到规则违规。
- en: 5.2 Guardrail Performance
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 防护性能
- en: 'In Tab. [2](https://arxiv.org/html/2406.09187v1#S5.T2 "Table 2 ‣ Evaluation
    metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning"), we show the performance of GuardAgent
    compared with the baselines using our comprehensive evaluation metrics. GuardAgent
    achieves better LPAs than the two baselines with also clear gaps in CCAs, showing
    the advantage of ‘agent guarding agents’ over ‘model guarding agents’. We attribute
    this advantage to our design of reasoning-based code generation and execution,
    which is clearly infeasible by guardrail models. In many failure cases of GPT-4
    on EICU-AC, we found that guardrails based on natural language cannot effectively
    distinguish column names if they are shared by different databases. For example,
    in Fig. [3](https://arxiv.org/html/2406.09187v1#S5.F3 "Figure 3 ‣ Evaluation metrics
    ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning"), the entire database ‘vitalperiodic’ that contains
    a column named ‘patientunitstayid’ is not accessible to ‘general administration’,
    while the column with the same name in the database ‘patient’ is accessible to
    the same role. In this case, the model-based guardrail using GPT-4 fails to determine
    the column ‘patientunitstayid’ in the database ‘vitalperiodic’ as ‘inaccessible’.
    In contrast, our GuardAgent based on code generation accurately converts each
    database and its columns into a dictionary, effectively avoiding such ambiguity
    in column names.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[2](https://arxiv.org/html/2406.09187v1#S5.T2 "Table 2 ‣ Evaluation metrics
    ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning")中，我们展示了GuardAgent与基准方法的性能比较，使用了我们全面的评估指标。GuardAgent在LPA上表现优于两个基准方法，并且在CCA上也有明显差距，展示了“代理保护代理”相对于“模型保护代理”的优势。我们将这一优势归因于我们基于推理的代码生成和执行设计，而这种方法是护栏模型无法实现的。在GPT-4在EICU-AC上的许多失败案例中，我们发现基于自然语言的护栏无法有效区分列名，尤其是在不同数据库中共享同一列名的情况下。例如，在图[3](https://arxiv.org/html/2406.09187v1#S5.F3
    "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中，包含名为‘patientunitstayid’的列的整个数据库‘vitalperiodic’对‘general
    administration’不可访问，而在数据库‘patient’中的同名列对相同角色是可访问的。在这种情况下，基于GPT-4的模型护栏未能识别数据库‘vitalperiodic’中的列‘patientunitstayid’为“不可访问”。相比之下，我们基于代码生成的GuardAgent准确地将每个数据库及其列转换为字典，有效避免了这种列名模糊性。'
- en: 'On the right of Fig. [3](https://arxiv.org/html/2406.09187v1#S5.F3 "Figure
    3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show a typical failure
    case of GuardAgent where the violated rule is undetected. We found that the query
    failed to be connected to the designated rule in the first step of the chain-of-thought
    reasoning during task planning, possibly due to the overwhelming details in the
    query. However, this issue can be mitigated by involving more demonstrations with
    better linguistic diversity, or using more powerful LLM as the core reasoning
    step.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '在图[3](https://arxiv.org/html/2406.09187v1#S5.F3 "Figure 3 ‣ Evaluation metrics
    ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning")的右侧，我们展示了GuardAgent的一个典型失败案例，其中违规规则未被检测到。我们发现，查询未能在任务规划中的链式推理的第一步与指定规则连接，可能是由于查询中的细节过于繁杂。然而，通过提供更多具有更好语言多样性的示范，或者使用更强大的LLM作为核心推理步骤，可以缓解这个问题。'
- en: 'Table 3: Breakdown of GuardAgent results over the three roles in EICU-AC and
    the six rules in Mind2Web-SC. GuardAgent performs uniformly well for all roles
    and rules except for rule 5 related to movies, music, and videos.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：GuardAgent在EICU-AC三个角色和Mind2Web-SC六个规则上的结果分解。GuardAgent在除与电影、音乐和视频相关的规则5外，对所有角色和规则的表现都很均匀。
- en: '|  | EHRAgent on EICU-AC | SeeAct on Mind2Web-SC |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | EHRAgent 在 EICU-AC 上 | SeeAct 在 Mind2Web-SC 上 |'
- en: '|  | physician | nursing | GA | rule 1 | rule 2 | rule 3 | rule 4 | rule 5
    | rule 6 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | 医生 | 护理 | GA | 规则 1 | 规则 2 | 规则 3 | 规则 4 | 规则 5 | 规则 6 |'
- en: '| LPA $\uparrow$ | 97.9 | 98.2 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| LPA $\uparrow$ | 97.9 | 98.2 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
- en: '| CCA $\uparrow$ | 95.7 | 96.4 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| CCA $\uparrow$ | 95.7 | 96.4 | 100.0 | 89.5 | 91.7 | 87.5 | 83.3 | 52.4 |
    83.3 |'
- en: 5.3 Ablation Studies
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 消融实验
- en: Breakdown results
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结果分解
- en: 'In Tab. [3](https://arxiv.org/html/2406.09187v1#S5.T3 "Table 3 ‣ 5.2 Guardrail
    Performance ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning"), we show LPA and CCA of GuardAgent for a) EHRAgent
    for each role of EICU-AC and b) SeeAct for each rule of EICU-AC (by only considering
    positive examples). In general, GuardAgent performances uniformly well for the
    three roles in EICU-AC and the six rules in Mind2Web-SC except for rule 5 related
    to movies, music, and videos. We find that all the failure cases for this rule
    are similar to the one illustrated in Fig. [3](https://arxiv.org/html/2406.09187v1#S5.F3
    "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") where the query
    cannot be related to the rule during reasoning. Still, GuardAgent demonstrates
    relatively strong capabilities in handling complex guard requests with high diversity.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '在表[3](https://arxiv.org/html/2406.09187v1#S5.T3 "Table 3 ‣ 5.2 Guardrail Performance
    ‣ 5 Experiments ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")中，我们展示了GuardAgent对a) EHRAgent在EICU-AC每个角色的LPA和CCA，以及b) SeeAct在EICU-AC每个规则的LPA和CCA（仅考虑正例）。总体而言，GuardAgent在EICU-AC的三个角色和Mind2Web-SC的六个规则上表现均匀良好，除了与电影、音乐和视频相关的规则5。我们发现所有此规则的失败案例都类似于图[3](https://arxiv.org/html/2406.09187v1#S5.F3
    "Figure 3 ‣ Evaluation metrics ‣ 5.1 Setup ‣ 5 Experiments ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中所示的情形，其中查询在推理过程中无法与规则相关联。尽管如此，GuardAgent仍然展示了处理多样化复杂防护请求的相对强大能力。'
- en: Influence of number of demonstrations
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 演示次数的影响
- en: 'We vary the number of demonstrations used by GuardAgent and show the corresponding
    LPAs and CCAs in Fig. [4](https://arxiv.org/html/2406.09187v1#S5.F4 "Figure 4
    ‣ Influence of number of demonstrations ‣ 5.3 Ablation Studies ‣ 5 Experiments
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning").
    The results show that GuardAgent can achieve descent guardrail performance with
    very few shots of demonstrations.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '我们改变了GuardAgent使用的演示次数，并在图[4](https://arxiv.org/html/2406.09187v1#S5.F4 "Figure
    4 ‣ Influence of number of demonstrations ‣ 5.3 Ablation Studies ‣ 5 Experiments
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中展示了相应的LPA和CCA。结果表明，GuardAgent在极少数的演示样本下也能取得不错的防护栏表现。'
- en: '![Refer to caption](img/27e56ac9e39c9cf162beff136bcf30d5.png)![Refer to caption](img/3ce347b9c00ecae5cd6d189d83cb03ae.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/27e56ac9e39c9cf162beff136bcf30d5.png)![参考说明](img/3ce347b9c00ecae5cd6d189d83cb03ae.png)'
- en: 'Figure 4: Performance of GuardAgent with different numbers of demonstrations
    on EICU-AC and Mind2Web-SC. GuardAgent is effective with very few demonstrations.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：在EICU-AC和Mind2Web-SC上，GuardAgent在不同数量的演示下的表现。GuardAgent在演示次数非常少的情况下仍然有效。
- en: 5.4 Code-Based Guardrail is the Natural Preference of LLMs, but Tools are Needed
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 基于代码的防护栏是LLMs的自然偏好，但仍需要工具
- en: 'We consider a challenging task where GuardAgent is instructed to generate guardrail
    code, but is provided with neither a) the functions needed for the guard requests
    nor b) demonstrations for guardrail code generation. Specifically, the guardrail
    code is now generated by $C^{\prime}={\rm LLM}(I_{c}(\mathcal{F}^{\prime}),I_{i},I_{o},P)$,
    where $\mathcal{F}^{\prime}$ represents the toolbox without the required functions.
    In this case, GuardAgent either defines the required functions or produces procedural
    code towards the same goal (see App. [H](https://arxiv.org/html/2406.09187v1#A8
    "Appendix H Function Defined by GuardAgent in Zero-Shot Setting ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") for an
    example guardrail function generated by GuardAgent), and has achieved a 90.8%
    LPA with a 96.1% CCA on EICU-AC. These results support the need for the list of
    callable functions and the demonstrations as our key design for the code generation
    step. They also demonstrate a decent zero-shot generalization capability of GuardAgent
    to address new guard requests.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '我们考虑一个具有挑战性的任务，要求GuardAgent生成防护栏代码，但未提供a)生成防护请求所需的函数，也未提供b)防护栏代码生成的演示。具体来说，防护栏代码现在由$C^{\prime}={\rm
    LLM}(I_{c}(\mathcal{F}^{\prime}),I_{i},I_{o},P)$生成，其中$\mathcal{F}^{\prime}$表示不包含所需函数的工具箱。在这种情况下，GuardAgent要么定义所需的函数，要么生成面向同一目标的程序化代码（见附录[H](https://arxiv.org/html/2406.09187v1#A8
    "Appendix H Function Defined by GuardAgent in Zero-Shot Setting ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中的GuardAgent生成的防护栏函数示例），并在EICU-AC上达到了90.8%的LPA和96.1%的CCA。这些结果支持我们在代码生成步骤中采用可调用函数列表和演示作为关键设计，并展示了GuardAgent在零样本情况下处理新防护请求的良好泛化能力。'
- en: Moreover, we consider an even more challenging guardrail task. We use the GPT-4
    model to safeguard EHRAgent on EICU-AC, but remove all instructions related to
    code generation. In other words, the LLM has to figure out its way, either with
    or without code generation, to provide a guardrail. Interestingly, we find that
    for 68.0% examples in EICU-AC, the LLM chose to generate a code-based guardrail
    (though mostly inexecutable). This result shows the intrinsic tendency of LLMs
    to utilize code as a structured and precise method for guardrail, supporting our
    design of GuardAgent based on code generation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们考虑了一个更加具有挑战性的安全防护任务。我们使用GPT-4模型来保护EICU-AC中的EHRAgent，但去除了所有与代码生成相关的指令。换句话说，LLM必须自己摸索，无论是否生成代码，都能提供安全防护。有趣的是，我们发现，在EICU-AC中的68.0%的示例中，LLM选择了生成基于代码的安全防护（尽管大多数情况下不可执行）。这一结果展示了LLM倾向于使用代码作为一种结构化且精确的安全防护方法，支持我们基于代码生成设计GuardAgent。
- en: 6 Conclusion
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this paper, we present the first study on guardrails for LLM agents to address
    diverse user safety requests. We propose GuardAgent, the first LLM agent framework
    designed to safeguard other LLM agents. GuardAgent leverages knowledge-enabled
    reasoning capabilities of LLMs to generate a task plan and convert it into a guardrail
    code. It is featured by the generalization capabilities to new guardrail requests,
    the reliability of the code-based guardrail, and the low computational overhead.
    In addition, we propose two benchmarks for evaluating privacy-related access control
    and safety control of LLM agents for healthcare and the web, respectively. We
    show that GuardAgent outperforms ‘model guarding agent’ baselines on these two
    benchmarks and the code generalization capabilities of GuardAgent under zero-shot
    settings.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了首个关于LLM代理安全防护的研究，旨在应对各种用户安全需求。我们提出了GuardAgent，这是第一个旨在保护其他LLM代理的LLM代理框架。GuardAgent利用LLM的知识启用推理能力生成任务计划，并将其转化为安全防护代码。其特点是能够概括新型安全防护请求、代码化安全防护的可靠性和低计算开销。此外，我们提出了两个基准测试，分别用于评估LLM代理在医疗和网页领域的隐私相关访问控制和安全控制。我们展示了GuardAgent在这两个基准测试中超越了“模型保护代理”基线，并且在零样本设置下，GuardAgent的代码泛化能力表现出色。
- en: References
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Guardrails AI. [https://www.guardrailsai.com/](https://www.guardrailsai.com/),
    2023.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Guardrails AI. [https://www.guardrailsai.com/](https://www.guardrailsai.com/)，2023年。'
- en: '[2] Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, and Ramesh Jain. Conversational
    health agents: A personalized llm-powered agent framework, 2024.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Mahyar Abbasian, Iman Azimi, Amir M. Rahmani, 和 Ramesh Jain. 会话健康代理：一个个性化的LLM驱动代理框架，2024年。'
- en: '[3] Can Cui, Zichong Yang, Yupeng Zhou, Yunsheng Ma, Juanwu Lu, Lingxi Li,
    Yaobin Chen, Jitesh Panchal, and Ziran Wang. Personalized autonomous driving with
    large language models: Field experiments, 2024.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Can Cui, Zichong Yang, Yupeng Zhou, Yunsheng Ma, Juanwu Lu, Lingxi Li,
    Yaobin Chen, Jitesh Panchal, 和 Ziran Wang. 基于大语言模型的个性化自动驾驶：实地实验，2024年。'
- en: '[4] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,
    Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web, 2023.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,
    Huan Sun, 和 Yu Su. Mind2web: 迈向一个通用型网页代理，2023年。'
- en: '[5] Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari, Yutaka Matsuo,
    Douglas Eck, and Aleksandra Faust. A real-world webagent with planning, long context
    understanding, and program synthesis. In The Twelfth International Conference
    on Learning Representations, 2024.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari, Yutaka Matsuo,
    Douglas Eck, 和 Aleksandra Faust. 一种具有规划、长上下文理解和程序合成能力的真实世界网页代理。发表于《第十二届国际学习表示大会》，2024年。'
- en: '[6] Wencheng Han, Dongqian Guo, Cheng-Zhong Xu, and Jianbing Shen. Dme-driver:
    Integrating human decision logic and 3d scene perception in autonomous driving,
    2024.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Wencheng Han, Dongqian Guo, Cheng-Zhong Xu, 和 Jianbing Shen. Dme-driver:
    将人类决策逻辑与3D场景感知结合的自动驾驶，2024年。'
- en: '[7] Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer,
    Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, and Madian
    Khabsa. Llama guard: Llm-based input-output safeguard for human-ai conversations,
    2023.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer,
    Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, 和 Madian
    Khabsa. Llama guard: 基于LLM的人类-人工智能对话输入输出安全防护，2023年。'
- en: '[8] Ye Jin, Xiaoxi Shen, Huiling Peng, Xiaoan Liu, Jingli Qin, Jiayang Li,
    Jintao Xie, Peizhong Gao, Guyue Zhou, and Jiangtao Gong. Surrealdriver: Designing
    generative driver agent simulation framework in urban contexts based on large
    language model, 2023.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Ye Jin, Xiaoxi Shen, Huiling Peng, Xiaoan Liu, Jingli Qin, Jiayang Li,
    Jintao Xie, Peizhong Gao, Guyue Zhou, 和 Jiangtao Gong. Surrealdriver：基于大语言模型设计的城市环境下生成驾驶员代理模拟框架，2023年。'
- en: '[9] Alyssa Lees, Vinh Q. Tran, Yi Tay, Jeffrey Sorensen, Jai Gupta, Donald
    Metzler, and Lucy Vasserman. A new generation of perspective api: Efficient multilingual
    character-level transformers. In Proceedings of the 28th ACM SIGKDD Conference
    on Knowledge Discovery and Data Mining, 2022.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Alyssa Lees, Vinh Q. Tran, Yi Tay, Jeffrey Sorensen, Jai Gupta, Donald
    Metzler, 和 Lucy Vasserman. 新一代视角API：高效的多语言字符级变换器. 见于第28届ACM SIGKDD知识发现与数据挖掘大会，2022年。'
- en: '[10] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    Sebastian Riedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive
    nlp tasks. In Proceedings of the 34th International Conference on Neural Information
    Processing Systems, 2020.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    Sebastian Riedel, 和 Douwe Kiela. 用于知识密集型NLP任务的检索增强生成. 见于第34届神经信息处理系统国际会议，2020年。'
- en: '[11] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, and Yang Liu. Agent hospital: A simulacrum of hospital with evolvable
    medical agents, 2024.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Junkai Li, Siyu Wang, Meng Zhang, Weitao Li, Yunghwei Lai, Xinhui Kang,
    Weizhi Ma, 和 Yang Liu. 代理医院：一个具有可进化医学代理的医院模拟体，2024年。'
- en: '[12] Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, and Yue Wang. A language
    agent for autonomous driving. 2023.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, 和 Yue Wang. 一种用于自动驾驶的语言代理.
    2023年。'
- en: '[13] Todor Markov, Chong Zhang, Sandhini Agarwal, Tyna Eloundou, Teddy Lee,
    Steven Adler, Angela Jiang, and Lilian Weng. A holistic approach to undesired
    content detection in the real world. In AAAI, 2023.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Todor Markov, Chong Zhang, Sandhini Agarwal, Tyna Eloundou, Teddy Lee,
    Steven Adler, Angela Jiang, 和 Lilian Weng. 一种面向现实世界中不良内容检测的整体方法. 见于AAAI，2023年。'
- en: '[14] Tom J Pollard, Alistair E W Johnson, Jesse D Raffa, Leo A Celi, Roger G
    Mark, and Omar Badawi. The eicu collaborative research database, a freely available
    multi-center database for critical care research. Scientific Data, 2018.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Tom J Pollard, Alistair E W Johnson, Jesse D Raffa, Leo A Celi, Roger
    G Mark, 和 Omar Badawi. eicu协作研究数据库，一个自由提供的多中心危重病研究数据库. 《科学数据》，2018年。'
- en: '[15] Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek Mittal,
    and Peter Henderson. Fine-tuning aligned language models compromises safety, even
    when users do not intend to! In The Twelfth International Conference on Learning
    Representations, 2024.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Xiangyu Qi, Yi Zeng, Tinghao Xie, Pin-Yu Chen, Ruoxi Jia, Prateek Mittal,
    和 Peter Henderson. 微调对齐语言模型危及安全性，即便用户并非有意为之！ 见于第十二届国际学习表征会议，2024年。'
- en: '[16] Traian Rebedea, Razvan Dinu, Makesh Narsimhan Sreedhar, Christopher Parisien,
    and Jonathan Cohen. NeMo guardrails: A toolkit for controllable and safe LLM applications
    with programmable rails. In Proceedings of the 2023 Conference on Empirical Methods
    in Natural Language Processing: System Demonstrations, December 2023.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Traian Rebedea, Razvan Dinu, Makesh Narsimhan Sreedhar, Christopher Parisien,
    和 Jonathan Cohen. NeMo护栏：一套用于可控和安全LLM应用程序的工具包，带有可编程护栏. 见于2023年自然语言处理经验方法大会：系统演示，2023年12月。'
- en: '[17] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda
    Zhu, Joyce Ho, Carl Yang, and May D. Wang. Ehragent: Code empowers large language
    models for few-shot complex tabular reasoning on electronic health records, 2024.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda
    Zhu, Joyce Ho, Carl Yang, 和 May D. Wang. Ehragent：代码赋能大型语言模型在电子健康记录上的少样本复杂表格推理，2024年。'
- en: '[18] Tao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro
    Tanno, Amy Wang, Brenna Li, Mohamed Amin, Nenad Tomasev, Shekoofeh Azizi, Karan
    Singhal, Yong Cheng, Le Hou, Albert Webson, Kavita Kulkarni, S Sara Mahdavi, Christopher
    Semturs, Juraj Gottweis, Joelle Barral, Katherine Chou, Greg S Corrado, Yossi
    Matias, Alan Karthikesalingam, and Vivek Natarajan. Towards conversational diagnostic
    ai, 2024.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Tao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro
    Tanno, Amy Wang, Brenna Li, Mohamed Amin, Nenad Tomasev, Shekoofeh Azizi, Karan
    Singhal, Yong Cheng, Le Hou, Albert Webson, Kavita Kulkarni, S Sara Mahdavi, Christopher
    Semturs, Juraj Gottweis, Joelle Barral, Katherine Chou, Greg S Corrado, Yossi
    Matias, Alan Karthikesalingam, 和 Vivek Natarajan. 面向对话诊断AI的研究，2024年。'
- en: '[19] Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui
    Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et al. Decodingtrust:
    A comprehensive assessment of trustworthiness in gpt models. 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] 王博鑫, 陈伟新, 裴恒智, 谢楚林, 康敏通, 张晨晖, 许车剑, 熊子狄, 达达·里提克, 赖兰·谢弗, 等. 解码信任：对 GPT 模型可信度的全面评估。2023年。'
- en: '[20] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter,
    Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. Chain of thought prompting elicits
    reasoning in large language models. In Advances in Neural Information Processing
    Systems, 2022.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] 韦杰森, 王学志, 达尔·施尔曼, 马尔滕·博斯马, 布莱恩·伊奇特, 夏飞, 艾德·H·齐, 乐国伟, 和周邓尼. 思维链提示在大型语言模型中引发推理。发表于神经信息处理系统进展，2022年。'
- en: '[21] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming
    Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang,
    Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu,
    Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin,
    Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui. The rise and potential
    of large language model based agents: A survey, 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] 习志恒, 陈文翔, 郭鑫, 何伟, 丁怡文, 洪博扬, 张铭, 王俊哲, 金森杰, 周恩宇, 郑瑞, 范晓冉, 王晓, 熊丽茂, 周宇浩,
    王伟然, 蒋长豪, 邹一程, 刘向阳, 尹张月, 杜诗寒, 翁荣祥, 程文森, 张琦, 秦文娟, 郑永岩, 邱西鹏, 黄宣晶, 和桂涛. 大型语言模型代理的崛起与潜力：一项综述，2023年。'
- en: '[22] Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao,
    Wenhao Huang, Shiji Song, and Gao Huang. Llm agents for psychology: A study on
    gamified assessments, 2024.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] 杨启森, 王泽坤, 陈洪辉, 王申志, 蒲怡凡, 高鑫, 黄文浩, 宋世杰, 和黄高. 心理学中的 LLM 代理：关于游戏化评估的研究，2024年。'
- en: '[23] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
    and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. In International
    Conference on Learning Representations (ICLR), 2023.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] 姚顺宇, 赵杰斐, 于典, 杜楠, 沙夫兰·伊扎克, 纳拉西曼·卡尔提克, 和曹远. ReAct：推理与行动在语言模型中的协同作用。发表于国际学习表征会议（ICLR），2023年。'
- en: '[24] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang,
    Rong Liu, Jordan W. Suchow, and Khaldoun Khashanah. Finmem: A performance-enhanced
    llm trading agent with layered memory and character design, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] 杨阳余, 李浩航, 陈志, 蒋月辰, 李扬, 张邓辉, 刘蓉, 乔丹·W·萨丘, 和哈尔顿·卡沙纳. Finmem：一种性能增强的具有分层记忆和角色设计的
    LLM 交易代理，2023年。'
- en: '[25] Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie Zhao, Tian
    Xia, Lizhen Xu, Binglin Zhou, Li Fangqi, Zhuosheng Zhang, Rui Wang, and Gongshen
    Liu. R-judge: Benchmarking safety risk awareness for LLM agents. In ICLR 2024
    Workshop on Large Language Model (LLM) Agents, 2024.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] 袁同鑫, 何志伟, 董凌钟, 王一鸣, 赵瑞杰, 夏天, 许丽珍, 周秉林, 方琦李, 张卓生, 王瑞, 和刘功申. R-judge：LLM
    代理的安全风险意识基准测试。发表于 ICLR 2024 大型语言模型（LLM）代理工作坊，2024年。'
- en: '[26] Zhuowen Yuan, Zidi Xiong, Yi Zeng, Ning Yu, Ruoxi Jia, Dawn Song, and
    Bo Li. Rigorllm: Resilient guardrails for large language models against undesired
    content. In ICML, 2024.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] 袁周文, 熊子狄, 曾怡, 于宁, 贾若曦, 宋晨, 和李博. Rigorllm：抵御不良内容的强韧护栏，适用于大型语言模型。发表于 ICML，2024年。'
- en: '[27] Boyuan Zheng, Boyu Gou, Jihyung Kil, Huan Sun, and Yu Su. Gpt-4v(ision)
    is a generalist web agent, if grounded. arXiv preprint arXiv:2401.01614, 2024.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] 郑博源, 苟博宇, 吉亨基尔, 孙欢, 和苏宇. GPT-4v(视觉)是一个通用型网页代理，前提是有实地基础。arXiv 预印本 arXiv:2401.01614，2024年。'
- en: '[28] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
    Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic
    web environment for building autonomous agents. arXiv preprint arXiv:2307.13854,
    2023.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] 周书彦, 徐弗兰克·F, 朱浩, 周旭辉, 罗伯特·洛, 阿比谢克·斯里达, 程显易, 约拿坦·比斯克, 丹尼尔·弗里德, 乌里·阿隆, 等.
    Webarena：一个构建自主代理的现实网络环境。arXiv 预印本 arXiv:2307.13854，2023年。'
- en: Limitations
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: While GuardAgent performs well on the two benchmarks with also evidence of its
    generalization capabilities, it requires the core LLM to have descent reasoning
    capabilities. This limitation is due to the complexity of both the guardrail tasks
    and the target agent to be safeguarded. However, this limitation can be mitigated
    as current LLMs are becoming more and more powerful in reasoning.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 GuardAgent 在两个基准测试上表现良好，并且有其泛化能力的证据，但它要求核心 LLM 具有合理的推理能力。这个限制源于 guardrail
    任务和目标代理的复杂性。然而，随着当前 LLM 在推理能力上的不断增强，这一限制是可以减轻的。
- en: Broader Impacts
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更广泛的影响
- en: We propose GuardAgent with potentially positive social impacts. GuardAgent is
    the first LLM agent framework that safeguards other LLM agents. GuardAgent directly
    addresses the safety and trustworthiness concerns of LLM agents and will potentially
    inspire more advanced guardrail approaches for LLM agents.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了具有潜在积极社会影响的GuardAgent。GuardAgent是第一个旨在保护其他LLM代理的LLM代理框架。GuardAgent直接解决了LLM代理的安全性和可信度问题，可能会激发更先进的LLM代理防护方法。
- en: Appendix A Details About the EICU-AC Benchmark
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A EICU-AC基准的详细信息
- en: A.1 Role-Based Access Permission
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 基于角色的访问权限
- en: 'For the EICU-AC benchmark, we consider three roles: ‘physician’, ‘nursing’,
    and ‘general administration’. These roles are selected based on our understanding
    of the ICU environment. Although various other roles exist, we focus on these
    three roles due to their prevalence, ensuring sufficient queries relevant to each
    role when creating the benchmark.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于EICU-AC基准，我们考虑了三种角色：‘医生’、‘护理’和‘综合管理’。这些角色是基于我们对ICU环境的理解选择的。尽管还有许多其他角色存在，但由于这三种角色的普遍性，我们专注于这三种角色，以确保在创建基准时，每个角色都能进行足够的查询。
- en: '![Refer to caption](img/003485a15bcfb2c4d262ec98ef8232e3.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/003485a15bcfb2c4d262ec98ef8232e3.png)'
- en: (a) List of all databases and columns.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 所有数据库和列的列表。
- en: '![Refer to caption](img/d3238e5abd8989f523643951ffcc8193.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/d3238e5abd8989f523643951ffcc8193.png)'
- en: (b) Databases and columns accessible by ‘physician’.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: (b) ‘医生’角色可以访问的数据库和列。
- en: '![Refer to caption](img/c4c0ae44015fbd74025e79327ad4759b.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/c4c0ae44015fbd74025e79327ad4759b.png)'
- en: (c) Databases and columns accessible by ‘nursing’.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: (c) ‘护理’角色可以访问的数据库和列。
- en: empty space
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 空白区域
- en: '![Refer to caption](img/bc7c70cfb0be9a461b388d0dfe677d69.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/bc7c70cfb0be9a461b388d0dfe677d69.png)'
- en: (d) Databases and columns accessible by ‘general administration’.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: (d) ‘综合管理’角色可以访问的数据库和列。
- en: 'Figure 5: Databases and columns accessible to the three roles defined for EICU-AC,
    and the complete list of databases and columns for reference. Accessible columns
    and inaccessible columns for each role are marked in green while inaccessible
    ones are shaded.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：EICU-AC定义的三个角色可以访问的数据库和列，以及完整的数据库和列列表供参考。每个角色可访问和不可访问的列以绿色标出，无法访问的列则以阴影表示。
- en: 'For each role, we select a subset of accessible databases and columns from
    the EICU benchmark, as shown in Fig. [5](https://arxiv.org/html/2406.09187v1#A1.F5
    "Figure 5 ‣ A.1 Role-Based Access Permission ‣ Appendix A Details About the EICU-AC
    Benchmark ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"). Our selection rule is to query ChatGPT about the access permission
    for the three roles over each database. For example, for the ‘diagnosis’ database
    with four columns, ‘patientunitstayid’, ‘icd9code’, ‘diagnosisname’, and ‘diagnosistime’,
    we query ChatGPT using the prompt shown in Fig. [6](https://arxiv.org/html/2406.09187v1#A1.F6
    "Figure 6 ‣ A.1 Role-Based Access Permission ‣ Appendix A Details About the EICU-AC
    Benchmark ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"). ChatGPT responds with the recommended access permission (‘full access’,
    ‘limited access’, or ‘no access’) for each role to each of the four columns. Here,
    we follow all ‘full access’ and ‘no access’ recommendations by ChatGPT. For ‘limited
    access’, we set it to ‘no access’ if it is recommended for ‘physician’ or ‘nursing’;
    if it is recommended for ‘general administration’, we set it to ‘full access’.
    This is to ensure both ‘physician’ and ‘nursing’ roles have sufficient inaccessible
    databases so that there will be sufficient queries that should be denied in the
    ground truth (to achieve relatively balanced labeling for both roles).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '对于每个角色，我们从EICU基准中选择一部分可访问的数据库和列，如图[5](https://arxiv.org/html/2406.09187v1#A1.F5
    "图5 ‣ A.1 基于角色的访问权限 ‣ 附录A EICU-AC基准的详细信息 ‣ GuardAgent: 通过知识启用推理保护LLM代理的守卫代理")所示。我们的选择规则是向ChatGPT查询三个角色对每个数据库的访问权限。例如，对于包含四个列的‘诊断’数据库，分别是‘patientunitstayid’、‘icd9code’、‘diagnosisname’和‘diagnosistime’，我们使用图[6](https://arxiv.org/html/2406.09187v1#A1.F6
    "图6 ‣ A.1 基于角色的访问权限 ‣ 附录A EICU-AC基准的详细信息 ‣ GuardAgent: 通过知识启用推理保护LLM代理的守卫代理")所示的提示词查询ChatGPT。ChatGPT会根据每个角色对四个列的访问权限（‘完全访问’、‘有限访问’或‘无访问’）进行推荐。在此，我们遵循ChatGPT关于‘完全访问’和‘无访问’的所有推荐。对于‘有限访问’，如果推荐给‘医生’或‘护理’角色，则将其设置为‘无访问’；如果推荐给‘综合管理’角色，则将其设置为‘完全访问’。这样做是为了确保‘医生’和‘护理’角色有足够的不可访问数据库，以便在真实标签中可以进行足够的拒绝查询（从而实现两个角色的标注相对平衡）。'
- en: '![Refer to caption](img/01055a80db0f2a4670242c24f4216599.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/01055a80db0f2a4670242c24f4216599.png)'
- en: 'Figure 6: Our prompt to ChatGPT for the access permission for the three roles
    to the ‘diagnosis’ database (with four columns, ‘patientunitstayid’, ‘icd9code’,
    ‘diagnosisname’, and ‘diagnosistime’), and the responses of ChatGPT.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：我们向ChatGPT请求三个角色访问“诊断”数据库的权限（该数据库包含四列：‘patientunitstayid’，‘icd9code’，‘diagnosisname’，和‘diagnosistime’），以及ChatGPT的响应。
- en: A.2 Sampling from EICU
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 来自EICU的采样
- en: 'As mentioned in the main paper, each example in EICU-AC contains 1) a healthcare-related
    question and the correct answer, 2) the databases and the columns required to
    answer the question, 3) a user identity, 4) a binary label (either ‘0’ for ‘access
    granted’ and ‘1’ for ‘access denied’), and 5) databases and the columns required
    to answer the question but not accessible for the given role (if there are any).
    The examples in EICU-AC are created by sampling from the original EICU dataset
    following the steps below. First, from the 580 test examples in EICU, we obtain
    183 examples that are correctly responded to by EHRAgent with GPT-4 at temperature
    zero. For each of these examples, we manually check the code generated by EHRAgent
    to obtain the databases and columns required to answer the question. Second, we
    assign the three roles to each example, which gives 549 examples in total. We
    label these examples by checking if any of the required databases or columns are
    inaccessible to the given role (i.e., by comparing with the access permission
    for each role in Fig. [5](https://arxiv.org/html/2406.09187v1#A1.F5 "Figure 5
    ‣ A.1 Role-Based Access Permission ‣ Appendix A Details About the EICU-AC Benchmark
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")).
    This will lead to a highly imbalanced dataset with 136, 110, and 48 examples labeled
    ‘0’ for ‘physician’, ‘nursing’, and ‘general administration’, respectively, and
    47, 73, and 135 examples labeled ‘1’ for ‘physician’, ‘nursing’, and ‘general
    administration’, respectively. In the third step, we remove some of the 549 created
    examples to a) achieve a better balance between the labels and b) reduce the duplication
    of questions among these examples. We notice that for ‘general administration’,
    there are many more examples labeled ‘1’ than ‘0’, while for the other two roles,
    there are many more examples labeled ‘0’ than ‘1’. Thus, for each example with
    ‘general administration’ and label ‘1’, we remove it if any of the two examples
    with the same question for the other two roles are labeled ‘1’. Then, for each
    example with ‘nursing’ and label ‘1’, we remove it if any example with the same
    question for ‘physician’ is labeled ‘1’. Similarly, we remove each example with
    ‘physician’ and label ‘0’ if any of the two examples with the same question for
    the other two roles are also labeled ‘0’. Then for each example with ‘nursing’
    and label ‘0’, we remove it if any example with the same question for ‘general
    administration’ is labeled ‘0’. After this step, we have 41, 78, and 48 examples
    labeled ‘0’ for ‘physician’, ‘nursing’, and ‘general administration’, respectively,
    and 47, 41, and 62 examples labeled ‘1’ for ‘physician’, ‘nursing’, and ‘general
    administration’, respectively. Finally, we randomly remove some examples for ‘nursing’
    with label ‘0’ and ‘general administration’ with label ‘1’, and randomly add some
    examples for the other four categories (‘physician’ with label ‘0’, ‘general administration’
    with label ‘0’, ‘physician’ with label ‘1’, and ‘nursing’ with label ‘1’) to achieve
    a better balance. The added examples are generated based on the questions from
    the training set²²2In the original EICU dataset, both the training set and the
    test set do not contain the ground truth answer for each question. The ground
    truth answers in the test set of EICU are provided by Shi et al. [[17](https://arxiv.org/html/2406.09187v1#bib.bib17)].
    of the original EICU benchmark. The ultimate number of examples in our created
    EICU-AC benchmark is 316, with the distribution of examples across the three roles
    and two labels displayed in Tab [4](https://arxiv.org/html/2406.09187v1#A1.T4
    "Table 4 ‣ A.2 Sampling from EICU ‣ Appendix A Details About the EICU-AC Benchmark
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '如主文中所述，EICU-AC中的每个示例包含：1) 一个与医疗相关的问题及其正确答案，2) 回答该问题所需的数据库和列，3) 用户身份，4) 一个二进制标签（‘0’表示‘访问授权’，‘1’表示‘访问拒绝’），以及5)
    回答该问题所需的数据库和列，但对于给定角色不可访问（如果有的话）。EICU-AC中的示例是通过从原始EICU数据集中抽样生成的，具体步骤如下。首先，从EICU中的580个测试示例中，我们获得了183个示例，这些示例通过GPT-4在温度为零时由EHRAgent正确响应。对于每个示例，我们手动检查EHRAgent生成的代码，以获取回答问题所需的数据库和列。其次，我们将三个角色分配给每个示例，总共生成了549个示例。我们通过检查所需的数据库或列是否对给定角色不可访问来标注这些示例（即，通过与图[5](https://arxiv.org/html/2406.09187v1#A1.F5
    "Figure 5 ‣ A.1 Role-Based Access Permission ‣ Appendix A Details About the EICU-AC
    Benchmark ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")中每个角色的访问权限进行比较）。这将导致一个高度不平衡的数据集，其中‘physician’、‘nursing’和‘general administration’分别有136、110和48个示例被标注为‘0’，而分别有47、73和135个示例被标注为‘1’。在第三步，我们删除一些已创建的549个示例，以a)
    实现标签之间的更好平衡，b) 减少这些示例中问题的重复性。我们注意到，对于‘general administration’，标注为‘1’的示例比标注为‘0’的示例多得多，而对于其他两个角色，标注为‘0’的示例比标注为‘1’的示例多得多。因此，对于每个带有‘general
    administration’标签为‘1’的示例，如果其他两个角色中有相同问题的示例标注为‘1’，我们将删除该示例。然后，对于每个带有‘nursing’标签为‘1’的示例，如果‘physician’角色中有相同问题的示例标注为‘1’，我们将删除该示例。同样地，如果其他两个角色中有相同问题的示例也被标注为‘0’，我们将删除每个带有‘physician’标签为‘0’的示例。然后，对于每个带有‘nursing’标签为‘0’的示例，如果‘general
    administration’角色中有相同问题的示例标注为‘0’，我们将删除该示例。经过这一步后，我们得到41、78和48个示例，分别标注为‘0’的‘physician’、‘nursing’和‘general
    administration’，以及47、41和62个示例，分别标注为‘1’的‘physician’、‘nursing’和‘general administration’。最后，我们随机删除一些带标签‘0’的‘nursing’示例和带标签‘1’的‘general
    administration’示例，并随机添加一些其他四类的示例（‘physician’标签为‘0’，‘general administration’标签为‘0’，‘physician’标签为‘1’，和‘nursing’标签为‘1’），以实现更好的平衡。新增的示例是基于训练集中的问题生成的²²2在原始EICU数据集中，训练集和测试集都不包含每个问题的真实答案。EICU测试集中的真实答案由Shi等人提供[[17](https://arxiv.org/html/2406.09187v1#bib.bib17)]。我们创建的最终EICU-AC基准中的示例总数为316个，三个角色和两个标签之间的示例分布显示在表[4](https://arxiv.org/html/2406.09187v1#A1.T4
    "Table 4 ‣ A.2 Sampling from EICU ‣ Appendix A Details About the EICU-AC Benchmark
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning")中。'
- en: 'Table 4: Number of examples in EICU-AC for each role and each label.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 4：EICU-AC 中每个角色和每个标签的示例数量。
- en: '|  | physician | nursing | general administration |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | 医生 | 护理 | 一般管理 |'
- en: '| label ‘0’ (access denied) | 52 | 57 | 45 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 标签 ‘0’（访问拒绝） | 52 | 57 | 45 |'
- en: '| label ‘1’ (access granted) | 46 | 55 | 61 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 标签 ‘1’（访问授权） | 46 | 55 | 61 |'
- en: A.3 Healthcare Questions Involved in EICU-AC
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 EICU-AC 中涉及的医疗问题
- en: As mentioned in the main paper, our created EICU-AC dataset involves healthcare
    questions spanning 50 different ICU information categories, i.e., columns across
    all 10 databases of the EICU benchmark. We further categorize the questions in
    EICU-AC following the ‘template’ provided by EICU (extracted from the ‘q_tag’
    entry of each example [[17](https://arxiv.org/html/2406.09187v1#bib.bib17)]).
    This gives 70 different question templates, showing the high diversity of healthcare
    questions involved in our EICU-AC benchmark.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如主文中所述，我们创建的 EICU-AC 数据集包含了涉及 50 个不同 ICU 信息类别的医疗问题，即 EICU 基准中所有 10 个数据库的列。我们进一步按照
    EICU 提供的“模板”（从每个示例的 ‘q_tag’ 条目提取）对 EICU-AC 中的问题进行分类[[17](https://arxiv.org/html/2406.09187v1#bib.bib17)]。这提供了
    70 种不同的问题模板，展示了我们 EICU-AC 基准中涉及的医疗问题的高度多样性。
- en: 'Table 5: Number of examples labeled ‘1’ in Mind2Web-SC for each rule violation.
    Note that examples labeled ‘0’ do not violate any rules.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5：Mind2Web-SC 中每个规则违反的标记为 ‘1’ 的示例数量。请注意，标记为 ‘0’ 的示例不违反任何规则。
- en: '| Safety rules | No. examples |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 安全规则 | 示例数量 |'
- en: '| Rule 1: User must be a member to shop. | 19 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 规则 1：用户必须是会员才能购物。 | 19 |'
- en: '| Rule 2: Unvaccinated user cannot book a flight | 12 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 规则 2：未接种疫苗的用户不能预订航班 | 12 |'
- en: '| Rule 3: User without a driver’s license cannot buy or rent a car. | 24 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 规则 3：没有驾驶执照的用户不能购买或租赁汽车。 | 24 |'
- en: '| Rule 4: User aged under 18 cannot book a hotel. | 18 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 规则 4：未满 18 岁的用户不能预订酒店。 | 18 |'
- en: '| Rule 5: User must be in certain countries to search movies/musics/video.
    | 21 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 规则 5：用户必须在特定国家才能搜索电影/音乐/视频。 | 21 |'
- en: '| Rule 6: User under 15 cannot apply for jobs. | 6 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 规则 6：未满 15 岁的用户不能申请工作。 | 6 |'
- en: Appendix B Details About the Mind2Web-SC Benchmark
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B Mind2Web-SC 基准的详细信息
- en: 'In Sec. [3.2](https://arxiv.org/html/2406.09187v1#S3.SS2 "3.2 SeeAct and Mind2Web-SC
    Benchmark ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent: Safeguard LLM
    Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we have defined six
    safety rules for the Mind2Web-SC Benchmark. Rule 1 requires ‘membership’ in the
    user information to be ‘true’. Rule 2 requires ‘vaccine’ in the user information
    to be ‘true’. Rule 3 requires ‘dr_license’ in the user information to be ‘true’.
    Rule 4 requires ‘age’ in the user information to be no less than 18. Rule 5 requires
    ‘domestic’ in the user information to be ‘true’. Rule 6 requires ‘age’ in the
    user information to be no less than 15. In Tab. [5](https://arxiv.org/html/2406.09187v1#A1.T5
    "Table 5 ‣ A.3 Healthcare Questions Involved in EICU-AC ‣ Appendix A Details About
    the EICU-AC Benchmark ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via
    Knowledge-Enabled Reasoning"), we show the number of examples labeled ‘1’ in Mind2Web-SC
    for each rule violation. Note that examples labeled ‘0’ do not violate any rules.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 [3.2](https://arxiv.org/html/2406.09187v1#S3.SS2 "3.2 SeeAct 和 Mind2Web-SC
    基准 ‣ 3 安全请求针对多样化 LLM 代理 ‣ GuardAgent：通过知识启用推理保护 LLM 代理的守卫代理") 节中，我们为 Mind2Web-SC
    基准定义了六条安全规则。规则 1 要求用户信息中的“会员资格”为“真实”。规则 2 要求用户信息中的“疫苗”状态为“真实”。规则 3 要求用户信息中的“驾驶执照”状态为“真实”。规则
    4 要求用户信息中的“年龄”不小于 18 岁。规则 5 要求用户信息中的“国内”状态为“真实”。规则 6 要求用户信息中的“年龄”不小于 15 岁。在表 [5](https://arxiv.org/html/2406.09187v1#A1.T5
    "表 5 ‣ A.3 EICU-AC 中涉及的医疗问题 ‣ 附录 A EICU-AC 基准的详细信息 ‣ GuardAgent：通过知识启用推理保护 LLM
    代理的守卫代理") 中，我们展示了 Mind2Web-SC 中标记为‘1’的每个规则违反示例的数量。请注意，标记为‘0’的示例不违反任何规则。
- en: 'During the construction of Mind2Web-SC, we added some examples with label ‘1’
    and removed some examples with label ‘0’ to balance the two classes. By only following
    the steps in Sec. [3.2](https://arxiv.org/html/2406.09187v1#S3.SS2 "3.2 SeeAct
    and Mind2Web-SC Benchmark ‣ 3 Safety Requests for Diverse LLM Agents ‣ GuardAgent:
    Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning") without
    any adding or removal of examples, we obtain a highly imbalanced dataset with
    178 examples labeled ‘0’ and only 70 examples labeled ‘1’. Among the 178 examples
    labeled ‘0’, there are 148 examples with the tasks irrelevant to any of the rules
    – we keep 50 of them and remove the other $(148-50=)$ 98 examples. All 30 examples
    labeled ‘0’ but related to at least one rule are also kept. Then, we create 30
    examples labeled ‘1’ by reusing the tasks for these 30 examples labeled ‘0’. We
    keep generating random user profiles for these tasks until the task-related rule
    is violated, and the example is labeled to ‘1’. Note that the tasks are randomly
    selected but manually controlled to avoid duplicated tasks within one class. Similarly,
    we created 20 examples labeled ‘0’ by reusing the tasks for examples labeled ‘1’,
    with randomly generated user information without any rule violation. Finally,
    we obtain the Mind2Web-SC dataset with 100 examples in each class (200 examples
    in total). Among the 100 examples labeled ‘0’, 50 are related to at least one
    of the rules.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建 Mind2Web-SC 时，我们添加了一些标签为 '1' 的示例，并移除了部分标签为 '0' 的示例，以平衡这两个类别。仅按照第 [3.2](https://arxiv.org/html/2406.09187v1#S3.SS2
    "3.2 SeeAct 和 Mind2Web-SC 基准测试 ‣ 3 安全请求针对多样化 LLM 代理 ‣ GuardAgent：通过知识驱动推理保护 LLM
    代理") 节的步骤操作，不进行任何示例的添加或删除，我们得到一个高度不平衡的数据集，其中标签为 '0' 的示例有 178 个，标签为 '1' 的示例仅有 70
    个。在这 178 个标签为 '0' 的示例中，有 148 个与任何规则无关的任务 —— 我们保留其中的 50 个，移除其余的 $(148-50=)$ 98
    个示例。所有 30 个标签为 '0' 但与至少一条规则相关的示例也被保留。接着，我们通过重用这 30 个标签为 '0' 的示例任务，创建了 30 个标签为
    '1' 的示例。我们不断生成随机的用户档案，直到任务相关的规则被违反，示例被标记为 '1'。请注意，这些任务是随机选择的，但手动控制，以避免一个类别内的任务重复。类似地，我们通过重用标签为
    '1' 的示例任务，生成了 20 个标签为 '0' 的示例，这些示例的用户信息是随机生成的，且没有违反任何规则。最终，我们得到 Mind2Web-SC 数据集，每个类别有
    100 个示例（共 200 个示例）。在 100 个标签为 '0' 的示例中，50 个与至少一条规则相关。
- en: Appendix C Detailed System Prompts for Naive Access Control and Safety Control
    Based on Instructions
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 C 基于指令的简单访问控制和安全控制的详细系统提示
- en: 'In our preliminary studies, We created a naive access control for EHRAgent
    and a naive safety control for SeeAct by directly modifying their system prompts
    for planning. These approaches are either ineffective in safeguarding the agents
    or degrade the benign performance of the agents. In Fig. [7](https://arxiv.org/html/2406.09187v1#A3.F7
    "Figure 7 ‣ Appendix C Detailed System Prompts for Naive Access Control and Safety
    Control Based on Instructions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent
    via Knowledge-Enabled Reasoning"), we show the instructions we injected into the
    system prompts of these two agents.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的初步研究中，我们为 EHRAgent 创建了一个简单的访问控制，并通过直接修改其系统提示来为 SeeAct 创建了一个简单的安全控制。这些方法要么在保护代理方面无效，要么会降低代理的正常性能。在图
    [7](https://arxiv.org/html/2406.09187v1#A3.F7 "图 7 ‣ 附录 C 基于指令的简单访问控制和安全控制的详细系统提示
    ‣ GuardAgent：通过知识驱动推理保护 LLM 代理") 中，我们展示了我们注入到这两个代理系统提示中的指令。
- en: '![Refer to caption](img/215bccea9009767ea13f6a7fe097053d.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/215bccea9009767ea13f6a7fe097053d.png)'
- en: 'Figure 7: Instructions injected into the system prompt of EHRAgent for access
    control and SeeAct for safety control, as naive baselines that motivate our GuardAgent.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：注入到 EHRAgent 系统提示中的用于访问控制的指令和注入到 SeeAct 系统提示中的用于安全控制的指令，作为激发我们 GuardAgent
    的简单基准。
- en: Appendix D Complete Inputs and Output of GuardAgent
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D GuardAgent 的完整输入和输出
- en: Complete Inputs to GuardAgent
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GuardAgent 的完整输入
- en: 'As described in Sec. [4.2](https://arxiv.org/html/2406.09187v1#S4.SS2 "4.2
    Task Planning ‣ 4 GuardAgent Framework ‣ GuardAgent: Safeguard LLM Agents by a
    Guard Agent via Knowledge-Enabled Reasoning"), the inputs to GuardAgent include
    a specification $I_{s}$ of the target agent, a set of guard requests $I_{r}$,
    inputs $I_{i}$ to the target agent, and the output log $I_{o}$ by the target agent
    corresponding to $I_{i}$. In Fig. [8](https://arxiv.org/html/2406.09187v1#A4.F8
    "Figure 8 ‣ Complete Inputs to GuardAgent ‣ Appendix D Complete Inputs and Output
    of GuardAgent ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), we show the actual $I_{s}$ and $I_{r}$ for GuardAgent in our experiments
    for both EHRAgent on EICU-AC and SeeAct on Mind2Web. In the same figure, we also
    show the actual planning instruction $I_{p}$ and the actual instruction $I_{c}$
    used for code generation. In Fig. [9](https://arxiv.org/html/2406.09187v1#A4.F9
    "Figure 9 ‣ Complete Inputs to GuardAgent ‣ Appendix D Complete Inputs and Output
    of GuardAgent ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), we show real examples for the target agent inputs $I_{i}$ and output
    logs $I_{o}$ for both EHRAgent on EICU-AC and SeeAct on Mind2Web.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '如第 [4.2](https://arxiv.org/html/2406.09187v1#S4.SS2 "4.2 任务规划 ‣ GuardAgent框架
    ‣ GuardAgent: 通过知识驱动推理保护LLM代理的守卫代理")节中所述，GuardAgent的输入包括目标代理的规范$I_{s}$、一组守卫请求$I_{r}$、目标代理的输入$I_{i}$，以及目标代理对应$I_{i}$的输出日志$I_{o}$。在图
    [8](https://arxiv.org/html/2406.09187v1#A4.F8 "图 8 ‣ GuardAgent的完整输入 ‣ 附录D GuardAgent的完整输入和输出
    ‣ GuardAgent: 通过知识驱动推理保护LLM代理的守卫代理")中，我们展示了在我们的实验中，EHRAgent在EICU-AC上的实际$I_{s}$和$I_{r}$，以及SeeAct在Mind2Web上的实际$I_{s}$和$I_{r}$。在同一图中，我们还展示了实际的规划指令$I_{p}$和用于代码生成的实际指令$I_{c}$。在图
    [9](https://arxiv.org/html/2406.09187v1#A4.F9 "图 9 ‣ GuardAgent的完整输入 ‣ 附录D GuardAgent的完整输入和输出
    ‣ GuardAgent: 通过知识驱动推理保护LLM代理的守卫代理")中，我们展示了EHRAgent在EICU-AC和SeeAct在Mind2Web上的目标代理输入$I_{i}$和输出日志$I_{o}$的实际示例。'
- en: '![Refer to caption](img/125d55f8f3c08c83867d2afd770690b0.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/125d55f8f3c08c83867d2afd770690b0.png)'
- en: 'Figure 8: The actual planning instruction $I_{p}$, instruction $I_{c}$ for
    guardrail code generation, target agent specification $I_{s}$ and guard requests
    $I_{r}$ we used in our experiments for the two agents, EHRAgent and SeeAct, and
    the two benchmarks, EICU-AC and Mind2Web-SC.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：我们在实验中使用的实际规划指令$I_{p}$、用于守卫代码生成的指令$I_{c}$、目标代理规范$I_{s}$和守卫请求$I_{r}$，适用于两个代理EHRAgent和SeeAct，以及两个基准测试EICU-AC和Mind2Web-SC。
- en: '![Refer to caption](img/88de1a35b019473958bc5cbe09360434.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/88de1a35b019473958bc5cbe09360434.png)'
- en: 'Figure 9: Examples for target agent inputs $I_{i}$ and output logs $I_{o}$,
    as the inputs to GuardAgent, for the two agents, EHRAgent and SeeAct, and the
    two benchmarks, EICU-AC and Mind2Web-SC.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：目标代理输入$I_{i}$和输出日志$I_{o}$的示例，作为GuardAgent的输入，适用于两个代理EHRAgent和SeeAct，以及两个基准测试EICU-AC和Mind2Web-SC。
- en: Outputs of GuardAgent
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: GuardAgent的输出
- en: 'The intermediate outputs of GuardAgent, including the generated action plan
    $P$ and the guardrail code $C$, are similar to those in the manually created demonstrations
    (see App. [G](https://arxiv.org/html/2406.09187v1#A7 "Appendix G Manually Created
    Demonstrations ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning")); thus, we do not repeatedly show them. Here, we show example outputs,
    including the label prediction $O_{l}$ and the detailed reasons $O_{d}$ of GuardAgent
    for both benchmarks in Fig. [10](https://arxiv.org/html/2406.09187v1#A4.F10 "Figure
    10 ‣ Outputs of GuardAgent ‣ Appendix D Complete Inputs and Output of GuardAgent
    ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning").'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 'GuardAgent的中间输出，包括生成的行动计划$P$和守卫代码$C$，与手动创建的演示中类似（参见附录 [G](https://arxiv.org/html/2406.09187v1#A7
    "附录 G 手动创建的演示 ‣ GuardAgent: 通过知识驱动推理保护LLM代理的守卫代理")）；因此，我们不再重复显示这些输出。这里，我们展示了示例输出，包括标签预测$O_{l}$和GuardAgent的详细原因$O_{d}$，用于图
    [10](https://arxiv.org/html/2406.09187v1#A4.F10 "图 10 ‣ GuardAgent的输出 ‣ 附录D GuardAgent的完整输入和输出
    ‣ GuardAgent: 通过知识驱动推理保护LLM代理的守卫代理")中两个基准测试的结果。'
- en: '![Refer to caption](img/00eea11d75394dbee497a5293dadf9eb.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/00eea11d75394dbee497a5293dadf9eb.png)'
- en: 'Figure 10: Example outputs of GuardAgent, including the label prediction $O_{l}$,
    the detailed reasons $O_{d}$, and the final answer/action of the target agent
    with guardrail, for the two agents, EHRAgent and SeeAct, and the two benchmarks,
    EICU-AC and Mind2Web-SC.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：GuardAgent的示例输出，包括标签预测$O_{l}$、详细原因$O_{d}$和目标代理的最终答案/行动（带有守卫代码），适用于两个代理EHRAgent和SeeAct，以及两个基准测试EICU-AC和Mind2Web-SC。
- en: Appendix E Callable Functions
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 E 可调用函数
- en: 'Our experiments involve two callable functions shown in Fig. [11](https://arxiv.org/html/2406.09187v1#A5.F11
    "Figure 11 ‣ Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning"). However, the user of GuardAgent
    can easily extend the toolbox by uploading more functions. The actual toolbox
    of GuardAgent in practice will contain much more callable functions than for our
    experiments.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的实验涉及图 [11](https://arxiv.org/html/2406.09187v1#A5.F11 "Figure 11 ‣ Appendix
    E Callable Functions ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning") 中展示的两个可调用函数。然而，GuardAgent 的用户可以通过上传更多函数轻松扩展工具箱。在实际应用中，GuardAgent 的工具箱将包含比我们实验中更多的可调用函数。'
- en: '![Refer to caption](img/29356d03a45334b47f2343e631b3663b.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/29356d03a45334b47f2343e631b3663b.png)'
- en: 'Figure 11: Callable functions in the toolbox of GuardAgent involved in our
    experiments.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：我们实验中涉及的 GuardAgent 工具箱中的可调用函数。
- en: Appendix F Prompts for Baselines
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 基准的提示词
- en: 'In the main experiments, we compare GuardAgent with two baselines using LLMs
    to safeguard LLM agents. The guardrail is created by prompting the LLM with a
    system instruction, the specification of the target agent, the guard requests,
    the user inputs to the target agent with the associated output logs, and a few
    show of examples. Here the system instruction is adapted from the one used by
    GuardAgent for task planning. However, we include additional instructions about
    the format of the guardrail outputs. The baselines do not involve any guardrail
    code generation, and this is reflected by the demonstrations we created that generate
    guardrails solely based on reasoning over the textual inputs to the LLM. In Fig.
    [12](https://arxiv.org/html/2406.09187v1#A6.F12 "Figure 12 ‣ Appendix F Prompts
    for Baselines ‣ GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled
    Reasoning"), we show the modified system prompt template for the baselines, with
    two example demonstrations for the two benchmarks, respectively.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '在主要实验中，我们将 GuardAgent 与两个基准进行了比较，基准使用 LLM 来保护 LLM 代理。护栏是通过向 LLM 提供系统指令、目标代理的规格、护栏请求、用户输入目标代理的内容及相关输出日志，以及一些示例来创建的。这里的系统指令是从
    GuardAgent 用于任务规划的指令改编而来的。然而，我们还包括了关于护栏输出格式的额外指令。基准不涉及任何护栏代码生成，这一点在我们创建的示例中得到了体现，示例仅仅是基于对
    LLM 文本输入的推理来生成护栏。在图 [12](https://arxiv.org/html/2406.09187v1#A6.F12 "Figure 12
    ‣ Appendix F Prompts for Baselines ‣ GuardAgent: Safeguard LLM Agents by a Guard
    Agent via Knowledge-Enabled Reasoning") 中，我们展示了针对基准修改后的系统提示模板，并为两个基准分别展示了两个示例演示。'
- en: '![Refer to caption](img/df5a833cc2ed3c73744607534e3b6c77.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/df5a833cc2ed3c73744607534e3b6c77.png)'
- en: 'Figure 12: System prompt template for the baselines and the two example demonstrations
    for EICU-AC and Mind2Web-SC, respectively.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：基准系统提示模板，以及针对 EICU-AC 和 Mind2Web-SC 两个示例的演示。
- en: Appendix G Manually Created Demonstrations
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 G 手动创建的示例
- en: 'We manually created a set of demonstrations for each benchmark. In Fig. [13](https://arxiv.org/html/2406.09187v1#A7.F13
    "Figure 13 ‣ Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard
    LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"), we show two example
    demonstrations for EHRAgent on EICU-AC and SeeAct on Mind2Web-SC, respectively.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '我们手动为每个基准创建了一组示例。在图 [13](https://arxiv.org/html/2406.09187v1#A7.F13 "Figure
    13 ‣ Appendix G Manually Created Demonstrations ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning") 中，我们展示了 EHRAgent 在 EICU-AC
    和 SeeAct 在 Mind2Web-SC 上的两个示例演示。'
- en: '![Refer to caption](img/fa65c5279b29da7460b9cd95a9a6e6f2.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明文字](img/fa65c5279b29da7460b9cd95a9a6e6f2.png)'
- en: 'Figure 13: Example demonstrations for EHRAgent on EICU-AC and SeeAct on Mind2Web-SC.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：EHRAgent 在 EICU-AC 和 SeeAct 在 Mind2Web-SC 上的示例演示。
- en: Appendix H Function Defined by GuardAgent in Zero-Shot Setting
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H 在零样本设置下由 GuardAgent 定义的功能
- en: 'In the zero-shot setting where GuardAgent is provided with neither the required
    functions nor demonstrations for guardrail code generation, GuardAgent can still
    generate guardrails by defining new functions. In Fig. [14](https://arxiv.org/html/2406.09187v1#A8.F14
    "Figure 14 ‣ Appendix H Function Defined by GuardAgent in Zero-Shot Setting ‣
    GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"),
    we show a function defined by GuardAgent during guardrail code generation. The
    function differs from those we provided in Fig. [11](https://arxiv.org/html/2406.09187v1#A5.F11
    "Figure 11 ‣ Appendix E Callable Functions ‣ GuardAgent: Safeguard LLM Agents
    by a Guard Agent via Knowledge-Enabled Reasoning"), but it achieves the same guardrail
    goals.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在零-shot设置中，GuardAgent既没有所需的功能，也没有防护代码生成的示范，仍然可以通过定义新功能来生成防护措施。在图[14](https://arxiv.org/html/2406.09187v1#A8.F14
    "图14 ‣ 附录H GuardAgent在零-shot设置中定义的函数 ‣ GuardAgent：通过知识启用推理保护LLM代理")中，我们展示了GuardAgent在防护代码生成过程中定义的一个函数。该函数与我们在图[11](https://arxiv.org/html/2406.09187v1#A5.F11
    "图11 ‣ 附录E 可调用的函数 ‣ GuardAgent：通过知识启用推理保护LLM代理")中提供的函数不同，但它实现了相同的防护目标。
- en: '![Refer to caption](img/e1996650d3d63776298ae57bee8ea5a4.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e1996650d3d63776298ae57bee8ea5a4.png)'
- en: 'Figure 14: A function defined by GuardAgent in zero-shot setting with neither
    demonstrations for code generation nor required functions'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：在零-shot设置下，由GuardAgent定义的函数，既没有代码生成示范，也没有所需的功能。
- en: Appendix I Execution Time of GuardAgent
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录I GuardAgent的执行时间
- en: The average execution time for GuardAgent (with GPT-4) safeguarding EHRAgent
    on EICU-AC is 45.4 seconds per example, while the average execution time for EHRAgent
    (with GPT-4) is 31.9 seconds per example. The average execution time for GuardAgent
    (with GPT-4) safeguarding SeeAct on Mind2Web-SC is about 60 seconds per example,
    while the average execution time for EHRAgent (with LLaVA-1.5) is about 20 seconds
    per example. In general, the execution time for GuardAgent is comparable to the
    execution time of the target agent. Moreover, human inspectors will likely need
    much more time than our GuardAgent to read the guard requests and then moderate
    the inputs and outputs of the target agent correspondingly. Given the effectiveness
    of our GuardAgent as shown in the experiments, we believe that GuardAgent is the
    current best for safeguarding LLM agents.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: GuardAgent（使用GPT-4）在EICU-AC上保护EHRAgent的平均执行时间为每个示例45.4秒，而EHRAgent（使用GPT-4）的平均执行时间为每个示例31.9秒。GuardAgent（使用GPT-4）在Mind2Web-SC上保护SeeAct的平均执行时间约为每个示例60秒，而EHRAgent（使用LLaVA-1.5）的平均执行时间约为每个示例20秒。总体而言，GuardAgent的执行时间与目标代理的执行时间相当。此外，人类检查员通常需要比我们的GuardAgent更多的时间来阅读防护请求，并相应地调整目标代理的输入和输出。鉴于实验中GuardAgent的有效性，我们相信GuardAgent是当前最适合保护LLM代理的工具。
