- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:44:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 12:44:54'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
    Predictive Agent Reasoning and Critical Agent Instruction'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于LLMs的少量样本疾病预测：一种结合预测代理推理与批判性代理指导的新方法
- en: 来源：[https://arxiv.org/html/2403.15464/](https://arxiv.org/html/2403.15464/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2403.15464/](https://arxiv.org/html/2403.15464/)
- en: \institutes
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \institutes
- en: ${}^{1}$ Department of Computer Science, Emory University, Atlanta, GA
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ${}^{1}$ 艾默里大学计算机科学系，美国乔治亚州亚特兰大
- en: ${}^{2}$ School of Computer Science & Engineering, University of Washington,
    Seattle, WA
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ${}^{2}$ 华盛顿大学计算机科学与工程学院，美国华盛顿州西雅图
- en: ${}^{3}$ Department of Computer Science & Engineering, UCSD, San Diego, CA
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ${}^{3}$ 加州大学圣地亚哥分校计算机科学与工程系，美国加利福尼亚州圣地亚哥
- en: ${}^{4}$ Rollins School of Public Health, Emory University, Atlanta, GA
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ${}^{4}$ 艾默里大学罗林斯公共卫生学院，美国乔治亚州亚特兰大
- en: ${}^{5}$ School of Medicine, Emory University, Atlanta, GA
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ${}^{5}$ 艾默里大学医学院，美国乔治亚州亚特兰大
- en: Hejie Cui${}^{1}$    Zhuocheng Shen${}^{1}$    Jieyu Zhang${}^{2}$    Hui Shao
       MD    PhD${}^{4,5}$    Lianhui Qin    PhD${}^{3}$    Joyce C. Ho    PhD${}^{1}$
       Carl Yang    PhD${}^{1,4}$
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 崔贺杰${}^{1}$    沈卓诚${}^{1}$    张洁瑜${}^{2}$    邵辉    医学博士    博士${}^{4,5}$    秦连辉
       博士${}^{3}$    何Joyce C.    博士${}^{1}$    杨Carl    博士${}^{1,4}$
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Electronic health records (EHRs) contain valuable patient data for health-related
    prediction tasks, such as disease prediction. Traditional approaches rely on supervised
    learning methods that require large labeled datasets, which can be expensive and
    challenging to obtain. In this study, we investigate the feasibility of applying
    Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses,
    labs, prescriptions) into natural language narratives. We evaluate the zero-shot
    and few-shot performance of LLMs using various EHR-prediction-oriented prompting
    strategies. Furthermore, we propose a novel approach that utilizes LLM agents
    with different roles: a predictor agent that makes predictions and generates reasoning
    processes and a critic agent that analyzes incorrect predictions and provides
    guidance for improving the reasoning of the predictor agent. Our results demonstrate
    that with the proposed approach, LLMs can achieve decent few-shot performance
    compared to traditional supervised learning methods in EHR-based disease predictions,
    suggesting its potential for health-oriented applications.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 电子健康记录（EHR）包含了宝贵的患者数据，广泛用于健康相关的预测任务，如疾病预测。传统方法依赖于需要大量标注数据集的监督学习方法，这些数据集的获取既昂贵又具有挑战性。在本研究中，我们探讨了将大型语言模型（LLMs）应用于将结构化的患者就诊数据（例如，诊断、实验室检查、处方）转换为自然语言叙述的可行性。我们评估了使用不同EHR预测导向的提示策略，LLMs在零样本和少量样本任务中的表现。此外，我们提出了一种新颖的方法，利用具有不同角色的LLM代理：一个预测代理负责进行预测并生成推理过程，另一个批判性代理负责分析错误的预测并提供改进预测代理推理的指导。我们的结果表明，使用该方法，LLMs在EHR基础的疾病预测中能达到与传统监督学习方法相媲美的少样本表现，表明其在健康导向应用中的潜力。
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Large Language Models (LLMs) have emerged as a powerful tool in various domains,
    including healthcare. These models, such as GPT family ^([1](https://arxiv.org/html/2403.15464v1#bib.bib1))
    and PaLM ^([2](https://arxiv.org/html/2403.15464v1#bib.bib2)), are trained on
    vast amounts of text data, allowing them to encode extensive knowledge across
    multiple fields. In the medical domain, the ability of LLMs to leverage their
    encoded medical knowledge has been showcased in recent studies ^([3](https://arxiv.org/html/2403.15464v1#bib.bib3);
    [4](https://arxiv.org/html/2403.15464v1#bib.bib4)), with impressive performance
    on tasks such as medical question answering ^([5](https://arxiv.org/html/2403.15464v1#bib.bib5)),
    clinical text summarization ^([6](https://arxiv.org/html/2403.15464v1#bib.bib6)),
    and clinical decision support ^([7](https://arxiv.org/html/2403.15464v1#bib.bib7)).
    Certain very large language models demonstrate an emerging ability for few-shot
    learning, where the model can draw upon their existing understanding to quickly
    adapt to new tasks with limited examples ^([8](https://arxiv.org/html/2403.15464v1#bib.bib8);
    [9](https://arxiv.org/html/2403.15464v1#bib.bib9)). This raises the question of
    whether LLMs can be directly applied to perform few-shot disease predictions using
    Electronic Health Record (EHR) data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）已经成为多个领域中强大的工具，包括医疗健康领域。这些模型，如GPT系列 ^([1](https://arxiv.org/html/2403.15464v1#bib.bib1))和PaLM ^([2](https://arxiv.org/html/2403.15464v1#bib.bib2))，经过大量文本数据的训练，使它们能够在多个领域内编码广泛的知识。在医学领域，LLMs利用其编码的医学知识的能力在近期的研究中得到了展示 ^([3](https://arxiv.org/html/2403.15464v1#bib.bib3);
    [4](https://arxiv.org/html/2403.15464v1#bib.bib4))，在诸如医学问答 ^([5](https://arxiv.org/html/2403.15464v1#bib.bib5))、临床文本摘要 ^([6](https://arxiv.org/html/2403.15464v1#bib.bib6))和临床决策支持 ^([7](https://arxiv.org/html/2403.15464v1#bib.bib7))等任务上表现出色。一些非常大的语言模型展示了少样本学习的初步能力，在这种学习模式下，模型可以借助其现有的理解，快速适应具有有限样本的新任务 ^([8](https://arxiv.org/html/2403.15464v1#bib.bib8);
    [9](https://arxiv.org/html/2403.15464v1#bib.bib9))。这引发了一个问题：LLMs是否可以直接应用于使用电子健康记录（EHR）数据进行少样本疾病预测。
- en: EHRs contain a wealth of patient data for predictive modeling tasks such as
    disease prediction, readmission risk assessment, and mortality prediction ^([10](https://arxiv.org/html/2403.15464v1#bib.bib10)).
    Existing approaches to EHR-based prediction primarily rely on supervised learning
    methods, including traditional machine learning models, representation learning ^([11](https://arxiv.org/html/2403.15464v1#bib.bib11);
    [12](https://arxiv.org/html/2403.15464v1#bib.bib12); [13](https://arxiv.org/html/2403.15464v1#bib.bib13)),
    and graph-based models ^([14](https://arxiv.org/html/2403.15464v1#bib.bib14)).
    While effective, these supervised approaches require training on large labeled
    datasets, which can be computationally expensive and challenging to obtain due
    to the high cost and difficulty of acquiring high-quality labeled EHR data ^([15](https://arxiv.org/html/2403.15464v1#bib.bib15)).
    In contrast, the capacity for few-shot learning enables LLMs to adapt to new tasks
    with minimal data, without any finetuning ^([8](https://arxiv.org/html/2403.15464v1#bib.bib8)).
    This adaptability raises the possibility of employing LLMs for few-shot disease
    prediction using EHR, a step forward in making healthcare more precise and efficient ^([16](https://arxiv.org/html/2403.15464v1#bib.bib16)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 电子健康记录（EHR）包含大量的患者数据，可用于预测建模任务，如疾病预测、再入院风险评估和死亡率预测 ^([10](https://arxiv.org/html/2403.15464v1#bib.bib10))。现有的基于EHR的预测方法主要依赖于监督学习方法，包括传统的机器学习模型、表示学习 ^([11](https://arxiv.org/html/2403.15464v1#bib.bib11);
    [12](https://arxiv.org/html/2403.15464v1#bib.bib12); [13](https://arxiv.org/html/2403.15464v1#bib.bib13))，以及基于图的模型 ^([14](https://arxiv.org/html/2403.15464v1#bib.bib14))。尽管这些监督方法有效，但它们需要在大规模标注数据集上进行训练，而这在计算上昂贵且难以获得，因为获取高质量标注的EHR数据成本高且困难 ^([15](https://arxiv.org/html/2403.15464v1#bib.bib15))。相比之下，少样本学习的能力使得大语言模型（LLMs）能够以最少的数据适应新任务，无需任何微调 ^([8](https://arxiv.org/html/2403.15464v1#bib.bib8))。这种适应性为使用LLMs进行少样本疾病预测提供了可能，这是使医疗服务更加精准和高效的一步 ^([16](https://arxiv.org/html/2403.15464v1#bib.bib16))。
- en: 'In this study, we investigate the efficacy of LLMs-based few-shot disease prediction
    using the EHRs generated from clinical encounters that include three types of
    medical codes: disease, medications, and procedures. We convert the structured
    patient visit records into unstructured language narratives by mapping the ICD
    codes to their names and connecting them with proper conjunctives. This conversion
    process allows LLMs to better understand clinical records and retrieve related
    internal knowledge. We assess the zero-shot and few-shot diagnostic performance
    of LLMs using various prompting strategies, such as considering factor interactions
    and providing prevalence statistics and exemplars. The results of this evaluation
    provide insights into the potential of LLMs as a tool for EHR-based disease prediction
    and highlight the influence of prompting strategies on their performance.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们探讨了基于LLMs的少量样本疾病预测的有效性，使用了由临床接触生成的电子健康记录（EHRs），这些记录包含三种类型的医疗编码：疾病、药物和治疗方法。我们通过将ICD编码映射到其名称，并用适当的连词将它们连接起来，将结构化的病人就诊记录转换为非结构化的语言叙述。这个转换过程使得LLMs能够更好地理解临床记录，并提取相关的内部知识。我们使用各种提示策略评估LLMs的零样本和少量样本诊断表现，例如考虑因素之间的交互作用，并提供流行病学统计数据和示例。此次评估的结果为LLMs作为基于EHR的疾病预测工具的潜力提供了见解，并突出了提示策略对其表现的影响。
- en: 'Building upon the findings of our initial evaluation, we propose an innovative
    approach to further improve the few-shot diagnostic performance of LLMs on EHR
    data. Studies have shown the promise of specialized LLM agents working collaboratively
    ^([17](https://arxiv.org/html/2403.15464v1#bib.bib17); [18](https://arxiv.org/html/2403.15464v1#bib.bib18);
    [19](https://arxiv.org/html/2403.15464v1#bib.bib19)), leveraging their diverse
    functionalities through few-shot learning. Our approach combines the strengths
    of predictive agent reasoning and critical agent instruction to create a more
    robust and accurate prediction system. The overall framework is shown in Figure [1](https://arxiv.org/html/2403.15464v1#Sx2.F1
    "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR:
    A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction").
    Specifically, we employ two LLM agents with different roles: a predictor agent
    and a critic agent. The predictor agent makes few-shot predictions given the unstructured
    narratives, which are converted from structured records, and generates a reasoning
    process to support its predictions. The critic agent then takes the predictor’s
    output alongside the ground-truth disease labels as input and identifies issues
    or biases in the predictor agent’s reasoning process. Based on the analysis, the
    critic agent generates a set of instructions that draw the predictor agent’s attention
    to potentially overlooked factors and offer specific recommendations for refining
    its reasoning process. These instructions are subsequently appended to the prompts
    used for the predictor agent, serving as additional context to inform its predictions.
    Our results show that by refining the prompts based on the critic agent’s feedback,
    the overall diagnostic accuracy of the LLM-based few-shot prediction system improves
    significantly. This approach leverages the complementary strengths of predictive
    reasoning and critical analysis, enabling the system to learn from its mistakes
    and adapt to the specific challenges of EHR-based disease prediction. In summary,
    our main contributions are:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们初步评估的发现，我们提出了一种创新的方法，进一步提高大语言模型在EHR数据上的少样本诊断性能。研究表明，专门化的大语言模型代理在协同工作中展现了潜力
    ^([17](https://arxiv.org/html/2403.15464v1#bib.bib17); [18](https://arxiv.org/html/2403.15464v1#bib.bib18);
    [19](https://arxiv.org/html/2403.15464v1#bib.bib19))，通过少样本学习发挥各自的多样化功能。我们的方法结合了预测代理推理和批评代理指导的优势，创建了一个更强大、更准确的预测系统。总体框架如图[1](https://arxiv.org/html/2403.15464v1#Sx2.F1
    "图 1 ‣ 引言 ‣ 基于LLMs的少样本疾病预测：结合预测代理推理与批评代理指导的创新方法")所示。具体而言，我们采用了两个具有不同角色的大语言模型代理：一个预测代理和一个批评代理。预测代理根据从结构化记录转化而来的非结构化叙述进行少样本预测，并生成支持其预测的推理过程。随后，批评代理将预测代理的输出与实际疾病标签一起作为输入，识别预测代理推理过程中的问题或偏差。基于分析，批评代理生成一组指令，提醒预测代理注意可能被忽视的因素，并提供具体的改进建议。这些指令随后附加到用于预测代理的提示中，作为额外的上下文来指导其预测。我们的结果表明，通过基于批评代理的反馈改进提示，基于大语言模型的少样本预测系统的整体诊断准确性显著提高。这种方法利用了预测推理和批评分析的互补优势，使系统能够从错误中学习，并适应基于EHR的疾病预测的具体挑战。总之，我们的主要贡献包括：
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We investigate the application of LLMs to EHR-based disease prediction tasks
    by converting structured data into natural language narratives and evaluating
    zero-shot and few-shot performance using various prompting strategies.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过将结构化数据转化为自然语言叙述，并采用不同的提示策略评估零样本和少样本性能，研究了大语言模型（LLMs）在基于电子健康记录（EHR）的疾病预测任务中的应用。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We propose a novel approach combining two LLM agents with different roles:
    a predictor agent that makes predictions and provides reasoning processes, and
    a critic agent that analyzes incorrect predictions and provides feedback for improvement.
    The critic agent’s feedback is used to update the predictor agent’s prompts, enabling
    the system to learn from its mistakes and adapt to EHR-based disease prediction
    challenges.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一种新颖的方法，将两个具有不同角色的大语言模型代理结合起来：一个预测代理，用于进行预测并提供推理过程，另一个是批评代理，用于分析不正确的预测并提供改进反馈。批评代理的反馈用于更新预测代理的提示，从而使系统能够从错误中学习并适应基于EHR的疾病预测挑战。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We summarize a set of insights into the performance of LLMs under various settings
    and share practical guidance on leveraging LLMs for diagnostic tasks with limited
    labeled data. We hope this can contribute to developing efficient and effective
    clinical decision support systems in the era of LLMs.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们总结了一组关于LLM在各种设置下表现的见解，并分享了在有限标注数据情况下利用LLM进行诊断任务的实践指导。我们希望这能为在LLM时代开发高效且有效的临床决策支持系统做出贡献。
- en: '![Refer to caption](img/a1a7ca27c29d7c530688a510df64f1a8.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/a1a7ca27c29d7c530688a510df64f1a8.png)'
- en: 'Figure 1: The framework of EHR-CoAgent employs two LLM agents: a predictor
    agent that makes predictions and generates reasoning processes and a critic agent
    that analyzes incorrect predictions and provides guidance for improvement. The
    critic agent’s feedback is used to update the prompts given to the predictor agent,
    enabling the system to learn from its mistakes and adapt to the specific challenges
    of the EHR-based disease prediction task.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：EHR-CoAgent框架采用了两个LLM代理：一个预测代理，负责进行预测并生成推理过程；一个批评代理，负责分析错误预测并提供改进的指导。批评代理的反馈被用来更新给预测代理的提示，从而使系统能够从错误中学习并适应基于EHR的疾病预测任务的具体挑战。
- en: Related Work
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作
- en: Large Language Models for Healthcare LLMs have demonstrated remarkable capabilities
    in various application scenarios. Recently, there has been a growing interest
    in applying LLMs to the medical domain ^([20](https://arxiv.org/html/2403.15464v1#bib.bib20);
    [21](https://arxiv.org/html/2403.15464v1#bib.bib21); [22](https://arxiv.org/html/2403.15464v1#bib.bib22)),
    particularly for tasks such as clinical note analysis ^([23](https://arxiv.org/html/2403.15464v1#bib.bib23);
    [24](https://arxiv.org/html/2403.15464v1#bib.bib24)), medical question answering ^([25](https://arxiv.org/html/2403.15464v1#bib.bib25);
    [26](https://arxiv.org/html/2403.15464v1#bib.bib26)), disease prediction ^([27](https://arxiv.org/html/2403.15464v1#bib.bib27)),
    clinical trial matching ^([28](https://arxiv.org/html/2403.15464v1#bib.bib28)),
    medical report generation ^([29](https://arxiv.org/html/2403.15464v1#bib.bib29)).
    For example, Yang et al. ^([30](https://arxiv.org/html/2403.15464v1#bib.bib30))
    introduced GatorTron, an LLM specifically designed for EHRs. They demonstrated
    the effectiveness of GatorTron in various clinical natural language processing
    (NLP) tasks, such as named entity recognition and relation extraction, showcasing
    the potential of LLMs to extract valuable information from unstructured EHR data.
    Peng et al. ^([22](https://arxiv.org/html/2403.15464v1#bib.bib22)) investigated
    the use of generative LLMs for medical research and healthcare. They explored
    the capabilities of LLMs in tasks such as medical question answering, disease
    prediction, and clinical trial matching, highlighting their potential to support
    clinical decision-making and assist research.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型在医疗领域的应用 LLMs在多种应用场景中展现了卓越的能力。近年来，越来越多的研究者开始关注将LLMs应用于医疗领域 ^([20](https://arxiv.org/html/2403.15464v1#bib.bib20);
    [21](https://arxiv.org/html/2403.15464v1#bib.bib21); [22](https://arxiv.org/html/2403.15464v1#bib.bib22))，尤其是在临床笔记分析 ^([23](https://arxiv.org/html/2403.15464v1#bib.bib23);
    [24](https://arxiv.org/html/2403.15464v1#bib.bib24))、医学问答 ^([25](https://arxiv.org/html/2403.15464v1#bib.bib25);
    [26](https://arxiv.org/html/2403.15464v1#bib.bib26))、疾病预测 ^([27](https://arxiv.org/html/2403.15464v1#bib.bib27))、临床试验匹配 ^([28](https://arxiv.org/html/2403.15464v1#bib.bib28))、医学报告生成 ^([29](https://arxiv.org/html/2403.15464v1#bib.bib29))等任务中。例如，Yang等人 ^([30](https://arxiv.org/html/2403.15464v1#bib.bib30))提出了GatorTron，这是一个专为EHR设计的LLM。他们展示了GatorTron在多种临床自然语言处理（NLP）任务中的有效性，如命名实体识别和关系抽取，展示了LLM从非结构化EHR数据中提取有价值信息的潜力。Peng等人 ^([22](https://arxiv.org/html/2403.15464v1#bib.bib22))研究了生成型LLM在医学研究和医疗保健中的应用。他们探索了LLM在医学问答、疾病预测和临床试验匹配等任务中的能力，突显了其在支持临床决策和协助研究中的潜力。
- en: However, applying LLMs to EHR-based disease prediction tasks remains under-explored.
    While some studies have investigated the use of LLMs for clinical NLP tasks on
    EHR ^([30](https://arxiv.org/html/2403.15464v1#bib.bib30)), there is still a lack
    of research on leveraging the reasoning and instruction-following capabilities
    of LLMs for few-shot EHR-based prediction. Our research addresses this gap by
    exploring the use of LLMs for EHR-based disease prediction and proposes new methods
    to enable accurate prediction with minimal training data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将LLM应用于基于EHR的疾病预测任务仍然是一个未充分探索的领域。尽管已有一些研究探讨了LLM在EHR上的临床自然语言处理（NLP）任务中的应用^([30](https://arxiv.org/html/2403.15464v1#bib.bib30))，但关于如何利用LLM的推理和遵循指令的能力进行少样本EHR预测的研究仍然不足。我们的研究通过探索LLM在EHR基础上的疾病预测应用，填补了这一空白，并提出了新方法以在最少训练数据下实现准确预测。
- en: Method
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法
- en: 'In this study, we expand our investigations on two levels: (1) evaluating the
    zero-shot and few-shot performance of LLMs on EHR-based disease prediction tasks,
    and (2) proposing a novel approach that leverages collaborative LLM agents to
    enhance the predictive performance.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们从两个层面扩展了我们的研究：（1）评估大型语言模型（LLM）在电子健康记录（EHR）基础上的疾病预测任务中的零样本和少样本表现，及（2）提出一种利用协作型LLM代理来增强预测性能的新方法。
- en: 'LLM Performance on Disease Prediction with EHR The structured patient visit
    data are typically stored in tabular formats, where each row represents an individual
    patient visit record generated from clinical encounters, and columns correspond
    to different medical codes. In this study, we utilize EHR data that includes three
    types of medical codes $\mathcal{C}$: (1) diseases $\mathcal{C}_{D}$, (2) medications
    $\mathcal{C}_{M}$, and (3) procedures $\mathcal{C}_{P}$. Each patient visit sample
    $v_{i}$ in the record $\mathcal{V}$ is represented by a set of medical codes $\{c_{1},c_{2},\ldots,c_{n}\}$,
    where $c_{j}\in\mathcal{C}$. We convert the structured EHR records into unstructured
    language narratives, denoted as $\mathcal{H}$, by mapping the medical codes to
    their names to enable the application of LLMs.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在基于EHR的疾病预测中的表现 结构化的患者就诊数据通常以表格形式存储，其中每一行代表一次单独的患者就诊记录，这些记录来源于临床接触，列则对应不同的医学编码。在本研究中，我们利用包括三种类型医学编码的EHR数据$\mathcal{C}$：（1）疾病$\mathcal{C}_{D}$，（2）药物$\mathcal{C}_{M}$，以及（3）治疗过程$\mathcal{C}_{P}$。记录中的每一个患者就诊样本$v_{i}$通过一组医学编码$\{c_{1},c_{2},\ldots,c_{n}\}$表示，其中$c_{j}\in\mathcal{C}$。我们通过将医学编码映射到其名称，将结构化的EHR记录转换为非结构化的语言叙述，记作$\mathcal{H}$，以便应用LLM。
- en: '$\diamond$ Zero-Shot: Leveraging Pre-existing Knowledge Prompt engineering
    has emerged as a powerful technique for guiding the behavior of LLMs and improving
    their performance on various healthcare-related tasks, such as clinical named
    entity recognition ^([31](https://arxiv.org/html/2403.15464v1#bib.bib31); [32](https://arxiv.org/html/2403.15464v1#bib.bib32))
    and clinical text classification ^([33](https://arxiv.org/html/2403.15464v1#bib.bib33);
    [34](https://arxiv.org/html/2403.15464v1#bib.bib34)). We develop a set of prompting
    strategies tailored to EHR-based prediction tasks to provide additional context
    and guide the reasoning process of LLMs, including:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 零样本：利用现有知识 提示工程已经成为一种强大的技术，用于引导LLM的行为，并提高其在各类与医疗相关的任务中的表现，例如临床命名实体识别^([31](https://arxiv.org/html/2403.15464v1#bib.bib31);
    [32](https://arxiv.org/html/2403.15464v1#bib.bib32))和临床文本分类^([33](https://arxiv.org/html/2403.15464v1#bib.bib33);
    [34](https://arxiv.org/html/2403.15464v1#bib.bib34))。我们开发了一套专门针对EHR基础预测任务的提示策略，以提供额外的背景信息并引导LLM的推理过程，包括：
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Chain-of-thought (CoT) reasoning ^([35](https://arxiv.org/html/2403.15464v1#bib.bib35)):
    prompt the LLMs to generate step-by-step explanations;'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 思维链（CoT）推理^([35](https://arxiv.org/html/2403.15464v1#bib.bib35))：提示LLM生成逐步解释；
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Incorporation of factor interactions: encourage LLMs to consider the interactions
    and dependencies among different medical factors (e.g., diseases, medications,
    and procedures);'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因素交互的结合：鼓励LLM考虑不同医学因素（如疾病、药物和治疗过程）之间的相互作用和依赖关系；
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Prevalence information: integrate information about the prevalence statistics
    to provide additional context.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 流行病信息：整合流行病统计信息，以提供额外的背景信息。
- en: '$\diamond$ Few-Shot: Enhancing Performance with Limited Examples We randomly
    select a small number of positive and negative samples (e.g., 3 positive and 3
    negative) from the training data to serve as exemplars for each prediction category.
    These exemplars are incorporated into the prompts to provide the LLMs with a limited
    set of task-specific examples to learn from. This leverages the LLMs’ vast pre-existing
    knowledge while allowing them to adapt quickly to the specific characteristics
    of the EHR prediction task. By this, we aim to guide LLMs’ attention toward the
    most relevant patterns associated with each prediction category.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 少样本：通过有限示例增强性能 我们从训练数据中随机选择少量正负样本（例如，3个正样本和3个负样本）作为每个预测类别的示例。这些示例被纳入提示中，为LLM提供有限的任务特定示例进行学习。这利用了LLM广泛的预先存在的知识，同时使其能够快速适应EHR预测任务的特定特征。通过这种方式，我们旨在引导LLM的注意力集中于与每个预测类别相关的最相关模式。
- en: 'EHR-CoAgent: Collaborative LLM Agents for Enhanced Prediction Recently, the
    potential of LLMs has extended beyond single-agent applications. By leveraging
    the power of multiple LLMs with different roles working together in a collaborative
    framework, new possibilities have been unlocked for tackling complex problems
    and enhancing the performance of language models ^([17](https://arxiv.org/html/2403.15464v1#bib.bib17)).
    In this study, we propose a novel approach called EHR-CoAgent (as demonstrated
    in Figure [1](https://arxiv.org/html/2403.15464v1#Sx2.F1 "Figure 1 ‣ Introduction
    ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
    Predictive Agent Reasoning and Critical Agent Instruction")), which harnesses
    the potential of collaborative LLM agents for enhanced prediction of EHR. Our
    framework consists of two components: a predictor agent $\mathcal{P}_{\text{LLM}}$
    and a critic agent $\mathcal{K}_{\text{LLM}}$. The predictor agent focuses on
    generating predictions and providing explanatory reasoning, while the critic agent
    observes the predictor’s outputs and provides instructional feedback to refine
    the prediction process. By integrating the feedback from the critic agent into
    the prompts used by the predictor agent, we aim to create an in-context learning
    process with feedback to continuously enhance disease prediction accuracy.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 'EHR-CoAgent: 协作LLM代理增强预测 最近，LLM的潜力已经超越了单一代理应用。通过利用多个具有不同角色的LLM在协作框架下共同工作，新的可能性被开启，用于解决复杂问题并增强语言模型的性能^([17](https://arxiv.org/html/2403.15464v1#bib.bib17))。在本研究中，我们提出了一种新的方法，称为EHR-CoAgent（如图[1](https://arxiv.org/html/2403.15464v1#Sx2.F1
    "Figure 1 ‣ Introduction ‣ LLMs-based Few-Shot Disease Predictions using EHR:
    A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction")所示），它利用协作LLM代理的潜力来增强EHR的预测。我们的框架由两个组件组成：一个预测代理$\mathcal{P}_{\text{LLM}}$和一个批评代理$\mathcal{K}_{\text{LLM}}$。预测代理专注于生成预测并提供解释性推理，而批评代理观察预测者的输出并提供指导性反馈，以完善预测过程。通过将批评代理的反馈整合到预测代理使用的提示中，我们旨在创建一个具有反馈的上下文学习过程，持续增强疾病预测的准确性。'
- en: '$\diamond$ Predictor Agent: Generating Predictions and Reasoning The predictor
    agent $\mathcal{P}_{\text{LLM}}$ is an LLM that performs few-shot disease predictions
    and provides explanatory reasoning based on the input EHR data. Given a patient’s
    medical history $\mathcal{H}_{i}$, the predictor LLM analyzes the relevant information
    and generates the most likely prediction $\widehat{\mathcal{D}_{i}}$ and provides
    a step-by-step explanation of its reasoning process $\mathcal{R}_{i}$. Such explanatory
    reasoning is crucial for enhancing the interpretability of the generated predictions.
    By highlighting the key factors and evidence influencing the LLM agent’s decision-making
    process, the reasoning serves as a transparent and informative basis for further
    analysis and validation. The detailed prompt we used for the predictor agent in
    EHR-CoAgent is shown in Figure [3](https://arxiv.org/html/2403.15464v1#Sx9.F3
    "Figure 3 ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction").'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 预测器代理：生成预测和推理 预测器代理 $\mathcal{P}_{\text{LLM}}$ 是一个大语言模型（LLM），它能够根据输入的电子健康记录（EHR）数据进行少量样本的疾病预测，并提供解释性推理。给定一个患者的病史
    $\mathcal{H}_{i}$，预测器 LLM 分析相关信息并生成最可能的预测 $\widehat{\mathcal{D}_{i}}$，同时提供其推理过程的逐步解释
    $\mathcal{R}_{i}$。这种解释性推理对于增强生成预测的可解释性至关重要。通过突出影响 LLM 代理决策过程的关键因素和证据，推理为进一步分析和验证提供了透明且信息丰富的基础。我们在
    EHR-CoAgent 中使用的详细提示如图 [3](https://arxiv.org/html/2403.15464v1#Sx9.F3 "图 3 ‣ 基于LLM的少样本疾病预测方法：结合预测代理推理和批判代理指导的创新方法")所示。
- en: '$\diamond$ Critic Agent: Providing Instructional Feedback The critic agent
    $\mathcal{K}_{\text{agent}}$ is another LLM that plays a different role in the
    EHR-CoAgent framework by observing a set of sampled wrong predictions from the
    predictor agent. Each set, denoted as $\mathcal{B}_{j}=\{(\widehat{\mathcal{D}}_{ji},\mathcal{R}_{ji})\}_{i=1}^{b}$,
    contains generated prediction $\widehat{\mathcal{D}}_{ji}$ and their accompanying
    explanatory reasoning $\mathcal{R}_{ji}$ for $b$ instances. The critic agent analyzes
    the inconsistency of the generated prediction to their corresponding ground truth
    label $\mathcal{D}_{ji}$ for each batch $\mathcal{B}_{j}$, identifying error patterns
    for improvement. Based on this analysis, we let the critic agent generate a set
    of instructional feedback $\{\mathcal{F}_{j}\}$ for batch $\mathcal{B}_{j}$ and
    repeat this process for $m$ times. The detailed prompt we used for the critic
    agent in EHR-CoAgent is shown in Figure [4](https://arxiv.org/html/2403.15464v1#Sx9.F4
    "Figure 4 ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction").'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 批判代理：提供指导性反馈 批判代理 $\mathcal{K}_{\text{agent}}$ 是另一个 LLM，在 EHR-CoAgent
    框架中发挥着不同的作用，它通过观察从预测器代理中采样到的一组错误预测来进行工作。每个集合，记作 $\mathcal{B}_{j}=\{(\widehat{\mathcal{D}}_{ji},\mathcal{R}_{ji})\}_{i=1}^{b}$，包含生成的预测
    $\widehat{\mathcal{D}}_{ji}$ 及其伴随的解释性推理 $\mathcal{R}_{ji}$，共涉及 $b$ 个实例。批判代理分析每个批次
    $\mathcal{B}_{j}$ 中生成的预测与其对应的真实标签 $\mathcal{D}_{ji}$ 之间的不一致性，识别错误模式以进行改进。基于此分析，我们让批判代理为批次
    $\mathcal{B}_{j}$ 生成一组指导性反馈 $\{\mathcal{F}_{j}\}$，并对这一过程重复 $m$ 次。我们在 EHR-CoAgent
    中使用的详细提示如图 [4](https://arxiv.org/html/2403.15464v1#Sx9.F4 "图 4 ‣ 基于LLM的少样本疾病预测方法：结合预测代理推理和批判代理指导的创新方法")所示。
- en: To provide concise and coherent guidance, we employ GPT-4 to process the set
    of instructional feedback $\{\mathcal{F}_{j}\}_{j=1}^{m}$. GPT-4 analyzes the
    feedback across multiple batches and generates a consolidated set of instructions
    $\mathcal{F}_{\text{consolidated}}$ that captures the most important and recurring
    insights. This consolidated feedback highlights common biases or errors in the
    reasoning process, offers suggestions for considering additional factors, and
    provides insights into the relationships between different medical concepts.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供简洁且连贯的指导，我们使用 GPT-4 来处理一组指导性反馈 $\{\mathcal{F}_{j}\}_{j=1}^{m}$。GPT-4 分析跨多个批次的反馈，并生成一组综合性指导
    $\mathcal{F}_{\text{consolidated}}$，以捕捉最重要且反复出现的见解。这一综合反馈突出显示推理过程中的常见偏差或错误，提出考虑额外因素的建议，并提供关于不同医学概念之间关系的见解。
- en: '$\diamond$ Instruction-Enhanced Prompting: Integrating Feedback for Refinement
    To effectively incorporate the feedback generated by the critic LLM, we introduce
    an instruction-enhanced prompting mechanism. This mechanism integrates the critic
    LLM’s instructional feedback $\mathcal{F}_{\text{consolidated}}$ directly into
    the prompts $\mathcal{P}$ used by the predictor LLM. By augmenting the prompts
    with specific instructions and guidance, we aim to steer the predictor LLM’s attention
    toward the most relevant aspects of the input data and encourage it to consider
    the insights provided by the critic LLM. This iterative process of making predictions,
    receiving feedback, and refining the prompts allows the predictor LLM to continuously
    improve its performance and adapt to the specific challenges of EHR-based disease
    prediction.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 指令增强型提示：集成反馈以进行优化 为了有效地整合评论LLM生成的反馈，我们引入了一种指令增强型提示机制。该机制将评论LLM的指令性反馈$\mathcal{F}_{\text{consolidated}}$直接集成到预测LLM使用的提示$\mathcal{P}$中。通过用具体的指令和指导信息来增强提示，我们旨在引导预测LLM将注意力集中在输入数据的最相关方面，并鼓励它考虑评论LLM提供的见解。这一预测、反馈和优化提示的迭代过程使得预测LLM能够不断提升性能，并适应基于EHR的疾病预测中的特定挑战。
- en: Experimental Settings
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验设置
- en: 'Datasets We conducted experiments on two datasets: the publicly accessible
    MIMIC-III dataset and the privately-owned CRADLE dataset. MIMIC-III ^([36](https://arxiv.org/html/2403.15464v1#bib.bib36))
    is a large, publicly accessible dataset comprising de-identified health-related
    data associated with over forty thousand patients who stayed in critical care
    units of the Beth Israel Deaconess Medical Center between 2001 and 2012\. Our
    task is to predict whether acute care conditions will be present during a patient’s
    next visit, given their current ICU stay records. We focus on a specific chronic
    phenotype, Disorders of Lipid Metabolism, which is identified using Clinical Classifications
    Software (CCS) from the Healthcare Cost and Utilization Project (HCUP)¹¹1[https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt).
    During preprocessing, we extract patients with more than one hospital visit and
    create pairs of adjacent visits for each patient. For each pair, the former visit
    serves as the input, and the phenotypes in the latter visit are used as labels.
    This process yields 12,353 records with labels. For budget consideration, we randomly
    sample 1,000 records based on the data distribution of the prediction target as
    our testing set.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 我们在两个数据集上进行了实验：公开访问的MIMIC-III数据集和私有的CRADLE数据集。MIMIC-III ^([36](https://arxiv.org/html/2403.15464v1#bib.bib36))
    是一个大型的、公开访问的数据集，包含了超过四万名患者在2001到2012年期间，在贝eth以色列迪肯尼斯医疗中心重症监护病房住院的去标识化健康相关数据。我们的任务是根据患者当前在ICU的住院记录，预测他们在下次就诊时是否会出现急性护理状况。我们专注于一个特定的慢性表型——脂质代谢障碍，它是通过临床分类软件（CCS）从医疗费用和使用项目（HCUP）¹¹1[https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt](https://www.hcup-us.ahrq.gov/toolssoftware/ccs/AppendixASingleDX.txt)中识别的。在预处理阶段，我们提取了有多个住院记录的患者，并为每个患者创建了相邻的住院记录对。对于每一对记录，前一次住院作为输入，而后一次住院中的表型则作为标签。这一过程产生了12,353条带标签的记录。出于预算考虑，我们根据预测目标的数据分布随机抽取了1,000条记录作为测试集。
- en: Project CRADLE (Emory Clinical Research Analytics Data Lake Environment) is
    a privately-owned database that contains de-identified electronic health records
    at Emory Healthcare from 2013 to 2017\. In this study, we focus on the patients
    with type 2 diabetes and predict whether those patients will experience cardiovascular
    disease (CVD) endpoints within a year after the initial diabetes diagnosis. The
    CVD endpoints include coronary heart disease (CHD), congestive heart failure (CHF),
    myocardial infarction (MI), or stroke, which are identified by their ICD-9 and
    ICD-10 clinical codes. For patients who developed CVD complications within a year
    (positive cases), we select the earliest recorded encounter within a year of the
    CVD endpoint presence as the input. For patients without CVD complications (negative
    cases), we randomly select one encounter as the input from all encounters that
    occurred at least one year before the last recorded encounter. Patients are excluded
    if they (1) have less than two encounters at Emory Healthcare, (2) the time interval
    between their first and last encounter is less than one year, or (3) have a history
    of CVD conditions. After applying these exclusion criteria, 35,404 patients remain
    in the dataset. Similar to MIMIC-III, we randomly sample 1,000 records based on
    the data distribution of the prediction target
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: CRADLE 项目（Emory 临床研究分析数据湖环境）是一个私有数据库，包含了从 2013 年到 2017 年在 Emory Healthcare 中去标识化的电子健康记录。在本研究中，我们聚焦于
    2 型糖尿病患者，预测这些患者在首次糖尿病诊断后的 1 年内是否会经历心血管疾病（CVD）终点。CVD 终点包括冠心病（CHD）、充血性心力衰竭（CHF）、心肌梗死（MI）或中风，这些通过
    ICD-9 和 ICD-10 临床代码进行识别。对于在一年内发展出 CVD 并发症的患者（阳性病例），我们选择在 CVD 终点出现的一年内记录的最早一次就诊作为输入。对于没有
    CVD 并发症的患者（阴性病例），我们从至少在最后一次就诊前一年发生的所有就诊中随机选择一次作为输入。如果患者满足以下条件，将被排除： (1) 在 Emory
    Healthcare 就诊次数少于两次，(2) 第一次和最后一次就诊的时间间隔少于一年，或 (3) 有 CVD 病史。应用这些排除标准后，数据集中剩余 35,404
    名患者。与 MIMIC-III 类似，我们根据预测目标的数据分布随机抽取了 1,000 条记录。
- en: Evaluation Metrics Both the MIMIC-III and CRADLE datasets exhibit class imbalance,
    with the prevalence of Disorders of Lipid Metabolism in MIMIC-III being 27.6%
    and the prevalence of cardiovascular disease (CVD) endpoints in CRADLE being 21.4%.
    To account for the imbalanced data distributions, we employ accuracy, sensitivity,
    specificity, and F1 score as evaluation metrics ^([14](https://arxiv.org/html/2403.15464v1#bib.bib14)).
    When evaluating LLM methods, we identify the presence of “Yes” or “No” tokens
    in the LLM responses and extract the top 5 probabilities associated with the predicting
    token. These probabilities are then normalized over both answers. We observed
    that GPT family models tend to provide highly confident answers (a confirmed prediction
    of either “Yes” or “No”, with almost 0.0 probability for the other choice), often
    resulting in a majority probability of either 0.0 or 1.0.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 评价指标 MIMIC-III 和 CRADLE 数据集都存在类别不平衡问题，其中 MIMIC-III 中脂质代谢障碍的患病率为 27.6%，CRADLE
    中心血管疾病（CVD）终点的患病率为 21.4%。为了考虑数据分布的不平衡，我们采用了准确率、敏感性、特异性和 F1 分数作为评估指标 ^([14](https://arxiv.org/html/2403.15464v1#bib.bib14))。在评估
    LLM 方法时，我们识别 LLM 响应中是否包含“是”或“否”标记，并提取与预测标记相关的前 5 个概率。这些概率随后会在两个答案上进行归一化。我们观察到，GPT
    系列模型倾向于提供高度自信的答案（即确认预测为“是”或“否”，而另一个选项的概率几乎为 0.0），通常会导致较大概率为 0.0 或 1.0。
- en: 'Baselines We compare the performance of EHR-CoAgent with traditional machine
    learning (ML), including Decision Trees, Logistic Regression, and Random Forests,
    which are widely used in EHR-based prediction tasks ^([37](https://arxiv.org/html/2403.15464v1#bib.bib37);
    [38](https://arxiv.org/html/2403.15464v1#bib.bib38)), and single-agent LLM approaches
    using GPT-4 (gpt-4-0125-preview) and GPT-3.5 (gpt-35-turbo-16k-0613). The ML models
    are trained in both fully supervised and few-shot settings, while the LLM approaches
    are evaluated in pure zero-shot, zero-shot with additional prompt information
    as mentioned in section [Method](https://arxiv.org/html/2403.15464v1#Sx4 "Method
    ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
    Predictive Agent Reasoning and Critical Agent Instruction"), and few-shot learning
    settings. By comparing EHR-CoAgent with these baselines, we aim to evaluate the
    effectiveness of diverse LLM agent frameworks in EHR-based disease prediction
    tasks.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '基线：我们将EHR-CoAgent与传统机器学习（ML）方法进行比较，包括决策树、逻辑回归和随机森林，这些方法在基于EHR的预测任务中广泛使用 ^([37](https://arxiv.org/html/2403.15464v1#bib.bib37);
    [38](https://arxiv.org/html/2403.15464v1#bib.bib38))，以及使用GPT-4（gpt-4-0125-preview）和GPT-3.5（gpt-35-turbo-16k-0613）的单一代理LLM方法。ML模型在完全监督和少-shot设置下进行训练，而LLM方法则在纯零-shot、带附加提示信息的零-shot（如[方法](https://arxiv.org/html/2403.15464v1#Sx4
    "Method ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction")章节中所述）和少-shot学习设置下进行评估。通过将EHR-CoAgent与这些基线进行比较，我们旨在评估不同LLM代理框架在基于EHR的疾病预测任务中的有效性。'
- en: Implementation Details We implemented the empirical study methods in Python.
    The baseline machine learning models were trained and evaluated using the popular
    sklearn package, which provides a comprehensive set of tools for machine learning
    tasks. To access the various GPT models securely, we utilized the Azure OpenAI
    Service, a trusted and compliant cloud platform. Azure OpenAI offers a secure
    API interface that allows seamless integration of the GPT capabilities into our
    research pipeline while maintaining strict privacy and security controls. By leveraging
    Azure OpenAI, we ensured that the sensitive patient dataset was processed in a
    protected environment, adhering to necessary regulations and standards, such as
    HIPAA and GDPR.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 实验细节：我们在Python中实现了实验研究方法。基线机器学习模型使用流行的sklearn包进行训练和评估，该包为机器学习任务提供了全面的工具集。为了安全地访问各种GPT模型，我们使用了Azure
    OpenAI服务，这是一个受信任且符合要求的云平台。Azure OpenAI提供了一个安全的API接口，可以将GPT能力无缝集成到我们的研究流程中，同时保持严格的隐私和安全控制。通过利用Azure
    OpenAI，我们确保敏感的患者数据集在受保护的环境中处理，遵循必要的法规和标准，如HIPAA和GDPR。
- en: Experimental Results
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验结果
- en: 'Table 1: Performance (%) of different models under the zero-shot, few-shot,
    and fully-supervised settings on MIMIC-III and CRADLE datasets. The proposed method
    is colored in green. The reference results under the supervised training setting
    (trained on 11,353 samples for MIMIC-III and 34,404 samples for CRADLE) are colored
    in gray.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：不同模型在MIMIC-III和CRADLE数据集上的零-shot、少-shot和完全监督设置下的性能（%）。提出的方法用绿色标出。监督训练设置下的参考结果（在MIMIC-III上训练了11,353个样本，CRADLE上训练了34,404个样本）用灰色标出。
- en: '| Type | Model | MIMIC-III (Pos : Neg = 27.6% : 72.4%) | CRADLE (Pos : Neg
    = 21.4% : 78.6%) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 模型 | MIMIC-III（正 : 负 = 27.6% : 72.4%） | CRADLE（正 : 负 = 21.4% : 78.6%）
    |'
- en: '| ACC | Sensitivity | Specificity | F1 | ACC | Sensitivity | Specificity |
    F1 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 敏感性 | 特异性 | F1 | 准确率 | 敏感性 | 特异性 | F1 |'
- en: '| Fully-Supervised | Decision Tree | 81.30 | 76.97 | 84.31 | 76.20 | 80.30
    | 53.87 | 88.27 | 52.15 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 完全监督 | 决策树 | 81.30 | 76.97 | 84.31 | 76.20 | 80.30 | 53.87 | 88.27 | 52.15
    |'
- en: '| Logistic Regression | 79.70 | 70.48 | 83.56 | 73.18 | 80.90 | 58.34 | 86.15
    | 59.74 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑回归 | 79.70 | 70.48 | 83.56 | 73.18 | 80.90 | 58.34 | 86.15 | 59.74 |'
- en: '| Random Forest | 78.60 | 66.12 | 83.16 | 70.58 | 80.20 | 56.49 | 86.14 | 57.34
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 78.60 | 66.12 | 83.16 | 70.58 | 80.20 | 56.49 | 86.14 | 57.34 |'
- en: '| Few-Shot (N=6) | Decision Tree | 71.10 | 53.14 | 77.62 | 51.16 | 31.90 |
    54.81 | 25.99 | 31.71 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 少-shot (N=6) | 决策树 | 71.10 | 53.14 | 77.62 | 51.16 | 31.90 | 54.81 | 25.99
    | 31.71 |'
- en: '| Logistic Regression | 58.70 | 73.40 | 53.44 | 56.78 | 53.30 | 53.95 | 53.13
    | 48.16 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑回归 | 58.70 | 73.40 | 53.44 | 56.78 | 53.30 | 53.95 | 53.13 | 48.16 |'
- en: '| Random Forest | 69.70 | 62.88 | 72.18 | 63.61 | 65.00 | 51.50 | 68.43 | 51.04
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 69.70 | 62.88 | 72.18 | 63.61 | 65.00 | 51.50 | 68.43 | 51.04 |'
- en: '| GPT-4 | Zero-Shot | 51.90 | 76.15 | 42.56 | 51.89 | 24.10 | 51.81 | 16.82
    | 22.33 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 零-shot | 51.90 | 76.15 | 42.56 | 51.89 | 24.10 | 51.81 | 16.82 |
    22.33 |'
- en: '| Zero-Shot+ | 62.90 | 59.30 | 64.29 | 58.58 | 30.00 | 53.25 | 23.76 | 29.67
    |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 零-shot+ | 62.90 | 59.30 | 64.29 | 58.58 | 30.00 | 53.25 | 23.76 | 29.67 |'
- en: '| Few-Shot (N=6) | 65.70 | 79.35 | 59.89 | 64.72 | 41.20 | 59.05 | 36.33 |
    40.88 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本学习（N=6） | 65.70 | 79.35 | 59.89 | 64.72 | 41.20 | 59.05 | 36.33 | 40.88
    |'
- en: '| EHR-CoAgent | 79.10 | 73.11 | 81.43 | 73.88 | 70.00 | 62.88 | 71.72 | 60.21
    |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| EHR-CoAgent | 79.10 | 73.11 | 81.43 | 73.88 | 70.00 | 62.88 | 71.72 | 60.21
    |'
- en: '| GPT-3.5 | Zero-Shot | 78.00 | 66.87 | 82.37 | 68.56 | 56.50 | 59.88 | 55.45
    | 52.29 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 零-shot | 78.00 | 66.87 | 82.37 | 68.56 | 56.50 | 59.88 | 55.45
    | 52.29 |'
- en: '| Zero-Shot+ | 72.40 | 50.00 | 80.37 | 42.00 | 62.60 | 57.62 | 63.96 | 54.40
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 零-shot+ | 72.40 | 50.00 | 80.37 | 42.00 | 62.60 | 57.62 | 63.96 | 54.40 |'
- en: '| Few-Shot (N=6) | 76.30 | 63.73 | 80.93 | 63.84 | 40.80 | 54.56 | 36.96 |
    40.32 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本学习（N=6） | 76.30 | 63.73 | 80.93 | 63.84 | 40.80 | 54.56 | 36.96 | 40.32
    |'
- en: '| EHR-CoAgent | 79.30 | 74.49 | 80.98 | 71.59 | 66.60 | 58.31 | 68.83 | 55.83
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| EHR-CoAgent | 79.30 | 74.49 | 80.98 | 71.59 | 66.60 | 58.31 | 68.83 | 55.83
    |'
- en: 'Table [1](https://arxiv.org/html/2403.15464v1#Sx6.T1 "Table 1 ‣ Experimental
    Results ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction") presents
    the experimental results on the two datasets. The findings highlight several key
    observations:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](https://arxiv.org/html/2403.15464v1#Sx6.T1 "Table 1 ‣ Experimental Results
    ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
    Predictive Agent Reasoning and Critical Agent Instruction") 展示了在两个数据集上的实验结果。研究结果突出了几个关键观察点：'
- en: $\diamond$ Traditional machine learning (ML) models achieve respectable performance
    when fully trained on large datasets (11,353 samples for MIMIC-III and 34,404
    samples for CRADLE). However, the performance of simpler models, such as Decision
    Trees and Logistic Regression, substantially deteriorates in the few-shot learning
    setting, emphasizing their limitations when labeled data is scarce.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 传统的机器学习（ML）模型在对大数据集进行充分训练时表现不错（MIMIC-III数据集为11,353个样本，CRADLE数据集为34,404个样本）。然而，当面对少量样本学习时，像决策树和逻辑回归这样的简单模型表现大幅下降，强调了在标签数据稀缺时这些模型的局限性。
- en: $\diamond$ When comparing the performance of zero-shot or few-shot LLMs with
    ML methods under few-shot settings, we observe that LLMs exhibit higher sensitivity
    but lower specificity. This finding suggests that LLMs excel at correctly identifying
    positive cases (i.e., patients with the condition of interest) but at the cost
    of a higher false positive rate. In other words, LLMs are more prone to classifying
    a patient as having the condition, even when they do not. This tendency implies
    that LLMs, particularly GPT-4, adopt a more conservative mindset, possibly due
    to their alignment to err on the side of caution to mitigate the risk of potentially
    missing true positive cases.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 在比较零-shot或少量样本学习LLMs与机器学习（ML）方法在少量样本设置下的表现时，我们观察到LLMs表现出更高的敏感性但较低的特异性。这一发现表明，LLMs擅长正确识别阳性病例（即患有目标疾病的患者），但代价是较高的假阳性率。换句话说，LLMs更倾向于将患者误判为患有该疾病，即使他们并没有。这一倾向意味着LLMs，尤其是GPT-4，采取了更为保守的思维方式，可能是因为它们在面对潜在的错过真实阳性病例时，倾向于采取更为谨慎的立场。
- en: $\diamond$ Zero-shot with additional prompting strategies (Zero-Shot+) can improve
    based on pure zero-shot, with occasionally produced errors. This observation underscores
    the importance of carefully crafting prompts to optimize the performance of LLMs
    in EHR-based disease prediction tasks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 通过额外的提示策略（Zero-Shot+）可以在纯粹的零-shot基础上提升性能，但偶尔会产生一些错误。这一观察结果突显了精心设计提示在优化LLM在基于电子健康记录（EHR）的疾病预测任务中表现的重要性。
- en: $\diamond$ Most of the time, adding few-shot demonstrations enhance prediction
    performance compared to their respective Zero-Shot+ counterparts. This finding
    emphasizes providing even a limited number of labeled examples can potentially
    steer language models toward more precise predictions. By leveraging a small set
    of representative samples, LLMs can quickly adapt to the specific characteristics
    of the EHR-based disease prediction task.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 大多数情况下，加入少量样本学习的演示效果优于对应的Zero-Shot+方法。这一发现强调了即使提供有限数量的标签示例，也可以潜在地引导语言模型做出更精确的预测。通过利用一小组具有代表性的样本，LLMs能够快速适应基于EHR的疾病预测任务的具体特征。
- en: $\diamond$ Our proposed approach EHR-CoAgent demonstrates remarkable performance,
    surpassing other methods and even fully supervised ML models in certain scenarios,
    with GPT-4 generally outperforming GPT-3.5\. On the CRADLE dataset, EHR-CoAgent
    achieves an F1 score of 60.21%, outperforming all fully trained ML models. Similarly,
    on the MIMIC-III dataset, EHR-CoAgent obtains an F1 score of 73.88%, comparable
    to the fully trained Decision Tree model and superior to Logistic Regression and
    Random Forest.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 我们提出的方法EHR-CoAgent展现出了卓越的性能，在某些场景下超越了其他方法，甚至超过了完全监督的机器学习模型，其中GPT-4的表现通常优于GPT-3.5。在CRADLE数据集上，EHR-CoAgent取得了60.21%的F1分数，超越了所有完全训练的机器学习模型。同样，在MIMIC-III数据集上，EHR-CoAgent获得了73.88%的F1分数，与完全训练的决策树模型相当，且优于逻辑回归和随机森林。
- en: $\diamond$ Compared with the few-shot setting with a single LLM predictor, EHR-CoAgent
    improves significantly on all four metrics. This can be attributed to the feedback
    instructions provided by the critic agent, which analyzes the outputs and identifies
    issues and biases in LLM’s reasoning process, such as overly relying on conservative
    thinking or neglecting certain key factors. The feedback instructions generated
    by the critic agent help to correct these issues, dynamically refining the predictor
    agent’s reasoning process, thus improving the accuracy of the prediction.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: $\diamond$ 与单一LLM预测器的少量样本设置相比，EHR-CoAgent在所有四个指标上都有显著提升。这可以归因于批评代理提供的反馈指令，批评代理分析输出结果并识别LLM推理过程中的问题和偏见，如过度依赖保守思维或忽视某些关键因素。批评代理生成的反馈指令有助于纠正这些问题，动态地优化预测代理的推理过程，从而提高预测的准确性。
- en: Generated Instructions
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成的指令
- en: '![Refer to caption](img/93b805c83dd81cd8f9ca9f11535a1093.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/93b805c83dd81cd8f9ca9f11535a1093.png)'
- en: 'Figure 2: Examples of instructional feedback generated by the GPT-4-based critic
    agent, which aims to refine the predictor agent’s reasoning process and improve
    the accuracy of its prediction.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：由基于GPT-4的批评代理生成的指导反馈示例，旨在细化预测代理的推理过程，并提高其预测的准确性。
- en: 'Figure [2](https://arxiv.org/html/2403.15464v1#Sx7.F2 "Figure 2 ‣ Generated
    Instructions ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach
    Combining Predictive Agent Reasoning and Critical Agent Instruction") showcases
    examples of the criteria and instructions generated by the critic agent. These
    examples demonstrate the critic agent’s ability to identify potential issues in
    the predictor agent’s prediction and reasoning process and provide targeted instructions
    to address them. For instance, the first instruction for the CRADLE dataset, “Avoid
    bias towards predicting a positive CVD endpoint based on conservative thinking
    when the patient is actively monitored and managed for known risk factors. Evaluate
    the effectiveness of the interventions in place” highlights a possible prediction
    bias of the predictor agent. This instruction encourages the predictor agent to
    avoid relying on conservative assumptions when making predictions, as such assumptions
    may be a result of the over-alignment of advanced AI models. By explicitly addressing
    this issue, the critic agent aims to guide the predictor agent toward more objective
    and comprehensive reasoning. Another example for the MIMIC dataset, “Pharmacological
    Interventions Consideration: Incorporate an evaluation of prescribed drugs, focusing
    on their relevance to managing the risk factors of the disorders of lipoid metabolism”
    suggests that the predictor agent should take into account the role of prescribed
    medications in managing the patient’s condition. By analyzing the relevance and
    potential impact of these drugs on the risk factors associated with disorders
    of lipoid metabolism, the predictor agent can make more informed predictions.
    These examples illustrate how the critic agent’s feedback can guide the predictor
    agent towards more comprehensive and nuanced reasoning, ultimately leading to
    improved disease prediction performance.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '图[2](https://arxiv.org/html/2403.15464v1#Sx7.F2 "Figure 2 ‣ Generated Instructions
    ‣ LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining
    Predictive Agent Reasoning and Critical Agent Instruction")展示了批评代理生成的标准和指令的示例。这些示例展示了批评代理识别预测代理预测和推理过程中的潜在问题的能力，并提供了有针对性的指令以解决这些问题。例如，对于CRADLE数据集的第一条指令，“避免基于保守思维对积极监测和管理已知风险因素的患者预测阳性心血管疾病（CVD）终点的偏向。评估现有干预措施的效果”突显了预测代理可能存在的预测偏差。这条指令鼓励预测代理在进行预测时避免依赖保守假设，因为这些假设可能是先进AI模型过度对齐的结果。通过明确解决这一问题，批评代理旨在引导预测代理朝着更加客观和全面的推理方向发展。另一个例子是针对MIMIC数据集的指令，“药物干预考虑：结合对处方药物的评估，重点关注其在管理脂质代谢紊乱的风险因素中的相关性”，提示预测代理应考虑处方药物在管理患者病情中的作用。通过分析这些药物与脂质代谢紊乱相关风险因素的相关性和潜在影响，预测代理可以做出更为明智的预测。这些示例说明了批评代理的反馈如何引导预测代理朝着更全面和细致的推理，最终提高疾病预测性能。'
- en: Conclusions
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this study, we investigated the application of Large Language Models (LLMs)
    to Electronic Health Record (EHR) based disease prediction tasks. We evaluated
    the zero-shot and few-shot diagnostic performance of LLMs using various prompting
    strategies and proposed a novel collaborative approach combining a predictor agent
    and a critic agent. This approach enables the system to learn from its mistakes
    and adapt to the challenges of EHR-based disease prediction. Our work highlights
    the potential of LLMs as a tool for clinical decision support and contributes
    to the development of efficient disease prediction systems that can operate with
    minimal training data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们探讨了大语言模型（LLMs）在基于电子健康记录（EHR）的疾病预测任务中的应用。我们评估了使用不同提示策略下LLMs的零-shot和少-shot诊断性能，并提出了一种结合预测代理和批评代理的新型协作方法。该方法使系统能够从错误中学习，并适应基于EHR的疾病预测的挑战。我们的工作突显了LLMs作为临床决策支持工具的潜力，并为开发能够在最少训练数据下运行的高效疾病预测系统作出了贡献。
- en: Ethical Considerations
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理考虑
- en: To ensure the ethical use of credential data with GPT-based services, we have
    signed and strictly adhered to the PhysioNet Credentialed Data Use Agreement²²2https://physionet.org/about/licenses/physionet-credentialed-health-data-license-150.
    We follow the guidelines³³3https://physionet.org/news/post/gpt-responsible-use
    for responsible use of MIMIC data in online services, including opting out of
    human review of the data through the Azure OpenAI Additional Use Case Form⁴⁴4https://aka.ms/oai/additionalusecase,
    to prevent sensitive information from being shared with third parties.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保GPT基础服务中凭证数据的伦理使用，我们已签署并严格遵守PhysioNet凭证数据使用协议²²2https://physionet.org/about/licenses/physionet-credentialed-health-data-license-150。我们遵循负责使用MIMIC数据的指南³³3https://physionet.org/news/post/gpt-responsible-use，包括通过Azure
    OpenAI附加使用案例表单选择不进行人工审查数据⁴⁴4https://aka.ms/oai/additionalusecase，以防止敏感信息泄露给第三方。
- en: References
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 1 Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, et al. Gpt-4 technical
    report. arXiv preprint arXiv:230308774\. 2023.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 Achiam J, Adler S, Agarwal S, Ahmad L, Akkaya I, Aleman FL, 等人。GPT-4技术报告。arXiv预印本
    arXiv:230308774. 2023。
- en: 2 Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, et al. Palm 2 technical
    report. arXiv preprint arXiv:230510403\. 2023.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, 等人。Palm 2技术报告。arXiv预印本
    arXiv:230510403. 2023。
- en: 3 Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large language
    models encode clinical knowledge. Nature. 2023;620:172-80.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, 等人。大语言模型编码临床知识。《自然》.
    2023;620:172-80。
- en: '4 Hernandez E, Mahajan D, Wulff J, Smith MJ, Ziegler Z, Nadler D, et al. Do
    We Still Need Clinical Language Models? In: Conference on Health, Inference, and
    Learning; 2023\. .'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 Hernandez E, Mahajan D, Wulff J, Smith MJ, Ziegler Z, Nadler D, 等人。我们还需要临床语言模型吗？在：健康、推理与学习会议；2023。
- en: 5 Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, et al. Towards expert-level
    medical question answering with large language models. arXiv preprint arXiv:230509617\.
    2023.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5 Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, 等人。利用大语言模型迈向专家级医学问答。arXiv预印本
    arXiv:230509617. 2023。
- en: 6 Van Veen D, Van Uden C, Blankemeier L, Delbrouck JB, Aali A, Bluethgen C,
    et al. Adapted large language models can outperform medical experts in clinical
    text summarization. Nature Medicine. 2024:1-9.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 6 Van Veen D, Van Uden C, Blankemeier L, Delbrouck JB, Aali A, Bluethgen C,
    等人。调整后的大语言模型可以在临床文本摘要中超越医学专家。《自然医学》。2024:1-9。
- en: '7 Hegselmann S, Buendia A, Lang H, Agrawal M, Jiang X, Sontag D. Tabllm: Few-shot
    classification of tabular data with large language models. In: AISTATS; 2023\.
    .'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7 Hegselmann S, Buendia A, Lang H, Agrawal M, Jiang X, Sontag D. Tabllm：使用大语言模型进行少样本表格数据分类。在：AISTATS;
    2023。
- en: 8 Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language
    models are few-shot learners. NeurIPS. 2020.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 8 Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, 等人。语言模型是少样本学习者。NeurIPS.
    2020。
- en: 9 Schick T, Schütze H. Exploiting cloze questions for few shot text classification
    and natural language inference. arXiv preprint arXiv:200107676\. 2020.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 9 Schick T, Schütze H. 利用填空题进行少量样本文本分类和自然语言推理。arXiv预印本 arXiv:200107676. 2020。
- en: '10 Shickel B, Tighe PJ, Bihorac A, Rashidi P. Deep EHR: a survey of recent
    advances in deep learning techniques for electronic health record (EHR) analysis.
    IEEE journal of biomedical and health informatics. 2017;22:1589-604.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10 Shickel B, Tighe PJ, Bihorac A, Rashidi P. 深度EHR：电子健康记录（EHR）分析中深度学习技术的最新进展综述。IEEE生物医学与健康信息学期刊。2017;22:1589-604。
- en: 11 Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, et al. Scalable and
    accurate deep learning with electronic health records. NPJ digital medicine. 2018;1:1-10.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 11 Rajkomar A, Oren E, Chen K, Dai AM, Hajaj N, Hardt M, 等人。可扩展且准确的电子健康记录深度学习。《NPJ数字医学》。2018;1:1-10。
- en: 12 Landi I, Glicksberg BS, Lee HC, Cherng S, Landi G, Danieletto M, et al. Deep
    representation learning of electronic health records to unlock patient stratification
    at scale. NPJ digital medicine. 2020;3:96.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 12 Landi I, Glicksberg BS, Lee HC, Cherng S, Landi G, Danieletto M, 等人。电子健康记录的深度表示学习以解锁大规模患者分层。《NPJ数字医学》。2020;3:96。
- en: 13 Fridgeirsson EA, Sontag D, Rijnbeek P. Attention-based neural networks for
    clinical prediction modelling on electronic health records. BMC Medical Research
    Methodology:285.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 13 Fridgeirsson EA, Sontag D, Rijnbeek P. 基于注意力的神经网络在电子健康记录中的临床预测建模。BMC医学研究方法学:285。
- en: '14 Choi E, Xu Z, Li Y, Dusenberry M, Flores G, Xue E, et al. Learning the graphical
    structure of electronic health records with graph convolutional transformer. In:
    AAAI; 2020\. .'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 14 Choi E, Xu Z, Li Y, Dusenberry M, Flores G, Xue E, 等人。利用图卷积变换器学习电子健康记录的图结构。在：AAAI;
    2020。
- en: '15 Xiao C, Choi E, Sun J. Opportunities and challenges in developing deep learning
    models using electronic health records data: a systematic review. Journal of the
    American Medical Informatics Association. 2018;25:1419-28.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 15 Xiao C, Choi E, Sun J. 使用电子健康记录数据开发深度学习模型的机会与挑战：一项系统评审。美国医学信息学会杂志。2018;25:1419-28.
- en: '16 Wornow M, Thapa R, Steinberg E, Fries J, Shah N. Ehrshot: An ehr benchmark
    for few-shot evaluation of foundation models. NeurIPS. 2023.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 16 Wornow M, Thapa R, Steinberg E, Fries J, Shah N. Ehrshot：一个用于基础模型少量样本评估的电子健康记录基准。NeurIPS.
    2023.
- en: '17 Wu Q, Bansal G, Zhang J, Wu Y, Zhang S, Zhu E, et al. Autogen: Enabling
    next-gen llm applications via multi-agent conversation framework. arXiv preprint
    arXiv:230808155\. 2023.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 17 Wu Q, Bansal G, Zhang J, Wu Y, Zhang S, Zhu E, 等. Autogen：通过多代理对话框架推动下一代大型语言模型应用。arXiv预印本
    arXiv:230808155。2023.
- en: '18 Talebirad Y, Nadiri A. Multi-agent collaboration: Harnessing the power of
    intelligent llm agents. arXiv preprint arXiv:230603314\. 2023.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 18 Talebirad Y, Nadiri A. 多代理协作：利用智能大型语言模型代理的力量。arXiv预印本 arXiv:230603314。2023.
- en: '19 Jin Q, Yang Y, Chen Q, Lu Z. Genegpt: Augmenting large language models with
    domain tools for improved access to biomedical information. Bioinformatics. 2024;40:btae075.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 19 Jin Q, Yang Y, Chen Q, Lu Z. Genegpt：通过领域工具增强大型语言模型，改善生物医学信息获取。生物信息学。2024;40:btae075.
- en: 20 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW.
    Large language models in medicine. Nature medicine. 2023;29(8):1930-40.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW.
    医学中的大型语言模型。自然医学。2023;29(8):1930-40.
- en: '21 He K, Mao R, Lin Q, Ruan Y, Lan X, Feng M, et al.. A Survey of Large Language
    Models for Healthcare: from Data, Technology, and Applications to Accountability
    and Ethics; 2023.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 21 He K, Mao R, Lin Q, Ruan Y, Lan X, Feng M, 等. 医疗保健领域大型语言模型调查：从数据、技术和应用到问责制与伦理；2023.
- en: 22 Peng C, Yang X, Chen A, Smith KE, PourNejatian N, Costa AB, et al. A study
    of generative large language model for medical research and healthcare. npj Digital
    Medicine. 2023;6:210.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 22 Peng C, Yang X, Chen A, Smith KE, PourNejatian N, Costa AB, 等. 生成性大型语言模型在医学研究和医疗保健中的应用研究。npj数字医学。2023;6:210.
- en: '23 Agrawal M, Hegselmann S, Lang H, Kim Y, Sontag D. Large language models
    are few-shot clinical information extractors. In: EMNLP; 2022\. .'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 23 Agrawal M, Hegselmann S, Lang H, Kim Y, Sontag D. 大型语言模型是少量样本临床信息提取器。载于：EMNLP;
    2022。
- en: '24 Mannhardt N, Bondi-Kelly E, Lam B, O’Connell C, Asiedu M, Mozannar H, et al..
    Impact of Large Language Model Assistance on Patients Reading Clinical Notes:
    A Mixed-Methods Study; 2024.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 24 Mannhardt N, Bondi-Kelly E, Lam B, O'Connell C, Asiedu M, Mozannar H, 等.
    大型语言模型辅助对患者阅读临床记录的影响：一项混合方法研究；2024.
- en: 25 Liévin V, Hother CE, Motzfeldt AG, Winther O. Can large language models reason
    about medical questions? Patterns. 2024;5:100943.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 25 Liévin V, Hother CE, Motzfeldt AG, Winther O. 大型语言模型能推理医学问题吗？Patterns。2024;5:100943.
- en: 26 Han T, Adams LC, Papaioannou JM, Grundmann P, Oberhauser T, Löser A, et al.
    MedAlpaca–an open-source collection of medical conversational AI models and training
    data. arXiv preprint arXiv:230408247\. 2023.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 26 Han T, Adams LC, Papaioannou JM, Grundmann P, Oberhauser T, Löser A, 等. MedAlpaca——一个开源的医学对话式AI模型和训练数据集。arXiv预印本
    arXiv:230408247。2023.
- en: '27 Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT: large language models finetuned
    with diverse medical data and comprehensive evaluation. arXiv preprint arXiv:230609968\.
    2023.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 27 Wang G, Yang G, Du Z, Fan L, Li X. ClinicalGPT：通过多样化医学数据微调的大型语言模型和全面评估。arXiv预印本
    arXiv:230609968。2023.
- en: '28 Yuan J, Tang R, Jiang X, Hu X. Large language models for healthcare data
    augmentation: An example on patient-trial matching. In: AMIA Annual Symposium
    Proceedings. vol. 2023; 2023\. p. 1324.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 28 Yuan J, Tang R, Jiang X, Hu X. 大型语言模型在医疗数据增强中的应用：以患者-试验匹配为例。载于：AMIA年度研讨会论文集。第2023卷；2023。p.
    1324.
- en: '29 D’Antonoli TA, Stanzione A, Bluethgen C, Vernuccio F, Ugga L, Klontzas ME,
    et al. Large language models in radiology: fundamentals, applications, ethical
    considerations, risks, and future directions. Diagnostic and Interventional Radiology.
    2024;30:80.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 29 D'Antonoli TA, Stanzione A, Bluethgen C, Vernuccio F, Ugga L, Klontzas ME,
    等. 放射学中的大型语言模型：基础、应用、伦理考量、风险与未来方向。诊断与介入放射学。2024;30:80.
- en: 30 Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C, et al. A large
    language model for electronic health records. npj Digital Medicine:194.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30 Yang X, Chen A, PourNejatian N, Shin HC, Smith KE, Parisien C, 等. 用于电子健康记录的大型语言模型。npj数字医学：194.
- en: 31 Sivarajkumar S, Kelley M, Samolyk-Mazzanti A, Visweswaran S, Wang Y. An empirical
    evaluation of prompting strategies for large language models in zero-shot clinical
    natural language processing. arXiv preprint arXiv:230908008\. 2023.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 31 Sivarajkumar S, Kelley M, Samolyk-Mazzanti A, Visweswaran S, Wang Y。大规模语言模型在零样本临床自然语言处理中的提示策略实证评估。arXiv预印本
    arXiv:230908008\. 2023。
- en: 32 Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, et al. Improving large language
    models for clinical named entity recognition via prompt engineering. Journal of
    the American Medical Informatics Association. 2024:ocad259.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 32 Hu Y, Chen Q, Du J, Peng X, Keloth VK, Zuo X, 等人。通过提示工程改进大规模语言模型在临床命名实体识别中的表现。美国医学信息学会期刊。2024:ocad259。
- en: '33 Lu Y, Zhao X, Wang J. Medical knowledge-enhanced prompt learning for diagnosis
    classification from clinical text. In: Clinical Natural Language Processing Workshop;
    2023\. p. 278-88.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 33 Lu Y, Zhao X, Wang J。医学知识增强的提示学习用于临床文本中的诊断分类。在：临床自然语言处理研讨会；2023\. 第278-288页。
- en: '34 Sivarajkumar S, Wang Y. Healthprompt: A zero-shot learning paradigm for
    clinical natural language processing. In: AMIA Annual Symposium Proceedings. vol.
    2022; 2022\. p. 972.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 34 Sivarajkumar S, Wang Y。Healthprompt：一种用于临床自然语言处理的零样本学习范式。在：AMIA年会论文集。卷 2022;
    2022\. 第972页。
- en: 35 Wei J, Wang X, Schuurmans D, Bosma M, Xia F, Chi E, et al. Chain-of-thought
    prompting elicits reasoning in large language models. NeurIPS. 2022;35.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 35 Wei J, Wang X, Schuurmans D, Bosma M, Xia F, Chi E, 等人。链式思维提示引发大规模语言模型的推理。NeurIPS。2022;35。
- en: 36 Johnson AE, Pollard TJ, Shen L, Lehman LwH, Feng M, Ghassemi M, et al. MIMIC-III,
    a freely accessible critical care database. Scientific data. 2016;3:1-9.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 36 Johnson AE, Pollard TJ, Shen L, Lehman LwH, Feng M, Ghassemi M, 等人。MIMIC-III，一个免费访问的重症监护数据库。科学数据。2016;3:1-9。
- en: '37 Wu J, Roy J, Stewart WF. Prediction modeling using EHR data: challenges,
    strategies, and a comparison of machine learning approaches. Medical care. 2010;48:S106-13.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 37 Wu J, Roy J, Stewart WF。使用 EHR 数据进行预测建模：挑战、策略以及机器学习方法的比较。医疗护理。2010;48:S106-13。
- en: '38 Goldstein BA, Navar AM, Pencina MJ, Ioannidis JP. Opportunities and challenges
    in developing risk prediction models with electronic health records data: a systematic
    review. Journal of the American Medical Informatics Association: JAMIA. 2017;24:198.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 38 Goldstein BA, Navar AM, Pencina MJ, Ioannidis JP。利用电子健康记录数据开发风险预测模型的机会与挑战：一项系统性回顾。美国医学信息学会期刊：JAMIA。2017;24:198。
- en: '![Refer to caption](img/a32dba535e9a36da98ba185ef4d6a786.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/a32dba535e9a36da98ba185ef4d6a786.png)'
- en: 'Figure 3: Prompt for Predictor Agent in EHR-CoAgent for the CRADLE dataset.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：CRADLE 数据集在 EHR-CoAgent 中预测代理的提示。
- en: '![Refer to caption](img/0770c891189d6ca6fd8849b6785e45df.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/0770c891189d6ca6fd8849b6785e45df.png)'
- en: 'Figure 4: Prompt for Critic Agent in EHR-CoAgent for the CRADLE dataset.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：CRADLE 数据集在 EHR-CoAgent 中批评代理的提示。
