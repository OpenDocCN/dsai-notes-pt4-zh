- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2025-01-11 12:35:52'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2025-01-11 12:35:52'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Can Graph Learning Improve Planning in LLM-based Agents?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图学习能否提高基于LLM的代理人规划能力？
- en: 来源：[https://arxiv.org/html/2405.19119/](https://arxiv.org/html/2405.19119/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2405.19119/](https://arxiv.org/html/2405.19119/)
- en: Xixi Wu^(1,3)     Yifei Shen^(2∗)✉    Caihua Shan²     Kaitao Song²     Siwei
    Wang²     Bohang Zhang⁴
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 吴溪溪^(1,3)     沈易非^(2∗)✉    单彩华²     宋凯涛²     王思维²     张博航⁴
- en: Jiarui Feng⁵    Hong Cheng³     Wei Chen²     Yun Xiong¹✉    Dongsheng Li²
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 冯佳瑞⁵    程辉³     陈伟²     熊云¹✉    李东生²
- en: ¹Fudan University    ²Microsoft Research Asia   ³The Chinese University of Hong
    Kong
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹复旦大学    ²微软亚洲研究院   ³香港中文大学
- en: ⁴Peking University     ⁵Washington University, Saint Louis  denotes equal contributions.
    Work was done during Xixi Wu’s (xxwu@se.cuhk.edu.hk) internship at Microsoft Research
    Asia. Corresponding authors (yifeishen@microsoft.com, yunx@fudan.edu.cn) Shanghai
    Key Laboratory of Data Science, School of Computer Science, Fudan University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴北京大学     ⁵华盛顿大学圣路易斯分校 表示平等贡献。工作是在吴溪溪（xxwu@se.cuhk.edu.hk）于微软亚洲研究院实习期间完成的。通讯作者（yifeishen@microsoft.com,
    yunx@fudan.edu.cn） 上海数据科学重点实验室，复旦大学计算机科学与技术系
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Task planning in language agents is emerging as an important research topic
    alongside the development of large language models (LLMs). It aims to break down
    complex user requests in natural language into solvable sub-tasks, thereby fulfilling
    the original requests. In this context, the sub-tasks can be naturally viewed
    as a graph, where the nodes represent the sub-tasks, and the edges denote the
    dependencies among them. Consequently, task planning is a decision-making problem
    that involves selecting a connected path or subgraph within the corresponding
    graph and invoking it. In this paper, we explore graph learning-based methods
    for task planning, a direction that is orthogonal to the prevalent focus on prompt
    design. Our interest in graph learning stems from a theoretical discovery: the
    biases of attention and auto-regressive loss impede LLMs’ ability to effectively
    navigate decision-making on graphs, which is adeptly addressed by graph neural
    networks (GNNs). This theoretical insight led us to integrate GNNs with LLMs to
    enhance overall performance. Extensive experiments demonstrate that GNN-based
    methods surpass existing solutions even without training, and minimal training
    can further enhance their performance. The performance gain increases with a larger
    task graph size. ¹¹1 The code and datasets are available at [https://github.com/WxxShirley/GNN4TaskPlan](https://github.com/WxxShirley/GNN4TaskPlan)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模语言模型（LLM）的发展，语言代理人的任务规划正成为一个重要的研究课题。其目的是将复杂的自然语言用户请求分解为可解决的子任务，从而实现原始请求。在这种背景下，子任务可以自然地被视为一个图，其中节点代表子任务，边表示它们之间的依赖关系。因此，任务规划是一个决策问题，涉及在相应图中选择一个连接路径或子图并调用它。在本文中，我们探索基于图学习的任务规划方法，这是与目前流行的提示设计研究方向正交的一个方向。我们对图学习的兴趣源于一个理论发现：注意力偏置和自回归损失阻碍了LLM有效地进行图上的决策导航，而图神经网络（GNN）巧妙地解决了这一问题。这个理论洞察促使我们将GNN与LLM结合，以提高整体性能。大量实验表明，基于GNN的方法即使在没有训练的情况下也优于现有的解决方案，而最小的训练也能进一步提升其性能。随着任务图大小的增加，性能提升更加显著。
    ¹¹1 代码和数据集可以在[https://github.com/WxxShirley/GNN4TaskPlan](https://github.com/WxxShirley/GNN4TaskPlan)获取
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: LLM-based agents have recently emerged as a rapidly growing field of research
    and are considered a significant step towards artificial general intelligence
    (AGI) [[61](https://arxiv.org/html/2405.19119v3#bib.bib61), [7](https://arxiv.org/html/2405.19119v3#bib.bib7)].
    These agents have achieved remarkable successes across a variety of domains, as
    evidenced by their ability to address complex AI challenges (e.g., HuggingGPT
    [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]), excel in gaming environments
    (e.g., Voyager [[58](https://arxiv.org/html/2405.19119v3#bib.bib58)]), and drive
    innovation in chemical research (e.g., [[5](https://arxiv.org/html/2405.19119v3#bib.bib5)]).
    Within this burgeoning field, task planning in language agents emerges as a critical
    area of study. It involves LLMs autonomously interpreting user instructions, breaking
    user’s instructions in natural language into concrete and solvable sub-tasks,
    and then fulfilling the user’s request by executing each sub-task [[43](https://arxiv.org/html/2405.19119v3#bib.bib43),
    [46](https://arxiv.org/html/2405.19119v3#bib.bib46), [45](https://arxiv.org/html/2405.19119v3#bib.bib45)].
    For instance, in the case of HuggingGPT [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)],
    task planning involves invoking expert AI models from the HuggingFace website
    to solve complex AI tasks beyond the capabilities of GPT alone.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的代理最近作为一个快速发展的研究领域崭露头角，被认为是迈向人工通用智能（AGI）的重要一步[[61](https://arxiv.org/html/2405.19119v3#bib.bib61),
    [7](https://arxiv.org/html/2405.19119v3#bib.bib7)]。这些代理在多个领域取得了显著成功，体现了它们在应对复杂AI挑战方面的能力（例如，HuggingGPT
    [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]），在游戏环境中表现出色（例如，Voyager [[58](https://arxiv.org/html/2405.19119v3#bib.bib58)]），并推动了化学研究的创新（例如，[[5](https://arxiv.org/html/2405.19119v3#bib.bib5)]）。在这一蓬勃发展的领域中，语言代理的任务规划成为了一个关键研究方向。它涉及LLM自主解释用户指令，将用户的自然语言指令分解为具体且可解决的子任务，然后通过执行每个子任务来完成用户的请求[[43](https://arxiv.org/html/2405.19119v3#bib.bib43),
    [46](https://arxiv.org/html/2405.19119v3#bib.bib46), [45](https://arxiv.org/html/2405.19119v3#bib.bib45)]。例如，在HuggingGPT的案例中[[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]，任务规划涉及从HuggingFace网站调用专家AI模型，以解决超出单一GPT能力范围的复杂AI任务。
- en: Given its practical significance, numerous algorithms have been proposed, with
    a major focus on prompt design [[45](https://arxiv.org/html/2405.19119v3#bib.bib45),
    [46](https://arxiv.org/html/2405.19119v3#bib.bib46), [33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [30](https://arxiv.org/html/2405.19119v3#bib.bib30), [60](https://arxiv.org/html/2405.19119v3#bib.bib60),
    [49](https://arxiv.org/html/2405.19119v3#bib.bib49), [71](https://arxiv.org/html/2405.19119v3#bib.bib71),
    [4](https://arxiv.org/html/2405.19119v3#bib.bib4), [63](https://arxiv.org/html/2405.19119v3#bib.bib63)].
    This paper proposes to explore an orthogonal direction, i.e., graph-learning-based
    approaches. In task planning, solvable sub-tasks can be naturally represented
    as a *task graph*, wherein each node corresponds to a distinct sub-task, and each
    edge signifies the dependencies between these sub-tasks. The crux of task planning,
    therefore, involves selecting a connected path or subgraph to satisfy the user’s
    request, which is a decision-making problem on graphs. Adopting this framework,
    we analyze the task planning capabilities of LLMs, specifically within the context
    of HuggingGPT [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]. Our empirical
    investigation uncovers that a considerable portion of planning failures can be
    ascribed to the LLMs’ inefficacy in accurately discerning the structure of the
    task graph. This finding presents intriguing questions from both theoretical and
    empirical perspectives. Theoretically, it initiates a discussion on the inherent
    limitations of LLMs in processing task graphs. Empirically, it highlights the
    urgent need for developing effective and efficient strategies to mitigate this
    deficiency and improve task planning performance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于其实际意义，已经提出了众多算法，主要集中在提示设计上[[45](https://arxiv.org/html/2405.19119v3#bib.bib45),
    [46](https://arxiv.org/html/2405.19119v3#bib.bib46), [33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [30](https://arxiv.org/html/2405.19119v3#bib.bib30), [60](https://arxiv.org/html/2405.19119v3#bib.bib60),
    [49](https://arxiv.org/html/2405.19119v3#bib.bib49), [71](https://arxiv.org/html/2405.19119v3#bib.bib71),
    [4](https://arxiv.org/html/2405.19119v3#bib.bib4), [63](https://arxiv.org/html/2405.19119v3#bib.bib63)]。本文提议探索一个正交方向，即基于图学习的方法。在任务规划中，可解决的子任务可以自然地表示为一个*任务图*，其中每个节点对应一个独特的子任务，每条边则表示这些子任务之间的依赖关系。因此，任务规划的核心问题在于选择一条连通路径或子图以满足用户的请求，这实际上是一个图上的决策问题。在这一框架下，我们分析了大规模语言模型（LLMs）在任务规划中的能力，特别是在HuggingGPT的上下文中[[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]。我们的实证研究发现，任务规划失败的相当一部分可以归因于LLMs在准确识别任务图结构方面的低效。这一发现从理论和实证角度提出了引人深思的问题。从理论上讲，它引发了关于LLMs在处理任务图时固有局限性的讨论。从实证角度来看，它凸显了迫切需要开发有效且高效的策略，以缓解这一缺陷并改善任务规划性能。
- en: For the theoretical question, we first investigate the expressiveness of Transformer
    architectures when applied to graph tasks with sequential graph input, such as
    edge list representations, which is the graph input format for task planning.
    Our initial hypothesis is that the format of sequential graph input might not
    align with the inductive bias inherent to graph structures, potentially reducing
    expressiveness. Contrary to this hypothesis, it is proved that by taking edge
    lists as the input, a constant-width Transformer can solve graph decision-making
    problems by simulating dynamic programming algorithms on edge lists. Nevertheless,
    we find that LLMs’ solutions lack invariance under graph isomorphism, an important
    property for graph decision-making problems. In addition, the expressiveness is
    weakened if the attention is sparse, which is typically observed in LLMs [[66](https://arxiv.org/html/2405.19119v3#bib.bib66)].
    Beyond expressiveness, we also examine the influence of auto-regressive loss,
    demonstrating that it introduces spurious correlations that can be harmful to
    graph decision-making tasks. These insights expose the inherent limitations of
    LLMs in task planning and, more broadly, in graph-related problems (e.g., the
    challenges in [[14](https://arxiv.org/html/2405.19119v3#bib.bib14), [59](https://arxiv.org/html/2405.19119v3#bib.bib59),
    [34](https://arxiv.org/html/2405.19119v3#bib.bib34)]).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于理论问题，我们首先研究了Transformer架构在处理具有顺序图输入（如边列表表示）的图任务时的表达能力，这也是任务规划中使用的图输入格式。我们最初的假设是，顺序图输入的格式可能与图结构固有的归纳偏差不匹配，从而降低表达能力。与这一假设相反，证明通过将边列表作为输入，常宽度的Transformer可以通过模拟动态规划算法在边列表上解决图决策问题。然而，我们发现LLM的解决方案在图同构下缺乏不变性，这是图决策问题中的一个重要特性。此外，如果注意力稀疏（这通常在LLM中观察到），表达能力会减弱
    [[66](https://arxiv.org/html/2405.19119v3#bib.bib66)]。除了表达能力，我们还考察了自回归损失的影响，证明它会引入虚假的相关性，这对图决策任务可能有害。这些见解揭示了LLM在任务规划中的固有局限性，更广泛地说，也揭示了LLM在图相关问题中的局限性（例如，[[14](https://arxiv.org/html/2405.19119v3#bib.bib14),
    [59](https://arxiv.org/html/2405.19119v3#bib.bib59), [34](https://arxiv.org/html/2405.19119v3#bib.bib34)]
    中的挑战）。
- en: 'To tackle the limitations, we take the use of GNNs, which have been shown to
    adeptly handle graph decision-making problems, both in theory and in practice
    [[24](https://arxiv.org/html/2405.19119v3#bib.bib24), [68](https://arxiv.org/html/2405.19119v3#bib.bib68)].
    Initially, we deploy LLMs to interpret an ambiguous user request, breaking it
    down into more detailed steps. Subsequently, we utilize a GNN to retrieve the
    relevant sub-tasks based on these detailed steps and the corresponding sub-task
    descriptions. Notably, this approach can be implemented without training if we
    adopt parameter-free GNN models such as SGC [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)].
    In the case of training-based methods, we apply the Bayesian Personalized Ranking
    (BPR) loss [[41](https://arxiv.org/html/2405.19119v3#bib.bib41)] to facilitate
    learning from the implicit sub-task rankings. Extensive experiments demonstrate
    that the proposed methods achieve better performance than baselines. Specifically,
    our main contributions are summarized as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些限制，我们使用了图神经网络（GNN），该网络已经被证明能够有效处理图决策问题，无论在理论上还是实践中 [[24](https://arxiv.org/html/2405.19119v3#bib.bib24),
    [68](https://arxiv.org/html/2405.19119v3#bib.bib68)]。最初，我们部署大语言模型（LLM）来解读模糊的用户请求，并将其分解为更详细的步骤。接下来，我们利用GNN根据这些详细步骤及相应的子任务描述来检索相关的子任务。值得注意的是，如果我们采用无需训练的无参数GNN模型，如SGC
    [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)]，该方法可以在无需训练的情况下实现。对于基于训练的方法，我们应用贝叶斯个性化排序（BPR）损失
    [[41](https://arxiv.org/html/2405.19119v3#bib.bib41)]，以便从隐式的子任务排序中进行学习。大量实验表明，所提出的方法在性能上优于基线方法。具体来说，我们的主要贡献总结如下：
- en: '1.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: 'Task Planning Formulation: This study presents a formulation of task planning
    as a graph decision-making problem. In the realm of task planning, our work initiates
    the exploration of graph learning methodologies to enhance performance. Concurrently,
    it introduces task planning as a new application in the graph learning domain.'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任务规划公式化：本研究将任务规划公式化为一个图决策问题。在任务规划领域，我们的工作首次探索了图学习方法，以提升性能。同时，它还将任务规划作为图学习领域中的一种新应用引入。
- en: '2.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'Theoretical Insights: We prove that Transformers have expressiveness to solve
    graph decision-making problems *based on edge list input*, but inductive biases
    of attention and the auto-regressive loss function may serve as obstacles to their
    full potential.'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 理论见解：我们证明了Transformer模型有能力解决基于边列表输入的图决策问题，但注意力机制和自回归损失函数的归纳偏差可能成为其发挥全部潜力的障碍。
- en: '3.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'Novel Algorithms: Based on the theoretical analysis, we introduce an additional
    GNN for sub-task retrieval, available in both training-free and training-based
    variants. The experiments on diverse LLMs and planning datasets demonstrate that
    the proposed method outperforms existing solutions with much less computation
    time. Furthermore, the performance is further enhanced by improved prompts or
    a fine-tuned model.'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 新颖算法：基于理论分析，我们引入了一个额外的图神经网络（GNN）用于子任务检索，既有无训练版本，也有基于训练的版本。在不同的LLM和规划数据集上的实验表明，所提出的方法比现有的解决方案在计算时间上大大减少且表现更好。此外，通过改进提示或微调模型，性能进一步提升。
- en: 2 Preliminaries
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 初步知识
- en: In this section, we introduce task planning in language agents and the current
    LLM-based solutions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了语言智能体中的任务规划以及当前基于LLM的解决方案。
- en: 2.1 Task Planning in Language Agents
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 语言智能体中的任务规划
- en: We start with the definition of task planning with a concrete example of HuggingGPT
    [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]. In task planning, there
    is a pool of pre-defined tasks. Task planning inputs include this task pool and
    a user request. The user request is expressed in natural language, which is ambiguous
    and could encompass multiple complex tasks. The output is a sequence of tasks
    and the order of their invocation to address the user’s request.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个具体的例子——HuggingGPT的任务规划定义开始[[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]。在任务规划中，有一个预定义任务池。任务规划的输入包括该任务池和用户请求。用户请求以自然语言表达，这种表达通常是模糊的，可能涉及多个复杂任务。输出是一个任务序列以及它们调用的顺序，用于满足用户的请求。
- en: 'Figure [1](https://arxiv.org/html/2405.19119v3#S2.F1 "Figure 1 ‣ 2.2 Current
    LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?") features the task planning in HuggingGPT, with
    the pre-defined tasks corresponding to APIs from the HuggingFace website, such
    as Translation and Pose-to-Image, accompanied by detailed descriptions. For instance,
    the detailed description for Translation is “Translation is the task of converting
    text from one language to another”. The user request is “Please generate an image
    where a girl is reading a book, and her pose matches the boy in ‘example.jpg’,
    then describe the new image with your voice.” The ground-truth output is a sequence
    of four APIs (nodes): $\{\texttt{Pose Detection},\texttt{Pose-to-Image},\texttt{Image-to-Text},%
    \texttt{Text-to-Speech}\}$, outlining the order of their invocation (a path).
    By invoking these APIs on HuggingFace, the user request can be fulfilled.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](https://arxiv.org/html/2405.19119v3#S2.F1 "Figure 1 ‣ 2.2 当前基于LLM的任务规划解决方案
    ‣ 2 初步知识 ‣ 图学习能否改善基于LLM的智能体规划？")展示了HuggingGPT中的任务规划，其中预定义任务对应于HuggingFace网站上的API，如翻译（Translation）和姿势到图像（Pose-to-Image），并附有详细描述。例如，翻译的详细描述是：“翻译是将文本从一种语言转换为另一种语言的任务。”用户请求是：“请生成一张图像，图中女孩正在读书，并且她的姿势与‘example.jpg’中的男孩相匹配，然后用你的声音描述这张新图像。”实际的输出是四个API（节点）的序列：$\{\texttt{Pose
    Detection}, \texttt{Pose-to-Image}, \texttt{Image-to-Text}, \texttt{Text-to-Speech}\}$，概述了它们的调用顺序（路径）。通过在HuggingFace上调用这些API，用户请求可以得到满足。
- en: 2.2 Current LLM-based Solution to Task Planning
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 当前基于LLM的任务规划解决方案
- en: 'The current solution of task planning is purely based on LLMs and involves
    two stages [[45](https://arxiv.org/html/2405.19119v3#bib.bib45), [46](https://arxiv.org/html/2405.19119v3#bib.bib46)].
    The first stage involves request decomposition, where a user’s ambiguous request
    is broken down into concrete *steps* via LLMs. For instance, the request illustrated
    in Figure [1](https://arxiv.org/html/2405.19119v3#S2.F1 "Figure 1 ‣ 2.2 Current
    LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?") is decomposed into the following steps: (1) analyze
    the pose of the boy; (2) take that pose and generate a new image; (3) generate
    the caption for newly generated image; (4) convert the generated text into audio.
    The second stage is task retrieval. For each decomposed step, LLMs are employed
    to retrieve an appropriate task from the task pool and execute them in sequence.
    For example, “Analyze the pose of the boy” corresponds to Pose detection. The
    output tasks should be (1) Pose detection; (2) Pose-to-Image; (3) Image-to-Text;
    (4) Text-to-Speech. Figure [6](https://arxiv.org/html/2405.19119v3#A5.F6 "Figure
    6 ‣ E.1 Implementation of Baselines ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?") illustrates
    this procedure.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的任务规划解决方案完全基于大语言模型（LLMs），并涉及两个阶段[[45](https://arxiv.org/html/2405.19119v3#bib.bib45),
    [46](https://arxiv.org/html/2405.19119v3#bib.bib46)]。第一阶段是请求分解，用户的模糊请求通过 LLMs
    被分解成具体的*步骤*。例如，图 [1](https://arxiv.org/html/2405.19119v3#S2.F1 "图 1 ‣ 2.2 基于 LLM
    的任务规划当前解决方案 ‣ 2 基础知识 ‣ 图学习能否改善基于 LLM 的智能体规划？") 中的请求被分解为以下步骤：（1）分析男孩的姿势；（2）获取该姿势并生成新图像；（3）为新生成的图像生成说明文字；（4）将生成的文本转换为音频。第二阶段是任务检索。对于每个分解的步骤，LLMs
    用来从任务池中检索合适的任务并按顺序执行它们。例如，“分析男孩的姿势”对应于姿势检测。输出的任务应为：（1）姿势检测；（2）姿势转图像；（3）图像转文本；（4）文本转语音。图
    [6](https://arxiv.org/html/2405.19119v3#A5.F6 "图 6 ‣ E.1 基准实施 ‣ 附录 E 不依赖训练的补充材料
    ‣ 图学习能否改善基于 LLM 的智能体规划？") 说明了这一过程。
- en: '![Refer to caption](img/9918dcf7354f7648cc430eee5e9e7697.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/9918dcf7354f7648cc430eee5e9e7697.png)'
- en: 'Figure 1: Illustration of Task Planning in Language Agents (e.g., HuggingGPT
    [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)])'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：语言智能体中的任务规划示意图（例如，HuggingGPT [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]）
- en: 3 Graph Formulation and Insights
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 图表示与洞察
- en: 3.1 Graph Formulation of Task Planning
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 任务规划的图表示
- en: In this subsection, we formulate the task planning as a decision-making problem
    on the task graph. The task graph is a special kind of text-attributed graphs
    and we define it as $G=(V,E,T)$. Each node $v\in V$ represents a pre-defined task
    in the task pool, associated with a text $t_{v}\in T$ describing its function
    (e.g., “Translation. Translation is the task of converting text from one language
    to another.”). Each edge $(u,v)\in E$ indicates a dependency between tasks (e.g.,
    the output format of task $u$ matches the input format of task $v$). Task planning
    is to select a path or connected sub-graph on the task graph.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将任务规划表述为任务图上的决策问题。任务图是一种特殊类型的带文本属性的图，我们将其定义为 $G=(V,E,T)$。每个节点 $v\in
    V$ 代表任务池中的一个预定义任务，并且与一个文本 $t_{v}\in T$ 相关联，描述其功能（例如，“翻译。翻译是将文本从一种语言转换为另一种语言的任务。”）。每条边
    $(u,v)\in E$ 表示任务之间的依赖关系（例如，任务 $u$ 的输出格式与任务 $v$ 的输入格式匹配）。任务规划就是在任务图上选择一条路径或连接的子图。
- en: Viewed from this angle, task planning bears resemblance to traditional decision-making
    problems on graphs, such as planning for the shortest path. Compared with traditional
    planning, task planning in language agents involves diverse and open-ended goals
    due to the varied users’ personal requests. For example, on platforms like HuggingFace,
    users’ intentions span across video, text, and image domains. On the contrary,
    classic planning has a fixed goal for a given domain, which is often explicitly
    expressed by mathematical formulas [[55](https://arxiv.org/html/2405.19119v3#bib.bib55),
    [36](https://arxiv.org/html/2405.19119v3#bib.bib36)].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，任务规划与传统的图形决策问题相似，例如最短路径规划。与传统规划相比，语言智能体中的任务规划涉及多样化且开放式的目标，因为用户的个人需求各不相同。例如，在像
    HuggingFace 这样的平台注册上，用户的意图涵盖了视频、文本和图像领域。相反，经典规划对于给定领域有一个固定的目标，这个目标通常通过数学公式明确表示[[55](https://arxiv.org/html/2405.19119v3#bib.bib55),
    [36](https://arxiv.org/html/2405.19119v3#bib.bib36)]。
- en: '![Refer to caption](img/5e1ccd59a3dbd22e2415fb0f3b65ad5a.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/5e1ccd59a3dbd22e2415fb0f3b65ad5a.png)'
- en: (a) Performance and Hallucination ratios
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 性能与幻觉比率
- en: '![Refer to caption](img/d496c0edc11bd374d3abfc23bb5e21b0.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/d496c0edc11bd374d3abfc23bb5e21b0.png)'
- en: (b) Hallucination ratios across datasets
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 数据集中的幻觉比例
- en: 'Figure 2: Illustration of (a) LLMs’ planning performance and hallucination
    in HuggingGPT, and (b) hallucination in relation to task graph size.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：展示了(a) LLM在HuggingGPT中的规划性能与幻觉，以及(b) 幻觉与任务图大小的关系。
- en: '3.2 Failures of LLMs in Planning: Empirical Findings'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 LLM在规划中的失败：实证发现
- en: 'With the task graph at hand, we diagnose LLMs in task planning in Figure [2](https://arxiv.org/html/2405.19119v3#S3.F2
    "Figure 2 ‣ 3.1 Graph Formulation of Task Planning ‣ 3 Graph Formulation and Insights
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?"). We adopt the experimental
    settings as outlined in the work of HuggingGPT [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)],
    where the prompts are specifically optimized for task planning on HuggingFace.
    The evaluation metric calculates the F1 score to assess the accuracy of the tasks
    identified by LLMs against the ground-truth tasks. Additionally, we report two
    task-graph-related metrics: the node hallucination ratio and the edge hallucination
    ratio. These metrics measure the frequency of non-existent nodes (i.e., tasks)
    and edges (i.e., dependencies) outputted by LLMs, respectively, indicative of
    the models’ misinterpretation of the graph input.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有任务图后，我们在图[2](https://arxiv.org/html/2405.19119v3#S3.F2 "图2 ‣ 3.1 任务规划的图表式表示
    ‣ 3 图表式表示与见解 ‣ 图学习能改善基于LLM的代理的规划吗？")中对LLM在任务规划中的表现进行了诊断。我们采用了HuggingGPT工作中概述的实验设置[[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]，其中提示词专门为HuggingFace上的任务规划进行了优化。评估指标计算F1得分，以评估LLM在与实际任务对比中识别任务的准确性。此外，我们报告了两个与任务图相关的指标：节点幻觉比例和边缘幻觉比例。这些指标分别衡量LLM输出的虚假节点（即任务）和边缘（即依赖关系）的频率，反映了模型对图输入的误解。
- en: Our empirical findings reveal that (1) LLMs exhibit a certain hallucination
    ratio, and (2) there is a strong correlation between the hallucination ratio and
    planning performance. This suggests that LLMs struggle to accurately interpret
    the task graph while the task graph is the key to the performance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实证发现表明：(1) LLM表现出一定的幻觉比例，(2) 幻觉比例与规划性能之间存在强烈的相关性。这表明，LLM在准确解释任务图时存在困难，而任务图是性能的关键。
- en: We further explore whether the incidence of hallucinations correlates with the
    number of sub-tasks. The HuggingGPT dataset contains 23 sub-tasks, and our analysis
    is expanded to incorporate the UltraTool dataset [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)],
    which consists of 260 sub-tasks. Figure [2(b)](https://arxiv.org/html/2405.19119v3#S3.F2.sf2
    "In Figure 2 ‣ 3.1 Graph Formulation of Task Planning ‣ 3 Graph Formulation and
    Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?") illustrates
    that the hallucination ratio increases with a larger task graph size.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步探讨了幻觉发生的频率是否与子任务数量相关。HuggingGPT数据集包含23个子任务，我们的分析扩展到包括UltraTool数据集[[20](https://arxiv.org/html/2405.19119v3#bib.bib20)]，该数据集包含260个子任务。图[2(b)](https://arxiv.org/html/2405.19119v3#S3.F2.sf2
    "在图2 ‣ 3.1 任务规划的图表式表示 ‣ 3 图表式表示与见解 ‣ 图学习能改善基于LLM的代理的规划吗？")显示，随着任务图规模的增大，幻觉比例增加。
- en: '3.3 Failures of LLMs in Planning: Theoretical Insights'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 LLM在规划中的失败：理论见解
- en: In this subsection, we provide theoretical insights into the limitations of
    LLMs in processing task graphs. In contrast to previous graph learning approaches
    for graph decision-making problems, LLMs process the graph input by flattening
    it into a sequence and are trained using an auto-regressive loss. We will then
    examine the impact of these two factors.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们提供了关于LLM在处理任务图时局限性的理论见解。与之前用于图决策问题的图学习方法不同，LLM通过将图输入展平为序列并使用自回归损失进行训练。我们将进一步考察这两个因素的影响。
- en: 'How does sequential graph input impact the expressiveness? We consider general
    graph decision-making problems that can be resolved using dynamic programming
    (DP) as described in ([2](https://arxiv.org/html/2405.19119v3#S3.E2 "In 3.3 Failures
    of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation and Insights ‣
    Can Graph Learning Improve Planning in LLM-based Agents?")). The input comprises
    the edge list and initial states:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化图输入如何影响表达能力？我们考虑了可以通过动态规划（DP）解决的一般图决策问题，如([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "在3.3 LLM在规划中的失败：理论见解 ‣ 3 图表式表示与见解 ‣ 图学习能改善基于LLM的代理的规划吗？"))所述。输入包括边列表和初始状态：
- en: '|  | $\displaystyle\underbrace{u_{1}\ v_{1}\ c[u_{1}][v_{1}]\ u_{1}\ v_{2}\
    c[u_{1}]% [v_{2}]\ \ldots}_{\text{edge list}}\ \underbrace{u_{1}\ \text{Answer}[0][u_{1}%
    ]\ \ldots\ u_{n}\ \text{Answer}[0][u_{n}]}_{\text{initial states}}$ |  | (1) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\underbrace{u_{1}\ v_{1}\ c[u_{1}][v_{1}]\ u_{1}\ v_{2}\
    c[u_{1}]% [v_{2}]\ \ldots}_{\text{边列表}}\ \underbrace{u_{1}\ \text{Answer}[0][u_{1}%
    ]\ \ldots\ u_{n}\ \text{Answer}[0][u_{n}]}_{\text{初始状态}}$ |  | (1) |'
- en: 'The intended output format is $u_{1}\ \text{Answer}[k][u_{1}]\ \ldots\ u_{n}\
    \text{Answer}[k][u_{n}]$. In existing studies, task graphs are often presented
    in ([1](https://arxiv.org/html/2405.19119v3#S3.E1 "In 3.3 Failures of LLMs in
    Planning: Theoretical Insights ‣ 3 Graph Formulation and Insights ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")), where the edge list is described
    by natural language and the initial states are the task descriptions of each task
    node, detailed in Appendix A.9 of [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)].'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的输出格式是 $u_{1}\ \text{Answer}[k][u_{1}]\ \ldots\ u_{n}\ \text{Answer}[k][u_{n}]$。在现有的研究中，任务图通常以
    ([1](https://arxiv.org/html/2405.19119v3#S3.E1 "在3.3节 LLMs在规划中的失败：理论见解 ‣ 3 图形公式与见解
    ‣ 图学习能否改善基于LLM的代理的规划？")) 的形式呈现，其中边列表由自然语言描述，初始状态是每个任务节点的任务描述，详见附录A.9 [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]。
- en: As discussed in the previous subsection, task planning is a decision-making
    problem on the task graph. The decision-making problems on graphs are often solved
    by DP [[3](https://arxiv.org/html/2405.19119v3#bib.bib3)] and its general formulation
    is given by
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一小节所讨论，任务规划是任务图上的决策问题。图上的决策问题通常通过动态规划（DP）解决 [[3](https://arxiv.org/html/2405.19119v3#bib.bib3)]，其一般形式为
- en: '|  | $\displaystyle\text{Answer}[k][i]=f\left(\square_{j\in\mathcal{T}(i)}g(\text{%
    Answer}[k-1][j],c[i][j])\right),$ |  | (2) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{Answer}[k][i]=f\left(\square_{j\in\mathcal{T}(i)}g(\text{%
    Answer}[k-1][j],c[i][j])\right),$ |  | (2) |'
- en: where $\text{Answer}[k][i]$ is the solution to state $i$ in the $k$-th iteration,
    $c[i][j]$ is a cost associated with state $i$ and $j$, $\mathcal{T}(i)$ is the
    set of state can be transited to $i$, $\square_{j\in\mathcal{T}(i)}$ is an aggregation
    function such as MAX or SUM, and $f,g$ are task-specific update functions. We
    give the formulation of typical DP algorithms in Appendix [D.1](https://arxiv.org/html/2405.19119v3#A4.SS1
    "D.1 Dynamic Programming ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?") including
    some NPC problems. For the decision-making problems on the text-attributed graphs
    (e.g., task planning), one may conceptualize them as DP in the feature space,
    as discussed in [[68](https://arxiv.org/html/2405.19119v3#bib.bib68)].
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\text{Answer}[k][i]$ 是第 $k$ 次迭代中状态 $i$ 的解，$c[i][j]$ 是与状态 $i$ 和 $j$ 相关的成本，$\mathcal{T}(i)$
    是可以转换到 $i$ 的状态集合，$\square_{j\in\mathcal{T}(i)}$ 是一种聚合函数，如 MAX 或 SUM，$f,g$ 是特定任务的更新函数。我们在附录
    [D.1](https://arxiv.org/html/2405.19119v3#A4.SS1 "D.1 动态规划 ‣ 附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的代理的规划？")
    中给出了典型动态规划算法的公式，包括一些NPC问题。对于文本属性图上的决策问题（例如任务规划），可以将其概念化为特征空间中的动态规划（DP），如 [[68](https://arxiv.org/html/2405.19119v3#bib.bib68)]
    中所讨论的。
- en: To our surprise, although the edge list input does not directly reflect the
    geometric structures of graphs, it enables Transformers to simulate DP efficiently,
    in terms of expressiveness, as demonstrated by the following theorem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 令我们惊讶的是，尽管边列表输入并未直接反映图的几何结构，但它使得Transformers能够有效地模拟动态规划（DP），在表达能力方面，如以下定理所示。
- en: Theorem 1.
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理1。
- en: '(LLMs have enough expressiveness) Assume the input format is given in ([1](https://arxiv.org/html/2405.19119v3#S3.E1
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) and
    $f,g,\square$ in DP update ([2](https://arxiv.org/html/2405.19119v3#S3.E2 "In
    3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation and
    Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) satisfy
    the assumptions [1](https://arxiv.org/html/2405.19119v3#Thmassumption1 "Assumption
    1\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and [2](https://arxiv.org/html/2405.19119v3#Thmassumption2
    "Assumption 2\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials
    for Theoretical Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?")
    in Appendix. There exists a log-precision constant-depth and constant-width Transformer
    that simulates one step of DP update in ([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")). As
    a consequence, there exists a log-precision $O(k)$-depth and constant-width Transformer
    that simulates $k$ steps of DP update in ([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: (LLMs具有足够的表达能力) 假设输入格式如([1](https://arxiv.org/html/2405.19119v3#S3.E1 "在3.3节
    LLMs在规划中的失败：理论见解 ‣ 3 图形表达和见解 ‣ 图学习能否改善基于LLM的代理的规划？"))所给出，并且DP更新中的$f,g,\square$([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "在3.3节 LLMs在规划中的失败：理论见解 ‣ 3 图形表达和见解 ‣ 图学习能否改善基于LLM的代理的规划？"))满足假设[1](https://arxiv.org/html/2405.19119v3#Thmassumption1
    "假设1. ‣ D.2 定理1的证明 ‣ 附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的代理的规划？")和[2](https://arxiv.org/html/2405.19119v3#Thmassumption2
    "假设2. ‣ D.2 定理1的证明 ‣ 附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的代理的规划？")中所述的假设。在([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "在3.3节 LLMs在规划中的失败：理论见解 ‣ 3 图形表达和见解 ‣ 图学习能否改善基于LLM的代理的规划？"))中，存在一个对数精度常深度和常宽度的Transformer，能够模拟DP更新的单步过程。因此，存在一个对数精度$O(k)$深度和常宽度的Transformer，能够模拟在([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "在3.3节 LLMs在规划中的失败：理论见解 ‣ 3 图形表达和见解 ‣ 图学习能否改善基于LLM的代理的规划？"))中$k$步的DP更新。
- en: The proof is presented in Appendix [D.2](https://arxiv.org/html/2405.19119v3#A4.SS2
    "D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials for Theoretical Results
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?"). However, certain
    aspects of the proof’s constructions are challenging to be realized in Transformers
    that have been pretrained on natural language. First, the embedding process must
    be carefully filtered to ensure invariance under graph isomorphism. This invariance
    property does not align with the inductive biases inherent in natural language,
    making it difficult to achieve. Consequently, if an LLM can accurately produce
    the correct answer for a specific ordering of nodes, it might not maintain this
    accuracy after the nodes have been reordered (experiments given in Appendix [D.3](https://arxiv.org/html/2405.19119v3#A4.SS3
    "D.3 Permutation Invariance Test of LLMs ‣ Appendix D Supplementary Materials
    for Theoretical Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?")).
    Second, each token needs to synchronize its hidden states with all other tokens
    sharing the same token ID, which is of order $O(|V|)$. In practice, the attention
    trained from natural language is typically sparse [[66](https://arxiv.org/html/2405.19119v3#bib.bib66)],
    leading to intractability issues. The formal lower bound is provided in the following
    proposition and the proof is given in Appendix [D.4](https://arxiv.org/html/2405.19119v3#A4.SS4
    "D.4 Proof of Proposition 1 ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?").
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 证明在附录 [D.2](https://arxiv.org/html/2405.19119v3#A4.SS2 "D.2 定理 1 的证明 ‣ 附录 D
    理论结果的补充材料 ‣ 图形学习能否改善基于LLM的智能体的规划？") 中给出。然而，证明中的某些构造在经过自然语言预训练的Transformer中难以实现。首先，嵌入过程必须经过精心过滤，以确保在图同构下的无变性。这个无变性属性与自然语言固有的归纳偏差不一致，导致其实现非常困难。因此，如果一个LLM能够准确地为特定节点顺序给出正确答案，它在节点重排后可能无法保持这一准确性（在附录
    [D.3](https://arxiv.org/html/2405.19119v3#A4.SS3 "D.3 LLMs 的排列不变性测试 ‣ 附录 D 理论结果的补充材料
    ‣ 图形学习能否改善基于LLM的智能体的规划？") 中给出了实验）。其次，每个标记需要与所有共享相同标记ID的其他标记同步其隐藏状态，这需要的复杂度为 $O(|V|)$。在实践中，从自然语言训练的注意力通常是稀疏的
    [[66](https://arxiv.org/html/2405.19119v3#bib.bib66)]，这导致了难以处理的问题。以下命题给出了正式的下界，证明则见附录
    [D.4](https://arxiv.org/html/2405.19119v3#A4.SS4 "D.4 命题 1 的证明 ‣ 附录 D 理论结果的补充材料
    ‣ 图形学习能否改善基于LLM的智能体的规划？")。
- en: Proposition 1.
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 命题 1.
- en: '(Inductive bias of language hinders expressiveness) Assume the input format
    is described ([1](https://arxiv.org/html/2405.19119v3#S3.E1 "In 3.3 Failures of
    LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation and Insights ‣ Can
    Graph Learning Improve Planning in LLM-based Agents?")) and that the attention
    mechanism is limited to attending to a constant number of tokens. There exists
    at least one instance of one-step DP update such that no log-precision constant-width
    constant-depth transformer can simulate.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: （语言的归纳偏差妨碍了表达能力）假设输入格式已描述（[1](https://arxiv.org/html/2405.19119v3#S3.E1 "在 3.3
    大型语言模型在规划中的失败：理论洞察 ‣ 3 图形表述与洞察 ‣ 图形学习能否改善基于LLM的智能体的规划？")），并且注意力机制被限制为只关注固定数量的标记。至少存在一个一阶DP更新的实例，使得没有任何对数精度的固定宽度和深度的Transformer能够进行模拟。
- en: 'How does auto-regressive Loss impact the generalization? Our investigation
    next focuses on the auto-regressive loss and considers the following scenario:
    given a fixed task graph, user data is collected to perform instruction tuning
    with next-token-prediction loss. For a tractable theoretical study, we conceptualize
    this issue as a path-planning problem, since the output of task planning is essentially
    a path. We consider the training dataset comprises input sequences of the form
    $s\ t\ s\ v_{1}\ v_{2}\ \cdots\ t$, where $s$ represents the source node, $t$
    the target node, and the sequence $s\ v_{1}\ v_{2}\ \cdots\ t$ is a path that
    adheres to specified constraints. During testing, given the initial and target
    nodes $s$ and $t$, the model is expected to generate a path with the same constraint.
    Our findings indicate that auto-regressive loss can lead to the emergence of a
    frequency-based spurious correlation, as substantiated by the following theorem
    and the proof is given in Appendix [D.5](https://arxiv.org/html/2405.19119v3#A4.SS5
    "D.5 Proof of Theorem 2 ‣ Appendix D Supplementary Materials for Theoretical Results
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归损失如何影响泛化能力？我们的研究接下来聚焦于自回归损失，并考虑以下情景：给定一个固定的任务图，收集用户数据以执行指令微调，并使用下一个标记预测损失。在可处理的理论研究中，我们将这个问题概念化为路径规划问题，因为任务规划的输出本质上是一个路径。我们假设训练数据集由以下形式的输入序列组成：$s\
    t\ s\ v_{1}\ v_{2}\ \cdots\ t$，其中$s$表示源节点，$t$表示目标节点，序列$s\ v_{1}\ v_{2}\ \cdots\
    t$是遵循特定约束的路径。在测试过程中，给定初始节点和目标节点$s$和$t$，模型应生成符合相同约束的路径。我们的研究结果表明，自回归损失可能导致基于频率的虚假相关性，这一点通过以下定理得到证实，证明见附录[D.5](https://arxiv.org/html/2405.19119v3#A4.SS5
    "D.5 Proof of Theorem 2 ‣ Appendix D Supplementary Materials for Theoretical Results
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?")。
- en: Theorem 2.
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 2.
- en: (Spurious correlations of auto-regressive loss) Assume (1) the loss employed
    is a next-token-prediction loss utilizing cross-entropy, applied to the sub-sequence
    $v_{1}\ v_{2}\ \cdots\ t$ during training; (2) the output logits are determined
    by target node $t$ and the current node $v_{i-1}$. Let $N_{t,v_{i-1},u}$ be the
    number of times in the training dataset such that $t$ is the target node, $v_{i-1}$
    is the current node and $v_{i}=u$ is the next node. The optimal logits for predicting
    the next node $u$ from current node $v_{i-1}$ towards target node $t$ is given
    by $\hat{\bm{v}}_{i}[u]=\frac{N_{t,v_{i-1},u}}{\sum_{u}N_{t,v_{i-1},u}}$ if $\sum_{u}N_{t,v_{i-1},u}>0$.
    If $\sum_{u}N_{t,v_{i-1},u}=0$, $\hat{\bm{v}}_{i}[u]$ can be any non-negative
    number subject to $\sum_{u}\hat{\bm{v}}_{i}[u]=1$.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: （自回归损失的虚假相关性）假设(1) 使用的损失是一个利用交叉熵的下一个标记预测损失，应用于训练过程中子序列$v_{1}\ v_{2}\ \cdots\
    t$；(2) 输出的logits由目标节点$t$和当前节点$v_{i-1}$决定。设$N_{t,v_{i-1},u}$为训练数据集中，$t$是目标节点，$v_{i-1}$是当前节点，$v_{i}=u$是下一个节点的次数。预测下一个节点$u$的最优logits为$\hat{\bm{v}}_{i}[u]=\frac{N_{t,v_{i-1},u}}{\sum_{u}N_{t,v_{i-1},u}}$，前提是$\sum_{u}N_{t,v_{i-1},u}>0$。如果$\sum_{u}N_{t,v_{i-1},u}=0$，那么$\hat{\bm{v}}_{i}[u]$可以是任何非负数，满足$\sum_{u}\hat{\bm{v}}_{i}[u]=1$。
- en: In our setup, $s$ $t$ is the instruction and the third token is a duplicate
    of the first token. It is reasonable to exclude these tokens in the loss calculation,
    which is the first assumption. The second assumption assumes that the output only
    depends on the current node and target node, which is a minimal requirement for
    path-related problems. For DP problems, the frequency-based prediction contradicts
    to the value-based ground-truth. We then give an example that auto-regressive
    loss even cannot find a valid path.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的设置中，$s$ $t$是指令，第三个标记是第一个标记的重复。因此，排除这些标记进行损失计算是合理的，这也是第一个假设。第二个假设认为输出仅依赖于当前节点和目标节点，这是与路径相关问题的最小要求。对于动态规划问题，基于频率的预测与基于值的真实情况相矛盾。接下来我们给出一个例子，表明自回归损失甚至无法找到有效路径。
- en: Example 1.
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 示例 1.
- en: Consider a training dataset consisting of a sufficient number of valid paths.
    Suppose the dataset contains two paths $a\ b\ c$ and $b\ c\ d$ and there are no
    other paths such that $t=d$ and the current node $v_{i}=a$ for all $i$. Then we
    have $N_{d,a,u}\equiv 0$ for all $u$ and the logits for the next node can be arbitrary.
    This results in the model’s inability to predict the next node of $a$ when given
    $a$ as the source node and $d$ as the target node.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个包含足够数量有效路径的训练数据集。假设数据集中包含两条路径$a\ b\ c$和$b\ c\ d$，且没有其他路径使得$t=d$，并且对于所有$i$，当前节点$v_{i}=a$。那么我们有$N_{d,a,u}\equiv
    0$对于所有$u$，且下一个节点的logits可以是任意的。这导致模型在给定源节点$a$和目标节点$d$时，无法预测$a$的下一个节点。
- en: To a human, finding a path from $a$ to $d$ simply involves concatenating the
    paths $a\ b\ c$ and $b\ c\ d$. However, auto-regressive loss fails under such
    circumstances. In task planning datasets, we indeed observe that the performance
    of fine-tuned LLMs is inferior to that of GNNs trained on the same dataset, as
    shown in Figure [3(b)](https://arxiv.org/html/2405.19119v3#S5.F3.sf2 "In Figure
    3 ‣ 5.4 Scaling to Large Task Graphs ‣ 5 Experiments and Analysis ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?").
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对人类而言，从$a$到$d$的路径寻找仅仅涉及将路径$a\ b\ c$和$b\ c\ d$连接起来。然而，在这种情况下，自回归损失会失败。在任务规划数据集中，我们确实观察到，经过微调的LLM的表现不如在同一数据集上训练的GNN，如[图3(b)](https://arxiv.org/html/2405.19119v3#S5.F3.sf2
    "图3 ‣ 5.4 扩展到大规模任务图 ‣ 5 实验与分析 ‣ 图学习能否改进基于LLM的代理任务规划？")所示。
- en: 4 Integrating GNNs and LLMs for Planning
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 集成GNN和LLM进行任务规划
- en: 4.1 Motivations
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 动机
- en: In the last section, we find that a considerable portion of planning failures
    can be ascribed to the LLMs’ inefficacy in accurately discerning the structure
    of the task graph, due to the hallucination, the inductive bias of the attention,
    and next-token prediction loss. In contrast to LLMs, GNNs can strictly operate
    on the task graph, thereby avoiding hallucinations. Additionally, they leverage
    the graph structure as input, rather than flattening the graph into a sequence,
    thus overcoming the theoretical limitations discussed previously. Furthermore,
    GNNs have demonstrated proficiency in handling graph decision-making problems,
    both theoretically and empirically [[68](https://arxiv.org/html/2405.19119v3#bib.bib68),
    [11](https://arxiv.org/html/2405.19119v3#bib.bib11), [24](https://arxiv.org/html/2405.19119v3#bib.bib24)].
    As a result, the simplest fix is to integrate GNNs into the task-planning algorithm.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们发现，相当一部分任务规划失败可归因于LLM在准确辨识任务图结构上的无效性，这主要是由于幻觉、注意力的归纳偏差和下一个标记预测损失造成的。与LLM不同，GNNs可以严格操作任务图，从而避免幻觉问题。此外，GNNs将图结构作为输入，而不是将图展平成序列，从而克服了之前讨论的理论限制。此外，GNNs在处理图决策问题上无论在理论上还是在实践中都表现出了出色的能力[[68](https://arxiv.org/html/2405.19119v3#bib.bib68),
    [11](https://arxiv.org/html/2405.19119v3#bib.bib11), [24](https://arxiv.org/html/2405.19119v3#bib.bib24)]。因此，最简单的解决办法是将GNNs集成到任务规划算法中。
- en: In the following subsections, we propose both training-free and training-based
    approaches to enhance performance. Training-free methods are necessary when the
    available tasks are continuously changing, or new tasks are emerging constantly.
    This scenario is common when the task planning module is deployed in a new system.
    Once the task planning module has been deployed for a period, it becomes possible
    to collect users’ requests and label a small proportion of the data, enabling
    lightweight training-based methods.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子章节中，我们提出了无训练和基于训练的两种方法来增强性能。当可用任务不断变化，或新任务持续出现时，必须采用无训练方法。这种情况在任务规划模块被部署到新系统时很常见。一旦任务规划模块部署一段时间后，就可以收集用户的请求，并标注一小部分数据，从而使轻量级的基于训练的方法成为可能。
- en: 4.2 A Training-free GNN-based Approach
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 一种无训练的基于GNN的方法
- en: As we discussed in Section [2.2](https://arxiv.org/html/2405.19119v3#S2.SS2
    "2.2 Current LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?"), the current solution to task
    planning involves two stages. The first stage requires the ability to understand
    users’ requests in natural language and break them down into concrete instructions,
    which is the unique ability of LLMs. The second stage is to select a path on the
    task graph, where each node corresponds to a decomposed step. Thus, we can integrate
    GNNs in this stage. The illustration of our framework is shown in Figure [7](https://arxiv.org/html/2405.19119v3#A6.F7
    "Figure 7 ‣ F.1 Implementation of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") in Appendix.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第[2.2节](https://arxiv.org/html/2405.19119v3#S2.SS2 "2.2 目前基于LLM的任务规划解决方案
    ‣ 2 基础知识 ‣ 图学习能否改进基于LLM的代理任务规划？")中讨论的那样，目前的任务规划解决方案包含两个阶段。第一阶段需要能够理解用户的自然语言请求，并将其分解为具体的指令，这正是LLM的独特能力。第二阶段是选择任务图中的一条路径，每个节点对应一个分解的步骤。因此，我们可以在这一阶段整合GNNs。我们框架的示意图见附录中的[图7](https://arxiv.org/html/2405.19119v3#A6.F7
    "图7 ‣ F.1 基于训练的GNN实现 ‣ 附录F 基于训练的方法补充材料 ‣ 图学习能否改进基于LLM的代理任务规划？")。
- en: For each decomposed step outputted by the first stage, we use a GNN to select
    a corresponding node within the task graph. Suppose we are selecting the node
    for the $i$-th decomposed step. First, we utilize a small pre-trained language
    model, e5-335M [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)], to embed
    the $i$-th decomposed step. The resulting embedding is denoted as $\bm{x}_{i}^{\text{step}}$.
    Second, for the task graph, we first use the same pre-trained language model e5-335M
    to convert each node’s description into embeddings, denoted as the node feature
    $\bm{h}^{0}_{v}$, where the superscript indicates the layer and the subscript
    represents the node. Then we adopt a $K$-layer SGC [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)]
    to compute the final node embeddings, resulting in $\bm{h}_{v}=\bm{h}_{v}^{(K)}$.
    Given a sequence of previously selected task nodes $\{v_{1},\cdots,v_{i-1}\}$,
    the next node $v_{i}$ is chosen according to $v_{i}=\text{argmax}_{v\in\mathcal{N}(v_{i-1})}\;\langle\bm{h}_{v},\bm{x}_{i}^{%
    \text{step}}\rangle$, where $\bm{h}_{v}$ is the final node embedding, and $\mathcal{N}(v_{i-1})$
    denotes the neighbors of node $v_{i-1}$ in the task graph. Particularly, $v_{1}$
    can be selected from the whole graph.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一阶段输出的每个分解步骤，我们使用GNN选择任务图中的相应节点。假设我们正在选择第$i$个分解步骤的节点。首先，我们使用一个小型预训练语言模型e5-335M
    [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]来嵌入第$i$个分解步骤。得到的嵌入表示为$\bm{x}_{i}^{\text{step}}$。其次，对于任务图，我们首先使用相同的预训练语言模型e5-335M将每个节点的描述转换为嵌入，表示为节点特征$\bm{h}^{0}_{v}$，其中上标表示层，下标表示节点。然后，我们采用$K$层SGC
    [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)]来计算最终的节点嵌入，得到$\bm{h}_{v}=\bm{h}_{v}^{(K)}$。给定一个先前选择的任务节点序列$\{v_{1},\cdots,v_{i-1}\}$，下一个节点$v_{i}$根据公式$v_{i}=\text{argmax}_{v\in\mathcal{N}(v_{i-1})}\;\langle\bm{h}_{v},\bm{x}_{i}^{\text{step}}\rangle$选择，其中$\bm{h}_{v}$是最终的节点嵌入，$\mathcal{N}(v_{i-1})$表示任务图中节点$v_{i-1}$的邻居。特别地，$v_{1}$可以从整个图中选择。
- en: As e5-335M is pre-trained and SGC is parameter-free, the proposed method requires
    no additional training and can be effectively applied in a zero-shot manner.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于e5-335M是预训练的且SGC是无参数的，因此该方法不需要额外的训练，可以有效地以零-shot的方式应用。
- en: 4.3 A Training-required GNN-based Approach
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 基于GNN的训练方法
- en: The inference process in training-required methods mirrors that of the training-free
    approach, with the difference being the substitution of parameter-free GNNs with
    parametric counterparts, such as GAT [[57](https://arxiv.org/html/2405.19119v3#bib.bib57)]
    or GraphSAGE [[15](https://arxiv.org/html/2405.19119v3#bib.bib15)]. Here we specify
    the training process of GNNs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练所需的方法中，推理过程与训练无关的方法相似，区别在于用带参数的图神经网络（GNN）替代了无参数的GNN，例如GAT [[57](https://arxiv.org/html/2405.19119v3#bib.bib57)]或GraphSAGE
    [[15](https://arxiv.org/html/2405.19119v3#bib.bib15)]。在这里，我们具体说明了GNN的训练过程。
- en: 'Data Preparation: We assume that each entry in the task planning dataset comprises
    a user request, a sequence of decomposed steps, and the corresponding ground-truth
    tasks, denoted as $(\text{request},\{s_{1},\ldots,s_{n}\},\{v_{1},\ldots,v_{n}\})$.
    If the dataset does not adhere to this format, we reformat it accordingly using
    GPT-4, with details provided in Appendix [C.2](https://arxiv.org/html/2405.19119v3#A3.SS2
    "C.2 Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?"). It is important to note that there is
    a one-to-one correspondence between the steps and tasks in the dataset. Therefore,
    the training dataset can be represented as $\{(s_{i},v_{i})\}_{i=1}^{n}$, where
    $s_{i}$ is a step described in natural language, and $v_{i}$ is its corresponding
    invoked task.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备：我们假设任务规划数据集中的每一条记录由用户请求、分解的步骤序列以及对应的真实任务组成，表示为$(\text{request},\{s_{1},\ldots,s_{n}\},\{v_{1},\ldots,v_{n}\})$。如果数据集不符合此格式，我们会使用GPT-4对其进行重新格式化，具体细节请参考附录[C.2](https://arxiv.org/html/2405.19119v3#A3.SS2
    "C.2 Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")。需要注意的是，数据集中的步骤与任务之间存在一一对应关系。因此，训练数据集可以表示为$\{(s_{i},v_{i})\}_{i=1}^{n}$，其中$s_{i}$是以自然语言描述的步骤，$v_{i}$是其对应的调用任务。
- en: 'Training Loss: The problem in the dataset can be viewed as a binary ranking
    problem, where the labeled node is $1$ and the other nodes are $0$. Therefore,
    we adopt the Bayesian Personalized Ranking (BPR) loss [[41](https://arxiv.org/html/2405.19119v3#bib.bib41)]
    designed for recommendation with binary rankings. The loss function is given by
    $\ell=\sum_{(\bm{x}^{\text{step}},v,v^{\prime})}-\log\;\sigma(\langle\bm{h}_{v}%
    ,\bm{x}^{\text{step}}\rangle-\langle\bm{h}_{v^{\prime}},\bm{x}^{\text{step}}\rangle)$,
    where $\bm{x}^{\text{step}}$ represents the embedding of the step’s textual description
    generated by e5-335M, $v$ is the ground-truth task, and $v^{\prime}$ is a negative
    task. We select negative tasks that are textually similar to the positive task,
    and for computational efficiency, we limit our selection to $2$ negative tasks
    per positive task. The trainable parameters may merely include GNNs or both GNNs
    and e5-335M with illustrative configurations shown in Figure [8](https://arxiv.org/html/2405.19119v3#A6.F8
    "Figure 8 ‣ F.1 Implementation of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") in Appendix.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 训练损失：数据集中的问题可以视为一个二元排序问题，其中标记的节点为$1$，其他节点为$0$。因此，我们采用了为二元排序推荐设计的贝叶斯个性化排序（BPR）损失[[41](https://arxiv.org/html/2405.19119v3#bib.bib41)]。损失函数为$\ell=\sum_{(\bm{x}^{\text{step}},v,v^{\prime})}-\log\;\sigma(\langle\bm{h}_{v}%
    ,\bm{x}^{\text{step}}\rangle-\langle\bm{h}_{v^{\prime}},\bm{x}^{\text{step}}\rangle)$，其中$\bm{x}^{\text{step}}$表示由e5-335M生成的步骤文本描述的嵌入，$v$是真实任务，$v^{\prime}$是负任务。我们选择与正任务文本相似的负任务，并为了计算效率，将每个正任务的负任务数量限制为$2$个。可训练的参数可能仅包括GNN或包括GNN和e5-335M，附录中的图[8](https://arxiv.org/html/2405.19119v3#A6.F8
    "Figure 8 ‣ F.1 Implementation of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?")展示了示例配置。
- en: 5 Experiments and Analysis
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 实验与分析
- en: 5.1 Experimental Setup
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 实验设置
- en: 'Datasets: We utilize four datasets across two task planning benchmarks: HuggingFace
    tasks, Multimedia tasks, and Daily Life API tasks from TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)],
    as well as TMDB API tasks from RestBench [[50](https://arxiv.org/html/2405.19119v3#bib.bib50)].
    The HuggingFace dataset includes AI models on the HuggingFace. The Multimedia
    dataset provides a wide range of user-centric tasks, such as file downloading
    and video editing. The Daily Life APIs cater to everyday services like web search
    and shopping functionalities. TMDB focuses on movie-related search and retrieval
    tasks. Statistics for each dataset are presented in Table [7](https://arxiv.org/html/2405.19119v3#A3.T7
    "Table 7 ‣ C.2 Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?") with illustrative examples shown
    in Figure [4](https://arxiv.org/html/2405.19119v3#A3.F4 "Figure 4 ‣ C.2 Reformatting
    Details of RestBench ‣ Appendix C Datasets ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?") in Appendix. Other benchmarks, such as ToolBench [[39](https://arxiv.org/html/2405.19119v3#bib.bib39)]
    and ToolAlpaca [[54](https://arxiv.org/html/2405.19119v3#bib.bib54)], are less
    suitable for our experiments due to (1) the absence of a well-defined task graph
    detailing tasks and their dependencies, and (2) a scarcity of samples involving
    multi-task planning, with a focus on single-task retrieval.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集：我们使用了跨越两个任务规划基准的四个数据集：HuggingFace任务、多媒体任务和来自TaskBench的日常生活API任务[[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]，以及来自RestBench的TMDB
    API任务[[50](https://arxiv.org/html/2405.19119v3#bib.bib50)]。HuggingFace数据集包括HuggingFace上的AI模型。多媒体数据集提供了广泛的以用户为中心的任务，如文件下载和视频编辑。日常生活API涵盖了如网页搜索和购物功能等日常服务。TMDB专注于与电影相关的搜索和检索任务。每个数据集的统计信息见表[7](https://arxiv.org/html/2405.19119v3#A3.T7
    "Table 7 ‣ C.2 Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")，并在附录中的图[4](https://arxiv.org/html/2405.19119v3#A3.F4
    "Figure 4 ‣ C.2 Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can
    Graph Learning Improve Planning in LLM-based Agents?")中给出了示例。其他基准，如ToolBench [[39](https://arxiv.org/html/2405.19119v3#bib.bib39)]和ToolAlpaca
    [[54](https://arxiv.org/html/2405.19119v3#bib.bib54)]，由于以下原因不适合我们的实验：(1)缺少详细列出任务及其依赖关系的明确任务图，(2)涉及多任务规划的样本稀缺，重点是单任务检索。
- en: 'Evaluation: For the datasets from TaskBench, we split $3000$ samples for training
    and $500$ samples for testing, each containing an invocation path with at least
    two tasks. For the TMDB dataset, we first filter to include the samples with two
    or more invoked tasks, and then randomly select a sample served as the in-context
    learning example. The remaining $94$ samples are designated for testing. We adopt
    the evaluation metric in TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]
    and HuggingGPT [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)], i.e., Node
    F1-Score (n-F1) and Link F1-Score (l-F1), which measure the accuracy of invoked
    tasks and invoked dependencies, respectively. Besides, the Accuracy (Acc) can
    measure the success rate from task level. We also measure the token consumption
    (# tok) as the efficiency metric.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：对于TaskBench中的数据集，我们将$3000$个样本用于训练，$500$个样本用于测试，每个样本包含至少两个任务的调用路径。对于TMDB数据集，我们首先筛选出包含两个或更多被调用任务的样本，然后随机选择一个样本作为上下文学习示例。其余的$94$个样本用于测试。我们采用TaskBench
    [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]和HuggingGPT [[46](https://arxiv.org/html/2405.19119v3#bib.bib46)]中的评估指标，即节点F1得分（n-F1）和链接F1得分（l-F1），分别衡量被调用任务和被调用依赖的准确性。此外，准确率（Acc）可以衡量任务级别的成功率。我们还测量了标记消耗（#
    tok）作为效率指标。
- en: 'Choices of LLMs: We consider close-sourced LLMs, i.e., GPT-3.5-turbo and GPT-4-turbo,
    as well as open-sourced LLMs with different parameter scales, including CodeLlama-13B(or
    7B)-Instruct-hf [[42](https://arxiv.org/html/2405.19119v3#bib.bib42)], Mistral-7B-Instruct-v0.2
    [[23](https://arxiv.org/html/2405.19119v3#bib.bib23)], Vicuna-13B-v1.5 [[72](https://arxiv.org/html/2405.19119v3#bib.bib72)],
    and Baichuan2-13B-Chat [[69](https://arxiv.org/html/2405.19119v3#bib.bib69)].'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: LLM选择：我们考虑了封闭源LLM，即GPT-3.5-turbo和GPT-4-turbo，以及不同参数规模的开源LLM，包括CodeLlama-13B（或7B）-Instruct-hf
    [[42](https://arxiv.org/html/2405.19119v3#bib.bib42)]、Mistral-7B-Instruct-v0.2
    [[23](https://arxiv.org/html/2405.19119v3#bib.bib23)]、Vicuna-13B-v1.5 [[72](https://arxiv.org/html/2405.19119v3#bib.bib72)]
    和 Baichuan2-13B-Chat [[69](https://arxiv.org/html/2405.19119v3#bib.bib69)]。
- en: 'Choices of GNNs: To comprehensively investigate the effectiveness of different
    graph learning methods for task planning, we consider a wide range of graph neural
    networks, including SGC [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)],
    GCN [[26](https://arxiv.org/html/2405.19119v3#bib.bib26)], GAT [[57](https://arxiv.org/html/2405.19119v3#bib.bib57)],
    GraphSAGE [[15](https://arxiv.org/html/2405.19119v3#bib.bib15)], GIN [[67](https://arxiv.org/html/2405.19119v3#bib.bib67)],
    and Graph Transformers [[47](https://arxiv.org/html/2405.19119v3#bib.bib47)].'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: GNN选择：为了全面调查不同图学习方法在任务规划中的有效性，我们考虑了多种图神经网络，包括SGC [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)]、GCN
    [[26](https://arxiv.org/html/2405.19119v3#bib.bib26)]、GAT [[57](https://arxiv.org/html/2405.19119v3#bib.bib57)]、GraphSAGE
    [[15](https://arxiv.org/html/2405.19119v3#bib.bib15)]、GIN [[67](https://arxiv.org/html/2405.19119v3#bib.bib67)]
    和 Graph Transformers [[47](https://arxiv.org/html/2405.19119v3#bib.bib47)]。
- en: 5.2 Performance of the Training-free Approach
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 无需训练方法的性能
- en: 'We compare the performance across three training-free methods: (1) LLM’s Direct
    Inference is introduced in Section [2.2](https://arxiv.org/html/2405.19119v3#S2.SS2
    "2.2 Current LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?"). (2) GraphSearch [[33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [52](https://arxiv.org/html/2405.19119v3#bib.bib52), [32](https://arxiv.org/html/2405.19119v3#bib.bib32)]
    leverages the classic graph search method to generate the candidate nodes and
    uses LLMs to give a score for node selection. Given a step, GreedySearch consistently
    selects the node with the highest score and adjacent to the previous task node;
    AdaptiveSearch selects the nodes with scores above a fixed threshold, adjusting
    the breadth of the search space in an adaptive mode; BeamSearch retains the $k$
    nodes with highest scores. (3) SGC [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)]
    employs a training-free SGC for task retrieval based on decomposed task steps.
    The details of baselines are given in Section [E.1](https://arxiv.org/html/2405.19119v3#A5.SS1
    "E.1 Implementation of Baselines ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and illustrated
    in Figure [6](https://arxiv.org/html/2405.19119v3#A5.F6 "Figure 6 ‣ E.1 Implementation
    of Baselines ‣ Appendix E Supplementary Materials for Training-free Methods ‣
    Can Graph Learning Improve Planning in LLM-based Agents?"). Table [1](https://arxiv.org/html/2405.19119v3#S5.T1
    "Table 1 ‣ 5.2 Performance of the Training-free Approach ‣ 5 Experiments and Analysis
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?") shows both the overall
    performance and token consumption costs, with results of Accuracy (Acc) moved
    to Table [9](https://arxiv.org/html/2405.19119v3#A5.T9 "Table 9 ‣ E.3 Accuracy
    Results of Training-free Methods ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?") in Appendix.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了三种无训练方法的性能：（1）LLM 的直接推理介绍见第 [2.2](https://arxiv.org/html/2405.19119v3#S2.SS2
    "2.2 Current LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")节。（2）GraphSearch [[33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [52](https://arxiv.org/html/2405.19119v3#bib.bib52), [32](https://arxiv.org/html/2405.19119v3#bib.bib32)]
    利用经典的图搜索方法生成候选节点，并使用 LLM 对节点选择进行评分。在给定的步骤中，GreedySearch 一直选择具有最高分数且与前一个任务节点相邻的节点；AdaptiveSearch
    选择得分高于固定阈值的节点，并以自适应方式调整搜索空间的广度；BeamSearch 保留得分最高的 $k$ 个节点。（3）SGC [[65](https://arxiv.org/html/2405.19119v3#bib.bib65)]
    采用无训练的 SGC 进行基于分解任务步骤的任务检索。基准的详细信息见第 [E.1](https://arxiv.org/html/2405.19119v3#A5.SS1
    "E.1 Implementation of Baselines ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?")节，并在图 [6](https://arxiv.org/html/2405.19119v3#A5.F6
    "Figure 6 ‣ E.1 Implementation of Baselines ‣ Appendix E Supplementary Materials
    for Training-free Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?")中进行了说明。表
    [1](https://arxiv.org/html/2405.19119v3#S5.T1 "Table 1 ‣ 5.2 Performance of the
    Training-free Approach ‣ 5 Experiments and Analysis ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?") 显示了整体性能和令牌消耗成本，准确性（Acc）的结果移至附录中的表 [9](https://arxiv.org/html/2405.19119v3#A5.T9
    "Table 9 ‣ E.3 Accuracy Results of Training-free Methods ‣ Appendix E Supplementary
    Materials for Training-free Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")。
- en: 'Table 1: Comparison of Training-free Methods: Overall Performance (Node-F1
    and Link-F1 in $\%$) and Token Consumption in $\times 10^{3}$. Performance of
    other LLMs are given in Table [8](https://arxiv.org/html/2405.19119v3#A5.T8 "Table
    8 ‣ E.2 Results of All LLMs ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?").'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：无训练方法比较：整体性能（Node-F1 和 Link-F1，单位为 $\%$）及令牌消耗（单位为 $\times 10^{3}$）。其他 LLM
    的性能见表 [8](https://arxiv.org/html/2405.19119v3#A5.T8 "Table 8 ‣ E.2 Results of
    All LLMs ‣ Appendix E Supplementary Materials for Training-free Methods ‣ Can
    Graph Learning Improve Planning in LLM-based Agents?")。
- en: '|  |  | TaskBench | RestBench |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  |  | TaskBench | RestBench |'
- en: '|  |  | HuggingFace | Multimedia | Daily Life | TMDB |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|  |  | HuggingFace | 多媒体 | 日常生活 | TMDB |'
- en: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | # Tok $\downarrow$ | n-F1
    $\uparrow$ | l-F1 $\uparrow$ | # Tok $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$
    | # Tok $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | #Tok $\downarrow$ |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | n-F1 $\uparrow$ | l-F1 $\uparrow$ | # Tok $\downarrow$ | n-F1
    $\uparrow$ | l-F1 $\uparrow$ | # Tok $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$
    | # Tok $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | #Tok $\downarrow$ |'
- en: '| Vicuna 13B | Direct | 50.46 | 21.27 | 2.50 | 53.57 | 23.19 | 2.64 | 73.70
    | 45.80 | 3.82 | 44.66 | 14.01 | 2.02 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna 13B | 直接推理 | 50.46 | 21.27 | 2.50 | 53.57 | 23.19 | 2.64 | 73.70 |
    45.80 | 3.82 | 44.66 | 14.01 | 2.02 |'
- en: '| GreedySearch | 52.94 | 25.73 | 6.23 | 46.99 | 23.11 | 5.55 | 42.98 | 13.33
    | 7.18 | 45.22 | 13.69 | 3.42 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 52.94 | 25.73 | 6.23 | 46.99 | 23.11 | 5.55 | 42.98 | 13.33
    | 7.18 | 45.22 | 13.69 | 3.42 |'
- en: '| AdaptiveSearch | 54.36 | 25.67 | 9.81 | 51.24 | 24.32 | 11.25 | 62.71 | 31.15
    | 13.92 | 41.32 | 7.02 | 6.51 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 54.36 | 25.67 | 9.81 | 51.24 | 24.32 | 11.25 | 62.71 | 31.15
    | 13.92 | 41.32 | 7.02 | 6.51 |'
- en: '| BeamSearch | 56.64 | 26.93 | 24.11 | 54.09 | 26.19 | 25.42 | 54.55 | 23.60
    | 24.86 | 46.91 | 15.41 | 7.79 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 56.64 | 26.93 | 24.11 | 54.09 | 26.19 | 25.42 | 54.55 | 23.60
    | 24.86 | 46.91 | 15.41 | 7.79 |'
- en: '| SGC | 59.62 | 31.98 | 2.31 | 61.78 | 37.60 | 2.43 | 83.33 | 63.77 | 3.82
    | 48.79 | 15.99 | 1.89 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 59.62 | 31.98 | 2.31 | 61.78 | 37.60 | 2.43 | 83.33 | 63.77 | 3.82
    | 48.79 | 15.99 | 1.89 |'
- en: '| Mistral 7B | Direct | 60.60 | 30.23 | 2.49 | 69.83 | 39.85 | 2.64 | 84.26
    | 53.63 | 3.77 | 62.23 | 22.02 | 1.96 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Mistral 7B | Direct | 60.60 | 30.23 | 2.49 | 69.83 | 39.85 | 2.64 | 84.26
    | 53.63 | 3.77 | 62.23 | 22.02 | 1.96 |'
- en: '| GreedySearch | 65.91 | 38.13 | 6.52 | 58.92 | 34.72 | 6.26 | 75.18 | 49.47
    | 8.27 | 60.64 | 23.18 | 4.38 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 65.91 | 38.13 | 6.52 | 58.92 | 34.72 | 6.26 | 75.18 | 49.47
    | 8.27 | 60.64 | 23.18 | 4.38 |'
- en: '| AdaptiveSearch | 67.30 | 38.90 | 7.68 | 71.59 | 44.84 | 10.66 | 86.39 | 63.65
    | 10.92 | 54.04 | 21.35 | 9.99 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 67.30 | 38.90 | 7.68 | 71.59 | 44.84 | 10.66 | 86.39 | 63.65
    | 10.92 | 54.04 | 21.35 | 9.99 |'
- en: '| BeamSearch | 67.13 | 36.73 | 25.66 | 73.55 | 47.12 | 31.10 | 85.87 | 61.53
    | 39.16 | 63.41 | 26.79 | 11.26 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 67.13 | 36.73 | 25.66 | 73.55 | 47.12 | 31.10 | 85.87 | 61.53
    | 39.16 | 63.41 | 26.79 | 11.26 |'
- en: '| SGC | 67.43 | 42.08 | 2.32 | 74.07 | 49.90 | 2.43 | 87.13 | 66.49 | 3.54
    | 64.72 | 25.67 | 1.89 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 67.43 | 42.08 | 2.32 | 74.07 | 49.90 | 2.43 | 87.13 | 66.49 | 3.54
    | 64.72 | 25.67 | 1.89 |'
- en: '| CodeLlama 13B | Direct | 57.55 | 28.88 | 2.45 | 68.57 | 41.79 | 2.59 | 91.20
    | 76.07 | 3.88 | 68.91 | 43.74 | 2.02 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama 13B | Direct | 57.55 | 28.88 | 2.45 | 68.57 | 41.79 | 2.59 | 91.20
    | 76.07 | 3.88 | 68.91 | 43.74 | 2.02 |'
- en: '| GreedySearch | 61.67 | 34.02 | 5.95 | 67.98 | 42.04 | 4.95 | 91.50 | 76.56
    | 5.54 | 66.67 | 42.16 | 3.81 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 61.67 | 34.02 | 5.95 | 67.98 | 42.04 | 4.95 | 91.50 | 76.56
    | 5.54 | 66.67 | 42.16 | 3.81 |'
- en: '| AdaptiveSearch | 60.85 | 31.66 | 11.10 | 68.14 | 41.71 | 6.77 | 91.34 | 76.09
    | 7.18 | 63.74 | 37.17 | 8.16 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 60.85 | 31.66 | 11.10 | 68.14 | 41.71 | 6.77 | 91.34 | 76.09
    | 7.18 | 63.74 | 37.17 | 8.16 |'
- en: '| BeamSearch | 62.65 | 34.31 | 20.14 | 69.53 | 43.35 | 19.51 | 91.74 | 76.60
    | 19.19 | 68.08 | 42.92 | 8.88 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 62.65 | 34.31 | 20.14 | 69.53 | 43.35 | 19.51 | 91.74 | 76.60
    | 19.19 | 68.08 | 42.92 | 8.88 |'
- en: '| SGC | 65.51 | 39.44 | 2.31 | 73.32 | 53.28 | 2.43 | 92.96 | 79.57 | 3.64
    | 71.40 | 47.55 | 1.90 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 65.51 | 39.44 | 2.31 | 73.32 | 53.28 | 2.43 | 92.96 | 79.57 | 3.64
    | 71.40 | 47.55 | 1.90 |'
- en: '| GPT- 3.5-turbo | Direct | 73.85 | 45.73 | 2.14 | 82.85 | 62.07 | 2.26 | 96.09
    | 83.65 | 3.36 | 81.70 | 57.52 | 1.67 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| GPT- 3.5-turbo | Direct | 73.85 | 45.73 | 2.14 | 82.85 | 62.07 | 2.26 | 96.09
    | 83.65 | 3.36 | 81.70 | 57.52 | 1.67 |'
- en: '| GreedySearch | 67.75 | 43.88 | 5.29 | 81.11 | 63.02 | 4.92 | 93.77 | 81.26
    | 7.36 | 76.19 | 50.11 | 3.06 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 67.75 | 43.88 | 5.29 | 81.11 | 63.02 | 4.92 | 93.77 | 81.26
    | 7.36 | 76.19 | 50.11 | 3.06 |'
- en: '| AdaptiveSearch | 72.18 | 47.55 | 7.47 | 81.86 | 62.71 | 5.71 | 93.79 | 81.41
    | 8.53 | 77.57 | 53.65 | 5.89 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 72.18 | 47.55 | 7.47 | 81.86 | 62.71 | 5.71 | 93.79 | 81.41
    | 8.53 | 77.57 | 53.65 | 5.89 |'
- en: '| BeamSearch | 75.51 | 49.62 | 14.22 | 83.57 | 64.50 | 12.91 | 95.66 | 82.72
    | 22.05 | 81.24 | 57.98 | 6.42 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 75.51 | 49.62 | 14.22 | 83.57 | 64.50 | 12.91 | 95.66 | 82.72
    | 22.05 | 81.24 | 57.98 | 6.42 |'
- en: '| SGC | 76.37 | 50.04 | 2.02 | 83.65 | 63.65 | 2.09 | 96.38 | 86.19 | 3.16
    | 82.63 | 59.15 | 1.61 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 76.37 | 50.04 | 2.02 | 83.65 | 63.65 | 2.09 | 96.38 | 86.19 | 3.16
    | 82.63 | 59.15 | 1.61 |'
- en: '| GPT- 4-turbo | Direct | 77.60 | 52.18 | 2.19 | 88.29 | 69.38 | 2.28 | 97.36
    | 84.58 | 3.37 | 82.56 | 56.67 | 1.75 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| GPT- 4-turbo | Direct | 77.60 | 52.18 | 2.19 | 88.29 | 69.38 | 2.28 | 97.36
    | 84.58 | 3.37 | 82.56 | 56.67 | 1.75 |'
- en: '| GreedySearch | 74.75 | 50.44 | 5.78 | 86.81 | 69.80 | 5.52 | 97.36 | 85.78
    | 7.37 | 75.34 | 49.95 | 3.73 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 74.75 | 50.44 | 5.78 | 86.81 | 69.80 | 5.52 | 97.36 | 85.78
    | 7.37 | 75.34 | 49.95 | 3.73 |'
- en: '| AdaptiveSearch | 76.17 | 51.30 | 8.94 | 88.02 | 69.99 | 7.14 | 97.30 | 85.80
    | 9.04 | 81.78 | 55.15 | 6.35 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 76.17 | 51.30 | 8.94 | 88.02 | 69.99 | 7.14 | 97.30 | 85.80
    | 9.04 | 81.78 | 55.15 | 6.35 |'
- en: '| BeamSearch | 77.56 | 52.54 | 8.98 | 88.16 | 70.39 | 6.90 | 97.35 | 85.78
    | 8.99 | 80.11 | 51.00 | 5.18 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 77.56 | 52.54 | 8.98 | 88.16 | 70.39 | 6.90 | 97.35 | 85.78
    | 8.99 | 80.11 | 51.00 | 5.18 |'
- en: '| SGC | 77.79 | 52.20 | 2.03 | 88.54 | 69.83 | 2.10 | 97.35 | 85.76 | 3.16
    | 82.27 | 56.37 | 1.62 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 77.79 | 52.20 | 2.03 | 88.54 | 69.83 | 2.10 | 97.35 | 85.76 | 3.16
    | 82.27 | 56.37 | 1.62 |'
- en: Compared with direct inference, integrating an SGC consistently improves performance,
    underscoring the effectiveness of the proposed method. GraphSearch-type methods
    rely on beam search to identify paths and employ LLMs for evaluation, where longer
    processing times generally lead to better outcomes. Notably, our proposed method
    achieves comparable or superior performance (Table [1](https://arxiv.org/html/2405.19119v3#S5.T1
    "Table 1 ‣ 5.2 Performance of the Training-free Approach ‣ 5 Experiments and Analysis
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and Table [9](https://arxiv.org/html/2405.19119v3#A5.T9
    "Table 9 ‣ E.3 Accuracy Results of Training-free Methods ‣ Appendix E Supplementary
    Materials for Training-free Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")) to BeamSearch while requiring $5$-$10$ times fewer tokens (Table [1](https://arxiv.org/html/2405.19119v3#S5.T1
    "Table 1 ‣ 5.2 Performance of the Training-free Approach ‣ 5 Experiments and Analysis
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) and inference time
    (Table [10](https://arxiv.org/html/2405.19119v3#A5.T10 "Table 10 ‣ E.4 Computational
    Cost Analysis ‣ Appendix E Supplementary Materials for Training-free Methods ‣
    Can Graph Learning Improve Planning in LLM-based Agents?")). The case studies
    are provided in Appendix [H](https://arxiv.org/html/2405.19119v3#A8 "Appendix
    H Case Studies ‣ Can Graph Learning Improve Planning in LLM-based Agents?"). However,
    we observed only marginal improvements with GPT-4-turbo. A unique feature of GPT-4-turbo
    is its ability to manage ChatGPT-plugins, and it may have been specially trained
    on task planning datasets. In addition, the pre-trained language model used for
    feature extraction in SGC is e5-335M, which may not be sufficiently powerful to
    effectively analyze GPT-4’s output. A detailed diagnostic analysis of cases involving
    GPT-4 is provided in Figure [11](https://arxiv.org/html/2405.19119v3#A8.F11 "Figure
    11 ‣ Appendix H Case Studies ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?") in Appendix.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与直接推理相比，集成SGC始终能提高性能，突显了所提出方法的有效性。GraphSearch类型的方法依赖于束搜索来识别路径，并使用LLM进行评估，其中较长的处理时间通常会带来更好的结果。值得注意的是，我们提出的方法在性能上与BeamSearch相当或更优（表格[1](https://arxiv.org/html/2405.19119v3#S5.T1
    "表1 ‣ 5.2 无训练方法的性能 ‣ 5 实验与分析 ‣ 图学习能否改善基于LLM的规划？") 和表格[9](https://arxiv.org/html/2405.19119v3#A5.T9
    "表9 ‣ E.3 无训练方法的准确度结果 ‣ 附录E 无训练方法的补充材料 ‣ 图学习能否改善基于LLM的规划？")）同时需要的令牌数少了$5$-$10$倍（表格[1](https://arxiv.org/html/2405.19119v3#S5.T1
    "表1 ‣ 5.2 无训练方法的性能 ‣ 5 实验与分析 ‣ 图学习能否改善基于LLM的规划？")）以及推理时间（表格[10](https://arxiv.org/html/2405.19119v3#A5.T10
    "表10 ‣ E.4 计算成本分析 ‣ 附录E 无训练方法的补充材料 ‣ 图学习能否改善基于LLM的规划？")）。案例研究可在附录[H](https://arxiv.org/html/2405.19119v3#A8
    "附录H 案例研究 ‣ 图学习能否改善基于LLM的规划？")中找到。然而，我们观察到GPT-4-turbo仅有边际改善。GPT-4-turbo的一个独特特点是它能够管理ChatGPT插件，并且可能在任务规划数据集上接受了特别训练。此外，用于SGC特征提取的预训练语言模型是e5-335M，这可能不足以有效分析GPT-4的输出。有关涉及GPT-4的案例的详细诊断分析，请参见附录中的图[11](https://arxiv.org/html/2405.19119v3#A8.F11
    "图11 ‣ 附录H 案例研究 ‣ 图学习能否改善基于LLM的规划？")。
- en: 5.3 Performance of the Training-based Approaches
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 基于训练方法的性能
- en: 'Settings: We further explore the efficacy of training-based GNNs in three TaskBench
    datasets. The TMDB dataset is excluded due to its limited sample size. Throughout
    our experiments, we trained a spectrum of GNN variants, both with and without
    co-training the small LM (i.e., e5-335M), whose role is to generate node embeddings
    derived from task names and descriptions. Owing to space constraints, we only
    show the performance of GraphSAGE in the main text, relegating a detailed comparison
    of all the situations to Table [11](https://arxiv.org/html/2405.19119v3#A6.T11
    "Table 11 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") and Table [12](https://arxiv.org/html/2405.19119v3#A6.T12
    "Table 12 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") in Appendix.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 设置：我们进一步探讨了基于训练的 GNN 在三个 TaskBench 数据集中的有效性。由于 TMDB 数据集样本数量有限，因此被排除在外。在我们的实验中，我们训练了多种
    GNN 变体，既包括与小型语言模型（即 e5-335M）共同训练的情况，也包括未共同训练的情况，其中小型语言模型的作用是生成来自任务名称和描述的节点嵌入。由于篇幅限制，我们仅在正文中展示了
    GraphSAGE 的性能，所有情况的详细比较请参见附录中的表格 [11](https://arxiv.org/html/2405.19119v3#A6.T11
    "Table 11 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") 和表格 [12](https://arxiv.org/html/2405.19119v3#A6.T12 "Table
    12 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")。
- en: 'Compared Methods: Due to the lack of training-based baseline methods specifically
    for task planning, we adapt two existing approaches that combine LLMs and GNNs
    for graph-related tasks, including: (1) TAPE [[16](https://arxiv.org/html/2405.19119v3#bib.bib16)]
    employs a $\text{LLM}\rightarrow\text{LM}\rightarrow\text{GNN}$ architecture for
    node classification task. In this framework, LLMs generate high-quality explanatory
    text for each predicted node, which is then fine-tuned by an LM to produce node
    embeddings. Finally, a GNN performs the downstream classification. We adapt TAPE
    for task planning by reformulating the problem as classifying user requests into
    corresponding node labels within the task graph. (2) GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)]
    uses GNNs to tokenize graph nodes, which are then fed into LLMs to generate textual
    outputs. In our adaptation for task planning, we treat the user request as the
    input question and the expected plan as the generated answer. Additional implementation
    details are provided in the Appendix [F.2](https://arxiv.org/html/2405.19119v3#A6.SS2
    "F.2 Implementation of TAPE and GraphToken ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?").'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对比方法：由于缺乏专门用于任务规划的基准训练方法，我们借用了两种现有方法，这些方法结合了 LLM 和 GNN 用于图相关任务，包括：（1）TAPE [[16](https://arxiv.org/html/2405.19119v3#bib.bib16)]
    采用 $\text{LLM}\rightarrow\text{LM}\rightarrow\text{GNN}$ 架构进行节点分类任务。在该框架中，LLM
    生成每个预测节点的高质量解释性文本，接着通过 LM 对其进行微调，生成节点嵌入。最后，GNN 执行下游分类。我们通过将任务规划问题重新表述为将用户请求分类为任务图中的对应节点标签，将
    TAPE 适应于任务规划。（2）GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)]
    使用 GNN 对图节点进行标记化，然后将其输入 LLM 生成文本输出。在我们的任务规划适配中，我们将用户请求视为输入问题，期望的计划作为生成答案。附录 [F.2](https://arxiv.org/html/2405.19119v3#A6.SS2
    "F.2 Implementation of TAPE and GraphToken ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?") 提供了更多实现细节。
- en: 'Observations: From Table [2](https://arxiv.org/html/2405.19119v3#S5.T2 "Table
    2 ‣ 5.3 Performance of the Training-based Approaches ‣ 5 Experiments and Analysis
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?"), we observe a significant
    improvement in performance when employing a training-based GraphSAGE approach
    over the training-free method. However, the co-training of GNNs with e5-335M does
    not yield a marked improvement, suggesting that message passing is the crucial
    element for enhancing performance. Further analysis across a broad spectrum of
    GNNs (as shown in Table [11](https://arxiv.org/html/2405.19119v3#A6.T11 "Table
    11 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?") and Table [12](https://arxiv.org/html/2405.19119v3#A6.T12 "Table 12
    ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")) reveals that powerful GNNs, such as GINs, perform similarly to networks
    perceived as less complex, like GCNs, and even underperform compared to GraphSAGE.
    This pattern indicates that the task’s challenge may not lie in the expressiveness
    of the models but rather in their ability to generalize. Regarding baselines,
    TAPE is unsuitable for task planning as its classification approach simplifies
    task planning, overlooking task dependencies. While GraphToken demonstrates superior
    performance over LLMs’ direct inference, we have noted instances of minor hallucination.
    This observation suggests that GraphToken’s understanding of the task graph is
    not yet perfect. In addition, GraphToken is limited to open-sourced LLMs. Besides,
    our proposed approaches also greatly boost the parameter prediction performance,
    as given in Appendix [G](https://arxiv.org/html/2405.19119v3#A7 "Appendix G Experiments
    on Task Parameter Prediction ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?") (e.g. $9\%$ improvement to GPT-3.5-turbo and $3\%$ improvement to GPT-4-turbo).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：从表[2](https://arxiv.org/html/2405.19119v3#S5.T2 "表2 ‣ 5.3 基于训练的方法的性能 ‣ 5
    实验与分析 ‣ 图学习能否改善基于LLM的代理规划？")中，我们观察到，采用基于训练的GraphSAGE方法相比于无训练方法，性能显著提高。然而，GNN与e5-335M共同训练并未带来明显的性能提升，这表明消息传递是提升性能的关键因素。进一步的分析显示，广泛的GNN（如表[11](https://arxiv.org/html/2405.19119v3#A6.T11
    "表11 ‣ F.4 基于训练的GNN的完整结果 ‣ 附录F 基于训练的方法的补充材料 ‣ 图学习能否改善基于LLM的代理规划？")和表[12](https://arxiv.org/html/2405.19119v3#A6.T12
    "表12 ‣ F.4 基于训练的GNN的完整结果 ‣ 附录F 基于训练的方法的补充材料 ‣ 图学习能否改善基于LLM的代理规划？")所示）的分析表明，像GIN这样的强大GNN，其性能与被认为较简单的网络（如GCN）相似，甚至表现不如GraphSAGE。这一模式表明，任务的挑战可能不在于模型的表达能力，而在于它们的泛化能力。在基准测试方面，TAPE不适用于任务规划，因为其分类方法简化了任务规划，忽视了任务之间的依赖关系。尽管GraphToken在LLM的直接推理上表现出更优的性能，但我们也注意到有轻微的幻觉现象。这一观察表明，GraphToken对任务图的理解还不完美。此外，GraphToken仅限于开源的LLM。此外，我们提出的方法也大大提升了参数预测的性能，如附录[G](https://arxiv.org/html/2405.19119v3#A7
    "附录G 任务参数预测实验 ‣ 图学习能否改善基于LLM的代理规划？")中所示（例如，对GPT-3.5-turbo的$9\%$提升，以及对GPT-4-turbo的$3\%$提升）。
- en: 'Efficiency: The details of the training time are given in Table [13](https://arxiv.org/html/2405.19119v3#A6.T13
    "Table 13 ‣ F.6 Computational Cost Analysis ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?"). The training cost is remarkably low because we use e5-335M [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]
    as the text embedding model for GNNs. If the trainable parameters are limited
    to the GNNs alone, training typically concludes within just 3 minutes. Furthermore,
    the training duration extends to only 15 minutes when GNNs are jointly trained
    with e5-335M model. This efficiency stands in stark contrast to the 10-20 hours
    required for tuning open-sourced LLMs.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 效率：训练时间的具体细节见表[13](https://arxiv.org/html/2405.19119v3#A6.T13 "表13 ‣ F.6 计算成本分析
    ‣ 附录F 基于训练的方法的补充材料 ‣ 图学习能否改善基于LLM的代理规划？")。训练成本显著较低，因为我们使用e5-335M作为GNN的文本嵌入模型[[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]。如果可训练参数仅限于GNN，通常训练将在短短3分钟内完成。此外，当GNN与e5-335M模型共同训练时，训练时间也仅延长至15分钟。这种效率与调整开源LLM所需的10到20小时形成鲜明对比。
- en: 'Table 2: Comparison with Training-based Approaches: Node-F1, Link-F1, and Accuracy
    are reported in $\%$. TAPE [[16](https://arxiv.org/html/2405.19119v3#bib.bib16)]
    is designed for node classification task and cannot predict links, so we report
    Link-F1 as “NA”. GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)]
    requires finetuning LLMs, which is not compatible with close-sourced LLMs. The
    performance of other GNNs and LLMs are given in Table [11](https://arxiv.org/html/2405.19119v3#A6.T11
    "Table 11 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") and Table [12](https://arxiv.org/html/2405.19119v3#A6.T12
    "Table 12 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?") in the Appendix.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：与基于训练的方法比较：节点-F1、链接-F1 和准确率以百分比（$\%$）报告。TAPE [[16](https://arxiv.org/html/2405.19119v3#bib.bib16)]
    是为节点分类任务设计的，不能预测链接，因此我们报告链接-F1为“NA”。GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)]
    需要微调LLM，这与闭源LLM不兼容。其他GNN和LLM的性能见附录中的表 [11](https://arxiv.org/html/2405.19119v3#A6.T11
    "表 11 ‣ F.4 基于训练的GNN的完整结果 ‣ 附录F 基于训练的方法补充材料 ‣ 图学习能否改善LLM代理的规划？") 和表 [12](https://arxiv.org/html/2405.19119v3#A6.T12
    "表 12 ‣ F.4 基于训练的GNN的完整结果 ‣ 附录F 基于训练的方法补充材料 ‣ 图学习能否改善LLM代理的规划？")。
- en: '|  |  | HuggingFace | Multimedia | Daily Life |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  |  | HuggingFace | 多媒体 | 日常生活 |'
- en: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | Acc $\uparrow$ | n-F1
    $\uparrow$ | l-F1 $\uparrow$ | Acc $\uparrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$
    | Acc $\uparrow$ |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 准确率 $\uparrow$ | n-F1 $\uparrow$
    | l-F1 $\uparrow$ | 准确率 $\uparrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 准确率 $\uparrow$
    |'
- en: '| Vicuna-13B | Direct | 50.46 | 21.27 | 8.72 | 53.57 | 23.19 | 11.20 | 73.70
    | 45.80 | 24.43 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna-13B | 直接 | 50.46 | 21.27 | 8.72 | 53.57 | 23.19 | 11.20 | 73.70 |
    45.80 | 24.43 |'
- en: '| TAPE | 59.47 | NA | 5.07 | 54.97 | NA | 2.07 | 73.26 | NA | 12.50 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| TAPE | 59.47 | NA | 5.07 | 54.97 | NA | 2.07 | 73.26 | NA | 12.50 |'
- en: '| GraphToken | 63.37 | 31.54 | 15.61 | 65.40 | 36.38 | 19.87 | 81.65 | 48.29
    | 43.37 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| GraphToken | 63.37 | 31.54 | 15.61 | 65.40 | 36.38 | 19.87 | 81.65 | 48.29
    | 43.37 |'
- en: '| GraphSAGE | 61.86 | 35.68 | 20.08 | 63.71 | 39.88 | 21.37 | 86.07 | 67.63
    | 48.64 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 61.86 | 35.68 | 20.08 | 63.71 | 39.88 | 21.37 | 86.07 | 67.63
    | 48.64 |'
- en: '| GraphSAGE${}_{\text{co-train}}$ | 62.82 | 37.04 | 19.68 | 65.89 | 42.18 |
    21.58 | 84.23 | 65.44 | 47.81 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE${}_{\text{co-train}}$ | 62.82 | 37.04 | 19.68 | 65.89 | 42.18 |
    21.58 | 84.23 | 65.44 | 47.81 |'
- en: '| Mistral-7B | Direct | 60.60 | 30.23 | 16.36 | 69.83 | 39.85 | 25.05 | 84.26
    | 53.63 | 44.52 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| Mistral-7B | 直接 | 60.60 | 30.23 | 16.36 | 69.83 | 39.85 | 25.05 | 84.26 |
    53.63 | 44.52 |'
- en: '| TAPE | 61.82 | NA | 6.13 | 58.92 | NA | 3.29 | 76.40 | NA | 16.44 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| TAPE | 61.82 | NA | 6.13 | 58.92 | NA | 3.29 | 76.40 | NA | 16.44 |'
- en: '| GraphToken | 64.42 | 32.04 | 18.60 | 72.31 | 42.60 | 30.31 | 86.82 | 57.06
    | 53.99 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| GraphToken | 64.42 | 32.04 | 18.60 | 72.31 | 42.60 | 30.31 | 86.82 | 57.06
    | 53.99 |'
- en: '| GraphSAGE | 68.12 | 43.09 | 25.77 | 75.51 | 52.94 | 34.29 | 87.51 | 66.57
    | 52.74 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 68.12 | 43.09 | 25.77 | 75.51 | 52.94 | 34.29 | 87.51 | 66.57
    | 52.74 |'
- en: '| GraphSAGE${}_{\text{co-train}}$ | 67.61 | 43.14 | 27.20 | 76.96 | 55.46 |
    33.26 | 87.61 | 66.75 | 52.97 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE${}_{\text{co-train}}$ | 67.61 | 43.14 | 27.20 | 76.96 | 55.46 |
    33.26 | 87.61 | 66.75 | 52.97 |'
- en: '| CodeLlama-13B | Direct | 57.55 | 28.88 | 14.29 | 68.57 | 41.79 | 24.10 |
    91.20 | 76.07 | 66.40 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-13B | 直接 | 57.55 | 28.88 | 14.29 | 68.57 | 41.79 | 24.10 | 91.20
    | 76.07 | 66.40 |'
- en: '| TAPE | 64.03 | NA | 8.05 | 58.27 | NA | 2.01 | 77.74 | NA | 17.37 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| TAPE | 64.03 | NA | 8.05 | 58.27 | NA | 2.01 | 77.74 | NA | 17.37 |'
- en: '| GraphToken | 62.15 | 32.55 | 20.08 | 74.57 | 47.60 | 35.06 | 92.50 | 73.57
    | 69.42 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| GraphToken | 62.15 | 32.55 | 20.08 | 74.57 | 47.60 | 35.06 | 92.50 | 73.57
    | 69.42 |'
- en: '| GraphSAGE | 67.30 | 42.41 | 26.56 | 74.93 | 54.52 | 38.55 | 93.84 | 80.38
    | 73.60 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 67.30 | 42.41 | 26.56 | 74.93 | 54.52 | 38.55 | 93.84 | 80.38
    | 73.60 |'
- en: '| GraphSAGE${}_{\text{co-train}}$ | 68.92 | 44.85 | 29.58 | 76.28 | 55.41 |
    37.75 | 93.30 | 79.51 | 74.00 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE${}_{\text{co-train}}$ | 68.92 | 44.85 | 29.58 | 76.28 | 55.41 |
    37.75 | 93.30 | 79.51 | 74.00 |'
- en: '|  | Direct | 73.85 | 45.73 | 28.95 | 82.85 | 62.07 | 47.96 | 96.09 | 83.65
    | 81.30 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接 | 73.85 | 45.73 | 28.95 | 82.85 | 62.07 | 47.96 | 96.09 | 83.65 | 81.30
    |'
- en: '|  | TAPE | 68.00 | NA | 8.83 | 62.43 | NA | 3.87 | 70.67 | NA | 8.92 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|  | TAPE | 68.00 | NA | 8.83 | 62.43 | NA | 3.87 | 70.67 | NA | 8.92 |'
- en: '| GPT-3.5-turbo | GraphSAGE | 77.90 | 52.68 | 35.11 | 85.29 | 65.80 | 53.55
    | 96.43 | 86.26 | 83.13 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | GraphSAGE | 77.90 | 52.68 | 35.11 | 85.29 | 65.80 | 53.55
    | 96.43 | 86.26 | 83.13 |'
- en: '|  | GraphSAGE${}_{\text{co-train}}$ | 77.87 | 53.04 | 35.32 | 85.51 | 66.56
    | 55.91 | 96.34 | 86.09 | 83.13 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphSAGE${}_{\text{co-train}}$ | 77.87 | 53.04 | 35.32 | 85.51 | 66.56
    | 55.91 | 96.34 | 86.09 | 83.13 |'
- en: '|  | Direct | 77.60 | 52.18 | 33.68 | 88.29 | 69.38 | 60.56 | 97.36 | 84.58
    | 86.77 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接 | 77.60 | 52.18 | 33.68 | 88.29 | 69.38 | 60.56 | 97.36 | 84.58 | 86.77
    |'
- en: '|  | TAPE | 68.82 | NA | 9.50 | 63.94 | NA | 4.02 | 71.51 | NA | 9.40 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|  | TAPE | 68.82 | NA | 9.50 | 63.94 | NA | 4.02 | 71.51 | NA | 9.40 |'
- en: '| GPT-4-turbo | GraphSAGE | 78.76 | 52.53 | 34.09 | 88.63 | 69.65 | 60.36 |
    97.34 | 85.67 | 86.97 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-turbo | GraphSAGE | 78.76 | 52.53 | 34.09 | 88.63 | 69.65 | 60.36 |
    97.34 | 85.67 | 86.97 |'
- en: '|  | GraphSAGE${}_{\text{co-train}}$ | 78.49 | 52.62 | 33.88 | 88.86 | 70.25
    | 62.37 | 97.42 | 85.80 | 86.57 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphSAGE${}_{\text{co-train}}$ | 78.49 | 52.62 | 33.88 | 88.86 | 70.25
    | 62.37 | 97.42 | 85.80 | 86.57 |'
- en: 'Table 3: Performance Comparison of SGC and GraphSAGE on the UltraTool Benchmark
    [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)]. Integrating GNNs can lead
    to more significant improvements in LLMs on larger task graphs.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：SGC和GraphSAGE在UltraTool基准测试中的性能比较 [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)]。集成GNN可以在更大的任务图上显著提高LLM的性能。
- en: '|  |  | 0-shot | 1-shot |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 0-shot | 1-shot |'
- en: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | Acc $\uparrow$ | # Tok
    $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | Acc $\uparrow$ | # Tok $\downarrow$
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 准确率 $\uparrow$ | Token数 $\downarrow$
    | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 准确率 $\uparrow$ | Token数 $\downarrow$ |'
- en: '|  | Direct | 38.88 | 16.42 | 13.58 | 10,535 | 57.64 | 30.44 | 26.25 | 10,737
    |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接方法 | 38.88 | 16.42 | 13.58 | 10,535 | 57.64 | 30.44 | 26.25 | 10,737
    |'
- en: '|  | BeamSearch | 49.71 | 22.51 | 17.08 | 26,008 | 64.93 | 36.23 | 33.47 |
    23,023 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  | BeamSearch | 49.71 | 22.51 | 17.08 | 26,008 | 64.93 | 36.23 | 33.47 |
    23,023 |'
- en: '|  | SGC | 61.07 | 37.61 | 25.31 | 10,456 | 71.64 | 44.00 | 39.68 | 10,658
    |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '|  | SGC | 61.07 | 37.61 | 25.31 | 10,456 | 71.64 | 44.00 | 39.68 | 10,658
    |'
- en: '| CodeLlama-13B | GraphSAGE | 63.78 | 39.91 | 27.98 | 10,456 | 72.81 | 45.26
    | 43.49 | 10,658 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-13B | GraphSAGE | 63.78 | 39.91 | 27.98 | 10,456 | 72.81 | 45.26
    | 43.49 | 10,658 |'
- en: '|  | Direct | 54.35 | 21.35 | 18.33 | 8,462 | 63.58 | 30.85 | 25.00 | 8,614
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接方法 | 54.35 | 21.35 | 18.33 | 8,462 | 63.58 | 30.85 | 25.00 | 8,614 |'
- en: '|  | BeamSearch | 55.40 | 28.02 | 19.76 | 21,979 | 63.41 | 34.05 | 26.28 |
    20,813 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | BeamSearch | 55.40 | 28.02 | 19.76 | 21,979 | 63.41 | 34.05 | 26.28 |
    20,813 |'
- en: '|  | SGC | 59.80 | 37.82 | 25.87 | 8,352 | 64.96 | 37.96 | 29.70 | 8,504 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | SGC | 59.80 | 37.82 | 25.87 | 8,352 | 64.96 | 37.96 | 29.70 | 8,504 |'
- en: '| GPT-3.5-turbo | GraphSAGE | 63.97 | 42.26 | 30.35 | 8,352 | 70.49 | 47.79
    | 39.74 | 8,504 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | GraphSAGE | 63.97 | 42.26 | 30.35 | 8,352 | 70.49 | 47.79
    | 39.74 | 8,504 |'
- en: '|  | Direct | 68.63 | 40.01 | 27.20 | 8,513 | 69.54 | 41.79 | 28.17 | 8,693
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接方法 | 68.63 | 40.01 | 27.20 | 8,513 | 69.54 | 41.79 | 28.17 | 8,693 |'
- en: '|  | BeamSearch | 71.29 | 43.99 | 30.40 | 18,793 | 71.99 | 44.54 | 31.62 |
    20,515 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  | BeamSearch | 71.29 | 43.99 | 30.40 | 18,793 | 71.99 | 44.54 | 31.62 |
    20,515 |'
- en: '|  | SGC | 70.87 | 44.01 | 31.60 | 8,346 | 70.46 | 44.82 | 33.00 | 8,504 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|  | SGC | 70.87 | 44.01 | 31.60 | 8,346 | 70.46 | 44.82 | 33.00 | 8,504 |'
- en: '| GPT-4-turbo | GraphSAGE | 70.67 | 43.83 | 34.40 | 8,346 | 70.75 | 47.68 |
    37.22 | 8,504 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-turbo | GraphSAGE | 70.67 | 43.83 | 34.40 | 8,346 | 70.75 | 47.68 |
    37.22 | 8,504 |'
- en: 5.4 Scaling to Large Task Graphs
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 扩展到大型任务图
- en: To demonstrate the scalability of our method to larger task graphs, we conducted
    a supplementary experiment on the newly released planning benchmark UltraTool
    [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)], which features a relatively
    large task graph with $260$ nodes. Details on processing this dataset are provided
    in Appendix [C.3](https://arxiv.org/html/2405.19119v3#A3.SS3 "C.3 Reformatting
    Details of UltraTool ‣ Appendix C Datasets ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?"). We present a performance comparison of GNN models (training-free
    SGC and training-required GraphSAGE) against strong baselines like BeamSearch
    in Table [3](https://arxiv.org/html/2405.19119v3#S5.T3 "Table 3 ‣ 5.3 Performance
    of the Training-based Approaches ‣ 5 Experiments and Analysis ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?"). Among the metrics, accuracy (Acc) is
    calculated based on whether the predicted tasks match the ground-truth tasks,
    measuring the success rate at each case level. In such conditions, integrating
    a GNN significantly enhances performance and mitigates planning failures, e.g.,
    GPT-4-turbo undergoes a 9.05% accuracy improvement with the introduction of GraphSAGE.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们的方法在更大任务图上的可扩展性，我们在新发布的规划基准测试UltraTool上进行了补充实验 [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)]，该基准测试包含一个相对较大的任务图，具有$260$个节点。关于处理该数据集的详细信息，请参见附录[C.3](https://arxiv.org/html/2405.19119v3#A3.SS3
    "C.3 Reformatting Details of UltraTool ‣ Appendix C Datasets ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")。我们在表[3](https://arxiv.org/html/2405.19119v3#S5.T3
    "Table 3 ‣ 5.3 Performance of the Training-based Approaches ‣ 5 Experiments and
    Analysis ‣ Can Graph Learning Improve Planning in LLM-based Agents?")中展示了GNN模型（无需训练的SGC和需要训练的GraphSAGE）与强基准模型如BeamSearch的性能比较。在这些指标中，准确率（Acc）是根据预测任务与真实任务的匹配程度计算的，用来衡量每个案例级别的成功率。在这种情况下，集成GNN显著提高了性能并减少了规划失败，例如，引入GraphSAGE后，GPT-4-turbo的准确率提高了9.05%。
- en: The results indicate that (1) LLMs’ performance is vulnerable to the scale of
    task graphs; (2) The performance gain of the proposed method increases with a
    larger task graph.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，(1) LLMs 的性能易受任务图规模的影响；(2) 所提方法的性能提升随着任务图规模的增大而增加。
- en: '![Refer to caption](img/d3b58e19d996e43cb4d1c2e73c868a8c.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d3b58e19d996e43cb4d1c2e73c868a8c.png)'
- en: (a) Different Prompts
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 不同的提示
- en: '![Refer to caption](img/a219ad8df523f8df81623f0e366a16c2.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a219ad8df523f8df81623f0e366a16c2.png)'
- en: (b) Fine-tuned LLMs
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 微调后的 LLMs
- en: 'Figure 3: Orthogonal Effectiveness to both Improved Prompts and Fine-tuned
    LLMs'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：对改进提示和微调 LLMs 的正交有效性
- en: 5.5 Improved Prompts and Fine-tuned LLMs
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 改进的提示和微调后的 LLMs
- en: In this subsection, we show that the proposed method is orthogonal to two dominant
    methods, i.e., prompt engineering and fine-tuning.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们展示了所提方法与两种主流方法（即提示工程和微调）是正交的。
- en: 'Orthogonal to Improved Prompts: We investigate GNN’s effectiveness when applied
    to improved prompt templates, i.e., strategically designed prompts that enhance
    the task planning abilities of LLMs. Specifically, we consider two types of prompts:
    (1) In-context Learning with Increased Examples [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]
    During main experiments, we maintain the consistent 1-shot in-context learning
    example for LLM’s direct inference. To realize further improvements, we increase
    the number of examples to $2$, and results under this setting are denoted as “2-shot
    Prompt”; (2) Plan like a Graph (PlaG) [[30](https://arxiv.org/html/2405.19119v3#bib.bib30)]
    We adopt the prompt in [[30](https://arxiv.org/html/2405.19119v3#bib.bib30)] to
    encourage LLM to think and plan in a graph-like manner. Specifically, we convert
    the entire task graph into plain text and then integrate PlaG instructions to
    enhance LLM’s planning. Results under this prompt template are denoted as “PlaG
    Prompt”.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 对改进提示的正交性：我们研究了将 GNN 应用于改进提示模板时的有效性，即通过战略性设计的提示，提升 LLMs 的任务规划能力。具体来说，我们考虑了两种类型的提示：
    (1) 增加示例的上下文学习 [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)] 在主要实验中，我们保持一致的
    1-shot 上下文学习示例用于 LLMs 的直接推理。为了实现进一步的改进，我们将示例数量增加到 $2$，在这种设置下的结果被标记为“2-shot 提示”；(2)
    像图一样进行规划（PlaG）[[30](https://arxiv.org/html/2405.19119v3#bib.bib30)] 我们采用 [[30](https://arxiv.org/html/2405.19119v3#bib.bib30)]
    中的提示来鼓励 LLM 以图形化的方式思考和规划。具体来说，我们将整个任务图转换为普通文本，然后集成 PlaG 指令来增强 LLM 的规划能力。在此提示模板下的结果被标记为“PlaG
    提示”。
- en: From the results shown in Figure [3(a)](https://arxiv.org/html/2405.19119v3#S5.F3.sf1
    "In Figure 3 ‣ 5.4 Scaling to Large Task Graphs ‣ 5 Experiments and Analysis ‣
    Can Graph Learning Improve Planning in LLM-based Agents?"), where we apply three
    different prompts to CodeLlama-13B and Mistral-7B on HuggingFace, it is clear
    that applying GraphSAGE to improved prompts, where task steps are more concisely
    decomposed and predictions are more accurate, can also boost performance.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 [3(a)](https://arxiv.org/html/2405.19119v3#S5.F3.sf1 "图 3 ‣ 5.4 扩展到大规模任务图
    ‣ 5 实验与分析 ‣ 图学习能否改善基于 LLM 的代理的规划能力？") 中的结果可以看出，当我们将三种不同的提示应用于 HuggingFace 上的 CodeLlama-13B
    和 Mistral-7B 时，显然将 GraphSAGE 应用于改进后的提示，任务步骤更简洁地分解且预测更为准确，也能提升性能。
- en: 'Orthogonal to LLMs’ Fine-tuning: To explore whether our framework maintains
    effectiveness on fine-tuned LLMs, which have acquired dataset-specific task planning
    capabilities, we conduct further experiments. For each dataset, we use LoRA [[19](https://arxiv.org/html/2405.19119v3#bib.bib19)]
    to fine-tune two LLMs of different parameter scales, including CodeLlama-7B and
    Vicuna-13B, based on the same training data as GNNs. Details of fine-tuning process
    are provided in Appendix [F.3](https://arxiv.org/html/2405.19119v3#A6.SS3 "F.3
    Implementation of Fine-tuning LLMs ‣ Appendix F Supplementary Materials for Training-based
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?"). The finetuned
    model is named as “FT-CodeLlama” and “FT-Vicuna” in Figure [3(b)](https://arxiv.org/html/2405.19119v3#S5.F3.sf2
    "In Figure 3 ‣ 5.4 Scaling to Large Task Graphs ‣ 5 Experiments and Analysis ‣
    Can Graph Learning Improve Planning in LLM-based Agents?").'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 与LLM微调的正交关系：为了探讨我们的框架在微调后的LLM上是否仍然有效，这些LLM已经具备了特定数据集的任务规划能力，我们进行了进一步的实验。对于每个数据集，我们使用LoRA
    [[19](https://arxiv.org/html/2405.19119v3#bib.bib19)] 对两种不同参数规模的LLM进行微调，包括CodeLlama-7B和Vicuna-13B，微调所用的训练数据与GNNs相同。微调过程的详细信息见附录
    [F.3](https://arxiv.org/html/2405.19119v3#A6.SS3 "F.3 LLM微调实现 ‣ 附录 F 训练方法的补充材料
    ‣ 图学习能否改善基于LLM的代理的规划？")。微调后的模型在图 [3(b)](https://arxiv.org/html/2405.19119v3#S5.F3.sf2
    "在图 3 ‣ 5.4 扩展到大型任务图 ‣ 5 实验与分析 ‣ 图学习能否改善基于LLM的代理的规划？") 中分别被命名为“FT-CodeLlama”和“FT-Vicuna”。
- en: The results depicted in Figure [3(b)](https://arxiv.org/html/2405.19119v3#S5.F3.sf2
    "In Figure 3 ‣ 5.4 Scaling to Large Task Graphs ‣ 5 Experiments and Analysis ‣
    Can Graph Learning Improve Planning in LLM-based Agents?") demonstrate that fine-tuning
    markedly enhances the task-planning capabilities of LLMs. Furthermore, applying
    GraphSAGE to the decomposed tasks of LLMs further improves the accuracy of task
    planning.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [3(b)](https://arxiv.org/html/2405.19119v3#S5.F3.sf2 "在图 3 ‣ 5.4 扩展到大型任务图
    ‣ 5 实验与分析 ‣ 图学习能否改善基于LLM的代理的规划？") 中展示的结果表明，微调显著增强了LLM的任务规划能力。此外，将GraphSAGE应用于LLM分解的任务进一步提高了任务规划的准确性。
- en: 6 Conclusions
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: This paper presents an initial exploration into graph-learning-based approaches
    for task planning in language agents. Through theoretical analysis, we demonstrate
    the inductive bias of the attention mechanism and the utility of auto-regressive
    loss impedes their effectiveness in task planning. We propose to integrate GNNs
    for task graph analysis, which yields performance improvements across a range
    of LLMs and planning benchmarks.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了基于图学习的方法在语言代理任务规划中的初步探索。通过理论分析，我们展示了注意力机制的归纳偏向以及自回归损失的效用，这些因素在任务规划中影响了它们的有效性。我们提出将图神经网络（GNNs）集成到任务图分析中，这在多个LLM和规划基准上提升了性能。
- en: 'Limitations: Despite the encouraging performance, there are limitations that
    highlight significant opportunities for enhancement. Firstly, our proposed method,
    while effective, is straightforward; more sophisticated graph-learning-based decision-making
    algorithms could potentially offer further improvements. Secondly, the construction
    of the task graph currently requires manual effort. Investigating automated graph
    generation techniques for diverse applications is another promising direction
    for future work.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 局限性：尽管结果令人鼓舞，但仍然存在一些局限性，显示出显著的改进机会。首先，我们提出的方法虽然有效，但较为简单；更复杂的基于图学习的决策算法可能提供进一步的改进。其次，任务图的构建目前仍需人工操作。研究多样化应用的自动图生成技术是未来工作中的一个有前景的方向。
- en: Acknowledgements
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is partly supported by grant from the Research Grants Council of the
    Hong Kong Special Administrative Region, China (No. CUHK 14217622).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分得到中国香港特别行政区研究资助局（编号：CUHK 14217622）资助。
- en: References
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Barto et al. [1995] Andrew G Barto, Steven J Bradtke, and Satinder P Singh.
    Learning to act using real-time dynamic programming. *Artificial intelligence*,
    72(1-2):81–138, 1995.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barto 等人 [1995] Andrew G Barto, Steven J Bradtke, 和 Satinder P Singh. 使用实时动态规划学习行动。*人工智能*，72(1-2)：81–138，1995年。
- en: Behrens et al. [2018] Timothy EJ Behrens, Timothy H Muller, James CR Whittington,
    Shirley Mark, Alon B Baram, Kimberly L Stachenfeld, and Zeb Kurth-Nelson. What
    is a cognitive map? organizing knowledge for flexible behavior. *Neuron*, 100(2):490–509,
    2018.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Behrens 等人 [2018] Timothy EJ Behrens, Timothy H Muller, James CR Whittington,
    Shirley Mark, Alon B Baram, Kimberly L Stachenfeld, 和 Zeb Kurth-Nelson. 什么是认知地图？组织知识以便灵活的行为。*Neuron*，100(2)：490–509，2018年。
- en: Bellman [1966] Richard Bellman. Dynamic programming. *science*, 153(3731):34–37,
    1966.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bellman [1966] Richard Bellman。动态规划。*科学*，153(3731):34–37，1966年。
- en: 'Besta et al. [2024] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger,
    Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski,
    Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large
    language models. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    volume 38, pp.  17682–17690, 2024.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Besta 等 [2024] Maciej Besta、Nils Blach、Ales Kubicek、Robert Gerstenberger、Michal
    Podstawski、Lukas Gianinazzi、Joanna Gajda、Tomasz Lehmann、Hubert Niewiadomski、Piotr
    Nyczyk 等。思维图：使用大型语言模型解决复杂问题。发表于 *人工智能协会会议论文集*，第38卷，第17682–17690页，2024年。
- en: Boiko et al. [2023] Daniil A Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes.
    Autonomous chemical research with large language models. *Nature*, 624(7992):570–578,
    2023.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boiko 等 [2023] Daniil A Boiko、Robert MacKnight、Ben Kline 和 Gabe Gomes。使用大型语言模型进行自主化学研究。*自然*，624(7992):570–578，2023年。
- en: 'Bonet & Geffner [2003] Blai Bonet and Hector Geffner. Labeled rtdp: Improving
    the convergence of real-time dynamic programming. In *ICAPS*, volume 3, pp.  12–21,
    2003.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bonet & Geffner [2003] Blai Bonet 和 Hector Geffner。标记化 RTDP：改进实时动态规划的收敛性。发表于
    *ICAPS*，第3卷，第12–21页，2003年。
- en: 'Bubeck et al. [2023] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
    Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
    et al. Sparks of artificial general intelligence: Early experiments with gpt-4.
    *arXiv preprint arXiv:2303.12712*, 2023.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bubeck 等 [2023] Sébastien Bubeck、Varun Chandrasekaran、Ronen Eldan、Johannes Gehrke、Eric
    Horvitz、Ece Kamar、Peter Lee、Yin Tat Lee、Yuanzhi Li、Scott Lundberg 等。人工通用智能的火花：与
    GPT-4 的早期实验。*arXiv 预印本 arXiv:2303.12712*，2023年。
- en: Cappart et al. [2023] Quentin Cappart, Didier Chételat, Elias B Khalil, Andrea
    Lodi, Christopher Morris, and Petar Veličković. Combinatorial optimization and
    reasoning with graph neural networks. *Journal of Machine Learning Research*,
    24(130):1–61, 2023.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cappart 等 [2023] Quentin Cappart、Didier Chételat、Elias B Khalil、Andrea Lodi、Christopher
    Morris 和 Petar Veličković。图神经网络的组合优化与推理。*机器学习研究杂志*，24(130):1–61，2023年。
- en: 'Chai et al. [2023] Ziwei Chai, Tianjie Zhang, Liang Wu, Kaiqiao Han, Xiaohai
    Hu, Xuanwen Huang, and Yang Yang. GraphLLM: Boosting graph reasoning ability of
    large language model. *arXiv preprint arXiv:2310.05845*, 2023.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chai 等 [2023] Ziwei Chai、Tianjie Zhang、Liang Wu、Kaiqiao Han、Xiaohai Hu、Xuanwen
    Huang 和 Yang Yang。GraphLLM：提升大型语言模型的图推理能力。*arXiv 预印本 arXiv:2310.05845*，2023年。
- en: Chen et al. [2024] Dillon Z Chen, Sylvie Thiébaux, and Felipe Trevizan. Learning
    domain-independent heuristics for grounded and lifted planning. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, volume 38, pp.  20078–20086,
    2024.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 [2024] Dillon Z Chen、Sylvie Thiébaux 和 Felipe Trevizan。为基础和提升规划学习领域无关的启发式方法。发表于
    *人工智能协会会议论文集*，第38卷，第20078–20086页，2024年。
- en: Dudzik & Veličković [2022] Andrew J Dudzik and Petar Veličković. Graph neural
    networks are dynamic programmers. *Advances in neural information processing systems*,
    35:20635–20647, 2022.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dudzik & Veličković [2022] Andrew J Dudzik 和 Petar Veličković。图神经网络是动态编程者。*神经信息处理系统进展*，35:20635–20647，2022年。
- en: 'Feng et al. [2024] Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di He,
    and Liwei Wang. Towards revealing the mystery behind chain of thought: a theoretical
    perspective. *Advances in Neural Information Processing Systems*, 36, 2024.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng 等 [2024] Guhao Feng、Bohang Zhang、Yuntian Gu、Haotian Ye、Di He 和 Liwei Wang。揭示思维链背后的奥秘：一种理论视角。*神经信息处理系统进展*，36，2024年。
- en: Gasse et al. [2019] Maxime Gasse, Didier Chételat, Nicola Ferroni, Laurent Charlin,
    and Andrea Lodi. Exact combinatorial optimization with graph convolutional neural
    networks. *Advances in neural information processing systems*, 32, 2019.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gasse 等 [2019] Maxime Gasse、Didier Chételat、Nicola Ferroni、Laurent Charlin 和
    Andrea Lodi。使用图卷积神经网络进行精确的组合优化。*神经信息处理系统进展*，32，2019年。
- en: 'Guo et al. [2023] Jiayan Guo, Lun Du, and Hengyu Liu. Gpt4graph: Can large
    language models understand graph structured data? an empirical evaluation and
    benchmarking. *arXiv preprint arXiv:2305.15066*, 2023.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等 [2023] Jiayan Guo、Lun Du 和 Hengyu Liu。Gpt4graph：大型语言模型能否理解图结构数据？一项经验评估与基准测试。*arXiv
    预印本 arXiv:2305.15066*，2023年。
- en: Hamilton et al. [2017] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive
    representation learning on large graphs. In *NIPS*, 2017.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hamilton 等 [2017] William L. Hamilton、Rex Ying 和 Jure Leskovec。大规模图上的归纳表示学习。发表于
    *NIPS*，2017年。
- en: 'He et al. [2023] Xiaoxin He, Xavier Bresson, Thomas Laurent, Adam Perold, Yann
    LeCun, and Bryan Hooi. Harnessing explanations: Llm-to-lm interpreter for enhanced
    text-attributed graph representation learning, 2023.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He et al. [2023] Xiaoxin He, Xavier Bresson, Thomas Laurent, Adam Perold, Yann
    LeCun, 和 Bryan Hooi. 利用解释：用于增强文本属性图表示学习的 Llm-to-lm 解释器，2023。
- en: 'He et al. [2024] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V Chawla, Thomas
    Laurent, Yann LeCun, Xavier Bresson, and Bryan Hooi. G-retriever: Retrieval-augmented
    generation for textual graph understanding and question answering. *arXiv preprint
    arXiv:2402.07630*, 2024.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'He et al. [2024] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V Chawla, Thomas
    Laurent, Yann LeCun, Xavier Bresson, 和 Bryan Hooi. G-retriever: 用于文本图理解和问答的检索增强生成方法.
    *arXiv 预印本 arXiv:2402.07630*, 2024.'
- en: 'Helmert & Domshlak [2009] Malte Helmert and Carmel Domshlak. Landmarks, critical
    paths and abstractions: what’s the difference anyway? In *Proceedings of the International
    Conference on Automated Planning and Scheduling*, volume 19, pp.  162–169, 2009.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Helmert & Domshlak [2009] Malte Helmert 和 Carmel Domshlak. 地标、关键路径和抽象：它们之间有什么区别？在
    *国际自动规划与调度会议论文集* 中，卷 19，第 162–169 页，2009。
- en: 'Hu et al. [2021] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language
    models. *ArXiv*, abs/2106.09685, 2021.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. [2021] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
    Yuanzhi Li, Shean Wang, 和 Weizhu Chen. Lora：大规模语言模型的低秩适配. *ArXiv*, abs/2106.09685,
    2021.
- en: 'Huang et al. [2024a] Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui
    Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang,
    Ruifeng Xu, and Qun Liu. Planning, creation, usage: Benchmarking llms for comprehensive
    tool utilization in real-world complex scenarios, 2024a.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2024a] Shijue Huang, Wanjun Zhong, Jianqiao Lu, Qi Zhu, Jiahui
    Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang,
    Ruifeng Xu, 和 Qun Liu. 规划、创建、使用：在现实世界复杂场景中对大规模语言模型进行全面工具使用基准测试，2024a。
- en: 'Huang et al. [2022] Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.
    Language models as zero-shot planners: Extracting actionable knowledge for embodied
    agents. In *International Conference on Machine Learning*, pp.  9118–9147\. PMLR,
    2022.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2022] Wenlong Huang, Pieter Abbeel, Deepak Pathak, 和 Igor Mordatch.
    语言模型作为零-shot 规划者：为具身智能体提取可执行知识. 在 *国际机器学习会议* 中，第 9118–9147 页。PMLR, 2022。
- en: 'Huang et al. [2024b] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao
    Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and Enhong Chen. Understanding the
    planning of llm agents: A survey. *arXiv preprint arXiv:2402.02716*, 2024b.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang et al. [2024b] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao
    Wang, Defu Lian, Yasheng Wang, Ruiming Tang, 和 Enhong Chen. 理解 LLM 智能体的规划：一项调查.
    *arXiv 预印本 arXiv:2402.02716*, 2024b。
- en: Jiang et al. [2023] Albert Qiaochu Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, L’elio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. Mistral 7b. *ArXiv*, abs/2310.06825, 2023.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang et al. [2023] Albert Qiaochu Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, L’elio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, 和
    William El Sayed. Mistral 7b. *ArXiv*, abs/2310.06825, 2023.
- en: Khalil et al. [2017] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and
    Le Song. Learning combinatorial optimization algorithms over graphs. *Advances
    in neural information processing systems*, 30, 2017.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khalil et al. [2017] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, 和
    Le Song. 学习图上的组合优化算法. *神经信息处理系统进展*, 30, 2017.
- en: 'Kingma & Ba [2014] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic
    optimization. *CoRR*, abs/1412.6980, 2014.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma & Ba [2014] Diederik P. Kingma 和 Jimmy Ba. Adam：一种随机优化方法. *CoRR*, abs/1412.6980,
    2014.
- en: Kipf & Welling [2017] Thomas N. Kipf and Max Welling. Semi-supervised classification
    with graph convolutional networks. In *International Conference on Learning Representations
    (ICLR)*, 2017.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kipf & Welling [2017] Thomas N. Kipf 和 Max Welling. 使用图卷积网络进行半监督分类. 在 *国际学习表征会议（ICLR）*
    中，2017。
- en: 'Li et al. [2023] Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong
    Cheng, and Jeffrey Xu Yu. A survey of graph meets large language model: Progress
    and future directions. *arXiv preprint arXiv:2311.12399*, 2023.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. [2023] Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong
    Cheng, 和 Jeffrey Xu Yu. 图与大规模语言模型的交汇：进展与未来方向的调查. *arXiv 预印本 arXiv:2311.12399*,
    2023。
- en: 'Li et al. [2024] Yuhan Li, Peisong Wang, Zhixun Li, Jeffrey Xu Yu, and Jia
    Li. Zerog: Investigating cross-dataset zero-shot transferability in graphs. *arXiv
    preprint arXiv:2402.11235*, 2024.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2024] 李宇涵、王佩松、李志勋、徐宇杰、李佳。Zerog：研究图结构中跨数据集零样本迁移能力。*arXiv 预印本 arXiv:2402.11235*,
    2024。
- en: Li et al. [2018] Zhuwen Li, Qifeng Chen, and Vladlen Koltun. Combinatorial optimization
    with graph convolutional networks and guided tree search. *Advances in neural
    information processing systems*, 31, 2018.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人 [2018] 李朱文、陈其锋、弗拉德伦·科尔顿。使用图卷积网络与引导树搜索进行组合优化。*神经信息处理系统进展*, 31, 2018。
- en: Lin et al. [2024] Fangru Lin, Emanuele La Malfa, Valentin Hofmann, Elle Michelle
    Yang, Anthony Cohn, and Janet B. Pierrehumbert. Graph-enhanced large language
    models in asynchronous plan reasoning. *ArXiv*, abs/2402.02805, 2024.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人 [2024] 林方如、埃马纽埃尔·拉·马尔法、瓦伦丁·霍夫曼、杨米歇尔·艾尔、安东尼·科恩、珍妮特·B·皮耶雷亨伯特。异步计划推理中的图增强大型语言模型。*ArXiv*,
    abs/2402.02805, 2024。
- en: 'Liu et al. [2023a] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang,
    Joydeep Biswas, and Peter Stone. Llm+ p: Empowering large language models with
    optimal planning proficiency. *arXiv preprint arXiv:2304.11477*, 2023a.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2023a] 刘博、蒋雨茜、张小寒、刘强、张诗琪、比斯瓦斯·乔伊深、彼得·斯通。LLM+ p：提升大型语言模型的最佳规划能力。*arXiv
    预印本 arXiv:2304.11477*, 2023a。
- en: 'Liu et al. [2024] Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang,
    Yuchen Liu, and Dongkuan Xu. Toolnet: Connecting large language models with massive
    tools via tool graph. *ArXiv*, abs/2403.00839, 2024.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2024] 刘旭坤、彭志远、易晓源、谢星、向立荣、刘宇晨、徐东宽。Toolnet：通过工具图将大型语言模型与海量工具连接。*ArXiv*,
    abs/2403.00839, 2024。
- en: 'Liu et al. [2023b] Zhaoyang Liu, Zeqiang Lai, Zhangwei Gao, Erfei Cui, Xizhou
    Zhu, Lewei Lu, Qifeng Chen, Yu Qiao, Jifeng Dai, and Wenhai Wang. Controlllm:
    Augment language models with tools by searching on graphs. *ArXiv*, abs/2310.17796,
    2023b.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 [2023b] 刘赵阳、赖泽强、高张伟、崔二飞、朱希舟、卢乐伟、陈其锋、乔宇、戴吉丰、王文海。Controlllm：通过图搜索增强语言模型与工具的结合。*ArXiv*,
    abs/2310.17796, 2023b。
- en: 'Luo et al. [2024] Zihan Luo, Xiran Song, Hong Huang, Jianxun Lian, Chenhao
    Zhang, Jinqi Jiang, Xing Xie, and Hai Jin. Graphinstruct: Empowering large language
    models with graph understanding and reasoning capability. *arXiv preprint arXiv:2403.04483*,
    2024.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo 等人 [2024] 罗子涵、宋希然、黄鸿、廉建勋、张晨浩、蒋锦奇、谢星、金海。Graphinstruct：赋能大型语言模型图结构理解与推理能力。*arXiv
    预印本 arXiv:2403.04483*, 2024。
- en: Mao et al. [2023a] Jiayuan Mao, Tomás Lozano-Pérez, Josh Tenenbaum, and Leslie
    Kaelbling. What planning problems can a relational neural network solve? *Advances
    in Neural Information Processing Systems*, 36, 2023a.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mao 等人 [2023a] 毛家远、托马斯·洛萨诺-佩雷斯、乔希·特内恩鲍姆、莱斯利·凯尔布林。关系型神经网络能解决哪些规划问题？*神经信息处理系统进展*,
    36, 2023a。
- en: Mao et al. [2023b] Jiayuan Mao, Tomas Lozano-Perez, Joshua B. Tenenbaum, and
    Leslie Pack Kaelbing. What Planning Problems Can A Relational Neural Network Solve?
    In *Advances in Neural Information Processing Systems (NeurIPS)*, 2023b.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mao 等人 [2023b] 毛家远、托马斯·洛萨诺-佩雷斯、乔书亚·B·特内恩鲍姆、莱斯利·包克·凯尔布林。关系型神经网络能解决哪些规划问题？在*神经信息处理系统进展
    (NeurIPS)*，2023b。
- en: Momennejad et al. [2023] Ida Momennejad, Hosein Hasanbeig, Felipe Vieira Frujeri,
    Hiteshi Sharma, Nebojsa Jojic, Hamid Palangi, Robert Ness, and Jonathan Larson.
    Evaluating cognitive maps and planning in large language models with CogEval.
    *Advances in Neural Information Processing Systems*, 36, 2023.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Momennejad 等人 [2023] 伊达·莫门贾德、霍赛因·哈桑贝伊、费利佩·维埃拉·弗鲁杰里、希特西·夏尔马、内博伊萨·乔吉奇、哈米德·帕兰吉、罗伯特·内斯、乔纳森·拉尔森。评估大语言模型中的认知地图与规划：CogEval。*神经信息处理系统进展*,
    36, 2023。
- en: 'Perozzi et al. [2024] Bryan Perozzi, Bahare Fatemi, Dustin Zelle, Anton Tsitsulin,
    Mehran Kazemi, Rami Al-Rfou, and Jonathan Halcrow. Let your graph do the talking:
    Encoding structured data for llms, 2024.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perozzi 等人 [2024] 布赖恩·佩罗齐、巴哈雷·法提米、达斯汀·泽尔、安东·齐楚林、梅赫兰·卡泽米、拉米·阿尔·尔弗、乔纳森·哈尔克罗。让你的图来发声：为
    LLM 编码结构化数据，2024 年。
- en: 'Qin et al. [2023] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian,
    Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.
    Toolllm: Facilitating large language models to master 16000+ real-world apis,
    2023.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等人 [2023] 秦宇佳、梁世豪、叶怡宁、朱昆仑、闫兰、卢雅希、林彦凯、崇鑫、唐向如、钱璧、赵思寒、田润初、谢若冰、周杰、格尔斯坦·马克、李大海、刘志远、孙茂松。Toolllm：助力大型语言模型掌握
    16000+ 个现实世界的 API，2023 年。
- en: 'Reimers & Gurevych [2019] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence
    embeddings using siamese bert-networks. In *Conference on Empirical Methods in
    Natural Language Processing*, 2019.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reimers & Gurevych [2019] Nils Reimers 和 Iryna Gurevych. Sentence-bert：基于孪生BERT网络的句子嵌入。载于
    *自然语言处理实证方法会议*，2019年。
- en: 'Rendle et al. [2012] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner,
    and Lars Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback.
    *arXiv preprint arXiv:1205.2618*, 2012.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rendle 等人 [2012] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner 和 Lars
    Schmidt-Thieme. Bpr：基于隐式反馈的贝叶斯个性化排序。*arXiv 预印本 arXiv:1205.2618*，2012年。
- en: 'Rozière et al. [2023] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten
    Sootla, Itai Gat, Xiaoqing Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin,
    Artyom Kozhevnikov, I. Evtimov, Joanna Bitton, Manish P Bhatt, Cristian Cantón
    Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre D’efossez, Jade Copet, Faisal
    Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel
    Synnaeve. Code llama: Open foundation models for code. *ArXiv*, abs/2308.12950,
    2023.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rozière 等人 [2023] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla,
    Itai Gat, Xiaoqing Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom
    Kozhevnikov, I. Evtimov, Joanna Bitton, Manish P Bhatt, Cristian Cantón Ferrer,
    Aaron Grattafiori, Wenhan Xiong, Alexandre D’efossez, Jade Copet, Faisal Azhar,
    Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom 和 Gabriel Synnaeve.
    Code llama：面向代码的开放基础模型。*ArXiv*，abs/2308.12950，2023年。
- en: 'Schick et al. [2024] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    Toolformer: Language models can teach themselves to use tools. *Advances in Neural
    Information Processing Systems*, 36, 2024.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schick 等人 [2024] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda 和 Thomas Scialom.
    Toolformer：语言模型可以自学使用工具。*神经信息处理系统进展*，第36卷，2024年。
- en: Shen et al. [2020] William Shen, Felipe Trevizan, and Sylvie Thiébaux. Learning
    domain-independent planning heuristics with hypergraph networks. In *Proceedings
    of the International Conference on Automated Planning and Scheduling*, volume 30,
    pp.  574–584, 2020.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 [2020] William Shen, Felipe Trevizan 和 Sylvie Thiébaux. 使用超图网络学习领域无关的规划启发式方法。载于
    *国际自动化规划与调度会议论文集*，第30卷，页574–584，2020年。
- en: 'Shen et al. [2023] Yongliang Shen, Kaitao Song, Xu Tan, Wenqi Zhang, Kan Ren,
    Siyu Yuan, Weiming Lu, Dongsheng Li, and Yueting Zhuang. Taskbench: Benchmarking
    large language models for task automation. *arXiv preprint arXiv:2311.18760*,
    2023.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 [2023] Yongliang Shen, Kaitao Song, Xu Tan, Wenqi Zhang, Kan Ren, Siyu
    Yuan, Weiming Lu, Dongsheng Li 和 Yueting Zhuang. Taskbench：大型语言模型任务自动化基准测试。*arXiv
    预印本 arXiv:2311.18760*，2023年。
- en: 'Shen et al. [2024] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. Hugginggpt: Solving ai tasks with chatgpt and its friends
    in hugging face. *Advances in Neural Information Processing Systems*, 36, 2024.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等人 [2024] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu
    和 Yueting Zhuang. Hugginggpt：通过ChatGPT及其在Hugging Face的朋友解决AI任务。*神经信息处理系统进展*，第36卷，2024年。
- en: 'Shi et al. [2021] Yunsheng Shi, Zhengjie Huang, Wenjin Wang, Hui Zhong, Shikun
    Feng, and Yu Sun. Masked label prediction: Unified massage passing model for semi-supervised
    classification. In *Proceedings of the Thirtieth International Joint Conference
    on Artificial Intelligence (IJCA)*, 2021.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi 等人 [2021] Yunsheng Shi, Zhengjie Huang, Wenjin Wang, Hui Zhong, Shikun Feng
    和 Yu Sun. 掩码标签预测：一种统一的消息传递模型用于半监督分类。载于 *第三十届国际人工智能联合会议（IJCA）论文集*，2021年。
- en: 'Shinn et al. [2024] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik
    Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement
    learning. *Advances in Neural Information Processing Systems*, 36, 2024.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shinn 等人 [2024] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan
    和 Shunyu Yao. Reflexion：带有语言强化学习的语言代理。*神经信息处理系统进展*，第36卷，2024年。
- en: 'Singh et al. [2023] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal,
    Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt:
    Generating situated robot task plans using large language models. In *2023 IEEE
    International Conference on Robotics and Automation (ICRA)*, pp.  11523–11530\.
    IEEE, 2023.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 等人 [2023] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal,
    Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason 和 Animesh Garg. Progprompt：利用大型语言模型生成定位的机器人任务计划。载于
    *2023 IEEE国际机器人与自动化会议（ICRA）*，页11523–11530，IEEE，2023年。
- en: 'Song et al. [2023] Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian,
    Mingbo Song, Hailiang Huang, Cheng Li, Ke Wang, Rong Yao, Ye Tian, and Sujian
    Li. Restgpt: Connecting large language models with real-world restful apis, 2023.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Song 等人 [2023] Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo
    Song, Hailiang Huang, Cheng Li, Ke Wang, Rong Yao, Ye Tian, 和 Sujian Li. Restgpt：将大型语言模型与现实世界的
    restful api 连接，2023年。
- en: 'Ståhlberg et al. [2022] Simon Ståhlberg, Blai Bonet, and Hector Geffner. Learning
    general optimal policies with graph neural networks: Expressive power, transparency,
    and limits. In *Proceedings of the International Conference on Automated Planning
    and Scheduling*, volume 32, pp.  629–637, 2022.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ståhlberg 等人 [2022] Simon Ståhlberg, Blai Bonet, 和 Hector Geffner. 使用图神经网络学习通用最优策略：表现力、透明性和局限性。见于
    *国际自动规划与调度会议论文集*，第 32 卷，页 629–637，2022年。
- en: 'Sun et al. [2023] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Sai Wang, Chen
    Lin, Yeyun Gong, Lionel M. Ni, Heung yeung Shum, and Jian Guo. Think-on-graph:
    Deep and responsible reasoning of large language model on knowledge graph. 2023.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等人 [2023] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Sai Wang, Chen Lin,
    Yeyun Gong, Lionel M. Ni, Heung yeung Shum, 和 Jian Guo. Think-on-graph：大型语言模型在知识图谱上的深度与负责任推理，2023年。
- en: 'Tang et al. [2023a] Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi
    Cheng, Dawei Yin, and Chao Huang. GraphGPT: Graph instruction tuning for large
    language models. *arXiv preprint arXiv:2310.13023*, 2023a.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人 [2023a] Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng,
    Dawei Yin, 和 Chao Huang. GraphGPT：为大型语言模型提供图指令微调。*arXiv 预印本 arXiv:2310.13023*，2023a。
- en: 'Tang et al. [2023b] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao
    Liang, and Le Sun. Toolalpaca: Generalized tool learning for language models with
    3000 simulated cases, 2023b.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人 [2023b] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang,
    和 Le Sun. Toolalpaca：具有3000个模拟案例的语言模型通用工具学习，2023b。
- en: 'Toyer et al. [2019] Sam Toyer, Felipe W. Trevizan, Sylvie Thiébaux, and Lexing
    Xie. Asnets: Deep learning for generalised planning. *ArXiv*, abs/1908.01362,
    2019.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Toyer 等人 [2019] Sam Toyer, Felipe W. Trevizan, Sylvie Thiébaux, 和 Lexing Xie.
    Asnets：用于广义规划的深度学习。*ArXiv*，abs/1908.01362，2019年。
- en: Trinh et al. [2024] Trieu H Trinh, Yuhuai Wu, Quoc V Le, He He, and Thang Luong.
    Solving Olympiad geometry without human demonstrations. *Nature*, 625(7995):476–482,
    2024.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trinh 等人 [2024] Trieu H Trinh, Yuhuai Wu, Quoc V Le, He He, 和 Thang Luong. 无需人工演示解决奥林匹克几何问题。*Nature*，625(7995):476–482，2024年。
- en: Veličković et al. [2018] Petar Veličković, Guillem Cucurull, Arantxa Casanova,
    Adriana Romero, Pietro Liò, and Yoshua Bengio. Graph attention networks. *International
    Conference on Learning Representations*, 2018.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Veličković 等人 [2018] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana
    Romero, Pietro Liò, 和 Yoshua Bengio. 图注意力网络。*国际学习表示大会*，2018年。
- en: 'Wang et al. [2023a] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied
    agent with large language models. *arXiv preprint arXiv:2305.16291*, 2023a.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2023a] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, 和 Anima Anandkumar. Voyager：一个开放式的具身代理与大型语言模型。*arXiv
    预印本 arXiv:2305.16291*，2023a。
- en: Wang et al. [2023b] Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang
    Han, and Yulia Tsvetkov. Can language models solve graph problems in natural language?
    *Advances in Neural Information Processing Systems*, 36, 2023b.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2023b] Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang
    Han, 和 Yulia Tsvetkov. 语言模型能否用自然语言解决图问题？*神经信息处理系统进展*，36，2023b。
- en: 'Wang et al. [2023c] Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. Plan-and-solve prompting: Improving zero-shot
    chain-of-thought reasoning by large language models. *arXiv preprint arXiv:2305.04091*,
    2023c.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2023c] Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy
    Ka-Wei Lee, 和 Ee-Peng Lim. Plan-and-solve 提示：通过大型语言模型改进零-shot 思维链推理。*arXiv 预印本
    arXiv:2305.04091*，2023c。
- en: Wang et al. [2024] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large
    language model based autonomous agents. *Frontiers of Computer Science*, 18(6):1–26,
    2024.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2024] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin 等人. 基于大型语言模型的自主代理调查。*计算机科学前沿*，18(6):1–26，2024年。
- en: Wang et al. [2022] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun
    Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. Text embeddings by weakly-supervised
    contrastive pre-training. *ArXiv*, abs/2212.03533, 2022.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人 [2022] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang,
    Daxin Jiang, Rangan Majumder, 和 Furu Wei. 通过弱监督对比预训练进行文本嵌入。*ArXiv*，abs/2212.03533，2022年。
- en: Wei et al. [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in neural information processing
    systems*, 35:24824–24837, 2022.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei 等人 [2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,
    Ed Chi, Quoc V Le, Denny Zhou 等人。链式思维提示激发大型语言模型的推理能力。*Advances in Neural Information
    Processing Systems*, 35:24824–24837, 2022。
- en: 'Whittington et al. [2020] James CR Whittington, Timothy H Muller, Shirley Mark,
    Guifen Chen, Caswell Barry, Neil Burgess, and Timothy EJ Behrens. The tolman-eichenbaum
    machine: unifying space and relational memory through generalization in the hippocampal
    formation. *Cell*, 183(5):1249–1263, 2020.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Whittington 等人 [2020] James CR Whittington, Timothy H Muller, Shirley Mark,
    Guifen Chen, Caswell Barry, Neil Burgess 和 Timothy EJ Behrens. Tolman-Eichenbaum
    机器：通过海马体结构中的泛化统一空间和关系记忆。*Cell*, 183(5):1249–1263, 2020。
- en: Wu et al. [2019] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao
    Yu, and Kilian Weinberger. Simplifying graph convolutional networks. In *International
    conference on machine learning*, pp.  6861–6871\. PMLR, 2019.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人 [2019] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu
    和 Kilian Weinberger. 简化图卷积网络。在 *国际机器学习会议* 上，第6861–6871页。PMLR, 2019。
- en: Xiao et al. [2023] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and
    Mike Lewis. Efficient streaming language models with attention sinks. *arXiv preprint
    arXiv:2309.17453*, 2023.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao 等人 [2023] Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han 和 Mike Lewis.
    具有注意力池的高效流式语言模型。*arXiv 预印本 arXiv:2309.17453*, 2023。
- en: Xu et al. [2019a] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
    How powerful are graph neural networks? In *International Conference on Learning
    Representations*, 2019a.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人 [2019a] Keyulu Xu, Weihua Hu, Jure Leskovec 和 Stefanie Jegelka. 图神经网络有多强大？在
    *国际学习表示会议* 上，2019a。
- en: Xu et al. [2019b] Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S Du, Ken-ichi
    Kawarabayashi, and Stefanie Jegelka. What can neural networks reason about? *arXiv
    preprint arXiv:1905.13211*, 2019b.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人 [2019b] Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S Du, Ken-ichi Kawarabayashi
    和 Stefanie Jegelka. 神经网络能推理什么？*arXiv 预印本 arXiv:1905.13211*, 2019b。
- en: 'Yang et al. [2023] Ai Ming Yang, Bin Xiao, and et al. Baichuan 2: Open large-scale
    language models. *ArXiv*, abs/2309.10305, 2023.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2023] Ai Ming Yang, Bin Xiao 等人。Baichuan 2：开放的大规模语言模型。*ArXiv*, abs/2309.10305,
    2023。
- en: Yang et al. [2024] Kai Yang, Jan Ackermann, Zhenyu He, Guhao Feng, Bohang Zhang,
    Yunzhen Feng, Qiwei Ye, Di He, and Liwei Wang. Do efficient transformers really
    save computation? *arXiv preprint arXiv:2402.13934*, 2024.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 [2024] Kai Yang, Jan Ackermann, Zhenyu He, Guhao Feng, Bohang Zhang,
    Yunzhen Feng, Qiwei Ye, Di He 和 Liwei Wang. 高效的 Transformer 真正节省计算吗？*arXiv 预印本
    arXiv:2402.13934*, 2024。
- en: 'Yao et al. [2024] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving
    with large language models. *Advances in Neural Information Processing Systems*,
    36, 2024.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等人 [2024] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths,
    Yuan Cao 和 Karthik Narasimhan. 思维树：使用大型语言模型进行深思熟虑的问题解决。*Advances in Neural Information
    Processing Systems*, 36, 2024。
- en: Zheng et al. [2023] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang,
    Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Haotong
    Zhang, Joseph Gonzalez, and Ion Stoica. Judging llm-as-a-judge with mt-bench and
    chatbot arena. *ArXiv*, abs/2306.05685, 2023.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等人 [2023] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao
    Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Haotong Zhang,
    Joseph Gonzalez 和 Ion Stoica. 使用 mt-bench 和 chatbot arena 评估 LLM 作为判官的表现。*ArXiv*,
    abs/2306.05685, 2023。
- en: 'Zhong et al. [2024] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin
    Wang. Memorybank: Enhancing large language models with long-term memory. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, volume 38, pp.  19724–19731,
    2024.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong 等人 [2024] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye 和 Yanlin Wang.
    Memorybank：通过长期记忆增强大型语言模型。在 *AAAI 人工智能会议论文集*，第38卷，第19724–19731页，2024。
- en: Contents
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 目录
- en: '[1 Introduction](https://arxiv.org/html/2405.19119v3#S1 "In Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1 引言](https://arxiv.org/html/2405.19119v3#S1 "在图学习能否改善基于 LLM 的代理规划中？")'
- en: '[2 Preliminaries](https://arxiv.org/html/2405.19119v3#S2 "In Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2 初步研究](https://arxiv.org/html/2405.19119v3#S2 "在图学习能否改善基于 LLM 的代理规划中？")'
- en: '[2.1 Task Planning in Language Agents](https://arxiv.org/html/2405.19119v3#S2.SS1
    "In 2 Preliminaries ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.1 语言代理中的任务规划](https://arxiv.org/html/2405.19119v3#S2.SS1 "在 2 初步研究 ‣ 图学习能否改善基于
    LLM 的代理规划中？")'
- en: '[2.2 Current LLM-based Solution to Task Planning](https://arxiv.org/html/2405.19119v3#S2.SS2
    "In 2 Preliminaries ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[2.2 当前基于 LLM 的任务规划解决方案](https://arxiv.org/html/2405.19119v3#S2.SS2 "在 2 前言
    ‣ 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[3 Graph Formulation and Insights](https://arxiv.org/html/2405.19119v3#S3 "In
    Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3 图表示与洞见](https://arxiv.org/html/2405.19119v3#S3 "在 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[3.1 Graph Formulation of Task Planning](https://arxiv.org/html/2405.19119v3#S3.SS1
    "In 3 Graph Formulation and Insights ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?")'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.1 任务规划的图表示](https://arxiv.org/html/2405.19119v3#S3.SS1 "在 3 图表示与洞见 ‣ 图学习能否改善基于
    LLM 的智能体的规划？")'
- en: '[3.2 Failures of LLMs in Planning: Empirical Findings](https://arxiv.org/html/2405.19119v3#S3.SS2
    "In 3 Graph Formulation and Insights ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?")'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.2 LLM 在规划中的失败：实证发现](https://arxiv.org/html/2405.19119v3#S3.SS2 "在 3 图表示与洞见
    ‣ 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[3.3 Failures of LLMs in Planning: Theoretical Insights](https://arxiv.org/html/2405.19119v3#S3.SS3
    "In 3 Graph Formulation and Insights ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?")'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[3.3 LLM 在规划中的失败：理论洞察](https://arxiv.org/html/2405.19119v3#S3.SS3 "在 3 图表示与洞见
    ‣ 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[4 Integrating GNNs and LLMs for Planning](https://arxiv.org/html/2405.19119v3#S4
    "In Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4 融合 GNN 和 LLMs 进行规划](https://arxiv.org/html/2405.19119v3#S4 "在 图学习能否改善基于
    LLM 的智能体的规划？")'
- en: '[4.1 Motivations](https://arxiv.org/html/2405.19119v3#S4.SS1 "In 4 Integrating
    GNNs and LLMs for Planning ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.1 动机](https://arxiv.org/html/2405.19119v3#S4.SS1 "在 4 融合 GNN 和 LLMs 进行规划
    ‣ 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[4.2 A Training-free GNN-based Approach](https://arxiv.org/html/2405.19119v3#S4.SS2
    "In 4 Integrating GNNs and LLMs for Planning ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.2 无需训练的 GNN 基础方法](https://arxiv.org/html/2405.19119v3#S4.SS2 "在 4 融合 GNN
    和 LLMs 进行规划 ‣ 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[4.3 A Training-required GNN-based Approach](https://arxiv.org/html/2405.19119v3#S4.SS3
    "In 4 Integrating GNNs and LLMs for Planning ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4.3 需要训练的 GNN 基础方法](https://arxiv.org/html/2405.19119v3#S4.SS3 "在 4 融合 GNN
    和 LLMs 进行规划 ‣ 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[5 Experiments and Analysis](https://arxiv.org/html/2405.19119v3#S5 "In Can
    Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5 实验与分析](https://arxiv.org/html/2405.19119v3#S5 "在 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[5.1 Experimental Setup](https://arxiv.org/html/2405.19119v3#S5.SS1 "In 5 Experiments
    and Analysis ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.1 实验设置](https://arxiv.org/html/2405.19119v3#S5.SS1 "在 5 实验与分析 ‣ 图学习能否改善基于
    LLM 的智能体的规划？")'
- en: '[5.2 Performance of the Training-free Approach](https://arxiv.org/html/2405.19119v3#S5.SS2
    "In 5 Experiments and Analysis ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.2 基于训练的无训练方法的性能](https://arxiv.org/html/2405.19119v3#S5.SS2 "在 5 实验与分析 ‣
    图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[5.3 Performance of the Training-based Approaches](https://arxiv.org/html/2405.19119v3#S5.SS3
    "In 5 Experiments and Analysis ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.3 基于训练的方法的性能](https://arxiv.org/html/2405.19119v3#S5.SS3 "在 5 实验与分析 ‣ 图学习能否改善基于
    LLM 的智能体的规划？")'
- en: '[5.4 Scaling to Large Task Graphs](https://arxiv.org/html/2405.19119v3#S5.SS4
    "In 5 Experiments and Analysis ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.4 扩展到大规模任务图](https://arxiv.org/html/2405.19119v3#S5.SS4 "在 5 实验与分析 ‣ 图学习能否改善基于
    LLM 的智能体的规划？")'
- en: '[5.5 Improved Prompts and Fine-tuned LLMs](https://arxiv.org/html/2405.19119v3#S5.SS5
    "In 5 Experiments and Analysis ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[5.5 改进的提示与微调 LLMs](https://arxiv.org/html/2405.19119v3#S5.SS5 "在 5 实验与分析 ‣
    图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[6 Conclusions](https://arxiv.org/html/2405.19119v3#S6 "In Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[6 结论](https://arxiv.org/html/2405.19119v3#S6 "在 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[A Related Works and Discussions](https://arxiv.org/html/2405.19119v3#A1 "In
    Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A 相关工作与讨论](https://arxiv.org/html/2405.19119v3#A1 "在 图学习能否改善基于 LLM 的智能体的规划？")'
- en: '[A.1 Planning Algorithms in LLMs](https://arxiv.org/html/2405.19119v3#A1.SS1
    "In Appendix A Related Works and Discussions ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A.1 LLM中的规划算法](https://arxiv.org/html/2405.19119v3#A1.SS1 "在附录A 相关工作与讨论 ‣
    图学习能否改善基于LLM的智能体规划？")'
- en: '[A.2 Task Planning in Traditional AI](https://arxiv.org/html/2405.19119v3#A1.SS2
    "In Appendix A Related Works and Discussions ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A.2 传统AI中的任务规划](https://arxiv.org/html/2405.19119v3#A1.SS2 "在附录A 相关工作与讨论 ‣
    图学习能否改善基于LLM的智能体规划？")'
- en: '[A.3 Planning in Agents and Neuroscience](https://arxiv.org/html/2405.19119v3#A1.SS3
    "In Appendix A Related Works and Discussions ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A.3 智能体与神经科学中的规划](https://arxiv.org/html/2405.19119v3#A1.SS3 "在附录A 相关工作与讨论
    ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[A.4 LLMs for Graphs](https://arxiv.org/html/2405.19119v3#A1.SS4 "In Appendix
    A Related Works and Discussions ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A.4 LLMs在图中的应用](https://arxiv.org/html/2405.19119v3#A1.SS4 "在附录A 相关工作与讨论 ‣
    图学习能否改善基于LLM的智能体规划？")'
- en: '[A.5 Theoretical Analysis of Reasoning](https://arxiv.org/html/2405.19119v3#A1.SS5
    "In Appendix A Related Works and Discussions ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A.5 推理的理论分析](https://arxiv.org/html/2405.19119v3#A1.SS5 "在附录A 相关工作与讨论 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[A.6 GNNs and GraphSearch for Combinatorial Optimization](https://arxiv.org/html/2405.19119v3#A1.SS6
    "In Appendix A Related Works and Discussions ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")'
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[A.6 GNN与GraphSearch在组合优化中的应用](https://arxiv.org/html/2405.19119v3#A1.SS6 "在附录A
    相关工作与讨论 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[B Prompts](https://arxiv.org/html/2405.19119v3#A2 "In Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[B 提示语](https://arxiv.org/html/2405.19119v3#A2 "在图学习能否改善基于LLM的智能体规划？")'
- en: '[C Datasets](https://arxiv.org/html/2405.19119v3#A3 "In Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[C 数据集](https://arxiv.org/html/2405.19119v3#A3 "在图学习能否改善基于LLM的智能体规划？")'
- en: '[C.1 Overview](https://arxiv.org/html/2405.19119v3#A3.SS1 "In Appendix C Datasets
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[C.1 概述](https://arxiv.org/html/2405.19119v3#A3.SS1 "在附录C 数据集 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[C.2 Reformatting Details of RestBench](https://arxiv.org/html/2405.19119v3#A3.SS2
    "In Appendix C Datasets ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[C.2 RestBench重格式化细节](https://arxiv.org/html/2405.19119v3#A3.SS2 "在附录C 数据集
    ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[C.3 Reformatting Details of UltraTool](https://arxiv.org/html/2405.19119v3#A3.SS3
    "In Appendix C Datasets ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[C.3 UltraTool重格式化细节](https://arxiv.org/html/2405.19119v3#A3.SS3 "在附录C 数据集
    ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[D Supplementary Materials for Theoretical Results](https://arxiv.org/html/2405.19119v3#A4
    "In Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[D 理论结果的补充材料](https://arxiv.org/html/2405.19119v3#A4 "在图学习能否改善基于LLM的智能体规划？")'
- en: '[D.1 Dynamic Programming](https://arxiv.org/html/2405.19119v3#A4.SS1 "In Appendix
    D Supplementary Materials for Theoretical Results ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[D.1 动态规划](https://arxiv.org/html/2405.19119v3#A4.SS1 "在附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[D.2 Proof of Theorem 1](https://arxiv.org/html/2405.19119v3#A4.SS2 "In Appendix
    D Supplementary Materials for Theoretical Results ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[D.2 定理1的证明](https://arxiv.org/html/2405.19119v3#A4.SS2 "在附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[D.3 Permutation Invariance Test of LLMs](https://arxiv.org/html/2405.19119v3#A4.SS3
    "In Appendix D Supplementary Materials for Theoretical Results ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[D.3 LLM的排列不变性测试](https://arxiv.org/html/2405.19119v3#A4.SS3 "在附录D 理论结果的补充材料
    ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[D.4 Proof of Proposition 1](https://arxiv.org/html/2405.19119v3#A4.SS4 "In
    Appendix D Supplementary Materials for Theoretical Results ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[D.4 命题1的证明](https://arxiv.org/html/2405.19119v3#A4.SS4 "在附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[D.5 Proof of Theorem 2](https://arxiv.org/html/2405.19119v3#A4.SS5 "In Appendix
    D Supplementary Materials for Theoretical Results ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[D.5 定理2的证明](https://arxiv.org/html/2405.19119v3#A4.SS5 "在附录D 理论结果的补充材料 ‣ 图学习能否改善基于LLM的智能体规划？")'
- en: '[E Supplementary Materials for Training-free Methods](https://arxiv.org/html/2405.19119v3#A5
    "In Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E 基于无训练方法的补充材料](https://arxiv.org/html/2405.19119v3#A5 "图学习能否改善LLM代理的规划？")'
- en: '[E.1 Implementation of Baselines](https://arxiv.org/html/2405.19119v3#A5.SS1
    "In Appendix E Supplementary Materials for Training-free Methods ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E.1 基准方法的实现](https://arxiv.org/html/2405.19119v3#A5.SS1 "在附录E：基于无训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[E.2 Results of All LLMs](https://arxiv.org/html/2405.19119v3#A5.SS2 "In Appendix
    E Supplementary Materials for Training-free Methods ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E.2 所有LLM的结果](https://arxiv.org/html/2405.19119v3#A5.SS2 "在附录E：基于无训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[E.3 Accuracy Results of Training-free Methods](https://arxiv.org/html/2405.19119v3#A5.SS3
    "In Appendix E Supplementary Materials for Training-free Methods ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E.3 基于无训练方法的准确度结果](https://arxiv.org/html/2405.19119v3#A5.SS3 "在附录E：基于无训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[E.4 Computational Cost Analysis](https://arxiv.org/html/2405.19119v3#A5.SS4
    "In Appendix E Supplementary Materials for Training-free Methods ‣ Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[E.4 计算成本分析](https://arxiv.org/html/2405.19119v3#A5.SS4 "在附录E：基于无训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[F Supplementary Materials for Training-based Methods](https://arxiv.org/html/2405.19119v3#A6
    "In Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F 基于训练的方法的补充材料](https://arxiv.org/html/2405.19119v3#A6 "图学习能否改善LLM代理的规划？")'
- en: '[F.1 Implementation of Training-based GNNs](https://arxiv.org/html/2405.19119v3#A6.SS1
    "In Appendix F Supplementary Materials for Training-based Methods ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")'
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F.1 基于训练的GNN实现](https://arxiv.org/html/2405.19119v3#A6.SS1 "在附录F：基于训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[F.2 Implementation of TAPE and GraphToken](https://arxiv.org/html/2405.19119v3#A6.SS2
    "In Appendix F Supplementary Materials for Training-based Methods ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F.2 TAPE和GraphToken的实现](https://arxiv.org/html/2405.19119v3#A6.SS2 "在附录F：基于训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[F.3 Implementation of Fine-tuning LLMs](https://arxiv.org/html/2405.19119v3#A6.SS3
    "In Appendix F Supplementary Materials for Training-based Methods ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")'
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F.3 微调LLM的实现](https://arxiv.org/html/2405.19119v3#A6.SS3 "在附录F：基于训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[F.4 Full Results of Training-based GNNs](https://arxiv.org/html/2405.19119v3#A6.SS4
    "In Appendix F Supplementary Materials for Training-based Methods ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")'
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F.4 基于训练的GNN的完整结果](https://arxiv.org/html/2405.19119v3#A6.SS4 "在附录F：基于训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[F.5 Performance of LM+GNN Co-trained Mode](https://arxiv.org/html/2405.19119v3#A6.SS5
    "In Appendix F Supplementary Materials for Training-based Methods ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F.5 LM+GNN联合训练模式的性能](https://arxiv.org/html/2405.19119v3#A6.SS5 "在附录F：基于训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[F.6 Computational Cost Analysis](https://arxiv.org/html/2405.19119v3#A6.SS6
    "In Appendix F Supplementary Materials for Training-based Methods ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")'
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[F.6 计算成本分析](https://arxiv.org/html/2405.19119v3#A6.SS6 "在附录F：基于训练的方法的补充材料
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[G Experiments on Task Parameter Prediction](https://arxiv.org/html/2405.19119v3#A7
    "In Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[G 任务参数预测实验](https://arxiv.org/html/2405.19119v3#A7 "图学习能否改善LLM代理的规划？")'
- en: '[G.1 Prompting LLMs to Fill in Parameters](https://arxiv.org/html/2405.19119v3#A7.SS1
    "In Appendix G Experiments on Task Parameter Prediction ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[G.1 提示LLM填充参数](https://arxiv.org/html/2405.19119v3#A7.SS1 "在附录G：任务参数预测实验 ‣
    图学习能否改善LLM代理的规划？")'
- en: '[G.2 Empirical Results of LLMs Predicted Parameters](https://arxiv.org/html/2405.19119v3#A7.SS2
    "In Appendix G Experiments on Task Parameter Prediction ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")'
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[G.2 LLM预测参数的实证结果](https://arxiv.org/html/2405.19119v3#A7.SS2 "在附录G：任务参数预测实验
    ‣ 图学习能否改善LLM代理的规划？")'
- en: '[H Case Studies](https://arxiv.org/html/2405.19119v3#A8 "In Can Graph Learning
    Improve Planning in LLM-based Agents?")'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[H 案例研究](https://arxiv.org/html/2405.19119v3#A8 "In Can Graph Learning Improve
    Planning in LLM-based Agents?")'
- en: Appendix A Related Works and Discussions
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 相关工作与讨论
- en: A.1 Planning Algorithms in LLMs
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1 大型语言模型中的规划算法
- en: The existing studies of task planning approaches can be categorized into several
    directions, including task decomposition, multi-plan selection, the use of external
    planners, reflection, and memory-aided planning [[22](https://arxiv.org/html/2405.19119v3#bib.bib22)].
    Task decomposition methods, such as the chain-of-thought approach [[63](https://arxiv.org/html/2405.19119v3#bib.bib63)],
    employ the divide-and-conquer strategy, utilizing LLMs for both task decomposition
    and sub-task planning. The application of this method to task planning is detailed
    in Section [2.2](https://arxiv.org/html/2405.19119v3#S2.SS2 "2.2 Current LLM-based
    Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?") and is referred to as “Direct” in the baseline comparison.
    Multi-plan selection strategies, exemplified by the tree-of-thought [[71](https://arxiv.org/html/2405.19119v3#bib.bib71)]
    and graph-of-thought [[4](https://arxiv.org/html/2405.19119v3#bib.bib4)], leverage
    search-based methods to generate plans. Subsequently, LLMs evaluate these plans
    to select the most effective one. The “GraphSearch” methods used in our baselines
    fall into this category. External planner approaches [[31](https://arxiv.org/html/2405.19119v3#bib.bib31)]
    use LLMs to convert the problem into Planning Domain Definition Language (PDDL)
    and then employ classic solvers to address the planning problem. PDDL requires
    a pre-defined goal, for example, moving the blocks from one state to another state.
    However, the goal of task planning investigated in language agents deals with
    more flexible and personal goals, spanning personal needs in video, text, and
    image processing. Translating these goals into formal PDDL is very difficult.
    We instead demonstrate that GNNs can serve as an effective external planner in
    this application. Reflection-based methods [[48](https://arxiv.org/html/2405.19119v3#bib.bib48)]
    focus on reflecting upon experiences to refine the plan, while memory-aided planning
    approaches [[73](https://arxiv.org/html/2405.19119v3#bib.bib73)] utilize external
    experiences, such as those from search engines. These approaches are deployed
    in interactive environments and orthogonal to this paper.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的任务规划方法研究可以分为几个方向，包括任务分解、多计划选择、外部规划器的使用、反思和记忆辅助规划 [[22](https://arxiv.org/html/2405.19119v3#bib.bib22)]。任务分解方法，如链式思维方法
    [[63](https://arxiv.org/html/2405.19119v3#bib.bib63)]，采用分治策略，利用大型语言模型（LLMs）进行任务分解和子任务规划。将该方法应用于任务规划的详细信息可见于第[2.2节](https://arxiv.org/html/2405.19119v3#S2.SS2
    "2.2 Current LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?")，并在基准比较中称为“直接法”。多计划选择策略，如树形思维
    [[71](https://arxiv.org/html/2405.19119v3#bib.bib71)] 和图形思维 [[4](https://arxiv.org/html/2405.19119v3#bib.bib4)]，利用基于搜索的方法生成计划。随后，LLMs评估这些计划以选择最有效的一个。我们基准方法中使用的“GraphSearch”方法属于这一类。外部规划器方法
    [[31](https://arxiv.org/html/2405.19119v3#bib.bib31)] 使用LLMs将问题转换为规划领域定义语言（PDDL），然后采用经典求解器解决规划问题。PDDL需要预定义的目标，例如，将方块从一个状态移动到另一个状态。然而，语言代理中研究的任务规划目标更加灵活且个性化，涵盖了视频、文本和图像处理中的个人需求。将这些目标转换为正式的PDDL非常困难。我们展示了图神经网络（GNNs）可以作为这一应用中的有效外部规划器。基于反思的方法
    [[48](https://arxiv.org/html/2405.19119v3#bib.bib48)] 侧重于通过反思经验来完善计划，而记忆辅助规划方法
    [[73](https://arxiv.org/html/2405.19119v3#bib.bib73)] 则利用外部经验，例如来自搜索引擎的经验。这些方法在交互式环境中部署，且与本文主题正交。
- en: A.2 Task Planning in Traditional AI
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2 传统人工智能中的任务规划
- en: Apart from task planning in language agents, there is also a domain in traditional
    AI called task planning [[1](https://arxiv.org/html/2405.19119v3#bib.bib1), [6](https://arxiv.org/html/2405.19119v3#bib.bib6),
    [18](https://arxiv.org/html/2405.19119v3#bib.bib18), [55](https://arxiv.org/html/2405.19119v3#bib.bib55),
    [44](https://arxiv.org/html/2405.19119v3#bib.bib44), [51](https://arxiv.org/html/2405.19119v3#bib.bib51),
    [35](https://arxiv.org/html/2405.19119v3#bib.bib35), [10](https://arxiv.org/html/2405.19119v3#bib.bib10)].
    Task planning in traditional AI is defined as $(\mathcal{S},\mathcal{A},\mathcal{T},\mathcal{C},\mathcal{G},s_{0})$,
    where $\mathcal{S}$ is the states, $\mathcal{A}$ is the action space, $\mathcal{T}:\mathcal{S}\times\mathcal{S}\times\mathcal{A}\rightarrow[0,1]$,
    a cost function $\mathcal{C}:\mathcal{S}\times\mathcal{A}\rightarrow[0,\infty)$,
    a set of goal states $\mathcal{G}\subseteq\mathcal{S}$, and an initial state $s_{0}$.
    An agent following a policy $\pi:\mathcal{A}\times\mathcal{S}\rightarrow[0,1]$
    will start in state $s_{0}$, then repeatedly choose an action $a\sim\pi(a|s)$
    and execute it to reach a new state $s^{\prime}\sim\mathcal{T}(s^{\prime}|s,a)$,
    incurring a cost $\mathcal{C}(s,a)$ along its way. An optimal policy $\pi^{*}(a|s)$
    is one that reaches the goal state with probability $1$ while minimizing the total
    expected cost. Traditionally, task planning is solved by reinforcement learning
    approaches [[6](https://arxiv.org/html/2405.19119v3#bib.bib6)] and heuristic A^∗
    approaches [[18](https://arxiv.org/html/2405.19119v3#bib.bib18)]. The neural network-based
    approaches are employed to accelerate the computation and improve the performance
    [[55](https://arxiv.org/html/2405.19119v3#bib.bib55), [44](https://arxiv.org/html/2405.19119v3#bib.bib44),
    [51](https://arxiv.org/html/2405.19119v3#bib.bib51), [35](https://arxiv.org/html/2405.19119v3#bib.bib35),
    [10](https://arxiv.org/html/2405.19119v3#bib.bib10)].
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 除了语言智能体中的任务规划，还有一个传统AI领域叫做任务规划 [[1](https://arxiv.org/html/2405.19119v3#bib.bib1),
    [6](https://arxiv.org/html/2405.19119v3#bib.bib6), [18](https://arxiv.org/html/2405.19119v3#bib.bib18),
    [55](https://arxiv.org/html/2405.19119v3#bib.bib55), [44](https://arxiv.org/html/2405.19119v3#bib.bib44),
    [51](https://arxiv.org/html/2405.19119v3#bib.bib51), [35](https://arxiv.org/html/2405.19119v3#bib.bib35),
    [10](https://arxiv.org/html/2405.19119v3#bib.bib10)]。传统AI中的任务规划定义为$(\mathcal{S},\mathcal{A},\mathcal{T},\mathcal{C},\mathcal{G},s_{0})$，其中$\mathcal{S}$表示状态，$\mathcal{A}$表示动作空间，$\mathcal{T}:\mathcal{S}\times\mathcal{S}\times\mathcal{A}\rightarrow[0,1]$，成本函数$\mathcal{C}:\mathcal{S}\times\mathcal{A}\rightarrow[0,\infty)$，目标状态集合$\mathcal{G}\subseteq\mathcal{S}$，初始状态为$s_{0}$。遵循策略$\pi:\mathcal{A}\times\mathcal{S}\rightarrow[0,1]$的智能体将从状态$s_{0}$开始，然后反复选择动作$a\sim\pi(a|s)$并执行它，达到新状态$s^{\prime}\sim\mathcal{T}(s^{\prime}|s,a)$，并在此过程中产生成本$\mathcal{C}(s,a)$。一个最优策略$\pi^{*}(a|s)$是一个能够以概率$1$到达目标状态并最小化总预期成本的策略。传统上，任务规划通过强化学习方法[[6](https://arxiv.org/html/2405.19119v3#bib.bib6)]和启发式A^∗方法[[18](https://arxiv.org/html/2405.19119v3#bib.bib18)]来解决。基于神经网络的方法被用于加速计算并提高性能[[55](https://arxiv.org/html/2405.19119v3#bib.bib55),
    [44](https://arxiv.org/html/2405.19119v3#bib.bib44), [51](https://arxiv.org/html/2405.19119v3#bib.bib51),
    [35](https://arxiv.org/html/2405.19119v3#bib.bib35), [10](https://arxiv.org/html/2405.19119v3#bib.bib10)]。
- en: The task planning in language agents is a different application. It cannot be
    solved as a constraint satisfaction problem, since both the features of task graph
    and user request are expressed in natural language. Compared with traditional
    planning, task planning for language agents involves diverse and open-ended goals
    due to the varied personal requirements users have. For example, on platforms
    like Hugging Face, users’ intentions span across video, text, and image domains.
    On the contrary, classic planning has a fixed goal for a given domain, e.g., in
    the n-puzzle [[55](https://arxiv.org/html/2405.19119v3#bib.bib55)], the goal is
    formally as placing the tiles in numerical order. Within this new application
    domain, while existing research primarily focuses on prompt design for pre-trained
    LLMs, our work underscores the importance of traditional planning methods, such
    as GNNs, in complementing LLMs.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 语言智能体中的任务规划是一个不同的应用。它不能像约束满足问题那样解决，因为任务图和用户请求的特征都是用自然语言表达的。与传统规划相比，语言智能体的任务规划涉及到多样化和开放性目标，因为用户有不同的个人需求。例如，在像
    Hugging Face 这样的平台上，用户的意图跨越视频、文本和图像等领域。相反，经典规划为特定领域设定了固定目标，例如，在n-puzzle [[55](https://arxiv.org/html/2405.19119v3#bib.bib55)]中，目标是将拼图块按照数字顺序排列。在这个新的应用领域，尽管现有研究主要集中在预训练LLM的提示设计上，我们的工作强调了传统规划方法（如GNN）在补充LLM方面的重要性。
- en: A.3 Planning in Agents and Neuroscience
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3 智能体与神经科学中的规划
- en: Planning is a pivotal topic in both agents and neuroscience, where graphs play
    an indispensable role. We believe the concepts and insights presented in this
    paper are useful to these fields.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 规划是代理和神经科学中的一个关键课题，图在其中扮演着不可或缺的角色。我们相信本文中提出的概念和见解对这些领域具有重要意义。
- en: The TaskBench, RestBench, and UltraTool dataset used in this paper belongs to
    the tool agents. The Math agent, AlphaGeometry, employs LLMs to generate auxiliary
    constructions in geometry [[56](https://arxiv.org/html/2405.19119v3#bib.bib56)].
    Considering lemmas as nodes and their interdependencies as edges, the endeavor
    to prove a theorem resembles the task of identifying a route to the theorem node
    within the graph constituted by potential lemma nodes and the edges that represent
    their interdependencies. There are no explicit task graphs in game agents [[58](https://arxiv.org/html/2405.19119v3#bib.bib58)],
    embodied agents [[21](https://arxiv.org/html/2405.19119v3#bib.bib21)], and code
    agents [[48](https://arxiv.org/html/2405.19119v3#bib.bib48)]. The core strategy
    in these domains is to employ verbal reinforcement learning within LLMs. The state
    and transitions in reinforcement learning can be modeled as nodes and edges in
    the graph. In addition, there are case-by-case graph models in these agent applications.
    For example, in code agents, one can view the class as the nodes and dependencies
    as the edges. In the embodied agents, the objects in the environment can be viewed
    as the nodes.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的TaskBench、RestBench和UltraTool数据集属于工具代理。数学代理AlphaGeometry利用LLMs生成几何学中的辅助构造[[56](https://arxiv.org/html/2405.19119v3#bib.bib56)]。将引理视为节点，将它们之间的相互依赖关系视为边，证明定理的努力类似于在由潜在引理节点和表示它们相互依赖关系的边组成的图中识别通往定理节点的路径。游戏代理[[58](https://arxiv.org/html/2405.19119v3#bib.bib58)]、具身代理[[21](https://arxiv.org/html/2405.19119v3#bib.bib21)]和代码代理[[48](https://arxiv.org/html/2405.19119v3#bib.bib48)]中没有显式的任务图。在这些领域中的核心策略是使用LLMs中的语言强化学习。强化学习中的状态和转移可以建模为图中的节点和边。此外，这些代理应用中存在按需图模型。例如，在代码代理中，可以将类视为节点，将依赖关系视为边。在具身代理中，可以将环境中的物体视为节点。
- en: In the neuroscience, animal planning is often assessed through path planning
    in mazes [[2](https://arxiv.org/html/2405.19119v3#bib.bib2), [64](https://arxiv.org/html/2405.19119v3#bib.bib64)].
    Inspired by these animal experiments, planning testbenches have been developed
    for LLMs [[37](https://arxiv.org/html/2405.19119v3#bib.bib37)]. A computational
    model known as the Tolman-Eichenbaum Machine (TEM) has been proposed to decipher
    the mechanisms of general planning in animals across various environments, such
    as mazes [[64](https://arxiv.org/html/2405.19119v3#bib.bib64)]. The TEM model
    posits that hippocampal cells, including place and landmark cells, remap between
    environments, while entorhinal cells exhibit a range of properties that mirror
    spatial responses, including grid, band, border, and object-vector cells. In essence,
    hippocampal cells map sensory inputs onto locations in abstract graphs and remap,
    and entorhinal cells execute graph operations.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经科学中，动物的规划通常通过迷宫中的路径规划来评估[[2](https://arxiv.org/html/2405.19119v3#bib.bib2),
    [64](https://arxiv.org/html/2405.19119v3#bib.bib64)]。受这些动物实验的启发，已经为LLMs开发了规划测试台[[37](https://arxiv.org/html/2405.19119v3#bib.bib37)]。一种被称为Tolman-Eichenbaum机（TEM）的计算模型已被提出，以解密动物在各种环境（如迷宫）中的一般规划机制[[64](https://arxiv.org/html/2405.19119v3#bib.bib64)]。TEM模型假设，包括位置细胞和地标细胞在内的海马细胞会在不同环境之间重新映射，而内嗅皮层细胞则表现出一系列与空间反应相关的特性，包括网格、带状、边界和物体-向量细胞。本质上，海马细胞将感官输入映射到抽象图中的位置并重新映射，而内嗅皮层细胞执行图操作。
- en: A.4 LLMs for Graphs
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.4 图的LLMs
- en: 'With the breakthroughs in LLMs, there has been a surge of interest in applying
    LLMs to graph-related problems [[27](https://arxiv.org/html/2405.19119v3#bib.bib27),
    [28](https://arxiv.org/html/2405.19119v3#bib.bib28)]. GPT4Graph [[14](https://arxiv.org/html/2405.19119v3#bib.bib14)]
    and NLGraph [[59](https://arxiv.org/html/2405.19119v3#bib.bib59)] are two prominent
    benchmarks designed to evaluate the performance of LLMs in the context of graph
    tasks. They encompass a wide spectrum of challenges, various input formats, and
    state-of-the-art prompting techniques, demonstrating that LLMs possess basic graph
    processing capabilities. Importantly, the choice of prompts and formats significantly
    influences performance. However, these benchmarks also expose the models’ susceptibility
    to spurious correlations within graphs. For instance, GPT-4 achieves only about
    $50\%$ accuracy on shortest-path tasks, even with the use of complex prompts.
    GraphInstruct [[34](https://arxiv.org/html/2405.19119v3#bib.bib34)] attempts to
    fine-tune LLMs on graph-theory-related tasks, resulting in improved performance,
    though it remains far from satisfactory. Despite these empirical efforts, there
    is a limited theoretical understanding of these evaluation results. The analysis
    in Section [3.3](https://arxiv.org/html/2405.19119v3#S3.SS3 "3.3 Failures of LLMs
    in Planning: Theoretical Insights ‣ 3 Graph Formulation and Insights ‣ Can Graph
    Learning Improve Planning in LLM-based Agents?") aims to shed light on the empirical
    observations reported in these studies.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '随着大型语言模型（LLMs）取得突破，应用LLMs解决图相关问题的兴趣激增[[27](https://arxiv.org/html/2405.19119v3#bib.bib27),
    [28](https://arxiv.org/html/2405.19119v3#bib.bib28)]。GPT4Graph [[14](https://arxiv.org/html/2405.19119v3#bib.bib14)]
    和 NLGraph [[59](https://arxiv.org/html/2405.19119v3#bib.bib59)] 是两个重要的基准测试，旨在评估LLMs在图任务中的表现。它们涵盖了广泛的挑战、不同的输入格式和最先进的提示技术，展示了LLMs具备基本的图处理能力。值得注意的是，提示和格式的选择对性能有着显著的影响。然而，这些基准测试也暴露了模型在图中的虚假关联性方面的易感性。例如，GPT-4在最短路径任务中的准确率仅约为$50\%$，即便使用了复杂的提示。GraphInstruct
    [[34](https://arxiv.org/html/2405.19119v3#bib.bib34)] 尝试在图论相关任务上对LLMs进行微调，取得了改进的性能，尽管仍远未令人满意。尽管有这些经验性努力，但对于这些评估结果的理论理解仍然有限。第[3.3节](https://arxiv.org/html/2405.19119v3#S3.SS3
    "3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")的分析旨在阐明这些研究报告中的经验性观察结果。'
- en: Considering these negative results, a new line of research has emerged that
    utilizes the output of GNNs as tokens for LLMs, as seen in GraphGPT [[53](https://arxiv.org/html/2405.19119v3#bib.bib53)],
    GraphLLM [[9](https://arxiv.org/html/2405.19119v3#bib.bib9)], GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)],
    and G-Retriever [[17](https://arxiv.org/html/2405.19119v3#bib.bib17)]. These approaches
    have demonstrated significant improvements in performance on GNN-related tasks.
    However, they have not yet been applied to task planning due to the lack of extensive
    training data. A promising future direction involves using task planning data
    generated by GPT to fine-tune graph foundation models, such as GraphGPT [[53](https://arxiv.org/html/2405.19119v3#bib.bib53)],
    and applying them to task planning. This paper proposes to use task planning as
    a new benchmark for this line of research.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些负面结果，一种新的研究方向应运而生，即利用图神经网络（GNNs）的输出作为LLMs的令牌，如GraphGPT [[53](https://arxiv.org/html/2405.19119v3#bib.bib53)]、GraphLLM
    [[9](https://arxiv.org/html/2405.19119v3#bib.bib9)]、GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)]
    和 G-Retriever [[17](https://arxiv.org/html/2405.19119v3#bib.bib17)]所示。这些方法在GNN相关任务中的表现显著提升。然而，由于缺乏广泛的训练数据，它们尚未应用于任务规划。一个有前景的未来方向是利用GPT生成的任务规划数据来微调图基础模型，如GraphGPT
    [[53](https://arxiv.org/html/2405.19119v3#bib.bib53)]，并将其应用于任务规划。本文建议将任务规划作为这一研究方向的新基准。
- en: A.5 Theoretical Analysis of Reasoning
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.5 推理的理论分析
- en: Reasoning is closely related to task planning and decision-making. The theoretical
    exploration of the reasoning abilities of neural networks was initiated by [[68](https://arxiv.org/html/2405.19119v3#bib.bib68)].
    This work unifies various reasoning tasks, such as intuitive physics, visual question
    answering, and shortest path calculations, into DP problems. It then analyzes
    the generalization capabilities of MLPs, DeepSets, and GNNs. It is demonstrated
    that GNNs exhibit the best generalization bounds, attributed to their architecture’s
    resemblance to the Bellman-Ford algorithm, which is adept at solving DP problems.
    In terms of reasoning abilities within LLMs, [[12](https://arxiv.org/html/2405.19119v3#bib.bib12)]
    examines how the Chain of Thought (CoT) approach aids in solving arithmetic and
    DP problems without graphs. By decomposing challenging problems into simpler subproblems,
    CoT extends the expressive capabilities of Transformers from $\text{TC}^{0}$ to
    P. This analysis is further applied to linear and sparse Transformers in [[70](https://arxiv.org/html/2405.19119v3#bib.bib70)].
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 推理与任务规划和决策密切相关。神经网络推理能力的理论探索始于[[68](https://arxiv.org/html/2405.19119v3#bib.bib68)]。这项工作将直观物理学、视觉问答和最短路径计算等各种推理任务统一为动态规划（DP）问题。接着，分析了MLPs、DeepSets和GNNs的泛化能力。研究表明，GNNs展现出最佳的泛化界限，这归因于其架构与贝尔曼-福特算法的相似性，该算法擅长解决DP问题。在LLMs的推理能力方面，[[12](https://arxiv.org/html/2405.19119v3#bib.bib12)]研究了链式思维（Chain
    of Thought, CoT）方法如何帮助解决没有图形的算术和DP问题。通过将复杂问题分解为更简单的子问题，CoT将Transformer的表达能力从$\text{TC}^{0}$扩展到P。该分析进一步应用于线性和稀疏Transformer，在[[70](https://arxiv.org/html/2405.19119v3#bib.bib70)]中进行了探讨。
- en: 'Our proof of Theorem [1](https://arxiv.org/html/2405.19119v3#Thmtheorem1 "Theorem
    1\. ‣ 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?") builds
    upon the proof of Theorem 4.7 in [[12](https://arxiv.org/html/2405.19119v3#bib.bib12)].
    However, while [[12](https://arxiv.org/html/2405.19119v3#bib.bib12)] addresses
    DP problems without graph structures, Theorem [1](https://arxiv.org/html/2405.19119v3#Thmtheorem1
    "Theorem 1\. ‣ 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph
    Formulation and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")
    specifically focuses on DP problems with graph edge list inputs. Moreover, unlike
    [[12](https://arxiv.org/html/2405.19119v3#bib.bib12)], which decomposes and solves
    the DP problem sequentially, Theorem [1](https://arxiv.org/html/2405.19119v3#Thmtheorem1
    "Theorem 1\. ‣ 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph
    Formulation and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")
    proposes a method to simulate DP on edge lists in parallel. In addition, we analyze
    the negative results rising from the inductive bias of attention mechanism and
    auto-regressive loss. These theoretical contributions are novel and promise to
    be valuable for general reasoning and planning tasks.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对定理[1](https://arxiv.org/html/2405.19119v3#Thmtheorem1 "定理 1\. ‣ 3.3 LLMs在规划中的失败：理论洞察
    ‣ 3 图形公式与洞察 ‣ 图形学习能否改善基于LLM的智能体规划？")的证明建立在[[12](https://arxiv.org/html/2405.19119v3#bib.bib12)]中定理4.7的证明基础上。然而，虽然[[12](https://arxiv.org/html/2405.19119v3#bib.bib12)]处理的是没有图形结构的DP问题，但定理[1](https://arxiv.org/html/2405.19119v3#Thmtheorem1
    "定理 1\. ‣ 3.3 LLMs在规划中的失败：理论洞察 ‣ 3 图形公式与洞察 ‣ 图形学习能否改善基于LLM的智能体规划？")专门聚焦于带有图边列表输入的DP问题。此外，与[[12](https://arxiv.org/html/2405.19119v3#bib.bib12)]通过分解并顺序解决DP问题不同，定理[1](https://arxiv.org/html/2405.19119v3#Thmtheorem1
    "定理 1\. ‣ 3.3 LLMs在规划中的失败：理论洞察 ‣ 3 图形公式与洞察 ‣ 图形学习能否改善基于LLM的智能体规划？")提出了一种方法，在边列表上并行模拟DP。我们还分析了来自注意力机制的归纳偏差和自回归损失所引发的负面结果。这些理论贡献是新颖的，并有望在一般的推理和规划任务中发挥重要作用。
- en: A.6 GNNs and GraphSearch for Combinatorial Optimization
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.6 GNNs与图搜索在组合优化中的应用
- en: GNNs are popular approaches for solving decision-making problems on graphs.
    The problems investigated are typically NP-hard, such as the minimum vertex cover,
    maximum cut, and the traveling salesman problem [[8](https://arxiv.org/html/2405.19119v3#bib.bib8)].
    The basic approach involves selecting nodes one by one in a manner that satisfies
    the constraints [[24](https://arxiv.org/html/2405.19119v3#bib.bib24)]. In this
    paper, we adopt this method to sequentially select task nodes. Furthermore, reinforcement
    learning can be used to enhance the performance of GNNs beyond what is achievable
    with supervised labels alone [[24](https://arxiv.org/html/2405.19119v3#bib.bib24)].
    In [[24](https://arxiv.org/html/2405.19119v3#bib.bib24)], the node with the highest
    score is selected exclusively. Conversely, [[29](https://arxiv.org/html/2405.19119v3#bib.bib29)]
    employs beam search to improve performance by selecting the top-$k$ nodes in a
    single iteration. Additionally, GNNs are utilized as the method for variable selection
    in exhaustive searches for exact solutions to combinatorial optimization problems
    [[13](https://arxiv.org/html/2405.19119v3#bib.bib13)]. This paper conceptualizes
    task planning as a graph-based decision-making problem. Both greedy and beam search
    algorithms have been adopted in task planning [[33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [32](https://arxiv.org/html/2405.19119v3#bib.bib32)]. Given this connection, a
    promising future direction involves repurposing GNNs for decision-making approaches
    in task-planning applications.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图神经网络（GNNs）是解决图上的决策问题的流行方法。所研究的问题通常是 NP-hard 的，例如最小顶点覆盖、最大割问题和旅行商问题 [[8](https://arxiv.org/html/2405.19119v3#bib.bib8)]。基本方法是逐个选择节点，确保满足约束条件
    [[24](https://arxiv.org/html/2405.19119v3#bib.bib24)]。本文采用这种方法按顺序选择任务节点。此外，强化学习可以增强
    GNNs 的性能，超越仅使用监督标签所能达到的效果 [[24](https://arxiv.org/html/2405.19119v3#bib.bib24)]。在
    [[24](https://arxiv.org/html/2405.19119v3#bib.bib24)] 中，独立选择得分最高的节点。相反，[[29](https://arxiv.org/html/2405.19119v3#bib.bib29)]
    采用束搜索，在一次迭代中选择前 $k$ 个节点以提高性能。此外，GNNs 被用作变量选择的方法，来进行穷举搜索，以求解组合优化问题的精确解 [[13](https://arxiv.org/html/2405.19119v3#bib.bib13)]。本文将任务规划概念化为基于图的决策问题。在任务规划中，贪心算法和束搜索算法都已被采用
    [[33](https://arxiv.org/html/2405.19119v3#bib.bib33), [32](https://arxiv.org/html/2405.19119v3#bib.bib32)]。基于这一联系，一个有前景的未来方向是将
    GNNs 重新应用于任务规划中的决策方法。
- en: Appendix B Prompts
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 B 提示
- en: 'Table 4: Prompt template for LLM’s direct inference [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：LLM 直接推理的提示模板 [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]
- en: '| # TASK LIST # {{ task list }}'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '| # 任务列表 # {{ 任务列表 }}'
- en: 'GOAL #'
  id: totrans-330
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '目标 #'
- en: 'Based on the above tasks, I want you to generate task steps and a task invocation
    graph (including nodes and edges) to address the # USER REQUEST #. The format
    must be in strict JSON format, like:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '基于上述任务，我希望你生成任务步骤和任务调用图（包括节点和边），以解决# 用户请求 #。格式必须严格符合 JSON 格式，如下所示：'
- en: $\{$
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: $\{$
- en: '${\color[rgb]{1,1,1}2}$ “task_steps”: $[$ step description for one or more
    steps $]$,'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}$ “task_steps”: $[$ 一个或多个步骤的描述 $]$，'
- en: '${\color[rgb]{1,1,1}2}$ “task_nodes”: $[\{$'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}$ “task_nodes”: $[\{$'
- en: '${\color[rgb]{1,1,1}2}\quad$ “task”: “ task name must be from # TASK LIST #
    ”,'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}\quad$ “task”: “任务名称必须从 # 任务列表 # 中选择”,'
- en: '${\color[rgb]{1,1,1}2}\quad$ “arguments”: $[$ a concise list of arguments for
    the task $]$'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}\quad$ “arguments”: $[$ 任务的简明参数列表 $]$'
- en: ${\color[rgb]{1,1,1}2}$$\}]$,
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ${\color[rgb]{1,1,1}2}$$\}]$，
- en: '${\color[rgb]{1,1,1}2}$ “task_links”: $[\{$ “source”: “task name i”, “target”:
    “task name j” $\}]$,'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}$ “task_links”: $[\{$ “source”: “任务名称 i”, “target”: “任务名称
    j” $\}]$，'
- en: $\}$
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: $\}$
- en: 'REQUIREMENTS #'
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '要求 #'
- en: '1\. Generated task steps and task nodes can resolve the user request # USER
    REQUEST # perfectly. Task name must be selected from # TASK LIST #.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '1\. 生成的任务步骤和任务节点能够完美解决用户请求 # 用户请求 #。任务名称必须从 # 任务列表 # 中选择。'
- en: 2\. The task steps should strictly align with the task nodes, and the number
    of task steps should be same with the task nodes.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 任务步骤应严格与任务节点对齐，且任务步骤的数量应与任务节点的数量相同。
- en: 3\. The task links should reflect the temporal and resource dependencies among
    task nodes, i.e., the order in which the tasks are invoked.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 任务链接应反映任务节点之间的时间和资源依赖关系，即任务调用的顺序。
- en: 'EXAMPLE #'
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '示例 #'
- en: '{{ in-context learning examples }}'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 上下文学习示例 }}'
- en: 'USER REQUEST #'
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '用户请求 #'
- en: '{{ user request }}'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 用户请求 }}'
- en: 'Now, please generate your response in a strict JSON format: # RESULT # |'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，请以严格的 JSON 格式生成你的回应：# 结果 # |'
- en: 'Table 5: Prompt templates of GraphSearch [[33](https://arxiv.org/html/2405.19119v3#bib.bib33)]'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：GraphSearch 的提示模板 [[33](https://arxiv.org/html/2405.19119v3#bib.bib33)]
- en: '| Scenario | Prompt |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 场景 | 提示 |'
- en: '| Task Assessment | # CANDIDATE TASK LIST # {{ candidate tasks }}'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '| 任务评估 | # CANDIDATE TASK LIST # {{ 候选任务 }}'
- en: 'GOAL #'
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'GOAL #'
- en: 'Based on the provided # CANDIDATE TASK LIST # and the user’s request described
    in the # STEP #, generate a score dictionary to assess each task’s problem-solving
    abilities. The output must be in a strict JSON format, like: $\{$ “candidate task
    name 1”: score, … $\}$.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '根据提供的 # CANDIDATE TASK LIST # 和用户在 # STEP # 中描述的请求，生成评分字典以评估每个任务的解决问题能力。输出必须严格遵循
    JSON 格式，如：$\{$ “candidate task name 1”: score, … $\}$。'
- en: 'REQUIREMENTS #'
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'REQUIREMENTS #'
- en: 1\. The keys of the generated score dictionary must align with the provided
    candidate tasks, and you should output scores for all candidate tasks.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 生成的评分字典的键必须与提供的候选任务一致，并且应为所有候选任务输出分数。
- en: 2\. The “score” field denotes a concrete score that assesses whether each task
    can solve the given step’s demand. The score should be in the range of $[1,2,3,4,5]$,
    where a higher score indicates better task-solving and matching abilities.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. “score”字段表示评估每个任务是否能够解决给定步骤需求的具体分数。分数应在 $[1,2,3,4,5]$ 范围内，其中分数越高表示任务的解决和匹配能力越强。
- en: '3\. Carefully consider the user’s intention in # STEP # to assign the score.
    If the # STEP # contains a candidate task, its score should be >= 3\.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '3\. 仔细考虑 # STEP # 中用户的意图来分配分数。如果 # STEP # 包含候选任务，其分数应 >= 3\。'
- en: 'EXAMPLE #'
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'EXAMPLE #'
- en: '{{ in-context learning examples }}'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 上下文学习示例 }}'
- en: 'STEP #'
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'STEP #'
- en: '{{ step description }}'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 步骤描述 }}'
- en: 'Now please generate your result in a strict JSON format: # RESULT # |'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '现在请以严格的 JSON 格式生成您的结果：# RESULT # |'
- en: '| Path Selection | # GOAL # Based on the provided # USER REQUEST # and initially
    inferred # STEPS #, select the best path solution list from # SOLUTION LIST #.
    The selected solution should be the one that can perfectly solve the user’s request
    and strictly align with the inferred steps. The output must be in strict JSON
    format, like: $\{$ “best_solution”: $[$list of invoked tasks $]\}$'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '| 路径选择 | # GOAL # 基于提供的 # USER REQUEST # 和最初推断的 # STEPS #，从 # SOLUTION LIST
    # 中选择最佳路径解决方案列表。所选解决方案应能够完美解决用户请求，并严格与推断的步骤一致。输出必须严格遵循 JSON 格式，如：$\{$ “best_solution”:
    $[$调用任务列表 $]\}$'
- en: 'REQUIREMENTS #'
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'REQUIREMENTS #'
- en: 1\. Carefully analyze both the user’s request and previously inferred task steps.
    Select the best solution that can perfectly follow the inferred steps and solve
    user’s request. Do not change their corresponding sequences.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 仔细分析用户的请求和先前推断的任务步骤。选择最适合完美遵循推断步骤并解决用户请求的最佳解决方案。不要更改它们对应的顺序。
- en: '2\. Make sure that each task in the final solution list exists in the valid
    # TASK LIST # {{ task list }}.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '2\. 确保最终解决方案列表中的每个任务都存在于有效的 # TASK LIST # {{ 任务列表 }} 中。'
- en: 'USER REQUEST #'
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'USER REQUEST #'
- en: '{{ user request }}'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 用户请求 }}'
- en: 'STEPS #'
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'STEPS #'
- en: '{{ steps }}'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 步骤 }}'
- en: 'SOLUTION LIST #'
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'SOLUTION LIST #'
- en: '{{ list of searched solutions }}'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 搜索解决方案列表 }}'
- en: 'Now please generate your result in a strict JSON format: # RESULT # |'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '现在请以严格的 JSON 格式生成您的结果：# RESULT # |'
- en: 'Table 6: Prompt template for LLM’s filling in invocation parameters [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：LLM 填充调用参数的提示模板 [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]
- en: '| # GOAL # Given a # USER REQUEST # and # PLANNED TASKS # to be invoked in
    sequence to solve this request, please fill up each invoked task’s invocation
    parameters. The format must be in strict JSON format, like:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '| # GOAL # 给定 # USER REQUEST # 和 # PLANNED TASKS #，按顺序调用以解决该请求，请填写每个调用任务的调用参数。格式必须严格遵循
    JSON 格式，如：'
- en: $\{$
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: $\{$
- en: '${\color[rgb]{1,1,1}2}$ “task_nodes”: $[\{$'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}$ “task_nodes”: $[\{$'
- en: '${\color[rgb]{1,1,1}2}\quad$ “task”: “ task name must be from # PLANNED TASKS
    # ”,'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}\quad$ “task”: “任务名称必须来自 # PLANNED TASKS # ”，'
- en: '${\color[rgb]{1,1,1}2}\quad$ “arguments”: $[$ a concise list of arguments for
    this task $]$'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '${\color[rgb]{1,1,1}2}\quad$ “arguments”: $[$ 该任务的简洁参数列表 $]$'
- en: ${\color[rgb]{1,1,1}22}$$\},\ldots]$  ${\color[rgb]{1,1,1}2}$
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ${\color[rgb]{1,1,1}22}$$\},\ldots]$  ${\color[rgb]{1,1,1}2}$
- en: $\}$
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: $\}$
- en: 'REQUIREMENTS #'
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'REQUIREMENTS #'
- en: 1\. Consider each task’s input and output requirements, and carefully fill in
    the arguments for each task.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 考虑每个任务的输入和输出要求，并仔细填写每个任务的参数。
- en: 2\. Analyze the resource dependencies, keeping in mind that these tasks are
    invoked sequentially to address the original request.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 分析资源依赖关系，记住这些任务是按顺序调用的，以解决原始请求。
- en: 3\. The number of predicted task_nodes must strictly align with the provided
    tasks.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 预测的任务节点数量必须严格与提供的任务对齐。
- en: 'USER REQUEST #'
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '用户请求 #'
- en: '{{ user request }}'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 用户请求 }}'
- en: 'PLANNED TASKS #'
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '计划任务 #'
- en: '{{ a list of previously GNN retrieved tasks }}'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 先前通过GNN检索的任务列表 }}'
- en: 'DETAILS OF TASKS #'
  id: totrans-390
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '任务细节 #'
- en: '{{ details, i.e., input and output requirements of each planned task }}'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 任务的详细信息，例如每个计划任务的输入和输出要求 }}'
- en: 'EXAMPLE #'
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '示例 #'
- en: '{{ in-context learning examples }} Now, please generate your response in a
    strict JSON format: # RESULT # |'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '{{ 上下文学习示例 }} 现在，请以严格的JSON格式生成您的响应：# 结果 # |'
- en: Appendix C Datasets
  id: totrans-394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 数据集
- en: C.1 Overview
  id: totrans-395
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.1 概述
- en: We provide the statistics of experimental datasets from three task planning
    benchmarks in Table [7](https://arxiv.org/html/2405.19119v3#A3.T7 "Table 7 ‣ C.2
    Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?"). The illustrative examples from each dataset are
    shown in Figure [4](https://arxiv.org/html/2405.19119v3#A3.F4 "Figure 4 ‣ C.2
    Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?"). For datasets from TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)],
    each sample consists of original user request, corresponding decomposed task steps,
    and ground-truth task invocation path. As RestBench [[50](https://arxiv.org/html/2405.19119v3#bib.bib50)]
    and UltraTool [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)] include only
    user requests and corresponding API invocation sequences, we prompt GPT-4 to infer
    decomposed task steps aligned with each invoked API, thereby finalizing the dataset.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在表格[7](https://arxiv.org/html/2405.19119v3#A3.T7 "Table 7 ‣ C.2 Reformatting
    Details of RestBench ‣ Appendix C Datasets ‣ Can Graph Learning Improve Planning
    in LLM-based Agents?")中提供了来自三个任务规划基准的实验数据集统计信息。每个数据集的示例在图[4](https://arxiv.org/html/2405.19119v3#A3.F4
    "Figure 4 ‣ C.2 Reformatting Details of RestBench ‣ Appendix C Datasets ‣ Can
    Graph Learning Improve Planning in LLM-based Agents?")中展示。来自TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]的数据集中的每个样本包含原始用户请求、相应的任务分解步骤和真实任务调用路径。由于RestBench
    [[50](https://arxiv.org/html/2405.19119v3#bib.bib50)]和UltraTool [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)]仅包含用户请求和相应的API调用序列，我们提示GPT-4推断与每个调用的API对齐的分解任务步骤，从而最终确定数据集。
- en: C.2 Reformatting Details of RestBench
  id: totrans-397
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2 RestBench 重新格式化细节
- en: 'The TMDB dataset from RestBench, focuses on movie-related searching and recommending
    functions. To align RestBench with our experiments, we have implemented the following
    processing steps:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: RestBench中的TMDB数据集专注于电影相关的搜索和推荐功能。为了将RestBench与我们的实验对齐，我们实施了以下处理步骤：
- en: 'Reformatting original APIs by assigning unique task names and descriptions:
    APIs in RestBench were represented by request paths, such as “GET /movie/top_rated”,
    referring to the API that retrieves top-rated movies on TMDB. To enhance semantic
    differentiation among APIs, we first prompt GPT-4 to assign a unique name and
    a detailed functional description to each API. These names and descriptions were
    then manually verified and refined. For example, the API previously mentioned
    is renamed “Get Top-Rated Movies” with the description: “This API retrieves a
    list of the highest-rated movies.” Note that though the original TMDB dataset
    contains $54$ APIs, some were never invoked in any data examples. Therefore, we
    focus only on those APIs that appeared in at least one user request, resulting
    in a refined set of $46$ APIs.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分配唯一的任务名称和描述重新格式化原始API：RestBench中的API通过请求路径表示，例如“GET /movie/top_rated”，指的是检索TMDB上排名最高电影的API。为了增强API之间的语义区分，我们首先提示GPT-4为每个API分配一个唯一的名称和详细的功能描述。这些名称和描述随后经过人工验证和完善。例如，前面提到的API被重命名为“获取排名最高的电影”，描述为：“该API检索最高评分电影的列表。”请注意，尽管原始TMDB数据集包含$54$个API，但其中一些API在任何数据示例中都未被调用。因此，我们只关注那些至少出现在一个用户请求中的API，最终得到一个精炼的$46$个API集。
- en: 'Constructing a Task Graph: Each API is regarded as a unique task node, and
    we depict their relationships from two aspects: (1) categorical association, and
    (2) resource dependencies. For instance, APIs that provide movie-related functionalities,
    such as retrieving movie details or recommending films, are grouped under the
    *movie* category. Conversely, APIs focused on person-related functions, like searching
    for actors, are classified under the *person* category. Additionally, if two APIs
    share a common parameter like move_id, we establish a link between them to indicate
    a resource dependency.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 构建任务图：每个 API 被视为一个独立的任务节点，我们从两个方面描述它们之间的关系：（1）类别关联，（2）资源依赖。例如，提供与电影相关功能的 API，如获取电影详情或推荐电影，归类为*电影*类别。相反，专注于人物相关功能的
    API，如搜索演员，归类为*人物*类别。此外，如果两个 API 共享一个共同的参数，如 move_id，我们会在它们之间建立一个连接，表示资源依赖。
- en: 'Reformatting Raw Data Examples: The original data samples in RestBench included
    a single query and its corresponding API invocation sequence. To reformat this
    data into a path structure, we treated each invoked API as a node and the sequence
    of invocations as directed links from one API to the next. For example, a TMDB
    data sample consists of the query “Who was the lead actor in the movie The Dark
    Knight” and corresponding ground-truth API solution $[$“GET /search/movie”, “GET
    /movie/{movie_id}/credits”$]$. We transform this solution into a task invocation
    path as “$\{$ “task_nodes”: $[$“Search Movie”, “Get Movie Credit”$]$, “task_links”:
    $[\{$“source”: “Search Movie”, “target”: “Get Movie Credit”$\}]\}$ ”.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '重构原始数据示例：RestBench 中的原始数据样本包括一个查询及其对应的 API 调用序列。为了将这些数据重构为路径结构，我们将每个调用的 API
    视为一个节点，并将调用序列视为从一个 API 到下一个 API 的有向链接。例如，一个 TMDB 数据样本包括查询“电影《黑暗骑士》的主演是谁”以及相应的真实
    API 解决方案 $[$“GET /search/movie”, “GET /movie/{movie_id}/credits”$]$。我们将这个解决方案转换为任务调用路径，表示为“$\{$
    “task_nodes”: $[$“搜索电影”, “获取电影演员”$]$, “task_links”: $[\{$“source”: “搜索电影”, “target”:
    “获取电影演员”$\}]\}$ ”。'
- en: 'Table 7: Statistics of Experimental Datasets'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7：实验数据集的统计信息
- en: '|  |  | TaskBench | RestBench |  |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '|  |  | TaskBench | RestBench |  |'
- en: '| Type | Statistic | HuggingFace | Multimedia | Daily Life | TMDB | UltraTool
    |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 统计信息 | HuggingFace | 多媒体 | 日常生活 | TMDB | UltraTool |'
- en: '| Task Graph | # Node | 23 | 40 | 40 | 46 | 260 |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 任务图 | # 节点数 | 23 | 40 | 40 | 46 | 260 |'
- en: '| # Links | 225 | 449 | 1560 | 979 | 611 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| # 链接数 | 225 | 449 | 1560 | 979 | 611 |'
- en: '| Link Type | Resource | Resource | Temporal | Resource / Category | Resource
    |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 链接类型 | 资源 | 资源 | 时间 | 资源 / 类别 | 资源 |'
- en: '| All Data | # Samples | 7,546 | 5,584 | 4,320 | 100 | 3,527 |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 所有数据 | # 样本数 | 7,546 | 5,584 | 4,320 | 100 | 3,527 |'
- en: '| Test Set | # Samples | 500 | 500 | 500 | 94 | 500 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 测试集 | # 样本数 | 500 | 500 | 500 | 94 | 500 |'
- en: '| # Avg Nodes | 3.81 | 3.92 | 4.05 | 2.33 | 2.38 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| # 平均节点数 | 3.81 | 3.92 | 4.05 | 2.33 | 2.38 |'
- en: '| # Avg Links | 2.81 | 2.92 | 3.05 | 1.33 | 1.38 | ![Refer to caption](img/d19fff558cc3f6e1ee85440811753445.png)'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '| # 平均链接数 | 2.81 | 2.92 | 3.05 | 1.33 | 1.38 | ![参见说明](img/d19fff558cc3f6e1ee85440811753445.png)'
- en: 'Figure 4: Illustrative details of experimental datasets.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：实验数据集的详细说明。
- en: C.3 Reformatting Details of UltraTool
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.3 UltraTool 的重构细节
- en: 'Motivation: In our main experiments using TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]
    and RestBench [[50](https://arxiv.org/html/2405.19119v3#bib.bib50)], we observed
    that strong LLMs like GPT-4-turbo already perform well. This may be attributed
    to two factors: (1) the training of GPT-4-turbo likely included knowledge relevent
    to these benchmarks, as both were released before GPT-4 and utilize popular platforms
    such as HuggingFace and TMDB; (2) the task graphs are relatively small, containing
    no more than $50$ tasks, which falls within the capabilities of LLMs. Therefore,
    we aim to evacuate planning performance as well as GNN’s effectiveness in a more
    challenging scenario, i.e., one that requires specific knowledge beyond the LLM’s
    training and involves larger task graphs that possibly exceed its memory and reasoning
    capabilities.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 动机：在我们使用 TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)] 和 RestBench
    [[50](https://arxiv.org/html/2405.19119v3#bib.bib50)] 进行的主要实验中，我们观察到像 GPT-4-turbo
    这样的强大 LLM 已经表现得非常好。这可能归因于两个因素：（1）GPT-4-turbo 的训练可能包含了与这些基准相关的知识，因为这两个基准在 GPT-4
    发布之前就已经发布，并且使用了 HuggingFace 和 TMDB 等流行平台；（2）任务图相对较小，最多包含$50$个任务，属于 LLM 的能力范围。因此，我们旨在通过更具挑战性的场景来评估规划性能以及
    GNN 的有效性，即需要超出 LLM 训练的特定知识，并涉及较大的任务图，可能超出了其记忆和推理能力。
- en: 'Constructing a Task Graph: We utilized UltraTool [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)],
    released in March 2024, which features complex planning scenarios across thousands
    of tasks, including travel, tourism, and other daily life domains. The original
    UltraTool contains $5,824$ samples with $2,032$ available tasks across $22$ distinct
    domains. However, we observed that some tasks appear in only one sample, making
    them quite rare. Therefore, we filtered this dataset as follows: first, we considered
    only tasks that appeared more than $5$ times across all samples, focusing on more
    common tasks that cater to daily life. Next, we retained samples that incorporated
    these filtered tasks, ensuring that the number of invoked tasks exceeded 2 to
    satisfy the multi-task planning scenario. After this filtering, we identified
    $260$ distinct tasks. We then constructed the task graph by treating each task
    as a node and adding links between tasks that were invoked sequentially in the
    dataset. For each task, we further verified and refined its functional descriptions
    to ensure semantic suitability.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 构建任务图：我们使用了UltraTool [[20](https://arxiv.org/html/2405.19119v3#bib.bib20)]，该工具于2024年3月发布，包含了跨越成千上万任务的复杂规划场景，包括旅行、旅游和其他日常生活领域。原始的UltraTool包含$5,824$个样本和$2,032$个可用任务，涵盖$22$个不同领域。然而，我们观察到某些任务只出现在一个样本中，使得它们相当稀有。因此，我们按以下方式过滤了这个数据集：首先，我们只考虑那些在所有样本中出现超过$5$次的任务，专注于更常见的、适用于日常生活的任务。接下来，我们保留了包含这些过滤任务的样本，确保调用的任务数量超过2个，以满足多任务规划场景。经过此过滤后，我们确定了$260$个不同的任务。然后，我们通过将每个任务视为一个节点，构建任务图，并在数据集中按顺序调用的任务之间添加连接。对于每个任务，我们进一步验证和完善其功能描述，以确保语义的适用性。
- en: 'Reformatting Raw Data Examples: We allocated $500$ samples for testing and
    $3,000$ samples for GNN training. Although the original UltraTool provided decomposed
    steps, we found them too coarse-grained, making it difficult to align step descriptions
    with suitable tasks. Therefore, we employed a similar strategy by prompting GPT-4
    to infer decomposed task steps that align with each invoked task. As a result,
    each data sample consists of the user request, corresponding steps, and ground-truth
    invoked tasks, ensuring high quality for GNN training.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据重构示例：我们分配了$500$个样本用于测试，$3,000$个样本用于GNN训练。尽管原始的UltraTool提供了分解的步骤，我们发现这些步骤过于粗糙，难以将步骤描述与合适的任务对齐。因此，我们采用了类似的策略，通过提示GPT-4推断出与每个调用的任务对齐的分解任务步骤。结果是，每个数据样本包含了用户请求、相应的步骤以及实际调用的任务，确保了GNN训练的高质量。
- en: Appendix D Supplementary Materials for Theoretical Results
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录D 理论结果的补充材料
- en: D.1 Dynamic Programming
  id: totrans-418
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.1 动态规划
- en: 'Longest Increasing Subsequence: The Longest Increasing Subsequence (LIS) problem
    is a classic dynamic programming problem that involves finding the length of the
    longest subsequence within a given array arr where the elements are in strictly
    increasing order. The state transition function for the LIS problem can be expressed
    as:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 最长递增子序列：最长递增子序列（LIS）问题是一个经典的动态规划问题，涉及在给定的数组arr中找到最长子序列的长度，其中元素按严格递增的顺序排列。LIS问题的状态转移函数可以表示为：
- en: '|  | $\displaystyle\text{Answer}[k][i]=\max_{j\in\mathcal{T}(i)}(\text{Answer}[k-1][%
    j]+(\mathbb{I}(j\neq i)\times 1)),$ |  |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{Answer}[k][i]=\max_{j\in\mathcal{T}(i)}(\text{Answer}[k-1][%
    j]+(\mathbb{I}(j\neq i)\times 1)),$ |  |'
- en: where $\mathcal{T}(i)=\{i\}\cup\{j\;|j<i\;\text{and}\;\texttt{arr}[j]<\texttt{arr}[i]\}$
    denotes the set of states that can transfer to state $i$, the aggregation function
    $g(x,y)$ is implemented as $\max(x,y)$, and the cost $c[i][j]$ is $1$ for those
    candidate states that are not equal to state $i$ as adding the element leads to
    a longer subsequence while $0$ for the state itself.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\mathcal{T}(i)=\{i\}\cup\{j\;|j<i\;\text{且}\;\texttt{arr}[j]<\texttt{arr}[i]\}$表示可以转移到状态$i$的状态集合，聚合函数$g(x,y)$被实现为$\max(x,y)$，而成本$c[i][j]$对于那些不等于状态$i$的候选状态为$1$，因为添加该元素会导致更长的子序列，而对于状态本身则为$0$。
- en: 'Bellman-Ford Algorithm: The Bellman-Ford algorithm is also a classic dynamic
    programming algorithm used to find the shortest paths from a single source vertex
    to all other vertices in a weighted graph. The core idea behind the Bellman-Ford
    algorithm is that the distance from the source vertex to a target vertex can be
    computed as the minimum distance from the source to any of the target’s neighboring
    vertices, plus the weight of the edge connecting the neighbor to the target. Therefore,
    the state transition function for the Bellman-Ford algorithm can be expressed
    as:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 贝尔曼-福特算法：贝尔曼-福特算法也是一种经典的动态规划算法，用于在加权图中找到从单个源顶点到所有其他顶点的最短路径。贝尔曼-福特算法背后的核心思想是，从源顶点到目标顶点的距离可以通过从源顶点到目标邻居的最短距离再加上连接邻居和目标的边的权重来计算。因此，贝尔曼-福特算法的状态转移函数可以表示为：
- en: '|  | $\displaystyle\text{Answer}[k][i]=\min_{j\in\mathcal{T}(i)}(\text{Answer}[k-1][%
    j]+w[j][i]),$ |  |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{Answer}[k][i]=\min_{j\in\mathcal{T}(i)}(\text{Answer}[k-1][j]+w[j][i]),$
    |  |'
- en: where $\text{Answer}[k][i]$ represents the length of the shortest path from
    the source vertex to node $i$ at the $k$-th iteration, $\mathcal{T}(i)=\mathcal{N}^{-}(i)$
    denotes the set of in-neighbors of node $i$, and $w[j][i]$ denotes the weight
    from node $j$ to $i$. The aggregation function $g(x,y)$ is implemented as $\min(x,y)$
    as we try to find the shortest path.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\text{Answer}[k][i]$表示从源顶点到节点$i$在第$k$次迭代中的最短路径长度，$\mathcal{T}(i)=\mathcal{N}^{-}(i)$表示节点$i$的入邻居集合，$w[j][i]$表示从节点$j$到$i$的权重。聚合函数$g(x,y)$被实现为$\min(x,y)$，因为我们尝试找到最短路径。
- en: 'Travelling Salesman Problem (TSP): This problem is defined as, given a set
    of cities and the distances between every pair of cities, finding the shortest
    possible route that visits every city exactly once and returns to the starting
    point. If we regard the set of already visited city $\mathcal{S}$ ending at $i$-th
    city as the current state, then states that can transfer to current state are
    those that ending city can reach $k$. Therefore, the state transition function
    for the TSP problem can be expressed as:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 旅行商问题（TSP）：该问题的定义是，给定一组城市和每对城市之间的距离，找出一条最短的路径，该路径恰好访问每个城市一次并返回起点。如果我们将已经访问的城市集合$\mathcal{S}$以第$i$个城市作为结束城市视为当前状态，那么可以转移到当前状态的状态是那些可以到达结束城市的$k$个城市。因此，TSP问题的状态转移函数可以表示为：
- en: '|  | $\displaystyle\text{Answer}[k][i][\mathcal{S}]=\min_{j\in\mathcal{S},j\neq
    i}(% \text{Answer}[k-1][j][\mathcal{S}\setminus\{i\}]+w[j][i]),$ |  |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\text{Answer}[k][i][\mathcal{S}]=\min_{j\in\mathcal{S},j\neq
    i}(\text{Answer}[k-1][j][\mathcal{S}\setminus\{i\}]+w[j][i]),$ |  |'
- en: where $\text{Answer}[k][i][\mathcal{S}]$ represents the cost of the shortest
    tour that visits all the cities in the set $\mathcal{S}$ and ends at the $i$-th
    city, the aggregation function $g(x,y)$ is still implemented as $\min(x,y)$ since
    we aim to find the shortest path, and $w[j][i]$ denotes the distance from city
    $j$ to city $i$.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\text{Answer}[k][i][\mathcal{S}]$表示访问集合$\mathcal{S}$中所有城市并以第$i$个城市为终点的最短路径的成本，聚合函数$g(x,y)$仍然实现为$\min(x,y)$，因为我们的目标是找到最短路径，$w[j][i]$表示从城市$j$到城市$i$的距离。
- en: 'D.2 Proof of Theorem [1](https://arxiv.org/html/2405.19119v3#Thmtheorem1 "Theorem
    1\. ‣ 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-428
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.2 定理[1](https://arxiv.org/html/2405.19119v3#Thmtheorem1 "定理 1\. ‣ 3.3 LLMs在规划中的失败：理论洞察
    ‣ 3 图的形式化与洞察 ‣ 图学习能否改善基于LLM的智能体规划？")的证明
- en: Assumption 1.
  id: totrans-429
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 假设 1.
- en: 'Each function $f,g$ in ([2](https://arxiv.org/html/2405.19119v3#S3.E2 "In 3.3
    Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation and Insights
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) can be approximated
    by constant size MLP.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 每个函数$f,g$在([2](https://arxiv.org/html/2405.19119v3#S3.E2 "在 3.3 LLMs在规划中的失败：理论洞察
    ‣ 3 图的形式化与洞察 ‣ 图学习能否改善基于LLM的智能体规划？"))中都可以通过常数大小的MLP来逼近。
- en: Assumption 2.
  id: totrans-431
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 假设 2.
- en: 'The aggregation function $\square$ in ([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) is
    one of min, max, sum, mean.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合函数$\square$在([2](https://arxiv.org/html/2405.19119v3#S3.E2 "在 3.3 LLMs在规划中的失败：理论洞察
    ‣ 3 图的形式化与洞察 ‣ 图学习能否改善基于LLM的智能体规划？"))中是min、max、sum、mean之一。
- en: The first assumption is mild as MLPs are universal approximators. The second
    assumption is mild because these are the most commonly used aggregation functions.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个假设是温和的，因为多层感知机（MLPs）是通用逼近器。第二个假设是温和的，因为这些是最常用的聚合函数。
- en: Theorem 3.
  id: totrans-434
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 3.
- en: '(Expressiveness) Assume the input format is given in ([1](https://arxiv.org/html/2405.19119v3#S3.E1
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) and
    $f,g,\square$ in DP update ([2](https://arxiv.org/html/2405.19119v3#S3.E2 "In
    3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation and
    Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) satisfy
    the assumptions [1](https://arxiv.org/html/2405.19119v3#Thmassumption1 "Assumption
    1\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and [2](https://arxiv.org/html/2405.19119v3#Thmassumption2
    "Assumption 2\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials
    for Theoretical Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?").
    There exists a log-precision constant-depth and constant-width Transformer that
    simulates $1$ steps of DP update in ([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")). As
    a consequence, there exists a log-precision $O(k)$-depth and constant-width Transformer
    that simulates $k$ steps of DP update in ([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")).'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: （表达能力）假设输入格式给定于 ([1](https://arxiv.org/html/2405.19119v3#S3.E1 "在 3.3 LLMs 在规划中的失败：理论见解
    ‣ 3 图形公式和见解 ‣ 图学习能否改善基于 LLM 的代理的规划？")) 且 $f,g,\square$ 在 DP 更新中 ([2](https://arxiv.org/html/2405.19119v3#S3.E2
    "在 3.3 LLMs 在规划中的失败：理论见解 ‣ 3 图形公式和见解 ‣ 图学习能否改善基于 LLM 的代理的规划？")) 满足假设 [1](https://arxiv.org/html/2405.19119v3#Thmassumption1
    "假设 1. ‣ D.2 定理 1 的证明 ‣ 附录 D 理论结果的补充材料 ‣ 图学习能否改善基于 LLM 的代理的规划？") 和 [2](https://arxiv.org/html/2405.19119v3#Thmassumption2
    "假设 2. ‣ D.2 定理 1 的证明 ‣ 附录 D 理论结果的补充材料 ‣ 图学习能否改善基于 LLM 的代理的规划？")。存在一个对数精度、恒定深度和恒定宽度的
    Transformer，可以模拟 ([2](https://arxiv.org/html/2405.19119v3#S3.E2 "在 3.3 LLMs 在规划中的失败：理论见解
    ‣ 3 图形公式和见解 ‣ 图学习能否改善基于 LLM 的代理的规划？")) 中的 $1$ 步 DP 更新。因此，存在一个对数精度、$O(k)$ 深度和恒定宽度的
    Transformer，可以模拟 ([2](https://arxiv.org/html/2405.19119v3#S3.E2 "在 3.3 LLMs 在规划中的失败：理论见解
    ‣ 3 图形公式和见解 ‣ 图学习能否改善基于 LLM 的代理的规划？")) 中的 $k$ 步 DP 更新。
- en: Proof.
  id: totrans-436
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: 'Token Embedding and Positional Embedding: The three-dimensional token embedding
    includes the token type $e^{\text{type1}}$ ($0$ for answer; $1$ for node; $2$
    for edge cost), refined token type $e^{\text{type2}}$ ($0$ for answer, $1$ for
    the node tokens in initial states, $2$ for the target node tokens in the edge
    list, $3$ for the source node tokens in the edge list, $4$ for edge cost), and
    the token id $e^{\text{token}}$ (from $0$ to $|V|-1$). The two-dimensional positional
    embedding includes the embedding for initial state tokens $e^{\text{pos1}}$ ($0$
    for edge list tokens, $1$ for the first two elements of initial states, $2$ for
    the second two elements of initial states, etc.), embedding for edge list tokens
    $e^{\text{pos2}}$ ($0$ for initial state tokens, $1$ for the first three elements
    of the edge list, $2$ for the second three elements of the edge list, etc.). There
    are also constant-dimensional placeholders to put the states of DP.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌嵌入和位置嵌入：三维令牌嵌入包括令牌类型 $e^{\text{type1}}$ （$0$ 表示答案；$1$ 表示节点；$2$ 表示边的代价），精细化的令牌类型
    $e^{\text{type2}}$ （$0$ 表示答案，$1$ 表示初始状态中的节点令牌，$2$ 表示边列表中的目标节点令牌，$3$ 表示边列表中的源节点令牌，$4$
    表示边的代价），以及令牌 ID $e^{\text{token}}$ （从 $0$ 到 $|V|-1$）。二维位置嵌入包括初始状态令牌的嵌入 $e^{\text{pos1}}$
    （$0$ 表示边列表令牌，$1$ 表示初始状态的前两个元素，$2$ 表示初始状态的第二对元素，以此类推），边列表令牌的嵌入 $e^{\text{pos2}}$
    （$0$ 表示初始状态令牌，$1$ 表示边列表的前三个元素，$2$ 表示边列表的第二组三个元素，以此类推）。还有常数维度的占位符，用于存放 DP 的状态。
- en: 'Block 1 - Initial State Broadcast: The goal of the first block is to broadcast
    the initial states from the initial state token to node tokens. (1) Use MLPs to
    recover the digits of the answer tokens and put them in the first placeholder
    if $e^{type}_{k}==0$; (2) Copy the first placeholder from answer token to its
    previous node token by using COPY in Lemma [1](https://arxiv.org/html/2405.19119v3#Thmlemma1
    "Lemma 1\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and setting
    $\mathcal{S}_{k}=\{j|(e^{\text{pos1}}_{k}-e^{\text{pos1}}_{j})^{2}<\delta\}$;
    (3) Broadcast the first placeholder with SUM in Lemma [1](https://arxiv.org/html/2405.19119v3#Thmlemma1
    "Lemma 1\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and setting
    $\mathcal{S}_{k}=\{j|(e^{\text{type1}}_{k}-e^{\text{type1}}_{j})^{2}+(e^{\text{%
    token}}_{k}-e^{\text{token}}_{j})^{2}<\delta\}$. Now the state for every node
    token $u_{i}$ is $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[0][u_{i}]]$.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 块 1 - 初始状态广播：第一块的目标是将初始状态从初始状态标记传递到节点标记。(1) 使用多层感知机（MLPs）恢复答案标记的数字，并在$e^{type}_{k}==0$时将其放入第一个占位符；(2)
    使用引理[1](https://arxiv.org/html/2405.19119v3#Thmlemma1 "引理 1． ‣ D.2 定理 1 的证明 ‣
    附录 D 理论结果的补充材料 ‣ 图学习能改善基于LLM的智能体规划吗？")，通过复制答案标记的第一个占位符到其前一个节点标记，并设置$\mathcal{S}_{k}=\{j|(e^{\text{pos1}}_{k}-e^{\text{pos1}}_{j})^{2}<\delta\}$；(3)
    使用引理[1](https://arxiv.org/html/2405.19119v3#Thmlemma1 "引理 1． ‣ D.2 定理 1 的证明 ‣
    附录 D 理论结果的补充材料 ‣ 图学习能改善基于LLM的智能体规划吗？")，通过SUM操作广播第一个占位符，并设置$\mathcal{S}_{k}=\{j|(e^{\text{type1}}_{k}-e^{\text{type1}}_{j})^{2}+(e^{\text{%
    token}}_{k}-e^{\text{token}}_{j})^{2}<\delta\}$。现在每个节点标记$u_{i}$的状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[0][u_{i}]]$。
- en: 'Block 2 - Edge Feature Operations: The goal of the second block is to copy
    the edge features from the edge feature token to the corresponding node tokens.
    (1) Use MLPs to recover the digits of the edge feature tokens and put them in
    the second placeholder if $e^{\text{type1}}==2$; (2) Copy the second placeholder
    from the edge feature token to the node token by using SUM in Lemma [1](https://arxiv.org/html/2405.19119v3#Thmlemma1
    "Lemma 1\. ‣ D.2 Proof of Theorem 1 ‣ Appendix D Supplementary Materials for Theoretical
    Results ‣ Can Graph Learning Improve Planning in LLM-based Agents?") and setting
    $\mathcal{S}_{k}=\{j|(e^{\text{pos2}}_{k}-e^{\text{pos2}}_{j})^{2}<\delta\}$.
    Now the state for every node token $u_{i}$ of the $i$-th edge is $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[0][u_{i}],c[u_{i}][v_{i}]]$.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 块 2 - 边特征操作：第二块的目标是将边特征从边特征标记复制到相应的节点标记。(1) 使用多层感知机（MLPs）恢复边特征标记的数字，并在$e^{\text{type1}}==2$时将其放入第二个占位符；(2)
    使用引理[1](https://arxiv.org/html/2405.19119v3#Thmlemma1 "引理 1． ‣ D.2 定理 1 的证明 ‣
    附录 D 理论结果的补充材料 ‣ 图学习能改善基于LLM的智能体规划吗？")，通过SUM操作将第二个占位符从边特征标记复制到节点标记，并设置$\mathcal{S}_{k}=\{j|(e^{\text{pos2}}_{k}-e^{\text{pos2}}_{j})^{2}<\delta\}$。现在每个节点标记$u_{i}$的状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[0][u_{i}],c[u_{i}][v_{i}]]$。
- en: 'Block 3 - Message Preparation: (1) Use MLPs to compute $g$ and place the results
    in the third placeholder. Now the state for every node token $u_{i}$ of the $i$-th
    edge is $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[0][u_{i}],c[u_{i}][v_{i}],g(\text{Answer}[0][u_{i}],c[u_{%
    i}][v_{i}])]$; (2) Use MLPs to clean up the first and second placeholder. Now
    the state for every node token $u_{i}$ is $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},g(\text{Answer}[0][u_{i}],c[u_{i}][v_{i}])]$'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 块 3 - 消息准备：(1) 使用多层感知机（MLPs）计算$g$并将结果放入第三个占位符。现在每个节点标记$u_{i}$的状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[0][u_{i}],c[u_{i}][v_{i}],g(\text{Answer}[0][u_{i}],c[u_{%
    i}][v_{i}])]$；(2) 使用多层感知机（MLPs）清理第一个和第二个占位符。现在每个节点标记$u_{i}$的状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},g(\text{Answer}[0][u_{i}],c[u_{i}][v_{i}])]$
- en: 'Block 4 - Message Passing: The goal of the fourth block is to compute $\square$
    and $f$. (1) Use one or two attention heads (one for max, min, mean aggregations,
    and two for sum aggregations) to perform the aggregation operation. This is achieved
    by using MEAN or MAX or SUM for the first placeholder and setting $\mathcal{S}_{k}=\{j|(e^{\text{token}}_{k}-e^{\text{token}}_{j})^{2}+(e^{\text{%
    type2}}_{k}-e^{\text{type2}}_{j})^{2}<\delta\}$. Now the state for every node
    token $u_{i}$ is $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\square_{v_{j}\in\mathcal{T}(u_{i})}g(\text{Answer}[0][u_{i}],c[u_{i}][%
    v_{j}])]$; (2) Use MLPs to compute $f$. Now the state for every node token is
    $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},f(\square_{v_{j}\in\mathcal{T}(i)}g(\text{Answer}[0][u_{i}],c[u_{i}][v_%
    {j}]))]$.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 第四块 - 消息传递：第四块的目标是计算$\square$和$f$。(1) 使用一个或两个注意力头（一个用于最大值、最小值、均值聚合，两个用于求和聚合）执行聚合操作。这是通过使用MEAN或MAX或SUM作为第一个占位符，并设置$\mathcal{S}_{k}=\{j|(e^{\text{token}}_{k}-e^{\text{token}}_{j})^{2}+(e^{\text{%
    type2}}_{k}-e^{\text{type2}}_{j})^{2}<\delta\}$来实现的。现在每个节点的状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\square_{v_{j}\in\mathcal{T}(u_{i})}g(\text{Answer}[0][u_{i}],c[u_{i}][%
    v_{j}])]$；(2) 使用MLP计算$f$。现在每个节点的状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},f(\square_{v_{j}\in\mathcal{T}(i)}g(\text{Answer}[0][u_{i}],c[u_{i}][v_%
    {j}]))]$。
- en: After four blocks, the final state for every node token $u_{i}$ is given by
    $[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[1][u_{i}]]$. $\text{Answer}[k][u_{i}]$ can be obtained by
    repeating the above four blocks $k$ times.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 经历四个块后，每个节点的最终状态是$[e^{\text{type1}},e^{\text{type2}},e^{\text{token}},e^{\text{pos1}},e^{\text{%
    pos2}},\text{Answer}[1][u_{i}]]$。$\text{Answer}[k][u_{i}]$可以通过重复上述四个块$k$次得到。
- en: ∎
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: ∎
- en: Lemma 1.
  id: totrans-444
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 引理 1.
- en: '[[12](https://arxiv.org/html/2405.19119v3#bib.bib12)] Let $n\in\mathbb{N}$
    be an integer and $\bm{x}_{1},\cdots,\bm{x}_{n}$ be a sequence of vectors where
    $\bm{x}_{i}=(\tilde{\bm{x}}_{i},r_{i},1)\in[-M,M]^{d+2}$ where $M$ is a large
    constant. Let $\bm{K},\bm{Q},\bm{V}\in\mathbb{R}^{d^{\prime}\times(d+2)}$ be any
    matrices with $\|\bm{V}\|_{\infty}\leq 1$ and let $0<\rho,\delta<M$ be any real
    numbers. Denote $\bm{q}_{i}=\bm{Q}\bm{x}_{i},\bm{k}_{j}=\bm{K}\bm{x}_{i},\bm{v}_{j}=\bm{V}\bm{x%
    }_{j}$. Define a matching set $\mathcal{S}=\{j||\bm{q}_{i}^{T}\bm{k}_{j}|\leq\rho\}$.
    Define two following operations'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '[[12](https://arxiv.org/html/2405.19119v3#bib.bib12)] 设$n\in\mathbb{N}$是一个整数，$\bm{x}_{1},\cdots,\bm{x}_{n}$是一个向量序列，其中$\bm{x}_{i}=(\tilde{\bm{x}}_{i},r_{i},1)\in[-M,M]^{d+2}$，$M$是一个大常数。设$\bm{K},\bm{Q},\bm{V}\in\mathbb{R}^{d^{\prime}\times(d+2)}$是任意矩阵，且$\|\bm{V}\|_{\infty}\leq
    1$，设$0<\rho,\delta<M$是任意实数。记$\bm{q}_{i}=\bm{Q}\bm{x}_{i},\bm{k}_{j}=\bm{K}\bm{x}_{i},\bm{v}_{j}=\bm{V}\bm{x%
    }_{j}$。定义一个匹配集$\mathcal{S}=\{j||\bm{q}_{i}^{T}\bm{k}_{j}|\leq\rho\}$。定义以下两种操作'
- en: •
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'COPY: The output is a sequence of vectors $\bm{u}_{1},\cdots,\bm{u}_{n}$ with
    $\bm{u}_{i}=\bm{v}_{\text{pos}(i)}$, where $\text{pos}(i)=\arg\max_{j\in\mathcal{S}_{i}}r_{j}$.'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: COPY：输出是一个向量序列$\bm{u}_{1},\cdots,\bm{u}_{n}$，其中$\bm{u}_{i}=\bm{v}_{\text{pos}(i)}$，其中$\text{pos}(i)=\arg\max_{j\in\mathcal{S}_{i}}r_{j}$。
- en: •
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MEAN, MAX, SUM: The output is a sequence of vectors $\bm{u}_{1},\cdots,\bm{u}_{n}$,
    where $\bm{u}_{i}=\square_{j\in\mathcal{S}_{i}}\bm{v}_{j}$ and $\square$ is min
    or max or sum or mean.'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MEAN, MAX, SUM：输出是一个向量序列$\bm{u}_{1},\cdots,\bm{u}_{n}$，其中$\bm{u}_{i}=\square_{j\in\mathcal{S}_{i}}\bm{v}_{j}$，$\square$可以是最小值、最大值、求和或均值。
- en: Specifically, for any sequence of vectors $\bm{x}_{1},\bm{x}_{2},\cdots,\bm{x}_{n}$,
    denote the corresponding output of the attention layer as $\bm{o}_{1},\bm{o}_{2},\cdots,\bm{o}_{n}$.
    Then, we have $\|\bm{u}_{i}-\bm{o}_{i}\|_{\infty}\leq\epsilon$ for all $i\in[n]$
    and $\mathcal{S}\neq\emptyset$.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，对于任意向量序列$\bm{x}_{1},\bm{x}_{2},\cdots,\bm{x}_{n}$，设对应的注意力层输出为$\bm{o}_{1},\bm{o}_{2},\cdots,\bm{o}_{n}$。然后，对于所有$i\in[n]$，我们有$\|\bm{u}_{i}-\bm{o}_{i}\|_{\infty}\leq\epsilon$，且$\mathcal{S}\neq\emptyset$。
- en: D.3 Permutation Invariance Test of LLMs
  id: totrans-451
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3 大型语言模型的排列不变性测试
- en: We test whether LLMs respect the permutation invariance property in graph problems
    and the results are given in Figure [5](https://arxiv.org/html/2405.19119v3#A4.F5
    "Figure 5 ‣ D.3 Permutation Invariance Test of LLMs ‣ Appendix D Supplementary
    Materials for Theoretical Results ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?").
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 我们测试大型语言模型是否在图问题中遵循排列不变性属性，结果见图[5](https://arxiv.org/html/2405.19119v3#A4.F5
    "图5 ‣ D.3 大型语言模型的排列不变性测试 ‣ 附录D 理论结果的补充材料 ‣ 图学习能否改善基于大型语言模型的规划？")。
- en: '![Refer to caption](img/082ba65d6417637a01e674144d944b55.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/082ba65d6417637a01e674144d944b55.png)'
- en: 'Figure 5: Illustrative Examples of LLMs Failure to Solve Graph Computational
    Problems under Permutation (i.e., node re-odering). Experiments were conducted
    for 30 times.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：在排列（即节点重新排序）下，LLMs 解决图计算问题失败的说明性示例。实验进行了 30 次。
- en: 'D.4 Proof of Proposition [1](https://arxiv.org/html/2405.19119v3#Thmproposition1
    "Proposition 1\. ‣ 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3
    Graph Formulation and Insights ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")'
  id: totrans-455
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4 命题[1](https://arxiv.org/html/2405.19119v3#Thmproposition1 "命题 1. ‣ 3.3 LLMs
    在规划中的失败：理论洞察 ‣ 3 图的表述和洞察 ‣ 图学习能否改善基于LLM的智能体的规划？")的证明。
- en: Proposition 2.
  id: totrans-456
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 命题 2。
- en: 'Assume the input format is as described in Equation ([1](https://arxiv.org/html/2405.19119v3#S3.E1
    "In 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")) and
    that the attention mechanism is limited to attending to a constant number of tokens.
    There exists at least one instance of one-step DP update such that no log-precision
    constant-width constant-depth transformer can simulate.'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输入格式如方程 ([1](https://arxiv.org/html/2405.19119v3#S3.E1 "在 3.3 LLMs 在规划中的失败：理论洞察
    ‣ 3 图的表述和洞察 ‣ 图学习能否改善基于LLM的智能体的规划？")) 中所述，并且注意力机制被限制为只能关注常数数量的标记。在此假设下，至少存在一个一步动态规划更新的实例，使得没有一个对数精度、常数宽度、常数深度的
    Transformer 可以模拟该过程。
- en: Proof.
  id: totrans-458
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: We present a proof by contradiction. Assume that a token in a Transformer with
    a constant depth, constant width, and log-precision can attend to only a constant
    number of nodes. Under this assumption, the total information accessible to the
    token in such a Transformer architecture amounts to $O(\log n)$ bits. However,
    for a graph with $|V|$ nodes, the number of possible outcomes from executing one-step
    DP is $O(e^{|V|})$, necessitating $\Theta(|V|)$ bits for representation. By the
    pigeonhole principle, this scenario inevitably leads to at least two distinct
    DP outcomes being represented by the same output sequence generated by the model,
    thereby constituting a contradiction. ∎
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过反证法来证明。假设一个具有常数深度、常数宽度和对数精度的 Transformer 中的标记只能关注常数数量的节点。在这一假设下，该 Transformer
    架构中标记能够访问的总信息量为 $O(\log n)$ 位。然而，对于一个包含 $|V|$ 个节点的图，执行一步动态规划的可能结果数量为 $O(e^{|V|})$，这需要
    $\Theta(|V|)$ 位进行表示。根据抽屉原理，这种情况不可避免地导致至少两个不同的动态规划结果被模型生成的相同输出序列所表示，从而形成矛盾。∎
- en: 'D.5 Proof of Theorem [2](https://arxiv.org/html/2405.19119v3#Thmtheorem2 "Theorem
    2\. ‣ 3.3 Failures of LLMs in Planning: Theoretical Insights ‣ 3 Graph Formulation
    and Insights ‣ Can Graph Learning Improve Planning in LLM-based Agents?")'
  id: totrans-460
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.5 定理[2](https://arxiv.org/html/2405.19119v3#Thmtheorem2 "定理 2. ‣ 3.3 LLMs
    在规划中的失败：理论洞察 ‣ 3 图的表述和洞察 ‣ 图学习能否改善基于LLM的智能体的规划？")的证明。
- en: Theorem 4.
  id: totrans-461
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定理 4。
- en: (Spurious correlations of auto-regressive loss) Assume (1) the loss employed
    is a next-token-prediction loss utilizing cross-entropy, applied to the sub-sequence
    $v_{1}\ v_{2}\ \cdots\ t$ during training; (2) the output logits are determined
    by target node $t$ and the current node $v_{i-1}$. Let $N_{t,v_{i-1},u}$ be the
    number of times in the training dataset such that $t$ is the target node, $v_{i-1}$
    is the current node and $v_{i}=u$ is the next node. The optimal logits for predicting
    the next node $u$ from current node $v_{i-1}$ towards target node $t$ is given
    by $\hat{\bm{v}}_{i}[u]=\frac{N_{t,v_{i-1},u}}{\sum_{u}N_{t,v_{i-1},u}}$ if $\sum_{u}N_{t,v_{i-1},u}>0$.
    If $\sum_{u}N_{t,v_{i-1},u}=0$, $\hat{\bm{v}}_{i}[u]$ can be any non-negative
    number subject to $\sum_{u}\hat{\bm{v}}_{i}[u]=1$.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: （自回归损失的虚假相关性）假设（1）所采用的损失是利用交叉熵的下一个标记预测损失，应用于训练过程中的子序列 $v_{1}\ v_{2}\ \cdots\
    t$；（2）输出对数值由目标节点 $t$ 和当前节点 $v_{i-1}$ 确定。设 $N_{t,v_{i-1},u}$ 为训练数据集中，$t$ 是目标节点，$v_{i-1}$
    是当前节点，且 $v_{i}=u$ 是下一个节点的次数。预测从当前节点 $v_{i-1}$ 到目标节点 $t$ 的下一个节点 $u$ 的最优对数值为 $\hat{\bm{v}}_{i}[u]=\frac{N_{t,v_{i-1},u}}{\sum_{u}N_{t,v_{i-1},u}}$，前提是
    $\sum_{u}N_{t,v_{i-1},u}>0$。如果 $\sum_{u}N_{t,v_{i-1},u}=0$，则 $\hat{\bm{v}}_{i}[u]$
    可以是任何非负数，且满足 $\sum_{u}\hat{\bm{v}}_{i}[u]=1$。
- en: Proof.
  id: totrans-463
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 证明。
- en: We denote $\mathcal{D}$ as the training dataset, $L_{i}$ as the sequence length
    of the $i$-th sequence in the dataset, $\bm{v}_{i,j}$ as the one hot embedding
    of the $j$-th token in the $i$-th training sequence, and $\hat{\bm{v}}_{i,j,u}$
    as the $u$-th logit at the $j$-th token in the $i$-th sequence. The cross-entropy
    loss is given by
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用$\mathcal{D}$表示训练数据集，用$L_{i}$表示数据集中第$i$个序列的长度，用$\bm{v}_{i,j}$表示第$i$个训练序列中第$j$个标记的one-hot嵌入，用$\hat{\bm{v}}_{i,j,u}$表示第$i$个序列中第$j$个标记的第$u$个logit。交叉熵损失由以下公式给出：
- en: '|  |  | $\displaystyle-\sum_{i\in[&#124;\mathcal{D}&#124;]}\sum_{j=4}^{L_{i}}\bm{v}_{i,j,u}\log%
    \hat{\bm{v}}_{i,j,u}=-\sum_{i\in[&#124;\mathcal{D}&#124;]}\sum_{j=4}^{L_{i}}\mathbb{I}_{%
    u=v_{i,j}}\log\hat{\bm{v}}_{i,j,u}\overset{(a)}{=}-\sum_{t,v_{j-1}}\sum_{u}N_{%
    t,v_{j-1},u}\log\hat{\bm{v}}_{i,j,u}$ |  |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle-\sum_{i\in[&#124;\mathcal{D}&#124;]}\sum_{j=4}^{L_{i}}\bm{v}_{i,j,u}\log%
    \hat{\bm{v}}_{i,j,u}=-\sum_{i\in[&#124;\mathcal{D}&#124;]}\sum_{j=4}^{L_{i}}\mathbb{I}_{%
    u=v_{i,j}}\log\hat{\bm{v}}_{i,j,u}\overset{(a)}{=}-\sum_{t,v_{j-1}}\sum_{u}N_{%
    t,v_{j-1},u}\log\hat{\bm{v}}_{i,j,u}$ |  |'
- en: '|  | $\displaystyle\overset{(b)}{=}$ | $\displaystyle-\sum_{t,v_{j-1},u}\left(\sum_{u}N_{t,v_{j-1},u}\right)\left[%
    \left(\frac{N_{t,v_{j-1},u}}{\sum_{u}N_{t,v_{j-1},u}}\right)\log\hat{\bm{v}}_{%
    i,j,u}\right],$ |  |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\overset{(b)}{=}$ | $\displaystyle-\sum_{t,v_{j-1},u}\left(\sum_{u}N_{t,v_{j-1},u}\right)\left[%
    \left(\frac{N_{t,v_{j-1},u}}{\sum_{u}N_{t,v_{j-1},u}}\right)\log\hat{\bm{v}}_{%
    i,j,u}\right],$ |  |'
- en: where (a) uses the assumption that the output logits are determined by target
    node $t$ and the current node $v_{i-1}$. In (b), we assume that $\sum_{u}N_{t,v_{i-1},u}\neq
    0$. The cross-entropy is minimized when $\hat{\bm{v}}_{i,j,u}=\frac{N_{t,v_{j-1},u}}{\sum_{u}N_{t,v_{j-1},u}}$.
    If $\sum_{u}N_{t,v_{i-1},u}=0$, then the corresponding logits will not affect
    the loss function and $\hat{\bm{v}}_{i,j,u}$ can take any number. ∎
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，(a)假设输出logits由目标节点$t$和当前节点$v_{i-1}$决定。在(b)中，我们假设$\sum_{u}N_{t,v_{i-1},u}\neq
    0$。当$\hat{\bm{v}}_{i,j,u}=\frac{N_{t,v_{j-1},u}}{\sum_{u}N_{t,v_{j-1},u}}$时，交叉熵达到最小值。如果$\sum_{u}N_{t,v_{i-1},u}=0$，则相应的logits不会影响损失函数，并且$\hat{\bm{v}}_{i,j,u}$可以取任何值。∎
- en: Appendix E Supplementary Materials for Training-free Methods
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 无需训练的方法的补充材料
- en: E.1 Implementation of Baselines
  id: totrans-469
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1 基准方法的实现
- en: In this subsection, we present the implementation details of training-free baselines,
    including LLM’s direct inference, GraphSearch, and ours SGC. Method illustrations
    are shown in Figure [6](https://arxiv.org/html/2405.19119v3#A5.F6 "Figure 6 ‣
    E.1 Implementation of Baselines ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?").
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，我们展示了无需训练的基准方法的实现细节，包括LLM的直接推理、GraphSearch方法和我们的SGC方法。方法示意图见图[6](https://arxiv.org/html/2405.19119v3#A5.F6
    "图 6 ‣ E.1 基准方法的实现 ‣ 附录E 无需训练的方法的补充材料 ‣ 图学习能否改善基于LLM的智能体的规划？")。
- en: '![Refer to caption](img/8c567b3ae577a66ca7b4659d79274e6b.png)'
  id: totrans-471
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/8c567b3ae577a66ca7b4659d79274e6b.png)'
- en: 'Figure 6: Illustration of LLM’s Direct Inference and GraphSearch Method.'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：LLM直接推理与GraphSearch方法的示意图。
- en: 'LLM’s Direct Inference: The prompt template for LLM’s direct inference is given
    in Table [4](https://arxiv.org/html/2405.19119v3#A2.T4 "Table 4 ‣ Appendix B Prompts
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?"). During experiments,
    we uniformly apply 1-shot in context learning for LLM’s direct inference of task
    invocation path. For open-sourced LLMs, the temperature parameter is set to $0.2$.'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: LLM直接推理：LLM直接推理的提示模板见表[4](https://arxiv.org/html/2405.19119v3#A2.T4 "表 4 ‣ 附录B
    提示 ‣ 图学习能否改善基于LLM的智能体的规划？")。在实验中，我们统一应用1-shot上下文学习进行LLM任务调用路径的直接推理。对于开源的LLM，温度参数设置为$0.2$。
- en: 'GraphSearch: The prompt template for GraphSearch is given in Table [5](https://arxiv.org/html/2405.19119v3#A2.T5
    "Table 5 ‣ Appendix B Prompts ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?"). This algorithm conducts an iterative search on the task graph to identify
    an optimal task invocation path that can best satisfy a given request. In each
    iteration, the neighbors of the last selected task are considered as candidates.
    These candidates are evaluated by LLM for their suitability for the current step
    (*Task Assessment*). The search process follows a depth-first approach. After
    the task assessment in the final step, a set of potential invocation paths is
    generated. Subsequently, LLM is prompted to select the most appropriate path from
    these options (*Path Selection*). The GraphSearch algorithm is implemented in
    three distinct variants, each employing a unique task selection strategy:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: GraphSearch：GraphSearch的提示模板见表 [5](https://arxiv.org/html/2405.19119v3#A2.T5
    "表 5 ‣ 附录B 提示 ‣ 图学习能否改善基于LLM的智能体中的规划？")。该算法在任务图上进行迭代搜索，以识别能够最好地满足给定请求的最优任务调用路径。在每次迭代中，考虑最后选定任务的邻居作为候选任务。LLM根据这些候选任务的适合度进行评估（*任务评估*）。搜索过程遵循深度优先方法。在最终步骤的任务评估后，会生成一组潜在的调用路径。随后，LLM被提示从这些选项中选择最合适的路径（*路径选择*）。GraphSearch算法有三种不同的变体，每种变体都采用独特的任务选择策略：
- en: •
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: GreedySearch consistently selects the task node with the highest score at each
    step. Although fast and simple, this approach can lead to cascading errors, resulting
    in degraded performance.
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GreedySearch始终在每个步骤选择得分最高的任务节点。虽然这种方法速度快且简单，但可能会导致级联错误，从而降低性能。
- en: •
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: AdaptiveSearch selects tasks with scores above a fixed threshold, adjusting
    the breadth of the search space in an adaptive mode. During experiments, we empirically
    set the score threshold to $3$.
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AdaptiveSearch选择得分高于固定阈值的任务，并以自适应方式调整搜索空间的广度。在实验中，我们经验性地将得分阈值设置为$3$。
- en: •
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: BeamSearch retains the top-$k$ tasks based on the LLM’s assessment scores within
    candidates. Beam search can expand the search space but slightly reduces the efficiency.
    We uniformly set the beam width to $2$.
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BeamSearch基于LLM评估分数保留前$k$个任务。BeamSearch可以扩展搜索空间，但效率略有下降。我们统一将束宽设置为$2$。
- en: 'Ours SGC: Regarding the choices of LM backbones, for integrating GPT-3.5-turbo
    and GPT-4-turbo with SGC, the Roberta-355M [[40](https://arxiv.org/html/2405.19119v3#bib.bib40)]
    serves as the text encoder. For all other datasets and LLMs, the e5-335M [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]
    configuration is employed.'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 SGC：关于语言模型骨干的选择，针对将 GPT-3.5-turbo 和 GPT-4-turbo 与 SGC 集成，Roberta-355M [[40](https://arxiv.org/html/2405.19119v3#bib.bib40)]
    用作文本编码器。对于所有其他数据集和LLM，采用 e5-335M [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]
    配置。
- en: E.2 Results of All LLMs
  id: totrans-482
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2 所有LLM的结果
- en: Table [8](https://arxiv.org/html/2405.19119v3#A5.T8 "Table 8 ‣ E.2 Results of
    All LLMs ‣ Appendix E Supplementary Materials for Training-free Methods ‣ Can
    Graph Learning Improve Planning in LLM-based Agents?") supplements Table [1](https://arxiv.org/html/2405.19119v3#S5.T1
    "Table 1 ‣ 5.2 Performance of the Training-free Approach ‣ 5 Experiments and Analysis
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?") with other LLMs.
    The proposed methods perform consistently better.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [8](https://arxiv.org/html/2405.19119v3#A5.T8 "表 8 ‣ E.2 所有LLM的结果 ‣ 附录E 训练免法方法的补充材料
    ‣ 图学习能否改善基于LLM的智能体中的规划？") 补充了表 [1](https://arxiv.org/html/2405.19119v3#S5.T1 "表
    1 ‣ 5.2 训练免法方法的表现 ‣ 5 实验与分析 ‣ 图学习能否改善基于LLM的智能体中的规划？")，并包含了其他LLM的结果。所提方法在各方面表现一致更佳。
- en: 'Table 8: Comparison of Training-free Approaches: Overall Performance (Node-F1
    and Link-F1 in $\%$) and Token Consumption in $\times 10^{3}$.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：训练免法方法的比较：整体性能（节点-F1 和链接-F1，以$\%$表示）及令牌消耗（以$\times 10^{3}$为单位）。
- en: '|  |  | TaskBench | RestBench |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '|  |  | TaskBench | RestBench |'
- en: '|  |  | HuggingFace | Multimedia | Daily Life | TMDB |'
  id: totrans-486
  prefs: []
  type: TYPE_TB
  zh: '|  |  | HuggingFace | Multimedia | Daily Life | TMDB |'
- en: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | # Tok $\downarrow$ | n-F1
    $\uparrow$ | l-F1 $\uparrow$ | # Tok $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$
    | # Tok $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | #Tok $\downarrow$ |'
  id: totrans-487
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 令牌数 $\downarrow$ | n-F1 $\uparrow$
    | l-F1 $\uparrow$ | 令牌数 $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 令牌数
    $\downarrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ | 令牌数 $\downarrow$ |'
- en: '| Baichuan2 13B | Direct | 45.85 | 19.00 | 2.43 | 47.57 | 4.08 | 2.59 | 33.45
    | 9.52 | 3.72 | 30.87 | 9.92 | 1.96 |'
  id: totrans-488
  prefs: []
  type: TYPE_TB
  zh: '| Baichuan2 13B | Direct | 45.85 | 19.00 | 2.43 | 47.57 | 4.08 | 2.59 | 33.45
    | 9.52 | 3.72 | 30.87 | 9.92 | 1.96 |'
- en: '| GreedySearch | 30.58 | 4.89 | 6.42 | 18.74 | 4.45 | 5.69 | 15.60 | 1.61 |
    5.91 | 22.52 | 2.98 | 3.62 |'
  id: totrans-489
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 30.58 | 4.89 | 6.42 | 18.74 | 4.45 | 5.69 | 15.60 | 1.61 |
    5.91 | 22.52 | 2.98 | 3.62 |'
- en: '| AdaptiveSearch | 39.30 | 10.41 | 10.81 | 33.24 | 9.22 | 11.17 | 34.39 | 12.73
    | 16.71 | 30.33 | 10.00 | 8.71 |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 39.30 | 10.41 | 10.81 | 33.24 | 9.22 | 11.17 | 34.39 | 12.73
    | 16.71 | 30.33 | 10.00 | 8.71 |'
- en: '| BeamSearch | 41.06 | 9.59 | 24.69 | 32.24 | 9.09 | 21.60 | 36.18 | 13.18
    | 23.83 | 30.97 | 7.61 | 9.08 |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 41.06 | 9.59 | 24.69 | 32.24 | 9.09 | 21.60 | 36.18 | 13.18
    | 23.83 | 30.97 | 7.61 | 9.08 |'
- en: '| SGC | 56.53 | 29.94 | 2.28 | 56.75 | 31.62 | 2.43 | 62.31 | 36.69 | 3.53
    | 32.97 | 9.11 | 1.84 |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 56.53 | 29.94 | 2.28 | 56.75 | 31.62 | 2.43 | 62.31 | 36.69 | 3.53
    | 32.97 | 9.11 | 1.84 |'
- en: '| Vicuna 13B | Direct | 50.46 | 21.27 | 2.50 | 53.57 | 23.19 | 2.64 | 73.70
    | 45.80 | 3.82 | 44.66 | 14.01 | 2.02 |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna 13B | Direct | 50.46 | 21.27 | 2.50 | 53.57 | 23.19 | 2.64 | 73.70
    | 45.80 | 3.82 | 44.66 | 14.01 | 2.02 |'
- en: '| GreedySearch | 52.94 | 25.73 | 6.23 | 46.99 | 23.11 | 5.55 | 42.98 | 13.33
    | 7.18 | 45.22 | 13.69 | 3.42 |'
  id: totrans-494
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 52.94 | 25.73 | 6.23 | 46.99 | 23.11 | 5.55 | 42.98 | 13.33
    | 7.18 | 45.22 | 13.69 | 3.42 |'
- en: '| AdaptiveSearch | 54.36 | 25.67 | 9.81 | 51.24 | 24.32 | 11.25 | 62.71 | 31.15
    | 13.92 | 41.32 | 7.02 | 6.51 |'
  id: totrans-495
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 54.36 | 25.67 | 9.81 | 51.24 | 24.32 | 11.25 | 62.71 | 31.15
    | 13.92 | 41.32 | 7.02 | 6.51 |'
- en: '| BeamSearch | 56.64 | 26.93 | 24.11 | 54.09 | 26.19 | 25.42 | 54.55 | 23.60
    | 24.86 | 46.91 | 15.41 | 7.79 |'
  id: totrans-496
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 56.64 | 26.93 | 24.11 | 54.09 | 26.19 | 25.42 | 54.55 | 23.60
    | 24.86 | 46.91 | 15.41 | 7.79 |'
- en: '| SGC | 59.62 | 31.98 | 2.31 | 61.78 | 37.60 | 2.43 | 83.33 | 63.77 | 3.82
    | 48.79 | 15.99 | 1.89 |'
  id: totrans-497
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 59.62 | 31.98 | 2.31 | 61.78 | 37.60 | 2.43 | 83.33 | 63.77 | 3.82
    | 48.79 | 15.99 | 1.89 |'
- en: '| CodeLlama 7B | Direct | 58.06 | 29.39 | 2.44 | 59.44 | 30.83 | 2.57 | 84.12
    | 62.89 | 3.82 | 65.67 | 41.99 | 1.94 |'
  id: totrans-498
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama 7B | Direct | 58.06 | 29.39 | 2.44 | 59.44 | 30.83 | 2.57 | 84.12
    | 62.89 | 3.82 | 65.67 | 41.99 | 1.94 |'
- en: '| GreedySearch | 58.71 | 31.56 | 5.84 | 62.83 | 38.12 | 5.35 | 82.51 | 63.83
    | 7.08 | 65.51 | 42.60 | 3.12 |'
  id: totrans-499
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 58.71 | 31.56 | 5.84 | 62.83 | 38.12 | 5.35 | 82.51 | 63.83
    | 7.08 | 65.51 | 42.60 | 3.12 |'
- en: '| AdaptiveSearch | 60.42 | 33.18 | 6.84 | 62.32 | 36.81 | 5.50 | 83.42 | 64.15
    | 7.83 | 65.37 | 40.64 | 5.00 |'
  id: totrans-500
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 60.42 | 33.18 | 6.84 | 62.32 | 36.81 | 5.50 | 83.42 | 64.15
    | 7.83 | 65.37 | 40.64 | 5.00 |'
- en: '| BeamSearch | 60.34 | 31.36 | 17.95 | 64.12 | 38.99 | 21.48 | 83.25 | 63.48
    | 24.48 | 64.60 | 40.50 | 5.78 |'
  id: totrans-501
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 60.34 | 31.36 | 17.95 | 64.12 | 38.99 | 21.48 | 83.25 | 63.48
    | 24.48 | 64.60 | 40.50 | 5.78 |'
- en: '| SGC | 63.98 | 39.27 | 2.30 | 67.04 | 45.04 | 2.43 | 87.73 | 70.49 | 3.59
    | 66.15 | 42.62 | 1.88 |'
  id: totrans-502
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 63.98 | 39.27 | 2.30 | 67.04 | 45.04 | 2.43 | 87.73 | 70.49 | 3.59
    | 66.15 | 42.62 | 1.88 |'
- en: '| Mistral 7B | Direct | 60.60 | 30.23 | 2.49 | 69.83 | 39.85 | 2.64 | 84.26
    | 53.63 | 3.77 | 62.23 | 22.02 | 1.96 |'
  id: totrans-503
  prefs: []
  type: TYPE_TB
  zh: '| Mistral 7B | Direct | 60.60 | 30.23 | 2.49 | 69.83 | 39.85 | 2.64 | 84.26
    | 53.63 | 3.77 | 62.23 | 22.02 | 1.96 |'
- en: '| GreedySearch | 65.91 | 38.13 | 6.52 | 58.92 | 34.72 | 6.26 | 75.18 | 49.47
    | 8.27 | 60.64 | 23.18 | 4.38 |'
  id: totrans-504
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 65.91 | 38.13 | 6.52 | 58.92 | 34.72 | 6.26 | 75.18 | 49.47
    | 8.27 | 60.64 | 23.18 | 4.38 |'
- en: '| AdaptiveSearch | 67.30 | 38.90 | 7.68 | 71.59 | 44.84 | 10.66 | 86.39 | 63.65
    | 10.92 | 54.04 | 21.35 | 9.99 |'
  id: totrans-505
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 67.30 | 38.90 | 7.68 | 71.59 | 44.84 | 10.66 | 86.39 | 63.65
    | 10.92 | 54.04 | 21.35 | 9.99 |'
- en: '| BeamSearch | 67.13 | 36.73 | 25.66 | 73.55 | 47.12 | 31.10 | 85.87 | 61.53
    | 39.16 | 63.41 | 26.79 | 11.26 |'
  id: totrans-506
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 67.13 | 36.73 | 25.66 | 73.55 | 47.12 | 31.10 | 85.87 | 61.53
    | 39.16 | 63.41 | 26.79 | 11.26 |'
- en: '| SGC | 67.43 | 42.08 | 2.32 | 74.07 | 49.90 | 2.43 | 87.13 | 66.49 | 3.54
    | 64.72 | 25.67 | 1.89 |'
  id: totrans-507
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 67.43 | 42.08 | 2.32 | 74.07 | 49.90 | 2.43 | 87.13 | 66.49 | 3.54
    | 64.72 | 25.67 | 1.89 |'
- en: '| CodeLlama 13B | Direct | 57.55 | 28.88 | 2.45 | 68.57 | 41.79 | 2.59 | 91.20
    | 76.07 | 3.88 | 68.91 | 43.74 | 2.02 |'
  id: totrans-508
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama 13B | Direct | 57.55 | 28.88 | 2.45 | 68.57 | 41.79 | 2.59 | 91.20
    | 76.07 | 3.88 | 68.91 | 43.74 | 2.02 |'
- en: '| GreedySearch | 61.67 | 34.02 | 5.95 | 67.98 | 42.04 | 4.95 | 91.50 | 76.56
    | 5.54 | 66.67 | 42.16 | 3.81 |'
  id: totrans-509
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 61.67 | 34.02 | 5.95 | 67.98 | 42.04 | 4.95 | 91.50 | 76.56
    | 5.54 | 66.67 | 42.16 | 3.81 |'
- en: '| AdaptiveSearch | 60.85 | 31.66 | 11.10 | 68.14 | 41.71 | 6.77 | 91.34 | 76.09
    | 7.18 | 63.74 | 37.17 | 8.16 |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 60.85 | 31.66 | 11.10 | 68.14 | 41.71 | 6.77 | 91.34 | 76.09
    | 7.18 | 63.74 | 37.17 | 8.16 |'
- en: '| BeamSearch | 62.65 | 34.31 | 20.14 | 69.53 | 43.35 | 19.51 | 91.74 | 76.60
    | 19.19 | 68.08 | 42.92 | 8.88 |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 62.65 | 34.31 | 20.14 | 69.53 | 43.35 | 19.51 | 91.74 | 76.60
    | 19.19 | 68.08 | 42.92 | 8.88 |'
- en: '| SGC | 65.51 | 39.44 | 2.31 | 73.32 | 53.28 | 2.43 | 92.96 | 79.57 | 3.64
    | 71.40 | 47.55 | 1.90 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 65.51 | 39.44 | 2.31 | 73.32 | 53.28 | 2.43 | 92.96 | 79.57 | 3.64
    | 71.40 | 47.55 | 1.90 |'
- en: '| GPT- 3.5-turbo | Direct | 73.85 | 45.73 | 2.14 | 82.85 | 62.07 | 2.26 | 96.09
    | 83.65 | 3.36 | 81.70 | 57.52 | 1.67 |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| GPT- 3.5-turbo | Direct | 73.85 | 45.73 | 2.14 | 82.85 | 62.07 | 2.26 | 96.09
    | 83.65 | 3.36 | 81.70 | 57.52 | 1.67 |'
- en: '| GreedySearch | 67.75 | 43.88 | 5.29 | 81.11 | 63.02 | 4.92 | 93.77 | 81.26
    | 7.36 | 76.19 | 50.11 | 3.06 |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 67.75 | 43.88 | 5.29 | 81.11 | 63.02 | 4.92 | 93.77 | 81.26
    | 7.36 | 76.19 | 50.11 | 3.06 |'
- en: '| AdaptiveSearch | 72.18 | 47.55 | 7.47 | 81.86 | 62.71 | 5.71 | 93.79 | 81.41
    | 8.53 | 77.57 | 53.65 | 5.89 |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 72.18 | 47.55 | 7.47 | 81.86 | 62.71 | 5.71 | 93.79 | 81.41
    | 8.53 | 77.57 | 53.65 | 5.89 |'
- en: '| BeamSearch | 75.51 | 49.62 | 14.22 | 83.57 | 64.50 | 12.91 | 95.66 | 82.72
    | 22.05 | 81.24 | 57.98 | 6.42 |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 75.51 | 49.62 | 14.22 | 83.57 | 64.50 | 12.91 | 95.66 | 82.72
    | 22.05 | 81.24 | 57.98 | 6.42 |'
- en: '| SGC | 76.37 | 50.04 | 2.02 | 83.65 | 63.65 | 2.09 | 96.38 | 86.19 | 3.16
    | 82.63 | 59.15 | 1.61 |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 76.37 | 50.04 | 2.02 | 83.65 | 63.65 | 2.09 | 96.38 | 86.19 | 3.16
    | 82.63 | 59.15 | 1.61 |'
- en: '| GPT- 4-turbo | Direct | 77.60 | 52.18 | 2.19 | 88.29 | 69.38 | 2.28 | 97.36
    | 84.58 | 3.37 | 82.56 | 56.67 | 1.75 |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| GPT- 4-turbo | 直接 | 77.60 | 52.18 | 2.19 | 88.29 | 69.38 | 2.28 | 97.36 |
    84.58 | 3.37 | 82.56 | 56.67 | 1.75 |'
- en: '| GreedySearch | 74.75 | 50.44 | 5.78 | 86.81 | 69.80 | 5.52 | 97.36 | 85.78
    | 7.37 | 75.34 | 49.95 | 3.73 |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 74.75 | 50.44 | 5.78 | 86.81 | 69.80 | 5.52 | 97.36 | 85.78
    | 7.37 | 75.34 | 49.95 | 3.73 |'
- en: '| AdaptiveSearch | 76.17 | 51.30 | 8.94 | 88.02 | 69.99 | 7.14 | 97.30 | 85.80
    | 9.04 | 81.78 | 55.15 | 6.35 |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 76.17 | 51.30 | 8.94 | 88.02 | 69.99 | 7.14 | 97.30 | 85.80
    | 9.04 | 81.78 | 55.15 | 6.35 |'
- en: '| BeamSearch | 77.56 | 52.54 | 8.98 | 88.16 | 70.39 | 6.90 | 97.35 | 85.78
    | 8.99 | 80.11 | 51.00 | 5.18 |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 77.56 | 52.54 | 8.98 | 88.16 | 70.39 | 6.90 | 97.35 | 85.78
    | 8.99 | 80.11 | 51.00 | 5.18 |'
- en: '| SGC | 77.79 | 52.20 | 2.03 | 88.54 | 69.83 | 2.10 | 97.35 | 85.76 | 3.16
    | 82.27 | 56.37 | 1.62 |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 77.79 | 52.20 | 2.03 | 88.54 | 69.83 | 2.10 | 97.35 | 85.76 | 3.16
    | 82.27 | 56.37 | 1.62 |'
- en: E.3 Accuracy Results of Training-free Methods
  id: totrans-523
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.3 训练无关方法的准确率结果
- en: 'Table 9: Results of Supplementary Metric: Accuracy ($\%$) for Training-free
    Methods on TaskBench. Accuracy is $1$ if predicted tasks match the ground-truth
    task set, and $0$ otherwise.'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：任务基准上训练无关方法的补充度量结果：准确率（$\%$）。如果预测任务与实际任务集匹配，则准确率为 $1$，否则为 $0$。
- en: '| LLM | Method | HuggingFace | Multimedia | DailyLife | LLM | Method | HuggingFace
    | Multimedia | DailyLife |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | HuggingFace | 多媒体 | 日常生活 | LLM | 方法 | HuggingFace | 多媒体 | 日常生活
    |'
- en: '| Vicuna 13B | Direct | 8.72 | 11.20 | 24.43 | CodeLlama 7B | Direct | 15.00
    | 15.19 | 47.69 |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna 13B | 直接 | 8.72 | 11.20 | 24.43 | CodeLlama 7B | 直接 | 15.00 | 15.19
    | 47.69 |'
- en: '| GreedySearch | 10.95 | 9.34 | 3.76 | GreedySearch | 16.20 | 20.04 | 45.07
    |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 10.95 | 9.34 | 3.76 | GreedySearch | 16.20 | 20.04 | 45.07
    |'
- en: '| AdaptiveSearch | 10.55 | 10.37 | 13.15 | AdaptiveSearch | 18.79 | 19.41 |
    46.48 |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 10.55 | 10.37 | 13.15 | AdaptiveSearch | 18.79 | 19.41 |
    46.48 |'
- en: '| BeamSearch | 12.58 | 12.03 | 11.06 | BeamSearch | 17.00 | 21.10 | 45.67 |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 12.58 | 12.03 | 11.06 | BeamSearch | 17.00 | 21.10 | 45.67 |'
- en: '| SGC | 16.02 | 20.12 | 42.17 | SGC | 21.20 | 29.32 | 55.33 |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 16.02 | 20.12 | 42.17 | SGC | 21.20 | 29.32 | 55.33 |'
- en: '| Mistral 7B | Direct | 16.36 | 25.05 | 44.52 | CodeLlama 13B | Direct | 14.29
    | 24.10 | 66.40 |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| Mistral 7B | 直接 | 16.36 | 25.05 | 44.52 | CodeLlama 13B | 直接 | 14.29 | 24.10
    | 66.40 |'
- en: '| GreedySearch | 20.45 | 16.02 | 29.22 | GreedySearch | 19.11 | 24.90 | 67.00
    |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 20.45 | 16.02 | 29.22 | GreedySearch | 19.11 | 24.90 | 67.00
    |'
- en: '| AdaptiveSearch | 21.88 | 26.90 | 49.32 | AdaptiveSearch | 17.30 | 24.10 |
    66.80 |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 21.88 | 26.90 | 49.32 | AdaptiveSearch | 17.30 | 24.10 |
    66.80 |'
- en: '| BeamSearch | 20.45 | 29.36 | 45.89 | BeamSearch | 19.92 | 25.70 | 67.20 |'
  id: totrans-534
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 20.45 | 29.36 | 45.89 | BeamSearch | 19.92 | 25.70 | 67.20 |'
- en: '| SGC | 25.15 | 33.68 | 52.28 | SGC | 22.54 | 36.75 | 70.80 |'
  id: totrans-535
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 25.15 | 33.68 | 52.28 | SGC | 22.54 | 36.75 | 70.80 |'
- en: '| GPT- 3.5-turbo | Direct | 28.95 | 47.96 | 81.30 | GPT- 4-turbo | Direct |
    33.68 | 60.56 | 86.77 |'
  id: totrans-536
  prefs: []
  type: TYPE_TB
  zh: '| GPT- 3.5-turbo | 直接 | 28.95 | 47.96 | 81.30 | GPT- 4-turbo | 直接 | 33.68 |
    60.56 | 86.77 |'
- en: '| GreedySearch | 26.90 | 52.47 | 73.17 | GreedySearch | 33.68 | 61.37 | 86.77
    |'
  id: totrans-537
  prefs: []
  type: TYPE_TB
  zh: '| GreedySearch | 26.90 | 52.47 | 73.17 | GreedySearch | 33.68 | 61.37 | 86.77
    |'
- en: '| AdaptiveSearch | 29.36 | 51.61 | 74.59 | AdaptiveSearch | 33.47 | 61.17 |
    86.77 |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
  zh: '| AdaptiveSearch | 29.36 | 51.61 | 74.59 | AdaptiveSearch | 33.47 | 61.17 |
    86.77 |'
- en: '| BeamSearch | 32.03 | 52.47 | 80.87 | BeamSearch | 33.26 | 61.57 | 86.57 |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 32.03 | 52.47 | 80.87 | BeamSearch | 33.26 | 61.57 | 86.57 |'
- en: '| SGC | 32.44 | 51.61 | 83.13 | SGC | 34.09 | 60.97 | 86.77 |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 32.44 | 51.61 | 83.13 | SGC | 34.09 | 60.97 | 86.77 |'
- en: Due to space limitations, we present only the Node-F1 and Link-F1 scores for
    training-free methods in the main text. Here, we provide the Accuracy results
    in Table [9](https://arxiv.org/html/2405.19119v3#A5.T9 "Table 9 ‣ E.3 Accuracy
    Results of Training-free Methods ‣ Appendix E Supplementary Materials for Training-free
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?"). These results
    show that integrating SGC significantly enhances accuracy across different LLMs
    on all datasets, making previously unsolvable planning scenarios manageable and
    successful.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 由于篇幅限制，本文只展示了训练无关方法的 Node-F1 和 Link-F1 分数。在此，我们提供了表[9](https://arxiv.org/html/2405.19119v3#A5.T9
    "Table 9 ‣ E.3 Accuracy Results of Training-free Methods ‣ Appendix E Supplementary
    Materials for Training-free Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")中的准确率结果。这些结果表明，整合 SGC 显著提高了在所有数据集上不同 LLMs 的准确率，使得以前无法解决的规划场景变得可管理并成功实现。
- en: E.4 Computational Cost Analysis
  id: totrans-542
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.4 计算成本分析
- en: In this subsection, we present a comprehensive efficiency study on inference
    time of training-free methods and results are shown in Table [10](https://arxiv.org/html/2405.19119v3#A5.T10
    "Table 10 ‣ E.4 Computational Cost Analysis ‣ Appendix E Supplementary Materials
    for Training-free Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?").
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们呈现了关于无训练方法的推理时间的综合效率研究，结果展示在表格[10](https://arxiv.org/html/2405.19119v3#A5.T10
    "表 10 ‣ E.4 计算成本分析 ‣ 附录 E 基于训练的无训练方法的补充材料 ‣ 图学习能否提高基于LLM的代理的规划能力？")中。
- en: 'Table 10: Computational Cost Analysis of Training-free Methods. Due to space
    constraints in the table, some LLMs are abbreviated such as “GPT-3.5” for “GPT-3.5-turbo”.'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10：无训练方法的计算成本分析。由于表格空间限制，一些大语言模型（LLMs）使用缩写，如“GPT-3.5”代表“GPT-3.5-turbo”。
- en: '|  | Inference Times Comparison on HuggingFace (Seconds) |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
  zh: '|  | HuggingFace上的推理时间比较（秒） |'
- en: '| Method | Baichuan | Vicuna | CodeLlama-7B | Mistral | CodeLlama-13B | GPT-3.5
    | GPT-4 |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 百川 | Vicuna | CodeLlama-7B | Mistral | CodeLlama-13B | GPT-3.5 | GPT-4
    |'
- en: '| Direct | 6.0 | 3.6 | 10.9 | 4.5 | 9.7 | 2.7 | 26.1 |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
  zh: '| 直接推理 | 6.0 | 3.6 | 10.9 | 4.5 | 9.7 | 2.7 | 26.1 |'
- en: '| GreedySearch | 30.7 | 45.7 | 23.1 | 109.8 | 29.1 | 7.4 | 55.6 |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
  zh: '| 贪心搜索 | 30.7 | 45.7 | 23.1 | 109.8 | 29.1 | 7.4 | 55.6 |'
- en: '| AdaptiveSearch | 50.2 | 79.4 | 27.2 | 28.2 | 52.4 | 9.4 | 87.0 |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
  zh: '| 自适应搜索 | 50.2 | 79.4 | 27.2 | 28.2 | 52.4 | 9.4 | 87.0 |'
- en: '| BeamSearch | 102.0 | 55.0 | 60.8 | 85.5 | 92.3 | 14.9 | 270.2 |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| 波束搜索 | 102.0 | 55.0 | 60.8 | 85.5 | 92.3 | 14.9 | 270.2 |'
- en: '| SGC | 6.1 | 3.7 | 10.7 | 4.6 | 9.5 | 3.0 | 24.4 |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 6.1 | 3.7 | 10.7 | 4.6 | 9.5 | 3.0 | 24.4 |'
- en: '|  | Inference Times Comparison on Multimedia (Seconds) |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '|  | 多媒体上的推理时间比较（秒） |'
- en: '| Direct | 9.7 | 3.3 | 13.2 | 4.5 | 14.6 | 2.9 | 25.1 |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '| 直接推理 | 9.7 | 3.3 | 13.2 | 4.5 | 14.6 | 2.9 | 25.1 |'
- en: '| GreedySearch | 52.3 | 54.3 | 37.0 | 109.7 | 9.9 | 8.8 | 52.2 |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: '| 贪心搜索 | 52.3 | 54.3 | 37.0 | 109.7 | 9.9 | 8.8 | 52.2 |'
- en: '| AdaptiveSearch | 98.1 | 142.5 | 25.7 | 41.6 | 25.6 | 9.6 | 84.2 |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| 自适应搜索 | 98.1 | 142.5 | 25.7 | 41.6 | 25.6 | 9.6 | 84.2 |'
- en: '| BeamSearch | 122.3 | 69.8 | 103.0 | 92.0 | 84.4 | 15.0 | 70.9 |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| 波束搜索 | 122.3 | 69.8 | 103.0 | 92.0 | 84.4 | 15.0 | 70.9 |'
- en: '| SGC | 9.5 | 3.4 | 12.9 | 4.5 | 14.1 | 3.1 | 23.5 |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 9.5 | 3.4 | 12.9 | 4.5 | 14.1 | 3.1 | 23.5 |'
- en: '|  | Inference Times Comparison on Daily Life (Seconds) |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '|  | 日常生活中的推理时间比较（秒） |'
- en: '| Direct | 10.0 | 6.5 | 19.4 | 5.6 | 18.6 | 3.4 | 31.0 |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| 直接推理 | 10.0 | 6.5 | 19.4 | 5.6 | 18.6 | 3.4 | 31.0 |'
- en: '| GreedySearch | 62.7 | 49.8 | 29.3 | 198.3 | 37.6 | 13.2 | 124.3 |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| 贪心搜索 | 62.7 | 49.8 | 29.3 | 198.3 | 37.6 | 13.2 | 124.3 |'
- en: '| AdaptiveSearch | 133.3 | 97.6 | 30.5 | 69.1 | 45.5 | 16.5 | 209.0 |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| 自适应搜索 | 133.3 | 97.6 | 30.5 | 69.1 | 45.5 | 16.5 | 209.0 |'
- en: '| BeamSearch | 196.9 | 54.1 | 106.9 | 195.9 | 64.9 | 89.4 | 161.7 |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| 波束搜索 | 196.9 | 54.1 | 106.9 | 195.9 | 64.9 | 89.4 | 161.7 |'
- en: '| SGC | 9.9 | 6.5 | 18.6 | 5.7 | 17.9 | 3.6 | 29.5 |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 9.9 | 6.5 | 18.6 | 5.7 | 17.9 | 3.6 | 29.5 |'
- en: Open-sourced LLMs were deployed as local API services using the FastChat framework²²2https://github.com/lm-sys/FastChat
    on a single A100-80G GPU. This configuration enables faster and parallel inference.
    Under this setup, LLM’s direct inference requires 3-15 seconds per request. GPT-3.5-turbo
    and GPT-4-turbo are accessed via API, with the latter generally requiring more
    time. GraphSearch requires several minutes to complete a request due to its exhaustive
    search on the task graph, impacting the efficiency. In contrast, SGC achieves
    comparable efficiency to LLM’s direct inference, as it requires only a single
    LLM query and both LM and SGC’s forward propagation processes are extremely efficient
    (typically completing within seconds). Note that some discrepancies in reported
    times, such as Mistral-7B’s GreedySearch taking longer than other modes, may be
    attributed to variations in the deployment across different A100 services.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 开源的大语言模型（LLMs）被部署为使用FastChat框架²²2https://github.com/lm-sys/FastChat的本地API服务，运行在单个A100-80G
    GPU上。这种配置使得推理更快且能并行执行。在这种设置下，LLM的直接推理每次请求需要3到15秒。GPT-3.5-turbo和GPT-4-turbo通过API访问，后者通常需要更多的时间。GraphSearch由于对任务图的穷举搜索，需要几分钟才能完成请求，影响了效率。相比之下，SGC通过仅需要一次LLM查询实现了与LLM直接推理相当的效率，因为LM和SGC的前向传播过程非常高效（通常在几秒钟内完成）。请注意，某些报告时间的差异，如Mistral-7B的贪心搜索比其他模式花费更多时间，可能与不同A100服务之间的部署差异有关。
- en: Appendix F Supplementary Materials for Training-based Methods
  id: totrans-565
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 F 基于训练的方法的补充材料
- en: F.1 Implementation of Training-based GNNs
  id: totrans-566
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.1 基于训练的 GNN 实现
- en: '![Refer to caption](img/0982e5500f015eaefe7ff0f17c39854a.png)'
  id: totrans-567
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0982e5500f015eaefe7ff0f17c39854a.png)'
- en: 'Figure 7: Illustration of our GNN-enhanced Task Planning. First, LLMs interpret
    user request into several manageable steps. Then, we leverage GNNs for task retrieval,
    sequentially matching each step description to a suitable task, finally generating
    the invocation path.'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：我们增强 GNN 的任务规划示意图。首先，LLM 将用户请求解释为若干个可管理的步骤。然后，我们利用 GNN 进行任务检索，按顺序将每个步骤描述与合适的任务匹配，最终生成调用路径。
- en: 'LM and GNN Configuration: For training-based GNNs, we uniformly use the e5-335M
    model [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)] as the LM backbone.
    For the graph encoder, our setup includes a single layer with a hidden dimension
    of $1024$. During the model training, we set the batch size to $512$ and run for
    $20$ epochs with a learning rate of $1e-3$. We use the Adam optimizer [[25](https://arxiv.org/html/2405.19119v3#bib.bib25)]
    and implement an early stopping mechanism with a patience of $5$ epochs to prevent
    over-fitting. All experiments are conducted on a single NVIDIA A100-80G GPU.'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: LM 和 GNN 配置：对于基于训练的 GNN，我们统一使用 e5-335M 模型 [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]
    作为 LM 主干模型。对于图编码器，我们的设置包括一个单层，隐藏维度为 $1024$。在模型训练期间，我们将批次大小设置为 $512$，并运行 $20$ 个周期，学习率为
    $1e-3$。我们使用 Adam 优化器 [[25](https://arxiv.org/html/2405.19119v3#bib.bib25)]，并实现了一个早停机制，耐心值为
    $5$ 个周期，以防止过拟合。所有实验都在单个 NVIDIA A100-80G GPU 上进行。
- en: 'Training Data Preparation: From each dataset in TaskBench, we randomly select
    $3,000$ samples to create the trainset. The original data includes specific task
    steps and corresponding task invocation paths. Therefore, we first employ a topological
    sort to align each task step accurately with corresponding task, forming “<step,
    ground-truth task>” pairs. Then, for each pair, we randomly sample two negative
    tasks to constitute the “<step, positive task, negative task>” triplets for model
    training. These negative samples are selected based on how textually similar they
    are to the positive one, creating a robust differentiation challenge for the model.'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据准备：从 TaskBench 中的每个数据集，我们随机选择 $3,000$ 个样本来创建训练集。原始数据包括特定任务步骤和相应的任务调用路径。因此，我们首先使用拓扑排序准确地将每个任务步骤与对应任务对齐，形成“<步骤，真实任务>”对。然后，对于每对样本，我们随机选择两个负任务来构成“<步骤，正任务，负任务>”三元组进行模型训练。这些负样本是根据它们与正任务在文本上的相似度来选择的，从而为模型创建了一个强有力的区分挑战。
- en: 'Choices of Different Configurations: Our training-based model offers two configuration
    options: training only the GNN while keeping the LM frozen, or co-training both
    the LM and GNN. Illustrations of these configurations are provided in Figure [8](https://arxiv.org/html/2405.19119v3#A6.F8
    "Figure 8 ‣ F.1 Implementation of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?"). The first configuration is designed to explore the GNN’s
    capability in task retrieval. The latter leverages the LM’s dataset-specific semantic
    embeddings to enhance performance. For the co-training setup, we use a learning
    rate of $2e-5$ and a training duration of $10$ epochs.'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 不同配置的选择：我们的基于训练的模型提供了两种配置选项：仅训练 GNN，同时保持 LM 冻结，或共同训练 LM 和 GNN。这些配置的示意图见图 [8](https://arxiv.org/html/2405.19119v3#A6.F8
    "图 8 ‣ F.1 基于训练的 GNN 实现 ‣ 附录 F 基于训练的方法补充材料 ‣ 图学习能否改善基于 LLM 的智能体的规划？")。第一种配置旨在探索
    GNN 在任务检索中的能力，第二种配置则利用 LM 的数据集特定语义嵌入来增强性能。在共同训练的设置中，我们使用学习率为 $2e-5$，训练周期为 $10$
    个。
- en: '![Refer to caption](img/0c301ab778ee092e853a24f5e69f2c65.png)'
  id: totrans-572
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/0c301ab778ee092e853a24f5e69f2c65.png)'
- en: 'Figure 8: LM+GNN Configuration. We offer two configurations: only training
    the GNN while keeping the LM frozen (Table [11](https://arxiv.org/html/2405.19119v3#A6.T11
    "Table 11 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?")), or co-training both the LM and GNN (Table [12](https://arxiv.org/html/2405.19119v3#A6.T12
    "Table 12 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?")).'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：LM+GNN 配置。我们提供两种配置：仅训练 GNN，同时保持 LM 冻结（表格 [11](https://arxiv.org/html/2405.19119v3#A6.T11
    "表 11 ‣ F.4 基于训练的 GNN 完整结果 ‣ 附录 F 基于训练的方法补充材料 ‣ 图学习能否改善基于 LLM 的智能体的规划？")），或者共同训练
    LM 和 GNN（表格 [12](https://arxiv.org/html/2405.19119v3#A6.T12 "表 12 ‣ F.4 基于训练的
    GNN 完整结果 ‣ 附录 F 基于训练的方法补充材料 ‣ 图学习能否改善基于 LLM 的智能体的规划？")）。
- en: F.2 Implementation of TAPE and GraphToken
  id: totrans-574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.2 TAPE 和 GraphToken 的实现
- en: We adapt TAPE [[16](https://arxiv.org/html/2405.19119v3#bib.bib16)] and GraphToken
    [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)] as training-required baselines
    for task planning. Here, we detail the adaptation processes for each method.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将TAPE [[16](https://arxiv.org/html/2405.19119v3#bib.bib16)]和GraphToken [[38](https://arxiv.org/html/2405.19119v3#bib.bib38)]作为任务规划所需的训练基准。在这里，我们详细介绍了每种方法的适应过程。
- en: 'TAPE: To adapt TAPE for task planning, we reformulate the planning task as
    a node classification problem, aiming to classify a user request into the appropriate
    task labels within the task graph. Firstly, LLMs interpret user requests by generating
    high-quality explanatory text, i.e., chain-of-thought reasoning, to understand
    each request. Then, a fine-tuned LM encodes these chain-of-thought texts into
    latent embeddings. The fine-tuning process is based on pairs of textual descriptions
    and their corresponding ground-truth tasks. Finally, GNNs select the suitable
    tasks by leveraging both the generated text embeddings and the task embeddings.
    For a fair performance comparison, we fine-tune the LM as e5-335M and configure
    the GNN as a $2$-layer GraphSAGE with a hidden dimension of $1024$. The training
    data for both the LM and GNNs are consistent, utilizing the same split of the
    training dataset.'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: TAPE：为了使TAPE适应任务规划，我们将规划任务重新表述为节点分类问题，目标是将用户请求分类到任务图中的适当任务标签。首先，LLM通过生成高质量的解释性文本，即链式推理，来解释用户请求，理解每个请求。然后，经过微调的语言模型将这些链式推理文本编码为潜在的嵌入表示。微调过程基于文本描述与其对应的真实任务对。最后，GNN通过利用生成的文本嵌入和任务嵌入来选择合适的任务。为了公平地进行性能比较，我们微调了语言模型e5-335M，并将GNN配置为$2$层GraphSAGE，隐藏维度为$1024$。LM和GNN的训练数据是一致的，使用相同的数据集划分进行训练。
- en: 'GraphToken: For adapting GraphToken, we first encode the task graph $G(V,E,X)$
    by computing each node’s representation $\bm{x}_{v}$ by feeding its descriptive
    text into the pre-trained LM, e5-335M. Then, a GNN transforms the initial node
    embedding matrix into $H$. The GNN is configured as a $2$-layer GraphSAGE with
    a hidden dimension of $1024$. A mean pooling operation is further applied to the
    node embeddings to obtain the graph’s overall representation as $\bm{h}_{G}=\text{Mean-Pooling}(H)$.
    Finally, both $\bm{h}_{G}$ and the text embeddings of input instruction and user
    request are concatenated and fed into the LLM to generate the output planning
    result. During this process, the backbone LLMs are frozen, and only the GNN’s
    parameters are tuned. For each dataset, we train over $4$ epochs using the same
    $3,000$ training samples consisting of <user request, ground-truth planning> pairs.
    The batch size is set to $16$, with a maximum input length of $512$ and a maximum
    output length of $300$ for HuggingFace and Multimedia datasets, and $600$ for
    DailyLife dataset. The learning rate is configured to $1e-5$.'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: GraphToken：为了适应GraphToken，我们首先通过将每个节点的描述文本输入到预训练的语言模型e5-335M中，计算每个节点的表示$\bm{x}_{v}$，从而对任务图$G(V,E,X)$进行编码。然后，GNN将初始的节点嵌入矩阵转换为$H$。该GNN配置为$2$层GraphSAGE，隐藏维度为$1024$。接着，进一步对节点嵌入应用均值池化操作，得到图的整体表示$\bm{h}_{G}=\text{Mean-Pooling}(H)$。最后，$\bm{h}_{G}$和输入指令及用户请求的文本嵌入被连接起来，并输入到LLM中以生成输出规划结果。在此过程中，骨干LLM被冻结，只有GNN的参数被调优。对于每个数据集，我们在$4$个epochs内使用相同的$3,000$个训练样本进行训练，这些样本由<用户请求，真实规划>对组成。批量大小设置为$16$，HuggingFace和Multimedia数据集的最大输入长度为$512$，最大输出长度为$300$，DailyLife数据集的最大输出长度为$600$。学习率设置为$1e-5$。
- en: F.3 Implementation of Fine-tuning LLMs
  id: totrans-578
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.3 微调LLM的实现
- en: To explore the effectiveness of our proposed framework on fine-tuned LLMs, we
    employ Supervised Fine-Tuning (SFT) on the CodeLlama-7B and Vicuna-13B models.
    We use the same set of $3,000$ samples from GNN training as the LLMs’ fine-tuning
    data. In fine-tuning the LLM with LoRA [[19](https://arxiv.org/html/2405.19119v3#bib.bib19)],
    we set the lora_r parameter (dimension for LoRA update matrices) to $8$ and the
    lora_alpha (scaling factor) to $16$. The dropout ratio is set to $0.1$, the batch
    size to $2$, and we conduct training over 2 epochs with a learning rate of $1e-5$.
    For HuggingFace dataset, the maximum input length is set to 800, while the maximum
    output length is 400\. For Multimedia and Daily Life datasets, which contain a
    larger number of tasks and require longer textual inputs, we set the maximum input
    and output length to 1000 and 500, respectively. We utilize 2 NVIDIA A100-80G
    GPUs for fine-tuning the LLMs.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索我们提出的框架在微调的 LLMs 上的有效性，我们对 CodeLlama-7B 和 Vicuna-13B 模型进行了监督微调（SFT）。我们使用了与
    LLM 微调数据相同的 $3,000$ 个 GNN 训练样本。在用 LoRA [[19](https://arxiv.org/html/2405.19119v3#bib.bib19)]
    微调 LLM 时，我们将 lora_r 参数（LoRA 更新矩阵的维度）设置为 $8$，将 lora_alpha（缩放因子）设置为 $16$。丢弃率设置为
    $0.1$，批量大小设置为 $2$，并且我们在 $1e-5$ 的学习率下进行 2 个周期的训练。对于 HuggingFace 数据集，最大输入长度设置为 800，而最大输出长度为
    400。对于多媒体和日常生活数据集，这些数据集包含更多的任务且需要更长的文本输入，因此我们将最大输入和输出长度分别设置为 1000 和 500。我们使用 2
    个 NVIDIA A100-80G GPU 来微调 LLMs。
- en: F.4 Full Results of Training-based GNNs
  id: totrans-580
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.4 基于训练的 GNN 完整结果
- en: In Table [11](https://arxiv.org/html/2405.19119v3#A6.T11 "Table 11 ‣ F.4 Full
    Results of Training-based GNNs ‣ Appendix F Supplementary Materials for Training-based
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?"), we present
    comprehensive results for all training-based GNNs, including GCN [[26](https://arxiv.org/html/2405.19119v3#bib.bib26)],
    GAT [[57](https://arxiv.org/html/2405.19119v3#bib.bib57)], GraphSAGE [[15](https://arxiv.org/html/2405.19119v3#bib.bib15)],
    GIN [[67](https://arxiv.org/html/2405.19119v3#bib.bib67)], and Graph Transformer
    [[47](https://arxiv.org/html/2405.19119v3#bib.bib47)]. To highlight the improvements
    brought by GNNs, we also include results from the strongest baseline, BeamSearch.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 在表格 [11](https://arxiv.org/html/2405.19119v3#A6.T11 "Table 11 ‣ F.4 Full Results
    of Training-based GNNs ‣ Appendix F Supplementary Materials for Training-based
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?") 中，我们展示了所有基于训练的
    GNN 的综合结果，包括 GCN [[26](https://arxiv.org/html/2405.19119v3#bib.bib26)]、GAT [[57](https://arxiv.org/html/2405.19119v3#bib.bib57)]、GraphSAGE
    [[15](https://arxiv.org/html/2405.19119v3#bib.bib15)]、GIN [[67](https://arxiv.org/html/2405.19119v3#bib.bib67)]
    和 Graph Transformer [[47](https://arxiv.org/html/2405.19119v3#bib.bib47)]。为了突出
    GNN 所带来的改进，我们还包括了最强基线的结果——BeamSearch。
- en: From the results, it is obvious that all GNN encoders significantly enhance
    the task planning abilities. For instance, when applied to Vicuna-13B on HuggingFace
    dataset, the introduction of GCN results in a performance improvement of $17.83\%$,
    GAT contributes to a $17.48\%$ increase, GraphSAGE leads to a $22.59\%$ boost,
    and GraphTransformer improves predictions by $18.0\%$. This conclusion can be
    generalized across various LLMs and datasets, demonstrating the robust capabilities
    of GNNs.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果来看，显然所有 GNN 编码器都显著增强了任务规划能力。例如，当应用于 HuggingFace 数据集上的 Vicuna-13B 时，引入 GCN
    使性能提高了 $17.83\%$，GAT 贡献了 $17.48\%$ 的提升，GraphSAGE 提高了 $22.59\%$，而 GraphTransformer
    使预测结果提高了 $18.0\%$。这一结论可以推广到各种 LLMs 和数据集，展示了 GNNs 的强大能力。
- en: 'Table 11: Performance of training-based GNNs. We also presents the results
    of BeamSeaerch, the strongest variant from GraphSearch method to provide a comprehensive
    comparison. All GNNs consistently enhance task planning performance across diverse
    LLMs, showing the effectiveness.'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 11：基于训练的 GNN 性能。我们还展示了来自 GraphSearch 方法的最强变体 BeamSearch 的结果，以提供全面的比较。所有 GNN
    一致地提高了不同 LLMs 上的任务规划性能，展示了其有效性。
- en: '|  |  | HuggingFace Tools | Multimedia Tools | Daily Life APIs |'
  id: totrans-584
  prefs: []
  type: TYPE_TB
  zh: '|  |  | HuggingFace 工具 | 多媒体工具 | 日常生活 API |'
- en: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | n-F1 $\uparrow$ | l-F1
    $\uparrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ |'
  id: totrans-585
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | n-F1 $\uparrow$ | l-F1 $\uparrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$
    | n-F1 $\uparrow$ | l-F1 $\uparrow$ |'
- en: '| Baichuan-13B | Direct | 45.85 | 19.00 | 47.57 | 4.08 | 33.45 | 9.52 |'
  id: totrans-586
  prefs: []
  type: TYPE_TB
  zh: '| Baichuan-13B | 直接 | 45.85 | 19.00 | 47.57 | 4.08 | 33.45 | 9.52 |'
- en: '| BeamSearch | 41.06 | 9.59 | 32.24 | 9.09 | 36.18 | 13.18 |'
  id: totrans-587
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 41.06 | 9.59 | 32.24 | 9.09 | 36.18 | 13.18 |'
- en: '| GCN | 57.67 | 31.47 | 55.51 | 30.16 | 62.11 | 37.05 |'
  id: totrans-588
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 57.67 | 31.47 | 55.51 | 30.16 | 62.11 | 37.05 |'
- en: '| GAT | 57.74 | 31.87 | 54.95 | 29.24 | 62.11 | 37.05 |'
  id: totrans-589
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 57.74 | 31.87 | 54.95 | 29.24 | 62.11 | 37.05 |'
- en: '| GraphSAGE | 59.32 | 34.36 | 56.15 | 31.60 | 65.18 | 40.49 |'
  id: totrans-590
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 59.32 | 34.36 | 56.15 | 31.60 | 65.18 | 40.49 |'
- en: '| GIN | 57.38 | 31.17 | 55.08 | 30.04 | 62.11 | 37.05 |'
  id: totrans-591
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 57.38 | 31.17 | 55.08 | 30.04 | 62.11 | 37.05 |'
- en: '| GraphTransformer | 59.15 | 34.36 | 56.06 | 31.12 | 64.52 | 40.14 |'
  id: totrans-592
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 59.15 | 34.36 | 56.06 | 31.12 | 64.52 | 40.14 |'
- en: '| Vicuna-13B | Direct | 50.46 | 21.27 | 53.57 | 23.19 | 73.70 | 45.80 |'
  id: totrans-593
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna-13B | Direct | 50.46 | 21.27 | 53.57 | 23.19 | 73.70 | 45.80 |'
- en: '| BeamSearch | 56.64 | 26.93 | 54.09 | 26.19 | 54.55 | 23.60 |'
  id: totrans-594
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 56.64 | 26.93 | 54.09 | 26.19 | 54.55 | 23.60 |'
- en: '| GCN | 59.46 | 33.14 | 62.48 | 38.89 | 83.05 | 62.95 |'
  id: totrans-595
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 59.46 | 33.14 | 62.48 | 38.89 | 83.05 | 62.95 |'
- en: '| GAT | 59.28 | 33.39 | 62.96 | 39.24 | 83.05 | 62.95 |'
  id: totrans-596
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 59.28 | 33.39 | 62.96 | 39.24 | 83.05 | 62.95 |'
- en: '| GraphSAGE | 61.86 | 35.68 | 63.71 | 39.88 | 86.07 | 67.63 |'
  id: totrans-597
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 61.86 | 35.68 | 63.71 | 39.88 | 86.07 | 67.63 |'
- en: '| GIN | 59.14 | 32.33 | 62.61 | 38.82 | 83.05 | 62.95 |'
  id: totrans-598
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 59.14 | 32.33 | 62.61 | 38.82 | 83.05 | 62.95 |'
- en: '| GraphTransformer | 59.57 | 33.47 | 63.32 | 39.38 | 85.41 | 66.28 |'
  id: totrans-599
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 59.57 | 33.47 | 63.32 | 39.38 | 85.41 | 66.28 |'
- en: '| CodeLlama-7B | Direct | 58.06 | 29.39 | 59.44 | 30.83 | 84.12 | 62.89 |'
  id: totrans-600
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-7B | Direct | 58.06 | 29.39 | 59.44 | 30.83 | 84.12 | 62.89 |'
- en: '| BeamSearch | 60.34 | 31.36 | 64.12 | 38.99 | 83.25 | 63.48 |'
  id: totrans-601
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 60.34 | 31.36 | 64.12 | 38.99 | 83.25 | 63.48 |'
- en: '| GCN | 65.07 | 40.50 | 67.46 | 45.84 | 87.23 | 69.27 |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 65.07 | 40.50 | 67.46 | 45.84 | 87.23 | 69.27 |'
- en: '| GAT | 65.20 | 40.93 | 67.41 | 46.46 | 87.23 | 69.27 |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 65.20 | 40.93 | 67.41 | 46.46 | 87.23 | 69.27 |'
- en: '| GraphSAGE | 66.67 | 43.03 | 67.97 | 46.31 | 88.53 | 72.02 |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 66.67 | 43.03 | 67.97 | 46.31 | 88.53 | 72.02 |'
- en: '| GIN | 65.52 | 40.98 | 66.89 | 45.41 | 87.23 | 69.27 |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 65.52 | 40.98 | 66.89 | 45.41 | 87.23 | 69.27 |'
- en: '| GraphTransformer | 65.83 | 42.58 | 68.90 | 47.20 | 88.36 | 71.72 |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 65.83 | 42.58 | 68.90 | 47.20 | 88.36 | 71.72 |'
- en: '| Mistral-7B | Direct | 60.60 | 30.23 | 69.83 | 39.85 | 84.26 | 53.63 |'
  id: totrans-607
  prefs: []
  type: TYPE_TB
  zh: '| Mistral-7B | Direct | 60.60 | 30.23 | 69.83 | 39.85 | 84.26 | 53.63 |'
- en: '| BeamSearch | 67.13 | 36.73 | 73.55 | 47.12 | 85.87 | 61.53 |'
  id: totrans-608
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 67.13 | 36.73 | 73.55 | 47.12 | 85.87 | 61.53 |'
- en: '| GCN | 66.54 | 40.74 | 73.34 | 50.76 | 86.39 | 65.49 |'
  id: totrans-609
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 66.54 | 40.74 | 73.34 | 50.76 | 86.39 | 65.49 |'
- en: '| GAT | 66.77 | 40.74 | 73.36 | 50.20 | 86.39 | 65.49 |'
  id: totrans-610
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 66.77 | 40.74 | 73.36 | 50.20 | 86.39 | 65.49 |'
- en: '| GraphSAGE | 68.12 | 43.09 | 75.51 | 52.94 | 87.51 | 66.57 |'
  id: totrans-611
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 68.12 | 43.09 | 75.51 | 52.94 | 87.51 | 66.57 |'
- en: '| GIN | 66.69 | 40.79 | 72.89 | 50.44 | 86.39 | 65.49 |'
  id: totrans-612
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 66.69 | 40.79 | 72.89 | 50.44 | 86.39 | 65.49 |'
- en: '| GraphTransformer | 68.26 | 43.08 | 73.80 | 51.45 | 88.25 | 67.84 |'
  id: totrans-613
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 68.26 | 43.08 | 73.80 | 51.45 | 88.25 | 67.84 |'
- en: '|  | Direct | 57.55 | 28.88 | 68.57 | 41.79 | 91.20 | 76.07 |'
  id: totrans-614
  prefs: []
  type: TYPE_TB
  zh: '|  | Direct | 57.55 | 28.88 | 68.57 | 41.79 | 91.20 | 76.07 |'
- en: '|  | BeamSearch | 62.65 | 34.31 | 69.53 | 43.35 | 91.74 | 76.60 |'
  id: totrans-615
  prefs: []
  type: TYPE_TB
  zh: '|  | BeamSearch | 62.65 | 34.31 | 69.53 | 43.35 | 91.74 | 76.60 |'
- en: '|  | GCN | 66.22 | 41.05 | 72.99 | 52.18 | 91.83 | 77.88 |'
  id: totrans-616
  prefs: []
  type: TYPE_TB
  zh: '|  | GCN | 66.22 | 41.05 | 72.99 | 52.18 | 91.83 | 77.88 |'
- en: '|  | GAT | 66.29 | 41.28 | 74.08 | 53.56 | 91.83 | 77.88 |'
  id: totrans-617
  prefs: []
  type: TYPE_TB
  zh: '|  | GAT | 66.29 | 41.28 | 74.08 | 53.56 | 91.83 | 77.88 |'
- en: '|  | GraphSAGE | 67.30 | 42.41 | 74.93 | 54.52 | 93.84 | 80.38 |'
  id: totrans-618
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphSAGE | 67.30 | 42.41 | 74.93 | 54.52 | 93.84 | 80.38 |'
- en: '|  | GIN | 66.40 | 40.89 | 73.62 | 53.15 | 91.83 | 77.88 |'
  id: totrans-619
  prefs: []
  type: TYPE_TB
  zh: '|  | GIN | 66.40 | 40.89 | 73.62 | 53.15 | 91.83 | 77.88 |'
- en: '| CodeLlama-13B | GraphTransformer | 66.70 | 42.07 | 74.72 | 54.10 | 93.81
    | 80.44 |'
  id: totrans-620
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-13B | GraphTransformer | 66.70 | 42.07 | 74.72 | 54.10 | 93.81
    | 80.44 |'
- en: '| GPT-3.5-turbo | Direct | 73.85 | 45.73 | 82.85 | 62.07 | 96.09 | 83.65 |'
  id: totrans-621
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | Direct | 73.85 | 45.73 | 82.85 | 62.07 | 96.09 | 83.65 |'
- en: '| BeamSearch | 75.51 | 49.62 | 83.57 | 64.50 | 95.66 | 82.72 |'
  id: totrans-622
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 75.51 | 49.62 | 83.57 | 64.50 | 95.66 | 82.72 |'
- en: '| GCN | 76.93 | 51.43 | 84.92 | 65.05 | 96.38 | 86.15 |'
  id: totrans-623
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 76.93 | 51.43 | 84.92 | 65.05 | 96.38 | 86.15 |'
- en: '| GAT | 75.63 | 49.36 | 84.77 | 65.48 | 96.38 | 86.15 |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 75.63 | 49.36 | 84.77 | 65.48 | 96.38 | 86.15 |'
- en: '| GraphSAGE | 77.90 | 52.68 | 85.29 | 65.80 | 96.43 | 86.26 |'
  id: totrans-625
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 77.90 | 52.68 | 85.29 | 65.80 | 96.43 | 86.26 |'
- en: '| GIN | 76.86 | 51.00 | 84.14 | 64.30 | 96.38 | 86.15 |'
  id: totrans-626
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 76.86 | 51.00 | 84.14 | 64.30 | 96.38 | 86.15 |'
- en: '| GraphTransformer | 77.61 | 52.30 | 84.21 | 64.32 | 96.38 | 86.19 |'
  id: totrans-627
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 77.61 | 52.30 | 84.21 | 64.32 | 96.38 | 86.19 |'
- en: '| GPT-4-turbo | Direct | 77.60 | 52.18 | 88.29 | 69.38 | 97.36 | 84.58 |'
  id: totrans-628
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-turbo | Direct | 77.60 | 52.18 | 88.29 | 69.38 | 97.36 | 84.58 |'
- en: '| BeamSearch | 77.56 | 52.54 | 88.16 | 70.39 | 97.35 | 85.78 |'
  id: totrans-629
  prefs: []
  type: TYPE_TB
  zh: '| BeamSearch | 77.56 | 52.54 | 88.16 | 70.39 | 97.35 | 85.78 |'
- en: '| GCN | 77.01 | 50.49 | 88.56 | 69.60 | 97.10 | 85.22 |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 77.01 | 50.49 | 88.56 | 69.60 | 97.10 | 85.22 |'
- en: '| GAT | 76.41 | 49.66 | 88.43 | 69.52 | 97.10 | 85.22 |'
  id: totrans-631
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 76.41 | 49.66 | 88.43 | 69.52 | 97.10 | 85.22 |'
- en: '| GraphSAGE | 78.76 | 52.53 | 88.63 | 69.65 | 97.34 | 85.67 |'
  id: totrans-632
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 78.76 | 52.53 | 88.63 | 69.65 | 97.34 | 85.67 |'
- en: '| GIN | 77.74 | 51.02 | 88.05 | 69.13 | 97.36 | 84.58 |'
  id: totrans-633
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 77.74 | 51.02 | 88.05 | 69.13 | 97.36 | 84.58 |'
- en: '|  | GraphTransformer | 78.47 | 52.17 | 88.07 | 68.71 | 97.32 | 85.57 |'
  id: totrans-634
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphTransformer | 78.47 | 52.17 | 88.07 | 68.71 | 97.32 | 85.57 |'
- en: 'Table 12: Performance of Training-based GNNs under the LM+GNN Co-trained Mode.
    Simultaneous training of LM and GNN yields significant performance improvements.'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: '表 12: 基于训练的GNN在LM+GNN联合训练模式下的性能。LM和GNN的同时训练显著提升了性能。'
- en: '|  |  | HuggingFace Tools | Multimedia Tools | Daily Life APIs |'
  id: totrans-636
  prefs: []
  type: TYPE_TB
  zh: '|  |  | HuggingFace工具 | 多媒体工具 | 日常生活API |'
- en: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | n-F1 $\uparrow$ | l-F1
    $\uparrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ |'
  id: totrans-637
  prefs: []
  type: TYPE_TB
  zh: '| LLM | Method | n-F1 $\uparrow$ | l-F1 $\uparrow$ | n-F1 $\uparrow$ | l-F1
    $\uparrow$ | n-F1 $\uparrow$ | l-F1 $\uparrow$ |'
- en: '| Baichuan-13B | Direct | 45.85 | 19.00 | 47.57 | 4.08 | 33.45 | 9.52 |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| Baichuan-13B | Direct | 45.85 | 19.00 | 47.57 | 4.08 | 33.45 | 9.52 |'
- en: '| SGC | 60.97 | 36.12 | 56.02 | 31.36 | 64.84 | 40.00 |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 60.97 | 36.12 | 56.02 | 31.36 | 64.84 | 40.00 |'
- en: '| GCN | 60.68 | 36.31 | 57.82 | 32.87 | 64.73 | 38.92 |'
  id: totrans-640
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 60.68 | 36.31 | 57.82 | 32.87 | 64.73 | 38.92 |'
- en: '| GAT | 60.39 | 35.37 | 57.24 | 32.19 | 64.46 | 40.14 |'
  id: totrans-641
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 60.39 | 35.37 | 57.24 | 32.19 | 64.46 | 40.14 |'
- en: '| GraphSAGE | 59.76 | 35.59 | 57.97 | 33.29 | 63.21 | 38.10 |'
  id: totrans-642
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 59.76 | 35.59 | 57.97 | 33.29 | 63.21 | 38.10 |'
- en: '| GIN | 60.31 | 35.82 | 56.62 | 31.53 | 63.55 | 38.19 |'
  id: totrans-643
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 60.31 | 35.82 | 56.62 | 31.53 | 63.55 | 38.19 |'
- en: '| GraphTransformer | 60.76 | 36.82 | 56.82 | 31.40 | 64.88 | 40.23 |'
  id: totrans-644
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 60.76 | 36.82 | 56.82 | 31.40 | 64.88 | 40.23 |'
- en: '| Vicuna-13B | Direct | 50.46 | 21.27 | 53.57 | 23.19 | 73.70 | 45.80 |'
  id: totrans-645
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna-13B | Direct | 50.46 | 21.27 | 53.57 | 23.19 | 73.70 | 45.80 |'
- en: '| SGC | 64.40 | 38.97 | 65.12 | 41.63 | 84.74 | 65.90 |'
  id: totrans-646
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 64.40 | 38.97 | 65.12 | 41.63 | 84.74 | 65.90 |'
- en: '| GCN | 62.06 | 35.49 | 65.02 | 40.63 | 85.22 | 66.93 |'
  id: totrans-647
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 62.06 | 35.49 | 65.02 | 40.63 | 85.22 | 66.93 |'
- en: '| GAT | 63.06 | 36.97 | 64.58 | 40.30 | 85.63 | 67.11 |'
  id: totrans-648
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 63.06 | 36.97 | 64.58 | 40.30 | 85.63 | 67.11 |'
- en: '| GraphSAGE | 62.82 | 37.04 | 65.89 | 42.18 | 84.23 | 65.44 |'
  id: totrans-649
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 62.82 | 37.04 | 65.89 | 42.18 | 84.23 | 65.44 |'
- en: '| GIN | 62.09 | 35.33 | 64.44 | 40.67 | 85.31 | 66.83 |'
  id: totrans-650
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 62.09 | 35.33 | 64.44 | 40.67 | 85.31 | 66.83 |'
- en: '| GraphTransformer | 62.11 | 36.01 | 64.57 | 40.17 | 85.42 | 66.55 |'
  id: totrans-651
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 62.11 | 36.01 | 64.57 | 40.17 | 85.42 | 66.55 |'
- en: '| CodeLlama-7B | Direct | 58.06 | 29.39 | 59.44 | 30.83 | 84.12 | 62.89 |'
  id: totrans-652
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-7B | Direct | 58.06 | 29.39 | 59.44 | 30.83 | 84.12 | 62.89 |'
- en: '| SGC | 67.47 | 43.58 | 69.61 | 48.24 | 87.98 | 70.63 |'
  id: totrans-653
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 67.47 | 43.58 | 69.61 | 48.24 | 87.98 | 70.63 |'
- en: '| GCN | 67.03 | 43.24 | 69.33 | 47.60 | 87.88 | 70.40 |'
  id: totrans-654
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 67.03 | 43.24 | 69.33 | 47.60 | 87.88 | 70.40 |'
- en: '| GAT | 67.12 | 42.96 | 68.62 | 46.17 | 88.59 | 71.64 |'
  id: totrans-655
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 67.12 | 42.96 | 68.62 | 46.17 | 88.59 | 71.64 |'
- en: '| GraphSAGE | 67.19 | 42.94 | 70.00 | 48.28 | 87.81 | 70.20 |'
  id: totrans-656
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 67.19 | 42.94 | 70.00 | 48.28 | 87.81 | 70.20 |'
- en: '| GIN | 66.62 | 42.34 | 69.00 | 47.72 | 88.45 | 71.53 |'
  id: totrans-657
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 66.62 | 42.34 | 69.00 | 47.72 | 88.45 | 71.53 |'
- en: '| GraphTransformer | 67.12 | 43.08 | 69.27 | 47.96 | 88.43 | 71.59 |'
  id: totrans-658
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 67.12 | 43.08 | 69.27 | 47.96 | 88.43 | 71.59 |'
- en: '| Mistral-7B | Direct | 60.60 | 30.23 | 69.83 | 39.85 | 84.26 | 53.63 |'
  id: totrans-659
  prefs: []
  type: TYPE_TB
  zh: '| Mistral-7B | Direct | 60.60 | 30.23 | 69.83 | 39.85 | 84.26 | 53.63 |'
- en: '| SGC | 69.04 | 44.22 | 76.09 | 54.91 | 87.58 | 66.70 |'
  id: totrans-660
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 69.04 | 44.22 | 76.09 | 54.91 | 87.58 | 66.70 |'
- en: '| GCN | 67.72 | 43.02 | 76.79 | 54.90 | 87.87 | 67.13 |'
  id: totrans-661
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 67.72 | 43.02 | 76.79 | 54.90 | 87.87 | 67.13 |'
- en: '| GAT | 67.54 | 43.56 | 76.26 | 53.94 | 87.86 | 67.30 |'
  id: totrans-662
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 67.54 | 43.56 | 76.26 | 53.94 | 87.86 | 67.30 |'
- en: '| GraphSAGE | 67.61 | 43.14 | 76.96 | 55.46 | 87.61 | 66.75 |'
  id: totrans-663
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 67.61 | 43.14 | 76.96 | 55.46 | 87.61 | 66.75 |'
- en: '| GIN | 68.95 | 43.97 | 76.47 | 54.95 | 87.75 | 67.07 |'
  id: totrans-664
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 68.95 | 43.97 | 76.47 | 54.95 | 87.75 | 67.07 |'
- en: '| GraphTransformer | 67.94 | 43.52 | 77.06 | 55.39 | 87.76 | 67.00 |'
  id: totrans-665
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 67.94 | 43.52 | 77.06 | 55.39 | 87.76 | 67.00 |'
- en: '| CodeLlama-13B | Direct | 57.55 | 28.88 | 68.57 | 41.79 | 91.20 | 76.07 |'
  id: totrans-666
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-13B | Direct | 57.55 | 28.88 | 68.57 | 41.79 | 91.20 | 76.07 |'
- en: '| SGC | 70.14 | 45.20 | 75.65 | 55.45 | 93.45 | 79.89 |'
  id: totrans-667
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 70.14 | 45.20 | 75.65 | 55.45 | 93.45 | 79.89 |'
- en: '| GCN | 69.39 | 45.18 | 76.03 | 55.22 | 93.38 | 79.74 |'
  id: totrans-668
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 69.39 | 45.18 | 76.03 | 55.22 | 93.38 | 79.74 |'
- en: '| GAT | 69.68 | 45.57 | 75.24 | 54.99 | 94.06 | 80.96 |'
  id: totrans-669
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 69.68 | 45.57 | 75.24 | 54.99 | 94.06 | 80.96 |'
- en: '| GraphSAGE | 68.92 | 44.85 | 76.28 | 55.41 | 93.30 | 79.51 |'
  id: totrans-670
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 68.92 | 44.85 | 76.28 | 55.41 | 93.30 | 79.51 |'
- en: '| GIN | 69.01 | 44.76 | 74.72 | 53.91 | 94.24 | 81.23 |'
  id: totrans-671
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 69.01 | 44.76 | 74.72 | 53.91 | 94.24 | 81.23 |'
- en: '| GraphTransformer | 69.52 | 45.68 | 75.46 | 55.14 | 93.98 | 81.06 |'
  id: totrans-672
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 69.52 | 45.68 | 75.46 | 55.14 | 93.98 | 81.06 |'
- en: '| GPT-3.5-turbo | Direct | 73.85 | 45.73 | 82.85 | 62.07 | 96.09 | 83.65 |'
  id: totrans-673
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | Direct | 73.85 | 45.73 | 82.85 | 62.07 | 96.09 | 83.65 |'
- en: '| SGC | 77.87 | 52.86 | 85.95 | 66.95 | 96.39 | 86.16 |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 77.87 | 52.86 | 85.95 | 66.95 | 96.39 | 86.16 |'
- en: '| GCN | 77.72 | 52.58 | 85.84 | 66.92 | 96.33 | 86.06 |'
  id: totrans-675
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 77.72 | 52.58 | 85.84 | 66.92 | 96.33 | 86.06 |'
- en: '| GAT | 77.49 | 52.30 | 85.81 | 66.97 | 96.38 | 86.15 |'
  id: totrans-676
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 77.49 | 52.30 | 85.81 | 66.97 | 96.38 | 86.15 |'
- en: '| GraphSAGE | 77.87 | 53.04 | 85.51 | 66.56 | 96.34 | 86.09 |'
  id: totrans-677
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 77.87 | 53.04 | 85.51 | 66.56 | 96.34 | 86.09 |'
- en: '| GIN | 77.73 | 52.36 | 85.63 | 66.69 | 96.38 | 86.19 |'
  id: totrans-678
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 77.73 | 52.36 | 85.63 | 66.69 | 96.38 | 86.19 |'
- en: '|  | GraphTransformer | 77.78 | 52.79 | 86.09 | 67.26 | 96.33 | 86.06 |'
  id: totrans-679
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphTransformer | 77.78 | 52.79 | 86.09 | 67.26 | 96.33 | 86.06 |'
- en: '| GPT-4-turbo | Direct | 77.60 | 52.18 | 88.29 | 69.38 | 97.36 | 84.58 |'
  id: totrans-680
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4-turbo | Direct | 77.60 | 52.18 | 88.29 | 69.38 | 97.36 | 84.58 |'
- en: '| SGC | 78.44 | 52.84 | 89.09 | 70.52 | 97.38 | 85.85 |'
  id: totrans-681
  prefs: []
  type: TYPE_TB
  zh: '| SGC | 78.44 | 52.84 | 89.09 | 70.52 | 97.38 | 85.85 |'
- en: '| GCN | 78.33 | 52.75 | 89.00 | 70.24 | 97.34 | 85.67 |'
  id: totrans-682
  prefs: []
  type: TYPE_TB
  zh: '| GCN | 78.33 | 52.75 | 89.00 | 70.24 | 97.34 | 85.67 |'
- en: '| GAT | 78.37 | 52.43 | 88.99 | 70.48 | 97.32 | 85.56 |'
  id: totrans-683
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 78.37 | 52.43 | 88.99 | 70.48 | 97.32 | 85.56 |'
- en: '| GraphSAGE | 78.49 | 52.62 | 88.86 | 70.25 | 97.42 | 85.80 |'
  id: totrans-684
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 78.49 | 52.62 | 88.86 | 70.25 | 97.42 | 85.80 |'
- en: '| GIN | 78.45 | 53.07 | 88.74 | 69.84 | 97.42 | 85.80 |'
  id: totrans-685
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 78.45 | 53.07 | 88.74 | 69.84 | 97.42 | 85.80 |'
- en: '|  | GraphTransformer | 78.30 | 52.27 | 88.90 | 70.24 | 97.42 | 85.80 |'
  id: totrans-686
  prefs: []
  type: TYPE_TB
  zh: '|  | GraphTransformer | 78.30 | 52.27 | 88.90 | 70.24 | 97.42 | 85.80 |'
- en: F.5 Performance of LM+GNN Co-trained Mode
  id: totrans-687
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.5 LM+GNN联合训练模式的性能
- en: During our main experiments, the LM backbone remains frozen while only the GNN
    is trained to automatically learn the alignment between implicit step descriptions
    and suitable tasks, facilitating task retrieval. In this subsection, we conduct
    a supplementary study where the parameters of a pre-trained LM are also tuned
    along with GNN during model training. The model configuration is illustrated in
    Figure [8](https://arxiv.org/html/2405.19119v3#A6.F8 "Figure 8 ‣ F.1 Implementation
    of Training-based GNNs ‣ Appendix F Supplementary Materials for Training-based
    Methods ‣ Can Graph Learning Improve Planning in LLM-based Agents?"), and the
    results are presented in Table [12](https://arxiv.org/html/2405.19119v3#A6.T12
    "Table 12 ‣ F.4 Full Results of Training-based GNNs ‣ Appendix F Supplementary
    Materials for Training-based Methods ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?").
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的主要实验中，LM骨干网络保持冻结，只有GNN被训练以自动学习隐性步骤描述与合适任务之间的对齐，从而促进任务检索。在本小节中，我们进行了一项补充研究，其中预训练的LM的参数与GNN一起在模型训练期间进行调优。模型配置如图[8](https://arxiv.org/html/2405.19119v3#A6.F8
    "图8 ‣ F.1 基于训练的GNN实现 ‣ 附录F 基于训练方法的补充材料 ‣ 图学习能否改善基于LLM的智能体的规划？")所示，结果见表[12](https://arxiv.org/html/2405.19119v3#A6.T12
    "表12 ‣ F.4 基于训练的GNN的完整结果 ‣ 附录F 基于训练方法的补充材料 ‣ 图学习能否改善基于LLM的智能体的规划？")。
- en: The results demonstrate that, compared to the GNN-only tunable mode, co-training
    LM+GNN can lead to further performance improvements. This enhancement occurs because
    the language model acquires task-specific semantics, which makes the representations
    more discriminative and boosts the GNN’s effectiveness in task retrieval. Additionally,
    it is noted that under the co-training setup, the differences between various
    GNN encoders are relatively minor, with performance variations across GNNs for
    a specific LLM on any dataset remaining within $2\%$.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，与仅GNN可调模式相比，联合训练LM+GNN可以进一步提升性能。这种提升的原因在于语言模型获得了特定任务的语义，使得表示更加具有区分性，并增强了GNN在任务检索中的效果。此外，值得注意的是，在联合训练设置下，各种GNN编码器之间的差异相对较小，对于特定LLM在任何数据集上的性能变化均保持在$2\%$以内。
- en: F.6 Computational Cost Analysis
  id: totrans-690
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F.6 计算成本分析
- en: 'In this subsection, we provide the computational costs of training-based methods:
    training time for GNN or LM+GNN co-trained, and resources needed for fine-tuning
    LLMs. Results are shown in Table [13](https://arxiv.org/html/2405.19119v3#A6.T13
    "Table 13 ‣ F.6 Computational Cost Analysis ‣ Appendix F Supplementary Materials
    for Training-based Methods ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?").'
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们提供了基于训练的方法的计算成本：GNN或LM+GNN联合训练的训练时间，以及微调LLMs所需的资源。结果见表[13](https://arxiv.org/html/2405.19119v3#A6.T13
    "表13 ‣ F.6 计算成本分析 ‣ 附录F 基于训练方法的补充材料 ‣ 图学习能否改善基于LLM的智能体的规划？")。
- en: 'Table 13: Computational Cost Analysis of Training-based Methods. We present
    total training times for both GNN and LM+GNN co-trained modes, and resources needed
    for fine-tuning LLMs.'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 表 13：基于训练的方法的计算成本分析。我们展示了GNN和LM+GNN联合训练模式的总训练时间，以及微调LLMs所需的资源。
- en: '| Training GNNs |'
  id: totrans-693
  prefs: []
  type: TYPE_TB
  zh: '| 训练GNN |'
- en: '|  |  |  | Time (Seconds) |'
  id: totrans-694
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 时间（秒） |'
- en: '| Mode | Configuration | # Parameters | HuggingFace | Multimedia | Daily Life
    |'
  id: totrans-695
  prefs: []
  type: TYPE_TB
  zh: '| 模式 | 配置 | 参数数量 | HuggingFace | 多媒体 | 日常生活 |'
- en: '| GNN-only | GCN | 1,049,600 | 136.5 | 136.1 | 237.7 |'
  id: totrans-696
  prefs: []
  type: TYPE_TB
  zh: '| GNN-only | GCN | 1,049,600 | 136.5 | 136.1 | 237.7 |'
- en: '| GAT | 1,051,648 | 136.9 | 151.8 | 237.8 |'
  id: totrans-697
  prefs: []
  type: TYPE_TB
  zh: '| GAT | 1,051,648 | 136.9 | 151.8 | 237.8 |'
- en: '| GraphSAGE | 2,098,176 | 134.2 | 149.8 | 233.8 |'
  id: totrans-698
  prefs: []
  type: TYPE_TB
  zh: '| GraphSAGE | 2,098,176 | 134.2 | 149.8 | 233.8 |'
- en: '| GIN | 2,099,200 | 134.2 | 134.9 | 233.6 |'
  id: totrans-699
  prefs: []
  type: TYPE_TB
  zh: '| GIN | 2,099,200 | 134.2 | 134.9 | 233.6 |'
- en: '| GraphTransformer | 4,198,400 | 135.0 | 150.2 | 233.7 |'
  id: totrans-700
  prefs: []
  type: TYPE_TB
  zh: '| GraphTransformer | 4,198,400 | 135.0 | 150.2 | 233.7 |'
- en: '| LM+GNN Co-trained | LM+SGC | 335,141,889 | 743.1 | 323.3 | 384.7 |'
  id: totrans-701
  prefs: []
  type: TYPE_TB
  zh: '| LM+GNN联合训练 | LM+SGC | 335,141,889 | 743.1 | 323.3 | 384.7 |'
- en: '| LM+GCN | 336,191,488 | 482.8 | 567.8 | 384.2 |'
  id: totrans-702
  prefs: []
  type: TYPE_TB
  zh: '| LM+GCN | 336,191,488 | 482.8 | 567.8 | 384.2 |'
- en: '| LM+GAT | 336,193,536 | 741.3 | 812.3 | 384.4 |'
  id: totrans-703
  prefs: []
  type: TYPE_TB
  zh: '| LM+GAT | 336,193,536 | 741.3 | 812.3 | 384.4 |'
- en: '| LM+GraphSAGE | 337,240,064 | 741.2 | 406.8 | 381.7 |'
  id: totrans-704
  prefs: []
  type: TYPE_TB
  zh: '| LM+GraphSAGE | 337,240,064 | 741.2 | 406.8 | 381.7 |'
- en: '| LM+GIN | 337,241,088 | 735.6 | 361.8 | 382.9 |'
  id: totrans-705
  prefs: []
  type: TYPE_TB
  zh: '| LM+GIN | 337,241,088 | 735.6 | 361.8 | 382.9 |'
- en: '|  | LM+GraphTransformer | 339,340,288 | 741.0 | 362.7 | 405.8 |  | Fine-tuning
    LLMs |'
  id: totrans-706
  prefs: []
  type: TYPE_TB
  zh: '|  | LM+GraphTransformer | 339,340,288 | 741.0 | 362.7 | 405.8 |  | 微调LLMs
    |'
- en: '|  |  | Device & Time (Hours) |'
  id: totrans-707
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 设备与时间（小时） |'
- en: '| LLM | # Param (# Trainable Param) | HuggingFace | Multimedia | Daily Life
    |'
  id: totrans-708
  prefs: []
  type: TYPE_TB
  zh: '| LLM | # 参数 (# 可训练参数) | HuggingFace | 多媒体 | 日常生活 |'
- en: '| CodeLlama-7B | 6,742,740,992 (4,194,304) | 2$\times$A100 7.0 | 1$\times$A100
    13.8 | 2$\times$A100 9.5 |'
  id: totrans-709
  prefs: []
  type: TYPE_TB
  zh: '| CodeLlama-7B | 6,742,740,992 (4,194,304) | 2$\times$A100 7.0 | 1$\times$A100
    13.8 | 2$\times$A100 9.5 |'
- en: '| Vicuna-13B | 13,022,417,920 (6,553,600) | 1$\times$A100 17.8 | 2$\times$A100
    10.3 | 2$\times$A100 19.0 |'
  id: totrans-710
  prefs: []
  type: TYPE_TB
  zh: '| Vicuna-13B | 13,022,417,920 (6,553,600) | 1$\times$A100 17.8 | 2$\times$A100
    10.3 | 2$\times$A100 19.0 |'
- en: 'Efficiency of Training GNNs: During experiments, each dataset shares the same
    GNN configuration: $1$ single layer with a hidden dimension of $1024$. Therefore,
    for each GNN, its number of parameters remains consistent across datasets. The
    parameter scales for GNN variants range from 1M to 4M, and the total training
    time for each dataset requires only 2-4 minutes, comparable to the time taken
    by GraphSearch to fulfill a single request. For LM+GNN co-trained mode, where
    e5-335M [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)] serves as the LM
    backbone, training times increase to approximately 6-12 minutes. In summary, both
    modes demonstrate high efficiency, with total training times spanning minutes,
    showcasing their ability to rapidly adapt to new task planning scenarios.'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: 训练GNNs的效率：在实验中，每个数据集使用相同的GNN配置：$1$个单层，隐藏维度为$1024$。因此，对于每个GNN，其参数数量在不同数据集间保持一致。GNN变体的参数规模从1M到4M不等，每个数据集的总训练时间仅需2-4分钟，与GraphSearch处理单个请求所需的时间相当。对于LM+GNN联合训练模式，其中e5-335M
    [[62](https://arxiv.org/html/2405.19119v3#bib.bib62)]作为LM主干，训练时间增加到大约6-12分钟。总的来说，这两种模式都表现出高效率，总训练时间仅需几分钟，展示了它们在新任务规划场景中的快速适应能力。
- en: 'Efficiency of Fine-tuning LLMs: Fine-tuning a LLM with $3,000$ training samples
    over $2$ epochs requires huge time, typically 10-20 hours on one or two A100-80G
    GPU devices.'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 微调LLMs的效率：用$3,000$个训练样本进行$2$轮的LLM微调需要大量时间，通常在一个或两个A100-80G GPU设备上需要10-20小时。
- en: Appendix G Experiments on Task Parameter Prediction
  id: totrans-713
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录G 任务参数预测实验
- en: To assess the quality of task planning, we primarily focus on the predicted
    tasks and their dependencies, leaving the parameters for invoking these tasks
    undiscussed. As LLMs’ direct inference for solely predicting tasks has proven
    unsatisfactory (Figure [2](https://arxiv.org/html/2405.19119v3#S3.F2 "Figure 2
    ‣ 3.1 Graph Formulation of Task Planning ‣ 3 Graph Formulation and Insights ‣
    Can Graph Learning Improve Planning in LLM-based Agents?")), relying on LLMs alone
    to directly predict these parameters is unreliable. In this section, we will first
    demonstrate that it is quite straightforward for LLMs to fill in the parameters
    given a planned task sequence, which is a simple extension of our framework. Furthermore,
    we will empirically show that with more accurately planned tasks, i.e., those
    retrieved by GNNs, LLMs can intelligently fill in the parameters.
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估任务规划的质量，我们主要关注预测的任务及其依赖关系，而不讨论调用这些任务的参数。由于LLMs直接推断仅预测任务的效果不佳（图 [2](https://arxiv.org/html/2405.19119v3#S3.F2
    "图 2 ‣ 3.1 任务规划图的形式 ‣ 3 图形式与洞察 ‣ 图学习能否改善基于LLM的代理规划？")），仅依赖LLMs直接预测这些参数是不可靠的。在本节中，我们首先展示，给定一个规划的任务序列，LLMs填充参数是相当简单的，这只是我们框架的一个简单扩展。此外，我们将通过实验证明，通过更准确规划的任务，即那些由GNN检索的任务，LLMs能够智能地填充参数。
- en: G.1 Prompting LLMs to Fill in Parameters
  id: totrans-715
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.1 提示LLMs填充参数
- en: 'Process: Recall that our framework enables more accurate invoked task sequences,
    e.g., $\{v_{1},\ldots,v_{n}\}$, for a specific user request. To finalize the invocation
    sequence, just adding an additional LLM query can complete the invocation parameters
    for each task. Specifically, by providing the original user request, planned tasks,
    and detailed descriptions including each task’s input and output requirements,
    LLMs can be intelligently prompted to fill in the invocation parameters for each
    planned task, resulting in a well-structured invocation sequence ready for execution.
    Prompts are provided in Table [6](https://arxiv.org/html/2405.19119v3#A2.T6 "Table
    6 ‣ Appendix B Prompts ‣ Can Graph Learning Improve Planning in LLM-based Agents?").'
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 过程：回想一下，我们的框架能够为特定用户请求提供更准确的调用任务序列，例如 $\{v_{1},\ldots,v_{n}\}$。为了完成调用序列，只需添加一个额外的LLM查询，就可以为每个任务完成调用参数。具体而言，通过提供原始用户请求、规划的任务以及包括每个任务输入和输出要求的详细描述，可以智能地提示LLMs填充每个规划任务的调用参数，从而得到一个结构良好的调用序列，准备好执行。提示词见表
    [6](https://arxiv.org/html/2405.19119v3#A2.T6 "表 6 ‣ 附录 B 提示词 ‣ 图学习能否改善基于LLM的代理规划？")。
- en: 'Example: Taking the request shown in Figure [1](https://arxiv.org/html/2405.19119v3#S2.F1
    "Figure 1 ‣ 2.2 Current LLM-based Solution to Task Planning ‣ 2 Preliminaries
    ‣ Can Graph Learning Improve Planning in LLM-based Agents?") as an example, which
    is: “Please generate an image where a girl is reading a book, and her pose is
    the same as the boy in ‘example.jpg’. Then, please describe the new image with
    your voice.” Suppose GNN’s planned tasks include $\{$ Pose Detection, Pose-to-Image,
    Image-to-Text, Text-to-Speech $\}$. LLMs can intelligently fill in the invocation
    arguments as follows: [ {“task”: Pose Detection, “arguments”: [‘example.jpg’]
    }, {“task”: Pose-to-Image, “arguments”: [output pose from Pose Detection] }, {“task”:
    Image-to-Text, “arguments”: [output image from Pose-to-Image] }, {“task”: Text-to-Speech,
    “arguments”: [output text from Image-to-Text]}].'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: '示例：以图[1](https://arxiv.org/html/2405.19119v3#S2.F1 "Figure 1 ‣ 2.2 Current
    LLM-based Solution to Task Planning ‣ 2 Preliminaries ‣ Can Graph Learning Improve
    Planning in LLM-based Agents?")所示的请求为例，该请求为：“请生成一张女孩正在读书的图像，并且她的姿势与‘example.jpg’中的男孩相同。然后，请用你的声音描述这张新图像。”假设GNN计划的任务包括$\{$
    姿势检测、姿势到图像、图像到文本、文本到语音 $\}$。LLMs可以智能地填充调用参数，如下所示：[ {“task”: 姿势检测, “arguments”:
    [‘example.jpg’] }, {“task”: 姿势到图像, “arguments”: [姿势检测输出] }, {“task”: 图像到文本, “arguments”:
    [姿势到图像输出] }, {“task”: 文本到语音, “arguments”: [图像到文本输出]}]。'
- en: G.2 Empirical Results of LLMs Predicted Parameters
  id: totrans-718
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: G.2 LLM预测参数的实证结果
- en: 'Experimental Setup: We conduct this supplementary experiment on the HuggingFace
    dataset from TaskBench [[45](https://arxiv.org/html/2405.19119v3#bib.bib45)].
    Specifically, we compare the directly predicted invocation parameters from LLMs
    (denoted as Direct) with the parameters filled automatically by LLMs using our
    GNN-retrieved tasks (querying prompt as shown in Table [6](https://arxiv.org/html/2405.19119v3#A2.T6
    "Table 6 ‣ Appendix B Prompts ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")). For GNNs, we consider both training-free SGC and training-required
    GraphSAGE. Notably, with SGC, since the query for completing parameters is also
    training-free, the entire pipeline can be deployed without any extensive model
    training or labeled data. We adopt evaluation metrics from TaskBench, including
    Parameter-Type F1-Score (Param t-F1) and Parameter-Value F1-Score (Param v-F1).
    These metrics measure the accuracy of the predicted parameter types and concrete
    values, respectively. For example, when filling in the invocation for Pose Detection,
    the ground-truth parameter type is Image, and the ground-truth value is ‘example.jpg’.'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 实验设置：我们在来自 TaskBench 的 HuggingFace 数据集上进行这项补充实验[[45](https://arxiv.org/html/2405.19119v3#bib.bib45)]。具体来说，我们将LLMs直接预测的调用参数（标记为直接）与LLMs通过我们的GNN检索任务自动填充的参数进行比较（查询提示如表[6](https://arxiv.org/html/2405.19119v3#A2.T6
    "Table 6 ‣ Appendix B Prompts ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?")所示）。对于GNN，我们考虑了既不需要训练的SGC和需要训练的GraphSAGE。值得注意的是，使用SGC时，由于完成参数的查询也不需要训练，因此整个流程可以在没有任何广泛模型训练或标注数据的情况下部署。我们采用TaskBench的评估指标，包括参数类型F1分数（Param
    t-F1）和参数值F1分数（Param v-F1）。这些指标分别衡量预测的参数类型和具体值的准确性。例如，当填写姿势检测的调用时，真实的参数类型是图像，真实的值是‘example.jpg’。
- en: 'Table 14: Performance (in $\%$) of Task Parameters Prediction on the HuggingFace
    dataset'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14: 在 HuggingFace 数据集上任务参数预测的性能（以$\%$表示）'
- en: '| LLM | Method | t-F1 $\uparrow$ | v-F1 $\uparrow$ | LLM | Method | t-F1 $\uparrow$
    | v-F1 $\uparrow$ |'
  id: totrans-721
  prefs: []
  type: TYPE_TB
  zh: '| LLM | 方法 | t-F1 $\uparrow$ | v-F1 $\uparrow$ | LLM | 方法 | t-F1 $\uparrow$
    | v-F1 $\uparrow$ |'
- en: '|  | Direct | 38.77 | 18.56 |  | Direct | 44.62 | 33.24 |'
  id: totrans-722
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接 | 38.77 | 18.56 |  | 直接 | 44.62 | 33.24 |'
- en: '|  | SGC | 58.13${}_{\textbf{+19.36}}$ | 39.64${}_{\textbf{+21.08}}$ |  | SGC
    | 57.74${}_{\textbf{+13.21}}$ | 43.21${}_{\textbf{+9.97}}$ |'
  id: totrans-723
  prefs: []
  type: TYPE_TB
  zh: '|  | SGC | 58.13${}_{\textbf{+19.36}}$ | 39.64${}_{\textbf{+21.08}}$ |  | SGC
    | 57.74${}_{\textbf{+13.21}}$ | 43.21${}_{\textbf{+9.97}}$ |'
- en: '| Mistral-7B | GraphSAGE | 59.07${}_{\textbf{+20.30}}$ | 41.40${}_{\textbf{+22.84}}$
    | CodeLlama-13B | GraphSAGE | 59.49${}_{\textbf{+14.87}}$ | 45.54${}_{\textbf{+12.30}}$
    |'
  id: totrans-724
  prefs: []
  type: TYPE_TB
  zh: '| Mistral-7B | GraphSAGE | 59.07${}_{\textbf{+20.30}}$ | 41.40${}_{\textbf{+22.84}}$
    | CodeLlama-13B | GraphSAGE | 59.49${}_{\textbf{+14.87}}$ | 45.54${}_{\textbf{+12.30}}$
    |'
- en: '|  | Direct | 62.42 | 48.27 |  | Direct | 70.73 | 55.54 |'
  id: totrans-725
  prefs: []
  type: TYPE_TB
  zh: '|  | 直接 | 62.42 | 48.27 |  | 直接 | 70.73 | 55.54 |'
- en: '|  | SGC | 68.13${}_{\textbf{+5.71}}$ | 54.34${}_{\textbf{+6.07}}$ |  | SGC
    | 72.91${}_{\textbf{+2.18}}$ | 58.02${}_{\textbf{+2.48}}$ |'
  id: totrans-726
  prefs: []
  type: TYPE_TB
  zh: '|  | SGC | 68.13${}_{\textbf{+5.71}}$ | 54.34${}_{\textbf{+6.07}}$ |  | SGC
    | 72.91${}_{\textbf{+2.18}}$ | 58.02${}_{\textbf{+2.48}}$ |'
- en: '| GPT-3.5-turbo | GraphSAGE | 71.19${}_{\textbf{+8.77}}$ | 56.83${}_{\textbf{+8.56}}$
    | GPT-4-turbo | GraphSAGE | 73.09${}_{\textbf{+2.36}}$ | 58.20${}_{\textbf{+2.66}}$
    |'
  id: totrans-727
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5-turbo | GraphSAGE | 71.19${}_{\textbf{+8.77}}$ | 56.83${}_{\textbf{+8.56}}$
    | GPT-4-turbo | GraphSAGE | 73.09${}_{\textbf{+2.36}}$ | 58.20${}_{\textbf{+2.66}}$
    |'
- en: 'Observation: From the results shown in Table [14](https://arxiv.org/html/2405.19119v3#A7.T14
    "Table 14 ‣ G.2 Empirical Results of LLMs Predicted Parameters ‣ Appendix G Experiments
    on Task Parameter Prediction ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?"), we can conclude that: (1) LLMs’ direct inference of invocation arguments
    is unsatisfactory. Even for the strongest LLM, GPT-4-turbo, the Parameter-Value
    F1 score is only $55\%$, which is far from expectations. (2) With accurate planning
    provided by GNNs, LLMs can leverage their inherent reasoning abilities to analyze
    the context and correctly fill in the parameters. Across four LLMs, improvements
    of $3\%$ to $23\%$ can be observed, highlighting the advantages of GNN-enhanced
    planning. (3) Our method is well-suited for training-free scenarios, as the tasks
    retrieved by the training-free SGC already enable LLMs to infer the parameters
    effectively, with only a minor performance gap compared to the training-required
    GraphSAGE.'
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：从表 [14](https://arxiv.org/html/2405.19119v3#A7.T14 "Table 14 ‣ G.2 Empirical
    Results of LLMs Predicted Parameters ‣ Appendix G Experiments on Task Parameter
    Prediction ‣ Can Graph Learning Improve Planning in LLM-based Agents?")中展示的结果可以得出以下结论：(1)
    LLM 直接推断调用参数的效果不理想。即使是最强的 LLM——GPT-4-turbo，其参数-值 F1 得分也仅为 $55\%$，远未达到预期。(2) 通过
    GNN 提供的准确规划，LLM 可以利用其固有的推理能力来分析上下文并正确填写参数。在四个 LLM 中，提升幅度从 $3\%$ 到 $23\%$ 不等，凸显了
    GNN 增强规划的优势。(3) 我们的方法非常适合于免训练场景，因为通过免训练的 SGC 检索到的任务已能够有效地使 LLM 推断参数，且与需要训练的 GraphSAGE
    相比，性能差距很小。
- en: Appendix H Case Studies
  id: totrans-729
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 H 案例研究
- en: 'Effectiveness of GNNs: We show two cases in Figure [9](https://arxiv.org/html/2405.19119v3#A8.F9
    "Figure 9 ‣ Appendix H Case Studies ‣ Can Graph Learning Improve Planning in LLM-based
    Agents?") where the results of LLM’s direct inference, BeamSearch, and GraphSAGE
    are compared. Due to space constraints and issues such as LLM’s output content
    decoding errors or invalid paths, we present only the first four valid paths searched
    by BeamSearch on the task graph. From the cases, we can conclude that BeamSearch
    relies on LLM’s inherent reasoning abilities. Although LLM can explore the ground-truth
    invocation path on the task graph, their final solutions are usually not the optimal
    as either containing the hallucination or wrongly invoked tasks due to limited
    instruction following and reasoning abilities. On the contrary, GNN can effectively
    align decomposed steps with suitable tasks, accurately achieving the ground-truth
    result and enhancing task planning.'
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: GNN 效果：我们在图 [9](https://arxiv.org/html/2405.19119v3#A8.F9 "Figure 9 ‣ Appendix
    H Case Studies ‣ Can Graph Learning Improve Planning in LLM-based Agents?")中展示了两个案例，比较了
    LLM 直接推断、BeamSearch 和 GraphSAGE 的结果。由于空间限制以及 LLM 输出内容解码错误或无效路径等问题，我们仅展示了 BeamSearch
    在任务图上搜索到的前四条有效路径。从这些案例中，我们可以得出结论：BeamSearch 依赖于 LLM 的固有推理能力。尽管 LLM 可以在任务图上探索真实的调用路径，但由于缺乏足够的指令跟随和推理能力，它们的最终解决方案通常不是最优的，可能包含虚构的任务或错误调用的任务。相反，GNN
    能够有效地将分解的步骤与适当的任务对齐，准确地达成真实结果，并增强任务规划。
- en: '![Refer to caption](img/8af13c81bd81fe2e87f3b5de22ea3028.png)![Refer to caption](img/54df471e57de17274f7fad502c15e767.png)'
  id: totrans-731
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/8af13c81bd81fe2e87f3b5de22ea3028.png)![参见说明文字](img/54df471e57de17274f7fad502c15e767.png)'
- en: 'Figure 9: Case Study of GNN’s Effectiveness. Nodes colored in pink and red
    denote wrongly predicted task or hallucinated task, respectively. Due to space
    limitations, we only show the first four valid searched paths of BeamSearch for
    illustration. Even though LLM can explore ground-truth paths during searching,
    they lack certain instruction-following and reasoning abilities to consistently
    choose the optimal path. On the contrary, GNN can correctly align decomposed steps
    with suitable tasks, hitting the ground-truth result.'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：GNN 效果的案例研究。粉色和红色的节点分别表示错误预测的任务和虚构的任务。由于空间限制，我们仅展示了 BeamSearch 搜索的前四条有效路径作为示例。尽管
    LLM 在搜索过程中可以探索真实路径，但由于缺乏一定的指令跟随和推理能力，它们无法始终选择最优路径。相反，GNN 能够正确地将分解的步骤与适当的任务对齐，达到真实结果。
- en: 'Failure Cases of GNNs: We also present the failure cases where GNN performance
    deteriorates compared to direct inference to provide a comprehensive discussion
    of our method. Our conclusion is that the method is sensitive to the quality of
    decomposed task steps, as an ambiguous step may mislead GNN to wrongly select
    the task, and such errors can cascade due to the sequential selection of tasks
    on the task graph. As the case shown in Figure [10](https://arxiv.org/html/2405.19119v3#A8.F10
    "Figure 10 ‣ Appendix H Case Studies ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?"), step 2 is ambiguously described as “Segment the image and
    identify the tabular data”, which actually incorporates two distinct steps. This
    ambiguity causes GNN to choose the unsuitable Tabular Classification instead of
    the correct Image Segmentation. Since tasks are selected sequentially on the task
    graph, where the next task is a neighbor of the current selection, such an error
    can prevent the exploration of the next appropriate task, as it may not be a neighbor
    of the current, incorrect selection. We also present the BeamSearch explored paths
    and its final solution, where it hits the ground-truth result.'
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: GNN的失败案例：我们还展示了GNN性能退化的失败案例，相较于直接推理，提供了我们方法的全面讨论。我们的结论是，该方法对任务步骤分解的质量非常敏感，因为模糊的步骤可能会误导GNN错误选择任务，而这种错误会因为任务图中任务的顺序选择而级联。例如图[10](https://arxiv.org/html/2405.19119v3#A8.F10
    "图 10 ‣ 附录 H 案例研究 ‣ 图学习能否提升基于LLM的代理的规划能力？")所示，步骤2被模糊描述为“分割图像并识别表格数据”，实际上包含了两个独立的步骤。这种模糊性导致GNN选择了不合适的表格分类任务，而不是正确的图像分割任务。由于任务在任务图中是按顺序选择的，其中下一个任务是当前选择的邻居，因此这样的错误可能会阻止探索下一个合适的任务，因为它可能不是当前错误选择的邻居。我们还展示了BeamSearch探索的路径及其最终解决方案，其中它达到了真实结果。
- en: '![Refer to caption](img/757712958e2cc3233e62a60ba59f532b.png)'
  id: totrans-734
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/757712958e2cc3233e62a60ba59f532b.png)'
- en: 'Figure 10: Failure cases of GNN. Our framework relies heavily on the quality
    of decomposed task steps. Ambiguous steps (step 2 which actually incorporates
    two steps) may mislead GNN to select the wrong task.'
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：GNN的失败案例。我们的框架在很大程度上依赖于任务步骤分解的质量。模糊的步骤（例如步骤2，实际上包含了两个步骤）可能会误导GNN选择错误的任务。
- en: 'Diagnosing GraphSearch with GPT-4-turbo: In our experiments, GraphSearch brings
    marginal or even decreased performance for GPT-4-turbo across most experimental
    datasets, contradicting current research [[33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [32](https://arxiv.org/html/2405.19119v3#bib.bib32)] which suggests that exhaustive
    search strategies can enhance the performance of more powerful LLMs. To provide
    a detailed analysis, we show three types of cases in Figure [11](https://arxiv.org/html/2405.19119v3#A8.F11
    "Figure 11 ‣ Appendix H Case Studies ‣ Can Graph Learning Improve Planning in
    LLM-based Agents?"): Successful cases, Failure cases, as well as Maintaining cases:'
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPT-4-turbo诊断GraphSearch：在我们的实验中，GraphSearch在大多数实验数据集上对GPT-4-turbo的表现带来了微弱甚至下降的效果，这与当前的研究相悖[[33](https://arxiv.org/html/2405.19119v3#bib.bib33),
    [32](https://arxiv.org/html/2405.19119v3#bib.bib32)]，这些研究表明，详尽的搜索策略可以提升更强大的LLM的性能。为了提供详细的分析，我们在图[11](https://arxiv.org/html/2405.19119v3#A8.F11
    "图 11 ‣ 附录 H 案例研究 ‣ 图学习能否提升基于LLM的代理的规划能力？")中展示了三种类型的案例：成功案例、失败案例以及维持案例：
- en: •
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Successful Cases: As shown in the figure, despite inaccuracies in task decomposition
    (GPT-4 predicts an extra step compared to the three-step ground truth), its inherent
    reasoning abilities and the knowledge explored along the task graph can fix these
    mistakes, hitting the ground-truth.'
  id: totrans-738
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成功案例：如图所示，尽管任务分解存在不准确（GPT-4预测的步骤比三步的真实结果多一步），但其固有的推理能力和任务图中探索到的知识可以修正这些错误，最终达到了真实结果。
- en: •
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Failure Cases: In the failure case, although GPT-4 identifies the ground-truth
    solution during searching process, the final decision includes an incorrect task.
    This occurs because the final solution selection demands complex reasoning abilities
    of LLM, as the context contains long textual information from different aspects:
    the full task graph, user request, all searched paths, and related instructions.
    The demanding context and reasoning challenge exceed GPT-4’s capabilities, leading
    to errors.'
  id: totrans-740
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 失败案例：在失败案例中，尽管GPT-4在搜索过程中识别到了真实的解决方案，但最终的决策却包括了一个错误的任务。这是因为最终的解决方案选择需要LLM具备复杂的推理能力，因为上下文包含了来自不同方面的长文本信息：完整的任务图、用户请求、所有搜索路径以及相关指令。这个复杂的上下文和推理挑战超出了GPT-4的能力范围，导致了错误的发生。
- en: •
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Maintaining Cases: These occur when GraphSearch merely replicates the result
    of LLM’s direct inference, indicating no added benefit from exploring the task
    graph. In these instances, despite navigating the graph, the LLM fails to self-correct
    inaccuracies due to inherent reasoning limitations.'
  id: totrans-742
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 维护案例：这些情况发生在GraphSearch仅仅复制LLM直接推理的结果时，表明在探索任务图时并未带来额外的好处。在这些情况下，尽管导航了任务图，LLM仍然由于固有的推理限制未能自我修正不准确之处。
- en: We emphasize that the results of GraphSearch with GPT-4-turbo, tend to “maintaining”
    cases. Under such conditions, even a few failures can degrade overall performance,
    explaining why GraphSearch does not consistently enhance performance for GPT-4-turbo.
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调，使用GPT-4-turbo的GraphSearch结果往往倾向于“维护”案例。在这种情况下，即便有少数失败，也会导致整体性能下降，解释了为什么GraphSearch并未始终提升GPT-4-turbo的性能。
- en: '![Refer to caption](img/82e10e5e66c73b86be5acb9a4bd9e564.png)'
  id: totrans-744
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/82e10e5e66c73b86be5acb9a4bd9e564.png)'
- en: 'Figure 11: Diagnosing GraphSearch for GPT-4. We provide three types of cases:
    Success Cases where GPT-4 can leverage inherent reasoning abilities to select
    the optimal invocation path, which may even fix wrongly decomposed task steps.
    Failure Cases where GPT-4 miss in the extremely long context, containing the whole
    task graph, all searched paths, and instructions, selecting an unsatisfactory
    path. Maintain Cases where the searched result is the same as direct inference
    result, and those wrongly predicted tasks can still not be refined even under
    exhaustive search.'
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：诊断GPT-4的GraphSearch。我们提供了三种类型的案例：成功案例，在这些案例中，GPT-4能够利用固有的推理能力选择最佳调用路径，甚至修正错误分解的任务步骤；失败案例，在这些案例中，GPT-4在极长的上下文中出错，该上下文包含了整个任务图、所有搜索路径和指令，最终选择了一个不令人满意的路径；维护案例，在这些案例中，搜索结果与直接推理的结果相同，即使在经过详尽搜索后，错误预测的任务仍然无法得到修正。
