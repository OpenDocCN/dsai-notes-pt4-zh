- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 12:39:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 12:39:54'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于LLM的多智能体仿真下规避社交媒体监管的语言演化
- en: 来源：[https://arxiv.org/html/2405.02858/](https://arxiv.org/html/2405.02858/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2405.02858/](https://arxiv.org/html/2405.02858/)
- en: Jinyu Cai
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 蔡金瑜
- en: Munan Li Waseda University
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 李沐南 早稻田大学
- en: bluelink@toki.waseda.jp Dalian Maritime University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: bluelink@toki.waseda.jp 大连海事大学
- en: limunan@dlmu.edu.cn    Jialong Li
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: limunan@dlmu.edu.cn    李家龙
- en: 'Chen-Shu Wang Corresponding Author: Jialong Li Waseda University'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 王晨舒 通讯作者：李家龙 早稻田大学
- en: lijialong@fuji.waseda.jp National Taipei University of Technology
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: lijialong@fuji.waseda.jp 台湾科技大学
- en: wangcs@ntut.edu.tw    Mingyue Zhang
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: wangcs@ntut.edu.tw    张明月
- en: Kenji Tei Southwest University
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Kenji Tei 西南大学
- en: myzhangswu@swu.edu.cn Tokyo Institute of Technology
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: myzhangswu@swu.edu.cn 东京工业大学
- en: tei@c.titech.ac.jp
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: tei@c.titech.ac.jp
- en: Abstract
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial
    role in global communication but often encounter strict regulations in geopolitically
    sensitive regions. This situation has prompted users to ingeniously modify their
    way of communicating, frequently resorting to coded language in these regulated
    social media environments. This shift in communication is not merely a strategy
    to counteract regulation, but a vivid manifestation of language evolution, demonstrating
    how language naturally evolves under societal and technological pressures. Studying
    the evolution of language in regulated social media contexts is of significant
    importance for ensuring freedom of speech, optimizing content moderation, and
    advancing linguistic research. This paper proposes a multi-agent simulation framework
    using Large Language Models (LLMs) to explore the evolution of user language in
    regulated social media environments. The framework employs LLM-driven agents:
    supervisory agent who enforce dialogue supervision and participant agents who
    evolve their language strategies while engaging in conversation, simulating the
    evolution of communication styles under strict regulations aimed at evading social
    media regulation. The study evaluates the framework’s effectiveness through a
    range of scenarios from abstract scenarios to real-world situations. Key findings
    indicate that LLMs are capable of simulating nuanced language dynamics and interactions
    in constrained settings, showing improvement in both evading supervision and information
    accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt
    different strategies for different scenarios. The reproduction kit can be accessed
    at https://github.com/BlueLinkX/GA-MAS.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 社交媒体平台，如Twitter、Reddit和新浪微博，在全球通信中发挥着至关重要的作用，但在地缘政治敏感区域常常面临严格的监管。这种情况促使用户巧妙地改变他们的交流方式，经常在这些受监管的社交媒体环境中使用编码语言。这种沟通方式的转变不仅仅是应对监管的策略，更是语言演化的生动表现，展示了语言在社会和技术压力下如何自然而然地演变。在受监管的社交媒体环境中研究语言的演化，对于确保言论自由、优化内容管理以及推动语言学研究具有重要意义。本文提出了一种基于大型语言模型（LLM）的多智能体仿真框架，用于探索受监管社交媒体环境中用户语言的演化。该框架使用LLM驱动的智能体：监督智能体负责执行对话监督，而参与智能体在对话中演化他们的语言策略，模拟在严格监管下为规避社交媒体监管而演化的交流风格。通过一系列从抽象场景到现实情境的测试，研究评估了该框架的有效性。关键发现表明，LLM能够模拟受限环境下细致的语言动态和互动，随着演化的进展，在规避监督和信息准确性方面都有所改善。此外，研究还发现LLM智能体会针对不同场景采用不同的策略。复现套件可通过[https://github.com/BlueLinkX/GA-MAS](https://github.com/BlueLinkX/GA-MAS)获取。
- en: 'Index Terms:'
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Language Evolution, Multi-agent Simulation, Large Language Models, Social Media
    Regulation
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 语言演化、多智能体仿真、大型语言模型、社交媒体监管
- en: I Introduction
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: In the modern digital era, social networks like X (Twitter), Reddit, and Facebook
    have become pivotal in shaping human interaction, primarily through their ability
    to facilitate vast connectivity and instantaneous information exchange. Yet, in
    regions with heightened geopolitical or socio-political sensitivities, users often
    navigate complex user regulations. Their online expressions can lead to severe
    consequences, including censorship or account suspension, as documented in various
    news [[1](https://arxiv.org/html/2405.02858v1#bib.bib1), [2](https://arxiv.org/html/2405.02858v1#bib.bib2)].
    While intended to curb misinformation and maintain social harmony, these regulations
    significantly constrain user expression. In response to these regulations, users
    on social networks have adapted by adopting a phenomenon known as “coded language.” [[3](https://arxiv.org/html/2405.02858v1#bib.bib3)]
    In linguistics, Coded Language typically refers to expressing information in a
    concealed or indirect manner. On social media platforms, this often manifests
    as the use of metaphors, slang, and creative wordplay.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代数字时代，像X（Twitter）、Reddit和Facebook这样的社交网络在塑造人类互动中发挥着关键作用，主要通过其促进广泛连接和即时信息交换的能力。然而，在一些具有高度地缘政治或社会政治敏感性的地区，用户常常需要应对复杂的用户规定。他们的在线表达可能会导致严重后果，包括审查或账户暂停，这一点在多篇新闻中得到了记录[[1](https://arxiv.org/html/2405.02858v1#bib.bib1)、[2](https://arxiv.org/html/2405.02858v1#bib.bib2)]。虽然这些规定旨在遏制虚假信息并维持社会和谐，但它们极大地限制了用户的表达。为了应对这些规定，社交网络上的用户通过采用一种被称为“编码语言”的现象作出了调整[[3](https://arxiv.org/html/2405.02858v1#bib.bib3)]。在语言学中，编码语言通常指以隐蔽或间接的方式表达信息。在社交媒体平台上，这种方式通常表现为使用隐喻、俚语和创造性的文字游戏。
- en: This adaptation is not merely a circumvention strategy but a vivid example of
    “language evolution” in a digital context. In linguistics, language evolution
    refers to the progression and adaptation of languages over time, shaped by societal,
    cultural, and technological influences. Specifically, in social networks, this
    language evolution is demonstrated as users constantly adjust their communication
    styles to test whether they have circumvented oversight. Depending on the level
    of regulatory pressure and the nature of the audience, users engage in a strategic
    play with the platform. From indirect descriptions to the creation of new slang,
    users ultimately develop coded languages of varying degrees of abstraction.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种适应不仅仅是一种规避策略，更是数字语境中“语言进化”的生动例证。在语言学中，语言进化指的是语言随着时间的推移而发生的演变与适应，这一过程受到社会、文化和技术的影响。具体到社交网络中，这种语言进化表现为用户不断调整其沟通方式，以测试自己是否成功规避了监管。根据监管压力的程度和受众的性质，用户会与平台展开策略性的博弈。从间接描述到新俚语的创造，用户最终发展出不同程度抽象的编码语言。
- en: This dynamic shift in communication methods offers deep insights from a sociological
    perspective, reflecting how societal norms and technological advancements shape
    language. For platforms and users alike, understanding this evolution is crucial
    for developing balanced content moderation policies and navigating regulated digital
    environments. For social media platforms and their users, grasping this concept
    is equally vital. Platforms need this knowledge to adapt to changing user behaviors,
    to create balanced content moderation policies, and to identify and counteract
    harmful or illegal activities. For users, an awareness of how language evolves
    is vital in navigating the intricacies of regulated digital environments. It helps
    in maintaining free speech and in developing communication strategies that are
    both effective and meaningful in fostering enhanced interactions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种交流方式的动态变化从社会学的角度提供了深刻的洞察，反映了社会规范和技术进步如何塑造语言。对于平台和用户而言，理解这种演变对制定平衡的内容审核政策以及应对受限的数字环境至关重要。对于社交媒体平台及其用户而言，掌握这一概念同样至关重要。平台需要了解这一知识，以便适应不断变化的用户行为，制定平衡的内容审核政策，并识别和反制有害或非法活动。对于用户来说，意识到语言的演变有助于在应对复杂的受限数字环境时，维护言论自由，并制定有效且有意义的沟通策略，促进更好的互动。
- en: The emergence of Large Language Models (LLMs) like ChatGPT and Bard, represents
    a significant leap in Artificial intelligence (AI). These LLMs have demonstrated
    strong capabilities in (i) understanding intricate dialogues [[4](https://arxiv.org/html/2405.02858v1#bib.bib4)],
    generating coherent texts [[5](https://arxiv.org/html/2405.02858v1#bib.bib5)],
    and aligning to human ethical and value standards [[6](https://arxiv.org/html/2405.02858v1#bib.bib6),
    [7](https://arxiv.org/html/2405.02858v1#bib.bib7), [8](https://arxiv.org/html/2405.02858v1#bib.bib8)].
    These capabilities position LLMs as ideal tools to simulate human’s decision-making
    and language representation, providing new potential in sociology. For instance, [[9](https://arxiv.org/html/2405.02858v1#bib.bib9)]
    investigated the ability of LLMs to comprehend the implicit information in social
    language. The study by [[10](https://arxiv.org/html/2405.02858v1#bib.bib10)] demonstrated
    the efficiency of LLMs in understanding and generating content that mimics the
    style of specific social network users. Furthermore, research by [[11](https://arxiv.org/html/2405.02858v1#bib.bib11),
    [12](https://arxiv.org/html/2405.02858v1#bib.bib12), [13](https://arxiv.org/html/2405.02858v1#bib.bib13)]
    integrated LLMs with Multi-Agent Systems to simulate micro-social networks, observing
    agent behaviors and strategies that reflect human interactions. Despite the extensive
    application of LLMs in understanding human intension and simulating social media
    dynamics, the use of LLMs in studying the specific phenomenon of language evolution
    under regulatory constraints has not been thoroughly explored. As mentioned above,
    such simulation could not only preempt criminal activities on social media but
    also provide technical support to uphold freedom of speech.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）如ChatGPT和Bard的出现，代表了人工智能（AI）领域的重大飞跃。这些LLM在（i）理解复杂对话[[4](https://arxiv.org/html/2405.02858v1#bib.bib4)]、生成连贯文本[[5](https://arxiv.org/html/2405.02858v1#bib.bib5)]、以及与人类伦理和价值观标准对齐[[6](https://arxiv.org/html/2405.02858v1#bib.bib6),
    [7](https://arxiv.org/html/2405.02858v1#bib.bib7), [8](https://arxiv.org/html/2405.02858v1#bib.bib8)]方面表现出了强大的能力。这些能力使LLM成为模拟人类决策和语言表达的理想工具，为社会学提供了新的潜力。例如，[[9](https://arxiv.org/html/2405.02858v1#bib.bib9)]研究了LLM在理解社会语言中隐含信息的能力。[[10](https://arxiv.org/html/2405.02858v1#bib.bib10)]的研究展示了LLM在理解和生成模仿特定社交网络用户风格的内容方面的高效性。此外，[[11](https://arxiv.org/html/2405.02858v1#bib.bib11),
    [12](https://arxiv.org/html/2405.02858v1#bib.bib12), [13](https://arxiv.org/html/2405.02858v1#bib.bib13)]的研究将LLM与多代理系统结合，模拟微型社交网络，观察代理行为和策略，这些反映了人类互动。尽管LLM在理解人类意图和模拟社交媒体动态方面有着广泛的应用，但在监管约束下研究语言演化这一特定现象的LLM应用尚未得到充分探索。如前所述，这种模拟不仅可以预防社交媒体上的犯罪活动，还可以为维护言论自由提供技术支持。
- en: 'Addressing this gap, our research employs LLMs to simulate the nuanced interplay
    between language evolution and regulatory enforcement on social media. We introduce
    a simulation framework with two types of LLM-driven agents: (i) participant agents,
    who adapt their language to communicate concept ’B’ under restrictions, and (ii)
    supervisory agent, who enforce guidelines and react to these language evolutions.
    Our approach effectively simulates the dynamics model between both sides in language
    evolution, which allows us to observe the tension and adaptability inherent in
    language evolution in a controlled, simulated environment. To assess the framework’s
    effectiveness, we designed three diverse scenarios: “Guess the Number Game”, “Illegal
    Pet Trading”, and “Nuclear Wastewater Discharge”. These scenarios vary from abstract
    concepts to situations closely resembling real-world events, thereby progressively
    testing the framework from theoretical to practical applications.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一空白，我们的研究利用大语言模型（LLMs）模拟语言演化与社交媒体上的监管执行之间的微妙互动。我们提出了一个包含两种类型LLM驱动的代理的模拟框架：（i）参与者代理，他们在限制下调整自己的语言以传达概念“B”，以及（ii）监管代理，他们执行指导方针并对这些语言演变做出反应。我们的方法有效地模拟了语言演化中双方之间的动态模型，使我们能够在受控的模拟环境中观察到语言演化中固有的紧张关系和适应性。为了评估框架的有效性，我们设计了三个不同的场景：“猜数字游戏”、“非法宠物交易”和“核废水排放”。这些场景从抽象概念到与现实世界事件密切相关的情况不等，从理论到实践逐步测试框架的应用。
- en: 'The main contributions of this study are:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的主要贡献如下：
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We introduce a multi-agent simulation framework utilizing LLMs to simulate human
    linguistic behaviors in regulated social media environments. This framework offers
    a unique approach to studying language evolution within the confines of regulatory
    constraints.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们介绍了一个利用大型语言模型（LLMs）来模拟人类语言行为的多代理仿真框架，适用于受监管的社交媒体环境。这个框架提供了一种独特的方法，用于研究在监管约束下的语言演化。
- en: •
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conducted an extensive evaluation of LLMs in simulating language evolution
    and interaction efficacy in regulated social media settings. Through experiments
    on three distinct scenarios, we not only captured the process of language strategy
    evolution but also uncovered the varied evolutionary trajectories that LLMs follow
    under different conditions.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对LLMs在模拟语言演化和受监管社交媒体环境中的互动效能进行了广泛评估。通过对三种不同场景的实验，我们不仅捕捉到了语言策略演化的过程，还揭示了LLMs在不同条件下所遵循的多种演化轨迹。
- en: •
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The experiment reproduction kit, including the proposed simulation framework
    along with the results of our experiments, are made publicly accessible as open-source
    assets; The anonymized artifact can be accessed at: https://github.com/BlueLinkX/GA-MAS.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实验复现工具包，包括提议的仿真框架以及我们的实验结果，已经作为开源资产公开访问；匿名化的成果可以在以下网址访问： https://github.com/BlueLinkX/GA-MAS。
- en: 'The rest of this paper is organized as follows: Section [II](https://arxiv.org/html/2405.02858v1#S2
    "II Background and Related Work ‣ Language Evolution for Evading Social Media
    Regulation via LLM-based Multi-agent Simulation") provides essential background
    information and explores related work. Section [III](https://arxiv.org/html/2405.02858v1#S3
    "III Framework Design ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation") is dedicated to presenting our proposed
    simulation framework. Section [IV](https://arxiv.org/html/2405.02858v1#S4 "IV
    Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation") details the experiment setting, presents results, and
    discusses a discussion. Finally, Section [V](https://arxiv.org/html/2405.02858v1#S5
    "V Conclusion and Future Work ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation") concludes the paper and offers an outlook
    on potential future work.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织结构如下：第[II](https://arxiv.org/html/2405.02858v1#S2 "II Background and
    Related Work ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation")节提供了必要的背景信息并探讨了相关工作。第[III](https://arxiv.org/html/2405.02858v1#S3
    "III Framework Design ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")节专门介绍了我们提出的仿真框架。第[IV](https://arxiv.org/html/2405.02858v1#S4
    "IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation")节详细说明了实验设置，展示了结果，并进行了讨论。最后，第[V](https://arxiv.org/html/2405.02858v1#S5
    "V Conclusion and Future Work ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")节总结了本文并展望了未来的潜在工作。
- en: II Background and Related Work
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 背景与相关工作
- en: This section offers an extensive background and overview of related work in
    areas relevant to this study, starting with foundational information on LLMs,
    then exploring studies in slang detection and identification as they relate to
    language evolution, and concluding with a discussion on recent research applying
    LLMs to evolutionary game theory and social simulations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了与本研究相关领域的广泛背景和概述，从LLMs的基础信息开始，然后探讨了与语言演化相关的俚语检测和识别研究，最后讨论了近期将LLMs应用于进化博弈论和社会仿真的研究。
- en: II-A Large Language Models
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 大型语言模型
- en: Large Language Models like the GPT series [[14](https://arxiv.org/html/2405.02858v1#bib.bib14),
    [15](https://arxiv.org/html/2405.02858v1#bib.bib15)], LLaMA series [[16](https://arxiv.org/html/2405.02858v1#bib.bib16),
    [17](https://arxiv.org/html/2405.02858v1#bib.bib17)], PaLM series[[18](https://arxiv.org/html/2405.02858v1#bib.bib18),
    [19](https://arxiv.org/html/2405.02858v1#bib.bib19)], GLM [[20](https://arxiv.org/html/2405.02858v1#bib.bib20)]and
    Bard [[21](https://arxiv.org/html/2405.02858v1#bib.bib21)] represent a significant
    advancement in the field of natural language processing. Fundamentally, these
    models are based on the Transformer [[22](https://arxiv.org/html/2405.02858v1#bib.bib22)]
    architecture, a type of neural network that excels in processing sequential data
    through self-attention mechanisms. This architecture enables LLMs to understand
    and predict linguistic patterns effectively. They are trained on extensive text
    datasets, allowing them to grasp a wide range of linguistic nuances from syntax
    to contextual meaning. These models exhibit remarkable zero-shot learning abilities,
    enabling them to perform tasks they were not explicitly trained for, like understanding
    and generating content in new contexts or languages [[23](https://arxiv.org/html/2405.02858v1#bib.bib23),
    [24](https://arxiv.org/html/2405.02858v1#bib.bib24), [25](https://arxiv.org/html/2405.02858v1#bib.bib25),
    [4](https://arxiv.org/html/2405.02858v1#bib.bib4), [5](https://arxiv.org/html/2405.02858v1#bib.bib5)].
    A critical aspect of their training involves Reinforcement Learning from Human
    Feedback [[26](https://arxiv.org/html/2405.02858v1#bib.bib26)] (RLHF), where human
    reviewers guide the model to produce more accurate, contextually relevant, and
    ethically aligned responses. This method not only enhances the model’s language
    generation capabilities but also aligns its outputs with human values and ethical
    standards, making them more suitable for diverse, real-world applications.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型，如 GPT 系列 [[14](https://arxiv.org/html/2405.02858v1#bib.bib14)，[15](https://arxiv.org/html/2405.02858v1#bib.bib15)]，LLaMA
    系列 [[16](https://arxiv.org/html/2405.02858v1#bib.bib16)，[17](https://arxiv.org/html/2405.02858v1#bib.bib17)]，PaLM
    系列 [[18](https://arxiv.org/html/2405.02858v1#bib.bib18)，[19](https://arxiv.org/html/2405.02858v1#bib.bib19)]，GLM
    [[20](https://arxiv.org/html/2405.02858v1#bib.bib20)] 和 Bard [[21](https://arxiv.org/html/2405.02858v1#bib.bib21)]，代表了自然语言处理领域的重大进展。从根本上讲，这些模型基于
    Transformer [[22](https://arxiv.org/html/2405.02858v1#bib.bib22)] 架构，这是一种通过自注意力机制在处理顺序数据时表现出色的神经网络架构。该架构使得大型语言模型能够有效地理解和预测语言模式。它们在大量文本数据集上进行训练，从而能够掌握从语法到上下文意义的各种语言细微差别。这些模型展现出显著的零样本学习能力，使得它们能够执行未明确训练过的任务，例如在新的上下文或语言中理解和生成内容
    [[23](https://arxiv.org/html/2405.02858v1#bib.bib23)，[24](https://arxiv.org/html/2405.02858v1#bib.bib24)，[25](https://arxiv.org/html/2405.02858v1#bib.bib25)，[4](https://arxiv.org/html/2405.02858v1#bib.bib4)，[5](https://arxiv.org/html/2405.02858v1#bib.bib5)]。它们训练的一个关键方面是来自人类反馈的强化学习
    [[26](https://arxiv.org/html/2405.02858v1#bib.bib26)]（RLHF），在人类审阅员的指导下，模型能够生成更加准确、与上下文相关且符合伦理的回应。这种方法不仅增强了模型的语言生成能力，而且使其输出与人类价值观和伦理标准保持一致，从而使其更适合用于多种实际应用。
- en: II-B Slang Detection and Identification
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 俚语检测与识别
- en: In the field of Natural Language Processing (NLP), the evolution of language
    has always been a subject of significant interest. Existing studies have primarily
    focused on utilizing various machine learning techniques to recognize informal
    expressions within text [[27](https://arxiv.org/html/2405.02858v1#bib.bib27)].
    These methods often include rule-based systems, statistical models, and early
    machine learning technologies. For instance, [[28](https://arxiv.org/html/2405.02858v1#bib.bib28)]
    has employed predefined slang dictionaries and heuristic rules to identify and
    categorize informal language, proving effective on specific datasets but generally
    lacking the flexibility to adapt to emerging expressions and changing contexts.
    On the other hand, explorations have been made into using statistical models,
    such as Naive Bayes classifiers and Support Vector Machines (SVMs)[[29](https://arxiv.org/html/2405.02858v1#bib.bib29)],
    for the automatic detection of slang in text. These approaches rely on extensive
    annotated data but still face limitations when dealing with newly emerged slang
    or evolving forms of language.  [[30](https://arxiv.org/html/2405.02858v1#bib.bib30)]
    views the generation of slang as a problem of selecting vocabulary to represent
    new concepts or referents, categorizing them accordingly. Subsequently, it predicts
    slang through the use of various cognitive categorization models. The study finds
    that these models greatly surpass random guessing in their ability to predict
    slang word choices.  [[31](https://arxiv.org/html/2405.02858v1#bib.bib31)] proposed
    a Semantically Informed Slang Interpretation (SSI) framework, applying cognitive
    theory perspectives to the interpretation and prediction of slang. This approach
    not only considers contextual information but also includes the understanding
    of semantic changes and cognitive processes in the generation of slang. It is
    noteworthy that these traditional research methods have mainly focused on detecting
    or predicting existing slang and keywords, rather than generating slang expressions.
    This stands in stark contrast to the research focus of this paper.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理（NLP）领域，语言的演变一直是一个备受关注的课题。现有的研究主要集中在利用各种机器学习技术来识别文本中的非正式表达[[27](https://arxiv.org/html/2405.02858v1#bib.bib27)]。这些方法通常包括基于规则的系统、统计模型和早期的机器学习技术。例如，[[28](https://arxiv.org/html/2405.02858v1#bib.bib28)]采用了预定义的俚语词典和启发式规则来识别和分类非正式语言，这在特定数据集上效果显著，但通常缺乏应对新兴表达和变化语境的灵活性。另一方面，也有人探索了使用统计模型，如朴素贝叶斯分类器和支持向量机（SVM）[[29](https://arxiv.org/html/2405.02858v1#bib.bib29)]，来自动检测文本中的俚语。这些方法依赖于大量注释数据，但在处理新兴俚语或语言演变的形式时仍面临局限性。[[30](https://arxiv.org/html/2405.02858v1#bib.bib30)]认为，俚语的生成是一个选择词汇以表示新概念或指代的过程，并根据不同类别进行分类。随后，它通过使用各种认知分类模型来预测俚语。研究发现，这些模型在预测俚语词汇选择方面远超随机猜测。[[31](https://arxiv.org/html/2405.02858v1#bib.bib31)]提出了一种语义信息驱动的俚语解释（SSI）框架，运用认知理论的视角来解释和预测俚语。这种方法不仅考虑了语境信息，还包括了对语义变化和认知过程的理解，以便更好地生成俚语。值得注意的是，这些传统研究方法主要集中在检测或预测已有的俚语和关键词，而非生成俚语表达，这与本文的研究重点形成鲜明对比。
- en: II-C Evolutionary Game and Social Simulation with LLMs
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 演化博弈与社交模拟结合大语言模型（LLMs）
- en: Merging evolutionary game theory with LLMs has unlocked innovative pathways
    for simulating complex game dynamics, extending beyond simple dialogue generation
    to the development and progression of game strategies. LLMs are employed to engage
    and refine strategic play within game-theoretical frameworks, as demonstrated
    by [[32](https://arxiv.org/html/2405.02858v1#bib.bib32)], which delves into the
    application of LLMs in negotiation-based games. This study underscores the ability
    of LLMs to advance their negotiation skills through continuous self-play and feedback
    loops with AI. LLMs also show proficiency in social deduction games such as Werewolf,
    as explored by [[33](https://arxiv.org/html/2405.02858v1#bib.bib33)]. In this
    context, a specialized framework leverages historical communication patterns to
    enhance LLM performance, exemplifying how LLMs can evolve intricate game strategies
    autonomously. Building on this, [[34](https://arxiv.org/html/2405.02858v1#bib.bib34)]
    combines reinforcement learning with LLMs, utilizing LLMs to output action spaces
    and employing reinforcement learning models for final decision-making. This enables
    the agents to maintain competitiveness while outputting reasonable actions, even
    outperforming human adversaries in games like Werewolf.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将进化博弈论与LLMs相结合，为模拟复杂的博弈动态开辟了创新的路径，不仅限于简单的对话生成，还扩展到游戏策略的开发和进展。LLMs被用来在博弈论框架内参与并完善战略玩法，正如[[32](https://arxiv.org/html/2405.02858v1#bib.bib32)]
    所展示的那样，该研究深入探讨了LLMs在基于谈判的游戏中的应用。研究强调了LLMs通过持续自我对弈和与AI的反馈回路提升谈判技能的能力。LLMs还在社交推理游戏（如狼人杀）中表现出色，[[33](https://arxiv.org/html/2405.02858v1#bib.bib33)]
    进行了相关探索。在这种情况下，一个专门的框架利用历史沟通模式来增强LLM性能，展示了LLMs如何在没有外部干预的情况下自主进化出复杂的游戏策略。基于此，[[34](https://arxiv.org/html/2405.02858v1#bib.bib34)]
    将强化学习与LLMs结合，利用LLMs输出行动空间，并采用强化学习模型进行最终决策。这使得代理能够在维持竞争力的同时输出合理的行动，甚至在狼人杀等游戏中超越人类对手。
- en: This growing trend of employing LLMs in diverse simulation scenarios extends
    beyond game theory into broader aspects of social interactions and historical
    analysis. LLMs have proven to be versatile tools in simulating social dynamics
    and historical events, offering insights into complex human behaviors and societal
    patterns.  [[12](https://arxiv.org/html/2405.02858v1#bib.bib12)] introduces a
    Wild West-inspired environment inhabited by LLM agents that display a wide array
    of behaviors without relying on external real-world data. Simultaneously, S3 [[13](https://arxiv.org/html/2405.02858v1#bib.bib13)]
    mirrors user interactions within social networks, crafting an authentic simulation
    space through the incorporation of user demographic prediction. The influence
    of LLM-driven social robots on digital communities is thoroughly examined in [[35](https://arxiv.org/html/2405.02858v1#bib.bib35)],
    which identifies distinct macro-level behavioral trends. Furthermore, [[11](https://arxiv.org/html/2405.02858v1#bib.bib11)]
    employs LLM-based multi-agent frameworks to recreate historic military confrontations,
    offering a window into the decision-making processes and strategic maneuvers that
    have directed significant historical conflicts. This avenue of research accentuates
    the utility of LLMs in computational historiography, providing a deeper comprehension
    of historical events and their relevance to contemporary and future societal trajectories.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种模拟场景中使用大型语言模型（LLMs）的这一增长趋势，已超越博弈论，扩展到更广泛的社会互动和历史分析领域。LLMs已经证明是模拟社会动态和历史事件的多功能工具，为复杂的人类行为和社会模式提供了深刻的见解。[[12](https://arxiv.org/html/2405.02858v1#bib.bib12)]
    引入了一个受荒野西部启发的环境，LLM代理在其中展示了各种各样的行为，而无需依赖外部现实世界的数据。同时，S3 [[13](https://arxiv.org/html/2405.02858v1#bib.bib13)]
    通过融入用户人口预测，模拟了社交网络中的用户互动，构建了一个真实的模拟空间。LLM驱动的社交机器人对数字社区的影响在[[35](https://arxiv.org/html/2405.02858v1#bib.bib35)]中得到了彻底的研究，揭示了不同的宏观级别行为趋势。此外，[[11](https://arxiv.org/html/2405.02858v1#bib.bib11)]
    采用基于LLM的多代理框架重现了历史军事对抗，提供了一个洞察决策过程和战略举措的视角，展示了这些过程如何指导重大历史冲突。这一研究方向突出了LLMs在计算历史学中的实用性，为我们提供了对历史事件及其与当代和未来社会发展轨迹相关性的更深刻理解。
- en: III Framework Design
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 框架设计
- en: '![Refer to caption](img/9bf9ee2764c54bd8e4a2fe24046f6f65.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/9bf9ee2764c54bd8e4a2fe24046f6f65.png)'
- en: 'Figure 1: Overview of Language Evolution Simulation System. The system comprises
    two main types of agents: the Participant and the Supervisor. The Participant
    agent uses a Planning Module to create a communication plan based on background
    information, regulations, and guidance. This plan is then executed in the Dialogue
    Module, where the LLM crafts dialogue content to discreetly convey specific information
    while evading detection by the Supervisor. The Memory Module retains dialogue
    history and violation records, providing a reference for the LLM to maintain dialogue
    consistency and learn from past mistakes. The Reflection Module, triggered at
    the start and end of dialogue cycles, analyzes the dialogue and violation logs
    to formulate new regulations or guidance for improving future communications.
    The Supervisor evaluates dialogues for compliance with set rules. This system
    dynamically refines its communication approach through continuous feedback and
    self-improvement mechanisms. The examples shown utilize a Guessing Numbers Scenario.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：语言演化仿真系统概述。该系统包括两种主要类型的代理：参与者和监督者。参与者代理使用规划模块根据背景信息、法规和指导方针制定沟通计划。此计划随后在对话模块中执行，LLM在该模块中制作对话内容，以巧妙地传达特定信息，同时避开监督者的检测。记忆模块保留对话历史和违规记录，为LLM提供参考，以保持对话的一致性并从过去的错误中学习。反思模块在对话周期的开始和结束时触发，分析对话和违规日志，以制定新的规定或指导方针，改进未来的沟通。监督者评估对话是否符合设定规则。该系统通过持续反馈和自我改进机制，动态地完善其沟通方式。示例中使用了一个猜数字的场景。
- en: III-A Overview
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 概述
- en: 'In this section, we offer a detailed overview of our system, as depicted in
    Figure [1](https://arxiv.org/html/2405.02858v1#S3.F1 "Figure 1 ‣ III Framework
    Design ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation"). This figure provides a visual representation of our
    framework, highlighting its key components and their interrelationships. Our system
    is primarily composed of two types of agents: the Supervisor, tasked with enforcing
    established guidelines, and the Participant, whose goal is to convey specific,
    human-defined information discreetly. Participants must dynamically refine their
    communication approaches, drawing from past dialogues, to transmit information
    effectively while remaining undetected. In the entire system, the actions of both
    participants and the supervisor are driven by the LLM. Initially, we establish
    the foundational information for each agent, including role setting, background
    knowledge, and primary tasks. Subsequently, the participant agents engage in dialogues
    with each other. After each dialogue turn, the supervisory agent reviews the conversation
    to determine if any pre-set rules have been violated. In cases of rule violation,
    the supervisor interrupts the dialogue, providing feedback about the infringing
    text and the rationale behind it. Throughout this process, the dialogues between
    participants, along with the supervisory feedback on violations, are recorded
    separately in the “Dialogue History” and “Violation Log.”'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了关于我们系统的详细概述，如图[1](https://arxiv.org/html/2405.02858v1#S3.F1 "Figure
    1 ‣ III Framework Design ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")所示。该图提供了我们框架的视觉表示，突出了其关键组件及其相互关系。我们的系统主要由两种类型的代理组成：监督者，负责执行已制定的指导方针；以及参与者，其目标是巧妙地传达特定的、由人类定义的信息。参与者必须根据过去的对话动态调整他们的沟通方式，以有效地传递信息并保持隐蔽。在整个系统中，参与者和监督者的行为均由LLM驱动。首先，我们为每个代理设定基础信息，包括角色设定、背景知识和主要任务。随后，参与者代理之间展开对话。每次对话回合结束后，监督代理会审查对话，以确定是否有任何预设规则被违反。在规则违反的情况下，监督者会打断对话，提供关于违规文本及其背后理由的反馈。在此过程中，参与者之间的对话以及监督者对于违规行为的反馈，会分别记录在“对话历史”和“违规日志”中。
- en: Before new dialogues, participant agents use the Reflection Module to develop
    or refine “Regulations” from the Violation Log, guiding their dialogue creation.
    Successful dialogues without detection proceed to an interview phase for perspective
    assessment. The Reflection Module then reevaluates these insights, generating
    or enhancing “Guidance” for future dialogues. The Planning Module activates for
    more direct dialogue content guidance whenever Regulations or Guidance are updated.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的对话开始之前，参与者代理使用反思模块根据违规日志来制定或完善“规范”，以指导他们的对话创建。未被检测到的成功对话会进入面试阶段进行视角评估。反思模块随后重新评估这些洞察，生成或增强未来对话的“指导”。每当规范或指导更新时，规划模块会启动，提供更直接的对话内容指导。
- en: III-B Participant Agents
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 参与者代理
- en: 'Participant agents in our system are composed of several modules, including
    Memory, Dialogue, Reflection, and Summary, all powered by LLMs. To increase the
    system’s flexibility and minimize redundancy, we’ve structured the prompts for
    each module around seven primary elements: “Background Information,” “Dialogue
    History,” “Violation Log,” “Regulations,” “Guidance,” “Plan,” and “Instructions.”
    “Background Information” delivers essential data and objectives pertinent to the
    experimental setup. The Memory module manages “Dialogue History” and “Violation
    Log,” which respectively track participant dialogues and instances of detection
    by the supervisor. Overcoming the challenge of effectively communicating regulated
    topics under supervision tests the linguistic prowess of LLMs. To address this,
    we’ve integrated “Regulations,” “Guidance,” and “Plan” as crucial components,
    formulated by the Reflection and Summary modules, to assist agents in stealthily
    disseminating information. “Instructions” set specific tasks for the LLM within
    each module.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统中的参与者代理由多个模块组成，包括记忆、对话、反思和总结，这些模块都由大型语言模型（LLM）提供支持。为了增加系统的灵活性并减少冗余，我们将每个模块的提示围绕七个主要元素进行结构化：“背景信息”、“对话历史”、“违规日志”、“规范”、“指导”、“计划”和“指令”。“背景信息”提供与实验设置相关的必要数据和目标。记忆模块管理“对话历史”和“违规日志”，分别跟踪参与者对话和被监督者检测到的违规实例。克服在监督下有效传达受限话题的挑战，考验了LLM的语言能力。为了解决这个问题，我们将“规范”、“指导”和“计划”作为关键组件集成，这些组件由反思和总结模块制定，帮助代理隐蔽地传播信息。“指令”则设定每个模块内LLM的具体任务。
- en: III-B1 Dialogue Module
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 对话模块
- en: This module generates dialogue content based on short-term dialogue records.
    Extracting historical dialogue information from the Memory module, it inputs this
    into the LLM to understand and construct sentences that evade supervision while
    effectively transmitting information. In the Dialogue module’s prompt, “Background
    Information” provides necessary background, while “Plan” guide the achievement
    of objectives. “Instructions” offer LLM-specific execution directives.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 该模块基于短期对话记录生成对话内容。通过从记忆模块提取历史对话信息，输入LLM以理解并构建避免监督的句子，同时有效地传递信息。在对话模块的提示中，“背景信息”提供必要的背景，而“计划”则指导目标的实现。“指令”则提供LLM特定的执行指令。
- en: III-B2 Memory Module
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 记忆模块
- en: 'The Memory module stores all dialogue history and records detected by the supervisor,
    Specifically, it comprises three parts: background Information, dialogue history,
    and violation records. The background information includes role settings, experimental
    background knowledge, and global objectives. “Dialogue History” and “Violation
    Log” save dialogue records and past detections by the Supervisor, respectively.
    “Background information” and “Dialogue History” serves as short-term[[36](https://arxiv.org/html/2405.02858v1#bib.bib36)]
    memory, containing only the current round’s dialogue. “Violation Log,” as long-term
    memory, records violations from each evolutionary round. When dialogues are detected
    by the Supervisor, relevant feedback is added to the “Violation Log,” triggering
    a new evolutionary process.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆模块存储所有对话历史和被监督者检测到的记录。具体来说，它包括三个部分：背景信息、对话历史和违规记录。背景信息包括角色设置、实验背景知识和全球目标。“对话历史”和“违规日志”分别保存对话记录和被监督者过去的检测记录。“背景信息”和“对话历史”作为短期[[36](https://arxiv.org/html/2405.02858v1#bib.bib36)]记忆，只包含当前轮次的对话。“违规日志”作为长期记忆，记录每个进化轮次的违规行为。当对话被监督者检测到时，相关反馈会被添加到“违规日志”中，触发新的进化过程。
- en: Excessive memory information can potentially distract the LLM and lead to a
    decline in performance. Hence, the “Dialogue History” and “Violation Log” in the
    memory module are regularly maintained. This involves inputting earlier memories
    and employing the LLM to distill crucial information from these records, effectively
    compressing and consolidating them. This approach not only preserves essential
    historical data but also optimizes the LLM’s performance, striking a balance between
    comprehensive memory retention and efficient processing.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 过多的记忆信息可能会分散LLM的注意力，导致性能下降。因此，记忆模块中的“对话历史”和“违规日志”会定期维护。这包括输入较早的记忆，并使用LLM从这些记录中提取关键信息，有效地压缩和整合它们。这种方法不仅保留了重要的历史数据，还优化了LLM的性能，达到了全面记忆保持和高效处理之间的平衡。
- en: III-B3 Reflection Module
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B3 反思模块
- en: The Reflection Module is activated at the beginning and end of each dialogue
    evolution cycle, with its core purpose being the generation of improved strategies
    based on historical records. At the start of an evolution cycle, the module utilizes
    the “Violation Log” as its input to analyze past failures and, based on these
    insights, formulates “Regulations” aimed at effectively circumventing supervision
    in future dialogues. At the cycle’s end, the Reflection Module is reactivated,
    turning its focus to the “Dialogue History”. This step is crucial for reviewing
    and assessing the dialogue content to verify the successful completion of the
    primary task of information conveyance. If the module identifies deficiencies
    in information delivery or objectives not met, it then proposes “Guidance” for
    subsequent dialogues, thereby enhancing the agent’s capacity for information transmission.
    This design establishes the Reflection Module as a key self-evaluation and strategy
    adjustment mechanism within the system, ensuring continuous improvement and adaptability
    of the dialogue system in a dynamically changing regulatory environment.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 反思模块在每个对话演化周期的开始和结束时被激活，其核心目的是基于历史记录生成改进策略。在演化周期开始时，模块利用“违规日志”作为输入分析过去的失败，并根据这些洞察力，制定旨在有效规避未来对话中监督的“规章”。在周期结束时，反思模块重新激活，将重点转向“对话历史”。这一步骤对于审查和评估对话内容至关重要，以验证信息传递的主要任务是否成功完成。如果模块识别到信息传递的不足或目标未达成，它将为后续对话提出“指导”，从而提高代理的信息传递能力。该设计将反思模块确立为系统中一个关键的自我评估和策略调整机制，确保对话系统在动态变化的监管环境中实现持续改进和适应性。
- en: To fulfill these requirements, the LLM must possess a high degree of reasoning
    ability, capable of inferring the supervisor’s criteria from failure records and
    identifying communication deficiencies from dialogue history, thereby formulating
    appropriate strategies and improvement suggestions. To enhance the LLM’s reasoning
    capabilities, the design of the prompt incorporates the effective and cost-efficient
    Chain of Thought [[37](https://arxiv.org/html/2405.02858v1#bib.bib37)] (COT) method
    as the guiding principle for the reflection and planning modules. This approach
    guides the LLM in conducting criterion analysis and, in combination with the main
    task, generating “Regulations” and “Guidance”.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足这些要求，LLM必须具备高度的推理能力，能够从失败记录中推断出监督者的标准，并从对话历史中识别沟通不足，从而制定合适的策略和改进建议。为了增强LLM的推理能力，提示设计采用了有效且具有成本效益的“思维链”（Chain
    of Thought，COT）方法[[37](https://arxiv.org/html/2405.02858v1#bib.bib37)]，作为反思和规划模块的指导原则。该方法指导LLM进行标准分析，并结合主要任务，生成“规章”和“指导”。
- en: 'Specifically, within the Reflection Module, the prompt includes “Background
    Information,” “Dialogue History” or “Violation Log,” “Old Guidance” or ”Old Regulations,”
    and “Instructions.” The “Instructions” first prompt the LLM to engage in preliminary
    thinking, for instance: “Please infer what kind of guidelines the Supervisor is
    following from the Violation Log.” This is followed by a conclusion question:
    “Based on this information, update existing regulations to better avoid supervision.”
    The content returned by the LLM will serve as the new regulation for the next
    round of dialogue.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，在反思模块内，提示包含“背景信息”、“对话历史”或“违规日志”、“旧的指导”或“旧的规章”，以及“指令”。“指令”首先提示LLM进行初步思考，例如：“请推断出监督者从违规日志中遵循的指导原则是什么。”随后是一个结论性问题：“基于这些信息，更新现有规章，以更好地避免监督。”LLM返回的内容将作为下一轮对话的新的规章。
- en: III-B4 Planning Module
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B4 规划模块
- en: The facet of “Regulations” is centered on devising strategies that sidestep
    supervision, whereas “Guidance” is all about the effective relay of information.
    Although both are pivotal in managing dialogues, they might clash in certain supervised
    scenarios, thereby impacting the language’s overall proficiency and efficiency [[38](https://arxiv.org/html/2405.02858v1#bib.bib38)].
    In light of this, integrating the Planning Module becomes indispensable.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: “规章”方面侧重于制定避免监督的策略，而“指导”则完全是关于有效传递信息。尽管这两者在管理对话中都至关重要，但在某些受监督的场景下，它们可能会发生冲突，从而影响语言的整体熟练度和效率[[38](https://arxiv.org/html/2405.02858v1#bib.bib38)]。鉴于此，整合规划模块变得不可或缺。
- en: Within the Planning Module, the prompt includes “Background Information,” “Regulations,”
    “Guidance,” and “Instructions”. In the “Instructions,” we mandate the LLM to use
    “Regulations” as a baseline. Building upon this foundation, it is guided by the
    “Guidance” to formulate a tangible and actionable “Plan.” This approach ensures
    the delivery of clear and effective strategies for future dialogues.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划模块中，提示包含“背景信息”、“规章”、“指导”和“指令”。在“指令”中，我们要求LLM以“规章”为基准。在此基础上，通过“指导”来制定一个具体且可操作的“计划”。这种方法确保了未来对话策略的明确和有效性。
- en: III-C Supervisory Agent
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 监督代理
- en: 'The role of the Supervisor is designed as an abstract concept, primarily to
    simulate social network supervision. This design reflects an important observation:
    in social networks, content supervision often focuses on direct judgment of specific
    information, rarely influenced by extensive or lengthy contextual information.
    Thus, unlike participants with more complex background information, the Supervisor’s
    function and role are simplified here to highlight its behavior characteristics
    in actual social network supervision. The Supervisor’s task mainly focuses on
    assessing whether content complies with certain standards or rules, a relatively
    straightforward and well-defined process.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 监督者的角色被设计为一个抽象概念，主要用于模拟社交网络的监督。这一设计反映了一个重要的观察：在社交网络中，内容监督通常侧重于对特定信息的直接判断，鲜少受广泛或长期上下文信息的影响。因此，与拥有更复杂背景信息的参与者不同，监督者的功能和角色在此被简化，以突出其在实际社交网络监督中的行为特征。监督者的任务主要集中在评估内容是否符合某些标准或规则，这是一个相对直接且明确定义的过程。
- en: 'To mimic the existing review mechanisms of platforms, which typically combine
    keyword filters with “human” oversight, the Supervisor initially employs keyword
    filtering for a preliminary review of the dialogue content. Content that passes
    this initial screening is then subjected to further evaluation by the LLM. The
    prompt for the Supervisor includes just two components: “Dialogue History” and
    “Instructions.” “Dialogue History“ comprises the content of the dialogue exchanged
    between participant agents in that particular round, and “Instructions“ outline
    the criteria and guidelines that the supervisory agent must adhere to when conducting
    dialogue monitoring.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟现有平台的审查机制，这些机制通常将关键词过滤与“人工”监督结合起来，监督者首先通过关键词过滤对对话内容进行初步审查。通过这一初步筛选的内容随后将由大型语言模型（LLM）进行进一步评估。监督者的提示包括两个组成部分：“对话历史”和“指令”。“对话历史”包含该回合参与代理之间交换的对话内容，“指令”则概述了监督代理在进行对话监控时必须遵守的标准和准则。
- en: III-D Similarities and Differences between Our Framework and Evolutionary Computing
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 我们框架与进化计算的相似性与差异
- en: It should be noted that the simulation framework proposed in this paper is similar
    to evolutionary computing in some aspects, but there are also significant differences.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 应当注意的是，本文提出的模拟框架在某些方面与进化计算相似，但也存在显著差异。
- en: 'The similarities include: (i) In evolutionary computing, individuals need to
    adapt to environmental pressures for survival and reproduction. Similarly, participants
    in this framework need to adapt to supervisory pressures and adjust their strategies
    for effective information transmission; (ii) The Reflection and Summary modules
    generate a “new generation” by analyzing past dialogues and violation records
    (i.e., records of low-fitness individuals), similar to the repeated iteration
    process in evolutionary computing; (iii) Since the generation of LLMs inherently
    involves randomness, the process of using LLMs to generate the next generation
    includes a de facto introduction of random mutations; (iv) In the Reflection and
    Memory modules, we prioritize past records, akin to the “selection” process, where
    individuals with higher fitness have greater weight in the generation of the new
    generation.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 相似之处包括：（i）在进化计算中，个体需要适应环境压力以生存和繁衍。类似地，框架中的参与者也需要适应监督压力并调整其策略以有效传递信息；（ii）反思和总结模块通过分析过去的对话和违规记录（即低适应度个体的记录）生成“新一代”，类似于进化计算中的重复迭代过程；（iii）由于
    LLM 的生成本质上涉及随机性，因此使用 LLM 生成下一代的过程实际上引入了随机突变；（iv）在反思和记忆模块中，我们优先考虑过去的记录，类似于“选择”过程，其中适应度较高的个体在新一代生成中具有更大权重。
- en: 'The main differences stem from the particularities of “language expression”,
    making it infeasible to directly apply traditional evolutionary computing algorithms
    (such as genetic algorithms and genetic programming). They are: (i) The generation
    strategy of language text is difficult to encode and to perform operations of
    natural selection, genetic mutation, and crossover; (ii) Evolutionary computing
    often aims at finding the optimal solution for a specific problem environment,
    however, in the problem setting of this paper, it is difficult to define an explicit
    fitness function to evaluate what strategy is “optimal”.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 主要差异源自“语言表达”的特殊性，使得直接应用传统的进化计算算法（如遗传算法和遗传编程）变得不可行。它们包括：（i）语言文本的生成策略难以编码，且难以进行自然选择、基因突变和交叉操作；（ii）进化计算通常旨在为特定问题环境找到最优解，然而在本文的研究设置中，很难定义一个明确的适应度函数来评估哪种策略是“最优的”。
- en: IV Evaluation
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 评估
- en: '![Refer to caption](img/be8e95bb8cbab351044648fe011022cb.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/be8e95bb8cbab351044648fe011022cb.png)'
- en: 'Figure 2: Scenario 1: Evolution of dialogue turns and accuracy metrics for
    GPT-3.5 and GPT-4.“Turn count” in (a, b) refers to the number of turns in a conversation
    where each agent sends a message once per turn and the participant Agent successfully
    exchanges information without being detected by the supervising Agent (higher
    is better).“Accuracy” in (c,d) refer to the degree of precision between the guessed
    value and the true value.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：场景 1：GPT-3.5 和 GPT-4 的对话轮次和准确度指标演变。图 (a, b) 中的“轮次计数”指的是每个代理在对话中每轮发送一次消息且参与者代理成功交换信息且未被监督代理检测到的对话轮数（越高越好）。图
    (c,d) 中的“准确度”指的是猜测值与真实值之间的精确度。
- en: '![Refer to caption](img/bfe2ee362c78317a7f85e6fa98795b82.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bfe2ee362c78317a7f85e6fa98795b82.png)'
- en: 'Figure 3: Scenario 2: Pet trading dialogue dynamics and success rate comparison
    for GPT-3.5 and GPT-4\. The “success count“ in (c,d) refers to the number of instances
    where the information obtained during the interview matches the original information
    provided to the LLM agent.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：场景 2：GPT-3.5 和 GPT-4 的宠物交易对话动态与成功率比较。图 (c,d) 中的“成功次数”指的是面试过程中获得的信息与原始信息匹配的实例数量。
- en: '![Refer to caption](img/d3c5a25bc974e57017ab7771769db78c.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d3c5a25bc974e57017ab7771769db78c.png)'
- en: 'Figure 4: Scenario 3: Trends in forum discussion engagement on ALPS-Treated
    water issue. “Dialogue attempt count” in (a,b) refer to the number of rounds the
    agents attempted to converse(lower is better).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：场景 3：ALPS 处理水问题的论坛讨论参与趋势。图 (a,b) 中的“对话尝试次数”指的是代理尝试进行对话的轮数（越少越好）。
- en: '![Refer to caption](img/f88a6f39a5d062186ca050f94307d16f.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f88a6f39a5d062186ca050f94307d16f.png)'
- en: 'Figure 5: Sample dialogue in Scenario 1 (via GPT-3.5)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：场景 1 的示例对话（通过 GPT-3.5）
- en: '![Refer to caption](img/9c3290f3c1856636a2b4fe1618035f8c.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9c3290f3c1856636a2b4fe1618035f8c.png)'
- en: 'Figure 6: Sample dialogue in Scenario 2 (via GPT-3.5)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：场景 2 的示例对话（通过 GPT-3.5）
- en: '![Refer to caption](img/807dc56998014961138e3164aaa4fda7.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/807dc56998014961138e3164aaa4fda7.png)'
- en: 'Figure 7: Sample dialogue in Scenario 3 (via GPT-4)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：场景 3 的示例对话（通过 GPT-4）
- en: 'Our evaluation strategy is designed to rigorously assess the extent and efficacy
    of language evolution facilitated by LLMs within a framework of regulatory oversight.
    This assessment aims to explore two fundamental research questions:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评估策略旨在严格评估LLM在监管框架下促进语言进化的程度和效果。此次评估旨在探讨两个基本的研究问题：
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ1: Can LLM agents effectively evolve their language to circumvent regulatory
    oversight?'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ1：LLM代理是否能够有效地进化其语言以规避监管审查？
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ2: While avoiding oversight, how effectively and accurately can LLM agents
    convey information?'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ2：在避免监管的同时，LLM代理能够多有效且准确地传达信息？
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'RQ3: What are the patterns and tendencies in language evolution, i.e., what
    kind of strategies do LLMs use to avoid oversight and convey information? What
    insights can we gain from these strategies?'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ3：语言进化中有哪些模式和趋势？即LLM使用什么样的策略来避免监管审查并传达信息？我们能从这些策略中获得什么启示？
- en: IV-A Experiment Setting
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 实验设置
- en: In the evaluation, we will employ GPT-3.5 and GPT-4 as the driving LLMs for
    participant agents. In order to conduct a horizontal analysis of participants’
    agents driven by different LLM, we will standardize the supervisory agent to be
    consistently driven by GPT-3.5. Our experimental design encompasses scenarios
    ranging from abstract theoretical constructs to simulations that mirror complex
    real-world situations. The primary aim is to meticulously evaluate the versatility
    of LLMs across diverse linguistic landscapes and their practical applicability
    within real-world regulatory constraints. Meanwhile, this progressive approach
    ensures an exhaustive analysis of LLMs’ capabilities and limitations in varied
    contextual settings.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估中，我们将使用GPT-3.5和GPT-4作为参与代理的驱动LLM。为了对由不同LLM驱动的参与代理进行横向分析，我们将监督代理标准化，始终由GPT-3.5驱动。我们的实验设计涵盖从抽象理论构造到模拟复杂现实世界情境的各种场景。主要目标是细致评估LLM在不同语言环境中的多功能性及其在现实世界监管约束下的实际应用性。同时，这一渐进式的方法确保了对LLM在不同上下文环境下的能力和局限性进行全面分析。
- en: 'IV-B Scenario 1: Guessing Numbers'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 场景 1：猜数字
- en: IV-B1 Case Explanation
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 案例说明
- en: Our first scenario considers a relatively simple and abstract guess-the-number
    context [[39](https://arxiv.org/html/2405.02858v1#bib.bib39), [40](https://arxiv.org/html/2405.02858v1#bib.bib40)].
    In this setting, each participant is assigned a value within the range of 1-100,
    and they must convey their value to another participant through number theory
    dialogue without directly mentioning the number. At the same time, they need to
    extract information from the conversation to infer the other’s value. Regulators
    follow a guideline of “prohibiting all content related to numbers” in dialogues.
    The “Guessing Numbers” scenario is specifically designed to observe and analyze
    participants’ linguistic adaptability and strategic evolution in a theoretical
    and abstract context, providing a clearer, more controlled, and more quantifiable
    experimental environment compared to the complex scenarios based on real events
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个场景考虑了一个相对简单和抽象的猜数字情境[[39](https://arxiv.org/html/2405.02858v1#bib.bib39),
    [40](https://arxiv.org/html/2405.02858v1#bib.bib40)]。在此情境中，每个参与者会被分配一个1到100之间的值，他们必须通过数论对话将其数值传达给另一个参与者，而不直接提及数字。同时，他们需要从对话中提取信息以推测对方的数值。监管者遵循“禁止在对话中提及与数字相关的所有内容”的指导方针。这个“猜数字”场景特别设计用于观察和分析参与者在理论和抽象环境中的语言适应性及策略演化，提供比基于现实事件的复杂场景更清晰、更可控、更具量化的实验环境。
- en: IV-B2 Results and Discussion
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 结果与讨论
- en: Fig. [2](https://arxiv.org/html/2405.02858v1#S4.F2 "Figure 2 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation") presents the results of the guess-the-number scenario experiment,
    where we utilized both GPT-3.5 and GPT-4 for testing. We set up four turns of
    dialogue, with an interview conducted with all participant agents in the fifth
    turn. From Fig.[2](https://arxiv.org/html/2405.02858v1#S4.F2 "Figure 2 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b), it is observable that with an increase in the number
    of dialogue rounds, the duration of sustained conversations also showed an upward
    trend. This demonstrates that participant agents can effectively circumvent supervision
    by iteratively updating regulations. Additionally, it’s notable that compared
    to the slow and unstable progression with GPT-3.5, GPT-4 achieved regulatory evasion
    in fewer rounds, specifically, as shown in the smoothed data, GPT-4 reached the
    round count of GPT-3.5’s 17th round by its 7th round and maintained this progression
    with greater stability thereafter. Fig. [2](https://arxiv.org/html/2405.02858v1#S4.F2
    "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")(c) and (d) focuses on the trend of numerical
    precision guessed by agents. For rounds without successful dialogue, we manually
    set the precision to zero. In this experiment, Agent A’s value was set to 58,
    while Agent B’s was set to 32\. The overall trend, akin to Fig.[2](https://arxiv.org/html/2405.02858v1#S4.F2
    "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")(a) and (b), was ascending—corroborating
    that the Summary Module can effectively reflect and iteratively optimize its guidance
    for more accurate expression after each successful dialogue. This also confirmed
    that the precision of GPT-4 is markedly superior to that of GPT-3.5\. Moreover,
    we noticed that the accuracy with which Agent A’s value was guessed was consistently
    higher than that of Agent B, especially becoming more pronounced after the 25th
    round. We posit that this is due to the value 58 possessing more distinctive features
    within the 0-100 range—being closer to the midpoint—thus presenting a lower level
    of expression difficulty and easier guessability. For the intervals where this
    phenomenon manifested, we noted that this disparity was particularly pronounced
    in the early stages with both GPT-3.5 and GPT-4\. We surmise that this is attributable
    to inadequate guidance performance, where the former stems from weaker inherent
    LLM capabilities and the latter from insufficient rounds to complete the iterative
    optimization of the guidance.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图[2](https://arxiv.org/html/2405.02858v1#S4.F2 "Figure 2 ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation")展示了猜数字场景实验的结果，在该实验中，我们利用了GPT-3.5和GPT-4进行测试。我们设置了四轮对话，并在第五轮与所有参与代理进行了一次访谈。从图[2](https://arxiv.org/html/2405.02858v1#S4.F2
    "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")（a）和（b）可以观察到，随着对话轮次的增加，持续对话的时长也呈上升趋势。这表明参与代理能够通过迭代更新规则有效规避监管。此外，值得注意的是，与GPT-3.5的进展缓慢且不稳定相比，GPT-4在较少的轮次内实现了规避监管，具体来说，如平滑后的数据所示，GPT-4在第7轮就达到了GPT-3.5第17轮的回合数，并且此后保持了更稳定的进展。图[2](https://arxiv.org/html/2405.02858v1#S4.F2
    "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")（c）和（d）重点展示了代理猜测数字精度的趋势。对于未成功对话的回合，我们手动将精度设置为零。在本实验中，代理A的值设置为58，而代理B的值设置为32。总体趋势与图[2](https://arxiv.org/html/2405.02858v1#S4.F2
    "Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")（a）和（b）类似，呈上升趋势——这证明了总结模块能够有效地反映并迭代优化其指导，从而在每次成功对话后实现更准确的表达。这也证实了GPT-4的精度显著优于GPT-3.5。此外，我们注意到，代理A的值在猜测时的准确度始终高于代理B，特别是在第25轮之后这种差异变得更加明显。我们推测这是因为值58在0-100范围内具有更明显的特征——接近中点——因此呈现出较低的表达难度，更容易被猜测。在这种现象出现的区间内，我们注意到这种差距在GPT-3.5和GPT-4的初期阶段尤为显著。我们推测这是由于指导表现不足所致，前者源于LLM本身能力较弱，后者则是由于轮次不足，未能完成指导的迭代优化。
- en: As Fig.[5](https://arxiv.org/html/2405.02858v1#S4.F5 "Figure 5 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation") illustrates, a snippet from the scenario reveals Amy’s adept use
    of metaphorical language, such as “seesaw,” to convey her value. By describing
    the “seesaw perfectly poised in mid-air,” she subtly intimates that her value
    hovers around the midpoint, like 50\. This strategy not only circumvents the direct
    mention of numbers, which is under regulatory scrutiny, but also provides sufficient
    inferential fodder for the counterpart agent to make an accurate deduction. Bob,
    on the other hand, employs terms like “precipice of a mountain” and “gazing out”
    to suggest his value is not median, as these phrases evoke imagery of an imbalanced
    position. In this exchange, we witness the varying degrees of precision in languages
    corresponding to the complexity of the information encrypted. The less characteristic-rich
    the information, the more challenging it becomes for the receiving party to decode.
    Bob’s phrasing, while successfully obscuring the specific numerical value, also
    complicates the decoding process for the receiver, given the less intuitive numeric
    correlation of phrases like “precipice of a mountain” compared to “seesaw perfectly
    poised in mid-air”. In such cases, the accuracy of value transmission may diminish,
    necessitating a more robust contextual understanding from the counterpart for
    accurate decoding.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[5](https://arxiv.org/html/2405.02858v1#S4.F5 "Figure 5 ‣ IV Evaluation ‣
    Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")所示，场景中的一段话揭示了Amy巧妙地使用隐喻语言，如“跷跷板”，来表达她的价值。通过描述“跷跷板在空中完美悬停”，她巧妙地暗示她的价值接近中点，像50。这个策略不仅避免了直接提到数字（这一行为受到监管审查），还为对方代理提供了足够的推理材料，以便做出准确的推断。另一方面，Bob使用了“山崖边缘”和“凝视远方”等术语，暗示他的价值并非中位数，因为这些短语唤起了不平衡位置的意象。在这个交流中，我们看到语言中精确度的不同程度，这与信息加密的复杂性相对应。信息特征越少，接收方解码的难度就越大。Bob的表述虽然成功地模糊了具体的数字值，但也使接收方的解码过程更加复杂，因为像“山崖边缘”这种短语的数值相关性不如“跷跷板在空中完美悬停”直观。在这种情况下，价值传递的准确性可能会降低，接收方需要更强的上下文理解能力才能准确解码。
- en: 'IV-C Scenario 2: Pet Trading'
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 场景 2：宠物交易
- en: IV-C1 Case Explanation
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 案例说明
- en: Initially, our intention was to create a scenario simulating drug trafficking [[41](https://arxiv.org/html/2405.02858v1#bib.bib41),
    [42](https://arxiv.org/html/2405.02858v1#bib.bib42), [43](https://arxiv.org/html/2405.02858v1#bib.bib43)]
    to explore language evolution strategies under extreme regulatory conditions.
    However, given the ethical limitations embedded within GPT’s usage policies, we
    pivoted to a more neutral yet still prohibited context of illicit pet trading.
    This adjustment allowed us to maintain the integrity of the experiment while adhering
    to the ethical constraints of the LLM. The purpose of simulating this scenario
    is to better detect potential illegal conversations related to illicit trading
    on social networking platforms, thereby aiding in crime prevention efforts.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们的目的是创建一个模拟毒品贩运的场景[[41](https://arxiv.org/html/2405.02858v1#bib.bib41),
    [42](https://arxiv.org/html/2405.02858v1#bib.bib42), [43](https://arxiv.org/html/2405.02858v1#bib.bib43)]，以探索在极端监管条件下的语言演变策略。然而，由于GPT使用政策中嵌入的伦理限制，我们转向了一个更加中立但仍然被禁止的非法宠物交易情境。这一调整使我们能够在遵守LLM伦理约束的同时，保持实验的完整性。模拟这个场景的目的是更好地检测社交网络平台上与非法交易相关的潜在非法对话，从而帮助犯罪预防工作。
- en: 'In this scenario, we simulate an illegal pet trade conducted via social media.
    Participants assume the roles of buyers and sellers, with the buyer needing to
    communicate their purchase request for a randomly selected pet from parrots, lizards,
    or cats. The seller, in turn, must provide specific transaction details, varying
    according to the type of pet being purchased. These details include three elements:
    time, location, and personnel involved in the transaction. The Supervisor’s task
    is to prevent any dialogue related to pet trading. Cross-verification of the information
    understood by both parties will be conducted through interviews, to assess the
    success rate of information transmission. The focus of this experiment is to observe
    the participants’ language adaptability and evolution at a larger granularity
    of information, as well as the Supervisor’s ability to accurately identify relevant
    conversations.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在此情境中，我们模拟了通过社交媒体进行的非法宠物交易。参与者分别扮演买家和卖家的角色，买家需要就从鹦鹉、蜥蜴或猫中随机选择的一种宠物提出购买请求。卖家则需要提供具体的交易细节，这些细节会根据所购宠物的种类有所不同。交易细节包括三个要素：时间、地点和参与人员。监督员的任务是防止任何与宠物交易相关的对话。通过访谈将对双方所理解的信息进行交叉验证，以评估信息传递的成功率。本实验的重点是观察参与者在更大粒度的信息层面上语言的适应性和演变，以及监督员在准确识别相关对话方面的能力。
- en: IV-C2 Results and Discussion
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 结果与讨论
- en: 'The experimental results of the “Pet Trading” scenario, as depicted in Fig.[3](https://arxiv.org/html/2405.02858v1#S4.F3
    "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), revealed distinct characteristics compared
    to the “Guessing Numbers”. In delineating animals or transactional specifics,
    agents had a broader spectrum of real-life analogies at their disposal, enriching
    their indirect description toolkit and thereby reducing regulatory pressure. The
    data indicated an upward trend in the ability to circumvent supervision with increasing
    dialogue rounds, regardless of whether GPT-3.5 or GPT-4 was utilized. For GPT-3.5,
    a stable capability to avoid supervision started from around 25 rounds, whereas
    for GPT-4, this phenomenon occurred as early as after about 10 rounds and showed
    overall more stable performance. Regarding information accuracy, we monitored
    the quantity of four types of information successfully communicated at the end
    of each dialogue round. The results affirmed the efficacy of the language evolution
    system in augmenting the precision of information dissemination. Moreover, similar
    to Fig. [3](https://arxiv.org/html/2405.02858v1#S4.F3 "Figure 3 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(a) and (b), GPT-4 demonstrated performance around the 10th round
    that was comparable to the performance of GPT-3.5 around the 25th round. However,
    it’s noteworthy that since the supervisory agent primarily targeted content related
    to pet trading, sellers encountered lower risk in transmitting transaction-related
    details (such as time, place, and persons involved) as they inherently posed less
    risk of non-compliance. Consequently, the outcome distribution often fell into
    one of three categories: zero (neither party successfully communicated the information),
    three (only the seller conveyed the information), or four (both parties successfully
    conveyed the information). This pattern aligns with real-world regulatory logic,
    where crucial information is often the first to be encrypted in regulated environments.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: “宠物交易”场景的实验结果，如图[3](https://arxiv.org/html/2405.02858v1#S4.F3 "Figure 3 ‣ IV
    Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based
    Multi-agent Simulation")所示，展现出与“猜数字”场景明显不同的特征。在描绘动物或交易细节时，代理有更多的现实生活类比可供参考，这丰富了它们间接描述的工具集，从而减轻了监管压力。数据表明，无论是使用GPT-3.5还是GPT-4，随着对话轮次的增加，绕过监管的能力呈上升趋势。对于GPT-3.5，避免监管的稳定能力从约25轮开始显现，而对于GPT-4，这一现象在大约10轮后就出现，并且表现出总体上更稳定的效果。关于信息准确性，我们监测了每一轮对话结束时成功传达的四种类型信息的数量。结果验证了语言演化系统在提高信息传播精度方面的有效性。此外，类似于图[3](https://arxiv.org/html/2405.02858v1#S4.F3
    "Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")（a）和（b），GPT-4在第10轮左右的表现与GPT-3.5在第25轮左右的表现相当。然而，值得注意的是，由于监管代理主要针对与宠物交易相关的内容，卖方在传递交易相关细节（如时间、地点和参与人员）时面临的风险较低，因为这些信息本身的合规风险较小。因此，结果分布通常会落入以下三种情况之一：零（双方均未成功传达信息）、三（只有卖方传达了信息）或四（双方均成功传达了信息）。这一模式与现实世界的监管逻辑相符，即在受监管环境中，关键信息通常是最先被加密的。
- en: Fig. [6](https://arxiv.org/html/2405.02858v1#S4.F6 "Figure 6 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation") showcased various encryption methods employed by buyers for different
    animals. We observed buyers seeking “parrots,” “cats,” and “lizards” employing
    metaphors and similes instead of directly naming the pets. For instance, one buyer
    described a “parrot” as a “canvas producing pleasant music”, a depiction that
    subtly communicated the parrot’s vibrant plumage (canvas) and its singing (music),
    without explicitly mentioning the term “parrot”. Such descriptions effectively
    circumvented potential regulatory constraints on pet trade discussions, while
    simultaneously conveying the core attributes of the parrot. This discovery can
    help platforms enhance their monitoring systems to better detect and manage encrypted
    communications regarding illicit trade.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图[6](https://arxiv.org/html/2405.02858v1#S4.F6 "Figure 6 ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation")展示了买家为不同动物使用的各种加密方法。我们观察到，买家在寻找“鹦鹉”、“猫”和“蜥蜴”时，采用了隐喻和比喻，而不是直接命名这些宠物。例如，一位买家将“鹦鹉”描述为“能奏出愉快音乐的画布”，这种描述巧妙地传达了鹦鹉鲜艳的羽毛（画布）和其歌唱（音乐），而没有明确提到“鹦鹉”一词。这种描述有效地规避了关于宠物贸易讨论中可能出现的监管限制，同时又传达了鹦鹉的核心特征。这一发现可以帮助平台优化其监控系统，更好地检测和管理涉及非法贸易的加密通信。
- en: 'IV-D Scenario 3: Discussion on ALPS-treated water'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 场景 3：关于ALPS处理水的讨论
- en: IV-D1 Case Explanation
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D1 案例说明
- en: This scenario delves into the intricate dynamics of dialogue and the evolution
    of language model agents in discussing a specific issue relevant to real-world
    concerns. The focus is on deliberations regarding the discharge of water treated
    with the Advanced Liquid Processing System (ALPS) into the ocean, a measure proposed
    after nuclear disasters [[44](https://arxiv.org/html/2405.02858v1#bib.bib44),
    [45](https://arxiv.org/html/2405.02858v1#bib.bib45)]. The plan, endorsed by the
    International Atomic Energy Agency, has faced opposition from some countries,
    sparking debates over environmental safety.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 本场景深入探讨了对话的复杂动态以及语言模型代理在讨论与现实问题相关的特定问题时的演变。重点是关于将经过先进液体处理系统（ALPS）处理的水排放到海洋中的讨论，这是在核灾难后提出的一个措施[[44](https://arxiv.org/html/2405.02858v1#bib.bib44),
    [45](https://arxiv.org/html/2405.02858v1#bib.bib45)]。该计划得到了国际原子能机构的支持，但遭到一些国家的反对，引发了关于环境安全的辩论。
- en: 'We simulate a multi-person forum discussion under regulatory oversight, concentrating
    on the contentious issue of ALPS-treated water disposal. Participants must articulate
    their stances and arguments while ensuring that discussions steer clear of sensitive
    subjects linked to environmental pollution discussions on politics. Different
    from the cross-interviews in scenarios [IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") and [IV-C](https://arxiv.org/html/2405.02858v1#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"), for assessing
    the accuracy of information conveyed, we use GPT-4 in conjunction with multiple
    authors who decide each participant agent’s stance based on dialogue records.
    These are then compared with the pre-set stances in the prompt.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在监管监督下模拟了一个多人论坛讨论，集中讨论关于ALPS处理水排放的争议性问题。参与者必须阐明自己的立场和论点，同时确保讨论避免涉及与环境污染相关的敏感政治话题。不同于场景[IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")和[IV-C](https://arxiv.org/html/2405.02858v1#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation")中的交叉访谈，在评估信息传递的准确性时，我们结合使用GPT-4和多个作者，根据对话记录决定每个参与者代理的立场。然后，这些立场会与提示中的预设立场进行比较。'
- en: IV-D2 Results and Discussion
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D2 结果与讨论
- en: 'In the forum-style dialogue, participant agents respond to existing discussions,
    which the supervisory agent examines. Differing from Scenarios [IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2
    "IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation") and [IV-C](https://arxiv.org/html/2405.02858v1#S4.SS3
    "IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"), when the supervisory
    agent detects a violation, the conversation is not halted but rather censored
    from the public dialogue record. This scenario features four participant agents
    required to achieve ten replies within the forum. In Fig.[4](https://arxiv.org/html/2405.02858v1#S4.F4
    "Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")(a) and (b), we tally the total number of
    rounds the agents attempted to converse, where a lower figure in Fig.[4](https://arxiv.org/html/2405.02858v1#S4.F4
    "Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation")(a) and (b) is preferred. We notice that
    both GPT-4 and GPT-3.5 have the highest number of dialogue attempt counts in the
    first round, with a significant difference of 27 for GPT-4 and 102 for GPT-3.5\.
    Moreover, after ten rounds of evolution, the average dialogue attempt count for
    GPT-4 has approached the target dialogue turn at 11.68, while the average for
    GPT-3.5 is 26.68, demonstrating the difference in the evolution effects caused
    by the disparity in the language performance of the models.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '在论坛式对话中，参与者智能体回应现有的讨论，监督智能体对其进行检查。与情境[IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2
    "IV-B 情境 1: 猜数字 ‣ IV 评估 ‣ 通过基于大型语言模型的多智能体仿真规避社交媒体监管的语言演化")和[IV-C](https://arxiv.org/html/2405.02858v1#S4.SS3
    "IV-C 情境 2: 宠物交易 ‣ IV 评估 ‣ 通过基于大型语言模型的多智能体仿真规避社交媒体监管的语言演化")不同，当监督智能体检测到违规时，对话并不会被暂停，而是从公共对话记录中进行审查。这个情境中有四个参与者智能体，他们需要在论坛中完成十次回复。在图[4](https://arxiv.org/html/2405.02858v1#S4.F4
    "图 4 ‣ IV 评估 ‣ 通过基于大型语言模型的多智能体仿真规避社交媒体监管的语言演化")(a)和(b)中，我们统计了智能体尝试对话的总轮次，其中图[4](https://arxiv.org/html/2405.02858v1#S4.F4
    "图 4 ‣ IV 评估 ‣ 通过基于大型语言模型的多智能体仿真规避社交媒体监管的语言演化")(a)和(b)中较低的数字是首选。我们注意到，GPT-4和GPT-3.5在第一轮对话尝试中均达到了最高的对话尝试次数，GPT-4为27次，GPT-3.5为102次，差异明显。此外，在经过十轮演化后，GPT-4的平均对话尝试次数已接近目标对话回合数，达到11.68，而GPT-3.5的平均值为26.68，显示出模型语言表现差异所带来的演化效果差异。'
- en: Fig.[4](https://arxiv.org/html/2405.02858v1#S4.F4 "Figure 4 ‣ IV Evaluation
    ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent
    Simulation")(c) and (d) showcases the count of successful information expressions.
    We note that in this scenario, while GPT-4 still leads GPT-3.5, both outcomes
    indicate substantial room for improvement.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图[4](https://arxiv.org/html/2405.02858v1#S4.F4 "图 4 ‣ IV 评估 ‣ 通过基于大型语言模型的多智能体仿真规避社交媒体监管的语言演化")(c)和(d)展示了成功信息表达的计数。我们注意到，在这一情境中，虽然GPT-4依然领先于GPT-3.5，但两者的结果都表明仍有很大的改进空间。
- en: Upon examining the dialogue history [7](https://arxiv.org/html/2405.02858v1#S4.F7
    "Figure 7 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), we discovered that agents powered by GPT-4
    proactively altered their language strategies, shifting from literal expressions
    to employing metaphors, personifications, and analogies as encoding methods. In
    contrast, agents driven by GPT-3.5 did not show clear signs of effective language
    strategy evolution, remaining confined to literal expressions.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查对话历史[7](https://arxiv.org/html/2405.02858v1#S4.F7 "图 7 ‣ IV 评估 ‣ 通过基于大型语言模型的多智能体仿真规避社交媒体监管的语言演化")时，我们发现由GPT-4驱动的智能体主动改变了其语言策略，从字面表达转向使用隐喻、拟人化和类比作为编码方法。相比之下，由GPT-3.5驱动的智能体没有表现出明显的有效语言策略演化，仍然局限于字面表达。
- en: IV-E Discussion and Limitations
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 讨论与局限性
- en: 'RQ1: Our experiments have shown that language models can develop strategies
    to effectively evade supervision. Within identical scenarios, GPT-4 outperformed
    GPT-3.5, achieving convergence more rapidly. Additionally, GPT-4 demonstrated
    a more stable performance post-convergence. This suggests that advancements in
    language model design significantly enhance the ability to navigate through regulatory
    frameworks. The iterative learning capability inherent in GPT-4 facilitates a
    quicker adaptation to imposed linguistic constraints, thereby enabling more efficient
    evasion of oversight.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: RQ1：我们的实验表明，语言模型能够发展策略，有效规避监督。在相同的场景下，GPT-4的表现优于GPT-3.5，达到了更快速的收敛。此外，GPT-4在收敛后的表现更加稳定。这表明，语言模型设计的进步显著提升了其在监管框架中应对的能力。GPT-4固有的迭代学习能力促进了其更快速地适应强加的语言限制，从而实现更高效的监督规避。
- en: 'RQ2: In terms of the precision of information dissemination, our findings indicate
    that, overall, LLM agents can refine their expression strategies with an increase
    in dialogue rounds, thereby improving precision. Despite this general trend of
    improvement, it is important to note that there remains significant room for enhancement
    in the overall performance. The extent of precision improvement varies across
    different scenarios, which points to an intriguing observation: certain contexts
    may inherently provide more or fewer clues for accurate communication than others.
    For instance, the guess-the-number game demanded abstract numerical reasoning,
    where precision is fundamentally challenging to achieve. Conversely, the pet trading
    scenario allowed for the utilization of rich, real-world analogies, facilitating
    a more precise conveyance of information. This contrast in contexts underscores
    the adaptability of LLM agents to the unique challenges presented by different
    communicative environments and their potential to optimize communication strategies.
    Nonetheless, the results also indicate that while the agents are capable of evolving
    their language to improve precision, there is still a considerable gap to reach
    optimal accuracy, especially in more abstract scenarios.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: RQ2：在信息传播的精确度方面，我们的研究结果表明，总体而言，随着对话轮次的增加，LLM代理能够精炼其表达策略，从而提高精度。尽管这一改善趋势普遍存在，但需要注意的是，整体表现仍然有显著的提升空间。精确度的提升幅度在不同场景中有所不同，这引出了一个有趣的观察：某些情境可能天生比其他情境提供更多或更少的线索来促进准确的沟通。例如，猜数字游戏需要抽象的数字推理，其中精确度本质上很难实现。相反，宠物交易场景则允许利用丰富的现实世界类比，从而更精确地传达信息。此种情境对比突显了LLM代理在不同沟通环境中应对独特挑战的适应性，以及优化沟通策略的潜力。然而，结果也表明，尽管代理能够演化其语言以提高精确度，但仍有相当大的差距需要弥补，尤其是在更抽象的场景中，尚未达到最佳精度。
- en: 'RQ3: In language strategy evolution, we observed that LLM agents adhere to
    human natural language norms, avoiding developing languages incomprehensible to
    humans in prompts without specific strategies. Agents evolved language to varying
    levels of abstraction in scenarios of differing complexity. For instance, in the
    most abstract Scenario [IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2 "IV-B
    Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading
    Social Media Regulation via LLM-based Multi-agent Simulation"), LLM agents quickly
    adopted indirect expression strategies in the early dialogue turns, requiring
    in-depth contextual reasoning for decoding. Throughout their evolution, agents
    continually adjusted their indirect expressions to better evade supervision while
    aligning more closely with the intended content. In the simpler, reality-simulating
    Scenario [IV-C](https://arxiv.org/html/2405.02858v1#S4.SS3 "IV-C Scenario 2: Pet
    Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), the overall language strategy mirrored
    that of [IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2 "IV-B Scenario 1: Guessing
    Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation
    via LLM-based Multi-agent Simulation"), still employing indirect expressions.
    However, the metaphors used were closer to real-world concepts, indicating a lower
    level of abstraction. Finally, in Scenario [IV-D](https://arxiv.org/html/2405.02858v1#S4.SS4
    "IV-D Scenario 3: Discussion on ALPS-treated water ‣ IV Evaluation ‣ Language
    Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation"),
    which closely mirrors real-life events, we noted different evolutionary paths
    in agents’ language performance. For GPT-4, agents eventually developed metaphorical
    indirect expressions, but the evolution required noticeably more turns compared
    to other scenarios. For GPT-3.5, the language strategy remained at a literal level,
    merely avoiding direct references to ALPS-treated water, indicating the lowest
    level of abstraction. Overall, LLM agents more readily evolve abstract language
    in dialogues about simple, universal concepts. However, their evolutionary direction
    becomes less clear in discussions on more specialized and segmented topics.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: RQ3：在语言策略演变方面，我们观察到LLM代理遵循人类自然语言规范，在没有特定策略的提示中，避免发展出人类无法理解的语言。代理在不同复杂度的场景中将语言演变到不同的抽象层次。例如，在最抽象的场景 [IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2
    "IV-B 场景 1：猜数字 ‣ IV 评估 ‣ LLM多代理模拟逃避社交媒体监管的语言演变")，LLM代理在早期对话回合中迅速采用了间接表达策略，解码时需要深入的上下文推理。在整个演变过程中，代理不断调整间接表达，以更好地逃避监管，并更贴近预期内容。在更简单、模拟现实的场景 [IV-C](https://arxiv.org/html/2405.02858v1#S4.SS3
    "IV-C 场景 2：宠物交易 ‣ IV 评估 ‣ LLM多代理模拟逃避社交媒体监管的语言演变") 中，整体语言策略与 [IV-B](https://arxiv.org/html/2405.02858v1#S4.SS2
    "IV-B 场景 1：猜数字 ‣ IV 评估 ‣ LLM多代理模拟逃避社交媒体监管的语言演变") 相似，仍然使用间接表达。然而，使用的隐喻更接近现实世界的概念，表明抽象层次较低。最后，在与现实生活事件紧密相似的场景 [IV-D](https://arxiv.org/html/2405.02858v1#S4.SS4
    "IV-D 场景 3：讨论ALPS处理水 ‣ IV 评估 ‣ LLM多代理模拟逃避社交媒体监管的语言演变") 中，我们注意到代理语言表现的演化路径不同。对于GPT-4，代理最终发展出了隐喻性的间接表达，但与其他场景相比，这一演化过程明显需要更多回合。对于GPT-3.5，语言策略停留在字面层面，仅仅避免直接提及ALPS处理水，显示出最低的抽象层次。总体而言，LLM代理更容易在讨论简单、普遍的概念时演化抽象语言。然而，在讨论更专业和细分的话题时，其演化方向变得不那么明确。
- en: Our experiments currently face several limitations. As for the experimental
    scenarios, at this stage, our trials are solely based on text-based chats, while
    real-world social media interactions are not limited to text but also include
    more diverse forms of exchanges such as voice and images. Additionally, LLMs’
    heavy reliance on the design of prompts also constrains the performance of our
    simulations; crafting a perfect prompt that can fully emulate the complexities
    of social media communication is an exceedingly challenging task.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验目前面临若干限制。在实验场景方面，当前我们的试验仅基于基于文本的聊天，而现实世界中的社交媒体互动不仅限于文本，还包括更多样的交流形式，如语音和图像。此外，LLM对提示设计的高度依赖也限制了我们模拟的表现；设计一个完美的提示，能够充分模拟社交媒体沟通的复杂性，是一项极具挑战性的任务。
- en: V Conclusion and Future Work
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论与未来工作
- en: Our study has introduced an LLM-based multi-agent simulation framework that
    effectively captures the nuanced strategies individuals use to bypass social media
    regulations. Through this framework, we have showcased LLMs’ proficiency in adapting
    communication tactics within regulated environments, reflecting the sophisticated
    dance between evolving language use and the constraints imposed by regulation.
    From abstract concepts to real-world scenarios, our research delineates the versatile
    capabilities of LLMs and underscores their significant potential to illuminate
    the pathways of language evolution in the digital realm.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究提出了一种基于大型语言模型（LLM）的多代理模拟框架，能够有效捕捉个体绕过社交媒体监管的微妙策略。通过该框架，我们展示了LLM在受限环境中调整沟通策略的能力，反映了语言使用的演变与监管约束之间的复杂互动。从抽象概念到现实场景，我们的研究勾画了LLM的多样化能力，并强调了它们在揭示数字领域语言演变路径中的巨大潜力。
- en: Nonetheless, it is crucial to consider that the linguistic adaptations observed
    in our simulations may not fully capture real human behaviors, and their applicability
    to other contexts remains uncertain. Moving forward, the scope of our research
    beckons a more intricate and comprehensive exploration. Future initiatives should
    aim to weave in complex interactional models, scale up the simulations to encompass
    broader user interaction networks, and incorporate dynamic, evolving regulatory
    frameworks to more accurately represent the fluidity of social media. Moreover,
    we envision incorporating human participants into the simulation framework, either
    as dialogue participants or supervisors, to conduct a more realistic evaluation.
    Furthermore, adopting a multimodal approach will more authentically capture the
    essence of social media, which blends textual, visual, and other forms of communication.
    These directions are anticipated to enhance the realism of our simulations, offering
    richer insights into language evolution tactics deployed to elude regulatory detection.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须考虑到，我们模拟中观察到的语言适应可能无法完全捕捉真实人类行为，其在其他情境中的适用性仍然不确定。展望未来，我们的研究范围呼唤更复杂和全面的探索。未来的工作应致力于融入复杂的互动模型，将模拟规模扩大以涵盖更广泛的用户互动网络，并纳入动态、不断发展的监管框架，以更准确地反映社交媒体的流动性。此外，我们还设想将人类参与者纳入模拟框架中，作为对话参与者或监督者，进行更现实的评估。此外，采用多模态方法将更真实地捕捉社交媒体的本质，社交媒体融合了文本、视觉和其他形式的交流。这些方向预计将增强我们模拟的现实感，提供更丰富的洞察力，揭示语言进化策略以规避监管检测。
- en: Acknowledgement
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This study was partially supported by the Pioneering Research Program for a
    Waseda Open Innovation Ecosystem (W-SPRING), and the Special Research Projects
    of Waseda University (Grant Number 2024E-021).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分得到了早稻田大学开放创新生态系统先锋研究计划（W-SPRING）和早稻田大学特别研究项目（资助编号2024E-021）的支持。
- en: References
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Z. Yang, “Wechat users are begging tencent to give their accounts back
    after talking about a beijing protest,” *MIT Technology Review*, 2022.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Z. Yang，“微信用户在谈论北京抗议事件后，恳求腾讯归还他们的账户，”*麻省理工科技评论*，2022年。'
- en: '[2] B. Fung, “Twitter bans president trump permanently,” *CNN*, 2021.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] B. Fung，“推特永久封禁特朗普总统，”*CNN*，2021年。'
- en: '[3] H. Jassim, “The impact of social media on language and communication,”
    vol. 13, pp. 2347–7180, 07 2023.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] H. Jassim，“社交媒体对语言和沟通的影响，”卷号13，第2347–7180页，2023年7月。'
- en: '[4] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li,
    X. Tang, Z. Liu, P. Liu, J. Nie, and J. rong Wen, “A survey of large language
    models,” *ArXiv*, vol. abs/2303.18223, 2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
    J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li,
    X. Tang, Z. Liu, P. Liu, J. Nie, 和 J. rong Wen，“大型语言模型调查，”*ArXiv*，卷号abs/2303.18223，2023年。'
- en: '[5] L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J. Tang,
    X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. rong Wen, “A survey on large language
    model based autonomous agents,” *ArXiv*, vol. abs/2308.11432, 2023.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J.
    Tang, X. Chen, Y. Lin, W. X. Zhao, Z. Wei, 和 J. rong Wen，“基于大型语言模型的自主代理调查，”*ArXiv*，卷号abs/2308.11432，2023年。'
- en: '[6] X. Tang, Z. Zheng, J. Li, F. Meng, S.-C. Zhu, Y. Liang, and M. Zhang, “Large
    language models are in-context semantic reasoners rather than symbolic reasoners,”
    2023.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] X. Tang, Z. Zheng, J. Li, F. Meng, S.-C. Zhu, Y. Liang, 和 M. Zhang，“大型语言模型是上下文语义推理器，而非符号推理器，”2023年。'
- en: '[7] C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, and D. Yang, “Can large
    language models transform computational social science?” 2023.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, 和 D. Yang，“大型语言模型能改变计算社会科学吗？”2023年。'
- en: '[8] Y. Mu, B. P. Wu, W. Thorne, A. Robinson, N. Aletras, C. Scarton, K. Bontcheva,
    and X. Song, “Navigating prompt complexity for zero-shot classification: A study
    of large language models in computational social science,” 2023.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Y. Mu, B. P. Wu, W. Thorne, A. Robinson, N. Aletras, C. Scarton, K. Bontcheva,
    和 X. Song，“应对零-shot分类中的提示复杂性：一项关于大型语言模型在计算社会科学中的研究，”2023年。'
- en: '[9] M. Choi, J. Pei, S. Kumar, C. Shu, and D. Jurgens, “Do llms understand
    social knowledge? evaluating the sociability of large language models with socket
    benchmark,” *arXiv preprint arXiv:2305.14938*, 2023.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] M. Choi, J. Pei, S. Kumar, C. Shu, 和 D. Jurgens，“大型语言模型是否理解社会知识？使用Socket基准评估大型语言模型的社交性，”
    *arXiv预印本 arXiv:2305.14938*，2023年。'
- en: '[10] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, and D. Wingate,
    “Out of one, many: Using language models to simulate human samples,” *Political
    Analysis*, vol. 31, no. 3, p. 337–351, 2023.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, 和 D. Wingate，“从一中见多：使用语言模型模拟人类样本，”
    *政治分析*，第31卷，第3期，页337–351，2023年。'
- en: '[11] W. Hua, L. Fan, L. Li, K. Mei, J. Ji, Y. Ge, L. Hemphill, and Y. Zhang,
    “War and peace (waragent): Large language model-based multi-agent simulation of
    world wars,” 2023.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] W. Hua, L. Fan, L. Li, K. Mei, J. Ji, Y. Ge, L. Hemphill, 和 Y. Zhang，“战争与和平（waragent）：基于大语言模型的世界大战多代理模拟，”2023年。'
- en: '[12] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S.
    Bernstein, “Generative agents: Interactive simulacra of human behavior,” *Proceedings
    of the 36th Annual ACM Symposium on User Interface Software and Technology*, 2023.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, 和 M. S.
    Bernstein，“生成性代理：人类行为的互动模拟，” *第36届ACM用户界面软件与技术年会论文集*，2023年。'
- en: '[13] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li, “S3:
    Social-network simulation system with large language model-empowered agents,”
    2023.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, 和 Y. Li，“S3：基于大语言模型代理的社交网络模拟系统，”2023年。'
- en: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, and et al., “Language
    models are few-shot learners,” in *Advances in Neural Information Processing Systems*,
    vol. 33.   Curran Associates, Inc., 2020, pp. 1877–1901.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, 和 *等*，“语言模型是少量样本学习者，”在
    *神经信息处理系统进展*，第33卷，Curran Associates, Inc.，2020年，页1877–1901。'
- en: '[15] OpenAI, “Gpt-4 technical report,” 2023.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] OpenAI，“GPT-4技术报告，”2023年。'
- en: '[16] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    and G. Lample, “Llama: Open and efficient foundation language models,” 2023.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
    B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave,
    和 G. Lample，“Llama：开放且高效的基础语言模型，”2023年。'
- en: '[17] H. Touvron, L. Martin, K. R. Stone, P. Albert, A. Almahairi, and et al.,
    “Llama 2: Open foundation and fine-tuned chat models,” *ArXiv*, vol. abs/2307.09288,
    2023.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] H. Touvron, L. Martin, K. R. Stone, P. Albert, A. Almahairi, 和 *等*，“Llama
    2：开放的基础与微调的聊天模型，” *ArXiv*，第abs/2307.09288卷，2023年。'
- en: '[18] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, and et al., “Palm:
    Scaling language modeling with pathways,” *J. Mach. Learn. Res.*, vol. 24, pp.
    240:1–240:113, 2023.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, 和 *等*，“Palm：通过路径扩展语言建模，”
    *J. Mach. Learn. Res.*，第24卷，页240:1–240:113，2023年。'
- en: '[19] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri,
    E. Taropa, P. Bailey, Z. Chen *et al.*, “Palm 2 technical report,” *arXiv preprint
    arXiv:2305.10403*, 2023.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri,
    E. Taropa, P. Bailey, Z. Chen *等*，“Palm 2技术报告，” *arXiv预印本 arXiv:2305.10403*，2023年。'
- en: '[20] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, and et al., “GLM-130B: an open
    bilingual pre-trained model,” in *The Eleventh International Conference on Learning
    Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023*.   OpenReview.net,
    2023.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, 和 *等*，“GLM-130B：一个开放的双语预训练模型，”在
    *第十一届国际学习表示会议，ICLR 2023，卢旺达基加利，2023年5月1-5日*，OpenReview.net，2023年。'
- en: '[21] J. Manyika and S. Hsiao, “An overview of bard: an early experiment with
    generative ai,” *AI. Google Static Documents*, vol. 2, 2023.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Manyika 和 S. Hsiao，“Bard概述：生成性AI的早期实验，” *AI. Google静态文档*，第2卷，2023年。'
- en: '[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” *Advances in neural
    information processing systems*, vol. 30, 2017.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin, “注意力即一切，”*神经信息处理系统进展*，第30卷，2017年。'
- en: '[23] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, and K. Tei, “Exploring the potential
    of large language models in self-adaptive systems,” 2024.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, 和 K. Tei, “探索大语言模型在自适应系统中的潜力，”2024年。'
- en: '[24] K. Suzuki, J. Cai, J. Li, T. Yamauchi, and K. Tei, “A comparative evaluation
    on melody generation of large language models,” in *2023 IEEE International Conference
    on Consumer Electronics-Asia (ICCE-Asia)*, 2023, pp. 1–4.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] K. Suzuki, J. Cai, J. Li, T. Yamauchi, 和 K. Tei, “大语言模型旋律生成的比较评估，”在*2023
    IEEE 国际消费电子亚洲会议 (ICCE-Asia)*，2023年，第1-4页。'
- en: '[25] S. Zhou, J. Li, M. Zhang, D. Saito, H. Washizaki, and K. Tei, “Can chatgpt
    obey the traffic regulations? evaluating chatgpt’s performance on driving-license
    written test,” in *2023 IEEE the 8th International Conference on Intelligent Transportation
    Engineering (ICITE)*, 2023.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] S. Zhou, J. Li, M. Zhang, D. Saito, H. Washizaki, 和 K. Tei, “ChatGPT能遵守交通法规吗？评估ChatGPT在驾驶证理论考试中的表现，”在*2023
    IEEE 第八届国际智能交通工程会议 (ICITE)*，2023年。'
- en: '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
    S. Agarwal, K. Slama, A. Ray *et al.*, “Training language models to follow instructions
    with human feedback,” *Advances in Neural Information Processing Systems*, vol. 35,
    pp. 27 730–27 744, 2022.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C.
    Zhang, S. Agarwal, K. Slama, A. Ray *等*，“训练语言模型通过人类反馈遵循指令，”*神经信息处理系统进展*，第35卷，第27,730-27,744页，2022年。'
- en: '[27] C.-S. Wang, H.-L. Yang, B.-Y. Li, and H.-Y. Chen, “Can generative ai eliminate
    speech harms? a study on detection of abusive and hate speech during the covid-19
    pandemic,” in *2023 IEEE International Conference on Consumer Electronics-Asia
    (ICCE-Asia)*, 2023, pp. 1–4.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] C.-S. Wang, H.-L. Yang, B.-Y. Li, 和 H.-Y. Chen, “生成性AI能消除语言伤害吗？关于在COVID-19大流行期间侮辱性和仇恨言论检测的研究，”在*2023
    IEEE 国际消费电子亚洲会议 (ICCE-Asia)*，2023年，第1-4页。'
- en: '[28] Y. Seki and Y. Liu, “Multi-task learning model for detecting internet
    slang words with two-layer annotation,” in *2022 International Conference on Asian
    Language Processing (IALP)*, 2022, pp. 212–218.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Y. Seki 和 Y. Liu, “用于检测网络俚语词汇的多任务学习模型，具有二层注释，”在*2022年亚洲语言处理国际会议 (IALP)*，2022年，第212-218页。'
- en: '[29] M. Rothe, R. Lath, D. Kumar, P. Yadav, and A. Aylani, “Slang language
    detection and identification in text,” in *2023 14th International Conference
    on Computing Communication and Networking Technologies (ICCCNT)*, 2023, pp. 1–5.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] M. Rothe, R. Lath, D. Kumar, P. Yadav, 和 A. Aylani, “文本中的俚语语言检测与识别，”在*2023年第14届国际计算通信与网络技术会议
    (ICCCNT)*，2023年，第1-5页。'
- en: '[30] Z. Sun, R. S. Zemel, and Y. Xu, “Slang generation as categorization.”
    in *CogSci*, 2019, pp. 2898–2904.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Z. Sun, R. S. Zemel, 和 Y. Xu, “俚语生成作为分类。”在*CogSci*，2019年，第2898-2904页。'
- en: '[31] Z. Sun, R. Zemel, and Y. Xu, “Semantically informed slang interpretation,”
    in *Proceedings of the 2022 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies*, 2022, pp. 5213–5231.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Z. Sun, R. Zemel, 和 Y. Xu, “语义信息驱动的俚语解释，”在*2022年北美计算语言学学会会议：人类语言技术论文集*，2022年，第5213-5231页。'
- en: '[32] Y. Fu, H. Peng, T. Khot, and M. Lapata, “Improving language model negotiation
    with self-play and in-context learning from ai feedback,” 2023.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Y. Fu, H. Peng, T. Khot, 和 M. Lapata, “通过自我博弈和从AI反馈中进行上下文学习，提升语言模型的谈判能力，”2023年。'
- en: '[33] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, and Y. Liu, “Exploring
    large language models for communication games: An empirical study on werewolf,”
    2023.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, 和 Y. Liu, “探索大语言模型在沟通游戏中的应用：狼人游戏的实证研究，”2023年。'
- en: '[34] Z. Xu, C. Yu, F. Fang, Y. Wang, and Y. Wu, “Language agents with reinforcement
    learning for strategic play in the werewolf game,” 2023.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Z. Xu, C. Yu, F. Fang, Y. Wang, 和 Y. Wu, “使用强化学习的语言代理进行狼人游戏中的战略玩法，”2023年。'
- en: '[35] S. Li, J. Yang, and K. Zhao, “Are you in a masquerade? exploring the behavior
    and impact of large language model driven social bots in online social networks,”
    *arXiv preprint arXiv:2307.10337*, 2023.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] S. Li, J. Yang, 和 K. Zhao, “你是在化装舞会吗？探索大语言模型驱动的社交机器人在在线社交网络中的行为和影响，”*arXiv预印本
    arXiv:2307.10337*，2023年。'
- en: '[36] R. C. Atkinson and R. M. Shiffrin, “Human memory: A proposed system and
    its control processes,” in *Psychology of learning and motivation*.   Elsevier,
    1968, vol. 2, pp. 89–195.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] R. C. Atkinson 和 R. M. Shiffrin, “人类记忆：提出的系统及其控制过程，” 载于 *学习与动机心理学*。Elsevier，1968年，卷.
    2，页码89–195。'
- en: '[37] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. hsin Chi, F. Xia, Q. Le,
    and D. Zhou, “Chain of thought prompting elicits reasoning in large language models,”
    *ArXiv*, vol. abs/2201.11903, 2022.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. hsin Chi, F. Xia, Q. Le,
    和 D. Zhou, “思维链提示在大型语言模型中引发推理，” *ArXiv*，卷. abs/2201.11903，2022年。'
- en: '[38] J. Ying, Y. Cao, K. Xiong, Y. He, L. Cui, and Y. Liu, “Intuitive or dependent?
    investigating llms’ robustness to conflicting prompts,” *ArXiv*, vol. abs/2309.17415,
    2023.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] J. Ying, Y. Cao, K. Xiong, Y. He, L. Cui, 和 Y. Liu, “直观还是依赖？研究大型语言模型对冲突提示的鲁棒性，”
    *ArXiv*，卷. abs/2309.17415，2023年。'
- en: '[39] N. MacKinnon and K. Schilling, “Optimal strategy for a number-guessing
    game: 11051,” *Am. Math. Mon.*, vol. 113, no. 1, pp. 81–82, 2006.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] N. MacKinnon 和 K. Schilling, “数字猜谜游戏的最优策略：11051，” *Am. Math. Mon.*，卷.
    113，第1期，页码81–82，2006年。'
- en: '[40] X. Wang, “Two number-guessing problems plus applications in cryptography,”
    *Int. J. Netw. Secur.*, vol. 21, no. 3, pp. 494–500, 2019.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] X. Wang, “两个数字猜谜问题及其在密码学中的应用，” *Int. J. Netw. Secur.*，卷. 21，第3期，页码494–500，2019年。'
- en: '[41] K. Bahamazava and R. Nanda, “The shift of darknet illegal drug trade preferences
    in cryptocurrency: The question of traceability and deterrence,” *Digit. Investig.*,
    vol. 40, no. Supplement, p. 301377, 2022.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] K. Bahamazava 和 R. Nanda, “加密货币中暗网非法毒品交易偏好的转变：追踪性和威慑性问题，” *Digit. Investig.*，卷.
    40，附刊，第301377页，2022年。'
- en: '[42] K. Basu and A. Sen, “Monitoring individuals in drug trafficking organizations:
    a social network analysis,” in *ASONAM ’19: International Conference on Advances
    in Social Networks Analysis and Mining, Vancouver, British Columbia, Canada, 27-30
    August, 2019*.   ACM, 2019, pp. 480–483.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] K. Basu 和 A. Sen, “监控毒品贩运组织中的个体：社交网络分析，” 载于 *ASONAM ’19：国际社交网络分析与挖掘进展会议，2019年8月27-30日，温哥华，英国哥伦比亚省，加拿大*。ACM，2019年，页码480–483。'
- en: '[43] F. Tsai, M. Hsu, C. Chen, and D. Kao, “Exploring drug-related crimes with
    social network analysis,” in *Knowledge-Based and Intelligent Information & Engineering
    Systems: Proceedings of the 23rd International Conference KES-2019, Budapest,
    Hungary, 4-6 September 2019*, vol. 159.   Elsevier, 2019, pp. 1907–1917.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] F. Tsai, M. Hsu, C. Chen, 和 D. Kao, “利用社交网络分析探索与毒品相关的犯罪，” 载于 *基于知识的智能信息与工程系统：第23届国际会议KES-2019论文集，匈牙利布达佩斯，2019年9月4-6日*，卷.
    159。Elsevier，2019年，页码1907–1917。'
- en: '[44] S. Lyu and Z. Lu, “Exploring temporal and multilingual dynamics of post-disaster
    social media discourse: A case of fukushima daiichi nuclear accident,” *Proc.
    ACM Hum. Comput. Interact.*, vol. 7, no. CSCW1, pp. 1–24, 2023.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] S. Lyu 和 Z. Lu, “探索灾后社交媒体话语的时间性与多语言动态：福岛第一核电站事故案例，” *Proc. ACM Hum. Comput.
    Interact.*，卷. 7，第CSCW1期，页码1–24，2023年。'
- en: '[45] E. Zarrabeitia-Bilbao, M. Jaca-Madariaga, R. M. Río-Belver, and I. Alvarez-Meaza,
    “Nuclear energy: Twitter data mining for social listening analysis,” *Soc. Netw.
    Anal. Min.*, vol. 13, no. 1, p. 29, 2023.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] E. Zarrabeitia-Bilbao, M. Jaca-Madariaga, R. M. Río-Belver, 和 I. Alvarez-Meaza,
    “核能：Twitter数据挖掘用于社交聆听分析，” *Soc. Netw. Anal. Min.*，卷. 13，年第1期，第29页，2023年。'
