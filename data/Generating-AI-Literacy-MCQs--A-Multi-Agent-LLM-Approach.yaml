- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 11:52:59'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:52:59
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Generating AI Literacy MCQs: A Multi-Agent LLM Approach'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成AI素养选择题：一种多代理LLM方法
- en: 来源：[https://arxiv.org/html/2412.00970/](https://arxiv.org/html/2412.00970/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2412.00970/](https://arxiv.org/html/2412.00970/)
- en: Jiayi Wang [jiayiwang2025@u.northwestern.edu](mailto:jiayiwang2025@u.northwestern.edu)
    [0009-0003-1665-9360](https://orcid.org/0009-0003-1665-9360 "ORCID identifier")
    Northwestern UniversityEvanstonIllinoisUSA ,  Ruiwei Xiao [ruiweix@andrew.cmu.edu](mailto:ruiweix@andrew.cmu.edu)
    [0000-0002-6461-7611](https://orcid.org/0000-0002-6461-7611 "ORCID identifier")
    Carnegie Mellon UniversityPittsburghPennsylvaniaUSA  and  Ying-Jui Tseng [yingjuit@andrew.cmu.edu](mailto:yingjuit@andrew.cmu.edu)
    [0009-0006-1801-6061](https://orcid.org/0009-0006-1801-6061 "ORCID identifier")
    Carnegie Mellon UniversityPittsburghPennsylvaniaUSA(2025)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 王家怡 [jiayiwang2025@u.northwestern.edu](mailto:jiayiwang2025@u.northwestern.edu)
    [0009-0003-1665-9360](https://orcid.org/0009-0003-1665-9360 "ORCID identifier")
    西北大学 埃文斯顿 伊利诺伊州 美国，肖瑞伟 [ruiweix@andrew.cmu.edu](mailto:ruiweix@andrew.cmu.edu)
    [0000-0002-6461-7611](https://orcid.org/0000-0002-6461-7611 "ORCID identifier")
    卡内基梅隆大学 匹兹堡 宾夕法尼亚州 美国，以及曾英杰 [yingjuit@andrew.cmu.edu](mailto:yingjuit@andrew.cmu.edu)
    [0009-0006-1801-6061](https://orcid.org/0009-0006-1801-6061 "ORCID identifier")
    卡内基梅隆大学 匹兹堡 宾夕法尼亚州 美国（2025）
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Artificial intelligence (AI) is transforming society, making it crucial to prepare
    the next generation through AI literacy in K-12 education. However, scalable and
    reliable AI literacy materials and assessment resources are lacking. To address
    this gap, our study presents a novel approach to generating multiple-choice questions
    (MCQs) for AI literacy assessments. Our method utilizes large language models
    (LLMs) to automatically generate scalable, high-quality assessment questions.
    These questions align with user-provided learning objectives, grade levels, and
    Bloom’s Taxonomy levels. We introduce an iterative workflow incorporating LLM-powered
    critique agents to ensure the generated questions meet pedagogical standards.
    In the preliminary evaluation, experts expressed strong interest in using the
    LLM-generated MCQs, indicating that this system could enrich existing AI literacy
    materials and provide a valuable addition to the toolkit of K-12 educators.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）正在改变社会，这使得通过AI素养为下一代做准备变得至关重要。然而，缺乏可扩展且可靠的AI素养材料和评估资源。为了解决这一问题，我们的研究提出了一种新颖的方法来生成AI素养评估的选择题（MCQs）。我们的方法利用大型语言模型（LLMs）自动生成可扩展的高质量评估问题。这些问题与用户提供的学习目标、年级水平和布鲁姆分类法的等级相一致。我们引入了一种迭代工作流，结合LLM驱动的评审代理，确保生成的问题符合教学标准。在初步评估中，专家们表示出强烈的兴趣，愿意使用LLM生成的选择题，这表明该系统可以丰富现有的AI素养材料，并为K-12教育者的工具包提供宝贵的补充。
- en: '^†^†journalyear: 2025^†^†copyright: rightsretained^†^†conference: Proceedings
    of the 56th ACM Technical Symposium on Computer Science Education V. 2; February
    26-March 1, 2025; Pittsburgh, PA, USA^†^†booktitle: Proceedings of the 56th ACM
    Technical Symposium on Computer Science Education V. 2 (SIGCSE TS 2025), February
    26-March 1, 2025, Pittsburgh, PA, USA^†^†doi: 10.1145/3641555.3705189^†^†isbn:
    979-8-4007-0532-8/25/02'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ^†^†期刊年份：2025^†^†版权：权利保留^†^†会议：第56届ACM计算机科学教育技术研讨会，第2卷；2025年2月26日至3月1日；宾夕法尼亚州匹兹堡，美国^†^†书名：第56届ACM计算机科学教育技术研讨会，第2卷（SIGCSE
    TS 2025），2025年2月26日至3月1日，宾夕法尼亚州匹兹堡，美国^†^†DOI：10.1145/3641555.3705189^†^†ISBN：979-8-4007-0532-8/25/02
- en: 1\. Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 引言
- en: AI is rapidly transforming our world, from the way we work to the way we interact
    with each other. To prepare the next generation for this AI-driven world, educational
    frameworks like AI4K12’s ”Five Big Ideas”(Touretzky et al., [2022](https://arxiv.org/html/2412.00970v1#bib.bib10))
    (Perception, Representation and Reasoning, Learning, Natural Interaction, and
    Natural Interaction) have been developed to integrate AI literacy into K-12 education.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）正在迅速改变我们的世界，从我们工作的方式到我们相互互动的方式。为了为下一代准备好这个由AI驱动的世界，像AI4K12的“五大理念”（Touretzky等人，[2022](https://arxiv.org/html/2412.00970v1#bib.bib10)）（感知、表示与推理、学习、自然交互以及自然交互）等教育框架已被开发出来，以将AI素养融入K-12教育。
- en: However, as a relatively new subject area, there is a lack of learning materials
    in AI literacy instructional and assessment activities(Gardner-McCune et al.,
    [2019](https://arxiv.org/html/2412.00970v1#bib.bib5)). In addition, existing courses
    and assessment resources are often not scalable or reliable (Tseng et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib11)).
    This shortage presents a significant challenge for teachers who must teach and
    assess students’ understanding of AI concepts while fostering critical thinking
    skills for responsible engagement with these technologies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，作为一个相对较新的学科领域，在人工智能素养教学和评估活动中缺乏学习材料（Gardner-McCune等，[2019](https://arxiv.org/html/2412.00970v1#bib.bib5)）。此外，现有的课程和评估资源通常不具备可扩展性或可靠性（Tseng等，[2024](https://arxiv.org/html/2412.00970v1#bib.bib11)）。这一短缺对教师构成了重大挑战，教师不仅需要教授和评估学生对AI概念的理解，还要培养学生在负责任地使用这些技术时的批判性思维能力。
- en: Leveraging Large Language Models (LLMs) to generate assessment questions (Doughty
    et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib4); Caines et al., [2023](https://arxiv.org/html/2412.00970v1#bib.bib3);
    Stamper et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib9)) offers a
    potential solution. This method has shown promise in subjects like programming(Doughty
    et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib4)), medicine(Indran
    et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib6)), and language learning(Caines
    et al., [2023](https://arxiv.org/html/2412.00970v1#bib.bib3)). The potential to
    apply these methods to AI literacy assessments could help bridge the gap for educators
    by providing accessible, scalable assessment resources.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 利用大语言模型（LLM）生成评估问题（Doughty等，[2024](https://arxiv.org/html/2412.00970v1#bib.bib4)；Caines等，[2023](https://arxiv.org/html/2412.00970v1#bib.bib3)；Stamper等，[2024](https://arxiv.org/html/2412.00970v1#bib.bib9)）为一种潜在的解决方案。这种方法在编程（Doughty等，[2024](https://arxiv.org/html/2412.00970v1#bib.bib4)）、医学（Indran等，[2024](https://arxiv.org/html/2412.00970v1#bib.bib6)）和语言学习（Caines等，[2023](https://arxiv.org/html/2412.00970v1#bib.bib3)）等学科中已经显示出潜力。将这些方法应用于人工智能素养评估，有助于为教育者提供可访问、可扩展的评估资源，从而弥合教育资源的缺口。
- en: 'This exploratory study, conducted as part of the active.ai¹¹1https://active-ai.vercel.app
    project, builds on previous research on MCQ generation (Doughty et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib4);
    Moore et al., [2023](https://arxiv.org/html/2412.00970v1#bib.bib7)) and AI literacy
    (Touretzky et al., [2022](https://arxiv.org/html/2412.00970v1#bib.bib10)). It
    seeks to address the following research question: Can LLM-powered multi-agent
    workflows effectively generate high-quality MCQs for AI literacy?'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本次探索性研究作为active.ai¹¹1https://active-ai.vercel.app项目的一部分，建立在之前关于选择题生成（Doughty等，[2024](https://arxiv.org/html/2412.00970v1#bib.bib4)；Moore等，[2023](https://arxiv.org/html/2412.00970v1#bib.bib7)）和人工智能素养（Touretzky等，[2022](https://arxiv.org/html/2412.00970v1#bib.bib10)）的研究基础上。它旨在回答以下研究问题：利用大语言模型驱动的多代理工作流，能否有效地生成高质量的人工智能素养选择题？
- en: 2\. Methodology
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 方法论
- en: '![Refer to caption](img/a813dff383fefcca7f7739094e872f0d.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/a813dff383fefcca7f7739094e872f0d.png)'
- en: Figure 1\. Multi-Agent MCQ Generation System.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 多代理选择题生成系统。
- en: The Multi-Agent MCQ Generation System developed for this study generates and
    refines MCQs to assess AI literacy, using a workflow built on the LangGraph framework²²2https://www.langchain.com/langgraph,
    and OpenAI’s gpt-4o-mini-2024-07-18 model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为本研究开发的多代理选择题生成系统，使用基于LangGraph框架²²2https://www.langchain.com/langgraph的工作流，结合OpenAI的gpt-4o-mini-2024-07-18模型，生成和完善评估人工智能素养的选择题。
- en: 'User inputs, including learning objectives, Bloom’s taxonomy levels (Anderson
    and Krathwohl, [2001](https://arxiv.org/html/2412.00970v1#bib.bib2)), grade level,
    and specific scenarios, guide the Generator Agent in producing an initial question
    with fields stem (question), key (correct option), and distractors (incorrect
    options). The question is independently reviewed by two critique agents: a Language
    Critique Agent, which evaluates readability and alignment with grade level, and
    an IWF (Item-Writing Flaw) Critique Agent (Moore et al., [2023](https://arxiv.org/html/2412.00970v1#bib.bib7)),
    which applies rule-based checks (modified from (Moore et al., [2023](https://arxiv.org/html/2412.00970v1#bib.bib7)))
    for issues such as implausible distractors or absolute terms. A question with
    0 or 1 flaw is considered acceptable. Based on feedback from these agents, the
    question is either approved by the Supervisor Agent or sent back to the Generator
    Agent for revision. This iterative process continues until the question meets
    quality standards or reaches the maximum number of revisions. We generated a total
    of 40 multiple choice questions for students in grades K7-9.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 用户输入的内容，包括学习目标、布鲁姆分类学层次（Anderson和Krathwohl，[2001](https://arxiv.org/html/2412.00970v1#bib.bib2)）、年级水平和具体场景，引导生成器代理（Generator
    Agent）生成初步问题，涵盖题干（问题）、关键（正确选项）和干扰项（错误选项）字段。该问题会由两位评审代理独立审查：语言评审代理（Language Critique
    Agent），评估可读性和与年级水平的契合度；以及IWF（题目写作缺陷）评审代理（Moore等人，[2023](https://arxiv.org/html/2412.00970v1#bib.bib7)），应用基于规则的检查（改编自(Moore等人，[2023](https://arxiv.org/html/2412.00970v1#bib.bib7)）），检查诸如不合理的干扰项或绝对词汇等问题。带有0或1个缺陷的问题被认为是可接受的。根据这些代理的反馈，问题要么被监督代理批准，要么返回给生成器代理进行修改。这个迭代过程会持续进行，直到问题符合质量标准或达到最大修订次数为止。我们共为K7-9年级的学生生成了40个多项选择题。
- en: 'The following is an example of a generated question:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是生成问题的示例：
- en: <svg class="ltx_picture" height="109.35" id="S2.p4.1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,109.35) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 91.15)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Sample Generated Question</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="59.65" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">Ben is considering using an AI tool to help him write a
    creative story. Which of the following reasons best explains when using AI might
    be a bad choice for his learning? A. It may produce a story that lacks originality
    and personal expression. B. AI can provide quick feedback on grammar and structure.
    C. Using AI can help him brainstorm new ideas for his story. D. AI tools can assist
    in organizing his thoughts more effectively.</foreignobject></g></g></svg>
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: <svg class="ltx_picture" height="109.35" id="S2.p4.1.pic1" overflow="visible"
    version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt"
    transform="translate(0,109.35) matrix(1 0 0 -1 0 0)"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 91.15)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible"
    transform="matrix(1 0 0 -1 0 16.6)" width="556.69">Sample Generated Question</foreignobject></g>
    <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject
    color="#000000" height="59.65" overflow="visible" transform="matrix(1 0 0 -1 0
    16.6)" width="556.69">Ben is considering using an AI tool to help him write a
    creative story. Which of the following reasons best explains when using AI might
    be a bad choice for his learning? A. It may produce a story that lacks originality
    and personal expression. B. AI can provide quick feedback on grammar and structure.
    C. Using AI can help him brainstorm new ideas for his story. D. AI tools can assist
    in organizing his thoughts more effectively.</foreignobject></g></g></svg>
- en: 3\. Results
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 结果
- en: 'Three experts with more than a year of K-12 AI Literacy teaching experiences,
    evaluated the quality of each of the 40 MCQs used a ten-item rubric (Table [1](https://arxiv.org/html/2412.00970v1#S3.T1
    "Table 1 ‣ 3\. Results ‣ Generating AI Literacy MCQs: A Multi-Agent LLM Approach")
    modified from (Scaria et al., [2024](https://arxiv.org/html/2412.00970v1#bib.bib8))).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '三位具有一年以上K-12人工智能素养教学经验的专家，使用十项标准评估了40个多项选择题的质量（表[1](https://arxiv.org/html/2412.00970v1#S3.T1
    "Table 1 ‣ 3\. Results ‣ Generating AI Literacy MCQs: A Multi-Agent LLM Approach")，改编自(Scaria等人，[2024](https://arxiv.org/html/2412.00970v1#bib.bib8))）。'
- en: '| Rubric Item | Definition and Response Option |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| Rubric Item | 定义和回应选项 |'
- en: '| --- | --- |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Understandable | Could you understand what the question is asking? (yes/no)
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Understandable | 你能理解这个问题在问什么吗？（是/否） |'
- en: '| LORelated | Is the question related to the learning objective? (yes/no) |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| LORelated | 该问题是否与学习目标相关？（是/否） |'
- en: '| Grammatical | Is the question grammatically well-formed? (yes/no) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Grammatical | 问题的语法是否正确？（是/否） |'
- en: '| Clear | Is it clear what the question asks for? (yes/more_or_less/no) |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Clear | 问题的要求是否清晰？（是/有些/否） |'
- en: '| Rephrase | Could you rephrase the question to make it clearer and error-free?
    (yes/no) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Rephrase | 你能改写这个问题，使其更加清晰并无错误吗？（是/否） |'
- en: '| Answerable | Can students answer the question with the information or context
    provided within? (yes/no) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Answerable | 学生是否能够根据提供的信息或背景回答这个问题？（是/否） |'
- en: '| Central | Do you think being able to answer the question is important to
    work on the topic given in the prompt? (yes/no) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Central | 你认为能回答该问题对于理解题干所给主题重要吗？（是/否） |'
- en: '| WouldYouUseIt | If you were a teacher teaching the course topic would you
    use this question or the rephrased version in the course? (this/rephrased/both/neither)
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| WouldYouUseIt | 如果你是教授该课程主题的老师，你会在课程中使用这个问题或改写版本吗？（这个/改写版/都用/都不用） |'
- en: '| Bloom’sLevel | Do you think the question is of the Bloom’s taxonomy level
    labeled? (yes/no) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Bloom’sLevel | 你认为这个问题属于布鲁姆分类学的哪个层次？（是/否） |'
- en: '| GradeLevel | Do you think the question is appropriate for K7-9? (yes/no)
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| GradeLevel | 你认为这个问题适合K7-9年级吗？（是/否） |'
- en: Table 1\. Rubric for Question Evaluation
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 问题评估标准
- en: '![Refer to caption](img/ef78bb6fb307fece3cbb739102681af5.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ef78bb6fb307fece3cbb739102681af5.png)'
- en: Figure 2\. Evaluation Result
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 评估结果
- en: Experts 1, 2, and 3 agreed with the system on 97.5%, 85%, and 85% of the correct
    answers, respectively. This suggests that the system generally produces correct
    answers that align with expert judgments. Although rare, there are also occasional
    misalignments between the system’s generated answers and expert evaluations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 专家1、2和3分别在97.5%、85%和85%的正确答案上与系统达成一致。这表明，系统通常能够生成与专家判断一致的正确答案。尽管较为罕见，但也存在系统生成的答案与专家评估之间的偶尔不一致。
- en: There was strong agreement among experts on syntactical correctness, with high
    ”Yes” responses for criteria such as Understandable, Answerable, Grammatical,
    and Clear, with average percentages ranging from 93.3% to 99.2%. This suggests
    that the questions generated by the multi-agent approach are well-formed and clear.
    Additionally, experts agreed that the questions were highly relevant to the learning
    objectives (LORelated 98.3%) and central to the topics being assessed (Central
    98.3%).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在语法正确性方面，专家们的意见高度一致，对于“易理解”、“可回答”、“语法正确”和“清晰”等标准，均给出了高比例的“是”回答，平均百分比范围从93.3%到99.2%。这表明，采用多代理方法生成的问题是结构良好且清晰的。此外，专家们一致认为，这些问题与学习目标高度相关（学习目标相关性98.3%）且紧扣评估的主题（主题相关性98.3%）。
- en: There was noticeable disagreement among the experts in criterion Rephrase, Bloom’sLevel,
    and GradeLevel. Expert 2 was stricter, suggesting that 97.5% of the questions
    needed rephrasing, while Experts 1 and 3 flagged fewer questions (7.5% and 17.5%).
    The same trend is seen with the GradeLevel, where Expert 2 marked 20% of the questions
    as inappropriate, compared to Expert 1 at 7.5% and Expert 3 at 5%. These discrepancies
    likely arise from varying interpretations of the rubric or differences in pedagogical
    approaches. Expert 1 significantly differed from Experts 2 and 3 on the Bloom’sLevel
    criterion, marking only 35% of the questions as appropriate for the intended cognitive
    level, while the other two experts rated all questions as aligned with the correct
    Bloom’s level.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在“重新措辞”、“布鲁姆认知水平”和“年级水平”这几个标准上，专家们的意见出现了明显分歧。专家2更为严格，认为97.5%的问题需要重新措辞，而专家1和专家3标注的问题较少（分别为7.5%和17.5%）。在年级水平方面，专家2标注了20%的问题为不合适，而专家1为7.5%，专家3为5%。这些差异可能源于对评分标准的不同理解或教学方法的差异。专家1在布鲁姆认知水平标准上与专家2和专家3存在显著不同，标注只有35%的问题适合预定的认知水平，而另外两位专家认为所有问题都符合正确的布鲁姆认知水平。
- en: Finally, there was moderate agreement on the WouldYouUseIt criterion, with expert
    responses ranging from 77.5% to 95% (average 84.2%). This indicates that a significant
    majority of the questions were seen as suitable for classroom use, demonstrating
    that the multi-agent system can produce questions that are not only well-formed
    but also useful in practical educational settings. However, the diverse responses
    suggest that individual preferences or teaching styles influence the willingness
    to use certain questions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在“是否愿意使用”这一标准上，专家们的意见呈中等一致性，专家的回应比例从77.5%到95%不等（平均为84.2%）。这表明，大多数专家认为这些问题适合课堂使用，证明了多代理系统不仅能生成结构良好的问题，还能生成在实际教育环境中有用的问题。然而，专家们的不同回答表明，个人偏好或教学风格会影响他们对某些问题的使用意愿。
- en: Overall, while some refinement is necessary to accommodate diverse educational
    contexts, the multi-agent approach demonstrates strong potential to generate pedagogically
    sound and scalable high-quality assessment questions for AI literacy in K-12 education.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，尽管需要进行一些调整以适应不同的教育环境，但多代理方法展示了生成符合教学需求、可扩展的高质量评估问题的巨大潜力，特别是在K-12教育中的人工智能素养方面。
- en: 4\. Limitations and Future Work
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 限制与未来工作
- en: One avenue for future work is to conduct classroom trials to evaluate student
    learning outcomes and teacher usability. While our multi-agent system successfully
    generated AI literacy MCQs, it has not been tested in real-world classrooms, so
    its effectiveness in diverse learning environments is still uncertain. Another
    important direction for future research is to explore additional methods for evaluating
    question quality beyond expert assessments, such as leveraging student performance
    data, crowd-sourced feedback, and automated analysis to provide a more comprehensive
    and objective evaluation. Our current evaluation relied on expert judgments, which
    introduces potential subjectivity. Key priorities include expanding the system’s
    adaptability to more grade levels, Bloom’s Taxonomy levels, and subjects beyond
    AI literacy, as well as integrating diverse assessment formats (e.g., open-ended,
    project-based questions) to enhance its practical utility. Finally, the tool can
    help teachers design AI literacy courses using a backward design approach, aligning
    assessments with learning objectives.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 未来研究的一个方向是进行课堂试验，以评估学生学习成果和教师可用性。尽管我们的多代理系统成功生成了 AI 素养的多项选择题，但它尚未在真实课堂中进行测试，因此其在多样化学习环境中的有效性仍不确定。另一个重要的研究方向是探索更多评估问题质量的方法，超越专家评估，例如利用学生表现数据、众包反馈和自动化分析来提供更全面和客观的评估。目前的评估依赖于专家判断，这可能引入潜在的主观性。关键的研究重点包括扩展系统对更多年级、布鲁姆分类法的不同层级以及超出
    AI 素养的学科的适应性，同时整合多样化的评估格式（例如，开放式问题、基于项目的问题），以增强其实际效用。最后，该工具可以帮助教师采用逆向设计方法来设计 AI
    素养课程，使评估与学习目标对齐。
- en: References
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Anderson and Krathwohl (2001) Lorin W. Anderson and David R. Krathwohl (Eds.).
    2001. *A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom’s
    Taxonomy of Educational Objectives* (complete ed ed.). Longman, New York.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anderson 和 Krathwohl（2001）Lorin W. Anderson 和 David R. Krathwohl（主编）。2001. *学习、教学与评估的分类法：布鲁姆教育目标分类法的修订版*（完整版）。Longman，纽约。
- en: Caines et al. (2023) Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher
    Davis, Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore, Christopher
    Bryant, et al. 2023. On the application of large language models for language
    teaching and assessment technology. *arXiv preprint arXiv:2307.08393* (2023).
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caines 等人（2023）Andrew Caines、Luca Benedetto、Shiva Taslimipoor、Christopher Davis、Yuan
    Gao、Oeistein Andersen、Zheng Yuan、Mark Elliott、Russell Moore、Christopher Bryant
    等人. 2023. 《大型语言模型在语言教学与评估技术中的应用》。*arXiv 预印本 arXiv:2307.08393*（2023）。
- en: Doughty et al. (2024) Jacob Doughty, Zipiao Wan, Anishka Bompelli, Jubahed Qayum,
    Taozhi Wang, Juran Zhang, Yujia Zheng, Aidan Doyle, Pragnya Sridhar, Arav Agarwal,
    et al. 2024. A comparative study of AI-generated (GPT-4) and human-crafted MCQs
    in programming education. In *Proceedings of the 26th Australasian Computing Education
    Conference*. 114–123.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doughty 等人（2024）Jacob Doughty、Zipiao Wan、Anishka Bompelli、Jubahed Qayum、Taozhi
    Wang、Juran Zhang、Yujia Zheng、Aidan Doyle、Pragnya Sridhar、Arav Agarwal 等人. 2024.
    《AI 生成的（GPT-4）与人工设计的编程教育多项选择题的比较研究》。载于 *第26届澳大利亚计算教育会议论文集*，114–123。
- en: 'Gardner-McCune et al. (2019) Christina Gardner-McCune, David Touretzky, Fred
    Martin, and Deborah Seehorn. 2019. AI for K-12: Making room for AI in K-12 CS
    curricula. In *Proceedings of the 50th ACM Technical Symposium on Computer Science
    Education*. 1244–1244.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gardner-McCune 等人（2019）Christina Gardner-McCune、David Touretzky、Fred Martin
    和 Deborah Seehorn. 2019. 《K-12 AI：为 K-12 计算机科学课程腾出 AI 空间》。载于 *第50届 ACM计算机科学教育技术研讨会论文集*，1244–1244。
- en: 'Indran et al. (2024) Inthrani Raja Indran, Priya Paranthaman, Neelima Gupta,
    and Nurulhuda Mustafa. 2024. Twelve tips to leverage AI for efficient and effective
    medical question generation: a guide for educators using Chat GPT. *Medical Teacher*
    (2024), 1–6.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Indran 等人（2024）Inthrani Raja Indran、Priya Paranthaman、Neelima Gupta 和 Nurulhuda
    Mustafa. 2024. 《利用 AI 高效生成医学问题的十二条建议：使用 Chat GPT 的教育者指南》。*医学教师*（2024），1–6。
- en: Moore et al. (2023) Steven Moore, Huy A Nguyen, Tianying Chen, and John Stamper.
    2023. Assessing the quality of multiple-choice questions using gpt-4 and rule-based
    methods. In *European Conference on Technology Enhanced Learning*. Springer, 229–245.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moore 等人（2023）Steven Moore、Huy A Nguyen、Tianying Chen 和 John Stamper. 2023.
    《使用 GPT-4 和基于规则的方法评估多项选择题质量》。载于 *欧洲技术增强学习大会*，Springer，229–245。
- en: 'Scaria et al. (2024) Nicy Scaria, Suma Dharani Chenna, and Deepak Subramani.
    2024. Automated Educational Question Generation at Different Bloom’s Skill Levels
    Using Large Language Models: Strategies and Evaluation. In *International Conference
    on Artificial Intelligence in Education*. Springer, 165–179.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scaria et al. (2024) Nicy Scaria, Suma Dharani Chenna, 和 Deepak Subramani. 2024.
    使用大型语言模型在不同布鲁姆技能层次上的自动化教育问题生成：策略与评估。载于*国际人工智能教育大会*。Springer，165–179。
- en: 'Stamper et al. (2024) John Stamper, Ruiwei Xiao, and Xinying Hou. 2024. Enhancing
    llm-based feedback: Insights from intelligent tutoring systems and the learning
    sciences. In *International Conference on Artificial Intelligence in Education*.
    Springer, 32–43.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stamper et al. (2024) John Stamper, Ruiwei Xiao, 和 Xinying Hou. 2024. 提升基于LLM的反馈：来自智能辅导系统和学习科学的洞察。载于*国际人工智能教育大会*。Springer，32–43。
- en: Touretzky et al. (2022) David S. Touretzky, Christina Gardner-Mccune, and Deborah W.
    Seehorn. 2022. Machine Learning and the Five Big Ideas in AI. *International Journal
    of Artificial Intelligence in Education* 33 (2022), 233–266.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touretzky et al. (2022) David S. Touretzky, Christina Gardner-Mccune, 和 Deborah
    W. Seehorn. 2022. 机器学习与AI中的五大核心理念。*国际人工智能教育期刊* 33 (2022)，233–266。
- en: Tseng et al. (2024) Ying-Jui Tseng, Ruiwei Xiao, Christopher Bogart, Jaromir
    Savelka, and Majd Sakr. 2024. Assessing the Efficacy of Goal-Based Scenarios in
    Scaling AI Literacy for Non-Technical Learners. In *Proceedings of the 55th ACM
    Technical Symposium on Computer Science Education V. 2*. 1842–1843.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tseng et al. (2024) Ying-Jui Tseng, Ruiwei Xiao, Christopher Bogart, Jaromir
    Savelka, 和 Majd Sakr. 2024. 评估基于目标的情境在扩大非技术性学习者AI素养中的有效性。载于*第55届ACM计算机科学教育技术研讨会论文集V.
    2*。1842–1843。
