- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 12:51:02'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 12:51:02
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Triad：一个利用多角色基于LLM的智能体解决知识库问答的框架
- en: 来源：[https://arxiv.org/html/2402.14320/](https://arxiv.org/html/2402.14320/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2402.14320/](https://arxiv.org/html/2402.14320/)
- en: Chang Zong¹, Yuchen Yan¹, Weiming Lu${{}^{1}}{{}^{\dagger}}$ , Jian Shao¹
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 宗常¹，严宇晨¹，陆伟名${{}^{1}}{{}^{\dagger}}$ ，邵建¹
- en: 'Yongfeng Huang², Heng Chang³, Yueting Zhuang${{}^{1}}{{}^{\dagger}}$ ¹¹footnotemark:
    1'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '黄永峰²，常恒³，庄悦婷${{}^{1}}{{}^{\dagger}}$ ¹¹footnotemark: 1'
- en: ¹College of Computer Science and Technology, Zhejiang University
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹浙江大学计算机科学与技术学院
- en: ²The Chinese University of Hong Kong
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²香港中文大学
- en: ³Tsinghua University
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³清华大学
- en: '{zongchang, luwm, yzhuang}@zju.edu.cn ^†Corresponding authors.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '{zongchang, luwm, yzhuang}@zju.edu.cn ^†通讯作者。'
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Recent progress with LLM-based agents has shown promising results across various
    tasks. However, their use in answering questions from knowledge bases remains
    largely unexplored. Implementing a KBQA system using traditional methods is challenging
    due to the shortage of task-specific training data and the complexity of creating
    task-focused model structures. In this paper, we present Triad, a unified framework
    that utilizes an LLM-based agent with multiple roles for KBQA tasks. The agent
    is assigned three roles to tackle different KBQA subtasks: agent as a generalist
    for mastering various subtasks, as a decision maker for the selection of candidates,
    and as an advisor for answering questions with knowledge. Our KBQA framework is
    executed in four phases, involving the collaboration of the agent’s multiple roles.
    We evaluated the performance of our framework using three benchmark datasets,
    and the results show that our framework outperforms state-of-the-art systems on
    the LC-QuAD and YAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的智能体最近在各种任务中取得了令人鼓舞的成果。然而，利用它们回答知识库中的问题仍然是一个未被充分探索的领域。由于任务特定训练数据的匮乏以及构建任务聚焦的模型结构的复杂性，采用传统方法实现KBQA系统具有挑战性。本文提出了Triad，一个统一的框架，利用具有多个角色的基于LLM的智能体来处理KBQA任务。该智能体被赋予三种角色，以应对不同的KBQA子任务：作为通才掌握各种子任务，作为决策者选择候选项，作为顾问用知识回答问题。我们的KBQA框架分为四个阶段，涉及智能体多个角色的协作。我们使用三个基准数据集评估了该框架的性能，结果显示我们的框架在LC-QuAD和YAGO-QA基准测试中分别取得了11.8%和20.7%的F1分数，优于现有的最先进系统。
- en: 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Triad：一个利用多角色基于LLM的智能体解决知识库问答的框架
- en: 'Chang Zong¹, Yuchen Yan¹, Weiming Lu${{}^{1}}{{}^{\dagger}}$ ^†^†thanks: ^†Corresponding
    authors., Jian Shao¹ Yongfeng Huang², Heng Chang³, Yueting Zhuang${{}^{1}}{{}^{\dagger}}$
    ¹¹footnotemark: 1 ¹College of Computer Science and Technology, Zhejiang University
    ²The Chinese University of Hong Kong ³Tsinghua University {zongchang, luwm, yzhuang}@zju.edu.cn'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '宗常¹，严宇晨¹，陆伟名${{}^{1}}{{}^{\dagger}}$ ^†^†thanks: ^†通讯作者。邵建¹ 黄永峰²，常恒³，庄悦婷${{}^{1}}{{}^{\dagger}}$
    ¹¹footnotemark: 1 ¹浙江大学计算机科学与技术学院 ²香港中文大学 ³清华大学 {zongchang, luwm, yzhuang}@zju.edu.cn'
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: A question-answering system is designed to extract information by converting
    a natural language question into a structured query that can retrieve precise
    information from an existing knowledge base Omar et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)).
    The resolution of Knowledge Base Question Answering (KBQA) typically involves
    phases including question understanding, URI linking, and query execution. Traditional
    KBQA systems require the use of specialized models trained with domain datasets
    for question parsing and entity linking Hu et al. ([2018](https://arxiv.org/html/2402.14320v6#bib.bib7));
    Omar et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)); Hu et al.
    ([2021](https://arxiv.org/html/2402.14320v6#bib.bib8)). Large language models
    (LLMs), however, have shown promising competencies in in-context learning using
    task-specific demonstrations Dong et al. ([2022](https://arxiv.org/html/2402.14320v6#bib.bib4)).
    LLMs have recently been employed as agents in the execution of complex problems.
    A framework that employs LLM-augmented agents can generate actions or coordinate
    multiple agents, thus improving the capacity to handle complex situations Liu
    et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib12)). Despite the remarkable
    performance of LLMs in various tasks as evidenced in previous studies, a comprehensive
    qualitative and quantitative evaluation of KBQA frameworks empowered with an LLM-based
    agent remains insufficiently explored.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 问答系统旨在通过将自然语言问题转换为结构化查询，从现有知识库中提取准确信息（Omar 等人，([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13))）。知识库问答（KBQA）的解决通常涉及多个阶段，包括问题理解、URI链接和查询执行。传统的KBQA系统需要使用专门的模型，这些模型通过领域数据集训练，用于问题解析和实体链接（Hu
    等人，([2018](https://arxiv.org/html/2402.14320v6#bib.bib7))）；Omar 等人，([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13))；Hu
    等人，([2021](https://arxiv.org/html/2402.14320v6#bib.bib8))。然而，大型语言模型（LLMs）在通过任务特定演示进行上下文学习方面显示出了有前景的能力（Dong
    等人，([2022](https://arxiv.org/html/2402.14320v6#bib.bib4))）。近年来，LLMs已被用作执行复杂问题的代理。使用LLM增强代理的框架可以生成行动或协调多个代理，从而提高处理复杂情况的能力（Liu
    等人，([2023](https://arxiv.org/html/2402.14320v6#bib.bib12))）。尽管LLMs在各类任务中表现出色，正如以往的研究所表明的那样，但基于LLM的代理赋能的KBQA框架的综合定性和定量评估仍然缺乏深入探索。
- en: '![Refer to caption](img/6df670956e63f0ca17ea4861412f27f6.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/6df670956e63f0ca17ea4861412f27f6.png)'
- en: 'Figure 1: A system with multiple roles who focus on sub-problems of each phase
    to solve a complex task.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：一个拥有多个角色的系统，专注于每个阶段的子问题以解决复杂任务。
- en: 'Studies on KBQA with LLMs has attracted considerable attention. Some works
    focus primarily on highlighting the inability of LLMs to generate complete factoid
    results Hu et al. ([2023b](https://arxiv.org/html/2402.14320v6#bib.bib6)); Tan
    et al. ([2023c](https://arxiv.org/html/2402.14320v6#bib.bib22)) or demonstrating
    their potential efficacy in future research Omar et al. ([2023b](https://arxiv.org/html/2402.14320v6#bib.bib14));
    Tan et al. ([2023b](https://arxiv.org/html/2402.14320v6#bib.bib21)). Other works
    concentrates on generating answers by prompt learning and incorporating external
    knowledge bases Baek et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib2));
    Tan et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib20)). Concurrently,
    LLMs can be deployed to address each phase within Text2SQL challengesLi et al.
    ([2023](https://arxiv.org/html/2402.14320v6#bib.bib10), [2024](https://arxiv.org/html/2402.14320v6#bib.bib11))
    or theorem proof tasksDong et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib3)).
    However, each phase of KBQA can be further decomposed into subtasks and completed
    through an agentic approach that provides feedback and cooperation. Additionally,
    decomposing the task reduces the complexity of cooperative working by allowing
    each role to concentrate on smaller sub-problemsWang et al. ([2020](https://arxiv.org/html/2402.14320v6#bib.bib27)).
    As illustrated in Figure [1](https://arxiv.org/html/2402.14320v6#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent
    to Solve Knowledge Base Question Answering"), three roles in an organization work
    together to provide the final answer for the overall task. The above observations
    spur our exploration into the following question: How does an LLM-based agent
    solve KBQA tasks by serving as multiple roles, and its performance is comparable
    to systems trained specifically?'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 基于大语言模型（LLMs）的知识库问答（KBQA）研究已引起了广泛关注。一些研究主要集中在突出大语言模型无法生成完整事实性结果的问题，胡等人（[2023b](https://arxiv.org/html/2402.14320v6#bib.bib6)）；谭等人（[2023c](https://arxiv.org/html/2402.14320v6#bib.bib22)）或展示它们在未来研究中的潜在效能，奥马尔等人（[2023b](https://arxiv.org/html/2402.14320v6#bib.bib14)）；谭等人（[2023b](https://arxiv.org/html/2402.14320v6#bib.bib21)）。其他研究则集中于通过提示学习生成答案并结合外部知识库，贝克等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib2)）；谭等人（[2023a](https://arxiv.org/html/2402.14320v6#bib.bib20)）。与此同时，大语言模型可以部署于解决Text2SQL挑战中的每个阶段，李等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib10)，[2024](https://arxiv.org/html/2402.14320v6#bib.bib11)）或定理证明任务，董等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib3)）。然而，KBQA的每个阶段都可以进一步细分为子任务，并通过一种提供反馈和协作的代理方法来完成。此外，任务的分解通过允许每个角色集中处理较小的子问题，从而降低了合作工作的复杂性，王等人（[2020](https://arxiv.org/html/2402.14320v6#bib.bib27)）。如图[1](https://arxiv.org/html/2402.14320v6#S1.F1
    "图 1 ‣ 1 引言 ‣ Triad：一个利用多角色基于LLM的代理解决知识库问答问题的框架")所示，组织中的三个角色共同合作，为整体任务提供最终答案。以上观察促使我们探讨以下问题：基于LLM的代理如何通过充当多个角色来解决KBQA任务，并且其表现与专门训练的系统相当？
- en: 'In this study, we introduce Triad, a unified framework that leverages an LLM-based
    agent with three roles to address KBQA tasks. Specifically, we implement the agent
    consisting of an LLM as the core, supplemented by various task-specific modules
    such as memory and executing functions. The agent is assigned three distinct roles:
    a generalist (G-Agent) adept at mastering numerous small tasks by the given examples,
    a decision maker (D-Agent) proficient at identifying options and selecting candidates,
    and an advisor (A-Agent) skilled at providing answers using internal and external
    knowledge. The cooperation of these agent roles composes a KBQA process containing
    four phases: question parsing, URI linking, query construction, and answer generation.
    We evaluate our framework on three benchmark datasets in various difficulties.
    The results show that our framework outperforms state-of-the-art systems, demonstrated
    by 11.8% and 20.7% F1 scores on the LC-QuAD and YAGO-QA benchmarks, respectively¹¹1Code
    and data are available at [https://github.com/ZJU-DCDLab/Triad](https://github.com/ZJU-DCDLab/Triad)..'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们介绍了Triad，这是一个统一的框架，利用基于LLM的代理，通过三种角色来解决KBQA任务。具体而言，我们实现了由LLM作为核心的代理，并补充了各种特定任务的模块，如记忆和执行功能。该代理被分配了三种不同的角色：通才（G-Agent），擅长通过给定的示例掌握许多小任务；决策者（D-Agent），擅长识别选项并选择候选者；以及顾问（A-Agent），擅长利用内部和外部知识提供答案。这些代理角色的合作构成了KBQA过程，包含四个阶段：问题解析、URI链接、查询构建和答案生成。我们在三个具有不同难度的基准数据集上评估了我们的框架。结果表明，我们的框架在性能上优于最先进的系统，在LC-QuAD和YAGO-QA基准测试中分别达到了11.8%和20.7%的F1得分¹¹1代码和数据可以在[https://github.com/ZJU-DCDLab/Triad](https://github.com/ZJU-DCDLab/Triad)获取。
- en: 'The contributions of this study can be summarized as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的贡献可以总结如下：
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose Triad, the first framework that leverages an LLM-based agent to solve
    KBQA tasks in all its four phases, without specialized training models.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了Triad，这是第一个利用基于LLM的代理来解决KBQA任务四个阶段的框架，无需专门的训练模型。
- en: •
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We implement an LLM-based agent with various task-specific modules that can
    act as three roles, including a generalist, a decision maker, and an advisor,
    to collaboratively solve KBQA via focusing on subtasks.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们实现了一个基于LLM的代理，配有各种特定任务的模块，可以充当三个角色，包括通才、决策者和顾问，通过聚焦于子任务共同解决KBQA问题。
- en: •
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We evaluate the performance of Triad. The results show a competitive ability
    compared to both state-of-the-art KBQA systems and pure LLM methods.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们评估了Triad的性能。结果表明，与最先进的KBQA系统和纯LLM方法相比，Triad展现了竞争力。
- en: 2 Preliminaries
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 基础
- en: 2.1 Phases of KBQA
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 KBQA的阶段
- en: 'A typical KBQA system has a process that encompasses four phases:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的KBQA系统包含一个涵盖四个阶段的过程：
- en: Question parsing
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 问题解析
- en: involves converting natural language questions into a structured format that
    incorporates references to entities and relations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 包括将自然语言问题转换为包含实体和关系引用的结构化格式。
- en: URI linking
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: URI链接
- en: entails associating and replacing these entity and relation mentions with their
    corresponding URIs within a knowledge base.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 包括将这些实体和关系提及与知识库中对应的URI进行关联和替换。
- en: Query construction
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查询构建
- en: involves creating executable queries in a standard format to extract answers
    from knowledge bases.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 包括以标准格式创建可执行查询，从知识库中提取答案。
- en: Answer generation
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 答案生成
- en: seeks to obtain the ultimate answers either by performing queries within knowledge
    bases or by directly querying an agent.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在通过在知识库中执行查询或直接查询代理来获得最终答案。
- en: 2.2 Roles of LLM-based Agent
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于LLM的代理角色
- en: 'Drawing an analogy to a software development scenario, where coders complete
    small development tasks, with the process and plan being decided by the manager,
    and ultimately the outcome inspected by the leader, we assign the following three
    roles to an LLM-based agent to solve the KBQA task:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 类比于软件开发场景，其中程序员完成小的开发任务，过程和计划由经理决定，最终结果由领导检查，我们将以下三个角色分配给基于LLM的代理，以解决KBQA任务：
- en: Agent as a generalist
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理作为通才
- en: (G-Agent) is capable of mastering various small tasks by providing a few examples.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: （G-Agent）能够通过提供少量示例掌握各种小任务。
- en: Agent as a decision-maker
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理作为决策者
- en: (D-Agent) adepts at analyzing options and providing candidate results as procedural
    feedback.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: （D-Agent）擅长分析选项并提供候选结果作为过程反馈。
- en: Agent as an advisor
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代理作为顾问
- en: (A-Agent) is skilled in providing final answers with the aid of both external
    and its own knowledge.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: （A-Agent）擅长在外部知识和自身知识的帮助下提供最终答案。
- en: 2.3 Task Formulation
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 任务表述
- en: 'A KBQA task refers to the process of solving a set of subtasks $S$. Each subtask
    $S_{t}\in S$ contributes to one phase of the whole process. An LLM-based agent
    $Agent_{r}$ with a role $r$ can be used to resolve a type of subtasks by its task-specific
    components, including a language model $LLM$, a memory $Mem_{t}$, a function $F_{t}$,
    a prompt $Pmt_{t}$ and a set of parameters $\theta_{t}$, using the set of role-related
    hyperparameters $\sigma_{r}$. The task can be formulated as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: KBQA任务指的是解决一组子任务$S$的过程。每个子任务$S_{t}\in S$有助于整个过程的一个阶段。一个基于LLM的智能体$Agent_{r}$，具有角色$r$，可以通过其任务特定的组件来解决一种类型的子任务，这些组件包括语言模型$LLM$、记忆$Mem_{t}$、功能$F_{t}$、提示$Pmt_{t}$以及一组参数$\theta_{t}$，并使用与角色相关的超参数$\sigma_{r}$。任务可以表述如下：
- en: '|  |  | $\displaystyle f(KBQA)=\mathop{\bigoplus}\limits_{t=1}^{T}f(S_{t})$
    |  | (1) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle f(KBQA)=\mathop{\bigoplus}\limits_{t=1}^{T}f(S_{t})$
    |  | (1) |'
- en: '|  | $\displaystyle f(S_{t})=$ | $\displaystyle Agent_{r}(LLM,Mem_{t},F_{t},Pmt_{t},\theta_{t},\sigma_{r})$
    |  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{t})=$ | $\displaystyle Agent_{r}(LLM,Mem_{t},F_{t},Pmt_{t},\theta_{t},\sigma_{r})$
    |  |'
- en: ', where $T$ is the total number of subtasks, $\bigoplus$ is the way to coordinate
    subtasks to solve the whole.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中$T$是子任务的总数，$\bigoplus$是协调子任务以解决整体任务的方式。
- en: 3 Triad Framework
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 三元框架
- en: 'The overall architecture of Triad is shown in Figure [2](https://arxiv.org/html/2402.14320v6#S3.F2
    "Figure 2 ‣ 3 Triad Framework ‣ Triad: A Framework Leveraging a Multi-Role LLM-based
    Agent to Solve Knowledge Base Question Answering"). Each role of the LLM-based
    agent, along with its associated subtasks, is illustrated as follows.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 'Triad的总体架构如图[2](https://arxiv.org/html/2402.14320v6#S3.F2 "Figure 2 ‣ 3 Triad
    Framework ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve
    Knowledge Base Question Answering")所示。每个基于LLM的智能体角色及其相关子任务如下所示。'
- en: '![Refer to caption](img/6f80a4054f365aa928fbfedc9e59d7ed.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/6f80a4054f365aa928fbfedc9e59d7ed.png)'
- en: 'Figure 2: Our Triad framework leverages an LLM-based agent with three different
    roles including a generalist, a decision-maker, and an advisor to cooperatively
    handle a series of subtasks in the four phases of a KBQA process.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：我们的三元框架利用基于LLM的智能体，智能体在三个不同角色下协作处理KBQA过程的四个阶段中的一系列子任务，这些角色包括通才、决策者和顾问。
- en: 3.1 G-Agent as a Generalized Solver
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 G-Agent作为通用求解器
- en: 'A generalized agent (G-Agent) proficiently manages numerous tasks by leveraging
    learning from limited examples through an LLM. In our framework, a G-Agent can
    perform question parsing, query template generation, or answer type classification
    as actions solely utilizing an LLM. These three subtasks are illustrated as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一个通用智能体（G-Agent）通过利用从有限示例中学习，使用LLM高效地管理众多任务。在我们的框架中，G-Agent可以仅利用LLM执行问题解析、查询模板生成或答案类型分类等操作。这三个子任务如下所示：
- en: 'Triplet mention extraction:'
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 三元组提取：
- en: 'The process of extracting triplet mentions in question parsing involves the
    conversion of a naturally phrased question, denoted as $Q$, into formatted triplets
    of entities and relations. This subtask is executed employing an LLM, which is
    guided by a prompt with a set of prerequisites and a selection of examples. This
    subtask can be represented as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在问题解析中提取三元组时，涉及将自然语言表达的问题$Q$转化为格式化的实体和关系三元组。这个子任务通过LLM来执行，并由带有一组先决条件和示例选择的提示来引导。这个子任务可以表示如下：
- en: '|  | $\displaystyle f(S_{tri})=$ | $\displaystyle Agent_{g}(LLM,Pmt_{tri},Q,\mathcal{N})$
    |  | (2) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{tri})=$ | $\displaystyle Agent_{g}(LLM,Pmt_{tri},Q,\mathcal{N})$
    |  | (2) |'
- en: '|  | $\displaystyle Pmt_{tri}=$ | $\displaystyle\left[Ins_{tri},Shot_{tri},CoT_{tri}\right]$
    |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Pmt_{tri}=$ | $\displaystyle\left[Ins_{tri},Shot_{tri},CoT_{tri}\right]$
    |  |'
- en: ', where $Agent_{g}$ is the agent as a generalist to perform the triplet extraction
    subtask with $\mathcal{N}$ examples. $Pmt_{tri}$ is the prompt to guide $LLM$
    to generate triplets from the question $Q$, which consists of instruction $Ins_{tri}$,
    examples $Shot_{tri}$, and chain-of-thought prompt $CoT_{tri}$ Kojima et al. ([2022](https://arxiv.org/html/2402.14320v6#bib.bib9)).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中$Agent_{g}$是作为通才的智能体，用于执行三元组提取子任务，使用$\mathcal{N}$个示例。$Pmt_{tri}$是引导$LLM$从问题$Q$生成三元组的提示，其中包括指令$Ins_{tri}$、示例$Shot_{tri}$和链式思维提示$CoT_{tri}$（Kojima等人，[2022](https://arxiv.org/html/2402.14320v6#bib.bib9)）。
- en: 'SPARQL template generation:'
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SPARQL模板生成：
- en: 'The generation of SPARQL templates in query construction involves the use of
    an LLM to create a SPARQL template that articulates the question using standard
    SPARQL syntax, replacing URI identifiers with entity and relation variables. To
    derive precise and comprehensive answers from the knowledge base using SPARQL
    queries, there are two potential strategies. One approach involves the direct
    generation of an executable SPARQL using an LLM, though this method may significantly
    increase LLM call times and error rates when numerous candidate queries are in
    play. Alternatively, a SPARQL template can initially be generated with entity
    and relation variables, which are subsequently replaced with linked URIs. For
    the sake of stability and efficiency, we opt for the second strategy. This subtask
    can be denoted as:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询构建中生成 SPARQL 模板涉及使用 LLM 创建一个 SPARQL 模板，该模板通过标准的 SPARQL 语法表达问题，将 URI 标识符替换为实体和关系变量。为了从知识库中使用
    SPARQL 查询得出精确和全面的答案，有两种潜在策略。一个方法是直接生成可执行的 SPARQL 查询，通过 LLM 来实现，尽管在多个候选查询的情况下，这种方法可能会显著增加
    LLM 调用时间和错误率。另一种方法是首先生成包含实体和关系变量的 SPARQL 模板，随后将这些变量替换为连接的 URI。为了稳定性和效率，我们选择了第二种策略。这个子任务可以表示为：
- en: '|  | $\displaystyle f(S_{qt})=$ | $\displaystyle Agent_{g}(LLM,Pmt_{qt},\theta_{qt},\mathcal{N}),$
    |  | (3) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{qt})=$ | $\displaystyle Agent_{g}(LLM,Pmt_{qt},\theta_{qt},\mathcal{N}),$
    |  | (3) |'
- en: '|  | $\displaystyle Pmt_{qt}=$ | $\displaystyle\left[Ins_{qt},Shot_{qt},CoT_{qt}\right],$
    |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Pmt_{qt}=$ | $\displaystyle\left[Ins_{qt},Shot_{qt},CoT_{qt}\right],$
    |  |'
- en: '|  | $\displaystyle\theta_{qt}=$ | $\displaystyle\left[Q,f(S_{tri})\right]$
    |  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\theta_{qt}=$ | $\displaystyle\left[Q,f(S_{tri})\right]$
    |  |'
- en: ', where $Agent_{g}$ is the agent as generalist to perform SPARQL template generation
    with $\mathcal{N}$ examples, $f(S_{tri})$ is the triplets derived from the previous
    subtask, $Pmt_{qt}$ is the prompt for $LLM$ to generate SPARQL template.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $Agent_{g}$ 是作为通才的智能体，通过 $\mathcal{N}$ 个示例执行 SPARQL 模板生成，$f(S_{tri})$ 是从前一个子任务中得出的三元组，$Pmt_{qt}$
    是用于生成 SPARQL 模板的 $LLM$ 提示。
- en: 'Answer type classification:'
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 答案类型分类：
- en: 'In the phase of answer generation, the answer type classification subtask refers
    to the process of assigning a specific category to a response according to the
    question. This process serves as a guiding mechanism for the framework to generate
    comprehensive and accurate answers. This classification subtask is denoted as:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在答案生成阶段，答案类型分类子任务指的是根据问题为回答分配特定类别的过程。这个过程作为框架生成全面和准确答案的指导机制。这个分类子任务表示为：
- en: '|  | $\displaystyle f(S_{cls})=$ | $\displaystyle Agent_{g}(LLM,Pmt_{cls},Q,\mathcal{N}),$
    |  | (4) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{cls})=$ | $\displaystyle Agent_{g}(LLM,Pmt_{cls},Q,\mathcal{N}),$
    |  | (4) |'
- en: '|  | $\displaystyle Pmt_{cls}=$ | $\displaystyle\left[Ins_{cls},Shot_{cls},CoT_{cls}\right]$
    |  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Pmt_{cls}=$ | $\displaystyle\left[Ins_{cls},Shot_{cls},CoT_{cls}\right]$
    |  |'
- en: ', where $Agent_{g}$ is the agent as a generalist to perform type classification
    subtask with $\mathcal{N}$ examples, $Pmt_{cls}$ is the prompt for $LLM$.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $Agent_{g}$ 是作为通才的智能体，通过 $\mathcal{N}$ 个示例执行类型分类子任务，$Pmt_{cls}$ 是用于 $LLM$
    的提示。
- en: 3.2 D-Agent as a Decision-Maker
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 D-Agent 作为决策者
- en: 'An agent as a decision maker (D-Agent) is capable of making candidate selections
    step by step through filtering and choosing from given options, harnessing the
    capabilities of an LLM and KB as memory. The D-Agent can effectively handle three
    subtasks, which are delineated as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 作为决策者的智能体（D-Agent）能够通过过滤和从给定选项中选择，逐步做出候选选择，利用 LLM 和知识库（KB）作为记忆。D-Agent 可以有效处理以下三个子任务，具体描述如下：
- en: 'Candidate entity selection:'
  id: totrans-77
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 候选实体选择：
- en: 'The selection of candidate entities in URI linking is pivotal to the ultimate
    efficacy of KBQA. Prior research has focused primarily on developing a semantic
    similarity model to address this linking challenge. However, the linking task
    requires numerous iterations of searching within the knowledge base, which poses
    a compatibility issue for LLM-oriented methods. In our framework, an agent as
    a decision maker is utilized initially to filter all potential entity URIs from
    the knowledge base, subsequently deploying an LLM to select candidate URIs from
    a pool of potential identifiers. For each entity, our aim is to find the $\mathcal{K}$
    most possible entity URIs which can be used to traverse over the KB to get the
    final answer. The entity selection subtask can be denoted as:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: URI 链接中的候选实体选择对知识库问答（KBQA）的最终效果至关重要。先前的研究主要集中在开发语义相似性模型，以解决这一链接挑战。然而，链接任务需要在知识库中进行多次迭代搜索，这对面向
    LLM 的方法提出了兼容性问题。在我们的框架中，首先使用作为决策者的智能体从知识库中过滤所有潜在的实体 URI，随后使用 LLM 从潜在标识符池中选择候选
    URI。对于每个实体，我们的目标是找到 $\mathcal{K}$ 个最可能的实体 URI，这些 URI 可以用来遍历知识库并得到最终答案。实体选择子任务可以表示为：
- en: '|  | $\displaystyle f(S_{es})=$ | $\displaystyle Agent_{d}(LLM,Mem_{es},F_{es},$
    |  | (5) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{es})=$ | $\displaystyle Agent_{d}(LLM,Mem_{es},F_{es},$
    |  | (5) |'
- en: '|  |  | $\displaystyle Pmt_{es},\theta_{es},\mathcal{K}),$ |  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{es},\theta_{es},\mathcal{K}),$ |  |'
- en: '|  | $\displaystyle Mem_{es}=$ | $\displaystyle\left[KB,List_{es}\right],\theta_{es}=\left[Q,f(S_{tri})\right]$
    |  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{es}=$ | $\displaystyle\left[KB,List_{es}\right],\theta_{es}=\left[Q,f(S_{tri})\right]$
    |  |'
- en: ', where $Agent_{d}$ is the agent as a decision maker to perform the entity
    selection subtask with question $Q$, extracted triplets $f(S_{tri})$ and memory
    $Mem_{es}$, $Mem_{es}$ is composed of a knowledge base $KB$ and a list of entity
    URIs $List_{es}$ filtered from $KB$ using a text similarity matching function
    $F_{es}$, $Pmt_{es}$ is the prompt for LLM to perform the subtask, $\mathcal{K}$
    is the hyperparameter of $Agent_{d}$, indicating the number of candidates selected
    by $LLM$.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中 $Agent_{d}$ 是作为决策者的智能体，通过问题 $Q$、提取的三元组 $f(S_{tri})$ 和内存 $Mem_{es}$ 执行实体选择子任务。$Mem_{es}$
    由知识库 $KB$ 和一个通过文本相似性匹配函数 $F_{es}$ 从 $KB$ 过滤出的实体 URI 列表 $List_{es}$ 组成，$Pmt_{es}$
    是 LLM 执行子任务的提示词，$\mathcal{K}$ 是 $Agent_{d}$ 的超参数，表示 LLM 选择的候选数目。
- en: 'Candidate relation selection:'
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 候选关系选择：
- en: 'The task of candidate relation selection in URI linking presents considerable
    challenges due to the discrepancies between word forms and meanings. Nevertheless,
    the existence of reasoning paths in the knowledge base can be utilized to allow
    for a significant reduction of the search space in relation linking. In our framework,
    an agent as a decision maker endeavors to sieve through all potential relation
    URIs by navigating the knowledge base with candidate entity URIs generated from
    the previous subtask. Subsequently, an LLM is used to select the top $\mathcal{K}$
    most probable relation URIs for output. The relation selection subtask can be
    denoted as:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在 URI 链接中，候选关系选择的任务面临着由于词形和意义之间的差异而带来的相当大的挑战。然而，知识库中推理路径的存在可以被利用，从而显著缩小与关系链接相关的搜索空间。在我们的框架中，作为决策者的智能体努力通过使用从前一个子任务中生成的候选实体
    URI，在知识库中筛选所有潜在的关系 URI。随后，使用 LLM 选择最有可能的 $\mathcal{K}$ 个关系 URI 作为输出。关系选择子任务可以表示为：
- en: '|  | $\displaystyle f(S_{rs})=$ | $\displaystyle Agent_{d}(LLM,Mem_{rs},F_{rs},$
    |  | (6) |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{rs})=$ | $\displaystyle Agent_{d}(LLM,Mem_{rs},F_{rs},$
    |  | (6) |'
- en: '|  |  | $\displaystyle Pmt_{rs},\theta_{rs},\mathcal{K}),$ |  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{rs},\theta_{rs},\mathcal{K}),$ |  |'
- en: '|  | $\displaystyle Mem_{rs}=$ | $\displaystyle\left[KB,List_{rs}\right],\theta_{rs}=\left[Q,f(S_{es})\right]$
    |  |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{rs}=$ | $\displaystyle\left[KB,List_{rs}\right],\theta_{rs}=\left[Q,f(S_{es})\right]$
    |  |'
- en: ', where memory $Mem_{rs}$ is composed of the knowledge base $KB$ and a list
    of possible relation URIs $List_{rs}$ filtered from $KB$ using a one-order traversing
    function $F_{rs}$. $Pmt_{rs}$ is the prompt for LLM to perform relation selection.
    $\mathcal{K}$ is the number of relation URIs selected by LLM.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中内存 $Mem_{rs}$ 由知识库 $KB$ 和一个从 $KB$ 使用一阶遍历函数 $F_{rs}$ 过滤出来的潜在关系 URI 列表 $List_{rs}$
    组成。$Pmt_{rs}$ 是 LLM 执行关系选择的提示词。$\mathcal{K}$ 是 LLM 选择的关系 URI 数量。
- en: 'Candidate SPARQL selection:'
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 候选 SPARQL 选择：
- en: 'The subtask of candidate SPARQL selection in query construction involves determining
    the appropriate SPARQL queries to obtain the final answers. Given a SPARQL template
    generated by the G-Agent, along with multiple candidate URIs selected from the
    D-Agent in previous subtasks, our D-Agent is targeted to identify the most plausible
    query. To further reduce the difficulty of selection, an executor function is
    applied to eliminate queries that cannot retrieve any results from the knowledge
    base. In conclusion, our aim in this subtask is to use D-Agent to construct executable
    SPARQLs and find the most possible one given a query candidate list with supported
    information. The SPARQL selection subtask can be denoted as:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 查询构建中的候选SPARQL选择子任务涉及确定适当的SPARQL查询以获得最终答案。给定一个由G-Agent生成的SPARQL模板，以及在前面的子任务中由D-Agent选择的多个候选URI，我们的D-Agent旨在识别最有可能的查询。为了进一步减少选择的难度，应用执行函数来排除那些无法从知识库中检索到任何结果的查询。总之，我们在此子任务中的目标是使用D-Agent构建可执行的SPARQL，并在给定包含支持信息的查询候选列表的情况下，找到最可能的查询。SPARQL选择子任务可以表示为：
- en: '|  | $\displaystyle f(S_{qs})=$ | $\displaystyle Agent_{d}(LLM,Mem_{qs},F_{qs},$
    |  | (7) |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{qs})=$ | $\displaystyle Agent_{d}(LLM,Mem_{qs},F_{qs},$
    |  | (7) |'
- en: '|  |  | $\displaystyle Pmt_{qs},\theta_{qs},\mathcal{K}),$ |  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{qs},\theta_{qs},\mathcal{K}),$ |  |'
- en: '|  | $\displaystyle Mem_{qs}=$ | $\displaystyle\left[KB,List_{qs}\right],$
    |  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{qs}=$ | $\displaystyle\left[KB,List_{qs}\right],$
    |  |'
- en: '|  | $\displaystyle\theta_{qs}=$ | $\displaystyle\left[Q,f(S_{es}),f(S_{rs}),f(S_{qt})\right]$
    |  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\theta_{qs}=$ | $\displaystyle\left[Q,f(S_{es}),f(S_{rs}),f(S_{qt})\right]$
    |  |'
- en: ', where memory $Mem_{qs}$ is composed of a knowledge base $KB$ and a list of
    possible SPARQLs $List_{qs}$ constructed with SPARQL template $f(S_{qt})$, entity
    URIs $f(S_{es})$, and relation URIs $f(S_{rs})$ by the function $F_{qs}$, $Pmt_{qs}$
    is the prompt for LLM to perform query selection, $\mathcal{K}=1$ is the number
    of queries selected by LLM.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ，其中记忆$Mem_{qs}$由知识库$KB$和由SPARQL模板$f(S_{qt})$、实体URI$f(S_{es})$、关系URI$f(S_{rs})$通过函数$F_{qs}$构建的可能SPARQL列表$List_{qs}$组成，$Pmt_{qs}$是LLM执行查询选择的提示，$\mathcal{K}=1$是LLM选择的查询数量。
- en: 3.3 A-Agent as a Comprehensive Advisor
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 A-Agent作为综合顾问
- en: 'An advisory agent (A-Agent) is capable of processing a question and a corresponding
    type of answer as input. Its response is generated by either extracting information
    from an external knowledge base or by utilizing its internal knowledge to provide
    a direct answer. This comprehensive answering subtask can be described as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 咨询代理（A-Agent）能够处理一个问题和相应类型的回答作为输入。它的响应是通过从外部知识库中提取信息或利用其内部知识提供直接答案来生成的。这个综合回答子任务可以描述如下：
- en: 'Comprehensive answering:'
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 综合回答：
- en: 'The objective of comprehensive answering in the answer generation phase is
    to derive a definitive response based on an incoming question. Previous work Omar
    et al. ([2023b](https://arxiv.org/html/2402.14320v6#bib.bib14)) has demonstrated
    that LLMs are more proficient in delivering single-fact responses and making Boolean
    judgments. Given this understanding, we implement an advisory agent that incorporates
    a simple policy to facilitate a comprehensive answering approach. Specifically,
    if a question yields a final SPARQL generated from the preceding steps, A-Agent
    extracts elements from the knowledge base to give the answer. Conversely, if the
    agent does not receive a feasible SPARQL, A-Agent provides a direct response with
    LLM’s internal knowledge, following the prompt based on the type of the answer.
    Additionally, A-Agent will send a retry signal to previous phases if no result
    is generated. The subtask can be formulated as below:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 综合回答阶段的目标是基于提问生成一个明确的回答。Omar等人（[2023b](https://arxiv.org/html/2402.14320v6#bib.bib14)）的研究表明，LLM在提供单一事实回答和做出布尔判断方面更为擅长。基于这一理解，我们实现了一个咨询代理（A-Agent），它采用一种简单的策略来促进综合回答方法的实施。具体来说，如果问题生成了一个最终的SPARQL查询（由前面的步骤生成），A-Agent会从知识库中提取元素来给出答案。相反，如果代理未收到可行的SPARQL，A-Agent会基于答案类型，利用LLM的内部知识提供直接响应。此外，如果未生成结果，A-Agent会向前面的阶段发送重试信号。这个子任务可以表示如下：
- en: '|  | $\displaystyle f(S_{ca})=$ | $\displaystyle Agent_{a}(LLM,Mem_{ca},F_{ca},$
    |  | (8) |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle f(S_{ca})=$ | $\displaystyle Agent_{a}(LLM,Mem_{ca},F_{ca},$
    |  | (8) |'
- en: '|  |  | $\displaystyle Pmt_{ca},\theta_{ca},\mathcal{T}),$ |  |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle Pmt_{ca},\theta_{ca},\mathcal{T}),$ |  |'
- en: '|  | $\displaystyle Mem_{ca}=$ | $\displaystyle\left[KB\right],\theta_{ca}=\left[Q,f(S_{qs}),f(S_{cls})\right]$
    |  |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle Mem_{ca}=$ | $\displaystyle\left[KB\right],\theta_{ca}=\left[Q,f(S_{qs}),f(S_{cls})\right]$
    |  |'
- en: ', where $Agent_{a}$ is the agent as an advisor to perform a comprehensive answering
    for the question $Q$ with a memory $Mem_{ca}$ of knowledge base, $Pmt_{ca}$ is
    the prompt for LLM to perform a direct response according to the type of the answer,
    $f(S_{qs})$ is the final query and $f(S_{cls})$ is the answer type, $\mathcal{T}$
    is the maximum times to retry for previous phases if no result is returned from
    $KB$.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ', 其中 $Agent_{a}$ 是作为顾问的代理，负责为问题 $Q$ 提供全面的回答，并拥有知识库的记忆 $Mem_{ca}$，$Pmt_{ca}$
    是 LLM 根据答案类型执行直接响应的提示，$f(S_{qs})$ 是最终查询，$f(S_{cls})$ 是答案类型，$\mathcal{T}$ 是当 $KB$
    未返回结果时，之前阶段最大重试次数。'
- en: 4 Performance Evaluation
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 性能评估
- en: 4.1 Experimental Settings
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 实验设置
- en: 'Indexed Knowledge Bases:'
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 索引的知识库：
- en: The efficacy of our framework is assessed through the collection of two real
    knowledge bases, specifically DBpedia and YAGO. DBpedia Auer et al. ([2007](https://arxiv.org/html/2402.14320v6#bib.bib1))
    serves as an accessible knowledge base extracted from Wikipedia, while YAGO Pellissier Tanon
    et al. ([2020](https://arxiv.org/html/2402.14320v6#bib.bib16)) is a large knowledge
    base that includes individuals, cities, nations, and organizations. We index the
    triples and the mentions of entities and relations in a Virtuoso endpoint and
    an Elasticsearch server, respectively.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过收集两个真实的知识库来评估我们框架的效能，分别是 DBpedia 和 YAGO。DBpedia Auer 等人（[2007](https://arxiv.org/html/2402.14320v6#bib.bib1)）是一个从
    Wikipedia 中提取的可访问知识库，而 YAGO Pellissier Tanon 等人（[2020](https://arxiv.org/html/2402.14320v6#bib.bib16)）是一个大型知识库，包含个人、城市、国家和组织。我们在
    Virtuoso 端点和 Elasticsearch 服务器中分别索引了三元组以及实体和关系的提及。
- en: 'KBQA Benchmark Datasets:'
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: KBQA 基准数据集：
- en: 'We evaluate our framework on datasets including YAGO-QA, LC-QuAD 1.0, and QALD-9,
    which have various difficulties in interpreting the questions. These datasets
    contain questions in English, paired with their respective SPARQL queries, and
    accurate responses derived from a specific knowledge base. QALD-9 Usbeck et al.
    ([2018](https://arxiv.org/html/2402.14320v6#bib.bib25)) and LC-QuAD 1.0 Trivedi
    et al. ([2017](https://arxiv.org/html/2402.14320v6#bib.bib24)) are frequently
    used to evaluate QA systems with DBpedia. The recently published YAGO-QA in Omar
    et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)), features questions
    accompanied by annotated SPARQL queries sourced from YAGO. The statistics for
    three benchmarks, along with their associated knowledge bases, are depicted in
    Table [1](https://arxiv.org/html/2402.14320v6#S4.T1 "Table 1 ‣ KBQA Benchmark
    Datasets: ‣ 4.1 Experimental Settings ‣ 4 Performance Evaluation ‣ Triad: A Framework
    Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering").'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在多个数据集上评估了我们的框架，包括 YAGO-QA、LC-QuAD 1.0 和 QALD-9，这些数据集在解读问题时具有不同的难度。这些数据集包含英语问题，配有相应的
    SPARQL 查询和从特定知识库中获取的准确回答。QALD-9 Usbeck 等人（[2018](https://arxiv.org/html/2402.14320v6#bib.bib25)）和
    LC-QuAD 1.0 Trivedi 等人（[2017](https://arxiv.org/html/2402.14320v6#bib.bib24)）常用于评估与
    DBpedia 相关的问答系统。最近发布的 YAGO-QA，Omar 等人（[2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)）提供了附带注释的
    SPARQL 查询问题，源自 YAGO。表 [1](https://arxiv.org/html/2402.14320v6#S4.T1 "表 1 ‣ KBQA
    基准数据集: ‣ 4.1 实验设置 ‣ 4 性能评估 ‣ Triad：一个利用多角色基于 LLM 的代理解决知识库问答的框架") 展示了三个基准的统计信息及其相关的知识库。'
- en: '| Benchmarks | Benchmark Statistics |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 基准 | 基准统计信息 |'
- en: '| #Questions | KB | #Triples | Virtuoso Size | ES size |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| #问题 | 知识库 | #三元组 | Virtuoso 大小 | ES 大小 |'
- en: '| LC-QuAD 1.0 | 1000 | DBpedia-04 | 397M | 35.40G | 1.56G |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| LC-QuAD 1.0 | 1000 | DBpedia-04 | 397M | 35.40G | 1.56G |'
- en: '| QALD-9 | 150 | DBpedia-10 | 374M | 36.89G | 1.57G |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| QALD-9 | 150 | DBpedia-10 | 374M | 36.89G | 1.57G |'
- en: '| YAGO-QA | 100 | YAGO-4 | 207M | 24.85G | 0.54G |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| YAGO-QA | 100 | YAGO-4 | 207M | 24.85G | 0.54G |'
- en: 'Table 1: The statistics of KBQA benchmarks, including the number of questions
    number, the number of triples, the size of index in Virtuoso and Elasticsearch.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：KBQA 基准的统计信息，包括问题数量、三元组数量、Virtuoso 中的索引大小以及 Elasticsearch 中的索引大小。
- en: '| Type | Frameworks | LC-QuAD 1.0 | QALD-9 | YAGO-QA |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 框架 | LC-QuAD 1.0 | QALD-9 | YAGO-QA |'
- en: '| P | R | F1 | P | R | F1 | P | R | F1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| P | R | F1 | P | R | F1 | P | R | F1 |'
- en: '| full-shot | gAnswer | - | - | - | 0.293 | 0.327 | 0.298 | 0.585 | 0.341 |
    0.430 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 全样本 | gAnswer | - | - | - | 0.293 | 0.327 | 0.298 | 0.585 | 0.341 | 0.430
    |'
- en: '|  | EDGQA | 0.505 | 0.560 | 0.531 | 0.313 | 0.403 | 0.320 | 0.419 | 0.408
    | 0.414 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | EDGQA | 0.505 | 0.560 | 0.531 | 0.313 | 0.403 | 0.320 | 0.419 | 0.408
    | 0.414 |'
- en: '|  | KGQAN | 0.587 | 0.461 | 0.516 | 0.511 | 0.387 | 0.441 | 0.485 | 0.652
    | 0.556 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | KGQAN | 0.587 | 0.461 | 0.516 | 0.511 | 0.387 | 0.441 | 0.485 | 0.652
    | 0.556 |'
- en: '| few-shot | GPT-3.5 | 0.269 | 0.251 | 0.266 | 0.240 | 0.217 | 0.228 | 0.171
    | 0.142 | 0.155 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| few-shot | GPT-3.5 | 0.269 | 0.251 | 0.266 | 0.240 | 0.217 | 0.228 | 0.171
    | 0.142 | 0.155 |'
- en: '|  | GPT-4 | 0.336 | 0.344 | 0.340 | 0.250 | 0.249 | 0.249 | 0.193 | 0.190
    | 0.191 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  | GPT-4 | 0.336 | 0.344 | 0.340 | 0.250 | 0.249 | 0.249 | 0.193 | 0.190
    | 0.191 |'
- en: '|  | Triad-GPT3.5 | 0.490 | 0.519 | 0.504 | 0.293 | 0.302 | 0.297 | 0.660 |
    0.639 | 0.649 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | Triad-GPT3.5 | 0.490 | 0.519 | 0.504 | 0.293 | 0.302 | 0.297 | 0.660 |
    0.639 | 0.649 |'
- en: '|  | Triad-GPT4 | 0.561 | 0.568 | 0.564 | 0.408 | 0.425 | 0.416 | 0.690 | 0.664
    | 0.677 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|  | Triad-GPT4 | 0.561 | 0.568 | 0.564 | 0.408 | 0.425 | 0.416 | 0.690 | 0.664
    | 0.677 |'
- en: 'Table 2: The performance of our proposed Triad on three benchmarks, comparing
    with traditional KBQA systems (full-shot) and pure LLM (few-shot) baselines. The
    optimal and suboptimal scores are highlighted with bold and underlined text, respectively.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：我们提出的Triad在三个基准测试中的性能，与传统的KBQA系统（全量）和纯LLM（少量）基准进行了比较。最优和次优得分分别以**粗体**和下划线文本突出显示。
- en: 'Baseline Methods:'
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基准方法：
- en: We evaluate Triad against traditional KBQA systems such as KGQAN Omar et al.
    ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)), EDGQA Hu et al. ([2021](https://arxiv.org/html/2402.14320v6#bib.bib8))
    and gAnswer Hu et al. ([2018](https://arxiv.org/html/2402.14320v6#bib.bib7)).
    This comparison shows how our LLM-based agent framework can rival full-shot systems
    with just a few examples. Additionally, we contrast our framework with pure GPT
    models like GPT-3.5 Turbo and GPT-4 ²²2https://platform.openai.com/docs/models
    to exhibit Triad’s architectural performance. We treat these foundation models
    as few-shot methods to answer the questions referring to some examples.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将Triad与传统的KBQA系统进行评估，如KGQAN Omar等([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13))、EDGQA
    Hu等([2021](https://arxiv.org/html/2402.14320v6#bib.bib8))和gAnswer Hu等([2018](https://arxiv.org/html/2402.14320v6#bib.bib7))。该比较展示了我们的基于LLM的代理框架如何仅通过少量示例与全量系统相媲美。此外，我们还将框架与纯GPT模型（如GPT-3.5
    Turbo和GPT-4 ²²2https://platform.openai.com/docs/models）进行对比，以展示Triad的架构性能。我们将这些基础模型视为少量示例方法，用于回答参考示例的问题。
- en: 'Implementation Details:'
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实现细节：
- en: 'Triad is implemented with Python 3.9\. We incorporate LLM capabilities to our
    multi-role agent via OpenAI’s API services. The names of entities and relations
    from knowledge bases are indexed in an ElasticSearch 7.5.2 server for text matching.
    All triples are imported into an SPARQL endpoint of Virtuoso 07.20.3237 for retrieval.
    Triad requires four hyperparameters: the number of examples G-Agent uses for subtask
    learning, the number of candidates D-Agent selects for entity and relation linking,
    and the retry times for handling non-response SPARQLs. The optimal values for
    these parameters are 3, 2, 2, and 3, respectively. The framework and its variants
    are tested five times on each benchmark, with the average scores reported as the
    final results. For traditional systems, we report the results recorded in their
    papers. For pure LLM baselines, we write prompts to hire an LLM to answer questions
    directly referring to examples, and then link the mentions from the responses
    to the URIs in our indexed knowledge bases via built-in similarity search.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Triad是使用Python 3.9实现的。我们通过OpenAI的API服务将LLM能力集成到我们的多角色代理中。知识库中的实体和关系名称被索引在ElasticSearch
    7.5.2服务器中，用于文本匹配。所有三元组都被导入到Virtuoso 07.20.3237的SPARQL端点中进行检索。Triad需要四个超参数：G-Agent用于子任务学习的示例数量，D-Agent选择用于实体和关系链接的候选数量，以及处理无响应SPARQL查询的重试次数。这些参数的最优值分别为3、2、2和3。框架及其变体在每个基准测试中进行了五次测试，报告的平均分作为最终结果。对于传统系统，我们报告它们论文中记录的结果。对于纯LLM基准，我们编写提示语，聘请LLM直接回答参考示例的问题，然后通过内置的相似性搜索将响应中的提及链接到我们索引的知识库中的URI。
- en: 4.2 Performance Comparison
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 性能比较
- en: 'The performance of Triad compared to traditional KBQA systems and pure LLM
    generation methods is shown in Table [2](https://arxiv.org/html/2402.14320v6#S4.T2
    "Table 2 ‣ KBQA Benchmark Datasets: ‣ 4.1 Experimental Settings ‣ 4 Performance
    Evaluation ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve
    Knowledge Base Question Answering"). Evaluation metrics precision(P), recall(R),
    and F1-score(F1) are reported. We can observe from the experimental results that:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 'Triad与传统KBQA系统和纯LLM生成方法的性能比较见表[2](https://arxiv.org/html/2402.14320v6#S4.T2
    "Table 2 ‣ KBQA Benchmark Datasets: ‣ 4.1 Experimental Settings ‣ 4 Performance
    Evaluation ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve
    Knowledge Base Question Answering")。评估指标包括精确度(P)、召回率(R)和F1得分(F1)。从实验结果中我们可以观察到：'
- en: Few-shot can be competitive with full-shot.
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 少量学习可以与全量学习竞争。
- en: Our multi-role LLM-based agent framework, though executing a few-shot prompt
    learning, exhibits competitive performance with cutting-edge full-shot KBQA systems.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基于多角色 LLM 的代理框架，尽管执行了少量提示学习，但在与最前沿的全量知识库问答（KBQA）系统相比，展现出了具有竞争力的表现。
- en: Underlying capability matters.
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基础能力至关重要。
- en: The use of GPT-4 as the core in an LLM-based agent significantly outperforms
    GPT-3.5 on all benchmarks, demonstrating the importance of the underlying capabilities
    of an agent.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 基础的代理中使用 GPT-4 作为核心，在所有基准测试中显著优于 GPT-3.5，证明了代理基础能力的重要性。
- en: Explicit knowledge is necessary.
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 明确的知识是必要的。
- en: Pure LLM models with GPT-3.5 and GPT-4 display deficiencies in generating accurate
    responses without an auxiliary knowledge base as a memory for intermediary steps
    such as URI linking.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 纯 LLM 模型（如 GPT-3.5 和 GPT-4）在没有辅助知识库作为中介步骤记忆（如 URI 链接）时，生成准确回答存在不足。
- en: Performance varies with complexity.
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能随复杂度变化。
- en: Triad demonstrates superior results on the LC-QuAD and YAGO-QA benchmarks compared
    to QALD-9, due to an increasing failure in response to complex questions, which
    will be discussed later.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Triad 在 LC-QuAD 和 YAGO-QA 基准测试中表现优于 QALD-9，原因是它在回答复杂问题时的失败率较高，这将在后文中讨论。
- en: 4.3 Study on Capabilities of Agent Roles
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 代理角色能力研究
- en: 'We assess the efficacy of G-Agent with various other language models as the
    core. The framework without G-task uses the text-davinci-002, which is not as
    powerful as GPT-3.5 and GPT-4 in solving many tasks, and the one without G-chat
    uses text-davinci-003 to eliminate the chat and alignment abilities. We test the
    ability of D-Agent without D-uri and D-query by replacing the URI selection and
    query selection with URI matching and query generation, respectively. We evaluate
    the contribution of A-Agent eliminating A-llm and A-fact by responding to questions
    without using LLM’s assistance or use an LLM to answer Boolean questions for auxiliary
    rather than single-fact questions. The F1 results of the role ablation experiments
    on two representative datasets are shown in Table [3](https://arxiv.org/html/2402.14320v6#S4.T3
    "Table 3 ‣ 4.3 Study on Capabilities of Agent Roles ‣ 4 Performance Evaluation
    ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering"). The results indicate that every component pertaining
    to each role contributes to the overall performance. More specifically, a G-Agent
    that employs a less powerful LLM as its core can drastically undermine performance.
    D-Agent assumes a more pivotal role during the linking phase compared to the query
    construction phase. A-Agent, on the other hand, proves to be an efficient solution
    for managing situations where SPARQL results are absent.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '我们评估了以不同语言模型为核心的 G-Agent 的效果。没有 G-task 的框架使用的是 text-davinci-002，它在解决许多任务时不如
    GPT-3.5 和 GPT-4 强大；没有 G-chat 的框架使用的是 text-davinci-003，去除了聊天和对齐能力。我们通过分别用 URI 匹配和查询生成代替
    URI 选择和查询选择，测试了没有 D-uri 和 D-query 的 D-Agent 的能力。我们通过不使用 LLM 的帮助来回答问题，或者仅在辅助布尔问题时使用
    LLM，而不是单一事实问题，评估了去除 A-llm 和 A-fact 后 A-Agent 的贡献。两组代表性数据集上的角色消融实验的 F1 结果如表 [3](https://arxiv.org/html/2402.14320v6#S4.T3
    "Table 3 ‣ 4.3 Study on Capabilities of Agent Roles ‣ 4 Performance Evaluation
    ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering") 所示。结果表明，每个角色相关的组件对整体性能都有贡献。更具体地说，使用较弱 LLM 作为核心的 G-Agent
    会显著削弱性能。D-Agent 在链接阶段比查询构造阶段更为关键。A-Agent 则在管理没有 SPARQL 结果的情况时表现为一个高效的解决方案。'
- en: '| G-task | G-chat | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| G-task | G-chat | LC-QuAD 1.0 | QALD-9 |'
- en: '| ✗ | ✗ | 0.343 | 0.159 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✗ | 0.343 | 0.159 |'
- en: '| ✓ | ✗ | 0.443 | 0.248 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.443 | 0.248 |'
- en: '| ✓ | ✓ | 0.564 | 0.416 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.564 | 0.416 |'
- en: '| D-uri | D-query | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| D-uri | D-query | LC-QuAD 1.0 | QALD-9 |'
- en: '| ✗ | ✓ | 0.274 | 0.210 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✓ | 0.274 | 0.210 |'
- en: '| ✓ | ✗ | 0.431 | 0.301 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.431 | 0.301 |'
- en: '| ✓ | ✓ | 0.564 | 0.416 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.564 | 0.416 |'
- en: '| A-llm | A-fact | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| A-llm | A-fact | LC-QuAD 1.0 | QALD-9 |'
- en: '| ✗ | ✗ | 0.459 | 0.382 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✗ | 0.459 | 0.382 |'
- en: '| ✓ | ✗ | 0.473 | 0.385 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.473 | 0.385 |'
- en: '| ✓ | ✓ | 0.564 | 0.416 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.564 | 0.416 |'
- en: 'Table 3: Study on the roles of LLM-based agent by eliminating an element or
    downgrading the capability.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：通过消除一个元素或降低能力来研究基于 LLM 的代理角色。
- en: 4.4 Analysis of Role Hyperparameters
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 角色超参数分析
- en: 'We concentrate on three hyperparameters of roles, including the number of examples
    ($\mathcal{N}\in\{1,2,3\}$) provided for G-Agent to learn subtasks, the number
    of URI candidates ($\mathcal{K}\in\{(1,1),(1,2),(2,2),(2,3)\}$) selected by D-Agent
    for query construction, and the number of retry times ($\mathcal{T}\in\{1,2,3\}$)
    launched by A-Agent when there is no response. Table [4](https://arxiv.org/html/2402.14320v6#S4.T4
    "Table 4 ‣ 4.4 Analysis of Role Hyperparameters ‣ 4 Performance Evaluation ‣ Triad:
    A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question
    Answering") presents the F1 results of Triad’s performance, employing three hyperparameters
    on two benchmarks. We discover that:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '我们集中在三个角色的超参数上，包括为G-Agent学习子任务提供的示例数量（$\mathcal{N}\in\{1,2,3\}$），D-Agent为查询构建选择的URI候选数量（$\mathcal{K}\in\{(1,1),(1,2),(2,2),(2,3)\}$），以及当没有响应时A-Agent发起的重试次数（$\mathcal{T}\in\{1,2,3\}$）。表[4](https://arxiv.org/html/2402.14320v6#S4.T4
    "Table 4 ‣ 4.4 Analysis of Role Hyperparameters ‣ 4 Performance Evaluation ‣ Triad:
    A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question
    Answering")展示了Triad在两个基准上采用这三个超参数的F1结果。我们发现：'
- en: '| Triad Variants | LC-QuAD 1.0 | QALD-9 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Triad Variants | LC-QuAD 1.0 | QALD-9 |'
- en: '| Triad-1-Shot | 0.556 | 0.376 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| Triad-1-Shot | 0.556 | 0.376 |'
- en: '| Triad-2-Shot | 0.511 | 0.402 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Triad-2-Shot | 0.511 | 0.402 |'
- en: '| Triad-3-Shot | 0.564 | 0.416 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Triad-3-Shot | 0.564 | 0.416 |'
- en: '| Triad-Top1-1 | 0.528 | 0.281 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top1-1 | 0.528 | 0.281 |'
- en: '| Triad-Top1-2 | 0.562 | 0.375 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top1-2 | 0.562 | 0.375 |'
- en: '| Triad-Top2-2 | 0.564 | 0.416 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top2-2 | 0.564 | 0.416 |'
- en: '| Triad-Top2-3 | 0.558 | 0.384 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Triad-Top2-3 | 0.558 | 0.384 |'
- en: '| Triad-1-Try | 0.529 | 0.375 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Triad-1-Try | 0.529 | 0.375 |'
- en: '| Triad-2-Tries | 0.561 | 0.407 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Triad-2-Tries | 0.561 | 0.407 |'
- en: '| Triad-3-Tries | 0.564 | 0.416 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| Triad-3-Tries | 0.564 | 0.416 |'
- en: 'Table 4: Performance evaluation on three hyperparameters that related to each
    role of an LLM-based agent.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：基于LLM的智能体各角色相关的三个超参数的性能评估。
- en: Quality is more important than quantity.
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 质量比数量更重要。
- en: More examples provided to G-Agent do not always improve the performance. The
    efficacy of G-Agent is significantly influenced by the quality of examples.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 提供给G-Agent的更多示例并不总是能提高性能。G-Agent的效能受到示例质量的显著影响。
- en: More options may harm the result.
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更多的选项可能会损害结果。
- en: Choosing more candidate URIs for entities and relations could potentially disrupt
    subsequent query phases, thus affecting overall performance.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为实体和关系选择更多的候选URI可能会干扰后续查询阶段，从而影响整体性能。
- en: More chances benefits the framework.
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更多的机会有利于框架。
- en: Persistently attempting to construct and execute SPARQL queries is an effective
    strategy that improves the probability of obtaining accurate answers. Considering
    the efficiency of overall execution, we set the maximum retry times as 3 in practice.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 持续尝试构建并执行SPARQL查询是一种有效的策略，可以提高获取准确答案的概率。考虑到整体执行效率，我们在实践中将最大重试次数设置为3。
- en: 4.5 Analysis of Linking Recall
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 链接召回分析
- en: The process of linking is a relatively complex subtask in both the Text2SQL
    and the KBQA process Li et al. ([2024](https://arxiv.org/html/2402.14320v6#bib.bib11)).
    Calculating the recall ratio of accurate URIs using D-Agent provides clarity on
    which step most adversely impacts performance. In the entity linking phase, considering
    all URIs of entities in the testing set as the ground truth of the linking results,
    80\. 75% of the correct URIs are contained from the output of the entity matching
    filter in D-Agent and 70\. 50% of the correct URIs are retained from the entity
    selection performed by the LLM in D-Agent. Whereas, in the relation linking phase,
    only 52\. 54% of the correct relation URIs survive from the selection of LLM,
    which indicates a greater difficulty in relation linking.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 链接过程是Text2SQL和KBQA过程中相对复杂的子任务（Li等人，[2024](https://arxiv.org/html/2402.14320v6#bib.bib11)）。使用D-Agent计算准确URI的召回率，有助于明确哪个步骤对性能的影响最大。在实体链接阶段，将测试集中所有实体的URI作为链接结果的真实情况，D-Agent实体匹配过滤器的输出包含了80.75%的正确URI，而LLM在D-Agent中执行的实体选择保留了70.50%的正确URI。而在关系链接阶段，只有52.54%的正确关系URI通过LLM的选择存活下来，表明关系链接更具挑战性。
- en: 4.6 Study on Complex Cases
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 复杂案例研究
- en: 'Despite the impressive performance of Triad in certain benchmarks, notable
    deficiencies remain in its ability to understand questions and generate queries
    for complex questions. A critical analysis of unsuccessful cases in QALD-9, which
    has the lowest F1 score, has revealed three primary reasons for this failure,
    as detailed below:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Triad在某些基准测试中表现出色，但在理解问题和为复杂问题生成查询方面仍存在明显不足。对QALD-9中未成功的案例进行的深入分析，揭示了导致这种失败的三个主要原因，具体如下：
- en: '| Fail Reason | Ratio | Example |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 失败原因 | 比例 | 示例 |'
- en: '| Complex Syntax | 20% | Q42: Which countries have places with more than two
    caves? |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 复杂语法 | 20% | Q42: 哪些国家的地方有超过两个洞穴？ |'
- en: '| Unexploited Semantics | 17% | Q199: Give me all Argentine films. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 未利用语义 | 17% | Q199: 给我所有的阿根廷电影。 |'
- en: '| Implicit Reasoning | 5% | Q133: What are the names of the Teenage Mutant
    Ninja Turtles? |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 隐式推理 | 5% | Q133: 青少年变种忍者龟的名字是什么？ |'
- en: 'Table 5: The major reasons of complexity that result in failures, with their
    corresponding ratios of occurrence in failed cases.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 表5：导致失败的复杂性主要原因及其在失败案例中的出现比例。
- en: Complex Syntax
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 复杂语法
- en: 'signifies that advanced SPARQL queries incorporate keywords such as GROUP BY
    and HAVING. These terms augment the error propensity in the generation of SPARQL
    templates such as the example: Which frequent flyer program has the most airlines?'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 表示高级SPARQL查询包含如GROUP BY和HAVING等关键词。这些术语增加了在生成SPARQL模板时的错误倾向，例如示例：哪个常旅客计划拥有最多的航空公司？
- en: Unexploited Semantics
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 未利用语义
- en: indicates that semantics of an implicit entity should be comprehended in order
    to exclude irrelevant URIs. In the example Give me all Argentine films, the meaning
    of films should be used to narrow down the scope of potential entities in order
    to eliminate unrelated answers.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表明必须理解隐式实体的语义，以排除无关的URI。在示例“给我所有的阿根廷电影”中，电影的含义应被用来缩小潜在实体的范围，以排除无关的答案。
- en: Implicit Reasoning
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 隐式推理
- en: presents a challenge that requires a deeper level of traversal by the framework
    to deduce accurate results from the posed question. For example, another failure
    question, How many grand-children did Jacques Cousteau have?, the term grand-children
    must be interpreted to son of son to ensure an accurate response.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了一个挑战，要求框架进行更深入的遍历，以从提出的问题中推导出准确的结果。例如，另一个失败的例子，“Jacques Cousteau有多少个孙子？”
    其中，“孙子”一词必须被解释为“儿子的儿子”，以确保得到准确的回答。
- en: 4.7 Cost Comparison and Analysis
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.7 成本比较与分析
- en: According to our evaluation on the three datasets, the average cost of running
    a single case is 0.007 USD on average using Triad-GPT3.5 and 0.05 USD on average
    using Triad-GPT4\. Specifically, most API calls occur in the phases of URL linking
    and comprehensive answering. Meanwhile, traditional KBQA baselines require a lot
    of training data and local training resources to achieve the SOTA performance,
    whereas Triad follows a zero- or few-shot manner to save computational cost locally.
    Furthermore, as shown in Section 4.4, in practice, adjusting the hyperparameters
    can make the cost as low as possible while preserving overall performance. As
    the cost of LLM services decreases, the value of Triad will increase accordingly.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们对三个数据集的评估，使用Triad-GPT3.5运行单个案例的平均成本为0.007美元，而使用Triad-GPT4的平均成本为0.05美元。具体来说，大多数API调用发生在URL链接和综合回答阶段。同时，传统的KBQA基准需要大量的训练数据和本地训练资源才能实现SOTA性能，而Triad采用零-shot或少-shot方式，在本地节省计算成本。此外，如第4.4节所示，在实际应用中，调整超参数可以在保持整体性能的同时将成本降低到最低。当LLM服务的成本下降时，Triad的价值将相应增加。
- en: 5 Related Work
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 相关工作
- en: 5.1 SPARQL-based and LLM-based KBQA
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 基于SPARQL和LLM的KBQA
- en: Traditional KBQA methods transform natural language queries into SPARQL requests
    for data extraction. Specific models are employed either for question understanding
    or URI linking, utilizing domain-based training datasets. Hu et al. ([2018](https://arxiv.org/html/2402.14320v6#bib.bib7))
    introduces a semantic query graph to structurally represent the natural language
    query, thereby simplifying the task into a subgraph matching problem. Hu et al.
    ([2021](https://arxiv.org/html/2402.14320v6#bib.bib8)) proposes an entity description
    graph to represent natural language queries for question parsing and element linking.
    Omar et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)) restructures
    the question parsing task as a text generation issue using a sequence-to-sequence
    model. With the advent of LLMs, certain phases of KBQA can be enhanced with LLM-integrated
    methods. Baek et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib2)) aims
    to augment LLM-based QA tasks with pertinent facts extracted from knowledge bases,
    offering a fully zero-shot architecture. Tan et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib20))
    leverages the general applicability of LLMs to filter linking candidates by making
    selections via few-shot in-context learning. Omar et al. ([2023b](https://arxiv.org/html/2402.14320v6#bib.bib14))
    provides a thorough comparison between LLMs and QA systems, recommending further
    studies to improve KBQA with LLM capabilities. However, apart from the above studies,
    our study proposes a complete framework incorporating both an LLM and few-shot
    learning across all KBQA phases from a systematic perspective.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的知识库问答（KBQA）方法将自然语言查询转换为SPARQL请求以进行数据提取。特定模型用于问题理解或URI链接，利用基于领域的训练数据集。胡等人（[2018](https://arxiv.org/html/2402.14320v6#bib.bib7)）提出了一种语义查询图，结构化地表示自然语言查询，从而将任务简化为子图匹配问题。胡等人（[2021](https://arxiv.org/html/2402.14320v6#bib.bib8)）提出了一种实体描述图，用于表示自然语言查询，以便进行问题解析和元素链接。奥马尔等人（[2023a](https://arxiv.org/html/2402.14320v6#bib.bib13)）将问题解析任务重构为使用序列到序列模型的文本生成问题。随着LLM（大语言模型）的出现，KBQA的某些阶段可以通过LLM集成方法得到增强。白克等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib2)）旨在通过从知识库中提取相关事实，增强基于LLM的问答任务，提供一个完全的零样本架构。谭等人（[2023a](https://arxiv.org/html/2402.14320v6#bib.bib20)）利用LLM的广泛适用性，通过少量示例的上下文学习筛选链接候选项。奥马尔等人（[2023b](https://arxiv.org/html/2402.14320v6#bib.bib14)）对LLM和问答系统进行了全面比较，建议进一步研究以提升LLM在KBQA中的应用。然而，除了上述研究外，我们的研究提出了一个完整的框架，从系统的角度整合LLM和少量样本学习，涵盖KBQA各个阶段。
- en: 5.2 LLM-based Agents for Complex Tasks
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基于LLM的复杂任务代理
- en: LLMs have recently gained significant attention due to their ability to approximate
    human-level intelligence. This has led to numerous studies focusing on LLM-based
    agents. A recent surveyWang et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib26))
    proposes a unified architecture for LLM-based agents, which consists of four modules
    that include profile, memory, plan, and action. CHATDBHu et al. ([2023a](https://arxiv.org/html/2402.14320v6#bib.bib5))
    employs an LLM controller to generate SQL instructions, which allows for symbolic
    memory and complex multi-hop reasoning. ARTParanjape et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib15))
    uses a frozen LLM to generate reasoning steps and further integrates tools for
    new tasks with minimal human intervention. ToolformerSchick et al. ([2024](https://arxiv.org/html/2402.14320v6#bib.bib17))
    takes a different approach by training an LLM to plan and execute tools for the
    next token prediction by learning API calls generation. ReActYao et al. ([2023](https://arxiv.org/html/2402.14320v6#bib.bib28))
    focuses on overcoming LLM hallucination by interacting with external knowledge
    bases, thus generating interpretable task-solving strategies. CodeAgentTang et al.
    ([2024](https://arxiv.org/html/2402.14320v6#bib.bib23)) designs a multi-agent
    collaboration system across four phases in a code review process. Divergent from
    the aforementioned studies, our framework concentrates on the solving KBQA tasks
    by introducing a multi-role LLM-based agent that specializes in various subtasks
    distributed across different phases.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM能够近似人类级别的智能，最近引起了广泛关注。这导致了大量研究集中于基于LLM的智能体。最近的一项调查Wang等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib26)）提出了一种统一的基于LLM的智能体架构，该架构由四个模块组成，包括个人资料、记忆、计划和行动。CHATDBHu等人（[2023a](https://arxiv.org/html/2402.14320v6#bib.bib5)）采用LLM控制器生成SQL指令，从而实现符号记忆和复杂的多跳推理。ARTParanjape等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib15)）使用冻结的LLM生成推理步骤，并进一步结合工具来处理新任务，且最小化人类干预。ToolformerSchick等人（[2024](https://arxiv.org/html/2402.14320v6#bib.bib17)）通过训练LLM来规划和执行工具，以通过学习API调用生成来预测下一个令牌。ReActYao等人（[2023](https://arxiv.org/html/2402.14320v6#bib.bib28)）专注于通过与外部知识库交互来克服LLM的幻觉，从而生成可解释的任务解决策略。CodeAgentTang等人（[2024](https://arxiv.org/html/2402.14320v6#bib.bib23)）设计了一个跨四个阶段的多智能体协作系统，用于代码审查过程。与上述研究不同，我们的框架专注于通过引入一个多角色的基于LLM的智能体，解决KBQA任务，该智能体专门处理分布在不同阶段的各种子任务。
- en: 6 Conclusion
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this study, we aim to bridge the gap between KBQA tasks and the investigation
    of LLM-based agents. We introduce Triad, a framework to address the KBQA task
    through an LLM-based agent acting as multiple roles, including a generalist capable
    of mastering diverse tasks given minimal examples, a decision-maker concentrating
    on option analysis and candidate selection, and an advisor skilled in answering
    questions with the aid of both external and internal knowledge. Triad achieves
    the best or competitive performance across three benchmark datasets compared to
    traditional KBQA systems and pure LLM models. In future research, we plan to broaden
    our framework to handle more intricate questions, such as multi-hop reasoning,
    and exploring the integration between our framework and retrieval-augmented generation.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们旨在弥合KBQA任务与基于LLM的智能体研究之间的差距。我们介绍了Triad，这是一个通过基于LLM的智能体来解决KBQA任务的框架，该智能体扮演多个角色，包括能够在给定最少示例的情况下掌握多种任务的通才，专注于选项分析和候选选择的决策者，以及能够在外部和内部知识的帮助下回答问题的顾问。与传统的KBQA系统和纯LLM模型相比，Triad在三个基准数据集上达到了最佳或具有竞争力的表现。在未来的研究中，我们计划拓展我们的框架，以处理更为复杂的问题，例如多跳推理，并探索我们的框架与增强检索生成的整合。
- en: Limitations
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: 'The limitation of our research lies in following aspects: (1) In terms of data,
    a broader range of QA datasets needs to be evaluated, encompassing datasets from
    different domains, languages, and difficulty levels. (2) In terms of model, more
    LLMs need to be evaluated, including open-source and commercial models from different
    organizations and on various scales. (3) In terms of framework, more types of
    agent collaboration methods can be explored to solve KBQA problems.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究的局限性体现在以下几个方面：（1）在数据方面，需要评估更广泛的QA数据集，包括来自不同领域、语言和难度级别的数据集。（2）在模型方面，需要评估更多的LLM，包括来自不同组织和不同规模的开源和商业模型。（3）在框架方面，可以探索更多类型的智能体协作方法来解决KBQA问题。
- en: Ethics Considerations
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理考量
- en: All datasets utilized in this study are publicly available and we have adhered
    to ethical considerations by not introducing additional information as input during
    LLM text generation.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中使用的所有数据集都是公开可用的，并且我们在LLM文本生成过程中没有引入额外的信息作为输入，遵守了伦理规范。
- en: Acknowledgements
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work is supported by the "Pioneer" and "Leading Goose" R&D Program of Zhejiang
    (Grant No. 2023C01152).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了浙江省“先锋”和“领头雁”研发计划的资助（资助编号：2023C01152）。
- en: References
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Auer et al. (2007) Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann,
    Richard Cyganiak, and Zachary Ives. 2007. [Dbpedia: A nucleus for a web of open
    data](https://doi.org/https://doi.org/10.1007/978-3-540-76298-0_52). In *The Semantic
    Web*, pages 722–735, Berlin, Heidelberg. Springer Berlin Heidelberg.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Auer 等人（2007）Sören Auer、Christian Bizer、Georgi Kobilarov、Jens Lehmann、Richard
    Cyganiak 和 Zachary Ives。2007年。[Dbpedia: A nucleus for a web of open data](https://doi.org/https://doi.org/10.1007/978-3-540-76298-0_52)。在
    *The Semantic Web* 书中，页码722–735，柏林，海德堡。Springer Berlin Heidelberg。'
- en: Baek et al. (2023) Jinheon Baek, AlhamFikri Aji, and Amir Saffari. 2023. [Knowledge-augmented
    language model prompting for zero-shot knowledge graph question answering](https://doi.org/https://doi.org/10.48550/arXiv.2306.04136).
    *arXiv preprint arXiv:2306.04136*.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baek 等人（2023）Jinheon Baek、AlhamFikri Aji 和 Amir Saffari。2023年。[Knowledge-augmented
    language model prompting for zero-shot knowledge graph question answering](https://doi.org/https://doi.org/10.48550/arXiv.2306.04136)。*arXiv
    预印本 arXiv:2306.04136*。
- en: 'Dong et al. (2023) Qingxiu Dong, Li Dong, Ke Xu, Guangyan Zhou, Yaru Hao, Zhifang
    Sui, and Furu Wei. 2023. Large language model for science: A study on p vs. np.
    *arXiv preprint arXiv:2309.05689*.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等人（2023）Qingxiu Dong、Li Dong、Ke Xu、Guangyan Zhou、Yaru Hao、Zhifang Sui 和
    Furu Wei。2023年。大语言模型在科学中的应用：关于 P vs. NP 的研究。*arXiv 预印本 arXiv:2309.05689*。
- en: Dong et al. (2022) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao
    Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for in-context learning.
    *arXiv preprint arXiv:2301.00234*.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等人（2022）Qingxiu Dong、Lei Li、Damai Dai、Ce Zheng、Zhiyong Wu、Baobao Chang、Xu
    Sun、Jingjing Xu 和 Zhifang Sui。2022年。一项关于上下文学习的调查。*arXiv 预印本 arXiv:2301.00234*。
- en: 'Hu et al. (2023a) Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao,
    and Hang Zhao. 2023a. [Chatdb: Augmenting llms with databases as their symbolic
    memory](https://doi.org/https://doi.org/10.48550/arXiv.2306.03901). *arXiv preprint
    arXiv:2306.03901*.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu 等人（2023a）Chenxu Hu、Jie Fu、Chenzhuang Du、Simian Luo、Junbo Zhao 和 Hang Zhao。2023a年。[Chatdb:
    Augmenting llms with databases as their symbolic memory](https://doi.org/https://doi.org/10.48550/arXiv.2306.03901)。*arXiv
    预印本 arXiv:2306.03901*。'
- en: Hu et al. (2023b) Nan Hu, Yike Wu, Guilin Qi, Dehai Min, Jiaoyan Chen, Jeff Z
    Pan, and Zafar Ali. 2023b. [An empirical study of pre-trained language models
    in simple knowledge graph question answering](https://doi.org/https://doi.org/10.1007/s11280-023-01166-y).
    *World Wide Web*, pages 1–32.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2023b）Nan Hu、Yike Wu、Guilin Qi、Dehai Min、Jiaoyan Chen、Jeff Z Pan 和 Zafar
    Ali。2023b年。[An empirical study of pre-trained language models in simple knowledge
    graph question answering](https://doi.org/https://doi.org/10.1007/s11280-023-01166-y)。*World
    Wide Web*，页码1–32。
- en: Hu et al. (2018) Sen Hu, Lei Zou, Jeffrey Xu Yu, Haixun Wang, and Dongyan Zhao.
    2018. [Answering natural language questions by subgraph matching over knowledge
    graphs](https://doi.org/10.1109/tkde.2017.2766634). *IEEE Transactions on Knowledge
    and Data Engineering*, page 824–837.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2018）Sen Hu、Lei Zou、Jeffrey Xu Yu、Haixun Wang 和 Dongyan Zhao。2018年。[Answering
    natural language questions by subgraph matching over knowledge graphs](https://doi.org/10.1109/tkde.2017.2766634)。*IEEE
    Transactions on Knowledge and Data Engineering*，页码824–837。
- en: 'Hu et al. (2021) Xixin Hu, Yiheng Shu, Xiang Huang, and Yuzhong Qu. 2021. [Edg-based
    question decomposition for complex question answering over knowledge bases](https://doi.org/10.1007/978-3-030-88361-4_8).
    In *The Semantic Web – ISWC 2021: 20th International Semantic Web Conference,
    ISWC 2021, Virtual Event, October 24–28, 2021, Proceedings*, page 128–145, Berlin,
    Heidelberg. Springer-Verlag.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hu 等人（2021）Xixin Hu、Yiheng Shu、Xiang Huang 和 Yuzhong Qu。2021年。[Edg-based question
    decomposition for complex question answering over knowledge bases](https://doi.org/10.1007/978-3-030-88361-4_8)。在
    *The Semantic Web – ISWC 2021: 20th International Semantic Web Conference, ISWC
    2021, Virtual Event, October 24–28, 2021, Proceedings* 书中，页码128–145，柏林，海德堡。Springer-Verlag。'
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. [Large language models are zero-shot reasoners](https://doi.org/https://doi.org/10.48550/arXiv.2205.1191).
    *Advances in neural information processing systems*, 35:22199–22213.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人（2022）Takeshi Kojima、Shixiang Shane Gu、Machel Reid、Yutaka Matsuo 和
    Yusuke Iwasawa。2022年。[Large language models are zero-shot reasoners](https://doi.org/https://doi.org/10.48550/arXiv.2205.1191)。*Advances
    in neural information processing systems*，35:22199–22213。
- en: 'Li et al. (2023) Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao
    Ma, Nan Huo, Fei Huang, Wenyu Du, Luo Si, and Yongbin Li. 2023. Graphix-t5: Mixing
    pre-trained transformers with graph-aware layers for text-to-sql parsing. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, volume 37, pages 13076–13084.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人（2023）Jinyang Li, Binyuan Hui, Reynold Cheng, Bowen Qin, Chenhao Ma, Nan
    Huo, Fei Huang, Wenyu Du, Luo Si, 和 Yongbin Li. 2023. Graphix-t5: 将预训练的变换器与图感知层混合用于文本到
    SQL 的解析. 收录于 *AAAI 人工智能大会论文集*，第 37 卷，页面 13076–13084.'
- en: Li et al. (2024) Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen
    Li, Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo, et al. 2024. Can llm already
    serve as a database interface? a big bench for large-scale database grounded text-to-sqls.
    *Advances in Neural Information Processing Systems*, 36.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等人（2024）Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li,
    Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo 等. 2024. 大型语言模型（LLM）能否已经作为数据库接口？一个用于大规模数据库基础的文本到
    SQL 基准测试. *神经信息处理系统进展*，第 36 卷.
- en: 'Liu et al. (2023) Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, et al.
    2023. [Bolaa: Benchmarking and orchestrating llm-augmented autonomous agents](https://doi.org/https://doi.org/10.48550/arXiv.2308.05960).
    *arXiv preprint arXiv:2308.05960*.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人（2023）Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke,
    Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit 等.
    2023. [Bolaa: 基准测试和协同操作 LLM 增强的自主智能体](https://doi.org/https://doi.org/10.48550/arXiv.2308.05960).
    *arXiv 预印本 arXiv:2308.05960*.'
- en: Omar et al. (2023a) Reham Omar, Ishika Dhall, Panos Kalnis, and Essam Mansour.
    2023a. [A universal question-answering platform for knowledge graphs](https://doi.org/10.1145/3588911).
    *Proceedings of the ACM on Management of Data*, 1(1):1–25.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Omar 等人（2023a）Reham Omar, Ishika Dhall, Panos Kalnis, 和 Essam Mansour. 2023a.
    [一个通用的知识图谱问答平台](https://doi.org/10.1145/3588911). *ACM 数据管理会议论文集*，1(1):1–25.
- en: 'Omar et al. (2023b) Reham Omar, Omij Mangukiya, Panos Kalnis, and Essam Mansour.
    2023b. [Chatgpt versus traditional question answering for knowledge graphs: Current
    status and future directions towards knowledge graph chatbots](https://doi.org/https://doi.org/10.48550/arXiv.2302.06466).
    *arXiv preprint arXiv:2302.06466*.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Omar 等人（2023b）Reham Omar, Omij Mangukiya, Panos Kalnis, 和 Essam Mansour. 2023b.
    [ChatGPT 与传统问答在知识图谱中的比较：现状与未来知识图谱聊天机器人的发展方向](https://doi.org/https://doi.org/10.48550/arXiv.2302.06466).
    *arXiv 预印本 arXiv:2302.06466*.
- en: 'Paranjape et al. (2023) Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh
    Hajishirzi, Luke Zettlemoyer, and MarcoTulio Ribeiro. 2023. [Art: Automatic multi-step
    reasoning and tool-use for large language models](https://doi.org/https://doi.org/10.48550/arXiv.2303.09014).
    *arXiv preprint arXiv:2303.09014*.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Paranjape 等人（2023）Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh
    Hajishirzi, Luke Zettlemoyer, 和 MarcoTulio Ribeiro. 2023. [Art: 大型语言模型的自动多步骤推理和工具使用](https://doi.org/https://doi.org/10.48550/arXiv.2303.09014).
    *arXiv 预印本 arXiv:2303.09014*.'
- en: 'Pellissier Tanon et al. (2020) Thomas Pellissier Tanon, Gerhard Weikum, and
    Fabian Suchanek. 2020. [Yago 4: A reason-able knowledge base](https://doi.org/https://doi.org/10.1007/978-3-030-49461-2_34).
    In *The Semantic Web*, pages 583–596, Cham. Springer International Publishing.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pellissier Tanon 等人（2020）Thomas Pellissier Tanon, Gerhard Weikum, 和 Fabian
    Suchanek. 2020. [Yago 4: 一个合理的知识库](https://doi.org/https://doi.org/10.1007/978-3-030-49461-2_34).
    收录于 *语义网*，第 583–596 页，Cham. Springer 国际出版.'
- en: 'Schick et al. (2024) Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    2024. Toolformer: Language models can teach themselves to use tools. *Advances
    in Neural Information Processing Systems*, 36.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Schick 等人（2024）Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom.
    2024. Toolformer: 语言模型可以自我学习使用工具. *神经信息处理系统进展*，第 36 卷.'
- en: 'Shen et al. (2024) Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. 2024. Hugginggpt: Solving ai tasks with chatgpt and its
    friends in hugging face. *Advances in Neural Information Processing Systems*,
    36.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shen 等人（2024）Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu,
    和 Yueting Zhuang. 2024. Hugginggpt: 利用 ChatGPT 和 Hugging Face 的伙伴解决 AI 任务. *神经信息处理系统进展*，第
    36 卷.'
- en: 'Shinn et al. (2023) Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023. [Reflexion:
    an autonomous agent with dynamic memory and self-reflection](https://doi.org/https://doi.org/10.48550/arXiv.2303.11366).
    *arXiv preprint arXiv:2303.11366*.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shinn 等人（2023）Noah Shinn, Beck Labash, 和 Ashwin Gopinath. 2023. [Reflexion:
    一个具有动态记忆和自我反思的自主智能体](https://doi.org/https://doi.org/10.48550/arXiv.2303.11366).
    *arXiv 预印本 arXiv:2303.11366*.'
- en: Tan et al. (2023a) Chuanyuan Tan, Yuehe Chen, Wenbiao Shao, Wenliang Chen, Zhefeng
    Wang, Baoxing Huai, and Min Zhang. 2023a. [Make a choice! knowledge base question
    answering with in-context learning](https://doi.org/https://doi.org/10.48550/arXiv.2305.13972).
    *arXiv preprint arXiv:2305.13972*.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人（2023a）Chuanyuan Tan, Yuehe Chen, Wenbiao Shao, Wenliang Chen, Zhefeng
    Wang, Baoxing Huai, 和 Min Zhang. 2023a. [做出选择！基于上下文学习的知识库问答](https://doi.org/https://doi.org/10.48550/arXiv.2305.13972).
    *arXiv 预印本 arXiv:2305.13972*.
- en: Tan et al. (2023b) Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen,
    and Guilin Qi. 2023b. Can chatgpt replace traditional kbqa models? an in-depth
    analysis of the question answering performance of the gpt llm family. In *International
    Semantic Web Conference*, pages 348–367\. Springer.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人（2023b）Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, 和
    Guilin Qi. 2023b. ChatGPT 能否替代传统的知识库问答模型？对 GPT LLM 家族问答性能的深入分析. 在 *国际语义网会议*，第
    348–367 页。Springer.
- en: Tan et al. (2023c) Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen,
    and Guilin Qi. 2023c. [Evaluation of chatgpt as a question answering system for
    answering complex questions](https://doi.org/https://doi.org/10.48550/arXiv.2303.0799).
    *arXiv preprint arXiv:2303.07992*.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan 等人（2023c）Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, 和
    Guilin Qi. 2023c. [评估 ChatGPT 作为复杂问题解答系统的表现](https://doi.org/https://doi.org/10.48550/arXiv.2303.0799).
    *arXiv 预印本 arXiv:2303.07992*.
- en: Tang et al. (2024) Daniel Tang, Zhenghan Chen, Kisub Kim, Yewei Song, Haoye
    Tian, Saad Ezzini, Yongfeng Huang, and Jacques Klein Tegawende F Bissyande. 2024.
    Collaborative agents for software engineering. *arXiv preprint arXiv:2402.02172*.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tang 等人（2024）Daniel Tang, Zhenghan Chen, Kisub Kim, Yewei Song, Haoye Tian,
    Saad Ezzini, Yongfeng Huang, 和 Jacques Klein Tegawende F Bissyande. 2024. 软件工程的协作代理.
    *arXiv 预印本 arXiv:2402.02172*.
- en: 'Trivedi et al. (2017) Priyansh Trivedi, Gaurav Maheshwari, Mohnish Dubey, and
    Jens Lehmann. 2017. [Lc-quad: A corpus for complex question answering over knowledge
    graphs](https://doi.org/https://doi.org/10.1007/978-3-319-68204-4_22). In *The
    Semantic Web – ISWC 2017*, pages 210–218, Cham. Springer International Publishing.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trivedi 等人（2017）Priyansh Trivedi, Gaurav Maheshwari, Mohnish Dubey, 和 Jens Lehmann.
    2017. [Lc-quad：一个用于知识图谱复杂问答的语料库](https://doi.org/https://doi.org/10.1007/978-3-319-68204-4_22).
    在 *The Semantic Web – ISWC 2017*，第 210–218 页，Cham. Springer International Publishing.
- en: Usbeck et al. (2018) Ricardo Usbeck, Ria Hari Gusmita, Axel-Cyrille Ngonga Ngomo,
    and Muhammad Saleem. 2018. [9th challenge on question answering over linked data
    (qald-9) (invited paper)](https://doi.org/https://api.semanticscholar.org/CorpusID:53220210).
    In *Semdeep/NLIWoD@ISWC*.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Usbeck 等人（2018）Ricardo Usbeck, Ria Hari Gusmita, Axel-Cyrille Ngonga Ngomo,
    和 Muhammad Saleem. 2018. [第九届基于链接数据的问答挑战（QALD-9）](https://doi.org/https://api.semanticscholar.org/CorpusID:53220210).
    在 *Semdeep/NLIWoD@ISWC*.
- en: Wang et al. (2023) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023. [A survey
    on large language model based autonomous agents](https://doi.org/https://doi.org/10.48550/arXiv.2308.11432).
    *arXiv preprint arXiv:2308.11432*.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023）Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin 等人. 2023. [基于大语言模型的自主代理调查](https://doi.org/https://doi.org/10.48550/arXiv.2308.11432).
    *arXiv 预印本 arXiv:2308.11432*.
- en: 'Wang et al. (2020) Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon
    Whiteson, and Chongjie Zhang. 2020. Rode: Learning roles to decompose multi-agent
    tasks. *arXiv preprint arXiv:2010.01523*.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2020）Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson,
    和 Chongjie Zhang. 2020. Rode：学习角色以分解多智能体任务. *arXiv 预印本 arXiv:2010.01523*.
- en: 'Yao et al. (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2023. [React: Synergizing reasoning and acting
    in language models](https://doi.org/https://doi.org/10.48550/arXiv.2210.03629).'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等人（2023）Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik
    Narasimhan, 和 Yuan Cao. 2023. [React: 协同推理与行动的语言模型](https://doi.org/https://doi.org/10.48550/arXiv.2210.03629).'
- en: Appendix A Response Time Analysis
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 响应时间分析
- en: 'We analyze various QA frameworks in response time to a question. The average
    latency of each phase including question parsing (QP), URI linking (UL), and answer
    generation (AG) for each knowledge base is reported. We randomly select 10 samples
    from each dataset for evaluation to obtain the average response times for Triad-1
    and Triad-3, which represent retrying three times and generating an answer in
    one go, respectively, during the answer generation phase. The comparison between
    traditional QA systems and Triad is shown in Figure [3](https://arxiv.org/html/2402.14320v6#A1.F3
    "Figure 3 ‣ Appendix A Response Time Analysis ‣ Triad: A Framework Leveraging
    a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"). Triad
    generally shows a competitive time-consuming performance to latest traditional
    QA systems. Specifically, compared to other phases, URL linking consumes more
    time due to the need to invoke LLM multiple times. Moreover, according to Section
    4.4, with smaller retry times of A-Agent, Triad can significantly reduce time
    cost while only causing slight performance degradation, revealing the advantages
    of our framework in balancing performance and efficiency.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '我们分析了各种问答框架在回答问题时的响应时间。报告了每个知识库中各阶段的平均延迟时间，包括问题解析（QP）、URI链接（UL）和答案生成（AG）。我们随机选择了每个数据集中的10个样本进行评估，以获得Triad-1和Triad-3的平均响应时间，这分别代表在答案生成阶段重试三次和一次性生成答案。传统问答系统与Triad的对比如图[3](https://arxiv.org/html/2402.14320v6#A1.F3
    "Figure 3 ‣ Appendix A Response Time Analysis ‣ Triad: A Framework Leveraging
    a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering")所示。总体而言，Triad在时间消耗上表现出与最新传统问答系统具有竞争力的表现。具体而言，与其他阶段相比，URL链接消耗了更多时间，因为需要多次调用LLM。此外，根据第4.4节，随着A-Agent的重试次数减少，Triad能够显著减少时间成本，同时只造成轻微的性能下降，揭示了我们框架在平衡性能和效率方面的优势。'
- en: '![Refer to caption](img/47cab0478ece17c2b31dd1062d310e52.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![参见图例](img/47cab0478ece17c2b31dd1062d310e52.png)'
- en: 'Figure 3: Response time of traditional KBQA systems and Triad on three datasets.
    Each bar shows average response time of a particular phase of KBQA.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：传统KBQA系统和Triad在三个数据集上的响应时间。每个条形图显示KBQA特定阶段的平均响应时间。
- en: Appendix B Role Performance on YAGO-QA
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B：YAGO-QA上的角色性能
- en: 'We choose LC-QuAD 1.0 and QALD-9 as our two representative datasets in Section
    4.3, as the questions among them vary in difficulty, and the tasks in these two
    datasets are relatively more challenging than YAGO-QA. We provide the performance
    of agent roles on YAGO-QA in Table [6](https://arxiv.org/html/2402.14320v6#A2.T6
    "Table 6 ‣ Appendix B Role Performance on YAGO-QA ‣ Triad: A Framework Leveraging
    a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"), which
    shows a consistent result with other datasets in Table [3](https://arxiv.org/html/2402.14320v6#S4.T3
    "Table 3 ‣ 4.3 Study on Capabilities of Agent Roles ‣ 4 Performance Evaluation
    ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering").'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在第4.3节中选择LC-QuAD 1.0和QALD-9作为我们的两个代表性数据集，因为它们之间的问题难度不同，而这两个数据集中的任务比YAGO-QA更具挑战性。我们在表[6](https://arxiv.org/html/2402.14320v6#A2.T6
    "Table 6 ‣ Appendix B Role Performance on YAGO-QA ‣ Triad: A Framework Leveraging
    a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering")中提供了在YAGO-QA上代理角色的表现，结果与表[3](https://arxiv.org/html/2402.14320v6#S4.T3
    "Table 3 ‣ 4.3 Study on Capabilities of Agent Roles ‣ 4 Performance Evaluation
    ‣ Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge
    Base Question Answering")中的其他数据集一致。'
- en: '| G-task | G-chat | YAGO-QA |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| G-task | G-chat | YAGO-QA |'
- en: '| ✗ | ✗ | 0.427 |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✗ | 0.427 |'
- en: '| ✓ | ✗ | 0.553 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.553 |'
- en: '| ✓ | ✓ | 0.677 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.677 |'
- en: '| D-uri | D-query | YAGO-QA |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| D-uri | D-query | YAGO-QA |'
- en: '| ✗ | ✓ | 0.346 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✓ | 0.346 |'
- en: '| ✓ | ✗ | 0.534 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.534 |'
- en: '| ✓ | ✓ | 0.677 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.677 |'
- en: '| A-llm | A-fact | YAGO-QA |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| A-llm | A-fact | YAGO-QA |'
- en: '| ✗ | ✗ | 0.626 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| ✗ | ✗ | 0.626 |'
- en: '| ✓ | ✗ | 0.647 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✗ | 0.647 |'
- en: '| ✓ | ✓ | 0.677 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | 0.677 |'
- en: 'Table 6: Performance of roles of LLM-based agent by eliminating an element
    or downgrading the capability.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：通过删除某个元素或降低能力来评估基于LLM的代理角色的性能。
- en: Appendix C Prompts Provided to LLMs of G-Agent for Solving Various Subtasks
    in KBQA
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C：为G-Agent提供的用于解决KBQA各子任务的提示
- en: 'The prompt given to LLMs of $Agent_{g}$ to perform triplet extraction from
    the question $Q$ is as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 给LLM的$Agent_{g}$用于从问题$Q$中提取三元组的提示如下：
- en: 'You are an assistant to identify triples within a provided sentence. Please
    adhere to the following guidelines: 1\. Triples should be structured in the format
    <entity1, relation, entity2>. 2\. The sentence must contain at least one triple,
    so you should provide at least one. 3\. Entities should represent the smallest
    semantic units and should not contain descriptive details. 4\. Entities can take
    the form of explicit or implicit references. Explicit entities refer to specific
    named resources, whereas implicit entities are less certain. 5\. When an entity
    is implicit, utilize a variable format such as ’?variable’ to denote it, for example,
    ’?location’ or ’?person’. Here are some examples: Which city’s founder is John
    Forbes? : <?city, foundeer, John Forbes> How many races have the horses bred by
    Jacques Van’t Hart participated in? : <?horse, participated in, ?race> <?horse,
    breeder, Jacques Van’t Hart> Is camel of the chordate phylum? : <camel, phylum,
    chordate> Sentence: <Question Sentence> Output:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责从提供的句子中识别三元组。请遵循以下指导方针：1\. 三元组应当按格式<entity1, relation, entity2>构造。2\.
    句子中必须包含至少一个三元组，因此你需要提供至少一个。3\. 实体应当表示最小的语义单位，不应包含描述性细节。4\. 实体可以是显式的或隐式的。显式实体指特定的命名资源，而隐式实体则较为不确定。5\.
    当实体是隐式的时，应使用变量格式，如’?variable’来表示，例如’?location’或’?person’。以下是一些示例：哪个城市的创始人是约翰·福布斯？：<?city,
    founder, John Forbes> 雅克·范特·哈特所培育的马匹参加了多少场比赛？：<?horse, participated in, ?race>
    <?horse, breeder, Jacques Van’t Hart> 骆驼属于脊索动物门吗？：<camel, phylum, chordate> 句子：<问题句子>
    输出：
- en: 'The prompt given to LLMs of $Agent_{g}$ for SPARQL template generation is as
    follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 提供给 $Agent_{g}$ 的 LLM 用于生成 SPARQL 模板的提示如下：
- en: 'You are an assistant to generate a SPARQL query to address a specific question.
    Here are the guidelines to follow: 1\. Ensure that the resulting SPARQL query
    is designed to answer the provided question. 2\. Adhere to the commonly accepted
    SPARQL standards when generating the query. 3\. Make an effort to leverage the
    information provided to assist in the creation of the SPARQL query. 4\. Strive
    to keep the generated SPARQL query as straightforward as possible. 5\. Avoid including
    ’PREFIX’ or ’:’ in the SPARQL query. 6\. Enclose condition entities and predicates
    within angle brackets, such as <entity> or <predicate>. 7\. Maintain the original
    order of the given triples without altering their sequence. Question: <question
    sentence> Triplets: <extracted triplets> Output:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责生成 SPARQL 查询以解决特定问题。请遵循以下指导方针：1\. 确保生成的 SPARQL 查询能够回答所提供的问题。2\. 在生成查询时遵循常见的
    SPARQL 标准。3\. 努力利用提供的信息来帮助生成 SPARQL 查询。4\. 尽量保持生成的 SPARQL 查询尽可能简洁。5\. 避免在 SPARQL
    查询中包含’PREFIX’或’：’。6\. 将条件实体和谓词用尖括号括起来，如<entity>或<predicate>。7\. 保持给定三元组的原始顺序，不要改变其顺序。问题：<问题句子>
    三元组：<提取的三元组> 输出：
- en: 'The prompt given to LLMs of $Agent_{g}$ for question type classification is
    as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 提供给 $Agent_{g}$ 的 LLM 问题类型分类提示如下：
- en: 'You are an assistant to determine the specific type of a given question according
    to the following guidelines: 1\. You must determine the most probable question
    type for the input question. 2\. The type of question should be enclosed within
    angle brackets, denoted as ’<’ and ’>’. 3\. Possible question types include: <count>,
    <select>, and <yes or no>. Question: <question sentence> Output:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责根据以下指导方针确定给定问题的具体类型：1\. 你必须确定输入问题的最可能问题类型。2\. 问题类型应当用尖括号括起来，表示为’<’和’>’。3\.
    可能的问题类型包括：<count>、<select> 和 <yes or no>。问题：<问题句子> 输出：
- en: Appendix D Prompts Provided to LLMs of D-Agent for Solving Selection Subtasks
    in KBQA
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 提供给 D-Agent 的提示，用于解决 KBQA 中的选择子任务
- en: 'The prompt given to LLMs of $Agent_{d}$ for candidate entities selection is
    as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 提供给 $Agent_{d}$ 的 LLM 用于候选实体选择的提示如下：
- en: 'You are an assistant to select <K> URIs from a provided list of possible URIs
    for a specified entity, following these guidelines: 1\. Identify the <K> most
    appropriate URIs from the given list that best represent the entity in question.
    2\. Seek to understand the semantic information associated with the specified
    entity by examining the provided question. 3\. The output should consist of <K>
    URIs chosen from the provided list of possible URIs. 4\. Simply output these <K>
    target URIs, each on a separate line, without providing any additional explanations.
    Sentence: <question sentence> Entity: <entity mention> Possible entity URIs: <Entity
    URI list> Output:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责从提供的可能URI列表中选择<K>个URI，代表指定实体，遵循以下指导原则：1\. 从给定列表中识别出最合适的<K>个URI，最好能代表相关实体。2\.
    通过检查提供的问题，理解与指定实体相关的语义信息。3\. 输出应包含从提供的可能URI列表中选择的<K>个URI。4\. 仅输出这些<K>个目标URI，每个单独一行，不提供任何额外解释。句子：<question
    sentence> 实体：<entity mention> 可能的实体URI：<Entity URI list> 输出：
- en: 'The prompt given to LLMs of $Agent_{d}$ for candidate relation selection is
    as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 给定给$Agent_{d}$的提示，用于候选关系选择如下：
- en: 'You are an assistant tasked with selecting the <K> relation URIs between entities
    mentioned in a sentence. Here are the guidelines: 1\. The two entities are listed
    one after the other, without a specific order. 2\. Use the provided sentence to
    discern the semantic meaning of these entities. 3\. The potential relation URIs
    are listed one by one. 4\. Your output should consist of a maximum of <K> possible
    relation URIs, although you may also output fewer if appropriate. 5\. Ensure that
    your output is organized, prioritizing the most likely relationship first. 6\.
    Provide a list of no more than <K> relation URIs (each on a separate line if there
    are multiple) without any additional descriptions. Sentence: <question sentence>
    Entities: <entity pair> Possible relation URIs: <URI list> Output:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责选择句子中提到的实体之间的<K>关系URI。以下是指导原则：1\. 两个实体没有特定顺序，依次列出。2\. 使用提供的句子来判断这些实体的语义含义。3\.
    潜在的关系URI逐个列出。4\. 你的输出应包含最多<K>个可能的关系URI，但如果合适，你也可以输出更少。5\. 确保你的输出是有组织的，优先列出最可能的关系。6\.
    提供不超过<K>个关系URI的列表（如果有多个，每个都单独列出），且不附加任何额外描述。句子：<question sentence> 实体：<entity
    pair> 可能的关系URI：<URI list> 输出：
- en: 'The prompt given to LLMs of $Agent_{d}$ for the final SPARQL selection is as
    follows:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 给定给$Agent_{d}$的提示，用于最终的SPARQL选择如下：
- en: 'You are an assistant to select an appropriate SPARQL query from the provided
    list in order to respond to a specific question. Please adhere to the following
    guidelines: 1\. Select the most suitable SPARQL query from the given query list
    to address the question. 2\. Select a SPARQL query solely from the provided list;
    avoid crafting your own SPARQL query. 3\. The selected SPARQL query must be applicable
    to answer the given question. Sentence: <question sentence> SPARQL candidates:
    <SPARQLs to choose> Output:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个助手，负责从提供的查询列表中选择一个适当的SPARQL查询，以回答特定问题。请遵循以下指导原则：1\. 从给定的查询列表中选择最合适的SPARQL查询来回答问题。2\.
    仅从提供的查询列表中选择SPARQL查询，避免自己编写SPARQL查询。3\. 选择的SPARQL查询必须适用于回答给定的问题。句子：<question sentence>
    SPARQL候选：<SPARQLs to choose> 输出：
- en: Appendix E Prompts Provided to LLMs of A-Agent for Solving Answering Subtask
    in KBQA
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 提供给A-Agent的提示，用于解决KBQA中的回答子任务
- en: 'The prompt given to LLMs of $Agent_{a}$ to generate a yes or no answer for
    the give question is as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 给定给$Agent_{a}$的提示，用于生成给定问题的是或否回答如下：
- en: 'You are an assistant to answer a yes-or-no question. Please adhere to the following
    guidelines: 1\. If you believe that the answer is yes, provide an output of ’True’.
    If not, provide an output of ’False’. 2\. Please do not include additional information
    or explanations in your response. Sentence: <question sentence> Output:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个用于回答是或否问题的助手。请遵循以下指导原则：1\. 如果你认为答案是“是”，请输出“True”。如果不是，输出“False”。2\. 请不要在回答中包含额外的信息或解释。句子：<question
    sentence> 输出：
- en: 'The prompt given to LLMs of $Agent_{a}$ to generate a single-fact answer for
    the give question is as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 给定给$Agent_{a}$的提示，用于生成给定问题的单一事实回答如下：
- en: 'You are an assistant to answer a question. Please adhere to the following guidelines:
    1\. The answer to the question is a single entity. 2\. You should just output
    the full expression of the answer without any punctuation. 3\. Do not output any
    other description. Sentence: <question sentence> Output:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一个回答问题的助手。请遵循以下准则：1\. 问题的答案是一个单一的实体。2\. 你应该只输出答案的完整表达式，不加任何标点符号。3\. 不要输出任何其他描述。句子：<question
    sentence> 输出：
