- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»ï¼šæœªåˆ†ç±»
- en: 'date: 2025-01-11 13:06:10'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2025-01-11 13:06:10
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'SurrealDriver: Designing LLM-powered Generative Driver Agent Framework based
    on Human Driversâ€™ Driving-thinking Data'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SurrealDriverï¼šåŸºäºäººç±»é©¾é©¶å‘˜é©¾é©¶æ€ç»´æ•°æ®è®¾è®¡çš„LLMé©±åŠ¨ç”Ÿæˆä»£ç†æ¡†æ¶
- en: æ¥æºï¼š[https://arxiv.org/html/2309.13193/](https://arxiv.org/html/2309.13193/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://arxiv.org/html/2309.13193/](https://arxiv.org/html/2309.13193/)
- en: Ye Jin, Ruoxuan Yang, Zhijie Yi, Xiaoxi Shen, Huiling Peng, Xiaoan Liu, Jingli
    Qin,
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¶é‡‘ï¼Œæ¨è‹¥è½©ï¼Œæ˜“æ™ºæ°ï¼Œæ²ˆæ™“ç†™ï¼Œå½­æ…§ç²ï¼Œåˆ˜å°å®‰ï¼Œç§¦é™è‰ï¼Œ
- en: 'Jiayang Li, Jintao Xie, Peizhong Gao, Guyue Zhou and Jiangtao Gong^(ğŸ–‚) The
    authors are with the Institute for AI Industry Research, Tsinghua University,
    Beijing, China. Corresponding Email: gongjiangtao@air.tsinghua.edu.cn'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æå®¶æ‰¬ï¼Œè°¢åŠ²æ¶›ï¼Œé«˜ä½©ä¸­ï¼Œå‘¨é¡¾æ‚¦ï¼Œé¾šæ±Ÿæ¶›^(ğŸ–‚) ä½œè€…æ¥è‡ªæ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢ï¼ŒåŒ—äº¬ï¼Œä¸­å›½ã€‚é€šè®¯é‚®ç®±ï¼šgongjiangtao@air.tsinghua.edu.cn
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: Leveraging advanced reasoning capabilities and extensive world knowledge of
    large language models (LLMs) to construct generative agents for solving complex
    real-world problems is a major trend. However, LLMs inherently lack embodiment
    as humans, resulting in suboptimal performance in many embodied decision-making
    tasks. In this paper, we introduce a framework for building human-like generative
    driving agents using post-driving self-report driving-thinking data from human
    drivers as both demonstration and feedback. To capture high-quality, natural language
    data from drivers, we conducted urban driving experiments, recording driversâ€™
    verbalized thoughts under various conditions to serve as chain-of-thought prompts
    and demonstration examples for the LLM-Agent. The frameworkâ€™s effectiveness was
    evaluated through simulations and human assessments. Results indicate that incorporating
    expert demonstration data significantly reduced collision rates by 81.04% and
    increased human likeness by 50% compared to a baseline LLM-based agent. Our study
    provides insights into using natural language-based human demonstration data for
    embodied tasks. The driving-thinking dataset is available at https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é«˜çº§æ¨ç†èƒ½åŠ›å’Œå¹¿æ³›çš„ä¸–ç•ŒçŸ¥è¯†æ¥æ„å»ºç”Ÿæˆä»£ç†ï¼Œç”¨äºè§£å†³å¤æ‚çš„ç°å®ä¸–ç•Œé—®é¢˜ï¼Œæ˜¯å½“å‰çš„ä¸»è¦è¶‹åŠ¿ã€‚ç„¶è€Œï¼ŒLLMæœ¬èº«ç¼ºä¹ç±»ä¼¼äººç±»çš„å…·è±¡åŒ–èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨è®¸å¤šå…·è±¡åŒ–å†³ç­–ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸å°½å¦‚äººæ„ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ„å»ºç±»äººç”Ÿæˆé©¾é©¶ä»£ç†çš„æ¡†æ¶ï¼Œä½¿ç”¨æ¥è‡ªäººç±»é©¾é©¶å‘˜çš„é©¾é©¶åè‡ªæŠ¥å‘Šé©¾é©¶æ€ç»´æ•°æ®ä½œä¸ºç¤ºèŒƒå’Œåé¦ˆã€‚ä¸ºäº†æ•æ‰æ¥è‡ªé©¾é©¶å‘˜çš„é«˜è´¨é‡è‡ªç„¶è¯­è¨€æ•°æ®ï¼Œæˆ‘ä»¬è¿›è¡Œäº†åŸå¸‚é©¾é©¶å®éªŒï¼Œè®°å½•äº†é©¾é©¶å‘˜åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„å£å¤´æ€ç»´ï¼Œä»¥ä½œä¸ºLLMä»£ç†çš„æ€ç»´é“¾æç¤ºå’Œç¤ºèŒƒç¤ºä¾‹ã€‚è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§é€šè¿‡ä»¿çœŸå’Œäººå·¥è¯„ä¼°è¿›è¡Œäº†éªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œä¸åŸºäºLLMçš„åŸºå‡†ä»£ç†ç›¸æ¯”ï¼ŒåŠ å…¥ä¸“å®¶ç¤ºèŒƒæ•°æ®æ˜¾è‘—å°†ç¢°æ’ç‡é™ä½äº†81.04%ï¼Œå¹¶ä½¿ç±»äººç¨‹åº¦æé«˜äº†50%ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºåˆ©ç”¨åŸºäºè‡ªç„¶è¯­è¨€çš„äººç±»ç¤ºèŒƒæ•°æ®å¤„ç†å…·è±¡ä»»åŠ¡æä¾›äº†å¯ç¤ºã€‚é©¾é©¶æ€ç»´æ•°æ®é›†å¯åœ¨[https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset](https://github.com/AIR-DISCOVER/Driving-Thinking-Dataset)è·å–ã€‚
- en: I INTRODUCTION
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I å¼•è¨€
- en: Recently, remarkable advancements have been achieved in large language models
    (LLMs) known for their zero-shot prompting and common sense reasoning capabilitiesÂ [[1](https://arxiv.org/html/2309.13193v2#bib.bib1),
    [2](https://arxiv.org/html/2309.13193v2#bib.bib2), [3](https://arxiv.org/html/2309.13193v2#bib.bib3),
    [4](https://arxiv.org/html/2309.13193v2#bib.bib4), [5](https://arxiv.org/html/2309.13193v2#bib.bib5)].
    In addition to natural language tasks, LLMs, when equipped with specific sensory
    and control modulesÂ [[6](https://arxiv.org/html/2309.13193v2#bib.bib6), [7](https://arxiv.org/html/2309.13193v2#bib.bib7)],
    can act as the decision-making core in executing embodied tasks, such as robotics
    and autonomous drivingÂ [[8](https://arxiv.org/html/2309.13193v2#bib.bib8), [9](https://arxiv.org/html/2309.13193v2#bib.bib9),
    [10](https://arxiv.org/html/2309.13193v2#bib.bib10)]. Previous research has validated
    the effectiveness of LLMsâ€™ advanced reasoning and extensive knowledge in embodied
    tasksÂ [[9](https://arxiv.org/html/2309.13193v2#bib.bib9), [10](https://arxiv.org/html/2309.13193v2#bib.bib10)],
    but has also highlighted limitations in complex scenarios, like generating implausible
    sequencesÂ [[11](https://arxiv.org/html/2309.13193v2#bib.bib11), [12](https://arxiv.org/html/2309.13193v2#bib.bib12)]
    and a lack of operational experienceÂ [[13](https://arxiv.org/html/2309.13193v2#bib.bib13)].
    However, traditional demonstrations of embodied tasks are seldom suitable as examples
    for few-shot learning. Current approaches primarily involve adjusting or constraining
    the LLMâ€™s task scopeÂ [[12](https://arxiv.org/html/2309.13193v2#bib.bib12)] and
    enabling the LLM Agent to independently accumulate experience through environmental
    interactionsÂ [[13](https://arxiv.org/html/2309.13193v2#bib.bib13), [14](https://arxiv.org/html/2309.13193v2#bib.bib14)].
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼ŒåŸºäºé›¶-shotæç¤ºå’Œå¸¸è¯†æ¨ç†èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•[[1](https://arxiv.org/html/2309.13193v2#bib.bib1),
    [2](https://arxiv.org/html/2309.13193v2#bib.bib2), [3](https://arxiv.org/html/2309.13193v2#bib.bib3),
    [4](https://arxiv.org/html/2309.13193v2#bib.bib4), [5](https://arxiv.org/html/2309.13193v2#bib.bib5)]ã€‚é™¤äº†è‡ªç„¶è¯­è¨€ä»»åŠ¡å¤–ï¼Œå½“é…å¤‡äº†ç‰¹å®šçš„æ„ŸçŸ¥å’Œæ§åˆ¶æ¨¡å—[[6](https://arxiv.org/html/2309.13193v2#bib.bib6),
    [7](https://arxiv.org/html/2309.13193v2#bib.bib7)]ï¼ŒLLMsè¿˜èƒ½ä½œä¸ºæ‰§è¡Œå…·èº«ä»»åŠ¡ï¼ˆå¦‚æœºå™¨äººå’Œè‡ªåŠ¨é©¾é©¶ï¼‰çš„å†³ç­–æ ¸å¿ƒ[[8](https://arxiv.org/html/2309.13193v2#bib.bib8),
    [9](https://arxiv.org/html/2309.13193v2#bib.bib9), [10](https://arxiv.org/html/2309.13193v2#bib.bib10)]ã€‚å…ˆå‰çš„ç ”ç©¶éªŒè¯äº†LLMsåœ¨å…·èº«ä»»åŠ¡ä¸­å…ˆè¿›æ¨ç†å’Œå¹¿æ³›çŸ¥è¯†çš„æœ‰æ•ˆæ€§[[9](https://arxiv.org/html/2309.13193v2#bib.bib9),
    [10](https://arxiv.org/html/2309.13193v2#bib.bib10)]ï¼Œä½†ä¹Ÿçªå‡ºäº†åœ¨å¤æ‚åœºæ™¯ä¸­çš„å±€é™æ€§ï¼Œä¾‹å¦‚ç”Ÿæˆä¸åˆç†çš„åºåˆ—[[11](https://arxiv.org/html/2309.13193v2#bib.bib11),
    [12](https://arxiv.org/html/2309.13193v2#bib.bib12)]ä»¥åŠç¼ºä¹æ“ä½œç»éªŒ[[13](https://arxiv.org/html/2309.13193v2#bib.bib13)]ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„å…·èº«ä»»åŠ¡ç¤ºèŒƒå¾€å¾€ä¸é€‚åˆä½œä¸ºå°‘é‡ç¤ºèŒƒå­¦ä¹ çš„ä¾‹å­ã€‚ç›®å‰çš„æ–¹æ³•ä¸»è¦åŒ…æ‹¬è°ƒæ•´æˆ–é™åˆ¶LLMçš„ä»»åŠ¡èŒƒå›´[[12](https://arxiv.org/html/2309.13193v2#bib.bib12)]ï¼Œå¹¶é€šè¿‡ä¸ç¯å¢ƒçš„äº’åŠ¨ä½¿LLM
    Agentç‹¬ç«‹ç§¯ç´¯ç»éªŒ[[13](https://arxiv.org/html/2309.13193v2#bib.bib13), [14](https://arxiv.org/html/2309.13193v2#bib.bib14)]ã€‚
- en: In the context of autonomous driving, agents analyze multimodal data, such as
    vectorsÂ [[15](https://arxiv.org/html/2309.13193v2#bib.bib15)] and imagesÂ [[16](https://arxiv.org/html/2309.13193v2#bib.bib16)],
    to make end-to-end driving decisions, demonstrated by projects like Driving with
    LLMsÂ [[15](https://arxiv.org/html/2309.13193v2#bib.bib15)] and DriveGPT4Â [[16](https://arxiv.org/html/2309.13193v2#bib.bib16)].
    Compared to traditional fine-tuning, prompt-based methods with LLMs offer cost-effective
    and generalizable solutionsÂ [[17](https://arxiv.org/html/2309.13193v2#bib.bib17)].
    Approaches like Drive As You SpeakÂ [[18](https://arxiv.org/html/2309.13193v2#bib.bib18)]
    and DiLuÂ [[19](https://arxiv.org/html/2309.13193v2#bib.bib19)] integrate memory
    for coherent decision-making, and Drive Like a HumanÂ [[20](https://arxiv.org/html/2309.13193v2#bib.bib20)]
    incorporate expert feedback to enhance performance. However, these so-called human-like
    driving behaviors primarily rely on the human common sense inherent in LLMs. LLMs
    acquire this common sense non-embodiedly from the noisy text corpus of the internet,
    lacking integration of professional, task-specific human data for embodied tasksÂ [[21](https://arxiv.org/html/2309.13193v2#bib.bib21)].
    For LLM-based agents, employing human demonstrationsÂ [[22](https://arxiv.org/html/2309.13193v2#bib.bib22)]
    and feedbackÂ [[23](https://arxiv.org/html/2309.13193v2#bib.bib23)] for reinforcement
    learning in embodied tasks such as driving proves prohibitively expensive. A persistent
    challenge in this field is the lack of high-quality demonstrations and supervised
    human data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è‡ªåŠ¨é©¾é©¶èƒŒæ™¯ä¸‹ï¼Œä»£ç†åˆ†æå¤šæ¨¡æ€æ•°æ®ï¼Œå¦‚å‘é‡[[15](https://arxiv.org/html/2309.13193v2#bib.bib15)]å’Œå›¾åƒ[[16](https://arxiv.org/html/2309.13193v2#bib.bib16)]ï¼Œä»¥åšå‡ºç«¯åˆ°ç«¯çš„é©¾é©¶å†³ç­–ï¼Œä½“ç°äº†â€œé©¾é©¶ä¸LLMsâ€[[15](https://arxiv.org/html/2309.13193v2#bib.bib15)]å’Œâ€œDriveGPT4â€[[16](https://arxiv.org/html/2309.13193v2#bib.bib16)]ç­‰é¡¹ç›®ã€‚ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æç¤ºæ–¹æ³•æä¾›äº†å…·æœ‰æˆæœ¬æ•ˆç›Šä¸”å¯æ¨å¹¿çš„è§£å†³æ–¹æ¡ˆ[[17](https://arxiv.org/html/2309.13193v2#bib.bib17)]ã€‚åƒâ€œDrive
    As You Speakâ€[[18](https://arxiv.org/html/2309.13193v2#bib.bib18)]å’Œâ€œDiLuâ€[[19](https://arxiv.org/html/2309.13193v2#bib.bib19)]ç­‰æ–¹æ³•é€šè¿‡æ•´åˆè®°å¿†æ¥å®ç°è¿è´¯çš„å†³ç­–ï¼Œè€Œâ€œDrive
    Like a Humanâ€[[20](https://arxiv.org/html/2309.13193v2#bib.bib20)]åˆ™é€šè¿‡å¼•å…¥ä¸“å®¶åé¦ˆæ¥å¢å¼ºæ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ‰€è°“çš„ç±»äººé©¾é©¶è¡Œä¸ºä¸»è¦ä¾èµ–äºå¤§è¯­è¨€æ¨¡å‹ä¸­å›ºæœ‰çš„äººç±»å¸¸è¯†ã€‚å¤§è¯­è¨€æ¨¡å‹ä»äº’è”ç½‘çš„å™ªå£°æ–‡æœ¬è¯­æ–™åº“ä¸­éå…·è±¡åœ°è·å¾—è¿™äº›å¸¸è¯†ï¼Œç¼ºä¹å°†ä¸“ä¸šçš„ã€ä»»åŠ¡ç‰¹å®šçš„äººç±»æ•°æ®èå…¥åˆ°å…·è±¡ä»»åŠ¡ä¸­çš„èƒ½åŠ›[[21](https://arxiv.org/html/2309.13193v2#bib.bib21)]ã€‚å¯¹äºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»£ç†æ¥è¯´ï¼Œåœ¨å…·è±¡ä»»åŠ¡ï¼ˆå¦‚é©¾é©¶ï¼‰ä¸­ä½¿ç”¨äººç±»æ¼”ç¤º[[22](https://arxiv.org/html/2309.13193v2#bib.bib22)]å’Œåé¦ˆ[[23](https://arxiv.org/html/2309.13193v2#bib.bib23)]è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œæˆæœ¬è¿‡é«˜ã€‚è¯¥é¢†åŸŸçš„ä¸€ä¸ªæŒç»­æŒ‘æˆ˜æ˜¯ç¼ºä¹é«˜è´¨é‡çš„æ¼”ç¤ºå’Œç›‘ç£æ€§äººç±»æ•°æ®ã€‚
- en: 'To this end, in this paper, we innovatively leverage post-driving self-reports
    from human drivers, analyzing their thought processes as chain-of-thought prompts
    to enhance driving performance and human alignment in LLM-based agents. This approach
    offers new insights for aligning LLM-based agents with human drivers in embodied
    driving tasks. We collected post-driving self-reports from 24 real-world drivers,
    detailing their considerations and decision-making processes during driving. We
    then designed â€™SurrealDriver,â€™ an LLM-based framework for urban driving, grounded
    in four design considerations: a basic driving pipeline, a safety and memory mechanism,
    and human-aligned long-term driving guidelines, informed by demonstrations of
    human driving thought processes. Our framework was evaluated through simulation
    experiments and human assessments, confirming its design efficiency.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæœ¬æ–‡åˆ›æ–°æ€§åœ°åˆ©ç”¨äº†äººç±»é©¾é©¶å‘˜çš„é©¾é©¶åè‡ªæˆ‘æŠ¥å‘Šï¼Œåˆ†æä»–ä»¬çš„æ€ç»´è¿‡ç¨‹ä½œä¸ºé“¾å¼æ€ç»´æç¤ºï¼Œä»¥å¢å¼ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»£ç†çš„é©¾é©¶æ€§èƒ½å’Œä¸äººç±»çš„å¯¹é½ã€‚è¿™ä¸€æ–¹æ³•ä¸ºå°†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»£ç†ä¸äººç±»é©¾é©¶å‘˜å¯¹é½æä¾›äº†æ–°çš„è§†è§’ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·è±¡çš„é©¾é©¶ä»»åŠ¡ä¸­ã€‚æˆ‘ä»¬æ”¶é›†äº†24ä½ç°å®ä¸–ç•Œé©¾é©¶å‘˜çš„é©¾é©¶åè‡ªæˆ‘æŠ¥å‘Šï¼Œè¯¦ç»†æè¿°äº†ä»–ä»¬åœ¨é©¾é©¶è¿‡ç¨‹ä¸­æ‰€è€ƒè™‘çš„å› ç´ å’Œå†³ç­–è¿‡ç¨‹ã€‚éšåï¼Œæˆ‘ä»¬è®¾è®¡äº†â€œSurrealDriverâ€â€”â€”ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŸå¸‚é©¾é©¶æ¡†æ¶ï¼ŒåŸºäºå››ä¸ªè®¾è®¡è€ƒè™‘å› ç´ ï¼šåŸºæœ¬é©¾é©¶æµç¨‹ã€å®‰å…¨æ€§å’Œè®°å¿†æœºåˆ¶ï¼Œä»¥åŠé€šè¿‡äººç±»é©¾é©¶æ€ç»´è¿‡ç¨‹çš„æ¼”ç¤ºæ¥æŒ‡å¯¼çš„é•¿æœŸé©¾é©¶å‡†åˆ™ã€‚é€šè¿‡ä»¿çœŸå®éªŒå’Œäººå·¥è¯„ä¼°ï¼Œæˆ‘ä»¬å¯¹æ¡†æ¶è¿›è¡Œäº†è¯„ä¼°ï¼ŒéªŒè¯äº†å…¶è®¾è®¡çš„é«˜æ•ˆæ€§ã€‚
- en: 'Therefore, the contributions of this paper are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæœ¬æ–‡çš„è´¡çŒ®å¦‚ä¸‹ï¼š
- en: â€¢
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: The first high-quality human driversâ€™ natural language-type driving-thinking
    dataset collected through an urban driving experiment;
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é€šè¿‡åŸå¸‚é©¾é©¶å®éªŒæ”¶é›†çš„é¦–ä¸ªé«˜è´¨é‡äººç±»é©¾é©¶å‘˜è‡ªç„¶è¯­è¨€ç±»å‹çš„é©¾é©¶æ€ç»´æ•°æ®é›†ï¼›
- en: â€¢
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: A generative driver agent framework designed based on LLMs with human driversâ€™
    driving-thinking data as chain-of-thought prompts and implemented in Carla Simulator;
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®¾è®¡çš„ç”Ÿæˆå‹é©¾é©¶ä»£ç†æ¡†æ¶ï¼Œä»¥äººç±»é©¾é©¶å‘˜çš„é©¾é©¶æ€ç»´æ•°æ®ä½œä¸ºé“¾å¼æ€ç»´æç¤ºï¼Œå¹¶åœ¨Carla Simulatorä¸­å®ç°ï¼›
- en: â€¢
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€¢
- en: An empirical validation of the effectiveness of our framework through simulation
    ablation experiments and human evaluation.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»¿çœŸæ¶ˆèå®éªŒå’Œäººå·¥è¯„ä¼°ï¼Œå¯¹æˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§è¿›è¡Œäº†å®è¯éªŒè¯ã€‚
- en: II Driving-thinking Dataset
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II é©¾é©¶æ€ç»´æ•°æ®é›†
- en: II-A Driving Experiment and data collections
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A é©¾é©¶å®éªŒä¸æ•°æ®æ”¶é›†
- en: To collect high-quality human driversâ€™ language-type demonstration data, we
    invited 24 drivers (10 expert drivers and 14 novice drivers) to this driving-thinking
    Data collection session. Ten expert drivers were recruited through a formal career
    recruitment platform. They had extensive driving experience, ranging from 12 to
    28 years, and their ages ranged from 35 to 48 years (M = 39.9, SD = 4.18). Novice
    drivers were recruited through social media, resulting in a group of 14 individuals
    aged between 20 and 25 years (M = 21.93, SD =1.49), with driving experience ranging
    from 1 to 4 years. This study was approved by the Institutional Review Board of
    the authorsâ€™ institution. Before the experiment, all participants were ensured
    informed consent, acknowledging potential risks and their right to discontinue
    the study. To preserve participant confidentiality, all personal and confidential
    information has been anonymized, and the research results presented below have
    been subjected to de-identification.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ”¶é›†é«˜è´¨é‡çš„é©¾é©¶å‘˜è¯­è¨€ç±»å‹ç¤ºèŒƒæ•°æ®ï¼Œæˆ‘ä»¬é‚€è¯·äº†24åé©¾é©¶å‘˜ï¼ˆ10åä¸“å®¶é©¾é©¶å‘˜å’Œ14åæ–°æ‰‹é©¾é©¶å‘˜ï¼‰å‚ä¸æ­¤æ¬¡é©¾é©¶æ€ç»´æ•°æ®æ”¶é›†ç¯èŠ‚ã€‚10åä¸“å®¶é©¾é©¶å‘˜é€šè¿‡æ­£å¼çš„èŒä¸šæ‹›è˜å¹³å°æ‹›å‹Ÿï¼Œä»–ä»¬æ‹¥æœ‰ä¸°å¯Œçš„é©¾é©¶ç»éªŒï¼Œç»éªŒå¹´é™ä»12å¹´åˆ°28å¹´ä¸ç­‰ï¼Œå¹´é¾„ä»35å²åˆ°48å²ï¼ˆM
    = 39.9, SD = 4.18ï¼‰ã€‚æ–°æ‰‹é©¾é©¶å‘˜åˆ™é€šè¿‡ç¤¾äº¤åª’ä½“æ‹›å‹Ÿï¼Œç»“æœç»„æˆäº†ä¸€ä¸ª14äººçš„å°ç»„ï¼Œå¹´é¾„ä»‹äº20å²è‡³25å²ä¹‹é—´ï¼ˆM = 21.93, SD =
    1.49ï¼‰ï¼Œé©¾é©¶ç»éªŒèŒƒå›´ä¸º1å¹´åˆ°4å¹´ã€‚è¯¥ç ”ç©¶è·å¾—äº†ä½œè€…æ‰€åœ¨æœºæ„çš„ä¼¦ç†å§”å‘˜ä¼šæ‰¹å‡†ã€‚åœ¨å®éªŒå‰ï¼Œæ‰€æœ‰å‚ä¸è€…éƒ½å·²ç¡®ä¿çŸ¥æƒ…åŒæ„ï¼Œç¡®è®¤äº†æ½œåœ¨é£é™©å¹¶çŸ¥æ™“ä»–ä»¬æœ‰æƒéšæ—¶ä¸­æ­¢ç ”ç©¶ã€‚ä¸ºäº†ä¿æŠ¤å‚ä¸è€…çš„éšç§ï¼Œæ‰€æœ‰ä¸ªäººå’Œæœºå¯†ä¿¡æ¯å‡å·²åŒ¿ååŒ–ï¼Œä»¥ä¸‹å‘ˆç°çš„ç ”ç©¶ç»“æœå·²ç»è¿‡å»èº«ä»½è¯†åˆ«å¤„ç†ã€‚
- en: To ensure the consistency between the collected natural language demonstrations
    and actual driving behaviors, we first had them participate in an actual complex
    urban road driving experiment and then we conducted post-driving interviews to
    collect their thinking-aloud data for safety reasons. For reviewing the driving
    experiment details in interview sessions, we recorded the driving process using
    multiple in-car cameras, including the driverâ€™s eye-tracking device (Tobii Glass
    3Â¹Â¹1https://www.tobii.com/products/eye-trackers/wearables/tobii-pro-glasses-3),
    roof-mounted 360-degree panoramic camera (Insta360 X3Â²Â²2https://www.insta360.com/product/insta360-x3),
    and in-car motion camera (Dji OSMO Action 3Â³Â³3https://store.dji.com/hk-en/product/osmo-action-3).
    During the interviews, the drivers vocalized their decision-making process behind
    each driving behaviour as they reviewed the recorded footage. Besides, drivers
    were asked to contemplate the potential reasons behind their judgments and driving
    actions in complex driving scenarios during the experiment.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¡®ä¿æ”¶é›†åˆ°çš„è‡ªç„¶è¯­è¨€ç¤ºèŒƒä¸å®é™…é©¾é©¶è¡Œä¸ºä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬é¦–å…ˆè®©é©¾é©¶å‘˜å‚ä¸äº†å®é™…çš„å¤æ‚åŸå¸‚é“è·¯é©¾é©¶å®éªŒï¼Œç„¶åå‡ºäºå®‰å…¨è€ƒè™‘ï¼Œæˆ‘ä»¬è¿›è¡Œäº†é©¾é©¶åè®¿è°ˆï¼Œæ”¶é›†ä»–ä»¬çš„æ€ç»´è¿‡ç¨‹æ•°æ®ã€‚åœ¨è®¿è°ˆè¿‡ç¨‹ä¸­å›é¡¾é©¾é©¶å®éªŒç»†èŠ‚æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šå°è½¦è½½æ‘„åƒå¤´è®°å½•äº†é©¾é©¶è¿‡ç¨‹ï¼ŒåŒ…æ‹¬é©¾é©¶å‘˜çš„çœ¼åŠ¨è¿½è¸ªè®¾å¤‡ï¼ˆTobii
    Glass 3Â¹Â¹1https://www.tobii.com/products/eye-trackers/wearables/tobii-pro-glasses-3ï¼‰ã€è½¦é¡¶å®‰è£…çš„360åº¦å…¨æ™¯æ‘„åƒå¤´ï¼ˆInsta360
    X3Â²Â²2https://www.insta360.com/product/insta360-x3ï¼‰ä»¥åŠè½¦å†…è¿åŠ¨æ‘„åƒå¤´ï¼ˆDji OSMO Action 3Â³Â³3https://store.dji.com/hk-en/product/osmo-action-3ï¼‰ã€‚åœ¨è®¿è°ˆè¿‡ç¨‹ä¸­ï¼Œé©¾é©¶å‘˜åœ¨å›é¡¾å½•åˆ¶çš„å½±åƒæ—¶ï¼Œé˜è¿°äº†æ¯ä¸ªé©¾é©¶è¡Œä¸ºèƒŒåçš„å†³ç­–è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œé©¾é©¶å‘˜è¢«è¦æ±‚åœ¨å®éªŒè¿‡ç¨‹ä¸­æ€è€ƒå¤æ‚é©¾é©¶åœºæ™¯ä¸­è‡ªå·±åˆ¤æ–­å’Œé©¾é©¶è¡Œä¸ºèƒŒåçš„æ½œåœ¨åŸå› ã€‚
- en: II-B Data Analysis and Dataset Construction
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B æ•°æ®åˆ†æä¸æ•°æ®é›†æ„å»º
- en: Our data consists of 24 driver interview videos, with a duration ranging from
    1.5 to 2 hours. We transcribed the audio recordings into written documents and
    organized the participantsâ€™ descriptions of their driving decision processes for
    each scenario encountered during the experiments. Each participantâ€™s data was
    processed by two to three trained coders, and a coding consistency check was performed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ•°æ®åŒ…æ‹¬24æ®µé©¾é©¶å‘˜è®¿è°ˆè§†é¢‘ï¼Œæ—¶é•¿ä¸º1.5å°æ—¶è‡³2å°æ—¶ä¸ç­‰ã€‚æˆ‘ä»¬å°†éŸ³é¢‘å½•éŸ³è½¬å½•æˆä¹¦é¢æ–‡æ¡£ï¼Œå¹¶æ•´ç†äº†å‚ä¸è€…æè¿°ä»–ä»¬åœ¨å®éªŒä¸­é‡åˆ°çš„æ¯ä¸ªåœºæ™¯çš„é©¾é©¶å†³ç­–è¿‡ç¨‹çš„æ•°æ®ã€‚æ¯ä½å‚ä¸è€…çš„æ•°æ®ç”±ä¸¤åˆ°ä¸‰åè®­ç»ƒæœ‰ç´ çš„ç¼–ç å‘˜å¤„ç†ï¼Œå¹¶è¿›è¡Œäº†ç¼–ç ä¸€è‡´æ€§æ£€æŸ¥ã€‚
- en: From our findings, an expert human driver doesnâ€™t just exhibit good driving
    behaviors by chance or intuition but continuously summarizes rules and patterns
    of driving behaviors. The construction of a thought chain progresses from strategic-level
    thinking to tactical-level decision-making and further to operational-level execution.
    For example, most expert drivers reported that they observed different directions
    systematically while turning, no matter which direction they went in. As D11 (expert)
    shared,
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘ä»¬çš„ç ”ç©¶å‘ç°ï¼Œä¸“å®¶çº§äººç±»é©¾é©¶å‘˜å¹¶éå‡­å€Ÿå¶ç„¶æˆ–ç›´è§‰å±•ç°å‡ºè‰¯å¥½çš„é©¾é©¶è¡Œä¸ºï¼Œè€Œæ˜¯æŒç»­æ€»ç»“é©¾é©¶è¡Œä¸ºçš„è§„åˆ™å’Œæ¨¡å¼ã€‚æ€ç»´é“¾çš„æ„å»ºä»æˆ˜ç•¥å±‚é¢çš„æ€è€ƒå¼€å§‹ï¼Œé€æ­¥è¿‡æ¸¡åˆ°æˆ˜æœ¯å±‚é¢çš„å†³ç­–ï¼Œå†åˆ°æ“ä½œå±‚é¢çš„æ‰§è¡Œã€‚ä¾‹å¦‚ï¼Œå¤§å¤šæ•°ä¸“å®¶é©¾é©¶å‘˜è¡¨ç¤ºï¼Œä»–ä»¬åœ¨è½¬å¼¯æ—¶ç³»ç»Ÿæ€§åœ°è§‚å¯Ÿä¸åŒçš„æ–¹å‘ï¼Œæ— è®ºä»–ä»¬é©¶å‘å“ªä¸ªæ–¹å‘ã€‚æ­£å¦‚D11ï¼ˆä¸“å®¶ï¼‰æ‰€åˆ†äº«çš„ï¼Œ
- en: 'D11 (expert): â€No matter right or left, I must look at the direction that I
    turn to first because thatâ€™s the road that I will take. However, I also look in
    the opposite direction. Basically, I look twice. The first time is to look at
    both sides; the second time is to confirm. Then I take the turns.â€'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: D11ï¼ˆä¸“å®¶ï¼‰ï¼šâ€œæ— è®ºæ˜¯å³è½¬è¿˜æ˜¯å·¦è½¬ï¼Œæˆ‘å¿…é¡»é¦–å…ˆçœ‹æˆ‘è¦è½¬å‘çš„æ–¹å‘ï¼Œå› ä¸ºé‚£æ˜¯æˆ‘å°†è¦èµ°çš„é“è·¯ã€‚ä¸è¿‡ï¼Œæˆ‘ä¹Ÿä¼šçœ‹åæ–¹å‘ã€‚åŸºæœ¬ä¸Šï¼Œæˆ‘ä¼šçœ‹ä¸¤æ¬¡ã€‚ç¬¬ä¸€æ¬¡æ˜¯çœ‹ä¸¤è¾¹ï¼Œç¬¬äºŒæ¬¡æ˜¯ç¡®è®¤ã€‚ç„¶åæˆ‘å°±å¼€å§‹è½¬å¼¯ã€‚â€
- en: Moreover, the expert drivers also had systematic, well-developed behavioral
    patterns when they interacted with other road users. For example, before entering
    the main road, the expert drivers evaluated the status of cars on the main road
    to decide when and how they got onto the main road.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œä¸“å®¶é©¾é©¶å‘˜åœ¨ä¸å…¶ä»–é“è·¯ä½¿ç”¨è€…äº’åŠ¨æ—¶ï¼Œä¹Ÿæœ‰ç³»ç»ŸåŒ–ä¸”æˆç†Ÿçš„è¡Œä¸ºæ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿›å…¥ä¸»å¹²é“ä¹‹å‰ï¼Œä¸“å®¶é©¾é©¶å‘˜ä¼šè¯„ä¼°ä¸»å¹²é“ä¸Šè½¦è¾†çš„çŠ¶å†µï¼Œä»¥å†³å®šä½•æ—¶ä»¥åŠå¦‚ä½•è¿›å…¥ä¸»å¹²é“ã€‚
- en: 'D06 (expert): â€Look at the left rearview mirror first, mainly about the speed
    of the back car. If the speed is slow, I can step on gases and go directly. If
    the speed is fast, I can pause and wait. I can go after they pass by.â€'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: D06ï¼ˆä¸“å®¶ï¼‰ï¼šâ€œé¦–å…ˆçœ‹å·¦åè§†é•œï¼Œä¸»è¦æ˜¯è§‚å¯Ÿåæ–¹è½¦è¾†çš„é€Ÿåº¦ã€‚å¦‚æœé€Ÿåº¦è¾ƒæ…¢ï¼Œæˆ‘å¯ä»¥åŠ é€Ÿç›´æ¥è¡Œé©¶ã€‚å¦‚æœé€Ÿåº¦è¾ƒå¿«ï¼Œæˆ‘å¯ä»¥æš‚åœç­‰å¾…ï¼Œç­‰ä»–ä»¬é€šè¿‡åæˆ‘å†é©¶å…¥ã€‚â€
- en: We can see the thought chain of expert drivers is composed of multiple interconnected
    decision points, each based on the current traffic conditions and anticipated
    future changes. Such patterns not only enable human drivers to form muscle memory
    through repeated practice but can also be summarized into explicit chains of thought
    to teach autonomous driving algorithms based on LLMs. Thus, we think that by using
    the driving-thinking data of expert drivers as prompts, these excellent driving
    behavior patterns can be expanded and generalized through LLMs. We compiled the
    â€driving-thinkingâ€ data, along with demographic information and driving-related
    questionnaire data from the participants, into a dataset. This facilitates future
    research on driving behavior and the development of autonomous driving algorithms.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸“å®¶é©¾é©¶å‘˜çš„æ€ç»´é“¾ç”±å¤šä¸ªç›¸äº’å…³è”çš„å†³ç­–ç‚¹ç»„æˆï¼Œæ¯ä¸ªå†³ç­–ç‚¹éƒ½åŸºäºå½“å‰çš„äº¤é€šçŠ¶å†µå’Œé¢„è®¡çš„æœªæ¥å˜åŒ–ã€‚è¿™ç§æ¨¡å¼ä¸ä»…ä½¿äººç±»é©¾é©¶å‘˜é€šè¿‡åå¤ç»ƒä¹ å½¢æˆè‚Œè‚‰è®°å¿†ï¼Œè¿˜å¯ä»¥æ€»ç»“æˆæ˜ç¡®çš„æ€ç»´é“¾ï¼Œæ¥æ•™å¯¼åŸºäºLLMçš„è‡ªåŠ¨é©¾é©¶ç®—æ³•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¤ä¸ºï¼Œé€šè¿‡å°†ä¸“å®¶é©¾é©¶å‘˜çš„é©¾é©¶-æ€ç»´æ•°æ®ä½œä¸ºæç¤ºï¼Œè¿™äº›ä¼˜ç§€çš„é©¾é©¶è¡Œä¸ºæ¨¡å¼å¯ä»¥é€šè¿‡LLMè¿›è¡Œæ‰©å±•å’Œæ³›åŒ–ã€‚æˆ‘ä»¬å°†â€œé©¾é©¶-æ€ç»´â€æ•°æ®ã€å‚ä¸è€…çš„ä¸ªäººä¿¡æ¯ä»¥åŠä¸é©¾é©¶ç›¸å…³çš„é—®å·æ•°æ®ç¼–åˆ¶æˆæ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›æœªæ¥å¯¹é©¾é©¶è¡Œä¸ºçš„ç ”ç©¶å’Œè‡ªåŠ¨é©¾é©¶ç®—æ³•çš„å‘å±•ã€‚
- en: '![Refer to caption](img/a74943f0ba8c00f06617ac6e1bc37875.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![è¯·å‚è§æ ‡é¢˜è¯´æ˜](img/a74943f0ba8c00f06617ac6e1bc37875.png)'
- en: 'Figure 1: The framework of SurrealDriver.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1ï¼šSurrealDriveræ¡†æ¶ã€‚
- en: III SurrealDriver Framework
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III SurrealDriveræ¡†æ¶
- en: III-A Framework Design
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A æ¡†æ¶è®¾è®¡
- en: 'Designing an agent capable of driving requires it to comprehend the complexity
    and diversity of driving environments, execute a continuous series of intricate
    operations, ensure safety, and harmonize with other human-driven vehicles. Based
    on these considerations, we have established the following framework as shown
    in Fig.Â [1](https://arxiv.org/html/2309.13193v2#S2.F1 "Figure 1 â€£ II-B Data Analysis
    and Dataset Construction â€£ II Driving-thinking Dataset â€£ SurrealDriver: Designing
    LLM-powered Generative Driver Agent Framework based on Human Driversâ€™ Driving-thinking
    Data"):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿé©¾é©¶çš„ä»£ç†éœ€è¦å®ƒç†è§£é©¾é©¶ç¯å¢ƒçš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼Œæ‰§è¡Œä¸€ç³»åˆ—å¤æ‚çš„æ“ä½œï¼Œç¡®ä¿å®‰å…¨ï¼Œå¹¶ä¸å…¶ä»–äººç±»é©¾é©¶çš„è½¦è¾†å’Œè°å…±å­˜ã€‚åŸºäºè¿™äº›è€ƒè™‘ï¼Œæˆ‘ä»¬å»ºç«‹äº†å¦‚ä¸‹æ¡†æ¶ï¼Œå¦‚å›¾[1](https://arxiv.org/html/2309.13193v2#S2.F1
    "å›¾1 â€£ II-B æ•°æ®åˆ†æä¸æ•°æ®é›†æ„å»º â€£ II é©¾é©¶-æ€ç»´æ•°æ®é›† â€£ SurrealDriver: åŸºäºäººç±»é©¾é©¶å‘˜é©¾é©¶-æ€ç»´æ•°æ®çš„LLMé©±åŠ¨ç”Ÿæˆé©¾é©¶ä»£ç†æ¡†æ¶")æ‰€ç¤ºï¼š'
- en: 'III-A1 Perception: Atomic Scene and Atomic Actions.'
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 æ„ŸçŸ¥ï¼šåŸå­åœºæ™¯ä¸åŸå­è¡Œä¸ºã€‚
- en: Human driving scenarios are diverse, requiring agents to understand complex
    situations in detail. Traditional driving simulation methods train across a wide
    range of scenarios, which is costly. Our approach breaks down driving scenarios
    into discrete parameters for the LLMs. These parameters help the agent assess
    situations using common sense. We also simplify driving actions in the simulator
    into basic operations, enabling the agent to combine these for complex driving
    behaviors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: äººç±»é©¾é©¶åœºæ™¯å¤šç§å¤šæ ·ï¼Œè¦æ±‚ä»£ç†è¯¦ç»†ç†è§£å¤æ‚çš„æƒ…å†µã€‚ä¼ ç»Ÿçš„é©¾é©¶ä»¿çœŸæ–¹æ³•éœ€è¦åœ¨å„ç§åœºæ™¯ä¸‹è¿›è¡Œè®­ç»ƒï¼Œè¿™æˆæœ¬å¾ˆé«˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†é©¾é©¶åœºæ™¯åˆ†è§£ä¸ºç¦»æ•£å‚æ•°ä¾›å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½¿ç”¨ã€‚è¿™äº›å‚æ•°å¸®åŠ©ä»£ç†è¿ç”¨å¸¸è¯†è¯„ä¼°æƒ…å†µã€‚æˆ‘ä»¬è¿˜å°†æ¨¡æ‹Ÿå™¨ä¸­çš„é©¾é©¶è¡Œä¸ºç®€åŒ–ä¸ºåŸºæœ¬æ“ä½œï¼Œä½¿ä»£ç†èƒ½å¤Ÿå°†è¿™äº›æ“ä½œç»„åˆèµ·æ¥æ‰§è¡Œå¤æ‚çš„é©¾é©¶è¡Œä¸ºã€‚
- en: 'III-A2 Execution: Short-Term Driving Memory.'
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 æ‰§è¡Œï¼šçŸ­æœŸé©¾é©¶è®°å¿†ã€‚
- en: Effective car driving demands seamless and continuous actions, minimizing abrupt
    braking or sharp turns whenever feasible. Additionally, actions such as overtaking
    and following entail a fusion of fundamental maneuvers (e.g., acceleration, lane
    changing), rendering driving actions relatively intricate. To maintain smooth
    driving, we capture the agentâ€™s recent driving behavior over a few steps in the
    short-term driving memory module. These short-term driving memories aid the agent
    in sustaining consistency in decision-making. Moreover, the agent can employ these
    driving memories to amalgamate several basic driving operations for executing
    complex driving behaviors.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„æ±½è½¦é©¾é©¶éœ€è¦æ— ç¼ä¸”è¿ç»­çš„æ“ä½œï¼Œå°½å¯èƒ½é¿å…çªç„¶åˆ¹è½¦æˆ–æ€¥è½¬å¼¯ã€‚æ­¤å¤–ï¼Œè¶…è½¦å’Œè·Ÿè½¦ç­‰æ“ä½œéœ€è¦èåˆåŸºæœ¬çš„é©¾é©¶æ“ä½œï¼ˆä¾‹å¦‚ï¼ŒåŠ é€Ÿã€å˜é“ï¼‰ï¼Œä½¿å¾—é©¾é©¶è¡Œä¸ºç›¸å¯¹å¤æ‚ã€‚ä¸ºäº†ä¿æŒå¹³ç¨³é©¾é©¶ï¼Œæˆ‘ä»¬åœ¨çŸ­æœŸé©¾é©¶è®°å¿†æ¨¡å—ä¸­æ•æ‰ä»£ç†æœ€è¿‘çš„é©¾é©¶è¡Œä¸ºã€‚è¿™äº›çŸ­æœŸé©¾é©¶è®°å¿†å¸®åŠ©ä»£ç†ä¿æŒå†³ç­–çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œä»£ç†å¯ä»¥åˆ©ç”¨è¿™äº›é©¾é©¶è®°å¿†å°†è‹¥å¹²åŸºæœ¬é©¾é©¶æ“ä½œç»“åˆèµ·æ¥ï¼Œæ‰§è¡Œå¤æ‚çš„é©¾é©¶è¡Œä¸ºã€‚
- en: 'III-A3 Planning: Long-Term Human-like Driving Guidelines.'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A3 è§„åˆ’ï¼šé•¿æœŸç±»äººé©¾é©¶æŒ‡å—ã€‚
- en: The agent must align its planning with that of human drivers. This module facilitates
    the agent in emulating the process by which humans learn from expert drivers to
    amass expertise and continually enhance their driving skills. To this end, we
    designed CoachAgent to assess the DriverAgentâ€™s driving behaviors and impart guidelines
    that must be adhered to. These guidelines are consistently integrated, contributing
    to the ongoing enhancement of the DriverAgentâ€™s driving proficiency.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç†å¿…é¡»ä½¿å…¶è§„åˆ’ä¸äººç±»é©¾é©¶å‘˜çš„è§„åˆ’ä¿æŒä¸€è‡´ã€‚æ­¤æ¨¡å—å¸®åŠ©ä»£ç†æ¨¡æ‹Ÿäººç±»å¦‚ä½•ä»ä¸“å®¶é©¾é©¶å‘˜é‚£é‡Œå­¦ä¹ ï¼Œç§¯ç´¯ç»éªŒï¼Œå¹¶ä¸æ–­æå‡å…¶é©¾é©¶æŠ€èƒ½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†CoachAgentæ¥è¯„ä¼°DriverAgentçš„é©¾é©¶è¡Œä¸ºï¼Œå¹¶ä¼ æˆå¿…é¡»éµå®ˆçš„æŒ‡å—ã€‚è¿™äº›æŒ‡å—å§‹ç»ˆè¢«æ•´åˆï¼Œä¿ƒè¿›DriverAgenté©¾é©¶èƒ½åŠ›çš„æŒç»­æå‡ã€‚
- en: 'III-A4 Overall Process: Strict Safety Criteria.'
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A4 æ€»ä½“æµç¨‹ï¼šä¸¥æ ¼çš„å®‰å…¨æ ‡å‡†ã€‚
- en: Ensuring safety is the most critical requirement for driving behavior simulation.
    Any simulated driving system must prioritize safety and establish rules within
    its framework to ensure the agentâ€™s safety.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿å®‰å…¨æ˜¯é©¾é©¶è¡Œä¸ºä»¿çœŸçš„æœ€å…³é”®è¦æ±‚ã€‚ä»»ä½•æ¨¡æ‹Ÿé©¾é©¶ç³»ç»Ÿå¿…é¡»ä¼˜å…ˆè€ƒè™‘å®‰å…¨ï¼Œå¹¶åœ¨å…¶æ¡†æ¶å†…åˆ¶å®šè§„åˆ™ï¼Œä»¥ç¡®ä¿ä»£ç†çš„å®‰å…¨ã€‚
- en: Thus, throughout the entire driving process, safety should be consistently ensured
    through safety redundancy mechanisms. The agent is provided with stringent safety
    criteria to ensure the fundamental safety of the driving process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨æ•´ä¸ªé©¾é©¶è¿‡ç¨‹ä¸­ï¼Œå®‰å…¨åº”é€šè¿‡å®‰å…¨å†—ä½™æœºåˆ¶æŒç»­å¾—åˆ°ä¿éšœã€‚ä¸ºç¡®ä¿é©¾é©¶è¿‡ç¨‹çš„åŸºæœ¬å®‰å…¨ï¼Œä»£ç†è¢«èµ‹äºˆäº†ä¸¥æ ¼çš„å®‰å…¨æ ‡å‡†ã€‚
- en: III-B Implementation
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B å®ç°
- en: '![Refer to caption](img/665a2b065cbef5c27aa00bd4581d6c55.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è€ƒæ ‡é¢˜](img/665a2b065cbef5c27aa00bd4581d6c55.png)'
- en: 'Figure 2: The Details of DriverAgent.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2ï¼šDriverAgentçš„è¯¦ç»†ä¿¡æ¯ã€‚
- en: We built the SurrealDriver framework in the CARLA simulatorÂ [[24](https://arxiv.org/html/2309.13193v2#bib.bib24)],
    including the basic driving pipeline, the memory and safety mechanism, and the
    human-aligned long-term driving guidelines.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨CARLAæ¨¡æ‹Ÿå™¨ä¸­æ„å»ºäº†SurrealDriveræ¡†æ¶[[24](https://arxiv.org/html/2309.13193v2#bib.bib24)]ï¼ŒåŒ…æ‹¬åŸºæœ¬é©¾é©¶æµç¨‹ã€è®°å¿†ä¸å®‰å…¨æœºåˆ¶ï¼Œä»¥åŠä¸äººç±»å¯¹é½çš„é•¿æœŸé©¾é©¶æŒ‡å—ã€‚
- en: III-B1 Basic Driving Pipeline.
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 åŸºæœ¬é©¾é©¶æµç¨‹ã€‚
- en: 'As shown in Fig.Â [2](https://arxiv.org/html/2309.13193v2#S3.F2 "Figure 2 â€£
    III-B Implementation â€£ III SurrealDriver Framework â€£ SurrealDriver: Designing
    LLM-powered Generative Driver Agent Framework based on Human Driversâ€™ Driving-thinking
    Data"), the basic driving pipeline consists of three main processes: perception,
    decision-making, and control. In perception, DriverAgent receives and integrates
    vehicle and environmental data from the CARLA simulator. This data, provided as
    parameters, is analyzed based on predefined prompts and common sense, enabling
    DriverAgent to understand the vehicleâ€™s current situation. Following perception,
    DriverAgent decides on the next steps, prioritizing safety and efficiency. It
    then proceeds to the control phase, where it sends JSON-formatted commands to
    CARLA, choosing from actions like stopping, maintaining speed, lane changing,
    or adjusting speed. These atomic actions allow DriverAgent to execute complex
    maneuvers based on the scenario.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å›¾[2](https://arxiv.org/html/2309.13193v2#S3.F2 "å›¾ 2 â€£ III-B å®ç° â€£ III è¶…ç°å®é©¾é©¶å‘˜æ¡†æ¶
    â€£ è¶…ç°å®é©¾é©¶å‘˜ï¼šåŸºäºäººç±»é©¾é©¶å‘˜é©¾é©¶æ€ç»´æ•°æ®è®¾è®¡çš„LLMé©±åŠ¨ç”Ÿæˆé©¾é©¶å‘˜ä»£ç†æ¡†æ¶")æ‰€ç¤ºï¼ŒåŸºæœ¬çš„é©¾é©¶æµç¨‹åŒ…å«ä¸‰ä¸ªä¸»è¦è¿‡ç¨‹ï¼šæ„ŸçŸ¥ã€å†³ç­–å’Œæ§åˆ¶ã€‚åœ¨æ„ŸçŸ¥é˜¶æ®µï¼ŒDriverAgentæ¥æ”¶å¹¶æ•´åˆæ¥è‡ªCARLAæ¨¡æ‹Ÿå™¨çš„è½¦è¾†å’Œç¯å¢ƒæ•°æ®ã€‚è¿™äº›æ•°æ®ä»¥å‚æ•°å½¢å¼æä¾›ï¼ŒåŸºäºé¢„å®šä¹‰çš„æç¤ºå’Œå¸¸è¯†è¿›è¡Œåˆ†æï¼Œä½¿DriverAgentèƒ½å¤Ÿç†è§£è½¦è¾†çš„å½“å‰çŠ¶å†µã€‚æ„ŸçŸ¥åï¼ŒDriverAgentå†³å®šä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨ï¼Œä¼˜å…ˆè€ƒè™‘å®‰å…¨æ€§å’Œæ•ˆç‡ã€‚éšåè¿›å…¥æ§åˆ¶é˜¶æ®µï¼ŒDriverAgentå‘CARLAå‘é€JSONæ ¼å¼çš„æŒ‡ä»¤ï¼Œé€‰æ‹©å¦‚åœè½¦ã€ä¿æŒè½¦é€Ÿã€å˜é“æˆ–è°ƒæ•´è½¦é€Ÿç­‰åŠ¨ä½œã€‚è¿™äº›åŸå­åŠ¨ä½œä½¿DriverAgentèƒ½å¤ŸåŸºäºåœºæ™¯æ‰§è¡Œå¤æ‚çš„æ“ä½œã€‚
- en: III-B2 Memory and Safety Mechanisms
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 å†…å­˜å’Œå®‰å…¨æœºåˆ¶
- en: 'The memory and safety mechanisms are built on top of the basic driving pipeline
    to store the information needed by the DriverAgent. It consists of three modules:
    Safety criteria and Short-term memory.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å†…å­˜å’Œå®‰å…¨æœºåˆ¶å»ºç«‹åœ¨åŸºæœ¬é©¾é©¶æµç¨‹ä¹‹ä¸Šï¼Œç”¨äºå­˜å‚¨DriverAgentæ‰€éœ€çš„ä¿¡æ¯ã€‚å®ƒç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆï¼šå®‰å…¨æ ‡å‡†å’ŒçŸ­æœŸè®°å¿†ã€‚
- en: 'Safety Criteria: We implemented stringent safety criteria set to prevent hazardous
    maneuvers. The safety redundancy mechanism has two tiers. The first, mandatory
    tier, mandates actions like stopping if a vehicle or pedestrian is within 10 meters
    or at a red traffic light. The second, optional but recommended tier, includes
    decelerating when nearing vehicles or pedestrians within 20 meters, slowing down
    at intersections, keeping a minimum distance of 1 meter from moving cars, and
    optimizing energy use by reducing unnecessary speed changes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å®‰å…¨æ ‡å‡†ï¼šæˆ‘ä»¬å®æ–½äº†ä¸¥æ ¼çš„å®‰å…¨æ ‡å‡†ï¼Œæ—¨åœ¨é˜²æ­¢å±é™©æ“ä½œã€‚å®‰å…¨å†—ä½™æœºåˆ¶åˆ†ä¸ºä¸¤ä¸ªå±‚çº§ã€‚ç¬¬ä¸€ä¸ªå¼ºåˆ¶æ€§å±‚çº§è¦æ±‚åœ¨è½¦è¾†æˆ–è¡Œäººè·ç¦»å°äº10ç±³æ—¶ï¼Œæˆ–è€…åœ¨çº¢ç¯æ—¶ï¼Œå¿…é¡»é‡‡å–åœè½¦ç­‰è¡ŒåŠ¨ã€‚ç¬¬äºŒä¸ªå¯é€‰ä½†æ¨èçš„å±‚çº§åŒ…æ‹¬ï¼šåœ¨æ¥è¿‘20ç±³å†…çš„è½¦è¾†æˆ–è¡Œäººæ—¶å‡é€Ÿï¼Œåœ¨äº¤å‰å£å‡é€Ÿï¼Œä¸è¡Œé©¶ä¸­çš„æ±½è½¦ä¿æŒè‡³å°‘1ç±³çš„å®‰å…¨è·ç¦»ï¼Œä»¥åŠé€šè¿‡å‡å°‘ä¸å¿…è¦çš„è½¦é€Ÿå˜åŒ–æ¥ä¼˜åŒ–èƒ½é‡ä½¿ç”¨ã€‚
- en: 'Short-term Memory: To ensure the continuity and complexity of driving, we will
    store the driving behaviors of the current agent from the past few iterations
    and continuously update them, replacing the oldest with the latest to maintain
    a certain number of stored behaviors. These behaviors will then be provided to
    the DriverAgent again, becoming part of its perception.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ­æœŸè®°å¿†ï¼šä¸ºäº†ç¡®ä¿é©¾é©¶çš„è¿ç»­æ€§å’Œå¤æ‚æ€§ï¼Œæˆ‘ä»¬å°†å­˜å‚¨å½“å‰ä»£ç†åœ¨è¿‡å»å‡ ä¸ªè¿­ä»£ä¸­çš„é©¾é©¶è¡Œä¸ºï¼Œå¹¶ä¸æ–­æ›´æ–°ï¼Œç”¨æœ€æ–°çš„è¡Œä¸ºæ›¿æ¢æœ€æ—§çš„è¡Œä¸ºï¼Œä¿æŒä¸€å®šæ•°é‡çš„å·²å­˜å‚¨è¡Œä¸ºã€‚è¿™äº›è¡Œä¸ºå°†å†æ¬¡æä¾›ç»™DriverAgentï¼Œæˆä¸ºå…¶æ„ŸçŸ¥çš„ä¸€éƒ¨åˆ†ã€‚
- en: III-B3 Human aligned Long-term Driving Guideline
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B3 äººç±»å¯¹é½çš„é•¿æœŸé©¾é©¶æŒ‡å—
- en: 'To better align SurrealDriver with human drivers, we utilize the driving-thinking
    data of expert drivers collected in SectionÂ LABEL:Thnking-aloud a chain-of-thought
    prompt. While designing examples, we followed a three-dimensional approach: situation,
    reasoning, and action as shown in Fig.Â [3](https://arxiv.org/html/2309.13193v2#S3.F3
    "Figure 3 â€£ III-B3 Human aligned Long-term Driving Guideline â€£ III-B Implementation
    â€£ III SurrealDriver Framework â€£ SurrealDriver: Designing LLM-powered Generative
    Driver Agent Framework based on Human Driversâ€™ Driving-thinking Data"). Situation
    provided specific road conditions during driver operations, and for each comparison
    case, we set the same road conditions, referencing the road conditions real drivers
    faced during their interviews. Reasoning was designed based on the content of
    driver interviews, with irrelevant information removed to make our examples concise
    and efficient in demonstrating human thinking and guiding the agent to learn human
    thought patterns.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°å°†SurrealDriverä¸äººç±»é©¾é©¶å‘˜å¯¹é½ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†åœ¨â€œæ€ç»´é“¾å¼æç¤ºâ€éƒ¨åˆ†æ”¶é›†çš„ä¸“å®¶é©¾é©¶å‘˜é©¾é©¶æ€ç»´æ•°æ®ã€‚åœ¨è®¾è®¡ç¤ºä¾‹æ—¶ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸‰ç»´æ–¹æ³•ï¼šæƒ…å¢ƒã€æ¨ç†å’Œè¡ŒåŠ¨ï¼Œå¦‚å›¾[3](https://arxiv.org/html/2309.13193v2#S3.F3
    "å›¾3 â€£ III-B3 äººç±»å¯¹é½çš„é•¿æœŸé©¾é©¶æŒ‡å— â€£ III-B å®æ–½ â€£ III SurrealDriveræ¡†æ¶ â€£ SurrealDriverï¼šåŸºäºäººç±»é©¾é©¶å‘˜é©¾é©¶æ€ç»´æ•°æ®è®¾è®¡LLMé©±åŠ¨çš„ç”Ÿæˆé©¾é©¶å‘˜ä»£ç†æ¡†æ¶")æ‰€ç¤ºã€‚æƒ…å¢ƒæä¾›äº†é©¾é©¶å‘˜æ“ä½œæœŸé—´çš„å…·ä½“é“è·¯æ¡ä»¶ï¼Œå¯¹äºæ¯ä¸ªæ¯”è¾ƒæ¡ˆä¾‹ï¼Œæˆ‘ä»¬è®¾ç½®äº†ç›¸åŒçš„é“è·¯æ¡ä»¶ï¼Œå‚è€ƒäº†çœŸå®é©¾é©¶å‘˜åœ¨é¢è¯•ä¸­æ‰€é¢å¯¹çš„é“è·¯æ¡ä»¶ã€‚æ¨ç†æ˜¯åŸºäºé©¾é©¶å‘˜é¢è¯•å†…å®¹è®¾è®¡çš„ï¼Œå»é™¤äº†ä¸ç›¸å…³çš„ä¿¡æ¯ï¼Œä½¿æˆ‘ä»¬çš„ç¤ºä¾‹ç®€æ´é«˜æ•ˆï¼Œèƒ½å¤Ÿå±•ç¤ºäººç±»æ€ç»´å¹¶æŒ‡å¯¼ä»£ç†å­¦ä¹ äººç±»çš„æ€ç»´æ¨¡å¼ã€‚
- en: '![Refer to caption](img/574b6df36881bd3d7576988beaaf510f.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![å‚è§è¯´æ˜](img/574b6df36881bd3d7576988beaaf510f.png)'
- en: 'Figure 3: The CoachAgent for human alignment.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3ï¼šç”¨äºäººç±»å¯¹é½çš„CoachAgentã€‚
- en: IV Evaluation
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV è¯„ä¼°
- en: 'We conducted driving experiments using agents from different frameworks in
    the same scenario, analyzing variations in their behaviors to understand how directives
    from different frameworks influence their driving. We evaluated the agents based
    on two primary dimensions: safety-driving capability and human-likeness. Safety-driving
    capability was assessed using an algorithmic experiment, while human-likeness
    was assessed through a human experiment.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç›¸åŒåœºæ™¯ä¸‹ä½¿ç”¨æ¥è‡ªä¸åŒæ¡†æ¶çš„ä»£ç†è¿›è¡Œäº†é©¾é©¶å®éªŒï¼Œåˆ†æå®ƒä»¬è¡Œä¸ºä¸Šçš„å·®å¼‚ï¼Œä»¥ç†è§£ä¸åŒæ¡†æ¶çš„æŒ‡ä»¤å¦‚ä½•å½±å“å®ƒä»¬çš„é©¾é©¶ã€‚æˆ‘ä»¬æ ¹æ®ä¸¤ä¸ªä¸»è¦ç»´åº¦è¯„ä¼°äº†è¿™äº›ä»£ç†ï¼šå®‰å…¨é©¾é©¶èƒ½åŠ›å’Œç±»äººæ€§ã€‚å®‰å…¨é©¾é©¶èƒ½åŠ›é€šè¿‡ç®—æ³•å®éªŒè¯„ä¼°ï¼Œè€Œç±»äººæ€§åˆ™é€šè¿‡äººç±»å®éªŒè¿›è¡Œè¯„ä¼°ã€‚
- en: IV-A Algorithm Experiment
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A ç®—æ³•å®éªŒ
- en: IV-A1 Experiment Environment Set-up
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 å®éªŒç¯å¢ƒè®¾ç½®
- en: The experimental setup on a ThundeRobot Zero desktop computer. The simulation
    environment was built upon the CARLA simulator version 0.9.14Â [[24](https://arxiv.org/html/2309.13193v2#bib.bib24)]
    and operated on Python 3.7 with Unreal Engine 4\. The simulated environment was
    chosen to be Town10, and the Audi TT was the designated vehicle for all experiments,
    with fixed starting and continuously, randomly generated ending points for its
    path. Upon reaching the endpoint, another endpoint is randomly generated for continuous
    experiments. This process continues until the required number of driving rounds
    are completed. We leverage OpenAIâ€™s GPT-4 APIs for simulating driversâ€™ driving
    decisions and solving related problems in a simulated environment. However, it
    takes several seconds for GPT-4 to make a decision, which is too long in a driving
    context for making immediate decisions. Therefore, we slowed down CARLAâ€™s simulation
    time based on the required token count by setting a fixed time step of 0.0006-0.0015
    seconds.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å®éªŒåœ¨ä¸€å°ThundeRobot Zeroå°å¼è®¡ç®—æœºä¸Šè¿›è¡Œã€‚ä»¿çœŸç¯å¢ƒæ˜¯åŸºäºCARLAä»¿çœŸå™¨ç‰ˆæœ¬0.9.14 [[24](https://arxiv.org/html/2309.13193v2#bib.bib24)]
    æ„å»ºçš„ï¼Œå¹¶åœ¨Python 3.7å’Œè™šå¹»å¼•æ“4ä¸Šè¿è¡Œã€‚é€‰å®šçš„ä»¿çœŸç¯å¢ƒä¸ºTown10ï¼ŒAudi TTæ˜¯æ‰€æœ‰å®éªŒçš„æŒ‡å®šè½¦è¾†ï¼Œè·¯å¾„çš„èµ·ç‚¹å›ºå®šï¼Œç»ˆç‚¹åˆ™æ˜¯éšæœºç”Ÿæˆä¸”è¿ç»­å˜åŒ–çš„ã€‚åœ¨åˆ°è¾¾ç»ˆç‚¹åï¼Œç³»ç»Ÿä¼šéšæœºç”Ÿæˆæ–°çš„ç»ˆç‚¹ä»¥è¿›è¡ŒæŒç»­å®éªŒã€‚æ­¤è¿‡ç¨‹å°†æŒç»­è¿›è¡Œï¼Œç›´åˆ°å®Œæˆæ‰€éœ€çš„é©¾é©¶å›åˆæ•°ã€‚æˆ‘ä»¬åˆ©ç”¨OpenAIçš„GPT-4
    APIæ¥æ¨¡æ‹Ÿé©¾é©¶å‘˜çš„é©¾é©¶å†³ç­–å¹¶è§£å†³ä»¿çœŸç¯å¢ƒä¸­çš„ç›¸å…³é—®é¢˜ã€‚ç„¶è€Œï¼ŒGPT-4åšå‡ºå†³ç­–éœ€è¦å‡ ç§’é’Ÿï¼Œè¿™åœ¨é©¾é©¶åœºæ™¯ä¸­å¤„ç†å³æ—¶å†³ç­–æ—¶æ˜¾å¾—è¿‡é•¿ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ ¹æ®æ‰€éœ€çš„ä»¤ç‰Œæ•°é‡ï¼Œé€šè¿‡è®¾ç½®å›ºå®šçš„æ—¶é—´æ­¥é•¿0.0006-0.0015ç§’æ¥å‡æ…¢CARLAçš„ä»¿çœŸæ—¶é—´ã€‚
- en: IV-A2 Results
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 ç»“æœ
- en: 'The overall experiment lasted 108405.90s (30.11 hours); the average experiment
    time for each condition was 7079.67s, 13730.6s, 23870.28s, and 63725.35s, respectively.
    We conducted statistical analyses separately for collision rates per unit distance
    and collision rates per unit time. The detailed results are shown in TableÂ [I](https://arxiv.org/html/2309.13193v2#S4.T1
    "TABLE I â€£ IV-A2 Results â€£ IV-A Algorithm Experiment â€£ IV Evaluation â€£ SurrealDriver:
    Designing LLM-powered Generative Driver Agent Framework based on Human Driversâ€™
    Driving-thinking Data"). Notably, we adjusted the algorithms controlling other
    vehicles and pedestrians to make them more prone to sudden maneuvers (e.g. abrupt
    lane changes, running red lights). These edge cases aim to increase the risk level
    of the driving environment for the agent vehicle, making its driving performance
    more observable.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ•´ä½“å®éªŒæŒç»­äº†108405.90ç§’ï¼ˆ30.11å°æ—¶ï¼‰ï¼›æ¯ä¸ªæ¡ä»¶ä¸‹çš„å¹³å‡å®éªŒæ—¶é—´åˆ†åˆ«ä¸º7079.67ç§’ã€13730.6ç§’ã€23870.28ç§’å’Œ63725.35ç§’ã€‚æˆ‘ä»¬åˆ†åˆ«å¯¹æ¯å•ä½è·ç¦»å’Œæ¯å•ä½æ—¶é—´çš„ç¢°æ’ç‡è¿›è¡Œäº†ç»Ÿè®¡åˆ†æã€‚è¯¦ç»†ç»“æœè¯·è§è¡¨æ ¼[I](https://arxiv.org/html/2309.13193v2#S4.T1
    "TABLE I â€£ IV-A2 Results â€£ IV-A Algorithm Experiment â€£ IV Evaluation â€£ SurrealDriver:
    Designing LLM-powered Generative Driver Agent Framework based on Human Driversâ€™
    Driving-thinking Data")ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬è°ƒæ•´äº†æ§åˆ¶å…¶ä»–è½¦è¾†å’Œè¡Œäººçš„ç®—æ³•ï¼Œä½¿å®ƒä»¬æ›´å®¹æ˜“è¿›è¡Œçªå‘æ€§æ“ä½œï¼ˆä¾‹å¦‚æ€¥åˆ¹è½¦ã€çªç„¶å˜é“ã€é—¯çº¢ç¯ï¼‰ã€‚è¿™äº›æç«¯æƒ…å†µæ—¨åœ¨æé«˜é©¾é©¶ç¯å¢ƒçš„é£é™©çº§åˆ«ï¼Œä»è€Œä½¿ä»£ç†è½¦è¾†çš„é©¾é©¶è¡¨ç°æ›´ä¸ºå¯è§‚å¯Ÿã€‚'
- en: 'TABLE I: Collision Rate of Algorithm Experiment'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨æ ¼ Iï¼šç®—æ³•å®éªŒçš„ç¢°æ’ç‡
- en: '| Framework |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| æ¡†æ¶ |'
- en: '&#124; Collision Rate by &#124;'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æŒ‰è·ç¦»çš„ç¢°æ’ç‡ &#124;'
- en: '&#124; Distance (per meter) &#124;'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124;ï¼ˆæ¯ç±³ï¼‰&#124;'
- en: '|'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Collision Rate by &#124;'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æŒ‰ç¢°æ’ç‡ &#124;'
- en: '&#124; Time (per second) &#124;'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ—¶é—´ï¼ˆæ¯ç§’ï¼‰&#124;'
- en: '|'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; w/o safety criteria, &#124;'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ— å®‰å…¨æ ‡å‡†ï¼Œ&#124;'
- en: '&#124; w/o short-term memory, &#124;'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ— çŸ­æœŸè®°å¿†ï¼Œ&#124;'
- en: '&#124; w/o long-term guidelines &#124;'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ— é•¿æœŸæŒ‡å¯¼ &#124;'
- en: '| 0.01453958 | 0.041315485 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 0.01453958 | 0.041315485 |'
- en: '|'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; with safety criteria, &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æœ‰å®‰å…¨æ ‡å‡†ï¼Œ&#124;'
- en: '&#124; w/o short-term memory, &#124;'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ— çŸ­æœŸè®°å¿†ï¼Œ&#124;'
- en: '&#124; w/o long-term guidelines &#124;'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ— é•¿æœŸæŒ‡å¯¼ &#124;'
- en: '| 0.00923361 | 0.02366976 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 0.00923361 | 0.02366976 |'
- en: '|'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; with safety criteria, &#124;'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æœ‰å®‰å…¨æ ‡å‡†ï¼Œ&#124;'
- en: '&#124; with short-term memory, &#124;'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æœ‰çŸ­æœŸè®°å¿†ï¼Œ&#124;'
- en: '&#124; w/o long-term guidelines &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; æ— é•¿æœŸæŒ‡å¯¼ &#124;'
- en: '| 0.005046864 | 0.009530682 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 0.005046864 | 0.009530682 |'
- en: '| Full framework | 0.002757353 | 0.005100011 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| å®Œæ•´æ¡†æ¶ | 0.002757353 | 0.005100011 |'
- en: For the Safety Module, collision rate data shows that the framework with the
    safety module has a collision rate 57.46% lower than the one without it. For example,
    in the absence of Safety Criteria, when the vehicle was at a distance of 5 meters
    from the preceding vehicle, the DriverAgent initiated a lane change, leading to
    a collision with the front vehicle. However, when running a framework with Safety
    Criteria, the vehicle encountered a situation where the distance to the preceding
    vehicle was 7 meters. Based on the information provided by the safety criteria,
    it initiated a stop behavior, safely coming to a halt behind the lead vehicle.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå®‰å…¨æ¨¡å—ï¼Œç¢°æ’ç‡æ•°æ®æ˜¾ç¤ºï¼Œé‡‡ç”¨å®‰å…¨æ¨¡å—çš„æ¡†æ¶ä¸æœªé‡‡ç”¨å®‰å…¨æ¨¡å—çš„æ¡†æ¶ç›¸æ¯”ï¼Œç¢°æ’ç‡é™ä½äº†57.46%ã€‚ä¾‹å¦‚ï¼Œåœ¨æ²¡æœ‰å®‰å…¨æ ‡å‡†çš„æƒ…å†µä¸‹ï¼Œå½“è½¦è¾†ä¸å‰è½¦çš„è·ç¦»ä¸º5ç±³æ—¶ï¼ŒDriverAgentå‘èµ·äº†å˜é“ï¼Œå¯¼è‡´ä¸å‰è½¦å‘ç”Ÿç¢°æ’ã€‚ç„¶è€Œï¼Œåœ¨è¿è¡Œå¸¦æœ‰å®‰å…¨æ ‡å‡†çš„æ¡†æ¶æ—¶ï¼Œè½¦è¾†ä¸å‰è½¦çš„è·ç¦»ä¸º7ç±³ã€‚åŸºäºå®‰å…¨æ ‡å‡†æä¾›çš„ä¿¡æ¯ï¼Œè½¦è¾†å‘èµ·äº†åœè½¦è¡Œä¸ºï¼Œå®‰å…¨åœ°åœåœ¨äº†å‰è½¦åæ–¹ã€‚
- en: 'For the Short-term Memory Module, collision rate data shows that the framework
    with Short-term Memory has a collision rate 82.96% lower than the one without
    it. We found that short-term memory plays an important role in enhancing the continuity
    of the agentâ€™s driving decisions. For example, in one experimental trial, the
    vehicle initially accelerated for a few steps, and when DriverAgent had to decide
    its next action, it had two options: to continue accelerating or to maintain its
    current speed. Considering its previous acceleration actions, it chose to maintain
    its current speed.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºçŸ­æœŸè®°å¿†æ¨¡å—ï¼Œç¢°æ’ç‡æ•°æ®æ˜¾ç¤ºï¼Œå¸¦æœ‰çŸ­æœŸè®°å¿†çš„æ¡†æ¶ç›¸æ¯”äºæ²¡æœ‰çŸ­æœŸè®°å¿†çš„æ¡†æ¶ï¼Œç¢°æ’ç‡é™ä½äº†82.96%ã€‚æˆ‘ä»¬å‘ç°çŸ­æœŸè®°å¿†åœ¨å¢å¼ºä»£ç†é©¾é©¶å†³ç­–çš„è¿ç»­æ€§æ–¹é¢èµ·åˆ°äº†é‡è¦ä½œç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸæ¬¡å®éªŒä¸­ï¼Œè½¦è¾†æœ€åˆåŠ é€Ÿäº†å‡ æ­¥ï¼Œå½“DriverAgentéœ€è¦å†³å®šä¸‹ä¸€æ­¥æ“ä½œæ—¶ï¼Œå®ƒæœ‰ä¸¤ä¸ªé€‰æ‹©ï¼šç»§ç»­åŠ é€Ÿæˆ–ä¿æŒå½“å‰é€Ÿåº¦ã€‚è€ƒè™‘åˆ°ä¹‹å‰çš„åŠ é€Ÿè¡Œä¸ºï¼Œå®ƒé€‰æ‹©ä¿æŒå½“å‰é€Ÿåº¦ã€‚
- en: For the Long-term Guidelines Module, collision rate data shows that the framework
    with Long-term Guidelines has a collision rate 83.03% lower than the one without
    them. With long-term guidelines, the DriverAgent demonstrated an improvement in
    driving skills. For example, in one experimental trial, CoachAgent analyzed the
    initial driving behaviors and classified them as â€™Bad.â€™ The reason for this assessment
    was the excessive frequency of stopping. A guideline was generated that â€™Maintain
    a consistent and safe speed.â€™, which made the agent perform more human-like driving
    behaviour.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºé•¿æœŸæŒ‡å¯¼æ¨¡å—ï¼Œç¢°æ’ç‡æ•°æ®è¡¨æ˜ï¼Œä½¿ç”¨é•¿æœŸæŒ‡å¯¼çš„æ¡†æ¶ç›¸æ¯”æ²¡æœ‰ä½¿ç”¨çš„æ¡†æ¶ï¼Œç¢°æ’ç‡é™ä½äº†83.03%ã€‚ä½¿ç”¨é•¿æœŸæŒ‡å¯¼åï¼ŒDriverAgentçš„é©¾é©¶æŠ€èƒ½æœ‰æ‰€æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€æ¬¡å®éªŒä¸­ï¼ŒCoachAgentåˆ†æäº†åˆå§‹çš„é©¾é©¶è¡Œä¸ºå¹¶å°†å…¶è¯„ä¸ºâ€œå·®â€ã€‚è¯„å®šçš„åŸå› æ˜¯é¢‘ç¹åœè½¦ã€‚ç³»ç»Ÿç”Ÿæˆäº†ä¸€ä¸ªæŒ‡å¯¼æ„è§â€œä¿æŒä¸€è‡´ä¸”å®‰å…¨çš„é€Ÿåº¦â€ï¼Œè¿™ä½¿å¾—ä»£ç†è¡¨ç°å‡ºæ›´å…·äººç±»ç‰¹å¾çš„é©¾é©¶è¡Œä¸ºã€‚
- en: IV-B Human Evaluation Experiment
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B äººç±»è¯„ä¼°å®éªŒ
- en: 'A single-factor within-subjects design was used to investigate how people rate
    each framework used in the algorithm experiment (see in SectionÂ [IV-A](https://arxiv.org/html/2309.13193v2#S4.SS1
    "IV-A Algorithm Experiment â€£ IV Evaluation â€£ SurrealDriver: Designing LLM-powered
    Generative Driver Agent Framework based on Human Driversâ€™ Driving-thinking Data")).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä½¿ç”¨å•å› ç´ ç»„å†…è®¾è®¡æ¥è°ƒæŸ¥äººä»¬å¦‚ä½•è¯„å®šç®—æ³•å®éªŒä¸­ä½¿ç”¨çš„æ¯ä¸ªæ¡†æ¶ï¼ˆè¯·å‚è§[IV-A](https://arxiv.org/html/2309.13193v2#S4.SS1
    "IV-A Algorithm Experiment â€£ IV Evaluation â€£ SurrealDriver: Designing LLM-powered
    Generative Driver Agent Framework based on Human Driversâ€™ Driving-thinking Data")éƒ¨åˆ†ï¼‰ã€‚'
- en: IV-B1 Experiment Design and Materials
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 å®éªŒè®¾è®¡å’Œææ–™
- en: 'The independent variable was the framework, which included the â€œw/o safety,
    memory, or guideline frameworkâ€ without safety criteria, short-term memory, or
    long-term guidelines; the â€œw/o memory or guideline frameworkâ€ with safety criteria
    only; the â€œw/o guideline frameworkâ€ with both safety criteria and short-term memory;
    and the â€œfull frameworkâ€ with safety criteria, short-term memory, and long-term
    guidelines. Therefore, the guideline framework was the full framework of SurrealDriver.
    The video of each framework was created by recording experiments in the algorithm
    experiment (see in SectionÂ [IV-A](https://arxiv.org/html/2309.13193v2#S4.SS1 "IV-A
    Algorithm Experiment â€£ IV Evaluation â€£ SurrealDriver: Designing LLM-powered Generative
    Driver Agent Framework based on Human Driversâ€™ Driving-thinking Data")). The length
    of each video is around 30 seconds.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 'è‡ªå˜é‡æ˜¯æ¡†æ¶ï¼ŒåŒ…æ‹¬â€œæ²¡æœ‰å®‰å…¨æ€§ã€è®°å¿†æˆ–æŒ‡å¯¼æ¡†æ¶â€â€”â€”æ²¡æœ‰å®‰å…¨æ ‡å‡†ã€çŸ­æœŸè®°å¿†æˆ–é•¿æœŸæŒ‡å¯¼ï¼›â€œæ²¡æœ‰è®°å¿†æˆ–æŒ‡å¯¼æ¡†æ¶â€â€”â€”ä»…æœ‰å®‰å…¨æ ‡å‡†ï¼›â€œæ²¡æœ‰æŒ‡å¯¼æ¡†æ¶â€â€”â€”åŒæ—¶å…·æœ‰å®‰å…¨æ ‡å‡†å’ŒçŸ­æœŸè®°å¿†ï¼›ä»¥åŠâ€œå®Œæ•´æ¡†æ¶â€â€”â€”åŒ…æ‹¬å®‰å…¨æ ‡å‡†ã€çŸ­æœŸè®°å¿†å’Œé•¿æœŸæŒ‡å¯¼ã€‚å› æ­¤ï¼ŒæŒ‡å¯¼æ¡†æ¶å°±æ˜¯SurrealDriverçš„å®Œæ•´æ¡†æ¶ã€‚æ¯ä¸ªæ¡†æ¶çš„è§†é¢‘æ˜¯é€šè¿‡è®°å½•ç®—æ³•å®éªŒä¸­çš„å®éªŒè¿‡ç¨‹åˆ¶ä½œçš„ï¼ˆè¯·å‚è§[IV-A](https://arxiv.org/html/2309.13193v2#S4.SS1
    "IV-A Algorithm Experiment â€£ IV Evaluation â€£ SurrealDriver: Designing LLM-powered
    Generative Driver Agent Framework based on Human Driversâ€™ Driving-thinking Data")éƒ¨åˆ†ï¼‰ã€‚æ¯ä¸ªè§†é¢‘çš„æ—¶é•¿å¤§çº¦ä¸º30ç§’ã€‚'
- en: IV-B2 Participants and Procedures
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 å‚ä¸è€…å’Œç¨‹åº
- en: We invited another 24 adult participants (aged 29.3Â±4.9, male = 17, no overlap
    with participants in the Driving-thinking data collection experiment) with legal
    driving licenses to our human evaluation experiment. The experiment was conducted
    through online surveys. The survey started with demographic information questions
    including participantsâ€™ age, gender, phone number, driving silence status, years
    of driving experience, and kilometers of driving per month. Then the survey guided
    participants to watch videos embedded in the survey. All participants watched
    the videos in random order. After watching each video, they rate items that measure
    human likeness by asking whether the driver demonstrated driving operations like
    those conducted by human drivers using a 5-point Likert scale where 1 represented
    â€œnot at allâ€ and 5 presented â€œalmost all.â€
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é‚€è¯·äº†å¦å¤–24åæˆå¹´äººï¼ˆå¹´é¾„29.3Â±4.9å²ï¼Œç”·æ€§ = 17ï¼Œæ— ä¸é©¾é©¶æ€ç»´æ•°æ®æ”¶é›†å®éªŒçš„å‚ä¸è€…é‡å ï¼‰å‚ä¸æˆ‘ä»¬çš„äººå·¥è¯„ä¼°å®éªŒï¼Œæ‰€æœ‰å‚ä¸è€…å‡æŒæœ‰åˆæ³•é©¾é©¶æ‰§ç…§ã€‚å®éªŒé€šè¿‡åœ¨çº¿è°ƒæŸ¥è¿›è¡Œã€‚è°ƒæŸ¥ä»ä¸€äº›äººå£ç»Ÿè®¡ä¿¡æ¯é—®é¢˜å¼€å§‹ï¼ŒåŒ…æ‹¬å‚ä¸è€…çš„å¹´é¾„ã€æ€§åˆ«ã€ç”µè¯å·ç ã€æ˜¯å¦é©¾è½¦æ²‰é»˜ã€é©¾é©¶ç»éªŒå¹´é™ä»¥åŠæ¯æœˆé©¾é©¶çš„å…¬é‡Œæ•°ã€‚ç„¶åï¼Œè°ƒæŸ¥å¼•å¯¼å‚ä¸è€…è§‚çœ‹åµŒå…¥åœ¨è°ƒæŸ¥ä¸­çš„è§†é¢‘ã€‚æ‰€æœ‰å‚ä¸è€…æŒ‰éšæœºé¡ºåºè§‚çœ‹è¿™äº›è§†é¢‘ã€‚æ¯è§‚çœ‹å®Œä¸€ä¸ªè§†é¢‘åï¼Œå‚ä¸è€…éœ€è¦æ ¹æ®ä¸€ä¸ª5ç‚¹Likerté‡è¡¨å¯¹è§†é¢‘ä¸­çš„äººç±»ç›¸ä¼¼æ€§è¿›è¡Œè¯„åˆ†ï¼Œé‡è¡¨1è¡¨ç¤ºâ€œå®Œå…¨ä¸â€ï¼Œ5è¡¨ç¤ºâ€œå‡ ä¹å®Œå…¨â€ã€‚
- en: IV-B3 Results
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B3 ç»“æœ
- en: 'A one-way repeated measure ANOVAs were conducted to compare ratings among the
    four frameworks. For human-likeness, the Huynh-Feldt correction was used because
    Mauchlyâ€™s test of sphericity was significant with epsilon values larger than 0.75\.
    We found significant differences among the four frameworks: $F(2.5,57.4)=4.353$,
    $\textit{p}=0.01$. The Bonferroni post hoc test revealed that the scores of the
    guideline framework were significantly higher than those of the w/o safety, memory,
    or guideline framework, $\textit{p}=0.009$.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›è¡Œäº†å•å› ç´ é‡å¤æµ‹é‡æ–¹å·®åˆ†æï¼ˆANOVAï¼‰ï¼Œæ¯”è¾ƒäº†å››ä¸ªæ¡†æ¶ä¹‹é—´çš„è¯„åˆ†ã€‚å¯¹äºäººç±»ç›¸ä¼¼åº¦ï¼Œé‡‡ç”¨äº†Huynh-Feldtæ ¡æ­£ï¼Œå› ä¸ºMauchlyçƒå½¢æ£€éªŒç»“æœæ˜¾è‘—ï¼Œ$\epsilon$å€¼å¤§äº0.75ã€‚æˆ‘ä»¬å‘ç°å››ä¸ªæ¡†æ¶ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼š$F(2.5,57.4)=4.353$ï¼Œ$\textit{p}=0.01$ã€‚Bonferroniäº‹åæ£€éªŒæ˜¾ç¤ºï¼ŒæŒ‡å—æ¡†æ¶çš„è¯„åˆ†æ˜¾è‘—é«˜äºä¸å«å®‰å…¨ã€è®°å¿†æˆ–æŒ‡å—æ¡†æ¶çš„è¯„åˆ†ï¼Œ$\textit{p}=0.009$ã€‚
- en: V Conclusion
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V ç»“è®º
- en: In our research, we developed SurrealDriver, an LLM-based driver agent framework.
    The results of both algorithm experiments and human evaluation indicate that this
    LLM-based driver agent framework offers better performance than the basic approach
    for driver simulations, bringing driver agent behavior closer to human-like driving
    and, consequently, simulating more realistic traffic environments. By integrating
    human Driving-thinking data with LLMs, agents can utilize natural language and
    examples to add rules more conveniently, allowing for easier rule adjustments.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†SurrealDriverï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºLLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰çš„é©¾é©¶å‘˜æ™ºèƒ½ä½“æ¡†æ¶ã€‚æ— è®ºæ˜¯ç®—æ³•å®éªŒç»“æœè¿˜æ˜¯äººå·¥è¯„ä¼°éƒ½è¡¨æ˜ï¼Œè¿™ä¸ªåŸºäºLLMçš„é©¾é©¶å‘˜æ™ºèƒ½ä½“æ¡†æ¶åœ¨é©¾é©¶æ¨¡æ‹Ÿä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä½¿å¾—é©¾é©¶å‘˜æ™ºèƒ½ä½“çš„è¡Œä¸ºæ›´æ¥è¿‘äººç±»é©¾é©¶ï¼Œä»è€Œæ¨¡æ‹Ÿå‡ºæ›´çœŸå®çš„äº¤é€šç¯å¢ƒã€‚é€šè¿‡å°†äººç±»é©¾é©¶æ€ç»´æ•°æ®ä¸LLMç»“åˆï¼Œæ™ºèƒ½ä½“å¯ä»¥æ›´æ–¹ä¾¿åœ°ä½¿ç”¨è‡ªç„¶è¯­è¨€å’Œç¤ºä¾‹æ¥æ·»åŠ è§„åˆ™ï¼Œä½¿å¾—è§„åˆ™è°ƒæ•´æ›´åŠ å®¹æ˜“ã€‚
- en: Thus, we provide the agent with the driving-thinking data of real driversâ€™ behaviors
    obtained through interviews conducted during real vehicle experiments. The agent
    uses its capabilities based on LLMs to autonomously assess the quality of its
    driving behavior compared to detailed driving behaviour reasoning. It then enhances
    its driving skills based on the behavior of expert drivers. This approach differs
    from traditional reinforcement learning and other training methods by enabling
    the agent to learn directly from driver transcripts, similar to humans, without
    the need for translation into code. Our research provided valuable insights for
    future human-aligned agent generation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å‘æ™ºèƒ½ä½“æä¾›äº†é€šè¿‡åœ¨å®é™…è½¦è¾†å®éªŒä¸­è¿›è¡Œè®¿è°ˆè·å¾—çš„çœŸå®é©¾é©¶å‘˜è¡Œä¸ºæ•°æ®ã€‚æ™ºèƒ½ä½“åŸºäºLLMçš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿè‡ªä¸»è¯„ä¼°å…¶é©¾é©¶è¡Œä¸ºçš„è´¨é‡ï¼Œå¹¶ä¸è¯¦ç»†çš„é©¾é©¶è¡Œä¸ºæ¨ç†è¿›è¡Œæ¯”è¾ƒã€‚ç„¶åï¼Œå®ƒåŸºäºä¸“å®¶é©¾é©¶å‘˜çš„è¡Œä¸ºæå‡å…¶é©¾é©¶æŠ€èƒ½ã€‚è¿™ä¸€æ–¹æ³•ä¸åŒäºä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ å’Œå…¶ä»–è®­ç»ƒæ–¹æ³•ï¼Œå®ƒä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿç›´æ¥ä»é©¾é©¶å‘˜çš„è®°å½•ä¸­å­¦ä¹ ï¼Œç±»ä¼¼äººç±»ï¼Œæ— éœ€å°†å…¶è½¬åŒ–ä¸ºä»£ç ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºæœªæ¥äººç±»å¯¹é½çš„æ™ºèƒ½ä½“ç”Ÿæˆæä¾›äº†å®è´µçš„è§è§£ã€‚
- en: References
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] S.Â Yao, J.Â Zhao, D.Â Yu, N.Â Du, I.Â Shafran, K.Â Narasimhan, and Y.Â Cao, â€œReact:
    Synergizing reasoning and acting in language models,â€ *arXiv preprint arXiv:2210.03629*,
    2022.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, å’Œ Y. Caoï¼Œâ€œReactï¼šåœ¨è¯­è¨€æ¨¡å‹ä¸­ååŒæ¨ç†ä¸è¡Œä¸ºï¼Œâ€
    *arXivé¢„å°æœ¬ arXiv:2210.03629*ï¼Œ2022å¹´ã€‚'
- en: '[2] H.Â Liu, D.Â Tam, M.Â Muqeeth, J.Â Mohta, T.Â Huang, M.Â Bansal, and C.Â A. Raffel,
    â€œFew-shot parameter-efficient fine-tuning is better and cheaper than in-context
    learning,â€ *Advances in Neural Information Processing Systems*, vol.Â 35, pp. 1950â€“1965,
    2022.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, å’Œ C. A. Raffelï¼Œâ€œå°‘é‡æ ·æœ¬çš„å‚æ•°é«˜æ•ˆå¾®è°ƒä¼˜äºä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œâ€
    *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬35å·ï¼Œç¬¬1950-1965é¡µï¼Œ2022å¹´ã€‚'
- en: '[3] T.Â Brown, B.Â Mann, N.Â Ryder, M.Â Subbiah, J.Â D. Kaplan, P.Â Dhariwal, A.Â Neelakantan,
    P.Â Shyam, G.Â Sastry, A.Â Askell, *etÂ al.*, â€œLanguage models are few-shot learners,â€
    *Advances in neural information processing systems*, vol.Â 33, pp. 1877â€“1901, 2020.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell, *ç­‰*ï¼Œâ€œè¯­è¨€æ¨¡å‹æ˜¯å°‘é‡æ ·æœ¬å­¦ä¹ è€…ï¼Œâ€ *ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬33å·ï¼Œç¬¬1877-1901é¡µï¼Œ2020å¹´ã€‚'
- en: '[4] S.Â Hao, Y.Â Gu, H.Â Ma, J.Â J. Hong, Z.Â Wang, D.Â Z. Wang, and Z.Â Hu, â€œReasoning
    with language model is planning with world model,â€ *arXiv preprint arXiv:2305.14992*,
    2023.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] S. Hao, Y. Gu, H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, å’Œ Z. Huï¼Œâ€œä¸è¯­è¨€æ¨¡å‹æ¨ç†å³æ˜¯ä½¿ç”¨ä¸–ç•Œæ¨¡å‹è¿›è¡Œè§„åˆ’ï¼Œâ€
    *arXivé¢„å°æœ¬ arXiv:2305.14992*ï¼Œ2023å¹´ã€‚'
- en: '[5] Z.Â Xi, W.Â Chen, X.Â Guo, W.Â He, Y.Â Ding, B.Â Hong, M.Â Zhang, J.Â Wang, S.Â Jin,
    E.Â Zhou, *etÂ al.*, â€œThe rise and potential of large language model based agents:
    A survey,â€ *arXiv preprint arXiv:2309.07864*, 2023.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S.
    Jin, E. Zhou, *ç­‰*ï¼Œâ€œåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“çš„å´›èµ·ä¸æ½œåŠ›ï¼šä¸€é¡¹è°ƒæŸ¥ï¼Œâ€ *arXivé¢„å°æœ¬ arXiv:2309.07864*ï¼Œ2023å¹´ã€‚'
- en: '[6] J.Â Huang, S.Â Yong, X.Â Ma, X.Â Linghu, P.Â Li, Y.Â Wang, Q.Â Li, S.-C. Zhu,
    B.Â Jia, and S.Â Huang, â€œAn embodied generalist agent in 3d world,â€ *arXiv preprint
    arXiv:2311.12871*, 2023.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] J. Huang, S. Yong, X. Ma, X. Linghu, P. Li, Y. Wang, Q. Li, S.-C. Zhu,
    B. Jia, å’Œ S. Huang, â€œ3Dä¸–ç•Œä¸­çš„å…·èº«é€šç”¨ä½“æ™ºèƒ½ä½“ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2311.12871*, 2023ã€‚'
- en: '[7] P.Â Chen, X.Â Sun, H.Â Zhi, R.Â Zeng, T.Â H. Li, G.Â Liu, M.Â Tan, and C.Â Gan,
    â€œ$ a^ 2$ nav: Action-aware zero-shot robot navigation by exploiting vision-and-language
    ability of foundation models,â€ *arXiv preprint arXiv:2308.07997*, 2023.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] P. Chen, X. Sun, H. Zhi, R. Zeng, T. H. Li, G. Liu, M. Tan, å’Œ C. Gan, â€œ$a^2$
    nav: åˆ©ç”¨åŸºç¡€æ¨¡å‹çš„è§†è§‰ä¸è¯­è¨€èƒ½åŠ›è¿›è¡Œè¡ŒåŠ¨æ„ŸçŸ¥çš„é›¶æ ·æœ¬æœºå™¨äººå¯¼èˆªï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2308.07997*, 2023ã€‚'
- en: '[8] L.Â Chen, Y.Â Zhang, S.Â Ren, H.Â Zhao, Z.Â Cai, Y.Â Wang, P.Â Wang, T.Â Liu, and
    B.Â Chang, â€œTowards end-to-end embodied decision making via multi-modal large language
    model: Explorations with gpt4-vision and beyond,â€ *arXiv preprint arXiv:2310.02071*,
    2023.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] L. Chen, Y. Zhang, S. Ren, H. Zhao, Z. Cai, Y. Wang, P. Wang, T. Liu, å’Œ
    B. Chang, â€œé€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¨åŠ¨ç«¯åˆ°ç«¯å…·èº«å†³ç­–ï¼šåŸºäºgpt4-visionåŠå…¶åç»­æ¢ç´¢ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.02071*,
    2023ã€‚'
- en: '[9] A.Â Rajvanshi, K.Â Sikka, X.Â Lin, B.Â Lee, H.-P. Chiu, and A.Â Velasquez, â€œSaynav:
    Grounding large language models for dynamic planning to navigation in new environments,â€
    *arXiv preprint arXiv:2309.04077*, 2023.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] A. Rajvanshi, K. Sikka, X. Lin, B. Lee, H.-P. Chiu, å’Œ A. Velasquez, â€œSaynav:
    åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŠ¨æ€è§„åˆ’ä¸æ–°ç¯å¢ƒå¯¼èˆªçš„åŸºç¡€æ–¹æ³•ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2309.04077*, 2023ã€‚'
- en: '[10] C.Â H. Song, J.Â Wu, C.Â Washington, B.Â M. Sadler, W.-L. Chao, and Y.Â Su,
    â€œLlm-planner: Few-shot grounded planning for embodied agents with large language
    models,â€ in *Proceedings of the IEEE/CVF International Conference on Computer
    Vision*, 2023, pp. 2998â€“3009.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] C. H. Song, J. Wu, C. Washington, B. M. Sadler, W.-L. Chao, å’Œ Y. Su, â€œLLM-planner:
    åŸºäºå°‘é‡ç¤ºä¾‹çš„å…·èº«æ™ºèƒ½ä½“è§„åˆ’æ–¹æ³•ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼Œâ€ æ”¶å½•äº *IEEE/CVFè®¡ç®—æœºè§†è§‰å›½é™…ä¼šè®®è®ºæ–‡é›†*ï¼Œ2023ï¼Œç¬¬2998-3009é¡µã€‚'
- en: '[11] Z.Â Wu, Z.Â Wang, X.Â Xu, J.Â Lu, and H.Â Yan, â€œEmbodied task planning with
    large language models,â€ *arXiv preprint arXiv:2307.01848*, 2023.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Z. Wu, Z. Wang, X. Xu, J. Lu, å’Œ H. Yan, â€œç»“åˆå¤§è¯­è¨€æ¨¡å‹çš„å…·èº«ä»»åŠ¡è§„åˆ’ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2307.01848*,
    2023ã€‚'
- en: '[12] Y.Â Wu, S.Â Y. Min, Y.Â Bisk, R.Â Salakhutdinov, A.Â Azaria, Y.Â Li, T.Â Mitchell,
    and S.Â Prabhumoye, â€œPlan, eliminate, and trackâ€“language models are good teachers
    for embodied agents,â€ *arXiv preprint arXiv:2305.02412*, 2023.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Y. Wu, S. Y. Min, Y. Bisk, R. Salakhutdinov, A. Azaria, Y. Li, T. Mitchell,
    å’Œ S. Prabhumoye, â€œè®¡åˆ’ã€æ¶ˆé™¤ä¸è·Ÿè¸ªâ€”â€”è¯­è¨€æ¨¡å‹æ˜¯å…·èº«æ™ºèƒ½ä½“çš„è‰¯å¸ˆç›Šå‹ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2305.02412*, 2023ã€‚'
- en: '[13] G.Â Wang, Y.Â Xie, Y.Â Jiang, A.Â Mandlekar, C.Â Xiao, Y.Â Zhu, L.Â Fan, and
    A.Â Anandkumar, â€œVoyager: An open-ended embodied agent with large language models,â€
    *arXiv preprint arXiv:2305.16291*, 2023.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] G. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan, å’Œ A.
    Anandkumar, â€œVoyager: ä¸€ä¸ªå¼€æ”¾å¼çš„å…·èº«æ™ºèƒ½ä½“ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2305.16291*, 2023ã€‚'
- en: '[14] A.Â Zhao, D.Â Huang, Q.Â Xu, M.Â Lin, Y.-J. Liu, and G.Â Huang, â€œExpel: Llm
    agents are experiential learners,â€ 2023.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] A. Zhao, D. Huang, Q. Xu, M. Lin, Y.-J. Liu, å’Œ G. Huang, â€œExpel: LLMæ™ºèƒ½ä½“æ˜¯ç»éªŒå­¦ä¹ è€…ï¼Œâ€
    2023ã€‚'
- en: '[15] L.Â Chen, O.Â Sinavski, J.Â HÃ¼nermann, A.Â Karnsund, A.Â J. Willmott, D.Â Birch,
    D.Â Maund, and J.Â Shotton, â€œDriving with llms: Fusing object-level vector modality
    for explainable autonomous driving,â€ *arXiv preprint arXiv:2310.01957*, 2023.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] L. Chen, O. Sinavski, J. HÃ¼nermann, A. Karnsund, A. J. Willmott, D. Birch,
    D. Maund, å’Œ J. Shotton, â€œä¸LLMå…±åŒé©¾é©¶ï¼šèåˆé¢å‘å¯¹è±¡çš„å‘é‡æ¨¡æ€ä»¥å®ç°å¯è§£é‡Šçš„è‡ªåŠ¨é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.01957*,
    2023ã€‚'
- en: '[16] Z.Â Xu, Y.Â Zhang, E.Â Xie, Z.Â Zhao, Y.Â Guo, K.Â K. Wong, Z.Â Li, and H.Â Zhao,
    â€œDrivegpt4: Interpretable end-to-end autonomous driving via large language model,â€
    *arXiv preprint arXiv:2310.01412*, 2023.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Z. Xu, Y. Zhang, E. Xie, Z. Zhao, Y. Guo, K. K. Wong, Z. Li, å’Œ H. Zhao,
    â€œDrivegpt4: åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2310.01412*, 2023ã€‚'
- en: '[17] B.Â Chen, Z.Â Zhang, N.Â LangrenÃ©, and S.Â Zhu, â€œUnleashing the potential
    of prompt engineering in large language models: a comprehensive review,â€ *arXiv
    preprint arXiv:2310.14735*, 2023.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] B. Chen, Z. Zhang, N. LangrenÃ©, å’Œ S. Zhu, â€œé‡Šæ”¾å¤§è¯­è¨€æ¨¡å‹ä¸­æç¤ºå·¥ç¨‹çš„æ½œåŠ›ï¼šä¸€é¡¹å…¨é¢å›é¡¾ï¼Œâ€ *arXiv
    é¢„å°æœ¬ arXiv:2310.14735*, 2023ã€‚'
- en: '[18] C.Â Cui, Y.Â Ma, X.Â Cao, W.Â Ye, and Z.Â Wang, â€œDrive as you speak: Enabling
    human-like interaction with large language models in autonomous vehicles,â€ in
    *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision*,
    2024, pp. 902â€“909.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] C. Cui, Y. Ma, X. Cao, W. Ye, å’Œ Z. Wang, â€œåƒè¯´è¯ä¸€æ ·é©¾é©¶ï¼šåœ¨äººç±»æ™ºèƒ½ä¸å¤§è¯­è¨€æ¨¡å‹ä¹‹é—´å®ç°è‡ªåŠ¨é©¾é©¶æ±½è½¦çš„äº¤äº’ï¼Œâ€
    æ”¶å½•äº *IEEE/CVFè®¡ç®—æœºè§†è§‰åº”ç”¨å†¬å­£ä¼šè®®è®ºæ–‡é›†*ï¼Œ2024ï¼Œç¬¬902-909é¡µã€‚'
- en: '[19] L.Â Wen, D.Â Fu, X.Â Li, X.Â Cai, T.Â Ma, P.Â Cai, M.Â Dou, B.Â Shi, L.Â He, and
    Y.Â Qiao, â€œDilu: A knowledge-driven approach to autonomous driving with large language
    models,â€ *arXiv preprint arXiv:2309.16292*, 2023.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] L. Wen, D. Fu, X. Li, X. Cai, T. Ma, P. Cai, M. Dou, B. Shi, L. He, å’Œ
    Y. Qiao, â€œDilu: ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†é©±åŠ¨è‡ªåŠ¨é©¾é©¶æ–¹æ³•ï¼Œâ€ *arXiv é¢„å°æœ¬ arXiv:2309.16292*, 2023ã€‚'
- en: '[20] D.Â Fu, X.Â Li, L.Â Wen, M.Â Dou, P.Â Cai, B.Â Shi, and Y.Â Qiao, â€œDrive like
    a human: Rethinking autonomous driving with large language models,â€ in *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, 2024, pp.
    910â€“919.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] D. Fu, X. Li, L. Wen, M. Dou, P. Cai, B. Shi, å’Œ Y. Qiaoï¼Œâ€œåƒäººç±»ä¸€æ ·é©¾é©¶ï¼šç”¨å¤§å‹è¯­è¨€æ¨¡å‹é‡æ–°æ€è€ƒè‡ªåŠ¨é©¾é©¶ï¼Œâ€å‘è¡¨äº*IEEE/CVFå†¬å­£è®¡ç®—æœºè§†è§‰åº”ç”¨ä¼šè®®è®ºæ–‡é›†*ï¼Œ2024å¹´ï¼Œç¬¬910-919é¡µã€‚'
- en: '[21] M.Â Shanahan, K.Â McDonell, and L.Â Reynolds, â€œRole play with large language
    models,â€ *Nature*, vol. 623, no. 7987, pp. 493â€“498, 2023.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] M. Shanahan, K. McDonell, å’Œ L. Reynoldsï¼Œâ€œä¸å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè§’è‰²æ‰®æ¼”ï¼Œâ€*è‡ªç„¶*ï¼Œç¬¬623å·ï¼Œç¬¬7987æœŸï¼Œç¬¬493-498é¡µï¼Œ2023å¹´ã€‚'
- en: '[22] M.Â Luo, X.Â Xu, Z.Â Dai, P.Â Pasupat, M.Â Kazemi, C.Â Baral, V.Â Imbrasaite,
    and V.Â Y. Zhao, â€œDr. icl: Demonstration-retrieved in-context learning,â€ *arXiv
    preprint arXiv:2305.14128*, 2023.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] M. Luo, X. Xu, Z. Dai, P. Pasupat, M. Kazemi, C. Baral, V. Imbrasaite,
    å’Œ V. Y. Zhaoï¼Œâ€œDr. iclï¼šé€šè¿‡æ¼”ç¤ºè·å–çš„ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œâ€*arXivé¢„å°æœ¬arXiv:2305.14128*ï¼Œ2023å¹´ã€‚'
- en: '[23] L.Â Ouyang, J.Â Wu, X.Â Jiang, D.Â Almeida, C.Â Wainwright, P.Â Mishkin, C.Â Zhang,
    S.Â Agarwal, K.Â Slama, A.Â Ray, *etÂ al.*, â€œTraining language models to follow instructions
    with human feedback,â€ *Advances in neural information processing systems*, vol.Â 35,
    pp. 27â€‰730â€“27â€‰744, 2022.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C.
    Zhang, S. Agarwal, K. Slama, A. Ray, *ç­‰äºº*ï¼Œâ€œè®­ç»ƒè¯­è¨€æ¨¡å‹æŒ‰ç…§æŒ‡ä»¤è¿›è¡Œæ“ä½œå¹¶ç»“åˆäººç±»åé¦ˆï¼Œâ€*ç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿè¿›å±•*ï¼Œç¬¬35å·ï¼Œç¬¬27,730-27,744é¡µï¼Œ2022å¹´ã€‚'
- en: '[24] A.Â Dosovitskiy, G.Â Ros, F.Â Codevilla, A.Â Lopez, and V.Â Koltun, â€œCarla:
    An open urban driving simulator,â€ in *Conference on robot learning*.Â Â Â PMLR, 2017,
    pp. 1â€“16.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, å’Œ V. Koltunï¼Œâ€œCarlaï¼šä¸€ä¸ªå¼€æ”¾çš„åŸå¸‚é©¾é©¶æ¨¡æ‹Ÿå™¨ï¼Œâ€å‘è¡¨äº*æœºå™¨äººå­¦ä¹ ä¼šè®®*ã€‚PMLR,
    2017, ç¬¬1-16é¡µã€‚'
