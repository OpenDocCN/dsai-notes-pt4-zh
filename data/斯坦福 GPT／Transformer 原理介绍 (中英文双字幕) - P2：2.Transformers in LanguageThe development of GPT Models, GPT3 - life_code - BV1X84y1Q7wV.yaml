- en: æ–¯å¦ç¦ GPTï¼Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P2ï¼š2.Transformers in LanguageThe development
    of GPT Models, GPT3 - life_code - BV1X84y1Q7wV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦ GPT/Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P2ï¼š2.è¯­è¨€ä¸­çš„Transformers GPTæ¨¡å‹çš„å‘å±•ï¼ŒGPT3 - life_code
    - BV1X84y1Q7wV
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_0.png)'
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_1.png)'
- en: Greatï¼Œ okay perfect so a sample from this model looks like thisï¼Œ so they also
    point to 99ã€‚6 billion from $2004063% know it's a bunch of kind of gibberish so
    the sentence isn't too coherentã€‚but at least the words do seem to be somewhat
    related like they come from the same spaceã€‚ğŸ˜Šã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_3.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œå®Œç¾ï¼Œå› æ­¤è¿™ä¸ªæ¨¡å‹çš„æ ·æœ¬çœ‹èµ·æ¥åƒè¿™æ ·ï¼Œå®ƒä»¬ä¹ŸæŒ‡å‘ä»$2004063%çš„99.6äº¿ï¼Œè¿™æ˜¯ä¸€å †æ— æ„ä¹‰çš„è¯ï¼Œæ‰€ä»¥å¥å­å¹¶ä¸å¤ªè¿è´¯ã€‚ä½†è‡³å°‘è¿™äº›è¯ä¼¼ä¹è¿˜æ˜¯æœ‰äº›ç›¸å…³ï¼Œåƒæ˜¯æ¥è‡ªåŒä¸€ä¸ªé¢†åŸŸã€‚ğŸ˜Šã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_3.png)
- en: Yesã€‚Now jumping forward to the beginning of the deep learning room in 2011ã€‚we
    have language modeling with neural networks now and in particular with recurrent
    neural networksã€‚so we can get rid of this giant lookup table from the NG models
    and instead we can have our influences be these tokens and let this kind of recurrent
    cell remember some state and persist some stateã€‚So if we set up a neural model
    like thisï¼Œ we get a sample as shown below so the meaning of life is the tradition
    of the ancient human reproduction is less favorable to the good boy for when to
    remove figure so again this doesn't really make any senseã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ã€‚ç°åœ¨è·³åˆ°2011å¹´æ·±åº¦å­¦ä¹ çš„åˆå§‹é˜¶æ®µã€‚æˆ‘ä»¬ç°åœ¨æœ‰åŸºäºç¥ç»ç½‘ç»œçš„è¯­è¨€å»ºæ¨¡ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨é€’å½’ç¥ç»ç½‘ç»œã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æ‘†è„±NGæ¨¡å‹ä¸­çš„å·¨å¤§æŸ¥æ‰¾è¡¨ï¼Œè€Œè®©è¿™äº›æ ‡è®°æˆä¸ºæˆ‘ä»¬çš„å½±å“ï¼Œè®©è¿™ç§é€’å½’å•å…ƒè®°ä½æŸäº›çŠ¶æ€å¹¶æŒç»­æŸäº›çŠ¶æ€ã€‚å¦‚æœæˆ‘ä»¬è®¾ç½®ä¸€ä¸ªç¥ç»æ¨¡å‹ï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°å¦‚ä¸‹æ ·æœ¬ï¼Œå› æ­¤ç”Ÿæ´»çš„æ„ä¹‰æ˜¯å¤ä»£äººç±»ç¹æ®–çš„ä¼ ç»Ÿå¯¹å¥½ç”·å­©çš„å½±å“è¾ƒå°ï¼Œå› æ­¤ç§»é™¤å›¾å½¢çš„æ—¶æœºä¸ä½³ï¼Œæ‰€ä»¥è¿™å®é™…ä¸Šå¹¶æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ã€‚
- en: but it kind of starts to have the flow of a real sentenceã€‚ğŸ˜Šã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_5.png)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ƒå¼€å§‹æœ‰äº†çœŸå®å¥å­çš„æµç•…æ„Ÿã€‚ğŸ˜Šã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_5.png)
- en: Yeahï¼Œ so jumping forward even more to 2016ï¼Œ we have LSTM models and of courseã€‚LSTMs
    are an architectural innovation on top of R endNs and they have kind of better
    gradient flow so they're ever better to they can better model long term dependenciesã€‚And
    so with an LSDM modelï¼Œ we get a sample like this with even more new technologies
    coming onto the market quickly during the past three years and increasing number
    of companiesã€‚musust tackle the ever changing and ever changing environmental or
    challenges onlineã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œæ‰€ä»¥å†å¾€å‰æ¨åˆ°2016å¹´ï¼Œæˆ‘ä»¬æœ‰äº†LSTMæ¨¡å‹ï¼Œå½“ç„¶ã€‚LSTMæ˜¯åŸºäºRNNçš„ä¸€ç§æ¶æ„åˆ›æ–°ï¼Œå…·æœ‰æ›´å¥½çš„æ¢¯åº¦æµï¼Œå› æ­¤å®ƒä»¬åœ¨å»ºæ¨¡é•¿æœŸä¾èµ–å…³ç³»æ–¹é¢è¡¨ç°æ›´ä½³ã€‚é€šè¿‡LSTMæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°è¿™æ ·çš„æ ·æœ¬ï¼Œåœ¨è¿‡å»ä¸‰å¹´ä¸­ï¼Œå¸‚åœºä¸Šè¿…é€Ÿå‡ºç°äº†æ›´å¤šæ–°æŠ€æœ¯ï¼Œä»¥åŠè¶Šæ¥è¶Šå¤šçš„å…¬å¸å¿…é¡»åº”å¯¹ä¸æ–­å˜åŒ–çš„åœ¨çº¿ç¯å¢ƒæˆ–æŒ‘æˆ˜ã€‚
- en: so this sentence is starting to make a little bit of senseã€‚though there are
    clear artifacts like the repetition of the phrase ever changingã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_7.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ä¸ªå¥å­å¼€å§‹æœ‰ç‚¹æ„æ€äº†ï¼Œå°½ç®¡æ˜æ˜¾æœ‰ä¸€äº›ä¼ªå½±ï¼Œæ¯”å¦‚â€œä¸æ–­å˜åŒ–â€è¿™ä¸ªçŸ­è¯­çš„é‡å¤ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_7.png)
- en: Nowï¼Œ starting in 2018ï¼Œ we have our first autoaggressive transformer based language
    modelsã€‚which are even better at modeling these very long term dependenciesã€‚And
    here what I'm showing is an example of a completionã€‚so in a completion the user
    supplies the prompt in this case it this text swings over Kansasã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä»2018å¹´å¼€å§‹ï¼Œæˆ‘ä»¬æœ‰äº†ç¬¬ä¸€ä¸ªåŸºäºè‡ªå›å½’çš„å˜æ¢å™¨è¯­è¨€æ¨¡å‹ï¼Œå®ƒä»¬åœ¨å»ºæ¨¡è¿™äº›éå¸¸é•¿æœŸçš„ä¾èµ–å…³ç³»æ–¹é¢è¡¨ç°å¾—æ›´å¥½ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å±•ç¤ºçš„æ˜¯ä¸€ä¸ªå®Œæˆçš„ä¾‹å­ã€‚åœ¨è¿™ä¸ªå®Œæˆä¸­ï¼Œç”¨æˆ·æä¾›æç¤ºï¼Œè¿™é‡Œæ˜¯â€œè¿™æ®µæ–‡å­—åœ¨å ªè¨æ–¯å·æ‘‡æ‘†â€ã€‚
- en: And the model will continue from this promptã€‚So you can see that this completion
    is proherent across multiple sentences nowã€‚though there are notable spelling mistakesï¼Œ
    so you see this like whatever do the fee isã€‚so it doesn't quite make senseã€‚And
    now we arrive at GPT2ï¼Œ which is a 1ã€‚5 billion parameter transformer modelã€‚And
    I copied in what I personally found was the most compelling completion from PPT2ã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹å°†ä»è¿™ä¸ªæç¤ºç»§ç»­ã€‚å› æ­¤ä½ å¯ä»¥çœ‹åˆ°è¿™ä¸ªå®Œæˆåœ¨å¤šä¸ªå¥å­ä¸­æ˜¯è¿è´¯çš„ï¼Œå°½ç®¡æœ‰æ˜æ˜¾çš„æ‹¼å†™é”™è¯¯ï¼Œæ‰€ä»¥ä½ ä¼šçœ‹åˆ°è¿™åƒæ˜¯â€œæ— è®ºè´¹ç”¨å¦‚ä½•â€ã€‚æ‰€ä»¥è¿™å¹¶ä¸å¤ªæœ‰æ„ä¹‰ã€‚ç°åœ¨æˆ‘ä»¬æ¥åˆ°äº†GPT2ï¼Œå®ƒæ˜¯ä¸€ä¸ª15äº¿å‚æ•°çš„å˜æ¢å™¨æ¨¡å‹ã€‚æˆ‘å¤åˆ¶äº†æˆ‘ä¸ªäººè®¤ä¸ºåœ¨PPT2ä¸­æœ€å¼•äººæ³¨ç›®çš„å®Œæˆã€‚
- en: And in contrast with the last slideï¼Œ what this does is it sets up a clearly
    fake problemã€‚so this we have something about finding unicorns and scientists in
    South Americaã€‚And so the model's probably not seen this exact prompt before and
    has to make up something that's consistentã€‚So the thing I find most impressive
    is it does so and is coherent across multiple paragraphsã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ä¸Šä¸€å¼ å¹»ç¯ç‰‡ç›¸åï¼Œè¿™ä¸ªæ¨¡å‹è®¾ç½®äº†ä¸€ä¸ªæ˜æ˜¾è™šå‡çš„é—®é¢˜ã€‚æˆ‘ä»¬æåˆ°å¯»æ‰¾ç‹¬è§’å…½å’Œå—ç¾çš„ç§‘å­¦å®¶ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯èƒ½ä»¥å‰æ²¡æœ‰è§è¿‡è¿™ä¸ªç¡®åˆ‡çš„æç¤ºï¼Œå¿…é¡»ç¼–é€ ä¸€äº›è¿è´¯çš„å†…å®¹ã€‚æ‰€ä»¥æˆ‘è§‰å¾—æœ€ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ï¼Œå®ƒç¡®å®åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªæ®µè½ä¸­ä¿æŒä¸€è‡´ã€‚
- en: it invents this fictional Drã€‚Perez and it persists Perez throughout multiple
    paragraphs and I think it's like very aly namedã€‚you have him from University of
    Lapaz and yeah we just have fairly coherent completions at this pointã€‚So it's
    worth disclosing that this was the best of 10 samplesã€‚so we still had to sample
    multiple times to get a sample like thisã€‚And finallyï¼Œ to end yeahï¼Œ yeahã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåˆ›é€ äº†è™šæ„çš„ä½©é›·æ–¯åšå£«ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªæ®µè½ä¸­æŒç»­æåˆ°ä½©é›·æ–¯ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªåå­—èµ·å¾—å¾ˆå¥½ã€‚ä½ å¯ä»¥çœ‹åˆ°ä»–æ¥è‡ªæ‹‰å·´æ–¯å¤§å­¦ï¼Œç›®å‰æˆ‘ä»¬å¾—åˆ°äº†ç›¸å½“è¿è´¯çš„å®Œæˆã€‚å› æ­¤å€¼å¾—è¯´æ˜çš„æ˜¯ï¼Œè¿™æ˜¯10ä¸ªæ ·æœ¬ä¸­æœ€å¥½çš„ä¸€ä¸ªï¼Œæ‰€ä»¥æˆ‘ä»¬ä»ç„¶éœ€è¦å¤šæ¬¡å–æ ·æ‰èƒ½å¾—åˆ°è¿™æ ·çš„æ ·æœ¬ã€‚æœ€åï¼Œç»“æŸæ—¶ï¼Œæ˜¯çš„ï¼Œæ˜¯çš„ã€‚
- en: for sure I can post them upã€‚Yesï¼Œ Yesï¼Œ yesï¼Œ yesã€‚ğŸ˜Šï¼ŒYeahã€‚ğŸ˜Šã€‚sorry one last when
    you have these1 you say we took the best the in what sense Yeah so this is human
    judge and I'll probably expand a little bit on that motivatedã€‚So I want to end
    this kind of fly by overview with GPT3 and since GT2 already produces such coherent
    text like how do you characterize GPT3 and I would say that the best way to do
    so is that say you took the best of like one best out of five or 10 completions
    from GT2 that would be kind of your first completion from GT3 and of course best
    is kind of a personal metric hereã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶æˆ‘å¯ä»¥æŠŠå®ƒä»¬å‘ä¸Šå»ã€‚æ˜¯çš„ï¼Œæ˜¯çš„ï¼Œæ˜¯çš„ã€‚ğŸ˜Šï¼Œå¥½çš„ã€‚ğŸ˜Šã€‚æŠ±æ­‰ï¼Œæœ€åä¸€ä¸ªé—®é¢˜ï¼Œå½“ä½ æåˆ°è¿™äº›æ—¶ï¼Œä½ è¯´æˆ‘ä»¬æŒ‘é€‰äº†æœ€å¥½çš„ï¼Œè¿™åœ¨ä»€ä¹ˆæ„ä¹‰ä¸Šï¼Ÿæ‰€ä»¥è¿™æ˜¯äººç±»è¯„åˆ¤ï¼Œæˆ‘å¯èƒ½ä¼šç¨å¾®æ‰©å±•ä¸€ä¸‹è¿™ä¸€åŠ¨æœºã€‚å› æ­¤ï¼Œæˆ‘æƒ³ä»¥è¿™ç§é£é€Ÿçš„æ¦‚è¿°ç»“æŸå…³äºGPT-3çš„è®¨è®ºï¼Œå› ä¸ºG2å·²ç»äº§ç”Ÿäº†å¦‚æ­¤è¿è´¯çš„æ–‡æœ¬ï¼ŒåƒGPT-3ä½ ä¼šå¦‚ä½•è¡¨å¾å‘¢ï¼Ÿæˆ‘è®¤ä¸ºæœ€å¥½æ–¹å¼æ˜¯è¯´ä½ ä»G2çš„äº”æˆ–åä¸ªå®Œæˆä¸­æŒ‘é€‰äº†æœ€å¥½çš„ä¸€é¡¹ï¼Œé‚£å°±æ˜¯ä½ ä»G3å¾—åˆ°çš„ç¬¬ä¸€æ¬¡å®Œæˆï¼Œå½“ç„¶â€œæœ€å¥½â€åœ¨è¿™é‡Œæ˜¯ä¸€ç§ä¸ªäººæ ‡å‡†ã€‚
- en: So here I'm showing completion from the blood class3 body problemã€‚You can see
    that the impressive things about this completion or that it really stays true
    to this style of the novelã€‚I think the second thing that kind of impressed me
    was just how poet like the metaphors and siimmis that it produces are so you have
    this stuff like blood was seeing through her jacket and the dark red flowers blooming
    on her chest like these kind of like very very poetic and stylistic sentencesã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘å±•ç¤ºäº†æ¥è‡ªè¡€æ¶²ç±»3èº«ä½“é—®é¢˜çš„å®Œæˆã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™ä¸ªå®Œæˆçš„ä»¤äººå°è±¡æ·±åˆ»ä¹‹å¤„åœ¨äºï¼Œå®ƒçœŸçš„ä¿æŒäº†å°è¯´çš„é£æ ¼ã€‚æˆ‘è§‰å¾—å¦ä¸€ä¸ªä»¤æˆ‘å°è±¡æ·±åˆ»çš„åœ°æ–¹æ˜¯å®ƒæ‰€äº§ç”Ÿçš„éšå–»å’Œæ¯”å–»éå¸¸åƒè¯—å¥ï¼Œæ¯”å¦‚â€œè¡€æ¶²é€è¿‡å¥¹çš„å¤–å¥—ï¼Œæ·±çº¢è‰²çš„èŠ±æœµåœ¨å¥¹çš„èƒ¸å£ç»½æ”¾â€ï¼Œè¿™äº›å¥å­éå¸¸éå¸¸å¯Œæœ‰è¯—æ„å’Œé£æ ¼ã€‚
- en: So it definitely understands it's part of a novel and is' trying to generate
    this kind of prose thatã€‚In the same styleã€‚So as generated text becomes more and
    more coherentã€‚I think one really output Yeah so it's 175 billion parameters versus
    G2 which is one around 1 billion subtle Yeah that's a very good question So theres
    kind maybe we can dive into it a little bit after but there is work on kind of
    neural scaling laws and so the idea is like can you predict the performance of
    a larger model from a series of smaller models and so I would rather characterize
    the increase in performance not by kind the small gain perplexity but like whether
    it lines up with the projections and in that sense G3 does yeah that's some intuition
    for yeah I think personally Open we going to stop this experiment if it didn'tã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒç¡®å®ç†è§£å®ƒæ˜¯å°è¯´çš„ä¸€éƒ¨åˆ†ï¼Œå¹¶ä¸”åœ¨å°è¯•ç”Ÿæˆè¿™ç§é£æ ¼çš„æ•£æ–‡ã€‚éšç€ç”Ÿæˆæ–‡æœ¬å˜å¾—è¶Šæ¥è¶Šè¿è´¯ï¼Œæˆ‘è®¤ä¸ºä¸€ä¸ªçœŸæ­£çš„è¾“å‡ºæ˜¯1750äº¿ä¸ªå‚æ•°ï¼Œè€ŒG2å¤§çº¦æ˜¯10äº¿ä¸ªï¼Œè¿™ç¡®å®æ˜¯ä¸ªå¥½é—®é¢˜ã€‚å› æ­¤ï¼Œå¯èƒ½æˆ‘ä»¬å¯ä»¥ç¨åæ·±å…¥è®¨è®ºä¸€ä¸‹ï¼Œè¿™é‡Œæœ‰ä¸€äº›å…³äºç¥ç»ç½‘ç»œè§„æ¨¡æ³•åˆ™çš„ç ”ç©¶ï¼Œæƒ³æ³•æ˜¯ä½ èƒ½å¦ä»ä¸€ç³»åˆ—è¾ƒå°æ¨¡å‹ä¸­é¢„æµ‹è¾ƒå¤§æ¨¡å‹çš„æ€§èƒ½ã€‚æˆ‘æ›´å€¾å‘äºé€šè¿‡è¿™ç§å°çš„å›°æƒ‘åº¦æå‡æ¥è¡¨å¾æ€§èƒ½çš„æé«˜ï¼Œè€Œæ˜¯çœ‹å®ƒæ˜¯å¦ç¬¦åˆé¢„æµ‹ï¼Œåœ¨è¿™ä¸ªæ„ä¹‰ä¸ŠG3ç¡®å®å¦‚æ­¤ã€‚å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œæˆ‘è®¤ä¸ºå¦‚æœæ²¡æœ‰è¿™æ ·çš„ç»“æœï¼Œæˆ‘ä»¬å°†åœæ­¢è¿™ä¸ªå®éªŒã€‚
- en: This little bit general thing so we don't need to go through this changing in
    machine learning you be equal pushing for like an extra you know 1% to ã€‚5% accuracyï¼Œ
    but the models are increasing in a scale that's professional right so I wonder
    sometimesã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ‰ç‚¹æ™®éï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦é€æ­¥è®²è§£æœºå™¨å­¦ä¹ çš„å˜åŒ–ï¼Œä½ ä¼šå‘ç°å®ƒä»¬åœ¨ç²¾ç¡®åº¦ä¸Šæ¨åŠ¨äº†å¤§çº¦1%åˆ°0.5%çš„æå‡ï¼Œä½†æ¨¡å‹çš„è§„æ¨¡æ­£åœ¨ä¸“ä¸šåŒ–åœ°å¢é•¿ï¼Œå› æ­¤æˆ‘æœ‰æ—¶ä¼šæ„Ÿåˆ°å¥½å¥‡ã€‚
- en: Whether it's worth it like where you should stop right yeahã€‚I think maybe this
    slide will get to it a little bitã€‚but there's also some sense in which like as
    you reach kind of like the entropy floor of modeling like every having kind of
    gives you like like if you think about accuracy right it's not on a linear scale
    right like a 1% early on isn't the same as that last 1% and so yeah those last
    bits really do help you squeeze a little bit out of this accuracy Oh yesã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯å¦å€¼å¾—ï¼Œä»¥åŠä½ åº”è¯¥åœ¨å“ªé‡Œåœæ­¢ï¼Œæˆ‘è®¤ä¸ºä¹Ÿè®¸è¿™ä¸€å¼ å¹»ç¯ç‰‡ä¼šç¨å¾®æåˆ°ï¼Œä½†è¿˜æœ‰ä¸€ç§æ„ä¹‰æ˜¯ï¼Œå½“ä½ è¾¾åˆ°å»ºæ¨¡çš„ç†µåº•çº¿æ—¶ï¼Œæ¯ä¸€æ¬¡çš„æé«˜éƒ½ä¼šç»™ä½ å¸¦æ¥å½±å“ï¼Œæ€è€ƒå‡†ç¡®æ€§æ—¶ï¼Œè¿™ä¸æ˜¯çº¿æ€§æ¯”ä¾‹ï¼Œæœ€å¼€å§‹çš„1%å’Œæœ€åçš„1%å¹¶ä¸ç›¸åŒï¼Œæœ€åçš„éƒ¨åˆ†ç¡®å®èƒ½å¸®åŠ©ä½ æŒ¤å‡ºä¸€ç‚¹å‡†ç¡®æ€§ã€‚
- en: yesï¼Œ sorry this is accuracy I will explain the slideã€‚So yepã€‚so as generated
    text becomes more and more realisticã€‚I think one very natural question to ask
    is whether humans can still distinguish between real and big texts right and so
    in here we have this is of course like a very setup scenario it's not in all cases
    the models they would occur humansã€‚but this is for news articlesï¼Œ we kind of presented
    GPT3 generated samples against real news articlesã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼ŒæŠ±æ­‰ï¼Œè¿™æ˜¯å‡†ç¡®æ€§ï¼Œæˆ‘å°†è§£é‡Šè¿™ä¸€å¼ å¹»ç¯ç‰‡ã€‚æ˜¯çš„ï¼Œéšç€ç”Ÿæˆæ–‡æœ¬å˜å¾—è¶Šæ¥è¶ŠçœŸå®ï¼Œæˆ‘è®¤ä¸ºä¸€ä¸ªéå¸¸è‡ªç„¶çš„é—®é¢˜æ˜¯äººç±»æ˜¯å¦ä»ç„¶èƒ½åŒºåˆ†çœŸå®ä¸ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå› æ­¤åœ¨è¿™é‡Œæˆ‘ä»¬å½“ç„¶æ˜¯åœ¨ä¸€ä¸ªéå¸¸è®¾å®šçš„åœºæ™¯ä¸‹ï¼Œå¹¶ä¸é€‚ç”¨äºæ‰€æœ‰æƒ…å†µä¸‹æ¨¡å‹çš„è¡¨ç°ï¼Œä½†è¿™æ˜¯é’ˆå¯¹æ–°é—»æ–‡ç« ï¼Œæˆ‘ä»¬å°†GPT3ç”Ÿæˆçš„æ ·æœ¬ä¸çœŸå®æ–°é—»æ–‡ç« è¿›è¡Œå¯¹æ¯”ã€‚
- en: and you can tell kind of as the number of parameters increasesã€‚the ability of
    humans to distinguish between the real Olympic big articlesã€‚that ability goes
    down to nerve randomom chanceã€‚ğŸ˜Šï¼ŒAnd oh yesã€‚how did you generate the news articles
    what Oh I'm actually not completely sure so I didn't do this work particularlyã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šå‘ç°éšç€å‚æ•°æ•°é‡çš„å¢åŠ ï¼Œäººç±»åŒºåˆ†çœŸå®ä¸ç”Ÿæˆçš„å¥¥æ—åŒ¹å…‹æ–‡ç« çš„èƒ½åŠ›ä¸‹é™åˆ°éšæœºæœºä¼šã€‚ğŸ˜Šï¼Œå“¦ï¼Œæ˜¯çš„ï¼Œä½ æ˜¯æ€ä¹ˆç”Ÿæˆæ–°é—»æ–‡ç« çš„ï¼Ÿå“¦ï¼Œæˆ‘å®é™…ä¸Šå¹¶ä¸å®Œå…¨ç¡®å®šï¼Œå› ä¸ºæˆ‘æ²¡æœ‰ç‰¹åˆ«å‚ä¸è¿™é¡¹å·¥ä½œã€‚
- en: but I think one possible approach would be to prime with a couple of news articles
    and then just to have a delimiter and just have it start generating news articles
    from thereã€‚Yeahã€‚Or any other precusionsï¼ŸYeahã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_9.png)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘è®¤ä¸ºä¸€ç§å¯èƒ½çš„æ–¹æ³•æ˜¯é€šè¿‡å‡ ç¯‡æ–°é—»æ–‡ç« è¿›è¡Œå¼•å¯¼ï¼Œç„¶åè®¾ç½®ä¸€ä¸ªåˆ†éš”ç¬¦ï¼Œè®©ç³»ç»Ÿä»é‚£é‡Œå¼€å§‹ç”Ÿæˆæ–°é—»æ–‡ç« ã€‚å¯¹ï¼Œæˆ–è€…è¿˜æœ‰å…¶ä»–çš„é¢„å¤„ç†å—ï¼Ÿå¯¹ï¼[](img/542291b724ae1b1a3bd31a38e9d3acdc_9.png)
- en: Greatï¼Œ so even with all of these impressive resultsã€‚I think it's worth taking
    a step back at this point and askingã€‚what do we really care about language modeling
    forï¼ŸAnd what is that actually useful forï¼Ÿ
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼Œæ‰€ä»¥å³ä½¿æœ‰è¿™äº›ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œæˆ‘è®¤ä¸ºæ­¤æ—¶å€¼å¾—é€€ä¸€æ­¥é—®ï¼šæˆ‘ä»¬ç©¶ç«Ÿä¸ºä½•å…³å¿ƒè¯­è¨€å»ºæ¨¡ï¼Ÿå®ƒå®é™…ä¸Šæœ‰ä»€ä¹ˆç”¨ï¼Ÿ
- en: And I think you don't you make the argument that it is actually a fairly narrow
    capabilityã€‚like why would you just want some system that just continues text for
    youï¼Ÿ
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºä½ å¯ä»¥æå‡ºè¿™æ ·çš„è®ºç‚¹ï¼šå®ƒå®é™…ä¸Šæ˜¯ä¸€ä¸ªç›¸å¯¹ç‹­çª„çš„èƒ½åŠ›ã€‚ä¸ºä»€ä¹ˆä½ åªæƒ³è¦ä¸€ä¸ªæŒç»­ç”Ÿæˆæ–‡æœ¬çš„ç³»ç»Ÿå‘¢ï¼Ÿ
- en: And you can argue that there's more important test to solve like summarization
    or translationã€‚And I think most researchersï¼Œ I open meï¼Œ I would agree with this
    point of viewã€‚And in factã€‚GPT was not really a project that was focused on language
    modeling as an end goalã€‚but mostly as a tool to solve a problem called unsupervised
    learningã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è¯´è¿˜æœ‰æ›´é‡è¦çš„æµ‹è¯•éœ€è¦è§£å†³ï¼Œæ¯”å¦‚æ‘˜è¦æˆ–ç¿»è¯‘ï¼Œæˆ‘è®¤ä¸ºå¤§å¤šæ•°ç ”ç©¶äººå‘˜ï¼ŒåŒ…æ‹¬æˆ‘è‡ªå·±ï¼Œéƒ½ä¼šåŒæ„è¿™ä¸€è§‚ç‚¹ã€‚å®é™…ä¸Šï¼ŒGPTå¹¶ä¸æ˜¯ä¸€ä¸ªä»¥è¯­è¨€å»ºæ¨¡ä¸ºæœ€ç»ˆç›®æ ‡çš„é¡¹ç›®ï¼Œè€Œä¸»è¦æ˜¯ä½œä¸ºè§£å†³ä¸€ä¸ªè¢«ç§°ä¸ºæ— ç›‘ç£å­¦ä¹ çš„é—®é¢˜çš„å·¥å…·ã€‚
- en: which I'm going to go through in the next couple of slidesã€‚So I want to do a
    history of language modeling at Open AI and hopefully motivate why we ended up
    at the GPT series of models and kind of how we arrive there and hopefully it'll
    become much more intuitive after this sectionã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†åœ¨æ¥ä¸‹æ¥çš„å‡ å¼ å¹»ç¯ç‰‡ä¸­è®²è¿°è¿™ä¸ªé—®é¢˜ã€‚å› æ­¤ï¼Œæˆ‘æƒ³å›é¡¾ä¸€ä¸‹Open AIçš„è¯­è¨€å»ºæ¨¡å†å²ï¼Œå¹¶å¸Œæœ›èƒ½æ¿€åŠ±æˆ‘ä»¬ä¸ºä½•æœ€ç»ˆé€‰æ‹©äº†GPTç³»åˆ—æ¨¡å‹ï¼Œä»¥åŠæˆ‘ä»¬æ˜¯å¦‚ä½•åˆ°è¾¾è¿™ä¸€ç‚¹çš„ï¼Œå¸Œæœ›åœ¨è¿™ä¸€éƒ¨åˆ†åä¼šå˜å¾—æ›´ç›´è§‚ã€‚
- en: So the deep learning boom started in 2012 with Alexã€‚Wwhich was a system that
    could take images and labels and it could classify images to their labels and
    what we found with Alexnet was these systems were able to generalize surprisingly
    well like you could take data sets that weren't necessarily the training distribution
    and used to have pretty good features onã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦å­¦ä¹ çš„ç¹è£å§‹äº2012å¹´ï¼ŒAlexnetæ˜¯ä¸€ä¸ªèƒ½å¤Ÿå°†å›¾åƒä¸æ ‡ç­¾åŒ¹é…å¹¶å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»çš„ç³»ç»Ÿï¼Œæˆ‘ä»¬å‘ç°Alexnetè¿™äº›ç³»ç»Ÿèƒ½å¤Ÿå‡ºå¥‡åœ°å¾ˆå¥½åœ°è¿›è¡Œæ³›åŒ–ï¼Œç”šè‡³å¯ä»¥ä½¿ç”¨é‚£äº›å¹¶ä¸ä¸€å®šå±äºè®­ç»ƒåˆ†å¸ƒçš„æ•°æ®é›†ã€‚
- en: And since thenï¼Œ this kind of supervised approach has been reallyã€‚really powerful
    right we've been able to train models in many different domains to classify very
    accuratelyã€‚ğŸ˜Šï¼ŒAnd you can even have some guarantees that supervised learning will
    work wellã€‚so there's critical risk immunization and but the problem with supervised
    learning is that oftentimes the labels are scarceã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£æ—¶èµ·ï¼Œè¿™ç§ç›‘ç£æ–¹æ³•çœŸçš„å˜å¾—éå¸¸å¼ºå¤§ã€‚æˆ‘ä»¬èƒ½å¤Ÿåœ¨è®¸å¤šä¸åŒçš„é¢†åŸŸè®­ç»ƒæ¨¡å‹ä»¥éå¸¸å‡†ç¡®åœ°è¿›è¡Œåˆ†ç±»ã€‚ğŸ˜Šï¼Œè€Œä¸”ä½ ç”šè‡³å¯ä»¥æœ‰ä¸€äº›ä¿è¯ï¼Œç›‘ç£å­¦ä¹ ä¼šè¿ä½œè‰¯å¥½ã€‚å› æ­¤ï¼Œå­˜åœ¨å…³é”®çš„é£é™©å…ç–«ï¼Œä½†ç›‘ç£å­¦ä¹ çš„é—®é¢˜åœ¨äºæ ‡ç­¾å¾€å¾€ç¨€ç¼ºã€‚
- en: right especially in language testsï¼Œ there isn't really that many kind of text
    paired with their summaries or too many pairs across languages for instanceã€‚So
    collecting a lot of data can be not too hardï¼Œ but actually scalably labeling all
    of that dataã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å°¤å…¶æ˜¯åœ¨è¯­è¨€æµ‹è¯•ä¸­ï¼Œå¹¶æ²¡æœ‰å¤ªå¤šæ–‡æœ¬ä¸å…¶æ‘˜è¦é…å¯¹ï¼Œæˆ–è€…è·¨è¯­è¨€çš„é…å¯¹ä¹Ÿå¾ˆå°‘ã€‚å› æ­¤ï¼Œæ”¶é›†å¤§é‡æ•°æ®å¯èƒ½å¹¶ä¸éš¾ï¼Œä½†å®é™…ä¸Šè¦å¯æ‰©å±•åœ°æ ‡è®°æ‰€æœ‰è¿™äº›æ•°æ®å´å¾ˆå›°éš¾ã€‚
- en: it could be very time consuming and expensiveã€‚So the main problem with unsupervised
    learning is can we also learn from unlabeled dataï¼Ÿ
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½éå¸¸è€—æ—¶ä¸”æ˜‚è´µã€‚å› æ­¤ï¼Œæ— ç›‘ç£å­¦ä¹ çš„ä¸»è¦é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬æ˜¯å¦ä¹Ÿèƒ½ä»æœªæ ‡è®°çš„æ•°æ®ä¸­å­¦ä¹ ï¼Ÿ
- en: And this is a lot scarier because all of a sudden we're starting to optimize
    an objective which isn't the one we care about thatstream right so there a lot
    of the guarantees that we used to have we no longer haveã€‚And we can only kind
    of hope that we learn some features that are adaptable to a wide variety of downstream
    tasksã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è®©äººæ›´åŠ ææƒ§ï¼Œå› ä¸ºçªç„¶é—´æˆ‘ä»¬å¼€å§‹ä¼˜åŒ–ä¸€ä¸ªä¸æˆ‘ä»¬å…³æ³¨çš„ä¸‹æ¸¸ä»»åŠ¡æ— å…³çš„ç›®æ ‡ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»¥å‰æ‰€æ‹¥æœ‰çš„è®¸å¤šä¿è¯ç°åœ¨éƒ½ä¸å¤å­˜åœ¨ã€‚æˆ‘ä»¬åªèƒ½å¸Œæœ›èƒ½å¤Ÿå­¦ä¹ åˆ°é€‚åº”å„ç§ä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹å¾ã€‚
- en: But neverthelessï¼Œ there's a reason to be very optimistic in languageã€‚And the
    reason is that there is a huge trove of unlabeled data and it's called the internet
    and so the real question is can we leverage all this unlabeled data from the internetï¼Ÿ
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œå°½ç®¡å¦‚æ­¤ï¼Œå¯¹äºè¯­è¨€æ¥è¯´ï¼Œä»ç„¶æœ‰ç†ç”±éå¸¸ä¹è§‚ã€‚åŸå› åœ¨äºæœ‰å¤§é‡æœªæ ‡è®°çš„æ•°æ®ï¼Œè¿™è¢«ç§°ä¸ºäº’è”ç½‘ï¼Œå› æ­¤çœŸæ­£çš„é—®é¢˜æ˜¯æˆ‘ä»¬èƒ½å¦åˆ©ç”¨æ¥è‡ªäº’è”ç½‘çš„æ‰€æœ‰è¿™äº›æœªæ ‡è®°æ•°æ®ï¼Ÿ
- en: To solve language tasks where we don't really have that much dataã€‚And the hope
    is that if we kind of pretrain this model on the internetã€‚you'll see all of these
    words used in different settingsï¼Œ kind of understand the relationshipsã€‚And you'll
    be able to leverage this kind of understanding for any kind of task we developmentã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å¹¶æ²¡æœ‰å¤ªå¤šæ•°æ®çš„æƒ…å†µä¸‹è§£å†³è¯­è¨€ä»»åŠ¡ã€‚å¸Œæœ›æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬åœ¨äº’è”ç½‘ä¸Šå¯¹è¿™ä¸ªæ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½ å°†çœ‹åˆ°è¿™äº›å•è¯åœ¨ä¸åŒåœºæ™¯ä¸­çš„ä½¿ç”¨ï¼Œä»è€Œç†è§£å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚ä½ å°†èƒ½å¤Ÿåˆ©ç”¨è¿™ç§ç†è§£æ¥å¤„ç†æˆ‘ä»¬å¼€å‘çš„ä»»ä½•ä»»åŠ¡ã€‚
- en: So now that we've established why language is such a good domain to try unsupervised
    learning inã€‚let's talk about why use generative models for it and also why use
    auto aggressiveive generative modelsã€‚And I do want to stress that a lot of the
    guarantees we have with supervised learning are no longer there for unsupervised
    learning so some of these arguments will be a little bit kind of intuitive and
    so the first argument I want to present is this quote by Richard Feynman which
    is pretty widespread so what I cannot create I do not understandã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ç¡®å®šäº†ä¸ºä»€ä¹ˆè¯­è¨€æ˜¯å°è¯•æ— ç›‘ç£å­¦ä¹ çš„ä¸€ä¸ªå¾ˆå¥½çš„é¢†åŸŸã€‚è®©æˆ‘ä»¬è°ˆè°ˆä¸ºä»€ä¹ˆè¦ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œä»¥åŠä¸ºä»€ä¹ˆè¦ä½¿ç”¨è‡ªå›å½’ç”Ÿæˆæ¨¡å‹ã€‚æˆ‘æƒ³å¼ºè°ƒçš„æ˜¯ï¼Œè®¸å¤šæˆ‘ä»¬åœ¨ç›‘ç£å­¦ä¹ ä¸­æ‹¥æœ‰çš„ä¿è¯åœ¨æ— ç›‘ç£å­¦ä¹ ä¸­ä¸å†å­˜åœ¨ï¼Œå› æ­¤ä¸€äº›è®ºç‚¹å¯èƒ½ä¼šç¨æ˜¾ç›´è§‚ã€‚æˆ‘æƒ³æå‡ºçš„ç¬¬ä¸€ä¸ªè®ºç‚¹æ˜¯ç†æŸ¥å¾·Â·è´¹æ›¼çš„ä¸€å¥å¹¿ä¸ºæµä¼ çš„åè¨€ï¼šâ€œæˆ‘æ— æ³•åˆ›é€ çš„ï¼Œæˆ‘ä¸ç†è§£ã€‚â€
- en: And there's the inverse of this idea which we call analysis by synthesis and
    it's what I can createã€‚I can also understand and this has been studied by kind
    Josh Tenenbaumã€‚there's definitely some kind of biological motivation as well for
    itã€‚Umã€‚å¯¹ã€‚The the idea here is that if you're able to create a language model which
    can generate diverse samples that are coherentã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰è¿™ä¸ªæƒ³æ³•çš„åé¢ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºåˆæˆåˆ†æï¼Œè¿™æ˜¯æˆ‘å¯ä»¥åˆ›é€ çš„ã€‚æˆ‘ä¹Ÿå¯ä»¥ç†è§£ï¼Œè¿™ä¸€ç‚¹å·²ç»å¾—åˆ°äº†åƒä¹”ä»€Â·ç‰¹å«©é²å§†è¿™æ ·çš„ç ”ç©¶è€…çš„ç ”ç©¶ã€‚å®ƒèƒŒåè‚¯å®šä¹Ÿæœ‰æŸç§ç”Ÿç‰©å­¦åŠ¨æœºã€‚å—¯ã€‚å¯¹ã€‚è¿™é‡Œçš„æƒ³æ³•æ˜¯ï¼Œå¦‚æœä½ èƒ½å¤Ÿåˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”è¿è´¯æ ·æœ¬çš„è¯­è¨€æ¨¡å‹ã€‚
- en: then it must also build up representations that can help you solve language
    understandingã€‚And then the next question isï¼Œ why do we use auto regressive modelsï¼Ÿ
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œå®ƒè¿˜å¿…é¡»å»ºç«‹èµ·å¯ä»¥å¸®åŠ©ä½ è§£å†³è¯­è¨€ç†è§£çš„è¡¨å¾ã€‚æ¥ä¸‹æ¥çš„é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆè¦ä½¿ç”¨è‡ªå›å½’æ¨¡å‹ï¼Ÿ
- en: You might argue that autoregressive models are a kind of local objective right
    like you're just predicting the next wordsã€‚you could do really well with kind
    of some ngram approximation right like why would it be good at solving things
    that allow you to summarize an entire piece of thingsï¼Ÿ
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šäº‰è¾©è¯´ï¼Œè‡ªå›å½’æ¨¡å‹æ˜¯ä¸€ç§å±€éƒ¨ç›®æ ‡ï¼Œå¯¹å§ï¼Ÿä½ åªæ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚ä½ å¯ä»¥ç”¨ä¸€äº›n-gramè¿‘ä¼¼æ¥è¡¨ç°å¾—å¾ˆå¥½ï¼Œå¯¹å§ï¼Ÿé‚£ä¹ˆä¸ºä»€ä¹ˆå®ƒåœ¨è§£å†³å…è®¸ä½ æ€»ç»“æ•´ç¯‡å†…å®¹çš„äº‹æƒ…ä¸Šä¼šè¡¨ç°å¾—å¾ˆå¥½å‘¢ï¼Ÿ
- en: And so an intuitive argument here could beï¼Œ say that you wanted to do very well
    on language modeling for a mystery novelã€‚And there's this grand reveal at the
    end like ohï¼Œ like the culprit wasã€‚and then you want to predict that next token
    and to do really well at that taskã€‚you really need to have a good understanding
    of what happened in the story along with all the twists and turns and maybe even
    some of this kind of like deductive reasoning bookã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„ä¸€ä¸ªç›´è§‚è®ºç‚¹å¯èƒ½æ˜¯ï¼Œæ¯”å¦‚è¯´ä½ æƒ³åœ¨æ¨ç†å°è¯´çš„è¯­è¨€å»ºæ¨¡ä¸Šè¡¨ç°å¾—å¾ˆå¥½ã€‚æ•…äº‹çš„ç»“å°¾æœ‰ä¸€ä¸ªå¤§æ­ç¤ºï¼Œæ¯”å¦‚è¯´ï¼Œç½ªçŠ¯æ˜¯è°ã€‚è€Œä¸”ä½ æƒ³é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼Œè¦åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½ çœŸçš„éœ€è¦å¯¹æ•…äº‹ä¸­çš„æ‰€æœ‰æ›²æŠ˜å’Œè½¬æŠ˜æœ‰å¾ˆå¥½çš„ç†è§£ï¼Œç”šè‡³è¿˜è¦æœ‰ä¸€äº›åƒæ¨ç†ä¹¦é‚£æ ·çš„é€»è¾‘æ€ç»´èƒ½åŠ›ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_11.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_11.png)'
- en: So the first sign of lifeï¼Œ ohï¼Œ did have a questionï¼ŸOh yeahï¼Œ Oh yeahï¼Œ yeahã€‚So
    so the first sign of life we had at Open theI was in the task of predicting whether
    Amazon reviews were positive or negative and this was worked done in 2017ã€‚so instead
    of training a classifier in the kind of typical supervised wayã€‚what we did was
    we trained an LSTM model just to predict the next character in Amazon reviewsã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæˆ‘ä»¬åœ¨OpenAIçš„ç¬¬ä¸€æ¬¡ç”Ÿå‘½è¿¹è±¡ï¼Œå“¦ï¼Œæœ‰é—®é¢˜å—ï¼Ÿå“¦ï¼Œæ˜¯çš„ï¼Œå“¦ï¼Œæ˜¯çš„ï¼Œæ˜¯çš„ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬åœ¨OpenAIçš„ç¬¬ä¸€æ¬¡ç”Ÿå‘½è¿¹è±¡æ˜¯åœ¨é¢„æµ‹äºšé©¬é€Šè¯„è®ºæ˜¯æ­£é¢è¿˜æ˜¯è´Ÿé¢è¿™ä¸€ä»»åŠ¡ä¸Šï¼Œå·¥ä½œæ˜¯åœ¨2017å¹´å®Œæˆçš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸æ˜¯ä»¥å…¸å‹çš„ç›‘ç£æ–¹å¼è®­ç»ƒåˆ†ç±»å™¨ï¼Œè€Œæ˜¯è®­ç»ƒäº†ä¸€ä¸ªLSTMæ¨¡å‹ï¼Œä»…ç”¨äºé¢„æµ‹äºšé©¬é€Šè¯„è®ºä¸­çš„ä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚
- en: And when we trained a linear model on the features from this LSPMã€‚what we found
    surprisingly was like one of these cells or one of these neurons was firing in
    terms of predicting sentiment and positive activations for this neuron corresponded
    to positive reviews and negative activations to negative reviews and this was
    despite being not seeing any of the labels at training timeã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åœ¨è¿™ä¸ªLSPMçš„ç‰¹å¾ä¸Šè®­ç»ƒçº¿æ€§æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æƒŠè®¶åœ°å‘ç°ï¼Œåƒæ˜¯è¿™äº›ç»†èƒæˆ–ç¥ç»å…ƒåœ¨é¢„æµ‹æƒ…æ„Ÿæ—¶æ˜¯æ¿€æ´»çš„ï¼Œæ­£æ¿€æ´»ä¸æ­£é¢è¯„è®ºå¯¹åº”ï¼Œè´Ÿæ¿€æ´»ä¸è´Ÿé¢è¯„è®ºå¯¹åº”ï¼Œå°½ç®¡åœ¨è®­ç»ƒæ—¶æ²¡æœ‰çœ‹åˆ°ä»»ä½•æ ‡ç­¾ã€‚
- en: So you can even track kind of what this neuron value is across a sampleã€‚so it's
    a little bit hard to readï¼Œ but these are reviews where maybe someone saysã€‚oh I
    really like this film but I didn't like this part and you can kind of see the
    sentiment switching and as you go from positive to negativeã€‚So yeahï¼Œ just predicting
    the next character resulted inï¼Œ oh yeahã€‚yeah no noã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä½ ç”šè‡³å¯ä»¥è·Ÿè¸ªæ ·æœ¬ä¸­è¿™ä¸ªç¥ç»å…ƒçš„å€¼ã€‚é˜…è¯»èµ·æ¥æœ‰ç‚¹å›°éš¾ï¼Œä½†è¿™äº›æ˜¯è¯„è®ºï¼Œå¯èƒ½æœ‰äººä¼šè¯´ï¼Œå“¦ï¼Œæˆ‘çœŸçš„å¾ˆå–œæ¬¢è¿™éƒ¨ç”µå½±ï¼Œä½†æˆ‘ä¸å–œæ¬¢è¿™ä¸ªéƒ¨åˆ†ï¼Œä½ å¯ä»¥çœ‹åˆ°æƒ…æ„Ÿçš„è½¬å˜ï¼Œä»ç§¯æè½¬ä¸ºæ¶ˆæã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œä»…ä»…é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦å°±å¯¼è‡´äº†ï¼Œå“¦ï¼Œæ˜¯çš„ï¼Œä¸ï¼Œä¸ã€‚
- en: this was just a P in the hidden state so you train a linear class on top of
    that and one neuron is firing with yeah just outsized predictive power great so
    next QPT1 was one of the first demonstrations that this kind of approach could
    work broadly for text so GP1 was trained on the internet not on Amazon reviews
    anymore and it was fine too on a bunch of different downstreamã€‚
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯éšè—çŠ¶æ€ä¸­çš„ä¸€ä¸ªPï¼Œå› æ­¤ä½ åœ¨å…¶ä¸Šè®­ç»ƒä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œå…¶ä¸­ä¸€ä¸ªç¥ç»å…ƒçš„æ¿€æ´»æ˜¯å·¨å¤§çš„é¢„æµ‹èƒ½åŠ›ï¼Œå¤ªæ£’äº†ï¼Œæ‰€ä»¥ä¸‹ä¸€ä¸ªQPT1æ˜¯é¦–æ¬¡å±•ç¤ºè¿™ç§æ–¹æ³•å¯ä»¥å¹¿æ³›ç”¨äºæ–‡æœ¬çš„æ¡ˆä¾‹ï¼Œå› æ­¤GP1æ˜¯åœ¨äº’è”ç½‘ä¸Šè®­ç»ƒçš„ï¼Œè€Œä¸æ˜¯åœ¨äºšé©¬é€Šè¯„è®ºä¸Šï¼Œå®ƒåœ¨å¤šä¸ªä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šä¹Ÿè¡¨ç°å¾—å¾ˆå¥½ã€‚
- en: Rightï¼Œ and one thing to stress here is kind of to your point that the fine training
    was veryã€‚I guess minimally kind ofï¼Œ you're not kind of bashing the architecture
    apart and kind of repurposing a new module and it's just a new head that classifies
    for your taskã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ï¼Œæ˜¯çš„ï¼Œè¿™é‡Œè¦å¼ºè°ƒçš„ä¸€ç‚¹æ˜¯ï¼Œæ­£å¦‚ä½ æ‰€è¯´ï¼Œå¾®è°ƒæ˜¯éå¸¸çš„ã€‚æˆ‘æƒ³è¯´æ˜¯æœ€å°çš„ï¼Œä½ å¹¶æ²¡æœ‰æ‹†è§£æ¶æ„å¹¶é‡æ–°å®šåˆ¶ä¸€ä¸ªæ–°æ¨¡å—ï¼Œè€Œåªæ˜¯å¢åŠ äº†ä¸€ä¸ªæ–°çš„å¤´éƒ¨æ¥ä¸ºä½ çš„ä»»åŠ¡è¿›è¡Œåˆ†ç±»ã€‚
- en: And this showed that you can use this approach not just for center analysisã€‚But
    also for like entailmentsï¼Œmatic similarity and getting so does on a lot of these
    benchmarks downstreamã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_13.png)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡¨æ˜ä½ å¯ä»¥ä½¿ç”¨è¿™ç§æ–¹æ³•ä¸ä»…ç”¨äºä¸­å¿ƒåˆ†æï¼Œè¿˜å¯ä»¥ç”¨äºè•´å«ã€ç›¸ä¼¼æ€§ç­‰ï¼Œå¹¶ä¸”åœ¨å¾ˆå¤šä¸‹æ¸¸åŸºå‡†ä¸Šè·å¾—è‰¯å¥½æ•ˆæœã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_13.png)
- en: So I've already presented QptT2 from the point of view of a very powerful language
    modelã€‚and now I think it's worth visiting from the viewpoint of principal supervisorã€‚So
    like GT1ã€‚GT2 was trained on a large chunk of the internetã€‚And it's only trained
    to predict the next token or word from previous wordsã€‚But the key insight of GT2
    is that many downstream tasks can be expressed naturally as a language model impactã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å·²ç»ä»ä¸€ä¸ªéå¸¸å¼ºå¤§çš„è¯­è¨€æ¨¡å‹çš„è§’åº¦å±•ç¤ºäº†QptT2ã€‚ç°åœ¨æˆ‘è§‰å¾—ä»ä¸»è¦ç›‘ç£è€…çš„è§’åº¦æ¥çœ‹ä¹Ÿæ˜¯å€¼å¾—æ¢è®¨çš„ã€‚å°±åƒGT1ä¸€æ ·ï¼ŒGT2æ˜¯åŸºäºäº’è”ç½‘çš„å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒçš„ã€‚å®ƒåªè®­ç»ƒé¢„æµ‹å…ˆå‰å•è¯çš„ä¸‹ä¸€ä¸ªæ ‡è®°æˆ–å•è¯ã€‚ä½†GT2çš„å…³é”®æ´å¯Ÿæ˜¯ï¼Œè®¸å¤šä¸‹æ¸¸ä»»åŠ¡å¯ä»¥è‡ªç„¶åœ°è¡¨è¾¾ä¸ºè¯­è¨€æ¨¡å‹çš„å½±å“ã€‚
- en: And yeahï¼Œ so GT2 explores how well we can perform on downstreamcast simply by
    using this method without any fine tuningã€‚Right so let me start with a couple
    of examples so let's say you want to solve some reading comprehension benchmark
    and this is usually set up as a prompt which is some passage you have to read
    and then a bunch of questions which you have to answerã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ‰€ä»¥GT2æ¢ç´¢äº†æˆ‘ä»¬åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ä»…é€šè¿‡è¿™ç§æ–¹æ³•è€Œä¸è¿›è¡Œä»»ä½•å¾®è°ƒçš„è¡¨ç°ã€‚å¥½å§ï¼Œè®©æˆ‘å…ˆå¼€å§‹å‡ ä¸ªä¾‹å­ï¼Œå‡è®¾ä½ æƒ³è§£å†³ä¸€äº›é˜…è¯»ç†è§£åŸºå‡†ï¼Œè¿™é€šå¸¸æ˜¯è®¾ç½®ä¸ºä¸€ä¸ªæç¤ºï¼Œå…¶ä¸­åŒ…å«ä¸€äº›ä½ å¿…é¡»é˜…è¯»çš„æ®µè½ï¼Œä»¥åŠä¸€å †ä½ å¿…é¡»å›ç­”çš„é—®é¢˜ã€‚
- en: So you can literally just stick the entire prompting contextï¼Œ you put a question
    colonã€‚you write out the questionï¼Œ answer colon and then have the model complete
    from there and this side kind of gives you zero shot reading comprehensionã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_15.png)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¯ä»¥å­—é¢ä¸Šå°†æ•´ä¸ªæç¤ºä¸Šä¸‹æ–‡ç²˜è´´åœ¨ä¸€èµ·ï¼Œä½ å†™ä¸‹é—®é¢˜ï¼šï¼Œç„¶åå†™å‡ºé—®é¢˜ï¼Œå›ç­”ï¼šï¼Œç„¶åè®©æ¨¡å‹ä»é‚£é‡Œå®Œæˆï¼Œè¿™æ ·å°±å¯ä»¥å®ç°é›¶æ ·æœ¬é˜…è¯»ç†è§£ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_15.png)
- en: We can also use it for other tasks like summarizationï¼Œ for instanceã€‚here's like
    of course the beginning of a CNN article about kind of some archaeological finding
    and you can just put TLDR after you see this passage and the model hopefully if
    it's good enough will produce good summariesã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨å®ƒæ¥åšå…¶ä»–ä»»åŠ¡ï¼Œæ¯”å¦‚æ‘˜è¦ã€‚ä¾‹å¦‚ï¼Œè¿™é‡Œæœ‰ä¸€ç¯‡å…³äºä¸€äº›è€ƒå¤å‘ç°çš„CNNæ–‡ç« çš„å¼€å¤´ï¼Œä½ åªéœ€åœ¨çœ‹åˆ°è¿™ä¸ªæ®µè½ååŠ ä¸ŠTLDRï¼Œæ¨¡å‹å¦‚æœè¶³å¤Ÿå¥½ï¼Œå°±ä¼šäº§ç”Ÿå¥½çš„æ‘˜è¦ã€‚
- en: And the final example I want to show is that you can do zero shot translation
    as wellã€‚So the way you would do this is if you wanted to convertï¼Œ let's say a
    French sentence into Englishã€‚you could set up a prompt like the sentence insert
    the French sentence translated from French to English means and then the model
    will complete and they can sometimes do as well and one kind of critical thing
    to note here is that here's the chart of performance as you increase the number
    of parameters andã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 'æˆ‘æƒ³å±•ç¤ºçš„æœ€åä¸€ä¸ªä¾‹å­æ˜¯ï¼Œä½ ä¹Ÿå¯ä»¥è¿›è¡Œé›¶æ ·æœ¬ç¿»è¯‘ã€‚æ‰€ä»¥ä½ å¯ä»¥è¿™æ ·åšï¼Œå¦‚æœä½ æƒ³å°†ä¸€å¥æ³•è¯­å¥å­è½¬æ¢ä¸ºè‹±è¯­ï¼Œä½ å¯ä»¥è®¾ç½®ä¸€ä¸ªæç¤ºï¼Œæ¯”å¦‚è¿™å¥å¥å­â€œä»æ³•è¯­ç¿»è¯‘æˆè‹±è¯­æ„å‘³ç€â€ï¼Œç„¶åæ¨¡å‹ä¼šå®Œæˆï¼Œæœ‰æ—¶å®ƒèƒ½åšåˆ°ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„ä¸€ä¸ªå…³é”®ç‚¹æ˜¯ï¼Œéšç€å‚æ•°æ•°é‡çš„å¢åŠ ï¼Œè¿™é‡Œæ˜¯æ€§èƒ½çš„å›¾è¡¨ã€‚ '
- en: å—¯ã€‚In all of these modelsï¼Œ they were trained on the same data setã€‚so the only
    kind of compounding variable is scaleã€‚And you can see that as we scale up the
    models these kind of zero shot capabilities emerge or and kind of smoothly get
    better so the role of scale is important here and yeah and I think these are starting
    to approach some I guess they're not great benchmarks but at least respectable
    benchmarksã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ã€‚åœ¨æ‰€æœ‰è¿™äº›æ¨¡å‹ä¸­ï¼Œå®ƒä»¬éƒ½æ˜¯åœ¨åŒä¸€ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒçš„ã€‚æ‰€ä»¥å”¯ä¸€çš„å¤åˆå˜é‡æ˜¯è§„æ¨¡ã€‚éšç€æˆ‘ä»¬æ‰©å¤§æ¨¡å‹ï¼Œè¿™ç§é›¶æ ·æœ¬èƒ½åŠ›ä¼šå‡ºç°ï¼Œå¹¶ä¸”ä¼šé€æ¸å˜å¾—æ›´å¥½ï¼Œå› æ­¤è§„æ¨¡åœ¨è¿™é‡Œæ˜¯é‡è¦çš„ã€‚æˆ‘è®¤ä¸ºè¿™äº›æ¨¡å‹å¼€å§‹æ¥è¿‘ä¸€äº›ï¼Œæˆ‘æƒ³å®ƒä»¬ä¸æ˜¯å¾ˆå¥½çš„åŸºå‡†ï¼Œä½†è‡³å°‘æ˜¯å€¼å¾—å°Šé‡çš„åŸºå‡†ã€‚
- en: Yeahï¼Œ yeahï¼Œ yeahã€‚ exactlyã€‚ It's not gonna be great in a lot of casesã€‚And to
    be honestã€‚like the blue metric used for translation is actually often pretty you
    very muchã€‚it's not a great metricã€‚What it does is it takes a reference solution
    And basicallyã€‚it does some kind of like Ngram comparisonã€‚ So it is a big problem
    to have good translation metrics in an LPã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ˜¯çš„ï¼Œæ²¡é”™ã€‚åœ¨å¾ˆå¤šæƒ…å†µä¸‹å®ƒå¹¶ä¸ä¼šå¾ˆå¥½ã€‚è€å®è¯´ï¼Œç”¨äºç¿»è¯‘çš„è“è‰²æŒ‡æ ‡å®é™…ä¸Šç»å¸¸ç›¸å½“ä¸é è°±ã€‚è¿™ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æŒ‡æ ‡ã€‚å®ƒæ‰€åšçš„æ˜¯å–ä¸€ä¸ªå‚è€ƒè§£å†³æ–¹æ¡ˆï¼Œå¹¶åŸºæœ¬ä¸Šè¿›è¡ŒæŸç§Ngramæ¯”è¾ƒã€‚å› æ­¤ï¼Œåœ¨LPä¸­æœ‰è‰¯å¥½çš„ç¿»è¯‘æŒ‡æ ‡æ˜¯ä¸ªå¤§é—®é¢˜ã€‚
- en: And yeahï¼Œ I think when I talk about codeï¼Œ I'll talk a little more completelyã€‚ğŸ˜Šï¼ŒRightã€‚so
    let's finally talk about how GP3 fit into this pictureã€‚So the primary insight
    of GP3 is that the training process itself can be interpreted in the context of
    meta alertã€‚which is kind of like learning over a distributionã€‚And during trainingã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºå½“æˆ‘è°ˆè®ºä»£ç æ—¶ï¼Œæˆ‘ä¼šæ›´å…¨é¢åœ°è®¨è®ºã€‚ğŸ˜Šï¼Œå¥½å§ã€‚è®©æˆ‘ä»¬æœ€åè°ˆè°ˆGP3åœ¨è¿™ä¸ªå›¾æ™¯ä¸­çš„é€‚åº”æƒ…å†µã€‚GP3çš„ä¸»è¦æ´å¯Ÿæ˜¯è®­ç»ƒè¿‡ç¨‹æœ¬èº«å¯ä»¥åœ¨å…ƒè­¦æŠ¥çš„èƒŒæ™¯ä¸‹è¿›è¡Œè§£é‡Šï¼Œè¿™å°±åƒæ˜¯åœ¨ä¸€ä¸ªåˆ†å¸ƒä¸Šè¿›è¡Œå­¦ä¹ ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚
- en: what the model' is doing is it's developing certain kind of capabilitiesã€‚it's
    picking up some set of like skills in terms of modeling certain passagesã€‚And during
    inference time what it's doingï¼Œ it's kind of quickly picking up on what a task
    is based on what the prompt is so far and adapting to that task to predict the
    next toã€‚So you can kind of view there's this outward loop of all the SGD steps
    you're doing during training and this inward loop of kind of picking up on what
    the task is and then modeling the next toingã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ‰€åšçš„æ˜¯å‘å±•æŸç§èƒ½åŠ›ã€‚å®ƒæ­£åœ¨æŒæ¡æŸç§æŠ€èƒ½ï¼Œä»¥å»ºæ¨¡ç‰¹å®šæ®µè½ã€‚åœ¨æ¨ç†æ—¶ï¼Œå®ƒå¿«é€Ÿè¯†åˆ«ä»»åŠ¡æ˜¯ä»€ä¹ˆï¼ŒåŸºäºåˆ°ç›®å‰ä¸ºæ­¢çš„æç¤ºï¼Œå¹¶é€‚åº”è¯¥ä»»åŠ¡ä»¥é¢„æµ‹ä¸‹ä¸€ä¸ªã€‚æ‰€ä»¥ä½ å¯ä»¥å°†å…¶è§†ä¸ºè®­ç»ƒæœŸé—´ä½ æ‰€åšçš„æ‰€æœ‰SGDæ­¥éª¤çš„å¤–å¾ªç¯ï¼Œä»¥åŠè¯†åˆ«ä»»åŠ¡å¹¶å»ºæ¨¡ä¸‹ä¸€ä¸ªçš„å†…å¾ªç¯ã€‚
- en: So you can imagine a lot of tasks being framed in this wayã€‚for instance on the
    left you can have addition kind of you have a lot of examples of the context and
    hopefully that would help you with a new edition problem where you can try to
    unscram a word for instance and I'll explore results on these two kind of benchmarks
    in the next slidesã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä½ å¯ä»¥æƒ³è±¡å¾ˆå¤šä»»åŠ¡å¯ä»¥ä»¥è¿™ç§æ–¹å¼è¿›è¡Œæ„å»ºã€‚ä¾‹å¦‚åœ¨å·¦ä¾§ï¼Œä½ å¯ä»¥è¿›è¡ŒåŠ æ³•ï¼Œä½ æœ‰å¾ˆå¤šä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œå¸Œæœ›è¿™èƒ½å¸®åŠ©ä½ è§£å†³æ–°çš„åŠ æ³•é—®é¢˜ï¼Œæˆ–è€…ä½ å¯ä»¥å°è¯•è§£å¼€ä¸€ä¸ªå•è¯ï¼Œä¾‹å¦‚ï¼Œæˆ‘å°†åœ¨æ¥ä¸‹æ¥çš„å¹»ç¯ç‰‡ä¸­æ¢è®¨è¿™ä¸¤ç§åŸºå‡†çš„ç»“æœã€‚
- en: So this setting we call fu shot arithmetic and just to explain what's going
    onã€‚you're taking the entire context slide of your transformer and you're putting
    in as many examples as we'll fitã€‚And then finally you put in the example that
    you would like to solve so here like these examples could beã€‚These kind of first
    three edition problems and then you have 31 plus 41 equals and you ask the model
    to completeã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ä¸ªè®¾ç½®æˆ‘ä»¬ç§°ä¹‹ä¸ºfu shotç®—æœ¯ï¼Œåªæ˜¯ä¸ºäº†è§£é‡Šå‘ç”Ÿäº†ä»€ä¹ˆã€‚ä½ å°†æ•´ä¸ªå˜æ¢å™¨çš„ä¸Šä¸‹æ–‡æ»‘å—æ”¾å…¥å°½å¯èƒ½å¤šçš„ç¤ºä¾‹ã€‚æœ€åï¼Œä½ æ”¾å…¥ä½ æƒ³è¦è§£å†³çš„ç¤ºä¾‹ï¼Œæ‰€ä»¥è¿™é‡Œåƒè¿™äº›ç¤ºä¾‹å¯ä»¥æ˜¯ã€‚è¿™äº›å‰é¢çš„ä¸‰é“é¢˜ç›®ï¼Œç„¶åä½ æœ‰31åŠ 41ç­‰äºï¼Œå¹¶è¯·æ¨¡å‹å®Œæˆã€‚
- en: So you notice that as the language model gets biggerï¼Œ it's better able to recognize
    this taskã€‚And you can see that kind of performance on additionsã€‚subtracting even
    some kind of multiplication tests increases sharply as you go towards 20 billionion
    parameters and there just seem to be kind of some step function change right hereã€‚And
    looking at word unscrambling this is also true so we have parameters again on
    the X axis we have accuracyn each should these as a different kind of unstble
    task so this blue line is you kind of do a cyclic shift of the letters and you
    want it to uncycle and there's a lot of other transforms you can do like randomly
    inserting words for instanceã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ ä¼šæ³¨æ„åˆ°ï¼Œéšç€è¯­è¨€æ¨¡å‹çš„å¢å¤§ï¼Œå®ƒæ›´èƒ½è¯†åˆ«è¿™ä¸ªä»»åŠ¡ã€‚ä½ å¯ä»¥çœ‹åˆ°åœ¨åŠ æ³•ã€å‡æ³•ç”šè‡³æŸç§ä¹˜æ³•æµ‹è¯•ä¸Šçš„è¡¨ç°ï¼Œéšç€å‚æ•°æ¥è¿‘200äº¿è€Œæ€¥å‰§å¢åŠ ï¼Œè¿™é‡Œä¼¼ä¹æœ‰æŸç§é˜¶è·ƒå‡½æ•°å˜åŒ–ã€‚è§‚å¯Ÿå•è¯è§£ç ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå› æ­¤æˆ‘ä»¬åœ¨Xè½´ä¸Šæœ‰å‚æ•°ï¼Œæ¯ç§ä¸åŒçš„ä¸ç¨³å®šä»»åŠ¡éƒ½æœ‰å‡†ç¡®æ€§ï¼Œè¿™æ¡è“çº¿æ˜¯ä½ è¿›è¡Œå­—æ¯çš„å¾ªç¯ç§»ä½ï¼Œä½ å¸Œæœ›å®ƒè§£å›å»ï¼Œè¿˜æœ‰å¾ˆå¤šå…¶ä»–å˜æ¢ä½ å¯ä»¥è¿›è¡Œï¼Œä¾‹å¦‚éšæœºæ’å…¥å•è¯ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_17.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_17.png)'
- en: Yeahã€‚So the final point here is that this is a pretty general phenomenon we
    didn't just test it on these two aforementioned tasks we tried an array of I think
    40 plus tasks and here you can see how the zero shot one shot and few shot performance
    increases as we scale the models so of course they're smoothly increasing but
    one thing to be aware of is that the gap between zero shot and fu shot is also
    improving as a function of scaleã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ã€‚æ‰€ä»¥è¿™é‡Œçš„æœ€åä¸€ç‚¹æ˜¯è¿™æ˜¯ä¸€ä¸ªç›¸å½“æ™®éçš„ç°è±¡ï¼Œæˆ‘ä»¬ä¸ä»…ä»…åœ¨è¿™ä¸¤ä¸ªå‰é¢æåˆ°çš„ä»»åŠ¡ä¸Šæµ‹è¯•è¿‡ï¼Œè€Œæ˜¯å°è¯•äº†40å¤šä¸ªä»»åŠ¡ï¼Œè¿™é‡Œä½ å¯ä»¥çœ‹åˆ°é›¶-shotã€one-shotå’Œfew-shotæ€§èƒ½éšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ è€Œæé«˜ï¼Œå› æ­¤å®ƒä»¬æ˜¯å¹³æ»‘å¢åŠ çš„ï¼Œä½†è¦æ³¨æ„çš„æ˜¯ï¼Œé›¶-shotå’Œfu
    shotä¹‹é—´çš„å·®è·ä¹Ÿåœ¨éšç€è§„æ¨¡çš„å˜åŒ–è€Œæ”¹å–„ã€‚
- en: é˜¿ä»€ã€‚So we've just seen that we can pre train the transfer oh goodã€‚One isã€‚Themelves
    that were used two is the number of parameters and then three my understanding
    is also the quantity of the tested I was curious sort of between those three which
    ones you've shown a lot ofã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: é˜¿ä»€ã€‚æ‰€ä»¥æˆ‘ä»¬åˆšåˆšçœ‹åˆ°æˆ‘ä»¬å¯ä»¥é¢„è®­ç»ƒä¼ è¾“ï¼Œå“¦ï¼Œå¥½ã€‚ä¸€æ˜¯ã€‚è¢«ä½¿ç”¨çš„ä¸»é¢˜ï¼ŒäºŒæ˜¯å‚æ•°çš„æ•°é‡ï¼Œç„¶åä¸‰ï¼Œæˆ‘çš„ç†è§£ä¹Ÿæ˜¯æµ‹è¯•æ•°é‡ï¼Œæˆ‘å¾ˆå¥½å¥‡åœ¨è¿™ä¸‰è€…ä¹‹é—´ï¼Œä½ å±•ç¤ºäº†å¾ˆå¤šçš„ã€‚
- en: A number of parameters definitely helps I was curious though if you have a sense
    so the degree to which also the training tasks and the sophistication of the tasks
    as well as the quantity of the adjustedã€‚Yeahï¼Œ yeah so I guess I can dive maybe
    it's something to say for a group but yeah yeah let's dig into that after yeah
    I guess GPPD2 and three aren't different GPD1 just has an extra classification
    head for certain tasks yeahã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å‚æ•°çš„æ•°é‡ç¡®å®æœ‰å¸®åŠ©ï¼Œä½†æˆ‘å¾ˆå¥½å¥‡ä½ æ˜¯å¦æœ‰ä¸€ç§æ„Ÿè§‰ï¼Œå³è®­ç»ƒä»»åŠ¡çš„å¤æ‚æ€§ä»¥åŠè°ƒæ•´çš„æ•°é‡å¯¹ç»“æœçš„å½±å“ã€‚æ˜¯çš„ï¼Œæˆ‘æƒ³æˆ‘å¯ä»¥æ·±å…¥æ¢è®¨ï¼Œä¹Ÿè®¸è¿™å¯¹ä¸€ä¸ªå°ç»„æ¥è¯´æ˜¯å€¼å¾—è®¨è®ºçš„ï¼Œä½†æˆ‘ä»¬å¯ä»¥åœ¨ä¹‹åæ·±å…¥ç ”ç©¶ã€‚æˆ‘çŒœGPPD2å’Œ3ä¸GPD1æ²¡æœ‰ä¸åŒï¼ŒGPD1åªæ˜¯ä¸ºæŸäº›ä»»åŠ¡å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„åˆ†ç±»å¤´ã€‚
- en: ğŸ˜Šï¼ŒGreatï¼Œ yeahï¼Œ good questionsã€‚So yeahï¼Œ we've just seen that we can use a transformer
    in this kind of pretrain and binding setup where we have some kind of a lot of
    unlabeled data in the pre training settingã€‚and we have just a little bit of data
    in binding settingã€‚ğŸ˜Šã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œå¾ˆå¥½ï¼Œæ˜¯çš„ï¼Œå¥½çš„é—®é¢˜ã€‚æ‰€ä»¥æˆ‘ä»¬åˆšåˆšçœ‹åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™ç§é¢„è®­ç»ƒå’Œç»‘å®šçš„è®¾ç½®ä¸­ä½¿ç”¨å˜æ¢å™¨ï¼Œåœ¨é¢„è®­ç»ƒç¯å¢ƒä¸­æœ‰å¤§é‡çš„æœªæ ‡è®°æ•°æ®ï¼Œè€Œåœ¨ç»‘å®šè®¾ç½®ä¸­åªæœ‰å°‘é‡æ•°æ®ã€‚ğŸ˜Šã€‚
- en: And we can solve a lot of language tasks in this wayã€‚and I would say this has
    become the dominant paradigm in language over the last couple of yearsã€‚so there's
    follow up objectives like BERT and T5 which have done extremely good at pushing
    the sodaã€‚But there's nothing really that says that these transformative models
    have to be applied to languageã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä»¥è¿™ç§æ–¹å¼è§£å†³å¾ˆå¤šè¯­è¨€ä»»åŠ¡ã€‚æˆ‘ä¼šè¯´ï¼Œåœ¨è¿‡å»å‡ å¹´ä¸­ï¼Œè¿™å·²ç»æˆä¸ºè¯­è¨€é¢†åŸŸçš„ä¸»å¯¼èŒƒå¼ã€‚å› æ­¤æœ‰åç»­ç›®æ ‡ï¼Œå¦‚BERTå’ŒT5ï¼Œå®ƒä»¬åœ¨æ¨åŠ¨æ•ˆæœä¸Šè¡¨ç°æå…¶ä¼˜ç§€ã€‚ä½†æ²¡æœ‰ä»€ä¹ˆçœŸæ­£è¯´æ˜è¿™äº›å˜æ¢æ¨¡å‹å¿…é¡»åº”ç”¨äºè¯­è¨€ã€‚
- en: The transformer is a sequence model and as such it can just ingest any sequence
    of bytes and model them and when you think about this like all of the data that
    we consume like videos or audio they're represented on our computers as sequences
    of bitetes right and so we might thinkã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å˜æ¢å™¨æ˜¯ä¸€ç§åºåˆ—æ¨¡å‹ï¼Œå› æ­¤å®ƒå¯ä»¥å¤„ç†ä»»ä½•å­—èŠ‚åºåˆ—ã€‚å½“ä½ æƒ³åˆ°è¿™ä¸€ç‚¹æ—¶ï¼Œæˆ‘ä»¬æ¶ˆè€—çš„æ‰€æœ‰æ•°æ®ï¼Œå¦‚è§†é¢‘æˆ–éŸ³é¢‘ï¼Œåœ¨è®¡ç®—æœºä¸Šéƒ½è¡¨ç¤ºä¸ºæ¯”ç‰¹åºåˆ—ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è®¤ä¸ºã€‚
- en: oh could this approach be used to just model whatever modality we wantï¼ŸAnd I
    think this kind ofã€‚Paraigm is veryã€‚At least interesting when when we don't really
    have good inductive biases like we don't we don't do itã€‚But one question to ask
    is does it even work when you do have really strong adaptductive biases so I'm
    going to present some work that suggests that the answer is yesã€‚it still works
    fairly well in this caseï¼Œ in the domain of images where convolutions are already
    so popular and proven outã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦ï¼Œè¿™ç§æ–¹æ³•èƒ½å¦ç”¨äºå»ºæ¨¡æˆ‘ä»¬æƒ³è¦çš„ä»»ä½•æ¨¡æ€ï¼Ÿæˆ‘è®¤ä¸ºè¿™ç§èŒƒå¼éå¸¸æœ‰è¶£ï¼Œå°¤å…¶æ˜¯å½“æˆ‘ä»¬æ²¡æœ‰å¥½çš„å½’çº³åå·®æ—¶ã€‚ä½†æ˜¯ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå½“ä½ ç¡®å®æœ‰å¼ºå¤§çš„é€‚åº”æ€§åå·®æ—¶ï¼Œå®ƒæ˜¯å¦æœ‰æ•ˆï¼Ÿæˆ‘å°†å±•ç¤ºä¸€äº›å·¥ä½œï¼Œè¡¨æ˜ç­”æ¡ˆæ˜¯è‚¯å®šçš„ã€‚åœ¨å›¾åƒé¢†åŸŸï¼Œå®ƒä»ç„¶æœ‰æ•ˆï¼Œå·ç§¯å·²ç»éå¸¸æµè¡Œå¹¶å¾—åˆ°éªŒè¯ã€‚
- en: And I'm going to show a second result very briefly hereï¼Œ which is Doliã€‚which
    shows that it's strong enough to even ingest two different modalities be able
    to join the modelã€‚Itã€‚So the first question isï¼Œ how would you apply GPT to imagesï¼Ÿ
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ç®€è¦å±•ç¤ºç¬¬äºŒä¸ªç»“æœï¼Œå³Doliï¼Œæ˜¾ç¤ºå®ƒè¶³å¤Ÿå¼ºå¤§ï¼Œç”šè‡³å¯ä»¥å¤„ç†ä¸¤ç§ä¸åŒçš„æ¨¡æ€å¹¶å°†å…¶æ•´åˆè¿›æ¨¡å‹ã€‚å› æ­¤ï¼Œç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä½ å°†å¦‚ä½•å°†GPTåº”ç”¨äºå›¾åƒï¼Ÿ
- en: And there's a few things you have to doï¼Œ you have to modify this utteraggressive
    next word prediction objectiveã€‚so the natural analog is you can think of images
    as a very strange language where the words are pixels instead and instead you
    need to predict the next pixel at each pointã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ä»¶äº‹æƒ…éœ€è¦åšï¼Œä½ éœ€è¦ä¿®æ”¹è¿™ç§æå…·æ”»å‡»æ€§çš„ä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹ç›®æ ‡ã€‚å› æ­¤ï¼Œè‡ªç„¶çš„ç±»æ¯”æ˜¯ï¼Œä½ å¯ä»¥å°†å›¾åƒè§†ä¸ºä¸€ç§éå¸¸å¥‡æ€ªçš„è¯­è¨€ï¼Œå…¶ä¸­å•è¯æ˜¯åƒç´ ï¼Œè€Œä½ éœ€è¦åœ¨æ¯ä¸ªç‚¹ä¸Šé¢„æµ‹ä¸‹ä¸€ä¸ªåƒç´ ã€‚
- en: and so we can just change the objective for next word prediction next pixel
    predictionã€‚And of courseï¼Œ we want this kind of largeã€‚Yeahã€‚Oh yeahã€‚so you just
    unroll it as a sequence it's the same way it's it stored on a computer you just
    have like a sequence device yeah yeah good question so in the language study we
    pre on this large unlabeled data setã€‚On the internet and we fine tune on question
    answering or this other benchmarkã€‚And in imagesã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä»…æ›´æ”¹ç›®æ ‡ï¼Œä»¥è¿›è¡Œä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹æˆ–ä¸‹ä¸€ä¸ªåƒç´ é¢„æµ‹ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬å¸Œæœ›è¿™æ ·çš„è§„æ¨¡ã€‚æ˜¯çš„ã€‚æ‰€ä»¥ä½ åªéœ€å°†å…¶å±•å¼€ä¸ºåºåˆ—ï¼Œå®ƒä¸å­˜å‚¨åœ¨è®¡ç®—æœºä¸Šçš„æ–¹å¼ç›¸åŒï¼Œä½ åªéœ€åƒå¤„ç†åºåˆ—è®¾å¤‡ä¸€æ ·å¤„ç†ã€‚æ˜¯çš„ï¼Œå¾ˆå¥½çš„é—®é¢˜ï¼Œå› æ­¤åœ¨è¯­è¨€ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åœ¨è¿™ä¸ªå¤§å‹æœªæ ‡è®°çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œç„¶ååœ¨é—®ç­”æˆ–å…¶ä»–åŸºå‡†ä¸Šè¿›è¡Œå¾®è°ƒã€‚åœ¨å›¾åƒä¸Šã€‚
- en: one good analog of this situation is you can pretrain on imagenet without the
    labels you have a let's say a low resource low data sorry setting like SFR and
    you can try to attack SFR classification and of course in both settings you can
    do fine tuning in GPT you can do zero shot and I would say the standard eval on
    images is you do linear probes so you take features from your model the model
    is frozen you pass through SFR through the modelã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æƒ…å†µçš„ä¸€ä¸ªä¸é”™çš„ç±»æ¯”æ˜¯ï¼Œä½ å¯ä»¥åœ¨æ²¡æœ‰æ ‡ç­¾çš„æƒ…å†µä¸‹å¯¹imagenetè¿›è¡Œé¢„è®­ç»ƒã€‚å‡è®¾ä½ æœ‰ä¸€ä¸ªä½èµ„æºã€ä½æ•°æ®çš„è®¾ç½®ï¼Œæ¯”å¦‚SFRï¼Œä½ å¯ä»¥å°è¯•æ”»å‡»SFRåˆ†ç±»ã€‚å½“ç„¶ï¼Œåœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥è¿›è¡Œå¾®è°ƒã€‚åœ¨GPTä¸­ï¼Œä½ å¯ä»¥åšåˆ°é›¶æ ·æœ¬è¯„ä¼°ï¼Œè€Œæˆ‘ä¼šè¯´æ ‡å‡†çš„å›¾åƒè¯„ä¼°æ˜¯è¿›è¡Œçº¿æ€§æ¢æµ‹ï¼Œæ‰€ä»¥ä½ ä»ä½ çš„æ¨¡å‹ä¸­æå–ç‰¹å¾ï¼Œæ¨¡å‹æ˜¯å†»ç»“çš„ï¼Œä½ æŠŠSFRä¼ é€’é€šè¿‡æ¨¡å‹ã€‚
- en: get some features and you see how predictive these features are of the CF classesã€‚Is
    it kind of pixel thereï¼Œ which basically you ask model to predict the next pixel
    given theã€‚Yeah yeah so pixelix CNN is an instantation of an autoive image model
    so what we're asking here is can we actually take the same transformer architecture
    that we use in language don't make any modifications at all and just throw so
    there's no kind of 2D prior on thisã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å¾—åˆ°ä¸€äº›ç‰¹å¾åï¼Œä½ å¯ä»¥çœ‹åˆ°è¿™äº›ç‰¹å¾å¯¹CFç±»åˆ«çš„é¢„æµ‹èƒ½åŠ›ã€‚åŸºæœ¬ä¸Šï¼Œè¿™æ˜¯åœ¨é—®æ¨¡å‹ç»™å®šå‰ä¸€ä¸ªåƒç´ æ—¶ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªåƒç´ ã€‚æ˜¯çš„ï¼Œæ‰€ä»¥pixelix CNNæ˜¯è‡ªç¼–ç å›¾åƒæ¨¡å‹çš„ä¸€ç§å®ç°ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œé—®çš„æ˜¯ï¼Œæ˜¯å¦å¯ä»¥ä½¿ç”¨æˆ‘ä»¬åœ¨è¯­è¨€ä¸­ä½¿ç”¨çš„ç›¸åŒå˜å‹å™¨æ¶æ„ï¼Œè€Œä¸åšä»»ä½•ä¿®æ”¹ï¼Œå› æ­¤æ²¡æœ‰ä»»ä½•2Då…ˆéªŒã€‚
- en: So yeah I'll call this model that we train image sheet or IGP for sure and here
    you can see actually what some completions from the model look like so on the
    left column what I'm feeding in is the pixels of the first half of the image and
    the next floor columns what you're seeing is different model generated completions
    and the right column here is the original reference imageã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œæˆ‘ä¼šç§°æˆ‘ä»¬è®­ç»ƒçš„è¿™ä¸ªæ¨¡å‹ä¸ºå›¾åƒè¡¨æ ¼æˆ–IGPã€‚åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥çœ‹åˆ°æ¨¡å‹ç”Ÿæˆçš„ä¸€äº›ç»“æœã€‚å·¦åˆ—æ˜¯æˆ‘è¾“å…¥çš„å›¾åƒå‰åŠéƒ¨åˆ†çš„åƒç´ ï¼Œæ¥ä¸‹æ¥çš„å››åˆ—æ˜¯ä¸åŒæ¨¡å‹ç”Ÿæˆçš„ç»“æœï¼Œè€Œå³åˆ—æ˜¯åŸå§‹å‚è€ƒå›¾åƒã€‚
- en: And you can actually see that the model is kind of doing some interesting things
    right if you look at the last two rowsã€‚it's not coming up with tenisemmaticically
    the same completion every single timeã€‚it's like putting these birds in different
    settingsï¼Œ sometimes adding reflectionsã€‚is putting this lighthouse in grassy areas
    and like watery areasï¼Œ for instanceã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å®é™…ä¸Šå¯ä»¥çœ‹åˆ°è¿™ä¸ªæ¨¡å‹åœ¨æœ€åä¸¤è¡Œåšäº†ä¸€äº›æœ‰è¶£çš„äº‹æƒ…ã€‚å¦‚æœä½ è§‚å¯Ÿï¼Œæ¨¡å‹å¹¶ä¸æ˜¯æ¯æ¬¡éƒ½ç»™å‡ºå®Œå…¨ç›¸åŒçš„ç»“æœï¼Œè€Œæ˜¯å°†è¿™äº›é¸Ÿæ”¾åœ¨ä¸åŒçš„ç¯å¢ƒä¸­ï¼Œæœ‰æ—¶è¿˜ä¼šæ·»åŠ åå°„ã€‚ä¾‹å¦‚ï¼Œå®ƒæŠŠè¿™ä¸ªç¯å¡”æ”¾åœ¨è‰åœ°åŒºå’Œæ°´åŸŸä¸­ã€‚
- en: So if you buy into this philosophy of analysis by synthesisã€‚we definitely have
    some hint of this synthesis partã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_19.png)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œå¦‚æœä½ ç›¸ä¿¡é€šè¿‡åˆæˆè¿›è¡Œåˆ†æçš„è¿™ç§å“²å­¦ï¼Œæˆ‘ä»¬è‚¯å®šåœ¨åˆæˆéƒ¨åˆ†æœ‰ä¸€äº›çº¿ç´¢ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_19.png)
- en: So I don't have time to go through all of the results with youã€‚but I just want
    to say that it is fairly successful in this SaFar setting where you don't have
    much label data if you train a linear model on top of the featuresã€‚you get better
    results than if you do the same approach with a renet trained on Inet with so
    that's like the typical approach in the field you train some re on Inet you get
    the features oh yeah oh yeah and if you compare to yeah this approach a generative
    model on Inet without the labelsã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ²¡æœ‰æ—¶é—´é€ä¸€å’Œä½ åˆ†ææ‰€æœ‰ç»“æœï¼Œä½†æˆ‘æƒ³è¯´ï¼Œåœ¨è¿™ä¸ªæ²¡æœ‰å¤ªå¤šæ ‡ç­¾æ•°æ®çš„SaFarè®¾ç½®ä¸­ï¼Œå¦‚æœä½ åœ¨ç‰¹å¾ä¸Šè®­ç»ƒä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼Œä½ ä¼šè·å¾—æ¯”ç”¨åœ¨Inetä¸Šè®­ç»ƒçš„renetç›¸åŒæ–¹æ³•æ›´å¥½çš„ç»“æœã€‚è¿™å°±æ˜¯è¯¥é¢†åŸŸçš„å…¸å‹æ–¹æ³•ï¼Œä½ åœ¨Inetä¸Šè®­ç»ƒæŸäº›æ¨¡å‹ï¼Œç„¶åæå–ç‰¹å¾ï¼Œå“¦ï¼Œæ˜¯çš„ï¼Œå¦‚æœä½ ä¸åœ¨Inetä¸Šæ²¡æœ‰æ ‡ç­¾çš„ç”Ÿæˆæ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚
- en: take the features it's actually better predictive yeah is exactly yeah yeah
    yeah yeah itã€‚So this and note so you can modify QP to have like 2D bias like you
    can do 2D position your bes well we don't do that we just want to see can you
    use the same exact approach Yeah at least so early recently data is just sequential
    Yeah but also there's like metadata showing about how that sequential should be
    reconstructed the image like what's the wayã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾å®é™…ä¸Šæ›´å…·é¢„æµ‹æ€§ï¼Œæ˜¯çš„ï¼Œç¡®å®å¦‚æ­¤ã€‚æ‰€ä»¥è¯·æ³¨æ„ï¼Œä½ å¯ä»¥ä¿®æ”¹QPï¼Œä½¿å…¶å…·æœ‰2Dåå·®ï¼Œæ¯”å¦‚ä½ å¯ä»¥è¿›è¡Œ2Dä½ç½®è°ƒæ•´ï¼Œä½†æˆ‘ä»¬å¹¶ä¸è¿™æ ·åšï¼Œæˆ‘ä»¬åªæ˜¯æƒ³çœ‹çœ‹æ˜¯å¦å¯ä»¥ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ–¹æ³•ã€‚è‡³å°‘ï¼Œæœ€è¿‘çš„æ•°æ®æ˜¯é¡ºåºçš„ï¼Œä½†ä¹Ÿæœ‰å…ƒæ•°æ®è¡¨æ˜è¿™ä¸ªé¡ºåºåº”è¯¥å¦‚ä½•é‡å»ºå›¾åƒï¼Œå…·ä½“æ–¹å¼æ˜¯æ€æ ·çš„ã€‚
- en: For exampleï¼Œ do you so the data on this stored yesã€‚But when you want to transform
    the sequencing into an imageã€‚you have metadata that will say something like just
    like in nu raceã€‚it'll say here's the strikeã€‚Yeah so here's how to rearrange it
    to the two dimension I see what I'm curious to notice is D before it's given an
    imageã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä½ é—®è¿™ä¸ªæ•°æ®å­˜å‚¨äº†å—ï¼Ÿæ˜¯çš„ã€‚ä½†å½“ä½ æƒ³æŠŠåºåˆ—è½¬æ¢æˆå›¾åƒæ—¶ï¼Œä½ æœ‰å…ƒæ•°æ®ä¼šå‘Šè¯‰ä½ ä¸€äº›äº‹æƒ…ï¼Œå°±åƒåœ¨nu raceä¸­ä¸€æ ·ã€‚å®ƒä¼šè¯´ï¼Œè¿™é‡Œæ˜¯æ‰“å‡»ã€‚æ˜¯çš„ï¼Œæ‰€ä»¥è¿™æ˜¯å¦‚ä½•å°†å…¶é‡æ–°æ’åˆ—æˆäºŒç»´çš„ã€‚æˆ‘å¾ˆå¥½å¥‡çš„æ˜¯åœ¨ç»™å®šå›¾åƒä¹‹å‰çš„Dã€‚
- en: at least given this metadata I see I see Okay that's extremely good question
    I don't know this problem is solvedã€‚in this caseï¼Œ all the images are have the
    same shapeã€‚ä¸ã€‚Yeah so but we don't tell it like the concept of row within the model
    like yeah all images of the same yeah so it needs to learn it from the dataã€‚but
    yeah the data looks same adjusting if it's like variable image shapes then I can
    adjust way to do it yeahã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘ç»™å®šè¿™ä¸ªå…ƒæ•°æ®ï¼Œæˆ‘æ˜ç™½äº†ã€‚å“¦ï¼Œè¿™æ˜¯ä¸ªéå¸¸å¥½çš„é—®é¢˜ï¼Œæˆ‘ä¸çŸ¥é“è¿™ä¸ªé—®é¢˜æ˜¯å¦è§£å†³äº†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰å›¾åƒéƒ½æœ‰ç›¸åŒçš„å½¢çŠ¶ã€‚ä¸ã€‚æ˜¯çš„ï¼Œä½†æˆ‘ä»¬ä¸ä¼šå‘Šè¯‰å®ƒåœ¨æ¨¡å‹ä¸­è¡Œçš„æ¦‚å¿µï¼Œæ˜¯çš„ï¼Œæ‰€æœ‰å›¾åƒéƒ½æ˜¯ç›¸åŒçš„ï¼Œæ‰€ä»¥å®ƒéœ€è¦ä»æ•°æ®ä¸­å­¦ä¹ ã€‚ä½†æ•°æ®çœ‹èµ·æ¥ç›¸åŒï¼Œå¦‚æœæ˜¯å¯å˜çš„å›¾åƒå½¢çŠ¶ï¼Œæˆ‘å¯ä»¥è°ƒæ•´å¤„ç†æ–¹å¼ï¼Œæ˜¯çš„ã€‚
- en: å“¦ã‚„ã€‚å•Šï¼Œå•Šå¯¹äº†ã€‚A lot more pixel there are token sizes yeahï¼Œ So this is a pretty low
    resolution imagesã€‚Yeahï¼Œ so we can actuallyï¼Œ the models we're comparing us are
    trained on kind of high resolution imagesã€‚So I think that makes it even more impressiveã€‚Oh
    yeahã€‚we're just training at the2 by the2 resolutionã€‚Yeahã€‚Coolã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å“¦ï¼Œå¯¹äº†ã€‚å¾ˆå¤šåƒç´ éƒ½æ˜¯ä»¤ç‰Œå¤§å°ï¼Œæ˜¯çš„ï¼Œæ‰€ä»¥è¿™æ˜¯ç›¸å½“ä½åˆ†è¾¨ç‡çš„å›¾åƒã€‚æ˜¯çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å®é™…ä¸Šï¼Œæ¯”è¾ƒçš„æ¨¡å‹æ˜¯åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒä¸Šè®­ç»ƒçš„ã€‚æˆ‘è®¤ä¸ºè¿™ä½¿å¾—ç»“æœæ›´åŠ ä»¤äººå°è±¡æ·±åˆ»ã€‚å“¦ï¼Œæ˜¯çš„ã€‚æˆ‘ä»¬åªæ˜¯ä»¥2ä¹˜ä»¥2çš„åˆ†è¾¨ç‡è¿›è¡Œè®­ç»ƒã€‚æ˜¯çš„ã€‚é…·ã€‚
- en: so if we fine tune these models for s classificationï¼Œ we can get 99% accuracyã€‚which
    matches G5 and this is G5ï¼Œ for instanceï¼Œ is a system which is pre traineded on
    imagenet with labels and then also fine tuned with labelsã€‚So yeahï¼Œ it just kind
    of shows you like even this approach which doesn't really know about convolutions
    can do wellã€‚I think you're going to hear more about that next week with Lucus
    Talkã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœæˆ‘ä»¬ä¸ºè¿™äº›æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—99%çš„å‡†ç¡®ç‡ã€‚è¿™ä¸G5ç›¸åŒ¹é…ï¼Œè€ŒG5ï¼Œä¾‹å¦‚ï¼Œæ˜¯ä¸€ä¸ªåœ¨imagenetä¸Šé¢„è®­ç»ƒå¹¶å¸¦æœ‰æ ‡ç­¾çš„ç³»ç»Ÿï¼Œç„¶åä¹Ÿè¿›è¡Œäº†æ ‡ç­¾å¾®è°ƒã€‚æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™å±•ç¤ºäº†å³ä½¿è¿™ç§æ–¹æ³•ä¸å¤ªäº†è§£å·ç§¯ä¹Ÿèƒ½åšå¾—å¾ˆå¥½ã€‚æˆ‘æƒ³ä½ ä¸‹å‘¨ä¼šå¬åˆ°æ›´å¤šå…³äºè¿™ä¸ªçš„å†…å®¹ï¼ŒLucusä¼šè°ˆã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_21.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_21.png)'
- en: æ˜¯ã€‚So by nowï¼Œ it shouldn't be surprising at all that you can model a lot of different
    modalities with transformersã€‚So in Dolly we just asked what about throwing two
    different modalities at the model and seeing if we can learn kind of how to condition
    on text to produce an image and for instanceã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ã€‚æ‰€ä»¥åˆ°ç°åœ¨ä¸ºæ­¢ï¼Œä½ åº”è¯¥ä¸æ„Ÿåˆ°æƒŠè®¶çš„æ˜¯ï¼Œä½¿ç”¨å˜æ¢å™¨å¯ä»¥å»ºæ¨¡è®¸å¤šä¸åŒçš„æ¨¡æ€ã€‚å› æ­¤ï¼Œåœ¨Dollyä¸­ï¼Œæˆ‘ä»¬åªæ˜¯é—®å°†ä¸¤ç§ä¸åŒçš„æ¨¡æ€è¾“å…¥æ¨¡å‹ï¼Œçœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥å­¦ä¹ å¦‚ä½•æ ¹æ®æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼Œä¾‹å¦‚ã€‚
- en: one thing you might want it to do is like you one of these text captions and
    you wanted it to generate some image like the one below and the easy way to do
    this is just train a transformer around the contaminatation of a caption in an
    imageã€‚And of courseï¼Œ in a lot of these situations like the idea is very simpleã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½æƒ³è®©å®ƒåšçš„ä¸€ä»¶äº‹æ˜¯ï¼Œä½ æœ‰ä¸€ä¸ªè¿™æ ·çš„æ–‡æœ¬æ ‡é¢˜ï¼Œå¹¶å¸Œæœ›å®ƒç”Ÿæˆä¸€äº›å›¾åƒï¼Œåƒä¸‹é¢çš„é‚£æ ·ï¼Œç®€å•çš„æ–¹æ³•æ˜¯è®­ç»ƒä¸€ä¸ªå›´ç»•å›¾åƒä¸­æ ‡é¢˜çš„å˜æ¢å™¨ã€‚å½“ç„¶ï¼Œåœ¨å¾ˆå¤šæƒ…å†µä¸‹ï¼Œè¿™ä¸ªæƒ³æ³•éå¸¸ç®€å•ã€‚
- en: but the implementation and execution is where the difficulty is and I'm not
    going to talk too much about thatã€‚I think the focus today is on language but we
    can refer to the paper for a lot of those detailsã€‚ğŸ˜Šã€‚Captionã€‚VeryOh yeahã€‚So youï¼Œ
    you likeï¼Œ sayï¼Œ have a max cap lengthã€‚And you just kind of cut it off at that lengthã€‚
    and you can pad up to thatã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ç°å’Œæ‰§è¡Œæ‰æ˜¯å›°éš¾æ‰€åœ¨ï¼Œæˆ‘ä¸æ‰“ç®—è¯¦ç»†è®¨è®ºè¿™ä¸ªã€‚æˆ‘è®¤ä¸ºä»Šå¤©çš„é‡ç‚¹æ˜¯è¯­è¨€ï¼Œä½†æˆ‘ä»¬å¯ä»¥å‚è€ƒè®ºæ–‡è·å–è®¸å¤šç»†èŠ‚ã€‚ğŸ˜Šã€‚æ ‡é¢˜ã€‚å—¯ï¼Œå“¦å¯¹äº†ã€‚æ‰€ä»¥ä½ ï¼Œæœ‰ä¸€ä¸ªæœ€å¤§é•¿åº¦é™åˆ¶ã€‚ä½ å°±æŠŠå®ƒåˆ‡æ–­åˆ°é‚£ä¸ªé•¿åº¦ï¼Œå¹¶ä¸”å¯ä»¥å¡«å……åˆ°é‚£ä¸ªé•¿åº¦ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_23.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_23.png)'
- en: Right so you can see that it can generate fairly good samples so if you want
    like a storefront with the word opening eye on it it's not perfectã€‚but it's understood
    at least it's kind of like reverse orcrR problem where you take some text and
    render it and it's kind of typically rendering it in like office looking places
    so that's one encouraging sign but I do think my favorite results here are zero
    shock emission image transformation So what's going on here is for instanceã€‚
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹ï¼Œæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°å®ƒå¯ä»¥ç”Ÿæˆç›¸å½“ä¸é”™çš„æ ·æœ¬ï¼Œå¦‚æœä½ æƒ³è¦ä¸€ä¸ªä¸Šé¢å†™ç€â€œå¼€é—¨â€çš„åº—é¢ï¼Œå®ƒå¹¶ä¸æ˜¯å®Œç¾çš„ï¼Œä½†è‡³å°‘å®ƒç†è§£äº†è¿™æ˜¯ä¸€ç§åå‘çš„OCRé—®é¢˜ï¼Œä½ æŠŠä¸€äº›æ–‡æœ¬æ¸²æŸ“å‡ºæ¥ï¼Œé€šå¸¸æ˜¯åœ¨åŠå…¬å®¤çœ‹èµ·æ¥çš„åœ°æ–¹æ¸²æŸ“å‡ºæ¥ï¼Œè¿™æ˜¯ä¸€ä¸ªé¼“èˆäººå¿ƒçš„è¿¹è±¡ï¼Œä½†æˆ‘è®¤ä¸ºæˆ‘åœ¨è¿™é‡Œæœ€å–œæ¬¢çš„ç»“æœæ˜¯é›¶æ ·æœ¬çš„å›¾åƒå˜æ¢ã€‚é‚£ä¹ˆè¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆå‘¢ï¼Ÿ
- en: if your prompt is the exact same cat on the top as as a sketch on the bottom
    and you feed in the top half of this image which is a cap and you ask it to complete
    the rest of the image then it'll render the top cat actually as likeã€‚ğŸ˜Šï¼ŒA sketchã€‚And
    you can do the same thing with like flipping over photosï¼Œ for instanceã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”å¦‚è¯´ï¼Œå¦‚æœä½ çš„æç¤ºæ˜¯ä¸Šé¢é‚£åªçŒ«å’Œä¸‹é¢çš„è‰å›¾æ˜¯å®Œå…¨ä¸€æ ·çš„ï¼Œä½ è¾“å…¥è¿™å¹…å›¾åƒçš„ä¸ŠåŠéƒ¨åˆ†ï¼Œå³çŒ«çš„éƒ¨åˆ†ï¼Œå¹¶è¦æ±‚å®ƒå®Œæˆå‰©ä¸‹çš„å›¾åƒï¼Œé‚£ä¹ˆå®ƒä¼šæŠŠä¸Šé¢çš„çŒ«æ¸²æŸ“æˆåƒæ˜¯ğŸ˜Šï¼Œä¸€å¹…è‰å›¾ã€‚ä½ ä¹Ÿå¯ä»¥å¯¹ç…§ç‰‡è¿›è¡Œç¿»è½¬ä¹‹ç±»çš„äº‹æƒ…ã€‚
- en: You can zoom in a photoã€‚Of course they're not perfectã€‚but it has some understanding
    of what the Texas training do in the captions originally like the training in
    the training setã€‚do they have like wording such I screen close up you I think
    that that is the if it probably are some examples like thatã€‚And that's probably
    where it's picking up some of the knowledge from though we don't seek out these
    examples It's just yeahã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ”¾å¤§ä¸€å¼ ç…§ç‰‡ã€‚å½“ç„¶ï¼Œå®ƒä»¬å¹¶ä¸æ˜¯å®Œç¾çš„ï¼Œä½†å®ƒå¯¹æ–‡æœ¬è®­ç»ƒä¸­åŸå§‹è¯´æ˜çš„ç†è§£æœ‰ä¸€äº›äº†è§£ï¼Œæ¯”å¦‚åœ¨è®­ç»ƒé›†ä¸­æ˜¯å¦æœ‰åƒâ€œå±å¹•ç‰¹å†™â€è¿™æ ·çš„è¯ï¼Œæˆ‘è®¤ä¸ºè¿™å¯èƒ½æ˜¯ä¸€äº›è¿™æ ·çš„ä¾‹å­ã€‚è€Œè¿™å¤§æ¦‚æ˜¯å®ƒè·å–ä¸€äº›çŸ¥è¯†çš„åœ°æ–¹ï¼Œå°½ç®¡æˆ‘ä»¬å¹¶ä¸ä¸“é—¨å¯»æ‰¾è¿™äº›ä¾‹å­ï¼Œç¡®å®æ˜¯è¿™æ ·çš„ã€‚
- en: yeah exactly Okayï¼Œ perfectã€‚Yeahï¼Œ so this is just how we just go and do a massive
    web scriptã€‚there's no kind ofï¼Œ we're not trying to find examples like thisã€‚Right
    and so you can also do things like colorization right you can take the cat color
    red and this has to like kind of recognize that what the object is in the figure
    and yeah and so you could do stuff like seman transformations like adding sunglasses
    into the cat and you can put it on postage for instance yeah so justs remarkably
    that you can do a lot of these like transform zero shots it wasn't trained to
    do these things specificallyã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ­£æ˜¯å¦‚æ­¤ï¼Œå¥½çš„ï¼Œå®Œç¾ã€‚æ˜¯çš„ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¦‚ä½•è¿›è¡Œä¸€ä¸ªå¤§å‹ç½‘é¡µè„šæœ¬çš„æ–¹å¼ã€‚æˆ‘ä»¬å¹¶ä¸æ˜¯åœ¨å¯»æ‰¾è¿™æ ·çš„ä¾‹å­ã€‚å¯¹ï¼Œæ‰€ä»¥ä½ ä¹Ÿå¯ä»¥åšä¸€äº›åƒä¸Šè‰²çš„äº‹æƒ…ï¼Œæ¯”å¦‚è¯´æŠŠçŒ«çš„é¢œè‰²å˜æˆçº¢è‰²ï¼Œè¿™éœ€è¦è¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“æ˜¯ä»€ä¹ˆï¼Œå¯¹å§ï¼Ÿæ‰€ä»¥ä½ å¯ä»¥åšä¸€äº›åƒè¯­ä¹‰å˜æ¢çš„äº‹æƒ…ï¼Œæ¯”å¦‚ç»™çŒ«åŠ ä¸Šå¤ªé˜³é•œï¼Œç”šè‡³å¯ä»¥æŠŠå®ƒæ”¾åœ¨é‚®ç¥¨ä¸Šï¼Œæ‰€ä»¥çœŸçš„å¾ˆäº†ä¸èµ·ï¼Œä½ å¯ä»¥åšå¾ˆå¤šè¿™ç§å˜æ¢çš„é›¶æ ·æœ¬ï¼Œå®ƒå¹¶ä¸æ˜¯ä¸“é—¨è®­ç»ƒæ¥åšè¿™äº›äº‹æƒ…çš„ã€‚
- en: Coolï¼Œ so moving onï¼Œ the last section of my talk today is on CodeXã€‚which is our
    most recently released code writing modelsã€‚And the first question you should rightly
    ask here isã€‚Whyhy train a model on anyway isn't at this point isn't it just another
    modalityï¼ŸğŸ˜¡ã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆé…·ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥æˆ‘ä»Šå¤©æ¼”è®²çš„æœ€åä¸€éƒ¨åˆ†æ˜¯å…³äºCodeXçš„ï¼Œè¿™æ˜¯æˆ‘ä»¬æœ€è¿‘å‘å¸ƒçš„ä»£ç ç¼–å†™æ¨¡å‹ã€‚ä½ åº”è¯¥æ­£ç¡®åœ°é—®çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šä¸ºä»€ä¹ˆè¦è®­ç»ƒä¸€ä¸ªæ¨¡å‹å‘¢ï¼Ÿåœ¨è¿™ä¸ªæ—¶å€™ï¼Œè¿™éš¾é“ä¸åªæ˜¯å¦ä¸€ç§æ¨¡æ€å—ï¼ŸğŸ˜¡
- en: And what is the novelty that there is at this point rightï¼Œ so let me give you
    a couple of reasonsã€‚So first is that GP3 it had a rudimentary ability to write
    Python code already from a do string or descriptive method name and we actually
    didn't train it on much code data actually I think there might have been active
    filtering to get rid of code data and so we were surprised that there is this
    capability anyway so that you know like if we actually purpose a model and trained
    it on the large amount of code that we can find maybe something interesting will
    happen thereã€‚
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆç°åœ¨æœ‰ä»€ä¹ˆæ–°å¥‡ä¹‹å¤„å‘¢ï¼Ÿè®©æˆ‘ç»™ä½ å‡ ä¸ªç†ç”±ã€‚é¦–å…ˆæ˜¯GP3å·²ç»å…·å¤‡äº†ä»ä¸€ä¸ªæè¿°æ€§æ–¹æ³•åç§°æˆ–å­—ç¬¦ä¸²å†™Pythonä»£ç çš„åŸºæœ¬èƒ½åŠ›ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¹¶æ²¡æœ‰åœ¨å¾ˆå¤šä»£ç æ•°æ®ä¸Šè®­ç»ƒå®ƒï¼Œå®é™…ä¸Šæˆ‘è®¤ä¸ºå¯èƒ½è¿›è¡Œäº†ä¸»åŠ¨è¿‡æ»¤ï¼Œä»¥å»é™¤ä»£ç æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¹æ­¤èƒ½åŠ›æ„Ÿåˆ°æƒŠè®¶ã€‚æ‰€ä»¥ä½ çŸ¥é“ï¼Œå¦‚æœæˆ‘ä»¬çœŸçš„ä¸“é—¨ä¸ºæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æˆ‘ä»¬èƒ½æ‰¾åˆ°çš„å¤§é‡ä»£ç ä¸Šè®­ç»ƒï¼Œä¹Ÿè®¸ä¼šå‘ç”Ÿä¸€äº›æœ‰è¶£çš„äº‹æƒ…ã€‚
- en: Nextï¼Œ what sets apart code from other modalities is that there is a kind of
    ground truth correctness of a sample and functions can be tested with unit tests
    and an interpreter so this is very different from language whereas to get a ground
    truth value you might need a human to come in and even then sometimes humans won't
    agree like this this is the better sample or this isn't the better sampleã€‚
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œä»£ç ä¸å…¶ä»–æ¨¡å¼çš„åŒºåˆ«åœ¨äºï¼Œæ ·æœ¬çš„æ­£ç¡®æ€§æœ‰ä¸€ç§æ ‡å‡†çœŸç›¸ï¼Œå¹¶ä¸”å‡½æ•°å¯ä»¥é€šè¿‡å•å…ƒæµ‹è¯•å’Œè§£é‡Šå™¨è¿›è¡Œæµ‹è¯•ï¼Œè¿™ä¸è¯­è¨€æ˜¯éå¸¸ä¸åŒçš„ï¼Œå› ä¸ºè¦è·å¾—æ ‡å‡†çœŸç›¸å€¼ï¼Œä½ å¯èƒ½éœ€è¦äººç±»çš„å‚ä¸ï¼Œå³ä½¿è¿™æ ·ï¼Œæœ‰æ—¶äººç±»ä¹Ÿä¸ä¼šè¾¾æˆä¸€è‡´ï¼Œæ¯”å¦‚è¿™ä¸ªæ ·æœ¬æ›´å¥½æˆ–ä¸æ›´å¥½ã€‚
- en: And last thing is I used to double in competitive programming myself and yeah
    I really wanted to create a model that could solve problems that I could'tã€‚ğŸ˜Šï¼ŒSo
    if oh yeahï¼ŒThis is the same thing that we to get up on thisï¼Œ yeahã€‚Yeahã€‚we wrote
    a paper on it tooï¼Œ so yeahã€‚ğŸ˜Šï¼Œperson is kind of a high levelã€‚Programming language
    is similar to our human languageã€‚
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¥å‰ä¹Ÿå‚ä¸è¿‡ç«äº‰ç¼–ç¨‹ï¼Œç¡®å®å¾ˆæƒ³åˆ›å»ºä¸€ä¸ªèƒ½è§£å†³æˆ‘æ— æ³•è§£å†³çš„é—®é¢˜çš„æ¨¡å‹ã€‚ğŸ˜Šæ‰€ä»¥ï¼Œå¦‚æœå“¦å¯¹äº†ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬è¦åšåˆ°çš„ï¼Œæ²¡é”™ã€‚æˆ‘ä»¬ä¹Ÿå†™è¿‡ä¸€ç¯‡è®ºæ–‡ï¼Œå—¯ï¼Œä¸ªäººæ„Ÿè§‰è¿™ç§ç¼–ç¨‹è¯­è¨€åœ¨æŸç§ç¨‹åº¦ä¸Šç±»ä¼¼äºæˆ‘ä»¬çš„äººç±»è¯­è¨€ã€‚
- en: I you guess ever try to predict some even lower level language like CP or yeah
    yeah yeah I think there's yeahã€‚there's follow up work where we just trade on a
    bunch of different languages and I don't know the metrics off the top of my head
    but I have seen some assembly of writing modelsã€‚
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¯•å›¾é¢„æµ‹ä¸€äº›æ›´ä½çº§çš„è¯­è¨€ï¼Œæ¯”å¦‚CPï¼Œå—¯ï¼Œæˆ‘è§‰å¾—æ˜¯æœ‰çš„ã€‚æœ‰åç»­å·¥ä½œï¼Œæˆ‘ä»¬å°±ç”¨å„ç§ä¸åŒçš„è¯­è¨€è¿›è¡Œè®­ç»ƒï¼Œæˆ‘ä¸å¤ªè®°å¾—å…·ä½“çš„æŒ‡æ ‡ï¼Œä½†æˆ‘è§è¿‡ä¸€äº›æ±‡ç¼–è¯­è¨€çš„æ¨¡å‹ã€‚
- en: Cool so I guess yeah continuing on the third from before so we have this this
    setting where we have unit tests and interpreter so how do we actually evaluate
    these models in a way that's kind of aware of these two concepts so the first
    thing we did was we have a data set a new data set which is 164 handwritten programming
    problemsã€‚
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæ¥ç€ä¹‹å‰çš„ç¬¬ä¸‰ç‚¹ï¼Œæˆ‘ä»¬æœ‰è¿™æ ·çš„ç¯å¢ƒï¼Œæœ‰å•å…ƒæµ‹è¯•å’Œè§£é‡Šå™¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬å®é™…ä¸Šå¦‚ä½•ä»¥ä¸€ç§å…³æ³¨è¿™ä¸¤ä¸ªæ¦‚å¿µçš„æ–¹å¼è¯„ä¼°è¿™äº›æ¨¡å‹å‘¢ï¼Ÿæˆ‘ä»¬é¦–å…ˆåšçš„æ˜¯å‡†å¤‡ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œå…±164ä¸ªæ‰‹å†™ç¼–ç¨‹é—®é¢˜ã€‚
- en: And these kind of have the format shown hereï¼Œ like there's a function nameï¼Œ
    a doc stringã€‚there's a solutionï¼Œ and there's an average of around eight unit tests
    per problemã€‚And why is it important that we handrote these well the thing is we're
    training on such a large part of GiHub like if you said okay I'm going to take
    like some Vcode problems and I'm going to turn them into an evaluation that's
    not going to work because there's just so many GiHub reppos that are like oh here's
    the solution to this V code problem so while this doesn't kind of guarantee that
    this problem isn't duplicateupd at least someone wrote it without trying to copy
    it from another sourceã€‚
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æœ‰ç±»ä¼¼äºæ­¤çš„æ ¼å¼ï¼Œæ¯”å¦‚å‡½æ•°åã€æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¿˜æœ‰è§£å†³æ–¹æ¡ˆï¼Œä»¥åŠæ¯ä¸ªé—®é¢˜å¤§çº¦å…«ä¸ªå•å…ƒæµ‹è¯•ã€‚é‡è¦çš„æ˜¯æˆ‘ä»¬è¦å¾ˆå¥½åœ°æ‰‹åŠ¨ä¹¦å†™è¿™äº›ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨è®­ç»ƒGitHubä¸Šå¦‚æ­¤å¤§é‡çš„æ•°æ®ã€‚å¦‚æœä½ è¯´æˆ‘è¦æŠŠä¸€äº›Vä»£ç é—®é¢˜è½¬åŒ–ä¸ºè¯„ä¼°ï¼Œé‚£æ˜¯ä¸è¡Œçš„ï¼Œå› ä¸ºæœ‰å¤ªå¤šGitHubä»“åº“æ˜¯è¿™æ ·ï¼šâ€œå“¦ï¼Œè¿™æ˜¯è¿™ä¸ªVä»£ç é—®é¢˜çš„è§£å†³æ–¹æ¡ˆâ€ï¼Œæ‰€ä»¥è™½ç„¶è¿™å¹¶ä¸èƒ½å®Œå…¨ä¿è¯è¿™ä¸ªé—®é¢˜ä¸æ˜¯é‡å¤çš„ï¼Œè‡³å°‘æœ‰äººåœ¨æ²¡æœ‰è¯•å›¾ä»å…¶ä»–æ¥æºå¤åˆ¶çš„æƒ…å†µä¸‹å†™äº†å®ƒã€‚
- en: Umã€‚So here's some kind of examples of unit test that you would evaluate the
    previous function onã€‚I think it should be fairly clear that we should be using
    this metric like this is the correct kind of ground truth metric to use I mean
    humans do use unit tests to evaluate code and I would say like if you're familiar
    with a competitive programming like you can't manually judge all like tens of
    thousands of submissions that are coming inã€‚
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œè¿™é‡Œæœ‰ä¸€äº›å•å…ƒæµ‹è¯•çš„ä¾‹å­ï¼Œä½ å¯ä»¥ç”¨æ¥è¯„ä¼°ä¹‹å‰çš„å‡½æ•°ã€‚æˆ‘è§‰å¾—å¾ˆæ˜æ˜¾ï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨è¿™ä¸ªæŒ‡æ ‡ï¼Œè¿™æ˜¯çœŸæ­£çš„æ ‡å‡†çœŸç›¸æŒ‡æ ‡ï¼Œæˆ‘çš„æ„æ€æ˜¯ï¼Œäººç±»ç¡®å®ä¼šä½¿ç”¨å•å…ƒæµ‹è¯•æ¥è¯„ä¼°ä»£ç ï¼Œè€Œä¸”æˆ‘ä¼šè¯´ï¼Œå¦‚æœä½ ç†Ÿæ‚‰ç«äº‰ç¼–ç¨‹ï¼Œä½ æ— æ³•æ‰‹åŠ¨è¯„åˆ¤æˆåƒä¸Šä¸‡çš„æäº¤ã€‚
- en: you need the unit tests and that is a fairly good filterã€‚So what an interesting
    point here was we had to create a sandbox environment to run these kind of generated
    solutions in because when you turn on Gitubã€‚there's a bunch of malicious codeï¼Œ
    there's a bunch of kind of insecure codeã€‚you know why your model should be sampling
    that and kind of running that on your environmentã€‚
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦å•å…ƒæµ‹è¯•ï¼Œè¿™æ˜¯ä¸€ä¸ªç›¸å½“ä¸é”™çš„è¿‡æ»¤å™¨ã€‚æ‰€ä»¥è¿™é‡Œæœ‰ä¸€ä¸ªæœ‰è¶£çš„ç‚¹æ˜¯ï¼Œæˆ‘ä»¬å¿…é¡»åˆ›å»ºä¸€ä¸ªæ²™ç®±ç¯å¢ƒæ¥è¿è¡Œè¿™äº›ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆï¼Œå› ä¸ºå½“ä½ å¼€å¯GitHubæ—¶ï¼Œæœ‰ä¸€å †æ¶æ„ä»£ç ï¼Œå¾ˆå¤šä¸å®‰å…¨çš„ä»£ç ã€‚ä½ çŸ¥é“ä½ çš„æ¨¡å‹ä¸ºä»€ä¹ˆåº”è¯¥å»é‡‡æ ·é‚£äº›ï¼Œå¹¶åœ¨ä½ çš„ç¯å¢ƒä¸­è¿è¡Œã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_25.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_25.png)'
- en: Yeahã€‚Coolï¼Œ so now that we have an evaluation data setï¼Œ let's define a metric
    onã€‚And so the metric we're going to use is called pass at Kã€‚and the definition
    is the average probability over all the problems that at least one out of K sampless
    passes the unit testã€‚So if we evaluate this metric by just taking every problem
    exactly generating K samplesã€‚
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œé…·ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†è¯„ä¼°æ•°æ®é›†ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæŒ‡æ ‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨çš„æŒ‡æ ‡ç§°ä¸º K çš„é€šè¿‡ç‡ã€‚å…¶å®šä¹‰æ˜¯æ‰€æœ‰é—®é¢˜çš„å¹³å‡æ¦‚ç‡ï¼Œå…¶ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ ·æœ¬é€šè¿‡å•å…ƒæµ‹è¯•ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬é€šè¿‡ç”Ÿæˆ
    K ä¸ªæ ·æœ¬æ¥è¯„ä¼°è¿™ä¸ªæŒ‡æ ‡ã€‚
- en: it's actually not there's high variances just kind of sampling in that way like
    imagine the past rate of a particular samples around one over k like this is kind
    of like an all or nothing metric so what we do instead is we generate a much larger
    set of samples and greater than K most of the times it's like greater than5 k
    and we count the number of that are correct and we compute this unbiased estcalator
    and it looks more complicated and actually is its just complementary accounting
    you you take kind of the number of combos where all of them fail subject thatã€‚
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šå¹¶ä¸æ˜¯è¿™æ ·ï¼Œè¿™é‡Œæœ‰å¾ˆé«˜çš„æ–¹å·®ï¼Œåªæ˜¯åœ¨ä»¥è¿™ç§æ–¹å¼é‡‡æ ·ï¼›æƒ³è±¡ä¸€ä¸‹ï¼Œç‰¹å®šæ ·æœ¬çš„è¿‡å»ç‡åœ¨ 1/k é™„è¿‘ï¼Œè¿™æœ‰ç‚¹åƒå…¨æœ‰æˆ–å…¨æ— çš„æŒ‡æ ‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡å–çš„æ–¹å¼æ˜¯ç”Ÿæˆä¸€ä¸ªæ›´å¤§çš„æ ·æœ¬é›†ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹å¤§äº
    Kï¼Œåƒæ˜¯å¤§äº 5Kï¼Œæˆ‘ä»¬ç»Ÿè®¡æ­£ç¡®çš„æ ·æœ¬æ•°é‡ï¼Œå¹¶è®¡ç®—è¿™ä¸ªæ— åä¼°è®¡ï¼Œè¿™çœ‹èµ·æ¥æ¯”å®é™…å¤æ‚ï¼Œå…¶å®åªæ˜¯äº’è¡¥è®¡æ•°ï¼Œä½ è¦è€ƒè™‘æ‰€æœ‰å¤±è´¥ç»„åˆçš„æ•°é‡ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_27.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_27.png)'
- en: Coolï¼Œ so then we train our model and like I alluded to earlierï¼Œ there's about
    160 gigabytes of codeã€‚which is collected from 54 million repositoriesã€‚For efficient
    training what we did was we fine tune from GPT3 models of various sizes and this
    isn't actually strictly necessaryã€‚
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: é…·ï¼Œç„¶åæˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæ­£å¦‚æˆ‘ä¹‹å‰æåˆ°çš„ï¼Œæœ‰å¤§çº¦ 160GB çš„ä»£ç ï¼Œæ¥è‡ª 5400ä¸‡ä¸ªä»£ç åº“ã€‚ä¸ºäº†æœ‰æ•ˆçš„è®­ç»ƒï¼Œæˆ‘ä»¬ä»å„ç§å¤§å°çš„ GPT-3 æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¿™å…¶å®å¹¶ä¸æ˜¯ç»å¯¹å¿…è¦çš„ã€‚
- en: we find that we can get to roughly the same final loss and performance without
    C but it is slower to do it without without the free training step and so we already
    have these models why not just fine tune themã€‚And one extra trick to make training
    much faster here is in code there's a lot of runs of spaces right and those don't
    get compressed efficiently in language because you just don't see them very often
    so they typically get broken up into like many separate tokens and so we introduce
    additionally some tokens that compress runs of one space and that makes training
    maybe likeã€‚
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‘ç°ï¼Œæ²¡æœ‰ C çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°å¤§è‡´ç›¸åŒçš„æœ€ç»ˆæŸå¤±å’Œæ€§èƒ½ï¼Œä½†æ²¡æœ‰å…è´¹çš„è®­ç»ƒæ­¥éª¤ï¼Œé€Ÿåº¦è¾ƒæ…¢ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å·²ç»æœ‰äº†è¿™äº›æ¨¡å‹ï¼Œä½•ä¸ç›´æ¥å¾®è°ƒå®ƒä»¬å‘¢ï¼Ÿä¸ºäº†åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œæˆ‘ä»¬åœ¨ä»£ç ä¸­å‘ç°æœ‰å¾ˆå¤šè¿ç»­çš„ç©ºæ ¼ï¼Œè€Œè¿™äº›åœ¨è¯­è¨€ä¸­å¹¶æ²¡æœ‰è¢«æœ‰æ•ˆå‹ç¼©ï¼Œå› ä¸ºä½ å¾ˆå°‘è§åˆ°å®ƒä»¬ï¼Œæ‰€ä»¥é€šå¸¸ä¼šè¢«æ‹†åˆ†æˆå¤šä¸ªå•ç‹¬çš„æ ‡è®°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é¢å¤–å¼•å…¥äº†ä¸€äº›æ ‡è®°ï¼Œæ¥å‹ç¼©è¿ç»­çš„ç©ºæ ¼ï¼Œè¿™æ ·è®­ç»ƒå¯èƒ½ä¼šæ›´å¿«ã€‚
- en: 30 or 40% more efficientYeahï¼Œ exactlyï¼Œ yeahã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_29.png)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æ•ˆç‡æé«˜äº† 30% æˆ– 40%ã€‚æ˜¯çš„ï¼Œç¡®å®å¦‚æ­¤ï¼[](img/542291b724ae1b1a3bd31a38e9d3acdc_29.png)
- en: Greatï¼Œ so once we have these modelsï¼Œ we can go and revisit the human E data
    set and I can share a couple of problems to give you a sense of where the models
    are at and also what kind of difficulty level the problems in the data set are
    atã€‚So this is a 12 billion parameter model the pass out is 90%ã€‚
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼Œä¸€æ—¦æˆ‘ä»¬æœ‰äº†è¿™äº›æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°æŸ¥çœ‹äººç±» E æ•°æ®é›†ï¼Œæˆ‘å¯ä»¥åˆ†äº«å‡ ä¸ªé—®é¢˜ï¼Œè®©ä½ äº†è§£æ¨¡å‹çš„è¡¨ç°ä»¥åŠæ•°æ®é›†ä¸­é—®é¢˜çš„éš¾åº¦æ°´å¹³ã€‚è¿™æ˜¯ä¸€ä¸ª120äº¿å‚æ•°çš„æ¨¡å‹ï¼Œé€šè¡Œç‡ä¸º90%ã€‚
- en: which means that 90% of the samples will pass the unit test and this is very
    something like anyone kind of doing a first day of Python would be able to do
    so you increment all the elements of a list by oneã€‚Here is a problem where the
    pass rate is 17% so this is a solution I gave the problem I gave earlier so you
    are given a nonmp list of integers you want to return to some of odd elements
    that are in even positions and this might not sound that much harder to you but
    models can often get confused about like oh like is odd referring to positions
    or elements and so here you can actually see that it's doing the right thingã€‚
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€ 90% çš„æ ·æœ¬å°†é€šè¿‡å•å…ƒæµ‹è¯•ï¼Œè¿™å¯¹äºä»»ä½•ç¬¬ä¸€æ¬¡å­¦ä¹  Python çš„äººæ¥è¯´éƒ½æ˜¯å¾ˆç®€å•çš„äº‹æƒ…ï¼Œæ¯”å¦‚ä½ è¦å°†åˆ—è¡¨ä¸­çš„æ‰€æœ‰å…ƒç´ åŠ ä¸€ã€‚è¿™æ˜¯ä¸€ä¸ªé€šè¿‡ç‡ä¸º
    17% çš„é—®é¢˜ï¼Œè¿™æ˜¯æˆ‘ä¹‹å‰ç»™å‡ºçš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œä½ ä¼šå¾—åˆ°ä¸€ä¸ªåŒ…å«æ•´æ•°çš„åˆ—è¡¨ï¼Œä½ æƒ³è¿”å›åœ¨å¶æ•°ä½ç½®çš„å¥‡æ•°å…ƒç´ ã€‚è¿™å¯èƒ½å¬èµ·æ¥ä¸å¤ªéš¾ï¼Œä½†æ¨¡å‹é€šå¸¸ä¼šå¯¹å¥‡æ•°æ˜¯æŒ‡ä½ç½®è¿˜æ˜¯å…ƒç´ äº§ç”Ÿå›°æƒ‘ï¼Œå› æ­¤åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°å®ƒåšå¯¹äº†ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_31.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_31.png)'
- en: And finallyï¼Œ this is an example of one of the harder problems in the data set
    So the pass rate is under 1% here and so what's going on here is actually there's
    an encode function which takes a streamã€‚it kind of chunks it up into groups of
    three characters and it does a cyclic shift on each character and you have to
    write a decoderã€‚
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè¿™æ˜¯æ•°æ®é›†ä¸­ä¸€äº›è¾ƒéš¾é—®é¢˜çš„ç¤ºä¾‹ã€‚å› æ­¤ï¼Œåˆæ ¼ç‡åœ¨è¿™é‡Œä½äº1%ã€‚è¿™é‡Œå‘ç”Ÿçš„äº‹æƒ…å®é™…ä¸Šæ˜¯æœ‰ä¸€ä¸ªç¼–ç å‡½æ•°ï¼Œå®ƒä¼šå°†ä¸€ä¸ªæµåˆ†æˆä¸‰å­—ç¬¦çš„ç»„ï¼Œå¹¶å¯¹æ¯ä¸ªå­—ç¬¦è¿›è¡Œå¾ªç¯ç§»ä½ï¼Œä½ éœ€è¦ç¼–å†™ä¸€ä¸ªè§£ç å™¨ã€‚
- en: something that reverses this operation so you can see that model this is a real
    model solution so it chunks up the characters in the same way you can see that
    the cyclic shift is the opposite way so up there it takes the first element of
    each group moves it to the end and now it takes the last element of each group
    moves it into theã€‚
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›åè½¬è¿™ä¸ªæ“ä½œçš„å†…å®¹ï¼Œæ‰€ä»¥ä½ å¯ä»¥çœ‹åˆ°æ¨¡å‹ï¼Œè¿™æ˜¯çœŸå®çš„æ¨¡å‹è§£å†³æ–¹æ¡ˆï¼Œå®ƒä»¥ç›¸åŒçš„æ–¹å¼åˆ†å—å­—ç¬¦ã€‚ä½ å¯ä»¥çœ‹åˆ°å¾ªç¯ç§»ä½æ˜¯ç›¸åçš„ï¼Œæ‰€ä»¥åœ¨ä¸Šé¢ï¼Œå®ƒå°†æ¯ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ ç§»åŠ¨åˆ°æœ€åï¼Œå¹¶ä¸”ç°åœ¨å®ƒå°†æ¯ç»„çš„æœ€åä¸€ä¸ªå…ƒç´ ç§»åˆ°ã€‚
- en: Okayï¼Œ as I'm wonderingï¼Œ what's the effect of so like you had a couple of examples
    in the previous slideã€‚it was in the commentsã€‚So like I'm wondering if the model
    will be able to extrapolate what it's doing by the examples so on and not relying
    on the right yeah so some of our tasks there are some examples in the doctrine
    and some of them don't I think it's just to kind of match the distribution of
    the old kind of tasks we find in the real world like in this case it doesn't have
    it but definitely for the unit tests none of those appear within I'm justing like
    if you just give it the examples and not the the description all the task Oh I
    see I see so can it do like pure induction where you like don't tell the task
    at off Yeah I haven't tried it to be honest I think it's worth the shot yeah thanksã€‚
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œæˆ‘åœ¨æƒ³ï¼Œåƒä½ åœ¨ä¹‹å‰çš„å¹»ç¯ç‰‡ä¸­æœ‰å‡ ä¸ªä¾‹å­ï¼Œé‚£æ˜¯åœ¨è¯„è®ºä¸­ã€‚æ‰€ä»¥æˆ‘æƒ³çŸ¥é“è¿™ä¸ªæ¨¡å‹æ˜¯å¦èƒ½å¤Ÿé€šè¿‡è¿™äº›ä¾‹å­æ¨æ–­å‡ºå®ƒæ­£åœ¨åšçš„äº‹æƒ…ï¼Œè€Œä¸ä¾èµ–äºå¯¹çš„ã€‚æ˜¯çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ä»»åŠ¡ä¸­æœ‰ä¸€äº›ä¾‹å­åœ¨æ–‡æ¡£ä¸­ï¼Œæœ‰ä¸€äº›åˆ™æ²¡æœ‰ã€‚æˆ‘è®¤ä¸ºè¿™åªæ˜¯ä¸ºäº†åŒ¹é…æˆ‘ä»¬åœ¨ç°å®ä¸–ç•Œä¸­å‘ç°çš„æ—§ä»»åŠ¡çš„åˆ†å¸ƒï¼Œæ¯”å¦‚åœ¨è¿™ç§æƒ…å†µä¸‹æ²¡æœ‰ï¼Œä½†ç»å¯¹å¯¹äºå•å…ƒæµ‹è¯•æ¥è¯´ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ²¡æœ‰å‡ºç°ã€‚æˆ‘åªæ˜¯æƒ³ï¼Œå¦‚æœä½ åªç»™å®ƒä¾‹å­ï¼Œè€Œä¸æ˜¯ä»»åŠ¡çš„æè¿°ï¼Œå“¦ï¼Œæˆ‘æ˜ç™½äº†ï¼Œæˆ‘æ˜ç™½äº†ã€‚æ‰€ä»¥å®ƒå¯ä»¥åšåˆ°åƒçº¯å½’çº³é‚£æ ·çš„äº‹æƒ…å—ï¼Œæ‚¨ä¸å‘Šè¯‰ä»»åŠ¡çš„å†…å®¹ï¼Ÿæ˜¯çš„ï¼Œè€å®è¯´æˆ‘è¿˜æ²¡æœ‰å°è¯•è¿‡ï¼Œæˆ‘è§‰å¾—å€¼å¾—ä¸€è¯•ã€‚è°¢è°¢ã€‚
- en: Yeahï¼Œ so yeah at this pointï¼Œ we've trained codex models we've evaluated on this
    metricã€‚but the thing is like was it worth all this trouble right you already have
    these metrics like blue that are matchbased in language couldn't we have just
    used this to Rosmate and we don't need like an interpreter we don't need like
    to generate so many samples and it would be great if like it kind of like separate
    it out like this but what we find is that this is if you take four random poems
    from human eva and you plot the distribution of blue scores for correct and wrong
    solutions you actually find a lot of distributional overlap right like it's hard
    to distinguish likeã€‚
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ‰€ä»¥åœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæˆ‘ä»¬å·²ç»è®­ç»ƒäº†codexæ¨¡å‹ï¼Œå¹¶åœ¨è¿™ä¸ªæŒ‡æ ‡ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ä½†é—®é¢˜æ˜¯ï¼Œæ‰€æœ‰è¿™äº›éº»çƒ¦æ˜¯å¦å€¼å¾—å‘¢ï¼Ÿä½ å·²ç»æœ‰è¿™äº›åŸºäºè¯­è¨€çš„æŒ‡æ ‡ï¼Œæ¯”å¦‚è“è‰²åˆ†æ•°ï¼Œæˆ‘ä»¬éš¾é“ä¸èƒ½ä»…ä»…ä½¿ç”¨è¿™äº›è¿›è¡ŒRosmateå—ï¼Ÿæˆ‘ä»¬ä¸éœ€è¦åƒç”Ÿæˆé‚£ä¹ˆå¤šæ ·æœ¬çš„è§£é‡Šå™¨ï¼Œå¦‚æœå®ƒèƒ½åƒè¿™æ ·åˆ†å¼€é‚£å°±å¤ªå¥½äº†ã€‚ä½†æˆ‘ä»¬å‘ç°çš„æ˜¯ï¼Œå¦‚æœä½ ä»äººç±»Evaä¸­éšæœºå–å››é¦–è¯—ï¼Œå¹¶ç»˜åˆ¶æ­£ç¡®å’Œé”™è¯¯è§£å†³æ–¹æ¡ˆçš„è“è‰²åˆ†æ•°åˆ†å¸ƒï¼Œä½ å®é™…ä¸Šä¼šå‘ç°å¾ˆå¤šåˆ†å¸ƒé‡å ï¼Œæ²¡é‚£ä¹ˆå®¹æ˜“åŒºåˆ†ã€‚
- en: ğŸ˜Šï¼ŒThe green from the blue distribution and so this suggests that blue actually
    isn't a very good metric for gaugging functional correctness and that we actually
    do need this this new kind of metric and this new data setã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_33.png)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæ¥è‡ªè“è‰²åˆ†å¸ƒçš„ç»¿è‰²ï¼Œæ‰€ä»¥è¿™è¡¨æ˜è“è‰²å®é™…ä¸Šä¸æ˜¯è¡¡é‡åŠŸèƒ½æ­£ç¡®æ€§çš„ä¸€ä¸ªå¾ˆå¥½çš„æŒ‡æ ‡ï¼Œæˆ‘ä»¬ç¡®å®éœ€è¦è¿™ç§æ–°ç±»å‹çš„æŒ‡æ ‡å’Œè¿™ä¸ªæ–°çš„æ•°æ®é›†ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_33.png)
- en: So now let's explore the setting where in passec K is greater than oneã€‚And so
    the first observation we have here is that the temperature that you sample at
    it affects your pass I and just for some intuitionã€‚if you do temperature zero
    samplingï¼Œ you're going to get the same sample every single time you're doing artifact
    sampling so it doesn't matter like how many samples you generate you're just going
    to get the same pass rate but if you want to generate 100 samples right you can
    afford to make some mistakes right you just want a very diverse set of samplesã€‚
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ¢ç´¢Kå¤§äº1çš„è®¾ç½®ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œçš„ç¬¬ä¸€ä¸ªè§‚å¯Ÿæ˜¯ï¼Œæ‚¨é‡‡æ ·æ—¶çš„æ¸©åº¦ä¼šå½±å“æ‚¨çš„é€šè¿‡ç‡ï¼Œä»…ä¾›ç›´è§‚å‚è€ƒã€‚å¦‚æœæ‚¨è¿›è¡Œæ¸©åº¦ä¸ºé›¶çš„é‡‡æ ·ï¼Œæ‚¨å°†æ¯æ¬¡éƒ½è·å¾—ç›¸åŒçš„æ ·æœ¬ï¼Œæ‚¨åœ¨è¿›è¡Œä¼ªé€ é‡‡æ ·æ—¶ã€‚å› æ­¤ï¼Œæ— è®ºç”Ÿæˆå¤šå°‘æ ·æœ¬ï¼Œæ‚¨åªä¼šè·å¾—ç›¸åŒçš„é€šè¿‡ç‡ï¼Œä½†å¦‚æœæ‚¨æƒ³ç”Ÿæˆ100ä¸ªæ ·æœ¬ï¼Œæ‚¨å¯ä»¥æ‰¿å—ä¸€äº›é”™è¯¯ï¼Œæ‚¨åªæƒ³è¦ä¸€ä¸ªéå¸¸å¤šæ ·åŒ–çš„æ ·æœ¬é›†ã€‚
- en: So you can up the temperatureï¼Œ in can see kind of as you up the temperatureã€‚the
    slope of the kind of number of samples against pass weightï¼Œ it becomes steepã€‚And
    so you can kind of take the upper hole of this and you can find the optimal temperature
    for each number of samplesã€‚And so this brings me to personally my favorite result
    of the paperã€‚
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¯ä»¥æé«˜æ¸©åº¦ï¼Œä½ å¯ä»¥çœ‹åˆ°éšç€ä½ æé«˜æ¸©åº¦ï¼Œæ ·æœ¬æ•°é‡ä¸é€šè¿‡æƒé‡ä¹‹é—´çš„æ–œç‡å˜å¾—é™¡å³­ã€‚å› æ­¤ä½ å¯ä»¥å¤§è‡´å–ä¸Šé¢çš„è¿™ä¸€éƒ¨åˆ†ï¼Œæ‰¾åˆ°æ¯ä¸ªæ ·æœ¬æ•°é‡çš„æœ€ä½³æ¸©åº¦ã€‚è¿™è®©æˆ‘ä¸ªäººå¾—å‡ºè¿™ç¯‡è®ºæ–‡ä¸­æˆ‘æœ€å–œæ¬¢çš„ç»“æœã€‚
- en: which I call the unreasonable effectiveness of samplingã€‚And so let me explain
    what's going on here because this is the number of parameters in the model and
    here you have pass rate at one and a pass rate at 100ã€‚And the reason I use this
    term unreasonable effectiveness is that I think there's a world where if the orange
    line and the blend weren't that far apartã€‚I might not be that surprised like at
    these scales the model it rarely makes kind of syntactical errors anymore like
    if you run it ill run and produce some kind of output so you could imagine a world
    where basically what you're the model has some approach in mind is just repeatedly
    sampling that approach and it it's just either right or wrongã€‚
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç§°ä¹‹ä¸ºé‡‡æ ·çš„ä¸åˆç†æœ‰æ•ˆæ€§ã€‚æ‰€ä»¥è®©æˆ‘è§£é‡Šä¸€ä¸‹è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆï¼Œå› ä¸ºè¿™æ˜¯æ¨¡å‹ä¸­çš„å‚æ•°æ•°é‡ï¼Œè€Œè¿™é‡Œä½ æœ‰åœ¨ä¸€ä¸ªçš„é€šè¿‡ç‡å’Œåœ¨100çš„é€šè¿‡ç‡ã€‚æˆ‘ä¹‹æ‰€ä»¥ä½¿ç”¨è¿™ä¸ªâ€œä¸åˆç†æœ‰æ•ˆæ€§â€è¿™ä¸ªæœ¯è¯­ï¼Œæ˜¯å› ä¸ºæˆ‘è®¤ä¸ºåœ¨ä¸€ä¸ªä¸–ç•Œé‡Œï¼Œå¦‚æœæ©™è‰²çº¿å’Œæ··åˆä¹‹é—´æ²¡æœ‰é‚£ä¹ˆå¤§çš„å·®è·ï¼Œæˆ‘å¯èƒ½ä¸ä¼šæ„Ÿåˆ°é‚£ä¹ˆæƒŠè®¶ï¼›åœ¨è¿™äº›å°ºåº¦ä¸Šï¼Œæ¨¡å‹å¾ˆå°‘å†çŠ¯ä¸€äº›è¯­æ³•é”™è¯¯äº†ï¼Œæ¯”å¦‚å¦‚æœä½ è¿è¡Œå®ƒï¼Œå®ƒä¼šäº§ç”ŸæŸç§è¾“å‡ºï¼Œå› æ­¤ä½ å¯ä»¥æƒ³è±¡ä¸€ä¸ªä¸–ç•Œï¼ŒåŸºæœ¬ä¸Šæ¨¡å‹å¿ƒä¸­æœ‰æŸç§æ–¹æ³•ï¼Œåªæ˜¯åå¤é‡‡æ ·è¿™ç§æ–¹æ³•ï¼Œè€Œå®ƒè¦ä¹ˆæ˜¯æ­£ç¡®çš„ï¼Œè¦ä¹ˆæ˜¯é”™è¯¯çš„ã€‚
- en: but instead we find is that the model is actually composing different parts
    and producing functionally different thingsã€‚And you get this huge boost from under
    30% to over 70%ã€‚just by sampling a lot of samples from the modelã€‚So unfortunatelyã€‚knowing
    that one of your samples is correctï¼Œ isn't that useful if you don't haveã€‚
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬å‘ç°æ¨¡å‹å®é™…ä¸Šæ˜¯åœ¨ç»„åˆä¸åŒçš„éƒ¨åˆ†ï¼Œäº§ç”ŸåŠŸèƒ½ä¸Šä¸åŒçš„ä¸œè¥¿ã€‚é€šè¿‡ä»æ¨¡å‹ä¸­é‡‡æ ·å¤§é‡æ ·æœ¬ï¼Œä½ ä¼šçœ‹åˆ°ä»ä¸åˆ°30%çš„æå‡åˆ°è¶…è¿‡70%ã€‚æ‰€ä»¥ä¸å¹¸çš„æ˜¯ï¼ŒçŸ¥é“ä½ çš„ä¸€ä¸ªæ ·æœ¬æ˜¯æ­£ç¡®çš„ï¼Œå¦‚æœä½ æ²¡æœ‰å…¶ä»–ä¸œè¥¿ï¼Œé‚£å¹¶ä¸æ˜¯å¾ˆæœ‰ç”¨ã€‚
- en: Access to the unit test and one setting where practical setting where you would
    care about this is see you're creating an autocomplete tool right and you generate
    100 samples but you don't want to show your user 100 samples and help them pick
    one right you want to kind of try to pre filterter but you don't have unit tests
    so can we kind of approximate this oracle sampling with some other ranking heuristicã€‚
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: è®¿é—®å•å…ƒæµ‹è¯•ï¼Œè€Œä¸€ä¸ªä½ å…³å¿ƒçš„å®é™…è®¾ç½®å°±æ˜¯ï¼Œä½ æ­£åœ¨åˆ›å»ºä¸€ä¸ªè‡ªåŠ¨è¡¥å…¨å·¥å…·ï¼Œå¯¹å§ï¼Œä½ ç”Ÿæˆäº†100ä¸ªæ ·æœ¬ï¼Œä½†ä½ ä¸æƒ³å‘ç”¨æˆ·å±•ç¤º100ä¸ªæ ·æœ¬å¹¶å¸®åŠ©ä»–ä»¬é€‰æ‹©ä¸€ä¸ªæ­£ç¡®çš„ï¼Œä½ æƒ³å°è¯•é¢„ç­›é€‰ï¼Œä½†ä½ æ²¡æœ‰å•å…ƒæµ‹è¯•ï¼Œæ‰€ä»¥æˆ‘ä»¬èƒ½å¦ç”¨ä¸€äº›å…¶ä»–çš„æ’åå¯å‘å¼æ–¹æ³•æ¥è¿‘ä¼¼è¿™ç§oracleé‡‡æ ·ã€‚
- en: So here I'm showing a couple of different heuristics like you randomly pick
    oneã€‚but the one that seemsã€‚Most promising is to rank by me in that probability
    and it's I know it's like kind of maybe not theoretical we walk around itã€‚but
    in language this kind of heuristic is fairly strong as wellã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_35.png)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨è¿™é‡Œæˆ‘å±•ç¤ºäº†å‡ ç§ä¸åŒçš„å¯å‘å¼æ–¹æ³•ï¼Œæ¯”å¦‚éšæœºé€‰æ‹©ä¸€ä¸ªã€‚ä½†ä¼¼ä¹æœ€æœ‰å‰æ™¯çš„æ˜¯æ ¹æ®æ¦‚ç‡è¿›è¡Œæ’åï¼Œæˆ‘çŸ¥é“è¿™å¯èƒ½ä¸å¤ªç†è®ºåŒ–ï¼Œä½†åœ¨è¯­è¨€æ–¹é¢ï¼Œè¿™ç§å¯å‘å¼æ–¹æ³•ä¹Ÿæ˜¯ç›¸å½“å¼ºçš„ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_35.png)
- en: So recall that what we're doing is we have this evaluation set where we have
    kind of standalone functionsã€‚we want to produce solutions to themã€‚But when we're
    doing training there's a lot of code that isn't relevant for this taskã€‚for instance
    there's a lot of classes that we're seeing there's actually data classes too which
    aren't relevant at all and actually there's a lot of incorrect food on GitHub
    too so we might be modeling incorrect solutions as well as correct onesã€‚Soã€‚ğŸ˜Šï¼ŒOne
    thing we thought was let's finet codex further on a couple of data sets where
    they are standalone functions and you have kind of more guaranteed correct solutions
    to thatã€‚
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å›æƒ³ä¸€ä¸‹æˆ‘ä»¬æ‰€åšçš„äº‹æƒ…ï¼Œæˆ‘ä»¬æœ‰è¿™ä¸ªè¯„ä¼°é›†ï¼Œå…¶ä¸­æœ‰ä¸€äº›ç‹¬ç«‹çš„å‡½æ•°ã€‚æˆ‘ä»¬æƒ³ä¸ºå®ƒä»¬ç”Ÿæˆè§£å†³æ–¹æ¡ˆã€‚ä½†åœ¨æˆ‘ä»¬è¿›è¡Œè®­ç»ƒæ—¶ï¼Œæœ‰å¾ˆå¤šä»£ç ä¸è¿™ä¸ªä»»åŠ¡æ— å…³ã€‚ä¾‹å¦‚ï¼Œæœ‰å¾ˆå¤šç±»æˆ‘ä»¬çœ‹åˆ°å®é™…ä¸Šä¹Ÿæ˜¯æ•°æ®ç±»ï¼Œè¿™äº›ç±»å®Œå…¨ä¸ç›¸å…³ï¼Œå®é™…ä¸ŠGitHubä¸Šè¿˜æœ‰å¾ˆå¤šé”™è¯¯çš„ä»£ç ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯èƒ½åœ¨å»ºæ¨¡é”™è¯¯çš„è§£å†³æ–¹æ¡ˆä»¥åŠæ­£ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚å› æ­¤ï¼ŒğŸ˜Šï¼Œæˆ‘ä»¬æƒ³åˆ°çš„ä¸€ä»¶äº‹æ˜¯è¿›ä¸€æ­¥å¾®è°ƒCodexï¼Œåœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè¿™äº›æ•°æ®é›†æ˜¯ç‹¬ç«‹çš„å‡½æ•°ï¼Œå¹¶ä¸”ä½ æœ‰æ›´ä¿è¯çš„æ­£ç¡®è§£å†³æ–¹æ¡ˆã€‚
- en: So what we did was we found these problems from a couple of sourcesã€‚So one is
    competitive programming problemsã€‚ You can kind of go on these sitesã€‚oftentimesã€‚they'll
    just give you the unit testã€‚Sometimes when they don't give you the unit testã€‚you
    can submit incorrect solutions and they'll tell you the first one you failed on
    and kind of keep it certainã€‚
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬æ‰¾åˆ°è¿™äº›é—®é¢˜æ¥è‡ªå‡ ä¸ªæ¥æºã€‚å…¶ä¸­ä¸€ä¸ªæ˜¯ç«äº‰ç¼–ç¨‹é—®é¢˜ã€‚ä½ å¯ä»¥å»è¿™äº›ç½‘ç«™ï¼Œé€šå¸¸ä»–ä»¬ä¼šç»™ä½ å•å…ƒæµ‹è¯•ã€‚æœ‰æ—¶ä»–ä»¬ä¸æä¾›å•å…ƒæµ‹è¯•ï¼Œä½ å¯ä»¥æäº¤é”™è¯¯çš„è§£å†³æ–¹æ¡ˆï¼Œä»–ä»¬ä¼šå‘Šè¯‰ä½ ç¬¬ä¸€ä¸ªå¤±è´¥çš„åœ°æ–¹ï¼Œå¹¶ç»§ç»­åé¦ˆã€‚
- en: Yes so you can get a lot of competitive programming problems and another source
    is projects where continuous integration is enabled so why aren are these useful
    because you can actually kind of do an execution tracing so when you run the integration
    test you can get all the inputs to functions that are called and their outputs
    as well and so you actually have the true function body you know what the test
    output is supposed to be so you know kind of the ground truth inputs and outputã€‚
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ‰€ä»¥ä½ å¯ä»¥è·å–å¾ˆå¤šç«äº‰ç¼–ç¨‹é—®é¢˜ï¼Œå¦ä¸€ä¸ªæ¥æºæ˜¯å¯ç”¨æŒç»­é›†æˆçš„é¡¹ç›®ã€‚è¿™äº›ä¸ºä»€ä¹ˆæœ‰ç”¨ï¼Ÿå› ä¸ºä½ å¯ä»¥è¿›è¡Œæ‰§è¡Œè·Ÿè¸ªï¼Œå½“ä½ è¿è¡Œé›†æˆæµ‹è¯•æ—¶ï¼Œå¯ä»¥è·å–æ‰€æœ‰è°ƒç”¨å‡½æ•°çš„è¾“å…¥å’Œè¾“å‡ºï¼Œä½ å®é™…ä¸Šæ‹¥æœ‰çœŸå®çš„å‡½æ•°ä½“ï¼ŒçŸ¥é“æµ‹è¯•è¾“å‡ºåº”è¯¥æ˜¯ä»€ä¹ˆï¼Œæ‰€ä»¥ä½ äº†è§£çœŸæ­£çš„è¾“å…¥å’Œè¾“å‡ºã€‚
- en: ğŸ˜Šï¼ŒAnd these are kind of like two orthogonal data setsã€‚one kind of helps you
    with like algorithmic kind of tasks and one is more kind of like trying I manipulate
    command line utilities and tasks like thatã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_37.png)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šè¿™äº›å°±åƒæ˜¯ä¸¤ä¸ªæ­£äº¤æ•°æ®é›†ã€‚ä¸€ä¸ªæœ‰åŠ©äºç®—æ³•ä»»åŠ¡ï¼Œå¦ä¸€ä¸ªæ›´åƒæ˜¯å°è¯•æ“ä½œå‘½ä»¤è¡Œå·¥å…·å’Œä»»åŠ¡ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_37.png)
- en: So this brings us to the main figure of the codetex paperã€‚so really what we're
    seeing is a progression of capabilities so with G3 on this human eval data set
    the password rate at one is zero basically you can generate like one or two lines
    coherently never really a whole program coherentlyã€‚
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¼•å‡ºäº†codetexè®ºæ–‡çš„ä¸»è¦å†…å®¹ã€‚æ‰€ä»¥æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯èƒ½åŠ›çš„è¿›å±•ï¼Œåœ¨è¿™ä¸ªäººç±»è¯„ä¼°æ•°æ®é›†ä¸­ï¼ŒG3çš„å¯†ç ç‡åŸºæœ¬ä¸Šä¸ºé›¶ï¼ŒåŸºæœ¬ä¸Šä½ åªèƒ½è¿è´¯åœ°ç”Ÿæˆä¸€ä¸¤è¡Œï¼Œæ ¹æœ¬æ— æ³•ç”Ÿæˆå®Œæ•´çš„ç¨‹åºã€‚
- en: Now when you fine tune on codeï¼Œ which is Codexï¼Œ this orange lineã€‚you start to
    see some kind of knowledgeable performance on this data setã€‚When you do this additional
    supervised flight training that's this green lineã€‚you get even better password
    ratess and then if you kind of generate 100 samples from this model rerank with
    mean log Pã€‚
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå½“ä½ åœ¨ä»£ç ä¸Šè¿›è¡Œå¾®è°ƒæ—¶ï¼Œå°±æ˜¯Codexï¼Œè¿™æ¡æ©™çº¿ã€‚ä½ å¼€å§‹åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šçœ‹åˆ°ä¸€äº›æœ‰çŸ¥è¯†çš„è¡¨ç°ã€‚å½“ä½ è¿›è¡Œé¢å¤–çš„ç›‘ç£è®­ç»ƒæ—¶ï¼Œå°±æ˜¯è¿™æ¡ç»¿è‰²çº¿ã€‚ä½ ä¼šå¾—åˆ°æ›´å¥½çš„å¯†ç ç‡ï¼Œå¦‚æœä½ ä»è¿™ä¸ªæ¨¡å‹ç”Ÿæˆ100ä¸ªæ ·æœ¬å¹¶ä½¿ç”¨å¹³å‡å¯¹æ•°Pè¿›è¡Œé‡æ–°æ’åã€‚
- en: even better password ratessï¼Œ and finallyï¼Œ of course if you have access to an
    Oracleã€‚it gives you the best pass ratesã€‚Some one question here is can you actually
    use a deep link to like like further to the model can you use it for like as a
    backdrop signal Yeahã€‚
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ç”šè‡³æ›´å¥½çš„å¯†ç ç‡ï¼Œæœ€åï¼Œå¦‚æœä½ æœ‰è®¿é—®Oracleçš„æƒé™ï¼Œå®ƒä¼šç»™ä½ æœ€ä½³çš„é€šè¿‡ç‡ã€‚æœ‰ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œä½ æ˜¯å¦å¯ä»¥ä½¿ç”¨æ·±åº¦é“¾æ¥ï¼Œæ¯”å¦‚è¿›ä¸€æ­¥è¿æ¥æ¨¡å‹ï¼Œæ˜¯å¦å¯ä»¥ç”¨ä½œèƒŒæ™¯ä¿¡å·ï¼Ÿæ˜¯çš„ã€‚
- en: yeahï¼Œ so we do you spoil that I don't know if I can say too much about these
    results got it but yeahã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_39.png)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¹æ­¤æœ‰æ‰€äº†è§£ï¼Œæˆ‘ä¸çŸ¥é“æˆ‘æ˜¯å¦å¯ä»¥å¤šè¯´è¿™äº›ç»“æœï¼Œä½†ç¡®å®å¦‚æ­¤ã€‚![](img/542291b724ae1b1a3bd31a38e9d3acdc_39.png)
- en: And finally I don't want to suggest that these models are perfectã€‚they have
    a lot of limitations that human programmers don't run into so one is like actually
    all generative models are autoaggressive geneative models kind of have some problems
    with binding so when there's like a lot of variables going on like a lot of operations
    going on sometimes it's like hard to figure out which operation is finding to
    which variable so you can kind of see some examples of that on the left and one
    other kind of counterintuitive behavior is composition so we can take a bunch
    of very simple building blocks like take a string and reverse it or like delete
    every pre third character or something and a human like if you can chain two of
    these operations you could probably chain n of them but our models aren't to do
    that yetã€‚
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä¸æƒ³æš—ç¤ºè¿™äº›æ¨¡å‹æ˜¯å®Œç¾çš„ã€‚å®ƒä»¬æœ‰å¾ˆå¤šäººç±»ç¨‹åºå‘˜ä¸ä¼šé‡åˆ°çš„é™åˆ¶ï¼Œæ¯”å¦‚å®é™…ä¸Šæ‰€æœ‰ç”Ÿæˆæ¨¡å‹éƒ½æ˜¯è‡ªå›å½’ç”Ÿæˆæ¨¡å‹ï¼Œæœ‰ä¸€äº›ç»‘å®šé—®é¢˜ã€‚å½“å˜é‡å¾ˆå¤šã€æ“ä½œå¾ˆå¤šæ—¶ï¼Œæœ‰æ—¶å¾ˆéš¾å¼„æ¸…å“ªä¸ªæ“ä½œç»‘å®šåˆ°å“ªä¸ªå˜é‡ï¼Œä½ å¯ä»¥åœ¨å·¦ä¾§çœ‹åˆ°ä¸€äº›ä¾‹å­ã€‚å¦ä¸€ä¸ªåç›´è§‰çš„è¡Œä¸ºæ˜¯ç»„åˆï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€äº›éå¸¸ç®€å•çš„æ„å»ºå—ï¼Œæ¯”å¦‚åè½¬ä¸€ä¸ªå­—ç¬¦ä¸²æˆ–åˆ é™¤æ¯ç¬¬ä¸‰ä¸ªå­—ç¬¦ï¼Œåƒäººç±»ä¸€æ ·ï¼Œå¦‚æœä½ å¯ä»¥é“¾æ¥è¿™ä¸¤ç§æ“ä½œï¼Œä½ å¯èƒ½å¯ä»¥é“¾æ¥nä¸ªï¼Œä½†æˆ‘ä»¬çš„æ¨¡å‹è¿˜åšä¸åˆ°è¿™ä¸€ç‚¹ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_41.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_41.png)'
- en: Coolï¼Œ so moving on to the conclusionï¼Œ we have four main points in today's talkã€‚so
    first progress in neural language modeling has been fairly rapidã€‚And at GTã€‚it
    wasn't the result of a push on language modeling and more a result of work on
    pushing unsupervised learning in languageã€‚The third point is that autoaggressive
    modeling is universal and it can yield strong results even when there are strong
    inive biases like in images or in text imagesã€‚
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆé…·ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬è¿›å…¥ç»“è®ºï¼Œä»Šå¤©çš„è®²åº§æœ‰å››ä¸ªä¸»è¦è§‚ç‚¹ã€‚é¦–å…ˆï¼Œç¥ç»è¯­è¨€å»ºæ¨¡çš„è¿›å±•éå¸¸è¿…é€Ÿã€‚åœ¨GTï¼Œè¿™ä¸æ˜¯è¯­è¨€å»ºæ¨¡çš„æ¨åŠ¨ç»“æœï¼Œè€Œæ˜¯æ¨åŠ¨æ— ç›‘ç£å­¦ä¹ åœ¨è¯­è¨€ä¸­çš„å·¥ä½œçš„ç»“æœã€‚ç¬¬ä¸‰ç‚¹æ˜¯è‡ªå›å½’å»ºæ¨¡æ˜¯æ™®éçš„ï¼Œå³ä½¿åœ¨å­˜åœ¨å¼ºçƒˆçš„åè§ï¼ˆå¦‚å›¾åƒæˆ–æ–‡æœ¬å›¾åƒï¼‰æ—¶ï¼Œå®ƒä¹Ÿèƒ½äº§ç”Ÿå¼ºå¤§çš„ç»“æœã€‚
- en: And finallyï¼Œ we can produce strong co generatingrating models like fine tuneing
    GPT for young codeã€‚And as sampling is an unreasonably effective way to improve
    model performanceã€‚Cool now to end with some acknowledgeknowmentsï¼Œ I want to thank
    my CodeX primary coauorsã€‚some mentors at Open AI and the algorithms team which
    I've worked very closely with great thank you guys for your attentionã€‚
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆå¼ºå¤§çš„å…±åŒç”Ÿæˆæ¨¡å‹ï¼Œæ¯”å¦‚å¾®è°ƒGPTä»¥é€‚åº”å¹´è½»çš„ä»£ç ã€‚é‡‡æ ·æ˜¯ä¸€ç§å¼‚å¸¸æœ‰æ•ˆçš„æé«˜æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ã€‚å¾ˆé…·ï¼Œç°åœ¨ä»¥ä¸€äº›æ„Ÿè°¢æ¥ç»“æŸï¼Œæˆ‘æƒ³æ„Ÿè°¢æˆ‘çš„CodeXä¸»è¦åˆä½œè€…ï¼Œä»¥åŠåœ¨OpenAIçš„ä¸€äº›å¯¼å¸ˆå’Œæˆ‘å¯†åˆ‡åˆä½œçš„ç®—æ³•å›¢é˜Ÿï¼Œæ„Ÿè°¢ä½ ä»¬çš„å…³æ³¨ã€‚
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_43.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_43.png)'
- en: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_44.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/542291b724ae1b1a3bd31a38e9d3acdc_44.png)'
