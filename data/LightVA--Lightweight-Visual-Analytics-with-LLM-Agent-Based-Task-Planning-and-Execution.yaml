- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 11:58:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:58:05
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LightVA：基于 LLM 代理的轻量级可视分析与任务规划与执行
- en: 来源：[https://arxiv.org/html/2411.05651/](https://arxiv.org/html/2411.05651/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2411.05651/](https://arxiv.org/html/2411.05651/)
- en: \mdfsetup
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \mdfsetup
- en: skipabove=1em,skipbelow=0em
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: skipabove=1em,skipbelow=0em
- en: Yuheng Zhao, Junjie Wang, Linbin Xiang, Xiaowen Zhang, Zifei Guo,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Yuheng Zhao、Junjie Wang、Linbin Xiang、Xiaowen Zhang、Zifei Guo
- en: 'Cagatay Turkay, Yu Zhang and Siming Chen Yuheng Zhao, Junjie Wang, Linbin Xiang,
    Xiaowen Zhang, Zifei Guo, Siming Chen are with School of Data Science, Fudan University.
    E-mail: {yuhengzhao, simingchen}@fudan.edu.cn. Siming Chen is the corresponding
    author.Cagatay Turkay is with the Centre for Interdisciplinary Methodologies,
    University of Warwick. E-mail: Cagatay.Turkay@warwick.ac.uk.Yu Zhang is with Department
    of Computer Science, University of Oxford. E-mail: yuzhang94@outlook.com. Manuscript
    received April 19, 2005; revised August 26, 2015.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Cagatay Turkay、Yu Zhang 和 Siming Chen Yuheng Zhao、Junjie Wang、Linbin Xiang、Xiaowen
    Zhang、Zifei Guo、Siming Chen 均来自复旦大学数据科学学院。电子邮件：{yuhengzhao, simingchen}@fudan.edu.cn。Siming
    Chen 为通讯作者。Cagatay Turkay 来自华威大学跨学科方法学中心。电子邮件：Cagatay.Turkay@warwick.ac.uk。Yu
    Zhang 来自牛津大学计算机科学系。电子邮件：yuzhang94@outlook.com。手稿接收于 2005 年 4 月 19 日，修订于 2015 年
    8 月 26 日。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Visual analytics (VA) requires analysts to iteratively propose analysis tasks
    based on observations and execute tasks by creating visualizations and interactive
    exploration to gain insights. This process demands skills in programming, data
    processing, and visualization tools, highlighting the need for a more intelligent,
    streamlined VA approach. Large language models (LLMs) have recently been developed
    as agents to handle various tasks with dynamic planning and tool-using capabilities,
    offering the potential to enhance the efficiency and versatility of VA. We propose
    LightVA, a lightweight VA framework that supports task decomposition, data analysis,
    and interactive exploration through human-agent collaboration. Our method is designed
    to help users progressively translate high-level analytical goals into low-level
    tasks, producing visualizations and deriving insights. Specifically, we introduce
    an LLM agent-based task planning and execution strategy, employing a recursive
    process involving a planner, executor, and controller. The planner is responsible
    for recommending and decomposing tasks, the executor handles task execution, including
    data analysis, visualization generation and multi-view composition, and the controller
    coordinates the interaction between the planner and executor. Building on the
    framework, we develop a system with a hybrid user interface that includes a task
    flow diagram for monitoring and managing the task planning process, a visualization
    panel for interactive data exploration, and a chat view for guiding the model
    through natural language instructions. We examine the effectiveness of our method
    through a usage scenario and an expert study.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 可视分析（VA）要求分析师根据观察结果反复提出分析任务，并通过创建可视化和互动探索来执行任务，以获取洞察。这一过程需要编程、数据处理和可视化工具的技能，凸显了需要一种更智能、更精简的
    VA 方法。近年来，大型语言模型（LLM）被开发为代理，能够处理具有动态规划和工具使用能力的各种任务，从而有潜力提高 VA 的效率和多样性。我们提出了 LightVA，这是一种支持任务分解、数据分析和通过人机协作进行互动探索的轻量级
    VA 框架。我们的方法旨在帮助用户将高层次的分析目标逐步转化为低层次的任务，生成可视化并得出洞察。具体而言，我们引入了一种基于 LLM 代理的任务规划与执行策略，采用递归过程，包括规划者、执行者和控制者。规划者负责推荐和分解任务，执行者负责执行任务，包括数据分析、可视化生成和多视图组合，控制者协调规划者与执行者之间的互动。在此框架基础上，我们开发了一个包含混合用户界面的系统，其中包括一个用于监控和管理任务规划过程的任务流图，一个用于交互式数据探索的可视化面板，以及一个用于通过自然语言指令引导模型的聊天视图。我们通过使用场景和专家研究来检验我们方法的有效性。
- en: 'Index Terms:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Visual Analytics, Task Planning, Large Language Model Agent, Mixed-Initiative
    Interaction
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可视分析、任务规划、大型语言模型代理、混合主动交互
- en: I Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: 'Visual analytics (VA) deciphers complex datasets with data mining and interactive
    visualizations [[1](https://arxiv.org/html/2411.05651v1#bib.bib1), [2](https://arxiv.org/html/2411.05651v1#bib.bib2)].
    However, building and using a VA system can be a costly endeavor that encompasses
    several main stages: goal understanding, task decomposition, data modeling, and
    visualization creation to discover insights. A key challenge is that this process
    is iterative, requiring continual refinement based on evolving needs [[3](https://arxiv.org/html/2411.05651v1#bib.bib3)].
    Different tasks necessitate various data analysis and visualization methods to
    form a VA system. While using the system, tasks may evolve based on the insights
    gained, necessitating ongoing iterations until the analytical goals are achieved [[4](https://arxiv.org/html/2411.05651v1#bib.bib4)].
    Consider a scenario where the goal is to identify high-risk events from social
    media data. Users may first need an overview from different perspectives, such
    as the distribution of keywords over time or changes in sentiment for risk analysis.
    If outliers are identified, users may need further details, such as spatial distribution
    or entity relationships. In this process, the task space is broad and fluid, requiring
    efficient task planning and method implementation.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可视分析（VA）通过数据挖掘和交互式可视化解读复杂数据集[[1](https://arxiv.org/html/2411.05651v1#bib.bib1),
    [2](https://arxiv.org/html/2411.05651v1#bib.bib2)]。然而，构建和使用VA系统可能是一个昂贵的过程，涉及几个主要阶段：目标理解、任务分解、数据建模和可视化创建以发现洞察。一个关键挑战是，这个过程是迭代性的，需要根据不断变化的需求进行持续的完善[[3](https://arxiv.org/html/2411.05651v1#bib.bib3)]。不同的任务需要不同的数据分析和可视化方法来形成一个VA系统。在使用该系统时，任务可能会根据获得的洞察而发生变化，这需要不断的迭代，直到达成分析目标[[4](https://arxiv.org/html/2411.05651v1#bib.bib4)]。考虑一个情境，其中目标是从社交媒体数据中识别高风险事件。用户可能首先需要从不同的视角获得概览，比如关键词随时间的分布或风险分析中情感的变化。如果识别出异常值，用户可能需要更多的细节，比如空间分布或实体关系。在这个过程中，任务空间广泛且流动，需要高效的任务规划和方法实施。
- en: Recent research focuses on data-driven or natural language-based visual data
    exploration, with an emphasis on automatic visualization generation [[5](https://arxiv.org/html/2411.05651v1#bib.bib5),
    [6](https://arxiv.org/html/2411.05651v1#bib.bib6)] or insight mining [[7](https://arxiv.org/html/2411.05651v1#bib.bib7),
    [8](https://arxiv.org/html/2411.05651v1#bib.bib8)]. Large Language Models (LLMs)
    present a potential for data analysis, supporting dynamic task planning and lower
    development costs across various scenarios. The reasoning abilities that enable
    autonomous planning and execution of analytical tasks [[9](https://arxiv.org/html/2411.05651v1#bib.bib9),
    [10](https://arxiv.org/html/2411.05651v1#bib.bib10), [11](https://arxiv.org/html/2411.05651v1#bib.bib11)],
    while code generation capability support creating insightful visualizations efficiently [[12](https://arxiv.org/html/2411.05651v1#bib.bib12),
    [13](https://arxiv.org/html/2411.05651v1#bib.bib13), [14](https://arxiv.org/html/2411.05651v1#bib.bib14)].
    Additionally, their broad knowledge base makes LLMs versatile tools capable of
    adapting to diverse data analysis contexts [[15](https://arxiv.org/html/2411.05651v1#bib.bib15),
    [16](https://arxiv.org/html/2411.05651v1#bib.bib16)]. LEVA [[17](https://arxiv.org/html/2411.05651v1#bib.bib17)]
    integrates LLMs in VA systems to recommend insights for a given task but still
    cannot generate visualization and data modeling methods adapted to tasks. There
    is a lack of approaches supporting task planning, VA methods implementation, and
    interactive analysis with human-agent collaboration.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究集中于数据驱动或基于自然语言的视觉数据探索，重点在于自动化可视化生成[[5](https://arxiv.org/html/2411.05651v1#bib.bib5),
    [6](https://arxiv.org/html/2411.05651v1#bib.bib6)] 或洞察挖掘[[7](https://arxiv.org/html/2411.05651v1#bib.bib7),
    [8](https://arxiv.org/html/2411.05651v1#bib.bib8)]。大型语言模型（LLMs）展现了在数据分析中的潜力，支持动态任务规划，并在各种场景中降低开发成本。赋能自主规划和执行分析任务的推理能力[[9](https://arxiv.org/html/2411.05651v1#bib.bib9),
    [10](https://arxiv.org/html/2411.05651v1#bib.bib10), [11](https://arxiv.org/html/2411.05651v1#bib.bib11)]，同时代码生成能力支持高效创建有洞察力的可视化[[12](https://arxiv.org/html/2411.05651v1#bib.bib12),
    [13](https://arxiv.org/html/2411.05651v1#bib.bib13), [14](https://arxiv.org/html/2411.05651v1#bib.bib14)]。此外，它们广泛的知识库使得LLMs成为多功能工具，能够适应不同的数据分析场景[[15](https://arxiv.org/html/2411.05651v1#bib.bib15),
    [16](https://arxiv.org/html/2411.05651v1#bib.bib16)]。LEVA[[17](https://arxiv.org/html/2411.05651v1#bib.bib17)]
    将LLMs集成到VA系统中，以推荐给定任务的洞察，但仍无法生成适应任务的可视化和数据建模方法。目前缺乏支持任务规划、VA方法实施和人与智能体协作的交互式分析的方法。
- en: 'This paper introduces LightVA, a lightweight VA framework with agent-based
    task planning. The term “lightweight” refers to the framework’s focus on reducing
    the cost of development and using VA systems. Using LLM agents to aid the task
    planning and execution process. The framework builds upon multi-level relationships,
    translating high-level goals to low-level tasks and deriving insights through
    data mining and interactive visualizations. Specifically, the framework employs
    a recursive process that includes a planner, executor, and controller, which dynamically
    accommodates task complexity. The planner is responsible for task decomposition,
    the executor handles task execution, including visualization generation and data
    analysis, and the controller orchestrates the executor and planner and manages
    whether tasks continue to be decomposed. We develop a system based on the framework
    that provides a chat view to support communication among users and agents, a task
    flow view to visualize manage the process of task planning, a visualization panel
    to show single view and multiple linked views connected to the task flow. Our
    main contributions are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了 LightVA，一个具有基于代理的任务规划的轻量级 VA 框架。术语“轻量级”指的是该框架侧重于减少开发成本和 VA 系统的使用成本。通过使用
    LLM 代理来辅助任务规划和执行过程。该框架基于多层次关系，将高层次目标转化为低层次任务，并通过数据挖掘和交互式可视化来得出洞察。具体而言，该框架采用递归过程，包括规划器、执行器和控制器，动态适应任务复杂性。规划器负责任务分解，执行器处理任务执行，包括可视化生成和数据分析，而控制器则协调执行器和规划器，管理任务是否继续分解。我们开发了一个基于该框架的系统，提供聊天视图以支持用户与代理之间的沟通，任务流视图以可视化管理任务规划过程，和可视化面板以展示单一视图和与任务流连接的多个联动视图。我们的主要贡献如下：
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We propose a lightweight VA framework using LLM agent-based task planning and
    execution. This approach enables adaptive, efficient analysis through human-agent
    collaboration, supporting users in task decomposition, visualization, and insight
    discovery.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一个轻量级的 VA 框架，采用基于 LLM 代理的任务规划与执行。该方法通过人类与代理的协作，实现了适应性强且高效的分析，帮助用户进行任务分解、可视化和洞察发现。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We develop a system that embodies our framework, supporting users to analyze
    data with the assistance of agents and communicate through the hybrid user interface.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们开发了一个体现该框架的系统，支持用户在代理的帮助下分析数据，并通过混合用户界面进行沟通。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We demonstrate the effectiveness of the system through a usage scenario and
    an expert study.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过使用场景和专家研究展示了该系统的有效性。
- en: II Related Work
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 相关工作
- en: Our research is related to prior studies on visualization recommendations, task-driven
    data exploration, and LLM application in data exploration.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究与之前的可视化推荐、任务驱动的数据探索以及 LLM 在数据探索中的应用相关。
- en: II-A Visualization Recommendation
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 可视化推荐
- en: Visualization authoring typically requires users to have professional visualization
    knowledge and programming ability. For example, tools like Tableau support creating
    visualizations and multiple linked views with shelf-configuration design, offering
    robust visualization creation features. However, while Tableau excels as an authoring
    tool, it offers limited support for automatic task decomposition and VA method
    implementation to further assist with analysis. A corpus of research has been
    proposed on automatic visualization recommendations [[18](https://arxiv.org/html/2411.05651v1#bib.bib18),
    [19](https://arxiv.org/html/2411.05651v1#bib.bib19), [20](https://arxiv.org/html/2411.05651v1#bib.bib20)].
    Rule-based methods, such as Voyager [[21](https://arxiv.org/html/2411.05651v1#bib.bib21)]
    and CompassQL [[22](https://arxiv.org/html/2411.05651v1#bib.bib22)], utilize the
    visualization principles to construct visual mapping and allow users to choose
    their interested data properties and visual encoding to create visualizations.
    For machine learning methods, Data2Vis [[23](https://arxiv.org/html/2411.05651v1#bib.bib23)]
    introduces an end-to-end trainable neural translation model for automatically
    generating visualizations from given datasets. VizML [[24](https://arxiv.org/html/2411.05651v1#bib.bib24)]
    learned visualization design choices from a corpus of data-visualization pairs.
    Table2Charts [[25](https://arxiv.org/html/2411.05651v1#bib.bib25)] recommends
    visualizations by learning patterns between tables and visualizations. ChartSeer [[26](https://arxiv.org/html/2411.05651v1#bib.bib26)]
    employs deep learning to recommend visualizations based on users’ interactions.
    Unlike end-to-end deep learning methods that directly learn from datasets to generate
    visualizations, knowledge graph-based approaches, such as AdaVis [[27](https://arxiv.org/html/2411.05651v1#bib.bib27)],
    KG4VIS [[28](https://arxiv.org/html/2411.05651v1#bib.bib28)], Lodestar [[29](https://arxiv.org/html/2411.05651v1#bib.bib29)],
    leverage structured information about data and relationships to recommend visualizations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化创作通常要求用户具备专业的可视化知识和编程能力。例如，像 Tableau 这样的工具支持通过货架配置设计创建可视化和多个链接视图，提供强大的可视化创作功能。然而，尽管
    Tableau 在作为创作工具方面表现出色，但它在自动任务分解和 VA 方法实施方面的支持有限，无法进一步辅助分析。关于自动可视化推荐的研究成果已提出 [[18](https://arxiv.org/html/2411.05651v1#bib.bib18),
    [19](https://arxiv.org/html/2411.05651v1#bib.bib19), [20](https://arxiv.org/html/2411.05651v1#bib.bib20)]。基于规则的方法，如
    Voyager [[21](https://arxiv.org/html/2411.05651v1#bib.bib21)] 和 CompassQL [[22](https://arxiv.org/html/2411.05651v1#bib.bib22)]，利用可视化原理构建视觉映射，允许用户选择他们感兴趣的数据属性和视觉编码来创建可视化。对于机器学习方法，Data2Vis [[23](https://arxiv.org/html/2411.05651v1#bib.bib23)]
    引入了一种端到端可训练的神经翻译模型，用于从给定数据集自动生成可视化。VizML [[24](https://arxiv.org/html/2411.05651v1#bib.bib24)]
    从一对数据-可视化对中学习可视化设计选择。Table2Charts [[25](https://arxiv.org/html/2411.05651v1#bib.bib25)]
    通过学习表格与可视化之间的模式推荐可视化。ChartSeer [[26](https://arxiv.org/html/2411.05651v1#bib.bib26)]
    采用深度学习基于用户的交互推荐可视化。与直接从数据集学习并生成可视化的端到端深度学习方法不同，基于知识图谱的方法，如 AdaVis [[27](https://arxiv.org/html/2411.05651v1#bib.bib27)]，KG4VIS [[28](https://arxiv.org/html/2411.05651v1#bib.bib28)]，Lodestar [[29](https://arxiv.org/html/2411.05651v1#bib.bib29)]，利用关于数据和关系的结构化信息来推荐可视化。
- en: In addition, there are some works that consider multi-view generation. Qu and
    Hullman [[30](https://arxiv.org/html/2411.05651v1#bib.bib30)] proposes coordination
    principles to keep consistency. Sun et al.[[31](https://arxiv.org/html/2411.05651v1#bib.bib31)]
    investigate different linking techniques based on data relationships. Dziban [[32](https://arxiv.org/html/2411.05651v1#bib.bib32)]
    is a visualization API using anchored recommendation and extending Draco [[33](https://arxiv.org/html/2411.05651v1#bib.bib33)]
    to reason about multiple views. DMiner [[34](https://arxiv.org/html/2411.05651v1#bib.bib34)]
    investigated the design rules of the single views and view-wise relationships
    from online notebooks to recommend multiple-view dashboards. MultiVision [[35](https://arxiv.org/html/2411.05651v1#bib.bib35)]
    and DashBot [[5](https://arxiv.org/html/2411.05651v1#bib.bib5)] recommend dashboards
    given an input dataset in an end-to-end manner using deep learning models. Shi
    et al. [[36](https://arxiv.org/html/2411.05651v1#bib.bib36)] optimize multi-view
    layouts by predicting the similarity of visual elements using Transformer-based
    models. Previous work has provided a solid research foundation for the principles
    between data, visualization, and multi-views. Building on this, we further study
    integrating LLM-agent to recommend visualizations that align with high-level goals
    and evolving tasks throughout the VA pipeline, which require significant human
    effort.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些研究考虑了多视图生成。Qu和Hullman [[30](https://arxiv.org/html/2411.05651v1#bib.bib30)]
    提出了协调原则以保持一致性。Sun等人[[31](https://arxiv.org/html/2411.05651v1#bib.bib31)] 研究了基于数据关系的不同联接技术。Dziban
    [[32](https://arxiv.org/html/2411.05651v1#bib.bib32)] 是一个使用锚定推荐的可视化API，并扩展了Draco
    [[33](https://arxiv.org/html/2411.05651v1#bib.bib33)] 来推理多个视图。DMiner [[34](https://arxiv.org/html/2411.05651v1#bib.bib34)]
    研究了在线笔记本中单视图和视图间关系的设计规则，以推荐多视图仪表板。MultiVision [[35](https://arxiv.org/html/2411.05651v1#bib.bib35)]
    和DashBot [[5](https://arxiv.org/html/2411.05651v1#bib.bib5)] 使用深度学习模型，以端到端的方式推荐给定输入数据集的仪表板。Shi等人[[36](https://arxiv.org/html/2411.05651v1#bib.bib36)]
    通过使用基于Transformer的模型预测视觉元素的相似性来优化多视图布局。之前的研究为数据、可视化和多视图之间的原则提供了坚实的研究基础。在此基础上，我们进一步研究了将LLM-agent整合进来，以推荐符合高级目标和不断变化任务的可视化，这些都需要大量的人力投入。
- en: II-B Task-Driven Visual Data Exploration
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 任务驱动的可视化数据探索
- en: In addition to data attributes when recommending visualizations, some visualization
    recommendation systems are task-driven recommendation systems that consider one
    or more analytic tasks (e.g., correlate, analyze trend). Some scholars study the
    recommendation of analysis methods in exploratory data analysis (EDA) within notebooks.
    EDAssistant [[37](https://arxiv.org/html/2411.05651v1#bib.bib37)] recommends code
    by analyzing associations between APIs in a large notebook collection. ATENA [[38](https://arxiv.org/html/2411.05651v1#bib.bib38)]
    shapes EDA into a Markov Decision Process (MDP) model using a deep reinforcement
    learning architecture to effectively optimize notebook generation. Furthermore,
    visual analytics incorporates visualization techniques into the EDA process, expanding
    the task space. Casner [[39](https://arxiv.org/html/2411.05651v1#bib.bib39)] presents
    one of the earliest examples of visualization systems that suggest charts based
    on a user’s task (e.g., finding direct flight routes or a table to see flight
    information). Saket et al. [[40](https://arxiv.org/html/2411.05651v1#bib.bib40)]
    conducted a study to assess the effectiveness of five canonical visualizations
    on ten low-level analytic tasks [[41](https://arxiv.org/html/2411.05651v1#bib.bib41)]
    and developed a recommendation engine based on their study’s findings. Gotz and
    Wen [[42](https://arxiv.org/html/2411.05651v1#bib.bib42)] present a prototype
    system that observes interaction patterns (e.g., repeatedly changing filters or
    swapping attributes) to infer analytic tasks such as comparison or trend analysis
    and correspondingly recommends visualizations such as small multiples or line
    charts. VizAssist [[43](https://arxiv.org/html/2411.05651v1#bib.bib43)] enables
    its users to specify their data objectives in terms of analytic tasks (e.g., correlate,
    compare) and considers these tasks in combination with existing perceptual guidelines
    as input to a genetic algorithm for recommending visualizations. Foresight [[8](https://arxiv.org/html/2411.05651v1#bib.bib8)]
    uses tasks like distributions, outliers, and correlations to guide insight discovery
    and grouping recommendations. TaskVis [[44](https://arxiv.org/html/2411.05651v1#bib.bib44)]
    recommends visualizations under specific tasks through answer set programming.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在推荐可视化时考虑数据属性外，一些可视化推荐系统是任务驱动型推荐系统，它们会考虑一个或多个分析任务（例如，相关性分析、趋势分析）。一些学者研究了在笔记本中进行探索性数据分析（EDA）时对分析方法的推荐。EDAssistant [[37](https://arxiv.org/html/2411.05651v1#bib.bib37)]
    通过分析大量笔记本集合中API之间的关联来推荐代码。ATENA [[38](https://arxiv.org/html/2411.05651v1#bib.bib38)]
    将EDA转化为马尔可夫决策过程（MDP）模型，使用深度强化学习架构有效优化笔记本生成过程。此外，视觉分析将可视化技术融入EDA过程，扩展了任务空间。Casner [[39](https://arxiv.org/html/2411.05651v1#bib.bib39)]
    提出了最早的可视化系统之一，该系统根据用户的任务（例如，查找直飞航线或查看航班信息的表格）来推荐图表。Saket等人 [[40](https://arxiv.org/html/2411.05651v1#bib.bib40)]
    进行了一项研究，评估了五种经典可视化在十个低级分析任务中的有效性 [[41](https://arxiv.org/html/2411.05651v1#bib.bib41)]，并根据研究结果开发了一个推荐引擎。Gotz和Wen [[42](https://arxiv.org/html/2411.05651v1#bib.bib42)]
    提出了一个原型系统，通过观察交互模式（例如，反复更改过滤器或交换属性）来推断分析任务（如比较或趋势分析），并相应地推荐可视化（如小倍数图或折线图）。VizAssist [[43](https://arxiv.org/html/2411.05651v1#bib.bib43)]
    使用户能够根据分析任务（例如，相关性分析、比较）来指定他们的数据目标，并将这些任务与现有的感知指南结合，作为输入到遗传算法中推荐可视化。Foresight [[8](https://arxiv.org/html/2411.05651v1#bib.bib8)]
    使用分布、异常值和相关性等任务来引导洞察发现和分组推荐。TaskVis [[44](https://arxiv.org/html/2411.05651v1#bib.bib44)]
    通过答案集编程在特定任务下推荐可视化。
- en: In addition to visual generation based on a single task, Medley [[45](https://arxiv.org/html/2411.05651v1#bib.bib45)]
    recommends multi-view collections based on several analytic intents, and views
    and widgets can be selected to compose a variety of dashboards. However, the analytic
    intents and visualization combinations are often chosen from preset options, which
    limits exploration flexibility. Different from them, we study dynamic task planning
    based on the goal and findings and leverage human-agent collaboration.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基于单一任务的可视化生成外，Medley [[45](https://arxiv.org/html/2411.05651v1#bib.bib45)]
    基于多个分析意图推荐多视图集合，用户可以选择视图和小部件来组合成多种仪表板。然而，分析意图和可视化组合通常是从预设选项中选择的，这限制了探索的灵活性。与此不同，我们研究基于目标和发现的动态任务规划，并利用人机协作。
- en: II-C Large Language Model in Data Exploration
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 大型语言模型在数据探索中的应用
- en: LLM-based tools have been proposed for data exploration and visualization tasks.
    For visualization generation and recommendations, LLM4Vis [[14](https://arxiv.org/html/2411.05651v1#bib.bib14)]
    and ChartGPT [[46](https://arxiv.org/html/2411.05651v1#bib.bib46)] utilize LLMs
    to choose appropriate visualizations from natural language instructions. Li et
    al. [[47](https://arxiv.org/html/2411.05651v1#bib.bib47)] evaluate the capability
    of GPT-3.5 to generate visualization specifications, demonstrating its superiority
    over previous machine learning-based approaches. NL2Rigel [[48](https://arxiv.org/html/2411.05651v1#bib.bib48)]
    showcases the LLM’s ability to convert instructions into comprehensive data visualizations
    and tables. For analytical task translation and automation, Hassan et al.[[49](https://arxiv.org/html/2411.05651v1#bib.bib49)]
    and Data-Copilot[[16](https://arxiv.org/html/2411.05651v1#bib.bib16)] concentrate
    on converting analytical goals and ambiguous queries into actionable data analysis
    tasks. Ma et al.[[50](https://arxiv.org/html/2411.05651v1#bib.bib50)] and JarviX[[12](https://arxiv.org/html/2411.05651v1#bib.bib12)]
    introduce systems that automate the data exploration process by identifying suitable
    analysis intents and generating insights. Text2Analysis [[51](https://arxiv.org/html/2411.05651v1#bib.bib51)]
    offers a framework for categorizing data analysis tasks, establishing a structured
    approach to tackling common analytical challenges ranging from basic operations
    to forecasting and chart generation. However, the tasks in these studies are generally
    straightforward and focused, with limited exploration into the decomposition of
    more complex tasks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的工具已被提出用于数据探索和可视化任务。在可视化生成和推荐方面，LLM4Vis [[14](https://arxiv.org/html/2411.05651v1#bib.bib14)]
    和ChartGPT [[46](https://arxiv.org/html/2411.05651v1#bib.bib46)] 利用LLMs从自然语言指令中选择适当的可视化方案。Li等人[[47](https://arxiv.org/html/2411.05651v1#bib.bib47)]评估了GPT-3.5生成可视化规范的能力，展示了其在传统机器学习方法中的优势。NL2Rigel [[48](https://arxiv.org/html/2411.05651v1#bib.bib48)]
    展示了LLM将指令转化为全面数据可视化和表格的能力。对于分析任务的翻译和自动化，Hassan等人[[49](https://arxiv.org/html/2411.05651v1#bib.bib49)]和Data-Copilot[[16](https://arxiv.org/html/2411.05651v1#bib.bib16)]集中于将分析目标和模糊查询转化为可执行的数据分析任务。Ma等人[[50](https://arxiv.org/html/2411.05651v1#bib.bib50)]
    和JarviX[[12](https://arxiv.org/html/2411.05651v1#bib.bib12)]介绍了通过识别合适的分析意图并生成洞察来自动化数据探索过程的系统。Text2Analysis [[51](https://arxiv.org/html/2411.05651v1#bib.bib51)]
    提供了一个框架，用于对数据分析任务进行分类，建立了一种结构化的方法来应对从基本操作到预测和图表生成等常见的分析挑战。然而，这些研究中的任务通常较为简单且集中，较少探索更复杂任务的分解。
- en: When using LLMs to solve complex tasks where multi-step reasoning is demanded,
    the performance of directly using LLMs tends to decrease. Recently, prior methods
    have utilized LLMs with input-output prompting, CoT [[52](https://arxiv.org/html/2411.05651v1#bib.bib52)],
    ToT [[53](https://arxiv.org/html/2411.05651v1#bib.bib53)] or GoT [[54](https://arxiv.org/html/2411.05651v1#bib.bib54)]
    to perform complex task planning and execution. These methods proved that LLMs
    are good at task planning but require appropriate prompting techniques. Another
    way is to integrate LLMs in the interface, allowing chaining multiple prompts
    to address a much wider range of human tasks. Wu et al. [[55](https://arxiv.org/html/2411.05651v1#bib.bib55)]
    introduce the chaining of AI models, where a complex task is divided into multiple
    steps. Talk2Data [[56](https://arxiv.org/html/2411.05651v1#bib.bib56)] presents
    a natural language interface that enables users to explore visual data through
    question decomposition. However, the linked visualization and more advanced data
    analysis methods remain limited. To enhance this capability, we leverage LLMs
    and propose an agent-based autonomous task-planning strategy for adaptive VA system
    construction and exploration.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用LLM解决需要多步骤推理的复杂任务时，直接使用LLM的性能往往会下降。最近，先前的方法通过输入输出提示、CoT [[52](https://arxiv.org/html/2411.05651v1#bib.bib52)]、ToT [[53](https://arxiv.org/html/2411.05651v1#bib.bib53)]
    或GoT [[54](https://arxiv.org/html/2411.05651v1#bib.bib54)]等方式来执行复杂的任务规划和执行。这些方法证明了LLM在任务规划方面表现优异，但需要合适的提示技巧。另一种方式是将LLM集成到接口中，允许通过链式多个提示来应对更广泛的人类任务。Wu等人[[55](https://arxiv.org/html/2411.05651v1#bib.bib55)]介绍了AI模型的链式结构，其中将复杂任务分解为多个步骤。Talk2Data [[56](https://arxiv.org/html/2411.05651v1#bib.bib56)]
    提供了一个自然语言接口，使用户能够通过问题分解探索可视化数据。然而，相关的可视化和更高级的数据分析方法仍然有限。为了增强这一能力，我们利用LLM并提出了一种基于代理的自主任务规划策略，用于适应性VA系统的构建和探索。
- en: III LightVA Framework
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III LightVA框架
- en: 'The pipeline of VA involves two stages: development and analysis. Thus, in
    LightVA, we aim to reduce the efforts for both developers and analysts. In the
    following, we will examine the challenges and derive the design requirements for
    integrating LLM-based agents into the user’s workflow. Finally, we introduce the
    conceptual framework of agent-based VA workflow.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: VA的流程包括两个阶段：开发和分析。因此，在LightVA中，我们旨在减少开发人员和分析师的工作量。在接下来的部分，我们将探讨挑战并提出集成基于LLM的代理到用户工作流中的设计要求。最后，我们介绍基于代理的VA工作流的概念框架。
- en: III-A Challenges
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 挑战
- en: 'Through a review of visual analytics literature, we identify and dissect specific
    challenges that intensify the effort users must exert:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对视觉分析文献的回顾，我们识别并剖析了加重用户工作量的具体挑战：
- en: C1
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: C1
- en: 'Accommodating diverse analysis requirements: Data Analysts often face the immense
    challenge of navigating a vast exploration space, where the analytical process
    is dynamic and iterative [[4](https://arxiv.org/html/2411.05651v1#bib.bib4)].
    Forming hypotheses and validating them through the continuous proposal of new
    tasks and insights is complex. They have to figure out the connections between
    tasks and insights in their mind and try to propose tasks in the next few steps
    until they achieve the goal.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适应多样化的分析需求：数据分析师通常面临着在广阔的探索空间中导航的巨大挑战，其中分析过程是动态的和迭代的[[4](https://arxiv.org/html/2411.05651v1#bib.bib4)]。形成假设并通过持续提出新任务和新见解来验证它们是复杂的。他们必须在脑海中理清任务和见解之间的关联，并尝试在接下来的几步中提出任务，直到达成目标。
- en: C2
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: C2
- en: 'Developing visualization and data mining tools is time-consuming:  Analysts
    often lack proficiency in developing and managing VA systems, which makes it challenging
    for them to select and apply appropriate data modeling and visualization techniques [[45](https://arxiv.org/html/2411.05651v1#bib.bib45)].
    Additionally, when tasks involve multiple visualizations, these must be integrated
    into a linked view to enable more effective interactive exploration [[57](https://arxiv.org/html/2411.05651v1#bib.bib57)].
    However, this process requires substantial knowledge of both visualization principles
    and coding skills, resulting in inefficiencies and delays [[58](https://arxiv.org/html/2411.05651v1#bib.bib58)].'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开发可视化和数据挖掘工具是耗时的：分析师通常缺乏开发和管理VA系统的能力，这使得他们在选择和应用合适的数据建模和可视化技术时面临挑战[[45](https://arxiv.org/html/2411.05651v1#bib.bib45)]。此外，当任务涉及多个可视化时，这些可视化必须集成到一个链接视图中，以便进行更有效的交互式探索[[57](https://arxiv.org/html/2411.05651v1#bib.bib57)]。然而，这一过程需要对可视化原理和编程技能有深刻的了解，从而导致低效和延误[[58](https://arxiv.org/html/2411.05651v1#bib.bib58)]。
- en: III-B Design Requirements
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 设计要求
- en: Based on these challenges, we have settled on a set of targeted design requirements.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些挑战，我们已经确定了一组有针对性的设计要求。
- en: R1
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R1
- en: 'Adaptive task planning: Task proposals need to be tailored to users’ analysis
    goals and the given dataset. This includes exploring in depth and breadth, with
    automatic planning and execution reducing user efforts. Moreover, as exploration
    results emerge, new tasks should contextually link to previous exploration results,
    adapting to the switching between tasks. (C1)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自适应任务规划：任务提议需要根据用户的分析目标和给定的数据集量身定制。这包括深入和广泛的探索，自动化的规划和执行能够减少用户的努力。此外，随着探索结果的出现，新的任务应与先前的探索结果在语境上进行关联，以适应任务之间的切换。（C1）
- en: R2
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R2
- en: 'Flexible visualization generation: The generation of visualizations should
    flexibly handle different tasks and data. This encompasses accurate data identification,
    transformation, and selection of visualization types, as well as adding highlights
    based on discovered insights to reduce cognitive load. Furthermore, generated
    views should support interaction, allowing for more immersive user analysis. (C2)'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 灵活的可视化生成：可视化的生成应灵活地处理不同的任务和数据。这包括准确的数据识别、转换和可视化类型的选择，以及根据发现的见解添加高亮，以减轻认知负担。此外，生成的视图应支持交互，使用户能够进行更为沉浸的分析。（C2）
- en: R3
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R3
- en: 'Automatic insight generation: To reduce development costs, the system should
    efficiently complete code-based data analyses for given tasks, providing visualizations
    and suggesting findings to facilitate hypothesis forming and validation. To lessen
    the cognitive burden, important parts of insights should be highlighted in rich
    text format in the output results. (C2)'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动洞察生成：为了减少开发成本，系统应高效地完成给定任务的基于代码的数据分析，提供可视化并提出发现，以促进假设的形成和验证。为了减轻认知负担，洞察的关键部分应在输出结果中以富文本格式突出显示。（C2）
- en: R4
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R4
- en: 'Multiple view composition: As new visualizations are added, older ones may
    become less relevant. To display the most recent results to the user, the visualization
    panel needs to be updated. However, it is crucial to avoid discarding previous
    results as they may be relevant to new insights. Users should be allowed to merge
    visualizations of interest even if they are not the latest. Within the merged
    views, users can focus their analysis on a smaller scope through interaction,
    reducing cognitive load among large sets. (C2)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多视图合成：随着新可视化的添加，旧的可视化可能变得不再相关。为了向用户显示最新结果，可视化面板需要更新。然而，避免丢弃以前的结果至关重要，因为它们可能与新的洞察相关。即使它们不是最新的，用户也应该被允许合并感兴趣的可视化。在合并的视图中，用户可以通过交互将分析集中在更小的范围内，从而减少在大数据集中的认知负担。（C2）
- en: R5
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R5
- en: 'Intuitive analysis process: The relationship between tasks, visualization,
    insights, and analysis progress should be presented in a more intuitive form.
    The system should support interactions between human and agent to help users understand
    the agent’s task planning and execution. (C1, C2)'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直观分析过程：任务、可视化、洞察和分析进展之间的关系应以更直观的形式呈现。系统应支持人类与代理之间的交互，帮助用户理解代理的任务规划和执行过程。（C1，C2）
- en: III-C Conceptual Framework
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 概念框架
- en: 'Based on the challenges and requirements discussed, we propose LightVA, a lightweight
    VA framework with agent-based task planning. The “lightweight” refers to the light
    expectations in developing VA systems and using the developed systems for analysis.
    We design the framework to involve a recursive task-solving process in which goals
    and data are inputs, and insights are outputs. The intermediate results are tasks,
    subtasks, visualization, data modeling ([Fig. 1](https://arxiv.org/html/2411.05651v1#S3.F1
    "In III-C1 Defining Primitives ‣ III-C Conceptual Framework ‣ III LightVA Framework
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")). The LLM agents are integrated to support goal understanding and
    task decomposition (R1), data modeling and visualization codes generation (R2,
    R3), and linked view generation for interactive exploration (R4). Meanwhile, the
    users can monitor the process, guide the agent, and refine the agent’s output
    through direct manipulations and natural languages (R5).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 基于讨论中的挑战和需求，我们提出了LightVA，一个基于代理的轻量级VA框架。“轻量级”指的是在开发VA系统和使用开发出的系统进行分析时对系统的低要求。我们设计该框架，采用递归任务解决过程，其中目标和数据是输入，洞察是输出。中间结果包括任务、子任务、可视化、数据建模
    ([图 1](https://arxiv.org/html/2411.05651v1#S3.F1 "在 III-C1 定义基本元素 ‣ III-C 概念框架
    ‣ III LightVA 框架 ‣ LightVA：基于LLM代理的轻量级视觉分析和任务规划与执行"))。LLM代理被集成以支持目标理解和任务分解（R1）、数据建模和可视化代码生成（R2，R3），以及生成互动探索的链接视图（R4）。同时，用户可以通过直接操作和自然语言监控过程、引导代理并细化代理输出（R5）。
- en: III-C1 Defining Primitives
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C1 定义基本元素
- en: '![Refer to caption](img/c5584c2004b8ff4cf574db55965b455a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅图例](img/c5584c2004b8ff4cf574db55965b455a.png)'
- en: 'Figure 1: The illustration of conceptual framework in LightVA. The agent creates
    the VA system for analysis by task planning and execution, while the user uses
    the created VA system and refines agent outputs.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：LightVA概念框架的说明。代理通过任务规划和执行创建VA系统进行分析，而用户使用创建的VA系统并细化代理输出。
- en: According to the above descriptions of the framework, some key primitives need
    to be defined.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 根据框架的上述描述，需要定义一些关键的基本元素。
- en: 'Goal and Data: We define a goal as an overall description or a vague utterance
    that expresses the high-level purpose of the analysis. For instance, “to analyze
    the influence factor on a car’s fuel efficiency”. The goal directs the focus of
    the analysis, and the data supplies the analysis evidence to meet the goal.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 目标和数据：我们将目标定义为对分析高层次目的的总体描述或模糊表述。例如，“分析影响汽车燃油效率的因素”。目标引导分析的焦点，数据提供满足目标的分析证据。
- en: 'Task: Tasks are specific aspects derived from the goal and make the goal executable.
    We define them using four attributes:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 任务：任务是从目标中派生出来的具体方面，使目标可以执行。我们通过四个属性来定义任务：
- en: '|  | $task:=\langle type,\leavevmode\nobreak\ data\leavevmode\nobreak\ variables,%
    \leavevmode\nobreak\ method,\leavevmode\nobreak\ progress\rangle$ |  | (1) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $task:=\langle type,\leavevmode\nobreak\ data\leavevmode\nobreak\ variables,%
    \leavevmode\nobreak\ method,\leavevmode\nobreak\ progress\rangle$ |  | (1) |'
- en: The type indicates the nature or category of the analytical operation to be
    performed, such as finding extreme, outlier, change point, trend analysis, etc.
    The data variables are the objects upon which the tasks will be applied. The method
    defines how the task will be solved, including data modeling and visualization
    methods, and the solved result is insight. If the task is complex, which means
    it covers multiple data variables and needs to use multiple methods to solve,
    the task can be decomposed into subtasks. To depict whether the task is completed,
    we define progress, which means the task is solved when its subtasks are solved
    as well. Given that the tasks can be complex and range from low to high abstraction,
    we describe them using natural language.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 类型表示要执行的分析操作的性质或类别，例如查找极值、离群点、变化点、趋势分析等。数据变量是任务应用的对象。方法定义了任务的解决方式，包括数据建模和可视化方法，解决后的结果即为洞察。如果任务复杂，意味着它涉及多个数据变量并需要使用多种方法解决，那么任务可以分解为子任务。为了描述任务是否完成，我们定义了进度，意味着当其子任务完成时，任务也被视为完成。鉴于任务可能复杂，且范围从低到高的抽象层次不等，我们使用自然语言来描述它们。
- en: 'Insight: This denotes the expected or targeted knowledge or understanding that
    the task aims to achieve. We define insight using four attributes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 洞察：这表示任务旨在达到的预期或目标知识或理解。我们通过四个属性来定义洞察：
- en: '|  | $insight:=\langle type,\leavevmode\nobreak\ parameters,\leavevmode\nobreak\
    % data\leavevmode\nobreak\ variables,\leavevmode\nobreak\ data\leavevmode% \nobreak\
    values\rangle$ |  | (2) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | $insight:=\langle type,\leavevmode\nobreak\ parameters,\leavevmode\nobreak\
    % data\leavevmode\nobreak\ variables,\leavevmode\nobreak\ data\leavevmode% \nobreak\
    values\rangle$ |  | (2) |'
- en: The insight type can be discoveries, patterns, trends, or anomalies identified
    through analysis [[59](https://arxiv.org/html/2411.05651v1#bib.bib59)]. For example,
    if the task type is “compare”, the insight type could be “difference” [[7](https://arxiv.org/html/2411.05651v1#bib.bib7)].
    The parameters specific features of the insight, such as “increasing” or “decreasing”
    of “trend”. The data variables for insights can be the original data columns or
    transformed variables, while the data variables for tasks are the original data
    columns. For example, if the task involves analyzing vehicle weight and fuel efficiency
    (MPG), the task’s data variables would include “Weight_in_lbs” and “MPG”. If the
    insight includes a derived metric such as “MPG per pound,” this would be considered
    a transformed variable specific to the insight. The data values refer to particular
    values of data variables. For example, the maximum MPG value is “48”.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 洞察类型可以是通过分析识别出的发现、模式、趋势或异常[[59](https://arxiv.org/html/2411.05651v1#bib.bib59)]。例如，如果任务类型是“比较”，那么洞察类型可以是“差异”[[7](https://arxiv.org/html/2411.05651v1#bib.bib7)]。洞察的具体特征参数，如“趋势”的“增加”或“减少”。洞察的数据变量可以是原始数据列或转换后的变量，而任务的数据变量则是原始数据列。例如，如果任务涉及分析车辆重量和燃油效率（MPG），任务的数据变量将包括“Weight_in_lbs”和“MPG”。如果洞察包括一个衍生指标，如“每磅MPG”，这将被视为特定于洞察的转换变量。数据值指的是数据变量的特定值。例如，最大MPG值为“48”。
- en: 'Visualization: Refers to the visual representation required for the task that
    best conveys the data and insights.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化：指为任务所需的最佳数据和洞察传达方式的视觉表现。
- en: '|  | $visualization:=\langle type,\leavevmode\nobreak\ encoding,\leavevmode\nobreak%
    \ interaction,\leavevmode\nobreak\ coordination\rangle$ |  | (3) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $visualization:=\langle type,\leavevmode\nobreak\ encoding,\leavevmode\nobreak%
    \ interaction,\leavevmode\nobreak\ coordination\rangle$ |  | (3) |'
- en: Our framework generates visualizations using Vega-Lite grammar [[60](https://arxiv.org/html/2411.05651v1#bib.bib60)],
    which supports the above four aspects. The types of interactions are, e.g., filtering,
    zooming, and hovering supported by the visualization. The coordination describes
    how this visualization interacts or synchronizes with other visualizations, such
    as a brush, to filter each other.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架使用Vega-Lite语法[[60](https://arxiv.org/html/2411.05651v1#bib.bib60)]生成可视化，支持上述四个方面。交互类型包括例如过滤、缩放和悬停，这些都受到可视化的支持。协调描述了此可视化如何与其他可视化进行交互或同步，例如使用刷选功能互相过滤。
- en: III-C2 Workflow of Framework
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C2 框架的工作流程
- en: 'Our framework involves building a task flow, represented as a directed compound
    graph $G=(V,E)$, where each node $v\in V$ represents a task and edge $e\in E$
    represents the connection from one task to another task. Since the process of
    exploration involves both enlightening and in-depth thinking, we define two types
    of task edges: recommendation and decomposition. And we define the solving of
    the task as execution. The difference between recommendation and decomposition
    is that recommendation is “goal-oriented”, and decomposition is “task-specific”.
    The recommendation aims to broaden the exploration scope, providing heuristic
    suggestions. The decomposition aims to ensure a detailed plan with clear logic
    for solving the task. The following sections will introduce how humans and agents
    collaborated to complete the analysis in our framework ([Fig. 2](https://arxiv.org/html/2411.05651v1#S3.F2
    "In III-C2 Workflow of Framework ‣ III-C Conceptual Framework ‣ III LightVA Framework
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架涉及构建一个任务流，表示为一个有向复合图 $G=(V,E)$，其中每个节点 $v\in V$ 表示一个任务，边 $e\in E$ 表示一个任务与另一个任务之间的连接。由于探索过程既涉及启发性思维又涉及深入思考，我们定义了两种任务边：推荐和分解。我们将任务的解决定义为执行。推荐和分解的区别在于，推荐是“目标导向的”，而分解是“任务特定的”。推荐旨在拓宽探索范围，提供启发式建议；分解则旨在确保为解决任务制定详细且逻辑清晰的计划。接下来的部分将介绍人类与代理如何在我们的框架中协作完成分析（[图2](https://arxiv.org/html/2411.05651v1#S3.F2
    "在III-C2 框架的工作流程 ‣ III-C 概念框架 ‣ III LightVA框架 ‣ LightVA：基于LLM代理的轻量级可视化分析任务规划与执行")）。
- en: '![Refer to caption](img/306a1215466984923295083a788f0925.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/306a1215466984923295083a788f0925.png)'
- en: 'Figure 2: The workflow of the LLM agent-based task planning and execution for
    visual analytics. The collaboration between users and the AI agent is characterized
    by three stages: task recommendation, task execution, and task decomposition.
    The user proposes goals, selects tasks, merges visualizations, and engages in
    interactive exploration (H1-H5). The agent interprets data, recommends tasks,
    generates codes, reports insights, evaluates tasks, and decomposes tasks (A1-A6).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：基于LLM代理的任务规划和执行的工作流程，用于可视化分析。用户与AI代理之间的协作可分为三个阶段：任务推荐、任务执行和任务分解。用户提出目标，选择任务，合并可视化并进行交互式探索（H1-H5）。代理解释数据，推荐任务，生成代码，报告见解，评估任务并分解任务（A1-A6）。
- en: 'Stage1: Task recommendation. Initially, the user uploads the data and inputs
    a goal (H1), and then the agent interprets data (A1) and transforms the goal into
    specific, actionable tasks (A2). The user can provide feedback and accept or modify
    recommended tasks to align with their analysis needs (H2). Specifically, the interaction
    process involves two stages:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段1：任务推荐。最初，用户上传数据并输入目标（H1），然后代理解释数据（A1），并将目标转化为具体的、可执行的任务（A2）。用户可以提供反馈，接受或修改推荐的任务，以便与其分析需求对齐（H2）。具体而言，交互过程涉及两个阶段：
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Initial stage: At the begining, agent should first interpret the data and propose
    tasks that make the goal executable by mapping it to the data. The principle is
    to identify data variables and task type. For instance, for a goal of “find high-risk
    events in a city”, useful data variables could include time, space, text, and
    sentiment. The agent also needs to distinguish the purpose of the analysis, e.g.,
    “finding outliers”. Thus, different combinations of data variables and task types
    can form different tasks under a goal.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 初始阶段：开始时，代理应首先解释数据，并通过将目标与数据映射来提出使目标可执行的任务。原则是识别数据变量和任务类型。例如，对于“在一个城市中找到高风险事件”的目标，有用的数据变量可能包括时间、空间、文本和情感。代理还需要区分分析的目的，例如，“发现异常值”。因此，数据变量和任务类型的不同组合可以形成目标下的不同任务。
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Historical context stage: As the analysis continues to accumulate in the recommendation
    process, the agent should recommend tasks considering previous tasks and the overall
    goal. First, when a task is completed, the agent evaluates if the overall goal
    has been achieved. If not, it should recommend new tasks aligned with the goal.
    Second, previously unexplored tasks should be re-evaluated and proposed again
    if they are still relevant to the goal.'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 历史背景阶段：随着分析在推荐过程中不断积累，代理应考虑先前任务和整体目标，推荐任务。首先，当一个任务完成时，代理评估是否已实现整体目标。如果没有，它应该推荐与目标对齐的新任务。其次，如果之前未探索的任务仍然与目标相关，应该重新评估并再次提出。
- en: 'Stage2: Task execution. In this stage, the agent generates visualization and
    modeling codes (A3) and executes the codes to report and summarize insights (A4).
    Having multiple visualizations and modeling approaches, users could select visualizations
    to merge a linked view (H3) and interactively explore it (H4). It comprises the
    following two-step approach:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段2：任务执行。在这个阶段，智能体生成可视化和建模代码（A3），并执行代码报告并总结洞察（A4）。通过多种可视化和建模方法，用户可以选择可视化方式来合并联动视图（H3），并进行交互式探索（H4）。它包括以下两个步骤：
- en: •
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Visualization and insight generation: When the user selects an agent-proposed
    task or proposes a task themselves, the agent writes codes to complete the analysis.
    The agent needs to choose appropriate data modeling and visualization methods
    for each task and run the codes to complete the analysis. The agent then needs
    to generate the insights into a structured format. Finally, the agent should summarize
    insights obtained from the decomposition of subtasks, providing a comprehensive
    overview of the analysis.'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化和洞察生成：当用户选择一个智能体建议的任务或自行提出任务时，智能体编写代码以完成分析。智能体需要为每个任务选择适当的数据建模和可视化方法，并运行代码完成分析。然后，智能体需要将洞察生成结构化格式。最后，智能体应总结从子任务分解中获得的洞察，提供分析的全面概览。
- en: •
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Multi-view linking: Users can initiate coordination by selecting multiple visualizations
    they prefer while the agent generates codes. We currently do not automatically
    combine visualizations from subtasks because subtasks decomposed from a main task
    often share common variables and visualization types. For example, several subtasks
    might use latitude and longitude to create maps exploring different spatial patterns.
    The linked view is often used to conduct multi-variate association analysis with
    different visualizations. Thus, allowing users to choose their visualizations
    can provide a more flexible analysis.'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多视图联动：用户可以通过选择多个喜欢的可视化来发起协调，而智能体生成代码。目前，我们不会自动将子任务的可视化合并，因为从主任务分解出的子任务通常共享相同的变量和可视化类型。例如，几个子任务可能使用纬度和经度创建不同空间模式的地图。联动视图通常用于与不同的可视化进行多变量关联分析。因此，允许用户选择自己的可视化可以提供更灵活的分析方式。
- en: 'Stage3: Task decomposition. We design the decomposition following a “on-demand”
    strategy. In other words, execution is prioritized, and decomposition is considered
    only if the task is not completed. This approach aims to ensure users can see
    initial results quickly in an interactive environment. In this stage, the agent
    is responsible for evaluating tasks (A5) and proposing a decomposition plan (A6),
    while the users can examine and modify agent output to override the agents (H5).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段3：任务分解。我们根据“按需”策略设计分解。换句话说，优先执行任务，只有在任务未完成时才考虑分解。这种方法旨在确保用户能够在互动环境中快速看到初步结果。在这个阶段，智能体负责评估任务（A5）并提出分解计划（A6），同时用户可以检查并修改智能体输出，从而覆盖智能体的建议（H5）。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Results assessment: Based on the initial execution’s insights and the complexity
    of the task, the agent assesses the need for further analysis. According to the
    definition of task, the agent should verify the selection of data variables and
    the rationality of data modeling and visualization methods. The evaluation should
    be explained to make users understand the motivation of decomposition.'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果评估：根据初步执行的见解和任务的复杂性，智能体评估是否需要进一步分析。根据任务的定义，智能体应验证数据变量的选择以及数据建模和可视化方法的合理性。评估应进行解释，以便用户理解分解的动机。
- en: •
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sub-task generation: If decomposition is necessary, agent should formulate
    a plan outlining subtasks. Each subtask should have appropriate data variables
    and methods addressing distinct aspects of the main task. These subtasks should
    have an execution order, e.g., in parallel or sequentially.'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 子任务生成：如果需要分解，智能体应制定一个计划，概述子任务。每个子任务应具有适当的数据变量和方法，解决主要任务的不同方面。这些子任务应有执行顺序，例如并行或顺序执行。
- en: IV LightVA System
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV LightVA 系统
- en: Guided by the design requirements, we propose a pipeline of LLM agent-based
    task planning and an interface to support interactive visual data exploration
    with assistance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计要求的指导下，我们提出了基于LLM智能体的任务规划流程和支持互动可视化数据探索的接口。
- en: '![Refer to caption](img/3937e9b3a802f6dc46d61e55bceb3c4b.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![请参考说明文字](img/3937e9b3a802f6dc46d61e55bceb3c4b.png)'
- en: 'Figure 3: The agent-based system architecture. The pipeline starts from the
    goal and data with an agent-based task planning strategy, including recommendation,
    execution, and decomposition. Specific components and interactions are labeled
    (a)-(f), where (a) is the initial stage to recommend tasks from the goal, (b)
    recommends tasks with historical contexts, and (c) is the execution of tasks generating
    visualization and insights. After that, a series of optimizations for visual consistency
    are performed (d). Historical records are managed, and the progress of tasks is
    updated in a timely manner (e). According to the analysis results, the agent evaluates
    whether the task needs to be decomposed (f).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：基于代理的系统架构。管道从目标和数据开始，采用基于代理的任务规划策略，包括推荐、执行和分解。具体组件和交互标记为（a）-（f），其中（a）是从目标推荐任务的初始阶段，（b）推荐具有历史背景的任务，（c）是执行任务，生成可视化和洞察。之后，进行一系列视觉一致性的优化（d）。历史记录被管理，任务的进度得到及时更新（e）。根据分析结果，代理评估任务是否需要分解（f）。
- en: IV-A Agent-based Task Planning
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 基于代理的任务规划
- en: 'Based on the conceptual framework previously introduced, we propose an agent-based
    task-planning pipeline [Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3 "In
    IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution"). In this process, we have three kinds of modules.
    The planner has two types: recommender and decomposer, which are responsible for
    task recommendation and decomposition respectively. The executor handles task
    execution, including visualization generation and data analysis, and the controller
    is the recursive algorithm that bridges the executor and planner (See the algorithm
    in the appendix). When introducing each stage’s strategy, we provide the prompt
    templates that describe input and output, instructions to LLMs, and indicators
    to describe the output format. The prompt examples and outputs are available in
    Appendix A.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '基于之前介绍的概念框架，我们提出了一种基于代理的任务规划管道[图 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "在 IV LightVA 系统 ‣ LightVA: 轻量级视觉分析与 LLM 基于代理的任务规划与执行")。在这一过程中，我们有三种模块。规划器有两种类型：推荐器和分解器，分别负责任务推荐和分解。执行器负责任务执行，包括可视化生成和数据分析，而控制器是将执行器与规划器连接的递归算法（详见附录中的算法）。在介绍每个阶段的策略时，我们提供了描述输入和输出、LLM
    指令以及输出格式的指标的提示模板。提示示例和输出在附录 A 中可用。'
- en: IV-A1 Task recommendation
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 任务推荐
- en: 'Task planning begins with a recommendation approach based on the given goal
    and dataset. The recommender aims to transform the goal into actionable tasks.
    The implementation follows the step-by-step guidelines with two stages: initial
    stage and historical context stage (Prompt template [1](https://arxiv.org/html/2411.05651v1#ThmPrompt1
    "Prompt Template 1 (Task Recommendation). ‣ IV-A1 Task recommendation ‣ IV-A Agent-based
    Task Planning ‣ IV LightVA System ‣ LightVA: Lightweight Visual Analytics with
    LLM Agent-Based Task Planning and Execution")).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '任务规划从基于给定目标和数据集的推荐方法开始。推荐器的目标是将目标转化为可执行的任务。实施遵循逐步指南，分为两个阶段：初始阶段和历史背景阶段（提示模板[1](https://arxiv.org/html/2411.05651v1#ThmPrompt1
    "提示模板 1（任务推荐）。 ‣ IV-A1 任务推荐 ‣ IV-A 基于代理的任务规划 ‣ IV LightVA 系统 ‣ LightVA: 轻量级视觉分析与
    LLM 基于代理的任务规划与执行")）。'
- en: 'In the initial stage, the input is the goal and the data ([Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-a) and the objective is to convert the goal into
    actionable tasks. Based on the framework ([Section III-C2](https://arxiv.org/html/2411.05651v1#S3.SS3.SSS2
    "III-C2 Workflow of Framework ‣ III-C Conceptual Framework ‣ III LightVA Framework
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")), we guide the model with three principles. First, identify data variables
    relevant to the goal. Second, propose several task type to refine the goal from
    different aspects. Third, draft descriptions of tasks by combining these data
    variables and task types.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始阶段，输入为目标和数据（[图 3](https://arxiv.org/html/2411.05651v1#S4.F3 "在 IV LightVA
    系统 ‣ LightVA：基于 LLM 代理的轻量级可视分析与任务规划与执行")-a），目标是将目标转化为可执行的任务。基于框架（[第三节 C2](https://arxiv.org/html/2411.05651v1#S3.SS3.SSS2
    "III-C2 框架工作流程 ‣ III-C 概念框架 ‣ III LightVA 框架 ‣ LightVA：基于 LLM 代理的轻量级可视分析与任务规划与执行")），我们以三条原则来指导模型。首先，识别与目标相关的数据变量。其次，提出多种任务类型，从不同角度细化目标。第三，通过结合这些数据变量和任务类型，起草任务描述。
- en: 'In the historical context stage ([Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-b), the generated tasks should be divided into two
    types: linking goals with discoveries to propose new tasks and tasks that might
    have been forgotten by the user needs to review. To achieve this goal, the model
    might need to consider the following steps. First, evaluate completed tasks to
    check if the overall goal is achieved. Second, propose new tasks based on the
    current context and previous tasks. Third, propose previously unexplored tasks
    if they remain relevant. In addition to guidelines, we should provide examples
    of output to guide models.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在历史背景阶段（[图 3](https://arxiv.org/html/2411.05651v1#S4.F3 "在 IV LightVA 系统 ‣ LightVA：基于
    LLM 代理的轻量级可视分析与任务规划与执行")-b），生成的任务应分为两种类型：将目标与发现联系起来，提出新任务，以及可能被用户忽视的任务，需要复审。为实现此目标，模型可能需要考虑以下步骤。首先，评估已完成的任务，检查整体目标是否已达成。其次，基于当前背景和先前的任务提出新任务。第三，如果先前未探索的任务仍然相关，提出这些任务。除了指南外，我们还应提供输出示例以指导模型。
- en: Prompt Template 1 (Task Recommendation).
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示模板 1（任务推荐）。
- en: ———————————————————-Initial stage
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ———————————————————-初始阶段
- en: 'Input: {goal, data}'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：{目标、数据}
- en: 'Instruction: You need to come up with a short plan based on the understanding
    of the data to help accomplish the goal. Please recommend n exploratory tasks,
    including task description, type, and data variables. For task type, you may consider
    the trend, correlation, category, distribution, etc, to explore the goal from
    different aspects. For data_variables, list the original column names.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 指令：你需要基于对数据的理解，提出一个简短的计划，以帮助完成目标。请推荐 n 个探索性任务，包括任务描述、类型和数据变量。对于任务类型，你可以考虑趋势、关联、类别、分布等，从不同方面探索目标。对于数据变量，列出原始列名称。
- en: 'Indicator: {An example in JSON format} Output: {new tasks} —————————————————Historical
    context'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 指标：{JSON 格式的示例} 输出：{新任务} —————————————————历史背景
- en: 'Input: {goal, data, explored and unexplored tasks} Instruction: You need to
    supplement some new tasks for explored tasks by considering the results of tasks
    already explored if needed. Second, it is recommended that previous unexplored
    tasks be revisited if they are suitable for analysis at this stage by considering
    the explored tasks. Indicator: {An example in JSON format}'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：{目标、数据、已探索任务和未探索任务} 指令：如有需要，你需要根据已探索任务的结果为已探索任务补充一些新任务。其次，建议根据已探索任务，重新审视那些适合在此阶段进行分析的未探索任务。指标：{JSON
    格式的示例}
- en: 'Output: {new tasks, existing tasks to review}'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：{新任务、需要复审的现有任务}
- en: IV-A2 Task Execution
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 任务执行
- en: 'After tasks are proposed and confirmed by the user, the executor will solve
    tasks by generating codes ([Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-c). We then adopt the “decompose on-demand” strategy,
    which means we first execute the task and then decompose the task if the results
    are unsatisfactory. This approach allows users to obtain preliminary results quickly
    and enables a more flexible way to address both simple and complex tasks, avoiding
    unnecessary time cost that comes from always decomposing tasks in advance.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户提出任务并确认后，执行器将通过生成代码来解决任务（[图3](https://arxiv.org/html/2411.05651v1#S4.F3 "在IV
    LightVA系统中 ‣ LightVA：轻量级可视分析与LLM代理任务规划和执行")-c）。我们采用“按需分解”策略，意味着我们首先执行任务，然后在结果不理想时再进行任务分解。这种方法让用户能够快速获得初步结果，并且提供了更灵活的方式来处理简单和复杂的任务，避免了总是提前分解任务所带来的不必要时间成本。
- en: 'To execute a task, the input for the executor includes a goal, data, and task
    description, and the output includes visualizations and insights for the selected
    task (Prompt template [2](https://arxiv.org/html/2411.05651v1#ThmPrompt2 "Prompt
    Template 2 (Task Execution). ‣ IV-A2 Task Execution ‣ IV-A Agent-based Task Planning
    ‣ IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")). In the first round, two code snippets are generated:
    one for data analysis and the other for visualization. In the second round, structured
    insights are generated by data analysis results.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 执行任务时，执行器的输入包括目标、数据和任务描述，输出包括所选任务的可视化和洞察（提示模板 [2](https://arxiv.org/html/2411.05651v1#ThmPrompt2
    "提示模板 2（任务执行）。 ‣ IV-A2 任务执行 ‣ IV-A 基于代理的任务规划 ‣ IV LightVA 系统 ‣ LightVA：轻量级可视分析与LLM代理任务规划和执行")）。在第一轮中，生成两个代码片段：一个用于数据分析，另一个用于可视化。在第二轮中，通过数据分析结果生成结构化洞察。
- en: Prompt Template 2 (Task Execution).
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示模板 2（任务执行）。
- en: —————————————————-Code generation
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: —————————————————-代码生成
- en: 'Input: {task, data summary, code template}'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：{任务，数据总结，代码模板}
- en: 'Instruction: You need to write Python codes to analyze the data to solve this
    task. After finishing the data analysis, you should continue to use Altair to
    generate an interactive visualization. Add a brush or click function, a tooltip,
    and a legend if different colors are used. Indicator: {A code template}'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 指令：你需要编写Python代码来分析数据以解决该任务。在完成数据分析后，你应继续使用Altair生成交互式可视化。如果使用了不同的颜色，请添加刷选或点击功能、工具提示和图例。指标：{代码模板}
- en: '[⬇](data:text/plain;base64,aW1wb3J0IGFsdGFpciBhcyBhbHQKaW1wb3J0IHBhbmRhcyBhcyBwZApkZWYgcGxvdChkYXRhOiBwZC5EYXRhRnJhbWUpOgogICAgIyBEYXRhIHByZXByb2Nlc3NpbmcKICAgICAgICA8Y29kZXM+CiAgICAjIENoYXJ0IGdlbmVyYXRpb24KICAgIGNoYXJ0ID0gYWx0LkNoYXJ0KCkubWFya19iYXIoKS5lbmNvZGUoKQogICAgcmV0dXJuIGNoYXJ0)1import  altair  as  alt2import  pandas  as  pd3def  plot(data:  pd.DataFrame):4  #  Data  preprocessing5  <codes>6  #  Chart  generation7  chart  =  alt.Chart().mark_bar().encode()8  return  chart'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,aW1wb3J0IGFsdGFpciBhcyBhbHQKaW1wb3J0IHBhbmRhcyBhcyBwZApkZWYgcGxvdChkYXRhOiBwZC5EYXRhRnJhbWUpOgogICAgIyBEYXRhIHByZXByb2Nlc3NpbmcKICAgICAgICA8Y29kZXM+CiAgICAjIENoYXJ0IGdlbmVyYXRpb24KICAgIGNoYXJ0ID0gYWx0LkNoYXJ0KCkubWFya19iYXIoKS5lbmNvZGUoKQogICAgcmV0dXJuIGNoYXJ0)1import  altair  as  alt2import  pandas  as  pd3def  plot(data:  pd.DataFrame):4  #  数据预处理5  <codes>6  #  图表生成7  chart  =  alt.Chart().mark_bar().encode()8  return  chart'
- en: Output:{insight, visualization}
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：{洞察，可视化}
- en: ————————————-Structured insight generation
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ————————————-结构化洞察生成
- en: 'Input: {task, data, codes}'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：{任务，数据，代码}
- en: 'Instruction: Run the codes to report an important insight for this task: task.
    You should output insight, including text, insight type, parameters, data variables,
    and data values. {Definitions of insight attributes.} Indicator: {A few examples
    in JSON format}'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 指令：运行代码以报告该任务的重要洞察：任务。你应输出洞察，包括文本、洞察类型、参数、数据变量和数据值。{洞察属性的定义。} 指标：{一些JSON格式的示例}
- en: 'Output: {insight}'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：{洞察}
- en: 'Visualization generation: For each task, the model needs to implement data
    analysis and visualization methods, where one task corresponds to one visualization,
    and the visualizations will be combined into multiple views when multi-variables
    association analysis is required, which we will introduce later. We use Vega-Lite
    via Altair [[60](https://arxiv.org/html/2411.05651v1#bib.bib60)] to generate visualizations.
    Vega-Lite is a high-level grammar that can support the generation of a variety
    of visualization types in a low-code way, and its declarative structure allows
    users to modify visualizations easily. As Altair only supports basic data transformation,
    we leverage Python’s flexible libraries, allowing for more complex analysis, such
    as regression and clustering. However, this may introduce inconsistencies and
    errors between analysis and visualization code snippets. To address this, we provide
    a code scaffold in the prompt to let LLMs fill the empty to enhance consistency
    and improve output stability.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化生成：对于每个任务，模型需要实现数据分析和可视化方法，其中一个任务对应一个可视化，当需要进行多变量关联分析时，多个可视化将组合成多个视图，稍后我们将介绍这一点。我们通过
    Altair 使用 Vega-Lite [[60](https://arxiv.org/html/2411.05651v1#bib.bib60)] 来生成可视化。Vega-Lite
    是一种高阶语法，支持通过低代码方式生成各种可视化类型，其声明式结构使用户能够轻松修改可视化。由于 Altair 仅支持基本的数据转换，我们利用 Python
    的灵活库来进行更复杂的分析，例如回归分析和聚类分析。然而，这可能会在分析和可视化代码片段之间引入不一致和错误。为了解决这个问题，我们在提示中提供了代码框架，允许
    LLM 填充空缺，以增强一致性并提高输出稳定性。
- en: 'Structured insight generation: After generating visualization and modeling
    codes, the executor needs to execute them to structure the results into insights.
    As the agent’s coding environment¹¹1[https://platform.openai.com/docs/assistants/tools/code-interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter),
    Last accessed March 2024\. Code Interpreter allows Assistants to write and run
    Python code in a sandboxed execution environment. does not support Altair, we
    use the local environment to execute the visualization part of the code. The agent
    runs the data analysis part, interprets the results, and derives insights. We
    provide a format example according to our definition of insight in the framework
    to guide model output. This includes the insight description, the insight type,
    and the data variables and values. These attributes highlight key elements in
    the insight description to improve readability.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化洞察生成：在生成可视化和建模代码之后，执行者需要执行这些代码，将结果结构化为洞察。由于代理的编码环境¹¹1[https://platform.openai.com/docs/assistants/tools/code-interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter)，最后访问时间为2024年3月，Code
    Interpreter 允许助手在沙盒执行环境中编写和运行 Python 代码，但不支持 Altair，因此我们使用本地环境来执行代码中的可视化部分。代理运行数据分析部分，解释结果并推导出洞察。我们根据框架中对洞察的定义提供格式示例，以指导模型输出。这包括洞察描述、洞察类型以及数据变量和数值。这些属性突出了洞察描述中的关键元素，以提高可读性。
- en: 'Linked-view generation: For multi-variable association analysis, we enable
    the generation of multiple linked views ([Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-d). While LLMs can add interactivity and set basic
    colors and layouts within the code, maintaining visual consistency across views,
    such as avoiding duplicate colors and ensuring neat layouts, requires implementing
    additional constraints.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '关联视图生成：对于多变量关联分析，我们启用生成多个关联视图（[图3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-d）。虽然 LLM 可以在代码中添加交互性并设置基本的颜色和布局，但保持视图之间的视觉一致性，例如避免颜色重复和确保布局整洁，则需要实施额外的约束。'
- en: •
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interaction linking: To enable interaction linking among charts, we instruct
    the model to modify and combine the chart codes following several guidelines.
    First, ensure both charts contain common key columns with consistent data formats
    for the selection fields. Next, define the selection mechanisms. Common interaction
    methods include a brush on the time axis for the line chart, dual brushes for
    the scatter plot, and click interactions for the bar chart. Then, the transform
    filter should be applied to the other charts.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 交互链接：为了实现图表之间的交互链接，我们指导模型按照若干准则修改和组合图表代码。首先，确保两个图表都包含共同的关键列，并且选择字段的数据格式一致。接下来，定义选择机制。常见的交互方法包括线形图上的时间轴刷选、散点图上的双刷选，以及条形图上的点击交互。然后，变换筛选器应应用于其他图表。
- en: •
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Layout organization: When generating new visualizations, we set the charts
    to the same size and arrange them sequentially. If the user selects charts to
    merge multiple views, we allow selecting up to six charts to avoid excessive cognitive
    load. The LLMs should output the layout no more than three charts in a row.'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 布局组织：在生成新的可视化时，我们设置图表为相同大小，并按顺序排列。如果用户选择合并多个视图的图表，我们允许最多选择六个图表，以避免过度的认知负担。LLM
    应该输出的布局最多每行三个图表。
- en: •
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Color mapping: We built a data-to-color mapping rule within the task space
    based on Qu and Hullman’s guidelines [[30](https://arxiv.org/html/2411.05651v1#bib.bib30)],
    where one color corresponds to one data dimension without reuse. For example,
    the same field should use the same quantitative color scale across different views,
    while different fields should use non-overlapping hues or palettes to avoid confusion.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 色彩映射：我们在任务空间中基于 Qu 和 Hullman 的指南 [[30](https://arxiv.org/html/2411.05651v1#bib.bib30)]
    构建了一个数据到颜色的映射规则，其中每种颜色对应一个数据维度，且不重用。例如，同一领域应在不同视图中使用相同的定量色彩比例，而不同领域则应使用不重叠的色调或调色板，以避免混淆。
- en: 'Task progress calculation: In the analysis process, each node has a progress
    attribute that quantifies the task completion degree. When the task is executed,
    the agent evaluates the task’s completion status. If the task remains incomplete
    and needs further in-depth analysis, the progress is set to 0%; otherwise, it
    is set to 100%. Upon determining a task as incomplete, the agent suggests a decomposition
    plan. If the further decomposition is denied by the user, the progress is set
    to 100%. Each recently executed task is represented as a leaf node, initiating
    a bottom-up refresh of progress values for non-leaf nodes across the tree ([Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-e). The process for the main task is the average
    progress of two child tasks, which are user-confirmed nodes generated by task
    decomposition or recommendation. This hierarchical update process accurately reflects
    the analysis status and ensures progress values account for both the agent’s assessments
    and user input.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 任务进度计算：在分析过程中，每个节点都有一个进度属性，用于量化任务的完成度。当任务执行时，代理评估任务的完成状态。如果任务未完成且需要进一步深入分析，进度设置为
    0%；否则，进度设置为 100%。一旦任务被确定为未完成，代理会提出分解方案。如果用户拒绝进一步分解，进度设置为 100%。每个最近执行的任务都表示为叶节点，启动自底向上的进度值刷新，更新树中非叶节点的进度值
    ([图 3](https://arxiv.org/html/2411.05651v1#S4.F3 "在 IV LightVA 系统 ‣ LightVA：基于
    LLM 代理的轻量级可视分析与任务规划执行")-e)。主任务的进度为两个子任务的平均进度，这些子任务是用户确认的由任务分解或推荐生成的节点。这个分层更新过程准确反映了分析状态，并确保进度值既考虑了代理的评估，也包含了用户输入。
- en: '![Refer to caption](img/1a902ec916119735cf655891e02c206d.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1a902ec916119735cf655891e02c206d.png)'
- en: 'Figure 4: The LightVA system comprises four views. Users can communicate with
    LLMs and control the planning process in (A) Chat view by selecting the tasks
    or setting the decomposition plan. The generated visualization and insights from
    LLMs are updated in (B) Visualization view. Task flow view (C) visualizes the
    task planning structure and allows users to control the analysis process. When
    a task is completed, users check the data exploration situation in the Data table
    with table lens (D).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：LightVA 系统包含四个视图。用户可以在 (A) 聊天视图中与 LLM 进行互动并控制规划过程，选择任务或设置分解计划。LLM 生成的可视化和洞察信息会在
    (B) 可视化视图中更新。任务流程视图 (C) 展示任务规划结构，并允许用户控制分析过程。当任务完成时，用户可在数据表 (D) 的表格镜头中查看数据探索情况。
- en: IV-A3 Task Decomposition
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A3 任务分解
- en: 'Upon the execution of a task, the decomposer evaluates the quality of completion
    and decides whether to decompose and how (Prompt template [3](https://arxiv.org/html/2411.05651v1#ThmPrompt3
    "Prompt Template 3 (Task Decomposition). ‣ IV-A3 Task Decomposition ‣ IV-A Agent-based
    Task Planning ‣ IV LightVA System ‣ LightVA: Lightweight Visual Analytics with
    LLM Agent-Based Task Planning and Execution")). To evaluate if the task is completed,
    the input includes tasks, codes, and insight, while the output is a score ranging
    from 0 to 10 and an explanation. Then, if decomposition is needed (i.e., its score
    is below a certain threshold, like 8), a detailed decomposition plan with the
    appropriate logic operators will be proposed ([Fig. 3](https://arxiv.org/html/2411.05651v1#S4.F3
    "In IV LightVA System ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-f). Conversely, if no further decomposition is required,
    the controller calls the recommender to propose new exploratory tasks. According
    to the framework, the evaluation process can be guided by the following guidelines.
    The first is to determine if the initial solution adequately segments the data,
    ensuring that the analysis covers all relevant subsets. Second, assess if the
    task requires further data mining or visualization methods (e.g., regression,
    clustering) to extract deeper insights.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行任务时，分解器会评估任务完成的质量，并决定是否需要进一步分解以及如何分解（提示模板 [3](https://arxiv.org/html/2411.05651v1#ThmPrompt3
    "提示模板 3（任务分解）。 ‣ IV-A3 任务分解 ‣ IV-A 基于代理的任务规划 ‣ IV LightVA 系统 ‣ LightVA：基于大语言模型的轻量级视觉分析与任务规划与执行")).
    为了评估任务是否完成，输入包括任务、代码和洞察，而输出是一个从 0 到 10 的分数及解释。如果需要进一步分解（即分数低于某个阈值，如 8），将提出一个详细的分解计划，并采用适当的逻辑运算符（[图
    3](https://arxiv.org/html/2411.05651v1#S4.F3 "在 IV LightVA 系统 ‣ LightVA：基于大语言模型的轻量级视觉分析与任务规划与执行")-f）。相反，如果不需要进一步分解，控制器将调用推荐器来提出新的探索性任务。根据该框架，评估过程可以通过以下准则来指导。第一个是判断初步解决方案是否适当地划分了数据，确保分析覆盖所有相关子集。第二，评估任务是否需要进一步的数据挖掘或可视化方法（例如回归、聚类），以提取更深的洞察。
- en: Prompt Template 3 (Task Decomposition).
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示模板 3（任务分解）。
- en: ———————————————————–Is complete
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ———————————————————–已完成
- en: 'Input: {task, codes, insight}'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：{任务，代码，洞察}
- en: 'Instruction: You need to judge whether the task requires further analysis.
    The complexity of the task can be considered from data, data mining, and visualization
    methods. If the task appears incomplete, it needs to be decomposed further. Please
    rate the task from 1-10\. For example, if the initial solution adequately segments
    the data or if the task requires advanced statistical analysis. You should output
    a score and explanation for your evaluation. Indicator: {A output template in
    JSON format}'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 指令：你需要判断任务是否需要进一步分析。任务的复杂性可以从数据、数据挖掘和可视化方法中考虑。如果任务看起来不完整，则需要进一步分解。请对任务进行 1-10
    的评分。例如，如果初步解决方案适当地划分了数据，或任务需要高级统计分析。你应输出评分和解释。指示：{JSON 格式的输出模板}
- en: 'Output: {score, explanation}'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：{分数，解释}
- en: ———————————————————–Decompose
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ———————————————————–分解
- en: 'Input: {task, insight, score, explanation}'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：{任务，洞察，分数，解释}
- en: 'Instruction: This task requires further analysis. According to the score and
    explanation, please generate no more than n subtasks and indicate the methods
    they use respectively based on this. There are two operators AND and DOWN in the
    execution order to connect tasks. Indicator: {An example in JSON format}'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 指令：此任务需要进一步分析。根据评分和解释，请生成不超过 n 个子任务，并基于此分别指明它们所使用的方法。执行顺序中有两个运算符 AND 和 DOWN
    用于连接任务。指示：{JSON 格式的示例}
- en: 'Output: {subtasks, execution order}'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：{子任务，执行顺序}
- en: If a task requires decomposition, a depth-first decomposition process is employed.
    This process is guided by two factors. One is a predefined maximum decomposition
    step depth ($k_{max}$), managing the depth ($k$) of decomposition (decompose when
    $k<k_{max}$). Another factor is the completeness of subtasks. Here, we define
    each task that can be decomposed into subtasks with two types of logic.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任务需要分解，将采用深度优先的分解过程。该过程由两个因素指导。一个是预定义的最大分解深度 ($k_{max}$)，管理分解的深度 ($k$)（当 $k<k_{max}$
    时进行分解）。另一个因素是子任务的完整性。在这里，我们定义每个可以分解为子任务的任务，有两种类型的逻辑。
- en: •
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'AND: Subtasks are independent and executed in parallel order with multiple
    agents.'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AND：子任务是独立的，并与多个代理并行执行。
- en: •
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'DOWN: This is a particular AND case. Subtasks are dependent and will be executed
    in serial order with a single agent.'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'DOWN: 这是一个特定的**AND**案例。子任务是相互依赖的，将由单一代理按顺序执行。'
- en: 'We use an example to illustrate the decomposition process. If the task of analyzing
    vehicle weight and fuel efficiency is completed with a score of 6/10, the agent
    might suggest the following decompositions: T1: Segment the data into weight categories
    (light, medium, heavy) and analyze the fuel efficiency within each segment. T2:
    Within each weight category, conduct a clustering analysis to identify patterns
    or groupings that could further explain variations in fuel efficiency. T3: Perform
    a multiple regression analysis to control for additional variables like engine
    size and vehicle age. The execution logic would be (T1 DOWN T2 AND T3).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个示例来说明分解过程。如果分析车辆重量和燃油效率的任务完成，得分为6/10，代理可能会建议以下分解：T1：将数据分为重量类别（轻型、中型、重型），并分析每个类别中的燃油效率。T2：在每个重量类别内，进行聚类分析，以识别可能进一步解释燃油效率变化的模式或分组。T3：进行多元回归分析，控制发动机尺寸和车辆年龄等额外变量。执行逻辑为（T1
    DOWN T2 AND T3）。
- en: According to the logic, the agent executes each subtask and summarizes the subtasks’
    insights to formulate an overall insight for the decomposed task. No further decomposition
    is required if subtasks are all completed or up to the max steps. Then, considering
    the goal and analysis results, the agent might propose revisiting previously proposed
    tasks or recommending new exploration tasks.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 根据逻辑，代理会执行每个子任务，并总结子任务的见解，形成对分解任务的整体见解。如果所有子任务都完成或达到了最大步骤，则不需要进一步分解。然后，考虑到目标和分析结果，代理可能建议重新审视先前提出的任务或推荐新的探索任务。
- en: IV-B LightVA Interface
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B LightVA 界面
- en: 'The agent-based interface includes several views to enable user-controlled
    visual exploration, as shown in [Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution"). To enable this, we provide four views: Chat view, Visualization view,
    Task flow view, Data view. The design of the interaction follows the design considerations
    of [Section III-B](https://arxiv.org/html/2411.05651v1#S3.SS2 "III-B Design Requirements
    ‣ III LightVA Framework ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution") and provides three modes of interaction.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 基于代理的界面包含多个视图，允许用户进行可视化探索，如[图4](https://arxiv.org/html/2411.05651v1#S4.F4 "在
    IV-A2 任务执行 ‣ IV-A 基于代理的任务规划 ‣ IV LightVA 系统 ‣ LightVA：基于大语言模型代理的轻量级可视化分析与任务规划执行")所示。为了实现这一点，我们提供了四个视图：聊天视图、可视化视图、任务流程视图、数据视图。交互设计遵循[第III-B节](https://arxiv.org/html/2411.05651v1#S3.SS2
    "III-B 设计要求 ‣ III LightVA 框架 ‣ LightVA：基于大语言模型代理的轻量级可视化分析与任务规划执行")中的设计考虑，并提供三种交互模式。
- en: 'Chat view: The exploration begins with the Chat view ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")A), an LLM-based chat box that facilitates direct communication between
    users and agents through natural language interaction. The interaction between
    the user and agent can switch between delegate, guide, and discuss. In this interface,
    the user uploads data and inputs goals. The agent then responds with its understanding
    of the dataset and suggests new tasks in the form of buttons. Users can bookmark
    tasks of interest, and tasks that are not of interest will not be counted in the
    progress of exploration. The user can then execute a task by clicking on it. Additionally,
    users can enter their own tasks in the chat box. After submitting a task, the
    agent will provide a visualization of the production and insights obtained from
    the calculations in the Visualization view ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")B). If the task needs to be decomposed, the task decomposition plan
    will appear. The user can modify the logical relationship between the task and
    the execution plan by switching the text button. The agent will analyze the task
    based on the user’s instructions and return the results of multiple subtasks.
    During the exploration process, users can ask various questions and discuss them
    with LLM in the dialog box, such as the problem analysis method, understanding
    of the answer, and explanation for the recommendation.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '聊天视图：探索从聊天视图开始 ([图 4](https://arxiv.org/html/2411.05651v1#S4.F4 "In IV-A2 Task
    Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System ‣ LightVA: Lightweight
    Visual Analytics with LLM Agent-Based Task Planning and Execution")A)，这是一个基于LLM的聊天框，便于用户与代理通过自然语言交互进行直接沟通。用户与代理之间的互动可以在委托、引导和讨论三种模式间切换。在此界面中，用户上传数据并输入目标。代理随后会根据其对数据集的理解，并以按钮的形式建议新的任务。用户可以收藏感兴趣的任务，而不感兴趣的任务不会计入探索的进度。用户可以通过点击任务来执行它。此外，用户还可以在聊天框中输入自己的任务。提交任务后，代理会在可视化视图中提供该任务的生成可视化和计算得到的洞察 ([图
    4](https://arxiv.org/html/2411.05651v1#S4.F4 "In IV-A2 Task Execution ‣ IV-A Agent-based
    Task Planning ‣ IV LightVA System ‣ LightVA: Lightweight Visual Analytics with
    LLM Agent-Based Task Planning and Execution")B)。如果任务需要被分解，则会显示任务分解计划。用户可以通过切换文本按钮来修改任务与执行计划之间的逻辑关系。代理会根据用户的指示分析任务，并返回多个子任务的结果。在探索过程中，用户可以在对话框中提出各种问题，并与LLM讨论，如问题分析方法、对答案的理解以及推荐的解释。'
- en: 'Visualization view: This view presents visualizations and insights in the form
    of cards. Each card contains the task serial number, the task content, the interactive
    visualizations, and the insights in rich text format. Users can modify the Vega-Lite
    JSON codes and insight text. To address the issue of cognitive load for the user,
    we allow the user to select which visualization cards they want to view, and these
    selected cards are displayed in the main view while the remaining cards are moved
    to the candidate set below. Additionally, the user can merge the selected cards
    to create an interactive linked view. Moreover, users can modify and export the
    generated codes, which providing flexibility for those who need to customize their
    analyses further.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化视图：此视图以卡片的形式展示可视化和洞察。每张卡片包含任务序号、任务内容、交互式可视化以及富文本格式的洞察。用户可以修改Vega-Lite JSON代码和洞察文本。为了解决用户的认知负担问题，我们允许用户选择希望查看的可视化卡片，这些选中的卡片会显示在主视图中，而其余的卡片则移至下面的候选集。此外，用户还可以合并选中的卡片，创建一个交互式的链接视图。用户可以修改并导出生成的代码，为需要进一步定制分析的用户提供灵活性。
- en: 'Task flow view: The task flow view updates as goals and tasks are added, providing
    the user with a clear analysis of status and progress ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")C). Each node is a rectangular box showing the task id, task type,
    and percent progress. The original task text appears when the cursor is over a
    node. Clicking on a node will update the visualization layout in the Visualization
    view. Hovering over the edge can see the differences in data and task type between
    the associated nodes. In accordance with design considerations, we allow users
    to choose unexplored tasks to be executed and delegate them to the agent. Additionally,
    users can remove pending tasks from the flow to reduce workload. A clear exploration
    structure may inspire user’s ideas.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 任务流视图：任务流视图会随着目标和任务的添加而更新，为用户提供任务状态和进度的清晰分析（[图 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "在 IV-A2 任务执行 ‣ IV-A 基于代理的任务规划 ‣ IV LightVA 系统 ‣ LightVA：基于 LLM 代理的轻量级可视分析与任务规划和执行")C）。每个节点都是一个矩形框，显示任务
    ID、任务类型和进度百分比。当光标悬停在节点上时，会显示原始任务文本。点击节点将更新可视化布局中的可视化视图。将鼠标悬停在边缘上可以查看关联节点之间的数据和任务类型的差异。根据设计考虑，我们允许用户选择未探索的任务进行执行，并将其委派给代理。此外，用户还可以从任务流中移除待处理任务，以减少工作负载。清晰的探索结构可能会激发用户的创意。
- en: 'Data table view: In addition to task visualization, we provide a data lens
    visualization in Data table view ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")D) to guide users in the large exploration space. When a task is being
    completed, the user can observe the exploration of the accumulated data usage
    frequency in table lens mode. The color of the table cell represents the relative
    frequency of each cell being explored. This observation may inspire the user to
    discover regions of interest to propose new questions.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表视图：除了任务可视化外，我们还提供了数据表视图中的数据透镜可视化（[图 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "在 IV-A2 任务执行 ‣ IV-A 基于代理的任务规划 ‣ IV LightVA 系统 ‣ LightVA：基于 LLM 代理的轻量级可视分析与任务规划和执行")D），以引导用户在广阔的探索空间中进行操作。当任务正在完成时，用户可以观察在表格透镜模式下积累的数据使用频率的探索情况。表格单元格的颜色表示每个单元格被探索的相对频率。这种观察可能会激发用户发现感兴趣的区域，从而提出新的问题。
- en: IV-C Error Handling
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 错误处理
- en: We refer to errors as issues that cause the system to crash or become unresponsive.
    Due to the inherent unpredictability of LLM outputs, errors may occur if the outputs
    cannot be parsed correctly, causing the system to crash or become unresponsive.
    To ensure the system operates correctly and prevents workflow disruptions, we
    implement an error-handling mechanism.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将错误定义为导致系统崩溃或无响应的问题。由于 LLM 输出本质上的不可预测性，如果输出无法正确解析，就可能发生错误，导致系统崩溃或无响应。为了确保系统正确运行并防止工作流中断，我们实现了错误处理机制。
- en: 'To develop an effective error-handling mechanism, we conducted a test using
    two datasets in expert evaluation with 20 agent-opposed tasks, employing both
    GPT-3.5-turbo and GPT-4-turbo. Each task was tested with code generation and insight
    annotation, utilizing two different prompting techniques. This resulted in a total
    of 160 initial tests. We classified the errors in the test into five categories:
    (1) Unfamiliar dataset, (2) Data binding issues, (3) Serialization issues, (4)
    Data transformation issues, (5) Syntax errors. More details about the test can
    be found in Appendix B. To address these types of errors effectively, we implemented
    specific error-handling strategies in three ways: before model generation with
    prompting techniques, within the system after generation, or delegated to users.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发有效的错误处理机制，我们进行了一个测试，使用了两个数据集，并通过专家评估了 20 个与代理对立的任务，采用了 GPT-3.5-turbo 和 GPT-4-turbo
    两种模型。每个任务都进行了代码生成和洞察注释的测试，使用了两种不同的提示技术，共进行了 160 次初始测试。我们将测试中的错误分为五类：（1）不熟悉的数据集，（2）数据绑定问题，（3）序列化问题，（4）数据转换问题，（5）语法错误。更多关于测试的细节请参见附录
    B。为有效应对这些类型的错误，我们在三种方式中实现了特定的错误处理策略：在模型生成之前使用提示技术，在生成后在系统内处理，或委托给用户。
- en: 'Prompting techniques: (1) Few-shot prompting[[61](https://arxiv.org/html/2411.05651v1#bib.bib61)]:
    We provide examples to assist the model in better grasping the requirements of
    the outputs. For example, when making insight annotations, examples can explain
    the insight components of the model. (2) Chain-of-thoughts [[52](https://arxiv.org/html/2411.05651v1#bib.bib52)]:
    We guide the model through a thought plan with step-by-step instructions, which
    is helpful in reasoning processes, such as task execution.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 提示技术：（1）少量提示[[61](https://arxiv.org/html/2411.05651v1#bib.bib61)]：我们提供示例来帮助模型更好地理解输出的要求。例如，在进行洞察注释时，示例可以解释模型的洞察组成部分。（2）思维链[[52](https://arxiv.org/html/2411.05651v1#bib.bib52)]：我们通过一步步的指令引导模型进行思维计划，这对于推理过程（如任务执行）非常有帮助。
- en: 'Within system handling: (1) Self-reflection[[62](https://arxiv.org/html/2411.05651v1#bib.bib62)]:
    We allow LLMs to examine and correct their actions and outputs. For example, the
    model should debug codes based on the observation of the error. Based on our test
    results, the self-correction helped reduce around 40% initially identified errors,
    such as syntax errors, spelling mistakes, and logical inconsistencies. (2) Catching
    and feedback: Common syntax errors such as matching quotes and parentheses, can
    be solved by rule-based solutions. We classify these common errors to highlight
    which steps in the data analysis process the LLM made mistakes rather than merely
    pointing out low-level errors.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 系统内部处理：（1）自我反思[[62](https://arxiv.org/html/2411.05651v1#bib.bib62)]：我们允许LLMs检查并纠正其行为和输出。例如，模型应该根据错误的观察来调试代码。根据我们的测试结果，自我纠正帮助减少了大约40%的初始识别错误，如语法错误、拼写错误和逻辑不一致。（2）捕捉与反馈：常见的语法错误，如引号和括号匹配问题，可以通过基于规则的解决方案来解决。我们对这些常见错误进行分类，以突出LLM在数据分析过程中的错误步骤，而不仅仅是指出低级错误。
- en: 'User-side handling: Once errors are identified, the system notifies the user,
    and the user may edit the codes. Additionally, we maintain the analysis history,
    allowing for a rollback to the previous step if an error occurs during the execution
    of the current task. Users can choose a new task and remove the failed task from
    the task flow.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 用户端处理：一旦识别出错误，系统会通知用户，用户可以编辑代码。此外，我们会维护分析历史记录，如果当前任务执行过程中发生错误，可以回滚到上一步。用户可以选择新的任务，并将失败的任务从任务流程中移除。
- en: 'V Usage scenario: Event Analysis'
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 使用场景：事件分析
- en: To examine the effectiveness of our framework, we demonstrate the LightVA with
    IEEE VAST Challenge 2021 Mini-Challenge 3 ²²2[https://vast-challenge.github.io/2021/MC3.html](https://vast-challenge.github.io/2021/MC3.html)
    as a usage scenario. The challenge’s goal is to detect events that happened in
    Abila City during the evening of January 23, 2014\. The provided data include
    microblog records and emergency dispatch records from a call center. Our motivation
    for this scenario stems from two reasons. Firstly, it incorporates a representative
    blend of data types and corresponding visualizations, encompassing text, spatial,
    and temporal data, which is a typical VA scenario. Secondly, the VAST challenge
    has the ground truth to support an objective evaluation of our LightVA. We use
    the OpenAI GPT-4 model in our work. For a more detailed demonstration of this
    scenario, a video is added to the supplemental materials.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检验我们的框架的有效性，我们展示了使用IEEE VAST Challenge 2021 Mini-Challenge 3 ²²2[https://vast-challenge.github.io/2021/MC3.html](https://vast-challenge.github.io/2021/MC3.html)作为使用场景。该挑战的目标是在2014年1月23日晚上，检测发生在Abila市的事件。提供的数据包括来自呼叫中心的微博记录和紧急调度记录。我们选择这个场景的动机有两个原因。首先，它涵盖了具有代表性的多种数据类型和相应的可视化方式，包括文本、空间和时间数据，这是一个典型的VA场景。其次，VAST挑战提供了地面实况数据，以支持对我们LightVA的客观评估。我们的工作中使用了OpenAI的GPT-4模型。为了更详细地展示这一场景，我们在补充材料中附加了一个视频。
- en: 'Initialization: In the beginning, we upload a dataset .csv file and a map outline
    data .json file at the Chat view. Then, we type a goal, “find some high-risk events
    in this city”. The dataset is introduced briefly, and the system proposes four
    initial exploration tasks based on our goal: sentiment analysis, keyword analysis,
    tags analysis, and spatial analysis ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-a1). As the four tasks are aligned with our objectives, we bookmark
    them all in our progress. We then prioritize the exploration of the first task
    - sentiment analysis. Upon submission, the agent generates a time varying card
    at the Visualization view ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-B). The generated insight for sentiment analysis indicates that the
    microblog records has experienced a drop in average sentiment, especially with
    a minimum polarity in 19:20, indicating potentially dangerous events ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-b1).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化：在开始时，我们在聊天视图中上传一个数据集 `.csv` 文件和一个地图轮廓数据 `.json` 文件。然后，我们输入一个目标：“在这个城市中找到一些高风险事件”。数据集被简要介绍，系统根据我们的目标提出了四个初步的探索任务：情感分析、关键词分析、标签分析和空间分析
    ([图4](https://arxiv.org/html/2411.05651v1#S4.F4 "在 IV-A2 任务执行 ‣ IV-A 基于代理的任务规划
    ‣ IV LightVA 系统 ‣ LightVA：基于 LLM 代理的轻量级视觉分析与任务规划执行")-a1)。由于这四个任务与我们的目标一致，我们将它们全部标记在进度中。接下来，我们优先探索第一个任务——情感分析。提交后，代理在可视化视图中生成一个时间变化卡片
    ([图4](https://arxiv.org/html/2411.05651v1#S4.F4 "在 IV-A2 任务执行 ‣ IV-A 基于代理的任务规划
    ‣ IV LightVA 系统 ‣ LightVA：基于 LLM 代理的轻量级视觉分析与任务规划执行")-B)。生成的情感分析洞察表明，微博记录的平均情感值下降，特别是在19:20时，极性达到最低，表明可能发生危险事件
    ([图4](https://arxiv.org/html/2411.05651v1#S4.F4 "在 IV-A2 任务执行 ‣ IV-A 基于代理的任务规划
    ‣ IV LightVA 系统 ‣ LightVA：基于 LLM 代理的轻量级视觉分析与任务规划执行")-b1)。
- en: '![Refer to caption](img/e0e72bd2880e5ac89f0f33568198319a.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/e0e72bd2880e5ac89f0f33568198319a.png)'
- en: 'Figure 5: A linked view for event analysis. The timeline, histograms, and map
    are selected by the user to generate a linked view. The charts can be brushed
    or clicked to filter each other (a). The polarity, tags, and message can be found
    in the tooltip (b) of each view to support detailed analysis. By interactively
    exploring the linked views (c, d), we find some dangerous events, such as “Hit
    and run”, “Standoff”, “Fire”.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：事件分析的联动视图。用户选择时间轴、柱状图和地图来生成联动视图。图表可以通过刷选或点击进行相互过滤（a）。每个视图的工具提示（b）中可以找到极性、标签和消息，以支持详细分析。通过交互式探索联动视图（c,
    d），我们发现了一些危险事件，如“肇事逃逸”、“对峙”、“火灾”。
- en: 'Task recommendation: The agent not only generates the visualization and findings
    but also evaluates them. For this sentiment analysis task, the agent gives a score
    of 8/10 and explains that the generated results have basically completed the task,
    but further statistical analysis can be performed ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-a3). As we prefer to start with a broad overview, we decide not to
    decompose. The agent thus reminds us to revisit our previous collection tasks
    in time. Thus, we choose the second task (keyword analysis), which involves generating
    a preliminary keyword visualization. The generated finding summarizes the highly
    frequent words such as “fire”, “police”, and “POK”. In addition to the agent’s
    finding, clicking over the stacked histogram for task 11 shows the time range
    of each word. For example, the “shooting” from 19:40 until 19:50 and “abilafire”
    from 19:00 until 21:30. These findings suggest high-risk incidents like shootings
    and fires at first glance. The agent then recommends spatial analysis. From the
    Data table with lens, we can notice that there is indeed no latitude and longitude
    explored so far, which indicates that agent recommendation can pay attention to
    the data coverage ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4 "In IV-A2
    Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System ‣ LightVA:
    Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-D).
    After execution, the system generates a map with shapes and messages, and the
    decomposition structure is updated on the Task flow ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-c1). We observe a higher concentration of microblogs in two specific
    locations, which might indicate incidents affecting public safety in those areas ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-b2).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '任务推荐：该代理不仅生成可视化和结果，还会进行评估。对于这项情感分析任务，代理给出了8/10的评分，并解释说生成的结果基本完成了任务，但可以进一步进行统计分析（[图4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-a3）。由于我们倾向于从广泛的概述开始，因此决定不进行分解。因此，代理提醒我们及时回顾之前的收集任务。于是，我们选择了第二个任务（关键词分析），其内容包括生成初步的关键词可视化。生成的结果总结了诸如“fire”、“police”和“POK”等高频词汇。除了代理的发现，点击任务11的堆叠直方图显示了每个词的时间范围。例如，“shooting”发生在19:40到19:50之间，而“abilafire”则从19:00到21:30。初看这些结果似乎表明了高风险事件，如枪击和火灾。代理随后建议进行空间分析。从带有镜头的数据表中，我们可以注意到目前为止并未探索纬度和经度，这表明代理的推荐可以关注数据的覆盖范围（[图4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-D）。执行后，系统生成了带有形状和信息的地图，且任务流程中的分解结构得到更新（[图4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-c1）。我们观察到在两个特定地点的微博数量较为集中，这可能表明这些区域发生了影响公共安全的事件（[图4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-b2）。'
- en: 'Task decomposition: Based on the assessment of tasks and preliminary results,
    the agent recommends further decomposition with three subtasks: clustering analysis,
    hotspots detection, and prediction modeling, with an AND and DOWN logic ([Fig. 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "In IV-A2 Task Execution ‣ IV-A Agent-based Task Planning ‣ IV LightVA System
    ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and
    Execution")-a3). To conduct a retrospective analysis, we choose the first two
    subtasks. The cluster analysis combines location and polarity to divide messages
    on the map into five categories. We find that two places on the left and right
    sides of the map have a distinct sentiment distribution. The second sub-task,
    through analyzing message quantity, highlights hotspots, visually indicating areas
    with dense messages.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 任务分解：根据任务评估和初步结果，智能体建议进一步分解为三个子任务：聚类分析、热点检测和预测建模，采用“与”与“下降”逻辑（[图 4](https://arxiv.org/html/2411.05651v1#S4.F4
    "在 IV-A2 任务执行 ‣ IV-A 基于智能体的任务规划 ‣ IV LightVA 系统 ‣ LightVA：基于 LLM 智能体的轻量级可视化分析与任务规划和执行")-a3）。为了进行回顾性分析，我们选择了前两个子任务。聚类分析结合位置和情感极性，将地图上的信息分为五类。我们发现地图左右两侧有两个地方具有明显的情感分布。第二个子任务，通过分析信息量，突出了热点区域，直观地标示出消息密集的区域。
- en: 'Linked-view analysis: Based on the suggestion of the agent, we can form the
    analytical logic from multi-variables to concrete details. To find events more
    clearly, we select three tasks from the task flow view. The tasks include sentiment
    evolution charts, tag evolution charts, and a map to form an interactive multi-view ([Fig. 5](https://arxiv.org/html/2411.05651v1#S5.F5
    "In V Usage scenario: Event Analysis ‣ LightVA: Lightweight Visual Analytics with
    LLM Agent-Based Task Planning and Execution")). Through interaction on line chart ([Fig. 5](https://arxiv.org/html/2411.05651v1#S5.F5
    "In V Usage scenario: Event Analysis ‣ LightVA: Lightweight Visual Analytics with
    LLM Agent-Based Task Planning and Execution")-a), we observe the histogram and
    map and discover that around 19:20, a “hit-and-run” event occurs: a “black van”
    first collides with a small car and then a cyclist, sparking a lot of discussions ([Fig. 5](https://arxiv.org/html/2411.05651v1#S5.F5
    "In V Usage scenario: Event Analysis ‣ LightVA: Lightweight Visual Analytics with
    LLM Agent-Based Task Planning and Execution")-b, c). Additionally, we find that
    the fire occurred near the hit-and-run site. Later, we find that the black van
    heads west by 19:44, and a shooting occurs with the police, marking the period
    with the highest discussion intensity. Finally, at 21:17, the van guys surrender.
    By observing the table and task flow, we find that the progress of the goal reached
    100%, and the data is basically covered, “type” “latitude” and “longitude” were
    explored frequently.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 联动视图分析：根据智能体的建议，我们可以从多变量到具体细节形成分析逻辑。为了更清晰地找到事件，我们从任务流视图中选择了三个任务。这些任务包括情感演变图、标签演变图和一张地图，形成一个互动的多视图（[图 5](https://arxiv.org/html/2411.05651v1#S5.F5
    "在 V 使用场景：事件分析 ‣ LightVA：基于 LLM 智能体的轻量级可视化分析与任务规划和执行")）。通过在折线图上的互动（[图 5](https://arxiv.org/html/2411.05651v1#S5.F5
    "在 V 使用场景：事件分析 ‣ LightVA：基于 LLM 智能体的轻量级可视化分析与任务规划和执行")-a），我们观察到直方图和地图，发现大约在19:20发生了“肇事逃逸”事件：“黑色面包车”首先撞上了一辆小车，然后撞上了一名骑自行车的人，激起了大量讨论（[图 5](https://arxiv.org/html/2411.05651v1#S5.F5
    "在 V 使用场景：事件分析 ‣ LightVA：基于 LLM 智能体的轻量级可视化分析与任务规划和执行")-b, c）。此外，我们还发现火灾发生在肇事逃逸地点附近。随后，我们发现黑色面包车在19:44时向西行驶，并与警方发生了枪战，标志着讨论强度最高的时期。最后，在21:17，面包车上的人投降。通过观察表格和任务流，我们发现目标的进度达到了100%，数据基本覆盖，“类型”、“纬度”和“经度”被频繁探索。
- en: To conclude, in this scenario, we find significant events such as Fire, Hit
    and Run, and Stand-off without manually coding and designing. With task planning,
    we generate eight views with auto-summarized findings based on statistical analysis
    and a linked view to solve the goal rapidly. Compared to our submission to the
    VAST Challenge [[63](https://arxiv.org/html/2411.05651v1#bib.bib63)], where we
    spent 2 people, 2 days, and 6 hours on data preprocessing (including tagging,
    categorizing, and removing spam messages) plus 2 people, 7 days, and 6 hours on
    interface construction and analysis, totaling around 108 hours. In LightVA, we
    upload the preprocessed data. Further construction and analysis take roughly 1
    hour. This represents an efficiency increase of approximately 5 times, as the
    current effort is 25 out of 108 hours. Moreover, it is worth noting that data
    wrangling still require human involvement, especially in complex scenarios. One
    potential avenue would be to integrate agent-assisted data annotation and cleaning
    into LightVA’s workflow. In addition, there may be a lack of finesse and aesthetic
    appeal in interface visualizations and interactions when compared to manual designs.
    Despite this, the overall cost-effectiveness has been enhanced. To address this
    concern, we offer support for exporting the code, which can be further modified
    as needed.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在这个场景中，我们发现了显著的事件，如火灾、肇事逃逸和对峙，而无需手动编码和设计。通过任务规划，我们基于统计分析生成了八个视图，并通过链接视图快速解决目标。与我们提交给VAST挑战赛[[63](https://arxiv.org/html/2411.05651v1#bib.bib63)]的情况相比，当时我们花费了2人、2天、6小时进行数据预处理（包括标注、分类和删除垃圾信息），再加上2人、7天、6小时进行界面构建和分析，总共大约108小时。在LightVA中，我们上传预处理过的数据，进一步的构建和分析大约需要1小时。这代表了效率的提升，约为5倍，因为当前的工作量是108小时中的25小时。此外，值得注意的是，数据处理仍然需要人工参与，尤其是在复杂场景中。一种潜在的解决方案是将代理协助的数据标注和清理集成到LightVA的工作流程中。另外，与手动设计相比，界面可视化和交互可能缺乏精致感和美学吸引力。尽管如此，总体的性价比得到了提升。为了应对这一问题，我们提供了支持导出代码的功能，可以根据需要进一步修改。
- en: VI Expert Study
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI专家研究
- en: To examine the effectiveness of LightVA in VA system construction and task recommendation,
    we invited two VA experts (denoted as E1 and E2) and a domain expert (denoted
    as E3) to participate in the study. These experts have experience in data analysis
    and are familiar with using VA systems.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检验LightVA在VA系统构建和任务推荐中的有效性，我们邀请了两位VA专家（分别标记为E1和E2）和一位领域专家（标记为E3）参与了研究。这些专家在数据分析方面有经验，并且熟悉使用VA系统。
- en: 'Participants background: E1 is a VA expert specializing in VA system development,
    topics around digital humanities, text-based data, road data for autonomous driving,
    spatiotemporal datasets, and tabular data. E1 often uses D3.js and Vue.js to develop
    VA systems. E2 is a VA expert with experience in autonomous driving and social
    media, as well as work experience in business analysis. In daily work, E2 chooses
    to use tools like Tableau within the company to analyze quantitative data. The
    frequency of using data analysis and visualization tools is about weekly. E3 is
    a domain expert analyzing data for fast-moving consumer goods and supply chains.
    E3 frequently uses Excel and Power BI and occasionally uses Python for in-depth
    analysis. The use of data analysis and visualization tools occurs on a daily basis.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者背景：E1是一位专注于VA系统开发的VA专家，研究领域包括数字人文学科、基于文本的数据、自动驾驶的道路数据、时空数据集和表格数据。E1经常使用D3.js和Vue.js开发VA系统。E2是一位具有自动驾驶和社交媒体经验的VA专家，并且有商务分析的工作经验。在日常工作中，E2选择使用Tableau等工具进行定量数据分析。数据分析和可视化工具的使用频率大约为每周一次。E3是一位分析快速消费品和供应链数据的领域专家。E3经常使用Excel和Power
    BI，偶尔使用Python进行深入分析。数据分析和可视化工具的使用频率为每天一次。
- en: 'Procedure: The study consists of three sessions. First, we spent 15 minutes
    to know the experts’ backgrounds in data analysis and introduced our work by showing
    the video demonstration. Then, in the exploration phase, the experts spend about
    30 minutes exploring the system using the think-aloud method [[64](https://arxiv.org/html/2411.05651v1#bib.bib64)].
    Considering E3’s daily work requirements and aligning with their domain expertise,
    we opted for a dataset that mirrors their routine tasks. Due to data confidentiality
    concerns, we substituted the original dataset with a comparable one related to
    sales for E3’s use. Meanwhile, the automotive dataset was designated for exploration
    by E1 and E2, fitting their respective areas of expertise. During the system usage
    stage, we observed and recorded how they interacted with the LightVA system. In
    the final stage of the interview, we spent approximately 30 minutes gathering
    the experts’ feedback on their usage experience of the system.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 程序：本研究包括三个阶段。首先，我们花了15分钟了解专家们在数据分析方面的背景，并通过展示视频演示介绍了我们的工作。接着，在探索阶段，专家们花了大约30分钟使用“边思考边说”方法探索系统[[64](https://arxiv.org/html/2411.05651v1#bib.bib64)]。考虑到E3的日常工作需求，并与其领域专业对接，我们选择了一个与他们日常任务相似的数据集。由于数据保密问题，我们用一个与销售相关的可比数据集替代了原始数据集供E3使用。同时，汽车数据集被指定供E1和E2探索，符合他们各自的专业领域。在系统使用阶段，我们观察并记录了他们与LightVA系统的互动过程。在最后的访谈阶段，我们花了大约30分钟收集专家们对系统使用体验的反馈。
- en: 'VI-A Visual Analytics Expert Evaluation: Cars Dataset'
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 视觉分析专家评估：汽车数据集
- en: In this study, we evaluate LightVA with E1 and E2 using a well-known Auto MPG
    dataset ³³3[http://archive.ics.uci.edu/ml/datasets/Auto+MPG](http://archive.ics.uci.edu/ml/datasets/Auto+MPG).
    The dataset has 406 records and 9 attributes, including brand, model, performance
    indicators (such as horsepower and cylinders), and the year of manufacture and
    place of origin.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们使用著名的Auto MPG数据集³³3[http://archive.ics.uci.edu/ml/datasets/Auto+MPG](http://archive.ics.uci.edu/ml/datasets/Auto+MPG)对LightVA进行了E1和E2的评估。该数据集包含406条记录和9个属性，包括品牌、型号、性能指标（如马力和气缸数）、以及制造年份和原产地。
- en: '![Refer to caption](img/3dfd09965ee7eae6fde51a9b21da76a1.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3dfd09965ee7eae6fde51a9b21da76a1.png)'
- en: 'Figure 6: The illustrations of the expert study using our framework with cars
    dataset. Two VA experts show different analysis preferences during the exploration
    process. (A) E1 focuses on the creation of VA, progressively decomposing the goal
    and employing statistical methods to complete the exploration. (B) E2 has a clear
    goal during the analysis, and continuously optimizes the goal with task decomposition,
    and leverages the linked-view interactions to find a satisfactory answer.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：使用我们框架的专家研究插图，数据集为汽车数据集。两位VA专家在探索过程中表现出不同的分析偏好。（A）E1专注于VA的创建，逐步分解目标，并使用统计方法完成探索。（B）E2在分析过程中有明确的目标，并通过任务分解不断优化目标，利用联动视图交互找到满意的答案。
- en: 'During the exploration process, E1 is more concerned with the construction
    of the VA system. At the beginning, E1 sets the analytical goal to identify the
    factors influencing fuel efficiency. E1 chooses one of the initially proposed
    tasks for execution. After completing that task, the agent presents a detailed
    decomposition plan. E1 then follows the agent’s guidance to continue selecting
    subsequent sub-tasks for further decomposition and in-depth analysis. In the generated
    visualization ([Fig. 6](https://arxiv.org/html/2411.05651v1#S6.F6 "In VI-A Visual
    Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣ LightVA: Lightweight
    Visual Analytics with LLM Agent-Based Task Planning and Execution")-a1), E1 discovers
    the differences in the distribution of the number of vehicles produced by different
    origins across various performance ranges in the bar chart on the right, by utilizing
    the area brushing feature on the scatter plot. E1 also discovers the performance
    differences between cars with different numbers of cylinders through the filter
    functionality between linked view ([Fig. 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-a2).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '在探索过程中，E1 更关注 VA 系统的构建。一开始，E1 设置了分析目标，即识别影响燃油效率的因素。E1 从最初提出的任务中选择一个进行执行。在完成该任务后，智能体提供了详细的分解计划。随后，E1
    按照智能体的指导继续选择后续子任务进行进一步分解和深入分析。在生成的可视化图表中（[图 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-a1），E1
    通过利用散点图上的区域刷选功能，发现了不同来源车辆在各种性能区间内生产数量的分布差异。在通过关联视图的过滤功能（[图 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-a2）查看时，E1
    还发现了不同气缸数量的汽车在性能上的差异。'
- en: 'Another expert E2, demonstrates a focused interest in the data analysis, pursuing
    a clear analytical goal that was refined throughout the analysis process. Initially,
    E2’s goal was to identify vehicles that excel both in fuel efficiency and performance ([Fig. 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-b1).
    However, recommended insights revealed a strong negative correlation between fuel
    efficiency (measured in MPG) and the majority of performance metrics, indicating
    a trade-off between high fuel efficiency and superior performance capabilities.
    This insight led E2 to quickly adjust the analytical goal towards prioritizing
    fuel efficiency while ensuring performance was not significantly compromised ([Fig. 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-b2).
    Based on the plan proposed in task decomposition, E2 explored the relationship
    between various vehicle performance metrics and fuel efficiency with five charts.
    Finally, E2 combined these charts to generate linked view ([Fig. 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-b3).
    By filtering points across views, E2 found several vehicle models meeting the
    revised goal.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '另一位专家 E2 表现出对数据分析的专注兴趣，并在整个分析过程中逐步细化了明确的分析目标。最初，E2 的目标是识别在燃油效率和性能方面都表现出色的车辆（[图
    6](https://arxiv.org/html/2411.05651v1#S6.F6 "In VI-A Visual Analytics Expert
    Evaluation: Cars Dataset ‣ VI Expert Study ‣ LightVA: Lightweight Visual Analytics
    with LLM Agent-Based Task Planning and Execution")-b1）。然而，推荐的见解揭示了燃油效率（以 MPG 衡量）与大多数性能指标之间存在强烈的负相关关系，这表明高燃油效率与卓越性能之间存在权衡。这一见解促使
    E2 快速调整分析目标，优先考虑燃油效率，同时确保性能不会显著下降（[图 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-b2）。根据任务分解中提出的计划，E2
    使用五个图表探索了各个车辆性能指标与燃油效率之间的关系。最后，E2 将这些图表结合，生成了关联视图（[图 6](https://arxiv.org/html/2411.05651v1#S6.F6
    "In VI-A Visual Analytics Expert Evaluation: Cars Dataset ‣ VI Expert Study ‣
    LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution")-b3）。通过跨视图过滤数据点，E2
    找到了几款符合调整后目标的车辆模型。'
- en: 'VI-B Domain Expert Evaluation: Sales Dataset'
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 领域专家评估：销售数据集
- en: To further evaluate LightVA, we conducted another study with a domain expert.
    E3 was interested in a sales dataset for a large store that provides detailed
    transaction information ⁴⁴4[https://www.kaggle.com/datasets/addhyay/superstore-dataset](https://www.kaggle.com/datasets/addhyay/superstore-dataset).
    The dataset contains 3,312 records with 21 fields, e.g., sales, discount, profit,
    and category.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步评估LightVA，我们与领域专家进行了另一项研究。E3对一个大型商店的销售数据集感兴趣，该数据集提供了详细的交易信息⁴⁴4[https://www.kaggle.com/datasets/addhyay/superstore-dataset](https://www.kaggle.com/datasets/addhyay/superstore-dataset)。该数据集包含3,312条记录，涵盖21个字段，例如销售额、折扣、利润和类别。
- en: 'At the beginning, E3 mentioned the high-time sensitivity of sales data for
    products in real-world scenarios. Therefore, in the initial tasks, E3 opted to
    explore the temporal trends of product sales volumes. In the histogram and insight
    ([Fig. 7](https://arxiv.org/html/2411.05651v1#S6.F7 "In VI-C Results and Analysis
    ‣ VI Expert Study ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-a1) suggested by the agent, E3 found that the overall
    sales of the item differ significantly from month to month. In the next step of
    the decomposition plan, E3 categorized the products to explore the temporal trends
    of different categories ([Fig. 7](https://arxiv.org/html/2411.05651v1#S6.F7 "In
    VI-C Results and Analysis ‣ VI Expert Study ‣ LightVA: Lightweight Visual Analytics
    with LLM Agent-Based Task Planning and Execution")-a2). It was found that the
    temporal trends of the different categories were broadly similar, but the total
    sales volume of the technology category in November was the highest. Moreover,
    following the agent’s decomposition into another task: “Analyze sales trends of
    top-selling and bottom-selling products”, E3 noted that in the domain scenario,
    “finding out how well products are selling can optimize inventory to prevent stockouts
    and excess inventory.” Therefore, E3 selected a task previously proposed but not
    executed, recommended for review by the agent, to rank the sales volumes of different
    categories and subcategories ([Fig. 7](https://arxiv.org/html/2411.05651v1#S6.F7
    "In VI-C Results and Analysis ‣ VI Expert Study ‣ LightVA: Lightweight Visual
    Analytics with LLM Agent-Based Task Planning and Execution")-a3). Based on the
    generated visualization, E3 discovered that the “phone” subcategory within the
    “Technology” category has the best sales performance.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '一开始，E3提到了现实场景中产品销售数据的高时间敏感性。因此，在初始任务中，E3选择探索产品销售量的时间趋势。在由智能体建议的直方图和洞察图（[图 7](https://arxiv.org/html/2411.05651v1#S6.F7
    "In VI-C Results and Analysis ‣ VI Expert Study ‣ LightVA: Lightweight Visual
    Analytics with LLM Agent-Based Task Planning and Execution")-a1）中，E3发现该商品的整体销售量在不同月份之间有显著差异。在接下来的分解计划中，E3对产品进行了分类，以探索不同类别的时间趋势（[图
    7](https://arxiv.org/html/2411.05651v1#S6.F7 "In VI-C Results and Analysis ‣ VI
    Expert Study ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task
    Planning and Execution")-a2）。结果发现，不同类别的时间趋势大致相似，但“技术类”产品在11月的总销售量最高。此外，按照智能体分解后的另一个任务：“分析畅销产品和滞销产品的销售趋势”，E3注意到，在该领域的场景中，“了解产品的销售情况可以优化库存，避免缺货和库存过剩。”因此，E3选择了一个之前提出但未执行的任务，并由智能体推荐进行复审，即对不同类别和子类别的销售量进行排名（[图
    7](https://arxiv.org/html/2411.05651v1#S6.F7 "In VI-C Results and Analysis ‣ VI
    Expert Study ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based Task
    Planning and Execution")-a3）。根据生成的可视化图表，E3发现“技术类”中的“手机”子类别销售表现最佳。'
- en: 'After finding the answer to the previous task, E3 was interested in “analyze
    the correlation between sales and profit.” Upon receiving the specific scatter
    plot ([Fig. 7](https://arxiv.org/html/2411.05651v1#S6.F7 "In VI-C Results and
    Analysis ‣ VI Expert Study ‣ LightVA: Lightweight Visual Analytics with LLM Agent-Based
    Task Planning and Execution")-b1), E3 discovered that high sales do not always
    mean higher profit. The expert speculated that this may be due to the impact of
    discounts, as items with high sales often have significant discounts. E3 confirmed
    this hypothesis through interaction with and analysis of the scatter plots of
    sales and profit, with and without discount ([Fig. 7](https://arxiv.org/html/2411.05651v1#S6.F7
    "In VI-C Results and Analysis ‣ VI Expert Study ‣ LightVA: Lightweight Visual
    Analytics with LLM Agent-Based Task Planning and Execution")-b2). To find the
    optimal discount rate for products, E3 chose to analyze the relationship between
    discount and profit across different product categories. According to [Fig. 7](https://arxiv.org/html/2411.05651v1#S6.F7
    "In VI-C Results and Analysis ‣ VI Expert Study ‣ LightVA: Lightweight Visual
    Analytics with LLM Agent-Based Task Planning and Execution")-b3, the differences
    between product categories are minor, with all reaching maximum profit at a 10%
    discount.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '在找到前一个任务的答案后，E3对“分析销售与利润之间的关联”产生了兴趣。在收到具体的散点图（[图 7](https://arxiv.org/html/2411.05651v1#S6.F7
    "在 VI-C 结果与分析 ‣ VI 专家研究 ‣ LightVA: 基于 LLM 代理任务规划与执行的轻量级可视化分析")-b1）后，E3发现高销售额并不总是意味着更高的利润。专家推测，这可能是由于折扣的影响，因为销售量高的商品通常有较大的折扣。E3通过与销售和利润的散点图（含折扣与不含折扣的散点图）（[图
    7](https://arxiv.org/html/2411.05651v1#S6.F7 "在 VI-C 结果与分析 ‣ VI 专家研究 ‣ LightVA:
    基于 LLM 代理任务规划与执行的轻量级可视化分析")-b2）进行互动和分析，确认了这一假设。为了找出产品的最佳折扣率，E3选择分析不同产品类别下折扣与利润之间的关系。根据[图
    7](https://arxiv.org/html/2411.05651v1#S6.F7 "在 VI-C 结果与分析 ‣ VI 专家研究 ‣ LightVA:
    基于 LLM 代理任务规划与执行的轻量级可视化分析")-b3，产品类别之间的差异较小，所有类别在 10% 的折扣下都达到了最大利润。'
- en: VI-C Results and Analysis
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-C 结果与分析
- en: This section discusses the expert’s exploration process and feedback on the
    system construction and task planning.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论了专家在系统构建和任务规划中的探索过程及反馈。
- en: 'Exploration process analysis: The exploration behaviors of the three experts
    differ significantly. VA expert E1 created the most visualization charts, with
    half including interactive features, emphasizing the generation of visualizations
    and the exploratory use of linked views. Furthermore, E1 delved deeper into task
    decomposition to employ more complex statistical methods, such as linear regression
    and polynomial regression. E2, with profound data analysis experience, did not
    strictly follow the agent’s recommendations during the exploration process. Instead,
    E2 refined and improved the analysis goals and exploration directions based on
    the results of previous tasks, proposing new questions and flexibly employing
    interactive VA to complete the goal. E3, as a domain expert, possessed an understanding
    of the characteristics of certain data attributes within the dataset, such as
    the relationships between discounts, sales, and profit. E3’s analysis was grounded
    in real-world scenarios, selecting different analysis methods as needed to integrate
    data insights into practical applications. This suggests our system supports a
    degree of flexibility, responding effectively to users’ individual needs.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 探索过程分析：三位专家的探索行为差异显著。VA 专家 E1 创建了最多的可视化图表，其中一半包括交互功能，强调了可视化图表的生成以及联动视图的探索性使用。此外，E1深入进行了任务分解，采用了更为复杂的统计方法，如线性回归和多项式回归。具有深厚数据分析经验的
    E2 在探索过程中并未严格遵循代理的建议，而是基于先前任务的结果精炼和改进分析目标与探索方向，提出新问题，并灵活地运用交互式 VA 完成目标。作为领域专家的
    E3，了解数据集中某些数据属性的特征，如折扣、销售和利润之间的关系。E3 的分析基于实际场景，必要时选择不同的分析方法，将数据洞察融入实际应用中。这表明我们的系统支持一定的灵活性，能够有效响应用户的个性化需求。
- en: 'Feedback on system construction: E2 and E3 both expressed that interactive
    analysis through linked views facilitates a better understanding of the data.
    From the perspective of a VA expert, E1 commented that “basic charts and interactions
    can be generated, which are sufficient for simple data analysis problems, but
    modifications might be necessary for more complex issues.” E2 and E3 agreed that
    the system can effectively generate insights, enhancing the accuracy of analysis.
    E2 suggested that generating insights based on awaring of user behavior would
    enhance the execution of tasks. Additionally, E3 noted the significant reduction
    in manual effort due to AI generation, stating, “Previously, using PowerBI required
    a lot of time and operations, but now it only takes a sentence.”'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 系统建设反馈：E2 和 E3 都表示，通过关联视图进行互动分析有助于更好地理解数据。从 VA 专家的角度来看，E1 评论道：“可以生成基本图表和交互功能，足以解决简单的数据分析问题，但对于更复杂的问题可能需要进行修改。”
    E2 和 E3 认同该系统能够有效生成洞察，提升分析的准确性。E2 建议，基于用户行为的洞察生成将有助于任务的执行。此外，E3 提到，由于 AI 生成的使用，手动工作量大幅减少，并表示：“以前，使用
    PowerBI 需要花费大量时间和操作，但现在只需一句话。”
- en: 'Feedback on task planning: E3 observed that “the proposed tasks are quite good,
    indicating the system has a certain understanding of the dataset, and the language
    used is very standard.” E1 valued the system’s ability to decompose tasks as “the
    most useful part,” which can provide deeper analysis and reveal certain characteristics
    of the data, especially for those lacking domain-specific expertise. However,
    domain expert E3 cautioned that the decomposed tasks are not always reliable,
    stating, “The process of task decomposition needs to be explained.” Regarding
    task recommendations, E1 seeks more targeted suggestions that adhere closely to
    instructions without becoming too divergent. In contrast, E3 emphasizes that approaching
    goals from different perspectives can yield valuable insights and strategies in
    their work scenarios. These differing viewpoints highlight the need for the planning
    algorithm to be adaptable to user preferences.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 任务规划反馈：E3 观察到：“提出的任务非常好，表明系统对数据集有一定的理解，所使用的语言也很规范。” E1 认为系统将任务分解的能力是“最有用的部分”，能够提供更深入的分析，揭示数据的某些特征，尤其是对于缺乏领域特定知识的人来说。然而，领域专家
    E3 提醒，分解后的任务并不总是可靠，并表示：“任务分解的过程需要进行解释。” 关于任务建议，E1 希望得到更多符合指令、避免过度偏离的建议。相比之下，E3
    强调，从不同角度接近目标可以为工作场景中带来有价值的洞察和策略。这些不同的观点突显了规划算法需要适应用户偏好的重要性。
- en: '![Refer to caption](img/0ca9fa000b42ebca710f01de7398c7a6.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0ca9fa000b42ebca710f01de7398c7a6.png)'
- en: 'Figure 7: The example results of the domain expert study with a superstore
    sales dataset. E3 implements analysis from overview to details and beyond with
    two rounds of task decomposition. (A) The top-selling products and specific categories
    are found for inventory formulation. (B) The system effectively pointed out the
    impact of discounts on sales and profits, promoting hypothesis generation and
    verification.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：使用超市销售数据集的领域专家研究示例结果。E3 通过两轮任务分解实现从概览到细节的分析。(A) 找出了用于库存制定的畅销产品和特定类别。(B)
    系统有效指出了折扣对销售和利润的影响，促进了假设的生成和验证。
- en: VII Discussion
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第七章 讨论
- en: This section outlines the limitations of our work and discuss the implications
    learned from the research with the future directions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述了我们工作的局限性，并讨论了从研究中获得的启示及未来方向。
- en: 'Generalizability of the framework: Our framework is generalizable in two aspects.
    First, our conceptual framework unifies the development and usage of VA systems,
    based on the connections between goals, tasks, visualizations, and insights. Secondly,
    compared with existing visualization software, e.g., Tableau (with AI version,
    Ask Data) ⁵⁵5[https://help.tableau.com/current/pro/desktop/en-us/ask_data.htm](https://help.tableau.com/current/pro/desktop/en-us/ask_data.htm),
    last accessed March 2024, LightVA offers several distinct advantages. While Tableau
    supports natural language interfaces, task recommendation, and single visualization
    generation, it lacks support for task decomposition, multi-view visualization
    generation, and iterative human-in-the-loop task completion evaluation, which
    are the focuses of LightVA.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 框架的通用性：我们的框架在两个方面具有通用性。首先，我们的概念框架统一了VA系统的开发和使用，基于目标、任务、可视化和洞察之间的联系。其次，与现有的可视化软件相比，例如Tableau（带有AI版本，Ask
    Data）⁵⁵5[https://help.tableau.com/current/pro/desktop/en-us/ask_data.htm](https://help.tableau.com/current/pro/desktop/en-us/ask_data.htm)，最后访问时间为2024年3月，LightVA提供了几个显著的优势。虽然Tableau支持自然语言接口、任务推荐和单一可视化生成，但它缺乏对任务分解、多视图可视化生成和迭代的人机协作任务完成评估的支持，而这些正是LightVA的重点。
- en: Meanwhile, there are some limitations to our framework. First, the framework
    may require more detailed guidelines for complex and specific domains, particularly
    in task customization, visualization methods, and model selection. A more comprehensive
    grammar for tasks and insights would improve model output evaluation and refinement.
    This necessitates extensive research and documentation, categorizing different
    tasks and domains to enhance the framework’s applicability. Second, functionality
    in the development of VA systems needs to be improved, particularly features that
    facilitate authoring and version iteration. Third, the relatively small number
    of participants in the expert study limits the generalizability of the results.
    Conducting a larger crowdsourced user study would be beneficial in verifying the
    quality of the automated output further and investigating the factors that contribute
    to users’ perceived quality.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，我们的框架也存在一些局限性。首先，框架可能需要更详细的指南，特别是在复杂和特定领域的任务定制、可视化方法和模型选择方面。一个更全面的任务和洞察语法将有助于提高模型输出的评估和优化。这需要广泛的研究和文档工作，对不同任务和领域进行分类，以增强框架的适用性。其次，VA系统开发中的功能需要改进，特别是那些有助于创作和版本迭代的功能。第三，专家研究中参与者数量相对较少，限制了结果的普适性。进行更大规模的众包用户研究将有助于进一步验证自动输出的质量，并调查影响用户感知质量的因素。
- en: 'The performance of LLMs in VA tasks: While LLM exhibits potentials, some of
    the limitations of LLM requires careful handling.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在VA任务中的表现：尽管LLM展现了潜力，但LLM的一些局限性仍需要谨慎处理。
- en: •
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Output stability and accuracy: The output of LLMs can be unstable. During our
    evaluation, we encountered instances where the model failed to follow instructions
    accurately, leading to parsing and execution failures in the generated code. In
    order to address this problem, we propose an error-handling mechanism. Although
    this mechanism helps to avoid errors making system crashes, additional LLM errors
    about incorrect facts should be detected and corrected. In the future, we can
    incorporate LLMs’ self-reflection to solve hallucination [[65](https://arxiv.org/html/2411.05651v1#bib.bib65)]
    and provide insights on errors so that users can work together to fix these errors.'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出稳定性和准确性：LLMs的输出可能不稳定。在我们的评估过程中，我们遇到过模型未能准确按照指令执行的情况，导致生成的代码解析和执行失败。为了解决这个问题，我们提出了一种错误处理机制。尽管该机制有助于避免系统崩溃的错误，但对于不正确事实的LLM错误仍需检测和修正。未来，我们可以结合LLM的自我反思能力，解决幻觉问题[[65](https://arxiv.org/html/2411.05651v1#bib.bib65)]，并提供错误的洞察，以便用户共同修复这些错误。
- en: •
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Response speed: From our test, GPT-3.5-turbo completes tasks in significantly
    less time than GPT-4-turbo. To increase the running speed, we use a multi-agent
    parallel computing strategy and error handling for time exceeding a certain threshold.
    A future direction could be to utilize caching mechanisms such as GPTCache [[66](https://arxiv.org/html/2411.05651v1#bib.bib66)]
    to explore acceleration strategies in data analysis scenarios.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 响应速度：根据我们的测试，GPT-3.5-turbo在完成任务的时间上明显快于GPT-4-turbo。为了提高运行速度，我们采用了多智能体并行计算策略，并对超过某一阈值的时间进行错误处理。未来的方向可以是利用缓存机制，如GPTCache [[66](https://arxiv.org/html/2411.05651v1#bib.bib66)]，探索数据分析场景中的加速策略。
- en: •
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Problem-solving ability: Our test results indicate that LLMs can struggle with
    complex tasks, such as predictive modeling. This highlights the need for a broader
    evaluation of model capabilities across various complex domain-specific problems
    to derive guidelines or evaluation metrics for task planning and execution. Additionally,
    we found that LLMs may struggle with processing issues like missing values due
    to unfamiliarity with data. From the implementation side, we should provide additional
    materials or tools and teach agents to process data effectively [[67](https://arxiv.org/html/2411.05651v1#bib.bib67)].'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题解决能力：我们的测试结果表明，LLM 在处理复杂任务时可能会遇到困难，例如预测建模。这凸显了需要更广泛地评估模型在各种复杂领域特定问题上的能力，以制定任务规划和执行的指南或评估指标。此外，我们发现，LLM
    在处理诸如缺失值等问题时可能会遇到困难，这是由于其对数据的不熟悉。从实施角度来看，我们应该提供额外的材料或工具，并教导代理有效地处理数据[[67](https://arxiv.org/html/2411.05651v1#bib.bib67)]。
- en: •
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Domain knowledge: In some scenarios, LLMs may not have sufficient domain knowledge.
    To address this limitation, future research can focus on combining retrieval augmented
    generation (RAG) and fine-tuning for LLMs to solve specific domain tasks [[68](https://arxiv.org/html/2411.05651v1#bib.bib68)].'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 域知识：在某些场景下，LLM 可能缺乏足够的领域知识。为了克服这一限制，未来的研究可以重点关注将检索增强生成（RAG）和微调技术结合，以便 LLM 解决特定领域任务[[68](https://arxiv.org/html/2411.05651v1#bib.bib68)]。
- en: 'Injecting visualization design knowledge: Design knowledge is important in
    designing VA systems. In our implementation, we constrain color, interaction,
    and layout. These constraints are not exhaustive and we only consider them as
    preliminary. Further research can include more design guidelines for the LLM with
    prompting techniques or multimodal models [[69](https://arxiv.org/html/2411.05651v1#bib.bib69)]
    to perceive and evaluate the effectiveness. Besides, a memory module [[70](https://arxiv.org/html/2411.05651v1#bib.bib70)]
    can be integrated to make the agent evolve. In addition, interactions other than
    natural language can be designed to facilitate user input of intentions, such
    as sketching [[71](https://arxiv.org/html/2411.05651v1#bib.bib71)] or generating
    widgets [[72](https://arxiv.org/html/2411.05651v1#bib.bib72)].'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 注入可视化设计知识：设计知识在设计 VA 系统中至关重要。在我们的实现中，我们对颜色、交互和布局进行了约束。这些约束并不全面，我们只将其视为初步的。进一步的研究可以通过提示技术或多模态模型[[69](https://arxiv.org/html/2411.05651v1#bib.bib69)]为
    LLM 提供更多设计指导，以感知和评估其有效性。此外，可以集成记忆模块[[70](https://arxiv.org/html/2411.05651v1#bib.bib70)]，使代理不断发展。此外，还可以设计除自然语言外的交互方式，以便用户输入意图，例如草图绘制[[71](https://arxiv.org/html/2411.05651v1#bib.bib71)]或生成小部件[[72](https://arxiv.org/html/2411.05651v1#bib.bib72)]。
- en: 'Automation and personalization: From the user study, we found that users from
    different backgrounds have different needs. Some users have a clear idea of what
    they want and need the agent to follow orders in detail, while others prefer the
    agent to take the lead in a more automated way. This divergence in user preferences
    highlights the balance between user agency (the control they maintain over decisions)
    and the automation of processes. In future studies, we could explore how different
    levels of agency and automation affect task performance and user satisfaction [[32](https://arxiv.org/html/2411.05651v1#bib.bib32)].
    Additionally, users may require different levels of assistance in terms of breadth
    and depth. We could conduct further qualitative experiments to test the differences
    in decision-making paths when experts in visualization are assisted by agents [[73](https://arxiv.org/html/2411.05651v1#bib.bib73),
    [74](https://arxiv.org/html/2411.05651v1#bib.bib74)], comparing these paths visually
    using graph algorithms. This could help us build a preference knowledge base for
    different user types, enabling the model to simulate and adapt to users’ desired
    paths, providing more personalized recommendations.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化与个性化：从用户研究中，我们发现不同背景的用户需求各不相同。有些用户对自己想要的内容非常明确，且需要代理详细地执行命令，而另一些用户则更倾向于让代理以更自动化的方式引导他们。这种用户偏好的差异突出了用户自主性（他们在决策中保持的控制权）与过程自动化之间的平衡。在未来的研究中，我们可以探索不同程度的自主性和自动化如何影响任务表现和用户满意度[[32](https://arxiv.org/html/2411.05651v1#bib.bib32)]。此外，用户在广度和深度方面可能需要不同程度的帮助。我们可以进一步开展定性实验，测试当可视化领域的专家受到代理帮助时，决策路径的差异[[73](https://arxiv.org/html/2411.05651v1#bib.bib73)，[74](https://arxiv.org/html/2411.05651v1#bib.bib74)]，并使用图算法直观地比较这些路径。这可以帮助我们为不同类型的用户构建偏好知识库，使模型能够模拟并适应用户的期望路径，提供更个性化的推荐。
- en: VIII Conclusion
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VIII 结论
- en: In this paper, we aim to reduce the complexities and technical demands of carrying
    out visual analytics. Therefore, We introduce LightVA, a lightweight visual analytics
    framework that supports task planning, insight analysis, and linked visualization
    generation based on human-agent collaboration. Our framework utilizes LLM agents
    for task planning and execution. The framework employs a recursive approach in
    which the agents recommend tasks, break down complex tasks into subtasks, and
    generate visualization and data modeling codes to solve tasks. We develop a system
    that embodies our proposed framework, supporting users to analyze data based on
    the communication with LLM agents and use the task-driven generated VA system.
    A usage scenario and an expert study suggest that LightVA not only reduced the
    manual effort required but also provided new opportunities to leverage LLMs to
    facilitate visual data exploration.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们旨在减少进行视觉分析时的复杂性和技术需求。因此，我们介绍了LightVA，一个轻量级的视觉分析框架，支持基于人机协作的任务规划、洞察分析和关联可视化生成。我们的框架利用LLM代理进行任务规划和执行。该框架采用递归方法，代理推荐任务，将复杂任务分解为子任务，并生成可视化和数据建模代码来解决任务。我们开发了一个体现我们提出的框架的系统，支持用户基于与LLM代理的通信分析数据，并使用任务驱动生成的VA系统。一个使用场景和专家研究表明，LightVA不仅减少了所需的人工努力，还提供了利用LLM促进视觉数据探索的新机会。
- en: Acknowledgments
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: We thank anonymous reviewers for their constructive comments. This work is supported
    by the Natural Science Foundation of China (NSFC No.62472099).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢匿名评审者的建设性评论。本研究得到了中国自然科学基金（NSFC No.62472099）的支持。
- en: References
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] J. J. Thomas and K. A. Cook, *Illuminating the Path: An R&D Agenda for
    Visual Analytics*.   National Visualization and Analytics Ctr, 2005, pp. 69–104.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] J. J. Thomas 和 K. A. Cook, *Illuminating the Path: An R&D Agenda for Visual
    Analytics*.  国家可视化与分析中心, 2005年，第69–104页。'
- en: '[2] D. Keim, G. Andrienko, J.-D. Fekete, C. Görg, J. Kohlhammer, and G. Melançon,
    “Visual analytics: Definition, process, and challenges,” in *Information Visualization:
    Human-Centered Issues and Perspectives*, 2008, vol. 4950, pp. 154–175.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] D. Keim, G. Andrienko, J.-D. Fekete, C. Görg, J. Kohlhammer, 和 G. Melançon,
    “视觉分析：定义、过程与挑战,” 收录于 *Information Visualization: Human-Centered Issues and Perspectives*,
    2008年，第4950卷，第154–175页。'
- en: '[3] A. Wu, D. Deng, F. Cheng, Y. Wu, S. Liu, and H. Qu, “In defence of visual
    analytics systems: Replies to critics,” *IEEE Transactions on Visualization and
    Computer Graphics*, vol. 29, no. 1, pp. 1026–1036, 2023.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] A. Wu, D. Deng, F. Cheng, Y. Wu, S. Liu, 和 H. Qu, “为视觉分析系统辩护：对批评者的回应,”
    *IEEE Transactions on Visualization and Computer Graphics*, 第29卷，第1期，第1026–1036页，2023年。'
- en: '[4] D. Ceneda, T. Gschwandtner, T. May, S. Miksch, H.-J. Schulz, M. Streit,
    and C. Tominski, “Characterizing guidance in visual analytics,” *IEEE transactions
    on visualization and computer graphics*, vol. 23, no. 1, pp. 111–120, 2016.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] D. Ceneda, T. Gschwandtner, T. May, S. Miksch, H.-J. Schulz, M. Streit,
    和 C. Tominski, “视觉分析中的指导特征,” *IEEE transactions on visualization and computer
    graphics*, 第23卷，第1期，第111–120页，2016年。'
- en: '[5] D. Deng, A. Wu, H. Qu, and Y. Wu, “DashBot: Insight-driven dashboard generation
    based on deep reinforcement learning,” *IEEE Transactions on Visualization and
    Computer Graphics*, vol. 29, no. 1, pp. 690–700, 2023.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] D. Deng, A. Wu, H. Qu, 和 Y. Wu, “DashBot: 基于深度强化学习的洞察驱动仪表板生成,” *IEEE Transactions
    on Visualization and Computer Graphics*, 第29卷，第1期，第690–700页，2023年。'
- en: '[6] B. Yu and C. T. Silva, “FlowSense: A natural language interface for visual
    data exploration within a dataflow system,” *IEEE Transactions on Visualization
    and Computer Graphics*, vol. 26, no. 1, pp. 1–11, 2019.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] B. Yu 和 C. T. Silva, “FlowSense: 数据流系统中视觉数据探索的自然语言接口,” *IEEE Transactions
    on Visualization and Computer Graphics*, 第26卷，第1期，第1–11页，2019年。'
- en: '[7] Y. Wang, Z. Sun, H. Zhang, W. Cui, K. Xu, X. Ma, and D. Zhang, “DataShot:
    Automatic generation of fact sheets from tabular data,” *IEEE Transactions on
    Visualization and Computer Graphics*, vol. 26, no. 1, pp. 895–905, 2020.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Y. Wang, Z. Sun, H. Zhang, W. Cui, K. Xu, X. Ma, 和 D. Zhang, “DataShot:
    从表格数据自动生成事实表,” *IEEE Transactions on Visualization and Computer Graphics*, 第26卷，第1期，第895–905页，2020年。'
- en: '[8] C. Demiralp, P. J. Haas, S. Parthasarathy, and T. Pedapati, “Foresight:
    Recommending visual insights,” *Proceedings of the VLDB Endowment International
    Conference on Very Large Data Bases*, vol. 10, no. 12, 2017.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] C. Demiralp, P. J. Haas, S. Parthasarathy, 和 T. Pedapati, “Foresight: 推荐视觉洞察,”
    *Proceedings of the VLDB Endowment International Conference on Very Large Data
    Bases*, 第10卷，第12期，2017年。'
- en: '[9] S. Hao, Y. Gu, H. Ma, J. Hong, Z. Wang, D. Wang, and Z. Hu, “Reasoning
    with language model is planning with world model,” in *Proceedings of the Conference
    on Empirical Methods in Natural Language Processing*, H. Bouamor, J. Pino, and
    K. Bali, Eds., Dec. 2023, pp. 8154–8173.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] S. Hao, Y. Gu, H. Ma, J. Hong, Z. Wang, D. Wang, 和 Z. Hu, “使用语言模型进行推理即是使用世界模型进行规划，”
    收录于 *《自然语言处理经验方法会议论文集》*，H. Bouamor, J. Pino, 和 K. Bali 编，2023年12月，第8154–8173页。'
- en: '[10] S. Sharan, F. Pittaluga, M. Chandraker *et al.*, “LLM-Assist: Enhancing
    closed-loop planning with language-based reasoning,” *arXiv preprint arXiv:2401.00125*,
    2023.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] S. Sharan, F. Pittaluga, M. Chandraker *等*， “LLM-Assist：通过基于语言的推理增强闭环规划，”
    *arXiv预印本 arXiv:2401.00125*，2023年。'
- en: '[11] J. Yang, A. Prabhakar, K. Narasimhan, and S. Yao, “InterCode: Standardizing
    and benchmarking interactive coding with execution feedback,” *Advances in Neural
    Information Processing Systems*, vol. 36, pp. 23 826–23 854, 2023.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] J. Yang, A. Prabhakar, K. Narasimhan, 和 S. Yao, “InterCode：标准化和基准化交互式编码与执行反馈，”
    *《神经信息处理系统进展》*，第36卷，第23,826–23,854页，2023年。'
- en: '[12] S.-C. Liu, S. Wang, T. Chang, W. Lin, C.-W. Hsiung, Y.-C. Hsieh, Y.-P.
    Cheng, S.-H. Luo, and J. Zhang, “JarviX: A llm no code platform for tabular data
    analysis and optimization,” in *Proceedings of the Conference on Empirical Methods
    in Natural Language Processing: Industry Track*, 2023, pp. 622–630.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S.-C. Liu, S. Wang, T. Chang, W. Lin, C.-W. Hsiung, Y.-C. Hsieh, Y.-P.
    Cheng, S.-H. Luo, 和 J. Zhang, “JarviX：一个用于表格数据分析和优化的LLM无代码平台，” 收录于 *《自然语言处理经验方法会议论文集：行业轨道》*，2023年，第622–630页。'
- en: '[13] V. Dibia, “LIDA: A tool for automatic generation of grammar-agnostic visualizations
    and infographics using large language models,” in *Proceedings of the 61st Annual
    Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)*,
    D. Bollegala, R. Huang, and A. Ritter, Eds., Jul. 2023, pp. 113–126.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] V. Dibia, “LIDA：一个使用大型语言模型自动生成语法无关可视化和信息图表的工具，” 收录于 *《第61届计算语言学协会年会论文集（第3卷：系统演示）》*，D.
    Bollegala, R. Huang, 和 A. Ritter 编，2023年7月，第113–126页。'
- en: '[14] L. Wang, S. Zhang, Y. Wang, E.-P. Lim, and Y. Wang, “LLM4Vis: Explainable
    visualization recommendation using chatgpt,” *arXiv preprint arXiv:2310.07652*,
    2023.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] L. Wang, S. Zhang, Y. Wang, E.-P. Lim, 和 Y. Wang, “LLM4Vis：使用ChatGPT进行可解释的可视化推荐，”
    *arXiv预印本 arXiv:2310.07652*，2023年。'
- en: '[15] R. Mao, G. Chen, X. Zhang, F. Guerin, and E. Cambria, “GPTEval: A survey
    on assessments of chatgpt and gpt-4,” *arXiv preprint arXiv:2308.12488*, 2023.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] R. Mao, G. Chen, X. Zhang, F. Guerin, 和 E. Cambria, “GPTEval：关于ChatGPT和GPT-4评估的综述，”
    *arXiv预印本 arXiv:2308.12488*，2023年。'
- en: '[16] W. Zhang, Y. Shen, W. Lu, and Y. Zhuang, “Data-Copilot: Bridging billions
    of data and humans with autonomous workflow,” *arXiv preprint arXiv:2306.07209*,
    2023.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] W. Zhang, Y. Shen, W. Lu, 和 Y. Zhuang, “Data-Copilot：通过自主工作流连接数十亿数据和人类，”
    *arXiv预印本 arXiv:2306.07209*，2023年。'
- en: '[17] Y. Zhao, Y. Zhang, Y. Zhang, X. Zhao, J. Wang, Z. Shao, C. Turkay, and
    S. Chen, “LEVA: Using large language models to enhance visual analytics,” *IEEE
    Transactions on Visualization and Computer Graphics*, pp. 1–17, 2024.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Y. Zhao, Y. Zhang, Y. Zhang, X. Zhao, J. Wang, Z. Shao, C. Turkay, 和 S.
    Chen, “LEVA：利用大型语言模型增强视觉分析，” *《IEEE可视化与计算机图形学学报》*，第1–17页，2024年。'
- en: '[18] A. Wu, Y. Wang, X. Shu, D. Moritz, W. Cui, H. Zhang, D. Zhang, and H. Qu,
    “AI4VIS: Survey on artificial intelligence approaches for data visualization,”
    *IEEE Transactions on Visualization and Computer Graphics*, vol. 28, no. 12, pp.
    5049–5070, 2021.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] A. Wu, Y. Wang, X. Shu, D. Moritz, W. Cui, H. Zhang, D. Zhang, 和 H. Qu,
    “AI4VIS：关于数据可视化的人工智能方法综述，” *《IEEE可视化与计算机图形学学报》*，第28卷，第12期，第5049–5070页，2021年。'
- en: '[19] Q. Wang, Z. Chen, Y. Wang, and H. Qu, “A survey on ML4VIS: Applying machine
    learning advances to data visualization,” *IEEE transactions on visualization
    and computer graphics*, vol. 28, no. 12, pp. 5134–5153, 2021.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Q. Wang, Z. Chen, Y. Wang, 和 H. Qu, “ML4VIS综述：将机器学习的进展应用于数据可视化，” *《IEEE可视化与计算机图形学学报》*，第28卷，第12期，第5134–5153页，2021年。'
- en: '[20] P. Ren, Y. Wang, and F. Zhao, “Re-understanding of data storytelling tools
    from a narrative perspective,” *Visual Intelligence*, vol. 1, no. 1, p. 11, 2023.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] P. Ren, Y. Wang, 和 F. Zhao, “从叙事角度重新理解数据讲故事工具，” *《视觉智能》*，第1卷，第1期，第11页，2023年。'
- en: '[21] K. Wongsuphasawat, D. Moritz, A. Anand, J. Mackinlay, B. Howe, and J. Heer,
    “Voyager: Exploratory analysis via faceted browsing of visualization recommendations,”
    *IEEE Transactions on Visualization and Computer Graphics*, vol. 22, no. 1, pp.
    649–658, 2015.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] K. Wongsuphasawat, D. Moritz, A. Anand, J. Mackinlay, B. Howe, 和 J. Heer,
    “Voyager：通过可视化推荐的分面浏览进行探索性分析，” *《IEEE可视化与计算机图形学学报》*，第22卷，第1期，第649–658页，2015年。'
- en: '[22] K. Wongsuphasawat, D. Moritz, A. Anand, J. Mackinlay, B. Howe, and J. Heer,
    “Towards a general-purpose query language for visualization recommendation,” in
    *Proceedings of the Workshop on Human-In-the-Loop Data Analytics*, 2016, pp. 1–6.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] K. Wongsuphasawat, D. Moritz, A. Anand, J. Mackinlay, B. Howe, 和 J. Heer，"朝着一个通用的可视化推荐查询语言迈进"，载于
    *《人类参与数据分析研讨会论文集》*，2016年，第1–6页。'
- en: '[23] V. Dibia and Ç. Demiralp, “Data2Vis: Automatic generation of data visualizations
    using sequence to sequence recurrent neural networks,” *IEEE computer graphics
    and applications*, vol. 39, no. 5, pp. 33–46, 2019.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] V. Dibia 和 Ç. Demiralp，"Data2Vis：使用序列到序列递归神经网络自动生成数据可视化"，*《IEEE 计算机图形与应用》*，第39卷，第5期，第33–46页，2019年。'
- en: '[24] K. Hu, M. A. Bakker, S. Li, T. Kraska, and C. Hidalgo, “VizML: A machine
    learning approach to visualization recommendation,” in *Proceedings of the SIGCHI
    Conference on Human Factors in Computing Systems*, 2019, pp. 1–12.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] K. Hu, M. A. Bakker, S. Li, T. Kraska, 和 C. Hidalgo，"VizML：一种机器学习方法用于可视化推荐"，载于
    *《SIGCHI 计算机系统中的人因会议论文集》*，2019年，第1–12页。'
- en: '[25] M. Zhou, Q. Li, X. He, Y. Li, Y. Liu, W. Ji, S. Han, Y. Chen, D. Jiang,
    and D. Zhang, “Table2Charts: Recommending charts by learning shared table representations,”
    in *Proceedings of the ACM SIGKDD Conference on Knowledge Discovery & Data Mining*,
    2021, pp. 2389–2399.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] M. Zhou, Q. Li, X. He, Y. Li, Y. Liu, W. Ji, S. Han, Y. Chen, D. Jiang,
    和 D. Zhang，"Table2Charts：通过学习共享表格表示推荐图表"，载于 *《ACM SIGKDD 知识发现与数据挖掘大会论文集》*，2021年，第2389–2399页。'
- en: '[26] J. Zhao, M. Fan, and M. Feng, “ChartSeer: Interactive steering exploratory
    visual analysis with machine intelligence,” *IEEE Transactions on Visualization
    and Computer Graphics*, vol. 28, no. 3, pp. 1500–1513, 2020.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] J. Zhao, M. Fan, 和 M. Feng，"ChartSeer：利用机器智能进行交互式引导的探索性视觉分析"，*《IEEE 可视化与计算机图形学期刊》*，第28卷，第3期，第1500–1513页，2020年。'
- en: '[27] S. Zhang, Y. Wang, H. Li, and H. Qu, “AdaVis: Adaptive and explainable
    visualization recommendation for tabular data,” *IEEE Transactions on Visualization
    and Computer Graphics*, 2023.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] S. Zhang, Y. Wang, H. Li, 和 H. Qu，"AdaVis：针对表格数据的自适应和可解释可视化推荐"，*《IEEE
    可视化与计算机图形学期刊》*，2023年。'
- en: '[28] H. Li, Y. Wang, S. Zhang, Y. Song, and H. Qu, “KG4Vis: A knowledge graph-based
    approach for visualization recommendation,” *IEEE Transactions on Visualization
    and Computer Graphics*, vol. 28, no. 1, pp. 195–205, 2021.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] H. Li, Y. Wang, S. Zhang, Y. Song, 和 H. Qu，"KG4Vis：基于知识图谱的可视化推荐方法"，*《IEEE
    可视化与计算机图形学期刊》*，第28卷，第1期，第195–205页，2021年。'
- en: '[29] D. Raghunandan, Z. Cui, K. Krishnan, S. Tirfe, S. Shi, T. D. Shrestha,
    L. Battle, and N. Elmqvist, “Lodestar: Supporting independent learning and rapid
    experimentation through data-driven analysis recommendations,” *arXiv preprint
    arXiv:2204.07876*, 2022.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] D. Raghunandan, Z. Cui, K. Krishnan, S. Tirfe, S. Shi, T. D. Shrestha,
    L. Battle, 和 N. Elmqvist，"Lodestar：通过数据驱动分析推荐支持独立学习和快速实验"，*arXiv 预印本 arXiv:2204.07876*，2022年。'
- en: '[30] Z. Qu and J. Hullman, “Keeping multiple views consistent: Constraints,
    validations, and exceptions in visualization authoring,” *IEEE Transactions on
    Visualization and Computer Graphics*, vol. 24, no. 1, pp. 468–477, 2017.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Z. Qu 和 J. Hullman，"保持多视图一致性：可视化创作中的约束、验证与例外"，*《IEEE 可视化与计算机图形学期刊》*，第24卷，第1期，第468–477页，2017年。'
- en: '[31] M. Sun, A. Namburi, D. Koop, J. Zhao, T. Li, and H. Chung, “Towards systematic
    design considerations for visualizing cross-view data relationships,” *IEEE Transactions
    on Visualization and Computer Graphics*, vol. 28, no. 12, pp. 4741–4756, 2021.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] M. Sun, A. Namburi, D. Koop, J. Zhao, T. Li, 和 H. Chung，"朝着可视化跨视图数据关系的系统化设计考虑迈进"，*《IEEE
    可视化与计算机图形学期刊》*，第28卷，第12期，第4741–4756页，2021年。'
- en: '[32] H. Lin, D. Moritz, and J. Heer, “Dziban: Balancing agency & automation
    in visualization design via anchored recommendations,” in *Proceedings of the
    SIGCHI Conference on Human Factors in Computing Systems*, ser. CHI ’20, 2020,
    pp. 1–12.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] H. Lin, D. Moritz, 和 J. Heer，"Dziban：通过锚定推荐平衡可视化设计中的代理性与自动化"，载于 *《SIGCHI
    计算机系统中的人因会议论文集》*，系列 CHI ’20，2020年，第1–12页。'
- en: '[33] D. Moritz, C. Wang, G. L. Nelson, H. Lin, A. M. Smith, B. Howe, and J. Heer,
    “Formalizing visualization design knowledge as constraints: Actionable and extensible
    models in draco,” *IEEE Transactions on Visualization and Computer Graphics*,
    vol. 25, no. 1, pp. 438–448, 2018.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] D. Moritz, C. Wang, G. L. Nelson, H. Lin, A. M. Smith, B. Howe, 和 J. Heer，"将可视化设计知识形式化为约束：在
    Draco 中可操作和可扩展的模型"，*《IEEE 可视化与计算机图形学期刊》*，第25卷，第1期，第438–448页，2018年。'
- en: '[34] Y. Lin, H. Li, A. Wu, Y. Wang, and H. Qu, “DMiner: Dashboard design mining
    and recommendation,” *IEEE Transactions on Visualization and Computer Graphics*,
    pp. 1–15, 2023.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Y. Lin, H. Li, A. Wu, Y. Wang, 和 H. Qu, “DMiner: 仪表板设计挖掘与推荐，”*IEEE Transactions
    on Visualization and Computer Graphics*，页码1–15，2023年。'
- en: '[35] A. Wu, Y. Wang, M. Zhou, X. He, H. Zhang, H. Qu, and D. Zhang, “MultiVision:
    Designing analytical dashboards with deep learning based recommendation,” *IEEE
    Transactions on Visualization and Computer Graphics*, vol. 28, no. 1, pp. 162–172,
    2021.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] A. Wu, Y. Wang, M. Zhou, X. He, H. Zhang, H. Qu, 和 D. Zhang, “MultiVision：基于深度学习推荐设计分析仪表板，”*IEEE
    Transactions on Visualization and Computer Graphics*，第28卷，第1期，页码162–172，2021年。'
- en: '[36] D. Shi, W. Cui, D. Huang, H. Zhang, and N. Cao, “Reverse-engineering information
    presentations: Recovering hierarchical grouping from layouts of visual elements,”
    *Visual Intelligence*, vol. 1, no. 1, p. 9, 2023.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] D. Shi, W. Cui, D. Huang, H. Zhang, 和 N. Cao, “反向工程信息呈现：从可视化元素布局中恢复层次分组，”*Visual
    Intelligence*，第1卷，第1期，页码9，2023年。'
- en: '[37] X. Li, Y. Zhang, J. Leung, C. Sun, and J. Zhao, “EDAssistant: Supporting
    exploratory data analysis in computational notebooks with in situ code search
    and recommendation,” *ACM Transactions on Interactive Intelligent Systems*, vol. 13,
    no. 1, pp. 1–27, 2023.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] X. Li, Y. Zhang, J. Leung, C. Sun, 和 J. Zhao, “EDAssistant: 支持计算笔记本中探索性数据分析的现场代码搜索与推荐，”*ACM
    Transactions on Interactive Intelligent Systems*，第13卷，第1期，页码1–27，2023年。'
- en: '[38] O. Bar El, T. Milo, and A. Somech, “Automatically generating data exploration
    sessions using deep reinforcement learning,” in *Proceedings of the 2020 ACM SIGMOD
    international conference on management of data*, 2020, pp. 1527–1537.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] O. Bar El, T. Milo, 和 A. Somech, “使用深度强化学习自动生成数据探索会话，”收录于*2020年ACM SIGMOD国际数据管理会议论文集*，2020年，页码1527–1537。'
- en: '[39] S. M. Casner, “Task-analytic approach to the automated design of graphic
    presentations,” *ACM Transactions on Graphics (ToG)*, vol. 10, no. 2, pp. 111–151,
    1991.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] S. M. Casner, “面向任务的自动化图形展示设计方法，”*ACM Transactions on Graphics (ToG)*,
    第10卷，第2期，页码111–151，1991年。'
- en: '[40] B. Saket, A. Endert, and Ç. Demiralp, “Task-based effectiveness of basic
    visualizations,” *IEEE Transactions on Visualization and Computer Graphics*, vol. 25,
    no. 7, pp. 2505–2512, 2018.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] B. Saket, A. Endert, 和 Ç. Demiralp, “基于任务的基本可视化效果，”*IEEE Transactions
    on Visualization and Computer Graphics*，第25卷，第7期，页码2505–2512，2018年。'
- en: '[41] R. Amar, J. Eagan, and J. Stasko, “Low-level components of analytic activity
    in information visualization,” in *Proceddings of IEEE Symposium on Information
    Visualization*.   IEEE, 2005, pp. 111–117.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] R. Amar, J. Eagan, 和 J. Stasko, “信息可视化中的低级分析活动组件，”收录于*IEEE信息可视化研讨会论文集*。IEEE，2005年，页码111–117。'
- en: '[42] D. Gotz and Z. Wen, “Behavior-driven visualization recommendation,” in
    *Proceedings of the 14th international conference on Intelligent user interfaces*,
    ser. IUI ’09, 2009, pp. 315–324.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] D. Gotz 和 Z. Wen, “基于行为的可视化推荐，”收录于*第14届国际智能用户界面会议论文集*，系列IUI ’09，2009年，页码315–324。'
- en: '[43] F. Bouali, A. Guettala, and G. Venturini, “VizAssist: an interactive user
    assistant for visual data mining,” *The Visual Computer*, vol. 32, pp. 1447–1463,
    2016.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] F. Bouali, A. Guettala, 和 G. Venturini, “VizAssist: 一种用于视觉数据挖掘的交互式用户助手，”*The
    Visual Computer*，第32卷，页码1447–1463，2016年。'
- en: '[44] L. Shen, E. Shen, Z. Tai, Y. Song, and J. Wang, “TaskVis: Task-oriented
    visualization recommendation,” in *EuroVis*, 2021.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] L. Shen, E. Shen, Z. Tai, Y. Song, 和 J. Wang, “TaskVis: 面向任务的可视化推荐，”收录于*EuroVis*，2021年。'
- en: '[45] A. Pandey, A. Srinivasan, and V. Setlur, “Medley: Intent-based recommendations
    to support dashboard composition,” *IEEE Transactions on Visualization and Computer
    Graphics*, vol. 29, no. 1, pp. 1135–1145, 2022.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] A. Pandey, A. Srinivasan, 和 V. Setlur, “Medley: 基于意图的推荐支持仪表板组合，”*IEEE
    Transactions on Visualization and Computer Graphics*，第29卷，第1期，页码1135–1145，2022年。'
- en: '[46] Y. Tian, W. Cui, D. Deng, X. Yi, Y. Yang, H. Zhang, and Y. Wu, “ChartGPT:
    Leveraging llms to generate charts from abstract natural language,” *IEEE Transactions
    on Visualization and Computer Graphics*, pp. 1–15, 2024.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Y. Tian, W. Cui, D. Deng, X. Yi, Y. Yang, H. Zhang, 和 Y. Wu, “ChartGPT:
    利用大型语言模型从抽象自然语言生成图表，”*IEEE Transactions on Visualization and Computer Graphics*，页码1–15，2024年。'
- en: '[47] G. Li, X. Wang, G. Aodeng, S. Zheng, Y. Zhang, C. Ou, S. Wang, and C. H.
    Liu, “Visualization generation with large language models: An evaluation,” *arXiv
    preprint arXiv:2401.11255*, 2024.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] G. Li, X. Wang, G. Aodeng, S. Zheng, Y. Zhang, C. Ou, S. Wang, 和 C. H.
    Liu, “使用大型语言模型生成可视化：评估，”*arXiv预印本arXiv:2401.11255*，2024年。'
- en: '[48] Y. Huang, Y. Zhou, R. Chen, C. Pan, X. Shu, D. Weng, and Y. Wu, “Interactive
    table synthesis with natural language,” *IEEE Transactions on Visualization and
    Computer Graphics*, 2023.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Y. Huang, Y. Zhou, R. Chen, C. Pan, X. Shu, D. Weng, 和 Y. Wu, “与自然语言交互的表格合成，”
    *IEEE可视化与计算机图形学学报*，2023年。'
- en: '[49] M. M. Hassan, A. Knipper, and S. K. K. Santu, “ChatGPT as your personal
    data scientist,” *arXiv preprint arXiv:2305.13657*, 2023.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] M. M. Hassan, A. Knipper, 和 S. K. K. Santu, “ChatGPT作为您的个人数据科学家，” *arXiv预印本
    arXiv:2305.13657*，2023年。'
- en: '[50] P. Ma, R. Ding, S. Wang, S. Han, and D. Zhang, “Demonstration of InsightPilot:
    An llm-empowered automated data exploration system,” *arXiv preprint arXiv:2304.00477*,
    2023.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] P. Ma, R. Ding, S. Wang, S. Han, 和 D. Zhang, “InsightPilot演示：一个由LLM赋能的自动数据探索系统，”
    *arXiv预印本 arXiv:2304.00477*，2023年。'
- en: '[51] X. He, M. Zhou, X. Xu, X. Ma, R. Ding, L. Du, Y. Gao, R. Jia, X. Chen,
    S. Han *et al.*, “Text2Analysis: A benchmark of table question answering with
    advanced data analysis and unclear queries,” *arXiv preprint arXiv:2312.13671*,
    2023.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] X. He, M. Zhou, X. Xu, X. Ma, R. Ding, L. Du, Y. Gao, R. Jia, X. Chen,
    S. Han *等*，“Text2Analysis：具有高级数据分析和不明确查询的表格问答基准，” *arXiv预印本 arXiv:2312.13671*，2023年。'
- en: '[52] J. Wei, X. Wang, D. Schuurmans, M. Bosma, b. ichter, F. Xia, E. Chi, Q. V.
    Le, and D. Zhou, “Chain-of-Thought prompting elicits reasoning in large language
    models,” *Advances in Neural Information Processing Systems*, vol. 35, pp. 24 824–24 837,
    2022.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] J. Wei, X. Wang, D. Schuurmans, M. Bosma, b. icter, F. Xia, E. Chi, Q.
    V. Le, 和 D. Zhou, “链式思维提示在大型语言模型中的推理激发，” *神经信息处理系统进展*，第35卷，第24,824-24,837页，2022年。'
- en: '[53] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, and K. Narasimhan,
    “Tree of Thoughts: Deliberate problem solving with large language models,” *Advances
    in Neural Information Processing Systems*, vol. 36, pp. 11 809–11 822, 2023.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, 和 K. Narasimhan,
    “思维树：与大型语言模型的深度问题解决，” *神经信息处理系统进展*，第36卷，第11,809-11,822页，2023年。'
- en: '[54] M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, L. Gianinazzi, J. Gajda,
    T. Lehmann, M. Podstawski, H. Niewiadomski, P. Nyczyk *et al.*, “Graph of thoughts:
    Solving elaborate problems with large language models,” *arXiv preprint arXiv:2308.09687*,
    2023.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, L. Gianinazzi, J. Gajda,
    T. Lehmann, M. Podstawski, H. Niewiadomski, P. Nyczyk *等*，“思维图：使用大型语言模型解决复杂问题，”
    *arXiv预印本 arXiv:2308.09687*，2023年。'
- en: '[55] T. Wu, M. Terry, and C. J. Cai, “AI Chains: Transparent and controllable
    human-ai interaction by chaining large language model prompts,” in *Proceedings
    of the SIGCHI Conference on human factors in computing systems*, ser. CHI ’22,
    2022, pp. 1–22.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] T. Wu, M. Terry, 和 C. J. Cai, “AI Chains：通过链接大型语言模型提示实现透明且可控的人机交互，” 见
    *SIGCHI人机计算系统会议录*，CHI ’22系列，2022年，第1-22页。'
- en: '[56] Y. Guo, D. Shi, M. Guo, Y. Wu, N. Cao, and Q. Chen, “Talk2Data: A natural
    language interface for exploratory visual analysis via question decomposition,”
    *ACM Transactions on Interactive Intelligent Systems*, 2021.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Y. Guo, D. Shi, M. Guo, Y. Wu, N. Cao, 和 Q. Chen, “Talk2Data：通过问题分解进行探索性可视化分析的自然语言接口，”
    *ACM互动智能系统学报*，2021年。'
- en: '[57] M. Q. Wang Baldonado, A. Woodruff, and A. Kuchinsky, “Guidelines for using
    multiple views in information visualization,” in *Proceedings of the Working Conference
    on Advanced Visual Interfaces*, ser. AVI ’00, 2000, pp. 110–119.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] M. Q. Wang Baldonado, A. Woodruff, 和 A. Kuchinsky, “信息可视化中使用多视图的指南，” 见
    *先进视觉接口工作会议录*，AVI ’00系列，2000年，第110-119页。'
- en: '[58] S. Khan, P. H. Nguyen, A. Abdul-Rahman, E. Freeman, C. Turkay, and M. Chen,
    “Rapid development of a data visualization service in an emergency response,”
    *IEEE Transactions on Services Computing*, vol. 15, no. 3, pp. 1251–1264, 2022.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] S. Khan, P. H. Nguyen, A. Abdul-Rahman, E. Freeman, C. Turkay, 和 M. Chen,
    “紧急响应中数据可视化服务的快速开发，” *IEEE服务计算学报*，第15卷，第3期，第1251-1264页，2022年。'
- en: '[59] R. Ding, S. Han, Y. Xu, H. Zhang, and D. Zhang, “QuickInsights: Quick
    and automatic discovery of insights from multi-dimensional data,” in *Proceedings
    of the International Conference on Management of Data*, ser. SIGMOD ’19, 2019,
    pp. 317–332.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] R. Ding, S. Han, Y. Xu, H. Zhang, 和 D. Zhang, “QuickInsights：从多维数据中快速自动发现洞见，”
    见 *国际数据管理会议录*，SIGMOD ’19系列，2019年，第317-332页。'
- en: '[60] A. Satyanarayan, D. Moritz, K. Wongsuphasawat, and J. Heer, “Vega-Lite:
    A grammar of interactive graphics,” *IEEE Transactions on Visualization and Computer
    Graphics*, vol. 23, no. 1, p. 341–350, jan 2017.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] A. Satyanarayan, D. Moritz, K. Wongsuphasawat, 和 J. Heer, “Vega-Lite：交互图形的语法，”
    *IEEE可视化与计算机图形学学报*，第23卷，第1期，第341-350页，2017年1月。'
- en: '[61] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan,
    R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler,
    M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford,
    I. Sutskever, and D. Amodei, “Language models are few-shot learners,” in *Advances
    in Neural Information Processing Systems*, H. Larochelle, M. Ranzato, R. Hadsell,
    M. Balcan, and H. Lin, Eds., vol. 33, 2020, pp. 1877–1901.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A.
    Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger,
    T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen,
    E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A.
    Radford, I. Sutskever, 和 D. Amodei，“语言模型是少样本学习者，”载于 *《神经信息处理系统进展》*，H. Larochelle,
    M. Ranzato, R. Hadsell, M. Balcan, 和 H. Lin 主编，第33卷，2020年，第1877–1901页。'
- en: '[62] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, “Reflexion:
    language agents with verbal reinforcement learning,” in *Proceedings of the 37th
    International Conference on Neural Information Processing Systems*, ser. NIPS
    ’23, 2024.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, 和 S. Yao，“Reflexion：带有语言强化学习的语言代理，”载于
    *《第37届国际神经信息处理系统会议论文集》*，系列 NIPS ’23，2024年。'
- en: '[63] L. Peng, Y. Zhao, Y. Hou, Q. Wang, S. Shen, X. Lai, J. Gao, J. Dong, Z. Lin,
    and S. Chen, “Mixed-initiative visual exploration of social media text and events,”
    in *Proceedings of the IEEE Conference on Visualization and Visual Analytics*,
    2021.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] L. Peng, Y. Zhao, Y. Hou, Q. Wang, S. Shen, X. Lai, J. Gao, J. Dong, Z.
    Lin, 和 S. Chen，“社交媒体文本和事件的混合式主动可视化探索，”载于 *《IEEE可视化与可视分析会议论文集》*，2021年。'
- en: '[64] M. Van Someren, Y. F. Barnard, and J. Sandberg, “The think aloud method:
    A practical approach to modelling cognitive,” *London: AcademicPress*, vol. 11,
    no. 6, 1994.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] M. Van Someren, Y. F. Barnard, 和 J. Sandberg，“思维大声法：建模认知的实用方法，” *伦敦：学术出版社*，第11卷，第6期，1994年。'
- en: '[65] Z. Ji, T. Yu, Y. Xu, N. Lee, E. Ishii, and P. Fung, “Towards mitigating
    llm hallucination via self reflection,” in *Findings of the Association for Computational
    Linguistics: EMNLP 2023*, 2023, pp. 1827–1843.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Z. Ji, T. Yu, Y. Xu, N. Lee, E. Ishii, 和 P. Fung，“通过自我反思减少LLM幻觉的探索，”载于
    *《计算语言学协会发现：EMNLP 2023》*，2023年，第1827–1843页。'
- en: '[66] F. Bang, “GPTCache: An open-source semantic cache for llm applications
    enabling faster answers and cost savings,” in *Proceedings of the 3rd Workshop
    for Natural Language Processing Open Source Software*, 2023, pp. 212–218.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] F. Bang，“GPTCache：一个开源语义缓存，用于LLM应用程序加速回答和节省成本，”载于 *《第三届自然语言处理开源软件研讨会论文集》*，2023年，第212–218页。'
- en: '[67] Y. Qin, S. Liang, Y. Ye, K. Zhu, L. Yan, Y. Lu, Y. Lin, X. Cong, X. Tang,
    B. Qian, S. Zhao, R. Tian, R. Xie, J. Zhou, M. Gerstein, D. Li, Z. Liu, and M. Sun,
    “ToolLLM: Facilitating large language models to master 16000+ real-world apis,”
    *arxiv.2307.16789*, 2023.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Y. Qin, S. Liang, Y. Ye, K. Zhu, L. Yan, Y. Lu, Y. Lin, X. Cong, X. Tang,
    B. Qian, S. Zhao, R. Tian, R. Xie, J. Zhou, M. Gerstein, D. Li, Z. Liu, 和 M. Sun，“ToolLLM：帮助大型语言模型掌握16000+现实世界API，”
    *arxiv.2307.16789*，2023年。'
- en: '[68] L. Gao, J. Lu, Z. Shao, Z. Lin, S. Yue, C. Ieong, Y. Sun, R. J. Zauner,
    Z. Wei, and S. Chen, “Fine-tuned large language model for visualization system:
    A study on self-regulated learning in education,” *IEEE Transactions on Visualization
    and Computer Graphics*, pp. 1–11, 2024.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] L. Gao, J. Lu, Z. Shao, Z. Lin, S. Yue, C. Ieong, Y. Sun, R. J. Zauner,
    Z. Wei, 和 S. Chen，“用于可视化系统的微调大型语言模型：自我调节学习在教育中的研究，” *IEEE可视化与计算机图形学学报*，第1–11页，2024年。'
- en: '[69] X. Zeng, H. Lin, Y. Ye, and W. Zeng, “Advancing multimodal large language
    models in chart question answering with visualization-referenced instruction tuning,”
    *IEEE Transactions on Visualization and Computer Graphics*, pp. 1–11, 2024.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] X. Zeng, H. Lin, Y. Ye, 和 W. Zeng，“推进多模态大型语言模型在图表问题回答中的应用，结合可视化引用的指令调优，”
    *IEEE可视化与计算机图形学学报*，第1–11页，2024年。'
- en: '[70] C. Packer, V. Fang, S. G. Patil, K. Lin, S. Wooders, and J. E. Gonzalez,
    “MemGPT: Towards llms as operating systems,” *arXiv preprint arXiv:2310.08560*,
    2023.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] C. Packer, V. Fang, S. G. Patil, K. Lin, S. Wooders, 和 J. E. Gonzalez，“MemGPT：将LLMs作为操作系统的探索，”
    *arXiv预印本arXiv:2310.08560*，2023年。'
- en: '[71] D. Masson, S. Malacria, G. Casiez, and D. Vogel, “DirectGPT: A direct
    manipulation interface to interact with large language models,” in *Proceedings
    of the 2024 CHI Conference on Human Factors in Computing Systems*, ser. CHI ’24,
    2024.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] D. Masson, S. Malacria, G. Casiez, 和 D. Vogel，“DirectGPT：与大型语言模型互动的直接操控接口，”载于
    *《2024年CHI计算机系统人因会议论文集》*，系列 CHI ’24，2024年。'
- en: '[72] P. Vaithilingam, E. L. Glassman, J. P. Inala, and C. Wang, “DynaVis: Dynamically
    synthesized ui widgets for visualization editing,” in *Proceedings of the CHI
    Conference on Human Factors in Computing Systems*, ser. CHI ’24, 2024.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] P. Vaithilingam, E. L. Glassman, J. P. Inala, 和 C. Wang, “DynaVis: 动态合成的用于可视化编辑的
    UI 小部件，”载于 *CHI 人机交互系统会议论文集*，系列 CHI ’24, 2024。'
- en: '[73] L. Battle and J. Heer, “Characterizing exploratory visual analysis: A
    literature review and evaluation of analytic provenance in tableau,” *Computer
    graphics forum*, vol. 38, no. 3, pp. 145–159, 2019.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] L. Battle 和 J. Heer, “探索性视觉分析的特征：文献综述及 Tableau 中分析溯源的评估，” *计算机图形学论坛*，第
    38 卷，第 3 期，页码 145–159, 2019。'
- en: '[74] Y. Liu, T. Althoff, and J. Heer, “Paths Explored, Paths Omitted, Paths
    Obscured: Decision points & selective reporting in end-to-end data analysis,”
    in *Proceedings of the SIGCHI Conference on Human Factors in Computing Systems*,
    ser. CHI ’20, 2020, pp. 1–14.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] Y. Liu, T. Althoff, 和 J. Heer, “探索的路径、遗漏的路径、模糊的路径：端到端数据分析中的决策点与选择性报告，”载于
    *SIGCHI 人机交互系统会议论文集*，系列 CHI ’20, 2020，页码 1–14。'
