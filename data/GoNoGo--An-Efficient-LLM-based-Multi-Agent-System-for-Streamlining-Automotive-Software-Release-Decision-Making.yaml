- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2025-01-11 12:18:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2025-01-11 12:18:42'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'GoNoGo: 一种高效的基于LLM的多智能体系统，用于简化汽车软件发布决策'
- en: 来源：[https://arxiv.org/html/2408.09785/](https://arxiv.org/html/2408.09785/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2408.09785/](https://arxiv.org/html/2408.09785/)
- en: '¹¹institutetext: Department of Computer Science and Engineering, Chalmers University
    of Technology, Gothenburg, Sweden ¹¹email: {khoee, yinan, robert.feldt}@chalmers.se
    ²²institutetext: Volvo Group, Gothenburg, Sweden ²²email: {andris.freimanis, patrick.andersson,
    dhasarathy.parthasarathy}@volvo.comArsham Gholamzadeh Khoee 1122 [0000-0002-5130-5520](https://orcid.org/0000-0002-5130-5520
    "ORCID identifier")    Yinan Yu 11 [0000-0002-3221-7517](https://orcid.org/0000-0002-3221-7517
    "ORCID identifier")    Robert Feldt 11 [0000-0002-5179-4205](https://orcid.org/0000-0002-5179-4205
    "ORCID identifier")    Andris Freimanis 22    Patrick Andersson Rhodin 22    Dhasarathy
    Parthasarathy 22 [0000-0002-3620-8589](https://orcid.org/0000-0002-3620-8589 "ORCID
    identifier")'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹institutetext: 瑞典哥德堡，查尔姆斯理工大学计算机科学与工程系 ¹¹email: {khoee, yinan, robert.feldt}@chalmers.se
    ²²institutetext: 瑞典哥德堡，沃尔沃集团 ²²email: {andris.freimanis, patrick.andersson, dhasarathy.parthasarathy}@volvo.comArsham
    Gholamzadeh Khoee 1122 [0000-0002-5130-5520](https://orcid.org/0000-0002-5130-5520
    "ORCID identifier")    Yinan Yu 11 [0000-0002-3221-7517](https://orcid.org/0000-0002-3221-7517
    "ORCID identifier")    Robert Feldt 11 [0000-0002-5179-4205](https://orcid.org/0000-0002-5179-4205
    "ORCID identifier")    Andris Freimanis 22    Patrick Andersson Rhodin 22    Dhasarathy
    Parthasarathy 22 [0000-0002-3620-8589](https://orcid.org/0000-0002-3620-8589 "ORCID
    identifier")'
- en: Abstract
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Traditional methods for making software deployment decisions in the automotive
    industry typically rely on manual analysis of tabular software test data. These
    methods often lead to higher costs and delays in the software release cycle due
    to their labor-intensive nature. Large Language Models (LLMs) present a promising
    solution to these challenges. However, their application generally demands multiple
    rounds of human-driven prompt engineering, which limits their practical deployment,
    particularly for industrial end-users who need reliable and efficient results.
    In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive
    software deployment while meeting both functional requirements and practical industrial
    constraints. Unlike previous systems, GoNoGo is specifically tailored to address
    domain-specific and risk-sensitive systems. We evaluate GoNoGo’s performance across
    different task difficulties using zero-shot and few-shot examples taken from industrial
    practice. Our results show that GoNoGo achieves a 100% success rate for tasks
    up to Level 2 difficulty with 3-shot examples, and maintains high performance
    even for more complex tasks. We find that GoNoGo effectively automates decision-making
    for simpler tasks, significantly reducing the need for manual intervention. In
    summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently
    employed in our industrial partner’s company to assist with software release decision-making,
    supporting more informed and timely decisions in the release process for risk-sensitive
    vehicle systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 汽车行业中，传统的软件部署决策方法通常依赖于手动分析表格化的软件测试数据。这些方法通常会由于其劳动密集性导致更高的成本和软件发布周期的延迟。大型语言模型（LLMs）提供了一个有前景的解决方案。然而，它们的应用通常需要多轮人工驱动的提示工程，这限制了它们的实际部署，特别是对于需要可靠和高效结果的工业终端用户。本文提出了GoNoGo，一个旨在简化汽车软件部署的LLM代理系统，同时满足功能需求和实际的工业约束。与以前的系统不同，GoNoGo专门针对特定领域和风险敏感的系统进行定制。我们通过来自工业实践的零-shot和少-shot示例评估了GoNoGo在不同任务难度下的表现。我们的结果表明，GoNoGo在Level
    2难度的任务中使用3-shot示例时实现了100%的成功率，并且在处理更复杂的任务时仍保持高性能。我们发现GoNoGo有效地自动化了简单任务的决策过程，显著减少了手动干预的需求。总之，GoNoGo代表了一个高效且用户友好的基于LLM的解决方案，目前在我们的工业合作伙伴公司中被用来辅助软件发布决策，支持在风险敏感的车辆系统发布过程中做出更有依据和及时的决策。
- en: 'Keywords:'
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: LLMs LLM-based Multi-agent Software Release Assistant Table Analysis Automation
    Risk-sensitive Systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 基于LLM的多智能体软件发布助手表格分析自动化风险敏感系统。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In the automotive industry, decisions about when to release software, particularly
    embedded software in risk-sensitive systems, carry immense weight. The complexity
    of modern vehicles, with their multiple levels of integration, further complicates
    this process. Each integration level involves one or more gating steps, with tests
    conducted to verify whether gate criteria are fulfilled. Gate failures can delay
    the integration of all dependent subsystems, regardless of their individual quality.
    In this intricate process, release managers, bearing the responsibility of gatekeeping
    could greatly benefit from assistance to make faster and better decisions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业中，关于何时发布软件，特别是在风险敏感系统中的嵌入式软件，具有巨大的影响力。现代车辆的复杂性，以及它们多层次的集成，使得这一过程更加复杂。每个集成层级都涉及一个或多个门控步骤，需要进行测试以验证是否满足门控标准。门控失败可能会延迟所有依赖子系统的集成，无论其自身的质量如何。在这一复杂的过程中，作为门控管理者的发布经理可能会从辅助决策中受益，从而做出更快、更好的决策。
- en: '![Refer to caption](img/b8362df0d155a1bb39a1800d27dacdb6.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/b8362df0d155a1bb39a1800d27dacdb6.png)'
- en: 'Figure 1: An actual example demonstrating the use of the LLM-based multi-agent
    system for automating ad-hoc tabular data analysis.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个实际示例，展示了基于LLM的多代理系统在自动化临时表格数据分析中的应用。
- en: Large language models (LLMs) present an interesting avenue for providing such
    assistance. In particular, LLMs have demonstrated strong capabilities in zero-
    and few-shot settings with in-context learning [[5](https://arxiv.org/html/2408.09785v2#bib.bib5)].
    Recent advancements have improved reasoning [[32](https://arxiv.org/html/2408.09785v2#bib.bib32)],
    exemplar selection, and prompt design [[7](https://arxiv.org/html/2408.09785v2#bib.bib7)].
    Companies now use LLMs for software engineering tasks like API testing, code generation,
    and documentation and research studies have already shown test automation improvements
    over the state-of-the-art [[28](https://arxiv.org/html/2408.09785v2#bib.bib28)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLMs）为提供此类帮助提供了一个有趣的途径。特别是，LLMs在零样本和少样本设置下通过上下文学习展示了强大的能力[[5](https://arxiv.org/html/2408.09785v2#bib.bib5)]。最近的进展提高了推理[[32](https://arxiv.org/html/2408.09785v2#bib.bib32)]、示例选择和提示设计[[7](https://arxiv.org/html/2408.09785v2#bib.bib7)]的效果。如今，许多公司已经开始使用LLM进行软件工程任务，例如API测试、代码生成和文档编写，研究表明它们在自动化测试方面优于现有的技术[[28](https://arxiv.org/html/2408.09785v2#bib.bib28)]。
- en: However, when applying LLMs to *risk-sensitive* *domain-specific* tasks, several
    unique challenges must be addressed. In our research with industrial partners,
    the most prominent challenges include 1) Incorporating specific logic and terminology
    relevant to the domain; 2) Understanding and parsing high-level queries or vague
    language used by non-expert stakeholders and translating them into actionable
    plans, 3) Enabling interpretability so that domain experts can explain system
    functionality to stakeholders without excessive complexity, 4) Operating efficiently
    to meet the time-critical demands of organizational applications, mitigating potential
    bottlenecks related to limited LLM licensing or infrastructure, and 5) Designing
    the system to enable ease of troubleshooting and maintenance, ensuring that any
    issues can be quickly identified and resolved.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在将大语言模型（LLMs）应用于*风险敏感*的*特定领域*任务时，必须解决一些独特的挑战。在我们与工业合作伙伴的研究中，最突出的问题包括：1）纳入与领域相关的特定逻辑和术语；2）理解和解析由非专家利益相关者提出的高层次问题或模糊语言，并将其转化为可执行的计划；3）实现可解释性，以便领域专家能够向利益相关者解释系统功能，而不增加过多复杂性；4）提高效率，以满足组织应用的时间敏感需求，缓解与有限的LLM授权或基础设施相关的潜在瓶颈；5）设计系统以便于故障排除和维护，确保能够快速识别和解决任何问题。
- en: 'To address these challenges, we propose a multi-agent system that encodes domain-specific
    requirements using in-context learning. This system comprises two primary LLM
    agents: a Planner and an Actor (refer to Figure [2](https://arxiv.org/html/2408.09785v2#S3.F2
    "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")). The Planner, which forms the core of the
    system, comprehends and decomposes user queries into step-by-step instructions
    for data analysis [[14](https://arxiv.org/html/2408.09785v2#bib.bib14)]. The Actor
    then synthesizes and generates executable scripts from these higher-level instructions.
    Within the Actor, a coder LLM utilizes the self-reflection mechanism besides a
    memory to produce the most effective Python script optimized for querying the
    given data for each instruction generated by the Planner [[1](https://arxiv.org/html/2408.09785v2#bib.bib1),
    [28](https://arxiv.org/html/2408.09785v2#bib.bib28)].'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决这些挑战，我们提出了一种多智能体系统，利用上下文学习对特定领域的需求进行编码。该系统由两个主要的LLM代理组成：规划者（Planner）和执行者（Actor）（参见图[2](https://arxiv.org/html/2408.09785v2#S3.F2
    "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")）。规划者作为系统的核心，理解并将用户查询分解为逐步的数据分析指令[[14](https://arxiv.org/html/2408.09785v2#bib.bib14)]。然后，执行者将这些更高层次的指令综合并生成可执行的脚本。在执行者内部，一个编码器LLM除了利用自我反思机制外，还使用记忆来生成针对每个规划者指令优化的、查询给定数据的最有效Python脚本[[1](https://arxiv.org/html/2408.09785v2#bib.bib1),
    [28](https://arxiv.org/html/2408.09785v2#bib.bib28)]。'
- en: 'This system provides an interface for end-users at our industrial partner,
    illustrated by Figure [1](https://arxiv.org/html/2408.09785v2#S1.F1 "Figure 1
    ‣ 1 Introduction ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making"), which shows a real-world example
    of its use. It allows end-users, like release managers, to interpret results from
    a business and safety perspective without needing detailed technical knowledge.
    For example, they can simply receive a short table that reports the test case
    functions that have failed the most for each release candidate as shown in Figure [1](https://arxiv.org/html/2408.09785v2#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ GoNoGo: An Efficient LLM-based Multi-Agent System
    for Streamlining Automotive Software Release Decision-Making"). By reviewing this
    information, release managers can make well-informed decisions on whether to release
    the software or not, ensuring that it meets both business objectives and safety
    standards in the automotive industry. This approach can significantly reduce time
    and resources by eliminating the need for various database and programming experts
    to achieve the desired results for end-users. Our agent automates test data analysis
    across multiple vehicle development integration levels, providing detailed reports
    on component functionality and system interactions. This assists release managers
    in making informed decisions about software readiness for release, accelerating
    development while enhancing gatekeeping reliability. Our contributions can be
    summarized as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '该系统为我们工业合作伙伴的最终用户提供了一个接口，如图[1](https://arxiv.org/html/2408.09785v2#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")所示，展示了其在实际中的使用示例。它允许像发布经理这样的最终用户从业务和安全的角度解释结果，而无需详细的技术知识。例如，他们可以简单地接收一个短表格，报告每个发布候选版本中测试用例功能最常失败的情况，如图[1](https://arxiv.org/html/2408.09785v2#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ GoNoGo: An Efficient LLM-based Multi-Agent System
    for Streamlining Automotive Software Release Decision-Making")所示。通过查看这些信息，发布经理可以做出是否发布软件的明智决策，确保软件符合汽车行业的业务目标和安全标准。这种方法可以通过消除对各种数据库和编程专家的需求，显著减少时间和资源消耗，从而为最终用户实现预期结果。我们的代理自动化了跨多个车辆开发集成层级的测试数据分析，提供关于组件功能和系统交互的详细报告。这帮助发布经理做出关于软件是否准备好发布的知情决策，加速开发进程，同时增强门控可靠性。我们的贡献可以总结如下：'
- en: '{outline}\1'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '{outline}\1'
- en: 'We highlight the practicality of the proposed LLM-based intelligent assistant
    in making software release decisions within the automotive industry. This is achieved
    by enhancing two key capabilities: \2 Domain-specificity: We design a framework
    to handle unstructured queries from non-expert stakeholders in the automotive
    industry by mapping generic language to domain-specific logic using in-context
    learning. \2 Risk-sensitivity: We incorporate two predefined atomic operations
    to restrict the action space and improve the risk-sensitive aspect of the planner.
    \1 Experiments on a total of 50 crafted test queries show that our proposed system
    is effective at analyzing data and deriving the required insights for software
    release decision-making. \1 Our system, now deployed and actively used within
    our industrial partner’s company, has demonstrated significant improvements in
    the software release decision-making process besides saving time, improving accessibility,
    reducing reliance on specialized analysts, and accelerating overall workflow.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强调了基于大型语言模型（LLM）的智能助手在汽车行业软件发布决策中的实际应用。通过增强两个关键能力实现这一目标：\2 领域特定性：我们设计了一个框架，通过使用上下文学习将通用语言映射到领域特定的逻辑，以处理来自非专家利益相关者的非结构化查询。
    \2 风险敏感性：我们结合了两种预定义的原子操作，限制了动作空间，提升了规划器在风险敏感方面的表现。 \1 总共对50个精心设计的测试查询进行了实验，结果表明我们提出的系统在分析数据和得出软件发布决策所需的洞察力方面非常有效。
    \1 我们的系统目前已经部署并在我们的工业合作伙伴公司中积极使用，除了节省时间、提高可访问性、减少对专业分析师的依赖并加速整体工作流程外，还在软件发布决策过程中表现出了显著的改进。
- en: 'The remainder of this paper is structured as follows: Section [2](https://arxiv.org/html/2408.09785v2#S2
    "2 Manual Process of Release Decisions: Insights From the Industry ‣ GoNoGo: An
    Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release
    Decision-Making") provides an overview of the manual process behind automotive
    software release decisions and the need for streamlining operations. Section [3](https://arxiv.org/html/2408.09785v2#S3
    "3 GoNoGo: Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making")
    details our approach, including a description of the architecture of our LLM-based
    multi-agent system and an explanation of the Planner and Actor agents. Furthermore,
    in Section [4](https://arxiv.org/html/2408.09785v2#S4 "4 Experiments ‣ GoNoGo:
    An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software
    Release Decision-Making"), we present our experimental setup and results. Section
    [6](https://arxiv.org/html/2408.09785v2#S6 "6 Related Work ‣ GoNoGo: An Efficient
    LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making")
    provides an overview of similar research in LLMs for data analysis. Finally, Section
    [7](https://arxiv.org/html/2408.09785v2#S7 "7 Conclusion ‣ GoNoGo: An Efficient
    LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making")
    concludes the paper by summarizing key findings and discussing the broader implications
    of our work in the context of industrial software release management and risk-sensitive
    systems.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的其余部分结构如下：第[2](https://arxiv.org/html/2408.09785v2#S2 "2 Manual Process of
    Release Decisions: Insights From the Industry ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making")节概述了汽车软件发布决策背后的手动过程以及简化操作的必要性。第[3](https://arxiv.org/html/2408.09785v2#S3
    "3 GoNoGo: Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making")节详细介绍了我们的方法，包括对基于LLM的多智能体系统架构的描述，以及规划器和执行者智能体的解释。此外，在第[4](https://arxiv.org/html/2408.09785v2#S4
    "4 Experiments ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")节中，我们展示了实验设置和结果。第[6](https://arxiv.org/html/2408.09785v2#S6
    "6 Related Work ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")节提供了关于LLM在数据分析中应用的相关研究概述。最后，第[7](https://arxiv.org/html/2408.09785v2#S7
    "7 Conclusion ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")节总结了本文的关键发现，并讨论了我们工作在工业软件发布管理和风险敏感系统背景下的广泛影响。'
- en: '2 Manual Process of Release Decisions: Insights From the Industry'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 软件发布决策的手动过程：来自行业的见解
- en: Deciding to go ahead, or not, with a software release in the automotive industry
    is a complex task involving multiple stakeholders and extensive data analysis.
    This section reviews the current, and typical of the industry at large, manual
    workflow and the need for streamlining.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在汽车行业，决定是否推进软件发布是一个复杂的任务，涉及多个利益相关者和大量数据分析。本节回顾了当前的行业普遍手动工作流程以及简化这一流程的需求。
- en: Vehicle development progresses through multiple phases, each becoming more complex
    as more components are integrated. Numerous tests are conducted at each stage
    to ensure functionality and identify revisions, generating vast amounts of data.
    Software components require repeated testing and validation, adding to this data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆开发经历多个阶段，每个阶段随着更多组件的集成而变得更加复杂。在每个阶段都会进行大量的测试，以确保功能性并识别修订，从而产生大量数据。软件组件需要反复测试和验证，进一步增加了这些数据量。
- en: Project managers, verification engineers, and quality engineers need clear analytics
    and insights from these tests in order to make software release decisions. Extracting
    essential information is time-consuming. Quality engineers analyze data for continuous
    improvement, while release engineers need specific information to make informed
    release decisions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 项目经理、验证工程师和质量工程师需要从这些测试中获取清晰的分析和洞察，以便做出软件发布决策。提取关键信息是非常耗时的。质量工程师分析数据以进行持续改进，而发布工程师则需要具体的信息来做出有依据的发布决策。
- en: Within this process, statisticians provide an overall view of the data to project
    managers and quality engineers for future business decisions. Manual data processing
    is necessary due to the critical nature of these decisions and their impact on
    consumer safety. However, this approach is time-consuming and prone to errors,
    partly due to the differing perspectives of technical data analyzers and statisticians,
    who may not fully understand the project managers’ goals.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一过程中，统计学家为项目经理和质量工程师提供数据的总体视图，以支持未来的业务决策。由于这些决策的关键性质及其对消费者安全的影响，手动数据处理是必要的。然而，这种方法非常耗时且容易出错，部分原因是技术数据分析师和统计学家的视角不同，他们可能无法完全理解项目经理的目标。
- en: A critical and typical stage in this process is “Testing on Closed Track,” where
    vehicles equipped with the necessary software release undergo systematic and rigorous
    testing of their systems in a controlled environment. After these tests, release
    managers analyze large amounts of data to decide whether to move to the next test
    stage. This involves manually querying data to generate reports that support informed
    decisions. Errors or delays in this analysis can hinder timely software release,
    affect business goals, and delay subsystem integration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程中的一个关键且典型阶段是“封闭赛道测试”，在该阶段，配备必要软件发布的车辆在受控环境中进行系统化和严格的系统测试。测试结束后，发布经理会分析大量数据，以决定是否进入下一个测试阶段。这涉及到手动查询数据以生成支持决策的报告。分析中的错误或延迟可能会阻碍及时的软件发布，影响业务目标，并延迟子系统集成。
- en: The deployment of an intelligent assistant has the potential to facilitate software
    release decisions in the automotive industry [[20](https://arxiv.org/html/2408.09785v2#bib.bib20)],
    particularly during the critical testing on a closed track phase. In this work,
    we have focused on designing such an LLM-based multi-agent system to address the
    challenges of this specific stage. By rapidly processing test data from closed
    track testing, the system can generate comprehensive reports tailored to different
    stakeholders’ needs. For example, it can quickly compile summaries of failed tests,
    highlight software performance trends across vehicle models, or analyze a specific
    component’s behavior under various conditions. Consequently, this reduces the
    time spent on initial analysis, allowing release managers to focus on interpreting
    results and making informed decisions. This not only accelerates the development
    process but also enhances the accuracy and reliability of the information used
    in release decisions, ultimately contributing to maintaining high safety and quality
    standards in automotive software development.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 部署智能助手有潜力促进汽车行业的软件发布决策[[20](https://arxiv.org/html/2408.09785v2#bib.bib20)]，尤其是在封闭赛道测试阶段的关键测试期间。在这项工作中，我们专注于设计一个基于大型语言模型（LLM）的多智能体系统，以应对这一特定阶段的挑战。通过快速处理封闭赛道测试的数据，该系统可以生成针对不同利益相关者需求的全面报告。例如，它可以迅速汇总失败测试的摘要，突出显示不同车型间的软件性能趋势，或分析某一特定组件在不同条件下的行为。因此，这减少了初步分析所花费的时间，使发布经理能够专注于解读结果并做出明智决策。这不仅加速了开发过程，还提高了用于发布决策的信息的准确性和可靠性，最终有助于保持汽车软件开发中的高安全性和质量标准。
- en: '3 GoNoGo: Intelligent Software Release Assistant'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '3 GoNoGo: 智能软件发布助手'
- en: 3.1 System Requirements
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 系统要求
- en: 'After discussing current needs and opinions about the software release analysis
    and decision-making processes with our industrial partner, we identified the following
    main challenges in automating data analysis:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在与我们的工业合作伙伴讨论了关于软件发布分析和决策过程的当前需求和意见后，我们确定了在自动化数据分析中的以下主要挑战：
- en: Understanding User Queries
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 理解用户查询
- en: The system must interpret queries, typically presented in natural language [[17](https://arxiv.org/html/2408.09785v2#bib.bib17)],
    within the specific domain context, using any provided domain-specific knowledge.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 系统必须在特定的领域上下文中解读查询，通常这些查询以自然语言呈现[[17](https://arxiv.org/html/2408.09785v2#bib.bib17)]，并利用任何提供的领域特定知识。
- en: Translating User Queries to Actionable Steps
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 将用户查询转换为可执行步骤
- en: The system needs to convert the user’s query into concrete steps, breaking down
    complex queries into simpler tasks, determining the order of operations, and selecting
    appropriate data manipulation or analysis techniques. Additionally, the action
    space must be carefully managed to adhere to risk-sensitive requirements.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 系统需要将用户的查询转化为具体步骤，将复杂的查询分解为更简单的任务，确定操作顺序，并选择适当的数据处理或分析技术。此外，必须仔细管理操作空间，以符合风险敏感的要求。
- en: Execution and Result Preparation
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 执行和结果准备
- en: The system must execute the planned actions, interact with data using scripts
    (e.g., querying databases, performing calculations, applying filters), and compile
    the results into the desired format for the user.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 系统必须执行计划中的操作，通过脚本与数据交互（例如，查询数据库、执行计算、应用过滤器），并将结果汇总成用户所需的格式。
- en: These steps rely heavily on the LLM’s domain-specific knowledge and reasoning
    ability, crucial for effective query instruction planning [[18](https://arxiv.org/html/2408.09785v2#bib.bib18)].
    Consequently, this work explores techniques for enhancing the reasoning capabilities
    of LLM agent systems, particularly for the analysis of tabular data in industrial
    contexts.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤严重依赖于LLM的领域特定知识和推理能力，这对于有效的查询指令规划至关重要[[18](https://arxiv.org/html/2408.09785v2#bib.bib18)]。因此，本研究探讨了增强LLM智能体系统推理能力的技术，特别是在工业环境中分析表格数据的能力。
- en: 3.2 System Architecture
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 系统架构
- en: 'Our approach to automating tabular data analysis leverages LLMs to create an
    intelligent system capable of interpreting natural language queries, executing
    complex analyses, and delivering desired results. The system architecture consists
    of two main components: the Planner supported by a Knowledge Base and Examples
    for few-shot learning and the Actor including coder LLM, memory module, and some
    Plugin components. Figure [2](https://arxiv.org/html/2408.09785v2#S3.F2 "Figure
    2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making") illustrates the overall architecture of the
    developed system.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的自动化表格数据分析方法利用LLMs创建一个智能系统，能够解析自然语言查询、执行复杂分析并提供期望的结果。系统架构由两个主要组件构成：由知识库和少量样本学习示例支持的规划器，以及包括编码器LLM、记忆模块和一些插件组件的执行者。图[2](https://arxiv.org/html/2408.09785v2#S3.F2
    "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making")展示了该系统的整体架构。'
- en: '![Refer to caption](img/2d2ba6e61540473dda01094cb5515072.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2d2ba6e61540473dda01094cb5515072.png)'
- en: 'Figure 2: Architecture of the LLM-based multi-agent system GoNoGo along with
    the illustration of the interaction procedure of the system. GoNoGo receives high-level
    queries from the end user, performs the required data manipulations, and outputs
    the result table as a decision support resource. GoNoGo comprises a Planner agent,
    which interprets queries and devises analysis strategies using Chain-of-Thought
    prompting and self-consistency, supported by a *Knowledge Base* and *Examples*
    for few-shot learning. The Actor includes a Coder LLM with a *Self-reflection*
    mechanism, utilizing *Memory* and *Plugins* for code generation and error resolution.
    The total running time of GoNoGo for one user query is approximately 120 seconds,
    which satisfies typical user requirements.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于LLM的多智能体系统GoNoGo的架构，以及系统交互过程的插图。GoNoGo接收来自最终用户的高层次查询，执行所需的数据处理，并输出结果表格作为决策支持资源。GoNoGo包含一个规划器智能体，负责解析查询并利用链式思维（Chain-of-Thought）提示和自一致性制定分析策略，支持*知识库*和*示例*以进行少量样本学习。执行者包括一个具有*自我反思*机制的编码器LLM，利用*记忆*和*插件*进行代码生成和错误解决。GoNoGo对单个用户查询的总运行时间大约为120秒，满足典型用户需求。
- en: 3.2.1 Planner
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 规划器
- en: The Planner is the core of our system, responsible for interpreting user queries
    and devising appropriate analysis strategies. One of the core challenges of designing
    an LLM-based multi-agent system is the inherent inaccuracy of prompting. As decision-making
    becomes more distributed over multiple LLM agents, the uncertainty within the
    multi-agent system increases. To mitigate this, we centralize the complexity within
    the Planner, which is responsible for the majority of design choices. By focusing
    on the Planner as the main agent for refinement, we aim to create a system that
    is both interpretable and easily maintainable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器是我们系统的核心，负责解析用户查询并制定适当的分析策略。设计基于大语言模型（LLM）的多智能体系统的核心挑战之一是提示的固有不准确性。随着决策过程在多个LLM智能体之间分布，系统中的不确定性增加。为了缓解这一问题，我们将复杂性集中在规划器中，规划器负责大多数设计决策。通过将规划器作为主要的精炼智能体，我们旨在创建一个既可解释又易于维护的系统。
- en: 'Our problem consists of two main aspects: domain-specificity and risk-sensitivity.
    These two characteristics frequently manifest together in real-world applications,
    particularly in fields such as healthcare and automotive, where unreliability
    and inaccuracies can have significant consequences. However, there is a noticeable
    gap in addressing both aspects simultaneously, let alone demonstrating such systems
    in practice. As part of our system, we want to explicitly address both of these
    aspects. As the Planner is the component with the most decision-making responsibility,
    these two requirements are encoded into the Planner prompts as depicted in Figure [3](https://arxiv.org/html/2408.09785v2#S3.F3
    "Figure 3 ‣ 3.2.1 Planner ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software
    Release Assistant ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making").'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的问题由两个主要方面组成：领域特定性和风险敏感性。这两个特性在实际应用中经常同时出现，尤其是在医疗和汽车等领域，在这些领域中，不可靠性和不准确性可能带来重大后果。然而，在同时解决这两个方面的问题时存在显著的空白，更不用说在实践中展示此类系统了。作为我们系统的一部分，我们希望明确解决这两个方面的问题。由于规划器是决策责任最重的组件，这两个要求已被编码为规划器提示，如图[3](https://arxiv.org/html/2408.09785v2#S3.F3
    "图 3 ‣ 3.2.1 规划器 ‣ 3.2 系统架构 ‣ 3 GoNoGo: 智能软件发布助手 ‣ GoNoGo: 一个高效的基于LLM的多代理系统，用于简化汽车软件发布决策")所示。'
- en: '![Refer to caption](img/041eec03393173dab02e1224c4790111.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/041eec03393173dab02e1224c4790111.png)'
- en: 'Figure 3: Planner prompting strategies addressing domain-specificity and risk-sensitivity
    in the LLM-based agent system for tabular data analysis.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：规划器提示策略，解决LLM基础代理系统中表格数据分析的领域特定性和风险敏感性问题。
- en: 3.2.2 Domain-specificity
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 领域特定性
- en: The Planner utilizes a Knowledge Base containing a structured description of
    the data and its attributes to provide the necessary context and domain-specific
    information in the prompts given to the LLM, enhancing the system’s performance
    and applicability [[15](https://arxiv.org/html/2408.09785v2#bib.bib15)]. The Knowledge
    Base serves as a comprehensive repository of metadata, including detailed descriptions
    of data tables, possible states and values for essential fields, and domain-specific
    terminologies, as well as the semantic meanings of various data elements. This
    enables the system to understand and interpret high-level queries and devise appropriate
    analysis plans by using this information as input prompts for the Planner, taking
    advantage of in-context learning. This integration ensures that the entire pipeline,
    from query interpretation to result generation, is informed by relevant domain
    knowledge, enabling the LLM agent to provide more accurate, relevant, and specialized
    responses to user queries.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 规划器利用包含数据及其属性结构化描述的知识库，在给定LLM的提示中提供必要的上下文和领域特定信息，从而增强系统的性能和适用性[[15](https://arxiv.org/html/2408.09785v2#bib.bib15)]。该知识库作为一个全面的元数据存储库，包含了数据表的详细描述、关键字段的可能状态和取值、领域特定术语以及各种数据元素的语义意义。这使得系统能够理解和解释高级查询，并通过将这些信息作为输入提示提供给规划器，制定合适的分析计划，利用上下文学习。这种整合确保了从查询解释到结果生成的整个流程都受到相关领域知识的影响，使LLM代理能够为用户查询提供更准确、更相关、更专业的回答。
- en: In our system architecture, we also feed some input-output pairs as examples
    into the Planner, allowing few-shot learning alongside the Knowledge Base. This
    combination enables the Planner to interpret user queries more effectively, drawing
    on both general knowledge and specific task examples to formulate appropriate
    analysis plans. This approach makes the system a powerful tool for automated tabular
    data analysis across various industries and use cases.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的系统架构中，我们还将一些输入-输出对作为示例输入到规划器中，结合知识库进行少量示例学习。这种组合使得规划器能够更有效地解释用户查询，结合一般知识和特定任务示例来制定合适的分析计划。这种方法使得该系统成为一个强大的自动化表格数据分析工具，适用于各行各业和不同的使用场景。
- en: Helpful prompts serve as constraints, enhancing the LLM’s reasoning capabilities [[13](https://arxiv.org/html/2408.09785v2#bib.bib13)].
    For example, constraints help the model understand that queries should account
    for more than just binary states for some fields. Retrieving records with ‘A’
    and its opposite doesn’t always mean retrieving all records, as other non-binary
    states might exist. For instance, ‘successful’ and ‘failed’ tests don’t encompass
    all possible test statuses; there may be additional statuses to consider, such
    as ‘N/A’, that the model should take into account.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的提示作为约束，增强了LLM的推理能力 [[13](https://arxiv.org/html/2408.09785v2#bib.bib13)]。例如，约束帮助模型理解某些字段的查询不仅应考虑二元状态。仅通过‘A’及其反义项来检索记录并不总是意味着检索所有记录，因为可能还存在其他非二元状态。例如，‘成功’和‘失败’的测试并未涵盖所有可能的测试状态；可能还存在需要考虑的其他状态，如‘N/A’，模型应该考虑这些。
- en: The focus is on pushing the model to generate an optimized query plan. This
    involves narrowing down data through filtering and selection before performing
    sorting and other operations on the reduced dataset to minimize processing. Accordingly,
    designed constraints help the agent explore the characteristics of each field
    and the data, providing more accurate planning.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 重点是推动模型生成优化的查询计划。这包括在对数据进行排序和其他操作之前，通过过滤和选择来缩小数据范围，从而最小化处理过程。因此，设计的约束帮助智能体探索每个字段和数据的特征，提供更准确的规划。
- en: 3.2.3 Risk-sensitivity
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 风险敏感性
- en: 'We guide the Planner with two pre-defined atomic actions to limit the action
    space of the planner: slicing and operation. Slicing involves specifying the columns
    to select and the conditions for filtering rows from the data to be analyzed. Operation involves
    describing the operations (such as max, mean, count, etc.) to be performed on
    the values of one or more columns of the data obtained from the slicing step.
    The steps should be returned as a Python list, with each step described in natural
    language, including all relevant values and column names.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过两种预定义的原子操作指导规划器，以限制规划器的动作空间：切片（slicing）和操作（operation）。切片涉及指定选择的列以及过滤数据行的条件。操作则是描述对通过切片步骤获得的数据中一个或多个列的值进行的操作（如最大值、均值、计数等）。这些步骤应以Python列表的形式返回，每个步骤都用自然语言描述，包含所有相关值和列名。
- en: Also, we leverage Chain-of-Thought (CoT) prompting to further enhance the reasoning
    capabilities of our LLM-based agent [[23](https://arxiv.org/html/2408.09785v2#bib.bib23)].
    This technique incorporates intermediate reasoning steps into the prompt, guiding
    the model to break down complex problems into smaller, more manageable steps [[33](https://arxiv.org/html/2408.09785v2#bib.bib33)].
    This approach mimics human-like reasoning and problem-solving processes. Additionally,
    CoT prompting makes the agent’s decision-making process more transparent by explicitly
    showing the reasoning steps, allowing users to understand how the agent arrived
    at a particular conclusion or analysis result.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们利用链式推理（Chain-of-Thought, CoT）提示进一步增强了基于LLM的智能体的推理能力 [[23](https://arxiv.org/html/2408.09785v2#bib.bib23)]。该技术将中间推理步骤融入提示中，引导模型将复杂问题拆解为更小、更易管理的步骤 [[33](https://arxiv.org/html/2408.09785v2#bib.bib33)]。这种方法模仿了类似人类的推理和解决问题的过程。此外，CoT提示通过明确展示推理步骤，使智能体的决策过程更加透明，用户可以理解智能体是如何得出特定结论或分析结果的。
- en: We combine CoT prompting with few-shot learning by providing examples that not
    only show input-output pairs but also include the intermediate reasoning steps.
    This synergy further enhances the agent’s ability to handle diverse and complex
    data analysis tasks [[10](https://arxiv.org/html/2408.09785v2#bib.bib10)].
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将CoT提示与少量学习（few-shot learning）相结合，通过提供示例，不仅展示输入输出对，还包括中间推理步骤。这种协同作用进一步增强了智能体处理多样化和复杂数据分析任务的能力 [[10](https://arxiv.org/html/2408.09785v2#bib.bib10)]。
- en: To further improve reasoning, we employ self-consistency in conjunction with
    CoT prompting. This involves generating multiple independent reasoning paths for
    the same query, comparing them for consistency, and using majority voting to determine
    the most reliable outcome [[22](https://arxiv.org/html/2408.09785v2#bib.bib22)].
    By considering multiple reasoning paths, the system becomes less likely to be
    misled by a single flawed chain of thought. As a result, for queries with potential
    ambiguity, self-consistency can help identify different valid interpretations
    and provide a more comprehensive answer.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提升推理能力，我们结合 CoT 提示技术采用自一致性方法。这包括为同一查询生成多个独立的推理路径，比较它们的一致性，并通过多数投票来确定最可靠的结果
    [[22](https://arxiv.org/html/2408.09785v2#bib.bib22)]。通过考虑多个推理路径，系统变得不容易被单一错误的思路误导。因此，对于具有潜在歧义的查询，自一致性能够帮助识别不同的有效解释并提供更全面的答案。
- en: 3.2.4 Actor
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.4 Actor
- en: 'The Actor is responsible for carrying out the analysis plans devised by the
    Planner. It consists of several interacting components: Coder LLM with Self-reflection,
    Memory, and Plugins, as depicted in Figure [2](https://arxiv.org/html/2408.09785v2#S3.F2
    "Figure 2 ‣ 3.2 System Architecture ‣ 3 GoNoGo: Intelligent Software Release Assistant
    ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive
    Software Release Decision-Making").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 'Actor 负责执行 Planner 制定的分析计划。它由多个相互作用的组件组成：带有自我反思功能的 Coder LLM、Memory 和 Plugins，如图
    [2](https://arxiv.org/html/2408.09785v2#S3.F2 "Figure 2 ‣ 3.2 System Architecture
    ‣ 3 GoNoGo: Intelligent Software Release Assistant ‣ GoNoGo: An Efficient LLM-based
    Multi-Agent System for Streamlining Automotive Software Release Decision-Making")
    所示。'
- en: The Coder LLM is responsible for generating executable scripts based on the
    Planner’s instructions. This component is crucial as it translates abstract plans
    into concrete, executable code that can interact with the data using the required
    Plugins and perform the necessary analysis. It includes a Self-reflection mechanism,
    which works in tandem with a Memory module. This Memory stores generated code,
    error messages, execution results, and contextual information about the current
    task [[8](https://arxiv.org/html/2408.09785v2#bib.bib8)].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Coder LLM 负责根据 Planner 的指示生成可执行脚本。该组件至关重要，因为它将抽象的计划转化为具体的、可执行的代码，可以使用所需的 Plugins
    与数据交互并执行必要的分析。它包括一个自我反思机制，与 Memory 模块协同工作。Memory 存储生成的代码、错误信息、执行结果以及当前任务的上下文信息
    [[8](https://arxiv.org/html/2408.09785v2#bib.bib8)]。
- en: The Self-reflection mechanism is a sophisticated process that allows the Coder
    LLM to critically analyze its own output and decision-making process. When an
    error occurs during script execution, the Self-reflection mechanism activates,
    providing feedback to the Coder LLM. This feedback loop enables the LLM to analyze
    error messages within the task context [[11](https://arxiv.org/html/2408.09785v2#bib.bib11),
    [28](https://arxiv.org/html/2408.09785v2#bib.bib28)], facilitating iterative improvement
    of the generated code.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 自我反思机制是一个复杂的过程，它允许 Coder LLM 批判性地分析其自身的输出和决策过程。当脚本执行过程中发生错误时，自我反思机制会被激活，并向 Coder
    LLM 提供反馈。这一反馈循环使 LLM 能够在任务上下文中分析错误信息 [[11](https://arxiv.org/html/2408.09785v2#bib.bib11),
    [28](https://arxiv.org/html/2408.09785v2#bib.bib28)]，促进生成代码的迭代改进。
- en: 'The Self-reflection mechanism offers several advantages: It enables the Coder
    LLM to autonomously identify and correct errors by continuously analyzing and
    reflecting on its own output, thereby reducing the need for external debugging
    and intervention. This mechanism promotes a cycle of continuous improvement, allowing
    each iteration to refine the scripts for progressively better performance and
    reliability [[25](https://arxiv.org/html/2408.09785v2#bib.bib25)]. By utilizing
    the Memory module, the Coder LLM can make context-aware adjustments, considering
    previous errors, execution results, and specific task requirements, which leads
    to more precise and contextually appropriate code generation. Automated error
    correction and iterative refinement result in a more efficient coding process,
    speeding up the development cycle and enhancing the robustness and reliability
    of the final scripts. Additionally, the self-reflective capabilities minimize
    the need for human intervention in the debugging process, enabling engineers to
    focus on more complex and high-level tasks.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 自我反思机制提供了多个优势：它使得编码器大语言模型（Coder LLM）能够通过不断分析和反思自身的输出，自动识别和修正错误，从而减少了对外部调试和干预的需求。该机制促进了持续改进的循环，使得每次迭代都能优化脚本，从而提升性能和可靠性[[25](https://arxiv.org/html/2408.09785v2#bib.bib25)]。通过利用记忆模块，编码器大语言模型可以根据上下文进行调整，考虑到之前的错误、执行结果以及特定任务要求，从而生成更加精确、符合上下文的代码。自动错误修正和迭代优化使得编码过程更加高效，加速了开发周期，并增强了最终脚本的稳健性和可靠性。此外，自我反思能力减少了对人工干预调试过程的需求，使得工程师可以专注于更复杂和更高级的任务。
- en: This architecture enables the Actor to not only generate code for data analysis
    tasks but also to troubleshoot and improve its own output, resulting in a more
    robust and reliable automated data analysis system.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该架构使得演员不仅能够为数据分析任务生成代码，还能够自我排除故障并改进自身输出，从而形成一个更强大、更可靠的自动化数据分析系统。
- en: 3.3 System Implementation
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 系统实现
- en: The system uses Azure OpenAI’s GPT-3.5 Turbo for both the Planner and Actor
    agents. The Planner utilizes specially designed prompts for task planning, defining
    the entire data analysis task by specifying the details of each step in the plan.
    Moreover, the Actor uses predefined prompts to generate the required Python code
    for executing each step of the provided plan with the pandas library, performing
    tasks on the given data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 系统使用了Azure OpenAI的GPT-3.5 Turbo作为规划者和演员代理。规划者使用专门设计的提示词进行任务规划，通过指定每个步骤的细节来定义整个数据分析任务。此外，演员使用预定义的提示词生成所需的Python代码，利用pandas库执行计划中每个步骤，对给定的数据进行处理。
- en: 4 Experiments
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 实验
- en: 4.1 Data
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 数据
- en: The data used for analysis at our industrial partner is called “GoNoGo” data
    and is updated after testing each function of every software component in each
    vehicle. This internal company data contains about 40 different fields and is
    critical for release decisions, as it includes detailed information regarding
    the performance and functionality of software components. It provides the necessary
    information for determining whether to advance a vehicle to the next phase of
    development and allow it to be driven on open roads. Although the data is updated
    after each test, we used a dataset of 55,000 records to report our experiments.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们工业合作伙伴用于分析的数据被称为“GoNoGo”数据，并在每次测试完每个软件组件的每个功能后进行更新。这些内部公司数据包含大约40个不同的字段，对于发布决策至关重要，因为它包含了关于软件组件性能和功能的详细信息。它提供了必要的信息，用于判断是否将一辆车推进到开发的下一阶段，并允许其在开放道路上行驶。尽管数据会在每次测试后更新，我们使用了包含55,000条记录的数据集来报告我们的实验结果。
- en: Stakeholders often ask questions like “What are the test case functions that
    fail the most for release candidate X?” or “What is the Y-status of X?” where
    X is the release candidate’s name and Y is a specific functionality. Answering
    these questions requires domain knowledge and an understanding of the data to
    extract and communicate the answers accurately. By analyzing this data, release
    managers can determine if a vehicle meets the necessary criteria to progress to
    the next development phase or be driven on public roads. This ensures that only
    vehicles that meet stringent safety and quality standards are advanced, maintaining
    high standards in automotive software development.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 利益相关者经常提出类似“对于发布候选版本 X，最常失败的测试用例功能是什么？”或“X 的 Y 状态是什么？”这样的问题，其中 X 是发布候选版本的名称，Y
    是特定功能。回答这些问题需要领域知识和对数据的理解，以准确提取并传达答案。通过分析这些数据，发布经理可以确定一辆车是否符合必要的标准，以便进入下一个开发阶段或在公共道路上行驶。这确保了只有符合严格安全和质量标准的车辆才能继续推进，维持汽车软件开发中的高标准。
- en: 4.2 Benchmark Overview
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基准测试概述
- en: To evaluate the GoNoGo system’s performance, we developed a benchmark based
    on 15 initial analysis tasks. These tasks were defined with the help of release
    engineers, quality engineers, and verification engineers. We identified the most
    common high-level queries and criteria frequently used by these end users in their
    workflows. Our goal was to design tasks that capture the nuances and complexity
    of the demanding queries necessary for their decision-making processes. These
    tasks were then translated into explicit table analysis queries that GoNoGo could
    process, ensuring that the benchmark reflects real-world scenarios and challenges
    typically encountered by these professionals. We created definitive ground-truth
    solutions for these queries using Python, breaking down the solutions into smaller
    code chunks representing operations such as filtering, grouping, and sorting.
    For each query, we generated a series of query ablations by incrementally adding
    code chunks and formulating corresponding queries that these chunks would solve.
    This method expanded our original 15 queries into 50 query ablations, each with
    a corresponding ground-truth solution and Python code.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 GoNoGo 系统的性能，我们开发了一个基准测试，基于 15 个初始分析任务。这些任务是在发布工程师、质量工程师和验证工程师的帮助下定义的。我们识别了这些最终用户在工作流程中最常用的高层次查询和标准。我们的目标是设计能够捕捉到决策过程中所需的复杂查询的任务，这些任务能够反映这些用户的细微差别和复杂性。然后，这些任务被转化为
    GoNoGo 可以处理的显式表格分析查询，确保基准测试能够反映现实世界中这些专业人士常遇到的场景和挑战。我们使用 Python 创建了这些查询的确定性真实答案，将解决方案拆解成更小的代码块，表示如过滤、分组和排序等操作。对于每个查询，我们通过逐步添加代码块并形成相应的查询来生成查询削减版本，这些查询块将解决这些查询。通过这种方法，我们将原有的
    15 个查询扩展为 50 个查询削减版本，每个查询削减版本都有相应的真实答案和 Python 代码。
- en: 'In this way, we established queries with four levels of difficulty:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们建立了四个难度级别的查询：
- en: Level 1
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 1
- en: These are the simplest queries, typically involving a single operation such
    as filtering or sorting.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是最简单的查询，通常只涉及单一操作，如过滤或排序。
- en: Level 2
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 2
- en: These queries combine two or three basic operations, such as multiple filtering
    followed by sorting.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些查询结合了两到三个基本操作，如多次过滤后再排序。
- en: Level 3
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 3
- en: These queries involve more than three operations, potentially including grouping
    and aggregating.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些查询涉及三个以上的操作，可能包括分组和聚合。
- en: Level 4
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 4
- en: These are the most complex queries, requiring multiple advanced operations such
    as grouping and aggregating, for calculating statistics, beyond basic filtering
    and sorting.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是最复杂的查询，需要多个高级操作，如分组和聚合，用于计算统计数据，超出了基本的过滤和排序操作。
- en: This incremental approach to query complexity allows us to assess GoNoGO’s performance
    at various levels of difficulty. It helps identify at which point, if any, the
    system’s performance begins to degrade, and provides insights into its capabilities
    in handling increasingly complex table analysis tasks.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种查询复杂性递增的方法使我们能够评估 GoNoGo 在不同难度级别的表现。它有助于识别系统性能在哪一点开始下降（如果有的话），并提供关于其处理日益复杂的表格分析任务能力的见解。
- en: This benchmark allows for objective evaluation of the GoNoGo’s ability to handle
    increasingly complex table analysis tasks, ensuring a comprehensive assessment
    of its performance across a spectrum of difficulty levels.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基准测试可以客观地评估 GoNoGo 处理日益复杂的表格分析任务的能力，确保对其在不同难度级别的表现进行全面评估。
- en: 4.3 Evaluation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 评估
- en: The evaluation process involves comparing the GoNoGo system’s results against
    manually generated ground-truth results. The comparison is based on a strict matching
    criterion [[9](https://arxiv.org/html/2408.09785v2#bib.bib9)]. For a match to
    be considered successful, the system’s output must contain the same columns as
    the ground truth. Additionally, each record in the system’s output must exactly
    match a corresponding record in the ground truth, including all values across
    different fields. The system’s output must also contain the same number of records
    as the ground truth, with no missing or extra entries. This strict matching ensures
    that the output is not just similar, but identical in structure and content to
    the expected result. If the agent’s output satisfies all these criteria when compared
    to the ground truth, the task is marked as successful; otherwise, it is considered
    a failure. The model’s performance is then quantified by calculating the success
    rate, defined as the ratio of successful tasks to the total number of tasks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 评估过程包括将GoNoGo系统的结果与人工生成的真实结果进行比较。比较是基于严格的匹配标准[[9](https://arxiv.org/html/2408.09785v2#bib.bib9)]。要认为匹配成功，系统的输出必须包含与真实结果相同的列。此外，系统输出中的每一条记录必须完全匹配真实结果中的对应记录，包括不同字段中的所有值。系统的输出还必须包含与真实结果相同数量的记录，不能有缺失或多余的条目。这一严格的匹配标准确保输出不仅在结构和内容上与预期结果一致，而且在每个细节上完全相同。如果在与真实结果对比时，代理的输出满足所有这些标准，则任务标记为成功；否则，视为失败。然后，通过计算成功任务数与总任务数的比例来量化模型的性能，得出成功率。
- en: 4.4 Results
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 结果
- en: 'We present our experiment results on the GoNoGo system in Table [1](https://arxiv.org/html/2408.09785v2#S4.T1
    "Table 1 ‣ 4.4 Results ‣ 4 Experiments ‣ GoNoGo: An Efficient LLM-based Multi-Agent
    System for Streamlining Automotive Software Release Decision-Making"). We evaluated
    its performance across different levels of task difficulty using 0-shot, 1-shot,
    2-shot, and 3-shot examples. GoNoGo achieved high performance with 3-shot examples.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在表格[1](https://arxiv.org/html/2408.09785v2#S4.T1 "Table 1 ‣ 4.4 Results ‣
    4 Experiments ‣ GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining
    Automotive Software Release Decision-Making")中展示了GoNoGo系统的实验结果。我们通过使用0-shot、1-shot、2-shot和3-shot示例评估了其在不同任务难度级别下的表现。GoNoGo在3-shot示例下达到了高性能。'
- en: 'Table 1: Performance evaluation of the GoNoGo system with varying numbers of
    example queries across different levels of task difficulty.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：在不同任务难度级别下，使用不同数量示例查询对GoNoGo系统性能的评估。
- en: '| # Examples | Task Difficulty | # Total Tasks | # Success | # Failed | Performance
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| # 示例 | 任务难度 | 总任务数 | 成功数 | 失败数 | 性能 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 0-shot | 1 | 16 | 3 | 13 | 18.75% |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 0-shot | 1 | 16 | 3 | 13 | 18.75% |'
- en: '| 1-2 | 32 | 6 | 26 | 18.75% |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 6 | 26 | 18.75% |'
- en: '| 1-3 | 44 | 9 | 35 | 20.45% |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 9 | 35 | 20.45% |'
- en: '| 1-4 | 50 | 11 | 39 | 22% |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 11 | 39 | 22% |'
- en: '| 1-shot | 1 | 16 | 15 | 1 | 93.75% |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 1-shot | 1 | 16 | 15 | 1 | 93.75% |'
- en: '| 1-2 | 32 | 27 | 5 | 84.37% |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 27 | 5 | 84.37% |'
- en: '| 1-3 | 44 | 32 | 12 | 72.72% |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 32 | 12 | 72.72% |'
- en: '| 1-4 | 50 | 34 | 16 | 68% |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 34 | 16 | 68% |'
- en: '| 2-shot | 1 | 16 | 16 | 0 | 100% |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 2-shot | 1 | 16 | 16 | 0 | 100% |'
- en: '| 1-2 | 32 | 31 | 1 | 96.87% |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 31 | 1 | 96.87% |'
- en: '| 1-3 | 44 | 38 | 6 | 86.36% |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 38 | 6 | 86.36% |'
- en: '| 1-4 | 50 | 41 | 9 | 82% |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 41 | 9 | 82% |'
- en: '| 3-shot | 1 | 16 | 16 | 0 | 100% |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 3-shot | 1 | 16 | 16 | 0 | 100% |'
- en: '| 1-2 | 32 | 32 | 0 | 100% |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 32 | 32 | 0 | 100% |'
- en: '| 1-3 | 44 | 41 | 3 | 93% |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 | 44 | 41 | 3 | 93% |'
- en: '| 1-4 | 50 | 45 | 5 | 90% |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 1-4 | 50 | 45 | 5 | 90% |'
- en: Initially, we assessed GoNoGo’s ability to handle the simplest queries involving
    basic operations like filtering or sorting (Level 1). We then incrementally increased
    the complexity by including queries that combined Level 1 and Level 2 difficulties,
    followed by those incorporating Level 1 to Level 3 difficulties. Finally, we evaluated
    GoNoGo’s performance on the full spectrum of tasks, including the most complex
    queries (Level 4), which require multiple operations such as filtering, sorting,
    grouping, and calculating statistics.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们评估了GoNoGo处理最简单查询的能力，这些查询涉及基本操作，如过滤或排序（级别1）。然后，我们逐步增加复杂性，包含结合了级别1和级别2难度的查询，再包括那些涉及级别1到级别3难度的查询。最后，我们评估了GoNoGo在全范围任务中的表现，包括最复杂的查询（级别4），这些查询需要多种操作，如过滤、排序、分组和统计计算。
- en: Our observations indicate that GoNoGo with 3-shot examples is particularly effective
    for solving queries with task difficulty up to Level 2 and can handle these tasks
    without error. For more complex tasks involving Level 3 or Level 4 difficulties,
    human intervention is recommended to perform the necessary manipulations and computations,
    rather than relying solely on the automated system.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的观察表明，使用3-shot示例的GoNoGo方法对于解决任务难度最高达到2级的查询尤其有效，能够在没有错误的情况下处理这些任务。对于涉及3级或4级难度的更复杂任务，建议进行人工干预，执行必要的操作和计算，而不是仅依赖自动化系统。
- en: 5 Threats to Validity
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 有效性威胁
- en: 'We identify the following threats to the validity of our study:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们识别出以下威胁可能影响我们研究的有效性：
- en: Limitation of the Created Benchmark
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 创建基准的局限性
- en: Our study relies on a benchmark specifically created for evaluating the system.
    While this benchmark is designed to be comprehensive, it may not cover all potential
    scenarios and edge cases encountered in real-world applications. Efforts have
    been made to design queries and tasks to be as comprehensive as possible by involving
    verification engineers to mitigate subjectiveness. However, despite these efforts,
    the limitation remains that it may not capture every potential scenario and edge
    case. This limitation could affect the generalizability and robustness of our
    findings.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的研究依赖于一个专门创建的基准来评估系统。虽然该基准旨在尽可能全面，但它可能无法涵盖在现实应用中遇到的所有潜在场景和边缘情况。为了尽量减少主观性，我们努力通过涉及验证工程师来设计尽可能全面的查询和任务。然而，尽管做出了这些努力，仍然存在一个局限性，即它可能无法捕捉每个潜在的场景和边缘情况。这一局限性可能会影响我们发现的普适性和稳健性。
- en: Selection of the Foundation Model
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型的选择
- en: The choice of the foundation model, in this case GPT-3.5 Turbo, which is considered
    a widely used LLM in recent studies, might influence the results. Different foundation
    models, such as GPT-4, GPT-4o, Claude 3, or LLaMA 3, may yield better performance
    levels and interpretations of the same tasks. However, we limited the project
    to using GPT-3.5 Turbo and focused on improving its reasoning and planning capabilities.
    Besides, our framework is flexible and can be easily applied to different pre-trained
    models. The dependency on a single model means that our conclusions may not hold
    if another model were used.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 选择基础模型（在这种情况下是GPT-3.5 Turbo），这是最近研究中广泛使用的LLM，可能会影响结果。不同的基础模型，如GPT-4、GPT-4o、Claude
    3或LLaMA 3，可能会在同样的任务中表现出更好的性能和解读。然而，我们将项目限定在使用GPT-3.5 Turbo，并专注于提升其推理和规划能力。此外，我们的框架是灵活的，可以轻松应用于不同的预训练模型。依赖于单一模型意味着，如果使用其他模型，我们的结论可能不成立。
- en: 6 Related Work
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 相关工作
- en: The application of tabular data in machine learning holds significant potential,
    ranging from few-shot learning for data analysis to end-to-end data pipeline automation.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中应用表格数据具有巨大的潜力，从数据分析的少量学习到端到端的数据管道自动化。
- en: Integrating LLM with tabular data presents several substantial challenges [[4](https://arxiv.org/html/2408.09785v2#bib.bib4)].
    Most foundation models are not trained on tabular data, making it difficult for
    them to process and interpret this type of data effectively. To mitigate this
    issue, pre-training LLMs using tabular data or fine-tuning on specific tasks are
    two commonly adopted options. [[16](https://arxiv.org/html/2408.09785v2#bib.bib16)]
    described different phases and strategies for LLM training, and [[19](https://arxiv.org/html/2408.09785v2#bib.bib19)]
    provided guidelines for enterprises who are interested in fine-tuning LLMs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 将LLM与表格数据结合存在若干重大挑战[[4](https://arxiv.org/html/2408.09785v2#bib.bib4)]。大多数基础模型没有在表格数据上进行训练，这使得它们难以有效地处理和解读这种类型的数据。为了解决这个问题，使用表格数据进行LLM的预训练或在特定任务上进行微调是两种常见的选择。[[16](https://arxiv.org/html/2408.09785v2#bib.bib16)]
    描述了LLM训练的不同阶段和策略，而[[19](https://arxiv.org/html/2408.09785v2#bib.bib19)] 提供了有意进行LLM微调的企业的指导方针。
- en: In particular, recent literature has seen a growing interest in pre-training
    and self-supervised learning (SSL) approaches using tabular data. [[21](https://arxiv.org/html/2408.09785v2#bib.bib21)]
    emphasizes SSL for non-sequential tabular data (SSL4NS-TD), categorizing methods
    into predictive, contrastive, and hybrid learning, and discussing application
    issues such as automatic data engineering and cross-table transferability. In
    contrast, [[30](https://arxiv.org/html/2408.09785v2#bib.bib30)] introduces TapTap,
    a novel table pre-training method that enhances tabular prediction and generates
    synthetic tables for various applications. Finally, [[26](https://arxiv.org/html/2408.09785v2#bib.bib26)]
    introduces Tabular data Pre-Training via Meta-representation (TabPTM), which enables
    training-free generalization across heterogeneous datasets by standardizing data
    representations through distance to prototypes. The common theme across these
    works is the enhancement of tabular data handling through innovative pre-training
    and SSL techniques, though they differ in their specific methodologies and application
    focuses, ranging from generating synthetic data to improving model generalization
    and manipulation capabilities. [[29](https://arxiv.org/html/2408.09785v2#bib.bib29)]
    proposes Tabular Foundation Models (TabFMs), leveraging a pre-trained LLM fine-tuned
    on diverse tabular datasets to excel in instruction-following tasks and efficient
    learning with scarce data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，最近的文献对使用表格数据的预训练和自监督学习（SSL）方法表现出了日益浓厚的兴趣。[ [21](https://arxiv.org/html/2408.09785v2#bib.bib21)]
    强调了非序列表格数据的自监督学习（SSL4NS-TD），将方法分类为预测性、对比性和混合学习，并讨论了自动数据工程和跨表格可迁移性等应用问题。与此相比，[[30](https://arxiv.org/html/2408.09785v2#bib.bib30)]
    引入了TapTap，这是一种新型的表格预训练方法，能够增强表格预测并生成用于各种应用的合成表格。最后，[ [26](https://arxiv.org/html/2408.09785v2#bib.bib26)]
    提出了通过元表示（TabPTM）进行的表格数据预训练，该方法通过与原型的距离标准化数据表示，使得跨异构数据集的训练自由泛化。这些工作的共同主题是通过创新的预训练和自监督学习技术增强表格数据处理能力，尽管它们在具体方法和应用焦点上有所不同，从生成合成数据到改善模型泛化能力和处理能力不等。[
    [29](https://arxiv.org/html/2408.09785v2#bib.bib29)] 提出了表格基础模型（TabFMs），利用预训练的LLM，并在各种表格数据集上进行微调，擅长执行跟随指令的任务，并能高效学习稀缺数据。
- en: Pre-training aims to enhance LLMs’ capability of handling tabular data in general.
    However, it does not necessarily improve their performance on specific tasks.
    On the other hand, fine-tuning pre-trained LLMs have demonstrated potential for
    enhancing tabular data manipulation on specific tasks. [[31](https://arxiv.org/html/2408.09785v2#bib.bib31)]
    introduced TableLLM, a robust 13-billion-parameter model designed for handling
    tabular data in real-world office scenarios. In particular, TableLLM incorporates
    reasoning process extensions and cross-way validation strategies, outperforming
    existing general-purpose and tabular-focused LLMs. [[12](https://arxiv.org/html/2408.09785v2#bib.bib12)]
    explored zero-shot and few-shot tabular data classification by prompting LLMs
    with serialized data and problem descriptions, achieving superior performance
    over traditional deep-learning methods and even strong baselines like gradient-boosted
    trees. [[34](https://arxiv.org/html/2408.09785v2#bib.bib34)] addressed question
    answering over hybrid tabular and textual data, fine-tuning LLaMA 2 using a step-wise
    pipeline, resulting in TAT-LLM, which outperforms both prior fine-tuned models
    and large-scale LLMs such as GPT-4 on specific benchmarks. [[24](https://arxiv.org/html/2408.09785v2#bib.bib24)]
    focused on applying LLMs to predictive tasks in tabular data, enhancing LLM capabilities
    through extensive training on annotated tables.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练旨在增强大型语言模型（LLMs）处理表格数据的能力。然而，它并不一定能提高模型在特定任务上的表现。另一方面，微调预训练的LLM已经展现出在特定任务中提升表格数据处理能力的潜力。[
    [31](https://arxiv.org/html/2408.09785v2#bib.bib31)] 提出了TableLLM，这是一个强大的130亿参数模型，专为处理真实办公场景中的表格数据而设计。特别地，TableLLM结合了推理过程扩展和交叉验证策略，优于现有的通用和表格数据专注的LLM。[
    [12](https://arxiv.org/html/2408.09785v2#bib.bib12)] 通过序列化数据和问题描述来提示LLM，探索了零-shot和少-shot的表格数据分类，取得了比传统深度学习方法和甚至强大的基准模型如梯度提升树更优秀的表现。[
    [34](https://arxiv.org/html/2408.09785v2#bib.bib34)] 针对混合表格和文本数据的问答问题，通过逐步管道微调LLaMA
    2，提出了TAT-LLM，该模型在特定基准上优于以前的微调模型和大型LLM，如GPT-4。[ [24](https://arxiv.org/html/2408.09785v2#bib.bib24)]
    聚焦于将LLM应用于表格数据的预测任务，通过在带注释的表格上进行广泛的训练，增强了LLM的能力。
- en: Industrial considerations
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 工业考虑
- en: One known issue is that LLMs often memorize tabular data verbatim, leading to
    overfitting. [[2](https://arxiv.org/html/2408.09785v2#bib.bib2)] highlights that
    despite their nontrivial generalization capability, LLMs perform better on datasets
    they were exposed to during training compared to new, unseen datasets. This indicates
    a tendency towards memorization, necessitating robust testing and validation protocols.
    This issue is particularly critical for companies’ internal data and tasks that
    a foundation model has not encountered before, as public benchmarks do not necessarily
    predict performance on these internal tasks. In addition, it is worth noting that
    some applications have stringent data privacy policies, a concern increasingly
    being addressed in the literature [[27](https://arxiv.org/html/2408.09785v2#bib.bib27),
    [6](https://arxiv.org/html/2408.09785v2#bib.bib6), [3](https://arxiv.org/html/2408.09785v2#bib.bib3)].
    In our work, we assume that the data resides within a secure local network, and
    we do not address data privacy issues in this paper. In industrial settings, practical
    constraints such as interpretability, user-centric adaptation, ease of development
    and maintenance, latency requirements, and IT infrastructure limitations are crucial.
    Our objective is to design a system that addresses these industrial needs without
    unnecessary complexity and excessive resources typically required by pre-training
    and fine-tuning LLMs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 一个已知的问题是，大语言模型（LLMs）经常逐字记忆表格数据，从而导致过拟合。[ [2](https://arxiv.org/html/2408.09785v2#bib.bib2)
    ] 强调，尽管大语言模型具有非平凡的泛化能力，但它们在训练过程中接触过的数据集上表现更好，而不是在新颖的、未见过的数据集上。这表明大语言模型有记忆的倾向，因此需要进行稳健的测试和验证协议。这个问题对于公司内部数据和基础模型之前未遇到过的任务尤为重要，因为公开基准测试并不一定能预测其在这些内部任务上的表现。此外，值得注意的是，一些应用有严格的数据隐私政策，这一问题在文献中正日益得到关注
    [ [27](https://arxiv.org/html/2408.09785v2#bib.bib27), [6](https://arxiv.org/html/2408.09785v2#bib.bib6),
    [3](https://arxiv.org/html/2408.09785v2#bib.bib3) ]。在我们的工作中，我们假设数据存储在一个安全的本地网络中，并且在本文中没有涉及数据隐私问题。在工业环境中，实际约束条件，如可解释性、以用户为中心的适应性、开发和维护的便捷性、延迟要求以及IT基础设施的限制，都至关重要。我们的目标是设计一个系统，满足这些工业需求，同时避免预训练和微调大语言模型通常所需的复杂性和过多的资源。
- en: 7 Conclusion
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 结论
- en: We present the GoNoGo, an LLM-based multi-agent system designed to streamline
    software release decisions in the automotive industry by analyzing and deriving
    insights from real-world data using Python code. We have employed this system
    within our industrial partner’s company, which is significantly assisting release
    managers and reducing the number of engineers engaged in this process, allowing
    them to focus on their high-level tasks.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了GoNoGo，一个基于大语言模型（LLM）的多智能体系统，旨在通过使用Python代码分析和提取现实世界数据中的洞察，从而简化汽车行业的软件发布决策。我们已在我们的工业合作伙伴公司内应用该系统，显著帮助了发布经理，并减少了参与此过程的工程师数量，使他们能够专注于更高层次的任务。
- en: The impact of our system extends beyond automation, transforming how automotive
    companies manage their software release cycles. It reduces the time and effort
    required for data analysis while increasing decision accuracy and reliability.
    This shift allows engineers and managers to focus on higher-level tasks, accelerating
    the overall development and deployment process by bridging the gap between raw
    data and actionable insights, driving the industry towards more efficient, data-driven
    software release practices. Without GoNoGo in place, our industrial partner would
    experience more wasted time and effort across various teams and employees, with
    the decision-making process becoming significantly prolonged. Pilot users have
    reported saving approximately 2 hours per person each time they make a decision,
    highlighting the system’s positive impact on efficiency and the industrial partner’s
    overall business goals.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统的影响超出了自动化，它改变了汽车公司管理软件发布周期的方式。它减少了数据分析所需的时间和精力，同时提高了决策的准确性和可靠性。这一转变使工程师和经理能够专注于更高层次的任务，通过弥合原始数据与可操作洞察之间的差距，加速整体开发和部署过程，推动行业朝着更加高效、数据驱动的软件发布实践发展。如果没有GoNoGo，我们的工业合作伙伴将面临更多团队和员工浪费时间和精力的情况，决策过程将变得显著延长。试点用户报告称，每次做出决策时，每人节省了大约2小时，突显了该系统对效率的积极影响以及对工业合作伙伴整体业务目标的促进作用。
- en: 8 Acknowledgement
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 致谢
- en: This work was partially supported by the Wallenberg AI, Autonomous Sys- tems
    and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究部分得到了由Knut和Alice Wallenberg基金会资助的Wallenberg人工智能、自动化系统和软件计划（WASP）的支持。
- en: References
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D.,
    Jiang, E., Cai, C., Terry, M., Le, Q., et al.: Program synthesis with large language
    models. arXiv preprint arXiv:2108.07732 (2021)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D.,
    Jiang, E., Cai, C., Terry, M., Le, Q., 等：使用大语言模型进行程序合成。arXiv 预印本 arXiv:2108.07732
    (2021)'
- en: '[2] Bordt, S., Nori, H., Rodrigues, V., Nushi, B., Caruana, R.: Elephants never
    forget: Memorization and learning of tabular data in large language models. arXiv
    preprint arXiv:2404.06209 (2024)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Bordt, S., Nori, H., Rodrigues, V., Nushi, B., Caruana, R.: 大象永不忘记：大语言模型中表格数据的记忆与学习。arXiv
    预印本 arXiv:2404.06209 (2024)'
- en: '[3] Boudewijn, A.T.P., Ferraris, A.F., Panfilo, D., Cocca, V., Zinutti, S.,
    De Schepper, K., Chauvenet, C.R.: Privacy measurements in tabular synthetic data:
    State of the art and future research directions. In: NeurIPS 2023 Workshop on
    Synthetic Data Generation with Generative AI (2023)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Boudewijn, A.T.P., Ferraris, A.F., Panfilo, D., Cocca, V., Zinutti, S.,
    De Schepper, K., Chauvenet, C.R.: 表格合成数据中的隐私度量：现状与未来研究方向。载于：NeurIPS 2023年合成数据生成与生成性AI研讨会（2023）'
- en: '[4] van Breugel, B., van der Schaar, M.: Why Tabular Foundation Models Should
    Be a Research Priority (Jun 2024)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] van Breugel, B., van der Schaar, M.: 为什么表格基础模型应该成为研究优先事项（2024年6月）'
- en: '[5] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.: Language models are
    few-shot learners. Advances in neural information processing systems 33, 1877–1901
    (2020)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P.,
    Neelakantan, A., Shyam, P., Sastry, G., Askell, A., 等：语言模型是少样本学习者。神经信息处理系统进展 33，1877–1901
    (2020)'
- en: '[6] Carey, A.N., Bhaila, K., Edemacu, K., Wu, X.: Dp-tabicl: In-context learning
    with differentially private tabular data. arXiv preprint arXiv:2403.05681 (2024)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Carey, A.N., Bhaila, K., Edemacu, K., Wu, X.: Dp-tabicl：使用差分隐私表格数据进行上下文学习。arXiv
    预印本 arXiv:2403.05681 (2024)'
- en: '[7] Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi,
    X., Wang, C., Wang, Y., et al.: A survey on evaluation of large language models.
    ACM Transactions on Intelligent Systems and Technology 15(3), 1–45 (2024)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi,
    X., Wang, C., Wang, Y., 等：关于大语言模型评估的调查。ACM智能系统与技术学报 15(3)，1–45 (2024)'
- en: '[8] Chen, X., Lin, M., Schärli, N., Zhou, D.: Teaching large language models
    to self-debug. arXiv preprint arXiv:2304.05128 (2023)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Chen, X., Lin, M., Schärli, N., Zhou, D.: 教授大语言模型自我调试。arXiv 预印本 arXiv:2304.05128
    (2023)'
- en: '[9] Chiang, W.L., Zheng, L., Sheng, Y., Angelopoulos, A.N., Li, T., Li, D.,
    Zhang, H., Zhu, B., Jordan, M., Gonzalez, J.E., et al.: Chatbot arena: An open
    platform for evaluating llms by human preference. arXiv preprint arXiv:2403.04132
    (2024)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Chiang, W.L., Zheng, L., Sheng, Y., Angelopoulos, A.N., Li, T., Li, D.,
    Zhang, H., Zhu, B., Jordan, M., Gonzalez, J.E., 等：聊天机器人竞技场：基于人类偏好的大语言模型评估开放平台。arXiv
    预印本 arXiv:2403.04132 (2024)'
- en: '[10] Dagdelen, J., Dunn, A., Lee, S., Walker, N., Rosen, A.S., Ceder, G., Persson,
    K.A., Jain, A.: Structured information extraction from scientific text with large
    language models. Nature Communications 15(1),  1418 (2024)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Dagdelen, J., Dunn, A., Lee, S., Walker, N., Rosen, A.S., Ceder, G., Persson,
    K.A., Jain, A.: 使用大语言模型从科学文本中提取结构化信息。自然通讯 15(1)，1418 (2024)'
- en: '[11] Dyachenko, Y., Nenkov, N., Petrova, M., Skarga-Bandurova, I., Soloviov,
    O.: Approaches to cognitive architecture of autonomous intelligent agent. Biologically
    Inspired Cognitive Architectures 26, 130–135 (2018)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Dyachenko, Y., Nenkov, N., Petrova, M., Skarga-Bandurova, I., Soloviov,
    O.: 自主智能体的认知架构方法。生物启发式认知架构 26，130–135 (2018)'
- en: '[12] Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., Sontag,
    D.: TabLLM: Few-shot Classification of Tabular Data with Large Language Models'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., Sontag,
    D.: TabLLM：使用大语言模型进行表格数据的少样本分类'
- en: '[13] Huang, J., Chang, K.C.C.: Towards reasoning in large language models:
    A survey. arXiv preprint arXiv:2212.10403 (2022)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Huang, J., Chang, K.C.C.: 面向大语言模型推理的探索：一项调查。arXiv 预印本 arXiv:2212.10403
    (2022)'
- en: '[14] Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P.,
    Sabharwal, A.: Decomposed prompting: A modular approach for solving complex tasks.
    arXiv preprint arXiv:2210.02406 (2022)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P.,
    Sabharwal, A.: 分解提示：解决复杂任务的模块化方法。arXiv 预印本 arXiv:2210.02406 (2022)'
- en: '[15] Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. ACM Computing Surveys 55(9), 1–35 (2023)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: 预训练、提示和预测：自然语言处理提示方法的系统调查。ACM计算机调查
    55(9)，1–35（2023）'
- en: '[16] Patil, R., Gudivada, V.: A review of current trends, techniques, and challenges
    in large language models (llms). Applied Sciences 14(5),  2074 (2024)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Patil, R., Gudivada, V.: 当前大型语言模型（LLMs）趋势、技术和挑战综述。应用科学 14(5)，2074（2024）'
- en: '[17] Rahimi, A., Veisi, H.: Integrating model-agnostic meta-learning with advanced
    language embeddings for few-shot intent classification. In: 2024 32nd International
    Conference on Electrical Engineering (ICEE). pp. 1–5\. IEEE (2024)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Rahimi, A., Veisi, H.: 将模型无关的元学习与先进的语言嵌入相结合，用于少样本意图分类。2024年第32届国际电气工程会议（ICEE），第1–5页，IEEE（2024）'
- en: '[18] Valmeekam, K., Marquez, M., Sreedharan, S., Kambhampati, S.: On the planning
    abilities of large language models-a critical investigation. Advances in Neural
    Information Processing Systems 36, 75993–76005 (2023)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Valmeekam, K., Marquez, M., Sreedharan, S., Kambhampati, S.: 大型语言模型的规划能力——一项关键调查。神经信息处理系统进展
    36, 75993–76005（2023）'
- en: '[19] VM, K., Warrier, H., Gupta, Y., et al.: Fine tuning llm for enterprise:
    Practical guidelines and recommendations. arXiv preprint arXiv:2404.10779 (2024)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] VM, K., Warrier, H., Gupta, Y., 等: 面向企业的LLM微调：实践指南和建议。arXiv预印本 arXiv:2404.10779（2024）'
- en: '[20] Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z.,
    Tang, J., Chen, X., Lin, Y., et al.: A survey on large language model based autonomous
    agents. Frontiers of Computer Science 18(6), 186345 (2024)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z.,
    Tang, J., Chen, X., Lin, Y., 等: 基于大型语言模型的自主智能体调查。计算机科学前沿 18(6)，186345（2024）'
- en: '[21] Wang, W.Y., Du, W.W., Xu, D., Wang, W., Peng, W.C.: A survey on self-supervised
    learning for non-sequential tabular data. arXiv preprint arXiv:2402.01204 (2024)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Wang, W.Y., Du, W.W., Xu, D., Wang, W., Peng, W.C.: 面向非顺序表格数据的自监督学习调查。arXiv预印本
    arXiv:2402.01204（2024）'
- en: '[22] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., Zhou, D.: Self-consistency improves chain of thought reasoning in language
    models. arXiv preprint arXiv:2203.11171 (2022)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery,
    A., Zhou, D.: 自一致性提高语言模型中的思维链推理能力。arXiv预印本 arXiv:2203.11171（2022）'
- en: '[23] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V.,
    Zhou, D., et al.: Chain-of-thought prompting elicits reasoning in large language
    models. Advances in neural information processing systems 35, 24824–24837 (2022)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V.,
    Zhou, D., 等: 思维链提示法激发大型语言模型中的推理能力。神经信息处理系统进展 35, 24824–24837（2022）'
- en: '[24] Yang, Y., Wang, Y., Sen, S., Li, L., Liu, Q.: Unleashing the Potential
    of Large Language Models for Predictive Tabular Tasks in Data Science (2024)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Yang, Y., Wang, Y., Sen, S., Li, L., Liu, Q.: 释放大型语言模型在数据科学中进行预测表格任务的潜力（2024）'
- en: '[25] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.:
    React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629
    (2022)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y.:
    React：协同推理与行动的语言模型。arXiv预印本 arXiv:2210.03629（2022）'
- en: '[26] Ye, H.J., Zhou, Q., Zhan, D.C.: Training-free generalization on heterogeneous
    tabular data via meta-representation (2023)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Ye, H.J., Zhou, Q., Zhan, D.C.: 通过元表示在异质表格数据上的免训练泛化（2023）'
- en: '[27] Ye, J., Du, M., Wang, G.: DataFrame QA: A Universal LLM Framework on DataFrame
    Question Answering Without Data Exposure (2024)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Ye, J., Du, M., Wang, G.: DataFrame QA：一种无需数据曝光的通用LLM框架用于DataFrame问答（2024）'
- en: '[28] Yoon, J., Feldt, R., Yoo, S.: Intent-driven mobile gui testing with autonomous
    large language model agents. In: 2024 IEEE Conference on Software Testing, Verification
    and Validation (ICST). IEEE (2024)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Yoon, J., Feldt, R., Yoo, S.: 基于意图的移动GUI测试与自主大型语言模型智能体。2024年IEEE软件测试、验证与验证会议（ICST），IEEE（2024）'
- en: '[29] Zhang, H., Wen, X., Zheng, S., Xu, W., Bian, J.: Towards foundation models
    for learning on tabular data. arXiv preprint arXiv:2310.07338 (2023)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Zhang, H., Wen, X., Zheng, S., Xu, W., Bian, J.: 面向表格数据学习的基础模型探索。arXiv预印本
    arXiv:2310.07338（2023）'
- en: '[30] Zhang, T., Wang, S., Yan, S., Li, J., Liu, Q.: Generative table pre-training
    empowers models for tabular prediction. arXiv preprint arXiv:2305.09696 (2023)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Zhang, T., Wang, S., Yan, S., Li, J., Liu, Q.: 生成性表格预训练赋能模型进行表格预测。arXiv预印本
    arXiv:2305.09696（2023）'
- en: '[31] Zhang, X., Zhang, J., Ma, Z., Li, Y., Zhang, B., Li, G., Yao, Z., Xu,
    K., Zhou, J., Zhang-Li, D., Yu, J., Zhao, S., Li, J., Tang, J.: TableLLM: Enabling
    Tabular Data Manipulation by LLMs in Real Office Usage Scenarios (2024)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] 张, X., 张, J., 马, Z., 李, Y., 张, B., 李, G., 姚, Z., 许, K., 周, J., 张李, D.,
    余, J., 赵, S., 李, J., 唐, J.：TableLLM：在真实办公场景中通过LLM实现表格数据操作（2024）'
- en: '[32] Zhang, Z., Yao, Y., Zhang, A., Tang, X., Ma, X., He, Z., Wang, Y., Gerstein,
    M., Wang, R., Liu, G., et al.: Igniting language intelligence: The hitchhiker’s
    guide from chain-of-thought reasoning to language agents. arXiv preprint arXiv:2311.11797
    (2023)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] 张, Z., 姚, Y., 张, A., 唐, X., 马, X., 何, Z., 王, Y., Gerstein, M., 王, R.,
    刘, G., 等：点燃语言智能：从链式思维推理到语言代理的搭车指南。arXiv预印本 arXiv:2311.11797（2023）'
- en: '[33] Zhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans,
    D., Cui, C., Bousquet, O., Le, Q., et al.: Least-to-most prompting enables complex
    reasoning in large language models. arXiv preprint arXiv:2205.10625 (2022)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] 周, D., Schärli, N., 侯, L., 魏, J., Scales, N., 王, X., Schuurmans, D., 崔,
    C., Bousquet, O., Le, Q., 等：从少到多的提示促进大型语言模型中的复杂推理。arXiv预印本 arXiv:2205.10625（2022）'
- en: '[34] Zhu, F., Liu, Z., Feng, F., Wang, C., Li, M., Chua, T.S.: TAT-LLM: A Specialized
    Language Model for Discrete Reasoning over Tabular and Textual Data (Feb 2024)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] 朱, F., 刘, Z., 冯, F., 王, C., 李, M., 蔡, T.S.：TAT-LLM：一种专门针对表格和文本数据离散推理的语言模型（2024年2月）'
