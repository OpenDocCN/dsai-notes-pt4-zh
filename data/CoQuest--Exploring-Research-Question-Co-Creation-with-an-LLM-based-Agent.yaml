- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 13:04:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 13:04:05
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'CoQuest: 探索基于大型语言模型的智能体在研究问题共创中的应用'
- en: 来源：[https://arxiv.org/html/2310.06155/](https://arxiv.org/html/2310.06155/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2310.06155/](https://arxiv.org/html/2310.06155/)
- en: Yiren Liu [yirenl2@illinois.edu](mailto:yirenl2@illinois.edu) University of
    Illinois Urbana-ChampaignUSA ,  Si Chen [sic3@illinois.edu](mailto:sic3@illinois.edu)
    University of Illinois Urbana-ChampaignUSA ,  Haocong Cheng [haocong2@illinois.edu](mailto:haocong2@illinois.edu)
    University of Illinois Urbana-ChampaignUSA ,  Mengxia Yu [myu2@nd.edu](mailto:myu2@nd.edu)
    University of Notre DameUSA ,  Xiao Ran [xiaor2@illinois.edu](mailto:xiaor2@illinois.edu)
    University of Illinois Urbana-ChampaignUSA ,  Andrew Mo [jiajunm3@illinois.edu](mailto:jiajunm3@illinois.edu)
    University of Illinois Urbana-ChampaignUSA ,  Yiliu Tang [yiliut2@illinois.edu](mailto:yiliut2@illinois.edu)
    University of Illinois Urbana-ChampaignUSA  and  Yun Huang [yunhuang@illinois.edu](mailto:yunhuang@illinois.edu)
    University of Illinois Urbana-ChampaignUSA(2024; 2024)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 刘一任 [yirenl2@illinois.edu](mailto:yirenl2@illinois.edu) 伊利诺伊大学厄本那-香槟分校，美国，陈思
    [sic3@illinois.edu](mailto:sic3@illinois.edu) 伊利诺伊大学厄本那-香槟分校，美国，程浩聪 [haocong2@illinois.edu](mailto:haocong2@illinois.edu)
    伊利诺伊大学厄本那-香槟分校，美国，余梦霞 [myu2@nd.edu](mailto:myu2@nd.edu) 圣母大学，美国，任晓 [xiaor2@illinois.edu](mailto:xiaor2@illinois.edu)
    伊利诺伊大学厄本那-香槟分校，美国，莫安德鲁 [jiajunm3@illinois.edu](mailto:jiajunm3@illinois.edu) 伊利诺伊大学厄本那-香槟分校，美国，唐一柳
    [yiliut2@illinois.edu](mailto:yiliut2@illinois.edu) 伊利诺伊大学厄本那-香槟分校，美国，黄云 [yunhuang@illinois.edu](mailto:yunhuang@illinois.edu)
    伊利诺伊大学厄本那-香槟分校，美国（2024年；2024年）
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: 'Developing novel research questions (RQs) often requires extensive literature
    reviews, especially in interdisciplinary fields. To support RQ development through
    human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based
    agent system named CoQuest. We conducted an experiment with 20 HCI researchers
    to examine the impact of two interaction designs: breadth-first and depth-first
    RQ generation. The findings revealed that participants perceived the breadth-first
    approach as more creative and trustworthy upon task completion. Conversely, during
    the task, participants considered the depth-first generated RQs as more creative.
    Additionally, we discovered that AI processing delays allowed users to reflect
    on multiple RQs simultaneously, leading to a higher quantity of generated RQs
    and an enhanced sense of control. Our work makes both theoretical and practical
    contributions by proposing and evaluating a mental model for human-AI co-creation
    of RQs. We also address potential ethical issues, such as biases and over-reliance
    on AI, advocating for using the system to improve human research creativity rather
    than automating scientific inquiry. The system’s source is available at: [https://github.com/yiren-liu/coquest](https://github.com/yiren-liu/coquest).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 开发新颖的研究问题（RQ）通常需要广泛的文献综述，尤其是在跨学科领域。为了支持通过人机协同创造研究问题，我们利用大型语言模型（LLM）构建了一个基于LLM的智能体系统，命名为CoQuest。我们与20位HCI（人机交互）研究人员进行了一次实验，考察了两种互动设计对RQ生成的影响：广度优先和深度优先。研究结果显示，参与者在任务完成后认为广度优先的方法更具创意且更值得信赖。相反，在任务进行过程中，参与者认为深度优先生成的RQ更具创意。此外，我们发现AI处理延迟使得用户能够同时反思多个RQ，从而生成更多的RQ并增强了控制感。我们的工作通过提出并评估一个人机共创RQ的心理模型，做出了理论和实践上的贡献。我们还探讨了潜在的伦理问题，如偏见和过度依赖AI，提倡使用该系统来提升人类的研究创造力，而不是自动化科学探究。该系统的源代码可在以下链接获取：[https://github.com/yiren-liu/coquest](https://github.com/yiren-liu/coquest)。
- en: 'Scientifc Discovery, Large Language Models, Co-creation Systems, Mixed-initiative
    Design^†^†copyright: acmcopyright^†^†journalyear: 2024^†^†doi: XXXXXXX.XXXXXXX^†^†conference:
    ; ; Honolulu, HI^†^†booktitle: CHI 2024^†^†price: 15.00^†^†isbn: 978-1-4503-XXXX-X/18/06^†^†journalyear:
    2024^†^†copyright: acmlicensed^†^†conference: Proceedings of the CHI Conference
    on Human Factors in Computing Systems; May 11–16, 2024; Honolulu, HI, USA^†^†booktitle:
    Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI ’24),
    May 11–16, 2024, Honolulu, HI, USA^†^†doi: 10.1145/3613904.3642698^†^†isbn: 979-8-4007-0330-0/24/05^†^†ccs:
    Human-centered computing Empirical studies in HCI^†^†ccs: Human-centered computing Interactive
    systems and tools^†^†ccs: Computing methodologies Natural language processing'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 科学发现，大型语言模型，共同创造系统，混合倡议设计^†^†版权：acmcopyright^†^†期刊年份：2024^†^†doi：XXXXXXX.XXXXXXX^†^†会议：；；檀香山，夏威夷^†^†书名：CHI
    2024^†^†价格：15.00^†^†isbn：978-1-4503-XXXX-X/18/06^†^†期刊年份：2024^†^†版权：acmlicensed^†^†会议：计算机系统中的人类因素
    CHI 会议论文集；2024年5月11日至16日；夏威夷檀香山^†^†书名：计算机系统中的人类因素 CHI 会议论文集（CHI ’24），2024年5月11日至16日，夏威夷檀香山，美国^†^†doi：10.1145/3613904.3642698^†^†isbn：979-8-4007-0330-0/24/05^†^†ccs：以人为本的计算
    人机交互领域的实证研究^†^†ccs：以人为本的计算 交互系统与工具^†^†ccs：计算方法 语义处理
- en: 'Figure 1. CoQuest enables Human-AI co-creation of research questions (RQs)
    using LLMs through a three-panel design: RQ Flow Editor, Paper Graph Visualizer,
    and AI Thoughts. Major features of the RQ Flow Editor panel include: (a) offering
    either breadth-first and depth-first RQ generation (see Figure [4](https://arxiv.org/html/2310.06155v3#S5.F4
    "Figure 4 ‣ 5.1.2\. RQ Flow Editor: Two Design Options ‣ 5.1\. CoQuest Interaction
    Design ‣ 5\. CoQuest System Design and Implementation ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent")); (b) enabling users to provide
    feedback to AI based on a generated RQ, and to explore related papers in details
    on the Paper Graph Visualizer panel; and (c) presenting the rationale behind RQ
    generation on the AI Thoughts panel when a link between two RQs is clicked.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. CoQuest 通过三面板设计：RQ 流编辑器、论文图可视化器和 AI 思想，使人类与 AI 共同创造研究问题（RQ）。RQ 流编辑器面板的主要功能包括：(a)
    提供广度优先和深度优先的 RQ 生成方式（见图 [4](https://arxiv.org/html/2310.06155v3#S5.F4 "图4 ‣ 5.1.2\.
    RQ 流编辑器：两种设计选项 ‣ 5.1\. CoQuest 交互设计 ‣ 5\. CoQuest 系统设计与实现 ‣ CoQuest：基于 LLM 的代理探索研究问题的共同创造")）；(b)
    使用户能够根据生成的 RQ 向 AI 提供反馈，并在论文图可视化器面板中详细探索相关论文；(c) 当点击两个 RQ 之间的链接时，在 AI 思想面板上呈现
    RQ 生成的理由。
- en: '![Refer to caption](img/c2a988547fc2492ec62781431d48843a.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c2a988547fc2492ec62781431d48843a.png)'
- en: 'This is an overview of the CoQuest system interface. There are three panels.
    The main panel is the RQ Flow Editor Panel with 2 design options, detailed in
    Figure 4\. There are six nodes presented on this panel: three on the left, three
    on the right. The three nodes on the left are each connected to a node not included
    in this diagram. The top left node is connected to three nodes on the right. Each
    edge had text associated on it. The top right node is expanded with more content
    and a different color. The top left node is denoted (a), the expanded node on
    the top right is denoted (b), and one of the edges is denoted (c). On the right
    of RQ Flow Editor Panel is the Paper Graph Visualizer Panel, which presents an
    interactive graph. Each paper node on the network represents a paper. One paper
    node is selected and the details of this paper is presented below the graph on
    this panel. On the bottom-left of the RQ Flow Editor Panel is the AI Thoughts
    Panel, which has three blocks of texts on it.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 CoQuest 系统界面的概述。界面分为三面板。主面板是 RQ 流编辑器面板，具有两种设计选项，详见图4。此面板上展示了六个节点：左侧三个，右侧三个。左侧的三个节点分别与图中未包含的节点相连。左上角节点连接到右侧的三个节点，每条边上都有相关的文本。右上角的节点展开了更多内容，并且颜色不同。左上角的节点标记为（a），右上角展开的节点标记为（b），其中一条边标记为（c）。RQ
    流编辑器面板右侧是论文图可视化器面板，呈现一个交互式图形。网络中的每个论文节点代表一篇论文。当选中一个论文节点时，该论文的详细信息会显示在图形下方的面板上。RQ
    流编辑器面板的左下角是 AI 思想面板，其中有三块文本。
- en: 'Figure 1. CoQuest enables Human-AI co-creation of research questions (RQs)
    using LLMs through a three-panel design: RQ Flow Editor, Paper Graph Visualizer,
    and AI Thoughts. Major features of the RQ Flow Editor panel include: (a) offering
    either breadth-first and depth-first RQ generation (see Figure [4](https://arxiv.org/html/2310.06155v3#S5.F4
    "Figure 4 ‣ 5.1.2\. RQ Flow Editor: Two Design Options ‣ 5.1\. CoQuest Interaction
    Design ‣ 5\. CoQuest System Design and Implementation ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent")); (b) enabling users to provide
    feedback to AI based on a generated RQ, and to explore related papers in details
    on the Paper Graph Visualizer panel; and (c) presenting the rationale behind RQ
    generation on the AI Thoughts panel when a link between two RQs is clicked.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1. CoQuest 通过三面板设计实现了人类与人工智能共同创造研究问题（RQ），包括：RQ 流编辑器、论文图可视化工具和 AI 思维面板。RQ
    流编辑器面板的主要功能包括：（a）提供广度优先和深度优先的 RQ 生成选项（见图 [4](https://arxiv.org/html/2310.06155v3#S5.F4
    "图 4 ‣ 5.1.2\. RQ 流编辑器：两种设计选项 ‣ 5.1\. CoQuest 互动设计 ‣ 5\. CoQuest 系统设计与实现 ‣ CoQuest:
    探索基于 LLM 的代理进行研究问题共创")）；（b）使用户能够根据生成的 RQ 向 AI 提供反馈，并在论文图可视化工具面板中详细探索相关论文；（c）当点击两个
    RQ 之间的链接时，在 AI 思维面板中展示 RQ 生成的背后推理过程。'
- en: 1\. Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: Identifying research questions (RQs) is a critical step of scientific research
    and discovery (Elio et al., [2011](https://arxiv.org/html/2310.06155v3#bib.bib14)).
    To formulate creative and valuable research ideas, researchers often start with
    searching and scoping the relevant literature, especially when the search involves
    works spanning multiple domains (Kang et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib30)).
    Developing research questions is also iterative, that researchers would first
    have an initial idea or topic in mind, then conduct a literature search to refine
    the ideas, and repeat this process until they have a satisfying research idea
    (Foster, [2004](https://arxiv.org/html/2310.06155v3#bib.bib19)). Reading a large
    body of literature, synthesizing them, and identifying the relevant work can be
    rather time-consuming.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 确定研究问题（RQ）是科学研究和发现的关键步骤（Elio 等人，[2011](https://arxiv.org/html/2310.06155v3#bib.bib14)）。为了提出有创意且有价值的研究想法，研究人员通常从检索和梳理相关文献开始，尤其是当搜索涉及跨多个领域的工作时（Kang
    等人，[2022](https://arxiv.org/html/2310.06155v3#bib.bib30)）。研究问题的形成也是一个迭代过程，研究人员首先有一个初步的想法或主题，然后进行文献搜索以完善这些想法，并不断重复这一过程，直到他们有一个令人满意的研究创意（Foster，[2004](https://arxiv.org/html/2310.06155v3#bib.bib19)）。阅读大量文献、综合整理并识别相关工作的过程可能非常耗时。
- en: With the rapid development of Large Language Models (LLMs), scholars have investigated
    the potential of harnessing the power of LLMs to support the process of research
    literature discovery (Ought, [2023](https://arxiv.org/html/2310.06155v3#bib.bib55);
    Qureshi et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib60); Consensus,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib10)), which helps users significantly
    speed up the literature discovery process. Meanwhile, the thriving of generative
    AI technologies has also been widely used in various fields to promote creativity
    (Epstein et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib15); Yuan et al.,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib88); Mirowski et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib49)).
    For example, a recent study has found that more than 4.9% of users used ChatGPT
    to support creative ideation (Fishkin, [2023](https://arxiv.org/html/2310.06155v3#bib.bib18)).
    Although recent research has demonstrated the potential of using smaller language
    models to generate novel RQs (Liu et al., [2023b](https://arxiv.org/html/2310.06155v3#bib.bib43)),
    there remains a lack of empirical understanding about how humans evaluate AI-generated
    RQs. Given that LLMs are known to have problems with hallucination and lack of
    factual accuracy (Ji et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib28)),
    creating high-quality RQs requires inputs from human researchers for their unique
    backgrounds and expertise. Enabling humans and AI to co-create novel research
    questions is particularly promising for conducting interdisciplinary research.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模语言模型（LLMs）的快速发展，学者们已经探讨了利用LLMs的潜力来支持研究文献发现过程（Ought, [2023](https://arxiv.org/html/2310.06155v3#bib.bib55);
    Qureshi et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib60); Consensus,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib10)），这帮助用户显著加快了文献发现的过程。与此同时，生成性人工智能技术的蓬勃发展也在各个领域得到广泛应用，促进了创造力的发展（Epstein
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib15); Yuan et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib88);
    Mirowski et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib49)）。例如，最近的一项研究发现，超过4.9%的用户使用ChatGPT支持创意构思（Fishkin,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib18)）。尽管近期的研究已经展示了使用较小语言模型生成新颖的研究问题（RQ）的潜力（Liu
    et al., [2023b](https://arxiv.org/html/2310.06155v3#bib.bib43)），但关于人类如何评估人工智能生成的研究问题仍然缺乏实证理解。鉴于大规模语言模型已知存在幻觉和缺乏事实准确性的问题（Ji
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib28)），创建高质量的研究问题需要来自人类研究人员的输入，因其拥有独特的背景和专业知识。使人类与人工智能共同创造新颖的研究问题，尤其有助于开展跨学科研究。
- en: The concept of human-AI co-creation draws insights from pioneering research
    on mixed-initiative systems, where human users and computer systems contribute
    to a shared goal (Horvitz, [1999](https://arxiv.org/html/2310.06155v3#bib.bib24);
    Yannakakis et al., [2014](https://arxiv.org/html/2310.06155v3#bib.bib84)). Recent
    academic endeavors have also introduced a variety of design guidelines for human-AI
    co-creation systems (Rezwana and Maher, [2022](https://arxiv.org/html/2310.06155v3#bib.bib63);
    Weisz et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib79); Lin et al.,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib40)), further inspiring the
    intricate design considerations of mixed-initiative systems. For instance, Rezwana
    and Maher ([2022](https://arxiv.org/html/2310.06155v3#bib.bib63)) explored whether
    the exchange of initiatives between humans and AI should be designed as either
    parallel or in a turn-taking manner. However, there remains a gap in empirical
    research regarding the influence of AI-driven initiatives or creativity on user
    experiences, such as their perception of the creative process, trust in the AI,
    and sense of control. Moreover, the potential impact of these factors on the results
    of human-AI co-creation, such as the quality of generated content, has yet to
    be investigated.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 人类与人工智能共创的概念从混合主动系统的开创性研究中汲取了启示，在这些系统中，人类用户和计算机系统共同为一个共享目标做出贡献（Horvitz, [1999](https://arxiv.org/html/2310.06155v3#bib.bib24);
    Yannakakis et al., [2014](https://arxiv.org/html/2310.06155v3#bib.bib84)）。近年来的学术努力也提出了多种人类与人工智能共创系统的设计指南（Rezwana
    and Maher, [2022](https://arxiv.org/html/2310.06155v3#bib.bib63); Weisz et al.,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib79); Lin et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib40)），进一步激发了混合主动系统的复杂设计考虑。例如，Rezwana
    和 Maher（[2022](https://arxiv.org/html/2310.06155v3#bib.bib63)）探讨了人类与人工智能之间的主动权交换是否应设计为并行进行或轮流进行。然而，关于人工智能驱动的主动权或创造力对用户体验的影响，仍然存在实证研究的空白，例如他们对创作过程的认知、对人工智能的信任以及对控制感的体验。此外，这些因素对人类与人工智能共创成果的潜在影响，例如生成内容的质量，仍未得到充分研究。
- en: 'To this end, we proposed a novel system called CoQuest, which allows an AI
    agent to initiate RQ generation by tapping the power of LLMs and taking humans’
    feedback into a co-creation process. The system consists of three panels: RQ Flow
    Editor for supporting RQ generation, Paper Graph Visualizer for exploration of
    literature space, and AI Thoughts for explaining AI’s rationales. The system design
    was informed by a formative study, where we invited four researchers to verbalize
    their expected RQ-generation processes with AI support. The formative study yielded
    an initial mental model of human-AI co-creation for RQs. The system design was
    further evaluated with 20 participants who are HCI researchers through a within-subject
    experiment.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们提出了一个新颖的系统，名为CoQuest，它允许AI代理通过利用LLM的力量并将人类的反馈纳入共创过程来启动研究问题生成。该系统由三个面板组成：支持研究问题生成的RQ流程编辑器、用于探索文献空间的论文图可视化工具和用于解释AI推理的AI思维。系统设计是通过一项形成性研究得出的，在这项研究中，我们邀请了四位研究人员口头表达他们期望的AI支持下的研究问题生成过程。该形成性研究得出了一个初步的关于人类与AI共创研究问题的心理模型。该系统设计通过一项同质实验进一步评估，参与者为20名HCI研究人员。
- en: Our work makes novel and significant contributions as follows. Firstly, we made
    a theoretical contribution by proposing and evaluating a new mental model for
    human-AI co-creation of research questions in the HCI research domain. Second,
    we proposed a new agent LLM system and implemented two interaction designs (breadth-first
    and depth-first), where the AI agent took different levels of initiative in supporting
    users to develop RQs. Third, through a within-subject experiment with HCI researchers,
    we gained new empirical understandings of how AI’s different initiatives impact
    users’ perceived experiences and outcomes. Specifically, for overall experience,
    the breadth-first design made users “feel” more creative and gained more trust
    from users, though the effect varies by users’ research background; but when rating
    individual RQs, users scored the depth-first questions for higher creativity.
    Fourth, by closely observing participants’ interaction with AI, we discovered
    important co-creation behavior and proposed a new design implication, namely,
    intentionally “slowing down AI”, giving wait times for users to explore the co-creation
    space. This is especially beneficial for users to gain a stronger sense of control.
    Last but not least, we discussed the implications of our study for designing ethical
    human-AI co-creation systems, along with potential ethical concerns. We advocate
    for employing LLM-based systems to augment human creativity and support the ideation
    and scaffolding process, rather than using LLM-generated ideas for automating
    HCI research.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作做出了以下新颖且重要的贡献。首先，我们通过提出并评估一种新的心理模型，为人类与人工智能共同创造研究问题（RQ）的HCI研究领域做出了理论贡献。其次，我们提出了一个新的代理LLM系统，并实现了两种交互设计（广度优先和深度优先），在这些设计中，AI代理在支持用户开发研究问题时扮演了不同层次的主动角色。第三，通过与HCI研究人员进行的一项同质实验，我们获得了关于AI不同主动性如何影响用户感知体验和结果的新实证理解。具体而言，在整体体验上，广度优先设计让用户“感觉”更具创造力，并获得了更多的信任，尽管这一效果因用户的研究背景而有所不同；但在评价单个研究问题时，用户对深度优先问题的创造力评分更高。第四，通过密切观察参与者与AI的互动，我们发现了重要的共创行为，并提出了一项新的设计启示，即故意“放慢AI的速度”，给予用户探索共创空间的等待时间。这对用户获得更强的控制感尤其有益。最后但同样重要的是，我们讨论了本研究对设计伦理人类-人工智能共创系统的启示，以及潜在的伦理问题。我们主张采用基于LLM的系统来增强人类创造力，并支持构思和支架过程，而不是使用LLM生成的想法来自动化HCI研究。
- en: 2\. Related Work
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: 2.1\. Human-Led Literature Discovery and Research Idea Creation
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 以人为主的文献发现与研究创意生成
- en: 'Scholars have sought to understand the process of how researchers conduct literature
    discovery and formulate new research ideas (Glueck and Jauch, [1975](https://arxiv.org/html/2310.06155v3#bib.bib21);
    Pertsas and Constantopoulos, [2017](https://arxiv.org/html/2310.06155v3#bib.bib57)).
    Extensive works have strived to formulate the model of researchers’ scientific
    activities (Palmer et al., [2009](https://arxiv.org/html/2310.06155v3#bib.bib56);
    Vilar, [2015](https://arxiv.org/html/2310.06155v3#bib.bib72); Benardou et al.,
    [2010](https://arxiv.org/html/2310.06155v3#bib.bib2)). For example, Foster ([2004](https://arxiv.org/html/2310.06155v3#bib.bib19))
    proposed a framework of idea formulation in academic research from an information
    behavior perspective, which consists of three major components: Opening (initial
    exploration), Orientation (problem definition and literature survey) and Consolidation
    (knowledge creation). In this framework, literature discovery and idea formulation
    are discussed as a recursive and iterative process. Many studies have also been
    conducted to understand how researchers produce innovative ideas for research
    purposes (Yang et al., [2016](https://arxiv.org/html/2310.06155v3#bib.bib83)).
    For example, Jing et al. ([2015](https://arxiv.org/html/2310.06155v3#bib.bib29))
    proposed a system for research idea creation that incorporates knowledge reuse
    through ontology construction. Later work by (Guo and Laidlaw, [2020](https://arxiv.org/html/2310.06155v3#bib.bib22))
    introduced a system for supporting research ideation through topic modeling and
    visualization. Recently, Liu et al. ([2023b](https://arxiv.org/html/2310.06155v3#bib.bib43))
    proposed to generate new research questions using generative language models fine-tuned
    over related works and explicitly written research questions from publications
    within the HCI domain. But none of these works leveraged large language models
    (LLMs) or built an LLM-based system to examine human-AI co-creation RQ processes.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 学者们一直致力于理解研究人员如何进行文献发现和提出新研究思路的过程（Glueck 和 Jauch, [1975](https://arxiv.org/html/2310.06155v3#bib.bib21)；Pertsas
    和 Constantopoulos, [2017](https://arxiv.org/html/2310.06155v3#bib.bib57)）。大量研究努力提出研究人员科学活动的模型（Palmer
    等, [2009](https://arxiv.org/html/2310.06155v3#bib.bib56)；Vilar, [2015](https://arxiv.org/html/2310.06155v3#bib.bib72)；Benardou
    等, [2010](https://arxiv.org/html/2310.06155v3#bib.bib2)）。例如，Foster（[2004](https://arxiv.org/html/2310.06155v3#bib.bib19)）从信息行为的角度提出了一个学术研究中思路形成的框架，该框架由三个主要部分组成：开放（初步探索）、定向（问题定义与文献调查）和整合（知识创生）。在这个框架中，文献发现和思路形成被讨论为一个递归和迭代的过程。许多研究也致力于理解研究人员如何为研究目的产生创新性思路（Yang
    等, [2016](https://arxiv.org/html/2310.06155v3#bib.bib83)）。例如，Jing 等（[2015](https://arxiv.org/html/2310.06155v3#bib.bib29)）提出了一个通过本体构建实现知识重用的研究思路创生系统。之后，Guo
    和 Laidlaw（[2020](https://arxiv.org/html/2310.06155v3#bib.bib22)）提出了一个通过主题建模和可视化支持研究构思的系统。最近，Liu
    等（[2023b](https://arxiv.org/html/2310.06155v3#bib.bib43)）提出了使用生成性语言模型生成新的研究问题，该模型通过相关文献和HCI领域出版物中的明确书写的研究问题进行微调。然而，这些研究中没有任何一项利用大型语言模型（LLMs）或构建基于LLM的系统来研究人类与AI协作的研究问题（RQ）过程。
- en: 2.2\. Agent-based Large Language Model (LLM) Systems
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 基于代理的大型语言模型（LLM）系统
- en: Recent surge in the success of LLMs (OpenAI, [2023](https://arxiv.org/html/2310.06155v3#bib.bib53);
    Touvron et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib70)) has spurred
    strong interests in employing LLMs for solving complex tasks. There has recently
    been a heated wave of explorations in building autonomous agents using LLMs as
    a reasoning engine to solve different tasks, such as software development (Shinn
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib66); Qian et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib59)),
    gaming (Wang et al., [2023b](https://arxiv.org/html/2310.06155v3#bib.bib74)),
    and assisting social science research (Ziems et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib92)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，LLMs（OpenAI, [2023](https://arxiv.org/html/2310.06155v3#bib.bib53)；Touvron
    等, [2023](https://arxiv.org/html/2310.06155v3#bib.bib70)）的成功激发了强烈的兴趣，推动了人们利用LLMs解决复杂任务的研究。最近，使用LLMs作为推理引擎构建自主代理以解决不同任务的探索热潮不断升温，这些任务包括软件开发（Shinn
    等, [2023](https://arxiv.org/html/2310.06155v3#bib.bib66)；Qian 等, [2023](https://arxiv.org/html/2310.06155v3#bib.bib59)）、游戏（Wang
    等, [2023b](https://arxiv.org/html/2310.06155v3#bib.bib74)）以及辅助社会科学研究（Ziems 等,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib92)）。
- en: System designs are proposed for improving the method of prompting in Human-AI
    interaction systems enabled by LLMs (Wu et al., [2022b](https://arxiv.org/html/2310.06155v3#bib.bib82),
    [a](https://arxiv.org/html/2310.06155v3#bib.bib81); Dang et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib11)).
    To enhance the reasoning capabilities of LLMs, researchers proposed several prompting
    frameworks to elicit reasoning in LLMs by decomposing and solving the sub-tasks
    step by step by applying prompting techniques for general purposes, such as Chain-of-Thought
    (Wei et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib77); Kojima et al.,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib35)), Self-Consistency (Wang
    et al., [2023a](https://arxiv.org/html/2310.06155v3#bib.bib75)), Least-to-Most
    (Zhou et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib91)). These prompting
    techniques focus on improving the task-specific performance of LLMs. To build
    autonomous agents with LLMs, Yao et al. ([2022a](https://arxiv.org/html/2310.06155v3#bib.bib85))
    proposed a prompting framework named “ReAct” that unifies the ability of LLMs
    to reason, take actions, and observe the results. Recent research on LLM-based
    prompt engineering (Wang and Zhao, [2023](https://arxiv.org/html/2310.06155v3#bib.bib76))
    has explored a viable approach of introducing humans’ mental model as prompting
    techniques to boost LLM’s reasoning ability. These frameworks set a great foundation
    for Q&A reasoning or general-purpose tasks (Liu et al., [2023c](https://arxiv.org/html/2310.06155v3#bib.bib42)).
    In this paper, we applied LLM to build an agent for specialized tasks in the context
    of literature discovery and research ideation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了系统设计，以改进由大语言模型（LLMs）支持的人类-人工智能交互系统中的提示方法（Wu等，[2022b](https://arxiv.org/html/2310.06155v3#bib.bib82)，[a](https://arxiv.org/html/2310.06155v3#bib.bib81)；Dang等，[2022](https://arxiv.org/html/2310.06155v3#bib.bib11)）。为了增强LLMs的推理能力，研究人员提出了几种提示框架，通过逐步分解和解决子任务，应用通用目的的提示技术来引导LLMs进行推理，例如链式思维（Chain-of-Thought）（Wei等，[2022](https://arxiv.org/html/2310.06155v3#bib.bib77)；Kojima等，[2022](https://arxiv.org/html/2310.06155v3#bib.bib35)），自一致性（Self-Consistency）（Wang等，[2023a](https://arxiv.org/html/2310.06155v3#bib.bib75)），最小到最大（Least-to-Most）（Zhou等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib91)）。这些提示技术集中在提升LLMs在特定任务中的表现。为了构建具有自主性的LLM代理，Yao等人（[2022a](https://arxiv.org/html/2310.06155v3#bib.bib85)）提出了一种名为“ReAct”的提示框架，统一了LLMs进行推理、采取行动和观察结果的能力。最近关于基于LLM的提示工程的研究（Wang和Zhao，[2023](https://arxiv.org/html/2310.06155v3#bib.bib76)）探索了一种引入人类心理模型作为提示技术来提升LLM推理能力的可行方法。这些框架为问答推理或通用任务（Liu等，[2023c](https://arxiv.org/html/2310.06155v3#bib.bib42)）奠定了坚实的基础。在本文中，我们应用LLM构建了一个用于文献发现和研究构思的专业任务代理。
- en: 2.3\. Designing Human-AI Co-creation Systems
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3. 设计人类-人工智能共创系统
- en: Many human-AI co-creation systems utilize generative AI technologies (Sun et al.,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib69); Louie et al., [2020](https://arxiv.org/html/2310.06155v3#bib.bib46)).
    For example, Bilgram and Laarmann ([2023](https://arxiv.org/html/2310.06155v3#bib.bib3))
    showed that generative AI could augment the early phases of innovation, such as
    exploration, ideation, and digital prototyping. Epstein et al. ([2022](https://arxiv.org/html/2310.06155v3#bib.bib16))
    discovered that discrepancies between users’ expected outputs and the actual output
    from the system play a critical role in creating new ideas.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人类-人工智能共创系统利用了生成式AI技术（Sun等，[2022](https://arxiv.org/html/2310.06155v3#bib.bib69)；Louie等，[2020](https://arxiv.org/html/2310.06155v3#bib.bib46)）。例如，Bilgram和Laarmann（[2023](https://arxiv.org/html/2310.06155v3#bib.bib3)）展示了生成式AI可以增强创新的早期阶段，例如探索、构思和数字原型制作。Epstein等人（[2022](https://arxiv.org/html/2310.06155v3#bib.bib16)）发现，用户预期的输出与系统实际输出之间的差异在创造新想法中起着关键作用。
- en: 'Scholars and practitioners try to develop design guidelines for using generative
    AI (Weisz et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib79); Davis
    et al., [2015](https://arxiv.org/html/2310.06155v3#bib.bib12); Liu and Chilton,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib41); Muller et al., [2020](https://arxiv.org/html/2310.06155v3#bib.bib50)).
    From a role-based perspective, human-AI co-creation systems are found to be different
    from prior systems where machines mainly provide support to humans (Kantosalo
    and Jordanous, [2021](https://arxiv.org/html/2310.06155v3#bib.bib32)). In co-creation
    systems, both humans and AIs can be designed to take the initiative in producing
    creative artifacts (Oh et al., [2018](https://arxiv.org/html/2310.06155v3#bib.bib52);
    Guzdial et al., [2019](https://arxiv.org/html/2310.06155v3#bib.bib23)). Rezwana
    and Maher ([2022](https://arxiv.org/html/2310.06155v3#bib.bib63)) introduced a
    Co-Creative Framework for Interaction design (COFI), which categorizes mixed-initiative
    system designs into two types based on their styles of participation: parallel
    and turn-taking. The evaluation of mixed-initiative designs has been explored
    by recent research (Kreminski et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib36);
    Withington and Tokarchuk, [2023](https://arxiv.org/html/2310.06155v3#bib.bib80))
    in application domains such as poem writing and game design. Our research seeks
    to systematically model the co-creation process and provide both theoretical and
    practical implications in the scholarly research domain.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 学者和实践者们尝试为使用生成性AI制定设计指南（Weisz等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib79)；Davis等，[2015](https://arxiv.org/html/2310.06155v3#bib.bib12)；Liu和Chilton，[2022](https://arxiv.org/html/2310.06155v3#bib.bib41)；Muller等，[2020](https://arxiv.org/html/2310.06155v3#bib.bib50)）。从基于角色的视角来看，人与AI的共创系统被发现与先前的系统有所不同，后者主要是机器为人类提供支持（Kantosalo和Jordanous，[2021](https://arxiv.org/html/2310.06155v3#bib.bib32)）。在共创系统中，人工智能和人类都可以被设计成在创作过程中主动提供创意成果（Oh等，[2018](https://arxiv.org/html/2310.06155v3#bib.bib52)；Guzdial等，[2019](https://arxiv.org/html/2310.06155v3#bib.bib23)）。Rezwana和Maher（[2022](https://arxiv.org/html/2310.06155v3#bib.bib63)）介绍了一个面向互动设计的共创框架（COFI），该框架根据参与方式将混合主动性系统设计分为两种类型：并行式和轮流式。近期的研究探索了混合主动性设计的评估（Kreminski等，[2022](https://arxiv.org/html/2310.06155v3#bib.bib36)；Withington和Tokarchuk，[2023](https://arxiv.org/html/2310.06155v3#bib.bib80)），应用领域包括诗歌创作和游戏设计。我们的研究旨在系统地建模共创过程，并为学术研究领域提供理论和实践上的启示。
- en: In this study, we propose and examine a new agent LLM system that helps researchers
    formulate research questions by combining LLMs’ reasoning ability with the mental
    model we discovered through a formative study with actual researchers. We also
    discuss whether LLM-based co-creation systems can help facilitate the process
    of information gathering and idea evolution using user study results to provide
    new empirical understandings.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究提出并检验了一种新的代理LLM系统，该系统通过结合LLM的推理能力与我们通过与实际研究人员的形成性研究发现的心理模型，帮助研究人员制定研究问题。我们还讨论了基于LLM的共创系统是否能利用用户研究结果促进信息收集和创意演化的过程，从而提供新的实证理解。
- en: 3\. Research Questions
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 研究问题
- en: 'Given the above literature and identified research gaps, we aim to address
    the following research questions:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述文献和已识别的研究空白，我们旨在解决以下研究问题：
- en: 'RQ1 (perception & outcome): How do users perceive the co-creation experience
    (e.g., trust, control, feeling of being creative) and outcomes (creativity ratings
    of generated RQs) when using the CoQuest system?'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RQ1（感知与结果）：用户在使用CoQuest系统时，如何看待共创体验（例如，信任、控制感、创造感）和结果（生成的研究问题的创造性评分）？
- en: 'RQ2 (behavior): How do users interact with AI when it provides different levels
    of initiatives during the co-creation process?'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RQ2（行为）：当AI在共创过程中提供不同层次的主动性时，用户如何与其互动？
- en: 'RQ3 (relationship): What behavioral factors are associated with users’ enhanced
    perceived experience and outcomes in human-AI co-creation?'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RQ3（关系）：哪些行为因素与用户在人工智能共创中的增强感知体验和结果相关？
- en: In the remainder of this paper, we will first present the formative study, where
    we developed an initial mental model for RQ co-creation between humans and AI.
    We then introduce the system design and our experimental study and detail the
    findings in the order of the proposed research questions. We will conclude with
    an in-depth discussion on the updated mental model informed by our findings and
    explore design implications for future work. Note that we use RQ1, RQ2, and RQ3
    to refer to our three research questions in the remainder of the paper, whereas
    RQ and RQs are used to refer to the research questions co-created by the user
    and AI.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的剩余部分，我们将首先展示形成性研究，我们在其中开发了一个初步的研究问题共同创作的心理模型，旨在探索人类与AI之间的互动。接着，我们介绍系统设计、实验研究，并按提出的研究问题顺序详细说明研究结果。最后，我们将深入讨论我们的研究发现所更新的心理模型，并探讨对未来工作的设计启示。请注意，在本文剩余部分，我们使用RQ1、RQ2和RQ3来指代我们的三个研究问题，而RQ和RQs则指代用户与AI共同创作的研究问题。
- en: 4\. Formative Study
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 形成性研究
- en: We conducted a formative study in order to understand the cognitive process
    of researchers creating research questions. To understand how researchers create
    RQs, we first conducted semi-structured interviews with 4 HCI researchers about
    how they formulate research questions. We then organized a focus group with the
    same group of interviewed participants to identify their needs for an RQ co-creation
    system.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项形成性研究，目的是了解研究人员创建研究问题的认知过程。为了理解研究人员如何创建研究问题，我们首先与四位HCI（人机交互）研究人员进行了半结构化访谈，探讨他们如何制定研究问题。然后，我们组织了一个焦点小组，与同一组受访者一起讨论他们对研究问题共同创作系统的需求。
- en: We invited four researchers to participate in our semi-structured interviews
    to understand their process of conducting research. All four participants were
    doctoral researchers. We asked the interviewees to describe their most recent
    experience starting a research project from scratch. Most participants mentioned
    starting from a rough idea (e.g., domains, keywords, application scenarios) before
    searching for related literature. Participants also emphasized that formulating
    research ideas is often an iterative process. Typically, participants used one
    or multiple hypothetical research questions/ideas to facilitate the search for
    related literature and identify research gaps. This process was described by the
    participants as both time-consuming and labor-intensive. Participants also identified
    their process of research question creation as hierarchical. One participant explicitly
    mentioned that creating research questions naturally resembles the form of a “mind
    map”, where the development of ideas gradually “narrows down” but could have different
    branches. As described by the participants, the initial set of RQs can often be
    broader and more general and can subsequently derive sub-RQs under the topics
    of their predecessors, which helps facilitate the trade-off between specific and
    general ideas as a common decision-making step during the research ideation process.
    This process often resulted in the evolution of RQs that, when visualized, could
    be drawn as a tree of RQs. This later informed the design of our system to take
    the form of an interactive “mind map” that preserved the provenance of RQ development.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们邀请了四位研究人员参加我们的半结构化访谈，以了解他们进行研究的过程。所有四位参与者都是博士研究人员。我们要求受访者描述他们最近一次从零开始启动研究项目的经历。大多数参与者提到，在查找相关文献之前，他们通常会从一个粗略的想法（例如，领域、关键词、应用场景）开始。参与者还强调，制定研究思路通常是一个迭代过程。通常，参与者会使用一个或多个假设性的研究问题/思路来促进相关文献的检索并识别研究空白。参与者描述这一过程既费时又费力。参与者还认为他们的研究问题创作过程具有层次性。一位参与者明确提到，创建研究问题自然类似于“思维导图”的形式，其中思路的发展逐渐“收缩”，但也可能有不同的分支。参与者描述道，初步的研究问题集通常较为广泛和一般化，随后可以在其前置主题下派生出子问题，这有助于在研究构思过程中作为常见的决策步骤，权衡具体与一般的思路。这个过程通常导致研究问题的演变，若将其可视化，可以画成一个研究问题的树形结构。这一过程后续为我们的系统设计提供了灵感，使其呈现为一个互动的“思维导图”，保留了研究问题发展的来源。
- en: (a) Feature Design.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 功能设计.
- en: '![Refer to caption](img/66f99fde134f0a17473d8724a19ee8c5.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/66f99fde134f0a17473d8724a19ee8c5.png)'
- en: The feature design screenshot was presented on sticky notes on this diagram.
    The sticky notes were grouped into five themes, with different number of notes
    in each group. There are also three yellow notes on top of the groups.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 特性设计截图展示在这张图表中的便利贴上。便利贴被分为五个主题，每个主题中的便利贴数量不同。图表顶部还放置了三张黄色便利贴。
- en: (a) Feature Design.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 特性设计。
- en: (b) Workflow Design.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 工作流程设计。
- en: '![Refer to caption](img/1635e109b326f0ba251583676bfa0e9d.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/1635e109b326f0ba251583676bfa0e9d.png)'
- en: The workflow design screenshot was presented on sticky notes on this diagram.
    Six sticky notes on the right are inside a rectangular shape with text ”Iterative
    co-creation.” Five more sticky notes are on the left outside the rectangular.
    All notes, except one white note on the left, are connected to at least one other
    note.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程设计截图展示在这张图表中的便利贴上。右侧的六张便利贴处于一个矩形框内，框内写着“迭代共同创造”。左侧的五张便利贴在矩形框外。除了左侧的一张白色便利贴外，所有便利贴都与至少一张其他便利贴相连。
- en: (b) Workflow Design.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 工作流程设计。
- en: Figure 2. Screenshots of content created by participants using Miro during the
    focus group study.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. 参与者在焦点小组研究中使用 Miro 创建的内容截图。
- en: 'After the first interview study, the same participants were invited back to
    a focus group session, where we aimed to identify their needs based on their research
    workflow and propose interaction design to support the process. The focus group
    went through two steps. First, participants were given three questions created
    by researchers as cues, and then were asked to brainstorm ideas and design expectations
    given the context of an AI-based system that supports research question development.
    The three question cues were designed as follows: 1) What questions will you ask
    the AI system? 2) What information do you want to provide for the model to generate
    RQ for you? 3) How do you produce RQ currently? And do you think the AI model
    can help you produce RQs? The ideas created by participants are shown in Figure
    [2](https://arxiv.org/html/2310.06155v3#S4.F2 "Figure 2 ‣ 4\. Formative Study
    ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次访谈研究后，同样的参与者被邀请回到焦点小组会议中，在此次会议中，我们旨在根据他们的研究工作流程识别需求，并提出支持该过程的互动设计。焦点小组分为两步进行。首先，研究人员给参与者提供了三个人工智能系统创建的问题作为提示，然后让他们根据支持研究问题发展的基于
    AI 的系统的背景来头脑风暴想法和设计期望。三个人工智能问题提示的设计如下：1）你会问人工智能系统什么问题？ 2）你希望提供哪些信息给模型，以便它为你生成研究问题？
    3）你目前如何生成研究问题？你认为人工智能模型能帮助你生成研究问题吗？参与者创作的想法如图 [2](https://arxiv.org/html/2310.06155v3#S4.F2
    "图 2 ‣ 4\. 形成性研究 ‣ CoQuest：与基于大语言模型的代理探索研究问题共同创造") 所示。
- en: After discussion and summarizing themes, participants were asked to proceed
    to the second step inspired by participatory approaches, where they discussed
    a hypothetical workflow by contextualizing themselves using an AI-based RQ co-creation
    system. During the focus group, we found that participants highlighted several
    expectations for designing a human-AI RQ co-creation system. Participants mentioned
    that the system should enable strong user control by taking into consideration
    users’ inputs (e.g., ideas, keywords, and domain concepts), when generating new
    RQs. The ability for the system to generate different variations of RQs with high
    diversity was also deemed a preferred design, where the user should be allowed
    to choose from the outputs based on their preference and expertise.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论并总结主题后，参与者被要求进入第二步，这一步灵感来自于参与式方法，在该步骤中，他们通过使用基于 AI 的研究问题共同创造系统来将自己置于一个假设的工作流程中。在焦点小组讨论中，我们发现参与者强调了在设计人类-AI
    共同创造研究问题系统时的若干期望。参与者提到，系统应当能够强烈地控制用户输入（例如，想法、关键词和领域概念），以生成新的研究问题。同时，系统能够生成多种高多样性的研究问题也是一种首选设计，用户应该能够根据个人的偏好和专业选择输出结果。
- en: 'Human-AI Co-Creation of Research Questions (RQs): a Mental Model After completing
    the formative study, we summarized the findings and proposed a new mental model
    aiming to capture the major interactions during the process of Human-AI Co-Creation
    for RQs.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能与人类共同创造研究问题（RQ）：一种思维模型 完成形成性研究后，我们总结了研究结果并提出了一种新的思维模型，旨在捕捉人类与人工智能共同创造研究问题过程中的主要互动。
- en: Figure 3. Participants’ mental model of co-creating RQs with an LLM-based AI
    agent is delineated as follows. An “action” labeled with an AI icon denotes that
    participants perceived that AI could significantly reduce the ”labor”; a human
    icon means that participants were expected to evaluate AI-generated RQs and provide
    feedback to drive the iterative process. However, it is hard to determine how
    human and AI share the task of “refine and re-scope,” as it depends on individual
    expertise and the clarity of the intended research focus.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 参与者与基于LLM的AI代理共同创造RQ的心理模型如下所示。带有AI图标的“动作”表示参与者认为AI能够显著减少“劳动”；而带有人类图标的动作则意味着参与者需要评估AI生成的RQ并提供反馈，以推动迭代过程。然而，很难确定人类和AI如何共享“精炼与重新定义”的任务，因为这取决于个人的专业知识和研究焦点的清晰度。
- en: '![Refer to caption](img/ce79f659b5201937d20808ccb9d7ef44.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ce79f659b5201937d20808ccb9d7ef44.png)'
- en: 'This is human’s mental model of RQ co-creation with the LLM-based agent. There
    are four components inside this model: Present RQs and Explain AI Thoughts (lower
    left, rectangular), Understand the Literature (center, rectangular), Literature
    Space (top, with cylinder shape), and Refine and Re-scope (lower right, rectangular).
    From Present RQs and Explain AI Thoughts to Refine and Re-scope, there are two
    user-driven activities: Evaluate RQ creativity, feasibility, etc., and Provide
    feedback. From Refine and Re-scope to Understand the Literature, there is one
    user- and AI-driven activity: Incorporate Human Feedback. From Understand the
    Literature to Present RQs and Explain AI Thoughts, there is one AI-driven activity:
    Bootstrap Initial RQs. From Understand the Literature to Literature Space, there
    is one AI-driven activity: Search and select. From Literature space to Understand
    the Literature, there is one AI-driven activity: Summarize and Integrate. The
    model has ”Initial idea / keywords” as input and ”Well-defined High Quality RQs”
    as output.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是人类与基于LLM的代理共同创造RQ的心理模型。该模型包含四个组成部分：呈现RQ并解释AI思维（左下方，矩形），理解文献（中间，矩形），文献空间（顶部，圆柱形），以及精炼与重新定义（右下方，矩形）。从呈现RQ并解释AI思维到精炼与重新定义，有两个由用户驱动的活动：评估RQ的创造性、可行性等，并提供反馈。从精炼与重新定义到理解文献，有一个由用户和AI共同驱动的活动：整合人类反馈。从理解文献到呈现RQ并解释AI思维，有一个由AI驱动的活动：引导初始RQ。从理解文献到文献空间，有一个由AI驱动的活动：搜索与选择。从文献空间到理解文献，有一个由AI驱动的活动：总结与整合。该模型的输入为“初始想法/关键词”，输出为“明确定义的高质量RQ”。
- en: Figure 3. Participants’ mental model of co-creating RQs with an LLM-based AI
    agent is delineated as follows. An “action” labeled with an AI icon denotes that
    participants perceived that AI could significantly reduce the ”labor”; a human
    icon means that participants were expected to evaluate AI-generated RQs and provide
    feedback to drive the iterative process. However, it is hard to determine how
    human and AI share the task of “refine and re-scope,” as it depends on individual
    expertise and the clarity of the intended research focus.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 参与者与基于LLM的AI代理共同创造RQ的心理模型如下所示。带有AI图标的“动作”表示参与者认为AI能够显著减少“劳动”；而带有人类图标的动作则意味着参与者需要评估AI生成的RQ并提供反馈，以推动迭代过程。然而，很难确定人类和AI如何共享“精炼与重新定义”的任务，因为这取决于个人的专业知识和研究焦点的清晰度。
- en: 'The proposed mental model consists of three major components: Understand Literature,
    Present RQs and Explain AI Thoughts, and Refine and Re-scope. Past research has
    provided in-depth discussion over how literature discovery plays a major role
    in the scientific research process (Foster, [2004](https://arxiv.org/html/2310.06155v3#bib.bib19);
    Palmer et al., [2009](https://arxiv.org/html/2310.06155v3#bib.bib56)). However,
    such models were often discussed in a human-only context. Our formative study
    results indicate the importance of considering AI as a “collaborator” during the
    process of research ideation (Kim and Maher, [2023](https://arxiv.org/html/2310.06155v3#bib.bib34)).
    Refining research questions has also often been interpreted as a sub-step of literature
    search and understanding. Although research ideation and literature search are
    mutually dependent, our formative study results indicated a distinction between
    the behaviors researchers conducted during the two different stages. The process
    of literature discovery often involves reading and summarizing a wide range of
    existing works. Participants emphasized their challenges during the process of
    literature search and discovery, especially for unfamiliar domains, and the need
    for AI to facilitate this process with less human involvement. AI can be best
    used to perform factual summarization and distillation of findings and knowledge
    before presenting them to humans. On the contrary, proposing and refining research
    questions often requires more creative thinking and generalization beyond past
    knowledge. In this scenario, it is crucial to involve both humans and AI through
    the design of mix-initiative co-creation systems in order to combine humans’ expertise
    and preference with AI’s general world knowledge. Moreover, our formative study
    findings explicate the evaluation of RQs as an additional component during the
    RQ co-creation process. This process, as discussed during the formative study,
    should utilize human expertise and the ability to conduct follow-up research and
    validation.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的心理模型由三个主要组成部分构成：理解文献、呈现研究问题（RQ）并解释AI思维、以及细化和重新界定。以往的研究深入讨论了文献发现如何在科学研究过程中发挥重要作用（Foster,
    [2004](https://arxiv.org/html/2310.06155v3#bib.bib19); Palmer等人, [2009](https://arxiv.org/html/2310.06155v3#bib.bib56)）。然而，这些模型通常是在仅限人类的背景下进行讨论的。我们的形成性研究结果表明，在研究构思过程中，将AI视为“合作者”是至关重要的（Kim和Maher,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib34)）。细化研究问题也常被视为文献搜索和理解的一个子步骤。尽管研究构思与文献搜索相互依赖，我们的形成性研究结果表明，在这两个不同阶段，研究者的行为存在区别。文献发现过程通常涉及阅读和总结大量现有的工作。参与者强调了在文献搜索和发现过程中，特别是在不熟悉的领域中的挑战，并且表达了需要AI在这一过程中减少人类干预的需求。AI在执行事实总结和提炼发现及知识方面最为有效，然后再将其呈现给人类。相反，提出和细化研究问题通常需要更具创意的思维和超越过去知识的归纳。在这种情况下，通过设计混合主动性共同创作系统，确保人类和AI的合作至关重要，以便将人类的专业知识和偏好与AI的通用世界知识相结合。此外，我们的形成性研究结果明确了在研究问题共同创作过程中，评估研究问题作为一个附加环节的重要性。正如在形成性研究中所讨论的那样，该过程应利用人类的专业知识和进行后续研究及验证的能力。
- en: 'Design Requirements Based on our findings from the focus group and the proposed
    mental model, we also propose the following design requirements for the system:
    The system should be able to 1) assist users’ brainstorming process by automatically
    generating RQ candidates by taking human feedback; 2) support users’ sensemaking
    of AI’s outputs by Explaining the rationale behind the generation; 3) help users
    discover relevant literature and identify research gaps.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 设计需求：基于我们从焦点小组和提议的心理模型中获得的发现，我们还提出了以下系统设计需求：该系统应该能够 1）通过接受用户反馈，自动生成研究问题（RQ）候选项，协助用户的头脑风暴过程；
    2）通过解释生成背后的理由，支持用户对AI输出结果的理解； 3）帮助用户发现相关文献并识别研究空白。
- en: 5\. CoQuest System Design and Implementation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. CoQuest系统设计与实现
- en: Based on our findings from the formative study, we designed and implemented
    an LLM-based system that supports human-AI co-creation of creative research questions.
    In this section, we provide details about the design of 1) the three-panel interface
    of the CoQuest system, including two different designs to provide varied degrees
    of AI initiative; and 2) the agent LLM backend of the CoQuest system.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们从形成性研究中获得的发现，我们设计并实现了一个基于大语言模型（LLM）的系统，支持人类与AI共同创作创新的研究问题。在这一部分，我们提供了关于1）CoQuest系统三面板界面的设计细节，包括两种不同的设计，提供不同程度的AI主动性；以及2）CoQuest系统的代理LLM后端的设计细节。
- en: 5.1\. CoQuest Interaction Design
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. CoQuest互动设计
- en: 'To support RQ co-creation, we designed features of the CoQuest systems around
    the two-way communication between users and the AI, where users and AI take turns
    during the communication process. As shown in Figure [1](https://arxiv.org/html/2310.06155v3#S0.F1
    "Figure 1 ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent"), our proposed system consists of three major panels:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '为了支持RQ共同创作，我们设计了CoQuest系统的功能，围绕用户与AI之间的双向交流展开，在交流过程中用户和AI轮流进行交互。如图[1](https://arxiv.org/html/2310.06155v3#S0.F1
    "Figure 1 ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent")所示，我们提出的系统由三个主要面板组成：'
- en: (1)
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: RQ Flow Editor that facilitates a user’s major interactions, such as generating
    RQs, providing input and feedback to AI, and editing the RQ flow (e.g., drag and
    delete);
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RQ流程编辑器，便于用户进行主要操作，如生成RQ、向AI提供输入和反馈、以及编辑RQ流程（例如，拖动和删除）；
- en: (2)
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: Paper Graph Visualizer that displays the literature space related to each RQ;
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文献图可视化工具，展示与每个RQ相关的文献空间；
- en: (3)
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: AI Thoughts that explains AI’s rationale of why each RQ is generated.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AI思路，解释AI生成每个RQ的理由。
- en: 5.1.1\. Example User Walkthrough
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1\. 示例用户演练
- en: Consider a user of the CoQuest system, Jamie, who is a junior doctoral student
    with a research direction in Human-Computer Interaction. Jamie has previously
    been familiar with publications related to interaction design for online learning
    systems. With recent exposure to social media discussions on VR and AR applications,
    they wanted to explore the potential of such applications in the domain of online
    learning. Jamie formed an initial idea of using AR to promote learner’s brainstorming.
    However, without a deeper understanding of the literature space from the VR and
    AR domain, they found it challenging to refine and improve upon the idea further.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个使用CoQuest系统的用户，Jamie，是一名人机交互方向的博士生。Jamie之前已经熟悉与在线学习系统的互动设计相关的文献。最近，通过接触到关于虚拟现实（VR）和增强现实（AR）应用的社交媒体讨论，他们想探索这些应用在在线学习领域的潜力。Jamie最初想到了利用AR促进学习者的头脑风暴。然而，由于对VR和AR领域的文献了解不深，他们发现很难进一步完善和提升这个想法。
- en: Introduced with the CoQuest system, Jamie first created an initial idea node,
    typed down “Using AR to promote brainstorming,” and generated follow-up RQs by
    right clicking the node and selecting “generate RQs” using the RQ Flow Editor.
    Aware of Jamie’s initial idea, the CoQuest system retrieved several works related
    to the idea and generated follow-up RQ nodes along with rationales. Jamie first
    saw one of the RQ nodes with an RQ displayed as “How can social AR be designed
    to promote collaborative brainstorming?”
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用CoQuest系统时，Jamie首先创建了一个初步的想法节点，输入了“使用AR促进头脑风暴”，然后右键点击该节点，选择“生成RQ”以使用RQ流程编辑器生成后续的RQ。CoQuest系统根据Jamie的初步想法，检索了几篇与该想法相关的文献，并生成了跟进的RQ节点及其理由。Jamie首先看到其中一个RQ节点，RQ内容为：“如何设计社交AR以促进协作型头脑风暴？”
- en: Jamie was intrigued by the generated RQ, but also a bit confused since the concept
    of “social AR” appeared new to them. Jamie then clicked the RQ node and skimmed
    through the papers displayed on the Paper Graph Visualizer panel. Several papers
    seemed relevant to Jamie, and they further clicked the provided URL to read the
    papers in detail. The papers retrieved by CoQuest helped Jamie comprehend the
    domain knowledge behind the generated RQ.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Jamie对生成的RQ感到兴趣，但也有些困惑，因为“社交AR”这一概念对他们来说是新的。于是，Jamie点击了RQ节点，并浏览了在文献图可视化工具面板上显示的论文。几篇论文似乎与Jamie相关，他们进一步点击了提供的链接，详细阅读了这些论文。CoQuest系统检索到的文献帮助Jamie理解了生成的RQ背后的领域知识。
- en: After the reading, Jamie had a question in mind — “Why is using AR important
    for collaborative brainstorming?”. They then typed in this question as user feedback
    to the system and clicked to generate new RQs following up the previous RQ. One
    of the newly generated RQs, “How can spatial design in AR promote group-based
    collaborative brainstorming,” caught Jamie’s attention.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读后，Jamie心里产生了一个问题——“为什么使用AR对协作型头脑风暴很重要？”他们随后将这个问题输入作为用户反馈并点击生成新的RQ，跟进之前的RQ。新生成的RQ之一，“如何通过AR中的空间设计促进基于小组的协作型头脑风暴”，引起了Jamie的兴趣。
- en: The appearance of the concept “spatial design” raised Jamie’s interest, but
    they were unclear about the system’s rationale for generating this RQ from the
    previous question. By clicking on the edge connecting this RQ with its predecessor,
    they were able to examine the AI Thoughts panel explaining the rationales and
    actions taken by the agent LLM in the CoQuest backend that led to the RQ. The
    panel showed that the system performed action “hypothesize user cases” and one
    of the resulting use cases was shown as “Online learners can form groups and organize
    ideas by creating and organizing concepts and links in spatial AR environment.”
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: “空间设计”这一概念的出现激发了Jamie的兴趣，但他们对系统如何从前一个问题生成这个RQ的原理并不清楚。通过点击连接这个RQ和其前驱的边，他们能够查看AI思想面板，解释代理LLM在CoQuest后台为生成该RQ所采取的原理和行动。面板显示，系统执行了“假设用户案例”这一动作，其中一个生成的使用案例显示为“在线学习者可以通过在空间AR环境中创建和组织概念和链接来形成小组并组织想法。”
- en: '5.1.2\. RQ Flow Editor: Two Design Options'
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2. RQ流程编辑器：两种设计选项
- en: 'CoQuest offers an interactive RQ Flow Editor panel that allows users to co-create
    RQs with AI in an iterative manner. This panel is designed in a way to resemble
    the design of a mind map, where each RQ node represents a generated RQ (except
    the initial nodes, which only contain users’ initial ideas). This allows users
    to organize RQs more easily under different topics while preserving the hierarchical
    structure among different RQs, as suggested by the findings from the formative
    study in section [2](https://arxiv.org/html/2310.06155v3#S4.F2 "Figure 2 ‣ 4\.
    Formative Study ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent"). Users can type in their rough ideas or keywords by creating an initial
    node. When users click on one of the nodes, the node expands, and users can 1)
    type in textual user feedback to AI in the text box; and 2) right-click on the
    node to generate more follow-up RQs. The generated RQs will be connected with
    annotated edges to the source RQ node. The RQ generation will result in one or
    several Directed Acyclic Graphs (DAGs), which we will later refer to as RQ flows,
    that embed both the hierarchical relations between generated RQs. Users can perform
    basic interactions using the RQ flow editor, including zooming in/out and dragging
    the nodes to organize the flows to aid their thinking process.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest提供了一个互动式RQ流程编辑器面板，允许用户以迭代的方式与AI共同创建RQ。该面板的设计类似于思维导图的布局，其中每个RQ节点代表一个生成的RQ（初始节点除外，初始节点仅包含用户的初步想法）。这使得用户能够在不同的主题下更容易地组织RQ，同时保持不同RQ之间的层级结构，正如[2](https://arxiv.org/html/2310.06155v3#S4.F2
    "图2 ‣ 4\. 形成性研究 ‣ CoQuest：探索基于LLM代理的研究问题共创")章节中的形成性研究结果所建议的那样。用户可以通过创建初始节点输入自己的粗略想法或关键词。当用户点击某个节点时，节点会展开，用户可以：1)
    在文本框中输入对AI的文本反馈；以及2) 右键单击该节点生成更多后续的RQ。生成的RQ将通过带注释的边与源RQ节点连接。RQ生成将导致一个或多个有向无环图（DAGs），我们以后将其称为RQ流程，嵌入了生成的RQ之间的层级关系。用户可以使用RQ流程编辑器进行基本的交互，包括放大/缩小和拖动节点以组织流程，从而帮助他们的思维过程。
- en: 'Two design options with different levels of AI initiative: Breadth-first and
    Depth-first generation. One of the major design options we considered for the
    CoQuest system is the degree of how much AI takes initiative during the co-creation
    process. During the formative study, we obtained an understanding of how users
    formulated their research questions in a hierarchical form, where follow-up RQs
    are iteratively created based on previous predecessor RQs. Intuitively, when formulating
    different RQs, the researcher might choose to explore different topics in a broader
    sense, or to dive deep into a specific topic. Thus, we consider two different
    designs when the system generates new RQs, as shown in Figure [4](https://arxiv.org/html/2310.06155v3#S5.F4
    "Figure 4 ‣ 5.1.2\. RQ Flow Editor: Two Design Options ‣ 5.1\. CoQuest Interaction
    Design ‣ 5\. CoQuest System Design and Implementation ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent"): 1) breadth-first generation: When
    a user initiates the generation of follow-up RQs, several RQs are produced simultaneously
    in parallel. These new questions are all at the same hierarchical level following
    the original question. 2) depth-first generation: In contrast, with this method,
    when a user initiates the generation, follow-up RQs are created one after the
    other, with each new question building upon the previous one in a sequential manner.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '两种具有不同级别AI主动性的设计选项：广度优先生成和深度优先生成。我们为CoQuest系统考虑的主要设计选项之一是AI在共同创作过程中主动性程度的选择。在形成性研究期间，我们理解了用户如何以层次化的形式制定他们的研究问题，其中后续的研究问题（RQ）是基于前置的研究问题（RQ）迭代生成的。直观来看，在制定不同的研究问题时，研究人员可能会选择以更广泛的方式探索不同的主题，或深入研究某一特定主题。因此，在系统生成新的研究问题时，我们考虑了两种不同的设计，如图[4](https://arxiv.org/html/2310.06155v3#S5.F4
    "Figure 4 ‣ 5.1.2\. RQ Flow Editor: Two Design Options ‣ 5.1\. CoQuest Interaction
    Design ‣ 5\. CoQuest System Design and Implementation ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent")所示：1）广度优先生成：当用户启动后续研究问题的生成时，多个研究问题会同时并行生成。这些新问题都处于与原问题相同的层次级别。2）深度优先生成：相比之下，采用此方法时，当用户启动生成时，后续的研究问题会一个接一个地生成，每个新问题都会在顺序上基于前一个问题进行构建。'
- en: The two designs impact the degree of initiative taken by AI in the CoQuest system.
    Under the breadth-first generation, the user will have the freedom to choose from
    multiple generated RQs and provide feedback at each turn of generation, and then
    proceed to generate more RQs if desired. As in the depth-first generation, the
    agent recursively generates a sequence of multiple RQs without user input during
    the process. During the depth-first generation, the agent needs to autonomously
    further “refine” the RQs multiple steps based on the previous steps’ results,
    thus taking more initiative during the co-creation. Although in both designs,
    AI actively participates in the co-creation process by turn-taking with the human
    (Rezwana and Maher, [2022](https://arxiv.org/html/2310.06155v3#bib.bib63)), there
    exists a difference between the degree of initiative taken by AI, as AI engages
    more actively during the depth-first generation compared to the breadth-first
    generation. By carrying out the within-subject study under the two designs, we
    aim to provide an empirical understanding of how initiative-driven design options
    can impact users’ behavior and perception using human-AI co-creation systems.
    To simplify the study design, we ensured that three RQs were generated per turn
    in both designs.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种设计影响了CoQuest系统中AI的主动性程度。在广度优先生成下，用户将有自由选择从多个生成的研究问题中挑选，并在每一轮生成时提供反馈，随后如果需要，可以继续生成更多的研究问题。而在深度优先生成中，代理会在没有用户输入的情况下递归地生成一系列研究问题。在深度优先生成过程中，代理需要根据前一步的结果进一步“细化”研究问题，因此在共同创作过程中表现出更多的主动性。尽管在这两种设计中，AI通过与人类轮流参与共同创作，但AI所采取的主动性存在差异，在深度优先生成中，AI相比于广度优先生成展现出更为积极的参与。通过在这两种设计下进行的被试内研究，我们旨在提供一种经验性的理解，探索主动性驱动的设计选项如何影响用户在使用人类与AI共同创作系统时的行为和感知。为了简化研究设计，我们确保在两种设计下每轮生成三个研究问题。
- en: 'Figure 4. The RQ Flow Editor panel in the CoQuest system features two distinct
    designs for generating research questions (RQs): the breadth-first and depth-first
    approaches. The breadth-first generation approach is designed to trigger the creation
    of multiple RQs in a single iteration, facilitating a wide exploration of potential
    research areas. In contrast, the depth-first generation focuses on triggering
    more iterations of RQ refinement, allowing the AI to delve deeper into a specific
    topic for a more focused and detailed exploration.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图4。CoQuest系统中的RQ流程编辑器面板展示了两种不同的研究问题（RQ）生成设计：广度优先和深度优先方法。广度优先生成方法旨在通过一次迭代触发多个RQ的生成，便于广泛探索潜在的研究领域。相比之下，深度优先生成则侧重于触发更多的RQ精炼迭代，使AI能够更深入地探索特定主题，从而进行更为集中的详细探索。
- en: '![Refer to caption](img/44275308012aa12d4aca88a412dc2d43.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/44275308012aa12d4aca88a412dc2d43.png)'
- en: 'The two design options are presented side by side. On the left is Design Option
    1: Breadth-first Generation. From a Source RQ node on the left, three generated
    RQ nodes on the right were connected with arrows. An additional arrow pointing
    toward three Generated RQ nodes shows that these three arrows are under iteration
    1\. On the right is Design Option 2: Depth-first Generation. From a Source RQ
    node, a first Generated RQ node is connected with an arrow. An additional arrow
    pointing toward the first Generated RQ node shows that this is iteration 1\. From
    the first Generated RQ, a second Generated RQ node is connected with an arrow.
    An additional arrow pointing toward the second Generated RQ node shows that this
    is iteration 2\. From the second Generated RQ, a third Generated RQ node is connected
    with an arrow. An additional arrow pointing toward the third Generated RQ node
    shows that this is iteration 3.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 两种设计选项并排展示。左侧是设计选项1：广度优先生成。从左侧的源RQ节点出发，三个生成的RQ节点通过箭头与右侧连接。额外的箭头指向这三个生成的RQ节点，表示这三条箭头属于迭代1。右侧是设计选项2：深度优先生成。从源RQ节点出发，第一个生成的RQ节点通过箭头连接。额外的箭头指向第一个生成的RQ节点，表示这是迭代1。从第一个生成的RQ节点出发，第二个生成的RQ节点通过箭头连接。额外的箭头指向第二个生成的RQ节点，表示这是迭代2。从第二个生成的RQ节点出发，第三个生成的RQ节点通过箭头连接。额外的箭头指向第三个生成的RQ节点，表示这是迭代3。
- en: 'Figure 4. The RQ Flow Editor panel in the CoQuest system features two distinct
    designs for generating research questions (RQs): the breadth-first and depth-first
    approaches. The breadth-first generation approach is designed to trigger the creation
    of multiple RQs in a single iteration, facilitating a wide exploration of potential
    research areas. In contrast, the depth-first generation focuses on triggering
    more iterations of RQ refinement, allowing the AI to delve deeper into a specific
    topic for a more focused and detailed exploration.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图4。CoQuest系统中的RQ流程编辑器面板展示了两种不同的研究问题（RQ）生成设计：广度优先和深度优先方法。广度优先生成方法旨在通过一次迭代触发多个RQ的生成，便于广泛探索潜在的研究领域。相比之下，深度优先生成则侧重于触发更多的RQ精炼迭代，使AI能够更深入地探索特定主题，从而进行更为集中的详细探索。
- en: '5.1.3\. Paper Graph Visualizer: Interactive Literature Graph'
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.3\. 论文图可视化器：交互式文献图
- en: 'The CoQuest system also provides an LLM-enabled literature discovery feature
    to assist users in efficiently identifying and exploring existing works related
    to each generated RQ. As shown in Figure [1](https://arxiv.org/html/2310.06155v3#S0.F1
    "Figure 1 ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent"), CoQuest’s literature discovery feature is presented in the Paper Graph
    Visualizer panel.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest系统还提供了基于LLM的文献发现功能，帮助用户高效地识别和探索与每个生成的RQ相关的现有工作。如图[1](https://arxiv.org/html/2310.06155v3#S0.F1
    "图1 ‣ CoQuest：基于LLM代理的研究问题共创探索")所示，CoQuest的文献发现功能呈现在论文图可视化器面板中。
- en: 'When a user clicks on one of the generated RQ nodes, the Paper Graph Visualizer
    panel reveals itself by visualizing the top-k most relevant papers along with
    their citation relations retrieved from our citation graph. The top-k papers are
    retrieved using our paper retrieval pipeline, as described in section [5.2.2](https://arxiv.org/html/2310.06155v3#S5.SS2.SSS2
    "5.2.2\. Related Paper Retrieval. ‣ 5.2\. CoQuest Backend and Implementation ‣
    5\. CoQuest System Design and Implementation ‣ CoQuest: Exploring Research Question
    Co-Creation with an LLM-based Agent"), using the text of the RQ clicked on by
    the user as the query. In the displayed citation graph, each paper node represents
    a paper, and each edge represents a citation relation. When the user hovers the
    cursor over one of the paper nodes, a tooltip will appear with a quick preview
    of the paper’s title information.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '当用户点击生成的任一RQ节点时，论文图可视化面板会展示自己，通过可视化从我们的引文图中检索到的最相关的前k篇论文及其引用关系。前k篇论文是通过我们的论文检索管道检索出来的，具体流程见第[5.2.2](https://arxiv.org/html/2310.06155v3#S5.SS2.SSS2
    "5.2.2\. 相关论文检索. ‣ 5.2\. CoQuest 后端和实现 ‣ 5\. CoQuest 系统设计和实现 ‣ CoQuest: 探索基于LLM的代理共同生成研究问题")节，查询使用的是用户点击的RQ文本。在展示的引文图中，每个论文节点代表一篇论文，每条边代表一种引用关系。当用户将光标悬停在某个论文节点上时，会出现一个提示框，快速预览该论文的标题信息。'
- en: The paper nodes in the citation graph are designed to be interactive. When the
    user clicks on one of the paper nodes , the detailed information of the selected
    paper will be displayed below. The information displayed includes the paper’s
    title, author names, abstract, a TLDR summary provided by Semantic Scholar API¹¹1https://www.semanticscholar.org/product/api,
    and a URL linking to the page of the paper on Semantic Scholar. Upon the click
    on the paper node, the Paper Graph Visualizer panel will also highlight the selected
    node and its nearest neighbors (nodes and edges) to indicate which paper(s) have
    directly cited the selected paper or been cited by the selected paper.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 引文图中的论文节点被设计为可交互。当用户点击某个论文节点时，所选论文的详细信息会显示在下面。显示的信息包括论文的标题、作者姓名、摘要、由Semantic
    Scholar API提供的TLDR摘要¹¹1https://www.semanticscholar.org/product/api，以及指向该论文在Semantic
    Scholar页面的URL。点击论文节点后，论文图可视化面板还会高亮所选节点及其最邻近的邻居节点（节点和边），以指示哪些论文直接引用了所选论文或被所选论文引用。
- en: '5.1.4\. AI Thoughts: Explaining AI Rationale'
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.4\. AI 思考：解释AI的推理
- en: 'The edges between RQ nodes represent the relation of which RQ the newly generated
    RQ is based on. They also contain information about the results of the actions
    undertaken by the agent leading up to the new RQ generated. When the user clicks
    on an edge, the AI Thoughts panel appears that displays the results of the agent’s
    action in a narrative format, as shown in the Figure [1](https://arxiv.org/html/2310.06155v3#S0.F1
    "Figure 1 ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent"). Detailed implementations of the LLM-based backend for generating RQs
    and rationales are provided below.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 'RQ节点之间的边表示新生成的RQ所依据的原RQ的关系。它们还包含有关代理执行的操作结果的信息，这些操作最终生成了新的RQ。当用户点击某条边时，AI 思考面板会以叙述格式显示代理的操作结果，如图[1](https://arxiv.org/html/2310.06155v3#S0.F1
    "图1 ‣ CoQuest: 探索基于LLM的代理共同生成研究问题")所示。下文将详细介绍用于生成RQ及其推理的基于LLM的后端实现。'
- en: 'Figure 5. Illustration of the CoQuest framework; The mental model of HCI researchers
    is used to build the LLM-based agent capable of accessing and querying a literature
    collection to generate research questions (RQs). This agent not only presents
    the generated RQs to the users but also provides the rationales behind their generation
    and literature grounding through the frontend interface. Examples of prompts used
    to build the agent can are available in Appendix [A.3](https://arxiv.org/html/2310.06155v3#A1.SS3
    "A.3\. Examples of LLM-based Agent Prompts and Responses ‣ Appendix A Appendices
    ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '图5. CoQuest框架示意图；HCI研究者的心理模型被用来构建一个基于LLM的代理，该代理能够访问和查询文献集合，以生成研究问题(RQs)。该代理不仅向用户展示生成的RQ，还通过前端界面提供生成过程的合理性解释和文献依据。用于构建代理的提示示例可以在附录[A.3](https://arxiv.org/html/2310.06155v3#A1.SS3
    "A.3\. 基于LLM的代理提示与响应示例 ‣ 附录A 附录 ‣ CoQuest: 探索基于LLM的代理共同生成研究问题")中找到。'
- en: '![Refer to caption](img/b2462e6900ec6e6465e9ad867e0e4250.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/b2462e6900ec6e6465e9ad867e0e4250.png)'
- en: 'This image is a diagram representing a user interface for a research co-creation
    platform. There are several components illustrated. User: This is likely where
    the user inputs information or interacts with the system. System Interface: Shows
    a workflow with several stages, probably indicating how the user can create research
    questions (RQ Creation) and see a visual representation of related research papers
    (Paper Graph). AI Thoughts panel: This might be a section where the system provides
    feedback or suggestions on how to narrow down research questions. CoQuest Agent:
    Depicts a robot icon, which suggests an AI or machine learning component that
    assists in the research process. LLM: Stands for Language Learning Model, indicating
    a machine learning model that processes natural language input. Co-Creation Mental
    Model: This section includes what appears to be a conceptual framework for how
    researchers interact with the system. Literature Pool: A database or collection
    of research literature that the system draws from. Paper Graph Visualizer panel:
    This panel displays relevant papers and citations based on the selected research
    question. The diagram is detailed and uses symbols like gears, magnifying glass,
    and a robot to represent different functions or processes within the platform.
    The overall design suggests a complex system designed to facilitate collaborative
    research efforts, possibly through AI-driven insights and a database of academic
    papers.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了一个用于研究共同创作平台的用户界面图示。图中描绘了几个组件。用户：这可能是用户输入信息或与系统互动的地方。系统接口：展示了一个包含多个阶段的工作流程，可能表明用户如何创建研究问题（RQ创建）并查看相关研究论文的可视化表示（论文图）。AI思维面板：这可能是一个系统提供反馈或建议的区域，帮助用户缩小研究问题的范围。CoQuest代理：图中展示了一个机器人图标，暗示着一个帮助研究过程的AI或机器学习组件。LLM：指的是语言学习模型，表示一个处理自然语言输入的机器学习模型。共同创作心智模型：这一部分似乎包括了一个概念框架，描述研究人员如何与系统互动。文献库：一个研究文献的数据库或集合，系统从中提取资料。论文图可视化面板：此面板根据所选的研究问题展示相关论文和引用。该图示详细且使用了齿轮、放大镜和机器人等符号来表示平台内不同的功能或过程。整体设计暗示着一个复杂的系统，旨在通过AI驱动的洞察和学术论文数据库来促进协作研究工作。
- en: 'Figure 5. Illustration of the CoQuest framework; The mental model of HCI researchers
    is used to build the LLM-based agent capable of accessing and querying a literature
    collection to generate research questions (RQs). This agent not only presents
    the generated RQs to the users but also provides the rationales behind their generation
    and literature grounding through the frontend interface. Examples of prompts used
    to build the agent can are available in Appendix [A.3](https://arxiv.org/html/2310.06155v3#A1.SS3
    "A.3\. Examples of LLM-based Agent Prompts and Responses ‣ Appendix A Appendices
    ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '图5. CoQuest框架的示意图；HCI研究人员的心智模型用于构建基于LLM的代理，能够访问和查询文献集合以生成研究问题（RQ）。该代理不仅向用户呈现生成的RQ，还通过前端接口提供生成过程的推理和文献依据。用于构建该代理的提示示例可在附录[A.3](https://arxiv.org/html/2310.06155v3#A1.SS3
    "A.3\. 基于LLM的代理提示和响应示例 ‣ 附录A 附录 ‣ CoQuest: 探索基于LLM的代理在研究问题共同创作中的应用")中查看。'
- en: 5.2\. CoQuest Backend and Implementation
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. CoQuest后台与实现
- en: 'The backend of the CoQuest system comprises an LLM-based agent that automatically
    generates RQs based on users’ input and feedback, by performing reasoning and
    executing actions that simulate a researcher’s mental model in a semi-autonomous
    manner. Two major functions of the CoQuest backend include: 1) the RQ generation
    ability of the LLM agent and 2) the related paper retrieval module that supports
    literature discovery. The framework of how the system’s backend connects with
    the major features are shown in Figure [5](https://arxiv.org/html/2310.06155v3#S5.F5
    "Figure 5 ‣ 5.1.4\. AI Thoughts: Explaining AI Rationale ‣ 5.1\. CoQuest Interaction
    Design ‣ 5\. CoQuest System Design and Implementation ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent").'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 'CoQuest系统的后台由一个基于LLM的代理组成，该代理根据用户的输入和反馈自动生成研究问题（RQ），通过推理和执行模拟研究人员心智模型的操作，半自动化地进行研究过程。CoQuest后台的两个主要功能包括：1）LLM代理的RQ生成能力；2）支持文献发现的相关论文检索模块。系统后台与主要功能的框架示意图见图[5](https://arxiv.org/html/2310.06155v3#S5.F5
    "图5 ‣ 5.1.4\. AI思维：解释AI推理 ‣ 5.1\. CoQuest交互设计 ‣ 5\. CoQuest系统设计与实现 ‣ CoQuest:
    探索基于LLM的代理在研究问题共同创作中的应用")。'
- en: 5.2.1\. Generating RQs with LLM-based Agent.
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 使用基于 LLM 的代理生成 RQ。
- en: 'The CoQuest system uses an LLM-based agent to generate creative research questions
    (RQs) following the ReAct framework (Yao et al., [2022b](https://arxiv.org/html/2310.06155v3#bib.bib86)),
    by adapting the “Think-Act-Observe” framework when designing the prompting method.
    First, the ”Think” step analyzes user input and context to decide an action, resembling
    human research methods detailed in [2](https://arxiv.org/html/2310.06155v3#S4.F2
    "Figure 2 ‣ 4\. Formative Study ‣ CoQuest: Exploring Research Question Co-Creation
    with an LLM-based Agent"). During this round, the LLM generates a chain of thought
    (following our designed prompt) before reaching the conclusion of the action as
    the next step. The actions are executable sub-processes whose results will be
    used as additional context to help the LLM generate better RQs. The available
    actions include: 1) Search and summarize related works (Literature Discovery);
    2) Hypothesizing use cases (Proposition); 3) Scoping/narrowing down (Refinement);
    4) Reflection through comparison with existing works (Evaluation). Next, during
    the “Act” and “Observe” steps, the execution of actions is achieved in the format
    of API calls through prompting and can be later parsed and executed through one
    or multiple pre-implemented Python functions (e.g., retrieve_papers and summarize_papers).
    After the next action has been inferred during the “Think” step, the agent executes
    the action and appends the results of the action to the context. Finally, for
    the agent to generate RQs at each step, we added an additional step of creating
    RQs at the end of each “Observe” step. At this step, new RQs are generated based
    on the provided context and instructions that combine the output from the performed
    action and predefined prompt. The detailed usage of prompts in the backend can
    be found in Appendix [A.3](https://arxiv.org/html/2310.06155v3#A1.SS3 "A.3\. Examples
    of LLM-based Agent Prompts and Responses ‣ Appendix A Appendices ‣ CoQuest: Exploring
    Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest 系统使用基于 LLM 的代理，遵循 ReAct 框架（Yao 等，[2022b](https://arxiv.org/html/2310.06155v3#bib.bib86)）生成创意研究问题（RQ），通过在设计提示方法时适应“Think-Act-Observe”框架。首先，"Think"
    步骤分析用户输入和上下文，以决定行动，类似于[2](https://arxiv.org/html/2310.06155v3#S4.F2 "图 2 ‣ 4\.
    形成性研究 ‣ CoQuest：探索基于 LLM 的代理共同创作研究问题")中详细描述的人类研究方法。在这一轮中，LLM 会生成一系列思维链（遵循我们设计的提示），然后得出作为下一步行动的结论。这些行动是可执行的子过程，其结果将作为额外的上下文，帮助
    LLM 生成更好的 RQ。可用的行动包括：1）搜索并总结相关文献（文献发现）；2）假设使用案例（假设）；3）范围界定/缩小（细化）；4）通过与现有工作对比进行反思（评估）。接下来，在“Act”和“Observe”步骤中，行动的执行通过提示以
    API 调用的格式实现，并可以通过一个或多个预实现的 Python 函数（例如，retrieve_papers 和 summarize_papers）进行解析和执行。在“Think”步骤中推断出下一步行动后，代理执行该行动，并将该行动的结果添加到上下文中。最后，为了让代理在每个步骤中生成
    RQ，我们在每个“Observe”步骤的末尾添加了生成 RQ 的额外步骤。在此步骤中，基于提供的上下文和结合执行的动作输出及预定义提示的指令生成新的 RQ。关于后台提示的详细使用，可以参考附录
    [A.3](https://arxiv.org/html/2310.06155v3#A1.SS3 "A.3\. 基于 LLM 的代理提示和响应示例 ‣ 附录
    A 附录 ‣ CoQuest：探索基于 LLM 的代理共同创作研究问题")。
- en: 5.2.2\. Related Paper Retrieval.
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2\. 相关论文检索。
- en: 'In order to help users identify related works more easily, the CoQuest system
    employs a retrieval pipeline to gather existing papers related to the RQs that
    the users are developing. We curated a literature citation graph from an existing
    pool of HCI papers, where the nodes represent papers, and the edges represent
    citation relations. The CoQuest system uses a sentence-based semantic embedding
    model (Reimers and Gurevych, [2019](https://arxiv.org/html/2310.06155v3#bib.bib62))
    to obtain vector representations of each paper in the citation graph. Given a
    paper’s title, metadata, and abstract in text form and a given query (e.g., RQs
    and user input), the sentence embedding model encodes them into semantic embeddings.
    After obtaining the embeddings of papers and the query, the system calculates
    the similarity between paper candidates and the query. This is done through re-ranking
    using Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, [1998](https://arxiv.org/html/2310.06155v3#bib.bib8)).
    Then, the system ranks the paper candidates and selects the top-k papers with
    the highest similarity scores as the final related papers to visualize. More details
    on the implementation of the retrieval pipeline are discussed in [5.2.3](https://arxiv.org/html/2310.06155v3#S5.SS2.SSS3
    "5.2.3\. System Implementation ‣ 5.2\. CoQuest Backend and Implementation ‣ 5\.
    CoQuest System Design and Implementation ‣ CoQuest: Exploring Research Question
    Co-Creation with an LLM-based Agent").'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助用户更容易地识别相关的研究成果，CoQuest系统采用了检索管道来收集与用户正在开发的研究问题（RQ）相关的现有论文。我们从现有的HCI文献池中策划了一个文献引用图，其中节点代表论文，边表示引用关系。CoQuest系统使用基于句子的语义嵌入模型（Reimers和Gurevych，[2019](https://arxiv.org/html/2310.06155v3#bib.bib62)）来获得引用图中每篇论文的向量表示。给定论文的标题、元数据和摘要文本，以及给定的查询（例如，研究问题和用户输入），句子嵌入模型将它们编码为语义嵌入。获取论文和查询的嵌入后，系统计算论文候选和查询之间的相似度。这是通过使用最大边际相关性（MMR）（Carbonell和Goldstein，[1998](https://arxiv.org/html/2310.06155v3#bib.bib8)）重新排序来完成的。然后，系统对论文候选进行排序，并选择相似度得分最高的前k篇论文作为最终的相关论文进行可视化。检索管道的实现细节在[5.2.3](https://arxiv.org/html/2310.06155v3#S5.SS2.SSS3
    "5.2.3\. 系统实现 ‣ 5.2\. CoQuest后端与实现 ‣ 5\. CoQuest系统设计与实现 ‣ CoQuest：探索与LLM代理的研究问题共同创作")中进行了详细讨论。
- en: 5.2.3\. System Implementation
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3\. 系统实现
- en: The CoQuest system is implemented in Typescript as a web application using ReactJS
    and TailwindCSS for the frontend. The interactive flow editor is implemented using
    React Flow²²2https://github.com/wbkd/react-flow/. The application backend uses
    Python with FastAPI³³3https://github.com/tiangolo/fastapi/ as the RESTful API
    server framework. We use AutoGPT⁴⁴4https://github.com/Significant-Gravitas/Auto-GPT/
    as the foundation of our agent-based LLM implementation⁵⁵5https://github.com/yiren-liu/coquest.
    We used the gpt3.5-turbo-16k model by OpenAI as our LLM engine and text-embedding-ada-002
    model as the sentence embedding model through the cloud service API provided by
    Microsoft Azure. We collected a fixed set of open-access publications through
    the Semantic Scholar API covering several major HCI conferences (including CHI,
    CSCW, UIST, Group, IMWUT, IJHCI, and IUI). The final collection of publications
    includes 2,043 papers.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest系统是用Typescript实现的Web应用程序，前端使用ReactJS和TailwindCSS。交互式流程编辑器是使用React Flow²²2https://github.com/wbkd/react-flow/实现的。应用程序的后端使用Python与FastAPI³³3https://github.com/tiangolo/fastapi/作为RESTful
    API服务器框架。我们使用AutoGPT⁴⁴4https://github.com/Significant-Gravitas/Auto-GPT/作为我们的基于代理的LLM实现的基础⁵⁵5https://github.com/yiren-liu/coquest。我们使用OpenAI的gpt3.5-turbo-16k模型作为我们的LLM引擎，并通过微软Azure提供的云服务API使用text-embedding-ada-002模型作为句子嵌入模型。我们通过Semantic
    Scholar API收集了一组固定的开放获取出版物，涵盖了多个主要的HCI会议（包括CHI、CSCW、UIST、Group、IMWUT、IJHCI和IUI）。最终的出版物集合包括2043篇论文。
- en: 6\. User Study Evaluating Co-Creation with CoQuest
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 用户研究：评估与CoQuest的共同创作
- en: To further understand the effect of the CoQuest system and how two designs of
    RQ generation impact users’ human-AI co-creation behavior, we conducted a within-subjects
    user study with 20 HCI researchers from 8 different institutions by asking the
    participants to create new research questions using the CoQuest system. All participants
    were graduate students currently enrolled or just graduated with prior experience
    with research. During the study process, we collected participants’ behavior and
    perception (i.e., ratings towards RQs, and ratings towards the CoQuest system)
    data for mixed-method (quantitative and qualitative) analysis. All studies were
    completed remotely online over video calls, where participants were asked to share
    their screens. Participants were also free to withdraw at any point during the
    study. Study procedures were approved by the IRB of the researchers’ institution.
    We compensated participants $20 per hour for the user study. Studies lasted 1-2
    hours, including two tasks using two designs (breadth-first and depth-first generations),
    a survey after each task, and an exit interview.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步了解CoQuest系统的效果，以及RQ生成的两种设计如何影响用户的人工智能与人类共同创作行为，我们进行了一个被试内实验，邀请了来自8个不同机构的20名HCI研究人员，要求参与者使用CoQuest系统生成新的研究问题。所有参与者均为当前在读或刚毕业的研究生，且具备研究经验。在研究过程中，我们收集了参与者的行为和感知数据（即对研究问题的评价和对CoQuest系统的评价），以进行混合方法（定量和定性）分析。所有研究均通过视频通话远程在线完成，参与者需要共享屏幕。参与者也可以在研究的任何阶段自由退出。研究程序得到了参与者所在机构伦理委员会（IRB）的批准。我们为每位参与者提供每小时20美元的报酬。研究持续了1-2小时，包括两项使用两种设计（广度优先和深度优先生成）的任务，每项任务后都有一份问卷，以及一次退出面谈。
- en: '6.1\. Within-Subjects User Study - Two Tasks with Assigned Condition: Breadth-First
    vs. Depth-first'
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 被试内实验 - 分配条件下的两项任务：广度优先与深度优先
- en: 'A within-subjects user study was conducted to understand the difference in
    users’ behavior and perception of the system potentially brought by the two different
    conditions using the two designs, referred to as breadth-first condition and depth-first
    condition. Each participant was asked to complete two tasks: During each task,
    we asked each participant to complete a task designed by researchers to simulate
    real-life scenarios of research idea formulation. The two task topics used in
    this study are: “AR/VR for education and learning” and “AI and crowdsourcing”.
    The two topics were chosen since they cover a wide range of specific domains and
    provide ample opportunities for users to explore and drill down on related topics.
    To account for the effect of the chronological order of both the task topics and
    conditions on the results, we followed a counterbalanced design (Pollatsek and
    Well, [1995](https://arxiv.org/html/2310.06155v3#bib.bib58)) by randomizing the
    experiment conditions so that all possible orders and combinations were randomly
    assigned to an equal number of participants. Participants were encouraged to think
    aloud during the tasks.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解用户在两种不同条件下的行为和对系统的感知差异，我们进行了一个被试内实验，条件分别为广度优先条件和深度优先条件。每位参与者需要完成两项任务：在每个任务中，我们要求参与者完成由研究人员设计的任务，以模拟研究构思的真实场景。此次研究使用的两个任务主题是：“教育与学习中的AR/VR”和“人工智能与众包”。选择这两个主题是因为它们涵盖了广泛的具体领域，并为用户提供了丰富的机会去探索并深入相关主题。为了考虑任务主题和条件的时间顺序对结果的影响，我们采用了平衡设计（Pollatsek
    和 Well, [1995](https://arxiv.org/html/2310.06155v3#bib.bib58)），通过随机化实验条件，使所有可能的顺序和组合都被随机分配给等数量的参与者。鼓励参与者在任务过程中大声思考。
- en: 6.2\. Data Collection and Analysis
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 数据收集与分析
- en: 'We collected both users’ perception and behavior data to perform a comprehensive
    evaluation of the CoQuest system. To understand users’ perception of the CoQuest
    system, we gathered two types of perception data from participants: individual
    ratings for each generated RQ (RQ ratings), which reflects users’ perception of
    their co-creation outcomes; and overall post-task evaluations of the system (system
    ratings), which reflects users’ perception of their co-creation experience. Users’
    behavior data was also collected in the form of system logs and video recordings
    for later analysis.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了用户的感知数据和行为数据，以对 CoQuest 系统进行全面评估。为了了解用户对 CoQuest 系统的感知，我们从参与者那里收集了两种类型的感知数据：每个生成的
    RQ 的个别评分（RQ 评分），反映用户对其共同创作结果的感知；以及系统的整体任务后评估（系统评分），反映用户对共同创作体验的感知。用户的行为数据也通过系统日志和视频录制的形式收集，以供后续分析。
- en: '6.2.1\. Co-Creation Outcome: Rating AI-Generated RQs During Each Task'
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1. 共同创作结果：在每个任务中对 AI 生成的 RQ 进行评分
- en: The RQ ratings are collected on the fly during each task of the study, where
    participants were asked to rate at least six RQs of their choice. These ratings
    are intended to capture the immediate perception of users towards the co-creation
    outcomes (i.e., generated RQs). The during-task rating collection was designed
    with the intention of nudging users to actively evaluate the RQs during the co-creation
    process, and also as a way to reflect the accurate user perception in real-time.
    We adopt Boden’s criteria (Boden, [2004](https://arxiv.org/html/2310.06155v3#bib.bib4))
    to measure creativity from three different aspects- novelty, value, surprise,
    and relevance. Participants can give ratings using a 5-point Likert scale slider
    positioned under each RQ node.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: RQ 评分是在每个任务进行过程中实时收集的，参与者被要求至少评定六个自己选择的 RQ。这些评分旨在捕捉用户对共同创作结果（即生成的 RQ）的即时感知。任务过程中评分的收集设计旨在引导用户在共同创作过程中积极评估
    RQ，并且作为一种方式，实时反映用户的准确感知。我们采用 Boden 的标准（Boden, [2004](https://arxiv.org/html/2310.06155v3#bib.bib4)）从三个不同的方面——新颖性、价值、惊讶和相关性来衡量创造力。参与者可以使用一个
    5 分 Likert 量表滑块，在每个 RQ 节点下进行评分。
- en: '6.2.2\. Perceived Experience: Survey Scores collected at the End of Each Task,
    and Exit Interviews'
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2. 感知体验：每个任务结束时收集的问卷评分和退出访谈
- en: To analyze participants’ perceived experience using our system, we collected
    their survey scores upon the completion of each task and conducted exit interviews
    before the end of each study.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析参与者使用我们系统时的感知体验，我们在每个任务完成后收集了他们的问卷评分，并在每个研究结束前进行了退出访谈。
- en: 'Survey Scores The co-creation experience scores, however, were given by participants
    at the end of each task through a survey. The survey contains multiple 5-point
    Likert scale questions designed to measure their experience from the aspects of:
    control, creativity, meta-creativity, cognitive load, and trust. We designed 2
    Likert-scale questions for each of the 5 aspects to avoid potential bias and ensure
    a more comprehensive evaluation⁶⁶6The collected survey ratings have an average
    Cronbach’s Alpha value of $\alpha=.85$, suggesting good reliability.. The complete
    list of survey questions can be found in Appendix [A.1](https://arxiv.org/html/2310.06155v3#A1.SS1
    "A.1\. Post-Session Survey Questions ‣ Appendix A Appendices ‣ CoQuest: Exploring
    Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 问卷评分 然而，共同创作体验评分是由参与者在每个任务结束时通过问卷给出的。问卷包含多个 5 分 Likert 量表问题，旨在从以下几个方面衡量他们的体验：控制感、创造力、元创造力、认知负荷和信任。我们为每个方面设计了
    2 个 Likert 量表问题，以避免潜在偏差并确保更全面的评估⁶⁶6收集到的问卷评分的 Cronbach’s Alpha 平均值为 $\alpha=.85$，表明具有良好的可靠性。完整的问卷问题列表可以在附录
    [A.1](https://arxiv.org/html/2310.06155v3#A1.SS1 "A.1\. 后续调查问题 ‣ 附录 A 附录 ‣ CoQuest：探索基于
    LLM 的代理与研究问题共同创作") 中找到。
- en: 'Exit Interview After the participant completed the post-task rating survey,
    we also conducted a ten-minute semi-structured interview to obtain a deeper understanding
    of the participant’s experience with the system. Interview data was analyzed using
    open-ended coding, by having two researchers review the interview transcripts
    and frequently discuss with each other (Khandkar, [2009](https://arxiv.org/html/2310.06155v3#bib.bib33)).
    The interview coding highlighted differences in perception between the two conditions
    explicated by participants. To measure participants’ familiarity with the task
    topic, we also asked participants how familiar they were with the two topics with
    three choices: not familiar, kind of familiar, and very familiar.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 退出访谈 在参与者完成任务后评分调查后，我们还进行了一个十分钟的半结构化访谈，以更深入了解参与者与系统的体验。访谈数据通过开放式编码进行分析，两位研究人员审阅了访谈转录，并频繁进行讨论（Khandkar，[2009](https://arxiv.org/html/2310.06155v3#bib.bib33)）。访谈编码突出了参与者在两种条件下的感知差异。为了衡量参与者对任务主题的熟悉度，我们还询问了参与者对这两个主题的熟悉程度，提供了三个选项：不熟悉、有点熟悉和非常熟悉。
- en: '6.2.3\. Behavior: Think-Aloud Data and System Log.'
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3\. 行为：思维大声说出数据与系统日志。
- en: We annotated users’ behavior (think-aloud transcripts and system usage) to understand
    how users utilized our system.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们标注了用户的行为（思维大声说出转录和系统使用情况），以了解用户如何使用我们的系统。
- en: Think-Aloud During Co-Creation Think-aloud data was primarily used for understanding
    how users generated and interpreted RQs. One researcher first generated a codebook
    through open coding using videos and transcripts from three randomly selected
    participants, and then three other researchers independently coded the data of
    the same three participants, reaching an inter-rater agreement of 0.83 in Krippendorf’s
    alpha. The annotators then discussed and refined the codebook again until they
    reached full agreement. Then, four researchers proceeded to annotate the remaining
    17 participants’ behavior data separately. In the final codebook, whether users
    interacted with the system was annotated and used for quantitative analysis in
    RQ3 as “Acted During Wait”. The final codebook also included sense-making behavior
    (e.g., reasons for (not) waiting, reason for providing certain feedback) as qualitative
    results.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 思维大声说出（Co-Creation中的思维大声说出） 思维大声说出数据主要用于理解用户如何生成和解释RQ。一位研究人员首先通过开放编码，使用来自三位随机选择参与者的视频和转录资料生成了一个编码本，随后三位其他研究人员独立对同三位参与者的数据进行编码，最终在Krippendorf的α值中达到了0.83的评分一致性。标注员们随后进行了讨论并再次完善编码本，直到达成完全一致。接着，四位研究人员分别对剩余17名参与者的行为数据进行标注。在最终的编码本中，是否用户与系统进行了交互被标注并用于RQ3的定量分析，标注为“在等待期间有行为”。最终的编码本还包括意义构建行为（例如，等待的原因、是否等待的原因、提供某些反馈的原因）作为定性结果。
- en: System Log During Co-Creation We gathered multiple types of system logs for
    subsequent analysis of user behavior. We collected and used the counts of generated
    RQs and the lengths of user-typed feedback to AI for quantitative analysis of
    RQ1 and RQ3\. User interactions such as clicks on components like RQ nodes and
    AI Thoughts were used for qualitative analysis along with the think-aloud data.
    The text content of user-typed feedback was also used for qualitative analysis
    in RQ2.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 系统日志 在共同创作过程中，我们收集了多种类型的系统日志，以便后续分析用户行为。我们收集并使用了生成的RQ的计数和用户输入给AI的反馈长度，以进行RQ1和RQ3的定量分析。用户与组件（如RQ节点和AI思想）进行交互的行为（例如点击）被用作与思维大声说出数据一起进行定性分析。用户输入的反馈文本内容也被用作RQ2中的定性分析。
- en: We used different notations throughout this paper to distinguish among the different
    types of quotes presented in the results. For AI-generated RQs, we use italic
    (e.g., AI-generated RQ); for feedback to the AI, we use double-quotes (e.g., “feedback”);
    for interview and think-aloud quotes, we use double-quoted italics (e.g., “interview
    quotes”).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们使用了不同的符号来区分结果中呈现的不同类型的引述。对于AI生成的RQ，我们使用斜体（例如，AI生成的RQ）；对于反馈给AI的内容，我们使用双引号（例如，“反馈”）；对于访谈和思维大声说出的引述，我们使用双引号和斜体（例如，“访谈引述”）。
- en: Figure 6. Participants rated their perceptions of the system’s two designs using
    a 5-point Likert scale survey. The survey ratings indicated that participants
    experienced a significantly higher sense of creativity and trust when engaging
    with the system under the breadth-first condition.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图6. 参与者通过5点李克特量表对系统的两种设计进行评分。调查评分显示，参与者在宽度优先条件下使用系统时，感受到的创造力和信任感显著更高。
- en: '![Refer to caption](img/8b3a1b15c3df2bfdabd0a78e106b5648.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/8b3a1b15c3df2bfdabd0a78e106b5648.png)'
- en: 'There are five violinplots (similar to boxplots) that presents users’ 5-point
    Likert scale survey ratings toward five dimensions: control, creativity, meta
    creativity, cognitive load, trust. Each violinplot has breadth-first and depth-first
    side by side. For control, the two shapes are very similar with the same median
    and upper limit. The lower limit is higher for breadth-first than depth-first.
    For creativity, breadth-first has a higher median and higher upper limit than
    depth-first, and the lower limit is the same. For meta creativity, the upper limit
    and lower limit are the same, but breadth-first has a higher median. For cognitive
    load, the shapes are very similar with the same median, upper-limit, and lower-limit.
    For trust, breadth-first has a higher median, higher upper-limit, and higher lower-limit
    than depth-first.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有五个小提琴图（类似箱线图），展示了用户在五个维度上的5点Likert量表调查评分：控制、创造力、元创造力、认知负担、信任。每个小提琴图都有广度优先和深度优先两个并排显示。在控制方面，两种形状非常相似，具有相同的中位数和上限。广度优先的下限高于深度优先。在创造力方面，广度优先的中位数和上限高于深度优先，下限相同。在元创造力方面，上限和下限相同，但广度优先的中位数较高。在认知负担方面，两种形状非常相似，具有相同的中位数、上限和下限。在信任方面，广度优先的中位数、上限和下限均高于深度优先。
- en: Figure 6. Participants rated their perceptions of the system’s two designs using
    a 5-point Likert scale survey. The survey ratings indicated that participants
    experienced a significantly higher sense of creativity and trust when engaging
    with the system under the breadth-first condition.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图6. 参与者使用5点Likert量表调查评估了他们对系统两种设计的感知。调查结果表明，当在广度优先条件下与系统互动时，参与者体验到显著更高的创造力和信任感。
- en: 7\. Findings
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 研究结果
- en: 7.1\. Perception of Co-Creation Experience and Outcome (RQ1)
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 共同创作体验与结果的感知（RQ1）
- en: The breadth-first condition allows users to generate multiple RQs in parallel
    with one interaction, whereas the depth-first condition creates three RQs sequentially,
    one after another. In this section, we analyzed how these two different conditions
    impact participants’ perception towards both co-creation experience and outcomes.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 广度优先条件允许用户在一次互动中并行生成多个研究问题，而深度优先条件则顺序生成三个研究问题，一次生成一个。在本节中，我们分析了这两种不同条件如何影响参与者对共同创作体验和结果的感知。
- en: '7.1.1\. Experience: User Perceived Stronger Creativity and Trust Using Breadth-first
    Condition'
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1\. 体验：用户在广度优先条件下感知到更强的创造力和信任
- en: 'In total, 20 participants created 504 RQs throughout the study, with 276 RQs
    (M=14.53, SD=6.19) co-created with CoQuest system under the breadth-first condition
    and 228 RQs (M=12, SD=5.31) under the depth-first condition. To evaluate the overall
    experience of the co-creation process, we asked our participants to complete surveys
    upon finishing each task. A Mann-Whitney U test⁷⁷7Power analysis conducted using
    G*Power(Faul et al., [2007](https://arxiv.org/html/2310.06155v3#bib.bib17)). of
    the survey results suggested that users perceived significantly stronger creativity
    ($U=288.0$, $p=.015^{*},d=.68,Power=.83$) using the system under the breadth-first
    condition (M=3.78, SD=0.82) than the depth-first condition (M=3.18, SD=0.69).
    Similarly, the user-perceived trust under the breadth-first condition (M=4.15,
    SD=0.76) was found significantly higher ($U=292.0,p=.011^{*},d=.67,Power=.81$)
    than the depth-first condition (M=3.5, SD=0.86). The results of all 5 rating categories
    are shown in Figure [6](https://arxiv.org/html/2310.06155v3#S6.F6 "Figure 6 ‣
    6.2.3\. Behavior: Think-Aloud Data and System Log. ‣ 6.2\. Data Collection and
    Analysis ‣ 6\. User Study Evaluating Co-Creation with CoQuest ‣ CoQuest: Exploring
    Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 总共有20名参与者在整个研究过程中创建了504个研究问题（RQ），其中276个研究问题（M=14.53，SD=6.19）是在广度优先条件下与CoQuest系统共同创建的，228个研究问题（M=12，SD=5.31）是在深度优先条件下创建的。为了评估共同创作过程的整体体验，我们要求参与者在完成每个任务后填写调查问卷。使用G*Power（Faul等，[2007](https://arxiv.org/html/2310.06155v3#bib.bib17)）进行的Mann-Whitney
    U检验⁷⁷7Power分析表明，用户在广度优先条件下使用系统时，感知到的创造力显著更强（$U=288.0$，$p=.015^{*},d=.68,Power=.83$）（M=3.78，SD=0.82），相比于深度优先条件（M=3.18，SD=0.69）。同样，用户在广度优先条件下感知到的信任（M=4.15，SD=0.76）显著高于深度优先条件（M=3.5，SD=0.86）（$U=292.0,p=.011^{*},d=.67,Power=.81$）。所有5个评分类别的结果见图[6](https://arxiv.org/html/2310.06155v3#S6.F6
    "图6 ‣ 6.2.3\. 行为：思维过程数据与系统日志。 ‣ 6.2\. 数据收集与分析 ‣ 6\. 用户研究评估与CoQuest的共同创作 ‣ CoQuest：基于LLM的研究问题共同创作探索")。
- en: 'During the interview, 12 out of 20 participants (60%) also mentioned that they
    preferred the breadth-first condition. An example RQ flow generated by the participant
    (P4) during one of the sessions under the breadth-first condition is shown in
    Figure [7](https://arxiv.org/html/2310.06155v3#S7.F7 "Figure 7 ‣ 7.1.1\. Experience:
    User Perceived Stronger Creativity and Trust Using Breadth-first Condition ‣ 7.1\.
    Perception of Co-Creation Experience and Outcome (RQ1) ‣ 7\. Findings ‣ CoQuest:
    Exploring Research Question Co-Creation with an LLM-based Agent"). The interview
    and think-aloud transcripts explained why the breadth-first condition was perceived
    to create a better experience.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在访谈中，20名参与者中的12名（60%）还提到他们更喜欢广度优先条件。在广度优先条件下，参与者（P4）在某次会议中生成的一个示例RQ流程如图[7](https://arxiv.org/html/2310.06155v3#S7.F7
    "图7 ‣ 7.1.1\. 经验：用户认为使用广度优先条件能激发更强的创造力和信任 ‣ 7.1\. 共创体验与结果的感知（RQ1） ‣ 7\. 研究发现 ‣
    CoQuest：探索与基于LLM的代理共同创建研究问题")所示。访谈和思维 aloud 的记录解释了为什么广度优先条件被认为能创造更好的体验。
- en: Figure 7. Part of P4’s RQ flow using the breadth-first condition when exploring
    the topic of “AI and crowdsourcing.” Note that the participant generated from
    two different RQ nodes in the same iteration, and only one set of generated RQs
    was presented. The participant provided feedback using keywords such as “AI and
    crowdsourcing” and “educational setting” to help the AI generate more RQs. The
    third iteration was not included in this figure.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图7. P4在探索“人工智能与众包”主题时使用广度优先条件的部分RQ流程。请注意，参与者在同一次迭代中从两个不同的RQ节点生成了内容，并且只展示了一组生成的RQ。参与者通过使用“人工智能与众包”和“教育环境”等关键词提供反馈，以帮助AI生成更多的RQ。第三次迭代未包括在此图中。
- en: '![Refer to caption](img/9ef1221d1ced3321884e0c678364d789.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/9ef1221d1ced3321884e0c678364d789.png)'
- en: 'The RQ flow of P4 using breadth-first condition. From the left, there is an
    initial node with user feedback ”crowdsourcing and AI.” It leads to three RQ nodes
    with the same text on each edge ”BreadthL search_and_summarize_papers.” The generated
    RQs are: How can AI be used to improve the efficiency and quality of crowdsourcing;
    What are the ethical implications of using AI in crowdsourcing; How can crowdsourcing
    be used to improve the accuracy and effectiveness of AI algorithms. The first
    RQ is connected with three edges, but the three RQ nodes from it are not included
    in this diagram. The third RQ is expanded with user feedback ”in an education
    setting.” This node further leads to three RQ nodes on the right with the same
    text on edge ”Breadth: narrow_down_rqs.” The three RQ nodes are: What are the
    potential ethical concerns associated with using AI in grading and assessment
    in educational settings; What are the ethical implications of using AI in crowdsourcing
    for educational research; How can AI be used in educational settings to enhance
    student learning while minimizing ethical concerns. The third RQ had three more
    edges connected to it, but generated RQ nodes were not included in this diagram.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 'P4使用广度优先条件的RQ流程。从左侧开始，存在一个初始节点，用户反馈为“众包与人工智能”。它引导到三个RQ节点，每个边上都有相同的文本“BreadthL
    search_and_summarize_papers”。生成的RQ包括：人工智能如何用于提高众包的效率和质量；使用人工智能进行众包时的伦理影响；如何利用众包提高人工智能算法的准确性和有效性。第一个RQ与三个边连接，但来自它的三个RQ节点未包含在此图中。第三个RQ通过用户反馈“在教育环境中”进行扩展。该节点进一步引导到右侧的三个RQ节点，边上有相同的文本“Breadth:
    narrow_down_rqs”。这三个RQ节点包括：使用人工智能进行评分和评估时，在教育环境中可能涉及的伦理问题；在教育研究中使用人工智能进行众包的伦理影响；如何在教育环境中使用人工智能提高学生学习效果，同时最小化伦理问题。第三个RQ有三个更多的边连接，但生成的RQ节点未包含在此图中。'
- en: Figure 7. Part of P4’s RQ flow using the breadth-first condition when exploring
    the topic of “AI and crowdsourcing.” Note that the participant generated from
    two different RQ nodes in the same iteration, and only one set of generated RQs
    was presented. The participant provided feedback using keywords such as “AI and
    crowdsourcing” and “educational setting” to help the AI generate more RQs. The
    third iteration was not included in this figure.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图7. P4在探索“人工智能与众包”主题时使用广度优先条件的部分RQ流程。请注意，参与者在同一次迭代中从两个不同的RQ节点生成了内容，并且只展示了一组生成的RQ。参与者通过使用“人工智能与众包”和“教育环境”等关键词提供反馈，以帮助AI生成更多的RQ。第三次迭代未包括在此图中。
- en: First, the breadth-first condition results are easier to interpret and require
    less wait time to obtain the same amount of RQs compared with the depth-first
    condition. Participants appreciated that the AI was able to list the three generated
    RQs in parallel “all at once” (P10), which allowed them to easily “compare among
    the RQs” (P10) and “explore multiple potential research questions” (P4). It is
    also easier to understand the reason behind the generated RQs in breadth-first
    condition, as all three RQs shared the same predecessor RQ and rationale. Although
    the depth-first condition also generated three RQs using one click, participants
    had to wait longer to see all three generated RQs than when using the breadth-first
    condition. Therefore, some participants tended to either focus on the first RQ
    and ignore the other two, or they would start with the last RQ and move to an
    earlier generated RQ if the latter one was not deemed ideal.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，与深度优先条件相比，广度优先条件的结果更容易解释，且获取相同数量的研究问题（RQ）所需的等待时间更短。参与者表示，他们很欣赏AI能够并行地“一次性列出三个生成的RQ”（P10），这使他们能够轻松地“在RQ之间进行比较”（P10）并“探索多个潜在的研究问题”（P4）。在广度优先条件下，理解生成的RQ背后的原因也更容易，因为所有三个RQ共享相同的前置RQ和逻辑。尽管深度优先条件也能通过一次点击生成三个RQ，但参与者需要等待更长时间才能看到所有三个生成的RQ，而在广度优先条件下则不需要。因此，一些参与者倾向于集中关注第一个RQ，忽略另外两个RQ，或者如果最后一个RQ不理想，他们会从最后一个RQ开始，再回到前一个生成的RQ。
- en: Second, participants found that the breadth-first condition gave them more control
    over which direction of RQs they would like to proceed with. With the three options
    listed in parallel, participants were able to choose the RQ that they preferred
    the most and generate more follow-up RQs based on it. The tree-structured design
    also allowed participants to highlight RQs that were more relevant, and then choose
    the branch they were more interested in. P14 found the breadth-first condition
    to be “less cognitively demanding,” and P16 preferred to use the breadth-first
    condition for “brainstorming under one topic.” The depth-first condition, on the
    other hand, may generate RQs in the second and third iterations that were hard
    to understand how they were related to the first iteration. For example, P6 started
    an RQ flow with feedback “crowdsourcing and AI” with the depth-first condition.
    While the first question and their feedback did not mention the term medical diagnosis,
    this word appeared after the second iteration but disappeared again after the
    third iteration. During the interview, they mentioned that the depth-first condition
    “sometimes goes back and forth” and it was “confusing” to understand “the logic
    of why these 3 are parent, child, and grandchild [nodes].”
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，参与者发现广度优先条件让他们在选择研究问题的方向上拥有更多控制权。由于三个选项并行列出，参与者能够选择自己最偏好的RQ，并基于它生成更多的后续RQ。树状结构设计还允许参与者突出显示与自己更相关的RQ，然后选择他们更感兴趣的分支。P14认为广度优先条件“认知负担较小”，而P16更喜欢在“一个主题下进行头脑风暴”时使用广度优先条件。另一方面，深度优先条件可能在第二次和第三次迭代中生成的RQ很难理解它们与第一次迭代之间的关系。例如，P6使用深度优先条件开始了一个关于“众包与AI”的RQ流程。虽然第一个问题和他们的反馈没有提到“医学诊断”这个词，但在第二次迭代后这个词出现了，但在第三次迭代后又消失了。在访谈中，他们提到深度优先条件“有时会来回反复”，而且很难理解“这三个节点为什么是父节点、子节点和孙子节点[关系]”。
- en: Figure 8. Part of P2’s RQ flow using the depth-first condition when exploring
    the topic of “AI and crowdsourcing.” The dashed lines represent the second and
    third iterations of RQ generation, which were not based on user feedback. From
    the first three iterations, the participant chose to continue with the RQ generated
    in the first iteration, and then provided feedback, asking the AI to be more specific.
    Subsequently, the AI generated three more RQs, and the participant once again
    chose to proceed with the first of those three (subsequent RQs are not included
    in this figure).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图8. P2使用深度优先条件在探索“AI与众包”主题时的部分RQ流程。虚线表示第二次和第三次迭代生成的RQ，这些RQ并非基于用户反馈。从前三次迭代来看，参与者选择继续使用第一次迭代生成的RQ，然后提供反馈，要求AI更加具体。随后，AI生成了三个新的RQ，参与者再次选择继续使用这三者中的第一个（后续的RQ未包含在此图中）。
- en: '![Refer to caption](img/689ebce032a10cfb487ed6528f79aad6.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/689ebce032a10cfb487ed6528f79aad6.png)'
- en: 'The RQ flow of P2 using depth-first condition. From the left, there is an initial
    node with user feedback ”Crowd and AI collaboration for finding relevant literature
    for research questions.” It leads to one RQ node with text ”depth: search_and_summarize_papers”
    on the solid line edge. The RQ is: How can we design AI systems that effectively
    collaborate with human experts to find relevant literature for research questions.
    This RQ node is expanded with user feedback ”Can you be more specific about AI
    systems? this is just repeating my initial thought.” This RQ node is connected
    to 2 nodes. The upper node is connected using a dashed edge and text ”depth: hypothesize_use_cases.”
    The generated RQ is: What are the most effective strategies for incentivizing
    participation and engagement in a crowd-based system for finding relevant literature
    for research questions. From this node, there is another dashed edge connecting
    to another generated node with text ”depth: search_and_summarize_papers” on the
    edge. The generated RQ is: How can we design a crowd and AI collaboration system
    for finding relevant literature for research questions that is transparent, accountable,
    and inclusive of diverse perspectives and expertise. The lower RQ node connected
    to the first, expanded RQ node is connected with a solid line edge with text ”depth:
    hypothesize_use_cases.” The generated RQ is: How can AI systems be designed to
    effectively integrate feedback from human experts to improve the quality and relevance
    of the literature that is retrieved. This node is further connected with two edges.
    The lower edge with a solid line is connected to the outside of the diagram. The
    upper edge with dashed line has text ”depth: compare_rq_with_papers” and connects
    to the RQ: How can we design AI systems that can effectively handle the diverse
    and complex needs of different research domains and communities. This node is
    further connected to another RQ node with a dashed line and text ”depth: hypothesize_use_cases”
    on the edge. The generated RQ is: What are the best ways to evaluate the accuracy
    and relevance of AI systems that collaborate with human experts to find relevant
    literature for research questions.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 'P2的RQ流程使用了深度优先条件。从左侧开始，有一个初始节点，用户反馈为“群体与AI协作用于寻找与研究问题相关的文献。”它引出了一个带有文本“depth:
    search_and_summarize_papers”的RQ节点，连接线为实线。该RQ是：我们如何设计能够与人类专家有效协作、寻找与研究问题相关文献的AI系统？这个RQ节点被扩展，用户反馈为“你能具体说明一下AI系统吗？这只是重复了我的初步想法。”这个RQ节点连接到两个节点。上面的节点通过虚线连接，文本为“depth:
    hypothesize_use_cases”。生成的RQ是：在基于群体的系统中，如何激励参与者和增强他们的参与度，以寻找与研究问题相关的文献？从这个节点，另一条虚线连接到另一个生成节点，边缘的文本为“depth:
    search_and_summarize_papers”。生成的RQ是：我们如何设计一个群体与AI协作的系统，用于寻找与研究问题相关的文献，并确保该系统具有透明性、问责制，并包容多元视角与专业知识？下方连接到第一个扩展RQ节点的RQ节点通过实线边缘连接，文本为“depth:
    hypothesize_use_cases”。生成的RQ是：我们如何设计AI系统，使其能够有效地整合人类专家的反馈，以提高检索文献的质量和相关性？这个节点进一步通过两条边缘连接。下方的实线边缘连接到图表外部。上方的虚线边缘文本为“depth:
    compare_rq_with_papers”，连接到RQ：我们如何设计AI系统，使其能够有效处理不同研究领域和社区的多样化和复杂需求？这个节点进一步通过一条虚线连接到另一个RQ节点，边缘的文本为“depth:
    hypothesize_use_cases”。生成的RQ是：评估与人类专家协作以寻找与研究问题相关的文献的AI系统的准确性和相关性，最好的方法是什么？'
- en: Figure 8. Part of P2’s RQ flow using the depth-first condition when exploring
    the topic of “AI and crowdsourcing.” The dashed lines represent the second and
    third iterations of RQ generation, which were not based on user feedback. From
    the first three iterations, the participant chose to continue with the RQ generated
    in the first iteration, and then provided feedback, asking the AI to be more specific.
    Subsequently, the AI generated three more RQs, and the participant once again
    chose to proceed with the first of those three (subsequent RQs are not included
    in this figure).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图8. P2使用深度优先条件探索“AI与众包”主题时的RQ流程部分。虚线表示第二和第三轮RQ生成，它们不是基于用户反馈。在前面三轮中，参与者选择继续使用第一轮生成的RQ，然后提供反馈，要求AI更加具体。随后，AI生成了三个更多的RQ，参与者再次选择继续使用这三者中的第一个（后续的RQ未包含在此图中）。
- en: '7.1.2\. Outcome: Depth-first Condition Yields RQs with Higher-rated Creativity'
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2\. 结果：深度优先条件产生的RQ具有更高的创造性评分
- en: 'We measure the outcomes from the co-creation process by asking participants
    to rate the RQs on the fly during the tasks. To account for the problem of multiple
    comparisons, we conducted a MANOVA and found a significant difference ($F(4,209)=3.79,p=.0057^{**};Wilk^{\prime}s\
    \Lambda=0.909$) in the user-provided ratings for RQs between the two conditions
    (i.e., breadth-first and depth-first). We conducted Mann-Whitney U tests with
    these ratings toward generated RQs and found that both the novelty ($U=2199.5,p=.002^{**},d=.40,Power=.89$)
    and surprise ($U=2387.5,p=0.017^{*},d=.32,Power=.75$) of the RQs were rated higher
    when using the depth-first condition (M=3.78, SD=1.29) compared to the breadth-first
    condition (M=3.28, SD=1.22). In contrast to the post-task survey results that
    suggested that the breadth-first condition was perceived to be more creative,
    the RQ ratings suggested that the generated RQs using the depth-first condition
    were more innovative instead. Figure [8](https://arxiv.org/html/2310.06155v3#S7.F8
    "Figure 8 ‣ 7.1.1\. Experience: User Perceived Stronger Creativity and Trust Using
    Breadth-first Condition ‣ 7.1\. Perception of Co-Creation Experience and Outcome
    (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent") shows an example of participants using the depth-first condition.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '我们通过让参与者在任务过程中实时评估研究问题（RQs）来衡量共同创作过程的结果。为了考虑多重比较的问题，我们进行了MANOVA分析，发现两种条件（即广度优先和深度优先）下用户提供的RQs评分存在显著差异（$F(4,209)=3.79,p=.0057^{**};Wilk^{\prime}s\
    \Lambda=0.909$）。我们对这些评分进行了Mann-Whitney U检验，结果显示，当使用深度优先条件时，生成的RQs在新颖性（$U=2199.5,p=.002^{**},d=.40,Power=.89$）和惊讶感（$U=2387.5,p=0.017^{*},d=.32,Power=.75$）上的评分较高（深度优先条件M=3.78，SD=1.29），相比之下，广度优先条件（M=3.28，SD=1.22）的评分较低。与任务后调查结果（表明广度优先条件被认为更具创造力）相反，RQ评分表明，使用深度优先条件生成的RQs反而更具创新性。[图8](https://arxiv.org/html/2310.06155v3#S7.F8
    "Figure 8 ‣ 7.1.1\. Experience: User Perceived Stronger Creativity and Trust Using
    Breadth-first Condition ‣ 7.1\. Perception of Co-Creation Experience and Outcome
    (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent")展示了使用深度优先条件的参与者示例。'
- en: During tasks and interviews, participants explained why they found the outcomes
    from the depth-first condition to be more innovative. First, participants found
    that the depth-first condition tended to generate surprising RQs with ideas that
    were not present previously or included in their feedback to AI. Since the second
    and third RQs were generated based on the first RQ without user feedback, the
    AI sometimes may add unexpected keywords to the RQs. While a few participants
    found these unexpected additions to be “surprising in a negative manner” (P3)
    or “distracting” (P12), more participants described it in a positive way such
    as “insightful” (P18) or “impressive” (P8) and found it interesting to see the
    AI “thinking when generating the questions (P11).” This would be particularly
    useful if the participant was less familiar with a certain topic, as it would
    be more inspiring.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务和访谈过程中，参与者解释了为什么他们认为深度优先条件的结果更具创新性。首先，参与者发现深度优先条件倾向于生成带有以前没有出现过的或者未被他们反馈给AI的想法的令人惊讶的RQ。由于第二个和第三个RQ是基于第一个RQ生成的，且没有用户反馈，AI有时会向RQ中添加意料之外的关键词。虽然有少数参与者认为这些意外的添加是“负面的惊讶”（P3）或“分心的”（P12），但更多参与者以积极的方式描述这一点，如“有洞察力的”（P18）或“令人印象深刻的”（P8），并且觉得看到AI在生成问题时“思考”很有趣（P11）。如果参与者对某一主题不太熟悉，这种情况尤其有帮助，因为它能够激发更多的灵感。
- en: Second, the depth-first condition allows participants to dive deep into one
    chosen RQ and improve its quality. While it requires “more patience” (P14) to
    wait for and read through all three generated RQs from one interaction using depth-first
    condition, participants found it easier to go “deeper” and form an RQ that is
    “more specific” (P4). The depth-first RQs were also found to be more “creative
    and unique” (P13). P17 also expressed a positive opinion about having the freedom
    to choose and generate follow-up RQs from any AI-generated RQs they would like
    to work on. In fact, participants could also utilize the AI generation wait time
    to better interpret existing RQs and generate more valuable RQs.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，深度优先条件使参与者能够深入探讨一个选定的RQ并提高其质量。虽然它需要“更多的耐心”（P14）来等待并阅读一次交互中生成的所有三个RQ，参与者发现更容易“深入”并形成一个“更具体的”（P4）RQ。深度优先生成的RQ也被认为更具“创造性和独特性”（P13）。P17也对能够自由选择并从任何自己愿意处理的AI生成的RQ中生成后续RQ表示赞同。事实上，参与者还可以利用AI生成的等待时间更好地解释现有的RQ，并生成更有价值的RQ。
- en: Figure 9. Part of P4’s RQ flow involved using the depth-first condition when
    exploring the topic of “AR/VR for education and learning.” The dashed lines represent
    the second and third iterations of RQ generation, which were not based on the
    user’s feedback. The participant provided feedback to the RQs generated at depth=1
    and depth=2\. Based on the RQ at depth=2, three more RQs were generated. P4’s
    perceived novelty, surprise, value, and relevance initially scored at (3,4,3,5)
    during the first iteration (at depth=1), and these scores increased to (4,5,4,5)
    as the depth increased.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9. P4 的 RQ 流程的一部分涉及在探索“教育和学习中的 AR/VR”话题时使用深度优先条件。虚线表示 RQ 生成的第二次和第三次迭代，这些迭代并非基于用户反馈。在深度=1
    和深度=2 时，参与者对生成的 RQ 提供了反馈。基于深度=2 的 RQ，生成了更多的三个 RQ。P4 的感知新颖性、惊讶感、价值和相关性在第一次迭代（深度=1）时得分为（3,4,3,5），随着深度的增加，这些分数提高至（4,5,4,5）。
- en: '![Refer to caption](img/a8c80448a2cf2d295bbe3a88ce3ed0ff.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题说明](img/a8c80448a2cf2d295bbe3a88ce3ed0ff.png)'
- en: 'The RQ flow of P4 using depth-first condition. From the left, there is an initial
    node with user feedback ”VR/AR for education and learning.” It leads to one RQ
    node with text ”depth: search_and_summarize_papers” on the solid line edge. The
    RQ is: What are the most effective VR/AR learning environments for different subjects
    and age groups? This RQ node is denoted as depth=1\. It is expanded with user
    feedback ”teaching computer science.” This RQ node is connected to 2 nodes. The
    upper node, denoted as depth=2, is connected to using a dashed edge, and further
    connected to another node, denoted as depth=3, using a dashed edge. Both edges
    did not have text and the RQs in these nodes were omitted. The lower node was
    connected with a solid line edge with text ”Depth: narrow_down_rqs.” The generated
    RQ is: What are the best VR/AR learning environments for teaching computer networking
    concepts to college students? This node is denoted as depth=2\. This RQ node is
    connected to 2 nodes. The upper node, denoted as depth=3, is connected to using
    a dashed edge, and further connected to another node, denoted as depth=4, using
    a dashed edge. Again, both edges did not have text and the RQs in these nodes
    were omitted. The lower node was connected with a solid line edge with text ”Depth:
    hypothesize_use_cases.” The generated RQ is: How does the use of VR/AR learning
    environments affect student engagement and motivation in computer networking courses
    compared to traditional classroom environments? This node is denoted as depth=3\.
    From this node, there is a dashed edge connecting to a generated node with text
    ”Depth: narrow_down_rqs” on the edge. The generated RQ is: What are the potential
    advantages and disadvantages of using VR/AR learning environments for teaching
    computer networking concepts to college students compared to traditional classroom
    environments in terms of cost, accessibility, and effectiveness, and how do these
    factors impact the overall effectiveness of VR/AR learning environments? This
    node is denoted as depth=4\. This node is further connected to another node using
    dashed lines with text ”Depth: narrow_down_rqs” on the edge. The generated RQ
    is: How does the use of VR/AR learning environments affect student engagement
    and motivation compared to traditional classroom environments for teaching computer
    networking concepts to college students, and what factors influence this impact?
    This node is denoted as depth=5.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 'P4 的RQ流程使用深度优先条件。从左侧开始，有一个初始节点，用户反馈为“教育和学习中的VR/AR”。它通过实线边连接到一个RQ节点，文本为“depth:
    search_and_summarize_papers”。该RQ是：针对不同学科和年龄组，最有效的VR/AR学习环境是什么？此RQ节点表示为depth=1\。它通过用户反馈“教授计算机科学”进行扩展。此RQ节点连接到2个节点。上方节点，表示为depth=2，通过虚线边连接，并进一步通过虚线边连接到另一个节点，表示为depth=3。两个边都没有文本，且这些节点中的RQ被省略。下方节点通过实线边连接，文本为“Depth:
    narrow_down_rqs”。生成的RQ是：针对大学生教授计算机网络概念，最佳的VR/AR学习环境是什么？此节点表示为depth=2\。此RQ节点连接到2个节点。上方节点，表示为depth=3，通过虚线边连接，并进一步通过虚线边连接到另一个节点，表示为depth=4。同样，这两个边都没有文本，且这些节点中的RQ被省略。下方节点通过实线边连接，文本为“Depth:
    hypothesize_use_cases”。生成的RQ是：使用VR/AR学习环境相比传统课堂环境，如何影响学生在计算机网络课程中的参与度和动力？此节点表示为depth=3\。从该节点出发，通过虚线边连接到生成的节点，边上文本为“Depth:
    narrow_down_rqs”。生成的RQ是：使用VR/AR学习环境相比传统课堂环境，在成本、可及性和有效性方面，教授计算机网络概念给大学生有哪些潜在的优缺点？这些因素如何影响VR/AR学习环境的总体有效性？此节点表示为depth=4\。该节点通过虚线边进一步连接到另一个节点，边上文本为“Depth:
    narrow_down_rqs”。生成的RQ是：使用VR/AR学习环境相比传统课堂环境，如何影响大学生学习计算机网络概念时的参与度和动力？哪些因素会影响这一影响？此节点表示为depth=5。'
- en: Figure 9. Part of P4’s RQ flow involved using the depth-first condition when
    exploring the topic of “AR/VR for education and learning.” The dashed lines represent
    the second and third iterations of RQ generation, which were not based on the
    user’s feedback. The participant provided feedback to the RQs generated at depth=1
    and depth=2\. Based on the RQ at depth=2, three more RQs were generated. P4’s
    perceived novelty, surprise, value, and relevance initially scored at (3,4,3,5)
    during the first iteration (at depth=1), and these scores increased to (4,5,4,5)
    as the depth increased.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图9. P4的部分RQ流程涉及在探讨“AR/VR用于教育和学习”主题时使用了深度优先条件。虚线表示第二次和第三次的RQ生成迭代，这些迭代并没有基于用户的反馈。参与者对深度为1和深度为2的RQ生成结果提供了反馈。基于深度为2的RQ，生成了三个新的RQ。P4在第一次迭代（深度为1时）对新颖性、惊讶度、价值和相关性的评分分别为（3,4,3,5），随着深度增加，这些评分提升到了（4,5,4,5）。
- en: 'To further understand how users’ perception towards RQs varied throughout the
    co-creation process, we performed a temporal analysis over the depth of RQ flows.
    By computing Spearman’s correlation coefficient, we found significant positive
    correlations between the depth of RQs and their corresponding ratings of novelty
    ($r(514)=.41$, $p<.001^{***}$), value ($r(514)=.22$, $p=.011^{*}$) and surprise
    ($r(514)=.24$, $p=.006^{**}$). We also found that RQs with depths of 9 or higher
    seemed to exhibit a drop in ratings. This might be due to the repetitiveness of
    RQs that was caused by the narrowing-down of topic and thus fixed literature space.
    To further illustrate this narrowing-down process of RQs, a sample flow of RQs
    generated under depth-first condition by one of the participants, P4, is shown
    in Figure [9](https://arxiv.org/html/2310.06155v3#S7.F9 "Figure 9 ‣ 7.1.2\. Outcome:
    Depth-first Condition Yields RQs with Higher-rated Creativity ‣ 7.1\. Perception
    of Co-Creation Experience and Outcome (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring
    Research Question Co-Creation with an LLM-based Agent"). The participant initially
    expressed confusion towards the first RQ generated as it was perceived as “kind
    of vague” and “more like a literature review question instead of research question.”
    After instructing the system to provide more details, P4 read and commented on
    the follow-up RQ generated as “an OK research question… But I wish it could be
    more specific on what (factor) makes VR/AR good for learning environment…” Then,
    they generated three more follow-up RQs and perceived them to be more specific
    and surprising “I’m a bit surprised that it was able to pick up the concept of
    accessibility.” However, they noted that making sense of the connections between
    later RQs was more challenging.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '为了进一步理解用户在共创过程中对研究问题（RQ）的认知变化，我们对RQ流程的深度进行了时间分析。通过计算斯皮尔曼相关系数，我们发现RQ的深度与其对应的新颖性评分（$r(514)=.41$,
    $p<.001^{***}$）、价值评分（$r(514)=.22$, $p=.011^{*}$）和惊讶度评分（$r(514)=.24$, $p=.006^{**}$）之间存在显著的正相关关系。我们还发现，深度为9或更高的RQ似乎表现出评分下降的趋势。这可能是由于RQ的重复性增加，而这种重复性是由话题缩小以及随之而来的固定文献空间造成的。为了进一步说明RQ的缩小过程，图[9](https://arxiv.org/html/2310.06155v3#S7.F9
    "Figure 9 ‣ 7.1.2\. Outcome: Depth-first Condition Yields RQs with Higher-rated
    Creativity ‣ 7.1\. Perception of Co-Creation Experience and Outcome (RQ1) ‣ 7\.
    Findings ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent")展示了其中一位参与者P4在深度优先条件下生成的RQ流程示例。该参与者最初对第一个生成的RQ表示困惑，因为它被认为“有点模糊”，并且“更像是一个文献综述问题，而不是研究问题。”在指示系统提供更多细节后，P4阅读并评论了后续生成的RQ，认为它是“一个还可以的研究问题……但我希望它能更具体地指出是什么（因素）使得VR/AR适合用于学习环境……”然后，他们生成了三个后续的RQ，并认为这些问题更加具体和令人惊讶，“我有点惊讶它能提取出可及性这一概念。”然而，他们也指出，理解后续RQ之间的联系变得更加具有挑战性。'
- en: 'Summary (RQ1): According to the post-session survey results, the breadth-first
    condition offered users a better co-creation experience, with higher perceptions
    of creativity and trust. In contrast, RQ rating data showed that the depth-first
    approach led to the generation of RQs deemed more creative by participants, with
    a unique depth and unexpected novelty. This insight indicates that while the breadth-first
    condition enhances user engagement, the depth-first condition stimulates deeper
    and more novel outcomes, leading to distinct advantages in different aspects of
    the co-creation process. Positive correlation between users’ ratings towards RQs
    and depth were also observed, indicating improved user perception towards co-creation
    outcomes as exploration unfolded.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 总结 (RQ1)：根据会后调查结果，广度优先条件为用户提供了更好的共同创造体验，用户在创造力和信任感方面的感知更高。相比之下，RQ 评分数据显示，深度优先方法导致生成的
    RQ 被参与者认为更具创造性，具有独特的深度和意外的新颖性。这个发现表明，尽管广度优先条件提升了用户参与度，但深度优先条件刺激了更深刻且更具新颖性的结果，在共同创造过程的不同方面具有显著优势。还观察到用户对
    RQ 的评分与深度之间存在正相关关系，表明随着探索的展开，用户对共同创造成果的感知得到了提升。
- en: 7.2\. Users’ Co-creation Behavior with LLM-based Agent (RQ2)
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 用户与基于LLM的智能体的共同创造行为 (RQ2)
- en: To explore users’ co-creation behavior with AI, we examined how they interacted
    with the CoQuest system through think-aloud comments, feedback to AI, and activities
    performed while they were waiting for AI to generate the results. In this section,
    we explain the findings to shed light on how participants used the CoQuest system
    under the two conditions.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索用户与 AI 的共同创造行为，我们通过思维大声表达、反馈 AI 和用户在等待 AI 生成结果时所执行的活动来分析他们与 CoQuest 系统的互动。在本节中，我们解释了研究结果，旨在揭示参与者在两种条件下如何使用
    CoQuest 系统。
- en: 7.2.1\. Depth-first Condition Stimulated More User Interactions During Wait
    Time
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.1\. 深度优先条件在等待期间激发了更多的用户互动
- en: The CoQuest system required users to wait for approximately 30 seconds for the
    LLM inference to finish after each time the generation was triggered. During this
    wait time, users can utilize other system features in parallel to the generation,
    such as interpreting other RQs, generating additional RQs, viewing AI Thoughts,
    and exploring the paper graph. By examining the behavior data of participants,
    we found that most participants utilized the wait time during the generation of
    RQs to perform other activities. In total, 12 out of 20 participants utilized
    the wait time to interpret and evaluate other existing RQs on the RQ flow editor.
    Among them, 7 participants created new RQs while waiting for prior RQs generation
    to be finished. We also found that more participants explored other RQs during
    wait time under the depth-first condition (N=12) than the breadth-first condition
    (N=6), with a two-proportion z-test indicating significance ($z=-2.01$, $p=0.045^{*}$).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest 系统要求用户在每次触发生成后等待大约 30 秒，直到 LLM 推理完成。在这个等待时间内，用户可以并行使用其他系统功能，如解读其他 RQ、生成额外的
    RQ、查看 AI 思维和探索论文图表。通过分析参与者的行为数据，我们发现大多数参与者在生成 RQ 的等待时间内进行了其他活动。总共有 20 位参与者中有 12
    位利用等待时间解读并评估 RQ 流编辑器中的其他现有 RQ。其中，7 位参与者在等待先前的 RQ 生成完成时创建了新的 RQ。我们还发现，在深度优先条件下（N=12）比在广度优先条件下（N=6）更多的参与者在等待时间内探索了其他
    RQ，使用两比例 z 检验显示了显著性（$z=-2.01$, $p=0.045^{*}$）。
- en: Participants were observed to switch among different threads of RQs during the
    wait time of generation. P16, for example, utilized wait time under depth-first
    conditions to start generating another thread of RQs. The participant further
    explained during the interview that if the RQs were generated quicker, “probably
    would just end up exploring one at a time. But because it was taking a while,
    I was like, oh, I can write another one.” The participant found the generation
    wait time beneficial for brainstorming new ideas, as it offered a good opportunity
    for exploring different directions in parallel. In addition, we also found a positive
    correlation, shown by Pearson’s correlation test ($r(392)=0.18,p<0.001^{***}$),
    between whether a user made use of the RQ generation wait time and the length
    of the user’s feedback to AI. The test result indicated that users utilized the
    RQ generation wait time to contemplate more detailed feedback for AI, suggesting
    higher engagement in human-AI co-creation.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者在生成的等待时间中被观察到在不同的RQ线程之间切换。例如，P16在深度优先条件下利用等待时间开始生成另一个RQ线程。该参与者在访谈中进一步解释道，如果RQ生成得更快，“可能最终只会一个一个地探索。但是因为花了些时间，我就想，哦，我可以再写一个。”该参与者发现生成等待时间对头脑风暴新想法有帮助，因为它提供了一个很好的机会，可以并行地探索不同的方向。此外，我们还发现了一个正相关关系，通过皮尔逊相关性检验显示（$r(392)=0.18,p<0.001^{***}$），即用户是否利用RQ生成等待时间与用户对AI反馈的长度之间存在正相关。测试结果表明，用户利用RQ生成等待时间来思考更详细的反馈给AI，这表明在人与AI的共同创作中有更高的参与度。
- en: During the wait time for generation, participants were also found to use the
    “AI thoughts” feature to understand the relationship between different RQs and
    the rationales behind generated RQs. Though it was confusing for some participants,
    most participants were observed to have read the “AI thoughts,” especially while
    waiting for all three RQs to be generated under the depth-first condition (14
    out of 20 users clicked and viewed the “AI thoughts” more than 10 times). More
    specifically, in the depth-first condition, each click generates three different
    “AI thoughts” compared to breadth-first condition, where each click only generates
    one “AI thoughts.” In addition to understanding the logical relation and reasoning
    behind RQs, participants also used “AI thoughts” for other co-creation purposes
    that were shared between the two conditions. For instance, users have found AI
    thoughts to be helpful both in terms of understanding the rationale of how RQs
    are generated, and also providing additional ideas for users to elaborate on.
    Some participants used the AI thoughts for sense-making of the generated RQs.
    When they recognized the AI thoughts were connected with the paper graph, they
    expressed that they trusted the system more because it seems like the AI thoughts
    are “from actual papers” that “are peer-reviewed” rather than “coming from large
    language model, which is not necessarily [factually] true” (P10). Among our different
    types of “AI thoughts,” one participant who could tell such differences (P16)
    said they liked the “summary of existing work” explanation type because it seems
    like this type “builds on existing works” and makes it more trustworthy. Some
    other participants also used the terms and keywords that appeared in “AI thoughts”
    to help develop their feedback to further guide RQ generation. For example, P10
    wrote the feedback to AI “Explore feature selection for non-experts” by taking
    inspiration from the AI’s thoughts about a summary of works related to feature
    selection techniques for data mining.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成等待期间，参与者还被发现使用“AI 思维”功能来理解不同研究问题（RQ）之间的关系以及生成的 RQ 背后的推理。尽管对一些参与者来说，这有些困惑，但大多数参与者在等待所有三个
    RQ 在深度优先条件下生成时，都会阅读“AI 思维”（20 位用户中有 14 位点击并查看了“AI 思维”超过 10 次）。更具体地说，在深度优先条件下，每次点击会生成三个不同的“AI
    思维”，而在广度优先条件下，每次点击只会生成一个“AI 思维”。除了理解 RQ 之间的逻辑关系和推理，参与者还使用“AI 思维”进行其他在两种条件下共享的共创目的。例如，用户发现
    AI 思维在理解 RQ 生成的推理方面很有帮助，同时也能为用户提供更多的思路来进一步阐述。一些参与者使用 AI 思维来理解生成的 RQ。当他们意识到 AI
    思维与论文图表相关时，他们表示更加信任系统，因为这看起来像是来自“实际的论文”，而不是“来自大型语言模型，后者不一定是[事实]准确的”（P10）。在我们不同类型的“AI
    思维”中，一位能够辨别这些差异的参与者（P16）表示，他们喜欢“现有工作总结”这一解释类型，因为这类类型似乎“建立在现有工作之上”，使其更值得信赖。一些其他参与者也使用了“AI
    思维”中出现的术语和关键词，帮助他们发展反馈，以进一步指导 RQ 的生成。例如，P10 在写给 AI 的反馈中写道：“为非专家探索特征选择”，灵感来自 AI
    思维中关于与数据挖掘特征选择技术相关的现有工作总结。
- en: 'To understand how users’ actions during wait time varied temporally during
    the exploration process, we performed Mann-Whitney U tests to examine the difference
    between users’ wait time actions under breadth- and depth-first conditions within
    each stage, i.e. earlier (depth¡=3) and later (depth¿3) stages. The stage of exploration
    is determined by computing the mean depth across all RQ nodes ($M=3.38$). Significant
    behavioral differences were observed between depth-first and breadth-first design
    conditions. The earlier stage of interaction revealed notable distinctions: users
    in the breadth-first condition engaged more frequently in ’Check paper graph’
    ($U=4414$, $P=0.009^{**}$) and ’Generate new RQs’ ($U=4483$, $P=0.011^{*}$) actions
    compared to those in the depth-first condition. This suggests that the breadth-first
    approach, which presents multiple research questions simultaneously, encourages
    more active exploration and engagement early in the interaction. However, these
    differences diminished in the later stage, indicating a convergence in user behavior
    as interaction progresses. This finding highlights the impact of initial information
    presentation on user actions, particularly in systems like CoQuest where engagement
    patterns can influence the user’s exploratory experience.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解用户在等待时间中的行为如何随时间变化，我们进行了 Mann-Whitney U 检验，检查了在每个阶段（即早期阶段（depth≤3）和后期阶段（depth>3））下，用户在宽度优先和深度优先条件下的等待时间行为差异。探索阶段是通过计算所有
    RQ 节点的平均深度来确定的（$M=3.38$）。在深度优先和宽度优先设计条件之间观察到了显著的行为差异。交互的早期阶段揭示了显著的区别：宽度优先条件下的用户比深度优先条件下的用户更频繁地进行“检查论文图表”（$U=4414$，$P=0.009^{**}$）和“生成新
    RQ”（$U=4483$，$P=0.011^{*}$）的操作。这表明，宽度优先方法通过同时展示多个研究问题，鼓励了交互初期更积极的探索和参与。然而，随着交互的进行，这些差异在后期阶段逐渐减小，表明随着交互的推进，用户行为趋于一致。这个发现突显了初始信息呈现对用户行为的影响，尤其是在像
    CoQuest 这样的系统中，参与模式能够影响用户的探索体验。
- en: 7.2.2\. Users Have Different Strategies for Providing Feedback to AI
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.2\. 用户在向 AI 提供反馈时采用了不同的策略
- en: 'The CoQuest system allows users to type in textual feedback to AI under each
    RQ before triggering the generation of new RQs. Overall, 20 participants wrote
    119 pieces of feedback in total using both conditions (M=7.44, SD=5.25) during
    the co-creation process. To find whether the participants had different ways of
    communicating with the AI using text feedback, we first analyzed the difference
    among users’ input lengths (word counts) by fitting a mixed-effects model that
    considers both the random effect from different users and the potential fixed
    effect from the two conditions. Details of the model and results can be found
    in Appendix [A.2](https://arxiv.org/html/2310.06155v3#A1.SS2 "A.2\. A Mixed-Effect
    Model of User Feedback Length ‣ Appendix A Appendices ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent"). A likelihood ratio test was then
    conducted to validate the significance of the random effect brought by users ($\chi^{2}(1)=9.189,p=0.002^{**}$).
    The result of the likelihood ratio test indicated a statistically significant
    difference in feedback lengths among different users regardless of the condition.
    However, we found no significant association between the system condition and
    users’ feedback lengths.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 'CoQuest 系统允许用户在每个 RQ 下输入文本反馈给 AI，然后再触发新 RQ 的生成。总体而言，20 名参与者在共创过程中使用两种条件写了 119
    条反馈（M=7.44，SD=5.25）。为了找出参与者在使用文本反馈与 AI 交流时是否存在不同的方式，我们首先通过拟合一个混合效应模型来分析用户输入长度（字数）之间的差异，该模型考虑了不同用户的随机效应以及两种条件下可能的固定效应。模型和结果的详细信息可以在附录
    [A.2](https://arxiv.org/html/2310.06155v3#A1.SS2 "A.2\. A Mixed-Effect Model of
    User Feedback Length ‣ Appendix A Appendices ‣ CoQuest: Exploring Research Question
    Co-Creation with an LLM-based Agent") 中找到。随后进行了似然比检验，以验证用户带来的随机效应的显著性（$\chi^{2}(1)=9.189,p=0.002^{**}$）。似然比检验的结果表明，无论条件如何，不同用户之间的反馈长度存在显著统计差异。然而，我们发现系统条件与用户反馈长度之间没有显著关联。'
- en: To obtain a deeper understanding of how participants employ different strategies
    in providing feedback to AI, we further reviewed and coded participants’ feedback
    to AI during the co-creation process and observed that participants tend to provide
    feedback to the AI in different ways. More specifically, we found three main themes.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地了解参与者在向 AI 提供反馈时采用的不同策略，我们进一步回顾并编码了参与者在共创过程中向 AI 提供的反馈，并观察到参与者倾向于以不同的方式向
    AI 提供反馈。更具体地说，我们发现了三个主要主题。
- en: 'The most common theme of giving AI feedback is to provide keywords (N=59),
    which is shorter in length. For feedback under this theme, 61.0 % (N=36) were
    used to start a new node using the keywords that the participant would like the
    AI to start with. From a generated RQ, participants may also provide new keywords
    and instruct the AI to include these keywords in the next iteration. Search and
    summarize was frequently used by AI to generate RQs based on the new keywords.
    For example, P4 started a node using the breadth-first condition with “AI and
    crowdsourcing,” as shown in Figure [7](https://arxiv.org/html/2310.06155v3#S7.F7
    "Figure 7 ‣ 7.1.1\. Experience: User Perceived Stronger Creativity and Trust Using
    Breadth-first Condition ‣ 7.1\. Perception of Co-Creation Experience and Outcome
    (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent"). The participant then continued with the generated RQ What are
    the ethical implications of using AI in crowdsourcing? and wrote “in an educational
    setting.” The AI then generated three new RQs with the new keyword.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 向AI提供反馈的最常见主题是提供关键词（N=59），这些反馈通常较短。此主题下的反馈中，61.0%（N=36）的情况是，参与者使用他们希望AI从中开始的关键词来启动新节点。从生成的研究问题中，参与者也可能提供新的关键词，并指示AI在下一次迭代中包含这些关键词。AI经常使用搜索和总结的方式，根据新的关键词生成研究问题。例如，P4使用“AI和众包”作为关键词，启动了一个使用广度优先条件的节点，如图[7](https://arxiv.org/html/2310.06155v3#S7.F7
    "图7 ‣ 7.1.1. 体验：用户在使用广度优先条件时感知到更强的创造性和信任 ‣ 7.1. 共同创作体验和结果的感知（RQ1） ‣ 7. 发现 ‣ CoQuest：探索基于LLM的代理的研究问题共同创作")所示。参与者随后继续处理生成的研究问题“在众包中使用AI的伦理影响是什么？”，并写下了“在教育环境中”。AI随后根据新的关键词生成了三个新的研究问题。
- en: The second theme is asking AI-specific questions (N=40). These questions are
    usually longer and in full sentences that either ask the AI to explain terms used
    in a generated RQ, to lead the AI toward a new direction, or to ask the AI to
    review more related literature. For example, based on the RQ What is the impact
    of medical simulations on medical student learning and skill development?, P17
    wrote, “It is a good question to research into, can you give me some information
    that is common among the papers.” The participant was able to proceed with one
    of the three generated RQs.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个主题是向AI提出具体问题（N=40）。这些问题通常较长，并且是完整的句子，通常是要求AI解释生成的研究问题中使用的术语，或者引导AI朝新的方向发展，或要求AI回顾更多相关文献。例如，基于研究问题“医学模拟对医学生学习和技能发展的影响是什么？”，P17写道：“这是一个值得研究的问题，你能给我一些在论文中常见的信息吗？”参与者能够继续处理三个生成的研究问题之一。
- en: 'A third theme is asking the AI to be more specific on an RQ (N=55). Feedback
    under this theme usually starts with the phrase “be more specific.” In 45 out
    of the 55 cases, participants would also include the direction that they would
    like the AI to continue on. In response, the AI usually narrows down RQs or performs
    search and summarization. For example, after seeing the RQ How can we design AI
    systems that effectively collaborate with human experts to find relevant literature
    for research questions? using depth-first condition, P2 wrote, “Can you be more
    specific about AI systems? this is just repeating my initial thought.” The AI
    then generated three more RQs, as shown in Figure [8](https://arxiv.org/html/2310.06155v3#S7.F8
    "Figure 8 ‣ 7.1.1\. Experience: User Perceived Stronger Creativity and Trust Using
    Breadth-first Condition ‣ 7.1\. Perception of Co-Creation Experience and Outcome
    (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent").'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个主题是要求AI在研究问题（RQ）上更加具体（N=55）。这一主题下的反馈通常以“be more specific”（更具体一些）开头。在55个案例中的45个，参与者还会包括他们希望AI继续进行的方向。作为回应，AI通常会缩小研究问题的范围，或进行搜索和总结。例如，在看到研究问题“我们如何设计能够有效与人类专家协作的AI系统，以便为研究问题找到相关文献？”后，使用深度优先条件，P2写道：“你能具体一点说明AI系统吗？这只是在重复我最初的想法。”随后，AI生成了三个新的研究问题，如图[8](https://arxiv.org/html/2310.06155v3#S7.F8
    "图8 ‣ 7.1.1. 体验：用户在使用广度优先条件时感知到更强的创造性和信任 ‣ 7.1. 共同创作体验和结果的感知（RQ1） ‣ 7. 发现 ‣ CoQuest：探索基于LLM的代理的研究问题共同创作")所示。
- en: 'Summary (RQ2): Participants were found to have employed different strategies
    when co-creating research questions (RQs) with AI. Participants mainly provided
    feedback by listing keywords, posing additional questions, or requesting specificity.
    While waiting for the AI’s response, users often explored other RQs, showing greater
    engagement in conditions with longer wait times. The AI Thoughts panel, which
    offers insights into the AI’s reasoning, was found beneficial in enhancing trust
    and inspiring feedback, especially when grounded in peer-reviewed literature.
    Moreover, our analysis revealed that in the early stages of interaction, users
    in the breadth-first condition engaged in more actions during wait time, such
    as checking paper graphs and generating new research questions, indicating that
    initial information presentation in a breadth-first manner notably influenced
    users’ early exploration behavior.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 概要（RQ2）：研究发现，参与者在与AI共同创造研究问题（RQ）时采用了不同的策略。参与者主要通过列出关键词、提出额外问题或请求具体化来提供反馈。在等待AI回应期间，用户常常探索其他RQ，表现出在等待时间较长的条件下更高的参与度。AI思想面板提供了关于AI推理的洞见，被发现有助于增强信任并激发反馈，特别是当这些推理基于同行评审文献时。此外，我们的分析表明，在互动的初期阶段，处于广度优先条件下的用户在等待时间内进行了更多操作，例如检查论文图表和生成新的研究问题，表明广度优先的信息呈现方式显著影响了用户的早期探索行为。
- en: 7.3\. Association between Users’ Persona/Behavior and Their Perceptions (RQ3)
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3\. 用户角色/行为与其感知之间的关联（RQ3）
- en: Table 1. Regression Results with RQ ratings as dependent variables and users’
    behavior data as predictors. Each column in the table represents one regression
    performed with the corresponding rating item as the dependent variable.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 回归结果，以RQ评分作为因变量，用户行为数据作为预测变量。表中的每一列表示针对相应评分项作为因变量所进行的回归分析。
- en: '|  | Dependent Variables — Outcomes (RQ Ratings) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|  | 因变量 — 结果（RQ评分） |'
- en: '| Predictors | Novelty | Value | Surprise | Relevance |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 预测变量 | 新颖性 | 价值 | 惊讶 | 相关性 |'
- en: '|  | $\beta$ (S.E.) | $\beta$ (S.E.) | $\beta$ (S.E.) | $\beta$ (S.E.) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | $\beta$ (标准误) | $\beta$ (标准误) | $\beta$ (标准误) | $\beta$ (标准误) |'
- en: '| Condition (Depth-First=1) | 1.53 (.63)* | 1.54 (.64)* | 1.52 (.60)* | 1.70
    (.68)* |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 条件（深度优先=1） | 1.53 (.63)* | 1.54 (.64)* | 1.52 (.60)* | 1.70 (.68)* |'
- en: '| Feedback Length | .15 (.06)* | .17 (.06)* | .15 (.06)* | .18 (.06)** |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 反馈长度 | .15 (.06)* | .17 (.06)* | .15 (.06)* | .18 (.06)** |'
- en: '| Total # of RQs Created | -.01 (.03) | -.03 (.03) | -.02 (.03) | -.04 (.04)
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 创建的RQ总数 | -.01 (.03) | -.03 (.03) | -.02 (.03) | -.04 (.04) |'
- en: '| Acted During Wait | -.06 (.07) | -.07 (.07) | -.06 (.06) | -.08 (.07) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 等待期间的操作 | -.06 (.07) | -.07 (.07) | -.06 (.06) | -.08 (.07) |'
- en: '| Familiarity | .19 (.14) | .18 (.14) | .20 (.13) | .22 (.15) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 熟悉度 | .19 (.14) | .18 (.14) | .20 (.13) | .22 (.15) |'
- en: '| *: p$<$0.05, **: p$<$0.01, ***: p$<$0.001 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| *: p$<$0.05, **: p$<$0.01, ***: p$<$0.001 |'
- en: Table 2. Regression Results with survey ratings as dependent variables and users’
    behavior data as predictors.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2. 回归结果，以调查评分作为因变量，用户行为数据作为预测变量。
- en: '|  | Dependent Variables — Experience (Survey Scores) |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|  | 因变量 — 经验（调查评分） |'
- en: '| Predictors | Control | Creativity | Meta Creativity | Cognitive Load | Trust
    |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 预测变量 | 控制 | 创造力 | 元创造力 | 认知负荷 | 信任 |'
- en: '|  | $\beta$ (S.E.) | $\beta$ (S.E.) | $\beta$ (S.E.) | $\beta$ (S.E.) | $\beta$ (S.E.)
    |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  | $\beta$ (标准误) | $\beta$ (标准误) | $\beta$ (标准误) | $\beta$ (标准误) | $\beta$ (标准误)
    |'
- en: '| Cond. (Depth-First=1) | .34 (.71) | -.41 (.46) | -.74 (.23)** | .82 (.36)*
    | -.58 (.88) |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 条件（深度优先=1） | .34 (.71) | -.41 (.46) | -.74 (.23)** | .82 (.36)* | -.58 (.88)
    |'
- en: '| Feedback Length | -.03 (.04) | .02 (.05) | -.01 (.03) | .07 (.01)*** | .03
    (.04) |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 反馈长度 | -.03 (.04) | .02 (.05) | -.01 (.03) | .07 (.01)*** | .03 (.04) |'
- en: '| Total # of RQs Created | -.07 (.03)* | -.01 (.01) | .03 (.01)* | -.01 (.01)
    | .02 (.05) |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 创建的RQ总数 | -.07 (.03)* | -.01 (.01) | .03 (.01)* | -.01 (.01) | .02 (.05)
    |'
- en: '| Acted During Wait | .10 (.04)** | -.06 (.07) | -.03 (.04) | .06 (.05) | -.03
    (.04) |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 等待期间的操作 | .10 (.04)** | -.06 (.07) | -.03 (.04) | .06 (.05) | -.03 (.04)
    |'
- en: '| Familiarity | -.22 (.08)** | .04 (.09) | -.09 (.05) | -.08 (.04)* | .07 (.08)
    |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 熟悉度 | -.22 (.08)** | .04 (.09) | -.09 (.05) | -.08 (.04)* | .07 (.08) |'
- en: '| *: p$<$0.05, **: p$<$0.01, ***: p$<$0.001 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| *: p$<$0.05, **: p$<$0.01, ***: p$<$0.001 |'
- en: 'To better understand the factors influencing participants’ perceived experiences
    and outcomes, we performed two linear regression analyses, aiming to associate
    user perceptions with their behaviors and backgrounds. The two sets of regressions
    aim to yield insights about users’ perceptions from two perspectives: 1) the first
    set of regressions adopts participants’ ratings for RQs (i.e., novelty, value,
    surprise, and relevance) as dependent variables; 2) another set of regressions
    participants’ post-session survey scores for the system (i.e., control, creativity,
    meta creativity, and cognitive load) as the dependent variables.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解影响参与者感知体验和结果的因素，我们进行了两项线性回归分析，旨在将用户的感知与其行为和背景关联起来。这两组回归分析的目的是从两个角度为用户的感知提供见解：1)
    第一组回归分析采用参与者对RQ（即新颖性、价值、惊讶和相关性）的评分作为因变量；2) 另一组回归分析则采用参与者在会后调查中对系统的评分（即控制、创造力、元创造力和认知负荷）作为因变量。
- en: 'We chose factors that could represent users’ behavior as predictors based on
    our previous findings⁸⁸8 To examine the potential issue of multicollinearity,
    we calculated the Variance Inflation Factor (VIF) for each predictor. All predictors
    yielded VIFs lower than the common threshold of 5 (James et al., [2013](https://arxiv.org/html/2310.06155v3#bib.bib27)),
    indicating no substantial collinearity problem. . We first considered the conditions
    of the system (breadth-first or depth-first) experienced by the user, as indicated
    by the results in [7.1](https://arxiv.org/html/2310.06155v3#S7.SS1 "7.1\. Perception
    of Co-Creation Experience and Outcome (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring
    Research Question Co-Creation with an LLM-based Agent") that the two conditions
    might have a difference between their impact over the user’s perception of co-creation
    experience and outcomes. We constructed the predictor as a categorical variable,
    with value 0 standing for breadth-first condition and value 1 standing for depth-first
    condition. We also considered factors related to user engagement, including the
    length of user feedback to AI, which was found to vary across different users
    as mentioned in [7.2.2](https://arxiv.org/html/2310.06155v3#S7.SS2.SSS2 "7.2.2\.
    Users Have Different Strategies for Providing Feedback to AI ‣ 7.2\. Users’ Co-creation
    Behavior with LLM-based Agent (RQ2) ‣ 7\. Findings ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent"), and the count of total RQ nodes
    created. Additionally, we included whether users performed any actions while waiting
    for results from an already triggered generation as a potential factor, as discussed
    in [7.2.1](https://arxiv.org/html/2310.06155v3#S7.SS2.SSS1 "7.2.1\. Depth-first
    Condition Stimulated More User Interactions During Wait Time ‣ 7.2\. Users’ Co-creation
    Behavior with LLM-based Agent (RQ2) ‣ 7\. Findings ‣ CoQuest: Exploring Research
    Question Co-Creation with an LLM-based Agent"). Participants’ familiarity with
    task topics was also considered as a predictor, measured through the familiarity
    ratings collected through the post-session surveys. The familiarity variable was
    constructed as an ordinal variable taking three possible integer values from 0
    (not familiar) to 2 (very familiar).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '我们选择了能够代表用户行为的因素作为预测变量，基于我们之前的研究发现⁸⁸8。为了检查多重共线性问题的潜在影响，我们计算了每个预测变量的方差膨胀因子（VIF）。所有预测变量的VIF值均低于常见的阈值5（James
    et al., [2013](https://arxiv.org/html/2310.06155v3#bib.bib27)），表明没有显著的共线性问题。我们首先考虑了用户体验的系统条件（广度优先或深度优先），如[7.1](https://arxiv.org/html/2310.06155v3#S7.SS1
    "7.1\. Co-Creation体验和结果的感知 (RQ1) ‣ 7\. 发现 ‣ CoQuest: 探索与LLM代理共同创作研究问题")的结果所示，两个条件可能在其对用户共同创作体验和结果的影响上存在差异。我们将预测变量构造为一个分类变量，值为0表示广度优先条件，值为1表示深度优先条件。我们还考虑了与用户参与度相关的因素，包括用户向AI提供反馈的长度，正如[7.2.2](https://arxiv.org/html/2310.06155v3#S7.SS2.SSS2
    "7.2.2\. 用户在提供反馈时有不同策略 ‣ 7.2\. 用户与LLM代理的共同创作行为 (RQ2) ‣ 7\. 发现 ‣ CoQuest: 探索与LLM代理共同创作研究问题")中提到的，这一长度在不同用户之间有所不同，以及创建的总RQ节点数。此外，我们还包括了用户在等待已经触发生成的结果时是否进行任何操作作为潜在因素，如[7.2.1](https://arxiv.org/html/2310.06155v3#S7.SS2.SSS1
    "7.2.1\. 深度优先条件激发了更多的用户互动 ‣ 7.2\. 用户与LLM代理的共同创作行为 (RQ2) ‣ 7\. 发现 ‣ CoQuest: 探索与LLM代理共同创作研究问题")中讨论的内容。参与者对任务主题的熟悉程度也被考虑作为一个预测变量，通过会后调查中收集的熟悉度评分来衡量。熟悉度变量被构建为一个有序变量，取三个可能的整数值，从0（不熟悉）到2（非常熟悉）。'
- en: 'Positive perceptions of generated RQs associated with longer feedback to AI.
    As shown by the results in Table [1](https://arxiv.org/html/2310.06155v3#S7.T1
    "Table 1 ‣ 7.3\. Association between Users’ Persona/Behavior and Their Perceptions
    (RQ3) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent"), a positive association has been identified between all four
    dimensions of user-perceived RQ ratings and the average lengths of users’ input
    feedback lengths. The finding suggests that increased user engagement in the human-AI
    co-creation process through providing textual feedback might improve the perceived
    outcome quality. In addition, we found that the RQ ratings are positively associated
    with whether a user used the system under the depth-first condition. Namely, users
    perceived the RQs generated by AI under the depth-first condition to be of better
    quality than the breadth-first condition. This also corresponds to our findings
    in [7.1.2](https://arxiv.org/html/2310.06155v3#S7.SS1.SSS2 "7.1.2\. Outcome: Depth-first
    Condition Yields RQs with Higher-rated Creativity ‣ 7.1\. Perception of Co-Creation
    Experience and Outcome (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question
    Co-Creation with an LLM-based Agent"). From Table [1](https://arxiv.org/html/2310.06155v3#S7.T1
    "Table 1 ‣ 7.3\. Association between Users’ Persona/Behavior and Their Perceptions
    (RQ3) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent"), it can also be seen that participants’ feedback length is positively
    associated with perceived cognitive load. The results indicate that, although
    providing longer feedback required users to invest more thoughts, it also improved
    the co-creation outcomes. The finding also aligns with our earlier qualitative
    results in [7.1](https://arxiv.org/html/2310.06155v3#S7.SS1 "7.1\. Perception
    of Co-Creation Experience and Outcome (RQ1) ‣ 7\. Findings ‣ CoQuest: Exploring
    Research Question Co-Creation with an LLM-based Agent"). The interview result
    further reveals that providing feedback promoted their reflection on themselves
    and trying to understand how AI works, although tiring, simultaneously helped
    them improve and manage their own creative thinking processes. More specially,
    some participants were observed during think-aloud performing “reverse engineering”
    to interpret how AI works and even try to replicate the generation process in
    a new thread.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '对生成的研究问题（RQ）的积极感知与对AI的较长反馈时间相关。如表[1](https://arxiv.org/html/2310.06155v3#S7.T1
    "Table 1 ‣ 7.3\. Association between Users’ Persona/Behavior and Their Perceptions
    (RQ3) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent")所示，用户感知的所有四个维度的RQ评分与用户输入反馈时长的平均值之间存在正相关。该发现表明，通过提供文本反馈，用户在与AI共同创作过程中的参与度增加，可能有助于提升感知的结果质量。此外，我们发现RQ评分与用户是否在深度优先条件下使用系统之间存在正相关。即，用户认为在深度优先条件下生成的RQ质量优于广度优先条件下生成的RQ。这一结果也与我们在[7.1.2](https://arxiv.org/html/2310.06155v3#S7.SS1.SSS2
    "7.1.2\. Outcome: Depth-first Condition Yields RQs with Higher-rated Creativity
    ‣ 7.1\. Perception of Co-Creation Experience and Outcome (RQ1) ‣ 7\. Findings
    ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent")中的发现一致。从表[1](https://arxiv.org/html/2310.06155v3#S7.T1
    "Table 1 ‣ 7.3\. Association between Users’ Persona/Behavior and Their Perceptions
    (RQ3) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent")中也可以看出，参与者的反馈时长与感知的认知负荷呈正相关。结果表明，尽管提供较长的反馈需要用户投入更多的思考，但也提高了共同创作的结果。这个发现与我们在[7.1](https://arxiv.org/html/2310.06155v3#S7.SS1
    "7.1\. Perception of Co-Creation Experience and Outcome (RQ1) ‣ 7\. Findings ‣
    CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent")中的早期定性结果一致。访谈结果进一步揭示，提供反馈促进了他们对自己的反思，并尝试理解AI的工作原理，尽管这令人疲惫，但也帮助他们提升和管理自己的创造性思维过程。更具体地说，一些参与者在“边想边说”过程中被观察到进行“逆向工程”，以解释AI如何工作，甚至尝试在新的线程中复制生成过程。'
- en: 'Factors associated with users’ perception of co-creation experience. Table
    [2](https://arxiv.org/html/2310.06155v3#S7.T2 "Table 2 ‣ 7.3\. Association between
    Users’ Persona/Behavior and Their Perceptions (RQ3) ‣ 7\. Findings ‣ CoQuest:
    Exploring Research Question Co-Creation with an LLM-based Agent") shows the regression
    results with participants’ survey rating responses as dependent variables and
    user-specific factors as predictors. We found a statistically significant positive
    association between whether a participant has utilized the RQ generation wait
    time to perform other activities and the participant’s perceived control for the
    system. This indicates that users tend to perceive higher control of the system
    when better utilizing the generation wait time beyond merely waiting for the generated
    results. There was also a negative association between the total number of nodes
    generated by participants and their perceived control, which indicates that as
    users generate more RQs during each session, they perceive to have weaker control
    of the system.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '与用户共创体验感知相关的因素。表[2](https://arxiv.org/html/2310.06155v3#S7.T2 "Table 2 ‣ 7.3\.
    Association between Users’ Persona/Behavior and Their Perceptions (RQ3) ‣ 7\.
    Findings ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent")展示了回归结果，参与者的调查评分作为因变量，用户特定因素作为预测变量。我们发现，参与者是否利用RQ生成等待时间进行其他活动与参与者对系统控制感知之间存在统计学上显著的正相关。这表明，当用户更好地利用生成等待时间，而不仅仅是等待生成结果时，他们会感知到对系统的更高控制感。参与者生成的节点总数与他们的控制感知之间存在负相关，这表明，随着用户在每次会话中生成更多的RQ，他们感知到的系统控制感更弱。'
- en: 'Participants’ familiarity with the task topics was also found to be negatively
    associated with their perceived control. This was also reflected by participants
    during their think-aloud process, as users who were more familiar with the task
    topic had stronger expectations for the generated RQs: “… in educational research,
    we don’t say crowdsourcing anymore. We say learner sourcing … ” (P4). We also
    noted that more experienced researchers would explicitly specify their needs for
    the agent to generate RQs in directions using terms related to research methodology.
    For example, one feedback P17 wrote to AI was “What the metrics for effectiveness
    and engagements.” Several participants reflected that they were having a rough
    initial thought in their mind when being assigned a topic that is familiar to
    them, and what AI does is only help them externalize the thoughts. P4, for example,
    found several generated RQs to be “surprising in a negative manner” as he would
    evaluate whether an RQ “is something interesting, something novel, and … relates
    to some of the prior literature.”'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者对任务主题的熟悉度也被发现与他们的控制感知呈负相关。这一点在参与者的思维大声表达过程中也得到了体现，因为熟悉任务主题的用户对生成的RQ有更强的期望：“……在教育研究中，我们不再说众包，而是说学习者众包……”（P4）。我们还注意到，经验更丰富的研究人员会明确说明他们希望代理根据研究方法相关术语生成RQ。例如，一位反馈者P17向AI写道：“什么是有效性和参与度的衡量标准。”几位参与者反映，当他们被分配到一个自己熟悉的主题时，心中已有一个粗略的初步想法，而AI所做的只是帮助他们将这些想法外化。例如，P4发现几个生成的RQ“在负面意义上令人惊讶”，因为他会评估一个RQ“是否有趣、是否新颖，并且……与一些先前的文献相关。”
- en: 'Summary (RQ3): Factors related to participants’ system usage were found to
    be associated with users’ perceptions of co-creation experiences and outcomes.
    The depth-first condition was also associated with better-perceived outcome quality
    in AI-generated RQs than the breadth-first condition. Users’ familiarity with
    task topics, interestingly, led to a reduced sense of control, indicating users
    with different levels of expertise may have specific expectations unmet by the
    AI system. Additionally, we found that users providing longer feedback to AI,
    although introducing a larger cognitive load, led to outcomes with better quality.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总结（RQ3）：与参与者的系统使用相关的因素与用户的共创体验和结果感知相关。深度优先条件与AI生成的RQ在结果质量上的较好感知有关，优于广度优先条件。有趣的是，用户对任务主题的熟悉度与控制感知呈负相关，表明不同专业水平的用户可能对AI系统的期望未能满足。此外，我们发现，用户向AI提供较长反馈，虽然会增加认知负担，但也导致了更高质量的结果。
- en: 8\. Discussion
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 讨论
- en: In this section, we explore how the insights from our user study align with
    established theories and previous research. Furthermore, we offer design implications
    for future co-creation systems using Large Language Models.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们探讨了我们的用户研究洞察与已有理论及先前研究的对接方式。此外，我们还为未来使用大语言模型的共创系统提供了设计启示。
- en: Figure 10. Updating the mental model of human-AI RQ co-creation with additional
    factors identified through the experimental study.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10. 通过实验研究发现的额外因素，更新人类与 AI 研究问题共创的心理模型。
- en: '![Refer to caption](img/925a299b214e826578c01aeae9ca30b6.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/925a299b214e826578c01aeae9ca30b6.png)'
- en: 'This is the updated human’s mental model of RQ co-creation with the LLM-based
    agent. The following description are the same as the initial model in Figure.
    There are four components inside this model: Present RQs and Explain AI Thoughts
    (lower left, rectangular), Understand the Literature (center, rectangular), Literature
    Space (top, with cylinder shape), and Refine and Re-scope (lower right, rectangular).
    From Present RQs and Explain AI Thoughts to Refine and Re-scope, there are two
    user-driven activities: Evaluate RQ creativity, feasibility, etc., and Provide
    feedback. From Refine and Re-scope to Understand the Literature, there is one
    user- and AI-driven activity: Incorporate Human Feedback. From Understand the
    Literature to Present RQs and Explain AI Thoughts, there is one AI-driven activity:
    Bootstrap Initial RQs. From Understand the Literature to Literature Space, there
    is one AI-driven activity: Search and select. From Literature space to Understand
    the Literature, there is one AI-driven activity: Summarize and Integrate. The
    model has ”Initial idea / keywords” as input and ”Well-defined High Quality RQs”
    as output. The following descriptions are the differences from the initial model.
    There are three additional blue texts highlighting the additional factors added
    to the model. From Present RQs and Explain AI Thoughts to Refine and Re-scope,
    there is blue text: User persona. From Refine and Re-scope to Understand the Literature,
    there is blue text: Intentional wait-time. From Understand the Literature to Present
    RQs and Explain AI Thoughts, there is a blue text: AI Initiatives: breadth/depth.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这是人类与基于 LLM 的代理共同创作研究问题的更新心理模型。以下描述与图中的初始模型相同。该模型包含四个部分：呈现研究问题并解释 AI 思路（左下方，矩形）、理解文献（中央，矩形）、文献空间（顶部，圆柱形）和细化与重新规划（右下方，矩形）。从呈现研究问题并解释
    AI 思路到细化与重新规划，有两个用户驱动的活动：评估研究问题的创造性、可行性等，以及提供反馈。从细化与重新规划到理解文献，有一个用户与 AI 驱动的活动：融入人类反馈。从理解文献到呈现研究问题并解释
    AI 思路，有一个 AI 驱动的活动：引导初始研究问题。从理解文献到文献空间，有一个 AI 驱动的活动：搜索并选择。从文献空间到理解文献，有一个 AI 驱动的活动：总结与整合。该模型的输入是“初始想法/关键词”，输出是“明确的高质量研究问题”。以下描述是与初始模型的不同之处。模型中增加了三处蓝色文本，突出了新增的因素。从呈现研究问题并解释
    AI 思路到细化与重新规划，有蓝色文本：“用户画像”。从细化与重新规划到理解文献，有蓝色文本：“有意等待时间”。从理解文献到呈现研究问题并解释 AI 思路，有蓝色文本：“AI
    主动性：广度/深度”。
- en: Figure 10. Updating the mental model of human-AI RQ co-creation with additional
    factors identified through the experimental study.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10. 通过实验研究发现的额外因素，更新人类与 AI 研究问题共创的心理模型。
- en: 8.1\. Enriching Our Proposed Mental Model for Human-AI Co-Creation of Novel
    Research Questions
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1\. 丰富我们提出的人类与 AI 共创新型研究问题的心理模型
- en: 'Existing studies (Foster, [2004](https://arxiv.org/html/2310.06155v3#bib.bib19);
    Palmer et al., [2009](https://arxiv.org/html/2310.06155v3#bib.bib56)) have mostly
    been focused on the research lifecycle as a whole when discussing the models of
    the research process. Our user study findings shed light on additional factors
    to consider when designing future human-AI co-creation systems for research question
    generation, as shown in Figure [10](https://arxiv.org/html/2310.06155v3#S8.F10
    "Figure 10 ‣ 8\. Discussion ‣ CoQuest: Exploring Research Question Co-Creation
    with an LLM-based Agent").'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '现有研究（Foster, [2004](https://arxiv.org/html/2310.06155v3#bib.bib19); Palmer
    等人, [2009](https://arxiv.org/html/2310.06155v3#bib.bib56)）在讨论研究过程模型时，主要集中于整个研究生命周期。我们的用户研究发现揭示了在设计未来人类与
    AI 共创研究问题系统时需要考虑的额外因素，如图 [10](https://arxiv.org/html/2310.06155v3#S8.F10 "Figure
    10 ‣ 8\. Discussion ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent") 所示。'
- en: 8.1.1\. Wait Time in AI-based Co-Creation System as an Opportunity to Promote
    Creativity
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.1\. 在基于 AI 的共创系统中，等待时间作为促进创造力的机会
- en: 'Our observation of users’ behavior patterns when using the CoQuest system sheds
    light on the possibility of utilizing the AI system’s processing wait time as
    a design opportunity for users’ exploration in the context of human-AI co-creation
    systems. The RQ3 findings revealed that when users utilized wait time to perform
    other activities, it improved their perceived control of the co-creation experience.
    This is contradictory to the common belief that the response delay in AI-based
    systems only leads to a negative impact on users’ experience. In our RQ2 findings,
    two participants (P10 and P16) mentioned that AI Thoughts panel improved their
    trust for the system. However, this effect may not have been significant in the
    regression results of Table [2](https://arxiv.org/html/2310.06155v3#S7.T2 "Table
    2 ‣ 7.3\. Association between Users’ Persona/Behavior and Their Perceptions (RQ3)
    ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based
    Agent") due to the aggregation of various actions under the “acted during wait”
    category. We recognize that the impact of the AI thoughts panel on trust might
    have been diluted when combined with other actions in the aggregated data, thus
    statistically insignificant. Future work should separate these actions to measure
    their individual impacts on trust more precisely. This will allow a clearer understanding
    of how specific features, such as the AI thoughts panel, contribute to enhancing
    user trust. Our RQ2 results also showed that users utilized the time waiting to
    jump across different threads of RQs and perform exploration of ideas in parallel,
    or to articulate more detailed feedback for AI. The utilization of wait time was
    found to be prominent especially under the depth-first condition, which could
    be one of the reasons leading to its higher perceived co-creation outcome quality.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '我们在使用CoQuest系统时观察到的用户行为模式揭示了在人工智能（AI）系统处理等待时间的背景下，如何将其作为一个设计机会，促进用户在人与AI共同创作系统中的探索。RQ3的研究结果表明，当用户利用等待时间进行其他活动时，会提高他们对共同创作体验的控制感。这与普遍认为AI系统中的响应延迟只会对用户体验产生负面影响的看法相矛盾。在我们的RQ2结果中，两个参与者（P10和P16）提到AI思想面板提升了他们对系统的信任。然而，由于在表[2](https://arxiv.org/html/2310.06155v3#S7.T2
    "Table 2 ‣ 7.3\. Association between Users’ Persona/Behavior and Their Perceptions
    (RQ3) ‣ 7\. Findings ‣ CoQuest: Exploring Research Question Co-Creation with an
    LLM-based Agent")中的回归结果是将“在等待期间采取的行动”类别下的各种行动进行聚合，因此这种效应可能在统计上没有显著性。我们认识到，当AI思想面板的影响与其他行为在聚合数据中合并时，可能会削弱其对信任的影响，从而导致统计上不显著。未来的工作应当将这些行为分开，以更精确地衡量它们对信任的单独影响。这将有助于更清晰地了解诸如AI思想面板等特定功能如何增强用户信任。我们的RQ2结果还显示，用户利用等待时间在不同的RQ线程间跳跃，并并行进行创意探索，或为AI提供更详细的反馈。尤其在深度优先条件下，等待时间的利用尤为突出，这可能是导致其更高感知共同创作成果质量的原因之一。'
- en: Most recent studies on LLM optimization focus on reducing the inference time
    and speeding the generation wait time needed for general purposes (Liu et al.,
    [2023a](https://arxiv.org/html/2310.06155v3#bib.bib44); Leviathan et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib38);
    Dettmers and Zettlemoyer, [2023](https://arxiv.org/html/2310.06155v3#bib.bib13)).
    Our findings, however, provided a unique perspective that in the context of LLM-based
    co-creation systems, the generation wait time can be exploited, or even purposely
    introduced, to promote users’ creative activities. This can be achieved using
    different design techniques, such as tree-based visualization that highlights
    concurrency, or incorporating interactive nudges that guide users towards reflection,
    ideation, or brainstorming during these pauses. Such techniques can not only enhance
    user engagement but also maximize the cognitive benefits derived from the wait
    time breaks, potentially leading to more innovative and diverse co-creation outcomes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 最近关于大语言模型（LLM）优化的研究大多集中在减少推理时间和加速生成等待时间，以满足一般用途（Liu et al., [2023a](https://arxiv.org/html/2310.06155v3#bib.bib44);
    Leviathan et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib38); Dettmers
    and Zettlemoyer, [2023](https://arxiv.org/html/2310.06155v3#bib.bib13)）。然而，我们的研究发现提供了一个独特的视角：在基于LLM的共同创作系统中，生成等待时间可以被利用，甚至故意引入，以促进用户的创意活动。这可以通过不同的设计技术实现，例如突出并发性的基于树的可视化，或融入引导用户反思、构思或头脑风暴的互动性提示。这些技术不仅可以增强用户的参与感，还能最大化等待时间带来的认知益处，可能导致更具创新性和多样性的共同创作成果。
- en: 8.1.2\. Aligning Users’ Perception towards Experience and Outcomes of Generated
    RQs for Improved Creativity
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.2\. 调整用户对生成的研究问题（RQ）体验和结果的感知，以提升创造力
- en: 'In addition to prior studies’ understanding of mix-initiative system design
    (Rezwana and Maher, [2022](https://arxiv.org/html/2310.06155v3#bib.bib63); Weisz
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib79)), our study provides
    empirical findings to support the need to consider the degree of initiative taken
    by AI as a design option in further human-AI co-creation system design. Our RQ1
    findings indicate that the degree of initiative taken by AI during co-creation
    could affect users’ perception of both co-creation experience and outcomes: If
    AI takes less initiative and gives users more freedom to choose from various generation
    outputs, it improves the users’ co-creation experience. Contrarily, if AI drives
    deeper thoughts by taking more initiative, it leads to co-creation outcomes with
    higher quality and creativity. Based on our study results, this can be implied
    through lower user-given ratings (e.g., creativity and trust) towards their experience
    during the co-creation process. The findings lead us to believe that there exists
    a balance between user agency and AI initiative that can be aligned to better
    support co-creation. An ideal design would likely involve a dynamic adjustment
    of AI’s role based on the user’s expertise, background, and desire for control,
    allowing for both an engaging co-creation experience and innovative outcomes.
    Future designs should prioritize user feedback and adaptability, ensuring that
    the AI system can recognize and respond to user needs and preferences throughout
    the co-creation process.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 除了以往研究对混合主动系统设计的理解（Rezwana 和 Maher, [2022](https://arxiv.org/html/2310.06155v3#bib.bib63);
    Weisz 等人, [2023](https://arxiv.org/html/2310.06155v3#bib.bib79)），我们的研究提供了实证结果，支持在进一步的人机共同创作系统设计中考虑AI采取主动程度作为设计选项。我们的RQ1研究结果表明，AI在共同创作过程中采取的主动程度可能会影响用户对共同创作体验和结果的感知：如果AI采取较少的主动性，给用户更多选择各种生成结果的自由，那么它能改善用户的共同创作体验。相反，如果AI通过采取更多的主动性来引发更深层次的思考，它将导致更高质量和更具创造性的共同创作结果。根据我们的研究结果，这可以通过用户在共同创作过程中对他们体验的评分较低（例如，创造力和信任）来体现。研究结果使我们相信，用户自主性和AI主动性之间存在一种平衡，调整这种平衡能够更好地支持共同创作。理想的设计可能涉及根据用户的专业知识、背景和控制欲望动态调整AI的角色，以提供既有吸引力的共同创作体验，又能产生创新结果的设计。未来的设计应优先考虑用户反馈和适应性，确保AI系统能够识别并响应用户在共同创作过程中的需求和偏好。
- en: 8.1.3\. Customizing Co-Creation based on Researcher’s Persona
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.3\. 基于研究者角色的共同创作定制
- en: The findings of RQ3 revealed that the background of researchers, including factors
    such as domain knowledge and research experience, were found to influence their
    interaction with our system and their evaluation of generated RQs. Additionally,
    a user’s preference for the diversity and specificity of the model’s outputs can
    vary depending on their research stage. For instance, during earlier stages of
    research, users tend to prefer the generated RQs to be more explorative and cover
    a broader perspective, while they might value more relevant and specific outputs
    during later stages of research where the research topic or idea has been scoped
    down to a certain degree. Although prior research has described the information-seeking
    behavior of researchers as a non-linear and dynamic process (Foster, [2004](https://arxiv.org/html/2310.06155v3#bib.bib19)),
    our observations suggest that users’ expectations of the system diverge based
    on their individual backgrounds and the progression of their research. The newly
    identified factors highlight the significance of personalization and adaptability
    to users’ evolving needs in co-creation systems, particularly in the context of
    scholarly research. Recent research in aligning user persona with LLMs (Hwang
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib25); Salemi et al.,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib64)) has provided viable means
    for future designs of personalized research co-creation systems. It’s crucial
    that later designs emphasize adaptability to ensure that system outcomes align
    with the individual researcher’s background, progress, and specific research goals.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: RQ3的研究结果表明，研究者的背景，包括领域知识和研究经验等因素，影响了他们与我们系统的互动以及他们对生成的研究问题（RQs）的评价。此外，用户对模型输出的多样性和具体性的偏好可能会根据其研究阶段而有所不同。例如，在研究的早期阶段，用户倾向于偏好生成的研究问题更具探索性，涵盖更广泛的视角，而在研究后期，当研究主题或思路已经缩小到一定程度时，用户可能更看重相关性强、具体的输出。尽管先前的研究已经描述了研究者的信息寻求行为是一种非线性和动态的过程（Foster，[2004](https://arxiv.org/html/2310.06155v3#bib.bib19)），我们的观察结果表明，用户对系统的期望会根据他们的个人背景和研究进展而有所不同。新识别的因素凸显了个性化和适应性在共创系统中的重要性，特别是在学术研究的背景下。最近关于将用户画像与大语言模型（LLMs）对齐的研究（Hwang等人，[2023](https://arxiv.org/html/2310.06155v3#bib.bib25)；Salemi等人，[2023](https://arxiv.org/html/2310.06155v3#bib.bib64)）为未来个性化研究共创系统的设计提供了可行的途径。后续设计必须强调适应性，以确保系统的输出与个别研究者的背景、进展和具体研究目标相一致。
- en: 8.2\. Design Implications
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2\. 设计意义
- en: 8.2.1\. Explaining LLM Rationales Through Mind-Map-Styled Design
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.1\. 通过思维导图样式的设计解释大语言模型（LLM）的推理
- en: Besides harnessing the text generation capability of LLMs, our study also highlighted
    the importance of utilizing the Chain-of-Thoughts prompting ability to not only
    improve LLMs’ task-specific performance (Wei et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib77)),
    but also as a way to enhance the explainability of AI-based systems and bridge
    the gap for users to understand the rationale of AI. Prior research has explored
    using mind-map-like design (Kang et al., [2021](https://arxiv.org/html/2310.06155v3#bib.bib31))
    to support users’ creative ideation process. Our CoQuest system explored another
    viable design of using mind-map-styled visualization to facilitate a natural communication
    of LLMs’ chain of thoughts towards humans in addition to the modality of text,
    most importantly through the AI Thoughts feature. It was also noted that some
    participants encountered difficulty interpreting AI rationales even after reading
    the explanation provided through AI Thoughts, as they could not ask for further
    explanations as in common chat-based interfaces. We argue for future designs of
    AI-based co-creation systems to provide explanations of AI rationales interactively
    through graphical designs, such as dynamic exploration features where users can
    prompt for further explanations or ask questions directly within a mind-map-like
    interface.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 除了利用大型语言模型（LLMs）的文本生成能力，我们的研究还强调了利用连锁思维提示能力的重要性，不仅可以提高LLMs在特定任务上的表现（Wei et al.,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib77)），还可以作为增强基于AI系统可解释性的一种方式，帮助用户理解AI背后的推理过程。之前的研究已经探索了使用类似思维导图的设计（Kang
    et al., [2021](https://arxiv.org/html/2310.06155v3#bib.bib31)）来支持用户的创意思维过程。我们的CoQuest系统探索了另一种可行的设计，采用思维导图风格的可视化，除了文本模式外，还能自然地传达LLMs的思维链条，最重要的是通过AI思维功能。还注意到，一些参与者即使在阅读了通过AI思维提供的解释后，仍然难以理解AI的推理过程，因为他们无法像在常见的聊天界面中那样请求进一步的解释。我们提倡未来的AI共创系统设计应该通过图形设计的交互方式提供AI推理的解释，例如动态探索功能，让用户可以提示进一步的解释或在类似思维导图的界面中直接提问。
- en: '8.2.2\. Sharing of Expertise: Steering the Direction of Outputs by Injecting
    Meta-Research Knowledge'
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.2\. 专业知识的分享：通过注入元研究知识引导输出方向
- en: The CoQuest can not only be used for co-creation, but also for educational purposes
    that transfer knowledge about meta-research practices among researchers of different
    levels of experience. During our user study, we observed that while some researchers
    focused on the novel elements AI provided in newly generated RQs in a brainstorming
    manner, researchers with more experience tended to explicitly indicate their needs
    for AI to generate results from a more “technical” perspective, such as providing
    ideas related to evaluation metrics or surveying existing works regarding certain
    research methodology. Although users often have different specific topics of interest
    during RQ co-creation, the higher-level research thinking and skills, as discussed
    in existing meta-research works (Weissgerber, [2021](https://arxiv.org/html/2310.06155v3#bib.bib78);
    Ioannidis et al., [2015](https://arxiv.org/html/2310.06155v3#bib.bib26); Stevens
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib68)), can be beneficial
    in general when shared across users, especially for novice researchers or researchers
    new to certain fields. Past research has explored designs to facilitate the cultivation
    of new researchers’ research skills, such as storytelling (Schrum and Bogdewiecz,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib65)). New understandings unveiled
    by this study about researchers’ behavior using LLM-enabled co-creation to provide
    novel implications that can pave the way for a more collaborative and educative
    approach in future system designs. Experienced researchers’ interaction with the
    co-creation system can provide pathways from which less experienced researchers
    can learn and benefit. Integrating this understanding, we envision a design where
    the AI serves not just as a tool for co-creation, but also as a mediator in the
    knowledge transfer process between researchers. This integration can potentially
    bridge the gap between research idea formulation across domains by utilizing user-sourced
    expertise of meta-research.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest不仅可以用于共同创作，还可以用于教育目的，将有关元研究实践的知识在不同经验水平的研究人员之间传递。在我们的用户研究中，我们观察到，一些研究人员在头脑风暴中专注于AI在新生成的研究问题（RQ）中提供的新颖元素，而经验较丰富的研究人员则倾向于从更“技术性”的角度明确指出他们希望AI生成的结果，例如提供与评估指标相关的想法或调查关于某些研究方法论的现有工作。尽管用户在研究问题共同创作过程中通常有不同的具体兴趣话题，但如现有元研究工作中讨论的那样（Weissgerber，[2021](https://arxiv.org/html/2310.06155v3#bib.bib78);
    Ioannidis et al.，[2015](https://arxiv.org/html/2310.06155v3#bib.bib26); Stevens
    et al.，[2023](https://arxiv.org/html/2310.06155v3#bib.bib68)），更高层次的研究思维和技能在用户之间共享时通常是有益的，特别是对于新手研究人员或对某些领域不熟悉的研究人员。过去的研究探讨了促进新研究人员研究技能培养的设计，如讲故事（Schrum和Bogdewiecz，[2022](https://arxiv.org/html/2310.06155v3#bib.bib65)）。本研究揭示的关于研究人员使用LLM支持的共同创作行为的新理解，提供了新颖的启示，可以为未来系统设计中的更协作和教育化方法铺平道路。经验丰富的研究人员与共同创作系统的互动可以为经验较少的研究人员提供学习和受益的途径。结合这一理解，我们设想一种设计，其中AI不仅作为共同创作的工具，还作为研究人员之间知识传递过程的媒介。这一整合有可能通过利用用户提供的元研究专业知识，弥合跨领域研究问题构思之间的差距。
- en: 8.2.3\. Utilizing Personalized Design to Harness “Surprising” Outputs
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.3. 利用个性化设计来发挥“意外”输出的作用
- en: Hallucination is a well-recognized challenge in many task-oriented LLM system
    designs (Singhal et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib67);
    Li et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib39); McKenna et al.,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib48)). Previous HCI studies suggest
    that while users might sometimes view unexpected outputs favorably (Epstein et al.,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib16)), they can also find them
    unhelpful at times (Lee et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib37)).
    Our findings echo these observations. While certain users viewed AI’s topic drift-off
    unfavorably, others appreciated the fresh content introduced by the AI. This points
    to a subjective user preference. Additionally, our findings in RQ3 reflected that
    users’ background influences their expectations for outputs generated by AI. Thus,
    we argue that in the future design of human-AI co-creation systems, the decision
    to allow models to introduce potentially out-of-context content (often labeled
    as “hallucination”) should be seen as a design choice rather than a blanket problem.
    Furthermore, user backgrounds, such as domain familiarity, should be taken into
    account as they could influence the optimal design options. Future designs might
    consider how to detect users’ different intents via their feedback. One possible
    approach could be to utilize implicit preference probing, where the system actively
    gauges the user’s reaction to certain outputs and adjusts its responses accordingly.
    For instance, if a user consistently displays positive engagement with unexpected
    outputs, the AI could be more inclined to provide similarly “out-of-context” suggestions
    in future responses. Similar designs can also be applied to identify which stage
    of the research or creative process a user is in, so that the AI can tailor its
    responses.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉是许多面向任务的LLM系统设计中一个广为人知的挑战（Singhal et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib67);
    Li et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib39); McKenna et al.,
    [2023](https://arxiv.org/html/2310.06155v3#bib.bib48)）。之前的HCI研究表明，尽管用户有时会对意外输出持积极态度（Epstein
    et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib16)），但他们也会在某些情况下觉得这些输出没有帮助（Lee
    et al., [2022](https://arxiv.org/html/2310.06155v3#bib.bib37)）。我们的研究结果与这些观察一致。尽管某些用户对AI的主题偏离表示不满，但其他人却欣赏AI所带来的新鲜内容。这表明了用户的主观偏好。此外，我们在RQ3中的发现表明，用户的背景影响他们对AI生成的输出的期望。因此，我们认为，在未来的人工智能协作系统设计中，是否允许模型引入潜在的脱离上下文的内容（通常被标记为“幻觉”）应该视为一种设计选择，而非普遍性的问题。此外，用户背景，如领域熟悉度，应考虑在内，因为这些因素可能会影响最优的设计选项。未来的设计可以考虑如何通过用户的反馈来检测不同的意图。一种可能的方法是使用隐性偏好探测，即系统主动评估用户对某些输出的反应，并相应调整其回应。例如，如果用户始终对意外输出表现出积极反应，AI可能会在未来的回答中更倾向于提供类似的“脱离上下文”的建议。类似的设计还可以应用于识别用户处于研究或创作过程的哪个阶段，以便AI能够量身定制其回应。
- en: 8.3\. Ethical Concerns and Potential Biases
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3\. 伦理问题与潜在偏见
- en: '8.3.1\. Ethical Implications of LLM Usage: Plagiarism and Hallucination'
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.3.1\. 大型语言模型使用的伦理影响：抄袭与幻觉
- en: The use of LLMs in research idea co-creation processes can lead to potential
    ethical concerns, e.g., risks of plagiarism and hallucination. LLMs generate content
    based on their vast training data, which raises concerns about the originality
    of their outputs. When asked about their concerns over the CoQuest system, several
    participants raised their concerns about the originality of ideas generated by
    the LLM-based backend. The possibility that an LLM might inadvertently replicate
    existing content without proper attribution, even when they are not directly copying
    content from the training corpus, poses a significant challenge to the integrity
    of research and creative processes (Gingerich and Sullivan, [2013](https://arxiv.org/html/2310.06155v3#bib.bib20)).
    This is particularly relevant in academic contexts where the originality of ideas
    and proper citation are at core (Orenstrakh et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib54)).
    Additionally, LLMs are known to suffer from the issue of hallucination (Zhang
    et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib90); Rawte et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib61)).
    This characteristic of LLMs can mislead users, especially those who might be new
    to a research domain. Reliance on hallucinated content could lead to erroneous
    conclusions or decisions especially during the earlier stages of a research lifecycle.
    To mitigate these risks from the perspective of designing LLM-based co-creation
    systems for scientific research, it is essential to verify the credibility of
    LLM-generated content and apply methods to ensure proper attribution of scientific
    ideas from other researchers. This may be achieved through methods like fact-checking
    (Manakul et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib47)), grounding
    LLM-generated content within credible sources (Yue et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib89)),
    and developing understanding among users to recognize potential flaws in LLM-generated
    content. Addressing these ethical concerns is crucial for maintaining the integrity
    and reliability of LLM-based human-AI co-creation, particularly in fields where
    intellectual property rights are highly valued.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究创意共创过程中使用大型语言模型（LLMs）可能引发潜在的伦理问题，例如剽窃和虚构的风险。LLMs根据其庞大的训练数据生成内容，这引发了对其输出原创性的担忧。当被询问关于CoQuest系统的担忧时，几位参与者提出了他们对LLM基础后台生成创意原创性的担忧。LLM可能在没有恰当归属的情况下，不经意地复制现有内容的可能性，即使它们并未直接从训练语料库中复制内容，这对研究和创意过程的完整性构成了重大挑战（Gingerich
    和 Sullivan，[2013](https://arxiv.org/html/2310.06155v3#bib.bib20)）。这一问题在学术领域尤为相关，因为在这些领域，创意的原创性和恰当的引用是核心（Orenstrakh
    等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib54)）。此外，LLMs已知存在虚构问题（Zhang
    等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib90)；Rawte 等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib61)）。LLMs的这一特点可能会误导用户，尤其是那些对某一研究领域不太熟悉的用户。依赖虚构内容可能导致错误的结论或决策，特别是在研究生命周期的早期阶段。为了从设计基于LLM的科学研究共创系统的角度减轻这些风险，验证LLM生成内容的可信度，并采取措施确保适当归属其他研究者的科学创意是至关重要的。这可以通过如事实核查（Manakul
    等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib47)）、将LLM生成的内容与可信来源进行对接（Yue
    等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib89)），以及培养用户识别LLM生成内容潜在缺陷的能力来实现。解决这些伦理问题对于保持基于LLM的人机共创的完整性和可靠性至关重要，尤其是在知识产权高度重视的领域。
- en: 8.3.2\. User biases and blind spots
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.3.2\. 用户偏见与盲点
- en: In our study, we found that users’ expertise influenced their sense of control
    when co-creating with AI. Specifically, users felt less control and lower cognitive
    demand when working on familiar topics. Interviews with participants revealed
    that they had taken cognitive shortcuts by having intrinsic expectations about
    the generated outcomes. Their sense of control also decreased when these expectations
    were not met, indicating the presence of confirmation biases. This aligns with
    the growing research on understanding cognitive biases in human-AI interactions
    (Boonprakong et al., [2023b](https://arxiv.org/html/2310.06155v3#bib.bib6), [a](https://arxiv.org/html/2310.06155v3#bib.bib5);
    Wang et al., [2019](https://arxiv.org/html/2310.06155v3#bib.bib73); Chen et al.,
    [2022](https://arxiv.org/html/2310.06155v3#bib.bib9)). Our research further highlights
    the impact of confirmation biases on users’ perceived control in human-AI co-creation
    tasks. Moreover, our research suggests that these biases can operate through the
    lens of human expertise, potentially creating blind spots. Future research should
    explore diverse strategies for mitigating bias in co-creation with AI, such as
    drawing from crowd-sourced ideas, as demonstrated in Yen et al. ([2023](https://arxiv.org/html/2310.06155v3#bib.bib87))’s
    work.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们发现用户的专业知识影响了他们在与人工智能共同创作时的控制感。具体来说，当在熟悉的主题上工作时，用户感觉到较少的控制感和较低的认知需求。与参与者的访谈揭示，他们通过对生成结果有内在预期来采取了认知捷径。当这些预期未能实现时，他们的控制感也有所下降，表明存在确认偏误。这与日益增长的关于理解人机交互中认知偏误的研究一致（Boonprakong等，[2023b](https://arxiv.org/html/2310.06155v3#bib.bib6)，[a](https://arxiv.org/html/2310.06155v3#bib.bib5)；Wang等，[2019](https://arxiv.org/html/2310.06155v3#bib.bib73)；Chen等，[2022](https://arxiv.org/html/2310.06155v3#bib.bib9)）。我们的研究进一步突出了确认偏误在人机共同创作任务中对用户感知控制的影响。此外，我们的研究表明，这些偏误可能通过人类专业知识的视角运作，进而产生盲点。未来的研究应探索缓解与人工智能共同创作中偏误的多种策略，如借鉴来自群众智慧的创意，正如Yen等人（[2023](https://arxiv.org/html/2310.06155v3#bib.bib87)）的研究所示。
- en: 8.3.3\. Over-reliance on AI
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.3.3. 对人工智能的过度依赖
- en: Another ethical concern with our system is users blindly accepting AI-generated
    outcomes or relying too heavily on them, as pointed out by Buçinca et al. ([2021](https://arxiv.org/html/2310.06155v3#bib.bib7)).
    To address this, we implemented two effective approaches in our design. First,
    we introduced an RQ rating during the generation process to encourage users to
    evaluate AI-generated content. Second, we incorporated AI thoughts to assist users
    in understanding the literature space and the generation process. Users frequently
    utilized AI thoughts during wait times, which enhanced their perceived control
    in co-creation. These two strategies, utilizing metrics to promote human active
    evaluation of AI-generated content and providing explanations to enhance human
    understanding of the AI-generation process, offer valuable insights for those
    seeking to mitigate bias in human-AI collaboration. Our work builds upon prior
    research (Vasconcelos et al., [2023](https://arxiv.org/html/2310.06155v3#bib.bib71))
    by providing options for users to check for explanations in order to reduce AI
    over-reliance.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们系统的另一个伦理问题是用户盲目接受人工智能生成的结果或过度依赖这些结果，正如Buçinca等人（[2021](https://arxiv.org/html/2310.06155v3#bib.bib7)）所指出的。为了解决这个问题，我们在设计中实施了两种有效的措施。首先，我们在生成过程中引入了RQ评分，以鼓励用户评估人工智能生成的内容。其次，我们融入了人工智能思考，帮助用户理解文献空间和生成过程。用户在等待期间经常利用人工智能思考，这增强了他们在共同创作中的控制感。这两种策略，利用度量标准促进人类对人工智能生成内容的主动评估，并提供解释以增强人类对人工智能生成过程的理解，为那些希望减少人工智能过度依赖的用户提供了宝贵的见解。我们的工作在先前研究（Vasconcelos等，[2023](https://arxiv.org/html/2310.06155v3#bib.bib71)）的基础上，通过为用户提供查看解释的选项来减少人工智能过度依赖。
- en: Nonetheless, our study did not provide empirical understanding of the longer-term
    impact of using an LLM-based RQ co-creation system. Prior research (Loi et al.,
    [2020](https://arxiv.org/html/2310.06155v3#bib.bib45)) has pointed out that certain
    designs in current AI systems could hinder human creativity development in the
    long term. We argue that further studies should be conducted to understand both
    the positive and negative impacts of human-AI co-creation systems for research
    ideation longitudinally over human researchers regarding aspects such as creativity,
    research preferences, and behaviors during ideation. Future research should also
    explore more ways of explaining AI outputs and designs to promote active human
    thinking and advance the understanding of the role of explanations in research
    and learning.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的研究并未提供关于使用基于LLM的RQ共创系统的长期影响的实证理解。先前的研究（Loi et al., [2020](https://arxiv.org/html/2310.06155v3#bib.bib45)）指出，当前AI系统中的某些设计可能会在长期内妨碍人类创造力的发展。我们认为，应该开展进一步的研究，纵向了解人类与AI共创系统对研究创意过程的正面和负面影响，涉及创造力、研究偏好以及创意生成过程中行为等方面。未来的研究还应探索更多解释AI输出和设计的方式，以促进主动的人类思维，并推进对解释在研究与学习中的作用的理解。
- en: 9\. Limitations and Future Work
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 局限性与未来工作
- en: We acknowledge that our study has several limitations. First, our system currently
    relies on a fixed and relatively limited set of publications as its source pool.
    This design limitation often results in users finding themselves constrained to
    a narrow segment of literature after a few iterations of RQ generation. Ideally,
    the system should be integrated with online publications databases to harness
    a broader and continuously updated spectrum of publications. Trust in the system
    also emerged as a concern. Some users hesitated to utilize the generated RQs directly
    with concern about their originality and fearing potential overlaps with pre-existing
    research. Addressing these concerns is crucial for enhancing user confidence and
    the overall effectiveness of the system. Furthermore, the time constraints imposed
    on the tasks might not have been optimal for all participants. Those less familiar
    with the task might require more time before they get acquainted with the research
    space and can effectively generate RQs. This “warm-up” period could be considered
    more thoughtfully in future studies. Additionally, we acknowledge the limitation
    in our analysis related to user behavior beyond wait times. Our system did not
    precisely record the completion times for each RQ generated. Due to the extensive
    duration and the complexity of behaviors in these periods, these activities were
    not systematically coded and analyzed, which may have omitted valuable insights
    into user interaction with the system. Moreover, our evaluation focused solely
    on doctoral students who, while having some research background, are still in
    the early stages of their research careers. The results might differ when evaluating
    seasoned researchers or even undergraduates. Expanding the participant pool in
    future studies can offer a more comprehensive understanding of the system’s effectiveness
    and user experience across varying expertise levels. Future work should also study
    the longitudinal effect of the CoQuest system usage over human researchers.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们承认我们的研究存在一些局限性。首先，我们的系统目前依赖于一个固定且相对有限的出版物集合作为其来源池。这种设计局限性常常导致用户在进行几轮RQ生成后，发现自己只能局限于一小部分文献。理想情况下，系统应该与在线出版物数据库集成，以便利用更广泛并持续更新的出版物资源。此外，系统的信任度也成为了一个问题。一些用户对直接使用生成的RQ感到犹豫，担心其原创性，并且害怕与已有研究存在重叠。解决这些问题对增强用户信心和系统的整体效果至关重要。此外，任务所施加的时间限制可能对所有参与者而言并不理想。那些不太熟悉任务的用户可能需要更多时间才能适应研究领域，并能有效地生成RQ。未来的研究可以更为周全地考虑这一“热身”阶段。我们还承认，在与用户行为相关的分析中，除了等待时间之外存在局限性。我们的系统并未精确记录每个RQ生成的完成时间。由于这些时间段内的活动时长较长且行为复杂，因此这些活动未能被系统地编码和分析，这可能遗漏了关于用户与系统互动的宝贵见解。此外，我们的评估仅集中在博士生身上，尽管他们有一定的研究背景，但仍处于研究生涯的初期阶段。评估经验丰富的研究人员或甚至本科生时，结果可能会有所不同。未来研究可以通过扩大参与者范围，提供更全面的关于系统效果和用户体验的理解，涵盖不同专业水平的受众。未来的工作还应研究CoQuest系统在科研人员身上的长期使用效果。
- en: 10\. Conclusion
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 结论
- en: 'In this study, we introduced an agent LLM system, called CoQuest, aiming to
    support the creation of research questions. Through a formative study with actual
    researchers, we proposed a mental model combining the process of literature discovery
    and research ideation and applied it to the design of the CoQuest system. We introduced
    two interaction design options for CoQuest: breadth-first and depth-first generations,
    diversifying the degree of AI’s initiative during co-creation. A within-subjective
    study with 20 participants revealed that a higher degree of AI initiative led
    to co-creation outcomes with enhanced creativity, albeit at the expense of the
    overall co-creation experience. We also found that users who effectively utilized
    wait time experienced higher-quality outcomes and developed a stronger sense of
    control.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们介绍了一种名为CoQuest的代理LLM系统，旨在支持研究问题的创建。通过与实际研究人员的形成性研究，我们提出了一种结合文献发现和研究构思过程的心理模型，并将其应用于CoQuest系统的设计。我们为CoQuest引入了两种交互设计选项：广度优先和深度优先生成，旨在多样化人工智能在共同创作中的主动程度。通过对20名参与者的内部主观研究，我们发现较高的人工智能主动性会导致创作结果的创造力增强，尽管整体的共同创作体验有所牺牲。我们还发现，能够有效利用等待时间的用户在创作结果上体验到了更高的质量，并且获得了更强的控制感。
- en: Acknowledgements.
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: This material is based upon work supported by the National Science Foundation
    under Grant No. 2119589\. Any opinions, findings, and conclusions or recommendations
    expressed in this material are those of the author(s) and do not necessarily reflect
    the views of the National Science Foundation. Additionally, results presented
    in this paper were obtained using CloudBank (Norman et al., [2021](https://arxiv.org/html/2310.06155v3#bib.bib51)),
    which is supported by the National Science Foundation under award No. 1925001.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 本材料基于国家科学基金会资助的工作，资助编号为2119589。文中表达的任何观点、发现、结论或建议均为作者（们）的意见，不一定反映国家科学基金会的观点。此外，本文中呈现的结果是通过使用CloudBank（Norman
    et al., [2021](https://arxiv.org/html/2310.06155v3#bib.bib51)）获得的，该平台得到了国家科学基金会资助，奖项编号为1925001。
- en: References
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Benardou et al. (2010) Agiatis Benardou, Panos Constantopoulos, Costis Dallas,
    and Dimitris Gavrilis. 2010. A conceptual model for scholarly research activity.
    (2010).
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Benardou et al. (2010) Agiatis Benardou, Panos Constantopoulos, Costis Dallas,
    和 Dimitris Gavrilis. 2010. 学术研究活动的概念模型。（2010年）。
- en: 'Bilgram and Laarmann (2023) Volker Bilgram and Felix Laarmann. 2023. Accelerating
    Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation
    Methods. *IEEE Engineering Management Review* 51 (2023), 18–25.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bilgram 和 Laarmann (2023) Volker Bilgram 和 Felix Laarmann. 2023. 利用生成性人工智能加速创新：AI增强的数字原型制作与创新方法。*IEEE工程管理评论*
    51（2023），18–25。
- en: 'Boden (2004) Margaret A Boden. 2004. *The creative mind: Myths and mechanisms*.
    Psychology Press.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boden (2004) Margaret A Boden. 2004. *创造性思维：神话与机制*。心理学出版社。
- en: 'Boonprakong et al. (2023a) Nattapat Boonprakong, Xiuge Chen, Catherine Davey,
    Benjamin Tag, and Tilman Dingler. 2023a. Bias-Aware Systems: Exploring Indicators
    for the Occurrences of Cognitive Biases when Facing Different Opinions. In *Proceedings
    of the 2023 CHI Conference on Human Factors in Computing Systems*. 1–19.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boonprakong et al. (2023a) Nattapat Boonprakong, Xiuge Chen, Catherine Davey,
    Benjamin Tag, 和 Tilman Dingler. 2023a. 偏见感知系统：探索在面对不同观点时认知偏差发生的指示器。收录于*2023年CHI人类因素计算系统会议论文集*。1–19。
- en: Boonprakong et al. (2023b) Nattapat Boonprakong, Gaole He, Ujwal Gadiraju, Niels
    van Berkel, Danding Wang, Si Chen, Jiqun Liu, Benjamin Tag, Jorge Goncalves, and
    Tilman Dingler. 2023b. Workshop on Understanding and Mitigating Cognitive Biases
    in Human-AI Collaboration. (2023).
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boonprakong et al. (2023b) Nattapat Boonprakong, Gaole He, Ujwal Gadiraju, Niels
    van Berkel, Danding Wang, Si Chen, Jiqun Liu, Benjamin Tag, Jorge Goncalves, 和
    Tilman Dingler. 2023b. 关于理解和减缓人类与人工智能协作中的认知偏差的研讨会。（2023年）。
- en: 'Buçinca et al. (2021) Zana Buçinca, Maja Barbara Malaya, and Krzysztof Z Gajos.
    2021. To trust or to think: cognitive forcing functions can reduce overreliance
    on AI in AI-assisted decision-making. *Proceedings of the ACM on Human-Computer
    Interaction* 5, CSCW1 (2021), 1–21.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Buçinca et al. (2021) Zana Buçinca, Maja Barbara Malaya, 和 Krzysztof Z Gajos.
    2021. 信任还是思考：认知强制功能可以减少AI辅助决策中对AI的过度依赖。*ACM人机交互会议录* 5, CSCW1（2021），1–21。
- en: Carbonell and Goldstein (1998) Jaime Carbonell and Jade Goldstein. 1998. The
    use of MMR, diversity-based reranking for reordering documents and producing summaries.
    In *Proceedings of the 21st annual international ACM SIGIR conference on Research
    and development in information retrieval*. 335–336.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carbonell 和 Goldstein (1998) Jaime Carbonell 和 Jade Goldstein. 1998. 使用基于多样性的
    MM R 排序方法重新排序文档并生成摘要。在 *第21届国际 ACM SIGIR 信息检索研究与开发年会论文集* 中，335–336。
- en: Chen et al. (2022) Si Chen, Yixin Liu, Risheng Lu, Yuqian Zhou, Yi-Chieh Lee,
    and Yun Huang. 2022. ”Mirror, Mirror, on the Wall” - Promoting Self-Regulated
    Learning Using Affective States Recognition via Facial Movements. In *Proceedings
    of the 2022 ACM Designing Interactive Systems Conference* (Virtual Event, Australia)
    *(DIS ’22)*. Association for Computing Machinery, New York, NY, USA, 1300–1314.
    [https://doi.org/10.1145/3532106.3533500](https://doi.org/10.1145/3532106.3533500)
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等人 (2022) Si Chen, Yixin Liu, Risheng Lu, Yuqian Zhou, Yi-Chieh Lee, 和
    Yun Huang. 2022. “镜子，镜子，墙上的镜子” - 通过面部运动促进情感状态识别的自我调节学习。在 *2022年 ACM 设计互动系统会议论文集*
    (虚拟活动，澳大利亚) *(DIS ’22)* 中。美国计算机协会，纽约，纽约州，美国，1300–1314。[https://doi.org/10.1145/3532106.3533500](https://doi.org/10.1145/3532106.3533500)
- en: Consensus (2023) Consensus. 2023. Consensus. [https://consensus.app/](https://consensus.app/)
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Consensus (2023) Consensus. 2023. Consensus. [https://consensus.app/](https://consensus.app/)
- en: Dang et al. (2022) Hai Dang, Lukas Mecke, Florian Lehmann, Sven Goller, and
    Daniel Buschek. 2022. How to prompt? Opportunities and challenges of zero-and
    few-shot learning for human-AI interaction in creative applications of generative
    models. *arXiv preprint arXiv:2209.01390* (2022).
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dang 等人 (2022) Hai Dang, Lukas Mecke, Florian Lehmann, Sven Goller, 和 Daniel
    Buschek. 2022. 如何进行提示？零样本和少样本学习在人类与 AI 交互中的机会与挑战，尤其是在生成模型的创意应用中。*arXiv 预印本 arXiv:2209.01390*
    (2022)。
- en: Davis et al. (2015) Nicholas Davis, Chih-Pin Hsiao, Yanna Popova, and Brian
    Magerko. 2015. An enactive model of creativity for computational collaboration
    and co-creation. *Creativity in the digital age* (2015), 109–133.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davis 等人 (2015) Nicholas Davis, Chih-Pin Hsiao, Yanna Popova, 和 Brian Magerko.
    2015. 用于计算协作与共同创作的行动模型。*数字时代的创造力* (2015), 109–133。
- en: 'Dettmers and Zettlemoyer (2023) Tim Dettmers and Luke Zettlemoyer. 2023. The
    case for 4-bit precision: k-bit inference scaling laws. In *International Conference
    on Machine Learning*. PMLR, 7750–7774.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dettmers 和 Zettlemoyer (2023) Tim Dettmers 和 Luke Zettlemoyer. 2023. 4位精度的理由：k位推理扩展法则。在
    *国际机器学习会议* 上。PMLR, 7750–7774。
- en: Elio et al. (2011) Renee Elio, Jim Hoover, Ioanis Nikolaidis, Mohammad Salavatipour,
    Lorna Stewart, and Ken Wong. 2011. About computing science research methodology.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elio 等人 (2011) Renee Elio, Jim Hoover, Ioanis Nikolaidis, Mohammad Salavatipour,
    Lorna Stewart, 和 Ken Wong. 2011. 关于计算机科学研究方法论。
- en: Epstein et al. (2023) Ziv Epstein, Aaron Hertzmann, Laura Mariah Herman, Robert
    Mahari, Morgan R. Frank, Matthew Groh, Hope Schroeder, Amy Smith, Memo Akten,
    Jessica Fjeld, Hany Farid, Neil Leach, Alex Pentland, and Olga Russakovsky. 2023.
    Art and the science of generative AI. *Science* 380 (2023), 1110 – 1111.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Epstein 等人 (2023) Ziv Epstein, Aaron Hertzmann, Laura Mariah Herman, Robert
    Mahari, Morgan R. Frank, Matthew Groh, Hope Schroeder, Amy Smith, Memo Akten,
    Jessica Fjeld, Hany Farid, Neil Leach, Alex Pentland, 和 Olga Russakovsky. 2023.
    艺术与生成 AI 的科学。*科学* 380 (2023), 1110 – 1111。
- en: 'Epstein et al. (2022) Ziv Epstein, Hope Schroeder, and Dava Newman. 2022. When
    happy accidents spark creativity: Bringing collaborative speculation to life with
    generative AI. In *International Conference on Innovative Computing and Cloud
    Computing*.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Epstein 等人 (2022) Ziv Epstein, Hope Schroeder, 和 Dava Newman. 2022. 当意外的幸福激发创意：通过生成
    AI 实现协作性推测的生命力。在 *国际创新计算与云计算会议* 上。
- en: 'Faul et al. (2007) Franz Faul, Edgar Erdfelder, Albert-Georg Lang, and Axel
    Buchner. 2007. G* Power 3: A flexible statistical power analysis program for the
    social, behavioral, and biomedical sciences. *Behavior research methods* 39, 2
    (2007), 175–191.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Faul 等人 (2007) Franz Faul, Edgar Erdfelder, Albert-Georg Lang, 和 Axel Buchner.
    2007. G* Power 3: 一款灵活的统计功效分析程序，适用于社会、行为和生物医学科学。*行为研究方法* 39, 2 (2007), 175–191。'
- en: 'Fishkin (2023) Rand Fishkin. 2023. We Analyzed Millions of ChatGPT User Sessions:
    Visits are Down 29% since May, Programming Assistance is 30% of Use. [https://sparktoro.com/blog/we-analyzed-millions-of-chatgpt-user-sessions-visits-are-down-29-since-may-programming-assistance-is-30-of-use/](https://sparktoro.com/blog/we-analyzed-millions-of-chatgpt-user-sessions-visits-are-down-29-since-may-programming-assistance-is-30-of-use/)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fishkin (2023) Rand Fishkin. 2023. 我们分析了数百万次 ChatGPT 用户会话：自5月以来访问量下降了29%，编程辅助占使用的30%。[https://sparktoro.com/blog/we-analyzed-millions-of-chatgpt-user-sessions-visits-are-down-29-since-may-programming-assistance-is-30-of-use/](https://sparktoro.com/blog/we-analyzed-millions-of-chatgpt-user-sessions-visits-are-down-29-since-may-programming-assistance-is-30-of-use/)
- en: Foster (2004) Allen Foster. 2004. A nonlinear model of information-seeking behavior.
    *Journal of the American society for information science and technology* 55, 3
    (2004), 228–237.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Foster (2004) Allen Foster. 2004. 信息检索行为的非线性模型。*《美国信息科学与技术学会杂志》* 55, 3 (2004)，228–237。
- en: 'Gingerich and Sullivan (2013) Amanda C Gingerich and Meaghan C Sullivan. 2013.
    Claiming hidden memories as one’s own: A review of inadvertent plagiarism. *Journal
    of Cognitive Psychology* 25, 8 (2013), 903–916.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gingerich and Sullivan (2013) Amanda C Gingerich 和 Meaghan C Sullivan. 2013.
    声称隐藏记忆为自己的：无意抄袭的回顾。*《认知心理学杂志》* 25, 8 (2013)，903–916。
- en: Glueck and Jauch (1975) William F. Glueck and Lawrence R. Jauch. 1975. Sources
    of Research Ideas Among Productive Scholars. Implications for Administrators.
    *The Journal of Higher Education* 46 (1975), 103–114.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Glueck and Jauch (1975) William F. Glueck 和 Lawrence R. Jauch. 1975. 富有成效的学者研究思路的来源：对管理员的启示。*《高等教育期刊》*
    46 (1975)，103–114。
- en: Guo and Laidlaw (2020) Hua Guo and David H. Laidlaw. 2020. Topic-Based Exploration
    and Embedded Visualizations for Research Idea Generation. *IEEE Transactions on
    Visualization and Computer Graphics* 26 (2020), 1592–1607.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo and Laidlaw (2020) Hua Guo 和 David H. Laidlaw. 2020. 基于主题的探索和嵌入式可视化在研究思路生成中的应用。*《IEEE可视化与计算机图形学汇刊》*
    26 (2020)，1592–1607。
- en: 'Guzdial et al. (2019) Matthew Guzdial, Nicholas Liao, Jonathan Chen, Shao-Yu
    Chen, Shukan Shah, Vishwa Shah, Joshua Reno, Gillian Smith, and Mark O Riedl.
    2019. Friend, collaborator, student, manager: How design of an ai-driven game
    level editor affects creators. In *Proceedings of the 2019 CHI conference on human
    factors in computing systems*. 1–13.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guzdial et al. (2019) Matthew Guzdial, Nicholas Liao, Jonathan Chen, Shao-Yu
    Chen, Shukan Shah, Vishwa Shah, Joshua Reno, Gillian Smith, 和 Mark O Riedl. 2019.
    朋友、合作者、学生、经理：AI驱动的游戏关卡编辑器设计如何影响创作者。见于*《2019 CHI会议论文集：计算机系统中的人类因素》*，1–13。
- en: Horvitz (1999) Eric Horvitz. 1999. Principles of mixed-initiative user interfaces.
    In *Proceedings of the SIGCHI conference on Human Factors in Computing Systems*.
    159–166.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Horvitz (1999) Eric Horvitz. 1999. 混合主动式用户界面原理。见于*《SIGCHI会议论文集：计算机系统中的人类因素》*，159–166。
- en: Hwang et al. (2023) EunJeong Hwang, Bodhisattwa Prasad Majumder, and Niket Tandon.
    2023. Aligning Language Models to User Opinions. *arXiv preprint arXiv:2305.14929*
    (2023).
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hwang et al. (2023) EunJeong Hwang, Bodhisattwa Prasad Majumder, 和 Niket Tandon.
    2023. 使语言模型与用户意见对齐。*arXiv预印本 arXiv:2305.14929* (2023)。
- en: 'Ioannidis et al. (2015) John PA Ioannidis, Daniele Fanelli, Debbie Drake Dunne,
    and Steven N Goodman. 2015. Meta-research: evaluation and improvement of research
    methods and practices. *PLoS biology* 13, 10 (2015), e1002264.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioannidis et al. (2015) John PA Ioannidis, Daniele Fanelli, Debbie Drake Dunne,
    和 Steven N Goodman. 2015. 元研究：评估和改进研究方法和实践。*《PLoS 生物学》* 13, 10 (2015)，e1002264。
- en: James et al. (2013) Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani,
    et al. 2013. *An introduction to statistical learning*. Vol. 112. Springer.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: James et al. (2013) Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani
    等. 2013. *统计学习导论*。第112卷。Springer。
- en: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey
    of hallucination in natural language generation. *Comput. Surveys* 55, 12 (2023),
    1–38.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ji et al. (2023) Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan
    Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. 自然语言生成中的幻觉调查。*《计算机调查》*
    55, 12 (2023)，1–38。
- en: Jing et al. (2015) Delin Jing, Hongji Yang, Meiyu Shi, and Wei Zhu. 2015. Developing
    a Research Ideas Creation System through Reusing Knowledge Bases for Ontology
    Construction. *2015 IEEE 39th Annual Computer Software and Applications Conference*
    3 (2015), 175–180.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jing et al. (2015) Delin Jing, Hongji Yang, Meiyu Shi, 和 Wei Zhu. 2015. 通过重用知识库进行本体构建的研究创意生成系统开发。*《2015
    IEEE第39届年度计算机软件与应用会议》* 3 (2015)，175–180。
- en: Kang et al. (2022) Hyeonsu B Kang, Sheshera Mysore, Kevin Huang, Haw-Shiuan
    Chang, Thorben Prein, Andrew McCallum, Aniket Kittur, and Elsa A. Olivetti. 2022.
    Augmenting Scientific Creativity with Retrieval across Knowledge Domains. *ArXiv*
    abs/2206.01328 (2022).
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang et al. (2022) Hyeonsu B Kang, Sheshera Mysore, Kevin Huang, Haw-Shiuan
    Chang, Thorben Prein, Andrew McCallum, Aniket Kittur, and Elsa A. Olivetti. 2022.
    跨知识领域检索增强科学创造力。*《ArXiv》* abs/2206.01328 (2022)。
- en: 'Kang et al. (2021) Youwen Kang, Zhida Sun, Sitong Wang, Zeyu Huang, Ziming
    Wu, and Xiaojuan Ma. 2021. MetaMap: Supporting visual metaphor ideation through
    multi-dimensional example-based exploration. In *Proceedings of the 2021 CHI Conference
    on Human Factors in Computing Systems*. 1–15.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang et al. (2021) Youwen Kang, Zhida Sun, Sitong Wang, Zeyu Huang, Ziming Wu,
    和 Xiaojuan Ma. 2021. MetaMap：通过多维基于示例的探索支持视觉隐喻构思。见于*《2021 CHI会议论文集：计算机系统中的人类因素》*，1–15。
- en: Kantosalo and Jordanous (2021) Anna Kantosalo and Anna Jordanous. 2021. Role-based
    perceptions of computer participants in human-computer co-creativity. AISB.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kantosalo 和 Jordanous (2021) Anna Kantosalo 和 Anna Jordanous. 2021. 基于角色的计算机参与者在人机共创中的感知。AISB。
- en: Khandkar (2009) Shahedul Huq Khandkar. 2009. Open coding. *University of Calgary*
    23, 2009 (2009).
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khandkar (2009) Shahedul Huq Khandkar. 2009. 开放编码。*卡尔加里大学* 23, 2009 (2009)。
- en: Kim and Maher (2023) Jingoog Kim and Mary Lou Maher. 2023. The effect of AI-based
    inspiration on human design ideation. *International Journal of Design Creativity
    and Innovation* 11, 2 (2023), 81–98.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 和 Maher (2023) Jingoog Kim 和 Mary Lou Maher. 2023. 基于 AI 的灵感对人类设计创意的影响。*国际设计创意与创新期刊*
    11, 2 (2023), 81–98。
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners.
    *Advances in neural information processing systems* 35 (2022), 22199–22213.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima 等人 (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo
    和 Yusuke Iwasawa. 2022. 大型语言模型是零-shot 推理器。*神经信息处理系统进展* 35 (2022), 22199–22213。
- en: Kreminski et al. (2022) Max Kreminski, Isaac Karth, Michael Mateas, and Noah
    Wardrip-Fruin. 2022. Evaluating Mixed-Initiative Creative Interfaces via Expressive
    Range Coverage Analysis.. In *IUI Workshops*. 34–45.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kreminski 等人 (2022) Max Kreminski, Isaac Karth, Michael Mateas 和 Noah Wardrip-Fruin.
    2022. 通过表现范围覆盖分析评估混合主动创意界面。发表于 *IUI 研讨会*。34–45。
- en: 'Lee et al. (2022) Mina Lee, Percy Liang, and Qian Yang. 2022. CoAuthor: Designing
    a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities.
    *Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems*
    (2022).'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lee 等人 (2022) Mina Lee, Percy Liang 和 Qian Yang. 2022. CoAuthor: 设计一个人类-AI
    协作写作数据集，以探索语言模型的能力。*2022年人类计算系统会议（CHI会议）* (2022)。'
- en: Leviathan et al. (2023) Yaniv Leviathan, Matan Kalman, and Yossi Matias. 2023.
    Fast inference from transformers via speculative decoding. In *International Conference
    on Machine Learning*. PMLR, 19274–19286.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leviathan 等人 (2023) Yaniv Leviathan, Matan Kalman 和 Yossi Matias. 2023. 通过推测解码从变换器中进行快速推理。发表于
    *国际机器学习大会*。PMLR, 19274–19286。
- en: 'Li et al. (2023) Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jianyun Nie, and
    Ji rong Wen. 2023. HaluEval: A Large-Scale Hallucination Evaluation Benchmark
    for Large Language Models. *ArXiv* abs/2305.11747 (2023).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人 (2023) Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jianyun Nie 和 Ji rong
    Wen. 2023. HaluEval: 大型语言模型的幻觉评估基准。*ArXiv* abs/2305.11747 (2023)。'
- en: 'Lin et al. (2023) Zhiyu Lin, Upol Ehsan, Rohan Agarwal, Samihan Dani, Vidushi
    Vashishth, and Mark Riedl. 2023. Beyond Prompts: Exploring the Design Space of
    Mixed-Initiative Co-Creativity Systems. *arXiv preprint arXiv:2305.07465* (2023).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人 (2023) Zhiyu Lin, Upol Ehsan, Rohan Agarwal, Samihan Dani, Vidushi Vashishth
    和 Mark Riedl. 2023. 超越提示：探索混合主动共创系统的设计空间。*arXiv 预印本 arXiv:2305.07465* (2023)。
- en: Liu and Chilton (2022) Vivian Liu and Lydia B Chilton. 2022. Design guidelines
    for prompt engineering text-to-image generative models. In *Proceedings of the
    2022 CHI Conference on Human Factors in Computing Systems*. 1–23.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 和 Chilton (2022) Vivian Liu 和 Lydia B Chilton. 2022. 提示工程文本到图像生成模型的设计指南。发表于
    *2022年人类计算系统会议（CHI会议）*。1–23。
- en: 'Liu et al. (2023c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Yuxian Gu, Hangliang Ding, Kai Men, Kejuan Yang, Shudan Zhang, Xiang
    Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Shengqi Shen, Tianjun Zhang, Yu
    Su, Huan Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2023c. AgentBench: Evaluating
    LLMs as Agents. *ArXiv* abs/2308.03688 (2023).'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2023c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Yuxian Gu, Hangliang Ding, Kai Men, Kejuan Yang, Shudan Zhang, Xiang
    Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Shengqi Shen, Tianjun Zhang, Yu
    Su, Huan Sun, Minlie Huang, Yuxiao Dong 和 Jie Tang. 2023c. AgentBench: 评估 LLMs
    作为代理。*ArXiv* abs/2308.03688 (2023)。'
- en: Liu et al. (2023b) Yiren Liu, Mengxia Yu, Meng-Long Jiang, and Yun Huang. 2023b.
    Creative Research Question Generation for Human-Computer Interaction Research.
    In *IUI Workshops*.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2023b) Yiren Liu, Mengxia Yu, Meng-Long Jiang 和 Yun Huang. 2023b. 人机交互研究中的创意研究问题生成。发表于
    *IUI 研讨会*。
- en: 'Liu et al. (2023a) Zichang Liu, Jue Wang, Tri Dao, Tianyi Zhou, Binhang Yuan,
    Zhao Song, Anshumali Shrivastava, Ce Zhang, Yuandong Tian, Christopher Re, et al.
    2023a. Deja vu: Contextual sparsity for efficient llms at inference time. In *International
    Conference on Machine Learning*. PMLR, 22137–22176.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等人 (2023a) Zichang Liu, Jue Wang, Tri Dao, Tianyi Zhou, Binhang Yuan, Zhao
    Song, Anshumali Shrivastava, Ce Zhang, Yuandong Tian, Christopher Re 等人. 2023a.
    Déjà vu: 在推理时高效的 LLM 上的上下文稀疏性。发表于 *国际机器学习大会*。PMLR, 22137–22176。'
- en: Loi et al. (2020) Michele Loi, Eleonora Viganò, and Lonneke van der Plas. 2020.
    The societal and ethical relevance of computational creativity. *arXiv preprint
    arXiv:2007.11973* (2020).
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loi等人（2020年）Michele Loi, Eleonora Viganò, 和 Lonneke van der Plas。2020年。《计算创造力的社会和伦理相关性》。*arXiv预印本
    arXiv:2007.11973*（2020年）。
- en: Louie et al. (2020) Ryan Louie, Andy Coenen, Cheng Zhi Huang, Michael Terry,
    and Carrie J Cai. 2020. Novice-AI music co-creation via AI-steering tools for
    deep generative models. In *Proceedings of the 2020 CHI conference on human factors
    in computing systems*. 1–13.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Louie等人（2020年）Ryan Louie, Andy Coenen, Cheng Zhi Huang, Michael Terry, 和 Carrie
    J Cai。2020年。《通过深度生成模型的AI引导工具进行新手AI音乐共创》。载于*《2020年CHI人机交互会议论文集》*。1–13。
- en: 'Manakul et al. (2023) Potsawee Manakul, Adian Liusie, and Mark JF Gales. 2023.
    Selfcheckgpt: Zero-resource black-box hallucination detection for generative large
    language models. *arXiv preprint arXiv:2303.08896* (2023).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Manakul等人（2023年）Potsawee Manakul, Adian Liusie, 和 Mark JF Gales。2023年。《Selfcheckgpt：针对生成式大型语言模型的零资源黑箱幻觉检测》。*arXiv预印本
    arXiv:2303.08896*（2023年）。
- en: McKenna et al. (2023) Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini,
    Mark Johnson, and Mark Steedman. 2023. Sources of Hallucination by Large Language
    Models on Inference Tasks. *ArXiv* abs/2305.14552 (2023).
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McKenna等人（2023年）Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini,
    Mark Johnson, 和 Mark Steedman。2023年。《大型语言模型在推理任务中产生幻觉的来源》。*arXiv* abs/2305.14552（2023年）。
- en: 'Mirowski et al. (2023) Piotr Mirowski, Kory W Mathewson, Jaylen Pittman, and
    Richard Evans. 2023. Co-Writing Screenplays and Theatre Scripts with Language
    Models: Evaluation by Industry Professionals. In *Proceedings of the 2023 CHI
    Conference on Human Factors in Computing Systems*. 1–34.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mirowski等人（2023年）Piotr Mirowski, Kory W Mathewson, Jaylen Pittman, 和 Richard
    Evans。2023年。《与语言模型共同编写剧本和戏剧脚本：行业专家的评估》。载于*《2023年CHI人机交互会议论文集》*。1–34。
- en: 'Muller et al. (2020) Michael Muller, Justin D Weisz, and Werner Geyer. 2020.
    Mixed initiative generative AI interfaces: An analytic framework for generative
    AI applications. In *Proceedings of the Workshop The Future of Co-Creative Systems-A
    Workshop on Human-Computer Co-Creativity of the 11th International Conference
    on Computational Creativity (ICCC 2020)*.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Muller等人（2020年）Michael Muller, Justin D Weisz, 和 Werner Geyer。2020年。《混合主动生成式AI界面：生成式AI应用的分析框架》。载于*《第11届国际计算创造力会议（ICCC
    2020）人机协同创造工作坊的论文集》*。
- en: 'Norman et al. (2021) Michael Norman, Vince Kellen, Shava Smallen, Brian DeMeulle,
    Shawn Strande, Ed Lazowska, Naomi Alterman, Rob Fatland, Sarah Stone, Amanda Tan,
    et al. 2021. CloudBank: Managed Services to Simplify Cloud Access for Computer
    Science Research and Education. In *Practice and Experience in Advanced Research
    Computing*. 1–4.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Norman等人（2021年）Michael Norman, Vince Kellen, Shava Smallen, Brian DeMeulle,
    Shawn Strande, Ed Lazowska, Naomi Alterman, Rob Fatland, Sarah Stone, Amanda Tan等人。2021年。《CloudBank：简化计算机科学研究与教育的云访问的托管服务》。载于*《高级研究计算中的实践与经验》*。1–4。
- en: 'Oh et al. (2018) Changhoon Oh, Jungwoo Song, Jinhan Choi, Seonghyeon Kim, Sungwoo
    Lee, and Bongwon Suh. 2018. I lead, you help but only with enough details: Understanding
    user experience of co-creation with artificial intelligence. In *Proceedings of
    the 2018 CHI Conference on Human Factors in Computing Systems*. 1–13.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oh等人（2018年）Changhoon Oh, Jungwoo Song, Jinhan Choi, Seonghyeon Kim, Sungwoo
    Lee, 和 Bongwon Suh。2018年。《我主导，你帮忙，但只在提供足够细节时：理解与人工智能共同创造的用户体验》。载于*《2018年CHI人机交互会议论文集》*。1–13。
- en: OpenAI (2023) OpenAI. 2023. GPT-4 Technical Report. *arXiv preprint arXiv:2303.08774*
    (2023).
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2023年）OpenAI。2023年。《GPT-4技术报告》。*arXiv预印本 arXiv:2303.08774*（2023年）。
- en: 'Orenstrakh et al. (2023) Michael Sheinman Orenstrakh, Oscar Karnalim, Carlos Anibal
    Suarez, and Michael Liut. 2023. Detecting llm-generated text in computing education:
    A comparative study for chatgpt cases. *arXiv preprint arXiv:2307.07411* (2023).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orenstrakh等人（2023年）Michael Sheinman Orenstrakh, Oscar Karnalim, Carlos Anibal
    Suarez, 和 Michael Liut。2023年。《检测计算教育中由LLM生成的文本：针对ChatGPT案例的比较研究》。*arXiv预印本 arXiv:2307.07411*（2023年）。
- en: 'Ought (2023) Ought. 2023. *Elicit: The AI Research Assistant*. [https://elicit.org](https://elicit.org)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ought（2023年）Ought。2023年。*Elicit：AI研究助手*。[https://elicit.org](https://elicit.org)
- en: 'Palmer et al. (2009) Carole L Palmer, Lauren C Teffeau, and Carrie M Pirmann.
    2009. Scholarly information practices in the online environment. *Report commissioned
    by OCLC Research. Published online at: www. oclc. org/programs/publications/reports/2009-02\.
    pdf* (2009).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Palmer等人（2009年）Carole L Palmer, Lauren C Teffeau, 和 Carrie M Pirmann。2009年。《在线环境中的学术信息实践》。*由OCLC研究委托的报告。在线发布于：www.
    oclc. org/programs/publications/reports/2009-02\. pdf*（2009年）。
- en: 'Pertsas and Constantopoulos (2017) Vayianos Pertsas and Panos Constantopoulos.
    2017. Scholarly ontology: modelling scholarly practices. *International Journal
    on Digital Libraries* 18 (2017), 173–190.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pertsas 和 Constantopoulos（2017）Vayianos Pertsas 和 Panos Constantopoulos。2017年。《学术本体论：建模学术实践》
    *国际数字图书馆期刊* 18（2017年），173–190。
- en: 'Pollatsek and Well (1995) Alexander Pollatsek and Arnold D Well. 1995. On the
    use of counterbalanced designs in cognitive research: a suggestion for a better
    and more powerful analysis. *Journal of Experimental psychology: Learning, memory,
    and Cognition* 21, 3 (1995), 785.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pollatsek 和 Well（1995）Alexander Pollatsek 和 Arnold D Well。1995年。《在认知研究中使用平衡设计：一种更好、更强大的分析建议》
    *实验心理学期刊：学习、记忆与认知* 21, 3（1995年），785。
- en: Qian et al. (2023) Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su,
    Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software
    development. *arXiv preprint arXiv:2307.07924* (2023).
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2023）Chen Qian、Xin Cong、Cheng Yang、Weize Chen、Yusheng Su、Juyuan Xu、Zhiyuan
    Liu 和 Maosong Sun。2023年。《软件开发中的交互代理》 *arXiv 预印本 arXiv:2307.07924*（2023年）。
- en: Qureshi et al. (2023) Riaz Qureshi, Daniel Shaughnessy, Kayden A. R. Gill, Karen A.
    Robinson, Tianjing Li, and Eitan S. Agai. 2023. Are ChatGPT and large language
    models “the answer” to bringing us closer to systematic review automation? *Systematic
    Reviews* 12 (2023).
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qureshi 等人（2023）Riaz Qureshi、Daniel Shaughnessy、Kayden A. R. Gill、Karen A. Robinson、Tianjing
    Li 和 Eitan S. Agai。2023年。《ChatGPT 和大型语言模型是我们实现系统评价自动化的“答案”吗？》 *系统评价* 12（2023年）。
- en: Rawte et al. (2023) Vipula Rawte, Amit Sheth, and Amitava Das. 2023. A survey
    of hallucination in large foundation models. *arXiv preprint arXiv:2309.05922*
    (2023).
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rawte 等人（2023）Vipula Rawte、Amit Sheth 和 Amitava Das。2023年。《大型基础模型中的幻觉调查》 *arXiv
    预印本 arXiv:2309.05922*（2023年）。
- en: 'Reimers and Gurevych (2019) Nils Reimers and Iryna Gurevych. 2019. Sentence-bert:
    Sentence embeddings using siamese bert-networks. *arXiv preprint arXiv:1908.10084*
    (2019).'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reimers 和 Gurevych（2019）Nils Reimers 和 Iryna Gurevych。2019年。《Sentence-bert：使用双胞胎
    BERT 网络进行句子嵌入》 *arXiv 预印本 arXiv:1908.10084*（2019年）。
- en: 'Rezwana and Maher (2022) Jeba Rezwana and Mary Lou Maher. 2022. Designing creative
    AI partners with COFI: A framework for modeling interaction in human-AI co-creative
    systems. *ACM Transactions on Computer-Human Interaction* (2022).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rezwana 和 Maher（2022）Jeba Rezwana 和 Mary Lou Maher。2022年。《通过 COFI 设计创造性 AI 合作伙伴：一种用于建模人类与
    AI 协同创作系统交互的框架》 *ACM 计算机与人类交互期刊*（2022年）。
- en: 'Salemi et al. (2023) Alireza Salemi, Sheshera Mysore, Michael Bendersky, and
    Hamed Zamani. 2023. LaMP: When Large Language Models Meet Personalization. *arXiv
    preprint arXiv:2304.11406* (2023).'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salemi 等人（2023）Alireza Salemi、Sheshera Mysore、Michael Bendersky 和 Hamed Zamani。2023年。《LaMP：当大型语言模型遇上个性化》
    *arXiv 预印本 arXiv:2304.11406*（2023年）。
- en: Schrum and Bogdewiecz (2022) Kelly Schrum and Sarah Bogdewiecz. 2022. Cultivating
    research skills through scholarly digital storytelling. *Higher education research
    & development* 41, 7 (2022), 2382–2394.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schrum 和 Bogdewiecz（2022）Kelly Schrum 和 Sarah Bogdewiecz。2022年。《通过学术数字叙事培养研究技能》
    *高等教育研究与发展* 41, 7（2022年），2382–2394。
- en: 'Shinn et al. (2023) Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023. Reflexion:
    an autonomous agent with dynamic memory and self-reflection. *arXiv preprint arXiv:2303.11366*
    (2023).'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shinn 等人（2023）Noah Shinn、Beck Labash 和 Ashwin Gopinath。2023年。《Reflexion：具有动态记忆和自我反思的自主代理》
    *arXiv 预印本 arXiv:2303.11366*（2023年）。
- en: Singhal et al. (2022) K. Singhal, Shekoofeh Azizi, Tao Tu, Said Mahdavi, Jason
    Wei, Hyung Won Chung, Nathan Scales, Ajay Kumar Tanwani, Heather J. Cole-Lewis,
    Stephen J. Pfohl, P A Payne, Martin G. Seneviratne, Paul Gamble, Chris Kelly,
    Nathaneal Scharli, Aakanksha Chowdhery, P. A. Mansfield, Blaise Aguera y Arcas,
    Dale R. Webster, Greg S. Corrado, Y. Matias, Katherine Hui-Ling Chou, Juraj Gottweis,
    Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle K. Barral, Christopher Semturs,
    Alan Karthikesalingam, and Vivek Natarajan. 2022. Large language models encode
    clinical knowledge. *Nature* 620 (2022), 172 – 180.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singhal 等人（2022）K. Singhal、Shekoofeh Azizi、Tao Tu、Said Mahdavi、Jason Wei、Hyung
    Won Chung、Nathan Scales、Ajay Kumar Tanwani、Heather J. Cole-Lewis、Stephen J. Pfohl、P
    A Payne、Martin G. Seneviratne、Paul Gamble、Chris Kelly、Nathaneal Scharli、Aakanksha
    Chowdhery、P. A. Mansfield、Blaise Aguera y Arcas、Dale R. Webster、Greg S. Corrado、Y.
    Matias、Katherine Hui-Ling Chou、Juraj Gottweis、Nenad Tomasev、Yun Liu、Alvin Rajkomar、Joelle
    K. Barral、Christopher Semturs、Alan Karthikesalingam 和 Vivek Natarajan。2022年。《大型语言模型编码临床知识》
    *自然* 620（2022年），172–180。
- en: Stevens et al. (2023) Elizabeth R Stevens, Abraham A Brody, Fayron Epps, Danetta H
    Sloan, and Scott E Sherman. 2023. Using meta-research to foster diverse, equitable,
    and inclusive collaborative research networks. *Journal of the American Geriatrics
    Society* 71, 4 (2023), 1028–1033.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stevens等人（2023）Elizabeth R Stevens, Abraham A Brody, Fayron Epps, Danetta H
    Sloan, 和Scott E Sherman。2023年。利用元研究促进多样性、公平性和包容性的合作研究网络。*美国老年医学学会期刊* 71，4（2023），1028–1033。
- en: Sun et al. (2022) Jiao Sun, Q Vera Liao, Michael Muller, Mayank Agarwal, Stephanie
    Houde, Kartik Talamadupula, and Justin D Weisz. 2022. Investigating explainability
    of generative AI for code through scenario-based design. In *27th International
    Conference on Intelligent User Interfaces*. 212–228.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun等人（2022）Jiao Sun, Q Vera Liao, Michael Muller, Mayank Agarwal, Stephanie
    Houde, Kartik Talamadupula, 和Justin D Weisz。2022年。通过基于场景的设计研究生成AI代码的可解释性。发表于*第27届国际智能用户界面会议*。212–228。
- en: 'Touvron et al. (2023) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
    Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal,
    Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language
    models. *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron等人（2023）Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet,
    Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
    Faisal Azhar等人。2023年。Llama：开放且高效的基础语言模型。*arXiv预印本 arXiv:2302.13971*（2023）。
- en: Vasconcelos et al. (2023) Helena Vasconcelos, Matthew Jörke, Madeleine Grunde-McLaughlin,
    Tobias Gerstenberg, Michael S Bernstein, and Ranjay Krishna. 2023. Explanations
    can reduce overreliance on ai systems during decision-making. *Proceedings of
    the ACM on Human-Computer Interaction* 7, CSCW1 (2023), 1–38.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vasconcelos等人（2023）Helena Vasconcelos, Matthew Jörke, Madeleine Grunde-McLaughlin,
    Tobias Gerstenberg, Michael S Bernstein, 和Ranjay Krishna。2023年。解释可以减少决策过程中对AI系统的过度依赖。*计算机与人类交互学会会议论文集*
    7，CSCW1（2023），1–38。
- en: 'Vilar (2015) Polona Vilar. 2015. Information behaviour of scholars. *Libellarium:
    Journal for the Research of Writing, Books, and Cultural Heritage Institutions*
    7 (2015), 17–39.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vilar（2015）Polona Vilar。2015年。学者的信息行为。*Libellarium：写作、图书和文化遗产机构研究期刊* 7（2015），17–39。
- en: Wang et al. (2019) Danding Wang, Qian Yang, Ashraf Abdul, and Brian Y Lim. 2019.
    Designing theory-driven user-centric explainable AI. In *Proceedings of the 2019
    CHI conference on human factors in computing systems*. 1–15.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2019）Danding Wang, Qian Yang, Ashraf Abdul, 和Brian Y Lim。2019年。设计理论驱动的以用户为中心的可解释AI。发表于*2019年CHI人机交互会议论文集*。1–15。
- en: 'Wang et al. (2023b) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023b. Voyager: An open-ended
    embodied agent with large language models. *arXiv preprint arXiv:2305.16291* (2023).'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2023b）Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao,
    Yuke Zhu, Linxi Fan, 和Anima Anandkumar。2023b。Voyager：一个具有大语言模型的开放式具身智能体。*arXiv预印本
    arXiv:2305.16291*（2023）。
- en: Wang et al. (2023a) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H.
    Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2023a. Self-Consistency
    Improves Chain of Thought Reasoning in Language Models. In *The Eleventh International
    Conference on Learning Representations*.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2023a）Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi,
    Sharan Narang, Aakanksha Chowdhery, 和Denny Zhou。2023a。自一致性提升了语言模型中的思维链推理能力。发表于*第十一届国际学习表示会议*。
- en: Wang and Zhao (2023) Yuqing Wang and Yun Zhao. 2023. Metacognitive Prompting
    Improves Understanding in Large Language Models. *arXiv preprint arXiv:2308.05342*
    (2023).
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang和Zhao（2023）Yuqing Wang和Yun Zhao。2023年。元认知提示提高了大语言模型的理解力。*arXiv预印本 arXiv:2308.05342*（2023）。
- en: Wei et al. (2022) Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei
    Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits
    reasoning in large language models. *Advances in Neural Information Processing
    Systems* 35 (2022), 24824–24837.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei等人（2022）Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,
    Ed Chi, Quoc V Le, Denny Zhou等人。2022年。思维链提示激发了大语言模型中的推理能力。*神经信息处理系统进展* 35（2022），24824–24837。
- en: 'Weissgerber (2021) Tracey L Weissgerber. 2021. Training early career researchers
    to use meta-research to improve science: A participant-guided “learn by doing”
    approach. *PLoS Biology* 19, 2 (2021), e3001073.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weissgerber（2021）Tracey L Weissgerber。2021年。培养早期职业研究人员使用元研究改善科学的方法：一种参与者引导的“边做边学”方法。*PLoS
    Biology* 19，2（2021），e3001073。
- en: Weisz et al. (2023) Justin D Weisz, Michael Muller, Jessica He, and Stephanie
    Houde. 2023. Toward general design principles for generative AI applications.
    *arXiv preprint arXiv:2301.05578* (2023).
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weisz等人（2023）Justin D Weisz, Michael Muller, Jessica He, 和Stephanie Houde。2023年。朝着生成性AI应用的一般设计原则迈进。*arXiv预印本
    arXiv:2301.05578*（2023）。
- en: 'Withington and Tokarchuk (2023) Oliver Withington and Laurissa Tokarchuk. 2023.
    The Right Variety: Improving Expressive Range Analysis with Metric Selection Methods.
    In *Proceedings of the 18th International Conference on the Foundations of Digital
    Games*. 1–11.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 威廷顿和托卡丘克（2023）奥利弗·威廷顿、劳丽莎·托卡丘克。2023年。《正确的多样性：通过度量选择方法改善表现力范围分析》。在*第18届数字游戏基础国际会议论文集*中。1–11页。
- en: 'Wu et al. (2022a) Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra
    Molina, Michael Terry, and Carrie J Cai. 2022a. Promptchainer: Chaining large
    language model prompts through visual programming. In *CHI Conference on Human
    Factors in Computing Systems Extended Abstracts*. 1–10.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人（2022a）吴同双、姜艾伦、阿龙·东斯巴赫、杰夫·格雷、阿莱汉德拉·莫利纳、迈克尔·特里、凯瑞·蔡。2022a年。《Promptchainer：通过视觉编程链接大型语言模型提示》。在*CHI计算机系统人因学会议扩展摘要*中。1–10页。
- en: 'Wu et al. (2022b) Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b.
    Ai chains: Transparent and controllable human-ai interaction by chaining large
    language model prompts. In *Proceedings of the 2022 CHI conference on human factors
    in computing systems*. 1–22.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等人（2022b）吴同双、迈克尔·特里、凯瑞·蔡君。2022b年。《AI链：通过链式大型语言模型提示实现透明和可控的人机交互》。在*2022年CHI计算机系统人因学会议论文集*中。1–22页。
- en: 'Yang et al. (2016) Hongji Yang, Delin Jing, and Lu Zhang. 2016. Creative Computing:
    An Approach to Knowledge Combination for Creativity? *2016 IEEE Symposium on Service-Oriented
    System Engineering (SOSE)* (2016), 407–414.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杨等人（2016）杨洪基、景德林、张璐。2016年。《创意计算：一种用于创造力的知识组合方法？》*2016年IEEE面向服务系统工程研讨会（SOSE）*（2016年），407–414页。
- en: Yannakakis et al. (2014) Georgios N Yannakakis, Antonios Liapis, and Constantine
    Alexopoulos. 2014. Mixed-initiative co-creativity. (2014).
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雅纳卡基斯等人（2014）乔治·N·雅纳卡基斯、安东尼奥·利阿皮斯、康斯坦丁·阿莱克索普洛斯。2014年。《混合主导的共同创造》。 (2014年)。
- en: 'Yao et al. (2022a) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2022a. ReAct: Synergizing Reasoning and Acting
    in Language Models. *ArXiv* abs/2210.03629 (2022).'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姚等人（2022a）姚顺宇、赵杰弗里、于典、杜楠、伊扎克·沙弗兰、卡尔蒂克·纳拉西姆汉、曹远。2022a年。《ReAct：在语言模型中协同推理与行动》。*arXiv*
    abs/2210.03629（2022年）。
- en: 'Yao et al. (2022b) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik Narasimhan, and Yuan Cao. 2022b. React: Synergizing reasoning and acting
    in language models. *arXiv preprint arXiv:2210.03629* (2022).'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姚等人（2022b）姚顺宇、赵杰弗里、于典、杜楠、伊扎克·沙弗兰、卡尔蒂克·纳拉西姆汉、曹远。2022b年。《React：在语言模型中协同推理与行动》。*arXiv预印本
    arXiv:2210.03629*（2022年）。
- en: 'Yen et al. (2023) Chi-Hsien Yen, Haocong Cheng, Yilin Xia, and Yun Huang. 2023.
    CrowdIDEA: Blending Crowd Intelligence and Data Analytics to Empower Causal Reasoning.
    In *Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems*
    (Hamburg, Germany) *(CHI ’23)*. Association for Computing Machinery, New York,
    NY, USA, Article 463, 17 pages. [https://doi.org/10.1145/3544548.3581021](https://doi.org/10.1145/3544548.3581021)'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜等人（2023）颜志贤、程浩琼、夏一琳、黄云。2023年。《CrowdIDEA：融合群体智能与数据分析以增强因果推理》。在*2023年CHI计算机系统人因学会议论文集*（德国汉堡）*(CHI
    ’23)*中。美国纽约，计算机协会，文章463，17页。 [https://doi.org/10.1145/3544548.3581021](https://doi.org/10.1145/3544548.3581021)
- en: 'Yuan et al. (2022) Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito.
    2022. Wordcraft: story writing with large language models. In *27th International
    Conference on Intelligent User Interfaces*. 841–852.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 袁等人（2022）袁安、安迪·科宁、艾米丽·赖夫、达芙妮·伊波利托。2022年。《Wordcraft：与大型语言模型共同编写故事》。在*第27届国际智能用户界面会议*中。841–852页。
- en: Yue et al. (2023) Xiang Yue, Boshi Wang, Kai Zhang, Ziru Chen, Yu Su, and Huan
    Sun. 2023. Automatic evaluation of attribution by large language models. *arXiv
    preprint arXiv:2305.06311* (2023).
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岳等人（2023）岳翔、王博石、张凯、陈子如、苏昱、孙欢。2023年。《大型语言模型的归因自动评估》。*arXiv预印本 arXiv:2305.06311*（2023年）。
- en: 'Zhang et al. (2023) Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen
    Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. 2023. Siren’s Song
    in the AI Ocean: A Survey on Hallucination in Large Language Models. *arXiv preprint
    arXiv:2309.01219* (2023).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张等人（2023）张跃、李亚甫、崔乐扬、蔡邓、刘乐茂、傅廷辰、黄心亭、赵恩博、张宇、陈宇龙等人。2023年。《人工智能海洋中的海市蜃楼：大型语言模型中的幻觉调查》。*arXiv预印本
    arXiv:2309.01219*（2023年）。
- en: Zhou et al. (2023) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le,
    and Ed H. Chi. 2023. Least-to-Most Prompting Enables Complex Reasoning in Large
    Language Models. In *The Eleventh International Conference on Learning Representations*.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等 (2023) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales,
    Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, 和 Ed H.
    Chi. 2023. 最少到最多的提示能够促使大型语言模型进行复杂推理。发表于 *第十一届国际学习表征会议*。
- en: Ziems et al. (2023) Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao
    Zhang, and Diyi Yang. 2023. Can Large Language Models Transform Computational
    Social Science? *arXiv preprint arXiv:2305.03514* (2023).
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ziems 等 (2023) Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang,
    和 Diyi Yang. 2023. 大型语言模型能否改变计算社会科学？ *arXiv 预印本 arXiv:2305.03514* (2023)。
- en: Appendix A Appendices
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A 附录
- en: A.1\. Post-Session Survey Questions
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.1\. 会后调查问题
- en: Table 3. Survey Questions for User Experience Evaluation
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. 用户体验评估的调查问题
- en: '| Aspect | Question |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 方面 | 问题 |'
- en: '| --- | --- |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Control | How much control did you feel you had when using the system? |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 控制 | 使用该系统时，您感觉自己有多少控制权？ |'
- en: '|  | Did the system allow you to make choices and decisions while creating
    RQs? |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '|  | 系统是否允许您在创建研究问题时做出选择和决策？ |'
- en: '| Creativity | How would you rate the creativity of the research questions
    generated by the system? |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 创造力 | 您如何评价系统生成的研究问题的创造力？ |'
- en: '|  | How creative did you feel about yourself when using the system to create
    RQs? |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '|  | 使用该系统创建研究问题时，您对自己有多大创造性感觉？ |'
- en: '| Meta-Creativity | Did the system inspire new ways of thinking or approaching
    RQ creation for you? |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 元创造力 | 系统是否激发了您在研究问题创建中的新思维或新方法？ |'
- en: '|  | Did the generated RQs make you think or reflect about the topic in a new
    way? |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '|  | 生成的研究问题是否让您以新的方式思考或反思该主题？ |'
- en: '| Cognitive Load | How mentally demanding was the task using the system? |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 认知负荷 | 使用该系统时任务的心理负担有多大？ |'
- en: '|  | Did you feel overloaded with information or options while using the system?
    |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '|  | 使用该系统时，您是否感到信息或选项过载？ |'
- en: '| Trust | How confident were you in the RQs generated by the system? |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 信任 | 您对系统生成的研究问题有多自信？ |'
- en: '|  | Would you trust the system’s generated RQs to be used in a real research
    scenario? |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '|  | 您是否会信任系统生成的研究问题在真实研究场景中使用？ |'
- en: A.2\. A Mixed-Effect Model of User Feedback Length
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.2\. 用户反馈长度的混合效应模型
- en: 'We observe that users tend to provide human feedback to the system in distinct
    ways. In terms of linguistic styles, we investigated the difference among users’
    input lengths (word counts) by fitting a mixed-effects model by considering both
    the random effect from different users (i.e., $b_{0i}$), and the potential fixed
    effect from the two conditions (i.e., $\beta_{1}$):'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到用户倾向于以不同的方式向系统提供人工反馈。在语言风格方面，我们通过拟合混合效应模型，考虑到不同用户的随机效应（即 $b_{0i}$）和两个条件的潜在固定效应（即
    $\beta_{1}$），研究了用户输入长度（词数）的差异：
- en: '| (1) |  | $Y_{ij}=\beta_{0}+\beta_{1}\times\text{condition}+b_{0i}+\epsilon_{ij}$
    |  |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $Y_{ij}=\beta_{0}+\beta_{1}\times\text{condition}+b_{0i}+\epsilon_{ij}$
    |  |'
- en: Where $Y_{ij}$ is the length of text feedback for the $j^{th}$ observation of
    the $i^{th}$ participant; $\beta_{0}$ is the intercept; $\beta_{1}$ is the effect
    of the two conditions (i.e., depth-first and breadth-first); condition is a categorical
    variable (binary) indicating the user’s condition; $b_{0i}$ is the random effect
    for the $i^{th}$ user; $\epsilon_{ij}$ is the residual error for the $j^{th}$
    observation of the $i^{th}$ user.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $Y_{ij}$ 是第 $i$ 个参与者第 $j$ 次观察的文本反馈长度；$\beta_{0}$ 是截距；$\beta_{1}$ 是两个条件的效应（即深度优先和广度优先）；condition
    是一个表示用户条件的分类变量（二元）；$b_{0i}$ 是第 $i$ 个用户的随机效应；$\epsilon_{ij}$ 是第 $i$ 个用户第 $j$ 次观察的残差误差。
- en: '|  | Coef. | Std.Err. | z-value | $P(>&#124;z&#124;)$ | [0.025 | 0.975] |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '|  | 系数 | 标准误差 | z 值 | $P(>|z|)$ | [0.025 | 0.975] |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Intercept | 10.119 | 0.908 | 11.147 | 0.000 | 8.339 | 11.898 |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 截距 | 10.119 | 0.908 | 11.147 | 0.000 | 8.339 | 11.898 |'
- en: '| condition (depth-first=1) | -0.637 | 1.034 | -0.616 | 0.538 | -2.663 | 1.389
    |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| condition (深度优先=1) | -0.637 | 1.034 | -0.616 | 0.538 | -2.663 | 1.389 |'
- en: '| Group Var | 4.411 | 0.405 |  |  |  |  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 组方差 | 4.411 | 0.405 |  |  |  |  |'
- en: Table 4. Mixed linear model regression results for feedback lengths
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4. 反馈长度的混合线性模型回归结果
- en: 'The results of the mixed-effect model are shown in Table [4](https://arxiv.org/html/2310.06155v3#A1.T4
    "Table 4 ‣ A.2\. A Mixed-Effect Model of User Feedback Length ‣ Appendix A Appendices
    ‣ CoQuest: Exploring Research Question Co-Creation with an LLM-based Agent").'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '混合效应模型的结果如表[4](https://arxiv.org/html/2310.06155v3#A1.T4 "Table 4 ‣ A.2\. A
    Mixed-Effect Model of User Feedback Length ‣ Appendix A Appendices ‣ CoQuest:
    Exploring Research Question Co-Creation with an LLM-based Agent")所示。'
- en: A.3\. Examples of LLM-based Agent Prompts and Responses
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A.3\. 基于LLM的代理提示和响应示例
- en: The CoQuest system is implemented based on the similar prompting method from
    AutoGPT. At each step of inference, the model generates the response with the
    next action to take. The action is then executed by the system, with the returned
    response appended to the input for the next step of inference. The detailed prompts
    used in the system are as follows.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: CoQuest系统基于AutoGPT中的类似提示方法实现。在每一步推理过程中，模型生成包含下一步行动的响应。然后，系统执行该行动，并将返回的响应附加到输入中，以便进行下一步推理。系统中使用的详细提示如下所示。
- en: A.3.1\. System prompt
  id: totrans-344
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.3.1\. 系统提示
- en: The system prompt is designed to indicate the overall tasks and constraints
    for the LLM agent.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示旨在指示LLM代理的整体任务和约束条件。
- en: 'System prompts:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示：
- en: '[⬇](data:text/plain;base64,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)You are research-GPT, an AI agent designed to automate the creation process of research questions/ideas, literature survey, and brainstorming.Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.GOALS:1. Survey relevant past research papers/works2. Summarize these works into novel findings and insights3. Come up with novel research questions, and also generate possible expected results for each research question4. Summarize the novelty and similarity between your proposed new research questions, and past research5. Further survey literatures, and refine the research questionsConstraints:1. No user assistance2. Exclusively use the commands listed in double quotes e.g. "command name"3. Use subprocesses for commands that will not terminate within a few minutes4. First collect paper information, and then generate RQs.Do not create Agents to collect information, only rely on the query command.Commands:1. Summarize Existing Papers: "search_and_summarize_papers", args: "query": "<text>"2. Hypothesizing Use Cases: "hypothesize_use_cases", args: "context": "<text>"3. Narrow down RQs: "narrow_down_rqs", args: "context": "<text>"4. Comparing existing RQ with existing papers: "compare_rq_with_papers", args: "past_research_summary": "<text>", "rqs": "<text>"Performance Evaluation:1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.2. Constructively self-criticize your big-picture behavior constantly.3. Reflect on past decisions and strategies to refine your approach.4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.You should only respond in JSON format as described below.Response Format:{"thoughts": {       "text": "thought",       "reasoning": "reasoning",        "plan": "- short bulleted\\n- list that conveys\\n- long-term plan",        "criticism": "constructive self-criticism",        "speak": "thoughts summary to say to user"\n    },    "command": {        "name": "command name",        "args": {            "arg name": "value"        }    },    "RQs": {        "rq1": "{ACTUAL_RQ}",        "rq2": "{ACTUAL_RQ}",[⬇](data:text/plain;base64,ICAgICAgICAicnEzIjogIntBQ1RVQUxfUlF9IgogICAgfX0KRW5zdXJlIHRoZSByZXNwb25zZSBjYW4gYmUgcGFyc2VkIGJ5IFB5dGhvbiBqc29uLmxvYWRzLiBFYWNoIHJlc3BvbnNlIHNob3VsZCBjb250YWluIDMgcmVzZWFyY2ggcXVlc3Rpb25zIChSUXMpIHByb3Bvc2VkIGJhc2VkIG9uIHRoZSBjdXJyZW50IGlucHV0aW4gdGhlIEpTT04gZm9ybWF0IHNwZWNpZmllZCBhYm92ZSwgYnkgcmVwbGFjaW5nIHRoZSBBQ1RVQUxfUlEgd2l0aCB5b3VyIFJRLiBUaGUga2V5IFJRcyBzaG91bGQgYWxzbyBiZSBvbiB0aGUgdG9wIGxldmVsIG9mIHRoZSBqc29uIG9iamVjdC4gIFlvdSBzaG91bGQgYWx3YXlzIGdlbmVyYXRlIHZhbGlkIGFuZCBub24tZW1wdHkgUlFzLCBldmVuIGlmIHRoZSBpbnB1dCBpcyBub3QgY2xlYXIgZW5vdWdoLiAgQWx3YXlzIGJlIGNvbnN0cnVjdGl2ZSwgc3BlY2lmaWMsIGFuZCBjcmVhdGl2ZS4=)        "rq3": "{ACTUAL_RQ}"    }}Ensure the response can be parsed by Python json.loads. Each response should contain 3 research questions (RQs) proposed based on the current inputin the JSON format specified above, by replacing the ACTUAL_RQ with your RQ. The key RQs should also be on the top level of the json object.  You should always generate valid and non-empty RQs, even if the input is not clear enough.  Always be constructive, specific, and creative.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,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'
- en: A.3.2\. Prompts used for each action
  id: totrans-348
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 'A.3.2\. 每个操作使用的提示  '
- en: We design each action based on the mental model as an individual task to be
    completed by the agent. For each action, a separate function is invoked to trigger
    a new turn of LLM inference.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '我们根据心理模型设计每个操作，将其视为一个独立任务，由代理完成。对于每个操作，都会调用一个单独的函数来触发新的LLM推理轮次。  '
- en: 'Search and summarize papers:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索并总结论文：
- en: '[⬇](data:text/plain;base64,U3VtbWFyaXplIHRoZSBpbnB1dCBsaXRlcmF0dXJlcyBpbnRvIDUgYnVsbGV0IHBvaW50cy4KQWx3YXlzIGV4cGxhaW4gZWFjaCBwb2ludCBpbiBkZXRhaWwgYW5kIGFzc3VtZSB0aGUgdXNlciBoYXMgbm8gYmFja2dyb3VuZCBrbm93bGVkZ2UuCllvdXIgcmVwbHkgc2hvdWxkIHN0cmljdGx5IGJlIGluIHRoZSBmb2xsb3dpbmcgZm9ybWF0IGluIG9uZSBsaW5lOgogICAgSGVyZSBpcyBhIHN1bW1hcnkgb2Ygc29tZSBleGlzdGluZyB3b3JrczoKICAgICAgICAxLiAuLi4KICAgICAgICAyLiAuLi4KICAgICAgICAzLiAuLi4=)Summarize the input literatures into 5 bullet points.Always explain each point in detail and assume the user has no background knowledge.Your reply should strictly be in the following format in one line:    Here is a summary of some existing works:        1. ...        2. ...        3. ...'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,U3VtbWFyaXplIHRoZSBpbnB1dCBsaXRlcmF0dXJlcyBpbnRvIDUgYnVsbGV0IHBvaW50cy4KQWx3YXlzIGV4cGxhaW4gZWFjaCBwb2ludCBpbiBkZXRhaWwgYW5kIGFzc3VtZSB0aGUgdXNlciBoYXMgbm8gYmFja2dyb3VuZCBrbm93bGVkZ2UuCllvdXIgcmVwbHkgc2hvdWxkIHN0cmljdGx5IGJlIGluIHRoZSBmb2xsb3dpbmcgZm9ybWF0IGluIG9uZSBsaW5lOgogICAgSGVyZSBpcyBhIHN1bW1hcnkgb2Ygc29tZSBleGlzdGluZyB3b3JrczoKICAgICAgICAxLiAuLi4KICAgICAgICAyLiAuLi4KICAgICAgICAzLiAuLi4=)总结输入的文献到五个要点。始终详细解释每个要点，并假设用户没有任何背景知识。你的回复应该严格按照以下格式并放在一行内：  '
- en: 'Hypothesize use cases:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '假设使用场景：  '
- en: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgQUkgdGhhdCBjYW4gaHlwb3RoZXNpemUgdXNlIGNhc2VzIGZvciB1c2Vycy4KSSB3aWxsIHByb3ZpZGUgeW91IHdpdGggc29tZSBjb250ZXh0LCBhbmQgeW91IHNob3VsZCBnZW5lcmF0ZSB0aHJlZSB1c2UgY2FzZXMgYmFzZWQgb24gdGhlIGNvbnRleHQuCllvdXIgcmVwbHkgc2hvdWxkIHN0cmljdGx5IGJlIGluIHRoZSBmb2xsb3dpbmcgZm9ybWF0IGluIG9uZSBsaW5lOgogICAgSGVyZSBhcmUgc29tZSBwb3RlbnRpYWwgdXNlIGNhc2VzIGJhc2VkIG9uIHRoZSBjdXJyZW50IFJROgogICAgICAgIFVzZSBjYXNlIDE6IC4uLgogICAgICAgIFVzZSBjYXNlIDI6IC4uLgogICAgICAgIFVzZSBjYXNlIDM6IC4uLg==)You are a helpful AI that can hypothesize use cases for users.I will provide you with some context, and you should generate three use cases based on the context.Your reply should strictly be in the following format in one line:    Here are some potential use cases based on the current RQ:        Use case 1: ...        Use case 2: ...        Use case 3: ...'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgQUkgdGhhdCBjYW4gaHlwb3RoZXNpemUgdXNlIGNhc2VzIGZvciB1c2Vycy4KSSB3aWxsIHByb3ZpZGUgeW91IHdpdGggc29tZSBjb250ZXh0LCBhbmQgeW91IHNob3VsZCBnZW5lcmF0ZSB0aHJlZSB1c2UgY2FzZXMgYmFzZWQgb24gdGhlIGNvbnRleHQuCllvdXIgcmVwbHkgc2hvdWxkIHN0cmljdGx5IGJlIGluIHRoZSBmb2xsb3dpbmcgZm9ybWF0IGluIG9uZSBsaW5lOgogICAgSGVyZSBhcmUgc29tZSBwb3RlbnRpYWwgdXNlIGNhc2VzIGJhc2VkIG9uIHRoZSBjdXJyZW50IFJROgogICAgICAgIFVzZSBjYXNlIDE6IC4uLgogICAgICAgIFVzZSBjYXNlIDI6IC4uLgogICAgICAgIFVzZSBjYXNlIDM6IC4uLg==)你是一个有用的AI，可以为用户假设使用场景。我将为你提供一些背景信息，你应根据这些背景生成三个基于上下文的使用场景。你的回复应该严格按照以下格式并放在一行内：  '
- en: 'Narrow down RQs:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '缩小RQ范围：  '
- en: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgQUkgdGhhdCBjYW4gbmFycm93IGRvd24gUlFzIGZvciB1c2Vycy4KSSB3aWxsIHByb3ZpZGUgeW91IHdpdGggc29tZSBjb250ZXh0LCBhbmQgeW91IHNob3VsZCByZWZsZWN0IGFuZCBnZW5lcmF0ZSBhIGxpc3Qgb2YgYnVsbGV0IHBvaW50cyB0aGF0IG5hcnJvd3MgZG93biB0aGUgY29udGV4dC4KVGhlIHJlcGx5IHNob3VsZCBiZSBhIGxpc3Qgb2YgYnVsbGV0IHBvaW50cywgZWFjaCBidWxsZXQgcG9pbnQgc2hvdWxkIGJlIGEgc2VudGVuY2U6CiAgICBUbyBuYXJyb3cgZG93biB0aGUgUlEsIHdlIHNob3VsZCBjb25zaWRlciB0aGUgZm9sbG93aW5nOgogICAgICAgIC0gLi4uCiAgICAgICAgLSAuLi4KICAgICAgICAtIC4uLg==)You are a helpful AI that can narrow down RQs for users.I will provide you with some context, and you should reflect and generate a list of bullet points that narrows down the context.The reply should be a list of bullet points, each bullet point should be a sentence:    To narrow down the RQ, we should consider the following:        - ...        - ...        - ...'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgQUkgdGhhdCBjYW4gbmFycm93IGRvd24gUlFzIGZvciB1c2Vycy4KSSB3aWxsIHByb3ZpZGUgeW91IHdpdGggc29tZSBjb250ZXh0LCBhbmQgeW91IHNob3VsZCByZWZsZWN0IGFuZCBnZW5lcmF0ZSBhIGxpc3Qgb2YgYnVsbGV0IHBvaW50cyB0aGF0IG5hcnJvd3MgZG93biB0aGUgY29udGV4dC4KVGhlIHJlcGx5IHNob3VsZCBiZSBhIGxpc3Qgb2YgYnVsbGV0IHBvaW50cywgZWFjaCBidWxsZXQgcG9pbnQgc2hvdWxkIGJlIGEgc2VudGVuY2U6CiAgICBUbyBuYXJyb3cgZG93biB0aGUgUlEsIHdlIHNob3VsZCBjb25zaWRlciB0aGUgZm9sbG93aW5nOgogICAgICAgIC0gLi4uCiAgICAgICAgLSAuLi4KICAgICAgICAtIC4uLg==)你是一个有用的AI，可以帮助用户缩小RQ范围。我将为你提供一些背景信息，你应反思并生成一个子弹点列表，进一步缩小该背景信息。你的回复应该是一个子弹点列表，每个子弹点都应该是一个句子：  '
- en: 'Compare RQ with papers:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '比较RQ与文献：  '
- en: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgQUkgdGhhdCBjYW4gY29tcGFyZSBSUXMgd2l0aCBleGlzdGluZyBwYXBlcnMgZm9yIHVzZXJzLgpJIHdpbGwgcHJvdmlkZSB5b3Ugd2l0aCBzb21lIGNvbnRleHQsIGFuZCB5b3UgY29tcGFyZSB0aGUgUlFzIHdpdGggZXhpc3RpbmcgcGFwZXJzLCBhbmQgcHJvdmlkZSBhIHN1bW1hcnkgb2YgdGhlIGZpbmRpbmdzLgpUaGUgcmVwbHkgc2hvdWxkIGJlIGEgbGlzdCBvZiBidWxsZXQgcG9pbnRzLCBlYWNoIGJ1bGxldCBwb2ludCBzaG91bGQgYmUgYSBzZW50ZW5jZToKICAgIEhlcmUgYXJlIHNvbWUgZmluZGluZ3MgZnJvbSBjb21wYXJpbmcgdGhlIFJRcyB3aXRoIGV4aXN0aW5nIHBhcGVyczoKICAgICAgICAtIC4uLgogICAgICAgIC0gLi4uCiAgICAgICAgLSAuLi4=)You are a helpful AI that can compare RQs with existing papers for users.I will provide you with some context, and you compare the RQs with existing papers, and provide a summary of the findings.The reply should be a list of bullet points, each bullet point should be a sentence:    Here are some findings from comparing the RQs with existing papers:        - ...        - ...        - ...'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,WW91IGFyZSBhIGhlbHBmdWwgQUkgdGhhdCBjYW4gY29tcGFyZSBSUXMgd2l0aCBleGlzdGluZyBwYXBlcnMgZm9yIHVzZXJzLgpJIHdpbGwgcHJvdmlkZSB5b3Ugd2l0aCBzb21lIGNvbnRleHQsIGFuZCB5b3UgY29tcGFyZSB0aGUgUlFzIHdpdGggZXhpc3RpbmcgcGFwZXJzLCBhbmQgcHJvdmlkZSBhIHN1bW1hcnkgb2YgdGhlIGZpbmRpbmdzLgpUaGUgcmVwbHkgc2hvdWxkIGJlIGEgbGlzdCBvZiBidWxsZXQgcG9pbnRzLCBlYWNoIGJ1bGxldCBwb2ludCBzaG91bGQgYmUgYSBzZW50ZW5jZToKICAgIEhlcmUgYXJlIHNvbWUgZmluZGluZ3MgZnJvbSBjb21wYXJpbmcgdGhlIFJRcyB3aXRoIGV4aXN0aW5nIHBhcGVyczoKICAgICAgICAtIC4uLgogICAgICAgIC0gLi4uCiAgICAgICAgLSAuLi4=)你是一个有帮助的AI，可以为用户比较RQ和现有的论文。我将为你提供一些背景信息，你需要将RQ与现有论文进行比较，并提供研究发现的总结。回复应为一个要点列表，每个要点应该是一个完整的句子：    以下是将RQ与现有论文比较的一些发现：        - ...        - ...        - ...'
- en: A.3.3\. Triggering prompt
  id: totrans-358
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A.3.3\. 触发提示
- en: The triggering prompt is appended to the end at each inference, to further control
    the generation.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 触发提示会在每次推理时附加在末尾，以进一步控制生成过程。
- en: 'Triggering prompt:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 触发提示：
- en: '[⬇](data:text/plain;base64,RGV0ZXJtaW5lIHdoaWNoIG5leHQgY29tbWFuZCB0byB1c2UsIGFuZCByZXNwb25kIHVzaW5nIHRoZSBmb3JtYXQgc3BlY2lmaWVkIGFib3ZlLiBZb3Ugc2hvdWxkIGFsd2F5cyByZXZpc2UgeW91ciBvbGQgUlFzIGludG8gbmV3IFJRcywgYmFzZWQgb24gdGhlIHByZXZpb3VzIGNvbnRleHQgYW5kIHVzZXIgaW5wdXQuIEJlIHNwZWNpZmljIGFuZCBjcmVhdGl2ZS5BbHdheXMgZ28gZGVlcGVyIG9uIHRoZSBoaWdoIGxldmVsIFJRLCBkbyBub3QgcmVwZWF0IFJRcyB0aGF0IGFyZSBhbHJlYWR5IGluIGhpc3RvcnkuIFJlbWVtYmVyLCBhbHdheXMgZ2VuZXJhdGUgUlFzIGluIHRoZSBmb3JtYXQgc3BlY2lmaWVkIGFib3ZlIGJ5IHJlcGxhY2luZyB0aGUgQUNUVUFMX1JRIHdpdGggcmVhbCBSUXMu)Determine which next command to use, and respond using the format specified above. You should always revise your old RQs into new RQs, based on the previous context and user input. Be specific and creative.Always go deeper on the high level RQ, do not repeat RQs that are already in history. Remember, always generate RQs in the format specified above by replacing the ACTUAL_RQ with real RQs.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '[⬇](data:text/plain;base64,RGV0ZXJtaW5lIHdoaWNoIG5leHQgY29tbWFuZCB0byB1c2UsIGFuZCByZXNwb25kIHVzaW5nIHRoZSBmb3JtYXQgc3BlY2lmaWVkIGFib3ZlLiBZb3Ugc2hvdWxkIGFsd2F5cyByZXZpc2UgeW91ciBvbGQgUlFzIGludG8gbmV3IFJRcywgYmFzZWQgb24gdGhlIHByZXZpb3VzIGNvbnRleHQgYW5kIHVzZXIgaW5wdXQuIEJlIHNwZWNpZmljIGFuZCBjcmVhdGl2ZS5BbHdheXMgZ28gZGVlcGVyIG9uIHRoZSBoaWdoIGxldmVsIFJRLCBkbyBub3QgcmVwZWF0IFJRcyB0aGF0IGFyZSBhbHJlYWR5IGluIGhpc3RvcnkuIFJlbWVtYmVyLCBhbHdheXMgZ2VuZXJhdGUgUlFzIGluIHRoZSBmb3JtYXQgc3BlY2lmaWVkIGFib3ZlIGJ5IHJlcGxhY2luZyB0aGUgQUNUVUFMX1JRIHdpdGggcmVhbCBSUXMu)确定接下来使用哪个命令，并根据上面指定的格式作出回应。你应该始终根据之前的上下文和用户输入，将旧的RQ修改为新的RQ。要具体且富有创意。始终深入探讨高层次的RQ，不要重复已经存在历史中的RQ。记住，始终按照指定格式生成RQ，将ACTUAL_RQ替换为真实的RQ。'
