- en: æ–¯å¦ç¦ GPTï¼Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P10ï¼š10.Represent part-whole hierarchies
    in a neural network, Geoff Hinton - life_code - BV1X84y1Q7wV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦ GPT/Transformer åŸç†ä»‹ç» (ä¸­è‹±æ–‡åŒå­—å¹•) - P10ï¼š10. åœ¨ç¥ç»ç½‘ç»œä¸­è¡¨ç¤ºéƒ¨åˆ†-æ•´ä½“å±‚æ¬¡ç»“æ„ï¼ŒGeoff Hinton -
    life_code - BV1X84y1Q7wV
- en: '![](img/a6e82a7e40b8f10bedf5eedaad6d0492_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6e82a7e40b8f10bedf5eedaad6d0492_0.png)'
- en: Before we start I gave the same talk at Stanford quite recentlyã€‚I suggested
    to the people inviting me I could just give one talk and both audiences come but
    they will prefer it as two separate talks so if you went to this talk recently
    I suggest you leave now you won't learn anything newã€‚
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘æœ€è¿‘åœ¨æ–¯å¦ç¦åšäº†åŒæ ·çš„æ¼”è®²ã€‚æˆ‘å»ºè®®é‚€è¯·æˆ‘çš„äººå¯ä»¥è®©æˆ‘åªåšä¸€æ¬¡æ¼”è®²ï¼Œè®©ä¸¤ä¸ªè§‚ä¼—ä¸€èµ·å‚ä¸ï¼Œä½†ä»–ä»¬æ›´å¸Œæœ›åˆ†å¼€æˆä¸¤åœºæ¼”è®²ã€‚æ‰€ä»¥å¦‚æœä½ æœ€è¿‘å‚åŠ äº†è¿™ä¸ªæ¼”è®²ï¼Œæˆ‘å»ºè®®ä½ ç°åœ¨ç¦»å¼€ï¼Œä½ ä¸ä¼šå­¦åˆ°ä»»ä½•æ–°ä¸œè¥¿ã€‚
- en: '![](img/a6e82a7e40b8f10bedf5eedaad6d0492_2.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6e82a7e40b8f10bedf5eedaad6d0492_2.png)'
- en: Okayã€‚å—¯ã€‚What I'm going to do is combine some recent ideas in neural networksã€‚To
    try to explain how a neural network could represent parthole hierarchiesã€‚Without
    violating any of the basic principles of how neurons workã€‚And I'm going toã€‚IEx
    these ideas in terms of an imaginary systemã€‚I started writing a design document
    for a system and in the end I decided the design document by itself was quite
    interestingã€‚
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ã€‚å—¯ã€‚æˆ‘å°†ç»“åˆä¸€äº›å…³äºç¥ç»ç½‘ç»œçš„æœ€æ–°æƒ³æ³•ï¼Œå°è¯•è§£é‡Šä¸€ä¸ªç¥ç»ç½‘ç»œå¦‚ä½•è¡¨ç¤ºéƒ¨åˆ†-æ•´ä½“å±‚æ¬¡ç»“æ„ï¼Œè€Œä¸è¿åç¥ç»å…ƒå·¥ä½œçš„åŸºæœ¬åŸåˆ™ã€‚æˆ‘å°†é€šè¿‡ä¸€ä¸ªå‡æƒ³ç³»ç»Ÿæ¥è§£é‡Šè¿™äº›æƒ³æ³•ã€‚æˆ‘å¼€å§‹ä¸ºä¸€ä¸ªç³»ç»Ÿå†™è®¾è®¡æ–‡æ¡£ï¼Œæœ€åæˆ‘å†³å®šè¿™ä¸ªè®¾è®¡æ–‡æ¡£æœ¬èº«ç›¸å½“æœ‰è¶£ã€‚
- en: so this is just vapourware stuff that doesn't exist little bits of it not exist
    butã€‚Somehow I find it easy to explain the ideas in the context of an imaginary
    systemã€‚So most people now studying neural networks are doing engineering and they
    don't really care if it's exactly how the brain worksã€‚they're not trying to understand
    how the brain worksï¼Œ they're trying to make cool technologyã€‚
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™åªæ˜¯ä¸€ç§è™šå¹»çš„ä¸œè¥¿ï¼Œå®é™…ä¸Šå¹¶ä¸å­˜åœ¨ï¼Œåªæœ‰å°éƒ¨åˆ†ä¸çœŸå®ã€‚ä½†ä¸çŸ¥ä¸ºä½•ï¼Œæˆ‘å‘ç°å¾ˆå®¹æ˜“åœ¨ä¸€ä¸ªå‡æƒ³ç³»ç»Ÿçš„èƒŒæ™¯ä¸‹è§£é‡Šè¿™äº›æƒ³æ³•ã€‚æ‰€ä»¥ï¼Œç°åœ¨å¤§å¤šæ•°å­¦ä¹ ç¥ç»ç½‘ç»œçš„äººéƒ½åœ¨åšå·¥ç¨‹ï¼Œä»–ä»¬å¹¶ä¸åœ¨æ„è¿™æ˜¯å¦æ­£æ˜¯å¤§è„‘çš„å·¥ä½œæ–¹å¼ã€‚ä»–ä»¬å¹¶ä¸æ˜¯åœ¨è¯•å›¾ç†è§£å¤§è„‘æ˜¯å¦‚ä½•è¿ä½œçš„ï¼Œè€Œæ˜¯åœ¨åŠªåŠ›åˆ›é€ é…·ç‚«çš„æŠ€æœ¯ã€‚
- en: And so 100 layers is fine in a ressonnetï¼Œ weight sharing is fine in the convolutionary
    neuraletteã€‚Some researchersï¼Œ particularly computational neuroscientistsï¼Œ investigate
    neural networksã€‚artificial neural networks in an attempt to understand how the
    brain might actually workã€‚I think weve still got a lot to learn from the brainã€‚
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨ä¸€ä¸ªæ®‹å·®ç½‘ç»œä¸­ï¼Œ100 å±‚æ˜¯å¯ä»¥çš„ï¼Œå·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æƒé‡å…±äº«ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚ä¸€äº›ç ”ç©¶äººå‘˜ï¼Œç‰¹åˆ«æ˜¯è®¡ç®—ç¥ç»ç§‘å­¦å®¶ï¼Œç ”ç©¶ç¥ç»ç½‘ç»œï¼Œè¯•å›¾ç†è§£å¤§è„‘å¯èƒ½çš„å·¥ä½œæ–¹å¼ã€‚æˆ‘è®¤ä¸ºæˆ‘ä»¬ä»ç„¶æœ‰å¾ˆå¤šä¸œè¥¿å¯ä»¥å‘å¤§è„‘å­¦ä¹ ã€‚
- en: And I think it's worth remembering that for about half a centuryã€‚the only thing
    that kept research on neural networks going was the belief that it must be possible
    to make these things learn complicated things because the brain doesã€‚Soã€‚Every
    image has a different pass treeï¼Œ that is the structure of the holes and the parts
    in the imageã€‚And in a real neural networkï¼Œ you can't dynamically allocateã€‚
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºå€¼å¾—è®°ä½çš„æ˜¯ï¼Œåœ¨å¤§çº¦åŠä¸ªä¸–çºªçš„æ—¶é—´é‡Œï¼Œæ¨åŠ¨ç¥ç»ç½‘ç»œç ”ç©¶çš„å”¯ä¸€åŠ¨åŠ›å°±æ˜¯ç›¸ä¿¡è¿™äº›ä¸œè¥¿èƒ½å¤Ÿå­¦ä¹ å¤æ‚çš„å†…å®¹ï¼Œå› ä¸ºå¤§è„‘å¯ä»¥ã€‚æ‰€ä»¥ï¼Œæ¯ä¸ªå›¾åƒéƒ½æœ‰ä¸€ä¸ªä¸åŒçš„é€šè·¯æ ‘ï¼Œè¿™å°±æ˜¯å›¾åƒä¸­å­”å’Œéƒ¨åˆ†çš„ç»“æ„ã€‚åœ¨ä¸€ä¸ªçœŸæ­£çš„ç¥ç»ç½‘ç»œä¸­ï¼Œä½ ä¸èƒ½åŠ¨æ€åˆ†é…ã€‚
- en: you can't just grab a bunch of neurons and sayï¼Œ okayï¼Œ you now represent thisã€‚Because
    you don't have random excess memoryï¼Œ you can't just set the weights of the neurons
    to be whatever you like What a neuron does is determined by its connections and
    they only change slowlyã€‚
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¸èƒ½éšä¾¿æŠ“ä¸€å †ç¥ç»å…ƒè¯´ï¼Œå¥½å§ï¼Œä½ ç°åœ¨ä»£è¡¨è¿™ä¸ªã€‚å› ä¸ºä½ æ²¡æœ‰éšæœºçš„é¢å¤–è®°å¿†ï¼Œä½ ä¸èƒ½éšæ„è®¾ç½®ç¥ç»å…ƒçš„æƒé‡ã€‚ç¥ç»å…ƒçš„åŠŸèƒ½æ˜¯ç”±å®ƒçš„è¿æ¥å†³å®šçš„ï¼Œè€Œè¿™äº›è¿æ¥å˜åŒ–ç¼“æ…¢ã€‚
- en: At least probably mostly the change slightlyã€‚å—¯ã€‚So the question is if you can't
    change what neurons do quicklyã€‚How can you represent a dynamic past treeï¼ŸIn symbolic
    AI it's not a problemã€‚you just grab a piece of memory that's what it normally
    amounts to and say this is going to represent a node in the past and I'm going
    to give it pointers to other nodesã€‚other bits of memory that represent other nodesï¼Œ
    so there's no problemã€‚For about five yearsã€‚
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³å°‘å˜åŒ–å¤§å¤šæ˜¯è½»å¾®çš„ã€‚å—¯ã€‚æ‰€ä»¥é—®é¢˜æ˜¯ï¼Œå¦‚æœä½ ä¸èƒ½å¿«é€Ÿæ”¹å˜ç¥ç»å…ƒçš„åŠŸèƒ½ï¼Œå¦‚ä½•è¡¨ç¤ºä¸€ä¸ªåŠ¨æ€çš„é€šè·¯æ ‘ï¼Ÿåœ¨ç¬¦å·äººå·¥æ™ºèƒ½ä¸­ï¼Œè¿™ä¸æ˜¯é—®é¢˜ã€‚ä½ åªéœ€æŠ“å–ä¸€å—å†…å­˜ï¼Œè¿™é€šå¸¸å°±æ˜¯å…¶æœ¬è´¨ï¼Œè¯´æ˜è¿™å°†ä»£è¡¨é€šè·¯ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå¹¶ç»™å®ƒæŒ‡å‘å…¶ä»–èŠ‚ç‚¹çš„æŒ‡é’ˆã€‚å…¶ä»–å†…å­˜å—è¡¨ç¤ºå…¶ä»–èŠ‚ç‚¹ï¼Œå› æ­¤æ²¡æœ‰é—®é¢˜ã€‚å¤§çº¦äº”å¹´ã€‚
- en: I played with a theory called capsulesã€‚Whereã€‚You say because you can't allocate
    neurons on the flyã€‚you're going to allocate them in advanceï¼Œ so we're going to
    take groups of neurons and we're going to allocate them to different possible
    nodes in a poitoryã€‚
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ›¾å°è¯•ä¸€ç§åä¸ºèƒ¶å›Šçš„ç†è®ºã€‚ä½ å¯ä»¥è¯´ï¼Œç”±äºä¸èƒ½åŠ¨æ€åˆ†é…ç¥ç»å…ƒï¼Œå› æ­¤ä½ å°†æå‰åˆ†é…å®ƒä»¬ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†æŠŠä¸€ç»„ç¥ç»å…ƒåˆ†é…åˆ°æ½œåœ¨èŠ‚ç‚¹ä¸­ã€‚
- en: And most of these groups of neurons for most images are going to be silentã€‚a
    few are going to be activeã€‚And then the ones that are activeã€‚we have to dynamically
    hook them up into a past treeã€‚so we have to have a way of roing between these
    groups of neuronsã€‚So that was the capsules theoryã€‚
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤§å¤šæ•°å›¾åƒï¼Œè¿™äº›ç¥ç»å…ƒç»„ä¸­çš„å¤§å¤šæ•°å°†æ˜¯é™é»˜çš„ã€‚å°‘æ•°ä¼šå¤„äºæ´»åŠ¨çŠ¶æ€ã€‚è€Œå¯¹äºé‚£äº›æ´»è·ƒçš„ç¥ç»å…ƒï¼Œæˆ‘ä»¬å¿…é¡»åŠ¨æ€åœ°å°†å®ƒä»¬è¿æ¥åˆ°ä¸€ä¸ªæ ‘çŠ¶ç»“æ„ä¸­ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»æœ‰ä¸€ç§æ–¹æ³•æ¥åœ¨è¿™äº›ç¥ç»å…ƒç»„ä¹‹é—´è¿›è¡Œè¿æ¥ã€‚è¿™å°±æ˜¯èƒ¶å›Šç†è®ºã€‚
- en: And I had some very competent people working with me who actually made it workã€‚but
    it was tough goingã€‚My view is the side ideas want to work and some ideas don't
    want to work and capsules were sort of in between things like back propagation
    just want to work you try them and they work there's other ideas I've had that
    just don't want to work capsules were sort of in between and we got it workingã€‚
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æœ‰ä¸€äº›éå¸¸æœ‰èƒ½åŠ›çš„äººä¸æˆ‘åˆä½œï¼Œä»–ä»¬å®é™…ä¸Šä½¿è¿™ä¸€åˆ‡å·¥ä½œã€‚ä½†è¿‡ç¨‹ç›¸å½“è‰°éš¾ã€‚æˆ‘çš„çœ‹æ³•æ˜¯ï¼ŒæŸäº›å‰¯æƒ³æ³•æƒ³è¦å‘æŒ¥ä½œç”¨ï¼Œè€Œæœ‰äº›æƒ³æ³•åˆ™ä¸æ„¿æ„å·¥ä½œï¼Œè€Œèƒ¶å›Šç†è®ºåˆ™ä»‹äºä¸¤è€…ä¹‹é—´ï¼Œæ¯”å¦‚åå‘ä¼ æ’­è¿™æ ·çš„æƒ³æ³•åˆ™æƒ³è¦å·¥ä½œï¼Œä½ å°è¯•å®ƒä»¬ï¼Œå®ƒä»¬å°±ä¼šæœ‰æ•ˆï¼Œè€Œæˆ‘æœ‰äº›å…¶ä»–æƒ³æ³•å°±æ˜¯ä¸æ„¿æ„å·¥ä½œï¼Œèƒ¶å›Šç†è®ºåˆ™åœ¨ä¸¤è€…ä¹‹é—´ï¼Œæˆ‘ä»¬æœ€ç»ˆä½¿å®ƒå·¥ä½œäº†ã€‚
- en: But I now have a new theory that could be seen as a funny kind of capsules model
    in which each capsule is universalã€‚that is instead of a capsule being dedicated
    to a particular kind of thingã€‚Each capsule can represent any kind of thingã€‚But
    hardware still comes in capsulesã€‚Which are also called embedding sometimesã€‚Soã€‚The
    imaginary system I'll talk about is called Gmã€‚
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ç°åœ¨æœ‰ä¸€ä¸ªæ–°çš„ç†è®ºï¼Œå¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§å¥‡æ€ªçš„èƒ¶å›Šæ¨¡å‹ï¼Œå…¶ä¸­æ¯ä¸ªèƒ¶å›Šæ˜¯é€šç”¨çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸å…¶å°†èƒ¶å›Šä¸“ç”¨äºæŸç§ç‰¹å®šçš„äº‹ç‰©ï¼Œæ¯ä¸ªèƒ¶å›Šå¯ä»¥è¡¨ç¤ºä»»ä½•ç§ç±»çš„äº‹ç‰©ã€‚ä½†æ˜¯ç¡¬ä»¶ä»ç„¶ä»¥èƒ¶å›Šçš„å½¢å¼å‡ºç°ï¼Œè¿™ç§èƒ¶å›Šæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºåµŒå…¥ã€‚å› æ­¤ï¼Œæˆ‘å°†è°ˆè®ºçš„è™šæ‹Ÿç³»ç»Ÿç§°ä¸ºGmã€‚
- en: And in Gamã€‚Hardware gets allocated to columnsã€‚And each column contains multiple
    levels of representation of what's happening in a small patch of the imageã€‚So
    within a columnï¼Œ you might have a lower level representation that says it's a
    nostrilã€‚And the next level up might say it's a nose and the next level up might
    say a faceã€‚the next level up a person on the top level might say it's a partyï¼Œ
    that's what the whole scene isã€‚
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Gamä¸­ï¼Œç¡¬ä»¶åˆ†é…ç»™åˆ—ã€‚æ¯åˆ—åŒ…å«å¯¹å›¾åƒå°è¡¥ä¸ä¸­å‘ç”Ÿçš„äº‹æƒ…çš„å¤šä¸ªå±‚æ¬¡çš„è¡¨ç¤ºã€‚å› æ­¤ï¼Œåœ¨ä¸€åˆ—ä¸­ï¼Œä½ å¯èƒ½æœ‰ä¸€ä¸ªè¾ƒä½å±‚æ¬¡çš„è¡¨ç¤ºï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªé¼»å­”ã€‚æ¥ä¸‹æ¥çš„å±‚æ¬¡å¯èƒ½è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªé¼»å­ï¼Œå†å¾€ä¸Šå±‚å¯èƒ½è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªè„¸ï¼Œé¡¶å±‚å¯èƒ½è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªæ´¾å¯¹ï¼Œè¿™å°±æ˜¯æ•´ä¸ªåœºæ™¯ã€‚
- en: And the idea for representing part hollow hierarchies is to use islands of agreement
    between the embeddings at these different levelsã€‚So at the scene levelï¼Œ at the
    top levelï¼Œ you'd like the same embedding for every patch of the image because
    that patch is a patch of the same scene everywhereã€‚
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ç¤ºéƒ¨åˆ†ç©ºå¿ƒå±‚æ¬¡ç»“æ„çš„æƒ³æ³•æ˜¯åˆ©ç”¨è¿™äº›ä¸åŒå±‚æ¬¡çš„åµŒå…¥ä¹‹é—´çš„å…±è¯†å²›å±¿ã€‚å› æ­¤ï¼Œåœ¨åœºæ™¯å±‚é¢ï¼Œåœ¨é¡¶å±‚ï¼Œä½ å¸Œæœ›å›¾åƒçš„æ¯ä¸ªè¡¥ä¸éƒ½æœ‰ç›¸åŒçš„åµŒå…¥ï¼Œå› ä¸ºè¯¥è¡¥ä¸æ˜¯åŒä¸€åœºæ™¯çš„è¡¥ä¸ã€‚
- en: At the object levelï¼Œ you'd like the embeddings of all the different patches
    that belong to the object to be the sameã€‚So as you go up this hierarchï¼Œ you're
    trying to make things more and more the sameã€‚And that's how you're squeezing redundancy
    outã€‚The embedding vectors are the things that act like pointers and the embedding
    vectors are dynamicã€‚they're neural activations rather than neural weightsã€‚
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯¹è±¡å±‚é¢ä¸Šï¼Œä½ å¸Œæœ›å±äºè¯¥å¯¹è±¡çš„æ‰€æœ‰ä¸åŒè¡¥ä¸çš„åµŒå…¥éƒ½æ˜¯ç›¸åŒçš„ã€‚å› æ­¤ï¼Œéšç€ä½ å‘ä¸Šç§»åŠ¨è¿™ä¸ªå±‚æ¬¡ç»“æ„ï¼Œä½ è¯•å›¾è®©äº‹ç‰©è¶Šæ¥è¶Šç›¸ä¼¼ã€‚è¿™å°±æ˜¯ä½ æŒ¤å‹å†—ä½™çš„æ–¹å¼ã€‚åµŒå…¥å‘é‡åƒæŒ‡é’ˆä¸€æ ·èµ·ä½œç”¨ï¼ŒåµŒå…¥å‘é‡æ˜¯åŠ¨æ€çš„ã€‚å®ƒä»¬æ˜¯ç¥ç»æ¿€æ´»è€Œä¸æ˜¯ç¥ç»æƒé‡ã€‚
- en: so it's fine to have different embedding vectors for every imageã€‚So here's a
    little picture if you had a one dimensional row of patchesã€‚These are the columns
    for the patchesã€‚Andã€‚You'd have something like a convolution on neuralness as the
    front endã€‚And then after the front end you produce your lowest level embeddings
    to say what's going on in each particular patch and so that bottom layer of black
    arrows they all different Of course these embeddings are thousands of dimensionsã€‚
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸ºæ¯ä¸ªå›¾åƒæ‹¥æœ‰ä¸åŒçš„åµŒå…¥å‘é‡æ˜¯å¯ä»¥çš„ã€‚è¿™æ˜¯ä¸€ä¸ªå°å›¾ç¤ºï¼Œå¦‚æœä½ æœ‰ä¸€ä¸ªä¸€ç»´çš„è¡¥ä¸è¡Œã€‚è¿™äº›æ˜¯è¡¥ä¸çš„åˆ—ã€‚è€Œä¸”ï¼Œä½ ä¼šæœ‰ç±»ä¼¼äºç¥ç»ç½‘ç»œå‰ç«¯çš„å·ç§¯ã€‚ç„¶ååœ¨å‰ç«¯ä¹‹åï¼Œä½ ç”Ÿæˆæœ€ä½çº§åˆ«çš„åµŒå…¥ï¼Œä»¥è¯´æ˜æ¯ä¸ªç‰¹å®šè¡¥ä¸ä¸­å‘ç”Ÿäº†ä»€ä¹ˆï¼Œå› æ­¤åº•å±‚çš„é»‘è‰²ç®­å¤´éƒ½ä¸åŒã€‚å½“ç„¶ï¼Œè¿™äº›åµŒå…¥æ˜¯æˆåƒä¸Šä¸‡ç»´çš„ã€‚
- en: Maybe hundreds of thousands in your brainã€‚And so a two dimensional vectorã€‚Isn't
    rightã€‚but at least I can represent whether two vectors are the same by using the
    orientationã€‚So at the lowest levelï¼Œ all the patches will have different representationsã€‚But
    the next level upã€‚The first two patchesï¼Œ they might be part of a nostrilï¼Œ for
    exampleã€‚And soã€‚å—¯ã€‚Yeahã€‚
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸åœ¨ä½ å¤§è„‘ä¸­æœ‰æˆåƒä¸Šä¸‡çš„è¿™ç§æƒ…å†µã€‚å› æ­¤ï¼ŒäºŒç»´å‘é‡å¹¶ä¸å‡†ç¡®ã€‚ä½†è‡³å°‘æˆ‘å¯ä»¥é€šè¿‡æ–¹å‘æ¥è¡¨ç¤ºä¸¤ä¸ªå‘é‡æ˜¯å¦ç›¸åŒã€‚æ‰€ä»¥åœ¨æœ€ä½å±‚é¢ï¼Œæ‰€æœ‰çš„è¡¥ä¸éƒ½ä¼šæœ‰ä¸åŒçš„è¡¨ç¤ºã€‚ä½†ä¸‹ä¸€ä¸ªå±‚é¢ï¼Œå‰ä¸¤ä¸ªè¡¥ä¸ï¼Œå®ƒä»¬å¯èƒ½æ˜¯é¼»å­”çš„ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ã€‚å—¯ã€‚æ˜¯çš„ã€‚
- en: they'll have the same embeddingã€‚But the next level upã€‚The first three patches
    might be part of a noseã€‚And so they'll all have the same embeddingã€‚Notice that
    even though what's in the image is quite differentã€‚At the part levelã€‚those three
    red vectors are all meant to be the sameã€‚
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬ä¼šæœ‰ç›¸åŒçš„åµŒå…¥ã€‚ä½†ä¸Šé¢çš„ä¸‹ä¸€ä¸ªå±‚é¢ï¼Œå‰ä¸‰ä¸ªè¡¥ä¸å¯èƒ½æ˜¯é¼»å­çš„éƒ¨åˆ†ã€‚æ‰€ä»¥å®ƒä»¬éƒ½ä¼šæœ‰ç›¸åŒçš„åµŒå…¥ã€‚æ³¨æ„ï¼Œå°½ç®¡å›¾åƒä¸­çš„å†…å®¹éå¸¸ä¸åŒï¼Œä½†åœ¨éƒ¨åˆ†å±‚é¢ä¸Šï¼Œé‚£ä¸‰ä¸ªçº¢è‰²å‘é‡éƒ½æ˜¯æ„å‘³ç€ç›¸åŒçš„ã€‚
- en: So what we're doing is we're getting the same representation for things that
    are superficially very differentã€‚ğŸ˜Šï¼ŒWe're finding spatial coherence in an image
    by giving the same representation to different thingsã€‚ğŸ˜Šï¼ŒAnd at the object levelï¼Œ
    you might have a nose and then a mouseã€‚And they're the same faceã€‚they're part
    of the same face and so all those vectors are the same and this network hasn't
    yet settled down to produce on the unseen levelã€‚
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨åšçš„æ˜¯ä¸ºè¡¨é¢ä¸Šéå¸¸ä¸åŒçš„äº‹ç‰©è·å–ç›¸åŒçš„è¡¨ç¤ºã€‚ğŸ˜Šæˆ‘ä»¬é€šè¿‡ç»™äºˆä¸åŒäº‹ç‰©ç›¸åŒçš„è¡¨ç¤ºæ¥å¯»æ‰¾å›¾åƒä¸­çš„ç©ºé—´ä¸€è‡´æ€§ã€‚ğŸ˜Šåœ¨ç‰©ä½“å±‚é¢ä¸Šï¼Œä½ å¯èƒ½æœ‰ä¸€ä¸ªé¼»å­å’Œä¸€ä¸ªè€é¼ ã€‚å®ƒä»¬æ˜¯åŒä¸€å¼ è„¸ï¼Œå®ƒä»¬æ˜¯åŒä¸€å¼ è„¸çš„ä¸€éƒ¨åˆ†ï¼Œå› æ­¤æ‰€æœ‰è¿™äº›å‘é‡éƒ½æ˜¯ç›¸åŒçš„ï¼Œè€Œè¿™ä¸ªç½‘ç»œå°šæœªç¨³å®šåˆ°äº§ç”Ÿçœ‹ä¸è§çš„å±‚é¢ã€‚
- en: So the islands of agreement are what capture the past treeã€‚now they're a bit
    more powerful than a past treeï¼Œ they can capture things like shut the heck upã€‚You
    can have shut an up can be different vectors at one levelï¼Œ but at a higher levelã€‚shut
    an up can have exactly the same vectorï¼Œ namely the vector for shut upã€‚
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä¸€è‡´æ€§çš„å²›å±¿æ•æ‰åˆ°äº†è¿‡å»çš„æ ‘ã€‚ç°åœ¨å®ƒä»¬æ¯”è¿‡å»çš„æ ‘æ›´å¼ºå¤§ï¼Œå®ƒä»¬å¯ä»¥æ•æ‰åƒâ€œé—­å˜´â€è¿™æ ·çš„ä¸œè¥¿ã€‚ä½ å¯ä»¥åœ¨ä¸€ä¸ªå±‚é¢ä¸Šå°†â€œé—­â€ä¸â€œå˜´â€çœ‹ä½œä¸åŒçš„å‘é‡ï¼Œä½†åœ¨æ›´é«˜å±‚é¢ä¸Šï¼Œâ€œé—­å˜´â€å¯ä»¥æœ‰å®Œå…¨ç›¸åŒçš„å‘é‡ï¼Œå³â€œé—­å˜´â€çš„å‘é‡ã€‚
- en: And they can be disconnected so you can do things a bit more powerful than a
    context free grammar hereã€‚but basically it's a past trueã€‚If you're a physicistã€‚You
    can think of each of these levels as an icing modelã€‚With real valued vectors rather
    than binary spinsã€‚And you can think of them being coordinate transforms between
    levelsã€‚
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬å¯ä»¥æ˜¯æ–­å¼€çš„ï¼Œæ‰€ä»¥ä½ å¯ä»¥åœ¨è¿™é‡Œåšä¸€äº›æ¯”ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•æ›´å¼ºå¤§çš„äº‹æƒ…ã€‚ä½†åŸºæœ¬ä¸Šï¼Œå®ƒæ˜¯ä¸€ä¸ªè¿‡å»çš„çœŸå®ã€‚å¦‚æœä½ æ˜¯ç‰©ç†å­¦å®¶ï¼Œä½ å¯ä»¥å°†æ¯ä¸ªå±‚é¢è§†ä¸ºä¸€ä¸ªå†°æ·‡æ·‹æ¨¡å‹ã€‚ç”¨å®å€¼å‘é‡è€Œä¸æ˜¯äºŒè¿›åˆ¶è‡ªæ—‹ã€‚ä½ å¯ä»¥è®¤ä¸ºå®ƒä»¬æ˜¯å±‚é—´çš„åæ ‡å˜æ¢ã€‚
- en: which makes it much more complicatedï¼Œ and then this is a kind of multi level
    icing modelã€‚But with complicated interactions between the levelsï¼Œ becauseï¼Œ for
    exampleã€‚between the red arrows and the black arrows above themã€‚you need the coordinate
    transform between a nose and a faceï¼Œ but we'll come to that laterã€‚
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—æƒ…å†µæ›´åŠ å¤æ‚ï¼Œè¿™æ˜¯ä¸€ç§å¤šå±‚æ¬¡çš„å†°æ·‡æ·‹æ¨¡å‹ã€‚ä½†æ˜¯å„å±‚ä¹‹é—´æœ‰å¤æ‚çš„äº’åŠ¨ï¼Œå› ä¸ºï¼Œä¾‹å¦‚ã€‚åœ¨ä¸Šé¢çš„çº¢è‰²ç®­å¤´å’Œé»‘è‰²ç®­å¤´ä¹‹é—´ã€‚ä½ éœ€è¦åœ¨é¼»å­å’Œè„¸ä¹‹é—´è¿›è¡Œåæ ‡å˜æ¢ï¼Œä½†æˆ‘ä»¬ç¨åä¼šè®¨è®ºè¿™ä¸ªã€‚
- en: If you're not a physicistï¼Œ ignore all that because it won't helpã€‚So I want to
    start and this is I guess is particularly relevant for a natural language course
    where you're some of you are not vision peopleã€‚By trying to prove to you that
    coordinate systems are not just something invented by Descarteã€‚coordinate systems
    were invented by the brain a long time agoã€‚
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸æ˜¯ç‰©ç†å­¦å®¶ï¼Œé‚£å°±å¿½ç•¥è¿™äº›ï¼Œå› ä¸ºè¿™æ²¡æœ‰å¸®åŠ©ã€‚æ‰€ä»¥æˆ‘æƒ³å¼€å§‹ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªç„¶è¯­è¨€è¯¾ç¨‹ä¸­ï¼Œå¯¹ä½ ä»¬ä¸­çš„ä¸€äº›äººæ¥è¯´ï¼Œè¿™å°¤å…¶ç›¸å…³ã€‚é€šè¿‡è¯•å›¾è¯æ˜åæ ‡ç³»ç»Ÿä¸ä»…ä»…æ˜¯ç¬›å¡å°”å‘æ˜çš„ã€‚åæ ‡ç³»ç»Ÿæ—©åœ¨å¾ˆä¹…ä»¥å‰å°±ç”±å¤§è„‘å‘æ˜äº†ã€‚
- en: and we use coordinate systems in understanding what's going on in an imageã€‚I
    also want to demonstrate the psychological reality of past trees for an imageã€‚So
    I'm going to do this with a task that I invented a long time agoã€‚In the 1970s
    when I was a grad studentï¼Œ in factã€‚And you have to do this task to get that full
    benefit from itã€‚
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç†è§£å›¾åƒä¸­çš„å†…å®¹æ—¶ä½¿ç”¨åæ ‡ç³»ç»Ÿã€‚æˆ‘è¿˜æƒ³å±•ç¤ºå›¾åƒä¸­è¿‡å»æ ‘çš„å¿ƒç†ç°å®ã€‚æ‰€ä»¥æˆ‘å°†ç”¨ä¸€ä¸ªæˆ‘å¾ˆä¹…ä»¥å‰å‘æ˜çš„ä»»åŠ¡æ¥è¿›è¡Œæ¼”ç¤ºã€‚äº‹å®ä¸Šæ˜¯åœ¨1970å¹´ä»£ï¼Œå½“æ—¶æˆ‘è¿˜æ˜¯ç ”ç©¶ç”Ÿã€‚ä½ éœ€è¦å®Œæˆè¿™ä¸ªä»»åŠ¡æ‰èƒ½å……åˆ†å—ç›Šäºå®ƒã€‚
- en: So I want you to imagine on the tabletop in front of youï¼Œ there's a wireframe
    cubeã€‚And it's in the standard orientation for a cube is resting on the tabletopã€‚And
    from your point of viewã€‚There's a front bottom right hand cornerã€‚And a top back
    left hand cornerã€‚here we goã€‚okã€‚The front bottom right hand corner is resting on
    the tabletop along with the four other cornersã€‚
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘æƒ³è®©ä½ æƒ³è±¡åœ¨ä½ é¢å‰çš„æ¡Œé¢ä¸Šï¼Œæœ‰ä¸€ä¸ªçº¿æ¡†ç«‹æ–¹ä½“ã€‚å®ƒå¤„äºç«‹æ–¹ä½“çš„æ ‡å‡†æœå‘ï¼Œé™é™åœ°æ”¾åœ¨æ¡Œé¢ä¸Šã€‚ä»ä½ çš„è§†è§’æ¥çœ‹ï¼Œæœ‰ä¸€ä¸ªå‰ä¸‹å³è§’å’Œä¸€ä¸ªåä¸Šå·¦è§’ã€‚å¥½äº†ï¼Œå¼€å§‹å§ã€‚å‰ä¸‹å³è§’å’Œå…¶ä»–å››ä¸ªè§’ä¸€æ ·ï¼Œéƒ½åœ¨æ¡Œé¢ä¸Šã€‚
- en: And the top back left hand corner is at the other end of a diagonal that goes
    through the center of the cubeã€‚Okayï¼Œ so far so goodã€‚Now what we're going to do
    is rotate the cube so that this finger stays on the tabletopã€‚And the other finger
    is vertically above it like thatã€‚ğŸ˜Šï¼ŒThis finger shouldn't have movedã€‚okã€‚So now
    we've got the cube in an orientation where that thing that was a body diagon is
    now verticalã€‚
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œåä¸Šå·¦è§’ä½äºç©¿è¿‡ç«‹æ–¹ä½“ä¸­å¿ƒçš„å¯¹è§’çº¿çš„å¦ä¸€ç«¯ã€‚å¥½çš„ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ä¸€åˆ‡é¡ºåˆ©ã€‚ç°åœ¨æˆ‘ä»¬è¦åšçš„æ˜¯æ—‹è½¬ç«‹æ–¹ä½“ï¼Œä½¿å¾—è¿™ä¸ªæ‰‹æŒ‡ä¿æŒåœ¨æ¡Œé¢ä¸Šï¼Œå¦ä¸€ä¸ªæ‰‹æŒ‡å‚ç›´åœ°æŒ‡åœ¨å®ƒä¸Šæ–¹ã€‚ğŸ˜Šï¼Œè¿™ä¸ªæ‰‹æŒ‡ä¸åº”è¯¥ç§»åŠ¨ã€‚å¥½çš„ã€‚ç°åœ¨æˆ‘ä»¬æŠŠç«‹æ–¹ä½“æ”¾åœ¨ä¸€ä¸ªæœå‘ä¸Šï¼Œä½¿å¾—åŸæœ¬æ˜¯å¯¹è§’çº¿çš„ä¸œè¥¿ç°åœ¨æ˜¯å‚ç›´çš„ã€‚
- en: And all you've got to do is take the bottom finger because that's still on the
    tabletop and point with the bottom finger to where the other corners of the cubeã€‚So
    I want you to actually do it off you goï¼Œ take your bottom fingerã€‚hold your top
    finger at the other end of that diagonal that's now be made political and just
    point to where the other corners areã€‚Andã€‚Luckily zoom so most of youï¼Œ other people
    won't be able to see what you did and I can see that some of you aren't pointing
    and that's very badã€‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¦åšçš„å°±æ˜¯ç”¨åº•éƒ¨çš„æ‰‹æŒ‡ï¼Œå› ä¸ºå®ƒä»ç„¶åœ¨æ¡Œé¢ä¸Šï¼ŒæŒ‡å‘ç«‹æ–¹ä½“çš„å…¶ä»–è§’ã€‚æ‰€ä»¥æˆ‘å¸Œæœ›ä½ å®é™…å»åšï¼Œæ¥å§ï¼Œæ‹¿èµ·ä½ çš„åº•éƒ¨æ‰‹æŒ‡ã€‚æŠŠä½ çš„é¡¶éƒ¨æ‰‹æŒ‡æ”¾åœ¨é‚£æ¡å¯¹è§’çº¿çš„å¦ä¸€ç«¯ï¼Œç„¶åæŒ‡å‘å…¶ä»–è§’åœ¨å“ªé‡Œã€‚å¹¸è¿çš„æ˜¯ï¼Œå¤§å¤šæ•°ä½ ä»¬ï¼Œå…¶ä»–äººå¯èƒ½çœ‹ä¸åˆ°ä½ åšäº†ä»€ä¹ˆï¼Œæˆ‘å¯ä»¥çœ‹åˆ°ä½ ä»¬ä¸­æœ‰äº›äººæ²¡æœ‰æŒ‡ï¼Œè¿™éå¸¸ç³Ÿç³•ã€‚
- en: So most peopleã€‚Point out four other corners and the most common response is
    to say they're hereã€‚hereï¼Œ here and hereï¼Œ they point out four corners in a square
    halfway at that axisã€‚å—¯ã€‚That's wrongã€‚as you might imagineï¼Œ and it's easy to see
    that it's wrong because if you imagine the cubeã€‚the normal orientationã€‚And camp
    the cornersï¼Œ there's eight of themã€‚And these were two cornersã€‚
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¤§å¤šæ•°äººä¼šæŒ‡å‡ºå…¶ä»–å››ä¸ªè§’ï¼Œæœ€å¸¸è§çš„ååº”æ˜¯è¯´å®ƒä»¬åœ¨è¿™é‡Œã€è¿™é‡Œã€è¿™é‡Œå’Œè¿™é‡Œï¼Œä»–ä»¬åœ¨é‚£æ¡è½´çš„ä¸­é—´ç”»å‡ºä¸€ä¸ªæ­£æ–¹å½¢çš„å››ä¸ªè§’ã€‚å—¯ã€‚è¿™æ˜¯é”™è¯¯çš„ã€‚æ­£å¦‚ä½ æ‰€æƒ³è±¡çš„é‚£æ ·ï¼Œå¾ˆå®¹æ˜“çœ‹å‡ºè¿™æ˜¯é”™è¯¯çš„ï¼Œå› ä¸ºå¦‚æœä½ æƒ³è±¡è¿™ä¸ªç«‹æ–¹ä½“ï¼Œæ­£å¸¸çš„æœå‘ï¼Œå¹¶ä¸”æ•°è§’ï¼Œä¸€å…±æœ‰å…«ä¸ªè§’ã€‚è€Œè¿™ä¸¤ä¸ªè§’å°±æ˜¯å…¶ä¸­ä¹‹ä¸€ã€‚
- en: So where did the other two corners goï¼ŸSo one theory is that when you rotated
    the cubeã€‚the centpetal forces made them fly off into your unconsciousï¼Œ that's
    not a very good theoryã€‚Soã€‚What's happening here is you have no idea where the
    other corners are unless you're something like a crystallographerã€‚You can sort
    of imagine bits of the cubeï¼Œ but you just can't imagine this structure of the
    other cornersã€‚
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆå…¶ä»–ä¸¤ä¸ªè§’å»å“ªé‡Œäº†å‘¢ï¼Ÿæœ‰ä¸€ç§ç†è®ºè®¤ä¸ºï¼Œå½“ä½ æ—‹è½¬ç«‹æ–¹ä½“æ—¶ï¼Œç¦»å¿ƒåŠ›ä½¿å®ƒä»¬é£å…¥ä½ çš„æ— æ„è¯†ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç†è®ºã€‚é‚£ä¹ˆï¼Œå‘ç”Ÿçš„äº‹æƒ…æ˜¯ï¼Œé™¤éä½ æ˜¯åƒç»“æ™¶å­¦å®¶é‚£æ ·çš„äººï¼Œå¦åˆ™ä½ å¯¹å…¶ä»–è§’çš„å»å‘æ¯«æ— å¤´ç»ªã€‚ä½ å¯ä»¥æƒ³è±¡ç«‹æ–¹ä½“çš„æŸäº›éƒ¨åˆ†ï¼Œä½†ä½ å°±æ˜¯æ— æ³•æƒ³è±¡å…¶ä»–è§’çš„ç»“æ„ã€‚
- en: what structure they formã€‚And this common response that people give are four
    corners in a squareã€‚Is doing something very weirdã€‚Is trying to is saying well
    okay I don't know I don't know whether it's of a cube bar but I know something
    about cubesã€‚I know the corners come in foursï¼Œ I know a cube has this fourfold
    rotational symmetry or two planes of bilateral symmetry but right angle s ratherã€‚And
    so what people do is they preserve the symmetries of the cube in their responseã€‚
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬å½¢æˆä»€ä¹ˆç»“æ„ã€‚è¿™ç§äººä»¬å¸¸è§çš„ååº”æ˜¯å››ä¸ªè§’åœ¨ä¸€ä¸ªæ­£æ–¹å½¢ä¸­ã€‚æ­£åœ¨åšä¸€äº›éå¸¸å¥‡æ€ªçš„äº‹æƒ…ã€‚è¯•å›¾è¯´ï¼Œå¥½çš„ï¼Œæˆ‘ä¸çŸ¥é“ç«‹æ–¹ä½“çš„æ ·å­ï¼Œä½†æˆ‘å¯¹ç«‹æ–¹ä½“æœ‰äº›äº†è§£ã€‚æˆ‘çŸ¥é“è§’æ˜¯æˆå››ä¸ªå‡ºç°çš„ï¼Œæˆ‘çŸ¥é“ç«‹æ–¹ä½“å…·æœ‰å››é‡æ—‹è½¬å¯¹ç§°æ€§æˆ–ä¸¤ä¸ªå¹³é¢çš„åŒä¾§å¯¹ç§°æ€§ï¼Œä½†éƒ½æ˜¯ç›´è§’çš„ã€‚å› æ­¤ï¼Œäººä»¬åœ¨å›åº”ä¸­ä¿æŒäº†ç«‹æ–¹ä½“çš„å¯¹ç§°æ€§ã€‚
- en: They give four corners in a squareã€‚Nowï¼Œ what they've actually pointed out if
    they do that is two pyramidsã€‚Each of which has a square baseï¼Œ one's upside downï¼Œ
    and they're stuck base to baseã€‚So you can visualize that quite easilyï¼Œ a square
    based pyramid with another one stuck underneath itã€‚And so now you get your two
    fingers as the vertices of those two pyramidsã€‚Andã€‚
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ç»™å‡ºäº†å››ä¸ªè§’åœ¨ä¸€ä¸ªæ­£æ–¹å½¢ä¸­ã€‚ç°åœ¨ï¼Œå¦‚æœä»–ä»¬è¿™æ ·åšï¼Œå®é™…ä¸Šä»–ä»¬æŒ‡çš„æ˜¯ä»€ä¹ˆæ˜¯ä¸¤ä¸ªé‡‘å­—å¡”ã€‚æ¯ä¸ªé‡‘å­—å¡”éƒ½æœ‰ä¸€ä¸ªæ­£æ–¹å½¢åº•é¢ï¼Œä¸€ä¸ªæ˜¯å€’è¿‡æ¥çš„ï¼Œå®ƒä»¬åº•å¯¹åº•åœ°ç²˜åœ¨ä¸€èµ·ã€‚æ‰€ä»¥ä½ å¯ä»¥å¾ˆå®¹æ˜“åœ°æƒ³è±¡ï¼Œä¸€ä¸ªæ­£æ–¹å½¢åº•é¢çš„é‡‘å­—å¡”ä¸‹é¢å†æœ‰ä¸€ä¸ªã€‚äºæ˜¯ç°åœ¨ä½ çš„ä¸¤ä¸ªæ‰‹æŒ‡ä½œä¸ºè¿™ä¸¤ä¸ªé‡‘å­—å¡”çš„é¡¶ç‚¹ã€‚
- en: What's interesting about that isã€‚You've preserved the symmetries of the cube
    at the cost of doing something pretty radicalã€‚which is changing faces to vertices
    and vertices to facesã€‚The thing you pointed out if you did that was an octtoahedronã€‚It
    has eight faces and six verticesã€‚the cube has six faces and eight verticesã€‚ğŸ˜Šï¼ŒSo
    in order to preserve the symmetries you know about of the cubeã€‚
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œä½ åœ¨åšä¸€äº›ç›¸å½“æ¿€è¿›çš„äº‹æƒ…çš„ä»£ä»·ä¸‹ï¼Œä¿ç•™äº†ç«‹æ–¹ä½“çš„å¯¹ç§°æ€§ï¼Œé‚£å°±æ˜¯å°†é¢å˜æˆé¡¶ç‚¹ï¼Œé¡¶ç‚¹å˜æˆé¢ã€‚ä½ æŒ‡å‡ºçš„äº‹æƒ…æ˜¯ï¼Œå¦‚æœä½ è¿™æ ·åšï¼Œå¾—åˆ°äº†ä¸€ä¸ªå…«é¢ä½“ã€‚å®ƒæœ‰å…«ä¸ªé¢å’Œå…­ä¸ªé¡¶ç‚¹ï¼Œè€Œç«‹æ–¹ä½“æœ‰å…­ä¸ªé¢å’Œå…«ä¸ªé¡¶ç‚¹ã€‚ğŸ˜Šæ‰€ä»¥ä¸ºäº†ä¿ç•™ä½ æ‰€çŸ¥é“çš„ç«‹æ–¹ä½“çš„å¯¹ç§°æ€§ã€‚
- en: You've if you did thatï¼Œ you've done something really radicalï¼Œ which has changed
    faces forversitiesã€‚andversities for facesã€‚å—¯ã€‚I should show you what the answer
    looks likeã€‚so I'm going to step back and try and get enough light and maybe you
    can see this cubeã€‚So this is a queueã€‚Andã€‚You can see that the other edgesã€‚
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿™æ ·åšäº†ï¼Œé‚£çœŸçš„å¾ˆæ¿€è¿›ï¼Œæ”¹å˜äº†é¢ä¸é¡¶ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚å—¯ã€‚æˆ‘åº”è¯¥ç»™ä½ å±•ç¤ºä¸€ä¸‹ç­”æ¡ˆæ˜¯ä»€ä¹ˆæ ·å­çš„ï¼Œæ‰€ä»¥æˆ‘å°†åé€€ä¸€æ­¥ï¼Œå°è¯•å¾—åˆ°è¶³å¤Ÿçš„å…‰ï¼Œä¹Ÿè®¸ä½ å¯ä»¥çœ‹åˆ°è¿™ä¸ªç«‹æ–¹ä½“ã€‚æ‰€ä»¥è¿™å°±æ˜¯ä¸€ä¸ªé˜Ÿåˆ—ã€‚ä½ å¯ä»¥çœ‹åˆ°å…¶ä»–è¾¹ã€‚
- en: Former coding of Zigza ring around the middleã€‚So I got a picture of itã€‚So the
    colored rods here are the other edges of the cubeï¼Œ the ones that don't touch your
    fingertipsã€‚And your top finger connected to the three vertices of those flapsã€‚And
    your bottom fingers connected to the lowest three vertices thereã€‚
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å‰é¢çš„ç¼–ç æ˜¯Zigzaç¯ç»•ä¸­é—´çš„æ ·å­ã€‚æˆ‘æœ‰å®ƒçš„å›¾ç‰‡ã€‚è¿™äº›æœ‰è‰²æ†æ˜¯ç«‹æ–¹ä½“çš„å…¶ä»–è¾¹ï¼Œä¸æ¥è§¦ä½ çš„æŒ‡å°–ã€‚ä½ çš„é¡¶éƒ¨æ‰‹æŒ‡è¿æ¥åˆ°è¿™äº›ç¿»è½¬çš„ä¸‰ä¸ªé¡¶ç‚¹ï¼Œè€Œä½ çš„åº•éƒ¨æ‰‹æŒ‡è¿æ¥åˆ°æœ€åº•éƒ¨çš„ä¸‰ä¸ªé¡¶ç‚¹ã€‚
- en: And that's what a cube looks like is's something you had no idea about this
    is just a completely different model of a cube it's so different I'll give it
    a different name I call it a hexahahedronã€‚ğŸ˜Šï¼ŒAndã€‚The thing to notice is a hexahahedron
    and a cube are just conceptually utterly differentã€‚
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œç«‹æ–¹ä½“çš„æ ·å­æ˜¯ä½ å¯¹å®ƒå®Œå…¨æ²¡æœ‰æƒ³æ³•çš„ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå®Œå…¨ä¸åŒçš„ç«‹æ–¹ä½“æ¨¡å‹ï¼Œå®ƒå¦‚æ­¤ä¸åŒï¼Œæˆ‘ç»™å®ƒä¸€ä¸ªä¸åŒçš„åå­—ï¼Œæˆ‘ç§°å®ƒä¸ºå…­é¢ä½“ã€‚ğŸ˜Šå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå…­é¢ä½“å’Œç«‹æ–¹ä½“åœ¨æ¦‚å¿µä¸Šæ˜¯å®Œå…¨ä¸åŒçš„ã€‚
- en: you wouldn't even know one was the same as the other if you think about one
    as hegen and one as a cubeã€‚It's like the ambiguity between a tilted square and
    an upright diamondã€‚but more powerful because you're not familiar with itã€‚å—¯ã€‚And
    that's my demonstration that people really do use coordinate systems and if you
    use a different coordinate system to describe thingsã€‚
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æŠŠä¸€ä¸ªçœ‹ä½œæ­£æ–¹ä½“ï¼Œå¦ä¸€ä¸ªçœ‹ä½œç«‹æ–¹ä½“ï¼Œä½ ç”šè‡³ä¸ä¼šçŸ¥é“å®ƒä»¬æ˜¯ç›¸åŒçš„ã€‚è¿™å°±åƒå€¾æ–œçš„æ­£æ–¹å½¢å’Œç›´ç«‹çš„è±å½¢ä¹‹é—´çš„æ¨¡ç³Šæ€§ï¼Œä½†æ›´å¼ºå¤§ï¼Œå› ä¸ºä½ å¯¹å®ƒä¸ç†Ÿæ‚‰ã€‚å—¯ã€‚è¿™å°±æ˜¯æˆ‘çš„æ¼”ç¤ºï¼Œè¡¨æ˜äººä»¬ç¡®å®ä½¿ç”¨åæ ‡ç³»ç»Ÿï¼Œå¦‚æœä½ ç”¨ä¸åŒçš„åæ ‡ç³»ç»Ÿæ¥æè¿°äº‹ç‰©ã€‚
- en: and here I force you to use a different coordinate system by making the diagonal
    be vertical and asking you to describe it relative to that vertical axisã€‚Then
    familiar things become completely unfamiliarã€‚ğŸ˜¡ã€‚And when you do see them relative
    to this new frameï¼Œ they're just a completely different thingã€‚Notice that things
    like convolutional neural nets don't have thatã€‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘å¼ºè¿«ä½ ä½¿ç”¨ä¸åŒçš„åæ ‡ç³»ç»Ÿï¼Œä½¿å¯¹è§’çº¿ç«–ç›´ï¼Œå¹¶è¦æ±‚ä½ ç›¸å¯¹äºè¿™ä¸ªå‚ç›´è½´è¿›è¡Œæè¿°ã€‚ç„¶åç†Ÿæ‚‰çš„äº‹ç‰©å˜å¾—å®Œå…¨é™Œç”Ÿã€‚ğŸ˜¡å½“ä½ ç›¸å¯¹äºè¿™ä¸ªæ–°æ¡†æ¶çœ‹åˆ°å®ƒä»¬æ—¶ï¼Œå®ƒä»¬å°±æ˜¯å®Œå…¨ä¸åŒçš„ä¸œè¥¿ã€‚æ³¨æ„ï¼Œå·ç§¯ç¥ç»ç½‘ç»œæ²¡æœ‰é‚£æ ·çš„ã€‚
- en: they can't look at something and have two utterly different internal representations
    of the very same thingã€‚I'm also showing you that you do parsingï¼Œ so here I've
    colored it so you pass it into what I call the crownã€‚which is three triangular
    flaps that slope upward withs and outwardsã€‚Here's a different policyã€‚The same
    green flap sloping upwards and outwardsï¼Œ now we have a red flap sloping downwards
    and outwardsã€‚
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä»¬ä¸èƒ½çœ‹ç€æŸæ ·ä¸œè¥¿ï¼Œå´å¯¹åŒä¸€äº‹ç‰©æœ‰ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„å†…éƒ¨è¡¨å¾ã€‚æˆ‘è¿˜åœ¨å‘ä½ å±•ç¤ºä½ ç¡®å®åœ¨è§£æï¼Œæ‰€ä»¥æˆ‘æŠŠå®ƒæ¶‚æˆé¢œè‰²ï¼Œä½ å°†å®ƒä¼ é€’ç»™æˆ‘æ‰€ç§°çš„çš‡å† ï¼Œå®ƒæœ‰ä¸‰ä¸ªå‘ä¸Šå€¾æ–œçš„ä¸‰è§’å½¢ç¿»è½¬ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªä¸åŒçš„æ”¿ç­–ã€‚ç›¸åŒçš„ç»¿è‰²ç¿»è½¬å‘ä¸Šå€¾æ–œå¹¶å‘å¤–æ‰©å±•ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªå‘ä¸‹å€¾æ–œå¹¶å‘å¤–æ‰©å±•çš„çº¢è‰²ç¿»è½¬ã€‚
- en: And we have a central rectangleï¼Œ and you just have the two ends of the rectangleã€‚Nã€‚if
    you perceive thisã€‚And now close your eyes and ask youï¼Œ were there any parallel
    edges thereï¼Ÿ
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä¸€ä¸ªä¸­å¤®çŸ©å½¢ï¼Œè€Œä½ åªæœ‰çŸ©å½¢çš„ä¸¤ä¸ªç«¯ç‚¹ã€‚å¦‚æœä½ æ„ŸçŸ¥åˆ°è¿™ä¸ªï¼Œç°åœ¨é—­ä¸Šçœ¼ç›é—®ä½ ï¼Œé‚£é‡Œæœ‰æ²¡æœ‰å¹³è¡Œè¾¹ï¼Ÿ
- en: You're very well aware that those two blue edges were parallelã€‚And you're typically
    not aware of any other parallelesï¼Œ even though you know by symmetryã€‚there must
    be other pairsã€‚Similarly with the crownï¼Œ if you see the crownã€‚and then I ask you
    to close your eyes and ask you where the para isï¼Œ you don't see any parallelurgsã€‚
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éå¸¸æ¸…æ¥šé‚£ä¸¤æ¡è“è¾¹æ˜¯å¹³è¡Œçš„ã€‚é€šå¸¸ä½ ä¸ä¼šæ„è¯†åˆ°å…¶ä»–ä»»ä½•å¹³è¡Œçº¿ï¼Œå°½ç®¡ä½ çŸ¥é“é€šè¿‡å¯¹ç§°æ€§ï¼Œå¿…ç„¶è¿˜æœ‰å…¶ä»–å¯¹ã€‚åŒæ ·ï¼Œå¯¹äºçš‡å† ï¼Œå¦‚æœä½ çœ‹åˆ°çš‡å† ï¼Œç„¶åæˆ‘è®©ä½ é—­ä¸Šçœ¼ç›ï¼Œé—®ä½ å¹³è¡Œçº¿åœ¨å“ªé‡Œï¼Œä½ ä¸ä¼šçœ‹åˆ°ä»»ä½•å¹³è¡Œçº¿ã€‚
- en: And that's because the coordinate systems you're using for those flaps don't
    line up with the edges and you only notice parallels if they line up with the
    coordinate system you're using so here for the rectangle the parallelurgs align
    line with the coordinate system for the flaps they don'tã€‚
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯å› ä¸ºä½ ä¸ºé‚£äº›è¥Ÿç¿¼ä½¿ç”¨çš„åæ ‡ç³»ç»Ÿä¸è¾¹ç¼˜ä¸å¯¹é½ï¼Œåªæœ‰å½“å®ƒä»¬ä¸æ‰€ç”¨åæ ‡ç³»ç»Ÿå¯¹é½æ—¶ï¼Œä½ æ‰ä¼šæ³¨æ„åˆ°å¹³è¡Œçº¿ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œå¯¹äºçŸ©å½¢ï¼Œå¹³è¡Œçº¿ä¸è¥Ÿç¿¼çš„åæ ‡ç³»ç»Ÿå¯¹é½ï¼Œè€Œå®ƒä»¬å¹¶æ²¡æœ‰ã€‚
- en: So you're aware that those two blue edges are parallelã€‚but you're not aware
    that one of the green edges and one of the red edges is parallelã€‚å—¯ã€‚So this isn't
    like the Necker cube ambiguity where when it flipsã€‚you think that what's out there
    in reality is differentï¼Œ things are at a different depthã€‚
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ æ„è¯†åˆ°è¿™ä¸¤æ¡è“è¾¹æ˜¯å¹³è¡Œçš„ã€‚ä½†ä½ æ²¡æœ‰æ„è¯†åˆ°ä¸€æ¡ç»¿è‰²è¾¹å’Œä¸€æ¡çº¢è‰²è¾¹æ˜¯å¹³è¡Œçš„ã€‚å—¯ã€‚è¿™ä¸åƒå†…å…‹å°”ç«‹æ–¹ä½“çš„æ¨¡ç³Šæ€§ï¼Œå½“å®ƒç¿»è½¬æ—¶ã€‚ä½ è®¤ä¸ºç°å®ä¸­çš„ä¸œè¥¿ä¸åŒï¼Œäº‹ç‰©å¤„äºä¸åŒçš„æ·±åº¦ã€‚
- en: This is like next weekend we should be visiting relativesã€‚So if you take the
    sentence next weekend we shall be visiting relativesã€‚it can mean next weekend
    what we will be doing is visiting relativesã€‚or it can mean next weekend what we
    will be is visiting relativesã€‚
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±åƒä¸‹ä¸ªå‘¨æœ«æˆ‘ä»¬åº”è¯¥å»æ‹œè®¿äº²æˆšã€‚å› æ­¤ï¼Œå¦‚æœä½ æ‹¿ä¸‹ä¸ªå‘¨æœ«æˆ‘ä»¬å°†æ‹œè®¿äº²æˆšè¿™å¥è¯ï¼Œå®ƒå¯ä»¥æ„å‘³ç€ä¸‹ä¸ªå‘¨æœ«æˆ‘ä»¬è¦åšçš„å°±æ˜¯æ‹œè®¿äº²æˆšã€‚æˆ–è€…å®ƒå¯ä»¥æ„å‘³ç€ä¸‹ä¸ªå‘¨æœ«æˆ‘ä»¬å°†æ˜¯æ‹œè®¿äº²æˆšã€‚
- en: Now those are completely different sensesï¼Œ they happen to have the same truth
    conditionsã€‚they mean the same thing in the sense of truth conditions because if
    you're visiting relativesã€‚what you are is visiting relativesã€‚And it's that kind
    of ambiguityã€‚no disagreement around what's going on in the worldã€‚
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿™äº›æ˜¯å®Œå…¨ä¸åŒçš„æ„ä¹‰ï¼Œå®ƒä»¬æ°å¥½æœ‰ç›¸åŒçš„çœŸå€¼æ¡ä»¶ã€‚åœ¨çœŸå€¼æ¡ä»¶ä¸Šå®ƒä»¬æ„å‘³ç€ç›¸åŒçš„ä¸œè¥¿ï¼Œå› ä¸ºå¦‚æœä½ æ­£åœ¨æ‹œè®¿äº²æˆšã€‚ä½ å°±æ˜¯åœ¨æ‹œè®¿äº²æˆšã€‚æ­£æ˜¯è¿™ç§æ¨¡ç³Šæ€§ã€‚å¯¹ä¸–ç•Œä¸Šå‘ç”Ÿçš„äº‹æƒ…æ²¡æœ‰åˆ†æ­§ã€‚
- en: but two completely different ways of seeing the sentenceã€‚Soã€‚This is this was
    drawn in the 1970sã€‚this is what AI was like in the 1970sã€‚This is a sort of structural
    description of the crown interpretationã€‚So you have nodes for the all various
    parts in the hierarchyã€‚I've also put something on the arcs that RWx is the relationship
    between the crown and the flapã€‚
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯å¯¹å¥å­çš„ä¸¤ç§å®Œå…¨ä¸åŒçš„çœ‹æ³•ã€‚å› æ­¤ã€‚è¿™æ˜¯åœ¨1970å¹´ä»£ç»˜åˆ¶çš„ã€‚è¿™å°±æ˜¯1970å¹´ä»£çš„äººå·¥æ™ºèƒ½ã€‚è¿™æ˜¯ä¸€ç§çš‡å† è§£é‡Šçš„ç»“æ„æè¿°ã€‚å› æ­¤ï¼Œä½ ä¸ºå±‚æ¬¡ç»“æ„ä¸­çš„å„ä¸ªéƒ¨åˆ†è®¾ç½®äº†èŠ‚ç‚¹ã€‚æˆ‘è¿˜åœ¨å¼§ä¸Šæ ‡æ³¨äº†RWxæ˜¯çš‡å† ä¸è¥Ÿç¿¼ä¹‹é—´çš„å…³ç³»ã€‚
- en: And that can be represented by a matrix is really the relationship between the
    intrinsic frame of reference of the chrome and the intrinsic frame of reference
    of the flapã€‚ğŸ˜Šï¼ŒAnd notice thatã€‚If I change my viewpointï¼Œ that doesn't change at
    allã€‚ğŸ˜¡ã€‚So that kind of relationship will be a good thing to put in the weights
    of a neural network because you'd like a neural network to be able to recognize
    shapes independently viewpointã€‚And that RWX is knowledge about this shapeï¼Œ that's
    independent of viewpointã€‚
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œè¿™å¯ä»¥ç”¨çŸ©é˜µè¡¨ç¤ºï¼Œå®é™…ä¸Šæ˜¯é“¬çš„å†…åœ¨å‚è€ƒæ¡†æ¶ä¸è¥Ÿç¿¼çš„å†…åœ¨å‚è€ƒæ¡†æ¶ä¹‹é—´çš„å…³ç³»ã€‚ğŸ˜Šï¼Œè¯·æ³¨æ„ã€‚å¦‚æœæˆ‘æ”¹å˜æˆ‘çš„è§†è§’ï¼Œè¿™ä¸€ç‚¹å®Œå…¨æ²¡æœ‰æ”¹å˜ã€‚ğŸ˜¡ã€‚æ‰€ä»¥è¿™ç§å…³ç³»å°†æ˜¯æ”¾å…¥ç¥ç»ç½‘ç»œæƒé‡ä¸­çš„å¥½ä¸œè¥¿ï¼Œå› ä¸ºä½ å¸Œæœ›ç¥ç»ç½‘ç»œèƒ½å¤Ÿç‹¬ç«‹äºè§†è§’è¯†åˆ«å½¢çŠ¶ã€‚è€ŒRWXæ˜¯å…³äºè¿™ç§å½¢çŠ¶çš„çŸ¥è¯†ï¼Œå®ƒç‹¬ç«‹äºè§†è§’ã€‚
- en: Here's the zigzag interpretationã€‚And here's something else where I've addedã€‚The
    things in the heavy blue boxesã€‚They're the relationship betweenã€‚ğŸ˜¡ï¼ŒThe aode and
    the viewerã€‚That is to be more explicitï¼Œ the coordinate transformation between
    the intrinsic frame of reference of the crown and the intrinsic frame of reference
    of the viewerã€‚your eyeball is that R WVã€‚And that's a different kind of thing altogether
    because as you change viewpoint that changesã€‚
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é”¯é½¿å½¢çš„è§£é‡Šã€‚è¿˜æœ‰å…¶ä»–æˆ‘æ·»åŠ çš„å†…å®¹ã€‚åœ¨æ·±è“è‰²æ¡†ä¸­çš„äº‹ç‰©ã€‚å®ƒä»¬æ˜¯ä¹‹é—´çš„å…³ç³»ã€‚ğŸ˜¡ï¼ŒæŒ‡çš„æ˜¯aodeå’Œè§‚ä¼—ã€‚æ›´æ˜ç¡®åœ°è¯´ï¼Œæ˜¯çš‡å† çš„å†…åœ¨å‚è€ƒæ¡†æ¶ä¸è§‚ä¼—çš„å†…åœ¨å‚è€ƒæ¡†æ¶ä¹‹é—´çš„åæ ‡å˜æ¢ã€‚ä½ çš„çœ¼çƒå°±æ˜¯é‚£ä¸ªR
    WVã€‚è¿™å®Œå…¨æ˜¯å¦ä¸€ç§ä¸œè¥¿ï¼Œå› ä¸ºå½“ä½ æ”¹å˜è§†è§’æ—¶ï¼Œé‚£ä¼šæ”¹å˜ã€‚
- en: in factï¼Œ as you change viewpoint all those things in blue boxes all change together
    in a consistent wayã€‚And there's a simple relationshipï¼Œ which is that if you take
    RWVï¼Œ and you multiply it by RWxã€‚you get Rx vã€‚So you can easily propagate viewpoint
    information over a structural descriptionã€‚And that's what I think a mental image
    is rather than a bunch of pixelsã€‚
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œå½“ä½ æ”¹å˜è§†è§’æ—¶ï¼Œæ‰€æœ‰è“æ¡†ä¸­çš„äº‹ç‰©éƒ½ä¼šä»¥ä¸€è‡´çš„æ–¹å¼ä¸€èµ·å˜åŒ–ã€‚è¿˜æœ‰ä¸€ä¸ªç®€å•çš„å…³ç³»ï¼Œå°±æ˜¯å¦‚æœä½ å–RWVå¹¶ä¹˜ä»¥RWxã€‚ä½ ä¼šå¾—åˆ°Rx vã€‚å› æ­¤ï¼Œä½ å¯ä»¥è½»æ¾åœ°åœ¨ç»“æ„æè¿°ä¸­ä¼ æ’­è§†è§’ä¿¡æ¯ã€‚è¿™å°±æ˜¯æˆ‘è®¤ä¸ºçš„å¿ƒç†å›¾åƒï¼Œè€Œä¸æ˜¯ä¸€å †åƒç´ ã€‚
- en: It's a structural description with Associative viewpoint informationã€‚å—¯ã€‚That
    makes sense of a lot of properties of mental imagesã€‚like if you want to do any
    reasoning with things like RWXï¼Œ you form a mental imageã€‚That is you fill in that
    you choose a viewpointã€‚And I want to do one more demo to convince you you always
    choose a viewpoint when you're solving mental imagery problemsã€‚
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç»“æ„æè¿°ï¼Œå¸¦æœ‰å…³è”è§†ç‚¹ä¿¡æ¯ã€‚å—¯ã€‚è¿™è®©è®¸å¤šå¿ƒç†å›¾åƒçš„ç‰¹æ€§å˜å¾—æœ‰æ„ä¹‰ã€‚æ¯”å¦‚ï¼Œå¦‚æœä½ æƒ³ç”¨RWXè¿›è¡Œä»»ä½•æ¨ç†ï¼Œä½ ä¼šå½¢æˆä¸€ä¸ªå¿ƒç†å›¾åƒã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å¡«å†™äº†ä½ é€‰æ‹©çš„è§†ç‚¹ã€‚æˆ‘è¿˜æƒ³åšä¸€ä¸ªæ¼”ç¤ºæ¥è®©ä½ ç›¸ä¿¡ï¼Œåœ¨è§£å†³å¿ƒç†æƒ³è±¡é—®é¢˜æ—¶ä½ æ€»æ˜¯é€‰æ‹©ä¸€ä¸ªè§†ç‚¹ã€‚
- en: So I'm going give you another very simple mental imagery problem at the risk
    of running overtimeã€‚Imagine thatã€‚You're at a particular point and you travel a
    mile east and then you travel a mile north and then you travel a mile east againã€‚what's
    your direction back to your starting pointï¼ŸThis isn't a very hard problemã€‚it's
    sort of a bit south and quite a lot westï¼Œ rightï¼ŸIt's not exactly southwestã€‚
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å°†ç»™ä½ å¦ä¸€ä¸ªéå¸¸ç®€å•çš„å¿ƒç†æƒ³è±¡é—®é¢˜ï¼Œå†’ç€è¶…æ—¶çš„é£é™©ã€‚æƒ³è±¡ä¸€ä¸‹ã€‚ä½ åœ¨ä¸€ä¸ªç‰¹å®šçš„ç‚¹ä¸Šï¼Œå‘ä¸œèµ°ä¸€è‹±é‡Œï¼Œç„¶åå‘åŒ—èµ°ä¸€è‹±é‡Œï¼Œç„¶åå†å‘ä¸œèµ°ä¸€è‹±é‡Œã€‚ä½ å›åˆ°èµ·ç‚¹çš„æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªå¾ˆéš¾çš„é—®é¢˜ã€‚å®ƒæœ‰ç‚¹å‘å—ï¼Œå¹¶ä¸”ç›¸å½“å‘è¥¿ï¼Œå¯¹å§ï¼Ÿå¹¶ä¸å®Œå…¨æ˜¯è¥¿å—ã€‚
- en: but it's sort of southwestã€‚Nowï¼Œ when you did that taskã€‚what you imagined from
    your point of view is you went to mile East and then you went to mile north and
    then you went to mile East againã€‚I'll tell you what you didn't imagineï¼Œ you didn't
    imagine that you went to my East and then you went to my north and then you went
    to my East againã€‚You could have solved the problem perfectly well with North not
    being upï¼Œ but you had north Aã€‚
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ƒæœ‰ç‚¹å‘è¥¿å—ã€‚ç°åœ¨ï¼Œå½“ä½ å®Œæˆé‚£ä¸ªä»»åŠ¡æ—¶ã€‚ä½ ä»ä½ çš„è§†ç‚¹æƒ³è±¡çš„æ˜¯ä½ å‘ä¸œèµ°ä¸€è‹±é‡Œï¼Œç„¶åå‘åŒ—èµ°ä¸€è‹±é‡Œï¼Œå†å‘ä¸œèµ°ä¸€è‹±é‡Œã€‚æˆ‘å‘Šè¯‰ä½ ä½ æ²¡æœ‰æƒ³è±¡çš„æ˜¯ä»€ä¹ˆï¼Œä½ æ²¡æœ‰æƒ³è±¡ä½ å‘ä¸œèµ°ä¸€è‹±é‡Œï¼Œç„¶åå‘åŒ—èµ°ä¸€è‹±é‡Œï¼Œå†å‘ä¸œèµ°ä¸€è‹±é‡Œã€‚ä½ æœ¬å¯ä»¥åœ¨åŒ—æ–¹ä¸æŒ‡å‘ä¸Šæ–¹çš„æƒ…å†µä¸‹å¾ˆå¥½åœ°è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†ä½ æ˜¯ä»¥åŒ—ä¸ºAã€‚
- en: you also didn't imagine thisï¼Œ you go a mile east and then a mile north and then
    a mile east againã€‚And you didn't imagine thisï¼Œ you go mile east and then a mile
    north and so onã€‚you imagined it at a particular scale in a particular orientation
    and in a particular positionã€‚ğŸ˜Šã€‚That'sã€‚And you can answer questions about roughly
    how big it was and soã€‚
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿæ²¡æœ‰æƒ³è±¡è¿™ä¸ªï¼Œä½ å‘ä¸œèµ°ä¸€è‹±é‡Œï¼Œç„¶åå‘åŒ—èµ°ä¸€è‹±é‡Œï¼Œå†å‘ä¸œèµ°ä¸€è‹±é‡Œã€‚ä½ æ²¡æœ‰æƒ³è±¡è¿™ä¸ªï¼Œä½ å‘ä¸œèµ°ä¸€è‹±é‡Œï¼Œç„¶åå‘åŒ—èµ°ä¸€è‹±é‡Œï¼Œç­‰ç­‰ã€‚ä½ åœ¨ç‰¹å®šçš„æ¯”ä¾‹ã€ç‰¹å®šçš„æ–¹å‘å’Œç‰¹å®šçš„ä½ç½®è¿›è¡Œäº†æƒ³è±¡ã€‚ğŸ˜Šã€‚å°±æ˜¯è¿™æ ·ã€‚ä½ å¯ä»¥å›ç­”å…³äºå®ƒå¤§è‡´æœ‰å¤šå¤§çš„é—®é¢˜ç­‰ç­‰ã€‚
- en: so that's evidence that to solve these tasks that involve using relationships
    between thingsã€‚you form a mental image okayï¼Œ and that form mental imageryã€‚So I'm
    now going to give you a very brief introduction to contrastive learningã€‚So where
    this is a completeã€‚Disconnect in the talkï¼Œ but I'll come back together soonã€‚Soã€‚
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™è¯æ˜äº†ï¼Œè§£å†³æ¶‰åŠä½¿ç”¨äº‹ç‰©ä¹‹é—´å…³ç³»çš„ä»»åŠ¡æ—¶ã€‚ä½ ä¼šå½¢æˆä¸€ä¸ªå¿ƒç†å›¾åƒï¼Œå¥½å—ï¼Œè¿™å°±æ˜¯å¿ƒç†æƒ³è±¡ã€‚å› æ­¤ï¼Œæˆ‘ç°åœ¨å°†ç»™ä½ ä¸€ä¸ªéå¸¸ç®€çŸ­çš„å¯¹æ¯”å­¦ä¹ ä»‹ç»ã€‚è¿™åœ¨æ¼”è®²ä¸­æ˜¯ä¸€ä¸ªå®Œå…¨çš„æ–­è£‚ï¼Œä½†æˆ‘ä¼šå¾ˆå¿«æŠŠå®ƒä»¬é‡æ–°ç»“åˆèµ·æ¥ã€‚æ‰€ä»¥ã€‚
- en: In contrast selfive wise learningï¼Œ what we try and do is make two different
    crops of an image have the same representationã€‚å—¯ã€‚There's a paper a long time ago
    by Becker and Hinton where we were doing this to discover low level coherence
    in an imageã€‚like the continuity of surfacesã€‚æˆ‘ã€‚The depth of surfacesã€‚It's been
    improved a lot since then and it's been used for doing things like classificationã€‚
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è‡ªæˆ‘æ™ºæ…§å­¦ä¹ ç›¸å¯¹ï¼Œæˆ‘ä»¬æ‰€å°è¯•åšçš„æ˜¯è®©å›¾åƒçš„ä¸¤ä¸ªä¸åŒè£å‰ªéƒ¨åˆ†å…·æœ‰ç›¸åŒçš„è¡¨ç¤ºã€‚å—¯ã€‚å¾ˆä¹…ä»¥å‰ï¼ŒBeckerå’ŒHintonæœ‰ä¸€ç¯‡è®ºæ–‡ï¼Œæˆ‘ä»¬ç”¨è¿™ä¸ªæ–¹æ³•æ¥å‘ç°å›¾åƒä¸­çš„ä½çº§ä¸€è‡´æ€§ï¼Œæ¯”å¦‚è¡¨é¢çš„è¿ç»­æ€§ã€‚æˆ‘ã€‚è¡¨é¢çš„æ·±åº¦ã€‚è‡ªé‚£ä»¥åï¼Œè¿™ä¸€æ–¹æ³•å¾—åˆ°äº†å¾ˆå¤§çš„æ”¹è¿›ï¼Œå¹¶å·²è¢«ç”¨äºåˆ†ç±»ç­‰ä»»åŠ¡ã€‚
- en: that is you take an image that has one prominent object in itã€‚And you sayã€‚If
    I take a crop of the image that contains sort of any part of that objectã€‚It should
    have the same representation as some other crop of the image containing part of
    that objectã€‚Andã€‚This has been developed a lot in the last few yearsã€‚
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å–ä¸€å¹…å›¾åƒï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªçªå‡ºçš„ç‰©ä½“ã€‚ç„¶åä½ è¯´ã€‚å¦‚æœæˆ‘è£å‰ªå‡ºåŒ…å«è¯¥ç‰©ä½“ä»»ä½•éƒ¨åˆ†çš„å›¾åƒï¼Œè¿™ä¸ªè£å‰ªéƒ¨åˆ†çš„è¡¨ç¤ºåº”è¯¥ä¸åŒ…å«è¯¥ç‰©ä½“éƒ¨åˆ†çš„å…¶ä»–è£å‰ªéƒ¨åˆ†ç›¸åŒã€‚è€Œä¸”ã€‚è¿™ä¸ªæ–¹æ³•åœ¨è¿‡å»å‡ å¹´ä¸­å¾—åˆ°äº†å¾ˆå¤§çš„å‘å±•ã€‚
- en: I'm going to talk about a model developed a couple of years ago of my group
    in Toronto called Sinclair but there's lots of other models and since then things
    have improvedã€‚So in Simclairï¼Œ you're taking an image Xã€‚You take two different
    crops and you also do color distortion of the cropsã€‚
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†è°ˆè®ºæˆ‘åœ¨å¤šä¼¦å¤šçš„å›¢é˜Ÿå‡ å¹´å‰å¼€å‘çš„ä¸€ä¸ªæ¨¡å‹ï¼Œå«åšSinclairï¼Œä½†è¿˜æœ‰å¾ˆå¤šå…¶ä»–æ¨¡å‹ï¼Œè‡ªé‚£æ—¶èµ·æƒ…å†µä¹Ÿæœ‰æ‰€æ”¹å–„ã€‚å› æ­¤ï¼Œåœ¨Simclairä¸­ï¼Œä½ å–ä¸€å¹…å›¾åƒXã€‚ä½ å–ä¸¤ä¸ªä¸åŒçš„è£å‰ªï¼ŒåŒæ—¶è¿˜å¯¹è£å‰ªè¿›è¡Œé¢œè‰²å¤±çœŸã€‚
- en: different color distortions of each cropã€‚And that's to prevent it from using
    color histograms to say they're the sameã€‚So you mess with the color so it can't
    use colorã€‚In a simple wayã€‚Andã€‚That gives you Xi tilde and Xj tildeã€‚You then put
    those through the same neural network Fã€‚Then you get a representation Hã€‚And then
    you take your representation H and you put it through another neural networkã€‚
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªè£å‰ªçš„ä¸åŒé¢œè‰²æ‰­æ›²ã€‚è¿™æ˜¯ä¸ºäº†é˜²æ­¢å®ƒä½¿ç”¨é¢œè‰²ç›´æ–¹å›¾æ¥åˆ¤æ–­å®ƒä»¬æ˜¯ç›¸åŒçš„ã€‚æ‰€ä»¥ä½ åœ¨é¢œè‰²ä¸Šåšä¸€äº›è°ƒæ•´ï¼Œä»¥ä¾¿å®ƒæ— æ³•ä½¿ç”¨é¢œè‰²ã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ–¹æ³•ã€‚ç„¶åä½ å¾—åˆ°Xi
    tildeå’ŒXj tildeã€‚æ¥ç€ä½ å°†å®ƒä»¬æ”¾å…¥ç›¸åŒçš„ç¥ç»ç½‘ç»œFä¸­ã€‚ç„¶åä½ å¾—åˆ°ä¸€ä¸ªè¡¨ç¤ºHã€‚ç„¶åä½ å°†ä½ çš„è¡¨ç¤ºHæ”¾å…¥å¦ä¸€ä¸ªç¥ç»ç½‘ç»œä¸­ã€‚
- en: which compresses it a bitã€‚It goes to low dimensionalityã€‚That's an extra complexity
    I'm not going to explainï¼Œ but it makes it work a bit betterã€‚You can do it without
    doing thatã€‚And you get two embedding Z and Zjã€‚And your aim is to maximize the
    agreement between those vectorsã€‚
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šç¨å¾®å‹ç¼©å®ƒã€‚å®ƒå˜ä¸ºä½ç»´åº¦ã€‚è¿™æ˜¯ä¸€ä¸ªé¢å¤–çš„å¤æ‚æ€§ï¼Œæˆ‘ä¸æ‰“ç®—è§£é‡Šï¼Œä½†å®ƒè®©å®ƒè¿è¡Œå¾—æ›´å¥½ã€‚ä½ å¯ä»¥åœ¨ä¸è¿™æ ·åšçš„æƒ…å†µä¸‹è¿›è¡Œï¼Œå¹¶å¾—åˆ°ä¸¤ä¸ªåµŒå…¥Zå’ŒZjã€‚ä½ çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–è¿™äº›å‘é‡ä¹‹é—´çš„å…±è¯†ã€‚
- en: And so you start off doing that and you sayï¼Œ okayï¼Œ let's start off with random
    neural networksã€‚random weights in the neural networksï¼Œ and let's take two patches
    and let's put them through these transformations and let's try and make ZI be
    the same as ZJ so let's back propagate the squared difference between components
    of I and components of Jã€‚
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ å¼€å§‹è¿™æ ·åšï¼Œä½ è¯´ï¼Œå¥½å§ï¼Œè®©æˆ‘ä»¬ä»éšæœºç¥ç»ç½‘ç»œå¼€å§‹ã€‚åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨éšæœºæƒé‡ï¼Œç„¶åæˆ‘ä»¬å–ä¸¤ä¸ªå›¾åƒå—ï¼Œå°†å®ƒä»¬é€šè¿‡è¿™äº›å˜æ¢ï¼Œå¹¶å°è¯•ä½¿ZIä¸ZJç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬å¯¹Iå’ŒJçš„ç»„ä»¶ä¹‹é—´çš„å¹³æ–¹å·®è¿›è¡Œåå‘ä¼ æ’­ã€‚
- en: And heyï¼Œ Prestoï¼Œ what you discover is when everything collapsesã€‚For every imageã€‚it
    will always produce the same ZI and Zjã€‚And then you realizeï¼Œ wellã€‚that's not what
    I meant by agreementï¼Œ I meant they should be the sameã€‚When you get two crops of
    the same image and different when you get two crops of different imagesã€‚
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å˜¿ï¼Œå¥‡è¿¹å‘ç”Ÿäº†ï¼Œä½ å‘ç°å½“ä¸€åˆ‡å´©æºƒæ—¶ã€‚å¯¹äºæ¯ä¸ªå›¾åƒï¼Œå®ƒæ€»ä¼šäº§ç”Ÿç›¸åŒçš„ZIå’ŒZjã€‚ç„¶åä½ æ„è¯†åˆ°ï¼Œè¿™ä¸æ˜¯æˆ‘æ‰€è¯´çš„å…±è¯†ï¼Œæˆ‘çš„æ„æ€æ˜¯å®ƒä»¬åº”è¯¥æ˜¯ç›¸åŒçš„ã€‚å½“ä½ è·å¾—ä¸¤ä¸ªç›¸åŒå›¾åƒçš„è£å‰ªæ—¶ï¼Œå®ƒä»¬æ˜¯ç›¸åŒçš„ï¼Œè€Œå½“ä½ è·å¾—ä¸¤ä¸ªä¸åŒå›¾åƒçš„è£å‰ªæ—¶ï¼Œå®ƒä»¬æ˜¯ä¸åŒçš„ã€‚
- en: Otherwiseï¼Œ there's not really agreementï¼Œ rightï¼Ÿå—¯ã€‚So you have to have negative
    examplesã€‚you have to show crops from different images and say those should be
    differentã€‚If they're already differentï¼Œ you don't try and make them a lot more
    differentã€‚It's very easy to make things very differentï¼Œ but that's not what you
    want you just want to be sure they're different enough so crop from different
    images aren't taken to be from the same imageã€‚
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¦åˆ™ï¼Œæ²¡æœ‰çœŸæ­£çš„å…±è¯†ï¼Œå¯¹å—ï¼Ÿå—¯ã€‚æ‰€ä»¥ä½ å¿…é¡»æœ‰è´Ÿä¾‹ã€‚ä½ å¿…é¡»å±•ç¤ºæ¥è‡ªä¸åŒå›¾åƒçš„è£å‰ªï¼Œå¹¶è¯´å®ƒä»¬åº”è¯¥æ˜¯ä¸åŒçš„ã€‚å¦‚æœå®ƒä»¬å·²ç»ä¸åŒï¼Œä½ å°±ä¸éœ€è¦è®©å®ƒä»¬å˜å¾—æ›´ä¸åŒã€‚è®©äº‹ç‰©å˜å¾—éå¸¸ä¸åŒæ˜¯å¾ˆå®¹æ˜“çš„ï¼Œä½†è¿™ä¸æ˜¯ä½ æƒ³è¦çš„ï¼Œä½ åªæƒ³ç¡®ä¿æ¥è‡ªä¸åŒå›¾åƒçš„è£å‰ªä¸ä¼šè¢«è§†ä¸ºæ¥è‡ªåŒä¸€å›¾åƒã€‚
- en: so if they happen to be very similar you push them apartã€‚And that stops your
    representations clapsing that's called contrastive learningã€‚And it works very
    wellã€‚Soã€‚What you can do is do unsupervised learningã€‚By trying to maximize agreement
    between theã€‚Representations you get from two image patches from the same imageã€‚
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å¦‚æœå®ƒä»¬æ°å¥½éå¸¸ç›¸ä¼¼ï¼Œä½ å°±å°†å®ƒä»¬åˆ†å¼€ã€‚è¿™é˜»æ­¢äº†ä½ çš„è¡¨ç¤ºå´©æºƒï¼Œè¿™ç§°ä¸ºå¯¹æ¯”å­¦ä¹ ã€‚æ•ˆæœå¾ˆå¥½ã€‚å› æ­¤ï¼Œä½ å¯ä»¥é€šè¿‡å°è¯•æœ€å¤§åŒ–æ¥è‡ªåŒä¸€å›¾åƒçš„ä¸¤ä¸ªå›¾åƒå—ä¹‹é—´çš„è¡¨ç¤ºçš„å…±è¯†æ¥è¿›è¡Œæ— ç›‘ç£å­¦ä¹ ã€‚
- en: And after you've done thatï¼Œ you just take your representation of the image patchã€‚And
    you feed it to a linear classifierï¼Œ a bunch of weights so that you multiply the
    representation by a weight matrixã€‚put it through a softmax and get class labelsã€‚And
    then you train that byã€‚Great descentã€‚Andã€‚What you discover is that that's just
    about as good as training on label dataã€‚
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ å®Œæˆåï¼Œä½ åªéœ€è·å–å›¾åƒå—çš„è¡¨ç¤ºã€‚ç„¶åå°†å…¶è¾“å…¥çº¿æ€§åˆ†ç±»å™¨ï¼Œä¸€å †æƒé‡ï¼Œä»¥ä¾¿ä½ å°†è¡¨ç¤ºä¹˜ä»¥æƒé‡çŸ©é˜µã€‚é€šè¿‡softmaxè·å¾—ç±»åˆ«æ ‡ç­¾ã€‚ç„¶åä½ é€šè¿‡æ¢¯åº¦ä¸‹é™æ¥è®­ç»ƒå®ƒã€‚ä½ å‘ç°ï¼Œè¿™ä¸åœ¨æ ‡ç­¾æ•°æ®ä¸Šè®­ç»ƒå‡ ä¹æ˜¯ä¸€æ ·å¥½çš„ã€‚
- en: so now the only thing you trained on label data is that last linear classifierã€‚The
    previous layers were trained on unlabeled dataã€‚And you've managed to train your
    representations without needing labelsã€‚Now there's a problem with thisã€‚He works
    very nicelyã€‚
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ è®­ç»ƒçš„å”¯ä¸€æ ‡ç­¾æ•°æ®æ˜¯æœ€åä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ã€‚ä¹‹å‰çš„å±‚æ˜¯åœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šè®­ç»ƒçš„ã€‚ä½ å·²ç»æˆåŠŸåœ°è®­ç»ƒäº†ä½ çš„è¡¨ç¤ºï¼Œè€Œæ— éœ€æ ‡ç­¾ã€‚ç°åœ¨è¿™æœ‰ä¸€ä¸ªé—®é¢˜ã€‚å®ƒå·¥ä½œå¾—å¾ˆå¥½ã€‚
- en: But it's really confounding objects and whole seasã€‚So it makes sense to say
    two different patches from the same sceneã€‚Should get the sameã€‚Vectctor label at
    the seam level because they're from the same sceneã€‚But what if one of the patches
    contains bits of objects A and B and another patch contains bits of objects A
    and Cã€‚
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ç¡®å®ä»¤äººå›°æƒ‘çš„æ˜¯å¯¹è±¡å’Œæ•´ä¸ªåœºæ™¯ã€‚æ‰€ä»¥è¯´åŒä¸€åœºæ™¯çš„ä¸¤ä¸ªä¸åŒç‰‡æ®µåº”è¯¥åœ¨æ¥ç¼å¤„å¾—åˆ°ç›¸åŒçš„**å‘é‡æ ‡ç­¾**æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºå®ƒä»¬æ¥è‡ªåŒä¸€åœºæ™¯ã€‚ä½†å¦‚æœå…¶ä¸­ä¸€ä¸ªç‰‡æ®µåŒ…å«å¯¹è±¡Aå’ŒBçš„ä¸€éƒ¨åˆ†ï¼Œè€Œå¦ä¸€ä¸ªç‰‡æ®µåŒ…å«å¯¹è±¡Aå’ŒCçš„ä¸€éƒ¨åˆ†å‘¢ï¼Ÿ
- en: you don't really want those two patches to have the same representation at the
    object levelã€‚So we have to distinguish these different levels of representationã€‚And
    for contrastive learningã€‚if you don't use any kind of gating or attentionï¼Œ then
    what's happening is you're really doing learning at the seam levelã€‚What we'd like
    is that the representations you get at the object levelã€‚Should be the sameã€‚
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¹¶ä¸å¸Œæœ›è¿™ä¸¤ä¸ªç‰‡æ®µåœ¨å¯¹è±¡å±‚é¢æœ‰ç›¸åŒçš„è¡¨ç¤ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»åŒºåˆ†è¿™äº›ä¸åŒçš„è¡¨ç¤ºå±‚çº§ã€‚å¯¹äºå¯¹æ¯”å­¦ä¹ æ¥è¯´ï¼Œå¦‚æœä¸ä½¿ç”¨ä»»ä½•å½¢å¼çš„**é—¨æ§**æˆ–æ³¨æ„åŠ›æœºåˆ¶ï¼Œé‚£ä¹ˆæ‰€å‘ç”Ÿçš„äº‹æƒ…å®é™…ä¸Šæ˜¯åœ¨æ¥ç¼å±‚é¢è¿›è¡Œå­¦ä¹ ã€‚æˆ‘ä»¬å¸Œæœ›çš„æ˜¯ï¼Œåœ¨å¯¹è±¡å±‚é¢è·å¾—çš„è¡¨ç¤ºåº”è¯¥æ˜¯ç›¸åŒçš„ã€‚
- en: If both patches are patches from J Aï¼Œ but should be different if one patches
    from JA and one patches from J Bã€‚and to do that we're going to need some form
    of attention to decide whether they really come from the same thingã€‚And so Glom
    is designed to do thatï¼Œ it to I take contrastive learningã€‚And to introduce attention
    of the kinds you get in transformers in order not to try and say things are the
    same when they're notã€‚
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸¤ä¸ªç‰‡æ®µéƒ½æ˜¯æ¥è‡ªJAçš„ç‰‡æ®µï¼Œä½†å¦‚æœä¸€ä¸ªæ¥è‡ªJAè€Œå¦ä¸€ä¸ªæ¥è‡ªJBï¼Œå®ƒä»¬åº”è¯¥æ˜¯ä¸åŒçš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦æŸç§å½¢å¼çš„æ³¨æ„åŠ›æ¥å†³å®šå®ƒä»¬æ˜¯å¦çœŸçš„æ¥è‡ªåŒä¸€äº‹ç‰©ã€‚å› æ­¤ï¼ŒGlomçš„è®¾è®¡æ—¨åœ¨è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œå¹¶å¼•å…¥å˜æ¢å™¨ä¸­è·å¾—çš„æ³¨æ„åŠ›ï¼Œä»¥é¿å…åœ¨ä¸ç›¸åŒçš„æƒ…å†µä¸‹å£°ç§°å®ƒä»¬æ˜¯ç›¸åŒçš„ã€‚
- en: I should mention at this point that most of you will be familiar with Bertã€‚And
    you could think of the word fragments that are fed into Bert as like the image
    patches I'm using hereã€‚And in Btï¼Œ you have that whole column of representations
    of the same word fragmentã€‚In bookã€‚what's happening presumably as you go up is
    you're gettingã€‚Semanically richer representationsã€‚
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åº”è¯¥æåˆ°æ­¤æ—¶å¤§å¤šæ•°äººå¯¹Bertæ˜¯ç†Ÿæ‚‰çš„ã€‚ä½ å¯ä»¥å°†è¾“å…¥Bertçš„å•è¯ç‰‡æ®µçœ‹ä½œæ˜¯æˆ‘åœ¨è¿™é‡Œä½¿ç”¨çš„å›¾åƒç‰‡æ®µã€‚åœ¨Btä¸­ï¼Œä½ ä¼šçœ‹åˆ°åŒä¸€å•è¯ç‰‡æ®µçš„æ•´ä¸ªè¡¨ç¤ºåˆ—ã€‚åœ¨ä¹¦ä¸­ï¼Œéšç€å±‚çº§çš„æå‡ï¼Œä½ ä¼šè·å¾—æ›´è¯­ä¹‰ä¸°å¯Œçš„è¡¨ç¤ºã€‚
- en: But in Burtï¼Œ there's no attempt to get representations of larger things like
    whole phrasesã€‚å—¯ã€‚This one I'm going to talk about will be a way to modify Bchï¼Œ
    so as you go upã€‚you get bigger and bigger islands of agreementã€‚So for exampleï¼Œ
    after a couple of levelsã€‚then things like New and York will have the different
    fragments of Yorkã€‚
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨Burtä¸­ï¼Œå¹¶æ²¡æœ‰å°è¯•è·å¾—åƒæ•´ä¸ªçŸ­è¯­è¿™æ ·çš„æ›´å¤§äº‹ç‰©çš„è¡¨ç¤ºã€‚å—¯ã€‚æˆ‘å°†è¦è®¨è®ºçš„è¿™ä¸ªæ–¹æ³•æ˜¯ä¿®æ”¹Bchçš„æ–¹æ³•ï¼Œéšç€å±‚çº§çš„æå‡ï¼Œä½ å°†è·å¾—è¶Šæ¥è¶Šå¤§çš„**ä¸€è‡´æ€§å²›å±¿**ã€‚æ‰€ä»¥ä¾‹å¦‚ï¼Œç»è¿‡å‡ ä¸ªå±‚çº§åï¼Œåƒâ€œNewâ€å’Œâ€œYorkâ€è¿™æ ·çš„äº‹ç‰©å°†ä¼šæœ‰ä¸åŒçš„çº¦å…‹ç‰‡æ®µã€‚
- en: I suppose it's got two different fragmentsï¼Œ will have exactly the same representation
    if it was done in the G rightã€‚And then as you go another levelã€‚The fragments of
    new or news probably are thin in its own rightã€‚but the fragments of York would
    all have exactly the same representationã€‚That had this island of agreement and
    that will be a representation of a compound thing and as you go up you're going
    to get these islands of agreement that represent bigger and bigger things and
    that's going to be a much more useful kind of bird because instead of taking vectors
    that represent word fragments and then sort of muning them together by taking
    the max of each for example the max of each component for exampleã€‚
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³å¦‚æœåœ¨æ­£ç¡®çš„Gä¸­å¤„ç†ï¼Œå®ƒå°†æœ‰ä¸¤ä¸ªä¸åŒçš„ç‰‡æ®µï¼Œç¡®åˆ‡åœ°ä¼šæœ‰ç›¸åŒçš„è¡¨ç¤ºã€‚è€Œå½“ä½ æ·±å…¥åˆ°å¦ä¸€ä¸ªå±‚çº§æ—¶ï¼Œæ–°çš„æˆ–æ–°é—»çš„ç‰‡æ®µå¯èƒ½æœ¬èº«å°±å¾ˆè–„ã€‚ä½†çº¦å…‹çš„ç‰‡æ®µå°†ä¼šæœ‰å®Œå…¨ç›¸åŒçš„è¡¨ç¤ºã€‚é‚£å°†æ˜¯ä¸€ä¸ª**ä¸€è‡´æ€§çš„å²›å±¿**ï¼Œä»£è¡¨ä¸€ä¸ªå¤åˆäº‹ç‰©ï¼Œè€Œéšç€å±‚çº§çš„æå‡ï¼Œä½ å°†å¾—åˆ°è¿™äº›ä»£è¡¨è¶Šæ¥è¶Šå¤§äº‹ç‰©çš„ä¸€è‡´æ€§å²›å±¿ï¼Œè¿™å°†æ˜¯ä¸€ç§æ›´æœ‰ç”¨çš„è¡¨ç¤ºï¼Œå› ä¸ºå®ƒä¸æ˜¯é€šè¿‡å–æ¯ä¸ªéƒ¨åˆ†çš„æœ€å¤§å€¼ç­‰æ–¹å¼æ¥å¤„ç†è¡¨ç¤ºå•è¯ç‰‡æ®µã€‚
- en: which is just a crazy thing to do you'd explicitly as you're learning form representations
    of larger parts and the parthole hierarchyã€‚okã€‚So what we're going after in Glom
    is a particular kind of spatial coherence that's more complicated than the spatial
    coherence caused by the fact that surfaces tend to be at the same depth and same
    orientation in nearby patches of an imageã€‚
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœŸæ˜¯ä¸€ä»¶ç–¯ç‹‚çš„äº‹æƒ…ï¼Œå› ä¸ºä½ åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æ˜¾å¼åœ°å½¢æˆæ›´å¤§éƒ¨åˆ†å’Œæ•´ä½“å±‚çº§çš„è¡¨ç¤ºã€‚å¥½å§ã€‚æ‰€ä»¥åœ¨Glomä¸­ï¼Œæˆ‘ä»¬è¿½æ±‚çš„æ˜¯ä¸€ç§ç‰¹å®šçš„ç©ºé—´ä¸€è‡´æ€§ï¼Œè¿™ç§ä¸€è‡´æ€§æ¯”ç”±äºè¡¨é¢å€¾å‘äºåœ¨ç›¸é‚»å›¾åƒç‰‡æ®µä¸­å¤„äºç›¸åŒæ·±åº¦å’Œæ–¹å‘è€Œå¼•èµ·çš„ç©ºé—´ä¸€è‡´æ€§è¦å¤æ‚å¾—å¤šã€‚
- en: We're going after the spatial coherenceã€‚UThat says that if you find a mouth
    in an image and you find a nose in an image and then the right spatial relationship
    to make a faceã€‚then that's a particular kind of coherenceã€‚And we want to go after
    that unsupervisedã€‚ğŸ˜Šã€‚
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿½æ±‚ç©ºé—´ä¸€è‡´æ€§ã€‚Uè¿™æ„å‘³ç€å¦‚æœä½ åœ¨å›¾åƒä¸­æ‰¾åˆ°ä¸€ä¸ªå˜´å·´ï¼Œå¹¶ä¸”åœ¨å›¾åƒä¸­æ‰¾åˆ°ä¸€ä¸ªé¼»å­ï¼Œç„¶åæ‰¾åˆ°æ„æˆé¢å­”çš„æ­£ç¡®ç©ºé—´å…³ç³»ï¼Œé‚£ä¹ˆè¿™å°±æ˜¯ä¸€ç§ç‰¹å®šçš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬å¸Œæœ›ä»¥æ— ç›‘ç£çš„æ–¹å¼å»è¿½æ±‚è¿™ä¸€ç‚¹ã€‚ğŸ˜Š
- en: And we want to discover that kind of coherence in imagesã€‚So before I go into
    more details of Alomã€‚I want to disclaim thatã€‚å•±ã€‚For yearsï¼Œ computer vision treated
    vision as you've got a static image a uniform resolution and you want to say what's
    in itã€‚That's not how vision works in the real world in the real worldã€‚this is
    actually a loop where you decide where to lookã€‚If you're a person or a robotã€‚
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è¦åœ¨å›¾åƒä¸­å‘ç°é‚£ç§ä¸€è‡´æ€§ã€‚åœ¨æ·±å…¥æ¢è®¨Alomä¹‹å‰ï¼Œæˆ‘æƒ³å…ˆå£°æ˜ä¸€ä¸‹ã€‚å•±ã€‚å¤šå¹´æ¥ï¼Œè®¡ç®—æœºè§†è§‰å°†è§†è§‰è§†ä¸ºä¸€ä¸ªé™æ€å›¾åƒï¼Œå…·æœ‰ç»Ÿä¸€çš„åˆ†è¾¨ç‡ï¼Œå¹¶è¯•å›¾åˆ¤æ–­å…¶ä¸­åŒ…å«ä»€ä¹ˆã€‚è¿™å¹¶ä¸æ˜¯ç°å®ä¸–ç•Œä¸­è§†è§‰çš„è¿ä½œæ–¹å¼ã€‚åœ¨ç°å®ä¸–ç•Œä¸­ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªå¾ªç¯ï¼Œä½ å†³å®šè¦çœ‹å“ªé‡Œã€‚å¦‚æœä½ æ˜¯ä¸€ä¸ªäººæˆ–ä¸€ä¸ªæœºå™¨äººã€‚
- en: You better do that intelligentlyã€‚Andã€‚That gives you a sample of the objectic
    arrayã€‚it turns the objectic arrayï¼Œ the incoming lightã€‚Into a retal image and on
    your retinaã€‚you have high resolution in the middle and low resolution around the
    edgesã€‚And so you're focusing on particular details and you neverã€‚
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æœ€å¥½èªæ˜åœ°å»åšã€‚è¿™ç»™ä½ æä¾›äº†å¯¹è±¡æ•°ç»„çš„æ ·æœ¬ã€‚å®ƒå°†å¯¹è±¡æ•°ç»„å’Œå…¥å°„å…‰è½¬åŒ–ä¸ºè§†ç½‘è†œå›¾åƒï¼Œè€Œåœ¨ä½ çš„è§†ç½‘è†œä¸Šï¼Œä¸­é—´æ˜¯é«˜åˆ†è¾¨ç‡ï¼Œè¾¹ç¼˜æ˜¯ä½åˆ†è¾¨ç‡ã€‚å› æ­¤ï¼Œä½ ä¸“æ³¨äºç‰¹å®šç»†èŠ‚ï¼Œè€Œä½ ä»æœªã€‚
- en: ever process the whole image a uniform resolutionã€‚you're always focusing on
    something and processing where you taking at high resolution and everything else
    at much lower resolutionã€‚particularly around the edgesã€‚So I'm going to ignore
    all the complexity of how you decide where to look and all the complexity of how
    you put together the information you get from different extensions by saying let's
    just talk about the very first fixation on a novel image so you look somewhere
    and now what happens on that first fixationã€‚
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ°¸è¿œä¸ä¼šä»¥ç»Ÿä¸€çš„åˆ†è¾¨ç‡å¤„ç†æ•´ä¸ªå›¾åƒã€‚ä½ æ€»æ˜¯ä¸“æ³¨äºæŸä¸ªä¸œè¥¿ï¼Œå¹¶åœ¨é«˜åˆ†è¾¨ç‡ä¸‹å¤„ç†ä½ æ‰€æ³¨è§†çš„éƒ¨åˆ†ï¼Œè€Œå…¶ä»–æ‰€æœ‰éƒ¨åˆ†åˆ™ä»¥æ›´ä½çš„åˆ†è¾¨ç‡å¤„ç†ï¼Œç‰¹åˆ«æ˜¯åœ¨è¾¹ç¼˜ã€‚å› æ­¤ï¼Œæˆ‘å°†å¿½ç•¥ä½ å¦‚ä½•å†³å®šçœ‹å“ªé‡Œä»¥åŠä½ å¦‚ä½•å°†ä»ä¸åŒæ‰©å±•ä¸­è·å¾—çš„ä¿¡æ¯æ•´åˆåœ¨ä¸€èµ·çš„å¤æ‚æ€§ï¼Œç®€å•åœ°è¯´ï¼Œæˆ‘ä»¬åªè®¨è®ºå¯¹æ–°å›¾åƒçš„ç¬¬ä¸€æ¬¡æ³¨è§†ï¼Œæ‰€ä»¥ä½ çœ‹å‘æŸå¤„ï¼Œç°åœ¨ç¬¬ä¸€æ¬¡æ³¨è§†å‘ç”Ÿäº†ä»€ä¹ˆã€‚
- en: We know that the same hardware in the brain is going to be reused for the next
    fixationã€‚but let's just think about the first fixationã€‚So finallyï¼Œ here's a picture
    of the architectureã€‚And this isã€‚ğŸ˜Šï¼ŒThe architectureã€‚For a single locationï¼Œ so like
    for a single word fragment in Btã€‚Andã€‚It shows you what's happening for multiple
    framesï¼Œ so Gom is really designed for videoã€‚
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çŸ¥é“å¤§è„‘ä¸­çš„ç›¸åŒç¡¬ä»¶å°†åœ¨ä¸‹ä¸€ä¸ªæ³¨è§†ä¸­è¢«é‡å¤ä½¿ç”¨ï¼Œä½†æˆ‘ä»¬å…ˆåªè€ƒè™‘ç¬¬ä¸€æ¬¡æ³¨è§†ã€‚å› æ­¤ï¼Œæœ€åï¼Œè¿™æ˜¯ä¸€å¼ æ¶æ„çš„å›¾ã€‚ğŸ˜Šè¿™æ˜¯å•ä¸ªä½ç½®çš„æ¶æ„ï¼Œå°±åƒBtä¸­çš„ä¸€ä¸ªå•è¯ç‰‡æ®µã€‚å®ƒå±•ç¤ºäº†å¤šä¸ªå¸§çš„å‘ç”Ÿæƒ…å†µï¼Œå› æ­¤Gomç¡®å®æ˜¯ä¸ºè§†é¢‘è®¾è®¡çš„ã€‚
- en: but I only talk about applying it to static imagesã€‚Then you should think of
    a static image as a very boring video in which the frames are all the same as
    each otherã€‚Soã€‚I'm showing you three adjacent levels in the hierarchyã€‚And I'm showing
    you what happens over timeã€‚So if you look at the middle levelã€‚Maybe that's the
    sort of major part levelã€‚
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘åªè®¨è®ºå°†å…¶åº”ç”¨äºé™æ€å›¾åƒã€‚é‚£ä¹ˆä½ åº”è¯¥æŠŠé™æ€å›¾åƒè§†ä¸ºä¸€ä¸ªéå¸¸æ— èŠçš„è§†é¢‘ï¼Œå…¶ä¸­æ¯ä¸€å¸§éƒ½æ˜¯ç›¸åŒçš„ã€‚å› æ­¤ï¼Œæˆ‘å±•ç¤ºäº†å±‚æ¬¡ç»“æ„ä¸­çš„ä¸‰ä¸ªç›¸é‚»çº§åˆ«ã€‚æˆ‘æ­£åœ¨å±•ç¤ºæ—¶é—´ä¸Šçš„å˜åŒ–ã€‚å› æ­¤ï¼Œå¦‚æœä½ çœ‹ä¸­é—´çº§åˆ«ï¼Œæˆ–è®¸é‚£æ˜¯ä¸»è¦éƒ¨åˆ†çº§åˆ«ã€‚
- en: And look at that box that says level Lã€‚And that's at frame fourã€‚So the right
    hand level L boxã€‚And let's ask how the state of that boxï¼Œ the state of that embedding
    is determinedã€‚So inside the boxã€‚we're going to get an embeddingã€‚å—¯ã€‚And the embedding
    is going to be the representation of what's going on at the major part level for
    that little patch of the imageã€‚And level L in this diagramï¼Œ all of these embeddings
    will always be devoted to the same patch of the retinal imageã€‚
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹çœ‹é‚£ä¸ªæ ‡è®°ä¸ºçº§åˆ«Lçš„æ¡†ã€‚é‚£æ˜¯åœ¨ç¬¬å››å¸§ã€‚æ‰€ä»¥å³ä¾§çš„çº§åˆ«Læ¡†ã€‚è®©æˆ‘ä»¬é—®ä¸€ä¸‹é‚£ä¸ªæ¡†çš„çŠ¶æ€ï¼Œé‚£ä¸ªåµŒå…¥çš„çŠ¶æ€æ˜¯å¦‚ä½•ç¡®å®šçš„ã€‚å› æ­¤ï¼Œåœ¨æ¡†å†…ï¼Œæˆ‘ä»¬å°†è·å¾—ä¸€ä¸ªåµŒå…¥ã€‚å—¯ã€‚è¿™ä¸ªåµŒå…¥å°†ä»£è¡¨å›¾åƒä¸­é‚£ä¸ªå°è¡¥ä¸çš„ä¸»è¦éƒ¨åˆ†çº§åˆ«å‘ç”Ÿçš„æƒ…å†µã€‚åœ¨è¿™ä¸ªå›¾ç¤ºä¸­çš„çº§åˆ«Lï¼Œæ‰€æœ‰è¿™äº›åµŒå…¥å°†å§‹ç»ˆç”¨äºåŒä¸€è§†ç½‘è†œå›¾åƒçš„è¡¥ä¸ã€‚
- en: okã€‚The level L embeddingã€‚On the right hand sideã€‚You can see there's three things
    determining it thereã€‚there's the green arrowã€‚And for static imagesï¼Œ the greenarrow
    are rather boringã€‚it's just saying you should sort of be similar to the previous
    state of level Lã€‚so it's just doing temporal integrationã€‚ç¬¬ä¸€ã€‚ğŸ˜Šï¼ŒBlue arrow is actually
    a neural net with a couple of hidden layers in itã€‚
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ã€‚å³ä¾§çš„Lçº§åµŒå…¥ã€‚ä½ å¯ä»¥çœ‹åˆ°æœ‰ä¸‰ä»¶äº‹æƒ…åœ¨å†³å®šå®ƒã€‚æœ‰ç»¿è‰²ç®­å¤´ã€‚å¯¹äºé™æ€å›¾åƒï¼Œç»¿è‰²ç®­å¤´ç›¸å½“æ— èŠã€‚å®ƒåªæ˜¯è¡¨ç¤ºä½ åº”è¯¥ä¸Lçº§åˆ«çš„å‰ä¸€ä¸ªçŠ¶æ€ç›¸ä¼¼ã€‚æ‰€ä»¥å®ƒåªæ˜¯è¿›è¡Œæ—¶é—´æ•´åˆã€‚ç¬¬ä¸€ã€‚ğŸ˜Šï¼Œè“è‰²ç®­å¤´å®é™…ä¸Šæ˜¯ä¸€ä¸ªå…·æœ‰å‡ ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œã€‚
- en: I'm just showing you the embeddings hereï¼Œ not all the layers of the neural netã€‚We
    need a couple of hidden layerss to do the coordinate transforms that are requiredã€‚And
    the blue arrowã€‚Is basically taking information at the level below at the previous
    time stepã€‚So level L minus1 on frame three might be representing that I think
    I might be a nostrilã€‚Wellã€‚
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™é‡Œåªå±•ç¤ºåµŒå…¥ï¼Œè€Œä¸æ˜¯ç¥ç»ç½‘ç»œçš„æ‰€æœ‰å±‚ã€‚æˆ‘ä»¬éœ€è¦å‡ ä¸ªéšè—å±‚æ¥å®Œæˆæ‰€éœ€çš„åæ ‡å˜æ¢ã€‚è“è‰²ç®­å¤´åŸºæœ¬ä¸Šæ˜¯ä»å‰ä¸€ä¸ªæ—¶é—´æ­¥çš„ä¸‹ä¸€çº§åˆ«è·å–ä¿¡æ¯ã€‚æ‰€ä»¥åœ¨ç¬¬ä¸‰å¸§çš„L-1çº§åˆ«å¯èƒ½è¡¨ç¤ºæˆ‘å¯èƒ½æ˜¯ä¸€ä¸ªé¼»å­”ã€‚å¥½å§ã€‚
- en: if you think you might be an nostrilï¼Œ what you predict at the next level up
    is a noseã€‚What's moreã€‚if you have a coordinate frame for the nostrilï¼Œ you can
    predict the coordinate frame for the noseã€‚maybe not perfectlyï¼Œ but you have a
    pretty good idea of the orientation position and scale of the noseã€‚So that bottom
    up neural netã€‚ğŸ˜¡ï¼ŒIsã€‚A netch that can take any kind of part at level on mine can
    take an nostrilã€‚
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è®¤ä¸ºä½ å¯èƒ½æ˜¯ä¸€ä¸ªé¼»å­”ï¼Œé‚£ä¹ˆåœ¨ä¸Šä¸€çº§åˆ«ä½ é¢„æµ‹çš„æ˜¯é¼»å­ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå¦‚æœä½ æœ‰é¼»å­”çš„åæ ‡æ¡†æ¶ï¼Œä½ å¯ä»¥é¢„æµ‹é¼»å­çš„åæ ‡æ¡†æ¶ã€‚ä¹Ÿè®¸ä¸æ˜¯å®Œå…¨å‡†ç¡®ï¼Œä½†ä½ å¯¹é¼»å­çš„æ–¹å‘ã€ä½ç½®å’Œå°ºåº¦æœ‰ç›¸å½“å¥½çš„æ¦‚å¿µã€‚æ‰€ä»¥é‚£ä¸ªè‡ªä¸‹è€Œä¸Šçš„ç¥ç»ç½‘ç»œã€‚ğŸ˜¡ï¼Œæ˜¯ã€‚ä¸€ä¸ªå¯ä»¥åœ¨ä»»æ„å±‚çº§æ¥æ”¶éƒ¨åˆ†çš„ç½‘ç»œï¼Œå®ƒå¯ä»¥æ¥æ”¶é¼»å­”ã€‚
- en: but it could also take a steering wheel and predict the car from the steering
    wheelã€‚And predict what you've got at the next level upã€‚ğŸ˜¡ï¼ŒThe red arrow is a top
    down you're all thatã€‚Soã€‚the red arrowã€‚Is predictingã€‚The nose from the whole faceã€‚and
    again it has a couple of hidden layers due coordinate transformsã€‚
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å®ƒä¹Ÿå¯ä»¥æ¥æ”¶æ–¹å‘ç›˜å¹¶é¢„æµ‹æ–¹å‘ç›˜çš„æ±½è½¦ã€‚å¹¶é¢„æµ‹ä½ åœ¨ä¸‹ä¸€çº§åˆ«çš„æƒ…å†µã€‚ğŸ˜¡ï¼Œçº¢è‰²ç®­å¤´æ˜¯ä¸€ä¸ªè‡ªä¸Šè€Œä¸‹çš„ç½‘ç»œã€‚æ‰€ä»¥ã€‚çº¢è‰²ç®­å¤´ã€‚æ˜¯ä»æ•´ä¸ªé¢éƒ¨é¢„æµ‹é¼»å­ã€‚åŒæ ·ï¼Œå®ƒæœ‰å‡ ä¸ªéšè—å±‚ç”¨äºåæ ‡å˜æ¢ã€‚
- en: Because if you know the co frame of the face and you know the relationship between
    a face and a nose and that's going to be in the weights of that top down you're
    on netã€‚Then you can predict that it's a nose and what the pose of the nose isã€‚And
    that's all going to be in activities in that embedding betterã€‚Okayã€‚Now there's
    all of that is what's going on in one column of hardware that's all about a specific
    patch of the imageã€‚
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå¦‚æœä½ çŸ¥é“é¢éƒ¨çš„åæ ‡æ¡†æ¶ï¼Œå¹¶ä¸”çŸ¥é“é¢éƒ¨ä¸é¼»å­ä¹‹é—´çš„å…³ç³»ï¼Œè€Œè¿™å°†åŒ…å«åœ¨è‡ªä¸Šè€Œä¸‹çš„ç½‘ç»œæƒé‡ä¸­ã€‚é‚£ä¹ˆä½ å°±å¯ä»¥é¢„æµ‹å®ƒæ˜¯é¼»å­ä»¥åŠé¼»å­çš„å§¿æ€ã€‚è¿™ä¸€åˆ‡éƒ½ä¼šåœ¨é‚£ä¸ªåµŒå…¥ä¸­çš„æ´»åŠ¨ä¸­ä½“ç°ã€‚å¥½å§ã€‚ç°åœ¨ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯åœ¨ä¸€ä¸ªç¡¬ä»¶åˆ—ä¸­å‘ç”Ÿçš„ï¼Œéƒ½æ˜¯å…³äºå›¾åƒç‰¹å®šåŒºåŸŸçš„ã€‚
- en: so that's veryï¼Œ very like what's going on for one word fragment in Bt you have
    all these levels of representationã€‚å—¯ã€‚It's a bit confusing exactly what the ratio
    of this is to Bt and I'll give you the reference to a long archive paper at the
    end that has a whole section on how this relates to Btã€‚
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™ä¸Btä¸­çš„ä¸€ä¸ªè¯ç‰‡æ®µçš„æƒ…å†µéå¸¸ç›¸ä¼¼ï¼Œä½ æœ‰æ‰€æœ‰è¿™äº›è¡¨ç¤ºå±‚ã€‚å—¯ã€‚ç¡®åˆ‡æ¥è¯´ï¼Œè¿™ä¸Btçš„æ¯”ç‡æœ‰ç‚¹ä»¤äººå›°æƒ‘ï¼Œæˆ‘ä¼šåœ¨æœ€åç»™ä½ ä¸€ä¸ªé•¿æ¡£æ¡ˆè®ºæ–‡çš„å‚è€ƒï¼Œé‡Œé¢æœ‰ä¸€æ•´èŠ‚è®²è¿°å®ƒä¸Btçš„å…³ç³»ã€‚
- en: But it's confusing because this has time stepsã€‚And that makes it a little more
    complicatedï¼Œ okayã€‚So those are three things that determine the level andbeddingï¼Œ
    but there's one fourth thingã€‚Which is in black at the bottom thereã€‚And that's
    the only way in which different locations interactã€‚And that's a very simplified
    form of a transformerã€‚If you take a transformer as in Btï¼Œ and you sayã€‚
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å¾ˆä»¤äººå›°æƒ‘ï¼Œå› ä¸ºè¿™æ¶‰åŠåˆ°æ—¶é—´æ­¥ã€‚è¿™ä½¿å¾—äº‹æƒ…å˜å¾—æœ‰ç‚¹å¤æ‚ï¼Œå¥½å§ã€‚æ‰€ä»¥è¿™æœ‰ä¸‰ä¸ªå†³å®šæ°´å¹³å’ŒåµŒå…¥çš„å› ç´ ï¼Œä½†è¿˜æœ‰ç¬¬å››ä¸ªå› ç´ ã€‚å°±æ˜¯åº•éƒ¨çš„é»‘è‰²éƒ¨åˆ†ã€‚è¿™æ˜¯ä¸åŒä½ç½®ç›¸äº’ä½œç”¨çš„å”¯ä¸€æ–¹å¼ã€‚è¿™æ˜¯å˜å‹å™¨çš„ä¸€ä¸ªéå¸¸ç®€åŒ–çš„å½¢å¼ã€‚å¦‚æœä½ æŠŠå˜å‹å™¨è§†ä¸ºBtï¼Œç„¶åä½ è¯´ã€‚
- en: let's make the embeddings and the keys and the queries and the values all be
    the same as each otherã€‚We just have this one vectorã€‚So now all you're trying to
    doã€‚Is make the level L embedding in one columnã€‚Be the same as the level L embedding
    in nearby columnsã€‚But it's going to be gatedï¼Œ you're only to try and make it be
    the sameã€‚Ifã€‚It's already quite similarã€‚
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®©åµŒå…¥ã€é”®ã€æŸ¥è¯¢å’Œå€¼å½¼æ­¤ç›¸åŒã€‚æˆ‘ä»¬åªæœ‰è¿™ä¸ªå‘é‡ã€‚æ‰€ä»¥ç°åœ¨ä½ è¦åšçš„å°±æ˜¯ä½¿ä¸€åˆ—ä¸­çš„Lçº§åµŒå…¥ä¸é™„è¿‘åˆ—ä¸­çš„Lçº§åµŒå…¥ç›¸åŒã€‚ä½†è¿™ä¼šå—åˆ°é™åˆ¶ï¼Œä½ åªä¼šè¯•å›¾ä½¿å®ƒä»¬ç›¸åŒã€‚å¦‚æœã€‚å®ƒä»¬å·²ç»ç›¸å½“ç›¸ä¼¼ã€‚
- en: So here's how the attention worksã€‚You take the level L embedding in location
    Xï¼Œ that's Alexã€‚And you take the level only em bedding in the nearby location Yï¼Œ
    that or whyã€‚You take the scalr productã€‚You expiateã€‚And you normalizeï¼Œ in other
    wordsï¼Œ you do a softmã€‚And that gives you the weight to useã€‚ğŸ˜¡ï¼ŒInã€‚Your desire to
    makeã€‚LXï¼Œ be the same as L Yã€‚
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è¿™å°±æ˜¯æ³¨æ„åŠ›å¦‚ä½•å·¥ä½œçš„ã€‚ä½ å–ä½ç½®Xä¸­çš„çº§åˆ«LåµŒå…¥ï¼Œä¹Ÿå°±æ˜¯Alexã€‚ä½ å–é™„è¿‘ä½ç½®Yä¸­çš„çº§åˆ«åµŒå…¥ï¼Œä¹Ÿå°±æ˜¯æˆ–Yã€‚ä½ è¿›è¡Œç‚¹ç§¯ã€‚ä½ è¿›è¡ŒæŒ‡æ•°è¿ç®—ã€‚ç„¶åä½ è¿›è¡Œå½’ä¸€åŒ–ï¼Œæ¢å¥è¯è¯´ï¼Œä½ åšä¸€ä¸ªsoftmaxã€‚è¿™ç»™äº†ä½ æƒé‡æ¥ä½¿ç”¨ã€‚ğŸ˜¡ï¼Œåœ¨ã€‚ä½ æƒ³è®©LXä¸LYç›¸åŒçš„æ„¿æœ›ä¸­ã€‚
- en: So the input producedã€‚By this from neighborsã€‚Is an attention weighted average
    of the level level embedding of nearby columnsï¼Ÿ
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç”±æ­¤äº§ç”Ÿçš„è¾“å…¥ã€‚æ¥è‡ªé‚»å±…çš„ï¼Œæ˜¯é™„è¿‘åˆ—çš„çº§åˆ«åµŒå…¥çš„æ³¨æ„åŠ›åŠ æƒå¹³å‡ï¼Ÿ
- en: And that's an extra input that you get is trying to make you agree with nearby
    things and that's what's going to cause you to get these islands of agreementã€‚So
    back to this pictureã€‚I thinkã€‚Yeahã€‚This is what we'd like to seeã€‚ğŸ˜¡ï¼ŒAnd the reasonã€‚We
    get those that big island of agreement at the object levelã€‚Is because we're trying
    to get agreement thereï¼Œ we're trying to learn the coordinate transformã€‚
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: é¢å¤–çš„è¾“å…¥è¯•å›¾è®©ä½ ä¸å‘¨å›´çš„äº‹ç‰©è¾¾æˆä¸€è‡´ï¼Œè¿™å°±æ˜¯å¯¼è‡´ä½ è·å¾—è¿™äº›å…±è¯†å²›å±¿çš„åŸå› ã€‚æ‰€ä»¥å›åˆ°è¿™ä¸ªå›¾ã€‚æˆ‘æƒ³ã€‚æ˜¯çš„ã€‚è¿™æ˜¯æˆ‘ä»¬æƒ³çœ‹åˆ°çš„ã€‚ğŸ˜¡ï¼Œè€ŒåŸå› æ˜¯ã€‚æˆ‘ä»¬åœ¨å¯¹è±¡å±‚é¢è·å¾—é‚£ä¹ˆå¤§çš„å…±è¯†å²›å±¿ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬åœ¨åŠªåŠ›è¾¾æˆå…±è¯†ï¼Œæˆ‘ä»¬åœ¨å°è¯•å­¦ä¹ åæ ‡å˜æ¢ã€‚
- en: From the red arrows to the level above and from the green arrows to the level
    aboveã€‚such that we get agreementã€‚okã€‚Nowï¼Œ one thing we need to worry aboutã€‚Is that
    the difficult thing in perceptionã€‚å—¯ã€‚It's not so bad in languageã€‚it's probably
    worse than visual perceptionï¼Œ is that there's a lot of ambiguityã€‚
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä»çº¢è‰²ç®­å¤´åˆ°ä¸Šå±‚ï¼Œä»ç»¿è‰²ç®­å¤´åˆ°ä¸Šå±‚ã€‚è¿™æ ·æˆ‘ä»¬å°±èƒ½è¾¾æˆå…±è¯†ã€‚å¥½çš„ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦æ‹…å¿ƒçš„ä¸€ä»¶äº‹æ˜¯ï¼Œæ„ŸçŸ¥ä¸­çš„å›°éš¾ä¹‹å¤„ã€‚å—¯ã€‚åœ¨è¯­è¨€ä¸­æ²¡é‚£ä¹ˆç³Ÿç³•ã€‚å¯èƒ½æ¯”è§†è§‰æ„ŸçŸ¥æ›´ç³Ÿï¼Œå¾ˆå¤šæ¨¡ç³Šæ€§ã€‚
- en: If I'm looking at a line drawingï¼Œ for exampleï¼Œ I see a circleã€‚Well a circle
    could be the right eye of a face or it could be the left eye of a face or it could
    be the front wheel of a car or the back wheel of a car there's all sorts of things
    that that circle could beã€‚
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘åœ¨çœ‹ä¸€å¹…çº¿æ¡ç”»ï¼Œä¾‹å¦‚ï¼Œæˆ‘çœ‹åˆ°ä¸€ä¸ªåœ†ã€‚é‚£ä¹ˆè¿™ä¸ªåœ†å¯èƒ½æ˜¯è„¸çš„å³çœ¼ï¼Œä¹Ÿå¯èƒ½æ˜¯è„¸çš„å·¦çœ¼ï¼Œæˆ–è€…å®ƒå¯èƒ½æ˜¯æ±½è½¦çš„å‰è½®æˆ–åè½®ï¼Œè¿™ä¸ªåœ†å¯ä»¥æœ‰å„ç§å¯èƒ½ã€‚
- en: And we'd like to disambiguate the circleã€‚And there's a long line of workã€‚usingsing
    things like markco random fieldsï¼Œ here we need a variational mark random fieldã€‚which
    I'll call a transformational random fieldã€‚Because the interaction betweenï¼Œ for
    exampleã€‚something that might be an eye and something that might be a mouseã€‚
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›æ¶ˆé™¤åœ†åœˆçš„æ­§ä¹‰ã€‚è¿™é‡Œæœ‰ä¸€ç³»åˆ—çš„å·¥ä½œï¼Œä½¿ç”¨è¯¸å¦‚é©¬å°”å¯å¤«éšæœºåœºçš„ä¸œè¥¿ï¼Œè¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå˜åˆ†é©¬å°”å¯å¤«éšæœºåœºã€‚æˆ‘ç§°ä¹‹ä¸ºå˜æ¢éšæœºåœºã€‚å› ä¸ºä¾‹å¦‚ï¼ŒæŸä¸ªå¯èƒ½æ˜¯çœ¼ç›çš„ä¸œè¥¿å’ŒæŸä¸ªå¯èƒ½æ˜¯å˜´å·´çš„ä¸œè¥¿ä¹‹é—´çš„äº’åŠ¨ã€‚
- en: Needs to be gated by corner transformsã€‚You knowï¼Œ for theã€‚let's take a nose on
    our mouth because that's my standard thingã€‚If you take something that might be
    a nose and you want to askã€‚does anybody out there support the IR noseï¼ŸWellï¼Œ what
    you'd like to do is send to everything nearby a message sayingã€‚
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦é€šè¿‡è§’ç‚¹å˜æ¢æ¥é™åˆ¶ã€‚ä½ çŸ¥é“ï¼Œè®©æˆ‘ä»¬æŠŠé¼»å­æ”¾åœ¨å˜´å·´ä¸Šï¼Œå› ä¸ºé‚£æ˜¯æˆ‘çš„æ ‡å‡†ã€‚å¦‚æœä½ æ‹¿ä¸€ä¸ªå¯èƒ½æ˜¯é¼»å­çš„ä¸œè¥¿ï¼Œä½ æƒ³é—®ã€‚æœ‰è°æ”¯æŒIRé¼»å­ï¼Ÿå¥½å§ï¼Œä½ æƒ³åšçš„å°±æ˜¯å‘é™„è¿‘çš„æ‰€æœ‰ä¸œè¥¿å‘é€ä¸€æ¡ä¿¡æ¯ã€‚
- en: ğŸ˜¡ï¼ŒUmï¼Œ do you have the right kind of pose and right kind of identity to support
    the idea that I'mknowsï¼Ÿ
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜¡ï¼Œå—¯ï¼Œä½ æ˜¯å¦æ‹¥æœ‰æ­£ç¡®çš„å§¿åŠ¿å’Œèº«ä»½æ¥æ”¯æŒâ€œæˆ‘çŸ¥é“â€çš„æƒ³æ³•ï¼Ÿ
- en: And so you'd likeï¼Œ for exampleï¼Œ to send out a message from the noseã€‚You'd send
    out a message to all nearby locations saying does anybody have a mouth with the
    pose that I predict by taking the pose of the noseã€‚multiplying by the coordinate
    transform between a nose and a mouth and now I can predict the pose of the mouth
    is there anybody out there with that pose who thinks they might be a mouthï¼Ÿ
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä½ æƒ³ï¼Œä¾‹å¦‚ï¼Œä»é¼»å­å‘å‡ºä¿¡æ¯ã€‚ä½ ä¼šå‘æ‰€æœ‰é™„è¿‘çš„ä½ç½®å‘é€ä¿¡æ¯ï¼Œè¯¢é—®æ˜¯å¦æœ‰å˜´å·´çš„å§¿åŠ¿ç¬¦åˆæˆ‘é€šè¿‡é¼»å­çš„å§¿åŠ¿ä¹˜ä»¥é¼»å­ä¸å˜´å·´ä¹‹é—´çš„åæ ‡å˜æ¢æ‰€é¢„æµ‹çš„å§¿åŠ¿ï¼Œç°åœ¨æˆ‘å¯ä»¥é¢„æµ‹å˜´å·´çš„å§¿åŠ¿ï¼Œæ˜¯å¦æœ‰è°è®¤ä¸ºä»–ä»¬å¯èƒ½æ˜¯å˜´å·´ï¼Ÿ
- en: And I think you can see you're going to have to send out a lot of different
    messagesã€‚ğŸ˜Šã€‚For each kind of other thing that might support youï¼Œ you're going to
    send a different messageã€‚so you're going to need a multi headedã€‚transformformer
    and it's going to be doing these coordinate transforms and you have to corner
    transform the inverse transform on the way back because if the mouse supports
    you what it needs to support is a nose not with the pose of the mouthã€‚
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºä½ å¯ä»¥çœ‹åˆ°ï¼Œä½ å°†ä¸å¾—ä¸å‘é€å¾ˆå¤šä¸åŒçš„ä¿¡æ¯ã€‚ğŸ˜Šã€‚å¯¹äºå¯èƒ½æ”¯æŒä½ çš„æ¯ä¸€ç§å…¶ä»–äº‹ç‰©ï¼Œä½ å°†å‘é€ä¸åŒçš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œä½ å°†éœ€è¦ä¸€ä¸ªå¤šå¤´å˜æ¢å™¨ï¼Œå®ƒå°†è¿›è¡Œè¿™äº›åæ ‡å˜æ¢ï¼Œä½ å¿…é¡»åœ¨è¿”å›æ—¶è¿›è¡Œé€†å˜æ¢ï¼Œå› ä¸ºå¦‚æœé¼ æ ‡æ”¯æŒä½ ï¼Œå®ƒéœ€è¦æ”¯æŒçš„æ˜¯é¼»å­ï¼Œè€Œä¸æ˜¯å˜´å·´çš„å§¿åŠ¿ã€‚
- en: but with the appropriate poseã€‚So that's going to get very complicatedã€‚you're
    going have n squared interactions all with coordinate transformsã€‚There's another
    way of doing it that's much simplerï¼Œ that's called a half transformã€‚ğŸ˜Šã€‚At least
    it's much simpler if you have a way of representing ambiguityã€‚
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¦æœ‰é€‚å½“çš„å§¿åŠ¿ã€‚å› æ­¤ï¼Œè¿™å°†å˜å¾—éå¸¸å¤æ‚ã€‚ä½ å°†æœ‰nå¹³æ–¹çš„äº¤äº’ï¼Œéƒ½æ˜¯å¸¦æœ‰åæ ‡å˜æ¢çš„ã€‚æœ‰å¦ä¸€ç§åšæ³•ï¼Œæ›´ç®€å•ï¼Œè¢«ç§°ä¸ºåŠå˜æ¢ã€‚ğŸ˜Šã€‚è‡³å°‘å¦‚æœä½ æœ‰åŠæ³•è¡¨ç¤ºæ¨¡ç³Šæ€§ï¼Œé‚£å°±ç®€å•å¾—å¤šã€‚
- en: So instead of these direct interactions between parts like a nose and a mouthã€‚What
    you're going to do is you're going to make each of the partsã€‚Predict the wholeã€‚So
    the nose can predict the faceï¼Œ and it can predict the pose of the faceã€‚and the
    mouth can also predict the faceã€‚ğŸ˜Šï¼ŒNow these will be in different columns of Gã€‚
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œä»£æ›¿è¿™äº›éƒ¨åˆ†ä¹‹é—´çš„ç›´æ¥äº¤äº’ï¼Œæ¯”å¦‚é¼»å­å’Œå˜´å·´ã€‚ä½ è¦åšçš„æ˜¯è®©æ¯ä¸ªéƒ¨åˆ†é¢„æµ‹æ•´ä½“ã€‚å› æ­¤ï¼Œé¼»å­å¯ä»¥é¢„æµ‹è„¸ï¼Œå¹¶ä¸”å®ƒå¯ä»¥é¢„æµ‹è„¸çš„å§¿åŠ¿ï¼Œè€Œå˜´å·´ä¹Ÿå¯ä»¥é¢„æµ‹è„¸ã€‚ğŸ˜Šï¼Œç°åœ¨è¿™äº›å°†ä½äºGçš„ä¸åŒåˆ—ä¸­ã€‚
- en: but in one column of Gï¼Œ you'll have a nose preing faceã€‚In a nearby columnã€‚you'll
    have a mouth predicting a faceã€‚And those two faces should be the same if this
    really is a faceã€‚So when you do this attention weighted averaging with nearby
    thingsã€‚what you're doing is you're getting confirmationã€‚That the supportã€‚For the
    hypothesis you've gotã€‚
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†åœ¨Gçš„ä¸€åˆ—ä¸­ï¼Œä½ ä¼šæœ‰ä¸€ä¸ªé¼»å­åœ¨é¢„æµ‹è„¸ã€‚åœ¨é™„è¿‘çš„ä¸€åˆ—ä¸­ï¼Œä½ ä¼šæœ‰ä¸€ä¸ªå˜´å·´åœ¨é¢„æµ‹è„¸ã€‚å¦‚æœè¿™çœŸçš„æ˜¯ä¸€å¼ è„¸ï¼Œè¿™ä¸¤å¼ è„¸åº”è¯¥æ˜¯ç›¸åŒçš„ã€‚å› æ­¤ï¼Œå½“ä½ å¯¹é™„è¿‘çš„äº‹ç‰©è¿›è¡Œæ³¨æ„åŠ›åŠ æƒå¹³å‡æ—¶ï¼Œä½ æ‰€åšçš„æ˜¯è·å–ç¡®è®¤ã€‚é‚£å°±æ˜¯æ”¯æŒä½ å‡è®¾çš„è¯æ®ã€‚
- en: I meanï¼Œ suppose to in one column make the hypothesisï¼Œ it's a face with this
    poemsã€‚That gets supported by nearby columns that derived the very same embedding
    from quite different dataã€‚one derived it from the nose and one derived it from
    the mouthã€‚And this doesn't require any dynamic routingã€‚Because the embeddings
    are always referring to what's going on in the same small patch of the imageã€‚
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ„æ€æ˜¯ï¼Œå‡è®¾åœ¨ä¸€åˆ—ä¸­æå‡ºå‡è®¾ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰è¿™ç§å§¿åŠ¿çš„è„¸ã€‚è¿™ä¸ªå‡è®¾å¾—åˆ°äº†æ¥è‡ªé™„è¿‘åˆ—çš„æ”¯æŒï¼Œè¿™äº›åˆ—ä»ä¸åŒçš„æ•°æ®ä¸­æ¨å¯¼å‡ºå®Œå…¨ç›¸åŒçš„åµŒå…¥ï¼Œä¸€ä¸ªæ˜¯ä»é¼»å­æ¨å¯¼çš„ï¼Œå¦ä¸€ä¸ªæ˜¯ä»å˜´å·´æ¨å¯¼çš„ã€‚è¿™ä¸éœ€è¦ä»»ä½•åŠ¨æ€è·¯ç”±ã€‚å› ä¸ºè¿™äº›åµŒå…¥å§‹ç»ˆå‚è€ƒçš„æ˜¯å›¾åƒä¸­åŒä¸€å°è¡¥ä¸ä¸Šå‘ç”Ÿçš„äº‹æƒ…ã€‚
- en: We in a column there's no routingã€‚And between columnsã€‚There's something a bit
    like rootingã€‚but it's just the standard transformer kind of attentionã€‚you're just
    trying to agree with things that are similarã€‚Andã€‚Okayï¼Œ so that's how Gs meant
    to workã€‚And the big problem isã€‚ğŸ˜¡ï¼ŒThat if I see a circleï¼Œ it might be a left eyeï¼Œ
    it might be a right eyeã€‚
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€åˆ—ä¸­æ²¡æœ‰è·¯ç”±ã€‚åœ¨åˆ—ä¸åˆ—ä¹‹é—´ï¼Œæœ‰äº›ç±»ä¼¼è·¯ç”±çš„ä¸œè¥¿ï¼Œä½†è¿™ä»…ä»…æ˜¯æ ‡å‡†å˜æ¢å™¨ç±»å‹çš„æ³¨æ„åŠ›ã€‚ä½ åªæ˜¯è¯•å›¾ä¸ç›¸ä¼¼çš„äº‹ç‰©è¾¾æˆä¸€è‡´ã€‚å¥½çš„ï¼Œè¿™å°±æ˜¯Gsçš„å·¥ä½œæ–¹å¼ã€‚å¤§é—®é¢˜æ˜¯ã€‚ğŸ˜¡ï¼Œå¦‚æœæˆ‘çœ‹åˆ°ä¸€ä¸ªåœ†åœˆï¼Œå®ƒå¯èƒ½æ˜¯å·¦çœ¼ï¼Œä¹Ÿå¯èƒ½æ˜¯å³çœ¼ã€‚
- en: it might be aã€‚From wheel of a car might be the battery wheel of a car because
    my embedding for a particular patch at a particular level has to be able to represent
    anythingã€‚When I get an ambiguous thing I have to do with all these possibilities
    of what whole it might be part of so instead of trying to resolve ambiguity at
    the part level what I can do is jump to the next level up and resolve the ambiguity
    there just by saying things are the sameã€‚
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå¯èƒ½æ˜¯æ±½è½¦çš„è½¦è½®ï¼Œä¹Ÿå¯èƒ½æ˜¯æ±½è½¦çš„ç”µæ± ï¼Œå› ä¸ºæˆ‘å¯¹ç‰¹å®šå±‚ä¸Šç‰¹å®šè¡¥ä¸çš„åµŒå…¥å¿…é¡»èƒ½å¤Ÿè¡¨ç¤ºä»»ä½•ä¸œè¥¿ã€‚å½“æˆ‘é‡åˆ°æ¨¡ç³Šçš„äº‹ç‰©æ—¶ï¼Œæˆ‘å¿…é¡»å¤„ç†å®ƒå¯èƒ½å±äºçš„æ‰€æœ‰æ•´ä½“å¯èƒ½æ€§ï¼Œå› æ­¤ï¼Œä»£æ›¿åœ¨éƒ¨åˆ†å±‚é¢ä¸Šå°è¯•è§£å†³æ¨¡ç³Šæ€§ï¼Œæˆ‘å¯ä»¥è·³åˆ°æ›´é«˜çº§åˆ«ï¼Œå¹¶é€šè¿‡è¯´äº‹ç‰©æ˜¯ç›¸åŒçš„æ¥è§£å†³æ¨¡ç³Šæ€§ã€‚
- en: which is an easier way to resolve ambiguityã€‚But the cost of that is I have to
    be able to represent all the ambiguity I get at the next level upã€‚Now it turns
    out you can do that we've done a little toy example where you can actually preserve
    this ambiguityã€‚
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç§æ›´ç®€å•çš„æ–¹å¼æ¥è§£å†³æ¨¡ç³Šæ€§ã€‚ä½†è¿™æ ·åšçš„ä»£ä»·æ˜¯æˆ‘å¿…é¡»èƒ½å¤Ÿåœ¨ä¸‹ä¸€ä¸ªæ›´é«˜çº§åˆ«ä¸Šè¡¨ç¤ºæ‰€æœ‰çš„æ¨¡ç³Šæ€§ã€‚ç»“æœè¯æ˜ï¼Œä½ å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åšäº†ä¸€ä¸ªå°ç©å…·ç¤ºä¾‹ï¼Œå®é™…ä¸Šå¯ä»¥ä¿ç•™è¿™ç§æ¨¡ç³Šæ€§ã€‚
- en: But it's difficultï¼Œ it's the kind of thing neural nets are good atã€‚So if you
    think about the embedding of the next level upã€‚You've got a whole bunch of neurons
    whose activities are that embeddingã€‚And you want to represent a highly multimodal
    distributionã€‚
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™å¾ˆå›°éš¾ï¼Œè¿™æ˜¯ç¥ç»ç½‘ç»œæ“…é•¿çš„äº‹æƒ…ã€‚æ‰€ä»¥å¦‚æœä½ è€ƒè™‘ä¸‹ä¸€å±‚çš„åµŒå…¥ã€‚ä½ æœ‰ä¸€å¤§å †ç¥ç»å…ƒï¼Œå®ƒä»¬çš„æ´»åŠ¨å°±æ˜¯é‚£ä¸ªåµŒå…¥ã€‚ä½ æƒ³è¦è¡¨ç¤ºä¸€ä¸ªé«˜åº¦å¤šæ¨¡æ€çš„åˆ†å¸ƒã€‚
- en: like it might be a car with this pose or a car with that pose or a face with
    this pose or a face with that poseã€‚All of these are possible predictions for finding
    a circleã€‚And so you have to represent all thatã€‚And the question isï¼Œ can you let's
    do thatï¼ŸAnd I think the way they must be doing it isã€‚Each neuron in the embeddingã€‚Stands
    for an unnormalized log probability distribution over this huge space of possible
    identities and possible posesã€‚
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”å¦‚è¯´å¯èƒ½æ˜¯ä¸€è¾†è½¦åœ¨è¿™ä¸ªå§¿åŠ¿ï¼Œæˆ–è€…ä¸€è¾†è½¦åœ¨é‚£ä¸ªå§¿åŠ¿ï¼Œæˆ–è€…ä¸€å¼ è„¸åœ¨è¿™ä¸ªå§¿åŠ¿ï¼Œæˆ–è€…ä¸€å¼ è„¸åœ¨é‚£ä¸ªå§¿åŠ¿ã€‚æ‰€æœ‰è¿™äº›éƒ½æ˜¯å¯»æ‰¾ä¸€ä¸ªåœ†çš„å¯èƒ½é¢„æµ‹ã€‚å› æ­¤ä½ å¿…é¡»è¡¨ç¤ºæ‰€æœ‰è¿™äº›ã€‚é—®é¢˜æ˜¯ï¼Œä½ èƒ½åšåˆ°å—ï¼Ÿæˆ‘è®¤ä¸ºå®ƒä»¬å¿…é¡»æ˜¯è¿™æ ·åšçš„ã€‚åµŒå…¥ä¸­çš„æ¯ä¸ªç¥ç»å…ƒã€‚ä»£è¡¨ç€è¿™ä¸ªå·¨å¤§ç©ºé—´ä¸­å¯èƒ½èº«ä»½å’Œå¯èƒ½å§¿åŠ¿çš„æœªå½’ä¸€åŒ–å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒã€‚
- en: the sort of cross product of identities impose posesã€‚å—¯ã€‚And so the neuron is
    this rather the log probability distribution over that spaceã€‚And when you activate
    the neuronï¼Œ what it's saying is add in that log probability distribution to what
    you've already gotã€‚And so now if you have a whole bunch of load probability distributionsã€‚And
    you add them all togetherã€‚
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§èº«ä»½ä¸å§¿åŠ¿çš„äº¤å‰ä¹˜ç§¯ã€‚å—¯ã€‚æ‰€ä»¥ç¥ç»å…ƒå°±æ˜¯è¿™ä¸ªç©ºé—´çš„å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒã€‚å½“ä½ æ¿€æ´»ç¥ç»å…ƒæ—¶ï¼Œå®ƒæ‰€è¡¨ç¤ºçš„æ˜¯å°†è¯¥å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒæ·»åŠ åˆ°ä½ å·²ç»æ‹¥æœ‰çš„å†…å®¹ä¸­ã€‚å› æ­¤ï¼Œç°åœ¨å¦‚æœä½ æœ‰ä¸€å¤§å †ä½æ¦‚ç‡åˆ†å¸ƒã€‚å¹¶ä¸”æŠŠå®ƒä»¬åŠ åœ¨ä¸€èµ·ã€‚
- en: You can get a much more peaky log probability distributionã€‚And when you expentiate
    to get a probability distributionï¼Œ it gets very peakyã€‚And so very vague basis
    functionsã€‚In this joint space of pose and identity and basis functions in the
    log probability in that spaceã€‚Can be combined to produce sharp conclusionsã€‚Soã€‚I
    think that's how neurons are representing things most people think about neurons
    as they think about the thing that they're representingã€‚
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°±èƒ½å¾—åˆ°ä¸€ä¸ªæ›´å°–é”çš„å¯¹æ•°æ¦‚ç‡åˆ†å¸ƒã€‚å½“ä½ æŒ‡æ•°åŒ–ä»¥è·å¾—æ¦‚ç‡åˆ†å¸ƒæ—¶ï¼Œå®ƒä¼šå˜å¾—éå¸¸å°–é”ã€‚å› æ­¤ï¼Œéå¸¸æ¨¡ç³Šçš„åŸºå‡½æ•°ã€‚åœ¨è¿™ä¸ªå§¿åŠ¿å’Œèº«ä»½çš„è”åˆç©ºé—´ï¼Œä»¥åŠè¯¥ç©ºé—´ä¸­çš„å¯¹æ•°æ¦‚ç‡ã€‚å¯ä»¥ç»“åˆèµ·æ¥äº§ç”Ÿæ˜ç¡®çš„ç»“è®ºã€‚æ‰€ä»¥ï¼Œæˆ‘è®¤ä¸ºè¿™å°±æ˜¯ç¥ç»å…ƒå¦‚ä½•è¡¨ç¤ºäº‹ç‰©çš„æ–¹å¼ï¼Œå¤§å¤šæ•°äººå¯¹ç¥ç»å…ƒçš„æ€è€ƒæ˜¯ä»–ä»¬æ­£åœ¨è¡¨ç¤ºçš„äº‹ç‰©ã€‚
- en: But obviously in perceptionï¼Œ you have to deal with uncertainty and so neurons
    have to be good at representing multimodal distributionsã€‚And this is the only
    way I can think of that's good at doing itã€‚That's a rather weak argumentã€‚I mean
    it's the argument that led Chomsky to believe that language wasn't learned because
    he couldn't think of how it was learnedã€‚My view is neurons must be using this
    representation because I can't think of any other way of doing itã€‚
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¾ç„¶åœ¨æ„ŸçŸ¥ä¸­ï¼Œä½ å¿…é¡»å¤„ç†ä¸ç¡®å®šæ€§ï¼Œå› æ­¤ç¥ç»å…ƒå¿…é¡»å–„äºè¡¨ç¤ºå¤šæ¨¡æ€åˆ†å¸ƒã€‚è¿™æ˜¯æˆ‘èƒ½æƒ³åˆ°çš„å”¯ä¸€æœ‰æ•ˆçš„æ–¹æ³•ã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å½“è–„å¼±çš„è®ºç‚¹ã€‚æˆ‘çš„æ„æ€æ˜¯ï¼Œè¿™æ˜¯å¯¼è‡´ä¹”å§†æ–¯åŸºç›¸ä¿¡è¯­è¨€ä¸æ˜¯å­¦ä¹ çš„è®ºç‚¹ï¼Œå› ä¸ºä»–æ— æ³•æƒ³åˆ°å®ƒæ˜¯å¦‚ä½•å­¦ä¹ çš„ã€‚æˆ‘çš„è§‚ç‚¹æ˜¯ï¼Œç¥ç»å…ƒå¿…é¡»ä½¿ç”¨è¿™ç§è¡¨ç¤ºæ–¹æ³•ï¼Œå› ä¸ºæˆ‘æƒ³ä¸å‡ºå…¶ä»–ä»»ä½•æ–¹æ³•ã€‚
- en: okã€‚I just said all that because I got ahead of myself because I got excitedã€‚Now
    the reason you can get away with thisï¼Œ the reason you have these very vague distributions
    in the unormalized low probability spaceã€‚Is because these neurons are all dedicated
    to a small patch of image and they're all trying to represent the thing that's
    happening that patch of image so you're only trying to represent one thingã€‚you're
    not trying to represent some set of possible objects if you're trying to represent
    some set of possible objects you have a horrible binding problem and you couldn't
    use these very vague distributions but so long as you know that all of these neuronsã€‚
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ã€‚æˆ‘åˆšæ‰è¯´äº†è¿™äº›ï¼Œå› ä¸ºæˆ‘æœ‰ç‚¹å…´å¥‹ï¼Œæå‰å¼€å§‹äº†ã€‚ç°åœ¨ä½ èƒ½è¿™æ ·åšçš„åŸå› ï¼Œä½ åœ¨æœªå½’ä¸€åŒ–çš„ä½æ¦‚ç‡ç©ºé—´ä¸­æ‹¥æœ‰è¿™äº›éå¸¸æ¨¡ç³Šçš„åˆ†å¸ƒã€‚æ˜¯å› ä¸ºè¿™äº›ç¥ç»å…ƒéƒ½ä¸“æ³¨äºå›¾åƒçš„ä¸€å°éƒ¨åˆ†ï¼Œå®ƒä»¬éƒ½åœ¨è¯•å›¾è¡¨ç¤ºè¯¥å›¾åƒåŒºåŸŸå†…å‘ç”Ÿçš„äº‹æƒ…ï¼Œæ‰€ä»¥ä½ åªæ˜¯åœ¨è¯•å›¾è¡¨ç¤ºä¸€ä»¶äº‹æƒ…ã€‚ä½ å¹¶ä¸æ˜¯åœ¨è¯•å›¾è¡¨ç¤ºä¸€äº›å¯èƒ½å¯¹è±¡çš„é›†åˆï¼Œå¦‚æœä½ è¯•å›¾è¡¨ç¤ºä¸€äº›å¯èƒ½å¯¹è±¡çš„é›†åˆï¼Œä½ ä¼šé¢ä¸´å¯æ€•çš„ç»‘å®šé—®é¢˜ï¼Œè€Œæ— æ³•ä½¿ç”¨è¿™äº›éå¸¸æ¨¡ç³Šçš„åˆ†å¸ƒï¼Œä½†åªè¦ä½ çŸ¥é“æ‰€æœ‰è¿™äº›ç¥ç»å…ƒã€‚
- en: all of the active neurons refer to the same thing then you can do the intersectionã€‚you
    can add the low probability distribution together and intersect the sets of things
    they representã€‚Okayï¼Œ I'm getting near the endï¼Œ how would you train a system like
    thisï¼ŸWellï¼Œ obviouslyã€‚you could train it the way you train but you could do deep
    end to end trainingã€‚And for Gmã€‚
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰æ´»åŠ¨çš„ç¥ç»å…ƒéƒ½æŒ‡å‘åŒä¸€äº‹ç‰©æ—¶ï¼Œä½ å°±å¯ä»¥è¿›è¡Œäº¤é›†ã€‚ä½ å¯ä»¥å°†ä½æ¦‚ç‡åˆ†å¸ƒç›¸åŠ ï¼Œå¹¶äº¤é›†å®ƒä»¬æ‰€ä»£è¡¨çš„äº‹ç‰©çš„é›†åˆã€‚å¥½çš„ï¼Œæˆ‘å¿«åˆ°æœ€åäº†ï¼Œå¦‚ä½•è®­ç»ƒè¿™æ ·çš„ç³»ç»Ÿå‘¢ï¼Ÿæ˜¾ç„¶ã€‚ä½ å¯ä»¥ç”¨ä½ è®­ç»ƒçš„æ–¹å¼æ¥è®­ç»ƒï¼Œä½†ä½ å¯ä»¥è¿›è¡Œæ·±åº¦çš„ç«¯åˆ°ç«¯è®­ç»ƒã€‚å¯¹äºGmã€‚
- en: what that will consist of and the way we trained a toy exampleã€‚Is youã€‚Take an
    imageã€‚You leave out some patches of the imageã€‚You then let Gom settle down for
    about 10 iterationsã€‚And is trying to fill inã€‚The lowest level representation of
    the bo in the imageã€‚The lowest level embeddingã€‚And it fills them in role and so
    you know back propagate that error and you're back propagating it through time
    in this networkã€‚
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åŒ…æ‹¬æˆ‘ä»¬å¦‚ä½•è®­ç»ƒä¸€ä¸ªç©å…·ç¤ºä¾‹çš„æ–¹å¼ã€‚ä½ ã€‚æ‹¿ä¸€å¼ å›¾åƒã€‚ä½ ç•™ä¸‹ä¸€äº›å›¾åƒçš„è¡¥ä¸ã€‚ç„¶åè®©Gomæ²‰æ·€å¤§çº¦10æ¬¡è¿­ä»£ã€‚å¹¶è¯•å›¾å¡«å……å›¾åƒä¸­æœ€ä½å±‚æ¬¡çš„è¡¨ç¤ºã€‚æœ€ä½å±‚çš„åµŒå…¥ã€‚å®ƒå¡«å……äº†è¿™äº›è§’è‰²ï¼Œå› æ­¤ä½ çŸ¥é“åå‘ä¼ æ’­é‚£ä¸ªè¯¯å·®ï¼Œå¹¶ä¸”ä½ æ­£åœ¨é€šè¿‡è¿™ä¸ªç½‘ç»œåœ¨æ—¶é—´ä¸Šè¿›è¡Œåå‘ä¼ æ’­ã€‚
- en: so it will also back propagate up and down through the levelsã€‚ç¯ã€‚So you're basically
    just doing back proation through time of the errorã€‚Due to filling in things incorrectlyï¼Œ
    that's basically how B is trained and you could train G the same wayã€‚But I also
    want to include an extra bit in the trainingã€‚To encourage islandsã€‚å—¯ã€‚
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥å®ƒä¹Ÿä¼šåœ¨å±‚çº§ä¹‹é—´å‘ä¸Šå’Œå‘ä¸‹åå‘ä¼ æ’­ã€‚ç¯ã€‚å› æ­¤ï¼ŒåŸºæœ¬ä¸Šä½ åªæ˜¯åœ¨è¿›è¡Œæ—¶é—´ä¸Šçš„è¯¯å·®åå‘ä¼ æ’­ã€‚ç”±äºé”™è¯¯åœ°å¡«å……å†…å®¹ï¼Œè¿™åŸºæœ¬ä¸Šå°±æ˜¯Bæ˜¯å¦‚ä½•è®­ç»ƒçš„ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨åŒæ ·çš„æ–¹æ³•è®­ç»ƒGã€‚ä½†æˆ‘è¿˜æƒ³åœ¨è®­ç»ƒä¸­åŠ å…¥ä¸€ä¸ªé¢å¤–çš„éƒ¨åˆ†ï¼Œä»¥é¼“åŠ±å½¢æˆå²›å±¿ã€‚å—¯ã€‚
- en: We want to encourage big islands of identical vectors at high levelsã€‚And you
    can do that by using conrusive learningã€‚Soã€‚If you think how the nextã€‚At the next
    time stepã€‚you think how an embedding is determinedã€‚Is determined by combiningã€‚A
    whole bunch of different factorsï¼Œ what was going on in the previous time stepã€‚
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›åœ¨é«˜å±‚æ¬¡ä¸Šé¼“åŠ±å¤§è§„æ¨¡ç›¸åŒå‘é‡çš„å²›å±¿ã€‚ä½ å¯ä»¥é€šè¿‡ä½¿ç”¨å¯¹æŠ—å­¦ä¹ æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æ‰€ä»¥ï¼Œå¦‚æœä½ è€ƒè™‘ä¸‹ä¸€æ­¥ã€‚ä½ è€ƒè™‘ä¸€ä¸ªåµŒå…¥æ˜¯å¦‚ä½•ç¡®å®šçš„ã€‚æ˜¯é€šè¿‡ç»“åˆè®¸å¤šä¸åŒå› ç´ æ¥ç¡®å®šçš„ï¼Œè¿™äº›å› ç´ æ¥è‡ªäºå‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤çš„æƒ…å†µã€‚
- en: At this level of representation in this locationã€‚What was going on at the previous
    time step in this locationã€‚but to the next level downï¼ŸOf the next little aã€‚And
    also what was going on at the previous time step at nearby locationsã€‚At the same
    levelã€‚And the weighted average of all those things I'll call the consensus embeddingã€‚and
    that's what you use for the next embeddingã€‚And I think you can see that if we
    try and make the bottom up neural net on the top down neural netã€‚
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä½ç½®çš„è¡¨ç¤ºå±‚çº§ä¸­ã€‚å‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤åœ¨æ­¤ä½ç½®å‘ç”Ÿäº†ä»€ä¹ˆã€‚ä½†è¦åˆ°ä¸‹ä¸€ä¸ªå±‚æ¬¡ï¼Ÿä¸‹ä¸€ä¸ªå°açš„å±‚æ¬¡ã€‚è¿˜æœ‰å‰ä¸€ä¸ªæ—¶é—´æ­¥éª¤åœ¨é™„è¿‘ä½ç½®çš„æƒ…å†µã€‚åœ¨åŒä¸€å±‚æ¬¡ä¸Šã€‚æ‰€æœ‰è¿™äº›äº‹ç‰©çš„åŠ æƒå¹³å‡æˆ‘ç§°ä¹‹ä¸ºå…±è¯†åµŒå…¥ã€‚è¿™å°±æ˜¯ä½ ç”¨äºä¸‹ä¸€ä¸ªåµŒå…¥çš„å†…å®¹ã€‚å¦‚æœæˆ‘ä»¬å°è¯•è®©è‡ªä¸‹è€Œä¸Šçš„ç¥ç»ç½‘ç»œä¸è‡ªä¸Šè€Œä¸‹çš„ç¥ç»ç½‘ç»œä¸€è‡´ã€‚
- en: if we try and make the predictions agree with the consensusã€‚The consensus has
    folded in information from nearby locationsã€‚That already roughly agree because
    of the attention waitingã€‚And so by trying to make the top down and bottom up neural
    networksï¼Œ agree with the consensusã€‚
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°è¯•è®©é¢„æµ‹ä¸å…±è¯†ä¸€è‡´ã€‚å…±è¯†å·²ç»æŠ˜å äº†æ¥è‡ªé™„è¿‘ä½ç½®çš„ä¿¡æ¯ã€‚ç”±äºæ³¨æ„åŠ›æœºåˆ¶çš„æƒé‡ï¼Œè¿™äº›ä¿¡æ¯å¤§è‡´ä¸Šå·²ç»ä¸€è‡´ã€‚å› æ­¤ï¼Œé€šè¿‡è®©è‡ªä¸Šè€Œä¸‹å’Œè‡ªä¸‹è€Œä¸Šçš„ç¥ç»ç½‘ç»œä¸å…±è¯†ä¸€è‡´ã€‚
- en: You're trying to make them agree with what's going on nearby locations that
    are similarã€‚And say you'll betraying it to four islandsã€‚This is more interesting
    to neuroscientists than to people who do natural languageã€‚so I'm going to ignore
    thatã€‚å—¯ã€‚You might think it's wasteful to be replicatingã€‚All these embeddings at
    the object levelï¼Œ so the idea is at the object level there'll be a large number
    of patches that all have exactly the same vector representationã€‚
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ è¯•å›¾è®©å®ƒä»¬ä¸ç›¸ä¼¼çš„é™„è¿‘ä½ç½®çš„æƒ…å†µä¸€è‡´ã€‚å‡è®¾ä½ è¦å°†å…¶è®­ç»ƒæˆå››ä¸ªå²›å±¿ã€‚è¿™å¯¹ç¥ç»ç§‘å­¦å®¶æ¥è¯´æ¯”å¯¹è‡ªç„¶è¯­è¨€å¤„ç†è€…æ›´æœ‰è¶£ï¼Œæ‰€ä»¥æˆ‘å°†å¿½ç•¥è¿™ä¸€ç‚¹ã€‚å—¯ã€‚ä½ å¯èƒ½ä¼šè§‰å¾—åœ¨å¯¹è±¡çº§åˆ«å¤åˆ¶æ‰€æœ‰è¿™äº›åµŒå…¥æ˜¯æµªè´¹çš„ï¼Œå› æ­¤åœ¨å¯¹è±¡çº§åˆ«ä¼šæœ‰å¤§é‡çš„è¡¥ä¸ï¼Œå®ƒä»¬éƒ½æœ‰å®Œå…¨ç›¸åŒçš„å‘é‡è¡¨ç¤ºã€‚
- en: And that seems like a wasteï¼Œ but actually biology is full of things like thatã€‚all
    your cells have exactly the same DNA and all the parts of an organ have pretty
    much the same vector of protein expressions so there's lots of replication goes
    on in to keep things localã€‚
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼¼ä¹æ˜¯ä¸€ç§æµªè´¹ï¼Œä½†å®é™…ä¸Šç”Ÿç‰©å­¦ä¸­å……æ»¡äº†è¿™æ ·çš„ç°è±¡ã€‚ä½ æ‰€æœ‰çš„ç»†èƒéƒ½æœ‰å®Œå…¨ç›¸åŒçš„DNAï¼Œå™¨å®˜çš„æ‰€æœ‰éƒ¨åˆ†å‡ ä¹éƒ½æœ‰ç›¸åŒçš„è›‹ç™½è´¨è¡¨è¾¾å‘é‡ï¼Œæ‰€ä»¥æœ‰å¾ˆå¤šå¤åˆ¶å‘ç”Ÿä»¥ä¿æŒäº‹ç‰©çš„å±€éƒ¨æ€§ã€‚
- en: ğŸ˜Šï¼ŒAnd it's the same here and actually that replication is very useful when you're
    settling on an interpretation because before you settle down you don't know which
    things should be the same as which other thingsã€‚so having separate vectors in
    each location to represent what's going on there at the object level gives you
    the flexibility to gradually segment things as you settle down in a sensible wayã€‚
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œè¿™é‡Œä¹Ÿæ˜¯å¦‚æ­¤ï¼Œå®é™…ä¸Šè¿™ç§å¤åˆ¶åœ¨ä½ ç¡®å®šä¸€ä¸ªè§£é‡Šæ—¶éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºåœ¨ä½ ç¡®å®šä¹‹å‰ï¼Œä½ ä¸çŸ¥é“å“ªäº›ä¸œè¥¿åº”è¯¥ä¸å…¶ä»–ä¸œè¥¿ç›¸åŒã€‚å› æ­¤ï¼Œåœ¨æ¯ä¸ªä½ç½®æ‹¥æœ‰ç‹¬ç«‹å‘é‡ä»¥è¡¨ç¤ºç‰©ä½“å±‚æ¬¡ä¸Šå‘ç”Ÿçš„äº‹æƒ…ï¼Œå¯ä»¥è®©ä½ åœ¨ä»¥åˆç†çš„æ–¹å¼é€æ¸åˆ†æ®µæ—¶ä¿æŒçµæ´»æ€§ã€‚
- en: ğŸ˜Šï¼ŒIt allows you to hedge your bets and what you're doing is not quite like clustering
    you're creating clusters of identical vectors rather than discovering clusters
    in fixed dataã€‚so clustering you're given the data and it's fixed and you find
    the clusters here the embeddings at every level they vary over time they're determined
    by the top down and bottom up inputs and by inputs coming from nearby locations
    so what you're doing is forming clusters rather than discovering them in fixed
    dataã€‚
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œè¿™è®©ä½ èƒ½å¤Ÿå¯¹é£é™©è¿›è¡Œå¯¹å†²ï¼Œè€Œä½ æ‰€åšçš„å¹¶ä¸åƒèšç±»ï¼Œä½ æ˜¯åœ¨åˆ›å»ºç›¸åŒå‘é‡çš„ç°‡ï¼Œè€Œä¸æ˜¯åœ¨å›ºå®šæ•°æ®ä¸­å‘ç°ç°‡ã€‚æ‰€ä»¥åœ¨èšç±»ä¸­ï¼Œä½ æ˜¯ç»™å®šæ•°æ®ä¸”æ•°æ®æ˜¯å›ºå®šçš„ï¼Œä½ ä¼šæ‰¾åˆ°è¿™äº›ç°‡ï¼Œè€Œè¿™é‡Œçš„åµŒå…¥åœ¨æ¯ä¸ªå±‚æ¬¡ä¸Šéšæ—¶é—´å˜åŒ–ï¼Œå®ƒä»¬ç”±è‡ªä¸Šè€Œä¸‹å’Œè‡ªä¸‹è€Œä¸Šçš„è¾“å…¥ä»¥åŠæ¥è‡ªé™„è¿‘ä½ç½®çš„è¾“å…¥å†³å®šï¼Œå› æ­¤ä½ æ‰€åšçš„æ˜¯å½¢æˆç°‡ï¼Œè€Œä¸æ˜¯åœ¨å›ºå®šæ•°æ®ä¸­å‘ç°å®ƒä»¬ã€‚
- en: And that's got a somewhat different flavor and can't settle down fasterã€‚And
    one other advantage this replication isã€‚What you don't want is to have much more
    work in your transformer as you go to higher levelsã€‚But you do need longer range
    interactions at higher levelsã€‚presumably for the lowest levels you want fairly
    short range interactions in your transformer and they could be dense as you go
    to high levels you want much longer range interactions so you could make them
    sparseã€‚
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œè¿™æœ‰ç€ç•¥å¾®ä¸åŒçš„ç‰¹æ€§ï¼Œä¸èƒ½æ›´å¿«åœ°ç¨³å®šä¸‹æ¥ã€‚è¿˜æœ‰ä¸€ä¸ªå¥½å¤„æ˜¯è¿™ç§å¤åˆ¶ã€‚ä½ ä¸å¸Œæœ›åœ¨æ›´é«˜å±‚æ¬¡çš„å˜æ¢å™¨ä¸­æœ‰æ›´å¤šçš„å·¥ä½œã€‚ä½†åœ¨æ›´é«˜å±‚æ¬¡ä¸Šï¼Œä½ ç¡®å®éœ€è¦æ›´é•¿èŒƒå›´çš„äº¤äº’ã€‚æ˜¾ç„¶ï¼Œå¯¹äºæœ€ä½å±‚æ¬¡ï¼Œä½ å¸Œæœ›åœ¨å˜æ¢å™¨ä¸­æœ‰ç›¸å¯¹çŸ­çš„äº¤äº’ï¼Œå¹¶ä¸”åœ¨å‘é«˜å±‚æ¬¡ç§»åŠ¨æ—¶ï¼Œå®ƒä»¬å¯ä»¥æ˜¯å¯†é›†çš„ï¼Œè€Œåœ¨é«˜å±‚æ¬¡æ—¶ä½ å¸Œæœ›æœ‰æ›´é•¿èŒƒå›´çš„äº¤äº’ï¼Œå› æ­¤ä½ å¯ä»¥ä½¿å®ƒä»¬å˜å¾—ç¨€ç–ã€‚
- en: And people have done things like that forã€‚But like systemsã€‚Here it's easy to
    make them sparse because you're expecting big islands so all you need to do is
    see one patch of a big island to know what the vector representation of that island
    is and so sparse representations will work much better if you have these big islands
    of agreement as you go up so the idea is you have longer range and sparse connections
    as you go up so the amount of computation is the same at every levelã€‚
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: äººä»¬å·²ç»åšè¿‡ç±»ä¼¼çš„äº‹æƒ…ã€‚å¯¹äºåƒè¿™æ ·çš„ç³»ç»Ÿï¼Œåœ¨è¿™é‡Œå¾ˆå®¹æ˜“ä½¿å®ƒä»¬ç¨€ç–ï¼Œå› ä¸ºä½ æœŸå¾…æœ‰å¤§å²›å±¿ï¼Œå› æ­¤ä½ æ‰€éœ€è¦åšçš„å°±æ˜¯çœ‹åˆ°ä¸€ä¸ªå¤§å²›å±¿çš„ä¸€éƒ¨åˆ†ï¼Œå°±çŸ¥é“è¯¥å²›å±¿çš„å‘é‡è¡¨ç¤ºæ˜¯ä»€ä¹ˆï¼Œå› æ­¤å¦‚æœä½ æœ‰è¿™äº›å¤§çš„å…±è¯†å²›å±¿ï¼Œç¨€ç–è¡¨ç¤ºä¼šæ›´æœ‰æ•ˆï¼Œæ‰€ä»¥è¿™ä¸ªæƒ³æ³•æ˜¯ä½ åœ¨å‘ä¸Šç§»åŠ¨æ—¶æœ‰æ›´é•¿èŒƒå›´å’Œç¨€ç–çš„è¿æ¥ï¼Œå› æ­¤æ¯ä¸€å±‚çš„è®¡ç®—é‡æ˜¯ç›¸åŒçš„ã€‚
- en: And just to summarizeã€‚å—¯ã€‚I showed how to combine three important advances of
    neural networks in Gm I didn't actually talk about neural fields and that's important
    for the top down network maybe since I've got two minutes to spare i'm going to
    go back and mention neural fields very brieflyã€‚
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹ã€‚å—¯ã€‚æˆ‘å±•ç¤ºäº†å¦‚ä½•ç»“åˆç¥ç»ç½‘ç»œä¸­çš„ä¸‰ä¸ªé‡è¦è¿›å±•ï¼Œä½†æˆ‘å®é™…ä¸Šæ²¡æœ‰è°ˆåˆ°ç¥ç»åœºï¼Œè¿™å¯¹è‡ªä¸Šè€Œä¸‹çš„ç½‘ç»œå¾ˆé‡è¦ï¼Œä¹Ÿè®¸å› ä¸ºæˆ‘è¿˜æœ‰ä¸¤åˆ†é’Ÿçš„æ—¶é—´ï¼Œæˆ‘å°†ç®€è¦æåŠç¥ç»åœºã€‚
- en: Yeahï¼Œ when I train that top down neural networkã€‚I have a problemã€‚And the problem
    isã€‚ğŸ˜°ã€‚If you look at those red arrows and those green arrowsã€‚They're quite differentã€‚ğŸ˜¡ã€‚But
    if you look at the level above the object levelã€‚All those vectors are the sameã€‚Andï¼Œ
    of courseã€‚In an engineered systemï¼Œ I want to replicate the neural nets in every
    locationã€‚
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œå½“æˆ‘è®­ç»ƒé‚£ä¸ªè‡ªä¸Šè€Œä¸‹çš„ç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ã€‚è¿™ä¸ªé—®é¢˜æ˜¯ã€‚ğŸ˜°ã€‚å¦‚æœä½ çœ‹é‚£äº›çº¢è‰²ç®­å¤´å’Œç»¿è‰²ç®­å¤´ï¼Œå®ƒä»¬æ˜¯ç›¸å½“ä¸åŒçš„ã€‚ğŸ˜¡ã€‚ä½†æ˜¯å¦‚æœä½ çœ‹ç‰©ä½“å±‚æ¬¡ä¹‹ä¸Šçš„å±‚æ¬¡ï¼Œæ‰€æœ‰é‚£äº›å‘é‡éƒ½æ˜¯ç›¸åŒçš„ã€‚å½“ç„¶ï¼Œåœ¨ä¸€ä¸ªå·¥ç¨‹ç³»ç»Ÿä¸­ï¼Œæˆ‘æƒ³åœ¨æ¯ä¸ªä½ç½®å¤åˆ¶ç¥ç»ç½‘ç»œã€‚
- en: so he's exactly the same top down and bottom up neural nets everywhereã€‚And so
    the question isã€‚how can the same neural net be given a black arrowï¼Ÿ
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ä»–åœ¨æ¯ä¸ªåœ°æ–¹éƒ½æ˜¯å®Œå…¨ç›¸åŒçš„è‡ªä¸Šè€Œä¸‹å’Œè‡ªä¸‹è€Œä¸Šçš„ç¥ç»ç½‘ç»œã€‚å› æ­¤é—®é¢˜æ˜¯ï¼Œå¦‚ä½•ç»™åŒä¸€ä¸ªç¥ç»ç½‘ç»œä¸€ä¸ªé»‘è‰²ç®­å¤´ï¼Ÿ
- en: And sometimes produce a red arrow and sometimes produce a green arrowã€‚which
    have quite different orientationsã€‚How can it produce a nose where there's nose
    and a mouth where there's magsã€‚even though the face vector is the same everywhereï¼Ÿ
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶äº§ç”Ÿçº¢è‰²ç®­å¤´ï¼Œæœ‰æ—¶äº§ç”Ÿç»¿è‰²ç®­å¤´ï¼Œå®ƒä»¬æœ‰ç€æˆªç„¶ä¸åŒçš„æ–¹å‘ã€‚å®ƒå¦‚ä½•åœ¨æ²¡æœ‰é¼»å­çš„åœ°æ–¹äº§ç”Ÿé¼»å­ï¼Œåœ¨æœ‰å˜´å·´çš„åœ°æ–¹äº§ç”Ÿå˜´å·´ï¼Ÿå³ä½¿é¢éƒ¨å‘é‡åœ¨ä»»ä½•åœ°æ–¹éƒ½æ˜¯ç›¸åŒçš„ï¼Ÿ
- en: And the answer is the top down neural network doesn't just get the face vectorã€‚it
    also gets the location of the patch for which is producing the PA vectorã€‚So the
    three patches that should get the red vector are different from different locations
    from the three patches that should get the green vectorã€‚So if I use a neural network
    and the guess the location is input as wellï¼Œ here's what it can doã€‚
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆæ˜¯ï¼Œè‡ªä¸Šè€Œä¸‹çš„ç¥ç»ç½‘ç»œä¸ä»…è·å¾—é¢éƒ¨å‘é‡ã€‚å®ƒè¿˜è·å¾—ç”ŸæˆPAå‘é‡çš„è¡¥ä¸ä½ç½®ã€‚å› æ­¤ï¼Œåº”è¯¥è·å¾—çº¢è‰²å‘é‡çš„ä¸‰ä¸ªè¡¥ä¸ä¸åº”è¯¥è·å¾—ç»¿è‰²å‘é‡çš„ä¸‰ä¸ªè¡¥ä¸çš„ä½ç½®æ˜¯ä¸åŒçš„ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œå¹¶å°†ä½ç½®ä½œä¸ºè¾“å…¥ï¼Œè¿™å°±æ˜¯å®ƒå¯ä»¥åšåˆ°çš„ã€‚
- en: it can take the pose that's encoded in that black vectorï¼Œ the pose of the faceã€‚It
    can take the locationã€‚In the image for which is predicting the vector of the level
    belowã€‚And the pose is relative to the image tooï¼Œ so knowing the location in the
    image and knowing the pose of the whole face it can figure out which bit of the
    face it needs to predict at that location and so in one location it can predict
    okay there should be nose there and it gives you the red vector in another location
    it can predict from where that image patch is there should be mouth there so it
    can give you the green arrowã€‚
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå¯ä»¥æå–é»‘è‰²å‘é‡ä¸­ç¼–ç çš„å§¿åŠ¿ï¼Œå³é¢éƒ¨çš„å§¿åŠ¿ã€‚å®ƒå¯ä»¥è·å–ä½ç½®ã€‚åœ¨å®ƒé¢„æµ‹ä¸‹å±‚å‘é‡çš„å›¾åƒä¸­ã€‚å¹¶ä¸”å§¿åŠ¿ä¸å›¾åƒä¹Ÿæ˜¯ç›¸å…³çš„ï¼Œå› æ­¤äº†è§£å›¾åƒä¸­çš„ä½ç½®ä»¥åŠæ•´ä¸ªé¢éƒ¨çš„å§¿åŠ¿ï¼Œå®ƒå¯ä»¥ç¡®å®šåœ¨è¯¥ä½ç½®éœ€è¦é¢„æµ‹é¢éƒ¨çš„å“ªä¸ªéƒ¨åˆ†ï¼Œå› æ­¤åœ¨ä¸€ä¸ªä½ç½®å®ƒå¯ä»¥é¢„æµ‹â€œå¥½å§ï¼Œé‚£é‡Œåº”è¯¥æœ‰é¼»å­â€ï¼Œå¹¶ç»™ä½ çº¢è‰²å‘é‡ï¼›åœ¨å¦ä¸€ä¸ªä½ç½®å®ƒå¯ä»¥é¢„æµ‹â€œé‚£é‡Œçš„å›¾åƒè¡¥ä¸åº”è¯¥æœ‰å˜´å·´â€ï¼Œå› æ­¤å®ƒå¯ä»¥ç»™ä½ ç»¿è‰²ç®­å¤´ã€‚
- en: ğŸ˜Šï¼ŒSo you can get the same vector at the level above to predict different vectors
    in different places at the level below by giving it the place that it's predicting
    for and that's what's going on in neural fieldsã€‚ğŸ˜Šï¼ŒOkay now this was quite a complicated
    talk there's a long paper about it on archive that goes into much more detailã€‚
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ˜Šï¼Œæ‰€ä»¥ä½ å¯ä»¥åœ¨ä¸Šå±‚è·å¾—ç›¸åŒçš„å‘é‡ï¼Œé€šè¿‡æä¾›å®ƒæ‰€é¢„æµ‹çš„ä½ç½®ï¼Œæ¥é¢„æµ‹ä¸‹å±‚ä¸åŒä½ç½®çš„ä¸åŒå‘é‡ï¼Œè¿™å°±æ˜¯ç¥ç»åœºä¸­çš„è¿ä½œæ–¹å¼ã€‚ğŸ˜Šï¼Œå¥½å§ï¼Œè¿™ä¸ªè®¨è®ºç›¸å½“å¤æ‚ï¼Œå…³äºè¿™ä¸ªä¸»é¢˜æœ‰ä¸€ç¯‡æ›´è¯¦ç»†çš„é•¿æ–‡åœ¨archiveä¸Šã€‚
- en: And you could view this talk as just an encouragement to read that paper when
    I'm doneã€‚Exactly on timeã€‚thank youã€‚a lotã€‚![](img/a6e82a7e40b8f10bedf5eedaad6d0492_4.png)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å°†è¿™ä¸ªè®¨è®ºè§†ä¸ºåœ¨æˆ‘å®Œæˆåé¼“åŠ±ä½ é˜…è¯»é‚£ç¯‡è®ºæ–‡ã€‚æ­£å¥½å‡†æ—¶ã€‚è°¢è°¢ã€‚å¾ˆå¤šã€‚![](img/a6e82a7e40b8f10bedf5eedaad6d0492_4.png)
