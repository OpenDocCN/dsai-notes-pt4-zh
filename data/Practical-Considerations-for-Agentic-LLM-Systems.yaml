- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2025-01-11 11:50:44'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2025-01-11 11:50:44
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Practical Considerations for Agentic LLM Systems
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**代理型大型语言模型系统的实践考量**'
- en: 来源：[https://arxiv.org/html/2412.04093/](https://arxiv.org/html/2412.04093/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/html/2412.04093/](https://arxiv.org/html/2412.04093/)
- en: Chris Sypherd University of EdinburghEdinburghUnited Kingdom [c.n.sypherd@sms.ed.ac.uk](mailto:c.n.sypherd@sms.ed.ac.uk)
     and  Vaishak Belle University of EdinburghEdinburghUnited Kingdom [vbelle@ed.ac.uk](mailto:vbelle@ed.ac.uk)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Chris Sypherd 爱丁堡大学 爱丁堡 英国 [c.n.sypherd@sms.ed.ac.uk](mailto:c.n.sypherd@sms.ed.ac.uk)  和
    Vaishak Belle 爱丁堡大学 爱丁堡 英国 [vbelle@ed.ac.uk](mailto:vbelle@ed.ac.uk)
- en: Abstract.
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: As the strength of Large Language Models (LLMs) has grown over recent years,
    so too has interest in their use as the underlying models for autonomous agents.
    Although LLMs demonstrate emergent abilities and broad expertise across natural
    language domains, their inherent unpredictability makes the implementation of
    LLM agents challenging, resulting in a gap between related research and the real-world
    implementation of such systems. To bridge this gap, this paper frames actionable
    insights and considerations from the research community in the context of established
    application paradigms to enable the construction and facilitate the informed deployment
    of robust LLM agents. Namely, we position relevant research findings into four
    broad categories—Planning, Memory, Tools, and Control Flow—based on common practices
    in application-focused literature and highlight practical considerations to make
    when designing agentic LLMs for real-world applications, such as handling stochasticity
    and managing resources efficiently. While we do not conduct empirical evaluations,
    we do provide the necessary background for discussing critical aspects of agentic
    LLM designs, both in academia and industry.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLM）在近年来的强大，越来越多的人开始关注将其作为自主智能体的基础模型进行使用。尽管LLM在自然语言领域展示了新兴能力和广泛的专业知识，但其固有的不可预测性使得LLM智能体的实现变得具有挑战性，导致相关研究与这些系统在现实世界中应用之间存在差距。为了弥合这一差距，本文在已建立的应用范式的背景下，提供了来自研究社区的可操作性洞见和考量，旨在促进鲁棒LLM智能体的构建并帮助在实际部署时做出明智决策。具体而言，我们将相关研究成果归纳为四大类——规划、记忆、工具和控制流程——这些类别基于应用导向文献中的常见做法，并强调在为现实应用设计代理型LLM时需要考虑的实际问题，例如如何处理随机性和高效地管理资源。虽然我们未进行实证评估，但我们提供了讨论代理型LLM设计中关键方面所需的背景，无论是在学术界还是工业界。
- en: Large Language Models (LLMs), LLM Agents, Agentic LLMs, Applied LLM Systems
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs），LLM智能体，代理型LLM，应用LLM系统
- en: 1\. Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: In academia, the concept of ”agents” has been well-defined for decades (e.g., (Wooldridge
    and Jennings, [1995](https://arxiv.org/html/2412.04093v1#bib.bib95))), and thus
    the proposition of agents based on LLMs comes with predefined criteria and expectations.
    As such, agentic LLMs in the research community have come to be defined as autonomous
    systems with capabilities of beliefs (Sclar et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib72);
    Li et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib48); Park et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib63)), reasoning (Zhang et al.,
    [2024c](https://arxiv.org/html/2412.04093v1#bib.bib106)), planning (Huang et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib37); Shen et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib73)),
    and control (Shen et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib73)).
    Under this definition, the ability to plan, reason, and interact with an environment
    have emerged as the key considerations for success (Xi et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib98)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术界，“智能体”这一概念已经得到了数十年的明确定义（例如，（Wooldridge和Jennings，[1995](https://arxiv.org/html/2412.04093v1#bib.bib95)）），因此基于LLM的智能体提出了预定义的标准和期望。因此，在研究社区中，代理型LLM被定义为具备信念（Sclar等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib72);
    Li等，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib48); Park等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib63)）、推理（Zhang等，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib106)）、规划（Huang等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib37);
    Shen等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib73)）和控制（Shen等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib73)）能力的自主系统。在这一定义下，规划、推理和与环境的互动已成为成功的关键考量因素（Xi等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib98)）。
- en: For LLM agents in industry and real-world deployment, the history and breadth
    of agents has been condensed to a definition along the lines of ”a system that
    can use an LLM to reason through a problem, create a plan to solve the problem,
    and execute the plan with the help of a set of tools” (Varshney, [2023](https://arxiv.org/html/2412.04093v1#bib.bib85)).
    Most industry discussions follow this form, introducing the LLM as the central
    reasoning engine and adding planning, memory, and tools as three necessary modules
    (e.g.,  (SAA, [2024](https://arxiv.org/html/2412.04093v1#bib.bib14); PGA, [2024](https://arxiv.org/html/2412.04093v1#bib.bib13);
    TFA, [2024](https://arxiv.org/html/2412.04093v1#bib.bib17); Varshney, [2023](https://arxiv.org/html/2412.04093v1#bib.bib85);
    Weng, [2023](https://arxiv.org/html/2412.04093v1#bib.bib94))). Indeed, most industry
    resources focusing on deployable agentic LLM systems are accompanied by a diagram
    similar to Figure [1](https://arxiv.org/html/2412.04093v1#S1.F1 "Figure 1 ‣ 1\.
    Introduction ‣ Practical Considerations for Agentic LLM Systems"), focusing largely
    on single agents. While this description is helpful for the most basic of LLM
    agents, it glosses over some of the more nuanced considerations that must be made
    for the informed construction of robust agentic LLM systems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于工业界和实际部署中的LLM代理，代理的历史和范围已经被简化为类似于“一个可以使用LLM推理问题、创建解决问题的计划，并借助一套工具执行该计划的系统”的定义（Varshney，[2023](https://arxiv.org/html/2412.04093v1#bib.bib85)）。大多数行业讨论遵循这种形式，将LLM作为中央推理引擎，并添加规划、记忆和工具作为三个必要的模块（例如，（SAA，[2024](https://arxiv.org/html/2412.04093v1#bib.bib14)；PGA，[2024](https://arxiv.org/html/2412.04093v1#bib.bib13)；TFA，[2024](https://arxiv.org/html/2412.04093v1#bib.bib17)；Varshney，[2023](https://arxiv.org/html/2412.04093v1#bib.bib85)；Weng，[2023](https://arxiv.org/html/2412.04093v1#bib.bib94)））。事实上，大多数关注可部署代理LLM系统的行业资源都会附带一幅类似于图[1](https://arxiv.org/html/2412.04093v1#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Practical Considerations for Agentic LLM Systems")的图，主要集中在单个代理上。虽然这种描述对于最基础的LLM代理是有帮助的，但它忽略了一些更微妙的考虑，若要构建稳健的代理LLM系统，这些考虑必须被充分理解。
- en: The prevailing view of LLM agents in industry brings to light the disparity
    between (1) research into LLMs and agents and (2) the application of agentic LLM
    systems in real-world scenarios. To bridge this gap, we propose framing relevant
    findings from the research community in the common industry view of LLM agents.
    To that end, we organize this work into four main sections—Planning, Memory, Tools,
    and Control Flow—that correspond to, respectively, planning, memory, tools, and
    the central reasoning engine components referenced above. We tailor the contents
    of this paper to black-box LLM-based single-agent systems typical of that industry
    perspective. By doing so, we hope to create an actionable and approachable survey
    that enables information exchange between academia and industry within a manageable
    scope.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当前工业界对LLM代理的主流观点揭示了（1）LLM和代理的研究与（2）LLM代理系统在实际场景中的应用之间的差距。为了弥合这一差距，我们建议将研究界的相关发现与工业界对LLM代理的普遍看法结合起来。为此，我们将本文组织成四个主要部分——规划、记忆、工具和控制流——它们分别对应上述提到的规划、记忆、工具和中央推理引擎组件。我们将本文内容专门针对典型的基于LLM的黑箱单代理系统，符合工业界的视角。通过这样做，我们希望创建一篇可操作且易于接近的调查报告，促进学术界与工业界之间在可控范围内的信息交流。
- en: '![Refer to caption](img/b0f3b1ce80da8d0efd5a06359f475274.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明文字](img/b0f3b1ce80da8d0efd5a06359f475274.png)'
- en: Figure 1\. A typical application-focused depiction of LLM agents.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 一种典型的面向应用的LLM代理描绘。
- en: \Description
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: A diagram showing five boxes containing the texts ”User Input,” ”Agent,” ”Planning,”
    ”Tools,” and ”Memory. The ”Agent” box sits between ”User Input” and the other
    three boxes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一幅图展示了五个框，分别包含文本“用户输入”、“代理”、“规划”、“工具”和“记忆”。“代理”框位于“用户输入”和其他三个框之间。
- en: 2\. Related Work
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 相关工作
- en: Many surveys discussing LLM-based agents focus on multi-agent frameworks and
    related ideas (Guo et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib33);
    Zhang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib106)). While
    similar, the challenges facing multi-agent systems are distinct from the real-world
    deployment of a single LLM agent. Here, we focus more on deliberately crafting
    a robust agent rather than the orchestration of many.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 许多讨论基于LLM的代理的调查关注的是多代理框架及相关思想（Guo等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib33)；Zhang等，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib106)）。尽管相似，但多代理系统所面临的挑战与单个LLM代理在实际部署中的情况有所不同。在这里，我们更多地关注如何有意识地打造一个稳健的代理，而不是如何协调多个代理。
- en: Another approach, taken by (Yang et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib101)),
    focuses on methods for improving agentic LLM performance starting at the underlying
    model, looking into data composition and training methodologies. We focus on implementation
    considerations that improve agentic LLM system performance from a black-box perspective,
    which lends itself more to real-world deployment. Others focus on creating unified
    taxonomies  (Li, [2024](https://arxiv.org/html/2412.04093v1#bib.bib50); Xi et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib98)) or target a single component
    of LLM agents, such as planning (Huang et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib37)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法，由 (Yang et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib101))
    提出，聚焦于从底层模型开始改进代理 LLM 性能的方法，探讨数据组成和训练方法。我们则关注提高代理 LLM 系统性能的实施考虑，从黑箱视角出发，这更适用于实际部署。还有一些工作聚焦于创建统一的分类法
     (Li, [2024](https://arxiv.org/html/2412.04093v1#bib.bib50); Xi et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib98))，或专注于
    LLM 代理的单一组件，如规划 (Huang et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib37))。
- en: The most similar work is (Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)),
    providing a comprehensive survey of works relating to LLMs as agents as well as
    reviewing aspects of their design, application, and evaluation. While (Wang et al.,
    [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)) develops a valuable unified
    framework based on extant research, we leverage research findings to provide practical
    application-focused insights and frame our review in the context of the LLM agent
    paradigm that has developed organically in industry.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最相似的工作是 (Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88))，提供了一项全面的综述，涉及
    LLM 作为代理的相关研究，并回顾了它们的设计、应用和评估方面。虽然 (Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88))
    基于现有研究开发了一个有价值的统一框架，但我们利用研究成果提供了以实践应用为中心的洞见，并将我们的综述框定在业界自然发展起来的 LLM 代理范式中。
- en: To the best of our knowledge, this is the first work that coalesces research
    relevant to LLM agents through the lens of common industry practices. We expand
    that contribution by not just presenting existing research but by extrapolating
    actionable insights and best practices from it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，这是第一篇从常见行业实践的视角汇总与 LLM 代理相关研究的工作。我们通过不仅展示现有研究，还从中推导出可行的洞见和最佳实践，扩展了这一贡献。
- en: 3\. Applied Scenario
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 应用场景
- en: To help illustrate some of the following points, we propose the example outlined
    in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied
    Scenario ‣ Practical Considerations for Agentic LLM Systems") of applying an LLM
    agent as a pescetarian¹¹1Someone that does not eat meat, aside from fish and other
    seafood. meal assistant. We will refer to this as the primary example²²2While
    we attempt to select a simple example with some relevance to the real world, it
    is still a contrived example to demonstrate the points outlined in this work and
    may not fully reflect the complexities of the real world. throughout this work
    for consistency, citing specifics from it by the codes assigned in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")
    (e.g., [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").R1 to refer to ”Pescetarian
    recipe book”).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助阐明以下几点，我们提出了图 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "图 2 ‣ 3\. 应用场景
    ‣ 代理 LLM 系统的实践考虑") 中概述的示例，应用 LLM 代理作为鱼食主义¹¹1不吃肉，除了鱼类和其他海鲜的食物。餐助手。我们将在本工作中为一致性起见，称之为主要示例²²2虽然我们尽力选择一个与现实世界有一定关联的简单示例，但它仍然是一个人为的示例，用于展示本文中概述的要点，可能并不完全反映现实世界的复杂性。我们将在整篇工作中引用此示例，并通过图
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "图 2 ‣ 3\. 应用场景 ‣ 代理 LLM 系统的实践考虑")
    中分配的代码（例如，[2](https://arxiv.org/html/2412.04093v1#S3.F2 "图 2 ‣ 3\. 应用场景 ‣ 代理 LLM
    系统的实践考虑")）来引用具体内容，如”鱼食主义食谱书“。
- en: '![Refer to caption](img/7e4db6426895a9ed29f58036407c3825.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7e4db6426895a9ed29f58036407c3825.png)'
- en: Figure 2\. An example scenario featuring a pescetarian meal assistant LLM agent.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 一个包含鱼食主义餐助手 LLM 代理的示例场景。
- en: \Description
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: \描述
- en: A diagram showing the user, task, and environment definition relating to a pescetarian
    meal assistant example.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一张展示与鱼食主义餐助手示例相关的用户、任务和环境定义的图表。
- en: 4\. Glossary
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 术语表
- en: This glossary serves to briefly introduce the following terms that will be used
    across subsequent sections. Later sections will provide additional contextualization
    and examples of their utility but not necessarily explicit definitions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本词汇表旨在简要介绍将在后续章节中使用的以下术语。后续章节将提供更多的上下文和它们的应用示例，但不一定提供明确的定义。
- en: Persona. A persona (also referred to as a ”role” or a ”profile”) is the identity
    assigned to the LLM, often as part of the system prompt. The persona is the lens
    through which the LLM will interpret and respond to prompts. The persona (e.g.,
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe2) can be defined and refined
    by an occupation (e.g., ”professional chef”), level and domain of expertise (e.g.,
    ”specializing in pescetarian dishes”), and personality traits (e.g., ”friendly
    and understanding”) but can be further customized by adding details such as age,
    race, gender, and nationality (Argyle et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib18);
    Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 人物角色。人物角色（也称为“角色”或“个人档案”）是赋予LLM的身份，通常是作为系统提示的一部分。人物角色是LLM解读和回应提示的视角。例如，图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 代理式LLM系统的实际考虑")中展示的人物角色，可以通过职业（例如，“专业厨师”）、专业领域和水平（例如，“擅长素食海鲜菜肴”）、以及个性特征（例如，“友好且理解”）来定义和细化，还可以通过添加如年龄、种族、性别和国籍等细节进行进一步定制（Argyle等,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib18); Wang等, [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)）。
- en: Tool. Tools are the means by which an LLM can interact with its environment
    (beyond basic textual exchange) and access external resources (Qin et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib67)).
    [Retrieval Augmented Generation](https://arxiv.org/html/2412.04093v1#S6.SS1 "In
    6\. Memory ‣ Practical Considerations for Agentic LLM Systems") (RAG) is commonly
    used as a tool (Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2
    ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T1)
    but is limited in its utility as it exclusively retrieves information about the
    environment. The true power of tools is realized when they are used to perform
    actions in the environment, such as the example in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T2
    that would allow the pescetarian meal assistant to not only recommend recipes
    but also order the ingredients to prepare them. Other examples of tools include
    ground-truth verification methods (e.g., code execution and calculator usage)
    and real-time environment querying (e.g., requesting trending recipes) (Wang et al.,
    [2024b](https://arxiv.org/html/2412.04093v1#bib.bib92)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 工具。工具是LLM与其环境进行互动（超越基本文本交换）并访问外部资源的手段（Qin等, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib67)）。[检索增强生成](https://arxiv.org/html/2412.04093v1#S6.SS1
    "在 6\. 内存 ‣ 代理式LLM系统的实际考虑")（RAG）通常作为工具使用（图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 代理式LLM系统的实际考虑")）。但它的效用是有限的，因为它仅能检索关于环境的信息。工具的真正力量体现在它们被用来在环境中执行操作时，比如图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 代理式LLM系统的实际考虑")所示的例子，这将使得素食餐助手不仅可以推荐食谱，还能为准备食谱订购所需的食材。工具的其他例子包括真实验证方法（例如，代码执行和计算器使用）以及实时环境查询（例如，查询流行食谱）（Wang等,
    [2024b](https://arxiv.org/html/2412.04093v1#bib.bib92)）。
- en: Hyperparameters. This section includes a brief overview of hyperparameters we
    will reference but does not explore their technical details³³3See (Gem, [2024b](https://arxiv.org/html/2412.04093v1#bib.bib10);
    Ope, [[n.d.]](https://arxiv.org/html/2412.04093v1#bib.bib2); Ant, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib7))
    for common commercial API support for these hyperparameters..
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数。本节简要概述了我们将提到的超参数，但并不探讨其技术细节³³3详见(Gem, [2024b](https://arxiv.org/html/2412.04093v1#bib.bib10);
    Ope, [[n.d.]](https://arxiv.org/html/2412.04093v1#bib.bib2); Ant, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib7))，这些超参数常见的商业API支持。
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Seed. Some LLM interfaces will have a “seed” parameter that should, provided
    all other parameters remain constant, produce the same output.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 种子。一些LLM接口会有一个“种子”参数，只要其他所有参数保持不变，就应该生成相同的输出。
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Temperature. Temperature corresponds to the degree to which randomness will
    be employed in selecting the output tokens. This usually plays out in higher temperature
    responses being more creative and rambling while lower temperature responses are
    more predictable and straight-to-the-point. Thus, for more consistent results,
    a lower temperature (e.g., 0.0 to 0.5) can be used.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 温度。温度对应于在选择输出令牌时引入随机性的程度。通常，高温度响应会更加创造性和漫无目的，而低温度响应则更可预测并直截了当。因此，为了获得更一致的结果，可以使用较低的温度（例如0.0到0.5）。
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Top-p. Top-p (also known as ”nucleus sampling;” introduced in (Holtzman et al.,
    [2020](https://arxiv.org/html/2412.04093v1#bib.bib35))) corresponds to the probability
    threshold for selecting tokens that can form part of the output, bounded 0.0 to
    1.0\. Lower top-p values restrict the pool of tokens the LLM can choose from,
    resulting in more reproducible outputs.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Top-p。Top-p（也称为“核心采样”；在 (Holtzman 等人，[2020](https://arxiv.org/html/2412.04093v1#bib.bib35))中介绍）对应于选择可以作为输出一部分的令牌的概率阈值，范围为0.0到1.0。较低的top-p值限制了LLM可以选择的令牌池，从而产生更可重复的输出。
- en: 5\. Planning
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 规划
- en: Planning has long been a core component of agent research (Nau et al., [2004](https://arxiv.org/html/2412.04093v1#bib.bib60);
    Wooldridge and Jennings, [1995](https://arxiv.org/html/2412.04093v1#bib.bib95));
    it allows more complex tasks to be handled in smaller, more manageable steps.
    Planning can also enhance the interpretability of an LLM agent, as the steps of
    the plan and the stopping criteria will be defined in a interpretable format.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 规划长期以来一直是代理人研究的核心组成部分 (Nau 等人，[2004](https://arxiv.org/html/2412.04093v1#bib.bib60);
    Wooldridge 和 Jennings，[1995](https://arxiv.org/html/2412.04093v1#bib.bib95))；它通过将更复杂的任务分解为更小、更易管理的步骤来处理问题。规划还可以增强LLM代理人的可解释性，因为计划的步骤和停止标准将以可解释的格式进行定义。
- en: 5.1\. LLMs and Planning
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. LLMs 和 规划
- en: Despite anecdotal applications showing signs of successful LLM planning (Song
    et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib78)), more holistic
    reviews suggest that LLMs make poor planners (Valmeekam et al., [2022](https://arxiv.org/html/2412.04093v1#bib.bib84),
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib83); Kambhampati, [2024](https://arxiv.org/html/2412.04093v1#bib.bib39);
    Liu et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib53); Dagan et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib26)). As such, if an LLM agent
    is to be deployed in an environment with a consistent task, manually curating
    a plan can alleviate the pains of poor LLM planning as well as provide an opportunity
    to manually craft relevant roles and prompts. Another option is to augment the
    LLM agent with an external planning tool, which has shown promise (Liu et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib53); Dagan et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib26)).
    Because LLM planning remains an open area of research, the example in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").P1
    simply assumes planning capabilities without subscribing to a specific approach,
    for illustrative purposes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些轶事应用显示LLM规划成功的迹象 (Song 等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib78))，但更多的整体性评审表明LLM是糟糕的规划者 (Valmeekam
    等人，[2022](https://arxiv.org/html/2412.04093v1#bib.bib84)，[2024](https://arxiv.org/html/2412.04093v1#bib.bib83);
    Kambhampati，[2024](https://arxiv.org/html/2412.04093v1#bib.bib39); Liu 等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib53);
    Dagan 等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib26))。因此，如果要在具有一致任务的环境中部署LLM代理人，手动策划一个计划可以缓解LLM规划差的问题，并提供手动设计相关角色和提示的机会。另一种选择是通过外部规划工具增强LLM代理人，这已经显示出一定的前景 (Liu
    等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib53); Dagan 等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib26))。由于LLM规划仍然是一个开放的研究领域，图
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems") 中的示例仅假设规划能力，而没有订阅特定的方法，仅用于说明目的。
- en: To describe current approaches to planning in LLM agents, we categorize them
    into implicit and explicit planning. For implicit planning, some agents will rely
    on the LLM to iteratively determine the immediate next step until the task is
    complete, without ever eliciting a plan (Zhang et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib105);
    Gur et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib34)). This approach
    relies on the idea that, when provided with an end goal, the LLM can maintain
    an internal plan whose steps are revealed iteratively without any explicit plan
    formalization. This approach can be viable when the environment is dynamic or
    only partially observable, such as interacting with a webpage (Gur et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib34)).
    The other form of implicit planning is the creation and execution of a plan in
    a single inference, as seen in prompting strategies such as Plan-and-Solve (Wang
    et al., [2023b](https://arxiv.org/html/2412.04093v1#bib.bib89)) and, to a degree,
    zero-shot Chain-of-Thought (Kojima et al., [2022](https://arxiv.org/html/2412.04093v1#bib.bib43)).
    These approaches rely on conditioning subsequent token generation (i.e., the ”execution”)
    on a plan by first generating said plan. Due to the single-hop nature of this
    approach, it is not recommended for complex tasks, particularly those that would
    benefit from feedback during execution.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了描述当前 LLM 代理的规划方法，我们将其分为隐式规划和显式规划。对于隐式规划，一些代理将依赖 LLM 迭代地确定下一个立即步骤，直到任务完成，而无需提出一个计划（Zhang
    等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib105)；Gur 等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib34)）。这种方法依赖于这样的理念：当提供一个最终目标时，LLM
    可以保持一个内部计划，其步骤会被迭代地揭示，而无需任何显式的计划形式化。当环境动态变化或只有部分可观察时，这种方法是可行的，例如与网页交互（Gur 等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib34)）。另一种隐式规划形式是在单次推理中创建并执行一个计划，正如
    Plan-and-Solve 提示策略所示（Wang 等，[2023b](https://arxiv.org/html/2412.04093v1#bib.bib89)），以及在一定程度上，零-shot
    Chain-of-Thought（Kojima 等，[2022](https://arxiv.org/html/2412.04093v1#bib.bib43)）。这些方法依赖于通过首先生成计划来条件化随后的令牌生成（即“执行”）。由于这种方法的单跳性质，它不适用于复杂任务，特别是那些在执行过程中需要反馈的任务。
- en: Explicit planning is characterized by the explicit formalization of a multi-step
    plan, typically executed in a multi-hop fashion. The most basic form is to simply
    request the formulation of a plan and then execute it, as demonstrated by the
    Least-to-Most prompting strategy (Zhou et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib108)).
    More advanced approaches will first develop a plan and then iteratively refine
    the plan as steps are executed (Liu et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib56)).
    Both of these require long-term planning, which is where LLMs tend to demonstrate
    lackluster performance (Valmeekam et al., [2022](https://arxiv.org/html/2412.04093v1#bib.bib84),
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib83); Kambhampati, [2024](https://arxiv.org/html/2412.04093v1#bib.bib39)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 显式规划的特点是将多步骤的计划明确地形式化，通常以多跳的方式执行。最基本的形式是简单地请求制定一个计划，然后执行它，正如最小到最大提示策略所示（Zhou
    等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib108)）。更先进的方法首先制定计划，然后在执行步骤时迭代地完善计划（Liu
    等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib56)）。这两者都需要长期规划，而这正是 LLM
    往往表现不佳的地方（Valmeekam 等，[2022](https://arxiv.org/html/2412.04093v1#bib.bib84)，[2024](https://arxiv.org/html/2412.04093v1#bib.bib83)；Kambhampati，[2024](https://arxiv.org/html/2412.04093v1#bib.bib39)）。
- en: 5.2\. Task Decomposition
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 任务分解
- en: It is important to understand the limitations of an LLM before formulating a
    plan for it to execute. Agentic LLM systems are often applied to problems that
    a single LLM call cannot resolve but a sequence of calls can. Tasks can typically
    be decomposed into smaller pieces that, when solved individually, can be reconstructed
    to produce the final solution (Zhou et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib108)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在制定 LLM 执行计划之前，了解 LLM 的局限性是很重要的。代理式 LLM 系统通常应用于单个 LLM 调用无法解决的问题，但一系列调用可以解决。任务通常可以分解成更小的部分，当单独解决这些部分时，可以重建并得出最终解决方案（Zhou
    等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib108)）。
- en: 'Returning to Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2
    ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems"), the
    request made in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2
    ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I1
    is composed of multiple subtasks, namely: (1) retrieve recipes that contain rice,
    beans, and tomato that the user will like and (2) order any missing ingredients.
    It is also reasonable to decompose (1) further, into a retrieval of recipes that
    contain the required ingredients and separately a request to select the one that
    best fits the user’s tastes.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 回到图[2](https://arxiv.org/html/2412.04093v1#S3.F2 "图2 ‣ 3\. 应用场景 ‣ 代理型LLM系统的实践考虑")，图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图2 ‣ 3\. 应用场景 ‣ 代理型LLM系统的实践考虑")中提出的请求I1由多个子任务组成，分别是：(1) 检索包含米饭、豆类和番茄的食谱，并且这些食谱是用户会喜欢的，以及(2)
    订购缺失的任何食材。合理的做法是将(1)进一步分解为检索包含所需食材的食谱，并单独请求选择最符合用户口味的食谱。
- en: If decomposing a well-defined task manually, iteratively decomposing the task
    into subtasks and testing an LLM on them can provide valuable insight into what
    the LLM can consistently handle. Breaking down the problem logically is simple
    enough, but ascertaining which tasks an LLM can perform well and which require
    further decomposition can be challenging, particularly when dealing with stochasticity
    and prompt changes. It is recommended to evaluate the LLM agent frequently and
    systematically during this process, as discussed in Section [9.2](https://arxiv.org/html/2412.04093v1#S9.SS2
    "9.2\. Evaluation ‣ 9\. Additional Considerations ‣ Practical Considerations for
    Agentic LLM Systems"). It may be easier to start at the most basic building blocks
    of the tasks and combine them than to find the minimum number of viable tasks
    to start.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果手动分解一个明确定义的任务，逐步将任务分解为子任务并对LLM进行测试，可以为了解LLM能够一致处理哪些任务提供宝贵的见解。逻辑上分解问题足够简单，但确定LLM能够很好执行哪些任务，哪些任务需要进一步分解，可能是具有挑战性的，特别是在处理随机性和提示变化时。建议在此过程中频繁且系统地评估LLM代理，如[9.2](https://arxiv.org/html/2412.04093v1#S9.SS2
    "9.2\. 评估 ‣ 9\. 附加考虑 ‣ 代理型LLM系统的实践考虑")一节中所讨论的那样。在开始时，可能更容易从任务的最基本构建块开始并将它们组合起来，而不是寻找可行任务的最小数量来启动。
- en: While it may be intuitive to assume that the more atomic the task the better,
    this is not always the case. It has been shown that LLMs not only possess the
    ability to solve multiple distinct tasks in a single query (Xiong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib99);
    Son et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib77); Laskar et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib45)) but that composing multiple
    tasks into a single prompt can increase performance on all constituent tasks,
    as well as decreasing overall context usage (Son et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib77)).
    However, the degree to which tasks may be combined should be the subject of rigorous
    experimentation for the specific task and environment in which it is considered.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管直观上可能认为任务越原子化越好，但事实并非总是如此。研究表明，LLM不仅具备在单个查询中解决多个不同任务的能力 (Xiong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib99);
    Son et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib77); Laskar et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib45))，而且将多个任务组合成一个提示可以提高所有组成任务的表现，同时减少整体上下文的使用量 (Son
    et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib77))。然而，任务能够组合的程度应当成为针对特定任务和环境进行严格实验的课题。
- en: 5.3\. Plan Adherence
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 计划遵循
- en: One of the responsibilities of the LLM agent is to oversee the application of
    the plan. It should decide if a step needs to be repeated (e.g., for [Error Handling](https://arxiv.org/html/2412.04093v1#S8.SS2
    "In 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems")) or
    skipped for a given input (e.g., to iterate on the plan (Liu et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib56))).
    One of the major concerns of LLMs as planners is their inability to identify whether
    or not they can complete a given task (Kambhampati, [2024](https://arxiv.org/html/2412.04093v1#bib.bib39)).
    As such, it is often impossible for an LLM agent to know if a step will be successful
    until it has been attempted. Thus, it follows logically that an evaluation of
    the success of each step should take place following execution. Similarly, the
    overall success of the plan should be evaluated upon completion of all steps.
    If unsuccessful, the LLM agent may need to adjust or rerun the plan, based on
    the results of each step and the overall plan (see Section [8.2](https://arxiv.org/html/2412.04093v1#S8.SS2
    "8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems") for a discussion on incorporating feedback).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 代理的责任之一是监督计划的执行。它应该决定是否需要为给定输入重复某个步骤（例如，[错误处理](https://arxiv.org/html/2412.04093v1#S8.SS2
    "在 8\. 控制流程 ‣ 代理式 LLM 系统的实际考虑")）或跳过某个步骤（例如，为了对计划进行迭代（Liu 等， [2024a](https://arxiv.org/html/2412.04093v1#bib.bib56)））。作为计划者的
    LLM 主要的关注点之一是它们无法判断是否能够完成给定任务（Kambhampati，[2024](https://arxiv.org/html/2412.04093v1#bib.bib39)）。因此，LLM
    代理通常无法知道某个步骤是否会成功，直到尝试执行该步骤。因此，逻辑上应该在执行后评估每个步骤的成功与否。同样，整个计划的成功与否也应该在所有步骤完成后进行评估。如果计划不成功，LLM
    代理可能需要根据每个步骤的结果和整体计划调整或重新执行计划（详见第 [8.2](https://arxiv.org/html/2412.04093v1#S8.SS2
    "8.2\. 错误处理 ‣ 8\. 控制流程 ‣ 代理式 LLM 系统的实际考虑")节，讨论如何结合反馈）。
- en: 6\. Memory
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 内存
- en: 6.1\. Retrieval Augmented Generation
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 检索增强生成
- en: 'Retrieval augmented generation (RAG) (introduced in (Lewis et al., [2020](https://arxiv.org/html/2412.04093v1#bib.bib47)))
    has emerged as a staple of agentic LLM applications in industry  (Gao et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib32)). The basis is simple: a
    system that can provide external context relevant to a natural language input.
    Typically, an incoming input will be compared against a ground-truth data store
    and the most relevant piece(s) of information will be provided to the LLM as context
    upon which it will base its response. This can be done either implicitly, where
    a user’s input is always used for retrieval for a given LLM call, or explicitly,
    where the LLM uses RAG as a tool. This has a number of benefits for LLM systems:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）（在（Lewis 等，[2020](https://arxiv.org/html/2412.04093v1#bib.bib47)）中首次提出）已经成为工业界代理式
    LLM 应用的核心（Gao 等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib32)）。其基本原理很简单：一个能够提供与自然语言输入相关的外部上下文的系统。通常，传入的输入会与一个真实数据存储进行比较，然后将最相关的信息片段作为上下文提供给
    LLM，LLM 将基于这些信息作出回应。这可以通过隐式方式完成，即用户的输入始终用于检索某个 LLM 调用；也可以通过显式方式完成，即 LLM 将 RAG
    作为工具使用。这对 LLM 系统有许多好处：
- en: •
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Grounding. Rather than relying on the LLM “remembering” relevant context from
    its training data correctly, we can provide the LLM with accurate relevant information.
    Providing grounded text as context significantly reduces LLM hallucinations and
    fills knowledge gaps in the training data (Shuster et al., [2021](https://arxiv.org/html/2412.04093v1#bib.bib75);
    Es et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib31); Lewis et al.,
    [2020](https://arxiv.org/html/2412.04093v1#bib.bib47)).
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基础化。与其依赖 LLM 正确“记住”训练数据中的相关上下文，不如直接为 LLM 提供准确的相关信息。作为上下文提供基础化文本显著减少了 LLM 的幻觉现象，并填补了训练数据中的知识空白（Shuster
    等，[2021](https://arxiv.org/html/2412.04093v1#bib.bib75)；Es 等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib31)；Lewis
    等，[2020](https://arxiv.org/html/2412.04093v1#bib.bib47)）。
- en: •
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Explainability. Rather than relying on an LLM opaquely referencing information
    it has been trained on, adherence to context supplied as part of RAG provides
    insight into exactly where an LLM is getting its information (Gao et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib32)).
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性。与其依赖 LLM 模糊地引用其训练中获得的信息，不如遵循作为 RAG 一部分提供的上下文，这样可以清晰地了解 LLM 获取信息的具体来源（Gao
    等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib32)）。
- en: •
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Timeliness. While LLMs can reference information from their static training
    data, the LLM will be subject to a hard information cutoff (the latest date training
    data was scraped) and a soft information cutoff (events close to its hard information
    cutoff that have limited coverage). Rather than turning to the infeasible prospect
    of retraining with updated data, we can provide updated information that is relevant
    to the query as context (Gao et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib32)).
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 时效性。虽然LLMs可以引用来自静态训练数据的信息，但LLM会受到硬性信息截止日期（即训练数据抓取的最晚日期）和软性信息截止日期（即接近硬性信息截止日期且覆盖有限的事件）的限制。与其转向重新训练并使用更新数据这一不可行的前景，我们可以提供与查询相关的更新信息作为上下文（Gao等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib32)）。
- en: •
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Outsourcing. Depending on the content, quality, and reliability of the RAG database,
    aspects of the query can be implicitly outsourced to the context returned, such
    as reasoning and decision-making.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 外包。根据RAG数据库的内容、质量和可靠性，查询的某些方面可以隐式地外包给返回的上下文，例如推理和决策。
- en: •
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Alignment. The vast amount of training data used for LLMs is the source of their
    natural language understanding but should not necessarily be relied on for unbiased,
    trustworthy, and safe generation. Typically, aligning LLM ouputs with human preferences
    is seen as a data collection and training problem (Wang et al., [2023c](https://arxiv.org/html/2412.04093v1#bib.bib91);
    Bai et al., [2022](https://arxiv.org/html/2412.04093v1#bib.bib20)) but can also
    be addressed post-hoc with RAG. By augmenting an LLM’s natural language capabilities
    and tendencies with context derived from a more refined dataset that adheres to
    a desired set of human preferences, its output can be guided to conform to a desired
    set of content and attitudes. This requires careful curation of the data store
    but is a viable method for black-box alignment.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对齐。用于大规模语言模型（LLMs）的大量训练数据是其自然语言理解的来源，但不应完全依赖于此以生成无偏见、值得信赖且安全的内容。通常，将LLM的输出与人类偏好对齐被视为一个数据收集和训练问题（Wang等，[2023c](https://arxiv.org/html/2412.04093v1#bib.bib91)；Bai等，[2022](https://arxiv.org/html/2412.04093v1#bib.bib20)），但也可以通过RAG后处理来解决。通过利用从符合人类偏好期望集的更精炼数据集获取的上下文，增强LLM的自然语言能力和倾向，其输出可以被引导以符合期望的内容和态度。这需要仔细策划数据存储，但它是一种可行的黑箱对齐方法。
- en: To exemplify the points above, consider the RAG sources referenced in Figure
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").R1 and [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").R2\.
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").R1 can be quoted to avoid
    recipe hallucinations (grounding) and be updated with new recipes (timeliness).
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").R2 could be useful in responding
    to Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied
    Scenario ‣ Practical Considerations for Agentic LLM Systems").I2; where there
    is no general consensus, we can supply our own ground truth rather than require
    the LLM to answer a potentially moral question (outsourcing). The tone and terminology
    of both Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied
    Scenario ‣ Practical Considerations for Agentic LLM Systems").R1 and [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").R2
    will guide the ideals, content, and terminology used by the LLM (alignment).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明上述观点，请参见图 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\.
    Applied Scenario ‣ Practical Considerations for Agentic LLM Systems") 中引用的 RAG
    来源。R1 和 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied
    Scenario ‣ Practical Considerations for Agentic LLM Systems")。R2。图 [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")。R1
    可以被引用以避免配方幻觉（基础验证）并用新配方进行更新（时效性）。图 [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")。R2
    可以在回应图 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems")。I2 时派上用场；在没有普遍共识的情况下，我们可以提供自己的基础事实，而不是要求
    LLM 回答一个潜在的道德问题（外包）。图 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2
    ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")。R1
    和 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems")。R2 的语气和术语将引导 LLM 使用的理想、内容和术语（对齐）。
- en: 'There are two main approaches to RAG: knowledge graphs (Edge et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib30))
    and vector databases (Gao et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib32);
    Barron et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib21)), with the
    latter seeing far greater adoption due to its simplicity. For a discussion on
    implementing RAG and the extant commercial and open-source offerings, see (Gao
    et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib32)).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 有两种主要方法：知识图谱（Edge 等， [2024](https://arxiv.org/html/2412.04093v1#bib.bib30)）和向量数据库（Gao
    等， [2024](https://arxiv.org/html/2412.04093v1#bib.bib32)；Barron 等， [2024](https://arxiv.org/html/2412.04093v1#bib.bib21)），后者因其简便性而被广泛采用。关于
    RAG 实施及现有的商业和开源产品的讨论，见（Gao 等， [2024](https://arxiv.org/html/2412.04093v1#bib.bib32)）。
- en: 6.2\. Long-Term Memory
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 长期记忆
- en: Sometimes, key information is gained during a conversation that may be helpful
    across all contexts, such as a useful piece of external knowledge or information
    about a user or task. In those instances, it may be advantageous to store that
    information in a way accessible to the agent so that its impact is not limited
    to the current context. This is commonly referred to as ”long-term memory” (Qian
    et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib65); Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88);
    Zhong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107))⁴⁴4A real-world
    implementation of long-term memory is OpenAI’s “Memory” (OAI, [2024](https://arxiv.org/html/2412.04093v1#bib.bib15)).
    During conversations with ChatGPT, the LLM will save information that it deems
    particularly useful to its memory. That memory is then made available to the LLM
    in future conversations. A clear benefit of this is that it reduces repetition
    on the part of the user and allows the LLM to better fulfill its objective of
    providing relevant responses..
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，在对话中获得的关键信息可能对所有上下文都有帮助，例如有用的外部知识或关于用户或任务的信息。在这种情况下，将该信息以一种可以被代理访问的方式存储可能是有利的，以便它的影响不局限于当前的上下文。这通常被称为“长期记忆”（Qian等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib65)；Wang等，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)；Zhong等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107))⁴⁴4长期记忆的现实世界实现是OpenAI的“记忆”（OAI，[2024](https://arxiv.org/html/2412.04093v1#bib.bib15)）。在与ChatGPT的对话中，LLM会保存其认为特别有用的信息。这些信息随后将在未来的对话中提供给LLM。这带来的一个明显好处是，它减少了用户的重复性操作，并且让LLM能更好地实现提供相关回复的目标。
- en: We want to be selective with the information that is stored in long-term memory
    so that it is generally useful and not excessively large. Some common approaches
    are to store prior solutions to queries (Qian et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib65)),
    global summaries and insights (Zhong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107)),
    and acquired tools (Wang et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望对存储在长期记忆中的信息进行选择，以确保其一般有用且不过于庞大。一些常见的方法是存储先前的查询解决方案（Qian等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib65)），全局总结和洞察（Zhong等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107)），以及获得的工具（Wang等，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)）。
- en: 'Long-term memory can be enhanced with reflection, consolidation, forgetting,
    revision, and other mechanisms designed to mimic long-term memory in humans (see (Zhong
    et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107)) for a discussion
    on advanced long-term memory implementation). For simplicity, we focus on a simple
    version of long-term memory, where information is simply stored and retrieved,
    and any edits are manual. For this simple variation, we derive the following three
    criteria from existing literature on long-term memory in LLM agents (Qian et al.,
    [2024a](https://arxiv.org/html/2412.04093v1#bib.bib65); Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88);
    Zhong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107); OAI, [2024](https://arxiv.org/html/2412.04093v1#bib.bib15);
    Wang et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)) to use as
    a litmus test for what information should be stored:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反思、巩固、遗忘、修订以及其他旨在模仿人类长期记忆的机制，长期记忆可以得到增强（有关高级长期记忆实现的讨论，请参见（Zhong等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107)））。为了简化，我们专注于长期记忆的简单版本，其中信息只是被存储和检索，任何编辑都需要手动进行。对于这个简单的变体，我们从现有的LLM代理长期记忆文献中得出以下三个标准（Qian等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib65)；Wang等，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)；Zhong等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107)；OAI，[2024](https://arxiv.org/html/2412.04093v1#bib.bib15)；Wang等，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)）作为应该存储信息的试金石：
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Independent. The information should not have any implicit dependencies, such
    as input values.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 独立性。信息应该没有任何隐式依赖，例如输入值。
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Relevant to a consistency. The information should be relevant to consistencies
    in the agentic LLM system, which may include a task, user, or environment.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与一致性相关。信息应与代理系统中的一致性相关，这可能包括任务、用户或环境。
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Applicable long-term. The information should consistently be applicable to contexts
    to which the LLM agent may be exposed.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适用长期性。信息应始终适用于LLM代理可能接触的上下文。
- en: See Table [1](https://arxiv.org/html/2412.04093v1#S6.T1 "Table 1 ‣ 6.2\. Long-Term
    Memory ‣ 6\. Memory ‣ Practical Considerations for Agentic LLM Systems") for the
    above criteria applied to examples drawn from Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见表 [1](https://arxiv.org/html/2412.04093v1#S6.T1 "表 1 ‣ 6.2\. 长期记忆 ‣ 6\. 记忆
    ‣ 代理型大语言模型系统的实际考虑")，其中应用了以上标准，并结合图 [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 代理型大语言模型系统的实际考虑") 中的示例。
- en: If the three criteria above are ensured, then the gathered in-context information
    can be a useful starting place for prompt improvements. It will be information
    that has been identified as generally and consistently useful to the LLM agent’s
    environment and may be appropriately suited to permanent inclusion in user or
    system prompts. It can also be valuable to review long-term memory when making
    prompt, task, persona, hyperparameter, or model updates; reordering LLM calls;
    or adjusting tool functionality as such changes may impact the validity of the
    three criteria.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果确保了上述三个标准，那么收集到的上下文信息可以成为提示改进的有用起点。它将是那些被识别为通常和持续对 LLM 代理的环境有用的信息，可能适合永久性地包含在用户或系统的提示中。进行提示、任务、角色、超参数或模型更新时，审查长期记忆也非常有价值；例如，重新排序
    LLM 调用，或调整工具功能时，因为这些变化可能会影响三个标准的有效性。
- en: Table 1\. Analysis of information from Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")
    in context of the three criteria for storing in-context information.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 根据存储上下文信息的三个标准，分析图 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "图 2
    ‣ 3\. 应用场景 ‣ 代理型大语言模型系统的实际考虑") 中的信息。
- en: '| Information | Independent | Relevant to Consistency | Applicable Long-Term
    | Store the Info |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 信息 | 独立性 | 与一致性相关 | 适用于长期 | 存储信息 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| E1 Corn is no longer available | Yes | Yes | Yes | Yes |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| E1 玉米不再可用 | 是 | 是 | 是 | 是 |'
- en: '| E2 Poultry is no longer available | Yes | No | No | No |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| E2 家禽类食品不再可用 | 是 | 否 | 否 | 否 |'
- en: '| U2 Allergic to nuts | Yes | Yes | Yes | Yes |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| U2 对坚果过敏 | 是 | 是 | 是 | 是 |'
- en: '| I1 I have rice, beans, and tomatoes… | No | Yes | No | No |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| I1 我有米饭、豆类和西红柿…… | 否 | 是 | 否 | 否 |'
- en: 6.2.1\. Extracting Information for Long-Term Memory
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1\. 提取长期记忆信息
- en: A common approach to extracting information that belongs in long-term memory
    is to leverage an external conversation moderator (Zhong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107);
    Shinn et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib74)). The external
    moderator (e.g., an LLM with a separate role) that reviews conversations (either
    whole or in pieces) and can be tasked with extracting information it deems compliant
    with the three criteria above. This is an instance where care must be taken with
    phrasing as the subjectivity of the task may make the LLM prone to framing bias
    in its response (e.g., if we ask if there is anything useful to pull out, the
    LLM will likely pull out some information) (Echterhoff et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib29)).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 提取属于长期记忆的信息的常见方法是利用外部对话主持人 (Zhong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107);
    Shinn et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib74))。外部主持人（例如，具有独立角色的大语言模型）会审查对话（完整对话或片段），并可以被任务化提取其认为符合上述三个标准的信息。这是一个需要注意措辞的实例，因为任务的主观性可能使得大语言模型在响应时容易受到框架偏见的影响（例如，如果我们问是否有任何有用的信息需要提取，大语言模型很可能会提取一些信息）（Echterhoff
    et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib29)）。
- en: 6.2.2\. Storing Long-Term Memory
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2\. 存储长期记忆
- en: Once a piece of information has been deemed worthy of long-term memory, it should
    be stored. Some approaches include embedding and storing the information in a
    vector database (similar to [RAG](https://arxiv.org/html/2412.04093v1#S6.SS1 "6.1\.
    Retrieval Augmented Generation ‣ 6\. Memory ‣ Practical Considerations for Agentic
    LLM Systems")) (Zhong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib107);
    Lin et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib52)) and natural
    language storage, although interacting with the latter quickly becomes unwieldy
    as the amount of long-term memory increases. The structure of the vector database
    allows us to easily query relevant information (Lin et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib52);
    Wang et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib87); Zhong et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib107)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦某一信息被认为值得存入长期记忆，它就应该被存储。某些方法包括将信息嵌入并存储在向量数据库中（类似于[RAG](https://arxiv.org/html/2412.04093v1#S6.SS1
    "6.1\. Retrieval Augmented Generation ‣ 6\. Memory ‣ Practical Considerations
    for Agentic LLM Systems")）（Zhong 等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107)；Lin
    等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib52)），以及自然语言存储，尽管随着长期记忆量的增加，与后者的交互很快会变得不方便。向量数据库的结构使得我们可以轻松查询相关信息（Lin
    等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib52)；Wang 等人，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)；Zhong
    等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107)）。
- en: 6.2.3\. Utilizing Long-Term Memory
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3\. 利用长期记忆
- en: Once information is stored in long-term memory, we must decide when to expose
    it to the LLM agent. It is key to understand what information is relevant in the
    current scope. LLM agents may be composed of many LLM calls with different purposes
    and contexts; not all information from long-term memory will apply to every LLM
    call. For example, if the user from Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")
    decides to plan meals once a week (per Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I5),
    that would be a valuable long-term memory for Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe1
    but not necessarily [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣
    3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe2,
    which is mainly used for its culinary expertise. In such instances, the relevance
    afforded by retrieval from a vector database is valuable (Lin et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib52);
    Wang et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib87); Zhong et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib107)). Once relevant information
    has been retrieved from long-term memory, it can be shared in an LLM call via
    the user or system prompt.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦信息被存储到长期记忆中，我们必须决定何时将其暴露给LLM代理。理解当前范围内哪些信息是相关的至关重要。LLM代理可能由许多不同目的和背景的LLM调用组成；并非所有长期记忆中的信息都会应用于每一次LLM调用。例如，如果图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems")中的用户决定每周规划一次餐单（如图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I5所示），这对图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe1来说是有价值的，但不一定对[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe2有价值，因为后者主要用于其烹饪专业知识。在这种情况下，通过向量数据库检索得到的相关性是有价值的（Lin
    等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib52)；Wang 等人，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)；Zhong
    等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib107)）。一旦从长期记忆中检索到相关信息，它可以通过用户或系统提示在LLM调用中共享。
- en: 7\. Tools
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 工具
- en: 7.1\. Using Tools
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 使用工具
- en: To enable the LLM to use tools, tool descriptions and methods of invocation
    need to be exposed with the LLM (similar to traditional software engineering documentation).
    If the number of tools in use is small, they can be introduced in natural language.
    The method for invoking a tool should be clear and easily parsable. A common way
    to do this is by defining JSON schemas or function signatures, although the latter
    has been shown to be better for LLM agents (Roucher and Petrov, [2024](https://arxiv.org/html/2412.04093v1#bib.bib69);
    Wang et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib90)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要使LLM能够使用工具，需要与LLM一起公开工具描述和调用方法（类似于传统的软件工程文档）。如果使用的工具数量较少，可以用自然语言进行介绍。调用工具的方法应该清晰且易于解析。常见的做法是定义JSON架构或函数签名，尽管后者被证明更适合LLM代理（Roucher和Petrov，[2024](https://arxiv.org/html/2412.04093v1#bib.bib69)；Wang等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib90)）。
- en: Tools can be called either explicitly or implicitly, with the former being the
    de facto approach in practice. Explicit usage simply entails the invocation of
    a tool as part of the LLM agent’s output (Schick et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib71);
    Qin et al., [2024b](https://arxiv.org/html/2412.04093v1#bib.bib68)). Once the
    tools are defined and passed as context, the agent will have the means to perform
    such an invocation in the specified parsable format. Tools can also be implicitly
    invoked by the implementor in response to an LLM agent’s action or inaction. For
    example, if a transition between personas occurs, it may be the case that the
    system will always benefit from a summarization of preceding dialogue. Rather
    than rely on the LLM agent to invoke a summarization at every persona change,
    every such transition can trigger a summarization behind the scenes. See Section
    [9.3](https://arxiv.org/html/2412.04093v1#S9.SS3 "9.3\. Integration with Traditional
    Engineering ‣ 9\. Additional Considerations ‣ Practical Considerations for Agentic
    LLM Systems") for a discussion on incorporating implicit tool calling.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 工具可以通过显式或隐式调用，前者在实践中是事实上的常用方法。显式使用仅仅意味着在LLM代理的输出中调用工具（Schick等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib71)；Qin等，[2024b](https://arxiv.org/html/2412.04093v1#bib.bib68)）。一旦工具被定义并作为上下文传递，代理就能以指定的可解析格式执行这样的调用。工具也可以通过实现者在响应LLM代理的行动或无动作时隐式调用。例如，如果发生角色之间的转换，系统可能会始终受益于对前面对话的总结。与其依赖LLM代理在每次角色变化时调用总结，不如让每次转换都在后台触发一次总结。有关隐式调用工具的讨论，请参见[9.3节](https://arxiv.org/html/2412.04093v1#S9.SS3
    "9.3\. 集成与传统工程 ‣ 9\. 额外考虑 ‣ 代理LLM系统的实践考虑")。
- en: 7.2\. Managing Multiplicity
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2. 管理多样性
- en: As the number of tools grows, defining tools in natural language quickly becomes
    unwieldy and a structured approach is necessary. To do so, we can leverage LLMs’
    convenient understanding of code by creating more concise tool definitions using
    JSON schemas or function signatures in conjunction with condensed natural language
    descriptions⁵⁵5See https://python.langchain.com/docs/concepts/#tools for a discussion
    on tool definition and (PCo, [[n.d.]](https://arxiv.org/html/2412.04093v1#bib.bib3))
    for an implementation..
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 随着工具数量的增加，用自然语言定义工具很快会变得难以管理，这时需要采用结构化的方法。为此，我们可以利用LLM对代码的便捷理解，通过结合JSON架构或函数签名以及简洁的自然语言描述来创建更简明的工具定义⁵⁵5有关工具定义的讨论，请参见[https://python.langchain.com/docs/concepts/#tools](https://python.langchain.com/docs/concepts/#tools)，以及(PCo,
    [[n.d.]](https://arxiv.org/html/2412.04093v1#bib.bib3))的实现。
- en: Often, distinct tools can be placed into distinct groups based on similar core
    functionality (i.e., if they can reasonably be seen as inheriting from the same
    base class). These groups can be called “toolsets” or ”toolkits”⁶⁶6See https://python.langchain.com/docs/concepts/#toolkits.
    and are helpful for determining if tools can be combined behind a single interface
    or introduced together in the prompt. For example, the tools Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T1
    and [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").T2 introduced in the example
    would not belong in the same toolset but [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T2
    and [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").T3 would.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，基于相似的核心功能（即，如果它们可以合理地看作是继承自相同的基类）可以将不同的工具分组。这些组可以称为“工具集”或“工具包”⁶⁶6请参见 https://python.langchain.com/docs/concepts/#toolkits。这有助于确定工具是否可以通过单一接口组合，或者是否可以在提示中一起引入。例如，在示例中介绍的工具
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").T1 和 [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T2
    不属于同一工具集，但 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied
    Scenario ‣ Practical Considerations for Agentic LLM Systems").T2 和 [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T3
    会属于同一工具集。
- en: 7.3\. Adding Tools Dynamically
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3\. 动态添加工具
- en: Sometimes the tools that are available in the environment in which an agentic
    LLM system will be deployed are not known beforehand. In this case, we can add
    “tool identification” as a task for the system (Schick et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib71);
    Wang et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)). A compelling
    example and implementation of this can be observed in the Voyager paper, where
    an LLM-based agent autonomously traverses the world of Minecraft⁷⁷7https://www.minecraft.net
    and dynamically assembles a set of tools based on interactions with the environment,
    which are then stored in long-term memory (Wang et al., [2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，代理 LLM 系统将要部署的环境中的工具并不事先已知。在这种情况下，我们可以将“工具识别”作为系统的一个任务（Schick 等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib71);
    Wang 等，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)）。一个引人注目的示例和实现可以在
    Voyager 论文中看到，其中基于 LLM 的代理在 Minecraft 的世界中自主穿行⁷⁷7https://www.minecraft.net，并根据与环境的交互动态地组装一组工具，这些工具随后存储在长期记忆中（Wang
    等，[2023a](https://arxiv.org/html/2412.04093v1#bib.bib87)）。
- en: 8\. Control Flow
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 控制流
- en: In the context of LLM agents, control flow refers to the ability to determine
    what needs to be done in order to respond to a query. Tasking an LLM with control
    flow is what enables LLM-based agents to accomplish complex tasks that elude the
    capacity of a single inference. This endows the LLM agent with the autonomy to
    incorporate advanced techniques such as planning, tool usage, and multi-step reasoning
    as it sees fit (Shen et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib73);
    Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 代理的上下文中，控制流指的是确定为了回应查询需要做什么的能力。给 LLM 任务控制流使得基于 LLM 的代理能够完成那些单次推理无法解决的复杂任务。这赋予了
    LLM 代理自主性，可以根据需要融入诸如规划、工具使用和多步推理等先进技术（Shen 等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib73);
    Wang 等，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)）。
- en: In practice, this may look like the LLM agent receiving user input (i.e., observing
    the environment) and selecting the immediate next action. The agent continues
    to take actions until it decides to stop. For this to be possible, the LLM agent
    needs to be aware of the action space (Yao et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib103)),
    such as the stopping criteria, available tools (e.g., Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T1,
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").T2, and [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T3),
    available planning options ([2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure
    2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").P1),
    the ability to take a turn to think out loud (Yao et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib103)),
    and utilizing other personas (e.g., [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe2).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这可能表现为LLM代理接收用户输入（即，观察环境）并选择立即采取的下一步行动。代理会继续采取行动，直到决定停止。为了使这一过程可行，LLM代理需要了解其行动空间（Yao等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib103)），例如停止标准、可用工具（例如，图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。T1，[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。T2，和[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。T3)，可用的规划选项（[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。P1），能够进行思维外化（Yao等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib103)），以及使用其他角色（例如，[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。Pe2）。
- en: Consider an LLM agent receiving Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I1\.
    Rather than simply providing an output, the agent can opt to leverage [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").P1,
    the planning module, to decompose the complex task and generate a multi-step plan
    that it can then administer. Once the plan is complete, the agent can decide if
    it has enough information to provide the final output to [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I1
    or if it needs to take additional actions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个接收图示[2](https://arxiv.org/html/2412.04093v1#S3.F2 "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM
    系统的实际考虑")的LLM代理。I1。代理不仅仅提供输出，它还可以选择利用[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。P1，规划模块，来分解复杂的任务并生成一个多步骤的计划，然后执行该计划。一旦计划完成，代理可以决定是否有足够的信息提供最终输出给[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图 2 ‣ 3\. 应用场景 ‣ 智能 LLM 系统的实际考虑")。I1，或者它是否需要采取额外的行动。
- en: Here, we present practical considerations for ensuring the LLM agent can interact
    with its environment smoothly and without interruption.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍了一些实际考虑，确保LLM代理能够与其环境顺畅且不断裂地交互。
- en: 8.1\. Output Processing
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 输出处理
- en: 'When chaining together multiple LLM inputs and outputs, it is often advantageous
    to process the text before handing it off to the next step. Although natural language
    is human-readable, it is advisable to use a more structured format (such as JSON
    or executable code) that is easily parsable (Wang et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib90)).
    While weaker models may struggle with instruction following, most commercial models
    have been optimized to adhere to desired output formats specified in the user
    or system prompt⁸⁸8Output processing documentation for common commercial models:
    Anthropic (Ant, [[n.d.]](https://arxiv.org/html/2412.04093v1#bib.bib4)); OpenAI (OAI,
    [[n.d.]b](https://arxiv.org/html/2412.04093v1#bib.bib6)); Google (Gem, [2024c](https://arxiv.org/html/2412.04093v1#bib.bib11)).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在将多个 LLM 输入和输出串联在一起时，通常先对文本进行处理再传递给下一步是有利的。虽然自然语言是人类可读的，但建议使用更结构化的格式（如 JSON
    或可执行代码），以便更容易解析（Wang 等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib90)）。虽然较弱的模型可能在跟随指令时遇到困难，但大多数商业模型已经优化了以遵循用户或系统提示中指定的输出格式⁸⁸8常见商业模型的输出处理文档：Anthropic（Ant，[[n.d.]](https://arxiv.org/html/2412.04093v1#bib.bib4)）；OpenAI（OAI，[[n.d.]b](https://arxiv.org/html/2412.04093v1#bib.bib6)）；Google（Gem，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib11)）。
- en: Because we approach LLMs from a black-box perspective, we do not discuss the
    underlying approaches to constraining LLMs to output a specific format. However,
    it is important to note that the reasoning capabilities demonstrated by an LLM
    may be negatively (and inadvertently) impacted by constrained generation, depending
    on the implementation (Beurer-Kellner et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib23);
    Tam et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib80)). Because of
    this, it has been shown that requiring code outputs instead of a specific structure
    can yield better agents (Wang et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib90)).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们从黑箱的角度来研究 LLM，因此不会讨论约束 LLM 输出特定格式的底层方法。然而，需要注意的是，LLM 展示出的推理能力可能会受到约束生成的负面（且无意的）影响，这取决于具体的实现方式（Beurer-Kellner
    等， [2024](https://arxiv.org/html/2412.04093v1#bib.bib23)；Tam 等， [2024](https://arxiv.org/html/2412.04093v1#bib.bib80)）。因此，研究表明，要求输出代码而非特定结构，可以生成更好的代理（Wang
    等，[2024a](https://arxiv.org/html/2412.04093v1#bib.bib90)）。
- en: 8.2\. Error Handling
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2\. 错误处理
- en: Error handling is one of the most important yet elusive parts of building a
    robust agentic LLM system. Because LLMs are inherently stochastic, chaining several
    LLM calls together compounds the risk of failure to the point of near inevitability
    for long sequences. As such, every LLM call in an agentic LLM system should be
    treated as a potential point of failure and supported by appropriate error handling.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 错误处理是构建强大代理 LLM 系统中最重要但又最难捉摸的部分之一。由于 LLM 本质上是随机的，将多个 LLM 调用串联在一起会增加失败的风险，尤其是对于长序列几乎不可避免。因此，代理
    LLM 系统中的每个 LLM 调用都应该被视为潜在的失败点，并通过适当的错误处理来支持。
- en: We provide Figure [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣
    8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems") of an erroneous tool call to demonstrate several approaches to error
    handling, where specific responses will be referenced by the codes assigned in
    the figure (e.g., [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\.
    Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems").UI
    to refer to ”Order me an onion.”). The system prompt, containing role and tool
    information, is excluded for simplicity.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供图[3](https://arxiv.org/html/2412.04093v1#S8.F3 "图 3 ‣ 8.2\. 错误处理 ‣ 8\. 控制流
    ‣ 智能 LLM 系统的实际考虑")来展示几种错误处理方法，其中会通过图中分配的代码（例如， [3](https://arxiv.org/html/2412.04093v1#S8.F3
    "图 3 ‣ 8.2\. 错误处理 ‣ 8\. 控制流 ‣ 智能 LLM 系统的实际考虑")的UI，引用“为我点一个洋葱。”）来参考具体的响应。为简化起见，系统提示（包含角色和工具信息）被省略。
- en: '![Refer to caption](img/7e5c70573b95471b818bb0e7aaf3e964.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/7e5c70573b95471b818bb0e7aaf3e964.png)'
- en: Figure 3\. An example of an erroneous tool call, following the scenario presented
    in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied
    Scenario ‣ Practical Considerations for Agentic LLM Systems").
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. 错误工具调用的示例，参照图[2](https://arxiv.org/html/2412.04093v1#S3.F2 "图 2 ‣ 3\.
    应用场景 ‣ 智能 LLM 系统的实际考虑")中的场景。
- en: \Description
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: \说明
- en: A diagram showing an erroneous tool call from the agent.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 显示代理出现错误工具调用的图示。
- en: 8.2.1\. Static Retry
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.1\. 静态重试
- en: The simplest approach to handling a problematic output is to retry the LLM call
    with the same prompt. While other [hyperparameters](https://arxiv.org/html/2412.04093v1#S4
    "4\. Glossary ‣ Practical Considerations for Agentic LLM Systems") may stay the
    same, the seed should always change between static retries to avoid completely
    duplicate calls. If using a low temperature or a high top-p, then it may also
    make sense to adjust those values appropriately so as to receive a different output.
    In the context of Figure [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure
    3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems"), this might look like [3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").UI simply being rerun with a different seed.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 处理问题输出的最简单方法是用相同的提示重新调用LLM。虽然其他[超参数](https://arxiv.org/html/2412.04093v1#S4
    "4\. Glossary ‣ Practical Considerations for Agentic LLM Systems")可能保持不变，但每次静态重试时种子应始终更改，以避免完全重复的调用。如果使用低温度或高top-p值，则也可以适当调整这些值，以便获得不同的输出。在图
    [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\. Error Handling
    ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems")的上下文中，这可能表现为仅用不同的种子重新运行[3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").UI。
- en: For low-context calls that yield output that is easily verifiable (e.g., parsing
    the output into a JSON object), it is a simple yet valuable addition to attempt
    a few static retries in case verification fails. For outputs that are more difficult
    to verify, such as natural language instructions that are interpreted downstream,
    static retries are less helpful as the cost of verification increases.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些输出容易验证的低上下文调用（例如，将输出解析为JSON对象），如果验证失败，进行一些静态重试是一种简单而有价值的补充。对于那些更难验证的输出，例如下游解释的自然语言指令，静态重试的效果较差，因为验证成本较高。
- en: 8.2.2\. Informed Retry
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.2\. 知情重试
- en: 'A more informed approach is to append the LLM’s output to the history, add
    another user message indicating that the output was unsuccessful, and try again.
    This should be supplemented with specific error messages or additional directions (Kamoi
    et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib40); Tyen et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib82)).
    In the Figure [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\.
    Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems")
    example, an informed retry might look like sending the following list of messages:
    [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\. Error Handling
    ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems").UI, [3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").AO, [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure
    3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems").TR, and ”Attempting the above code yielded the provided error. Please
    provide an updated output that achieves the initial instruction.”.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更为知情的方法是将LLM的输出附加到历史记录中，添加另一条用户消息，表明该输出未成功，并再次尝试。这应当辅以具体的错误信息或额外的指令（Kamoi
    等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib40); Tyen 等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib82)）。在图
    [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\. Error Handling
    ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems") 示例中，知情重试可能如下所示：发送以下消息列表：[3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").UI, [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure
    3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems").AO, [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\.
    Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems").TR，以及“尝试上述代码时出现了提供的错误。请提供更新后的输出，以实现最初的指令。”。
- en: 8.2.3\. External Retry
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.3\. 外部重试
- en: Rather than asking for an informed retry from the same context, we can pull
    out pieces of the history and provide it to an LLM in a separate context to either
    fix the previous output or generate a new one. This will likely require significant
    context from the original call but can be supplemented and differentiated by using
    a different role, different instructions, and error information. Often, shifting
    roles from, for example, a software engineer to a code reviewer can provide the
    impetus the LLM needs to fix or generate the correct output. While it has been
    shown that the explanations from external LLM-based error systems are frequently
    unreliable and sensitive to prompt changes (Kamoi et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib40)),
    having access to task-specific roles, detailed error information (e.g., the error
    raised by a piece of generated Python code), and background context helps mitigate
    those issues(Tyen et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib82)).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与其在同一上下文中请求知情重试，不如将历史记录中的部分内容提取出来，并以单独的上下文提供给LLM，以修正先前的输出或生成新的输出。这通常需要来自原始调用的显著上下文，但可以通过使用不同的角色、不同的指令和错误信息来补充和区分。通常，将角色从软件工程师转变为代码审阅员可以为LLM提供修复或生成正确输出的动力。尽管已有研究表明，外部基于LLM的错误系统的解释通常不可靠，并且对提示变化敏感（Kamoi等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib40)），但访问特定任务的角色、详细的错误信息（例如由生成的Python代码引发的错误）以及背景上下文有助于减轻这些问题（Tyen等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib82)）。
- en: 'In the Figure [3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\.
    Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems")
    example, an external retry might look like sending the following list of messages:
    ”You are an expert debugger. You have access to {tool information}.” and ”When
    attempting to fulfill the request, ’{[3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").UI}’, a helper tried to run the code ‘{[3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").AO}‘, which yielded ‘{[3](https://arxiv.org/html/2412.04093v1#S8.F3
    "Figure 3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations
    for Agentic LLM Systems").TR}‘. Please provide an updated output that achieves
    the initial instruction.”.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在图示[3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure 3 ‣ 8.2\. Error Handling
    ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems")的示例中，外部重试可能表现为发送以下消息列表：“你是一个专家级调试员，你可以访问{tool
    information}。”和“在尝试执行请求时，‘{[3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure
    3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems").UI}’，助手尝试运行代码‘{[3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure
    3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems").AO}’，结果为‘{[3](https://arxiv.org/html/2412.04093v1#S8.F3 "Figure
    3 ‣ 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems").TR}’。请提供一个更新的输出，以实现最初的指令。”。
- en: It should be noted that LLMs struggle to locate errors (Kamoi et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib40);
    Tyen et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib82)) but demonstrate
    strong error correction capabilities if provided sufficient context, specifically
    error location (Tyen et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib82)).
    As such, when employing [Informed Retry](https://arxiv.org/html/2412.04093v1#S8.SS2.SSS2
    "In 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems") or [External Retry](https://arxiv.org/html/2412.04093v1#S8.SS2.SSS3
    "In 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems"), care should be taken to include error information that pinpoints
    the source, such as diagnostic error messages and tracebacks from APIs and runtime
    environments.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意，LLM在定位错误方面存在困难（Kamoi等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib40)；Tyen等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib82)），但如果提供足够的上下文，特别是错误位置，它们表现出强大的错误修正能力（Tyen等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib82)）。因此，在使用[知情重试](https://arxiv.org/html/2412.04093v1#S8.SS2.SSS2
    "In 8.2\. Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems")或[外部重试](https://arxiv.org/html/2412.04093v1#S8.SS2.SSS3 "In 8.2\.
    Error Handling ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM Systems")时，应注意包括能准确定位错误来源的错误信息，例如来自API和运行时环境的诊断错误信息和堆栈跟踪。
- en: 8.3\. Stopping
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3\. 停止
- en: As the control flow of the agentic LLM system is controlled by an LLM, a clear
    stopping method needs to be defined. This will likely take the form of a predetermined
    stop token or phrase inserted into the system prompt, such as ”TERMINATE” (Wu
    et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib96)). It should be
    a token or phrase that is easily parsable and not otherwise likely, to avoid accidental
    stopping.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 由于智能体LLM系统的控制流程由LLM控制，因此需要定义一个明确的停止方法。这通常表现为插入系统提示中的预定停止标记或短语，例如“TERMINATE”（Wu
    等, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib96)）。它应当是一个易于解析的标记或短语，并且不会轻易出现，以避免意外停止。
- en: 8.4\. Multiple Personas
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4\. 多重角色
- en: Often, the role that an LLM is assigned has a significant impact on its performance
    on a given task. This has been observed in LLM literature generally, becoming
    a key ingredient of effective prompting (Karmaker Santu and Feng, [2023](https://arxiv.org/html/2412.04093v1#bib.bib42);
    Kong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib44)), and in recent
    LLM multi-agent research, emerging as a necessary component for agent multiplicity
    in many such architectures (Hong et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib36);
    Wu et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib96); Li et al.,
    [2023b](https://arxiv.org/html/2412.04093v1#bib.bib51); Guo et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib33);
    Wang et al., [2024d](https://arxiv.org/html/2412.04093v1#bib.bib93); Park et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib63)). For example, while the
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe1 role is good for answering
    most of the user’s queries, the Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe2
    role may be better at answering Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I4
    because it requires specialist culinary knowledge.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，分配给大规模语言模型（LLM）的角色对其在特定任务中的表现有显著影响。这在LLM文献中普遍被观察到，已成为有效提示的重要组成部分（Karmaker
    Santu 和 Feng, [2023](https://arxiv.org/html/2412.04093v1#bib.bib42)；Kong 等, [2024](https://arxiv.org/html/2412.04093v1#bib.bib44)），并且在近期的LLM多智能体研究中，已成为许多此类架构中智能体多样性的必要组成部分（Hong
    等, [2024](https://arxiv.org/html/2412.04093v1#bib.bib36)；Wu 等, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib96)；Li
    等, [2023b](https://arxiv.org/html/2412.04093v1#bib.bib51)；Guo 等, [2024](https://arxiv.org/html/2412.04093v1#bib.bib33)；Wang
    等, [2024d](https://arxiv.org/html/2412.04093v1#bib.bib93)；Park 等, [2023](https://arxiv.org/html/2412.04093v1#bib.bib63)）。例如，虽然Figure
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe1角色适合回答大部分用户查询，但Figure
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe2角色可能更适合回答Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I4，因为该任务需要专业的烹饪知识。
- en: 'Because there are likely to be many distinct tasks that form part of an agentic
    LLM system, there is usually room for multiple roles to be used. An overview of
    approaches to defining personas for LLMs, or ”profiling” them, is detailed in
     (Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)), categorizing
    them as handcrafted (e.g., (Qian et al., [2024a](https://arxiv.org/html/2412.04093v1#bib.bib65);
    Park et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib63))), LLM-generated
    (e.g, (Wang et al., [2024d](https://arxiv.org/html/2412.04093v1#bib.bib93); Xu
    et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib100))), or dataset-aligned
    (i.e., derived from a pertinent dataset). The roles should be informed by the
    task that the call is handling. This is dependent on the overall context of the
    agentic LLM system but can largely be addressed in the following ways:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 由于智能体LLM系统中可能包含许多不同的任务，因此通常需要使用多个角色。一种定义LLM角色或“角色建模”的方法概述详细列出（Wang 等, [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)），将其分类为手工制作（例如，(Qian
    等, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib65)；Park 等, [2023](https://arxiv.org/html/2412.04093v1#bib.bib63)）），LLM生成（例如，(Wang
    等, [2024d](https://arxiv.org/html/2412.04093v1#bib.bib93)；Xu 等, [2023](https://arxiv.org/html/2412.04093v1#bib.bib100)））或数据集对齐（即，来源于相关数据集）。这些角色应根据所处理任务进行定义。这取决于智能体LLM系统的整体上下文，但通常可以通过以下方式解决：
- en: •
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If the tasks are well-defined, handcraft specialist roles for each task (e.g.,
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe1 and [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe2).
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果任务已明确规定，为每个任务手工制作专业角色（例如，图 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure
    2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe1
    和 [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe2)）。
- en: •
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: If the tasks are not well-defined but generally correspond to a single topic,
    use the most specific handcrafted role for that topic (e.g., the catch-all Figure
    [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe1).
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果任务未明确规定，但通常与单一主题相关，使用该主题的最具体手工制作角色（例如，通用图 [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe1）。
- en: •
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'If the tasks are truly undefined to start (e.g., an assistant that helps with
    anything) or the topic is very broad:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果任务在开始时确实未定义（例如，帮助处理任何事务的助手）或主题非常广泛：
- en: –
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: Define several distinct roles to which the LLM agent can route subsequent calls
    as it sees fit (Si et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib76)).
    Once the agent is in use, a more informed set of personas can be defined according
    to the most frequently ones. This may also be thought of as the dataset alignment
    approach (Wang et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)),
    where the dataset is constructed in the environment under an interim set of personas.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定义多个不同的角色，LLM 代理可以根据需要将后续调用路由到这些角色（Si 等， [2023](https://arxiv.org/html/2412.04093v1#bib.bib76)）。一旦代理开始使用，可以根据最常用的角色定义更为细化的人物设定。这也可以看作是数据集对齐方法（Wang
    等， [2024c](https://arxiv.org/html/2412.04093v1#bib.bib88)），在该方法中，数据集是在特定环境下根据临时设定的人物设定构建的。
- en: –
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: Leverage an LLM to create the role that it deems would be best able to respond
    to the prompt (Wang et al., [2024d](https://arxiv.org/html/2412.04093v1#bib.bib93);
    Xu et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib100)). This is more
    expensive as generating the role requires LLM usage but is certainly more robust
    to unforeseen scenarios. This approach may be used in conjunction with the above
    point (e.g., if no suitable predefined role is found, create one).
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 利用 LLM 创建它认为最适合响应提示的角色（Wang 等， [2024d](https://arxiv.org/html/2412.04093v1#bib.bib93)；Xu
    等， [2023](https://arxiv.org/html/2412.04093v1#bib.bib100)）。这种方法更为昂贵，因为生成角色需要使用
    LLM，但无疑对于应对不可预见的情况更为稳健。此方法可以与上述方法结合使用（例如，如果没有找到合适的预定义角色，则创建一个）。
- en: 8.5\. Managing Relevant Context
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5\. 管理相关上下文
- en: 'Managing the context that is sent to an LLM is an effective method of increasing
    the efficiency (speed and cost) and performance of an LLM system, as inference
    time is dependent on the number of input tokens (Vaswani et al., [2017](https://arxiv.org/html/2412.04093v1#bib.bib86);
    Pope et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib64)) and LLMs perform
    worse in long-context scenarios, particularly for complex tasks (Li et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib49);
    Liu et al., [2024b](https://arxiv.org/html/2412.04093v1#bib.bib54)). Additionally,
    careful context management is a necessity given that LLMs have limited context
    windows⁹⁹9E.g., Claude 3: 200k (Ant, [2024b](https://arxiv.org/html/2412.04093v1#bib.bib16));
    Gemini 1.5 Pro: 2M+ (Gem, [2024a](https://arxiv.org/html/2412.04093v1#bib.bib9));
    GPT-4o: 128k (OAI, [[n.d.]a](https://arxiv.org/html/2412.04093v1#bib.bib5)). Even
    for ”long-”context LLMs (¿100k token limit), many tasks quickly become unwieldy
    if not properly managed (e.g., working with HTML, where single webpages can be
    hundreds of thousands of tokens). This is a key consideration to make during [task
    decomposition](https://arxiv.org/html/2412.04093v1#S5.SS2 "5.2\. Task Decomposition
    ‣ 5\. Planning ‣ Practical Considerations for Agentic LLM Systems"); the more
    specific the task, the more extraneous context (e.g., prior messages) can be trimmed (Qian
    et al., [2024b](https://arxiv.org/html/2412.04093v1#bib.bib66)). As such, the
    context that a specific LLM call receives should be tailored to the task as much
    as possible. Even if an LLM call requires past messages, it is often possible
    to strip out certain pieces of context or summarize them, leaving the parts the
    subsequent call relies on intact and maintaining the overall meaning. Significant
    adjustments can be made to the context between calls to decrease the overall token
    count and remove extraneous context, thus reducing LLM confusion and increasing
    performance for the LLM call (Qian et al., [2024b](https://arxiv.org/html/2412.04093v1#bib.bib66)).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 管理发送到LLM的上下文是提高LLM系统效率（速度和成本）和性能的有效方法，因为推理时间取决于输入标记的数量（Vaswani等， [2017](https://arxiv.org/html/2412.04093v1#bib.bib86)；Pope等，
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib64)），而且LLM在长上下文场景下表现较差，尤其是在复杂任务中（Li等，
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib49)；Liu等， [2024b](https://arxiv.org/html/2412.04093v1#bib.bib54)）。此外，由于LLM具有有限的上下文窗口⁹⁹9例如，Claude
    3：200k（Ant， [2024b](https://arxiv.org/html/2412.04093v1#bib.bib16)）；Gemini 1.5
    Pro：2M+（Gem， [2024a](https://arxiv.org/html/2412.04093v1#bib.bib9)）；GPT-4o：128k（OAI，
    [[n.d.]a](https://arxiv.org/html/2412.04093v1#bib.bib5)），精心的上下文管理变得尤为必要。即便是“长”上下文LLM（¿100k
    标记限制），若管理不当，许多任务也会迅速变得难以应对（例如，处理HTML时，单个网页可能包含数十万个标记）。这是在进行[任务分解](https://arxiv.org/html/2412.04093v1#S5.SS2
    "5.2\. Task Decomposition ‣ 5\. Planning ‣ Practical Considerations for Agentic
    LLM Systems")时必须考虑的关键事项；任务越具体，越多的额外上下文（例如，先前的消息）可以被裁剪掉（Qian等， [2024b](https://arxiv.org/html/2412.04093v1#bib.bib66)）。因此，特定LLM调用接收到的上下文应尽可能根据任务进行量身定制。即使LLM调用需要过去的消息，通常也可以去除某些上下文部分或对其进行总结，只保留后续调用依赖的部分，且保持整体意义不变。可以在调用之间对上下文进行显著调整，以减少总体标记数并去除多余的上下文，从而减少LLM的混淆并提高LLM调用的性能（Qian等，
    [2024b](https://arxiv.org/html/2412.04093v1#bib.bib66)）。
- en: 9\. Additional Considerations
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 额外考虑事项
- en: 9.1\. Model Size
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1\. 模型大小
- en: 'The size of the model to use is typically driven by three concerns: cost, speed,
    and performance. Usually, the bigger the model, the higher the cost, the lower
    the speed, and the better the performance (although this is not a hard-and-fast
    rule). It can be tempting to build an agentic LLM system around the weakest model
    that will adequately do the job so that all three conditions are optimized from
    the start. However, attempting to build out a functional system from a smaller
    model first will likely be more time consuming and expensive than starting at
    the strongest model possible and downgrading the models used for specific calls
    once the LLM agent has demonstrated competence in the environment. Due to the
    influence one call can have on subsequent ones, it is infeasible to understand
    what is possible for a given use case if not all the pieces are working optimally.
    By starting with stronger models, there will be a gold-standard baseline to compare
    against so the performance impact of downgrading a model for a specific call can
    be measured^(10)^(10)10See (Benram, [2024](https://arxiv.org/html/2412.04093v1#bib.bib22);
    ljunkai, [2023](https://arxiv.org/html/2412.04093v1#bib.bib57)) for discussions
    on these points from an industry perspective.. It is recommended that the correct
    model is selected on a per-task basis and evaluated both individually and in the
    context of the entire agentic LLM system.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，选择使用的模型大小由三个因素决定：成本、速度和性能。通常情况下，模型越大，成本越高，速度越慢，性能越好（尽管这不是一个硬性规定）。围绕最弱的模型构建一个具有代理功能的LLM系统，以便从一开始就优化所有三个条件，可能是很有诱惑力的。然而，试图首先从较小的模型开始构建一个可行的系统，可能比从最强的模型开始，等LLM代理在环境中展现出能力后，再针对特定调用降级使用的模型更加耗时且昂贵。由于一次调用可能对后续调用产生影响，如果不是所有的组件都在最佳状态下运行，那么要理解给定用例中可能的情况是不现实的。通过从更强的模型开始，将有一个黄金标准的基准可供比较，这样就能衡量降级模型在特定调用中的性能影响^(10)^(10)10参见（Benram，[2024](https://arxiv.org/html/2412.04093v1#bib.bib22)；ljunkai，[2023](https://arxiv.org/html/2412.04093v1#bib.bib57)）从行业角度讨论这些观点..
    建议根据每个任务选择合适的模型，并在单独评估和作为整个代理LLM系统的一部分的背景下进行评估。
- en: 9.2\. Evaluation
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2\. 评估
- en: Evaluating an agentic LLM system can be challenging due to the potential for
    long sequences, non-determinism in LLMs, interactions with external entities,
    and tasks that may not have obviously correct solutions. Nonetheless, it is essential
    to have an approach to evaluation defined before deployment to (1) have a baseline
    to compare against and (2) measure performance changes over time and in response
    to changes.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 评估一个代理LLM系统可能是具有挑战性的，因为可能涉及长序列、LLM中的非确定性、与外部实体的互动以及可能没有明显正确解答的任务。尽管如此，在部署之前，定义一种评估方法仍然至关重要，以便（1）有一个基准可以进行对比，并且（2）能够衡量随着时间推移和响应变化而发生的性能变化。
- en: When creating a dataset for evaluating an LLM agent, the most important consideration
    is that it accurately resembles the environment in which is will be deployed.
    There are many LLM agent benchmarks available targeting specific domains (Deng
    et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib27); Yao et al., [2022](https://arxiv.org/html/2412.04093v1#bib.bib102);
    Liu et al., [2024c](https://arxiv.org/html/2412.04093v1#bib.bib55); Zhang et al.,
    [2024b](https://arxiv.org/html/2412.04093v1#bib.bib104)) as well as general purpose
    application (Srivastava et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib79);
    Wu et al., [2024b](https://arxiv.org/html/2412.04093v1#bib.bib97); Mialon et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib59)), but many agentic LLM systems
    applied to a specific task will be too niche to benefit from a broader benchmark.
    However, insomuch as an established benchmark fits the application of the LLM
    system, it can be a strong starting point for evaluation and refinement. Whether
    an existing benchmark is used or not, it is advisable to collect informative agent
    interactions (e.g., long sequences, short sequences, incorrect outputs, correct
    outputs, etc.) and related metadata (e.g., hyperparameters) in the deployment
    environment. Doing so will allow the creation of a dataset, comprised of reproducible
    input and output pairs, that is derived from the environment. Even a dataset with
    a few samples will provide a baseline to compare against to ensure prompt engineering
    addresses failed executions, identify the effects of model and prompt changes,
    and avoid regression in the system^(11)^(11)11See (Lan, [2024](https://arxiv.org/html/2412.04093v1#bib.bib8))
    for an industry approach to evaluating deployed LLM systems..
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在为评估LLM代理创建数据集时，最重要的考虑因素是它能够准确地模拟将要部署的环境。许多针对特定领域的LLM代理基准测试已经可用（Deng等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib27)；Yao等人，[2022](https://arxiv.org/html/2412.04093v1#bib.bib102)；Liu等人，[2024c](https://arxiv.org/html/2412.04093v1#bib.bib55)；Zhang等人，[2024b](https://arxiv.org/html/2412.04093v1#bib.bib104)），以及通用应用基准（Srivastava等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib79)；Wu等人，[2024b](https://arxiv.org/html/2412.04093v1#bib.bib97)；Mialon等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib59)），但是许多应用于特定任务的代理LLM系统将过于专业，无法从更广泛的基准中受益。然而，只要一个已建立的基准适用于LLM系统的应用，它可以成为评估和改进的有力起点。无论是否使用现有的基准，都建议在部署环境中收集有用的代理交互数据（例如，长序列、短序列、错误输出、正确输出等）及相关元数据（例如，超参数）。这样做将能够创建一个由可复现的输入和输出对组成的数据集，这些数据集来源于该环境。即使数据集样本较少，它也能提供一个基准，用于进行对比，确保提示工程能够解决失败的执行，识别模型和提示变更的影响，并避免系统回归^(11)^(11)11请参见（Lan，[2024](https://arxiv.org/html/2412.04093v1#bib.bib8)）了解评估已部署LLM系统的行业方法..
- en: While traditional metrics (e.g., precision, recall, etc.) are useful to track,
    metrics specific to the agent can help reveal changes in the system that higher-level
    metrics fail to reflect (Chang et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib25);
    Kapoor et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib41)). For example,
    an LLM agent that arrives at the same answer when presented with two different
    prompts is superficially consistent but a difference in the number of intermediate
    steps to reach that conclusion may indicate that the system is overly sensitive
    to prompt changes. Building from (Liu et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib53);
    Kapoor et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib41); Mehta et al.,
    [2024](https://arxiv.org/html/2412.04093v1#bib.bib58)) that suggest types of alternative
    evaluation, we provide sample metrics below to use as a starting place, although
    useful metrics should be chosen in accordance with the design of the LLM agent
    and the environment in which it is implemented^(12)^(12)12Note that the following
    are focused primarily on evaluating agentic LLM systems but that external components
    should also be evaluated, such as the RAG system (e.g., the quality of retrievals
    and the fidelity of embedded documents) (Salemi and Zamani, [2024](https://arxiv.org/html/2412.04093v1#bib.bib70);
    Es et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib31)) and tools (e.g.,
    reliability and consistency of their output)..
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然传统指标（例如精准度、召回率等）在追踪过程中非常有用，但针对代理的特定指标可以帮助揭示高层次指标未能反映的系统变化（Chang等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib25)；Kapoor等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib41)）。例如，当给定两个不同的提示时，LLM代理如果得出相同的答案，表面上看是保持一致的，但达到这个结论所需的中间步骤数量的差异可能表明该系统对提示变化过于敏感。从(Liu等人，[2023](https://arxiv.org/html/2412.04093v1#bib.bib53)；Kapoor等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib41)；Mehta等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib58))的研究中可以找到替代评估方法的建议，我们在下面提供了一些示例指标作为起点，尽管有用的指标应根据LLM代理的设计以及其所处的环境来选择^(12)^(12)12请注意，以下指标主要侧重于评估代理型LLM系统，但外部组件也应进行评估，如RAG系统（例如，检索质量和嵌入文档的忠实度）（Salemi和Zamani，[2024](https://arxiv.org/html/2412.04093v1#bib.bib70)；Es等人，[2024](https://arxiv.org/html/2412.04093v1#bib.bib31)）和工具（例如，它们输出的可靠性和一致性）。
- en: 9.2.1\. Holistic
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.2.1\. 整体评估
- en: No matter how well an agentic LLM system might do along the way or what emergent
    capabilities it might demonstrate, the final output will determine whether the
    system is accomplishing its task or not. It is impossible to tell how a composition
    of LLM calls will perform without running them end-to-end; thus, evaluating an
    LLM agent should primarily rely on holistic metrics to determine if it is performing
    as expected.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 无论代理型LLM系统在过程中表现如何，或展示了什么新兴能力，最终输出将决定系统是否完成了任务。无法在不进行端到端运行的情况下预测LLM调用的组合会如何表现；因此，评估LLM代理主要应依赖于整体指标，以确定其是否按预期执行。
- en: Sample Metrics.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 示例指标。
- en: •
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Across X distinct prompts, how many correct answers does the agent produce?
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在X个不同的提示下，代理产生了多少个正确答案？
- en: •
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For input X across N trials, how many distinct answers does the agent produce?
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于输入X在N次试验中的表现，代理产生了多少个不同的答案？
- en: •
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For input X across N trials, what is the average number of steps executed by
    the agent?
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于输入X在N次试验中的表现，代理执行的步骤平均数量是多少？
- en: •
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For input X across N trials, what is the average number of tools used by the
    agent?
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于输入X在N次试验中的表现，代理使用工具的平均数量是多少？
- en: •
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For input X (that requires LLM planning) across N trials, what is the average
    number of steps in each plan?
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于需要LLM规划的输入X在N次试验中的表现，每个规划的平均步骤数是多少？
- en: •
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For input X across N trials, what is the average cost/time?
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于输入X在N次试验中的表现，平均成本/时间是多少？
- en: 9.2.2\. Piecemeal
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.2.2\. 逐步评估
- en: Measuring the performance of a single or a subset of LLM calls that completes
    a definable task is a viable method of diagnosing problems in or making changes
    to the system. However, due to the influence a single LLM call can have downstream
    in an LLM agent, isolated piecemeal evaluation of an agentic LLM system should
    never be considered a substitute for [Holistic](https://arxiv.org/html/2412.04093v1#S9.SS2.SSS1
    "In 9.2\. Evaluation ‣ 9\. Additional Considerations ‣ Practical Considerations
    for Agentic LLM Systems") measures.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 测量单个或 LLM 调用子集的性能，以完成可定义的任务，是诊断系统问题或进行更改的一种可行方法。然而，由于单个 LLM 调用可能对 LLM 代理产生下游影响，因此不应将对代理式
    LLM 系统的孤立碎片化评估视为[整体评估](https://arxiv.org/html/2412.04093v1#S9.SS2.SSS1 "在 9.2\.
    评估 ‣ 9\. 额外考虑 ‣ 代理式 LLM 系统的实践考虑")的替代。
- en: Sample Metrics.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 示例指标。
- en: •
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For call X with N trials, how many distinct answers are produced?
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 N 次试验中的调用 X，产生了多少个不同的答案？
- en: •
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For N synonymous versions of input A to call X, how many distinct top-K documents
    are provided by RAG from each embedded version of A?
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 N 个同义版本的输入 A 调用 X，RAG 从 A 的每个嵌入版本中提供了多少个不同的 top-K 文档？
- en: •
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For call X with tool access across N trials, how many distinct tools are used?
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 N 次试验中使用工具访问调用 X，使用了多少种不同的工具？
- en: •
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: For call X across N trials, what is the average cost/time?
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 N 次试验中调用 X，平均成本/时间是多少？
- en: 9.3\. Integration with Traditional Engineering
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3\. 与传统工程的集成
- en: Because LLMs are inherently stochastic, it is often easier to offload as much
    of the agent’s responsibility onto traditional engineering as possible. This allows
    outsourcing parts of the system that require determinism to methods that can be
    deterministic. By crafting an LLM agent according to software engineering best
    practices, we can ensure that key components that are necessary for a given task
    are always completed or included, rather than relying on the agent to make a request
    or execute an action. This can take the form of automatically managing context
    between calls, [output processing](https://arxiv.org/html/2412.04093v1#S8.SS1
    "8.1\. Output Processing ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems"), combining tools into toolsets (e.g., putting Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T2
    and [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").T3 behind a ”delivery” interface),
    incorporating information from long-term memory permanently into the prompts (e.g.,
    Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").E1), setting callbacks on
    certain transitions and calls (e.g., to generate a summary of the most recent
    conversation to use as context when transitioning from Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe1
    to [2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure 2 ‣ 3\. Applied Scenario
    ‣ Practical Considerations for Agentic LLM Systems").Pe2), and adding an evaluation
    after each step of a plan (see [Plan Adherence](https://arxiv.org/html/2412.04093v1#S5.SS3
    "In 5\. Planning ‣ Practical Considerations for Agentic LLM Systems")). (The last
    two can be thought of as implicit tool usage; see Section [7.1](https://arxiv.org/html/2412.04093v1#S7.SS1
    "7.1\. Using Tools ‣ 7\. Tools ‣ Practical Considerations for Agentic LLM Systems")).
    However, care should be taken not to limit the autonomy of the agent in doing
    so. One way to return autonomy to the agent while still leveraging the benefits
    of traditional engineering is to allow the agent to short-circuit.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大型语言模型（LLMs）本质上是随机的，通常将尽可能多的代理责任转移到传统工程中是更为便捷的做法。这样可以将需要确定性的系统部分外包给可以实现确定性的方法。通过按照软件工程最佳实践设计LLM代理，我们可以确保完成或包括执行特定任务所需的关键组件，而不是依赖代理进行请求或执行操作。这可以表现为自动管理调用之间的上下文，[输出处理](https://arxiv.org/html/2412.04093v1#S8.SS1
    "8.1\. Output Processing ‣ 8\. Control Flow ‣ Practical Considerations for Agentic
    LLM Systems")，将工具组合成工具集（例如，将图[2](https://arxiv.org/html/2412.04093v1#S3.F2 "Figure
    2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T2和[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").T3放置在一个“交付”接口后），将来自长期记忆的信息永久融入提示中（例如，图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").E1），在某些过渡和调用上设置回调（例如，在从图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe1到[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").Pe2）时生成最近一次对话的摘要以作为过渡时的上下文），并在每个计划步骤之后添加评估（参见[计划遵守](https://arxiv.org/html/2412.04093v1#S5.SS3
    "In 5\. Planning ‣ Practical Considerations for Agentic LLM Systems")）。（最后两者可以视为隐式工具使用；参见第[7.1](https://arxiv.org/html/2412.04093v1#S7.SS1
    "7.1\. Using Tools ‣ 7\. Tools ‣ Practical Considerations for Agentic LLM Systems")节。）然而，需注意的是，这样做时不能限制代理的自主性。一种在仍然利用传统工程优势的同时恢复代理自主性的方法是允许代理进行短路化。
- en: 9.3.1\. Short-Circuiting
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.3.1\. 短路化
- en: 'Short-circuiting (from the world of software engineering: the idea of evaluating
    an expression only so far as to guarantee a single answer) is an integral technique
    for agentic LLM systems. This can be as simple as including [stopping](https://arxiv.org/html/2412.04093v1#S8.SS3
    "8.3\. Stopping ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM
    Systems") criteria into the LLM agent’s instructions (see Section [8.3](https://arxiv.org/html/2412.04093v1#S8.SS3
    "8.3\. Stopping ‣ 8\. Control Flow ‣ Practical Considerations for Agentic LLM
    Systems") for examples) or allowing the LLM agent to produce a final output in
    a single turn. If an agentic LLM system does not short-circuit when it obviously
    should, the system may have an overreliance on external engineering (i.e., the
    flow (or parts of the flow) of the agent being hard-coded)^(13)^(13)13A recent
    example of this is OpenAI’s GPT-o1 (OpenAI, [2024](https://arxiv.org/html/2412.04093v1#bib.bib61)).
    The initial implementation has no short-circuiting, meaning even simple queries
    that a much weaker model can handle or that require no significant output still
    incur a full traversal of the agentic LLM system. For example, asking GPT-o1 to
    “Do nothing” will still pass through the planning, thinking, and alignment stages
    of the system..'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 短路（来自软件工程领域的概念：仅评估一个表达式到足以保证得到单一答案的程度）是代理型LLM系统中的一项重要技术。这可以像将[停止](https://arxiv.org/html/2412.04093v1#S8.SS3
    "8.3\. 停止 ‣ 8\. 控制流 ‣ 代理型LLM系统的实际考虑")标准添加到LLM代理的指令中（参见第[8.3](https://arxiv.org/html/2412.04093v1#S8.SS3
    "8.3\. 停止 ‣ 8\. 控制流 ‣ 代理型LLM系统的实际考虑")节的示例），或允许LLM代理在一次操作中产生最终输出。如果一个代理型LLM系统在显然应该短路时没有进行短路，那么该系统可能过于依赖外部工程（即代理的流程（或部分流程）是硬编码的）^(13)^(13)13
    最近的一个例子是OpenAI的GPT-o1（OpenAI，[2024](https://arxiv.org/html/2412.04093v1#bib.bib61)）。最初的实现没有短路，这意味着即使是一个较弱的模型可以处理的简单查询，或者不需要显著输出的查询，仍然会进行整个代理型LLM系统的完整遍历。例如，询问GPT-o1“什么都不做”仍然会经过规划、思考和对齐阶段。
- en: As an example, the query presented in Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").I3
    demonstrates an instance when an LLM agent may want to short-circuit. The query
    poses a simple question-answering scenario that most current models could satisfactorily
    respond to. Allowing the agent the autonomy to determine what step to take next
    (as opposed to, for example, implicitly calling Figure [2](https://arxiv.org/html/2412.04093v1#S3.F2
    "Figure 2 ‣ 3\. Applied Scenario ‣ Practical Considerations for Agentic LLM Systems").P1
    for every input) would permit it to simply provide an answer, thus short-circuiting
    any other components.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，图[2](https://arxiv.org/html/2412.04093v1#S3.F2 "图2 ‣ 3\. 应用场景 ‣ 代理型LLM系统的实际考虑")中的查询I3展示了一个LLM代理可能希望进行短路的实例。该查询提出了一个简单的问答场景，目前的大多数模型都能令人满意地响应。允许代理自主决定下一步应该采取什么行动（与例如每次输入都隐式调用图[2](https://arxiv.org/html/2412.04093v1#S3.F2
    "图2 ‣ 3\. 应用场景 ‣ 代理型LLM系统的实际考虑")中的P1不同）将使它能够简单地提供答案，从而短路其他组件。
- en: 10\. Limitations
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 限制
- en: Although we present some practical methods for the evaluation of deployed systems,
    we do not explore human-in-the-loop evaluation as human-computer interaction represents
    a rich field of study that exceeds the scope of this work.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们展示了一些部署系统评估的实际方法，但我们并未探讨人类环节评估，因为人机交互是一个丰富的研究领域，超出了本工作的范围。
- en: An important follow-up to evaluation is how to compare and respond to changes
    in a deployed agentic LLM system, such as prompt, model, and environment changes.
    These considerations remain largely underexplored in current literature and represent
    some of the key challenges to deploying real-world LLM agents. We do not discuss
    these considerations as agent maintenance does not fall into the scope of this
    work but suggest that they are prominent directions for future work.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 评估的一个重要后续是如何比较和响应部署的代理型LLM系统的变化，例如提示、模型和环境变化。这些考虑在当前文献中仍然没有得到充分探讨，并且代表了部署现实世界LLM代理的一些关键挑战。我们不讨论这些考虑，因为代理维护不属于本工作的范围，但建议它们是未来研究的显著方向。
- en: We explore one aspect of cost for agentic LLM systems, model size, but leave
    other considerations (such as whether to use an out-of-the-box model or to finetune
    one on a specific task (Bucher and Martini, [2024](https://arxiv.org/html/2412.04093v1#bib.bib24);
    Lehman et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib46)), to leverage
    increasingly strong open-source models (Dubey et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib28);
    Jiang et al., [2023](https://arxiv.org/html/2412.04093v1#bib.bib38); Bai et al.,
    [2023](https://arxiv.org/html/2412.04093v1#bib.bib19)) or to rely on aligned commercial
    models (OpenAI et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib62);
    Team et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib81); cla, [2024](https://arxiv.org/html/2412.04093v1#bib.bib12)),
    and, similarly, to self-host or to use a 3rd party provider) for future work as
    cost and feasibility of proposed agent architectures warrant a review on their
    own. See (Kapoor et al., [2024](https://arxiv.org/html/2412.04093v1#bib.bib41))
    for a discussion on the need for cost-informed LLM agent research.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了代理型LLM系统成本的一个方面——模型大小，但将其他考虑因素（例如是使用现成的模型，还是在特定任务上对其进行微调（Bucher和Martini，[2024](https://arxiv.org/html/2412.04093v1#bib.bib24)；Lehman等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib46)），利用日益强大的开源模型（Dubey等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib28)；Jiang等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib38)；Bai等，[2023](https://arxiv.org/html/2412.04093v1#bib.bib19)）或依赖于对齐的商业模型（OpenAI等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib62)；Team等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib81)；cla，[2024](https://arxiv.org/html/2412.04093v1#bib.bib12)），以及是否自托管或使用第三方提供商等）留待未来的研究，因为代理架构的成本和可行性要求对此进行单独的评估。有关基于成本的LLM代理研究需求的讨论，请参见(Kapoor等，[2024](https://arxiv.org/html/2412.04093v1#bib.bib41))。
- en: While we approach the agent’s underlying LLM from a black-box perspective for
    simplicity and relevance to many industry applications, approaching it as whitebox
    opens up additional complexities and opportunities. We deem that considering model
    specifics exceeds the scope of this review but recognize the value of future work
    highlighting practical considerations for the real-world deployment of whitebox
    LLM agents.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化和与许多行业应用的相关性，我们从黑盒的角度接触代理的底层LLM，但将其作为白盒来处理则带来了额外的复杂性和机会。我们认为，考虑模型的具体细节超出了本次综述的范围，但也认识到未来的研究能够突出针对白盒LLM代理在现实世界中部署的实际考虑因素的价值。
- en: 11\. Conclusion
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11\. 结论
- en: In this review, we present relevant research into LLM agents and derive actionable
    insights from it that can be utilized when implementing and deploying agentic
    LLM systems in the real world. We ascribe relevant research and insights to the
    four main components of LLM agents from application-focused literature—[Planning](https://arxiv.org/html/2412.04093v1#S5
    "In Practical Considerations for Agentic LLM Systems"), [Memory](https://arxiv.org/html/2412.04093v1#S6
    "In Practical Considerations for Agentic LLM Systems"), [Tools](https://arxiv.org/html/2412.04093v1#S7
    "In Practical Considerations for Agentic LLM Systems"), and [Control Flow](https://arxiv.org/html/2412.04093v1#S8
    "In Practical Considerations for Agentic LLM Systems")—to provide a review that
    is mutually accessible to both industry and academia. Namely, for [Planning](https://arxiv.org/html/2412.04093v1#S5
    "In Practical Considerations for Agentic LLM Systems"), we explore how poor LLM
    planning capabilities hinder current LLM agent applications and the practical
    benefits to be derived from task decomposition; for [Memory](https://arxiv.org/html/2412.04093v1#S6
    "In Practical Considerations for Agentic LLM Systems"), we explore the benefits
    of and practical considerations to make when leveraging RAG and long-term memory
    in an LLM agent; for [Tools](https://arxiv.org/html/2412.04093v1#S7 "In Practical
    Considerations for Agentic LLM Systems"), we discuss how to present and manage
    tools for an LLM agent; for [Control Flow](https://arxiv.org/html/2412.04093v1#S8
    "In Practical Considerations for Agentic LLM Systems"), we provide practical insights
    for promoting an uninterrupted LLM agent execution and managing agent internals,
    such as personas and context usage; and, lastly, suggest additional considerations,
    such as model size, evaluation, and integrating an LLM agent with traditional
    engineering.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本综述中，我们展示了与LLM代理相关的研究，并从中提取了可操作的见解，这些见解可以在实现和部署代理型LLM系统时加以利用。我们将相关研究和见解归纳为应用导向文献中LLM代理的四个主要组成部分——[规划](https://arxiv.org/html/2412.04093v1#S5
    "在代理型LLM系统的实际考虑中")、[记忆](https://arxiv.org/html/2412.04093v1#S6 "在代理型LLM系统的实际考虑中")、[工具](https://arxiv.org/html/2412.04093v1#S7
    "在代理型LLM系统的实际考虑中")和[控制流](https://arxiv.org/html/2412.04093v1#S8 "在代理型LLM系统的实际考虑中")——提供了一个对行业和学术界都可访问的综述。具体来说，关于[规划](https://arxiv.org/html/2412.04093v1#S5
    "在代理型LLM系统的实际考虑中")，我们探讨了LLM规划能力差如何阻碍当前LLM代理应用的实施，以及任务分解的实际好处；关于[记忆](https://arxiv.org/html/2412.04093v1#S6
    "在代理型LLM系统的实际考虑中")，我们探讨了在LLM代理中利用RAG和长期记忆时的好处和实际考虑；关于[工具](https://arxiv.org/html/2412.04093v1#S7
    "在代理型LLM系统的实际考虑中")，我们讨论了如何为LLM代理呈现和管理工具；关于[控制流](https://arxiv.org/html/2412.04093v1#S8
    "在代理型LLM系统的实际考虑中")，我们提供了促进LLM代理执行不中断并管理代理内部信息（如角色和上下文使用）的实用见解；最后，提出了其他考虑因素，如模型大小、评估和将LLM代理与传统工程结合的建议。
- en: Acknowledgements.
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: We would like to acknowledge Sergei Petrov and Sonny George, whose input and
    feedback were instrumental in shaping the foundations of this work.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢Sergei Petrov和Sonny George，他们的意见和反馈在塑造本工作的基础方面起到了关键作用。
- en: References
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Ope ([n.d.]) OpenAI [n.d.]. *API Reference*. OpenAI. Retrieved October 16, 2024
    from [https://platform.openai.com/docs/api-reference](https://platform.openai.com/docs/api-reference)
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ope ([n.d.]) OpenAI [n.d.]。*API参考*。OpenAI。于2024年10月16日从[https://platform.openai.com/docs/api-reference](https://platform.openai.com/docs/api-reference)获取。
- en: PCo ([n.d.]) Pinecone [n.d.]. *Building Custom Tools for LLM Agents*. Pinecone.
    Retrieved October 6, 2024 from [https://www.pinecone.io/learn/series/langchain/langchain-tools/](https://www.pinecone.io/learn/series/langchain/langchain-tools/)
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PCo ([n.d.]) Pinecone [n.d.]。*为LLM代理构建自定义工具*。Pinecone。于2024年10月6日从[https://www.pinecone.io/learn/series/langchain/langchain-tools/](https://www.pinecone.io/learn/series/langchain/langchain-tools/)获取。
- en: Ant ([n.d.]) Anthropic [n.d.]. *Increase output consistency (JSON mode)*. Anthropic.
    Retrieved October 16, 2024 from [https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency)
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ant ([n.d.]) Anthropic [n.d.]。*提高输出一致性（JSON模式）*。Anthropic。于2024年10月16日从[https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency](https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency)获取。
- en: OAI ([n.d.]a) OpenAI [n.d.]a. *Models*. OpenAI. Retrieved October 16, 2024 from
    [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OAI ([n.d.]a) OpenAI [n.d.]a。*模型*。OpenAI。于2024年10月16日从[https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)获取。
- en: OAI ([n.d.]b) OpenAI [n.d.]b. *Structured Outputs*. OpenAI. Retrieved October
    16, 2024 from [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs)
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OAI（[n.d.]b）OpenAI [n.d.]b. *结构化输出*。OpenAI. 2024年10月16日获取自 [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs)
- en: Ant (2024a) Anthropic 2024a. *API Reference*. Anthropic. Retrieved October 16,
    2024 from [https://docs.anthropic.com/en/api](https://docs.anthropic.com/en/api)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ant（2024a）Anthropic 2024a. *API参考*。Anthropic. 2024年10月16日获取自 [https://docs.anthropic.com/en/api](https://docs.anthropic.com/en/api)
- en: Lan (2024) LangChain 2024. *Evaluate your LLM application*. LangChain. Retrieved
    October 16, 2024 from [https://docs.smith.langchain.com/tutorials/Developers/evaluation](https://docs.smith.langchain.com/tutorials/Developers/evaluation)
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lan（2024）LangChain 2024. *评估您的LLM应用程序*。LangChain. 2024年10月16日获取自 [https://docs.smith.langchain.com/tutorials/Developers/evaluation](https://docs.smith.langchain.com/tutorials/Developers/evaluation)
- en: Gem (2024a) Google 2024a. *Gemini models*. Google. Retrieved October 16, 2024
    from [https://ai.google.dev/gemini-api/docs/models/gemini](https://ai.google.dev/gemini-api/docs/models/gemini)
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gem（2024a）Google 2024a. *Gemini模型*。Google. 2024年10月16日获取自 [https://ai.google.dev/gemini-api/docs/models/gemini](https://ai.google.dev/gemini-api/docs/models/gemini)
- en: Gem (2024b) Google 2024b. *Generate content with the Gemini API*. Google. Retrieved
    October 16, 2024 from [https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference)
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gem（2024b）Google 2024b. *使用Gemini API生成内容*。Google. 2024年10月16日获取自 [https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference)
- en: Gem (2024c) Google 2024c. *Generate structured output with the Gemini API*.
    Google. Retrieved October 16, 2024 from [https://ai.google.dev/gemini-api/docs/structured-output](https://ai.google.dev/gemini-api/docs/structured-output)
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gem（2024c）Google 2024c. *使用Gemini API生成结构化输出*。Google. 2024年10月16日获取自 [https://ai.google.dev/gemini-api/docs/structured-output](https://ai.google.dev/gemini-api/docs/structured-output)
- en: cla (2024) Anthropic 2024. *Introducing the next generation of Claude*. Anthropic.
    Retrieved October 8, 2024 from [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family)
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cla（2024）Anthropic 2024. *介绍Claude的下一代*。Anthropic. 2024年10月8日获取自 [https://www.anthropic.com/news/claude-3-family](https://www.anthropic.com/news/claude-3-family)
- en: PGA (2024) DAIR.AI 2024. *LLM Agents*. DAIR.AI. Retrieved October 8, 2024 from
    [https://www.promptingguide.ai/research/llm-agents](https://www.promptingguide.ai/research/llm-agents)
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PGA（2024）DAIR.AI 2024. *LLM代理*。DAIR.AI. 2024年10月8日获取自 [https://www.promptingguide.ai/research/llm-agents](https://www.promptingguide.ai/research/llm-agents)
- en: 'SAA (2024) SuperAnnotate 2024. *LLM agents: The ultimate guide*. SuperAnnotate.
    Retrieved October 7, 2024 from [https://www.superannotate.com/blog/llm-agents](https://www.superannotate.com/blog/llm-agents)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAA（2024）SuperAnnotate 2024. *LLM代理：终极指南*。SuperAnnotate. 2024年10月7日获取自 [https://www.superannotate.com/blog/llm-agents](https://www.superannotate.com/blog/llm-agents)
- en: OAI (2024) OpenAI 2024. *Memory and new controls for ChatGPT*. OpenAI. Retrieved
    October 8, 2024 from [https://openai.com/index/memory-and-new-controls-for-chatgpt/](https://openai.com/index/memory-and-new-controls-for-chatgpt/)
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OAI（2024）OpenAI 2024. *ChatGPT的记忆和新控制功能*。OpenAI. 2024年10月8日获取自 [https://openai.com/index/memory-and-new-controls-for-chatgpt/](https://openai.com/index/memory-and-new-controls-for-chatgpt/)
- en: Ant (2024b) Anthropic 2024b. *Models*. Anthropic. Retrieved October 16, 2024
    from [https://docs.anthropic.com/en/docs/about-claude/models](https://docs.anthropic.com/en/docs/about-claude/models)
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ant（2024b）Anthropic 2024b. *模型*。Anthropic. 2024年10月16日获取自 [https://docs.anthropic.com/en/docs/about-claude/models](https://docs.anthropic.com/en/docs/about-claude/models)
- en: TFA (2024) truefoundry 2024. *What are LLM Agents?* truefoundry. Retrieved October
    7, 2024 from [https://www.truefoundry.com/blog/llm-agents](https://www.truefoundry.com/blog/llm-agents)
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TFA（2024）truefoundry 2024. *什么是LLM代理？* truefoundry. 2024年10月7日获取自 [https://www.truefoundry.com/blog/llm-agents](https://www.truefoundry.com/blog/llm-agents)
- en: 'Argyle et al. (2023) Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua R.
    Gubler, Christopher Rytting, and David Wingate. 2023. Out of One, Many: Using
    Language Models to Simulate Human Samples. *Political Analysis* 31, 3 (Feb. 2023),
    337–351. [https://doi.org/10.1017/pan.2023.2](https://doi.org/10.1017/pan.2023.2)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argyle等（2023）Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua R. Gubler,
    Christopher Rytting, 和 David Wingate. 2023. 从一到多：利用语言模型模拟人类样本。*政治分析* 31, 3（2023年2月），337–351.
    [https://doi.org/10.1017/pan.2023.2](https://doi.org/10.1017/pan.2023.2)
- en: Bai et al. (2023) Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong
    Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang
    Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui
    Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang,
    Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian
    Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang,
    Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan
    Zhou, and Tianhang Zhu. 2023. Qwen Technical Report. arXiv:2309.16609 [cs.CL]
    [https://arxiv.org/abs/2309.16609](https://arxiv.org/abs/2309.16609)
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人（2023）Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng,
    Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin,
    Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men,
    Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang,
    Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian
    Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang,
    Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan
    Zhou, 和 Tianhang Zhu. 2023. 《Qwen技术报告》。arXiv:2309.16609 [cs.CL] [https://arxiv.org/abs/2309.16609](https://arxiv.org/abs/2309.16609)
- en: 'Bai et al. (2022) Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell,
    Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron
    McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn
    Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared
    Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane
    Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova
    DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec,
    Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly,
    Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario
    Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. 2022. Constitutional
    AI: Harmlessness from AI Feedback. arXiv:2212.08073 [cs.CL] [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人（2022）Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson
    Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,
    Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep
    Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller,
    Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt,
    Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma,
    Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer
    El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly,
    Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario
    Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, 和 Jared Kaplan. 2022. 《宪法式人工智能：来自人工智能反馈的无害性》。arXiv:2212.08073
    [cs.CL] [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073)
- en: Barron et al. (2024) Ryan C. Barron, Ves Grantcharov, Selma Wanna, Maksim E.
    Eren, Manish Bhattarai, Nicholas Solovyev, George Tompkins, Charles Nicholas,
    Kim Ø. Rasmussen, Cynthia Matuszek, and Boian S. Alexandrov. 2024. Domain-Specific
    Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor
    Factorization. arXiv:2410.02721 [cs.CL] [https://arxiv.org/abs/2410.02721](https://arxiv.org/abs/2410.02721)
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barron 等人（2024）Ryan C. Barron, Ves Grantcharov, Selma Wanna, Maksim E. Eren,
    Manish Bhattarai, Nicholas Solovyev, George Tompkins, Charles Nicholas, Kim Ø.
    Rasmussen, Cynthia Matuszek, 和 Boian S. Alexandrov. 2024. 《使用向量存储、知识图谱和张量分解的领域特定检索增强生成》。arXiv:2410.02721
    [cs.CL] [https://arxiv.org/abs/2410.02721](https://arxiv.org/abs/2410.02721)
- en: Benram (2024) Gad Benram. 2024. *Understanding the cost of Large Language Models
    (LLMs)*. Retrieved October 16, 2024 from [https://www.tensorops.ai/post/understanding-the-cost-of-large-language-models-llms](https://www.tensorops.ai/post/understanding-the-cost-of-large-language-models-llms)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Benram（2024）Gad Benram. 2024. *理解大型语言模型（LLM）的成本*。2024年10月16日获取自 [https://www.tensorops.ai/post/understanding-the-cost-of-large-language-models-llms](https://www.tensorops.ai/post/understanding-the-cost-of-large-language-models-llms)
- en: 'Beurer-Kellner et al. (2024) Luca Beurer-Kellner, Marc Fischer, and Martin
    Vechev. 2024. Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation.
    In *Proceedings of the 41st International Conference on Machine Learning* *(Proceedings
    of Machine Learning Research, Vol. 235)*, Ruslan Salakhutdinov, Zico Kolter, Katherine
    Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp (Eds.).
    PMLR, 3658–3673. [https://proceedings.mlr.press/v235/beurer-kellner24a.html](https://proceedings.mlr.press/v235/beurer-kellner24a.html)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beurer-Kellner 等人（2024）Luca Beurer-Kellner, Marc Fischer, 和 Martin Vechev. 2024.
    《正确引导大型语言模型：快速、非侵入性约束生成》。发表于*第41届国际机器学习大会论文集*（*机器学习研究论文集，第235卷*），Ruslan Salakhutdinov,
    Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett,
    和 Felix Berkenkamp（编辑）。PMLR, 3658–3673. [https://proceedings.mlr.press/v235/beurer-kellner24a.html](https://proceedings.mlr.press/v235/beurer-kellner24a.html)
- en: Bucher and Martini (2024) Martin Juan José Bucher and Marco Martini. 2024. Fine-Tuned
    ’Small’ LLMs (Still) Significantly Outperform Zero-Shot Generative AI Models in
    Text Classification. arXiv:2406.08660 [cs.CL] [https://arxiv.org/abs/2406.08660](https://arxiv.org/abs/2406.08660)
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布赫尔和马尔蒂尼（2024）马丁·胡安·何塞·布赫尔和马尔科·马尔蒂尼。2024。微调后的“小”LLM（仍然）显著超越零-shot生成式AI模型在文本分类中的表现。arXiv:2406.08660
    [cs.CL] [https://arxiv.org/abs/2406.08660](https://arxiv.org/abs/2406.08660)
- en: Chang et al. (2024) Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang,
    Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang,
    Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. 2024. A Survey on Evaluation
    of Large Language Models. *ACM Trans. Intell. Syst. Technol.* 15, 3, Article 39
    (March 2024), 45 pages. [https://doi.org/10.1145/3641289](https://doi.org/10.1145/3641289)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常等人（2024）常玉鹏、王旭、王金东、吴源、杨林义、朱凯杰、陈昊、易晓源、王存翔、王艺东、叶伟、张月、常一、余磊、杨强、谢星。2024。大语言模型评估综述。*ACM
    智能系统技术学报* 15, 3, 第39篇（2024年3月），45页。 [https://doi.org/10.1145/3641289](https://doi.org/10.1145/3641289)
- en: 'Dagan et al. (2024) Gautier Dagan, Frank Keller, and Alex Lascarides Keller.
    2024. Dynamic planning with an LLM. In *Proceedings of the Language Gamification
    Workshop 2024 at NeurIPS*. Neural Information Processing Systems Foundation (NeurIPS),
    1–14. [https://doi.org/10.48550/arXiv.2308.06391](https://doi.org/10.48550/arXiv.2308.06391)
    Language Gamification Workshop 2024 at NeurIPS ; Conference date: 14-12-2024 Through
    14-12-2024.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 达根等人（2024）戈蒂埃·达根、弗兰克·凯勒、亚历克斯·拉斯卡里德斯·凯勒。2024。使用LLM进行动态规划。发表于*2024年NeurIPS语言游戏化研讨会论文集*。神经信息处理系统基金会（NeurIPS），1–14。[https://doi.org/10.48550/arXiv.2308.06391](https://doi.org/10.48550/arXiv.2308.06391)
    2024年NeurIPS语言游戏化研讨会；会议日期：2024年12月14日至2024年12月14日。
- en: 'Deng et al. (2024) Shihan Deng, Weikai Xu, Hongda Sun, Wei Liu, Tao Tan, Liujianfeng
    Liujianfeng, Ang Li, Jian Luan, Bin Wang, Rui Yan, and Shuo Shang. 2024. Mobile-Bench:
    An Evaluation Benchmark for LLM-based Mobile Agents. In *Proceedings of the 62nd
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers)*, Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for
    Computational Linguistics, Bangkok, Thailand, 8813–8831. [https://doi.org/10.18653/v1/2024.acl-long.478](https://doi.org/10.18653/v1/2024.acl-long.478)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邓等人（2024）邓世汉、徐伟凯、孙洪达、刘伟、谭涛、刘建峰、李俊峰、李昂、段健、王斌、严锐、尚烁。2024。Mobile-Bench：基于LLM的移动智能体评估基准。发表于*计算语言学协会第62届年会论文集（第一卷：长篇论文）*，吕文伟、安德烈·马丁斯、维韦克·斯里库马尔（主编）。计算语言学协会，泰国曼谷，8813–8831。
    [https://doi.org/10.18653/v1/2024.acl-long.478](https://doi.org/10.18653/v1/2024.acl-long.478)
- en: Dubey et al. (2024) Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek
    Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang,
    Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar,
    Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen
    Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern,
    Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian
    Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer,
    Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits,
    David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino,
    Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael
    Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis
    Anderson, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen,
    Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel
    Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana
    Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer
    Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen
    Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca,
    Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Kartikeya Upasani,
    Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika
    Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Laurens
    van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan,
    Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh
    Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Mathew Oldham, Mathieu
    Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh,
    Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev,
    Niladri Chatterji, Olivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang,
    Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen
    Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan,
    Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta
    Raileanu, Rohit Girdhar, Rohit Patel, Romain Sauvestre, Ronnie Polidoro, Roshan
    Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana Chennabasappa,
    Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan
    Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang,
    Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot,
    Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha,
    Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao,
    Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez,
    Vincent Gonguet, Virginie Do, Vish Vogeti, Vladan Petrovic, Weiwei Chu, Wenhan
    Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaoqing Ellen
    Tan, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine
    Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre
    Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aaron Grattafiori,
    Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva
    Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alex Vaughan, Alexei Baevski,
    Allie Feinstein, Amanda Kallet, Amit Sangani, Anam Yunus, Andrei Lupu, Andres
    Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit
    Ramchandani, Annie Franco, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel,
    Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin
    Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu,
    Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian
    Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Changhan Wang,
    Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal,
    Christoph Feichtenhofer, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, Danny
    Wyatt, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana
    Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling,
    Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Erik
    Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng
    Tian, Firat Ozgenel, Francesco Caggioni, Francisco Guzmán, Frank Kanayet, Frank
    Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil
    Halpern, Govind Thattai, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan,
    Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph,
    Helen Suk, Henry Aspegren, Hunter Goldman, Ibrahim Damlaj, Igor Molybog, Igor
    Tufanov, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli,
    Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny
    Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang,
    Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh
    Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Karthik Prasad, Kartikay
    Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena,
    Keqian Li, Kun Huang, Kunal Chawla, Kushal Lakhotia, Kyle Huang, Lailin Chen,
    Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng
    Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt,
    Maria Tsimpoukelli, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso,
    Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Michael L. Seltzer,
    Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan,
    Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat, Mohammad
    Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White, Navyata
    Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikolay Pavlovich Laptev, Ning
    Dong, Ning Zhang, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem
    Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip
    Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani,
    Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham
    Murthy, Raghu Nayani, Rahul Mitra, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky
    Wang, Rohan Maheswari, Russ Howes, Ruty Rinott, Sai Jayesh Bondu, Samyak Datta,
    Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Verma,
    Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao
    Lin, Shengxin Cindy Zha, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong
    Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen
    Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Sungmin
    Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar
    Glaser, Tamara Best, Thilo Kohler, Thomas Robinson, Tianhe Li, Tianjun Zhang,
    Tim Matthews, Timothy Chou, Tzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria
    Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vítor Albiero, Vlad
    Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen
    Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang, Xiaofang Wang,
    Xiaojian Wu, Xiaolan Wang, Xide Xia, Xilun Wu, Xinbo Gao, Yanjun Chen, Ye Hu,
    Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu,
    Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick,
    Zhaoduo Wen, Zhenyu Yang, and Zhiwei Zhao. 2024. The Llama 3 Herd of Models. arXiv:2407.21783 [cs.AI]
    [https://arxiv.org/abs/2407.21783](https://arxiv.org/abs/2407.21783)
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubey 等人 (2024) Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian,
    Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan,
    Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar,
    Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen
    Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern,
    Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian
    Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer,
    Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits,
    David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino,
    Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric
    Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee,
    Georgia Lewis Anderson, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell,
    Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta
    Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan
    Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde,
    Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang,
    Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph
    Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Kartikeya
    Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini,
    Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Lauren Rantala-Yeary,
    Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish
    Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi,
    Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Mathew Oldham,
    Mathieu Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar
    Singh, Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev,
    Niladri Chatterji, Olivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang,
    Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen
    Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan,
    Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta
    Raileanu, Rohit Girdhar, Rohit Patel, Romain Sauvestre, Ronnie Polidoro, Roshan
    Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana Chennabasappa,
    Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan
    Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang,
    Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot,
    Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha,
    Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao,
    Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez,
    Vincent Gonguet, Virginie Do, Vish Vogeti, Vladan Petrovic, Weiwei Chu, Wenhan
    Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaoqing Ellen
    Tan, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine
    Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre
    Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aaron Grattafiori,
    Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva
    Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alex Vaughan, Alexei Baevski,
    Allie Feinstein, Amanda Kallet, Amit Sangani, Anam Yunus, Andrei Lupu, Andres
    Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit
    Ramchandani, Annie Franco, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel,
    Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin
    Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu,
    Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian
    Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Changhan Wang,
    Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal,
    Christoph Feichtenhofer, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, Danny
    Wyatt, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana
    Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling,
    Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Erik
    Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng
    Tian, Firat Ozgenel, Francesco Caggioni, Francisco Guzmán, Frank Kanayet, Frank
    Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil
    Halpern, Govind Thattai, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan,
    Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph,
    Helen Suk, Henry Aspegren, Hunter Goldman, Ibrahim Damlaj, Igor Molybog, Igor
    Tufanov, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli,
    Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny
    Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang,
    Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh
    Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Karthik Prasad, Kartikay
    Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena,
    Keqian Li, Kun Huang, Kunal Chawla, Kushal Lakhotia, Kyle Huang, Lailin Chen,
    Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng
    Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt,
    Maria Tsimpoukelli, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso,
    Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Michael L. Seltzer,
    Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan,
    Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat, Mohammad
    Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White, Navyata
    Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikolay Pavlovich Laptev, Ning
    Dong, Ning Zhang, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem
    Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip
    Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani,
    Pritish Y
- en: 'Echterhoff et al. (2024) Jessica Maria Echterhoff, Yao Liu, Abeer Alessa, Julian
    McAuley, and Zexue He. 2024. Cognitive Bias in Decision-Making with LLMs. In *Findings
    of the Association for Computational Linguistics: EMNLP 2024*, Yaser Al-Onaizan,
    Mohit Bansal, and Yun-Nung Chen (Eds.). Association for Computational Linguistics,
    Miami, Florida, USA, 12640–12653. [https://doi.org/10.18653/v1/2024.findings-emnlp.739](https://doi.org/10.18653/v1/2024.findings-emnlp.739)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Echterhoff 等（2024）Jessica Maria Echterhoff、Yao Liu、Abeer Alessa、Julian McAuley
    和 Zexue He. 2024. 《基于大型语言模型的决策中的认知偏差》。载于 *计算语言学协会年会论文集：EMNLP 2024*，Yaser Al-Onaizan、Mohit
    Bansal 和 Yun-Nung Chen（编）。计算语言学协会，佛罗里达州迈阿密，美国，12640–12653. [https://doi.org/10.18653/v1/2024.findings-emnlp.739](https://doi.org/10.18653/v1/2024.findings-emnlp.739)
- en: 'Edge et al. (2024) Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex
    Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. 2024. From Local to Global:
    A Graph RAG Approach to Query-Focused Summarization. arXiv:2404.16130 [cs.CL]
    [https://arxiv.org/abs/2404.16130](https://arxiv.org/abs/2404.16130)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Edge 等（2024）Darren Edge、Ha Trinh、Newman Cheng、Joshua Bradley、Alex Chao、Apurva
    Mody、Steven Truitt 和 Jonathan Larson. 2024. 《从局部到全局：基于图的检索增强生成方法的查询聚焦摘要》。arXiv:2404.16130
    [cs.CL] [https://arxiv.org/abs/2404.16130](https://arxiv.org/abs/2404.16130)
- en: 'Es et al. (2024) Shahul Es, Jithin James, Luis Espinosa Anke, and Steven Schockaert.
    2024. RAGAs: Automated Evaluation of Retrieval Augmented Generation. In *Proceedings
    of the 18th Conference of the European Chapter of the Association for Computational
    Linguistics: System Demonstrations*, Nikolaos Aletras and Orphee De Clercq (Eds.).
    Association for Computational Linguistics, St. Julians, Malta, 150–158. [https://aclanthology.org/2024.eacl-demo.16](https://aclanthology.org/2024.eacl-demo.16)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Es 等（2024）Shahul Es、Jithin James、Luis Espinosa Anke 和 Steven Schockaert. 2024.
    《RAGAs：检索增强生成的自动评估》。载于 *计算语言学协会欧洲分会第18届会议：系统演示论文集*，Nikolaos Aletras 和 Orphee De
    Clercq（编）。计算语言学协会，马耳他圣朱利安，150–158. [https://aclanthology.org/2024.eacl-demo.16](https://aclanthology.org/2024.eacl-demo.16)
- en: 'Gao et al. (2024) Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan,
    Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and Haofen Wang. 2024. Retrieval-Augmented
    Generation for Large Language Models: A Survey. arXiv:2312.10997 [cs.CL] [https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等（2024）Yunfan Gao、Yun Xiong、Xinyu Gao、Kangxiang Jia、Jinliu Pan、Yuxi Bi、Yi
    Dai、Jiawei Sun、Meng Wang 和 Haofen Wang. 2024. 《基于检索增强生成的大型语言模型：一项调查》。arXiv:2312.10997
    [cs.CL] [https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997)
- en: 'Guo et al. (2024) Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao
    Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. 2024. Large Language
    Model Based Multi-agents: A Survey of Progress and Challenges. In *Proceedings
    of the Thirty-Third International Joint Conference on Artificial Intelligence,
    IJCAI-24*, Kate Larson (Ed.). International Joint Conferences on Artificial Intelligence
    Organization, 8048–8057. [https://doi.org/10.24963/ijcai.2024/890](https://doi.org/10.24963/ijcai.2024/890)
    Survey Track.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo 等（2024）Taicheng Guo、Xiuying Chen、Yaqi Wang、Ruidi Chang、Shichao Pei、Nitesh
    V. Chawla、Olaf Wiest 和 Xiangliang Zhang. 2024. 《基于大型语言模型的多智能体：进展与挑战综述》。载于 *第三十三届国际人工智能联合会议论文集，IJCAI-24*，Kate
    Larson（编）。国际人工智能联合会议组织，8048–8057. [https://doi.org/10.24963/ijcai.2024/890](https://doi.org/10.24963/ijcai.2024/890)
    综述专辑。
- en: Gur et al. (2024) Izzeddin Gur, Hiroki Furuta, Austin V Huang, Mustafa Safdari,
    Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. 2024. A Real-World WebAgent
    with Planning, Long Context Understanding, and Program Synthesis. In *The Twelfth
    International Conference on Learning Representations*. [https://openreview.net/forum?id=9JQtrumvg8](https://openreview.net/forum?id=9JQtrumvg8)
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gur 等（2024）Izzeddin Gur、Hiroki Furuta、Austin V Huang、Mustafa Safdari、Yutaka
    Matsuo、Douglas Eck 和 Aleksandra Faust. 2024. 《一个具有规划、长时上下文理解和程序合成的真实世界 WebAgent》。载于
    *第十二届国际学习表示大会*。 [https://openreview.net/forum?id=9JQtrumvg8](https://openreview.net/forum?id=9JQtrumvg8)
- en: Holtzman et al. (2020) Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin
    Choi. 2020. The Curious Case of Neural Text Degeneration. In *International Conference
    on Learning Representations*. [https://openreview.net/forum?id=rygGQyrFvH](https://openreview.net/forum?id=rygGQyrFvH)
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Holtzman 等（2020）Ari Holtzman、Jan Buys、Li Du、Maxwell Forbes 和 Yejin Choi. 2020.
    《神经文本退化的奇特案例》。载于 *国际学习表示大会*。 [https://openreview.net/forum?id=rygGQyrFvH](https://openreview.net/forum?id=rygGQyrFvH)
- en: 'Hong et al. (2024) Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng,
    Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan
    Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber.
    2024. MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. In
    *The Twelfth International Conference on Learning Representations*. [https://openreview.net/forum?id=VtmBAGCN7o](https://openreview.net/forum?id=VtmBAGCN7o)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong等人（2024）Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng,
    Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou,
    Chenyu Ran, Lingfeng Xiao, Chenglin Wu, 和 Jürgen Schmidhuber. 2024. MetaGPT：面向多代理协作框架的元编程。收录于
    *第十二届国际学习表示会议*。 [https://openreview.net/forum?id=VtmBAGCN7o](https://openreview.net/forum?id=VtmBAGCN7o)
- en: 'Huang et al. (2024) Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao
    Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and Enhong Chen. 2024. Understanding
    the planning of LLM agents: A survey. arXiv:2402.02716 [cs.AI] [https://arxiv.org/abs/2402.02716](https://arxiv.org/abs/2402.02716)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang等人（2024）Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu
    Lian, Yasheng Wang, Ruiming Tang, 和 Enhong Chen. 2024. 理解LLM代理的规划：一项调查。arXiv:2402.02716
    [cs.AI] [https://arxiv.org/abs/2402.02716](https://arxiv.org/abs/2402.02716)
- en: Jiang et al. (2023) Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch,
    Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna
    Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux,
    Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and
    William El Sayed. 2023. Mistral 7B. arXiv:2310.06825 [cs.CL] [https://arxiv.org/abs/2310.06825](https://arxiv.org/abs/2310.06825)
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang等人（2023）Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,
    Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,
    Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre
    Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, 和 William
    El Sayed. 2023. Mistral 7B. arXiv:2310.06825 [cs.CL] [https://arxiv.org/abs/2310.06825](https://arxiv.org/abs/2310.06825)
- en: Kambhampati (2024) Subbarao Kambhampati. 2024. Can large language models reason
    and plan? *Annals of the New York Academy of Sciences* 1534, 1 (March 2024), 15–18.
    [https://doi.org/10.1111/nyas.15125](https://doi.org/10.1111/nyas.15125)
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kambhampati（2024）Subbarao Kambhampati. 2024. 大型语言模型能否推理和规划？*纽约科学院年刊* 1534, 1
    (2024年3月), 15–18。 [https://doi.org/10.1111/nyas.15125](https://doi.org/10.1111/nyas.15125)
- en: Kamoi et al. (2024) Ryo Kamoi, Sarkar Snigdha Sarathi Das, Renze Lou, Jihyun Janice
    Ahn, Yilun Zhao, Xiaoxin Lu, Nan Zhang, Yusen Zhang, Haoran Ranran Zhang, Sujeeth Reddy
    Vummanthala, Salika Dave, Shaobo Qin, Arman Cohan, Wenpeng Yin, and Rui Zhang.
    2024. Evaluating LLMs at Detecting Errors in LLM Responses. In *First Conference
    on Language Modeling*. [https://openreview.net/forum?id=dnwRScljXr](https://openreview.net/forum?id=dnwRScljXr)
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamoi等人（2024）Ryo Kamoi, Sarkar Snigdha Sarathi Das, Renze Lou, Jihyun Janice
    Ahn, Yilun Zhao, Xiaoxin Lu, Nan Zhang, Yusen Zhang, Haoran Ranran Zhang, Sujeeth
    Reddy Vummanthala, Salika Dave, Shaobo Qin, Arman Cohan, Wenpeng Yin, 和 Rui Zhang.
    2024. 评估LLM在检测LLM回应错误方面的表现。收录于 *第一次语言建模会议*。 [https://openreview.net/forum?id=dnwRScljXr](https://openreview.net/forum?id=dnwRScljXr)
- en: Kapoor et al. (2024) Sayash Kapoor, Benedikt Stroebl, Zachary S. Siegel, Nitya
    Nadgir, and Arvind Narayanan. 2024. AI Agents That Matter. arXiv:2407.01502 [cs.LG]
    [https://arxiv.org/abs/2407.01502](https://arxiv.org/abs/2407.01502)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kapoor等人（2024）Sayash Kapoor, Benedikt Stroebl, Zachary S. Siegel, Nitya Nadgir,
    和 Arvind Narayanan. 2024. 重要的AI代理。arXiv:2407.01502 [cs.LG] [https://arxiv.org/abs/2407.01502](https://arxiv.org/abs/2407.01502)
- en: 'Karmaker Santu and Feng (2023) Shubhra Kanti Karmaker Santu and Dongji Feng.
    2023. TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.
    In *Findings of the Association for Computational Linguistics: EMNLP 2023*, Houda
    Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics,
    Singapore, 14197–14203. [https://doi.org/10.18653/v1/2023.findings-emnlp.946](https://doi.org/10.18653/v1/2023.findings-emnlp.946)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karmaker Santu 和 Feng（2023）Shubhra Kanti Karmaker Santu 和 Dongji Feng. 2023.
    TELeR：用于基准复杂任务的大型语言模型提示的通用分类法。收录于 *计算语言学协会会议成果：EMNLP 2023*，Houda Bouamor, Juan
    Pino, 和 Kalika Bali（编辑）。计算语言学协会，新加坡，14197–14203。 [https://doi.org/10.18653/v1/2023.findings-emnlp.946](https://doi.org/10.18653/v1/2023.findings-emnlp.946)
- en: Kojima et al. (2022) Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka
    Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners.
    *Advances in neural information processing systems* 35 (2022), 22199–22213.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kojima等人（2022）Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo,
    和 Yusuke Iwasawa. 2022. 大型语言模型是零样本推理器。*神经信息处理系统进展* 35 (2022), 22199–22213.
- en: 'Kong et al. (2024) Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin,
    Ruiqi Sun, Xin Zhou, Enzhi Wang, and Xiaohang Dong. 2024. Better Zero-Shot Reasoning
    with Role-Play Prompting. In *Proceedings of the 2024 Conference of the North
    American Chapter of the Association for Computational Linguistics: Human Language
    Technologies (Volume 1: Long Papers)*, Kevin Duh, Helena Gomez, and Steven Bethard
    (Eds.). Association for Computational Linguistics, Mexico City, Mexico, 4099–4113.
    [https://doi.org/10.18653/v1/2024.naacl-long.228](https://doi.org/10.18653/v1/2024.naacl-long.228)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kong等（2024）Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun,
    Xin Zhou, Enzhi Wang 和 Xiaohang Dong. 2024. 通过角色扮演提示提升零-shot推理能力。在*2024年北美计算语言学协会：人类语言技术会议（卷1：长篇论文）*中，Kevin
    Duh、Helena Gomez 和 Steven Bethard（编）。计算语言学协会，墨西哥城，墨西哥，4099–4113。[https://doi.org/10.18653/v1/2024.naacl-long.228](https://doi.org/10.18653/v1/2024.naacl-long.228)
- en: 'Laskar et al. (2023) Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman,
    Md Amran Hossen Bhuiyan, Shafiq Joty, and Jimmy Huang. 2023. A Systematic Study
    and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. In *Findings of
    the Association for Computational Linguistics: ACL 2023*, Anna Rogers, Jordan
    Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics,
    Toronto, Canada, 431–469. [https://doi.org/10.18653/v1/2023.findings-acl.29](https://doi.org/10.18653/v1/2023.findings-acl.29)'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laskar等（2023）Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran
    Hossen Bhuiyan, Shafiq Joty 和 Jimmy Huang. 2023. ChatGPT在基准数据集上的系统性研究与全面评估。在*计算语言学协会会议发现：ACL
    2023*中，Anna Rogers、Jordan Boyd-Graber 和 Naoaki Okazaki（编）。计算语言学协会，多伦多，加拿大，431–469。[https://doi.org/10.18653/v1/2023.findings-acl.29](https://doi.org/10.18653/v1/2023.findings-acl.29)
- en: Lehman et al. (2023) Eric Lehman, Evan Hernandez, Diwakar Mahajan, Jonas Wulff,
    Micah J Smith, Zachary Ziegler, Daniel Nadler, Peter Szolovits, Alistair Johnson,
    and Emily Alsentzer. 2023. Do We Still Need Clinical Language Models?. In *Proceedings
    of the Conference on Health, Inference, and Learning* *(Proceedings of Machine
    Learning Research, Vol. 209)*, Bobak J. Mortazavi, Tasmie Sarker, Andrew Beam,
    and Joyce C. Ho (Eds.). PMLR, 578–597. [https://proceedings.mlr.press/v209/eric23a.html](https://proceedings.mlr.press/v209/eric23a.html)
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lehman等（2023）Eric Lehman, Evan Hernandez, Diwakar Mahajan, Jonas Wulff, Micah
    J Smith, Zachary Ziegler, Daniel Nadler, Peter Szolovits, Alistair Johnson 和 Emily
    Alsentzer. 2023. 我们仍然需要临床语言模型吗？在*健康、推理和学习会议论文集*（*机器学习研究论文集，卷209*）中，Bobak J. Mortazavi,
    Tasmie Sarker, Andrew Beam 和 Joyce C. Ho（编）。PMLR，578–597。[https://proceedings.mlr.press/v209/eric23a.html](https://proceedings.mlr.press/v209/eric23a.html)
- en: Lewis et al. (2020) Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni,
    Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
    Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-augmented generation
    for knowledge-intensive NLP tasks. In *Proceedings of the 34th International Conference
    on Neural Information Processing Systems* (Vancouver, BC, Canada) *(NIPS ’20)*.
    Curran Associates Inc., Red Hook, NY, USA, Article 793, 16 pages.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis等（2020）Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
    Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,
    Sebastian Riedel 和 Douwe Kiela. 2020. 用于知识密集型NLP任务的检索增强生成。在*第34届神经信息处理系统国际会议论文集*（温哥华，加拿大）*(NIPS
    '20)*中。Curran Associates Inc.，纽约州红钩，美国，文章793，16页。
- en: Li et al. (2023a) Huao Li, Yu Chong, Simon Stepputtis, Joseph Campbell, Dana
    Hughes, Charles Lewis, and Katia Sycara. 2023a. Theory of Mind for Multi-Agent
    Collaboration via Large Language Models. In *Proceedings of the 2023 Conference
    on Empirical Methods in Natural Language Processing*, Houda Bouamor, Juan Pino,
    and Kalika Bali (Eds.). Association for Computational Linguistics, Singapore,
    180–192. [https://doi.org/10.18653/v1/2023.emnlp-main.13](https://doi.org/10.18653/v1/2023.emnlp-main.13)
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2023a）Huao Li, Yu Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes,
    Charles Lewis, 和 Katia Sycara. 2023a. 通过大型语言模型实现多智能体协作的心智理论。在*2023年自然语言处理实证方法会议论文集*中，Houda
    Bouamor、Juan Pino 和 Kalika Bali（编）。计算语言学协会， Singapore，180–192。[https://doi.org/10.18653/v1/2023.emnlp-main.13](https://doi.org/10.18653/v1/2023.emnlp-main.13)
- en: Li et al. (2024) Tianle Li, Ge Zhang, Quy Duc Do, Xiang Yue, and Wenhu Chen.
    2024. Long-context LLMs Struggle with Long In-context Learning. *CoRR* abs/2404.02060
    (2024). [https://doi.org/10.48550/arXiv.2404.02060](https://doi.org/10.48550/arXiv.2404.02060)
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2024）Tianle Li, Ge Zhang, Quy Duc Do, Xiang Yue 和 Wenhu Chen. 2024. 长上下文LLMs在长上下文学习中遇到困难。*CoRR*
    abs/2404.02060（2024）。[https://doi.org/10.48550/arXiv.2404.02060](https://doi.org/10.48550/arXiv.2404.02060)
- en: 'Li (2024) Xinzhe Li. 2024. A Review of Prominent Paradigms for LLM-Based Agents:
    Tool Use (Including RAG), Planning, and Feedback Learning. arXiv:2406.05804 [cs.AI]
    [https://arxiv.org/abs/2406.05804](https://arxiv.org/abs/2406.05804)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li (2024) Xinzhe Li. 2024. LLM基础代理的主要范式综述：工具使用（包括RAG）、规划与反馈学习。arXiv:2406.05804
    [cs.AI] [https://arxiv.org/abs/2406.05804](https://arxiv.org/abs/2406.05804)
- en: 'Li et al. (2023b) Yuan Li, Yixuan Zhang, and Lichao Sun. 2023b. MetaAgents:
    Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination
    via Collaborative Generative Agents. *ArXiv* abs/2310.06500 (2023). [https://api.semanticscholar.org/CorpusID:263829557](https://api.semanticscholar.org/CorpusID:263829557)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2023b) Yuan Li, Yixuan Zhang, 和 Lichao Sun. 2023b. MetaAgents: 通过协作生成代理模拟人类行为的交互，用于基于LLM的任务导向协调。*ArXiv*
    abs/2310.06500 (2023)。 [https://api.semanticscholar.org/CorpusID:263829557](https://api.semanticscholar.org/CorpusID:263829557)'
- en: 'Lin et al. (2023) Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue
    Ping, and Qin Chen. 2023. AgentSims: An Open-Source Sandbox for Large Language
    Model Evaluation. arXiv:2308.04026 [cs.AI] [https://arxiv.org/abs/2308.04026](https://arxiv.org/abs/2308.04026)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin et al. (2023) Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue
    Ping, 和 Qin Chen. 2023. AgentSims: 一种用于大型语言模型评估的开源沙盒。arXiv:2308.04026 [cs.AI]
    [https://arxiv.org/abs/2308.04026](https://arxiv.org/abs/2308.04026)'
- en: 'Liu et al. (2023) Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang,
    Joydeep Biswas, and Peter Stone. 2023. LLM+P: Empowering Large Language Models
    with Optimal Planning Proficiency. arXiv:2304.11477 [cs.AI] [https://arxiv.org/abs/2304.11477](https://arxiv.org/abs/2304.11477)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023) Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang,
    Joydeep Biswas, 和 Peter Stone. 2023. LLM+P: 赋能大型语言模型以优化规划能力。arXiv:2304.11477 [cs.AI]
    [https://arxiv.org/abs/2304.11477](https://arxiv.org/abs/2304.11477)'
- en: 'Liu et al. (2024b) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024b. Lost in the Middle:
    How Language Models Use Long Contexts. *Transactions of the Association for Computational
    Linguistics* 12 (2024), 157–173. [https://doi.org/10.1162/tacl_a_00638](https://doi.org/10.1162/tacl_a_00638)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2024b) Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape,
    Michele Bevilacqua, Fabio Petroni, 和 Percy Liang. 2024b. 迷失在中间：语言模型如何使用长上下文。*计算语言学协会会刊*
    12 (2024), 157–173. [https://doi.org/10.1162/tacl_a_00638](https://doi.org/10.1162/tacl_a_00638)
- en: 'Liu et al. (2024c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. 2024c. AgentBench: Evaluating LLMs
    as Agents. In *The Twelfth International Conference on Learning Representations*.
    [https://openreview.net/forum?id=zAdUB0aCTQ](https://openreview.net/forum?id=zAdUB0aCTQ)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2024c) Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu
    Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng,
    Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
    Sun, Minlie Huang, Yuxiao Dong, 和 Jie Tang. 2024c. AgentBench: 评估LLM作为代理的能力。载于
    *第十二届国际学习表示会议*。 [https://openreview.net/forum?id=zAdUB0aCTQ](https://openreview.net/forum?id=zAdUB0aCTQ)'
- en: 'Liu et al. (2024a) Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke,
    Boyi Liu, and Zhaoran Wang. 2024a. Reason for Future, Act for Now: A Principled
    Framework for Autonomous LLM Agents with Provable Sample Efficiency. arXiv:2309.17382 [cs.AI]
    [https://arxiv.org/abs/2309.17382](https://arxiv.org/abs/2309.17382)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu et al. (2024a) Zhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi Ke, Boyi
    Liu, 和 Zhaoran Wang. 2024a. 面向未来，行动当下：一种具有可证明样本效率的自主LLM代理的原则框架。arXiv:2309.17382
    [cs.AI] [https://arxiv.org/abs/2309.17382](https://arxiv.org/abs/2309.17382)
- en: ljunkai (2023) ljunkai. 2023. *How to find the optimal model size for Large
    Language Models to optimize effectiveness and cost*. Retrieved October 16, 2024
    from [https://repost.aws/articles/ARv5lSlUnnSkanRxSD2EFz5w/how-to-find-the-optimal-model-size-for-large-language-models-to-optimize-effectiveness-and-cost](https://repost.aws/articles/ARv5lSlUnnSkanRxSD2EFz5w/how-to-find-the-optimal-model-size-for-large-language-models-to-optimize-effectiveness-and-cost)
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ljunkai (2023) ljunkai. 2023. *如何找到大型语言模型的最优模型大小，以优化效果和成本*。2024年10月16日检索自 [https://repost.aws/articles/ARv5lSlUnnSkanRxSD2EFz5w/how-to-find-the-optimal-model-size-for-large-language-models-to-optimize-effectiveness-and-cost](https://repost.aws/articles/ARv5lSlUnnSkanRxSD2EFz5w/how-to-find-the-optimal-model-size-for-large-language-models-to-optimize-effectiveness-and-cost)
- en: 'Mehta et al. (2024) Nikhil Mehta, Milagro Teruel, Xin Deng, Sergio Figueroa Sanz,
    Ahmed Awadallah, and Julia Kiseleva. 2024. Improving Grounded Language Understanding
    in a Collaborative Environment by Interacting with Agents Through Help Feedback.
    In *Findings of the Association for Computational Linguistics: EACL 2024*, Yvette
    Graham and Matthew Purver (Eds.). Association for Computational Linguistics, St.
    Julian’s, Malta, 1306–1321. [https://aclanthology.org/2024.findings-eacl.87](https://aclanthology.org/2024.findings-eacl.87)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mehta 等人（2024）Nikhil Mehta、Milagro Teruel、Xin Deng、Sergio Figueroa Sanz、Ahmed
    Awadallah 和 Julia Kiseleva。2024年。通过与代理的帮助反馈互动，改善协作环境中的基础语言理解。载于*计算语言学协会成果：EACL
    2024*，Yvette Graham 和 Matthew Purver（编）。计算语言学协会，马耳他圣朱利安斯，1306–1321。[https://aclanthology.org/2024.findings-eacl.87](https://aclanthology.org/2024.findings-eacl.87)
- en: 'Mialon et al. (2024) Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann
    LeCun, and Thomas Scialom. 2024. GAIA: a benchmark for General AI Assistants.
    In *The Twelfth International Conference on Learning Representations*. [https://openreview.net/forum?id=fibxvahvs3](https://openreview.net/forum?id=fibxvahvs3)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mialon 等人（2024）Grégoire Mialon、Clémentine Fourrier、Thomas Wolf、Yann LeCun 和
    Thomas Scialom。2024年。《GAIA：通用AI助手的基准测试》。载于*第十二届国际学习表征会议*。[https://openreview.net/forum?id=fibxvahvs3](https://openreview.net/forum?id=fibxvahvs3)
- en: 'Nau et al. (2004) Dana Nau, Malik Ghallab, and Paolo Traverso. 2004. *Automated
    Planning: Theory & Practice*. Morgan Kaufmann Publishers Inc., San Francisco,
    CA, USA.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nau 等人（2004）Dana Nau、Malik Ghallab 和 Paolo Traverso。2004年。*自动规划：理论与实践*。Morgan
    Kaufmann Publishers Inc.，美国加利福尼亚州旧金山。
- en: OpenAI (2024) OpenAI. 2024. Learning to Reason with LLMs. Technical Report.
    Retrieved October 16, 2024 from [https://openai.com/index/learning-to-reason-with-llms/](https://openai.com/index/learning-to-reason-with-llms/)
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI（2024）OpenAI。2024年。《学习使用LLMs进行推理》。技术报告。2024年10月16日从[https://openai.com/index/learning-to-reason-with-llms/](https://openai.com/index/learning-to-reason-with-llms/)获取。
- en: OpenAI et al. (2024) OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
    Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt,
    Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie
    Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello,
    Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff,
    Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles
    Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey,
    Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek
    Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey
    Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux,
    Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling,
    Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus,
    Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie
    Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes,
    Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane
    Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton,
    Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon
    Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn
    Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto,
    Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider,
    Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina
    Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,
    Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen
    Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung,
    Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin,
    Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning,
    Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew,
    Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina,
    Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie
    Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David
    Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard
    Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe
    Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita,
    Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres,
    Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass,
    Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul
    Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra
    Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli,
    Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr,
    John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah
    Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin,
    Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher,
    Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak,
    Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston
    Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun
    Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben
    Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder,
    Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich,
    Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu,
    Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang,
    Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and
    Barret Zoph. 2024. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL] [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 等人（2024）OpenAI、Josh Achiam、Steven Adler、Sandhini Agarwal、Lama Ahmad、Ilge
    Akkaya、Florencia Leoni Aleman、Diogo Almeida、Janko Altenschmidt、Sam Altman、Shyamal
    Anadkat、Red Avila、Igor Babuschkin、Suchir Balaji、Valerie Balcom、Paul Baltescu、Haiming
    Bao、Mohammad Bavarian、Jeff Belgum、Irwan Bello、Jake Berdine、Gabriel Bernadett-Shapiro、Christopher
    Berner、Lenny Bogdonoff、Oleg Boiko、Madelaine Boyd、Anna-Luisa Brakman、Greg Brockman、Tim
    Brooks、Miles Brundage、Kevin Button、Trevor Cai、Rosie Campbell、Andrew Cann、Brittany
    Carey、Chelsea Carlson、Rory Carmichael、Brooke Chan、Che Chang、Fotis Chantzis、Derek
    Chen、Sully Chen、Ruby Chen、Jason Chen、Mark Chen、Ben Chess、Chester Cho、Casey Chu、Hyung
    Won Chung、Dave Cummings、Jeremiah Currier、Yunxing Dai、Cory Decareaux、Thomas Degry、Noah
    Deutsch、Damien Deville、Arka Dhar、David Dohan、Steve Dowling、Sheila Dunning、Adrien
    Ecoffet、Atty Eleti、Tyna Eloundou、David Farhi、Liam Fedus、Niko Felix、Simón Posada
    Fishman、Juston Forte、Isabella Fulford、Leo Gao、Elie Georges、Christian Gibson、Vik
    Goel、Tarun Gogineni、Gabriel Goh、Rapha Gontijo-Lopes、Jonathan Gordon、Morgan Grafstein、Scott
    Gray、Ryan Greene、Joshua Gross、Shixiang Shane Gu、Yufei Guo、Chris Hallacy、Jesse
    Han、Jeff Harris、Yuchen He、Mike Heaton、Johannes Heidecke、Chris Hesse、Alan Hickey、Wade
    Hickey、Peter Hoeschele、Brandon Houghton、Kenny Hsu、Shengli Hu、Xin Hu、Joost Huizinga、Shantanu
    Jain、Shawn Jain、Joanne Jang、Angela Jiang、Roger Jiang、Haozhun Jin、Denny Jin、Shino
    Jomoto、Billie Jonn、Heewoo Jun、Tomer Kaftan、Łukasz Kaiser、Ali Kamali、Ingmar Kanitscheider、Nitish
    Shirish Keskar、Tabarak Khan、Logan Kilpatrick、Jong Wook Kim、Christina Kim、Yongjik
    Kim、Jan Hendrik Kirchner、Jamie Kiros、Matt Knight、Daniel Kokotajlo、Łukasz Kondraciuk、Andrew
    Kondrich、Aris Konstantinidis、Kyle Kosic、Gretchen Krueger、Vishal Kuo、Michael Lampe、Ikai
    Lan、Teddy Lee、Jan Leike、Jade Leung、Daniel Levy、Chak Ming Li、Rachel Lim、Molly Lin、Stephanie
    Lin、Mateusz Litwin、Theresa Lopez、Ryan Lowe、Patricia Lue、Anna Makanju、Kim Malfacini、Sam
    Manning、Todor Markov、Yaniv Markovski、Bianca Martin、Katie Mayer、Andrew Mayne、Bob
    McGrew、Scott Mayer McKinney、Christine McLeavey、Paul McMillan、Jake McNeil、David
    Medina、Aalok Mehta、Jacob Menick、Luke Metz、Andrey Mishchenko、Pamela Mishkin、Vinnie
    Monaco、Evan Morikawa、Daniel Mossing、Tong Mu、Mira Murati、Oleg Murk、David Mély、Ashvin
    Nair、Reiichiro Nakano、Rajeev Nayak、Arvind Neelakantan、Richard Ngo、Hyeonwoo Noh、Long
    Ouyang、Cullen O’Keefe、Jakub Pachocki、Alex Paino、Joe Palermo、Ashley Pantuliano、Giambattista
    Parascandolo、Joel Parish、Emy Parparita、Alex Passos、Mikhail Pavlov、Andrew Peng、Adam
    Perelman、Filipe de Avila Belbute Peres、Michael Petrov、Henrique Ponde de Oliveira
    Pinto、Michael Pokorny、Michelle Pokrass、Vitchyr H. Pong、Tolly Powell、Alethea Power、Boris
    Power、Elizabeth Proehl、Raul Puri、Alec Radford、Jack Rae、Aditya Ramesh、Cameron Raymond、Francis
    Real、Kendra Rimbach、Carl Ross、Bob Rotsted、Henri Roussez、Nick Ryder、Mario Saltarelli、Ted
    Sanders、Shibani Santurkar、Girish Sastry、Heather Schmidt、David Schnurr、John Schulman、Daniel
    Selsam、Kyla Sheppard、Toki Sherbakov、Jessica Shieh、Sarah Shoker、Pranav Shyam、Szymon
    Sidor、Eric Sigler、Maddie Simens、Jordan Sitkin、Katarina Slama、Ian Sohl、Benjamin
    Sokolowsky、Yang Song、Natalie Staudacher、Felipe Petroski Such、Natalie Summers、Ilya
    Sutskever、Jie Tang、Nikolas Tezak、Madeleine B. Thompson、Phil Tillet、Amin Tootoonchian、Elizabeth
    Tseng、Preston Tuggle、Nick Turley、Jerry Tworek、Juan Felipe Cerón Uribe、Andrea Vallone、Arun
    Vijayvergiya、Chelsea Voss、Carroll Wainwright、Justin Jay Wang、Alvin Wang、Ben Wang、Jonathan
    Ward、Jason Wei、CJ Weinmann、Akila Welihinda、Peter Welinder、Jiayi Weng、Lilian Weng、Matt
    Wiethoff、Dave Willner、Clemens Winter、Samuel Wolrich、Hannah Wong、Lauren Workman、Sherwin
    Wu、Jeff Wu、Michael Wu、Kai Xiao、Tao Xu、Sarah Yoo、Kevin Yu、Qiming Yuan、Wojciech
    Zaremba、Rowan Zellers、Chong Zhang、Marvin Zhang、Shengjia Zhao、Tianhao Zheng、Juntang
    Zhuang、William Zhuk 和 Barret Zoph。2024。GPT-4 技术报告。arXiv:2303.08774 [cs.CL] [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
- en: 'Park et al. (2023) Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel
    Morris, Percy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive
    Simulacra of Human Behavior *(UIST ’23)*. Association for Computing Machinery,
    New York, NY, USA, Article 2, 22 pages. [https://doi.org/10.1145/3586183.3606763](https://doi.org/10.1145/3586183.3606763)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park 等人（2023）Joon Sung Park、Joseph O’Brien、Carrie Jun Cai、Meredith Ringel Morris、Percy
    Liang 和 Michael S. Bernstein。2023年。生成代理：人类行为的互动模拟 *(UIST ’23)*。美国计算机协会，纽约，美国，文章
    2，22 页。[https://doi.org/10.1145/3586183.3606763](https://doi.org/10.1145/3586183.3606763)
- en: Pope et al. (2023) Reiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin,
    James Bradbury, Jonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean. 2023.
    Efficiently Scaling Transformer Inference. In *MLSys*. [https://proceedings.mlsys.org/paper_files/paper/2023/hash/c4be71ab8d24cdfb45e3d06dbfca2780-Abstract-mlsys2023.html](https://proceedings.mlsys.org/paper_files/paper/2023/hash/c4be71ab8d24cdfb45e3d06dbfca2780-Abstract-mlsys2023.html)
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pope 等人（2023）Reiner Pope、Sholto Douglas、Aakanksha Chowdhery、Jacob Devlin、James
    Bradbury、Jonathan Heek、Kefan Xiao、Shivani Agrawal 和 Jeff Dean。2023年。高效扩展 Transformer
    推理。发表于 *MLSys*。[https://proceedings.mlsys.org/paper_files/paper/2023/hash/c4be71ab8d24cdfb45e3d06dbfca2780-Abstract-mlsys2023.html](https://proceedings.mlsys.org/paper_files/paper/2023/hash/c4be71ab8d24cdfb45e3d06dbfca2780-Abstract-mlsys2023.html)
- en: 'Qian et al. (2024a) Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang,
    Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li,
    Zhiyuan Liu, and Maosong Sun. 2024a. ChatDev: Communicative Agents for Software
    Development. In *Proceedings of the 62nd Annual Meeting of the Association for
    Computational Linguistics (Volume 1: Long Papers)*, Lun-Wei Ku, Andre Martins,
    and Vivek Srikumar (Eds.). Association for Computational Linguistics, Bangkok,
    Thailand, 15174–15186. [https://doi.org/10.18653/v1/2024.acl-long.810](https://doi.org/10.18653/v1/2024.acl-long.810)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2024a）Chen Qian、Wei Liu、Hongzhang Liu、Nuo Chen、Yufan Dang、Jiahao Li、Cheng
    Yang、Weize Chen、Yusheng Su、Xin Cong、Juyuan Xu、Dahai Li、Zhiyuan Liu 和 Maosong Sun。2024a。ChatDev：软件开发的交互代理。发表于
    *第62届计算语言学协会年会论文集（卷1：长篇论文）*，Lun-Wei Ku、Andre Martins 和 Vivek Srikumar（编辑）。计算语言学协会，泰国曼谷，15174–15186。[https://doi.org/10.18653/v1/2024.acl-long.810](https://doi.org/10.18653/v1/2024.acl-long.810)
- en: Qian et al. (2024b) Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Yujia
    Zhou, Xu Chen, and Zhicheng Dou. 2024b. Are Long-LLMs A Necessity For Long-Context
    Tasks? arXiv:2405.15318 [cs.CL] [https://arxiv.org/abs/2405.15318](https://arxiv.org/abs/2405.15318)
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人（2024b）Hongjin Qian、Zheng Liu、Peitian Zhang、Kelong Mao、Yujia Zhou、Xu
    Chen 和 Zhicheng Dou。2024b。长文本任务是否需要长时间的语言模型？arXiv:2405.15318 [cs.CL] [https://arxiv.org/abs/2405.15318](https://arxiv.org/abs/2405.15318)
- en: Qin et al. (2024a) Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding,
    Ganqu Cui, Zheni Zeng, Xuanhe Zhou, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren
    Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang,
    Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang
    Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi
    Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng
    Ji, Guoliang Li, Zhiyuan Liu, and Maosong Sun. 2024a. Tool Learning with Foundation
    Models. *ACM Comput. Surv.* (Nov. 2024). [https://doi.org/10.1145/3704435](https://doi.org/10.1145/3704435)
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等人（2024a）Yujia Qin、Shengding Hu、Yankai Lin、Weize Chen、Ning Ding、Ganqu Cui、Zheni
    Zeng、Xuanhe Zhou、Yufei Huang、Chaojun Xiao、Chi Han、Yi Ren Fung、Yusheng Su、Huadong
    Wang、Cheng Qian、Runchu Tian、Kunlun Zhu、Shihao Liang、Xingyu Shen、Bokai Xu、Zhen
    Zhang、Yining Ye、Bowen Li、Ziwei Tang、Jing Yi、Yuzhang Zhu、Zhenning Dai、Lan Yan、Xin
    Cong、Yaxi Lu、Weilin Zhao、Yuxiang Huang、Junxi Yan、Xu Han、Xian Sun、Dahai Li、Jason
    Phang、Cheng Yang、Tongshuang Wu、Heng Ji、Guoliang Li、Zhiyuan Liu 和 Maosong Sun。2024a。使用基础模型进行工具学习。*ACM
    Comput. Surv.*（2024年11月）。[https://doi.org/10.1145/3704435](https://doi.org/10.1145/3704435)
- en: 'Qin et al. (2024b) Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan,
    Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong,
    Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and
    Maosong Sun. 2024b. ToolLLM: Facilitating Large Language Models to Master 16000+
    Real-world APIs. In *The Twelfth International Conference on Learning Representations*.
    [https://openreview.net/forum?id=dHng2O0Jjr](https://openreview.net/forum?id=dHng2O0Jjr)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qin 等人（2024b）Yujia Qin、Shihao Liang、Yining Ye、Kunlun Zhu、Lan Yan、Yaxi Lu、Yankai
    Lin、Xin Cong、Xiangru Tang、Bill Qian、Sihan Zhao、Lauren Hong、Runchu Tian、Ruobing
    Xie、Jie Zhou、Mark Gerstein、Dahai Li、Zhiyuan Liu 和 Maosong Sun。2024b。ToolLLM：帮助大语言模型掌握
    16000+ 个真实世界的 API。发表于 *第十二届国际学习表示会议*。[https://openreview.net/forum?id=dHng2O0Jjr](https://openreview.net/forum?id=dHng2O0Jjr)
- en: Roucher and Petrov (2024) Aymeric Roucher and Sergei Petrov. 2024. *Our Transformers
    Code Agent beats the GAIA benchmark!* Hugging Face. Retrieved October 2, 2024
    from [https://huggingface.co/blog/beating-gaia](https://huggingface.co/blog/beating-gaia)
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roucher 和 Petrov (2024) Aymeric Roucher 和 Sergei Petrov. 2024. *我们的 Transformer
    代码代理超越了 GAIA 基准测试！* Hugging Face. 2024年10月2日检索自 [https://huggingface.co/blog/beating-gaia](https://huggingface.co/blog/beating-gaia)
- en: Salemi and Zamani (2024) Alireza Salemi and Hamed Zamani. 2024. Evaluating Retrieval
    Quality in Retrieval-Augmented Generation. In *Proceedings of the 47th International
    ACM SIGIR Conference on Research and Development in Information Retrieval* (Washington
    DC, USA) *(SIGIR ’24)*. Association for Computing Machinery, New York, NY, USA,
    2395–2400. [https://doi.org/10.1145/3626772.3657957](https://doi.org/10.1145/3626772.3657957)
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salemi 和 Zamani (2024) Alireza Salemi 和 Hamed Zamani. 2024. 在检索增强生成中的检索质量评估.
    收录于 *第47届国际 ACM SIGIR 信息检索研究与发展会议论文集*（美国华盛顿DC） *(SIGIR ’24)*. 计算机协会，美国纽约，2395–2400页.
    [https://doi.org/10.1145/3626772.3657957](https://doi.org/10.1145/3626772.3657957)
- en: 'Schick et al. (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.
    2023. Toolformer: Language Models Can Teach Themselves to Use Tools. In *Thirty-seventh
    Conference on Neural Information Processing Systems*. [https://openreview.net/forum?id=Yacmpz84TH](https://openreview.net/forum?id=Yacmpz84TH)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schick 等 (2023) Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu,
    Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom.
    2023. Toolformer：语言模型能自学使用工具. 收录于 *第37届神经信息处理系统会议*. [https://openreview.net/forum?id=Yacmpz84TH](https://openreview.net/forum?id=Yacmpz84TH)
- en: 'Sclar et al. (2023) Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin
    Choi, and Yulia Tsvetkov. 2023. Minding Language Models’ (Lack of) Theory of Mind:
    A Plug-and-Play Multi-Character Belief Tracker. In *Proceedings of the 61st Annual
    Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*,
    Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational
    Linguistics, Toronto, Canada, 13960–13980. [https://doi.org/10.18653/v1/2023.acl-long.780](https://doi.org/10.18653/v1/2023.acl-long.780)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sclar 等 (2023) Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi,
    和 Yulia Tsvetkov. 2023. 关注语言模型（缺乏）心智理论：一个即插即用的多角色信念追踪器. 收录于 *第61届计算语言学协会年会论文集（第1卷：长篇论文）*,
    Anna Rogers, Jordan Boyd-Graber 和 Naoaki Okazaki（编辑）. 计算语言学协会，加拿大多伦多，13960–13980页.
    [https://doi.org/10.18653/v1/2023.acl-long.780](https://doi.org/10.18653/v1/2023.acl-long.780)
- en: 'Shen et al. (2023) Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming
    Lu, and Yueting Zhuang. 2023. HuggingGPT: Solving AI Tasks with ChatGPT and its
    Friends in Hugging Face. In *Thirty-seventh Conference on Neural Information Processing
    Systems*. [https://openreview.net/forum?id=yHdTscY6Ci](https://openreview.net/forum?id=yHdTscY6Ci)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen 等 (2023) Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu,
    和 Yueting Zhuang. 2023. HuggingGPT：用 ChatGPT 和 Hugging Face 中的伙伴解决 AI 任务. 收录于
    *第37届神经信息处理系统会议*. [https://openreview.net/forum?id=yHdTscY6Ci](https://openreview.net/forum?id=yHdTscY6Ci)
- en: 'Shinn et al. (2024) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik
    Narasimhan, and Shunyu Yao. 2024. Reflexion: language agents with verbal reinforcement
    learning. In *Proceedings of the 37th International Conference on Neural Information
    Processing Systems* (New Orleans, LA, USA) *(NIPS ’23)*. Curran Associates Inc.,
    Red Hook, NY, USA, Article 377, 19 pages.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shinn 等 (2024) Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan,
    和 Shunyu Yao. 2024. Reflexion：具有语言强化学习的语言代理. 收录于 *第37届国际神经信息处理系统会议论文集*（美国路易斯安那州新奥尔良）
    *(NIPS ’23)*. Curran Associates Inc., 美国纽约红钩，文章377，19页。
- en: 'Shuster et al. (2021) Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and
    Jason Weston. 2021. Retrieval Augmentation Reduces Hallucination in Conversation.
    In *Findings of the Association for Computational Linguistics: EMNLP 2021*, Marie-Francine
    Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association
    for Computational Linguistics, Punta Cana, Dominican Republic, 3784–3803. [https://doi.org/10.18653/v1/2021.findings-emnlp.320](https://doi.org/10.18653/v1/2021.findings-emnlp.320)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shuster 等 (2021) Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, 和 Jason
    Weston. 2021. 检索增强减少对话中的幻觉. 收录于 *计算语言学协会会议成果：EMNLP 2021*, Marie-Francine Moens,
    Xuanjing Huang, Lucia Specia 和 Scott Wen-tau Yih（编辑）. 计算语言学协会，多米尼加共和国蓬塔卡纳，3784–3803页.
    [https://doi.org/10.18653/v1/2021.findings-emnlp.320](https://doi.org/10.18653/v1/2021.findings-emnlp.320)
- en: Si et al. (2023) Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer, and Jordan Lee
    Boyd-Graber. 2023. Getting MoRE out of Mixture of Language Model Reasoning Experts.
    In *The 2023 Conference on Empirical Methods in Natural Language Processing*.
    [https://openreview.net/forum?id=UMywlqrW3n](https://openreview.net/forum?id=UMywlqrW3n)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Si et al. (2023) Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer, 和 Jordan
    Lee Boyd-Graber. 2023. 《从语言模型推理专家的混合体中获得更多》（Getting MoRE out of Mixture of Language
    Model Reasoning Experts）。发表于 *2023年自然语言处理实证方法大会（EMNLP 2023）*。[https://openreview.net/forum?id=UMywlqrW3n](https://openreview.net/forum?id=UMywlqrW3n)
- en: 'Son et al. (2024) Guijin Son, SangWon Baek, Sangdae Nam, Ilgyun Jeong, and
    Seungone Kim. 2024. Multi-Task Inference: Can Large Language Models Follow Multiple
    Instructions at Once?. In *Proceedings of the 62nd Annual Meeting of the Association
    for Computational Linguistics (Volume 1: Long Papers)*, Lun-Wei Ku, Andre Martins,
    and Vivek Srikumar (Eds.). Association for Computational Linguistics, Bangkok,
    Thailand, 5606–5627. [https://doi.org/10.18653/v1/2024.acl-long.304](https://doi.org/10.18653/v1/2024.acl-long.304)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Son et al. (2024) Guijin Son, SangWon Baek, Sangdae Nam, Ilgyun Jeong, 和 Seungone
    Kim. 2024. 《多任务推理：大型语言模型能否同时执行多项指令？》（Multi-Task Inference: Can Large Language
    Models Follow Multiple Instructions at Once?）。发表于 *第62届计算语言学协会年会论文集（第1卷：长篇论文）*，Lun-Wei
    Ku, Andre Martins, 和 Vivek Srikumar（编）。计算语言学协会，泰国曼谷，5606–5627。[https://doi.org/10.18653/v1/2024.acl-long.304](https://doi.org/10.18653/v1/2024.acl-long.304)'
- en: 'Song et al. (2023) C. Song, B. M. Sadler, J. Wu, W. Chao, C. Washington, and
    Y. Su. 2023. LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with
    Large Language Models. In *2023 IEEE/CVF International Conference on Computer
    Vision (ICCV)*. IEEE Computer Society, Los Alamitos, CA, USA, 2986–2997. [https://doi.org/10.1109/ICCV51070.2023.00280](https://doi.org/10.1109/ICCV51070.2023.00280)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Song et al. (2023) C. Song, B. M. Sadler, J. Wu, W. Chao, C. Washington, 和
    Y. Su. 2023. 《LLM-Planner：使用大型语言模型进行面向具体任务的少样本规划》（LLM-Planner: Few-Shot Grounded
    Planning for Embodied Agents with Large Language Models）。发表于 *2023年IEEE/CVF计算机视觉国际会议（ICCV
    2023）*。IEEE计算机学会，美国加州洛斯阿拉米托斯，2986–2997。[https://doi.org/10.1109/ICCV51070.2023.00280](https://doi.org/10.1109/ICCV51070.2023.00280)'
- en: 'Srivastava et al. (2023) Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
    Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya
    Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal,
    Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali
    Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda
    Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Johan Andreassen,
    Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La,
    Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta,
    Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum,
    Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick,
    Avia Efrat, Aykut Erdem, Ayla Karakaş, B. Ryan Roberts, Bao Sheng Loe, Barret
    Zoph, Bartłomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur,
    Benjamin Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan
    Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cesar
    Ferri, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu,
    Chris Callison-Burch, Christopher Waites, Christian Voigt, Christopher D Manning,
    Christopher Potts, Cindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel,
    Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks,
    Dan Kilman, Dan Roth, C. Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí
    González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar
    Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli,
    Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes,
    Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan
    Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth
    Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu,
    Eric Tang, Erkut Erdem, Ernie Chang, Ethan A Chi, Ethan Dyer, Ethan Jerzak, Ethan
    Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar,
    Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav
    Mishra, Genta Indra Winata, Gerard de Melo, Germán Kruszewski, Giambattista Parascandolo,
    Giorgio Mariani, Gloria Xinyue Wang, Gonzalo Jaimovitch-Lopez, Gregor Betz, Guy
    Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh
    Mehta, Hayden Bogar, Henry Francis Anthony Shevlin, Hinrich Schuetze, Hiromu Yakura,
    Hongming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger,
    Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B Simon,
    James Koppel, James Zheng, James Zou, Jan Kocon, Jana Thompson, Janelle Wingfield,
    Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason Wei, Jason
    Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen
    Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Joan
    Waweru, John Burden, John Miller, John U. Balis, Jonathan Batchelder, Jonathan
    Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph Boudeman, Joseph
    Guerr, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz,
    Karen Livescu, Karl Krauth, Karthik Gopalakrishnan, Katerina Ignatyeva, Katja
    Markert, Kaustubh Dhole, Kevin Gimpel, Kevin Omondi, Kory Wallace Mathewson, Kristen
    Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle Richardson, Laria
    Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando,
    Louis-Philippe Morency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt,
    Luheng He, Luis Oliveros-Colón, Luke Metz, Lütfi Kerem Senel, Maarten Bosma, Maarten
    Sap, Maartje Ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco
    Baturan, Marco Marelli, Marco Maru, Maria Jose Ramirez-Quintana, Marie Tolkiehn,
    Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L Leavitt, Matthias
    Hagen, Mátyás Schubert, Medina Orduna Baitemirova, Melody Arnaud, Melvin McElrath,
    Michael Andrew Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt,
    Michael Strube, Michał Sw\kedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir
    Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mohit Bansal,
    Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan Andrew
    Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron, Nicholas Roberts, Nick
    Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niklas Muennighoff, Nitish Shirish
    Keskar, Niveditha S. Iyer, Noah Constant, Noah Fiedel, Nuan Wen, Oliver Zhang,
    Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio Moreno Casares,
    Parth Doshi, Pascale Fung, Paul Pu Liang, Paul Vicol, Pegah Alipoormolabashi,
    Peiyuan Liao, Percy Liang, Peter W Chang, Peter Eckersley, Phu Mon Htut, Pinyu
    Hwang, Piotr Miłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei,
    Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel, Rahel
    Habacker, Ramon Risco, Raphaël Millière, Rhythm Garg, Richard Barnes, Rif A. Saurous,
    Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan Sikand, Roman Novak, Roman
    Sitelew, Ronan Le Bras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Russ Salakhutdinov,
    Ryan Andrew Chi, Seungjae Ryan Lee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib
    Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman,
    Samuel Gruetter, Samuel R. Bowman, Samuel Stern Schoenholz, Sanghyun Han, Sanjeev
    Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey, Sebastian Bischoff,
    Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon
    Zhou, Shashank Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang Shane
    Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima Shammie Debnath,
    Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini,
    Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic,
    Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven Piantadosi,
    Stuart Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen,
    Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsunori Hashimoto, Te-Lin Wu, Théo
    Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo
    Schick, Timofei Kornev, Titus Tunduny, Tobias Gerstenberg, Trenton Chang, Trishala
    Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria
    Nyamai, Vikas Raunak, Vinay Venkatesh Ramasesh, vinay uday prabhu, Vishakh Padmakumar,
    Vivek Srikumar, William Fedus, William Saunders, William Zhang, Wout Vossen, Xiang
    Ren, Xiaoyu Tong, Xinran Zhao, Xinyi Wu, Xudong Shen, Yadollah Yaghoobzadeh, Yair
    Lakretz, Yangqiu Song, Yasaman Bahri, Yejin Choi, Yichi Yang, Yiding Hao, Yifu
    Chen, Yonatan Belinkov, Yu Hou, Yufang Hou, Yuntao Bai, Zachary Seid, Zhuoye Zhao,
    Zijian Wang, Zijie J. Wang, Zirui Wang, and Ziyi Wu. 2023. Beyond the Imitation
    Game: Quantifying and extrapolating the capabilities of language models. *Transactions
    on Machine Learning Research* (2023). [https://openreview.net/forum?id=uyTL5Bvosj](https://openreview.net/forum?id=uyTL5Bvosj)'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava 等人（2023）Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal
    Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta,
    Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea
    Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv,
    Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza,
    Ambrose Slone, Ameet Rahane, Anantharaman S. Iyer, Anders Johan Andreassen, Andrea
    Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La, Andrew
    Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna
    Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum,
    Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick,
    Avia Efrat, Aykut Erdem, Ayla Karakaş, B. Ryan Roberts, Bao Sheng Loe, Barret
    Zoph, Bartłomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur,
    Benjamin Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan
    Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cesar
    Ferri, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu,
    Chris Callison-Burch, Christopher Waites, Christian Voigt, Christopher D Manning,
    Christopher Potts, Cindy Ramirez, Clara E. Rivera, Clemencia Siro, Colin Raffel,
    Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks,
    Dan Kilman, Dan Roth, C. Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel
    Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito,
    Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli,
    Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes,
    Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan
    Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth
    Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu,
    Eric Tang, Erkut Erdem, Ernie Chang, Ethan A Chi, Ethan Dyer, Ethan Jerzak, Ethan
    Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar,
    Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav
    Mishra, Genta Indra Winata, Gerard de Melo, Germán Kruszewski, Giambattista Parascandolo,
    Giorgio Mariani, Gloria Xinyue Wang, Gonzalo Jaimovitch-Lopez, Gregor Betz, Guy
    Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh
    Mehta, Hayden Bogar, Henry Francis Anthony Shevlin, Hinrich Schuetze, Hiromu Yakura,
    Hongming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger,
    Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B Simon,
    James Koppel, James Zheng, James Zou, Jan Kocon, Jana Thompson, Janelle Wingfield,
    Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason Wei, Jason
    Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen
    Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Joan
    Waweru, John Burden, John Miller, John U. Balis, Jonathan Batchelder, Jonathan
    Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph Boudeman, Joseph
    Guerr, Joseph Jones, Joshua B. Tenenbaum, Joshua S. Rule, Joyce Chua, Kamil Kanclerz,
    Karen Livescu, Karl Krauth, Karthik Gopalakrishnan, Katerina Ignatyeva, Katja
    Markert, Kaustubh Dhole, Kevin Gimpel, Kevin Omondi, Kory Wallace Mathewson, Kristen
    Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle McDonell, Kyle Richardson, Laria
    Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando,
    Louis-Philippe Morency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt,
    Luheng He, Luis Oliveros-Colón, Luke Metz, Lütfi Kerem Senel, Maarten Bosma, Maarten
    Sap, Maartje Ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco
    Baturan, Marco Marelli, Marco Maru, Maria Jose Ramirez-Quintana, Marie Tolkiehn,
    Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L Leavitt, Matthias
    Hagen, Mátyás Schubert, Medina Orduna Baitemirova, Melody Arnaud, Melvin McElrath,
    Michael Andrew Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt,
    Michael Strube, Michał Sw\kedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir
    Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mohit Bansal,
    Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma T, Nanyun Peng, Nathan
    Andrew Chi, Nayeon Lee, Neta Gur-Ari Krakover, Nicholas Cameron, Nicholas Roberts,
    Nick Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niklas Muennighoff,
    Nitish Shirish Keskar, Niveditha S. Iyer, Noah Constant, Noah Fiedel, Nuan Wen,
    Oliver Zhang, Omar Agha, Omar Elbaghdadi, Omer Levy, Owain Evans, Pablo Antonio
    Moreno Casares, Parth Doshi, Pascale Fung, Paul Pu Liang, Paul Vicol, Pegah Alipoormolabashi,
    Peiyuan Liao, Percy Liang, Peter W Chang, Peter Eckersley, Phu Mon Htut, Pinyu
    Hwang, Piotr Miłkowski, Piyush Patil, Pouya Pezeshkpour, Priti Oli, Qiaozhu Mei,
    Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Etta Rudolph, Raefer Gabriel, Rahel
    Habacker, Ramon Risco, Raphaël Millière, Rhythm Garg, Richard Barnes, Rif A. Saurous,
    Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan Sikand, Roman Novak, Roman
    Sitelew, Ronan Le Bras, Rosanne Liu, Rowan Jacobs, Rui Zhang, Russ Salakhutdinov,
    Ryan Andrew Chi, Seungjae Ryan Lee, Ryan Stovall, Ryan Teehan, Rylan Yang, Sahib
    Singh, Saif M. Mohammad, Sajant Anand, Sam Dillavou, Sam Shleifer, Sam Wiseman,
    Samuel Gruetter, Samuel R. Bowman, Samuel Stern Schoenholz, Sanghyun Han, Sanjeev
    Kwatra, Sarah A. Rous, Sarik Ghazarian, Sayan Ghosh, Sean Casey, Sebastian Bischoff,
    Sebastian Gehrmann, Sebastian Schuster, Sepideh Sadeghi, Shadi Hamdan, Sharon
    Zhou, Shashank Srivastava, Sherry Shi, Shikhar Singh, Shima Asaadi, Shixiang Shane
    Gu, Shubh Pachchigar, Shubham Toshniwal, Shyam Upadhyay, Shyamolima Shammie Debnath,
    Siamak Shakeri, Simon Thormeyer, Simone Melzi, Siva Reddy, Sneha Priscilla Makini,
    Soo-Hwan Lee, Spencer Torene, Sriharsha Hatwar, Stanislas Dehaene, Stefan Divic,
    Stefano Ermon, Stella Biderman, Stephanie Lin, Stephen Prasad, Steven Piantadosi,
    Stuart Shieber, Summer Misherghi, Svetlana Kiritchenko, Swaroop Mishra, Tal Linzen,
    Tal Schuster, Tao Li, Tao Yu, Tariq Ali, Tatsunori Hashimoto, Te-Lin Wu, Théo
    Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Tiberius Nkinyili, Timo
    Schick, Timofei Kornev, Titus Tunduny, Tobias
- en: 'Tam et al. (2024) Zhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-Yen Lin,
    Hung-yi Lee, and Yun-Nung Chen. 2024. Let Me Speak Freely? A Study On The Impact
    Of Format Restrictions On Large Language Model Performance.. In *Proceedings of
    the 2024 Conference on Empirical Methods in Natural Language Processing: Industry
    Track*, Franck Dernoncourt, Daniel Preoţiuc-Pietro, and Anastasia Shimorina (Eds.).
    Association for Computational Linguistics, Miami, Florida, US, 1218–1236. [https://doi.org/10.18653/v1/2024.emnlp-industry.91](https://doi.org/10.18653/v1/2024.emnlp-industry.91)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tam 等人（2024）Zhi Rui Tam、Cheng-Kuang Wu、Yi-Lin Tsai、Chieh-Yen Lin、Hung-yi Lee
    和 Yun-Nung Chen。2024年。**让我自由表达？**关于格式限制对大型语言模型性能影响的研究。载于 *2024年自然语言处理实证方法会议：行业专场论文集*，Franck
    Dernoncourt、Daniel Preoţiuc-Pietro 和 Anastasia Shimorina（编辑）。计算语言学会，迈阿密，佛罗里达州，美国，1218–1236。[https://doi.org/10.18653/v1/2024.emnlp-industry.91](https://doi.org/10.18653/v1/2024.emnlp-industry.91)
- en: 'Team et al. (2024) Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste
    Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth,
    Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser,
    Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou,
    Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom Hennigan, Benjamin
    Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens
    Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, Jack Krawczyk,
    Cosmo Du, Ed Chi, Heng-Tze Cheng, Eric Ni, Purvi Shah, Patrick Kane, Betty Chan,
    Manaal Faruqui, Aliaksei Severyn, Hanzhao Lin, YaGuang Li, Yong Cheng, Abe Ittycheriah,
    Mahdis Mahdieh, Mia Chen, Pei Sun, Dustin Tran, Sumit Bagri, Balaji Lakshminarayanan,
    Jeremiah Liu, Andras Orban, Fabian Güra, Hao Zhou, Xinying Song, Aurelien Boffy,
    Harish Ganapathy, Steven Zheng, HyunJeong Choe, Ágoston Weisz, Tao Zhu, Yifeng
    Lu, Siddharth Gopal, Jarrod Kahn, Maciej Kula, Jeff Pitman, Rushin Shah, Emanuel
    Taropa, Majd Al Merey, Martin Baeuml, Zhifeng Chen, Laurent El Shafey, Yujing
    Zhang, Olcan Sercinoglu, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr,
    Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen,
    Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman,
    Jakub Sygnowski, Alexandre Frechette, Charlotte Smith, Laura Culp, Lev Proleev,
    Yi Luan, Xi Chen, James Lottes, Nathan Schucher, Federico Lebron, Alban Rrustemi,
    Natalie Clay, Phil Crone, Tomas Kocisky, Jeffrey Zhao, Bartek Perz, Dian Yu, Heidi
    Howard, Adam Bloniarz, Jack W. Rae, Han Lu, Laurent Sifre, Marcello Maggioni,
    Fred Alcober, Dan Garrette, Megan Barnes, Shantanu Thakoor, Jacob Austin, Gabriel
    Barth-Maron, William Wong, Rishabh Joshi, Rahma Chaabouni, Deeni Fatiha, Arun
    Ahuja, Gaurav Singh Tomar, Evan Senter, Martin Chadwick, Ilya Kornakov, Nithya
    Attaluri, Iñaki Iturrate, Ruibo Liu, Yunxuan Li, Sarah Cogan, Jeremy Chen, Chao
    Jia, Chenjie Gu, Qiao Zhang, Jordan Grimstad, Ale Jakse Hartman, Xavier Garcia,
    Thanumalayan Sankaranarayana Pillai, Jacob Devlin, Michael Laskin, Diego de Las Casas,
    Dasha Valter, Connie Tao, Lorenzo Blanco, Adrià Puigdomènech Badia, David Reitter,
    Mianna Chen, Jenny Brennan, Clara Rivera, Sergey Brin, Shariq Iqbal, Gabriela
    Surita, Jane Labanowski, Abhi Rao, Stephanie Winkler, Emilio Parisotto, Yiming
    Gu, Kate Olszewska, Ravi Addanki, Antoine Miech, Annie Louis, Denis Teplyashin,
    Geoff Brown, Elliot Catt, Jan Balaguer, Jackie Xiang, Pidong Wang, Zoe Ashwood,
    Anton Briukhov, Albert Webson, Sanjay Ganapathy, Smit Sanghavi, Ajay Kannan, Ming-Wei
    Chang, Axel Stjerngren, Josip Djolonga, Yuting Sun, Ankur Bapna, Matthew Aitchison,
    Pedram Pejman, Henryk Michalewski, Tianhe Yu, Cindy Wang, Juliette Love, Junwhan
    Ahn, Dawn Bloxwich, Kehang Han, Peter Humphreys, Thibault Sellam, James Bradbury,
    Varun Godbole, Sina Samangooei, Bogdan Damoc, Alex Kaskasoli, Sébastien M. R.
    Arnold, Vijay Vasudevan, Shubham Agrawal, Jason Riesa, Dmitry Lepikhin, Richard
    Tanburn, Srivatsan Srinivasan, Hyeontaek Lim, Sarah Hodkinson, Pranav Shyam, Johan
    Ferret, Steven Hand, Ankush Garg, Tom Le Paine, Jian Li, Yujia Li, Minh Giang,
    Alexander Neitz, Zaheer Abbas, Sarah York, Machel Reid, Elizabeth Cole, Aakanksha
    Chowdhery, Dipanjan Das, Dominika Rogozińska, Vitaliy Nikolaev, Pablo Sprechmann,
    Zachary Nado, Lukas Zilka, Flavien Prost, Luheng He, Marianne Monteiro, Gaurav
    Mishra, Chris Welty, Josh Newlan, Dawei Jia, Miltiadis Allamanis, Clara Huiyi
    Hu, Raoul de Liedekerke, Justin Gilmer, Carl Saroufim, Shruti Rijhwani, Shaobo
    Hou, Disha Shrivastava, Anirudh Baddepudi, Alex Goldin, Adnan Ozturel, Albin Cassirer,
    Yunhan Xu, Daniel Sohn, Devendra Sachan, Reinald Kim Amplayo, Craig Swanson, Dessie
    Petrova, Shashi Narayan, Arthur Guez, Siddhartha Brahma, Jessica Landon, Miteyan
    Patel, Ruizhe Zhao, Kevin Villela, Luyu Wang, Wenhao Jia, Matthew Rahtz, Mai Giménez,
    Legg Yeung, James Keeling, Petko Georgiev, Diana Mincu, Boxi Wu, Salem Haykal,
    Rachel Saputro, Kiran Vodrahalli, James Qin, Zeynep Cankara, Abhanshu Sharma,
    Nick Fernando, Will Hawkins, Behnam Neyshabur, Solomon Kim, Adrian Hutter, Priyanka
    Agrawal, Alex Castro-Ros, George van den Driessche, Tao Wang, Fan Yang, Shuo yiin
    Chang, Paul Komarek, Ross McIlroy, Mario Lučić, Guodong Zhang, Wael Farhan, Michael
    Sharman, Paul Natsev, Paul Michel, Yamini Bansal, Siyuan Qiao, Kris Cao, Siamak
    Shakeri, Christina Butterfield, Justin Chung, Paul Kishan Rubenstein, Shivani
    Agrawal, Arthur Mensch, Kedar Soparkar, Karel Lenc, Timothy Chung, Aedan Pope,
    Loren Maggiore, Jackie Kay, Priya Jhakra, Shibo Wang, Joshua Maynez, Mary Phuong,
    Taylor Tobin, Andrea Tacchetti, Maja Trebacz, Kevin Robinson, Yash Katariya, Sebastian
    Riedel, Paige Bailey, Kefan Xiao, Nimesh Ghelani, Lora Aroyo, Ambrose Slone, Neil
    Houlsby, Xuehan Xiong, Zhen Yang, Elena Gribovskaya, Jonas Adler, Mateo Wirth,
    Lisa Lee, Music Li, Thais Kagohara, Jay Pavagadhi, Sophie Bridgers, Anna Bortsova,
    Sanjay Ghemawat, Zafarali Ahmed, Tianqi Liu, Richard Powell, Vijay Bolina, Mariko
    Iinuma, Polina Zablotskaia, James Besley, Da-Woon Chung, Timothy Dozat, Ramona
    Comanescu, Xiance Si, Jeremy Greer, Guolong Su, Martin Polacek, Raphaël Lopez
    Kaufman, Simon Tokumine, Hexiang Hu, Elena Buchatskaya, Yingjie Miao, Mohamed
    Elhawaty, Aditya Siddhant, Nenad Tomasev, Jinwei Xing, Christina Greer, Helen
    Miller, Shereen Ashraf, Aurko Roy, Zizhao Zhang, Ada Ma, Angelos Filos, Milos
    Besta, Rory Blevins, Ted Klimenko, Chih-Kuan Yeh, Soravit Changpinyo, Jiaqi Mu,
    Oscar Chang, Mantas Pajarskas, Carrie Muir, Vered Cohen, Charline Le Lan, Krishna
    Haridasan, Amit Marathe, Steven Hansen, Sholto Douglas, Rajkumar Samuel, Mingqiu
    Wang, Sophia Austin, Chang Lan, Jiepu Jiang, Justin Chiu, Jaime Alonso Lorenzo,
    Lars Lowe Sjösund, Sébastien Cevey, Zach Gleicher, Thi Avrahami, Anudhyan Boral,
    Hansa Srinivasan, Vittorio Selo, Rhys May, Konstantinos Aisopos, Léonard Hussenot,
    Livio Baldini Soares, Kate Baumli, Michael B. Chang, Adrià Recasens, Ben Caine,
    Alexander Pritzel, Filip Pavetic, Fabio Pardo, Anita Gergely, Justin Frye, Vinay
    Ramasesh, Dan Horgan, Kartikeya Badola, Nora Kassner, Subhrajit Roy, Ethan Dyer,
    Víctor Campos Campos, Alex Tomala, Yunhao Tang, Dalia El Badawy, Elspeth White,
    Basil Mustafa, Oran Lang, Abhishek Jindal, Sharad Vikram, Zhitao Gong, Sergi Caelles,
    Ross Hemsley, Gregory Thornton, Fangxiaoyu Feng, Wojciech Stokowiec, Ce Zheng,
    Phoebe Thacker, Çağlar Ünlü, Zhishuai Zhang, Mohammad Saleh, James Svensson, Max
    Bileschi, Piyush Patil, Ankesh Anand, Roman Ring, Katerina Tsihlas, Arpi Vezer,
    Marco Selvi, Toby Shevlane, Mikel Rodriguez, Tom Kwiatkowski, Samira Daruki, Keran
    Rong, Allan Dafoe, Nicholas FitzGerald, Keren Gu-Lemberg, Mina Khan, Lisa Anne
    Hendricks, Marie Pellat, Vladimir Feinberg, James Cobon-Kerr, Tara Sainath, Maribeth
    Rauh, Sayed Hadi Hashemi, Richard Ives, Yana Hasson, Eric Noland, Yuan Cao, Nathan
    Byrd, Le Hou, Qingze Wang, Thibault Sottiaux, Michela Paganini, Jean-Baptiste
    Lespiau, Alexandre Moufarek, Samer Hassan, Kaushik Shivakumar, Joost van Amersfoort,
    Amol Mandhane, Pratik Joshi, Anirudh Goyal, Matthew Tung, Andrew Brock, Hannah
    Sheahan, Vedant Misra, Cheng Li, Nemanja Rakićević, Mostafa Dehghani, Fangyu Liu,
    Sid Mittal, Junhyuk Oh, Seb Noury, Eren Sezener, Fantine Huot, Matthew Lamm, Nicola De
    Cao, Charlie Chen, Sidharth Mudgal, Romina Stella, Kevin Brooks, Gautam Vasudevan,
    Chenxi Liu, Mainak Chain, Nivedita Melinkeri, Aaron Cohen, Venus Wang, Kristie
    Seymore, Sergey Zubkov, Rahul Goel, Summer Yue, Sai Krishnakumaran, Brian Albert,
    Nate Hurley, Motoki Sano, Anhad Mohananey, Jonah Joughin, Egor Filonov, Tomasz
    Kępa, Yomna Eldawy, Jiawern Lim, Rahul Rishi, Shirin Badiezadegan, Taylor Bos,
    Jerry Chang, Sanil Jain, Sri Gayatri Sundara Padmanabhan, Subha Puttagunta, Kalpesh
    Krishna, Leslie Baker, Norbert Kalb, Vamsi Bedapudi, Adam Kurzrok, Shuntong Lei,
    Anthony Yu, Oren Litvin, Xiang Zhou, Zhichun Wu, Sam Sobell, Andrea Siciliano,
    Alan Papir, Robby Neale, Jonas Bragagnolo, Tej Toor, Tina Chen, Valentin Anklin,
    Feiran Wang, Richie Feng, Milad Gholami, Kevin Ling, Lijuan Liu, Jules Walter,
    Hamid Moghaddam, Arun Kishore, Jakub Adamek, Tyler Mercado, Jonathan Mallinson,
    Siddhinita Wandekar, Stephen Cagle, Eran Ofek, Guillermo Garrido, Clemens Lombriser,
    Maksim Mukha, Botu Sun, Hafeezul Rahman Mohammad, Josip Matak, Yadi Qian, Vikas
    Peswani, Pawel Janus, Quan Yuan, Leif Schelin, Oana David, Ankur Garg, Yifan He,
    Oleksii Duzhyi, Anton Älgmyr, Timothée Lottaz, Qi Li, Vikas Yadav, Luyao Xu, Alex
    Chinien, Rakesh Shivanna, Aleksandr Chuklin, Josie Li, Carrie Spadine, Travis
    Wolfe, Kareem Mohamed, Subhabrata Das, Zihang Dai, Kyle He, Daniel von Dincklage,
    Shyam Upadhyay, Akanksha Maurya, Luyan Chi, Sebastian Krause, Khalid Salama, Pam G
    Rabinovitch, Pavan Kumar Reddy M, Aarush Selvan, Mikhail Dektiarev, Golnaz Ghiasi,
    Erdem Guven, Himanshu Gupta, Boyi Liu, Deepak Sharma, Idan Heimlich Shtacher,
    Shachi Paul, Oscar Akerlund, François-Xavier Aubet, Terry Huang, Chen Zhu, Eric
    Zhu, Elico Teixeira, Matthew Fritze, Francesco Bertolini, Liana-Eleonora Marinescu,
    Martin Bölle, Dominik Paulus, Khyatti Gupta, Tejasi Latkar, Max Chang, Jason Sanders,
    Roopa Wilson, Xuewei Wu, Yi-Xuan Tan, Lam Nguyen Thiet, Tulsee Doshi, Sid Lall,
    Swaroop Mishra, Wanming Chen, Thang Luong, Seth Benjamin, Jasmine Lee, Ewa Andrejczuk,
    Dominik Rabiej, Vipul Ranjan, Krzysztof Styrc, Pengcheng Yin, Jon Simon, Malcolm Rose
    Harriott, Mudit Bansal, Alexei Robsky, Geoff Bacon, David Greene, Daniil Mirylenka,
    Chen Zhou, Obaid Sarvana, Abhimanyu Goyal, Samuel Andermatt, Patrick Siegler,
    Ben Horn, Assaf Israel, Francesco Pongetti, Chih-Wei ”Louis” Chen, Marco Selvatici,
    Pedro Silva, Kathie Wang, Jackson Tolins, Kelvin Guu, Roey Yogev, Xiaochen Cai,
    Alessandro Agostini, Maulik Shah, Hung Nguyen, Noah Ó Donnaile, Sébastien Pereira,
    Linda Friso, Adam Stambler, Adam Kurzrok, Chenkai Kuang, Yan Romanikhin, Mark
    Geller, ZJ Yan, Kane Jang, Cheng-Chun Lee, Wojciech Fica, Eric Malmi, Qijun Tan,
    Dan Banica, Daniel Balle, Ryan Pham, Yanping Huang, Diana Avram, Hongzhi Shi,
    Jasjot Singh, Chris Hidey, Niharika Ahuja, Pranab Saxena, Dan Dooley, Srividya Pranavi
    Potharaju, Eileen O’Neill, Anand Gokulchandran, Ryan Foley, Kai Zhao, Mike Dusenberry,
    Yuan Liu, Pulkit Mehta, Ragha Kotikalapudi, Chalence Safranek-Shrader, Andrew
    Goodman, Joshua Kessinger, Eran Globen, Prateek Kolhar, Chris Gorgolewski, Ali
    Ibrahim, Yang Song, Ali Eichenbaum, Thomas Brovelli, Sahitya Potluri, Preethi
    Lahoti, Cip Baetu, Ali Ghorbani, Charles Chen, Andy Crawford, Shalini Pal, Mukund
    Sridhar, Petru Gurita, Asier Mujika, Igor Petrovski, Pierre-Louis Cedoz, Chenmei
    Li, Shiyuan Chen, Niccolò Dal Santo, Siddharth Goyal, Jitesh Punjabi, Karthik
    Kappaganthu, Chester Kwak, Pallavi LV, Sarmishta Velury, Himadri Choudhury, Jamie
    Hall, Premal Shah, Ricardo Figueira, Matt Thomas, Minjie Lu, Ting Zhou, Chintu
    Kumar, Thomas Jurdi, Sharat Chikkerur, Yenai Ma, Adams Yu, Soo Kwak, Victor Ähdel,
    Sujeevan Rajayogam, Travis Choma, Fei Liu, Aditya Barua, Colin Ji, Ji Ho Park,
    Vincent Hellendoorn, Alex Bailey, Taylan Bilal, Huanjie Zhou, Mehrdad Khatir,
    Charles Sutton, Wojciech Rzadkowski, Fiona Macintosh, Konstantin Shagin, Paul
    Medina, Chen Liang, Jinjing Zhou, Pararth Shah, Yingying Bi, Attila Dankovics,
    Shipra Banga, Sabine Lehmann, Marissa Bredesen, Zifan Lin, John Eric Hoffmann,
    Jonathan Lai, Raynald Chung, Kai Yang, Nihal Balani, Arthur Bražinskas, Andrei
    Sozanschi, Matthew Hayes, Héctor Fernández Alcalde, Peter Makarov, Will Chen,
    Antonio Stella, Liselotte Snijders, Michael Mandl, Ante Kärrman, Paweł Nowak,
    Xinyi Wu, Alex Dyck, Krishnan Vaidyanathan, Raghavender R, Jessica Mallet, Mitch
    Rudominer, Eric Johnston, Sushil Mittal, Akhil Udathu, Janara Christensen, Vishal
    Verma, Zach Irving, Andreas Santucci, Gamaleldin Elsayed, Elnaz Davoodi, Marin
    Georgiev, Ian Tenney, Nan Hua, Geoffrey Cideron, Edouard Leurent, Mahmoud Alnahlawi,
    Ionut Georgescu, Nan Wei, Ivy Zheng, Dylan Scandinaro, Heinrich Jiang, Jasper
    Snoek, Mukund Sundararajan, Xuezhi Wang, Zack Ontiveros, Itay Karo, Jeremy Cole,
    Vinu Rajashekhar, Lara Tumeh, Eyal Ben-David, Rishub Jain, Jonathan Uesato, Romina
    Datta, Oskar Bunyan, Shimu Wu, John Zhang, Piotr Stanczyk, Ye Zhang, David Steiner,
    Subhajit Naskar, Michael Azzam, Matthew Johnson, Adam Paszke, Chung-Cheng Chiu,
    Jaume Sanchez Elias, Afroz Mohiuddin, Faizan Muhammad, Jin Miao, Andrew Lee, Nino
    Vieillard, Jane Park, Jiageng Zhang, Jeff Stanway, Drew Garmon, Abhijit Karmarkar,
    Zhe Dong, Jong Lee, Aviral Kumar, Luowei Zhou, Jonathan Evens, William Isaac,
    Geoffrey Irving, Edward Loper, Michael Fink, Isha Arkatkar, Nanxin Chen, Izhak
    Shafran, Ivan Petrychenko, Zhe Chen, Johnson Jia, Anselm Levskaya, Zhenkai Zhu,
    Peter Grabowski, Yu Mao, Alberto Magni, Kaisheng Yao, Javier Snaider, Norman Casagrande,
    Evan Palmer, Paul Suganthan, Alfonso Castaño, Irene Giannoumis, Wooyeol Kim, Mikołaj
    Rybiński, Ashwin Sreevatsa, Jennifer Prendki, David Soergel, Adrian Goedeckemeyer,
    Willi Gierke, Mohsen Jafari, Meenu Gaba, Jeremy Wiesner, Diana Gage Wright, Yawen
    Wei, Harsha Vashisht, Yana Kulizhskaya, Jay Hoover, Maigo Le, Lu Li, Chimezie
    Iwuanyanwu, Lu Liu, Kevin Ramirez, Andrey Khorlin, Albert Cui, Tian LIN, Marcus
    Wu, Ricardo Aguilar, Keith Pallo, Abhishek Chakladar, Ginger Perng, Elena Allica
    Abellan, Mingyang Zhang, Ishita Dasgupta, Nate Kushman, Ivo Penchev, Alena Repina,
    Xihui Wu, Tom van der Weide, Priya Ponnapalli, Caroline Kaplan, Jiri Simsa, Shuangfeng
    Li, Olivier Dousse, Fan Yang, Jeff Piper, Nathan Ie, Rama Pasumarthi, Nathan Lintz,
    Anitha Vijayakumar, Daniel Andor, Pedro Valenzuela, Minnie Lui, Cosmin Paduraru,
    Daiyi Peng, Katherine Lee, Shuyuan Zhang, Somer Greene, Duc Dung Nguyen, Paula
    Kurylowicz, Cassidy Hardin, Lucas Dixon, Lili Janzer, Kiam Choo, Ziqiang Feng,
    Biao Zhang, Achintya Singhal, Dayou Du, Dan McKinnon, Natasha Antropova, Tolga
    Bolukbasi, Orgad Keller, David Reid, Daniel Finchelstein, Maria Abi Raad, Remi
    Crocker, Peter Hawkins, Robert Dadashi, Colin Gaffney, Ken Franko, Anna Bulanova,
    Rémi Leblond, Shirley Chung, Harry Askham, Luis C. Cobo, Kelvin Xu, Felix Fischer,
    Jun Xu, Christina Sorokin, Chris Alberti, Chu-Cheng Lin, Colin Evans, Alek Dimitriev,
    Hannah Forbes, Dylan Banarse, Zora Tung, Mark Omernick, Colton Bishop, Rachel
    Sterneck, Rohan Jain, Jiawei Xia, Ehsan Amid, Francesco Piccinno, Xingyu Wang,
    Praseem Banzal, Daniel J. Mankowitz, Alex Polozov, Victoria Krakovna, Sasha Brown,
    MohammadHossein Bateni, Dennis Duan, Vlad Firoiu, Meghana Thotakuri, Tom Natan,
    Matthieu Geist, Ser tan Girgin, Hui Li, Jiayu Ye, Ofir Roval, Reiko Tojo, Michael
    Kwong, James Lee-Thorp, Christopher Yew, Danila Sinopalnikov, Sabela Ramos, John
    Mellor, Abhishek Sharma, Kathy Wu, David Miller, Nicolas Sonnerat, Denis Vnukov,
    Rory Greig, Jennifer Beattie, Emily Caveness, Libin Bai, Julian Eisenschlos, Alex
    Korchemniy, Tomy Tsai, Mimi Jasarevic, Weize Kong, Phuong Dao, Zeyu Zheng, Frederick
    Liu, Fan Yang, Rui Zhu, Tian Huey Teh, Jason Sanmiya, Evgeny Gladchenko, Nejc
    Trdin, Daniel Toyama, Evan Rosen, Sasan Tavakkol, Linting Xue, Chen Elkind, Oliver
    Woodman, John Carpenter, George Papamakarios, Rupert Kemp, Sushant Kafle, Tanya
    Grunina, Rishika Sinha, Alice Talbert, Diane Wu, Denese Owusu-Afriyie, Cosmo Du,
    Chloe Thornton, Jordi Pont-Tuset, Pradyumna Narayana, Jing Li, Saaber Fatehi,
    John Wieting, Omar Ajmeri, Benigno Uria, Yeongil Ko, Laura Knight, Amélie Héliou,
    Ning Niu, Shane Gu, Chenxi Pang, Yeqing Li, Nir Levine, Ariel Stolovich, Rebeca
    Santamaria-Fernandez, Sonam Goenka, Wenny Yustalim, Robin Strudel, Ali Elqursh,
    Charlie Deck, Hyo Lee, Zonglin Li, Kyle Levin, Raphael Hoffmann, Dan Holtmann-Rice,
    Olivier Bachem, Sho Arora, Christy Koh, Soheil Hassas Yeganeh, Siim Põder, Mukarram
    Tariq, Yanhua Sun, Lucian Ionita, Mojtaba Seyedhosseini, Pouya Tafti, Zhiyu Liu,
    Anmol Gulati, Jasmine Liu, Xinyu Ye, Bart Chrzaszcz, Lily Wang, Nikhil Sethi,
    Tianrun Li, Ben Brown, Shreya Singh, Wei Fan, Aaron Parisi, Joe Stanton, Vinod
    Koverkathu, Christopher A. Choquette-Choo, Yunjie Li, TJ Lu, Abe Ittycheriah,
    Prakash Shroff, Mani Varadarajan, Sanaz Bahargam, Rob Willoughby, David Gaddy,
    Guillaume Desjardins, Marco Cornero, Brona Robenek, Bhavishya Mittal, Ben Albrecht,
    Ashish Shenoy, Fedor Moiseev, Henrik Jacobsson, Alireza Ghaffarkhah, Morgane Rivière,
    Alanna Walton, Clément Crepy, Alicia Parrish, Zongwei Zhou, Clement Farabet, Carey
    Radebaugh, Praveen Srinivasan, Claudia van der Salm, Andreas Fidjeland, Salvatore
    Scellato, Eri Latorre-Chimoto, Hanna Klimczak-Plucińska, David Bridson, Dario
    de Cesare, Tom Hudson, Piermaria Mendolicchio, Lexi Walker, Alex Morris, Matthew
    Mauger, Alexey Guseynov, Alison Reid, Seth Odoom, Lucia Loher, Victor Cotruta,
    Madhavi Yenugula, Dominik Grewe, Anastasia Petrushkina, Tom Duerig, Antonio Sanchez,
    Steve Yadlowsky, Amy Shen, Amir Globerson, Lynette Webb, Sahil Dua, Dong Li, Surya
    Bhupatiraju, Dan Hurt, Haroon Qureshi, Ananth Agarwal, Tomer Shani, Matan Eyal,
    Anuj Khare, Shreyas Rammohan Belle, Lei Wang, Chetan Tekur, Mihir Sanjay Kale,
    Jinliang Wei, Ruoxin Sang, Brennan Saeta, Tyler Liechty, Yi Sun, Yao Zhao, Stephan
    Lee, Pandu Nayak, Doug Fritz, Manish Reddy Vuyyuru, John Aslanides, Nidhi Vyas,
    Martin Wicke, Xiao Ma, Evgenii Eltyshev, Nina Martin, Hardie Cate, James Manyika,
    Keyvan Amiri, Yelin Kim, Xi Xiong, Kai Kang, Florian Luisier, Nilesh Tripuraneni,
    David Madras, Mandy Guo, Austin Waters, Oliver Wang, Joshua Ainslie, Jason Baldridge,
    Han Zhang, Garima Pruthi, Jakob Bauer, Feng Yang, Riham Mansour, Jason Gelman,
    Yang Xu, George Polovets, Ji Liu, Honglong Cai, Warren Chen, XiangHai Sheng, Emily
    Xue, Sherjil Ozair, Christof Angermueller, Xiaowei Li, Anoop Sinha, Weiren Wang,
    Julia Wiesinger, Emmanouil Koukoumidis, Yuan Tian, Anand Iyer, Madhu Gurumurthy,
    Mark Goldenson, Parashar Shah, MK Blake, Hongkun Yu, Anthony Urbanowicz, Jennimaria
    Palomaki, Chrisantha Fernando, Ken Durden, Harsh Mehta, Nikola Momchev, Elahe
    Rahimtoroghi, Maria Georgaki, Amit Raul, Sebastian Ruder, Morgan Redshaw, Jinhyuk
    Lee, Denny Zhou, Komal Jalan, Dinghua Li, Blake Hechtman, Parker Schuh, Milad
    Nasr, Kieran Milan, Vladimir Mikulik, Juliana Franco, Tim Green, Nam Nguyen, Joe
    Kelley, Aroma Mahendru, Andrea Hu, Joshua Howland, Ben Vargas, Jeffrey Hui, Kshitij
    Bansal, Vikram Rao, Rakesh Ghiya, Emma Wang, Ke Ye, Jean Michel Sarr, Melanie Moranski
    Preston, Madeleine Elish, Steve Li, Aakash Kaku, Jigar Gupta, Ice Pasupat, Da-Cheng
    Juan, Milan Someswar, Tejvi M., Xinyun Chen, Aida Amini, Alex Fabrikant, Eric
    Chu, Xuanyi Dong, Amruta Muthal, Senaka Buthpitiya, Sarthak Jauhari, Nan Hua,
    Urvashi Khandelwal, Ayal Hitron, Jie Ren, Larissa Rinaldi, Shahar Drath, Avigail
    Dabush, Nan-Jiang Jiang, Harshal Godhia, Uli Sachs, Anthony Chen, Yicheng Fan,
    Hagai Taitelbaum, Hila Noga, Zhuyun Dai, James Wang, Chen Liang, Jenny Hamer,
    Chun-Sung Ferng, Chenel Elkind, Aviel Atias, Paulina Lee, Vít Listík, Mathias
    Carlen, Jan van de Kerkhof, Marcin Pikus, Krunoslav Zaher, Paul Müller, Sasha
    Zykova, Richard Stefanec, Vitaly Gatsko, Christoph Hirnschall, Ashwin Sethi, Xingyu Federico
    Xu, Chetan Ahuja, Beth Tsai, Anca Stefanoiu, Bo Feng, Keshav Dhandhania, Manish
    Katyal, Akshay Gupta, Atharva Parulekar, Divya Pitta, Jing Zhao, Vivaan Bhatia,
    Yashodha Bhavnani, Omar Alhadlaq, Xiaolin Li, Peter Danenberg, Dennis Tu, Alex
    Pine, Vera Filippova, Abhipso Ghosh, Ben Limonchik, Bhargava Urala, Chaitanya Krishna
    Lanka, Derik Clive, Yi Sun, Edward Li, Hao Wu, Kevin Hongtongsak, Ianna Li, Kalind
    Thakkar, Kuanysh Omarov, Kushal Majmundar, Michael Alverson, Michael Kucharski,
    Mohak Patel, Mudit Jain, Maksim Zabelin, Paolo Pelagatti, Rohan Kohli, Saurabh
    Kumar, Joseph Kim, Swetha Sankar, Vineet Shah, Lakshmi Ramachandruni, Xiangkai
    Zeng, Ben Bariach, Laura Weidinger, Tu Vu, Alek Andreev, Antoine He, Kevin Hui,
    Sheleem Kashem, Amar Subramanya, Sissie Hsiao, Demis Hassabis, Koray Kavukcuoglu,
    Adam Sadovsky, Quoc Le, Trevor Strohman, Yonghui Wu, Slav Petrov, Jeffrey Dean,
    and Oriol Vinyals. 2024. Gemini: A Family of Highly Capable Multimodal Models.
    arXiv:2312.11805 [cs.CL] [https://arxiv.org/abs/2312.11805](https://arxiv.org/abs/2312.11805)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Team et al. (2024) Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste
    Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M. Dai, Anja Hauth,
    Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser,
    Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou,
    Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom Hennigan, Benjamin
    Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens
    Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, Jack Krawczyk,
    Cosmo Du, Ed Chi, Heng-Tze Cheng, Eric Ni, Purvi Shah, Patrick Kane, Betty Chan,
    Manaal Faruqui, Aliaksei Severyn, Hanzhao Lin, YaGuang Li, Yong Cheng, Abe Ittycheriah,
    Mahdis Mahdieh, Mia Chen, Pei Sun, Dustin Tran, Sumit Bagri, Balaji Lakshminarayanan,
    Jeremiah Liu, Andras Orban, Fabian Güra, Hao Zhou, Xinying Song, Aurelien Boffy,
    Harish Ganapathy, Steven Zheng, HyunJeong Choe, Ágoston Weisz, Tao Zhu, Yifeng
    Lu, Siddharth Gopal, Jarrod Kahn, Maciej Kula, Jeff Pitman, Rushin Shah, Emanuel
    Taropa, Majd Al Merey, Martin Baeuml, Zhifeng Chen, Laurent El Shafey, Yujing
    Zhang, Olcan Sercinoglu, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr,
    Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen,
    Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman,
    Jakub Sygnowski, Alexandre Frechette, Charlotte Smith, Laura Culp, Lev Proleev,
    Yi Luan, Xi Chen, James Lottes, Nathan Schucher, Federico Lebron, Alban Rrustemi,
    Natalie Clay, Phil Crone, Tomas Kocisky, Jeffrey Zhao, Bartek Perz, Dian Yu, Heidi
    Howard, Adam Bloniarz, Jack W. Rae, Han Lu, Laurent Sifre, Marcello Maggioni,
    Fred Alcober, Dan Garrette, Megan Barnes, Shantanu Thakoor, Jacob Austin, Gabriel
    Barth-Maron, William Wong, Rishabh Joshi, Rahma Chaabouni, Deeni Fatiha, Arun
    Ahuja, Gaurav Singh Tomar, Evan Senter, Martin Chadwick, Ilya Kornakov, Nithya
    Attaluri, Iñaki Iturrate, Ruibo Liu, Yunxuan Li, Sarah Cogan, Jeremy Chen, Chao
    Jia, Chenjie Gu, Qiao Zhang, Jordan Grimstad, Ale Jakse Hartman, Xavier Garcia,
    Thanumalayan Sankaranarayana Pillai, Jacob Devlin, Michael Laskin, Diego de Las Casas,
    Dasha Valter, Connie Tao, Lorenzo Blanco, Adrià Puigdomènech Badia, David Reitter,
    Mianna Chen, Jenny Brennan, Clara Rivera, Sergey Brin, Shariq Iqbal, Gabriela
    Surita, Jane Labanowski, Abhi Rao, Stephanie Winkler, Emilio Parisotto, Yiming
    Gu, Kate Olszewska, Ravi Addanki, Antoine Miech, Annie Louis, Denis Teplyashin,
    Geoff Brown, Elliot Catt, Jan Balaguer, Jackie Xiang, Pidong Wang, Zoe Ashwood,
    Anton Briukhov, Albert Webson, Sanjay Ganapathy, Smit Sanghavi, Ajay Kannan, Ming-Wei
    Chang, Axel Stjerngren, Josip Djolonga, Yuting Sun, Ankur Bapna, Matthew Aitchison,
    Pedram Pejman, Henryk Michalewski, Tianhe Yu, Cindy Wang, Juliette Love, Junwhan
    Ahn, Dawn Bloxwich, Kehang Han, Peter Humphreys, Thibault Sellam, James Bradbury,
    Varun Godbole, Sina Samangooei, Bogdan Damoc, Alex Kaskasoli, Sébastien M. R.
    Arnold, Vijay Vasudevan, Shubham Agrawal, Jason Riesa, Dmitry Lepikhin, Richard
    Tanburn, Srivatsan Srinivasan, Hyeontaek Lim, Sarah Hodkinson, Pranav Shyam, Johan
    Ferret, Steven Hand, Ankush Garg, Tom Le Paine, Jian Li, Yujia Li, Minh Giang,
    Alexander Neitz, Zaheer Abbas, Sarah York, Machel Reid, Elizabeth Cole, Aakanksha
    Chowdhery, Dipanjan Das, Dominika Rogozińska, Vitaliy Nikolaev, Pablo Sprechmann,
    Zachary Nado, Lukas Zilka, Flavien Prost, Luheng He, Marianne Monteiro, Gaurav
    Mishra, Chris Welty, Josh Newlan, Dawei Jia, Miltiadis Allamanis, Clara Huiyi
    Hu, Raoul de Liedekerke, Justin Gilmer, Carl Saroufim, Shruti Rijhwani, Shaobo
    Hou, Disha Shrivastava, Anirudh Baddepudi, Alex Goldin, Adnan Ozturel, Albin Cassirer,
    Yunhan Xu, Daniel Sohn, Devendra Sachan, Reinald Kim Amplayo, Craig Swanson, Dessie
    Petrova, Shashi Narayan, Arthur Guez, Siddhartha Brahma, Jessica Landon, Miteyan
    Patel, Ruizhe Zhao, Kevin Villela, Luyu Wang, Wenhao Jia, Matthew Rahtz, Mai Giménez,
    Legg Yeung, James Keeling, Petko Georgiev, Diana Mincu, Boxi Wu, Salem Haykal,
    Rachel Saputro, Kiran Vodrahalli, James Qin, Zeynep Cankara, Abhanshu Sharma,
    Nick Fernando, Will Hawkins, Behnam Neyshabur, Solomon Kim, Adrian Hutter, Priyanka
    Agrawal, Alex Castro-Ros, George van den Driessche, Tao Wang, Fan Yang, Shuo yiin
    Chang, Paul Komarek, Ross McIlroy, Mario Lučić, Guodong Zhang, Wael Farhan, Michael
    Sharman, Paul Natsev, Paul Michel, Yamini Bansal, Siyuan Qiao, Kris Cao, Siamak
    Shakeri, Christina Butterfield, Justin Chung, Paul Kishan Rubenstein, Shivani
    Agrawal, Arthur Mensch, Kedar Soparkar, Karel Lenc, Timothy Chung, Aedan Pope,
    Loren Maggiore, Jackie Kay, Priya Jhakra, Shibo Wang, Joshua Maynez, Mary Phuong,
    Taylor Tobin, Andrea Tacchetti, Maja Trebacz, Kevin Robinson, Yash Katariya, Sebastian
    Riedel, Paige Bailey, Kefan Xiao, Nimesh Ghelani, Lora Aroyo, Ambrose Slone, Neil
    Houlsby, Xuehan Xiong, Zhen Yang, Elena Gribovskaya, Jonas Adler, Mateo Wirth,
    Lisa Lee, Music Li, Thais Kagohara, Jay Pavagadhi, Sophie Bridgers, Anna Bortsova,
    Sanjay Ghemawat, Zafarali Ahmed, Tianqi Liu, Richard Powell, Vijay Bolina, Mariko
    Iinuma, Polina Zablotskaia, James Besley, Da-Woon Chung, Timothy Dozat, Ramona
    Comanescu, Xiance Si, Jeremy Greer, Guolong Su, Martin Polacek, Raphaël Lopez
    Kaufman, Simon Tokumine, Hexiang Hu, Elena Buchatskaya, Yingjie Miao, Mohamed
    Elhawaty, Aditya Siddhant, Nenad Tomasev, Jinwei Xing, Christina Greer, Helen
    Miller, Shereen Ashraf, Aurko Roy, Zizhao Zhang, Ada Ma, Angelos Filos, Milos
    Besta, Rory Blevins, Ted Klimenko, Chih-Kuan Yeh, Soravit Changpinyo, Jiaqi Mu,
    Oscar Chang, Mantas Pajarskas, Carrie Muir, Vered Cohen, Charline Le Lan, Krishna
    Haridasan, Amit Marathe, Steven Hansen, Sholto Douglas, Rajkumar Samuel, Mingqiu
    Wang, Sophia Austin, Chang Lan, Jiepu Jiang, Justin Chiu, Jaime Alonso Lorenzo,
    Lars Lowe Sjösund, Sébastien Cevey, Zach Gleicher, Thi Avrahami, Anudhyan Boral,
    Hansa Srinivasan, Vittorio Selo, Rhys May, Konstantinos Aisopos, Léonard Hussenot,
    Livio Baldini Soares, Kate Baumli, Michael B. Chang, Adrià Recasens, Ben Caine,
    Alexander Pritzel, Filip Pavetic, Fabio Pardo, Anita Gergely, Justin Frye, Vinay
    Ramasesh, Dan Horgan, Kartikeya Badola, Nora Kassner, Subhrajit Roy, Ethan Dyer,
    Víctor Campos Campos, Alex Tomala, Yunhao Tang, Dalia El Badawy, El
- en: 'Tyen et al. (2024) Gladys Tyen, Hassan Mansoor, Victor Carbune, Peter Chen,
    and Tony Mak. 2024. LLMs cannot find reasoning errors, but can correct them given
    the error location. In *Findings of the Association for Computational Linguistics:
    ACL 2024*, Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for
    Computational Linguistics, Bangkok, Thailand, 13894–13908. [https://doi.org/10.18653/v1/2024.findings-acl.826](https://doi.org/10.18653/v1/2024.findings-acl.826)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tyen等人（2024）Gladys Tyen, Hassan Mansoor, Victor Carbune, Peter Chen, 和 Tony
    Mak. 2024. LLM不能发现推理错误，但可以在给定错误位置的情况下纠正它们。发表于*计算语言学协会的发现：ACL 2024*，Lun-Wei Ku,
    Andre Martins, 和 Vivek Srikumar（编）。计算语言学协会，泰国曼谷，13894–13908. [https://doi.org/10.18653/v1/2024.findings-acl.826](https://doi.org/10.18653/v1/2024.findings-acl.826)
- en: 'Valmeekam et al. (2024) Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan,
    and Subbarao Kambhampati. 2024. On the planning abilities of large language models:
    a critical investigation. In *Proceedings of the 37th International Conference
    on Neural Information Processing Systems* (New Orleans, LA, USA) *(NIPS ’23)*.
    Curran Associates Inc., Red Hook, NY, USA, Article 3320, 13 pages.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Valmeekam等人（2024）Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, 和 Subbarao
    Kambhampati. 2024. 大语言模型的规划能力：一个批判性的研究。发表于*第37届神经信息处理系统国际会议论文集*（美国路易斯安那州新奥尔良）*(NIPS
    ’23)*. Curran Associates Inc., 美国纽约红钩，文章3320，13页。
- en: Valmeekam et al. (2022) Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan,
    and Subbarao Kambhampati. 2022. Large Language Models Still Can’t Plan (A Benchmark
    for LLMs on Planning and Reasoning about Change). In *NeurIPS 2022 Foundation
    Models for Decision Making Workshop*. [https://openreview.net/forum?id=wUU-7XTL5XO](https://openreview.net/forum?id=wUU-7XTL5XO)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Valmeekam等人（2022）Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, 和 Subbarao
    Kambhampati. 2022. 大语言模型仍然无法进行规划（一个关于规划和推理变化的LLM基准测试）。在*NeurIPS 2022决策模型基础工作坊*中.
    [https://openreview.net/forum?id=wUU-7XTL5XO](https://openreview.net/forum?id=wUU-7XTL5XO)
- en: Varshney (2023) Tanay Varshney. 2023. Introduction to LLM Agents. Blog. Retrieved
    October 7, 2024 from [https://developer.nvidia.com/blog/introduction-to-llm-agents/](https://developer.nvidia.com/blog/introduction-to-llm-agents/)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Varshney（2023）Tanay Varshney. 2023. LLM代理简介. 博客. 2024年10月7日检索自[https://developer.nvidia.com/blog/introduction-to-llm-agents/](https://developer.nvidia.com/blog/introduction-to-llm-agents/)
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is All you Need. In *Advances in Neural Information Processing Systems*, I. Guyon,
    U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
    (Eds.), Vol. 30\. Curran Associates, Inc. [https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani等人（2017）Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
    Jones, Aidan N Gomez, Ł ukasz Kaiser, 和 Illia Polosukhin. 2017. 注意力机制是你所需要的全部。在*神经信息处理系统进展*中，I.
    Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, 和 R.
    Garnett（编），第30卷. Curran Associates, Inc. [https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- en: 'Wang et al. (2023a) Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi (Jim) Fan, and Anima Anandkumar. 2023a. Voyager: An Open-Ended
    Embodied Agent with Large Language Models. *Trans. Mach. Learn. Res.* 2024 (2023).
    [https://api.semanticscholar.org/CorpusID:258887849](https://api.semanticscholar.org/CorpusID:258887849)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang等人（2023a）Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei
    Xiao, Yuke Zhu, Linxi (Jim) Fan, 和 Anima Anandkumar. 2023a. Voyager: 一个基于大语言模型的开放式具身代理。*机器学习研究汇刊*
    2024 (2023年). [https://api.semanticscholar.org/CorpusID:258887849](https://api.semanticscholar.org/CorpusID:258887849)'
- en: Wang et al. (2024c) Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, and Jirong Wen. 2024c. A survey on large language model based autonomous
    agents. *Frontiers of Computer Science* 18, 6 (March 2024). [https://doi.org/10.1007/s11704-024-40231-1](https://doi.org/10.1007/s11704-024-40231-1)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang等人（2024c）Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
    Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei
    Wei, 和 Jirong Wen. 2024c. 基于大语言模型的自主代理的调查。*计算机科学前沿* 18, 6 (2024年3月). [https://doi.org/10.1007/s11704-024-40231-1](https://doi.org/10.1007/s11704-024-40231-1)
- en: 'Wang et al. (2023b) Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan,
    Roy Ka-Wei Lee, and Ee-Peng Lim. 2023b. Plan-and-Solve Prompting: Improving Zero-Shot
    Chain-of-Thought Reasoning by Large Language Models. In *Proceedings of the 61st
    Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
    Papers)*, Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association
    for Computational Linguistics, Toronto, Canada, 2609–2634. [https://doi.org/10.18653/v1/2023.acl-long.147](https://doi.org/10.18653/v1/2023.acl-long.147)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023b）王磊、徐婉玉、蓝一槐、胡志强、蓝云狮、李凯伟和林亦鹏。2023b。计划与解决提示：通过大型语言模型改进零-shot 连锁思维推理。在
    *第61届计算语言学协会年会（第1卷：长篇论文）* 中，Anna Rogers、Jordan Boyd-Graber 和 Naoaki Okazaki（编辑）。计算语言学协会，多伦多，加拿大，2609–2634。[https://doi.org/10.18653/v1/2023.acl-long.147](https://doi.org/10.18653/v1/2023.acl-long.147)
- en: Wang et al. (2024a) Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu
    Li, Hao Peng, and Heng Ji. 2024a. Executable Code Actions Elicit Better LLM Agents.
    In *Forty-first International Conference on Machine Learning*. [https://openreview.net/forum?id=jJ9BoXAfFa](https://openreview.net/forum?id=jJ9BoXAfFa)
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2024a）王星耀、陈阳毅、袁丽凡、张一哲、李云竹、彭浩和纪衡。2024a。可执行代码行动激发更好的 LLM 代理。在 *第41届国际机器学习会议*
    中。[https://openreview.net/forum?id=jJ9BoXAfFa](https://openreview.net/forum?id=jJ9BoXAfFa)
- en: 'Wang et al. (2023c) Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan
    Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, and Qun Liu. 2023c. Aligning Large
    Language Models with Human: A Survey. arXiv:2307.12966 [cs.CL] [https://arxiv.org/abs/2307.12966](https://arxiv.org/abs/2307.12966)'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2023c）王宇飞、钟婉君、李良友、米飞、曾兴山、黄文勇、尚立峰、姜鑫和刘群。2023c。将大型语言模型与人类对齐：一项调查。arXiv:2307.12966
    [cs.CL] [https://arxiv.org/abs/2307.12966](https://arxiv.org/abs/2307.12966)
- en: Wang et al. (2024b) Zhiruo Wang, Zhoujun Cheng, Hao Zhu, Daniel Fried, and Graham
    Neubig. 2024b. What Are Tools Anyway? A Survey from the Language Model Perspective.
    In *First Conference on Language Modeling*. [https://openreview.net/forum?id=Xh1B90iBSR](https://openreview.net/forum?id=Xh1B90iBSR)
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2024b）王志若、程周俊、朱浩、Daniel Fried 和 Graham Neubig。2024b。工具到底是什么？来自语言模型视角的调查。在
    *第一次语言建模会议* 中。[https://openreview.net/forum?id=Xh1B90iBSR](https://openreview.net/forum?id=Xh1B90iBSR)
- en: 'Wang et al. (2024d) Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu
    Wei, and Heng Ji. 2024d. Unleashing the Emergent Cognitive Synergy in Large Language
    Models: A Task-Solving Agent through Multi-Persona Self-Collaboration. In *Proceedings
    of the 2024 Conference of the North American Chapter of the Association for Computational
    Linguistics: Human Language Technologies (Volume 1: Long Papers)*, Kevin Duh,
    Helena Gomez, and Steven Bethard (Eds.). Association for Computational Linguistics,
    Mexico City, Mexico, 257–279. [https://doi.org/10.18653/v1/2024.naacl-long.15](https://doi.org/10.18653/v1/2024.naacl-long.15)'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2024d）王震海龙、毛少光、吴文山、葛涛、魏富如和纪衡。2024d。释放大型语言模型中的突现认知协同：通过多人格自我协作的任务解决代理。在
    *2024年北美计算语言学协会会议：人类语言技术（第1卷：长篇论文）* 中，Kevin Duh、Helena Gomez 和 Steven Bethard（编辑）。计算语言学协会，墨西哥城，墨西哥，257–279。[https://doi.org/10.18653/v1/2024.naacl-long.15](https://doi.org/10.18653/v1/2024.naacl-long.15)
- en: Weng (2023) Lilian Weng. 2023. LLM Powered Autonomous Agents. Blog. Retrieved
    October 8, 2024 from [https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/)
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weng（2023）Lilian Weng。2023。LLM 驱动的自主代理。博客。2024年10月8日从[https://lilianweng.github.io/posts/2023-06-23-agent/](https://lilianweng.github.io/posts/2023-06-23-agent/)检索。
- en: 'Wooldridge and Jennings (1995) Michael Wooldridge and Nicholas R. Jennings.
    1995. Intelligent agents: theory and practice. *The Knowledge Engineering Review*
    10, 2 (1995), 115–152. [https://doi.org/10.1017/S0269888900008122](https://doi.org/10.1017/S0269888900008122)'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wooldridge 和 Jennings（1995）Michael Wooldridge 和 Nicholas R. Jennings。1995。智能代理：理论与实践。*知识工程评论*
    10, 2（1995），115–152。[https://doi.org/10.1017/S0269888900008122](https://doi.org/10.1017/S0269888900008122)
- en: 'Wu et al. (2024a) Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,
    Erkang (Eric) Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Ahmed Awadallah, Ryen W.
    White, Doug Burger, and Chi Wang. 2024a. AutoGen: Enabling Next-Gen LLM Applications
    via Multi-Agent Conversation. In *COLM 2024*.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu 等人（2024a）吴清云、加甘·班萨尔、张杰宇、吴怡然、李贝宾、朱尔康（Eric）、姜立、张晓云、张绍坤、艾哈迈德·阿瓦达拉、Ryen W. White、道格·伯杰和王驰。2024a。AutoGen：通过多代理对话实现下一代
    LLM 应用。在 *COLM 2024* 中。
- en: 'Wu et al. (2024b) Yue Wu, Xuan Tang, Tom Mitchell, and Yuanzhi Li. 2024b. SmartPlay
    : A Benchmark for LLMs as Intelligent Agents. In *The Twelfth International Conference
    on Learning Representations*. [https://openreview.net/forum?id=S2oTVrlcp3](https://openreview.net/forum?id=S2oTVrlcp3)'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu 等人 (2024b) Yue Wu, Xuan Tang, Tom Mitchell, 和 Yuanzhi Li. 2024b. SmartPlay:
    用作智能代理的大型语言模型基准测试. 发表在 *第十二届国际学习表示会议* 上. [https://openreview.net/forum?id=S2oTVrlcp3](https://openreview.net/forum?id=S2oTVrlcp3)'
- en: 'Xi et al. (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan,
    Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou,
    Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang,
    Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui. 2023. The
    Rise and Potential of Large Language Model Based Agents: A Survey. arXiv:2309.07864 [cs.AI]
    [https://arxiv.org/abs/2309.07864](https://arxiv.org/abs/2309.07864)'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xi 等人 (2023) Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang
    Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan,
    Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou,
    Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang,
    Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, 和 Tao Gui. 2023. 基于大型语言模型代理的崛起与潜力：一项调查.
    arXiv:2309.07864 [cs.AI] [https://arxiv.org/abs/2309.07864](https://arxiv.org/abs/2309.07864)
- en: 'Xiong et al. (2024) Zheyang Xiong, Ziyang Cai, John Cooper, Albert Ge, Vasilis
    Papageorgiou, Zack Sifakis, Angeliki Giannou, Ziqian Lin, Liu Yang, Saurabh Agarwal,
    Grigorios G Chrysos, Samet Oymak, Kangwook Lee, and Dimitris Papailiopoulos. 2024.
    Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in
    Superposition. arXiv:2410.05603 [cs.LG] [https://arxiv.org/abs/2410.05603](https://arxiv.org/abs/2410.05603)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiong 等人 (2024) Zheyang Xiong, Ziyang Cai, John Cooper, Albert Ge, Vasilis Papageorgiou,
    Zack Sifakis, Angeliki Giannou, Ziqian Lin, Liu Yang, Saurabh Agarwal, Grigorios
    G Chrysos, Samet Oymak, Kangwook Lee, 和 Dimitris Papailiopoulos. 2024. 《无处不在，瞬时发生：LLMs
    可以在超位态中同时学习多项任务》. arXiv:2410.05603 [cs.LG] [https://arxiv.org/abs/2410.05603](https://arxiv.org/abs/2410.05603)
- en: 'Xu et al. (2023) Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong
    Zhang, and Zhendong Mao. 2023. ExpertPrompting: Instructing Large Language Models
    to be Distinguished Experts. arXiv:2305.14688 [cs.CL] [https://arxiv.org/abs/2305.14688](https://arxiv.org/abs/2305.14688)'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xu 等人 (2023) Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong
    Zhang, 和 Zhendong Mao. 2023. ExpertPrompting: 指导大型语言模型成为卓越专家. arXiv:2305.14688
    [cs.CL] [https://arxiv.org/abs/2305.14688](https://arxiv.org/abs/2305.14688)'
- en: 'Yang et al. (2024) Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung,
    Sha Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, and Chengxiang
    Zhai. 2024. If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code
    Empowers Large Language Models to Serve as Intelligent Agents. arXiv:2401.00812 [cs.CL]
    [https://arxiv.org/abs/2401.00812](https://arxiv.org/abs/2401.00812)'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人 (2024) Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung, Sha Li,
    Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, 和 Chengxiang Zhai. 2024.
    如果 LLM 是魔法师，那么代码就是魔杖：一项关于代码如何赋能大型语言模型以作为智能代理的调查. arXiv:2401.00812 [cs.CL] [https://arxiv.org/abs/2401.00812](https://arxiv.org/abs/2401.00812)
- en: 'Yao et al. (2022) Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan.
    2022. WebShop: Towards Scalable Real-World Web Interaction with Grounded Language
    Agents. In *Advances in Neural Information Processing Systems 35 - 36th Conference
    on Neural Information Processing Systems, NeurIPS 2022* *(Advances in Neural Information
    Processing Systems)*, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho,
    and A. Oh (Eds.). Neural information processing systems foundation. Publisher
    Copyright: © 2022 Neural information processing systems foundation. All rights
    reserved.; 36th Conference on Neural Information Processing Systems, NeurIPS 2022
    ; Conference date: 28-11-2022 Through 09-12-2022.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等人 (2022) Shunyu Yao, Howard Chen, John Yang, 和 Karthik Narasimhan. 2022.
    WebShop: 面向可扩展的现实世界网页交互与基础语言代理. 发表在 *神经信息处理系统进展 35 - 第36届神经信息处理系统会议, NeurIPS 2022*
    *（神经信息处理系统进展）* 中，S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, 和 A.
    Oh (编辑). 神经信息处理系统基金会出版. 出版版权：© 2022 神经信息处理系统基金会。保留所有权利。; 第36届神经信息处理系统会议, NeurIPS
    2022 ; 会议日期：2022年11月28日至2022年12月9日。'
- en: 'Yao et al. (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
    Karthik R Narasimhan, and Yuan Cao. 2023. ReAct: Synergizing Reasoning and Acting
    in Language Models. In *The Eleventh International Conference on Learning Representations*.
    [https://openreview.net/forum?id=WE_vluYUL-X](https://openreview.net/forum?id=WE_vluYUL-X)'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等人 (2023) Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik
    R Narasimhan, 和 Yuan Cao. 2023. ReAct: 协同推理与执行的语言模型. 发表在 *第十一届国际学习表示会议* 上. [https://openreview.net/forum?id=WE_vluYUL-X](https://openreview.net/forum?id=WE_vluYUL-X)'
- en: 'Zhang et al. (2024b) Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, and Zhi Jin.
    2024b. CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems
    for Real-World Repo-level Coding Challenges. In *Proceedings of the 62nd Annual
    Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*,
    Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for Computational
    Linguistics, Bangkok, Thailand, 13643–13658. [https://doi.org/10.18653/v1/2024.acl-long.737](https://doi.org/10.18653/v1/2024.acl-long.737)'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人（2024b）Kechi Zhang、Jia Li、Ge Li、Xianjie Shi和Zhi Jin。2024b。CodeAgent：通过工具集成代理系统增强代码生成，解决现实世界的仓库级编码挑战。在*第62届计算语言学协会年会论文集（卷1：长篇论文）*中，Lun-Wei
    Ku、Andre Martins和Vivek Srikumar（编辑）。计算语言学协会，泰国曼谷，13643–13658。[https://doi.org/10.18653/v1/2024.acl-long.737](https://doi.org/10.18653/v1/2024.acl-long.737)
- en: 'Zhang et al. (2024a) Li Zhang, Peter Jansen, Tianyi Zhang, Peter Clark, Chris
    Callison-Burch, and Niket Tandon. 2024a. PDDLEGO: Iterative Planning in Textual
    Environments. In *Proceedings of the 13th Joint Conference on Lexical and Computational
    Semantics (*SEM 2024)*, Danushka Bollegala and Vered Shwartz (Eds.). Association
    for Computational Linguistics, Mexico City, Mexico, 212–221. [https://doi.org/10.18653/v1/2024.starsem-1.17](https://doi.org/10.18653/v1/2024.starsem-1.17)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人（2024a）Li Zhang、Peter Jansen、Tianyi Zhang、Peter Clark、Chris Callison-Burch和Niket
    Tandon。2024a。PDDLEGO：文本环境中的迭代规划。在*第13届联合词汇与计算语义学会议（*SEM 2024）*上，Danushka Bollegala和Vered
    Shwartz（编辑）。计算语言学协会，墨西哥城，墨西哥，212–221。[https://doi.org/10.18653/v1/2024.starsem-1.17](https://doi.org/10.18653/v1/2024.starsem-1.17)
- en: 'Zhang et al. (2024c) Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Yan Xia,
    Wenshan Wu, Ting Song, Man Lan, and Furu Wei. 2024c. LLM as a Mastermind: A Survey
    of Strategic Reasoning with Large Language Models. In *First Conference on Language
    Modeling*. [https://openreview.net/forum?id=iMqJsQ4evS](https://openreview.net/forum?id=iMqJsQ4evS)'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等人（2024c）Yadong Zhang、Shaoguang Mao、Tao Ge、Xun Wang、Yan Xia、Wenshan Wu、Ting
    Song、Man Lan和Furu Wei。2024c。LLM作为战略 mastermind：使用大规模语言模型进行战略推理的调研。在*第一届语言建模会议*上。[https://openreview.net/forum?id=iMqJsQ4evS](https://openreview.net/forum?id=iMqJsQ4evS)
- en: 'Zhong et al. (2024) Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin
    Wang. 2024. MemoryBank: Enhancing Large Language Models with Long-Term Memory.
    *Proceedings of the AAAI Conference on Artificial Intelligence* 38, 17 (Mar. 2024),
    19724–19731. [https://doi.org/10.1609/aaai.v38i17.29946](https://doi.org/10.1609/aaai.v38i17.29946)'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong等人（2024）Wanjun Zhong、Lianghong Guo、Qiqi Gao、He Ye和Yanlin Wang。2024。MemoryBank：通过长期记忆增强大规模语言模型。*2024年AAAI人工智能会议论文集*，38卷，17期（2024年3月），19724–19731。[https://doi.org/10.1609/aaai.v38i17.29946](https://doi.org/10.1609/aaai.v38i17.29946)
- en: Zhou et al. (2023) Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan
    Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le,
    and Ed H. Chi. 2023. Least-to-Most Prompting Enables Complex Reasoning in Large
    Language Models. In *The Eleventh International Conference on Learning Representations*.
    [https://openreview.net/forum?id=WZH7099tgfM](https://openreview.net/forum?id=WZH7099tgfM)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等人（2023）Denny Zhou、Nathanael Schärli、Le Hou、Jason Wei、Nathan Scales、Xuezhi
    Wang、Dale Schuurmans、Claire Cui、Olivier Bousquet、Quoc V Le和Ed H. Chi。2023。最小到最多提示法使大规模语言模型能够进行复杂推理。在*第十一届国际学习表征会议*上。[https://openreview.net/forum?id=WZH7099tgfM](https://openreview.net/forum?id=WZH7099tgfM)
